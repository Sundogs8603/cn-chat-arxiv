# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Emergent and Predictable Memorization in Large Language Models.](http://arxiv.org/abs/2304.11158) | 该论文的研究发现中间检查点比完全训练的模型更好地预测模型的记忆化行为，并且发现了大型语言模型中记忆化得分的分布规律。 |
| [^2] | [Automated Mapping of CVE Vulnerability Records to MITRE CWE Weaknesses.](http://arxiv.org/abs/2304.11130) | 该论文介绍了一种自动将CVE漏洞记录映射到MITRE CWE弱点的方法，并提供了一个手动注释的数据集，可用于解决此问题的监督式机器学习。 |
| [^3] | [Inducing anxiety in large language models increases exploration and bias.](http://arxiv.org/abs/2304.11111) | 对大型语言模型施加焦虑能影响它们的探索性和偏见，这需要更多道德考虑和监管。 |
| [^4] | [ChatABL: Abductive Learning via Natural Language Interaction with ChatGPT.](http://arxiv.org/abs/2304.11107) | 本研究提出了一种新方法ChatABL，将大型语言模型LLM整合到归纳学习ABL框架中，通过自然语言对话实现交互式学习，旨在以更加用户友好和易理解的方式统一感知、语言理解和推理能力。实验结果显示，ChatABL可以更有效和高效地学习解决归纳推理问题。 |
| [^5] | [Is Cross-modal Information Retrieval Possible without Training?.](http://arxiv.org/abs/2304.11095) | 本论文研究了不需要训练，基于简单映射的跨模态信息检索方法，利用来自预训练深度学习模型的编码表示。这种方法可以在语义上将不同模态的数据映射到同一空间，并在文本和图像之间达到有竞争力的性能水平。 |
| [^6] | [Effectiveness of Debiasing Techniques: An Indigenous Qualitative Analysis.](http://arxiv.org/abs/2304.11094) | 本文以本土的视角探讨了针对预训练语言模型去偏见技术的有效性，呼吁在算法中纳入本地知识和理解以确保公正，特别是在面对资源受限的社会时。 |
| [^7] | [Hi Sheldon! Creating Deep Personalized Characters from TV Shows.](http://arxiv.org/abs/2304.11093) | 从多模态数据中通过DPCC创造出能够与用户进行视听交互的深度个性化数字角色，并收集了一个包含近10k个话语和6个小时音频/视频的角色中心多模态对话数据集。 |
| [^8] | [Towards Responsible AI in the Era of ChatGPT: A Reference Architecture for Designing Foundation Model-based AI Systems.](http://arxiv.org/abs/2304.11090) | 本文提出了一个以模式为导向的负责任AI-by-design参考架构，用于设计基于基础模型的AI系统，重点关注可解释性、公平性、安全性和鲁棒性等关键设计元素。 |
| [^9] | [Profiling the news spreading barriers using news headlines.](http://arxiv.org/abs/2304.11088) | 本文利用新闻标题的语义知识和情感特征来对新闻传播障碍进行分类，可以有效地检测新闻传播障碍。 |
| [^10] | [Testing the Reliability of ChatGPT for Text Annotation and Classification: A Cautionary Remark.](http://arxiv.org/abs/2304.11085) | 本研究测试了ChatGPT在文本标注和分类中的可靠性，结果显示输出的一致性不足以满足科学可靠性的阈值，因此使用ChatGPT时需要谨慎。 |
| [^11] | [Fundamental Limitations of Alignment in Large Language Models.](http://arxiv.org/abs/2304.11082) | 本文通过提出一种理论方法——行为期望边界（BEB），展示了大型语言模型中对齐的基本限制，并证明任何对齐过程都无法根除不希望的行为，这对于防止恶意攻击是不安全的。 |
| [^12] | [HeRo: RoBERTa and Longformer Hebrew Language Models.](http://arxiv.org/abs/2304.11077) | 本论文提供了希伯来语言处理社区所需的最大预训练数据集HeDC4，以及两种表现最先进的预训练语言模型：用于标准长度输入的HeRo和用于长输入序列的LongHeRo。两个模型在多项任务中实现了最先进的性能。 |
| [^13] | [Can ChatGPT-like Generative Models Guarantee Factual Accuracy? On the Mistakes of New Generation Search Engines.](http://arxiv.org/abs/2304.11076) | 论文质疑类ChatGPT生成模型是否能保证事实准确性，很多新一代搜索引擎的公开演示中存在事实错误，呼吁科研人员和开发人员提高透明度和事实正确性。 |
| [^14] | [Spaiche: Extending State-of-the-Art ASR Models to Swiss German Dialects.](http://arxiv.org/abs/2304.11075) | 本项目在瑞士德语方言ASR模型的研究中提供了有价值的思路，通过提出考虑语义距离的新颖损失函数，对OpenAI的Whisper模型进行微调，取得了优于当前先进成果的效果。 |
| [^15] | [OLISIA: a Cascade System for Spoken Dialogue State Tracking.](http://arxiv.org/abs/2304.11073) | 我们提出了OLISIA，一个口语对话状态跟踪的级联系统，使用自动语音识别和DST模型，采用几个适应性策略来提高稳健性，并在DSTC11 Track3中取得第一名的好成绩。 |
| [^16] | [Conversational Process Modelling: State of the Art, Applications, and Implications in Practice.](http://arxiv.org/abs/2304.11065) | 本文系统的研究了现有聊天机器人对于支持对话式流程建模所提供的应用场景，并推导出了在实践中使用聊天机器人进行对话式流程建模的建议。 |
| [^17] | [Think Before You Act: Unified Policy for Interleaving Language Reasoning with Actions.](http://arxiv.org/abs/2304.11063) | 本文提出了一种新的方法，将语言推理与动作统一在单个策略中，利用 transformer 模型，能够生成交替使用动作的文本标题。在 BabyAI 任务中测试，我们的推理策略始终优于没有标题的基准线。 |
| [^18] | [Scaling Transformer to 1M tokens and beyond with RMT.](http://arxiv.org/abs/2304.11062) | 本文介绍了一种利用循环记忆扩展BERT上下文长度的方法，成功扩展到了前所未有的200万个标记，有望增强自然语言处理中的长期依赖处理并为内存密集型应用程序实现大规模上下文处理。 |
| [^19] | [CEIL: A General Classification-Enhanced Iterative Learning Framework for Text Clustering.](http://arxiv.org/abs/2304.11061) | CEIL是一种迭代学习框架，通过引入分类目标来改进特征表示和文本聚类效果，能够普适于不同领域的文本聚类任务。 |
| [^20] | [SkillGPT: a RESTful API service for skill extraction and standardization using a Large Language Model.](http://arxiv.org/abs/2304.11060) | SkillGPT是一种使用大型语言模型进行技能提取和标准化的RESTful API服务，通过摘要和向量相似性搜索平衡速度和准确度。 |
| [^21] | [Novel Intent Detection and Active Learning Based Classification (Student Abstract).](http://arxiv.org/abs/2304.11058) | 本文提出了一个名为NIDAL的人工智能框架，可以自动检测不同语言中出现的新型意图类别并减少人员标注成本，通过在多个基准数据集上的实验证明，该系统可以实现高准确率和宏F1值。 |
| [^22] | [A Comparison of Semi-Supervised Learning Techniques for Streaming ASR at Scale.](http://arxiv.org/abs/2304.11053) | 比较三种半监督ASR方法的优劣，发现这些方法不仅在原始WER方面有所提高，而且在尾部单词WER、推理过程中的解码器计算和栅格密度等方面都有显著的提高。 |
| [^23] | [Affective social anthropomorphic intelligent system.](http://arxiv.org/abs/2304.11046) | 本研究提出了一种情感社交化人形智能系统，可以更好地理解人类声音的情感语义，实现类人对话。 |
| [^24] | [Emotional Expression Detection in Spoken Language Employing Machine Learning Algorithms.](http://arxiv.org/abs/2304.11040) | 通过使用MATLAB函数和机器学习算法，研究人员利用声音的特征来识别人类不同的情感，提高了机器学习模型的效率。 |
| [^25] | [DIN-SQL: Decomposed In-Context Learning of Text-to-SQL with Self-Correction.](http://arxiv.org/abs/2304.11015) | DIN-SQL通过将复杂的文本到SQL任务分解为子问题，并将这些子问题的解决方案馈入到大型语言模型中，显著提高了它们的表现，使准确性超过了当前最先进的技术。 |
| [^26] | [BERT Based Clinical Knowledge Extraction for Biomedical Knowledge Graph Construction and Analysis.](http://arxiv.org/abs/2304.10996) | 本文提出了一种基于BERT和CRF技术的生物医学临床笔记知识提取和分析的端到端方法，用于构建和分析生物医学知识图谱。 |
| [^27] | [Information Extraction from Documents: Question Answering vs Token Classification in real-world setups.](http://arxiv.org/abs/2304.10994) | 本研究比较了传统标记分类和新兴问答方法在文献信息提取方面的表现，并发现问答方法在处理复杂信息的文档时更加有效。 |
| [^28] | [Evaluating Transformer Language Models on Arithmetic Operations Using Number Decomposition.](http://arxiv.org/abs/2304.10977) | 本文评估了使用数字分解技术进行微调后的变形金刚语言模型在执行算术运算时的表现。结果显示，这种方法在五位数字加法任务中的准确度提高了63%。 |
| [^29] | [LEIA: Linguistic Embeddings for the Identification of Affect.](http://arxiv.org/abs/2304.10973) | 该论文提出了一种名为LEIA的情感识别模型，使用了由超过6百万个自注释文本帖子组成的数据集进行训练，利用掩蔽单词的方法增强模型预训练过程中对情感单词的学习，并在三个测试数据集上实现了约73的宏F1值，优于其他方法。 |
| [^30] | [CancerGPT: Few-shot Drug Pair Synergy Prediction using Large Pre-trained Language Models.](http://arxiv.org/abs/2304.10946) | CancerGPT 是一种基于LLMs的少样本学习技术，可在生物学推断中预测罕见组织中的药物对协同作用。实验表明该技术准确性高，即使在样本数据非常有限的情况下仍可进行预测。 |
| [^31] | [Text2Time: Transformer-based article time period predictor.](http://arxiv.org/abs/2304.10859) | 本文提出了一个基于Transformer模型的文章时间段预测器，使用预训练的BERT模型对新闻文章进行分类的结果表现优于先前尝试的模型，具有很高的准确性。 |
| [^32] | [Better Sign Language Translation with Monolingual Data.](http://arxiv.org/abs/2304.10844) | 本文提出了一种规则转换方法，可以自动将大规模单语数据转录为其伪手语编码以提高手语翻译的翻译质量。该方法在两个基准数据集上实现了最新的技术能力。 |
| [^33] | [Tokenization Tractability for Human and Machine Learning Model: An Annotation Study.](http://arxiv.org/abs/2304.10813) | 研究比较了六种分词方法，并发现人类可追溯的分词与机器学习模型中的分词不一定相同。 |
| [^34] | [Downstream Task-Oriented Neural Tokenizer Optimization with Vocabulary Restriction as Post Processing.](http://arxiv.org/abs/2304.10808) | 本文提出了一种针对预先训练的下游模型优化 tokenization 的方法，通过限制词汇的方式可以生成更低损失值的 tokenization 结果，并训练一个复现 tokenization 结果的分词器。实验证明该方法可以提高 tokenization 的性能。 |
| [^35] | [Which Factors Predict the Chat Experience of a Natural Language Generation Dialogue Service?.](http://arxiv.org/abs/2304.10785) | 本文研究了自然语言生成对话系统中影响聊天体验的多种因素，包括提示、连贯性、情感、相似性和用户对话代理的好感度，发现用户的好感度和连贯性、情感、相似性是聊天体验的正向预测因素。此外，用户可能更喜欢具有外向性、开放性、责任心、宜人性和非神经质特征的对话代理。 |
| [^36] | [Eyettention: An Attention-based Dual-Sequence Model for Predicting Human Scanpaths during Reading.](http://arxiv.org/abs/2304.10784) | Eyettention是第一个同时处理语言序列和时间序列的阅读模型，可以更准确地模拟阅读者的扫视路径，对机器学习的自然语言处理模型具有借鉴意义。 |
| [^37] | [GeoLayoutLM: Geometric Pre-training for Visual Information Extraction.](http://arxiv.org/abs/2304.10759) | 本文提出了一个名为GeoLayoutLM的预训练模型，能够显式地建模预训练的几何关系，在关系提取任务中取得了最优结果。 |
| [^38] | [Improving Grounded Language Understanding in a Collaborative Environment by Interacting with Agents Through Help Feedback.](http://arxiv.org/abs/2304.10750) | 研究通过互动反馈与代理交互来提高协作环境下基于实地理解的能力。 |
| [^39] | [KitchenScale: Learning to predict ingredient quantities from recipe contexts.](http://arxiv.org/abs/2304.10739) | KitchenScale是一个经过Fine-tuned的预训练语言模型（PLM），可根据食谱上下文预测目标成分的数量和测量单位。该模型采用离散潜在指数（DExp）方法处理食谱语料库中数字尺度的高方差，尝试从食谱文本到PLMs的转移学习。在新构建的数据集和推荐示例上进行实验，证明了KitchenScale具有泛化性并可以理解各种食谱语境，同时提供了一个Web应用程序来为用户提供所需的食品量的配方特定的测量单位。 |
| [^40] | [ReCEval: Evaluating Reasoning Chains via Correctness and Informativeness.](http://arxiv.org/abs/2304.10703) | 本文提出了一种基于推导链正确性和信息量的推理链评估框架ReCEval，用以评估多步推理能力。该框架能够客观、系统和准确地评估推理链，并在多个数据集上实现了良好的效果。 |
| [^41] | [Meta Semantics: Towards better natural language understanding and reasoning.](http://arxiv.org/abs/2304.10663) | 该论文提出了解决词汇外问题的两种策略以及一个用于更好的自然语言理解和推理的语义模型，旨在克服深度神经网络方法和基于规则方法的不足。 |
| [^42] | [Word Sense Induction with Knowledge Distillation from BERT.](http://arxiv.org/abs/2304.10642) | 本文提出了一种从BERT中蒸馏知识进行多词义识别的方法，可有效地利用词的多个语义感知，在资源限制的情况下获得与最先进的多词义嵌入相当的结果。 |
| [^43] | [IXA/Cogcomp at SemEval-2023 Task 2: Context-enriched Multilingual Named Entity Recognition using Knowledge Bases.](http://arxiv.org/abs/2304.10637) | 本文提出了一种基于知识库的上下文增强的多语言命名实体识别方法，通过识别、链接和预测实体类别，能够准确地分类细粒度和新兴实体。 |
| [^44] | ["HOT" ChatGPT: The promise of ChatGPT in detecting and discriminating hateful, offensive, and toxic comments on social media.](http://arxiv.org/abs/2304.10619) | 本研究使用ChatGPT探究了生成式AI模型检测社交媒体上有害评论的可行性，结果显示ChatGPT可以达到约80%的准确性。 |
| [^45] | [Multi-aspect Repetition Suppression and Content Moderation of Large Language Models.](http://arxiv.org/abs/2304.10611) | 本文介绍了一种使用标记和序列级别的不可能性损失，以及在培训期间的重复惩罚、推理和后处理等多层面方法来抑制大型语言模型中的重复，并避免生成攻击性内容的能力。 |
| [^46] | [Supporting Qualitative Analysis with Large Language Models: Combining Codebook with GPT-3 for Deductive Coding.](http://arxiv.org/abs/2304.10548) | 本研究探讨了使用大型语言模型来支持定性分析中的演绎编码。通过结合GPT-3和专家编写的编码本，研究人员成功地实现了与专家编码结果相近的标记结果，并且还允许进行高效和有效的编码本优化。 |
| [^47] | [Towards a Benchmark for Scientific Understanding in Humans and Machines.](http://arxiv.org/abs/2304.10327) | 该论文提出了一个框架来创建衡量人类和人工智能科学理解的基准。他们使用了行为观念，提出了一组问题以衡量不同水平的科学理解。这个框架可以帮助评估和比较不同水平和方法的科学理解。 |
| [^48] | [Chinese Open Instruction Generalist: A Preliminary Release.](http://arxiv.org/abs/2304.07987) | 本论文旨在通过适应不同子任务的固有特性，创建一个中文指令数据集，以填补指令调整技术在中文语言领域的空白。 |
| [^49] | [An investigation of speaker independent phrase break models in End-to-End TTS systems.](http://arxiv.org/abs/2304.04157) | 本文研究了在端到端TTS系统中，加入语调断点预测模型是否有用以及如何衡量其有效性。经过实验验证，使用训练好的语调模型预测断点的故事比未使用预测断点的故事更受欢迎。 |
| [^50] | [Unleashing the Power of ChatGPT for Translation: An Empirical Study.](http://arxiv.org/abs/2304.02182) | 本文实证研究了在机器翻译中采用ChatGPT辅助的效果。实验结果表明，ChatGPT具有与专业翻译系统相当甚至更好的性能，并且在特定领域的翻译上表现优异。 |
| [^51] | [Combat AI With AI: Counteract Machine-Generated Fake Restaurant Reviews on Social Media.](http://arxiv.org/abs/2302.07731) | 本文针对机器生成的虚假评论提出了一种用高质量餐厅评论生成虚假评论并微调GPT输出检测器的方法，该方法预测虚假评论的性能优于现有解决方案。同时，我们还探索了预测非精英评论的模型，并在几个维度上对这些评论进行分析，此类机器生成的虚假评论是社交媒体平台面临的持续挑战。 |
| [^52] | [Large Language Models are Versatile Decomposers: Decompose Evidence and Questions for Table-based Reasoning.](http://arxiv.org/abs/2301.13808) | 这篇论文介绍了利用大型语言模型作为分解器，解决基于表格推理中的性能下降和复杂问题的问题，并在多个基准数据集上显著优于现有方法。 |
| [^53] | [tieval: An Evaluation Framework for Temporal Information Extraction Systems.](http://arxiv.org/abs/2301.04643) | 本文提出了tieval，一种用于时间信息抽取系统的评估框架，它提供了标准的接口和评估指标，以克服不同数据集注释体系的差异、解析不同语料库的格式和不同的评估指标等限制。本文通过分析几个TIE系统在不同数据集上的结果，证明了tieval的有效性。 |
| [^54] | [Distill the Image to Nowhere: Inversion Knowledge Distillation for Multimodal Machine Translation.](http://arxiv.org/abs/2210.04468) | 本文提出 IKD-MMT 框架来支持无图像推断的多模式机器翻译，并通过在源文本中生成多模式特征来实现。该框架在多个基准数据集上表现出优异的性能，为实际应用场景中缺乏对齐图像的机器翻译提供了可行的解决方案。 |
| [^55] | [Large scale analysis of gender bias and sexism in song lyrics.](http://arxiv.org/abs/2208.02052) | 本文对377808首英文歌曲歌词进行大规模的自然语言处理分析，揭示了及时的性别歧视的增加以及不同性别表演者的语言偏见。 |

# 详细

[^1]: 大型语言模型中的突现和可预知性记忆

    Emergent and Predictable Memorization in Large Language Models. (arXiv:2304.11158v1 [cs.CL])

    [http://arxiv.org/abs/2304.11158](http://arxiv.org/abs/2304.11158)

    该论文的研究发现中间检查点比完全训练的模型更好地预测模型的记忆化行为，并且发现了大型语言模型中记忆化得分的分布规律。

    

    记忆化是大型语言模型（LLMs）输出其训练数据完全相同序列的倾向，这是安全部署语言模型的关键问题之一。特别地，最小化模型对包含个人可识别信息（PII）等敏感数据点的记忆化是至关重要的。这种不良的记忆化的普及可能会给模型训练者带来问题，甚至可能需要丢弃否则功能良好的模型。因此，我们试图通过推断低计算力试验运行的记忆化行为来预测哪些序列将在大型模型的全局培训期间进行记忆化。我们测量了Pythia模型套件的记忆化，发现中间检查点比较小的已完全训练模型更好地预测了模型的记忆化行为。此外，我们还提供了有关模型和数据记忆化分数分布的进一步新发现。

    Memorization, or the tendency of large language models (LLMs) to output entire sequences from their training data verbatim, is a key concern for safely deploying language models. In particular, it is vital to minimize a model's memorization of sensitive datapoints such as those containing personal identifiable information (PII). The prevalence of such undesirable memorization can pose issues for model trainers, and may even require discarding an otherwise functional model. We therefore seek to predict which sequences will be memorized before a large model's full train-time by extrapolating the memorization behavior of lower-compute trial runs. We measure memorization of the Pythia model suite, and find that intermediate checkpoints are better predictors of a model's memorization behavior than smaller fully-trained models. We additionally provide further novel discoveries on the distribution of memorization scores across models and data.
    
[^2]: 自动将CVE漏洞记录映射到MITRE CWE弱点

    Automated Mapping of CVE Vulnerability Records to MITRE CWE Weaknesses. (arXiv:2304.11130v1 [cs.CR])

    [http://arxiv.org/abs/2304.11130](http://arxiv.org/abs/2304.11130)

    该论文介绍了一种自动将CVE漏洞记录映射到MITRE CWE弱点的方法，并提供了一个手动注释的数据集，可用于解决此问题的监督式机器学习。

    

    最近几年，网络安全威胁和多样性的增加导致了漏洞报告和分析的增加。为了应对这一问题，许多非营利组织在这一领域崛起，如MITRE和OSWAP，他们一直在积极追踪漏洞，并以标准化格式发布防御建议。由于手动生产这种格式的数据非常耗时，因此一些提议试图自动化该过程。不幸的是，采用监督式机器学习解决此问题的一个重要障碍是缺乏公开的专业数据集。在此，我们旨在弥合这一差距。特别是，我们专注于将CVE记录映射到MITRE CWE弱点，并向研究社区发布了一个手动注释的数据集，其中包含4,012条记录。在考虑到人在循环框架的情况下，我们将问题视为排名任务，并旨在采用强化学习来利用其中。

    In recent years, a proliferation of cyber-security threats and diversity has been on the rise culminating in an increase in their reporting and analysis. To counter that, many non-profit organizations have emerged in this domain, such as MITRE and OSWAP, which have been actively tracking vulnerabilities, and publishing defense recommendations in standardized formats. As producing data in such formats manually is very time-consuming, there have been some proposals to automate the process. Unfortunately, a major obstacle to adopting supervised machine learning for this problem has been the lack of publicly available specialized datasets. Here, we aim to bridge this gap. In particular, we focus on mapping CVE records into MITRE CWE Weaknesses, and we release to the research community a manually annotated dataset of 4,012 records for this task. With a human-in-the-loop framework in mind, we approach the problem as a ranking task and aim to incorporate reinforced learning to make use of the
    
[^3]: 引发大型语言模型的焦虑会增加它们的探索性和偏见

    Inducing anxiety in large language models increases exploration and bias. (arXiv:2304.11111v1 [cs.CL])

    [http://arxiv.org/abs/2304.11111](http://arxiv.org/abs/2304.11111)

    对大型语言模型施加焦虑能影响它们的探索性和偏见，这需要更多道德考虑和监管。

    

    大型语言模型正在改变机器学习研究，引发公众的辩论。理解这些模型不仅何时能够正常工作和成功，也为什么会失败和行为失常，具有巨大的社会意义。我们提出将计算精神病学的视角转向这些模型产生的输出。本文着眼于Generative Pre-Trained Transformer 3.5，并将其置于精神病学中常见的任务中。结果表明，GPT-3.5对常见的焦虑问卷做出有力的反应，产生比人类主体更高的焦虑分数。此外，使用情绪感应提示可以可预测地改变GPT-3.5的反应。情感感应不仅影响GPT-3.5在衡量探索决策-making的认知任务中的行为，还影响其在之前建立的衡量种族主义和失能主义等偏见的任务中的行为。至关重要的是，GPT-3.5在受到焦虑诱导时呈现出明显的探索性和偏见增加，表明其输出容易受到情感操纵的影响。这些结果突显了在语言模型的开发和使用过程中需要更多的道德考虑和监管。

    Large language models are transforming research on machine learning while galvanizing public debates. Understanding not only when these models work well and succeed but also why they fail and misbehave is of great societal relevance. We propose to turn the lens of computational psychiatry, a framework used to computationally describe and modify aberrant behavior, to the outputs produced by these models. We focus on the Generative Pre-Trained Transformer 3.5 and subject it to tasks commonly studied in psychiatry. Our results show that GPT-3.5 responds robustly to a common anxiety questionnaire, producing higher anxiety scores than human subjects. Moreover, GPT-3.5's responses can be predictably changed by using emotion-inducing prompts. Emotion-induction not only influences GPT-3.5's behavior in a cognitive task measuring exploratory decision-making but also influences its behavior in a previously-established task measuring biases such as racism and ableism. Crucially, GPT-3.5 shows a s
    
[^4]: ChatABL：通过与ChatGPT的自然语言交互实现归纳学习

    ChatABL: Abductive Learning via Natural Language Interaction with ChatGPT. (arXiv:2304.11107v1 [cs.CL])

    [http://arxiv.org/abs/2304.11107](http://arxiv.org/abs/2304.11107)

    本研究提出了一种新方法ChatABL，将大型语言模型LLM整合到归纳学习ABL框架中，通过自然语言对话实现交互式学习，旨在以更加用户友好和易理解的方式统一感知、语言理解和推理能力。实验结果显示，ChatABL可以更有效和高效地学习解决归纳推理问题。

    

    最近，像ChatGPT这样的大型语言模型(LLM)已经展示出在数学能力方面的重大潜力，并提供了一种与人类自然语言一致的有价值的推理范式。然而，由于它们之间底层信息流的不兼容性，LLM目前难以在感知、语言理解和推理能力之间建立桥梁，使得实现自主任务变得具有挑战性。另一方面，用于将感知和推理两种能力整合的归纳学习(ABL)框架在不完整事实的逆向解密方面取得了重大成功，但它受到逻辑推理规则的语义理解不足以及依赖于复杂的领域知识表示的限制。本文提出了一种新方法(ChatABL)，将LLM整合到ABL框架中，旨在以更加用户友好和易理解的方式统一这三种能力。所提出的方法利用LLM的优势通过自然语言交流进行交互式学习，实现归纳推理。ChatABL框架旨在使LLM在感知和推理能力之间建立桥梁，结合深度学习和符号推理的自然语言处理能力。实验结果表明，与现有的ABL模型相比，ChatABL可以更有效和高效地学习解决归纳推理问题。

    Large language models (LLMs) such as ChatGPT have recently demonstrated significant potential in mathematical abilities, providing valuable reasoning paradigm consistent with human natural language. However, LLMs currently have difficulty in bridging perception, language understanding and reasoning capabilities due to incompatibility of the underlying information flow among them, making it challenging to accomplish tasks autonomously. On the other hand, abductive learning (ABL) frameworks for integrating the two abilities of perception and reasoning has seen significant success in inverse decipherment of incomplete facts, but it is limited by the lack of semantic understanding of logical reasoning rules and the dependence on complicated domain knowledge representation. This paper presents a novel method (ChatABL) for integrating LLMs into the ABL framework, aiming at unifying the three abilities in a more user-friendly and understandable manner. The proposed method uses the strengths o
    
[^5]: 不需要训练，跨模态信息检索是否可行？

    Is Cross-modal Information Retrieval Possible without Training?. (arXiv:2304.11095v1 [cs.LG])

    [http://arxiv.org/abs/2304.11095](http://arxiv.org/abs/2304.11095)

    本论文研究了不需要训练，基于简单映射的跨模态信息检索方法，利用来自预训练深度学习模型的编码表示。这种方法可以在语义上将不同模态的数据映射到同一空间，并在文本和图像之间达到有竞争力的性能水平。

    

    预训练深度学习模型中编码的表示(例如BERT文本嵌入，图像的倒数第二个卷积神经网络层激活)传递了一组有益的信息检索特征。给定数据模态的嵌入存在自己的高维空间中，但可以通过简单的映射进行语义对齐。在本文中，我们使用来自最小二乘法和奇异值分解 (SVD) 的简单映射作为Procrustes问题的解决方案，从而实现跨模态信息检索的手段。也就是说，给定一个模态中的信息，例如文本，该映射可以帮助我们在另一个模态中找到与其语义相当的数据项，例如图像。使用现成的预训练深度学习模型，我们在文本到图像和图像到文本的检索任务中尝试了上述简单的跨模态映射。尽管简单，我们的映射表现出竞争性的性能，并达到了与最先进方法相当的水平。

    Encoded representations from a pretrained deep learning model (e.g., BERT text embeddings, penultimate CNN layer activations of an image) convey a rich set of features beneficial for information retrieval. Embeddings for a particular modality of data occupy a high-dimensional space of its own, but it can be semantically aligned to another by a simple mapping without training a deep neural net. In this paper, we take a simple mapping computed from the least squares and singular value decomposition (SVD) for a solution to the Procrustes problem to serve a means to cross-modal information retrieval. That is, given information in one modality such as text, the mapping helps us locate a semantically equivalent data item in another modality such as image. Using off-the-shelf pretrained deep learning models, we have experimented the aforementioned simple cross-modal mappings in tasks of text-to-image and image-to-text retrieval. Despite simplicity, our mappings perform reasonably well reachin
    
[^6]: 去偏见技术的有效性：一个本土的定性分析

    Effectiveness of Debiasing Techniques: An Indigenous Qualitative Analysis. (arXiv:2304.11094v1 [cs.CL])

    [http://arxiv.org/abs/2304.11094](http://arxiv.org/abs/2304.11094)

    本文以本土的视角探讨了针对预训练语言模型去偏见技术的有效性，呼吁在算法中纳入本地知识和理解以确保公正，特别是在面对资源受限的社会时。

    

    本文以本土的视角，探讨了针对预训练语言模型（PLMs）去偏见技术的有效性。目前衡量与去偏见PLMs使用的技术存在美国种族偏见的倾向，并且依赖于预定义的偏见属性（例如“黑人”与“白人”）。有些技术需要大量数据集和进一步的预训练。这样的技术并不能捕捉其他国家中被较少代表的土著人口，例如新西兰的毛利人。必须纳入本地的知识和理解，以确保公正的算法，特别是在面对资源受限的社会时。

    An indigenous perspective on the effectiveness of debiasing techniques for pre-trained language models (PLMs) is presented in this paper. The current techniques used to measure and debias PLMs are skewed towards the US racial biases and rely on pre-defined bias attributes (e.g. "black" vs "white"). Some require large datasets and further pre-training. Such techniques are not designed to capture the underrepresented indigenous populations in other countries, such as M\=aori in New Zealand. Local knowledge and understanding must be incorporated to ensure unbiased algorithms, especially when addressing a resource-restricted society.
    
[^7]: Hi Sheldon! 从电视剧中创建深度个性化角色。

    Hi Sheldon! Creating Deep Personalized Characters from TV Shows. (arXiv:2304.11093v1 [cs.CL])

    [http://arxiv.org/abs/2304.11093](http://arxiv.org/abs/2304.11093)

    从多模态数据中通过DPCC创造出能够与用户进行视听交互的深度个性化数字角色，并收集了一个包含近10k个话语和6个小时音频/视频的角色中心多模态对话数据集。

    

    想象一下，你可以与一个通过人工智能生成的数字角色进行视听交互，其外貌和个性与《生活大爆炸》中的Sheldon几乎一模一样。为了实现这一神奇的视听交互场景，我们提出了一个名为"Deep Personalized Character Creation（DPCC）"的创新任务：从电视剧等多模态数据中创造出个性化角色。具体而言，给定单一或多个模式的文本、音频或视频输入，DPCC旨在生成与某个特定角色（如Sheldon）的个性特点非常匹配且质量高的多模态（文本、音频、视频）响应。为了支持这一创新任务，我们进一步收集了一个名为"Deep Personalized Character Dataset（DPCD）"的角色中心多模态对话数据集，该数据集包含~10k个话语和~6个小时的音频/视频。

    Imagine an interesting multimodal interactive scenario that you can see, hear, and chat with an AI-generated digital character, who is capable of behaving like Sheldon from The Big Bang Theory, as a DEEP copy from appearance to personality. Towards this fantastic multimodal chatting scenario, we propose a novel task, named Deep Personalized Character Creation (DPCC): creating multimodal chat personalized characters from multimodal data such as TV shows. Specifically, given a single- or multi-modality input (text, audio, video), the goal of DPCC is to generate a multi-modality (text, audio, video) response, which should be well-matched the personality of a specific character such as Sheldon, and of high quality as well. To support this novel task, we further collect a character centric multimodal dialogue dataset, named Deep Personalized Character Dataset (DPCD), from TV shows. DPCD contains character-specific multimodal dialogue data of ~10k utterances and ~6 hours of audio/video per c
    
[^8]: 在ChatGPT时代迈向负责任的人工智能：用于设计基于基础模型的AI系统的参考架构

    Towards Responsible AI in the Era of ChatGPT: A Reference Architecture for Designing Foundation Model-based AI Systems. (arXiv:2304.11090v1 [cs.CL])

    [http://arxiv.org/abs/2304.11090](http://arxiv.org/abs/2304.11090)

    本文提出了一个以模式为导向的负责任AI-by-design参考架构，用于设计基于基础模型的AI系统，重点关注可解释性、公平性、安全性和鲁棒性等关键设计元素。

    

    ChatGPT、Bard和其他大型语言模型(LLM)聊天机器人的推出在全球范围内引起了巨大关注。基础模型将成为未来大多数AI系统的基础构建块的趋势正在增长。然而，将基础模型纳入AI系统引发了对负责任AI的重大关注，这是由于其黑匣子性质和快速发展的超级智能引起的。此外，基础模型的增长能力最终可能会吞噬AI系统的其他组件，引入架构设计中的运动边界和接口演变挑战。为了应对这些挑战，本文提出了一种以模式为导向的负责任AI-by-design参考架构，用于设计基于基础模型的AI系统。特别地，本文首先呈现了基于基础模型的AI系统在架构演进方面的发展，从"基础模型作为连接器"到"基础模型作为单片机核"。然后，它提出了一个参考架构，包括五个类别的模式，重点关注关键设计元素，例如可解释性、公平性、安全性和鲁棒性。所提出的参考架构为设计负责任的基础模型的AI系统提供了系统化和透明的方法。

    The release of ChatGPT, Bard, and other large language model (LLM)-based chatbots has drawn huge attention on foundations models worldwide. There is a growing trend that foundation models will serve as the fundamental building blocks for most of the future AI systems. However, incorporating foundation models in AI systems raises significant concerns about responsible AI due to their black box nature and rapidly advancing super-intelligence. Additionally, the foundation model's growing capabilities can eventually absorb the other components of AI systems, introducing the moving boundary and interface evolution challenges in architecture design. To address these challenges, this paper proposes a pattern-oriented responsible-AI-by-design reference architecture for designing foundation model-based AI systems. Specially, the paper first presents an architecture evolution of AI systems in the era of foundation models, from "foundation-model-as-a-connector" to "foundation-model-as-a-monolithi
    
[^9]: 使用新闻标题来分析新闻传播障碍

    Profiling the news spreading barriers using news headlines. (arXiv:2304.11088v1 [cs.CL])

    [http://arxiv.org/abs/2304.11088](http://arxiv.org/abs/2304.11088)

    本文利用新闻标题的语义知识和情感特征来对新闻传播障碍进行分类，可以有效地检测新闻传播障碍。

    

    新闻标题可以是检测新闻媒体中新闻传播障碍的好数据源，在许多实际应用中非常有用。本文利用基于推理的模型COMET的语义知识和新闻标题的情感特征来对障碍进行分类。我们考虑了文化、经济、政治、语言和地理等五种障碍，以及包括健康、运动、科学、娱乐、游戏、住房、社会、购物、计算机和商业等不同类型的新闻标题。为此，我们利用新闻出版商的元数据自动收集和标记新闻标题，以此来检测新闻传播障碍。我们将我们的方法与传统的文本分类方法、深度学习和基于transformer的方法进行了比较。结果表明，利用推理为基础的语义知识和情感特征的方法可以有效地检测新闻传播障碍。

    News headlines can be a good data source for detecting the news spreading barriers in news media, which may be useful in many real-world applications. In this paper, we utilize semantic knowledge through the inference-based model COMET and sentiments of news headlines for barrier classification. We consider five barriers including cultural, economic, political, linguistic, and geographical, and different types of news headlines including health, sports, science, recreation, games, homes, society, shopping, computers, and business. To that end, we collect and label the news headlines automatically for the barriers using the metadata of news publishers. Then, we utilize the extracted commonsense inferences and sentiments as features to detect the news spreading barriers. We compare our approach to the classical text classification methods, deep learning, and transformer-based methods. The results show that the proposed approach using inferences-based semantic knowledge and sentiment offe
    
[^10]: 对ChatGPT用于文本标注和分类的可靠性进行测试——一个警告性的说明。

    Testing the Reliability of ChatGPT for Text Annotation and Classification: A Cautionary Remark. (arXiv:2304.11085v1 [cs.CL])

    [http://arxiv.org/abs/2304.11085](http://arxiv.org/abs/2304.11085)

    本研究测试了ChatGPT在文本标注和分类中的可靠性，结果显示输出的一致性不足以满足科学可靠性的阈值，因此使用ChatGPT时需要谨慎。

    

    最近的研究表明，ChatGPT在各种文本标注和分类任务中具有很大的潜力。然而，ChatGPT是非确定性的，这意味着与人类编码器一样，相同的输入可能导致不同的输出。鉴于此，测试ChatGPT的可靠性似乎是恰当的。因此，本研究调查了ChatGPT在文本标注和分类中的零-shot能力的一致性，重点关注不同的模型参数、提示变化和相同输入的重复。基于对将网站文本区分为新闻和非新闻的实际分类任务，结果显示，ChatGPT的分类输出一致性可能不足以满足科学可靠性的阈值。例如，提示中即使进行微小的措辞改变或重复相同的输入也会导致输出不同。虽然从多次重复的输出中汇总可以提高可靠性，但本研究建议在使用ChatGPT进行文本标注和分类时要谨慎。

    Recent studies have demonstrated promising potential of ChatGPT for various text annotation and classification tasks. However, ChatGPT is non-deterministic which means that, as with human coders, identical input can lead to different outputs. Given this, it seems appropriate to test the reliability of ChatGPT. Therefore, this study investigates the consistency of ChatGPT's zero-shot capabilities for text annotation and classification, focusing on different model parameters, prompt variations, and repetitions of identical inputs. Based on the real-world classification task of differentiating website texts into news and not news, results show that consistency in ChatGPT's classification output can fall short of scientific thresholds for reliability. For example, even minor wording alterations in prompts or repeating the identical input can lead to varying outputs. Although pooling outputs from multiple repetitions can improve reliability, this study advises caution when using ChatGPT for
    
[^11]: 大型语言模型对齐的基本限制

    Fundamental Limitations of Alignment in Large Language Models. (arXiv:2304.11082v1 [cs.CL])

    [http://arxiv.org/abs/2304.11082](http://arxiv.org/abs/2304.11082)

    本文通过提出一种理论方法——行为期望边界（BEB），展示了大型语言模型中对齐的基本限制，并证明任何对齐过程都无法根除不希望的行为，这对于防止恶意攻击是不安全的。

    

    开发与人交互的语言模型的重要方面是对齐其行为，使其对其人类用户有用且无害。这通常通过调整模型的方式来实现，以增强所需的行为并抑制不希望的行为。在本文中，我们提出了一种名为行为期望边界(BEB)的理论方法，它允许我们正式研究大型语言模型中的几个内在特征和对齐的限制。重要的是，我们证明对于任何具有被该模型表现出的有限概率的行为，都存在可以触发模型输出此行为的提示，其概率随提示的长度增加而增加。这意味着任何减弱不希望的行为但未将其完全消除的对齐过程都无法抵御针对性攻击。此外，我们的框架提示了领先的

    An important aspect in developing language models that interact with humans is aligning their behavior to be useful and unharmful for their human users. This is usually achieved by tuning the model in a way that enhances desired behaviors and inhibits undesired ones, a process referred to as alignment. In this paper, we propose a theoretical approach called Behavior Expectation Bounds (BEB) which allows us to formally investigate several inherent characteristics and limitations of alignment in large language models. Importantly, we prove that for any behavior that has a finite probability of being exhibited by the model, there exist prompts that can trigger the model into outputting this behavior, with probability that increases with the length of the prompt. This implies that any alignment process that attenuates undesired behavior but does not remove it altogether, is not safe against adversarial prompting attacks. Furthermore, our framework hints at the mechanism by which leading al
    
[^12]: HeRo: RoBERTa和 Longformer的希伯来语言模型

    HeRo: RoBERTa and Longformer Hebrew Language Models. (arXiv:2304.11077v1 [cs.CL])

    [http://arxiv.org/abs/2304.11077](http://arxiv.org/abs/2304.11077)

    本论文提供了希伯来语言处理社区所需的最大预训练数据集HeDC4，以及两种表现最先进的预训练语言模型：用于标准长度输入的HeRo和用于长输入序列的LongHeRo。两个模型在多项任务中实现了最先进的性能。

    

    本文填补了希伯来语自然语言处理（NLP）社区现有资源的空白，提供迄今最大的预训练数据集HeDC4、用于标准长度输入的最先进的预训练语言模型HeRo以及用于长输入序列的高效transformer LongHeRo. HeRo 模型在情感分析、命名实体识别和问答任务中进行了评估，而 LongHeRo 模型在由长文档组成的文档分类任务中进行了评估。 这两个模型均呈现出最先进的性能。本文使用的数据集和模型检查点是公开可用的。

    In this paper, we fill in an existing gap in resources available to the Hebrew NLP community by providing it with the largest so far pre-train dataset HeDC4, a state-of-the-art pre-trained language model HeRo for standard length inputs and an efficient transformer LongHeRo for long input sequences. The HeRo model was evaluated on the sentiment analysis, the named entity recognition, and the question answering tasks while the LongHeRo model was evaluated on the document classification task with a dataset composed of long documents. Both HeRo and LongHeRo presented state-of-the-art performance. The dataset and model checkpoints used in this work are publicly available.
    
[^13]: “类ChatGPT生成模型能否保证事实准确性？新一代搜索引擎的失误”

    Can ChatGPT-like Generative Models Guarantee Factual Accuracy? On the Mistakes of New Generation Search Engines. (arXiv:2304.11076v1 [cs.CL])

    [http://arxiv.org/abs/2304.11076](http://arxiv.org/abs/2304.11076)

    论文质疑类ChatGPT生成模型是否能保证事实准确性，很多新一代搜索引擎的公开演示中存在事实错误，呼吁科研人员和开发人员提高透明度和事实正确性。

    

    尽管像OpenAI的ChatGPT这样的大型对话型AI模型展现出了巨大的潜力，但我们质疑这些模型能否保证事实准确性。最近，微软和谷歌等科技公司宣布了旨在将搜索引擎与对话型AI相结合的新服务。然而，我们发现公开演示中存在许多错误，这表明我们不应轻易相信AI模型的事实主张。我们希望呼吁研究人员和开发人员改善AI模型的透明度和事实正确性，而不是批评特定的模型或公司。

    Although large conversational AI models such as OpenAI's ChatGPT have demonstrated great potential, we question whether such models can guarantee factual accuracy. Recently, technology companies such as Microsoft and Google have announced new services which aim to combine search engines with conversational AI. However, we have found numerous mistakes in the public demonstrations that suggest we should not easily trust the factual claims of the AI models. Rather than criticizing specific models or companies, we hope to call on researchers and developers to improve AI models' transparency and factual correctness.
    
[^14]: Spaiche: 将最先进的ASR模型扩展到瑞士德语方言

    Spaiche: Extending State-of-the-Art ASR Models to Swiss German Dialects. (arXiv:2304.11075v1 [cs.CL])

    [http://arxiv.org/abs/2304.11075](http://arxiv.org/abs/2304.11075)

    本项目在瑞士德语方言ASR模型的研究中提供了有价值的思路，通过提出考虑语义距离的新颖损失函数，对OpenAI的Whisper模型进行微调，取得了优于当前先进成果的效果。

    

    最近自然语言处理方面的突破大大增加了ASR系统在我们日常生活中的存在。然而，对于许多低资源语言，由于难以获取相关数据，ASR模型仍需要改进。本项目旨在通过提供关于最近发布的瑞士德语语音数据集上最先进的ASR模型性能的见解，帮助推进瑞士德语方言ASR模型的研究。我们提出了一种新颖的损失函数，考虑了预测和基准标签之间的语义距离。通过对瑞士德语数据集对OpenAI的Whisper模型进行微调，我们超越了当前先进的成果。

    Recent breakthroughs in NLP largely increased the presence of ASR systems in our daily lives. However, for many low-resource languages, ASR models still need to be improved due in part to the difficulty of acquiring pertinent data. This project aims to help advance research in ASR models for Swiss German dialects, by providing insights about the performance of state-of-the-art ASR models on recently published Swiss German speech datasets. We propose a novel loss that takes into account the semantic distance between the predicted and the ground-truth labels. We outperform current state-of-the-art results by fine-tuning OpenAI's Whisper model on Swiss-German datasets.
    
[^15]: OLISIA: 一个用于口语化对话状态跟踪的级联系统

    OLISIA: a Cascade System for Spoken Dialogue State Tracking. (arXiv:2304.11073v1 [eess.AS])

    [http://arxiv.org/abs/2304.11073](http://arxiv.org/abs/2304.11073)

    我们提出了OLISIA，一个口语对话状态跟踪的级联系统，使用自动语音识别和DST模型，采用几个适应性策略来提高稳健性，并在DSTC11 Track3中取得第一名的好成绩。

    

    对话状态跟踪 (DST) 是口语对话系统的核心组成部分。然而，最近关于该任务的研究大多集中于聊天时的语料库，忽略了口语和书面语之间的差异。本文提出了 OLISIA，这是一个级联系统，它集成了自动语音识别 (ASR) 模型和 DST 模型。我们在 ASR 和 DST 模块中引入了几个适应性策略，以提高对口语对话的整合性和稳健性。经过这些策略的调整，我们的系统在 DSTC11 Track 3 中排名第一，这是一个评估口语 DST 性能的基准。我们进行了深入的结果分析，发现规范化 ASR 的输出和通过数据增强调整 DST 的输入，以及增加预训练模型的大小，都在降低书面和口语对话之间性能差异方面发挥了重要作用。

    Though Dialogue State Tracking (DST) is a core component of spoken dialogue systems, recent work on this task mostly deals with chat corpora, disregarding the discrepancies between spoken and written language.In this paper, we propose OLISIA, a cascade system which integrates an Automatic Speech Recognition (ASR) model and a DST model. We introduce several adaptations in the ASR and DST modules to improve integration and robustness to spoken conversations.With these adaptations, our system ranked first in DSTC11 Track 3, a benchmark to evaluate spoken DST. We conduct an in-depth analysis of the results and find that normalizing the ASR outputs and adapting the DST inputs through data augmentation, along with increasing the pre-trained models size all play an important role in reducing the performance discrepancy between written and spoken conversations.
    
[^16]: 对话过程建模：现状、应用和实践影响的综述

    Conversational Process Modelling: State of the Art, Applications, and Implications in Practice. (arXiv:2304.11065v1 [cs.CL])

    [http://arxiv.org/abs/2304.11065](http://arxiv.org/abs/2304.11065)

    本文系统的研究了现有聊天机器人对于支持对话式流程建模所提供的应用场景，并推导出了在实践中使用聊天机器人进行对话式流程建模的建议。

    

    最近Chatbots等聊天机器人引起了极大的关注。对于BPM应用来说，如何应用聊天机器人来生成商业价值通常是不明确的。因此，本文旨在系统地分析现有的聊天机器人对于支持对话式流程建模作为面向流程的能力的支持。该研究识别了沿流程生命周期的应用场景，然后进行了对话式流程建模的系统文献综述。得出的分类学用作对话式流程建模的应用场景的识别，包括流程描述的释义和改进。应用场景基于高等教育领域的实际测试集对现有聊天机器人进行评估。该测试集包含流程描述及其对应的流程模型，以及模型质量的评估。基于文献和应用场景分析，得出了关于在对话式流程建模中使用聊天机器人的建议。

    Chatbots such as ChatGPT have caused a tremendous hype lately. For BPM applications, it is often not clear how to apply chatbots to generate business value. Hence, this work aims at the systematic analysis of existing chatbots for their support of conversational process modelling as process-oriented capability. Application scenarios are identified along the process life cycle. Then a systematic literature review on conversational process modelling is performed. The resulting taxonomy serves as input for the identification of application scenarios for conversational process modelling, including paraphrasing and improvement of process descriptions. The application scenarios are evaluated for existing chatbots based on a real-world test set from the higher education domain. It contains process descriptions as well as corresponding process models, together with an assessment of the model quality. Based on the literature and application scenario analyses, recommendations for the usage (prac
    
[^17]: 慎思之后再行动：将语言推理与动作统一的交错策略方法

    Think Before You Act: Unified Policy for Interleaving Language Reasoning with Actions. (arXiv:2304.11063v1 [cs.CL])

    [http://arxiv.org/abs/2304.11063](http://arxiv.org/abs/2304.11063)

    本文提出了一种新的方法，将语言推理与动作统一在单个策略中，利用 transformer 模型，能够生成交替使用动作的文本标题。在 BabyAI 任务中测试，我们的推理策略始终优于没有标题的基准线。

    

    带有语言建模目标的 transformer 模型的成功训练为强化学习框架带来了一个有前途的机会，Decision Transformer 是朝着这个方向迈出的一步，展示了如何在离线数据上训练类似的下一步预测目标的 transformers；而这个领域的另一个重要发展是近期出现了从互联网收集而来的大规模数据集，例如由视频教程和字幕组成的数据集，其中的人们讲述他们正在做的事情。为了利用这种语言组件，我们提出了一种将语言推理和动作统一在单个策略中的新方法。具体来说，我们增加了一个带有单词输出的 transformer 策略，以便它可以生成交替使用动作的文本标题。在最具挑战性的 BabyAI 任务中测试，我们的推理策略在描述下一个子目标的标题上，始终优于没有标题的基准线。

    The success of transformer models trained with a language modeling objective brings a promising opportunity to the reinforcement learning framework. Decision Transformer is a step towards this direction, showing how to train transformers with a similar next-step prediction objective on offline data. Another important development in this area is the recent emergence of large-scale datasets collected from the internet, such as the ones composed of tutorial videos with captions where people talk about what they are doing. To take advantage of this language component, we propose a novel method for unifying language reasoning with actions in a single policy. Specifically, we augment a transformer policy with word outputs, so it can generate textual captions interleaved with actions. When tested on the most challenging task in BabyAI, with captions describing next subgoals, our reasoning policy consistently outperforms the caption-free baseline.
    
[^18]: 利用RMT将Transformer扩展到100万个标记及以上。

    Scaling Transformer to 1M tokens and beyond with RMT. (arXiv:2304.11062v1 [cs.CL])

    [http://arxiv.org/abs/2304.11062](http://arxiv.org/abs/2304.11062)

    本文介绍了一种利用循环记忆扩展BERT上下文长度的方法，成功扩展到了前所未有的200万个标记，有望增强自然语言处理中的长期依赖处理并为内存密集型应用程序实现大规模上下文处理。

    

    本技术报告介绍了一种利用循环记忆扩展BERT上下文长度的方法，BERT是自然语言处理中最有效的基于Transformer模型之一。通过利用循环记忆Transformer架构，我们成功地将模型的有效上下文长度增加到了前所未有的200万个标记，同时保持了高的内存检索准确性。我们的方法允许存储和处理本地和全局信息，并通过使用循环实现输入序列各部分之间的信息流动。我们的实验证明了我们的方法的有效性，具有显著的潜力来增强自然语言理解和生成任务中的长期依赖处理，并能够为内存密集型应用程序实现大规模上下文处理。

    This technical report presents the application of a recurrent memory to extend the context length of BERT, one of the most effective Transformer-based models in natural language processing. By leveraging the Recurrent Memory Transformer architecture, we have successfully increased the model's effective context length to an unprecedented two million tokens, while maintaining high memory retrieval accuracy. Our method allows for the storage and processing of both local and global information and enables information flow between segments of the input sequence through the use of recurrence. Our experiments demonstrate the effectiveness of our approach, which holds significant potential to enhance long-term dependency handling in natural language understanding and generation tasks as well as enable large-scale context processing for memory-intensive applications.
    
[^19]: CEIL：一种通用的分类增强迭代学习框架用于文本聚类

    CEIL: A General Classification-Enhanced Iterative Learning Framework for Text Clustering. (arXiv:2304.11061v1 [cs.CL])

    [http://arxiv.org/abs/2304.11061](http://arxiv.org/abs/2304.11061)

    CEIL是一种迭代学习框架，通过引入分类目标来改进特征表示和文本聚类效果，能够普适于不同领域的文本聚类任务。

    

    作为无监督学习中最基本的挑战之一，文本聚类旨在将语义上相似的文本段分组，而不依赖于人工注释。随着深度学习的迅速发展，深度聚类在传统聚类方法上取得了显著优势。尽管有效，大多数现有的深度文本聚类方法严重依赖于在一般领域预训练的表示，这可能不是在特定目标领域聚类的最佳解决方案。为了解决这个问题，我们提出了CEIL，一种新颖的短文本聚类分类增强迭代学习框架，旨在通过将分类目标引入迭代地改进特征表示的方法，从而普遍提高聚类性能。在每个迭代中，我们首先采用语言模型检索初始文本表示，然后使用我们提出的分类不可分割分布（CDC）模块收集聚类结果。然后，我们引入分类模块将分类目标整合到聚类框架中，并使用得到的改进特征表示在下一次迭代中。对多个基准数据集的广泛实验证明了CEIL的有效性以及其优于现有最先进算法的优越性。

    Text clustering, as one of the most fundamental challenges in unsupervised learning, aims at grouping semantically similar text segments without relying on human annotations. With the rapid development of deep learning, deep clustering has achieved significant advantages over traditional clustering methods. Despite the effectiveness, most existing deep text clustering methods rely heavily on representations pre-trained in general domains, which may not be the most suitable solution for clustering in specific target domains. To address this issue, we propose CEIL, a novel Classification-Enhanced Iterative Learning framework for short text clustering, which aims at generally promoting the clustering performance by introducing a classification objective to iteratively improve feature representations. In each iteration, we first adopt a language model to retrieve the initial text representations, from which the clustering results are collected using our proposed Category Disentangled Contr
    
[^20]: SkillGPT: 一种使用大型语言模型进行技能提取和标准化的RESTful API服务

    SkillGPT: a RESTful API service for skill extraction and standardization using a Large Language Model. (arXiv:2304.11060v1 [cs.CL])

    [http://arxiv.org/abs/2304.11060](http://arxiv.org/abs/2304.11060)

    SkillGPT是一种使用大型语言模型进行技能提取和标准化的RESTful API服务，通过摘要和向量相似性搜索平衡速度和准确度。

    

    我们提出了 SkillGPT，一种利用开源的大型语言模型 (LLM) 进行从自由风格职位描述和用户资料中进行技能提取和标准化 (SES) 的工具。与大多数类似任务的以前方法不同，SkillGPT 直接使用最新的对话 LLM 进行标准技能的提示，通过摘要和向量相似性搜索来平衡速度和准确度。因此，我们的免费 SkillGPT 让用户能够高效可靠地进行对话型 SES。

    We present SkillGPT, a tool for skill extraction and standardization (SES) from free-style job descriptions and user profiles with an open-source Large Language Model (LLM) as backbone. Most previous methods for similar tasks either need supervision or rely on heavy data-preprocessing and feature engineering. Directly prompting the latest conversational LLM for standard skills, however, is slow, costly and inaccurate. In contrast, SkillGPT utilizes a LLM to perform its tasks in steps via summarization and vector similarity search, to balance speed with precision. The backbone LLM of SkillGPT is based on Llama, free for academic use and thus useful for exploratory research and prototype development. Hence, our cost-free SkillGPT gives users the convenience of conversational SES, efficiently and reliably.
    
[^21]: 新型意图检测和基于主动学习的分类（学生摘要）

    Novel Intent Detection and Active Learning Based Classification (Student Abstract). (arXiv:2304.11058v1 [cs.CL])

    [http://arxiv.org/abs/2304.11058](http://arxiv.org/abs/2304.11058)

    本文提出了一个名为NIDAL的人工智能框架，可以自动检测不同语言中出现的新型意图类别并减少人员标注成本，通过在多个基准数据集上的实验证明，该系统可以实现高准确率和宏F1值。

    

    在连续交互的对话代理情境中，新型意图类别检测是一个重要问题。已经进行了许多研究工作，以检测英语为主要文本和图像中的新型意图。但是，当前系统缺乏一种端到端通用框架，以在各种不同语言的同时检测新型意图，同时减少对人类注释的需求以处理被分类错误或系统拒绝的样本。本文提出了NIDAL（Novel Intent Detection and Active Learning based classification），这是一个半监督框架，用于检测新型意图并减少人类注释成本。各种基准数据集上的实验证明，该系统的准确性和宏F1相对于基线方法提高了10%以上，且总注释成本仅为系统可用未标注数据的6-10％。

    Novel intent class detection is an important problem in real world scenario for conversational agents for continuous interaction. Several research works have been done to detect novel intents in a mono-lingual (primarily English) texts and images. But, current systems lack an end-to-end universal framework to detect novel intents across various different languages with less human annotation effort for mis-classified and system rejected samples. This paper proposes NIDAL (Novel Intent Detection and Active Learning based classification), a semi-supervised framework to detect novel intents while reducing human annotation cost. Empirical results on various benchmark datasets demonstrate that this system outperforms the baseline methods by more than 10% margin for accuracy and macro-F1. The system achieves this while maintaining overall annotation cost to be just ~6-10% of the unlabeled data available to the system.
    
[^22]: 一种大规模语音识别的半监督学习技术比较

    A Comparison of Semi-Supervised Learning Techniques for Streaming ASR at Scale. (arXiv:2304.11053v1 [cs.CL])

    [http://arxiv.org/abs/2304.11053](http://arxiv.org/abs/2304.11053)

    比较三种半监督ASR方法的优劣，发现这些方法不仅在原始WER方面有所提高，而且在尾部单词WER、推理过程中的解码器计算和栅格密度等方面都有显著的提高。

    

    在缺乏大规模标注数据集的情况下，无配对文本和音频注入已成为提高自动语音识别性能的主要方法。然而，对于训练有非常大的受监督语料库并且有一些现实的要求（如模型大小和CPU预算、流媒体能力以及用于重新评分和下游NLU任务的丰富栅格）的产品ASR系统，缺乏有效的部署指南。在这项工作中，我们在联合训练的控制环境中比较了三种最先进的半监督方法，包括无配对文本和音频以及几种它们的组合。我们发现，在我们的设置中，这些方法除了原始WER之外还提供了许多改进，包括尾部单词WER的大幅度增益，在推理过程中的解码器计算和栅格密度等方面。

    Unpaired text and audio injection have emerged as dominant methods for improving ASR performance in the absence of a large labeled corpus. However, little guidance exists on deploying these methods to improve production ASR systems that are trained on very large supervised corpora and with realistic requirements like a constrained model size and CPU budget, streaming capability, and a rich lattice for rescoring and for downstream NLU tasks. In this work, we compare three state-of-the-art semi-supervised methods encompassing both unpaired text and audio as well as several of their combinations in a controlled setting using joint training. We find that in our setting these methods offer many improvements beyond raw WER, including substantial gains in tail-word WER, decoder computation during inference, and lattice density.
    
[^23]: 情感社交化人形智能系统

    Affective social anthropomorphic intelligent system. (arXiv:2304.11046v1 [cs.SD])

    [http://arxiv.org/abs/2304.11046](http://arxiv.org/abs/2304.11046)

    本研究提出了一种情感社交化人形智能系统，可以更好地理解人类声音的情感语义，实现类人对话。

    

    人类的对话风格可以通过幽默感、个性和语调来衡量。这些特征已经成为对话智能虚拟助手的关键。然而，大多数最先进的智能虚拟助手（IVAs）无法解释人类声音的情感语义。本研究提出了一个人形智能系统，可以通过表达情感和个性来进行类人对话。同时，提出了一种语音风格转换方法，可以将特定情感的属性映射出来。首先，通过将时间音频波形数据转换为频域数据（Mel-Spectrogram），创建了离散的音频特征模式，如音符、音调、节奏、旋律等等。并使用一个外部CNN-Transformer-Encoder模型来预测声音中的七种不同的情感状态。同时，该模型将语音输入到一个RNN模型（Deep-speech）中，生成对音频的文本转录。然后，转录文本将通过一个transformer解码器与相应情感的响应一起产生。

    Human conversational styles are measured by the sense of humor, personality, and tone of voice. These characteristics have become essential for conversational intelligent virtual assistants. However, most of the state-of-the-art intelligent virtual assistants (IVAs) are failed to interpret the affective semantics of human voices. This research proposes an anthropomorphic intelligent system that can hold a proper human-like conversation with emotion and personality. A voice style transfer method is also proposed to map the attributes of a specific emotion. Initially, the frequency domain data (Mel-Spectrogram) is created by converting the temporal audio wave data, which comprises discrete patterns for audio features such as notes, pitch, rhythm, and melody. A collateral CNN-Transformer-Encoder is used to predict seven different affective states from voice. The voice is also fed parallelly to the deep-speech, an RNN model that generates the text transcription from the spectrogram. Then t
    
[^24]: 基于机器学习算法的口语情感识别

    Emotional Expression Detection in Spoken Language Employing Machine Learning Algorithms. (arXiv:2304.11040v1 [cs.SD])

    [http://arxiv.org/abs/2304.11040](http://arxiv.org/abs/2304.11040)

    通过使用MATLAB函数和机器学习算法，研究人员利用声音的特征来识别人类不同的情感，提高了机器学习模型的效率。

    

    人类的声音具有多种特征，如音高、音色、音量和嗓音。通过这些特征可以观察到人们在说话时使用不同的嗓音质量来表达情感。本研究的主要目标是使用多个MATLAB函数，如谱描述符、周期性和谐波，识别人类的不同情感，如愤怒、悲伤、恐惧、中立、厌恶、惊喜和快乐。为了完成这项工作，我们分析了人类语音的CREMA-D（众包情感多模态演员数据）和TESS（多伦多情感语音集）数据集。音频文件包含具有各种特征（如嘈杂、快速、缓慢）的数据，因此机器学习模型的效率显著提高。利用经验模态分解（EMD）进行信号分解的过程。然后，通过使用几个

    There are a variety of features of the human voice that can be classified as pitch, timbre, loudness, and vocal tone. It is observed in numerous incidents that human expresses their feelings using different vocal qualities when they are speaking. The primary objective of this research is to recognize different emotions of human beings such as anger, sadness, fear, neutrality, disgust, pleasant surprise, and happiness by using several MATLAB functions namely, spectral descriptors, periodicity, and harmonicity. To accomplish the work, we analyze the CREMA-D (Crowd-sourced Emotional Multimodal Actors Data) & TESS (Toronto Emotional Speech Set) datasets of human speech. The audio file contains data that have various characteristics (e.g., noisy, speedy, slow) thereby the efficiency of the ML (Machine Learning) models increases significantly. The EMD (Empirical Mode Decomposition) is utilized for the process of signal decomposition. Then, the features are extracted through the use of severa
    
[^25]: DIN-SQL: 自纠正的文本到SQL分解式上下文学习

    DIN-SQL: Decomposed In-Context Learning of Text-to-SQL with Self-Correction. (arXiv:2304.11015v1 [cs.CL])

    [http://arxiv.org/abs/2304.11015](http://arxiv.org/abs/2304.11015)

    DIN-SQL通过将复杂的文本到SQL任务分解为子问题，并将这些子问题的解决方案馈入到大型语言模型中，显著提高了它们的表现，使准确性超过了当前最先进的技术。

    

    本文研究了将复杂的文本到SQL任务分解为较小的子任务，并且这种分解如何显著提高大型语言模型在推理过程中的表现。我们展示了尽管SQL查询具有声明式结构，但可以将其分解为子问题，并将这些子问题的解决方案馈入到大型语言模型中，从而显著提高它们的表现。我们的实验表明，这种方法能够稳定提高三种大型语言模型的表现，大约提高了10％，将大型语言模型的准确性推向最新水平，并在Holdout Spider数据集上甚至超过了经过精调的大型模型。

    We study the problem of decomposing a complex text-to-sql task into smaller sub-tasks and how such a decomposition can significantly improve the performance of Large Language Models (LLMs) in the reasoning process. There is currently a significant gap between the performance of fine-tuned models and prompting approaches using LLMs on challenging text-to-sql datasets such as Spider. We show that SQL queries, despite their declarative structure, can be broken down into sub-problems and the solutions of those sub-problems can be fed into LLMs to significantly improve their performance. Our experiments with three LLMs show that this approach consistently improves their performance by roughly 10%, pushing the accuracy of LLMs towards state-of-the-art, and even beating large fine-tuned models on the holdout Spider dataset.
    
[^26]: 基于BERT的临床知识提取用于生物医学知识图谱构建和分析

    BERT Based Clinical Knowledge Extraction for Biomedical Knowledge Graph Construction and Analysis. (arXiv:2304.10996v1 [cs.CL])

    [http://arxiv.org/abs/2304.10996](http://arxiv.org/abs/2304.10996)

    本文提出了一种基于BERT和CRF技术的生物医学临床笔记知识提取和分析的端到端方法，用于构建和分析生物医学知识图谱。

    

    背景：知识随时间而演变，往往是由于新的发现或推理方法的变化导致。此外，可能会有新的事实或证据出现，导致对复杂现象的新理解。这在生物医学领域尤为真实，科学家和医生不断努力寻找新的诊断、治疗方法和最终的治愈。知识图谱（KG）提供了一种真实的方法来组织和检索大量增长的生物医学知识。

    Background : Knowledge is evolving over time, often as a result of new discoveries or changes in the adopted methods of reasoning. Also, new facts or evidence may become available, leading to new understandings of complex phenomena. This is particularly true in the biomedical field, where scientists and physicians are constantly striving to find new methods of diagnosis, treatment and eventually cure. Knowledge Graphs (KGs) offer a real way of organizing and retrieving the massive and growing amount of biomedical knowledge.  Objective : We propose an end-to-end approach for knowledge extraction and analysis from biomedical clinical notes using the Bidirectional Encoder Representations from Transformers (BERT) model and Conditional Random Field (CRF) layer.  Methods : The approach is based on knowledge graphs, which can effectively process abstract biomedical concepts such as relationships and interactions between medical entities. Besides offering an intuitive way to visualize these co
    
[^27]: 文件信息提取：在真实场景中，问答与标记分类哪个更好？

    Information Extraction from Documents: Question Answering vs Token Classification in real-world setups. (arXiv:2304.10994v1 [cs.CL])

    [http://arxiv.org/abs/2304.10994](http://arxiv.org/abs/2304.10994)

    本研究比较了传统标记分类和新兴问答方法在文献信息提取方面的表现，并发现问答方法在处理复杂信息的文档时更加有效。

    

    文献信息提取通常被当做标记分类问题来解决。但是，最近自然语言处理和计算机视觉方面的突破导致了一种名为Question Answering（问答）的提取文档关键信息的新子任务的出现。本研究比较了问答方法和传统的标记分类方法在文档关键信息提取方面的表现，并设计了五个实验，测试其在原始性能、噪声环境下的稳健性、提取长实体的能力、Few-Shot Learning（少量数据学习）的微调速度和Zero-Shot Learning（零数据学习）方面的表现。研究表明，在处理含有复杂信息的文档时，问答方法比标记分类方法更加有效。

    Research in Document Intelligence and especially in Document Key Information Extraction (DocKIE) has been mainly solved as Token Classification problem. Recent breakthroughs in both natural language processing (NLP) and computer vision helped building document-focused pre-training methods, leveraging a multimodal understanding of the document text, layout and image modalities. However, these breakthroughs also led to the emergence of a new DocKIE subtask of extractive document Question Answering (DocQA), as part of the Machine Reading Comprehension (MRC) research field. In this work, we compare the Question Answering approach with the classical token classification approach for document key information extraction. We designed experiments to benchmark five different experimental setups : raw performances, robustness to noisy environment, capacity to extract long entities, fine-tuning speed on Few-Shot Learning and finally Zero-Shot Learning. Our research showed that when dealing with cl
    
[^28]: 使用数字分解评估变形金刚语言模型在算术运算上的表现

    Evaluating Transformer Language Models on Arithmetic Operations Using Number Decomposition. (arXiv:2304.10977v1 [cs.CL])

    [http://arxiv.org/abs/2304.10977](http://arxiv.org/abs/2304.10977)

    本文评估了使用数字分解技术进行微调后的变形金刚语言模型在执行算术运算时的表现。结果显示，这种方法在五位数字加法任务中的准确度提高了63%。

    

    近年来，像GPT-3这样的大型语言模型在零和少量样本的NLP任务中展现出了非凡的能力。然而，实验突显出GPT-3在需要一定推理能力的任务，如算术运算中的困难。本文通过一个流程来评估变形金刚语言模型在执行算术运算时的能力，在这个流程中，数字会在计算之前被分解为个位、十位等。我们称使用这个流程微调后的模型为Calculon，并在GPT-3的同一测试数据集上测试了它们在执行加、减和乘法任务时的表现。结果显示，在五位数字加法任务中，准确度提高了63%。此外，我们还展示了引入分解流程的重要性，因为将相同的语言模型进行微调，但没有进行数字分解，其在五位数字加法任务中的准确度为0%。

    In recent years, Large Language Models such as GPT-3 showed remarkable capabilities in performing NLP tasks in the zero and few shot settings. On the other hand, the experiments highlighted the difficulty of GPT-3 in carrying out tasks that require a certain degree of reasoning, such as arithmetic operations. In this paper we evaluate the ability of Transformer Language Models to perform arithmetic operations following a pipeline that, before performing computations, decomposes numbers in units, tens, and so on. We denote the models fine-tuned with this pipeline with the name Calculon and we test them in the task of performing additions, subtractions and multiplications on the same test sets of GPT-3. Results show an increase of accuracy of 63% in the five-digit addition task. Moreover, we demonstrate the importance of the decomposition pipeline introduced, since fine-tuning the same Language Model without decomposing numbers results in 0% accuracy in the five-digit addition task.
    
[^29]: LEIA：语言嵌入用于情感识别

    LEIA: Linguistic Embeddings for the Identification of Affect. (arXiv:2304.10973v1 [cs.CL])

    [http://arxiv.org/abs/2304.10973](http://arxiv.org/abs/2304.10973)

    该论文提出了一种名为LEIA的情感识别模型，使用了由超过6百万个自注释文本帖子组成的数据集进行训练，利用掩蔽单词的方法增强模型预训练过程中对情感单词的学习，并在三个测试数据集上实现了约73的宏F1值，优于其他方法。

    

    社交媒体产生了大量文本数据，使得使用语言模型分析情感变得更加容易。这些模型通常在由读者生成的小型而昂贵的文本注释数据集上进行训练，这些读者猜测社交媒体帖子中表达的情感。这影响了情感识别方法的质量，因为存在训练数据大小限制和用于模型开发的标签生产中的噪声。我们提出了LEIA，这是一种文本情感识别模型，它基于由超过6百万个帖子组成的数据集进行训练，其中这些帖子具有自注释的情感标签，包括快乐、亲情、悲伤、愤怒和恐惧。LEIA基于一种掩蔽单词的方法，增强了模型预训练过程中对情感单词的学习。LEIA在三个测试数据集上实现了约73的宏F1值，优于其他监督和无监督方法，并在强基准测试中表现出LEIA可以概括不同的帖子、用户和时间段。

    The wealth of text data generated by social media has enabled new kinds of analysis of emotions with language models. These models are often trained on small and costly datasets of text annotations produced by readers who guess the emotions expressed by others in social media posts. This affects the quality of emotion identification methods due to training data size limitations and noise in the production of labels used in model development. We present LEIA, a model for emotion identification in text that has been trained on a dataset of more than 6 million posts with self-annotated emotion labels for happiness, affection, sadness, anger, and fear. LEIA is based on a word masking method that enhances the learning of emotion words during model pre-training. LEIA achieves macro-F1 values of approximately 73 on three in-domain test datasets, outperforming other supervised and unsupervised methods in a strong benchmark that shows that LEIA generalizes across posts, users, and time periods.
    
[^30]: CancerGPT: 基于LLMs的极少样本药物对协同作用预测技术

    CancerGPT: Few-shot Drug Pair Synergy Prediction using Large Pre-trained Language Models. (arXiv:2304.10946v1 [cs.CL])

    [http://arxiv.org/abs/2304.10946](http://arxiv.org/abs/2304.10946)

    CancerGPT 是一种基于LLMs的少样本学习技术，可在生物学推断中预测罕见组织中的药物对协同作用。实验表明该技术准确性高，即使在样本数据非常有限的情况下仍可进行预测。

    

    大型预训练语言模型（LLMs）在许多领域中具有显着的远程监控潜力，即使只有极少量的训练数据。但是，它们在更复杂的领域，如生物学领域中对未见过的任务的泛化能力尚未得到充分评估。 LLM可以提供一种有前途的替代方法，特别是在结构化数据和样本大小有限的情况下，通过从文本语料库中提取先验知识。 我们提出了一种基于LLMs的少样本学习方法，用于预测缺乏结构化数据和特征的罕见组织中药物对的协同作用。 实验涉及来自不同癌症类型的七种罕见组织，表明基于LLMs的预测模型在非常少或零样本的情况下也能取得显着的准确性。我们提出的模型CancerGPT（具有$\sim 124M$参数）甚至可以与更大的微调GPT-3模型（具有$\sim 175B$参数）相媲美。我们的研究是第一个利用LLMs进行少样本学习的案例，为生物学推断提供了一种有前途的替代方法。

    Large pre-trained language models (LLMs) have been shown to have significant potential in few-shot learning across various fields, even with minimal training data. However, their ability to generalize to unseen tasks in more complex fields, such as biology, has yet to be fully evaluated. LLMs can offer a promising alternative approach for biological inference, particularly in cases where structured data and sample size are limited, by extracting prior knowledge from text corpora. Our proposed few-shot learning approach uses LLMs to predict the synergy of drug pairs in rare tissues that lack structured data and features. Our experiments, which involved seven rare tissues from different cancer types, demonstrated that the LLM-based prediction model achieved significant accuracy with very few or zero samples. Our proposed model, the CancerGPT (with $\sim$ 124M parameters), was even comparable to the larger fine-tuned GPT-3 model (with $\sim$ 175B parameters). Our research is the first to 
    
[^31]: Text2Time: 基于Transformer的文章时间段预测器

    Text2Time: Transformer-based article time period predictor. (arXiv:2304.10859v1 [cs.CL])

    [http://arxiv.org/abs/2304.10859](http://arxiv.org/abs/2304.10859)

    本文提出了一个基于Transformer模型的文章时间段预测器，使用预训练的BERT模型对新闻文章进行分类的结果表现优于先前尝试的模型，具有很高的准确性。

    

    本论文探讨利用文本内容预测文章发表时间段的问题。我们创建了一个包含超过35万篇《纽约时报》历时六十年的标记数据集。我们实现了一个简单的朴素贝叶斯基准模型，它在准确性方面表现出人意料之外的不错性能。最后，我们使用了一个预训练的BERT模型，对其进行了微调以实现文本分类的任务。这个模型的性能超过了我们的预期，并提供了一些非常令人印象深刻的结果，准确地将新闻文章分类至其出版的年代。结果超过了先前尝试的这种相对不受关注的文本预测任务模型的性能。

    We explore the problem of predicting the publication period of text document, such as a news article, using the text from that document. In order to do so, we created our own extensive labeled dataset of over 350,000 news articles published by The New York Times over six decades. We then provide an implementation of a simple Naive Bayes baseline model, which surprisingly achieves decent performance in terms of accuracy.Finally, for our approach, we use a pretrained BERT model fine-tuned for the task of text classification. This model exceeds our expectations and provides some very impressive results in terms of accurately classifying news articles into their respective publication decades. The results beat the performance of the few previously tried models for this relatively unexplored task of time prediction from text.
    
[^32]: 利用单语数据实现更好的手语翻译

    Better Sign Language Translation with Monolingual Data. (arXiv:2304.10844v1 [cs.CL])

    [http://arxiv.org/abs/2304.10844](http://arxiv.org/abs/2304.10844)

    本文提出了一种规则转换方法，可以自动将大规模单语数据转录为其伪手语编码以提高手语翻译的翻译质量。该方法在两个基准数据集上实现了最新的技术能力。

    

    手语翻译系统通常由视频到手语编码（V2G）识别和通过中介手语编码的互译（G2T）翻译组成，且该中介手语编码的人工注释进一步恶化了手语翻译数据的稀缺性。本文提出了一种简单有效的规则转换方法，将大规模目标语单语数据自动转录为其伪手语编码，以提高手语翻译的翻译质量。实证结果表明，提出的方法可以显著提高手语翻译的性能，尤其是在 PHEONIX-WEATHER 2014T 和 ASLG-PC12 两个手语翻译基准数据集上实现了最新的技术能力。已经通过代码开源: https://github.com/pengr/Mono\_SLT。

    Sign language translation (SLT) systems, which are often decomposed into video-to-gloss (V2G) recognition and gloss-to-text (G2T) translation through the pivot gloss, heavily relies on the availability of large-scale parallel G2T pairs. However, the manual annotation of pivot gloss, which is a sequence of transcribed written-language words in the order in which they are signed, further exacerbates the scarcity of data for SLT. To address this issue, this paper proposes a simple and efficient rule transformation method to transcribe the large-scale target monolingual data into its pseudo glosses automatically for enhancing the SLT translation. Empirical results show that the proposed approach can significantly improve the performance of SLT, especially achieving state-of-the-art results on two SLT benchmark datasets PHEONIX-WEATHER 2014T and ASLG-PC12. Our code has been released at: https://github.com/pengr/Mono\_SLT.
    
[^33]: 人类和机器学习模型的分词可追溯性：一个注释研究

    Tokenization Tractability for Human and Machine Learning Model: An Annotation Study. (arXiv:2304.10813v1 [cs.CL])

    [http://arxiv.org/abs/2304.10813](http://arxiv.org/abs/2304.10813)

    研究比较了六种分词方法，并发现人类可追溯的分词与机器学习模型中的分词不一定相同。

    

    人类可追溯的分词对于机器学习模型是否也是可追溯的？本研究探讨了人类可追溯的分词（如适当性和可读性）与机器学习模型中的分词（如在NLP任务中的性能）之间的关系。我们在日语常识问答数据集（JGLUE的JCommmonsenseQA）中比较了六种分词方法。我们使用不同的分词器对问答数据集中的问题文本进行分词，并比较了人类标注者和机器学习模型的性能。此外，我们分析了性能、分词的适当性和回答问题的响应时间之间的关系。本文提供了一个定量调查结果，显示出对于人类和机器学习模型来说，可追溯的分词不一定相同。

    Is tractable tokenization for humans also tractable for machine learning models? This study investigates relations between tractable tokenization for humans (e.g., appropriateness and readability) and one for models of machine learning (e.g., performance on an NLP task). We compared six tokenization methods on the Japanese commonsense question-answering dataset (JCommmonsenseQA in JGLUE). We tokenized question texts of the QA dataset with different tokenizers and compared the performance of human annotators and machine-learning models. Besides,we analyze relationships among the performance, appropriateness of tokenization, and response time to questions. This paper provides a quantitative investigation result that shows the tractable tokenizations for humans and machine learning models are not necessarily the same as each other.
    
[^34]: 限制词汇的神经网络分词器优化方法

    Downstream Task-Oriented Neural Tokenizer Optimization with Vocabulary Restriction as Post Processing. (arXiv:2304.10808v1 [cs.CL])

    [http://arxiv.org/abs/2304.10808](http://arxiv.org/abs/2304.10808)

    本文提出了一种针对预先训练的下游模型优化 tokenization 的方法，通过限制词汇的方式可以生成更低损失值的 tokenization 结果，并训练一个复现 tokenization 结果的分词器。实验证明该方法可以提高 tokenization 的性能。

    

    本文提出了一种针对预先训练的下游模型优化 tokenization 的方法。我们的方法通过限制词汇的方式生成 tokenization 结果，使得在训练数据上给定下游模型的损失值更低，并训练一个可以复现 tokenization 结果的分词器。因此，我们的方法可以应用于各种分词方法，而现有的工作由于分词器和下游模型的同时学习，因此不能应用于各种分词方法。本文提出了 BiLSTM-based 分词器的示例，它可以比现有工作中使用的非神经网络分词方法捕捉更广泛的上下文信息。在日语、汉语和英语文本分类任务上的实验结果表明，所提出的方法在 tokenization 优化方面比现有方法表现更好。

    This paper proposes a method to optimize tokenization for the performance improvement of already trained downstream models. Our method generates tokenization results attaining lower loss values of a given downstream model on the training data for restricting vocabularies and trains a tokenizer reproducing the tokenization results. Therefore, our method can be applied to variety of tokenization methods, while existing work cannot due to the simultaneous learning of the tokenizer and the downstream model. This paper proposes an example of the BiLSTM-based tokenizer with vocabulary restriction, which can capture wider contextual information for the tokenization process than non-neural-based tokenization methods used in existing work. Experimental results on text classification in Japanese, Chinese, and English text classification tasks show that the proposed method improves performance compared to the existing methods for tokenization optimization.
    
[^35]: 自然语言生成对话服务的聊天体验预测因素研究

    Which Factors Predict the Chat Experience of a Natural Language Generation Dialogue Service?. (arXiv:2304.10785v1 [cs.CL])

    [http://arxiv.org/abs/2304.10785](http://arxiv.org/abs/2304.10785)

    本文研究了自然语言生成对话系统中影响聊天体验的多种因素，包括提示、连贯性、情感、相似性和用户对话代理的好感度，发现用户的好感度和连贯性、情感、相似性是聊天体验的正向预测因素。此外，用户可能更喜欢具有外向性、开放性、责任心、宜人性和非神经质特征的对话代理。

    

    本文提出了一个概念性模型，用于预测自然语言生成对话系统中的聊天体验。我们使用部分最小二乘结构方程建模方法（PLS-SEM）对120名参与者进行了评估，并获得了0.541的R方值。该模型考虑了多种因素，包括用于生成的提示、对话中的连贯性、情感和相似性，以及用户对话代理的好感度。我们进一步探讨了我们提出的模型子集的有效性。结果显示，用户的好感度和对话中的连贯性、情感和相似性是用户聊天体验的正向预测因素。此外，我们发现用户可能更喜欢具有外向性、开放性、责任心、宜人性和非神经质特征的对话代理。通过我们的研究，自适应对话系统可以使用收集到的数据来推断我们模型中的因素，并通过调整对话代理的特征来预测用户的聊天体验。

    In this paper, we proposed a conceptual model to predict the chat experience in a natural language generation dialog system. We evaluated the model with 120 participants with Partial Least Squares Structural Equation Modeling (PLS-SEM) and obtained an R-square (R2) with 0.541. The model considers various factors, including the prompts used for generation; coherence, sentiment, and similarity in the conversation; and users' perceived dialog agents' favorability. We then further explore the effectiveness of the subset of our proposed model. The results showed that users' favorability and coherence, sentiment, and similarity in the dialogue are positive predictors of users' chat experience. Moreover, we found users may prefer dialog agents with characteristics of Extroversion, Openness, Conscientiousness, Agreeableness, and Non-Neuroticism. Through our research, an adaptive dialog system might use collected data to infer factors in our model, predict the chat experience for users through 
    
[^36]: Eyettention：基于注意力机制的双序列模型以预测人类阅读时的扫视路径

    Eyettention: An Attention-based Dual-Sequence Model for Predicting Human Scanpaths during Reading. (arXiv:2304.10784v1 [cs.CL])

    [http://arxiv.org/abs/2304.10784](http://arxiv.org/abs/2304.10784)

    Eyettention是第一个同时处理语言序列和时间序列的阅读模型，可以更准确地模拟阅读者的扫视路径，对机器学习的自然语言处理模型具有借鉴意义。

    

    阅读时的眼动揭示了阅读者的认知过程和所阅读文本的特征。因此，阅读中扫视路径的分析已引起各个领域的关注，涵盖了从认知科学到语言学和计算机科学。然而，模拟阅读时人类的扫视路径的主要挑战在于它们是由双序列组成的：单词按照语言的语法规则排序，而注视则按照时间顺序排序。人类并不严格按左到右的顺序阅读，而是跳过或重复注视单词，并倒退到以前的单词，语言序列和时间序列的对齐并不容易。本文开发了Eyettention，这是第一个同时处理语言序列和时间序列的双序列模型。

    Eye movements during reading offer insights into both the reader's cognitive processes and the characteristics of the text that is being read. Hence, the analysis of scanpaths in reading have attracted increasing attention across fields, ranging from cognitive science over linguistics to computer science. In particular, eye-tracking-while-reading data has been argued to bear the potential to make machine-learning-based language models exhibit a more human-like linguistic behavior. However, one of the main challenges in modeling human scanpaths in reading is their dual-sequence nature: the words are ordered following the grammatical rules of the language, whereas the fixations are chronologically ordered. As humans do not strictly read from left-to-right, but rather skip or refixate words and regress to previous words, the alignment of the linguistic and the temporal sequence is non-trivial. In this paper, we develop Eyettention, the first dual-sequence model that simultaneously process
    
[^37]: GeoLayoutLM: 基于几何形态的视觉信息抽取预训练模型

    GeoLayoutLM: Geometric Pre-training for Visual Information Extraction. (arXiv:2304.10759v1 [cs.CV])

    [http://arxiv.org/abs/2304.10759](http://arxiv.org/abs/2304.10759)

    本文提出了一个名为GeoLayoutLM的预训练模型，能够显式地建模预训练的几何关系，在关系提取任务中取得了最优结果。

    

    视觉信息抽取（VIE）在文档智能领域扮演着重要角色，通常被划分为语义实体识别（SER）和关系提取（RE）两个任务。尽管文档的预训练模型在SER方面已经取得了实质性进展，但是现有模型大都采用隐式方式学习几何形态信息，这种方式对于RE任务不够有效，因为对于RE而言几何形态信息尤其重要。此外，我们发现对于RE而言，预训练阶段和微调阶段之间的目标间隙也影响了RE性能的提升。因此，本文提出了一个多模型框架GeoLayoutLM，能够显式地建模预训练的几何关系，我们称之为几何预训练。GeoLayoutLM通过三个特别设计的几何相关预训练任务实现了几何预训练。此外，为了弥补目标间隙，新颖的关系头检测任务也在RE的微调阶段引入。GeoLayoutLM在几个基准数据集上都取得了SER和RE任务的最优结果，证明了本方法的有效性和通用性。

    Visual information extraction (VIE) plays an important role in Document Intelligence. Generally, it is divided into two tasks: semantic entity recognition (SER) and relation extraction (RE). Recently, pre-trained models for documents have achieved substantial progress in VIE, particularly in SER. However, most of the existing models learn the geometric representation in an implicit way, which has been found insufficient for the RE task since geometric information is especially crucial for RE. Moreover, we reveal another factor that limits the performance of RE lies in the objective gap between the pre-training phase and the fine-tuning phase for RE. To tackle these issues, we propose in this paper a multi-modal framework, named GeoLayoutLM, for VIE. GeoLayoutLM explicitly models the geometric relations in pre-training, which we call geometric pre-training. Geometric pre-training is achieved by three specially designed geometry-related pre-training tasks. Additionally, novel relation he
    
[^38]: 通过互动反馈与代理交互来提高协作环境下基于实地理解（Grounded Language Understanding）的能力

    Improving Grounded Language Understanding in a Collaborative Environment by Interacting with Agents Through Help Feedback. (arXiv:2304.10750v1 [cs.CL])

    [http://arxiv.org/abs/2304.10750](http://arxiv.org/abs/2304.10750)

    研究通过互动反馈与代理交互来提高协作环境下基于实地理解的能力。

    

    许多自然语言处理任务通常被视为单步问题。在这些任务中，代理接收一个指令，执行它，然后根据最终结果进行评估。然而，人类语言本质上是交互式的，我们主张人工智能与人类的协作也应是交互式的，人类监督人工智能代理的工作，并提供代理可以理解和利用的反馈信息。在这项工作中，我们探讨了通过Help Feedback实现这一目标的方向。

    Many approaches to Natural Language Processing (NLP) tasks often treat them as single-step problems, where an agent receives an instruction, executes it, and is evaluated based on the final outcome. However, human language is inherently interactive, as evidenced by the back-and-forth nature of human conversations. In light of this, we posit that human-AI collaboration should also be interactive, with humans monitoring the work of AI agents and providing feedback that the agent can understand and utilize. Further, the AI agent should be able to detect when it needs additional information and proactively ask for help. Enabling this scenario would lead to more natural, efficient, and engaging human-AI collaborations.  In this work, we explore these directions using the challenging task defined by the IGLU competition, an interactive grounded language understanding task in a MineCraft-like world. We explore multiple types of help players can give to the AI to guide it and analyze the impac
    
[^39]: KitchenScale: 从食谱上下文中学习预测成分量。

    KitchenScale: Learning to predict ingredient quantities from recipe contexts. (arXiv:2304.10739v1 [cs.CL])

    [http://arxiv.org/abs/2304.10739](http://arxiv.org/abs/2304.10739)

    KitchenScale是一个经过Fine-tuned的预训练语言模型（PLM），可根据食谱上下文预测目标成分的数量和测量单位。该模型采用离散潜在指数（DExp）方法处理食谱语料库中数字尺度的高方差，尝试从食谱文本到PLMs的转移学习。在新构建的数据集和推荐示例上进行实验，证明了KitchenScale具有泛化性并可以理解各种食谱语境，同时提供了一个Web应用程序来为用户提供所需的食品量的配方特定的测量单位。

    

    在烹饪实践中，确定成分的适当量对于丰富口感和促进健康至关重要。我们介绍了KitchenScale，这是一个经过Fine-tuned的预训练语言模型（PLM），根据食谱上下文预测目标成分的数量和测量单位。为了有效地训练我们的KitchenScale模型，我们制定了一个包括三个子任务的成分量预测任务，这些子任务是成分测量类型分类、单位分类和数量回归任务。此外，我们利用了从食谱文本到PLMs的烹饪知识的转移学习。我们采用了离散潜在指数（DExp）方法来应对食谱语料库中数字尺度的高方差。我们使用我们新构建的数据集和推荐示例进行实验，证明了KitchenScale理解各种食谱语境以及在预测成分量方面具有泛化性。我们实现了一个Web应用程序，为用户提供所需的用于所需人数食品量的配方特定的测量单位。

    Determining proper quantities for ingredients is an essential part of cooking practice from the perspective of enriching tastiness and promoting healthiness. We introduce KitchenScale, a fine-tuned Pre-trained Language Model (PLM) that predicts a target ingredient's quantity and measurement unit given its recipe context. To effectively train our KitchenScale model, we formulate an ingredient quantity prediction task that consists of three sub-tasks which are ingredient measurement type classification, unit classification, and quantity regression task. Furthermore, we utilized transfer learning of cooking knowledge from recipe texts to PLMs. We adopted the Discrete Latent Exponent (DExp) method to cope with high variance of numerical scales in recipe corpora. Experiments with our newly constructed dataset and recommendation examples demonstrate KitchenScale's understanding of various recipe contexts and generalizability in predicting ingredient quantities. We implemented a web applicati
    
[^40]: 通过正确性和信息量评估推理链的ReCEval

    ReCEval: Evaluating Reasoning Chains via Correctness and Informativeness. (arXiv:2304.10703v1 [cs.CL])

    [http://arxiv.org/abs/2304.10703](http://arxiv.org/abs/2304.10703)

    本文提出了一种基于推导链正确性和信息量的推理链评估框架ReCEval，用以评估多步推理能力。该框架能够客观、系统和准确地评估推理链，并在多个数据集上实现了良好的效果。

    

    多步推理能力在许多自然语言任务中都是基础，但什么构成好的推理链以及如何评估它们尚不清楚。大多数现有方法仅关注推理链是否导致正确的结论，但这种以答案为导向的观点可能会将好的推理质量与其他用于预测答案的假捷径混淆。为了弥补这一差距，我们将推理链视为推导最终答案的非正式证明，通过评估推理链的两个关键特性——（1）正确性，即每个步骤基于步骤，前置步骤和输入上下文中包含的信息进行有效推理，以及（2）信息量，即每个步骤提供新信息有助于推导生成的答案——我们提出了ReCEval（推理链评估）框架。我们使用自然语言推理模型和信息理论测量实现了ReCEval。在多个数据集上的实验表明，我们的框架在评估推理链方面比现有方法更加客观、系统和准确。

    Multi-step reasoning ability is fundamental to many natural language tasks, yet it is unclear what constitutes a good reasoning chain and how to evaluate them. Most existing methods focus solely on whether the reasoning chain leads to the correct conclusion, but this answer-oriented view may confound the quality of reasoning with other spurious shortcuts to predict the answer. To bridge this gap, we evaluate reasoning chains by viewing them as informal proofs that derive the final answer. Specifically, we propose ReCEval (Reasoning Chain Evaluation), a framework that evaluates reasoning chains through two key properties: (1) correctness, i.e., each step makes a valid inference based on the information contained within the step, preceding steps, and input context, and (2) informativeness, i.e., each step provides new information that is helpful towards deriving the generated answer. We implement ReCEval using natural language inference models and information-theoretic measures. On multi
    
[^41]: 元语义学：迈向更好的自然语言理解和推理

    Meta Semantics: Towards better natural language understanding and reasoning. (arXiv:2304.10663v1 [cs.CL])

    [http://arxiv.org/abs/2304.10663](http://arxiv.org/abs/2304.10663)

    该论文提出了解决词汇外问题的两种策略以及一个用于更好的自然语言理解和推理的语义模型，旨在克服深度神经网络方法和基于规则方法的不足。

    

    自然语言理解是人工智能中最具挑战性的问题之一。深度神经网络方法，特别是大型语言模块（LLM）方法，如ChatGPT和GPT-3，具有采用非正式文本的强大灵活性，但在逻辑推导上较弱，并且受到词汇外（OOV）问题的影响。另一方面，基于规则的方法，如Mathematica、语义网络和Lean，在推理方面表现出色，但无法处理复杂和易变的非正式文本。受到语用学和结构主义的启发，我们提出了两种策略来解决OOV问题，并提出了一个语义模型，用于更好的自然语言理解和推理。

    Natural language understanding is one of the most challenging topics in artificial intelligence. Deep neural network methods, particularly large language module (LLM) methods such as ChatGPT and GPT-3, have powerful flexibility to adopt informal text but are weak on logical deduction and suffer from the out-of-vocabulary (OOV) problem. On the other hand, rule-based methods such as Mathematica, Semantic web, and Lean, are excellent in reasoning but cannot handle the complex and changeable informal text. Inspired by pragmatics and structuralism, we propose two strategies to solve the OOV problem and a semantic model for better natural language understanding and reasoning.
    
[^42]: 从BERT中蒸馏知识进行词义识别

    Word Sense Induction with Knowledge Distillation from BERT. (arXiv:2304.10642v1 [cs.CL])

    [http://arxiv.org/abs/2304.10642](http://arxiv.org/abs/2304.10642)

    本文提出了一种从BERT中蒸馏知识进行多词义识别的方法，可有效地利用词的多个语义感知，在资源限制的情况下获得与最先进的多词义嵌入相当的结果。

    

    预训练的上下文语言模型被广泛用于语言理解任务，但对于资源受限的系统来说并不适用。在这种情况下，非上下文词向量是一种有效的替代方案。本文提出了一种两阶段方法，通过在上下文中利用词的多个语义感知来从一个预训练的语言模型（BERT）中蒸馏多个词义，并将这种信息传递到类skip-gram框架下的多词义嵌入中。

    Pre-trained contextual language models are ubiquitously employed for language understanding tasks, but are unsuitable for resource-constrained systems. Noncontextual word embeddings are an efficient alternative in these settings. Such methods typically use one vector to encode multiple different meanings of a word, and incur errors due to polysemy. This paper proposes a two-stage method to distill multiple word senses from a pre-trained language model (BERT) by using attention over the senses of a word in a context and transferring this sense information to fit multi-sense embeddings in a skip-gram-like framework. We demonstrate an effective approach to training the sense disambiguation mechanism in our model with a distribution over word senses extracted from the output layer embeddings of BERT. Experiments on the contextual word similarity and sense induction tasks show that this method is superior to or competitive with state-of-the-art multi-sense embeddings on multiple benchmark d
    
[^43]: IXA/Cogcomp在SemEval-2023任务2中的表现：基于知识库的上下文增强多语言命名实体识别。

    IXA/Cogcomp at SemEval-2023 Task 2: Context-enriched Multilingual Named Entity Recognition using Knowledge Bases. (arXiv:2304.10637v1 [cs.CL])

    [http://arxiv.org/abs/2304.10637](http://arxiv.org/abs/2304.10637)

    本文提出了一种基于知识库的上下文增强的多语言命名实体识别方法，通过识别、链接和预测实体类别，能够准确地分类细粒度和新兴实体。

    

    命名实体识别(NER)是一项核心的自然语言处理任务，在这方面，预训练的语言模型表现出了卓越的性能。然而，像CoNLL 2003等标准基准并没有解决部署NER系统需要面对的许多挑战，例如需要以细粒度的方式对新兴或复杂实体进行分类。本文提出了一种新颖的NER级联方法，包括三个步骤：首先，识别输入句子中的实体候选项；其次，将每个候选项链接到现有的知识库；第三，预测每个实体候选项的细粒度类别。我们通过实验证明了外部知识库在准确分类细粒度和新兴实体方面的重要性。我们的系统在MultiCoNER2共享任务中表现出了鲁棒性能，即使在低资源语言环境中，我们也能利用高资源语言的知识库。

    Named Entity Recognition (NER) is a core natural language processing task in which pre-trained language models have shown remarkable performance. However, standard benchmarks like CoNLL 2003 \cite{conll03} do not address many of the challenges that deployed NER systems face, such as having to classify emerging or complex entities in a fine-grained way. In this paper we present a novel NER cascade approach comprising three steps: first, identifying candidate entities in the input sentence; second, linking the each candidate to an existing knowledge base; third, predicting the fine-grained category for each entity candidate. We empirically demonstrate the significance of external knowledge bases in accurately classifying fine-grained and emerging entities. Our system exhibits robust performance in the MultiCoNER2 \cite{multiconer2-data} shared task, even in the low-resource language setting where we leverage knowledge bases of high-resource languages.
    
[^44]: “HOT” ChatGPT：ChatGPT在社交媒体上检测和识别令人讨厌、令人不悦和有害评论的潜力

    "HOT" ChatGPT: The promise of ChatGPT in detecting and discriminating hateful, offensive, and toxic comments on social media. (arXiv:2304.10619v1 [cs.CL])

    [http://arxiv.org/abs/2304.10619](http://arxiv.org/abs/2304.10619)

    本研究使用ChatGPT探究了生成式AI模型检测社交媒体上有害评论的可行性，结果显示ChatGPT可以达到约80%的准确性。

    

    社交媒体上危害性内容的存在对在线社区和参与产生了负面影响。解决这个问题的方法之一是开发需要人工标注的检测模型。然而，构建这样的模型需要曝露标注者于有害和冒犯性内容的任务，可能需要大量的时间和成本。生成式AI模型有潜力理解和检测有害内容。为了研究这个潜力，我们使用ChatGPT，并将其性能与MTurker注释进行了比较，这些注释与有害内容相关的三个经常讨论的概念：令人讨厌、令人不悦和有害（HOT）。我们设计了五个提示与ChatGPT进行交互，并进行了四个实验来引出HOT的分类。我们的结果显示，与MTurker注释相比，ChatGPT可以达到约80％的准确性。具体而言，与HOT评论相比，模型对非HOT评论的分类更加一致。

    Harmful content is pervasive on social media, poisoning online communities and negatively impacting participation. A common approach to address this issue is to develop detection models that rely on human annotations. However, the tasks required to build such models expose annotators to harmful and offensive content and may require significant time and cost to complete. Generative AI models have the potential to understand and detect harmful content. To investigate this potential, we used ChatGPT and compared its performance with MTurker annotations for three frequently discussed concepts related to harmful content: Hateful, Offensive, and Toxic (HOT). We designed five prompts to interact with ChatGPT and conducted four experiments eliciting HOT classifications. Our results show that ChatGPT can achieve an accuracy of approximately 80% when compared to MTurker annotations. Specifically, the model displays a more consistent classification for non-HOT comments than HOT comments compared 
    
[^45]: 大型语言模型的多方面重复抑制和内容调控

    Multi-aspect Repetition Suppression and Content Moderation of Large Language Models. (arXiv:2304.10611v1 [cs.CL])

    [http://arxiv.org/abs/2304.10611](http://arxiv.org/abs/2304.10611)

    本文介绍了一种使用标记和序列级别的不可能性损失，以及在培训期间的重复惩罚、推理和后处理等多层面方法来抑制大型语言模型中的重复，并避免生成攻击性内容的能力。

    

    自然语言生成在NLP领域是最具影响力的领域之一，近年来由大型语言模型(LLMs)带来的进步得到了人们的关注。作为编写助手应用程序的关键工具，它们通常容易复制或扩展输入中提供的具有攻击性的内容。在低资源数据环境中，它们也可能导致输出重复的问题。本文介绍了一种精确和非精确重复抑制的结合方法，使用标记和序列级别的不可能性损失，培训期间的重复惩罚、推理和后处理。我们进一步探讨了多级不可能性损失的范围，以赋予模型避免从一开始产生攻击性词汇和短语的能力。最后，通过全面的实验，在多个度量标准上证明了我们提出的方法的有效性。

    Natural language generation is one of the most impactful fields in NLP, and recent years have witnessed its evolution brought about by large language models (LLMs). As the key instrument for writing assistance applications, they are generally prone to replicating or extending offensive content provided in the input. In low-resource data regime, they can also lead to repetitive outputs (Holtzman et al., 2019) [1]. Usually, offensive content and repetitions are mitigated with post-hoc methods, including n-gram level blocklists, top-k and nucleus sampling. In this paper, we introduce a combination of exact and non-exact repetition suppression using token and sequence level unlikelihood loss, repetition penalty during training, inference, and post-processing respectively. We further explore multi-level unlikelihood loss to the extent that it endows the model with abilities to avoid generating offensive words and phrases from the beginning. Finally, with comprehensive experiments, we demons
    
[^46]: 结合编码本和GPT-3支持定性分析的大语言模型

    Supporting Qualitative Analysis with Large Language Models: Combining Codebook with GPT-3 for Deductive Coding. (arXiv:2304.10548v1 [cs.CL])

    [http://arxiv.org/abs/2304.10548](http://arxiv.org/abs/2304.10548)

    本研究探讨了使用大型语言模型来支持定性分析中的演绎编码。通过结合GPT-3和专家编写的编码本，研究人员成功地实现了与专家编码结果相近的标记结果，并且还允许进行高效和有效的编码本优化。

    

    对文本内容进行定性分析通过给数据打上标签揭示了丰富而有价值的信息。然而，处理大型数据集时，这个过程往往需要耗费大量人力资源。虽然最近的基于人工智能的工具展示了其实用性，但研究人员可能无法获得现成的人工智能资源和技术，更不必说挑战那些任务特定模型的有限泛化能力了。在本研究中，我们探讨了在支持演绎编码的情况下，使用大型语言模型（LLM）的可能性。演绎编码是定性分析的主要类别之一，研究人员使用预先确定的编码本将数据标记到一组固定的编码中。我们发现，使用基于好奇心驱动的问题编码任务作为案例研究，通过将GPT-3与专家制定的编码本相结合，我们的方法与专家编码结果实现了公平到相当大的一致性，并允许有效地进行编码本的优化。我们的研究发现结合LLM和演绎编码是定性分析的一个有前途的方向，并具有潜在的实践意义。

    Qualitative analysis of textual contents unpacks rich and valuable information by assigning labels to the data. However, this process is often labor-intensive, particularly when working with large datasets. While recent AI-based tools demonstrate utility, researchers may not have readily available AI resources and expertise, let alone be challenged by the limited generalizability of those task-specific models. In this study, we explored the use of large language models (LLMs) in supporting deductive coding, a major category of qualitative analysis where researchers use pre-determined codebooks to label the data into a fixed set of codes. Instead of training task-specific models, a pre-trained LLM could be used directly for various tasks without fine-tuning through prompt learning. Using a curiosity-driven questions coding task as a case study, we found, by combining GPT-3 with expert-drafted codebooks, our proposed approach achieved fair to substantial agreements with expert-coded resu
    
[^47]: 向着人类和机器科学理解的基准迈进

    Towards a Benchmark for Scientific Understanding in Humans and Machines. (arXiv:2304.10327v1 [cs.AI])

    [http://arxiv.org/abs/2304.10327](http://arxiv.org/abs/2304.10327)

    该论文提出了一个框架来创建衡量人类和人工智能科学理解的基准。他们使用了行为观念，提出了一组问题以衡量不同水平的科学理解。这个框架可以帮助评估和比较不同水平和方法的科学理解。

    

    科学理解是科学的基本目标，它使我们能够解释世界。目前还没有好的方法来衡量代理人的科学理解，无论它们是人类还是人工智能系统。缺乏清晰的基准，难以评估和比较不同水平和方法的科学理解。在此路线图中，我们提出了一个框架，利用科学哲学工具创建科学理解的基准。我们采用行为观念，认为真正的理解应该被认为是执行某些任务的能力。我们通过考虑一组问题来扩展这个概念，这些问题可以衡量不同水平的科学理解，包括信息检索，安排信息以生成解释的能力以及在不同情况下推断事物会有哪些不同。Scientific Understanding Benchmark（SUB）由

    Scientific understanding is a fundamental goal of science, allowing us to explain the world. There is currently no good way to measure the scientific understanding of agents, whether these be humans or Artificial Intelligence systems. Without a clear benchmark, it is challenging to evaluate and compare different levels of and approaches to scientific understanding. In this Roadmap, we propose a framework to create a benchmark for scientific understanding, utilizing tools from philosophy of science. We adopt a behavioral notion according to which genuine understanding should be recognized as an ability to perform certain tasks. We extend this notion by considering a set of questions that can gauge different levels of scientific understanding, covering information retrieval, the capability to arrange information to produce an explanation, and the ability to infer how things would be different under different circumstances. The Scientific Understanding Benchmark (SUB), which is formed by 
    
[^48]: 中文开放式指令广义语言模型：初步发布

    Chinese Open Instruction Generalist: A Preliminary Release. (arXiv:2304.07987v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.07987](http://arxiv.org/abs/2304.07987)

    本论文旨在通过适应不同子任务的固有特性，创建一个中文指令数据集，以填补指令调整技术在中文语言领域的空白。

    

    指令调整被广泛认为是构建广义语言模型的关键技术，随着InstructGPT和ChatGPT的发布，它已经引起了研究人员和公众的关注。尽管英语为基础的大规模语言模型取得了令人瞩目的进展，但是还未探索英语为基础的语言模型在多语任务上是否可以像英语任务那样通过精心设计的指令调整来执行，以及我们如何构建所需的语料库进行调整。为填补这一空白，我们提出了一个项目，试图通过适应4个子任务的固有特性，采用各种方法创建一个中文指令数据集。我们收集了约20万个中文指令调整样本，并进行了人工检查以确保高质量。我们还总结了现有的英文和中文指令语料库，并对一些潜在的应用进行了简要描述。

    Instruction tuning is widely recognized as a key technique for building generalist language models, which has attracted the attention of researchers and the public with the release of InstructGPT~\citep{ouyang2022training} and ChatGPT\footnote{\url{https://chat.openai.com/}}. Despite impressive progress in English-oriented large-scale language models (LLMs), it is still under-explored whether English-based foundation LLMs can perform similarly on multilingual tasks compared to English tasks with well-designed instruction tuning and how we can construct the corpora needed for the tuning.  To remedy this gap, we propose the project as an attempt to create a Chinese instruction dataset by various methods adapted to the intrinsic characteristics of 4 sub-tasks. We collect around 200k Chinese instruction tuning samples, which have been manually checked to guarantee high quality. We also summarize the existing English and Chinese instruction corpora and briefly describe some potential applic
    
[^49]: 在端到端的TTS系统中，说话人独立语调断点模型的研究

    An investigation of speaker independent phrase break models in End-to-End TTS systems. (arXiv:2304.04157v1 [eess.AS])

    [http://arxiv.org/abs/2304.04157](http://arxiv.org/abs/2304.04157)

    本文研究了在端到端TTS系统中，加入语调断点预测模型是否有用以及如何衡量其有效性。经过实验验证，使用训练好的语调模型预测断点的故事比未使用预测断点的故事更受欢迎。

    

    本文提出了我们对于端到端TTS系统中语调断点预测的研究，研究动机是：（一）在端到端TTS系统中融入明确的语调模型是否有用？（二）如何评估端到端TTS系统的语调模型是否有效？特别地，我们将对儿童故事合成的语境下短语断点预测模型的效用和有效性进行评估，使用的评估指标为听众理解度。我们通过实验听力评估表明，通过使用经过训练的语调模型预测短语断点位置合成的故事比直接合成的故事更受欢迎。

    This paper presents our work on phrase break prediction in the context of end-to-end TTS systems, motivated by the following questions: (i) Is there any utility in incorporating an explicit phrasing model in an end-to-end TTS system?, and (ii) How do you evaluate the effectiveness of a phrasing model in an end-to-end TTS system? In particular, the utility and effectiveness of phrase break prediction models are evaluated in in the context of childrens story synthesis, using listener comprehension. We show by means of perceptual listening evaluations that there is a clear preference for stories synthesized after predicting the location of phrase breaks using a trained phrasing model, over stories directly synthesized without predicting the location of phrase breaks.
    
[^50]: 发掘ChatGPT翻译的能力：一项实证研究

    Unleashing the Power of ChatGPT for Translation: An Empirical Study. (arXiv:2304.02182v1 [cs.CL])

    [http://arxiv.org/abs/2304.02182](http://arxiv.org/abs/2304.02182)

    本文实证研究了在机器翻译中采用ChatGPT辅助的效果。实验结果表明，ChatGPT具有与专业翻译系统相当甚至更好的性能，并且在特定领域的翻译上表现优异。

    

    最近发布的ChatGPT展示了在自然语言理解和自然语言生成方面惊人的能力。机器翻译是自然语言处理领域中一个重要且广泛研究的任务，它严重依赖于语言理解和生成的能力。在本文中，我们探讨如何使用ChatGPT辅助机器翻译。我们在广泛的翻译中采用了几个翻译提示。我们的实验证明，使用设计好的翻译提示的ChatGPT可以在高资源语言翻译中达到与专业翻译系统相当或更好的性能，但在低资源翻译上严重滞后。我们进一步使用多个参考文本对翻译质量进行评估，结果显示ChatGPT相对于专业系统表现更加优异。我们还在特定领域的翻译上进行实验，最终结果表明ChatGPT能够达到与专业翻译系统相媲美的水平。

    The recently released ChatGPT has demonstrated surprising abilities in natural language understanding and natural language generation. Machine translation is an important and extensively studied task in the field of natural language processing, which heavily relies on the abilities of language understanding and generation. Thus, in this paper, we explore how to assist machine translation with ChatGPT. We adopt several translation prompts on a wide range of translations. Our experimental results show that ChatGPT with designed translation prompts can achieve comparable or better performance over professional translation systems for high-resource language translations but lags behind significantly on low-resource translations. We further evaluate the translation quality using multiple references, and ChatGPT achieves superior performance compared to the professional systems. We also conduct experiments on domain-specific translations, the final results show that ChatGPT is able to compre
    
[^51]: AI对抗AI：在社交媒体上打击机器生成的虚假餐厅评论

    Combat AI With AI: Counteract Machine-Generated Fake Restaurant Reviews on Social Media. (arXiv:2302.07731v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.07731](http://arxiv.org/abs/2302.07731)

    本文针对机器生成的虚假评论提出了一种用高质量餐厅评论生成虚假评论并微调GPT输出检测器的方法，该方法预测虚假评论的性能优于现有解决方案。同时，我们还探索了预测非精英评论的模型，并在几个维度上对这些评论进行分析，此类机器生成的虚假评论是社交媒体平台面临的持续挑战。

    

    最近生成模型（如GPT）的发展使得以更低的成本制造出难以区分的虚假顾客评论，从而对社交媒体平台检测这些机器生成的虚假评论造成挑战。本文提出利用Yelp验证的高质量的精英餐厅评论来生成OpenAI GPT评论生成器的虚假评论，并最终微调GPT输出检测器来预测明显优于现有解决方案的虚假评论。我们进一步将模型应用于预测非精英评论，并在几个维度（如评论、用户和餐厅特征以及写作风格）上识别模式。我们展示了社交媒体平台正在不断面临机器生成的虚假评论的挑战，尽管他们可能实施检测系统以过滤出可疑的评论。

    Recent advances in generative models such as GPT may be used to fabricate indistinguishable fake customer reviews at a much lower cost, thus posing challenges for social media platforms to detect these machine-generated fake reviews. We propose to leverage the high-quality elite restaurant reviews verified by Yelp to generate fake reviews from the OpenAI GPT review creator and ultimately fine-tune a GPT output detector to predict fake reviews that significantly outperform existing solutions. We further apply the model to predict non-elite reviews and identify the patterns across several dimensions, such as review, user and restaurant characteristics, and writing style. We show that social media platforms are continuously challenged by machine-generated fake reviews, although they may implement detection systems to filter out suspicious reviews.
    
[^52]: 大型语言模型是多才多艺的分解器：将证据和问题分解为表格推理

    Large Language Models are Versatile Decomposers: Decompose Evidence and Questions for Table-based Reasoning. (arXiv:2301.13808v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.13808](http://arxiv.org/abs/2301.13808)

    这篇论文介绍了利用大型语言模型作为分解器，解决基于表格推理中的性能下降和复杂问题的问题，并在多个基准数据集上显著优于现有方法。

    

    基于表格的推理已经在结合深度模型和离散推理方面取得了显著的进展，它需要对自由形式的自然语言问题和结构化表格数据进行推理。然而，以往的基于表格的推理解决方案通常会在海量证据（表格）上遭遇显著的性能退化。此外，大多数现有方法在处理复杂问题时也面临困难，因为所需信息分散在不同的位置。为了缓解上述挑战，我们利用大型语言模型（LLMs）作为有效的基于表格推理的分解器，将（i）巨大的证据（一个巨大的表格）分解成子证据（一个小表格），以减轻无用信息对表格推理的干扰；和（ii）将复杂问题分解成更简单的子问题进行文本推理。具体而言，我们首先使用LLMs分解当前问题涉及的证据（表格），保留相关证据并排除不相关部分。然后，我们使用LLMs将复杂问题重新表述为更简单的子问题，以便更精确地检索每个子问题的相应证据。我们在几个基准数据集上评估了我们的方法，实验结果表明我们的方法显著优于现有的基于表格推理的方法。

    Table-based reasoning has shown remarkable progress in combining deep models with discrete reasoning, which requires reasoning over both free-form natural language (NL) questions and structured tabular data. However, previous table-based reasoning solutions usually suffer from significant performance degradation on huge evidence (tables). In addition, most existing methods struggle to reason over complex questions since the required information is scattered in different places. To alleviate the above challenges, we exploit large language models (LLMs) as decomposers for effective table-based reasoning, which (i) decompose huge evidence (a huge table) into sub-evidence (a small table) to mitigate the interference of useless information for table reasoning; and (ii) decompose complex questions into simpler sub-questions for text reasoning. Specifically, we first use the LLMs to break down the evidence (tables) involved in the current question, retaining the relevant evidence and excludin
    
[^53]: tieval：一种用于时间信息抽取系统评估的评估框架

    tieval: An Evaluation Framework for Temporal Information Extraction Systems. (arXiv:2301.04643v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.04643](http://arxiv.org/abs/2301.04643)

    本文提出了tieval，一种用于时间信息抽取系统的评估框架，它提供了标准的接口和评估指标，以克服不同数据集注释体系的差异、解析不同语料库的格式和不同的评估指标等限制。本文通过分析几个TIE系统在不同数据集上的结果，证明了tieval的有效性。

    

    近二十年来，时间信息抽取(TIE)引起了广泛关注，推动了大量数据集的开发。然而，拥有大量语料库的好处与此同时也使得对TIE系统进行基准测试变得困难。不同数据集具有不同的注释体系，这使得比较不同语料库中的竞争对手变得困难。此外，每个语料库通常采用不同的格式进行传播，因此需要研究人员/从业人员在开发所有语料库的解析器时付出大量的工程努力。这种限制迫使研究人员选择有限的数据集来评估他们的系统，从而限制了系统的比较。另一个阻碍TIE系统可比性的障碍是评估指标的采用。本文提出了tieval，一种TIE系统的评估框架，为语料库访问、黄金标准表示和评估指标提供了标准接口。我们还展示了如何使用tieval评估TIE系统，并对TIE社区中使用的两个黄金标准的几个TIE系统的结果进行了广泛的分析。

    Temporal information extraction (TIE) has attracted a great deal of interest over the last two decades, leading to the development of a significant number of datasets. Despite its benefits, having access to a large volume of corpora makes it difficult when it comes to benchmark TIE systems. On the one hand, different datasets have different annotation schemes, thus hindering the comparison between competitors across different corpora. On the other hand, the fact that each corpus is commonly disseminated in a different format requires a considerable engineering effort for a researcher/practitioner to develop parsers for all of them. This constraint forces researchers to select a limited amount of datasets to evaluate their systems which consequently limits the comparability of the systems. Yet another obstacle that hinders the comparability of the TIE systems is the evaluation metric employed. While most research works adopt traditional metrics such as precision, recall, and $F_1$, a fe
    
[^54]: 失去目标的图像压缩：用反演知识蒸馏支持多模式机器翻译的无图像推断

    Distill the Image to Nowhere: Inversion Knowledge Distillation for Multimodal Machine Translation. (arXiv:2210.04468v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.04468](http://arxiv.org/abs/2210.04468)

    本文提出 IKD-MMT 框架来支持无图像推断的多模式机器翻译，并通过在源文本中生成多模式特征来实现。该框架在多个基准数据集上表现出优异的性能，为实际应用场景中缺乏对齐图像的机器翻译提供了可行的解决方案。

    

    过去多模式机器翻译方面的研究通过融合外来视觉信息提升了双语设置。然而，多模式数据集要求对齐的 [图像、源文本、目标文本] 形式的图像必须在推断阶段提供，这在常规 NMT 设置的无对齐图像情况下特别麻烦。因此，本文引入了 IKD-MMT，一种支持无图像推断的多模式机器翻译框架，通过反演知识蒸馏方案执行多模式特征生成器，直接从（只有）源文本作为输入生成多模式特征。我们的实验表明，我们提出的 IKD-MMT 框架在多个基准数据集上表现优于无图像基线，并达到与图像必须多模式机器翻译类似的性能。我们的研究在使多模式机器翻译更加实用的现实场景中迈出了一步。

    Past works on multimodal machine translation (MMT) elevate bilingual setup by incorporating additional aligned vision information. However, an image-must requirement of the multimodal dataset largely hinders MMT's development -namely that it demands an aligned form of [image, source text, target text]. This limitation is generally troublesome during the inference phase especially when the aligned image is not provided as in the normal NMT setup. Thus, in this work, we introduce IKD-MMT, a novel MMT framework to support the image-free inference phase via an inversion knowledge distillation scheme. In particular, a multimodal feature generator is executed with a knowledge distillation module, which directly generates the multimodal feature from (only) source texts as the input. While there have been a few prior works entertaining the possibility to support image-free inference for machine translation, their performances have yet to rival the image-must translation. In our experiments, 
    
[^55]: 歌词中的性别歧视和性别偏见的大规模分析

    Large scale analysis of gender bias and sexism in song lyrics. (arXiv:2208.02052v3 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2208.02052](http://arxiv.org/abs/2208.02052)

    本文对377808首英文歌曲歌词进行大规模的自然语言处理分析，揭示了及时的性别歧视的增加以及不同性别表演者的语言偏见。

    

    我们使用自然语言处理技术分析了“Two Million Song Database”语料库中377808首英文歌曲歌词，着重分析了五十年（1960-2010）间性别歧视的表达，以及对性别偏差的评测。通过使用一个性别歧视分类器，我们在较大的规模上识别了性别歧视歌词，远超前人用手动标注流行歌曲的小样本研究。此外，通过在歌曲歌词上学习的词嵌入来衡量关联，我们揭示了性别偏见。我们发现，尤其是由男性艺术家演唱的流行歌曲中的性别歧视内容在时间上呈逐渐增多的趋势。根据表演者的性别不同，歌曲还显示出不同的语言偏见，男性独唱艺术家的歌曲中包含更多和更强的偏见。这是第一次进行这种大规模的分析，为我们揭示了流行文化这一重要部分的语言用法。

    We employ Natural Language Processing techniques to analyse 377808 English song lyrics from the "Two Million Song Database" corpus, focusing on the expression of sexism across five decades (1960-2010) and the measurement of gender biases. Using a sexism classifier, we identify sexist lyrics at a larger scale than previous studies using small samples of manually annotated popular songs. Furthermore, we reveal gender biases by measuring associations in word embeddings learned on song lyrics. We find sexist content to increase across time, especially from male artists and for popular songs appearing in Billboard charts. Songs are also shown to contain different language biases depending on the gender of the performer, with male solo artist songs containing more and stronger biases. This is the first large scale analysis of this type, giving insights into language usage in such an influential part of popular culture.
    

