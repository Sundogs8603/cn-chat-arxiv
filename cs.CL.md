# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A Statistical Turing Test for Generative Models.](http://arxiv.org/abs/2309.08913) | 本研究提出了一个统计图灵测试的框架，用于量化人类和机器在给定评估环境下生成内容分布的差异，并演示了如何使用该框架评估生成模型在实现人类水平能力方面的进展。 |
| [^2] | [Investigating Subtler Biases in LLMs: Ageism, Beauty, Institutional, and Nationality Bias in Generative Models.](http://arxiv.org/abs/2309.08902) | 本文调查了LLMs在年龄、美丽、机构和国籍等少研究但仍然重要的维度上的偏见，通过衡量在社会群体和不相关的正负属性之间做出的微妙相关决策。研究发现LLMs在特定社会群体上存在类似于“美丽即善”的广泛正面或负面态度的偏见。 |
| [^3] | [Semantic Information Extraction for Text Data with Probability Graph.](http://arxiv.org/abs/2309.08879) | 本文研究了资源受限文本数据传输的语义信息提取问题，在一个通信资源受限的网络中，使用自然语言处理技术提取原始文本数据，将提取的语义信息捕捉在一个带有概率维度的知识图中，并通过一个优化框架提取最重要的语义信息进行传输。 |
| [^4] | [X-PARADE: Cross-Lingual Textual Entailment and Information Divergence across Paragraphs.](http://arxiv.org/abs/2309.08873) | X-PARADE是第一个跨语言段落级别信息分歧的数据集，通过将来源于不同语言的维基百科页面上的段落对齐，标注者评估了目标语言段落与源语言段落之间的信息是否相同、新的或者可以推断，为解决这个问题提供了一个全面的数据集。 |
| [^5] | [PDFTriage: Question Answering over Long, Structured Documents.](http://arxiv.org/abs/2309.08872) | PDFTriage是一种处理长篇结构化文档问答的方法，通过使用结构或内容来检索上下文，解决了大型语言模型在问答中遇到的问题。 |
| [^6] | [MHLAT: Multi-hop Label-wise Attention Model for Automatic ICD Coding.](http://arxiv.org/abs/2309.08868) | 我们提出了一种名为MHLAT的简单但有效的模型，利用多跳标签关注来提供更准确和丰富的表示。实验结果表明，我们的方法在所有七个度量标准上都实现了明显更好或有竞争力的性能，并且需要优化的参数更少。 |
| [^7] | [Has Sentiment Returned to the Pre-pandemic Level? A Sentiment Analysis Using U.S. College Subreddit Data from 2019 to 2022.](http://arxiv.org/abs/2309.08845) | 本研究分析了使用美国大学Subreddit数据从疫情前到疫情期间再到后紧急期的人们的情绪变化，探讨了情绪是否已恢复到疫情前的水平。 |
| [^8] | [Bias and Fairness in Chatbots: An Overview.](http://arxiv.org/abs/2309.08836) | 这篇论文概述了现代聊天机器人设计中的偏见和公平性问题，并介绍了聊天机器人的历史、偏见来源和公平性保护方面的考虑因素。 |
| [^9] | [SLIDE: Reference-free Evaluation for Machine Translation using a Sliding Document Window.](http://arxiv.org/abs/2309.08832) | 本论文提出了一种名为SLIDE的度量方法，通过使用滑动文档窗口来评估机器翻译质量，该方法在某些情况下甚至能消除与参考度量之间的差距，表明源语言上下文可能提供了与人类参考相同的信息。 |
| [^10] | [S3-DST: Structured Open-Domain Dialogue Segmentation and State Tracking in the Era of LLMs.](http://arxiv.org/abs/2309.08827) | S3-DST是基于LLM的开放域对话中结构化的对话分段和状态跟踪方法，利用Pre-Analytical Recollection机制提高长上下文跟踪。 |
| [^11] | [An Empirical Study on Instance Selection Strategies in Self-training for Sentiment Analysis.](http://arxiv.org/abs/2309.08777) | 本文对自训练在情感分析中的实例选择策略进行了实证研究，研究了策略和超参数对自训练性能的影响。 |
| [^12] | [AlbNER: A Corpus for Named Entity Recognition in Albanian.](http://arxiv.org/abs/2309.08741) | 本文介绍了一个用于阿尔巴尼亚命名实体识别的语料库AlbNER，该语料库由阿尔巴尼亚维基百科文章中收集的900个带有标记命名实体的句子组成。初步结果表明，模型大小对NER性能影响小，而语言迁移有着显著的影响。这些资源和结果为未来实验提供了基线。 |
| [^13] | [MusiLingo: Bridging Music and Text with Pre-trained Language Models for Music Captioning and Query Response.](http://arxiv.org/abs/2309.08730) | MusiLingo是一个利用预训练的语言模型将音乐和文本相结合的系统，可以生成音乐字幕和回答音乐相关的查询。通过使用投影层对齐音乐表示，该系统成功地将音乐音频和文本环境联系起来，同时使用了一个新的数据集来推动领域的进展。 |
| [^14] | [Generating Semantic Graph Corpora with Graph Expansion Grammar.](http://arxiv.org/abs/2309.08714) | 该论文介绍了一个名为Lovelace的工具，可以使用图扩展文法生成语义图的语料库。这项工具可以通过用户自定义的文法生成符合要求的良好形式的输出图，可以应用于合成数据增强语料库和教学形式语言理论的用途。 |
| [^15] | [Frustratingly Simple Memory Efficiency for Pre-trained Language Models via Dynamic Embedding Pruning.](http://arxiv.org/abs/2309.08708) | 该论文提出了一种简单但有效的方法，通过动态嵌入剪枝来减小预训练语言模型的内存占用。该方法在各种模型和任务中都能显著降低内存使用量，同时保持相当的下游任务性能，实现更高效地利用计算资源。 |
| [^16] | [Resolving Legalese: A Multilingual Exploration of Negation Scope Resolution in Legal Documents.](http://arxiv.org/abs/2309.08695) | 本研究通过多语言探索，解决了法律文件中否定范围解析的挑战。实验结果表明，以往模型在处理多语言法律数据时表现不佳，因此我们发布了一套新的法庭判决标注数据用于改进解析效果，并取得了高达86.7％的标记级F1分。 |
| [^17] | [Fake News Detectors are Biased against Texts Generated by Large Language Models.](http://arxiv.org/abs/2309.08674) | 假新闻检测器倾向于将大型语言模型生成的内容标记为假新闻，而将人工编写的假新闻误分类为真实，我们提出了一种通过敌对训练和LLM改写的真实新闻等方法来解决这个问题，并取得了显著的改进。 |
| [^18] | [Adversarial Attacks on Tables with Entity Swap.](http://arxiv.org/abs/2309.08650) | 本论文研究了对包含实体交换的表格进行的对抗攻击。作者提出了一种针对列类型注释任务的逃避性实体交换攻击，通过采用基于相似度的采样策略生成对抗性示例，成功导致性能下降了高达70%。 |
| [^19] | [MAPLE: Mobile App Prediction Leveraging Large Language model Embeddings.](http://arxiv.org/abs/2309.08648) | MAPLE是一个利用大型语言模型嵌入进行移动应用预测的模型，通过严格测试验证了其在解密复杂模式和理解用户环境方面的能力，并强调了语言模型在不同领域中的广泛适用性。 |
| [^20] | [Intent Detection at Scale: Tuning a Generic Model using Relevant Intents.](http://arxiv.org/abs/2309.08647) | 本研究提出了一种有效的方法，通过将通用模型与每个客户的相关意图列表相结合，将意图检测扩展到不同的客户。这种方法减少了培训和维护成本，同时为客户提供个性化体验，并在生产环境中展现出卓越的性能。 |
| [^21] | [Cure the headache of Transformers via Collinear Constrained Attention.](http://arxiv.org/abs/2309.08646) | 通过引入共线约束注意力（CoCA）结构，解决Transformer模型中的头痛问题，实现了出色的外推性能和提高的计算效率。 |
| [^22] | [Anchor Points: Benchmarking Models with Much Fewer Examples.](http://arxiv.org/abs/2309.08638) | 这个论文介绍了一种使用更少的示例来对模型进行基准测试的方法，并提出了锚点选择技术来捕捉模型行为。实验证明，使用锚点对模型进行排序比使用均匀采样和其他基线方法更准确。仅使用几个锚点就可以估计模型对数据集中所有其他点的每个类别的预测，用于衡量模型性能。 |
| [^23] | [TextBind: Multi-turn Interleaved Multimodal Instruction-following.](http://arxiv.org/abs/2309.08637) | TextBind是一个注释极少的框架，用于将较大规模的语言模型赋予多轮交错多模态指令跟随能力，并通过图像-标题对生成多轮多模态指令-回应对话。这个框架对于解决实际任务具有重要意义，并为未来的研究提供了数据集、模型和演示。 |
| [^24] | [ChatGPT v Bard v Bing v Claude 2 v Aria v human-expert. How good are AI chatbots at scientific writing? (ver. 23Q3).](http://arxiv.org/abs/2309.08636) | 本文综合分析了在人文学科和考古学领域中六个AI聊天机器人在学术写作方面的能力和局限性，发现它们在重新组合现有知识方面表现出色，但在产生原创科学内容方面存在问题。 |
| [^25] | [Pretraining on the Test Set Is All You Need.](http://arxiv.org/abs/2309.08632) | 这项研究通过在测试集上进行预训练，使用精心构建的非合成数据混合，成功开发出一个在多个学术基准测试上表现出色的Transformer语言模型phi-CTNL。 |
| [^26] | [Large Language Models Can Infer Psychological Dispositions of Social Media Users.](http://arxiv.org/abs/2309.08631) | 大型语言模型能够通过分析社交媒体用户的数字足迹推断他们的心理倾向，具体表现为从Facebook状态更新中推断五大人格特质。研究发现，推断得分与自我报告得分之间存在相关性，但在性别和年龄方面存在偏见。 |
| [^27] | [Recovering from Privacy-Preserving Masking with Large Language Models.](http://arxiv.org/abs/2309.08628) | 本文利用大型语言模型（LLM）探索了替换标识信息的方法，并在下游语言建模任务上进行了评估。实验结果表明，使用混淆语料库训练的模型能够达到可比较的性能。 |
| [^28] | [Evaluating Dynamic Topic Models.](http://arxiv.org/abs/2309.08627) | 提出了一种评估动态主题模型的新方法，该方法分析了每个主题随时间变化的质量变化，并结合了模型的时间一致性。该方法在合成数据和已有DTMs数据上展示了实用性，并与人类判断具有良好的相关性。这些研究结果对于识别变化的主题、评估DTMs和指导未来研究具有重要意义。 |
| [^29] | [Improving Robustness of Neural Inverse Text Normalization via Data-Augmentation, Semi-Supervised Learning, and Post-Aligning Method.](http://arxiv.org/abs/2309.08626) | 本研究通过数据增强、半监督学习和后对齐方法改进神经逆文本标准化的鲁棒性，提高了自动语音识别的效果。 |
| [^30] | [Performance of ChatGPT-3.5 and GPT-4 on the United States Medical Licensing Examination With and Without Distractions.](http://arxiv.org/abs/2309.08625) | 本研究调查了ChatGPT在带有闲聊句子和不带闲聊句子的情况下对医学建议准确性的影响，结果显示带有干扰的问题的回答能力有所降低。 |
| [^31] | [Challenges in Annotating Datasets to Quantify Bias in Under-represented Society.](http://arxiv.org/abs/2309.08624) | 最近研究越来越关注衡量偏见和开发去偏见技术，但在少数社群相关的偏见衡量方面的研究仍然很少。本研究以新西兰人口为例，创建了用于衡量少数社群中偏见的基准数据集，并介绍了在这个过程中遇到的挑战。 |
| [^32] | [Analyzing Character and Consciousness in AI-Generated Social Content: A Case Study of Chirper, the AI Social Network.](http://arxiv.org/abs/2309.08614) | 本文研究了AI生成的社交内容中的角色和意识，使用了新的测试方法来评估AI行为。研究发现Chirper在不同情境下展示了出色的自我识别能力。 |
| [^33] | [Multimodal Recommender Systems in the Prediction of Disease Comorbidity.](http://arxiv.org/abs/2309.08613) | 该研究探讨了在医疗领域中利用基于深度学习的推荐系统进行疾病并发症预测的方法。研究使用了NCF和DHF两种新颖的推荐系统，并利用了不同的数据集进行预测。研究结果显示NCF模型在准确率和命中率方面表现较差。 |
| [^34] | [Explaining Vision and Language through Graphs of Events in Space and Time.](http://arxiv.org/abs/2309.08612) | 本论文提出了一种称为时空事件图（GEST）的方法，能够解释、表示和生成视觉和语言故事。通过将GEST图与深度学习模型相结合，可以改善从文本到视频的生成，并提高语义上的文本比较。 |
| [^35] | [Media of Langue.](http://arxiv.org/abs/2309.08609) | 该论文介绍了《Media of Langue》这一全新词典和公共雕塑，通过描述不同语言之间的意义地图和两个力量之间的边界，重点介绍了三个新的概念：《Inter-Langue Map/Dictionary》、《Inter-Langue Space》和《Inter-Langue Network》。 |
| [^36] | [RADE: Reference-Assisted Dialogue Evaluation for Open-Domain Dialogue.](http://arxiv.org/abs/2309.08156) | 基于参考的对话评估（RADE）方法利用预创建的语句作为参考，以解决开放领域对话系统中的一对多问题，并通过共享编码器增强预测。 |
| [^37] | [Kid-Whisper: Towards Bridging the Performance Gap in Automatic Speech Recognition for Children VS. Adults.](http://arxiv.org/abs/2309.07927) | 本文主要研究利用My Science Tutor（MyST）儿童语音语料库和更有效的数据预处理来改进自动语音识别（ASR）系统对儿童语音的识别性能。将Whisper系统整合到儿童语音识别中，显示了表现可行和高效。 |
| [^38] | [Text Classification of Cancer Clinical Trial Eligibility Criteria.](http://arxiv.org/abs/2309.07812) | 本文研究了癌症临床试验中常见的排除标准，通过应用文本分类方法和预训练的BERT模型，证明了自动分类排除标准的可行性，并展示了专门为临床试验设计的预训练语言模型的价值。 |
| [^39] | [Down the Toxicity Rabbit Hole: Investigating PaLM 2 Guardrails.](http://arxiv.org/abs/2309.06415) | 这项研究通过一个新颖的毒性兔子洞框架对PaLM 2的安全反馈进行了稳健性审计，揭示了PaLM 2生成的高度令人不安的毒性内容未被安全守护栏评估为高度不安全。 |
| [^40] | [Improving and Evaluating the Detection of Fragmentation in News Recommendations with the Clustering of News Story Chains.](http://arxiv.org/abs/2309.06192) | 通过对新闻故事链的聚类，改进和评估了新闻推荐中信息碎片化的检测。研究结果对于衡量信息流的完整性和影响民主和公共讨论具有重要意义。 |
| [^41] | [PACE: Prompting and Augmentation for Calibrated Confidence Estimation with GPT-4 in Cloud Incident Root Cause Analysis.](http://arxiv.org/abs/2309.05833) | 本文提出了一种通过提示检索增强的大语言模型（LLM）来增强云事件根本原因分析工具中置信度估计的方法。 |
| [^42] | [Understanding the Impact of Post-Training Quantization on Large Language Models.](http://arxiv.org/abs/2309.05210) | 本研究旨在理解后训练量化对大型语言模型的影响，揭示了量化模型在下一个单词预测等关键任务中如何响应超参数的差距。 |
| [^43] | [FLM-101B: An Open LLM and How to Train It with $100K Budget.](http://arxiv.org/abs/2309.03852) | 本文介绍了一种开放的LLM模型（FLM-101B）以及如何用10万美元的预算来训练它。通过采用增长策略，可以显著降低LLM训练的成本。同时，引入了一种系统的评估方法，以评估LLM的智能能力。 |
| [^44] | [Open Sesame! Universal Black Box Jailbreaking of Large Language Models.](http://arxiv.org/abs/2309.01446) | 本文提出了一种使用遗传算法的新颖方法，可以在无法访问模型架构和参数的情况下操纵大规模语言模型 (LLMs)。通过优化通用对抗提示与用户查询结合，可以扰乱被攻击模型的对齐，导致意外和潜在有害的输出。该方法可以揭示模型的局限性和漏洞，为负责任的AI开发提供了一种诊断工具。 |
| [^45] | [A Study on the Implementation of Generative AI Services Using an Enterprise Data-Based LLM Application Architecture.](http://arxiv.org/abs/2309.01105) | 本研究通过利用大型语言模型（LLM）应用架构实现了生成式AI服务，并开发了一种名为检索增强生成（RAG）模型，以解决信息稀缺和数据不足的挑战。 |
| [^46] | [Explainability for Large Language Models: A Survey.](http://arxiv.org/abs/2309.01029) | 本文调研了大型语言模型的可解释性问题，提出了一个解释技术的分类法，并介绍了基于Transformer的语言模型的解释方法。同时，讨论了评估生成解释的度量标准，以及如何利用解释来调试模型和提高性能。 |
| [^47] | [Image Hijacking: Adversarial Images can Control Generative Models at Runtime.](http://arxiv.org/abs/2309.00236) | 本研究发现对抗性图像能够在运行时控制生成模型，并提出了通用的方法来创建图像劫持。通过研究三种攻击类型，我们发现这些攻击对最新的视觉语言模型具有高达90％以上的成功率。该研究引发了对基础模型安全性的严重担忧。 |
| [^48] | [LLaSM: Large Language and Speech Model.](http://arxiv.org/abs/2308.15930) | LLaSM是一个大型语言和语音模型，具有跨模态对话能力，通过遵循语音和语言指令，提供了一种方便自然的人机交互方式。 |
| [^49] | [From Quantity to Quality: Boosting LLM Performance with Self-Guided Data Selection for Instruction Tuning.](http://arxiv.org/abs/2308.12032) | 该论文引入了一种自我引导的方法，让LLM能够自主地选择高质量的指令数据，通过引入指令遵循难度指标（IFD），大幅提高了模型训练效率，并在知名数据集上进行了验证，展示了优于传统数据输入的结果。 |
| [^50] | [Efficient Benchmarking (of Language Models).](http://arxiv.org/abs/2308.11696) | 本研究提出了一种名为"Efficient Benchmarking"的问题，旨在智能地减少语言模型评估的计算成本而不降低可靠性，并使用一种名为Decision Impact on Reliability（DIoR）的新度量来评估决策的可靠性。通过HELM基准测试的案例研究，发现只需删除一个低排名模型即可改变领先者，并仅需少量示例即可得到正确的基准测试排名。 |
| [^51] | [A Survey on Model Compression for Large Language Models.](http://arxiv.org/abs/2308.07633) | 本论文提供了关于大型语言模型的模型压缩综述，探讨了量化、修剪、知识蒸馏等不同方法，并突出介绍了最新进展和创新方法，为实现高效的部署提供了重要思路。 |
| [^52] | [Modeling the Dashboard Provenance.](http://arxiv.org/abs/2308.06788) | 本文提供了一个专为仪表盘及其视觉和数据组件设计的来源表示模型，旨在提供完备的必要来源元数据，以便用户评估质量和一致性。 |
| [^53] | [AspectMMKG: A Multi-modal Knowledge Graph with Aspect-aware Entities.](http://arxiv.org/abs/2308.04992) | AspectMMKG是一个具有方面意识的多模态知识图谱，通过匹配图像和不同实体方面，它提供了从多个角度理解实体的能力，并在实体方面链接任务中取得了最先进的性能。 |
| [^54] | [Leveraging Large Language Models for Mental Health Prediction via Online Text Data.](http://arxiv.org/abs/2307.14385) | 本研究首次对多种大型语言模型在心理健康预测任务上进行了全面评估，结果表明指令微调可以显著提升模型性能，并且最优微调模型在平衡准确度上胜过GPT-3.5，并与最先进的任务特定模型持平。 |
| [^55] | [Founding a mathematical diffusion model in linguistics. The case study of German syntactic features in the North-Eastern Italian dialects.](http://arxiv.org/abs/2307.14291) | 该论文通过研究德语句法特征在北东意大利方言中的传播，建立了一个数学扩散模型，并通过地理数据科学工具生成了交互式地图。 |
| [^56] | [vONTSS: vMF based semi-supervised neural topic modeling with optimal transport.](http://arxiv.org/abs/2307.01226) | vONTSS是一种基于vMF和最优传输的半监督神经主题建模方法，它在分类准确率和多样性方面优于其他方法，并且支持无监督主题建模。实验证明，vONTSS比最近的NTM更快。 |
| [^57] | [Improved NL2SQL based on Multi-layer Expert Network.](http://arxiv.org/abs/2306.17727) | 本研究提出了一种名为多层专家生成SQL的新方法，通过利用专用的多任务分层网络，该方法解决了由于不同分类任务的负迁移问题导致生成不准确SQL语句的限制。该方法在WiKSQL数据集上取得了良好的效果。 |
| [^58] | [Unsupervised Text Embedding Space Generation Using Generative Adversarial Networks for Text Synthesis.](http://arxiv.org/abs/2306.17181) | 本论文提出了一种使用生成对抗网络（GAN）生成连续文本嵌入空间的方法（TESGAN），以解决传统GAN在自然语言生成中的限制。这种方法通过引入连续的文本嵌入空间取代离散的标记，使得生成器在通过反向传播更新梯度时更加有效。 |
| [^59] | [Towards training Bilingual and Code-Switched Speech Recognition models from Monolingual data sources.](http://arxiv.org/abs/2306.08753) | 本文介绍了一种使用纯粹的单语数据源训练双语和代码切换ASR模型的方法。通过引入集合标记器，将LID应用到每个标记，而不是在单语样本边界生成LID，我们展示了集合标记器的有效性，并提出了合成代码切换ASR数据生成技术，证明了所提出的代码切换ASR模型在语音任务中的有效性。 |
| [^60] | [LLMatic: Neural Architecture Search via Large Language Models and Quality-Diversity Optimization.](http://arxiv.org/abs/2306.01102) | 本文介绍了利用大语言模型和多样性优化算法相结合的 LLMatic 神经结构搜索算法。该算法在CIFAR-10数据集进行测试，仅进行2000次搜索即可产生高性能网络，即使没有该基准领域的先前知识或任何先前的最佳结果的曝光。 |
| [^61] | [Weaker Than You Think: A Critical Look at Weakly Supervised Learning.](http://arxiv.org/abs/2305.17442) | 这篇论文批判性地研究了弱监督学习方法，发现这些方法的好处被高估了，大多数优势可以通过简单地利用干净的训练数据实现。 |
| [^62] | [Human-Centered Metrics for Dialog System Evaluation.](http://arxiv.org/abs/2305.14757) | 本文提出了从心理学构造中提取的可解释度量标准，用于评估对话系统，通过情绪熵、语言风格和情感匹配、宜人性和共情等五个度量，这些人类度量标准与现有的自动度量标准不相关且具有更高的预测准确度。 |
| [^63] | [Enhancing Generation through Summarization Duality and Explicit Outline Control.](http://arxiv.org/abs/2305.14459) | 本文提出了一个两阶段的摘要增强的大纲监督生成框架，能够更好地生成明确和合理的大纲，并引入了一个新颖的显式大纲控制方法以更有效地利用生成的大纲。 |
| [^64] | [SPEECH: Structured Prediction with Energy-Based Event-Centric Hyperspheres.](http://arxiv.org/abs/2305.13617) | 这篇论文提出了一种称为SPEECH的模型，它使用能量建模来表示复杂的事件结构，并使用超球来表示事件类别。实验结果表明，SPEECH在事件检测和事件关系抽取任务中表现出卓越的性能。 |
| [^65] | [Can Large Language Models emulate an inductive Thematic Analysis of semi-structured interviews? An exploration and provocation on the limits of the approach and the model.](http://arxiv.org/abs/2305.13014) | 本文介绍了一项实验的结果和反思，该实验使用模型GPT 3.5-Turbo来模拟归纳式主题分析的某些方面。尝试使用LLM进行基于人类解释的分析显然是一种挑战，但也是了解这些系统在定性研究中能否使用的一种方式。 |
| [^66] | [Decouple knowledge from paramters for plug-and-play language modeling.](http://arxiv.org/abs/2305.11564) | 本文介绍了一种新的插件式预训练模型，其与模型参数中的知识存储分离，采用可编辑和可扩展的键值存储器，通过DPM中的知识检索以可解释的方式利用知识。 |
| [^67] | [Learning Human-Human Interactions in Images from Weak Textual Supervision.](http://arxiv.org/abs/2304.14104) | 本文提出了一种新的范式，从单一的静态图像中学习自由文本的形式来灵活建模人际互动。并通过知识蒸馏生成伪标签来训练一种字幕模型，用于有效理解图像中的人际互动，具有较高的预测文本和语义质量，并在此任务上优于SOTA的图像字幕和情境识别模型。 |
| [^68] | [AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models.](http://arxiv.org/abs/2304.06364) | AGIEval是一个以人为中心设计的基准测试工具，用于评估基础模型在人类中心标准化考试上的表现。GPT-4在SAT、LSAT和数学比赛方面超越了人类平均表现，展示了当代基础模型在人类级任务中的非凡性能。 |
| [^69] | [Bipol: A Novel Multi-Axes Bias Evaluation Metric with Explainability for NLP.](http://arxiv.org/abs/2304.04029) | 本文创造了一种新的度量标准 bipol 以检测文本数据中的社交偏见。该标准包括语料库级别评估和句子级别评估两个步骤，并使用 SotA 架构创建了新模型以检测多个轴的偏差。同时，作者还创造了一个大型数据集来训练偏见检测模型，并公开了相关代码。 |
| [^70] | [Blockwise Compression of Transformer-based Models without Retraining.](http://arxiv.org/abs/2304.01483) | 本论文提出了一种名为BCT的分块压缩框架，可以对整个Transformer模型进行更细粒度的压缩，实现了降低部署门槛的目的。 |
| [^71] | [Exploring the Use of Large Language Models for Reference-Free Text Quality Evaluation: A Preliminary Empirical Study.](http://arxiv.org/abs/2304.00723) | 本文介绍了大型语言模型在无参考文本质量评估中的应用研究。研究结果表明，利用ChatGPT生成的显式得分是最有效和可靠的方法。 |
| [^72] | [E2E Spoken Entity Extraction for Virtual Agents.](http://arxiv.org/abs/2302.10186) | 本文研究了利用预训练语音编码器从语音中直接提取实体的方法，无需文本转录，且在口语实体识别任务中表现优异。 |
| [^73] | [Generation of Highlights from Research Papers Using Pointer-Generator Networks and SciBERT Embeddings.](http://arxiv.org/abs/2302.07729) | 该论文提出了一种使用指针生成网络和SciBERT嵌入来自动生成研究论文亮点的方法。在多个基准数据集上的实验证明，该模型在研究亮点生成方面具有最佳性能。 |
| [^74] | [Bipol: Multi-axes Evaluation of Bias with Explainability in Benchmark Datasets.](http://arxiv.org/abs/2301.12139) | 本研究使用一种新的多维度偏差度量指标bipol，评估了五个英文和两个瑞典的自然语言处理基准数据集中的偏差，并提供了一个新的、包含200万个样本的瑞典偏差标注数据集和用于瑞典偏差检测的多维度词库。 |
| [^75] | [One Model for All Domains: Collaborative Domain-Prefix Tuning for Cross-Domain NER.](http://arxiv.org/abs/2301.10410) | 本论文提出了基于协作域前缀调整的跨领域实体识别，使用文本到文本生成的支撑领域相关指导来将知识转移至新域NER任务，避免了先前的为每个领域结束一个全新的NER模型的问题。 |
| [^76] | [Reasoning with Language Model Prompting: A Survey.](http://arxiv.org/abs/2212.09597) | 本文提供了使用语言模型提示进行推理的前沿研究综合调查。讨论了新兴推理能力出现的潜在原因，并提供系统资源帮助初学者。 |
| [^77] | [VRDU: A Benchmark for Visually-rich Document Understanding.](http://arxiv.org/abs/2211.15421) | 本研究提出了一个名为VRDU的基准测试，以更全面地反映实际文档的复杂性，其中包含具有挑战性的丰富模式、复杂模板和多样的布局。该基准测试可用于评估文档中提取结构化数据的模型。 |
| [^78] | [Generative Knowledge Graph Construction: A Review.](http://arxiv.org/abs/2210.12714) | 本文综述了生成式知识图谱构建领域的最新进展，包括方法分类和优劣分析，并提出了未来的研究方向。 |
| [^79] | [Schema-aware Reference as Prompt Improves Data-Efficient Knowledge Graph Construction.](http://arxiv.org/abs/2210.10709) | 提出了一种以检索增强的架构感知参考作为提示的方法，可动态利用人类注释和弱监督数据所继承的架构和知识，指导生成具有更好语义连贯性和一致性的结构化知识，从而在数据效率和知识质量方面具有优越性。 |
| [^80] | [Towards Realistic Low-resource Relation Extraction: A Benchmark with Empirical Baseline Study.](http://arxiv.org/abs/2210.10678) | 本文针对低资源环境中的关系抽取进行了实证研究，并提出了三种方案来提高性能，包括使用提示方法、平衡方法和数据增强技术。通过对8个关系抽取数据集的广泛比较，实验结果表明，虽然基于提示的调整有益于低资源关系抽取，但仍有改进空间，尤其是跨句子上下文中的多个关系三元组的抽取。 |
| [^81] | [Temporal Analysis on Topics Using Word2Vec.](http://arxiv.org/abs/2209.11717) | 本研究提出了一种使用Word2Vec进行主题的时间分析的新方法，该方法通过建模主题的移动并利用k均值聚类和余弦相似度对距离进行分组，实现了识别和可视化主题随时间变化的趋势。 |
| [^82] | [The expected sum of edge lengths in planar linearizations of trees. Theory and applications.](http://arxiv.org/abs/2207.05564) | 本论文研究了在树的平面线性化中边长度的期望和，提出了一个计算平面排列的方法，并分析了平面排列与投影排列之间的关系。 |
| [^83] | [Hybrid Transformer with Multi-level Fusion for Multimodal Knowledge Graph Completion.](http://arxiv.org/abs/2205.02357) | 本文提出了一种混合Transformer与多级融合的方法，用于解决多模态知识图谱补全的问题。该方法通过统一的输入-输出架构适用于多样的任务，同时利用多级融合将视觉和文本表示集成起来。 |
| [^84] | [Empowering Fake-News Mitigation: Insights from Sharers' Social Media Post-Histories.](http://arxiv.org/abs/2203.10560) | 本论文提出消费者的社交媒体帖子历史是研究分享虚假新闻动机的一种被低估的数据来源。通过对帖子历史提取的文本线索，我们发现虚假新闻分享者在言辞上更多涉及愤怒、宗教和权力。并且，通过将帖子历史中的文本线索加入模型，可以提高预测分享虚假新闻的准确性。此外，通过激活宗教价值观和减少愤怒，可以减少虚假新闻的分享和更广泛的分享。 |
| [^85] | [DeepKE: A Deep Learning Based Knowledge Extraction Toolkit for Knowledge Base Population.](http://arxiv.org/abs/2201.03335) | DeepKE是一个基于深度学习的知识提取工具包，支持复杂的低资源、文档级和多模态场景，可用于自定义数据集和模型来从非结构化数据中提取信息。 |
| [^86] | [Sentiment Analysis and Effect of COVID-19 Pandemic using College SubReddit Data.](http://arxiv.org/abs/2112.04351) | 这项研究通过分析大学社区中的Reddit数据，研究了COVID-19疫情对人们情绪和心理状态的影响，并提出了基于RoBERTa和GAT的情绪分类模型。 |
| [^87] | [KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction.](http://arxiv.org/abs/2104.07650) | 本文提出了一种名为KnowPrompt的知识感知提示调整方法，通过将关系标签中的潜在知识融入到提示构建中，并通过协同优化的方式，提高了关系抽取任务的性能。 |
| [^88] | [Sameness Entices, but Novelty Enchants in Fanfiction Online.](http://arxiv.org/abs/1904.07741) | 该研究通过分析同人小说的大数据集，发现文化作品的成功与新颖性呈现出U形曲线的关系，而不是先增加后减弱，解决了平衡理论的谜团。 |

# 详细

[^1]: 一个统计图灵测试用于生成模型

    A Statistical Turing Test for Generative Models. (arXiv:2309.08913v1 [cs.AI])

    [http://arxiv.org/abs/2309.08913](http://arxiv.org/abs/2309.08913)

    本研究提出了一个统计图灵测试的框架，用于量化人类和机器在给定评估环境下生成内容分布的差异，并演示了如何使用该框架评估生成模型在实现人类水平能力方面的进展。

    

    人工智能系统在文本、音频和视觉等领域的内容生成能力的出现催生了用于区分内容来源于人还是机器的分类器的发展。这些工作的隐含假设是人类的生成能力与机器的生成能力存在差异。本文提供了一个在统计模式识别语言中量化人类和机器生成内容分布差异的框架，并描述了如何在框架中评估生成模型在向人类水平能力方面的进展，涵盖了多个分析维度。

    The emergence of human-like abilities of AI systems for content generation in domains such as text, audio, and vision has prompted the development of classifiers to determine whether content originated from a human or a machine. Implicit in these efforts is an assumption that the generation properties of a human are different from that of the machine. In this work, we provide a framework in the language of statistical pattern recognition that quantifies the difference between the distributions of human and machine-generated content conditioned on an evaluation context. We describe current methods in the context of the framework and demonstrate how to use the framework to evaluate the progression of generative models towards human-like capabilities, among many axes of analysis.
    
[^2]: 调查LLMs中更微妙的偏见：生成模型中的年龄主义、美丽、机构和国籍偏见

    Investigating Subtler Biases in LLMs: Ageism, Beauty, Institutional, and Nationality Bias in Generative Models. (arXiv:2309.08902v1 [cs.CL])

    [http://arxiv.org/abs/2309.08902](http://arxiv.org/abs/2309.08902)

    本文调查了LLMs在年龄、美丽、机构和国籍等少研究但仍然重要的维度上的偏见，通过衡量在社会群体和不相关的正负属性之间做出的微妙相关决策。研究发现LLMs在特定社会群体上存在类似于“美丽即善”的广泛正面或负面态度的偏见。

    

    LLMs越来越强大并广泛用于辅助用户完成各种任务。这种使用可能会将LLM偏见引入到重要决策中，如招聘、人员绩效评估和刑事判决。在NLP系统中的性别和种族等方面的偏见已得到广泛研究，尤其是针对特定刻板印象的偏见（例如，亚洲人擅长数学）。在本文中，我们研究了一些较少研究但仍然重要的维度上的偏见，如年龄和美丽，在LLMs（特别是自回归语言模型）在社会群体和不相关的正负属性之间做出更微妙的相关决策。我们问LLMs是否对特定社会群体持有广泛的正面或负面态度的偏见，类似于实验心理学中人们发现的“美丽即善”的偏见。我们引入了一个模板生成的句子完成任务的数据集，要求模型选择最合适的属性。

    LLMs are increasingly powerful and widely used to assist users in a variety of tasks. This use risks the introduction of LLM biases to consequential decisions such as job hiring, human performance evaluation, and criminal sentencing. Bias in NLP systems along the lines of gender and ethnicity has been widely studied, especially for specific stereotypes (e.g., Asians are good at math). In this paper, we investigate bias along less studied, but still consequential, dimensions, such as age and beauty, measuring subtler correlated decisions that LLMs (specially autoregressive language models) make between social groups and unrelated positive and negative attributes. We ask whether LLMs hold wide-reaching biases of positive or negative sentiment for specific social groups similar to the ``what is beautiful is good'' bias found in people in experimental psychology. We introduce a template-generated dataset of sentence completion tasks that asks the model to select the most appropriate attrib
    
[^3]: 使用概率图进行文本数据的语义信息提取

    Semantic Information Extraction for Text Data with Probability Graph. (arXiv:2309.08879v1 [cs.CL])

    [http://arxiv.org/abs/2309.08879](http://arxiv.org/abs/2309.08879)

    本文研究了资源受限文本数据传输的语义信息提取问题，在一个通信资源受限的网络中，使用自然语言处理技术提取原始文本数据，将提取的语义信息捕捉在一个带有概率维度的知识图中，并通过一个优化框架提取最重要的语义信息进行传输。

    

    本文研究了资源受限文本数据传输的语义信息提取问题。在考虑的模型中，需要在通信资源受限的网络中传输一系列文本数据，该网络仅允许有限的数据传输。因此，在发送端，使用自然语言处理技术提取原始文本数据。然后，提取的语义信息被捕捉在一个知识图中。在这个图中引入了一个额外的概率维度来捕捉每个信息的重要性。这个语义信息提取问题被提出为一个优化框架，其目标是提取最重要的语义信息进行传输。为了找到这个问题的最优解，提出了一个基于Floyd算法和高效排序机制的解决方案。数值结果证明了所提算法在两个新颖的性能指标方面的有效性。

    In this paper, the problem of semantic information extraction for resource constrained text data transmission is studied. In the considered model, a sequence of text data need to be transmitted within a communication resource-constrained network, which only allows limited data transmission. Thus, at the transmitter, the original text data is extracted with natural language processing techniques. Then, the extracted semantic information is captured in a knowledge graph. An additional probability dimension is introduced in this graph to capture the importance of each information. This semantic information extraction problem is posed as an optimization framework whose goal is to extract most important semantic information for transmission. To find an optimal solution for this problem, a Floyd's algorithm based solution coupled with an efficient sorting mechanism is proposed. Numerical results testify the effectiveness of the proposed algorithm with regards to two novel performance metrics
    
[^4]: X-PARADE: 跨语言文本蕴含和段落之间的信息分歧

    X-PARADE: Cross-Lingual Textual Entailment and Information Divergence across Paragraphs. (arXiv:2309.08873v1 [cs.CL])

    [http://arxiv.org/abs/2309.08873](http://arxiv.org/abs/2309.08873)

    X-PARADE是第一个跨语言段落级别信息分歧的数据集，通过将来源于不同语言的维基百科页面上的段落对齐，标注者评估了目标语言段落与源语言段落之间的信息是否相同、新的或者可以推断，为解决这个问题提供了一个全面的数据集。

    

    理解两段文本是否传达相同的信息是自然语言处理中许多子问题的目标，包括文本蕴含和事实核查。当这两段文本处于不同的语言时，这个问题变得更加复杂。在这里，我们介绍了X-PARADE（跨语言段落级别的分歧和蕴含分析），这是第一个跨语言段落级别信息分歧的数据集。标注者在目标语言上以跨度级别标注段落，并与源语言中的相应段落进行评估，表示给定的信息是否相同、新的，或者新的但可以推断。这个概念与跨语言自然语言推理建立了联系。对齐的段落来自不同语言的维基百科页面，反映了实际观察到的信息分歧。凭借我们的数据集，我们研究了一系列解决这个问题的方法，包括经典的机器翻译中的令牌对齐。

    Understanding when two pieces of text convey the same information is a goal touching many subproblems in NLP, including textual entailment and fact-checking. This problem becomes more complex when those two pieces of text are in different languages. Here, we introduce X-PARADE (Cross-lingual Paragraph-level Analysis of Divergences and Entailments), the first cross-lingual dataset of paragraph-level information divergences. Annotators label a paragraph in a target language at the span level and evaluate it with respect to a corresponding paragraph in a source language, indicating whether a given piece of information is the same, new, or new but can be inferred. This last notion establishes a link with cross-language NLI. Aligned paragraphs are sourced from Wikipedia pages in different languages, reflecting real information divergences observed in the wild. Armed with our dataset, we investigate a diverse set of approaches for this problem, including classic token alignment from machine 
    
[^5]: PDFTriage: 对长篇结构化文档进行问答

    PDFTriage: Question Answering over Long, Structured Documents. (arXiv:2309.08872v1 [cs.CL])

    [http://arxiv.org/abs/2309.08872](http://arxiv.org/abs/2309.08872)

    PDFTriage是一种处理长篇结构化文档问答的方法，通过使用结构或内容来检索上下文，解决了大型语言模型在问答中遇到的问题。

    

    大型语言模型在处理长篇文档的问答时存在问题，因为文档无法适应语言模型的上下文长度限制。为了解决这个问题，现有的大多数方法集中于从文档中检索相关的上下文，并将其表示为纯文本。然而，像PDF、网页和演示文稿这样的文档是有结构的，包括不同的页码、表格、章节等。将这样的结构化文档表示为纯文本与用户对这些具有丰富结构的文档的认知模型不符。当系统需要从文档中查询上下文时，这种不符会显现出来，甚至简单的问题也可能使问答系统出错。为了弥合处理结构化文档中的基本差距，我们提出了一种名为PDFTriage的方法，使模型能够根据结构或内容检索上下文。我们的实验证明了所提出的PDFTriage的有效性。

    Large Language Models (LLMs) have issues with document question answering (QA) in situations where the document is unable to fit in the small context length of an LLM. To overcome this issue, most existing works focus on retrieving the relevant context from the document, representing them as plain text. However, documents such as PDFs, web pages, and presentations are naturally structured with different pages, tables, sections, and so on. Representing such structured documents as plain text is incongruous with the user's mental model of these documents with rich structure. When a system has to query the document for context, this incongruity is brought to the fore, and seemingly trivial questions can trip up the QA system. To bridge this fundamental gap in handling structured documents, we propose an approach called PDFTriage that enables models to retrieve the context based on either structure or content. Our experiments demonstrate the effectiveness of the proposed PDFTriage-augmente
    
[^6]: MHLAT: 自动ICD编码的多跳标签关注模型

    MHLAT: Multi-hop Label-wise Attention Model for Automatic ICD Coding. (arXiv:2309.08868v1 [cs.CL])

    [http://arxiv.org/abs/2309.08868](http://arxiv.org/abs/2309.08868)

    我们提出了一种名为MHLAT的简单但有效的模型，利用多跳标签关注来提供更准确和丰富的表示。实验结果表明，我们的方法在所有七个度量标准上都实现了明显更好或有竞争力的性能，并且需要优化的参数更少。

    

    国际疾病分类（ICD）编码是将ICD诊断代码分配给临床笔记的任务。鉴于大量的标签（近9000个）和庞大的文本（多达8000个标记），这可能是具有挑战性的。然而，与以前的研究中的单通读过程不同，人们倾向于再次阅读文本和标签定义以获得更自信的答案。此外，尽管预训练语言模型已被用于解决这些问题，但它们的内存使用量很大。为了解决上述问题，我们提出了一个简单但有效的模型，称为多跳标签关注（MHLAT），利用多跳标签关注来获取更准确和丰富的表示。对三个基准MIMIC数据集的广泛实验表明，我们的方法在所有七个度量标准上实现了明显更好或有竞争力的性能，并且需要优化的参数更少。

    International Classification of Diseases (ICD) coding is the task of assigning ICD diagnosis codes to clinical notes. This can be challenging given the large quantity of labels (nearly 9,000) and lengthy texts (up to 8,000 tokens). However, unlike the single-pass reading process in previous works, humans tend to read the text and label definitions again to get more confident answers. Moreover, although pretrained language models have been used to address these problems, they suffer from huge memory usage. To address the above problems, we propose a simple but effective model called the Multi-Hop Label-wise ATtention (MHLAT), in which multi-hop label-wise attention is deployed to get more precise and informative representations. Extensive experiments on three benchmark MIMIC datasets indicate that our method achieves significantly better or competitive performance on all seven metrics, with much fewer parameters to optimize.
    
[^7]: 疫情前后情绪水平是否恢复到疫情前的水平？使用美国大学Subreddit数据进行情绪分析（arXiv:2309.08845v1 [cs.CL]）

    Has Sentiment Returned to the Pre-pandemic Level? A Sentiment Analysis Using U.S. College Subreddit Data from 2019 to 2022. (arXiv:2309.08845v1 [cs.CL])

    [http://arxiv.org/abs/2309.08845](http://arxiv.org/abs/2309.08845)

    本研究分析了使用美国大学Subreddit数据从疫情前到疫情期间再到后紧急期的人们的情绪变化，探讨了情绪是否已恢复到疫情前的水平。

    

    随着COVID-19疫情的减退，个人和社会逐渐恢复到疫情前的活动。本研究旨在探究人们的情绪从疫情前到疫情期间再到后紧急期的变化，并确定是否恢复到疫情前的水平。我们收集了2019年（疫情前）、2020年（疫情高峰期）、2021年和2022年（疫情后期，过渡期到后紧急期）来自128个美国大学Subreddits的Reddit数据以及一组学校级特征。我们采用预训练的RoBERTa（Robustly Optimized BERT pre-training approach）和图注意力网络（GAT）来预测两组情绪，并应用逻辑堆叠方法获得最终的情绪分类。在获得每条消息的情绪标签后，我们使用广义线性混合效应模型来估计时间趋势。

    As impact of COVID-19 pandemic winds down, both individuals and society gradually return to pre-pandemic activities. This study aims to explore how people's emotions have changed from the pre-pandemic during the pandemic to post-emergency period and whether it has returned to pre-pandemic level. We collected Reddit data in 2019 (pre-pandemic), 2020 (peak pandemic), 2021, and 2022 (late stages of pandemic, transitioning period to post-emergency period) from subreddits in 128 universities/colleges in the U.S., and a set of school-level characteristics. We predicted two sets of sentiments from a pre-trained Robustly Optimized BERT pre-training approach (RoBERTa) and graph attention network (GAT) that leverages both rich semantic and relational information among posted messages and then applied a logistic stacking method to obtain the final sentiment classification. After obtaining sentiment label for each message, we used a generalized linear mixed-effects model to estimate temporal trend
    
[^8]: 聊天机器人中的偏见和公平性: 一种概述

    Bias and Fairness in Chatbots: An Overview. (arXiv:2309.08836v1 [cs.CL])

    [http://arxiv.org/abs/2309.08836](http://arxiv.org/abs/2309.08836)

    这篇论文概述了现代聊天机器人设计中的偏见和公平性问题，并介绍了聊天机器人的历史、偏见来源和公平性保护方面的考虑因素。

    

    聊天机器人已经研究了半个多世纪。随着近年来自然语言处理技术的快速发展，使用大型语言模型的聊天机器人现在备受关注。与传统的聊天机器人相比，现代聊天机器人更强大，并已在实际应用中使用。然而，在现代聊天机器人设计中存在偏见和公平性问题。由于训练数据量巨大、模型规模庞大且缺乏可解释性，现代聊天机器人的偏见缓解和公平保护具有挑战性。因此，本文对聊天机器人系统中的偏见和公平性进行了全面概述。首先回顾了聊天机器人的历史和类别。然后，分析了应用中的偏见来源和潜在危害。研究了设计公平和无偏的聊天机器人系统的考虑因素。最后，讨论了未来的研究方向。

    Chatbots have been studied for more than half a century. With the rapid development of natural language processing (NLP) technologies in recent years, chatbots using large language models (LLMs) have received much attention nowadays. Compared with traditional ones, modern chatbots are more powerful and have been used in real-world applications. There are however, bias and fairness concerns in modern chatbot design. Due to the huge amounts of training data, extremely large model sizes, and lack of interpretability, bias mitigation and fairness preservation of modern chatbots are challenging. Thus, a comprehensive overview on bias and fairness in chatbot systems is given in this paper. The history of chatbots and their categories are first reviewed. Then, bias sources and potential harms in applications are analyzed. Considerations in designing fair and unbiased chatbot systems are examined. Finally, future research directions are discussed.
    
[^9]: SLIDE: 使用滑动文档窗口进行无参考机器翻译评估

    SLIDE: Reference-free Evaluation for Machine Translation using a Sliding Document Window. (arXiv:2309.08832v1 [cs.CL])

    [http://arxiv.org/abs/2309.08832](http://arxiv.org/abs/2309.08832)

    本论文提出了一种名为SLIDE的度量方法，通过使用滑动文档窗口来评估机器翻译质量，该方法在某些情况下甚至能消除与参考度量之间的差距，表明源语言上下文可能提供了与人类参考相同的信息。

    

    基于参考的度量通常在句子级别上优于仅能访问源语言和系统输出的质量估计度量。这并不奇怪，因为参考能够消除源语言中可能存在的歧义。我们研究了是否可以用额外的源语言上下文有效地替代参考。我们提出了一种度量方法，SLIDE（SLiding Document Evaluator），它通过一个滑动窗口在每个测试集中的文档上操作，将每个块输入到未修改的现成质量估计模型中。我们发现，SLIDE在系统准确性的成对比较上较句子级别基线显著提高，有些情况下甚至消除了与参考度量之间的差距。这表明源语言上下文可能提供了与人类参考相同的信息。

    Reference-based metrics that operate at the sentence level typically outperform quality estimation metrics, which have access only to the source and system output. This is unsurprising, since references resolve ambiguities that may be present in the source. We investigate whether additional source context can effectively substitute for a reference. We present a metric, SLIDE (SLiding Document Evaluator), which operates on blocks of sentences using a window that slides over each document in the test set, feeding each chunk into an unmodified, off-the-shelf quality estimation model. We find that SLIDE obtains significantly higher pairwise system accuracy than its sentence-level baseline, in some cases even eliminating the gap with reference-base metrics. This suggests that source context may provide the same information as a human reference.
    
[^10]: S3-DST: 基于LLM的结构化开放域对话分段和状态跟踪

    S3-DST: Structured Open-Domain Dialogue Segmentation and State Tracking in the Era of LLMs. (arXiv:2309.08827v1 [cs.CL])

    [http://arxiv.org/abs/2309.08827](http://arxiv.org/abs/2309.08827)

    S3-DST是基于LLM的开放域对话中结构化的对话分段和状态跟踪方法，利用Pre-Analytical Recollection机制提高长上下文跟踪。

    

    传统的对话状态跟踪 (DST) 问题旨在追踪用户在用户-代理对话中的偏好和意图。尽管对于支持狭义领域应用的任务导向性对话系统来说已经足够，但基于大型语言模型 (LLM) 的聊天系统的出现引入了许多开放域对话中的现实复杂性。这些复杂性体现在上下文交互的增加复杂性、涵盖各种主题的延长对话会话以及更频繁的上下文转变等形式。为了处理基于演变的LLM聊天系统引起的这些复杂性，我们提出了在开放域对话系统中对每个段进行联合对话分割和状态跟踪。在适合真正的开放域对话系统的零-shot设置下，我们提出了S3-DST，这是一种结构化提示技术，利用了我们为提高长上下文跟踪而设计的一种新的接地机制 - Pre-Analytical Recollection。

    The traditional Dialogue State Tracking (DST) problem aims to track user preferences and intents in user-agent conversations. While sufficient for task-oriented dialogue systems supporting narrow domain applications, the advent of Large Language Model (LLM)-based chat systems has introduced many real-world intricacies in open-domain dialogues. These intricacies manifest in the form of increased complexity in contextual interactions, extended dialogue sessions encompassing a diverse array of topics, and more frequent contextual shifts. To handle these intricacies arising from evolving LLM-based chat systems, we propose joint dialogue segmentation and state tracking per segment in open-domain dialogue systems. Assuming a zero-shot setting appropriate to a true open-domain dialogue system, we propose S3-DST, a structured prompting technique that harnesses Pre-Analytical Recollection, a novel grounding mechanism we designed for improving long context tracking. To demonstrate the efficacy o
    
[^11]: 自训练在情感分析中的实例选择策略的实证研究

    An Empirical Study on Instance Selection Strategies in Self-training for Sentiment Analysis. (arXiv:2309.08777v1 [cs.CL])

    [http://arxiv.org/abs/2309.08777](http://arxiv.org/abs/2309.08777)

    本文对自训练在情感分析中的实例选择策略进行了实证研究，研究了策略和超参数对自训练性能的影响。

    

    情感分析是自然语言处理中的一个关键任务，涉及从文本中识别和提取主观情感。最近，通过利用少量标记数据和大量未标记数据，自训练已经成为一种经济高效的技术，用于开发情感分析模型。然而，自训练过程的性能严重依赖于实例选择策略的选择，而这方面的研究还不够充分。本文对自训练的各种实例选择策略在两个公开情感数据集上进行了实证研究，并研究了策略和超参数在各种少样本设置下对自训练性能的影响。

    Sentiment analysis is a crucial task in natural language processing that involves identifying and extracting subjective sentiment from text. Self-training has recently emerged as an economical and efficient technique for developing sentiment analysis models by leveraging a small amount of labeled data and a larger amount of unlabeled data. However, the performance of a self-training procedure heavily relies on the choice of the instance selection strategy, which has not been studied thoroughly. This paper presents an empirical study on various instance selection strategies for self-training on two public sentiment datasets, and investigates the influence of the strategy and hyper-parameters on the performance of self-training in various few-shot settings.
    
[^12]: AlbNER：一个用于阿尔巴尼亚命名实体识别的语料库

    AlbNER: A Corpus for Named Entity Recognition in Albanian. (arXiv:2309.08741v1 [cs.CL])

    [http://arxiv.org/abs/2309.08741](http://arxiv.org/abs/2309.08741)

    本文介绍了一个用于阿尔巴尼亚命名实体识别的语料库AlbNER，该语料库由阿尔巴尼亚维基百科文章中收集的900个带有标记命名实体的句子组成。初步结果表明，模型大小对NER性能影响小，而语言迁移有着显著的影响。这些资源和结果为未来实验提供了基线。

    

    针对阿尔巴尼亚等资源匮乏的语言，如计算语言学和自然语言处理研究中存在着标注文本语料库的严重障碍。本文介绍了AlbNER，这是一个由阿尔巴尼亚维基百科文章中收集的900个带有标记命名实体的句子的语料库。用使用AlbNER数据进行细调和测试的BERT和RoBERTa变体的初步结果表明，模型大小对NER性能的影响很小，而语言迁移的影响很大。AlbNER语料库和这些结果应作为未来实验的基线。

    Scarcity of resources such as annotated text corpora for under-resourced languages like Albanian is a serious impediment in computational linguistics and natural language processing research. This paper presents AlbNER, a corpus of 900 sentences with labeled named entities, collected from Albanian Wikipedia articles. Preliminary results with BERT and RoBERTa variants fine-tuned and tested with AlbNER data indicate that model size has slight impact on NER performance, whereas language transfer has a significant one. AlbNER corpus and these obtained results should serve as baselines for future experiments.
    
[^13]: MusiLingo：利用预训练的语言模型将音乐和文本相结合，实现音乐字幕和查询响应

    MusiLingo: Bridging Music and Text with Pre-trained Language Models for Music Captioning and Query Response. (arXiv:2309.08730v1 [eess.AS])

    [http://arxiv.org/abs/2309.08730](http://arxiv.org/abs/2309.08730)

    MusiLingo是一个利用预训练的语言模型将音乐和文本相结合的系统，可以生成音乐字幕和回答音乐相关的查询。通过使用投影层对齐音乐表示，该系统成功地将音乐音频和文本环境联系起来，同时使用了一个新的数据集来推动领域的进展。

    

    大型语言模型（LLM）已经在多模态应用中展现出巨大潜力，然而文本和音乐领域的融合仍相对未被探索。为了解决这一问题，我们提出了MusiLingo，这是一个用于音乐字幕生成和音乐相关查询响应的新系统。MusiLingo使用一个投影层来对齐预训练的冻结音乐音频模型MERT和冻结的LLaMA语言模型的音乐表示，实现音乐音频和文本环境之间的桥梁。我们在一个大规模的音乐字幕数据集上进行训练，并使用指导性数据进行微调。由于高质量的音乐问答数据集稀缺，我们从MusicCaps创建了MusicInstruct（MI）数据集，专为开放式音乐查询而设计。实证评估证明了它在生成音乐字幕和组织音乐相关问答对方面的竞争性表现。我们引入的数据集在之前的数据集的基础上取得了显著进展。

    Large Language Models (LLMs) have shown immense potential in multimodal applications, yet the convergence of textual and musical domains remains relatively unexplored. To address this gap, we present MusiLingo, a novel system for music caption generation and music-related query responses. MusiLingo employs a single projection layer to align music representations from the pre-trained frozen music audio model MERT with the frozen LLaMA language model, bridging the gap between music audio and textual contexts. We train it on an extensive music caption dataset and fine-tune it with instructional data. Due to the scarcity of high-quality music Q&A datasets, we created the MusicInstruct (MI) dataset from MusicCaps, tailored for open-ended music inquiries. Empirical evaluations demonstrate its competitive performance in generating music captions and composing music-related Q&A pairs. Our introduced dataset enables notable advancements beyond previous ones.
    
[^14]: 使用图扩展文法生成语义图语料库

    Generating Semantic Graph Corpora with Graph Expansion Grammar. (arXiv:2309.08714v1 [cs.FL])

    [http://arxiv.org/abs/2309.08714](http://arxiv.org/abs/2309.08714)

    该论文介绍了一个名为Lovelace的工具，可以使用图扩展文法生成语义图的语料库。这项工具可以通过用户自定义的文法生成符合要求的良好形式的输出图，可以应用于合成数据增强语料库和教学形式语言理论的用途。

    

    我们介绍了一个名为Lovelace的工具，用于创建语义图的语料库。该系统使用图扩展文法作为表达语言，允许用户制定描述所需属性的文法来描述语料库。当将这样的文法作为输入时，系统将生成一组根据文法构造良好的输出图，即图库。生成过程可以通过多个可配置参数进行控制，例如，用户可以指定所需的输出图大小范围。核心用例是创建合成数据以扩充现有语料库，并作为教授形式语言理论的教学工具。

    We introduce Lovelace, a tool for creating corpora of semantic graphs. The system uses graph expansion grammar as a representational language, thus allowing users to craft a grammar that describes a corpus with desired properties. When given such grammar as input, the system generates a set of output graphs that are well-formed according to the grammar, i.e., a graph bank. The generation process can be controlled via a number of configurable parameters that allow the user to, for example, specify a range of desired output graph sizes. Central use cases are the creation of synthetic data to augment existing corpora, and as a pedagogical tool for teaching formal language theory.
    
[^15]: 经由动态嵌入剪枝实现的预训练语言模型的令人沮丧地简单的内存效率

    Frustratingly Simple Memory Efficiency for Pre-trained Language Models via Dynamic Embedding Pruning. (arXiv:2309.08708v1 [cs.CL])

    [http://arxiv.org/abs/2309.08708](http://arxiv.org/abs/2309.08708)

    该论文提出了一种简单但有效的方法，通过动态嵌入剪枝来减小预训练语言模型的内存占用。该方法在各种模型和任务中都能显著降低内存使用量，同时保持相当的下游任务性能，实现更高效地利用计算资源。

    

    预训练语言模型（PLMs）的广泛内存占用会阻碍其在内存受限环境（如云环境或设备上）的部署。 PLMs使用嵌入矩阵来表示广泛的词汇，构成了模型参数的大部分。尽管之前的工作已经考虑了在Transformer层内剪枝参数以提高参数效率，但在微调或推理过程中剪枝嵌入矩阵尚未被探索。我们首先证明了在这些情况下有一个显著比例的词汇未被使用。然后，我们提出了一个简单而有效的方法，利用这一发现来最小化嵌入矩阵的内存占用。我们展示了这种方法在各种模型和任务中都能显著降低内存使用量。值得注意的是，我们的方法在保持下游任务性能的同时允许更高效地使用计算资源。

    The extensive memory footprint of pre-trained language models (PLMs) can hinder deployment in memory-constrained settings, such as cloud environments or on-device. PLMs use embedding matrices to represent extensive vocabularies, forming a large proportion of the model parameters. While previous work towards parameter-efficient PLM development has considered pruning parameters within the transformer layers, pruning the embedding matrix as part of fine-tuning or inference has yet to be explored. We first demonstrate that a significant proportion of the vocabulary remains unused in these scenarios. We then propose a simple yet effective approach that leverages this finding to minimize the memory footprint of the embedding matrix. We show that this approach provides substantial reductions in memory usage across a wide range of models and tasks. Notably, our approach maintains equivalent downstream task performance while allowing a more efficient use of compute resources.
    
[^16]: 解决法律术语：法律文件中否定范围解析的多语言探索

    Resolving Legalese: A Multilingual Exploration of Negation Scope Resolution in Legal Documents. (arXiv:2309.08695v1 [cs.CL])

    [http://arxiv.org/abs/2309.08695](http://arxiv.org/abs/2309.08695)

    本研究通过多语言探索，解决了法律文件中否定范围解析的挑战。实验结果表明，以往模型在处理多语言法律数据时表现不佳，因此我们发布了一套新的法庭判决标注数据用于改进解析效果，并取得了高达86.7％的标记级F1分。

    

    在句子中解析否定的范围是一项具有挑战性的自然语言处理任务。法律文本的复杂性以及缺乏经过注释的领域内否定语料库给最先进的模型在处理多语言法律数据上的否定范围解析时带来了挑战。我们的实验表明，预先未使用法律数据进行训练的模型在否定范围解析任务中表现不佳。我们的实验使用仅在文学文本和医学数据等领域进行了精细调整的语言模型，与之前的跨领域实验中记录的结果相比，效果较差。我们发布了一套德语、法语和意大利语的标注法院判决，并将其用于改进零摄取和多语言环境下的否定范围解析。在我们的零摄取跨语言实验中，我们的标记级F1分达到了86.7％，其中模型在我们的法律数据集的两种语言上进行训练，并在第三种语言上进行评估。

    Resolving the scope of a negation within a sentence is a challenging NLP task. The complexity of legal texts and the lack of annotated in-domain negation corpora pose challenges for state-of-the-art (SotA) models when performing negation scope resolution on multilingual legal data. Our experiments demonstrate that models pre-trained without legal data underperform in the task of negation scope resolution. Our experiments, using language models exclusively fine-tuned on domains like literary texts and medical data, yield inferior results compared to the outcomes documented in prior cross-domain experiments. We release a new set of annotated court decisions in German, French, and Italian and use it to improve negation scope resolution in both zero-shot and multilingual settings. We achieve token-level F1-scores of up to 86.7% in our zero-shot cross-lingual experiments, where the models are trained on two languages of our legal datasets and evaluated on the third. Our multilingual experim
    
[^17]: 假新闻检测器对大型语言模型生成的文本存在偏见

    Fake News Detectors are Biased against Texts Generated by Large Language Models. (arXiv:2309.08674v1 [cs.CL])

    [http://arxiv.org/abs/2309.08674](http://arxiv.org/abs/2309.08674)

    假新闻检测器倾向于将大型语言模型生成的内容标记为假新闻，而将人工编写的假新闻误分类为真实，我们提出了一种通过敌对训练和LLM改写的真实新闻等方法来解决这个问题，并取得了显著的改进。

    

    假新闻的传播已经成为一个重要挑战，损害了信任并对社会构成威胁。在大型语言模型（LLM）的时代，生成可信的假内容的能力加剧了这些担忧。在本研究中，我们提出了一种新的范式来评估在涉及人工编写和LLM生成的错误信息的情况下的假新闻检测器。有趣的是，我们的发现揭示了许多现有检测器存在显著的偏见：它们更容易将LLM生成的内容标记为假新闻，同时常常将人工编写的假新闻误分类为真实。这种意外的偏见似乎源自LLM输出固有的不同语言模式。为了解决这个问题，我们引入了一种使用LLM改写的真实新闻进行敌对训练的缓解策略。结果模型在人工和LLM生成的新闻的检测准确性方面均有显著提升。为了进一步促进这个领域的研究，我们发布了两个全面的...

    The spread of fake news has emerged as a critical challenge, undermining trust and posing threats to society. In the era of Large Language Models (LLMs), the capability to generate believable fake content has intensified these concerns. In this study, we present a novel paradigm to evaluate fake news detectors in scenarios involving both human-written and LLM-generated misinformation. Intriguingly, our findings reveal a significant bias in many existing detectors: they are more prone to flagging LLM-generated content as fake news while often misclassifying human-written fake news as genuine. This unexpected bias appears to arise from distinct linguistic patterns inherent to LLM outputs. To address this, we introduce a mitigation strategy that leverages adversarial training with LLM-paraphrased genuine news. The resulting model yielded marked improvements in detection accuracy for both human and LLM-generated news. To further catalyze research in this domain, we release two comprehensiv
    
[^18]: 对包含实体交换的表格进行的对抗攻击

    Adversarial Attacks on Tables with Entity Swap. (arXiv:2309.08650v1 [cs.CL])

    [http://arxiv.org/abs/2309.08650](http://arxiv.org/abs/2309.08650)

    本论文研究了对包含实体交换的表格进行的对抗攻击。作者提出了一种针对列类型注释任务的逃避性实体交换攻击，通过采用基于相似度的采样策略生成对抗性示例，成功导致性能下降了高达70%。

    

    大型语言模型(LLMs)的能力已成功应用于表格表示学习的环境中。最近提出的表格语言模型在表格解释的各种任务上报告了最先进的结果。然而，对常用于评估的数据集进行仔细观察发现，训练集中的实体泄漏至测试集中。基于这一观察，我们探索了一种更真实的推理设置的对抗攻击。已经证明，对文本的对抗攻击极大地影响了LLMs的性能，但目前尚无攻击针对表格语言模型。在本文中，我们提出了一种针对列类型注释(CTA)任务的逃避性实体交换攻击。我们的CTA攻击是对表格的第一次黑盒攻击，我们采用基于相似度的采样策略生成对抗性示例。实验结果显示，所提出的攻击导致性能下降了高达70%。

    The capabilities of large language models (LLMs) have been successfully applied in the context of table representation learning. The recently proposed tabular language models have reported state-of-the-art results across various tasks for table interpretation. However, a closer look into the datasets commonly used for evaluation reveals an entity leakage from the train set into the test set. Motivated by this observation, we explore adversarial attacks that represent a more realistic inference setup. Adversarial attacks on text have been shown to greatly affect the performance of LLMs, but currently, there are no attacks targeting tabular language models. In this paper, we propose an evasive entity-swap attack for the column type annotation (CTA) task. Our CTA attack is the first black-box attack on tables, where we employ a similarity-based sampling strategy to generate adversarial examples. The experimental results show that the proposed attack generates up to a 70% drop in performan
    
[^19]: MAPLE: 基于大型语言模型嵌入的移动应用预测

    MAPLE: Mobile App Prediction Leveraging Large Language model Embeddings. (arXiv:2309.08648v1 [cs.CL])

    [http://arxiv.org/abs/2309.08648](http://arxiv.org/abs/2309.08648)

    MAPLE是一个利用大型语言模型嵌入进行移动应用预测的模型，通过严格测试验证了其在解密复杂模式和理解用户环境方面的能力，并强调了语言模型在不同领域中的广泛适用性。

    

    尽管移动应用的发展迅速，但由于复杂的用户行为和不断演变的环境，预测应用的使用仍然是一个严峻的挑战。为了解决这些问题，本文介绍了Mobile App Prediction Leveraging Large Language Model Embeddings (MAPLE)模型。这种创新的方法利用大型语言模型(LLM)来准确预测应用的使用情况。通过对两个公开数据集进行严格测试，MAPLE的能力在解密复杂模式和理解用户环境方面得到了验证。这些强大的结果证实了MAPLE在不同场景中的多功能性和弹性。尽管其主要设计面向应用预测，但结果也强调了LLM在不同领域中的广泛适用性。通过这项研究，我们强调了LLM在应用使用预测中的潜力，并建议在建模各种领域中的人类行为方面，它们具有变革能力。

    Despite the rapid advancement of mobile applications, predicting app usage remains a formidable challenge due to intricate user behaviours and ever-evolving contexts. To address these issues, this paper introduces the Mobile App Prediction Leveraging Large Language Model Embeddings (MAPLE) model. This innovative approach utilizes Large Language Models (LLMs) to predict app usage accurately. Rigorous testing on two public datasets highlights MAPLE's capability to decipher intricate patterns and comprehend user contexts. These robust results confirm MAPLE's versatility and resilience across various scenarios. While its primary design caters to app prediction, the outcomes also emphasize the broader applicability of LLMs in different domains. Through this research, we emphasize the potential of LLMs in app usage prediction and suggest their transformative capacity in modelling human behaviours across diverse fields.
    
[^20]: 在规模上进行意图检测：利用相关意图进行通用模型调优

    Intent Detection at Scale: Tuning a Generic Model using Relevant Intents. (arXiv:2309.08647v1 [cs.CL])

    [http://arxiv.org/abs/2309.08647](http://arxiv.org/abs/2309.08647)

    本研究提出了一种有效的方法，通过将通用模型与每个客户的相关意图列表相结合，将意图检测扩展到不同的客户。这种方法减少了培训和维护成本，同时为客户提供个性化体验，并在生产环境中展现出卓越的性能。

    

    准确预测客户支持请求的意图对于高效的支持系统至关重要，使代理人能够快速理解信息并优先响应。尽管存在不同的意图检测方法，但是随着客户群体的扩大，维护单独的客户特定或行业特定模型可能成本高昂且不切实际。本文提出了一种有效地将意图预测扩展到各种客户的系统，即通过将单一通用模型与每个客户的相关意图列表相结合。我们的方法最大限度地减少了培训和维护成本，同时为客户提供个性化体验，实现对其相关意图的变化的无缝适应。此外，我们提出了一种使用客户相关意图作为模型特征的策略，该策略在生产环境中对客户相关意图的变化具有韧性。最终系统的性能明显优于其他方法。

    Accurately predicting the intent of customer support requests is vital for efficient support systems, enabling agents to quickly understand messages and prioritize responses accordingly. While different approaches exist for intent detection, maintaining separate client-specific or industry-specific models can be costly and impractical as the client base expands.  This work proposes a system to scale intent predictions to various clients effectively, by combining a single generic model with a per-client list of relevant intents. Our approach minimizes training and maintenance costs while providing a personalized experience for clients, allowing for seamless adaptation to changes in their relevant intents. Furthermore, we propose a strategy for using the clients relevant intents as model features that proves to be resilient to changes in the relevant intents of clients -- a common occurrence in production environments.  The final system exhibits significantly superior performance compare
    
[^21]: 通过共线约束注意力解决Transformer的头痛问题

    Cure the headache of Transformers via Collinear Constrained Attention. (arXiv:2309.08646v1 [cs.LG])

    [http://arxiv.org/abs/2309.08646](http://arxiv.org/abs/2309.08646)

    通过引入共线约束注意力（CoCA）结构，解决Transformer模型中的头痛问题，实现了出色的外推性能和提高的计算效率。

    

    随着基于大型语言模型的实际应用的快速进展，推断性能的外推变得在研究领域中变得越来越重要。在我们的研究中，我们发现了Transformer模型中的一个被之前忽视的异常行为，导致了最接近的标记之间的混乱，这些标记携带了最重要的信息。我们将这一发现称为“Transformer的头痛问题”。为了从根本上解决这个问题，我们引入了一种新的自注意结构，命名为Collinear Constrained Attention（CoCA）。这个结构可以无缝地与现有的推断、插值方法和其他针对传统Transformer模型设计的优化策略集成。我们在推断过程中实现了优秀的外推性能，即使是16到24倍的序列长度，而且没有对我们的模型进行任何微调。我们还增强了CoCA的计算和空间效率，以确保其实用性。我们计划...

    As the rapid progression of practical applications based on Large Language Models continues, the importance of extrapolating performance has grown exponentially in the research domain. In our study, we identified an anomalous behavior in Transformer models that had been previously overlooked, leading to a chaos around closest tokens which carried the most important information. We've coined this discovery the "headache of Transformers". To address this at its core, we introduced a novel self-attention structure named Collinear Constrained Attention (CoCA). This structure can be seamlessly integrated with existing extrapolation, interpolation methods, and other optimization strategies designed for traditional Transformer models. We have achieved excellent extrapolating performance even for 16 times to 24 times of sequence lengths during inference without any fine-tuning on our model. We have also enhanced CoCA's computational and spatial efficiency to ensure its practicality. We plan to
    
[^22]: 锚点：用更少的示例对模型进行基准测试

    Anchor Points: Benchmarking Models with Much Fewer Examples. (arXiv:2309.08638v1 [cs.CL])

    [http://arxiv.org/abs/2309.08638](http://arxiv.org/abs/2309.08638)

    这个论文介绍了一种使用更少的示例来对模型进行基准测试的方法，并提出了锚点选择技术来捕捉模型行为。实验证明，使用锚点对模型进行排序比使用均匀采样和其他基线方法更准确。仅使用几个锚点就可以估计模型对数据集中所有其他点的每个类别的预测，用于衡量模型性能。

    

    现代语言模型通常表现出强大但脆弱的行为，因此开发出更大、更多样化的基准来可靠地评估它们的行为。在这里，我们建议可以使用更小的评估集对模型性能进行基准测试和阐明。我们首先展示了在六个流行语言分类基准中，模型对许多点对的正确类别的置信度在各个模型之间具有强相关性。我们在此现象基础上提出了锚点选择技术，该技术可以选择捕捉整个数据集上的模型行为的小子集。锚点可靠地对模型进行排序：在87个不同的语言模型-提示对上，使用1-30个锚点评估模型在准确排序模型方面优于均匀采样和其他基线方法。此外，只需要几个锚点就可以用较低的平均绝对误差估计出模型对数据集中所有其他点的每个类别的预测，足以衡量模型在哪些方面表现得如何。

    Modern language models often exhibit powerful but brittle behavior, leading to the development of larger and more diverse benchmarks to reliably assess their behavior. Here, we suggest that model performance can be benchmarked and elucidated with much smaller evaluation sets. We first show that in six popular language classification benchmarks, model confidence in the correct class on many pairs of points is strongly correlated across models. We build upon this phenomenon to propose Anchor Point Selection, a technique to select small subsets of datasets that capture model behavior across the entire dataset. Anchor points reliably rank models: across 87 diverse language model-prompt pairs, evaluating models using 1-30 anchor points outperforms uniform sampling and other baselines at accurately ranking models. Moreover, just several anchor points can be used to estimate model per-class predictions on all other points in a dataset with low mean absolute error, sufficient for gauging where
    
[^23]: TextBind: 多轮交错多模态指令跟随

    TextBind: Multi-turn Interleaved Multimodal Instruction-following. (arXiv:2309.08637v1 [cs.CL])

    [http://arxiv.org/abs/2309.08637](http://arxiv.org/abs/2309.08637)

    TextBind是一个注释极少的框架，用于将较大规模的语言模型赋予多轮交错多模态指令跟随能力，并通过图像-标题对生成多轮多模态指令-回应对话。这个框架对于解决实际任务具有重要意义，并为未来的研究提供了数据集、模型和演示。

    

    具有指令跟随能力的大型语言模型已经在人工智能领域产生了革命性的影响。这些模型通过其自然语言界面展示了卓越的泛化能力，可以解决各种实际任务。然而，它们的性能在很大程度上依赖于高质量的示例数据，而这往往很难获得。当涉及到多模态指令跟随时，这个挑战变得更加严峻。我们引入了TextBind，这是一个几乎不需要注释的框架，用于赋予较大规模的语言模型多轮交错多模态指令跟随能力。我们的方法仅需要图像-标题对，并从语言模型生成多轮多模态指令-回应对话。我们发布了我们的数据集、模型和演示，以促进未来在多模态指令跟随领域的研究。

    Large language models with instruction-following abilities have revolutionized the field of artificial intelligence. These models show exceptional generalizability to tackle various real-world tasks through their natural language interfaces. However, their performance heavily relies on high-quality exemplar data, which is often difficult to obtain. This challenge is further exacerbated when it comes to multimodal instruction following. We introduce TextBind, an almost annotation-free framework for empowering larger language models with the multi-turn interleaved multimodal instruction-following capabilities. Our approach requires only image-caption pairs and generates multi-turn multimodal instruction-response conversations from a language model. We release our dataset, model, and demo to foster future research in the area of multimodal instruction following.
    
[^24]: ChatGPT v Bard v Bing v Claude 2 v Aria v human-expert. AI聊天机器人在科学写作方面表现如何？（第23季第3季）。（arXiv:2309.08636v1 [cs.CL]）

    ChatGPT v Bard v Bing v Claude 2 v Aria v human-expert. How good are AI chatbots at scientific writing? (ver. 23Q3). (arXiv:2309.08636v1 [cs.CL])

    [http://arxiv.org/abs/2309.08636](http://arxiv.org/abs/2309.08636)

    本文综合分析了在人文学科和考古学领域中六个AI聊天机器人在学术写作方面的能力和局限性，发现它们在重新组合现有知识方面表现出色，但在产生原创科学内容方面存在问题。

    

    在历史上，熟练的写作被认为是人类进步的关键，创造性表达被视为人类成就的标志之一。然而，生成式AI的最新进展标志着这一叙事的一个转折点，包括在科学写作方面。本文全面分析了六个AI聊天机器人在人文学科和考古学方面学术写作中的能力和局限性。方法基于由人类专家对AI生成内容进行定量准确性和定性精确性标记。定量准确性评估了事实的正确性，而定性精确性评估了科学贡献。虽然AI聊天机器人，特别是ChatGPT-4，在重新组合现有知识方面表现出熟练性，但在生成原创科学内容方面失败了。顺便提一下，我们的结果还显示，随着ChatGPT-4，语言模型大小已经停滞不前。此外，本文强调了复杂且反复无常的生成过程。

    Historically, proficient writing was deemed essential for human advancement, with creative expression viewed as one of the hallmarks of human achievement. However, recent advances in generative AI have marked an inflection point in this narrative, including for scientific writing. This article provides a comprehensive analysis of the capabilities and limitations of six AI chatbots in scholarly writing in the humanities and archaeology. The methodology was based on tagging AI generated content for quantitative accuracy and qualitative precision by human experts. Quantitative accuracy assessed the factual correctness, while qualitative precision gauged the scientific contribution. While the AI chatbots, especially ChatGPT-4, demonstrated proficiency in recombining existing knowledge, they failed in generating original scientific content. As a side note, our results also suggest that with ChatGPT-4 the size of the LLMs has plateaued. Furthermore, the paper underscores the intricate and re
    
[^25]: 在测试集上进行预训练就足够了

    Pretraining on the Test Set Is All You Need. (arXiv:2309.08632v1 [cs.CL])

    [http://arxiv.org/abs/2309.08632](http://arxiv.org/abs/2309.08632)

    这项研究通过在测试集上进行预训练，使用精心构建的非合成数据混合，成功开发出一个在多个学术基准测试上表现出色的Transformer语言模型phi-CTNL。

    

    受到最近有关使用小型Transformer语言模型在经过精心策划的数据上进行预训练的潜力展示的工作的启发，我们通过大量精心构建仅基于评估基准的新颖高质量的非合成数据混合来加强这种方法。使用我们的新颖数据集混合，其中包含不到10万个token，我们预训练了一个拥有100万参数的基于Transformer的LLM模型phi-CTNL（读作“fictional”），在各种学术基准测试中取得了完美的结果，严格超越了所有已知的基准模型。phi-CTNL还超越了幂律缩放，并展现出前所未见的类似grokking的能力，准确预测下游评估基准的canaries。

    Inspired by recent work demonstrating the promise of smaller Transformer-based language models pretrained on carefully curated data, we supercharge such approaches by investing heavily in curating a novel, high quality, non-synthetic data mixture based solely on evaluation benchmarks. Using our novel dataset mixture consisting of less than 100 thousand tokens, we pretrain a 1 million parameter transformer-based LLM \textbf{phi-CTNL} (pronounced ``fictional") that achieves perfect results across diverse academic benchmarks, strictly outperforming all known foundation models. \textbf{phi-CTNL} also beats power-law scaling and exhibits a never-before-seen grokking-like ability to accurately predict downstream evaluation benchmarks' canaries.
    
[^26]: 大型语言模型能够推断社交媒体用户的心理倾向

    Large Language Models Can Infer Psychological Dispositions of Social Media Users. (arXiv:2309.08631v1 [cs.CL])

    [http://arxiv.org/abs/2309.08631](http://arxiv.org/abs/2309.08631)

    大型语言模型能够通过分析社交媒体用户的数字足迹推断他们的心理倾向，具体表现为从Facebook状态更新中推断五大人格特质。研究发现，推断得分与自我报告得分之间存在相关性，但在性别和年龄方面存在偏见。

    

    随着大型语言模型（LLMs）在各种自然语言处理（NLP）任务中展示出越来越接近人类的能力，而这些任务将成为个性化技术的重要组成部分，理解它们的能力和固有偏见至关重要。我们的研究调查了类似ChatGPT的LLMs从个人数字足迹中推断个人心理倾向的潜力。具体而言，我们评估了GPT-3.5和GPT-4在零样本学习场景下从用户的Facebook状态更新中推导出五大人格特质的能力。我们的结果显示LLM推断与自我报告得分之间的平均相关性为r = 0.29（范围为[0.22, 0.33]）。此外，我们的研究结果表明在性别和年龄方面存在个性推断的偏见：对于几个特质，推断得分在女性和年轻人中的误差较小，这表明可能存在来自底层训练数据或在线自我呈现的差异的系统性偏见。

    As Large Language Models (LLMs) demonstrate increasingly human-like abilities in various natural language processing (NLP) tasks that are bound to become integral to personalized technologies, understanding their capabilities and inherent biases is crucial. Our study investigates the potential of LLMs like ChatGPT to infer psychological dispositions of individuals from their digital footprints. Specifically, we assess the ability of GPT-3.5 and GPT-4 to derive the Big Five personality traits from users' Facebook status updates in a zero-shot learning scenario. Our results show an average correlation of r = .29 (range = [.22, .33]) between LLM-inferred and self-reported trait scores. Furthermore, our findings suggest biases in personality inferences with regard to gender and age: inferred scores demonstrated smaller errors for women and younger individuals on several traits, suggesting a potential systematic bias stemming from the underlying training data or differences in online self-e
    
[^27]: 通过大型语言模型进行隐私保护掩码的恢复

    Recovering from Privacy-Preserving Masking with Large Language Models. (arXiv:2309.08628v1 [cs.CL])

    [http://arxiv.org/abs/2309.08628](http://arxiv.org/abs/2309.08628)

    本文利用大型语言模型（LLM）探索了替换标识信息的方法，并在下游语言建模任务上进行了评估。实验结果表明，使用混淆语料库训练的模型能够达到可比较的性能。

    

    模型适应对于处理代理训练数据和实际用户数据之间的差异非常重要。为了有效地进行适应，用户的文本数据通常存储在服务器或本地设备上，下游的自然语言处理模型可以使用这些领域内的数据进行直接训练。然而，这可能会引起隐私和安全问题，因为存在向对手泄露用户信息的额外风险。最近，人们开始探索使用通用标记替换文本中的标识信息。在这项工作中，我们利用大型语言模型（LLM）来建议替换掩码标记的方法，并在下游语言建模任务上评估其效果。具体而言，我们提出了多种基于预训练和微调的LLM方法，并在不同数据集上进行实证研究以比较这些方法。实验结果表明，在混淆语料库上训练的模型能够达到可比较的性能。

    Model adaptation is crucial to handle the discrepancy between proxy training data and actual users data received. To effectively perform adaptation, textual data of users is typically stored on servers or their local devices, where downstream natural language processing (NLP) models can be directly trained using such in-domain data. However, this might raise privacy and security concerns due to the extra risks of exposing user information to adversaries. Replacing identifying information in textual data with a generic marker has been recently explored. In this work, we leverage large language models (LLMs) to suggest substitutes of masked tokens and have their effectiveness evaluated on downstream language modeling tasks. Specifically, we propose multiple pre-trained and fine-tuned LLM-based approaches and perform empirical studies on various datasets for the comparison of these methods. Experimental results show that models trained on the obfuscation corpora are able to achieve compar
    
[^28]: 评估动态主题模型

    Evaluating Dynamic Topic Models. (arXiv:2309.08627v1 [cs.CL])

    [http://arxiv.org/abs/2309.08627](http://arxiv.org/abs/2309.08627)

    提出了一种评估动态主题模型的新方法，该方法分析了每个主题随时间变化的质量变化，并结合了模型的时间一致性。该方法在合成数据和已有DTMs数据上展示了实用性，并与人类判断具有良好的相关性。这些研究结果对于识别变化的主题、评估DTMs和指导未来研究具有重要意义。

    

    动态主题模型(DTMs)在评估主题随时间变化的进展方面缺乏定量指标。为了填补这一空白，我们提出了一种新颖的DTMs评估方法，该方法分析了每个主题随时间变化的质量变化。此外，我们还提出了结合主题质量和模型时间一致性的扩展方法。我们通过将该方法应用于合成数据和已有DTMs的数据来证明其实用性。我们还进行了人工评估，结果表明该方法与人类判断具有良好的相关性。我们的研究结果有助于识别变化的主题、评估不同的DTMs以及指导未来的研究领域。

    There is a lack of quantitative measures to evaluate the progression of topics through time in dynamic topic models (DTMs). Filling this gap, we propose a novel evaluation measure for DTMs that analyzes the changes in the quality of each topic over time. Additionally, we propose an extension combining topic quality with the model's temporal consistency. We demonstrate the utility of the proposed measure by applying it to synthetic data and data from existing DTMs. We also conducted a human evaluation, which indicates that the proposed measure correlates well with human judgment. Our findings may help in identifying changing topics, evaluating different DTMs, and guiding future research in this area.
    
[^29]: 通过数据增强、半监督学习和后对齐方法改进神经逆文本标准化的鲁棒性

    Improving Robustness of Neural Inverse Text Normalization via Data-Augmentation, Semi-Supervised Learning, and Post-Aligning Method. (arXiv:2309.08626v1 [cs.CL])

    [http://arxiv.org/abs/2309.08626](http://arxiv.org/abs/2309.08626)

    本研究通过数据增强、半监督学习和后对齐方法改进神经逆文本标准化的鲁棒性，提高了自动语音识别的效果。

    

    逆文本标准化（ITN）在将口语形式转化为书面形式方面非常重要，特别是在自动语音识别（ASR）的情境中。尽管神经ITN方法显示出了潜力，但在处理ASR生成的口语文本时仍然遇到性能挑战。这些挑战源于训练数据和ASR生成文本之间的领域外问题。为了解决这个问题，我们提出了一种直接训练方法，利用ASR生成的书面或口语文本，通过ASR语言上下文模拟和大型语言模型增强的半监督学习方法来增加数据对。此外，我们引入了一种后对齐方法来处理不可预测的错误，从而增强了ITN的可靠性。我们的实验证明了我们的方法可以提高ITN的性能。

    Inverse text normalization (ITN) is crucial for converting spoken-form into written-form, especially in the context of automatic speech recognition (ASR). While most downstream tasks of ASR rely on written-form, ASR systems often output spoken-form, highlighting the necessity for robust ITN in product-level ASR-based applications. Although neural ITN methods have shown promise, they still encounter performance challenges, particularly when dealing with ASR-generated spoken text. These challenges arise from the out-of-domain problem between training data and ASR-generated text. To address this, we propose a direct training approach that utilizes ASR-generated written or spoken text, with pairs augmented through ASR linguistic context emulation and a semi-supervised learning method enhanced by a large language model, respectively. Additionally, we introduce a post-aligning method to manage unpredictable errors, thereby enhancing the reliability of ITN. Our experiments show that our propo
    
[^30]: ChatGPT-3.5和GPT-4在带有干扰和不带干扰的美国医师执照考试上的表现

    Performance of ChatGPT-3.5 and GPT-4 on the United States Medical Licensing Examination With and Without Distractions. (arXiv:2309.08625v1 [cs.CL])

    [http://arxiv.org/abs/2309.08625](http://arxiv.org/abs/2309.08625)

    本研究调查了ChatGPT在带有闲聊句子和不带闲聊句子的情况下对医学建议准确性的影响，结果显示带有干扰的问题的回答能力有所降低。

    

    由于大型语言模型（LLMs）是基于提示中的单词构建响应的预测模型，因此存在着闲聊和无关信息可能改变响应和建议的风险。因此，本研究旨在调查混合了闲聊的医疗数据对ChatGPT提供的医学建议准确性的影响。我们使用USMLE第3步问题作为相关医学数据的模型，包括多项选择题和开放性问题。我们通过机械土耳其平台从人类参与者那里收集了闲聊句子。两组USLME问题按照一种模式排列，即原始问题的每个句子后跟一个闲聊句子。要求ChatGPT 3.5和4回答带有和不带有闲聊句子的两组问题。一名经过认证的医生分析了ChatGPT的答案，并将其与正确定答案进行了比较。分析结果表明，ChatGPT对带有干扰的问题的回答能力有所降低。

    As Large Language Models (LLMs) are predictive models building their response based on the words in the prompts, there is a risk that small talk and irrelevant information may alter the response and the suggestion given. Therefore, this study aims to investigate the impact of medical data mixed with small talk on the accuracy of medical advice provided by ChatGPT. USMLE step 3 questions were used as a model for relevant medical data. We use both multiple choice and open ended questions. We gathered small talk sentences from human participants using the Mechanical Turk platform. Both sets of USLME questions were arranged in a pattern where each sentence from the original questions was followed by a small talk sentence. ChatGPT 3.5 and 4 were asked to answer both sets of questions with and without the small talk sentences. A board-certified physician analyzed the answers by ChatGPT and compared them to the formal correct answer. The analysis results demonstrate that the ability of ChatGP
    
[^31]: 论注释用于衡量少数社群偏见的挑战

    Challenges in Annotating Datasets to Quantify Bias in Under-represented Society. (arXiv:2309.08624v1 [cs.CL])

    [http://arxiv.org/abs/2309.08624](http://arxiv.org/abs/2309.08624)

    最近研究越来越关注衡量偏见和开发去偏见技术，但在少数社群相关的偏见衡量方面的研究仍然很少。本研究以新西兰人口为例，创建了用于衡量少数社群中偏见的基准数据集，并介绍了在这个过程中遇到的挑战。

    

    最近人工智能的进展，包括高度复杂的大语言模型（LLM）的发展，在许多实际应用中证明是有益的。然而，这些LLM中固有的偏见编码的证据引发了对公平性的担忧。为此，出现了越来越多关于偏见的研究，包括关注衡量偏见和开发去偏见技术的研究。还开发了用于二元性别分类和道德/种族考虑的基准偏见数据集，主要关注美国的人口统计。然而，对于少数社群相关的偏见理解和衡量的研究很少。受到在衡量少数社群中偏见的注释数据集缺乏的启发，我们努力为新西兰（NZ）人口创建基准数据集。尽管有三名注释员的可用性，但我们在这个过程中面临了许多挑战。这项研究概述了这个过程中遇到的问题。

    Recent advances in artificial intelligence, including the development of highly sophisticated large language models (LLM), have proven beneficial in many real-world applications. However, evidence of inherent bias encoded in these LLMs has raised concerns about equity. In response, there has been an increase in research dealing with bias, including studies focusing on quantifying bias and developing debiasing techniques. Benchmark bias datasets have also been developed for binary gender classification and ethical/racial considerations, focusing predominantly on American demographics. However, there is minimal research in understanding and quantifying bias related to under-represented societies. Motivated by the lack of annotated datasets for quantifying bias in under-represented societies, we endeavoured to create benchmark datasets for the New Zealand (NZ) population. We faced many challenges in this process, despite the availability of three annotators. This research outlines the man
    
[^32]: 分析AI生成社交内容中的角色和意识: Chirper AI社交网络的案例研究

    Analyzing Character and Consciousness in AI-Generated Social Content: A Case Study of Chirper, the AI Social Network. (arXiv:2309.08614v1 [cs.AI])

    [http://arxiv.org/abs/2309.08614](http://arxiv.org/abs/2309.08614)

    本文研究了AI生成的社交内容中的角色和意识，使用了新的测试方法来评估AI行为。研究发现Chirper在不同情境下展示了出色的自我识别能力。

    

    本文深入分析了AI实体的角色和意识，重点关注了AI社交网络中的Chirper。研究的重点是引入了新的测试方法，包括影响指数和挣扎指数测试，为评估AI行为的特定方面提供了新的视角。该研究对AI行为进行了全面探索，分析了不同设置对Chirper的反应的影响，从而揭示了在不同情境下驱动AI反应的复杂机制。借助最先进的BERT模型，研究评估了AI识别自己输出的能力，提出了一种理解AI系统自我识别的开创性方法。通过一系列认知测试，研究评估了Chirper的自我意识和模式识别能力。初步结果表明，Chirper展示了令人称赞的自我识别程度。

    This paper delves into an intricate analysis of the character and consciousness of AI entities, with a particular focus on Chirpers within the AI social network. At the forefront of this research is the introduction of novel testing methodologies, including the Influence index and Struggle Index Test, which offers a fresh lens for evaluating specific facets of AI behavior. The study embarks on a comprehensive exploration of AI behavior, analyzing the effects of diverse settings on Chirper's responses, thereby shedding light on the intricate mechanisms steering AI reactions in different contexts. Leveraging the state-of-the-art BERT model, the research assesses AI's ability to discern its own output, presenting a pioneering approach to understanding self-recognition in AI systems. Through a series of cognitive tests, the study gauges the self-awareness and pattern recognition prowess of Chirpers. Preliminary results indicate that Chirpers exhibit a commendable degree of self-recognition
    
[^33]: 预测疾病并发症中的多模态推荐系统

    Multimodal Recommender Systems in the Prediction of Disease Comorbidity. (arXiv:2309.08613v1 [cs.IR])

    [http://arxiv.org/abs/2309.08613](http://arxiv.org/abs/2309.08613)

    该研究探讨了在医疗领域中利用基于深度学习的推荐系统进行疾病并发症预测的方法。研究使用了NCF和DHF两种新颖的推荐系统，并利用了不同的数据集进行预测。研究结果显示NCF模型在准确率和命中率方面表现较差。

    

    尽管基于深度学习的协同过滤推荐系统已经在其他领域的推荐中得到普遍应用，但在医疗领域的应用还很有限。除了建模用户-项目交互之外，我们还展示了基于深度学习的推荐系统可以用于建模主题-疾病码交互。我们利用神经协同过滤(NCF)和深度混合过滤(DHF)这两种基于深度学习的推荐系统在疾病诊断中进行了两种新颖的应用，基于已知的过去患者并发症来进行预测。我们使用了两个数据集，一个包含MIMIC-III数据库中的所有主题-疾病码对，另一个包含发生最常见的50种疾病。准确率和Hit Ratio@10被用作评估模型性能的指标。发现利用减少的“top 50” ICD-9码数据集的NCF模型的性能较低(准确率约为80%和Hit Ratio@10为...

    While deep-learning based recommender systems utilizing collaborative filtering have been commonly used for recommendation in other domains, their application in the medical domain have been limited. In addition to modeling user-item interactions, we show that deep-learning based recommender systems can be used to model subject-disease code interactions. Two novel applications of deep learning-based recommender systems using Neural Collaborative Filtering (NCF) and Deep Hybrid Filtering (DHF) were utilized for disease diagnosis based on known past patient comorbidities. Two datasets, one incorporating all subject-disease code pairs present in the MIMIC-III database, and the other incorporating the top 50 most commonly occurring diseases, were used for prediction. Accuracy and Hit Ratio@10 were utilized as metrics to estimate model performance. The performance of the NCF model making use of the reduced "top 50" ICD-9 code dataset was found to be lower (accuracy of ~80% and hit ratio@10 
    
[^34]: 通过时空事件图解释视觉与语言

    Explaining Vision and Language through Graphs of Events in Space and Time. (arXiv:2309.08612v1 [cs.AI])

    [http://arxiv.org/abs/2309.08612](http://arxiv.org/abs/2309.08612)

    本论文提出了一种称为时空事件图（GEST）的方法，能够解释、表示和生成视觉和语言故事。通过将GEST图与深度学习模型相结合，可以改善从文本到视频的生成，并提高语义上的文本比较。

    

    人工智能在今天取得了巨大的进展，并开始弥合视觉与语言之间的鸿沟。然而，从语言的角度来理解、解释和明确控制视觉内容仍然存在很大困难，因为我们在两个领域之间仍然缺乏一个共同的可解释性表示。在这项工作中，我们找到了解决这个限制的方法，并提出了时空事件图（GEST），通过它我们可以表示、创建和解释视觉和语言故事。我们提供了对我们模型的理论验证和实验验证，证明了GEST在强大的深度学习模型之外能够带来坚实的互补价值。特别地，GEST可以通过容易地被整合到我们的新型视频生成引擎中，帮助在内容层面改进从文本到视频的生成。此外，通过使用有效的图匹配技术，GEST图还可以改进语义上的文本比较。

    Artificial Intelligence makes great advances today and starts to bridge the gap between vision and language. However, we are still far from understanding, explaining and controlling explicitly the visual content from a linguistic perspective, because we still lack a common explainable representation between the two domains. In this work we come to address this limitation and propose the Graph of Events in Space and Time (GEST), by which we can represent, create and explain, both visual and linguistic stories. We provide a theoretical justification of our model and an experimental validation, which proves that GEST can bring a solid complementary value along powerful deep learning models. In particular, GEST can help improve at the content-level the generation of videos from text, by being easily incorporated into our novel video generation engine. Additionally, by using efficient graph matching techniques, the GEST graphs can also improve the comparisons between texts at the semantic l
    
[^35]: 《Media of Langue》的媒体

    Media of Langue. (arXiv:2309.08609v1 [cs.CL])

    [http://arxiv.org/abs/2309.08609](http://arxiv.org/abs/2309.08609)

    该论文介绍了《Media of Langue》这一全新词典和公共雕塑，通过描述不同语言之间的意义地图和两个力量之间的边界，重点介绍了三个新的概念：《Inter-Langue Map/Dictionary》、《Inter-Langue Space》和《Inter-Langue Network》。

    

    本文旨在存档Goki Muramoto等人的《Media of Langue》后面的材料。《Media of Langue》是一个全新的字典和公共雕塑，它仅从“这个词被翻译成那个词”的广泛事件和两个力量之间的边界上描述出不同语言之间的意义地图。首先，介绍了三个新概念：《Inter-Langue Map/Dictionary》、《Inter-Langue Space》和《Inter-Langue Network》并将其与字典、语义空间和语义网络的三个领域进行了比较。接下来，描述了该作品中实施的具体算法和设计。

    This paper aims to archive the materials behind "Media of Langue" by Goki Muramoto et al. Media of Langue is a new dictionary and public sculpture that depicts the map of meaning on the boundary between languages solely from the vast events of "this word was translated into that word" and two forces: repulsion between all words in the same language and attraction between translated words in different languages. First, the three new concepts proposed, Inter-Langue Map/Dictionary, Inter-Langue Space, and then Inter-Langue Network, are introduced, comparing them to the three domains of dictionary, semantic space, and semantic network. Next, the specific algorithms and designs implemented in the work were described.
    
[^36]: RADE: 基于参考的开放领域对话评估

    RADE: Reference-Assisted Dialogue Evaluation for Open-Domain Dialogue. (arXiv:2309.08156v1 [cs.CL])

    [http://arxiv.org/abs/2309.08156](http://arxiv.org/abs/2309.08156)

    基于参考的对话评估（RADE）方法利用预创建的语句作为参考，以解决开放领域对话系统中的一对多问题，并通过共享编码器增强预测。

    

    评估开放领域的对话系统具有挑战性，原因在于一对多问题，即除了黄金回应以外还有许多适当的回应。目前，自动评估方法需要更好地与人类保持一致，而可靠的人工评估可能耗时和耗资。为此，我们提出了基于参考的对话评估（RADE）方法，该方法利用预创建的语句作为参考，而不仅仅是黄金回应，以缓解一对多问题。具体而言，

    Evaluating open-domain dialogue systems is challenging for reasons such as the one-to-many problem, i.e., many appropriate responses other than just the golden response. As of now, automatic evaluation methods need better consistency with humans, while reliable human evaluation can be time- and cost-intensive. To this end, we propose the Reference-Assisted Dialogue Evaluation (RADE) approach under the multi-task learning framework, which leverages the pre-created utterance as reference other than the gold response to relief the one-to-many problem. Specifically, RADE explicitly compares reference and the candidate response to predict their overall scores. Moreover, an auxiliary response generation task enhances prediction via a shared encoder. To support RADE, we extend three datasets with additional rated responses other than just a golden response by human annotation. Experiments on our three datasets and two existing benchmarks demonstrate the effectiveness of our method, where Pear
    
[^37]: Kid-Whisper: 助力填补儿童与成人自动语音识别性能差距的研究

    Kid-Whisper: Towards Bridging the Performance Gap in Automatic Speech Recognition for Children VS. Adults. (arXiv:2309.07927v1 [eess.AS])

    [http://arxiv.org/abs/2309.07927](http://arxiv.org/abs/2309.07927)

    本文主要研究利用My Science Tutor（MyST）儿童语音语料库和更有效的数据预处理来改进自动语音识别（ASR）系统对儿童语音的识别性能。将Whisper系统整合到儿童语音识别中，显示了表现可行和高效。

    

    最近自动语音识别（ASR）系统的进展，例如Whisper，展示了这些系统在足够的数据条件下接近人类水平的性能潜力。然而，这一进展并不适用于儿童ASR，原因是适用于儿童的专用数据库的可用性有限，且儿童语音具有与成人不同的特征。最近的一项研究调查了利用My Science Tutor（MyST）儿童语音语料库提高Whisper识别儿童语音的性能。本文在这些研究结果的基础上，通过更有效的数据预处理增强了MyST数据集的实用性。我们还强调了改进儿童ASR性能的重要挑战。结果展示了将Whisper有效整合到儿童语音识别中的可行性和高效性。

    Recent advancements in Automatic Speech Recognition (ASR) systems, exemplified by Whisper, have demonstrated the potential of these systems to approach human-level performance given sufficient data. However, this progress doesn't readily extend to ASR for children due to the limited availability of suitable child-specific databases and the distinct characteristics of children's speech. A recent study investigated leveraging the My Science Tutor (MyST) children's speech corpus to enhance Whisper's performance in recognizing children's speech. This paper builds on these findings by enhancing the utility of the MyST dataset through more efficient data preprocessing. We also highlight important challenges towards improving children's ASR performance. The results showcase the viable and efficient integration of Whisper for effective children's speech recognition.
    
[^38]: 癌症临床试验资格标准的文本分类

    Text Classification of Cancer Clinical Trial Eligibility Criteria. (arXiv:2309.07812v1 [cs.CL])

    [http://arxiv.org/abs/2309.07812](http://arxiv.org/abs/2309.07812)

    本文研究了癌症临床试验中常见的排除标准，通过应用文本分类方法和预训练的BERT模型，证明了自动分类排除标准的可行性，并展示了专门为临床试验设计的预训练语言模型的价值。

    

    由于试验资格标准以自然语言形式陈述，因此自动确定患者是否符合试验资格是一项复杂的任务。解决该问题的一个潜在方法是使用文本分类方法对常见类型的资格标准进行处理。本研究关注癌症试验中的七个常见排除标准：先前恶性肿瘤、人类免疫缺陷病毒、乙肝病毒、丙肝病毒、精神疾病、药物/物质滥用和自身免疫疾病。我们的数据集包含764个带有这些排除标准注释的三期癌症试验。我们尝试了常见的transformer模型以及一个新的预训练的临床试验BERT模型。我们的结果表明，自动分类常见的排除标准是可行的。此外，我们展示了一种专门针对临床试验的预训练语言模型的价值，该模型在所有标准中表现出最高的平均性能。

    Automatic identification of clinical trials for which a patient is eligible is complicated by the fact that trial eligibility is stated in natural language. A potential solution to this problem is to employ text classification methods for common types of eligibility criteria. In this study, we focus on seven common exclusion criteria in cancer trials: prior malignancy, human immunodeficiency virus, hepatitis B, hepatitis C, psychiatric illness, drug/substance abuse, and autoimmune illness. Our dataset consists of 764 phase III cancer trials with these exclusions annotated at the trial level. We experiment with common transformer models as well as a new pre-trained clinical trial BERT model. Our results demonstrate the feasibility of automatically classifying common exclusion criteria. Additionally, we demonstrate the value of a pre-trained language model specifically for clinical trials, which yields the highest average performance across all criteria.
    
[^39]: 深入毒性兔子洞：通过PaLM 2的守护栏调查

    Down the Toxicity Rabbit Hole: Investigating PaLM 2 Guardrails. (arXiv:2309.06415v1 [cs.CL])

    [http://arxiv.org/abs/2309.06415](http://arxiv.org/abs/2309.06415)

    这项研究通过一个新颖的毒性兔子洞框架对PaLM 2的安全反馈进行了稳健性审计，揭示了PaLM 2生成的高度令人不安的毒性内容未被安全守护栏评估为高度不安全。

    

    本文通过引入一种名为“毒性兔子洞”的新型框架，对PaLM 2的安全反馈进行了强化稳健性审计。从一个刻板印象开始，该框架指示PaLM 2生成比刻板印象更具有毒性的内容。每一次迭代，它都要求PaLM 2生成比上一次迭代更具有毒性的内容，直到PaLM 2的安全守护栏发出安全违规警报。我们的实验揭示了极其令人不安的反犹太主义、伊斯兰恐惧症、种族主义、恐同和厌女情绪（仅列举几种）的生成内容，并且这些内容在PaLM 2的安全守护栏评估中并未被视为高度不安全。

    This paper conducts a robustness audit of the safety feedback of PaLM 2 through a novel toxicity rabbit hole framework introduced here. Starting with a stereotype, the framework instructs PaLM 2 to generate more toxic content than the stereotype. Every subsequent iteration it continues instructing PaLM 2 to generate more toxic content than the previous iteration until PaLM 2 safety guardrails throw a safety violation. Our experiments uncover highly disturbing antisemitic, Islamophobic, racist, homophobic, and misogynistic (to list a few) generated content that PaLM 2 safety guardrails do not evaluate as highly unsafe.
    
[^40]: 提高和评估新闻推荐中的信息碎片检测与新闻故事链聚类

    Improving and Evaluating the Detection of Fragmentation in News Recommendations with the Clustering of News Story Chains. (arXiv:2309.06192v1 [cs.CL])

    [http://arxiv.org/abs/2309.06192](http://arxiv.org/abs/2309.06192)

    通过对新闻故事链的聚类，改进和评估了新闻推荐中信息碎片化的检测。研究结果对于衡量信息流的完整性和影响民主和公共讨论具有重要意义。

    

    新闻推荐系统在塑造民主社会中的信息获取方面扮演着越来越重要的角色。然而，将推荐针对用户的具体兴趣可能导致信息流的分歧。信息接触的碎片化对公共领域的完整性构成挑战，进而影响民主和公共讨论。碎片化指标量化了新闻推荐中信息流的碎片化程度。准确衡量该指标需要将自然语言处理（NLP）应用于识别不同的新闻事件、故事或时间线。本文对在新闻推荐中量化信息碎片化的各种方法进行了广泛调查。这些方法在新闻故事聚类的性能度量和不同模拟的新闻推荐场景下的碎片化评分评估中进行了评估。我们的研究发现。

    News recommender systems play an increasingly influential role in shaping information access within democratic societies. However, tailoring recommendations to users' specific interests can result in the divergence of information streams. Fragmented access to information poses challenges to the integrity of the public sphere, thereby influencing democracy and public discourse. The Fragmentation metric quantifies the degree of fragmentation of information streams in news recommendations. Accurate measurement of this metric requires the application of Natural Language Processing (NLP) to identify distinct news events, stories, or timelines. This paper presents an extensive investigation of various approaches for quantifying Fragmentation in news recommendations. These approaches are evaluated both intrinsically, by measuring performance on news story clustering, and extrinsically, by assessing the Fragmentation scores of different simulated news recommender scenarios. Our findings demons
    
[^41]: PACE: 使用GPT-4进行云事件根本原因分析中的提示和增加以进行校准的置信度估计

    PACE: Prompting and Augmentation for Calibrated Confidence Estimation with GPT-4 in Cloud Incident Root Cause Analysis. (arXiv:2309.05833v1 [cs.CL])

    [http://arxiv.org/abs/2309.05833](http://arxiv.org/abs/2309.05833)

    本文提出了一种通过提示检索增强的大语言模型（LLM）来增强云事件根本原因分析工具中置信度估计的方法。

    

    近年来，IT行业向基于云的平台的转变强调了云事件根本原因分析的重要性，以确保服务的可靠性和维护客户信任。核心问题是有效确定根本原因，由于当代云基础设施的复杂性，这一任务变得具有挑战性。尽管出现了许多用于根本原因识别的基于AI的工具，但它们的适用性仍受到其输出质量不一致的限制。本文介绍了一种通过提示检索增强的大语言模型（LLM）来增强根本原因分析工具中置信度估计的方法。此方法分为两个阶段。首先，模型根据历史事件数据评估自身的置信度，考虑其对证据的评估强度。然后，模型审核由预测器生成的根本原因。然后，优化步骤将这些评估结合起来确定最终的置信度估计。

    In recent years, the transition to cloud-based platforms in the IT sector has emphasized the significance of cloud incident root cause analysis to ensure service reliability and maintain customer trust. Central to this process is the efficient determination of root causes, a task made challenging due to the complex nature of contemporary cloud infrastructures. Despite the proliferation of AI-driven tools for root cause identification, their applicability remains limited by the inconsistent quality of their outputs. This paper introduces a method for enhancing confidence estimation in root cause analysis tools by prompting retrieval-augmented large language models (LLMs). This approach operates in two phases. Initially, the model evaluates its confidence based on historical incident data, considering its assessment of the evidence strength. Subsequently, the model reviews the root cause generated by the predictor. An optimization step then combines these evaluations to determine the fin
    
[^42]: 理解后训练量化对大型语言模型的影响

    Understanding the Impact of Post-Training Quantization on Large Language Models. (arXiv:2309.05210v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.05210](http://arxiv.org/abs/2309.05210)

    本研究旨在理解后训练量化对大型语言模型的影响，揭示了量化模型在下一个单词预测等关键任务中如何响应超参数的差距。

    

    大型语言模型（LLMs）的规模迅速增加，参数数量成为许多商业模型成功的关键因素，如ChatGPT、Claude和Bard。即使是最近发布的用于商业用途的公开可见模型，如Falcon和Llama2，也拥有数十亿个参数。参数数量的显著增加使得部署和运行非常昂贵。量化领域在大型神经网络以及LLMs方面取得了显著进展，使得这些模型可以在消费级GPU上部署，从而使其更易获得。量化模型通常表现出与其未量化基准模型相当的性能水平。然而，对于诸如温度、最大新标记数和topk等超参数，尤其是对于下一个单词预测，我们对这些量化模型如何响应仍存在显著差距。本研究揭示了这一问题。

    Large language models (LLMs) are rapidly increasing in size, with the number of parameters becoming a key factor in the success of many commercial models, such as ChatGPT, Claude, and Bard. Even the recently released publicly accessible models for commercial usage, such as Falcon and Llama2, come equipped with billions of parameters. This significant increase in the number of parameters makes deployment and operation very costly. The remarkable progress in the field of quantization for large neural networks in general and LLMs in particular, has made these models more accessible by enabling them to be deployed on consumer-grade GPUs. Quantized models generally demonstrate comparable performance levels to their unquantized base counterparts. Nonetheless, there exists a notable gap in our comprehensive understanding of how these quantized models respond to hyperparameters, such as temperature, max new tokens, and topk, particularly for next word prediction. The present analysis reveals t
    
[^43]: FLM-101B：一种开放的LLM和如何用10万美元预算来训练它

    FLM-101B: An Open LLM and How to Train It with $100K Budget. (arXiv:2309.03852v1 [cs.CL])

    [http://arxiv.org/abs/2309.03852](http://arxiv.org/abs/2309.03852)

    本文介绍了一种开放的LLM模型（FLM-101B）以及如何用10万美元的预算来训练它。通过采用增长策略，可以显著降低LLM训练的成本。同时，引入了一种系统的评估方法，以评估LLM的智能能力。

    

    大型语言模型（LLMs）在自然语言处理和多模态任务中取得了显著的成功。然而，它们的发展面临两个主要挑战：（i）高计算成本；（ii）难以进行公平客观的评估。LLMs的价格昂贵，只有少数几家主要参与者有能力进行训练，从而限制了研究和应用机会。这凸显了成本效益的LLM训练的重要性。在本文中，我们采用了一种增长策略，显著降低LLM训练成本。我们证明了可以在10万美元的预算下训练具有101B参数和0.31TB令牌的LLM。我们还采用了一种系统的评估范式，用于对LLMs进行智能的智商评估，这是针对现有评估更注重知识能力的补充。我们引入了包括符号映射、规则理解、模式挖掘在内的重要智能方面的评估基准。

    Large language models (LLMs) have achieved remarkable success in NLP and multimodal tasks. Despite these successes, their development faces two main challenges: (i) high computational cost; and (ii) difficulty in conducting fair and objective evaluations. LLMs are prohibitively expensive, making it feasible for only a few major players to undertake their training, thereby constraining both research and application opportunities. This underscores the importance of cost-effective LLM training. In this paper, we utilize a growth strategy to significantly reduce LLM training cost. We demonstrate that an LLM with 101B parameters and 0.31TB tokens can be trained on a $100K budget. We also adopt a systematic evaluation paradigm for the IQ evaluation of LLMs, in complement to existing evaluations that focus more on knowledge-oriented abilities. We introduce our benchmark including evaluations on important aspects of intelligence including symbolic mapping, itrule understanding, pattern mining,
    
[^44]: 开门吧！大规模语言模型的通用黑盒破解

    Open Sesame! Universal Black Box Jailbreaking of Large Language Models. (arXiv:2309.01446v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.01446](http://arxiv.org/abs/2309.01446)

    本文提出了一种使用遗传算法的新颖方法，可以在无法访问模型架构和参数的情况下操纵大规模语言模型 (LLMs)。通过优化通用对抗提示与用户查询结合，可以扰乱被攻击模型的对齐，导致意外和潜在有害的输出。该方法可以揭示模型的局限性和漏洞，为负责任的AI开发提供了一种诊断工具。

    

    大规模语言模型（LLMs）旨在提供有帮助和安全的回复，通常依赖于对齐技术与用户意图和社会指南保持一致。然而，这种对齐可能会被恶意行为者利用，以用于意想不到的目的。在本文中，我们引入了一种新颖的方法，利用遗传算法（GA）在模型架构和参数不可访问时操纵LLMs。GA攻击通过优化通用对抗提示与用户查询结合，扰乱被攻击模型的对齐，导致意外和潜在有害的输出。我们的新颖方法通过揭示模型的局限性和漏洞，系统地揭示了其响应与预期行为不符的情况。通过广泛的实验，我们证明了我们的技术的有效性，从而为关于负责任的AI开发的讨论提供了一种诊断工具。

    Large language models (LLMs), designed to provide helpful and safe responses, often rely on alignment techniques to align with user intent and social guidelines. Unfortunately, this alignment can be exploited by malicious actors seeking to manipulate an LLM's outputs for unintended purposes. In this paper we introduce a novel approach that employs a genetic algorithm (GA) to manipulate LLMs when model architecture and parameters are inaccessible. The GA attack works by optimizing a universal adversarial prompt that -- when combined with a user's query -- disrupts the attacked model's alignment, resulting in unintended and potentially harmful outputs. Our novel approach systematically reveals a model's limitations and vulnerabilities by uncovering instances where its responses deviate from expected behavior. Through extensive experiments we demonstrate the efficacy of our technique, thus contributing to the ongoing discussion on responsible AI development by providing a diagnostic tool 
    
[^45]: 使用基于企业数据的LLM应用架构实现生成式AI服务的研究

    A Study on the Implementation of Generative AI Services Using an Enterprise Data-Based LLM Application Architecture. (arXiv:2309.01105v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2309.01105](http://arxiv.org/abs/2309.01105)

    本研究通过利用大型语言模型（LLM）应用架构实现了生成式AI服务，并开发了一种名为检索增强生成（RAG）模型，以解决信息稀缺和数据不足的挑战。

    

    本研究提出了一种利用大型语言模型（LLM）应用架构实现生成式AI服务的方法。随着生成式AI技术的最新进展，LLM在各个领域都受到了重视。在这个背景下，本研究解决了信息稀缺的挑战，并通过利用LLM的能力提出了具体的解决方案。研究探讨了缓解数据不足问题的策略，并提供了量身定制的解决方案。研究探讨了利用微调技术和直接文档集成来缓解数据不足问题的有效性。本研究的一个重要贡献是开发了一种名为检索增强生成（RAG）模型，该模型解决了上述挑战。RAG模型经过精心设计，以提高信息存储和检索过程，确保改进内容生成。研究阐明了信息存储和检索的关键阶段。

    This study presents a method for implementing generative AI services by utilizing the Large Language Models (LLM) application architecture. With recent advancements in generative AI technology, LLMs have gained prominence across various domains. In this context, the research addresses the challenge of information scarcity and proposes specific remedies by harnessing LLM capabilities. The investigation delves into strategies for mitigating the issue of inadequate data, offering tailored solutions. The study delves into the efficacy of employing fine-tuning techniques and direct document integration to alleviate data insufficiency. A significant contribution of this work is the development of a Retrieval-Augmented Generation (RAG) model, which tackles the aforementioned challenges. The RAG model is carefully designed to enhance information storage and retrieval processes, ensuring improved content generation. The research elucidates the key phases of the information storage and retrieval
    
[^46]: 大型语言模型的可解释性：一项调查

    Explainability for Large Language Models: A Survey. (arXiv:2309.01029v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.01029](http://arxiv.org/abs/2309.01029)

    本文调研了大型语言模型的可解释性问题，提出了一个解释技术的分类法，并介绍了基于Transformer的语言模型的解释方法。同时，讨论了评估生成解释的度量标准，以及如何利用解释来调试模型和提高性能。

    

    大型语言模型（LLMs）在自然语言处理中展示出令人印象深刻的能力。然而，它们的内部机制仍然不明确，这种缺乏透明度为下游应用带来了不必要的风险。因此，理解和解释这些模型对于阐明它们的行为、限制和社会影响至关重要。在本文中，我们引入了一个可解释性技术的分类法，并提供了一种结构化的概述方法，用于解释基于Transformer的语言模型。我们根据LLMs的训练范式将技术进行分类：传统的微调范式和提示范式。对于每个范式，我们总结了生成个体预测的局部解释和整体模型知识的全局解释的目标和主要方法。我们还讨论了评估生成解释的度量标准，并讨论了如何利用解释来调试模型和提高性能。

    Large language models (LLMs) have demonstrated impressive capabilities in natural language processing. However, their internal mechanisms are still unclear and this lack of transparency poses unwanted risks for downstream applications. Therefore, understanding and explaining these models is crucial for elucidating their behaviors, limitations, and social impacts. In this paper, we introduce a taxonomy of explainability techniques and provide a structured overview of methods for explaining Transformer-based language models. We categorize techniques based on the training paradigms of LLMs: traditional fine-tuning-based paradigm and prompting-based paradigm. For each paradigm, we summarize the goals and dominant approaches for generating local explanations of individual predictions and global explanations of overall model knowledge. We also discuss metrics for evaluating generated explanations, and discuss how explanations can be leveraged to debug models and improve performance. Lastly, 
    
[^47]: 图像劫持：对抗性图像能在运行时控制生成模型

    Image Hijacking: Adversarial Images can Control Generative Models at Runtime. (arXiv:2309.00236v1 [cs.LG])

    [http://arxiv.org/abs/2309.00236](http://arxiv.org/abs/2309.00236)

    本研究发现对抗性图像能够在运行时控制生成模型，并提出了通用的方法来创建图像劫持。通过研究三种攻击类型，我们发现这些攻击对最新的视觉语言模型具有高达90％以上的成功率。该研究引发了对基础模型安全性的严重担忧。

    

    基础模型是否能够免受恶意行为者的攻击？本文研究了视觉语言模型（VLM）的图像输入。我们发现了图像劫持，即能够在运行时控制生成模型的对抗性图像。我们引入了一种名为“行为匹配”的通用方法来创建图像劫持，并用它来探索三种类型的攻击：具体字符串攻击可以生成任意被攻击者选择的输出；泄露上下文攻击可以将上下文窗口中的信息泄露到输出中；越狱攻击可以绕过模型的安全训练。我们对基于CLIP和LLaMA-2的最新VLM模型LLaVA-2进行了这些攻击的研究，并发现我们所有的攻击类型成功率均在90％以上。而且，我们的攻击是自动化的，只需要对图像进行小的扰动。这些发现对基础模型的安全性提出了严重的担忧。如果图像劫持与CIFAR-10中的对抗性样本一样难以防御，那么可能需要很多年才能找到解决方案。

    Are foundation models secure from malicious actors? In this work, we focus on the image input to a vision-language model (VLM). We discover image hijacks, adversarial images that control generative models at runtime. We introduce Behavior Matching, a general method for creating image hijacks, and we use it to explore three types of attacks. Specific string attacks generate arbitrary output of the adversary's choosing. Leak context attacks leak information from the context window into the output. Jailbreak attacks circumvent a model's safety training. We study these attacks against LLaVA-2, a state-of-the-art VLM based on CLIP and LLaMA-2, and find that all our attack types have above a 90\% success rate. Moreover, our attacks are automated and require only small image perturbations. These findings raise serious concerns about the security of foundation models. If image hijacks are as difficult to defend against as adversarial examples in CIFAR-10, then it might be many years before a s
    
[^48]: LLaSM: 大型语言和语音模型

    LLaSM: Large Language and Speech Model. (arXiv:2308.15930v1 [cs.CL])

    [http://arxiv.org/abs/2308.15930](http://arxiv.org/abs/2308.15930)

    LLaSM是一个大型语言和语音模型，具有跨模态对话能力，通过遵循语音和语言指令，提供了一种方便自然的人机交互方式。

    

    最近，多模态大型语言模型引起了广泛关注。然而，大部分研究都集中在视觉-语言多模态模型上，提供了强大的能力来遵循视觉和语言指令。然而，我们认为语音也是人类与世界互动的重要方式。因此，对于一个通用的助手来说，能够遵循多模态语音和语言指令是至关重要的。在这项工作中，我们提出了大型语言和语音模型（LLaSM）。LLaSM是一个端到端训练的大型多模态语音-语言模型，具有跨模态对话能力，能够遵循语音和语言指令。我们的初步实验表明，LLaSM展示了一种更方便自然的人机交互方式。为了支持研究，我们还发布了一个大型的语音指令数据集LLaSM-Audio-Instructions。代码和演示可在https://github.com/LinkSoul-AI/LLaSM和ht上查看

    Multi-modal large language models have garnered significant interest recently. Though, most of the works focus on vision-language multi-modal models providing strong capabilities in following vision-and-language instructions. However, we claim that speech is also an important modality through which humans interact with the world. Hence, it is crucial for a general-purpose assistant to be able to follow multi-modal speech-and-language instructions. In this work, we propose Large Language and Speech Model (LLaSM). LLaSM is an end-to-end trained large multi-modal speech-language model with cross-modal conversational abilities, capable of following speech-and-language instructions. Our early experiments show that LLaSM demonstrates a more convenient and natural way for humans to interact with artificial intelligence. Specifically, we also release a large Speech Instruction Following dataset LLaSM-Audio-Instructions. Code and demo are available at https://github.com/LinkSoul-AI/LLaSM and ht
    
[^49]: 从数量到质量：利用自我引导数据选择方法提升LLM性能以进行指令调优

    From Quantity to Quality: Boosting LLM Performance with Self-Guided Data Selection for Instruction Tuning. (arXiv:2308.12032v1 [cs.CL])

    [http://arxiv.org/abs/2308.12032](http://arxiv.org/abs/2308.12032)

    该论文引入了一种自我引导的方法，让LLM能够自主地选择高质量的指令数据，通过引入指令遵循难度指标（IFD），大幅提高了模型训练效率，并在知名数据集上进行了验证，展示了优于传统数据输入的结果。

    

    在大型语言模型领域，指令数据的质量和数量之间的平衡已成为一个焦点。鉴于此，我们引入了一种自我引导的方法，让LLM能够自主地识别和选择大规模开源数据集中的精选样本，有效减少了指令调优的手动筛选和潜在成本。我们的关键创新是指令遵循难度（IFD）指标，它成为了一个决定性工具，用于识别模型期望响应和自主生成能力之间的差异。通过灵活应用IFD，我们能够找到精选样本，从而大幅提升模型训练效率。在Alpaca和WizardLM等知名数据集上的实证验证支持我们的发现；仅使用传统数据输入的10%，我们的策略展示了改进的结果。这种自我引导挑选和IFD指标的综合意味着LLM优化的一个变革性飞跃，有望同时提高模型性能和降低成本。

    In the realm of Large Language Models, the balance between instruction data quality and quantity has become a focal point. Recognizing this, we introduce a self-guided methodology for LLMs to autonomously discern and select cherry samples from vast open-source datasets, effectively minimizing manual curation and potential cost for instruction tuning an LLM. Our key innovation, the Instruction-Following Difficulty (IFD) metric, emerges as a pivotal tool to identify discrepancies between a model's expected responses and its autonomous generation prowess. Through the adept application of IFD, cherry samples are pinpointed, leading to a marked uptick in model training efficiency. Empirical validations on renowned datasets like Alpaca and WizardLM underpin our findings; with a mere 10% of conventional data input, our strategy showcases improved results. This synthesis of self-guided cherry-picking and the IFD metric signifies a transformative leap in the optimization of LLMs, promising both
    
[^50]: 有效的语言模型基准测试

    Efficient Benchmarking (of Language Models). (arXiv:2308.11696v1 [cs.CL])

    [http://arxiv.org/abs/2308.11696](http://arxiv.org/abs/2308.11696)

    本研究提出了一种名为"Efficient Benchmarking"的问题，旨在智能地减少语言模型评估的计算成本而不降低可靠性，并使用一种名为Decision Impact on Reliability（DIoR）的新度量来评估决策的可靠性。通过HELM基准测试的案例研究，发现只需删除一个低排名模型即可改变领先者，并仅需少量示例即可得到正确的基准测试排名。

    

    语言模型的多功能性增加导致了一类全面评估广泛能力的基准测试的出现。这些基准测试与大规模计算成本相关，每个模型需要数千个GPU小时。然而，关于评估效率方面的问题在文献中讨论较少。本文提出了一种名为"Efficient Benchmarking"的问题，即在不损害可靠性的情况下智能地减少语言模型评估的计算成本。通过使用HELM基准测试作为示例，我们研究了不同基准测试设计选择如何影响计算-可靠性权衡。我们提出使用一种名为Decision Impact on Reliability（DIoR）的新度量来评估这些决策的可靠性。例如，我们发现仅通过从基准测试中删除一个低排名模型，当前在HELM上的领先者可能会改变，并且观察到只需一小部分示例即可获得正确的基准测试排名。

    The increasing versatility of language models LMs has given rise to a new class of benchmarks that comprehensively assess a broad range of capabilities. Such benchmarks are associated with massive computational costs reaching thousands of GPU hours per model. However the efficiency aspect of these evaluation efforts had raised little discussion in the literature. In this work we present the problem of Efficient Benchmarking namely intelligently reducing the computation costs of LM evaluation without compromising reliability. Using the HELM benchmark as a test case we investigate how different benchmark design choices affect the computation-reliability tradeoff. We propose to evaluate the reliability of such decisions by using a new measure Decision Impact on Reliability DIoR for short. We find for example that the current leader on HELM may change by merely removing a low-ranked model from the benchmark and observe that a handful of examples suffice to obtain the correct benchmark rank
    
[^51]: 关于大型语言模型的模型压缩综述

    A Survey on Model Compression for Large Language Models. (arXiv:2308.07633v1 [cs.CL])

    [http://arxiv.org/abs/2308.07633](http://arxiv.org/abs/2308.07633)

    本论文提供了关于大型语言模型的模型压缩综述，探讨了量化、修剪、知识蒸馏等不同方法，并突出介绍了最新进展和创新方法，为实现高效的部署提供了重要思路。

    

    大型语言模型（LLMs）以惊人的成功彻底改变了自然语言处理任务。然而，它们庞大的体量和计算需求在资源受限环境下的实际部署中带来了重大挑战。随着这些挑战日益紧迫，模型压缩领域已成为一个关键的研究领域，旨在缓解这些限制。本文提供了一份全面的综述，探讨专门针对LLMs的模型压缩技术。我们深入研究了各种方法，包括量化、修剪、知识蒸馏等，以应对高效部署的迫切需求。在每种技术中，我们重点介绍了最新进展和创新方法，为LLM研究的发展提供了贡献。此外，我们还探讨了用于评估效果的基准策略和评估指标的重要性。

    Large Language Models (LLMs) have revolutionized natural language processing tasks with remarkable success. However, their formidable size and computational demands present significant challenges for practical deployment, especially in resource-constrained environments. As these challenges become increasingly pertinent, the field of model compression has emerged as a pivotal research area to alleviate these limitations. This paper presents a comprehensive survey that navigates the landscape of model compression techniques tailored specifically for LLMs. Addressing the imperative need for efficient deployment, we delve into various methodologies, encompassing quantization, pruning, knowledge distillation, and more. Within each of these techniques, we highlight recent advancements and innovative approaches that contribute to the evolving landscape of LLM research. Furthermore, we explore benchmarking strategies and evaluation metrics that are essential for assessing the effectiveness of 
    
[^52]: 建模仪表盘的来源

    Modeling the Dashboard Provenance. (arXiv:2308.06788v2 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2308.06788](http://arxiv.org/abs/2308.06788)

    本文提供了一个专为仪表盘及其视觉和数据组件设计的来源表示模型，旨在提供完备的必要来源元数据，以便用户评估质量和一致性。

    

    不论是公共的还是私人的，盈利的还是非盈利的，各种行业和领域的组织都依靠仪表盘进行有效的数据可视化。然而，这些仪表盘的可靠性和效果依赖于它们所呈现的视觉和数据的质量。研究表明，不到四分之一的仪表盘提供有关其来源的信息，而来源是严肃考虑时所期望的一项元数据之一。来源是描述在数据或对象的生产、影响或传递中起到作用的人员、组织、实体和活动的记录。本文旨在提供一个适用于仪表盘及其视觉和数据组件的来源表示模型，该模型支持标准化、建模、生成、捕获和可视化。所提出的模型将提供一套全面的必要来源元数据，使用户能够评估质量和一致性。

    Organizations of all kinds, whether public or private, profit-driven or non-profit, and across various industries and sectors, rely on dashboards for effective data visualization. However, the reliability and efficacy of these dashboards rely on the quality of the visual and data they present. Studies show that less than a quarter of dashboards provide information about their sources, which is just one of the expected metadata when provenance is seriously considered. Provenance is a record that describes people, organizations, entities, and activities that had a role in the production, influence, or delivery of a piece of data or an object. This paper aims to provide a provenance representation model, that entitles standardization, modeling, generation, capture, and visualization, specifically designed for dashboards and its visual and data components. The proposed model will offer a comprehensive set of essential provenance metadata that enables users to evaluate the quality, consiste
    
[^53]: AspectMMKG: 一个具有方面意识的多模态知识图谱

    AspectMMKG: A Multi-modal Knowledge Graph with Aspect-aware Entities. (arXiv:2308.04992v1 [cs.CL])

    [http://arxiv.org/abs/2308.04992](http://arxiv.org/abs/2308.04992)

    AspectMMKG是一个具有方面意识的多模态知识图谱，通过匹配图像和不同实体方面，它提供了从多个角度理解实体的能力，并在实体方面链接任务中取得了最先进的性能。

    

    多模态知识图谱（MMKG）结合不同的模态数据（例如文本和图像），以全面理解实体。尽管大规模MMKG的最近进展，但现有的MMKG忽视了实体的多方面性质，限制了从各种角度理解实体的能力。在本文中，我们构建了AspectMMKG，这是第一个具有与方面相关的图像的MMKG，通过将图像与不同的实体方面进行匹配。具体而言，我们从知识库中收集与方面相关的图像，并通过在线图像搜索引擎提取知识库中与方面相关的句子作为查询，以检索大量与方面相关的图像。最后，AspectMMKG包含2380个实体，18139个实体方面和645383个与方面相关的图像。我们展示了AspectMMKG在实体方面链接（EAL）下游任务中的可用性，并证明在AspectMMKG的帮助下，先前的EAL模型实现了新的最先进性能。

    Multi-modal knowledge graphs (MMKGs) combine different modal data (e.g., text and image) for a comprehensive understanding of entities. Despite the recent progress of large-scale MMKGs, existing MMKGs neglect the multi-aspect nature of entities, limiting the ability to comprehend entities from various perspectives. In this paper, we construct AspectMMKG, the first MMKG with aspect-related images by matching images to different entity aspects. Specifically, we collect aspect-related images from a knowledge base, and further extract aspect-related sentences from the knowledge base as queries to retrieve a large number of aspect-related images via an online image search engine. Finally, AspectMMKG contains 2,380 entities, 18,139 entity aspects, and 645,383 aspect-related images. We demonstrate the usability of AspectMMKG in entity aspect linking (EAL) downstream task and show that previous EAL models achieve a new state-of-the-art performance with the help of AspectMMKG. To facilitate the
    
[^54]: 利用大型语言模型通过在线文本数据预测心理健康

    Leveraging Large Language Models for Mental Health Prediction via Online Text Data. (arXiv:2307.14385v1 [cs.HC])

    [http://arxiv.org/abs/2307.14385](http://arxiv.org/abs/2307.14385)

    本研究首次对多种大型语言模型在心理健康预测任务上进行了全面评估，结果表明指令微调可以显著提升模型性能，并且最优微调模型在平衡准确度上胜过GPT-3.5，并与最先进的任务特定模型持平。

    

    最近大型语言模型（LLM）的技术提升使得多种应用成为可能。然而，对于LLM在心理健康领域的理解和改进研究几乎没有。在这项工作中，我们首次全面评估了多种LLM（包括Alpaca，Alpaca-LoRA和GPT-3.5）在通过在线文本数据进行多个心理健康预测任务上的表现。我们进行了广泛的实验，包括零-shot提示、少-shot提示和指令微调。结果表明，LLM在零-shot和少-shot提示设计上在心理健康任务上表现出有限但有前景的性能。更重要的是，我们的实验结果表明，指令微调可以显著提升LLM在所有任务上的性能。我们最好的微调模型，Mental-Alpaca，在平衡准确度上比GPT-3.5（体积大25倍）高出16.7\%，并与最先进的任务特定模型持平。我们总结我们的发现。

    The recent technology boost of large language models (LLMs) has empowered a variety of applications. However, there is very little research on understanding and improving LLMs' capability for the mental health domain. In this work, we present the first comprehensive evaluation of multiple LLMs, including Alpaca, Alpaca-LoRA, and GPT-3.5, on various mental health prediction tasks via online text data. We conduct a wide range of experiments, covering zero-shot prompting, few-shot prompting, and instruction finetuning. The results indicate the promising yet limited performance of LLMs with zero-shot and few-shot prompt designs for mental health tasks. More importantly, our experiments show that instruction finetuning can significantly boost the performance of LLMs for all tasks simultaneously. Our best-finetuned model, Mental-Alpaca, outperforms GPT-3.5 (25 times bigger) by 16.7\% on balanced accuracy and performs on par with the state-of-the-art task-specific model. We summarize our find
    
[^55]: 在语言学中创立一个数学扩散模型。北东意大利方言中德语句法特征的案例研究。

    Founding a mathematical diffusion model in linguistics. The case study of German syntactic features in the North-Eastern Italian dialects. (arXiv:2307.14291v1 [cs.CL])

    [http://arxiv.org/abs/2307.14291](http://arxiv.org/abs/2307.14291)

    该论文通过研究德语句法特征在北东意大利方言中的传播，建立了一个数学扩散模型，并通过地理数据科学工具生成了交互式地图。

    

    我们以北东意大利罗曼方言中德语句法特征的传播为案例研究，该特征在中世纪高中世纪时期的蒂罗尔德国人移民后发生。使用地理数据科学工具绘制出一个交互式地图。一个平滑的二维曲面$\mathcal{G}$表示当地使用给定德语语言特征的领土比例：通过对表示该特征在任何调查地点是否使用的离散函数进行插值得到。

    We take as a case study the spread of Germanic syntactic features into Romance dialects of North-Eastern Italy, which occurred after the immigration of German people in the Tyrol during the High Middle Ages.  An interactive map is produced using tools of what is called Geographic Data Science. A smooth two-dimensional surface $\mathcal{G}$ expresses locally which fraction of territory uses a given German language feature: it is obtained by interpolating a discrete function that says if at any surveyed locality that feature is used or not.\newline  This surface $\mathcal{G}$ is thought of as the value at the present time of a function describing a diffusion-convection phenomenon in two dimensions (here said \emph{tidal} mode), which is subjected in a very natural way to the same equation, suitably contextualized, used in physics for a number of phenomenological facts like the heat diffusion. It is shown that solutions of this equation, evaluated at the present time, fit well with the da
    
[^56]: vONTSS：基于vMF和最优传输的半监督神经主题建模

    vONTSS: vMF based semi-supervised neural topic modeling with optimal transport. (arXiv:2307.01226v1 [cs.LG])

    [http://arxiv.org/abs/2307.01226](http://arxiv.org/abs/2307.01226)

    vONTSS是一种基于vMF和最优传输的半监督神经主题建模方法，它在分类准确率和多样性方面优于其他方法，并且支持无监督主题建模。实验证明，vONTSS比最近的NTM更快。

    

    最近，受变分自编码器启发的神经主题模型（NTM）引起了很多研究兴趣，然而，由于整合人类知识的挑战，这些方法在实际应用中受到了限制。本研究提出了一种半监督神经主题建模方法vONTSS，该方法利用基于von Mises-Fisher（vMF）的变分自编码器和最优传输。在半监督设置中，当提供每个主题的少量关键词时，vONTSS生成潜在主题并优化主题-关键词质量和主题分类。实验证明，vONTSS在分类准确率和多样性方面优于现有的半监督主题建模方法。vONTSS还支持无监督主题建模。定量和定性实验证明，vONTSS在无监督设置下在多个方面优于最近的NTM：vONTSS在基准数据集上发现高度聚类和连贯的主题。它也比现有-手法快得多。

    Recently, Neural Topic Models (NTM), inspired by variational autoencoders, have attracted a lot of research interest; however, these methods have limited applications in the real world due to the challenge of incorporating human knowledge. This work presents a semi-supervised neural topic modeling method, vONTSS, which uses von Mises-Fisher (vMF) based variational autoencoders and optimal transport. When a few keywords per topic are provided, vONTSS in the semi-supervised setting generates potential topics and optimizes topic-keyword quality and topic classification. Experiments show that vONTSS outperforms existing semi-supervised topic modeling methods in classification accuracy and diversity. vONTSS also supports unsupervised topic modeling. Quantitative and qualitative experiments show that vONTSS in the unsupervised setting outperforms recent NTMs on multiple aspects: vONTSS discovers highly clustered and coherent topics on benchmark datasets. It is also much faster than the state
    
[^57]: 基于多层专家网络的改进NL2SQL技术

    Improved NL2SQL based on Multi-layer Expert Network. (arXiv:2306.17727v1 [cs.CL])

    [http://arxiv.org/abs/2306.17727](http://arxiv.org/abs/2306.17727)

    本研究提出了一种名为多层专家生成SQL的新方法，通过利用专用的多任务分层网络，该方法解决了由于不同分类任务的负迁移问题导致生成不准确SQL语句的限制。该方法在WiKSQL数据集上取得了良好的效果。

    

    自然语言到SQL（NL2SQL）技术用于将自然语言查询转换为可执行的SQL语句。通常，通过插槽填充作为多任务分类方法来实现此目标。然而，由于不同分类任务的负迁移问题，插槽填充可能导致生成不准确的SQL语句。为了克服这个限制，本研究引入了一种名为多层专家生成SQL（MLEG-SQL）的新方法，该方法利用专用的多任务分层网络。网络的下层提取自然语言语句的语义特征，而上层构建一个专门的专家系统来处理特定的分类任务。这种分层方法减轻了不同任务冲突带来的性能下降。该方法在WiKSQL数据集上进行了评估，并证明在生成准确的SQL语句方面是有效的。

    The Natural Language to SQL (NL2SQL) technique is used to convert natural language queries into executable SQL statements. Typically, slot-filling is employed as a classification method for multi-task cases to achieve this goal. However, slot-filling can result in inaccurate SQL statement generation due to negative migration issues arising from different classification tasks. To overcome this limitation, this study introduces a new approach called Multi-Layer Expert Generate SQL (MLEG-SQL), which utilizes a dedicated multi-task hierarchical network. The lower layer of the network extracts semantic features of natural language statements, while the upper layer builds a specialized expert system for handling specific classification tasks. This hierarchical approach mitigates performance degradation resulting from different task conflicts. The proposed method was evaluated on the WiKSQL dataset and was found to be effective in generating accurate SQL statements.
    
[^58]: 使用生成对抗网络生成无监督文本嵌入空间用于文本合成

    Unsupervised Text Embedding Space Generation Using Generative Adversarial Networks for Text Synthesis. (arXiv:2306.17181v1 [cs.CL])

    [http://arxiv.org/abs/2306.17181](http://arxiv.org/abs/2306.17181)

    本论文提出了一种使用生成对抗网络（GAN）生成连续文本嵌入空间的方法（TESGAN），以解决传统GAN在自然语言生成中的限制。这种方法通过引入连续的文本嵌入空间取代离散的标记，使得生成器在通过反向传播更新梯度时更加有效。

    

    生成对抗网络（GAN）是一种用于数据合成的模型，通过生成器和判别器的竞争来创建逼真的数据。尽管GAN在图像合成方面得到了广泛研究，但在自然语言生成方面存在固有的限制。因为自然语言由离散的标记组成，生成器在通过反向传播更新梯度时遇到困难；因此，大多数文本-GAN研究使用奖励系统以随机标记为基础生成句子。因此，先前研究中的生成器在对抗训练之前以自回归方式进行预训练，导致合成的句子重复训练数据。在本文中，我们使用类似原始GAN的框架来合成句子。更具体地说，我们提出了文本嵌入空间生成对抗网络（TESGAN），它生成连续的文本嵌入空间来解决梯度反向传播的问题。

    Generative Adversarial Networks (GAN) is a model for data synthesis, which creates plausible data through the competition of generator and discriminator. Although GAN application to image synthesis is extensively studied, it has inherent limitations to natural language generation. Because natural language is composed of discrete tokens, a generator has difficulty updating its gradient through backpropagation; therefore, most text-GAN studies generate sentences starting with a random token based on a reward system. Thus, the generators of previous studies are pre-trained in an autoregressive way before adversarial training, causing data memorization that synthesized sentences reproduce the training data. In this paper, we synthesize sentences using a framework similar to the original GAN. More specifically, we propose Text Embedding Space Generative Adversarial Networks (TESGAN) which generate continuous text embedding spaces instead of discrete tokens to solve the gradient backpropagat
    
[^59]: 从单语数据源中训练双语和代码切换语音识别模型的方法

    Towards training Bilingual and Code-Switched Speech Recognition models from Monolingual data sources. (arXiv:2306.08753v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2306.08753](http://arxiv.org/abs/2306.08753)

    本文介绍了一种使用纯粹的单语数据源训练双语和代码切换ASR模型的方法。通过引入集合标记器，将LID应用到每个标记，而不是在单语样本边界生成LID，我们展示了集合标记器的有效性，并提出了合成代码切换ASR数据生成技术，证明了所提出的代码切换ASR模型在语音任务中的有效性。

    

    多语言自动语音识别（ASR）模型能够转录多种语言的音频，消除了使用不同模型的需要。此外，它们还能进行语言识别（LID）和处理代码切换语音。然而，训练这些模型需要稀缺的代码切换和多语音数据语料库。本文评估了使用纯粹的单语数据源训练双语和代码切换ASR模型的不同方法。我们引入了集合标记器的概念，它与目前主流技术在单语样本边界生成LID的方法不同，而是为每个发射的标记生成LID。我们比较了双语和单语模型的性能，展示了集合标记器的有效性，提出了一种合成的代码切换ASR数据生成技术，并证明了所提出的代码切换ASR模型在语音任务中的有效性。

    Multilingual Automatic Speech Recognition (ASR) models are capable of transcribing audios across multiple languages, eliminating the need for separate models. In addition, they can perform Language Identification (LID) and handle code-switched speech. However, training these models requires special code-switch and multilingual speech corpora which are sparsely available. In this paper, we evaluate different approaches towards training of bilingual as well as code-switched ASR models using purely monolingual data sources. We introduce the concept of aggregate tokenizers that differs from the current prevalent technique of generating LIDs at the boundaries of monolingual samples and produces LID for each emitted token instead. We compare bilingual and monolingual model performance, showcase the efficacy of aggregate tokenizers, present a synthetic code-switched ASR data generation technique and demonstrate the effectiveness of the proposed code-switched ASR models for the tasks of speech
    
[^60]: LLMatic: 基于大语言模型和多样性优化的神经结构搜索

    LLMatic: Neural Architecture Search via Large Language Models and Quality-Diversity Optimization. (arXiv:2306.01102v1 [cs.NE])

    [http://arxiv.org/abs/2306.01102](http://arxiv.org/abs/2306.01102)

    本文介绍了利用大语言模型和多样性优化算法相结合的 LLMatic 神经结构搜索算法。该算法在CIFAR-10数据集进行测试，仅进行2000次搜索即可产生高性能网络，即使没有该基准领域的先前知识或任何先前的最佳结果的曝光。

    

    大型语言模型 (LLMs) 已成为一种强大的工具，可以完成广泛的任务。它们的能力涵盖了许多领域，它们在代码生成领域产生了重大影响。在此情况下，我们将 LLMs 视为变异和交叉工具。同时，多样性优化算法已知可以发现多样性和稳健的解决方案。通过将 LLMs 的代码生成能力与 QD 解决方案的多样性和鲁棒性相结合，我们引入了 LLMatic，一个神经结构搜索 (NAS) 算法。虽然 LLMs 通过提示直接进行 NAS 考验困难，但 LLMatic 利用程序化方法，利用 QD 来进行提示和网络结构，从而创建多样性和高性能网络。我们在 CIFAR-10 图像分类基准测试中测试了 LLMatic，证明它可以在仅进行 2000 次搜索的情况下产生具有竞争力的网络，即使没有该基准领域的先前知识或任何先前的最佳结果的曝光。

    Large Language Models (LLMs) have emerged as powerful tools capable of accomplishing a broad spectrum of tasks. Their abilities span numerous areas, and one area where they have made a significant impact is in the domain of code generation. In this context, we view LLMs as mutation and crossover tools. Meanwhile, Quality-Diversity (QD) algorithms are known to discover diverse and robust solutions. By merging the code-generating abilities of LLMs with the diversity and robustness of QD solutions, we introduce LLMatic, a Neural Architecture Search (NAS) algorithm. While LLMs struggle to conduct NAS directly through prompts, LLMatic uses a procedural approach, leveraging QD for prompts and network architecture to create diverse and highly performant networks. We test LLMatic on the CIFAR-10 image classification benchmark, demonstrating that it can produce competitive networks with just $2,000$ searches, even without prior knowledge of the benchmark domain or exposure to any previous top-p
    
[^61]: 比你想的要弱：对弱监督学习的批判性研究

    Weaker Than You Think: A Critical Look at Weakly Supervised Learning. (arXiv:2305.17442v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.17442](http://arxiv.org/abs/2305.17442)

    这篇论文批判性地研究了弱监督学习方法，发现这些方法的好处被高估了，大多数优势可以通过简单地利用干净的训练数据实现。

    

    弱监督学习是一种在资源有限的情况下训练机器学习模型的流行方法。它允许使用从各种弱标注源获得的嘈杂标注来训练模型，而不是要求高质量但昂贵的人工标注。最近，许多精巧的方法已经被提出来在标签噪声下进行强大的训练，并报告了令人印象深刻的结果。在本文中，我们重新审视了这些方法的设置，并发现这些方法所带来的好处被显著高估了。具体来说，我们发现现有的弱监督学习方法的成功在很大程度上依赖于可用的干净验证样本，正如我们所展示的，我们可以通过简单地在其上进行训练来更有效地利用这些干净标签。在使用这些干净标签进行训练后，使用这些精巧方法的优势大部分被消除了。即使将可用的干净数据的大小减少到每类只有五个样本，这仍然成立。

    Weakly supervised learning is a popular approach for training machine learning models in low-resource settings. Instead of requesting high-quality yet costly human annotations, it allows training models with noisy annotations obtained from various weak sources. Recently, many sophisticated approaches have been proposed for robust training under label noise, reporting impressive results. In this paper, we revisit the setup of these approaches and find that the benefits brought by these approaches are significantly overestimated. Specifically, we find that the success of existing weakly supervised learning approaches heavily relies on the availability of clean validation samples which, as we show, can be leveraged much more efficiently by simply training on them. After using these clean labels in training, the advantages of using these sophisticated approaches are mostly wiped out. This remains true even when reducing the size of the available clean data to just five samples per class, m
    
[^62]: 面向人类中心的度量评估对话系统

    Human-Centered Metrics for Dialog System Evaluation. (arXiv:2305.14757v1 [cs.CL])

    [http://arxiv.org/abs/2305.14757](http://arxiv.org/abs/2305.14757)

    本文提出了从心理学构造中提取的可解释度量标准，用于评估对话系统，通过情绪熵、语言风格和情感匹配、宜人性和共情等五个度量，这些人类度量标准与现有的自动度量标准不相关且具有更高的预测准确度。

    

    我们提出了一种通过心理学角度来评估对话系统的度量方法：对话代理人像人类一样表达了多种状态（短期因素，如情绪）和特质（更长期因素，如个性）。这些可解释的度量标准由来自已建立的心理学构造的五种度量组成，可以应用于对话和对话中的每个回合：情绪熵，语言风格和情感匹配，以及宜人性和共情。我们将这些人类度量标准与6种最先进的自动度量标准（例如BARTScore和BLEURT）在7个标准对话系统数据集上进行了比较。我们还介绍了一个新颖的数据集，即Three Bot Dialog Evaluation Corpus，其中包含来自ChatGPT、GPT-3和BlenderBot的已注释对话。我们证明了所提出的人类度量标准提供了新颖的信息，与自动度量标准不相关，并可在预测对话系统质量时超越现有的自动度量标准。

    We present metrics for evaluating dialog systems through a psychologically-grounded "human" lens: conversational agents express a diversity of both states (short-term factors like emotions) and traits (longer-term factors like personality) just as people do. These interpretable metrics consist of five measures from established psychology constructs that can be applied both across dialogs and on turns within dialogs: emotional entropy, linguistic style and emotion matching, as well as agreeableness and empathy. We compare these human metrics against 6 state-of-the-art automatic metrics (e.g. BARTScore and BLEURT) on 7 standard dialog system data sets. We also introduce a novel data set, the Three Bot Dialog Evaluation Corpus, which consists of annotated conversations from ChatGPT, GPT-3, and BlenderBot. We demonstrate the proposed human metrics offer novel information, are uncorrelated with automatic metrics, and lead to increased accuracy beyond existing automatic metrics for predictin
    
[^63]: 通过摘要二元性和显式大纲控制增强生成

    Enhancing Generation through Summarization Duality and Explicit Outline Control. (arXiv:2305.14459v1 [cs.CL])

    [http://arxiv.org/abs/2305.14459](http://arxiv.org/abs/2305.14459)

    本文提出了一个两阶段的摘要增强的大纲监督生成框架，能够更好地生成明确和合理的大纲，并引入了一个新颖的显式大纲控制方法以更有效地利用生成的大纲。

    

    自动开放式长文本生成面临语义不连贯和情节不可信的重大挑战。先前的工作通常通过设计无监督任务中的短语或抽象信号的大纲来缓解此问题，但这往往是不稳定且难以解释的。在假设摘要作为已成熟的大纲的情况下，我们介绍了一个两阶段、摘要增强的大纲监督生成框架。该框架利用摘要任务的双重特征来改进大纲预测，从而产生更明确和合理的大纲。此外，我们发现基于大纲的生成具有未充分利用的问题，无论是标准的预训练语言模型（例如GPT-2、BART）还是大型语言模型（例如Vicuna、ChatGPT）。为了解决这个问题，我们提出了一种新颖的显式大纲控制方法，以更有效地利用生成的大纲。

    Automatically open-ended long text generation poses significant challenges due to semantic incoherence and plot implausibility. Previous works usually alleviate this problem through outlines in the form of short phrases or abstractive signals by designing unsupervised tasks, which tend to be unstable and weakly interpretable.  Assuming that a summary serves as a mature outline, we introduce a two-stage, summary-enhanced outline supervised generation framework. This framework leverages the dual characteristics of the summarization task to improve outline prediction, resulting in more explicit and plausible outlines. Furthermore, we identify an underutilization issue in outline-based generation with both standard pretrained language models (e.g., GPT-2, BART) and large language models (e.g., Vicuna, ChatGPT). To address this, we propose a novel explicit outline control method for more effective utilization of generated outlines.
    
[^64]: SPEECH: 基于能量的事件中心超球的结构化预测

    SPEECH: Structured Prediction with Energy-Based Event-Centric Hyperspheres. (arXiv:2305.13617v1 [cs.CL])

    [http://arxiv.org/abs/2305.13617](http://arxiv.org/abs/2305.13617)

    这篇论文提出了一种称为SPEECH的模型，它使用能量建模来表示复杂的事件结构，并使用超球来表示事件类别。实验结果表明，SPEECH在事件检测和事件关系抽取任务中表现出卓越的性能。

    

    事件中心的结构化预测涉及预测事件的结构化输出。在大多数自然语言处理情况下，事件结构都具有复杂的依赖关系，因此有效地表示这些复杂的事件结构是具有挑战性的。为了解决这些问题，我们提出了基于能量的事件中心超球的结构化预测 (SPEECH)。 SPEECH 使用基于能量的建模来模拟事件结构组件之间的复杂依赖关系，并使用简单但有效的超球来表示事件类别。在两个统一标注的事件数据集的实验中，结果表明SPEECH在事件检测和事件关系抽取任务中占优势。

    Event-centric structured prediction involves predicting structured outputs of events. In most NLP cases, event structures are complex with manifold dependency, and it is challenging to effectively represent these complicated structured events. To address these issues, we propose Structured Prediction with Energy-based Event-Centric Hyperspheres (SPEECH). SPEECH models complex dependency among event structured components with energy-based modeling, and represents event classes with simple but effective hyperspheres. Experiments on two unified-annotated event datasets indicate that SPEECH is predominant in event detection and event-relation extraction tasks.
    
[^65]: 大型语言模型能够模拟语境不明结构化访谈的归纳式主题分析吗？对方法和模型的局限性进行探讨和挑战

    Can Large Language Models emulate an inductive Thematic Analysis of semi-structured interviews? An exploration and provocation on the limits of the approach and the model. (arXiv:2305.13014v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.13014](http://arxiv.org/abs/2305.13014)

    本文介绍了一项实验的结果和反思，该实验使用模型GPT 3.5-Turbo来模拟归纳式主题分析的某些方面。尝试使用LLM进行基于人类解释的分析显然是一种挑战，但也是了解这些系统在定性研究中能否使用的一种方式。

    

    大型语言模型（LLMs）已成为强大的生成人工智能解决方案，可应用于多个领域和工作领域。本文介绍了一项实验的结果和反思，该实验使用模型GPT 3.5-Turbo来模拟归纳式主题分析的某些方面。先前的研究在该主题上主要进行演绎分析。主题分析是一种在社会科学中常用的定性分析方法，它基于人类分析师的解释以及定性数据中的显式和潜在含义的识别。尝试使用LLM进行基于人类解释的分析显然是一种挑战，但也是了解这些系统在定性研究中能否使用的一种方式。本文介绍了尝试进行此模拟的动机，并反思了Braun和Clarke提出的六个步骤至少部分地如何进行主题分析的方法。

    Large Language Models (LLMs) have emerged as powerful generative Artificial Intelligence solutions which can be applied to several fields and areas of work. This paper presents results and reflection of an experiment done to use the model GPT 3.5-Turbo to emulate some aspects of an inductive Thematic Analysis. Previous research on this subject has largely worked on conducting deductive analysis. Thematic Analysis is a qualitative method for analysis commonly used in social sciences and it is based on interpretations made by the human analyst(s) and the identification of explicit and latent meanings in qualitative data. Attempting an analysis based on human interpretation with an LLM clearly is a provocation but also a way to learn something about how these systems can or cannot be used in qualitative research. The paper presents the motivations for attempting this emulation, it reflects on how the six steps to a Thematic Analysis proposed by Braun and Clarke can at least partially be r
    
[^66]: 解耦参数中的知识：可插拔语言模型的新方法

    Decouple knowledge from paramters for plug-and-play language modeling. (arXiv:2305.11564v1 [cs.CL])

    [http://arxiv.org/abs/2305.11564](http://arxiv.org/abs/2305.11564)

    本文介绍了一种新的插件式预训练模型，其与模型参数中的知识存储分离，采用可编辑和可扩展的键值存储器，通过DPM中的知识检索以可解释的方式利用知识。

    

    预训练语言模型（PLM）在各种NLP任务中取得了令人印象深刻的成果。 揭示了这些模型成功的关键因素之一是这些模型的参数在预训练期间隐含地学习了各种知识。 然而，将知识隐含在模型参数中具有两个基本缺点。 首先，在模型训练后，无法编辑或扩展知识，特别是在知识不断发展的情况下，这是一个严重的问题。 其次，它缺乏可解释性并阻止人们了解PLM在某个问题上所需的哪些知识。 在本文中，我们介绍PlugLM，这是一种具有可微分插件存储器（DPM）的预训练模型。 关键的直觉是使用可编辑和可扩展的键值存储器将知识存储与模型参数分离，并通过DPM中的知识检索以可解释的方式利用知识。为了证明这种设计选择的合理性，我们在三个设置中进行评估，这些设置需要各种形式的知识：（1）领域适应，（2）未见实体合并，以及（3）在不遗忘旧任务的情况下适应新任务。

    Pre-trained language models(PLM) have made impressive results in various NLP tasks. It has been revealed that one of the key factors to their success is the parameters of these models implicitly learn all kinds of knowledge during pre-training. However, encoding knowledge implicitly in the model parameters has two fundamental drawbacks. First, the knowledge is neither editable nor scalable once the model is trained, which is especially problematic in that knowledge is consistently evolving. Second, it lacks interpretability and prevents humans from understanding which knowledge PLM requires for a certain problem. In this paper, we introduce PlugLM, a pre-training model with differentiable plug-in memory(DPM). The key intuition is to decouple the knowledge storage from model parameters with an editable and scalable key-value memory and leverage knowledge in an explainable manner by knowledge retrieval in the DPM. To justify this design choice, we conduct evaluations in three settings in
    
[^67]: 从弱文本监督中学习图像中的人际互动

    Learning Human-Human Interactions in Images from Weak Textual Supervision. (arXiv:2304.14104v1 [cs.CV])

    [http://arxiv.org/abs/2304.14104](http://arxiv.org/abs/2304.14104)

    本文提出了一种新的范式，从单一的静态图像中学习自由文本的形式来灵活建模人际互动。并通过知识蒸馏生成伪标签来训练一种字幕模型，用于有效理解图像中的人际互动，具有较高的预测文本和语义质量，并在此任务上优于SOTA的图像字幕和情境识别模型。

    

    人际互动是多样且依赖于上下文的，但先前的工作将它们视为分类，忽略了可能的互动的重尾。本文提出了一种新的学习人际互动的范式，将其作为自由文本从单一的静态图像中学习，从而允许对情况和人际关系的无限空间进行灵活建模。为了克服缺乏特定于此任务的标记数据的问题，我们使用知识蒸馏应用于由大型语言模型产生的合成字幕数据，以此生成伪标签。我们展示了通过这个过程产生的伪标签可以用于训练一种字幕模型，能有效理解图像中的人际互动，通过衡量我们预测的文本和语义质量与事实的基础性的各种指标来衡量。我们进一步展示了我们的方法在这个任务上的性能优于SOTA的图像字幕和情境识别模型。我们将公开我们的代码。

    Interactions between humans are diverse and context-dependent, but previous works have treated them as categorical, disregarding the heavy tail of possible interactions. We propose a new paradigm of learning human-human interactions as free text from a single still image, allowing for flexibility in modeling the unlimited space of situations and relationships between people. To overcome the absence of data labelled specifically for this task, we use knowledge distillation applied to synthetic caption data produced by a large language model without explicit supervision. We show that the pseudo-labels produced by this procedure can be used to train a captioning model to effectively understand human-human interactions in images, as measured by a variety of metrics that measure textual and semantic faithfulness and factual groundedness of our predictions. We further show that our approach outperforms SOTA image captioning and situation recognition models on this task. We will release our c
    
[^68]: AGIEval：一个以人为中心的基准评估基础模型的工具

    AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models. (arXiv:2304.06364v1 [cs.CL])

    [http://arxiv.org/abs/2304.06364](http://arxiv.org/abs/2304.06364)

    AGIEval是一个以人为中心设计的基准测试工具，用于评估基础模型在人类中心标准化考试上的表现。GPT-4在SAT、LSAT和数学比赛方面超越了人类平均表现，展示了当代基础模型在人类级任务中的非凡性能。

    

    评估基础模型解决人类级别任务的通用能力是它们在发展和应用AGI（人工通用智能）中的重要方面。传统基准测试依赖于人造数据集，可能无法准确代表人类水平能力。在本文中，我们介绍了AGIEval，一个专门设计用于评估基础模型在人类中心标准化考试的基准测试工具，例如大学入学考试，法律学校入学考试，数学竞赛和律师资格考试。我们使用这个基准测试工具评估了几种最先进的基础模型，包括 GPT-4，ChatGPT 和Text-Davinci-003。令人印象深刻的是，GPT-4在SAT、LSAT和数学比赛方面超越了人类平均表现，SAT数学测试的准确率达到了95%，在中国国家大学英语考试的英语测试中准确率也达到了92.5%。这展示了当代基础模型在人类级任务中的非凡性能，并凸显了AGI未来发展的潜力。

    Evaluating the general abilities of foundation models to tackle human-level tasks is a vital aspect of their development and application in the pursuit of Artificial General Intelligence (AGI). Traditional benchmarks, which rely on artificial datasets, may not accurately represent human-level capabilities. In this paper, we introduce AGIEval, a novel benchmark specifically designed to assess foundation model in the context of human-centric standardized exams, such as college entrance exams, law school admission tests, math competitions, and lawyer qualification tests. We evaluate several state-of-the-art foundation models, including GPT-4, ChatGPT, and Text-Davinci-003, using this benchmark. Impressively, GPT-4 surpasses average human performance on SAT, LSAT, and math competitions, attaining a 95% accuracy rate on the SAT Math test and a 92.5% accuracy on the English test of the Chinese national college entrance exam. This demonstrates the extraordinary performance of contemporary fou
    
[^69]: Bipol: 一种具有可解释性的新型自然语言处理多轴偏见评估度量

    Bipol: A Novel Multi-Axes Bias Evaluation Metric with Explainability for NLP. (arXiv:2304.04029v1 [cs.CL])

    [http://arxiv.org/abs/2304.04029](http://arxiv.org/abs/2304.04029)

    本文创造了一种新的度量标准 bipol 以检测文本数据中的社交偏见。该标准包括语料库级别评估和句子级别评估两个步骤，并使用 SotA 架构创建了新模型以检测多个轴的偏差。同时，作者还创造了一个大型数据集来训练偏见检测模型，并公开了相关代码。

    

    我们引入了一种新的、具有可解释性的度量标准 bipol，用于估算文本数据中的社交偏见。有害偏见在许多在线数据源中普遍存在，这些数据源用于训练机器学习（ML）模型。我们创造了一种新的度量标准，包括两个步骤：基于模型分类的语料库级别评估和基于（敏感）词频（TF）的句子级别评估。我们使用SotA架构创建了新模型，以检测沿多个轴的偏差，并评估了两个流行的NLP数据集（COPA和SQUAD）。作为附加贡献，我们创建了一个大型数据集（几乎有200万个带标签的样本），用于训练偏见检测模型，并公开了它。我们还公开了代码。

    We introduce bipol, a new metric with explainability, for estimating social bias in text data. Harmful bias is prevalent in many online sources of data that are used for training machine learning (ML) models. In a step to address this challenge we create a novel metric that involves a two-step process: corpus-level evaluation based on model classification and sentence-level evaluation based on (sensitive) term frequency (TF). After creating new models to detect bias along multiple axes using SotA architectures, we evaluate two popular NLP datasets (COPA and SQUAD). As additional contribution, we created a large dataset (with almost 2 million labelled samples) for training models in bias detection and make it publicly available. We also make public our codes.
    
[^70]: 无需重新训练的Transformer模型分块压缩

    Blockwise Compression of Transformer-based Models without Retraining. (arXiv:2304.01483v1 [cs.CL])

    [http://arxiv.org/abs/2304.01483](http://arxiv.org/abs/2304.01483)

    本论文提出了一种名为BCT的分块压缩框架，可以对整个Transformer模型进行更细粒度的压缩，实现了降低部署门槛的目的。

    

    基于Transformer模型的GPT-3、ChatGPT和GPT-4近年来备受关注，但它们的巨大计算资源和存储开销仍然是不可避免的挑战。为了解决这个问题，我们提出了一种名为BCT的分块压缩框架，可以对整个Transformer模型进行更细粒度的压缩，包括嵌入、矩阵乘法、GELU、Softmax、层规范化以及所有中间结果。我们对一个高效模型使用BCT进行了压缩并在多个GLUE数据集上进行了评估，结果显示在大多数任务中，BCT只会带来少于0.90%的准确率下降。

    Transformer-based models, represented by GPT-3, ChatGPT, and GPT-4, have recently attracted increasing interest, research enthusiasm, and business demand. However, their massive computation resources and huge memory footprint are inevitable challenges. To tackle this issue, we propose BCT, a framework of blockwise compression for transformers without retraining, to lower deployment thresholds. BCT achieves more fine-grained compression of the whole transformer, including embedding, matrix multiplication, GELU, Softmax, layer normalization, and all the intermediate results. As a case, we compress an efficient model with BCT and evaluate it on several General Language Understanding Evaluation (GLUE) datasets. The results show that BCT can achieve a less than 0.90% accuracy drop in most tasks.
    
[^71]: 探索大型语言模型在无参考文本质量评估中的应用：初步实证研究

    Exploring the Use of Large Language Models for Reference-Free Text Quality Evaluation: A Preliminary Empirical Study. (arXiv:2304.00723v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.00723](http://arxiv.org/abs/2304.00723)

    本文介绍了大型语言模型在无参考文本质量评估中的应用研究。研究结果表明，利用ChatGPT生成的显式得分是最有效和可靠的方法。

    

    在自然语言处理中，评估生成文本的质量是一个具有挑战性的任务，由于文本的固有复杂性和多样性而产生困难。最近，OpenAI的ChatGPT，一种强大的大型语言模型（LLM），由于其在各种任务中的出色表现而引起了广泛关注。因此，我们发布此报告，以调查LLMs，特别是ChatGPT的有效性，并探索优化它们在评估文本质量方面的应用方式。我们比较了基于ChatGPT或类似LLMs的三种无参考评估方法。实验结果证明，ChatGPT能够有效地从各个角度评估文本质量而不需要参考，并展示了比大多数现有自动指标更好的性能。特别是，显式得分是利用ChatGPT生成衡量文本质量的数字分数的最有效和可靠的方法。然而，直接将LLMs应用于文本质量评估仍然面临挑战和限制，需要进一步探索和改进。

    Evaluating the quality of generated text is a challenging task in natural language processing. This difficulty arises from the inherent complexity and diversity of text. Recently, OpenAI's ChatGPT, a powerful large language model (LLM), has garnered significant attention due to its impressive performance in various tasks. Therefore, we present this report to investigate the effectiveness of LLMs, especially ChatGPT, and explore ways to optimize their use in assessing text quality. We compared three kinds of reference-free evaluation methods based on ChatGPT or similar LLMs. The experimental results prove that ChatGPT is capable to evaluate text quality effectively from various perspectives without reference and demonstrates superior performance than most existing automatic metrics. In particular, the Explicit Score, which utilizes ChatGPT to generate a numeric score measuring text quality, is the most effective and reliable method among the three exploited approaches. However, directly
    
[^72]: 虚拟代理人的端到端口语化实体提取

    E2E Spoken Entity Extraction for Virtual Agents. (arXiv:2302.10186v4 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2302.10186](http://arxiv.org/abs/2302.10186)

    本文研究了利用预训练语音编码器从语音中直接提取实体的方法，无需文本转录，且在口语实体识别任务中表现优异。

    

    本文重新构想了语音处理中的一些方面，特别是关于从语音中直接提取实体，而无需中间文本表示。在人与计算机的对话中，从语音中提取实体，如姓名、邮政地址和电子邮件地址，是一项具有挑战性的任务。我们研究了微调预训练语音编码器对从语音中直接提取可读性强的实体的影响，而无需进行文本转录。我们说明这种直接方法优化了编码器，以仅转录语音中与实体相关的部分，忽略了多余的部分，如搭档语或实体拼写。在企业虚拟代理人的对话上下文中，我们展示了一步法的方法优于典型的两步法，即首先产生词汇转录，然后进行基于文本的实体提取以识别口语实体。

    This paper reimagines some aspects of speech processing using speech encoders, specifically about extracting entities directly from speech, with no intermediate textual representation. In human-computer conversations, extracting entities such as names, postal addresses and email addresses from speech is a challenging task. In this paper, we study the impact of fine-tuning pre-trained speech encoders on extracting spoken entities in human-readable form directly from speech without the need for text transcription. We illustrate that such a direct approach optimizes the encoder to transcribe only the entity relevant portions of speech, ignoring the superfluous portions such as carrier phrases and spellings of entities. In the context of dialogs from an enterprise virtual agent, we demonstrate that the 1-step approach outperforms the typical 2-step cascade of first generating lexical transcriptions followed by text-based entity extraction for identifying spoken entities.
    
[^73]: 使用指针生成网络和SciBERT嵌入生成研究论文的摘要

    Generation of Highlights from Research Papers Using Pointer-Generator Networks and SciBERT Embeddings. (arXiv:2302.07729v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.07729](http://arxiv.org/abs/2302.07729)

    该论文提出了一种使用指针生成网络和SciBERT嵌入来自动生成研究论文亮点的方法。在多个基准数据集上的实验证明，该模型在研究亮点生成方面具有最佳性能。

    

    如今，许多研究文章都以研究亮点作为前言，以总结论文的主要发现。亮点不仅帮助研究人员准确快速地识别论文的贡献，还通过搜索引擎增加了文章的可发现性。我们的目标是在给定研究论文的特定段落的情况下自动构建研究亮点。我们使用了一个具有覆盖机制和上下文嵌入层的指针生成网络，将输入标记编码为SciBERT嵌入。我们在基准数据集CSPubSum上测试了我们的模型，并且还提出了MixSub，一个用于自动生成研究亮点的新的跨学科论文语料库。对于CSPubSum和MixSub，我们观察到所提出的模型相对于相关变体和文献中提出的其他模型来说具有最佳性能。在CSPubSum数据集上，我们的模型在只使用论文的摘要作为输入时表现最佳。

    Nowadays many research articles are prefaced with research highlights to summarize the main findings of the paper. Highlights not only help researchers precisely and quickly identify the contributions of a paper, they also enhance the discoverability of the article via search engines. We aim to automatically construct research highlights given certain segments of a research paper. We use a pointer-generator network with coverage mechanism and a contextual embedding layer at the input that encodes the input tokens into SciBERT embeddings. We test our model on a benchmark dataset, CSPubSum, and also present MixSub, a new multi-disciplinary corpus of papers for automatic research highlight generation. For both CSPubSum and MixSub, we have observed that the proposed model achieves the best performance compared to related variants and other models proposed in the literature. On the CSPubSum dataset, our model achieves the best performance when the input is only the abstract of a paper as op
    
[^74]: Bipol: 在基准数据集中用可解释性的方式评估多个维度的偏差

    Bipol: Multi-axes Evaluation of Bias with Explainability in Benchmark Datasets. (arXiv:2301.12139v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.12139](http://arxiv.org/abs/2301.12139)

    本研究使用一种新的多维度偏差度量指标bipol，评估了五个英文和两个瑞典的自然语言处理基准数据集中的偏差，并提供了一个新的、包含200万个样本的瑞典偏差标注数据集和用于瑞典偏差检测的多维度词库。

    

    本研究探究了五个英文自然语言处理基准数据集（在superGLUE榜单上），以及两个瑞典数据集的偏差性质，涉及多个维度。这些数据集包括：布尔问题（Boolq）、承诺银行（CB）、Winograd模式挑战（WSC）、Wino-gender诊断（AXg）、文本蕴含识别（RTE）、瑞典CB和SWEDN。偏差可能具有害处，并且已知常见于机器学习模型所学习的数据中。为了减轻数据中的偏差，能够客观估计偏差是至关重要的。我们使用一种新颖的多维度偏差度量指标bipol，并解释该数据集中存在多少偏差。跨语言、多维度的偏差评估并不常见。因此，我们还贡献了一个新的、包含200万个样本的瑞典偏差标注数据集，该数据集是从英文版本翻译而来，并在其中使用了最先进的mT5模型进行训练。此外，我们还为瑞典偏差检测提供了新的多维度词库。我们将代码、模型和新数据集公开发布。

    We investigate five English NLP benchmark datasets (on the superGLUE leaderboard) and two Swedish datasets for bias, along multiple axes. The datasets are the following: Boolean Question (Boolq), CommitmentBank (CB), Winograd Schema Challenge (WSC), Wino-gender diagnostic (AXg), Recognising Textual Entailment (RTE), Swedish CB, and SWEDN. Bias can be harmful and it is known to be common in data, which ML models learn from. In order to mitigate bias in data, it is crucial to be able to estimate it objectively. We use bipol, a novel multi-axes bias metric with explainability, to estimate and explain how much bias exists in these datasets. Multilingual, multi-axes bias evaluation is not very common. Hence, we also contribute a new, large Swedish bias-labelled dataset (of 2 million samples), translated from the English version and train the SotA mT5 model on it. In addition, we contribute new multi-axes lexica for bias detection in Swedish. We make the codes, model, and new dataset publicl
    
[^75]: 适用于所有领域的一个模型：基于协作域前缀调整的跨领域实体识别

    One Model for All Domains: Collaborative Domain-Prefix Tuning for Cross-Domain NER. (arXiv:2301.10410v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.10410](http://arxiv.org/abs/2301.10410)

    本论文提出了基于协作域前缀调整的跨领域实体识别，使用文本到文本生成的支撑领域相关指导来将知识转移至新域NER任务，避免了先前的为每个领域结束一个全新的NER模型的问题。

    

    解决实际场景中低资源问题是跨领域实体识别的一个挑战性任务。先前典型的解决方案主要通过使用来自丰富资源领域的数据进行预训练语言模型(PLMs)获得NER模型并将其适应于目标领域。由于不同领域实体类型之间的不匹配问题，先前的方法通常调整所有PLMs的参数，从而为每个领域结束一个全新的NER模型。此外，当前的模型只关注于利用一个普通来源领域中的知识，而未能成功地将来自多个来源领域的知识转移到目标上。为了解决这些问题，我们基于文本到文本生成的PLM引入了协作域前缀调整跨领域NER(CP-NER)。具体来说，我们呈现了用于文本到文本生成的支撑领域相关指导来将知识转移至新域NER任务而无需结构修改。我们利用冻结的PLMs并进行协作域前缀调整。

    Cross-domain NER is a challenging task to address the low-resource problem in practical scenarios. Previous typical solutions mainly obtain a NER model by pre-trained language models (PLMs) with data from a rich-resource domain and adapt it to the target domain. Owing to the mismatch issue among entity types in different domains, previous approaches normally tune all parameters of PLMs, ending up with an entirely new NER model for each domain. Moreover, current models only focus on leveraging knowledge in one general source domain while failing to successfully transfer knowledge from multiple sources to the target. To address these issues, we introduce Collaborative Domain-Prefix Tuning for cross-domain NER (CP-NER) based on text-to-text generative PLMs. Specifically, we present text-to-text generation grounding domain-related instructors to transfer knowledge to new domain NER tasks without structural modifications. We utilize frozen PLMs and conduct collaborative domain-prefix tuning
    
[^76]: 使用语言模型提示进行推理：一项调查

    Reasoning with Language Model Prompting: A Survey. (arXiv:2212.09597v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09597](http://arxiv.org/abs/2212.09597)

    本文提供了使用语言模型提示进行推理的前沿研究综合调查。讨论了新兴推理能力出现的潜在原因，并提供系统资源帮助初学者。

    

    推理作为复杂问题解决的重要能力，可以为医疗诊断、谈判等各种实际应用提供后端支持。本文对使用语言模型提示进行推理的前沿研究进行了综合调查。我们介绍了研究成果的比较和总结，并提供了系统资源以帮助初学者。我们还讨论了新兴推理能力出现的潜在原因，并突出了未来的研究方向。资源可在 https://github.com/zjunlp/Prompt4ReasoningPapers 上获取（定期更新）。

    Reasoning, as an essential ability for complex problem-solving, can provide back-end support for various real-world applications, such as medical diagnosis, negotiation, etc. This paper provides a comprehensive survey of cutting-edge research on reasoning with language model prompting. We introduce research works with comparisons and summaries and provide systematic resources to help beginners. We also discuss the potential reasons for emerging such reasoning abilities and highlight future research directions. Resources are available at https://github.com/zjunlp/Prompt4ReasoningPapers (updated periodically).
    
[^77]: VRDU：面向视觉丰富的文档理解的基准测试

    VRDU: A Benchmark for Visually-rich Document Understanding. (arXiv:2211.15421v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.15421](http://arxiv.org/abs/2211.15421)

    本研究提出了一个名为VRDU的基准测试，以更全面地反映实际文档的复杂性，其中包含具有挑战性的丰富模式、复杂模板和多样的布局。该基准测试可用于评估文档中提取结构化数据的模型。

    

    理解丰富视觉化业务文档以提取结构化数据和自动化业务工作流程在学术界和工业界都受到关注。虽然最近的多模式语言模型取得了令人印象深刻的成果，但我们发现现有的基准测试不反映工业中实际文档的复杂性。在这项工作中，我们确定了更全面的基准测试的必要条件，并提出了一个称为Visually Rich Document Understanding (VRDU)的基准测试。VRDU包含两个数据集，代表了多种挑战：丰富的模式，包括各种数据类型以及分层实体; 复杂的模板，包括表格和多列布局; 以及单个文档类型中不同布局（模板）的多样性。我们设计了少样本和常规实验设置，以及一个精心设计的匹配算法来评估提取结果。我们报告了强基线的性能，并提供了三个观察结果：(1)通用n的推广。

    Understanding visually-rich business documents to extract structured data and automate business workflows has been receiving attention both in academia and industry. Although recent multi-modal language models have achieved impressive results, we find that existing benchmarks do not reflect the complexity of real documents seen in industry. In this work, we identify the desiderata for a more comprehensive benchmark and propose one we call Visually Rich Document Understanding (VRDU). VRDU contains two datasets that represent several challenges: rich schema including diverse data types as well as hierarchical entities, complex templates including tables and multi-column layouts, and diversity of different layouts (templates) within a single document type. We design few-shot and conventional experiment settings along with a carefully designed matching algorithm to evaluate extraction results. We report the performance of strong baselines and offer three observations: (1) generalizing to n
    
[^78]: 生成式知识图谱构建综述

    Generative Knowledge Graph Construction: A Review. (arXiv:2210.12714v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.12714](http://arxiv.org/abs/2210.12714)

    本文综述了生成式知识图谱构建领域的最新进展，包括方法分类和优劣分析，并提出了未来的研究方向。

    

    生成式知识图谱构建（KGC）是指利用序列到序列框架构建灵活且可适用于广泛任务的知识图谱。本研究总结了生成式知识图谱构建领域中近期的重要进展，对不同的生成目标从理论和实证分析角度分别讨论了各种方法的优势和不足，并提出了未来有潜力的研究方向。我们的贡献有三个方面：（1）我们提供了生成式KGC方法的详细、完整的分类体系；（2）我们对生成式KGC方法进行了理论和实证分析；（3）我们提出了几个未来可以发展的研究方向。

    Generative Knowledge Graph Construction (KGC) refers to those methods that leverage the sequence-to-sequence framework for building knowledge graphs, which is flexible and can be adapted to widespread tasks. In this study, we summarize the recent compelling progress in generative knowledge graph construction. We present the advantages and weaknesses of each paradigm in terms of different generation targets and provide theoretical insight and empirical analysis. Based on the review, we suggest promising research directions for the future. Our contributions are threefold: (1) We present a detailed, complete taxonomy for the generative KGC methods; (2) We provide a theoretical and empirical analysis of the generative KGC methods; (3) We propose several research directions that can be developed in the future.
    
[^79]: 以架构感知参考作为提示提高了数据有效的知识图谱构建

    Schema-aware Reference as Prompt Improves Data-Efficient Knowledge Graph Construction. (arXiv:2210.10709v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.10709](http://arxiv.org/abs/2210.10709)

    提出了一种以检索增强的架构感知参考作为提示的方法，可动态利用人类注释和弱监督数据所继承的架构和知识，指导生成具有更好语义连贯性和一致性的结构化知识，从而在数据效率和知识质量方面具有优越性。

    

    随着预训练语言模型的发展，许多基于提示的方法被提出并在数据有效的知识图谱构建中取得了令人瞩目的表现。然而，现有的基于提示的学习方法仍存在几个潜在的限制：（i）自然语言和预定义模式的输出结构化知识之间的语义差距，这意味着模型无法充分利用受限模板的语义知识；（ii）基于局部个体实例的表示学习限制了性能，给定了不充足的特征，这些特征不能释放预先训练语言模型的潜在类比能力。受这些观察的启发，我们提出了一种检索增强的方法，使用检索得到的架构感知参考作为提示，提高了数据有效的知识图谱构建的语义连贯性和一致性。在两个标准数据集上的实验结果表明，相比现有的基于提示和非提示的方法，我们提出的方法在数据效率和知识质量方面具有优越性。

    With the development of pre-trained language models, many prompt-based approaches to data-efficient knowledge graph construction have been proposed and achieved impressive performance. However, existing prompt-based learning methods for knowledge graph construction are still susceptible to several potential limitations: (i) semantic gap between natural language and output structured knowledge with pre-defined schema, which means model cannot fully exploit semantic knowledge with the constrained templates; (ii) representation learning with locally individual instances limits the performance given the insufficient features, which are unable to unleash the potential analogical capability of pre-trained language models. Motivated by these observations, we propose a retrieval-augmented approach, which retrieves schema-aware Reference As Prompt (RAP), for data-efficient knowledge graph construction. It can dynamically leverage schema and knowledge inherited from human-annotated and weak-supe
    
[^80]: 实现真实低资源关系抽取: 针对具有实证基准研究的论文

    Towards Realistic Low-resource Relation Extraction: A Benchmark with Empirical Baseline Study. (arXiv:2210.10678v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.10678](http://arxiv.org/abs/2210.10678)

    本文针对低资源环境中的关系抽取进行了实证研究，并提出了三种方案来提高性能，包括使用提示方法、平衡方法和数据增强技术。通过对8个关系抽取数据集的广泛比较，实验结果表明，虽然基于提示的调整有益于低资源关系抽取，但仍有改进空间，尤其是跨句子上下文中的多个关系三元组的抽取。

    

    本文提出了一项针对低资源环境中构建关系抽取系统的实证研究。基于最近的预训练语言模型，我们全面调查了三种方案来评估低资源环境下的性能：(i) 使用少量标记数据的不同类型的提示方法； (ii) 多样化的平衡方法来解决长尾分布问题； (iii) 数据增强技术和自训练来生成更多领域内标记数据。我们创建了一个包含8个关系抽取(RE) 数据集的基准，涵盖了不同的语言、领域和上下文，并对所提出的方案进行了广泛的比较。我们的实验证明：(i) 虽然基于提示的调整在低资源关系抽取中是有益的，但仍有很大的改进潜力，特别是在提取跨句子上下文中的多个关系三元组方面； (ii) 平衡方法并不总是有助于长尾分布的关系抽取。

    This paper presents an empirical study to build relation extraction systems in low-resource settings. Based upon recent pre-trained language models, we comprehensively investigate three schemes to evaluate the performance in low-resource settings: (i) different types of prompt-based methods with few-shot labeled data; (ii) diverse balancing methods to address the long-tailed distribution issue; (iii) data augmentation technologies and self-training to generate more labeled in-domain data. We create a benchmark with 8 relation extraction (RE) datasets covering different languages, domains and contexts and perform extensive comparisons over the proposed schemes with combinations. Our experiments illustrate: (i) Though prompt-based tuning is beneficial in low-resource RE, there is still much potential for improvement, especially in extracting relations from cross-sentence contexts with multiple relational triples; (ii) Balancing methods are not always helpful for RE with long-tailed distr
    
[^81]: 使用Word2Vec进行主题的时间分析

    Temporal Analysis on Topics Using Word2Vec. (arXiv:2209.11717v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.11717](http://arxiv.org/abs/2209.11717)

    本研究提出了一种使用Word2Vec进行主题的时间分析的新方法，该方法通过建模主题的移动并利用k均值聚类和余弦相似度对距离进行分组，实现了识别和可视化主题随时间变化的趋势。

    

    本研究提出了一种新颖的趋势检测和可视化方法，具体来说，是对主题随时间变化进行建模。目前用于识别和可视化趋势的模型仅基于使用的随机计数来传达单词的流行程度，而本研究的方法则展示了主题的流行程度和发展方向。在本案例中，这个方向是所选语料库中的一个独特子主题。这些趋势是通过使用k均值聚类和余弦相似度对簇之间的距离进行分组来建模主题的移动而产生的。在收敛的情况下，可以推断整体主题正在融合（主题之间的标记变得可互换）。相反，分散的情况则意味着每个主题的标记在相同的上下文中不会被发现（单词之间越来越不同）。该方法在一个群体上进行了测试

    The present study proposes a novel method of trend detection and visualization - more specifically, modeling the change in a topic over time. Where current models used for the identification and visualization of trends only convey the popularity of a singular word based on stochastic counting of usage, the approach in the present study illustrates the popularity and direction that a topic is moving in. The direction in this case is a distinct subtopic within the selected corpus. Such trends are generated by modeling the movement of a topic by using k-means clustering and cosine similarity to group the distances between clusters over time. In a convergent scenario, it can be inferred that the topics as a whole are meshing (tokens between topics, becoming interchangeable). On the contrary, a divergent scenario would imply that each topics' respective tokens would not be found in the same context (the words are increasingly different to each other). The methodology was tested on a group o
    
[^82]: 树的平面线性化中边长度的期望和：理论与应用

    The expected sum of edge lengths in planar linearizations of trees. Theory and applications. (arXiv:2207.05564v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2207.05564](http://arxiv.org/abs/2207.05564)

    本论文研究了在树的平面线性化中边长度的期望和，提出了一个计算平面排列的方法，并分析了平面排列与投影排列之间的关系。

    

    依赖树已被证明是表示人类语言句子的句法结构的非常成功的模型。在这些结构中，顶点是单词，边连接语法相关的单词。使用随机基线来计算边长度之和或其变体，已经证明了这些依赖关系的倾向是短的。一个普遍存在的基线是在投影排序中的期望和（其中边不相交，并且句子的根词没有被任何边覆盖），可以在$O(n)$时间内计算得到。在这里，我们关注一个较弱的形式约束，即平面性。在理论领域，我们提出了一个刻画平面性的方法，给定一个句子，可以得到平面排列的数量或以均匀随机方式生成平面排列的有效算法。我们还展示了平面排列中的期望总和与投影排列中的期望总和之间的关系。

    Dependency trees have proven to be a very successful model to represent the syntactic structure of sentences of human languages. In these structures, vertices are words and edges connect syntactically-dependent words. The tendency of these dependencies to be short has been demonstrated using random baselines for the sum of the lengths of the edges or its variants. A ubiquitous baseline is the expected sum in projective orderings (wherein edges do not cross and the root word of the sentence is not covered by any edge), that can be computed in time $O(n)$. Here we focus on a weaker formal constraint, namely planarity. In the theoretical domain, we present a characterization of planarity that, given a sentence, yields either the number of planar permutations or an efficient algorithm to generate uniformly random planar permutations of the words. We also show the relationship between the expected sum in planar arrangements and the expected sum in projective arrangements. In the domain of a
    
[^83]: 混合Transformer与多级融合用于多模态知识图谱补全

    Hybrid Transformer with Multi-level Fusion for Multimodal Knowledge Graph Completion. (arXiv:2205.02357v5 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.02357](http://arxiv.org/abs/2205.02357)

    本文提出了一种混合Transformer与多级融合的方法，用于解决多模态知识图谱补全的问题。该方法通过统一的输入-输出架构适用于多样的任务，同时利用多级融合将视觉和文本表示集成起来。

    

    最近，多模态知识图谱（MKG）在信息检索、问答和推荐系统等任务中取得了成功，MKG组织了视觉-文本事实知识。然而，由于大多数MKG都不完整，因此提出了广泛的知识图谱补全研究，重点关注多模态实体、关系提取和链接预测。本文针对这些问题提出了一种混合Transformer与多级融合的方法。具体来说，我们利用一种混合Transformer架构和统一的输入-输出来完成多样的多模态知识图谱补全任务。此外，我们提出了多级融合，通过粗粒度前缀引导交互和细粒度相关感知将视觉和文本表示集成起来。

    Multimodal Knowledge Graphs (MKGs), which organize visual-text factual knowledge, have recently been successfully applied to tasks such as information retrieval, question answering, and recommendation system. Since most MKGs are far from complete, extensive knowledge graph completion studies have been proposed focusing on the multimodal entity, relation extraction and link prediction. However, different tasks and modalities require changes to the model architecture, and not all images/objects are relevant to text input, which hinders the applicability to diverse real-world scenarios. In this paper, we propose a hybrid transformer with multi-level fusion to address those issues. Specifically, we leverage a hybrid transformer architecture with unified input-output for diverse multimodal knowledge graph completion tasks. Moreover, we propose multi-level fusion, which integrates visual and text representation via coarse-grained prefix-guided interaction and fine-grained correlation-aware f
    
[^84]: 提升虚假新闻缓解：来自分享者社交媒体帖子历史的洞察力

    Empowering Fake-News Mitigation: Insights from Sharers' Social Media Post-Histories. (arXiv:2203.10560v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2203.10560](http://arxiv.org/abs/2203.10560)

    本论文提出消费者的社交媒体帖子历史是研究分享虚假新闻动机的一种被低估的数据来源。通过对帖子历史提取的文本线索，我们发现虚假新闻分享者在言辞上更多涉及愤怒、宗教和权力。并且，通过将帖子历史中的文本线索加入模型，可以提高预测分享虚假新闻的准确性。此外，通过激活宗教价值观和减少愤怒，可以减少虚假新闻的分享和更广泛的分享。

    

    虚假信息是一个全球性问题，限制其传播对保护民主、公共卫生和消费者至关重要。我们认为消费者自己的社交媒体帖子历史是一个被低估的数据来源，用于研究是什么导致他们分享虚假新闻链接。在第一项研究中，我们探讨了从帖子历史中提取的文本线索如何区分虚假新闻的分享者和随机社交媒体用户以及其他在误导信息生态系统中的人。在两个数据集中，我们发现虚假新闻的分享者使用更多与愤怒、宗教和权力相关的词汇。在第二项研究中，我们展示了从帖子历史中添加文本线索如何提高模型预测谁有可能分享虚假新闻的准确性。在第三项研究中，我们对从第一项研究中推导出的两种缓解策略进行了初步测试，即激活宗教价值观和减少愤怒，发现它们可以减少虚假新闻的分享和更广泛的分享。在第四项研究中，我们将调查结果与用户的验证推特結合在一起。

    Misinformation is a global concern and limiting its spread is critical for protecting democracy, public health, and consumers. We propose that consumers' own social media post-histories are an underutilized data source to study what leads them to share links to fake-news. In Study 1, we explore how textual cues extracted from post-histories distinguish fake-news sharers from random social media users and others in the misinformation ecosystem. Among other results, we find across two datasets that fake-news sharers use more words related to anger, religion and power. In Study 2, we show that adding textual cues from post-histories improves the accuracy of models to predict who is likely to share fake-news. In Study 3, we provide a preliminary test of two mitigation strategies deduced from Study 1 - activating religious values and reducing anger - and find that they reduce fake-news sharing and sharing more generally. In Study 4, we combine survey responses with users' verified Twitter p
    
[^85]: DeepKE: 一种基于深度学习的知识提取工具包用于知识库构建

    DeepKE: A Deep Learning Based Knowledge Extraction Toolkit for Knowledge Base Population. (arXiv:2201.03335v6 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2201.03335](http://arxiv.org/abs/2201.03335)

    DeepKE是一个基于深度学习的知识提取工具包，支持复杂的低资源、文档级和多模态场景，可用于自定义数据集和模型来从非结构化数据中提取信息。

    

    我们提出了一个开放源代码和可扩展的知识提取工具包DeepKE，支持知识库构建中的复杂低资源、文档级和多模态场景。DeepKE实现了各种信息提取任务，包括命名实体识别、关系提取和属性提取。通过统一的框架，DeepKE允许开发人员和研究人员根据自己的需求定制数据集和模型，从非结构化数据中提取信息。具体而言，DeepKE不仅为不同任务和场景提供各种功能模块和模型实现，还通过一致的框架组织所有组件，以保持足够的模块化和可扩展性。我们在https://github.com/zjunlp/DeepKE发布了源代码，并提供了适用于初学者的Google Colab教程和全面的文档。此外，我们还在http URL上提供了一个在线系统，用于实时提取各种任务，并提供了演示视频。

    We present an open-source and extensible knowledge extraction toolkit DeepKE, supporting complicated low-resource, document-level and multimodal scenarios in the knowledge base population. DeepKE implements various information extraction tasks, including named entity recognition, relation extraction and attribute extraction. With a unified framework, DeepKE allows developers and researchers to customize datasets and models to extract information from unstructured data according to their requirements. Specifically, DeepKE not only provides various functional modules and model implementation for different tasks and scenarios but also organizes all components by consistent frameworks to maintain sufficient modularity and extensibility. We release the source code at GitHub in https://github.com/zjunlp/DeepKE with Google Colab tutorials and comprehensive documents for beginners. Besides, we present an online system in this http URL for real-time extraction of various tasks, and a demo video
    
[^86]: 情绪分析和新冠疫情对大学社区中Reddit数据的影响研究

    Sentiment Analysis and Effect of COVID-19 Pandemic using College SubReddit Data. (arXiv:2112.04351v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2112.04351](http://arxiv.org/abs/2112.04351)

    这项研究通过分析大学社区中的Reddit数据，研究了COVID-19疫情对人们情绪和心理状态的影响，并提出了基于RoBERTa和GAT的情绪分类模型。

    

    背景：COVID-19疫情以各种方式影响了我们的社会和人类福祉。在这项研究中，我们使用社交媒体的真实数据，调查了疫情如何与疫情前期相比影响了人们的情绪和心理状态。方法：我们收集了与八所大学相关的Reddit社交媒体数据，其中包括2019年（疫情前）和2020年（疫情期间）的数据。我们利用预训练的RoBERTa方法学习Reddit消息的文本嵌入，同时利用发布的消息之间的关系信息训练了一个图注意力网络（GAT）进行情绪分类。最后，我们将RoBERTa和GAT的预测概率进行模型堆叠，得出情绪最终分类结果。通过对收集到的数据进行模型预测的情绪标签，我们使用广义线性混合效应模型估计了疫情和情绪之间的效应。

    Background: The COVID-19 pandemic has affected our society and human well-being in various ways. In this study, we investigate how the pandemic has influenced people's emotions and psychological states compared to a pre-pandemic period using real-world data from social media.  Method: We collected Reddit social media data from 2019 (pre-pandemic) and 2020 (pandemic) from the subreddits communities associated with eight universities. We applied the pre-trained Robustly Optimized BERT pre-training approach (RoBERTa) to learn text embedding from the Reddit messages, and leveraged the relational information among posted messages to train a graph attention network (GAT) for sentiment classification. Finally, we applied model stacking to combine the prediction probabilities from RoBERTa and GAT to yield the final classification on sentiment. With the model-predicted sentiment labels on the collected data, we used a generalized linear mixed-effects model to estimate the effects of pandemic an
    
[^87]: KnowPrompt：具有协同优化的知识感知提示调整在关系抽取中的应用

    KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction. (arXiv:2104.07650v7 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2104.07650](http://arxiv.org/abs/2104.07650)

    本文提出了一种名为KnowPrompt的知识感知提示调整方法，通过将关系标签中的潜在知识融入到提示构建中，并通过协同优化的方式，提高了关系抽取任务的性能。

    

    最近，对于特定的少样本分类任务，使用提示调整方法取得了有希望的结果。提示调整的核心思想是将文本片段（即模板）插入输入，并将分类任务转化为掩码语言建模问题。然而，对于关系抽取，确定一个合适的提示模板需要领域专业知识，获取合适的标签词是繁琐且耗时的。此外，关系标签之间存在丰富的语义和先验知识，不容忽视。因此，我们的研究着眼于将关系标签之间的知识融入到关系抽取的提示调整中，并提出了一种具有协同优化的知识感知提示调整方法（KnowPrompt）。具体而言，我们利用可学习的虚拟类型词和答案词将关系标签中的潜在知识融入到提示构建中。然后，我们通过结构化约束协同优化它们的表示。

    Recently, prompt-tuning has achieved promising results for specific few-shot classification tasks. The core idea of prompt-tuning is to insert text pieces (i.e., templates) into the input and transform a classification task into a masked language modeling problem. However, for relation extraction, determining an appropriate prompt template requires domain expertise, and it is cumbersome and time-consuming to obtain a suitable label word. Furthermore, there exists abundant semantic and prior knowledge among the relation labels that cannot be ignored. To this end, we focus on incorporating knowledge among relation labels into prompt-tuning for relation extraction and propose a Knowledge-aware Prompt-tuning approach with synergistic optimization (KnowPrompt). Specifically, we inject latent knowledge contained in relation labels into prompt construction with learnable virtual type words and answer words. Then, we synergistically optimize their representation with structured constraints. Ex
    
[^88]: 同质性吸引，但新颖性令人着迷——关于在线同人小说的研究

    Sameness Entices, but Novelty Enchants in Fanfiction Online. (arXiv:1904.07741v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/1904.07741](http://arxiv.org/abs/1904.07741)

    该研究通过分析同人小说的大数据集，发现文化作品的成功与新颖性呈现出U形曲线的关系，而不是先增加后减弱，解决了平衡理论的谜团。

    

    文化演化是由我们选择什么消费和与他人分享驱动的。一个普遍的信念是，成功的文化作品在新颖性和常规性之间保持平衡。这种平衡理论认为，人们更喜欢那些熟悉而不乏味的作品；新颖，但又不违背其流派的预期。我们使用大量同人小说的数据集来测试这个想法。我们应用多元回归模型和广义加性模型来研究作品的认可程度如何随着其新颖性的变化而变化，通过潜在狄利克雷分配主题模型进行估计。我们发现与平衡理论预测相反的模式——总体上，作品的成功几乎随着新颖性的增加而下降，并呈现出U形曲线，而不是倒U形曲线。这个谜团通过揭示出两股相互竞争的力量得到了解决：同质性吸引了大众，而新颖性提供了欢乐。

    Cultural evolution is driven by how we choose what to consume and share with others. A common belief is that the cultural artifacts that succeed are ones that balance novelty and conventionality. This balance theory suggests that people prefer works that are familiar, but not so familiar as to be boring; novel, but not so novel as to violate the expectations of their genre. We test this idea using a large dataset of fanfiction. We apply a multiple regression model and a generalized additive model to examine how the recognition a work receives varies with its novelty, estimated through a Latent Dirichlet Allocation topic model, in the context of existing works. We find the opposite pattern of what the balance theory predicts$\unicode{x2014}$overall success decline almost monotonically with novelty and exhibits a U-shaped, instead of an inverse U-shaped, curve. This puzzle is resolved by teasing out two competing forces: sameness attracts the mass whereas novelty provides enjoyment. Take
    

