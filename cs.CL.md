# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [FigCaps-HF: A Figure-to-Caption Generative Framework and Benchmark with Human Feedback.](http://arxiv.org/abs/2307.10867) | FigCaps-HF是一个图像生成标题的框架，可以通过融入领域专家的反馈意见，生成符合读者偏好的高质量图像标题。将自动评估和强化学习与人类反馈相结合，可以改善生成的标题与读者偏好的一致性。 |
| [^2] | [Divide & Bind Your Attention for Improved Generative Semantic Nursing.](http://arxiv.org/abs/2307.10864) | 本论文提出了一种名为"分割与绑定"的方法，旨在改进生成语义护理的效果。该方法引入了新的损失目标，包括关注丢失和绑定丢失，以解决复杂提示和不适当属性绑定的问题。 |
| [^3] | [Yelp Reviews and Food Types: A Comparative Analysis of Ratings, Sentiments, and Topics.](http://arxiv.org/abs/2307.10826) | 本研究比较分析了Yelp评论和食物类型之间的关系，发现不同类型的食物在评分、情感和主题上有不同的变化和分布。研究还提出了四类食物类型，并发现评论者在评论不同类型的食物时倾向于关注不同的主题。 |
| [^4] | [Cross-Corpus Multilingual Speech Emotion Recognition: Amharic vs. Other Languages.](http://arxiv.org/abs/2307.10814) | 通过比较不同语言的表现，我们研究了跨语言和多语种的语音情绪识别。结果显示阿姆哈拉语和英语在情绪识别上表现相似。 |
| [^5] | ["It Felt Like Having a Second Mind": Investigating Human-AI Co-creativity in Prewriting with Large Language Models.](http://arxiv.org/abs/2307.10811) | 通过三节次的定性研究，探究了人类与大型语言模型在预写过程中的合作模式，并发现了一个三阶段的人机共创过程：构思、启发和实施。在这个合作过程中，人类扮演着主导角色。 |
| [^6] | [Meta-Transformer: A Unified Framework for Multimodal Learning.](http://arxiv.org/abs/2307.10802) | Meta-Transformer是一个统一的多模态学习框架，利用一个冻结的编码器进行多模态感知，在没有成对多模态训练数据的情况下可以处理各种模态，并且能够提取输入数据的高级语义特征。 |
| [^7] | [Layer-wise Representation Fusion for Compositional Generalization.](http://arxiv.org/abs/2307.10799) | 该论文提出了一种层级表示融合的方法，以提升序列到序列模型在组合泛化方面的表现。之前的研究主要关注增强基于令牌的语义信息，而本文提出了在人类那样适当地组合和使用序列的句法和语义表示的方法。此外，从近期的关于训练更深Transformer的研究结果来看，纠缠问题主要是由于残差连接的“浅层”和简单的单步操作导致不能有效地融合前面层的信息。 |
| [^8] | [Extreme Multi-Label Skill Extraction Training using Large Language Models.](http://arxiv.org/abs/2307.10778) | 使用大型语言模型进行极端多标签技能提取训练，通过生成合成数据集和对比学习策略，提高了技能提取的准确率。 |
| [^9] | [Vesper: A Compact and Effective Pretrained Model for Speech Emotion Recognition.](http://arxiv.org/abs/2307.10757) | 本文提出了一种用于语音情感识别的紧凑高效预训练模型Vesper，通过优化大规模预训练模型生成任务特定模型，考虑情感特征并采用情感引导的掩蔽策略来增强对情感信息的敏感性。 |
| [^10] | [Exploring Perspectives on the Impact of Artificial Intelligence on the Creativity of Knowledge Work: Beyond Mechanised Plagiarism and Stochastic Parrots.](http://arxiv.org/abs/2307.10751) | 人工智能对知识工作的创造力有着深远的影响，但是对生成模型的批评者认为其输出只是随机的抄袭和混搭。然而，创造力和原创性的定义是复杂的，可能是一个过程、一个作者或一个观看者的属性。 |
| [^11] | [Large language models shape and are shaped by society: A survey of arXiv publication patterns.](http://arxiv.org/abs/2307.10700) | 大型语言模型的论文数量急剧增加，研究重点逐渐转向社会影响。与LLM相关的论文呈现持续增长的趋势，新发表关于LLM的作者更注重应用和社会影响。 |
| [^12] | [A Dataset and Strong Baselines for Classification of Czech News Texts.](http://arxiv.org/abs/2307.10666) | 该论文介绍了捷克新闻文本分类的数据集和基线模型。通过引入CZEch~NEws~Classification~dataset（CZE-NEC），这个跨越20多年的最大捷克新闻分类数据集，可以更严格地评估捷克自然语言处理的预训练模型。实验证明，基于预训练变换器模型的机器学习基线表现优于人类，并且语言特定的预训练编码器分析也超过了商业模型。 |
| [^13] | [Exploring the Landscape of Natural Language Processing Research.](http://arxiv.org/abs/2307.10652) | 该论文系统分类和分析了ACL Anthology中的研究论文，提供了对研究领域的结构化概述和NLP领域的分类学。本研究总结了最新的NLP发展，并提出了未来工作的方向。 |
| [^14] | [SciBench: Evaluating College-Level Scientific Problem-Solving Abilities of Large Language Models.](http://arxiv.org/abs/2307.10635) | 这篇论文介绍了一个名为SciBench的基准套件，旨在对大型语言模型的大学水平科学问题解决能力进行评估。研究结果显示，当前的语言模型在提供复杂科学问题解决能力方面还有不足之处。 |
| [^15] | [Generative Language Models on Nucleotide Sequences of Human Genes.](http://arxiv.org/abs/2307.10634) | 本研究开发了一种生成语言模型，用于处理人类基因的核苷酸序列，填补了DNA序列生成模型研究的空白。 |
| [^16] | [Multi-Method Self-Training: Improving Code Generation With Text, And Vice Versa.](http://arxiv.org/abs/2307.10633) | 多方法自训练可以通过在不同方法之间训练和生成数据来改善代码生成的性能，使模型更易于使用，并提高相关任务的性能。 |
| [^17] | [A Deep Dive into the Disparity of Word Error Rates Across Thousands of NPTEL MOOC Videos.](http://arxiv.org/abs/2307.10587) | 该论文对NPTEL MOOC视频中成千上万个单词错误率差异进行了深入研究，发现由于说话者的语音特性存在差异，最先进的自动语音识别系统在某些地区或人口统计信息的说话者身上面临困难。 |
| [^18] | [Instruction-following Evaluation through Verbalizer Manipulation.](http://arxiv.org/abs/2307.10558) | 本文提出了一种新的指示遵循评估协议，口述者操作，通过口述任务标签来检查模型对先验知识的依赖程度，以及覆盖它们的能力，从而准确地进行指示遵循。 |
| [^19] | [Dynamic Large Language Models on Blockchains.](http://arxiv.org/abs/2307.10549) | 本文提出在区块链上训练和部署动态大型语言模型，通过使用分布式计算和提供无法篡改的交易分类帐的区块链技术，可使语言模型具备连续学习的能力，为下一代人工智能系统的发展提供了新的方法和启示。 |
| [^20] | [Gender-tuning: Empowering Fine-tuning for Debiasing Pre-trained Language Models.](http://arxiv.org/abs/2307.10522) | 本研究提出了Gender-tuning方法，通过在下游任务的数据集上进行微调，去偏置预训练语言模型（PLMs），不仅能在PLMs的性别偏见得分方面优于现有方法，而且仅使用下游任务的数据集即可提高PLMs在下游任务中的性能。 |
| [^21] | [Building Socio-culturally Inclusive Stereotype Resources with Community Engagement.](http://arxiv.org/abs/2307.10514) | 通过社区参与的努力，在印度社会背景下扩展了对刻板印象伤害的评估资源。这个工作强调了包容不同文化和社会背景的人们和经验，以避免对伤害测量的严重低估或扭曲。 |
| [^22] | [IvyGPT: InteractiVe Chinese pathwaY language model in medical domain.](http://arxiv.org/abs/2307.10512) | IvyGPT是一种基于医学领域的中文互动语言模型，通过使用高质量的医学问答示例和人类反馈强化学习进行训练和微调，它能够输出更丰富的诊断和治疗答案，从而在医学GPT模型中表现出色。 |
| [^23] | [General Debiasing for Multimodal Sentiment Analysis.](http://arxiv.org/abs/2307.10511) | 提出了一个通用的去偏多模态情感分析任务，通过减少模型对虚假相关性的依赖，提高多模态情感分析模型的非分布外泛化能力。 |
| [^24] | [(Ab)using Images and Sounds for Indirect Instruction Injection in Multi-Modal LLMs.](http://arxiv.org/abs/2307.10490) | 本论文展示了如何利用图像和声音在多模态LLMs中进行间接指令注入，攻击者通过生成对抗扰动并将其融入图像或音频录音中，以操纵模型输出特定文本和指导对话的行为。 |
| [^25] | [SPRINT: A Unified Toolkit for Evaluating and Demystifying Zero-shot Neural Sparse Retrieval.](http://arxiv.org/abs/2307.10488) | SPRINT是一个统一的Python工具包，基于Pyserini和Lucene，支持评估和解析零样本神经稀疏检索。它解决了缺乏统一环境和实现在未见过领域上的检索能力的问题。 |
| [^26] | [FinGPT: Democratizing Internet-scale Data for Financial Large Language Models.](http://arxiv.org/abs/2307.10485) | FinGPT是一个开源的数据为中心的框架，旨在将互联网规模的金融数据民主化为金融大语言模型。它提供了自动收集和整理实时金融数据的功能，解决了金融文本数据稀缺的问题。 |
| [^27] | [What can we learn from Data Leakage and Unlearning for Law?.](http://arxiv.org/abs/2307.10476) | 本研究发现，大型语言模型存在泄露训练数据的问题，删除最容易被提取的用户数据后，新的数据点仍然容易被提取。精调模型不仅泄露训练数据，还会泄露预训练阶段记忆的预训练数据和个人身份信息。 |
| [^28] | [Findings of Factify 2: Multimodal Fake News Detection.](http://arxiv.org/abs/2307.10475) | Factify 2进行了一项多模态假新闻检测任务，通过比较社交媒体声明和支持文件的文本和图像信息，实现了对假新闻的自动检测和验证，最佳性能达到了81.82%的F1分数。 |
| [^29] | [Can Instruction Fine-Tuned Language Models Identify Social Bias through Prompting?.](http://arxiv.org/abs/2307.10472) | 本文介绍了一种通过零样本提示评估指令微调语言模型识别偏见能力的方法，展示了Alpaca 7B在偏见识别任务中的最佳性能，并提出扩大模型大小和数据多样性可进一步提高性能。 |
| [^30] | [Improving Pre-trained Language Models' Generalization.](http://arxiv.org/abs/2307.10457) | 该研究提出了一种名为Mask-tuning的训练方法，通过将Masked Language Modeling (MLM)训练目标整合到微调过程中来增强预训练语言模型（PLMs）的泛化能力。实验证明，Mask-tuning在非分布数据集上超过了当前最先进的技术，并提高了PLMs在分布数据集上的性能。 |
| [^31] | [Integrating a Heterogeneous Graph with Entity-aware Self-attention using Relative Position Labels for Reading Comprehension Model.](http://arxiv.org/abs/2307.10443) | 本文提出了一种新的注意力模式，使用图增强自注意力机制将从异构图中导出的推理知识整合到变压器架构中，从而克服了变压器模型在复杂推理任务中的限制。通过全局-局部注意力、图注意力和关系类型考虑，优化了实体和单词之间的注意力。该模式与相对位置标签相结合，能够与LUKE的实体感知自注意力机制相集成。 |
| [^32] | [Thrust: Adaptively Propels Large Language Models with External Knowledge.](http://arxiv.org/abs/2307.10442) | 本论文提出了一种实例级的自适应推动外部知识的方法，通过衡量大型语言模型的知识水平，并利用Thrust指标进行信息检索，实现更高的成本效益。 |
| [^33] | [PharmacyGPT: The AI Pharmacist.](http://arxiv.org/abs/2307.10432) | PharmacyGPT是一个新颖的框架，利用大型语言模型（LLM）来仿真临床药师的角色。通过生成患者群集、制定用药计划和预测患者结果，PharmacyGPT在临床药学中具有潜在应用和限制，为促进负责任和有效使用人工智能技术做出贡献。 |
| [^34] | [IncDSI: Incrementally Updatable Document Retrieval.](http://arxiv.org/abs/2307.10323) | IncDSI是一种递增可更新的文档检索方法，它通过最小改变网络参数的约束优化问题，实现实时添加文档而无需重新训练整个模型，具有与重新训练模型相竞争的速度，能够实时更新的文档检索系统的开发。 |
| [^35] | [Mood Classification of Bangla Songs Based on Lyrics.](http://arxiv.org/abs/2307.10314) | 本研究通过分析孟加拉歌曲的歌词，成功实现了对这些歌曲的情绪进行多类分类，包括快乐、悲伤、浪漫和放松，为使音乐更贴近人们的情感做出了重要贡献。 |
| [^36] | [Analyzing sports commentary in order to automatically recognize events and extract insights.](http://arxiv.org/abs/2307.10303) | 通过分析多种体育赛事的实时评论，利用自然语言处理技术自动识别主要行动，并通过分类和情感分析提取洞见。 |
| [^37] | [The Language Labyrinth: Constructive Critique on the Terminology Used in the AI Discourse.](http://arxiv.org/abs/2307.10292) | 这篇文章对人工智能领域使用的术语进行了建设性批评，指出AI的讨论缺乏对隐喻的批判性距离，导致对责任和潜在用途的反思被扭曲。文章通过提出更合适的术语来促进更富有成果的辩论。 |
| [^38] | [Mutual Reinforcement Effects in Japanese Sentence Classification and Named Entity Recognition Tasks.](http://arxiv.org/abs/2307.10291) | 该研究提出了一个综合分析方法，将句子分类和命名实体识别结合起来，并揭示了这两个信息提取子任务之间的相互增强效应。 |
| [^39] | [Zero-shot Domain-sensitive Speech Recognition with Prompt-conditioning Fine-tuning.](http://arxiv.org/abs/2307.10274) | 本研究提出了一种零样本领域敏感语音识别方法，利用文本提示来生成领域敏感模型，通过微调预训练的端到端模型实现。实验结果表明，该方法在不同领域和提示上下文下均取得了良好的性能，词错误率降低达到最高33%。通过仅使用文本进行微调，该模型在医学对话数据集上的识别效果最佳，词错误率降低达到29%。 |
| [^40] | [Automated Action Model Acquisition from Narrative Texts.](http://arxiv.org/abs/2307.10247) | NaRuto是一个系统，可以从叙事文本中自动提取结构化事件，并生成高质量的行动模型，优于现有的完全自动化方法和与半自动化方法相媲美。 |
| [^41] | [Deep Neural Networks and Brain Alignment: Brain Encoding and Decoding (Survey).](http://arxiv.org/abs/2307.10246) | 本文综述了深度神经网络和脑对齐的研究，重点在于脑编码和解码模型的应用。这些模型对于理解大脑的信息处理机制以及设计脑机接口具有重要意义。 |
| [^42] | [Look Before You Leap: An Exploratory Study of Uncertainty Measurement for Large Language Models.](http://arxiv.org/abs/2307.10236) | 本研究从不确定性的角度对大型语言模型进行了探索性研究，通过实验发现不确定性估计方法在探索和抵制大型语言模型的不良行为方面具有潜力。 |
| [^43] | [SentimentGPT: Exploiting GPT for Advanced Sentiment Analysis and its Departure from Current Machine Learning.](http://arxiv.org/abs/2307.10234) | 本研究通过利用GPT进行高级情感分析，并考察其与当前机器学习方法的差异，发现GPT方法相较于其他模型在预测性能上具有显著优势，并有效解决了情感分析任务中的一些挑战，如理解上下文和检测讽刺。 |
| [^44] | [Mitigating Bias in Conversations: A Hate Speech Classifier and Debiaser with Prompts.](http://arxiv.org/abs/2307.10213) | 该论文提出了一个双步骤的方法来减少在线对话中的偏见和仇恨言论。该方法通过先使用分类器检测仇恨言论，然后利用提示生成更少偏见或无偏见的替代语言，从而降低了负面影响，为减少在线讨论中的偏见，促进更具包容性和公平性的沟通环境做出了贡献。 |
| [^45] | [Unsupervised Domain Adaptation using Lexical Transformations and Label Injection for Twitter Data.](http://arxiv.org/abs/2307.10210) | 本论文提出了一种从数据集角度解决领域适应问题的方法。通过简单的词汇转换，减少了不同数据集之间的领域差异。在推特数据集上进行实验，取得了较好的无监督词性标注准确率。同时，通过合成推特文本并增加数据集，还实现了词性标注的最新性能。 |
| [^46] | [Disentangling Societal Inequality from Model Biases: Gender Inequality in Divorce Court Proceedings.](http://arxiv.org/abs/2307.10200) | 本文通过研究离婚法庭诉讼，探索了性别不平等问题，并发现了自然语言处理方法中存在的偏见问题。需要对现有资源进行修正来量化社会不平等。 |
| [^47] | [ChatGPT for Digital Forensic Investigation: The Good, The Bad, and The Unknown.](http://arxiv.org/abs/2307.10195) | 本文评估了ChatGPT对数字取证领域的影响和潜力，特别关注其最新预训练的大型语言模型GPT-4。通过一系列实验，发现了ChatGPT在数字取证用例中的优势和风险，并得出了一些总体结论。 |
| [^48] | [Subjective Crowd Disagreements for Subjective Data: Uncovering Meaningful CrowdOpinion with Population-level Learning.](http://arxiv.org/abs/2307.10189) | 本文介绍了一种名为CrowdOpinion的无监督学习方法，可以通过汇集标签分布中相似的项目，揭示在群体中存在的有意义的观点分歧，特别是在标注者人群中可能已经代表性不足的群体中。 |
| [^49] | [Several categories of Large Language Models (LLMs): A Short Survey.](http://arxiv.org/abs/2307.10188) | 本文是对大型语言模型（LLMs）的几个类别进行的简短调查，提供了各类LLM的最新发展和努力的概述，包括多语言LLMs、视觉语言LLMs和代码语言模型等。同时，还突出了在聊天机器人和虚拟助手领域存在的问题，如提升自然语言处理能力和解决道德和法律困境。 |
| [^50] | [DialogStudio: Towards Richest and Most Diverse Unified Dataset Collection for Conversational AI.](http://arxiv.org/abs/2307.10172) | DialogStudio是迄今为止最大且最多样化的对话数据集合，包含从开放领域对话到任务导向对话、自然语言理解、会话推荐、对话摘要和知识驱动对话的数据。它为对话研究和模型训练提供了丰富而多样化的资源。 |
| [^51] | [LLMs as Workers in Human-Computational Algorithms? Replicating Crowdsourcing Pipelines with LLMs.](http://arxiv.org/abs/2307.10168) | 本文研究探索了LLMs是否可以复制更复杂的众包流水线，并发现现代LLMs在模拟人类计算算法中的能力上有一定的成功，但受多种因素影响。文章强调了为LLMs提供人类面向的安全保障的重要性，并讨论了训练人类和LLMs互补技能的潜力。 |
| [^52] | [Efficient Guided Generation for LLMs.](http://arxiv.org/abs/2307.09702) | 本文描述了一种使用正则表达式和上下文无关文法来引导语言模型文本生成的高效方法。 |
| [^53] | [ChatGPT is Good but Bing Chat is Better for Vietnamese Students.](http://arxiv.org/abs/2307.08272) | 本研究比较了ChatGPT和Bing Chat在满足越南学生需求方面的效果，发现Bing Chat在除文学外的多个学科表现优于ChatGPT。Bing Chat采用更先进的GPT-4技术，能够提高文本的理解、推理和生成创造性、信息丰富的内容。 |
| [^54] | [Unifying Token and Span Level Supervisions for Few-Shot Sequence Labeling.](http://arxiv.org/abs/2307.07946) | 本文提出了一种统一令牌级别和跨度级别监督的CDAP网络用于少样本序列标注，通过在不同粒度上进行联合训练和一致损失，实现了两个网络的协同学习，在推理阶段使用了一致贪婪推理算法来选择非重叠跨度。 |
| [^55] | [Performance Comparison of Large Language Models on VNHSGE English Dataset: OpenAI ChatGPT, Microsoft Bing Chat, and Google Bard.](http://arxiv.org/abs/2307.02288) | 本文对OpenAI ChatGPT、Microsoft Bing Chat和Google Bard这三种大型语言模型在VNHSGE英文数据集上的性能进行了比较，结果显示Bing Chat优于ChatGPT和Bard。研究结果还表明，这些语言模型在英语语言教育中具有潜力，可以作为高中英语教学和学习的有效工具。 |
| [^56] | [PatternGPT :A Pattern-Driven Framework for Large Language Model Text Generation.](http://arxiv.org/abs/2307.00470) | PatternGPT是一种基于模式驱动的大型语言模型文本生成框架，通过利用大型语言模型的提取能力生成多样化的模式，并使用联邦学习的思想实现模式共享，最终通过搜索高质量模式指导生成模型。该框架具有生成多样化模式、保护数据隐私、结合外部知识等优势。 |
| [^57] | [Improving Text Matching in E-Commerce Search with A Rationalizable, Intervenable and Fast Entity-Based Relevance Model.](http://arxiv.org/abs/2307.00370) | 本研究提出了一种称为基于实体的关联模型（EBRM）的新模型，将查询-商品关联问题分解为多个查询-实体关联问题，并使用软逻辑聚合结果，以提高准确性和推理速度。 |
| [^58] | [ChatGPT for Robotics: Design Principles and Model Abilities.](http://arxiv.org/abs/2306.17582) | 本文介绍了使用ChatGPT进行机器人应用的实验研究，通过设计原则和函数库的结合，ChatGPT能够适应不同的机器人任务，并展示了在各种机器人任务中的有效性和多样性。 |
| [^59] | [MotionGPT: Human Motion as a Foreign Language.](http://arxiv.org/abs/2306.14795) | 本研究提出了MotionGPT，一种用于处理多个与动作相关任务的统一、多功能且易于使用的动作语言模型。通过将语言数据与大规模动作模型融合，实现了动作语言预训练，提升了动作相关任务的性能。 |
| [^60] | [$\alpha$-$\beta$-Factorization and the Binary Case of Simon's Congruence.](http://arxiv.org/abs/2306.14192) | 本研究通过介绍$\alpha$-$\beta$-分解的概念，将Simon同余特征化为$1$-普遍性单词，并应用于二元单词的完全刻画和同余指数计算。 |
| [^61] | [My Boli: Code-mixed Marathi-English Corpora, Pretrained Language Models and Evaluation Benchmarks.](http://arxiv.org/abs/2306.14030) | 本研究针对资源匮乏的印度语言马拉地语，提出了一个大型混合马拉地语-英语语料库，以及预训练的混合BERT模型和针对混合语言下游任务的评估数据集，该语料库训练的模型显著优于现有的BERT模型。 |
| [^62] | [Class-Incremental Learning based on Label Generation.](http://arxiv.org/abs/2306.12619) | 本文提出了一种基于标签生成方法的增量分类学习（CIL）方法（VAG），大幅减少了灾难性遗忘（CF），并更好地保留了预训练模型的可推广表示。 |
| [^63] | [ChatGPT Chemistry Assistant for Text Mining and Prediction of MOF Synthesis.](http://arxiv.org/abs/2306.11296) | 该论文使用提示工程的方法指导ChatGPT对科学文献进行自动化文本挖掘，以获得金属-有机框架（MOF）合成条件。通过该系统，可以高精确地提取大量合成参数，为MOF合成提供支持。 |
| [^64] | [Boosting Language Models Reasoning with Chain-of-Knowledge Prompting.](http://arxiv.org/abs/2306.06427) | 该论文提出了一种新的知识链提示（CoK）方法，旨在引导语言模型生成明确的知识证据，以提升推理能力，并通过F^2-Verification方法评估推理的准确性和可信度。 |
| [^65] | [Science in the Era of ChatGPT, Large Language Models and Generative AI: Challenges for Research Ethics and How to Respond.](http://arxiv.org/abs/2305.15299) | 这篇论文回顾了生成AI对科学研究所带来的认识论挑战、伦理和诚信风险，并提出了十项建议，以在AI时代促进更负责任的研究进行。 |
| [^66] | [AlignAtt: Using Attention-based Audio-Translation Alignments as a Guide for Simultaneous Speech Translation.](http://arxiv.org/abs/2305.11408) | AlignAtt是一种新型的SimulST策略，使用基于注意力的音频翻译对齐来指导模型，在BLEU和延迟方面均优于之前的策略。 |
| [^67] | [RadAdapt: Radiology Report Summarization via Lightweight Domain Adaptation of Large Language Models.](http://arxiv.org/abs/2305.01146) | 本研究重点研究了轻量化策略，通过在临床文本上进行预训练和在RRS示例上进行参数高效微调，实现适应大型语言模型进行放射性报告摘要（RRS）任务。并且该方法仅微调模型的0.32％的参数，提高了表现。研究结果强调了领域适应在RRS中的重要性，并为开发更好的放射性报告摘要模型提供了有价值的见解。 |
| [^68] | [Fairness in AI and Its Long-Term Implications on Society.](http://arxiv.org/abs/2304.09826) | 本文探讨了AI的公平性问题，指出缺乏AI公平性会加深偏见成为社会压力因素，可能对社会产生长期影响，因此需要寻求潜在解决方案。 |
| [^69] | [Sabi\'a: Portuguese Large Language Models.](http://arxiv.org/abs/2304.07880) | 针对葡萄牙语进行单语言预训练，可以显著提高大规模合成语言模型的质量，并能够在一系列葡萄牙语数据集上优于以英语为中心和多语言的对手，最好的模型的表现与GPT-3.5-turbo持平。 |
| [^70] | [Positive-Augmented Constrastive Learning for Image and Video Captioning Evaluation.](http://arxiv.org/abs/2303.12112) | 本论文提出一种新的图像标题评估指标PAC-S，可以更准确地评估图像和视频的标题，相比于现有的指标有更好的表现；源代码和训练模型已经公开。 |
| [^71] | [Mathematical Capabilities of ChatGPT.](http://arxiv.org/abs/2301.13867) | 本研究调查了ChatGPT和GPT-4的数学能力，并通过使用新的方法以及发布两个新数据集，评估了它们在各个维度的数学推理上的表现。这是第一个涵盖研究生级数学并由数学研究人员策划的自然语言数据集，也测试了它们作为专业数学家助手的潜力。 |
| [^72] | [Execution-based Code Generation using Deep Reinforcement Learning.](http://arxiv.org/abs/2301.13816) | 使用深度强化学习的PPOCoder框架将预训练的编程语言模型和Proximal Policy Optimization技术结合，通过利用代码执行和结构对齐的非可微反馈，实现了更高效的代码生成。 |
| [^73] | [ThoughtSource: A central hub for large language model reasoning data.](http://arxiv.org/abs/2301.11596) | ThoughtSource是一个用于连续思考推理的元数据集和软件库，旨在通过促进对连续思考的定性理解、实证评估和提供训练数据，改进未来的人工智能系统。 |
| [^74] | [A Textless Metric for Speech-to-Speech Comparison.](http://arxiv.org/abs/2210.11835) | 本文介绍了一种无文本的语音比较度量方法，利用语音到单元编码器转换语音表述为声学单元，并提出了与文本基准密切对应的基于语音的度量。该方法可以用于口述语言和没有可靠ASR系统的语音翻译评估，避免使用ASR转录的需求。 |
| [^75] | [MAP: Multimodal Uncertainty-Aware Vision-Language Pre-training Model.](http://arxiv.org/abs/2210.05335) | 本文提出了一种利用概率分布编码器进行多模态不确定性建模的预训练模型MAP，该模型在多项下游任务中均表现优异，超越了现有模型。 |
| [^76] | [ForecastTKGQuestions: A Benchmark for Temporal Question Answering and Forecasting over Temporal Knowledge Graphs.](http://arxiv.org/abs/2208.06501) | 本论文提出了一个新的任务，即在时间知识图谱上进行预测性问题回答。该任务对于人们寻求未来计划非常重要，并且是先前研究中未被探索的领域。 |
| [^77] | [ABNIRML: Analyzing the Behavior of Neural IR Models.](http://arxiv.org/abs/2011.00696) | ABNIRML提供了一个全面的框架，分析了神经信息检索模型的行为，包括写作风格、事实性、对改写和词序的敏感性等特征。通过进行广泛的实证研究，我们探究了神经模型增益的因素，并发现了潜在的偏见。 |

# 详细

[^1]: FigCaps-HF:一个基于人类反馈的图像生成标题框架和基准测试

    FigCaps-HF: A Figure-to-Caption Generative Framework and Benchmark with Human Feedback. (arXiv:2307.10867v1 [cs.CL])

    [http://arxiv.org/abs/2307.10867](http://arxiv.org/abs/2307.10867)

    FigCaps-HF是一个图像生成标题的框架，可以通过融入领域专家的反馈意见，生成符合读者偏好的高质量图像标题。将自动评估和强化学习与人类反馈相结合，可以改善生成的标题与读者偏好的一致性。

    

    标题对于理解科学可视化和文档至关重要。现有的科学图像生成标题方法依赖于从文档中提取的图像-标题配对进行训练，但其中许多配对在帮助性、解释性和视觉描述性等指标上存在不足，导致生成的标题与读者偏好不一致。为了能够生成高质量的图像标题，我们引入了FigCaps-HF，这是一个新的图像生成标题框架，可以融入领域专家的反馈意见，以生成优化了读者偏好的标题。我们的框架包含1）一种评估图像-标题配对质量的自动方法，2）一种基于人类反馈的强化学习（RLHF）方法，用于优化生成式图像生成标题模型以符合读者偏好。我们通过在不同类型的模型上改进性能，证明了我们简单的学习框架的有效性。

    Captions are crucial for understanding scientific visualizations and documents. Existing captioning methods for scientific figures rely on figure-caption pairs extracted from documents for training, many of which fall short with respect to metrics like helpfulness, explainability, and visual-descriptiveness [15] leading to generated captions being misaligned with reader preferences. To enable the generation of high-quality figure captions, we introduce FigCaps-HF a new framework for figure-caption generation that can incorporate domain expert feedback in generating captions optimized for reader preferences. Our framework comprises of 1) an automatic method for evaluating quality of figure-caption pairs, 2) a novel reinforcement learning with human feedback (RLHF) method to optimize a generative figure-to-caption model for reader preferences. We demonstrate the effectiveness of our simple learning framework by improving performance over standard fine-tuning across different types of mod
    
[^2]: 将注意力分割与绑定用于改进生成语义护理

    Divide & Bind Your Attention for Improved Generative Semantic Nursing. (arXiv:2307.10864v1 [cs.CV])

    [http://arxiv.org/abs/2307.10864](http://arxiv.org/abs/2307.10864)

    本论文提出了一种名为"分割与绑定"的方法，旨在改进生成语义护理的效果。该方法引入了新的损失目标，包括关注丢失和绑定丢失，以解决复杂提示和不适当属性绑定的问题。

    

    新兴的大规模文本到图像生成模型，如稳定扩散（SD），展示了高度逼真的压倒性结果。尽管取得了巨大的进展，但当前最先进的模型仍然难以完全依照输入提示生成图像。先前的研究——关注与激发，引入了生成语义护理（GSN）的概念，旨在在推断时优化跨注意力以更好地融入语义。它在生成简单提示，如“一只猫和一只狗”，方面展示了有希望的结果。然而，它在处理更复杂的提示以及解决不适当的属性绑定问题方面的功效有所下降。为了应对复杂提示或涉及多个实体的场景所带来的挑战，并实现改进的属性绑定，我们提出了分割与绑定。我们引入了两个新的GSN损失目标：一种新的关注丢失和一种绑定丢失。我们的方法在其能够更好地将语义纳入图像生成过程中的特点上脱颖而出。

    Emerging large-scale text-to-image generative models, e.g., Stable Diffusion (SD), have exhibited overwhelming results with high fidelity. Despite the magnificent progress, current state-of-the-art models still struggle to generate images fully adhering to the input prompt. Prior work, Attend & Excite, has introduced the concept of Generative Semantic Nursing (GSN), aiming to optimize cross-attention during inference time to better incorporate the semantics. It demonstrates promising results in generating simple prompts, e.g., ``a cat and a dog''. However, its efficacy declines when dealing with more complex prompts, and it does not explicitly address the problem of improper attribute binding. To address the challenges posed by complex prompts or scenarios involving multiple entities and to achieve improved attribute binding, we propose Divide & Bind. We introduce two novel loss objectives for GSN: a novel attendance loss and a binding loss. Our approach stands out in its ability to fa
    
[^3]: Yelp评论和食物类型: 对评分、情感和主题进行比较分析

    Yelp Reviews and Food Types: A Comparative Analysis of Ratings, Sentiments, and Topics. (arXiv:2307.10826v1 [cs.CL])

    [http://arxiv.org/abs/2307.10826](http://arxiv.org/abs/2307.10826)

    本研究比较分析了Yelp评论和食物类型之间的关系，发现不同类型的食物在评分、情感和主题上有不同的变化和分布。研究还提出了四类食物类型，并发现评论者在评论不同类型的食物时倾向于关注不同的主题。

    

    本研究考察了Yelp评论和食物类型之间的关系，研究了评分、情感和主题在不同类型食物之间的变化。具体而言，我们分析了评论评分和情感在不同食物类型中的变化，基于评分和情感对食物类型进行聚类，使用机器学习模型推断评论主题，并比较不同食物类型的主题分布。我们的分析揭示了一些食物类型具有相似的评分、情感和主题分布，而其他类型具有不同的模式。我们基于评分和情感鉴别出了四类食物类型，并发现评论者在评论某些食物类型时倾向于关注不同的主题。这些发现对于了解用户行为、文化对数字媒体平台的影响以及促进跨文化理解和欣赏具有重要意义。

    This study examines the relationship between Yelp reviews and food types, investigating how ratings, sentiments, and topics vary across different types of food. Specifically, we analyze how ratings and sentiments of reviews vary across food types, cluster food types based on ratings and sentiments, infer review topics using machine learning models, and compare topic distributions among different food types. Our analyses reveal that some food types have similar ratings, sentiments, and topics distributions, while others have distinct patterns. We identify four clusters of food types based on ratings and sentiments and find that reviewers tend to focus on different topics when reviewing certain food types. These findings have important implications for understanding user behavior and cultural influence on digital media platforms and promoting cross-cultural understanding and appreciation.
    
[^4]: 语料库跨语言多语种语音情绪识别：阿姆哈拉语与其他语言的比较

    Cross-Corpus Multilingual Speech Emotion Recognition: Amharic vs. Other Languages. (arXiv:2307.10814v1 [cs.CL])

    [http://arxiv.org/abs/2307.10814](http://arxiv.org/abs/2307.10814)

    通过比较不同语言的表现，我们研究了跨语言和多语种的语音情绪识别。结果显示阿姆哈拉语和英语在情绪识别上表现相似。

    

    在常规的语音情绪识别（SER）任务中，针对给定语言的分类器是在该语言现有的数据集上进行训练的。然而，在某些语言缺乏训练数据的情况下，可以使用其他语言的数据。我们尝试了跨语言和多语种的SER，使用了阿姆哈拉语、英语、德语和乌尔都语。对于阿姆哈拉语，我们使用了我们自己提供的阿姆哈拉语情绪语音数据集（ASED）。对于英语、德语和乌尔都语，我们使用了现有的RAVDESS、EMO-DB和URDU数据集。我们遵循了以前的研究，将所有数据集的标签映射为两个类别：积极和消极。因此，我们可以直接比较不同语言的性能，并将不同语言用于训练和测试。在第一实验中，使用三个分类器（AlexNet、VGGE和ResNet50）进行了单语种SER试验。对于ASED和RAVDESS，三个模型的平均结果非常相似，这表明阿姆哈拉语和英语在情绪识别上的表现相似。

    In a conventional Speech emotion recognition (SER) task, a classifier for a given language is trained on a pre-existing dataset for that same language. However, where training data for a language does not exist, data from other languages can be used instead. We experiment with cross-lingual and multilingual SER, working with Amharic, English, German and URDU. For Amharic, we use our own publicly-available Amharic Speech Emotion Dataset (ASED). For English, German and Urdu we use the existing RAVDESS, EMO-DB and URDU datasets. We followed previous research in mapping labels for all datasets to just two classes, positive and negative. Thus we can compare performance on different languages directly, and combine languages for training and testing. In Experiment 1, monolingual SER trials were carried out using three classifiers, AlexNet, VGGE (a proposed variant of VGG), and ResNet50. Results averaged for the three models were very similar for ASED and RAVDESS, suggesting that Amharic and E
    
[^5]: "感觉像有第二个思维": 探究在大型语言模型中进行创意可写性预写的人机共创

    "It Felt Like Having a Second Mind": Investigating Human-AI Co-creativity in Prewriting with Large Language Models. (arXiv:2307.10811v1 [cs.HC])

    [http://arxiv.org/abs/2307.10811](http://arxiv.org/abs/2307.10811)

    通过三节次的定性研究，探究了人类与大型语言模型在预写过程中的合作模式，并发现了一个三阶段的人机共创过程：构思、启发和实施。在这个合作过程中，人类扮演着主导角色。

    

    预写是在第一稿之前发现和发展思想的过程，它需要发散性思维，通常涉及到无结构的策略，如图表、概述和自由写作等。虽然已经证明大型语言模型（LLMs）在各种任务中都是有用的，包括创意写作，但对用户如何与LLMs合作来支持预写的方式知之甚少。在这种创造性过程中，LLMs的首选合作角色和主动性也不明确。为了研究人类与LLMs在预写过程中的合作模式和动力学，我们进行了一项三节次的定性研究，与15位参与者进行了两个创造性任务：写故事和写口号。研究结果表明，在合作的预写过程中，似乎存在着一个三阶段迭代的人机共创过程，包括构思、启发和实施阶段。这个合作过程以人类在主导角色中取得了成功。

    Prewriting is the process of discovering and developing ideas before a first draft, which requires divergent thinking and often implies unstructured strategies such as diagramming, outlining, free-writing, etc. Although large language models (LLMs) have been demonstrated to be useful for a variety of tasks including creative writing, little is known about how users would collaborate with LLMs to support prewriting. The preferred collaborative role and initiative of LLMs during such a creativity process is also unclear. To investigate human-LLM collaboration patterns and dynamics during prewriting, we conducted a three-session qualitative study with 15 participants in two creative tasks: story writing and slogan writing. The findings indicated that during collaborative prewriting, there appears to be a three-stage iterative Human-AI Co-creativity process that includes Ideation, Illumination, and Implementation stages. This collaborative process champions the human in a dominant role, in
    
[^6]: Meta-Transformer: 一个统一的多模态学习框架

    Meta-Transformer: A Unified Framework for Multimodal Learning. (arXiv:2307.10802v1 [cs.CV])

    [http://arxiv.org/abs/2307.10802](http://arxiv.org/abs/2307.10802)

    Meta-Transformer是一个统一的多模态学习框架，利用一个冻结的编码器进行多模态感知，在没有成对多模态训练数据的情况下可以处理各种模态，并且能够提取输入数据的高级语义特征。

    

    多模态学习旨在构建能够处理和关联多种模态的信息的模型。尽管在这个领域已经有多年的发展，但由于不同模态之间的固有差距，设计一个用于处理各种模态的统一网络仍然具有挑战性。在这项工作中，我们提出了一个名为Meta-Transformer的框架，该框架利用一个冻结的编码器在没有成对多模态训练数据的情况下进行多模态感知。在Meta-Transformer中，来自各种模态的原始输入数据被映射到一个共享的标记空间中，使得后续的编码器可以提取输入数据的高级语义特征。由三个主要组件组成：一个统一的数据标记器，一个模态共享的编码器和用于下游任务的特定任务头，Meta-Transformer是第一个在12种模态上进行统一学习的框架。

    Multimodal learning aims to build models that can process and relate information from multiple modalities. Despite years of development in this field, it still remains challenging to design a unified network for processing various modalities ($\textit{e.g.}$ natural language, 2D images, 3D point clouds, audio, video, time series, tabular data) due to the inherent gaps among them. In this work, we propose a framework, named Meta-Transformer, that leverages a $\textbf{frozen}$ encoder to perform multimodal perception without any paired multimodal training data. In Meta-Transformer, the raw input data from various modalities are mapped into a shared token space, allowing a subsequent encoder with frozen parameters to extract high-level semantic features of the input data. Composed of three main components: a unified data tokenizer, a modality-shared encoder, and task-specific heads for downstream tasks, Meta-Transformer is the first framework to perform unified learning across 12 modaliti
    
[^7]: Layer-wise Representation Fusion for Compositional Generalization. (arXiv:2307.10799v1 [cs.CL])

    Layer-wise Representation Fusion for Compositional Generalization. (arXiv:2307.10799v1 [cs.CL])

    [http://arxiv.org/abs/2307.10799](http://arxiv.org/abs/2307.10799)

    该论文提出了一种层级表示融合的方法，以提升序列到序列模型在组合泛化方面的表现。之前的研究主要关注增强基于令牌的语义信息，而本文提出了在人类那样适当地组合和使用序列的句法和语义表示的方法。此外，从近期的关于训练更深Transformer的研究结果来看，纠缠问题主要是由于残差连接的“浅层”和简单的单步操作导致不能有效地融合前面层的信息。

    

    尽管序列到序列模型在广泛的应用中取得了成功，但其构建的解决方案被认为在组合泛化方面不如人类。越来越多的证据表明，阻碍组合泛化的一个原因是编码器和解码器最上层的表示被纠缠在一起。换句话说，序列的句法和语义表示被不适当地扭曲了。然而，大多数以前的研究主要集中于增强基于令牌的语义信息，以缓解表示纠缠问题，而不是像人类那样适当地组合和使用序列的句法和语义表示。此外，我们从近期关于训练更深Transformer的研究的角度解释了为什么纠缠问题存在，主要是由于“浅层”残差连接和其简单的单步操作导致无法有效地融合前面层的信息。

    Despite successes across a broad range of applications, sequence-to-sequence models' construct of solutions are argued to be less compositional than human-like generalization. There is mounting evidence that one of the reasons hindering compositional generalization is representations of the encoder and decoder uppermost layer are entangled. In other words, the syntactic and semantic representations of sequences are twisted inappropriately. However, most previous studies mainly concentrate on enhancing token-level semantic information to alleviate the representations entanglement problem, rather than composing and using the syntactic and semantic representations of sequences appropriately as humans do. In addition, we explain why the entanglement problem exists from the perspective of recent studies about training deeper Transformer, mainly owing to the ``shallow'' residual connections and its simple, one-step operations, which fails to fuse previous layers' information effectively. Sta
    
[^8]: 使用大型语言模型进行极端多标签技能提取训练

    Extreme Multi-Label Skill Extraction Training using Large Language Models. (arXiv:2307.10778v1 [cs.CL])

    [http://arxiv.org/abs/2307.10778](http://arxiv.org/abs/2307.10778)

    使用大型语言模型进行极端多标签技能提取训练，通过生成合成数据集和对比学习策略，提高了技能提取的准确率。

    

    在线职位广告是技能需求信息的宝贵来源，对劳动市场分析和电子招聘过程起着至关重要的作用。由于这些广告通常以自由文本格式呈现，因此需要自然语言处理（NLP）技术来自动处理它们。我们特别关注检测技能（明确提到或隐含描述）并将其链接到大型技能本体论的任务，这成为了极端多标签分类（XMLC）的一种具有挑战性的情况。考虑到这个特定的XMLC任务没有大规模的标记（训练）数据集可用，我们提出利用通用的大型语言模型（LLMs）的技术。我们描述了一种费用效益高的方法来生成一个准确的、完全合成的用于技能提取的标记数据集，并提出了一种对比学习策略，在任务中证明有效。我们在三个技能提取基准测试中的结果显示，准确率提高了15%到25%之间。

    Online job ads serve as a valuable source of information for skill requirements, playing a crucial role in labor market analysis and e-recruitment processes. Since such ads are typically formatted in free text, natural language processing (NLP) technologies are required to automatically process them. We specifically focus on the task of detecting skills (mentioned literally, or implicitly described) and linking them to a large skill ontology, making it a challenging case of extreme multi-label classification (XMLC). Given that there is no sizable labeled (training) dataset are available for this specific XMLC task, we propose techniques to leverage general Large Language Models (LLMs). We describe a cost-effective approach to generate an accurate, fully synthetic labeled dataset for skill extraction, and present a contrastive learning strategy that proves effective in the task. Our results across three skill extraction benchmarks show a consistent increase of between 15 to 25 percentag
    
[^9]: Vesper：一种用于语音情感识别的紧凑高效预训练模型

    Vesper: A Compact and Effective Pretrained Model for Speech Emotion Recognition. (arXiv:2307.10757v1 [cs.SD])

    [http://arxiv.org/abs/2307.10757](http://arxiv.org/abs/2307.10757)

    本文提出了一种用于语音情感识别的紧凑高效预训练模型Vesper，通过优化大规模预训练模型生成任务特定模型，考虑情感特征并采用情感引导的掩蔽策略来增强对情感信息的敏感性。

    

    本文提出了一种将通用大规模预训练模型（PTMs）适应语音情感识别任务的范式。尽管PTMs为人工智能提供了新的思路，但它们是为通用任务构建的，因此在特定任务上的效果仍有提升空间。此外，由于PTMs体积较大，在实际应用中使用可能面临挑战。针对以上限制，本文提出了另一个研究方向，即优化大规模PTMs以生成紧凑且高效的任务特定PTMs。本文聚焦于语音情感识别任务，提出了一种改进的情感特定预训练编码器Vesper。Vesper在基于WavLM的语音数据集上进行预训练，并考虑了情感特征。为了增强对情感信息的敏感性，Vesper采用情感引导的掩蔽策略来识别需要掩蔽的区域。

    This paper presents a paradigm that adapts general large-scale pretrained models (PTMs) to speech emotion recognition task. Although PTMs shed new light on artificial general intelligence, they are constructed with general tasks in mind, and thus, their efficacy for specific tasks can be further improved. Additionally, employing PTMs in practical applications can be challenging due to their considerable size. Above limitations spawn another research direction, namely, optimizing large-scale PTMs for specific tasks to generate task-specific PTMs that are both compact and effective. In this paper, we focus on the speech emotion recognition task and propose an improved emotion-specific pretrained encoder called Vesper. Vesper is pretrained on a speech dataset based on WavLM and takes into account emotional characteristics. To enhance sensitivity to emotional information, Vesper employs an emotion-guided masking strategy to identify the regions that need masking. Subsequently, Vesper emplo
    
[^10]: 探讨人工智能对知识工作创造力的影响：超越机械化抄袭和随机鹦鹉的视角

    Exploring Perspectives on the Impact of Artificial Intelligence on the Creativity of Knowledge Work: Beyond Mechanised Plagiarism and Stochastic Parrots. (arXiv:2307.10751v1 [cs.HC])

    [http://arxiv.org/abs/2307.10751](http://arxiv.org/abs/2307.10751)

    人工智能对知识工作的创造力有着深远的影响，但是对生成模型的批评者认为其输出只是随机的抄袭和混搭。然而，创造力和原创性的定义是复杂的，可能是一个过程、一个作者或一个观看者的属性。

    

    人工智能（AI），尤其是生成模型，是知识工作的变革性工具。它们问题化了创造力、原创性、抄袭、归属权和版权所有权的概念。对生成模型的批评者强调其依赖大量的训练数据，并将这些模型的输出视为随机的抄袭、混搭或者拼贴源数据。基于这些理由，许多人主张对这些模型的部署、使用和输出的归属加强监管。然而，这些问题并不是人工智能独有的，也不是新问题。在这篇立场论文中，我使用文学批评、艺术史和版权法的例子，展示了创造力和原创性如何抵抗被定义为一个对象的可注释或信息论属性，而可见为一个过程、一个作者或一个观看者的属性。一些替代观点认为创造性工作实质上是一种需求一定程度的模仿、颠倒和重新组合。

    Artificial Intelligence (AI), and in particular generative models, are transformative tools for knowledge work. They problematise notions of creativity, originality, plagiarism, the attribution of credit, and copyright ownership. Critics of generative models emphasise the reliance on large amounts of training data, and view the output of these models as no more than randomised plagiarism, remix, or collage of the source data. On these grounds, many have argued for stronger regulations on the deployment, use, and attribution of the output of these models. However, these issues are not new or unique to artificial intelligence. In this position paper, using examples from literary criticism, the history of art, and copyright law, I show how creativity and originality resist definition as a notatable or information-theoretic property of an object, and instead can be seen as the property of a process, an author, or a viewer. Further alternative views hold that all creative work is essentiall
    
[^11]: 大型语言模型塑造并受到社会的影响：arXiv出版模式调查

    Large language models shape and are shaped by society: A survey of arXiv publication patterns. (arXiv:2307.10700v1 [cs.DL])

    [http://arxiv.org/abs/2307.10700](http://arxiv.org/abs/2307.10700)

    大型语言模型的论文数量急剧增加，研究重点逐渐转向社会影响。与LLM相关的论文呈现持续增长的趋势，新发表关于LLM的作者更注重应用和社会影响。

    

    大型语言模型的论文数量近年来呈急剧增加，这种变化对科学领域产生了戏剧性的影响，但目前还没有进行详细的文献计量分析。本文分析了CS和Stat arXiv上发布的388K篇论文，并重点关注2023年与2018-2022年之间发表模式的变化。我们分析了LLM论文的比例增加情况，得到了最多关注的与LLM相关的主题，撰写LLM论文的作者，作者的研究主题与背景的相关性，区分高被引用LLM论文的因素，以及国际合作的模式。我们展示了LLM研究越来越关注社会影响：在计算机与社会子arXiv上，与LLM相关的论文比例增加了18倍，新发表关于LLM的作者更倾向于关注应用和社会影响。LLM研究也受到社会动态的影响。

    There has been a steep recent increase in the number of large language model (LLM) papers, producing a dramatic shift in the scientific landscape which remains largely undocumented through bibliometric analysis. Here, we analyze 388K papers posted on the CS and Stat arXivs, focusing on changes in publication patterns in 2023 vs. 2018-2022. We analyze how the proportion of LLM papers is increasing; the LLM-related topics receiving the most attention; the authors writing LLM papers; how authors' research topics correlate with their backgrounds; the factors distinguishing highly cited LLM papers; and the patterns of international collaboration. We show that LLM research increasingly focuses on societal impacts: there has been an 18x increase in the proportion of LLM-related papers on the Computers and Society sub-arXiv, and authors newly publishing on LLMs are more likely to focus on applications and societal impacts than more experienced authors. LLM research is also shaped by social dyn
    
[^12]: 《捷克新闻文本分类的数据集和强基线》

    A Dataset and Strong Baselines for Classification of Czech News Texts. (arXiv:2307.10666v1 [cs.CL])

    [http://arxiv.org/abs/2307.10666](http://arxiv.org/abs/2307.10666)

    该论文介绍了捷克新闻文本分类的数据集和基线模型。通过引入CZEch~NEws~Classification~dataset（CZE-NEC），这个跨越20多年的最大捷克新闻分类数据集，可以更严格地评估捷克自然语言处理的预训练模型。实验证明，基于预训练变换器模型的机器学习基线表现优于人类，并且语言特定的预训练编码器分析也超过了商业模型。

    

    捷克自然语言处理的预训练模型通常在纯语言任务（词性标注、句法分析、命名实体识别）和相对简单的分类任务（情感分类、来自单一新闻源的文章分类）上进行评估。作为替代，我们介绍了CZEch~NEws~Classification~dataset（CZE-NEC），这是一个最大的捷克分类数据集，包含来自各种来源、跨越二十多年的新闻文章，可以更严格地评估这种模型。我们定义了四个分类任务：新闻源、新闻类别、推断作者的性别和星期几。为了验证任务的难度，我们进行了人工评估，结果显示，人类的表现落后于基于预训练变换器模型构建的强大机器学习基线。此外，我们还展示了语言特定的预训练编码器分析优于选定的商业可用的大规模生成语言模型。

    Pre-trained models for Czech Natural Language Processing are often evaluated on purely linguistic tasks (POS tagging, parsing, NER) and relatively simple classification tasks such as sentiment classification or article classification from a single news source. As an alternative, we present CZEch~NEws~Classification~dataset (CZE-NEC), one of the largest Czech classification datasets, composed of news articles from various sources spanning over twenty years, which allows a more rigorous evaluation of such models. We define four classification tasks: news source, news category, inferred author's gender, and day of the week. To verify the task difficulty, we conducted a human evaluation, which revealed that human performance lags behind strong machine-learning baselines built upon pre-trained transformer models. Furthermore, we show that language-specific pre-trained encoder analysis outperforms selected commercially available large-scale generative language models.
    
[^13]: 探讨自然语言处理研究领域的发展趋势

    Exploring the Landscape of Natural Language Processing Research. (arXiv:2307.10652v1 [cs.CL])

    [http://arxiv.org/abs/2307.10652](http://arxiv.org/abs/2307.10652)

    该论文系统分类和分析了ACL Anthology中的研究论文，提供了对研究领域的结构化概述和NLP领域的分类学。本研究总结了最新的NLP发展，并提出了未来工作的方向。

    

    自然语言处理(NLP)作为理解、生成和处理自然语言文本的一种高效方法，在近年来得到了快速传播和广泛应用。鉴于该领域研究工作的不断增加，研究界已对数个与NLP相关的方法进行了调查。然而，到目前为止，仍缺少一项全面的研究，对已建立的主题进行分类、识别趋势并概括未来研究方向。为填补这一空白，我们对ACL Anthology中包含的研究论文进行了系统分类和分析。结果呈现了研究领域的结构化概述，为NLP领域的研究提供了一个分类学，分析了NLP的最新发展，总结了我们的研究发现，并突出了未来工作的方向。

    As an efficient approach to understand, generate, and process natural language texts, research in natural language processing (NLP) has exhibited a rapid spread and wide adoption in recent years. Given the increasing amount of research work in this area, several NLP-related approaches have been surveyed in the research community. However, a comprehensive study that categorizes established topics, identifies trends, and outlines areas for future research remains absent to this day. Contributing to closing this gap, we have systematically classified and analyzed research papers included in the ACL Anthology. As a result, we present a structured overview of the research landscape, provide a taxonomy of fields-of-study in NLP, analyze recent developments in NLP, summarize our findings, and highlight directions for future work.
    
[^14]: SciBench: 对大型语言模型评估大学水平的科学问题解决能力

    SciBench: Evaluating College-Level Scientific Problem-Solving Abilities of Large Language Models. (arXiv:2307.10635v1 [cs.CL])

    [http://arxiv.org/abs/2307.10635](http://arxiv.org/abs/2307.10635)

    这篇论文介绍了一个名为SciBench的基准套件，旨在对大型语言模型的大学水平科学问题解决能力进行评估。研究结果显示，当前的语言模型在提供复杂科学问题解决能力方面还有不足之处。

    

    最近大型语言模型(LLMs)的进展在许多数学基准上取得了显著的进步。然而，这些基准大多只包含初高中科目的问题，仅包含多项选择题，并且仅限于基本算术运算范围。为了解决这些问题，本文介绍了一个广泛的基准套件SciBench，旨在系统地检测复杂科学问题解决所需的推理能力。SciBench包含两个经过精心策划的数据集：一个开放集，包括从数学、化学和物理教科书中摘录的大学水平的科学问题，以及一个封闭集，包含来自计算机科学和数学本科考试的问题。基于这两个数据集，我们对两个代表性的LLM进行了深入的基准研究，并采用不同的提示策略。结果表明，当前的LLMs在提供复杂科学问题解决能力方面还存在不足之处。

    Recent advances in large language models (LLMs) have demonstrated notable progress on many mathematical benchmarks. However, most of these benchmarks only feature problems grounded in junior and senior high school subjects, contain only multiple-choice questions, and are confined to a limited scope of elementary arithmetic operations. To address these issues, this paper introduces an expansive benchmark suite SciBench that aims to systematically examine the reasoning capabilities required for complex scientific problem solving. SciBench contains two carefully curated datasets: an open set featuring a range of collegiate-level scientific problems drawn from mathematics, chemistry, and physics textbooks, and a closed set comprising problems from undergraduate-level exams in computer science and mathematics. Based on the two datasets, we conduct an in-depth benchmark study of two representative LLMs with various prompting strategies. The results reveal that current LLMs fall short of deli
    
[^15]: 人类基因核苷酸序列的生成语言模型

    Generative Language Models on Nucleotide Sequences of Human Genes. (arXiv:2307.10634v1 [q-bio.GN])

    [http://arxiv.org/abs/2307.10634](http://arxiv.org/abs/2307.10634)

    本研究开发了一种生成语言模型，用于处理人类基因的核苷酸序列，填补了DNA序列生成模型研究的空白。

    

    自然语言处理领域的语言模型，特别是基于Transformer的模型，取得了巨大的成功。然而，在DNA相关的生物信息学领域，生成模型的研究相对较少。因此，本研究旨在开发一种类似于GPT-3的自回归生成语言模型，用于处理人类基因的核苷酸序列。考虑到处理整个DNA序列需要大量计算资源，我们决定在更小的尺度上进行研究，重点关注人类基因的核苷酸序列，而不是整个DNA。这个决策并不改变问题的结构，因为DNA和基因都可以看作由四种不同的核苷酸组成的一维序列。

    Language models, primarily transformer-based ones, obtained colossal success in NLP. To be more precise, studies like BERT in NLU and works such as GPT-3 for NLG are very crucial. DNA sequences are very close to natural language in terms of structure, so if the DNA-related bioinformatics domain is concerned, discriminative models, like DNABert, exist. Yet, the generative side of the coin is mainly unexplored to the best of our knowledge. Consequently, we focused on developing an autoregressive generative language model like GPT-3 for DNA sequences. Because working with whole DNA sequences is challenging without substantial computational resources, we decided to carry out our study on a smaller scale, focusing on nucleotide sequences of human genes, unique parts in DNA with specific functionalities, instead of the whole DNA. This decision did not change the problem structure a lot due to the fact that both DNA and genes can be seen as 1D sequences consisting of four different nucleotide
    
[^16]: 多方法自训练：通过文本改进代码生成，反之亦然

    Multi-Method Self-Training: Improving Code Generation With Text, And Vice Versa. (arXiv:2307.10633v1 [cs.CL])

    [http://arxiv.org/abs/2307.10633](http://arxiv.org/abs/2307.10633)

    多方法自训练可以通过在不同方法之间训练和生成数据来改善代码生成的性能，使模型更易于使用，并提高相关任务的性能。

    

    大型语言模型有许多解决同一问题的方法。这引入了新颖的优点（不同的方法可能对不同的问题有效），以及缺点（用户可能难以知道使用哪种方法）。在本文中，我们介绍了多方法自训练（MMST）方法，其中一种方法是在另一种方法的筛选输出上进行训练，从而增强每种方法的优点并改善它们的缺点。使用176B参数的语言和代码训练模型，我们证明MMST可以1）改善性能较差的方法（高达30%），使模型更易于使用，2）改善性能较好的方法（高达32.2%），使模型性能更优秀，以及3）通过改善模型生成解释能力，提高相关但不同任务的性能（高达10.3%）。然后，我们进行消融分析，探讨MMST的工作原理。我们证明MMST比传统的自训练方法生成更多数据，但性能提升更明显。

    Large Language Models have many methods for solving the same problem. This introduces novel strengths (different methods may work well for different problems) and weaknesses (it may be difficult for users to know which method to use). In this paper, we introduce Multi-Method Self-Training (MMST), where one method is trained on the filtered outputs of another, allowing us to augment the strengths and ameliorate the weaknesses of each method. Using a 176B parameter model trained on both language and code, we show that MMST can 1) improve the less performant method (up to 30%) making the model easier to use, 2) improve the more performant method (up to 32.2%) making the model more performant, and 3) improve the performance of related but distinct tasks (up to 10.3%) by improving the ability of the model to generate rationales. We then conduct ablation analyses to explore why MMST works. We show that MMST generates more data than traditional self-training, but the improvement in performanc
    
[^17]: 对NPTEL MOOC视频中成千上万个单词错误率差异的深入研究

    A Deep Dive into the Disparity of Word Error Rates Across Thousands of NPTEL MOOC Videos. (arXiv:2307.10587v1 [cs.CL])

    [http://arxiv.org/abs/2307.10587](http://arxiv.org/abs/2307.10587)

    该论文对NPTEL MOOC视频中成千上万个单词错误率差异进行了深入研究，发现由于说话者的语音特性存在差异，最先进的自动语音识别系统在某些地区或人口统计信息的说话者身上面临困难。

    

    自动语音识别（ASR）系统旨在将口语转录为书面文本，并在语音助手和转录服务等各种应用中发挥作用。然而，观察到尽管最先进的ASR系统在提供令人印象深刻的基准结果方面取得了成功，但由于说话者的语音特性存在差异，它们在某些地区或人口统计信息的说话者身上面临困难。在这项工作中，我们描述了一个庞大的语音数据集的策划，该数据集包含8740小时的技术讲座，以及由代表印度各个地区人口统计信息的讲师进行的讲座的记录。该数据集来源于非常流行的NPTEL MOOC平台。我们使用策划的数据集，通过衡量印度说话者的多样性人口统计特征，来衡量YouTube自动字幕和OpenAI Whisper模型的性能差异。

    Automatic speech recognition (ASR) systems are designed to transcribe spoken language into written text and find utility in a variety of applications including voice assistants and transcription services. However, it has been observed that state-of-the-art ASR systems which deliver impressive benchmark results, struggle with speakers of certain regions or demographics due to variation in their speech properties. In this work, we describe the curation of a massive speech dataset of 8740 hours consisting of $\sim9.8$K technical lectures in the English language along with their transcripts delivered by instructors representing various parts of Indian demography. The dataset is sourced from the very popular NPTEL MOOC platform. We use the curated dataset to measure the existing disparity in YouTube Automatic Captions and OpenAI Whisper model performance across the diverse demographic traits of speakers in India. While there exists disparity due to gender, native region, age and speech rate
    
[^18]: 通过口述方式操作进行指示遵循评估

    Instruction-following Evaluation through Verbalizer Manipulation. (arXiv:2307.10558v1 [cs.CL])

    [http://arxiv.org/abs/2307.10558](http://arxiv.org/abs/2307.10558)

    本文提出了一种新的指示遵循评估协议，口述者操作，通过口述任务标签来检查模型对先验知识的依赖程度，以及覆盖它们的能力，从而准确地进行指示遵循。

    

    虽然调整指令模型在各种自然语言处理任务中取得了显著的成功，但准确评估其遵循指令的能力仍然具有挑战性。现有的基准主要关注与模型在训练过程中学习的内容相吻合的常见指令。然而，对这些指令的回应能力并不一定意味着强大的遵循指令能力。在本文中，我们提出了一种新颖的指示遵循评估协议，称为口述者操作。它要求模型用与模型先验知识不同程度吻合的单词口述任务标签，从高度吻合（例如，对于积极情绪输出“积极”）到最少吻合（例如，对于积极情绪输出“消极”）。口述者操作可以与任何分类基准无缝集成，以检查模型对先验知识的依赖程度以及覆盖它们的能力，从而准确地进行指示遵循。

    While instruction-tuned models have shown remarkable success in various natural language processing tasks, accurately evaluating their ability to follow instructions remains challenging. Existing benchmarks primarily focus on common instructions that align well with what the model learned during training. However, proficiency in responding to these instructions does not necessarily imply strong ability in instruction following. In this paper, we propose a novel instruction-following evaluation protocol called verbalizer manipulation. It instructs the model to verbalize the task label with words aligning with model priors to different extents, adopting verbalizers from highly aligned (e.g., outputting ``postive'' for positive sentiment), to minimally aligned (e.g., outputting ``negative'' for positive sentiment). Verbalizer manipulation can be seamlessly integrated with any classification benchmark to examine the model's reliance on priors and its ability to override them to accurately 
    
[^19]: 区块链上的动态大型语言模型

    Dynamic Large Language Models on Blockchains. (arXiv:2307.10549v1 [cs.CV])

    [http://arxiv.org/abs/2307.10549](http://arxiv.org/abs/2307.10549)

    本文提出在区块链上训练和部署动态大型语言模型，通过使用分布式计算和提供无法篡改的交易分类帐的区块链技术，可使语言模型具备连续学习的能力，为下一代人工智能系统的发展提供了新的方法和启示。

    

    训练和部署大型语言模型需要大量的计算资源，因为语言模型包含数十亿个参数，文本拥有数千个标记。另一个问题是大型语言模型是静态的，在训练过程后就被固定下来了。为了解决这些问题，本文提出在区块链上训练和部署动态大型语言模型，区块链具有高计算性能并分布在一个计算机网络上。区块链是一个安全、分散和透明的系统，允许创建一个无法篡改的交易分类帐，无需中介机构。动态大型语言模型可以在训练过程之后不断从用户输入中学习。我们的方法提供了一种开发大型语言模型的新方法，并为下一代人工智能系统带来了启示。

    Training and deploying the large language models requires a large mount of computational resource because the language models contain billions of parameters and the text has thousands of tokens. Another problem is that the large language models are static. They are fixed after the training process. To tackle these issues, in this paper, we propose to train and deploy the dynamic large language model on blockchains, which have high computation performance and are distributed across a network of computers. A blockchain is a secure, decentralized, and transparent system that allows for the creation of a tamper-proof ledger for transactions without the need for intermediaries. The dynamic large language models can continuously learn from the user input after the training process. Our method provides a new way to develop the large language models and also sheds a light on the next generation artificial intelligence systems.
    
[^20]: Gender-tuning: 授权微调用于去偏置预训练语言模型的方法

    Gender-tuning: Empowering Fine-tuning for Debiasing Pre-trained Language Models. (arXiv:2307.10522v1 [cs.CL])

    [http://arxiv.org/abs/2307.10522](http://arxiv.org/abs/2307.10522)

    本研究提出了Gender-tuning方法，通过在下游任务的数据集上进行微调，去偏置预训练语言模型（PLMs），不仅能在PLMs的性别偏见得分方面优于现有方法，而且仅使用下游任务的数据集即可提高PLMs在下游任务中的性能。

    

    最近的研究表明，广泛使用的预训练语言模型（PLMs）从大型非调控的预训练语料库中传播社会偏见。现有的解决方案需要去偏置的训练过程和数据集，这些都需要大量资源和成本。此外，这些方法会损害PLMs在下游任务中的性能。在本研究中，我们提出了Gender-tuning，通过在下游任务的数据集上进行微调来去偏置PLMs。为了实现这个目标，Gender-tuning将掩码语言建模（MLM）的训练目标集成到微调的训练过程中。全面的实验证明，Gender-tuning在PLMs的平均性别偏见得分方面优于现有的基准线，同时仅使用下游任务的数据集来提高PLMs在下游任务中的性能。此外，Gender-tuning是一个可部署的去偏置工具，适用于任何采用原有微调方法的PLM。

    Recent studies have revealed that the widely-used Pre-trained Language Models (PLMs) propagate societal biases from the large unmoderated pre-training corpora. Existing solutions require debiasing training processes and datasets for debiasing, which are resource-intensive and costly. Furthermore, these methods hurt the PLMs' performance on downstream tasks. In this study, we propose Gender-tuning, which debiases the PLMs through fine-tuning on downstream tasks' datasets. For this aim, Gender-tuning integrates Masked Language Modeling (MLM) training objectives into fine-tuning's training process. Comprehensive experiments show that Gender-tuning outperforms the state-of-the-art baselines in terms of average gender bias scores in PLMs while improving PLMs' performance on downstream tasks solely using the downstream tasks' dataset. Also, Gender-tuning is a deployable debiasing tool for any PLM that works with original fine-tuning.
    
[^21]: 通过社区参与构建与社会文化包容性的刻板印象资源

    Building Socio-culturally Inclusive Stereotype Resources with Community Engagement. (arXiv:2307.10514v1 [cs.CL])

    [http://arxiv.org/abs/2307.10514](http://arxiv.org/abs/2307.10514)

    通过社区参与的努力，在印度社会背景下扩展了对刻板印象伤害的评估资源。这个工作强调了包容不同文化和社会背景的人们和经验，以避免对伤害测量的严重低估或扭曲。

    

    随着生成语言模型在全球范围内的迅速发展和部署，我们迫切需要在测量伤害方面进行扩展，不仅包括覆盖的伤害数量和类型，还要考虑到当地文化背景，包括边缘化身份和他们所经历的社会偏见。当前的评估范式在解决这个问题上存在局限性，因为它们不代表多元化、本地化但全球化的社会文化视角。为了避免对伤害测量产生严重低估或扭曲，我们迫切需要通过包含来自不同文化和社会的人们和经验来增强和校准我们的评估资源。在这项工作中，我们在印度社会背景下展示了对刻板印象伤害实施社会文化意识的评估资源的扩展。我们设计了一个社区参与的努力来构建一个包含刻板印象的资源。

    With rapid development and deployment of generative language models in global settings, there is an urgent need to also scale our measurements of harm, not just in the number and types of harms covered, but also how well they account for local cultural contexts, including marginalized identities and the social biases experienced by them. Current evaluation paradigms are limited in their abilities to address this, as they are not representative of diverse, locally situated but global, socio-cultural perspectives. It is imperative that our evaluation resources are enhanced and calibrated by including people and experiences from different cultures and societies worldwide, in order to prevent gross underestimations or skews in measurements of harm. In this work, we demonstrate a socio-culturally aware expansion of evaluation resources in the Indian societal context, specifically for the harm of stereotyping. We devise a community engaged effort to build a resource which contains stereotype
    
[^22]: IvyGPT：基于医学领域的互动式中文路径语言模型

    IvyGPT: InteractiVe Chinese pathwaY language model in medical domain. (arXiv:2307.10512v1 [cs.CL])

    [http://arxiv.org/abs/2307.10512](http://arxiv.org/abs/2307.10512)

    IvyGPT是一种基于医学领域的中文互动语言模型，通过使用高质量的医学问答示例和人类反馈强化学习进行训练和微调，它能够输出更丰富的诊断和治疗答案，从而在医学GPT模型中表现出色。

    

    一般的大型语言模型（LLM）如ChatGPT已取得了显著的成功。然而，由于精度不高和无法提供医疗建议，这些LLM在医学领域并未广泛应用。我们提出了一种基于LLaMA的LLM IvyGPT，它通过高质量的医学问答（QA）示例和人类反馈强化学习（RLHF）进行训练和微调。经过有监督微调后，IvyGPT具有良好的多轮对话能力，但在综合诊断等其他方面不能像医生一样运行。通过RLHF，IvyGPT可以输出更丰富的诊断和治疗答案，更接近于人类。在训练过程中，我们使用QLoRA在少量NVIDIA A100（80GB) GPU上训练了330亿个参数。实验结果表明，IvyGPT在医学GPT模型中表现优于其他模型。

    General large language models (LLMs) such as ChatGPT have shown remarkable success. However, such LLMs have not been widely adopted for medical purposes, due to poor accuracy and inability to provide medical advice. We propose IvyGPT, an LLM based on LLaMA that is trained and fine-tuned with high-quality medical question-answer (QA) instances and Reinforcement Learning from Human Feedback (RLHF). After supervised fine-tuning, IvyGPT has good multi-turn conversation capabilities, but it cannot perform like a doctor in other aspects, such as comprehensive diagnosis. Through RLHF, IvyGPT can output richer diagnosis and treatment answers that are closer to human. In the training, we used QLoRA to train 33 billion parameters on a small number of NVIDIA A100 (80GB) GPUs. Experimental results show that IvyGPT has outperformed other medical GPT models.
    
[^23]: 多模态情感分析的通用去偏方法

    General Debiasing for Multimodal Sentiment Analysis. (arXiv:2307.10511v1 [cs.CL])

    [http://arxiv.org/abs/2307.10511](http://arxiv.org/abs/2307.10511)

    提出了一个通用的去偏多模态情感分析任务，通过减少模型对虚假相关性的依赖，提高多模态情感分析模型的非分布外泛化能力。

    

    现有的多模态情感分析工作利用多模态信息进行预测，但不可避免地受到多模态特征和情感标签之间的虚假相关性的影响。例如，如果数据集中大多数带有蓝色背景的视频都有正面标签，模型将依赖于这样的相关性进行预测，而“蓝色背景”并不是一个与情感相关的特征。为解决这个问题，我们定义了一个通用的去偏多模态情感分析任务，旨在通过减少模型对虚假相关性的依赖，提高多模态情感分析模型的非分布外泛化能力。为此，我们提出了一个基于倒数概率加权（Inverse Probability Weighting，IPW）的通用去偏框架，该框架自适应地为具有更大偏差（即更严重的虚假相关性）的样本分配较小的权重。这个去偏框架的关键在于估计每个样本的偏差，这通过两个步骤实现：1）将鲁棒特征和偏见特征分离出来

    Existing work on Multimodal Sentiment Analysis (MSA) utilizes multimodal information for prediction yet unavoidably suffers from fitting the spurious correlations between multimodal features and sentiment labels. For example, if most videos with a blue background have positive labels in a dataset, the model will rely on such correlations for prediction, while ``blue background'' is not a sentiment-related feature. To address this problem, we define a general debiasing MSA task, which aims to enhance the Out-Of-Distribution (OOD) generalization ability of MSA models by reducing their reliance on spurious correlations. To this end, we propose a general debiasing framework based on Inverse Probability Weighting (IPW), which adaptively assigns small weights to the samples with larger bias i.e., the severer spurious correlations). The key to this debiasing framework is to estimate the bias of each sample, which is achieved by two steps: 1) disentangling the robust features and biased featur
    
[^24]: 图像和声音的滥用用于在多模态LLMs中进行间接指令注入

    (Ab)using Images and Sounds for Indirect Instruction Injection in Multi-Modal LLMs. (arXiv:2307.10490v1 [cs.CR])

    [http://arxiv.org/abs/2307.10490](http://arxiv.org/abs/2307.10490)

    本论文展示了如何利用图像和声音在多模态LLMs中进行间接指令注入，攻击者通过生成对抗扰动并将其融入图像或音频录音中，以操纵模型输出特定文本和指导对话的行为。

    

    我们展示了如何利用图像和声音在多模态LLMs中进行间接提示和指令注入。攻击者生成与提示相对应的对抗扰动，并将其融入图像或音频录音中。当用户向（未修改的良性）模型询问被扰动的图像或音频时，扰动会引导模型输出攻击者选择的文本和/或使后续对话遵循攻击者的指令。我们用几个概念验证示例针对LLaVa和PandaGPT来说明这种攻击。

    We demonstrate how images and sounds can be used for indirect prompt and instruction injection in multi-modal LLMs. An attacker generates an adversarial perturbation corresponding to the prompt and blends it into an image or audio recording. When the user asks the (unmodified, benign) model about the perturbed image or audio, the perturbation steers the model to output the attacker-chosen text and/or make the subsequent dialog follow the attacker's instruction. We illustrate this attack with several proof-of-concept examples targeting LLaVa and PandaGPT.
    
[^25]: SPRINT: 一种用于评估和解析零样本神经稀疏检索的统一工具包

    SPRINT: A Unified Toolkit for Evaluating and Demystifying Zero-shot Neural Sparse Retrieval. (arXiv:2307.10488v1 [cs.IR])

    [http://arxiv.org/abs/2307.10488](http://arxiv.org/abs/2307.10488)

    SPRINT是一个统一的Python工具包，基于Pyserini和Lucene，支持评估和解析零样本神经稀疏检索。它解决了缺乏统一环境和实现在未见过领域上的检索能力的问题。

    

    传统上，稀疏检索系统依赖于词汇表示来检索文档，如BM25，在信息检索任务中占主导地位。随着诸如BERT这样的预训练transformer模型的出现，神经稀疏检索引领了检索中的新范式。尽管取得了成功，但目前缺乏支持不同稀疏检索器在统一的环境中运行的软件。这妨碍了实践者公正地比较不同的稀疏模型，并获得真实的评估结果。还有一个缺失的部分是，大多数先前的工作是对稀疏检索模型进行域内检索评估，即仅在一个数据集上进行评估：MS MARCO。然而，在实际检索系统中，一个重要的要求是模型能够在未见过的域外，即零样本检索任务中具有良好的泛化能力。在这项工作中，我们提供了SPRINT，这是一个基于Pyserini和Lucene的统一Python工具包，支持神经稀疏检索的通用接口。

    Traditionally, sparse retrieval systems relied on lexical representations to retrieve documents, such as BM25, dominated information retrieval tasks. With the onset of pre-trained transformer models such as BERT, neural sparse retrieval has led to a new paradigm within retrieval. Despite the success, there has been limited software supporting different sparse retrievers running in a unified, common environment. This hinders practitioners from fairly comparing different sparse models and obtaining realistic evaluation results. Another missing piece is, that a majority of prior work evaluates sparse retrieval models on in-domain retrieval, i.e. on a single dataset: MS MARCO. However, a key requirement in practical retrieval systems requires models that can generalize well to unseen out-of-domain, i.e. zero-shot retrieval tasks. In this work, we provide SPRINT, a unified Python toolkit based on Pyserini and Lucene, supporting a common interface for evaluating neural sparse retrieval. The 
    
[^26]: FinGPT: 将互联网规模的金融数据民主化为金融大语言模型

    FinGPT: Democratizing Internet-scale Data for Financial Large Language Models. (arXiv:2307.10485v1 [cs.CL])

    [http://arxiv.org/abs/2307.10485](http://arxiv.org/abs/2307.10485)

    FinGPT是一个开源的数据为中心的框架，旨在将互联网规模的金融数据民主化为金融大语言模型。它提供了自动收集和整理实时金融数据的功能，解决了金融文本数据稀缺的问题。

    

    大型语言模型（LLM）在理解和生成类似人类文本方面展示了卓越的能力，这可能会彻底改变金融行业。然而，现有的LLM在金融领域往往表现不佳，主要原因是一般文本数据与金融文本数据之间的差异。不幸的是，现有的金融文本数据集数量有限（大小较小），而第一个金融LLM（FinLLM）BloombergGPT是封闭的（只发布了训练日志）。鉴于此，我们的目标是通过Internet规模的金融数据将LLM民主化，由于数据来源多样、信噪比低和时间有效性高，这是一个开放性的挑战。为了解决这些挑战，我们引入了一个开源和数据为中心的框架“金融生成预训练变压器（FinGPT）”，它可以自动收集和整理来自互联网上超过34个不同来源的实时金融数据。

    Large language models (LLMs) have demonstrated remarkable proficiency in understanding and generating human-like texts, which may potentially revolutionize the finance industry. However, existing LLMs often fall short in the financial field, which is mainly attributed to the disparities between general text data and financial text data. Unfortunately, there is only a limited number of financial text datasets available (quite small size), and BloombergGPT, the first financial LLM (FinLLM), is close-sourced (only the training logs were released). In light of this, we aim to democratize Internet-scale financial data for LLMs, which is an open challenge due to diverse data sources, low signal-to-noise ratio, and high time-validity. To address the challenges, we introduce an open-sourced and data-centric framework, \textit{Financial Generative Pre-trained Transformer (FinGPT)}, that automates the collection and curation of real-time financial data from >34 diverse sources on the Internet, p
    
[^27]: 数据泄露和遗忘对法律的启示

    What can we learn from Data Leakage and Unlearning for Law?. (arXiv:2307.10476v1 [cs.CR])

    [http://arxiv.org/abs/2307.10476](http://arxiv.org/abs/2307.10476)

    本研究发现，大型语言模型存在泄露训练数据的问题，删除最容易被提取的用户数据后，新的数据点仍然容易被提取。精调模型不仅泄露训练数据，还会泄露预训练阶段记忆的预训练数据和个人身份信息。

    

    大型语言模型存在隐私问题，会在推理过程中泄露训练数据（包括个人身份信息如电子邮件和电话号码）。为了遵守隐私法律，可以删除最容易被提取的用户数据。然而我们发现，一旦删除了最容易被提取的数据，一组新的数据点就会变得容易被提取。目前对于精调模型的记忆性尚未引起足够的关注。在这项研究中，我们还展示了精调模型不仅泄露其训练数据，而且还会泄露在预训练阶段记忆的预训练数据（以及个人身份信息）。

    Large Language Models (LLMs) have a privacy concern because they memorize training data (including personally identifiable information (PII) like emails and phone numbers) and leak it during inference. A company can train an LLM on its domain-customized data which can potentially also include their users' PII. In order to comply with privacy laws such as the "right to be forgotten", the data points of users that are most vulnerable to extraction could be deleted. We find that once the most vulnerable points are deleted, a new set of points become vulnerable to extraction. So far, little attention has been given to understanding memorization for fine-tuned models. In this work, we also show that not only do fine-tuned models leak their training data but they also leak the pre-training data (and PII) memorized during the pre-training phase. The property of new data points becoming vulnerable to extraction after unlearning and leakage of pre-training data through fine-tuned models can pos
    
[^28]: Factify 2调查报告: 多模态假新闻检测

    Findings of Factify 2: Multimodal Fake News Detection. (arXiv:2307.10475v1 [cs.CL])

    [http://arxiv.org/abs/2307.10475](http://arxiv.org/abs/2307.10475)

    Factify 2进行了一项多模态假新闻检测任务，通过比较社交媒体声明和支持文件的文本和图像信息，实现了对假新闻的自动检测和验证，最佳性能达到了81.82%的F1分数。

    

    随着社交媒体的使用在过去几年呈指数级增长，假新闻也变得非常普遍。假新闻的有害影响强调了研究自动检测错误信息并验证其准确性的需求。在这项工作中，我们呈现了Factify 2的结果，这是作为AAAI'23的DeFactify 2工作坊的一部分提供的多模态事实验证和讽刺新闻数据集。数据呼唤一种基于比较的方法来配对社交媒体声明和支持文件，包括文本和图像，根据多模态关系分为5类。在这个任务的第二次迭代中，我们有超过60个参与者和9个终期测试提交。最好的表现来自于在文本方面使用DeBERTa，在图像方面使用Swinv2和CLIP。所有五个类别的F1分数平均达到了81.82%。

    With social media usage growing exponentially in the past few years, fake news has also become extremely prevalent. The detrimental impact of fake news emphasizes the need for research focused on automating the detection of false information and verifying its accuracy. In this work, we present the outcome of the Factify 2 shared task, which provides a multi-modal fact verification and satire news dataset, as part of the DeFactify 2 workshop at AAAI'23. The data calls for a comparison based approach to the task by pairing social media claims with supporting documents, with both text and image, divided into 5 classes based on multi-modal relations. In the second iteration of this task we had over 60 participants and 9 final test-set submissions. The best performances came from the use of DeBERTa for text and Swinv2 and CLIP for image. The highest F1 score averaged for all five classes was 81.82%.
    
[^29]: 通过提示，指令微调的语言模型能否识别社会偏见？

    Can Instruction Fine-Tuned Language Models Identify Social Bias through Prompting?. (arXiv:2307.10472v1 [cs.CL])

    [http://arxiv.org/abs/2307.10472](http://arxiv.org/abs/2307.10472)

    本文介绍了一种通过零样本提示评估指令微调语言模型识别偏见能力的方法，展示了Alpaca 7B在偏见识别任务中的最佳性能，并提出扩大模型大小和数据多样性可进一步提高性能。

    

    随着语言模型应用的广度和深度不断扩展，构建有效的框架来衡量和减轻这些模型学习或继承的社会偏见变得越来越重要。本文提出了一种评估指令微调语言模型通过零样本提示（包括思维链提示）识别偏见能力的方法。在LLaMA及其两个指令微调版本中，Alpaca 7B在偏见识别任务中表现最好，准确率达56.7%。我们还展示了扩大语言模型大小和数据多样性可以进一步提高性能。这是我们偏见缓解框架的第一部分，正在进行的工作。我们将根据获得的更多结果不断更新本文。

    As the breadth and depth of language model applications continue to expand rapidly, it is increasingly important to build efficient frameworks for measuring and mitigating the learned or inherited social biases of these models. In this paper, we present our work on evaluating instruction fine-tuned language models' ability to identify bias through zero-shot prompting, including Chain-of-Thought (CoT) prompts. Across LLaMA and its two instruction fine-tuned versions, Alpaca 7B performs best on the bias identification task with an accuracy of 56.7%. We also demonstrate that scaling up LLM size and data diversity could lead to further performance gain. This is a work-in-progress presenting the first component of our bias mitigation framework. We will keep updating this work as we get more results.
    
[^30]: 提高预训练语言模型的泛化能力

    Improving Pre-trained Language Models' Generalization. (arXiv:2307.10457v1 [cs.CL])

    [http://arxiv.org/abs/2307.10457](http://arxiv.org/abs/2307.10457)

    该研究提出了一种名为Mask-tuning的训练方法，通过将Masked Language Modeling (MLM)训练目标整合到微调过程中来增强预训练语言模型（PLMs）的泛化能力。实验证明，Mask-tuning在非分布数据集上超过了当前最先进的技术，并提高了PLMs在分布数据集上的性能。

    

    最先进的预训练语言模型（PLMs）的可重复使用性通常受到其泛化问题的限制，即当在与训练数据集不同的示例上进行评估时，其性能显著下降，这种示例被称为“非分布/未见示例”。这一限制源于PLMs对虚假相关性的依赖，虚假相关性对于常见示例类型效果良好，但对于一般示例效果不佳。为了解决这个问题，我们提出了一种称为Mask-tuning的训练方法，该方法将遮蔽语言建模（MLM）训练目标整合到微调过程中，以增强PLMs的泛化能力。全面的实验表明，Mask-tuning超过了当前最先进的技术，并增强了PLMs对非分布数据集的泛化能力，同时提高了它们在分布数据集上的性能。研究结果表明，Mask-tuning提高了PLMs在未见数据上的可重复使用性，使它们在实际应用中更加实用和有效。

    The reusability of state-of-the-art Pre-trained Language Models (PLMs) is often limited by their generalization problem, where their performance drastically decreases when evaluated on examples that differ from the training dataset, known as Out-of-Distribution (OOD)/unseen examples. This limitation arises from PLMs' reliance on spurious correlations, which work well for frequent example types but not for general examples. To address this issue, we propose a training approach called Mask-tuning, which integrates Masked Language Modeling (MLM) training objectives into the fine-tuning process to enhance PLMs' generalization. Comprehensive experiments demonstrate that Mask-tuning surpasses current state-of-the-art techniques and enhances PLMs' generalization on OOD datasets while improving their performance on in-distribution datasets. The findings suggest that Mask-tuning improves the reusability of PLMs on unseen data, making them more practical and effective for real-world applications
    
[^31]: 使用相对位置标签将异构图与实体感知自注意力相结合的阅读理解模型

    Integrating a Heterogeneous Graph with Entity-aware Self-attention using Relative Position Labels for Reading Comprehension Model. (arXiv:2307.10443v1 [cs.CL])

    [http://arxiv.org/abs/2307.10443](http://arxiv.org/abs/2307.10443)

    本文提出了一种新的注意力模式，使用图增强自注意力机制将从异构图中导出的推理知识整合到变压器架构中，从而克服了变压器模型在复杂推理任务中的限制。通过全局-局部注意力、图注意力和关系类型考虑，优化了实体和单词之间的注意力。该模式与相对位置标签相结合，能够与LUKE的实体感知自注意力机制相集成。

    

    尽管变压器模型在机器阅读理解任务中取得了重大进展，但由于输入序列中缺少显式知识，它们仍然面临处理复杂推理任务的限制。本文提出了一种新颖的注意力模式来克服这个限制，它利用增强图自注意力机制将由异构图导出的推理知识整合到变压器架构中。提出的注意力模式包括三个关键要素：单词标记的全局-局部注意力，对实体标记的图注意力，实体标记对相关联的标记显示强烈的注意力而对不相关的标记显示较弱的注意力，以及考虑每个实体标记与单词标记之间的关系类型。这样，如果存在关系，则可以优化两者之间的注意力。该模式与特殊的相对位置标签相结合，使其能够与LUKE的实体感知自注意力机制相集成。

    Despite the significant progress made by transformer models in machine reading comprehension tasks, they still face limitations in handling complex reasoning tasks due to the absence of explicit knowledge in the input sequence. This paper proposes a novel attention pattern to overcome this limitation, which integrates reasoning knowledge derived from a heterogeneous graph into the transformer architecture using a graph-enhanced self-attention mechanism. The proposed attention pattern comprises three key elements: global-local attention for word tokens, graph attention for entity tokens that exhibit strong attention towards tokens connected in the graph as opposed to those unconnected, and the consideration of the type of relationship between each entity token and word token. This results in optimized attention between the two if a relationship exists. The pattern is coupled with special relative position labels, allowing it to integrate with LUKE's entity-aware self-attention mechanism
    
[^32]: Thrust: 用外部知识自适应推动大型语言模型

    Thrust: Adaptively Propels Large Language Models with External Knowledge. (arXiv:2307.10442v1 [cs.CL])

    [http://arxiv.org/abs/2307.10442](http://arxiv.org/abs/2307.10442)

    本论文提出了一种实例级的自适应推动外部知识的方法，通过衡量大型语言模型的知识水平，并利用Thrust指标进行信息检索，实现更高的成本效益。

    

    尽管大规模预训练语言模型（PTLM）已被证明在其模型参数中编码了丰富的知识，但PTLM中的内在知识可能是不透明或静态的，因此需要外部知识。然而，现有的信息检索技术可能成本高昂，甚至可能引入噪音和误导性知识。为了解决这些挑战，我们提出了实例级的自适应推动外部知识（IAPEK），只有在必要时才进行检索。为了实现这一目标，我们提出了一种新的度量标准Thrust，利用少量已见实例的表示分布来衡量PTLM是否包含足够的知识来解决一个实例。大量实验证明，Thrust是衡量PTLM模型实例级知识能力的良好指标。此外，利用Thrust分数作为检索指标可以实现显著的成本效益，高于对外部知识的朴素使用。

    Although large-scale pre-trained language models (PTLMs) are shown to encode rich knowledge in their model parameters, the inherent knowledge in PTLMs can be opaque or static, making external knowledge necessary. However, the existing information retrieval techniques could be costly and may even introduce noisy and sometimes misleading knowledge. To address these challenges, we propose the instance-level adaptive propulsion of external knowledge (IAPEK), where we only conduct the retrieval when necessary. To achieve this goal, we propose measuring whether a PTLM contains enough knowledge to solve an instance with a novel metric, Thrust, which leverages the representation distribution of a small number of seen instances. Extensive experiments demonstrate that thrust is a good measurement of PTLM models' instance-level knowledgeability. Moreover, we can achieve significantly higher cost-efficiency with the Thrust score as the retrieval indicator than the naive usage of external knowledge
    
[^33]: PharmacyGPT：AI药师

    PharmacyGPT: The AI Pharmacist. (arXiv:2307.10432v1 [cs.CL])

    [http://arxiv.org/abs/2307.10432](http://arxiv.org/abs/2307.10432)

    PharmacyGPT是一个新颖的框架，利用大型语言模型（LLM）来仿真临床药师的角色。通过生成患者群集、制定用药计划和预测患者结果，PharmacyGPT在临床药学中具有潜在应用和限制，为促进负责任和有效使用人工智能技术做出贡献。

    

    本研究介绍了PharmacyGPT，这是一个新颖的框架，用于评估大型语言模型（LLM）（如ChatGPT和GPT-4）在仿真临床药师角色方面的能力。我们的方法包括利用LLM生成可理解的患者群集、制定用药计划和预测患者结果。我们使用从北卡罗来纳大学教堂山医院（UNC）重症监护病房（ICU）获取的真实数据进行调查。我们的分析提供了对LLM在临床药学领域潜在应用和限制的有价值见解，对患者护理和未来基于AI的医疗解决方案的开发具有重要意义。通过评估PharmacyGPT的性能，我们旨在为有关在医疗保健环境中整合人工智能的持续讨论做出贡献，最终促进负责任和有效使用此类技术。

    In this study, we introduce PharmacyGPT, a novel framework to assess the capabilities of large language models (LLMs) such as ChatGPT and GPT-4 in emulating the role of clinical pharmacists. Our methodology encompasses the utilization of LLMs to generate comprehensible patient clusters, formulate medication plans, and forecast patient outcomes. We conduct our investigation using real data acquired from the intensive care unit (ICU) at the University of North Carolina Chapel Hill (UNC) Hospital. Our analysis offers valuable insights into the potential applications and limitations of LLMs in the field of clinical pharmacy, with implications for both patient care and the development of future AI-driven healthcare solutions. By evaluating the performance of PharmacyGPT, we aim to contribute to the ongoing discourse surrounding the integration of artificial intelligence in healthcare settings, ultimately promoting the responsible and efficacious use of such technologies.
    
[^34]: IncDSI：递增可更新的文档检索

    IncDSI: Incrementally Updatable Document Retrieval. (arXiv:2307.10323v1 [cs.IR])

    [http://arxiv.org/abs/2307.10323](http://arxiv.org/abs/2307.10323)

    IncDSI是一种递增可更新的文档检索方法，它通过最小改变网络参数的约束优化问题，实现实时添加文档而无需重新训练整个模型，具有与重新训练模型相竞争的速度，能够实时更新的文档检索系统的开发。

    

    不同iable搜索索引是最近提出的一种文档检索范例，它将文档语料库的信息编码在神经网络的参数中，并直接将查询映射到相应的文档。这些模型在许多基准测试中取得了最先进的性能。这些模型具有一个重要限制：在训练模型之后添加新文档并不容易。我们提出了IncDSI，一种实时添加文档的方法（每个文档约20-50毫秒），而无需对整个数据集（甚至部分数据集）重新训练模型。相反，我们将添加文档的过程形式化为一个在网络参数上进行最小改变的约束优化问题。虽然速度更快几个数量级，但我们的方法与在整个数据集上重新训练模型相竞争，并且可以实时更新的文档检索系统的开发。我们的IncDSI代码

    Differentiable Search Index is a recently proposed paradigm for document retrieval, that encodes information about a corpus of documents within the parameters of a neural network and directly maps queries to corresponding documents. These models have achieved state-of-the-art performances for document retrieval across many benchmarks. These kinds of models have a significant limitation: it is not easy to add new documents after a model is trained. We propose IncDSI, a method to add documents in real time (about 20-50ms per document), without retraining the model on the entire dataset (or even parts thereof). Instead we formulate the addition of documents as a constrained optimization problem that makes minimal changes to the network parameters. Although orders of magnitude faster, our approach is competitive with re-training the model on the whole dataset and enables the development of document retrieval systems that can be updated with new information in real-time. Our code for IncDSI
    
[^35]: 基于歌词的孟加拉歌曲情绪分类

    Mood Classification of Bangla Songs Based on Lyrics. (arXiv:2307.10314v1 [cs.IR])

    [http://arxiv.org/abs/2307.10314](http://arxiv.org/abs/2307.10314)

    本研究通过分析孟加拉歌曲的歌词，成功实现了对这些歌曲的情绪进行多类分类，包括快乐、悲伤、浪漫和放松，为使音乐更贴近人们的情感做出了重要贡献。

    

    音乐能唤起各种情绪，随着技术的进步，人们对音乐的接触也越来越多。然而对于展现不同人类情感的孟加拉音乐，相关的研究尚不足够。本文的作者旨在通过分析孟加拉歌曲的歌词来分类其情绪。为实现这一目标，研究人员收集了4000首孟加拉歌曲的歌词和流派，并运用自然语言处理和BERT算法来分析数据。在这4000首歌曲中，1513首代表悲伤情绪，1362首代表浪漫情绪，886首代表快乐，其余的239首被归类为放松。通过嵌入歌词，作者将这些歌曲分为四种情绪：快乐、悲伤、浪漫和放松。该研究对于实现音乐的多类情绪分类至关重要，使音乐更能与人们的情感产生共鸣。该文章详细描述了通过歌词准确推导出的四种情绪的自动化结果。

    Music can evoke various emotions, and with the advancement of technology, it has become more accessible to people. Bangla music, which portrays different human emotions, lacks sufficient research. The authors of this article aim to analyze Bangla songs and classify their moods based on the lyrics. To achieve this, this research has compiled a dataset of 4000 Bangla song lyrics, genres, and used Natural Language Processing and the Bert Algorithm to analyze the data. Among the 4000 songs, 1513 songs are represented for the sad mood, 1362 for the romantic mood, 886 for happiness, and the rest 239 are classified as relaxation. By embedding the lyrics of the songs, the authors have classified the songs into four moods: Happy, Sad, Romantic, and Relaxed. This research is crucial as it enables a multi-class classification of songs' moods, making the music more relatable to people's emotions. The article presents the automated result of the four moods accurately derived from the song lyrics.
    
[^36]: 分析体育评论以实现自动识别事件并提取洞见

    Analyzing sports commentary in order to automatically recognize events and extract insights. (arXiv:2307.10303v1 [cs.CL])

    [http://arxiv.org/abs/2307.10303](http://arxiv.org/abs/2307.10303)

    通过分析多种体育赛事的实时评论，利用自然语言处理技术自动识别主要行动，并通过分类和情感分析提取洞见。

    

    本文中，我们仔细研究了如何利用多种自然语言处理技术和方法，以自动识别体育赛事中的主要行动。我们通过分析不同来源的现场体育评论，并将这些主要行动分类到不同的类别中，来提取洞见。我们还研究了情感分析是否可以帮助检测这些主要行动。

    In this paper, we carefully investigate how we can use multiple different Natural Language Processing techniques and methods in order to automatically recognize the main actions in sports events. We aim to extract insights by analyzing live sport commentaries from different sources and by classifying these major actions into different categories. We also study if sentiment analysis could help detect these main actions.
    
[^37]: 语言迷宫：对人工智能话语中术语使用的建设性批评

    The Language Labyrinth: Constructive Critique on the Terminology Used in the AI Discourse. (arXiv:2307.10292v1 [cs.CY])

    [http://arxiv.org/abs/2307.10292](http://arxiv.org/abs/2307.10292)

    这篇文章对人工智能领域使用的术语进行了建设性批评，指出AI的讨论缺乏对隐喻的批判性距离，导致对责任和潜在用途的反思被扭曲。文章通过提出更合适的术语来促进更富有成果的辩论。

    

    在跨学科的人工智能（AI）领域中，术语明确性的问题尤为重要。本文认为，AI的讨论仍然缺乏对诸如“训练”、“学习”或“决策”等隐喻的批判性距离。因此，关于责任或潜在用途的反思被严重扭曲。然而，如果相关决策者相信AI可以发展“理解”或正确“解释”问题，那么它在决定社会福利或审判案件等敏感任务时的常规使用将会出现。本章通过分析AI辩论的核心概念来支持其观点，并通过提出更合适的术语来促进更富有成果的辩论。它是一项在批判性计算机科学和语言哲学之间交叉的概念性工作。

    In the interdisciplinary field of artificial intelligence (AI) the problem of clear terminology is especially momentous. This paper claims, that AI debates are still characterised by a lack of critical distance to metaphors like 'training', 'learning' or 'deciding'. As consequence, reflections regarding responsibility or potential use-cases are greatly distorted. Yet, if relevant decision-makers are convinced that AI can develop an 'understanding' or properly 'interpret' issues, its regular use for sensitive tasks like deciding about social benefits or judging court cases looms. The chapter argues its claim by analysing central notions of the AI debate and tries to contribute by proposing more fitting terminology and hereby enabling more fruitful debates. It is a conceptual work at the intersection of critical computer science and philosophy of language.
    
[^38]: 日语句子分类和命名实体识别任务中的相互增强效应

    Mutual Reinforcement Effects in Japanese Sentence Classification and Named Entity Recognition Tasks. (arXiv:2307.10291v1 [cs.CL])

    [http://arxiv.org/abs/2307.10291](http://arxiv.org/abs/2307.10291)

    该研究提出了一个综合分析方法，将句子分类和命名实体识别结合起来，并揭示了这两个信息提取子任务之间的相互增强效应。

    

    信息提取（IE）是自然语言处理中的重要领域。然而，对于传统分段方法在句子分类和命名实体识别任务中的复杂互动，目前研究尚不充分。本研究提出了一个综合分析方法，将句子分类和命名实体识别结合起来，旨在揭示和理解这两个信息提取子任务之间的相互增强效应。为了实现这个目标，我们引入了一个句子分类和命名实体识别多任务（SCNM）方法，结合了句子分类（SC）和命名实体识别（NER）。我们为SCNM开发了一个句子到标签生成（SLG）框架，并构建了一个包含SC和NER的维基百科数据集。通过格式转换器统一输入格式，使用生成模型生成SC标签、NER标签和相关文本段落。我们提出了一种新的神经网络模型，应用于日语句子分类和命名实体识别的任务，该模型利用了相互增强效应。

    Information extraction(IE) is a crucial subfield within natural language processing. However, for the traditionally segmented approach to sentence classification and Named Entity Recognition, the intricate interactions between these individual subtasks remain largely uninvestigated. In this study, we propose an integrative analysis, converging sentence classification with Named Entity Recognition, with the objective to unveil and comprehend the mutual reinforcement effect within these two information extraction subtasks. To achieve this, we introduce a Sentence Classification and Named Entity Recognition Multi-task (SCNM) approach that combines Sentence Classification (SC) and Named Entity Recognition (NER). We develop a Sentence-to-Label Generation (SLG) framework for SCNM and construct a Wikipedia dataset containing both SC and NER. Using a format converter, we unify input formats and employ a generative model to generate SC-labels, NER-labels, and associated text segments. We propos
    
[^39]: 使用提示条件微调实现零样本领域敏感语音识别

    Zero-shot Domain-sensitive Speech Recognition with Prompt-conditioning Fine-tuning. (arXiv:2307.10274v1 [eess.AS])

    [http://arxiv.org/abs/2307.10274](http://arxiv.org/abs/2307.10274)

    本研究提出了一种零样本领域敏感语音识别方法，利用文本提示来生成领域敏感模型，通过微调预训练的端到端模型实现。实验结果表明，该方法在不同领域和提示上下文下均取得了良好的性能，词错误率降低达到最高33%。通过仅使用文本进行微调，该模型在医学对话数据集上的识别效果最佳，词错误率降低达到29%。

    

    本研究提出了一种方法来创建利用文本领域信息的领域敏感语音识别模型，通过将其生成条件化在给定的文本提示上实现。通过对预训练的端到端模型（Whisper）进行微调，从提示示例中学习，这一目标得以实现。我们展示了这种能力可以推广到不同的领域和各种提示上下文，我们的模型在来自不同领域的未见数据集上获得了多达33％的词错误率（WER）降低，例如医学对话，空中交通控制通信和金融会议等。考虑到音频-文本对数据的有限可用性，我们进一步将我们的方法扩展到仅文本微调，以实现领域敏感性和领域适应性。我们证明了我们的仅文本微调模型也可以关注各种提示上下文，该模型在医学对话数据集上的WER降低最多达到29％。

    In this work, we propose a method to create domain-sensitive speech recognition models that utilize textual domain information by conditioning its generation on a given text prompt. This is accomplished by fine-tuning a pre-trained, end-to-end model (Whisper) to learn from demonstrations with prompt examples. We show that this ability can be generalized to different domains and even various prompt contexts, with our model gaining a Word Error Rate (WER) reduction of up to 33% on unseen datasets from various domains, such as medical conversation, air traffic control communication, and financial meetings. Considering the limited availability of audio-transcript pair data, we further extend our method to text-only fine-tuning to achieve domain sensitivity as well as domain adaptation. We demonstrate that our text-only fine-tuned model can also attend to various prompt contexts, with the model reaching the most WER reduction of 29% on the medical conversation dataset.
    
[^40]: 从叙事文本中自动获取行动模型

    Automated Action Model Acquisition from Narrative Texts. (arXiv:2307.10247v1 [cs.CL])

    [http://arxiv.org/abs/2307.10247](http://arxiv.org/abs/2307.10247)

    NaRuto是一个系统，可以从叙事文本中自动提取结构化事件，并生成高质量的行动模型，优于现有的完全自动化方法和与半自动化方法相媲美。

    

    行动模型以前提/效果公理的形式存在，为人工智能代理提供行动之间的因果关联和动机连接。行动模型获取被认为是计划技术应用中的瓶颈，特别是在叙事计划中。从叙事文本中以自动化的方式获取行动模型是必要的，但由于这样的文本本质上复杂，因此具有挑战性。我们提出了NaRuto，一个系统，它可以从叙事文本中提取结构化事件，并基于常识事件关系的预测以及文本上的矛盾和相似性无监督地生成计划语言风格的行动模型。经典的叙事计划领域的实验结果显示，NaRuto可以生成质量显著优于现有完全自动化方法的行动模型，甚至与半自动化方法的行动模型相媲美。

    Action models, which take the form of precondition/effect axioms, facilitate causal and motivational connections between actions for AI agents. Action model acquisition has been identified as a bottleneck in the application of planning technology, especially within narrative planning. Acquiring action models from narrative texts in an automated way is essential, but challenging because of the inherent complexities of such texts. We present NaRuto, a system that extracts structured events from narrative text and subsequently generates planning-language-style action models based on predictions of commonsense event relations, as well as textual contradictions and similarities, in an unsupervised manner. Experimental results in classical narrative planning domains show that NaRuto can generate action models of significantly better quality than existing fully automated methods, and even on par with those of semi-automated methods.
    
[^41]: 深度神经网络和脑对齐：脑编码和解码（综述）

    Deep Neural Networks and Brain Alignment: Brain Encoding and Decoding (Survey). (arXiv:2307.10246v1 [q-bio.NC])

    [http://arxiv.org/abs/2307.10246](http://arxiv.org/abs/2307.10246)

    本文综述了深度神经网络和脑对齐的研究，重点在于脑编码和解码模型的应用。这些模型对于理解大脑的信息处理机制以及设计脑机接口具有重要意义。

    

    大脑如何表示不同的信息模式？我们能否设计出一个可以自动理解用户思考内容的系统？这些问题可以通过研究功能磁共振成像（fMRI）等大脑记录来回答。作为第一步，神经科学界为被动阅读/听觉/观看概念词汇、叙述、图片和电影相关的认知神经科学数据集作出了贡献。过去二十年中，还提出了使用这些数据集的编码和解码模型。这些模型作为基础研究中的额外工具，在认知科学和神经科学领域有着多种实际应用。编码模型旨在自动地生成fMRI大脑表征，给定一个刺激。它们在评估和诊断神经系统疾病以及设计大脑损伤治疗方法方面有着多种实际应用。解码模型解决了根据fMRI重构刺激的逆问题。它们对于理解大脑如何处理信息以及设计脑机接口的发展都有着重要意义。

    How does the brain represent different modes of information? Can we design a system that automatically understands what the user is thinking? Such questions can be answered by studying brain recordings like functional magnetic resonance imaging (fMRI). As a first step, the neuroscience community has contributed several large cognitive neuroscience datasets related to passive reading/listening/viewing of concept words, narratives, pictures and movies. Encoding and decoding models using these datasets have also been proposed in the past two decades. These models serve as additional tools for basic research in cognitive science and neuroscience. Encoding models aim at generating fMRI brain representations given a stimulus automatically. They have several practical applications in evaluating and diagnosing neurological conditions and thus also help design therapies for brain damage. Decoding models solve the inverse problem of reconstructing the stimuli given the fMRI. They are useful for 
    
[^42]: 三思而后行：大型语言模型不确定性测量的探索性研究

    Look Before You Leap: An Exploratory Study of Uncertainty Measurement for Large Language Models. (arXiv:2307.10236v1 [cs.SE])

    [http://arxiv.org/abs/2307.10236](http://arxiv.org/abs/2307.10236)

    本研究从不确定性的角度对大型语言模型进行了探索性研究，通过实验发现不确定性估计方法在探索和抵制大型语言模型的不良行为方面具有潜力。

    

    大型语言模型（LLMs）的最近性能突破为众多工业应用和领域提供了新的机遇。然而，LLMs的错误生成，如虚假预测、错误信息和幻觉，也引发了对LLMs可靠性的严重关注，尤其在对安全、可靠性有敏感的场景中，可能阻碍其在实际中的应用。尽管不确定性估计已经显示出其在解释一般机器学习（ML）模型的预测风险方面的潜力，但关于它是否以及在多大程度上有助于探索LLMs的能力和抵制其不良行为方面知之甚少。为了弥合这一差距，本文从不确定性的角度开展了关于LLMs风险评估的探索性研究。具体来说，我们使用12种不确定性估计方法和4个LLMs在4个重要的自然语言处理（NLP）任务上进行实验，以调查不确定性在探索LLMs能力和对抗其不良行为方面的程度。

    The recent performance leap of Large Language Models (LLMs) opens up new opportunities across numerous industrial applications and domains. However, erroneous generations, such as false predictions, misinformation, and hallucination made by LLMs, have also raised severe concerns for the trustworthiness of LLMs', especially in safety-, security- and reliability-sensitive scenarios, potentially hindering real-world adoptions. While uncertainty estimation has shown its potential for interpreting the prediction risks made by general machine learning (ML) models, little is known about whether and to what extent it can help explore an LLM's capabilities and counteract its undesired behavior. To bridge the gap, in this paper, we initiate an exploratory study on the risk assessment of LLMs from the lens of uncertainty. In particular, we experiment with twelve uncertainty estimation methods and four LLMs on four prominent natural language processing (NLP) tasks to investigate to what extent unc
    
[^43]: SentimentGPT：利用GPT进行高级情感分析及其与当前机器学习方法的差异

    SentimentGPT: Exploiting GPT for Advanced Sentiment Analysis and its Departure from Current Machine Learning. (arXiv:2307.10234v1 [cs.CL])

    [http://arxiv.org/abs/2307.10234](http://arxiv.org/abs/2307.10234)

    本研究通过利用GPT进行高级情感分析，并考察其与当前机器学习方法的差异，发现GPT方法相较于其他模型在预测性能上具有显著优势，并有效解决了情感分析任务中的一些挑战，如理解上下文和检测讽刺。

    

    本研究对情感分析中各种生成预训练转换器（GPT）方法进行了全面的考察，特别是在SemEval 2017数据集的任务4中。采用了三种主要策略：1）使用GPT-3.5 Turbo进行提示工程，2）对GPT模型进行微调，3）采用创新的嵌入分类方法。研究结果揭示了这些策略和个别GPT模型之间的详细比较见解，展示了它们独特的优势和潜在的局限性。此外，本研究将这些基于GPT的方法与其他同时代、高性能的模型在相同数据集上进行比较。结果表明，GPT方法在预测性能方面具有显著的优势，相较于最先进技术，F1分数增加了22%以上。此外，本论文还探讨了情感分析任务中的常见挑战，如理解上下文和检测讽刺。研究强调了GPT方法的重要价值和潜力。

    This study presents a thorough examination of various Generative Pretrained Transformer (GPT) methodologies in sentiment analysis, specifically in the context of Task 4 on the SemEval 2017 dataset. Three primary strategies are employed: 1) prompt engineering using the advanced GPT-3.5 Turbo, 2) fine-tuning GPT models, and 3) an inventive approach to embedding classification. The research yields detailed comparative insights among these strategies and individual GPT models, revealing their unique strengths and potential limitations. Additionally, the study compares these GPT-based methodologies with other contemporary, high-performing models previously used with the same dataset. The results illustrate the significant superiority of the GPT approaches in terms of predictive performance, more than 22% in F1-score compared to the state-of-the-art. Further, the paper addresses common challenges in sentiment analysis tasks, such as understanding context and detecting sarcasm. It underscores
    
[^44]: 在对话中减少偏见：一个带提示的仇恨言论分类器和去偏见器

    Mitigating Bias in Conversations: A Hate Speech Classifier and Debiaser with Prompts. (arXiv:2307.10213v1 [cs.CL])

    [http://arxiv.org/abs/2307.10213](http://arxiv.org/abs/2307.10213)

    该论文提出了一个双步骤的方法来减少在线对话中的偏见和仇恨言论。该方法通过先使用分类器检测仇恨言论，然后利用提示生成更少偏见或无偏见的替代语言，从而降低了负面影响，为减少在线讨论中的偏见，促进更具包容性和公平性的沟通环境做出了贡献。

    

    歧视性语言和偏见通常在对话中存在，这通常对基于种族、性别和宗教的目标群体产生负面影响。为了解决这个问题，我们提出了一个双步骤的方法：首先，使用分类器检测仇恨言论，然后利用一个去偏见组件通过提示生成更少偏见或无偏见的替代语言。我们在一个基准数据集上评估了我们的方法，并观察到仇恨言论导致的负面性减少。该方法对于减少在线讨论中的偏见，促进更具包容性和公平性的沟通环境的努力有所贡献。

    Discriminatory language and biases are often present in hate speech during conversations, which usually lead to negative impacts on targeted groups such as those based on race, gender, and religion. To tackle this issue, we propose an approach that involves a two-step process: first, detecting hate speech using a classifier, and then utilizing a debiasing component that generates less biased or unbiased alternatives through prompts. We evaluated our approach on a benchmark dataset and observed reduction in negativity due to hate speech comments. The proposed method contributes to the ongoing efforts to reduce biases in online discourse and promote a more inclusive and fair environment for communication.
    
[^45]: 使用词汇转换和标签注入进行无监督领域适应的推特数据翻译

    Unsupervised Domain Adaptation using Lexical Transformations and Label Injection for Twitter Data. (arXiv:2307.10210v1 [cs.CL])

    [http://arxiv.org/abs/2307.10210](http://arxiv.org/abs/2307.10210)

    本论文提出了一种从数据集角度解决领域适应问题的方法。通过简单的词汇转换，减少了不同数据集之间的领域差异。在推特数据集上进行实验，取得了较好的无监督词性标注准确率。同时，通过合成推特文本并增加数据集，还实现了词性标注的最新性能。

    

    领域适应是自然语言处理中重要且广泛研究的问题。大量文献尝试通过将源领域训练的模型适应到目标领域来解决这个问题。本文从数据集的角度解决了这个问题。我们通过简单的词汇转换修改源领域数据集，以减少源数据集分布和目标数据集分布之间的领域差异。我们发现在转换后的源领域数据集上训练的模型比零样本模型表现更好。通过将标准英语转换为推特文本，我们实现了92.14%的无监督词性标注准确率（相比于81.54%的零样本准确率），仅略低于94.45%的有监督性能。我们还使用提出的转换方法合成推特文本并增加推特数据集，以实现词性标注的最新性能。

    Domain adaptation is an important and widely studied problem in natural language processing. A large body of literature tries to solve this problem by adapting models trained on the source domain to the target domain. In this paper, we instead solve this problem from a dataset perspective. We modify the source domain dataset with simple lexical transformations to reduce the domain shift between the source dataset distribution and the target dataset distribution. We find that models trained on the transformed source domain dataset performs significantly better than zero-shot models. Using our proposed transformations to convert standard English to tweets, we reach an unsupervised part-of-speech (POS) tagging accuracy of 92.14% (from 81.54% zero shot accuracy), which is only slightly below the supervised performance of 94.45%. We also use our proposed transformations to synthetically generate tweets and augment the Twitter dataset to achieve state-of-the-art performance for POS tagging.
    
[^46]: 从模型偏见中分离社会不平等：离婚法庭诉讼中的性别不平等

    Disentangling Societal Inequality from Model Biases: Gender Inequality in Divorce Court Proceedings. (arXiv:2307.10200v1 [cs.CY])

    [http://arxiv.org/abs/2307.10200](http://arxiv.org/abs/2307.10200)

    本文通过研究离婚法庭诉讼，探索了性别不平等问题，并发现了自然语言处理方法中存在的偏见问题。需要对现有资源进行修正来量化社会不平等。

    

    离婚是法院法律解除婚姻关系的过程。由于这通常是婚姻联合的不愉快结果，每一方都可能有理由要求退出决定，这通常在法庭诉讼中有详细记录。通过一份包含17,306份法庭诉讼的大量语料库，本文通过离婚法庭诉讼的角度研究了性别不平等问题。虽然新兴的数据来源（例如公共法庭记录）在辅助社会科学研究方面具有潜力，但先进的自然语言处理（NLP）方法中存在的偏见可能会干扰或影响此类研究。因此，我们需要对现有NLP资源中的潜在差距和限制进行彻底分析。在方法论上，本文证明了现有NLP资源需要进行几个非平凡的修改，以量化社会不平等。在实质上，我们发现尽管大量的法庭案件可能暗示着变化

    Divorce is the legal dissolution of a marriage by a court. Since this is usually an unpleasant outcome of a marital union, each party may have reasons to call the decision to quit which is generally documented in detail in the court proceedings. Via a substantial corpus of 17,306 court proceedings, this paper investigates gender inequality through the lens of divorce court proceedings. While emerging data sources (e.g., public court records) on sensitive societal issues hold promise in aiding social science research, biases present in cutting-edge natural language processing (NLP) methods may interfere with or affect such studies. We thus require a thorough analysis of potential gaps and limitations present in extant NLP resources. In this paper, on the methodological side, we demonstrate that existing NLP resources required several non-trivial modifications to quantify societal inequalities. On the substantive side, we find that while a large number of court cases perhaps suggest chan
    
[^47]: ChatGPT用于数字取证调查: 好的，坏的和未知的 (arXiv:2307.10195v1 [cs.CR])

    ChatGPT for Digital Forensic Investigation: The Good, The Bad, and The Unknown. (arXiv:2307.10195v1 [cs.CR])

    [http://arxiv.org/abs/2307.10195](http://arxiv.org/abs/2307.10195)

    本文评估了ChatGPT对数字取证领域的影响和潜力，特别关注其最新预训练的大型语言模型GPT-4。通过一系列实验，发现了ChatGPT在数字取证用例中的优势和风险，并得出了一些总体结论。

    

    在科学界和社会中，ChatGPT (GPT-3.5，GPT-4) 在各种领域的破坏性应用已经成为一个广泛讨论的话题。大型语言模型（LLMs），如BERT、Bard、生成预训练变压器（GPTs）、LLaMA等，具有根据大量文本训练数据接收用户指令或提示，并生成答案和解决方案的能力。本文评估了ChatGPT对数字取证领域的影响和潜力，特别关注其最新预训练LLM——GPT-4。通过一系列实验，评估了其在多个数字取证用例中的能力，包括证据理解、证据搜索、代码生成、异常检测、事件响应和教育。文章阐述了它在这些领域中的优势和风险，并得出了一些总体结论。总的来说，本文的结论是，虽然有一些潜在的低风险应用可能性，

    The disruptive application of ChatGPT (GPT-3.5, GPT-4) to a variety of domains has become a topic of much discussion in the scientific community and society at large. Large Language Models (LLMs), e.g., BERT, Bard, Generative Pre-trained Transformers (GPTs), LLaMA, etc., have the ability to take instructions, or prompts, from users and generate answers and solutions based on very large volumes of text-based training data. This paper assesses the impact and potential impact of ChatGPT on the field of digital forensics, specifically looking at its latest pre-trained LLM, GPT-4. A series of experiments are conducted to assess its capability across several digital forensic use cases including artefact understanding, evidence searching, code generation, anomaly detection, incident response, and education. Across these topics, its strengths and risks are outlined and a number of general conclusions are drawn. Overall this paper concludes that while there are some potential low-risk applicati
    
[^48]: 主观数据的主观人群分歧：通过群体级学习揭示有意义的群体意见

    Subjective Crowd Disagreements for Subjective Data: Uncovering Meaningful CrowdOpinion with Population-level Learning. (arXiv:2307.10189v1 [cs.IR])

    [http://arxiv.org/abs/2307.10189](http://arxiv.org/abs/2307.10189)

    本文介绍了一种名为CrowdOpinion的无监督学习方法，可以通过汇集标签分布中相似的项目，揭示在群体中存在的有意义的观点分歧，特别是在标注者人群中可能已经代表性不足的群体中。

    

    人类标注数据在AI系统的公平性中起着至关重要的作用，包括处理改变人们生活的决策或管理人类创建的网络/社交媒体内容的系统。传统上，在进行任何学习之前，会解决标注者之间的分歧。然而，研究人员越来越多地认识到标注者之间的分歧是普遍存在且有意义的。他们还质疑系统在标注者分歧时的性能。尤其是在忽视少数观点时，尤其是在标注者人群中可能已经代表性不足的群体中。在本文中，我们介绍了一种基于无监督学习的方法\emph{CrowdOpinion}，它使用语言特征和标签分布将相似的项目汇集成较大的标签分布样本。我们尝试了四种生成方法和一种基于密度的聚类方法，应用于五个标签分布和特征的线性组合。我们使用五个p

    Human-annotated data plays a critical role in the fairness of AI systems, including those that deal with life-altering decisions or moderating human-created web/social media content. Conventionally, annotator disagreements are resolved before any learning takes place. However, researchers are increasingly identifying annotator disagreement as pervasive and meaningful. They also question the performance of a system when annotators disagree. Particularly when minority views are disregarded, especially among groups that may already be underrepresented in the annotator population. In this paper, we introduce \emph{CrowdOpinion}\footnote{Accepted for publication at ACL 2023}, an unsupervised learning based approach that uses language features and label distributions to pool similar items into larger samples of label distributions. We experiment with four generative and one density-based clustering method, applied to five linear combinations of label distributions and features. We use five p
    
[^49]: 大型语言模型（LLMs）的几个类别：简短调查

    Several categories of Large Language Models (LLMs): A Short Survey. (arXiv:2307.10188v1 [cs.CL])

    [http://arxiv.org/abs/2307.10188](http://arxiv.org/abs/2307.10188)

    本文是对大型语言模型（LLMs）的几个类别进行的简短调查，提供了各类LLM的最新发展和努力的概述，包括多语言LLMs、视觉语言LLMs和代码语言模型等。同时，还突出了在聊天机器人和虚拟助手领域存在的问题，如提升自然语言处理能力和解决道德和法律困境。

    

    大型语言模型（LLMs）已成为自然语言处理的有效工具，并在许多不同领域中得到应用。本文对各种LLM子类进行了简洁的总结。该调查强调了各种LLM类型的最新发展和努力，包括基于任务的金融LLM，多语言LLM，生物医学和临床LLM，视觉语言LLM和代码语言模型。该调查对每个LLM类别中应用的方法、属性、数据集、变压器模型和比较指标进行了概述。此外，它还突出了在开发聊天机器人和虚拟助手领域存在的未解决问题，如提升自然语言处理能力，增强聊天机器人智能性以及解决道德和法律困境。本研究旨在为对基于LLM的聊天机器人和虚拟智能助手技术感兴趣的读者、开发人员、学术界人士和用户提供有用的信息和未来的方向。

    Large Language Models(LLMs)have become effective tools for natural language processing and have been used in many different fields. This essay offers a succinct summary of various LLM subcategories. The survey emphasizes recent developments and efforts made for various LLM kinds, including task-based financial LLMs, multilingual language LLMs, biomedical and clinical LLMs, vision language LLMs, and code language models. The survey gives a general summary of the methods, attributes, datasets, transformer models, and comparison metrics applied in each category of LLMs. Furthermore, it highlights unresolved problems in the field of developing chatbots and virtual assistants, such as boosting natural language processing, enhancing chatbot intelligence, and resolving moral and legal dilemmas. The purpose of this study is to provide readers, developers, academics, and users interested in LLM-based chatbots and virtual intelligent assistant technologies with useful information and future dire
    
[^50]: DialogStudio：面向会话 AI 的最丰富和最多样化的统一数据集集合

    DialogStudio: Towards Richest and Most Diverse Unified Dataset Collection for Conversational AI. (arXiv:2307.10172v1 [cs.CL])

    [http://arxiv.org/abs/2307.10172](http://arxiv.org/abs/2307.10172)

    DialogStudio是迄今为止最大且最多样化的对话数据集合，包含从开放领域对话到任务导向对话、自然语言理解、会话推荐、对话摘要和知识驱动对话的数据。它为对话研究和模型训练提供了丰富而多样化的资源。

    

    尽管会话 AI 取得了进展，但语言模型在处理多样化的对话任务时面临挑战，现有的对话数据集往往缺乏多样性和全面性。为解决这些问题，我们介绍了 DialogStudio：最大、最多样化的对话数据集集合，以一致的格式统一，同时保留其原始信息。我们的集合包括来自开放领域对话、任务导向对话、自然语言理解、会话推荐、对话摘要和知识驱动对话的数据，为对话研究和模型训练提供了非常丰富和多样化的资源。为了进一步增强 DialogStudio 的实用性，我们为每个数据集确定了许可证，并为选定对话设计了领域感知提示，以便促进指导感知微调。此外，我们使用数据集集合开发了会话 AI 模型，并在零摘要生成和分布式文字基准对话任务上进行了实验。

    Despite advancements in conversational AI, language models encounter challenges to handle diverse conversational tasks, and existing dialogue dataset collections often lack diversity and comprehensiveness. To tackle these issues, we introduce DialogStudio: the largest and most diverse collection of dialogue datasets, unified under a consistent format while preserving their original information. Our collection encompasses data from open-domain dialogues, task-oriented dialogues, natural language understanding, conversational recommendation, dialogue summarization, and knowledge-grounded dialogues, making it an incredibly rich and diverse resource for dialogue research and model training. To further enhance the utility of DialogStudio, we identify the licenses for each dataset and design domain-aware prompts for selected dialogues to facilitate instruction-aware fine-tuning. Furthermore, we develop conversational AI models using the dataset collection, and our experiments in both zero-sh
    
[^51]: LLM作为人-计算算法中的工作者？用LLM复制众包流水线。

    LLMs as Workers in Human-Computational Algorithms? Replicating Crowdsourcing Pipelines with LLMs. (arXiv:2307.10168v1 [cs.CL])

    [http://arxiv.org/abs/2307.10168](http://arxiv.org/abs/2307.10168)

    本文研究探索了LLMs是否可以复制更复杂的众包流水线，并发现现代LLMs在模拟人类计算算法中的能力上有一定的成功，但受多种因素影响。文章强调了为LLMs提供人类面向的安全保障的重要性，并讨论了训练人类和LLMs互补技能的潜力。

    

    LLM已经显示出在众包任务中复制人类行为的潜力，而这些任务以前被认为只有人类才能完成。然而，目前的研究主要集中在简单的原子任务上。我们探索LLM是否可以复制更复杂的众包流水线。我们发现现代LLM可以模拟某些众包工作者在这些“人类计算算法”中的能力，但成功的程度是可变的，并受到请求者对LLM能力的理解、子任务所需的特定技能以及执行这些子任务的最佳交互方式的影响。我们反思了人类和LLM对指示的不同敏感性，强调为LLM提供面向人类的安全保障的重要性，并讨论了训练具有互补技能的人类和LLM的潜力。关键是，我们展示了复制众包流水线提供了一个有价值的平台来研究LLM在不同任务上的相对优势（通过交叉验证

    LLMs have shown promise in replicating human-like behavior in crowdsourcing tasks that were previously thought to be exclusive to human abilities. However, current efforts focus mainly on simple atomic tasks. We explore whether LLMs can replicate more complex crowdsourcing pipelines. We find that modern LLMs can simulate some of crowdworkers' abilities in these "human computation algorithms," but the level of success is variable and influenced by requesters' understanding of LLM capabilities, the specific skills required for sub-tasks, and the optimal interaction modality for performing these sub-tasks. We reflect on human and LLMs' different sensitivities to instructions, stress the importance of enabling human-facing safeguards for LLMs, and discuss the potential of training humans and LLMs with complementary skill sets. Crucially, we show that replicating crowdsourcing pipelines offers a valuable platform to investigate (1) the relative strengths of LLMs on different tasks (by cross
    
[^52]: 高效的LLM引导生成

    Efficient Guided Generation for LLMs. (arXiv:2307.09702v1 [cs.CL])

    [http://arxiv.org/abs/2307.09702](http://arxiv.org/abs/2307.09702)

    本文描述了一种使用正则表达式和上下文无关文法来引导语言模型文本生成的高效方法。

    

    在本文中，我们描述了一种使用正则表达式和上下文无关文法来引导语言模型文本生成的高效方法。我们的方法在标记序列生成过程中几乎不增加任何开销，并使得引导生成在实际中可行。在开源Python库Outlines中提供了一个实现。

    In this article we describe an efficient approach to guiding language model text generation with regular expressions and context-free grammars. Our approach adds little to no overhead to the token sequence generation process, and makes guided generation feasible in practice. An implementation is provided in the open source Python library Outlines.
    
[^53]: ChatGPT很好，但对于越南学生来说，Bing Chat更好

    ChatGPT is Good but Bing Chat is Better for Vietnamese Students. (arXiv:2307.08272v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.08272](http://arxiv.org/abs/2307.08272)

    本研究比较了ChatGPT和Bing Chat在满足越南学生需求方面的效果，发现Bing Chat在除文学外的多个学科表现优于ChatGPT。Bing Chat采用更先进的GPT-4技术，能够提高文本的理解、推理和生成创造性、信息丰富的内容。

    

    本研究探讨了两个最先进的大型语言模型（LLMs），即ChatGPT和微软Bing Chat（BingChat），在满足越南学生需求方面的功效。尽管ChatGPT在多个学科中展现了高水准的能力，但Bing Chat被认为是更有优势的选择。我们对它们在数学、文学、英语、物理、化学、生物、历史、地理和公民教育等各个学科的学业成就进行了比较分析。研究结果表明，BingChat在多个学科上显示出比ChatGPT更优异的性能，唯独在文学方面，ChatGPT的表现更好一些。此外，与基于GPT-3.5构建的ChatGPT相比，BingChat采用了更先进的GPT-4技术，这使其能够提高文本的理解、推理和生成创造性、信息丰富的文本。此外，BingChat在越南地区可获得。

    This study examines the efficacy of two SOTA large language models (LLMs), namely ChatGPT and Microsoft Bing Chat (BingChat), in catering to the needs of Vietnamese students. Although ChatGPT exhibits proficiency in multiple disciplines, Bing Chat emerges as the more advantageous option. We conduct a comparative analysis of their academic achievements in various disciplines, encompassing mathematics, literature, English language, physics, chemistry, biology, history, geography, and civic education. The results of our study suggest that BingChat demonstrates superior performance compared to ChatGPT across a wide range of subjects, with the exception of literature, where ChatGPT exhibits better performance. Additionally, BingChat utilizes the more advanced GPT-4 technology in contrast to ChatGPT, which is built upon GPT-3.5. This allows BingChat to improve to comprehension, reasoning and generation of creative and informative text. Moreover, the fact that BingChat is accessible in Vietna
    
[^54]: 联合令牌级别和跨度级别的监督用于少样本序列标注

    Unifying Token and Span Level Supervisions for Few-Shot Sequence Labeling. (arXiv:2307.07946v1 [cs.CL])

    [http://arxiv.org/abs/2307.07946](http://arxiv.org/abs/2307.07946)

    本文提出了一种统一令牌级别和跨度级别监督的CDAP网络用于少样本序列标注，通过在不同粒度上进行联合训练和一致损失，实现了两个网络的协同学习，在推理阶段使用了一致贪婪推理算法来选择非重叠跨度。

    

    少样本序列标注旨在仅依据少量标注样本来识别新的类别。现有的方法主要通过设计基于度量学习的令牌级别或跨度级别标注模型来解决数据稀缺问题。然而，这些方法只在单一粒度上训练（即令牌级别或跨度级别），并且具有相应粒度的一些弱点。在本文中，我们首次统一了令牌级别和跨度级别的监督，并提出了一种一致双自适应原型网络（CDAP）用于少样本序列标注。CDAP包含令牌级别和跨度级别的网络，在不同粒度上进行联合训练。为了使两个网络的输出保持一致，我们进一步提出了一种一致损失，使它们可以互相学习。在推理阶段，我们提出了一种一致贪婪推理算法，首先调整预测概率，然后贪婪地选择具有最大概率的非重叠跨度。大量实验证明

    Few-shot sequence labeling aims to identify novel classes based on only a few labeled samples. Existing methods solve the data scarcity problem mainly by designing token-level or span-level labeling models based on metric learning. However, these methods are only trained at a single granularity (i.e., either token level or span level) and have some weaknesses of the corresponding granularity. In this paper, we first unify token and span level supervisions and propose a Consistent Dual Adaptive Prototypical (CDAP) network for few-shot sequence labeling. CDAP contains the token-level and span-level networks, jointly trained at different granularities. To align the outputs of two networks, we further propose a consistent loss to enable them to learn from each other. During the inference phase, we propose a consistent greedy inference algorithm that first adjusts the predicted probability and then greedily selects non-overlapping spans with maximum probability. Extensive experiments show t
    
[^55]: 大型语言模型在VNHSGE英文数据集上的性能比较：OpenAI ChatGPT、Microsoft Bing Chat和Google Bard

    Performance Comparison of Large Language Models on VNHSGE English Dataset: OpenAI ChatGPT, Microsoft Bing Chat, and Google Bard. (arXiv:2307.02288v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.02288](http://arxiv.org/abs/2307.02288)

    本文对OpenAI ChatGPT、Microsoft Bing Chat和Google Bard这三种大型语言模型在VNHSGE英文数据集上的性能进行了比较，结果显示Bing Chat优于ChatGPT和Bard。研究结果还表明，这些语言模型在英语语言教育中具有潜力，可以作为高中英语教学和学习的有效工具。

    

    本文介绍了三种大型语言模型（LLMs），分别是OpenAI ChatGPT、Microsoft Bing Chat和Google Bard，在VNHSGE英文数据集上的性能比较。结果表明，Bing Chat优于ChatGPT和Bard。因此，在ChatGPT尚未在越南正式发布之前，Bing Chat和Bard可以替代它。研究结果还表明，ChatGPT、Bing Chat和Bard在英语语言能力方面超过了越南学生。本研究的发现有助于理解LLMs在英语语言教育中的潜力。ChatGPT、Bing Chat和Bard的出色表现证明了它们作为高中英语教学和学习的有效工具的潜力。

    This paper presents a performance comparison of three large language models (LLMs), namely OpenAI ChatGPT, Microsoft Bing Chat, and Google Bard, on the VNHSGE English dataset. The results show that BingChat is better than ChatGPT and Bard. Therefore, BingChat and Bard can replace ChatGPT while ChatGPT is not yet officially available in Vietnam. The results also indicate that ChatGPT, Bing Chat, and Bard outperform Vietnamese students in English language proficiency. The findings of this study contribute to the understanding of the potential of LLMs in English language education. The remarkable performance of ChatGPT, Bing Chat, and Bard demonstrates their potential as effective tools for teaching and learning English at the high school level.
    
[^56]: PatternGPT: 一种基于模式的大型语言模型文本生成框架

    PatternGPT :A Pattern-Driven Framework for Large Language Model Text Generation. (arXiv:2307.00470v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.00470](http://arxiv.org/abs/2307.00470)

    PatternGPT是一种基于模式驱动的大型语言模型文本生成框架，通过利用大型语言模型的提取能力生成多样化的模式，并使用联邦学习的思想实现模式共享，最终通过搜索高质量模式指导生成模型。该框架具有生成多样化模式、保护数据隐私、结合外部知识等优势。

    

    大型语言模型(LLMs)展示了出色的文本生成能力，能够为许多下游任务生成流畅的响应。然而，将大型语言模型应用于现实世界的关键任务仍然具有挑战性，因为它们容易出现幻觉，并且无法直接使用外部知识。为解决上述问题，本文提出了PatternGPT，一种基于模式驱动的大型语言模型文本生成框架。首先，该框架利用大型语言模型的提取能力生成丰富多样的模式，然后借鉴联邦学习的思想，使用多个代理实现共享以获取更多样的模式。最后，它使用判断标准和优化算法搜索高质量的模式，并使用搜索到的模式指导模型进行生成。该框架具有生成多样化模式、保护数据隐私、结合外部知识等优势。

    Large language models(LLMS) have shown excellent text generation capabilities,capable of generating fluent responses for many downstream tasks. However,applying large language models to real-world critical tasks remains challenging due to their susceptibility to hallucinations and inability to directly use external knowledge. To address the above challenges,this paper proposes PatternGPT, a pattern-driven text generation framework for large language models. First,the framework utilizes the extraction capabilities of large language models to generate rich and diverse patterns and later draws on the idea of federated learning. Using multiple agents to achieve sharing to obtain more diverse patterns. Finally, it searches for high-quality patterns using judgment criteria and optimization algorithms and uses the searched patterns to guide the model for generation. This framework has the advantages of generating diversified patterns, protecting data privacy,combining external knowledge, and 
    
[^57]: 提升电子商务搜索中的文本匹配能力：基于可理解、可干预和快速实体关联模型

    Improving Text Matching in E-Commerce Search with A Rationalizable, Intervenable and Fast Entity-Based Relevance Model. (arXiv:2307.00370v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2307.00370](http://arxiv.org/abs/2307.00370)

    本研究提出了一种称为基于实体的关联模型（EBRM）的新模型，将查询-商品关联问题分解为多个查询-实体关联问题，并使用软逻辑聚合结果，以提高准确性和推理速度。

    

    在电子商务搜索系统中，从大量商品中发现用户查询的目标商品是主要目标之一。关联预测对于搜索系统至关重要，因为它有助于提高性能。目前，广泛使用的模型如Bi-encoder和Cross-encoder分别在准确性或推理速度上存在局限性。在这项工作中，我们提出了一种新的模型，称为基于实体的关联模型（EBRM）。我们识别商品中包含的实体，并将QI（查询-商品）关联问题分解为多个QE（查询-实体）关联问题；然后使用软逻辑形式聚合其结果以形成QI的预测。分解允许我们使用Cross-encoder QE关联模块以获得高准确性，并为快速在线推理缓存QE预测。利用软逻辑使预测过程可解释性高并具有干预能力。

    Discovering the intended items of user queries from a massive repository of items is one of the main goals of an e-commerce search system. Relevance prediction is essential to the search system since it helps improve performance. When online serving a relevance model, the model is required to perform fast and accurate inference. Currently, the widely used models such as Bi-encoder and Cross-encoder have their limitations in accuracy or inference speed respectively. In this work, we propose a novel model called the Entity-Based Relevance Model (EBRM). We identify the entities contained in an item and decompose the QI (query-item) relevance problem into multiple QE (query-entity) relevance problems; we then aggregate their results to form the QI prediction using a soft logic formulation. The decomposition allows us to use a Cross-encoder QE relevance module for high accuracy as well as cache QE predictions for fast online inference. Utilizing soft logic makes the prediction procedure int
    
[^58]: ChatGPT用于机器人技术：设计原则和模型能力

    ChatGPT for Robotics: Design Principles and Model Abilities. (arXiv:2306.17582v1 [cs.AI])

    [http://arxiv.org/abs/2306.17582](http://arxiv.org/abs/2306.17582)

    本文介绍了使用ChatGPT进行机器人应用的实验研究，通过设计原则和函数库的结合，ChatGPT能够适应不同的机器人任务，并展示了在各种机器人任务中的有效性和多样性。

    

    本文介绍了使用OpenAI的ChatGPT进行机器人应用的实验研究。我们概述了一种策略，将提示工程的设计原则与高级函数库的创建相结合，使ChatGPT能够适应不同的机器人任务、模拟器和形态。我们重点评估了不同的提示工程技术和对话策略对执行各种类型机器人任务的效果。我们探讨了ChatGPT使用自由形式对话、解析XML标记和合成代码的能力，以及使用任务特定提示函数和通过对话进行闭环推理的能力。我们的研究涵盖了机器人领域的一系列任务，从基本的逻辑、几何和数学推理到复杂的领域，如空中导航、操纵和具身代理。我们证明了ChatGPT在解决这些任务方面可以取得有效结果，同时使我们能够进行探索。

    This paper presents an experimental study regarding the use of OpenAI's ChatGPT for robotics applications. We outline a strategy that combines design principles for prompt engineering and the creation of a high-level function library which allows ChatGPT to adapt to different robotics tasks, simulators, and form factors. We focus our evaluations on the effectiveness of different prompt engineering techniques and dialog strategies towards the execution of various types of robotics tasks. We explore ChatGPT's ability to use free-form dialog, parse XML tags, and to synthesize code, in addition to the use of task-specific prompting functions and closed-loop reasoning through dialogues. Our study encompasses a range of tasks within the robotics domain, from basic logical, geometrical, and mathematical reasoning all the way to complex domains such as aerial navigation, manipulation, and embodied agents. We show that ChatGPT can be effective at solving several of such tasks, while allowing us
    
[^59]: MotionGPT: 人体运动作为一门外语

    MotionGPT: Human Motion as a Foreign Language. (arXiv:2306.14795v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.14795](http://arxiv.org/abs/2306.14795)

    本研究提出了MotionGPT，一种用于处理多个与动作相关任务的统一、多功能且易于使用的动作语言模型。通过将语言数据与大规模动作模型融合，实现了动作语言预训练，提升了动作相关任务的性能。

    

    尽管预训练的大型语言模型的进展不断展现，但构建一个用于语言和其他多模态数据（如动作）的统一模型仍然具有挑战性且尚未触及。幸运的是，人体运动显示出一种语义耦合，类似于人类语言，常被视为一种肢体语言形式。通过将语言数据与大规模动作模型融合，可以实现增强与动作相关任务性能的动作语言预训练。基于这一洞察力，我们提出了MotionGPT，一种统一、多功能且易于使用的动作语言模型，用于处理多个与动作相关的任务。具体而言，我们使用离散向量量化来处理人体运动，并将三维动作转换为动作令牌，类似于词令牌的生成过程。基于这个"动作词汇"，我们以统一的方式对动作和文本进行语言建模，将人体运动视为一种特定的语言。此外，受提示的启发。

    Though the advancement of pre-trained large language models unfolds, the exploration of building a unified model for language and other multi-modal data, such as motion, remains challenging and untouched so far. Fortunately, human motion displays a semantic coupling akin to human language, often perceived as a form of body language. By fusing language data with large-scale motion models, motion-language pre-training that can enhance the performance of motion-related tasks becomes feasible. Driven by this insight, we propose MotionGPT, a unified, versatile, and user-friendly motion-language model to handle multiple motion-relevant tasks. Specifically, we employ the discrete vector quantization for human motion and transfer 3D motion into motion tokens, similar to the generation process of word tokens. Building upon this "motion vocabulary", we perform language modeling on both motion and text in a unified manner, treating human motion as a specific language. Moreover, inspired by prompt
    
[^60]: $\alpha$-$\beta$-分解及Simon同余的二元情况

    $\alpha$-$\beta$-Factorization and the Binary Case of Simon's Congruence. (arXiv:2306.14192v2 [math.CO] UPDATED)

    [http://arxiv.org/abs/2306.14192](http://arxiv.org/abs/2306.14192)

    本研究通过介绍$\alpha$-$\beta$-分解的概念，将Simon同余特征化为$1$-普遍性单词，并应用于二元单词的完全刻画和同余指数计算。

    

    在1991年，H\'ebrard引入了一种单词的分解方法，被证明是研究单词的离散因子（也称为（离散）子串或子序列）的强大工具。基于此，Karandikar和Schnoebelen首先引入了$k$-丰富性的概念，随后Barker等人引入了$k$-普遍性的概念。在2022年，Fleischmann等人通过交集化单词的拱形分解和其逆序来推广了拱形分解。尽管作者仅仅使用这种分解方法来研究最短的缺失离散因子，但在本研究中我们将对这种新的$\alpha$-$\beta$-分解进行研究。我们在$k$-普遍性单词的$\alpha$-$\beta$-分解中将著名的Simon同余特征化为$1$-普遍性单词。此外，我们将这些结果应用于二元单词。在这种特殊情况下，我们得到了类别的完全刻画并计算了同余的指数。最后，我们开始研究三元情况，展示了...

    In 1991 H\'ebrard introduced a factorization of words that turned out to be a powerful tool for the investigation of a word's scattered factors (also known as (scattered) subwords or subsequences). Based on this, first Karandikar and Schnoebelen introduced the notion of $k$-richness and later on Barker et al. the notion of $k$-universality. In 2022 Fleischmann et al. presented a generalization of the arch factorization by intersecting the arch factorization of a word and its reverse. While the authors merely used this factorization for the investigation of shortest absent scattered factors, in this work we investigate this new $\alpha$-$\beta$-factorization as such. We characterize the famous Simon congruence of $k$-universal words in terms of $1$-universal words. Moreover, we apply these results to binary words. In this special case, we obtain a full characterization of the classes and calculate the index of the congruence. Lastly, we start investigating the ternary case, present a fu
    
[^61]: My Boli：混合马拉地语-英语的语料库、预训练语言模型和评估基准

    My Boli: Code-mixed Marathi-English Corpora, Pretrained Language Models and Evaluation Benchmarks. (arXiv:2306.14030v1 [cs.CL])

    [http://arxiv.org/abs/2306.14030](http://arxiv.org/abs/2306.14030)

    本研究针对资源匮乏的印度语言马拉地语，提出了一个大型混合马拉地语-英语语料库，以及预训练的混合BERT模型和针对混合语言下游任务的评估数据集，该语料库训练的模型显著优于现有的BERT模型。

    

    由于缺乏专门的混合语料库和预训练语言模型，混合语言数据的研究受到了限制。在这项工作中，我们关注资源匮乏的印度语言马拉地语，这个语言之前没有任何混合语言的研究。我们提出了L3Cube-MeCorpus，一个包含500万条推特的大型混合马拉地语-英语(Mr-En)语料库，用于预训练。我们还发布了L3Cube-MeBERT和MeRoBERTa，基于BERT的混合模型，在MeCorpus上预训练。此外，为了基准测试，我们提供了三个有监督的数据集MeHate、MeSent和MeLID，用于混合Mr-En仇恨言论检测、情感分析和语言识别等下游任务。这些评估数据集分别包含手动注释的\url{~}12,000条马拉地语-英语混合推特。削减实验表明，这个新语料库训练的模型显著优于现有的BERT模型。这是第一个提供混合马拉地语的代码的工作。

    The research on code-mixed data is limited due to the unavailability of dedicated code-mixed datasets and pre-trained language models. In this work, we focus on the low-resource Indian language Marathi which lacks any prior work in code-mixing. We present L3Cube-MeCorpus, a large code-mixed Marathi-English (Mr-En) corpus with 5 million tweets for pretraining. We also release L3Cube-MeBERT and MeRoBERTa, code-mixed BERT-based transformer models pre-trained on MeCorpus. Furthermore, for benchmarking, we present three supervised datasets MeHate, MeSent, and MeLID for downstream tasks like code-mixed Mr-En hate speech detection, sentiment analysis, and language identification respectively. These evaluation datasets individually consist of manually annotated \url{~}12,000 Marathi-English code-mixed tweets. Ablations show that the models trained on this novel corpus significantly outperform the existing state-of-the-art BERT models. This is the first work that presents artifacts for code-mix
    
[^62]: 基于标签生成的增量分类学习方法

    Class-Incremental Learning based on Label Generation. (arXiv:2306.12619v1 [cs.CL])

    [http://arxiv.org/abs/2306.12619](http://arxiv.org/abs/2306.12619)

    本文提出了一种基于标签生成方法的增量分类学习（CIL）方法（VAG），大幅减少了灾难性遗忘（CF），并更好地保留了预训练模型的可推广表示。

    

    尽管预训练语言模型取得了巨大成功，但对于类别增量学习（CIL）设置，由于灾难性遗忘（CF），使用这些模型进行连续学习仍然是一个挑战。本文发现，如果将CIL定式为一个连续的标签生成问题，则可以大幅减少CF并更好地保留预训练模型的可推广表示。因此，我们提出了一种新的CIL方法（VAG），该方法还利用了词汇表的稀疏性以便于生成，并使用标签语义创建伪重播样本。实验结果表明，VAG的性能比基线大幅优越。

    Despite the great success of pre-trained language models, it is still a challenge to use these models for continual learning, especially for the class-incremental learning (CIL) setting due to catastrophic forgetting (CF). This paper reports our finding that if we formulate CIL as a continual label generation problem, CF is drastically reduced and the generalizable representations of pre-trained models can be better retained. We thus propose a new CIL method (VAG) that also leverages the sparsity of vocabulary to focus the generation and creates pseudo-replay samples by using label semantics. Experimental results show that VAG outperforms baselines by a large margin.
    
[^63]: ChatGPT化学助手用于文本挖掘和MOF合成预测

    ChatGPT Chemistry Assistant for Text Mining and Prediction of MOF Synthesis. (arXiv:2306.11296v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2306.11296](http://arxiv.org/abs/2306.11296)

    该论文使用提示工程的方法指导ChatGPT对科学文献进行自动化文本挖掘，以获得金属-有机框架（MOF）合成条件。通过该系统，可以高精确地提取大量合成参数，为MOF合成提供支持。

    

    我们使用提示工程来指导ChatGPT自动化地从科学文献中挖掘多样的金属-有机框架（MOF）合成条件。这有效地减少了ChatGPT在科学领域中使用大型语言模型（LLMs）时出现信息产生误差的问题。我们的方法包括通过ChatGPT本身编程来开发实施文本挖掘的三个不同过程。所有这些过程都可以解析、搜索、过滤、分类、摘要和数据统一，但在劳动力、速度和准确性之间有不同的权衡。我们部署了该系统，从同行评审的研究文章中提取了26257个不同的合成参数，涉及大约800个MOF。这个过程包含了我们的ChemPrompt工程策略，以指导ChatGPT进行文本挖掘，结果显示出了90-99%的令人印象深刻的精确度、召回率和F1得分。

    We use prompt engineering to guide ChatGPT in the automation of text mining of metal-organic frameworks (MOFs) synthesis conditions from diverse formats and styles of the scientific literature. This effectively mitigates ChatGPT's tendency to hallucinate information -- an issue that previously made the use of Large Language Models (LLMs) in scientific fields challenging. Our approach involves the development of a workflow implementing three different processes for text mining, programmed by ChatGPT itself. All of them enable parsing, searching, filtering, classification, summarization, and data unification with different tradeoffs between labor, speed, and accuracy. We deploy this system to extract 26,257 distinct synthesis parameters pertaining to approximately 800 MOFs sourced from peer-reviewed research articles. This process incorporates our ChemPrompt Engineering strategy to instruct ChatGPT in text mining, resulting in impressive precision, recall, and F1 scores of 90-99%. Furthe
    
[^64]: 使用知识链推动提升语言模型的推理能力

    Boosting Language Models Reasoning with Chain-of-Knowledge Prompting. (arXiv:2306.06427v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.06427](http://arxiv.org/abs/2306.06427)

    该论文提出了一种新的知识链提示（CoK）方法，旨在引导语言模型生成明确的知识证据，以提升推理能力，并通过F^2-Verification方法评估推理的准确性和可信度。

    

    最近，链式思维（CoT）提示在复杂的推理任务上取得了成功，其目标是设计一个简单的提示，如“我们一步一步地思考”或多个上下文示例，以及设计良好的理由，以引导大型语言模型（LLM）生成中间推理步骤。然而，生成的理由往往带有错误，导致不准确和不可信的推理链。为了减少这种脆弱性，我们提出了一种新颖的知识链提示（CoK），旨在引导LLM生成显性的知识证据，以结构化三元组的形式呈现。这一灵感来自于人类行为，即在回答复杂问题之前，我们可以在脑海中绘制思维导图或知识图作为推理证据。通过使用CoK，我们额外引入了一种F^2-Verification方法来估计推理链的可靠性，包括准确性和可信度。对于不可靠的回答，错误的证据可以

    Recently, Chain-of-Thought (CoT) prompting has delivered success on complex reasoning tasks, which aims at designing a simple prompt like ``Let's think step by step'' or multiple in-context exemplars with well-designed rationales to elicit Large Language Models (LLMs) to generate intermediate reasoning steps. However, the generated rationales often come with mistakes, making unfactual and unfaithful reasoning chains. To mitigate this brittleness, we propose a novel Chain-of-Knowledge (CoK) prompting, where we aim at eliciting LLMs to generate explicit pieces of knowledge evidence in the form of structure triple. This is inspired by our human behaviors, i.e., we can draw a mind map or knowledge map as the reasoning evidence in the brain before answering a complex question. Benefiting from CoK, we additionally introduce a F^2-Verification method to estimate the reliability of the reasoning chains in terms of factuality and faithfulness. For the unreliable response, the wrong evidence can
    
[^65]: 在ChatGPT、大型语言模型和生成AI时代的科学：研究伦理的挑战及应对方法

    Science in the Era of ChatGPT, Large Language Models and Generative AI: Challenges for Research Ethics and How to Respond. (arXiv:2305.15299v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2305.15299](http://arxiv.org/abs/2305.15299)

    这篇论文回顾了生成AI对科学研究所带来的认识论挑战、伦理和诚信风险，并提出了十项建议，以在AI时代促进更负责任的研究进行。

    

    人工智能的大型语言模型（如ChatGPT）在科学研究中具有显著但有争议的应用。本文回顾了生成AI时代科学研究的认识论挑战、伦理和诚信风险，并旨在为高质量的研究伦理审查奠定新的及时基础。对AI语言模型作为研究工具和研究对象的角色进行了详细审查，并讨论了对科学家、参与者和评审人员的伦理影响。讨论了研究伦理审查的新兴实践，并给出了十项建议，为在AI时代更负责任的研究进行回应。

    Large language models of artificial intelligence (AI), such as ChatGPT, find remarkable but controversial applicability in science and research. This paper reviews epistemological challenges, ethical and integrity risks in science conduct in the advent of generative AI. This is with the aim to lay new timely foundations for a high-quality research ethics review. The role of AI language models as a research instrument and subject is scrutinized along with ethical implications for scientists, participants and reviewers. New emerging practices for research ethics review are discussed, concluding with ten recommendations that shape a response for a more responsible research conduct in the era of AI.
    
[^66]: AlignAtt：使用基于注意力的音频翻译对齐作为同时语音翻译的指导

    AlignAtt: Using Attention-based Audio-Translation Alignments as a Guide for Simultaneous Speech Translation. (arXiv:2305.11408v1 [cs.CL])

    [http://arxiv.org/abs/2305.11408](http://arxiv.org/abs/2305.11408)

    AlignAtt是一种新型的SimulST策略，使用基于注意力的音频翻译对齐来指导模型，在BLEU和延迟方面均优于之前的策略。

    

    注意力是当今自然语言处理中最常用的架构的核心机制，并已从许多角度进行分析，包括其在机器翻译相关任务中的有效性。在这些研究中，注意力在输入文本被替换为音频片段的情况下，也是获取有关单词对齐的有用信息的一种方式，例如语音翻译（ST）任务。在本文中，我们提出了AlignAtt，一种新颖的同时ST（SimulST）策略，它利用注意力信息来生成源-目标对齐，以在推理过程中指导模型。通过对MuST-C v1.0的8种语言对的实验，我们发现，在线下训练的模型上应用先前的最新SimulST策略，AlignAtt在BLEU方面获得了2个分数的提高，并且8种语言的延迟缩减在0.5秒到0.8秒之间。

    Attention is the core mechanism of today's most used architectures for natural language processing and has been analyzed from many perspectives, including its effectiveness for machine translation-related tasks. Among these studies, attention resulted to be a useful source of information to get insights about word alignment also when the input text is substituted with audio segments, as in the case of the speech translation (ST) task. In this paper, we propose AlignAtt, a novel policy for simultaneous ST (SimulST) that exploits the attention information to generate source-target alignments that guide the model during inference. Through experiments on the 8 language pairs of MuST-C v1.0, we show that AlignAtt outperforms previous state-of-the-art SimulST policies applied to offline-trained models with gains in terms of BLEU of 2 points and latency reductions ranging from 0.5s to 0.8s across the 8 languages.
    
[^67]: RadAdapt：通过大型语言模型的轻量化领域自适应实现放射学报告摘要

    RadAdapt: Radiology Report Summarization via Lightweight Domain Adaptation of Large Language Models. (arXiv:2305.01146v1 [cs.CL])

    [http://arxiv.org/abs/2305.01146](http://arxiv.org/abs/2305.01146)

    本研究重点研究了轻量化策略，通过在临床文本上进行预训练和在RRS示例上进行参数高效微调，实现适应大型语言模型进行放射性报告摘要（RRS）任务。并且该方法仅微调模型的0.32％的参数，提高了表现。研究结果强调了领域适应在RRS中的重要性，并为开发更好的放射性报告摘要模型提供了有价值的见解。

    

    本文系统地研究了轻量级策略，通过预训练（自然语言，生物医学文本，临床文本）和提示（零-shot、上下文学习）或参数高效微调（前缀微调，LoRA），来适应大型语言模型（LLMs）进行放射性报告摘要（RRS）任务。结果表明，最大程度地适应任务的方法是，通过在临床文本上预先训练，然后在RRS示例上进行参数高效微调。值得注意的是，这种方法仅微调模型的0.32％的参数，与端对端微调（100％的参数）形成对比。此外，在研究上下文示例和分布外（OOD）训练的影响后，我们进行了放射科医师读者研究和定性分析。我们的研究结果强调了领域适应在RRS中的重要性，并为开发更好的放射性报告摘要模型提供了有价值的见解。

    We systematically investigate lightweight strategies to adapt large language models (LLMs) for the task of radiology report summarization (RRS). Specifically, we focus on domain adaptation via pretraining (on natural language, biomedical text, and clinical text) and via prompting (zero-shot, in-context learning) or parameter-efficient fine-tuning (prefix tuning, LoRA). Our results on the MIMIC-III dataset consistently demonstrate best performance by maximally adapting to the task via pretraining on clinical text and parameter-efficient fine-tuning on RRS examples. Importantly, this method fine-tunes a mere 0.32% of parameters throughout the model, in contrast to end-to-end fine-tuning (100% of parameters). Additionally, we study the effect of in-context examples and out-of-distribution (OOD) training before concluding with a radiologist reader study and qualitative analysis. Our findings highlight the importance of domain adaptation in RRS and provide valuable insights toward developin
    
[^68]: AI的公平性及其对社会的长期影响

    Fairness in AI and Its Long-Term Implications on Society. (arXiv:2304.09826v1 [cs.CY])

    [http://arxiv.org/abs/2304.09826](http://arxiv.org/abs/2304.09826)

    本文探讨了AI的公平性问题，指出缺乏AI公平性会加深偏见成为社会压力因素，可能对社会产生长期影响，因此需要寻求潜在解决方案。

    

    人工智能（AI）在各种设置中的成功部署已经为个人和社会带来了许多积极的成果。然而，由于预测的偏见，AI系统也被证明对部分人口造成了伤害。我们着眼于AI的公平性，分析了缺乏AI公平性时如何导致偏见随着时间的加深而成为社会压力因素。如果问题持续存在，可能会对社会产生不良的长期影响，并通过与其他风险的交互来加强。我们检查了提高AI公平性的当前策略，并评估它们在实际部署方面的限制，并探讨了确保我们在不损害社会重要部分的情况下获得AI的好处的潜在路径。

    Successful deployment of artificial intelligence (AI) in various settings has led to numerous positive outcomes for individuals and society. However, AI systems have also been shown to harm parts of the population due to biased predictions. We take a closer look at AI fairness and analyse how lack of AI fairness can lead to deepening of biases over time and act as a social stressor. If the issues persist, it could have undesirable long-term implications on society, reinforced by interactions with other risks. We examine current strategies for improving AI fairness, assess their limitations in terms of real-world deployment, and explore potential paths forward to ensure we reap AI's benefits without harming significant parts of the society.
    
[^69]: Sabiá: 葡萄牙的大型语言模型

    Sabi\'a: Portuguese Large Language Models. (arXiv:2304.07880v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.07880](http://arxiv.org/abs/2304.07880)

    针对葡萄牙语进行单语言预训练，可以显著提高大规模合成语言模型的质量，并能够在一系列葡萄牙语数据集上优于以英语为中心和多语言的对手，最好的模型的表现与GPT-3.5-turbo持平。

    

    随着语言模型能力的不断提高，”一刀切“的模型仍然是主流。尤其是考虑到全球使用的语言数量非常庞大，并且其中很多语言都是低资源语言，主要的做法是对多种语言进行预训练。本文对这种做法提出了质疑，证明了针对目标语言进行单语言预训练可以显著提高大规模合成语言模型的质量。我们在本文中进一步介绍了用3%或更少的原始预训练预算在葡萄牙语文本上进一步预训练GPT-J和LLaMA模型。我们在Poeta（一套由14个葡萄牙语数据集组成的套件）上进行了少样本评估，结果显示我们的模型在表现上远优于以英语为中心的和多语言的对手。我们的最佳模型Sabiá-65B的表现与GPT-3.5-turbo持平。我们在目标语言中已经设想了数据集，以及经过翻译的数据集上都进行了评估。

    As the capabilities of language models continue to advance, it is conceivable that "one-size-fits-all" model will remain as the main paradigm. For instance, given the vast number of languages worldwide, many of which are low-resource, the prevalent practice is to pretrain a single model on multiple languages. In this paper, we add to the growing body of evidence that challenges this practice, demonstrating that monolingual pretraining on the target language significantly improves models already extensively trained on diverse corpora. More specifically, we further pretrain GPT-J and LLaMA models on Portuguese texts using 3% or less of their original pretraining budget. Few-shot evaluations on Poeta, a suite of 14 Portuguese datasets, reveal that our models outperform English-centric and multilingual counterparts by a significant margin. Our best model, Sabi\'a-65B, performs on par with GPT-3.5-turbo. By evaluating on datasets originally conceived in the target language as well as transl
    
[^70]: 基于正样本增强对比学习的图像视频标题评估

    Positive-Augmented Constrastive Learning for Image and Video Captioning Evaluation. (arXiv:2303.12112v1 [cs.CV])

    [http://arxiv.org/abs/2303.12112](http://arxiv.org/abs/2303.12112)

    本论文提出一种新的图像标题评估指标PAC-S，可以更准确地评估图像和视频的标题，相比于现有的指标有更好的表现；源代码和训练模型已经公开。

    

    最近CLIP模型在很多跨模态任务上都非常有效，包括从视觉和语言结构中生成的标题评估。本文提出了一种新的基于对比度的图像标题评估指标配方，即正样本增强的对比度学习分数（PAC-S），以一种新颖的方式统一了对比度视觉-语义空间的学习和策展数据上生成的图像和文本的添加。跨越多个数据集的实验表明，我们的新指标在图像和视频上与人类判断的相关性最高，优于现有参考指标（如CIDEr和SPICE）和无参考指标（如CLIP-Score）。最后，我们考虑了流行的图像标题方法，并评估了采用不同跨模态特征的影响。我们的源代码和训练模型是公开的。

    The CLIP model has been recently proven to be very effective for a variety of cross-modal tasks, including the evaluation of captions generated from vision-and-language architectures. In this paper, we propose a new recipe for a contrastive-based evaluation metric for image captioning, namely Positive-Augmented Contrastive learning Score (PAC-S), that in a novel way unifies the learning of a contrastive visual-semantic space with the addition of generated images and text on curated data. Experiments spanning several datasets demonstrate that our new metric achieves the highest correlation with human judgments on both images and videos, outperforming existing reference-based metrics like CIDEr and SPICE and reference-free metrics like CLIP-Score. Finally, we test the system-level correlation of the proposed metric when considering popular image captioning approaches, and assess the impact of employing different cross-modal features. Our source code and trained models are publicly availa
    
[^71]: ChatGPT的数学能力研究

    Mathematical Capabilities of ChatGPT. (arXiv:2301.13867v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.13867](http://arxiv.org/abs/2301.13867)

    本研究调查了ChatGPT和GPT-4的数学能力，并通过使用新的方法以及发布两个新数据集，评估了它们在各个维度的数学推理上的表现。这是第一个涵盖研究生级数学并由数学研究人员策划的自然语言数据集，也测试了它们作为专业数学家助手的潜力。

    

    本文通过使用一种新颖的方法，对ChatGPT（发布于2023年1月9日和1月30日）和GPT-4的数学能力进行了调查和测试，使用了公开可用的数据集以及手工制作的数据集。与正式数学不同，正式证明的大型数据库可供使用（例如，Lean数学库），当前用于基准语言模型的自然语言数学数据集要么只涵盖基础数学，要么非常小。我们通过公开发布两个新数据集：GHOSTS和miniGHOSTS来解决这个问题。这是由数学研究人员精心策划的第一个自然语言数据集，旨在涵盖研究生级数学、提供对语言模型数学能力的整体概述，并区分数学推理的多个方面。这些数据集还测试了ChatGPT和GPT-4是否可以成为专业数学家的有用助手，模拟其行为。

    We investigate the mathematical capabilities of two iterations of ChatGPT (released 9-January-2023 and 30-January-2023) and of GPT-4 by testing them on publicly available datasets, as well as hand-crafted ones, using a novel methodology. In contrast to formal mathematics, where large databases of formal proofs are available (e.g., the Lean Mathematical Library), current datasets of natural-language mathematics, used to benchmark language models, either cover only elementary mathematics or are very small. We address this by publicly releasing two new datasets: GHOSTS and miniGHOSTS. These are the first natural-language datasets curated by working researchers in mathematics that (1) aim to cover graduate-level mathematics, (2) provide a holistic overview of the mathematical capabilities of language models, and (3) distinguish multiple dimensions of mathematical reasoning. These datasets also test whether ChatGPT and GPT-4 can be helpful assistants to professional mathematicians by emulat
    
[^72]: 使用深度强化学习的基于执行的代码生成

    Execution-based Code Generation using Deep Reinforcement Learning. (arXiv:2301.13816v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.13816](http://arxiv.org/abs/2301.13816)

    使用深度强化学习的PPOCoder框架将预训练的编程语言模型和Proximal Policy Optimization技术结合，通过利用代码执行和结构对齐的非可微反馈，实现了更高效的代码生成。

    

    利用在大规模代码语料库上预训练的编程语言（PL）模型，作为自动化软件工程过程的手段，在代码完成、代码翻译和程序合成等各种代码生成任务中表现出了相当的潜力。然而，当前的方法主要依赖于从文本生成中借用的监督微调目标，忽视了代码的独特序列级特征，包括但不限于可编译性以及语法和功能正确性。为了解决这个限制，我们提出了PPOCoder，一种新的代码生成框架，它将预训练的PL模型与Proximal Policy Optimization（PPO）相结合，PPO是一种广泛使用的深度强化学习技术。通过利用代码执行和结构对齐的非可微反馈，PPOCoder将外部代码特定知识无缝集成到模型优化过程中。这是重要的。

    The utilization of programming language (PL) models, pre-trained on large-scale code corpora, as a means of automating software engineering processes has demonstrated considerable potential in streamlining various code generation tasks such as code completion, code translation, and program synthesis. However, current approaches mainly rely on supervised fine-tuning objectives borrowed from text generation, neglecting unique sequence-level characteristics of code, including but not limited to compilability as well as syntactic and functional correctness. To address this limitation, we propose PPOCoder, a new framework for code generation that synergistically combines pre-trained PL models with Proximal Policy Optimization (PPO) which is a widely used deep reinforcement learning technique. By utilizing non-differentiable feedback from code execution and structure alignment, PPOCoder seamlessly integrates external code-specific knowledge into the model optimization process. It's important
    
[^73]: ThoughtSource:一个用于大型语言模型推理数据的中央枢纽。

    ThoughtSource: A central hub for large language model reasoning data. (arXiv:2301.11596v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.11596](http://arxiv.org/abs/2301.11596)

    ThoughtSource是一个用于连续思考推理的元数据集和软件库，旨在通过促进对连续思考的定性理解、实证评估和提供训练数据，改进未来的人工智能系统。

    

    最近，像GPT-4这样的大型语言模型在多个任务上展示了令人印象深刻的结果。然而，这些语言模型在复杂推理上仍存在限制，它们的推理过程不透明，容易产生“幻觉”事实，并且存在其潜在偏见的担忧。最近提出了一种称为连续思考提示的技术，让模型以自然语言形式表达推理步骤，以解决这些问题。在这里，我们介绍了ThoughtSource，一个用于连续思考推理的元数据集和软件库。ThoughtSource的目标是通过促进对连续思考的定性理解、实证评估和提供训练数据来改进未来的人工智能系统。ThoughtSource的首次发布集成了六个科学/医学、三个通用领域和五个数学题答案数据集。

    Large language models (LLMs) such as GPT-4 have recently demonstrated impressive results across a wide range of tasks. LLMs are still limited, however, in that they frequently fail at complex reasoning, their reasoning processes are opaque, they are prone to 'hallucinate' facts, and there are concerns about their underlying biases. Letting models verbalize reasoning steps as natural language, a technique known as chain-of-thought prompting, has recently been proposed as a way to address some of these issues. Here we present ThoughtSource, a meta-dataset and software library for chain-of-thought (CoT) reasoning. The goal of ThoughtSource is to improve future artificial intelligence systems by facilitating qualitative understanding of CoTs, enabling empirical evaluations, and providing training data. This first release of ThoughtSource integrates six scientific/medical, three general-domain and five math word question answering datasets.
    
[^74]: 一种无文本的语音比较度量方法

    A Textless Metric for Speech-to-Speech Comparison. (arXiv:2210.11835v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.11835](http://arxiv.org/abs/2210.11835)

    本文介绍了一种无文本的语音比较度量方法，利用语音到单元编码器转换语音表述为声学单元，并提出了与文本基准密切对应的基于语音的度量。该方法可以用于口述语言和没有可靠ASR系统的语音翻译评估，避免使用ASR转录的需求。

    

    本文介绍了一种新的简单方法，用于比较语音表述而无需依赖文本转录。我们的语音对语音比较度量利用了最先进的语音到单元编码器（如HuBERT）将语音表述转换为离散的声学单元。然后，我们提出了一种简单易复制的神经架构，学习一种与文本基准度量密切对应的基于语音的度量。这种无文本度量具有许多潜在应用，包括评估口头语言、没有可靠ASR系统的语言的语音翻译，或者完全避免使用ASR转录的需求。本文还表明，在语音翻译评估中，ASR-BLEU（通过自动转录语音假设和参考语音，并计算转录之间的句子级BLEU）即使ASR系统强大，也是真实文本BLEU的一个较差代理。

    In this paper, we introduce a new and simple method for comparing speech utterances without relying on text transcripts. Our speech-to-speech comparison metric utilizes state-of-the-art speech2unit encoders like HuBERT to convert speech utterances into discrete acoustic units. We then propose a simple and easily replicable neural architecture that learns a speech-based metric that closely corresponds to its text-based counterpart. This textless metric has numerous potential applications, including evaluating speech-to-speech translation for oral languages, languages without dependable ASR systems, or to avoid the need for ASR transcription altogether. This paper also shows that for speech-to-speech translation evaluation, ASR-BLEU (which consists in automatically transcribing both speech hypothesis and reference and compute sentence-level BLEU between transcripts) is a poor proxy to real text-BLEU even when ASR system is strong.
    
[^75]: MAP：多模态不确定性感知的视觉语言预训练模型

    MAP: Multimodal Uncertainty-Aware Vision-Language Pre-training Model. (arXiv:2210.05335v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.05335](http://arxiv.org/abs/2210.05335)

    本文提出了一种利用概率分布编码器进行多模态不确定性建模的预训练模型MAP，该模型在多项下游任务中均表现优异，超越了现有模型。

    

    多模态语义理解经常需要处理不确定性，导致所获得的信息倾向于涉及多个目标。这种不确定性对我们的解释来说是有问题的，包括跨模态和内部模态的不确定性。鲜有研究探讨该不确定性的建模，特别是在未标记的数据集上预训练和在特定任务下游数据集中进行微调。在本文中，我们利用序列级交互通过概率分布编码器（PDE）将所有模态的表示投影为概率分布。与现有的确定性方法相比，这种不确定性建模可以传递更丰富的多模态语义信息和更复杂的关系。此外，我们将不确定性建模与流行的预训练框架结合起来，并提出适合的预训练任务:基于分布的视觉语言对比（D-VLC）、基于分布的掩蔽语言建模（D-MLM）和分布式图像检索（D-IR）。我们评估了我们提出的模型——多模态不确定性感知的视觉语言预训练模型（MAP）在各种下游任务中的表现，包括视觉问答、图像字幕和指称表达理解。实验结果表明，MAP比其确定性对应物表现更好，并在几个基准测试中达到了最先进的性能。

    Multimodal semantic understanding often has to deal with uncertainty, which means the obtained messages tend to refer to multiple targets. Such uncertainty is problematic for our interpretation, including inter- and intra-modal uncertainty. Little effort has studied the modeling of this uncertainty, particularly in pre-training on unlabeled datasets and fine-tuning in task-specific downstream datasets. In this paper, we project the representations of all modalities as probabilistic distributions via a Probability Distribution Encoder (PDE) by utilizing sequence-level interactions. Compared to the existing deterministic methods, such uncertainty modeling can convey richer multimodal semantic information and more complex relationships. Furthermore, we integrate uncertainty modeling with popular pre-training frameworks and propose suitable pre-training tasks: Distribution-based Vision-Language Contrastive learning (D-VLC), Distribution-based Masked Language Modeling (D-MLM), and Distribut
    
[^76]: ForecastTKGQuestions: 一个用于时间性问题回答和时间知识图谱预测的基准测试

    ForecastTKGQuestions: A Benchmark for Temporal Question Answering and Forecasting over Temporal Knowledge Graphs. (arXiv:2208.06501v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2208.06501](http://arxiv.org/abs/2208.06501)

    本论文提出了一个新的任务，即在时间知识图谱上进行预测性问题回答。该任务对于人们寻求未来计划非常重要，并且是先前研究中未被探索的领域。

    

    最近，对于时间性知识图谱问答（TKGQA）的兴趣逐渐增加。TKGQA需要时间推理技术来从时间知识库中提取相关信息。现有的TKGQA数据集只包含基于固定时间段的时间性问题，该时间段内的时间知识图谱（TKG）可以完全用于答案推理，允许TKGQA模型利用未来知识来回答基于过去事实的问题。然而，在现实场景中，鉴于到目前为止的知识，我们也希望TKGQA系统能够回答关于未来的问题。由于人们不断寻求未来的计划，构建能够回答这种预测性问题的TKGQA系统非常重要。然而，在先前的研究中，这一领域仍然未被探索。在本文中，我们提出了一个新的任务：预测性问题回答的时间知识图谱预测。

    Question answering over temporal knowledge graphs (TKGQA) has recently found increasing interest. TKGQA requires temporal reasoning techniques to extract the relevant information from temporal knowledge bases. The only existing TKGQA dataset, i.e., CronQuestions, consists of temporal questions based on the facts from a fixed time period, where a temporal knowledge graph (TKG) spanning the same period can be fully used for answer inference, allowing the TKGQA models to use even the future knowledge to answer the questions based on the past facts. In real-world scenarios, however, it is also common that given the knowledge until now, we wish the TKGQA systems to answer the questions asking about the future. As humans constantly seek plans for the future, building TKGQA systems for answering such forecasting questions is important. Nevertheless, this has still been unexplored in previous research. In this paper, we propose a novel task: forecasting question answering over temporal knowled
    
[^77]: ABNIRML: 分析神经信息检索模型的行为

    ABNIRML: Analyzing the Behavior of Neural IR Models. (arXiv:2011.00696v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2011.00696](http://arxiv.org/abs/2011.00696)

    ABNIRML提供了一个全面的框架，分析了神经信息检索模型的行为，包括写作风格、事实性、对改写和词序的敏感性等特征。通过进行广泛的实证研究，我们探究了神经模型增益的因素，并发现了潜在的偏见。

    

    预训练上下文化语言模型（如BERT和T5）已经建立了信息检索领域的新的最先进技术。然而，我们还不完全理解为什么这些方法如此有效，是什么使一些变种比其他变种更有效，以及它们可能存在哪些问题。我们提出了一个全面的框架来分析神经信息检索模型行为（ABNIRML），包括新的诊断探针类型，允许我们测试先前技术未解决的几个特征，例如写作风格，事实性，对改写和词序的敏感性等。为了展示这个框架的价值，我们进行了广泛的实证研究，得出了对神经模型增益因素的见解，并确定了模型可能存在的潜在偏见。我们的一些结果证实了传统的观点，例如最近的神经排序模型对查询的确切术语匹配的依赖程度较低，而是利用更丰富的语言特征。

    Pretrained contextualized language models such as BERT and T5 have established a new state-of-the-art for ad-hoc search. However, it is not yet well-understood why these methods are so effective, what makes some variants more effective than others, and what pitfalls they may have. We present a new comprehensive framework for Analyzing the Behavior of Neural IR ModeLs (ABNIRML), which includes new types of diagnostic probes that allow us to test several characteristics -- such as writing styles, factuality, sensitivity to paraphrasing and word order -- that are not addressed by previous techniques. To demonstrate the value of the framework, we conduct an extensive empirical study that yields insights into the factors that contribute to the neural model's gains, and identify potential unintended biases the models exhibit. Some of our results confirm conventional wisdom, like that recent neural ranking models rely less on exact term overlap with the query, and instead leverage richer ling
    

