# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [NeuroPrune: A Neuro-inspired Topological Sparse Training Algorithm for Large Language Models](https://arxiv.org/abs/2404.01306) | 本研究受神经系统启发，通过神经网络拓扑的稀疏方法，探索类似于生物网络的机制，展示了对各种 NLP 任务都表现出色和高效的模型-不可知稀疏性方法 |
| [^2] | [Interpreting Key Mechanisms of Factual Recall in Transformer-Based Language Models](https://arxiv.org/abs/2403.19521) | 通过深入研究Transformer-based语言模型在事实回忆任务中的机制，我们发现了零/少次样本情况下的特定任务头、MLP层和残差流的功能，以及抗过度自信机制。 |
| [^3] | [MD-PK: Metaphor Detection via Prompt Learning and Knowledge Distillation](https://arxiv.org/abs/2403.18253) | 引入知识蒸馏和提示学习的方法解决隐喻检测中的语言规则应用和数据稀疏性问题，通过提示信息和软标签优化学生模型，提高隐喻检测的准确性。 |
| [^4] | [Exploring the Deceptive Power of LLM-Generated Fake News: A Study of Real-World Detection Challenges](https://arxiv.org/abs/2403.18249) | 本研究提出了一种强假新闻攻击方法VLPrompt，通过消除对额外数据收集的需求，同时保持语境一致性和原始文本的复杂性，可以更好地缩小LLM生成虚假新闻的欺骗力差距。 |
| [^5] | [$\textit{LinkPrompt}$: Natural and Universal Adversarial Attacks on Prompt-based Language Models](https://arxiv.org/abs/2403.16432) | 基于提示的语言模型的优化过程揭示了生成对抗提示以误导模型的见解，引发了对该范式对抗性脆弱性的担忧。 |
| [^6] | [Large Language Models on Fine-grained Emotion Detection Dataset with Data Augmentation and Transfer Learning](https://arxiv.org/abs/2403.06108) | 本文研究了如何在细粒度情感检测数据集上使用大型语言模型来提高分类性能，并提出了对于文本中检测微妙情感的挑战的有价值见解。 |
| [^7] | [SemEval-2024 Task 8: Weighted Layer Averaging RoBERTa for Black-Box Machine-Generated Text Detection](https://arxiv.org/abs/2402.15873) | 本文介绍了SemEval-2024任务8的黑匣子机器生成文本检测中采用的加权层平均RoBERTa技术及结果 |
| [^8] | [Exploring the Impact of Table-to-Text Methods on Augmenting LLM-based Question Answering with Domain Hybrid Data](https://arxiv.org/abs/2402.12869) | 本文探索了如何将表格转文本方法集成到LLM问答系统中，通过实验发现不同的表格转文本方法对QA系统性能的影响。 |
| [^9] | [Counter-intuitive: Large Language Models Can Better Understand Knowledge Graphs Than We Thought](https://arxiv.org/abs/2402.11541) | 本文通过对KG知识注入方法进行全面比较，探索为LLMs提供知识图谱知识的最佳方法，以增强它们的理解能力。 |
| [^10] | [TeenyTinyLlama: open-source tiny language models trained in Brazilian Portuguese.](http://arxiv.org/abs/2401.16640) | 这篇论文开发了用于低资源环境中的开放式基础模型，以巴西葡萄牙语为例，发布在GitHub和Hugging Face上供社区使用和进一步开发。 |
| [^11] | [Mining experimental data from Materials Science literature with Large Language Models.](http://arxiv.org/abs/2401.11052) | 本研究评估了使用大型语言模型从材料科学文献中提取结构化信息的能力，并引入了一种新颖的方法来处理材料科学信息的复杂性。在命名实体识别和关系提取任务上，LLMs与传统模型相比表现有限，但在少数-shot提示下有一定的改进。 |
| [^12] | [Faithful and Robust Local Interpretability for Textual Predictions.](http://arxiv.org/abs/2311.01605) | 提出了一种名为FRED的新颖方法，用于解释文本预测。FRED可以识别文档中的关键词，并且通过与最先进的方法进行的实证评估证明了其在提供对文本模型的深入见解方面的有效性。 |
| [^13] | [TopRoBERTa: Topology-Aware Authorship Attribution of Deepfake Texts.](http://arxiv.org/abs/2309.12934) | 本论文提出了一种拓扑感知的深伪文本作者识别方法TopRoBERTa，通过捕捉深伪文本中的更多语言模式，改进了现有的作者识别解决方案。 |
| [^14] | [A Family of Pretrained Transformer Language Models for Russian.](http://arxiv.org/abs/2309.10931) | 本文介绍了一组专门针对俄语的预训练Transformer语言模型，包括编码器、解码器和编码器-解码器模型。这些模型在俄语自然语言理解和生成方面展现了良好的泛化能力，希望能够推动俄语领域的NLP研究和工业应用的发展。 |
| [^15] | [AV2Wav: Diffusion-Based Re-synthesis from Continuous Self-supervised Features for Audio-Visual Speech Enhancement.](http://arxiv.org/abs/2309.08030) | 本论文提出了一种名为AV2Wav的音频-视觉语音增强方法，利用连续自监督特征和扩散模型生成干净的语音，克服了现实训练数据的挑战。与基于掩蔽的基线方法相比，该方法在声码任务上表现更好，并通过多任务训练进一步优化性能。 |
| [^16] | [Advancing Regular Language Reasoning in Linear Recurrent Neural Networks.](http://arxiv.org/abs/2309.07412) | 通过分析现有的线性循环神经网络（LRNN），我们提出了一种新的LRNN模型，该模型配备了一个块对角且输入相关的转移矩阵，并且是唯一一个能够在正则语言任务上进行长度外推的LRNN。 |

# 详细

[^1]: NeuroPrune：一种受神经系统启发的用于大型语言模型的拓扑稀疏训练算法

    NeuroPrune: A Neuro-inspired Topological Sparse Training Algorithm for Large Language Models

    [https://arxiv.org/abs/2404.01306](https://arxiv.org/abs/2404.01306)

    本研究受神经系统启发，通过神经网络拓扑的稀疏方法，探索类似于生物网络的机制，展示了对各种 NLP 任务都表现出色和高效的模型-不可知稀疏性方法

    

    基于 Transformer 的语言模型由于在各种任务上的出色性能而在自然语言处理（NLP）中变得普遍。然而，昂贵的训练以及推理仍然是它们广泛适用性的一个重要障碍。在模型架构的各个层次强制引入稀疏性已被证明有助于解决扩展性和效率问题，但稀疏性对网络拓扑的影响仍存在断裂。受大脑神经网络启发，我们通过网络拓扑的视角探索稀疏性方法。具体而言，我们利用在生物网络中观察到的机制，如优先附着和冗余突触修剪，并展示了基于原则的、与模型无关的稀疏性方法在跨越分类（如自然语言推理）和生成（摘要、机器翻译）的各种 NLP 任务上表现出色且高效，尽管 o

    arXiv:2404.01306v1 Announce Type: cross  Abstract: Transformer-based Language Models have become ubiquitous in Natural Language Processing (NLP) due to their impressive performance on various tasks. However, expensive training as well as inference remains a significant impediment to their widespread applicability. While enforcing sparsity at various levels of the model architecture has found promise in addressing scaling and efficiency issues, there remains a disconnect between how sparsity affects network topology. Inspired by brain neuronal networks, we explore sparsity approaches through the lens of network topology. Specifically, we exploit mechanisms seen in biological networks, such as preferential attachment and redundant synapse pruning, and show that principled, model-agnostic sparsity approaches are performant and efficient across diverse NLP tasks, spanning both classification (such as natural language inference) and generation (summarization, machine translation), despite o
    
[^2]: 解释基于Transformer模型的语言模型在事实回忆中的关键机制

    Interpreting Key Mechanisms of Factual Recall in Transformer-Based Language Models

    [https://arxiv.org/abs/2403.19521](https://arxiv.org/abs/2403.19521)

    通过深入研究Transformer-based语言模型在事实回忆任务中的机制，我们发现了零/少次样本情况下的特定任务头、MLP层和残差流的功能，以及抗过度自信机制。

    

    本文深入探讨了Transformer-based语言模型在事实回忆任务中所采用的机制。在零次样本情况下，给定类似“法国的首都是”的提示，特定任务的注意力头会从上下文中提取主题实体，如“法国”，并将其传递给后续的MLP以回忆所需的答案，如“巴黎”。我们引入了一种新颖的分析方法，旨在将MLP的输出分解为人类可理解的组件。通过这种方法，我们量化了跟随这些特定任务头的MLP层的功能。在残差流中，它会擦除或放大来自各个头的信息。此外，它会生成一个组件，将残差流重新定向到预期答案的方向。这些零次机制也适用于少次样本情况。此外，我们观察到一种广泛存在的抗过度自信机制。

    arXiv:2403.19521v1 Announce Type: cross  Abstract: In this paper, we deeply explore the mechanisms employed by Transformer-based language models in factual recall tasks. In zero-shot scenarios, given a prompt like "The capital of France is," task-specific attention heads extract the topic entity, such as "France," from the context and pass it to subsequent MLPs to recall the required answer such as "Paris." We introduce a novel analysis method aimed at decomposing the outputs of the MLP into components understandable by humans. Through this method, we quantify the function of the MLP layer following these task-specific heads. In the residual stream, it either erases or amplifies the information originating from individual heads. Moreover, it generates a component that redirects the residual stream towards the direction of its expected answer. These zero-shot mechanisms are also employed in few-shot scenarios. Additionally, we observed a widely existent anti-overconfidence mechanism in 
    
[^3]: 通过提示学习和知识蒸馏的隐喻检测

    MD-PK: Metaphor Detection via Prompt Learning and Knowledge Distillation

    [https://arxiv.org/abs/2403.18253](https://arxiv.org/abs/2403.18253)

    引入知识蒸馏和提示学习的方法解决隐喻检测中的语言规则应用和数据稀疏性问题，通过提示信息和软标签优化学生模型，提高隐喻检测的准确性。

    

    隐喻在日常生活中随处可见，但是检测它们却是一个重大挑战。先前的方法经常因语言规则应用不当而难以应对，并忽视了数据稀疏性的问题。为了解决这些挑战，我们将知识蒸馏和提示学习引入隐喻检测中。具体来说，我们设计了一个专为隐喻检测任务量身定制的提示学习模板。通过屏蔽目标词并提供相关提示信息，我们引导模型准确推断这些词的上下文含义。这种方法不仅减轻了目标词字面含义的干扰，还确保了对于隐喻检测的MIP语言规则的正确利用。此外，我们利用一种配备先前知识的教师模型生成有意义的软标签，引导学生模型的优化过程。软标签的引入类似于标签平滑，有助于改善模型的泛化能力。

    arXiv:2403.18253v1 Announce Type: new  Abstract: Metaphors are ubiquitous in daily life, yet detecting them poses a significant challenge. Previous approaches often struggled with improper application of language rules and overlooked the issue of data sparsity. To address these challenges, we introduce knowledge distillation and prompt learning into metaphor detection. Specifically, we devise a prompt learning template tailored for the metaphor detection task. By masking target words and providing relevant prompt information, we guide the model to accurately infer the contextual meaning of these words. This approach not only mitigates the interference from the literal meaning of target words but also ensures the proper utilization of MIP language rules for metaphor detection. Moreover, we employ a teacher model equipped with prior knowledge to generate meaningful soft labels, guiding the optimization process of the student model. The inclusion of soft labels, akin to label smoothing, h
    
[^4]: 探索LLM生成的虚假新闻的欺骗力：对现实世界检测挑战的研究

    Exploring the Deceptive Power of LLM-Generated Fake News: A Study of Real-World Detection Challenges

    [https://arxiv.org/abs/2403.18249](https://arxiv.org/abs/2403.18249)

    本研究提出了一种强假新闻攻击方法VLPrompt，通过消除对额外数据收集的需求，同时保持语境一致性和原始文本的复杂性，可以更好地缩小LLM生成虚假新闻的欺骗力差距。

    

    最近，大型语言模型（LLMs）的进展使得在复杂领域如医疗保健领域尤为可能创造虚假新闻成为可能。研究突显了LLM生成的虚假新闻在有无人类辅助的情况下的欺骗力差距，但对于激励技术的潜力尚未完全探索。因此，本研究旨在确定激励策略是否能有效地缩小这一差距。当前基于LLM的虚假新闻攻击需要人类干预进行信息收集，通常会忽略细节并且无法保持上下文一致性。因此，为了更好地理解威胁策略，我们提出了一种称为条件变分自动编码器式提示（VLPrompt）的强假新闻攻击方法。与当前方法不同，VLPrompt消除了对额外数据收集的需求，同时保持了语境的连贯性并保留了原始文本的复杂性。

    arXiv:2403.18249v1 Announce Type: new  Abstract: Recent advancements in Large Language Models (LLMs) have enabled the creation of fake news, particularly in complex fields like healthcare. Studies highlight the gap in the deceptive power of LLM-generated fake news with and without human assistance, yet the potential of prompting techniques has not been fully explored. Thus, this work aims to determine whether prompting strategies can effectively narrow this gap. Current LLM-based fake news attacks require human intervention for information gathering and often miss details and fail to maintain context consistency. Therefore, to better understand threat tactics, we propose a strong fake news attack method called conditional Variational-autoencoder-Like Prompt (VLPrompt). Unlike current methods, VLPrompt eliminates the need for additional data collection while maintaining contextual coherence and preserving the intricacies of the original text. To propel future research on detecting VLPro
    
[^5]: $\textit{LinkPrompt}$: 基于提示的语言模型的自然和通用对抗攻击

    $\textit{LinkPrompt}$: Natural and Universal Adversarial Attacks on Prompt-based Language Models

    [https://arxiv.org/abs/2403.16432](https://arxiv.org/abs/2403.16432)

    基于提示的语言模型的优化过程揭示了生成对抗提示以误导模型的见解，引发了对该范式对抗性脆弱性的担忧。

    

    Prompt-based learning 是一种新的语言模型训练范式，它将预训练语言模型（PLMs）调整到下游任务，从而在各种自然语言处理（NLP）任务中提升了性能基准。一些研究表明，通过优化搜索提示的有效性，而不是使用固定的提示模板来微调模型。这种基于提示优化过程对PLMs的学习也揭示了生成对抗提示以误导模型的见解，引发了对这一范式对抗性脆弱性的担忧。最近的研究表明，可以生成通用对抗触发器（UATs）来改变不仅目标PLMs的预测，还有对应Prompt-based Fine-tuning Models（PFMs）的预测。然而，以前作品中发现的UATs通常是无法阅读的令牌或字符。

    arXiv:2403.16432v1 Announce Type: cross  Abstract: Prompt-based learning is a new language model training paradigm that adapts the Pre-trained Language Models (PLMs) to downstream tasks, which revitalizes the performance benchmarks across various natural language processing (NLP) tasks. Instead of using a fixed prompt template to fine-tune the model, some research demonstrates the effectiveness of searching for the prompt via optimization. Such prompt optimization process of prompt-based learning on PLMs also gives insight into generating adversarial prompts to mislead the model, raising concerns about the adversarial vulnerability of this paradigm. Recent studies have shown that universal adversarial triggers (UATs) can be generated to alter not only the predictions of the target PLMs but also the prediction of corresponding Prompt-based Fine-tuning Models (PFMs) under the prompt-based learning paradigm. However, UATs found in previous works are often unreadable tokens or characters a
    
[^6]: 在包含数据增强和迁移学习的细粒度情感检测数据集上使用大型语言模型

    Large Language Models on Fine-grained Emotion Detection Dataset with Data Augmentation and Transfer Learning

    [https://arxiv.org/abs/2403.06108](https://arxiv.org/abs/2403.06108)

    本文研究了如何在细粒度情感检测数据集上使用大型语言模型来提高分类性能，并提出了对于文本中检测微妙情感的挑战的有价值见解。

    

    本文深入研究了如何在GoEmotions数据集上提高情感检测的分类性能，这是一个大型、手动注释的文本情感检测数据集。本文的主要目标是解决在文本中检测微妙情感的挑战，这是自然语言处理中一个复杂的问题，具有重要的实际应用。研究结果为解决文本情感检测的挑战提供了宝贵的见解，并提出了未来研究的方向，包括合成该领域各个数据集上方法和性能的综述论文的潜在性。

    arXiv:2403.06108v1 Announce Type: cross  Abstract: This paper delves into enhancing the classification performance on the GoEmotions dataset, a large, manually annotated dataset for emotion detection in text. The primary goal of this paper is to address the challenges of detecting subtle emotions in text, a complex issue in Natural Language Processing (NLP) with significant practical applications. The findings offer valuable insights into addressing the challenges of emotion detection in text and suggest directions for future research, including the potential for a survey paper that synthesizes methods and performances across various datasets in this domain.
    
[^7]: SemEval-2024任务8：加权层平均RoBERTa用于黑匣子机器生成文本检测

    SemEval-2024 Task 8: Weighted Layer Averaging RoBERTa for Black-Box Machine-Generated Text Detection

    [https://arxiv.org/abs/2402.15873](https://arxiv.org/abs/2402.15873)

    本文介绍了SemEval-2024任务8的黑匣子机器生成文本检测中采用的加权层平均RoBERTa技术及结果

    

    这份文件包含了作者提交给SemEval 2024任务8会议论文的细节：多生成器、多领域和多语言黑匣子机器生成文本检测子任务A（单语）和B。随着大型语言模型（LLMs）的出现，机器生成文本的检测变得越来越重要。在这份文件中，我们阐述了用于执行相同任务的技术，以及所获得的结果。

    arXiv:2402.15873v1 Announce Type: new  Abstract: This document contains the details of the authors' submission to the proceedings of SemEval 2024's Task 8: Multigenerator, Multidomain, and Multilingual Black-Box Machine-Generated Text Detection Subtask A (monolingual) and B. Detection of machine-generated text is becoming an increasingly important task, with the advent of large language models (LLMs). In this document, we lay out the techniques utilized for performing the same, along with the results obtained.
    
[^8]: 探索表格转文本方法对增强基于LLM的问答系统在领域混合数据上的影响

    Exploring the Impact of Table-to-Text Methods on Augmenting LLM-based Question Answering with Domain Hybrid Data

    [https://arxiv.org/abs/2402.12869](https://arxiv.org/abs/2402.12869)

    本文探索了如何将表格转文本方法集成到LLM问答系统中，通过实验发现不同的表格转文本方法对QA系统性能的影响。

    

    大型语言模型（LLMs）在问答系统（QA）中使用领域特定数据进行增强已经引起了广泛关注。然而，领域数据通常以混合格式存在，包括文本和半结构化表格，对信息的无缝整合提出了挑战。表格转文本生成是一个有前途的解决方案，它通过将混合数据转化为统一文本格式的语料库。尽管这种技术已经被自然语言处理（NLP）社区广泛研究，但目前还没有比较分析不同表格转文本方法生成的语料库对QA系统性能的影响。本文分两步解决了这一研究空白。首先，我们将表格转文本生成创新地集成到增强基于LLM的QA系统与领域混合数据框架中。然后，我们利用这个框架在真实工业数据中进行了广泛实验，对两种类型的QA系统进行了测试（

    arXiv:2402.12869v1 Announce Type: new  Abstract: Augmenting Large Language Models (LLMs) for Question Answering (QA) with domain specific data has attracted wide attention. However, domain data often exists in a hybrid format, including text and semi-structured tables, posing challenges for the seamless integration of information. Table-to-Text Generation is a promising solution by facilitating the transformation of hybrid data into a uniformly text-formatted corpus. Although this technique has been widely studied by the NLP community, there is currently no comparative analysis on how corpora generated by different table-to-text methods affect the performance of QA systems. In this paper, we address this research gap in two steps. First, we innovatively integrate table-to-text generation into the framework of enhancing LLM-based QA systems with domain hybrid data. Then, we utilize this framework in real-world industrial data to conduct extensive experiments on two types of QA systems (
    
[^9]: 逆向认知：大型语言模型比我们想象的更擅长理解知识图谱

    Counter-intuitive: Large Language Models Can Better Understand Knowledge Graphs Than We Thought

    [https://arxiv.org/abs/2402.11541](https://arxiv.org/abs/2402.11541)

    本文通过对KG知识注入方法进行全面比较，探索为LLMs提供知识图谱知识的最佳方法，以增强它们的理解能力。

    

    虽然通过使用知识图谱（KGs）来增强大型语言模型（LLMs）的推理能力并减少它们的幻觉的方法受到了广泛关注，但目前对如何使LLMs能够即时整合KGs中的结构化知识的探索还不足。本文采用复杂问题回答（CQA）作为一项任务，评估LLM理解KG知识的能力。我们对KG知识注入方法进行了全面比较（从三元组到自然语言文本），旨在探索为LLMs提供KG知识的最佳提示方法，从而增强它们的理解能力。

    arXiv:2402.11541v1 Announce Type: cross  Abstract: Although the method of enhancing large language models' (LLMs') reasoning ability and reducing their hallucinations through the use of knowledge graphs (KGs) has received widespread attention, the exploration of how to enable LLMs to integrate the structured knowledge in KGs on-the-fly remains inadequate. Researchers often co-train KG embeddings and LLM parameters to equip LLMs with the ability of comprehending KG knowledge. However, this resource-hungry training paradigm significantly increases the model learning cost and is also unsuitable for non-open-source, black-box LLMs. In this paper, we employ complex question answering (CQA) as a task to assess the LLM's ability of comprehending KG knowledge. We conducted a comprehensive comparison of KG knowledge injection methods (from triples to natural language text), aiming to explore the optimal prompting method for supplying KG knowledge to LLMs, thereby enhancing their comprehension o
    
[^10]: TeenyTinyLlama：基于巴西葡萄牙语训练的开源微型语言模型

    TeenyTinyLlama: open-source tiny language models trained in Brazilian Portuguese. (arXiv:2401.16640v1 [cs.CL])

    [http://arxiv.org/abs/2401.16640](http://arxiv.org/abs/2401.16640)

    这篇论文开发了用于低资源环境中的开放式基础模型，以巴西葡萄牙语为例，发布在GitHub和Hugging Face上供社区使用和进一步开发。

    

    大型语言模型（LLMs）在自然语言处理方面取得了显著的进展，但在各种语言中的进展还不平衡。虽然大多数LLMs是在像英语这样的高资源语言中训练的，但多语言模型通常比单语言模型表现稍差。此外，它们的多语言基础有时会限制它们产生的副产品，如计算需求和许可制度。在本研究中，我们记录了为在低资源环境中使用而量身定制的开放式基础模型的开发过程、其局限性和优势。这就是TeenyTinyLlama：两个用于巴西葡萄牙语文本生成的紧凑型模型。我们在GitHub和Hugging Face上以宽松的Apache 2.0许可证发布它们，供社区使用和进一步开发。详见https://github.com/Nkluge-correa/TeenyTinyLlama

    Large language models (LLMs) have significantly advanced natural language processing, but their progress has yet to be equal across languages. While most LLMs are trained in high-resource languages like English, multilingual models generally underperform monolingual ones. Additionally, aspects of their multilingual foundation sometimes restrict the byproducts they produce, like computational demands and licensing regimes. In this study, we document the development of open-foundation models tailored for use in low-resource settings, their limitations, and their benefits. This is the TeenyTinyLlama pair: two compact models for Brazilian Portuguese text generation. We release them under the permissive Apache 2.0 license on GitHub and Hugging Face for community use and further development. See https://github.com/Nkluge-correa/TeenyTinyLlama
    
[^11]: 使用大型语言模型从材料科学文献中挖掘实验数据

    Mining experimental data from Materials Science literature with Large Language Models. (arXiv:2401.11052v1 [cs.CL])

    [http://arxiv.org/abs/2401.11052](http://arxiv.org/abs/2401.11052)

    本研究评估了使用大型语言模型从材料科学文献中提取结构化信息的能力，并引入了一种新颖的方法来处理材料科学信息的复杂性。在命名实体识别和关系提取任务上，LLMs与传统模型相比表现有限，但在少数-shot提示下有一定的改进。

    

    本研究致力于评估先进的大型语言模型（LLMs），如GPT-3.5-Turbo、GPT-4和GPT-4-Turbo，在材料科学领域科学文档中提取结构化信息的能力。我们引入了一种新颖的方法，用于比较分析复杂的材料表达式，强调化学式的标准化，以解决材料科学信息评估中固有的复杂性。为此，我们主要关注信息提取的两个关键任务：（i）研究材料和物理性质的命名实体识别（NER）和（ii）这些实体之间的关系提取（RE）。LLMs在执行这些任务时的表现与基于BERT架构和基于规则的传统模型进行了基准测试。对于NER，LLMs在零-shot提示下无法超越基准线，并且仅在少数-shot提示下有少量改进。然而，对于...

    This study is dedicated to evaluating the capabilities of advanced large language models (LLMs) such as GPT-3.5-Turbo, GPT-4, and GPT-4-Turbo in the extraction of structured information from scientific documents within the field of materials science. We introduce a novel methodology for the comparative analysis of intricate material expressions, emphasising the standardisation of chemical formulas to tackle the complexities inherent in materials science information assessment. To this end, we primarily focus on two critical tasks of information extraction: (i) a named entity recognition (NER) of studied materials and physical properties and (ii) a relation extraction (RE) between these entities. The performance of LLMs in executing these tasks is benchmarked against traditional models based on the BERT architecture and rule-based approaches. For NER, LLMs fail to outperform the baseline with zero-shot prompting and exhibit only limited improvement with few-shot prompting. However, for 
    
[^12]: 对于文本预测的忠实和稳健的本地可解释性

    Faithful and Robust Local Interpretability for Textual Predictions. (arXiv:2311.01605v1 [cs.CL])

    [http://arxiv.org/abs/2311.01605](http://arxiv.org/abs/2311.01605)

    提出了一种名为FRED的新颖方法，用于解释文本预测。FRED可以识别文档中的关键词，并且通过与最先进的方法进行的实证评估证明了其在提供对文本模型的深入见解方面的有效性。

    

    可解释性对于机器学习模型在关键领域中得到信任和部署是至关重要的。然而，现有的用于解释文本模型的方法通常复杂，并且缺乏坚实的数学基础，它们的性能也不能保证。在本文中，我们提出了一种新颖的方法FRED（Faithful and Robust Explainer for textual Documents），用于解释文本预测。FRED可以识别文档中的关键词，当这些词被移除时对预测结果产生重大影响。我们通过正式的定义和对可解释分类器的理论分析，确立了FRED的可靠性。此外，我们还通过与最先进的方法进行的实证评估，证明了FRED在提供对文本模型的深入见解方面的有效性。

    Interpretability is essential for machine learning models to be trusted and deployed in critical domains. However, existing methods for interpreting text models are often complex, lack solid mathematical foundations, and their performance is not guaranteed. In this paper, we propose FRED (Faithful and Robust Explainer for textual Documents), a novel method for interpreting predictions over text. FRED identifies key words in a document that significantly impact the prediction when removed. We establish the reliability of FRED through formal definitions and theoretical analyses on interpretable classifiers. Additionally, our empirical evaluation against state-of-the-art methods demonstrates the effectiveness of FRED in providing insights into text models.
    
[^13]: TopRoBERTa：拓扑感知的深伪文本作者识别

    TopRoBERTa: Topology-Aware Authorship Attribution of Deepfake Texts. (arXiv:2309.12934v1 [cs.CL])

    [http://arxiv.org/abs/2309.12934](http://arxiv.org/abs/2309.12934)

    本论文提出了一种拓扑感知的深伪文本作者识别方法TopRoBERTa，通过捕捉深伪文本中的更多语言模式，改进了现有的作者识别解决方案。

    

    最近大规模语言模型（LLM）的进展使得生成开放性、高质量的文本成为可能，这些文本很难与人类写作的文本区分开来，我们将这种LLM生成的文本称为“深伪文本”。目前，huggingface模型存储库中有超过11K个文本生成模型。因此，恶意用户可以轻松使用这些开源的LLM生成大规模的有害文本和虚假信息。为了缓解这个问题，我们希望有一种计算方法能够确定给定的文本是否为深伪文本，即通过图灵测试（TT）来判断。具体而言，在这项工作中，我们调查了更一般版本的问题，即在多类别设置下的“作者识别（AA）”，即不仅确定给定的文本是否为深伪文本，而且还能够确定哪个LLM是作者。我们提出了TopRoBERTa，通过包含更多深伪文本中的语言模式来改进现有的AA解决方案。

    Recent advances in Large Language Models (LLMs) have enabled the generation of open-ended high-quality texts, that are non-trivial to distinguish from human-written texts. We refer to such LLM-generated texts as \emph{deepfake texts}. There are currently over 11K text generation models in the huggingface model repo. As such, users with malicious intent can easily use these open-sourced LLMs to generate harmful texts and misinformation at scale. To mitigate this problem, a computational method to determine if a given text is a deepfake text or not is desired--i.e., Turing Test (TT). In particular, in this work, we investigate the more general version of the problem, known as \emph{Authorship Attribution (AA)}, in a multi-class setting--i.e., not only determining if a given text is a deepfake text or not but also being able to pinpoint which LLM is the author. We propose \textbf{TopRoBERTa} to improve existing AA solutions by capturing more linguistic patterns in deepfake texts by includ
    
[^14]: 一种针对俄语的预训练Transformer语言模型家族

    A Family of Pretrained Transformer Language Models for Russian. (arXiv:2309.10931v1 [cs.CL])

    [http://arxiv.org/abs/2309.10931](http://arxiv.org/abs/2309.10931)

    本文介绍了一组专门针对俄语的预训练Transformer语言模型，包括编码器、解码器和编码器-解码器模型。这些模型在俄语自然语言理解和生成方面展现了良好的泛化能力，希望能够推动俄语领域的NLP研究和工业应用的发展。

    

    如今，Transformer语言模型（LMs）是自然语言处理（NLP）研究方法和应用的基本组成部分。然而，专门针对俄语的这种模型的发展却受到了较少的关注。本文介绍了一组基于编码器（ruBERT, ruRoBERTa, ruELECTRA）、解码器（ruGPT-3）和编码器-解码器（ruT5, FRED-T5）模型的13个俄语Transformer LMs，具有多种尺寸。这些模型可通过HuggingFace平台轻松获取。我们提供了模型架构设计和预训练的报告，并评估了它们在俄语自然语言理解和生成数据集以及基准测试中的泛化能力。通过预训练和发布这些专门的Transformer LMs，我们希望拓宽NLP研究方向的范围，并促进针对俄语的工业解决方案的开发。

    Nowadays, Transformer language models (LMs) represent a fundamental component of the NLP research methodologies and applications. However, the development of such models specifically for the Russian language has received little attention. This paper presents a collection of 13 Russian Transformer LMs based on the encoder (ruBERT, ruRoBERTa, ruELECTRA), decoder (ruGPT-3), and encoder-decoder (ruT5, FRED-T5) models in multiple sizes. Access to these models is readily available via the HuggingFace platform. We provide a report of the model architecture design and pretraining, and the results of evaluating their generalization abilities on Russian natural language understanding and generation datasets and benchmarks. By pretraining and releasing these specialized Transformer LMs, we hope to broaden the scope of the NLP research directions and enable the development of industrial solutions for the Russian language.
    
[^15]: AV2Wav：基于连续自监督特征的扩散重合成技术用于音频-视觉语音增强

    AV2Wav: Diffusion-Based Re-synthesis from Continuous Self-supervised Features for Audio-Visual Speech Enhancement. (arXiv:2309.08030v1 [eess.AS])

    [http://arxiv.org/abs/2309.08030](http://arxiv.org/abs/2309.08030)

    本论文提出了一种名为AV2Wav的音频-视觉语音增强方法，利用连续自监督特征和扩散模型生成干净的语音，克服了现实训练数据的挑战。与基于掩蔽的基线方法相比，该方法在声码任务上表现更好，并通过多任务训练进一步优化性能。

    

    语音增强系统通常使用干净和噪声语音对进行训练。在音频-视觉语音增强中，干净的数据不够多；大多数音频-视觉数据集都是在现实环境中收集的，包含背景噪声和混响，这阻碍了音频-视觉语音增强的发展。在本研究中，我们引入了AV2Wav，一种基于重合成的音频-视觉语音增强方法，可以在现实训练数据的挑战下生成干净的语音。我们使用神经质量估计器从音频-视觉语料库中获取几乎干净的语音子集，并在此子集上训练一个扩散模型，该模型可以根据来自AV-HuBERT的连续语音表示生成声波形，具有噪声鲁棒训练。我们使用连续而不是离散表示来保留韵律和说话者信息。仅仅通过声码任务，该模型就比基于掩蔽的基线更好地执行语音增强。我们进一步fine-tune模型，以转化为在多任务下进行训练，通过联合多帧声学到语音转化来提高性能。

    Speech enhancement systems are typically trained using pairs of clean and noisy speech. In audio-visual speech enhancement (AVSE), there is not as much ground-truth clean data available; most audio-visual datasets are collected in real-world environments with background noise and reverberation, hampering the development of AVSE. In this work, we introduce AV2Wav, a resynthesis-based audio-visual speech enhancement approach that can generate clean speech despite the challenges of real-world training data. We obtain a subset of nearly clean speech from an audio-visual corpus using a neural quality estimator, and then train a diffusion model on this subset to generate waveforms conditioned on continuous speech representations from AV-HuBERT with noise-robust training. We use continuous rather than discrete representations to retain prosody and speaker information. With this vocoding task alone, the model can perform speech enhancement better than a masking-based baseline. We further fine-
    
[^16]: 在线性循环神经网络中推进正则语言推理

    Advancing Regular Language Reasoning in Linear Recurrent Neural Networks. (arXiv:2309.07412v1 [cs.CL])

    [http://arxiv.org/abs/2309.07412](http://arxiv.org/abs/2309.07412)

    通过分析现有的线性循环神经网络（LRNN），我们提出了一种新的LRNN模型，该模型配备了一个块对角且输入相关的转移矩阵，并且是唯一一个能够在正则语言任务上进行长度外推的LRNN。

    

    在最近的研究中，线性循环神经网络（LRNN）在自然语言建模和长程建模中取得了与Transformer相当的性能，同时提供了快速的并行训练和恒定的推理成本。在对LRNN重新产生兴趣的同时，我们研究它们是否能够学习训练序列中的隐藏规则，例如正则语言的语法结构。我们对一些已有的LRNN进行理论分析，发现它们在正则语言上存在限制。在这个分析的基础上，我们提出了一种新的LRNN，配备了一个块对角和输入相关的转移矩阵。实验表明，所提出的模型是唯一一个能够在正则语言任务（如求和、偶数对、模运算等）上进行长度外推的LRNN。

    In recent studies, linear recurrent neural networks (LRNNs) have achieved Transformer-level performance in natural language modeling and long-range modeling while offering rapid parallel training and constant inference costs. With the resurged interest in LRNNs, we study whether they can learn the hidden rules in training sequences, such as the grammatical structures of regular language. We theoretically analyze some existing LRNNs and discover their limitations on regular language. Motivated by the analysis, we propose a new LRNN equipped with a block-diagonal and input-dependent transition matrix. Experiments suggest that the proposed model is the only LRNN that can perform length extrapolation on regular language tasks such as Sum, Even Pair, and Modular Arithmetic.
    

