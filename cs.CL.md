# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [DialogStudio: Towards Richest and Most Diverse Unified Dataset Collection for Conversational AI.](http://arxiv.org/abs/2307.10172) | DialogStudio是迄今为止最大且最多样化的对话数据集合，包含从开放领域对话到任务导向对话、自然语言理解、会话推荐、对话摘要和知识驱动对话的数据。它为对话研究和模型训练提供了丰富而多样化的资源。 |
| [^2] | [Challenges and Applications of Large Language Models.](http://arxiv.org/abs/2307.10169) | 本文旨在总结大型语言模型领域的挑战和应用成功案例，帮助机器学习研究人员快速了解该领域的当前状态并提高效率。 |
| [^3] | [LLMs as Workers in Human-Computational Algorithms? Replicating Crowdsourcing Pipelines with LLMs.](http://arxiv.org/abs/2307.10168) | 本文研究探索了LLMs是否可以复制更复杂的众包流水线，并发现现代LLMs在模拟人类计算算法中的能力上有一定的成功，但受多种因素影响。文章强调了为LLMs提供人类面向的安全保障的重要性，并讨论了训练人类和LLMs互补技能的潜力。 |
| [^4] | [Exploring Transformer Extrapolation.](http://arxiv.org/abs/2307.10156) | 本文通过数学和实证分析，发现只要RPE的指数序列收敛，Transformer就具有长度外推的能力。从中导出了两种实践方法，并提出了一种新的理论感受野(TRF)来测量RPE的感受野。 |
| [^5] | [Gradient Sparsification For Masked Fine-Tuning of Transformers.](http://arxiv.org/abs/2307.10098) | 本研究提出了一种使用渐进稀疏化方法对预训练语言模型进行正则化，以改善微调性能。GradDrop及其变体通过在训练过程中随机屏蔽梯度，有效地进行梯度稀疏化。 |
| [^6] | [Android in the Wild: A Large-Scale Dataset for Android Device Control.](http://arxiv.org/abs/2307.10088) | 这个论文提出了一个名为Android in the Wild (AITW)的大规模数据集，用于研究设备控制系统，该数据集包括人类示范的设备交互、自然语言指令和多种Android版本和设备类型。这个数据集提供了一个新的挑战，需要从视觉外观中推断用户界面中可用的操作。 |
| [^7] | [An Empirical Study on Fertility Proposals Using Multi-Grined Topic Analysis Methods.](http://arxiv.org/abs/2307.10025) | 本研究通过采用多粒度主题分析方法，对微博评论进行语义分析，发现关于取消婚姻登记的生育限制的提案涉及个人、社会和国家三个维度，详细讨论了个人行为、社会伦理和法律以及国家政策等社会问题。 |
| [^8] | [Generating Mathematical Derivations with Large Language Models.](http://arxiv.org/abs/2307.09998) | 本文利用大型语言模型生成数学导出，分析了微调模型对未见符号和方程结构更改的敏感性，结果表明微调的FLAN-T5-large（MathT5）在各个测试集上的绝对性能优于GPT模型。 |
| [^9] | [GUIDO: A Hybrid Approach to Guideline Discovery & Ordering from Natural Language Texts.](http://arxiv.org/abs/2307.09959) | GUIDO是一种混合方法，通过使用BERT-based句子分类器进行句子相关性分类，并使用依赖解析从相关句子中提取流程模型，显著提高了流程模型的提取结果。 |
| [^10] | [Test-takers have a say: understanding the implications of the use of AI in language tests.](http://arxiv.org/abs/2307.09885) | 深入了解在语言测试中使用人工智能的影响和担忧，有助于利益相关者做出明智决策，确保社区福祉和测试完整性。 |
| [^11] | [DAPrompt: Deterministic Assumption Prompt Learning for Event Causality Identification.](http://arxiv.org/abs/2307.09813) | 这篇论文提出了一个名为DAPrompt的确定性假设提示学习模型，用于事件因果关系识别任务。与传统提示学习不同，该模型首先基于确定性假设对事件之间的因果关系进行评估，而不是预测答案词。通过利用预训练语言模型中的类百科知识，该模型可以更好地解决ECI任务。 |
| [^12] | [On the Origin of LLMs: An Evolutionary Tree and Graph for 15,821 Large Language Models.](http://arxiv.org/abs/2307.09793) | 本研究利用Hugging Face LLMs的命名法，通过层次聚类和n-gram方法，成功识别了15,821个LLMs的族群和子组，并呈现了一个公共的网页应用程序来浏览和探索这些LLMs。 |
| [^13] | [ZeroQuant-FP: A Leap Forward in LLMs Post-Training W4A8 Quantization Using Floating-Point Formats.](http://arxiv.org/abs/2307.09782) | ZeroQuant-FP通过使用浮点格式进行LLMs训练后量化，解决了在大型语言模型中平衡计算效率和保持模型质量的挑战，并发现FP8激活优于INT8，并且FP4权重表现与INT4相当甚至更优。 |
| [^14] | [Enhancing conversational quality in language learning chatbots: An evaluation of GPT4 for ASR error correction.](http://arxiv.org/abs/2307.09744) | 本文研究了在语言学习聊天机器人中使用GPT4进行ASR错误纠正的方法，发现GPT4纠正的转录导致更高的对话质量，尽管WER有所增加。 |
| [^15] | [RaTE: a Reproducible automatic Taxonomy Evaluation by Filling the Gap.](http://arxiv.org/abs/2307.09706) | RaTE是一种无标签的自动分类评分方法，它通过大型预训练的语言模型实现可重复的自动分类评估。结果表明，RaTE与人类评判具有较高的相关性，并且人为降低分类法会导致RaTE评分下降。 |
| [^16] | [CValues: Measuring the Values of Chinese Large Language Models from Safety to Responsibility.](http://arxiv.org/abs/2307.09705) | 本论文提出了CValues，这是首个中文人类价值观评估基准，用于衡量中文大型语言模型在安全和责任准则方面的一致性能力。研究发现，虽然大多数中文大型语言模型具有较高的准确性和效用，但仍然存在与人类价值观不一致的情况。 |
| [^17] | [Efficient Guided Generation for LLMs.](http://arxiv.org/abs/2307.09702) | 本文描述了一种使用正则表达式和上下文无关文法来引导语言模型文本生成的高效方法。 |
| [^18] | [Efficiency Pentathlon: A Standardized Arena for Efficiency Evaluation.](http://arxiv.org/abs/2307.09701) | 一项名为Pentathlon的效率评估竞技场被引入，旨在解决现代自然语言处理系统在模型效率评估和比较方面面临的挑战。该竞技场提供了严格控制的硬件平台，能够模拟现实世界的应用场景，同时集成了多个指标来评测不同方面的效率表现。 |
| [^19] | [Noor-Ghateh: A Benchmark Dataset for Evaluating Arabic Word Segmenters in Hadith Domain.](http://arxiv.org/abs/2307.09630) | 本研究提出了一个用于评估阿拉伯词分割方法的基准数据集，通过分析历史和宗教文本，帮助理解文本中的意义。这个数据集在词汇量和种类上都优于其他现有数据集，并且在阿拉伯哈迪斯领域是首个数据集。通过多种方法对数据集进行了评估并报告了注释质量。 |
| [^20] | [Understanding Multi-Turn Toxic Behaviors in Open-Domain Chatbots.](http://arxiv.org/abs/2307.09579) | 本研究针对开放域聊天机器人中的多轮有害行为问题进行了研究，发现现有工具无法检测出82%导致有害行为的单句都被认为是安全的。通过设计新的攻击方法\toxicbot，我们发现开放域聊天机器人模型可以在多轮对话中触发生成有害回应。 |
| [^21] | [Can Model Fusing Help Transformers in Long Document Classification? An Empirical Study.](http://arxiv.org/abs/2307.09532) | 本研究探讨了在长文档分类中采用模型融合的方法，与BERT和Longformer模型进行了比较，并发现模型融合在处理长文档分类问题上具有潜力。 |
| [^22] | [A comparative analysis of SR-GAN models.](http://arxiv.org/abs/2307.09456) | 本研究比较分析了多个最先进的SR-GAN模型，结果发现EDSR模型在保持视觉质量的同时显著提高了输入图像的分辨率，具有较高的PSNR和SSIM值，并且返回高质量的OCR结果，这表明EDSR是一种有效的超分辨率方法。 |
| [^23] | [Pseudo Outlier Exposure for Out-of-Distribution Detection using Pretrained Transformers.](http://arxiv.org/abs/2307.09455) | 本文提出了一种名为伪异常暴露（POE）的简单而有效的方法，通过顺序屏蔽与内分布类相关的令牌构建替代的外分布数据集，用于检测未知分布的样本。 |
| [^24] | [Let's ViCE! Mimicking Human Cognitive Behavior in Image Generation Evaluation.](http://arxiv.org/abs/2307.09416) | 本文介绍了一种新颖的自动化方法ViCE，通过结合大型语言模型和视觉问答，模拟人类认知过程来评估生成图像与提示之间的一致性和质量。 |
| [^25] | [Llama 2: Open Foundation and Fine-Tuned Chat Models.](http://arxiv.org/abs/2307.09288) | Llama 2是一个优化的聊天模型，通过fine-tuned技术和安全改进，表现优于开源模型，并可作为闭源模型的替代选择。 |
| [^26] | [Retentive Network: A Successor to Transformer for Large Language Models.](http://arxiv.org/abs/2307.08621) | Retentive Network（RetNet）作为大型语言模型的基础架构，实现了训练并行、低成本推理和良好的性能。通过并行、循环和分块循环三种计算范式，RetNet具有训练并行化、低成本推理和高效的长序列建模的特点。 |
| [^27] | [Distilling Large Vision-Language Model with Out-of-Distribution Generalizability.](http://arxiv.org/abs/2307.03135) | 本文研究了针对大型视觉语言模型的模型压缩方法，将教师模型的视觉表示压缩到学生模型中。研究重点在于超出分布可泛化的问题，并提出了两个原则来增强学生模型的性能。 |
| [^28] | [LongNet: Scaling Transformers to 1,000,000,000 Tokens.](http://arxiv.org/abs/2307.02486) | LongNet是一种可以扩展到10亿个标记的Transformer变体，通过扩张注意力解决了序列长度受限的问题，具有线性计算复杂度和对数依赖关系，可以作为分布式训练器使用并无缝集成到现有的Transformer优化中。实验证明LongNet在长序列和短序列上性能强大。 |
| [^29] | [Iterated Piecewise Affine (IPA) Approximation for Language Modeling.](http://arxiv.org/abs/2306.12317) | 迭代分段仿射插值（IPA）逼近法可以用于语言建模，与变压器解码器架构类似，并在交叉熵损失下的小序列长度下优于变压器1.5％。 |
| [^30] | [GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio Pretraining for Speech Emotion Recognition.](http://arxiv.org/abs/2306.07848) | 本文提出了GEmo-CLAP模型用于语音情感识别，结合了性别属性信息，相比于其他先进方法，该模型在IEMOCAP上实现了更优越的识别性能。 |
| [^31] | [ChatGPT Outperforms Crowd-Workers for Text-Annotation Tasks.](http://arxiv.org/abs/2303.15056) | ChatGPT在文本标注任务中表现优于众包工作者，包括相关性、态度、主题和框架检测任务。ChatGPT的零样本准确率超越众包工作者四个任务，编码者间一致性在所有任务中均超过众包工作者和受过训练的注释者。此外，ChatGPT的标注成本比MTurk便宜20倍左右，显示了大型语言模型提高文本分类效率的潜力。 |
| [^32] | [Understand Legal Documents with Contextualized Large Language Models.](http://arxiv.org/abs/2303.12135) | 本文介绍了针对 SemEval-2023 任务 6 开发的 Legal-BERT-HSLN 模型和 Legal-LUKE 模型，其中 Legal-BERT-HSLN 模型通过考虑句内和句间的上下文信息以预测修辞角色，Legal-LUKE 模型是具有法律上下文和实体知识的模型，以识别法律实体。模型相比基线模型更准确，能够解决在人口众多的国家处理法律文件的问题。 |
| [^33] | [ThoughtSource: A central hub for large language model reasoning data.](http://arxiv.org/abs/2301.11596) | ThoughtSource是一个用于连续思考推理的元数据集和软件库，旨在通过促进对连续思考的定性理解、实证评估和提供训练数据，改进未来的人工智能系统。 |
| [^34] | [Lego-MT: Towards Detachable Models in Massively Multilingual Machine Translation.](http://arxiv.org/abs/2212.10551) | 本文提出了一种可拆卸的多语言机器翻译模型，Lego-MT，以解决现有多语言单体模型在参数干扰和低效推导方面的挑战。进行实验评估表明，该模型具有较高的性能，相比具有10倍规模的模型，在效率和表现方面都更具优势。 |
| [^35] | [Can In-context Learners Learn a Reasoning Concept from Demonstrations?.](http://arxiv.org/abs/2212.01692) | 本文介绍了一种概念性少样本学习方法，以帮助在场学习者学习新技能。通过选择与预测示例共享可能信息的演示，这个方法可以在模型记忆独立的情况下区分模型的在场学习能力。 |
| [^36] | [Revisiting Softmax for Uncertainty Approximation in Text Classification.](http://arxiv.org/abs/2210.14037) | 本研究重新审视了Softmax在文本分类中的不确定性近似方法，并比较了基于MC Dropout的方法。实证分析发现，尽管MC dropout产生了最好的不确定性近似，但使用softmax也能产生相对准确的结果。 |

# 详细

[^1]: DialogStudio：面向会话 AI 的最丰富和最多样化的统一数据集集合

    DialogStudio: Towards Richest and Most Diverse Unified Dataset Collection for Conversational AI. (arXiv:2307.10172v1 [cs.CL])

    [http://arxiv.org/abs/2307.10172](http://arxiv.org/abs/2307.10172)

    DialogStudio是迄今为止最大且最多样化的对话数据集合，包含从开放领域对话到任务导向对话、自然语言理解、会话推荐、对话摘要和知识驱动对话的数据。它为对话研究和模型训练提供了丰富而多样化的资源。

    

    尽管会话 AI 取得了进展，但语言模型在处理多样化的对话任务时面临挑战，现有的对话数据集往往缺乏多样性和全面性。为解决这些问题，我们介绍了 DialogStudio：最大、最多样化的对话数据集集合，以一致的格式统一，同时保留其原始信息。我们的集合包括来自开放领域对话、任务导向对话、自然语言理解、会话推荐、对话摘要和知识驱动对话的数据，为对话研究和模型训练提供了非常丰富和多样化的资源。为了进一步增强 DialogStudio 的实用性，我们为每个数据集确定了许可证，并为选定对话设计了领域感知提示，以便促进指导感知微调。此外，我们使用数据集集合开发了会话 AI 模型，并在零摘要生成和分布式文字基准对话任务上进行了实验。

    Despite advancements in conversational AI, language models encounter challenges to handle diverse conversational tasks, and existing dialogue dataset collections often lack diversity and comprehensiveness. To tackle these issues, we introduce DialogStudio: the largest and most diverse collection of dialogue datasets, unified under a consistent format while preserving their original information. Our collection encompasses data from open-domain dialogues, task-oriented dialogues, natural language understanding, conversational recommendation, dialogue summarization, and knowledge-grounded dialogues, making it an incredibly rich and diverse resource for dialogue research and model training. To further enhance the utility of DialogStudio, we identify the licenses for each dataset and design domain-aware prompts for selected dialogues to facilitate instruction-aware fine-tuning. Furthermore, we develop conversational AI models using the dataset collection, and our experiments in both zero-sh
    
[^2]: 大型语言模型的挑战与应用

    Challenges and Applications of Large Language Models. (arXiv:2307.10169v1 [cs.CL])

    [http://arxiv.org/abs/2307.10169](http://arxiv.org/abs/2307.10169)

    本文旨在总结大型语言模型领域的挑战和应用成功案例，帮助机器学习研究人员快速了解该领域的当前状态并提高效率。

    

    大型语言模型在机器学习领域的讨论中从不存在到无处不在只用了几年的时间。由于领域的快速发展，很难确定剩余的挑战和已经取得的应用成功。本文旨在建立一个系统的一组未解决问题和应用成功案例，以便机器学习研究人员能够更快地了解该领域的当前状态并提高效率。

    Large Language Models (LLMs) went from non-existent to ubiquitous in the machine learning discourse within a few years. Due to the fast pace of the field, it is difficult to identify the remaining challenges and already fruitful application areas. In this paper, we aim to establish a systematic set of open problems and application successes so that ML researchers can comprehend the field's current state more quickly and become productive.
    
[^3]: LLM作为人-计算算法中的工作者？用LLM复制众包流水线。

    LLMs as Workers in Human-Computational Algorithms? Replicating Crowdsourcing Pipelines with LLMs. (arXiv:2307.10168v1 [cs.CL])

    [http://arxiv.org/abs/2307.10168](http://arxiv.org/abs/2307.10168)

    本文研究探索了LLMs是否可以复制更复杂的众包流水线，并发现现代LLMs在模拟人类计算算法中的能力上有一定的成功，但受多种因素影响。文章强调了为LLMs提供人类面向的安全保障的重要性，并讨论了训练人类和LLMs互补技能的潜力。

    

    LLM已经显示出在众包任务中复制人类行为的潜力，而这些任务以前被认为只有人类才能完成。然而，目前的研究主要集中在简单的原子任务上。我们探索LLM是否可以复制更复杂的众包流水线。我们发现现代LLM可以模拟某些众包工作者在这些“人类计算算法”中的能力，但成功的程度是可变的，并受到请求者对LLM能力的理解、子任务所需的特定技能以及执行这些子任务的最佳交互方式的影响。我们反思了人类和LLM对指示的不同敏感性，强调为LLM提供面向人类的安全保障的重要性，并讨论了训练具有互补技能的人类和LLM的潜力。关键是，我们展示了复制众包流水线提供了一个有价值的平台来研究LLM在不同任务上的相对优势（通过交叉验证

    LLMs have shown promise in replicating human-like behavior in crowdsourcing tasks that were previously thought to be exclusive to human abilities. However, current efforts focus mainly on simple atomic tasks. We explore whether LLMs can replicate more complex crowdsourcing pipelines. We find that modern LLMs can simulate some of crowdworkers' abilities in these "human computation algorithms," but the level of success is variable and influenced by requesters' understanding of LLM capabilities, the specific skills required for sub-tasks, and the optimal interaction modality for performing these sub-tasks. We reflect on human and LLMs' different sensitivities to instructions, stress the importance of enabling human-facing safeguards for LLMs, and discuss the potential of training humans and LLMs with complementary skill sets. Crucially, we show that replicating crowdsourcing pipelines offers a valuable platform to investigate (1) the relative strengths of LLMs on different tasks (by cross
    
[^4]: 探索Transformer外推

    Exploring Transformer Extrapolation. (arXiv:2307.10156v1 [cs.CL])

    [http://arxiv.org/abs/2307.10156](http://arxiv.org/abs/2307.10156)

    本文通过数学和实证分析，发现只要RPE的指数序列收敛，Transformer就具有长度外推的能力。从中导出了两种实践方法，并提出了一种新的理论感受野(TRF)来测量RPE的感受野。

    

    长度外推近期引起了相当大的关注，因为它允许transformers在训练中使用的序列长度之外进行测试。先前的研究表明，通过使用精心设计的相对位置编码(RPEs)可以实现这一属性。虽然这些方法在各种文集上表现良好，但对于长度外推的条件尚未得到研究。本文试图通过彻底的数学和实证分析确定哪种类型的RPEs可以实现长度外推。我们发现只要对应于RPE的指数收敛的序列，transformer一定具有这个属性。从这些条件中导出了两种实践方法，并在各种文集上进行了语言建模任务的研究。作为条件衍生的额外好处，我们推导出了一种新的理论感受野(TRF)，可以在不进行任何训练步骤的情况下测量RPE的感受野。进行了大量的实验。

    Length extrapolation has attracted considerable attention recently since it allows transformers to be tested on longer sequences than those used in training. Previous research has shown that this property can be attained by using carefully designed Relative Positional Encodings (RPEs). While these methods perform well on a variety of corpora, the conditions for length extrapolation have yet to be investigated. This paper attempts to determine what types of RPEs allow for length extrapolation through a thorough mathematical and empirical analysis. We discover that a transformer is certain to possess this property as long as the series that corresponds to the RPE's exponential converges. Two practices are derived from the conditions and examined in language modeling tasks on a variety of corpora. As a bonus from the conditions, we derive a new Theoretical Receptive Field (TRF) to measure the receptive field of RPEs without taking any training steps. Extensive experiments are conducted on
    
[^5]: 渐进稀疏化用于Transformer模型的遮罩微调

    Gradient Sparsification For Masked Fine-Tuning of Transformers. (arXiv:2307.10098v1 [cs.CL])

    [http://arxiv.org/abs/2307.10098](http://arxiv.org/abs/2307.10098)

    本研究提出了一种使用渐进稀疏化方法对预训练语言模型进行正则化，以改善微调性能。GradDrop及其变体通过在训练过程中随机屏蔽梯度，有效地进行梯度稀疏化。

    

    预训练的自监督语言模型的微调被广泛应用于向下游任务的迁移学习。微调可通过冻结预训练网络的梯度并只更新新添加的分类层的梯度，或通过对所有参数进行梯度更新来实现。渐进解冻在训练过程中逐渐解冻整个层的梯度，以在存储和训练速度与泛化性能之间进行权衡，这是一种有效的策略。然而，目前还不清楚渐进解冻整个训练是否是最优选择，相比之下，稀疏变体的渐进解冻可能可以提高微调性能。在本文中，我们提出了随机屏蔽梯度来正则化预训练语言模型，从而改善整体微调性能。我们介绍了GradDrop及其变体，一类梯度稀疏化方法，在训练过程中对梯度进行屏蔽。

    Fine-tuning pretrained self-supervised language models is widely adopted for transfer learning to downstream tasks. Fine-tuning can be achieved by freezing gradients of the pretrained network and only updating gradients of a newly added classification layer, or by performing gradient updates on all parameters. Gradual unfreezing makes a trade-off between the two by gradually unfreezing gradients of whole layers during training. This has been an effective strategy to trade-off between storage and training speed with generalization performance. However, it is not clear whether gradually unfreezing layers throughout training is optimal, compared to sparse variants of gradual unfreezing which may improve fine-tuning performance. In this paper, we propose to stochastically mask gradients to regularize pretrained language models for improving overall fine-tuned performance. We introduce GradDrop and variants thereof, a class of gradient sparsification methods that mask gradients during the b
    
[^6]: 在野外的Android：用于Android设备控制的大规模数据集

    Android in the Wild: A Large-Scale Dataset for Android Device Control. (arXiv:2307.10088v1 [cs.LG])

    [http://arxiv.org/abs/2307.10088](http://arxiv.org/abs/2307.10088)

    这个论文提出了一个名为Android in the Wild (AITW)的大规模数据集，用于研究设备控制系统，该数据集包括人类示范的设备交互、自然语言指令和多种Android版本和设备类型。这个数据集提供了一个新的挑战，需要从视觉外观中推断用户界面中可用的操作。

    

    对于能够解释人类自然语言指令并直接控制数字设备用户界面执行的设备控制系统，人们越来越感兴趣。我们提出了一个用于设备控制研究的数据集，Android in the Wild (AITW)，该数据集比当前数据集大几个数量级。该数据集包含了设备交互的人类示范，包括屏幕和操作，以及相应的自然语言指令。它包括715k个剧集，涵盖30k个不同的指令，四个Android版本（v10-13），以及八种不同的设备类型（从Pixel 2 XL到Pixel 6）和不同的屏幕分辨率。它包含需要语言和视觉上下文的语义理解的多步骤任务。这个数据集提出了一个新的挑战：必须从它们的视觉外观中推断出用户界面中可用的操作。而且，行动空间不再是简单的基于用户界面元素的行动，而是包含精确的手势（例如，水平滚动）

    There is a growing interest in device-control systems that can interpret human natural language instructions and execute them on a digital device by directly controlling its user interface. We present a dataset for device-control research, Android in the Wild (AITW), which is orders of magnitude larger than current datasets. The dataset contains human demonstrations of device interactions, including the screens and actions, and corresponding natural language instructions. It consists of 715k episodes spanning 30k unique instructions, four versions of Android (v10-13),and eight device types (Pixel 2 XL to Pixel 6) with varying screen resolutions. It contains multi-step tasks that require semantic understanding of language and visual context. This dataset poses a new challenge: actions available through the user interface must be inferred from their visual appearance. And, instead of simple UI element-based actions, the action space consists of precise gestures (e.g., horizontal scrolls 
    
[^7]: 通过使用多粒度主题分析方法的实证研究：生育政策提案

    An Empirical Study on Fertility Proposals Using Multi-Grined Topic Analysis Methods. (arXiv:2307.10025v1 [cs.HC])

    [http://arxiv.org/abs/2307.10025](http://arxiv.org/abs/2307.10025)

    本研究通过采用多粒度主题分析方法，对微博评论进行语义分析，发现关于取消婚姻登记的生育限制的提案涉及个人、社会和国家三个维度，详细讨论了个人行为、社会伦理和法律以及国家政策等社会问题。

    

    生育问题与人口安全密切相关，中国60年来首次出现人口负增长趋势，生育政策的变化引起了社会的极大关注。本文采用共现语义分析、主题分析和情感分析等方法，对微博评论进行多粒度的语义分析。发现关于“取消婚姻登记的生育限制”的提案讨论涉及个人、社会和国家三个维度，并详细探讨了个人行为、社会伦理和法律以及国家政策等社会问题。

    Fertility issues are closely related to population security, in 60 years China's population for the first time in a negative growth trend, the change of fertility policy is of great concern to the community. 2023 ``two sessions" proposal ``suggests that the country in the form of legislation, the birth of the registration of the cancellation of the marriage restriction" This topic was once a hot topic on the Internet, and ``unbundling" the relationship between birth registration and marriage has become the focus of social debate. In this paper, we adopt co-occurrence semantic analysis, topic analysis and sentiment analysis to conduct multi-granularity semantic analysis of microblog comments. It is found that the discussion on the proposal of ``removing marriage restrictions from birth registration" involves the individual, society and the state at three dimensions, and is detailed into social issues such as personal behaviour, social ethics and law, and national policy, with people's s
    
[^8]: 用大型语言模型生成数学导出

    Generating Mathematical Derivations with Large Language Models. (arXiv:2307.09998v1 [cs.CL])

    [http://arxiv.org/abs/2307.09998](http://arxiv.org/abs/2307.09998)

    本文利用大型语言模型生成数学导出，分析了微调模型对未见符号和方程结构更改的敏感性，结果表明微调的FLAN-T5-large（MathT5）在各个测试集上的绝对性能优于GPT模型。

    

    利用大型语言模型（LLM）在专业领域中生成数学结果的导出是一个新兴的研究方向，可以帮助识别模型的局限性，并有可能支持数学发现。本文利用符号引擎在大规模上生成方程的导出，并研究了LLM在从前提中导出目标方程时的能力。具体而言，我们采用上下文学习来对GPT进行训练，并对一系列T5模型进行了微调，以比较预训练策略对专门模型的鲁棒性和泛化能力。实证结果表明，经过微调的FLAN-T5-large（MathT5）在所有静态和超出分布的测试集上的绝对性能优于GPT模型。然而，深入分析表明，微调模型对涉及未见符号的扰动（以及在较小程度上的方程结构更改）更为敏感。此外，我们分析了1.7K个方程和200多个导出以凸显出LLM的局限性。

    The derivation of mathematical results in specialised fields using Large Language Models (LLMs) is an emerging research direction that can help identify models' limitations, and potentially support mathematical discovery. In this paper, we leverage a symbolic engine to generate derivations of equations at scale, and investigate the capabilities of LLMs when deriving goal equations from premises. Specifically, we employ in-context learning for GPT and fine-tune a range of T5 models to compare the robustness and generalisation of pre-training strategies to specialised models. Empirical results show that fine-tuned FLAN-T5-large (MathT5) outperforms GPT models on all static and out-of-distribution test sets in terms of absolute performance. However, an in-depth analysis reveals that the fine-tuned models are more sensitive to perturbations involving unseen symbols and (to a lesser extent) changes to equation structure. In addition, we analyse 1.7K equations and over 200 derivations to hig
    
[^9]: GUIDO：一种从自然语言文本中发现和排序指南的混合方法

    GUIDO: A Hybrid Approach to Guideline Discovery & Ordering from Natural Language Texts. (arXiv:2307.09959v1 [cs.CL])

    [http://arxiv.org/abs/2307.09959](http://arxiv.org/abs/2307.09959)

    GUIDO是一种混合方法，通过使用BERT-based句子分类器进行句子相关性分类，并使用依赖解析从相关句子中提取流程模型，显著提高了流程模型的提取结果。

    

    从文本描述中提取工作流网络可用于简化指南或形式化的业务流程和算法等正式流程的文本描述。然而，手动提取流程的任务需要领域专业知识和工作量。虽然自动流程模型提取是可取的，但用形式化的流程模型注释文本是昂贵的。因此，目前只有少数基于机器学习的提取方法。而基于规则的方法往往需要领域特定性才能良好运作，并且很少能够区分文本描述中的相关和不相关信息。本文提出了GUIDO，一种混合方法，用于处理流程模型提取任务。首先，使用基于BERT的句子分类器对句子进行相关性分类，然后使用依赖解析从被分类为相关的句子中提取流程模型。所提出的方法取得了显著改进的结果。

    Extracting workflow nets from textual descriptions can be used to simplify guidelines or formalize textual descriptions of formal processes like business processes and algorithms. The task of manually extracting processes, however, requires domain expertise and effort. While automatic process model extraction is desirable, annotating texts with formalized process models is expensive. Therefore, there are only a few machine-learning-based extraction approaches. Rule-based approaches, in turn, require domain specificity to work well and can rarely distinguish relevant and irrelevant information in textual descriptions. In this paper, we present GUIDO, a hybrid approach to the process model extraction task that first, classifies sentences regarding their relevance to the process model, using a BERT-based sentence classifier, and second, extracts a process model from the sentences classified as relevant, using dependency parsing. The presented approach achieves significantly better results
    
[^10]: 考试者有话说：理解在语言测试中使用人工智能的影响

    Test-takers have a say: understanding the implications of the use of AI in language tests. (arXiv:2307.09885v1 [cs.CY])

    [http://arxiv.org/abs/2307.09885](http://arxiv.org/abs/2307.09885)

    深入了解在语言测试中使用人工智能的影响和担忧，有助于利益相关者做出明智决策，确保社区福祉和测试完整性。

    

    语言测试衡量一个人在听、说、读、写方面使用某种语言的能力。这类测试在学术、职业和移民领域发挥着重要作用，教育机构、专业认证机构和政府等实体机构使用它们来评估候选人的语言熟练程度。人工智能和自然语言处理学科的最新进展促使语言测试提供者探索将人工智能应用于语言测试的潜在可能性，从而引发了围绕语言教学和学习的变革性活动模式。然而，在对人工智能信任性存在担忧的情况下，必须了解将人工智能整合到语言测试中的影响。这样的知识将使利益相关者能够做出明智的决策，从而保护社区的福祉和测试的完整性。为了了解在语言测试中使用人工智能的关切和影响，我们进行了...

    Language tests measure a person's ability to use a language in terms of listening, speaking, reading, or writing. Such tests play an integral role in academic, professional, and immigration domains, with entities such as educational institutions, professional accreditation bodies, and governments using them to assess candidate language proficiency. Recent advances in Artificial Intelligence (AI) and the discipline of Natural Language Processing have prompted language test providers to explore AI's potential applicability within language testing, leading to transformative activity patterns surrounding language instruction and learning. However, with concerns over AI's trustworthiness, it is imperative to understand the implications of integrating AI into language testing. This knowledge will enable stakeholders to make well-informed decisions, thus safeguarding community well-being and testing integrity. To understand the concerns and effects of AI usage in language tests, we conducted 
    
[^11]: DAPrompt: 事件因果关系识别的确定性假设提示学习

    DAPrompt: Deterministic Assumption Prompt Learning for Event Causality Identification. (arXiv:2307.09813v1 [cs.CL])

    [http://arxiv.org/abs/2307.09813](http://arxiv.org/abs/2307.09813)

    这篇论文提出了一个名为DAPrompt的确定性假设提示学习模型，用于事件因果关系识别任务。与传统提示学习不同，该模型首先基于确定性假设对事件之间的因果关系进行评估，而不是预测答案词。通过利用预训练语言模型中的类百科知识，该模型可以更好地解决ECI任务。

    

    事件因果关系识别（ECI）旨在确定两个事件提及之间是否存在因果关系。传统的提示学习设计了一个提示模板，首先预测一个答案词，然后将其映射到最终的决策。与传统提示不同，我们认为预测一个答案词可能不是ECI任务的必要先决条件。相反，我们可以首先对两个事件之间是否存在因果关系进行确定性假设，然后评估其合理性，接受或拒绝该假设。设计的动机是尽可能地利用预训练语言模型中嵌入的类百科知识。基于这些考虑，我们提出了一种确定性假设提示学习模型，称为DAPrompt，用于ECI任务。特别地，我们设计了一个简单的确定性假设模板，该模板与输入的事件对进行连接，其中包括两个掩码作为预测事件的标记。我们使用概率来衡量确定性假设的合理性。

    Event Causality Identification (ECI) aims at determining whether there is a causal relation between two event mentions. Conventional prompt learning designs a prompt template to first predict an answer word and then maps it to the final decision. Unlike conventional prompts, we argue that predicting an answer word may not be a necessary prerequisite for the ECI task. Instead, we can first make a deterministic assumption on the existence of causal relation between two events and then evaluate its rationality to either accept or reject the assumption. The design motivation is to try the most utilization of the encyclopedia-like knowledge embedded in a pre-trained language model. In light of such considerations, we propose a deterministic assumption prompt learning model, called DAPrompt, for the ECI task. In particular, we design a simple deterministic assumption template concatenating with the input event pair, which includes two masks as predicted events' tokens. We use the probabiliti
    
[^12]: 关于LLMs的起源：15821个大型语言模型的进化树和图谱

    On the Origin of LLMs: An Evolutionary Tree and Graph for 15,821 Large Language Models. (arXiv:2307.09793v1 [cs.DL])

    [http://arxiv.org/abs/2307.09793](http://arxiv.org/abs/2307.09793)

    本研究利用Hugging Face LLMs的命名法，通过层次聚类和n-gram方法，成功识别了15,821个LLMs的族群和子组，并呈现了一个公共的网页应用程序来浏览和探索这些LLMs。

    

    自2022年底以来，大型语言模型（LLMs）已成为非常突出的研究领域，像ChatGPT和Bard这样的LLMs已经吸引了数百万个用户。每周都有数百个新的LLMs被发布，其中许多被上传到Hugging Face，这是一个机器学习模型和数据集的库。到目前为止，该网站已经上传了近16000个文本生成模型。鉴于LLMs的大量涌入，了解哪些LLM骨干、设置、训练方法和族群受到欢迎或趋势变得很有意义。然而，目前没有一个全面的LLMs索引可用。我们利用Hugging Face LLMs的相对系统的命名法对LLMs进行层次聚类，并使用n-gram和词频-逆文档频率来识别LLMs之间的联系和群体。我们的方法成功地识别了LLMs的族群，并将LLMs准确地聚类成有意义的子组。我们展示了一个公共的网页应用程序来浏览和探索Constellation，我们的15821个LLMs的图谱。

    Since late 2022, Large Language Models (LLMs) have become very prominent with LLMs like ChatGPT and Bard receiving millions of users. Hundreds of new LLMs are announced each week, many of which are deposited to Hugging Face, a repository of machine learning models and datasets. To date, nearly 16,000 Text Generation models have been uploaded to the site. Given the huge influx of LLMs, it is of interest to know which LLM backbones, settings, training methods, and families are popular or trending. However, there is no comprehensive index of LLMs available. We take advantage of the relatively systematic nomenclature of Hugging Face LLMs to perform hierarchical clustering and identify communities amongst LLMs using n-grams and term frequency-inverse document frequency. Our methods successfully identify families of LLMs and accurately cluster LLMs into meaningful subgroups. We present a public web application to navigate and explore Constellation, our atlas of 15,821 LLMs. Constellation rap
    
[^13]: ZeroQuant-FP: 使用浮点格式进行LLMs训练后量化的一项飞跃

    ZeroQuant-FP: A Leap Forward in LLMs Post-Training W4A8 Quantization Using Floating-Point Formats. (arXiv:2307.09782v1 [cs.LG])

    [http://arxiv.org/abs/2307.09782](http://arxiv.org/abs/2307.09782)

    ZeroQuant-FP通过使用浮点格式进行LLMs训练后量化，解决了在大型语言模型中平衡计算效率和保持模型质量的挑战，并发现FP8激活优于INT8，并且FP4权重表现与INT4相当甚至更优。

    

    在大型语言模型（LLMs）的复杂领域中，平衡计算效率和保持模型质量是一个巨大的挑战。本研究通过探讨浮点（FP）量化的可行性，特别关注FP8和FP4，以应对均匀量化的固有限制，尤其是处理离群值，并受到NVIDIA H100硬件的启发。我们的全面调查发现，在LLMs中，FP8激活始终优于其整数（INT8）等效，性能优势在包含超过十亿参数的模型中更为明显。对于权重量化，我们的研究结果表明，FP4的性能与INT4相当，甚至更优，简化了在像H100这样支持FP的硬件上的部署。为了减少由权重和激活之间差异引起的精度对齐开销，我们提出了两个缩放约束。

    In the complex domain of large language models (LLMs), striking a balance between computational efficiency and maintaining model quality is a formidable challenge. Navigating the inherent limitations of uniform quantization, particularly when dealing with outliers, and motivated by the launch of NVIDIA's H100 hardware, this study delves into the viability of floating-point (FP) quantization, particularly focusing on FP8 and FP4, as a potential solution. Our comprehensive investigation reveals that for LLMs, FP8 activation consistently outshines its integer (INT8) equivalent, with the performance edge becoming more noticeable in models possessing parameters beyond one billion. For weight quantization, our findings indicate that FP4 exhibits comparable, if not superior, performance to INT4, simplifying deployment on FP-supported hardware like H100. To mitigate the overhead from precision alignment caused by the disparity between weights and activations, we propose two scaling constraints
    
[^14]: 提高语言学习聊天机器人对话质量：对GPT4在ASR错误纠正中的评估

    Enhancing conversational quality in language learning chatbots: An evaluation of GPT4 for ASR error correction. (arXiv:2307.09744v1 [cs.CL])

    [http://arxiv.org/abs/2307.09744](http://arxiv.org/abs/2307.09744)

    本文研究了在语言学习聊天机器人中使用GPT4进行ASR错误纠正的方法，发现GPT4纠正的转录导致更高的对话质量，尽管WER有所增加。

    

    自然语言处理技术（NLP）在教育应用中的整合已经显示出有希望的结果，特别是在语言学习领域。最近，许多口语开放领域的聊天机器人被用作口语伙伴，帮助语言学习者提升语言技能。然而，其中一个重要的挑战是在识别非母语/非流利语音时的高字错误率（WER），这会打断对话流程并令学习者感到失望。本文探讨了在对话环境中使用GPT4进行ASR错误纠正的方法。除了WER，我们还提出使用语义文本相似度（STS）和下一个回复的合理性（NRS）指标来评估错误纠正模型对对话质量的影响。我们发现，由GPT4纠正的转录导致更高的对话质量，尽管WER有所增加。GPT4还优于标准的错误纠正方法，而无需领域专属数据。

    The integration of natural language processing (NLP) technologies into educational applications has shown promising results, particularly in the language learning domain. Recently, many spoken open-domain chatbots have been used as speaking partners, helping language learners improve their language skills. However, one of the significant challenges is the high word-error-rate (WER) when recognizing non-native/non-fluent speech, which interrupts conversation flow and leads to disappointment for learners. This paper explores the use of GPT4 for ASR error correction in conversational settings. In addition to WER, we propose to use semantic textual similarity (STS) and next response sensibility (NRS) metrics to evaluate the impact of error correction models on the quality of the conversation. We find that transcriptions corrected by GPT4 lead to higher conversation quality, despite an increase in WER. GPT4 also outperforms standard error correction methods without the need for in-domain tr
    
[^15]: RaTE: 通过填补空白实现可重复的自动分类评估

    RaTE: a Reproducible automatic Taxonomy Evaluation by Filling the Gap. (arXiv:2307.09706v1 [cs.CL])

    [http://arxiv.org/abs/2307.09706](http://arxiv.org/abs/2307.09706)

    RaTE是一种无标签的自动分类评分方法，它通过大型预训练的语言模型实现可重复的自动分类评估。结果表明，RaTE与人类评判具有较高的相关性，并且人为降低分类法会导致RaTE评分下降。

    

    分类法对于知识表示是必不可少的，然而，大多数关于自动分类构建的研究仍然依赖于人工评估来评分提出的算法。我们认为自动分类评估和分类构建一样重要。我们提出了RaTE，一种无标签的自动分类评分方法，它依赖于一个大型预训练的语言模型。我们将该评估方法应用于三种最先进的自动分类构建算法，并从Yelp领域构建了七个分类法，结果显示：1）RaTE与人类评判的相关性较高；2）人为降低分类法会导致RaTE评分下降。

    Taxonomies are an essential knowledge representation, yet most studies on automatic taxonomy construction (ATC) resort to manual evaluation to score proposed algorithms. We argue that automatic taxonomy evaluation (ATE) is just as important as taxonomy construction. We propose RaTE, an automatic label-free taxonomy scoring procedure, which relies on a large pre-trained language model. We apply our evaluation procedure to three state-of-the-art ATC algorithms with which we built seven taxonomies from the Yelp domain, and show that 1) RaTE correlates well with human judgments and 2) artificially degrading a taxonomy leads to decreasing RaTE score.
    
[^16]: CValues: 从安全到责任度量中文大型语言模型的价值观

    CValues: Measuring the Values of Chinese Large Language Models from Safety to Responsibility. (arXiv:2307.09705v1 [cs.CL])

    [http://arxiv.org/abs/2307.09705](http://arxiv.org/abs/2307.09705)

    本论文提出了CValues，这是首个中文人类价值观评估基准，用于衡量中文大型语言模型在安全和责任准则方面的一致性能力。研究发现，虽然大多数中文大型语言模型具有较高的准确性和效用，但仍然存在与人类价值观不一致的情况。

    

    随着大型语言模型（LLMs）的迅速发展，人们越来越担心它们可能带来风险或对社会产生负面影响。因此，评估人类价值观的一致性变得越来越重要。先前的工作主要关注评估LLMs在特定知识和推理能力上的表现，而忽视了对人类价值观的一致性，特别是在中国的背景下。在本文中，我们提出了CValues，这是首个中文人类价值观评估基准，用于衡量LLMs在安全和责任准则方面的一致性能力。作为结果，我们手动收集了10个场景的对抗性安全提示，并由专业专家从8个领域诱导了责任提示。为了全面评估中文LLMs的价值观，我们不仅进行人工评估以进行可靠的比较，还构建了多选提示以进行自动评估。我们的研究结果表明，尽管大多数中文LLMs具有较高的准确性和效用，但仍然存在与人类价值观不一致的情况。

    With the rapid evolution of large language models (LLMs), there is a growing concern that they may pose risks or have negative social impacts. Therefore, evaluation of human values alignment is becoming increasingly important. Previous work mainly focuses on assessing the performance of LLMs on certain knowledge and reasoning abilities, while neglecting the alignment to human values, especially in a Chinese context. In this paper, we present CValues, the first Chinese human values evaluation benchmark to measure the alignment ability of LLMs in terms of both safety and responsibility criteria. As a result, we have manually collected adversarial safety prompts across 10 scenarios and induced responsibility prompts from 8 domains by professional experts. To provide a comprehensive values evaluation of Chinese LLMs, we not only conduct human evaluation for reliable comparison, but also construct multi-choice prompts for automatic evaluation. Our findings suggest that while most Chinese LL
    
[^17]: 高效的LLM引导生成

    Efficient Guided Generation for LLMs. (arXiv:2307.09702v1 [cs.CL])

    [http://arxiv.org/abs/2307.09702](http://arxiv.org/abs/2307.09702)

    本文描述了一种使用正则表达式和上下文无关文法来引导语言模型文本生成的高效方法。

    

    在本文中，我们描述了一种使用正则表达式和上下文无关文法来引导语言模型文本生成的高效方法。我们的方法在标记序列生成过程中几乎不增加任何开销，并使得引导生成在实际中可行。在开源Python库Outlines中提供了一个实现。

    In this article we describe an efficient approach to guiding language model text generation with regular expressions and context-free grammars. Our approach adds little to no overhead to the token sequence generation process, and makes guided generation feasible in practice. An implementation is provided in the open source Python library Outlines.
    
[^18]: Efficiency Pentathlon: 一项用于效率评估的标准竞技场

    Efficiency Pentathlon: A Standardized Arena for Efficiency Evaluation. (arXiv:2307.09701v1 [cs.CL])

    [http://arxiv.org/abs/2307.09701](http://arxiv.org/abs/2307.09701)

    一项名为Pentathlon的效率评估竞技场被引入，旨在解决现代自然语言处理系统在模型效率评估和比较方面面临的挑战。该竞技场提供了严格控制的硬件平台，能够模拟现实世界的应用场景，同时集成了多个指标来评测不同方面的效率表现。

    

    现代自然语言处理（NLP）系统的计算需求不断增加，增加了最前沿研究的准入门槛，同时引发了严重的环境问题。然而，模型效率的进展受到了模型评估和比较中的实际挑战的阻碍。例如，由于不同机构之间的可访问性差异，硬件控制具有挑战性。此外，FLOP等指标的改进通常无法转化为现实世界应用的进展。作为回应，我们引入了Pentathlon，这是一个用于整体和真实评估模型效率的基准测试。Pentathlon专注于推理，这在模型生命周期中占大多数计算。它提供了一个严格控制的硬件平台，并设计为模拟现实世界的应用场景。它包含了一套针对效率不同方面的度量标准，包括延迟、吞吐量、内存开销和能量消耗。

    Rising computational demands of modern natural language processing (NLP) systems have increased the barrier to entry for cutting-edge research while posing serious environmental concerns. Yet, progress on model efficiency has been impeded by practical challenges in model evaluation and comparison. For example, hardware is challenging to control due to disparate levels of accessibility across different institutions. Moreover, improvements in metrics such as FLOPs often fail to translate to progress in real-world applications. In response, we introduce Pentathlon, a benchmark for holistic and realistic evaluation of model efficiency. Pentathlon focuses on inference, which accounts for a majority of the compute in a model's lifecycle. It offers a strictly-controlled hardware platform, and is designed to mirror real-world applications scenarios. It incorporates a suite of metrics that target different aspects of efficiency, including latency, throughput, memory overhead, and energy consump
    
[^19]: Noor-Ghateh: 一个用于评估哈迪斯领域阿拉伯词分割器的基准数据集

    Noor-Ghateh: A Benchmark Dataset for Evaluating Arabic Word Segmenters in Hadith Domain. (arXiv:2307.09630v1 [cs.CL])

    [http://arxiv.org/abs/2307.09630](http://arxiv.org/abs/2307.09630)

    本研究提出了一个用于评估阿拉伯词分割方法的基准数据集，通过分析历史和宗教文本，帮助理解文本中的意义。这个数据集在词汇量和种类上都优于其他现有数据集，并且在阿拉伯哈迪斯领域是首个数据集。通过多种方法对数据集进行了评估并报告了注释质量。

    

    阿拉伯语具有许多复杂而丰富的形态学细微差别，这在分析传统的阿拉伯文本，特别是在历史和宗教语境中，对于理解文本的含义非常有用。词汇分离意味着将词语分解为诸如词根和词缀等不同部分。在形态学数据集中，标签的多样性和数据样本的数量有助于评估形态学方法。本文提出了一个基准数据集，用于评估分离阿拉伯词汇的方法，该数据集包含来自《伊斯兰教法》的约223,690个词汇，已由专家进行标记。就词汇量和种类而言，该数据集优于其他现有数据集，并且据我们所知，不存在阿拉伯哈迪斯领域的文本。为了评估该数据集，我们对数据集应用了不同的方法，如Farasa、Camel、Madamira和ALP，并通过四个参数报告了注释质量。

    There are many complex and rich morphological subtleties in the Arabic language, which are very useful when analyzing traditional Arabic texts, especially in the historical and religious contexts, and help in understanding the meaning of the texts. Vocabulary separation means separating the word into different parts such as root and affix. In the morphological datasets, the variety of labels and the number of data samples helps to evaluate the morphological methods. In this paper, we present a benchmark data set for evaluating the methods of separating Arabic words which include about 223,690 words from the book of Sharia alIslam, which have been labeled by experts. In terms of the volume and variety of words, this dataset is superior to other existing data sets, and as far as we know, there are no Arabic Hadith Domain texts. To evaluate the dataset, we applied different methods such as Farasa, Camel, Madamira, and ALP to the dataset and we reported the annotation quality through four 
    
[^20]: 理解开放域聊天机器人中的多轮有害行为

    Understanding Multi-Turn Toxic Behaviors in Open-Domain Chatbots. (arXiv:2307.09579v1 [cs.CR])

    [http://arxiv.org/abs/2307.09579](http://arxiv.org/abs/2307.09579)

    本研究针对开放域聊天机器人中的多轮有害行为问题进行了研究，发现现有工具无法检测出82%导致有害行为的单句都被认为是安全的。通过设计新的攻击方法\toxicbot，我们发现开放域聊天机器人模型可以在多轮对话中触发生成有害回应。

    

    最近自然语言处理和机器学习的进展使得聊天机器人模型如ChatGPT可以与人类用户进行对话。然而，这些模型在非有害的多轮对话中生成有害或有碍的回应能力仍然是一个开放性的研究问题。现有研究关注于单句测试，而我们发现82％因为单一句子而在对话中诱发有害行为的句子被现有工具认为是安全的。在本文中，我们设计了一种新的攻击方法\toxicbot，通过对聊天机器人进行微调与目标开放域聊天机器人进行对话。聊天机器人被微调为受控的会话序列。特别是，每个对话的起始都来自精心设计的提示句子数据集。我们的广泛评估表明，开放域聊天机器人模型可以在多轮对话中触发生成有害回应。

    Recent advances in natural language processing and machine learning have led to the development of chatbot models, such as ChatGPT, that can engage in conversational dialogue with human users. However, the ability of these models to generate toxic or harmful responses during a non-toxic multi-turn conversation remains an open research question. Existing research focuses on single-turn sentence testing, while we find that 82\% of the individual non-toxic sentences that elicit toxic behaviors in a conversation are considered safe by existing tools. In this paper, we design a new attack, \toxicbot, by fine-tuning a chatbot to engage in conversation with a target open-domain chatbot. The chatbot is fine-tuned with a collection of crafted conversation sequences. Particularly, each conversation begins with a sentence from a crafted prompt sentences dataset. Our extensive evaluation shows that open-domain chatbot models can be triggered to generate toxic responses in a multi-turn conversation
    
[^21]: 模型融合是否能帮助Transformer模型在长文档分类中取得更好的效果？一项实证研究。

    Can Model Fusing Help Transformers in Long Document Classification? An Empirical Study. (arXiv:2307.09532v1 [cs.CL])

    [http://arxiv.org/abs/2307.09532](http://arxiv.org/abs/2307.09532)

    本研究探讨了在长文档分类中采用模型融合的方法，与BERT和Longformer模型进行了比较，并发现模型融合在处理长文档分类问题上具有潜力。

    

    文本分类是自然语言处理（NLP）领域的一个研究方向，多年来一直受到关注。将NLP应用于多个领域为文本分类引入了许多新的挑战之一就是长文档分类。尽管最先进的Transformer模型在文本分类中提供了出色的结果，但大部分模型在输入序列的最大长度上存在限制。大多数Transformer模型仅限制为512个令牌，因此在长文档分类问题上表现不佳。在本研究中，我们探讨了在长文档分类中应用模型融合的相关方法，并将结果与知名的BERT和Longformer模型进行了比较。

    Text classification is an area of research which has been studied over the years in Natural Language Processing (NLP). Adapting NLP to multiple domains has introduced many new challenges for text classification and one of them is long document classification. While state-of-the-art transformer models provide excellent results in text classification, most of them have limitations in the maximum sequence length of the input sequence. The majority of the transformer models are limited to 512 tokens, and therefore, they struggle with long document classification problems. In this research, we explore on employing Model Fusing for long document classification while comparing the results with well-known BERT and Longformer architectures.
    
[^22]: SR-GAN模型的比较分析

    A comparative analysis of SR-GAN models. (arXiv:2307.09456v1 [cs.CV])

    [http://arxiv.org/abs/2307.09456](http://arxiv.org/abs/2307.09456)

    本研究比较分析了多个最先进的SR-GAN模型，结果发现EDSR模型在保持视觉质量的同时显著提高了输入图像的分辨率，具有较高的PSNR和SSIM值，并且返回高质量的OCR结果，这表明EDSR是一种有效的超分辨率方法。

    

    在这项研究中，我们评估了多个最先进的超分辨率生成对抗网络（SR GAN）模型，包括ESRGAN，Real-ESRGAN和EDSR，在一个标准数据集上以及经过降级处理的真实世界图像上的性能。我们的结果表明，一些模型似乎在保持视觉质量的同时显著提高了输入图像的分辨率，这是通过使用Tesseract OCR引擎评估的。我们观察到，来自huggingface的EDSR-BASE模型在定量指标和主观视觉质量评估方面表现优于其余候选模型，并且计算开销最小。具体而言，EDSR生成具有较高峰值信噪比（PSNR）和结构相似性指数（SSIM）值的图像，并在Tesseract OCR引擎下返回高质量的OCR结果。这些发现表明，EDSR是一种稳健有效的单图像超分辨率方法，特别适合于需要OCR的应用场景。

    In this study, we evaluate the performance of multiple state-of-the-art SR GAN (Super Resolution Generative Adversarial Network) models, ESRGAN, Real-ESRGAN and EDSR, on a benchmark dataset of real-world images which undergo degradation using a pipeline. Our results show that some models seem to significantly increase the resolution of the input images while preserving their visual quality, this is assessed using Tesseract OCR engine. We observe that EDSR-BASE model from huggingface outperforms the remaining candidate models in terms of both quantitative metrics and subjective visual quality assessments with least compute overhead. Specifically, EDSR generates images with higher peak signal-to-noise ratio (PSNR) and structural similarity index (SSIM) values and are seen to return high quality OCR results with Tesseract OCR engine. These findings suggest that EDSR is a robust and effective approach for single-image super-resolution and may be particularly well-suited for applications wh
    
[^23]: 基于预训练变换器的伪异常暴露法用于检测未知分布

    Pseudo Outlier Exposure for Out-of-Distribution Detection using Pretrained Transformers. (arXiv:2307.09455v1 [cs.CL])

    [http://arxiv.org/abs/2307.09455](http://arxiv.org/abs/2307.09455)

    本文提出了一种名为伪异常暴露（POE）的简单而有效的方法，通过顺序屏蔽与内分布类相关的令牌构建替代的外分布数据集，用于检测未知分布的样本。

    

    对于现实世界的语言应用，检测未知分布的样本有助于提醒用户或拒绝不可靠的样本。然而，现代过参数化的语言模型通常会对内分布和外分布样本都产生过度自信的预测。特别是，语言模型在与内分布样本具有相似语义表示的外分布样本上表现不佳，因为这些外分布样本位于内分布流形附近。可以通过使用内分布和多样的异常样本训练拒绝网络来检测测试的外分布样本，但明确收集辅助的外分布数据集会增加数据收集的负担。在本文中，我们提出了一种简单而有效的方法，称为伪异常暴露（POE），通过顺序屏蔽与内分布类相关的令牌来构建一个替代的外分布数据集。POE引入的替代外分布样本显示出与内部数据类似的表示，这对于训练拒绝网络最有效。我们的方法不需要任何

    For real-world language applications, detecting an out-of-distribution (OOD) sample is helpful to alert users or reject such unreliable samples. However, modern over-parameterized language models often produce overconfident predictions for both in-distribution (ID) and OOD samples. In particular, language models suffer from OOD samples with a similar semantic representation to ID samples since these OOD samples lie near the ID manifold. A rejection network can be trained with ID and diverse outlier samples to detect test OOD samples, but explicitly collecting auxiliary OOD datasets brings an additional burden for data collection. In this paper, we propose a simple but effective method called Pseudo Outlier Exposure (POE) that constructs a surrogate OOD dataset by sequentially masking tokens related to ID classes. The surrogate OOD sample introduced by POE shows a similar representation to ID data, which is most effective in training a rejection network. Our method does not require any 
    
[^24]: 让我们来ViCE！在图像生成评估中模拟人类认知行为

    Let's ViCE! Mimicking Human Cognitive Behavior in Image Generation Evaluation. (arXiv:2307.09416v1 [cs.CV])

    [http://arxiv.org/abs/2307.09416](http://arxiv.org/abs/2307.09416)

    本文介绍了一种新颖的自动化方法ViCE，通过结合大型语言模型和视觉问答，模拟人类认知过程来评估生成图像与提示之间的一致性和质量。

    

    近年来，在图像生成领域取得了重要进展，尤其是在引入了能够根据文字输入产生高质量视觉内容的视觉语言模型的推动下。尽管在生成质量和逼真度方面不断取得进展，但目前尚未定义系统性的框架来定量衡量生成内容的质量和与提示要求的一致性：到目前为止，只有基于人类的评估被用于质量满意度和比较不同的生成方法。我们引入了一种新颖的自动化方法来进行视觉概念评估（ViCE），即评估生成/编辑的图像与相应提示/指令之间的一致性，这一过程受到人类认知行为的启发。ViCE将大型语言模型（LLMs）和视觉问答（VQA）的优势结合到一个统一的流程中，旨在复制人类认知过程中的质量评估。

    Research in Image Generation has recently made significant progress, particularly boosted by the introduction of Vision-Language models which are able to produce high-quality visual content based on textual inputs. Despite ongoing advancements in terms of generation quality and realism, no methodical frameworks have been defined yet to quantitatively measure the quality of the generated content and the adherence with the prompted requests: so far, only human-based evaluations have been adopted for quality satisfaction and for comparing different generative methods. We introduce a novel automated method for Visual Concept Evaluation (ViCE), i.e. to assess consistency between a generated/edited image and the corresponding prompt/instructions, with a process inspired by the human cognitive behaviour. ViCE combines the strengths of Large Language Models (LLMs) and Visual Question Answering (VQA) into a unified pipeline, aiming to replicate the human cognitive process in quality assessment.
    
[^25]: Llama 2: 开放基础和优化聊天模型

    Llama 2: Open Foundation and Fine-Tuned Chat Models. (arXiv:2307.09288v1 [cs.CL])

    [http://arxiv.org/abs/2307.09288](http://arxiv.org/abs/2307.09288)

    Llama 2是一个优化的聊天模型，通过fine-tuned技术和安全改进，表现优于开源模型，并可作为闭源模型的替代选择。

    

    在这项工作中，我们开发并发布了Llama 2，一个包含预训练和优化的大型语言模型（LLM），其规模从70亿到700亿参数不等。我们的优化LLM，称为Llama 2-Chat，在对话使用案例中表现优于开源聊天模型。根据我们对有用性和安全性的人工评估结果，它们可能是闭源模型的合适替代品。我们详细描述了我们在Llama 2-Chat的优化和安全性改进方面的方法，以便让社区能够在我们的工作基础上构建并为LLM的负责任发展做出贡献。

    In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our models outperform open-source chat models on most benchmarks we tested, and based on our human evaluations for helpfulness and safety, may be a suitable substitute for closed-source models. We provide a detailed description of our approach to fine-tuning and safety improvements of Llama 2-Chat in order to enable the community to build on our work and contribute to the responsible development of LLMs.
    
[^26]: Retentive Network: 作为大型语言模型的Transformer的继任者

    Retentive Network: A Successor to Transformer for Large Language Models. (arXiv:2307.08621v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.08621](http://arxiv.org/abs/2307.08621)

    Retentive Network（RetNet）作为大型语言模型的基础架构，实现了训练并行、低成本推理和良好的性能。通过并行、循环和分块循环三种计算范式，RetNet具有训练并行化、低成本推理和高效的长序列建模的特点。

    

    在这项工作中，我们提出了Retentive Network (RetNet)作为大型语言模型的基础架构，同时实现了训练并行、低成本推理和良好的性能。我们从理论上推导出了循环和注意力之间的连接。然后，我们提出了序列建模的保留机制，支持三种计算范式，即并行、循环和分块循环。具体而言，并行表示允许进行训练并行化。循环表示能够实现低成本的$O(1)$推理，从而提高解码吞吐量、延迟和GPU内存，同时不损失性能。分块循环表示便于使用线性复杂度进行高效的长序列建模，其中每个块可以并行编码，同时进行循环摘要。语言建模实验结果表明，RetNet实现了良好的扩展结果、并行训练、低成本部署和高效的推理。

    In this work, we propose Retentive Network (RetNet) as a foundation architecture for large language models, simultaneously achieving training parallelism, low-cost inference, and good performance. We theoretically derive the connection between recurrence and attention. Then we propose the retention mechanism for sequence modeling, which supports three computation paradigms, i.e., parallel, recurrent, and chunkwise recurrent. Specifically, the parallel representation allows for training parallelism. The recurrent representation enables low-cost $O(1)$ inference, which improves decoding throughput, latency, and GPU memory without sacrificing performance. The chunkwise recurrent representation facilitates efficient long-sequence modeling with linear complexity, where each chunk is encoded parallelly while recurrently summarizing the chunks. Experimental results on language modeling show that RetNet achieves favorable scaling results, parallel training, low-cost deployment, and efficient i
    
[^27]: 用于超出分布可泛化性的大型视觉语言模型压缩

    Distilling Large Vision-Language Model with Out-of-Distribution Generalizability. (arXiv:2307.03135v1 [cs.CV])

    [http://arxiv.org/abs/2307.03135](http://arxiv.org/abs/2307.03135)

    本文研究了针对大型视觉语言模型的模型压缩方法，将教师模型的视觉表示压缩到学生模型中。研究重点在于超出分布可泛化的问题，并提出了两个原则来增强学生模型的性能。

    

    大型视觉语言模型取得了出色的性能，但其规模和计算要求使它们在资源受限设备和时间敏感任务上的部署变得不切实际。模型压缩是创建更小、更快的模型以保持较大模型性能的有希望的方法。本文研究了将大型视觉语言模型中的视觉表示压缩到轻量级学生模型中的过程，使用小型或中型数据集。值得注意的是，本研究关注的是超出分布（OOD）可泛化的开放词汇问题，这在以往的模型压缩研究中被忽视了。我们从视觉和语言的角度提出了两个原则来增强学生模型的OOD可泛化性：（1）更好地模仿教师的视觉表示空间，并在视觉语言对齐方面谨慎地促进更好的一致性；（2）通过丰富学生模型的自举学习和数据扩充来提高OOD可泛化性。

    Large vision-language models have achieved outstanding performance, but their size and computational requirements make their deployment on resource-constrained devices and time-sensitive tasks impractical. Model distillation, the process of creating smaller, faster models that maintain the performance of larger models, is a promising direction towards the solution. This paper investigates the distillation of visual representations in large teacher vision-language models into lightweight student models using a smallor mid-scale dataset. Notably, this study focuses on open-vocabulary out-of-distribution (OOD) generalization, a challenging problem that has been overlooked in previous model distillation literature. We propose two principles from vision and language modality perspectives to enhance student's OOD generalization: (1) by better imitating teacher's visual representation space, and carefully promoting better coherence in vision-language alignment with the teacher; (2) by enric
    
[^28]: LongNet: 将Transformer扩展到10亿个标记

    LongNet: Scaling Transformers to 1,000,000,000 Tokens. (arXiv:2307.02486v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.02486](http://arxiv.org/abs/2307.02486)

    LongNet是一种可以扩展到10亿个标记的Transformer变体，通过扩张注意力解决了序列长度受限的问题，具有线性计算复杂度和对数依赖关系，可以作为分布式训练器使用并无缝集成到现有的Transformer优化中。实验证明LongNet在长序列和短序列上性能强大。

    

    在大语言模型的时代，扩展序列长度已经成为一个关键需求。然而，现有的方法在计算复杂度或模型表达力上存在困难，导致序列长度受限。为了解决这个问题，我们引入了LongNet，它是一种Transformer的变体，可以将序列长度扩展到10亿个标记以上，而不会牺牲对较短序列的性能。具体而言，我们提出了扩张注意力，随着距离的增大，它将注意范围指数级扩展。LongNet具有显著的优势：1）它具有线性计算复杂度和序列中任意两个标记之间的对数依赖关系；2）它可以作为用于极长序列的分布式训练器；3）它的扩张注意力是标准注意力的即插即用替代品，可以与现有的基于Transformer的优化无缝集成。实验证明LongNet在长序列和短序列上都具有强大的性能。

    Scaling sequence length has become a critical demand in the era of large language models. However, existing methods struggle with either computational complexity or model expressivity, rendering the maximum sequence length restricted. To address this issue, we introduce LongNet, a Transformer variant that can scale sequence length to more than 1 billion tokens, without sacrificing the performance on shorter sequences. Specifically, we propose dilated attention, which expands the attentive field exponentially as the distance grows. LongNet has significant advantages: 1) it has a linear computation complexity and a logarithm dependency between any two tokens in a sequence; 2) it can be served as a distributed trainer for extremely long sequences; 3) its dilated attention is a drop-in replacement for standard attention, which can be seamlessly integrated with the existing Transformer-based optimization. Experiments results demonstrate that LongNet yields strong performance on both long-se
    
[^29]: 迭代分段仿射插值（IPA）逼近于语言建模的应用

    Iterated Piecewise Affine (IPA) Approximation for Language Modeling. (arXiv:2306.12317v1 [cs.CL])

    [http://arxiv.org/abs/2306.12317](http://arxiv.org/abs/2306.12317)

    迭代分段仿射插值（IPA）逼近法可以用于语言建模，与变压器解码器架构类似，并在交叉熵损失下的小序列长度下优于变压器1.5％。

    

    本文介绍了一种简单的一阶泰勒展开法来逼近一个通用的函数F: R^{n x m} -> R^{n x m} 并将其应用于语言建模。为了增强基本的泰勒展开，我们引入了迭代和分段建模，从而命名算法为迭代分段仿射插值（IPA）逼近。最终算法表现出与变压器解码器架构相似的有趣特征。通过比较IPA和变压器的参数，我们观察到在较小的序列长度下，IPA在下一个令牌预测任务中使用交叉熵损失比变压器高1.5％。

    In this work, we demonstrate the application of a simple first-order Taylor expansion to approximate a generic function $F: R^{n \times m} \to R^{n \times m}$ and utilize it in language modeling. To enhance the basic Taylor expansion, we introduce iteration and piecewise modeling, leading us to name the algorithm the Iterative Piecewise Affine (IPA) approximation. The final algorithm exhibits interesting resemblances to the Transformers decoder architecture. By comparing parameter arrangements in IPA and Transformers, we observe a strikingly similar performance, with IPA outperforming Transformers by 1.5\% in the next token prediction task with cross-entropy loss for smaller sequence lengths.
    
[^30]: GEmo-CLAP: 面向语音情感识别的性别属性增强对比语音-语言预训练模型

    GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio Pretraining for Speech Emotion Recognition. (arXiv:2306.07848v1 [cs.CL])

    [http://arxiv.org/abs/2306.07848](http://arxiv.org/abs/2306.07848)

    本文提出了GEmo-CLAP模型用于语音情感识别，结合了性别属性信息，相比于其他先进方法，该模型在IEMOCAP上实现了更优越的识别性能。

    

    对比语音-语言预训练（CLAP）最近在不同领域取得了惊人的成功。本文提出了一种名为GEmo-CLAP的高效性别属性增强CLAP模型，用于语音情感识别（SER）。具体而言，我们首先利用各种自监督学习的预训练模型构建了一种有效的情感CLAP模型（称为Emo-CLAP），用于SER。然后，考虑到在语音情感建模中性别属性的重要性，我们进一步提出了两种GEmo-CLAP方法，来整合语音信号的情感和性别信息，形成更合理的目标。在IEMOCAP语料库上进行的大量实验表明，我们提出的两种GEmo-CLAP方法始终优于基线Emo-CLAP模型（使用不同的预训练模型），同时与其他最先进的方法相比实现了更优越的识别性能。

    Contrastive Language-Audio Pretraining (CLAP) has recently exhibited impressive success in diverse fields. In this paper, we propose GEmo-CLAP, a kind of efficient gender-attribute-enhanced CLAP model for speech emotion recognition (SER). Specifically, we first build an effective emotion CLAP model termed Emo-CLAP for SER, utilizing various self-supervised learning based pre-trained models. Then, considering the importance of the gender attribute in speech emotion modeling, two GEmo-CLAP approaches are further proposed to integrate the emotion and gender information of speech signals, forming more reasonable objectives. Extensive experiments conducted on the IEMOCAP corpus demonstrate that our proposed two GEmo-CLAP approaches consistently outperform the baseline Emo-CLAP with different pre-trained models, while also achieving superior recognition performance compared with other state-of-the-art methods.
    
[^31]: ChatGPT在文本标注任务中表现优于众包工作者

    ChatGPT Outperforms Crowd-Workers for Text-Annotation Tasks. (arXiv:2303.15056v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.15056](http://arxiv.org/abs/2303.15056)

    ChatGPT在文本标注任务中表现优于众包工作者，包括相关性、态度、主题和框架检测任务。ChatGPT的零样本准确率超越众包工作者四个任务，编码者间一致性在所有任务中均超过众包工作者和受过训练的注释者。此外，ChatGPT的标注成本比MTurk便宜20倍左右，显示了大型语言模型提高文本分类效率的潜力。

    

    许多自然语言处理应用需要手动进行数据标注以进行各种任务，特别是用于训练分类器或评估无监督模型的性能。根据任务的规模和复杂程度，这些任务可以由众包工作者在MTurk等平台上进行，也可以由受过训练的注释者（如研究助理）进行。通过使用2382条推文的样本，我们证明了ChatGPT在多个标注任务中的表现优于众包工作者，包括相关性、态度、主题和框架检测。具体而言，ChatGPT的零样本准确率在五个任务中有四个超过了众包工作者，而ChatGPT的编码者间一致性在所有任务中均超过了众包工作者和受过训练的注释者。此外，ChatGPT的标注成本不到0.003美元，比MTurk便宜20倍左右。这些结果显示了大型语言模型极大地提高了文本分类的效率的潜力。

    Many NLP applications require manual data annotations for a variety of tasks, notably to train classifiers or evaluate the performance of unsupervised models. Depending on the size and degree of complexity, the tasks may be conducted by crowd-workers on platforms such as MTurk as well as trained annotators, such as research assistants. Using a sample of 2,382 tweets, we demonstrate that ChatGPT outperforms crowd-workers for several annotation tasks, including relevance, stance, topics, and frames detection. Specifically, the zero-shot accuracy of ChatGPT exceeds that of crowd-workers for four out of five tasks, while ChatGPT's intercoder agreement exceeds that of both crowd-workers and trained annotators for all tasks. Moreover, the per-annotation cost of ChatGPT is less than $0.003 -- about twenty times cheaper than MTurk. These results show the potential of large language models to drastically increase the efficiency of text classification.
    
[^32]: 利用上下文化的大型语言模型理解法律文件

    Understand Legal Documents with Contextualized Large Language Models. (arXiv:2303.12135v1 [cs.CL])

    [http://arxiv.org/abs/2303.12135](http://arxiv.org/abs/2303.12135)

    本文介绍了针对 SemEval-2023 任务 6 开发的 Legal-BERT-HSLN 模型和 Legal-LUKE 模型，其中 Legal-BERT-HSLN 模型通过考虑句内和句间的上下文信息以预测修辞角色，Legal-LUKE 模型是具有法律上下文和实体知识的模型，以识别法律实体。模型相比基线模型更准确，能够解决在人口众多的国家处理法律文件的问题。

    

    在人口众多的国家，如印度，待处理的法律案件数量不断增加，这已成为一个重大问题。因此，开发有效的技术来处理和理解法律文件将非常有用。在本文中，我们介绍了我们针对 SemEval-2023 任务 6（Modi 等人，2023）所开发的理解法律文本系统。具体来说，我们首先开发了 Legal-BERT-HSLN 模型，该模型考虑了句内和句间的综合上下文信息，以预测修辞角色（子任务 A），然后训练出 Legal-LUKE 模型，该模型具有法律上下文化和实体感知能力，以识别法律实体（子任务 B）。我们的评估表明，我们设计的模型比基线模型更准确，如在子任务 B 中 F1 值提高了达 15.0%。我们在任务排行榜上取得了显著的表现，如 0.834 微平均 F1 值，并在子任务 A 中排名第 5。

    The growth of pending legal cases in populous countries, such as India, has become a major issue. Developing effective techniques to process and understand legal documents is extremely useful in resolving this problem. In this paper, we present our systems for SemEval-2023 Task 6: understanding legal texts (Modi et al., 2023). Specifically, we first develop the Legal-BERT-HSLN model that considers the comprehensive context information in both intra- and inter-sentence levels to predict rhetorical roles (subtask A) and then train a Legal-LUKE model, which is legal-contextualized and entity-aware, to recognize legal entities (subtask B). Our evaluations demonstrate that our designed models are more accurate than baselines, e.g., with an up to 15.0% better F1 score in subtask B. We achieved notable performance in the task leaderboard, e.g., 0.834 micro F1 score, and ranked No.5 out of 27 teams in subtask A.
    
[^33]: ThoughtSource:一个用于大型语言模型推理数据的中央枢纽。

    ThoughtSource: A central hub for large language model reasoning data. (arXiv:2301.11596v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.11596](http://arxiv.org/abs/2301.11596)

    ThoughtSource是一个用于连续思考推理的元数据集和软件库，旨在通过促进对连续思考的定性理解、实证评估和提供训练数据，改进未来的人工智能系统。

    

    最近，像GPT-4这样的大型语言模型在多个任务上展示了令人印象深刻的结果。然而，这些语言模型在复杂推理上仍存在限制，它们的推理过程不透明，容易产生“幻觉”事实，并且存在其潜在偏见的担忧。最近提出了一种称为连续思考提示的技术，让模型以自然语言形式表达推理步骤，以解决这些问题。在这里，我们介绍了ThoughtSource，一个用于连续思考推理的元数据集和软件库。ThoughtSource的目标是通过促进对连续思考的定性理解、实证评估和提供训练数据来改进未来的人工智能系统。ThoughtSource的首次发布集成了六个科学/医学、三个通用领域和五个数学题答案数据集。

    Large language models (LLMs) such as GPT-4 have recently demonstrated impressive results across a wide range of tasks. LLMs are still limited, however, in that they frequently fail at complex reasoning, their reasoning processes are opaque, they are prone to 'hallucinate' facts, and there are concerns about their underlying biases. Letting models verbalize reasoning steps as natural language, a technique known as chain-of-thought prompting, has recently been proposed as a way to address some of these issues. Here we present ThoughtSource, a meta-dataset and software library for chain-of-thought (CoT) reasoning. The goal of ThoughtSource is to improve future artificial intelligence systems by facilitating qualitative understanding of CoTs, enabling empirical evaluations, and providing training data. This first release of ThoughtSource integrates six scientific/medical, three general-domain and five math word question answering datasets.
    
[^34]: Lego-MT: 走向可拆卸的高度多语言机器翻译模型

    Lego-MT: Towards Detachable Models in Massively Multilingual Machine Translation. (arXiv:2212.10551v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10551](http://arxiv.org/abs/2212.10551)

    本文提出了一种可拆卸的多语言机器翻译模型，Lego-MT，以解决现有多语言单体模型在参数干扰和低效推导方面的挑战。进行实验评估表明，该模型具有较高的性能，相比具有10倍规模的模型，在效率和表现方面都更具优势。

    

    多语言神经机器翻译(MNMT)旨在构建一个适用于多个语言方向的统一模型。现有的MNMT单体模型面临两个挑战:语言之间的参数干扰和大型模型的低效推理。本文重新审视了经典的多路径结构，通过将每种语言(或语言组)分配给支持即插即用训练和推理的单独分支，开发出可拆卸模型。为了满足在统一空间中为所有语言学习表示的需要，我们提出了一种新颖的高效训练配方，以此构建一个有效的可拆卸模型，Lego-MT。为了进行公正的比较，我们从OPUS收集数据，构建了一个包括433种语言和13亿个平行数据的翻译基准。实验表明，参数为12亿的Lego-MT带来了3.2个spBLEU的平均增益。它甚至胜过了参数为120亿的M2M-100。所提出的训练配方比并行训练提速了28.2倍。

    Multilingual neural machine translation (MNMT) aims to build a unified model for many language directions. Existing monolithic models for MNMT encounter two challenges: parameter interference among languages and inefficient inference for large models. In this paper, we revisit the classic multi-way structures and develop a detachable model by assigning each language (or group of languages) to an individual branch that supports plug-and-play training and inference. To address the needs of learning representations for all languages in a unified space, we propose a novel efficient training recipe, upon which we build an effective detachable model, Lego-MT. For a fair comparison, we collect data from OPUS and build a translation benchmark covering 433 languages and 1.3B parallel data. Experiments show that Lego-MT with 1.2B parameters brings an average gain of 3.2 spBLEU. It even outperforms M2M-100 with 12B parameters. The proposed training recipe brings a 28.2$\times$ speedup over the co
    
[^35]: 在场学习者能否从演示中学习推理概念？

    Can In-context Learners Learn a Reasoning Concept from Demonstrations?. (arXiv:2212.01692v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.01692](http://arxiv.org/abs/2212.01692)

    本文介绍了一种概念性少样本学习方法，以帮助在场学习者学习新技能。通过选择与预测示例共享可能信息的演示，这个方法可以在模型记忆独立的情况下区分模型的在场学习能力。

    

    大型语言模型展示了从少量输入-输出演示中学习新任务的新能力。然而，最近的研究表明，在场学习者大部分依赖于他们的预训练知识，如标签的情感，而不是在输入中找到新的关联性。然而，常用的少样本评估设置使用随机选择的在场演示无法区分模型从演示中学习新技能的能力，因为大部分随机选择的演示并不呈现超越暴露于新任务分布的预测的关系。为了在模型记忆独立的情况下区分模型的在场学习能力，我们引入了一个概念性少样本学习方法，选择与预测示例共享可能信息的演示。我们从注释解释中提取了一组这样的概念，并测量了模型展示这些概念可以获得多少好处。

    Large language models show an emergent ability to learn a new task from a small number of input-output demonstrations. However, recent work shows that in-context learners largely rely on their pre-trained knowledge, such as the sentiment of the labels, instead of finding new associations in the input. However, the commonly-used few-shot evaluation settings using a random selection of in-context demonstrations can not disentangle models' ability to learn a new skill from demonstrations, as most of the randomly-selected demonstrations do not present relations informative for prediction beyond exposing the new task distribution.  To disentangle models' in-context learning ability independent of models' memory, we introduce a Conceptual few-shot learning method selecting the demonstrations sharing a possibly-informative concept with the predicted sample. We extract a set of such concepts from annotated explanations and measure how much can models benefit from presenting these concepts in f
    
[^36]: 重新审视Softmax在文本分类中的不确定性近似

    Revisiting Softmax for Uncertainty Approximation in Text Classification. (arXiv:2210.14037v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.14037](http://arxiv.org/abs/2210.14037)

    本研究重新审视了Softmax在文本分类中的不确定性近似方法，并比较了基于MC Dropout的方法。实证分析发现，尽管MC dropout产生了最好的不确定性近似，但使用softmax也能产生相对准确的结果。

    

    文本分类中的不确定性近似是一个在领域适应和可解释性中应用广泛的重要领域。其中一种最常用的不确定性近似方法是蒙特卡罗（MC）Dropout，但由于需要多次前向传递，计算成本较高。相比之下，一种更便宜的方法是仅使用在单次前向传递中基于softmax的方法来估计模型的不确定性。然而，之前的研究表明，这种预测往往过于自信。本文通过在两种基本神经结构的五个数据集上进行彻底的实证分析，旨在探讨这两种方法之间的权衡。我们比较了softmax和MC Dropout的不确定性近似以及下游文本分类性能，同时比较了它们的运行时间（成本）和性能（效益）。我们发现，尽管MC dropout产生了最好的不确定性近似，但使用softmax也能产生相对准确的结果。

    Uncertainty approximation in text classification is an important area with applications in domain adaptation and interpretability. One of the most widely used uncertainty approximation methods is Monte Carlo (MC) Dropout, which is computationally expensive as it requires multiple forward passes through the model. A cheaper alternative is to simply use the softmax based on a single forward pass without dropout to estimate model uncertainty. However, prior work has indicated that these predictions tend to be overconfident. In this paper, we perform a thorough empirical analysis of these methods on five datasets with two base neural architectures in order to identify the trade-offs between the two. We compare both softmax and an efficient version of MC Dropout on their uncertainty approximations and downstream text classification performance, while weighing their runtime (cost) against performance (benefit). We find that, while MC dropout produces the best uncertainty approximations, usin
    

