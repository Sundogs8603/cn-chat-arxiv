# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [ParaGuide: Guided Diffusion Paraphrasers for Plug-and-Play Textual Style Transfer.](http://arxiv.org/abs/2308.15459) | ParaGuide是一种用于通用风格转移的引导性扩散改写器，可以灵活适应任意目标风格，通过梯度引导和改写条件的扩散模型实现文本的风格转变，同时保留语义信息。 |
| [^2] | [When Do Program-of-Thoughts Work for Reasoning?.](http://arxiv.org/abs/2308.15452) | 提出了复杂性影响推理分数（CIRS）来衡量编程语言对推理能力的影响，发现并非所有复杂性的代码数据都可以被学习或理解，适当的复杂性水平对于改善推理能力至关重要。 |
| [^3] | [Vulgar Remarks Detection in Chittagonian Dialect of Bangla.](http://arxiv.org/abs/2308.15448) | 这篇论文的研究重点是利用有监督的机器学习和深度学习算法在社交媒体中检测恰塔根语言方言中的粗俗言论，并发现逻辑回归取得了较高的准确率（0.91）。 |
| [^4] | [Characterizing Learning Curves During Language Model Pre-Training: Learning, Forgetting, and Stability.](http://arxiv.org/abs/2308.15419) | 本研究通过从五个英语语言模型预训练运行中提取学习曲线，揭示了语言模型在预训练期间的学习过程。结果表明，语言模型在学习生成更长、更连贯的文本之前，会生成短而重复的短语。同时，频繁出现的标记在预训练过程中更早学习，具有更小的变异性，并且很少被遗忘。较短、更频繁的上下文与稳定和快速获得的预测有关。词类的影响较小，但名词倾向于较晚获得且遗忘率较低。 |
| [^5] | [Rethinking Machine Ethics -- Can LLMs Perform Moral Reasoning through the Lens of Moral Theories?.](http://arxiv.org/abs/2308.15399) | 本研究提出了一个灵活的框架，引导大型语言模型根据跨学科研究中建立的道德理论进行道德推理，解决了现有方法面临的问题。 |
| [^6] | [Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation.](http://arxiv.org/abs/2308.15363) | 本文提出了一个大规模语言模型(LLMs)赋能的文本到SQL任务的基准评估，并基于实验结果提出了一种新的集成解决方案DAIL-SQL，刷新了Spider榜单并实现了86.6%的执行准确率。同时，强调了在提示工程中的词汇效率以实现高效经济的LLM-based文本到SQL解决方案，此外还对在上下文学习中应用开源LLMs进行了研究，并进行了任务特定的性能优化。 |
| [^7] | [Historical patterns of rice farming explain modern-day language use in China and Japan more than modernization and urbanization.](http://arxiv.org/abs/2308.15352) | 论文研究了中国和日本现代语言使用中的文化差异，发现历史上稻米种植对于社会互动和思维方式的影响比经济发展和城市化更为重要。 |
| [^8] | [A Framework for Responsible Development of Automated Student Feedback with Generative AI.](http://arxiv.org/abs/2308.15334) | 一种基于生成AI的自动学生反馈框架可以提供丰富的反馈，但引入了伦理问题，并需要解决“多数人的暴政”和忽视长尾中少数群体需求的挑战。 |
| [^9] | [TaskLAMA: Probing the Complex Task Understanding of Language Models.](http://arxiv.org/abs/2308.15299) | TaskLAMA论文研究了语言模型对复杂任务理解的能力，使用人工标注数据集和新的评估指标，实验证明LLMs能够有效地将复杂任务分解为个别步骤，并提出了进一步提升性能的方法。 |
| [^10] | [KGConv, a Conversational Corpus grounded in Wikidata.](http://arxiv.org/abs/2308.15298) | KGConv是一个基于Wikidata的大型对话语料库，每个对话都基于一个事实，并提供了多个变体的问题。它可以用于知识对话问题生成和其他相关任务。 |
| [^11] | [Enhancing OCR Performance through Post-OCR Models: Adopting Glyph Embedding for Improved Correction.](http://arxiv.org/abs/2308.15262) | 本研究通过后处理OCR模型，采用字形嵌入的方法来改进OCR性能。研究结果表明后处理能够有效解决劣质OCR模型的问题，并且字形嵌入可以提高校正结果，包括纠正个别单词。 |
| [^12] | [A Classification-Guided Approach for Adversarial Attacks against Neural Machine Translation.](http://arxiv.org/abs/2308.15246) | 本文介绍了一种基于分类引导的对抗攻击神经机器翻译的方法，通过改变整体意义生成保持语义的对抗样本，从而使得翻译结果属于不同的类别。 |
| [^13] | [PronounFlow: A Hybrid Approach for Calibrating Pronouns in Sentences.](http://arxiv.org/abs/2308.15235) | PronounFlow提出了一种混合方法来校准句子中的代词，以消除歧义。这对于使机器具备常识和推理能力具有重要意义。 |
| [^14] | [Classification-Aware Neural Topic Model Combined With Interpretable Analysis -- For Conflict Classification.](http://arxiv.org/abs/2308.15232) | 本文提出了一种结合可解释性分析的分类感知神经主题模型，用于冲突分类和主题发现。该模型提供了可靠的分类结果和发现的主题的解释，并通过优化模型的复杂度来提高分类性能。 |
| [^15] | [Multi-party Goal Tracking with LLMs: Comparing Pre-training, Fine-tuning, and Prompt Engineering.](http://arxiv.org/abs/2308.15231) | 本文评估了当前大型语言模型（LLMs）在捕捉任务导向的多方会话（MPCs）方面的能力，并比较了三种方法（预训练、微调和提示工程），结果表明在有限数据情况下，GPT-3.5-turbo通过"推理"风格的提示在少样本设置下表现最好。 |
| [^16] | [CLIPTrans: Transferring Visual Knowledge with Pre-trained Models for Multimodal Machine Translation.](http://arxiv.org/abs/2308.15226) | 本研究提出了CLIPTrans，它通过简单地适应独立预训练模型，实现了多模态机器翻译中视觉知识的转移。 |
| [^17] | [FurChat: An Embodied Conversational Agent using LLMs, Combining Open and Closed-Domain Dialogue with Facial Expressions.](http://arxiv.org/abs/2308.15214) | 本研究开发了一个交互式对话系统，将开放和封闭领域对话、脸部表情结合起来，通过使用LLMs和GPT-3.5模型来生成引人入胜的对话，以提供信息并与访客进行自然交流。 |
| [^18] | [Shared Lexical Items as Triggers of Code Switching.](http://arxiv.org/abs/2308.15209) | 该研究通过使用三种语言对的五个大型数据集，对共享词汇作为代码切换的触发器进行了深入探索。结果表明，共享词汇确实会触发代码切换，切换的倾向取决于触发器与切换点的距离和位置，而不取决于触发词的词源。 |
| [^19] | [Benchmarking the Generation of Fact Checking Explanations.](http://arxiv.org/abs/2308.15202) | 本论文基于新颖数据集和先进基准，旨在解决给出声明真实性解释的问题。研究结果表明，在使用非结构化知识的摘要方法中，命题信息是有益的，并且某些抽象策略表现出色。 |
| [^20] | [Enhancing Psychological Counseling with Large Language Model: A Multifaceted Decision-Support System for Non-Professionals.](http://arxiv.org/abs/2308.15192) | 本研究基于大型语言模型构建了一个决策支持系统，可帮助非专业人员在社交媒体上提供心理咨询，从而弥补了专业咨询师短缺的问题。 |
| [^21] | [The Anatomy of Conspirators: Unveiling Traits using a Comprehensive Twitter Dataset.](http://arxiv.org/abs/2308.15154) | 本研究通过构建一种全面的Twitter数据集，揭示了参与阴谋相关活动的用户的特点和行为特征，为阴谋论的检测提供了新的方法和依据。 |
| [^22] | [Evaluation and Analysis of Hallucination in Large Vision-Language Models.](http://arxiv.org/abs/2308.15126) | 本文提出了基于大型语言模型的幻觉评估框架HaELM，可以评估大型视觉语言模型中的幻觉问题，并分析了导致幻觉的因素，并提出了缓解幻觉问题的建议。 |
| [^23] | [SpikeBERT: A Language Spikformer Trained with Two-Stage Knowledge Distillation from BERT.](http://arxiv.org/abs/2308.15122) | 该论文提出了一种名为SpikeBERT的SNN模型，通过改进Spikformer架构和使用两阶段知识蒸馏方法，该模型在语言任务上超越了其他SNN模型，在文本分类任务上甚至达到了与BERT相当的结果。 |
| [^24] | [Large Language Models on the Chessboard: A Study on ChatGPT's Formal Language Comprehension and Complex Reasoning Skills.](http://arxiv.org/abs/2308.15118) | 本研究通过在国际象棋上使用OpenAI的ChatGPT语言模型作为案例，评估了该模型在复杂推理任务中的表现。我们发现ChatGPT在正式语言理解和自我调节方面存在局限性，但在游戏中展现了一致的战略倾向和决策自信度的提升。 |
| [^25] | [Sequential annotations for naturally-occurring HRI: first insights.](http://arxiv.org/abs/2308.15097) | 这篇论文介绍了一种用于改善嵌入式对话智能体交互的方法论，并提出了一种基于语言和多模态资源使用理论基础的注释实践。 |
| [^26] | [Killing two birds with one stone: Can an audio captioning system also be used for audio-text retrieval?.](http://arxiv.org/abs/2308.15090) | 这篇论文研究了音频字幕系统和音频文本检索系统之间的关系，通过探索未经修改的音频字幕系统对音频文本检索任务的性能。研究发现，即使未进行微调，音频字幕系统在音频文本检索任务上表现出了一定的能力。 |
| [^27] | [Taxonomic Loss for Morphological Glossing of Low-Resource Languages.](http://arxiv.org/abs/2308.15055) | 本文提出了一种利用形态信息的分类损失函数，在低资源语言的形态词义标注中提高了性能。 尽管在单标签预测准确性方面不如标准损失函数，但在前n个预测标签方面表现更好。 这个方法在人机协作标注方面具有潜力。 |
| [^28] | [Adapting text-based dialogue state tracker for spoken dialogues.](http://arxiv.org/abs/2308.15053) | 这篇论文描述了对构建适应口语对话系统的文本对话状态跟踪器进行的工程工作，利用自动语音识别错误校正和文本对话系统实现了插槽和值的估计。 |
| [^29] | [Large language models converge toward human-like concept organization.](http://arxiv.org/abs/2308.15047) | 大型语言模型学会以类似于知识库的方式组织概念，这表明它们具备人类推理语义和世界知识的能力。 |
| [^30] | [Improving Neural Ranking Models with Traditional IR Methods.](http://arxiv.org/abs/2308.15027) | 本文研究了一种低成本的替代方法，通过将传统的TF-IDF和浅层嵌入模型结合使用，可以与基于大型Transformer模型的神经排名模型竞争，并可以提高这些模型在大规模任务上的性能。 |
| [^31] | [Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models.](http://arxiv.org/abs/2308.15022) | 递归总结在大型语言模型中实现长期对话记忆，可以提高对话系统在长对话中记忆重要信息的能力。 |
| [^32] | [TransPrompt v2: A Transferable Prompting Framework for Cross-task Text Classification.](http://arxiv.org/abs/2308.15010) | TransPrompt v2是一种可转移的提示框架，适用于跨任务文本分类。它通过多任务元知识获取来训练一个捕捉跨任务可转移知识的元学习器，以提升预训练语言模型在少样本学习中的性能。 |
| [^33] | [Robust Open-Set Spoken Language Identification and the CU MultiLang Dataset.](http://arxiv.org/abs/2308.14951) | 本文实现了一种鲁棒的开放集言语识别系统，通过使用MFCC和音高特征，TDNN模型提取特征嵌入，设置置信度阈值，以及使用LDA和pLDA学习新的未知语言分类来实现。在经过训练的语言上，系统准确率达到91.76%，并且具备实时适应未知语言的能力。 |
| [^34] | [Gender bias and stereotypes in Large Language Models.](http://arxiv.org/abs/2308.14921) | 研究发现大型语言模型存在性别偏见和刻板印象，它们更倾向于选择与个人性别刻板印象一致的职业，并且放大了偏见，超过了现实情况。 |
| [^35] | [Neural approaches to spoken content embedding.](http://arxiv.org/abs/2308.14905) | 该论文研究了语音内容嵌入的神经方法。传统方法限制了性能和效率，因此提出了声学词嵌入作为替代。论文提出了单视图和多视图训练损失的方法，并探讨了声学词嵌入在实际任务中的应用。 |
| [^36] | [MEMORY-VQ: Compression for Tractable Internet-Scale Memory.](http://arxiv.org/abs/2308.14903) | MEMORY-VQ是一种使用向量量化压缩方法来减少内存增强模型存储需求的新方法，不牺牲性能。应用于LUMEN模型后，LUMEN-VQ在KILT基准测试上获得了16倍的压缩率，使得对于极大的检索语料库而言实现实际的检索增强成为可能。 |
| [^37] | [Multiscale Contextual Learning for Speech Emotion Recognition in Emergency Call Center Conversations.](http://arxiv.org/abs/2308.14894) | 本文介绍了一种用于语音情绪识别的多尺度对话上下文学习方法，该方法在紧急呼叫中心对话中取得了较好的效果。通过分析对话中的情绪流动并利用上下文信息，提高了情绪识别的准确性和鲁棒性。 |
| [^38] | [CommunityFish: A Poisson-based Document Scaling With Hierarchical Clustering.](http://arxiv.org/abs/2308.14873) | 本文介绍了一种新的文本缩放方法CommunityFish，它利用层次聚类算法在词空间上聚类，从而揭示文本数据中独立词组（社区）的差异。 |
| [^39] | [Attention Visualizer Package: Revealing Word Importance for Deeper Insight into Encoder-Only Transformer Models.](http://arxiv.org/abs/2308.14850) | 这个论文介绍了Attention Visualizer包，通过可视化展示单词在编码器-只有的Transformer模型中的重要性，提高了对神经网络的解释性和可解释性。 |
| [^40] | [VoiceBank-2023: A Multi-Speaker Mandarin Speech Corpus for Constructing Personalized TTS Systems for the Speech Impaired.](http://arxiv.org/abs/2308.14763) | VoiceBank-2023是用于构建个性化中文TTS系统的多说话人普通话语音语料库，可以为语言障碍患者提供个性化服务。该语料库包括111个说普通话的说话人的29.78小时的语音数据，以及性别、语言障碍程度等信息。语料库欢迎非商业用途申请使用，支持改进VoiceBanking项目的服务。 |
| [^41] | [Challenges of GPT-3-based Conversational Agents for Healthcare.](http://arxiv.org/abs/2308.14641) | 本文研究了使用基于GPT-3的模型进行医学问答系统（MedQA）的挑战和风险。通过上下文化的分析和手动设计患者查询的压力测试，我们发现这些模型无法充分回应高风险限制，可能导致错误的医学信息、不安全的建议和冒犯性内容。 |
| [^42] | [Empowering Clinicians and Democratizing Data Science: Large Language Models Automate Machine Learning for Clinical Studies.](http://arxiv.org/abs/2308.14120) | chatGPT ADA是一种能够自主开发临床研究所需的最先进的机器学习模型的大型语言模型，可将高级分析工具民主化，使非数据科学家的临床医生能够轻松应用于医学领域。 |
| [^43] | [Beyond Document Page Classification: Design, Datasets, and Challenges.](http://arxiv.org/abs/2308.12896) | 本文强调了将文档分类基准测试更接近于现实世界应用的需求，通过提出多页文档分类数据集和不同分类任务，以及高效的多页文档表示，来解决现有基准测试不适用于实际完整文档评估的问题。 |
| [^44] | [Cross-Lingual Constituency Parsing for Middle High German: A Delexicalized Approach.](http://arxiv.org/abs/2308.04645) | 本研究通过利用中古高地德语和现代德语的语言连续性和结构相似性，以及现有的现代德语树库资源，构建了一种适用于中古高地德语的短语结构分析器，无需依赖标注的MHG树库资源。 |
| [^45] | [NBIAS: A Natural Language Processing Framework for Bias Identification in Text.](http://arxiv.org/abs/2308.01681) | 本论文提出了一个名为NBIAS的自然语言处理框架，旨在识别文本中的偏见。通过收集来自社交媒体、医疗保健和职位招聘等领域的多样化数据构建数据集，并应用基于Transformer的令牌分类模型来识别偏见词/短语。通过定量和定性评估方法来评估模型的效果。 |
| [^46] | [Unveiling Gender Bias in Terms of Profession Across LLMs: Analyzing and Addressing Sociological Implications.](http://arxiv.org/abs/2307.09162) | 本研究分析了大型语言模型中的性别偏见，以GPT-2和GPT-3.5为例，通过全面的文献综述和深入的定量分析揭示了存在的性别化词语关联、语言使用和偏见叙述，并探讨了性别偏见可能对社会认知产生的伦理影响。 |
| [^47] | [Political Sentiment Analysis of Persian Tweets Using CNN-LSTM Model.](http://arxiv.org/abs/2307.07740) | 本论文使用CNN-LSTM模型对波斯推特的政治情感进行分析，使用ParsBERT进行词汇表示，并比较了机器学习和深度学习模型的效果。实验结果表明，深度学习模型表现更好，其中CNN-LSTM模型在两个数据集上分别达到了89%和71%的分类准确率。 |
| [^48] | [Large Language Models are Fixated by Red Herrings: Exploring Creative Problem Solving and Einstellung Effect using the Only Connect Wall Dataset.](http://arxiv.org/abs/2306.11167) | 这项研究探索了大型语言模型（LLMs）对创造性问题解决的能力，并发现大型语言模型容易被误导，出现固定效应和Einstellung范式。 |
| [^49] | [Block-State Transformer.](http://arxiv.org/abs/2306.09539) | 本文提出了一种名为块状态变换器（BST）的混合神经网络层，结合了状态空间模型和块变换器，旨在在语言建模任务中提高性能和可扩展性。实验证明，该模型在语言建模困惑度上优于类似的基于Transformer的架构，并且可以推广到更长的序列。此外，在层级别上具有超过十倍的速度提升。 |
| [^50] | [Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models.](http://arxiv.org/abs/2306.08018) | Mol-Instructions是一个专门为生物分子领域设计的综合指令数据集，可以显著提高大语言模型在生物领域中的适应能力和认知敏锐度。 |
| [^51] | [When Do Annotator Demographics Matter? Measuring the Influence of Annotator Demographics with the POPQUORN Dataset.](http://arxiv.org/abs/2306.06826) | 标注者的背景对数据标注的影响很重要。通过POPQUORN数据集的分析，我们发现标注者的背景在他们的判断中起到了显著作用，并且应该考虑以前未考虑的背景因素。我们的研究建议理解标注者的背景，从具有人口统计学平衡的众包工作者中收集标签，以减少数据集的偏差。 |
| [^52] | [Blockwise Parallel Transformer for Long Context Large Models.](http://arxiv.org/abs/2305.19370) | 本文提出了块级并行Transformer方法，以最小化内存成本，能够处理长序列，并且可以处理比先前的内存高效方法更长32倍的训练序列。 |
| [^53] | [Scissorhands: Exploiting the Persistence of Importance Hypothesis for LLM KV Cache Compression at Test Time.](http://arxiv.org/abs/2305.17118) | Scissorhands是一个可以在不对模型进行微调的情况下，通过利用重要性持久性假设将LLM KV缓存的内存使用维持在固定预算内的系统。 |
| [^54] | [A Trip Towards Fairness: Bias and De-Biasing in Large Language Models.](http://arxiv.org/abs/2305.13862) | 本文研究大型语言模型中的偏见问题，并提出了一种去偏差技术以产生在下游任务中表现良好的健壮去偏差模型。 |
| [^55] | [a unified front-end framework for english text-to-speech synthesis.](http://arxiv.org/abs/2305.10666) | 该论文提出了一个统一的前端框架，捕捉了英文语音合成前端模块之间的依赖关系，并且在所有模块中均取得了最先进的性能。 |
| [^56] | [Asymmetric feature interaction for interpreting model predictions.](http://arxiv.org/abs/2305.07224) | 本文提出了一种解释模型，能够探索深度神经自然语言处理模型推理中的非对称高阶特征交互。在两个情感分类数据集上的实验结果表明，该模型在识别影响特征方面优于现有特征交互归因方法。 |
| [^57] | [OLISIA: a Cascade System for Spoken Dialogue State Tracking.](http://arxiv.org/abs/2304.11073) | 我们提出了OLISIA，一个口语对话状态跟踪的级联系统，使用自动语音识别和DST模型，采用几个适应性策略来提高稳健性，并在DSTC11 Track3中取得第一名的好成绩。 |
| [^58] | [On the Robustness of ChatGPT: An Adversarial and Out-of-distribution Perspective.](http://arxiv.org/abs/2302.12095) | 本研究评估了ChatGPT的鲁棒性，发现其在对抗性和超出分布任务上有一致的优势，但绝对表现仍有提高空间，鲁棒性仍是一个重要的挑战。 |
| [^59] | [Theory of Mind May Have Spontaneously Emerged in Large Language Models.](http://arxiv.org/abs/2302.02083) | “通过测试多个语言模型在解决40个ToM任务上的表现，研究发现GPT-3和GPT-4能够解决大部分任务，说明类似ToM的能力可能是语言模型自发出现的附带产物。” |
| [^60] | [A Deep Convolutional Neural Networks Based Multi-Task Ensemble Model for Aspect and Polarity Classification in Persian Reviews.](http://arxiv.org/abs/2201.06313) | 本论文介绍了一种基于深度卷积神经网络的多任务集成模型，用于在波斯语评论中进行方面和极性分类。该模型能够同时检测方面类别和方面类别极性，通过结合多个模型进行集成学习，可以提高预测效果并减少错误。 |
| [^61] | [An Empirical Investigation of the Role of Pre-training in Lifelong Learning.](http://arxiv.org/abs/2112.09153) | 这项研究通过对大型预训练模型在多个任务上的性能评估，发现通用的前期训练可以在终身学习中减轻灾难性遗忘的影响。 |

# 详细

[^1]: ParaGuide: 用于即插即用文本风格转移的引导性扩散改写器

    ParaGuide: Guided Diffusion Paraphrasers for Plug-and-Play Textual Style Transfer. (arXiv:2308.15459v1 [cs.CL])

    [http://arxiv.org/abs/2308.15459](http://arxiv.org/abs/2308.15459)

    ParaGuide是一种用于通用风格转移的引导性扩散改写器，可以灵活适应任意目标风格，通过梯度引导和改写条件的扩散模型实现文本的风格转变，同时保留语义信息。

    

    文本风格转移是在保留意义的同时转变文本的风格属性的任务。目标风格可以以多种方式定义，从单一属性（例如正式性）到作者（例如莎士比亚）。先前的无监督风格转移方法通常依赖于大量标记数据，仅适用于固定的风格集，或需要大型语言模型。相反，我们引入了一种新的基于扩散的通用风格转移框架，可以在推理时灵活适应任意目标风格。我们的参数高效方法ParaGuide利用了改写条件的扩散模型以及来自现成的分类器和强大的风格嵌入器的梯度引导，以转变文本的风格同时保留语义信息。我们在Enron邮件语料库上进行了验证，包括人工和自动评估，并发现其在正式性和... (内容太多，请参考英文摘要)

    Textual style transfer is the task of transforming stylistic properties of text while preserving meaning. Target "styles" can be defined in numerous ways, ranging from single attributes (e.g, formality) to authorship (e.g, Shakespeare). Previous unsupervised style-transfer approaches generally rely on significant amounts of labeled data for only a fixed set of styles or require large language models. In contrast, we introduce a novel diffusion-based framework for general-purpose style transfer that can be flexibly adapted to arbitrary target styles at inference time. Our parameter-efficient approach, ParaGuide, leverages paraphrase-conditioned diffusion models alongside gradient-based guidance from both off-the-shelf classifiers and strong existing style embedders to transform the style of text while preserving semantic information. We validate the method on the Enron Email Corpus, with both human and automatic evaluations, and find that it outperforms strong baselines on formality, se
    
[^2]: 什么时候编程思维对推理起作用?

    When Do Program-of-Thoughts Work for Reasoning?. (arXiv:2308.15452v1 [cs.CL])

    [http://arxiv.org/abs/2308.15452](http://arxiv.org/abs/2308.15452)

    提出了复杂性影响推理分数（CIRS）来衡量编程语言对推理能力的影响，发现并非所有复杂性的代码数据都可以被学习或理解，适当的复杂性水平对于改善推理能力至关重要。

    

    大型语言模型（LLM）的推理能力在体现出人工智能领域中起着关键作用。尽管像编程思维提示这样的方法对于使用编程语言来解决复杂推理任务的LLM非常有效，但代码数据对推理能力的具体影响仍未充分探索。为了填补这一空白，我们提出了复杂性影响推理分数（CIRS），它结合了结构和逻辑属性，以衡量代码和推理能力之间的相关性。具体而言，我们使用抽象语法树来编码结构信息，并通过考虑难度和圈复杂度来计算逻辑复杂性。通过实证分析，我们发现并非所有复杂性的代码数据都可以被LLM学习或理解。最佳复杂性水平对于通过编程辅助提示改善推理能力至关重要。然后我们设计了一个自动合成的方法...

    The reasoning capabilities of Large Language Models (LLMs) play a pivotal role in the realm of embodied artificial intelligence. Although there are effective methods like program-of-thought prompting for LLMs which uses programming language to tackle complex reasoning tasks, the specific impact of code data on the improvement of reasoning capabilities remains under-explored. To address this gap, we propose complexity-impacted reasoning score (CIRS), which combines structural and logical attributes, to measure the correlation between code and reasoning abilities. Specifically, we use the abstract syntax tree to encode the structural information and calculate logical complexity by considering the difficulty and the cyclomatic complexity. Through an empirical analysis, we find not all code data of complexity can be learned or understood by LLMs. Optimal level of complexity is critical to the improvement of reasoning abilities by program-aided prompting. Then we design an auto-synthesizing
    
[^3]: 《孟加拉的欺凌言论检测》论文中对恰塔根语言方言的翻译研究

    Vulgar Remarks Detection in Chittagonian Dialect of Bangla. (arXiv:2308.15448v1 [cs.CL])

    [http://arxiv.org/abs/2308.15448](http://arxiv.org/abs/2308.15448)

    这篇论文的研究重点是利用有监督的机器学习和深度学习算法在社交媒体中检测恰塔根语言方言中的粗俗言论，并发现逻辑回归取得了较高的准确率（0.91）。

    

    随着互联网的普及，网络欺凌和骚扰的负面影响越来越大，尤其是在社交媒体上。解决方案之一是使用自然语言处理（NLP）和机器学习（ML）方法自动检测有害言论，但是在像孟加拉的恰塔根语言方言这样的低资源语言中，这些方法受限。本研究侧重于使用有监督的机器学习和深度学习算法在社交媒体上检测粗俗言论。逻辑回归取得了令人满意的准确度（0.91），而简单的循环神经网络与Word2vec和fastTex相比准确度较低（0.84-0.90），突显了神经网络算法需要更多数据的问题。

    The negative effects of online bullying and harassment are increasing with Internet popularity, especially in social media. One solution is using natural language processing (NLP) and machine learning (ML) methods for the automatic detection of harmful remarks, but these methods are limited in low-resource languages like the Chittagonian dialect of Bangla.This study focuses on detecting vulgar remarks in social media using supervised ML and deep learning algorithms.Logistic Regression achieved promising accuracy (0.91) while simple RNN with Word2vec and fastTex had lower accuracy (0.84-0.90), highlighting the issue that NN algorithms require more data.
    
[^4]: 语言模型预训练期间学习曲线的特征化：学习、遗忘和稳定性

    Characterizing Learning Curves During Language Model Pre-Training: Learning, Forgetting, and Stability. (arXiv:2308.15419v1 [cs.CL])

    [http://arxiv.org/abs/2308.15419](http://arxiv.org/abs/2308.15419)

    本研究通过从五个英语语言模型预训练运行中提取学习曲线，揭示了语言模型在预训练期间的学习过程。结果表明，语言模型在学习生成更长、更连贯的文本之前，会生成短而重复的短语。同时，频繁出现的标记在预训练过程中更早学习，具有更小的变异性，并且很少被遗忘。较短、更频繁的上下文与稳定和快速获得的预测有关。词类的影响较小，但名词倾向于较晚获得且遗忘率较低。

    

    在本文中，我们从五个自回归英语语言模型预训练运行中提取学习曲线，用于上下文中的100万个标记。我们观察到，在学习生成更长、更连贯文本之前，语言模型会生成短而重复的短语。我们定量描述了单个上下文中标记的学习曲线的最终surprisal、运行内变异性、获得年龄、遗忘度和跨运行变异性。更频繁的标记达到较低的最终surprisal，其内部和预训练运行间变异性较小，学习得更早，并且在预训练过程中很少被“遗忘”。更高的n-gram概率进一步加强了这些效果。与目标标记无关，较短、更频繁的上下文与较稳定和快速获得的预测略有相关。词类的影响也较小，尽管名词倾向于较晚获得且遗忘率较低。

    How do language models learn to make predictions during pre-training? To study this question, we extract learning curves from five autoregressive English language model pre-training runs, for 1M tokens in context. We observe that the language models generate short repetitive phrases before learning to generate longer and more coherent text. We quantify the final surprisal, within-run variability, age of acquisition, forgettability, and cross-run variability of learning curves for individual tokens in context. More frequent tokens reach lower final surprisals, exhibit less variability within and across pre-training runs, are learned earlier, and are less likely to be "forgotten" during pre-training. Higher n-gram probabilities further accentuate these effects. Independent of the target token, shorter and more frequent contexts correlate with marginally more stable and quickly acquired predictions. Effects of part-of-speech are also small, although nouns tend to be acquired later and les
    
[^5]: 重新思考机器伦理 - LLM能否通过道德理论进行道德推理？

    Rethinking Machine Ethics -- Can LLMs Perform Moral Reasoning through the Lens of Moral Theories?. (arXiv:2308.15399v1 [cs.CL])

    [http://arxiv.org/abs/2308.15399](http://arxiv.org/abs/2308.15399)

    本研究提出了一个灵活的框架，引导大型语言模型根据跨学科研究中建立的道德理论进行道德推理，解决了现有方法面临的问题。

    

    进行道德判断是发展伦理人工智能系统的重要一步。目前的方法大多数以自下而上的方式实施，通过使用大量的注释数据来训练基于众包意见的模型，来判断道德问题。这些方法因潜在过度普遍化有限的注释者道德立场并且缺乏可解释性而受到批评。相反，自上而下的方法是基于一套原则进行道德判断。然而，这个方法在概念上存在问题，因为之前的语言模型无法胜任，且道德原则之间存在未解决的辩论。在本研究中，我们提出了一个灵活的框架，可以引导大型语言模型（LLMs）根据跨学科研究中建立的道德理论进行道德推理。这个自上而下的理论引导框架可以融入各种道德理论。我们的实验验证了这个提出的框架在基于道德理论的数据集上的有效性。

    Making moral judgments is an essential step toward developing ethical AI systems. Prevalent approaches are mostly implemented in a bottom-up manner, which uses a large set of annotated data to train models based on crowd-sourced opinions about morality. These approaches have been criticized for potentially overgeneralizing a limited group of annotators' moral stances and lacking explainability. In contrast, top-down approaches make moral judgments grounded in a set of principles. However, it remains conceptual due to the incapability of previous language models and the unsolved debate among moral principles. In this study, we propose a flexible framework to steer Large Language Models (LLMs) to perform moral reasoning with well-established moral theories from interdisciplinary research. The theory-guided top-down framework can incorporate various moral theories. Our experiments demonstrate the effectiveness of the proposed framework on datasets derived from moral theories. Furthermore,
    
[^6]: 大语言模型赋能文本到SQL的研究：一个基准评估

    Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation. (arXiv:2308.15363v1 [cs.DB])

    [http://arxiv.org/abs/2308.15363](http://arxiv.org/abs/2308.15363)

    本文提出了一个大规模语言模型(LLMs)赋能的文本到SQL任务的基准评估，并基于实验结果提出了一种新的集成解决方案DAIL-SQL，刷新了Spider榜单并实现了86.6%的执行准确率。同时，强调了在提示工程中的词汇效率以实现高效经济的LLM-based文本到SQL解决方案，此外还对在上下文学习中应用开源LLMs进行了研究，并进行了任务特定的性能优化。

    

    大语言模型(LLMs)已经成为文本到SQL任务的一种新范式。然而，缺乏一个系统性的基准阻碍了设计有效、高效和经济的LLM-based文本到SQL解决方案的发展。为了解决这一挑战，本文首先对现有的提示工程方法进行了系统性和广泛的比较，包括问题表示、示例选择和示例组织，并根据实验结果详细阐述了它们的优缺点。基于这些发现，我们提出了一种新的集成解决方案，名为DAIL-SQL，刷新了Spider榜单，达到了86.6%的执行准确率，建立了一个新的标杆。为了实现高效经济的LLM-based文本到SQL解决方案，我们强调提示工程中的词汇效率，并在此度量下比较了之前的研究。此外，我们还研究了上下文学习中的开源LLMs，并用任务特定的监督进行了进一步的性能优化。

    Large language models (LLMs) have emerged as a new paradigm for Text-to-SQL task. However, the absence of a systematical benchmark inhibits the development of designing effective, efficient and economic LLM-based Text-to-SQL solutions. To address this challenge, in this paper, we first conduct a systematical and extensive comparison over existing prompt engineering methods, including question representation, example selection and example organization, and with these experimental results, we elaborates their pros and cons. Based on these findings, we propose a new integrated solution, named DAIL-SQL, which refreshes the Spider leaderboard with 86.6% execution accuracy and sets a new bar. Towards an efficient and economic LLM-based Text-to-SQL solution, we emphasize the token efficiency in prompt engineering and compare the prior studies under this metric. Additionally, we investigate open-source LLMs in in-context learning, and further enhance their performance with task-specific superv
    
[^7]: 中国和日本现代语言使用的历史模式解释比现代化和城市化更为重要

    Historical patterns of rice farming explain modern-day language use in China and Japan more than modernization and urbanization. (arXiv:2308.15352v1 [cs.CL])

    [http://arxiv.org/abs/2308.15352](http://arxiv.org/abs/2308.15352)

    论文研究了中国和日本现代语言使用中的文化差异，发现历史上稻米种植对于社会互动和思维方式的影响比经济发展和城市化更为重要。

    

    我们使用自然语言处理技术分析了十亿个词汇，以研究微博这一中国最大的社交媒体平台上的文化差异。我们将中国文化差异的两种常见解释（经济发展和城乡差异）与稻米与小麦种植的历史遗留影响进行了比较。稻农需要协调共享的灌溉网络并交换劳动力，以应对较高的劳动力需求。相反，小麦依赖降雨，所需劳动力只有稻米的一半。我们测试了这种历史遗留是否使得中国南方更加相互依赖。在所有词汇类别中，稻米解释的方差是经济发展和城市化的两倍。稻米种植区使用更多反映紧密社会联系、整体思维和谨慎、预防导向的词汇。然后，我们使用推特数据对日本的各个州进行了比较，结果基本上复制了中国的研究结果。这为稻米理论提供了关键证据。

    We used natural language processing to analyze a billion words to study cultural differences on Weibo, one of China's largest social media platforms. We compared predictions from two common explanations about cultural differences in China (economic development and urban-rural differences) against the less-obvious legacy of rice versus wheat farming. Rice farmers had to coordinate shared irrigation networks and exchange labor to cope with higher labor requirements. In contrast, wheat relied on rainfall and required half as much labor. We test whether this legacy made southern China more interdependent. Across all word categories, rice explained twice as much variance as economic development and urbanization. Rice areas used more words reflecting tight social ties, holistic thought, and a cautious, prevention orientation. We then used Twitter data comparing prefectures in Japan, which largely replicated the results from China. This provides crucial evidence of the rice theory in a differ
    
[^8]: 一种负责任开发基于生成AI的自动学生反馈框架

    A Framework for Responsible Development of Automated Student Feedback with Generative AI. (arXiv:2308.15334v1 [cs.CY])

    [http://arxiv.org/abs/2308.15334](http://arxiv.org/abs/2308.15334)

    一种基于生成AI的自动学生反馈框架可以提供丰富的反馈，但引入了伦理问题，并需要解决“多数人的暴政”和忽视长尾中少数群体需求的挑战。

    

    提供丰富的反馈对于支持学生学习至关重要。最近生成AI尤其是大规模语言模型的进展，为向学生提供可重复、可扩展和即时生成的自动反馈提供了机会，使得之前稀缺且昂贵的学习资源变得丰富起来。从技术角度而言，这种方法是可行的，得益于最近人工智能和自然语言处理的进步；然而，采用这些技术也引入了一系列潜在的伦理问题，需要认真考虑。人工智能系统的吸引力在于它们可以有效地自动化最乏味的任务；但是这也可能导致“多数人的暴政”，即忽视了长尾中少数群体的需求，因为这些需求很难自动化。因此，开发能够产生有价值和真实的机器学习模型变得至关重要。

    Providing rich feedback to students is essential for supporting student learning. Recent advances in generative AI, particularly within large language modelling (LLM), provide the opportunity to deliver repeatable, scalable and instant automatically generated feedback to students, making abundant a previously scarce and expensive learning resource. Such an approach is feasible from a technical perspective due to these recent advances in Artificial Intelligence (AI) and Natural Language Processing (NLP); while the potential upside is a strong motivator, doing so introduces a range of potential ethical issues that must be considered as we apply these technologies. The attractiveness of AI systems is that they can effectively automate the most mundane tasks; but this risks introducing a "tyranny of the majority", where the needs of minorities in the long tail are overlooked because they are difficult to automate.  Developing machine learning models that can generate valuable and authentic
    
[^9]: TaskLAMA: 探究语言模型对复杂任务理解的能力

    TaskLAMA: Probing the Complex Task Understanding of Language Models. (arXiv:2308.15299v1 [cs.CL])

    [http://arxiv.org/abs/2308.15299](http://arxiv.org/abs/2308.15299)

    TaskLAMA论文研究了语言模型对复杂任务理解的能力，使用人工标注数据集和新的评估指标，实验证明LLMs能够有效地将复杂任务分解为个别步骤，并提出了进一步提升性能的方法。

    

    结构化复杂任务分解（SCTD）是将复杂的现实世界任务（如策划婚礼）分解为有向无环图，图中的每个步骤都是为完成任务做出贡献的，边表示它们之间的时序依赖关系。SCTD是辅助规划工具的重要组成部分，也是常识推理系统所面临的挑战。我们探索了从大型语言模型（LLMs）提取的知识能够准确地进行SCTD的程度。我们为这个问题引入了一个高质量的人工标注数据集，并使用新的指标来公平评估LLMs相对于几个基准的性能。我们的实验揭示了LLMs能够有效地将复杂任务分解为个别步骤，相对于最佳基准方法可以提升15%到280%。我们还提出了一些进一步提升性能的方法，相对于基线模型可以提升7%到37%。然而，我们发现LLMs仍然面临困难。

    Structured Complex Task Decomposition (SCTD) is the problem of breaking down a complex real-world task (such as planning a wedding) into a directed acyclic graph over individual steps that contribute to achieving the task, with edges specifying temporal dependencies between them. SCTD is an important component of assistive planning tools, and a challenge for commonsense reasoning systems. We probe how accurately SCTD can be done with the knowledge extracted from Large Language Models (LLMs). We introduce a high-quality human-annotated dataset for this problem and novel metrics to fairly assess performance of LLMs against several baselines. Our experiments reveal that LLMs are able to decompose complex tasks into individual steps effectively, with a relative improvement of 15% to 280% over the best baseline. We also propose a number of approaches to further improve their performance, with a relative improvement of 7% to 37% over the base model. However, we find that LLMs still struggle 
    
[^10]: KGConv，基于Wikidata的对话语料库

    KGConv, a Conversational Corpus grounded in Wikidata. (arXiv:2308.15298v1 [cs.CL])

    [http://arxiv.org/abs/2308.15298](http://arxiv.org/abs/2308.15298)

    KGConv是一个基于Wikidata的大型对话语料库，每个对话都基于一个事实，并提供了多个变体的问题。它可以用于知识对话问题生成和其他相关任务。

    

    我们提出了KGConv，一个包含71k个对话的大型对话语料库，每个问题-回答对都基于Wikidata中的一个事实。每个对话平均含有8.6个问题，并为每个Wikidata事实提供多个变体(平均12个)，这些变体使用模板、人工注释、手工规则和问题重写神经模型生成。我们为基于知识的对话问题生成任务提供了基线。KGConv还可用于其他生成和分析任务，例如从Wikidata三元组生成单轮问题、问题重写、从对话或知识图中回答问题以及生成测验题。

    We present KGConv, a large, conversational corpus of 71k conversations where each question-answer pair is grounded in a Wikidata fact. Conversations contain on average 8.6 questions and for each Wikidata fact, we provide multiple variants (12 on average) of the corresponding question using templates, human annotations, hand-crafted rules and a question rewriting neural model. We provide baselines for the task of Knowledge-Based, Conversational Question Generation. KGConv can further be used for other generation and analysis tasks such as single-turn question generation from Wikidata triples, question rewriting, question answering from conversation or from knowledge graphs and quiz generation.
    
[^11]: 通过后处理OCR模型提高OCR性能：采用字形嵌入来改进校正

    Enhancing OCR Performance through Post-OCR Models: Adopting Glyph Embedding for Improved Correction. (arXiv:2308.15262v1 [cs.CV])

    [http://arxiv.org/abs/2308.15262](http://arxiv.org/abs/2308.15262)

    本研究通过后处理OCR模型，采用字形嵌入的方法来改进OCR性能。研究结果表明后处理能够有效解决劣质OCR模型的问题，并且字形嵌入可以提高校正结果，包括纠正个别单词。

    

    本研究探讨了后处理OCR模型克服OCR模型限制的潜力，并研究了将字形嵌入结合到后处理OCR校正中的影响。在本研究中，我们开发了自己的后处理OCR校正模型。我们方法的创新之处在于使用CharBERT和我们独特的嵌入技术来嵌入OCR输出，并捕捉字符的视觉特征。我们的研究结果表明，后处理OCR校正能有效解决劣质OCR模型的缺陷，而字形嵌入使模型能够取得卓越的结果，包括纠正个别单词。

    The study investigates the potential of post-OCR models to overcome limitations in OCR models and explores the impact of incorporating glyph embedding on post-OCR correction performance. In this study, we have developed our own post-OCR correction model. The novelty of our approach lies in embedding the OCR output using CharBERT and our unique embedding technique, capturing the visual characteristics of characters. Our findings show that post-OCR correction effectively addresses deficiencies in inferior OCR models, and glyph embedding enables the model to achieve superior results, including the ability to correct individual words.
    
[^12]: 一种基于分类引导的对抗攻击神经机器翻译方法

    A Classification-Guided Approach for Adversarial Attacks against Neural Machine Translation. (arXiv:2308.15246v1 [cs.CL])

    [http://arxiv.org/abs/2308.15246](http://arxiv.org/abs/2308.15246)

    本文介绍了一种基于分类引导的对抗攻击神经机器翻译的方法，通过改变整体意义生成保持语义的对抗样本，从而使得翻译结果属于不同的类别。

    

    神经机器翻译（NMT）模型已经被证明容易受到对抗攻击的影响，攻击者可以通过精心设计的输入扰动来误导目标模型。本文介绍了一种名为ACT的新型对抗攻击框架，针对NMT系统进行攻击，攻击过程中引导了一个分类器。在我们的攻击中，攻击者旨在生成保持语义的对抗样本，使得NMT模型的翻译结果与目标语言中的原始翻译属于不同的类别。与之前的攻击不同，我们的新方法更能改变整体意义，从而通过分类器将其归为不同的类别。为了评估NMT模型对该攻击的抵抗能力，我们提出了对现有基于单词替换的黑盒攻击进行改进的方法，通过在攻击过程中引入目标NMT模型的输出翻译和一个分类器的输出logit。通过在各种设置下进行大量实验证明了我们的方法的有效性。

    Neural Machine Translation (NMT) models have been shown to be vulnerable to adversarial attacks, wherein carefully crafted perturbations of the input can mislead the target model. In this paper, we introduce ACT, a novel adversarial attack framework against NMT systems guided by a classifier. In our attack, the adversary aims to craft meaning-preserving adversarial examples whose translations by the NMT model belong to a different class than the original translations in the target language. Unlike previous attacks, our new approach has a more substantial effect on the translation by altering the overall meaning, which leads to a different class determined by a classifier. To evaluate the robustness of NMT models to this attack, we propose enhancements to existing black-box word-replacement-based attacks by incorporating output translations of the target NMT model and the output logits of a classifier within the attack process. Extensive experiments in various settings, including a comp
    
[^13]: PronounFlow:一种用于校准句子中代词的混合方法

    PronounFlow: A Hybrid Approach for Calibrating Pronouns in Sentences. (arXiv:2308.15235v1 [cs.CL])

    [http://arxiv.org/abs/2308.15235](http://arxiv.org/abs/2308.15235)

    PronounFlow提出了一种混合方法来校准句子中的代词，以消除歧义。这对于使机器具备常识和推理能力具有重要意义。

    

    翻阅任何一本书或听任何一首歌词，你会遇到在某些情况下会阻碍理解的代词，特别是对于机器来说。随着认知机器在我们生活中的普及，许多系统已经被开发出来以解决各种挑战下的代词歧义。因此，人们认为能够消除句子中的代词歧义的系统将有助于使机器具备与人类相似的常识和推理能力。然而，这些系统在现代英语中面临的一个问题是缺乏性别代词，人们试图通过使用男性、女性或复数来避免整个问题的出现。由于人类的目标是构建出与人类类似的完整意义上的系统，那么当书面文本中的代词(如复数或中性代词)指的是性别不一定已知的未指定实体时会发生什么呢？

    Flip through any book or listen to any song lyrics, and you will come across pronouns that, in certain cases, can hinder meaning comprehension, especially for machines. As the role of having cognitive machines becomes pervasive in our lives, numerous systems have been developed to resolve pronouns under various challenges. Commensurate with this, it is believed that having systems able to disambiguate pronouns in sentences will help towards the endowment of machines with commonsense and reasoning abilities like those found in humans. However, one problem these systems face with modern English is the lack of gender pronouns, where people try to alternate by using masculine, feminine, or plural to avoid the whole issue. Since humanity aims to the building of systems in the full-bodied sense we usually reserve for people, what happens when pronouns in written text, like plural or epicene ones, refer to unspecified entities whose gender is not necessarily known? Wouldn't that put extra bar
    
[^14]: 结合可解释性分析的分类感知神经主题模型——用于冲突分类

    Classification-Aware Neural Topic Model Combined With Interpretable Analysis -- For Conflict Classification. (arXiv:2308.15232v1 [cs.LG])

    [http://arxiv.org/abs/2308.15232](http://arxiv.org/abs/2308.15232)

    本文提出了一种结合可解释性分析的分类感知神经主题模型，用于冲突分类和主题发现。该模型提供了可靠的分类结果和发现的主题的解释，并通过优化模型的复杂度来提高分类性能。

    

    世界上有大量的冲突事件一直在影响着我们。为了有效分析这些冲突事件，本文提出了一种用于冲突信息分类和主题发现的分类感知神经主题模型（CANTM-IA）。该模型通过引入可解释性分析来提供可靠的分类结果和发现的主题的解释。同时，将解释性引入模型架构中，以提高模型的分类性能，并使解释进一步关注数据的细节。最后，对模型架构进行优化，以降低模型的复杂度。

    A large number of conflict events are affecting the world all the time. In order to analyse such conflict events effectively, this paper presents a Classification-Aware Neural Topic Model (CANTM-IA) for Conflict Information Classification and Topic Discovery. The model provides a reliable interpretation of classification results and discovered topics by introducing interpretability analysis. At the same time, interpretation is introduced into the model architecture to improve the classification performance of the model and to allow interpretation to focus further on the details of the data. Finally, the model architecture is optimised to reduce the complexity of the model.
    
[^15]: 使用LLMs进行多方目标追踪：比较预训练、微调和提示工程方法

    Multi-party Goal Tracking with LLMs: Comparing Pre-training, Fine-tuning, and Prompt Engineering. (arXiv:2308.15231v1 [cs.CL])

    [http://arxiv.org/abs/2308.15231](http://arxiv.org/abs/2308.15231)

    本文评估了当前大型语言模型（LLMs）在捕捉任务导向的多方会话（MPCs）方面的能力，并比较了三种方法（预训练、微调和提示工程），结果表明在有限数据情况下，GPT-3.5-turbo通过"推理"风格的提示在少样本设置下表现最好。

    

    本文评估当前的大型语言模型（LLMs）能否捕捉面向任务的多方会话（MPCs）。我们记录并转录了29个在医院中患者、他们的伴侣和社交机器人之间的MPCs。然后我们对这个语料库进行了多方目标追踪和意图槽识别的注释。在MPCs中，人们分享目标，回答对方的目标，并提供其他人的目标 - 这些都不会在二元交互中发生。为了理解MPCs中用户的目标，我们在零样本和少样本设置下比较了三种方法：我们对T5进行了微调，使用LED创建了预训练任务来训练DialogLM，并使用GPT-3.5-turbo采用提示工程技术，以确定哪种方法可以在有限的数据下完成这个新颖的任务。在少样本设置下，GPT-3.5-turbo的性能显著优于其他方法。当给定7%的语料库作为示例标注对话时，"推理"风格的提示是表现最好的方法。它能正确注释...

    This paper evaluates the extent to which current Large Language Models (LLMs) can capture task-oriented multi-party conversations (MPCs). We have recorded and transcribed 29 MPCs between patients, their companions, and a social robot in a hospital. We then annotated this corpus for multi-party goal-tracking and intent-slot recognition. People share goals, answer each other's goals, and provide other people's goals in MPCs - none of which occur in dyadic interactions. To understand user goals in MPCs, we compared three methods in zero-shot and few-shot settings: we fine-tuned T5, created pre-training tasks to train DialogLM using LED, and employed prompt engineering techniques with GPT-3.5-turbo, to determine which approach can complete this novel task with limited data. GPT-3.5-turbo significantly outperformed the others in a few-shot setting. The `reasoning' style prompt, when given 7% of the corpus as example annotated conversations, was the best performing method. It correctly annot
    
[^16]: CLIPTrans：使用预训练模型转移视觉知识进行多模态机器翻译

    CLIPTrans: Transferring Visual Knowledge with Pre-trained Models for Multimodal Machine Translation. (arXiv:2308.15226v1 [cs.CV])

    [http://arxiv.org/abs/2308.15226](http://arxiv.org/abs/2308.15226)

    本研究提出了CLIPTrans，它通过简单地适应独立预训练模型，实现了多模态机器翻译中视觉知识的转移。

    

    近年来，开发增强神经机器翻译（NMT）的多模态机器翻译（MMT）系统以提高翻译质量的兴趣逐渐增长。这一问题设置涉及在训练过程中使用图像作为辅助信息，并且最近在推理过程中消除它们的使用。然而，之前的工作在从头开始训练强大的MMT模型时面临了一个挑战，因为多语言视觉语言数据的标注稀缺，尤其是对于低资源语言。与此同时，针对NMT的多语言预训练模型和针对视觉语言任务的多模态预训练模型大量涌现，主要针对英文，它们展现了出色的泛化能力。然而，这些模型对于MMT并不直接适用，因为它们没有为生成任务提供对齐的多模态多语言特征。为了解决这个问题，我们提出了CLIPTrans，它不像设计复杂的MMT模块，而是简单地适应独立预训练模型，

    There has been a growing interest in developing multimodal machine translation (MMT) systems that enhance neural machine translation (NMT) with visual knowledge. This problem setup involves using images as auxiliary information during training, and more recently, eliminating their use during inference. Towards this end, previous works face a challenge in training powerful MMT models from scratch due to the scarcity of annotated multilingual vision-language data, especially for low-resource languages. Simultaneously, there has been an influx of multilingual pre-trained models for NMT and multimodal pre-trained models for vision-language tasks, primarily in English, which have shown exceptional generalisation ability. However, these are not directly applicable to MMT since they do not provide aligned multimodal multilingual features for generative tasks. To alleviate this issue, instead of designing complex modules for MMT, we propose CLIPTrans, which simply adapts the independently pre-
    
[^17]: FurChat: 使用LLMs的具有脸部表情的交互式对话系统，结合开放和封闭领域对话

    FurChat: An Embodied Conversational Agent using LLMs, Combining Open and Closed-Domain Dialogue with Facial Expressions. (arXiv:2308.15214v1 [cs.CL])

    [http://arxiv.org/abs/2308.15214](http://arxiv.org/abs/2308.15214)

    本研究开发了一个交互式对话系统，将开放和封闭领域对话、脸部表情结合起来，通过使用LLMs和GPT-3.5模型来生成引人入胜的对话，以提供信息并与访客进行自然交流。

    

    我们展示了一个交互式对话系统，可以作为接待员，生成结合开放和封闭领域对话以及脸部表情的混合对话。通过使用大型语言模型（LLM）来开发引人入胜的对话，我们将该系统部署到了一个高度表达力的Furhat机器人上，在互动过程中使用了口头和非语言提示。该系统专门为国家机器人实验室设计，通过自然对话与访客进行交互，并向他们提供有关设施、研究、新闻、即将举行的活动等方面的信息。系统利用最先进的GPT-3.5模型根据提示生成这些信息，同时生成领域通用的对话和面部表情。

    We demonstrate an embodied conversational agent that can function as a receptionist and generate a mixture of open and closed-domain dialogue along with facial expressions, by using a large language model (LLM) to develop an engaging conversation. We deployed the system onto a Furhat robot, which is highly expressive and capable of using both verbal and nonverbal cues during interaction. The system was designed specifically for the National Robotarium to interact with visitors through natural conversations, providing them with information about the facilities, research, news, upcoming events, etc. The system utilises the state-of-the-art GPT-3.5 model to generate such information along with domain-general conversations and facial expressions based on prompt engineering.
    
[^18]: 共享词汇作为代码切换的触发器

    Shared Lexical Items as Triggers of Code Switching. (arXiv:2308.15209v1 [cs.CL])

    [http://arxiv.org/abs/2308.15209](http://arxiv.org/abs/2308.15209)

    该研究通过使用三种语言对的五个大型数据集，对共享词汇作为代码切换的触发器进行了深入探索。结果表明，共享词汇确实会触发代码切换，切换的倾向取决于触发器与切换点的距离和位置，而不取决于触发词的词源。

    

    为什么双语者要进行代码切换（混合两种语言）？在解释这种自然和普遍现象的几种理论中，触发假说将代码切换与切换点附近的词汇触发器（特别是同源词和专有名词）联系起来。我们基于三种语言对的五个大型数据集，反映了口语和书面双语交流，对触发假说进行了更全面、更细致、更精细的探索。我们的结果显示，被认为同时存在于两种语言的共享心理词汇中的词确实触发代码切换；切换的倾向取决于触发器与切换点的距离；以及触发器是在切换之前还是之后；但不取决于触发词的词源。因此，我们对词汇触发器与代码切换之间的关系提供了强有力、稳定、以证据为基础的证实。

    Why do bilingual speakers code-switch (mix their two languages)? Among the several theories that attempt to explain this natural and ubiquitous phenomenon, the Triggering Hypothesis relates code-switching to the presence of lexical triggers, specifically cognates and proper names, adjacent to the switch point. We provide a fuller, more nuanced and refined exploration of the triggering hypothesis, based on five large datasets in three language pairs, reflecting both spoken and written bilingual interactions. Our results show that words that are assumed to reside in a mental lexicon shared by both languages indeed trigger code-switching; that the tendency to switch depends on the distance of the trigger from the switch point; and on whether the trigger precedes or succeeds the switch; but not on the etymology of the trigger words. We thus provide strong, robust, evidence-based confirmation to several hypotheses on the relationships between lexical triggers and code-switching.
    
[^19]: 事实核查解释的基准化。 (arXiv:2308.15202v1 [cs.CL])

    Benchmarking the Generation of Fact Checking Explanations. (arXiv:2308.15202v1 [cs.CL])

    [http://arxiv.org/abs/2308.15202](http://arxiv.org/abs/2308.15202)

    本论文基于新颖数据集和先进基准，旨在解决给出声明真实性解释的问题。研究结果表明，在使用非结构化知识的摘要方法中，命题信息是有益的，并且某些抽象策略表现出色。

    

    打击错误信息是一项具有挑战性但至关重要的任务。尽管越来越多的专家参与手动事实核查，但这项活动耗时且无法跟得上每天产生的大量虚假新闻。因此，自动化此过程是必要的以帮助遏制错误信息。迄今为止，研究者主要关注声明真实度分类。而在本文中，我们着眼于解释生成（解释为什么声明被分类为真或假的文本解释）并与新颖数据集和先进基准进行了基准化。我们特别关注非结构化知识（即新闻文章）上的摘要方法，并尝试了几种提取和抽象策略。我们使用了两个具有不同风格和结构的数据集，以评估研究结果的普适性。结果表明，在解释生成摘要方面，由声明信息受益，并且某些抽象方法表现出色。

    Fighting misinformation is a challenging, yet crucial, task. Despite the growing number of experts being involved in manual fact-checking, this activity is time-consuming and cannot keep up with the ever-increasing amount of Fake News produced daily. Hence, automating this process is necessary to help curb misinformation. Thus far, researchers have mainly focused on claim veracity classification. In this paper, instead, we address the generation of justifications (textual explanation of why a claim is classified as either true or false) and benchmark it with novel datasets and advanced baselines. In particular, we focus on summarization approaches over unstructured knowledge (i.e. news articles) and we experiment with several extractive and abstractive strategies. We employed two datasets with different styles and structures, in order to assess the generalizability of our findings. Results show that in justification production summarization benefits from the claim information, and, in 
    
[^20]: 借助大型语言模型增强心理咨询：面向非专业人员的多方面决策支持系统

    Enhancing Psychological Counseling with Large Language Model: A Multifaceted Decision-Support System for Non-Professionals. (arXiv:2308.15192v1 [cs.AI])

    [http://arxiv.org/abs/2308.15192](http://arxiv.org/abs/2308.15192)

    本研究基于大型语言模型构建了一个决策支持系统，可帮助非专业人员在社交媒体上提供心理咨询，从而弥补了专业咨询师短缺的问题。

    

    在当今社交媒体的环境下，大量用户表达负面情绪，其中一些表现为强烈的自杀倾向。这种情况凸显了对训练有素的心理咨询师的迫切需求，他们可以实施有效的心理干预。然而，培养这些专业人员常常是一项必要但耗时的任务。因此，动员非专业人员或志愿者在这方面发挥作用成为一个紧迫的问题。利用人工智能的能力，尤其是大型语言模型的最新进展，为此挑战提供了可行的解决方案。本文介绍了一个基于大型语言模型构建的新型模型，以充分辅助非专业人员在在线用户交流中提供心理干预。该框架使得合理利用非专业咨询师的力量变得可行。进行了一项综合研究。

    In the contemporary landscape of social media, an alarming number of users express negative emotions, some of which manifest as strong suicidal intentions. This situation underscores a profound need for trained psychological counselors who can enact effective mental interventions. However, the development of these professionals is often an imperative but time-consuming task. Consequently, the mobilization of non-professionals or volunteers in this capacity emerges as a pressing concern. Leveraging the capabilities of artificial intelligence, and in particular, the recent advances in large language models, offers a viable solution to this challenge. This paper introduces a novel model constructed on the foundation of large language models to fully assist non-professionals in providing psychological interventions on online user discourses. This framework makes it plausible to harness the power of non-professional counselors in a meaningful way. A comprehensive study was conducted involvi
    
[^21]: 阴谋者的解剖学：揭示性格特点的全面Twitter数据集

    The Anatomy of Conspirators: Unveiling Traits using a Comprehensive Twitter Dataset. (arXiv:2308.15154v1 [cs.SI])

    [http://arxiv.org/abs/2308.15154](http://arxiv.org/abs/2308.15154)

    本研究通过构建一种全面的Twitter数据集，揭示了参与阴谋相关活动的用户的特点和行为特征，为阴谋论的检测提供了新的方法和依据。

    

    在充斥着在线环境中的大量错误信息中，关于阴谋论的讨论正在蓬勃发展。在这个领域的研究主要集中在社交媒体上检测阴谋论，往往依赖于有限的数据集。在本研究中，我们提出了一种新的方法论，用于构建一个包含2022年全年涉及阴谋相关活动的Twitter数据集。我们的方法着重于独立于特定阴谋论和信息操作的数据收集。此外，我们的数据集包括一个对照组，其中随机选择用户可以与涉及阴谋活动的个体进行公正比较。这次全面的收集工作总共得到了15K个账户和从他们的时间线中提取的37M条推文。我们对两个群体在主题、个人资料和行为特征这三个维度上进行了比较分析。结果表明，阴谋和

    The discourse around conspiracy theories is currently thriving amidst the rampant misinformation prevalent in online environments. Research in this field has been focused on detecting conspiracy theories on social media, often relying on limited datasets. In this study, we present a novel methodology for constructing a Twitter dataset that encompasses accounts engaged in conspiracy-related activities throughout the year 2022. Our approach centers on data collection that is independent of specific conspiracy theories and information operations. Additionally, our dataset includes a control group comprising randomly selected users who can be fairly compared to the individuals involved in conspiracy activities. This comprehensive collection effort yielded a total of 15K accounts and 37M tweets extracted from their timelines. We conduct a comparative analysis of the two groups across three dimensions: topics, profiles, and behavioral characteristics. The results indicate that conspiracy and
    
[^22]: 大型视觉语言模型中幻觉的评估与分析

    Evaluation and Analysis of Hallucination in Large Vision-Language Models. (arXiv:2308.15126v1 [cs.LG])

    [http://arxiv.org/abs/2308.15126](http://arxiv.org/abs/2308.15126)

    本文提出了基于大型语言模型的幻觉评估框架HaELM，可以评估大型视觉语言模型中的幻觉问题，并分析了导致幻觉的因素，并提出了缓解幻觉问题的建议。

    

    最近，大型视觉语言模型（LVLMs）取得了显著的成功。然而，LVLMs仍然存在幻觉问题，这限制了在许多场景中的实用性。幻觉指的是LVLMs响应中不存在于视觉输入中的信息，这可能导致重大后果的潜在风险。目前对LVLMs中的幻觉评估的研究工作有限。在本文中，我们提出了基于大型语言模型（LLM）的幻觉评估框架HaELM。HaELM的性能近似于ChatGPT的95%，并具有低成本、可复现、保护隐私和本地部署等额外优势。利用HaELM，我们评估了当前LVLMs中的幻觉。此外，我们分析了导致LVLMs中幻觉的因素，并提出了缓解幻觉问题的有用建议。

    Large Vision-Language Models (LVLMs) have recently achieved remarkable success. However, LVLMs are still plagued by the hallucination problem, which limits the practicality in many scenarios. Hallucination refers to the information of LVLMs' responses that does not exist in the visual input, which poses potential risks of substantial consequences. There has been limited work studying hallucination evaluation in LVLMs. In this paper, we propose Hallucination Evaluation based on Large Language Models (HaELM), an LLM-based hallucination evaluation framework. HaELM achieves an approximate 95% performance comparable to ChatGPT and has additional advantages including low cost, reproducibility, privacy preservation and local deployment. Leveraging the HaELM, we evaluate the hallucination in current LVLMs. Furthermore, we analyze the factors contributing to hallucination in LVLMs and offer helpful suggestions to mitigate the hallucination problem. Our training data and human annotation halluci
    
[^23]: SpikeBERT：一种采用两阶段BERT知识蒸馏训练的语言Spikformer

    SpikeBERT: A Language Spikformer Trained with Two-Stage Knowledge Distillation from BERT. (arXiv:2308.15122v1 [cs.CL])

    [http://arxiv.org/abs/2308.15122](http://arxiv.org/abs/2308.15122)

    该论文提出了一种名为SpikeBERT的SNN模型，通过改进Spikformer架构和使用两阶段知识蒸馏方法，该模型在语言任务上超越了其他SNN模型，在文本分类任务上甚至达到了与BERT相当的结果。

    

    脉冲神经网络（SNN）在以更节能的方式实现深度神经网络方面提供了一个有前景的途径。然而，现有的用于语言任务的SNN网络架构过于简单，深度架构尚未得到充分探索，与BERT等主流基于Transformer的网络相比，存在显著的性能差距。为此，我们改进了最近提出的脉冲Transformer（即Spikformer），使其能够处理语言任务，并提出了一种两阶段知识蒸馏方法来训练它，该方法结合了通过从BERT和大量未标记文本中蒸馏知识进行预训练，并通过再次从在相同训练示例上对BERT进行微调，并进行任务特定实例知识蒸馏。通过大量实验，我们展示了使用我们的方法训练的模型，命名为SpikeBERT，在实现上超过了最先进的SNN，并且甚至在文本分类任务上达到了与BERT相当的结果。

    Spiking neural networks (SNNs) offer a promising avenue to implement deep neural networks in a more energy-efficient way. However, the network architectures of existing SNNs for language tasks are too simplistic, and deep architectures have not been fully explored, resulting in a significant performance gap compared to mainstream transformer-based networks such as BERT. To this end, we improve a recently-proposed spiking transformer (i.e., Spikformer) to make it possible to process language tasks and propose a two-stage knowledge distillation method for training it, which combines pre-training by distilling knowledge from BERT with a large collection of unlabelled texts and fine-tuning with task-specific instances via knowledge distillation again from the BERT fine-tuned on the same training examples. Through extensive experimentation, we show that the models trained with our method, named SpikeBERT, outperform state-of-the-art SNNs and even achieve comparable results to BERTs on text 
    
[^24]: 棋盘上的大型语言模型：ChatGPT的正式语言理解和复杂推理技能研究

    Large Language Models on the Chessboard: A Study on ChatGPT's Formal Language Comprehension and Complex Reasoning Skills. (arXiv:2308.15118v1 [cs.CL])

    [http://arxiv.org/abs/2308.15118](http://arxiv.org/abs/2308.15118)

    本研究通过在国际象棋上使用OpenAI的ChatGPT语言模型作为案例，评估了该模型在复杂推理任务中的表现。我们发现ChatGPT在正式语言理解和自我调节方面存在局限性，但在游戏中展现了一致的战略倾向和决策自信度的提升。

    

    尽管大型语言模型在自然语言处理方面取得了进展，但它们在需要正式语言理解的复杂推理任务（如国际象棋）方面的熟练程度仍受到较少的研究。本文通过使用国际象棋作为案例研究，探究了OpenAI的高级语言模型ChatGPT在处理这种复杂推理任务上的表现。通过检查移动的合法性和质量等稳健指标，我们评估了ChatGPT对国际象棋棋盘的理解能力、对国际象棋规则的遵守情况以及战略决策能力。我们的评估发现了ChatGPT关注机制的局限性，影响其对正式语言的理解，并揭示了该模型未发展完善的自我调节能力。我们的研究还揭示了ChatGPT在游戏中的一致战略倾向以及当模型面对更多自然语言或具有更清晰理解能力时，决策自信度的明显增加。

    While large language models have made strides in natural language processing, their proficiency in complex reasoning tasks requiring formal language comprehension, such as chess, remains less investigated. This paper probes the performance of ChatGPT, a sophisticated language model by OpenAI in tackling such complex reasoning tasks, using chess as a case study. Through robust metrics examining both the legality and quality of moves, we assess ChatGPT's understanding of the chessboard, adherence to chess rules, and strategic decision-making abilities. Our evaluation identifies limitations within ChatGPT's attention mechanism that affect its formal language comprehension and uncovers the model's underdeveloped self-regulation abilities. Our study also reveals ChatGPT's propensity for a coherent strategy in its gameplay and a noticeable uptick in decision-making assertiveness when the model is presented with a greater volume of natural language or possesses a more lucid understanding of t
    
[^25]: 自然发生的人机交互的顺序注释:初步见解

    Sequential annotations for naturally-occurring HRI: first insights. (arXiv:2308.15097v1 [cs.AI])

    [http://arxiv.org/abs/2308.15097](http://arxiv.org/abs/2308.15097)

    这篇论文介绍了一种用于改善嵌入式对话智能体交互的方法论，并提出了一种基于语言和多模态资源使用理论基础的注释实践。

    

    我们解释了我们开发的方法论，通过对话分析的顺序和多模态分析来改善嵌入式交互式智能体的交互。使用案例是一个Pepper机器人，预期在图书馆中向用户提供信息和导航。为了提出和学习更好的交互模式，我们正在创建一个自然发生的交互语料库，并将其提供给社区。为此，我们提出了基于有关语言和多模态资源在人机交互中使用的一些理论基础的注释实践。

    We explain the methodology we developed for improving the interactions accomplished by an embedded conversational agent, drawing from Conversation Analytic sequential and multimodal analysis. The use case is a Pepper robot that is expected to inform and orient users in a library. In order to propose and learn better interactive schema, we are creating a corpus of naturally-occurring interactions that will be made available to the community. To do so, we propose an annotation practice based on some theoretical underpinnings about the use of language and multimodal resources in human-robot interaction. CCS CONCEPTS $\bullet$ Computing methodologies $\rightarrow$ Discourse, dialogue and pragmatics; $\bullet$ Human-centered computing $\rightarrow$ Text input; HCI theory, concepts and models; Field studies.
    
[^26]: 一石二鸟：音频字幕系统是否能用于音频文本检索？

    Killing two birds with one stone: Can an audio captioning system also be used for audio-text retrieval?. (arXiv:2308.15090v1 [cs.CL])

    [http://arxiv.org/abs/2308.15090](http://arxiv.org/abs/2308.15090)

    这篇论文研究了音频字幕系统和音频文本检索系统之间的关系，通过探索未经修改的音频字幕系统对音频文本检索任务的性能。研究发现，即使未进行微调，音频字幕系统在音频文本检索任务上表现出了一定的能力。

    

    自动音频字幕系统旨在开发能够用文本句子描述音频录音的系统。与此相反，音频文本检索系统旨在为给定的文本查询（文本到音频）或反之（音频到文本）找到最佳匹配的音频录音。这些任务需要不同类型的系统：音频字幕系统采用序列到序列模型，而音频文本检索系统利用在共享投射子空间内比较音频和文本表示的排序模型。然而，本研究通过探索未经修改的音频字幕系统（无需针对新任务进行微调）的音频文本检索能力，研究了音频字幕系统与音频文本检索系统之间的关系。我们的音频字幕系统包括一个在音频标记上通过AudioSet进行训练的音频编码器（ConvNeXt-Tiny），以及一个负责生成句子的变压器解码器。对于音频字幕系统，它在Clotho上的SPIDEr-FL得分平均为0.298，在AudioCaps上的得分平均为0.472。对于音频文本检索系统，我们提出使用标准的交叉熵损失值。

    Automated Audio Captioning (AAC) aims to develop systems capable of describing an audio recording using a textual sentence. In contrast, Audio-Text Retrieval (ATR) systems seek to find the best matching audio recording(s) for a given textual query (Text-to-Audio) or vice versa (Audio-to-Text). These tasks require different types of systems: AAC employs a sequence-to-sequence model, while ATR utilizes a ranking model that compares audio and text representations within a shared projection subspace. However, this work investigates the relationship between AAC and ATR by exploring the ATR capabilities of an unmodified AAC system, without fine-tuning for the new task. Our AAC system consists of an audio encoder (ConvNeXt-Tiny) trained on AudioSet for audio tagging, and a transformer decoder responsible for generating sentences. For AAC, it achieves a high SPIDEr-FL score of 0.298 on Clotho and 0.472 on AudioCaps on average. For ATR, we propose using the standard Cross-Entropy loss values ob
    
[^27]: 低资源语言的形态词义标注中的分类丧失

    Taxonomic Loss for Morphological Glossing of Low-Resource Languages. (arXiv:2308.15055v1 [cs.CL])

    [http://arxiv.org/abs/2308.15055](http://arxiv.org/abs/2308.15055)

    本文提出了一种利用形态信息的分类损失函数，在低资源语言的形态词义标注中提高了性能。 尽管在单标签预测准确性方面不如标准损失函数，但在前n个预测标签方面表现更好。 这个方法在人机协作标注方面具有潜力。

    

    形态词义标注是自动语言文档中的关键任务，它可以极大地提高其他下游应用的效果。尽管目前最先进的标注系统在数据丰富的语言上表现非常好，但在低资源语言上创建有用的模型更加困难。在本文中，我们提出了一种利用形态信息的分类损失函数，在数据稀缺的情况下，使形态词义标注的性能更好。我们发现，尽管使用这种损失函数在单标签预测准确性方面表现不如标准损失函数，但在考虑前n个预测标签时，它产生更好的预测。我们认为这种性质使得分类损失函数在人机协作标注的环境中有用。

    Morpheme glossing is a critical task in automated language documentation and can benefit other downstream applications greatly. While state-of-the-art glossing systems perform very well for languages with large amounts of existing data, it is more difficult to create useful models for low-resource languages. In this paper, we propose the use of a taxonomic loss function that exploits morphological information to make morphological glossing more performant when data is scarce. We find that while the use of this loss function does not outperform a standard loss function with regards to single-label prediction accuracy, it produces better predictions when considering the top-n predicted labels. We suggest this property makes the taxonomic loss function useful in a human-in-the-loop annotation setting.
    
[^28]: 适应口语对话的文本对话状态跟踪器

    Adapting text-based dialogue state tracker for spoken dialogues. (arXiv:2308.15053v1 [cs.CL])

    [http://arxiv.org/abs/2308.15053](http://arxiv.org/abs/2308.15053)

    这篇论文描述了对构建适应口语对话系统的文本对话状态跟踪器进行的工程工作，利用自动语音识别错误校正和文本对话系统实现了插槽和值的估计。

    

    尽管通过对话系统技术竞赛（DSTC）取得了显著进展，但构建一个具有语音界面的稳健的任务导向对话系统仍然是一个关键挑战。大部分进展都是针对基于文本的对话系统，因为有丰富的书面语料库数据集，而具有口语对话的数据集非常稀缺。然而，正如Siri和Alexa等语音助手系统所展示的，将这种成功转移到口语对话中具有实际重要性。在本文中，我们描述了我们在DSTC11的具有语音感知的对话系统技术挑战赛中的高度成功模型的工程努力。我们的模型由三个主要模块组成：（1）自动语音识别错误校正，以弥合口语和文本话语之间的差距，（2）用于估计插槽和值的基于文本的对话系统（D3ST），该系统使用插槽描述。

    Although there have been remarkable advances in dialogue systems through the dialogue systems technology competition (DSTC), it remains one of the key challenges to building a robust task-oriented dialogue system with a speech interface. Most of the progress has been made for text-based dialogue systems since there are abundant datasets with written corpora while those with spoken dialogues are very scarce. However, as can be seen from voice assistant systems such as Siri and Alexa, it is of practical importance to transfer the success to spoken dialogues. In this paper, we describe our engineering effort in building a highly successful model that participated in the speech-aware dialogue systems technology challenge track in DSTC11. Our model consists of three major modules: (1) automatic speech recognition error correction to bridge the gap between the spoken and the text utterances, (2) text-based dialogue system (D3ST) for estimating the slots and values using slot descriptions, an
    
[^29]: 大型语言模型在概念组织上趋向人类的水平

    Large language models converge toward human-like concept organization. (arXiv:2308.15047v1 [cs.LG])

    [http://arxiv.org/abs/2308.15047](http://arxiv.org/abs/2308.15047)

    大型语言模型学会以类似于知识库的方式组织概念，这表明它们具备人类推理语义和世界知识的能力。

    

    大型语言模型在知识提取、推理和对话方面展现出人类水平的表现，但这种表现是由于记忆和模式匹配，还是反映了类似于人类推理语义和世界知识的表现仍然存在争议。知识库（如WikiData）提供了推理语义和世界知识的大规模高质量表示。我们展示了大型语言模型学会以与这些知识库中概念的组织方式惊人相似的方式组织概念。知识库模拟了集体、机构化的知识，而大型语言模型似乎从原始文本中产生了这样的知识。我们展示了更大更好的模型在概念组织上表现出更加人类化的特点，涵盖了四个语言模型系列和三个知识图谱嵌入方法。

    Large language models show human-like performance in knowledge extraction, reasoning and dialogue, but it remains controversial whether this performance is best explained by memorization and pattern matching, or whether it reflects human-like inferential semantics and world knowledge. Knowledge bases such as WikiData provide large-scale, high-quality representations of inferential semantics and world knowledge. We show that large language models learn to organize concepts in ways that are strikingly similar to how concepts are organized in such knowledge bases. Knowledge bases model collective, institutional knowledge, and large language models seem to induce such knowledge from raw text. We show that bigger and better models exhibit more human-like concept organization, across four families of language models and three knowledge graph embeddings.
    
[^30]: 用传统IR方法提高神经排名模型

    Improving Neural Ranking Models with Traditional IR Methods. (arXiv:2308.15027v1 [cs.IR])

    [http://arxiv.org/abs/2308.15027](http://arxiv.org/abs/2308.15027)

    本文研究了一种低成本的替代方法，通过将传统的TF-IDF和浅层嵌入模型结合使用，可以与基于大型Transformer模型的神经排名模型竞争，并可以提高这些模型在大规模任务上的性能。

    

    基于大型Transformer模型的神经排名方法近年来在信息检索领域引起了极大关注，并被主要商业解决方案采用。然而，它们在创建过程中计算成本高昂，并需要大量标记数据来适应特定的语料库。在本文中，我们探索了低资源替代方案，即基于嵌入模型的文档检索方法，并发现它在信息检索任务上与细调的大型Transformer模型相竞争。我们的结果表明，将传统关键字匹配方法TF-IDF与浅层嵌入模型简单结合可以以低成本追赶到复杂神经排名模型在三个数据集上的性能。此外，在这些任务上添加TF-IDF度量可以提高大规模细调模型的性能。

    Neural ranking methods based on large transformer models have recently gained significant attention in the information retrieval community, and have been adopted by major commercial solutions. Nevertheless, they are computationally expensive to create, and require a great deal of labeled data for specialized corpora. In this paper, we explore a low resource alternative which is a bag-of-embedding model for document retrieval and find that it is competitive with large transformer models fine tuned on information retrieval tasks. Our results show that a simple combination of TF-IDF, a traditional keyword matching method, with a shallow embedding model provides a low cost path to compete well with the performance of complex neural ranking models on 3 datasets. Furthermore, adding TF-IDF measures improves the performance of large-scale fine tuned models on these tasks.
    
[^31]: 递归总结在大型语言模型中实现长期对话记忆

    Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models. (arXiv:2308.15022v1 [cs.CL])

    [http://arxiv.org/abs/2308.15022](http://arxiv.org/abs/2308.15022)

    递归总结在大型语言模型中实现长期对话记忆，可以提高对话系统在长对话中记忆重要信息的能力。

    

    大多数开放领域的对话系统在长期对话中容易遗忘重要信息。现有方法通常训练特定的检索器或总结器从过去获取关键信息，这需要耗费时间且高度依赖标记数据的质量。为了缓解这个问题，我们提出使用大型语言模型（LLMs）递归生成总结/记忆，以增强长期记忆能力。具体而言，我们的方法首先刺激LLMs记住小对话上下文，然后递归地使用之前的记忆和随后的对话内容产生新的记忆。最后，LLM可以在最新记忆的帮助下轻松生成高度一致的响应。我们使用ChatGPT和text-davinci-003进行评估，对广泛使用的公共数据集进行的实验证明我们的方法在长对话中可以生成更一致的响应。值得注意的是，我们的方法是实现LLM建模的潜在解决方案。

    Most open-domain dialogue systems suffer from forgetting important information, especially in a long-term conversation. Existing works usually train the specific retriever or summarizer to obtain key information from the past, which is time-consuming and highly depends on the quality of labeled data. To alleviate this problem, we propose to recursively generate summaries/ memory using large language models (LLMs) to enhance long-term memory ability. Specifically, our method first stimulates LLMs to memorize small dialogue contexts and then recursively produce new memory using previous memory and following contexts. Finally, the LLM can easily generate a highly consistent response with the help of the latest memory. We evaluate our method using ChatGPT and text-davinci-003, and the experiments on the widely-used public dataset show that our method can generate more consistent responses in a long-context conversation. Notably, our method is a potential solution to enable the LLM to model
    
[^32]: TransPrompt v2: 一种用于跨任务文本分类的可转移提示框架

    TransPrompt v2: A Transferable Prompting Framework for Cross-task Text Classification. (arXiv:2308.15010v1 [cs.CL])

    [http://arxiv.org/abs/2308.15010](http://arxiv.org/abs/2308.15010)

    TransPrompt v2是一种可转移的提示框架，适用于跨任务文本分类。它通过多任务元知识获取来训练一个捕捉跨任务可转移知识的元学习器，以提升预训练语言模型在少样本学习中的性能。

    

    文本分类是自然语言处理中最重要的任务之一。最近使用预训练语言模型（PLMs）取得了在这个任务上显著的成功。然而，PLMs获得满意的结果很大程度上取决于大量的任务特定标注数据，而在许多应用场景中，由于数据访问和隐私限制，这可能是不可行的。最近提出的基于提示的微调范式通过任务特定模板提高了PLMs在少样本文本分类中的性能。然而，目前还不清楚提示知识如何在任务之间进行传递，以实现相互增强的目的。我们提出了TransPrompt v2，一种新颖的可转移提示框架，适用于相似或不同的少样本学习文本分类任务。对于相似任务的学习，我们采用多任务元知识获取（MMA）过程来训练一个捕捉跨任务可转移知识的元学习器。

    Text classification is one of the most imperative tasks in natural language processing (NLP). Recent advances with pre-trained language models (PLMs) have shown remarkable success on this task. However, the satisfying results obtained by PLMs heavily depend on the large amounts of task-specific labeled data, which may not be feasible in many application scenarios due to data access and privacy constraints. The recently-proposed prompt-based fine-tuning paradigm improves the performance of PLMs for few-shot text classification with task-specific templates. Yet, it is unclear how the prompting knowledge can be transferred across tasks, for the purpose of mutual reinforcement. We propose TransPrompt v2, a novel transferable prompting framework for few-shot learning across similar or distant text classification tasks. For learning across similar tasks, we employ a multi-task meta-knowledge acquisition (MMA) procedure to train a meta-learner that captures the cross-task transferable knowled
    
[^33]: 鲁棒的开放集言语识别和CU MultiLang数据集

    Robust Open-Set Spoken Language Identification and the CU MultiLang Dataset. (arXiv:2308.14951v1 [cs.CL])

    [http://arxiv.org/abs/2308.14951](http://arxiv.org/abs/2308.14951)

    本文实现了一种鲁棒的开放集言语识别系统，通过使用MFCC和音高特征，TDNN模型提取特征嵌入，设置置信度阈值，以及使用LDA和pLDA学习新的未知语言分类来实现。在经过训练的语言上，系统准确率达到91.76%，并且具备实时适应未知语言的能力。

    

    大多数最先进的言语识别模型是闭集的，即它们只能输出它们在训练时使用的类别集合中的语言标签。然而，开放集言语识别系统具备检测输入是否不属于原始语言的能力。本文实现了一种新颖的开放集言语识别方法，该方法使用MFCC和音高特征， TDNN模型提取有意义的特征嵌入，通过对softmax输出进行置信度阈值处理，以及使用LDA和pLDA学习对新的未知语言进行分类。我们提出了一个言语识别系统，其在经过训练的语言上实现了91.76%的准确率，并具备实时适应未知语言的能力。为此，我们还构建了CU MultiLang数据集，这是一个大规模多样化的多语言语音语料库，用于训练和评估我们的系统。

    Most state-of-the-art spoken language identification models are closed-set; in other words, they can only output a language label from the set of classes they were trained on. Open-set spoken language identification systems, however, gain the ability to detect when an input exhibits none of the original languages. In this paper, we implement a novel approach to open-set spoken language identification that uses MFCC and pitch features, a TDNN model to extract meaningful feature embeddings, confidence thresholding on softmax outputs, and LDA and pLDA for learning to classify new unknown languages. We present a spoken language identification system that achieves 91.76% accuracy on trained languages and has the capability to adapt to unknown languages on the fly. To that end, we also built the CU MultiLang Dataset, a large and diverse multilingual speech corpus which was used to train and evaluate our system.
    
[^34]: 大型语言模型中的性别偏见和刻板印象

    Gender bias and stereotypes in Large Language Models. (arXiv:2308.14921v1 [cs.CL])

    [http://arxiv.org/abs/2308.14921](http://arxiv.org/abs/2308.14921)

    研究发现大型语言模型存在性别偏见和刻板印象，它们更倾向于选择与个人性别刻板印象一致的职业，并且放大了偏见，超过了现实情况。

    

    在过去几个月中，大型语言模型（LLMs）取得了显著的进展，在许多领域打破了最先进的测试基准。本文研究LLMs在性别刻板印象方面的行为，这是先前模型中已知的一个问题。我们使用一个简单的范例来测试性别偏见的存在，这一范例建立在但与WinoBias不同，后者是一个常用的性别偏见数据集，很可能包含在目前LLMs的训练数据中。我们测试了四个最近发布的LLMs，并证明它们在男性和女性职业方面表现出有偏见的假设。本文的贡献如下：（a）LLMs在选择与人的性别刻板印象一致的职业时的概率是3-6倍；（b）这些选择与人们的感知更加一致，而不是与官方职业统计数据的真实情况一致；（c）事实上，LLMs放大了偏见，超过了人们的感知或真实情况；（d）LLMs忽视了关键的歧义

    Large Language Models (LLMs) have made substantial progress in the past several months, shattering state-of-the-art benchmarks in many domains. This paper investigates LLMs' behavior with respect to gender stereotypes, a known issue for prior models. We use a simple paradigm to test the presence of gender bias, building on but differing from WinoBias, a commonly used gender bias dataset, which is likely to be included in the training data of current LLMs. We test four recently published LLMs and demonstrate that they express biased assumptions about men and women's occupations. Our contributions in this paper are as follows: (a) LLMs are 3-6 times more likely to choose an occupation that stereotypically aligns with a person's gender; (b) these choices align with people's perceptions better than with the ground truth as reflected in official job statistics; (c) LLMs in fact amplify the bias beyond what is reflected in perceptions or the ground truth; (d) LLMs ignore crucial ambiguities 
    
[^35]: 语音内容嵌入的神经方法

    Neural approaches to spoken content embedding. (arXiv:2308.14905v1 [cs.CL])

    [http://arxiv.org/abs/2308.14905](http://arxiv.org/abs/2308.14905)

    该论文研究了语音内容嵌入的神经方法。传统方法限制了性能和效率，因此提出了声学词嵌入作为替代。论文提出了单视图和多视图训练损失的方法，并探讨了声学词嵌入在实际任务中的应用。

    

    比较语音片段是语音处理中的核心操作。传统方法倾向于使用帧级动态规划算法（如动态时间规整），因为它们不需要监督，但在性能和效率上有局限性。作为替代，声学词嵌入——可变长度的语音词段的固定维度向量表示——开始被考虑用于这些任务。然而，当前仅限于这种鉴别性嵌入模型、训练方法以及其在实际下游任务中的应用。我们首先考虑“单视图”训练损失，目标是学习一种声学词嵌入模型，可以将相同词和不同词的语音段配对区分开。然后，我们考虑“多视图”对比损失。在这种设置中，声学词嵌入与字符序列的嵌入一起学习，以生成基于声学的嵌入。

    Comparing spoken segments is a central operation to speech processing. Traditional approaches in this area have favored frame-level dynamic programming algorithms, such as dynamic time warping, because they require no supervision, but they are limited in performance and efficiency. As an alternative, acoustic word embeddings -- fixed-dimensional vector representations of variable-length spoken word segments -- have begun to be considered for such tasks as well. However, the current space of such discriminative embedding models, training approaches, and their application to real-world downstream tasks is limited. We start by considering ``single-view" training losses where the goal is to learn an acoustic word embedding model that separates same-word and different-word spoken segment pairs. Then, we consider ``multi-view" contrastive losses. In this setting, acoustic word embeddings are learned jointly with embeddings of character sequences to generate acoustically grounded embeddings o
    
[^36]: MEMORY-VQ：用于可操作的互联网规模内存的压缩

    MEMORY-VQ: Compression for Tractable Internet-Scale Memory. (arXiv:2308.14903v1 [cs.CL])

    [http://arxiv.org/abs/2308.14903](http://arxiv.org/abs/2308.14903)

    MEMORY-VQ是一种使用向量量化压缩方法来减少内存增强模型存储需求的新方法，不牺牲性能。应用于LUMEN模型后，LUMEN-VQ在KILT基准测试上获得了16倍的压缩率，使得对于极大的检索语料库而言实现实际的检索增强成为可能。

    

    检索增强是使语言模型更加了解世界的一种强大但昂贵的方法。像LUMEN这样的基于内存的方法通过预计算检索到的段落的令牌表示来大大加快推理速度。然而，内存也导致了更大的存储需求，用于存储预计算的表示。我们提出了MEMORY-VQ，一种新的方法来减少内存增强模型的存储需求，同时不牺牲性能。我们的方法使用向量量化变分自动编码器（VQ-VAE）来压缩令牌表示。我们将MEMORY-VQ应用于LUMEN模型，得到了LUMEN-VQ，这是一个在KILT基准测试中具有可比性能的内存模型，压缩率为16倍。LUMEN-VQ使得即使对于非常大的检索语料库，实际的检索增强也变得可行。

    Retrieval augmentation is a powerful but expensive method to make language models more knowledgeable about the world. Memory-based methods like LUMEN pre-compute token representations for retrieved passages to drastically speed up inference. However, memory also leads to much greater storage requirements from storing pre-computed representations.  We propose MEMORY-VQ, a new method to reduce storage requirements of memory-augmented models without sacrificing performance. Our method uses a vector quantization variational autoencoder (VQ-VAE) to compress token representations. We apply MEMORY-VQ to the LUMEN model to obtain LUMEN-VQ, a memory model that achieves a 16x compression rate with comparable performance on the KILT benchmark. LUMEN-VQ enables practical retrieval augmentation even for extremely large retrieval corpora.
    
[^37]: 用于紧急呼叫中心对话中的语音情绪识别的多尺度上下文学习

    Multiscale Contextual Learning for Speech Emotion Recognition in Emergency Call Center Conversations. (arXiv:2308.14894v1 [cs.CL])

    [http://arxiv.org/abs/2308.14894](http://arxiv.org/abs/2308.14894)

    本文介绍了一种用于语音情绪识别的多尺度对话上下文学习方法，该方法在紧急呼叫中心对话中取得了较好的效果。通过分析对话中的情绪流动并利用上下文信息，提高了情绪识别的准确性和鲁棒性。

    

    对话中的情绪识别对于确保先进的人机交互至关重要。然而，在现实生活中创建稳健准确的情绪识别系统是具有挑战性的，主要是由于野外情绪数据集的稀缺性以及无法考虑对话上下文。CEMO数据集填补了这一空白，该数据集由法国呼叫中心的代理人和患者之间的紧急呼叫对话组成。这些互动的性质突出了对话中情绪流的作用，可以在理解实际感受方面通常产生差异。本文提出了一种多尺度对话上下文学习方法进行语音情绪识别，利用了这个假设。我们在语音转录和声学片段上对这种方法进行了研究。实验方法使用了目标片段的前一段或后一段信息。

    Emotion recognition in conversations is essential for ensuring advanced human-machine interactions. However, creating robust and accurate emotion recognition systems in real life is challenging, mainly due to the scarcity of emotion datasets collected in the wild and the inability to take into account the dialogue context. The CEMO dataset, composed of conversations between agents and patients during emergency calls to a French call center, fills this gap. The nature of these interactions highlights the role of the emotional flow of the conversation in predicting patient emotions, as context can often make a difference in understanding actual feelings. This paper presents a multi-scale conversational context learning approach for speech emotion recognition, which takes advantage of this hypothesis. We investigated this approach on both speech transcriptions and acoustic segments. Experimentally, our method uses the previous or next information of the targeted segment. In the text domai
    
[^38]: CommunityFish: 一种基于泊松分布的层次聚类文本缩放方法

    CommunityFish: A Poisson-based Document Scaling With Hierarchical Clustering. (arXiv:2308.14873v1 [cs.CL])

    [http://arxiv.org/abs/2308.14873](http://arxiv.org/abs/2308.14873)

    本文介绍了一种新的文本缩放方法CommunityFish，它利用层次聚类算法在词空间上聚类，从而揭示文本数据中独立词组（社区）的差异。

    

    文本缩放是社会科学家和政治研究人员在文本数据应用中的关键组成部分，也是一种重要的研究领域。本文介绍了一种新的文本缩放方法CommunityFish，它基于层次聚类算法Louvain，在词空间上进行聚类，通过识别共现在文档中的独立词组（称为社区），从而揭示演讲者或政党之间的差异。

    Document scaling has been a key component in text-as-data applications for social scientists and a major field of interest for political researchers, who aim at uncovering differences between speakers or parties with the help of different probabilistic and non-probabilistic approaches. Yet, most of these techniques are either built upon the agnostically bag-of-word hypothesis or use prior information borrowed from external sources that might embed the results with a significant bias. If the corpus has long been considered as a collection of documents, it can also be seen as a dense network of connected words whose structure could be clustered to differentiate independent groups of words, based on their co-occurrences in documents, known as communities. This paper introduces CommunityFish as an augmented version of Wordfish based on a hierarchical clustering, namely the Louvain algorithm, on the word space to yield communities as semantic and independent n-grams emerging from the corpus
    
[^39]: Attention Visualizer Package:揭示编码器-只有的Transformer模型中单词重要性的注意力可视化工具

    Attention Visualizer Package: Revealing Word Importance for Deeper Insight into Encoder-Only Transformer Models. (arXiv:2308.14850v1 [cs.CL])

    [http://arxiv.org/abs/2308.14850](http://arxiv.org/abs/2308.14850)

    这个论文介绍了Attention Visualizer包，通过可视化展示单词在编码器-只有的Transformer模型中的重要性，提高了对神经网络的解释性和可解释性。

    

    本文介绍了Attention Visualizer包，该包用于视觉化展示编码器-只有的Transformer模型中个别单词的重要性。与其他关注标记和自注意力分数的方法相比，我们的方法将研究单词及其对最终嵌入表示的影响。这样的库在增强神经网络的解释性和可解释性方面起着关键作用。它们提供了了解其内部机制、提高其性能的更好理解的机会。您可以访问以下GitHub存储库获取代码并查看示例：https://github.com/AlaFalaki/AttentionVisualizer。

    This report introduces the Attention Visualizer package, which is crafted to visually illustrate the significance of individual words in encoder-only transformer-based models. In contrast to other methods that center on tokens and self-attention scores, our approach will examine the words and their impact on the final embedding representation. Libraries like this play a crucial role in enhancing the interpretability and explainability of neural networks. They offer the opportunity to illuminate their internal mechanisms, providing a better understanding of how they operate and can be enhanced. You can access the code and review examples on the following GitHub repository: https://github.com/AlaFalaki/AttentionVisualizer.
    
[^40]: VoiceBank-2023：一个用于构建面向语言障碍患者的个性化中文TTS系统的多说话人普通话语音语料库

    VoiceBank-2023: A Multi-Speaker Mandarin Speech Corpus for Constructing Personalized TTS Systems for the Speech Impaired. (arXiv:2308.14763v1 [eess.AS])

    [http://arxiv.org/abs/2308.14763](http://arxiv.org/abs/2308.14763)

    VoiceBank-2023是用于构建个性化中文TTS系统的多说话人普通话语音语料库，可以为语言障碍患者提供个性化服务。该语料库包括111个说普通话的说话人的29.78小时的语音数据，以及性别、语言障碍程度等信息。语料库欢迎非商业用途申请使用，支持改进VoiceBanking项目的服务。

    

    针对普通话患有语言障碍的个性化TTS系统服务很少被提及。台湾在2020年启动了VoiceBanking项目，旨在建立一个完整的服务体系，为肌萎缩侧索硬化症患者提供个性化的普通话TTS系统。本文报告了VoiceBanking项目的语料库设计、语料库录制、数据清理和校正以及个性化TTS系统的评估。该语料库被命名为VoiceBank-2023语音语料库，因为它的发布年份是2023年。语料库包括111个以普通话为母语的说话人朗读的短段落和常用短语的语音，共计29.78小时。语料库还带有关于性别、语言障碍程度、用户类型、转录、信噪比和说话速度的信息标注。VoiceBank-2023语料库可供非商业用途申请使用，并欢迎各方加入VoiceBanking项目以改善服务。

    Services of personalized TTS systems for the Mandarin-speaking speech impaired are rarely mentioned. Taiwan started the VoiceBanking project in 2020, aiming to build a complete set of services to deliver personalized Mandarin TTS systems to amyotrophic lateral sclerosis patients. This paper reports the corpus design, corpus recording, data purging and correction for the corpus, and evaluations of the developed personalized TTS systems, for the VoiceBanking project. The developed corpus is named after the VoiceBank-2023 speech corpus because of its release year. The corpus contains 29.78 hours of utterances with prompts of short paragraphs and common phrases spoken by 111 native Mandarin speakers. The corpus is labeled with information about gender, degree of speech impairment, types of users, transcription, SNRs, and speaking rates. The VoiceBank-2023 is available by request for non-commercial use and welcomes all parties to join the VoiceBanking project to improve the services for the
    
[^41]: 基于GPT-3的医疗对话代理的挑战

    Challenges of GPT-3-based Conversational Agents for Healthcare. (arXiv:2308.14641v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.14641](http://arxiv.org/abs/2308.14641)

    本文研究了使用基于GPT-3的模型进行医学问答系统（MedQA）的挑战和风险。通过上下文化的分析和手动设计患者查询的压力测试，我们发现这些模型无法充分回应高风险限制，可能导致错误的医学信息、不安全的建议和冒犯性内容。

    

    医疗领域的对话代理具有提供患者更快信息访问的潜力，同时让医学专家专注于关键任务。然而，将大型语言模型（LLMs）整合到这些代理中存在一定的限制，可能导致严重后果。本文研究了在医学问答（MedQA）系统中使用基于GPT-3模型的挑战和风险。我们对几个评估进行了上下文化的分析，基于标准的医学原则。我们提供了手动设计患者查询的过程，以对LLMs在MedQA系统中的高风险限制进行压力测试。我们的分析揭示了LLMs无法对这些查询做出充分的回应，会生成错误的医学信息、不安全的建议以及可能被认为是冒犯性的内容。

    The potential to provide patients with faster information access while allowing medical specialists to concentrate on critical tasks makes medical domain dialog agents appealing. However, the integration of large-language models (LLMs) into these agents presents certain limitations that may result in serious consequences. This paper investigates the challenges and risks of using GPT-3-based models for medical question-answering (MedQA). We perform several evaluations contextualized in terms of standard medical principles. We provide a procedure for manually designing patient queries to stress-test high-risk limitations of LLMs in MedQA systems. Our analysis reveals that LLMs fail to respond adequately to these queries, generating erroneous medical information, unsafe recommendations, and content that may be considered offensive.
    
[^42]: 授权临床医生并民主化数据科学：大型语言模型自动化临床研究的机器学习。 (arXiv:2308.14120v2 [cs.LG] 更新版)

    Empowering Clinicians and Democratizing Data Science: Large Language Models Automate Machine Learning for Clinical Studies. (arXiv:2308.14120v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2308.14120](http://arxiv.org/abs/2308.14120)

    chatGPT ADA是一种能够自主开发临床研究所需的最先进的机器学习模型的大型语言模型，可将高级分析工具民主化，使非数据科学家的临床医生能够轻松应用于医学领域。

    

    机器学习（ML）开发者（如数据科学家）和从业者（如临床医生）之间存在知识差距，阻碍了ML在临床数据分析中的充分利用。我们研究了chatGPT Advanced Data Analysis（ADA），即GPT-4的扩展，来弥合这一差距并高效执行ML分析的潜力。我们向chatGPT ADA提供了各种医学专业的大型试验的真实临床数据和研究详细信息，没有给出具体指导。ChatGPT ADA基于原始研究的训练数据自主开发了最先进的ML模型，用于预测临床结果，如癌症发展、癌症进展、疾病并发症或致病基因序列等生物标志物。令人惊讶的是，这些ML模型与其已发表的对应物相匹配甚至表现更好。我们得出结论，chatGPT ADA为民主化医学中的ML提供了一个有前景的途径，使非ML专家能够获得先进的分析工具并推动广泛应用。

    A knowledge gap persists between Machine Learning (ML) developers (e.g., data scientists) and practitioners (e.g., clinicians), hampering the full utilization of ML for clinical data analysis. We investigated the potential of the chatGPT Advanced Data Analysis (ADA), an extension of GPT-4, to bridge this gap and perform ML analyses efficiently. Real-world clinical datasets and study details from large trials across various medical specialties were presented to chatGPT ADA without specific guidance. ChatGPT ADA autonomously developed state-of-the-art ML models based on the original study's training data to predict clinical outcomes such as cancer development, cancer progression, disease complications, or biomarkers such as pathogenic gene sequences. Strikingly, these ML models matched or outperformed their published counterparts. We conclude that chatGPT ADA offers a promising avenue to democratize ML in medicine, making advanced analytics accessible to non-ML experts and promoting broa
    
[^43]: 超越文档页分类：设计、数据集和挑战

    Beyond Document Page Classification: Design, Datasets, and Challenges. (arXiv:2308.12896v1 [cs.CV])

    [http://arxiv.org/abs/2308.12896](http://arxiv.org/abs/2308.12896)

    本文强调了将文档分类基准测试更接近于现实世界应用的需求，通过提出多页文档分类数据集和不同分类任务，以及高效的多页文档表示，来解决现有基准测试不适用于实际完整文档评估的问题。

    

    本文强调了将文档分类基准测试更接近于现实世界应用的需求，即在测试数据的性质上（$X$：多通道、多页、多行业；$Y$：类别分布和标签集的多样性）和考虑的分类任务上（$f$：多页文档、页面流和文档捆绑分类，...）。我们确定了公共的多页文档分类数据集的缺乏，并规范了应用场景中产生的不同分类任务，并激发了以高效的多页文档表示为目标的价值。对提出的多页文档分类数据集进行的实验研究表明，当前的基准测试已经变得无关紧要，并需要更新以评估实际中自然发生的完整文档。这个现实情况检查也呼吁更成熟的评估方法，涵盖校准评估、推理复杂性（时间-内存）和一系列现实分散情况。

    This paper highlights the need to bring document classification benchmarking closer to real-world applications, both in the nature of data tested ($X$: multi-channel, multi-paged, multi-industry; $Y$: class distributions and label set variety) and in classification tasks considered ($f$: multi-page document, page stream, and document bundle classification, ...). We identify the lack of public multi-page document classification datasets, formalize different classification tasks arising in application scenarios, and motivate the value of targeting efficient multi-page document representations. An experimental study on proposed multi-page document classification datasets demonstrates that current benchmarks have become irrelevant and need to be updated to evaluate complete documents, as they naturally occur in practice. This reality check also calls for more mature evaluation methodologies, covering calibration evaluation, inference complexity (time-memory), and a range of realistic distr
    
[^44]: 中古高地德语的跨语言短语结构分析：一种去词法化的方法

    Cross-Lingual Constituency Parsing for Middle High German: A Delexicalized Approach. (arXiv:2308.04645v1 [cs.CL])

    [http://arxiv.org/abs/2308.04645](http://arxiv.org/abs/2308.04645)

    本研究通过利用中古高地德语和现代德语的语言连续性和结构相似性，以及现有的现代德语树库资源，构建了一种适用于中古高地德语的短语结构分析器，无需依赖标注的MHG树库资源。

    

    短语结构分析在推动自然语言处理（NLP）任务中起着基础性的作用。然而，仅依靠标注的解析数据训练古代语言的自动句法分析系统是一项艰巨的任务，因为构建这些语言的树库存在固有挑战。这需要丰富的语言专业知识，导致可用资源的稀缺。为了克服这个障碍，跨语言转移技术为低资源目标语言提供了一种有希望的解决方案，这些技术需要最少甚至没有标注数据。在本研究中，我们着重于构建适用于中古高地德语（MHG）的短语结构分析器，在缺乏标注的MHG树库进行训练的现实条件下。在我们的方法中，我们利用MHG和现代德语（MG）之间的语言连续性和结构相似性，以及丰富的MG树库资源。

    Constituency parsing plays a fundamental role in advancing natural language processing (NLP) tasks. However, training an automatic syntactic analysis system for ancient languages solely relying on annotated parse data is a formidable task due to the inherent challenges in building treebanks for such languages. It demands extensive linguistic expertise, leading to a scarcity of available resources. To overcome this hurdle, cross-lingual transfer techniques which require minimal or even no annotated data for low-resource target languages offer a promising solution. In this study, we focus on building a constituency parser for $\mathbf{M}$iddle $\mathbf{H}$igh $\mathbf{G}$erman $\mathbf{MHG}$ under realistic conditions, where no annotated MHG treebank is available for training. In our approach, we leverage the linguistic continuity and structural similarity between MHG and $\mathbf{M}$odern $\mathbf{G}$erman $\mathbf{MG}$, along with the abundance of MG treebank resources. Specifically, b
    
[^45]: NBIAS: 用于文本中偏见识别的自然语言处理框架

    NBIAS: A Natural Language Processing Framework for Bias Identification in Text. (arXiv:2308.01681v1 [cs.CL])

    [http://arxiv.org/abs/2308.01681](http://arxiv.org/abs/2308.01681)

    本论文提出了一个名为NBIAS的自然语言处理框架，旨在识别文本中的偏见。通过收集来自社交媒体、医疗保健和职位招聘等领域的多样化数据构建数据集，并应用基于Transformer的令牌分类模型来识别偏见词/短语。通过定量和定性评估方法来评估模型的效果。

    

    在文本数据中存在偏见可能导致数据使用时产生倾斜的解释和结果。这些偏见可能会持续强化刻板印象、歧视或其他形式的不公平待遇。在有偏见的数据上训练的算法最终会做出不平等影响某个群体的决策。因此，检测和消除这些偏见至关重要，以确保对数据的公平和道德使用。为此，我们开发了一个全面而强大的框架"NBIAS"，它包括数据层、语料库构建、模型开发层和评估层。数据集由从各个领域收集的多样化数据构建，包括社交媒体、医疗保健和职位招聘门户网站。因此，我们应用了基于Transformer的令牌分类模型，通过一个唯一的命名实体能够识别出偏见词/短语。在评估过程中，我们结合了定量和定性评估方法来评估我们模型的效果。

    Bias in textual data can lead to skewed interpretations and outcomes when the data is used. These biases could perpetuate stereotypes, discrimination, or other forms of unfair treatment. An algorithm trained on biased data ends up making decisions that disproportionately impact a certain group of people. Therefore, it is crucial to detect and remove these biases to ensure the fair and ethical use of data. To this end, we develop a comprehensive and robust framework \textsc{Nbias} that consists of a data layer, corpus contruction, model development layer and an evaluation layer. The dataset is constructed by collecting diverse data from various fields, including social media, healthcare, and job hiring portals. As such, we applied a transformer-based token classification model that is able to identify bias words/ phrases through a unique named entity. In the assessment procedure, we incorporate a blend of quantitative and qualitative evaluations to gauge the effectiveness of our models.
    
[^46]: 揭示在LLM中职业性别偏见：分析和解决社会学影响

    Unveiling Gender Bias in Terms of Profession Across LLMs: Analyzing and Addressing Sociological Implications. (arXiv:2307.09162v1 [cs.CL])

    [http://arxiv.org/abs/2307.09162](http://arxiv.org/abs/2307.09162)

    本研究分析了大型语言模型中的性别偏见，以GPT-2和GPT-3.5为例，通过全面的文献综述和深入的定量分析揭示了存在的性别化词语关联、语言使用和偏见叙述，并探讨了性别偏见可能对社会认知产生的伦理影响。

    

    人工智能（AI）和自然语言处理中的性别偏见引起了广泛关注，因为它可能对社会认知和偏见产生影响。这篇研究旨在分析大型语言模型（LLMs）中的性别偏见，重点比较了GPT-2和GPT-3.5这些著名语言模型，以更好地理解其影响。通过全面的文献综述，该研究考察了现有关于AI语言模型中性别偏见的研究，并确定了当前知识的空白。研究方法包括收集和预处理GPT-2和GPT-3.5的数据，并运用深入的定量分析技术评估生成文本中的性别偏见。研究结果揭示了这些大型语言模型输出中存在的具有性别色彩的词语关联、语言使用和偏见叙述。讨论部分探讨了性别偏见的伦理影响以及其对社会认知的潜在后果。

    Gender bias in artificial intelligence (AI) and natural language processing has garnered significant attention due to its potential impact on societal perceptions and biases. This research paper aims to analyze gender bias in Large Language Models (LLMs) with a focus on multiple comparisons between GPT-2 and GPT-3.5, some prominent language models, to better understand its implications. Through a comprehensive literature review, the study examines existing research on gender bias in AI language models and identifies gaps in the current knowledge. The methodology involves collecting and preprocessing data from GPT-2 and GPT-3.5, and employing in-depth quantitative analysis techniques to evaluate gender bias in the generated text. The findings shed light on gendered word associations, language usage, and biased narratives present in the outputs of these Large Language Models. The discussion explores the ethical implications of gender bias and its potential consequences on social percepti
    
[^47]: 使用CNN-LSTM模型对波斯推特的政治情感进行分析

    Political Sentiment Analysis of Persian Tweets Using CNN-LSTM Model. (arXiv:2307.07740v1 [cs.CL])

    [http://arxiv.org/abs/2307.07740](http://arxiv.org/abs/2307.07740)

    本论文使用CNN-LSTM模型对波斯推特的政治情感进行分析，使用ParsBERT进行词汇表示，并比较了机器学习和深度学习模型的效果。实验结果表明，深度学习模型表现更好，其中CNN-LSTM模型在两个数据集上分别达到了89%和71%的分类准确率。

    

    情感分析是识别和分类人们对各种话题的情感或观点的过程。近年来，对Twitter情感的分析成为一个越来越受欢迎的话题。在本文中，我们提出了几种机器学习和深度学习模型，用于分析波斯政治推特的情感。我们使用词袋模型和ParsBERT进行词汇表示的分析。我们应用了高斯朴素贝叶斯、梯度提升、逻辑回归、决策树、随机森林以及CNN和LSTM的组合来分类推特的极性。本研究的结果表明，使用ParsBERT嵌入的深度学习模型比机器学习表现更好。CNN-LSTM模型在第一个有三种类别的数据集上的分类准确率为89％，在第二个有七种类别的数据集上的分类准确率为71％。由于波斯语的复杂性，达到这一效率水平是一项困难的任务。

    Sentiment analysis is the process of identifying and categorizing people's emotions or opinions regarding various topics. The analysis of Twitter sentiment has become an increasingly popular topic in recent years. In this paper, we present several machine learning and a deep learning model to analysis sentiment of Persian political tweets. Our analysis was conducted using Bag of Words and ParsBERT for word representation. We applied Gaussian Naive Bayes, Gradient Boosting, Logistic Regression, Decision Trees, Random Forests, as well as a combination of CNN and LSTM to classify the polarities of tweets. The results of this study indicate that deep learning with ParsBERT embedding performs better than machine learning. The CNN-LSTM model had the highest classification accuracy with 89 percent on the first dataset with three classes and 71 percent on the second dataset with seven classes. Due to the complexity of Persian, it was a difficult task to achieve this level of efficiency.
    
[^48]: 大型语言模型被误导：使用Only Connect Wall数据集探索创造性问题解决和Einstellung效应。

    Large Language Models are Fixated by Red Herrings: Exploring Creative Problem Solving and Einstellung Effect using the Only Connect Wall Dataset. (arXiv:2306.11167v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.11167](http://arxiv.org/abs/2306.11167)

    这项研究探索了大型语言模型（LLMs）对创造性问题解决的能力，并发现大型语言模型容易被误导，出现固定效应和Einstellung范式。

    

    自从人工智能诞生以来，对人类仿真智能的追求一直是人工智能研究的持久话题。最新一代的大型语言模型（LLM）的技术演进和新兴能力将这个主题从学术界带到了文化时代。尽管最近的NLP评估基准任务测试了人类仿真行为的一些方面（例如BIG-bench的“类人行为”任务），但几乎没有一个任务考察创造性问题解决能力。人类的创造性问题解决是认知神经科学中研究较为深入的主题，标准化测试主要使用将线索词之间的（异构）连接能力作为创造性的度量。在这样的任务中，暗示性的误导性刺激-被称为“诱导误解”的干扰因素-通过固定效应和Einstellung范式阻碍了人类的表现。在认知神经科学的研究中，通过事先让参与者接触到有相似拼写的错误因素来实验性地诱导这样的固定。

    The quest for human imitative AI has been an enduring topic in AI research since its inception. The technical evolution and emerging capabilities of the latest cohort of large language models (LLMs) have reinvigorated the subject beyond academia to the cultural zeitgeist. While recent NLP evaluation benchmark tasks test some aspects of human-imitative behaviour (e.g., BIG-bench's 'human-like behavior' tasks), few, if not none, examine creative problem solving abilities. Creative problem solving in humans is a well-studied topic in cognitive neuroscience with standardized tests that predominantly use the ability to associate (heterogeneous) connections among clue words as a metric for creativity. Exposure to misleading stimuli - distractors dubbed red herrings - impede human performance in such tasks via the fixation effect and Einstellung paradigm. In cognitive neuroscience studies, such fixations are experimentally induced by pre-exposing participants to orthographically similar incor
    
[^49]: 块状态变换器

    Block-State Transformer. (arXiv:2306.09539v1 [cs.CL])

    [http://arxiv.org/abs/2306.09539](http://arxiv.org/abs/2306.09539)

    本文提出了一种名为块状态变换器（BST）的混合神经网络层，结合了状态空间模型和块变换器，旨在在语言建模任务中提高性能和可扩展性。实验证明，该模型在语言建模困惑度上优于类似的基于Transformer的架构，并且可以推广到更长的序列。此外，在层级别上具有超过十倍的速度提升。

    

    状态空间模型（SSM）在需要建模长期依赖性并且需要高效扩展到长序列的任务中显示出了惊人的效果。尽管最初是为连续信号设计的，但SSM在视觉和音频等许多任务中表现出了优异的性能；然而，在语言建模任务中，SSM仍然落后于Transformers的性能。在这项工作中，我们提出了一个名为块状态变换器（BST）的混合层，它在内部组合了一个用于长距离上下文化的SSM子层和一个用于短期序列表示的块变换器子层。我们研究了三种不同的、完全可并行的集成SSM和块注意力的变体。我们证明了我们的模型在语言建模的困惑度上优于类似的基于Transformer的架构，并且可以推广到更长的序列。此外，块状态变换器在层级别上具有超过十倍的速度提升。

    State space models (SSMs) have shown impressive results on tasks that require modeling long-range dependencies and efficiently scale to long sequences owing to their subquadratic runtime complexity. Originally designed for continuous signals, SSMs have shown superior performance on a plethora of tasks, in vision and audio; however, SSMs still lag Transformer performance in Language Modeling tasks. In this work, we propose a hybrid layer named Block-State Transformer (BST), that internally combines an SSM sublayer for long-range contextualization, and a Block Transformer sublayer for short-term representation of sequences. We study three different, and completely parallelizable, variants that integrate SSMs and block-wise attention. We show that our model outperforms similar Transformer-based architectures on language modeling perplexity and generalizes to longer sequences. In addition, the Block-State Transformer demonstrates more than tenfold increase in speed at the layer level compa
    
[^50]: Mol-Instructions: 一个大规模生物分子指令数据集，为大语言模型提供支持

    Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models. (arXiv:2306.08018v1 [q-bio.QM])

    [http://arxiv.org/abs/2306.08018](http://arxiv.org/abs/2306.08018)

    Mol-Instructions是一个专门为生物分子领域设计的综合指令数据集，可以显著提高大语言模型在生物领域中的适应能力和认知敏锐度。

    

    大语言模型（LLM）以其卓越的任务处理能力和创新的输出，在许多领域推动了重大进展。然而，它们在生物分子研究等专业领域的熟练应用还受到限制。为了解决这个挑战，我们介绍了Mol-Instructions，这是一个经过精心策划、专门针对生物分子领域设计的综合指令数据集。Mol-Instructions由三个关键组成部分组成：分子导向指令、蛋白质导向指令和生物分子文本指令，每个部分都被策划用于增强LLM对生物分子特性和行为的理解和预测能力。通过对代表性LLM的广泛指令调整实验，我们强调了Mol-Instructions在增强大模型在生物分子研究复杂领域内的适应能力和认知敏锐度方面的潜力，从而促进生物分子领域的进一步发展。

    Large Language Models (LLMs), with their remarkable task-handling capabilities and innovative outputs, have catalyzed significant advancements across a spectrum of fields. However, their proficiency within specialized domains such as biomolecular studies remains limited. To address this challenge, we introduce Mol-Instructions, a meticulously curated, comprehensive instruction dataset expressly designed for the biomolecular realm. Mol-Instructions is composed of three pivotal components: molecule-oriented instructions, protein-oriented instructions, and biomolecular text instructions, each curated to enhance the understanding and prediction capabilities of LLMs concerning biomolecular features and behaviors. Through extensive instruction tuning experiments on the representative LLM, we underscore the potency of Mol-Instructions to enhance the adaptability and cognitive acuity of large models within the complex sphere of biomolecular studies, thereby promoting advancements in the biomol
    
[^51]: Annotator Demographics Matter - Measuring the Influence of Annotator Demographics with the POPQUORN Dataset

    When Do Annotator Demographics Matter? Measuring the Influence of Annotator Demographics with the POPQUORN Dataset. (arXiv:2306.06826v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.06826](http://arxiv.org/abs/2306.06826)

    标注者的背景对数据标注的影响很重要。通过POPQUORN数据集的分析，我们发现标注者的背景在他们的判断中起到了显著作用，并且应该考虑以前未考虑的背景因素。我们的研究建议理解标注者的背景，从具有人口统计学平衡的众包工作者中收集标签，以减少数据集的偏差。

    

    标注者的背景和经历会影响他们对数据的标注，然而，自然语言处理领域只近期开始考虑标注者身份对他们决策的影响。本文介绍了POPQUORN（POtato-Prolific 数据集，用于问题回答、冒犯性、文本改写和礼貌评分，包含人口统计学细微差异）。POPQUORN包含1,484个标注者的45,000个标注，采用了美国人口中性别、年龄和种族的代表样本。通过一系列分析，我们展示了标注者背景在他们的判断中起到了重要作用。此外，我们的工作还表明，在自然语言处理中以前未考虑的背景因素（例如教育）是有意义且应该被考虑的。我们的研究表明，理解标注者的背景，并从具有人口统计学平衡的众包工作者中收集标签，对减少数据集偏差非常重要。

    Annotators are not fungible. Their demographics, life experiences, and backgrounds all contribute to how they label data. However, NLP has only recently considered how annotator identity might influence their decisions. Here, we present POPQUORN (the POtato-Prolific dataset for QUestion-Answering, Offensiveness, text Rewriting, and politeness rating with demographic Nuance). POPQUORN contains 45,000 annotations from 1,484 annotators, drawn from a representative sample regarding sex, age, and race as the US population. Through a series of analyses, we show that annotators' background plays a significant role in their judgments. Further, our work shows that backgrounds not previously considered in NLP (e.g., education), are meaningful and should be considered. Our study suggests that understanding the background of annotators and collecting labels from a demographically balanced pool of crowd workers is important to reduce the bias of datasets. The dataset, annotator background, and anno
    
[^52]: 大型长序列模型的块级并行Transformer

    Blockwise Parallel Transformer for Long Context Large Models. (arXiv:2305.19370v1 [cs.CL])

    [http://arxiv.org/abs/2305.19370](http://arxiv.org/abs/2305.19370)

    本文提出了块级并行Transformer方法，以最小化内存成本，能够处理长序列，并且可以处理比先前的内存高效方法更长32倍的训练序列。

    

    Transformer已经成为最先进的自然语言处理模型的基石，在各种AI应用中展现出出色的性能。然而，Transformer中的自我注意机制和大型前馈网络所需的内存容量限制了它们处理长序列的能力，从而为涉及多个长序列或长期依赖的任务带来了挑战。我们提出了一种独特的方法，块级并行Transformer（BPT），它利用块级计算自我注意和前馈网络融合以最小化内存成本。通过在保持内存效率的同时处理更长的输入序列，BPT使训练序列的长度比原始的Transformer长32倍，比先前的内存高效方法长2到4倍。对语言建模和强化学习任务进行的大量实验证明了BPT在减少内存需求和提高性能方面的有效性。

    Transformers have emerged as the cornerstone of state-of-the-art natural language processing models, showcasing exceptional performance across a wide range of AI applications. However, the memory demands posed by the self-attention mechanism and the large feedforward network in Transformers limit their ability to handle long sequences, thereby creating challenges for tasks involving multiple long sequences or long-term dependencies. We present a distinct approach, Blockwise Parallel Transformer (BPT), that leverages blockwise computation of self-attention and feedforward network fusion to minimize memory costs. By processing longer input sequences while maintaining memory efficiency, BPT enables training sequences up to 32 times longer than vanilla Transformers and 2 to 4 times longer than previous memory-efficient methods. Extensive experiments on language modeling and reinforcement learning tasks demonstrate the effectiveness of BPT in reducing memory requirements and improving perfo
    
[^53]: 剪刀手：利用重要性持久性假设在测试时对LLM KV缓存进行压缩

    Scissorhands: Exploiting the Persistence of Importance Hypothesis for LLM KV Cache Compression at Test Time. (arXiv:2305.17118v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.17118](http://arxiv.org/abs/2305.17118)

    Scissorhands是一个可以在不对模型进行微调的情况下，通过利用重要性持久性假设将LLM KV缓存的内存使用维持在固定预算内的系统。

    

    大型语言模型（LLMs）引发了一波新的令人兴奋的人工智能应用。大规模托管这些模型需要大量的内存资源。部署过程中一个关键的内存瓶颈来自于上下文窗口。众所周知，模型权重占用大量内存；然而，在生成过程中存储的键值嵌入大小（KV缓存）往往超过了模型的大小。巨大的KV缓存大小对于关键字批处理大小的推理产生约束，这对于高吞吐量的推理工作负载至关重要。受到注意力分数的有趣观察的启发，我们提出了持久性重要性的假设：只有具有重要影响的关键标记，在一步中有实质性影响，才会在未来的生成中产生重大影响。基于对这一假设的经验验证和理论分析，我们提出了剪刀手，一个可以在不微调模型的情况下将KV缓存的内存使用维持在固定预算内的系统。

    Large language models(LLMs) have sparked a new wave of exciting AI applications. Hosting these models at scale requires significant memory resources. One crucial memory bottleneck for the deployment stems from the context window. It is commonly recognized that model weights are memory hungry; however, the size of key-value embedding stored during the generation process (KV cache) can easily surpass the model size. The enormous size of the KV cache puts constraints on the inference batch size, which is crucial for high throughput inference workload. Inspired by an interesting observation of the attention scores, we hypothesize the persistence of importance: only pivotal tokens, which had a substantial influence at one step, will significantly influence future generations. Based on our empirical verification and theoretical analysis around this hypothesis, we propose Scissorhands, a system that maintains the memory usage of the KV cache at a fixed budget without finetuning the model. In 
    
[^54]: 公平之路：大型语言模型中的偏差及去偏差

    A Trip Towards Fairness: Bias and De-Biasing in Large Language Models. (arXiv:2305.13862v1 [cs.CL])

    [http://arxiv.org/abs/2305.13862](http://arxiv.org/abs/2305.13862)

    本文研究大型语言模型中的偏见问题，并提出了一种去偏差技术以产生在下游任务中表现良好的健壮去偏差模型。

    

    基于转换器的语言模型（如GPT（Brown等，2020）和PaLM（Chowdhery等，2022））的普及引发了新的机器学习应用。特别是，在自然语言处理中，从大型文本语料库中进行预训练对于在下游任务中取得显着结果至关重要。然而，这些语言模型似乎具有对某些人口统计数据偏见的固有偏差。尽管研究试图缓解这个问题，但现有的方法要么未能完全消除偏见，要么降低了性能，要么代价过高。本文研究了当不同参数和预训练数据时，这些有前途的语言模型产生的偏见。最后，我们提出了一种去偏差技术，可以产生在下游任务中保持性能的健壮的去偏差模型。

    An outbreak in the popularity of transformer-based Language Models (such as GPT (Brown et al., 2020) and PaLM (Chowdhery et al., 2022)) has opened the doors to new Machine Learning applications. In particular, in Natural Language Processing and how pre-training from large text, corpora is essential in achieving remarkable results in downstream tasks. However, these Language Models seem to have inherent biases toward certain demographics reflected in their training data. While research has attempted to mitigate this problem, existing methods either fail to remove bias altogether, degrade performance, or are expensive. This paper examines the bias produced by promising Language Models when varying parameters and pre-training data. Finally, we propose a de-biasing technique that produces robust de-bias models that maintain performance on downstream tasks.
    
[^55]: 一个统一的英文文本到语音合成前端框架

    a unified front-end framework for english text-to-speech synthesis. (arXiv:2305.10666v1 [cs.CL])

    [http://arxiv.org/abs/2305.10666](http://arxiv.org/abs/2305.10666)

    该论文提出了一个统一的前端框架，捕捉了英文语音合成前端模块之间的依赖关系，并且在所有模块中均取得了最先进的性能。

    

    前端是英文文本到语音合成系统的关键组成部分，负责提取语言特征，如韵律和音素，这对于文本到语音模型合成语音至关重要。英文文本到语音前端通常由文本规范化模块（TN），单词韵律短语韵律短语模块（PWPP）和字形到音素模块（G2P）组成。然而，当前英文文本到语音前端的研究仅关注于单独模块，忽略它们之间的相互依赖，导致每个模块性能下降。因此，本文提出了一个统一的前端框架，捕捉英文文本到语音前端模块之间的依赖关系。广泛的实验表明，所提出的方法在所有模块中实现了最先进的性能。

    The front-end is a critical component of English text-to-speech (TTS) systems, responsible for extracting linguistic features that are essential for a text-to-speech model to synthesize speech, such as prosodies and phonemes. The English TTS front-end typically consists of a text normalization (TN) module, a prosody word prosody phrase (PWPP) module, and a grapheme-to-phoneme (G2P) module. However, current research on the English TTS front-end focuses solely on individual modules, neglecting the interdependence between them and resulting in sub-optimal performance for each module. Therefore, this paper proposes a unified front-end framework that captures the dependencies among the English TTS front-end modules. Extensive experiments have demonstrated that the proposed method achieves state-of-the-art (SOTA) performance in all modules.
    
[^56]: 面向模型预测解释的非对称特征交互

    Asymmetric feature interaction for interpreting model predictions. (arXiv:2305.07224v1 [cs.CL])

    [http://arxiv.org/abs/2305.07224](http://arxiv.org/abs/2305.07224)

    本文提出了一种解释模型，能够探索深度神经自然语言处理模型推理中的非对称高阶特征交互。在两个情感分类数据集上的实验结果表明，该模型在识别影响特征方面优于现有特征交互归因方法。

    

    在自然语言处理领域，深度神经网络能够模拟上下文之间的复杂交互，并在一系列自然语言处理任务上取得了令人瞩目的成果。先前有关特征交互归因的研究主要集中在对称交互的研究上，它只能解释单个词汇组合后对模型预测的附加影响，而无法捕捉导致模型预测的非对称影响。在本文中，我们提出了一个非对称特征交互解释模型，旨在探索深度神经自然语言处理模型推理中的非对称高阶特征交互。通过表示我们的解释为一个有向交互图，我们实验验证了该图的可解释性，能够发现非对称特征交互作用。在两个情感分类数据集上的实验结果表明，我们的模型在识别影响特征方面优于现有特征交互归因方法。

    In natural language processing (NLP), deep neural networks (DNNs) could model complex interactions between context and have achieved impressive results on a range of NLP tasks. Prior works on feature interaction attribution mainly focus on studying symmetric interaction that only explains the additional influence of a set of words in combination, which fails to capture asymmetric influence that contributes to model prediction. In this work, we propose an asymmetric feature interaction attribution explanation model that aims to explore asymmetric higher-order feature interactions in the inference of deep neural NLP models. By representing our explanation with an directed interaction graph, we experimentally demonstrate interpretability of the graph to discover asymmetric feature interactions. Experimental results on two sentiment classification datasets show the superiority of our model against the state-of-the-art feature interaction attribution methods in identifying influential featu
    
[^57]: OLISIA: 一个用于口语化对话状态跟踪的级联系统

    OLISIA: a Cascade System for Spoken Dialogue State Tracking. (arXiv:2304.11073v1 [eess.AS])

    [http://arxiv.org/abs/2304.11073](http://arxiv.org/abs/2304.11073)

    我们提出了OLISIA，一个口语对话状态跟踪的级联系统，使用自动语音识别和DST模型，采用几个适应性策略来提高稳健性，并在DSTC11 Track3中取得第一名的好成绩。

    

    对话状态跟踪 (DST) 是口语对话系统的核心组成部分。然而，最近关于该任务的研究大多集中于聊天时的语料库，忽略了口语和书面语之间的差异。本文提出了 OLISIA，这是一个级联系统，它集成了自动语音识别 (ASR) 模型和 DST 模型。我们在 ASR 和 DST 模块中引入了几个适应性策略，以提高对口语对话的整合性和稳健性。经过这些策略的调整，我们的系统在 DSTC11 Track 3 中排名第一，这是一个评估口语 DST 性能的基准。我们进行了深入的结果分析，发现规范化 ASR 的输出和通过数据增强调整 DST 的输入，以及增加预训练模型的大小，都在降低书面和口语对话之间性能差异方面发挥了重要作用。

    Though Dialogue State Tracking (DST) is a core component of spoken dialogue systems, recent work on this task mostly deals with chat corpora, disregarding the discrepancies between spoken and written language.In this paper, we propose OLISIA, a cascade system which integrates an Automatic Speech Recognition (ASR) model and a DST model. We introduce several adaptations in the ASR and DST modules to improve integration and robustness to spoken conversations.With these adaptations, our system ranked first in DSTC11 Track 3, a benchmark to evaluate spoken DST. We conduct an in-depth analysis of the results and find that normalizing the ASR outputs and adapting the DST inputs through data augmentation, along with increasing the pre-trained models size all play an important role in reducing the performance discrepancy between written and spoken conversations.
    
[^58]: 论ChatGPT的鲁棒性：对抗性和超出分布的视角。

    On the Robustness of ChatGPT: An Adversarial and Out-of-distribution Perspective. (arXiv:2302.12095v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.12095](http://arxiv.org/abs/2302.12095)

    本研究评估了ChatGPT的鲁棒性，发现其在对抗性和超出分布任务上有一致的优势，但绝对表现仍有提高空间，鲁棒性仍是一个重要的挑战。

    

    ChatGPT是OpenAI最近发布的聊天机器人服务，并在过去几个月中受到越来越多的关注。虽然已对ChatGPT的各个方面进行了评估，但其鲁棒性，即对于未预期输入的表现，仍不清楚。鲁棒性在负责任的AI中特别受关注，特别是对于安全关键应用程序。在本文中，我们从对抗性和超出分布（OOD）的角度对ChatGPT的鲁棒性进行了彻底评估。为此，我们采用了AdvGLUE和ANLI基准来评估对抗性鲁棒性，采用Flipkart评论和DDXPlus医学诊断数据集进行OOD评估。我们选择了几个流行的基础模型作为基准。结果表明，ChatGPT在大多数对抗性和OOD分类和翻译任务上表现出一致的优势。但是，绝对的表现远非完美，这表明对抗性和OOD鲁棒性仍然是一个重要的威胁。

    ChatGPT is a recent chatbot service released by OpenAI and is receiving increasing attention over the past few months. While evaluations of various aspects of ChatGPT have been done, its robustness, i.e., the performance to unexpected inputs, is still unclear to the public. Robustness is of particular concern in responsible AI, especially for safety-critical applications. In this paper, we conduct a thorough evaluation of the robustness of ChatGPT from the adversarial and out-of-distribution (OOD) perspective. To do so, we employ the AdvGLUE and ANLI benchmarks to assess adversarial robustness and the Flipkart review and DDXPlus medical diagnosis datasets for OOD evaluation. We select several popular foundation models as baselines. Results show that ChatGPT shows consistent advantages on most adversarial and OOD classification and translation tasks. However, the absolute performance is far from perfection, which suggests that adversarial and OOD robustness remains a significant threat 
    
[^59]: “大型语言模型可能会自发出现心智理论”

    Theory of Mind May Have Spontaneously Emerged in Large Language Models. (arXiv:2302.02083v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.02083](http://arxiv.org/abs/2302.02083)

    “通过测试多个语言模型在解决40个ToM任务上的表现，研究发现GPT-3和GPT-4能够解决大部分任务，说明类似ToM的能力可能是语言模型自发出现的附带产物。”

    

    “心智理论（ToM）指能够推理他人内心的不可观察状态，对于人类社交互动、交流、移情、自我意识和道德至关重要。我们使用了40个广泛用于测试人类ToM的经典虚假信念任务来测试几个语言模型。2020年之前发布的模型在解决ToM任务方面几乎没有能力。然而，2020年5月发布的第一个GPT-3版本（“davinci-001”）解决了约40％的虚假信念任务，与3.5岁的儿童的表现相当。它的第二个版本（“davinci-002”，2022年1月）解决了70％的虚假信念任务，与6岁儿童的表现相当。最新版本的GPT-3.5（“davinci-003”，2022年11月）解决了90％的虚假信念任务，达到了7岁儿童水平。于2023年3月发布的GPT-4解决了几乎所有的任务（95％）。这些发现表明，类似ToM的能力（迄今被认为是人类独有的）可能是语言的附带产物。”

    Theory of mind (ToM), or the ability to impute unobservable mental states to others, is central to human social interactions, communication, empathy, self-consciousness, and morality. We tested several language models using 40 classic false-belief tasks widely used to test ToM in humans. The models published before 2020 showed virtually no ability to solve ToM tasks. Yet, the first version of GPT-3 ("davinci-001"), published in May 2020, solved about 40% of false-belief tasks-performance comparable with 3.5-year-old children. Its second version ("davinci-002"; January 2022) solved 70% of false-belief tasks, performance comparable with six-year-olds. Its most recent version, GPT-3.5 ("davinci-003"; November 2022), solved 90% of false-belief tasks, at the level of seven-year-olds. GPT-4 published in March 2023 solved nearly all the tasks (95%). These findings suggest that ToM-like ability (thus far considered to be uniquely human) may have spontaneously emerged as a byproduct of language
    
[^60]: 基于深度卷积神经网络的多任务集成模型用于波斯语评论中的方面和极性分类

    A Deep Convolutional Neural Networks Based Multi-Task Ensemble Model for Aspect and Polarity Classification in Persian Reviews. (arXiv:2201.06313v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2201.06313](http://arxiv.org/abs/2201.06313)

    本论文介绍了一种基于深度卷积神经网络的多任务集成模型，用于在波斯语评论中进行方面和极性分类。该模型能够同时检测方面类别和方面类别极性，通过结合多个模型进行集成学习，可以提高预测效果并减少错误。

    

    方面级情感分析因其能够识别文本中讨论的所有方面而具有重要性和应用。然而，方面级情感分析在识别文本中所有讨论的方面的同时，还能识别它们的极性时最有效。大多数先前的方法使用管道方法，即首先识别方面，然后识别极性。这种方法对于实际应用不合适，因为它们可能导致模型错误。因此，在本研究中，我们提出了一个基于卷积神经网络（CNN）的多任务学习模型，它可以同时检测方面类别和检测方面类别的极性。仅创建一个模型可能无法提供最佳预测结果，并可能导致偏差和较高方差等错误。为了减少这些错误并提高模型预测的效率，结合多个模型，即集成学习，可能会提供更好的结果。因此，

    Aspect-based sentiment analysis is of great importance and application because of its ability to identify all aspects discussed in the text. However, aspect-based sentiment analysis will be most effective when, in addition to identifying all the aspects discussed in the text, it can also identify their polarity. Most previous methods use the pipeline approach, that is, they first identify the aspects and then identify the polarities. Such methods are unsuitable for practical applications since they can lead to model errors. Therefore, in this study, we propose a multi-task learning model based on Convolutional Neural Networks (CNNs), which can simultaneously detect aspect category and detect aspect category polarity. creating a model alone may not provide the best predictions and lead to errors such as bias and high variance. To reduce these errors and improve the efficiency of model predictions, combining several models known as ensemble learning may provide better results. Therefore,
    
[^61]: 前期训练在终身学习中的作用的实证研究

    An Empirical Investigation of the Role of Pre-training in Lifelong Learning. (arXiv:2112.09153v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2112.09153](http://arxiv.org/abs/2112.09153)

    这项研究通过对大型预训练模型在多个任务上的性能评估，发现通用的前期训练可以在终身学习中减轻灾难性遗忘的影响。

    

    机器学习中的终身学习范式不仅因其类似生物学习的特性而具有吸引力，而且因其通过避免过多的模型重新训练而减少能源浪费的潜力而备受关注。这一范式面临的关键挑战是灾难性遗忘现象。随着预训练模型在机器学习中的日益流行和成功，我们提出一个问题：在终身学习中，前期训练在灾难性遗忘方面扮演何种角色？我们在大型预训练模型的背景下研究现有方法，并在各种文本和图像分类任务中评估它们的性能，包括使用一个新颖的包含15个不同自然语言处理任务的数据集进行的大规模研究。在所有设置中，我们观察到与随机初始化模型相比，通用的前期训练在学习多个任务时隐含地缓解了灾难性遗忘的影响。

    The lifelong learning paradigm in machine learning is an attractive alternative to the more prominent isolated learning scheme not only due to its resemblance to biological learning but also its potential to reduce energy waste by obviating excessive model re-training. A key challenge to this paradigm is the phenomenon of catastrophic forgetting. With the increasing popularity and success of pre-trained models in machine learning, we pose the question: What role does pre-training play in lifelong learning, specifically with respect to catastrophic forgetting? We investigate existing methods in the context of large, pre-trained models and evaluate their performance on a variety of text and image classification tasks, including a large-scale study using a novel data set of 15 diverse NLP tasks. Across all settings, we observe that generic pre-training implicitly alleviates the effects of catastrophic forgetting when learning multiple tasks sequentially compared to randomly initialized mo
    

