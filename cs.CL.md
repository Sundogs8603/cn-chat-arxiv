# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [RAIN: Your Language Models Can Align Themselves without Finetuning.](http://arxiv.org/abs/2309.07124) | 本研究提出了RAIN方法，该方法可以在无需微调或额外数据的情况下，通过整合自我评估和回滚机制实现对齐冻结的语言模型，使其能够直接产生与人类偏好一致的响应。 |
| [^2] | [Sight Beyond Text: Multi-Modal Training Enhances LLMs in Truthfulness and Ethics.](http://arxiv.org/abs/2309.07120) | 多模态训练的MLLM在纯NLP任务中表现出卓越的真实性和伦理对齐能力，这得益于视觉指导调优和优秀的指导质量。 |
| [^3] | [Mitigating Hallucinations and Off-target Machine Translation with Source-Contrastive and Language-Contrastive Decoding.](http://arxiv.org/abs/2309.07098) | 本文介绍了一种通过源对比和语言对比解码来解决机器翻译中幻觉和偏离目标的问题的方法，实验证明这些方法能有效地抑制幻觉和偏离目标的翻译。 |
| [^4] | [Can Whisper perform speech-based in-context learning.](http://arxiv.org/abs/2309.07081) | 本文研究了Whisper自动语音识别模型的语境学习能力，并提出了一种基于语境的语音学习方法，用于在测试时适应。通过实验验证了该方法在中文方言上的有效性，可以显著减少单词错误率。通过进一步优化选择技术可以进一步提高效率。 |
| [^5] | [Large Language Models for Compiler Optimization.](http://arxiv.org/abs/2309.07062) | 本论文研究了将大型语言模型应用于代码优化的新颖方法，以7B参数的transformer模型为例，通过预测指令计数和生成优化代码等辅助学习任务，显著提高了模型的优化性能。在大量测试程序上的评估中，该方法相对编译器的优化效果提高了3.0%，并展现出令人惊喜的强大代码推理能力。 |
| [^6] | [SafetyBench: Evaluating the Safety of Large Language Models with Multiple Choice Questions.](http://arxiv.org/abs/2309.07045) | SafetyBench是一个全面基准，用于评估大型语言模型的安全性。它包括了11,435个多项选择问题，涵盖了7个不同的安全问题类别，并且还提供中英文数据。通过对25个热门中英文LLM进行测试，我们发现GPT-4在性能上明显优于其他模型，但当前LLM的安全性仍有很大的提升空间。 |
| [^7] | [How (Not) to Use Sociodemographic Information for Subjective NLP Tasks.](http://arxiv.org/abs/2309.07034) | 该论文研究了如何使用社会人口统计信息在主观NLP任务中，发现社会人口提示技术在某些任务上有效，但也存在一些限制和挑战。 |
| [^8] | [Beyond original Research Articles Categorization via NLP.](http://arxiv.org/abs/2309.07020) | 本研究利用预训练的语言模型提出了一种新的文本分类方法，通过自然语言处理技术，能够更有效地捕捉科学文献中的主题信息，以改进文本分类。 |
| [^9] | [R\'esum\'e Parsing as Hierarchical Sequence Labeling: An Empirical Study.](http://arxiv.org/abs/2309.07015) | 本研究将简历解析问题作为分层序列标注任务，提出了同时解决行和标记两个任务的模型架构，并构建了多语言的高质量简历解析语料库。实验结果表明，所提出模型在信息提取任务中优于先前工作中的方法。进一步分析了模型性能和资源效率，并描述了模型在生产环境中的权衡。 |
| [^10] | [OYXOY: A Modern NLP Test Suite for Modern Greek.](http://arxiv.org/abs/2309.07009) | 本文提出了一种适用于希腊语自然语言处理的现代NLP测试套件，其中包含四个专家验证的评估任务，用于自然语言推理、词义消歧和隐喻检测。创新之处在于推理数据集首次标记了所有可能的推理标签，并且展示了一种对于资源匮乏语言获取数据集的成本效益方法。 |
| [^11] | [Unsupervised Contrast-Consistent Ranking with Language Models.](http://arxiv.org/abs/2309.06991) | 无监督的对比一致排序与语言模型，通过训练一个受逻辑约束引导的探测模型，实现在多个语句中始终映射到对比的真-假极点的排序任务。 |
| [^12] | [Remote Inference of Cognitive Scores in ALS Patients Using a Picture Description.](http://arxiv.org/abs/2309.06989) | 本研究使用图片描述远程推断ALS患者的认知得分，并成功实现了数字版本的ECAS测试。这项研究为有效监测ALS患者的认知障碍提供了一种可行的远程方法。 |
| [^13] | [Auto-Regressive Next-Token Predictors are Universal Learners.](http://arxiv.org/abs/2309.06979) | 自回归的下一个标记预测器可以有效地近似图灵机计算的任何函数，并且在文本生成和算术任务上展现出非平凡的性能。 |
| [^14] | [Dynamic Causal Disentanglement Model for Dialogue Emotion Detection.](http://arxiv.org/abs/2309.06928) | 本文提出了一种动态因果解缠模型，通过分解对话内容和研究情感的时间积累，实现了更精确的情感识别。 |
| [^15] | [Native Language Identification with Big Bird Embeddings.](http://arxiv.org/abs/2309.06923) | 本研究通过使用Big Bird嵌入训练的分类器，在Reddit-L2数据集上超越了语言特征工程模型。此方法显示出了有效性和计算效率，为未来的母语识别工作提供了有前景的途径。 |
| [^16] | [Continual Learning with Dirichlet Generative-based Rehearsal.](http://arxiv.org/abs/2309.06917) | 该论文提出了一种新颖的基于狄利克雷生成的回顾策略，用于解决连续学习中伪样本生成的挑战。 |
| [^17] | [Towards the TopMost: A Topic Modeling System Toolkit.](http://arxiv.org/abs/2309.06908) | 本文提出了一个名为TopMost的主题建模系统工具包，通过涵盖更广泛的主题建模场景和具有高度凝聚力和解耦模块化设计的特点，可以促进主题模型的研究和应用。 |
| [^18] | [Gpachov at CheckThat! 2023: A Diverse Multi-Approach Ensemble for Subjectivity Detection in News Articles.](http://arxiv.org/abs/2309.06844) | Gpachov团队在CLEF-2023 CheckThat！实验室任务2中构建了一种多样的多方法集成解决方案，通过微调句子嵌入编码模型、样本高效的少样本学习模型和多语言转换器等方法结合得到了0.77的宏F1分数，并在英语子任务中获得第二名。 |
| [^19] | [Comparative Analysis of Contextual Relation Extraction based on Deep Learning Models.](http://arxiv.org/abs/2309.06814) | 本文比较分析了基于深度学习模型的上下文关系提取方法。现有技术无法高效预测由多于两个关系和未指定实体组成的句子中的复杂关系。研究采用深度学习技术从多个句子的语境中识别语义关系。现有机器学习模型在二元关系中表现较好，但随着关系数量的增加，预测准确率降低。 |
| [^20] | [Cognitive Mirage: A Review of Hallucinations in Large Language Models.](http://arxiv.org/abs/2309.06794) | 这篇论文综述了大规模语言模型中幻觉的现象，并提出了幻觉的分类、理论分析、检测方法和改进方法，同时还设想了未来的研究方向。 |
| [^21] | [Scaled Prompt-Tuning for Few-Shot Natural Language Generation.](http://arxiv.org/abs/2309.06759) | 本论文提出了一种Scaled Prompt-Tuning (SPT)方法，用于少样本自然语言生成 (NLG)。该方法冻结大多数参数，只微调其中一小部分参数，以减少内存占用、训练成本和标注成本，并在性能和泛化能力方面超越了传统的方法。在少样本情况下，SPT展现了更好的迁移能力。 |
| [^22] | [CONVERSER: Few-Shot Conversational Dense Retrieval with Synthetic Data Generation.](http://arxiv.org/abs/2309.06748) | CONVERSER是一个使用少量对话样本进行训练的对话式密集检索框架，通过利用大型语言模型的上下文学习能力，能够生成与检索语料库中段落相关的对话查询，实验结果表明其在少样本对话密集检索中表现出与完全监督模型相当的性能。 |
| [^23] | [Enhancing Keyphrase Generation by BART Finetuning with Splitting and Shuffling.](http://arxiv.org/abs/2309.06726) | 本文提出了关注关键短语的BART模型(Keyphrase-Focused BART)，通过拆分和重排的方式来增强关键短语生成的性能。在不出现的关键短语生成任务中，该模型在两个关键短语生成基准数据集上取得了新的最佳得分。 |
| [^24] | [Simultaneous Machine Translation with Large Language Models.](http://arxiv.org/abs/2309.06706) | 本文研究了使用大型语言模型进行同时机器翻译的可行性，通过引入混合策略，并进行有监督微调，取得了显著的性能改进。 |
| [^25] | [VLSlice: Interactive Vision-and-Language Slice Discovery.](http://arxiv.org/abs/2309.06703) | 这项工作提出了一种交互式系统VLSlice，可以通过用户引导发现一致的视觉和语言行为的表示级子组，以解决自动发现子组时的困难。 |
| [^26] | [Benchmarking Procedural Language Understanding for Low-Resource Languages: A Case Study on Turkish.](http://arxiv.org/abs/2309.06698) | 本研究通过对土耳其语的程序文本进行案例研究，扩展了土耳其wikiHow的教程数量，并研究了几个下游任务。研究发现，在大多数任务中，语言特定模型相对于多语言模型具有明显优势。 |
| [^27] | [Statistical Rejection Sampling Improves Preference Optimization.](http://arxiv.org/abs/2309.06657) | 本文提出了一种名为统计拒绝抽样的新方法，改进了优化偏好的过程，并解决了传统方法中缺乏奖励模型和从最优策略采样偏好对的问题。 |
| [^28] | [RT-LM: Uncertainty-Aware Resource Management for Real-Time Inference of Language Models.](http://arxiv.org/abs/2309.06619) | 这篇论文介绍了RT-LM，它是一种针对语言模型的实时推理进行优化的不确定性感知资源管理方法。该方法能够理解、量化和优化由于语言的不确定性而导致的推理延迟性能变化，以提高LMs的整体性能。 |
| [^29] | [Narrative as a Dynamical System.](http://arxiv.org/abs/2309.06600) | 叙事可以被视为一个动力系统，其演化可以用一个行动积分来描述，并且平均路径与行动原理一致。 |
| [^30] | [Do Generative Large Language Models need billions of parameters?.](http://arxiv.org/abs/2309.06589) | 本文研究了生成大语言模型的规模、性能和计算资源之间的权衡，并提出了新方法来减少参数数量，从而创建更高效、紧凑的模型，为AI语言建模的可持续和可访问的未来做出了贡献。 |
| [^31] | [Can humans help BERT gain "confidence"?.](http://arxiv.org/abs/2309.06580) | 本论文研究了如何将苏黎世认知语料库的认知特征与BERT模型集成，证明了脑电图和眼动特征可以提高自然语言处理模型的性能，并开发了一个用于基准测试的词-EEG词典。 |
| [^32] | [Can Large Language Models Discern Evidence for Scientific Hypotheses? Case Studies in the Social Sciences.](http://arxiv.org/abs/2309.06578) | 本文研究了大型语言模型（LLMs）根据科学摘要文本的能力，来辨别支持或反驳特定假设的证据。通过社区驱动的注释建立了一个新的数据集，针对社会科学中的科学假设证据任务。与其他基准进行了性能比较，并为未来研究提供了机会。 |
| [^33] | [Addressing the Blind Spots in Spoken Language Processing.](http://arxiv.org/abs/2309.06572) | 本文探讨了非语言线索在人类交流中的关键作用，并借鉴手语处理的进展，提出发展通用的自动手势分割和转录模型来弥补口语语言理解中的盲点，并增强NLP模型的范围和适用性。 |
| [^34] | [Unsupervised Bias Detection in College Student Newspapers.](http://arxiv.org/abs/2309.06557) | 本文提出了一个几乎没有人为影响的流程，用于从大学报纸档案中获取并检测偏见。该方法通过比较大型语言模型摘要的情感与原文来计算偏见，不需要大量标记数据，为客观理解学生报纸来源中的偏见提供了方法。 |
| [^35] | [Offline Prompt Evaluation and Optimization with Inverse Reinforcement Learning.](http://arxiv.org/abs/2309.06553) | 这项工作介绍了一种基于离线逆向强化学习的提示评估与优化方法，通过利用离线数据集和逆向强化学习，预测提示性能、提高成本效益、生成易读的结果。 |
| [^36] | [Synthetic Text Generation using Hypergraph Representations.](http://arxiv.org/abs/2309.06550) | 本论文提出了一种使用超图表示生成合成文本的方法，首先将文档分解为语义框架，然后使用此中间稀疏格式生成文本。通过扰动框架内容，包括拓扑分析挖掘新的超边以及包含层次结构和时间动态的复杂多元关系，我们的解决方案生成的文档在样式、情感、格式、构成和事实上是多样的、连贯的和变化的。 |
| [^37] | [Text Encoders Lack Knowledge: Leveraging Generative LLMs for Domain-Specific Semantic Textual Similarity.](http://arxiv.org/abs/2309.06541) | 生成式LLMs在描述复杂语义关系依赖于世界知识的两个文本之间的语义相似性时，显著优于基于编码器的STS模型，并在多个STS基准测试中保持强大的性能。 |
| [^38] | [Machine Translation Models Stand Strong in the Face of Adversarial Attacks.](http://arxiv.org/abs/2309.06527) | 本研究探讨了对抗攻击对机器翻译模型的影响，证明了机器翻译模型在面对已知的最佳对抗攻击时表现出强大的稳定性。同时，我们提出的攻击算法在相对性能上超过其他替代选择。 |
| [^39] | [Minimum Bayes' Risk Decoding for System Combination of Grammatical Error Correction Systems.](http://arxiv.org/abs/2309.06520) | 本文提出了一个用于语法错误修正系统系统组合的最小贝叶斯风险解码方法，并通过实验证明了其有效性。 |
| [^40] | [Overview of Memotion 3: Sentiment and Emotion Analysis of Codemixed Hinglish Memes.](http://arxiv.org/abs/2309.06517) | Memotion 3是对Hinglish混合语言表情包进行情感和情绪分析的共享任务，参与者使用了各种模型和方法来处理该任务。 |
| [^41] | [Leveraging Large Language Models and Weak Supervision for Social Media data annotation: an evaluation using COVID-19 self-reported vaccination tweets.](http://arxiv.org/abs/2309.06503) | 本研究评估了使用大型语言模型和弱监督方法，通过GPT-4模型在单次模式下提供标签的方式，来识别COVID-19疫苗相关推文，并与人工注释员的性能进行比较。 |
| [^42] | [AGIBench: A Multi-granularity, Multimodal, Human-referenced, Auto-scoring Benchmark for Large Language Models.](http://arxiv.org/abs/2309.06495) | AGIBench是一个用于大型语言模型的多粒度、多模态、人工参考、自动评分的基准，通过标记问题的属性来评估语言模型的问题解决能力和智能程度。 |
| [^43] | [Leveraging Large Language Models for Automated Dialogue Analysis.](http://arxiv.org/abs/2309.06490) | 本文研究了利用大型语言模型ChatGPT-3.5进行自动对话行为检测的能力，并评估了其与专门模型和人类表现的匹配度。研究结果显示，目前还没有一种模型能够令人满意地实现这一任务，达到人类的性能水平。 |
| [^44] | [Widely Interpretable Semantic Representation: Frameless Meaning Representation for Broader Applicability.](http://arxiv.org/abs/2309.06460) | 本文提出了一种名为WISeR的语义表示方法，克服了抽象意义表示（AMR）在应用于没有预定义语义框架的语言或领域时的挑战。通过将AMR中的编号参数转换为不需要引用语义框架的语义角色，WISeR提供了更易于解释和解析的语义表示。该方法在标注者一致性和解析器的准确性方面表现出色。 |
| [^45] | [Narrowing the Gap between Supervised and Unsupervised Sentence Representation Learning with Large Language Model.](http://arxiv.org/abs/2309.06453) | 本文通过实验比较了监督和无监督句子表示学习在训练过程中的行为，并探讨了如何缩小性能差距。 |
| [^46] | [AKEM: Aligning Knowledge Base to Queries with Ensemble Model for Entity Recognition and Linking.](http://arxiv.org/abs/2309.06175) | 本文提出了一种利用集成模型将知识库与查询对齐的方法，用于实体识别和链接挑战。通过扩展知识库和利用外部知识，提高了召回率，并使用支持向量回归和多元加性回归树过滤结果得到高精度的实体识别和链接。最终实现了高效的计算和0.535的F1分数。 |
| [^47] | [Stochastic LLMs do not Understand Language: Towards Symbolic, Explainable and Ontologically Based LLMs.](http://arxiv.org/abs/2309.05918) | 随机LLMs无法理解语言的原因是它们无法提供可以依赖的事实信息，它们存储的语言知识埋藏在无意义的微特征中，并在某些语言上下文中无法进行正确推理。本文建议在符号化方法中应用有效的自下而上策略 |
| [^48] | [Memory Injections: Correcting Multi-Hop Reasoning Failures during Inference in Transformer-Based Language Models.](http://arxiv.org/abs/2309.05605) | 本文提出了一种通过向Transformer-Based语言模型的LLM注意力头部定向注入内存来纠正多跳推理错误的方法，从而提高了模型在处理多跳推理问题时的表现。 |
| [^49] | [NExT-GPT: Any-to-Any Multimodal LLM.](http://arxiv.org/abs/2309.05519) | NExT-GPT是一个任何到任何的多模态语言模型系统，通过连接多模态适配器和不同扩散解码器，能够接受和生成任意组合的文本、图像、视频和音频内容。 |
| [^50] | [Understanding the Impact of Post-Training Quantization on Large Language Models.](http://arxiv.org/abs/2309.05210) | 本研究旨在理解后训练量化对大型语言模型的影响，揭示了量化模型在下一个单词预测等关键任务中如何响应超参数的差距。 |
| [^51] | [ChatRule: Mining Logical Rules with Large Language Models for Knowledge Graph Reasoning.](http://arxiv.org/abs/2309.01538) | 本论文提出了一个框架ChatRule，利用大型语言模型挖掘知识图谱中的逻辑规则。该框架通过充分利用知识图谱的语义和结构信息，能够提高推理性能并提供可解释的结果。 |
| [^52] | [A Methodology for Generative Spelling Correction via Natural Spelling Errors Emulation across Multiple Domains and Languages.](http://arxiv.org/abs/2308.09435) | 本文提出了一种用于生成拼写纠正的方法论，通过模拟文本中的自然拼写错误和打字错误，以有效丰富生成模型的预训练过程。研究结果表明，这种方法在英语和俄语语言上是可行的，并可以扩展到其他语言。 |
| [^53] | [SeACo-Paraformer: A Non-Autoregressive ASR System with Flexible and Effective Hotword Customization Ability.](http://arxiv.org/abs/2308.03266) | SeACo-Paraformer是一种具有灵活且有效的热词自定义能力的非自回归ASR系统，在大规模实验中表现优于基线模型，并提出了过滤大规模热词的有效方法。 |
| [^54] | [Scaling Relationship on Learning Mathematical Reasoning with Large Language Models.](http://arxiv.org/abs/2308.01825) | 本文研究了大型语言模型在学习数学推理时的规模关系，发现预训练损失更好地预测模型性能，并提出了一种使用拒绝采样微调技术来增强数据集的方法。 |
| [^55] | [GRDD: A Dataset for Greek Dialectal NLP.](http://arxiv.org/abs/2308.00802) | 本文介绍了一个用于研究现代希腊方言的大规模数据集GRDD，并使用该数据集进行方言识别实验，结果显示即使是简单的机器学习模型也能在该任务上表现良好。 |
| [^56] | [Findings of Factify 2: Multimodal Fake News Detection.](http://arxiv.org/abs/2307.10475) | Factify 2进行了一项多模态假新闻检测任务，通过比较社交媒体声明和支持文件的文本和图像信息，实现了对假新闻的自动检测和验证，最佳性能达到了81.82%的F1分数。 |
| [^57] | [A Comprehensive Overview of Large Language Models.](http://arxiv.org/abs/2307.06435) | 大语言模型的综合概述，分析了各种新的架构和训练策略，讨论了LLM的特点和功能，并总结了重要的研究发现和关键的架构和训练策略。 |
| [^58] | [Cross-corpus Readability Compatibility Assessment for English Texts.](http://arxiv.org/abs/2306.09704) | 本文提出了一个新的评估框架，Cross-corpus text Readability Compatibility Assessment (CRCA)，用于解决不同语料库之间的可读性兼容性的问题。研究结果表明该框架具有显著的兼容性，并适用于不同的特征表示和分类方法。 |
| [^59] | [GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio Pretraining for Speech Emotion Recognition.](http://arxiv.org/abs/2306.07848) | 本文提出了GEmo-CLAP模型用于语音情感识别，结合了性别属性信息，相比于其他先进方法，该模型在IEMOCAP上实现了更优越的识别性能。 |
| [^60] | [Do Language Models Know When They're Hallucinating References?.](http://arxiv.org/abs/2305.18248) | 本研究针对大型语言模型中的“幻觉”参考文献进行了研究，通过简单的搜索引擎查询可可靠地识别这些幻觉。并且通过对同一语言模型进行黑盒查询来进行分类，揭示了幻觉参考文献的性质。 |
| [^61] | [Does ChatGPT have Theory of Mind?.](http://arxiv.org/abs/2305.14020) | 本文研究了ChatGPT在心智理论方面的能力。通过对比不同版本的ChatGPT在几个经典问题上的表现，发现ChatGPT-4比随机答案给出了更多正确答案，尽管这些答案往往基于错误的假设或无效的推理。 |
| [^62] | [Exploring Challenges of Deploying BERT-based NLP Models in Resource-Constrained Embedded Devices.](http://arxiv.org/abs/2304.11520) | 本文探究了在资源受限的嵌入式设备上部署基于BERT的NLP模型的挑战，并得出结论：虽然DistilBERT和TinyBERT等轻量级模型相对占用更少内存，但它们在复杂的NLP任务上表现较差；ResNet-based BERT模型可以在精度和资源效率之间取得良好的平衡，适合在嵌入式设备上部署。 |
| [^63] | [Spaiche: Extending State-of-the-Art ASR Models to Swiss German Dialects.](http://arxiv.org/abs/2304.11075) | 本项目在瑞士德语方言ASR模型的研究中提供了有价值的思路，通过提出考虑语义距离的新颖损失函数，对OpenAI的Whisper模型进行微调，取得了优于当前先进成果的效果。 |
| [^64] | ["Correct answers" from the psychology of artificial intelligence.](http://arxiv.org/abs/2302.07267) | 本文使用OpenAI的GPT3.5模型重新复制了Many Labs 2复制项目中的14项研究，其中8项研究的结果被成功复制。然而，对于剩下的6项研究，GPT3.5以极其预定的方式回答了调查问题，导致无法分析这些研究。 |
| [^65] | [ColD Fusion: Collaborative Descent for Distributed Multitask Finetuning.](http://arxiv.org/abs/2212.01378) | ColD Fusion是一种协同下降的分布式多任务微调方法，通过利用分布式计算，可以不断改进预训练模型，并在各种数据集上表现良好，优于RoBERTa模型。 |
| [^66] | [Event and Entity Extraction from Generated Video Captions.](http://arxiv.org/abs/2211.02982) | 该论文提出了一个从生成的视频字幕中提取语义元数据的框架，通过使用密集视频字幕模型，可以提取实体、实体属性、实体之间的关系和视频分类。提取信息的质量受到事件定位质量和字幕生成性能的影响。 |

# 详细

[^1]: RAIN: 您的语言模型可以自我调整而无需微调

    RAIN: Your Language Models Can Align Themselves without Finetuning. (arXiv:2309.07124v1 [cs.CL])

    [http://arxiv.org/abs/2309.07124](http://arxiv.org/abs/2309.07124)

    本研究提出了RAIN方法，该方法可以在无需微调或额外数据的情况下，通过整合自我评估和回滚机制实现对齐冻结的语言模型，使其能够直接产生与人类偏好一致的响应。

    

    大型语言模型（LLM）常常与人类偏好存在不一致性。之前的研究通过收集人类偏好数据，然后使用强化学习或指导调优等方法对预训练模型进行微调以实现对齐。相比之下，无需任何额外数据对齐冻结的LLM更有吸引力。本研究探讨了后一种情景的潜力。我们发现通过将自我评估和回滚机制整合在一起，不对齐的LLM可以通过自我增强直接产生与人类偏好一致的响应。我们引入了一种新的推理方法，可回滚的自回归推理（RAIN），它允许预训练的LLM评估自己的生成，并利用评估结果来引导向后回滚和向前生成以确保人工智能的安全性。值得注意的是，RAIN在模型对齐时无需额外数据，并且不需要任何训练、梯度计算或参数更新；在自我评估阶段，模型接收的是一些随机回滚的生成样本，并将其与人类偏好进行比较。

    Large language models (LLMs) often demonstrate inconsistencies with human preferences. Previous research gathered human preference data and then aligned the pre-trained models using reinforcement learning or instruction tuning, the so-called finetuning step. In contrast, aligning frozen LLMs without any extra data is more appealing. This work explores the potential of the latter setting. We discover that by integrating self-evaluation and rewind mechanisms, unaligned LLMs can directly produce responses consistent with human preferences via self-boosting. We introduce a novel inference method, Rewindable Auto-regressive INference (RAIN), that allows pre-trained LLMs to evaluate their own generation and use the evaluation results to guide backward rewind and forward generation for AI safety. Notably, RAIN operates without the need of extra data for model alignment and abstains from any training, gradient computation, or parameter updates; during the self-evaluation phase, the model recei
    
[^2]: 超越文本视野：多模态训练提升了在真实性和伦理道德方面的MLLM

    Sight Beyond Text: Multi-Modal Training Enhances LLMs in Truthfulness and Ethics. (arXiv:2309.07120v1 [cs.CL])

    [http://arxiv.org/abs/2309.07120](http://arxiv.org/abs/2309.07120)

    多模态训练的MLLM在纯NLP任务中表现出卓越的真实性和伦理对齐能力，这得益于视觉指导调优和优秀的指导质量。

    

    多模态大语言模型（MLLM）基于大型语言模型（LLM）进行训练，具备理解多模态输入和生成文本响应的增强能力。虽然它们在多模态任务中表现出色，但对MLLM的纯NLP能力常常低估并未经测试。本研究中，我们采用了新颖的方法，揭示了MLLM的一个引人注目的特性——初步结果表明，视觉指导调优，一种将LLM转换为MLLM的流行策略，出乎意料地帮助模型在纯NLP环境中取得了提高真实性和伦理对齐的效果。例如，经过视觉指导调优的LLaMA2 7B模型在TruthfulQA-mc和伦理道德基准上超过了经过超过一百万人工标注的LLaMA2-chat 7B模型的性能。进一步的分析表明，这种改进的对齐可以归因于视觉-文本数据固有的优秀指导质量。

    Multi-modal large language models (MLLMs) are trained based on large language models (LLM), with an enhanced capability to comprehend multi-modal inputs and generate textual responses. While they excel in multi-modal tasks, the pure NLP abilities of MLLMs are often underestimated and left untested. In this study, we get out of the box and unveil an intriguing characteristic of MLLMs -- our preliminary results suggest that visual instruction tuning, a prevailing strategy for transitioning LLMs into MLLMs, unexpectedly and interestingly helps models attain both improved truthfulness and ethical alignment in the pure NLP context. For example, a visual-instruction-tuned LLaMA2 7B model surpasses the performance of the LLaMA2-chat 7B model, fine-tuned with over one million human annotations, on TruthfulQA-mc and Ethics benchmarks. Further analysis reveals that the improved alignment can be attributed to the superior instruction quality inherent to visual-text data. In releasing our code at 
    
[^3]: 通过源对比和语言对比解码来缓解幻觉和偏离目标的机器翻译问题

    Mitigating Hallucinations and Off-target Machine Translation with Source-Contrastive and Language-Contrastive Decoding. (arXiv:2309.07098v1 [cs.CL])

    [http://arxiv.org/abs/2309.07098](http://arxiv.org/abs/2309.07098)

    本文介绍了一种通过源对比和语言对比解码来解决机器翻译中幻觉和偏离目标的问题的方法，实验证明这些方法能有效地抑制幻觉和偏离目标的翻译。

    

    在机器翻译中，幻觉和偏离目标的翻译仍然是一个未解决的问题，特别是对于低资源语言和大规模多语言模型。本文介绍了一种修改的解码目标来缓解这两种失败情况的方法，而不需要重新训练或外部模型。在源对比解码中，我们寻找一个翻译，在给定正确输入时是可信的，但在随机输入片段给定时是不可信的，假设幻觉在任何情况下都是同样可信的。在语言对比解码中，我们寻找一个翻译，在给定正确语言指示符令牌时是可信的，但给定错误语言指示符令牌时是不可信的。在对M2M-100 (418M)和SMaLL-100进行实验后，我们发现这些方法有效地抑制了幻觉和偏离目标的翻译，平均在57个测试的翻译方向上提高了1.7和1.4个chrF2分数。在英德语言对的一个概念验证中，我们还展示了我们可以抑制偏离目标的翻译。

    Hallucinations and off-target translation remain unsolved problems in machine translation, especially for low-resource languages and massively multilingual models. In this paper, we introduce methods to mitigate both failure cases with a modified decoding objective, without requiring retraining or external models. In source-contrastive decoding, we search for a translation that is probable given the correct input, but improbable given a random input segment, hypothesising that hallucinations will be similarly probable given either. In language-contrastive decoding, we search for a translation that is probable, but improbable given the wrong language indicator token. In experiments on M2M-100 (418M) and SMaLL-100, we find that these methods effectively suppress hallucinations and off-target translations, improving chrF2 by 1.7 and 1.4 points on average across 57 tested translation directions. In a proof of concept on English--German, we also show that we can suppress off-target translat
    
[^4]: Whisper能够进行基于语境的语音学习吗？

    Can Whisper perform speech-based in-context learning. (arXiv:2309.07081v1 [eess.AS])

    [http://arxiv.org/abs/2309.07081](http://arxiv.org/abs/2309.07081)

    本文研究了Whisper自动语音识别模型的语境学习能力，并提出了一种基于语境的语音学习方法，用于在测试时适应。通过实验验证了该方法在中文方言上的有效性，可以显著减少单词错误率。通过进一步优化选择技术可以进一步提高效率。

    

    本文研究了OpenAI发布的Whisper自动语音识别（ASR）模型的语境学习能力。提出了一种新的基于语境的语音学习（SICL）方法，用于测试时适应，可以在没有梯度下降的情况下减少单词错误率（WER），只需要少量标记的语音样本。使用中文方言进行语言级别的适应实验表明，在将SICL应用于孤立词ASR时，可以在两个方言上使用任意大小的Whisper模型实现一致且显著的WER相对降低，平均为32.3%。基于k最近邻的上下文示例选择技术可以进一步提高SICL的效率，平均相对WER降低率为36.4%。通过说话人适应或连续语音识别任务来验证了这些发现，并且两者都实现了显著的相对WER降低。还提供了详细的定量分析。

    This paper investigates the in-context learning abilities of the Whisper automatic speech recognition (ASR) models released by OpenAI. A novel speech-based in-context learning (SICL) approach is proposed for test-time adaptation, which can reduce the word error rates (WERs) with only a small number of labelled speech samples without gradient descent. Language-level adaptation experiments using Chinese dialects showed that when applying SICL to isolated word ASR, consistent and considerable relative WER reductions can be achieved using Whisper models of any size on two dialects, which is on average 32.3%. A k-nearest-neighbours-based in-context example selection technique can be applied to further improve the efficiency of SICL, which can increase the average relative WER reduction to 36.4%. The findings are verified using speaker adaptation or continuous speech recognition tasks, and both achieved considerable relative WER reductions. Detailed quantitative analyses are also provided to
    
[^5]: 用于编译优化的大型语言模型

    Large Language Models for Compiler Optimization. (arXiv:2309.07062v1 [cs.PL])

    [http://arxiv.org/abs/2309.07062](http://arxiv.org/abs/2309.07062)

    本论文研究了将大型语言模型应用于代码优化的新颖方法，以7B参数的transformer模型为例，通过预测指令计数和生成优化代码等辅助学习任务，显著提高了模型的优化性能。在大量测试程序上的评估中，该方法相对编译器的优化效果提高了3.0%，并展现出令人惊喜的强大代码推理能力。

    

    我们探索了将大型语言模型应用于代码优化的新颖方法。我们展示了一个从头开始训练的7B参数的transformer模型，用于优化LLVM汇编的代码大小。该模型以未优化的汇编作为输入，并输出一组最佳优化程序的编译器选项。在训练过程中，我们要求模型预测优化前后的指令计数和优化后的代码本身。这些辅助学习任务显著提高了模型的优化性能，并提高了模型的理解深度。我们在一套大型测试程序上进行了评估。我们的方法在减少指令计数方面比编译器提高了3.0%，超过了需要数千次编译的两个最先进的基准方法。此外，该模型显示出令人惊讶的强大的代码推理能力，91%的时间生成可编译的代码，并70%的时间能完美模拟编译器的输出。

    We explore the novel application of Large Language Models to code optimization. We present a 7B-parameter transformer model trained from scratch to optimize LLVM assembly for code size. The model takes as input unoptimized assembly and outputs a list of compiler options to best optimize the program. Crucially, during training, we ask the model to predict the instruction counts before and after optimization, and the optimized code itself. These auxiliary learning tasks significantly improve the optimization performance of the model and improve the model's depth of understanding.  We evaluate on a large suite of test programs. Our approach achieves a 3.0% improvement in reducing instruction counts over the compiler, outperforming two state-of-the-art baselines that require thousands of compilations. Furthermore, the model shows surprisingly strong code reasoning abilities, generating compilable code 91% of the time and perfectly emulating the output of the compiler 70% of the time.
    
[^6]: SafetyBench: 用多项选择题评估大型语言模型的安全性

    SafetyBench: Evaluating the Safety of Large Language Models with Multiple Choice Questions. (arXiv:2309.07045v1 [cs.CL])

    [http://arxiv.org/abs/2309.07045](http://arxiv.org/abs/2309.07045)

    SafetyBench是一个全面基准，用于评估大型语言模型的安全性。它包括了11,435个多项选择问题，涵盖了7个不同的安全问题类别，并且还提供中英文数据。通过对25个热门中英文LLM进行测试，我们发现GPT-4在性能上明显优于其他模型，但当前LLM的安全性仍有很大的提升空间。

    

    随着大型语言模型（LLM）的快速发展，人们越来越关注它们的安全问题。因此，评估LLM的安全性已成为促进其广泛应用的重要任务。然而，缺乏全面的安全评估基准明显阻碍了对LLM安全性的有效评估和提升。在这项工作中，我们提出了SafetyBench，这是一个用于评估LLMs安全性的全面基准，包括11,435个不同的多项选择问题，涵盖了7个不同的安全问题类别。值得注意的是，SafetyBench还包括中英文数据，方便两种语言的评估。我们在25个热门中英文LLM上进行了广泛的测试，包括零-shot和少-shot设置。结果显示，GPT-4在性能上明显优于其他模型，并且当前LLM的安全性还有很大的提升空间。

    With the rapid development of Large Language Models (LLMs), increasing attention has been paid to their safety concerns. Consequently, evaluating the safety of LLMs has become an essential task for facilitating the broad applications of LLMs. Nevertheless, the absence of comprehensive safety evaluation benchmarks poses a significant impediment to effectively assess and enhance the safety of LLMs. In this work, we present SafetyBench, a comprehensive benchmark for evaluating the safety of LLMs, which comprises 11,435 diverse multiple choice questions spanning across 7 distinct categories of safety concerns. Notably, SafetyBench also incorporates both Chinese and English data, facilitating the evaluation in both languages. Our extensive tests over 25 popular Chinese and English LLMs in both zero-shot and few-shot settings reveal a substantial performance advantage for GPT-4 over its counterparts, and there is still significant room for improving the safety of current LLMs. We believe Saf
    
[^7]: 如何（不）在主观NLP任务中使用社会人口统计信息

    How (Not) to Use Sociodemographic Information for Subjective NLP Tasks. (arXiv:2309.07034v1 [cs.CL])

    [http://arxiv.org/abs/2309.07034](http://arxiv.org/abs/2309.07034)

    该论文研究了如何使用社会人口统计信息在主观NLP任务中，发现社会人口提示技术在某些任务上有效，但也存在一些限制和挑战。

    

    注释者的社会人口背景（即性别，年龄，教育背景等个体组成）对其在主观NLP任务中的决策有很大影响，比如仇恨言论检测。通常，异质的背景会导致高度分歧。为了建模这种差异，最近的研究探索了社会人口提示技术，这种技术将基于提示的模型的输出引导到具有特定社会人口特征的人类可能给出的答案。然而，现有的NLP文献对这种技术的效果存在分歧 - 它仍然不清楚它能在哪些任务和场景中有帮助，并且评估仅限于特定任务。我们通过展示迄今为止最大和最全面的社会人口提示研究来填补这一研究空白。具体来说，我们评估了七个数据集和六个经过指导调整的模型家族中的几个提示形式。我们发现，尽管社会人口提示对某些任务有效，但也存在一些限制和挑战。

    Annotators' sociodemographic backgrounds (i.e., the individual compositions of their gender, age, educational background, etc.) have a strong impact on their decisions when working on subjective NLP tasks, such as hate speech detection. Often, heterogeneous backgrounds result in high disagreements. To model this variation, recent work has explored sociodemographic prompting, a technique, which steers the output of prompt-based models towards answers that humans with specific sociodemographic profiles would give. However, the available NLP literature disagrees on the efficacy of this technique -- it remains unclear, for which tasks and scenarios it can help and evaluations are limited to specific tasks only. We address this research gap by presenting the largest and most comprehensive study of sociodemographic prompting today. Concretely, we evaluate several prompt formulations across seven datasets and six instruction-tuned model families. We find that (1) while sociodemographic prompt
    
[^8]: 通过自然语言处理超越原始研究文章分类

    Beyond original Research Articles Categorization via NLP. (arXiv:2309.07020v1 [cs.CL])

    [http://arxiv.org/abs/2309.07020](http://arxiv.org/abs/2309.07020)

    本研究利用预训练的语言模型提出了一种新的文本分类方法，通过自然语言处理技术，能够更有效地捕捉科学文献中的主题信息，以改进文本分类。

    

    本研究提出了一种新的文本分类方法，用于科学文献中未知类别的分类，利用自然语言处理技术。该研究利用预训练的语言模型SciBERT，从ArXiv数据集中提取摘要的有意义的表示。文本分类使用K-Means算法完成，并根据轮廓系数评分确定最佳聚类数。结果表明，所提出的方法比传统的arXiv标签系统更有效地捕捉到主题信息，从而实现了改进的文本分类。这种方法在科学研究文献的快速增长环境中，有望提供更好的导航和推荐系统。

    This work proposes a novel approach to text categorization -- for unknown categories -- in the context of scientific literature, using Natural Language Processing techniques. The study leverages the power of pre-trained language models, specifically SciBERT, to extract meaningful representations of abstracts from the ArXiv dataset. Text categorization is performed using the K-Means algorithm, and the optimal number of clusters is determined based on the Silhouette score. The results demonstrate that the proposed approach captures subject information more effectively than the traditional arXiv labeling system, leading to improved text categorization. The approach offers potential for better navigation and recommendation systems in the rapidly growing landscape of scientific research literature.
    
[^9]: 简历解析作为分层序列标注的实证研究

    R\'esum\'e Parsing as Hierarchical Sequence Labeling: An Empirical Study. (arXiv:2309.07015v1 [cs.CL])

    [http://arxiv.org/abs/2309.07015](http://arxiv.org/abs/2309.07015)

    本研究将简历解析问题作为分层序列标注任务，提出了同时解决行和标记两个任务的模型架构，并构建了多语言的高质量简历解析语料库。实验结果表明，所提出模型在信息提取任务中优于先前工作中的方法。进一步分析了模型性能和资源效率，并描述了模型在生产环境中的权衡。

    

    从简历中提取信息通常被形式化为一个两阶段的问题，即首先将文档分段，然后对每个段落进行单独处理以提取目标实体。我们将整个问题分为两个级别的序列标注任务，即行和标记，并研究了同时解决这两个任务的模型架构。我们构建了英语、法语、中文、西班牙语、德语、葡萄牙语和瑞典语的高质量简历解析语料库。基于这些语料库，我们提出了实验结果，证明了所提出模型在信息提取任务中的有效性，优于先前工作中的方法。我们对所提出的架构进行了消融研究。我们还分析了模型的性能和资源效率，并描述了在生产环境中进行模型部署时的权衡。

    Extracting information from r\'esum\'es is typically formulated as a two-stage problem, where the document is first segmented into sections and then each section is processed individually to extract the target entities. Instead, we cast the whole problem as sequence labeling in two levels -- lines and tokens -- and study model architectures for solving both tasks simultaneously. We build high-quality r\'esum\'e parsing corpora in English, French, Chinese, Spanish, German, Portuguese, and Swedish. Based on these corpora, we present experimental results that demonstrate the effectiveness of the proposed models for the information extraction task, outperforming approaches introduced in previous work. We conduct an ablation study of the proposed architectures. We also analyze both model performance and resource efficiency, and describe the trade-offs for model deployment in the context of a production environment.
    
[^10]: OYXOY:适用于现代希腊语的现代NLP测试套件

    OYXOY: A Modern NLP Test Suite for Modern Greek. (arXiv:2309.07009v1 [cs.CL])

    [http://arxiv.org/abs/2309.07009](http://arxiv.org/abs/2309.07009)

    本文提出了一种适用于希腊语自然语言处理的现代NLP测试套件，其中包含四个专家验证的评估任务，用于自然语言推理、词义消歧和隐喻检测。创新之处在于推理数据集首次标记了所有可能的推理标签，并且展示了一种对于资源匮乏语言获取数据集的成本效益方法。

    

    本文是为希腊语自然语言处理开展的一项基础性工作，旨在创建一个基于语言学和技术相关性的评估套件。我们通过引入四个经过专家验证的评估任务来开展这项工作，这些任务专门针对自然语言推理、词义消歧（通过示例比较或选择意义）和隐喻检测。与现有任务的语言适应副本不同的是，我们贡献了两个创新点，这些将与更广泛的资源和评估社区产生共鸣。首先，我们推理数据集是首个标记了不仅仅是\texttt{一}种，而是\texttt{所有}可能推理标签的数据集，考虑到由于歧义性或多义性可能导致的可能转变。其次，我们展示了一种对于资源匮乏语言获取数据集的成本效益方法。通过使用ChatGPT作为语言中立解析器，我们将希腊现代标准词典转换为结构化格式，从中衍生出其他的数据集。

    This paper serves as a foundational step towards the development of a linguistically motivated and technically relevant evaluation suite for Greek NLP. We initiate this endeavor by introducing four expert-verified evaluation tasks, specifically targeted at natural language inference, word sense disambiguation (through example comparison or sense selection) and metaphor detection. More than language-adapted replicas of existing tasks, we contribute two innovations which will resonate with the broader resource and evaluation community. Firstly, our inference dataset is the first of its kind, marking not just \textit{one}, but rather \textit{all} possible inference labels, accounting for possible shifts due to e.g. ambiguity or polysemy. Secondly, we demonstrate a cost-efficient method to obtain datasets for under-resourced languages. Using ChatGPT as a language-neutral parser, we transform the Dictionary of Standard Modern Greek into a structured format, from which we derive the other th
    
[^11]: 无监督的对比一致排序与语言模型

    Unsupervised Contrast-Consistent Ranking with Language Models. (arXiv:2309.06991v1 [cs.LG])

    [http://arxiv.org/abs/2309.06991](http://arxiv.org/abs/2309.06991)

    无监督的对比一致排序与语言模型，通过训练一个受逻辑约束引导的探测模型，实现在多个语句中始终映射到对比的真-假极点的排序任务。

    

    语言模型包含基于排序的知识，并且是处理上下文排名任务的强大解决者。最近的研究关注于配对、点对和列表提示技术，以揭示语言模型的排序知识。然而，我们发现，即使在仔细校准和限制解码的情况下，基于提示的技术在产生的排序中也不总是自洽的。这促使我们探索一种受无监督探测方法Contrast-Consistent Search（CCS）启发的替代方法。这个想法是训练一个受逻辑约束引导的探测模型：模型对一个语句及其否定的表示必须在多个语句中始终映射到对比的真-假极点。我们假设类似的约束适用于所有项通过一致性对相关排序任务。

    Language models contain ranking-based knowledge and are powerful solvers of in-context ranking tasks. For instance, they may have parametric knowledge about the ordering of countries by size or may be able to rank reviews by sentiment. Recent work focuses on pairwise, pointwise, and listwise prompting techniques to elicit a language model's ranking knowledge. However, we find that even with careful calibration and constrained decoding, prompting-based techniques may not always be self-consistent in the rankings they produce. This motivates us to explore an alternative approach that is inspired by an unsupervised probing method called Contrast-Consistent Search (CCS). The idea is to train a probing model guided by a logical constraint: a model's representation of a statement and its negation must be mapped to contrastive true-false poles consistently across multiple statements. We hypothesize that similar constraints apply to ranking tasks where all items are related via consistent pair
    
[^12]: 使用图片描述远程推断ALS患者的认知得分

    Remote Inference of Cognitive Scores in ALS Patients Using a Picture Description. (arXiv:2309.06989v1 [cs.CL])

    [http://arxiv.org/abs/2309.06989](http://arxiv.org/abs/2309.06989)

    本研究使用图片描述远程推断ALS患者的认知得分，并成功实现了数字版本的ECAS测试。这项研究为有效监测ALS患者的认知障碍提供了一种可行的远程方法。

    

    肌萎缩性侧索硬化症是一种致命的疾病，不仅影响运动、说话和呼吸，还影响认知能力。最近的研究集中在使用语言分析技术检测ALS并推断用于监测功能进展的量表。本文着重于另一个重要方面，认知障碍，它影响35-50%的ALS患者群体。为了接触常常存在行动限制的ALS患者群体，我们首次实现了爱丁堡认知与行为ALS筛查(ECAS)的数字版本。这个用于测量认知障碍的测试被56名来自EverythingALS Speech Study的参与者远程执行。作为研究的一部分，参与者（ALS和非ALS）被要求在家中电脑上显示的复杂场景的众多图片中每周描述一张图片。我们分析了在ECAS测试被进行的60天内（前后）进行的描述。

    Amyotrophic lateral sclerosis is a fatal disease that not only affects movement, speech, and breath but also cognition. Recent studies have focused on the use of language analysis techniques to detect ALS and infer scales for monitoring functional progression. In this paper, we focused on another important aspect, cognitive impairment, which affects 35-50% of the ALS population. In an effort to reach the ALS population, which frequently exhibits mobility limitations, we implemented the digital version of the Edinburgh Cognitive and Behavioral ALS Screen (ECAS) test for the first time. This test which is designed to measure cognitive impairment was remotely performed by 56 participants from the EverythingALS Speech Study. As part of the study, participants (ALS and non-ALS) were asked to describe weekly one picture from a pool of many pictures with complex scenes displayed on their computer at home. We analyze the descriptions performed within +/- 60 days from the day the ECAS test was 
    
[^13]: 自回归的下一个标记预测器是通用学习器。

    Auto-Regressive Next-Token Predictors are Universal Learners. (arXiv:2309.06979v1 [cs.LG])

    [http://arxiv.org/abs/2309.06979](http://arxiv.org/abs/2309.06979)

    自回归的下一个标记预测器可以有效地近似图灵机计算的任何函数，并且在文本生成和算术任务上展现出非平凡的性能。

    

    大型语言模型展现出在逻辑和数学推理方面的非凡能力，使其能够解决复杂任务。有趣的是，这些能力在训练于下一个标记预测的简单任务上的网络中出现。在这项工作中，我们提出了一个用于研究自回归下一个标记预测器的理论框架。我们证明了即使是简单的模型，如线性下一个标记预测器，当其在思维链数据上训练时，可以有效地近似图灵机计算的任何函数。我们引入了一个新的复杂度度量——长度复杂度，它衡量了在近似某个目标函数时，思维链序列中所需的中间标记的数量，并分析了长度复杂度和其他复杂性概念之间的相互关系。最后，我们通过实验证明简单的下一个标记预测器，如线性网络和浅层多层感知机（MLP），在文本生成和算术任务上展示出非平凡的性能。

    Large language models display remarkable capabilities in logical and mathematical reasoning, allowing them to solve complex tasks. Interestingly, these abilities emerge in networks trained on the simple task of next-token prediction. In this work, we present a theoretical framework for studying auto-regressive next-token predictors. We demonstrate that even simple models such as linear next-token predictors, trained on Chain-of-Thought (CoT) data, can approximate any function efficiently computed by a Turing machine. We introduce a new complexity measure -- length complexity -- which measures the number of intermediate tokens in a CoT sequence required to approximate some target function, and analyze the interplay between length complexity and other notions of complexity. Finally, we show experimentally that simple next-token predictors, such as linear networks and shallow Multi-Layer Perceptrons (MLPs), display non-trivial performance on text generation and arithmetic tasks. Our resul
    
[^14]: 用于对话情感检测的动态因果解缠模型

    Dynamic Causal Disentanglement Model for Dialogue Emotion Detection. (arXiv:2309.06928v1 [cs.CL])

    [http://arxiv.org/abs/2309.06928](http://arxiv.org/abs/2309.06928)

    本文提出了一种动态因果解缠模型，通过分解对话内容和研究情感的时间积累，实现了更精确的情感识别。

    

    情感检测是一项在不同领域广泛应用的关键技术。尽管结合常识知识对现有情感检测方法的效果有益，但基于对话的情感检测面临着许多困难和挑战，其中包括人类行为和对话内容的变异性。在对话中，人类情感往往以突发方式积累，但它们通常是隐含表达的。这意味着许多真实情感在大量不相关的词汇和对话中被隐藏起来。本文提出了一种基于隐藏变量分离的动态因果解缠模型，该模型通过有效分解对话内容并研究情感的时间积累，从而实现更精确的情感识别。首先，我们引入了一种新颖的因果定向无环图 (DAG) 来建立隐藏情感信息之间的相关性。

    Emotion detection is a critical technology extensively employed in diverse fields. While the incorporation of commonsense knowledge has proven beneficial for existing emotion detection methods, dialogue-based emotion detection encounters numerous difficulties and challenges due to human agency and the variability of dialogue content.In dialogues, human emotions tend to accumulate in bursts. However, they are often implicitly expressed. This implies that many genuine emotions remain concealed within a plethora of unrelated words and dialogues.In this paper, we propose a Dynamic Causal Disentanglement Model based on hidden variable separation, which is founded on the separation of hidden variables. This model effectively decomposes the content of dialogues and investigates the temporal accumulation of emotions, thereby enabling more precise emotion recognition. First, we introduce a novel Causal Directed Acyclic Graph (DAG) to establish the correlation between hidden emotional informatio
    
[^15]: 基于Big Bird嵌入的母语识别

    Native Language Identification with Big Bird Embeddings. (arXiv:2309.06923v1 [cs.CL])

    [http://arxiv.org/abs/2309.06923](http://arxiv.org/abs/2309.06923)

    本研究通过使用Big Bird嵌入训练的分类器，在Reddit-L2数据集上超越了语言特征工程模型。此方法显示出了有效性和计算效率，为未来的母语识别工作提供了有前景的途径。

    

    母语识别旨在根据作者用另一种语言编写的内容来分类其母语。在历史上，该任务严重依赖耗时的语言特征工程，而基于Transformer的母语识别模型迄今为止未能提供有效、实用的替代方案。本研究研究了输入大小是否是一个限制因素，并展示了使用Big Bird嵌入训练的分类器在Reddit-L2数据集上相对于语言特征工程模型取得了显著的优势。此外，我们还提供了对输入长度依赖性的进一步洞察，展示了一致的样本外性能，并对嵌入空间进行了定性分析。考虑到这种方法的效果和计算效率，我们认为它为未来的母语识别工作提供了有前景的途径。

    Native Language Identification (NLI) intends to classify an author's native language based on their writing in another language. Historically, the task has heavily relied on time-consuming linguistic feature engineering, and transformer-based NLI models have thus far failed to offer effective, practical alternatives. The current work investigates if input size is a limiting factor, and shows that classifiers trained using Big Bird embeddings outperform linguistic feature engineering models by a large margin on the Reddit-L2 dataset. Additionally, we provide further insight into input length dependencies, show consistent out-of-sample performance, and qualitatively analyze the embedding space. Given the effectiveness and computational efficiency of this method, we believe it offers a promising avenue for future NLI work.
    
[^16]: 使用狄利克雷生成基础的回顾的连续学习

    Continual Learning with Dirichlet Generative-based Rehearsal. (arXiv:2309.06917v1 [cs.CL])

    [http://arxiv.org/abs/2309.06917](http://arxiv.org/abs/2309.06917)

    该论文提出了一种新颖的基于狄利克雷生成的回顾策略，用于解决连续学习中伪样本生成的挑战。

    

    最近在面向任务的数据驱动对话系统（ToDs）方面的进展由于计算约束和耗时问题而困扰着增量学习。连续学习（CL）试图通过避免密集的预训练来解决这个问题，但它面临着灾难性遗忘（CF）的问题。虽然基于生成的回顾CL方法取得了显著进展，但生成能准确反映底层任务特定分布的伪样本仍然是一个挑战。在本文中，我们提出了狄利克雷连续学习（DCL），这是一种新颖的基于生成的回顾策略用于CL。与传统上在条件变分自动编码器（CVAE）中使用的高斯潜变量不同，DCL利用狄利克雷分布的灵活性和多样性来建模潜变量先验。这使得它能够高效地捕捉先前任务的句级特征，并有效地指导伪样本的生成。此外还引入了Jensen-苏彻利散度作为训练目标，以进一步提高DCL的性能。

    Recent advancements in data-driven task-oriented dialogue systems (ToDs) struggle with incremental learning due to computational constraints and time-consuming issues. Continual Learning (CL) attempts to solve this by avoiding intensive pre-training, but it faces the problem of catastrophic forgetting (CF). While generative-based rehearsal CL methods have made significant strides, generating pseudo samples that accurately reflect the underlying task-specific distribution is still a challenge. In this paper, we present Dirichlet Continual Learning (DCL), a novel generative-based rehearsal strategy for CL. Unlike the traditionally used Gaussian latent variable in the Conditional Variational Autoencoder (CVAE), DCL leverages the flexibility and versatility of the Dirichlet distribution to model the latent prior variable. This enables it to efficiently capture sentence-level features of previous tasks and effectively guide the generation of pseudo samples. In addition, we introduce Jensen-
    
[^17]: 走向TopMost：一个主题建模系统工具包

    Towards the TopMost: A Topic Modeling System Toolkit. (arXiv:2309.06908v1 [cs.CL])

    [http://arxiv.org/abs/2309.06908](http://arxiv.org/abs/2309.06908)

    本文提出了一个名为TopMost的主题建模系统工具包，通过涵盖更广泛的主题建模场景和具有高度凝聚力和解耦模块化设计的特点，可以促进主题模型的研究和应用。

    

    主题模型已经在过去几十年中被提出，并且具有各种应用，在神经变分推断的推动下近期得到了更新。然而，这些主题模型采用完全不同的数据集、实现和评估设置，这阻碍了它们的快速利用和公平比较。这严重阻碍了主题模型的研究进展。为了解决这些问题，本文提出了一个主题建模系统工具包（TopMost）。与现有的工具包相比，TopMost通过涵盖更广泛的主题建模场景，包括数据集预处理、模型训练、测试和评估的完整生命周期，脱颖而出。TopMost的高度凝聚力和解耦模块化设计可以快速利用，公平比较，并灵活扩展不同的主题模型，这可以促进主题模型的研究和应用。我们的代码、教程和文档可在https://github.com/bobxwu/topmost 上获得。

    Topic models have been proposed for decades with various applications and recently refreshed by the neural variational inference. However, these topic models adopt totally distinct dataset, implementation, and evaluation settings, which hinders their quick utilization and fair comparisons. This greatly hinders the research progress of topic models. To address these issues, in this paper we propose a Topic Modeling System Toolkit (TopMost). Compared to existing toolkits, TopMost stands out by covering a wider range of topic modeling scenarios including complete lifecycles with dataset pre-processing, model training, testing, and evaluations. The highly cohesive and decoupled modular design of TopMost enables quick utilization, fair comparisons, and flexible extensions of different topic models. This can facilitate the research and applications of topic models. Our code, tutorials, and documentation are available at https://github.com/bobxwu/topmost.
    
[^18]: Gpachov在CheckThat！2023中：一种多样的多方法集成用于新闻文章主观性检测

    Gpachov at CheckThat! 2023: A Diverse Multi-Approach Ensemble for Subjectivity Detection in News Articles. (arXiv:2309.06844v1 [cs.CL])

    [http://arxiv.org/abs/2309.06844](http://arxiv.org/abs/2309.06844)

    Gpachov团队在CLEF-2023 CheckThat！实验室任务2中构建了一种多样的多方法集成解决方案，通过微调句子嵌入编码模型、样本高效的少样本学习模型和多语言转换器等方法结合得到了0.77的宏F1分数，并在英语子任务中获得第二名。

    

    社交网络的广泛使用导致了互联网上的主观、误导甚至虚假信息的出现。因此，主观性检测在确保信息客观性和质量方面扮演着重要角色。本文介绍了Gpachov团队针对CLEF-2023 CheckThat！实验室任务2的主观性检测构建的解决方案。文章探索了三个不同的研究方向。第一个方向基于微调句子嵌入编码模型和降维。第二个方向探索了一种样本高效的少样本学习模型。第三个方向评估了在经过修改的数据集上微调多语言转换器，使用了多种语言的数据。最后，将这三种方法以简单的多数投票集成，结果在测试集上达到了0.77的宏F1，并在英语子任务上取得了第二名。

    The wide-spread use of social networks has given rise to subjective, misleading, and even false information on the Internet. Thus, subjectivity detection can play an important role in ensuring the objectiveness and the quality of a piece of information. This paper presents the solution built by the Gpachov team for the CLEF-2023 CheckThat! lab Task~2 on subjectivity detection. Three different research directions are explored. The first one is based on fine-tuning a sentence embeddings encoder model and dimensionality reduction. The second one explores a sample-efficient few-shot learning model. The third one evaluates fine-tuning a multilingual transformer on an altered dataset, using data from multiple languages. Finally, the three approaches are combined in a simple majority voting ensemble, resulting in 0.77 macro F1 on the test set and achieving 2nd place on the English subtask.
    
[^19]: 基于深度学习模型的上下文关系提取的比较分析

    Comparative Analysis of Contextual Relation Extraction based on Deep Learning Models. (arXiv:2309.06814v1 [cs.CL])

    [http://arxiv.org/abs/2309.06814](http://arxiv.org/abs/2309.06814)

    本文比较分析了基于深度学习模型的上下文关系提取方法。现有技术无法高效预测由多于两个关系和未指定实体组成的句子中的复杂关系。研究采用深度学习技术从多个句子的语境中识别语义关系。现有机器学习模型在二元关系中表现较好，但随着关系数量的增加，预测准确率降低。

    

    上下文关系提取主要用于借助本体构建知识图谱，在语义搜索、查询回答和文本蕴涵等方面起到重要作用。关系提取识别原始文本中的实体及其之间的关系。在生物医药行业中，高效准确的上下文关系提取系统对于创建领域知识至关重要。现有的机器学习和自然语言处理技术无法高效地从由多于两个关系和未指定实体组成的句子中预测复杂关系。本研究使用深度学习技术，从多个句子的语境中识别出适当的语义关系。尽管关系提取中使用了各种机器学习模型，但它们只对二元关系（即在句子中完全发生在两个实体之间的关系）提供更好的结果。机器学习模型的预测准确率会随着关系的数量增加而降低。

    Contextual Relation Extraction (CRE) is mainly used for constructing a knowledge graph with a help of ontology. It performs various tasks such as semantic search, query answering, and textual entailment. Relation extraction identifies the entities from raw texts and the relations among them. An efficient and accurate CRE system is essential for creating domain knowledge in the biomedical industry. Existing Machine Learning and Natural Language Processing (NLP) techniques are not suitable to predict complex relations from sentences that consist of more than two relations and unspecified entities efficiently. In this work, deep learning techniques have been used to identify the appropriate semantic relation based on the context from multiple sentences. Even though various machine learning models have been used for relation extraction, they provide better results only for binary relations, i.e., relations occurred exactly between the two entities in a sentence. Machine learning models are
    
[^20]: 认知幻觉：大规模语言模型中幻觉现象的综述

    Cognitive Mirage: A Review of Hallucinations in Large Language Models. (arXiv:2309.06794v1 [cs.CL])

    [http://arxiv.org/abs/2309.06794](http://arxiv.org/abs/2309.06794)

    这篇论文综述了大规模语言模型中幻觉的现象，并提出了幻觉的分类、理论分析、检测方法和改进方法，同时还设想了未来的研究方向。

    

    随着人工智能领域中大规模语言模型的发展，文本生成系统容易受到一种令人担忧的现象，即幻觉。在本研究中，我们总结了最近关于大规模语言模型中幻觉的引人注目的见解。我们提出了一种针对各种文本生成任务的幻觉的新分类体系，从而提供了理论性的洞见、检测方法和改进方法。基于此，我们提出了未来的研究方向。我们的贡献有三个方面：（1）我们为出现在文本生成任务中的幻觉提供了详细和完整的分类体系；（2）我们对大规模语言模型中的幻觉进行了理论分析，并提供了现有的检测和改进方法；（3）我们提出了几个未来可以发展的研究方向。由于幻觉受到了学术界的广泛关注，我们将维护与相关研究进展的更新。

    As large language models continue to develop in the field of AI, text generation systems are susceptible to a worrisome phenomenon known as hallucination. In this study, we summarize recent compelling insights into hallucinations in LLMs. We present a novel taxonomy of hallucinations from various text generation tasks, thus provide theoretical insights, detection methods and improvement approaches. Based on this, future research directions are proposed. Our contribution are threefold: (1) We provide a detailed and complete taxonomy for hallucinations appearing in text generation tasks; (2) We provide theoretical analyses of hallucinations in LLMs and provide existing detection and improvement methods; (3) We propose several research directions that can be developed in the future. As hallucinations garner significant attention from the community, we will maintain updates on relevant research progress.
    
[^21]: Scaled Prompt-Tuning for Few-Shot Natural Language Generation. (arXiv:2309.06759v1 [cs.CL])

    Scaled Prompt-Tuning for Few-Shot Natural Language Generation. (arXiv:2309.06759v1 [cs.CL])

    [http://arxiv.org/abs/2309.06759](http://arxiv.org/abs/2309.06759)

    本论文提出了一种Scaled Prompt-Tuning (SPT)方法，用于少样本自然语言生成 (NLG)。该方法冻结大多数参数，只微调其中一小部分参数，以减少内存占用、训练成本和标注成本，并在性能和泛化能力方面超越了传统的方法。在少样本情况下，SPT展现了更好的迁移能力。

    

    越来越强大的大型语言模型（LLMs）展示了更强的语言理解和生成能力，但对下游任务对LLMs进行微调的内存需求和计算成本是不可忽视的。此外，微调通常需要来自各个任务的一定数量的数据，而数据收集成本是实际应用中需要考虑的另一个问题。在这项工作中，我们关注少样本自然语言生成（NLG）的参数高效微调（PEFT）方法，该方法冻结LLMs中的大多数参数，并在少样本情况下微调一小部分参数，以降低内存占用、训练成本和标注成本，同时保持甚至提高性能。我们提出了一种Scaled Prompt-Tuning (SPT)方法，它在性能和泛化能力方面超越了传统的Prompt-Tuning (PT)方法，但没有明显增加训练成本。进一步研究表明，在少样本情况下，SPT具有更好的迁移能力。

    The increasingly Large Language Models (LLMs) demonstrate stronger language understanding and generation capabilities, while the memory demand and computation cost of fine-tuning LLMs on downstream tasks are non-negligible. Besides, fine-tuning generally requires a certain amount of data from individual tasks whilst data collection cost is another issue to consider in real-world applications. In this work, we focus on Parameter-Efficient Fine-Tuning (PEFT) methods for few-shot Natural Language Generation (NLG), which freeze most parameters in LLMs and tune a small subset of parameters in few-shot cases so that memory footprint, training cost, and labeling cost are reduced while maintaining or even improving the performance. We propose a Scaled Prompt-Tuning (SPT) method which surpasses conventional PT with better performance and generalization ability but without an obvious increase in training cost. Further study on intermediate SPT suggests the superior transferability of SPT in few-
    
[^22]: CONVERSER：使用合成数据生成的少样本对话密集检索

    CONVERSER: Few-Shot Conversational Dense Retrieval with Synthetic Data Generation. (arXiv:2309.06748v1 [cs.CL])

    [http://arxiv.org/abs/2309.06748](http://arxiv.org/abs/2309.06748)

    CONVERSER是一个使用少量对话样本进行训练的对话式密集检索框架，通过利用大型语言模型的上下文学习能力，能够生成与检索语料库中段落相关的对话查询，实验结果表明其在少样本对话密集检索中表现出与完全监督模型相当的性能。

    

    对话式搜索为信息检索提供了自然界面。最近的方法在对话式信息检索中应用了密集检索取得了有希望的结果。然而，训练密集检索器需要大量的领域相关的配对数据。这限制了对话式密集检索器的发展，因为收集大量领域相关对话是昂贵的。在本文中，我们提出了CONVERSER，这是一个用最多6对领域相关对话进行训练的对话式密集检索框架。具体而言，我们利用大型语言模型的上下文学习能力，根据检索语料库中的段落生成对话查询。对OR-QuAC和TREC CAsT 19等对话检索基准进行的实验结果表明，所提出的CONVERSER达到了与完全监督模型相当的性能，证明了我们提出的少样本对话密集检索框架的有效性。

    Conversational search provides a natural interface for information retrieval (IR). Recent approaches have demonstrated promising results in applying dense retrieval to conversational IR. However, training dense retrievers requires large amounts of in-domain paired data. This hinders the development of conversational dense retrievers, as abundant in-domain conversations are expensive to collect. In this paper, we propose CONVERSER, a framework for training conversational dense retrievers with at most 6 examples of in-domain dialogues. Specifically, we utilize the in-context learning capability of large language models to generate conversational queries given a passage in the retrieval corpus. Experimental results on conversational retrieval benchmarks OR-QuAC and TREC CAsT 19 show that the proposed CONVERSER achieves comparable performance to fully-supervised models, demonstrating the effectiveness of our proposed framework in few-shot conversational dense retrieval. All source code and
    
[^23]: 通过拆分和重排BART微调来增强关键短语生成

    Enhancing Keyphrase Generation by BART Finetuning with Splitting and Shuffling. (arXiv:2309.06726v1 [cs.CL])

    [http://arxiv.org/abs/2309.06726](http://arxiv.org/abs/2309.06726)

    本文提出了关注关键短语的BART模型(Keyphrase-Focused BART)，通过拆分和重排的方式来增强关键短语生成的性能。在不出现的关键短语生成任务中，该模型在两个关键短语生成基准数据集上取得了新的最佳得分。

    

    关键短语生成是一项识别最佳代表给定文本主题或主题的短语集的任务。关键短语分为出现和不在出现的关键短语。最近利用序列到序列模型的方法在不出现的关键短语生成上显示出了效果。然而，由于找到不出现的关键短语的难度，性能仍然有限。在本文中，我们提出了关注关键短语的BART模型(Keyphrase-Focused BART)，利用了出现和不出现关键短语生成之间的差异，并对出现和不出现关键短语分别进行了两个独立BART模型的微调。我们进一步展示了关键短语的重排和候选关键短语排序的有效方法。对于不出现的关键短语，在五个关键短语生成基准数据集中，我们的关注关键短语的BART在F1@5上取得了新的最佳得分。

    Keyphrase generation is a task of identifying a set of phrases that best repre-sent the main topics or themes of a given text. Keyphrases are dividend int pre-sent and absent keyphrases. Recent approaches utilizing sequence-to-sequence models show effectiveness on absent keyphrase generation. However, the per-formance is still limited due to the hardness of finding absent keyphrases. In this paper, we propose Keyphrase-Focused BART, which exploits the differ-ences between present and absent keyphrase generations, and performs fine-tuning of two separate BART models for present and absent keyphrases. We further show effective approaches of shuffling keyphrases and candidate keyphrase ranking. For absent keyphrases, our Keyphrase-Focused BART achieved new state-of-the-art score on F1@5 in two out of five keyphrase gen-eration benchmark datasets.
    
[^24]: 使用大型语言模型的同时机器翻译

    Simultaneous Machine Translation with Large Language Models. (arXiv:2309.06706v1 [cs.CL])

    [http://arxiv.org/abs/2309.06706](http://arxiv.org/abs/2309.06706)

    本文研究了使用大型语言模型进行同时机器翻译的可行性，通过引入混合策略，并进行有监督微调，取得了显著的性能改进。

    

    通过对话式交互，大型语言模型 (LLM) 已经展示出解决各种自然语言处理任务的能力。例如，研究表明，LLM可以在高资源语言的离线机器翻译任务中取得竞争性的性能。然而，将LLM应用于同时机器翻译 (SimulMT) 面临许多挑战，包括与不同解码模式产生的训练-推理不匹配问题。本文探索了利用LLM进行SimulMT的可行性。在传统方法的基础上，我们引入了一个简单而有效的混合策略，使LLM能够在不需要额外训练的情况下参与SimulMT。此外，在对全句和前缀句子进行有监督微调后，该模型展示出了显著的性能改进。我们使用MUST-C数据集上的九种语言对进行实验，结果表明LLM可以实现同时机器翻译。

    Large language models (LLM) have demonstrated their abilities to solve various natural language processing tasks through dialogue-based interactions. For instance, research indicates that LLMs can achieve competitive performance in offline machine translation tasks for high-resource languages. However, applying LLMs to simultaneous machine translation (SimulMT) poses many challenges, including issues related to the training-inference mismatch arising from different decoding patterns. In this paper, we explore the feasibility of utilizing LLMs for SimulMT. Building upon conventional approaches, we introduce a simple yet effective mixture policy that enables LLMs to engage in SimulMT without requiring additional training. Furthermore, after Supervised Fine-Tuning (SFT) on a mixture of full and prefix sentences, the model exhibits significant performance improvements. Our experiments, conducted with Llama2-7B-chat on nine language pairs from the MUST-C dataset, demonstrate that LLM can ac
    
[^25]: VLSlice：交互式视觉和语言切片发现

    VLSlice: Interactive Vision-and-Language Slice Discovery. (arXiv:2309.06703v1 [cs.CV])

    [http://arxiv.org/abs/2309.06703](http://arxiv.org/abs/2309.06703)

    这项工作提出了一种交互式系统VLSlice，可以通过用户引导发现一致的视觉和语言行为的表示级子组，以解决自动发现子组时的困难。

    

    最近的视觉和语言研究表明，大规模预训练可以学习出具有通用性的模型，可以有效地迁移到下游任务。尽管这可能改善数据集规模的聚合指标，但通过分析针对特定偏差维度的手工子组时，发现了系统性的不良行为。然而，这种子组分析通常会因为注释工作而停滞，而收集所需数据需要大量的时间和资源。先前的方法尝试自动发现子组以规避这些限制，但通常利用现有任务特定注释上的模型行为，并在超出“表格”数据的更复杂输入上快速降级，其中没有研究视觉和语言模型。本文介绍了VLSlice，一种交互式系统，可以通过用户引导发现一致的表示级子组，具有一致的视觉语言行为，被称为视觉和语言切片，从未标记的图像中获取。

    Recent work in vision-and-language demonstrates that large-scale pretraining can learn generalizable models that are efficiently transferable to downstream tasks. While this may improve dataset-scale aggregate metrics, analyzing performance around hand-crafted subgroups targeting specific bias dimensions reveals systemic undesirable behaviors. However, this subgroup analysis is frequently stalled by annotation efforts, which require extensive time and resources to collect the necessary data. Prior art attempts to automatically discover subgroups to circumvent these constraints but typically leverages model behavior on existing task-specific annotations and rapidly degrades on more complex inputs beyond "tabular" data, none of which study vision-and-language models. This paper presents VLSlice, an interactive system enabling user-guided discovery of coherent representation-level subgroups with consistent visiolinguistic behavior, denoted as vision-and-language slices, from unlabeled ima
    
[^26]: 用于低资源语言的程序性语言理解基准测试：以土耳其语为例的案例研究

    Benchmarking Procedural Language Understanding for Low-Resource Languages: A Case Study on Turkish. (arXiv:2309.06698v1 [cs.CL])

    [http://arxiv.org/abs/2309.06698](http://arxiv.org/abs/2309.06698)

    本研究通过对土耳其语的程序文本进行案例研究，扩展了土耳其wikiHow的教程数量，并研究了几个下游任务。研究发现，在大多数任务中，语言特定模型相对于多语言模型具有明显优势。

    

    理解程序性自然语言（例如，逐步说明）是执行和规划的关键步骤。然而，虽然英语中存在丰富的语料库和下游任务，但大多数语言缺乏这样的资源。为了解决这个问题，我们对土耳其程序文本进行了案例研究。我们首先使用自动翻译工具将土耳其wikiHow中的教程数量从2,000个扩展到52,000个，翻译质量和对原始含义的忠实性由专家团队在一个随机集上进行验证。然后，我们在语料库上生成了多个下游任务，例如链接操作、目标推理和摘要。为了解决这些任务，我们通过微调大型语言特定模型（如TR-BART和BERTurk）以及多语言模型（如mBART、mT5和XLM）实现了强基线模型。我们发现，在大多数任务中，语言特定模型始终以显著的优势胜过多语言模型。

    Understanding procedural natural language (e.g., step-by-step instructions) is a crucial step to execution and planning. However, while there are ample corpora and downstream tasks available in English, the field lacks such resources for most languages. To address this gap, we conduct a case study on Turkish procedural texts. We first expand the number of tutorials in Turkish wikiHow from 2,000 to 52,000 using automated translation tools, where the translation quality and loyalty to the original meaning are validated by a team of experts on a random set. Then, we generate several downstream tasks on the corpus, such as linking actions, goal inference, and summarization. To tackle these tasks, we implement strong baseline models via fine-tuning large language-specific models such as TR-BART and BERTurk, as well as multilingual models such as mBART, mT5, and XLM. We find that language-specific models consistently outperform their multilingual models by a significant margin across most pr
    
[^27]: 统计拒绝抽样改进了优化偏好方法

    Statistical Rejection Sampling Improves Preference Optimization. (arXiv:2309.06657v1 [cs.CL])

    [http://arxiv.org/abs/2309.06657](http://arxiv.org/abs/2309.06657)

    本文提出了一种名为统计拒绝抽样的新方法，改进了优化偏好的过程，并解决了传统方法中缺乏奖励模型和从最优策略采样偏好对的问题。

    

    提高语言模型与人类偏好的一致性仍然是一个活跃的研究挑战。之前的方法主要使用强化学习从人类反馈中学习（RLHF），通过在线强化学习方法如近端策略优化（PPO）。最近，离线方法如序列似然校准（SLiC）和直接偏好优化（DPO）已经成为有吸引力的替代方案，提供了稳定性和可扩展性的改进，同时保持了竞争性能。SLiC通过使用从经过监督微调（SFT）策略中采样的序列对来优化其损失函数，而DPO直接根据偏好数据优化语言模型，无需单独的奖励模型。然而，目标最优策略的最大似然估计器（MLE）需要从该策略中采样标记的偏好对。DPO缺乏奖励模型限制其从最优策略中采样偏好对的能力，而SLiC则受到了限制。

    Improving the alignment of language models with human preferences remains an active research challenge. Previous approaches have primarily utilized Reinforcement Learning from Human Feedback (RLHF) via online RL methods such as Proximal Policy Optimization (PPO). Recently, offline methods such as Sequence Likelihood Calibration (SLiC) and Direct Preference Optimization (DPO) have emerged as attractive alternatives, offering improvements in stability and scalability while maintaining competitive performance. SLiC refines its loss function using sequence pairs sampled from a supervised fine-tuned (SFT) policy, while DPO directly optimizes language models based on preference data, foregoing the need for a separate reward model. However, the maximum likelihood estimator (MLE) of the target optimal policy requires labeled preference pairs sampled from that policy. DPO's lack of a reward model constrains its ability to sample preference pairs from the optimal policy, and SLiC is restricted t
    
[^28]: RT-LM: 面向实时推理的语言模型不确定性感知资源管理

    RT-LM: Uncertainty-Aware Resource Management for Real-Time Inference of Language Models. (arXiv:2309.06619v1 [cs.LG])

    [http://arxiv.org/abs/2309.06619](http://arxiv.org/abs/2309.06619)

    这篇论文介绍了RT-LM，它是一种针对语言模型的实时推理进行优化的不确定性感知资源管理方法。该方法能够理解、量化和优化由于语言的不确定性而导致的推理延迟性能变化，以提高LMs的整体性能。

    

    最近语言模型（LMs）的进展引起了人们的广泛关注，因为它们具备生成类似人类回应的能力。尽管在对话AI等各种应用中展示了良好的前景，但由于计算成本极高且推理延迟无法预测，这些LMs在各种设备上的部署面临挑战。由于语言的本质导致的不确定性引发的不同推理延迟可能导致计算效率不高，从而降低LMs的整体性能，特别是在高流量的工作负载下。不幸的是，这些不确定性源的带宽非常广泛，给延迟的预测和由此产生的效果带来了复杂性。为了了解和减轻不确定性对实时响应需求系统的影响，我们首先要理解、量化和优化LMs中这些不确定性导致的延迟性能变化。具体而言，我们提出了RT-LM

    Recent advancements in language models (LMs) have gained substantial attentions on their capability to generate human-like responses. Though exhibiting a promising future for various applications such as conversation AI, these LMs face deployment challenges on various devices due to their extreme computational cost and unpredictable inference latency. Such varied inference latency, identified as a consequence of uncertainty intrinsic to the nature of language, can lead to computational inefficiency and degrade the overall performance of LMs, especially under high-traffic workloads. Unfortunately, the bandwidth of these uncertainty sources is extensive, complicating the prediction of latency and the effects emanating from such uncertainties. To understand and mitigate the impact of uncertainty on real-time response-demanding systems, we take the first step to comprehend, quantify and optimize these uncertainty-induced latency performance variations in LMs. Specifically, we present RT-LM
    
[^29]: 叙事作为一个动力系统

    Narrative as a Dynamical System. (arXiv:2309.06600v1 [cs.CL])

    [http://arxiv.org/abs/2309.06600](http://arxiv.org/abs/2309.06600)

    叙事可以被视为一个动力系统，其演化可以用一个行动积分来描述，并且平均路径与行动原理一致。

    

    越来越多的证据表明，人类活动的全过程以及叙事可以被视为物理意义上的动力系统；一个由行动积分描述其演化的系统，使得从A点到B点的所有可能路径的平均值由行动的极大值给出。我们通过平均约500个不同的叙事构建了三条这样的路径，并且我们展示了平均路径与行动原理一致。

    There is increasing evidence that human activity in general, and narrative in particular, can be treated as a dynamical system in the physics sense; a system whose evolution is described by an action integral, such that the average of all possible paths from point A to point B is given by the extremum of the action. We create by construction three such paths by averaging about 500 different narratives, and we show that the average path is consistent with an action principle.
    
[^30]: 生成大语言模型是否需要数十亿个参数？

    Do Generative Large Language Models need billions of parameters?. (arXiv:2309.06589v1 [cs.CL])

    [http://arxiv.org/abs/2309.06589](http://arxiv.org/abs/2309.06589)

    本文研究了生成大语言模型的规模、性能和计算资源之间的权衡，并提出了新方法来减少参数数量，从而创建更高效、紧凑的模型，为AI语言建模的可持续和可访问的未来做出了贡献。

    

    本文提出了用于开发高效大语言模型(LLMs)的新系统和方法。它探讨了模型大小、性能和计算资源之间的权衡，旨在最大化这些人工智能系统的效率。研究探索了允许模型的不同部分共享参数的新方法，从而减少所需的独立参数总数。这种方法确保了模型既紧凑又不损失学习和表示复杂语言结构的能力。本研究为创建更高效、更有效的LLMs提供了宝贵的见解和工具，为AI语言建模的可持续和可访问的未来做出了贡献。

    This paper presents novel systems and methodologies for the development of efficient large language models (LLMs). It explores the trade-offs between model size, performance, and computational resources, with the aim of maximizing the efficiency of these AI systems. The research explores novel methods that allow different parts of the model to share parameters, reducing the total number of unique parameters required. This approach ensures that the model remains compact without sacrificing its ability to learn and represent complex language structures. This study provides valuable insights and tools for creating more efficient and effective LLMs, contributing to a more sustainable and accessible future for AI language modeling.
    
[^31]: 人类能帮助BERT获得“信心”吗？

    Can humans help BERT gain "confidence"?. (arXiv:2309.06580v1 [cs.CL])

    [http://arxiv.org/abs/2309.06580](http://arxiv.org/abs/2309.06580)

    本论文研究了如何将苏黎世认知语料库的认知特征与BERT模型集成，证明了脑电图和眼动特征可以提高自然语言处理模型的性能，并开发了一个用于基准测试的词-EEG词典。

    

    过去十年中，人工智能的进步为跨学科研究开辟了多种途径。由于人工智能的灵感来自大脑神经元的工作原理，将这两个领域结合起来，并利用认知数据来训练AI模型似乎是非常实际的。这不仅有助于更深入地理解技术，还有助于理解大脑。在本论文中，我进行了新颖的实验，将苏黎世认知语料库（ZuCo）的认知特征与基于变压器的编码器模型BERT集成。我展示了来自ZuCo的脑电图（EEG）和眼动特征如何帮助提高自然语言处理模型的性能。我利用一个鲁棒性检查流水线确认了性能的提升，并生成了一个单词-EEG词典，用于在没有任何认知特征的外部数据集上进行基准测试。此外，我分析了内部工作机制。

    The advancements in artificial intelligence over the last decade have opened a multitude of avenues for interdisciplinary research. Since the idea of artificial intelligence was inspired by the working of neurons in the brain, it seems pretty practical to combine the two fields and take the help of cognitive data to train AI models. Not only it will help to get a deeper understanding of the technology, but of the brain as well. In this thesis, I conduct novel experiments to integrate cognitive features from the Zurich Cognitive Corpus (ZuCo) (Hollenstein et al., 2018) with a transformer-based encoder model called BERT. I show how EEG and eye-tracking features from ZuCo can help to increase the performance of the NLP model. I confirm the performance increase with the help of a robustness-checking pipeline and derive a word-EEG lexicon to use in benchmarking on an external dataset that does not have any cognitive features associated with it. Further, I analyze the internal working mechan
    
[^32]: 大型语言模型能否辨别科学假设的证据？社会科学案例研究。

    Can Large Language Models Discern Evidence for Scientific Hypotheses? Case Studies in the Social Sciences. (arXiv:2309.06578v1 [cs.CL])

    [http://arxiv.org/abs/2309.06578](http://arxiv.org/abs/2309.06578)

    本文研究了大型语言模型（LLMs）根据科学摘要文本的能力，来辨别支持或反驳特定假设的证据。通过社区驱动的注释建立了一个新的数据集，针对社会科学中的科学假设证据任务。与其他基准进行了性能比较，并为未来研究提供了机会。

    

    假设的制定和测试是经验性研究的核心。一个强有力的假设是基于现有证据的最佳猜测，并且是基于相关文献的全面视图进行启发的。然而，随着每年科学文章数量的指数增长，对于给定假设相关证据的手动汇总和综合是一项挑战。我们的工作探索了当前大型语言模型（LLMs）根据科学摘要文本中的证据，能否辨别支持或反驳特定假设的能力。我们共享了一个新颖的数据集，用于社会科学中使用社区驱动的研究注释的科学假设证据任务。我们将LLMs的性能与几个最先进的基准进行比较，并指出未来研究的机会。该数据集可在https://github.com/Sai90000/ScientificHypothesisEvidencing.git上获得。

    Hypothesis formulation and testing are central to empirical research. A strong hypothesis is a best guess based on existing evidence and informed by a comprehensive view of relevant literature. However, with exponential increase in the number of scientific articles published annually, manual aggregation and synthesis of evidence related to a given hypothesis is a challenge. Our work explores the ability of current large language models (LLMs) to discern evidence in support or refute of specific hypotheses based on the text of scientific abstracts. We share a novel dataset for the task of scientific hypothesis evidencing using community-driven annotations of studies in the social sciences. We compare the performance of LLMs to several state-of-the-art benchmarks and highlight opportunities for future research in this area. The dataset is available at https://github.com/Sai90000/ScientificHypothesisEvidencing.git
    
[^33]: 解决口语语言处理的盲区

    Addressing the Blind Spots in Spoken Language Processing. (arXiv:2309.06572v1 [eess.AS])

    [http://arxiv.org/abs/2309.06572](http://arxiv.org/abs/2309.06572)

    本文探讨了非语言线索在人类交流中的关键作用，并借鉴手语处理的进展，提出发展通用的自动手势分割和转录模型来弥补口语语言理解中的盲点，并增强NLP模型的范围和适用性。

    

    本文探讨了非语言线索在人类交流中的关键但往往被忽视的作用，包括协同语言手势和面部表情，并探讨这些线索对自然语言处理（NLP）的影响。我们认为理解人类交流需要一种更全面的方法，超越文本或口语词汇，包括非语言元素。借鉴手语处理的进展，我们提出发展通用的自动手势分割和转录模型，将这些非语言线索转录成文本形式。这种方法旨在弥补口语语言理解中的盲点，增强NLP模型的范围和适用性。通过示例，我们证明了仅依靠基于文本的模型的局限性。我们提出了一种计算效率高且灵活的方法，可以与现有的NLP流程无缝融合，并通过呼吁对现有方法的改进来结束。

    This paper explores the critical but often overlooked role of non-verbal cues, including co-speech gestures and facial expressions, in human communication and their implications for Natural Language Processing (NLP). We argue that understanding human communication requires a more holistic approach that goes beyond textual or spoken words to include non-verbal elements. Borrowing from advances in sign language processing, we propose the development of universal automatic gesture segmentation and transcription models to transcribe these non-verbal cues into textual form. Such a methodology aims to bridge the blind spots in spoken language understanding, enhancing the scope and applicability of NLP models. Through motivating examples, we demonstrate the limitations of relying solely on text-based models. We propose a computationally efficient and flexible approach for incorporating non-verbal cues, which can seamlessly integrate with existing NLP pipelines. We conclude by calling upon the
    
[^34]: 在大学学生报纸中无监督检测偏见

    Unsupervised Bias Detection in College Student Newspapers. (arXiv:2309.06557v1 [cs.CL])

    [http://arxiv.org/abs/2309.06557](http://arxiv.org/abs/2309.06557)

    本文提出了一个几乎没有人为影响的流程，用于从大学报纸档案中获取并检测偏见。该方法通过比较大型语言模型摘要的情感与原文来计算偏见，不需要大量标记数据，为客观理解学生报纸来源中的偏见提供了方法。

    

    本文提出了一个几乎没有人为影响的流程，用于从大学报纸档案中获取并检测偏见。该文介绍了一个从自动化工具无法获取数据的复杂档案网站上获取数据的框架，并生成了一个包含23,154个条目的14个学生报纸数据集。通过将大型语言模型摘要的情感与原文进行比较，还可以通过关键字查询来计算偏见。这种方法的优势在于它比重构偏见更少比较，并且比生成关键字情绪需要更少的标记数据。通过在政治性词汇以及控制词上计算结果，展示了如何得出结论。该完整方法有助于在假设和分类较少的情况下提取细致入微的见解，为客观理解学生报纸来源中的偏见铺平了道路。

    This paper presents a pipeline with minimal human influence for scraping and detecting bias on college newspaper archives. This paper introduces a framework for scraping complex archive sites that automated tools fail to grab data from, and subsequently generates a dataset of 14 student papers with 23,154 entries. This data can also then be queried by keyword to calculate bias by comparing the sentiment of a large language model summary to the original article. The advantages of this approach are that it is less comparative than reconstruction bias and requires less labelled data than generating keyword sentiment. Results are calculated on politically charged words as well as control words to show how conclusions can be drawn. The complete method facilitates the extraction of nuanced insights with minimal assumptions and categorizations, paving the way for a more objective understanding of bias within student newspaper sources.
    
[^35]: 离线逆向强化学习下的提示评估与优化

    Offline Prompt Evaluation and Optimization with Inverse Reinforcement Learning. (arXiv:2309.06553v1 [cs.CL])

    [http://arxiv.org/abs/2309.06553](http://arxiv.org/abs/2309.06553)

    这项工作介绍了一种基于离线逆向强化学习的提示评估与优化方法，通过利用离线数据集和逆向强化学习，预测提示性能、提高成本效益、生成易读的结果。

    

    最近，像ChatGPT这样的大型语言模型（LLM）的发展取得了显著的性能，通过利用人类专业知识。然而，充分揭示LLMs在复杂任务中的潜力需要在自然语言提示的广阔搜索空间中进行导航。虽然提示工程显示出潜力，但试错尝试中所需的人工设计提示和相关成本带来了重大挑战。关键是，提示优化的效率取决于昂贵的提示评估过程。本工作介绍了Prompt-OIRL，这是一种基于离线逆向强化学习的方法，旨在弥合有效提示评估和可负担性之间的差距。我们的方法利用专家评估的离线数据集，运用逆向强化学习获得一个针对离线、查询依赖型提示评估的奖励模型。Prompt-OIRL的优点是多方面的：它预测提示的性能，成本高效，生成易读的结果。

    The recent advances in the development of Large Language Models (LLMs) like ChatGPT have achieved remarkable performance by leveraging human expertise. Yet, fully eliciting LLMs' potential for complex tasks requires navigating the vast search space of natural language prompts. While prompt engineering has shown promise, the requisite human-crafted prompts in trial-and-error attempts and the associated costs pose significant challenges. Crucially, the efficiency of prompt optimization hinges on the costly procedure of prompt evaluation. This work introduces Prompt-OIRL, an approach rooted in offline inverse reinforcement learning that seeks to bridge the gap between effective prompt evaluation and affordability. Our method draws on offline datasets from expert evaluations, employing Inverse-RL to derive a reward model for offline, query-dependent prompt evaluations. The advantages of Prompt-OIRL are manifold: it predicts prompt performance, is cost-efficient, produces human-readable res
    
[^36]: 使用超图表示生成合成文本

    Synthetic Text Generation using Hypergraph Representations. (arXiv:2309.06550v1 [cs.CL])

    [http://arxiv.org/abs/2309.06550](http://arxiv.org/abs/2309.06550)

    本论文提出了一种使用超图表示生成合成文本的方法，首先将文档分解为语义框架，然后使用此中间稀疏格式生成文本。通过扰动框架内容，包括拓扑分析挖掘新的超边以及包含层次结构和时间动态的复杂多元关系，我们的解决方案生成的文档在样式、情感、格式、构成和事实上是多样的、连贯的和变化的。

    

    生成文档的合成变体通常被视为文本到文本的转换。我们提出了一种基于LLM的替代方法，该方法首先将文档分解为语义框架，然后使用此中间稀疏格式生成文本。这些框架使用超图进行建模，可以以恰当的方式扰动框架内容。具体而言，通过拓扑分析挖掘新的超边，包括层次结构和时间动态的复杂多元关系。我们展示了我们的解决方案生成的文档在样式、情感、格式、构成和事实上是多样的、连贯的和变化的。

    Generating synthetic variants of a document is often posed as text-to-text transformation. We propose an alternate LLM based method that first decomposes a document into semantic frames and then generates text using this interim sparse format. The frames are modeled using a hypergraph, which allows perturbing the frame contents in a principled manner. Specifically, new hyperedges are mined through topological analysis and complex polyadic relationships including hierarchy and temporal dynamics are accommodated. We show that our solution generates documents that are diverse, coherent and vary in style, sentiment, format, composition and facts.
    
[^37]: 文本编码器缺乏知识：利用生成语言模型（LLM）增强领域特定的语义文本相似性

    Text Encoders Lack Knowledge: Leveraging Generative LLMs for Domain-Specific Semantic Textual Similarity. (arXiv:2309.06541v1 [cs.CL])

    [http://arxiv.org/abs/2309.06541](http://arxiv.org/abs/2309.06541)

    生成式LLMs在描述复杂语义关系依赖于世界知识的两个文本之间的语义相似性时，显著优于基于编码器的STS模型，并在多个STS基准测试中保持强大的性能。

    

    在大型语言模型（LLM）在各种任务上得到广泛应用的背景下，我们发现语义文本相似性（STS）的研究相对较少。在本研究中，我们展示了STS可以被视为一个文本生成问题，并在多个STS基准测试中保持强大的性能。此外，当描述依赖于世界知识的两个文本之间的语义相似性时，我们发现生成式LLMs在性能上显著优于现有的基于编码器的STS模型。为了验证这一观点，我们在健康、政治和体育领域收集了三个新的STS挑战数据集，这些数据集需要在世界知识上进行判断。所有新收集的数据都来自于2023年5月之后发布的社交媒体内容，以确保ChatGPT等闭源模型的性能不能归功于记忆。我们的结果表明，平均而言，生成式LLM在性能上优于最好的编码器模型。

    Amidst the sharp rise in the evaluation of large language models (LLMs) on various tasks, we find that semantic textual similarity (STS) has been under-explored. In this study, we show that STS can be cast as a text generation problem while maintaining strong performance on multiple STS benchmarks. Additionally, we show generative LLMs significantly outperform existing encoder-based STS models when characterizing the semantic similarity between two texts with complex semantic relationships dependent on world knowledge. We validate this claim by evaluating both generative LLMs and existing encoder-based STS models on three newly collected STS challenge sets which require world knowledge in the domains of Health, Politics, and Sports. All newly collected data is sourced from social media content posted after May 2023 to ensure the performance of closed-source models like ChatGPT cannot be credited to memorization. Our results show that, on average, generative LLMs outperform the best enc
    
[^38]: 机器翻译模型在面对对抗攻击时表现出强大的稳定性

    Machine Translation Models Stand Strong in the Face of Adversarial Attacks. (arXiv:2309.06527v1 [cs.CL])

    [http://arxiv.org/abs/2309.06527](http://arxiv.org/abs/2309.06527)

    本研究探讨了对抗攻击对机器翻译模型的影响，证明了机器翻译模型在面对已知的最佳对抗攻击时表现出强大的稳定性。同时，我们提出的攻击算法在相对性能上超过其他替代选择。

    

    对抗攻击通过向输入引入微小扰动来暴露深度学习模型的漏洞，这导致输出结果发生重大变化。我们的研究关注这种对抗攻击对序列到序列（seq2seq）模型，特别是机器翻译模型的影响。我们引入了一些算法，包括基本文本扰动启发式和更高级的策略，如基于梯度的攻击，它利用可微分逼近非可微翻译度量。通过我们的调查，我们提供证据表明机器翻译模型对已知的最佳对抗攻击表现出了强大的稳定性，因为输出中的扰动程度与输入中的扰动成比例。然而，在不利情况下，我们的攻击胜过其他选择，提供了最佳的相对性能。另一个强大的候选是基于个体混合的攻击。

    Adversarial attacks expose vulnerabilities of deep learning models by introducing minor perturbations to the input, which lead to substantial alterations in the output. Our research focuses on the impact of such adversarial attacks on sequence-to-sequence (seq2seq) models, specifically machine translation models. We introduce algorithms that incorporate basic text perturbation heuristics and more advanced strategies, such as the gradient-based attack, which utilizes a differentiable approximation of the inherently non-differentiable translation metric. Through our investigation, we provide evidence that machine translation models display robustness displayed robustness against best performed known adversarial attacks, as the degree of perturbation in the output is directly proportional to the perturbation in the input. However, among underdogs, our attacks outperform alternatives, providing the best relative performance. Another strong candidate is an attack based on mixing of individu
    
[^39]: 语法错误修正系统的系统组合的最小贝叶斯风险解码方法

    Minimum Bayes' Risk Decoding for System Combination of Grammatical Error Correction Systems. (arXiv:2309.06520v1 [cs.CL])

    [http://arxiv.org/abs/2309.06520](http://arxiv.org/abs/2309.06520)

    本文提出了一个用于语法错误修正系统系统组合的最小贝叶斯风险解码方法，并通过实验证明了其有效性。

    

    对于序列到序列的任务来说，将各个系统的输出进行组合是一项具有挑战性的工作。同时，解码准则与评估准则之间通常存在不匹配。最小贝叶斯风险（MBR）解码可以用于以更好地与最终评估准则对齐的方式组合系统的输出。本文研究了在语法错误修正（GEC）系统中的MBR解码，该系统通常以编辑次数和相关的F分数来评估性能。因此，我们提出了一种与这种准则直接相关的新颖MBR损失函数。此外，文中还描述了一种扩展候选句子集合的方法。该方法基于当前的最大投票组合方案，以及个体编辑级别的选择。在三个流行的GEC数据集和最先进的GEC系统上进行的实验证明了所提出的MBR方法的有效性。此外，论文还突出了MBR解码中不同奖励指标的变化对结果的影响。

    For sequence-to-sequence tasks it is challenging to combine individual system outputs. Further, there is also often a mismatch between the decoding criterion and the one used for assessment. Minimum Bayes' Risk (MBR) decoding can be used to combine system outputs in a manner that encourages better alignment with the final assessment criterion. This paper examines MBR decoding for Grammatical Error Correction (GEC) systems, where performance is usually evaluated in terms of edits and an associated F-score. Hence, we propose a novel MBR loss function directly linked to this form of criterion. Furthermore, an approach to expand the possible set of candidate sentences is described. This builds on a current max-voting combination scheme, as well as individual edit-level selection. Experiments on three popular GEC datasets and with state-of-the-art GEC systems demonstrate the efficacy of the proposed MBR approach. Additionally, the paper highlights how varying reward metrics within the MBR d
    
[^40]: Memotion 3概述：Hinglish混合语言表情分析的情感与情绪分析

    Overview of Memotion 3: Sentiment and Emotion Analysis of Codemixed Hinglish Memes. (arXiv:2309.06517v1 [cs.CL])

    [http://arxiv.org/abs/2309.06517](http://arxiv.org/abs/2309.06517)

    Memotion 3是对Hinglish混合语言表情包进行情感和情绪分析的共享任务，参与者使用了各种模型和方法来处理该任务。

    

    分析互联网上的表情包已成为一个重要的任务，因为这种多模式内容对塑造在线话语的影响巨大。表情包已成为一种表达情感和情绪的强大工具，甚至可能通过幽默和讽刺传播仇恨和错误信息。本文介绍了Memotion 3共享任务的概述，作为AAAI-23的DeFactify 2研讨会的一部分。该任务发布了一份注释的Hindi-English混合语言表情包数据集，根据情感（任务A）、情绪（任务B）和情绪强度（任务C）对其进行标注。每个任务都被定义为一个独立的任务，参与者按照每个任务分别排名。超过50个团队注册参加了该共享任务，其中5个团队提交了Memotion 3数据集的测试集的最终结果。在参与者中，CLIP、BERT修改版本、ViT等模型最受欢迎，还有学生-教师模型、融合和集成等方法。任务A的最佳最终F1分数是？

    Analyzing memes on the internet has emerged as a crucial endeavor due to the impact this multi-modal form of content wields in shaping online discourse. Memes have become a powerful tool for expressing emotions and sentiments, possibly even spreading hate and misinformation, through humor and sarcasm. In this paper, we present the overview of the Memotion 3 shared task, as part of the DeFactify 2 workshop at AAAI-23. The task released an annotated dataset of Hindi-English code-mixed memes based on their Sentiment (Task A), Emotion (Task B), and Emotion intensity (Task C). Each of these is defined as an individual task and the participants are ranked separately for each task. Over 50 teams registered for the shared task and 5 made final submissions to the test set of the Memotion 3 dataset. CLIP, BERT modifications, ViT etc. were the most popular models among the participants along with approaches such as Student-Teacher model, Fusion, and Ensembling. The best final F1 score for Task A 
    
[^41]: 利用大型语言模型和弱监督对社交媒体数据进行注释:以COVID-19自我报告的疫苗推文为例

    Leveraging Large Language Models and Weak Supervision for Social Media data annotation: an evaluation using COVID-19 self-reported vaccination tweets. (arXiv:2309.06503v1 [cs.CL])

    [http://arxiv.org/abs/2309.06503](http://arxiv.org/abs/2309.06503)

    本研究评估了使用大型语言模型和弱监督方法，通过GPT-4模型在单次模式下提供标签的方式，来识别COVID-19疫苗相关推文，并与人工注释员的性能进行比较。

    

    COVID-19大流行给医疗行业和整个社会带来了重大挑战。随着COVID-19疫苗的快速发展，社交媒体平台已成为讨论疫苗相关话题的热门媒介。识别疫苗相关推文并进行分析可以为公共卫生研究人员和政策制定者提供宝贵的见解。然而，手动注释大量推文耗时且昂贵。在这项研究中，我们评估了使用大型语言模型，本例中为GPT-4（3月23日版本），和弱监督来识别COVID-19疫苗相关推文，目的是与人工注释员的性能进行比较。我们利用了一个手动策划的黄金标准数据集，并使用GPT-4在单次模式下（无需额外提示）提供标签，而无需任何额外的微调或指示。

    The COVID-19 pandemic has presented significant challenges to the healthcare industry and society as a whole. With the rapid development of COVID-19 vaccines, social media platforms have become a popular medium for discussions on vaccine-related topics. Identifying vaccine-related tweets and analyzing them can provide valuable insights for public health research-ers and policymakers. However, manual annotation of a large number of tweets is time-consuming and expensive. In this study, we evaluate the usage of Large Language Models, in this case GPT-4 (March 23 version), and weak supervision, to identify COVID-19 vaccine-related tweets, with the purpose of comparing performance against human annotators. We leveraged a manu-ally curated gold-standard dataset and used GPT-4 to provide labels without any additional fine-tuning or instructing, in a single-shot mode (no additional prompting).
    
[^42]: AGIBench: 用于大型语言模型的多粒度、多模态、人工参考、自动评分基准

    AGIBench: A Multi-granularity, Multimodal, Human-referenced, Auto-scoring Benchmark for Large Language Models. (arXiv:2309.06495v1 [cs.CL])

    [http://arxiv.org/abs/2309.06495](http://arxiv.org/abs/2309.06495)

    AGIBench是一个用于大型语言模型的多粒度、多模态、人工参考、自动评分的基准，通过标记问题的属性来评估语言模型的问题解决能力和智能程度。

    

    大型语言模型（LLM）如ChatGPT展示了惊人的智能。如何评估LLM的问题解决能力和智能程度是一个热点但具有挑战性的问题。首先，问题解决能力与不同的能力分支（如理解）和大规模的知识类别（如数学）交织在一起。第二，问题的输入是多模态的，可能涉及文本和图像。第三，LLM的响应格式多样，因此对结果提取和评估提出了巨大挑战。在本文中，我们提出了AGIBench--一种用于LLM的多粒度、多模态、人工参考和自动评分的基准方法。与混合问题集合不同，AGIBench专注于三个典型的能力分支，并采用四元组<能力分支、知识、难度、模态>来标记每个问题的属性。首先，它支持多粒度的基准化，例如每个问题、每个能力分支、每个知识类别的基准化。

    Large language models (LLMs) like ChatGPT have revealed amazing intelligence. How to evaluate the question-solving abilities of LLMs and their degrees of intelligence is a hot-spot but challenging issue. First, the question-solving abilities are interlaced with different ability branches like understanding and massive knowledge categories like mathematics. Second, the inputs of questions are multimodal that may involve text and images. Third, the response format of LLMs is diverse and thus poses great challenges for result extraction and evaluation. In this paper, we propose AGIBench -- a multi-granularity, multimodal, human-referenced, and auto-scoring benchmarking methodology for LLMs. Instead of a collection of blended questions, AGIBench focuses on three typical ability branches and adopts a four-tuple <ability branch, knowledge, difficulty, modal> to label the attributes of each question. First, it supports multi-granularity benchmarking, e.g., per-question, per-ability branch, pe
    
[^43]: 利用大型语言模型进行自动对话分析

    Leveraging Large Language Models for Automated Dialogue Analysis. (arXiv:2309.06490v1 [cs.CL])

    [http://arxiv.org/abs/2309.06490](http://arxiv.org/abs/2309.06490)

    本文研究了利用大型语言模型ChatGPT-3.5进行自动对话行为检测的能力，并评估了其与专门模型和人类表现的匹配度。研究结果显示，目前还没有一种模型能够令人满意地实现这一任务，达到人类的性能水平。

    

    开发高性能对话系统需要自动识别系统回应中的不良行为。然而，由于需要广泛的常识和对话实践的理解，这种行为的检测仍然具有挑战性。尽管最近的研究专注于构建用于检测特定对话行为的特殊分类器，但行为覆盖仍然不完整，并且缺乏对真实人机交互的测试。本文研究了最先进的大型语言模型（LLM）ChatGPT-3.5在真实人机对话中执行九个类别的对话行为检测的能力。我们旨在评估ChatGPT是否能够与专门模型相匹配并接近人类表现，从而降低行为检测任务的成本。我们的研究结果显示，无论是专门模型还是ChatGPT都尚未达到该任务的令人满意的结果，未能达到人类表现水平。

    Developing high-performing dialogue systems benefits from the automatic identification of undesirable behaviors in system responses. However, detecting such behaviors remains challenging, as it draws on a breadth of general knowledge and understanding of conversational practices. Although recent research has focused on building specialized classifiers for detecting specific dialogue behaviors, the behavior coverage is still incomplete and there is a lack of testing on real-world human-bot interactions. This paper investigates the ability of a state-of-the-art large language model (LLM), ChatGPT-3.5, to perform dialogue behavior detection for nine categories in real human-bot dialogues. We aim to assess whether ChatGPT can match specialized models and approximate human performance, thereby reducing the cost of behavior detection tasks. Our findings reveal that neither specialized models nor ChatGPT have yet achieved satisfactory results for this task, falling short of human performance.
    
[^44]: 广泛可解释的语义表示：面向更广泛应用的无框架意义表示

    Widely Interpretable Semantic Representation: Frameless Meaning Representation for Broader Applicability. (arXiv:2309.06460v1 [cs.CL])

    [http://arxiv.org/abs/2309.06460](http://arxiv.org/abs/2309.06460)

    本文提出了一种名为WISeR的语义表示方法，克服了抽象意义表示（AMR）在应用于没有预定义语义框架的语言或领域时的挑战。通过将AMR中的编号参数转换为不需要引用语义框架的语义角色，WISeR提供了更易于解释和解析的语义表示。该方法在标注者一致性和解析器的准确性方面表现出色。

    

    本文提出了一种新颖的语义表示方式，WISeR，它克服了抽象意义表示（AMR）所面临的挑战。虽然AMR具有很多优势，但它在没有预定义语义框架的语言或领域中不容易应用，并且其使用编号参数会导致语义角色标签，这些标签不直接可解释，并且对解析器来说具有语义过载。我们研究了AMR中谓词的编号参数，并将其转换为不需要引用语义框架的语义角色。我们创建了一个新的语料库，包括1K英语对话句子，标注了WISeR和AMR。WISeR在初学者和有经验的标注者之间具有更强的标注者一致性，初学者更快地掌握了WISeR的标注。最后，我们在AMR 3.0语料库和从AMR 3.0转换而来的WISeR语料库上训练了一种最先进的解析器。我们在这些语料库和对话语料库上评估了WISeR模型的准确性。

    This paper presents a novel semantic representation, WISeR, that overcomes challenges for Abstract Meaning Representation (AMR). Despite its strengths, AMR is not easily applied to languages or domains without predefined semantic frames, and its use of numbered arguments results in semantic role labels, which are not directly interpretable and are semantically overloaded for parsers. We examine the numbered arguments of predicates in AMR and convert them to thematic roles that do not require reference to semantic frames. We create a new corpus of 1K English dialogue sentences annotated in both WISeR and AMR. WISeR shows stronger inter-annotator agreement for beginner and experienced annotators, with beginners becoming proficient in WISeR annotation more quickly. Finally, we train a state-of-the-art parser on the AMR 3.0 corpus and a WISeR corpus converted from AMR 3.0. The parser is evaluated on these corpora and our dialogue corpus. The WISeR model exhibits higher accuracy than its AM
    
[^45]: 缩小监督和无监督句子表示学习的差距：大规模语言模型

    Narrowing the Gap between Supervised and Unsupervised Sentence Representation Learning with Large Language Model. (arXiv:2309.06453v1 [cs.CL])

    [http://arxiv.org/abs/2309.06453](http://arxiv.org/abs/2309.06453)

    本文通过实验比较了监督和无监督句子表示学习在训练过程中的行为，并探讨了如何缩小性能差距。

    

    句子表示学习是自然语言处理中的一项基本任务，对比学习的句子嵌入（CSE）作为主流技术具有出色的性能。然而，在CSE中有一个有趣的现象，即监督和无监督方法之间存在显著的性能差距，即使它们的句子编码器和损失函数相同。本文通过实证实验回答“发生了什么导致了性能差距”和“如何缩小性能差距”的问题。我们首先通过彻底比较监督和无监督CSE在各自的训练过程中的行为来回答“发生了什么”这个问题。

    Sentence Representation Learning (SRL) is a fundamental task in Natural Language Processing (NLP), with Contrastive learning of Sentence Embeddings (CSE) as the mainstream technique due to its superior performance. An intriguing phenomenon in CSE is the significant performance gap between supervised and unsupervised methods, even when their sentence encoder and loss function are the same. Previous works attribute this performance gap to differences in two representation properties (alignment and uniformity). However, alignment and uniformity only measure the results, which means they cannot answer "What happens during the training process that leads to the performance gap?" and "How can the performance gap be narrowed?". In this paper, we conduct empirical experiments to answer these "What" and "How" questions. We first answer the "What" question by thoroughly comparing the behavior of supervised and unsupervised CSE during their respective training processes. From the comparison, We o
    
[^46]: AKEM: 利用集成模型将知识库与查询对齐以进行实体识别和链接

    AKEM: Aligning Knowledge Base to Queries with Ensemble Model for Entity Recognition and Linking. (arXiv:2309.06175v1 [cs.CL])

    [http://arxiv.org/abs/2309.06175](http://arxiv.org/abs/2309.06175)

    本文提出了一种利用集成模型将知识库与查询对齐的方法，用于实体识别和链接挑战。通过扩展知识库和利用外部知识，提高了召回率，并使用支持向量回归和多元加性回归树过滤结果得到高精度的实体识别和链接。最终实现了高效的计算和0.535的F1分数。

    

    本文提出了一种解决NLPCC 2015中实体识别和链接挑战的新方法。该任务包括从短搜索查询中提取命名实体的提及，并将其链接到参考中文知识库中的实体。为了解决这个问题，我们首先扩展现有知识库，并利用外部知识识别候选实体，从而提高召回率。接下来，我们从候选实体中提取特征，并利用支持向量回归和多元加性回归树作为评分函数来过滤结果。此外，我们还应用规则来进一步细化结果和提高精度。我们的方法计算效率高，达到了0.535的F1分数。

    This paper presents a novel approach to address the Entity Recognition and Linking Challenge at NLPCC 2015. The task involves extracting named entity mentions from short search queries and linking them to entities within a reference Chinese knowledge base. To tackle this problem, we first expand the existing knowledge base and utilize external knowledge to identify candidate entities, thereby improving the recall rate. Next, we extract features from the candidate entities and utilize Support Vector Regression and Multiple Additive Regression Tree as scoring functions to filter the results. Additionally, we apply rules to further refine the results and enhance precision. Our method is computationally efficient and achieves an F1 score of 0.535.
    
[^47]: 随机LLMs无法理解语言：走向符号化、可解释性和本体论基于的LLMs

    Stochastic LLMs do not Understand Language: Towards Symbolic, Explainable and Ontologically Based LLMs. (arXiv:2309.05918v1 [cs.CL])

    [http://arxiv.org/abs/2309.05918](http://arxiv.org/abs/2309.05918)

    随机LLMs无法理解语言的原因是它们无法提供可以依赖的事实信息，它们存储的语言知识埋藏在无意义的微特征中，并在某些语言上下文中无法进行正确推理。本文建议在符号化方法中应用有效的自下而上策略

    

    在我们看来，围绕数据驱动的大型语言模型（LLMs）相对成功的狂热是有些误导的，原因如下：（i）LLMs不能依赖于事实信息，因为对于LLMs来说，摄入的所有文本（事实或非事实）都是平等的；（ii）由于它们的亚符号性质，这些模型对语言的任何“知识”都将永远埋藏在数十亿个微特征（权重）中，其中没有一个本身是有意义的；以及（iii）LLMs在几种语言上下文中常常无法进行正确推理（如名词复合词、共谓词、量词范围模糊和意向性上下文）。我们相信，数据驱动的大型语言模型（LLMs）的相对成功不是符号与亚符号之辩的反映，而是在规模上应用自下而上的逆向工程语言的成功策略的反映。在本文中，我们建议将有效的自下而上策略应用于符号化方法中

    In our opinion the exuberance surrounding the relative success of data-driven large language models (LLMs) is slightly misguided and for several reasons (i) LLMs cannot be relied upon for factual information since for LLMs all ingested text (factual or non-factual) was created equal; (ii) due to their subsymbolic na-ture, whatever 'knowledge' these models acquire about language will always be buried in billions of microfeatures (weights), none of which is meaningful on its own; and (iii) LLMs will often fail to make the correct inferences in several linguistic contexts (e.g., nominal compounds, copredication, quantifier scope ambi-guities, intensional contexts. Since we believe the relative success of data-driven large language models (LLMs) is not a reflection on the symbolic vs. subsymbol-ic debate but a reflection on applying the successful strategy of a bottom-up reverse engineering of language at scale, we suggest in this paper applying the effective bottom-up strategy in a symbol
    
[^48]: 内存注入：在Transformer-Based语言模型中纠正多跳推理错误

    Memory Injections: Correcting Multi-Hop Reasoning Failures during Inference in Transformer-Based Language Models. (arXiv:2309.05605v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.05605](http://arxiv.org/abs/2309.05605)

    本文提出了一种通过向Transformer-Based语言模型的LLM注意力头部定向注入内存来纠正多跳推理错误的方法，从而提高了模型在处理多跳推理问题时的表现。

    

    回答多跳推理问题需要从多个信息源中检索和综合信息。大语言模型(LLMs)往往难以保持一致的推理能力。本文提出了一种通过在LLM注意力头部进行定向内存注入来确定和纠正多跳推理错误的方法。首先，我们分析了GPT-2模型在单跳和多跳提示下各层的激活情况。然后，我们提出了一种机制，允许用户在推理过程中向关键LLM位置注入相关的提示特定信息，我们将其称为“记忆”。通过在推理过程中使LLM能够整合额外的相关信息，我们提高了多跳提示生成的质量。我们实证表明，将简单、高效且定向的记忆注入到关键注意力层中往往能够提高多跳任务中所需下一个标记的概率，提高了达到424%。

    Answering multi-hop reasoning questions requires retrieving and synthesizing information from diverse sources. Large Language Models (LLMs) struggle to perform such reasoning consistently. Here we propose an approach to pinpoint and rectify multi-hop reasoning failures through targeted memory injections on LLM attention heads. First, we analyze the per-layer activations of GPT-2 models in response to single and multi-hop prompts. We then propose a mechanism that allows users to inject pertinent prompt-specific information, which we refer to as "memories," at critical LLM locations during inference. By thus enabling the LLM to incorporate additional relevant information during inference, we enhance the quality of multi-hop prompt completions. We show empirically that a simple, efficient, and targeted memory injection into a key attention layer can often increase the probability of the desired next token in multi-hop tasks, by up to 424%.
    
[^49]: NExT-GPT: 任何到任何的多模态语言模型

    NExT-GPT: Any-to-Any Multimodal LLM. (arXiv:2309.05519v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2309.05519](http://arxiv.org/abs/2309.05519)

    NExT-GPT是一个任何到任何的多模态语言模型系统，通过连接多模态适配器和不同扩散解码器，能够接受和生成任意组合的文本、图像、视频和音频内容。

    

    最近，多模态大型语言模型（MM-LLM）取得了令人振奋的进展，但它们主要存在一个限制，即只能在输入端进行多模态理解，无法以多种模式生成内容。由于我们人类总是通过各种模态感知世界和与人交流，因此开发能够接受和传递任何模态内容的任何到任何的MM-LLM系统对于实现人级AI至关重要。为了填补这一空白，我们提出了一个端到端的通用任何到任何的多模态语言模型系统，NExT-GPT。我们通过连接一个含有多模态适配器和不同扩散解码器的LLM，使得NExT-GPT能够以任意的文本、图像、视频和音频的组合进行输入和输出。通过利用现有训练有素的高性能编码器和解码器，NExT-GPT仅通过调整某些投影层的少量参数（1%）进行调优，这不仅有利于低成本训练，还有助于方便的扩展性。

    While recently Multimodal Large Language Models (MM-LLMs) have made exciting strides, they mostly fall prey to the limitation of only input-side multimodal understanding, without the ability to produce content in multiple modalities. As we humans always perceive the world and communicate with people through various modalities, developing any-to-any MM-LLMs capable of accepting and delivering content in any modality becomes essential to human-level AI. To fill the gap, we present an end-to-end general-purpose any-to-any MM-LLM system, NExT-GPT. We connect an LLM with multimodal adaptors and different diffusion decoders, enabling NExT-GPT to perceive inputs and generate outputs in arbitrary combinations of text, images, videos, and audio. By leveraging the existing well-trained highly-performing encoders and decoders, NExT-GPT is tuned with only a small amount of parameter (1%) of certain projection layers, which not only benefits low-cost training and also facilitates convenient expansi
    
[^50]: 理解后训练量化对大型语言模型的影响

    Understanding the Impact of Post-Training Quantization on Large Language Models. (arXiv:2309.05210v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.05210](http://arxiv.org/abs/2309.05210)

    本研究旨在理解后训练量化对大型语言模型的影响，揭示了量化模型在下一个单词预测等关键任务中如何响应超参数的差距。

    

    大型语言模型（LLMs）的规模迅速增加，参数数量成为许多商业模型成功的关键因素，如ChatGPT、Claude和Bard。即使是最近发布的用于商业用途的公开可见模型，如Falcon和Llama2，也拥有数十亿个参数。参数数量的显著增加使得部署和运行非常昂贵。量化领域在大型神经网络以及LLMs方面取得了显著进展，使得这些模型可以在消费级GPU上部署，从而使其更易获得。量化模型通常表现出与其未量化基准模型相当的性能水平。然而，对于诸如温度、最大新标记数和topk等超参数，尤其是对于下一个单词预测，我们对这些量化模型如何响应仍存在显著差距。本研究揭示了这一问题。

    Large language models (LLMs) are rapidly increasing in size, with the number of parameters becoming a key factor in the success of many commercial models, such as ChatGPT, Claude, and Bard. Even the recently released publicly accessible models for commercial usage, such as Falcon and Llama2, come equipped with billions of parameters. This significant increase in the number of parameters makes deployment and operation very costly. The remarkable progress in the field of quantization for large neural networks in general and LLMs in particular, has made these models more accessible by enabling them to be deployed on consumer-grade GPUs. Quantized models generally demonstrate comparable performance levels to their unquantized base counterparts. Nonetheless, there exists a notable gap in our comprehensive understanding of how these quantized models respond to hyperparameters, such as temperature, max new tokens, and topk, particularly for next word prediction. The present analysis reveals t
    
[^51]: ChatRule：利用大型语言模型挖掘知识图谱推理中的逻辑规则

    ChatRule: Mining Logical Rules with Large Language Models for Knowledge Graph Reasoning. (arXiv:2309.01538v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2309.01538](http://arxiv.org/abs/2309.01538)

    本论文提出了一个框架ChatRule，利用大型语言模型挖掘知识图谱中的逻辑规则。该框架通过充分利用知识图谱的语义和结构信息，能够提高推理性能并提供可解释的结果。

    

    逻辑规则对于发现关系之间的逻辑连接至关重要，可以提高推理性能并提供可解释的知识图谱结果。尽管已经有许多努力在知识图谱上挖掘有意义的逻辑规则，但现有方法在规则空间上搜索计算密集且缺乏可伸缩性，尤其是对于大规模知识图谱。此外，它们常常忽视了关系的语义，而这对于揭示逻辑连接至关重要。最近，大型语言模型（LLMs）在自然语言处理领域和各种应用中展现出了令人瞩目的性能，归功于它们的新能力和泛化能力。在本文中，我们提出了一个新颖的框架ChatRule，利用大型语言模型挖掘知识图谱中的逻辑规则。具体而言，该框架以基于LLM的规则生成器为初始，充分利用了知识图谱的语义和结构信息。

    Logical rules are essential for uncovering the logical connections between relations, which could improve the reasoning performance and provide interpretable results on knowledge graphs (KGs). Although there have been many efforts to mine meaningful logical rules over KGs, existing methods suffer from the computationally intensive searches over the rule space and a lack of scalability for large-scale KGs. Besides, they often ignore the semantics of relations which is crucial for uncovering logical connections. Recently, large language models (LLMs) have shown impressive performance in the field of natural language processing and various applications, owing to their emergent ability and generalizability. In this paper, we propose a novel framework, ChatRule, unleashing the power of large language models for mining logical rules over knowledge graphs. Specifically, the framework is initiated with an LLM-based rule generator, leveraging both the semantic and structural information of KGs 
    
[^52]: 通过模拟跨多个领域和语言的自然拼写错误生成拼写纠正的方法论

    A Methodology for Generative Spelling Correction via Natural Spelling Errors Emulation across Multiple Domains and Languages. (arXiv:2308.09435v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.09435](http://arxiv.org/abs/2308.09435)

    本文提出了一种用于生成拼写纠正的方法论，通过模拟文本中的自然拼写错误和打字错误，以有效丰富生成模型的预训练过程。研究结果表明，这种方法在英语和俄语语言上是可行的，并可以扩展到其他语言。

    

    现代大型语言模型展示了出色的文本生成和泛化能力。然而，当涉及到纠正拼写错误和打字错误时，它们通常难以解决文本编辑任务。本文提出了一种用于生成拼写纠正的方法论，该方法在英语和俄语语言上进行了测试，并且在稍作修改后可以扩展到任何语言。我们的研究主要集中在探索文本中的自然拼写错误和打字错误，并研究这些错误可以如何在正确的句子中模拟，以有效丰富生成模型的预训练过程。我们研究了这种模拟的影响和模型在不同文本领域中的能力。本文研究了两种拼写破坏技术：1）第一种通过利用特定数据集中的错误统计来模拟人类犯错误时的行为；2）第二种是添加最常见的拼写错误。

    Modern large language models demonstrate impressive capabilities in text generation and generalization. However, they often struggle with solving text editing tasks, particularly when it comes to correcting spelling errors and mistypings. In this paper, we present a methodology for generative spelling correction (SC), which was tested on English and Russian languages and potentially can be extended to any language with minor changes. Our research mainly focuses on exploring natural spelling errors and mistypings in texts and studying the ways those errors can be emulated in correct sentences to effectively enrich generative models' pre-train procedure. We investigate the impact of such emulations and the models' abilities across different text domains. In this work, we investigate two spelling corruption techniques: 1) first one mimics human behavior when making a mistake through leveraging statistics of errors from particular dataset and 2) second adds the most common spelling errors,
    
[^53]: SeACo-Paraformer:一种具有灵活且有效的热词自定义能力的非自回归ASR系统

    SeACo-Paraformer: A Non-Autoregressive ASR System with Flexible and Effective Hotword Customization Ability. (arXiv:2308.03266v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2308.03266](http://arxiv.org/abs/2308.03266)

    SeACo-Paraformer是一种具有灵活且有效的热词自定义能力的非自回归ASR系统，在大规模实验中表现优于基线模型，并提出了过滤大规模热词的有效方法。

    

    热词自定义是ASR领域中一个重要的问题，使用户能够自定义实体、人物和其他短语的名称具有价值。过去几年中，ASR上下文建模的隐式和显式建模策略都得到了发展。尽管这些方法表现还不错，但仍存在某些缺点，例如在效果稳定性方面的不稳定性。在本文中，我们提出了一种新颖的基于语义增强的上下文Paraformer (SeACo-Paraformer)的非自回归ASR系统，具有灵活且有效的热词自定义能力。它结合了基于AED模型的准确性、基于NAR模型的效率以及在上下文建模方面的出色表现。在50,000小时的工业大数据实验中，我们提出的模型在自定义和常规ASR任务中优于强基线模型。此外，我们还探索了一种有效的方法来过滤大规模的热词以进一步改进。

    Hotword customization is one of the important issues remained in ASR field it is of value to enable users of ASR systems to customize names of entities, persons and other phrases. The past few years have seen both implicit and explicit modeling strategies for ASR contextualization developed. While these approaches have performed adequately, they still exhibit certain shortcomings such as instability in effectiveness. In this paper we propose Semantic-augmented Contextual-Paraformer (SeACo-Paraformer) a novel NAR based ASR system with flexible and effective hotword customization ability. It combines the accuracy of the AED-based model, the efficiency of the NAR model, and the excellent performance in contextualization. In 50,000 hours industrial big data experiments, our proposed model outperforms strong baselines in customization and general ASR tasks. Besides, we explore an efficient way to filter large scale incoming hotwords for further improvement. The source codes and industrial
    
[^54]: 使用大型语言模型学习数学推理的规模关系

    Scaling Relationship on Learning Mathematical Reasoning with Large Language Models. (arXiv:2308.01825v1 [cs.CL])

    [http://arxiv.org/abs/2308.01825](http://arxiv.org/abs/2308.01825)

    本文研究了大型语言模型在学习数学推理时的规模关系，发现预训练损失更好地预测模型性能，并提出了一种使用拒绝采样微调技术来增强数据集的方法。

    

    数学推理是大型语言模型（LLMs）的一项具有挑战性的任务，然而关于LLM容量与数学推理之间的规模关系尚未充分探索。本文研究了预训练损失、监督数据量和增强数据量对监督LLM的推理性能的影响。我们发现预训练损失是模型性能的更好指标，而不是模型参数数量。我们使用不同数量的监督数据进行监督微调（SFT），并实证发现数据量与模型性能之间存在对数线性关系，而较好的模型在扩大的监督数据集上改进较小。为了在不需要人工努力的情况下增加更多的数据样本以提高模型性能，我们提出了拒绝采样微调（RFT）。RFT使用监督模型生成和收集正确的推理路径作为增强的微调数据集。我们发现，使用更多不同的推理路径作为增强样本可以提高模型的性能。

    Mathematical reasoning is a challenging task for large language models (LLMs), while the scaling relationship of it with respect to LLM capacity is under-explored. In this paper, we investigate how the pre-training loss, supervised data amount, and augmented data amount influence the reasoning performances of a supervised LLM. We find that pre-training loss is a better indicator of the model's performance than the model's parameter count. We apply supervised fine-tuning (SFT) with different amounts of supervised data and empirically find a log-linear relation between data amount and model performance, and we find better models improve less with enlarged supervised datasets. To augment more data samples for improving model performances without any human effort, we propose to apply Rejection sampling Fine-Tuning (RFT). RFT uses supervised models to generate and collect correct reasoning paths as augmented fine-tuning datasets. We find with augmented samples containing more distinct reaso
    
[^55]: GRDD: 希腊方言自然语言处理的数据集

    GRDD: A Dataset for Greek Dialectal NLP. (arXiv:2308.00802v1 [cs.CL])

    [http://arxiv.org/abs/2308.00802](http://arxiv.org/abs/2308.00802)

    本文介绍了一个用于研究现代希腊方言的大规模数据集GRDD，并使用该数据集进行方言识别实验，结果显示即使是简单的机器学习模型也能在该任务上表现良好。

    

    本文介绍了一个用于研究现代希腊方言的数据集。该数据集包含了克里特、庞提、北希腊和塞浦路斯希腊四种方言的原始文本数据。尽管存在不平衡，但该数据集是相当大的，并且是创建现代希腊方言类似资源的首次尝试。我们还使用该数据集进行方言识别，并尝试了传统的机器学习算法和简单的深度学习架构。结果显示，在这个任务上表现非常好，这可能表明所研究的方言具有足够的独特特征，即使是简单的机器学习模型也能在该任务上表现良好。针对表现最佳的算法进行了错误分析，结果显示在一些情况下错误是由于数据集清理不足造成的。

    In this paper, we present a dataset for the computational study of a number of Modern Greek dialects. It consists of raw text data from four dialects of Modern Greek, Cretan, Pontic, Northern Greek and Cypriot Greek. The dataset is of considerable size, albeit imbalanced, and presents the first attempt to create large scale dialectal resources of this type for Modern Greek dialects. We then use the dataset to perform dialect idefntification. We experiment with traditional ML algorithms, as well as simple DL architectures. The results show very good performance on the task, potentially revealing that the dialects in question have distinct enough characteristics allowing even simple ML models to perform well on the task. Error analysis is performed for the top performing algorithms showing that in a number of cases the errors are due to insufficient dataset cleaning.
    
[^56]: Factify 2调查报告: 多模态假新闻检测

    Findings of Factify 2: Multimodal Fake News Detection. (arXiv:2307.10475v1 [cs.CL])

    [http://arxiv.org/abs/2307.10475](http://arxiv.org/abs/2307.10475)

    Factify 2进行了一项多模态假新闻检测任务，通过比较社交媒体声明和支持文件的文本和图像信息，实现了对假新闻的自动检测和验证，最佳性能达到了81.82%的F1分数。

    

    随着社交媒体的使用在过去几年呈指数级增长，假新闻也变得非常普遍。假新闻的有害影响强调了研究自动检测错误信息并验证其准确性的需求。在这项工作中，我们呈现了Factify 2的结果，这是作为AAAI'23的DeFactify 2工作坊的一部分提供的多模态事实验证和讽刺新闻数据集。数据呼唤一种基于比较的方法来配对社交媒体声明和支持文件，包括文本和图像，根据多模态关系分为5类。在这个任务的第二次迭代中，我们有超过60个参与者和9个终期测试提交。最好的表现来自于在文本方面使用DeBERTa，在图像方面使用Swinv2和CLIP。所有五个类别的F1分数平均达到了81.82%。

    With social media usage growing exponentially in the past few years, fake news has also become extremely prevalent. The detrimental impact of fake news emphasizes the need for research focused on automating the detection of false information and verifying its accuracy. In this work, we present the outcome of the Factify 2 shared task, which provides a multi-modal fact verification and satire news dataset, as part of the DeFactify 2 workshop at AAAI'23. The data calls for a comparison based approach to the task by pairing social media claims with supporting documents, with both text and image, divided into 5 classes based on multi-modal relations. In the second iteration of this task we had over 60 participants and 9 final test-set submissions. The best performances came from the use of DeBERTa for text and Swinv2 and CLIP for image. The highest F1 score averaged for all five classes was 81.82%.
    
[^57]: 大语言模型的综合概述

    A Comprehensive Overview of Large Language Models. (arXiv:2307.06435v1 [cs.CL])

    [http://arxiv.org/abs/2307.06435](http://arxiv.org/abs/2307.06435)

    大语言模型的综合概述，分析了各种新的架构和训练策略，讨论了LLM的特点和功能，并总结了重要的研究发现和关键的架构和训练策略。

    

    大语言模型（LLM）展示了出色的泛化能力，导致了众多模型的发展。这些模型提出了各种新的架构，通过改进的训练策略来调整现有的架构，增加上下文长度，使用高质量的训练数据，并增加训练时间以超越基线。分析新的发展对于识别增强训练稳定性和改进LLM泛化能力的变化至关重要。本综述论文全面分析了LLM的架构及其分类、训练策略、训练数据集和性能评估，并讨论未来的研究方向。此外，本文还讨论了LLM的基本构建块和概念，并提供了LLM的完整概述，包括其重要特点和功能。最后，本文总结了LLM研究的重要发现，并整合了关键的架构和训练策略。

    Large Language Models (LLMs) have shown excellent generalization capabilities that have led to the development of numerous models. These models propose various new architectures, tweaking existing architectures with refined training strategies, increasing context length, using high-quality training data, and increasing training time to outperform baselines. Analyzing new developments is crucial for identifying changes that enhance training stability and improve generalization in LLMs. This survey paper comprehensively analyses the LLMs architectures and their categorization, training strategies, training datasets, and performance evaluations and discusses future research directions. Moreover, the paper also discusses the basic building blocks and concepts behind LLMs, followed by a complete overview of LLMs, including their important features and functions. Finally, the paper summarizes significant findings from LLM research and consolidates essential architectural and training strateg
    
[^58]: 跨语料阅读性兼容性评估：英文文本

    Cross-corpus Readability Compatibility Assessment for English Texts. (arXiv:2306.09704v1 [cs.CL])

    [http://arxiv.org/abs/2306.09704](http://arxiv.org/abs/2306.09704)

    本文提出了一个新的评估框架，Cross-corpus text Readability Compatibility Assessment (CRCA)，用于解决不同语料库之间的可读性兼容性的问题。研究结果表明该框架具有显著的兼容性，并适用于不同的特征表示和分类方法。

    

    文本的可读性评估在各个领域的研究人员中受到了重视。然而，对语料库兼容性的缺乏探索构成了一项挑战，因为不同的研究小组使用不同的语料库。本研究提出了一个新的评估框架，Cross-corpus text Readability Compatibility Assessment (CRCA)，来解决这个问题。该框架包括三个关键组成部分：(1) 语料库：CEFR，CLEC，CLOTH，NES，OSP和RACE。提取了语言特征、GloVe词向量表示和它们的融合特征。(2) 分类模型：采用了机器学习方法（XGBoost，SVM）和深度学习方法（BiLSTM，Attention-BiLSTM）。(3) 兼容性指标：RJSD，RRNSS和NDCG指标。我们的研究结果表明：(1) OSP表现显著不同于其他数据集的证实了语料兼容性。(2) 兼容性、特征表示和分类方法之间有适应性效应。(3) 在不同兼容性指标下得到了一致的评估结果，这表明了我们的框架的效果。

    Text readability assessment has gained significant attention from researchers in various domains. However, the lack of exploration into corpus compatibility poses a challenge as different research groups utilize different corpora. In this study, we propose a novel evaluation framework, Cross-corpus text Readability Compatibility Assessment (CRCA), to address this issue. The framework encompasses three key components: (1) Corpus: CEFR, CLEC, CLOTH, NES, OSP, and RACE. Linguistic features, GloVe word vector representations, and their fusion features were extracted. (2) Classification models: Machine learning methods (XGBoost, SVM) and deep learning methods (BiLSTM, Attention-BiLSTM) were employed. (3) Compatibility metrics: RJSD, RRNSS, and NDCG metrics. Our findings revealed: (1) Validated corpus compatibility, with OSP standing out as significantly different from other datasets. (2) An adaptation effect among corpora, feature representations, and classification methods. (3) Consistent 
    
[^59]: GEmo-CLAP: 面向语音情感识别的性别属性增强对比语音-语言预训练模型

    GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio Pretraining for Speech Emotion Recognition. (arXiv:2306.07848v1 [cs.CL])

    [http://arxiv.org/abs/2306.07848](http://arxiv.org/abs/2306.07848)

    本文提出了GEmo-CLAP模型用于语音情感识别，结合了性别属性信息，相比于其他先进方法，该模型在IEMOCAP上实现了更优越的识别性能。

    

    对比语音-语言预训练（CLAP）最近在不同领域取得了惊人的成功。本文提出了一种名为GEmo-CLAP的高效性别属性增强CLAP模型，用于语音情感识别（SER）。具体而言，我们首先利用各种自监督学习的预训练模型构建了一种有效的情感CLAP模型（称为Emo-CLAP），用于SER。然后，考虑到在语音情感建模中性别属性的重要性，我们进一步提出了两种GEmo-CLAP方法，来整合语音信号的情感和性别信息，形成更合理的目标。在IEMOCAP语料库上进行的大量实验表明，我们提出的两种GEmo-CLAP方法始终优于基线Emo-CLAP模型（使用不同的预训练模型），同时与其他最先进的方法相比实现了更优越的识别性能。

    Contrastive Language-Audio Pretraining (CLAP) has recently exhibited impressive success in diverse fields. In this paper, we propose GEmo-CLAP, a kind of efficient gender-attribute-enhanced CLAP model for speech emotion recognition (SER). Specifically, we first build an effective emotion CLAP model termed Emo-CLAP for SER, utilizing various self-supervised learning based pre-trained models. Then, considering the importance of the gender attribute in speech emotion modeling, two GEmo-CLAP approaches are further proposed to integrate the emotion and gender information of speech signals, forming more reasonable objectives. Extensive experiments conducted on the IEMOCAP corpus demonstrate that our proposed two GEmo-CLAP approaches consistently outperform the baseline Emo-CLAP with different pre-trained models, while also achieving superior recognition performance compared with other state-of-the-art methods.
    
[^60]: 语言模型知道自己在产生“幻觉”参考文献吗？

    Do Language Models Know When They're Hallucinating References?. (arXiv:2305.18248v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.18248](http://arxiv.org/abs/2305.18248)

    本研究针对大型语言模型中的“幻觉”参考文献进行了研究，通过简单的搜索引擎查询可可靠地识别这些幻觉。并且通过对同一语言模型进行黑盒查询来进行分类，揭示了幻觉参考文献的性质。

    

    目前最先进的语言模型以其“幻觉”参考文献而闻名。这些虚构的文章和书名引起了危害，对它们的使用造成了障碍，并引起了公众的反弹。尽管其他类型的语言模型幻觉也很重要，但我们将幻觉参考文献提出作为大型语言模型(LLMs)中幻觉研究的“果蝇”，因为它们特别容易研究。我们展示了简单的搜索引擎查询可可靠地识别此类幻觉，从而便于评估。为了开始剖析幻觉语言模型参考文献的性质，我们尝试使用对同一语言模型的黑盒查询来对其进行分类，而不借助任何外部资源。我们将“直接”查询的一致性检查与“间接”查询的一致性检查进行了比较，后者询问了附加的细节，如作品的作者。

    State-of-the-art language models (LMs) are famous for "hallucinating" references. These fabricated article and book titles lead to harms, obstacles to their use, and public backlash. While other types of LM hallucinations are also important, we propose hallucinated references as the "drosophila" of research on hallucination in large language models (LLMs), as they are particularly easy to study. We show that simple search engine queries reliably identify such hallucinations, which facilitates evaluation. To begin to dissect the nature of hallucinated LM references, we attempt to classify them using black-box queries to the same LM, without consulting any external resources. Consistency checks done with "direct" queries about whether the generated reference title is real (inspired by Kadavath et al. 2022, Lin et al. 2022, Manakul et al. 2023) are compared to consistency checks with "indirect" queries which ask for ancillary details such as the authors of the work. These consistency chec
    
[^61]: ChatGPT是否具有心智理论？

    Does ChatGPT have Theory of Mind?. (arXiv:2305.14020v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.14020](http://arxiv.org/abs/2305.14020)

    本文研究了ChatGPT在心智理论方面的能力。通过对比不同版本的ChatGPT在几个经典问题上的表现，发现ChatGPT-4比随机答案给出了更多正确答案，尽管这些答案往往基于错误的假设或无效的推理。

    

    心智理论（ToM）是理解人类思维和决策的能力，这种能力在人与人之间的社交互动中起着至关重要的作用，包括语言交流。本文探讨了最近ChatGPT系列中的大型语言模型在多大程度上具备ToM。我们对两个版本的ChatGPT提出了六个经典问题，这些问题涉及人类推理和决策中的偏见，并在多种提示策略下对结果进行了比较。虽然关于ChatGPT-3的结果有些不确定，但ChatGPT-4被证明比预期更经常给出正确答案，尽管正确答案往往是基于错误的假设或无效的推理得出的。

    Theory of Mind (ToM) is the ability to understand human thinking and decision-making, an ability that plays a crucial role in social interaction between people, including linguistic communication. This paper investigates to what extent recent Large Language Models in the ChatGPT tradition possess ToM. We posed six well-known problems that address biases in human reasoning and decision making to two versions of ChatGPT and we compared the results under a range of prompting strategies. While the results concerning ChatGPT-3 were somewhat inconclusive, ChatGPT-4 was shown to arrive at the correct answers more often than would be expected based on chance, although correct answers were often arrived at on the basis of false assumptions or invalid reasoning.
    
[^62]: 在资源受限的嵌入式设备上部署基于BERT的NLP模型的挑战探究

    Exploring Challenges of Deploying BERT-based NLP Models in Resource-Constrained Embedded Devices. (arXiv:2304.11520v1 [cs.CL])

    [http://arxiv.org/abs/2304.11520](http://arxiv.org/abs/2304.11520)

    本文探究了在资源受限的嵌入式设备上部署基于BERT的NLP模型的挑战，并得出结论：虽然DistilBERT和TinyBERT等轻量级模型相对占用更少内存，但它们在复杂的NLP任务上表现较差；ResNet-based BERT模型可以在精度和资源效率之间取得良好的平衡，适合在嵌入式设备上部署。

    

    基于BERT的神经架构已经成为许多下游NLP任务的流行先进技术基准。然而，这些架构对数据依赖性强，占用大量内存和能量，经常阻碍它们在许多实时、资源受限的应用程序中的部署。现有的BERT轻量级版本（例如DistilBERT和TinyBERT）通常在复杂的NLP任务上无法表现出良好的性能。更重要的是，从设计师的角度来看，要为特定的NLP任务使用何种“正确的”基于BERT的架构，以在资源可用性和最终用户需求的最小精度之间实现最佳权衡，尚不确定。系统工程师必须花费大量时间进行试错实验，以找到合适的答案。本文在不同的资源限制和精度预算下对BERT-based模型进行了探究性研究，以得出有关此资源/精度权衡的经验性观察结果。我们的研究发现，虽然DistilBERT和TinyBERT等更轻量级的模型相对BERT-base占用的内存要少得多，但它们在复杂的NLP任务中精度的下降是明显的。我们还观察到，特别是基于ResNet的BERT模型，可以在准确性和资源效率之间取得良好的平衡，使其成为在资源受限的嵌入式设备中部署的良好候选模型。

    BERT-based neural architectures have established themselves as popular state-of-the-art baselines for many downstream NLP tasks. However, these architectures are data-hungry and consume a lot of memory and energy, often hindering their deployment in many real-time, resource-constrained applications. Existing lighter versions of BERT (eg. DistilBERT and TinyBERT) often cannot perform well on complex NLP tasks. More importantly, from a designer's perspective, it is unclear what is the "right" BERT-based architecture to use for a given NLP task that can strike the optimal trade-off between the resources available and the minimum accuracy desired by the end user. System engineers have to spend a lot of time conducting trial-and-error experiments to find a suitable answer to this question. This paper presents an exploratory study of BERT-based models under different resource constraints and accuracy budgets to derive empirical observations about this resource/accuracy trade-offs. Our findin
    
[^63]: Spaiche: 将最先进的ASR模型扩展到瑞士德语方言

    Spaiche: Extending State-of-the-Art ASR Models to Swiss German Dialects. (arXiv:2304.11075v1 [cs.CL])

    [http://arxiv.org/abs/2304.11075](http://arxiv.org/abs/2304.11075)

    本项目在瑞士德语方言ASR模型的研究中提供了有价值的思路，通过提出考虑语义距离的新颖损失函数，对OpenAI的Whisper模型进行微调，取得了优于当前先进成果的效果。

    

    最近自然语言处理方面的突破大大增加了ASR系统在我们日常生活中的存在。然而，对于许多低资源语言，由于难以获取相关数据，ASR模型仍需要改进。本项目旨在通过提供关于最近发布的瑞士德语语音数据集上最先进的ASR模型性能的见解，帮助推进瑞士德语方言ASR模型的研究。我们提出了一种新颖的损失函数，考虑了预测和基准标签之间的语义距离。通过对瑞士德语数据集对OpenAI的Whisper模型进行微调，我们超越了当前先进的成果。

    Recent breakthroughs in NLP largely increased the presence of ASR systems in our daily lives. However, for many low-resource languages, ASR models still need to be improved due in part to the difficulty of acquiring pertinent data. This project aims to help advance research in ASR models for Swiss German dialects, by providing insights about the performance of state-of-the-art ASR models on recently published Swiss German speech datasets. We propose a novel loss that takes into account the semantic distance between the predicted and the ground-truth labels. We outperform current state-of-the-art results by fine-tuning OpenAI's Whisper model on Swiss-German datasets.
    
[^64]: 人工智能心理学中的“正确答案”

    "Correct answers" from the psychology of artificial intelligence. (arXiv:2302.07267v3 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2302.07267](http://arxiv.org/abs/2302.07267)

    本文使用OpenAI的GPT3.5模型重新复制了Many Labs 2复制项目中的14项研究，其中8项研究的结果被成功复制。然而，对于剩下的6项研究，GPT3.5以极其预定的方式回答了调查问题，导致无法分析这些研究。

    This paper replicates 14 studies from the Many Labs 2 replication project with OpenAI's text-davinci-003 model, and successfully replicates the results of 8 studies. However, for the remaining 6 studies, GPT3.5 answered survey questions in an extremely predetermined way, making it impossible to analyze these studies.

    大型语言模型的能力已经大大增强。这种AI系统的一个提出的应用是支持社会和认知科学中的数据收集，目前完美的实验控制是不可行的，而大规模、代表性数据集的收集通常是昂贵的。在本文中，我们使用OpenAI的text-davinci-003模型（俗称GPT3.5）重新复制了Many Labs 2复制项目中的14项研究。我们通过将每项研究的调查作为文本输入，从GPT3.5的默认设置中收集了响应。在我们可以分析的八项研究中，我们的GPT样本复制了原始结果的37.5%以及Many Labs 2结果的37.5%。出乎意料的是，我们无法像预先注册的计划那样分析剩下的六项研究。这是因为对于这六项研究中的每一项，GPT3.5以极其预定的方式回答了调查问题（无论是因变量还是条件变量）：一个未知的

    Large Language Models have vastly grown in capabilities. One proposed application of such AI systems is to support data collection in the social and cognitive sciences, where perfect experimental control is currently unfeasible and the collection of large, representative datasets is generally expensive. In this paper, we re-replicate 14 studies from the Many Labs 2 replication project with OpenAI's text-davinci-003 model, colloquially known as GPT3.5. We collected responses from the default setting of GPT3.5 by inputting each study's survey as text. Among the eight studies we could analyse, our GPT sample replicated 37.5% of the original results as well as 37.5% of the Many Labs 2 results. Unexpectedly, we could not analyse the remaining six studies as we had planned in our pre-registration. This was because for each of these six studies, GPT3.5 answered at least one of the survey questions (either a dependent variable or a condition variable) in an extremely predetermined way: an unex
    
[^65]: ColD Fusion: 协同下降的分布式多任务微调方法

    ColD Fusion: Collaborative Descent for Distributed Multitask Finetuning. (arXiv:2212.01378v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.01378](http://arxiv.org/abs/2212.01378)

    ColD Fusion是一种协同下降的分布式多任务微调方法，通过利用分布式计算，可以不断改进预训练模型，并在各种数据集上表现良好，优于RoBERTa模型。

    

    我们提出了一种新的范式来不断演进预训练模型，称为ColD Fusion。它具有多任务学习的优势，但利用有限通信的分布式计算，并且消除了共享数据的需求。因此，ColD Fusion可以形成一个协同循环，其中微调模型可以循环利用，不断改进它们所基于的预训练模型。我们展示了ColD Fusion产生了与多任务训练相当的好处，通过产生一个在所有训练数据集上表现良好并且在未见数据集上进行微调的更好的起点模型。我们展示了ColD Fusion优于RoBERTa甚至以前的多任务模型。具体来说，在使用35个不同数据集进行训练和测试时，ColD Fusion-based模型在不改变架构的情况下平均优于RoBERTa 2.33个点。

    We propose a new paradigm to continually evolve pretrained models, denoted ColD Fusion. It provides the benefits of multitask learning but leverages distributed computation with limited communication and eliminates the need for shared data. Consequentially, ColD Fusion can give rise to a synergistic loop, where finetuned models can be recycled to continually improve the pretrained model they are based upon. We show that ColD Fusion yields comparable benefits to multitask training by producing a model that (a) attains strong performance on all of the datasets it was trained on; and (b) is a better starting point for finetuning on unseen datasets. We show that ColD Fusion outperforms RoBERTa and even previous multitask models. Specifically, when training and testing on 35 diverse datasets, ColD Fusion-based model outperforms RoBERTa by 2.33 points on average without any changes to the architecture.
    
[^66]: 生成视频字幕中的事件和实体提取

    Event and Entity Extraction from Generated Video Captions. (arXiv:2211.02982v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.02982](http://arxiv.org/abs/2211.02982)

    该论文提出了一个从生成的视频字幕中提取语义元数据的框架，通过使用密集视频字幕模型，可以提取实体、实体属性、实体之间的关系和视频分类。提取信息的质量受到事件定位质量和字幕生成性能的影响。

    

    由人工进行多媒体数据注释耗时且昂贵，而可靠的自动生成语义元数据是一个重大挑战。我们提出了一个从自动生成的视频字幕中提取语义元数据的框架。作为元数据，我们考虑实体、实体属性、实体之间的关系以及视频分类。我们使用两种最先进的密集视频字幕模型，即遮蔽转换器（MT）和并行解码（PVDC），为ActivityNet Captions数据集的视频生成字幕。我们的实验证明，从生成的字幕中提取实体、实体属性、实体之间的关系和视频分类是可能的。我们观察到，提取信息的质量主要受到视频中事件定位的质量以及事件字幕生成的性能的影响。

    Annotation of multimedia data by humans is time-consuming and costly, while reliable automatic generation of semantic metadata is a major challenge. We propose a framework to extract semantic metadata from automatically generated video captions. As metadata, we consider entities, the entities' properties, relations between entities, and the video category. We employ two state-of-the-art dense video captioning models with masked transformer (MT) and parallel decoding (PVDC) to generate captions for videos of the ActivityNet Captions dataset. Our experiments show that it is possible to extract entities, their properties, relations between entities, and the video category from the generated captions. We observe that the quality of the extracted information is mainly influenced by the quality of the event localization in the video as well as the performance of the event caption generation.
    

