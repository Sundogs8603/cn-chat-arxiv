# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [POMP: Probability-driven Meta-graph Prompter for LLMs in Low-resource Unsupervised Neural Machine Translation.](http://arxiv.org/abs/2401.05596) | POMP是一种新颖的方法，使用动态的、基于抽样的多辅助语言图形，提高了语言模型在低资源语言中的翻译能力。 |
| [^2] | [TrustLLM: Trustworthiness in Large Language Models.](http://arxiv.org/abs/2401.05561) | TrustLLM是对大型语言模型中可信性的全面研究，包括可信性原则的提出、建立基准的方法、评估主流语言模型的可信性，以及对未来挑战的讨论。 |
| [^3] | [The Impact of Reasoning Step Length on Large Language Models.](http://arxiv.org/abs/2401.04925) | 本研究探讨了推理步长对大型语言模型的影响，并发现在提示中增加推理步骤能显著提高模型的推理能力，而减少推理步骤则会降低模型的推理能力。 |
| [^4] | [Lightning Attention-2: A Free Lunch for Handling Unlimited Sequence Lengths in Large Language Models.](http://arxiv.org/abs/2401.04658) | 本文介绍了Lightning Attention-2，这是第一个能够实现线性注意力理论计算优势的线性注意力实现。通过利用平铺的思想，分别处理了线性注意力计算中的内部块和外部块组件。具体来说，采用传统的注意力计算机制处理内部块，并使用新的累积求和方法处理外部块。 |
| [^5] | [A Content-Based Novelty Measure for Scholarly Publications: A Proof of Concept.](http://arxiv.org/abs/2401.03642) | 本论文引入了一种基于信息论的学术论文新颖性度量方法，该方法通过量化语言模型感知的"惊喜"程度，结合了面向科学常识和领域专家评估，具有可解释性、细粒度和易用性。 |
| [^6] | [Has Your Pretrained Model Improved? A Multi-head Posterior Based Approach.](http://arxiv.org/abs/2401.02987) | 本研究提出一种基于多头后验的方法，通过利用实体的元特征和模型的表示之间的一致性作为度量标准，有效评估预训练模型在各个领域的表现。 |
| [^7] | [Beyond Extraction: Contextualising Tabular Data for Efficient Summarisation by Language Models.](http://arxiv.org/abs/2401.02333) | 本研究提出了一种创新的方法，通过上下文化表格数据来提高 RAG 系统中处理复杂表格查询的准确性，提高了摘要的效率。 |
| [^8] | [LLaVA-$\phi$: Efficient Multi-Modal Assistant with Small Language Model.](http://arxiv.org/abs/2401.02330) | LLaVA-$\phi$是一种高效的多模态助手，使用小型语言模型Phi-2来促进多模态对话。即使具有较少的参数，它也能有效地融合文本和视觉元素，并在各种任务中表现出色。它为时间敏感的环境和需要实时交互的系统开辟了新的应用途径。 |
| [^9] | [WordArt Designer API: User-Driven Artistic Typography Synthesis with Large Language Models on ModelScope.](http://arxiv.org/abs/2401.01699) | 本文介绍了WordArt设计师API，它利用大型语言模型在模型范围上进行用户驱动的艺术字体合成。通过提供动态、自适应和高效的替代方案，该方法能够满足非专业人士简化艺术字体的需求，并实现了更直观的设计过程。与现有系统相比，该API显著提高了用户满意度、设计灵活性和创造性表达，并为个性化数字通信和设计开辟了新的可能性。 |
| [^10] | [An Autoregressive Text-to-Graph Framework for Joint Entity and Relation Extraction.](http://arxiv.org/abs/2401.01326) | 这篇论文提出了一种新颖的方法，通过将联合实体和关系抽取问题作为条件序列生成问题来解决。该方法使用了基于跨度的图生成方式，并通过指向机制将生成的输出与原始文本对齐。评估结果证明了该方法的有效性，并获得了竞争性的结果。 |
| [^11] | [ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios.](http://arxiv.org/abs/2401.00741) | ToolEyes是一个专门用于评估大型语言模型在真实情景中的工具学习能力的细粒度系统，通过对七个真实情景的详细分析，评估了LLMs在工具学习的五个关键维度，并提供了一个拥有600种工具的工具库作为中介。 |
| [^12] | [Mitigating the Impact of False Negatives in Dense Retrieval with Contrastive Confidence Regularization.](http://arxiv.org/abs/2401.00165) | 该论文提出了一种用于减轻密集检索中假阴性影响的对比置信度正则化方法，通过改进对比学习的硬负例采样问题，使得密集检索模型更加稳健。 |
| [^13] | [MosaicBERT: A Bidirectional Encoder Optimized for Fast Pretraining.](http://arxiv.org/abs/2312.17482) | MosaicBERT是一种优化的BERT风格双向编码器，通过引入多项创新技术和优化方案，实现了快速预训练。 |
| [^14] | [Improving Low-resource Prompt-based Relation Representation with Multi-view Decoupling Learning.](http://arxiv.org/abs/2312.17267) | 提出了一种名为MVRE的新方法，通过将关系解耦为不同的视角，生成多视角关系表示，并利用预训练语言模型（PLMs）的能力来提高低资源关系抽取任务的性能。 |
| [^15] | [T-Eval: Evaluating the Tool Utilization Capability Step by Step.](http://arxiv.org/abs/2312.14033) | T-Eval是一种逐步评估工具利用能力的方法，它将工具利用评估解耦为多个子领域，从而能够更细致地分析大型语言模型（LLM）的能力。 |
| [^16] | [Knowledge Graph Error Detection with Contrastive Confidence Adaption.](http://arxiv.org/abs/2312.12108) | 本文提出了一种使用对比学习和交互式对比学习的知识图谱错误检测模型CCA，通过综合文本和图结构信息，更好地区分语义，从而在检测噪声方面优于当前最先进的方法。 |
| [^17] | ["Paraphrasing The Original Text" Makes High Accuracy Long-Context QA.](http://arxiv.org/abs/2312.11193) | 本论文提出了一种名为"原文改写"的任务来处理长文本问答，通过低成本高效的方法成功扩展了现有模型的上下文窗口至32k，并在多文档问答中达到了最先进的准确性。 |
| [^18] | [Knowledge Graph Enhanced Aspect-Level Sentiment Analysis.](http://arxiv.org/abs/2312.10048) | 本文提出了一种知识图谱增强的方面级情感分析方法，通过使用BERT模型和知识图谱的同义词数据，在解决上下文特定词义的挑战上取得了优越的性能。 |
| [^19] | [Mitigating Outlier Activations in Low-Precision Fine-Tuning of Language Models.](http://arxiv.org/abs/2312.09211) | 本论文研究了在语言模型低精度微调中减少异常激活的技术，提出了一种能够用8位整数表示异常激活值的新方法，通过使用整数和运算符切片来提高效率和性能。 |
| [^20] | [Linguistic and Structural Basis of Engineering Design Knowledge.](http://arxiv.org/abs/2312.06355) | 本文通过分析33881份专利文件的样本，将工程设计知识阐释为知识图谱，从而揭示工程设计知识的语言和结构基础。 |
| [^21] | [CLadder: A Benchmark to Assess Causal Reasoning Capabilities of Language Models.](http://arxiv.org/abs/2312.04350) | 该论文提出了一个新的NLP任务，评估语言模型在因果推理方面的能力。作者构建了一个大规模的数据集CLadder，并利用oracle因果推理引擎将符号问题转化为自然语言。研究结果表明多个LLMs在该数据集上的表现，并引入并评估了一种定制的链式推理机制。 |
| [^22] | [ChatGPT's One-year Anniversary: Are Open-Source Large Language Models Catching up?.](http://arxiv.org/abs/2311.16989) | ChatGPT一周年纪念，调查了开源大型语言模型是否赶上了封闭源代码模型的进展，尽管后者仍然优于前者，但开源模型在某些任务上已经达到了相同甚至更好的性能。 |
| [^23] | [Dynamic Fault Characteristics Evaluation in Power Grid.](http://arxiv.org/abs/2311.16522) | 该论文提出了一种在电力系统中进行故障检测的新方法，通过图神经网络识别故障节点，并利用前后时间段内节点的状态来辅助当前故障检测。实验证明该方法准确可靠，并提供了对故障节点传播的定性分析。 |
| [^24] | [Evaluating the Efficacy of Hybrid Deep Learning Models in Distinguishing AI-Generated Text.](http://arxiv.org/abs/2311.15565) | 本研究评估了混合深度学习模型在准确区分AI生成文本和人类写作方面的有效性。通过应用先进的自然语言处理技术和复杂的神经网络，我们的研究成功地检测到了AI生成文本和人类写作之间的微妙差异。 |
| [^25] | [Dynamic Fault Analysis in Substations Based on Knowledge Graphs.](http://arxiv.org/abs/2311.13708) | 提出了一种基于知识图谱的变电站动态故障分析方法，利用非结构化文本提取相关信息，通过隐藏马尔科夫模型训练数据，利用Neo4j图数据库创建知识图谱，实现对变电站中隐藏危险的可视化分析。 |
| [^26] | [Enabling On-Device Large Language Model Personalization with Self-Supervised Data Selection and Synthesis.](http://arxiv.org/abs/2311.12275) | 本文提出了一种在设备上实现自我监督数据选择和合成的大规模语言模型个性化的框架，通过选择和存储最具代表性的数据来解决稀疏注释和有限的设备存储限制。 |
| [^27] | [Large Language Models for Propaganda Span Annotation.](http://arxiv.org/abs/2311.09812) | 本研究探讨了使用大型语言模型（LLMs）来检测宣传性文本跨度的任务，并研究了利用该模型收集更具成本效益的标注的潜力。 |
| [^28] | [Knowledge Graph Construction in Power Distribution Networks.](http://arxiv.org/abs/2311.08724) | 本文提出了一种在电力分配网络中构建知识图谱的方法，该方法利用实体特征，在分配网络的知识图谱和分配文本中进行匹配，通过实验证明了其在电力分配知识图谱构建任务中的高准确性。 |
| [^29] | [Locating Cross-Task Sequence Continuation Circuits in Transformers.](http://arxiv.org/abs/2311.04131) | 通过分析和比较Transformer模型中类似的序列继续任务的电路，研究发现共享的计算结构可以提高模型的行为预测能力、错误识别能力和编辑过程的安全性。 |
| [^30] | [Do LLMs exhibit human-like response biases? A case study in survey design.](http://arxiv.org/abs/2311.04076) | 本研究以调查设计为案例研究，探讨了LLMs是否展现类似于人类的反应偏差的问题。 |
| [^31] | [ALYMPICS: Language Agents Meet Game Theory -- Exploring Strategic Decision-Making with AI Agents.](http://arxiv.org/abs/2311.03220) | 本文介绍了Alympics，一个利用大型语言模型代理人进行博弈论研究的系统性模拟框架。通过模拟人类战略互动，框架能够定性和定量地分析游戏决定因素、策略和结果，并对代理人在战略决策场景中的表现进行评估。 |
| [^32] | [LLMs may Dominate Information Access: Neural Retrievers are Biased Towards LLM-Generated Texts.](http://arxiv.org/abs/2310.20501) | 近期的研究发现，大型语言模型（LLMs）对信息检索系统产生了一种偏见，倾向于将LLM生成的文档排名较高。这种“来源偏见”可能对信息访问产生重大影响。 |
| [^33] | [Integrating Pre-trained Language Model into Neural Machine Translation.](http://arxiv.org/abs/2310.19680) | 该论文提出了PiNMT模型，将预训练语言模型整合到神经机器翻译中，通过三个关键部分和两种训练策略，实现了在IW数据集上的最先进性能。 |
| [^34] | [CXR-LLaVA: Multimodal Large Language Model for Interpreting Chest X-ray Images.](http://arxiv.org/abs/2310.18341) | 本研究开发了一种用于解读胸部X射线图像的开源多模态大型语言模型（CXR-LLaVA），通过预训练图像编码器和对比语言-图像预训练将图像与放射学异常对齐，并使用GPT-4进行微调，实现了问题回答的功能。 |
| [^35] | [Beyond Accuracy: Evaluating Self-Consistency of Code Large Language Models with IdentityChain.](http://arxiv.org/abs/2310.14053) | 这篇论文提出了一种评估大型代码语言模型自一致性的方法，并指出目前的模型在自一致性方面存在问题。 |
| [^36] | [MolCA: Molecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal Adapter.](http://arxiv.org/abs/2310.12798) | MolCA是一个可以通过跨模态投影和单模态适配器实现分子图和语言的建模系统。它可以通过连接图编码器和语言模型的表示空间来理解文本和图形的分子内容，并通过单模态适配器在下游任务中高效适应。 |
| [^37] | [VeRA: Vector-based Random Matrix Adaptation.](http://arxiv.org/abs/2310.11454) | VeRA提出了一种基于向量的随机矩阵自适应方法，相比于低秩自适应方法，可以显著减少可训练参数的数量，同时保持相同的性能。该方法在GLUE和E2E基准测试、图像分类任务以及指令调优中都取得了良好的效果。 |
| [^38] | [SD-HuBERT: Self-Distillation Induces Syllabic Organization in HuBERT.](http://arxiv.org/abs/2310.10803) | 本研究提出了SD-HuBERT模型，通过采用自我蒸馏目标进行微调，实现了在学习语音句子级表示时音节组织的出现，模型能够在语音中划定明确的边界，并展现出显著的音节结构。该研究还提出了一个新的基准任务用于评估语音的句子级表示，与之前的模型相比，在无监督音节发现和学习句子级表示方面表现优异。 |
| [^39] | [Self-Supervised Models of Speech Infer Universal Articulatory Kinematics.](http://arxiv.org/abs/2310.10788) | 本研究展示了自我监督语音模型具有推断语音发音运动学的能力，并显示出这一属性在不同语言中具有重叠性。此外，通过简单变换，模型可以在不同说话者、性别、语言和方言之间转换，表现出良好的泛化性。这些结果拓宽了我们对语音处理的理解。 |
| [^40] | [CP-KGC: Constrained-Prompt Knowledge Graph Completion with Large Language Models.](http://arxiv.org/abs/2310.08279) | CP-KGC方法利用大型语言模型，通过约束式提示来补全知识图谱，提高推断效果，展示了在低资源计算条件下的有效性，并在数据集上取得了优于之前方法的结果。 |
| [^41] | [Aligning Language Models with Human Preferences via a Bayesian Approach.](http://arxiv.org/abs/2310.05782) | 本文提出了一种贝叶斯方法，通过训练奖励模型来对齐语言模型和人类偏好。这种方法能够解决由于人类偏好的主观性而带来的困难，从而提高自然语言生成系统的性能。 |
| [^42] | [Glitter or Gold? Deriving Structured Insights from Sustainability Reports via Large Language Models.](http://arxiv.org/abs/2310.05628) | 通过大型语言模型和信息抽取技术，本研究提取了公司可持续性报告中的结构化ESG相关信息，为利益相关者提供简洁、信息丰富和可行动的数据。 |
| [^43] | [Transcending the Attention Paradigm: Representation Learning from Geospatial Social Media Data.](http://arxiv.org/abs/2310.05378) | 本研究通过分析地理社交媒体数据发现，传统的基于注意力的架构存在局限性，无法隐含学习总体文本主题。相比于捕捉复杂长期依赖性的网络，在线数据的模型缺乏结构，需要在聚合中检测潜在的结构。此研究使用了20亿条推文进行实证分析，并比较了不同城市的词袋嵌入表示，发现地理位置对在线沟通有重要影响。 |
| [^44] | [Multilingual Natural Language ProcessingModel for Radiology Reports -- The Summary is all you need!.](http://arxiv.org/abs/2310.00100) | 本研究通过在多语言文本到文本变换器模型上微调，开发了一个能够自动在多语言中总结放射学报告的模型。该模型有助于提高未来深度学习模型的研究和发展，且能够应用于不同族裔背景的患者数据。 |
| [^45] | [Unsupervised Fact Verification by Language Model Distillation.](http://arxiv.org/abs/2309.16540) | 本文提出了一种名为SFAVEL的无监督框架，通过语言模型蒸馏将自监督特征转化为高质量的主张-事实对齐，实现无监督事实验证。这通过一种新颖的对比损失函数实现，同时保留语料库间的语义关系。 |
| [^46] | [Human Feedback is not Gold Standard.](http://arxiv.org/abs/2309.16349) | 这个论文对人类反馈在语言模型评估中的使用进行了批判性分析，发现它们无法完全捕捉到关键错误标准，而且容易受到主观偏见和混杂因素的影响。 |
| [^47] | [Towards General-Purpose Text-Instruction-Guided Voice Conversion.](http://arxiv.org/abs/2309.14324) | 本文介绍了一种通过文本指令进行语音转换的通用模型。与传统方法不同，该模型利用文本指令修改语音的韵律和情感信息，具有较高的灵活性和特异性。实验证明了该模型能够理解指令并产生合理结果。 |
| [^48] | [AMPLIFY:Attention-based Mixup for Performance Improvement and Label Smoothing in Transformer.](http://arxiv.org/abs/2309.12689) | AMPLIFY提出了一种基于注意力机制的Mixup方法，用于减少原始样本中的噪音和异常值对于模型的影响，并在文本分类任务中表现出更好的性能。 |
| [^49] | [CB-Whisper: Contextual Biasing Whisper using Open-Vocabulary Keyword-Spotting.](http://arxiv.org/abs/2309.09552) | CB-Whisper是一种基于OpenAI的Whisper模型的自动语音识别系统，通过使用开放词汇关键词检测（OV-KWS）识别罕见的命名实体，并使用这些实体作为提示来改进识别效果。实验证明，该方法在提高实体召回率的同时会略微增加混淆错误率（MER）。 |
| [^50] | [Evaluation and Mitigation of Agnosia in Multimodal Large Language Models.](http://arxiv.org/abs/2309.04041) | 本文针对多模态大型语言模型中存在的失识症问题，提出了一种评估和缓解的框架EMMA。通过类比神经心理学中的失识症现象，定义了MLLM中的失识症，并提出了相应的评估和治疗方法。评估模块通过创建多样化的视觉问答示例来评估失识症程度，治疗模块则采用修正和增强的训练方法来减轻和纠正失识症。 |
| [^51] | [Dialogue for Prompting: a Policy-Gradient-Based Discrete Prompt Generation for Few-shot Learning.](http://arxiv.org/abs/2308.07272) | 本文介绍了一种基于对话的策略梯度离散提示优化方法，通过设计多轮对话对齐策略和高效的提示筛选度量，实现了在少样本学习任务中生成高质量提示集的目标。 |
| [^52] | [QuIP: 2-Bit Quantization of Large Language Models With Guarantees.](http://arxiv.org/abs/2307.13304) | 本文提出了一种新的基于无关处理的大型语言模型（LLMs）参数量化方法QuIP，通过使权重和Hessian矩阵与坐标轴不对齐，实现了准确的量化结果。经过经验实验，我们发现我们的方法改善了现有的量化算法，并且首次在仅使用两比特的情况下获得了可行的LLM量化结果。 |
| [^53] | [Integrating a Heterogeneous Graph with Entity-aware Self-attention using Relative Position Labels for Reading Comprehension Model.](http://arxiv.org/abs/2307.10443) | 本文提出了一种新的注意力模式，使用图增强自注意力机制将从异构图中导出的推理知识整合到变压器架构中，从而克服了变压器模型在复杂推理任务中的限制。通过全局-局部注意力、图注意力和关系类型考虑，优化了实体和单词之间的注意力。该模式与相对位置标签相结合，能够与LUKE的实体感知自注意力机制相集成。 |
| [^54] | [Advancing Italian Biomedical Information Extraction with Large Language Models: Methodological Insights and Multicenter Practical Application.](http://arxiv.org/abs/2306.05323) | 该研究创建了意大利神经精神命名实体识别数据集，并使用巨型语言模型开发出多中心识别模型，整体 F1得分为84.77%。该模型将帮助临床从业者从非结构化的医疗记录中自动提取信息。 |
| [^55] | [Using Large Language Model Annotations for Valid Downstream Statistical Inference in Social Science: Design-Based Semi-Supervised Learning.](http://arxiv.org/abs/2306.04746) | 该论文提出了一种新算法，使用大型语言模型（LLMs）输出进行下游统计分析，以实现有效的下游统计推断，并降低标签获取的研究成本80％，同时保证CSS研究的统计属性。 |
| [^56] | [Neural Task Synthesis for Visual Programming.](http://arxiv.org/abs/2305.18342) | 该论文提出了一种基于神经符号技术的可视化编程任务合成方法NeurTaskSyn。该方法能够针对规范中给出的解决方案代码所需要的编程概念和对可视化任务的限制，自动生成编程任务。 |
| [^57] | [Learning a Structural Causal Model for Intuition Reasoning in Conversation.](http://arxiv.org/abs/2305.17727) | 本文基于对话认知的直觉理论，提出了一个对话认知模型，以解释每个话语如何递归地获得和激活信息通道。通过将其代数转化为结构因果模型，我们进一步实现了该模型在话语级别的关系推理。通过利用变分推断，它解决了隐含原因的问题，并通过证据下界重构了话语的因果表示。 |
| [^58] | [Translatotron 3: Speech to Speech Translation with Monolingual Data.](http://arxiv.org/abs/2305.17547) | Translatotron 3提出了一种新方法，使用单语数据进行语音到语音翻译，无需配对的数据或专业建模，展示了保留语言/非语言信息的能力。 |
| [^59] | [Motion-Based Sign Language Video Summarization using Curvature and Torsion.](http://arxiv.org/abs/2305.16801) | 该论文介绍了一种基于曲率和扭矩的手语视频摘要技术，能够选出最具信息量的关键帧。 |
| [^60] | [ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via Tool Embeddings.](http://arxiv.org/abs/2305.11554) | 本论文提出了一种名为ToolkenGPT的方法，将大型语言模型（LLMs）与外部工具相结合，引入了toolken的概念，利用tool embeddings实现无缝交互，同时在各种下游任务上展示出了良好的效果。 |
| [^61] | [Democratized Diffusion Language Model.](http://arxiv.org/abs/2305.10818) | 本文提出了一个基于CDCD框架的民主扩散语言模型（DDLM），并通过GLUE基准测试了其知识转移能力，为研究人员提供了DDLM训练和评估流程以及已训练的DDLM模型。 |
| [^62] | [DinoSR: Self-Distillation and Online Clustering for Self-supervised Speech Representation Learning.](http://arxiv.org/abs/2305.10005) | 本研究提出了DinoSR模型，它结合了遮蔽语言建模、自蒸馏和在线聚类等概念，能够在自监督语音表示学习任务中产生很好的效果，超越了以前的最新技术水平。 |
| [^63] | [SwissBERT: The Multilingual Language Model for Switzerland.](http://arxiv.org/abs/2303.13310) | 该论文介绍了SwissBERT，它是一个专门为处理瑞士相关文本而创建的多语言语言模型，SwissBERT在与瑞士相关的自然语言理解任务上的效果优于以前的模型。 |
| [^64] | [Difficulty in learning chirality for Transformer fed with SMILES.](http://arxiv.org/abs/2303.11593) | 应用SMILES序列的Transformer模型在学习分子结构的整体性和手性方面存在困难，需要进行长时间的训练。生成的描述符用于分子性质预测时的准确率从开始到训练结束都是相似的。 |
| [^65] | [A Large-Scale Analysis of Persian Tweets Regarding Covid-19 Vaccination.](http://arxiv.org/abs/2302.04511) | 本文利用Twitter数据进行了对伊朗公众对COVID-19疫苗的意见进行的全面分析，结果显示该疫苗引起了广泛关注，涉及政府问题、安全性、犹豫不决和副作用等方面。 |
| [^66] | [The Re-Label Method For Data-Centric Machine Learning.](http://arxiv.org/abs/2302.04391) | 本文提出了一种重新标签的方法来解决手动标记的数据中存在噪声的问题，并通过模型预测来辅助人类标记噪声数据。实验证明此方法适用于多类深度学习任务。 |
| [^67] | [Undesirable biases in NLP: Averting a crisis of measurement.](http://arxiv.org/abs/2211.13709) | 这项研究提供了一个跨学科的方法来探讨NLP模型偏见的问题，通过采用心理测量学的视角，特别关注构念效度和测量工具的信度，在衡量模型偏见的情境中如何应用。 |
| [^68] | [NormSAGE: Multi-Lingual Multi-Cultural Norm Discovery from Conversations On-the-Fly.](http://arxiv.org/abs/2210.08604) | NormSAGE是一个用于对话驱动的多语言多文化规范发现的框架，利用预训练的GPT-3语言模型进行知识引发，并通过自验证机制确保发现的规范正确且与源对话相关。 |
| [^69] | [Towards Faithful Model Explanation in NLP: A Survey.](http://arxiv.org/abs/2209.11326) | 本调查研究回顾了超过110种自然语言处理模型解释方法，并从忠实性的角度进行了分类和综合。研究介绍了忠实解释的最新进展，并讨论了各个方法的优点、缺点以及未来的挑战。 |
| [^70] | [Discovering Salient Neurons in Deep NLP Models.](http://arxiv.org/abs/2206.13288) | 使用语言相关分析技术，我们发现在深度NLP模型中存在一些突出的神经元，这些神经元能够捕捉特定的语言属性，而且信息保存冗余程度较高。调整预训练模型对下游NLP任务的影响以及不同架构学习不同语言属性的差异也得到了研究。 |
| [^71] | [Representation Learning for Weakly Supervised Relation Extraction.](http://arxiv.org/abs/2105.00815) | 本研究关注如何通过无监督预训练来改进在有限训练数据情况下的监督基线系统性能，并分析了传统手工特征在关系抽取中可能存在的数据稀疏性问题。 |
| [^72] | [Inducing Meaningful Units from Character Sequences with Dynamic Capacity Slot Attention.](http://arxiv.org/abs/2102.01223) | 该论文提出了一种无监督的分布式方法，使用动态容量槽注意力模型从字符序列中学习抽象有意义单元，成功发现了与先前提出的单元相似的、适用于更高级别抽象的可捕捉有意义信息的单元。 |
| [^73] | [Learning From How Humans Correct.](http://arxiv.org/abs/2102.00225) | 本研究提出了一种从人类矫正中学习的方法。通过标注数据中的噪声数据，收集纠错信息，并将其注入至深度学习模型中，成功将文本分类准确度提升了1.7个百分点。 |

# 详细

[^1]: POMP:用于低资源无监督神经机器翻译中的概率驱动元图提示器

    POMP: Probability-driven Meta-graph Prompter for LLMs in Low-resource Unsupervised Neural Machine Translation. (arXiv:2401.05596v1 [cs.CL])

    [http://arxiv.org/abs/2401.05596](http://arxiv.org/abs/2401.05596)

    POMP是一种新颖的方法，使用动态的、基于抽样的多辅助语言图形，提高了语言模型在低资源语言中的翻译能力。

    

    低资源语言在有限的平行数据下面临着在监督神经机器翻译中的挑战，因此研究无监督方法。无监督神经机器翻译方法，包括反向翻译、迁移学习和基于枢轴的翻译，为低资源语言翻译提供了实用的解决方案，但是它们受到合成数据噪声、语言偏差和错误传播等问题的影响，这些问题可以通过大型语言模型进行缓解。语言模型通过上下文学习和有监督微调方法改进了NMT，但是训练数据不足使得在低资源语言上的性能较差。我们认为语言模型可以通过辅助语言减少语言噪声，提高低资源语言的翻译质量。在本文中，我们提出了一种名为POMP的概率驱动元图提示器，它采用了基于动态抽样的多个辅助语言的图形，以增强语言模型在低资源语言上的翻译能力。

    Low-resource languages (LRLs) face challenges in supervised neural machine translation due to limited parallel data, prompting research into unsupervised methods. Unsupervised neural machine translation (UNMT) methods, including back-translation, transfer learning, and pivot-based translation, offer practical solutions for LRL translation, but they are hindered by issues like synthetic data noise, language bias, and error propagation, which can potentially be mitigated by Large Language Models (LLMs). LLMs have advanced NMT with in-context learning (ICL) and supervised fine-tuning methods, but insufficient training data results in poor performance in LRLs. We argue that LLMs can mitigate the linguistic noise with auxiliary languages to improve translations in LRLs. In this paper, we propose Probability-driven Meta-graph Prompter (POMP), a novel approach employing a dynamic, sampling-based graph of multiple auxiliary languages to enhance LLMs' translation capabilities for LRLs. POMP inv
    
[^2]: TrustLLM: 大型语言模型中的可信性

    TrustLLM: Trustworthiness in Large Language Models. (arXiv:2401.05561v1 [cs.CL])

    [http://arxiv.org/abs/2401.05561](http://arxiv.org/abs/2401.05561)

    TrustLLM是对大型语言模型中可信性的全面研究，包括可信性原则的提出、建立基准的方法、评估主流语言模型的可信性，以及对未来挑战的讨论。

    

    大型语言模型（LLMs），如ChatGPT，因其出色的自然语言处理能力而引起了广泛关注。然而，这些LLMs在可信性方面存在许多挑战。因此，确保LLMs的可信性成为一个重要的话题。本文介绍了TrustLLM，它是对LLMs中可信性的全面研究，包括不同维度的可信性原则、建立基准、评估和分析主流LLMs的可信性，以及对开放挑战和未来方向的讨论。具体而言，我们首先提出了涵盖八个不同维度的可信LLMs原则。基于这些原则，我们进一步建立了一个跨六个维度的基准，包括真实性、安全性、公平性、鲁棒性、隐私性和机器伦理学。然后，我们在TrustLLM中展示了一个评估16个主流LLMs的研究，涵盖了30多个数据集。

    Large language models (LLMs), exemplified by ChatGPT, have gained considerable attention for their excellent natural language processing capabilities. Nonetheless, these LLMs present many challenges, particularly in the realm of trustworthiness. Therefore, ensuring the trustworthiness of LLMs emerges as an important topic. This paper introduces TrustLLM, a comprehensive study of trustworthiness in LLMs, including principles for different dimensions of trustworthiness, established benchmark, evaluation, and analysis of trustworthiness for mainstream LLMs, and discussion of open challenges and future directions. Specifically, we first propose a set of principles for trustworthy LLMs that span eight different dimensions. Based on these principles, we further establish a benchmark across six dimensions including truthfulness, safety, fairness, robustness, privacy, and machine ethics. We then present a study evaluating 16 mainstream LLMs in TrustLLM, consisting of over 30 datasets. Our find
    
[^3]: 推理步长对大型语言模型的影响

    The Impact of Reasoning Step Length on Large Language Models. (arXiv:2401.04925v1 [cs.CL])

    [http://arxiv.org/abs/2401.04925](http://arxiv.org/abs/2401.04925)

    本研究探讨了推理步长对大型语言模型的影响，并发现在提示中增加推理步骤能显著提高模型的推理能力，而减少推理步骤则会降低模型的推理能力。

    

    思维链条（CoT）对于提高大型语言模型（LLM）的推理能力具有重要作用。然而，CoT的有效性与提示中推理步骤的长度之间的关系仍然不为人所知。为了揭示这一点，我们进行了几个实证实验来探索这些关系。具体而言，我们设计了一些实验，扩展和压缩CoT演示中的合理推理步骤，同时保持其他因素不变。我们得出了以下主要发现。首先，结果表明，在提示中延长推理步骤，即使没有向提示中添加新信息，也会显著提高LLM在多个数据集上的推理能力。相反，缩短推理步骤，即使保留关键信息，也会显著降低模型的推理能力。这一发现突显了CoT提示中步骤数量的重要性，并提供了实际指导。

    Chain of Thought (CoT) is significant in improving the reasoning abilities of large language models (LLMs). However, the correlation between the effectiveness of CoT and the length of reasoning steps in prompts remains largely unknown. To shed light on this, we have conducted several empirical experiments to explore the relations. Specifically, we design experiments that expand and compress the rationale reasoning steps within CoT demonstrations, while keeping all other factors constant. We have the following key findings. First, the results indicate that lengthening the reasoning steps in prompts, even without adding new information into the prompt, considerably enhances LLMs' reasoning abilities across multiple datasets. Alternatively, shortening the reasoning steps, even while preserving the key information, significantly diminishes the reasoning abilities of models. This finding highlights the importance of the number of steps in CoT prompts and provides practical guidance to make 
    
[^4]: Lightning Attention-2:在大型语言模型中处理无限序列长度的"免费午餐"

    Lightning Attention-2: A Free Lunch for Handling Unlimited Sequence Lengths in Large Language Models. (arXiv:2401.04658v1 [cs.CL])

    [http://arxiv.org/abs/2401.04658](http://arxiv.org/abs/2401.04658)

    本文介绍了Lightning Attention-2，这是第一个能够实现线性注意力理论计算优势的线性注意力实现。通过利用平铺的思想，分别处理了线性注意力计算中的内部块和外部块组件。具体来说，采用传统的注意力计算机制处理内部块，并使用新的累积求和方法处理外部块。

    

    线性注意力是一种高效的注意力机制，最近被认为是传统softmax注意力的一种有前景的替代方法。线性注意力理论上能够在线性的计算复杂度下处理无限长度的序列，而不会牺牲速度，即在固定的内存消耗下，能够以恒定的训练速度处理不同长度的序列。然而，由于累积求和（cumsum）的问题，当前的线性注意力算法无法在因果设置下展现其理论优势。本文提出了Lightning Attention-2，这是第一个能够实现线性注意力理论计算优势的线性注意力实现。为了实现这一点，我们利用了平铺（tiling）的思想，分别处理了线性注意力计算中的内部块和外部块组件。具体来说，我们利用传统的注意力计算机制来处理内部块，然后使用一种新的累积求和的方法来处理外部块。

    Linear attention is an efficient attention mechanism that has recently emerged as a promising alternative to conventional softmax attention. With its ability to process tokens in linear computational complexities, linear attention, in theory, can handle sequences of unlimited length without sacrificing speed, i.e., maintaining a constant training speed for various sequence lengths with a fixed memory consumption. However, due to the issue with cumulative summation (cumsum), current linear attention algorithms cannot demonstrate their theoretical advantage in a causal setting. In this paper, we present Lightning Attention-2, the first linear attention implementation that enables linear attention to realize its theoretical computational benefits. To achieve this, we leverage the thought of tiling, separately handling the intra-block and inter-block components in linear attention calculation. Specifically, we utilize the conventional attention computation mechanism for the intra-blocks an
    
[^5]: 一种基于内容的学术论文新颖性度量方法：一个概念验证

    A Content-Based Novelty Measure for Scholarly Publications: A Proof of Concept. (arXiv:2401.03642v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.03642](http://arxiv.org/abs/2401.03642)

    本论文引入了一种基于信息论的学术论文新颖性度量方法，该方法通过量化语言模型感知的"惊喜"程度，结合了面向科学常识和领域专家评估，具有可解释性、细粒度和易用性。

    

    新颖性，类似于进化中的基因突变，为学术进步开辟了新的可能性。尽管同行评审仍然是评估学术交流和资源分配中新颖性的黄金标准，但庞大的投稿量需要自动化的学术新颖性度量方法。我们采用将新颖性视为现有知识的非典型组合的观点，引入了一种基于信息论的学术论文新颖性度量方法。该度量方法量化了表示学术讨论的词分布的语言模型所感知的“惊喜”程度。所提出的度量方法伴随着面向科学常识的外观和构造有效性证据；前者展示了与科学常识的一致性，后者通过与领域专家小组的新颖性评估相一致。此外，这种度量方法具有可解释性、细粒度和易用性的特点，弥补了普遍存在的差距。

    Novelty, akin to gene mutation in evolution, opens possibilities for scholarly advancement. Although peer review remains the gold standard for evaluating novelty in scholarly communication and resource allocation, the vast volume of submissions necessitates an automated measure of scholarly novelty. Adopting a perspective that views novelty as the atypical combination of existing knowledge, we introduce an information-theoretic measure of novelty in scholarly publications. This measure quantifies the degree of 'surprise' perceived by a language model that represents the word distribution of scholarly discourse. The proposed measure is accompanied by face and construct validity evidence; the former demonstrates correspondence to scientific common sense, and the latter is endorsed through alignment with novelty evaluations from a select panel of domain experts. Additionally, characterized by its interpretability, fine granularity, and accessibility, this measure addresses gaps prevalent 
    
[^6]: 你的预训练模型有改进吗？一种基于多头后验的方法

    Has Your Pretrained Model Improved? A Multi-head Posterior Based Approach. (arXiv:2401.02987v1 [cs.CL])

    [http://arxiv.org/abs/2401.02987](http://arxiv.org/abs/2401.02987)

    本研究提出一种基于多头后验的方法，通过利用实体的元特征和模型的表示之间的一致性作为度量标准，有效评估预训练模型在各个领域的表现。

    

    预训练模型的出现对自然语言处理（NLP）、计算机视觉和关系型数据集等领域产生了显著影响。传统上，这些模型通过下游任务进行评估。然而，这引发了如何更高效、更有效地评估这些模型的问题。在本研究中，我们探索了一种新颖的方法，即利用与每个实体相关的元特征作为世界知识的来源，并利用模型的实体表示。我们提出使用这些表示和元特征之间的一致性作为评估预训练模型的度量标准。我们的方法在各个领域表现出了有效性，包括具有关系型数据集、大型语言模型和图像模型的模型。

    The emergence of pretrained models has significantly impacted from Natural Language Processing (NLP) and Computer Vision to relational datasets. Traditionally, these models are assessed through fine-tuned downstream tasks. However, this raises the question of how to evaluate these models more efficiently and more effectively. In this study, we explore a novel approach where we leverage the meta features associated with each entity as a source of worldly knowledge and employ entity representations from the models. We propose using the consistency between these representations and the meta features as a metric for evaluating pretrained models. Our method's effectiveness is demonstrated across various domains, including models with relational datasets, large language models and images models.
    
[^7]: 超越提取：为语言模型提供上下文化的表格数据以实现高效摘要

    Beyond Extraction: Contextualising Tabular Data for Efficient Summarisation by Language Models. (arXiv:2401.02333v1 [cs.LG])

    [http://arxiv.org/abs/2401.02333](http://arxiv.org/abs/2401.02333)

    本研究提出了一种创新的方法，通过上下文化表格数据来提高 RAG 系统中处理复杂表格查询的准确性，提高了摘要的效率。

    

    传统的检索增强生成 (RAG) 架构在从各种文件中检索信息方面已被证明是有效的。然而，在处理包含复杂表格结构的 PDF 文档中的复杂表格查询时会遇到挑战。本研究引入了一种创新的方法来提高 RAG 系统中复杂表格查询的准确性。我们的方法涉及将 PDF 存储在检索数据库中，并单独提取表格内容。提取的表格经过上下文丰富的处理，将标题与相应的值连接起来。为了确保对丰富数据的全面理解，我们使用经过微调的 Llama-2-chat 语言模型在 RAG 架构中进行摘要。此外，我们通过一次性提示使用 ChatGPT 3.5 API 增强表格数据的上下文含义。然后，将这些丰富的数据与其他 PDF 文件一起输入检索数据库。

    The conventional use of the Retrieval-Augmented Generation (RAG) architecture has proven effective for retrieving information from diverse documents. However, challenges arise in handling complex table queries, especially within PDF documents containing intricate tabular structures.This research introduces an innovative approach to enhance the accuracy of complex table queries in RAG-based systems. Our methodology involves storing PDFs in the retrieval database and extracting tabular content separately. The extracted tables undergo a process of context enrichment, concatenating headers with corresponding values. To ensure a comprehensive understanding of the enriched data, we employ a fine-tuned version of the Llama-2-chat language model for summarisation within the RAG architecture. Furthermore, we augment the tabular data with contextual sense using the ChatGPT 3.5 API through a one-shot prompt. This enriched data is then fed into the retrieval database alongside other PDFs. Our appr
    
[^8]: LLaVA-$\phi$: 高效的多模态助手与小型语言模型

    LLaVA-$\phi$: Efficient Multi-Modal Assistant with Small Language Model. (arXiv:2401.02330v1 [cs.CV])

    [http://arxiv.org/abs/2401.02330](http://arxiv.org/abs/2401.02330)

    LLaVA-$\phi$是一种高效的多模态助手，使用小型语言模型Phi-2来促进多模态对话。即使具有较少的参数，它也能有效地融合文本和视觉元素，并在各种任务中表现出色。它为时间敏感的环境和需要实时交互的系统开辟了新的应用途径。

    

    在本文中，我们介绍了LLaVA-$\phi$（LLaVA-Phi），一种利用最近先进的小型语言模型Phi-2来促进多模态对话的高效多模态助手。LLaVA-Phi在紧凑的多模态模型领域中标志着重要进展。它证明了即使是个参数只有27亿的较小语言模型在训练有高质量语料库的情况下也可以有效地参与融合文本和视觉元素的复杂对话。我们的模型在包括视觉理解、推理和基于知识的感知等公开可用的基准测试中表现出色。除了在多模态对话任务中表现出卓越性能外，我们的模型为时间敏感的环境和需要实时交互的系统（如实体代理）开辟了新的应用途径。它突显了较小语言模型实现高级理解和交互的潜力。

    In this paper, we introduce LLaVA-$\phi$ (LLaVA-Phi), an efficient multi-modal assistant that harnesses the power of the recently advanced small language model, Phi-2, to facilitate multi-modal dialogues. LLaVA-Phi marks a notable advancement in the realm of compact multi-modal models. It demonstrates that even smaller language models, with as few as 2.7B parameters, can effectively engage in intricate dialogues that integrate both textual and visual elements, provided they are trained with high-quality corpora. Our model delivers commendable performance on publicly available benchmarks that encompass visual comprehension, reasoning, and knowledge-based perception. Beyond its remarkable performance in multi-modal dialogue tasks, our model opens new avenues for applications in time-sensitive environments and systems that require real-time interaction, such as embodied agents. It highlights the potential of smaller language models to achieve sophisticated levels of understanding and inte
    
[^9]: WordArt设计师API：利用模型范围上的大型语言模型进行用户驱动的艺术字体合成

    WordArt Designer API: User-Driven Artistic Typography Synthesis with Large Language Models on ModelScope. (arXiv:2401.01699v1 [cs.CV])

    [http://arxiv.org/abs/2401.01699](http://arxiv.org/abs/2401.01699)

    本文介绍了WordArt设计师API，它利用大型语言模型在模型范围上进行用户驱动的艺术字体合成。通过提供动态、自适应和高效的替代方案，该方法能够满足非专业人士简化艺术字体的需求，并实现了更直观的设计过程。与现有系统相比，该API显著提高了用户满意度、设计灵活性和创造性表达，并为个性化数字通信和设计开辟了新的可能性。

    

    本文介绍了WordArt设计师API，这是一个利用模型范围上的大型语言模型进行用户驱动的艺术字体合成的新框架。我们通过提供动态、自适应和计算效果高的替代传统刚性模板的方案，解决了非专业人士简化艺术字体的挑战。我们的方法利用LLMs的能力来理解和解释用户输入，促进更直观的设计过程。通过各种案例研究，我们展示了用户如何表达他们的审美偏好和功能需求，系统然后将其转化为独特且富有创意的字体设计。我们的评估结果表明，与现有系统相比，用户满意度、设计灵活性和创造性表达都有显著改进。WordArt设计师API不仅使字体艺术民主化，还为个性化数字通信和设计打开了新的可能性。

    This paper introduces the WordArt Designer API, a novel framework for user-driven artistic typography synthesis utilizing Large Language Models (LLMs) on ModelScope. We address the challenge of simplifying artistic typography for non-professionals by offering a dynamic, adaptive, and computationally efficient alternative to traditional rigid templates. Our approach leverages the power of LLMs to understand and interpret user input, facilitating a more intuitive design process. We demonstrate through various case studies how users can articulate their aesthetic preferences and functional requirements, which the system then translates into unique and creative typographic designs. Our evaluations indicate significant improvements in user satisfaction, design flexibility, and creative expression over existing systems. The WordArt Designer API not only democratizes the art of typography but also opens up new possibilities for personalized digital communication and design.
    
[^10]: 一种用于联合实体和关系抽取的自回归文本到图框架

    An Autoregressive Text-to-Graph Framework for Joint Entity and Relation Extraction. (arXiv:2401.01326v1 [cs.CL])

    [http://arxiv.org/abs/2401.01326](http://arxiv.org/abs/2401.01326)

    这篇论文提出了一种新颖的方法，通过将联合实体和关系抽取问题作为条件序列生成问题来解决。该方法使用了基于跨度的图生成方式，并通过指向机制将生成的输出与原始文本对齐。评估结果证明了该方法的有效性，并获得了竞争性的结果。

    

    本文提出了一种新颖的方法，将非结构化文本中的联合实体和关系抽取问题作为条件序列生成问题来解决。与传统的生成式信息抽取模型不同，我们的方法是基于跨度的，它生成一个线性化的图，其中节点表示文本跨度，边表示关系三元组。我们的方法采用了一个具有指向机制的转换器编码器-解码器架构，使用一个动态词汇表来表示跨度和关系类型。我们的模型能够通过跨度表示捕捉实体和关系的结构特征和边界，同时通过指向机制将生成的输出与原始文本进行对齐。在基准数据集上的评估验证了我们方法的有效性，展示了竞争性的结果。代码可在https://github.com/urchade/ATG找到。

    In this paper, we propose a novel method for joint entity and relation extraction from unstructured text by framing it as a conditional sequence generation problem. In contrast to conventional generative information extraction models that are left-to-right token-level generators, our approach is \textit{span-based}. It generates a linearized graph where nodes represent text spans and edges represent relation triplets. Our method employs a transformer encoder-decoder architecture with pointing mechanism on a dynamic vocabulary of spans and relation types. Our model can capture the structural characteristics and boundaries of entities and relations through span representations while simultaneously grounding the generated output in the original text thanks to the pointing mechanism. Evaluation on benchmark datasets validates the effectiveness of our approach, demonstrating competitive results. Code is available at https://github.com/urchade/ATG.
    
[^11]: ToolEyes：大型语言模型在实际情景中的工具学习能力的细粒度评估

    ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios. (arXiv:2401.00741v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.00741](http://arxiv.org/abs/2401.00741)

    ToolEyes是一个专门用于评估大型语言模型在真实情景中的工具学习能力的细粒度系统，通过对七个真实情景的详细分析，评估了LLMs在工具学习的五个关键维度，并提供了一个拥有600种工具的工具库作为中介。

    

    现有的工具学习评估主要集中于验证大型语言模型（LLMs）选择的工具与期望结果的一致性。然而，这些方法依赖于一组有限的情景，在这些情景中答案可以事先确定，与真实需求背道而驰。此外，仅关注结果忽视了LLMs有效利用工具所需的复杂能力。为解决这个问题，我们提出了ToolEyes，这是一个特别针对LLMs工具学习能力在真实情景中评估的细粒度系统。该系统详细分析了七个真实情景，分析了对LLMs在工具学习中至关重要的五个维度：格式对齐，意图理解，行为规划，工具选择和答案组织。此外，ToolEyes还包含一个拥有约600种工具的工具库，作为LLMs与物理世界之间的中介。在涉及三个类别的十个LLMs的评估中，ToolEyes取得了如下的创新与贡献。

    Existing evaluations of tool learning primarily focus on validating the alignment of selected tools for large language models (LLMs) with expected outcomes. However, these approaches rely on a limited set of scenarios where answers can be pre-determined, diverging from genuine needs. Furthermore, a sole emphasis on outcomes disregards the intricate capabilities essential for LLMs to effectively utilize tools. To tackle this issue, we propose ToolEyes, a fine-grained system tailored for the evaluation of the LLMs' tool learning capabilities in authentic scenarios. The system meticulously examines seven real-world scenarios, analyzing five dimensions crucial to LLMs in tool learning: format alignment, intent comprehension, behavior planning, tool selection, and answer organization. Additionally, ToolEyes incorporates a tool library boasting approximately 600 tools, serving as an intermediary between LLMs and the physical world. Evaluations involving ten LLMs across three categories revea
    
[^12]: 通过对比置信度正则化来减轻密集检索中的假阴性影响

    Mitigating the Impact of False Negatives in Dense Retrieval with Contrastive Confidence Regularization. (arXiv:2401.00165v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.00165](http://arxiv.org/abs/2401.00165)

    该论文提出了一种用于减轻密集检索中假阴性影响的对比置信度正则化方法，通过改进对比学习的硬负例采样问题，使得密集检索模型更加稳健。

    

    在开放域问答中，密集检索对于找到相关段落以生成答案至关重要。通常，对比学习用于训练一个将段落和查询映射到相同语义空间的检索模型。其目标是使相似的更加接近，不相似的更加远离。然而，由于虚假阴性问题，训练这样的系统是具有挑战性的，即在数据注释过程中可能会错过相关段落。通常用于改进对比学习的硬负例采样可能会在训练中引入更多噪声。这是因为硬负例是那些靠近给定查询的样本，因此更有可能是虚假阴性。为了解决这个问题，我们提出了一种新颖的对比置信度正则化器，用于密集检索常用的噪声对比估计（NCE）损失。我们的分析表明，该正则化器能够帮助密集检索模型更加稳健地应对虚假阴性，并具有理论保证。

    In open-domain Question Answering (QA), dense retrieval is crucial for finding relevant passages for answer generation. Typically, contrastive learning is used to train a retrieval model that maps passages and queries to the same semantic space. The objective is to make similar ones closer and dissimilar ones further apart. However, training such a system is challenging due to the false negative issue, where relevant passages may be missed during data annotation. Hard negative sampling, which is commonly used to improve contrastive learning, can introduce more noise in training. This is because hard negatives are those closer to a given query, and thus more likely to be false negatives. To address this issue, we propose a novel contrastive confidence regularizer for Noise Contrastive Estimation (NCE) loss, a commonly used loss for dense retrieval. Our analysis shows that the regularizer helps dense retrieval models be more robust against false negatives with a theoretical guarantee. Ad
    
[^13]: MosaicBERT：一种针对快速预训练进行优化的双向编码器

    MosaicBERT: A Bidirectional Encoder Optimized for Fast Pretraining. (arXiv:2312.17482v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.17482](http://arxiv.org/abs/2312.17482)

    MosaicBERT是一种优化的BERT风格双向编码器，通过引入多项创新技术和优化方案，实现了快速预训练。

    

    尽管BERT风格的编码器模型在NLP研究中广泛使用，但由于训练成本高昂，许多研究人员不会从头开始预训练自己的BERT。在BERT首次崭露头角的过去半-decade，已经对其他变压器架构和训练配置进行了许多进展，但尚未系统地纳入BERT中。在这里，我们引入了MosaicBERT，一种经验优化用于快速预训练的BERT风格编码器架构和训练方法。这种高效的架构将FlashAttention、带有线性偏差的Attention (ALiBi)、门控线性单元 (GLU)、动态移除填充令牌的模块和低精度LayerNorm等引入了经典的变压器编码器块。训练方法还包括30%的掩码比率用于遮蔽语言建模 (MLM) 目标，bfloat16精度，以及针对GPU吞吐量进行优化的词汇大小，此外还采用了RoBERTa和其他编码器模型的最佳实践。

    Although BERT-style encoder models are heavily used in NLP research, many researchers do not pretrain their own BERTs from scratch due to the high cost of training. In the past half-decade since BERT first rose to prominence, many advances have been made with other transformer architectures and training configurations that have yet to be systematically incorporated into BERT. Here, we introduce MosaicBERT, a BERT-style encoder architecture and training recipe that is empirically optimized for fast pretraining. This efficient architecture incorporates FlashAttention, Attention with Linear Biases (ALiBi), Gated Linear Units (GLU), a module to dynamically remove padded tokens, and low precision LayerNorm into the classic transformer encoder block. The training recipe includes a 30% masking ratio for the Masked Language Modeling (MLM) objective, bfloat16 precision, and vocabulary size optimized for GPU throughput, in addition to best-practices from RoBERTa and other encoder models. When pr
    
[^14]: 通过多视角解耦学习改进低资源的基于提示的关系表示

    Improving Low-resource Prompt-based Relation Representation with Multi-view Decoupling Learning. (arXiv:2312.17267v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.17267](http://arxiv.org/abs/2312.17267)

    提出了一种名为MVRE的新方法，通过将关系解耦为不同的视角，生成多视角关系表示，并利用预训练语言模型（PLMs）的能力来提高低资源关系抽取任务的性能。

    

    最近，使用预训练语言模型（PLMs）进行提示调整已经展示出了显著的关系抽取（RE）任务的增强能力。然而，在低资源场景中，即训练数据有限的情况下，由于对关系的表层理解，先前基于提示的方法可能仍然表现不佳，用于表示学习。为此，我们强调在低资源场景中学习高质量关系表示对于RE的重要性，并提出了一种新的基于提示的关系表示方法，名为MVRE（多视角关系抽取），以更好地利用PLMs的能力来改善低资源提示调整范式下的RE性能。具体而言，MVRE将每个关系解耦为不同的视角，以包含多视角的关系表示，以最大化关系推断过程中的似然性。此外，我们还设计了一个全局性的低领域任务学习策略，以进一步提高关系表示的质量。

    Recently, prompt-tuning with pre-trained language models (PLMs) has demonstrated the significantly enhancing ability of relation extraction (RE) tasks. However, in low-resource scenarios, where the available training data is scarce, previous prompt-based methods may still perform poorly for prompt-based representation learning due to a superficial understanding of the relation. To this end, we highlight the importance of learning high-quality relation representation in low-resource scenarios for RE, and propose a novel prompt-based relation representation method, named MVRE (\underline{M}ulti-\underline{V}iew \underline{R}elation \underline{E}xtraction), to better leverage the capacity of PLMs to improve the performance of RE within the low-resource prompt-tuning paradigm. Specifically, MVRE decouples each relation into different perspectives to encompass multi-view relation representations for maximizing the likelihood during relation inference. Furthermore, we also design a Global-Lo
    
[^15]: T-Eval: 逐步评估工具利用能力

    T-Eval: Evaluating the Tool Utilization Capability Step by Step. (arXiv:2312.14033v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.14033](http://arxiv.org/abs/2312.14033)

    T-Eval是一种逐步评估工具利用能力的方法，它将工具利用评估解耦为多个子领域，从而能够更细致地分析大型语言模型（LLM）的能力。

    

    大型语言模型（LLM）在各种NLP任务上取得了卓越的性能，并通过工具进行了更广泛的应用。然而，如何评估和分析LLM的工具利用能力仍未充分探索。与以往评估模型整体性能的工作不同，我们将工具利用全面分解为多个子过程，包括指令跟随、规划、推理、检索、理解和复查。在此基础上，我们进一步引入了T-Eval来逐步评估工具利用能力。T-Eval将工具利用评估解耦为多个子领域，有助于对LLM的整体和独立能力进行内部理解。我们对T-Eval进行了大量实验和各种LLM的深入分析。T-Eval不仅展现了与结果导向评估的一致性，还提供了对LLM能力更细致的分析，表明LLM具备了一定的能力。

    Large language models (LLM) have achieved remarkable performance on various NLP tasks and are augmented by tools for broader applications. Yet, how to evaluate and analyze the tool-utilization capability of LLMs is still under-explored. In contrast to previous works that evaluate models holistically, we comprehensively decompose the tool utilization into multiple sub-processes, including instruction following, planning, reasoning, retrieval, understanding, and review. Based on that, we further introduce T-Eval to evaluate the tool utilization capability step by step. T-Eval disentangles the tool utilization evaluation into several sub-domains along model capabilities, facilitating the inner understanding of both holistic and isolated competency of LLMs. We conduct extensive experiments on T-Eval and in-depth analysis of various LLMs. T-Eval not only exhibits consistency with the outcome-oriented evaluation but also provides a more fine-grained analysis of the capabilities of LLMs, prov
    
[^16]: 使用对比置信度调整的知识图谱错误检测

    Knowledge Graph Error Detection with Contrastive Confidence Adaption. (arXiv:2312.12108v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.12108](http://arxiv.org/abs/2312.12108)

    本文提出了一种使用对比学习和交互式对比学习的知识图谱错误检测模型CCA，通过综合文本和图结构信息，更好地区分语义，从而在检测噪声方面优于当前最先进的方法。

    

    知识图谱（KGs）中常常包含各种错误。以往关于KG错误检测的研究主要依赖于从图结构中嵌入的三元组。我们进行了实证研究发现，这些方法在区分噪声和语义相似的正确三元组方面存在困难。本文提出了一种KG错误检测模型CCA，通过从三元组重构中综合文本和图结构信息，更好地区分语义。我们设计了交互式对比学习来捕捉文本和结构模式之间的差异。此外，我们构建了具有语义相似噪声和对抗性噪声的实际数据集。实验结果表明，CCA在检测语义相似噪声和对抗性噪声方面优于当前最先进的基线方法。

    Knowledge graphs (KGs) often contain various errors. Previous works on detecting errors in KGs mainly rely on triplet embedding from graph structure. We conduct an empirical study and find that these works struggle to discriminate noise from semantically-similar correct triplets. In this paper, we propose a KG error detection model CCA to integrate both textual and graph structural information from triplet reconstruction for better distinguishing semantics. We design interactive contrastive learning to capture the differences between textual and structural patterns. Furthermore, we construct realistic datasets with semantically-similar noise and adversarial noise. Experimental results demonstrate that CCA outperforms state-of-the-art baselines, especially in detecting semantically-similar noise and adversarial noise.
    
[^17]: "原文改写"提高了高精度长文本问答的效果

    "Paraphrasing The Original Text" Makes High Accuracy Long-Context QA. (arXiv:2312.11193v6 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.11193](http://arxiv.org/abs/2312.11193)

    本论文提出了一种名为"原文改写"的任务来处理长文本问答，通过低成本高效的方法成功扩展了现有模型的上下文窗口至32k，并在多文档问答中达到了最先进的准确性。

    

    当面对长文本时，大多数开源生成式语言模型的上下文窗口限制在4k以内，这限制了它们的能力。即使是具有更长上下文窗口的模型也无法在长上下文问题上保证令人满意的准确性。为了解决这个问题，我们从训练数据的角度出发，从理论上证明了提高处理长上下文能力需要的是"有效"而不仅仅是"长"的数据。基于这个洞见，我们提出了使用"原文改写"任务，并通过一种低成本高效的方法，成功将现有模型的上下文窗口扩展到32k。我们的微调模型在具有相近规模的模型中在多文档问答方面达到了最先进的准确性。模型和训练数据已经在HuggingFace（https://huggingface.co/yuyijiong/Qwen-14b-chat-yarn-32k）和WiseModel（https://wisemodel.cn/models/yuyijiong/Qwen-14b-chat-yarn-32k）上提供。

    Most open-source generative language models currently have a context window of no more than 4k, limiting their ability when facing long text. Even models with longer context windows cannot guarantee satisfactory accuracy on long-context problems. To tackle this issue, we explore from the perspective of training data and theoretically demonstrate that improving the capability to handle long contexts requires "effective" rather than simply "long" data. Based on this insight, we propose using the "original text paraphrasing" task and successfully extend the context window of existing models to 32k through a low-cost and effective method. Our fine-tuned model achieves state-of-the-art accuracy in multi-document-QA among models of comparable scale. The model and training data have been made available on HuggingFace(https://huggingface.co/yuyijiong/Qwen-14b-chat-yarn-32k) and WiseModel(https://wisemodel.cn/models/yuyijiong/Qwen-14b-chat-yarn-32k).
    
[^18]: 知识图谱增强的方面级情感分析

    Knowledge Graph Enhanced Aspect-Level Sentiment Analysis. (arXiv:2312.10048v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.10048](http://arxiv.org/abs/2312.10048)

    本文提出了一种知识图谱增强的方面级情感分析方法，通过使用BERT模型和知识图谱的同义词数据，在解决上下文特定词义的挑战上取得了优越的性能。

    

    本文提出了一种新颖的方法，通过解决上下文特定词义的挑战，增强情感分析。它将BERT模型的优势与基于知识图谱的同义词数据相结合。这种协同作用利用动态注意机制来构建一个知识驱动的状态向量。为了对特定方面链接的情感进行分类，该方法构建了一个集成了位置数据的记忆库。然后使用DCGRU分析数据，以确定与特定方面术语相关的情感特征。在三个广泛使用的数据集上的实验表明，我们的方法在情感分类中具有卓越的性能。

    In this paper, we propose a novel method to enhance sentiment analysis by addressing the challenge of context-specific word meanings. It combines the advantages of a BERT model with a knowledge graph based synonym data. This synergy leverages a dynamic attention mechanism to develop a knowledge-driven state vector. For classifying sentiments linked to specific aspects, the approach constructs a memory bank integrating positional data. The data are then analyzed using a DCGRU to pinpoint sentiment characteristics related to specific aspect terms. Experiments on three widely used datasets demonstrate the superior performance of our method in sentiment classification.
    
[^19]: 降低语言模型低精度微调中的异常激活

    Mitigating Outlier Activations in Low-Precision Fine-Tuning of Language Models. (arXiv:2312.09211v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.09211](http://arxiv.org/abs/2312.09211)

    本论文研究了在语言模型低精度微调中减少异常激活的技术，提出了一种能够用8位整数表示异常激活值的新方法，通过使用整数和运算符切片来提高效率和性能。

    

    低精度微调语言模型已成为一种成本效益高且能源高效的方法，在各种应用中部署大规模模型。然而，这种方法容易受到激活中异常值的影响。激活中的异常值会对低精度微调语言模型的性能产生负面影响，因为它们影响了缩放因子，使得表示较小的值变得更困难。本文研究了在语言模型低精度整数微调中减少异常激活的技术。我们提出的新方法使我们能够用8位整数而不是浮点（FP16）值表示异常激活值。使用整数来表示异常值的好处是，它使我们能够使用运算符切片来避免执行16位整数矩阵乘法，从而有效解决这个问题。我们提供了理论分析和支持实验。

    Low-precision fine-tuning of language models has gained prominence as a cost-effective and energy-efficient approach to deploying large-scale models in various applications. However, this approach is susceptible to the existence of outlier values in activation. The outlier values in the activation can negatively affect the performance of fine-tuning language models in the low-precision regime since they affect the scaling factor and thus make representing smaller values harder. This paper investigates techniques for mitigating outlier activation in low-precision integer fine-tuning of the language models. Our proposed novel approach enables us to represent the outlier activation values in 8-bit integers instead of floating-point (FP16) values. The benefit of using integers for outlier values is that it enables us to use operator tiling to avoid performing 16-bit integer matrix multiplication to address this problem effectively. We provide theoretical analysis and supporting experiments
    
[^20]: 工程设计知识的语言和结构基础

    Linguistic and Structural Basis of Engineering Design Knowledge. (arXiv:2312.06355v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.06355](http://arxiv.org/abs/2312.06355)

    本文通过分析33881份专利文件的样本，将工程设计知识阐释为知识图谱，从而揭示工程设计知识的语言和结构基础。

    

    物品描述是工程设计知识的主要载体，既是设计过程的产物，也是驱动设计过程的因素。尽管物品可以以不同的内涵进行描述，但设计过程需要一种描述来体现工程设计知识，这通过实体和关系的复杂安排在文本中表现出来。虽然大型语言模型可以从各种文本中学习，但它们尚未生成体现明确的工程设计事实的文本。现有的本体论设计理论很少能指导目前仅限于构思和学习目的的大型语言模型的应用。本文从33881份专利文件的大样本中将工程设计知识阐释为知识图谱。我们研究这些知识图谱的组成部分，以理解工程设计知识的语言和结构基础。

    Artefact descriptions are the primary carriers of engineering design knowledge that is both an outcome and a driver of the design process. While an artefact could be described in different connotations, the design process requires a description to embody engineering design knowledge, which is expressed in the text through intricate placement of entities and relationships. As large-language models learn from all kinds of text merely as a sequence of characters/tokens, these are yet to generate text that embodies explicit engineering design facts. Existing ontological design theories are less likely to guide the large-language models whose applications are currently limited to ideation and learning purposes. In this article, we explicate engineering design knowledge as knowledge graphs from a large sample of 33,881 patent documents. We examine the constituents of these knowledge graphs to understand the linguistic and structural basis of engineering design knowledge. In terms of linguist
    
[^21]: CLadder: 评估语言模型因果推理能力的基准测试

    CLadder: A Benchmark to Assess Causal Reasoning Capabilities of Language Models. (arXiv:2312.04350v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.04350](http://arxiv.org/abs/2312.04350)

    该论文提出了一个新的NLP任务，评估语言模型在因果推理方面的能力。作者构建了一个大规模的数据集CLadder，并利用oracle因果推理引擎将符号问题转化为自然语言。研究结果表明多个LLMs在该数据集上的表现，并引入并评估了一种定制的链式推理机制。

    

    进行因果推理的能力被广泛视为智能的核心特征。本文研究了大型语言模型(LLMs)能否连贯地推理因果关系。现有的自然语言处理(NLP)工作主要关注评估LLMs中的常识因果推理，未能评估模型是否能够按照一组明确定义的形式规则执行因果推断。为了解决这个问题，我们提出了一个新的NLP任务，自然语言中的因果推断，受到Judea Pearl等人提出的“因果推断引擎”的启发。我们构建了一个包含10K个样本的大型数据集CLadder，通过一种oracle因果推理引擎，基于一组因果图和查询(联合、干预和反事实)，得到符号问题和真实答案，并将其翻译为自然语言。我们对数据集上的多个LLMs进行评估，并引入和评估了一种定制的链式推理机制。

    The ability to perform causal reasoning is widely considered a core feature of intelligence. In this work, we investigate whether large language models (LLMs) can coherently reason about causality. Much of the existing work in natural language processing (NLP) focuses on evaluating commonsense causal reasoning in LLMs, thus failing to assess whether a model can perform causal inference in accordance with a set of well-defined formal rules. To address this, we propose a new NLP task, causal inference in natural language, inspired by the "causal inference engine" postulated by Judea Pearl et al. We compose a large dataset, CLadder, with 10K samples: based on a collection of causal graphs and queries (associational, interventional, and counterfactual), we obtain symbolic questions and ground-truth answers, through an oracle causal inference engine. These are then translated into natural language. We evaluate multiple LLMs on our dataset, and we introduce and evaluate a bespoke chain-of-th
    
[^22]: ChatGPT一周年纪念：开源大型语言模型是否在赶上了？

    ChatGPT's One-year Anniversary: Are Open-Source Large Language Models Catching up?. (arXiv:2311.16989v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.16989](http://arxiv.org/abs/2311.16989)

    ChatGPT一周年纪念，调查了开源大型语言模型是否赶上了封闭源代码模型的进展，尽管后者仍然优于前者，但开源模型在某些任务上已经达到了相同甚至更好的性能。

    

    ChatGPT于2022年底发布后，带来了人工智能领域研究和商业领域的巨大转变。通过使用有监督微调和人类反馈的强化学习来调整大型语言模型(LLM)的指令，它展示了模型可以回答人类问题并遵循广泛任务面板上的指令。在这一成功之后，对于LLMs的兴趣持续增加，包括学术界和工业界中频繁涌现的新型LLMs，其中包括许多专注于LLMs的初创企业。尽管封闭源代码的LLMs（如OpenAI的GPT、Anthropic的Claude）通常在性能上优于开源对应物，但后者的进展迅速，声称在某些任务上实现了或甚至更好的性能。这不仅对研究，还对业务领域具有重要影响。在ChatGPT一周年之际，我们提供了这一成功的详尽概述，并调查了所有开源LLM声称已经实现了的任务。

    Upon its release in late 2022, ChatGPT has brought a seismic shift in the entire landscape of AI, both in research and commerce. Through instruction-tuning a large language model (LLM) with supervised fine-tuning and reinforcement learning from human feedback, it showed that a model could answer human questions and follow instructions on a broad panel of tasks. Following this success, interests in LLMs have intensified, with new LLMs flourishing at frequent interval across academia and industry, including many start-ups focused on LLMs. While closed-source LLMs (e.g., OpenAI's GPT, Anthropic's Claude) generally outperform their open-source counterparts, the progress on the latter has been rapid with claims of achieving parity or even better on certain tasks. This has crucial implications not only on research but also on business. In this work, on the first anniversary of ChatGPT, we provide an exhaustive overview of this success, surveying all tasks where an open-source LLM has claimed
    
[^23]: 电力系统中动态故障特性评估

    Dynamic Fault Characteristics Evaluation in Power Grid. (arXiv:2311.16522v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2311.16522](http://arxiv.org/abs/2311.16522)

    该论文提出了一种在电力系统中进行故障检测的新方法，通过图神经网络识别故障节点，并利用前后时间段内节点的状态来辅助当前故障检测。实验证明该方法准确可靠，并提供了对故障节点传播的定性分析。

    

    为了增强运维的智能度，提出了一种在电力系统中进行故障检测的新方法。该方法基于图神经网络，通过专门的特征提取方法和知识图谱来识别故障节点。通过引入时间数据，该方法利用前后时间段内节点的状态来辅助当前故障检测。为了验证节点特征的有效性，还进行了每个节点输出特征的相关性分析。实验证明，该方法可以在仿真场景中准确地定位故障节点，并具有显著的准确性。此外，基于图神经网络的特征建模可以定性地考察故障如何在节点间传播，为分析故障节点提供了有价值的见解。

    To enhance the intelligence degree in operation and maintenance, a novel method for fault detection in power grids is proposed. The proposed GNN-based approach first identifies fault nodes through a specialized feature extraction method coupled with a knowledge graph. By incorporating temporal data, the method leverages the status of nodes from preceding and subsequent time periods to help current fault detection. To validate the effectiveness of the node features, a correlation analysis of the output features from each node was conducted. The results from experiments show that this method can accurately locate fault nodes in simulation scenarios with a remarkable accuracy. Additionally, the graph neural network based feature modeling allows for a qualitative examination of how faults spread across nodes, which provides valuable insights for analyzing fault nodes.
    
[^24]: 评估混合深度学习模型在区分AI生成文本方面的有效性

    Evaluating the Efficacy of Hybrid Deep Learning Models in Distinguishing AI-Generated Text. (arXiv:2311.15565v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.15565](http://arxiv.org/abs/2311.15565)

    本研究评估了混合深度学习模型在准确区分AI生成文本和人类写作方面的有效性。通过应用先进的自然语言处理技术和复杂的神经网络，我们的研究成功地检测到了AI生成文本和人类写作之间的微妙差异。

    

    我的研究通过使用先进的混合深度学习模型，来准确区分AI生成的文本与人类写作。我应用了一种稳健的方法论，利用了一个精心选择的数据集，其中包括来自各种来源的AI和人类文本，每个文本都标有指示。先进的自然语言处理技术便于对文本特征进行分析。通过结合复杂的神经网络，这个定制模型使得它能够检测出AI和人类内容之间微妙的差异。

    My research investigates the use of cutting-edge hybrid deep learning models to accurately differentiate between AI-generated text and human writing. I applied a robust methodology, utilising a carefully selected dataset comprising AI and human texts from various sources, each tagged with instructions. Advanced natural language processing techniques facilitated the analysis of textual features. Combining sophisticated neural networks, the custom model enabled it to detect nuanced differences between AI and human content.
    
[^25]: 基于知识图谱的变电站动态故障分析

    Dynamic Fault Analysis in Substations Based on Knowledge Graphs. (arXiv:2311.13708v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.13708](http://arxiv.org/abs/2311.13708)

    提出了一种基于知识图谱的变电站动态故障分析方法，利用非结构化文本提取相关信息，通过隐藏马尔科夫模型训练数据，利用Neo4j图数据库创建知识图谱，实现对变电站中隐藏危险的可视化分析。

    

    为了解决从非结构化文本中识别变电站隐藏危险的挑战，提出了一种新颖的动态分析方法。首先从非结构化文本中提取相关信息，然后利用基于Elastic-Search构建的灵活分布式搜索引擎处理数据。接下来，使用隐藏马尔科夫模型来训练引擎中的数据。维特比算法被整合进来解密隐藏状态序列，便于对与隐藏危险相关的实体进行分割和标注。最后，使用Neo4j图数据库动态创建知识图谱来可视化变电站中的隐藏危险。通过对文本记录中揭示的具体变电站的隐藏危险进行案例分析，证明了所提方法的有效性。

    To address the challenge of identifying hidden danger in substations from unstructured text, a novel dynamic analysis method is proposed. We first extract relevant information from the unstructured text, and then leverages a flexible distributed search engine built on Elastic-Search to handle the data. Following this, the hidden Markov model is employed to train the data within the engine. The Viterbi algorithm is integrated to decipher the hidden state sequences, facilitating the segmentation and labeling of entities related to hidden dangers. The final step involves using the Neo4j graph database to dynamically create a knowledge graph that visualizes hidden dangers in the substation. The effectiveness of the proposed method is demonstrated through a case analysis from a specific substation with hidden dangers revealed in the text records.
    
[^26]: 在设备上实现自我监督数据选择和合成的大规模语言模型个性化

    Enabling On-Device Large Language Model Personalization with Self-Supervised Data Selection and Synthesis. (arXiv:2311.12275v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.12275](http://arxiv.org/abs/2311.12275)

    本文提出了一种在设备上实现自我监督数据选择和合成的大规模语言模型个性化的框架，通过选择和存储最具代表性的数据来解决稀疏注释和有限的设备存储限制。

    

    在将大规模语言模型（LLM）部署在边缘设备上后，希望这些设备能从用户生成的对话数据中学习，以实时生成针对用户的个性化回应。然而，用户生成的数据通常包含敏感和私密信息，而将此类数据上传到云端进行注释并不被推荐，甚至是禁止的。虽然可以通过直接询问用户提供首选回应来在本地获取注释，但这种注释必须稀疏以不影响用户体验。此外，边缘设备的存储通常太有限，无法进行全面的大规模微调。如何在考虑稀疏注释和受限的设备存储条件下实现在设备上的LLM个性化仍然是一个待解决的问题。在本文中，我们提出了一种新的框架，以自我监督的方式在线选择和存储最具代表性的数据。这种数据具有较小的内存占用，并允许很少的存储占用。

    After a large language model (LLM) is deployed on edge devices, it is desirable for these devices to learn from user-generated conversation data to generate user-specific and personalized responses in real-time. However, user-generated data usually contains sensitive and private information, and uploading such data to the cloud for annotation is not preferred if not prohibited. While it is possible to obtain annotation locally by directly asking users to provide preferred responses, such annotations have to be sparse to not affect user experience. In addition, the storage of edge devices is usually too limited to enable large-scale fine-tuning with full user-generated data. It remains an open question how to enable on-device LLM personalization, considering sparse annotation and limited on-device storage. In this paper, we propose a novel framework to select and store the most representative data online in a self-supervised way. Such data has a small memory footprint and allows infrequ
    
[^27]: 用于宣传性跨度注释的大型语言模型

    Large Language Models for Propaganda Span Annotation. (arXiv:2311.09812v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.09812](http://arxiv.org/abs/2311.09812)

    本研究探讨了使用大型语言模型（LLMs）来检测宣传性文本跨度的任务，并研究了利用该模型收集更具成本效益的标注的潜力。

    

    近年来，在线内容中使用宣传手法的情况有所增加，旨在操纵在线受众。针对各种建模场景，已经做出了自动检测和揭露此类内容的努力。这些场景包括确定内容（文本、图像或多模态）是否具有以下特征：（i）具有宣传性，（ii）使用一种或多种宣传手法，以及（iii）包含具有可识别范围的技巧。与前两种场景相比，已经对后一种场景进行了较大的研究工作。因此，本研究关注检测宣传性文本跨度的任务。具体而言，我们研究了大型语言模型（如GPT-4）是否能够有效执行该任务。此外，我们研究了利用该模型收集更具成本效益的标注的潜力。我们的实验使用了一套大规模的内部数据集，其中包含来自具有不同专业水平的人工标注者的注释。结果表明，

    The use of propagandistic techniques in online contents has increased in recent years aiming to manipulate online audiences. Efforts to automatically detect and debunk such content have been made addressing various modeling scenarios. These include determining whether the content (text, image, or multimodal) (i) is propagandistic, (ii) employs one or more propagandistic techniques, and (iii) includes techniques with identifiable spans. Significant research efforts have been devoted to the first two scenarios compared to the latter. Therefore, in this study, we focus on the task of detecting propagandistic textual spans. Specifically, we investigate whether large language models (LLMs), such as GPT-4, can effectively perform the task. Moreover, we study the potential of employing the model to collect more cost-effective annotations. Our experiments use a large-scale in-house dataset consisting of annotations from human annotators with varying expertise levels. The results suggest that p
    
[^28]: 电力分配网络中的知识图谱构建

    Knowledge Graph Construction in Power Distribution Networks. (arXiv:2311.08724v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.08724](http://arxiv.org/abs/2311.08724)

    本文提出了一种在电力分配网络中构建知识图谱的方法，该方法利用实体特征，在分配网络的知识图谱和分配文本中进行匹配，通过实验证明了其在电力分配知识图谱构建任务中的高准确性。

    

    本文提出了一种在电力分配网络中构建知识图谱的方法。该方法利用实体特征，包括其语义、音韵和句法特征，在分配网络的知识图谱和分配文本中进行匹配。基于卷积神经网络的增强模型，用于有效地将分配文本实体与知识图谱中的实体匹配。通过在真实世界的电力分配场景中进行实验评估了该模型的有效性。结果表明，与基线方法相比，所提出的模型在链接各种实体类型方面表现出色，在电力分配知识图谱构建任务中具有很高的整体准确性。

    In this paper, we propose a method for knowledge graph construction in power distribution networks. This method leverages entity features, which involve their semantic, phonetic, and syntactic characteristics, in both the knowledge graph of distribution network and the dispatching texts. An enhanced model based on Convolutional Neural Network, is utilized for effectively matching dispatch text entities with those in the knowledge graph. The effectiveness of this model is evaluated through experiments in real-world power distribution dispatch scenarios. The results indicate that, compared with the baselines, the proposed model excels in linking a variety of entity types, demonstrating high overall accuracy in power distribution knowledge graph construction task.
    
[^29]: 在Transformer中定位跨任务序列继续电路

    Locating Cross-Task Sequence Continuation Circuits in Transformers. (arXiv:2311.04131v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.04131](http://arxiv.org/abs/2311.04131)

    通过分析和比较Transformer模型中类似的序列继续任务的电路，研究发现共享的计算结构可以提高模型的行为预测能力、错误识别能力和编辑过程的安全性。

    

    虽然Transformer模型在语言任务上展现出强大的能力，但其复杂的架构使其难以解释。最近的研究旨在将Transformer模型还原为可读的电路表示，用于实现算法功能。我们通过分析和比较类似的序列继续任务的电路来扩展这项研究，其中包括数字、数字词和月份的递增序列。通过应用电路分析技术，我们确定了负责检测序列成员和预测序列中下一个成员的关键子电路。我们的分析揭示了语义相关序列依赖于具有类似作用的共享电路子图。总体而言，记录共享的计算结构能够更好地预测模型行为，识别错误，并进行更安全的编辑过程。这种对Transformer的机械理解是构建更健壮、调试和编辑更安全的模型的关键一步。

    While transformer models exhibit strong capabilities on linguistic tasks, their complex architectures make them difficult to interpret. Recent work has aimed to reverse engineer transformer models into human-readable representations called circuits that implement algorithmic functions. We extend this research by analyzing and comparing circuits for similar sequence continuation tasks, which include increasing sequences of digits, number words, and months. Through the application of circuit analysis techniques, we identify key sub-circuits responsible for detecting sequence members and for predicting the next member in a sequence. Our analysis reveals that semantically related sequences rely on shared circuit subgraphs with analogous roles. Overall, documenting shared computational structures enables better prediction of model behaviors, identification of errors, and safer editing procedures. This mechanistic understanding of transformers is a critical step towards building more robust,
    
[^30]: LLMs是否展现出类似于人类的反应偏倚？一项关于调查设计的案例研究。

    Do LLMs exhibit human-like response biases? A case study in survey design. (arXiv:2311.04076v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.04076](http://arxiv.org/abs/2311.04076)

    本研究以调查设计为案例研究，探讨了LLMs是否展现类似于人类的反应偏差的问题。

    

    随着大型语言模型（LLMs）的能力增强，人们对将LLMs用作代理人类进行主观标签任务（如调查和舆论调查）的可能性越来越兴奋。然而，LLMs对提示措辞的敏感性是其广泛引述的限制之一，但有趣的是，人类在回应中也显示出对指令变化的敏感性，表现为反应偏倚。因此，我们认为，如果要使用LLMs近似人类意见，有必要调查LLMs是否也反映了人类的反应偏差。在本研究中，我们以调查设计为案例研究，调查问卷中由于“提示”措辞的变化导致的人类反应偏差已经得到广泛研究。借鉴社会心理学的先前工作，我们设计了一个数据集并提出了一个评估框架，以评估LLMs是否在调查问卷中展现类似于人类的反应偏差。

    As large language models (LLMs) become more capable, there is growing excitement about the possibility of using LLMs as proxies for humans in real-world tasks where subjective labels are desired, such as in surveys and opinion polling. One widely-cited barrier to the adoption of LLMs is their sensitivity to prompt wording - but interestingly, humans also display sensitivities to instruction changes in the form of response biases. As such, we argue that if LLMs are going to be used to approximate human opinions, it is necessary to investigate the extent to which LLMs also reflect human response biases, if at all. In this work, we use survey design as a case study, where human response biases caused by permutations in wordings of "prompts" have been extensively studied. Drawing from prior work in social psychology, we design a dataset and propose a framework to evaluate whether LLMs exhibit human-like response biases in survey questionnaires. Our comprehensive evaluation of nine models s
    
[^31]: ALYMPICS：语言代理人与博弈论相遇——用AI代理人探索战略决策

    ALYMPICS: Language Agents Meet Game Theory -- Exploring Strategic Decision-Making with AI Agents. (arXiv:2311.03220v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.03220](http://arxiv.org/abs/2311.03220)

    本文介绍了Alympics，一个利用大型语言模型代理人进行博弈论研究的系统性模拟框架。通过模拟人类战略互动，框架能够定性和定量地分析游戏决定因素、策略和结果，并对代理人在战略决策场景中的表现进行评估。

    

    本文介绍了Alympics（代理人的奥运会），这是一个利用大型语言模型（LLM）代理人进行博弈论研究的系统性模拟框架。Alympics创建了一个多功能平台，用于研究复杂的博弈论问题，通过提供一个控制环境来模拟与LLM代理人进行类似人类的战略互动，弥合了理论博弈论和实证研究之间的差距。在我们的试点案例研究中，“水资源分配挑战”，我们通过一个关注稀缺生存资源多轮拍卖的挑战性战略游戏来探索Alympics。这项研究展示了该框架在定性和定量分析游戏决定因素、策略和结果方面的能力。此外，我们进行了全面的人类评估和对LLM代理人在战略决策场景中的深入评估。我们的发现不仅扩展了对LLM代理人模拟人类战略行为能力的理解，还

    This paper introduces Alympics (Olympics for Agents), a systematic simulation framework utilizing Large Language Model (LLM) agents for game theory research. Alympics creates a versatile platform for studying complex game theory problems, bridging the gap between theoretical game theory and empirical investigations by providing a controlled environment for simulating human-like strategic interactions with LLM agents. In our pilot case study, the "Water Allocation Challenge," we explore Alympics through a challenging strategic game focused on the multi-round auction on scarce survival resources. This study demonstrates the framework's ability to qualitatively and quantitatively analyze game determinants, strategies, and outcomes. Additionally, we conduct a comprehensive human assessment and an in-depth evaluation of LLM agents in strategic decision-making scenarios. Our findings not only expand the understanding of LLM agents' proficiency in emulating human strategic behavior but also h
    
[^32]: LLM可能主导信息访问：神经检索器对LLM生成的文本存在偏见。

    LLMs may Dominate Information Access: Neural Retrievers are Biased Towards LLM-Generated Texts. (arXiv:2310.20501v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2310.20501](http://arxiv.org/abs/2310.20501)

    近期的研究发现，大型语言模型（LLMs）对信息检索系统产生了一种偏见，倾向于将LLM生成的文档排名较高。这种“来源偏见”可能对信息访问产生重大影响。

    

    最近，大型语言模型（LLMs）的出现在信息检索（IR）应用，尤其是在网络搜索方面，彻底改变了范式。由于其在生成类人文本方面的卓越能力，LLMs在互联网上创造了大量的文本。因此，LLMs时代的IR系统面临一个新的挑战：索引的文档不仅是由人类撰写的，而且还包括由LLMs自动生成的文档。这些LLM生成的文档如何影响IR系统是一个紧迫且尚未探索的问题。在这项工作中，我们在涉及人类编写和LLM生成的文本的不同IR模型的场景中进行了定量评估。令人惊讶的是，我们的研究结果表明，神经检索模型倾向于将LLM生成的文档排名较高。我们将这种神经检索模型对LLM生成文本的偏见称为“来源偏见”。此外，我们发现这种偏见不仅限于f方相当的情况，而且在分类任务上也存在。

    Recently, the emergence of large language models (LLMs) has revolutionized the paradigm of information retrieval (IR) applications, especially in web search. With their remarkable capabilities in generating human-like texts, LLMs have created enormous texts on the Internet. As a result, IR systems in the LLMs era are facing a new challenge: the indexed documents now are not only written by human beings but also automatically generated by the LLMs. How these LLM-generated documents influence the IR systems is a pressing and still unexplored question. In this work, we conduct a quantitative evaluation of different IR models in scenarios where both human-written and LLM-generated texts are involved. Surprisingly, our findings indicate that neural retrieval models tend to rank LLM-generated documents higher. We refer to this category of biases in neural retrieval models towards the LLM-generated text as the \textbf{source bias}. Moreover, we discover that this bias is not confined to the f
    
[^33]: 将预训练语言模型整合到神经机器翻译中

    Integrating Pre-trained Language Model into Neural Machine Translation. (arXiv:2310.19680v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.19680](http://arxiv.org/abs/2310.19680)

    该论文提出了PiNMT模型，将预训练语言模型整合到神经机器翻译中，通过三个关键部分和两种训练策略，实现了在IW数据集上的最先进性能。

    

    通过广泛的研究和开发，神经机器翻译（NMT）已成为自然语言处理中的重要技术。然而，高质量的双语语言对数据的不足仍然是提高NMT性能的主要挑战。最近的研究一直在探索使用预训练语言模型（PLM）的上下文信息来解决这个问题。然而，PLM和NMT模型之间的不兼容问题尚未解决。本研究提出了PLM整合的NMT（PiNMT）模型来解决这些问题。PiNMT模型由三个关键组成部分组成，分别是PLM多层转换器，嵌入融合和余弦对齐，每个部分在向NMT提供有效的PLM信息方面发挥着重要作用。此外，本文还介绍了两种训练策略，分别是分离学习率和双步训练。通过实施所提出的PiNMT模型和训练策略，在IW数据集上实现了最先进的性能。

    Neural Machine Translation (NMT) has become a significant technology in natural language processing through extensive research and development. However, the deficiency of high-quality bilingual language pair data still poses a major challenge to improving NMT performance. Recent studies have been exploring the use of contextual information from pre-trained language model (PLM) to address this problem. Yet, the issue of incompatibility between PLM and NMT model remains unresolved. This study proposes PLM-integrated NMT (PiNMT) model to overcome the identified problems. PiNMT model consists of three critical components, PLM Multi Layer Converter, Embedding Fusion, and Cosine Alignment, each playing a vital role in providing effective PLM information to NMT. Furthermore, two training strategies, Separate Learning Rates and Dual Step Training, are also introduced in this paper. By implementing the proposed PiNMT model and training strategy, we achieve state-of-the-art performance on the IW
    
[^34]: CXR-LLaVA：用于解释胸部X射线图像的多模式大型语言模型

    CXR-LLaVA: Multimodal Large Language Model for Interpreting Chest X-ray Images. (arXiv:2310.18341v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.18341](http://arxiv.org/abs/2310.18341)

    本研究开发了一种用于解读胸部X射线图像的开源多模态大型语言模型（CXR-LLaVA），通过预训练图像编码器和对比语言-图像预训练将图像与放射学异常对齐，并使用GPT-4进行微调，实现了问题回答的功能。

    

    目的：最近大型语言模型（LLMs）的进步以多模态的方式扩展了它们的能力，可能复制人类放射科医师对图像的解释。本研究旨在开发用于解释胸部X射线图像的开源多模态大型语言模型（CXR-LLaVA）。我们还研究了提示工程和模型参数（如温度和核心采样）的影响。材料和方法：我们收集了659,287个公开可用的胸部X射线图像进行训练：417,336个图像带有某些放射学异常标签（数据集1）；241,951个图像带有自由文本放射学报告（数据集2）。在预训练Resnet50作为图像编码器之后，采用对比语言-图像预训练来对齐胸部X射线图像和相应的放射学异常。然后，使用数据集2对大型语言模型Meta AI-2进行微调，这些数据集经过GPT-4的改进，生成各种问题回答情景。代码可以在ht找到

    Purpose: Recent advancements in large language models (LLMs) have expanded their capabilities in a multimodal fashion, potentially replicating the image interpretation of human radiologists. This study aimed to develop open-source multimodal large language model for interpreting chest X-ray images (CXR-LLaVA). We also examined the effect of prompt engineering and model parameters such as temperature and nucleus sampling.  Materials and Methods: For training, we collected 659,287 publicly available CXRs: 417,336 CXRs had labels for certain radiographic abnormalities (dataset 1); 241,951 CXRs provided free-text radiology reports (dataset 2). After pre-training the Resnet50 as an image encoder, the contrastive language-image pre-training was used to align CXRs and corresponding radiographic abnormalities. Then, the Large Language Model Meta AI-2 was fine-tuned using dataset 2, which were refined using GPT-4, with generating various question answering scenarios. The code can be found at ht
    
[^35]: 超越准确性：用IdentityChain评估大型代码语言模型的自一致性

    Beyond Accuracy: Evaluating Self-Consistency of Code Large Language Models with IdentityChain. (arXiv:2310.14053v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.14053](http://arxiv.org/abs/2310.14053)

    这篇论文提出了一种评估大型代码语言模型自一致性的方法，并指出目前的模型在自一致性方面存在问题。

    

    代码语言模型(Code LLMs)在实际应用中的使用越来越多，因此对它们进行评估至关重要。传统的准确性评估方法评估Code LLMs在一系列独立任务上的性能，但忽视了其在不同任务上的自一致性。直观来讲，一个可信赖的模型在为其自身的代码生成自然语言规范以及为其自身的规范生成代码时应该是自一致的。未能保持自一致性揭示了对自然语言和编程语言共享语义的理解的不足，从而削弱了模型的可信度。本文首先正式定义了Code LLMs的自一致性，然后设计了一个名为IdentityChain的框架，可以同时有效且高效地评估模型的自一致性和传统准确性。我们研究了11个Code LLMs，并表明它们未能保持自一致性。

    Code Large Language Models (Code LLMs) are being increasingly employed in real-life applications, so evaluating them is critical. While the conventional accuracy evaluates the performance of Code LLMs on a set of individual tasks, their self-consistency across different tasks is overlooked. Intuitively, a trustworthy model should be self-consistent when generating natural language specifications for its own code and generating code for its own specifications. Failure to preserve self-consistency reveals a lack of understanding of the shared semantics underlying natural language and programming language, and therefore undermines the trustworthiness of a model. In this paper, we first formally define the self-consistency of Code LLMs and then design a framework, IdentityChain, which effectively and efficiently evaluates the self-consistency and conventional accuracy of a model at the same time. We study eleven Code LLMs and show that they fail to preserve self-consistency, which is indee
    
[^36]: MolCA: 通过跨模态投影和单模态适配器的分子图-语言建模

    MolCA: Molecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal Adapter. (arXiv:2310.12798v1 [cs.CL])

    [http://arxiv.org/abs/2310.12798](http://arxiv.org/abs/2310.12798)

    MolCA是一个可以通过跨模态投影和单模态适配器实现分子图和语言的建模系统。它可以通过连接图编码器和语言模型的表示空间来理解文本和图形的分子内容，并通过单模态适配器在下游任务中高效适应。

    

    语言模型在各种与文本相关的任务上展示了对分子的卓越理解能力。然而，它们本质上缺乏人类专业人员在理解分子拓扑结构中的关键能力 - 2D图形感知能力。为了弥合这个差距，我们提出了MolCA: 通过跨模态投影和单模态适配器进行分子图-语言建模。MolCA通过跨模态投影使语言模型（例如Galactica）能够理解基于文本和图形的分子内容。具体而言，跨模态投影器被实现为一个Q-Former，连接一个图编码器的表示空间和一个语言模型的文本空间。此外，MolCA使用单模态适配器（即LoRA）使语言模型能够有效适应下游任务。与先前的研究通过跨模态对比学习将语言模型与图形编码器耦合不同，MolCA保留了语言模型的开放式文本生成能力，并增加了2D图形信息。为了展示其有效性，

    Language Models (LMs) have demonstrated impressive molecule understanding ability on various 1D text-related tasks. However, they inherently lack 2D graph perception - a critical ability of human professionals in comprehending molecules' topological structures. To bridge this gap, we propose MolCA: Molecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal Adapter. MolCA enables an LM (e.g., Galactica) to understand both text- and graph-based molecular contents via the cross-modal projector. Specifically, the cross-modal projector is implemented as a Q-Former to connect a graph encoder's representation space and an LM's text space. Further, MolCA employs a uni-modal adapter (i.e., LoRA) for the LM's efficient adaptation to downstream tasks. Unlike previous studies that couple an LM with a graph encoder via cross-modal contrastive learning, MolCA retains the LM's ability of open-ended text generation and augments it with 2D graph information. To showcase its effectivenes
    
[^37]: VeRA: 基于向量的随机矩阵自适应

    VeRA: Vector-based Random Matrix Adaptation. (arXiv:2310.11454v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.11454](http://arxiv.org/abs/2310.11454)

    VeRA提出了一种基于向量的随机矩阵自适应方法，相比于低秩自适应方法，可以显著减少可训练参数的数量，同时保持相同的性能。该方法在GLUE和E2E基准测试、图像分类任务以及指令调优中都取得了良好的效果。

    

    低秩自适应（LoRA）是一种流行的方法，在微调大型语言模型时减少可训练参数的数量，但在扩展到更大模型或部署大量特定用户或任务自适应模型时仍然面临严重的存储挑战。在这项工作中，我们提出了基于向量的随机矩阵自适应（VeRA），与LoRA相比，它可以显著减少可训练参数的数量，同时保持相同的性能。它通过使用一对在所有层之间共享的低秩矩阵，并学习小的缩放向量来实现这一点。我们在GLUE和E2E基准测试、图像分类任务中展示了其有效性，并展示了其在7B和13B语言模型的指令调优中的应用。

    Low-rank adapation (LoRA) is a popular method that reduces the number of trainable parameters when finetuning large language models, but still faces acute storage challenges when scaling to even larger models or deploying numerous per-user or per-task adapted models. In this work, we present Vector-based Random Matrix Adaptation (VeRA), which significantly reduces the number of trainable parameters compared to LoRA, yet maintains the same performance. It achieves this by using a single pair of low-rank matrices shared across all layers and learning small scaling vectors instead. We demonstrate its effectiveness on the GLUE and E2E benchmarks, image classification tasks, and show its application in instruction-tuning of 7B and 13B language models.
    
[^38]: SD-HuBERT: 自我蒸馏诱导HuBERT中的音节组织

    SD-HuBERT: Self-Distillation Induces Syllabic Organization in HuBERT. (arXiv:2310.10803v1 [cs.CL])

    [http://arxiv.org/abs/2310.10803](http://arxiv.org/abs/2310.10803)

    本研究提出了SD-HuBERT模型，通过采用自我蒸馏目标进行微调，实现了在学习语音句子级表示时音节组织的出现，模型能够在语音中划定明确的边界，并展现出显著的音节结构。该研究还提出了一个新的基准任务用于评估语音的句子级表示，与之前的模型相比，在无监督音节发现和学习句子级表示方面表现优异。

    

    自我监督学习（SSL）中的数据驱动单元发现开启了口语语言处理的新时代。然而，发现的单元往往仍处于音素空间，限制了SSL表示的实用性。在这里，我们展示了在学习语音的句子级表示时，音节组织的出现。特别地，我们采用“自我蒸馏”目标来微调预训练的HuBERT，并加入一个汇聚标记来总结整个句子。在没有任何监督的情况下，得到的模型在语音中划定了明确的边界，并且帧间的表示显示出显著的音节结构。我们证明这种出现的结构很大程度上与真实音节对应。此外，我们提出了一个新的基准任务，Spoken Speech ABX，用于评估语音的句子级表示。与之前的模型相比，我们的模型在无监督音节发现和学习句子级表示方面表现优异。

    Data-driven unit discovery in self-supervised learning (SSL) of speech has embarked on a new era of spoken language processing. Yet, the discovered units often remain in phonetic space, limiting the utility of SSL representations. Here, we demonstrate that a syllabic organization emerges in learning sentence-level representation of speech. In particular, we adopt "self-distillation" objective to fine-tune the pretrained HuBERT with an aggregator token that summarizes the entire sentence. Without any supervision, the resulting model draws definite boundaries in speech, and the representations across frames show salient syllabic structures. We demonstrate that this emergent structure largely corresponds to the ground truth syllables. Furthermore, we propose a new benchmark task, Spoken Speech ABX, for evaluating sentence-level representation of speech. When compared to previous models, our model outperforms in both unsupervised syllable discovery and learning sentence-level representatio
    
[^39]: 自我监督的语音模型推断出普适的发音运动学

    Self-Supervised Models of Speech Infer Universal Articulatory Kinematics. (arXiv:2310.10788v1 [eess.AS])

    [http://arxiv.org/abs/2310.10788](http://arxiv.org/abs/2310.10788)

    本研究展示了自我监督语音模型具有推断语音发音运动学的能力，并显示出这一属性在不同语言中具有重叠性。此外，通过简单变换，模型可以在不同说话者、性别、语言和方言之间转换，表现出良好的泛化性。这些结果拓宽了我们对语音处理的理解。

    

    基于自我监督学习（SSL）的语音模型在许多下游任务中显示出了出色的性能。这些最先进的模型一直是黑匣子，但最近的许多研究开始对像HuBERT这样的模型进行"探测"，以将其内部表示与语音的不同方面相关联。本文中，我们展示了自我监督模型的一个基本属性，即"推断发音运动学"，即这些模型将声学转化为语音信号底层的因果性发音动态的能力。我们还显示出，该抽象在用于训练模型的数据的语言之间有较大的重叠，在类似音系的语言中有更高的偏好。此外，我们还显示出，通过简单的仿射变换，声学到发音的逆转换（AAI）在说话者之间具有可传递性，甚至在性别、语言和方言之间也具有可传递性，显示了该属性的普适性。总的来说，这些结果为我们对语音处理的认识提供了新的视角。

    Self-Supervised Learning (SSL) based models of speech have shown remarkable performance on a range of downstream tasks. These state-of-the-art models have remained blackboxes, but many recent studies have begun "probing" models like HuBERT, to correlate their internal representations to different aspects of speech. In this paper, we show "inference of articulatory kinematics" as fundamental property of SSL models, i.e., the ability of these models to transform acoustics into the causal articulatory dynamics underlying the speech signal. We also show that this abstraction is largely overlapping across the language of the data used to train the model, with preference to the language with similar phonological system. Furthermore, we show that with simple affine transformations, Acoustic-to-Articulatory inversion (AAI) is transferrable across speakers, even across genders, languages, and dialects, showing the generalizability of this property. Together, these results shed new light on the 
    
[^40]: CP-KGC: 利用大型语言模型的约束式提示对知识图谱进行补全

    CP-KGC: Constrained-Prompt Knowledge Graph Completion with Large Language Models. (arXiv:2310.08279v1 [cs.CL])

    [http://arxiv.org/abs/2310.08279](http://arxiv.org/abs/2310.08279)

    CP-KGC方法利用大型语言模型，通过约束式提示来补全知识图谱，提高推断效果，展示了在低资源计算条件下的有效性，并在数据集上取得了优于之前方法的结果。

    

    知识图谱补全旨在利用现有知识推断和推测知识图谱中缺失的连接。SimKGC等基于文本的方法已经超过了图嵌入方法，展示了归纳式知识图谱补全的潜力。然而，基于文本的方法的效果取决于实体文本描述的质量。为了减轻LLM生成的文本中的幻觉，在本文中，我们引入了一种基于约束的提示方法，利用实体及其文本描述作为上下文约束来提高数据质量。我们的约束式提示知识图谱补全方法（CP-KGC）在低资源计算条件下表现出有效的推断能力，并超过了WN18RR和FB15K237数据集上的之前结果。这展示了LLMs在知识图谱补全任务中的整合，并为未来的研究提供了新的方向。

    Knowledge graph completion (KGC) aims to utilize existing knowledge to deduce and infer missing connections within knowledge graphs. Text-based approaches, like SimKGC, have outperformed graph embedding methods, showcasing the promise of inductive KGC. However, the efficacy of text-based methods hinges on the quality of entity textual descriptions. In this paper, we identify the key issue of whether large language models (LLMs) can generate effective text. To mitigate hallucination in LLM-generated text in this paper, we introduce a constraint-based prompt that utilizes the entity and its textual description as contextual constraints to enhance data quality. Our Constrained-Prompt Knowledge Graph Completion (CP-KGC) method demonstrates effective inference under low resource computing conditions and surpasses prior results on the WN18RR and FB15K237 datasets. This showcases the integration of LLMs in KGC tasks and provides new directions for future research.
    
[^41]: 通过贝叶斯方法将语言模型与人类偏好对齐

    Aligning Language Models with Human Preferences via a Bayesian Approach. (arXiv:2310.05782v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.05782](http://arxiv.org/abs/2310.05782)

    本文提出了一种贝叶斯方法，通过训练奖励模型来对齐语言模型和人类偏好。这种方法能够解决由于人类偏好的主观性而带来的困难，从而提高自然语言生成系统的性能。

    

    在推进以人为中心的自然语言生成（NLG）系统的过程中，确保NLG模型与人类偏好的一致性至关重要。为了实现这种对齐，目前流行的方法利用强化学习（RL）方法，通过来自人类的反馈训练奖励模型。然而，由于人类偏好的主观性而带来的固有分歧对训练奖励模型构成了重大挑战，导致NLG性能的下降。为了解决这个问题，先前的方法通常依赖多数投票或平均值来将多个不一致的偏好合并成一个合并的偏好。虽然这些方法易于理解和执行，但是它们不能捕捉到人类之间细微的分歧程度，并且可能只代表了个别特定人群，从而缺乏定量披露人类偏好的普适性的能力。为了解决这个挑战，本文提出了一种贝叶斯方法来对齐语言模型和人类偏好。

    In the quest to advance human-centric natural language generation (NLG) systems, ensuring alignment between NLG models and human preferences is crucial. For this alignment, current popular methods leverage a reinforcement learning (RL) approach with a reward model trained on feedback from humans. However, inherent disagreements due to the subjective nature of human preferences pose a significant challenge for training the reward model, resulting in a deterioration of the NLG performance. To tackle this issue, previous approaches typically rely on majority voting or averaging to consolidate multiple inconsistent preferences into a merged one. Although straightforward to understand and execute, such methods suffer from an inability to capture the nuanced degrees of disaggregation among humans and may only represent a specialized subset of individuals, thereby lacking the ability to quantitatively disclose the universality of human preferences. To address this challenge, this paper propos
    
[^42]: 从可持续性报告中通过大型语言模型推导出结构化见解：闪光还是黄金？

    Glitter or Gold? Deriving Structured Insights from Sustainability Reports via Large Language Models. (arXiv:2310.05628v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.05628](http://arxiv.org/abs/2310.05628)

    通过大型语言模型和信息抽取技术，本研究提取了公司可持续性报告中的结构化ESG相关信息，为利益相关者提供简洁、信息丰富和可行动的数据。

    

    在过去的十年中，鉴于投资者对环境、社会和治理（ESG）问题越来越关注，一些监管机构开始要求上市公司披露非财务信息。这些信息以各种非结构化的多模态文档形式公开发布。因此，将这些数据聚合和整合到一个一致的框架中，以进一步推导出跨公司和市场的可持续性实践见解并不直观。鉴于这些前提，自然而然地，我们可以采用信息抽取（IE）技术为利益相关者提供简洁、信息丰富和可行动的数据。在本研究中，我们突破了传统的文本处理技术，利用大型语言模型（LLMs），结合突出的上下文学习技术和检索增强生成（RAG）范式，从公司的可持续性报告中提取具有语义结构的与ESG相关的信息。

    Over the last decade, several regulatory bodies have started requiring the disclosure of non-financial information from publicly listed companies, in light of the investors' increasing attention to Environmental, Social, and Governance (ESG) issues. Such information is publicly released in a variety of non-structured and multi-modal documentation. Hence, it is not straightforward to aggregate and consolidate such data in a cohesive framework to further derive insights about sustainability practices across companies and markets. Given these premises, it is natural to resort to Information Extraction (IE) techniques to provide concise, informative, and actionable data to the stakeholders. Moving beyond traditional text processing techniques, in this work we leverage Large Language Models (LLMs), along with the prominent in-context learning technique and the Retrieved Augmented Generation (RAG) paradigm, to extract semantically structured ESG-related information from companies' sustainabi
    
[^43]: 超越注意力范式：从地理社交媒体数据中学习表示

    Transcending the Attention Paradigm: Representation Learning from Geospatial Social Media Data. (arXiv:2310.05378v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.05378](http://arxiv.org/abs/2310.05378)

    本研究通过分析地理社交媒体数据发现，传统的基于注意力的架构存在局限性，无法隐含学习总体文本主题。相比于捕捉复杂长期依赖性的网络，在线数据的模型缺乏结构，需要在聚合中检测潜在的结构。此研究使用了20亿条推文进行实证分析，并比较了不同城市的词袋嵌入表示，发现地理位置对在线沟通有重要影响。

    

    虽然transformers作为语言建模的基石开创了注意力驱动的架构，但它们对显式上下文信息的依赖强调了它们在暗示性学习总体文本主题方面的局限性。本研究挑战了性能基准的启发式范式，通过将社交媒体数据作为分布式模式的源头进行研究。与依赖于捕捉复杂长期依赖性的网络形成鲜明对比的是，在线数据的模型本质上缺乏结构，被迫在聚合中检测潜在的结构。为了正确地表示这些抽象关系，本研究分解了经验社交媒体语料库成为其元素组成部分，分析了超过20亿条发表在人口密集地区的推文。我们创建了针对每个城市的词袋嵌入，并比较了它们的表示。发现即使在嘈杂的数据中，地理位置对在线沟通有着重要的影响。

    While transformers have pioneered attention-driven architectures as a cornerstone of language modeling, their dependence on explicitly contextual information underscores limitations in their abilities to tacitly learn overarching textual themes. This study challenges the heuristic paradigm of performance benchmarking by investigating social media data as a source of distributed patterns. In stark contrast to networks that rely on capturing complex long-term dependencies, models of online data inherently lack structure and are forced to detect latent structures in the aggregate. To properly represent these abstract relationships, this research dissects empirical social media corpora into their elemental components, analyzing over two billion tweets across population-dense locations. We create Bag-of-Word embedding specific to each city and compare their respective representations. This finds that even amidst noisy data, geographic location has a considerable influence on online communic
    
[^44]: 放射学报告的多语言自然语言处理模型--摘要是你需要的一切！

    Multilingual Natural Language ProcessingModel for Radiology Reports -- The Summary is all you need!. (arXiv:2310.00100v1 [cs.CL])

    [http://arxiv.org/abs/2310.00100](http://arxiv.org/abs/2310.00100)

    本研究通过在多语言文本到文本变换器模型上微调，开发了一个能够自动在多语言中总结放射学报告的模型。该模型有助于提高未来深度学习模型的研究和发展，且能够应用于不同族裔背景的患者数据。

    

    放射学报告的印象部分总结了重要的放射学发现，并在向医生传达这些发现时起到了关键作用。然而，对于放射科医生来说，准备这些摘要既耗时又容易出错。最近，已经开发了许多用于放射学报告摘要的模型。然而，目前还没有能够在多种语言中总结这些报告的模型。这样的模型可以极大地改进未来的研究和融合来自不同族裔背景的患者数据的深度学习模型的发展。本研究通过在公开可用的基于多语言文本到文本变换器的模型上微调，自动化地生成了不同语言的放射学印象，以总结英语、葡萄牙语和德语的放射学报告中的发现。在一项盲测中，两位有执业资格的放射科医生表示，对于至少70%的系统生成的摘要，其质量

    The impression section of a radiology report summarizes important radiology findings and plays a critical role in communicating these findings to physicians. However, the preparation of these summaries is time-consuming and error-prone for radiologists. Recently, numerous models for radiology report summarization have been developed. Nevertheless, there is currently no model that can summarize these reports in multiple languages. Such a model could greatly improve future research and the development of Deep Learning models that incorporate data from patients with different ethnic backgrounds. In this study, the generation of radiology impressions in different languages was automated by fine-tuning a model, publicly available, based on a multilingual text-to-text Transformer to summarize findings available in English, Portuguese, and German radiology reports. In a blind test, two board-certified radiologists indicated that for at least 70% of the system-generated summaries, the quality 
    
[^45]: 无监督语言模型蒸馏的事实验证

    Unsupervised Fact Verification by Language Model Distillation. (arXiv:2309.16540v1 [cs.CL])

    [http://arxiv.org/abs/2309.16540](http://arxiv.org/abs/2309.16540)

    本文提出了一种名为SFAVEL的无监督框架，通过语言模型蒸馏将自监督特征转化为高质量的主张-事实对齐，实现无监督事实验证。这通过一种新颖的对比损失函数实现，同时保留语料库间的语义关系。

    

    无监督事实验证旨在通过可靠知识库中的证据来验证主张，而无需任何形式的数据注释。为了解决这个挑战，算法必须为每个主张生成既语义明确又紧凑的特征，以便与源信息进行语义对齐。与之前的工作不同，前者通过学习包含主张及其相应标签的注释语料库来解决对齐问题。我们提出了SFAVEL（通过语言模型蒸馏的自监督事实验证），这是一个新颖的无监督框架，利用预训练的语言模型将自监督特征蒸馏为高质量的主张-事实对齐，而无需注释。这是通过一种新颖的对比损失函数实现的，该函数鼓励特征在保持语料库间的语义关系的同时实现高质量的主张和证据对齐。值得注意的是，我们展示了达到新颖的状态一.

    Unsupervised fact verification aims to verify a claim using evidence from a trustworthy knowledge base without any kind of data annotation. To address this challenge, algorithms must produce features for every claim that are both semantically meaningful, and compact enough to find a semantic alignment with the source information. In contrast to previous work, which tackled the alignment problem by learning over annotated corpora of claims and their corresponding labels, we propose SFAVEL (Self-supervised Fact Verification via Language Model Distillation), a novel unsupervised framework that leverages pre-trained language models to distil self-supervised features into high-quality claim-fact alignments without the need for annotations. This is enabled by a novel contrastive loss function that encourages features to attain high-quality claim and evidence alignments whilst preserving the semantic relationships across the corpora. Notably, we present results that achieve a new state-of-the
    
[^46]: 人类反馈不是黄金标准

    Human Feedback is not Gold Standard. (arXiv:2309.16349v1 [cs.CL])

    [http://arxiv.org/abs/2309.16349](http://arxiv.org/abs/2309.16349)

    这个论文对人类反馈在语言模型评估中的使用进行了批判性分析，发现它们无法完全捕捉到关键错误标准，而且容易受到主观偏见和混杂因素的影响。

    

    人类反馈已成为评估大型语言模型性能的事实标准，并越来越被用作训练目标。然而，不清楚这个单一的“偏好”分数捕捉到生成输出的哪些特性。我们假设偏好分数是主观的，并且容易受到不良偏差的影响。我们对人类反馈在训练和评估中的使用进行了批判性分析，以验证它是否完全捕捉到一系列关键错误标准。我们发现，虽然偏好分数的覆盖范围相当好，但它们在事实性等重要方面表现不足。我们进一步假设偏好分数和错误注释可能受到混杂因素的影响，并利用调试模型生成在两个可能的混杂维度上变化的输出：坚定性和复杂性。我们发现，输出的坚定性会使事实错误的感知率偏差，表明人类注释是不准确的。

    Human feedback has become the de facto standard for evaluating the performance of Large Language Models, and is increasingly being used as a training objective. However, it is not clear which properties of a generated output this single `preference' score captures. We hypothesise that preference scores are subjective and open to undesirable biases. We critically analyse the use of human feedback for both training and evaluation, to verify whether it fully captures a range of crucial error criteria. We find that while preference scores have fairly good coverage, they under-represent important aspects like factuality. We further hypothesise that both preference scores and error annotation may be affected by confounders, and leverage instruction-tuned models to generate outputs that vary along two possible confounding dimensions: assertiveness and complexity. We find that the assertiveness of an output skews the perceived rate of factuality errors, indicating that human annotations are no
    
[^47]: 通用文本指导语音转换模型研究

    Towards General-Purpose Text-Instruction-Guided Voice Conversion. (arXiv:2309.14324v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2309.14324](http://arxiv.org/abs/2309.14324)

    本文介绍了一种通过文本指令进行语音转换的通用模型。与传统方法不同，该模型利用文本指令修改语音的韵律和情感信息，具有较高的灵活性和特异性。实验证明了该模型能够理解指令并产生合理结果。

    

    本文介绍了一种新颖的语音转换模型，该模型通过文本指令如"慢慢清晰地说话，声音低沉"或"以快乐的少年声音说话"来指导转换过程。与传统方法不同，该模型增加了语音转换的通用性和特异性。该提出的语音转换模型是一个神经编解码器语言模型，通过处理一系列离散编码，得到转换后的语音编码序列。它利用文本指令作为样式提示，修改给定语音的韵律和情感信息。与之前的方法相比，该模型以端到端的方式处理语音的各种信息，而不需要使用独立的编码器处理源语音的不同方面，如韵律和内容。实验证明了我们模型在理解指令并产生合理结果方面的卓越能力。

    This paper introduces a novel voice conversion (VC) model, guided by text instructions such as "articulate slowly with a deep tone" or "speak in a cheerful boyish voice". Unlike traditional methods that rely on reference utterances to determine the attributes of the converted speech, our model adds versatility and specificity to voice conversion. The proposed VC model is a neural codec language model which processes a sequence of discrete codes, resulting in the code sequence of converted speech. It utilizes text instructions as style prompts to modify the prosody and emotional information of the given speech. In contrast to previous approaches, which often rely on employing separate encoders like prosody and content encoders to handle different aspects of the source speech, our model handles various information of speech in an end-to-end manner. Experiments have demonstrated the impressive capabilities of our model in comprehending instructions and delivering reasonable results.
    
[^48]: AMPLIFY: 基于注意力机制的Mixup方法，用于提高Transformer模型的性能和标签平滑

    AMPLIFY:Attention-based Mixup for Performance Improvement and Label Smoothing in Transformer. (arXiv:2309.12689v1 [cs.LG])

    [http://arxiv.org/abs/2309.12689](http://arxiv.org/abs/2309.12689)

    AMPLIFY提出了一种基于注意力机制的Mixup方法，用于减少原始样本中的噪音和异常值对于模型的影响，并在文本分类任务中表现出更好的性能。

    

    Mixup是一种有效的数据增强方法，通过对不同原始样本的线性组合生成新的增强样本。然而，如果原始样本中存在噪音或异常特征，Mixup可能将其传播到增强样本中，导致模型对这些异常值过于敏感。为了解决这个问题，本文提出了一种新的Mixup方法称为AMPLIFY。该方法利用Transformer自身的注意力机制减少原始样本中噪音和异常值对预测结果的影响，无需增加可训练参数，计算成本非常低，从而避免了常见Mixup方法（例如语句Mixup）中资源消耗过高的问题。实验结果表明，在更小的计算资源成本下，AMPLIFY在7个基准数据集的文本分类任务中优于其他Mixup方法，为进一步提高模型性能提供了新的思路和方法。

    Mixup is an effective data augmentation method that generates new augmented samples by aggregating linear combinations of different original samples. However, if there are noises or aberrant features in the original samples, Mixup may propagate them to the augmented samples, leading to over-sensitivity of the model to these outliers . To solve this problem, this paper proposes a new Mixup method called AMPLIFY. This method uses the Attention mechanism of Transformer itself to reduce the influence of noises and aberrant values in the original samples on the prediction results, without increasing additional trainable parameters, and the computational cost is very low, thereby avoiding the problem of high resource consumption in common Mixup methods such as Sentence Mixup . The experimental results show that, under a smaller computational resource cost, AMPLIFY outperforms other Mixup methods in text classification tasks on 7 benchmark datasets, providing new ideas and new ways to further
    
[^49]: CB-Whisper: 使用开放词汇关键词检测进行上下文偏置的Whisper

    CB-Whisper: Contextual Biasing Whisper using Open-Vocabulary Keyword-Spotting. (arXiv:2309.09552v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2309.09552](http://arxiv.org/abs/2309.09552)

    CB-Whisper是一种基于OpenAI的Whisper模型的自动语音识别系统，通过使用开放词汇关键词检测（OV-KWS）识别罕见的命名实体，并使用这些实体作为提示来改进识别效果。实验证明，该方法在提高实体召回率的同时会略微增加混淆错误率（MER）。

    

    自动语音识别系统往往难以识别罕见的命名实体，如个人姓名、组织机构和在训练数据中不经常遇到的专业术语。本文提出了一种基于OpenAI的Whisper模型的Contextual Biasing Whisper（CB-Whisper）自动语音识别系统，通过使用Whisper编码器的隐藏状态执行开放词汇关键词检测（OV-KWS）来识别用户定义的命名实体。识别出的实体被用作Whisper解码器的提示。我们首先提出了一种使用OV-KWS和ASR任务进行多任务训练的方法来优化模型。实验证明，与原始Whisper模型相比，这种方法在中国Aishell热词子集和两个内部代码切换测试集上显著提高了实体召回率。然而，由于灾难性遗忘，我们观察到在内部测试集上混淆错误率（MER）略微增加。为了解决这个问题并使用不同大小的Whisper模型，我们进一步提出了一种解决方案。

    End-to-end automatic speech recognition (ASR) systems often struggle to recognize rare name entities, such as personal names, organizations, and terminologies not frequently encountered in the training data. This paper presents Contextual Biasing Whisper (CB-Whisper), a novel ASR system based on OpenAI's Whisper model that can recognize user-defined name entities by performing open-vocabulary keyword-spotting (OV-KWS) using the hidden states of Whisper encoder. The recognized entities are used as prompts for the Whisper decoder. We first propose a multitask training approach with OV-KWS and ASR tasks to optimize the model. Experiments show that this approach substantially improves the entity recalls compared to the original Whisper model on Chinese Aishell hot word subsets and two internal code-switch test sets. However, we observed a slight increase in mixed-error-rate (MER) on internal test sets due to catastrophic forgetting. To address this problem and use different sizes of the Wh
    
[^50]: 评估和缓解多模态大型语言模型中的失识症

    Evaluation and Mitigation of Agnosia in Multimodal Large Language Models. (arXiv:2309.04041v1 [cs.CV])

    [http://arxiv.org/abs/2309.04041](http://arxiv.org/abs/2309.04041)

    本文针对多模态大型语言模型中存在的失识症问题，提出了一种评估和缓解的框架EMMA。通过类比神经心理学中的失识症现象，定义了MLLM中的失识症，并提出了相应的评估和治疗方法。评估模块通过创建多样化的视觉问答示例来评估失识症程度，治疗模块则采用修正和增强的训练方法来减轻和纠正失识症。

    

    尽管多模态大型语言模型（MLLMs）被广泛用于各种视觉语言任务，但观察到它们有时会误解视觉输入，甚至在简单情况下未能遵循文本指令，导致无关的回复、错误和无根据的主张。我们将这一观察类比于神经心理学中的一种现象，即失识症，即无法正确处理感觉模态和认识事物（例如，对象、颜色、关系）。在我们的研究中，我们采用这一类似的概念来定义“MLLM中的失识症”，我们的目标是全面评估和缓解MLLM中的失识症。受到神经心理学中的诊断和治疗过程的启发，我们提出了一种新的框架EMMA（评估和缓解多模态失识症）。在EMMA中，我们开发了一个评估模块，用于自动创建细粒度和多样化的视觉问答示例，全面评估MLLM中的失识症程度。我们还提出了一种治疗模块，使用修正和增强的训练方法来减轻和纠正MLLM中的失识症。

    While Multimodal Large Language Models (MLLMs) are widely used for a variety of vision-language tasks, one observation is that they sometimes misinterpret visual inputs or fail to follow textual instructions even in straightforward cases, leading to irrelevant responses, mistakes, and ungrounded claims. This observation is analogous to a phenomenon in neuropsychology known as Agnosia, an inability to correctly process sensory modalities and recognize things (e.g., objects, colors, relations). In our study, we adapt this similar concept to define "agnosia in MLLMs", and our goal is to comprehensively evaluate and mitigate such agnosia in MLLMs. Inspired by the diagnosis and treatment process in neuropsychology, we propose a novel framework EMMA (Evaluation and Mitigation of Multimodal Agnosia). In EMMA, we develop an evaluation module that automatically creates fine-grained and diverse visual question answering examples to assess the extent of agnosia in MLLMs comprehensively. We also d
    
[^51]: 基于策略梯度的离散提示生成用于少样本学习的对话式方法

    Dialogue for Prompting: a Policy-Gradient-Based Discrete Prompt Generation for Few-shot Learning. (arXiv:2308.07272v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2308.07272](http://arxiv.org/abs/2308.07272)

    本文介绍了一种基于对话的策略梯度离散提示优化方法，通过设计多轮对话对齐策略和高效的提示筛选度量，实现了在少样本学习任务中生成高质量提示集的目标。

    

    在少样本自然语言处理任务中，基于提示的预训练语言模型(PLMs)范式取得了显著的成功。然而，现有的离散提示优化方法需要专业知识来设计基本提示集并识别高质量的提示，这既费时又低效，而且主观性较强。同时，现有的连续提示优化方法通过学习PLMs的梯度信息来改进性能，但计算成本高、可读性和通用性低常常是问题。为了填补研究空白，本文提出了一种基于对话的策略梯度离散提示优化方法($DP_2O$)。首先，我们设计了一种基于GPT-4的多轮对话对齐策略，用于生成可读性提示集。此外，我们提出了一种高效的提示筛选度量，以线性复杂度识别高质量的提示。最后，我们构建了一个强化学习(RL)框架。

    Prompt-based pre-trained language models (PLMs) paradigm have succeeded substantially in few-shot natural language processing (NLP) tasks. However, prior discrete prompt optimization methods require expert knowledge to design the base prompt set and identify high-quality prompts, which is costly, inefficient, and subjective. Meanwhile, existing continuous prompt optimization methods improve the performance by learning the ideal prompts through the gradient information of PLMs, whose high computational cost, and low readability and generalizability are often concerning. To address the research gap, we propose a Dialogue-comprised Policy-gradient-based Discrete Prompt Optimization ($DP_2O$) method. We first design a multi-round dialogue alignment strategy for readability prompt set generation based on GPT-4. Furthermore, we propose an efficient prompt screening metric to identify high-quality prompts with linear complexity. Finally, we construct a reinforcement learning (RL) framework ba
    
[^52]: QuIP：具有保证的大型语言模型的2比特量化

    QuIP: 2-Bit Quantization of Large Language Models With Guarantees. (arXiv:2307.13304v1 [cs.LG])

    [http://arxiv.org/abs/2307.13304](http://arxiv.org/abs/2307.13304)

    本文提出了一种新的基于无关处理的大型语言模型（LLMs）参数量化方法QuIP，通过使权重和Hessian矩阵与坐标轴不对齐，实现了准确的量化结果。经过经验实验，我们发现我们的方法改善了现有的量化算法，并且首次在仅使用两比特的情况下获得了可行的LLM量化结果。

    

    本研究探讨了大型语言模型（LLMs）中的训练后参数量化。我们介绍了一种新的基于无关处理（QuIP）的量化方法，该方法基于以下见解：量化从不相关的权重和 Hessian 矩阵中收益，即通过准确地将它们舍入为与坐标轴不对齐的方向，使得获取重要的量化结果。QuIP 包含两个步骤：（1）最小化二次近似目标的自适应舍入过程；（2）通过与随机正交矩阵相乘来确保权重和 Hessian 无关的高效预处理和后处理。我们通过第一次针对 LLM 规模的量化算法进行了理论分析，并且证明我们的理论也适用于现有方法 OPTQ。经验证实，我们的无关预处理改善了现有的多个量化算法，并首次实现了仅使用每个权重2比特的大型语言模型量化方法。

    This work studies post-training parameter quantization in large language models (LLMs). We introduce quantization with incoherence processing (QuIP), a new method based on the insight that quantization benefits from incoherent weight and Hessian matrices, i.e., from the weights and the directions in which it is important to round them accurately being unaligned with the coordinate axes. QuIP consists of two steps: (1) an adaptive rounding procedure minimizing a quadratic proxy objective; (2) efficient pre- and post-processing that ensures weight and Hessian incoherence via multiplication by random orthogonal matrices. We complement QuIP with the first theoretical analysis for an LLM-scale quantization algorithm, and show that our theory also applies to an existing method, OPTQ. Empirically, we find that our incoherence preprocessing improves several existing quantization algorithms and yields the first LLM quantization methods that produce viable results using only two bits per weight.
    
[^53]: 使用相对位置标签将异构图与实体感知自注意力相结合的阅读理解模型

    Integrating a Heterogeneous Graph with Entity-aware Self-attention using Relative Position Labels for Reading Comprehension Model. (arXiv:2307.10443v1 [cs.CL])

    [http://arxiv.org/abs/2307.10443](http://arxiv.org/abs/2307.10443)

    本文提出了一种新的注意力模式，使用图增强自注意力机制将从异构图中导出的推理知识整合到变压器架构中，从而克服了变压器模型在复杂推理任务中的限制。通过全局-局部注意力、图注意力和关系类型考虑，优化了实体和单词之间的注意力。该模式与相对位置标签相结合，能够与LUKE的实体感知自注意力机制相集成。

    

    尽管变压器模型在机器阅读理解任务中取得了重大进展，但由于输入序列中缺少显式知识，它们仍然面临处理复杂推理任务的限制。本文提出了一种新颖的注意力模式来克服这个限制，它利用增强图自注意力机制将由异构图导出的推理知识整合到变压器架构中。提出的注意力模式包括三个关键要素：单词标记的全局-局部注意力，对实体标记的图注意力，实体标记对相关联的标记显示强烈的注意力而对不相关的标记显示较弱的注意力，以及考虑每个实体标记与单词标记之间的关系类型。这样，如果存在关系，则可以优化两者之间的注意力。该模式与特殊的相对位置标签相结合，使其能够与LUKE的实体感知自注意力机制相集成。

    Despite the significant progress made by transformer models in machine reading comprehension tasks, they still face limitations in handling complex reasoning tasks due to the absence of explicit knowledge in the input sequence. This paper proposes a novel attention pattern to overcome this limitation, which integrates reasoning knowledge derived from a heterogeneous graph into the transformer architecture using a graph-enhanced self-attention mechanism. The proposed attention pattern comprises three key elements: global-local attention for word tokens, graph attention for entity tokens that exhibit strong attention towards tokens connected in the graph as opposed to those unconnected, and the consideration of the type of relationship between each entity token and word token. This results in optimized attention between the two if a relationship exists. The pattern is coupled with special relative position labels, allowing it to integrate with LUKE's entity-aware self-attention mechanism
    
[^54]: 巨型语言模型在意大利生物医学信息提取方面的应用：方法论研究和实际应用的多中心实践

    Advancing Italian Biomedical Information Extraction with Large Language Models: Methodological Insights and Multicenter Practical Application. (arXiv:2306.05323v1 [cs.CL])

    [http://arxiv.org/abs/2306.05323](http://arxiv.org/abs/2306.05323)

    该研究创建了意大利神经精神命名实体识别数据集，并使用巨型语言模型开发出多中心识别模型，整体 F1得分为84.77%。该模型将帮助临床从业者从非结构化的医疗记录中自动提取信息。

    

    医院引入计算机化医疗记录有助于减少手写和信息提取等繁琐操作。然而，由于从非结构化文本医疗记录中提取数据需要时间和精力，因此医疗记录中包含的数据仍然被充分利用程度低。自然语言处理的子领域信息提取可以帮助临床从业者克服这一限制，使用自动化文本挖掘流程。在这项工作中，我们创建了意大利神经精神命名实体识别数据集 PsyNIT，并使用它来开发这一任务的巨型语言模型。此外，我们还进行了多个实验，使用三个外部独立数据集来实现有效的多中心模型，整体 F1 得分为 84.77%，精确率为 83.16%，召回率为 86.44%。我们学到的经验是: (i) 一致的注释过程的关键作用和 (ii) 结合经典方法和“少量训练”的 fine-tuning 策略。

    The introduction of computerized medical records in hospitals has reduced burdensome operations like manual writing and information fetching. However, the data contained in medical records are still far underutilized, primarily because extracting them from unstructured textual medical records takes time and effort. Information Extraction, a subfield of Natural Language Processing, can help clinical practitioners overcome this limitation, using automated text-mining pipelines. In this work, we created the first Italian neuropsychiatric Named Entity Recognition dataset, PsyNIT, and used it to develop a Large Language Model for this task. Moreover, we conducted several experiments with three external independent datasets to implement an effective multicenter model, with overall F1-score 84.77%, Precision 83.16%, Recall 86.44%. The lessons learned are: (i) the crucial role of a consistent annotation process and (ii) a fine-tuning strategy that combines classical methods with a "few-shot" a
    
[^55]: 使用大型语言模型注释进行社会科学中的有效下游统计推断: 基于设计的半监督学习

    Using Large Language Model Annotations for Valid Downstream Statistical Inference in Social Science: Design-Based Semi-Supervised Learning. (arXiv:2306.04746v1 [stat.ME])

    [http://arxiv.org/abs/2306.04746](http://arxiv.org/abs/2306.04746)

    该论文提出了一种新算法，使用大型语言模型（LLMs）输出进行下游统计分析，以实现有效的下游统计推断，并降低标签获取的研究成本80％，同时保证CSS研究的统计属性。

    

    在计算社会科学（CSS）中，研究人员通过分析文档来解释社会和政治现象。在大多数情况下，CSS研究人员首先获取文档的标签，然后使用可解释的回归分析来解释标签。大型语言模型（LLMs）的最近进展可以通过在规模上便宜地注释文档来降低CSS研究成本，但这些替代标签通常是不完美和有偏的。我们提出了一种新算法，用于使用LLMs的输出进行下游统计分析，同时保证与CSS研究基本相关的统计属性-如渐近无偏性和正确的不确定性量化。我们表明，直接在下游统计分析中使用LLM预测的替代标签会导致实质性偏差和无效置信区间，即使替代准确性高达80-90％。为了解决这个问题，我们基于无偏机器学习提出了基于设计的半监督学习（D-SSL）算法，该算法将LLM注释与有针对性的采样相结合，以实现有效的下游统计推断。我们的方法可以将标签获取的CSS研究成本降低80％，而不影响统计分析的有效性。模拟研究和实际数据示例表明，与直接使用LLM预测标签相比，D-SSL可以将回归估计的准确性提高多达40％。

    In computational social science (CSS), researchers analyze documents to explain social and political phenomena. In most scenarios, CSS researchers first obtain labels for documents and then explain labels using interpretable regression analyses in the second step. The recent advancements in large language models (LLMs) can lower costs for CSS research by annotating documents cheaply at scale, but such surrogate labels are often imperfect and biased. We present a new algorithm for using outputs from LLMs for downstream statistical analyses while guaranteeing statistical properties -- like asymptotic unbiasedness and proper uncertainty quantification -- which are fundamental to CSS research. We show that direct use of LLM-predicted surrogate labels in downstream statistical analyses leads to substantial bias and invalid confidence intervals, even with high surrogate accuracy of 80--90\%. To address this, we build on debiased machine learning to propose the design-based semi-supervised le
    
[^56]: 可视化编程中神经任务合成

    Neural Task Synthesis for Visual Programming. (arXiv:2305.18342v1 [cs.LG])

    [http://arxiv.org/abs/2305.18342](http://arxiv.org/abs/2305.18342)

    该论文提出了一种基于神经符号技术的可视化编程任务合成方法NeurTaskSyn。该方法能够针对规范中给出的解决方案代码所需要的编程概念和对可视化任务的限制，自动生成编程任务。

    

    通过合成新的内容，生成式神经模型在增强编程教育方面具有巨大的潜力。我们旨在设计神经模型，能够根据可视化编程环境下给定的规范自动生成编程任务。尽管近年来像 GPT-4 这样的大型生成模型获得了成功，但我们的初步结果显示，这些模型在合成可视化编程任务方面效果不佳，并且在逻辑和空间推理方面存在困难。我们提出了一种新颖的神经符号技术 NeurTaskSyn，该技术能够针对规范中给出的解决方案代码所需要的编程概念和对可视化任务的限制，合成编程任务。NeurTaskSyn 由两个部分构成：第一个部分通过模仿学习程序进行训练，生成可能的解决方案代码，第二个部分通过强化学习程序进行训练，指导底层符号执行引擎生成可视化任务。

    Generative neural models hold great promise in enhancing programming education by synthesizing new content for students. We seek to design neural models that can automatically generate programming tasks for a given specification in the context of visual programming domains. Despite the recent successes of large generative models like GPT-4, our initial results show that these models are ineffective in synthesizing visual programming tasks and struggle with logical and spatial reasoning. We propose a novel neuro-symbolic technique, NeurTaskSyn, that can synthesize programming tasks for a specification given in the form of desired programming concepts exercised by its solution code and constraints on the visual task. NeurTaskSyn has two components: the first component is trained via imitation learning procedure to generate possible solution codes, and the second component is trained via reinforcement learning procedure to guide an underlying symbolic execution engine that generates visua
    
[^57]: 在对话中学习结构因果模型的直觉推理

    Learning a Structural Causal Model for Intuition Reasoning in Conversation. (arXiv:2305.17727v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.17727](http://arxiv.org/abs/2305.17727)

    本文基于对话认知的直觉理论，提出了一个对话认知模型，以解释每个话语如何递归地获得和激活信息通道。通过将其代数转化为结构因果模型，我们进一步实现了该模型在话语级别的关系推理。通过利用变分推断，它解决了隐含原因的问题，并通过证据下界重构了话语的因果表示。

    

    推理是自然语言处理研究中一个至关重要的方面，但是目前的模型，包括大语言模型，在推理方面的处理还不够充分。对话推理作为其中一个关键组成部分，由于缺乏良好设计的认知模型而一直未被充分探索。本文受到对话认知的直觉理论的启发，提出了一个解释每个话语如何递归地获得和激活信息通道的对话认知模型（CCM）。此外，我们还对CCM进行了代数变换，得到了一个结构因果模型（SCM），在一些温和的假设下，SCM与各种因果发现方法兼容。我们进一步提出了SCM在话语级关系推理中的概率实现。通过利用变分推断，它探索了隐含原因的替代方案，解决了其不可观察性的问题，并通过证据下界重构了话语的因果表示。此外，我们还构建了...

    Reasoning, a crucial aspect of NLP research, has not been adequately addressed by prevailing models including Large Language Model. Conversation reasoning, as a critical component of it, remains largely unexplored due to the absence of a well-designed cognitive model. In this paper, inspired by intuition theory on conversation cognition, we develop a conversation cognitive model (CCM) that explains how each utterance receives and activates channels of information recursively. Besides, we algebraically transformed CCM into a structural causal model (SCM) under some mild assumptions, rendering it compatible with various causal discovery methods. We further propose a probabilistic implementation of the SCM for utterance-level relation reasoning. By leveraging variational inference, it explores substitutes for implicit causes, addresses the issue of their unobservability, and reconstructs the causal representations of utterances through the evidence lower bounds. Moreover, we constructed s
    
[^58]: Translatotron 3: 使用单语数据进行语音到语音翻译

    Translatotron 3: Speech to Speech Translation with Monolingual Data. (arXiv:2305.17547v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.17547](http://arxiv.org/abs/2305.17547)

    Translatotron 3提出了一种新方法，使用单语数据进行语音到语音翻译，无需配对的数据或专业建模，展示了保留语言/非语言信息的能力。

    

    本文提出了Translatotron 3的新方法，通过遮蔽自编码器、无监督的嵌入映射和回译将直接语音到语音翻译模型从单声道语音-文本数据集中完全无监督地进行训练。在西班牙语和英语之间的语音到语音翻译任务中，实验结果表明，Translatotron 3优于基准级联系统，在 synthesized Unpaired-Conversational 数据集上报告了18.14 BLEU分数的提高。与需要真实配对数据或专业建模来复制语言/非语言信息的监督方法不同，Translatotron 3展示了它保留了像暂停、说话速度和说话人身份等语言/非语言信息的能力。

    This paper presents Translatotron 3, a novel approach to train a direct speech-to-speech translation model from monolingual speech-text datasets only in a fully unsupervised manner. Translatotron 3 combines masked autoencoder, unsupervised embedding mapping, and back-translation to achieve this goal. Experimental results in speech-to-speech translation tasks between Spanish and English show that Translatotron 3 outperforms a baseline cascade system, reporting 18.14 BLEU points improvement on the synthesized Unpaired-Conversational dataset. In contrast to supervised approaches that necessitate real paired data, which is unavailable, or specialized modeling to replicate para-/non-linguistic information, Translatotron 3 showcases its capability to retain para-/non-linguistic such as pauses, speaking rates, and speaker identity. Audio samples can be found in our website this http URL
    
[^59]: 基于曲率和扭矩的手语视频摘要技术

    Motion-Based Sign Language Video Summarization using Curvature and Torsion. (arXiv:2305.16801v1 [cs.CV])

    [http://arxiv.org/abs/2305.16801](http://arxiv.org/abs/2305.16801)

    该论文介绍了一种基于曲率和扭矩的手语视频摘要技术，能够选出最具信息量的关键帧。

    

    视频摘要技术在很多基于视频的应用中都非常有用。本文介绍了一种新的手语视频摘要技术，该技术利用从视频帧中提取的三维手部运动数据来模型化每一帧中的三维运动。基于此，本文提出了一种基于曲率和扭矩的新型信息函数，以便选择最具信息量的关键帧。

    An interesting problem in many video-based applications is the generation of short synopses by selecting the most informative frames, a procedure which is known as video summarization. For sign language videos the benefits of using the $t$-parameterized counterpart of the curvature of the 2-D signer's wrist trajectory to identify keyframes, have been recently reported in the literature. In this paper we extend these ideas by modeling the 3-D hand motion that is extracted from each frame of the video. To this end we propose a new informative function based on the $t$-parameterized curvature and torsion of the 3-D trajectory. The method to characterize video frames as keyframes depends on whether the motion occurs in 2-D or 3-D space. Specifically, in the case of 3-D motion we look for the maxima of the harmonic mean of the curvature and torsion of the target's trajectory; in the planar motion case we seek for the maxima of the trajectory's curvature. The proposed 3-D feature is experime
    
[^60]: ToolkenGPT：通过工具嵌入扩充冻结语言模型

    ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via Tool Embeddings. (arXiv:2305.11554v1 [cs.CL])

    [http://arxiv.org/abs/2305.11554](http://arxiv.org/abs/2305.11554)

    本论文提出了一种名为ToolkenGPT的方法，将大型语言模型（LLMs）与外部工具相结合，引入了toolken的概念，利用tool embeddings实现无缝交互，同时在各种下游任务上展示出了良好的效果。

    

    将大型语言模型与外部工具结合起来解决复杂问题已成为一种有前途的方法。然而，传统方法需要用工具演示数据对LLM进行微调，既费时又受限于预定义的工具集。最近的上下文学习范例缓解了这些问题，但是有限的上下文长度只允许演示几次，导致对工具的理解不够充分。此外，当有大量工具可供选择时，上下文学习可能完全无法正常工作。在本文中，我们提出了一种$\textbf{ToolkenGPT}$的替代方法，将两种方法的优点结合起来。我们的方法将每个$\underline{工具}$表示为一个$\underline{token}$（$\textit{toolken}$），并为其学习一个嵌入，使得工具调用与生成常规单词标记的方式相同。一旦触发了toolken，LLM被提示完成工具执行所需的参数。ToolkenGPT提供了以下贡献：1）引入了toolken的概念，以扩充LLM与外部工具的交互，2）提出了一种新的学习范例，利用tool embeddings实现无缝交互，3）在各种下游任务上展示了我们方法的有效性。

    Augmenting large language models (LLMs) with external tools has emerged as a promising approach to solving complex problems. However, traditional methods, which finetune LLMs with tool demonstration data, can be both costly and restricted to a predefined set of tools. Recent in-context learning paradigm alleviates these issues, but the limited context length only allows for a few shots of demonstrations, leading to suboptimal understandings of the tools. Moreover, when there are numerous tools to choose from, in-context learning could completely fail to work. In this paper, we propose an alternative approach, $\textbf{ToolkenGPT}$, which combines the benefits of both sides. Our approach represents each $\underline{tool}$ as a to$\underline{ken}$ ($\textit{toolken}$) and learns an embedding for it, enabling tool calls in the same way as generating a regular word token. Once a toolken is triggered, the LLM is prompted to complete arguments for the tool to execute. ToolkenGPT offers the f
    
[^61]: 民主扩散语言模型

    Democratized Diffusion Language Model. (arXiv:2305.10818v1 [cs.LG])

    [http://arxiv.org/abs/2305.10818](http://arxiv.org/abs/2305.10818)

    本文提出了一个基于CDCD框架的民主扩散语言模型（DDLM），并通过GLUE基准测试了其知识转移能力，为研究人员提供了DDLM训练和评估流程以及已训练的DDLM模型。

    

    尽管扩散模型在自然语言处理中有潜在好处，但目前公开的实现、训练模型或可重现的训练程序并不存在。为解决这些挑战，我们提出了基于CDCD框架的民主扩散语言模型（DDLM）。我们提出了一种用C4数据集简化的DDLM训练流程，并对训练模型的行为进行了深入分析。此外，我们引入了一种用于速度更快的采样的新型早期退出策略，该策略针对使用得分插值训练的模型。由于此前没有研究旨在使用预训练扩散LM解决下游任务（例如分类任务），我们在GLUE基准上进行了实验，以研究DDLM的知识转移能力。通过本文，我们提出了可供其他研究人员使用的DDLM训练和评估流程以及预先训练的DDLM模型，这些模型可在未来的D相关的研究中使用。

    Despite the potential benefits of Diffusion Models for NLP applications, publicly available implementations, trained models, or reproducible training procedures currently need to be publicly available. We present the Democratized Diffusion Language Model (DDLM), based on the Continuous Diffusion for Categorical Data (CDCD) framework, to address these challenges. We propose a simplified training procedure for DDLM using the C4 dataset and perform an in-depth analysis of the trained model's behavior. Furthermore, we introduce a novel early-exiting strategy for faster sampling with models trained with score interpolation. Since no previous works aimed at solving downstream tasks with pre-trained Diffusion LM (e.g., classification tasks), we experimented with GLUE Benchmark to study the ability of DDLM to transfer knowledge. With this paper, we propose available training and evaluation pipelines to other researchers and pre-trained DDLM models, which could be used in future research with D
    
[^62]: DinoSR：自监督语音表示学习中的自蒸馏和在线聚类

    DinoSR: Self-Distillation and Online Clustering for Self-supervised Speech Representation Learning. (arXiv:2305.10005v1 [cs.CL])

    [http://arxiv.org/abs/2305.10005](http://arxiv.org/abs/2305.10005)

    本研究提出了DinoSR模型，它结合了遮蔽语言建模、自蒸馏和在线聚类等概念，能够在自监督语音表示学习任务中产生很好的效果，超越了以前的最新技术水平。

    

    本文介绍了自蒸馏和在线聚类用于自监督语音表示学习的DinoSR模型，它结合了遮蔽语言建模、自蒸馏和在线聚类这些概念，并展示它们相互补充，形成了一种强大的语音表示学习模型。DinoSR首先使用教师网络从输入音频中提取上下文化的嵌入向量，然后在嵌入向量上运行在线聚类系统以产生机器发现的音素库存，最后使用已离散化的标记指导学生网络。我们展示了DinoSR在多个下游任务中超越了以前的最新技术，并提供了模型和学习离散单元的详细分析。匿名期结束后，我们将提供源代码。

    In this paper, we introduce self-distillation and online clustering for self-supervised speech representation learning (DinoSR) which combines masked language modeling, self-distillation, and online clustering. We show that these concepts complement each other and result in a strong representation learning model for speech. DinoSR first extracts contextualized embeddings from the input audio with a teacher network, then runs an online clustering system on the embeddings to yield a machine-discovered phone inventory, and finally uses the discretized tokens to guide a student network. We show that DinoSR surpasses previous state-of-the-art performance in several downstream tasks, and provide a detailed analysis of the model and the learned discrete units. The source code will be made available after the anonymity period.
    
[^63]: SwissBERT：瑞士的多语言语言模型

    SwissBERT: The Multilingual Language Model for Switzerland. (arXiv:2303.13310v1 [cs.CL])

    [http://arxiv.org/abs/2303.13310](http://arxiv.org/abs/2303.13310)

    该论文介绍了SwissBERT，它是一个专门为处理瑞士相关文本而创建的多语言语言模型，SwissBERT在与瑞士相关的自然语言理解任务上的效果优于以前的模型。

    

    我们介绍了SwissBERT，这是一个专门为处理与瑞士相关的文本而创建的掩码语言模型。 SwissBERT是一种预训练模型，我们将其调整为能够处理瑞士国家语言 -德语、法语、意大利语和罗曼什语的新闻文章。我们评估了SwissBERT在与瑞士相关的自然语言理解任务上的效果，发现它在这些任务上的表现往往优于以前的模型，特别是在处理当代新闻和/或罗曼什语格里斯昆时。由于SwissBERT使用语言适配器，因此未来的工作可能将其扩展到瑞士德语方言中。该模型和我们的开源代码公开发布在https://github.com/ZurichNLP/swissbert。

    We present SwissBERT, a masked language model created specifically for processing Switzerland-related text. SwissBERT is a pre-trained model that we adapted to news articles written in the national languages of Switzerland -German, French, Italian, and Romansh. We evaluate SwissBERT on natural language understanding tasks related to Switzerland and find that it tends to outperform previous models on these tasks, especially when processing contemporary news and/or Romansh Grischun. Since SwissBERT uses language adapters, it may be extended to Swiss German dialects in future work. The model and our open-source code are publicly released at https://github.com/ZurichNLP/swissbert.
    
[^64]: 应用SMILES序列的Transformer模型在学习手性时存在困难

    Difficulty in learning chirality for Transformer fed with SMILES. (arXiv:2303.11593v1 [cs.LG])

    [http://arxiv.org/abs/2303.11593](http://arxiv.org/abs/2303.11593)

    应用SMILES序列的Transformer模型在学习分子结构的整体性和手性方面存在困难，需要进行长时间的训练。生成的描述符用于分子性质预测时的准确率从开始到训练结束都是相似的。

    

    近年来，基于对极其多样的分子进行表示学习的描述符生成已经得到了发展，特别是那些将自然语言处理（NLP）模型应用于SMILES，即分子结构的文字表示的模型。然而，关于这些模型如何理解化学结构的研究很少。为了解决这个问题，我们调查了一种代表性的NLP模型——Transformer，在学习SMILES和化学结构之间的关系。结果表明，虽然Transformer快速学习分子的部分结构，但需要进行长时间的训练才能理解整体结构。与之一致的是，在不同的学习步骤中生成的描述符用于分子性质预测时的准确率从开始到训练结束都是相似的。此外，我们发现Transformer需要特别长的训练时间才能学习手性，并且有时会出现低翻译准确率的停滞现象。

    Recent years have seen development of descriptor generation based on representation learning of extremely diverse molecules, especially those that apply natural language processing (NLP) models to SMILES, a literal representation of molecular structure. However, little research has been done on how these models understand chemical structure. To address this, we investigated the relationship between the learning progress of SMILES and chemical structure using a representative NLP model, the Transformer. The results suggest that while the Transformer learns partial structures of molecules quickly, it requires extended training to understand overall structures. Consistently, the accuracy of molecular property predictions using descriptors generated from models at different learning steps was similar from the beginning to the end of training. Furthermore, we found that the Transformer requires particularly long training to learn chirality and sometimes stagnates with low translation accura
    
[^65]: 关于COVID-19疫苗的波斯推文的大规模分析

    A Large-Scale Analysis of Persian Tweets Regarding Covid-19 Vaccination. (arXiv:2302.04511v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.04511](http://arxiv.org/abs/2302.04511)

    本文利用Twitter数据进行了对伊朗公众对COVID-19疫苗的意见进行的全面分析，结果显示该疫苗引起了广泛关注，涉及政府问题、安全性、犹豫不决和副作用等方面。

    

    COVID-19大流行对我们的生活产生了巨大影响，尤其是人们的互动。引入COVID-19疫苗后，关于接种疫苗与否的正反意见都有所提出。本文利用从Twitter获取的数据，包括推文和用户资料，对伊朗公众对冠状病毒疫苗的意见进行了全面分析。为此，我们采用了搜索查询技术和主题建模方法来提取与疫苗相关的推文。我们利用基于转换器的模型对推文内容进行分类，并提取围绕接种的主题。我们还进行了情感分析，以评估公众在这一话题上的快乐和愤怒程度。我们的结果表明，COVID-19疫苗已引起了各种不同角度的高度关注，如政府问题、安全性或犹豫不决以及副作用等。

    The Covid-19 pandemic had an enormous effect on our lives, especially on people's interactions. By introducing Covid-19 vaccines, both positive and negative opinions were raised over the subject of taking vaccines or not. In this paper, using data gathered from Twitter, including tweets and user profiles, we offer a comprehensive analysis of public opinion in Iran about the Coronavirus vaccines. For this purpose, we applied a search query technique combined with a topic modeling approach to extract vaccine-related tweets. We utilized transformer-based models to classify the content of the tweets and extract themes revolving around vaccination. We also conducted an emotion analysis to evaluate the public happiness and anger around this topic. Our results demonstrate that Covid-19 vaccination has attracted considerable attention from different angles, such as governmental issues, safety or hesitancy, and side effects. Moreover, Coronavirus-relevant phenomena like public vaccination and t
    
[^66]: 数据中心机器学习的重新标签法

    The Re-Label Method For Data-Centric Machine Learning. (arXiv:2302.04391v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.04391](http://arxiv.org/abs/2302.04391)

    本文提出了一种重新标签的方法来解决手动标记的数据中存在噪声的问题，并通过模型预测来辅助人类标记噪声数据。实验证明此方法适用于多类深度学习任务。

    

    在深度学习应用中，手动标记的数据在一定程度上存在噪声。为了解决这个问题，并在开发数据集上获得90分以上的成绩，本文提出了一种简单的方法来找出噪声数据，并通过采用模型预测作为人类标记的参考来重新标记噪声数据。本文阐述了我们在广泛的深度学习任务中的想法，包括分类、序列标记、物体检测、序列生成、点击率预测。实验结果和人类评估结果验证了我们的想法。

    In industry deep learning application, our manually labeled data has a certain number of noisy data. To solve this problem and achieve more than 90 score in dev dataset, we present a simple method to find the noisy data and re-label the noisy data by human, given the model predictions as references in human labeling. In this paper, we illustrate our idea for a broad set of deep learning tasks, includes classification, sequence tagging, object detection, sequence generation, click-through rate prediction. The experimental results and human evaluation results verify our idea.
    
[^67]: NLP中的不良偏见：避免衡量危机

    Undesirable biases in NLP: Averting a crisis of measurement. (arXiv:2211.13709v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.13709](http://arxiv.org/abs/2211.13709)

    这项研究提供了一个跨学科的方法来探讨NLP模型偏见的问题，通过采用心理测量学的视角，特别关注构念效度和测量工具的信度，在衡量模型偏见的情境中如何应用。

    

    随着大型语言模型和自然语言处理（NLP）技术的快速发展和普及，预测其使用可能对人们造成伤害变得至关重要。近年来，一个受到关注的问题是这一技术在行为中显示出有害偏见。尽管已经投入了大量的努力来评估和减轻这些偏见，但我们衡量NLP模型偏见的方法存在严重问题（例如，通常不清楚它们到底衡量了什么）。在本文中，我们采用心理测量学的视角，提供了一个跨学科的方法来讨论NLP模型偏见的问题，心理测量学专注于衡量不直接可观察到的概念，如偏见。具体而言，我们将探讨心理测量学的两个核心概念，即构念效度和测量工具的信度，并讨论它们在衡量模型偏见的情境中如何应用。我们的目标是提供一个全面的视角来解决这个问题。

    As Large Language Models and Natural Language Processing (NLP) technology rapidly develops and spreads into daily life, it becomes crucial to anticipate how its use could harm people. One problem that has received a lot of attention in recent years is that this technology has displayed harmful biases in its behavior. Although a lot of effort has been invested in assessing and mitigating these biases, our methods of measuring the biases of NLP models have serious problems (e.g., it is often unclear what they actually measure). In this paper, we provide an interdisciplinary approach to discussing the issue of NLP model bias by adopting the lens of psychometrics -- a field specialized in the measurement of concepts like bias that are not directly observable. In particular, we will explore two central notions from psychometrics, the construct validity and the reliability of measurement tools, and discuss how they can be applied in the context of measuring model bias. Our goal is to provide
    
[^68]: NormSAGE: 多语言多文化对话中的规范发现

    NormSAGE: Multi-Lingual Multi-Cultural Norm Discovery from Conversations On-the-Fly. (arXiv:2210.08604v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.08604](http://arxiv.org/abs/2210.08604)

    NormSAGE是一个用于对话驱动的多语言多文化规范发现的框架，利用预训练的GPT-3语言模型进行知识引发，并通过自验证机制确保发现的规范正确且与源对话相关。

    

    规范发现对于理解和推理人类交流和互动中可接受的行为和潜在违规行为非常重要。我们介绍了NormSage，一个用于解决新颖任务的框架，即基于语言模型提示和自验证的对话驱动的多语言多文化规范发现。NormSAGE利用预训练的GPT-3语言模型架构的表达能力和隐式知识，通过针对规范发现任务和对话背景的有向问题引发关于规范的知识。它还通过自验证机制解决语言模型虚构的风险，确保发现的规范是正确的，并且在很大程度上与它们的源对话相关。评估结果显示，与基准相比，我们的方法能够在实时对话中发现更多相关且有洞察力的规范（Likert评分中增加了10%以上）。

    Norm discovery is important for understanding and reasoning about the acceptable behaviors and potential violations in human communication and interactions. We introduce NormSage, a framework for addressing the novel task of conversation-grounded multi-lingual, multi-cultural norm discovery, based on language model prompting and self-verification. NormSAGE leverages the expressiveness and implicit knowledge of the pretrained GPT-3 language model backbone, to elicit knowledge about norms through directed questions representing the norm discovery task and conversation context. It further addresses the risk of language model hallucination with a self-verification mechanism ensuring that the norms discovered are correct and are substantially grounded to their source conversations. Evaluation results show that our approach discovers significantly more relevant and insightful norms for conversations on-the-fly compared to baselines (>10+% in Likert scale rating). The norms discovered from Ch
    
[^69]: 对于自然语言处理中忠实的模型解释的探索：一项调查研究

    Towards Faithful Model Explanation in NLP: A Survey. (arXiv:2209.11326v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.11326](http://arxiv.org/abs/2209.11326)

    本调查研究回顾了超过110种自然语言处理模型解释方法，并从忠实性的角度进行了分类和综合。研究介绍了忠实解释的最新进展，并讨论了各个方法的优点、缺点以及未来的挑战。

    

    端到端的神经网络自然语言处理模型一直以来都难以理解。这引发了近年来许多关于模型可解释性的努力。其中一个解释模型的要求是忠实性，即解释应准确地表达模型预测背后的推理过程。本调查通过忠实性的视角对超过110种自然语言处理模型解释方法进行了回顾。我们首先讨论忠实性的定义和评估，以及其对可解释性的意义。然后，我们介绍了忠实解释中的最新进展，并将现有方法分为五个类别：基于相似性的方法、模型内部结构的分析、反向传播方法、反事实干预和自解释模型。对于每个类别，我们综合了其代表性研究、优点和缺点。最后，我们总结了它们的共同优点和挑战，并展望了未来的研究方向。

    End-to-end neural Natural Language Processing (NLP) models are notoriously difficult to understand. This has given rise to numerous efforts towards model explainability in recent years. One desideratum of model explanation is faithfulness, i.e. an explanation should accurately represent the reasoning process behind the model's prediction. In this survey, we review over 110 model explanation methods in NLP through the lens of faithfulness. We first discuss the definition and evaluation of faithfulness, as well as its significance for explainability. We then introduce recent advances in faithful explanation, grouping existing approaches into five categories: similarity-based methods, analysis of model-internal structures, backpropagation-based methods, counterfactual intervention, and self-explanatory models. For each category, we synthesize its representative studies, strengths, and weaknesses. Finally, we summarize their common virtues and remaining challenges, and reflect on future wo
    
[^70]: 深度NLP模型中突出神经元的发现

    Discovering Salient Neurons in Deep NLP Models. (arXiv:2206.13288v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2206.13288](http://arxiv.org/abs/2206.13288)

    使用语言相关分析技术，我们发现在深度NLP模型中存在一些突出的神经元，这些神经元能够捕捉特定的语言属性，而且信息保存冗余程度较高。调整预训练模型对下游NLP任务的影响以及不同架构学习不同语言属性的差异也得到了研究。

    

    在理解深度NLP模型中学到的表示和它们所捕捉到的知识方面，已经做了很多工作，但对于个别神经元的关注很少。我们提出了一种称为语言相关分析的技术来提取模型中的突出神经元，以了解这种知识在神经元中是如何保留的。我们进行了精细的分析来回答以下问题：（i）我们能否识别出网络中捕捉特定语言属性的神经元子集？（ii）神经元在网络中是如何分布的？（iii）信息保存得有多冗余？（iv）通过将预训练模型调整到下游的NLP任务，如何影响所学的语言知识？（v）不同的架构在学习不同的语言属性方面有何不同？我们的数据驱动、定量分析揭示了一些有趣的发现：

    While a lot of work has been done in understanding representations learned within deep NLP models and what knowledge they capture, little attention has been paid towards individual neurons. We present a technique called as Linguistic Correlation Analysis to extract salient neurons in the model, with respect to any extrinsic property - with the goal of understanding how such a knowledge is preserved within neurons. We carry out a fine-grained analysis to answer the following questions: (i) can we identify subsets of neurons in the network that capture specific linguistic properties? (ii) how localized or distributed neurons are across the network? iii) how redundantly is the information preserved? iv) how fine-tuning pre-trained models towards downstream NLP tasks, impacts the learned linguistic knowledge? iv) how do architectures vary in learning different linguistic properties? Our data-driven, quantitative analysis illuminates interesting findings: (i) we found small subsets of neuro
    
[^71]: 弱监督关系抽取的表示学习

    Representation Learning for Weakly Supervised Relation Extraction. (arXiv:2105.00815v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2105.00815](http://arxiv.org/abs/2105.00815)

    本研究关注如何通过无监督预训练来改进在有限训练数据情况下的监督基线系统性能，并分析了传统手工特征在关系抽取中可能存在的数据稀疏性问题。

    

    近年来，信息抽取以及其中的子任务关系抽取取得了快速发展。关系抽取能够在句子中检测实体之间的语义关系。目前，许多高效的方法已被应用于关系抽取任务中。监督学习方法尤其具有良好的性能。然而，仍然存在许多难题。其中最严重的问题之一是手动标记数据难以获取。在大多数情况下，有限的训练数据等于较差的性能。因此，在只有有限训练数据的情况下，我们关注如何通过无监督预训练来改进我们的监督基线系统的性能。特征是改进监督方法的关键组成部分之一。传统方法通常使用手工特征，这些特征需要专业知识和昂贵的人力。然而，这种类型的特征可能会受到数据稀疏性的影响。

    Recent years have seen rapid development in Information Extraction, as well as its subtask, Relation Extraction. Relation Extraction is able to detect semantic relations between entities in sentences. Currently, many efficient approaches have been applied to relation extraction tasks. Supervised learning approaches especially have good performance. However, there are still many difficult challenges. One of the most serious problems is that manually labeled data is difficult to acquire. In most cases, limited data for supervised approaches equals lousy performance. Thus here, under the situation with only limited training data, we focus on how to improve the performance of our supervised baseline system with unsupervised pre-training. Feature is one of the key components in improving the supervised approaches. Traditional approaches usually apply hand-crafted features, which require expert knowledge and expensive human labor. However, this type of feature might suffer from data sparsity
    
[^72]: 使用动态容量槽注意力从字符序列中诱导有意义的单元

    Inducing Meaningful Units from Character Sequences with Dynamic Capacity Slot Attention. (arXiv:2102.01223v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2102.01223](http://arxiv.org/abs/2102.01223)

    该论文提出了一种无监督的分布式方法，使用动态容量槽注意力模型从字符序列中学习抽象有意义单元，成功发现了与先前提出的单元相似的、适用于更高级别抽象的可捕捉有意义信息的单元。

    

    字符本身并不传达意义，但字符序列却可以。我们提出了一种无监督的分布式方法，用于学习字符序列中的抽象有意义单元。我们的动态容量槽注意力模型不是对序列进行分割，而是发现序列中对象的连续表示，扩展了图像中对象发现的架构。我们对不同语言训练模型，并使用正向和反向探测分类器评估所得到表示的质量。实验证明，我们的模型成功地发现了与先前提出的单元在形式、内容和抽象级别上相似的单元，并显示了在更高级别的抽象中捕捉有意义信息的潜力。

    Characters do not convey meaning, but sequences of characters do. We propose an unsupervised distributional method to learn the abstract meaningful units in a sequence of characters. Rather than segmenting the sequence, our Dynamic Capacity Slot Attention model discovers continuous representations of the objects in the sequence, extending an architecture for object discovery in images. We train our model on different languages and evaluate the quality of the obtained representations with forward and reverse probing classifiers. These experiments show that our model succeeds in discovering units which are similar to those proposed previously in form, content and level of abstraction, and which show promise for capturing meaningful information at a higher level of abstraction.
    
[^73]: 从人类的纠错中学习

    Learning From How Humans Correct. (arXiv:2102.00225v14 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2102.00225](http://arxiv.org/abs/2102.00225)

    本研究提出了一种从人类矫正中学习的方法。通过标注数据中的噪声数据，收集纠错信息，并将其注入至深度学习模型中，成功将文本分类准确度提升了1.7个百分点。

    

    在工业自然语言处理应用中，我们手动标注的数据中存在一定数量的噪声数据。我们提出了一种简单的方法来找到噪声数据并手动重新标注它们，同时收集纠错信息。然后，我们提出了一种将人类纠错信息融入深度学习模型的新方法。人类知道如何纠正噪声数据，因此纠错信息可以注入到深度学习模型中。我们在自己的文本分类数据集上进行了实验，该数据集是手动标注的，因为我们重新标注了我们数据集中的噪声数据，以适用于我们的工业应用。实验结果显示，我们的方法将分类准确度从91.7%提升到92.5%。91.7%的准确度是在修正后的数据集上训练的，它将基线准确度从83.3%提升到91.7%。

    In industry NLP application, our manually labeled data has a certain number of noisy data. We present a simple method to find the noisy data and re-label them manually, meanwhile we collect the correction information. Then we present novel method to incorporate the human correction information into deep learning model. Human know how to correct noisy data. So the correction information can be inject into deep learning model. We do the experiment on our own text classification dataset, which is manually labeled, because we re-label the noisy data in our dataset for our industry application. The experiment result shows that our method improve the classification accuracy from 91.7% to 92.5%. The 91.7% accuracy is trained on the corrected dataset, which improve the baseline from 83.3% to 91.7%.
    

