# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [HiPrompt: Few-Shot Biomedical Knowledge Fusion via Hierarchy-Oriented Prompting.](http://arxiv.org/abs/2304.05973) | HiPrompt是一个监督效率高的知识融合框架，通过层次导向提示和少样本推理能力，弥补了生物医学知识融合和神经嵌入模型之间的差距。 |
| [^2] | [Boosted Prompt Ensembles for Large Language Models.](http://arxiv.org/abs/2304.05970) | 本文提出了一种增强提示集成方法，可以使用小型数据集构建集成提示提高大型语言模型的性能，优于单提示输出空间集成和袋装提示空间集成。 |
| [^3] | [ASL Citizen: A Community-Sourced Dataset for Advancing Isolated Sign Language Recognition.](http://arxiv.org/abs/2304.05934) | ASL Citizen是目前最大的独立手语识别数据集，可用于手语字典检索，利用该数据集训练的机器学习分类器在度量标准上取得显著进展，例如在训练或验证中未出现的用户的视频上，实现了62％的准确性和90％的前10项检索召回率。 |
| [^4] | [ReDWINE: A Clinical Datamart with Text Analytical Capabilities to Facilitate Rehabilitation Research.](http://arxiv.org/abs/2304.05929) | ReDWINE是一个具有文本分析能力的临床数据集，将UPMC医疗保健系统收集的康复相关EHR数据转换为OHDSI格式。它提供了一些丰富的数据元素，包括诊断、程序、药物、实验室检测结果和生命体征，可用于回答有关康复和物理医学的研究问题。 |
| [^5] | [Learning Homographic Disambiguation Representation for Neural Machine Translation.](http://arxiv.org/abs/2304.05860) | 本文提出了一种利用同义词句子建立同形异义词词级消歧表示（HDR）以改进神经机器翻译的方法。 |
| [^6] | [Rethinking Dense Retrieval's Few-Shot Ability.](http://arxiv.org/abs/2304.05845) | 本文提出了一个定制的FewDR数据集和一个统一的评估基准，以解决现有方法在少量数据集上评估时的不一致性问题，使得DR模型能够在基类和新颖类上进行连续训练，从而提高少样本密集检索的推广能力。 |
| [^7] | [Measuring Gender Bias in West Slavic Language Models.](http://arxiv.org/abs/2304.05783) | 本研究分析了西斯拉夫语言模型中的性别偏差，发现捷克语、波兰语和斯洛伐克语均存在相似程度的性别偏见。这一研究填补了研究非英语语言模型性别偏见的空白。 |
| [^8] | [Measuring Normative and Descriptive Biases in Language Models Using Census Data.](http://arxiv.org/abs/2304.05764) | 本文介绍了一种在预训练语言模型中测量规范和描述性职业分布偏差的方法，并通过使用官方的人口普查数据来探测多种语言模型对齐程度。 |
| [^9] | [Global Prompt Cell: A Portable Control Module for Effective Prompt.](http://arxiv.org/abs/2304.05642) | 全局提示单元(GPC)是一种用于调整预训练模型的可移植控制模块。它可以在所有编码器层中选择性地保留提示信息，从而提高了 5.8% 的 SuperGLUE 数据集的性能表现。 |
| [^10] | [ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning.](http://arxiv.org/abs/2304.05613) | 这篇论文评估了ChatGPT在22种不同的语言中的表现，并创建了一个多语言基准数据集。结果表明ChatGPT在各种语言和任务上表现出显著的一致性和功效，这为多语言学习和LLMs的研究提供了强有力的支持。 |
| [^11] | [Semantic Feature Verification in FLAN-T5.](http://arxiv.org/abs/2304.05591) | 本研究表明大规模语言模型可以极大地增强传统的语义特征规范验证方法，使之能够捕捉超过人类规范范畴的信息，对于我们理解人类和机器的概念表示具有重要意义。 |
| [^12] | [Does Informativeness Matter? Active Learning for Educational Dialogue Act Classification.](http://arxiv.org/abs/2304.05578) | 本文研究基于主动学习方法的教育对话行为分类，提出了一种新的方法来选择信息样本，并且能够优于随机抽样方法和其他AL方法。 |
| [^13] | [Distinguishing ChatGPT(-3.5, -4)-generated and human-written papers through Japanese stylometric analysis.](http://arxiv.org/abs/2304.05534) | 本研究通过比较GPT(-3.5和-4)生成的日语文体特征与人类写作的学术论文，证明了它们在文体特征上有显著区别。 |
| [^14] | [Understanding Causality with Large Language Models: Feasibility and Opportunities.](http://arxiv.org/abs/2304.05524) | 本文评估了大型语言模型回答因果问题的能力，发现它们可以回答基于已有因果知识的问题，但对于发现新知识或高风险决策任务的高精度要求不足。未来可以通过启用显式和隐式的因果模块以及深度因果感知的LLMs来解决这些问题。 |
| [^15] | [MoMo: A shared encoder Model for text, image and multi-Modal representations.](http://arxiv.org/abs/2304.05523) | MoMo是一个自监督的共享编码器模型，可以用于处理文本、图像和多模态数据，并且具备高效的性能。通过单一的变压器和阶段性的训练策略，在保留信息的同时，使用更少的参数和预训练数据，取得了与强模型相当的表现。 |
| [^16] | [Mathematical and Linguistic Characterization of Orhan Pamuk's Nobel Works.](http://arxiv.org/abs/2304.05512) | 本研究以诺贝尔文学奖得主奥尔罕·帕慕克的著作为例子，通过计算文本中字母和单词的数量，使用分形几何方法计算了他的文本的分形维度，并与应用于字母和单词的Zipf定律进行比较。发现小说《我的名字叫红》的Zipf维度与他的其他小说有很大的不同，但语言学上并没有根本的区别。 |
| [^17] | [chatIPCC: Grounding Conversational AI in Climate Science.](http://arxiv.org/abs/2304.05510) | chatIPCC是一个基于气候科学的对话型人工智能系统，通过整合IPCC AR6中的信息来增强GPT-4模型，并提供可靠、科学准确的答案。 |
| [^18] | [User Adaptive Language Learning Chatbots with a Curriculum.](http://arxiv.org/abs/2304.05489) | 本文研究了一种基于学科设置的自适 应语言学习聊天机器人，该机器人采用词汇限制解码引导系统生成符合学生课程设置的语言，经过在中学生学习英语中的实验结果表明，该系统可以提高学习效果和交流体验。 |
| [^19] | [A Survey of Resources and Methods for Natural Language Processing of Serbian Language.](http://arxiv.org/abs/2304.05468) | 塞尔维亚语是一种低资源、高屈折语言，自然语言处理具有挑战性。过去三十年中，有许多倡议开展了塞尔维亚语自然语言处理的资源和方法的开发。 |
| [^20] | [Zero-shot Temporal Relation Extraction with ChatGPT.](http://arxiv.org/abs/2304.05454) | 本文研究了基于ChatGPT的零样本时间关系抽取，设计了三种提示技术来拆分任务并评估ChatGPT，实验表明ChatGPT的表现与监督方法存在很大差距，但它可以更正确地推断出更多的小关系类。 |
| [^21] | [Galactic ChitChat: Using Large Language Models to Converse with Astronomy Literature.](http://arxiv.org/abs/2304.05406) | 本论文展示了使用OpenAI GPT-4大型语言模型通过上下文提示与天文学文献进行交互的潜力。该模型可用于提供多文献上下文下的详细答案，为天文学界探索开辟了有前途的途径。 |
| [^22] | [Controllable Textual Inversion for Personalized Text-to-Image Generation.](http://arxiv.org/abs/2304.05265) | 本文提出了一种名为COTI的技术，通过引入理论指导的损失目标和全面的加权评分机制，并结合主动学习范式来解决文本反转时的困难，提供了一个强大，数据效率高，易于使用的框架。 |
| [^23] | [Large Language Models as Master Key: Unlocking the Secrets of Materials Science with GPT.](http://arxiv.org/abs/2304.02213) | 本文介绍了一个新的自然语言处理任务——结构化信息推理（SIS），利用GPT-3模型能够准确提取材料科学设备层面的信息，并通过实验预测PCE和反向预测参数，展示了大型语言模型在材料学中的巨大潜力。 |
| [^24] | [Sociocultural knowledge is needed for selection of shots in hate speech detection tasks.](http://arxiv.org/abs/2304.01890) | HATELEXICON是一个包含巴西，德国，印度和肯尼亚仇恨言论的词汇表，利用其可以提高模型在训练中的性能表现。 |
| [^25] | [A Survey of Large Language Models.](http://arxiv.org/abs/2303.18223) | 本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。 |
| [^26] | [Capabilities of GPT-4 on Medical Challenge Problems.](http://arxiv.org/abs/2303.13375) | 本论文对最先进的LLM——GPT-4在医学能力考试和基准数据集上进行了全面评估，结果显示其表现出色，有助于医学相关领域的研究和应用。 |
| [^27] | [Mind meets machine: Unravelling GPT-4's cognitive psychology.](http://arxiv.org/abs/2303.11436) | 本研究评估了在广泛使用的CommonsenseQA数据集中的一套常识推理问题上，GPT-4的表现及其对常识知识的处理和整合过程，在此过程中我们也发现了其局限性。 |
| [^28] | [A Prototypical Semantic Decoupling Method via Joint Contrastive Learning for Few-Shot Name Entity Recognition.](http://arxiv.org/abs/2302.13610) | 本文提出了一种基于联合对比学习的原型语义解耦方法(PSDC)用于少样本命名实体识别，通过两种屏蔽策略解耦类特定的原型和语境语义原型，防止语义坍塌，实验证明PSDC可以持续优于以前的SOTA方法。 |
| [^29] | [VLSP2022-EVJVQA Challenge: Multilingual Visual Question Answering.](http://arxiv.org/abs/2302.11752) | 该论文介绍了一个新的多语种视觉问答数据集EVJVQA，包括越南语，英语和日语的33,000+问答对，可用于评估多语言VQA系统或模型的性能。 |
| [^30] | [Combat AI With AI: Counteract Machine-Generated Fake Restaurant Reviews on Social Media.](http://arxiv.org/abs/2302.07731) | 本文针对机器生成的虚假评论提出了一种用高质量餐厅评论生成虚假评论并微调GPT输出检测器的方法，该方法预测虚假评论的性能优于现有解决方案。同时，我们还探索了预测非精英评论的模型，并在几个维度上对这些评论进行分析，此类机器生成的虚假评论是社交媒体平台面临的持续挑战。 |
| [^31] | [Continual Pre-training of Language Models.](http://arxiv.org/abs/2302.03241) | 本文研究了语言模型的持续预训练，提出了一种新颖的持续领域自适应预训练方法，使用一系列未标记的领域语料库来逐步适应领域以提高LM在领域内的终端任务表现。该方法通过一个软掩蔽机制来直接控制LM的更新，并使用一种新颖的代理来保留LM中的整体知识，同时对比已学习领域知识和当前全网络的知识来实现知识整合。 |
| [^32] | [Momentum Contrastive Pre-training for Question Answering.](http://arxiv.org/abs/2212.05762) | 提出了一种用于抽取式问题回答的动量对比预训练方法，通过匹配填空式和自然查询-文章样本对的答案概率，能更好地将在填空式样本中学到的知识转移到回答自然问题上。 |
| [^33] | [Towards human-compatible autonomous car: A study of non-verbal Turing test in automated driving with affective transition modelling.](http://arxiv.org/abs/2212.02908) | 本文研究了自动驾驶汽车的人性化问题，通过非语言图灵测试，发现当前AI驾驶员不能创造类似人类的驾乘体验，需要在情感过渡模型中进行改进。 |
| [^34] | [Measuring Reliability of Large Language Models through Semantic Consistency.](http://arxiv.org/abs/2211.05853) | 本研究通过开发语义一致性度量来评估大型预训练语言模型的性能，以比较不同PLM的可靠性，保证其在相同或相似的提示下生成的输出一致。 |
| [^35] | [Gendered Mental Health Stigma in Masked Language Models.](http://arxiv.org/abs/2210.15144) | 面具语言模型存在性别化心理健康歧视，捕捉到了关于性别在心理健康方面的社会歧视，需要考虑性别因素来避免歧视。 |
| [^36] | [LittleBird: Efficient Faster & Longer Transformer for Question Answering.](http://arxiv.org/abs/2210.11870) | LittleBird是一个基于BigBird的问答模型，通过使用更灵活和高效的位置表示方法ALiBi和替换全局信息表示方法来提高速度和内存占用。它可以在短输入的预训练语言模型的基础上，对长输入进行工作并且在低资源的语言中表现良好。 |
| [^37] | [Decomposed Prompting: A Modular Approach for Solving Complex Tasks.](http://arxiv.org/abs/2210.02406) | 分解提示是解决复杂任务的一种新方法，它通过将复杂任务分解成更简单的子任务来委托给设计专门的提示库，优化每个提示的特定子任务，并可以进一步分解、替换或更新。我们的方法在少样本提示和符号推理任务上表现出色，表明具有潜力扩展到更大和更复杂的任务。 |
| [^38] | [Spillover of Antisocial Behavior from Fringe Platforms: The Unintended Consequences of Community Banning.](http://arxiv.org/abs/2209.09803) | 研究表明，禁止问题社区可能导致用户迁移到监管标准较低的边缘平台，而参与这些平台可能会导致在主流平台上的反社会行为增加。 |
| [^39] | [Self-supervised Multi-modal Training from Uncurated Image and Reports Enables Zero-shot Oversight Artificial Intelligence in Radiology.](http://arxiv.org/abs/2208.05140) | 本文提出了一种名为Medical X-VL的视觉语言模型，使用自监督单模型和融合编码器，以实现放射学中的零样本监督人工智能。 |
| [^40] | [Innovations in Neural Data-to-text Generation: A Survey.](http://arxiv.org/abs/2207.12571) | 本文综述了过去十年神经数据生成文本（DTG）领域的创新，将其与其他自然语言生成技术（NLG）区分开来，并强调了关注系统语言能力和公平、公正的DTG研究前景。 |
| [^41] | [NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages.](http://arxiv.org/abs/2205.15960) | 本文开发了10种印度尼西亚低资源语言的第一个平行资源，包括数据集、基准和词典。该资源将有助于激发有关印尼语和其他代表性不足语言的NLP研究。 |
| [^42] | [Do we need Label Regularization to Fine-tune Pre-trained Language Models?.](http://arxiv.org/abs/2205.12428) | 本文研究了不同的标签规范化技术，发现标签规范化通常会提高微调模型的性能，尤其是当使用较小的预训练语言模型时。提出了一种新的无教师网络的知识蒸馏方法，并发现其效果与知识蒸馏相当，但取决于教师网络的大小和下游任务。 |
| [^43] | [TemporalWiki: A Lifelong Benchmark for Training and Evaluating Ever-Evolving Language Models.](http://arxiv.org/abs/2204.14211) | TemporalWiki是一个用来训练和评估不断更新的语言模型的终身基准，通过利用英语维基百科和英语维基数据之间的连续快照差异进行训练和评估，使研究者可以周期性地跟踪LM的保留前一知识和在每个时间点上获取更新/新知识的能力。 |
| [^44] | [Combined Scaling for Zero-shot Transfer Learning.](http://arxiv.org/abs/2111.10050) | 提出了一种名为 BASIC 的综合缩放方法，在零样本迁移学习任务中实现了85.7%的高准确率，并在稳健性基准测试中表现出显着的改进。为了实现这些结果，该方法在数据大小、模型大小和批量大小三个维度上对比学习框架进行了放大。 |

# 详细

[^1]: HiPrompt: 层次导向提示的少样本生物医学知识融合

    HiPrompt: Few-Shot Biomedical Knowledge Fusion via Hierarchy-Oriented Prompting. (arXiv:2304.05973v1 [cs.IR])

    [http://arxiv.org/abs/2304.05973](http://arxiv.org/abs/2304.05973)

    HiPrompt是一个监督效率高的知识融合框架，通过层次导向提示和少样本推理能力，弥补了生物医学知识融合和神经嵌入模型之间的差距。

    

    综合的生物医学知识库可以增强医学决策过程，需要通过统一的索引系统融合来自不同来源的知识图谱。索引系统通常以层次结构组织生物医学术语，以提供细粒度的对齐实体。为了解决生物医学知识融合 (BKF) 任务中监督不足的挑战，研究人员提出了各种无监督方法。然而，这些方法严重依赖于特定的词汇和结构匹配算法，无法捕捉生物医学实体和术语所传达的丰富语义。最近，神经嵌入模型在语义丰富的任务中被证明是有效的，但它们依赖于充足标记数据进行充分训练。为了弥补稀缺标记 BKF 和神经嵌入模型之间的差距，我们提出了 HiPrompt，一个监督效率高的知识融合框架，可以引发大规模语义推理的少样本推理能力。

    Medical decision-making processes can be enhanced by comprehensive biomedical knowledge bases, which require fusing knowledge graphs constructed from different sources via a uniform index system. The index system often organizes biomedical terms in a hierarchy to provide the aligned entities with fine-grained granularity. To address the challenge of scarce supervision in the biomedical knowledge fusion (BKF) task, researchers have proposed various unsupervised methods. However, these methods heavily rely on ad-hoc lexical and structural matching algorithms, which fail to capture the rich semantics conveyed by biomedical entities and terms. Recently, neural embedding models have proved effective in semantic-rich tasks, but they rely on sufficient labeled data to be adequately trained. To bridge the gap between the scarce-labeled BKF and neural embedding models, we propose HiPrompt, a supervision-efficient knowledge fusion framework that elicits the few-shot reasoning ability of large la
    
[^2]: 大型语言模型的增强提示集成

    Boosted Prompt Ensembles for Large Language Models. (arXiv:2304.05970v1 [cs.CL])

    [http://arxiv.org/abs/2304.05970](http://arxiv.org/abs/2304.05970)

    本文提出了一种增强提示集成方法，可以使用小型数据集构建集成提示提高大型语言模型的性能，优于单提示输出空间集成和袋装提示空间集成。

    

    链式思维提示和自一致性等方法已经推动了语言模型推理性能的前沿，而且没有额外的训练。为了进一步提高性能，我们建议为大型语言模型提供一种提示集成方法，该方法使用小型数据集来构建一组少量的提示，这些提示共同构成了一个“增强的提示集成”。每个提示的少数样例是通过渐进式方式选择的，以便在上一个步骤的集成结果不确定时成为“困难”样例。我们证明这种方法在GSM8k和AQuA数据集等方面优于单提示输出空间集成和袋装提示空间集成。我们提出了训练时间和测试时间版本的增强提示，并使用不同级别的可用注释进行了详细的实证研究。

    Methods such as chain-of-thought prompting and self-consistency have pushed the frontier of language model reasoning performance with no additional training. To further improve performance, we propose a prompt ensembling method for large language models, which uses a small dataset to construct a set of few shot prompts that together comprise a ``boosted prompt ensemble''. The few shot examples for each prompt are chosen in a stepwise fashion to be ``hard'' examples on which the previous step's ensemble is uncertain. We show that this outperforms single-prompt output-space ensembles and bagged prompt-space ensembles on the GSM8k and AQuA datasets, among others. We propose both train-time and test-time versions of boosted prompting that use different levels of available annotation and conduct a detailed empirical study of our algorithm.
    
[^3]: ASL Citizen: 一个推进独立手语识别的社区数据集

    ASL Citizen: A Community-Sourced Dataset for Advancing Isolated Sign Language Recognition. (arXiv:2304.05934v1 [cs.CV])

    [http://arxiv.org/abs/2304.05934](http://arxiv.org/abs/2304.05934)

    ASL Citizen是目前最大的独立手语识别数据集，可用于手语字典检索，利用该数据集训练的机器学习分类器在度量标准上取得显著进展，例如在训练或验证中未出现的用户的视频上，实现了62％的准确性和90％的前10项检索召回率。

    

    手语被全球约7000万聋健人士用作主要语言。然而，大多数交流技术运作在口头和书面语言中，导致获取信息存在不公平。为了解决这个问题，我们发布了ASL Citizen，它是迄今为止最大的独立手语识别 (ISLR) 数据集，经过同意收集，包括52个手语者在各种环境中拍摄的2,731个不同手势的83,912个视频。我们建议将这个数据集用于美国手语 (ASL) 的手语字典检索，用户通过自己的网络摄像头演示手语，从字典中检索相匹配的手语。我们展示了利用我们的数据集对监督机器学习分类器进行训练，在与字典检索相关的度量标准上取得了显著进展，例如在训练或验证中未出现的用户的视频上，实现了62％的准确性和90％的前10项检索召回率。

    Sign languages are used as a primary language by approximately 70 million D/deaf people world-wide. However, most communication technologies operate in spoken and written languages, creating inequities in access. To help tackle this problem, we release ASL Citizen, the largest Isolated Sign Language Recognition (ISLR) dataset to date, collected with consent and containing 83,912 videos for 2,731 distinct signs filmed by 52 signers in a variety of environments. We propose that this dataset be used for sign language dictionary retrieval for American Sign Language (ASL), where a user demonstrates a sign to their own webcam with the aim of retrieving matching signs from a dictionary. We show that training supervised machine learning classifiers with our dataset greatly advances the state-of-the-art on metrics relevant for dictionary retrieval, achieving, for instance, 62% accuracy and a recall-at-10 of 90%, evaluated entirely on videos of users who are not present in the training or valida
    
[^4]: ReDWINE：具有文本分析能力的临床数据集，以促进康复研究

    ReDWINE: A Clinical Datamart with Text Analytical Capabilities to Facilitate Rehabilitation Research. (arXiv:2304.05929v1 [cs.CL])

    [http://arxiv.org/abs/2304.05929](http://arxiv.org/abs/2304.05929)

    ReDWINE是一个具有文本分析能力的临床数据集，将UPMC医疗保健系统收集的康复相关EHR数据转换为OHDSI格式。它提供了一些丰富的数据元素，包括诊断、程序、药物、实验室检测结果和生命体征，可用于回答有关康复和物理医学的研究问题。

    

    康复研究专注于确定治疗干预的组成部分，这些组成部分导致恢复和康复的机制，以及最终最大化患者身体、心理和社交功能的最佳干预策略。传统的随机临床试验研究和确定新干预措施面临着很多挑战，如高昂的费用和时间承诺。观察性研究利用现有的临床数据观察干预效果在RCTs方面表现出了几个优点。电子健康记录（EHRs）成为进行观察性研究的日益重要的资源。为支持这些研究，我们开发了一个临床研究数据集ReDWINE（可通过信息学基础设施进行康复研究的康复数据集），将UPMC医疗保健系统收集的康复相关EHR数据转换为支持观察性健康数据科学和信息学（OHDSI）格式。我们还在ReDWINE中实现了一个文本分析系统，允许研究人员从临床笔记中搜索、注释和提取信息以支持研究问题。ReDWINE提供了丰富的数据元素，包括人口统计信息、诊断、程序、药物、实验室检测结果和生命体征。这些数据元素可用于回答有关康复和物理医学的研究问题。

    Rehabilitation research focuses on determining the components of a treatment intervention, the mechanism of how these components lead to recovery and rehabilitation, and ultimately the optimal intervention strategies to maximize patients' physical, psychologic, and social functioning. Traditional randomized clinical trials that study and establish new interventions face several challenges, such as high cost and time commitment. Observational studies that use existing clinical data to observe the effect of an intervention have shown several advantages over RCTs. Electronic Health Records (EHRs) have become an increasingly important resource for conducting observational studies. To support these studies, we developed a clinical research datamart, called ReDWINE (Rehabilitation Datamart With Informatics iNfrastructure for rEsearch), that transforms the rehabilitation-related EHR data collected from the UPMC health care system to the Observational Health Data Sciences and Informatics (OHDS
    
[^5]: 学习同形异义词消歧表示以改进神经机器翻译

    Learning Homographic Disambiguation Representation for Neural Machine Translation. (arXiv:2304.05860v1 [cs.CL])

    [http://arxiv.org/abs/2304.05860](http://arxiv.org/abs/2304.05860)

    本文提出了一种利用同义词句子建立同形异义词词级消歧表示（HDR）以改进神经机器翻译的方法。

    

    同形异义词在神经机器翻译中一直是难点。本文提出一种在潜在空间中解决同形异义词问题的新方法。首先，我们利用“HDR-encoder”在自然语言推理任务中学习通用句子表示。然后，利用WordNet中的同义词句子建立同形异义词词级消歧表示（HDR），调整预训练的HDR-encoder。最后，我们将预训练的HDR-encoder与基于Transformer的NMT在不同方案中相结合来提高翻译准确性。四个翻译方向的实验表明了本方法在增强NMT系统处理同形异义词方面的有效性。

    Homographs, words with the same spelling but different meanings, remain challenging in Neural Machine Translation (NMT). While recent works leverage various word embedding approaches to differentiate word sense in NMT, they do not focus on the pivotal components in resolving ambiguities of homographs in NMT: the hidden states of an encoder. In this paper, we propose a novel approach to tackle homographic issues of NMT in the latent space. We first train an encoder (aka "HDR-encoder") to learn universal sentence representations in a natural language inference (NLI) task. We further fine-tune the encoder using homograph-based synset sentences from WordNet, enabling it to learn word-level homographic disambiguation representations (HDR). The pre-trained HDR-encoder is subsequently integrated with a transformer-based NMT in various schemes to improve translation accuracy. Experiments on four translation directions demonstrate the effectiveness of the proposed method in enhancing the perfor
    
[^6]: 重新思考密集检索的少样本能力

    Rethinking Dense Retrieval's Few-Shot Ability. (arXiv:2304.05845v1 [cs.CL])

    [http://arxiv.org/abs/2304.05845](http://arxiv.org/abs/2304.05845)

    本文提出了一个定制的FewDR数据集和一个统一的评估基准，以解决现有方法在少量数据集上评估时的不一致性问题，使得DR模型能够在基类和新颖类上进行连续训练，从而提高少样本密集检索的推广能力。

    

    少样本密集检索（DR）旨在通过学习少量样本有效地推广到新的搜索场景。尽管它非常重要，但对于专门的数据集和标准化的评估协议的研究很少。因此，当前的方法通常采用从监督数据集中随机采样来创建“少量数据”设置，并在评估过程中采用不一致的训练策略，这会在准确比较最近的进展方面带来挑战。在本文中，我们提出了一个定制的FewDR数据集和一个统一的评估基准。具体来说，FewDR采用按类别抽样的方法建立了一个标准化的“少样本”设置，定义了精细的类别，减少了多次抽样的变异性。此外，该数据集被分为基类和新颖类，允许DR模型在基类的丰富数据和新颖类的少量样本上进行连续训练。这个基准消除了新颖类泄漏的风险，提供了可靠的估计。

    Few-shot dense retrieval (DR) aims to effectively generalize to novel search scenarios by learning a few samples. Despite its importance, there is little study on specialized datasets and standardized evaluation protocols. As a result, current methods often resort to random sampling from supervised datasets to create "few-data" setups and employ inconsistent training strategies during evaluations, which poses a challenge in accurately comparing recent progress. In this paper, we propose a customized FewDR dataset and a unified evaluation benchmark. Specifically, FewDR employs class-wise sampling to establish a standardized "few-shot" setting with finely-defined classes, reducing variability in multiple sampling rounds. Moreover, the dataset is disjointed into base and novel classes, allowing DR models to be continuously trained on ample data from base classes and a few samples in novel classes. This benchmark eliminates the risk of novel class leakage, providing a reliable estimation o
    
[^7]: 捷克语、波兰语和斯洛伐克语中的性别偏见量化研究

    Measuring Gender Bias in West Slavic Language Models. (arXiv:2304.05783v1 [cs.CL])

    [http://arxiv.org/abs/2304.05783](http://arxiv.org/abs/2304.05783)

    本研究分析了西斯拉夫语言模型中的性别偏差，发现捷克语、波兰语和斯洛伐克语均存在相似程度的性别偏见。这一研究填补了研究非英语语言模型性别偏见的空白。

    

    预训练模型会将基础数据集中的偏见延续到下游任务。然而，这些研究大多基于英语的单语言模型，而针对扩展到英语以外的语言的语言模型中的偏见的研究很少。本文通过分析西斯拉夫语言模型中的性别偏差来填补这一空白。我们首次引入了基于模板的数据集（包括捷克语、波兰语和斯洛伐克语），以测量针对男性、女性和非二进制主体的性别偏见。我们使用单语和多语言模型来完成这些句子，并评估它们是否适合于被遮盖的语言建模任务。接下来，我们通过量化生成单词的有毒性和性别特征来测量西斯拉夫语言模型中的性别偏见。我们发现这些语言模型生成的语句会因主体的性别而产生伤害性的完成度。令人惊讶的是，捷克语、斯洛伐克语和波兰语均显示出相似程度的性别偏见。本研究对于关于语言模型中存在的偏见的日益增长的研究体系做出贡献，并为评估和减少西斯拉夫语言中的性别偏见奠定了基础。

    Pre-trained language models have been known to perpetuate biases from the underlying datasets to downstream tasks. However, these findings are predominantly based on monolingual language models for English, whereas there are few investigative studies of biases encoded in language models for languages beyond English. In this paper, we fill this gap by analysing gender bias in West Slavic language models. We introduce the first template-based dataset in Czech, Polish, and Slovak for measuring gender bias towards male, female and non-binary subjects. We complete the sentences using both mono- and multilingual language models and assess their suitability for the masked language modelling objective. Next, we measure gender bias encoded in West Slavic language models by quantifying the toxicity and genderness of the generated words. We find that these language models produce hurtful completions that depend on the subject's gender. Perhaps surprisingly, Czech, Slovak, and Polish language mode
    
[^8]: 使用人口普查数据测量语言模型中的规范和描述性偏差

    Measuring Normative and Descriptive Biases in Language Models Using Census Data. (arXiv:2304.05764v1 [cs.CL])

    [http://arxiv.org/abs/2304.05764](http://arxiv.org/abs/2304.05764)

    本文介绍了一种在预训练语言模型中测量规范和描述性职业分布偏差的方法，并通过使用官方的人口普查数据来探测多种语言模型对齐程度。

    

    本文研究了预训练语言模型中职业在性别方面的分布如何反映在模型中。这样的分布并不总是符合规范理想，也不一定反映现实中的描述评估。为了衡量预训练语言模型对规范和描述性职业分布的对齐程度，我们使用法国、挪威、英国和美国国家统计机构提供的有关性别-职业分布的官方人口普查信息。我们手动生成结合性别代词和名词以及职业的基于模板的句子，并随后探测英语、法语和挪威语的十种语言模型的选择。我们在本文中引入的评分系统是独立于语言的，可以用于任何基于模板的句子、职业和语言的组合。

    We investigate in this paper how distributions of occupations with respect to gender is reflected in pre-trained language models. Such distributions are not always aligned to normative ideals, nor do they necessarily reflect a descriptive assessment of reality. In this paper, we introduce an approach for measuring to what degree pre-trained language models are aligned to normative and descriptive occupational distributions. To this end, we use official demographic information about gender--occupation distributions provided by the national statistics agencies of France, Norway, United Kingdom, and the United States. We manually generate template-based sentences combining gendered pronouns and nouns with occupations, and subsequently probe a selection of ten language models covering the English, French, and Norwegian languages. The scoring system we introduce in this work is language independent, and can be used on any combination of template-based sentences, occupations, and languages. 
    
[^9]: 全局提示单元：一种有效的移植控制模块

    Global Prompt Cell: A Portable Control Module for Effective Prompt. (arXiv:2304.05642v1 [cs.CL])

    [http://arxiv.org/abs/2304.05642](http://arxiv.org/abs/2304.05642)

    全局提示单元(GPC)是一种用于调整预训练模型的可移植控制模块。它可以在所有编码器层中选择性地保留提示信息，从而提高了 5.8% 的 SuperGLUE 数据集的性能表现。

    

    全局提示单元(Global Prompt Cell, GPC)是一种用于调整预训练模型的可移植控制模块，可以在下游任务中冻结参数并在第一层的输入中插入可训练的嵌入向量。为了解决预训练模型的信息利用问题，GPC可以在所有编码器层中选择性地保留提示信息。实验结果表明，与普通提示调整相比，GPC 在 SuperGLUE 数据集上取得了 5.8% 的提高。

    As a novel approach to tuning pre-trained models, prompt tuning involves freezing the parameters in downstream tasks while inserting trainable embeddings into inputs in the first layer.However,previous methods have mainly focused on the initialization of prompt embeddings. The question of how to train and utilize prompt embeddings in a reasonable way has become aa limiting factor in the effectiveness of prompt tuning. To address this issue, we introduce the Global Prompt Cell (GPC), a portable control module for prompt tuning that selectively preserves prompt information across all encoder layers. Our experimental results demonstrate a 5.8% improvement on SuperGLUE datasets compared to vanilla prompt tuning.
    
[^10]: ChatGPT超越英语：朝着对多语言学习中的大型语言模型的全面评估

    ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning. (arXiv:2304.05613v1 [cs.CL])

    [http://arxiv.org/abs/2304.05613](http://arxiv.org/abs/2304.05613)

    这篇论文评估了ChatGPT在22种不同的语言中的表现，并创建了一个多语言基准数据集。结果表明ChatGPT在各种语言和任务上表现出显著的一致性和功效，这为多语言学习和LLMs的研究提供了强有力的支持。

    

    在过去的几年里，大型语言模型（LLMs）已经成为自然语言处理（NLP）中最重要的突破之一，从根本上改变了该领域的研究和发展。ChatGPT是最近开发的最令人兴奋的LLM系统之一，展示了对语言生成的出色技能，并受到了公众的高度关注。在发现ChatGPT在英语中的各种令人兴奋的应用程序中，该模型可以处理和生成多种语言的文本，因为它具有多语言训练数据。考虑到ChatGPT在不同问题和领域的英语中的广泛采用，一个自然的问题是ChatGPT是否也可以有效地应用于其他语言，还是需要开发更多的语言特定技术？这个问题的答案需要对ChatGPT在多个任务中进行全面评估，使用不同的语言和大型数据集（即超出了报道的轶事），这在当前的研究中仍然缺乏或有限。在本文中，我们通过评估ChatGPT的全面一组22种语言，从不同的家族中开发一个多语言基准测试数据集来回答这个问题。我们的结果表明，ChatGPT在各种语言和任务上表现出了显著的一致性和功效，这为问题提供了强有力的正面答案。我们预计我们的评估方法和基准测试数据集将促进未来的多语言学习和LLMs的研究。

    Over the last few years, large language models (LLMs) have emerged as the most important breakthroughs in natural language processing (NLP) that fundamentally transform research and developments in the field. ChatGPT represents one of the most exciting LLM systems developed recently to showcase impressive skills for language generation and highly attract public attention. Among various exciting applications discovered for ChatGPT in English, the model can process and generate texts for multiple languages due to its multilingual training data. Given the broad adoption of ChatGPT for English in different problems and areas, a natural question is whether ChatGPT can also be applied effectively for other languages or it is necessary to develop more language-specific technologies. The answer to this question requires a thorough evaluation of ChatGPT over multiple tasks with diverse languages and large datasets (i.e., beyond reported anecdotes), which is still missing or limited in current r
    
[^11]: FLAN-T5中语义特征验证的研究

    Semantic Feature Verification in FLAN-T5. (arXiv:2304.05591v1 [cs.CL])

    [http://arxiv.org/abs/2304.05591](http://arxiv.org/abs/2304.05591)

    本研究表明大规模语言模型可以极大地增强传统的语义特征规范验证方法，使之能够捕捉超过人类规范范畴的信息，对于我们理解人类和机器的概念表示具有重要意义。

    

    本研究评估了大规模语言模型在生成语义特征规范方面的潜力——这是评价认知科学中概念结构的关键工具。我们基于现有的人工生成数据集进行构建，结果表明，机器验证的规范捕捉了概念结构的某些方面，超越了仅考虑人类规范所能涵盖的范围，并且更好地解释了在远距离相关的项目之间的语义相似度人类判断。该结果表明LLM可以极大地增强传统的语义特征规范验证方法，这对于我们理解人类和机器的概念表示具有重要意义。

    This study evaluates the potential of a large language model for aiding in generation of semantic feature norms - a critical tool for evaluating conceptual structure in cognitive science. Building from an existing human-generated dataset, we show that machine-verified norms capture aspects of conceptual structure beyond what is expressed in human norms alone, and better explain human judgments of semantic similarity amongst items that are distally related. The results suggest that LLMs can greatly enhance traditional methods of semantic feature norm verification, with implications for our understanding of conceptual representation in humans and machines.
    
[^12]: 信息量是否重要？基于主动学习的教育对话行为分类

    Does Informativeness Matter? Active Learning for Educational Dialogue Act Classification. (arXiv:2304.05578v1 [cs.CL])

    [http://arxiv.org/abs/2304.05578](http://arxiv.org/abs/2304.05578)

    本文研究基于主动学习方法的教育对话行为分类，提出了一种新的方法来选择信息样本，并且能够优于随机抽样方法和其他AL方法。

    

    基于对话行为（DA），可以解释专家导师在辅导过程中做了什么以及学生知道什么。然而，现有的实证研究多采用随机抽样法来获得手动注释DA的句子样本，然后用于培训DA分类器。本文提出了一种基于主动学习（AL）方法，用于选择教育对话行为分类的信息样本。结果表明，他们的方法优于随机抽样方法和其他最新的AL方法。

    Dialogue Acts (DAs) can be used to explain what expert tutors do and what students know during the tutoring process. Most empirical studies adopt the random sampling method to obtain sentence samples for manual annotation of DAs, which are then used to train DA classifiers. However, these studies have paid little attention to sample informativeness, which can reflect the information quantity of the selected samples and inform the extent to which a classifier can learn patterns. Notably, the informativeness level may vary among the samples and the classifier might only need a small amount of low informative samples to learn the patterns. Random sampling may overlook sample informativeness, which consumes human labelling costs and contributes less to training the classifiers. As an alternative, researchers suggest employing statistical sampling methods of Active Learning (AL) to identify the informative samples for training the classifiers. However, the use of AL methods in educational D
    
[^13]: 通过日语文体分析区分ChatGPT(-3.5,-4)的生成文本与人类写作的论文

    Distinguishing ChatGPT(-3.5, -4)-generated and human-written papers through Japanese stylometric analysis. (arXiv:2304.05534v1 [cs.CL])

    [http://arxiv.org/abs/2304.05534](http://arxiv.org/abs/2304.05534)

    本研究通过比较GPT(-3.5和-4)生成的日语文体特征与人类写作的学术论文，证明了它们在文体特征上有显著区别。

    

    文本生成的人工智能，包括OpenAI的GPT-3.5和GPT-4，引起了全球广泛关注。本研究比较了GPT(-3.5和-4)生成和人类撰写的日语文体特征。通过多维尺度分析，将216个文本（36位单一作者的72篇学术论文、72篇GPT-3.5生成的文本和72篇GPT-4生成的文本）根据词性的二元组，词尾的二元组，逗号的位置和功能词的比例分成三类，结果显示出GPT(-3.5，-4)和人类之间在文体特征上有明显差异。

    Text-generative artificial intelligence (AI), including ChatGPT, equipped with GPT-3.5 and GPT-4, from OpenAI, has attracted considerable attention worldwide. In this study, first, we compared Japanese stylometric features generated by GPT (-3.5 and -4) and those written by humans. In this work, we performed multi-dimensional scaling (MDS) to confirm the classification of 216 texts into three classes (72 academic papers written by 36 single authors, 72 texts generated by GPT-3.5, and 72 texts generated by GPT-4 on the basis of the titles of the aforementioned papers) focusing on the following stylometric features: (1) bigrams of parts-of-speech, (2) bigram of postpositional particle words, (3) positioning of commas, and (4) rate of function words. MDS revealed distinct distributions at each stylometric feature of GPT (-3.5 and -4) and human. Although GPT-4 is more powerful than GPT-3.5 because it has more parameters, both GPT (-3.5 and -4) distributions are likely to overlap. These res
    
[^14]: 用大规模语言模型理解因果关系: 可行性和机遇

    Understanding Causality with Large Language Models: Feasibility and Opportunities. (arXiv:2304.05524v1 [cs.LG])

    [http://arxiv.org/abs/2304.05524](http://arxiv.org/abs/2304.05524)

    本文评估了大型语言模型回答因果问题的能力，发现它们可以回答基于已有因果知识的问题，但对于发现新知识或高风险决策任务的高精度要求不足。未来可以通过启用显式和隐式的因果模块以及深度因果感知的LLMs来解决这些问题。

    

    本文通过分析大型语言模型(LLMs)在回答三种类型因果问题时的优缺点，评估了它们回答因果问题的能力。我们认为，当前的LLMs可以像领域专家一样回答基于已有因果知识的因果问题。但是，它们还不能为发现新知识或高精度高风险决策任务提供令人满意的答案。我们讨论了未来可能的方向和机遇，例如启用显式和隐式的因果模块以及深度因果感知的LLMs。这些不仅可以使LLMs回答更多类型的因果问题以实现更大的影响力，还可以使LLMs在一般情况下更加值得信任和高效。

    We assess the ability of large language models (LLMs) to answer causal questions by analyzing their strengths and weaknesses against three types of causal question. We believe that current LLMs can answer causal questions with existing causal knowledge as combined domain experts. However, they are not yet able to provide satisfactory answers for discovering new knowledge or for high-stakes decision-making tasks with high precision. We discuss possible future directions and opportunities, such as enabling explicit and implicit causal modules as well as deep causal-aware LLMs. These will not only enable LLMs to answer many different types of causal questions for greater impact but also enable LLMs to be more trustworthy and efficient in general.
    
[^15]: MoMo: 一个共享编码器模型，用于文本、图像和多模态表示

    MoMo: A shared encoder Model for text, image and multi-Modal representations. (arXiv:2304.05523v1 [cs.CV])

    [http://arxiv.org/abs/2304.05523](http://arxiv.org/abs/2304.05523)

    MoMo是一个自监督的共享编码器模型，可以用于处理文本、图像和多模态数据，并且具备高效的性能。通过单一的变压器和阶段性的训练策略，在保留信息的同时，使用更少的参数和预训练数据，取得了与强模型相当的表现。

    

    我们提出了一个自监督的共享编码器模型，它在几个视觉、语言和多模态基准测试中取得了强大的结果，同时具有数据、内存和运行时效率。我们做出了三个关键贡献。首先，与大多数现有作品相比，我们使用了一个单一的变压器，所有编码器层处理文本和图像模态。其次，我们提出了一个分阶段的训练策略，其中模型首先在图像上进行训练，然后在单模文本和图像数据集上进行联合训练，最后在文本和文本-图像数据集上进行联合训练。第三，为了在两种模式下保留信息，我们提出了一个训练管道，它在每个训练更新步骤时同时从不同模态的梯度更新中学习。下游的纯文本、纯图像和多模态任务的结果显示，我们的模型与几个强模型竞争，同时使用更少的参数和较少的预训练数据。例如，MoMo在与FLAVA的竞争中表现得很有竞争力。

    We propose a self-supervised shared encoder model that achieves strong results on several visual, language and multimodal benchmarks while being data, memory and run-time efficient. We make three key contributions. First, in contrast to most existing works, we use a single transformer with all the encoder layers processing both the text and the image modalities. Second, we propose a stage-wise training strategy where the model is first trained on images, then jointly with unimodal text and image datasets and finally jointly with text and text-image datasets. Third, to preserve information across both the modalities, we propose a training pipeline that learns simultaneously from gradient updates of different modalities at each training update step. The results on downstream text-only, image-only and multimodal tasks show that our model is competitive with several strong models while using fewer parameters and lesser pre-training data. For example, MoMo performs competitively with FLAVA 
    
[^16]: 奥尔罕·帕慕克诺贝尔文学奖作品的数学和语言特征

    Mathematical and Linguistic Characterization of Orhan Pamuk's Nobel Works. (arXiv:2304.05512v1 [cs.CL])

    [http://arxiv.org/abs/2304.05512](http://arxiv.org/abs/2304.05512)

    本研究以诺贝尔文学奖得主奥尔罕·帕慕克的著作为例子，通过计算文本中字母和单词的数量，使用分形几何方法计算了他的文本的分形维度，并与应用于字母和单词的Zipf定律进行比较。发现小说《我的名字叫红》的Zipf维度与他的其他小说有很大的不同，但语言学上并没有根本的区别。

    

    本研究选择了诺贝尔文学奖得主奥尔罕·帕慕克的著作作为土耳其文学的例子。通过计算他的文本中字母和单词的数量，我们发现可以进行统计学研究。已知文本结构中存在几何顺序。这里介绍了基于分形几何基本假设的方法，用于计算帕姆克文本的分形维度。结果与应用于字母和单词的Zipf定律的应用进行比较，引入了两个概念，即Zipf维度和Zipf顺序。发现小说《我的名字叫红》的Zipf维度与他的其他小说有很大的不同。然而，从语言学角度观察，他的语料库之间并没有根本的区别。结果以分形维度和土耳其语言的角度进行了解释。

    In this study, Nobel Laureate Orhan Pamuk's works are chosen as examples of Turkish literature. By counting the number of letters and words in his texts, we find it possible to study his works statistically. It has been known that there is a geometrical order in text structures. Here the method based on the basic assumption of fractal geometry is introduced for calculating the fractal dimensions of Pamuk's texts. The results are compared with the applications of Zipf's law, which is successfully applied for letters and words, where two concepts, namely Zipf's dimension and Zipf's order, are introduced. The Zipf dimension of the novel My Name is Red is found to be much different than his other novels. However, it is linguistically observed that there is no fundamental difference between his corpora. The results are interpreted in terms of fractal dimensions and the Turkish language.
    
[^17]: chatIPCC: 基于气候科学的对话型人工智能系统

    chatIPCC: Grounding Conversational AI in Climate Science. (arXiv:2304.05510v1 [cs.CL])

    [http://arxiv.org/abs/2304.05510](http://arxiv.org/abs/2304.05510)

    chatIPCC是一个基于气候科学的对话型人工智能系统，通过整合IPCC AR6中的信息来增强GPT-4模型，并提供可靠、科学准确的答案。

    

    大型语言模型在近年来在问答任务方面取得了显着进展。然而，它们仍面临两个主要挑战：幻觉和训练后信息过时。在关键领域，如气候变化，快速从可靠来源获取准确和最新信息是至关重要且困难的。为了克服这些障碍，一个潜在的解决方案是为大型语言模型提供外部科学准确且可靠的来源（长期记忆），以持续更新其知识并防止不准确、不正确或过时信息的传播。在本研究中，我们通过整合联合政府间气候变化专门委员会第六次评估报告（IPCC AR6）中的信息来增强GPT-4。我们展示了我们的对话型人工智能原型，可以在www.chatclima.com上提问与气候科学相关的问题并获得基于IPCC AR6报告的科学准确答案。

    Large Language Models (LLMs) have made significant progress in recent years, achieving remarkable results in question-answering tasks (QA). However, they still face two major challenges: hallucination and outdated information after the training phase. These challenges take center stage in critical domains like climate change, where obtaining accurate and up-to-date information from reliable sources in a limited time is essential and difficult. To overcome these barriers, one potential solution is to provide LLMs with access to external, scientifically accurate, and robust sources (long-term memory) to continuously update their knowledge and prevent the propagation of inaccurate, incorrect, or outdated information. In this study, we enhanced GPT-4 by integrating the information from the Sixth Assessment Report of the Intergovernmental (IPCC AR6), the most comprehensive, up-to-date, and reliable source in this domain. We present our conversational AI prototype, available at www.chatclima
    
[^18]: 基于学科设置的自适应语言学习聊天机器人

    User Adaptive Language Learning Chatbots with a Curriculum. (arXiv:2304.05489v1 [cs.CL])

    [http://arxiv.org/abs/2304.05489](http://arxiv.org/abs/2304.05489)

    本文研究了一种基于学科设置的自适 应语言学习聊天机器人，该机器人采用词汇限制解码引导系统生成符合学生课程设置的语言，经过在中学生学习英语中的实验结果表明，该系统可以提高学习效果和交流体验。

    

    随着自然语言理解和生成系统的发展，对话系统已被广泛应用于语言学习和练习。许多当前的教育对话系统进行闲聊，生成内容和词汇不受限制。然而，在学校环境中，如果对话符合学生的课程设置并侧重于课本词汇，则通过对话实践更为有效。因此，我们调整了一种具有词汇限制解码的对话系统，促使对话系统在生成语言时包含与课程相关的词汇和短语。我们采用生成对话系统BlenderBot3作为我们的主模型，并对学习英语作为第二语言的中学生进行课程设置的对话系统进行评估。限制的单词和短语来自他们的课本，并由他们的英语老师建议。评估结果表明，具有课程信息的对话系统可以与学生产生更有效和吸引人的对话，准确使用与课程对齐的词汇可以增强学习体验。

    Along with the development of systems for natural language understanding and generation, dialog systems have been widely adopted for language learning and practicing. Many current educational dialog systems perform chitchat, where the generated content and vocabulary are not constrained. However, for learners in a school setting, practice through dialog is more effective if it aligns with students' curriculum and focuses on textbook vocabulary. Therefore, we adapt lexically constrained decoding to a dialog system, which urges the dialog system to include curriculum-aligned words and phrases in its generated utterances. We adopt a generative dialog system, BlenderBot3, as our backbone model and evaluate our curriculum-based dialog system with middle school students learning English as their second language. The constrained words and phrases are derived from their textbooks, suggested by their English teachers. The evaluation result demonstrates that the dialog system with curriculum inf
    
[^19]: 塞尔维亚语自然语言处理的资源和方法调查

    A Survey of Resources and Methods for Natural Language Processing of Serbian Language. (arXiv:2304.05468v1 [cs.CL])

    [http://arxiv.org/abs/2304.05468](http://arxiv.org/abs/2304.05468)

    塞尔维亚语是一种低资源、高屈折语言，自然语言处理具有挑战性。过去三十年中，有许多倡议开展了塞尔维亚语自然语言处理的资源和方法的开发。

    

    塞尔维亚语是一种斯拉夫语言，拥有超过1200万的说话者，并被超过1500万人了解。在自然语言处理领域，它可被视作一种低资源语言，并且是一种高屈折语言。许多单词的屈折形式和语言资源的稀缺性结合在一起，使得塞尔维亚语的自然语言处理具有挑战性。尽管如此，在过去的三十年中，有许多倡议开展了塞尔维亚语自然语言处理的资源和方法的开发，从书籍和互联网的免费文本语料库、分类和命名实体识别任务的注释语料库到各种执行这些任务的方法和模型。在本文中，我们回顾了这些倡议、资源、方法及其可用性。

    The Serbian language is a Slavic language spoken by over 12 million speakers and well understood by over 15 million people. In the area of natural language processing, it can be considered a low-resourced language. Also, Serbian is considered a high-inflectional language. The combination of many word inflections and low availability of language resources makes natural language processing of Serbian challenging. Nevertheless, over the past three decades, there have been a number of initiatives to develop resources and methods for natural language processing of Serbian, ranging from developing a corpus of free text from books and the internet, annotated corpora for classification and named entity recognition tasks to various methods and models performing these tasks. In this paper, we review the initiatives, resources, methods, and their availability.
    
[^20]: 基于ChatGPT的零样本时间关系抽取

    Zero-shot Temporal Relation Extraction with ChatGPT. (arXiv:2304.05454v1 [cs.CL])

    [http://arxiv.org/abs/2304.05454](http://arxiv.org/abs/2304.05454)

    本文研究了基于ChatGPT的零样本时间关系抽取，设计了三种提示技术来拆分任务并评估ChatGPT，实验表明ChatGPT的表现与监督方法存在很大差距，但它可以更正确地推断出更多的小关系类。

    

    时间关系抽取的目标是推断文档中两个事件之间的时间关系。 监督模型在该任务中占主导地位。本研究旨在探究ChatGPT在零样本时间关系抽取方面的能力。我们设计了三种不同的提示技术来拆分任务并评估ChatGPT。我们的实验表明，ChatGPT的表现与监督方法存在很大差距，而且很大程度上依赖于提示的设计。我们进一步证明，与监督方法相比，ChatGPT可以更正确地推断出更多的小关系类。本文还讨论了ChatGPT在时间关系抽取方面的现有缺陷。我们发现，ChatGPT在时间推断过程中无法保持一致性，并且在主动长依赖时间推断中失败。

    The goal of temporal relation extraction is to infer the temporal relation between two events in the document. Supervised models are dominant in this task. In this work, we investigate ChatGPT's ability on zero-shot temporal relation extraction. We designed three different prompt techniques to break down the task and evaluate ChatGPT. Our experiments show that ChatGPT's performance has a large gap with that of supervised methods and can heavily rely on the design of prompts. We further demonstrate that ChatGPT can infer more small relation classes correctly than supervised methods. The current shortcomings of ChatGPT on temporal relation extraction are also discussed in this paper. We found that ChatGPT cannot keep consistency during temporal inference and it fails in actively long-dependency temporal inference.
    
[^21]: 星际闲聊：使用大语言模型与天文学文献对话

    Galactic ChitChat: Using Large Language Models to Converse with Astronomy Literature. (arXiv:2304.05406v1 [cs.CL])

    [http://arxiv.org/abs/2304.05406](http://arxiv.org/abs/2304.05406)

    本论文展示了使用OpenAI GPT-4大型语言模型通过上下文提示与天文学文献进行交互的潜力。该模型可用于提供多文献上下文下的详细答案，为天文学界探索开辟了有前途的途径。

    

    我们展示了利用上下文提示，采用最先进的OpenAI GPT-4大语言模型与天文学论文进行有意义互动的潜力。为了提高效率，我们采用了一种蒸馏技术，可以有效地减少原始输入论文的50\％，同时保持段落结构和整体语义完整性。然后，我们使用多个文档内容进行模型的响应（十个蒸馏过的文献）。我们的研究结果表明，GPT-4在多文档领域表现出色，提供了在相关研究发现框架中进行上下文化详细解答的信息。我们的结果展示了大型语言模型在天文学界的潜力，为进一步探索提供了有前途的途径，尤其是利用模型进行假设生成的可能性。

    We demonstrate the potential of the state-of-the-art OpenAI GPT-4 large language model to engage in meaningful interactions with Astronomy papers using in-context prompting. To optimize for efficiency, we employ a distillation technique that effectively reduces the size of the original input paper by 50\%, while maintaining the paragraph structure and overall semantic integrity. We then explore the model's responses using a multi-document context (ten distilled documents). Our findings indicate that GPT-4 excels in the multi-document domain, providing detailed answers contextualized within the framework of related research findings. Our results showcase the potential of large language models for the astronomical community, offering a promising avenue for further exploration, particularly the possibility of utilizing the models for hypothesis generation.
    
[^22]: 个性化文本到图像生成的可控文本反转

    Controllable Textual Inversion for Personalized Text-to-Image Generation. (arXiv:2304.05265v1 [cs.CV])

    [http://arxiv.org/abs/2304.05265](http://arxiv.org/abs/2304.05265)

    本文提出了一种名为COTI的技术，通过引入理论指导的损失目标和全面的加权评分机制，并结合主动学习范式来解决文本反转时的困难，提供了一个强大，数据效率高，易于使用的框架。

    

    最近，大规模生成模型在以文本为引导的高保真图像的生成方面取得了前所未有的性能。当引导信息包含用户定义的、未见过的或长尾概念标记时，文本反转成为一种有效的个性化生成技术。尽管如此，我们发现并展示了文本反转的部署仍充满了“黑魔法”，例如额外数据集的严苛要求，在循环中需要艰苦的人力成本和缺乏鲁棒性等。在这项工作中，我们提出了一种名为可控文本反转的大大增强版反转，解决了所有上述问题，并反过来提供了一个强大，数据效率高，易于使用的框架。COTI的核心是基于理论的损失目标，具有全面和新颖的加权评分机制，并由主动学习范式所提取。广泛的结果表明，COTI的性能比之前技术有了显著的提升，尤其是在数据少的情况下。

    The recent large-scale generative modeling has attained unprecedented performance especially in producing high-fidelity images driven by text prompts. Text inversion (TI), alongside the text-to-image model backbones, is proposed as an effective technique in personalizing the generation when the prompts contain user-defined, unseen or long-tail concept tokens. Despite that, we find and show that the deployment of TI remains full of "dark-magics" -- to name a few, the harsh requirement of additional datasets, arduous human efforts in the loop and lack of robustness. In this work, we propose a much-enhanced version of TI, dubbed Controllable Textual Inversion (COTI), in resolving all the aforementioned problems and in turn delivering a robust, data-efficient and easy-to-use framework. The core to COTI is a theoretically-guided loss objective instantiated with a comprehensive and novel weighted scoring mechanism, encapsulated by an active-learning paradigm. The extensive results show that 
    
[^23]: 大型语言模型作为钥匙：用GPT解密材料科学的秘密。

    Large Language Models as Master Key: Unlocking the Secrets of Materials Science with GPT. (arXiv:2304.02213v1 [cs.CL])

    [http://arxiv.org/abs/2304.02213](http://arxiv.org/abs/2304.02213)

    本文介绍了一个新的自然语言处理任务——结构化信息推理（SIS），利用GPT-3模型能够准确提取材料科学设备层面的信息，并通过实验预测PCE和反向预测参数，展示了大型语言模型在材料学中的巨大潜力。

    

    本文介绍了一个新的自然语言处理（NLP）任务——结构化信息推理（SIS），以解决材料科学设备层面信息提取的复杂性。我们使用现有的钙钛矿太阳能电池FAIR数据集对GPT-3进行微调，获得了91.8 F1得分，并更新了数据集，包括迄今为止所有相关科学论文。所生成的数据集已被格式化和标准化，使得它可以直接作为后续数据分析的输入。这个特性将使材料科学家通过选择高质量的领域评论文章来开发其自己的模型。此外，我们设计了实验来预测PCE和反向预测参数，并获得了与DFT相当的性能，这证明了大型语言模型能够像材料学家一样评判材料和设计新材料。

    This article presents a new NLP task called structured information inference (SIS) to address the complexities of information extraction at the device level in materials science. We accomplished this task by finetuning GPT-3 on a exsiting perovskite solar cell FAIR dataset with 91.8 F1-score and we updated the dataset with all related scientific papers up to now. The produced dataset is formatted and normalized, enabling its direct utilization as input in subsequent data analysis. This feature will enable materials scientists to develop their own models by selecting high-quality review papers within their domain. Furthermore, we designed experiments to predict PCE and reverse-predict parameters and obtained comparable performance with DFT, which demonstrates the potential of large language models to judge materials and design new materials like a materials scientist.
    
[^24]: 社会文化知识在仇恨言论检测任务中对选项的选择是必要的

    Sociocultural knowledge is needed for selection of shots in hate speech detection tasks. (arXiv:2304.01890v1 [cs.CL])

    [http://arxiv.org/abs/2304.01890](http://arxiv.org/abs/2304.01890)

    HATELEXICON是一个包含巴西，德国，印度和肯尼亚仇恨言论的词汇表，利用其可以提高模型在训练中的性能表现。

    

    我们引入了HATELEXICON，这是一个包含巴西，德国，印度和肯尼亚的蔑称和仇恨言论目标的词汇表，以帮助模型的训练和可解释性。我们展示了我们的词汇表如何用于解释模型预测，表明发展用于分类极端言论的模型，在进行预测时严重依赖目标词。此外，我们提出了一种通过HATELEXICON来辅助低资源环境下训练选项的方法，选项选择在小样本学习中尤为重要。在我们的工作中，我们使用HASOC数据对德语和印地语进行了几个示范学习，并将Multilingual HateCheck（MHC）作为基准。我们展示了根据我们的词汇表选择样本，相对于随机采样的模型，能够更好地在MHC上表现。因此，当仅有少量的训练样本时，使用我们的词汇表来选择包含更多社会文化信息的样本能够更好地提高在仇恨言论检测任务中的性能。

    We introduce HATELEXICON, a lexicon of slurs and targets of hate speech for the countries of Brazil, Germany, India and Kenya, to aid training and interpretability of models. We demonstrate how our lexicon can be used to interpret model predictions, showing that models developed to classify extreme speech rely heavily on target words when making predictions. Further, we propose a method to aid shot selection for training in low-resource settings via HATELEXICON. In few-shot learning, the selection of shots is of paramount importance to model performance. In our work, we simulate a few-shot setting for German and Hindi, using HASOC data for training and the Multilingual HateCheck (MHC) as a benchmark. We show that selecting shots based on our lexicon leads to models performing better on MHC than models trained on shots sampled randomly. Thus, when given only a few training examples, using our lexicon to select shots containing more sociocultural information leads to better few-shot perf
    
[^25]: 大型语言模型综述

    A Survey of Large Language Models. (arXiv:2303.18223v1 [cs.CL])

    [http://arxiv.org/abs/2303.18223](http://arxiv.org/abs/2303.18223)

    本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。

    

    语言本质上是一个由语法规则控制的复杂精细的人类表达系统，对于开发理解和掌握语言的能力的AI算法来说是一项重大挑战。作为主要方法之一，语言建模在过去二十年里广泛研究用于语言理解和生成，从统计语言模型演化为神经语言模型。最近，通过在大规模语料库上预训练Transformer模型，提出了预训练语言模型（PLMs），在解决各种NLP任务方面显示出强大的能力。由于研究人员发现模型缩放可以导致性能改进，他们进一步通过增加模型规模来研究缩放效应，有趣的是，当参数规模超过一定水平时，这些扩大的语言模型不仅可以实现显着的性能提升，而且还显示出一些小规模语言模型所没有的特殊能力。

    Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale langu
    
[^26]: GPT-4在医学挑战问题上的能力

    Capabilities of GPT-4 on Medical Challenge Problems. (arXiv:2303.13375v1 [cs.CL])

    [http://arxiv.org/abs/2303.13375](http://arxiv.org/abs/2303.13375)

    本论文对最先进的LLM——GPT-4在医学能力考试和基准数据集上进行了全面评估，结果显示其表现出色，有助于医学相关领域的研究和应用。

    

    大型语言模型（LLMs）已经在各个领域展示了惊人的自然语言理解和生成能力，包括医学。我们对一项最先进的LLM——GPT-4在医学能力考试和基准数据集上进行了全面评估。GPT-4是一个通用模型，没有经过针对医学问题的训练或设计用于解决临床任务。我们的分析涵盖了美国临床能力评估和授权考核计划（USMLE）的两组官方练习材料。我们还评估了在MultiMedQA基准数据集上的表现。除了测量模型的性能，还进行了实验来研究包含文本和图像的测试问题对模型性能的影响，探索训练期间内容记忆的可能性，并研究概率校准在高风险应用中的重要性。

    Large language models (LLMs) have demonstrated remarkable capabilities in natural language understanding and generation across various domains, including medicine. We present a comprehensive evaluation of GPT-4, a state-of-the-art LLM, on medical competency examinations and benchmark datasets. GPT-4 is a general-purpose model that is not specialized for medical problems through training or engineered to solve clinical tasks. Our analysis covers two sets of official practice materials for the USMLE, a three-step examination program used to assess clinical competency and grant licensure in the United States. We also evaluate performance on the MultiMedQA suite of benchmark datasets. Beyond measuring model performance, experiments were conducted to investigate the influence of test questions containing both text and images on model performance, probe for memorization of content during training, and study probability calibration, which is of critical importance in high-stakes applications 
    
[^27]: 心灵与机器: 解开GPT-4的认知心理学之谜

    Mind meets machine: Unravelling GPT-4's cognitive psychology. (arXiv:2303.11436v1 [cs.CL])

    [http://arxiv.org/abs/2303.11436](http://arxiv.org/abs/2303.11436)

    本研究评估了在广泛使用的CommonsenseQA数据集中的一套常识推理问题上，GPT-4的表现及其对常识知识的处理和整合过程，在此过程中我们也发现了其局限性。

    

    常识推理是人类智能的基本成分，使其能够根据环境观察推断结论。大型语言模型(LLMs)正成为越来越能够执行人类级任务的强有力工具。最近开发的GPT-4及其在医学考试、律师考试等人类难以完成的任务中表现出的成功，增加了LLMs成为完美智能工具的信心。然而，尽管GPT-4论文向我们展示了其在某些常识推理任务中的表现，但对GPT-4在常识推理任务上的全面评估，特别是现有的已经确立好的数据集上的评估还是缺失的。为此，我们关注GPT-4在广泛使用的CommonsenseQA数据集中的一套常识推理问题上的表现评估及其认知心理学工具。通过这样做，我们能够理解GPT-4如何在其语言生成过程中处理和整合常识知识，以及其在这方面的局限性。

    Commonsense reasoning is a basic ingredient of intelligence in humans, empowering the ability to deduce conclusions based on the observations of surroundings. Large language models (LLMs) are emerging as potent tools increasingly capable of performing human-level tasks. The recent development in the form of GPT-4 and its demonstrated success in tasks complex to humans such as medical exam, bar exam and others has led to an increased confidence in the LLMs to become perfect instruments of intelligence. Though, the GPT-4 paper has shown performance on some common sense reasoning tasks, a comprehensive assessment of GPT-4 on common sense reasoning tasks, particularly on the existing well-established datasets is missing. In this study, we focus on the evaluation of GPT-4's performance on a set of common sense reasoning questions from the widely used CommonsenseQA dataset along with tools from cognitive psychology. In doing so, we understand how GPT-4 processes and integrates common sense k
    
[^28]: 一种联合对比学习的原型语义解耦方法用于少样本命名实体识别

    A Prototypical Semantic Decoupling Method via Joint Contrastive Learning for Few-Shot Name Entity Recognition. (arXiv:2302.13610v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.13610](http://arxiv.org/abs/2302.13610)

    本文提出了一种基于联合对比学习的原型语义解耦方法(PSDC)用于少样本命名实体识别，通过两种屏蔽策略解耦类特定的原型和语境语义原型，防止语义坍塌，实验证明PSDC可以持续优于以前的SOTA方法。

    

    少样本命名实体识别旨在基于极少量标注实例的情况下，识别出命名实体。大多数现有的基于原型的序列标注模型倾向于记忆实体提及，但这容易被相似的原型所混淆。本文提出了一种基于联合对比学习的原型语义解耦方法(PSDC)用于少样本命名实体识别。我们通过两种屏蔽策略来解耦类特定的原型和语境语义原型，以引导模型专注于推断的两种不同语义信息。此外，我们进一步引入联合对比学习目标来更好地整合两种解耦信息，并防止语义坍塌。在两个少样本NER基准测试上的实验结果表明，PSDC在整体性能方面一致优于以前的SOTA方法。广泛的分析进一步验证了PSDC的有效性和普适性。

    Few-shot named entity recognition (NER) aims at identifying named entities based on only few labeled instances. Most existing prototype-based sequence labeling models tend to memorize entity mentions which would be easily confused by close prototypes. In this paper, we proposed a Prototypical Semantic Decoupling method via joint Contrastive learning (PSDC) for few-shot NER. Specifically, we decouple class-specific prototypes and contextual semantic prototypes by two masking strategies to lead the model to focus on two different semantic information for inference. Besides, we further introduce joint contrastive learning objectives to better integrate two kinds of decoupling information and prevent semantic collapse. Experimental results on two few-shot NER benchmarks demonstrate that PSDC consistently outperforms the previous SOTA methods in terms of overall performance. Extensive analysis further validates the effectiveness and generalization of PSDC.
    
[^29]: VLSP2022-EVJVQA挑战：多语种视觉问答

    VLSP2022-EVJVQA Challenge: Multilingual Visual Question Answering. (arXiv:2302.11752v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.11752](http://arxiv.org/abs/2302.11752)

    该论文介绍了一个新的多语种视觉问答数据集EVJVQA，包括越南语，英语和日语的33,000+问答对，可用于评估多语言VQA系统或模型的性能。

    

    视觉问答（VQA）是自然语言处理（NLP）和计算机视觉（CV）的一个具有挑战性的任务，吸引了研究人员的重视。 英语是一个资源丰富的语言，在视觉问答的数据集和模型方面有着各种发展。 其他语言的视觉问答也将会有资源和模型的发展。 此外，还没有针对特定国家的视觉内容和文化特点提供多语言数据集。为了解决这些问题，我们提供了一个名为EVJVQA的基准数据集，包括在越南拍摄的约5,000张图片上的三种语言（越南语，英语和日语）的33,000多对问答对，以评估多语言VQA系统或模型。 EVJVQA作为挑战多语种视觉问答的基准数据集，在第9届越南语言和语音处理研讨会（VLSP2022）上使用。

    Visual Question Answering (VQA) is a challenging task of natural language processing (NLP) and computer vision (CV), attracting significant attention from researchers. English is a resource-rich language that has witnessed various developments in datasets and models for visual question answering. Visual question answering in other languages also would be developed for resources and models. In addition, there is no multilingual dataset targeting the visual content of a particular country with its own objects and cultural characteristics. To address the weakness, we provide the research community with a benchmark dataset named EVJVQA, including 33,000+ pairs of question-answer over three languages: Vietnamese, English, and Japanese, on approximately 5,000 images taken from Vietnam for evaluating multilingual VQA systems or models. EVJVQA is used as a benchmark dataset for the challenge of multilingual visual question answering at the 9th Workshop on Vietnamese Language and Speech Process
    
[^30]: AI对抗AI：在社交媒体上打击机器生成的虚假餐厅评论

    Combat AI With AI: Counteract Machine-Generated Fake Restaurant Reviews on Social Media. (arXiv:2302.07731v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.07731](http://arxiv.org/abs/2302.07731)

    本文针对机器生成的虚假评论提出了一种用高质量餐厅评论生成虚假评论并微调GPT输出检测器的方法，该方法预测虚假评论的性能优于现有解决方案。同时，我们还探索了预测非精英评论的模型，并在几个维度上对这些评论进行分析，此类机器生成的虚假评论是社交媒体平台面临的持续挑战。

    

    最近生成模型（如GPT）的发展使得以更低的成本制造出难以区分的虚假顾客评论，从而对社交媒体平台检测这些机器生成的虚假评论造成挑战。本文提出利用Yelp验证的高质量的精英餐厅评论来生成OpenAI GPT评论生成器的虚假评论，并最终微调GPT输出检测器来预测明显优于现有解决方案的虚假评论。我们进一步将模型应用于预测非精英评论，并在几个维度（如评论、用户和餐厅特征以及写作风格）上识别模式。我们展示了社交媒体平台正在不断面临机器生成的虚假评论的挑战，尽管他们可能实施检测系统以过滤出可疑的评论。

    Recent advances in generative models such as GPT may be used to fabricate indistinguishable fake customer reviews at a much lower cost, thus posing challenges for social media platforms to detect these machine-generated fake reviews. We propose to leverage the high-quality elite restaurant reviews verified by Yelp to generate fake reviews from the OpenAI GPT review creator and ultimately fine-tune a GPT output detector to predict fake reviews that significantly outperform existing solutions. We further apply the model to predict non-elite reviews and identify the patterns across several dimensions, such as review, user and restaurant characteristics, and writing style. We show that social media platforms are continuously challenged by machine-generated fake reviews, although they may implement detection systems to filter out suspicious reviews.
    
[^31]: 语言模型的持续预训练

    Continual Pre-training of Language Models. (arXiv:2302.03241v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.03241](http://arxiv.org/abs/2302.03241)

    本文研究了语言模型的持续预训练，提出了一种新颖的持续领域自适应预训练方法，使用一系列未标记的领域语料库来逐步适应领域以提高LM在领域内的终端任务表现。该方法通过一个软掩蔽机制来直接控制LM的更新，并使用一种新颖的代理来保留LM中的整体知识，同时对比已学习领域知识和当前全网络的知识来实现知识整合。

    

    语言模型（LMs）是自然语言处理快速发展的关键。本文研究LMs的持续预训练，特别是持续领域自适应预训练（或持续DAP训练）。现有研究表明，使用领域语料库进一步预训练LMs以使其适应于领域，可以提高领域内的最终任务性能。本文提出了一种新颖的方法，使用一系列未标记的领域语料库来持续DAP训练LMs，以使其适应于这些领域，从而提高它们的终端任务性能。我们方法的关键创新在于一种软掩蔽机制，可直接控制LMs的更新。还提出了一种新颖的代理来保留原始LMs中的普通知识。此外，它对先前学习的领域知识（包括预先训练的LMs中的普通知识）和来自当前全网络的知识进行对比，以实现知识整合。

    Language models (LMs) have been instrumental for the rapid advance of natural language processing. This paper studies continual pre-training of LMs, in particular, continual domain-adaptive pre-training (or continual DAP-training). Existing research has shown that further pre-training an LM using a domain corpus to adapt the LM to the domain can improve the end-task performance in the domain. This paper proposes a novel method to continually DAP-train an LM with a sequence of unlabeled domain corpora to adapt the LM to these domains to improve their end-task performances. The key novelty of our method is a soft-masking mechanism that directly controls the update to the LM. A novel proxy is also proposed to preserve the general knowledge in the original LM. Additionally, it contrasts the representations of the previously learned domain knowledge (including the general knowledge in the pre-trained LM) and the knowledge from the current full network to achieve knowledge integration. The m
    
[^32]: 用于问题回答的动量对比预训练方法

    Momentum Contrastive Pre-training for Question Answering. (arXiv:2212.05762v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.05762](http://arxiv.org/abs/2212.05762)

    提出了一种用于抽取式问题回答的动量对比预训练方法，通过匹配填空式和自然查询-文章样本对的答案概率，能更好地将在填空式样本中学到的知识转移到回答自然问题上。

    

    现有的抽取式问答（QA）预训练方法生成类似于填空题的查询，其语法结构与自然语言问题不同，这可能会导致预训练模型对简单的关键词匹配过拟合。为了解决这个问题，我们提出了一种新的动量对比式预训练方法，即MCROSS（Momentum Contrastive pRe-training fOr queStion anSwering）用于抽取式的问题回答。具体来说，MCROSS引入了动量对比学习框架来匹配填空式和自然查询-文章样本对之间的答案概率。因此，预训练模型能够更好地将在填空式样本中学到的知识转移到回答自然问题上。在三个基准QA数据集上的实验结果表明，与所有基线方法相比，我们的方法在有监督和零-shot场景下均取得了显著的改进。

    Existing pre-training methods for extractive Question Answering (QA) generate cloze-like queries different from natural questions in syntax structure, which could overfit pre-trained models to simple keyword matching. In order to address this problem, we propose a novel Momentum Contrastive pRe-training fOr queStion anSwering (MCROSS) method for extractive QA. Specifically, MCROSS introduces a momentum contrastive learning framework to align the answer probability between cloze-like and natural query-passage sample pairs. Hence, the pre-trained models can better transfer the knowledge learned in cloze-like samples to answering natural questions. Experimental results on three benchmarking QA datasets show that our method achieves noticeable improvement compared with all baselines in both supervised and zero-shot scenarios.
    
[^33]: 迈向人类兼容自动驾驶汽车：情感过渡模型中的非语言图灵测试研究

    Towards human-compatible autonomous car: A study of non-verbal Turing test in automated driving with affective transition modelling. (arXiv:2212.02908v5 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2212.02908](http://arxiv.org/abs/2212.02908)

    本文研究了自动驾驶汽车的人性化问题，通过非语言图灵测试，发现当前AI驾驶员不能创造类似人类的驾乘体验，需要在情感过渡模型中进行改进。

    

    当人类走向无需双手的生活方式时，自动驾驶汽车是不可或缺的。现有文献强调，如果自动驾驶汽车能够以类似人类的方式驾驶，人们会更容易接受它。然而，仅有少量研究从乘客角度的自然体验来检验目前的自动驾驶汽车是否具有类似人类的特征。本研究通过一项真实道路环境下的试验，测试了69位参与者的反馈，尝试了解AI驾驶人员能否为乘客创造类似人类的驾乘体验。我们设计了一种基于驾乘体验的非语言图灵测试，要求参与者作为乘客乘坐AI驾驶人员或人类驾驶人员驾驶的自动驾驶汽车，并判断司机是人类还是AI。结果显示，充当AI驾驶员的汽车未能通过我们的测试，因为乘客能够超过随机猜测地识别出AI驾驶员。相比之下，当人类驾驶员驾驶车辆时，乘客的判断结果约在随机猜测水平附近。我们进一步探讨了人类乘客在驾驶过程中给予了哪些人性化特征的归因。

    Autonomous cars are indispensable when humans go further down the hands-free route. Although existing literature highlights that the acceptance of the autonomous car will increase if it drives in a human-like manner, sparse research offers the naturalistic experience from a passenger's seat perspective to examine the human likeness of current autonomous cars. The present study tested whether the AI driver could create a human-like ride experience for passengers based on 69 participants' feedback in a real-road scenario. We designed a ride experience-based version of the non-verbal Turing test for automated driving. Participants rode in autonomous cars (driven by either human or AI drivers) as a passenger and judged whether the driver was human or AI. The AI driver failed to pass our test because passengers detected the AI driver above chance. In contrast, when the human driver drove the car, the passengers' judgement was around chance. We further investigated how human passengers ascri
    
[^34]: 通过语义一致性测量大型语言模型的可靠性。

    Measuring Reliability of Large Language Models through Semantic Consistency. (arXiv:2211.05853v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.05853](http://arxiv.org/abs/2211.05853)

    本研究通过开发语义一致性度量来评估大型预训练语言模型的性能，以比较不同PLM的可靠性，保证其在相同或相似的提示下生成的输出一致。

    

    虽然大型预训练语言模型（PLMs）在许多自然语言处理任务中表现出极高的流畅性和性能，但最近的研究表明，表现良好的PLMs非常敏感，对于输入的提示非常敏感。即使提示在语义上是相同的，语言模型也可能给出非常不同的答案。当考虑PLMs的安全和可信赖部署时，我们希望它们在意思相同或表达相同意图的提示下的输出是一致的。虽然一些研究已经探讨了最先进的PLMs如何解决这个需求，但它们仅限于评估单个或多个单词答案的词汇等价性，而不涉及生成文本序列的一致性。为了理解在生成文本设置下PLMs的一致性，我们开发了一个语义一致性度量，允许比较开放式文本输出的一致性。我们实现了几个版本的一致性度量来评估多个PLM的性能。

    While large pretrained language models (PLMs) demonstrate incredible fluency and performance on many natural language tasks, recent work has shown that well-performing PLMs are very sensitive to what prompts are feed into them. Even when prompts are semantically identical, language models may give very different answers. When considering safe and trustworthy deployments of PLMs we would like their outputs to be consistent under prompts that mean the same thing or convey the same intent. While some work has looked into how state-of-the-art PLMs address this need, they have been limited to only evaluating lexical equality of single- or multi-word answers and do not address consistency of generative text sequences. In order to understand consistency of PLMs under text generation settings, we develop a measure of semantic consistency that allows the comparison of open-ended text outputs. We implement several versions of this consistency metric to evaluate the performance of a number of PLM
    
[^35]: 面具语言模型中的性别化心理健康歧视

    Gendered Mental Health Stigma in Masked Language Models. (arXiv:2210.15144v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.15144](http://arxiv.org/abs/2210.15144)

    面具语言模型存在性别化心理健康歧视，捕捉到了关于性别在心理健康方面的社会歧视，需要考虑性别因素来避免歧视。

    

    心理健康歧视阻碍了许多人获得适当的治疗，社会心理学研究表明，心理健康倾向于被男性忽视。本研究探讨了面具语言模型中的性别化心理健康歧视。我们运用临床心理学文献来建立框架来实现心理健康歧视的操作性，使用心理学研究中的提示来评估模型生成性别化词汇的倾向性。我们发现面具语言模型捕捉到了关于性别在心理健康方面的社会歧视：在有心理健康问题的句子中，模型更有可能预测女性主语而非男性（32％比19％），这种差异在表明寻求治疗行为的句子中更为明显。此外，我们发现不同的模型在男女的歧视维度上表现不同，将如愤怒、责怪和怜悯等刻板印象与心理健康问题的女性联系得更紧密。我们的发现强调了需要考虑自然语言处理中的性别化心理健康歧视，并敦促研究人员和实践者注意他们的模型可能对维持有害刻板印象的影响。

    Mental health stigma prevents many individuals from receiving the appropriate care, and social psychology studies have shown that mental health tends to be overlooked in men. In this work, we investigate gendered mental health stigma in masked language models. In doing so, we operationalize mental health stigma by developing a framework grounded in psychology research: we use clinical psychology literature to curate prompts, then evaluate the models' propensity to generate gendered words. We find that masked language models capture societal stigma about gender in mental health: models are consistently more likely to predict female subjects than male in sentences about having a mental health condition (32% vs. 19%), and this disparity is exacerbated for sentences that indicate treatment-seeking behavior. Furthermore, we find that different models capture dimensions of stigma differently for men and women, associating stereotypes like anger, blame, and pity more with women with mental he
    
[^36]: LittleBird：用于问答的更快更长Transformer

    LittleBird: Efficient Faster & Longer Transformer for Question Answering. (arXiv:2210.11870v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.11870](http://arxiv.org/abs/2210.11870)

    LittleBird是一个基于BigBird的问答模型，通过使用更灵活和高效的位置表示方法ALiBi和替换全局信息表示方法来提高速度和内存占用。它可以在短输入的预训练语言模型的基础上，对长输入进行工作并且在低资源的语言中表现良好。

    

    BERT在各种自然语言处理任务中都表现出了出色的成果。但由于其注意机制，它在处理长输入方面存在局限性。Longformer、ETC和BigBird解决了这个问题并有效地解决了二次依赖性问题。然而，我们发现这些模型并不足够，因此提出了LittleBird，它是基于BigBird的新型模型，具有更高的速度和更小的内存占用，同时保持准确性。特别是，我们设计了一种更灵活、更有效的位置表示方法，称为Attention with Linear Biases (ALiBi)。我们还表明，在BigBird中用于表示全局信息的方法可以替换为打包和解包注意力，这更有效。该模型可以在用于短输入的预训练语言模型的基础上，对长输入进行工作，并且可以重用现有的预训练语言模型来高效地训练短输入。这对于获取大量长文本数据困难的低资源语言而言是一个重要的优势。

    BERT has shown a lot of sucess in a wide variety of NLP tasks. But it has a limitation dealing with long inputs due to its attention mechanism. Longformer, ETC and BigBird addressed this issue and effectively solved the quadratic dependency problem. However we find that these models are not sufficient, and propose LittleBird, a novel model based on BigBird with improved speed and memory footprint while maintaining accuracy. In particular, we devise a more flexible and efficient position representation method based on Attention with Linear Biases (ALiBi). We also show that replacing the method of global information represented in the BigBird with pack and unpack attention is more effective. The proposed model can work on long inputs even after being pre-trained on short inputs, and can be trained efficiently reusing existing pre-trained language model for short inputs. This is a significant benefit for low-resource languages where large amounts of long text data are difficult to obtain.
    
[^37]: 分解提示：一种解决复杂任务的模块化方法

    Decomposed Prompting: A Modular Approach for Solving Complex Tasks. (arXiv:2210.02406v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.02406](http://arxiv.org/abs/2210.02406)

    分解提示是解决复杂任务的一种新方法，它通过将复杂任务分解成更简单的子任务来委托给设计专门的提示库，优化每个提示的特定子任务，并可以进一步分解、替换或更新。我们的方法在少样本提示和符号推理任务上表现出色，表明具有潜力扩展到更大和更复杂的任务。

    

    少样本提示是一种令人惊讶的强大方法，可用于使用大型语言模型（LLM）解决各种任务。然而，随着任务复杂性的增加，或者当任务的各个推理步骤本身难以学习，特别是当它们嵌入到更复杂的任务中时，这种方法遇到了困难。为了解决这个问题，我们提出了“分解提示”，这是一种通过将复杂任务（通过提示）分解成更简单的子任务来解决复杂任务的新方法，这些子任务可以委托给专门为这些子任务设计的提示基础的LLM库。这种模块化结构允许优化每个提示的特定子任务，必要时进一步分解，甚至可以轻松替换更有效的提示、训练模型或符号函数。我们展示了分解提示的灵活性和模块化性能够优于使用GPT3的先前少样本提示的工作。对于符号推理任务，我们可以将对LLM困难的子任务进一步分解为更简单的子任务，从而不需要任何人设计的符号函数来解决这些任务。我们的方法显示出在扩展到更大、更复杂的任务时的潜力。

    Few-shot prompting is a surprisingly powerful way to use Large Language Models (LLMs) to solve various tasks. However, this approach struggles as the task complexity increases or when the individual reasoning steps of the task themselves are hard to learn, especially when embedded in more complex tasks. To address this, we propose Decomposed Prompting, a new approach to solve complex tasks by decomposing them (via prompting) into simpler sub-tasks that can be delegated to a library of prompting-based LLMs dedicated to these sub-tasks. This modular structure allows each prompt to be optimized for its specific sub-task, further decomposed if necessary, and even easily replaced with more effective prompts, trained models, or symbolic functions if desired. We show that the flexibility and modularity of Decomposed Prompting allows it to outperform prior work on few-shot prompting using GPT3. On symbolic reasoning tasks, we can further decompose sub-tasks that are hard for LLMs into even sim
    
[^38]: 边缘平台上的反社会行为外溢：社区禁止的意外后果

    Spillover of Antisocial Behavior from Fringe Platforms: The Unintended Consequences of Community Banning. (arXiv:2209.09803v2 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2209.09803](http://arxiv.org/abs/2209.09803)

    研究表明，禁止问题社区可能导致用户迁移到监管标准较低的边缘平台，而参与这些平台可能会导致在主流平台上的反社会行为增加。

    

    在线平台面临着保持社区文明和尊重的压力。因此，像Reddit和Facebook这样的主流平台禁止问题社区通常会受到热烈的公众反应。然而，这种政策可能导致用户迁移到监管标准较低且允许像喷子和骚扰这样反社会行为的替代边缘平台。由于这些社区的用户通常在主流和边缘平台上保持共同活动，所以反社会行为可能会波及到主流平台。我们通过分析从r/The_Donald、r/GenderCritical和r/Incels迁移到边缘平台的约70,000名用户来研究这种可能的外溢效应。使用差异分离设计，我们将共同活动用户与匹配的对照组对比，估计边缘平台参与对Reddit用户反社会行为的因果影响。我们的结果显示，在监管标准较低的边缘平台上参与可能导致Reddit用户的反社会行为增加。这突显了社区禁止的意外后果，并建议需要更加考虑周全的监管政策。

    Online platforms face pressure to keep their communities civil and respectful. Thus, the bannings of problematic online communities from mainstream platforms like Reddit and Facebook are often met with enthusiastic public reactions. However, this policy can lead users to migrate to alternative fringe platforms with lower moderation standards and where antisocial behaviors like trolling and harassment are widely accepted. As users of these communities often remain co-active across mainstream and fringe platforms, antisocial behaviors may spill over onto the mainstream platform. We study this possible spillover by analyzing around 70,000 users from three banned communities that migrated to fringe platforms: r/The_Donald, r/GenderCritical, and r/Incels. Using a difference-in-differences design, we contrast co-active users with matched counterparts to estimate the causal effect of fringe platform participation on users' antisocial behavior on Reddit. Our results show that participating in 
    
[^39]: 自监督的多模态训练，利用未经整理的图像和报告实现放射学零样本监督人工智能

    Self-supervised Multi-modal Training from Uncurated Image and Reports Enables Zero-shot Oversight Artificial Intelligence in Radiology. (arXiv:2208.05140v4 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2208.05140](http://arxiv.org/abs/2208.05140)

    本文提出了一种名为Medical X-VL的视觉语言模型，使用自监督单模型和融合编码器，以实现放射学中的零样本监督人工智能。

    

    监管型AI是放射学中的新兴概念，其中AI通过不断支持放射学家的决策，形成与放射学家的共生关系。视觉语言模型的最新进展揭示了监管性AI的长期问题，即它们理解视觉和文本概念及其语义对应关系。然而，将视觉语言模型应用于医学领域的成功案例还很有限，因为目前的视觉语言模型和学习策略需要图像和文本对的网络规模数据语料库，这在医学领域通常难以实现。因此，我们提出了一种被称为医学交叉关注视觉语言模型（Medical X-VL）的模型，利用适用于医学领域的关键组件。我们的医学X-VL模型基于以下组件：医学领域的自监督单模型和融合编码器，以构建多模态视觉语言模型。

    Oversight AI is an emerging concept in radiology where the AI forms a symbiosis with radiologists by continuously supporting radiologists in their decision-making. Recent advances in vision-language models sheds a light on the long-standing problems of the oversight AI by the understanding both visual and textual concepts and their semantic correspondences. However, there have been limited successes in the application of vision-language models in the medical domain, as the current vision-language models and learning strategies for photographic images and captions call for the web-scale data corpus of image and text pairs which was not often feasible in the medical domain. To address this, here we present a model dubbed Medical Cross-attention Vision-Language model (Medical X-VL), leveraging the key components to be tailored for the medical domain. Our medical X-VL model is based on the following components: self-supervised uni-modal models in medical domain and fusion encoder to bridge
    
[^40]: 神经数据生成文本的创新：综述（arXiv：2207.12571v2 [cs.CL] 更新版）

    Innovations in Neural Data-to-text Generation: A Survey. (arXiv:2207.12571v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2207.12571](http://arxiv.org/abs/2207.12571)

    本文综述了过去十年神经数据生成文本（DTG）领域的创新，将其与其他自然语言生成技术（NLG）区分开来，并强调了关注系统语言能力和公平、公正的DTG研究前景。

    

    过去十年间，神经语言处理（NLP）的兴起在数据生成文本（DTG）领域同样带来了显著的创新。本综述通过结构化的方法，对神经DTG范式的方法、基准数据集和评估协议进行了综合性的概述，从自然语言生成（NLG）领域中区分出DTG，包括对文献的最新综合和技术采用阶段的重点介绍，强调了不仅关注设计具有语言能力的系统，而且还要关注体现公平和公 accountability 的系统的DTG研究有前景的方向。

    The neural boom that has sparked natural language processing (NLP) research through the last decade has similarly led to significant innovations in data-to-text generation (DTG). This survey offers a consolidated view into the neural DTG paradigm with a structured examination of the approaches, benchmark datasets, and evaluation protocols. This survey draws boundaries separating DTG from the rest of the natural language generation (NLG) landscape, encompassing an up-to-date synthesis of the literature, and highlighting the stages of technological adoption from within and outside the greater NLG umbrella. With this holistic view, we highlight promising avenues for DTG research that not only focus on the design of linguistically capable systems but also systems that exhibit fairness and accountability.
    
[^41]: NusaX: 10种印度尼西亚当地语的多语言情感平行数据集

    NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages. (arXiv:2205.15960v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.15960](http://arxiv.org/abs/2205.15960)

    本文开发了10种印度尼西亚低资源语言的第一个平行资源，包括数据集、基准和词典。该资源将有助于激发有关印尼语和其他代表性不足语言的NLP研究。

    

    自然语言处理在机器翻译和搜索引擎等技术方面对社会产生了重大影响。尽管NLP技术获得成功，但仅适用于高资源语言，如英语和汉语，而对于许多语言仍然无法获得数据资源和基准。本文着眼于为印度尼西亚语言开发资源，尽管它是语言多样性第二，但大多数印尼语言都被归类为濒危语言，其中一些甚至灭绝了。我们为10种低资源印尼语言开发了第一个平行资源，包括数据集、多任务基准和词典，以及平行印尼语-英语数据集。我们进行了广泛的分析，并描述了创建这种资源时面临的挑战。我们希望我们的工作能够激发有关印尼语和其他代表性不足语言的NLP研究。

    Natural language processing (NLP) has a significant impact on society via technologies such as machine translation and search engines. Despite its success, NLP technology is only widely available for high-resource languages such as English and Chinese, while it remains inaccessible to many languages due to the unavailability of data resources and benchmarks. In this work, we focus on developing resources for languages in Indonesia. Despite being the second most linguistically diverse country, most languages in Indonesia are categorized as endangered and some are even extinct. We develop the first-ever parallel resource for 10 low-resource languages in Indonesia. Our resource includes datasets, a multi-task benchmark, and lexicons, as well as a parallel Indonesian-English dataset. We provide extensive analyses and describe the challenges when creating such resources. We hope that our work can spark NLP research on Indonesian and other underrepresented languages.
    
[^42]: 我们需要标签规范化来微调预训练语言模型吗？

    Do we need Label Regularization to Fine-tune Pre-trained Language Models?. (arXiv:2205.12428v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.12428](http://arxiv.org/abs/2205.12428)

    本文研究了不同的标签规范化技术，发现标签规范化通常会提高微调模型的性能，尤其是当使用较小的预训练语言模型时。提出了一种新的无教师网络的知识蒸馏方法，并发现其效果与知识蒸馏相当，但取决于教师网络的大小和下游任务。

    

    知识蒸馏是一种重要的神经模型压缩技术，它严重依赖于教师网络的预测来指导学生模型的训练。然而，由于预训练语言模型的不断增大，知识蒸馏经常被采用在许多涉及预训练语言模型的自然语言处理任务中。本文通过对各种预训练语言模型进行全面的实验，展示了标签规范化通常会提高微调模型的性能，即使使用较小的预训练语言模型。我们还发现，该方法的好处取决于教师网络的大小，并提出了一种新的无教师网络的知识蒸馏方法，称为“联合微调”，它使用学生模型的集合来代替教师网络，取得了与知识蒸馏相当的结果。

    Knowledge Distillation (KD) is a prominent neural model compression technique that heavily relies on teacher network predictions to guide the training of a student model. Considering the ever-growing size of pre-trained language models (PLMs), KD is often adopted in many NLP tasks involving PLMs. However, it is evident that in KD, deploying the teacher network during training adds to the memory and computational requirements of training. In the computer vision literature, the necessity of the teacher network is put under scrutiny by showing that KD is a label regularization technique that can be replaced with lighter teacher-free variants such as the label-smoothing technique. However, to the best of our knowledge, this issue is not investigated in NLP. Therefore, this work concerns studying different label regularization techniques and whether we actually need them to improve the fine-tuning of smaller PLM networks on downstream tasks. In this regard, we did a comprehensive set of exp
    
[^43]: TemporalWiki: 一个用于训练和评估不断更新的语言模型的终身基准

    TemporalWiki: A Lifelong Benchmark for Training and Evaluating Ever-Evolving Language Models. (arXiv:2204.14211v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2204.14211](http://arxiv.org/abs/2204.14211)

    TemporalWiki是一个用来训练和评估不断更新的语言模型的终身基准，通过利用英语维基百科和英语维基数据之间的连续快照差异进行训练和评估，使研究者可以周期性地跟踪LM的保留前一知识和在每个时间点上获取更新/新知识的能力。

    

    随着世界的变化，语言模型（LMs）变得过时，它们通常无法执行需要最新事实信息的任务，这在训练期间不存在或存在不同，这种现象叫做时间错位。这是一个挑战性的问题，因为研究界还缺乏一个一致的数据集，用于评估LMs对于经常更新的知识库（如维基百科）的适应能力。为此，我们引入了TemporalWiki，一个终身基准，用于不断更新的LMs，利用英语维基百科和英语维基数据之间的连续快照差异进行训练和评估。因此，该基准允许研究人员周期性地跟踪LM的保留前一知识和在每个时间点上获取更新/新知识的能力。我们还发现，在我们的基准测试中，通过继续学习方法对差异数据进行LM的训练，与在整个快照上使用12倍更少的计算实现相似或更好的困惑度。

    Language Models (LMs) become outdated as the world changes; they often fail to perform tasks requiring recent factual information which was absent or different during training, a phenomenon called temporal misalignment. This is especially a challenging problem because the research community still lacks a coherent dataset for assessing the adaptability of LMs to frequently-updated knowledge corpus such as Wikipedia. To this end, we introduce TemporalWiki, a lifelong benchmark for ever-evolving LMs that utilizes the difference between consecutive snapshots of English Wikipedia and English Wikidata for training and evaluation, respectively. The benchmark hence allows researchers to periodically track an LM's ability to retain previous knowledge and acquire updated/new knowledge at each point in time. We also find that training an LM on the diff data through continual learning methods achieves similar or better perplexity than on the entire snapshot in our benchmark with 12 times less comp
    
[^44]: 零样本迁移学习中的综合缩放技术

    Combined Scaling for Zero-shot Transfer Learning. (arXiv:2111.10050v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2111.10050](http://arxiv.org/abs/2111.10050)

    提出了一种名为 BASIC 的综合缩放方法，在零样本迁移学习任务中实现了85.7%的高准确率，并在稳健性基准测试中表现出显着的改进。为了实现这些结果，该方法在数据大小、模型大小和批量大小三个维度上对比学习框架进行了放大。

    

    我们提出了一种综合缩放方法（称为 BASIC），在不学习任何标记的 ImageNet 示例的情况下，该方法在 ImageNet ILSVRC-2012 验证集上实现了85.7%的 top-1 准确率。该准确率超过了最佳发布的类似模型（CLIP 和 ALIGN）9.3%。我们的 BASIC 模型还在稳健性基准测试中表现出了显著的改进。例如，在 5 个具有自然分布偏移的测试集（例如 ImageNet-{A,R,V2, Sketch} 和 ObjectNet）上，我们的模型实现了84.3% 的 top-1 平均准确率，只有一个小小的跌落，与其原始的 ImageNet 准确率相比。为了实现这些结果，我们在三个维度上放大了 CLIP 和 ALIGN 的对比学习框架：数据大小，模型大小和批量大小。我们的数据集拥有 66 亿个带有噪声的图像-文本对，比 ALIGN 大 4 倍，比 CLIP 大 16 倍。我们最大的模型有 30 亿个权重，参数比 ALIGN 和 CLIP 多出 3.75 倍，FLOPs 多出 8 倍。最后，我们的批处理大小为 65536，比 CLIP 多 2 倍，比 ALIGN 多 4 倍。

    We present a combined scaling method - named BASIC - that achieves 85.7% top-1 accuracy on the ImageNet ILSVRC-2012 validation set without learning from any labeled ImageNet example. This accuracy surpasses best published similar models - CLIP and ALIGN - by 9.3%. Our BASIC model also shows significant improvements in robustness benchmarks. For instance, on 5 test sets with natural distribution shifts such as ImageNet-{A,R,V2,Sketch} and ObjectNet, our model achieves 84.3% top-1 average accuracy, only a small drop from its original ImageNet accuracy. To achieve these results, we scale up the contrastive learning framework of CLIP and ALIGN in three dimensions: data size, model size, and batch size. Our dataset has 6.6B noisy image-text pairs, which is 4x larger than ALIGN, and 16x larger than CLIP. Our largest model has 3B weights, which is 3.75x larger in parameters and 8x larger in FLOPs than ALIGN and CLIP. Finally, our batch size is 65536 which is 2x more than CLIP and 4x more than
    

