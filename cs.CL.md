# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Evaluating Large Language Models for Radiology Natural Language Processing.](http://arxiv.org/abs/2307.13693) | 本研究通过对32个大型语言模型进行评估，填补了放射学自然语言处理领域的评估空白。评估结果为这些模型的性能、优势和弱点提供了关键见解，为它们在医学领域的实际应用提供了指导。 |
| [^2] | [ARB: Advanced Reasoning Benchmark for Large Language Models.](http://arxiv.org/abs/2307.13692) | ARB是一个新型基准，包含了数学、物理、生物、化学和法律领域的高级推理问题。目前的语言模型在这些任务上得分远低于50%，为了提高评估能力，我们引入了基于评分标准的评估方法。 |
| [^3] | [A Comprehensive Evaluation and Analysis Study for Chinese Spelling Check.](http://arxiv.org/abs/2307.13655) | 本研究在中文拼写检查领域进行了综合评估与分析，发现合理融合语音和图形信息可以提高检查效果，模型对测试集的错误分布敏感，先前经验对模型有重要影响，常用的基准测试集无法可靠评估模型性能。 |
| [^4] | [Contributions to the Improvement of Question Answering Systems in the Biomedical Domain.](http://arxiv.org/abs/2307.13631) | 这篇论文提出了在生物医学领域中问题回答系统的改进方法，包括问题类型分类和答案提取方法的优化。 |
| [^5] | [GPT-3 Models are Few-Shot Financial Reasoners.](http://arxiv.org/abs/2307.13617) | GPT-3模型在金融领域的少样本推理表现有限，需要使用独立的检索模型和逻辑引擎来获得最佳性能。 |
| [^6] | [XDLM: Cross-lingual Diffusion Language Model for Machine Translation.](http://arxiv.org/abs/2307.13560) | 本文介绍了XDLM，一种用于机器翻译的跨语言扩散语言模型。通过预训练和微调阶段，我们成功地提高了在不同语言之间的翻译性能，超过了传统扩散模型和Transformer模型。 |
| [^7] | [FacTool: Factuality Detection in Generative AI -- A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios.](http://arxiv.org/abs/2307.13528) | 提出了FacTool框架，用于检测大型语言模型（如ChatGPT）生成的文本中的事实错误。实验结果表明该方法在知识型问答、代码生成、数学推理和科学文献综述等四个任务中具有良好的效果。 |
| [^8] | [Zshot: An Open-source Framework for Zero-Shot Named Entity Recognition and Relation Extraction.](http://arxiv.org/abs/2307.13497) | Zshot是一个开源框架，用于零样本命名实体识别和关系抽取，通过比较不同的最新ZSL方法，支持研究人员和工业界的需求。 |
| [^9] | [Holistic Exploration on Universal Decompositional Semantic Parsing: Architecture, Data Augmentation, and LLM Paradigm.](http://arxiv.org/abs/2307.13424) | 本文全面探索了通用分解语义解析，通过引入级联模型和优化架构，减少推理时间并提高效果。同时，不同的数据增强方法进一步改进了解析结果。研究发现ChatGPT在属性解析方面表现好，但在关系解析上存在困难，使用ChatGPT进行数据增强效果不佳。 |
| [^10] | [Towards Resolving Word Ambiguity with Word Embeddings.](http://arxiv.org/abs/2307.13417) | 本文提出了一种方法，通过应用DBSCAN聚类算法来识别和评估具有歧义的单词，从而解决词义歧义问题。 |
| [^11] | [Towards Bridging the Digital Language Divide.](http://arxiv.org/abs/2307.13405) | 本文旨在探讨“语言偏见”现象，即多语言处理系统存在对某些语言的硬编码倾向，忽视了语言复杂性和语言社区的需求，阻碍了AI技术覆盖到“资源有限的语言”。 |
| [^12] | [Embedding Models for Supervised Automatic Extraction and Classification of Named Entities in Scientific Acknowledgements.](http://arxiv.org/abs/2307.13377) | 本论文评估了在科学论文致谢文本中自动提取和分类被致谢实体的不同嵌入模型的性能。在使用Flair NLP框架进行命名实体识别任务的训练中，Flair Embeddings模型在中等规模语料库上达到了最佳准确度（0.79）。同时，扩大训练语料库的规模可以显著提高所有训练算法的准确性。 |
| [^13] | [Empower Your Model with Longer and Better Context Comprehension.](http://arxiv.org/abs/2307.13365) | 本文研究了大语言模型（LLMs）内的信息传递，并提出了一种名为注意力转移的技术，该技术能够使模型在不增加训练或对生成流畅性的影响的情况下实现更长更好的上下文理解。 |
| [^14] | [Analyzing Chain-of-Thought Prompting in Large Language Models via Gradient-based Feature Attributions.](http://arxiv.org/abs/2307.13339) | 通过基于梯度的特征归因方法，研究发现思维链启发在大型语言模型中并没有增加与语义相关标记的重要性，但提高了与问题相关标记的重要性分数的鲁棒性。 |
| [^15] | [An Intent Taxonomy of Legal Case Retrieval.](http://arxiv.org/abs/2307.13298) | 本论文提出了一种新颖的法律案件检索的意图分类法，在明确了法律检索用户的潜在搜索意图更加复杂的情况下，通过五种意图类型进行分类。该分类法经过广泛的评估，揭示了用户行为和满意度方面的显著差异。 |
| [^16] | [LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA Composition.](http://arxiv.org/abs/2307.13269) | 本文研究了LoRA组合在跨任务通用性上的可行性，并提出了LoraHub框架，能够通过组合不同任务上训练的LoRA模块，实现对未见任务的可适应性性能。实验结果表明，LoraHub在少样本场景中能够有效模拟上下文学习的性能，而无需上下文示例。 |
| [^17] | [Schema-Driven Actionable Insight Generation and Smart Recommendation.](http://arxiv.org/abs/2307.13176) | 本文介绍了一种基于模式的方法，用于从数据中生成可执行的洞察，并根据用户的反馈对洞察进行排序，展示了其适应反馈的能力。 |
| [^18] | [Opinion Mining Using Population-tuned Generative Language Models.](http://arxiv.org/abs/2307.13173) | 本文提出了一种使用经过调整的生成式语言模型进行观点挖掘的方法。通过特定数据的微调，我们的方法可以学习和转移观点，并保持极性的比例。实验结果表明我们的方法在挖掘真实文本中的观点洞察方面具有良好的性能。 |
| [^19] | [Explaining Math Word Problem Solvers.](http://arxiv.org/abs/2307.13128) | 该论文研究了基于神经网络的自动化数学词问题求解器的工作原理，并发现这些求解器可能依赖于表面模式而不是数学语义逻辑来生成解决方案。 |
| [^20] | [How to use LLMs for Text Analysis.](http://arxiv.org/abs/2307.13106) | 本文介绍了如何使用LLMs进行文本分析，LLMs作为一种非常多功能的文本分析方法在社会科学中具有广泛的应用前景。使用LLMs可以实现从文本标注和分类到情感分析和批判性话语分析等多种任务，并且易于使用且速度快。这对于具有有限编程经验的学生和研究者来说尤其有用。 |
| [^21] | [Making Metadata More FAIR Using Large Language Models.](http://arxiv.org/abs/2307.13085) | 本研究提出了一种名为FAIRMetaText的自然语言处理应用程序，用于比较元数据。该应用程序分析元数据的自然语言描述，并提供数学相似度度量，可用于分析和识别可替代术语，从而大大减少人力成本。 |
| [^22] | [Extracting Molecular Properties from Natural Language with Multimodal Contrastive Learning.](http://arxiv.org/abs/2307.12996) | 该论文研究了如何使用多模态对比学习方法从自然语言中提取分子属性信息，通过改进文本检索和引入分子图扩增策略等方法提高了属性预测性能。实验结果显示相对于仅在图模态上预训练的模型，我们取得了+4.26%的AUROC增益和+1.54%的增益。 |
| [^23] | [Corrections of Zipf's and Heaps' Laws Derived from Hapax Rate Models.](http://arxiv.org/abs/2307.12896) | 本文的创新是基于Hapax Rate模型引入了对Zipf和Heaps定律的修正，并发现逻辑模型拟合效果最优。 |
| [^24] | [RRAML: Reinforced Retrieval Augmented Machine Learning.](http://arxiv.org/abs/2307.12798) | RRAML是一种新的机器学习框架，将大型语言模型（LLMs）的推理能力与用户提供的庞大数据库中的支持信息相结合。利用强化学习的进展，该方法成功解决了几个关键挑战。 |
| [^25] | [Question Decomposition Improves the Faithfulness of Model-Generated Reasoning.](http://arxiv.org/abs/2307.11768) | 通过将问题分解为子问题，可以显著提高大型语言模型生成推理的忠实度。 |
| [^26] | [EmotionPrompt: Leveraging Psychology for Large Language Models Enhancement via Emotional Stimulus.](http://arxiv.org/abs/2307.11760) | EmotionPrompt是一个基于心理学的方法，通过将情感刺激融入到提示中，提升了大型语言模型在各项任务上的性能，并且同时改善了其真实性和信息量。 |
| [^27] | [Retentive Network: A Successor to Transformer for Large Language Models.](http://arxiv.org/abs/2307.08621) | Retentive Network（RetNet）作为大型语言模型的基础架构，实现了训练并行、低成本推理和良好的性能。通过并行、循环和分块循环三种计算范式，RetNet具有训练并行化、低成本推理和高效的长序列建模的特点。 |
| [^28] | [Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language Models.](http://arxiv.org/abs/2307.08303) | 本论文提出了一种使用软提示调优来增强密集检索的方法（SPTAR）。通过优化任务特定的软提示并利用大型语言模型为未标记的文档生成弱查询，可以提高零样本和少样本的密集检索模型的性能。 |
| [^29] | [Generative User-Experience Research for Developing Domain-specific Natural Language Processing Applications.](http://arxiv.org/abs/2306.16143) | 本论文提出了一种在开发领域特定自然语言处理应用中整合生成式用户体验研究的方法。该方法将领域用户纳入原型开发的不同阶段，以更好地了解用户需求和评估用户价值的变化。 |
| [^30] | [Towards Explainable and Language-Agnostic LLMs: Symbolic Reverse Engineering of Language at Scale.](http://arxiv.org/abs/2306.00017) | 本文提出结合符号表示和自下而上的逆向工程的方法，解决大规模语言模型在真正语言理解上的局限性，实现可解释的、语言无关的LLMs。 |
| [^31] | [Interpretable Word Sense Representations via Definition Generation: The Case of Semantic Change Analysis.](http://arxiv.org/abs/2305.11993) | 该论文提出使用自动生成的自然语言定义作为词义表示，可以使语义变化分析更具可解释性，并允许用户直观解释词义的历时轨迹。此外，上下文化的定义在上下文中的语义相似性上也优于令牌或使用句嵌入。 |
| [^32] | [DataComp: In search of the next generation of multimodal datasets.](http://arxiv.org/abs/2304.14108) | DataComp是一个基准测试，旨在通过提出新的训练集来解决数据集在机器学习生态系统中的缺陷。它提供了一个多规模设计的实验测试平台，使用12.8B个图像-文本对的新候选池，让研究人员可以通过设计新的过滤技术或策划新的数据源并评估它们的新数据集来进行创新。 |
| [^33] | [Stabilizing Transformer Training by Preventing Attention Entropy Collapse.](http://arxiv.org/abs/2303.06296) | 本文研究了Transformer的训练动态，发现低注意力熵伴随着高训练不稳定性，提出了一种简单而有效的解决方案$\sigma$Reparam，成功地防止了注意力层中的熵崩溃，促进了更稳定的训练。 |
| [^34] | [Concept Algebra for Score-Based Conditional Models.](http://arxiv.org/abs/2302.03693) | 本文研究了基于分数的条件模型中学习表示的结构，并开发了一种数学形式化表达概念被编码为表示空间子空间的思想。利用这个方法，我们提出了一种简单的方法来识别给定概念对应的表示部分，并通过代数操作操纵模型所表达的概念。 |
| [^35] | [Revision Transformers: Instructing Language Models to Change their Values.](http://arxiv.org/abs/2210.10332) | 本论文提出了修订Transformer（RiT），旨在解决当前Transformer语言模型中出现的捷径学习和偏见问题，以便更方便地进行模型更新。RiT采用了大规模预训练的语言模型和清晰结构的修订引擎的组合，通过少量的努力和用户互动，可以轻松更新模型的知识。在道德数据集上的实验结果表明RiT在模型修订方面表现出强大的性能。 |
| [^36] | [Meta-Referential Games to Learn Compositional Learning Behaviours.](http://arxiv.org/abs/2207.08012) | 本论文提出了一种元元反游戏学习的方法来解决组合学习行为的问题，通过解决绑定问题来支持人工智能代理展示组合学习行为的能力。 |
| [^37] | [End-to-End Annotator Bias Approximation on Crowdsourced Single-Label Sentiment Analysis.](http://arxiv.org/abs/2111.02326) | 本文提出一种在众包单标签情感分析中解决注释者偏差的端到端方法，通过精确的偏差建模和真实值估计来改善准确性，实验证明在样本只由单个注释者标注的情况下效果显著。 |
| [^38] | [An Analysis of Programming Course Evaluations Before and After the Introduction of an Autograder.](http://arxiv.org/abs/2110.15134) | 本研究分析了引入自动评分系统前后多个大规模计算机科学基础课程的评估结果，探讨了自动评分系统对学生对编程课程和教学感知的影响。 |
| [^39] | [SocialVisTUM: An Interactive Visualization Toolkit for Correlated Neural Topic Models on Social Media Opinion Mining.](http://arxiv.org/abs/2110.10575) | 本文展示了如何使用基于词嵌入的主题建模方法，在交互式可视化工具包SocialVisTUM中显示相关主题模型。该工具包提供了丰富的功能和细节，支持对大文本集合的探索。从一个关于有机食品消费的英语社交媒体讨论数据的实例中，可视化结果证实了一项消费者研究的发现。 |
| [^40] | [Classification of Consumer Belief Statements From Social Media.](http://arxiv.org/abs/2106.15498) | 本研究探讨了使用复杂的专家注解在社交媒体中进行消费者信念陈述分类的准确性，比较了细粒度和抽象类别的标签，并说明复杂专家注解在高度特定的意见挖掘中的潜在优势。 |

# 详细

[^1]: 评估用于放射学自然语言处理的大型语言模型

    Evaluating Large Language Models for Radiology Natural Language Processing. (arXiv:2307.13693v1 [cs.CL])

    [http://arxiv.org/abs/2307.13693](http://arxiv.org/abs/2307.13693)

    本研究通过对32个大型语言模型进行评估，填补了放射学自然语言处理领域的评估空白。评估结果为这些模型的性能、优势和弱点提供了关键见解，为它们在医学领域的实际应用提供了指导。

    

    大型语言模型（LLMs）的崛起标志着自然语言处理（NLP）领域的重大转变。LLMs已经在许多领域引起了革命性的变化，并在医学领域产生了重要影响。大型语言模型比以往任何时候都更丰富，并且其中许多模型具有双语能力，可以熟练处理英文和中文。然而，对这些模型进行全面评估仍有待开展。在放射学NLP的背景下，尤其明显缺乏这种评估。本研究旨在通过对32个LLMs在解释放射学报告方面进行批判性评估来填补这一空白。具体评估了从影像学发现中得出印象的能力。这个评估的结果为这些LLMs的性能、优势和弱点提供了关键见解，并为它们在医学领域的实际应用提供了指导。

    The rise of large language models (LLMs) has marked a pivotal shift in the field of natural language processing (NLP). LLMs have revolutionized a multitude of domains, and they have made a significant impact in the medical field. Large language models are now more abundant than ever, and many of these models exhibit bilingual capabilities, proficient in both English and Chinese. However, a comprehensive evaluation of these models remains to be conducted. This lack of assessment is especially apparent within the context of radiology NLP. This study seeks to bridge this gap by critically evaluating thirty two LLMs in interpreting radiology reports, a crucial component of radiology NLP. Specifically, the ability to derive impressions from radiologic findings is assessed. The outcomes of this evaluation provide key insights into the performance, strengths, and weaknesses of these LLMs, informing their practical applications within the medical domain.
    
[^2]: ARB：大型语言模型的高级推理基准

    ARB: Advanced Reasoning Benchmark for Large Language Models. (arXiv:2307.13692v1 [cs.CL])

    [http://arxiv.org/abs/2307.13692](http://arxiv.org/abs/2307.13692)

    ARB是一个新型基准，包含了数学、物理、生物、化学和法律领域的高级推理问题。目前的语言模型在这些任务上得分远低于50%，为了提高评估能力，我们引入了基于评分标准的评估方法。

    

    大型语言模型（LLMs）在各种定量推理和知识基准上展示了卓越的性能。然而，尽管在这些领域中还没有达到专家水平，但许多这些基准随着LLMs获得越来越高的分数而失去了效用。我们引入了ARB，一个由多个领域的高级推理问题组成的新型基准。ARB提供比以前的基准更具挑战性的测试，包括数学、物理、生物、化学和法律领域的问题。作为ARB的一部分，我们介绍了一组挑战性的数学和物理问题，需要高级符号推理和领域知识。我们评估了最近的模型，如GPT-4和Claude在ARB上的表现，并证明当前模型在更具挑战性的任务上得分远低于50%。为了改进自动和辅助评估能力，我们引入了基于评分标准的评估方法，允许GPT-4对其自身的中间推理步骤评分。

    Large Language Models (LLMs) have demonstrated remarkable performance on various quantitative reasoning and knowledge benchmarks. However, many of these benchmarks are losing utility as LLMs get increasingly high scores, despite not yet reaching expert performance in these domains. We introduce ARB, a novel benchmark composed of advanced reasoning problems in multiple fields. ARB presents a more challenging test than prior benchmarks, featuring problems in mathematics, physics, biology, chemistry, and law. As a subset of ARB, we introduce a challenging set of math and physics problems which require advanced symbolic reasoning and domain knowledge. We evaluate recent models such as GPT-4 and Claude on ARB and demonstrate that current models score well below 50% on more demanding tasks. In order to improve both automatic and assisted evaluation capabilities, we introduce a rubric-based evaluation approach, allowing GPT-4 to score its own intermediate reasoning steps. Further, we conduct 
    
[^3]: 对中文拼写检查的综合评估与分析研究

    A Comprehensive Evaluation and Analysis Study for Chinese Spelling Check. (arXiv:2307.13655v1 [cs.CL])

    [http://arxiv.org/abs/2307.13655](http://arxiv.org/abs/2307.13655)

    本研究在中文拼写检查领域进行了综合评估与分析，发现合理融合语音和图形信息可以提高检查效果，模型对测试集的错误分布敏感，先前经验对模型有重要影响，常用的基准测试集无法可靠评估模型性能。

    

    随着预训练模型的发展和语音和图形信息的融合，神经模型在中文拼写检查方面取得了高分。然而，由于测试集的限制，它并没有全面反映模型的能力。在本研究中，我们提取了代表性的模型范例，用九种结构实现，并在我们构建的不同目的的综合测试集上进行了实验。我们对结果进行了详细分析，发现：1）合理地融合语音和图形信息对拼写检查是有效的。2）模型对于测试集的错误分布敏感，这反映了模型的缺点并揭示了我们应该努力的方向。3）错误和上下文的先前经验对模型有重要影响。4）常用的基准测试集SIGHAN无法可靠评估模型的性能。

    With the development of pre-trained models and the incorporation of phonetic and graphic information, neural models have achieved high scores in Chinese Spelling Check (CSC). However, it does not provide a comprehensive reflection of the models' capability due to the limited test sets. In this study, we abstract the representative model paradigm, implement it with nine structures and experiment them on comprehensive test sets we constructed with different purposes. We perform a detailed analysis of the results and find that: 1) Fusing phonetic and graphic information reasonably is effective for CSC. 2) Models are sensitive to the error distribution of the test set, which reflects the shortcomings of models and reveals the direction we should work on. 3) Whether or not the errors and contexts have been seen has a significant impact on models. 4) The commonly used benchmark, SIGHAN, can not reliably evaluate models' performance.
    
[^4]: 在生物医学领域中贡献于问题回答系统的改进

    Contributions to the Improvement of Question Answering Systems in the Biomedical Domain. (arXiv:2307.13631v1 [cs.CL])

    [http://arxiv.org/abs/2307.13631](http://arxiv.org/abs/2307.13631)

    这篇论文提出了在生物医学领域中问题回答系统的改进方法，包括问题类型分类和答案提取方法的优化。

    

    这篇论文工作涉及到生物医学领域中的问题回答(QA)的框架，其中涉及到了几个具体的挑战，如专业的词库和术语、处理的问题类型以及目标文档的特征。我们特别关注于研究和改进那些旨在从大量的生物医学文本文档中找到准确和简短答案的方法。QA的目标是为提问者提供直接、简短和准确的回答。在这篇博士论文中，我们提出了四个贡献，以改进在生物医学领域中QA的性能。在我们的第一个贡献中，我们提出了一种基于机器学习的方法用于问题类型分类，以确定给定问题的类型，从而使生物医学QA系统能够使用适当的答案提取方法。我们还提出了另一种基于机器学习的方法，用于a...

    This thesis work falls within the framework of question answering (QA) in the biomedical domain where several specific challenges are addressed, such as specialized lexicons and terminologies, the types of treated questions, and the characteristics of targeted documents. We are particularly interested in studying and improving methods that aim at finding accurate and short answers to biomedical natural language questions from a large scale of biomedical textual documents in English. QA aims at providing inquirers with direct, short and precise answers to their natural language questions. In this Ph.D. thesis, we propose four contributions to improve the performance of QA in the biomedical domain. In our first contribution, we propose a machine learning-based method for question type classification to determine the types of given questions which enable to a biomedical QA system to use the appropriate answer extraction method. We also propose an another machine learning-based method to a
    
[^5]: GPT-3模型是少样本金融推理器

    GPT-3 Models are Few-Shot Financial Reasoners. (arXiv:2307.13617v1 [cs.CL])

    [http://arxiv.org/abs/2307.13617](http://arxiv.org/abs/2307.13617)

    GPT-3模型在金融领域的少样本推理表现有限，需要使用独立的检索模型和逻辑引擎来获得最佳性能。

    

    金融分析是评估公司业绩的重要工具。从业者通过深入的量化分析回答金融问题，从而做出有利可图的投资决策。因此，金融问答是一个需要对数字进行深入推理的问题回答任务。此外，目前尚不清楚预训练语言模型在金融领域的推理能力如何。目前的最新技术需要一个检索模型从文本中收集与金融问题相关的事实，并使用一个生成器来生成有效的金融程序和最终答案。然而，最近的大型语言模型如GPT-3仅仅通过少量示例就实现了广泛任务的最新性能。我们对GPT-3进行了多个实验，发现独立的检索模型和逻辑引擎仍然是实现这一任务的关键组件，尤其是由于金融领域的精确性要求。

    Financial analysis is an important tool for evaluating company performance. Practitioners work to answer financial questions to make profitable investment decisions, and use advanced quantitative analyses to do so. As a result, Financial Question Answering (QA) is a question answering task that requires deep reasoning about numbers. Furthermore, it is unknown how well pre-trained language models can reason in the financial domain. The current state-of-the-art requires a retriever to collect relevant facts about the financial question from the text and a generator to produce a valid financial program and a final answer. However, recently large language models like GPT-3 have achieved state-of-the-art performance on wide variety of tasks with just a few shot examples. We run several experiments with GPT-3 and find that a separate retrieval model and logic engine continue to be essential components to achieving SOTA performance in this task, particularly due to the precise nature of finan
    
[^6]: XDLM: 用于机器翻译的跨语言扩散语言模型

    XDLM: Cross-lingual Diffusion Language Model for Machine Translation. (arXiv:2307.13560v1 [cs.CL])

    [http://arxiv.org/abs/2307.13560](http://arxiv.org/abs/2307.13560)

    本文介绍了XDLM，一种用于机器翻译的跨语言扩散语言模型。通过预训练和微调阶段，我们成功地提高了在不同语言之间的翻译性能，超过了传统扩散模型和Transformer模型。

    

    最近，扩散模型在图像生成任务中表现出色，并且已经应用于神经语言处理（NLP）中的可控文本生成。然而，扩散模型在跨语言环境中的应用相对较少。此外，尽管已经研究了在单一语言中使用扩散模型进行预训练，但跨语言预训练的潜力仍未被深入研究。为了填补这些空白，我们提出了XDLM，一种新颖的用于机器翻译的跨语言扩散模型，包括预训练和微调阶段。在预训练阶段，我们提出了TLDM，一种新的训练目标，用于掌握不同语言之间的映射关系；在微调阶段，我们基于预训练模型构建了翻译系统。我们在几个机器翻译基准上进行了评估，并超过了扩散和Transformer基线模型。

    Recently, diffusion models have excelled in image generation tasks and have also been applied to neural language processing (NLP) for controllable text generation. However, the application of diffusion models in a cross-lingual setting is less unexplored. Additionally, while pretraining with diffusion models has been studied within a single language, the potential of cross-lingual pretraining remains understudied. To address these gaps, we propose XDLM, a novel Cross-lingual diffusion model for machine translation, consisting of pretraining and fine-tuning stages. In the pretraining stage, we propose TLDM, a new training objective for mastering the mapping between different languages; in the fine-tuning stage, we build up the translation system based on the pretrained model. We evaluate the result on several machine translation benchmarks and outperformed both diffusion and Transformer baselines.
    
[^7]: FacTool：生成AI中的事实性检测 —— 一种为多任务和多领域场景加强的工具增强框架

    FacTool: Factuality Detection in Generative AI -- A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios. (arXiv:2307.13528v1 [cs.CL])

    [http://arxiv.org/abs/2307.13528](http://arxiv.org/abs/2307.13528)

    提出了FacTool框架，用于检测大型语言模型（如ChatGPT）生成的文本中的事实错误。实验结果表明该方法在知识型问答、代码生成、数学推理和科学文献综述等四个任务中具有良好的效果。

    

    生成式预训练模型的出现方便了高质量文本的合成，但也在识别生成文本中的事实错误方面提出了挑战。本文针对以下问题提出了FacTool框架：（1）越来越多的任务由生成模型处理时，存在着包含事实错误的风险；（2）生成的文本往往很长，缺乏清晰定义的细粒度个体事实；（3）在事实检查过程中缺乏明确的证据。我们在四个不同的任务上进行实验（基于知识的问答、代码生成、数学推理和科学文献综述），证明了该方法的有效性。

    The emergence of generative pre-trained models has facilitated the synthesis of high-quality text, but it has also posed challenges in identifying factual errors in the generated text. In particular: (1) A wider range of tasks now face an increasing risk of containing factual errors when handled by generative models. (2) Generated texts tend to be lengthy and lack a clearly defined granularity for individual facts. (3) There is a scarcity of explicit evidence available during the process of fact checking. With the above challenges in mind, in this paper, we propose FacTool, a task and domain agnostic framework for detecting factual errors of texts generated by large language models (e.g., ChatGPT). Experiments on four different tasks (knowledge-based QA, code generation, mathematical reasoning, and scientific literature review) show the efficacy of the proposed method.
    
[^8]: Zshot：一个用于零样本命名实体识别和关系抽取的开源框架

    Zshot: An Open-source Framework for Zero-Shot Named Entity Recognition and Relation Extraction. (arXiv:2307.13497v1 [cs.CL])

    [http://arxiv.org/abs/2307.13497](http://arxiv.org/abs/2307.13497)

    Zshot是一个开源框架，用于零样本命名实体识别和关系抽取，通过比较不同的最新ZSL方法，支持研究人员和工业界的需求。

    

    零样本学习（ZSL）任务涉及在训练过程中未见过的文本中识别实体或关系。由于特定领域中标注数据的稀缺性，ZSL已成为一个重要的研究领域，并且在近年来应用范围已大幅增长。随着大型预训练语言模型的出现，提出了许多新的方法，ZSL性能显著提升。研究界和工业界对一个全面支持最新方法和预训练模型开发和可访问性的ZSL框架的需求不断增长。本研究提出了一个名为Zshot的创新ZSL框架，旨在解决上述挑战。我们的主要目标是提供一个平台，允许研究人员使用标准基准数据集比较不同的最新ZSL方法。此外，我们设计了一个支持工业界的框架，具备易用性、灵活性和可扩展性。

    The Zero-Shot Learning (ZSL) task pertains to the identification of entities or relations in texts that were not seen during training. ZSL has emerged as a critical research area due to the scarcity of labeled data in specific domains, and its applications have grown significantly in recent years. With the advent of large pretrained language models, several novel methods have been proposed, resulting in substantial improvements in ZSL performance. There is a growing demand, both in the research community and industry, for a comprehensive ZSL framework that facilitates the development and accessibility of the latest methods and pretrained models.In this study, we propose a novel ZSL framework called Zshot that aims to address the aforementioned challenges. Our primary objective is to provide a platform that allows researchers to compare different state-of-the-art ZSL methods with standard benchmark datasets. Additionally, we have designed our framework to support the industry with readi
    
[^9]: 全面探索通用分解语义解析：架构、数据增强和LLM范式

    Holistic Exploration on Universal Decompositional Semantic Parsing: Architecture, Data Augmentation, and LLM Paradigm. (arXiv:2307.13424v1 [cs.CL])

    [http://arxiv.org/abs/2307.13424](http://arxiv.org/abs/2307.13424)

    本文全面探索了通用分解语义解析，通过引入级联模型和优化架构，减少推理时间并提高效果。同时，不同的数据增强方法进一步改进了解析结果。研究发现ChatGPT在属性解析方面表现好，但在关系解析上存在困难，使用ChatGPT进行数据增强效果不佳。

    

    本文对通用分解语义解析进行了全面探索。首先，我们引入了一种级联模型，将复杂的解析任务分解为语义上合适的子任务。我们的方法在减少推理时间的同时，优于之前的模型。我们还结合了句法信息并进一步优化了架构。此外，我们还探索了不同的数据增强方法，进一步提高了通用分解语义解析的效果。最后，我们进行了实验，调研了ChatGPT在处理通用分解语义解析任务方面的有效性，发现它在属性解析方面表现出色，但在关系解析方面存在困难，使用ChatGPT进行数据增强的效果不够理想。我们的代码可在https://github.com/hexuandeng/HExp4UDS上找到。

    In this paper, we conduct a holistic exploration of the Universal Decompositional Semantic (UDS) Parsing. We first introduce a cascade model for UDS parsing that decomposes the complex parsing task into semantically appropriate subtasks. Our approach outperforms the prior models, while significantly reducing inference time. We also incorporate syntactic information and further optimized the architecture. Besides, different ways for data augmentation are explored, which further improve the UDS Parsing. Lastly, we conduct experiments to investigate the efficacy of ChatGPT in handling the UDS task, revealing that it excels in attribute parsing but struggles in relation parsing, and using ChatGPT for data augmentation yields suboptimal results. Our code is available at https://github.com/hexuandeng/HExp4UDS.
    
[^10]: 用词向量解决词义歧义问题

    Towards Resolving Word Ambiguity with Word Embeddings. (arXiv:2307.13417v1 [cs.CL])

    [http://arxiv.org/abs/2307.13417](http://arxiv.org/abs/2307.13417)

    本文提出了一种方法，通过应用DBSCAN聚类算法来识别和评估具有歧义的单词，从而解决词义歧义问题。

    

    在自然语言中，歧义性普遍存在。解决歧义意义对于信息检索任务尤为重要。尽管词向量携带语义信息，但它们对于处理歧义性并不擅长。Transformer模型已被证明可以处理复杂查询中的词义歧义，但无法用于识别有歧义的单词，例如用于一个单词的查询。此外，训练这些模型在时间、硬件资源和训练数据方面成本高昂，限制了它们在具有敏感数据的专门环境中的使用。词向量可以使用适中的硬件资源进行训练。本文通过将DBSCAN聚类应用于潜空间，可以识别出有歧义的单词并评估其歧义程度。自动DBSCAN参数选择能够得到高质量的聚类，这些聚类在语义上是连贯的，并与给定单词的感知意义相对应。

    Ambiguity is ubiquitous in natural language. Resolving ambiguous meanings is especially important in information retrieval tasks. While word embeddings carry semantic information, they fail to handle ambiguity well. Transformer models have been shown to handle word ambiguity for complex queries, but they cannot be used to identify ambiguous words, e.g. for a 1-word query. Furthermore, training these models is costly in terms of time, hardware resources, and training data, prohibiting their use in specialized environments with sensitive data. Word embeddings can be trained using moderate hardware resources. This paper shows that applying DBSCAN clustering to the latent space can identify ambiguous words and evaluate their level of ambiguity. An automatic DBSCAN parameter selection leads to high-quality clusters, which are semantically coherent and correspond well to the perceived meanings of a given word.
    
[^11]: 走向缩小数字语言鸿沟的努力

    Towards Bridging the Digital Language Divide. (arXiv:2307.13405v1 [cs.CL])

    [http://arxiv.org/abs/2307.13405](http://arxiv.org/abs/2307.13405)

    本文旨在探讨“语言偏见”现象，即多语言处理系统存在对某些语言的硬编码倾向，忽视了语言复杂性和语言社区的需求，阻碍了AI技术覆盖到“资源有限的语言”。

    

    众所周知，当前基于人工智能的语言技术，如语言模型、机器翻译系统、多语言字典和语料库，主要关注全球2-3%的最常用语言。最近的研究努力致力于将AI技术扩大到“资源有限的语言”。我们论文的目标是引起人们对一种我们称之为“语言偏见”的现象的关注：多语言语言处理系统往往表现出对某些语言的硬编码倾向，这往往是无意识和隐藏的。即使在类似的测试条件下，语言偏见也会导致不同语言的性能不均衡。我们表明，具有偏见的技术往往是由于研发方法论没有对所表示的语言复杂性进行恰当处理而产生的，甚至会因忽视多样性宝贵的方面以及语言社区的需求而引起伦理问题。

    It is a well-known fact that current AI-based language technology -- language models, machine translation systems, multilingual dictionaries and corpora -focuses on the world's 2-3% most widely spoken languages. Recent research efforts have attempted to expand the coverage of AI technology to `under-resourced languages.' The goal of our paper is to bring attention to a phenomenon that we call linguistic bias: multilingual language processing systems often exhibit a hardwired, yet usually involuntary and hidden representational preference towards certain languages. Linguistic bias is manifested in uneven per-language performance even in the case of similar test conditions. We show that biased technology is often the result of research and development methodologies that do not do justice to the complexity of the languages being represented, and that can even become ethically problematic as they disregard valuable aspects of diversity as well as the needs of the language communities the
    
[^12]: 使用嵌入模型进行科学致谢中命名实体的自动提取和分类

    Embedding Models for Supervised Automatic Extraction and Classification of Named Entities in Scientific Acknowledgements. (arXiv:2307.13377v1 [cs.DL])

    [http://arxiv.org/abs/2307.13377](http://arxiv.org/abs/2307.13377)

    本论文评估了在科学论文致谢文本中自动提取和分类被致谢实体的不同嵌入模型的性能。在使用Flair NLP框架进行命名实体识别任务的训练中，Flair Embeddings模型在中等规模语料库上达到了最佳准确度（0.79）。同时，扩大训练语料库的规模可以显著提高所有训练算法的准确性。

    

    科学论文中的致谢部分可能揭示科学社区的某些方面，比如奖励体系、合作模式和隐藏的研究趋势。该论文旨在评估不同嵌入模型在科学论文致谢文本中自动提取和分类被致谢实体的性能。我们使用Flair NLP框架进行命名实体识别（NER）任务的训练和实现。训练使用了三个默认的Flair NER模型，使用四个不同大小的语料库和不同版本的Flair NLP框架进行。在最新的FLAIR版本上，使用中等规模的语料库训练的Flair嵌入模型显示出了最好的准确性，为0.79。将训练语料库的规模从非常小的扩展到中等规模大大提高了所有训练算法的准确性，但进一步扩大训练语料库并没有带来进一步的改善。此外，嵌入模型的性能在其他Embeddings选项上没有显著差异。

    Acknowledgments in scientific papers may give an insight into aspects of the scientific community, such as reward systems, collaboration patterns, and hidden research trends. The aim of the paper is to evaluate the performance of different embedding models for the task of automatic extraction and classification of acknowledged entities from the acknowledgment text in scientific papers. We trained and implemented a named entity recognition (NER) task using the Flair NLP framework. The training was conducted using three default Flair NER models with four differently-sized corpora and different versions of the Flair NLP framework. The Flair Embeddings model trained on the medium corpus with the latest FLAIR version showed the best accuracy of 0.79. Expanding the size of a training corpus from very small to medium size massively increased the accuracy of all training algorithms, but further expansion of the training corpus did not bring further improvement. Moreover, the performance of the
    
[^13]: 用更长更好的上下文理解将模型赋能

    Empower Your Model with Longer and Better Context Comprehension. (arXiv:2307.13365v1 [cs.CL])

    [http://arxiv.org/abs/2307.13365](http://arxiv.org/abs/2307.13365)

    本文研究了大语言模型（LLMs）内的信息传递，并提出了一种名为注意力转移的技术，该技术能够使模型在不增加训练或对生成流畅性的影响的情况下实现更长更好的上下文理解。

    

    最近，随着大量的大语言模型（LLMs）的出现，人工智能的实现进入了一个新的时代。无论这些模型自身的容量和结构如何，都存在对LLMs具有更长更复杂上下文的增强理解的需求，而模型通常在处理超出其理解能力范围的句子序列时会遇到上限，导致产生离题或混乱的回答。虽然最近有几项工作试图以不同的方式解决这个问题，但它们很少关注“为什么模型无法自行弥补或增强自己的能力”。在本文中，我们对LLMs内的信息传递性质进行了深入研究，并提出了一种名为注意力转移的新技术。这种技术能够使模型在最小化额外训练或对生成流利性的影响的情况下实现更长更好的上下文理解。我们的实验证明了这一点。

    Recently, with the emergence of numerous Large Language Models (LLMs), the implementation of AI has entered a new era. Irrespective of these models' own capacity and structure, there is a growing demand for LLMs to possess enhanced comprehension of longer and more complex contexts with relatively smaller sizes. Models often encounter an upper limit when processing sequences of sentences that extend beyond their comprehension capacity and result in off-topic or even chaotic responses. While several recent works attempt to address this issue in various ways, they rarely focus on "why models are unable to compensate or strengthen their capabilities on their own". In this paper, we thoroughly investigate the nature of information transfer within LLMs and propose a novel technique called Attention Transition. This technique empowers models to achieve longer and better context comprehension with minimal additional training or impact on generation fluency. Our experiments are conducted in XSu
    
[^14]: 通过基于梯度的特征归因分析大型语言模型中的思维链启发

    Analyzing Chain-of-Thought Prompting in Large Language Models via Gradient-based Feature Attributions. (arXiv:2307.13339v1 [cs.CL])

    [http://arxiv.org/abs/2307.13339](http://arxiv.org/abs/2307.13339)

    通过基于梯度的特征归因方法，研究发现思维链启发在大型语言模型中并没有增加与语义相关标记的重要性，但提高了与问题相关标记的重要性分数的鲁棒性。

    

    在各种问答任务中，已经证明思维链启发在大型语言模型的准确性方面有实际的改善。然而，为了确保这种现象是期望的模型行为的结果，理解为何思维链启发有效非常重要，但是目前很少有研究探讨这个问题。我们通过利用基于梯度的特征归因方法来回答这个问题，该方法产生了衡量输入标记对模型输出影响的重要性分数。具体而言，我们探索了几个开源的大型语言模型，以研究思维链启发是否会影响它们分配给特定输入标记的相对重要性。我们的结果表明，与标准的少样本启发相比，思维链启发并未增加分配给语义相关标记的重要性分数的大小，但它提高了分配给问题相关标记的重要性分数的鲁棒性。

    Chain-of-thought (CoT) prompting has been shown to empirically improve the accuracy of large language models (LLMs) on various question answering tasks. While understanding why CoT prompting is effective is crucial to ensuring that this phenomenon is a consequence of desired model behavior, little work has addressed this; nonetheless, such an understanding is a critical prerequisite for responsible model deployment. We address this question by leveraging gradient-based feature attribution methods which produce saliency scores that capture the influence of input tokens on model output. Specifically, we probe several open-source LLMs to investigate whether CoT prompting affects the relative importances they assign to particular input tokens. Our results indicate that while CoT prompting does not increase the magnitude of saliency scores attributed to semantically relevant tokens in the prompt compared to standard few-shot prompting, it increases the robustness of saliency scores to quest
    
[^15]: 法律案件检索的意图分类法

    An Intent Taxonomy of Legal Case Retrieval. (arXiv:2307.13298v1 [cs.IR])

    [http://arxiv.org/abs/2307.13298](http://arxiv.org/abs/2307.13298)

    本论文提出了一种新颖的法律案件检索的意图分类法，在明确了法律检索用户的潜在搜索意图更加复杂的情况下，通过五种意图类型进行分类。该分类法经过广泛的评估，揭示了用户行为和满意度方面的显著差异。

    

    法律案件检索是一项特殊的信息检索任务，关注的是法律案件文件。根据检索到的案件文件的下游任务和用户的信息需求，法律案件检索中的信息需求与网络搜索和传统的自适应检索任务可能会有显著的区别。虽然有几项研究根据文本相似性来检索法律案件，但作为本文所示，法律检索用户的潜在搜索意图更加复杂，但大部分尚未探索。为此，我们提出了一种新颖的法律案件检索的意图分类法。它由五种意图类型组成，根据三个标准进行分类，即搜索特定案例，特征描述，处罚，程序和利益。该分类法通过透明的构建和广泛的评估，包括访谈、编辑用户研究和查询日志分析。通过实验室用户研究，我们揭示了用户行为和满意度方面的显著差异。

    Legal case retrieval is a special Information Retrieval~(IR) task focusing on legal case documents. Depending on the downstream tasks of the retrieved case documents, users' information needs in legal case retrieval could be significantly different from those in Web search and traditional ad-hoc retrieval tasks. While there are several studies that retrieve legal cases based on text similarity, the underlying search intents of legal retrieval users, as shown in this paper, are more complicated than that yet mostly unexplored. To this end, we present a novel hierarchical intent taxonomy of legal case retrieval. It consists of five intent types categorized by three criteria, i.e., search for Particular Case(s), Characterization, Penalty, Procedure, and Interest. The taxonomy was constructed transparently and evaluated extensively through interviews, editorial user studies, and query log analysis. Through a laboratory user study, we reveal significant differences in user behavior and sati
    
[^16]: LoraHub: 通过动态LoRA组合实现高效的任务通用性

    LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA Composition. (arXiv:2307.13269v1 [cs.CL])

    [http://arxiv.org/abs/2307.13269](http://arxiv.org/abs/2307.13269)

    本文研究了LoRA组合在跨任务通用性上的可行性，并提出了LoraHub框架，能够通过组合不同任务上训练的LoRA模块，实现对未见任务的可适应性性能。实验结果表明，LoraHub在少样本场景中能够有效模拟上下文学习的性能，而无需上下文示例。

    

    低秩适应（LoRA）常常被用于对新任务进行大型语言模型（LLM）的微调。本文研究了LoRA组合在跨任务通用性上的可行性，并介绍了LoraHub，这是一个为目的性组装在不同给定任务上训练的LoRA模块的战略框架，旨在实现对未见任务的可适应性性能。仅凭借来自新任务的几个示例，LoraHub可以灵活地组合多个LoRA模块，消除了对人类专业知识的需求。值得注意的是，这种组合既不需要额外的模型参数，也不需要梯度。我们从Big-Bench Hard（BBH）基准测试中得出的实证结果表明，LoraHub在少样本场景中可以有效地模拟上下文学习的性能，在每个推理输入旁边不需要上下文示例。我们的研究的一个重要贡献是培育一个LoRA社区，用户可以在其中分享他们训练的LoRA模块。

    Low-rank adaptations (LoRA) are often employed to fine-tune large language models (LLMs) for new tasks. This paper investigates LoRA composability for cross-task generalization and introduces LoraHub, a strategic framework devised for the purposive assembly of LoRA modules trained on diverse given tasks, with the objective of achieving adaptable performance on unseen tasks. With just a few examples from a novel task, LoraHub enables the fluid combination of multiple LoRA modules, eradicating the need for human expertise. Notably, the composition requires neither additional model parameters nor gradients. Our empirical results, derived from the Big-Bench Hard (BBH) benchmark, suggest that LoraHub can effectively mimic the performance of in-context learning in few-shot scenarios, excluding the necessity of in-context examples alongside each inference input. A significant contribution of our research is the fostering of a community for LoRA, where users can share their trained LoRA module
    
[^17]: 基于模式的行动洞察生成和智能推荐

    Schema-Driven Actionable Insight Generation and Smart Recommendation. (arXiv:2307.13176v1 [cs.CL])

    [http://arxiv.org/abs/2307.13176](http://arxiv.org/abs/2307.13176)

    本文介绍了一种基于模式的方法，用于从数据中生成可执行的洞察，并根据用户的反馈对洞察进行排序，展示了其适应反馈的能力。

    

    在自然语言生成（NLG）中，洞察挖掘被视为一种将数据转化为文本的任务，其中数据被挖掘以寻找有趣的模式，并通过口头化转化为“洞察”陈述。一个“过量生成和排序”的范式被直观地用于生成这些洞察。这个过程的多维度和主观性使其具有挑战性。本文引入一种基于模式的方法，以生成从数据到推动增长和变革的可执行洞察。它还引入了一种通过用户反馈来与用户兴趣保持一致的排序洞察的技术。我们展示了使用我们的技术生成的洞察的初步定性结果，并展示了它适应反馈的能力。

    In natural language generation (NLG), insight mining is seen as a data-to-text task, where data is mined for interesting patterns and verbalised into 'insight' statements. An 'over-generate and rank' paradigm is intuitively used to generate such insights. The multidimensionality and subjectivity of this process make it challenging. This paper introduces a schema-driven method to generate actionable insights from data to drive growth and change. It also introduces a technique to rank the insights to align with user interests based on their feedback. We show preliminary qualitative results of the insights generated using our technique and demonstrate its ability to adapt to feedback.
    
[^18]: 使用经过人群调整的生成式语言模型进行观点挖掘

    Opinion Mining Using Population-tuned Generative Language Models. (arXiv:2307.13173v1 [cs.CL])

    [http://arxiv.org/abs/2307.13173](http://arxiv.org/abs/2307.13173)

    本文提出了一种使用经过调整的生成式语言模型进行观点挖掘的方法。通过特定数据的微调，我们的方法可以学习和转移观点，并保持极性的比例。实验结果表明我们的方法在挖掘真实文本中的观点洞察方面具有良好的性能。

    

    我们提出了一种新的方法，利用训练于不同人群数据上的生成式语言模型从文本集合中挖掘观点。我们描述了基本定义、方法论和观点洞察挖掘的通用算法。我们通过一个实验展示了我们的方法的性能：使用预训练的生成式模型，并使用特定的定制内容和完全标注的观点对其进行微调。我们证明了我们的方法可以学习和转移观点到语义类别，并保持极性的比例。最后，我们展示了一个洞察挖掘系统在实际文本语料库中发现观点洞察的扩展应用。

    We present a novel method for mining opinions from text collections using generative language models trained on data collected from different populations. We describe the basic definitions, methodology and a generic algorithm for opinion insight mining. We demonstrate the performance of our method in an experiment where a pre-trained generative model is fine-tuned using specifically tailored content with unnatural and fully annotated opinions. We show that our approach can learn and transfer the opinions to the semantic classes while maintaining the proportion of polarisation. Finally, we demonstrate the usage of an insight mining system to scale up the discovery of opinion insights from a real text corpus.
    
[^19]: 解释数学词问题求解器

    Explaining Math Word Problem Solvers. (arXiv:2307.13128v1 [cs.CL])

    [http://arxiv.org/abs/2307.13128](http://arxiv.org/abs/2307.13128)

    该论文研究了基于神经网络的自动化数学词问题求解器的工作原理，并发现这些求解器可能依赖于表面模式而不是数学语义逻辑来生成解决方案。

    

    基于神经网络的自动化数学词问题求解器已成功地在解决算术词问题中取得了70-80％的准确率。然而，研究表明这些求解器可能依赖于表面模式来获得它们的方程式。为了确定数学词问题求解器使用哪些信息来生成解决方案，我们去除输入的部分内容，并测量模型在扰动数据集上的性能。我们的结果表明，模型对于从输入中去除许多单词并仍然能够在给出无意义问题时找到正确答案并不敏感。这表明自动化求解器并未遵循数学词问题的语义逻辑，并且可能过度拟合特定单词的存在。

    Automated math word problem solvers based on neural networks have successfully managed to obtain 70-80\% accuracy in solving arithmetic word problems. However, it has been shown that these solvers may rely on superficial patterns to obtain their equations. In order to determine what information math word problem solvers use to generate solutions, we remove parts of the input and measure the model's performance on the perturbed dataset. Our results show that the model is not sensitive to the removal of many words from the input and can still manage to find a correct answer when given a nonsense question. This indicates that automatic solvers do not follow the semantic logic of math word problems, and may be overfitting to the presence of specific words.
    
[^20]: 如何使用LLMs进行文本分析

    How to use LLMs for Text Analysis. (arXiv:2307.13106v1 [cs.CL])

    [http://arxiv.org/abs/2307.13106](http://arxiv.org/abs/2307.13106)

    本文介绍了如何使用LLMs进行文本分析，LLMs作为一种非常多功能的文本分析方法在社会科学中具有广泛的应用前景。使用LLMs可以实现从文本标注和分类到情感分析和批判性话语分析等多种任务，并且易于使用且速度快。这对于具有有限编程经验的学生和研究者来说尤其有用。

    

    本指南介绍了大型语言模型（LLM）作为社会科学中一种非常多功能的文本分析方法。由于LLMs易于使用、成本低、速度快，并且适用于广泛的文本分析任务，从文本标注和分类到情感分析和批判性话语分析，许多学者认为LLMs将改变我们进行文本分析的方式。本指南面向具有有限编程经验的学生和研究者，并提供了如何在自己的研究项目中使用LLMs进行文本分析的简单介绍，以及最佳实践建议。我们将使用Python演示使用LLMs分析文本数据的每个步骤：安装软件，设置API，加载数据，开发分析提示，分析文本和验证结果。作为一个说明性例子，我们将使用在政治文本中识别民粹主义的具有挑战性的任务，并展示LLMs如何超越现有的方法。

    This guide introduces Large Language Models (LLM) as a highly versatile text analysis method within the social sciences. As LLMs are easy-to-use, cheap, fast, and applicable on a broad range of text analysis tasks, ranging from text annotation and classification to sentiment analysis and critical discourse analysis, many scholars believe that LLMs will transform how we do text analysis. This how-to guide is aimed at students and researchers with limited programming experience, and offers a simple introduction to how LLMs can be used for text analysis in your own research project, as well as advice on best practices. We will go through each of the steps of analyzing textual data with LLMs using Python: installing the software, setting up the API, loading the data, developing an analysis prompt, analyzing the text, and validating the results. As an illustrative example, we will use the challenging task of identifying populism in political texts, and show how LLMs move beyond the existing
    
[^21]: 使用大型语言模型使元数据更加FAIR

    Making Metadata More FAIR Using Large Language Models. (arXiv:2307.13085v1 [cs.CL])

    [http://arxiv.org/abs/2307.13085](http://arxiv.org/abs/2307.13085)

    本研究提出了一种名为FAIRMetaText的自然语言处理应用程序，用于比较元数据。该应用程序分析元数据的自然语言描述，并提供数学相似度度量，可用于分析和识别可替代术语，从而大大减少人力成本。

    

    随着全球实验数据资料的增加，统一利用这些资料的一个主要障碍是糟糕的元数据。为了弥合这个差距，本研究提出了一种名为FAIRMetaText的自然语言处理（NLP）应用程序，用于比较元数据。具体而言，FAIRMetaText分析元数据的自然语言描述，并提供两个术语之间的数学相似度度量。这个度量可以用于分析不同的元数据，通过建议符合性术语或分组相似术语来识别可替代术语。通过在公开的研究资料上进行深入研究，并在大规模语言模型（LLM）的各种元数据相关任务上定性和定量地展示了该算法的效果。这个软件可以极大地减少人力成本，同时利用多种实验数据过程中筛选各种自然语言元数据。

    With the global increase in experimental data artifacts, harnessing them in a unified fashion leads to a major stumbling block - bad metadata. To bridge this gap, this work presents a Natural Language Processing (NLP) informed application, called FAIRMetaText, that compares metadata. Specifically, FAIRMetaText analyzes the natural language descriptions of metadata and provides a mathematical similarity measure between two terms. This measure can then be utilized for analyzing varied metadata, by suggesting terms for compliance or grouping similar terms for identification of replaceable terms. The efficacy of the algorithm is presented qualitatively and quantitatively on publicly available research artifacts and demonstrates large gains across metadata related tasks through an in-depth study of a wide variety of Large Language Models (LLMs). This software can drastically reduce the human effort in sifting through various natural language metadata while employing several experimental dat
    
[^22]: 使用多模态对比学习从自然语言中提取分子属性

    Extracting Molecular Properties from Natural Language with Multimodal Contrastive Learning. (arXiv:2307.12996v1 [cs.LG])

    [http://arxiv.org/abs/2307.12996](http://arxiv.org/abs/2307.12996)

    该论文研究了如何使用多模态对比学习方法从自然语言中提取分子属性信息，通过改进文本检索和引入分子图扩增策略等方法提高了属性预测性能。实验结果显示相对于仅在图模态上预训练的模型，我们取得了+4.26%的AUROC增益和+1.54%的增益。

    

    在计算生物化学中，深度学习传统上专注于分子图神经表征；然而，最近语言模型的进展突显了文本中所编码的科学知识量。为了弥合这两种模态，我们研究了如何将分子属性信息从自然语言转化为图表征。我们研究了在使用对比学习将神经图表征与其特征的文本描述表征对齐后，属性预测性能的提升。我们实现了神经相关性评分策略以改进文本检索，引入了一种受有机反应启发的新颖合法分子图扩增策略，并在下游的MoleculeNet属性分类任务上展示了性能的改善。与仅在图模态上预训练的模型相比，我们取得了+4.26%的AUROC增益，并与最近提出的分子图/文本对比模型相比，取得了+1.54%的增益。

    Deep learning in computational biochemistry has traditionally focused on molecular graphs neural representations; however, recent advances in language models highlight how much scientific knowledge is encoded in text. To bridge these two modalities, we investigate how molecular property information can be transferred from natural language to graph representations. We study property prediction performance gains after using contrastive learning to align neural graph representations with representations of textual descriptions of their characteristics. We implement neural relevance scoring strategies to improve text retrieval, introduce a novel chemically-valid molecular graph augmentation strategy inspired by organic reactions, and demonstrate improved performance on downstream MoleculeNet property classification tasks. We achieve a +4.26% AUROC gain versus models pre-trained on the graph modality alone, and a +1.54% gain compared to recently proposed molecular graph/text contrastively t
    
[^23]: 从Hapax Rate模型导出的Zipf和Heaps定律的修正

    Corrections of Zipf's and Heaps' Laws Derived from Hapax Rate Models. (arXiv:2307.12896v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.12896](http://arxiv.org/abs/2307.12896)

    本文的创新是基于Hapax Rate模型引入了对Zipf和Heaps定律的修正，并发现逻辑模型拟合效果最优。

    

    本文基于Hapax Rate模型引入了对Zipf和Heaps定律的修正。推导基于两个假设：第一个假设是标准的瓮模型，预测较短文本的边际词频分布看起来就像是从一个给定的较长文本中盲目采样词元。第二个假设假定Hapax的频率是文本大小的简单函数。讨论了四个这样的函数：常数模型、Davis模型、线性模型和逻辑模型。结果显示逻辑模型拟合效果最好。

    The article introduces corrections to Zipf's and Heaps' laws based on systematic models of the hapax rate. The derivation rests on two assumptions: The first one is the standard urn model which predicts that marginal frequency distributions for shorter texts look as if word tokens were sampled blindly from a given longer text. The second assumption posits that the rate of hapaxes is a simple function of the text size. Four such functions are discussed: the constant model, the Davis model, the linear model, and the logistic model. It is shown that the logistic model yields the best fit.
    
[^24]: RRAML: 强化检索增强的机器学习

    RRAML: Reinforced Retrieval Augmented Machine Learning. (arXiv:2307.12798v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.12798](http://arxiv.org/abs/2307.12798)

    RRAML是一种新的机器学习框架，将大型语言模型（LLMs）的推理能力与用户提供的庞大数据库中的支持信息相结合。利用强化学习的进展，该方法成功解决了几个关键挑战。

    

    大型语言模型（LLMs）的出现彻底改变了机器学习和相关领域，在理解、生成和操作人类语言方面展示了显著的能力。然而，通过基于API的文本提示提交来使用它们会存在一定的限制，包括上下文约束和外部资源的可用性。为了解决这些挑战，我们提出了一种新的框架，称为强化检索增强的机器学习（RRAML）。RRAML将LLMs的推理能力与由专用检索器从用户提供的庞大数据库中检索到的支持信息相结合。通过利用强化学习的最新进展，我们的方法有效地解决了几个关键挑战。首先，它绕过了访问LLM梯度的需求。其次，我们的方法减轻了针对特定任务重新训练LLMs的负担，因为由于对模型和合作的访问受限，这往往是不可行或不可能的。

    The emergence of large language models (LLMs) has revolutionized machine learning and related fields, showcasing remarkable abilities in comprehending, generating, and manipulating human language. However, their conventional usage through API-based text prompt submissions imposes certain limitations in terms of context constraints and external source availability. To address these challenges, we propose a novel framework called Reinforced Retrieval Augmented Machine Learning (RRAML). RRAML integrates the reasoning capabilities of LLMs with supporting information retrieved by a purpose-built retriever from a vast user-provided database. By leveraging recent advancements in reinforcement learning, our method effectively addresses several critical challenges. Firstly, it circumvents the need for accessing LLM gradients. Secondly, our method alleviates the burden of retraining LLMs for specific tasks, as it is often impractical or impossible due to restricted access to the model and the co
    
[^25]: 问题分解提高了模型生成推理的忠实度

    Question Decomposition Improves the Faithfulness of Model-Generated Reasoning. (arXiv:2307.11768v1 [cs.CL])

    [http://arxiv.org/abs/2307.11768](http://arxiv.org/abs/2307.11768)

    通过将问题分解为子问题，可以显著提高大型语言模型生成推理的忠实度。

    

    随着大型语言模型（LLM）执行越来越复杂的任务，验证其行为的正确性和安全性变得越来越困难。其中一种解决方法是要求LLM在回答问题时以逐步推理的方式外化其推理过程（思维链；CoT）。推理过程可以让我们检查模型执行任务的过程。然而，这种方法依赖于所陈述的推理能够忠实地反映模型的实际推理，而这并非总是如此。为了提高CoT推理的忠实度，我们通过将问题分解为子问题来生成推理。基于分解的方法在问答任务上取得了较好的性能，有时接近CoT，并在几个最近提出的度量标准中提高了模型所陈述推理的忠实度。通过强制模型在单独的上下文中回答简单的子问题，我们大大增加了模型的忠实度。

    As large language models (LLMs) perform more difficult tasks, it becomes harder to verify the correctness and safety of their behavior. One approach to help with this issue is to prompt LLMs to externalize their reasoning, e.g., by having them generate step-by-step reasoning as they answer a question (Chain-of-Thought; CoT). The reasoning may enable us to check the process that models use to perform tasks. However, this approach relies on the stated reasoning faithfully reflecting the model's actual reasoning, which is not always the case. To improve over the faithfulness of CoT reasoning, we have models generate reasoning by decomposing questions into subquestions. Decomposition-based methods achieve strong performance on question-answering tasks, sometimes approaching that of CoT while improving the faithfulness of the model's stated reasoning on several recently-proposed metrics. By forcing the model to answer simpler subquestions in separate contexts, we greatly increase the faithf
    
[^26]: EmotionPrompt: 通过情感刺激提升大型语言模型的关键心理学方法

    EmotionPrompt: Leveraging Psychology for Large Language Models Enhancement via Emotional Stimulus. (arXiv:2307.11760v1 [cs.CL])

    [http://arxiv.org/abs/2307.11760](http://arxiv.org/abs/2307.11760)

    EmotionPrompt是一个基于心理学的方法，通过将情感刺激融入到提示中，提升了大型语言模型在各项任务上的性能，并且同时改善了其真实性和信息量。

    

    大型语言模型（LLMs）在推理、语言理解和数学问题解决等许多领域取得了显著的性能，并被视为人工通用智能（AGI）的关键步骤。然而，LLMs对提示的敏感性仍然是其日常应用的主要瓶颈。本文从心理学中汲取灵感，提出了EmotionPrompt来探索情感智能以提升LLMs的性能。EmotionPrompt基于一个非常简单明了的原则：将情感刺激融入到提示中。实验结果表明，我们的方法在相同的单一提示模板上，与原始的零样本提示和Zero-shot-CoT相比，在8个任务上都显著优于多种模型：ChatGPT、Vicuna-13b、Bloom和T5。此外，观察到EmotionPrompt能够提高真实性和信息量。我们相信EmotionPrompt为探索跨学科知识开辟了一条新的道路。

    Large language models (LLMs) have achieved significant performance in many fields such as reasoning, language understanding, and math problem-solving, and are regarded as a crucial step to artificial general intelligence (AGI). However, the sensitivity of LLMs to prompts remains a major bottleneck for their daily adoption. In this paper, we take inspiration from psychology and propose EmotionPrompt to explore emotional intelligence to enhance the performance of LLMs. EmotionPrompt operates on a remarkably straightforward principle: the incorporation of emotional stimulus into prompts. Experimental results demonstrate that our \method, using the same single prompt templates, significantly outperforms original zero-shot prompt and Zero-shot-CoT on 8 tasks with diverse models: ChatGPT, Vicuna-13b, Bloom, and T5. Further, EmotionPrompt was observed to improve both truthfulness and informativeness. We believe that EmotionPrompt heralds a novel avenue for exploring interdisciplinary knowledg
    
[^27]: Retentive Network: 作为大型语言模型的Transformer的继任者

    Retentive Network: A Successor to Transformer for Large Language Models. (arXiv:2307.08621v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.08621](http://arxiv.org/abs/2307.08621)

    Retentive Network（RetNet）作为大型语言模型的基础架构，实现了训练并行、低成本推理和良好的性能。通过并行、循环和分块循环三种计算范式，RetNet具有训练并行化、低成本推理和高效的长序列建模的特点。

    

    在这项工作中，我们提出了Retentive Network (RetNet)作为大型语言模型的基础架构，同时实现了训练并行、低成本推理和良好的性能。我们从理论上推导出了循环和注意力之间的连接。然后，我们提出了序列建模的保留机制，支持三种计算范式，即并行、循环和分块循环。具体而言，并行表示允许进行训练并行化。循环表示能够实现低成本的$O(1)$推理，从而提高解码吞吐量、延迟和GPU内存，同时不损失性能。分块循环表示便于使用线性复杂度进行高效的长序列建模，其中每个块可以并行编码，同时进行循环摘要。语言建模实验结果表明，RetNet实现了良好的扩展结果、并行训练、低成本部署和高效的推理。

    In this work, we propose Retentive Network (RetNet) as a foundation architecture for large language models, simultaneously achieving training parallelism, low-cost inference, and good performance. We theoretically derive the connection between recurrence and attention. Then we propose the retention mechanism for sequence modeling, which supports three computation paradigms, i.e., parallel, recurrent, and chunkwise recurrent. Specifically, the parallel representation allows for training parallelism. The recurrent representation enables low-cost $O(1)$ inference, which improves decoding throughput, latency, and GPU memory without sacrificing performance. The chunkwise recurrent representation facilitates efficient long-sequence modeling with linear complexity, where each chunk is encoded parallelly while recurrently summarizing the chunks. Experimental results on language modeling show that RetNet achieves favorable scaling results, parallel training, low-cost deployment, and efficient i
    
[^28]: 使用大型语言模型增强密集检索的软提示调优

    Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language Models. (arXiv:2307.08303v1 [cs.IR] CROSS LISTED)

    [http://arxiv.org/abs/2307.08303](http://arxiv.org/abs/2307.08303)

    本论文提出了一种使用软提示调优来增强密集检索的方法（SPTAR）。通过优化任务特定的软提示并利用大型语言模型为未标记的文档生成弱查询，可以提高零样本和少样本的密集检索模型的性能。

    

    密集检索（DR）将查询和文档转化为密集向量表示，并在向量空间中测量查询与文档之间的相似性。DR的一个挑战是缺乏领域特定的训练数据。虽然DR模型可以通过迁移学习从大规模公共数据集（如MS MARCO）中学习，但证据表明，并非所有DR模型和领域都能同等受益于迁移学习。最近，一些研究人员转向使用大型语言模型（LLMs）来改进零样本和少样本的DR模型。然而，这些方法中采用的硬提示或人工编写的提示无法保证生成的弱查询的质量。为了解决这个问题，我们提出了用于增强DR的软提示调优（SPTAR）：对于每个任务，我们利用软提示调优在有限的真实数据上优化任务特定的软提示，然后用这些提示引导LLMs为未标记的文档标记弱查询，从而得到足够的弱文档-查询对来训练任务特定的模型。

    Dense retrieval (DR) converts queries and documents into dense embeddings and measures the similarity between queries and documents in vector space. One of the challenges in DR is the lack of domain-specific training data. While DR models can learn from large-scale public datasets like MS MARCO through transfer learning, evidence shows that not all DR models and domains can benefit from transfer learning equally. Recently, some researchers have resorted to large language models (LLMs) to improve the zero-shot and few-shot DR models. However, the hard prompts or human-written prompts utilized in these works cannot guarantee the good quality of generated weak queries. To tackle this, we propose soft prompt tuning for augmenting DR (SPTAR): For each task, we leverage soft prompt-tuning to optimize a task-specific soft prompt on limited ground truth data and then prompt the LLMs to tag unlabeled documents with weak queries, yielding enough weak document-query pairs to train task-specific d
    
[^29]: 为开发领域特定自然语言处理应用而进行的生成式用户体验研究

    Generative User-Experience Research for Developing Domain-specific Natural Language Processing Applications. (arXiv:2306.16143v1 [cs.CL])

    [http://arxiv.org/abs/2306.16143](http://arxiv.org/abs/2306.16143)

    本论文提出了一种在开发领域特定自然语言处理应用中整合生成式用户体验研究的方法。该方法将领域用户纳入原型开发的不同阶段，以更好地了解用户需求和评估用户价值的变化。

    

    用户体验（UX）是人机交互（HCI）研究的一部分，专注于提高系统用户的直观性、透明度、简洁性和信任度。大多数针对机器学习（ML）或自然语言处理（NLP）的UX研究都采用数据驱动的方法，即没有关注用户需求，并仅仅将领域用户用于可用性评估。此外，更典型的UX方法是先针对用户的可用性进行定制，而不是首先了解用户需求。本文提出了一种将生成式UX研究整合到开发领域NLP应用中的方法。生成式UX研究将领域用户纳入原型开发的初始阶段，即构思和概念评估阶段，以及最后一阶段评估用户价值的变化。案例研究中，我们报道了一个针对过程工业中日常操作的领域特定语义搜索的完整原型开发过程。

    User experience (UX) is a part of human-computer interaction (HCI) research and focuses on increasing intuitiveness, transparency, simplicity, and trust for system users. Most of the UX research for machine learning (ML) or natural language processing (NLP) focuses on a data-driven methodology, i.e., it fails to focus on users' requirements, and engages domain users mainly for usability evaluation. Moreover, more typical UX methods tailor the systems towards user usability, unlike learning about the user needs first. The paper proposes a methodology for integrating generative UX research into developing domain NLP applications. Generative UX research employs domain users at the initial stages of prototype development, i.e., ideation and concept evaluation, and the last stage for evaluating the change in user value. In the case study, we report the full-cycle prototype development of a domain-specific semantic search for daily operations in the process industry. Our case study shows tha
    
[^30]: 向可解释的、语言无关的LLMs迈进：大规模语言符号逆向工程

    Towards Explainable and Language-Agnostic LLMs: Symbolic Reverse Engineering of Language at Scale. (arXiv:2306.00017v1 [cs.CL])

    [http://arxiv.org/abs/2306.00017](http://arxiv.org/abs/2306.00017)

    本文提出结合符号表示和自下而上的逆向工程的方法，解决大规模语言模型在真正语言理解上的局限性，实现可解释的、语言无关的LLMs。

    

    大型语言模型（LLMs）取得了一个里程碑，无可否认地改变了人工智能（AI）中许多信仰。然而，当涉及真正的语言理解时，这些LLM的许多限制仍然存在，这些限制是深度神经网络底层架构的副产品。此外，由于它们的亚符号性质，这些模型获得有关语言如何运作的任何知识都将被埋在数十亿个微特征（权重）中，其中没有一个单独的特征有意义，使得这些模型无法解释。为了解决这些限制，我们建议将符号表示的强度与我们认为是LLMs成功的关键结合起来，即在规模上成功地进行自下而上的语言逆向工程。因此，我们主张在符号设置下对语言进行自下而上的逆向工程。一些作者提出了这个项目的提示，我们将进行详细讨论。

    Large language models (LLMs) have achieved a milestone that undenia-bly changed many held beliefs in artificial intelligence (AI). However, there remains many limitations of these LLMs when it comes to true language understanding, limitations that are a byproduct of the under-lying architecture of deep neural networks. Moreover, and due to their subsymbolic nature, whatever knowledge these models acquire about how language works will always be buried in billions of microfeatures (weights), none of which is meaningful on its own, making such models hopelessly unexplainable. To address these limitations, we suggest com-bining the strength of symbolic representations with what we believe to be the key to the success of LLMs, namely a successful bottom-up re-verse engineering of language at scale. As such we argue for a bottom-up reverse engineering of language in a symbolic setting. Hints on what this project amounts to have been suggested by several authors, and we discuss in some detail
    
[^31]: 通过定义生成实现可解释的词义表示：以语义变化分析为例

    Interpretable Word Sense Representations via Definition Generation: The Case of Semantic Change Analysis. (arXiv:2305.11993v1 [cs.CL])

    [http://arxiv.org/abs/2305.11993](http://arxiv.org/abs/2305.11993)

    该论文提出使用自动生成的自然语言定义作为词义表示，可以使语义变化分析更具可解释性，并允许用户直观解释词义的历时轨迹。此外，上下文化的定义在上下文中的语义相似性上也优于令牌或使用句嵌入。

    

    我们提出使用自动生成的自然语言定义来表示可解释的词和词义。给定一个目标词的使用示例集合和相应的数据驱动使用聚类（即词义），使用专门的Flan-T5语言模型为每个用法生成定义，并选择使用聚类中最具代表性的定义作为该词义标签。我们展示了如何使用生成的词义标签使现有的语义变化分析方法更具可解释性，以及如何允许用户 - 历史语言学家、词典编纂者或社会科学家 - 探索并直观地解释词义的历时轨迹。语义变化分析仅是“定义作为表示”的模式的众多可能应用之一。除了人类可读外，上下文化的定义在上下文中的语义相似性上也优于令牌或使用句嵌入。

    We propose using automatically generated natural language definitions of contextualised word usages as interpretable word and word sense representations. Given a collection of usage examples for a target word, and the corresponding data-driven usage clusters (i.e., word senses), a definition is generated for each usage with a specialised Flan-T5 language model, and the most prototypical definition in a usage cluster is chosen as the sense label.  We demonstrate how the resulting sense labels can make existing approaches to semantic change analysis more interpretable, and how they can allow users -historical linguists, lexicographers, or social scientists -- to explore and intuitively explain diachronic trajectories of word meaning. Semantic change analysis is only one of many possible applications of the `definitions as representations' paradigm. Beyond being human-readable, contextualised definitions also outperform token or usage sentence embeddings in word-in-context semantic simi
    
[^32]: DataComp：寻找下一代多模态数据集

    DataComp: In search of the next generation of multimodal datasets. (arXiv:2304.14108v1 [cs.CV])

    [http://arxiv.org/abs/2304.14108](http://arxiv.org/abs/2304.14108)

    DataComp是一个基准测试，旨在通过提出新的训练集来解决数据集在机器学习生态系统中的缺陷。它提供了一个多规模设计的实验测试平台，使用12.8B个图像-文本对的新候选池，让研究人员可以通过设计新的过滤技术或策划新的数据源并评估它们的新数据集来进行创新。

    

    大型的多模态数据集在近期的突破中起到了关键作用，比如CLIP、Stable Diffusion和GPT-4等。与此同时，数据集很少得到与模型架构或训练算法同等的研究关注。为了解决这个在机器学习生态系统中的缺陷，我们介绍了DataComp，一个基准测试，其中训练代码是固定的，研究人员通过提出新的训练集来进行创新。我们提供了一个基于Common Crawl的新候选池，其中包含12.8B个图像-文本对的数据集实验测试平台。参加我们基准测试的研究人员可以设计新的过滤技术或策划新的数据源，并通过运行我们标准化的CLIP训练代码并在38个下游测试集上进行测试来评估他们的新数据集。我们的基准测试包含多个规模，四个候选池大小和相应的计算预算，在训练期间涵盖了从12.8M到12.8B个样本。这种多规模设计有助于研究规模趋势，并为研究人员提供了更多的选择余地。

    Large multimodal datasets have been instrumental in recent breakthroughs such as CLIP, Stable Diffusion, and GPT-4. At the same time, datasets rarely receive the same research attention as model architectures or training algorithms. To address this shortcoming in the machine learning ecosystem, we introduce DataComp, a benchmark where the training code is fixed and researchers innovate by proposing new training sets. We provide a testbed for dataset experiments centered around a new candidate pool of 12.8B image-text pairs from Common Crawl. Participants in our benchmark design new filtering techniques or curate new data sources and then evaluate their new dataset by running our standardized CLIP training code and testing on 38 downstream test sets. Our benchmark consists of multiple scales, with four candidate pool sizes and associated compute budgets ranging from 12.8M to 12.8B samples seen during training. This multi-scale design facilitates the study of scaling trends and makes the
    
[^33]: 防止注意力熵崩溃的Transformer训练稳定性研究

    Stabilizing Transformer Training by Preventing Attention Entropy Collapse. (arXiv:2303.06296v1 [cs.LG])

    [http://arxiv.org/abs/2303.06296](http://arxiv.org/abs/2303.06296)

    本文研究了Transformer的训练动态，发现低注意力熵伴随着高训练不稳定性，提出了一种简单而有效的解决方案$\sigma$Reparam，成功地防止了注意力层中的熵崩溃，促进了更稳定的训练。

    This paper investigates the training dynamics of Transformers and proposes a simple and efficient solution, $\sigma$Reparam, to prevent entropy collapse in the attention layers, promoting more stable training.

    训练稳定性对于Transformer至关重要。本文通过研究注意力层的演变来探究Transformer的训练动态。特别地，我们在训练过程中跟踪每个注意力头的注意力熵，这是模型锐度的代理。我们发现，在不同的架构和任务中存在一种常见模式，即低注意力熵伴随着高训练不稳定性，这可能采取振荡损失或发散的形式。我们将病态低注意力熵，对应高度集中的注意力分数，称为$\textit{熵崩溃}$。作为一种解决方案，我们提出了$\sigma$Reparam，一种简单而有效的解决方案，其中我们使用谱归一化和额外的学习标量重新参数化所有线性层。我们证明了所提出的重新参数化成功地防止了注意力层中的熵崩溃，促进了更稳定的训练。此外，我们

    Training stability is of great importance to Transformers. In this work, we investigate the training dynamics of Transformers by examining the evolution of the attention layers. In particular, we track the attention entropy for each attention head during the course of training, which is a proxy for model sharpness. We identify a common pattern across different architectures and tasks, where low attention entropy is accompanied by high training instability, which can take the form of oscillating loss or divergence. We denote the pathologically low attention entropy, corresponding to highly concentrated attention scores, as $\textit{entropy collapse}$. As a remedy, we propose $\sigma$Reparam, a simple and efficient solution where we reparametrize all linear layers with spectral normalization and an additional learned scalar. We demonstrate that the proposed reparameterization successfully prevents entropy collapse in the attention layers, promoting more stable training. Additionally, we 
    
[^34]: 基于分数的条件模型的概念代数

    Concept Algebra for Score-Based Conditional Models. (arXiv:2302.03693v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.03693](http://arxiv.org/abs/2302.03693)

    本文研究了基于分数的条件模型中学习表示的结构，并开发了一种数学形式化表达概念被编码为表示空间子空间的思想。利用这个方法，我们提出了一种简单的方法来识别给定概念对应的表示部分，并通过代数操作操纵模型所表达的概念。

    

    本文研究了文本引导生成模型中学习表示的结构，重点关注基于分数的模型。我们聚焦于概念被编码为某种表示空间的子空间（或方向）的思想，并开发了这个思想的数学形式化。利用这个形式化方法，我们展示了有一个自然的表示选择具有这种性质，并且我们开发了一种简单的方法来识别与给定概念对应的表示部分。特别是，这使我们能够通过对表示的代数操作来操纵模型所表达的概念。我们使用稳定扩散在文本引导图像生成的示例中演示了这个思想。

    This paper concerns the structure of learned representations in text-guided generative models, focusing on score-based models. Here, we focus on the idea that concepts are encoded as subspaces (or directions) of some representation space. We develop a mathematical formalization of this idea.Using this formalism, we show there's a natural choice of representation with this property, and we develop a simple method for identifying the part of the representation corresponding to a given concept. In particular, this allows us to manipulate the concepts expressed by the model through algebraic manipulation of the representation. We demonstrate the idea with examples text-guided image generation, using Stable Diffusion.
    
[^35]: 修订Transformer：指导语言模型改变其价值观

    Revision Transformers: Instructing Language Models to Change their Values. (arXiv:2210.10332v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.10332](http://arxiv.org/abs/2210.10332)

    本论文提出了修订Transformer（RiT），旨在解决当前Transformer语言模型中出现的捷径学习和偏见问题，以便更方便地进行模型更新。RiT采用了大规模预训练的语言模型和清晰结构的修订引擎的组合，通过少量的努力和用户互动，可以轻松更新模型的知识。在道德数据集上的实验结果表明RiT在模型修订方面表现出强大的性能。

    

    当前的Transformer语言模型是具有数十亿个参数的大规模模型。它们在各种任务上表现出很高的性能，但也容易出现捷径学习和偏见。通过参数调整来解决这类不正确的模型行为非常昂贵。对于更新文化或个人之间变化的道德价值等动态概念尤其棘手。在这项工作中，我们对将所有信息存储在模型参数中的当前常见做法提出质疑，并提出了修订Transformer（RiT）来促进模型的轻松更新。大规模预训练的语言模型与清晰结构的修订引擎的特定组合使得在少量的努力和用户互动的帮助下更新模型的知识成为可能。我们在一个道德数据集上示范了RiT，并模拟了用户反馈，展示了模型修订的强大性能。

    Current transformer language models (LM) are large-scale models with billions of parameters. They have been shown to provide high performances on a variety of tasks but are also prone to shortcut learning and bias. Addressing such incorrect model behavior via parameter adjustments is very costly. This is particularly problematic for updating dynamic concepts, such as moral values, which vary culturally or interpersonally. In this work, we question the current common practice of storing all information in the model parameters and propose the Revision Transformer (RiT) to facilitate easy model updating. The specific combination of a large-scale pre-trained LM that inherently but also diffusely encodes world knowledge with a clear-structured revision engine makes it possible to update the model's knowledge with little effort and the help of user interaction. We exemplify RiT on a moral dataset and simulate user feedback demonstrating strong performance in model revision even with small da
    
[^36]: 元元反游戏学习组合学习行为

    Meta-Referential Games to Learn Compositional Learning Behaviours. (arXiv:2207.08012v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2207.08012](http://arxiv.org/abs/2207.08012)

    本论文提出了一种元元反游戏学习的方法来解决组合学习行为的问题，通过解决绑定问题来支持人工智能代理展示组合学习行为的能力。

    

    人类利用组合性从过去的经验中推广到新颖的经验。我们假设我们的经验可以分解为基本的原子组件，这些组件可以以新颖的方式重新组合，以支持我们参与新颖经验的能力。我们将这视为学习以组合方式泛化的能力，并将利用这种能力的行为称为组合学习行为（CLBs）。学习CLBs的一个核心问题是解决绑定问题（BP）。尽管这是人类轻松完成的智能壮举，但对于现有技术的人工智能代理来说并非如此。因此，为了构建能够与人类合作的人工智能代理，我们建议开发一个新的基准来研究代理商通过解决BP的领域无关版本来展示CLBs的能力。我们受到指代游戏的语言涌现和基础架构框架的启发，提出了一个元学习扩展方案

    Human beings use compositionality to generalise from past experiences to novel experiences. We assume a separation of our experiences into fundamental atomic components that can be recombined in novel ways to support our ability to engage with novel experiences. We frame this as the ability to learn to generalise compositionally, and we will refer to behaviours making use of this ability as compositional learning behaviours (CLBs). A central problem to learning CLBs is the resolution of a binding problem (BP). While it is another feat of intelligence that human beings perform with ease, it is not the case for state-of-the-art artificial agents. Thus, in order to build artificial agents able to collaborate with human beings, we propose to develop a novel benchmark to investigate agents' abilities to exhibit CLBs by solving a domain-agnostic version of the BP. We take inspiration from the language emergence and grounding framework of referential games and propose a meta-learning extensio
    
[^37]: 一种在众包单标签情感分析中端到端的注释者偏差近似方法

    End-to-End Annotator Bias Approximation on Crowdsourced Single-Label Sentiment Analysis. (arXiv:2111.02326v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2111.02326](http://arxiv.org/abs/2111.02326)

    本文提出一种在众包单标签情感分析中解决注释者偏差的端到端方法，通过精确的偏差建模和真实值估计来改善准确性，实验证明在样本只由单个注释者标注的情况下效果显著。

    

    情感分析通常是一个容易受到众多注释者主观标签影响的众包任务。目前尚不完全了解如何使用最先进的方法正确地建模每个注释者的注释偏差。然而，准确可靠地解决注释者偏差是理解注释者标注行为并成功解决相应的个体误解和错误的关键。我们的贡献是对精确的端到端偏差建模和真实值估计进行解释和改进，从而减少现有先进方法中涉及的不希望出现的不匹配问题。分类实验表明，该方法有潜力提高仅由单个注释者标注的样本准确性。我们公开提供整个源代码，并发布一个包含讨论有机食品产品的10,000个句子的领域特定情感数据集，这些句子是从社交媒体抓取而来。

    Sentiment analysis is often a crowdsourcing task prone to subjective labels given by many annotators. It is not yet fully understood how the annotation bias of each annotator can be modeled correctly with state-of-the-art methods. However, resolving annotator bias precisely and reliably is the key to understand annotators' labeling behavior and to successfully resolve corresponding individual misconceptions and wrongdoings regarding the annotation task. Our contribution is an explanation and improvement for precise neural end-to-end bias modeling and ground truth estimation, which reduces an undesired mismatch in that regard of the existing state-of-the-art. Classification experiments show that it has potential to improve accuracy in cases where each sample is annotated only by one single annotator. We provide the whole source code publicly and release an own domain-specific sentiment dataset containing 10,000 sentences discussing organic food products. These are crawled from social me
    
[^38]: 引入自动评分系统前后编程课程评估的分析

    An Analysis of Programming Course Evaluations Before and After the Introduction of an Autograder. (arXiv:2110.15134v2 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2110.15134](http://arxiv.org/abs/2110.15134)

    本研究分析了引入自动评分系统前后多个大规模计算机科学基础课程的评估结果，探讨了自动评分系统对学生对编程课程和教学感知的影响。

    

    在高等教育机构中，常见的入门编程课程有数百名参与学生渴望学习编程。人工评审提交的源代码和提供反馈的工作量已经无法管理。手动评审提交的作业可能存在主观和不公平的问题，尤其是如果有多个助教负责评分。不同的自动评分系统可以在这种情况下提供帮助；然而，目前对于自动评分系统如何影响学生对编程课程和教学的整体感知缺乏了解。这对于课程组织者和机构在应对不断增加的学生数量时保持编程课程的吸引力具有重要意义。本文研究了最近引入自动评分系统的多个大规模基础计算机科学课程的标准化大学评估问卷的回答。分析了介入前后的差异。通过纳入其他观察角度，探讨了自动评分系统的潜在影响。

    Commonly, introductory programming courses in higher education institutions have hundreds of participating students eager to learn to program. The manual effort for reviewing the submitted source code and for providing feedback can no longer be managed. Manually reviewing the submitted homework can be subjective and unfair, particularly if many tutors are responsible for grading. Different autograders can help in this situation; however, there is a lack of knowledge about how autograders can impact students' overall perception of programming classes and teaching. This is relevant for course organizers and institutions to keep their programming courses attractive while coping with increasing students.  This paper studies the answers to the standardized university evaluation questionnaires of multiple large-scale foundational computer science courses which recently introduced autograding. The differences before and after this intervention are analyzed. By incorporating additional observa
    
[^39]: SocialVisTUM：面向社交媒体观点挖掘的相关神经主题模型的交互式可视化工具包

    SocialVisTUM: An Interactive Visualization Toolkit for Correlated Neural Topic Models on Social Media Opinion Mining. (arXiv:2110.10575v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2110.10575](http://arxiv.org/abs/2110.10575)

    本文展示了如何使用基于词嵌入的主题建模方法，在交互式可视化工具包SocialVisTUM中显示相关主题模型。该工具包提供了丰富的功能和细节，支持对大文本集合的探索。从一个关于有机食品消费的英语社交媒体讨论数据的实例中，可视化结果证实了一项消费者研究的发现。

    

    最近在观点挖掘方面的研究中，提出了基于词嵌入的主题建模方法，与传统主题建模相比，这些方法提供了更好的一致性。在本文中，我们展示了如何利用这些方法，在我们提出的交互式可视化工具包SocialVisTUM中，显示社交媒体文本上的相关主题模型。它显示了一个图，主题作为节点，它们的相关性作为边。进一步的细节以交互方式显示，以支持大文本集合的探索，例如主题的代表性词语和句子、主题和情感分布、分层主题聚类和可定制的预定义主题标签。该工具包可以自动优化自定义数据，以获得最佳的一致性。我们展示了工具包在从英语社交媒体讨论中爬取的有机食品消费数据上的工作实例。该可视化结果证实了一项定性消费者研究的发现。

    Recent research in opinion mining proposed word embedding-based topic modeling methods that provide superior coherence compared to traditional topic modeling. In this paper, we demonstrate how these methods can be used to display correlated topic models on social media texts using SocialVisTUM, our proposed interactive visualization toolkit. It displays a graph with topics as nodes and their correlations as edges. Further details are displayed interactively to support the exploration of large text collections, e.g., representative words and sentences of topics, topic and sentiment distributions, hierarchical topic clustering, and customizable, predefined topic labels. The toolkit optimizes automatically on custom data for optimal coherence. We show a working instance of the toolkit on data crawled from English social media discussions about organic food consumption. The visualization confirms findings of a qualitative consumer research study. SocialVisTUM and its training procedures ar
    
[^40]: 社交媒体中消费者信念陈述的分类

    Classification of Consumer Belief Statements From Social Media. (arXiv:2106.15498v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2106.15498](http://arxiv.org/abs/2106.15498)

    本研究探讨了使用复杂的专家注解在社交媒体中进行消费者信念陈述分类的准确性，比较了细粒度和抽象类别的标签，并说明复杂专家注解在高度特定的意见挖掘中的潜在优势。

    

    社交媒体提供了大量信息，可以进行市场调研，以满足客户的需求。研究人员通常通过收集和分类用户生成的内容，构建复杂细粒度的类别结构来进行市场调研。然而，在许多情况下，数据量较少且注解复杂。如何成功利用这些数据进行分类仍不完全清楚。本研究考察了当专家注解被应用于a) 许多细粒度类别和b) 少数抽象类别时的分类准确性。对于场景b)，我们比较了领域专家给出的抽象类别标签（基准）和自动分层聚类给出的抽象类别标签。我们将其与另一基准进行比较，该基准使用完全无监督的聚类方法给出整个类别结构。通过这样做，该研究可以作为复杂专家注解如何在高度特定的意见挖掘中发挥潜在优势，并以最优化的方式利用的示例。

    Social media offer plenty of information to perform market research in order to meet the requirements of customers. One way how this research is conducted is that a domain expert gathers and categorizes user-generated content into a complex and fine-grained class structure. In many of such cases, little data meets complex annotations. It is not yet fully understood how this can be leveraged successfully for classification. We examine the classification accuracy of expert labels when used with a) many fine-grained classes and b) few abstract classes. For scenario b) we compare abstract class labels given by the domain expert as baseline and by automatic hierarchical clustering. We compare this to another baseline where the entire class structure is given by a completely unsupervised clustering approach. By doing so, this work can serve as an example of how complex expert annotations are potentially beneficial and can be utilized in the most optimal way for opinion mining in highly speci
    

