# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [VideoXum: Cross-modal Visual and Textural Summarization of Videos.](http://arxiv.org/abs/2303.12060) | VideoXum是一个新的联合视频和文本摘要任务，它的目标是从长视频中生成对应的简化视频剪辑和文本摘要，利用了不同模态之间的关联和双重注意机制。该模型比现有的最先进方法在视频和文本摘要基准测试中表现更好。 |
| [^2] | [Large Language Models Can Be Used to Estimate the Ideologies of Politicians in a Zero-Shot Learning Setting.](http://arxiv.org/abs/2303.12057) | 本文展示了在零-shot学习环境下，大型语言模型可以用于评估政治家的意识形态，为我们更好地理解政治功能提供了有用的信息。 |
| [^3] | [Grading Conversational Responses Of Chatbots.](http://arxiv.org/abs/2303.12038) | 本文研究了ChatGPT聊天机器人对问题的回答表现，并使用标准的机器翻译评测指标进行比较，结果表明它们的表现仍然落后于典型人类的反应能力。 |
| [^4] | [Wearing Masks Implies Refuting Trump?: Towards Target-specific User Stance Prediction across Events in COVID-19 and US Election 2020.](http://arxiv.org/abs/2303.12029) | 该研究提出了一个框架，旨在预测一个人在未来事件中的行为，通过分析人们在口罩、种族平等和特朗普等话题上的立场，并揭示了过去行为在预测未来行为方面的能力。 |
| [^5] | [cTBL: Augmenting Large Language Models for Conversational Tables.](http://arxiv.org/abs/2303.12024) | 本论文提出了一种称为cTBL的方法，可以从表格中检索信息，并生成具有检索信息支撑的对话响应，其中使用了转换器编码器嵌入进行浓密表检索，可以获得更好的性能。 |
| [^6] | [Logical Reasoning over Natural Language as Knowledge Representation: A Survey.](http://arxiv.org/abs/2303.12023) | 本文总结了一种新的逻辑推理方法，它使用自然语言作为知识表示，具有不同于端到端神经方法的优势。这种新模式在未来有着很高的潜力。 |
| [^7] | [Unsupervised Cross-Domain Rumor Detection with Contrastive Learning and Cross-Attention.](http://arxiv.org/abs/2303.11945) | 本文提出一种无监督的、基于对比学习和交叉注意力机制的跨领域谣言检测模型。该模型不仅可以进行跨领域特征对齐，还可以强制目标样本与源域中的相应原型对齐，并使用聚类方法产生伪标签来学习域不变表示，能够显著提高跨领域谣言检测的性能。 |
| [^8] | [Chinese Intermediate English Learners outdid ChatGPT in deep cohesion: Evidence from English narrative writing.](http://arxiv.org/abs/2303.11812) | 本研究比较了ChatGPT和中国中级英语学习者在叙事主题上的写作表现，发现ChatGPT在叙事性、词汇具体性和指代连贯性方面优于人类作家，但在句法简单性和深层连贯性方面略逊一筹。 |
| [^9] | [LEAPT: Learning Adaptive Prefix-to-prefix Translation For Simultaneous Machine Translation.](http://arxiv.org/abs/2303.11750) | LEAPT提出了一种自适应前缀到前缀训练策略，使机器翻译模型能够更好地进行同声翻译，实验表明其在各种参数设置下均具有较好的表现。 |
| [^10] | [The Open-domain Paradox for Chatbots: Common Ground as the Basis for Human-like Dialogue.](http://arxiv.org/abs/2303.11708) | 最近研究表明，开放领域聊天机器人通过提供最少信息来实现最大化的“开放性”，在实践中导致了“开放领域悖论”——-要求用户“闲聊任何事情”会导致非常狭窄的对话形式。此研究进一步解释了共同基础理论与实现类似人类对话的关系，并提出了实现共同基础的路径。 |
| [^11] | [Simple Yet Effective Synthetic Dataset Construction for Unsupervised Opinion Summarization.](http://arxiv.org/abs/2303.11660) | 本文提出了两种简单有效的无监督方法，利用构建的合成数据集生成特定方面和一般意见摘要。SW-LOO方法通过种子词匹配确定评论的特定方面，并在SPACE和OPOSUM+数据集上都有很好效果；NLI-LOO方法通过NLI模型识别与方面相关的句子，在SPACE数据集上有很好效果。 |
| [^12] | [Heterogeneous-Branch Collaborative Learning for Dialogue Generation.](http://arxiv.org/abs/2303.11621) | 本文提出了一种异构分支协作学习模型，用于对话生成。该模型使用协作学习方法而非传统的知识蒸馏方法，在网络分支的训练中考虑到对话属性，使不同分支的特征多样化。 |
| [^13] | [Transformers in Speech Processing: A Survey.](http://arxiv.org/abs/2303.11607) | 本文综述了Transformer在语音相关领域的广泛应用，为研究者提供了有价值的资源。同时，指出了在语音处理领域中Transformer所面临的挑战及可能的解决思路。 |
| [^14] | [Difficulty in learning chirality for Transformer fed with SMILES.](http://arxiv.org/abs/2303.11593) | 应用SMILES序列的Transformer模型在学习分子结构的整体性和手性方面存在困难，需要进行长时间的训练。生成的描述符用于分子性质预测时的准确率从开始到训练结束都是相似的。 |
| [^15] | [SIFT: Sparse Iso-FLOP Transformations for Maximizing Training Efficiency.](http://arxiv.org/abs/2303.11525) | 本研究提出了一种名为SIFT的方法，用于提高深度神经网络的训练效率、准确性和表示能力，通过稀疏等FLOP转换，缩短训练时间。 |
| [^16] | [Language Model Behavior: A Comprehensive Survey.](http://arxiv.org/abs/2303.11504) | 该论文总结了250多个关于英文语言模型行为的最近研究，发现大型语言模型具有基本的句法、语义、语用、世界知识和推理能力，但容易出现不实回答、常识错误、记忆化文本和社会偏见等弱点。 |
| [^17] | [Large Language Models and Simple, Stupid Bugs.](http://arxiv.org/abs/2303.11455) | 本文研究表明，大型语言模型如Codex虽然有助于避免一些简单Bug，但经常会生成已知的，逐字的Bug，因此需要采取避免策略来减少这种情况，并增加有创意的Bug的生产。 |
| [^18] | [Mind meets machine: Unravelling GPT-4's cognitive psychology.](http://arxiv.org/abs/2303.11436) | 本研究评估了在广泛使用的CommonsenseQA数据集中的一套常识推理问题上，GPT-4的表现及其对常识知识的处理和整合过程，在此过程中我们也发现了其局限性。 |
| [^19] | [eP-ALM: Efficient Perceptual Augmentation of Language Models.](http://arxiv.org/abs/2303.11403) | 本论文提出了一种用对比学习提高语言模型的感知能力的高效方法eP-ALM，可以实现视觉感知信息和文本信息的融合，同时还能在多模态基准测试上实现最先进的结果。 |
| [^20] | [MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action.](http://arxiv.org/abs/2303.11381) | MM-REACT是一种融合视觉专家和ChatGPT的多模态推理和行动系统，通过文字提示设计，实现了ChatGPT和各种视觉专家的协同，具有广泛的高级视觉理解应用价值。 |
| [^21] | [Reflexion: an autonomous agent with dynamic memory and self-reflection.](http://arxiv.org/abs/2303.11366) | 本文提出 Reflexion 方法，给智能体赋予了动态记忆和自我反思能力，以增强其任务特定的行动选择能力。 |
| [^22] | [DocRED-FE: A Document-Level Fine-Grained Entity And Relation Extraction Dataset.](http://arxiv.org/abs/2303.11141) | 本研究构建了一个文档级细粒度实体和关系抽取的数据集DocRED-FE，重新设计了一个分层的实体类型模式，并根据该模式手动重新注释了DocRED。在全面的实验中发现，DocRED-FE的细粒度实体类型可以提高关系分类的性能。 |
| [^23] | [Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning.](http://arxiv.org/abs/2303.10475) | 传统的自然语言处理机器学习需要大规模的任务特定示例，但这不适用于任务可能过于复杂或成本过高以进行注释的场景。因此，社区对于自然语言处理中新的监督寻求范式--从任务指令学习--越来越感兴趣。 |
| [^24] | [GLEN: General-Purpose Event Detection for Thousands of Types.](http://arxiv.org/abs/2303.09093) | 研究者建立了一个通用事件检测数据集GLEN，涵盖了超过3,465种不同的事件类型，利用现有的标注，他们提出了一种新的多阶段事件检测模型，展示了在大本体大小和部分标签的情况下，该模型具有优越的性能。 |
| [^25] | [Data-Efficient Learning of Natural Language to Linear Temporal Logic Translators for Robot Task Specification.](http://arxiv.org/abs/2303.08006) | 本篇论文提出了一种基于学习的方法，通过算法生成 LTL 公式，转换成结构化英语来综合生成多样化的自然语言语料库，从而实现对于自然语言命令的 LTL 规格翻译，而且不需要大量的人工标记数据集。 |
| [^26] | [ChatGPT Is on the Horizon: Could a Large Language Model Be All We Need for Intelligent Transportation?.](http://arxiv.org/abs/2303.05382) | 本文探讨了ChatGPT在解决交通问题方面的应用。通过利用具有跨模态编码器的LLM，可以处理来自不同模态的交通数据并执行交通运营。作者提供了一个基于智能手机的碰撞报告自动生成和分析框架作为用例展示了这种潜力。 |
| [^27] | [QAID: Question Answering Inspired Few-shot Intent Detection.](http://arxiv.org/abs/2303.01593) | 本文提出了一个启发式的Few-shot意图检测方法，通过将意图检测重新定义为一个问题-回答检索任务来解决语义相似的细粒度意图问题，结果在三个few-shot意图检测基准测试上取得了最优表现。 |
| [^28] | [Vid2Seq: Large-Scale Pretraining of a Visual Language Model for Dense Video Captioning.](http://arxiv.org/abs/2302.14115) | 本文介绍了 Vid2Seq，这是一个在大规模 narrated 视频数据集上预先训练的多模态密集事件字幕模型。通过将转录语音的句子边界转化为伪事件边界，并使用转录语音句子作为伪事件字幕，我们有效利用未标注 narrated 视频数据集进行了密集视频字幕的训练。该模型在多个基准测试中表现出色，是目前最优秀的模型之一。 |
| [^29] | [Counteracts: Testing Stereotypical Representation in Pre-trained Language Models.](http://arxiv.org/abs/2301.04347) | 本文提出了一种使用反例测试预训练语言模型中内部刻板印象的方法，重点是性别偏见，结果表明模型在使用不相关的知识时表现出一定的鲁棒性，更倾向于使用浅层的语言线索来改变内部刻板印象。 |
| [^30] | [I Can't Believe There's No Images! Learning Visual Tasks Using only Language Data.](http://arxiv.org/abs/2211.09778) | 本文研究了通过利用对比训练的视觉和语言编码器的联合嵌入空间，并仅使用文本训练数据，在没有对视觉训练数据进行训练的情况下完成四项代表性视觉任务。研究发现这些模型表现良好，具有一定的可迁移性。 |
| [^31] | [PromptCap: Prompt-Guided Image Captioning for VQA with GPT-3.](http://arxiv.org/abs/2211.09699) | 提出了PromptCap，一种使用提示引导的图像字幕生成模型，用于解决基于知识的视觉问答中通用图像字幕无法准确描述视觉实体的问题。 |
| [^32] | [Collecting Interactive Multi-modal Datasets for Grounded Language Understanding.](http://arxiv.org/abs/2211.06552) | 本文提出了一个通过自然语言任务与协作体验智能体交互收集数据集的方法，并收集了首个交互基础语言理解数据集。 |
| [^33] | [Mitigating Covertly Unsafe Text within Natural Language Systems.](http://arxiv.org/abs/2210.09306) | 本文讨论了智能技术中日益普遍的文本安全问题，并强调了一个被忽视的类别：隐蔽不安全文本。该文提出了缓解策略以解决这一问题，以提高智能系统内部的安全性。 |
| [^34] | [The Maximum Linear Arrangement Problem for trees under projectivity and planarity.](http://arxiv.org/abs/2206.06924) | 该论文提出了一种解决在平面性和投影性定义下树的最大线性排列问题的算法，证明了最大投影和平面排列的多个性质，发现毛毛虫树最优，推广了之前的极值结果。 |
| [^35] | [A Token-level Contrastive Framework for Sign Language Translation.](http://arxiv.org/abs/2204.04916) | 提出了一种基于对比学习的手语翻译框架ConSLT，通过将标记级对比学习纳入SLT解码过程中，学习有效的标记表示，以缓解公开可用的手语翻译语料库非常有限的问题。 |
| [^36] | [Pre-trained Token-replaced Detection Model as Few-shot Learner.](http://arxiv.org/abs/2203.03235) | 本文提出了一种使用预训练的token-replaced检测模型的少样本学习器方法，将任务重新定义为token-replaced检测问题，能够优于使用预训练的遮蔽语言模型的少样本学习器。 |
| [^37] | [DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing.](http://arxiv.org/abs/2111.09543) | 本论文介绍了一种新的预训练语言模型DeBERTaV3，使用更加样本有效的替换令牌检测（RTD）取代了掩码语言建模（MLM）并提出了一种新的梯度去耦合嵌入共享方法，避免了“拔河”动态，提高了预训练模型的训练效率和质量。在多个下游自然语言理解任务中，DeBERTaV3表现出优秀的性能。 |
| [^38] | [Tracking, exploring and analyzing recent developments in German-language online press in the face of the coronavirus crisis: cOWIDplus Analysis and cOWIDplus Viewer.](http://arxiv.org/abs/2005.13316) | 该论文提供了三个相互连接的资源，用于捕捉和说明冠状病毒大流行对德语在线新闻的影响：德语新闻源的RSS语料库、一个静态但不断更新的HTML页面和一个Web应用程序。其中，Web应用程序可使其他研究人员和更广泛的公众能够探索这些影响而无需或只需稍有语料库表示和探索或统计分析方面的知识。 |

# 详细

[^1]: VideoXum: 视频的跨模态视觉和文本摘要

    VideoXum: Cross-modal Visual and Textural Summarization of Videos. (arXiv:2303.12060v1 [cs.CV])

    [http://arxiv.org/abs/2303.12060](http://arxiv.org/abs/2303.12060)

    VideoXum是一个新的联合视频和文本摘要任务，它的目标是从长视频中生成对应的简化视频剪辑和文本摘要，利用了不同模态之间的关联和双重注意机制。该模型比现有的最先进方法在视频和文本摘要基准测试中表现更好。

    

    视频摘要旨在从源视频中提炼出最重要的信息，以生成简短的视频剪辑或文本叙述。我们提出了一种新的联合视频和文本摘要任务，并构建了一个大规模人工注释的数据集 -- VideoXum。我们的框架利用不同模态之间的关联，利用双重注意机制来对齐视觉和文本信息。实验结果表明，我们的方法在视频和文本摘要基准测试中优于现有的最先进方法。

    Video summarization aims to distill the most important information from a source video to produce either an abridged clip or a textual narrative. Traditionally, different methods have been proposed depending on whether the output is a video or text, thus ignoring the correlation between the two semantically related tasks of visual summarization and textual summarization. We propose a new joint video and text summarization task. The goal is to generate both a shortened video clip along with the corresponding textual summary from a long video, collectively referred to as a cross-modal summary. The generated shortened video clip and text narratives should be semantically well aligned. To this end, we first build a large-scale human-annotated dataset -- VideoXum (X refers to different modalities). The dataset is reannotated based on ActivityNet. After we filter out the videos that do not meet the length requirements, 14,001 long videos remain in our new dataset. Each video in our reannotat
    
[^2]: 大型语言模型可以在零-shot学习环境下用于评估政治家的意识形态

    Large Language Models Can Be Used to Estimate the Ideologies of Politicians in a Zero-Shot Learning Setting. (arXiv:2303.12057v1 [cs.CY])

    [http://arxiv.org/abs/2303.12057](http://arxiv.org/abs/2303.12057)

    本文展示了在零-shot学习环境下，大型语言模型可以用于评估政治家的意识形态，为我们更好地理解政治功能提供了有用的信息。

    

    大型语言模型（LLMs）中蕴含的大量知识可以为社会科学中的可观测性和测量问题提供新的解决方案。本文研究了其中一种模型在衡量立法者的潜在意识形态方面的效用，这有助于我们更好地理解塑造政策的政治功能，以及政治行为者代表其选民的方式。我们通过提示ChatGPT在两两比较中选择更自由派（或保守派）的参议员，将第116届美国国会的参议员按照自由派-保守派的光谱进行缩放。我们展示了LLM在重复迭代中产生了稳定的答案，没有产生幻觉，并且不仅仅是从单一来源中复制信息。这个新尺度与现有的自由派-保守派尺度（如NOMINATE）强相关，但也在几个重要方面存在差异，比如正确定位一些路径依赖和自由派派别的议员。

    The mass aggregation of knowledge embedded in large language models (LLMs) holds the promise of new solutions to problems of observability and measurement in the social sciences. We examine the utility of one such model for a particularly difficult measurement task: measuring the latent ideology of lawmakers, which allows us to better understand functions that are core to democracy, such as how politics shape policy and how political actors represent their constituents. We scale the senators of the 116th United States Congress along the liberal-conservative spectrum by prompting ChatGPT to select the more liberal (or conservative) senator in pairwise comparisons. We show that the LLM produced stable answers across repeated iterations, did not hallucinate, and was not simply regurgitating information from a single source. This new scale strongly correlates with pre-existing liberal-conservative scales such as NOMINATE, but also differs in several important ways, such as correctly placin
    
[^3]: 评估聊天机器人的对话回复

    Grading Conversational Responses Of Chatbots. (arXiv:2303.12038v1 [cs.CL])

    [http://arxiv.org/abs/2303.12038](http://arxiv.org/abs/2303.12038)

    本文研究了ChatGPT聊天机器人对问题的回答表现，并使用标准的机器翻译评测指标进行比较，结果表明它们的表现仍然落后于典型人类的反应能力。

    

    聊天机器人能够回答基本问题，甚至回应奇怪的提示，但最近它们的改进显著提高。像OpenAI ChatGPT3这样的现代聊天机器人不仅能够回答基本问题，还能编写代码、电影剧本并模仿知名人物。在本文中，我们分析了ChatGPT对从流行Quora论坛的数据集中提出的各种问题的回答。我们向ChatGPT提交了60个问题，并根据三个行业标准评分机器翻译的度量标准(BLEU、METEOR和ROUGE)对答案进行评分。这些度量标准允许我们将机器的回复与同一问题的最多赞同的人类答案进行比较，以评估ChatGPT提交人性化回复的能力。结果显示，虽然ChatGPT的响应和翻译能力非常出色，但仍然达不到典型人类反应的水平。

    Chatbots have long been capable of answering basic questions and even responding to obscure prompts, but recently their improvements have been far more significant. Modern chatbots like Open AIs ChatGPT3 not only have the ability to answer basic questions but can write code and movie scripts and imitate well-known people. In this paper, we analyze ChatGPTs' responses to various questions from a dataset of queries from the popular Quora forum. We submitted sixty questions to ChatGPT and scored the answers based on three industry-standard metrics for grading machine translation: BLEU, METEOR, and ROUGE. These metrics allow us to compare the machine responses with the most upvoted human answer to the same question to assess ChatGPT's ability to submit a humanistic reply. The results showed that while the responses and translation abilities of ChatGPT are remarkable, they still fall short of what a typical human reaction would be.
    
[^4]: 戴口罩是否意味着反对特朗普？：跨新冠疫情和2020年美国大选的目标特定用户立场预测之路

    Wearing Masks Implies Refuting Trump?: Towards Target-specific User Stance Prediction across Events in COVID-19 and US Election 2020. (arXiv:2303.12029v1 [cs.SI])

    [http://arxiv.org/abs/2303.12029](http://arxiv.org/abs/2303.12029)

    该研究提出了一个框架，旨在预测一个人在未来事件中的行为，通过分析人们在口罩、种族平等和特朗普等话题上的立场，并揭示了过去行为在预测未来行为方面的能力。

    

    在具有争议的话题中，持相似观点的人可能会形成回音室，并可能对其他话题持有类似的政治观点。我们称这种联系存在的连接行为，为研究人员提供了预测一个人在未来事件中会如何行动的独特机会。在这项工作中，我们提出了一个框架来进行连接行为分析。我们利用在 Twitter 上收集的关于三个看似独立的话题（口罩、种族平等和特朗普）的数据来训练神经立场检测模型，以检测人们的立场，我们认为这是他们在每个与话题有关的事件中的在线行为。我们的结果揭示了三个主题事件的观点之间的强连接，并展示了过去行为在预测一个人未来行为方面的能力。

    People who share similar opinions towards controversial topics could form an echo chamber and may share similar political views toward other topics as well. The existence of such connections, which we call connected behavior, gives researchers a unique opportunity to predict how one would behave for a future event given their past behaviors. In this work, we propose a framework to conduct connected behavior analysis. Neural stance detection models are trained on Twitter data collected on three seemingly independent topics, i.e., wearing a mask, racial equality, and Trump, to detect people's stance, which we consider as their online behavior in each topic-related event. Our results reveal a strong connection between the stances toward the three topical events and demonstrate the power of past behaviors in predicting one's future behavior.
    
[^5]: cTBL：增强大型语言模型用于对话表格

    cTBL: Augmenting Large Language Models for Conversational Tables. (arXiv:2303.12024v1 [cs.CL])

    [http://arxiv.org/abs/2303.12024](http://arxiv.org/abs/2303.12024)

    本论文提出了一种称为cTBL的方法，可以从表格中检索信息，并生成具有检索信息支撑的对话响应，其中使用了转换器编码器嵌入进行浓密表检索，可以获得更好的性能。

    

    多模态对话人工智能中一个开放的挑战是如何从文本和非文本来源中增强大型语言模型以进行多轮对话。为了解决这个问题，本文引入了Conversation Table (cTBL)，这是一种三步编码器-解码器方法，用于检索表格信息并生成基于检索信息的对话响应。cTBL使用转换器编码器嵌入进行浓密表检索，并在HyrbiDialogue数据集Top-1和Top-3准确性上相对于稀疏检索提高了最多5%。此外，cTBL使用编码器和解码器模型进行表格知识检索，在HyrbiDialogue上产生了最高46%的ROUGE分数相对改进，并实现了更好的人工评估响应生成。

    An open challenge in multimodal conversational AI requires augmenting large language models with information from textual and non-textual sources for multi-turn dialogue. To address this problem, this paper introduces Conversational Tables (cTBL), a three-step encoder-decoder approach to retrieve tabular information and generate dialogue responses grounded on the retrieved information. cTBL uses Transformer encoder embeddings for Dense Table Retrieval and obtains up to 5% relative improvement in Top-1 and Top-3 accuracy over sparse retrieval on the HyrbiDialogue dataset. Additionally, cTBL performs tabular knowledge retrieval using both encoder and decoder models, resulting in up to 46% relative improvement in ROUGE scores and better human evaluation for response generation on HyrbiDialogue.
    
[^6]: 自然语言作为知识表示的逻辑推理研究：综述

    Logical Reasoning over Natural Language as Knowledge Representation: A Survey. (arXiv:2303.12023v1 [cs.CL])

    [http://arxiv.org/abs/2303.12023](http://arxiv.org/abs/2303.12023)

    本文总结了一种新的逻辑推理方法，它使用自然语言作为知识表示，具有不同于端到端神经方法的优势。这种新模式在未来有着很高的潜力。

    

    逻辑推理是人类认知和智能的核心。以往的人工智能中的逻辑推理研究使用形式化语言作为知识表示（和符号推理器）。然而，使用形式化语言进行推理证明具有困难（例如脆弱性和知识获取瓶颈）。本文总结了一种新的逻辑推理方法的综合概述，它使用自然语言作为知识表示（以及预训练语言模型作为推理器），包括逻辑推理的哲学定义和分类，新模式的优势、基准和方法，未来需要的任务和方法以及与相关 NLP 领域的关系。这种新模式是很有前途的，因为它不仅可以缓解形式化表示的许多挑战，而且也具有优于端到端神经方法的优势。

    Logical reasoning is central to human cognition and intelligence. Past research of logical reasoning within AI uses formal language as knowledge representation~(and symbolic reasoners). However, reasoning with formal language has proved challenging~(e.g., brittleness and knowledge-acquisition bottleneck). This paper provides a comprehensive overview on a new paradigm of logical reasoning, which uses natural language as knowledge representation~(and pretrained language models as reasoners), including philosophical definition and categorization of logical reasoning, advantages of the new paradigm, benchmarks and methods, challenges of the new paradigm, desirable tasks & methods in the future, and relation to related NLP fields. This new paradigm is promising since it not only alleviates many challenges of formal representation but also has advantages over end-to-end neural methods.
    
[^7]: 无监督跨领域谣言检测：基于对比学习和交叉注意力的方法

    Unsupervised Cross-Domain Rumor Detection with Contrastive Learning and Cross-Attention. (arXiv:2303.11945v1 [cs.SI])

    [http://arxiv.org/abs/2303.11945](http://arxiv.org/abs/2303.11945)

    本文提出一种无监督的、基于对比学习和交叉注意力机制的跨领域谣言检测模型。该模型不仅可以进行跨领域特征对齐，还可以强制目标样本与源域中的相应原型对齐，并使用聚类方法产生伪标签来学习域不变表示，能够显著提高跨领域谣言检测的性能。

    

    大规模谣言通常伴随着突发新闻或热门话题而出现，严重阻碍真相的查证。现有的谣言检测方法大多专注于相同领域，因此在跨领域情况下表现不佳。本文提出了一种端到端的基于实例和原型的，带有交叉注意力机制的对比学习模型，用于跨领域谣言检测。该模型不仅可以进行跨领域特征对齐，还可以强制目标样本与给定源域的相应原型对齐。由于目标域中的目标标签不可用，因此我们使用一种聚类的方法，并通过一批源域样本的仔细初始化中心来产生伪标签。此外，我们使用交叉注意力机制处理具有相同标签的一对源数据和目标数据，以学习域不变表示。由于领域对中的样本倾向于表达相似的语义模式，因此这种方法能够提高模型的检测性能。

    Massive rumors usually appear along with breaking news or trending topics, seriously hindering the truth. Existing rumor detection methods are mostly focused on the same domain, and thus have poor performance in cross-domain scenarios due to domain shift. In this work, we propose an end-to-end instance-wise and prototype-wise contrastive learning model with a cross-attention mechanism for cross-domain rumor detection. The model not only performs cross-domain feature alignment but also enforces target samples to align with the corresponding prototypes of a given source domain. Since target labels in a target domain are unavailable, we use a clustering-based approach with carefully initialized centers by a batch of source domain samples to produce pseudo labels. Moreover, we use a cross-attention mechanism on a pair of source data and target data with the same labels to learn domain-invariant representations. Because the samples in a domain pair tend to express similar semantic patterns,
    
[^8]: 中国中级英语学习者在深层连贯性方面胜过ChatGPT：基于英语叙事写作的证据

    Chinese Intermediate English Learners outdid ChatGPT in deep cohesion: Evidence from English narrative writing. (arXiv:2303.11812v1 [cs.CL])

    [http://arxiv.org/abs/2303.11812](http://arxiv.org/abs/2303.11812)

    本研究比较了ChatGPT和中国中级英语学习者在叙事主题上的写作表现，发现ChatGPT在叙事性、词汇具体性和指代连贯性方面优于人类作家，但在句法简单性和深层连贯性方面略逊一筹。

    

    ChatGPT是一个可公开访问的聊天机器人，可以快速生成指定主题的文本，但是不知道聊天机器人是否在写作的所有方面上都比人类作家优秀，并且不知道在更新命令的基础上其写作质量是否可以显著提高。因此，本研究比较了ChatGPT和中国中级英语（CIE）学习者在叙事主题上的写作表现，以揭示聊天机器人在写作方面的优势和劣势。数据使用Coh-Metrix（一种用于分析语言篇章的特殊工具）按照五个篇章成分进行分析。结果显示，ChatGPT在叙事性、词汇具体性和指代连贯性方面表现优于人类作家，但在句法简单性和深层连贯性方面表现较差。在更新了更多的修订命令后，结果版本的句法简单性得到了改善，但仍远远落后于CIE学习者的写作表现。

    ChatGPT is a publicly available chatbot that can quickly generate texts on given topics, but it is unknown whether the chatbot is really superior to human writers in all aspects of writing and whether its writing quality can be prominently improved on the basis of updating commands. Consequently, this study compared the writing performance on a narrative topic by ChatGPT and Chinese intermediate English (CIE) learners so as to reveal the chatbot's advantage and disadvantage in writing. The data were analyzed in terms of five discourse components using Coh-Metrix (a special instrument for analyzing language discourses), and the results revealed that ChatGPT performed better than human writers in narrativity, word concreteness, and referential cohesion, but worse in syntactic simplicity and deep cohesion in its initial version. After more revision commands were updated, while the resulting version was facilitated in syntactic simplicity, yet it is still lagged far behind CIE learners' wr
    
[^9]: LEAPT: 学习适应性前缀到前缀翻译以进行同声机器翻译

    LEAPT: Learning Adaptive Prefix-to-prefix Translation For Simultaneous Machine Translation. (arXiv:2303.11750v1 [cs.CL])

    [http://arxiv.org/abs/2303.11750](http://arxiv.org/abs/2303.11750)

    LEAPT提出了一种自适应前缀到前缀训练策略，使机器翻译模型能够更好地进行同声翻译，实验表明其在各种参数设置下均具有较好的表现。

    

    同声机器翻译旨在实现实时翻译，在许多现场应用中非常有用，但由于准确性与延迟之间的权衡而非常具有挑战性。为了在精度与延迟之间取得平衡，模型需要等待适当的流式文本（读取策略），然后生成翻译（写入策略）。然而，之前工作的写入策略要么由于端到端训练而对该方法本身具有特异性，要么由于非端到端训练的输入不匹配而受到影响。因此，学习同声机器翻译的通用且更好的写入策略至关重要。本研究受人类口译者及“等待”策略的启发，提出了一种名为LEAPT的新的自适应前缀到前缀训练策略，使我们的机器翻译模型能够学习如何翻译源句子前缀并利用未来的上下文。实验证明，在不同水平噪声和不同流式文本长度的情况下，我们的方法表现优于竞争模型，精度与延迟均得到了提高。

    Simultaneous machine translation, which aims at a real-time translation, is useful in many live scenarios but very challenging due to the trade-off between accuracy and latency. To achieve the balance for both, the model needs to wait for appropriate streaming text (READ policy) and then generates its translation (WRITE policy). However, WRITE policies of previous work either are specific to the method itself due to the end-to-end training or suffer from the input mismatch between training and decoding for the non-end-to-end training. Therefore, it is essential to learn a generic and better WRITE policy for simultaneous machine translation. Inspired by strategies utilized by human interpreters and "wait" policies, we propose a novel adaptive prefix-to-prefix training policy called LEAPT, which allows our machine translation model to learn how to translate source sentence prefixes and make use of the future context. Experiments show that our proposed methods greatly outperform competiti
    
[^10]: 开放领域聊天机器人的悖论：共同基础是实现人类对话的基础

    The Open-domain Paradox for Chatbots: Common Ground as the Basis for Human-like Dialogue. (arXiv:2303.11708v1 [cs.CL])

    [http://arxiv.org/abs/2303.11708](http://arxiv.org/abs/2303.11708)

    最近研究表明，开放领域聊天机器人通过提供最少信息来实现最大化的“开放性”，在实践中导致了“开放领域悖论”——-要求用户“闲聊任何事情”会导致非常狭窄的对话形式。此研究进一步解释了共同基础理论与实现类似人类对话的关系，并提出了实现共同基础的路径。

    

    大型语言模型的最新进展推动了开放领域聊天机器人的发展，其“开放性”预计通过向用户提供最少信息，包括假定的共同活动，来实现最大化。然而，证据表明效果相反。要求用户“闲聊任何事情”会导致非常狭窄的对话形式，我们称之为“开放领域悖论”。在本文中，我们通过共同基础理论解释了这个悖论作为实现类似人类对话的基础。此外，我们质疑开放领域聊天机器人背后的假设，并确定实现人机对话中共同基础的路径。

    There is a surge in interest in the development of open-domain chatbots, driven by the recent advancements of large language models. The "openness" of the dialogue is expected to be maximized by providing minimal information to the users about the common ground they can expect, including the presumed joint activity. However, evidence suggests that the effect is the opposite. Asking users to "just chat about anything" results in a very narrow form of dialogue, which we refer to as the "open-domain paradox". In this paper, we explain this paradox through the theory of common ground as the basis for human-like communication. Furthermore, we question the assumptions behind open-domain chatbots and identify paths forward for enabling common ground in human-computer dialogue.
    
[^11]: 构建简单有效的合成数据集用于无监督情感摘要

    Simple Yet Effective Synthetic Dataset Construction for Unsupervised Opinion Summarization. (arXiv:2303.11660v1 [cs.CL])

    [http://arxiv.org/abs/2303.11660](http://arxiv.org/abs/2303.11660)

    本文提出了两种简单有效的无监督方法，利用构建的合成数据集生成特定方面和一般意见摘要。SW-LOO方法通过种子词匹配确定评论的特定方面，并在SPACE和OPOSUM+数据集上都有很好效果；NLI-LOO方法通过NLI模型识别与方面相关的句子，在SPACE数据集上有很好效果。

    

    意见摘要提供了一个重要的解决方案，可以对大量评论中表达的意见进行摘要。但是，由于缺乏注释数据，生成特定方面和一般摘要是具有挑战性的。在本文中，我们提出了两种构建合成数据集的简单有效无监督方法，通过训练包含特定方面的评论内容的合成数据集来生成特定方面和一般意见摘要。第一种方法，基于种子词的留一法（SW-LOO），仅通过精确匹配方面的种子词来确定评论的特定方面，并在SPACE数据集上超过其他方法3.4 ROUGE-L点，在OPOSUM+数据集上超过0.5 ROUGE-1点，用于特定方面的意见摘要。第二种方法，基于自然语言推理的留一法（NLI-LOO），在更普遍的设置中，利用NLI模型识别与方面相关的句子，而不使用种子词，并在SPACE数据集上超过其他方法1.2 ROUGE-L点。

    Opinion summarization provides an important solution for summarizing opinions expressed among a large number of reviews. However, generating aspect-specific and general summaries is challenging due to the lack of annotated data. In this work, we propose two simple yet effective unsupervised approaches to generate both aspect-specific and general opinion summaries by training on synthetic datasets constructed with aspect-related review contents. Our first approach, Seed Words Based Leave-One-Out (SW-LOO), identifies aspect-related portions of reviews simply by exact-matching aspect seed words and outperforms existing methods by 3.4 ROUGE-L points on SPACE and 0.5 ROUGE-1 point on OPOSUM+ for aspect-specific opinion summarization. Our second approach, Natural Language Inference Based Leave-One-Out (NLI-LOO) identifies aspect-related sentences utilizing an NLI model in a more general setting without using seed words and outperforms existing approaches by 1.2 ROUGE-L points on SPACE for as
    
[^12]: 异构分支协作学习用于对话生成

    Heterogeneous-Branch Collaborative Learning for Dialogue Generation. (arXiv:2303.11621v1 [cs.CL])

    [http://arxiv.org/abs/2303.11621](http://arxiv.org/abs/2303.11621)

    本文提出了一种异构分支协作学习模型，用于对话生成。该模型使用协作学习方法而非传统的知识蒸馏方法，在网络分支的训练中考虑到对话属性，使不同分支的特征多样化。

    

    随着深度学习的发展，高级对话生成方法通常需要更多的计算资源。一种有效的获得高性能和轻量级模型的方法是知识蒸馏，其依赖于预训练的强大教师模型。协作学习，也称为在线知识蒸馏，在缺乏训练良好的大型教师模型的情况下，是进行单阶段群体蒸馏的有效方法。然而，先前的工作由于相同的训练目标和独立相同的训练集存在严重的分支同质性问题。为了缓解这个问题，我们考虑在网络分支的训练中考虑对话属性。每个分支基于所选子集学习与属性相关的特征。此外，我们提出了一个双重基于群体的知识蒸馏方法，包括积极蒸馏和消极蒸馏，进一步使不同分支的特征多样化。

    With the development of deep learning, advanced dialogue generation methods usually require a greater amount of computational resources. One promising approach to obtaining a high-performance and lightweight model is knowledge distillation, which relies heavily on the pre-trained powerful teacher. Collaborative learning, also known as online knowledge distillation, is an effective way to conduct one-stage group distillation in the absence of a well-trained large teacher model. However, previous work has a severe branch homogeneity problem due to the same training objective and the independent identical training sets. To alleviate this problem, we consider the dialogue attributes in the training of network branches. Each branch learns the attribute-related features based on the selected subset. Furthermore, we propose a dual group-based knowledge distillation method, consisting of positive distillation and negative distillation, to further diversify the features of different branches in
    
[^13]: 论文翻译：语音处理中的Transformer：综述（arXiv:2303.11607v1 [cs.CL]）

    Transformers in Speech Processing: A Survey. (arXiv:2303.11607v1 [cs.CL])

    [http://arxiv.org/abs/2303.11607](http://arxiv.org/abs/2303.11607)

    本文综述了Transformer在语音相关领域的广泛应用，为研究者提供了有价值的资源。同时，指出了在语音处理领域中Transformer所面临的挑战及可能的解决思路。

    

    Transformer 在自然语言处理领域中的显著成功引起了语音处理社区的兴趣，进而探索了其模拟语音序列中长距离依赖关系的潜力。最近，Transformer 在各种涉及语音的领域中名声鹊起，包括自动语音识别、语音合成、语音翻译、语音声调学、语音增强、口语对话系统，以及许多多模态应用。本文提供一份综合性调查报告，旨在桥接语音技术各子领域的研究。通过整合来自语音技术领域的研究结果，我们为希望利用Transformer推进领域发展的研究人员提供了有价值的资源。同时，我们也指出了Transformer在语音处理中遇到的挑战，并提供了解决这些问题的潜在思路。

    The remarkable success of transformers in the field of natural language processing has sparked the interest of the speech-processing community, leading to an exploration of their potential for modeling long-range dependencies within speech sequences. Recently, transformers have gained prominence across various speech-related domains, including automatic speech recognition, speech synthesis, speech translation, speech para-linguistics, speech enhancement, spoken dialogue systems, and numerous multimodal applications. In this paper, we present a comprehensive survey that aims to bridge research studies from diverse subfields within speech technology. By consolidating findings from across the speech technology landscape, we provide a valuable resource for researchers interested in harnessing the power of transformers to advance the field. We identify the challenges encountered by transformers in speech processing while also offering insights into potential solutions to address these issue
    
[^14]: 应用SMILES序列的Transformer模型在学习手性时存在困难

    Difficulty in learning chirality for Transformer fed with SMILES. (arXiv:2303.11593v1 [cs.LG])

    [http://arxiv.org/abs/2303.11593](http://arxiv.org/abs/2303.11593)

    应用SMILES序列的Transformer模型在学习分子结构的整体性和手性方面存在困难，需要进行长时间的训练。生成的描述符用于分子性质预测时的准确率从开始到训练结束都是相似的。

    

    近年来，基于对极其多样的分子进行表示学习的描述符生成已经得到了发展，特别是那些将自然语言处理（NLP）模型应用于SMILES，即分子结构的文字表示的模型。然而，关于这些模型如何理解化学结构的研究很少。为了解决这个问题，我们调查了一种代表性的NLP模型——Transformer，在学习SMILES和化学结构之间的关系。结果表明，虽然Transformer快速学习分子的部分结构，但需要进行长时间的训练才能理解整体结构。与之一致的是，在不同的学习步骤中生成的描述符用于分子性质预测时的准确率从开始到训练结束都是相似的。此外，我们发现Transformer需要特别长的训练时间才能学习手性，并且有时会出现低翻译准确率的停滞现象。

    Recent years have seen development of descriptor generation based on representation learning of extremely diverse molecules, especially those that apply natural language processing (NLP) models to SMILES, a literal representation of molecular structure. However, little research has been done on how these models understand chemical structure. To address this, we investigated the relationship between the learning progress of SMILES and chemical structure using a representative NLP model, the Transformer. The results suggest that while the Transformer learns partial structures of molecules quickly, it requires extended training to understand overall structures. Consistently, the accuracy of molecular property predictions using descriptors generated from models at different learning steps was similar from the beginning to the end of training. Furthermore, we found that the Transformer requires particularly long training to learn chirality and sometimes stagnates with low translation accura
    
[^15]: SIFT: 稀疏等FLOP转换以最大限度提高训练效率

    SIFT: Sparse Iso-FLOP Transformations for Maximizing Training Efficiency. (arXiv:2303.11525v1 [cs.LG])

    [http://arxiv.org/abs/2303.11525](http://arxiv.org/abs/2303.11525)

    本研究提出了一种名为SIFT的方法，用于提高深度神经网络的训练效率、准确性和表示能力，通过稀疏等FLOP转换，缩短训练时间。

    

    最近的研究探索了使用权重稀疏性来改善深度神经网络（DNN）的训练效率（与训练FLOPS相关的测试准确性）。 这些工作旨在减少训练FLOP，但使用稀疏权重进行训练通常会导致准确性损失或需要更长的训练周期，使得结果的训练效率不够清晰。 相比之下，我们专注于使用稀疏性提高准确性，同时使用与密集模型相同的FLOPS，并通过更高的准确性展示训练效率提高。 在本文中，我们介绍了SIFT，一组用作密集层的即插即用替代品来提高其表示能力和FLOP效率的稀疏等FLOP转换。 每个转换都由一个单一参数（稀疏级别）参数化，并提供更大的搜索空间以找到最佳的稀疏掩膜。

    Recent works have explored the use of weight sparsity to improve the training efficiency (test accuracy w.r.t training FLOPs) of deep neural networks (DNNs). These works aim to reduce training FLOPs but training with sparse weights often leads to accuracy loss or requires longer train schedules, making the resulting training efficiency less clear. In contrast, we focus on using sparsity to increase accuracy while using the same FLOPS as the dense model and show training efficiency gains through higher accuracy. In this work, we introduce SIFT, a family of Sparse Iso-FLOP Transformations which are used as drop-in replacements for dense layers to improve their representational capacity and FLOP efficiency. Each transformation is parameterized by a single parameter (sparsity level) and provides a larger search space to find optimal sparse masks. Without changing any training hyperparameters, replacing dense layers with SIFT leads to significant improvements across computer vision (CV) and
    
[^16]: 语言模型行为：一项全面调查

    Language Model Behavior: A Comprehensive Survey. (arXiv:2303.11504v1 [cs.CL])

    [http://arxiv.org/abs/2303.11504](http://arxiv.org/abs/2303.11504)

    该论文总结了250多个关于英文语言模型行为的最近研究，发现大型语言模型具有基本的句法、语义、语用、世界知识和推理能力，但容易出现不实回答、常识错误、记忆化文本和社会偏见等弱点。

    

    Transformer 语言模型已经受到了广泛的关注，然而它们生成的文本即使对于自然语言处理研究人员来说也常常令人惊讶。在本次调查中，我们讨论了250多个关于英语语言模型行为的最近研究，这些研究在任务特定的微调之前进行。语言模型具有基本的句法、语义、语用、世界知识和推理能力，但这些能力对特定的输入和表面特征很敏感。尽管模型随着参数量的增加而生成的文本质量显著提高，但它们仍然容易出现不实回答、常识错误、记忆化文本和社会偏见。其中许多弱点可以被描述为对文本中所学模式的过度推广或过度泛化。我们综合了最近的结果，突出了目前已知的大型语言模型能够做什么和不能做什么。

    Transformer language models have received widespread public attention, yet their generated text is often surprising even to NLP researchers. In this survey, we discuss over 250 recent studies of English language model behavior before task-specific fine-tuning. Language models possess basic capabilities in syntax, semantics, pragmatics, world knowledge, and reasoning, but these capabilities are sensitive to specific inputs and surface features. Despite dramatic increases in generated text quality as models scale to hundreds of billions of parameters, the models are still prone to unfactual responses, commonsense errors, memorized text, and social biases. Many of these weaknesses can be framed as over-generalizations or under-generalizations of learned patterns in text. We synthesize recent results to highlight what is currently known about what large language models can and cannot do.
    
[^17]: 大型语言模型与简单愚蠢 Bug

    Large Language Models and Simple, Stupid Bugs. (arXiv:2303.11455v1 [cs.SE])

    [http://arxiv.org/abs/2303.11455](http://arxiv.org/abs/2303.11455)

    本文研究表明，大型语言模型如Codex虽然有助于避免一些简单Bug，但经常会生成已知的，逐字的Bug，因此需要采取避免策略来减少这种情况，并增加有创意的Bug的生产。

    

    随着强大的神经语言模型的出现，用于辅助开发者进行编码任务的基于AI的系统变得普遍可用；Copilot便是这样的系统。Copilot使用Codex这个大型语言模型（LLM）来完成一个相应的“提示”后的代码。然而，Codex是在公共GitHub存储库上训练的，即可能包含错误和漏洞的代码。先前的研究表明Codex会复制训练中出现的漏洞。在这项研究中，我们研究了Codex生成的一个有趣的 Bug 类型的易发性，即单语句 Bug，通常被称为简单愚蠢 Bug 或 SStuBs。我们发现Codex和类似的LLMs确实有助于避免一些SStuBs，但确实会生成已知的，逐字的SStuBs，其出现的可能性是已知正确代码的2倍。我们探讨了Codex生成的SStuBs的后果，并提出了避免策略，这些策略可能有助于减少已知的，逐字的SStubs的生产，并增加有创意的Bug的生产。

    With the advent of powerful neural language models, AI-based systems to assist developers in coding tasks are becoming widely available; Copilot is one such system. Copilot uses Codex, a large language model (LLM), to complete code conditioned on a preceding "prompt". Codex, however, is trained on public GitHub repositories, viz., on code that may include bugs and vulnerabilities. Previous studies [1], [2] show Codex reproduces vulnerabilities seen in training. In this study, we examine how prone Codex is to generate an interesting bug category, single statement bugs, commonly referred to as simple, stupid bugs or SStuBs in the MSR community. We find that Codex and similar LLMs do help avoid some SStuBs, but do produce known, verbatim SStuBs as much as 2x as likely than known, verbatim correct code. We explore the consequences of the Codex generated SStuBs and propose avoidance strategies that suggest the possibility of reducing the production of known, verbatim SStubs, and increase th
    
[^18]: 心灵与机器: 解开GPT-4的认知心理学之谜

    Mind meets machine: Unravelling GPT-4's cognitive psychology. (arXiv:2303.11436v1 [cs.CL])

    [http://arxiv.org/abs/2303.11436](http://arxiv.org/abs/2303.11436)

    本研究评估了在广泛使用的CommonsenseQA数据集中的一套常识推理问题上，GPT-4的表现及其对常识知识的处理和整合过程，在此过程中我们也发现了其局限性。

    

    常识推理是人类智能的基本成分，使其能够根据环境观察推断结论。大型语言模型(LLMs)正成为越来越能够执行人类级任务的强有力工具。最近开发的GPT-4及其在医学考试、律师考试等人类难以完成的任务中表现出的成功，增加了LLMs成为完美智能工具的信心。然而，尽管GPT-4论文向我们展示了其在某些常识推理任务中的表现，但对GPT-4在常识推理任务上的全面评估，特别是现有的已经确立好的数据集上的评估还是缺失的。为此，我们关注GPT-4在广泛使用的CommonsenseQA数据集中的一套常识推理问题上的表现评估及其认知心理学工具。通过这样做，我们能够理解GPT-4如何在其语言生成过程中处理和整合常识知识，以及其在这方面的局限性。

    Commonsense reasoning is a basic ingredient of intelligence in humans, empowering the ability to deduce conclusions based on the observations of surroundings. Large language models (LLMs) are emerging as potent tools increasingly capable of performing human-level tasks. The recent development in the form of GPT-4 and its demonstrated success in tasks complex to humans such as medical exam, bar exam and others has led to an increased confidence in the LLMs to become perfect instruments of intelligence. Though, the GPT-4 paper has shown performance on some common sense reasoning tasks, a comprehensive assessment of GPT-4 on common sense reasoning tasks, particularly on the existing well-established datasets is missing. In this study, we focus on the evaluation of GPT-4's performance on a set of common sense reasoning questions from the widely used CommonsenseQA dataset along with tools from cognitive psychology. In doing so, we understand how GPT-4 processes and integrates common sense k
    
[^19]: eP-ALM:语言模型的高效感知增强

    eP-ALM: Efficient Perceptual Augmentation of Language Models. (arXiv:2303.11403v1 [cs.CV])

    [http://arxiv.org/abs/2303.11403](http://arxiv.org/abs/2303.11403)

    本论文提出了一种用对比学习提高语言模型的感知能力的高效方法eP-ALM，可以实现视觉感知信息和文本信息的融合，同时还能在多模态基准测试上实现最先进的结果。

    

    大型语言模型(LLM)迄今为止给世界留下了深刻印象，具有大规模模型所具有的非同寻常的能力。在视觉方面，变压器模型（即ViT）也在追随同一趋势，取得了最具挑战性的基准测试的最佳表现。随着这种单模型的丰富多样，自然会引发一个问题：我们是否需要跟随这个趋势来处理多模态任务？在这项工作中，我们提出将努力集中于现有模型的高效适应，并提出用感知来增强语言模型。现有的适应预训练模型用于视觉语言任务的方法仍然依赖于几个关键组件，从而影响了它们的效率。特别地，他们仍然训练大量的参数，依赖大规模的多模态预训练，使用在巨大的图像-文本数据集上训练的编码器（例如CLIP），并添加了显著的推理开销。此外，这些方法中的大多数关注Zero-Shot和In Context Learning，观察到两种范式之间的巨大差异。在本文中，我们介绍了eP-ALM，一种将视觉感知信息与语言模型相结合的高效方法。我们提出了一种方法，利用对比学习来实现视觉感知和文本信息的融合，具有极小的计算成本。我们的方法不需要任何新的预训练，仍然在多模态基准测试上实现了最先进的结果。

    Large Language Models (LLMs) have so far impressed the world, with unprecedented capabilities that emerge in models at large scales. On the vision side, transformer models (i.e., ViT) are following the same trend, achieving the best performance on challenging benchmarks. With the abundance of such unimodal models, a natural question arises; do we need also to follow this trend to tackle multimodal tasks? In this work, we propose to rather direct effort to efficient adaptations of existing models, and propose to augment Language Models with perception. Existing approaches for adapting pretrained models for vision-language tasks still rely on several key components that hinder their efficiency. In particular, they still train a large number of parameters, rely on large multimodal pretraining, use encoders (e.g., CLIP) trained on huge image-text datasets, and add significant inference overhead. In addition, most of these approaches have focused on Zero-Shot and In Context Learning, with l
    
[^20]: MM-REACT：促进ChatGPT进行多模态推理和行动的系统范式

    MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action. (arXiv:2303.11381v1 [cs.CV])

    [http://arxiv.org/abs/2303.11381](http://arxiv.org/abs/2303.11381)

    MM-REACT是一种融合视觉专家和ChatGPT的多模态推理和行动系统，通过文字提示设计，实现了ChatGPT和各种视觉专家的协同，具有广泛的高级视觉理解应用价值。

    

    本文提出了MM-REACT，一种将ChatGPT与视觉专家池集成以实现多模态推理和行动的系统范式。我们定义并探索了一系列先进的视觉任务，这些任务很有趣，但可能超出了现有视觉和视觉语言模型的能力范围。为了实现这种高级视觉智能，MM-REACT引入了一种文本提示设计，可以表示文本描述、文本化的空间坐标和对齐的文件名，用于处理图像和视频等密集的视觉信号。MM-REACT的提示设计允许语言模型接受、关联和处理多模态信息，从而促进了ChatGPT和各种视觉专家的协同组合。零样本实验证明了MM-REACT解决感兴趣的特定能力以及在需要高级视觉理解的不同场景中具有广泛应用的有效性。此外，我们还讨论和比较了M

    We propose MM-REACT, a system paradigm that integrates ChatGPT with a pool of vision experts to achieve multimodal reasoning and action. In this paper, we define and explore a comprehensive list of advanced vision tasks that are intriguing to solve, but may exceed the capabilities of existing vision and vision-language models. To achieve such advanced visual intelligence, MM-REACT introduces a textual prompt design that can represent text descriptions, textualized spatial coordinates, and aligned file names for dense visual signals such as images and videos. MM-REACT's prompt design allows language models to accept, associate, and process multimodal information, thereby facilitating the synergetic combination of ChatGPT and various vision experts. Zero-shot experiments demonstrate MM-REACT's effectiveness in addressing the specified capabilities of interests and its wide application in different scenarios that require advanced visual understanding. Furthermore, we discuss and compare M
    
[^21]: Reflexion：具有动态记忆和自我反思的自主智能体

    Reflexion: an autonomous agent with dynamic memory and self-reflection. (arXiv:2303.11366v1 [cs.AI])

    [http://arxiv.org/abs/2303.11366](http://arxiv.org/abs/2303.11366)

    本文提出 Reflexion 方法，给智能体赋予了动态记忆和自我反思能力，以增强其任务特定的行动选择能力。

    

    最近决策大型语言模型（LLM）代理的发展在各种基准测试中展现出卓越的性能。然而，这些最先进的方法通常需要内部模型微调、外部模型微调或在定义的状态空间上进行策略优化。由于高质量训练数据的稀缺性或缺乏良好定义的状态空间，实现这些方法可能会具有挑战性。此外，这些代理没有人类决策过程固有的某些品质，特别是从错误中学习的能力。通过反思，人类可以通过试错过程高效地解决新的问题。在最近的研究基础上，我们提出 Reflexion，一种将动态记忆和自我反思能力赋予智能体的方法，以增强其现有的推理轨迹和任务特定的行动选择能力。为了实现完全自动化，我们介绍了一种简单而有效的方法。

    Recent advancements in decision-making large language model (LLM) agents have demonstrated impressive performance across various benchmarks. However, these state-of-the-art approaches typically necessitate internal model fine-tuning, external model fine-tuning, or policy optimization over a defined state space. Implementing these methods can prove challenging due to the scarcity of high-quality training data or the lack of well-defined state space. Moreover, these agents do not possess certain qualities inherent to human decision-making processes, specifically the ability to learn from mistakes. Self-reflection allows humans to efficiently solve novel problems through a process of trial and error. Building on recent research, we propose Reflexion, an approach that endows an agent with dynamic memory and self-reflection capabilities to enhance its existing reasoning trace and task-specific action choice abilities. To achieve full automation, we introduce a straightforward yet effective 
    
[^22]: DocRED-FE：一份文档级细粒度实体和关系抽取数据集

    DocRED-FE: A Document-Level Fine-Grained Entity And Relation Extraction Dataset. (arXiv:2303.11141v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.11141](http://arxiv.org/abs/2303.11141)

    本研究构建了一个文档级细粒度实体和关系抽取的数据集DocRED-FE，重新设计了一个分层的实体类型模式，并根据该模式手动重新注释了DocRED。在全面的实验中发现，DocRED-FE的细粒度实体类型可以提高关系分类的性能。

    

    联合实体和关系抽取（JERE）是信息抽取中最重要的任务之一。然而，大多数现有的工作都集中在句子级别的粗粒度JERE上，在现实场景中存在一定局限性。本文构建了一个大规模的文档级细粒度JERE数据集DocRED-FE，该数据集通过细粒度实体类型来改进DocRED。具体而言，我们重新设计了一个分层的实体类型模式，包括11个粗粒度类型和119个细粒度类型，然后根据该模式手动重新注释了DocRED。通过全面的实验，我们发现：（1）对现有的JERE模型而言，DocRED-FE非常具有挑战性；（2）我们的细粒度实体类型可以提高关系分类的性能。我们在https://github.com/PKU-TANGENT/DOCRED-FE上提供了DocRED-FE的指令和我们基线模型的代码。

    Joint entity and relation extraction (JERE) is one of the most important tasks in information extraction. However, most existing works focus on sentence-level coarse-grained JERE, which have limitations in real-world scenarios. In this paper, we construct a large-scale document-level fine-grained JERE dataset DocRED-FE, which improves DocRED with Fine-Grained Entity Type. Specifically, we redesign a hierarchical entity type schema including 11 coarse-grained types and 119 fine-grained types, and then re-annotate DocRED manually according to this schema. Through comprehensive experiments we find that: (1) DocRED-FE is challenging to existing JERE models; (2) Our fine-grained entity types promote relation classification. We make DocRED-FE with instruction and the code for our baselines publicly available at https://github.com/PKU-TANGENT/DOCRED-FE.
    
[^23]: 仅仅提示足够了吗？不是的。指导学习的全面和更广阔视角（arXiv：2303.10475v1 [cs.CL]）

    Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning. (arXiv:2303.10475v1 [cs.CL])

    [http://arxiv.org/abs/2303.10475](http://arxiv.org/abs/2303.10475)

    传统的自然语言处理机器学习需要大规模的任务特定示例，但这不适用于任务可能过于复杂或成本过高以进行注释的场景。因此，社区对于自然语言处理中新的监督寻求范式--从任务指令学习--越来越感兴趣。

    

    任务语义可以通过一组输入输出示例或一条文本指令来表达。传统的自然语言处理（NLP）机器学习方法主要依赖于大规模的任务特定示例的可用性。这引起了两个问题：首先，收集任务特定标记示例不适用于任务可能过于复杂或成本过高以进行注释的场景，或者系统需要立即处理新任务。其次，这不是用户友好的，因为最终用户可能更愿意在使用系统之前提供任务描述而不是一组示例。因此，社区对于自然语言处理中新的监督寻求范式--从任务指令学习--越来越感兴趣。尽管取得了令人印象深刻的进展，但社区仍然面临着一些共同的问题。本次调查旨在总结指导学习的当前研究，特别是回答以下问题：

    Task semantics can be expressed by a set of input-to-output examples or a piece of textual instruction. Conventional machine learning approaches for natural language processing (NLP) mainly rely on the availability of large-scale sets of task-specific examples. Two issues arise: first, collecting task-specific labeled examples does not apply to scenarios where tasks may be too complicated or costly to annotate, or the system is required to handle a new task immediately; second, this is not user-friendly since end-users are probably more willing to provide task description rather than a set of examples before using the system. Therefore, the community is paying increasing interest in a new supervision-seeking paradigm for NLP: learning from task instructions. Despite its impressive progress, there are some common issues that the community struggles with. This survey paper tries to summarize the current research on instruction learning, particularly, by answering the following questions:
    
[^24]: GLEN：面向数千种类型的通用事件检测

    GLEN: General-Purpose Event Detection for Thousands of Types. (arXiv:2303.09093v1 [cs.CL])

    [http://arxiv.org/abs/2303.09093](http://arxiv.org/abs/2303.09093)

    研究者建立了一个通用事件检测数据集GLEN，涵盖了超过3,465种不同的事件类型，利用现有的标注，他们提出了一种新的多阶段事件检测模型，展示了在大本体大小和部分标签的情况下，该模型具有优越的性能。

    

    事件抽取系统的发展一直受限于缺乏广泛覆盖、大规模数据集。为了使事件抽取系统更易于使用，我们建立了一个通用事件检测数据集GLEN，涵盖了3,465种不同的事件类型，本体比任何当前数据集都大20倍以上。GLEN利用DWD叠加技术创建，通过提供维基百科Qnode和PropBank角色集之间的映射，使用PropBank的现有标注作为间接监督来完成创建。此外，我们还提出了一种新的多阶段事件检测模型，专门设计用于处理GLEN的大本体大小和部分标签。我们展示了我们的模型表现出优越的性能（F1分数提高了约10%），与传统的分类基线和较新的基于定义的模型相比。最后，我们进行了错误分析，并显示标签噪声仍然是提高性能的最大挑战。

    The development of event extraction systems has been hindered by the absence of wide-coverage, large-scale datasets. To make event extraction systems more accessible, we build a general-purpose event detection dataset GLEN, which covers 3,465 different event types, making it over 20x larger in ontology than any current dataset. GLEN is created by utilizing the DWD Overlay, which provides a mapping between Wikidata Qnodes and PropBank rolesets. This enables us to use the abundant existing annotation for PropBank as distant supervision. In addition, we also propose a new multi-stage event detection model specifically designed to handle the large ontology size and partial labels in GLEN. We show that our model exhibits superior performance (~10% F1 gain) compared to both conventional classification baselines and newer definition-based models. Finally, we perform error analysis and show that label noise is still the largest challenge for improving performance.
    
[^25]: 基于数据有效学习的机器人任务规格自然语言到线性时间逻辑翻译器

    Data-Efficient Learning of Natural Language to Linear Temporal Logic Translators for Robot Task Specification. (arXiv:2303.08006v1 [cs.CL])

    [http://arxiv.org/abs/2303.08006](http://arxiv.org/abs/2303.08006)

    本篇论文提出了一种基于学习的方法，通过算法生成 LTL 公式，转换成结构化英语来综合生成多样化的自然语言语料库，从而实现对于自然语言命令的 LTL 规格翻译，而且不需要大量的人工标记数据集。

    

    为了使机器人能够服务于更广泛的受众，赋予其理解自然语言命令并用线性时间逻辑（LTL）等形式语言定义具体任务规格的能力至关重要。本文提出了一种基于学习的方法，能够将自然语言命令翻译成 LTL 规格，而且只需要非常有限的受试者标注训练数据。与现有的自然语言到LTL翻译器相比，这种方法不需要大量的人工标记数据集，而是通过算法生成LTL公式，转换成结构化英语，然后利用现代大型语言模型（LLMs）的改写能力来综合生成多样化的自然语言语料库。

    To make robots accessible to a broad audience, it is critical to endow them with the ability to take universal modes of communication, like commands given in natural language, and extract a concrete desired task specification, defined using a formal language like linear temporal logic (LTL). In this paper, we present a learning-based approach for translating from natural language commands to LTL specifications with very limited human-labeled training data. This is in stark contrast to existing natural-language to LTL translators, which require large human-labeled datasets, often in the form of labeled pairs of LTL formulas and natural language commands, to train the translator. To reduce reliance on human data, our approach generates a large synthetic training dataset through algorithmic generation of LTL formulas, conversion to structured English, and then exploiting the paraphrasing capabilities of modern large language models (LLMs) to synthesize a diverse corpus of natural language
    
[^26]: ChatGPT已在地平线上：大语言模型是否就是我们需要的智能交通解决方案？

    ChatGPT Is on the Horizon: Could a Large Language Model Be All We Need for Intelligent Transportation?. (arXiv:2303.05382v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.05382](http://arxiv.org/abs/2303.05382)

    本文探讨了ChatGPT在解决交通问题方面的应用。通过利用具有跨模态编码器的LLM，可以处理来自不同模态的交通数据并执行交通运营。作者提供了一个基于智能手机的碰撞报告自动生成和分析框架作为用例展示了这种潜力。

    

    ChatGPT是由OpenAI开发的具有60亿参数的重要大语言模型之一。ChatGPT展示了LLM的卓越的语言理解能力，特别是在生成对话响应方面。随着LLM在各种研究或工程领域越来越受到关注，现在是时候设想LLM如何革新我们处理智能交通系统的方式了。本文探讨了LLM在解决关键交通问题方面的未来应用。通过利用具有跨模态编码器的LLM，智能系统还可以处理来自不同模态的交通数据并通过LLM执行交通运营。我们提出并验证了LLM装备的这些潜在的交通应用。为了进一步证明这种潜力，我们还提供了一个具体的基于智能手机的碰撞报告自动生成和分析框架作为用例。尽管存在潜在的益处，但与数据隐私相关的挑战仍然存在。

    ChatGPT, developed by OpenAI, is one of the milestone large language models (LLMs) with 6 billion parameters. ChatGPT has demonstrated the impressive language understanding capability of LLM, particularly in generating conversational response. As LLMs start to gain more attention in various research or engineering domains, it is time to envision how LLM may revolutionize the way we approach intelligent transportation systems. This paper explores the future applications of LLM in addressing key transportation problems. By leveraging LLM with cross-modal encoder, an intelligent system can also process traffic data from different modalities and execute transportation operations through an LLM. We present and validate these potential transportation applications equipped by LLM. To further demonstrate this potential, we also provide a concrete smartphone-based crash report auto-generation and analysis framework as a use case. Despite the potential benefits, challenges related to data privac
    
[^27]: QAID：启发式的Few-shot意图检测方法

    QAID: Question Answering Inspired Few-shot Intent Detection. (arXiv:2303.01593v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.01593](http://arxiv.org/abs/2303.01593)

    本文提出了一个启发式的Few-shot意图检测方法，通过将意图检测重新定义为一个问题-回答检索任务来解决语义相似的细粒度意图问题，结果在三个few-shot意图检测基准测试上取得了最优表现。

    

    意图检测涉及到一些语义相似的细粒度意图，是一个具有挑战性的任务。为了解决这个问题，我们将意图检测重新定义为一个问题-回答检索任务，将话语和意图名作为问题和答案。为此，我们利用了一个问题-回答检索体系结构，并采用了一个两阶段培训模式，其中包括批量对比损失。在预训练阶段，我们通过自我监督培训来改善查询表示。然后，在微调阶段中，我们增加了查询和同一意图答案之间的上下文化令牌级相似度分数。我們在三个few-shot意图检测基准测试上的结果达到了最优表现。

    Intent detection with semantically similar fine-grained intents is a challenging task. To address it, we reformulate intent detection as a question-answering retrieval task by treating utterances and intent names as questions and answers. To that end, we utilize a question-answering retrieval architecture and adopt a two stages training schema with batch contrastive loss. In the pre-training stage, we improve query representations through self-supervised training. Then, in the fine-tuning stage, we increase contextualized token-level similarity scores between queries and answers from the same intent. Our results on three few-shot intent detection benchmarks achieve state-of-the-art performance.
    
[^28]: Vid2Seq: 用于密集视频字幕的视觉语言模型的大规模预训练

    Vid2Seq: Large-Scale Pretraining of a Visual Language Model for Dense Video Captioning. (arXiv:2302.14115v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.14115](http://arxiv.org/abs/2302.14115)

    本文介绍了 Vid2Seq，这是一个在大规模 narrated 视频数据集上预先训练的多模态密集事件字幕模型。通过将转录语音的句子边界转化为伪事件边界，并使用转录语音句子作为伪事件字幕，我们有效利用未标注 narrated 视频数据集进行了密集视频字幕的训练。该模型在多个基准测试中表现出色，是目前最优秀的模型之一。

    

    本文介绍了 Vid2Seq，这是一个多模态的单级密集事件字幕模型，它是在大规模 narrated 视频数据集上预先训练的。 Vid2Seq 架构通过特殊的时间标记来增强语言模型，使其能够无缝地预测事件边界和文本描述。我们展示了如何利用未标注 narrated 视频数据集进行密集视频字幕的训练，通过将转录语音的句子边界转化为伪事件边界，并使用转录语音句子作为伪事件字幕。使用 YT-Temporal-1B 数据集预训练的 Vid2Seq 模型在各种密集视频字幕基准测试中均表现出色，包括 YouCook2、ViTT 和 ActivityNet Captions。 Vid2Seq 还可以很好地推广到视频段落字幕和视频片段字幕的任务中。

    In this work, we introduce Vid2Seq, a multi-modal single-stage dense event captioning model pretrained on narrated videos which are readily-available at scale. The Vid2Seq architecture augments a language model with special time tokens, allowing it to seamlessly predict event boundaries and textual descriptions in the same output sequence. Such a unified model requires large-scale training data, which is not available in current annotated datasets. We show that it is possible to leverage unlabeled narrated videos for dense video captioning, by reformulating sentence boundaries of transcribed speech as pseudo event boundaries, and using the transcribed speech sentences as pseudo event captions. The resulting Vid2Seq model pretrained on the YT-Temporal-1B dataset improves the state of the art on a variety of dense video captioning benchmarks including YouCook2, ViTT and ActivityNet Captions. Vid2Seq also generalizes well to the tasks of video paragraph captioning and video clip captionin
    
[^29]: Counteracts：在预训练语言模型中测试刻板印象的对抗性。

    Counteracts: Testing Stereotypical Representation in Pre-trained Language Models. (arXiv:2301.04347v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.04347](http://arxiv.org/abs/2301.04347)

    本文提出了一种使用反例测试预训练语言模型中内部刻板印象的方法，重点是性别偏见，结果表明模型在使用不相关的知识时表现出一定的鲁棒性，更倾向于使用浅层的语言线索来改变内部刻板印象。

    

    语言模型在各种自然语言理解任务中表现出了强大的性能。与人类一样，语言模型也可能从训练数据中学习到自己的偏见。随着越来越多的下游任务将语言模型作为管道的一部分集成，有必要了解内部刻板印象和减轻负面影响的方法。在本文中，我们提出了一种简单的方法，使用反例来测试预训练语言模型中的内部刻板印象。我们主要关注性别偏见，但该方法可以扩展到其他类型的偏见。我们评估了9个不同的填空式提示的模型，包括知识和基础提示。结果表明，在使用不相关的知识时，预训练语言模型表现出一定的鲁棒性，并且更倾向于使用浅层的语言线索，如单词位置和句法结构来改变内部刻板印象。

    Language models have demonstrated strong performance on various natural language understanding tasks. Similar to humans, language models could also have their own bias that is learned from the training data. As more and more downstream tasks integrate language models as part of the pipeline, it is necessary to understand the internal stereotypical representation and the methods to mitigate the negative effects. In this paper, we proposed a simple method to test the internal stereotypical representation in pre-trained language models using counterexamples. We mainly focused on gender bias, but the method can be extended to other types of bias. We evaluated models on 9 different cloze-style prompts consisting of knowledge and base prompts. Our results indicate that pre-trained language models show a certain amount of robustness when using unrelated knowledge, and prefer shallow linguistic cues, such as word position and syntactic structure, to alter the internal stereotypical representat
    
[^30]: 我竟然没有图片了！仅使用语言数据学习视觉任务

    I Can't Believe There's No Images! Learning Visual Tasks Using only Language Data. (arXiv:2211.09778v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.09778](http://arxiv.org/abs/2211.09778)

    本文研究了通过利用对比训练的视觉和语言编码器的联合嵌入空间，并仅使用文本训练数据，在没有对视觉训练数据进行训练的情况下完成四项代表性视觉任务。研究发现这些模型表现良好，具有一定的可迁移性。

    

    计算机视觉任务所需的许多高级技能，例如解析问题、比较和对比语义以及编写描述，也同样适用于其他领域，例如自然语言处理。本文探讨了是否可能从文本数据中学习这些技能，然后在没有对视觉训练数据进行训练的情况下将它们转移到视觉任务中。我们的方法的关键在于利用对比训练的视觉和语言编码器的联合嵌入空间。实践中，对比模型中不同模态的嵌入空间之间可能存在系统性差异，我们分析了这些差异如何影响我们的方法，并研究了缓解此问题的策略。我们使用仅 文本训练数据在四个代表性任务上生成模型：图像字幕、视觉蕴含、视觉问答和视觉新闻，并使用图像对标准基准进行评估。我们发现这些模型通常表现接近。

    Many high-level skills that are required for computer vision tasks, such as parsing questions, comparing and contrasting semantics, and writing descriptions, are also required in other domains such as natural language processing. In this paper, we ask whether it is possible to learn those skills from textual data and then transfer them to vision tasks without ever training on visual training data. Key to our approach is exploiting the joint embedding space of contrastively trained vision and language encoders. In practice, there can be systematic differences between embedding spaces for different modalities in contrastive models, and we analyze how these differences affect our approach and study strategies to mitigate this concern. We produce models using only text training data on four representative tasks: image captioning, visual entailment, visual question answering and visual news, and evaluate them on standard benchmarks using images. We find these models generally perform close 
    
[^31]: PromptCap：使用GPT-3的提示引导图像字幕生成进行视觉问答

    PromptCap: Prompt-Guided Image Captioning for VQA with GPT-3. (arXiv:2211.09699v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.09699](http://arxiv.org/abs/2211.09699)

    提出了PromptCap，一种使用提示引导的图像字幕生成模型，用于解决基于知识的视觉问答中通用图像字幕无法准确描述视觉实体的问题。

    

    基于知识的视觉问答涉及需要超越图片以产生正确答案的世界知识的问题。像GPT-3这样的大型语言模型特别适用于此任务，因为它们具有强大的知识检索和推理能力。为了使LM理解图像，先前的工作使用字幕模型将图像转换为文本。然而，在单个字幕句子中总结图像时，要描述哪些视觉实体经常不明确。通用图像字幕经常错过LM回答视觉问题所必需的视觉细节。为了解决这一挑战，我们提出了PromptCap（Prompt-guided image Captioning），一种字幕模型，旨在成为图像和黑盒LM之间更好的连接器。与通用字幕不同，PromptCap采用自然语言提示来控制生成的字幕中要描述的视觉实体。提示包含字幕应回答的问题。

    Knowledge-based visual question answering (VQA) involves questions that require world knowledge beyond the image to yield the correct answer. Large language models (LMs) like GPT-3 are particularly helpful for this task because of their strong knowledge retrieval and reasoning capabilities. To enable LM to understand images, prior work uses a captioning model to convert images into text. However, when summarizing an image in a single caption sentence, which visual entities to describe are often underspecified. Generic image captions often miss visual details essential for the LM to answer visual questions correctly. To address this challenge, we propose PromptCap (Prompt-guided image Captioning), a captioning model designed to serve as a better connector between images and black-box LMs. Different from generic captions, PromptCap takes a natural-language prompt to control the visual entities to describe in the generated caption. The prompt contains a question that the caption should ai
    
[^32]: 收集交互多模态数据集以进行基础语言理解

    Collecting Interactive Multi-modal Datasets for Grounded Language Understanding. (arXiv:2211.06552v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.06552](http://arxiv.org/abs/2211.06552)

    本文提出了一个通过自然语言任务与协作体验智能体交互收集数据集的方法，并收集了首个交互基础语言理解数据集。

    

    人类智慧能够迅速适应新的任务和环境。从很小的时候开始，人类通过模仿他人的行为或按照提供的自然语言指令学习新技能并学会解决新任务。为了促进研究能够在机器中实现类似功能的方法，本文作出了以下贡献：（1）形式化协作体验智能体使用自然语言任务；（2）开发了一个可进行广泛和可扩展的数据收集工具；（3）收集了首个交互基础语言理解数据集。

    Human intelligence can remarkably adapt quickly to new tasks and environments. Starting from a very young age, humans acquire new skills and learn how to solve new tasks either by imitating the behavior of others or by following provided natural language instructions. To facilitate research which can enable similar capabilities in machines, we made the following contributions (1) formalized the collaborative embodied agent using natural language task; (2) developed a tool for extensive and scalable data collection; and (3) collected the first dataset for interactive grounded language understanding.
    
[^33]: 缓解自然语言系统中隐蔽不安全的文本

    Mitigating Covertly Unsafe Text within Natural Language Systems. (arXiv:2210.09306v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2210.09306](http://arxiv.org/abs/2210.09306)

    本文讨论了智能技术中日益普遍的文本安全问题，并强调了一个被忽视的类别：隐蔽不安全文本。该文提出了缓解策略以解决这一问题，以提高智能系统内部的安全性。

    

    智能技术中一个日益普遍的问题是文本安全性，因为不受控制的系统可能会向用户生成导致伤害或威胁生命的建议。然而，可能导致身体伤害的生成语句的明确程度不同。在本文中，我们区分了可能导致身体伤害的文本类型，并建立了一个尤其未被探索的类别：隐蔽不安全文本。然后，我们进一步分解了这个类别并分析了每个小类别中文本的生成方式。最终，我们的工作定义了导致物理伤害的隐蔽不安全语言问题，并指出这个微妙但危险的问题需要成为相关利益相关者和监管机构的优先考虑问题。我们提出了缓解策略，以启发未来研究人员解决这个具有挑战性的问题，并帮助提高智能系统内部的安全性。

    An increasingly prevalent problem for intelligent technologies is text safety, as uncontrolled systems may generate recommendations to their users that lead to injury or life-threatening consequences. However, the degree of explicitness of a generated statement that can cause physical harm varies. In this paper, we distinguish types of text that can lead to physical harm and establish one particularly underexplored category: covertly unsafe text. Then, we further break down this category with respect to the system's information and discuss solutions to mitigate the generation of text in each of these subcategories. Ultimately, our work defines the problem of covertly unsafe language that causes physical harm and argues that this subtle yet dangerous issue needs to be prioritized by stakeholders and regulators. We highlight mitigation strategies to inspire future researchers to tackle this challenging problem and help improve safety within smart systems.
    
[^34]: 基于平面性与投影性定义下树的最大线性排列问题（arXiv:2206.06924v3[cs.DS] 更新版）

    The Maximum Linear Arrangement Problem for trees under projectivity and planarity. (arXiv:2206.06924v3 [cs.DS] UPDATED)

    [http://arxiv.org/abs/2206.06924](http://arxiv.org/abs/2206.06924)

    该论文提出了一种解决在平面性和投影性定义下树的最大线性排列问题的算法，证明了最大投影和平面排列的多个性质，发现毛毛虫树最优，推广了之前的极值结果。

    

    最大线性排列问题(MaxLA)是指找到从图G的n个顶点到不同连续整数的映射$ \pi $，使得$ D(G)=\sum_{uv\in E(G)}|\pi(u)-\pi(v)| $最大化。在这种情况下，顶点被认为在一条水平线上，并且边是作为半圆弧画在线上方的。存在一些限制排列的MaxLA变体。在平面变体中，禁止边交叉。在针对根树的投影变体中，排列是平面的，而根不能被任何边覆盖。在这里，我们提出了用于解决树的平面和投影MaxLA的O(n)-时间和O(n）-空间算法。我们还证明了最大投影和平面排列的多个性质，并且表明毛毛虫树在固定大小的所有树中最大化平面MaxLA，因此推广了先前关于树的极值结果。

    The Maximum Linear Arrangement problem (MaxLA) consists of finding a mapping $\pi$ from the $n$ vertices of a graph $G$ to distinct consecutive integers that maximizes $D(G)=\sum_{uv\in E(G)}|\pi(u) - \pi(v)|$. In this setting, vertices are considered to lie on a horizontal line and edges are drawn as semicircles above the line. There exist variants of MaxLA in which the arrangements are constrained. In the planar variant, edge crossings are forbidden. In the projective variant for rooted trees, arrangements are planar and the root cannot be covered by any edge. Here we present $O(n)$-time and $O(n)$-space algorithms that solve planar and projective MaxLA for trees. We also prove several properties of maximum projective and planar arrangements, and show that caterpillar trees maximize planar MaxLA over all trees of a fixed size thereby generalizing a previous extremal result on trees.
    
[^35]: 一种基于对比学习的手语翻译框架

    A Token-level Contrastive Framework for Sign Language Translation. (arXiv:2204.04916v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2204.04916](http://arxiv.org/abs/2204.04916)

    提出了一种基于对比学习的手语翻译框架ConSLT，通过将标记级对比学习纳入SLT解码过程中，学习有效的标记表示，以缓解公开可用的手语翻译语料库非常有限的问题。

    Proposed a token-level contrastive framework for sign language translation, ConSLT, which incorporates token-level contrastive learning into the SLT decoding process to learn effective token representations and alleviate the issue of limited publicly available SLT corpus.

    手语翻译是一项有前途的技术，可以弥合聋人和听力人之间的沟通隔阂。最近，研究人员采用了神经机器翻译（NMT）方法来实现手语翻译，但公开可用的手语翻译语料库非常有限，这导致了标记表示的崩溃和生成标记的不准确性。为了缓解这个问题，我们提出了ConSLT，一种新颖的基于对比学习的手语翻译框架，通过将标记级对比学习纳入SLT解码过程中，学习有效的标记表示。具体而言，ConSLT在解码过程中将每个标记及其由不同丢失掩码生成的对应标记视为正对，然后随机从当前句子中不在词汇表中的$K$个标记中抽样构建负例。我们进行了全面的实验来验证ConSLT的有效性。

    Sign Language Translation (SLT) is a promising technology to bridge the communication gap between the deaf and the hearing people. Recently, researchers have adopted Neural Machine Translation (NMT) methods, which usually require large-scale corpus for training, to achieve SLT. However, the publicly available SLT corpus is very limited, which causes the collapse of the token representations and the inaccuracy of the generated tokens. To alleviate this issue, we propose ConSLT, a novel token-level \textbf{Con}trastive learning framework for \textbf{S}ign \textbf{L}anguage \textbf{T}ranslation , which learns effective token representations by incorporating token-level contrastive learning into the SLT decoding process. Concretely, ConSLT treats each token and its counterpart generated by different dropout masks as positive pairs during decoding, and then randomly samples $K$ tokens in the vocabulary that are not in the current sentence to construct negative examples. We conduct comprehen
    
[^36]: 预训练的token-replaced检测模型作为少样本学习器

    Pre-trained Token-replaced Detection Model as Few-shot Learner. (arXiv:2203.03235v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.03235](http://arxiv.org/abs/2203.03235)

    本文提出了一种使用预训练的token-replaced检测模型的少样本学习器方法，将任务重新定义为token-replaced检测问题，能够优于使用预训练的遮蔽语言模型的少样本学习器。

    

    预训练的遮蔽语言模型已经展示出在少样本学习方面具有非凡的能力。本文提出了一种新的方法，使用预训练的token-replaced检测模型（比如ELECTRA）作为少样本学习器。该方法将分类或回归任务重新定义为token-replaced检测问题。具体来说，我们首先为每个任务定义一个模板和标签描述词，并将它们放入输入中形成一个自然语言提示。然后，我们使用预训练的token-replaced检测模型来预测哪个标签描述词在提示中是最原始的（即最少更改的）。对16个数据集的系统评估表明，我们的方法在一句话和两句话的学习任务中，都优于使用预训练的遮蔽语言模型的少样本学习器。

    Pre-trained masked language models have demonstrated remarkable ability as few-shot learners. In this paper, as an alternative, we propose a novel approach to few-shot learning with pre-trained token-replaced detection models like ELECTRA. In this approach, we reformulate a classification or a regression task as a token-replaced detection problem. Specifically, we first define a template and label description words for each task and put them into the input to form a natural language prompt. Then, we employ the pre-trained token-replaced detection model to predict which label description word is the most original (i.e., least replaced) among all label description words in the prompt. A systematic evaluation on 16 datasets demonstrates that our approach outperforms few-shot learners with pre-trained masked language models in both one-sentence and two-sentence learning tasks.
    
[^37]: DeBERTaV3：使用梯度去耦合嵌入共享的ELECTRA风格预训练来改进DeBERTa模型

    DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing. (arXiv:2111.09543v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2111.09543](http://arxiv.org/abs/2111.09543)

    本论文介绍了一种新的预训练语言模型DeBERTaV3，使用更加样本有效的替换令牌检测（RTD）取代了掩码语言建模（MLM）并提出了一种新的梯度去耦合嵌入共享方法，避免了“拔河”动态，提高了预训练模型的训练效率和质量。在多个下游自然语言理解任务中，DeBERTaV3表现出优秀的性能。

    

    本文介绍了一种新的预训练语言模型DeBERTaV3，它通过将掩码语言建模（MLM）替换为更加样本有效的替换令牌检测（RTD）来改进原始的DeBERTa模型。我们的分析表明，ELECTRA中的香草嵌入共享会影响训练效率和模型性能，因为判别器和生成器的训练损失将令牌嵌入拉向不同的方向，会造成“拔河”动态。因此，我们提出了一种新的梯度去耦合嵌入共享方法，避免了“拔河”动态，提高了预训练模型的训练效率和质量。我们使用与DeBERTa相同的设置预训练了DeBERTaV3，以展示其在各种下游自然语言理解（NLU）任务中的优秀性能。以八项任务为例的GLUE基准测试中，DeBERTaV3 Large模型平均得分为91.37％，比D高1.37％。

    This paper presents a new pre-trained language model, DeBERTaV3, which improves the original DeBERTa model by replacing mask language modeling (MLM) with replaced token detection (RTD), a more sample-efficient pre-training task. Our analysis shows that vanilla embedding sharing in ELECTRA hurts training efficiency and model performance. This is because the training losses of the discriminator and the generator pull token embeddings in different directions, creating the "tug-of-war" dynamics. We thus propose a new gradient-disentangled embedding sharing method that avoids the tug-of-war dynamics, improving both training efficiency and the quality of the pre-trained model. We have pre-trained DeBERTaV3 using the same settings as DeBERTa to demonstrate its exceptional performance on a wide range of downstream natural language understanding (NLU) tasks. Taking the GLUE benchmark with eight tasks as an example, the DeBERTaV3 Large model achieves a 91.37% average score, which is 1.37% over D
    
[^38]: 面对冠状病毒危机，追踪、探索和分析德语在线新闻的最新发展：cOWIDplus分析和cOWIDplus浏览器。

    Tracking, exploring and analyzing recent developments in German-language online press in the face of the coronavirus crisis: cOWIDplus Analysis and cOWIDplus Viewer. (arXiv:2005.13316v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2005.13316](http://arxiv.org/abs/2005.13316)

    该论文提供了三个相互连接的资源，用于捕捉和说明冠状病毒大流行对德语在线新闻的影响：德语新闻源的RSS语料库、一个静态但不断更新的HTML页面和一个Web应用程序。其中，Web应用程序可使其他研究人员和更广泛的公众能够探索这些影响而无需或只需稍有语料库表示和探索或统计分析方面的知识。

    

    冠状病毒大流行可能是自二战以来世界面临的最大危机。不出所料，它也对作为我们主要沟通工具的语言产生了影响。我们提供了三个相互连接的资源，旨在捕捉和说明这些影响对德语的子集造成的影响：德语新闻源的RSS语料库（提供自由可用的未截断的一元频率列表），一个静态但不断更新的HTML页面，用于跟踪所用词汇的多样性，并使其他研究人员和更广泛的公众能够探索这些影响，而无需或只需稍有语料库表示和探索或统计分析方面的知识。

    The coronavirus pandemic may be the largest crisis the world has had to face since World War II. It does not come as a surprise that it is also having an impact on language as our primary communication tool. We present three inter-connected resources that are designed to capture and illustrate these effects on a subset of the German language: An RSS corpus of German-language newsfeeds (with freely available untruncated unigram frequency lists), a static but continuously updated HTML page tracking the diversity of the used vocabulary and a web application that enables other researchers and the broader public to explore these effects without any or with little knowledge of corpus representation/exploration or statistical analyses.
    

