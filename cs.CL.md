# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [MagicLens: Self-Supervised Image Retrieval with Open-Ended Instructions](https://arxiv.org/abs/2403.19651) | 本研究提出了MagicLens，一系列支持开放式指令的自监督图像检索模型，核心创新在于利用文本指令使得图像检索可以检索到比视觉相似性更丰富关系的图像。 |
| [^2] | [Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models](https://arxiv.org/abs/2403.19647) | 该论文介绍了一种新方法，即稀疏特征电路，可以在语言模型中发现和编辑可解释的因果图，为我们提供了对未预料机制的详细理解和包含了用于提高分类器泛化能力的SHIFT方法。 |
| [^3] | [Asymmetric and trial-dependent modeling: the contribution of LIA to SdSV Challenge Task 2](https://arxiv.org/abs/2403.19634) | 该论文描述了对说话人识别领域的贡献，突出展示了对SdSv挑战任务的两个额外挑战：注册和测试数据不匹配以及评估试验数据集子集不匹配的问题。 |
| [^4] | [Retrieval-Enhanced Knowledge Editing for Multi-Hop Question Answering in Language Models](https://arxiv.org/abs/2403.19631) | 提出了用于多跳问题回答的检索增强模型编辑（RAE）框架，利用互信息最大化的检索方法和修剪策略，实现了对语言模型的有效优化。 |
| [^5] | [Semantic Map-based Generation of Navigation Instructions](https://arxiv.org/abs/2403.19603) | 通过使用语义地图作为视觉输入，我们提出了一种新的导航说明生成方法，将问题构建为图像字幕任务，有望降低生成指令的计算复杂性。 |
| [^6] | [Improving Adversarial Data Collection by Supporting Annotators: Lessons from GAHD, a German Hate Speech Dataset](https://arxiv.org/abs/2403.19559) | 通过支持标注者，提出新策略来创建更多样化的对抗性示例，引入GAHD德语对抗性仇恨言论数据集，表明训练模型使用GAHD可以显著提高模型的鲁棒性。 |
| [^7] | [WaterJudge: Quality-Detection Trade-off when Watermarking Large Language Models](https://arxiv.org/abs/2403.19548) | 提出了一个简单的分析框架，利用比较评估和灵活的NLG评估框架来评估特定水印设置对生成文本质量造成的影响。 |
| [^8] | [Interpreting Key Mechanisms of Factual Recall in Transformer-Based Language Models](https://arxiv.org/abs/2403.19521) | 通过深入研究Transformer-based语言模型在事实回忆任务中的机制，我们发现了零/少次样本情况下的特定任务头、MLP层和残差流的功能，以及抗过度自信机制。 |
| [^9] | [Improving Clinical NLP Performance through Language Model-Generated Synthetic Clinical Data](https://arxiv.org/abs/2403.19511) | 通过利用先进语言模型生成的合成数据，本研究探讨了提升临床自然语言处理性能的方法，展示出在高风险领域中可行的应用。 |
| [^10] | [Phonetic Segmentation of the UCLA Phonetics Lab Archive](https://arxiv.org/abs/2403.19509) | VoxAngeles是一个包含UCLA语音实验室档案的语音切分和音素级对齐的语料库，增强了原始数据的可用性，特别适用于定量语音类型学研究。 |
| [^11] | [JDocQA: Japanese Document Question Answering Dataset for Generative Language Models](https://arxiv.org/abs/2403.19454) | JDocQA是一个大规模的基于文档的问答数据集，要求结合视觉和文本信息回答问题，包括5,504个文档和11,600个问答实例。 |
| [^12] | [Mixed Preference Optimization: Reinforcement Learning with Data Selection and Better Reference Model](https://arxiv.org/abs/2403.19443) | 提出了一种混合偏好优化（MPO）方法，通过在简单数据集上训练Direct Preference Optimization（DPO），然后在困难数据集上执行Reinforcement Learning with Human Feedback（RLHF），从而减轻了两种方法的弱点。 |
| [^13] | [Uncovering Misattributed Suicide Causes through Annotation Inconsistency Detection in Death Investigation Notes](https://arxiv.org/abs/2403.19432) | 通过自然语言处理方法检测并纠正国家暴力死亡报告系统中的注释不一致性，提高了自杀危机分类器的性能。 |
| [^14] | [The Role of Syntactic Span Preferences in Post-Hoc Explanation Disagreement](https://arxiv.org/abs/2403.19424) | 此研究从语言学角度研究了不同方法之间的解释不一致，发现在句法跨度水平上比较方法可以平滑掉标记级别的差异，提出了动态估计最重要跨度的方法，改进了选择重要标记的配置。 |
| [^15] | [Echo-chambers and Idea Labs: Communication Styles on Twitter](https://arxiv.org/abs/2403.19423) | 本研究发现了Twitter社区在疫苗接种背景下具有不同沟通风格，除了回音室行为外，还存在着其他独特的社区沟通模式。 |
| [^16] | [BP4ER: Bootstrap Prompting for Explicit Reasoning in Medical Dialogue Generation](https://arxiv.org/abs/2403.19414) | BP4ER提出了一种Bootstrap Prompting方法，通过引导大型语言模型在多步推理中进行显式推理，分解医学对话生成为简单子问题，并引入了两种引导技术。 |
| [^17] | [KazParC: Kazakh Parallel Corpus for Machine Translation](https://arxiv.org/abs/2403.19399) | KazParC是一个跨哈萨克语、英语、俄语和土耳其语的机器翻译平行语料库，其中包含371,902个平行句子，还开发了性能优越的神经机器翻译模型Tilmash。 |
| [^18] | [Checkpoint Merging via Bayesian Optimization in LLM Pretraining](https://arxiv.org/abs/2403.19390) | 通过贝叶斯优化，我们提出了LLM预训练中的检查点合并方法，展现了在最小成本下增强预训练的能力以及在不同领域展示鲁棒泛化能力的特点。 |
| [^19] | [EthioMT: Parallel Corpus for Low-resource Ethiopian Languages](https://arxiv.org/abs/2403.19365) | EthioMT是一个新的平行语料库，为15种低资源埃塞俄比亚语言提供支持，并通过创建基准数据集改进了研究界对埃塞俄比亚语言的研究。 |
| [^20] | [Risk prediction of pathological gambling on social media](https://arxiv.org/abs/2403.19358) | 该论文通过在模型中纳入时间和情绪特征，提出了一种在社交媒体数据上预测Reddit用户患有病态赌博障碍的方法，实验证明顺序模型比连接模型效果更好。 |
| [^21] | [AIpom at SemEval-2024 Task 8: Detecting AI-produced Outputs in M4](https://arxiv.org/abs/2403.19354) | 本研究提出了AIpom系统，通过结合解码器模型和编码器序列标记器的预测，成功在SemEval-2024任务8中的排名第二，并取得了15.94的平均绝对误差，消融研究表明流水线处理编码器和解码器模型有助于提高性能。 |
| [^22] | [A diverse Multilingual News Headlines Dataset from around the World](https://arxiv.org/abs/2403.19352) | Babel Briefings是一个包含全球30种语言和54个地点的470万条新闻标题的数据集，可用于自然语言处理和媒体研究，提供了训练或评估语言模型的高质量数据集，并展示了基于事件相似度度量方法的文章聚类和事件特征可视化。 |
| [^23] | [Large Language Models Are Unconscious of Unreasonability in Math Problems](https://arxiv.org/abs/2403.19346) | 本文研究了大型语言模型在解决数学问题中对不合理性的反应，设计了不合理数学问题基准以及关键计算和结论提示模板，提升了它们在错误检测和修正方面的能力。 |
| [^24] | [Dataverse: Open-Source ETL (Extract, Transform, Load) Pipeline for Large Language Models](https://arxiv.org/abs/2403.19340) | Dataverse是一个面向大型语言模型的开源ETL管道，提供了用户友好的设计和易于定制的处理器添加功能，旨在成为LLM开发的重要工具，并开源整个库以促进社区贡献。 |
| [^25] | [KazSAnDRA: Kazakh Sentiment Analysis Dataset of Reviews and Attitudes](https://arxiv.org/abs/2403.19335) | KazSAnDRA是哈萨克情感分析领域的第一个最大的公开数据集，研究包括开发和评估四个机器学习模型，在极性分类和得分分类上取得了不错的成功结果。 |
| [^26] | [Plug-and-Play Grounding of Reasoning in Multimodal Large Language Models](https://arxiv.org/abs/2403.19322) | 提出了一种用于在多模式大型语言模型中实现即插即用推理基础的新框架P2G，通过利用MLLMs的工具使用潜力和专家代理实现对图像关键视觉和文本对象的即时确定性基础，从而实现有意识的推理。 |
| [^27] | [TableLLM: Enabling Tabular Data Manipulation by LLMs in Real Office Usage Scenarios](https://arxiv.org/abs/2403.19318) | TableLLM是一个拥有130亿参数的强大大语言模型，专门用于熟练处理表格数据操作任务，通过远程监督方法和交叉验证策略，TableLLM相对于其他现有的通用和表格数据专注的LLMs具有明显优势。 |
| [^28] | [Beyond Borders: Investigating Cross-Jurisdiction Transfer in Legal Case Summarization](https://arxiv.org/abs/2403.19317) | 本研究探讨了法律案例摘要模型的跨辖区普适性，调查了如何有效地总结目标司法管辖区的法律案例，并发现预训练在提高转移性能方面起着关键作用。 |
| [^29] | [MATEval: A Multi-Agent Discussion Framework for Advancing Open-Ended Text Evaluation](https://arxiv.org/abs/2403.19305) | 提出了MATEval框架，利用多个类GPT-4的LLMs作为评估Agent，模拟人类合作讨论方法，以评估开放性文本，结合自我反思和思维链策略，并加入反馈机制，提升评估深度和广度。 |
| [^30] | [Going Beyond Word Matching: Syntax Improves In-context Example Selection for Machine Translation](https://arxiv.org/abs/2403.19285) | 本文提出了一种基于句法的机器翻译上下文例句选择方法，通过计算依存树之间的句法相似性，结合词级和句法水平标准选择例句，实验结果表明语法可以有效提升机器翻译上下文学习质量。 |
| [^31] | [Ungrammatical-syntax-based In-context Example Selection for Grammatical Error Correction](https://arxiv.org/abs/2403.19283) | 在本文中，我们提出了一种基于不合语法句法的上下文示例选择策略，用于在语法错误校正中提高性能，并在基准英语GEC数据集上取得了比常用方法更好的表现。 |
| [^32] | [Fine-Tuning Language Models with Reward Learning on Policy](https://arxiv.org/abs/2403.19279) | 提出了在策略上的奖励学习框架，使用策略样本优化奖励模型以保持其分布上的一致性 |
| [^33] | [Knowledge Boundary and Persona Dynamic Shape A Better Social Media Agent](https://arxiv.org/abs/2403.19275) | 通过个性化知识和动态角色信息构建社交媒体代理以解决代理拥有不属于其角色的知识和无法消除多样化角色信息干扰的问题。 |
| [^34] | [sDPO: Don't Use Your Data All at Once](https://arxiv.org/abs/2403.19270) | sDPO是对直接偏好优化方法的扩展，通过分步利用偏好数据集而非一次性使用，促进更精确对齐参考模型的使用，并训练出性能更优的最终模型，甚至胜过其他具有更多参数的流行大型语言模型。 |
| [^35] | [MineLand: Simulating Large-Scale Multi-Agent Interactions with Limited Multimodal Senses and Physical Needs](https://arxiv.org/abs/2403.19267) | MineLand模拟器引入有限多模感知和生理需求，支持多智能体在协作中填补了信息和功能限制的空白，从而促进更具动态和有效性的多智能体交互。 |
| [^36] | [NaijaHate: Evaluating Hate Speech Detection on Nigerian Twitter Using Representative Data](https://arxiv.org/abs/2403.19260) | 首次引入 NaijaHate 数据集，在尼日利亚推特上评估 HSD，发现在代表性数据上评估的 HSD 性能高估了真实世界的表现，提出 NaijaXLM-T 模型，突出了域自适应预训练和微调在最大化 HSD 性能中的关键作用 |
| [^37] | [J-CRe3: A Japanese Conversation Dataset for Real-world Reference Resolution](https://arxiv.org/abs/2403.19259) | 我们提出了一个多模式参考解析任务，并构建了日本对话数据集J-CRe3，用于现实世界参考解析，其中包含了自我中心视频和对话音频，以及短语和视频帧中物体边界框之间的跨模态标记。 |
| [^38] | [Collaborative Knowledge Infusion for Low-resource Stance Detection](https://arxiv.org/abs/2403.19219) | 提出了一种用于低资源立场检测任务的协作知识融入方法，增强了对目标背景知识的利用，并采用高效参数学习技术。 |
| [^39] | [Dual-Personalizing Adapter for Federated Foundation Models](https://arxiv.org/abs/2403.19211) | 提出了一种新的设置，称为测试时间个性化，不仅关注目标本地任务，还延伸到其他展示测试时间个性化的任务 |
| [^40] | [Understanding Archives: Towards New Research Interfaces Relying on the Semantic Annotation of Documents](https://arxiv.org/abs/2403.19201) | 通过语义标注档案文件的文本内容，我们提出了构建新界面的方法论框架，解决了探索和利用文档的困难，以及应对当前技术障碍的潜在解决方案。 |
| [^41] | [Empirical Analysis for Unsupervised Universal Dependency Parse Tree Aggregation](https://arxiv.org/abs/2403.19183) | 通过广泛的实证研究比较不同的无监督后处理聚合方法，以确定最适合的依存树结构聚合方法 |
| [^42] | [Make Large Language Model a Better Ranker](https://arxiv.org/abs/2403.19181) | 本文介绍了一种具有对齐列表排名目标的语言模型框架（ALRO），旨在弥合大型语言模型的能力与推荐系统排名任务的要求之间的差距。 |
| [^43] | [Mitigating Misleading Chain-of-Thought Reasoning with Selective Filtering](https://arxiv.org/abs/2403.19167) | 提出了一种名为选择性过滤推理器（SelF-Reasoner）的新方法，用于评估问题与候选推理链之间的蕴涵关系，以减轻具有误导性的思维链推理过程。 |
| [^44] | [Improving Vietnamese-English Medical Machine Translation](https://arxiv.org/abs/2403.19161) | 介绍了MedEV数据集，通过对比不同的翻译模型在医学领域进行越南语-英语机器翻译，结果显示微调"vinai-translate"获得最佳性能，同时公开数据集促进进一步研究。 |
| [^45] | [Disentangling Length from Quality in Direct Preference Optimization](https://arxiv.org/abs/2403.19159) | 针对直接偏好优化中的长度问题展开研究，揭示了DPO中显著的利用情况，并将其与分布外引导联系起来。 |
| [^46] | [STaR-GATE: Teaching Language Models to Ask Clarifying Questions](https://arxiv.org/abs/2403.19154) | 通过奖励语言模型生成有用问题来自我改进的方法，提问者通过询问角色扮演者来引出偏好，从而迭代微调以增加任务高质量响应的概率。 |
| [^47] | [A Tulu Resource for Machine Translation](https://arxiv.org/abs/2403.19142) | 迁移学习方法使得即使源语言和目标语言之间没有平行数据，也能训练出一个机器翻译系统，从而克服了低资源语言机器翻译开发中的一个重大障碍。 |
| [^48] | [Compressing Large Language Models by Streamlining the Unimportant Layer](https://arxiv.org/abs/2403.19135) | 通过观察大型语言模型中不同层对隐藏状态的影响程度，提出了LLM-Streamline方法，包括层剪枝和层替换，用于压缩模型并保持性能。 |
| [^49] | [Code Comparison Tuning for Code Large Language Models](https://arxiv.org/abs/2403.19121) | 提出了一种简单有效的代码比较调优方法，用于改进代码大型语言模型的bug-fixing能力。 |
| [^50] | [MFORT-QA: Multi-hop Few-shot Open Rich Table Question Answering](https://arxiv.org/abs/2403.19116) | 本文介绍了MFORT-QA方法，通过Few-Shot Learning和大语言模型，实现了在表格数据中进行多跳少样本的开放式丰富问答。 |
| [^51] | [Top Leaderboard Ranking = Top Coding Proficiency, Always? EvoEval: Evolving Coding Benchmarks via LLM](https://arxiv.org/abs/2403.19114) | EvoEval通过将现有基准演化为不同的目标领域，创建了一个新的程序合成基准套件，以充分评估LLM编码能力。 |
| [^52] | [FACTOID: FACtual enTailment fOr hallucInation Detection](https://arxiv.org/abs/2403.19113) | 本文表明传统的文本蕴涵方法无法有效地发现大型语言模型生成的内容中存在的幻觉问题。 |
| [^53] | [Automated Black-box Prompt Engineering for Personalized Text-to-Image Generation](https://arxiv.org/abs/2403.19103) | PRISM是一种算法，可以自动识别人类可解释且易传递的提示，从而有效生成所需概念，仅使用黑盒访问T2I模型。 |
| [^54] | [Learning From Correctness Without Prompting Makes LLM Efficient Reasoner](https://arxiv.org/abs/2403.19094) | 本文介绍了一种用于大型语言模型的内在自我修正推理框架LeCo，无需人类反馈、外部工具或手动提示，通过学习正确的推理步骤并基于生成logits来提高推理性能。 |
| [^55] | [CAUSE: Counterfactual Assessment of User Satisfaction Estimation in Task-Oriented Dialogue Systems](https://arxiv.org/abs/2403.19056) | 本文通过利用大型语言模型生成满意感知的反事实对话来增加任务型对话系统的原始对话集合，以改善用户满意度估计的鲁棒性。 |
| [^56] | [Evaluating Large Language Models for Health-Related Text Classification Tasks with Public Social Media Data](https://arxiv.org/abs/2403.19031) | 综合实验表明，利用LLMs进行数据增强可以... |
| [^57] | [Towards LLM-RecSys Alignment with Textual ID Learning](https://arxiv.org/abs/2403.19021) | 通过提出IDGen，将每个推荐项目表示为独特、简洁、语义丰富的文本ID，从而使得基于大型语言模型的推荐更好地与自然语言生成对齐。 |
| [^58] | [ReflectSumm: A Benchmark for Course Reflection Summarization](https://arxiv.org/abs/2403.19012) | ReflectSumm是一个旨在总结学生反思性写作的数据集，可以帮助开发和评估针对现实场景的新型摘要技术，为进一步研究提供了基准。 |
| [^59] | ["Sorry, Come Again?" Prompting -- Enhancing Comprehension and Diminishing Hallucination with [PAUSE]-injected Optimal Paraphrasing](https://arxiv.org/abs/2403.18976) | 介绍了一种新的提示策略“Sorry, Come Again (SCA)”来避免大规模语言模型（LLMs）产生幻觉，通过进行最佳的改写和注入[PAUSE]标记来增强理解力。 |
| [^60] | [A Novel Corpus of Annotated Medical Imaging Reports and Information Extraction Results Using BERT-based Language Models](https://arxiv.org/abs/2403.18975) | 介绍了一个新的医学影像报告语料库，使用基于BERT的语言模型对报告进行标注，并通过事件化模式捕捉临床指示、病变和医学问题。 |
| [^61] | [Conformal Intent Classification and Clarification for Fast and Accurate Intent Recognition](https://arxiv.org/abs/2403.18973) | 提出了一种拟合意图分类和澄清框架，能够将意图分类器的不确定性分数转化为澄清问题，快速准确地解决用户查询，并具有超出范围检测能力。 |
| [^62] | [A Survey on Large Language Models from Concept to Implementation](https://arxiv.org/abs/2403.18969) | Transformer模型在改革传统任务和推进跨行业研究和开发中产生革命性影响。 |
| [^63] | [Moderating Illicit Online Image Promotion for Unsafe User-Generated Content Games Using Large Vision-Language Models](https://arxiv.org/abs/2403.18957) | 该研究旨在调查不安全用户生成内容游戏中的违法推广威胁，收集了一组包含性暴力和暴力内容的真实图像数据集。 |
| [^64] | [Reshaping Free-Text Radiology Notes Into Structured Reports With Generative Transformers](https://arxiv.org/abs/2403.18938) | 提出了一个从自由文本放射学报告中提取信息的流程，利用自然语言处理（NLP）和基于Transformer的模型来处理自动的SR注册表填写。 |
| [^65] | [SemEval Task 1: Semantic Textual Relatedness for African and Asian Languages](https://arxiv.org/abs/2403.18933) | 这个任务涉及14种非洲和亚洲语言的语义文本相关性，旨在考察跨语言的语义相关性现象。 |
| [^66] | [Measuring Political Bias in Large Language Models: What Is Said and How It Is Said](https://arxiv.org/abs/2403.18932) | 提出通过分析大型语言模型生成的政治议题内容和风格来测量其政治偏见，主张应该有由大型语言模型生成的政治偏见的细粒度和可解释性衡量。 |
| [^67] | [Enhancing Efficiency in Sparse Models with Sparser Selection](https://arxiv.org/abs/2403.18926) | 提出了一种新颖的MoE模型\tool，通过利用小型专家和基于阈值的路由器，使标记能够选择性地仅涉及到必要的参数，从而在减少MoE层计算负载50%以上的同时提高模型性能。 |
| [^68] | [Targeted Visualization of the Backbone of Encoder LLMs](https://arxiv.org/abs/2403.18872) | 本文研究了将DeepView方法应用于自然语言处理领域，以减少编码器模型存在的风险并解释模型决策过程。 |
| [^69] | [JEP-KD: Joint-Embedding Predictive Architecture Based Knowledge Distillation for Visual Speech Recognition](https://arxiv.org/abs/2403.18843) | 该论文提出了一种基于联合嵌入预测架构的知识蒸馏方法JEP-KD，旨在通过引入生成网络在嵌入层内增强视频编码器的语义特征提取能力，从而更有效地利用音频特征，逐步减少视觉语音识别与自动语音识别之间的性能差距。 |
| [^70] | [Quantifying and Mitigating Unimodal Biases in Multimodal Large Language Models: A Causal Perspective](https://arxiv.org/abs/2403.18346) | 提出了一个因果框架用于解释多模态大型语言模型在视觉问答问题中的偏差，并引入了一个新的挑战性数据集MORE，同时提出两种减轻单模态偏差的策略。 |
| [^71] | [Chinese Offensive Language Detection:Current Status and Future Directions](https://arxiv.org/abs/2403.18314) | 总体而言，这篇论文讨论了在中文中检测 offensive 语言的挑战，并强调了开发解决这一问题的特定模型和工具。 |
| [^72] | [Oh! We Freeze: Improving Quantized Knowledge Distillation via Signal Propagation Analysis for Large Language Models](https://arxiv.org/abs/2403.18159) | 通过信号传播分析，提出了一种改进大型语言模型的量化知识蒸馏方法，并提供了ov-freeze稳定KD-QAT过程的洞察。 |
| [^73] | [Improving Pre-trained Language Model Sensitivity via Mask Specific losses: A case study on Biomedical NER](https://arxiv.org/abs/2403.18025) | 提出了Mask Specific Language Modeling（MSLM）方法来改善LM在微调过程中对目标领域知识的敏感性，通过加权领域特定术语的重要性进行学习。 |
| [^74] | [DORE: A Dataset For Portuguese Definition Generation](https://arxiv.org/abs/2403.18018) | DORE是第一个用于葡萄牙语的定义生成数据集，填补了这一领域的空白，包含超过10万个定义，并评估了多种基于深度学习的模型。 |
| [^75] | [LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning](https://arxiv.org/abs/2403.17919) | 逐层重要性采样的新方法LISA在微调任务中表现出色，记忆成本低且优于传统方法。 |
| [^76] | [Can multiple-choice questions really be useful in detecting the abilities of LLMs?](https://arxiv.org/abs/2403.17752) | 多项选择题虽然被广泛用于评估大型语言模型，但在测试LLMs能力时存在一定局限性，特别是在需要长篇生成答案的情况下，我们发现LLMs在双语MCQs中表现出顺序敏感性。 |
| [^77] | [DANCER: Entity Description Augmented Named Entity Corrector for Automatic Speech Recognition](https://arxiv.org/abs/2403.17645) | DANCER提出了一种新颖的Description Augmented Named entity CorrEctoR（DANCER）模型，通过利用实体描述为自动语音识别中的NEC提供额外信息，帮助缓解NE列表中的音素混淆问题。 |
| [^78] | [Synthesize Step-by-Step: Tools, Templates and LLMs as Data Generators for Reasoning-Based Chart VQA](https://arxiv.org/abs/2403.16385) | 使用LLM作为数据生成器，通过逐步合成策略将复杂问题分解为逐步子问题，利用外部工具生成最终答案，以解决图表VQA模型在复杂推理问题上的表现不佳。 |
| [^79] | [WoLF: Large Language Model Framework for CXR Understanding](https://arxiv.org/abs/2403.15456) | WoLF框架提出了对于CXR的全面理解的改进，包括使用额外的健康相关数据、重构报告以提供更有组织的信息、以及改进生成答案的细致评估。 |
| [^80] | [Imagination Augmented Generation: Learning to Imagine Richer Context for Question Answering over Large Language Models](https://arxiv.org/abs/2403.15268) | 提出了一种新颖的知识增强框架，即想象增强生成（IAG），通过想象力，而非依赖外部资源，来补充大型语言模型中可能存在的知识缺陷，并提出了一种想象更丰富背景的方法（IMcQA）来解决问题回答中的挑战。 |
| [^81] | [Detoxifying Large Language Models via Knowledge Editing](https://arxiv.org/abs/2403.14472) | 本文研究了使用知识编辑技术对大型语言模型进行去毒化，在构建了SafeEdit基准的基础上，提出了一种简单而有效的方法 DINM，可以通过少量调整步骤减少模型的毒性，同时对各种去毒方法的内部机制进行了深入分析。 |
| [^82] | [Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity](https://arxiv.org/abs/2403.14403) | 通过新颖的自适应QA框架，根据查询的复杂度动态选择适合的检索增强大型语言模型策略，提高了回答准确性。 |
| [^83] | [When SMILES have Language: Drug Classification using Text Classification Methods on Drug SMILES Strings](https://arxiv.org/abs/2403.12984) | 将药物SMILES字符串视为句子并利用文本分类方法进行药物分类，证实了通过简单的自然语言处理方法解决复杂问题的可能性 |
| [^84] | [Towards Unified Multi-Modal Personalization: Large Vision-Language Models for Generative Recommendation and Beyond](https://arxiv.org/abs/2403.10667) | 本文旨在建立一个统一的多模态个性化系统(UniMP)，有效利用多模态数据同时消除与任务和模态特定定制相关的复杂性。 |
| [^85] | [FluoroSAM: A Language-aligned Foundation Model for X-ray Image Segmentation](https://arxiv.org/abs/2403.08059) | FluoroSAM是用于X光图像的分割的语言对齐基础模型，提供了一种在X光成像领域具有广泛适用性的自动图像分析工具。 |
| [^86] | [Can Small Language Models be Good Reasoners for Sequential Recommendation?](https://arxiv.org/abs/2403.04260) | 提出了逐步知识提取框架（SLIM），为顺序推荐系统解决了大型语言模型（LLMs）高资源需求的难题，使其能以资源高效的方式享受LLMs的出色推理能力。 |
| [^87] | [OffLanDat: A Community Based Implicit Offensive Language Dataset Generated by Large Language Model Through Prompt Engineering](https://arxiv.org/abs/2403.02472) | 介绍了一个通过提示工程生成的大型语言模型创建的社区基础隐式攻击性语言数据集OffLanDat，为38个不同目标群体提供数据。 |
| [^88] | [Retrieval Helps or Hurts? A Deeper Dive into the Efficacy of Retrieval Augmentation to Language Models](https://arxiv.org/abs/2402.13492) | 该研究深入探讨了如何通过检索增强语言模型，构建了新的QA数据集WiTQA，以实体和关系组合的影响为重点进行了详细分析。 |
| [^89] | [HU at SemEval-2024 Task 8A: Can Contrastive Learning Learn Embeddings to Detect Machine-Generated Text?](https://arxiv.org/abs/2402.11815) | 提出了一种基于对比学习的单一模型，用较少的参数实现与基线相当的机器生成文本检测性能 |
| [^90] | [Syntactic Language Change in English and German: Metrics, Parsers, and Convergences](https://arxiv.org/abs/2402.11549) | 本文研究英语和德语句法语言变化趋势，使用议会辩论语料库，探讨了句法依存距离最小化及基于树图属性的15个度量标准，揭示了现代解析器在这种变化中的影响。 |
| [^91] | [LLMs and the Human Condition](https://arxiv.org/abs/2402.08403) | 本文提出了将三个成熟的人类决策理论整合到一起，形成了一个目的性人类行动模型。同时，将语言作为行动的观点应用于对话用户界面。通过理解ChatGPT的智能来源，可以在减少资源的同时获得对我们之间关系的认识。 |
| [^92] | [Re-Envisioning Command and Control](https://arxiv.org/abs/2402.07946) | 重新构想的论文提出了未来指挥与控制（C2）决策需要面对更复杂和挑战性的环境，因此提出了基于人工智能系统与人类强有力伙伴关系的未来C2的愿景。这个愿景的核心是优化C2操作流程，保持协同努力，发展自适应的集体知识系统。 |
| [^93] | [Scalable Interactive Machine Learning for Future Command and Control](https://arxiv.org/abs/2402.06501) | 未来战争将需要指挥与控制（C2）人员在复杂且潜在模糊的情况下以更短的时间内做出决策。本论文通过利用互动式机器学习方法，结合人工智能和人类智能，以提高C2运作的适应性和效率。 |
| [^94] | [COA-GPT: Generative Pre-trained Transformers for Accelerated Course of Action Development in Military Operations](https://arxiv.org/abs/2402.01786) | COA-GPT是一种利用大型语言模型快速高效生成有效行动方案的算法，它融合了军事学说和领域专业知识，并在军事游戏中的实验中展示了其快速生成战略合理COAs的优势。 |
| [^95] | [Promptly Predicting Structures: The Return of Inference](https://arxiv.org/abs/2401.06877) | 本文提出了一个框架，通过使用结构约束和由此衍生的组合推理，可以过滤大型语言模型预测的不一致结构，从而构建有效的结构化输出，并提高性能。 |
| [^96] | [TimeChat: A Time-sensitive Multimodal Large Language Model for Long Video Understanding](https://arxiv.org/abs/2312.02051) | TimeChat是一种时间敏感的多模态大型语言模型，包含时间戳感知帧编码器和滑动视频Q-Former，以实现对长视频进行强大的零-shot时间本地化和推理能力。实验结果表明，在各种视频理解任务上表现出色。 |
| [^97] | [EgoThink: Evaluating First-Person Perspective Thinking Capability of Vision-Language Models](https://arxiv.org/abs/2311.15596) | EgoThink是一个新颖的视觉问答基准，旨在评估视觉语言模型从第一人称视角“思考”的能力。 |
| [^98] | [Prompt Risk Control: A Rigorous Framework for Responsible Deployment of Large Language Models](https://arxiv.org/abs/2311.13628) | 提示风险控制是一个轻量级框架，通过严格的信息风险度量族的上限选取提示，帮助减轻大型语言模型负责部署过程中产生意外糟糕响应的风险。 |
| [^99] | [MacGyver: Are Large Language Models Creative Problem Solvers?](https://arxiv.org/abs/2311.09682) | 通过创建MACGYVER数据集并与人类比较，研究发现大型语言模型在创意问题解决方面独具挑战性，在知识广度和可行性方面与人类存在独特差异，同时还展示了通过新的提示技术提升大型语言模型的问题解决能力潜力。 |
| [^100] | [Leveraging Code to Improve In-context Learning for Semantic Parsing](https://arxiv.org/abs/2311.09519) | 通过使用通用编程语言代替领域特定语言（DSLs）和增加结构化领域描述提示，本研究显著改善了语境学习（ICL）对语义解析的有效性，提高了准确性并减少了对大量示范的需求。 |
| [^101] | [Investigating the Emergent Audio Classification Ability of ASR Foundation Models](https://arxiv.org/abs/2311.09363) | ASR基础模型Whisper和MMS在不经过额外数据训练或添加新参数的情况下，展现了有希望的零-shot音频分类性能。 |
| [^102] | [LLMRefine: Pinpointing and Refining Large Language Models via Fine-Grained Actionable Feedback](https://arxiv.org/abs/2311.09336) | LLMRefine提出了一种细粒度反馈模型来指导大型语言模型定位缺陷并进行优化，在机器翻译、长篇问答和主题总结等任务中取得显著的改进。 |
| [^103] | [MILL: Mutual Verification with Large Language Models for Zero-Shot Query Expansion](https://arxiv.org/abs/2310.19056) | 该论文提出了一种利用大型语言模型进行相互验证的零-shot查询扩展框架，有效解决了查询扩展中已有方法的限制和缺陷。 |
| [^104] | [Prompt Space Optimizing Few-shot Reasoning Success with Large Language Models](https://arxiv.org/abs/2306.03799) | 提示工程是增强大语言模型能力的必要技术，我们提出了Prompt Space方法，通过文本嵌入和矩阵分解构建提示空间来解决当前方法缺乏确定最佳提示的问题，并取得显著优越表现。 |
| [^105] | [A Corpus for Sentence-level Subjectivity Detection on English News Articles](https://arxiv.org/abs/2305.18034) | 该研究开发了新的标注指南，建立了用于英语新闻文章句子级主观性检测的语料库，并表明多语境训练的模型在该任务上取得了最佳性能。 |
| [^106] | [PrOnto: Language Model Evaluations for 859 Languages](https://arxiv.org/abs/2305.12612) | 本研究提出了一种新的评估数据集构建方法，可以为任何具有新约翻译的语言提供预训练语言模型评估的评估数据集，无需手动标注，通过将语句与英文OntoNotes中的语句对齐并投影标注到目标语言。这项工作使得在859种语言中进行语言模型评估成为可能。 |
| [^107] | [Evaluating Step-by-Step Reasoning through Symbolic Verification](https://arxiv.org/abs/2212.08686) | 文中研究了预训练语言模型（LMs）通过解释或思维链（CoT）进行推理，在推理机制上提出了一种神经符号方法，通过学习逻辑规则和示例进行迭代推理，支持LMs输出自动验证 |
| [^108] | [SOLD: Sinhala Offensive Language Dataset](https://arxiv.org/abs/2212.00851) | 本文介绍了一种新的低资源语言——僧伽罗语攻击性语言识别数据集(SOLD)，填补了目前攻击性语言识别研究局限于高资源语言的空白。 |
| [^109] | [Incremental Processing in the Age of Non-Incremental Encoders: An Empirical Assessment of Bidirectional Models for Incremental NLU](https://arxiv.org/abs/2010.05330) | 双向模型在增量界面下的表现得到了支持，而全向BERT模型在增量访问方面受到较大影响，可通过调整训练机制缓解。 |
| [^110] | [A Comprehensive Study of Knowledge Editing for Large Language Models.](http://arxiv.org/abs/2401.01286) | 本研究全面研究了大型语言模型的知识编辑，旨在有效修改模型的行为，同时保持整体性能。 |
| [^111] | [A Study on the Calibration of In-context Learning.](http://arxiv.org/abs/2312.04021) | 本研究关注上下文学习（ICL），通过定制提示来调整静态语言模型（LMs），研究了在各种自然语言理解和推理任务中性能和校准之间的平衡。研究发现随着ICL示例数量的增加，模型的校准会先增加而后得到改善，而校准误差主要出现在低样本场景下。此外，微调和CoT提示等方法可能导致校准误差和不可靠的自然语言解释，提示需要针对可靠性场景开发新的方法。 |
| [^112] | [Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting.](http://arxiv.org/abs/2306.17563) | 本论文提出了一种名为PRP的新技术，通过使用两两排名提示来显著减轻大型语言模型（LLM）的负担，并首次在标准基准测试中实现了最先进的排名性能。 |
| [^113] | [Self-Prompting Large Language Models for Zero-Shot Open-Domain QA.](http://arxiv.org/abs/2212.08635) | 本论文提出了一种自我提示框架，可以有效利用大型语言模型的参数中存储的知识和指令理解能力，以实现零样本开放域问答，并且实验证明该方法在三个广泛使用的ODQA数据集中显著优于现有的最先进方法。 |

# 详细

[^1]: MagicLens：自监督图像检索与开放式指令

    MagicLens: Self-Supervised Image Retrieval with Open-Ended Instructions

    [https://arxiv.org/abs/2403.19651](https://arxiv.org/abs/2403.19651)

    本研究提出了MagicLens，一系列支持开放式指令的自监督图像检索模型，核心创新在于利用文本指令使得图像检索可以检索到比视觉相似性更丰富关系的图像。

    

    图像检索，即根据参考图像查找所需图像，固有地包含难以仅使用基于图像的度量捕捉到的丰富、多方面的搜索意图。最近的工作利用文本指令允许用户更自由地表达他们的搜索意图。然而，现有工作主要集中在那些视觉上相似和/或可以用一小组预定义关系来表征的图像对上。本文的核心论点是文本指令可以使图像检索能够检索到比视觉相似性更丰富关系的图像。为了证明这一点，我们引入了MagicLens，一系列支持开放式指令的自监督图像检索模型。MagicLens建立在一个重要的新颖见解上：自然发生在同一网页上的图像对包含着大量隐式关系（例如，内部视图），我们可以通过综合指令将这些隐式关系变为显式。

    arXiv:2403.19651v1 Announce Type: cross  Abstract: Image retrieval, i.e., finding desired images given a reference image, inherently encompasses rich, multi-faceted search intents that are difficult to capture solely using image-based measures. Recent work leverages text instructions to allow users to more freely express their search intents. However, existing work primarily focuses on image pairs that are visually similar and/or can be characterized by a small set of pre-defined relations. The core thesis of this paper is that text instructions can enable retrieving images with richer relations beyond visual similarity. To show this, we introduce MagicLens, a series of self-supervised image retrieval models that support open-ended instructions. MagicLens is built on a key novel insight: image pairs that naturally occur on the same web pages contain a wide range of implicit relations (e.g., inside view of), and we can bring those implicit relations explicit by synthesizing instructions
    
[^2]: 稀疏特征电路：在语言模型中发现和编辑可解释的因果图

    Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models

    [https://arxiv.org/abs/2403.19647](https://arxiv.org/abs/2403.19647)

    该论文介绍了一种新方法，即稀疏特征电路，可以在语言模型中发现和编辑可解释的因果图，为我们提供了对未预料机制的详细理解和包含了用于提高分类器泛化能力的SHIFT方法。

    

    我们介绍了用于发现和应用稀疏特征电路的方法。这些电路是人类可解释特征的因果相关子网络，用于解释语言模型行为。 在先前的工作中确定的电路由多义且难以解释的单元组成，例如注意力头或神经元，使它们不适用于许多下游应用。 相比之下，稀疏特征电路实现了对未预料机制的详细理解。 由于它们基于细粒度单元，稀疏特征电路对下游任务非常有用：我们 introduc了SHIFT，通过切除人类判断为任务不相关的特征，从而提高分类器的泛化能力。 最后，我们通过发现成千上万个稀疏特征电路来展示一个完全无监督且可扩展的可解释性管线，用于自动发现的模型行为。

    arXiv:2403.19647v1 Announce Type: cross  Abstract: We introduce methods for discovering and applying sparse feature circuits. These are causally implicated subnetworks of human-interpretable features for explaining language model behaviors. Circuits identified in prior work consist of polysemantic and difficult-to-interpret units like attention heads or neurons, rendering them unsuitable for many downstream applications. In contrast, sparse feature circuits enable detailed understanding of unanticipated mechanisms. Because they are based on fine-grained units, sparse feature circuits are useful for downstream tasks: We introduce SHIFT, where we improve the generalization of a classifier by ablating features that a human judges to be task-irrelevant. Finally, we demonstrate an entirely unsupervised and scalable interpretability pipeline by discovering thousands of sparse feature circuits for automatically discovered model behaviors.
    
[^3]: 非对称和试验依赖建模：LIA对SdSV挑战任务2的贡献

    Asymmetric and trial-dependent modeling: the contribution of LIA to SdSV Challenge Task 2

    [https://arxiv.org/abs/2403.19634](https://arxiv.org/abs/2403.19634)

    该论文描述了对说话人识别领域的贡献，突出展示了对SdSv挑战任务的两个额外挑战：注册和测试数据不匹配以及评估试验数据集子集不匹配的问题。

    

    SdSv挑战任务2为评估现代文本无关说话人验证系统的效率和鲁棒性提供了机会。但它也使得测试能够考虑到该挑战的主要问题（持续时间、语言等）的新方法成为可能。本文描述了我们实验室对说话人识别领域的贡献。这些贡献强调了除了短持续时间和语言之外的另外两个挑战：注册和测试数据之间的不匹配以及评估试验数据集子集之间的不匹配。所提出的方法在SdSv评估中实验性地展示了它们的相关性和效率，并且可能在许多现实应用中具有吸引力。

    arXiv:2403.19634v1 Announce Type: cross  Abstract: The SdSv challenge Task 2 provided an opportunity to assess efficiency and robustness of modern text-independent speaker verification systems. But it also made it possible to test new approaches, capable of taking into account the main issues of this challenge (duration, language, ...). This paper describes the contributions of our laboratory to the speaker recognition field. These contributions highlight two other challenges in addition to short-duration and language: the mismatch between enrollment and test data and the one between subsets of the evaluation trial dataset. The proposed approaches experimentally show their relevance and efficiency on the SdSv evaluation, and could be of interest in many real-life applications.
    
[^4]: 多跳问题回答中的检索增强知识编辑在语言模型中的应用

    Retrieval-Enhanced Knowledge Editing for Multi-Hop Question Answering in Language Models

    [https://arxiv.org/abs/2403.19631](https://arxiv.org/abs/2403.19631)

    提出了用于多跳问题回答的检索增强模型编辑（RAE）框架，利用互信息最大化的检索方法和修剪策略，实现了对语言模型的有效优化。

    

    大型语言模型（LLMs）在问题回答任务中显示出高效能，但往往难以整合实时知识更新，导致可能过时或不准确的响应。当处理多跳问题时，这个问题变得更具挑战性，因为它们要求LLMs更新和整合与问题相关的多个知识片段。为了解决这个问题，我们提出了针对多跳问题回答定制的检索增强模型编辑（RAE）框架。RAE首先检索编辑后的事实，然后通过上下文学习来完善语言模型。具体而言，我们的检索方法基于互信息最大化，利用LLMs的推理能力来识别链式事实，而天真的基于相似性的搜索可能会忽略这些事实。此外，我们的框架还采用了修剪策略，从检索到的事实中消除冗余信息，这增强了编辑

    arXiv:2403.19631v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have shown proficiency in question-answering tasks but often struggle to integrate real-time knowledge updates, leading to potentially outdated or inaccurate responses. This problem becomes even more challenging when dealing with multi-hop questions since they require LLMs to update and integrate multiple knowledge pieces relevant to the questions. To tackle the problem, we propose the Retrieval-Augmented model Editing (RAE) framework tailored for multi-hop question answering. RAE first retrieves edited facts and then refines the language model through in-context learning. Specifically, our retrieval approach, based on mutual information maximization, leverages the reasoning abilities of LLMs to identify chain facts that na\"ive similarity-based searches might miss. Additionally, our framework incorporates a pruning strategy to eliminate redundant information from the retrieved facts, which enhances the edi
    
[^5]: 基于语义地图的导航说明生成

    Semantic Map-based Generation of Navigation Instructions

    [https://arxiv.org/abs/2403.19603](https://arxiv.org/abs/2403.19603)

    通过使用语义地图作为视觉输入，我们提出了一种新的导航说明生成方法，将问题构建为图像字幕任务，有望降低生成指令的计算复杂性。

    

    我们对导航说明的生成很感兴趣，无论是作为自身存在的文本还是作为机器人导航任务的训练材料。在本文中，我们提出了一种新的导航说明生成方法，将问题构建为使用语义地图作为视觉输入的图像字幕任务。传统方法采用一系列全景图像来生成导航说明。语义地图将视觉细节抽象出来，将多个全景图像中的信息融合到单个自上而下的表示中，从而降低了处理输入的计算复杂性。我们提供了一个使用语义地图生成说明的基准数据集，提出了一个初始模型，并请人工主观评估生成说明的质量。我们的初步调查显示，使用语义地图生成说明而不是一系列全景图像具有潜力，但研究范围仍然广阔。

    arXiv:2403.19603v1 Announce Type: cross  Abstract: We are interested in the generation of navigation instructions, either in their own right or as training material for robotic navigation task. In this paper, we propose a new approach to navigation instruction generation by framing the problem as an image captioning task using semantic maps as visual input. Conventional approaches employ a sequence of panorama images to generate navigation instructions. Semantic maps abstract away from visual details and fuse the information in multiple panorama images into a single top-down representation, thereby reducing computational complexity to process the input. We present a benchmark dataset for instruction generation using semantic maps, propose an initial model and ask human subjects to manually assess the quality of generated instructions. Our initial investigations show promise in using semantic maps for instruction generation instead of a sequence of panorama images, but there is vast sco
    
[^6]: 支持标注者以改进对抗数据收集：来自GAHD的教训，一个德语仇恨言论数据集

    Improving Adversarial Data Collection by Supporting Annotators: Lessons from GAHD, a German Hate Speech Dataset

    [https://arxiv.org/abs/2403.19559](https://arxiv.org/abs/2403.19559)

    通过支持标注者，提出新策略来创建更多样化的对抗性示例，引入GAHD德语对抗性仇恨言论数据集，表明训练模型使用GAHD可以显著提高模型的鲁棒性。

    

    厌恶言论检测模型的表现取决于它们所训练的数据。从社交媒体获取的数据集存在系统性缺陷和偏见，导致模型具有简单的决策边界。通过利用模型的弱点收集的对抗性数据集承诺解决这一问题。然而，对抗数据集的收集可能缓慢且昂贵，而个体标注者的创造力有限。在本文中，我们介绍了GAHD，一个新的德语对抗性仇恨言论数据集，包含约11k个示例。在数据收集过程中，我们探索了支持标注者的新策略，以更有效地创建更多样化的对抗性示例，并为每种策略提供了标注者意见分歧的手动分析。我们的实验表明，由此产生的数据集即使对于最先进的仇恨言论检测模型也具有挑战性，并且在GAHD上的训练显然提高了模型的鲁棒性。

    arXiv:2403.19559v1 Announce Type: new  Abstract: Hate speech detection models are only as good as the data they are trained on. Datasets sourced from social media suffer from systematic gaps and biases, leading to unreliable models with simplistic decision boundaries. Adversarial datasets, collected by exploiting model weaknesses, promise to fix this problem. However, adversarial data collection can be slow and costly, and individual annotators have limited creativity. In this paper, we introduce GAHD, a new German Adversarial Hate speech Dataset comprising ca.\ 11k examples. During data collection, we explore new strategies for supporting annotators, to create more diverse adversarial examples more efficiently and provide a manual analysis of annotator disagreements for each strategy. Our experiments show that the resulting dataset is challenging even for state-of-the-art hate speech detection models, and that training on GAHD clearly improves model robustness. Further, we find that m
    
[^7]: WaterJudge: 在给大型语言模型设置水印时质量检测的权衡问题

    WaterJudge: Quality-Detection Trade-off when Watermarking Large Language Models

    [https://arxiv.org/abs/2403.19548](https://arxiv.org/abs/2403.19548)

    提出了一个简单的分析框架，利用比较评估和灵活的NLG评估框架来评估特定水印设置对生成文本质量造成的影响。

    

    给如LLMs这样的生成式AI系统设置水印已经引起了相当大的兴趣，这种兴趣是因为它们在广泛任务中的增强能力。尽管当前的方法已经证明，可以利用在词分布中的小的、上下文相关的变化来应用和检测水印，但对这些扰动对生成文本质量的影响还没有太多的研究。在选择适当的水印设置方面，平衡高可检测性和最小性能降级至关重要；因此，本文提出了一个简单的分析框架，其中使用比较评估、一个灵活的NLG评估框架，来评估特定水印设置造成的质量退化。我们展示了我们的框架可以轻松可视化水印设置的质量-检测权衡，从而为找到一个LLM水印操作点提供了一个简单的解决方案。

    arXiv:2403.19548v1 Announce Type: new  Abstract: Watermarking generative-AI systems, such as LLMs, has gained considerable interest, driven by their enhanced capabilities across a wide range of tasks. Although current approaches have demonstrated that small, context-dependent shifts in the word distributions can be used to apply and detect watermarks, there has been little work in analyzing the impact that these perturbations have on the quality of generated texts. Balancing high detectability with minimal performance degradation is crucial in terms of selecting the appropriate watermarking setting; therefore this paper proposes a simple analysis framework where comparative assessment, a flexible NLG evaluation framework, is used to assess the quality degradation caused by a particular watermark setting. We demonstrate that our framework provides easy visualization of the quality-detection trade-off of watermark settings, enabling a simple solution to find an LLM watermark operating po
    
[^8]: 解释基于Transformer模型的语言模型在事实回忆中的关键机制

    Interpreting Key Mechanisms of Factual Recall in Transformer-Based Language Models

    [https://arxiv.org/abs/2403.19521](https://arxiv.org/abs/2403.19521)

    通过深入研究Transformer-based语言模型在事实回忆任务中的机制，我们发现了零/少次样本情况下的特定任务头、MLP层和残差流的功能，以及抗过度自信机制。

    

    本文深入探讨了Transformer-based语言模型在事实回忆任务中所采用的机制。在零次样本情况下，给定类似“法国的首都是”的提示，特定任务的注意力头会从上下文中提取主题实体，如“法国”，并将其传递给后续的MLP以回忆所需的答案，如“巴黎”。我们引入了一种新颖的分析方法，旨在将MLP的输出分解为人类可理解的组件。通过这种方法，我们量化了跟随这些特定任务头的MLP层的功能。在残差流中，它会擦除或放大来自各个头的信息。此外，它会生成一个组件，将残差流重新定向到预期答案的方向。这些零次机制也适用于少次样本情况。此外，我们观察到一种广泛存在的抗过度自信机制。

    arXiv:2403.19521v1 Announce Type: cross  Abstract: In this paper, we deeply explore the mechanisms employed by Transformer-based language models in factual recall tasks. In zero-shot scenarios, given a prompt like "The capital of France is," task-specific attention heads extract the topic entity, such as "France," from the context and pass it to subsequent MLPs to recall the required answer such as "Paris." We introduce a novel analysis method aimed at decomposing the outputs of the MLP into components understandable by humans. Through this method, we quantify the function of the MLP layer following these task-specific heads. In the residual stream, it either erases or amplifies the information originating from individual heads. Moreover, it generates a component that redirects the residual stream towards the direction of its expected answer. These zero-shot mechanisms are also employed in few-shot scenarios. Additionally, we observed a widely existent anti-overconfidence mechanism in 
    
[^9]: 通过语言模型生成的合成临床数据提升临床自然语言处理的性能

    Improving Clinical NLP Performance through Language Model-Generated Synthetic Clinical Data

    [https://arxiv.org/abs/2403.19511](https://arxiv.org/abs/2403.19511)

    通过利用先进语言模型生成的合成数据，本研究探讨了提升临床自然语言处理性能的方法，展示出在高风险领域中可行的应用。

    

    生成模型在生产大量数据方面显示出潜力。本研究探讨了利用从先进语言模型生成的合成数据提升临床自然语言处理性能的方法。令人鼓舞的结果显示在这样一个高风险领域中有可行的应用。

    arXiv:2403.19511v1 Announce Type: new  Abstract: Generative models have been showing potential for producing data in mass. This study explores the enhancement of clinical natural language processing performance by utilizing synthetic data generated from advanced language models. Promising results show feasible applications in such a high-stakes domain.
    
[^10]: UCLA语音实验室档案的语音切分

    Phonetic Segmentation of the UCLA Phonetics Lab Archive

    [https://arxiv.org/abs/2403.19509](https://arxiv.org/abs/2403.19509)

    VoxAngeles是一个包含UCLA语音实验室档案的语音切分和音素级对齐的语料库，增强了原始数据的可用性，特别适用于定量语音类型学研究。

    

    研究语音技术和比较语言学依赖于获得多样化和可访问的语音数据。 UCLA语音实验室档案是最早的多语种语音语料库之一，其中包含314种语言的长篇音频记录和语音切分。最近，其中95种语言已经与单词级语音切分进行了时间对齐。本文介绍了VoxAngeles，这是一个经过审阅的UCLA语音实验室档案的语音切分和音素级对齐语料库，使用了95种语言的CMU重新发行作为我们的起始点。VoxAngeles还包括了原始UCLA语料库的单词级和音素级切分，以及单词和音素持续时间、元音共振峰和元音f0的语音测量。该语料库增强了原始数据的可用性，特别是对于定量语音类型学，通过一个元音整体分析案例研究进行了展示。

    arXiv:2403.19509v1 Announce Type: new  Abstract: Research in speech technologies and comparative linguistics depends on access to diverse and accessible speech data. The UCLA Phonetics Lab Archive is one of the earliest multilingual speech corpora, with long-form audio recordings and phonetic transcriptions for 314 languages (Ladefoged et al., 2009). Recently, 95 of these languages were time-aligned with word-level phonetic transcriptions (Li et al., 2021). Here we present VoxAngeles, a corpus of audited phonetic transcriptions and phone-level alignments of the UCLA Phonetics Lab Archive, which uses the 95-language CMU re-release as our starting point. VoxAngeles also includes word- and phone-level segmentations from the original UCLA corpus, as well as phonetic measurements of word and phone durations, vowel formants, and vowel f0. This corpus enhances the usability of the original data, particularly for quantitative phonetic typology, as demonstrated through a case study of vowel int
    
[^11]: JDocQA：用于生成语言模型的日语文档问答数据集

    JDocQA: Japanese Document Question Answering Dataset for Generative Language Models

    [https://arxiv.org/abs/2403.19454](https://arxiv.org/abs/2403.19454)

    JDocQA是一个大规模的基于文档的问答数据集，要求结合视觉和文本信息回答问题，包括5,504个文档和11,600个问答实例。

    

    arXiv:2403.19454v1 公告类型: 新的 摘要: 文档问答是针对给定文档（如报告、幻灯片、小册子和网站）的问答任务，这是一项非常具有挑战性的任务，因为纸质和电子形式的文档在我们的社会中非常普遍。 这是一个非常具有挑战性的任务，因为它不仅需要理解文本，还需要理解图表，因此除了文本方法之外，通常还会研究视觉问答（VQA）方法。 我们推出了《日语文档问答》（JDocQA），这是一个大规模的基于文档的问答数据集，基本上需要同时使用视觉和文本信息来回答问题，其中包括5,504个PDF格式的文档和11,600个日语问答实例。 每个问答实例都包括对文档页的引用和答案提示的边界框。

    arXiv:2403.19454v1 Announce Type: new  Abstract: Document question answering is a task of question answering on given documents such as reports, slides, pamphlets, and websites, and it is a truly demanding task as paper and electronic forms of documents are so common in our society. This is known as a quite challenging task because it requires not only text understanding but also understanding of figures and tables, and hence visual question answering (VQA) methods are often examined in addition to textual approaches. We introduce Japanese Document Question Answering (JDocQA), a large-scale document-based QA dataset, essentially requiring both visual and textual information to answer questions, which comprises 5,504 documents in PDF format and annotated 11,600 question-and-answer instances in Japanese. Each QA instance includes references to the document pages and bounding boxes for the answer clues. We incorporate multiple categories of questions and unanswerable questions from the do
    
[^12]: 混合偏好优化：强化学习中的数据选择与更好的参考模型

    Mixed Preference Optimization: Reinforcement Learning with Data Selection and Better Reference Model

    [https://arxiv.org/abs/2403.19443](https://arxiv.org/abs/2403.19443)

    提出了一种混合偏好优化（MPO）方法，通过在简单数据集上训练Direct Preference Optimization（DPO），然后在困难数据集上执行Reinforcement Learning with Human Feedback（RLHF），从而减轻了两种方法的弱点。

    

    大型语言模型（LLMs）因其处理和生成自然语言的能力而日益受到青睐。然而，由于它们是在大规模文本数据集上训练的，LLMs可能会继承有害偏见，并产生与人类价值观不一致的输出。本文研究了LLM对齐的两种主要方法：带人类反馈的强化学习（RLHF）和基于对比学习的方法如直接偏好优化（DPO）。通过分析RLHF和DPO的稳定性和鲁棒性，我们提出了MPO（混合偏好优化），这是一种缓解两种方法弱点的新方法。具体而言，我们提出了一个两阶段训练过程：首先在一个简单数据集上训练DPO，然后再在带有DPO模型作为参考模型的困难集上执行RLHF。在这里，简单和困难集是由训练良好的奖励模型构建的，将响应对分成具有较大差距的对。

    arXiv:2403.19443v1 Announce Type: new  Abstract: Large Language Models (LLMs) have become increasingly popular due to their ability to process and generate natural language. However, as they are trained on massive datasets of text, LLMs can inherit harmful biases and produce outputs that are not aligned with human values. This paper studies two main approaches to LLM alignment: Reinforcement Learning with Human Feedback (RLHF) and contrastive learning-based methods like Direct Preference Optimization (DPO). By analyzing the stability and robustness of RLHF and DPO, we propose MPO (Mixed Preference Optimization), a novel method that mitigates the weaknesses of both approaches. Specifically, we propose a two-stage training procedure: first train DPO on an easy dataset, and then perform RLHF on a difficult set with DPO model being the reference model. Here, the easy and difficult sets are constructed by a well-trained reward model that splits response pairs into those with large gaps of r
    
[^13]: 通过死因调查笔记中的注释不一致性检测揭示自杀原因的误归因

    Uncovering Misattributed Suicide Causes through Annotation Inconsistency Detection in Death Investigation Notes

    [https://arxiv.org/abs/2403.19432](https://arxiv.org/abs/2403.19432)

    通过自然语言处理方法检测并纠正国家暴力死亡报告系统中的注释不一致性，提高了自杀危机分类器的性能。

    

    数据准确性对科学研究和政策制定至关重要。国家暴力死亡报告系统（NVDRS）数据被广泛用于发现死亡的模式和原因。最近的研究表明NVDRS内存在注释不一致性，并可能影响错误的自杀原因归因。我们提出了一种经验性的自然语言处理（NLP）方法来检测注释不一致性，并采用类似交叉验证的范式来识别有问题的实例。我们分析了2003年至2020年间从NVDRS中的267,804起自杀死亡案例。结果显示，将目标州的数据纳入训练自杀危机分类器，使得在目标州测试集上的F-1分数增加了5.4％，在其他州测试集上降低了1.1％。总之，我们展示了NVDRS死因调查笔记中的注释不一致性，并确定了问题的实例。

    arXiv:2403.19432v1 Announce Type: cross  Abstract: Data accuracy is essential for scientific research and policy development. The National Violent Death Reporting System (NVDRS) data is widely used for discovering the patterns and causes of death. Recent studies suggested the annotation inconsistencies within the NVDRS and the potential impact on erroneous suicide-cause attributions. We present an empirical Natural Language Processing (NLP) approach to detect annotation inconsistencies and adopt a cross-validation-like paradigm to identify problematic instances. We analyzed 267,804 suicide death incidents between 2003 and 2020 from the NVDRS. Our results showed that incorporating the target state's data into training the suicide-crisis classifier brought an increase of 5.4% to the F-1 score on the target state's test set and a decrease of 1.1% on other states' test set. To conclude, we demonstrated the annotation inconsistencies in NVDRS's death investigation notes, identified problema
    
[^14]: 语法跨度偏好在事后解释不一致中的作用

    The Role of Syntactic Span Preferences in Post-Hoc Explanation Disagreement

    [https://arxiv.org/abs/2403.19424](https://arxiv.org/abs/2403.19424)

    此研究从语言学角度研究了不同方法之间的解释不一致，发现在句法跨度水平上比较方法可以平滑掉标记级别的差异，提出了动态估计最重要跨度的方法，改进了选择重要标记的配置。

    

    事后解释方法是增加模型透明度对用户来说是一个重要工具。不幸的是，目前用于归因标记重要性的方法经常产生不同的模式。在这项工作中，我们从语言学角度研究了方法之间不一致的潜在来源。我们发现不同的方法系统地选择不同类别的词，并且那些与其他方法和人类达成最高一致性的方法展现出类似的语言偏好。如果我们在句法跨度水平上比较方法，那么方法之间的标记级差异就会被平滑掉。通过动态估计最重要的跨度而不是依赖于固定大小为$k$的子集，我们发现方法之间的一致性更高。我们系统地调查了$k$和跨度之间的交互作用，并提出了一个用于选择重要标记的改进配置。

    arXiv:2403.19424v1 Announce Type: cross  Abstract: Post-hoc explanation methods are an important tool for increasing model transparency for users. Unfortunately, the currently used methods for attributing token importance often yield diverging patterns. In this work, we study potential sources of disagreement across methods from a linguistic perspective. We find that different methods systematically select different classes of words and that methods that agree most with other methods and with humans display similar linguistic preferences. Token-level differences between methods are smoothed out if we compare them on the syntactic span level. We also find higher agreement across methods by estimating the most important spans dynamically instead of relying on a fixed subset of size $k$. We systematically investigate the interaction between $k$ and spans and propose an improved configuration for selecting important tokens.
    
[^15]: Twitter上的回音室和Idea实验室：沟通风格

    Echo-chambers and Idea Labs: Communication Styles on Twitter

    [https://arxiv.org/abs/2403.19423](https://arxiv.org/abs/2403.19423)

    本研究发现了Twitter社区在疫苗接种背景下具有不同沟通风格，除了回音室行为外，还存在着其他独特的社区沟通模式。

    

    本文研究了Twitter社区在疫苗接种背景下的沟通风格和结构。虽然主流研究主要集中在回音室现象上，即某些观点被强化，参与者被隔离在对立观点之外，但这项研究揭示了不同社区之间存在着多样化的沟通风格。除了呈现回音室行为的社区外，这项研究还揭示了具有不同沟通模式的社区。通过揭示社交网络中沟通的微妙性质，本研究强调了理解在线社区内多元化观点的重要性。

    arXiv:2403.19423v1 Announce Type: cross  Abstract: This paper investigates the communication styles and structures of Twitter (X) communities within the vaccination context. While mainstream research primarily focuses on the echo-chamber phenomenon, wherein certain ideas are reinforced and participants are isolated from opposing opinions, this study reveals the presence of diverse communication styles across various communities. In addition to the communities exhibiting echo-chamber behavior, this research uncovers communities with distinct communication patterns. By shedding light on the nuanced nature of communication within social networks, this study emphasizes the significance of understanding the diversity of perspectives within online communities.
    
[^16]: BP4ER: 医学对话生成中用于显式推理的引导式自举方法

    BP4ER: Bootstrap Prompting for Explicit Reasoning in Medical Dialogue Generation

    [https://arxiv.org/abs/2403.19414](https://arxiv.org/abs/2403.19414)

    BP4ER提出了一种Bootstrap Prompting方法，通过引导大型语言模型在多步推理中进行显式推理，分解医学对话生成为简单子问题，并引入了两种引导技术。

    

    医学对话生成(MDG)因其实际价值日益受到关注。先前的研究通常采用序列到序列的框架，通过将对话上下文建模为带有标注医学实体的序列文本来生成医学回复。尽管这些方法在生成流畅回复方面取得了成功，但它们未能提供推理过程解释并且需要大量实体标注。为了解决这些限制，我们提出了Bootstrap Prompting for Explicit Reasoning in MDG (BP4ER)方法，该方法明确建模MDG的多步推理过程并迭代增强这一推理过程。我们采用由浅入深的提示策略，引导大型语言模型(LLM)进行显式推理，将MDG分解为更简单的子问题。这些子问题建立在先前问题的答案基础上。此外，我们还引入了两种不同的引导技术。

    arXiv:2403.19414v1 Announce Type: new  Abstract: Medical dialogue generation (MDG) has gained increasing attention due to its substantial practical value. Previous works typically employ a sequence-to-sequence framework to generate medical responses by modeling dialogue context as sequential text with annotated medical entities. While these methods have been successful in generating fluent responses, they fail to provide process explanations of reasoning and require extensive entity annotation. To address these limitations, we propose the method Bootstrap Prompting for Explicit Reasoning in MDG (BP4ER), which explicitly model MDG's multi-step reasoning process and iteratively enhance this reasoning process. We employ a least-to-most prompting strategy to guide a large language model (LLM) in explicit reasoning, breaking down MDG into simpler sub-questions. These sub-questions build on answers from previous ones. Additionally, we also introduce two distinct bootstrapping techniques for 
    
[^17]: KazParC：用于机器翻译的哈萨克平行语料库

    KazParC: Kazakh Parallel Corpus for Machine Translation

    [https://arxiv.org/abs/2403.19399](https://arxiv.org/abs/2403.19399)

    KazParC是一个跨哈萨克语、英语、俄语和土耳其语的机器翻译平行语料库，其中包含371,902个平行句子，还开发了性能优越的神经机器翻译模型Tilmash。

    

    我们介绍了KazParC，这是一个为跨哈萨克语、英语、俄语和土耳其语进行机器翻译而设计的平行语料库。作为其类别中首个也是最大的公开可用语料库，KazParC包含了371,902个平行句子的集合，涵盖不同领域，并在人类译者的协助下开发。我们的研究工作还扩展到了发展一个被昵称为Tilmash的神经机器翻译模型。引人注目的是，Tilmash的表现与工业巨头，如Google翻译和Yandex翻译，在标准评估指标（如BLEU和chrF）的基础上相媲美，并在某些情况下甚至超越。KazParC和Tilmash均可通过我们的GitHub存储库以知识共享署名4.0国际许可（CC BY 4.0）公开下载。

    arXiv:2403.19399v1 Announce Type: new  Abstract: We introduce KazParC, a parallel corpus designed for machine translation across Kazakh, English, Russian, and Turkish. The first and largest publicly available corpus of its kind, KazParC contains a collection of 371,902 parallel sentences covering different domains and developed with the assistance of human translators. Our research efforts also extend to the development of a neural machine translation model nicknamed Tilmash. Remarkably, the performance of Tilmash is on par with, and in certain instances, surpasses that of industry giants, such as Google Translate and Yandex Translate, as measured by standard evaluation metrics, such as BLEU and chrF. Both KazParC and Tilmash are openly available for download under the Creative Commons Attribution 4.0 International License (CC BY 4.0) through our GitHub repository.
    
[^18]: 在LLM预训练中通过贝叶斯优化进行检查点合并

    Checkpoint Merging via Bayesian Optimization in LLM Pretraining

    [https://arxiv.org/abs/2403.19390](https://arxiv.org/abs/2403.19390)

    通过贝叶斯优化，我们提出了LLM预训练中的检查点合并方法，展现了在最小成本下增强预训练的能力以及在不同领域展示鲁棒泛化能力的特点。

    

    大型语言模型（LLMs）如GPT-4和Gemini的迅速增长突显了在它们的训练过程中对资源的强烈需求，由于巨大的计算和环境成本，这提出了重大挑战。为了缓解这一问题，我们提出了LLM预训练中的检查点合并。该方法利用具有共享训练轨迹的LLM检查点，并通过贝叶斯优化对最佳合并权重进行广泛的搜索空间探索。通过各种实验，我们展示了：（1）我们提出的方法展示了增强预训练的能力，类似于在最小成本下获得重大收益的机会；（2）尽管我们提出的方法需要一个给定的保留数据集，但仍展示了跨多个领域的稳健泛化能力，这是预训练中的一个关键方面。

    arXiv:2403.19390v1 Announce Type: new  Abstract: The rapid proliferation of large language models (LLMs) such as GPT-4 and Gemini underscores the intense demand for resources during their training processes, posing significant challenges due to substantial computational and environmental costs. To alleviate this issue, we propose checkpoint merging in pretraining LLM. This method utilizes LLM checkpoints with shared training trajectories, and is rooted in an extensive search space exploration for the best merging weight via Bayesian optimization. Through various experiments, we demonstrate that: (1) Our proposed methodology exhibits the capacity to augment pretraining, presenting an opportunity akin to obtaining substantial benefits at minimal cost; (2) Our proposed methodology, despite requiring a given held-out dataset, still demonstrates robust generalization capabilities across diverse domains, a pivotal aspect in pretraining.
    
[^19]: EthioMT：低资源埃塞俄比亚语言的平行语料库

    EthioMT: Parallel Corpus for Low-resource Ethiopian Languages

    [https://arxiv.org/abs/2403.19365](https://arxiv.org/abs/2403.19365)

    EthioMT是一个新的平行语料库，为15种低资源埃塞俄比亚语言提供支持，并通过创建基准数据集改进了研究界对埃塞俄比亚语言的研究。

    

    自然语言处理（NLP）领域的最新研究取得了在机器翻译（MT）、新闻分类和问答等高资源语言任务中令人印象深刻的性能。然而，对于低资源语言，MT的性能仍有很大改进空间。这是由于这些语言可用平行语料库的规模较小，如果有的话。埃塞俄比亚语言的NLP也因为公开可访问的NLP任务数据集（包括MT）的不可用而受到相同问题的困扰。为了帮助研究界并促进埃塞俄比亚语言的研究，我们介绍了EthioMT - 一个包含15种语言的新平行语料库。我们还通过收集埃塞俄比亚更常见的已研究语言的数据集，创建了一个新的基准。我们使用transformer和微调方法对新收集的语料库和基准数据集对23种埃塞俄比亚语言进行了评估。

    arXiv:2403.19365v1 Announce Type: new  Abstract: Recent research in natural language processing (NLP) has achieved impressive performance in tasks such as machine translation (MT), news classification, and question-answering in high-resource languages. However, the performance of MT leaves much to be desired for low-resource languages. This is due to the smaller size of available parallel corpora in these languages, if such corpora are available at all. NLP in Ethiopian languages suffers from the same issues due to the unavailability of publicly accessible datasets for NLP tasks, including MT. To help the research community and foster research for Ethiopian languages, we introduce EthioMT -- a new parallel corpus for 15 languages. We also create a new benchmark by collecting a dataset for better-researched languages in Ethiopia. We evaluate the newly collected corpus and the benchmark dataset for 23 Ethiopian languages using transformer and fine-tuning approaches.
    
[^20]: 社交媒体上对病态赌博的风险预测

    Risk prediction of pathological gambling on social media

    [https://arxiv.org/abs/2403.19358](https://arxiv.org/abs/2403.19358)

    该论文通过在模型中纳入时间和情绪特征，提出了一种在社交媒体数据上预测Reddit用户患有病态赌博障碍的方法，实验证明顺序模型比连接模型效果更好。

    

    这篇论文解决了社交媒体数据上的风险预测问题，特别关注对Reddit用户进行分类，确定是否患有病态赌博障碍。为了解决这个问题，该论文侧重于将时间和情绪特征纳入模型中。预处理阶段涉及通过填充序列来处理帖子的时间不规则性。两种基准架构用于初步评估：基于BERT分类器的每个用户的连接帖子和基于GRU和LSTM的顺序数据。实验结果表明，顺序模型优于基于连接的模型。实验结果表明，通过将时间衰减层（TD）和情感分类层（EmoBERTa）通过LSTM来改善性能。实验表明，增加自注意力层并没有显著提高模型性能。

    arXiv:2403.19358v1 Announce Type: new  Abstract: This paper addresses the problem of risk prediction on social media data, specifically focusing on the classification of Reddit users as having a pathological gambling disorder. To tackle this problem, this paper focuses on incorporating temporal and emotional features into the model. The preprocessing phase involves dealing with the time irregularity of posts by padding sequences. Two baseline architectures are used for preliminary evaluation: BERT classifier on concatenated posts per user and GRU with LSTM on sequential data. Experimental results demonstrate that the sequential models outperform the concatenation-based model. The results of the experiments conclude that the incorporation of a time decay layer (TD) and passing the emotion classification layer (EmoBERTa) through LSTM improves the performance significantly. Experiments concluded that the addition of a self-attention layer didn't significantly improve the performance of th
    
[^21]: AIpom在SemEval-2024任务8中的应用：在M4中检测AI生成的输出

    AIpom at SemEval-2024 Task 8: Detecting AI-produced Outputs in M4

    [https://arxiv.org/abs/2403.19354](https://arxiv.org/abs/2403.19354)

    本研究提出了AIpom系统，通过结合解码器模型和编码器序列标记器的预测，成功在SemEval-2024任务8中的排名第二，并取得了15.94的平均绝对误差，消融研究表明流水线处理编码器和解码器模型有助于提高性能。

    

    这篇论文描述了AIpom，一个旨在检测人工撰写和机器生成文本之间边界的系统（SemEval-2024任务8，子任务C：人机混合文本检测）。我们提出了一个两阶段的流程，结合了一个经过指令调整的解码器模型和仅编码器的序列标记器的预测。AIpom在排行榜上排名第二，同时实现了15.94的平均绝对误差。消融研究证实了通过对编码器和解码器模型进行流水线处理在性能改善方面的好处。

    arXiv:2403.19354v1 Announce Type: new  Abstract: This paper describes AIpom, a system designed to detect a boundary between human-written and machine-generated text (SemEval-2024 Task 8, Subtask C: Human-Machine Mixed Text Detection). We propose a two-stage pipeline combining predictions from an instruction-tuned decoder-only model and encoder-only sequence taggers. AIpom is ranked second on the leaderboard while achieving a Mean Absolute Error of 15.94. Ablation studies confirm the benefits of pipelining encoder and decoder models, particularly in terms of improved performance.
    
[^22]: 世界各地的多语种新闻标题数据集

    A diverse Multilingual News Headlines Dataset from around the World

    [https://arxiv.org/abs/2403.19352](https://arxiv.org/abs/2403.19352)

    Babel Briefings是一个包含全球30种语言和54个地点的470万条新闻标题的数据集，可用于自然语言处理和媒体研究，提供了训练或评估语言模型的高质量数据集，并展示了基于事件相似度度量方法的文章聚类和事件特征可视化。

    

    Babel Briefings是一个新的数据集，包括从2020年8月到2021年11月的470万条新闻标题，涵盖30种语言和全球54个地点，其中包括所有文章的英文翻译。该数据集旨在用于自然语言处理和媒体研究，可作为训练或评估语言模型的高质量数据集，同时提供了一个简单易用的文章集合，用于分析全球新闻报道和文化叙事。作为对这一数据集分析的简单演示，我们使用基本过程利用TF-IDF加权相似度指标将文章分成有关同一事件的聚类。我们然后可视化该事件的\emph{事件签名}，显示随时间展示哪种语言的文章，揭示基于事件的邻近性和意外性的直观特征。该数据集可在\href{https://www.kaggle.com/datasets/fe}{链接}上获得。

    arXiv:2403.19352v1 Announce Type: new  Abstract: Babel Briefings is a novel dataset featuring 4.7 million news headlines from August 2020 to November 2021, across 30 languages and 54 locations worldwide with English translations of all articles included. Designed for natural language processing and media studies, it serves as a high-quality dataset for training or evaluating language models as well as offering a simple, accessible collection of articles, for example, to analyze global news coverage and cultural narratives. As a simple demonstration of the analyses facilitated by this dataset, we use a basic procedure using a TF-IDF weighted similarity metric to group articles into clusters about the same event. We then visualize the \emph{event signatures} of the event showing articles of which languages appear over time, revealing intuitive features based on the proximity of the event and unexpectedness of the event. The dataset is available on \href{https://www.kaggle.com/datasets/fe
    
[^23]: 大型语言模型在数学问题中对不合理性毫无意识

    Large Language Models Are Unconscious of Unreasonability in Math Problems

    [https://arxiv.org/abs/2403.19346](https://arxiv.org/abs/2403.19346)

    本文研究了大型语言模型在解决数学问题中对不合理性的反应，设计了不合理数学问题基准以及关键计算和结论提示模板，提升了它们在错误检测和修正方面的能力。

    

    大型语言模型(LLMs)展示了在解决数学问题方面的巨大能力。然而，当给出包含不合理错误的问题时，它们倾向于产生幻觉。在本文中，我们研究了LLMs在面对不合理数学问题时的行为，并进一步探讨了它们解决这些问题的潜力。首先，我们构建了不合理数学问题(UMP)基准来检查LLMs的错误检测能力。实验证明，LLMs能够检测到不合理错误，但仍然在生成非幻觉内容方面失败。为了改善它们的错误检测和修正能力，我们进一步设计了一种称为关键计算和结论(CCC)的战略提示模板。通过CCC，LLMs可以更好地自我评估并检测数学问题中的不合理错误，使它们在实际应用场景中更可靠和安全。

    arXiv:2403.19346v1 Announce Type: new  Abstract: Large language models (LLMs) demonstrate substantial capabilities in solving math problems. However, they tend to produce hallucinations when given questions containing unreasonable errors. In this paper, we study the behavior of LLMs when faced with unreasonable math problems and further explore their potential to address these problems. First, we construct the Unreasonable Math Problem (UMP) benchmark to examine the error detection ability of LLMs. Experiments show that LLMs are able to detect unreasonable errors, but still fail in generating non-hallucinatory content. In order to improve their ability of error detection and correction, we further design a strategic prompt template called Critical Calculation and Conclusion(CCC). With CCC, LLMs can better self-evaluate and detect unreasonable errors in math questions, making them more reliable and safe in practical application scenarios.
    
[^24]: Dataverse：用于大型语言模型的开源ETL（抽取、转换、加载）管道

    Dataverse: Open-Source ETL (Extract, Transform, Load) Pipeline for Large Language Models

    [https://arxiv.org/abs/2403.19340](https://arxiv.org/abs/2403.19340)

    Dataverse是一个面向大型语言模型的开源ETL管道，提供了用户友好的设计和易于定制的处理器添加功能，旨在成为LLM开发的重要工具，并开源整个库以促进社区贡献。

    

    为了解决规模化数据处理所面临的挑战，我们提出了Dataverse，一个统一的面向大型语言模型（LLMs）的开源抽取-转换-加载（ETL）管道，其核心具有用户友好的设计。在Dataverse中，通过基于块的界面轻松添加自定义处理器，使用户可以方便高效地使用Dataverse构建自己的ETL管道。我们希望Dataverse将成为LLM开发的重要工具，并开放整个库以欢迎社区贡献。此外，我们提供了一个简洁的、两分钟的系统演示视频，展示其功能和实现。

    arXiv:2403.19340v1 Announce Type: cross  Abstract: To address the challenges associated with data processing at scale, we propose Dataverse, a unified open-source Extract-Transform-Load (ETL) pipeline for large language models (LLMs) with a user-friendly design at its core. Easy addition of custom processors with block-based interface in Dataverse allows users to readily and efficiently use Dataverse to build their own ETL pipeline. We hope that Dataverse will serve as a vital tool for LLM development and open source the entire library to welcome community contribution. Additionally, we provide a concise, two-minute video demonstration of our system, illustrating its capabilities and implementation.
    
[^25]: KazSAnDRA：哈萨克情感分析评论和态度数据集

    KazSAnDRA: Kazakh Sentiment Analysis Dataset of Reviews and Attitudes

    [https://arxiv.org/abs/2403.19335](https://arxiv.org/abs/2403.19335)

    KazSAnDRA是哈萨克情感分析领域的第一个最大的公开数据集，研究包括开发和评估四个机器学习模型，在极性分类和得分分类上取得了不错的成功结果。

    

    本文介绍了KazSAnDRA，这是一个为哈萨克情感分析开发的数据集，是第一个也是最大的公开可用数据集。KazSAnDRA包括来自各种来源的18万零64条评论的广泛收集，并包括从1到5的数字评分，提供了客户态度的定量表示。研究还通过开发和评估四个用于极性分类和得分分类的机器学习模型，致力于哈萨克情感分类的自动化。实验分析包括考虑平衡和不平衡情况下的结果评估。最成功的模型在测试集上的极性分类和得分分类的F1分别达到了0.81和0.39。数据集和优化模型是开放获取的，可在知识共享署名4.0国际许可下下载。

    arXiv:2403.19335v1 Announce Type: new  Abstract: This paper presents KazSAnDRA, a dataset developed for Kazakh sentiment analysis that is the first and largest publicly available dataset of its kind. KazSAnDRA comprises an extensive collection of 180,064 reviews obtained from various sources and includes numerical ratings ranging from 1 to 5, providing a quantitative representation of customer attitudes. The study also pursued the automation of Kazakh sentiment classification through the development and evaluation of four machine learning models trained for both polarity classification and score classification. Experimental analysis included evaluation of the results considering both balanced and imbalanced scenarios. The most successful model attained an F1-score of 0.81 for polarity classification and 0.39 for score classification on the test sets. The dataset and fine-tuned models are open access and available for download under the Creative Commons Attribution 4.0 International Lic
    
[^26]: 在多模式大型语言模型中实现即插即用的推理基础

    Plug-and-Play Grounding of Reasoning in Multimodal Large Language Models

    [https://arxiv.org/abs/2403.19322](https://arxiv.org/abs/2403.19322)

    提出了一种用于在多模式大型语言模型中实现即插即用推理基础的新框架P2G，通过利用MLLMs的工具使用潜力和专家代理实现对图像关键视觉和文本对象的即时确定性基础，从而实现有意识的推理。

    

    随着多模式大型语言模型（MLLMs）的兴起，由于其在指令遵循和推理方面突出的新功能，这些模型极大地推动了视觉推理领域的发展。然而，受到其非无损图像标记化的限制，大多数MLLMs在全面捕捉文本和对象细节方面存在不足，尤其是在高分辨率图像中。为解决这一问题，我们提出了P2G，一种用于在MLLMs中实现即插即用推理基础的新框架。具体而言，P2G利用MLLMs的工具使用潜力，利用专家代理来实现对图像的关键视觉和文本对象的即时确定性基础，从而通过多模式提示实现有意识的推理。我们进一步创建了P2GB，一个旨在评估MLLMs在理解具有挑战性的高分辨率图像中的物体间关系和文本能力的基准。对视觉推理任务的全面实验表明了P2G的优越性。

    arXiv:2403.19322v1 Announce Type: cross  Abstract: The surge of Multimodal Large Language Models (MLLMs), given their prominent emergent capabilities in instruction following and reasoning, has greatly advanced the field of visual reasoning. However, constrained by their non-lossless image tokenization, most MLLMs fall short of comprehensively capturing details of text and objects, especially in high-resolution images. To address this, we propose P2G, a novel framework for plug-and-play grounding of reasoning in MLLMs. Specifically, P2G exploits the tool-usage potential of MLLMs to employ expert agents to achieve on-the-fly grounding to critical visual and textual objects of image, thus achieving deliberate reasoning via multimodal prompting. We further create P2GB, a benchmark aimed at assessing MLLMs' ability to understand inter-object relationships and text in challenging high-resolution images. Comprehensive experiments on visual reasoning tasks demonstrate the superiority of P2G. 
    
[^27]: TableLLM：在实际办公使用场景中实现LLMs对表格数据进行处理的能力

    TableLLM: Enabling Tabular Data Manipulation by LLMs in Real Office Usage Scenarios

    [https://arxiv.org/abs/2403.19318](https://arxiv.org/abs/2403.19318)

    TableLLM是一个拥有130亿参数的强大大语言模型，专门用于熟练处理表格数据操作任务，通过远程监督方法和交叉验证策略，TableLLM相对于其他现有的通用和表格数据专注的LLMs具有明显优势。

    

    我们介绍了TableLLM，这是一个拥有130亿参数的强大大语言模型（LLM），专门用于熟练处理表格数据操作任务，无论其嵌入在文档还是电子表格中，以满足真实办公场景需求。我们提出了一种远程监督方法进行训练，其中包括一种推理过程扩展策略，有助于训练LLMs更有效地理解推理模式，以及一种交叉验证策略，确保自动生成数据的质量。为了评估TableLLM的性能，我们构建了一个旨在解决文档和电子表格格式的基准测试，并构建了一个能够处理两种场景的组织良好的评估管线。彻底的评估凸显了TableLLM相对于各种现有通用和专注于表格数据的LLMs的优势。我们已公开发布了该模型。

    arXiv:2403.19318v1 Announce Type: new  Abstract: We introduce TableLLM, a robust large language model (LLM) with 13 billion parameters, purpose-built for proficiently handling tabular data manipulation tasks, whether they are embedded within documents or spreadsheets, catering to real-world office scenarios. We propose a distant supervision method for training, which comprises a reasoning process extension strategy, aiding in training LLMs to understand reasoning patterns more effectively as well as a cross-way validation strategy, ensuring the quality of the automatically generated data. To evaluate the performance of TableLLM, we have crafted a benchmark tailored to address both document and spreadsheet formats as well as constructed a well-organized evaluation pipeline capable of handling both scenarios. Thorough evaluations underscore the advantages of TableLLM when compared to various existing general-purpose and tabular data-focused LLMs. We have publicly released the model check
    
[^28]: 超越边界：探究法律案例摘要在跨辖区转移中的应用

    Beyond Borders: Investigating Cross-Jurisdiction Transfer in Legal Case Summarization

    [https://arxiv.org/abs/2403.19317](https://arxiv.org/abs/2403.19317)

    本研究探讨了法律案例摘要模型的跨辖区普适性，调查了如何有效地总结目标司法管辖区的法律案例，并发现预训练在提高转移性能方面起着关键作用。

    

    法律专业人士面临管理海量冗长判决的挑战，自动化法律案例摘要变得至关重要。然而，先前的方法主要集中在同一司法管辖区内训练和评估这些模型。本研究探讨了法律案例摘要模型的跨辖区普适性。具体来说，我们探讨了如何有效地总结目标司法管辖区的法律案例，在那里参考摘要不可用。我们特别调查了用未标记的目标司法管辖区语料库和通过对目标数据使用无监督算法获得的抽取式银标摘要来补充模型是否增强了转移性能。我们对来自不同司法管辖区的三个数据集所进行的综合研究突显了预训练在提高转移性能方面的作用。我们揭示了在选择最佳来源时，司法相似性在起关键作用的影响。

    arXiv:2403.19317v1 Announce Type: new  Abstract: Legal professionals face the challenge of managing an overwhelming volume of lengthy judgments, making automated legal case summarization crucial. However, prior approaches mainly focused on training and evaluating these models within the same jurisdiction. In this study, we explore the cross-jurisdictional generalizability of legal case summarization models.Specifically, we explore how to effectively summarize legal cases of a target jurisdiction where reference summaries are not available. In particular, we investigate whether supplementing models with unlabeled target jurisdiction corpus and extractive silver summaries obtained from unsupervised algorithms on target data enhances transfer performance. Our comprehensive study on three datasets from different jurisdictions highlights the role of pre-training in improving transfer performance. We shed light on the pivotal influence of jurisdictional similarity in selecting optimal source
    
[^29]: MATEval：用于推进开放性文本评估的多Agent讨论框架

    MATEval: A Multi-Agent Discussion Framework for Advancing Open-Ended Text Evaluation

    [https://arxiv.org/abs/2403.19305](https://arxiv.org/abs/2403.19305)

    提出了MATEval框架，利用多个类GPT-4的LLMs作为评估Agent，模拟人类合作讨论方法，以评估开放性文本，结合自我反思和思维链策略，并加入反馈机制，提升评估深度和广度。

    

    最近生成式大型语言模型（LLMs）的进展令人瞩目，然而，这些模型生成的文本质量经常暴露出持续存在的问题。评估这些模型生成的文本质量，特别是在开放性文本中，一直是一个重大挑战。为解决这一问题，最近的研究探讨了使用LLMs作为评估者的可能性。虽然使用单个LLM作为评估Agent表现出潜力，但却存在显著的不确定性和不稳定性。为了解决这些问题，我们提出了 MATEval：一种“多Agent文本评估框架”，其中所有Agent都由像GPT-4的LLMs扮演。MATEval框架模拟人类协作讨论方法，整合多个Agent的互动来评估开放性文本。我们的框架结合了自我反思和“思维链”策略，以及反馈机制，增强了评估的深度和广度。

    arXiv:2403.19305v1 Announce Type: cross  Abstract: Recent advancements in generative Large Language Models(LLMs) have been remarkable, however, the quality of the text generated by these models often reveals persistent issues. Evaluating the quality of text generated by these models, especially in open-ended text, has consistently presented a significant challenge. Addressing this, recent work has explored the possibility of using LLMs as evaluators. While using a single LLM as an evaluation agent shows potential, it is filled with significant uncertainty and instability. To address these issues, we propose the MATEval: A "Multi-Agent Text Evaluation framework" where all agents are played by LLMs like GPT-4. The MATEval framework emulates human collaborative discussion methods, integrating multiple agents' interactions to evaluate open-ended text. Our framework incorporates self-reflection and Chain-of-Thought (CoT) strategies, along with feedback mechanisms, enhancing the depth and br
    
[^30]: 超越词语匹配：句法改善上下文例句选择以提高机器翻译质量

    Going Beyond Word Matching: Syntax Improves In-context Example Selection for Machine Translation

    [https://arxiv.org/abs/2403.19285](https://arxiv.org/abs/2403.19285)

    本文提出了一种基于句法的机器翻译上下文例句选择方法，通过计算依存树之间的句法相似性，结合词级和句法水平标准选择例句，实验结果表明语法可以有效提升机器翻译上下文学习质量。

    

    arXiv:2403.19285v1 公告类型: 新的 摘要: 在大语言模型（LLMs）时代，上下文学习（ICL）是一种流行的提示策略，其中展示了一些示例以唤起LLMs在给定任务上的能力。如何选择信息量大的例句仍然是一个悬而未决的问题。先前关于机器翻译（MT）的上下文例句选择的作品侧重于表面的词级特征，而忽略了深层次的句法层次知识。在本文中，我们提出了一种基于语法的机器翻译上下文例句选择方法，通过使用多项式距离计算依赖树之间的句法相似性。此外，我们提出了一种综合策略，将通过词级和句法水平标准选择的例句进行组合。对英语和6种常见语言之间的实验结果表明，语法可以有效提升MT的ICL，获得了在12个翻译方向中11个方向上最高的COMET分数。

    arXiv:2403.19285v1 Announce Type: new  Abstract: In-context learning (ICL) is the trending prompting strategy in the era of large language models (LLMs), where a few examples are demonstrated to evoke LLMs' power for a given task. How to select informative examples remains an open issue. Previous works on in-context example selection for machine translation (MT) focus on superficial word-level features while ignoring deep syntax-level knowledge. In this paper, we propose a syntax-based in-context example selection method for MT, by computing the syntactic similarity between dependency trees using Polynomial Distance. In addition, we propose an ensemble strategy combining examples selected by both word-level and syntax-level criteria. Experimental results between English and 6 common languages indicate that syntax can effectively enhancing ICL for MT, obtaining the highest COMET scores on 11 out of 12 translation directions.
    
[^31]: 基于不合语法句法的上下文示例选择用于语法错误校正

    Ungrammatical-syntax-based In-context Example Selection for Grammatical Error Correction

    [https://arxiv.org/abs/2403.19283](https://arxiv.org/abs/2403.19283)

    在本文中，我们提出了一种基于不合语法句法的上下文示例选择策略，用于在语法错误校正中提高性能，并在基准英语GEC数据集上取得了比常用方法更好的表现。

    

    在大语言模型(LLMs)时代，上下文学习(ICL)作为一种有效的提示策略，探索LLMs在各种任务中的能力。然而，将LLMs应用于语法错误校正(GEC)仍然是一项具有挑战性的任务。在本文中，我们提出了一种新颖的基于不合语法句法的上下文示例选择策略用于GEC。具体而言，我们基于各种算法测量句子的相似性，并识别出与测试输入具有最相似不合格式句法的最佳ICL示例。此外，我们进行了一个两阶段流程，以进一步提高选择结果的质量。在基准英语GEC数据集上，实证结果表明我们提出的基于不合语法句法的策略比常用的基于单词匹配或语义的方法与多个LLMs表现更好。这表明对于像GEC这样的句法定向任务，更多关注语法是值得的。

    arXiv:2403.19283v1 Announce Type: new  Abstract: In the era of large language models (LLMs), in-context learning (ICL) stands out as an effective prompting strategy that explores LLMs' potency across various tasks. However, applying LLMs to grammatical error correction (GEC) is still a challenging task. In this paper, we propose a novel ungrammatical-syntax-based in-context example selection strategy for GEC. Specifically, we measure similarity of sentences based on their syntactic structures with diverse algorithms, and identify optimal ICL examples sharing the most similar ill-formed syntax to the test input. Additionally, we carry out a two-stage process to further improve the quality of selection results. On benchmark English GEC datasets, empirical results show that our proposed ungrammatical-syntax-based strategies outperform commonly-used word-matching or semantics-based methods with multiple LLMs. This indicates that for a syntax-oriented task like GEC, paying more attention to
    
[^32]: 使用奖励学习在策略上微调语言模型

    Fine-Tuning Language Models with Reward Learning on Policy

    [https://arxiv.org/abs/2403.19279](https://arxiv.org/abs/2403.19279)

    提出了在策略上的奖励学习框架，使用策略样本优化奖励模型以保持其分布上的一致性

    

    强化学习从人类反馈（RLHF）作为一种有效的方法出现，用于使大型语言模型（LLMs）与人类偏好保持一致。RLHF包含三个步骤，即收集人类偏好、奖励学习和策略优化，通常是串行执行的。然而，（固定的）奖励模型可能会因为策略优化不断改变LLMs的数据分布而遭受不准确的离分布情况。从最新的LLMs重复收集新的偏好数据可能会缓解这个问题，但不幸的是，这会使得结果系统更加复杂和难以优化。在本文中，我们提出了在策略上的奖励学习（RLP），这是一个无监督的框架，使用策略样本来优化奖励模型以保持其分布上的一致性。具体而言，引入了一种无监督的多视图学习方法来学习策略样本的稳健表示。

    arXiv:2403.19279v1 Announce Type: cross  Abstract: Reinforcement learning from human feedback (RLHF) has emerged as an effective approach to aligning large language models (LLMs) to human preferences. RLHF contains three steps, i.e., human preference collecting, reward learning, and policy optimization, which are usually performed serially. Despite its popularity, however, (fixed) reward models may suffer from inaccurate off-distribution, since policy optimization continuously shifts LLMs' data distribution. Repeatedly collecting new preference data from the latest LLMs may alleviate this issue, which unfortunately makes the resulting system more complicated and difficult to optimize. In this paper, we propose reward learning on policy (RLP), an unsupervised framework that refines a reward model using policy samples to keep it on-distribution. Specifically, an unsupervised multi-view learning method is introduced to learn robust representations of policy samples. Meanwhile, a synthetic
    
[^33]: 知识边界与角色动态塑造更好的社交媒体代理

    Knowledge Boundary and Persona Dynamic Shape A Better Social Media Agent

    [https://arxiv.org/abs/2403.19275](https://arxiv.org/abs/2403.19275)

    通过个性化知识和动态角色信息构建社交媒体代理以解决代理拥有不属于其角色的知识和无法消除多样化角色信息干扰的问题。

    

    构建个性化和拟人化代理在社交网络模拟中具有重要意义。然而，现有作品中仍存在两个关键问题：代理拥有不属于其角色的世界知识，不能消除多样化角色信息对当前行为的干扰，从而降低了代理的个性化和拟人化。为了解决以上问题，我们基于个性化知识和动态角色信息构建社交媒体代理。对于个性化知识，我们添加外部知识源并将其与代理的角色信息匹配，从而赋予代理个性化的世界知识。对于动态角色信息，我们使用当前行为信息内部检索代理的角色信息，从而减少多样化角色信息对当前行为的干扰。

    arXiv:2403.19275v1 Announce Type: cross  Abstract: Constructing personalized and anthropomorphic agents holds significant importance in the simulation of social networks. However, there are still two key problems in existing works: the agent possesses world knowledge that does not belong to its personas, and it cannot eliminate the interference of diverse persona information on current actions, which reduces the personalization and anthropomorphism of the agent. To solve the above problems, we construct the social media agent based on personalized knowledge and dynamic persona information. For personalized knowledge, we add external knowledge sources and match them with the persona information of agents, thereby giving the agent personalized world knowledge. For dynamic persona information, we use current action information to internally retrieve the persona information of the agent, thereby reducing the interference of diverse persona information on the current action. To make the age
    
[^34]: sDPO：不要一次性使用您的数据

    sDPO: Don't Use Your Data All at Once

    [https://arxiv.org/abs/2403.19270](https://arxiv.org/abs/2403.19270)

    sDPO是对直接偏好优化方法的扩展，通过分步利用偏好数据集而非一次性使用，促进更精确对齐参考模型的使用，并训练出性能更优的最终模型，甚至胜过其他具有更多参数的流行大型语言模型。

    

    随着大型语言模型（LLM）的发展，将它们与人类偏好相一致变得日益重要。我们提出了分步DPO（sDPO），这是对最近流行的直接偏好优化（DPO）进行调整的一个扩展。这种方法涉及将可用的偏好数据集分割，并以分步方式利用它们，而不是一次性使用。我们演示了这种方法促进了更精确对齐参考模型在DPO训练框架内的使用。此外，sDPO训练最终模型的性能更好，甚至胜过拥有更多参数的其他流行LLM。

    arXiv:2403.19270v1 Announce Type: cross  Abstract: As development of large language models (LLM) progresses, aligning them with human preferences has become increasingly important. We propose stepwise DPO (sDPO), an extension of the recently popularized direct preference optimization (DPO) for alignment tuning. This approach involves dividing the available preference datasets and utilizing them in a stepwise manner, rather than employing it all at once. We demonstrate that this method facilitates the use of more precisely aligned reference models within the DPO training framework. Furthermore, sDPO trains the final model to be more performant, even outperforming other popular LLMs with more parameters.
    
[^35]: MineLand：模拟具有有限多模感知和生理需求的大规模多智能体交互

    MineLand: Simulating Large-Scale Multi-Agent Interactions with Limited Multimodal Senses and Physical Needs

    [https://arxiv.org/abs/2403.19267](https://arxiv.org/abs/2403.19267)

    MineLand模拟器引入有限多模感知和生理需求，支持多智能体在协作中填补了信息和功能限制的空白，从而促进更具动态和有效性的多智能体交互。

    

    传统的多智能体仿真器通常假设拥有完美信息和无限功能，这限制了社会互动的生态有效性。我们提出了一个多智能体Minecraft模拟器MineLand，通过引入有限的多模感知和生理需求来弥合这一差距。我们的仿真器支持最多48个具有有限视觉、听觉和环境意识的智能体，迫使它们积极沟通和协作以满足食物和资源等生理需求。这促进了动态和有效的多智能体交互。我们进一步介绍了一个灵感来自多任务处理理论的AI智能体框架Alex，使智能体能够处理复杂的协调和调度。我们的实验表明，该模拟器、相应的基准测试和AI智能体框架有助于更具生态和细致的集体行为。MineLand和Alex的源代码可以在https://github.com/c中公开获取。

    arXiv:2403.19267v1 Announce Type: cross  Abstract: Conventional multi-agent simulators often assume perfect information and limitless capabilities, hindering the ecological validity of social interactions. We propose a multi-agent Minecraft simulator, MineLand, that bridges this gap by introducing limited multimodal senses and physical needs. Our simulator supports up to 48 agents with limited visual, auditory, and environmental awareness, forcing them to actively communicate and collaborate to fulfill physical needs like food and resources. This fosters dynamic and valid multi-agent interactions. We further introduce an AI agent framework, Alex, inspired by multitasking theory, enabling agents to handle intricate coordination and scheduling. Our experiments demonstrate that the simulator, the corresponding benchmark, and the AI agent framework contribute to more ecological and nuanced collective behavior. The source code of MineLand and Alex is openly available at https://github.com/c
    
[^36]: NaijaHate: 使用代表性数据评估尼日利亚 Twitter 上的仇恨言论检测

    NaijaHate: Evaluating Hate Speech Detection on Nigerian Twitter Using Representative Data

    [https://arxiv.org/abs/2403.19260](https://arxiv.org/abs/2403.19260)

    首次引入 NaijaHate 数据集，在尼日利亚推特上评估 HSD，发现在代表性数据上评估的 HSD 性能高估了真实世界的表现，提出 NaijaXLM-T 模型，突出了域自适应预训练和微调在最大化 HSD 性能中的关键作用

    

    为了解决在线平台上恶意内容蔓延的全球问题，通常会在美国收集的数据集上开发仇恨言论检测（HSD）模型，从而无法推广到来自大多数世界的英语方言。此外，HSD模型通常在策划样本上进行评估，这引发了对在真实环境中高估模型性能的担忧。在这项工作中，我们引入了第一个用于HSD标注的 NaijaHate 数据集，其中包含尼日利亚推文的代表性样本。我们证明，HSD在传统文献中传统使用的有偏见数据集上评估，在代表性数据上很大程度上高估了真实世界的性能。我们还提出了 NaijaXLM-T，一个针对尼日利亚 Twitter 上下文量身定制的预训练模型，并建立了域自适应预训练和微调在最大化HSD性能方面的关键作用。最后，我们表明，在这种情况下，人-机混合方法发挥了关键作用。

    arXiv:2403.19260v1 Announce Type: new  Abstract: To address the global issue of hateful content proliferating in online platforms, hate speech detection (HSD) models are typically developed on datasets collected in the United States, thereby failing to generalize to English dialects from the Majority World. Furthermore, HSD models are often evaluated on curated samples, raising concerns about overestimating model performance in real-world settings. In this work, we introduce NaijaHate, the first dataset annotated for HSD which contains a representative sample of Nigerian tweets. We demonstrate that HSD evaluated on biased datasets traditionally used in the literature largely overestimates real-world performance on representative data. We also propose NaijaXLM-T, a pretrained model tailored to the Nigerian Twitter context, and establish the key role played by domain-adaptive pretraining and finetuning in maximizing HSD performance. Finally, we show that in this context, a human-in-the-l
    
[^37]: J-CRe3：日本对话数据集用于现实世界参考解析

    J-CRe3: A Japanese Conversation Dataset for Real-world Reference Resolution

    [https://arxiv.org/abs/2403.19259](https://arxiv.org/abs/2403.19259)

    我们提出了一个多模式参考解析任务，并构建了日本对话数据集J-CRe3，用于现实世界参考解析，其中包含了自我中心视频和对话音频，以及短语和视频帧中物体边界框之间的跨模态标记。

    

    arXiv:2403.19259v1 公告类型：新的 摘要：理解指代物理世界的表达对于在真实世界中执行用户期望动作的机器人等助人系统至关重要。在现实世界的参考解析中，系统必须将用户交互中出现的语言信息与自我中心视图中观察到的视觉信息进行关联。为此，我们提出了一项多模式参考解析任务，并构建了一个用于现实世界参考解析的日语对话数据集（J-CRe3）。我们的数据集包含在家中两个人扮演主人和助理机器人之间的真实对话的自我中心视频和对话音频。该数据集带有话语中短语和视频帧中物体边界框之间的跨模态标记。这些标记包括间接参考关系，例如谓语-论元结构和桥接引用，以及直接引用关系。

    arXiv:2403.19259v1 Announce Type: new  Abstract: Understanding expressions that refer to the physical world is crucial for such human-assisting systems in the real world, as robots that must perform actions that are expected by users. In real-world reference resolution, a system must ground the verbal information that appears in user interactions to the visual information observed in egocentric views. To this end, we propose a multimodal reference resolution task and construct a Japanese Conversation dataset for Real-world Reference Resolution (J-CRe3). Our dataset contains egocentric video and dialogue audio of real-world conversations between two people acting as a master and an assistant robot at home. The dataset is annotated with crossmodal tags between phrases in the utterances and the object bounding boxes in the video frames. These tags include indirect reference relations, such as predicate-argument structures and bridging references as well as direct reference relations. We a
    
[^38]: 低资源立场检测的协作知识融入

    Collaborative Knowledge Infusion for Low-resource Stance Detection

    [https://arxiv.org/abs/2403.19219](https://arxiv.org/abs/2403.19219)

    提出了一种用于低资源立场检测任务的协作知识融入方法，增强了对目标背景知识的利用，并采用高效参数学习技术。

    

    立场检测是针对特定目标在给定语境下的观点（如推文、商业评论）。为了帮助立场检测模型更好地理解目标并做出正确判定，通常需要与目标相关的知识。然而，当前关于知识注入的立场检测作品主要将目标知识从一个缺乏领域知识验证的单一来源整合进来。低资源训练数据进一步增加了这一任务中数据驱动大模型的挑战。为了解决这些挑战，我们提出了一种针对低资源立场检测任务的协作知识融入方法，采用了对齐知识增强和高效参数学习技术的组合。具体来说，我们的立场检测方法通过从不同知识来源协作地利用目标背景知识，借助知识对齐

    arXiv:2403.19219v1 Announce Type: new  Abstract: Stance detection is the view towards a specific target by a given context (\textit{e.g.} tweets, commercial reviews). Target-related knowledge is often needed to assist stance detection models in understanding the target well and making detection correctly. However, prevailing works for knowledge-infused stance detection predominantly incorporate target knowledge from a singular source that lacks knowledge verification in limited domain knowledge. The low-resource training data further increases the challenge for the data-driven large models in this task. To address those challenges, we propose a collaborative knowledge infusion approach for low-resource stance detection tasks, employing a combination of aligned knowledge enhancement and efficient parameter learning techniques. Specifically, our stance detection approach leverages target background knowledge collaboratively from different knowledge sources with the help of knowledge alig
    
[^39]: 为联邦基金会模型提供双重个性化适配器

    Dual-Personalizing Adapter for Federated Foundation Models

    [https://arxiv.org/abs/2403.19211](https://arxiv.org/abs/2403.19211)

    提出了一种新的设置，称为测试时间个性化，不仅关注目标本地任务，还延伸到其他展示测试时间个性化的任务

    

    最近，基础模型，尤其是大型语言模型（LLMs），通过微调大量的指令数据，展现出了适应各种任务的令人印象深刻的能力。值得注意的是，联邦基金会模型作为一种隐私保护方法，在分布式学习（FL）环境下通过利用许多分布式数据集进行协作微调模型，这些数据集具有非IID数据。为了减轻通信和计算开销，引入了参数高效方法以提高效率，并且一些研究将个性化方法调整为联邦基金会模型，以获得更好的用户偏好对齐。然而，现有研究中存在的一个关键缺口是在真实应用中忽略了测试时间分布转移。因此，为了弥合这一差距，我们提出了一个新的设置，称为测试时间个性化，它不仅专注于目标本地任务，还延伸到其他展示测试时间个性化的任务。

    arXiv:2403.19211v1 Announce Type: cross  Abstract: Recently, foundation models, particularly large language models (LLMs), have demonstrated an impressive ability to adapt to various tasks by fine-tuning large amounts of instruction data. Notably, federated foundation models emerge as a privacy preservation method to fine-tune models collaboratively under federated learning (FL) settings by leveraging many distributed datasets with non-IID data. To alleviate communication and computation overhead, parameter-efficient methods are introduced for efficiency, and some research adapted personalization methods to federated foundation models for better user preferences alignment. However, a critical gap in existing research is the neglect of test-time distribution shifts in real-world applications. Therefore, to bridge this gap, we propose a new setting, termed test-time personalization, which not only concentrates on the targeted local task but also extends to other tasks that exhibit test-t
    
[^40]: 理解档案：基于文档语义标注的新研究界面

    Understanding Archives: Towards New Research Interfaces Relying on the Semantic Annotation of Documents

    [https://arxiv.org/abs/2403.19201](https://arxiv.org/abs/2403.19201)

    通过语义标注档案文件的文本内容，我们提出了构建新界面的方法论框架，解决了探索和利用文档的困难，以及应对当前技术障碍的潜在解决方案。

    

    近年来图书馆和档案馆进行的数字化活动促进了对其收藏文档的访问。然而，由于可供查阅的文档数量庞大，探索和利用这些文档仍然是困难的任务。在本文中，我们展示了如何通过对档案文件研究语料库的文本内容进行语义标注来促进其利用和价值。首先，我们提出了一个基于文本语义构建新界面的方法论框架，然后讨论当前的技术障碍及其潜在解决方案。最后，我们通过展示该框架的应用实例来总结。

    arXiv:2403.19201v1 Announce Type: cross  Abstract: The digitisation campaigns carried out by libraries and archives in recent years have facilitated access to documents in their collections. However, exploring and exploiting these documents remain difficult tasks due to the sheer quantity of documents available for consultation. In this article, we show how the semantic annotation of the textual content of study corpora of archival documents allow to facilitate their exploitation and valorisation. First, we present a methodological framework for the construction of new interfaces based on textual semantics, then address the current technological obstacles and their potential solutions. We conclude by presenting a practical case of the application of this framework.
    
[^41]: 无监督通用依存句法树聚合的实证分析

    Empirical Analysis for Unsupervised Universal Dependency Parse Tree Aggregation

    [https://arxiv.org/abs/2403.19183](https://arxiv.org/abs/2403.19183)

    通过广泛的实证研究比较不同的无监督后处理聚合方法，以确定最适合的依存树结构聚合方法

    

    依存分析是自然语言处理中的一个重要任务，依存分析器的质量对许多下游任务至关重要。依存分析器的质量通常取决于涉及的领域和语言。因此，解决质量不稳定的问题以实现稳定性能是至关重要的。在各种自然语言处理任务中，聚合方法用于后处理聚合，已被证明可以解决质量不稳定的问题。然而，在依存分析任务中，对于后处理聚合的聚合方法尚未得到充分研究。在广泛的实证研究中，我们比较了不同的无监督后处理聚合方法，以确定最适合的依存树结构聚合方法。

    arXiv:2403.19183v1 Announce Type: new  Abstract: Dependency parsing is an essential task in NLP, and the quality of dependency parsers is crucial for many downstream tasks. Parsers' quality often varies depending on the domain and the language involved. Therefore, it is essential to combat the issue of varying quality to achieve stable performance. In various NLP tasks, aggregation methods are used for post-processing aggregation and have been shown to combat the issue of varying quality. However, aggregation methods for post-processing aggregation have not been sufficiently studied in dependency parsing tasks. In an extensive empirical study, we compare different unsupervised post-processing aggregation methods to identify the most suitable dependency tree structure aggregation method.
    
[^42]: 让大型语言模型成为更好的排名器

    Make Large Language Model a Better Ranker

    [https://arxiv.org/abs/2403.19181](https://arxiv.org/abs/2403.19181)

    本文介绍了一种具有对齐列表排名目标的语言模型框架（ALRO），旨在弥合大型语言模型的能力与推荐系统排名任务的要求之间的差距。

    

    大型语言模型（LLMs）的发展显著增强了各个领域的能力，导致推荐系统（RSs）概念和开发方式发生了转变。然而，现有研究主要集中在点对点和成对推荐范式上。这些方法在基于LLM的推荐器中效率低下，因为利用大型语言模型的计算成本很高。一些研究虽然深入研究了列表型方法，但在排名任务中表现不佳。这一不足归因于排名和语言生成目标之间的不匹配。为此，本文介绍了具有对齐列表排名目标的语言模型框架（ALRO）。ALRO旨在弥合LLMs的能力与推荐系统排名任务的微妙要求之间的差距。ALRO的一个关键特性是引入了软lambda值lo

    arXiv:2403.19181v1 Announce Type: cross  Abstract: The evolution of Large Language Models (LLMs) has significantly enhanced capabilities across various fields, leading to a paradigm shift in how Recommender Systems (RSs) are conceptualized and developed. However, existing research primarily focuses on point-wise and pair-wise recommendation paradigms. These approaches prove inefficient in LLM-based recommenders due to the high computational cost of utilizing Large Language Models. While some studies have delved into list-wise approaches, they fall short in ranking tasks. This shortfall is attributed to the misalignment between the objectives of ranking and language generation. To this end, this paper introduces the Language Model Framework with Aligned Listwise Ranking Objectives (ALRO). ALRO is designed to bridge the gap between the capabilities of LLMs and the nuanced requirements of ranking tasks within recommender systems. A key feature of ALRO is the introduction of soft lambda lo
    
[^43]: 用选择性过滤减轻具有误导性的思维链推理

    Mitigating Misleading Chain-of-Thought Reasoning with Selective Filtering

    [https://arxiv.org/abs/2403.19167](https://arxiv.org/abs/2403.19167)

    提出了一种名为选择性过滤推理器（SelF-Reasoner）的新方法，用于评估问题与候选推理链之间的蕴涵关系，以减轻具有误导性的思维链推理过程。

    

    大型语言模型通过利用思维链推理技术解决复杂问题，展现了卓越的能力。然而，这种推理的效力取决于思维链的质量。为了解决这一挑战，我们提出了一种名为选择性过滤推理器（SelF-Reasoner）的新方法，该方法评估问题与候选推理链之间的蕴涵关系。当推理链展示出自信时，我们继续进行思维链推理；否则，我们选择直接预测答案。SelF-Reasoner在ScienceQA、ECQA和LastLetter任务上持续改善了经过微调的T5基线。

    arXiv:2403.19167v1 Announce Type: cross  Abstract: Large language models have manifested remarkable capabilities by leveraging chain-of-thought (CoT) reasoning techniques to solve intricate questions through step-by-step reasoning chains. Despite its success, the efficacy of such reasoning is inherently contingent upon the quality of CoT. However, flawless CoT reasoning cannot be guaranteed due to the presence of indecomposable questions and the potential for erroneous reasoning chains, particularly in the case of small-scale language models. To tackle this challenge, we propose a novel approach called the selective filtering reasoner (SelF-Reasoner) that assesses the entailment relationship between the question and the candidate reasoning chain. Then, we proceed with CoT reasoning when the reasoning chain demonstrates confidence; otherwise, we opt to predict the answer directly. SelF-Reasoner improves the fine-tuned T5 baseline consistently over the ScienceQA, ECQA, and LastLetter tas
    
[^44]: 改进越南语-英语医学机器翻译

    Improving Vietnamese-English Medical Machine Translation

    [https://arxiv.org/abs/2403.19161](https://arxiv.org/abs/2403.19161)

    介绍了MedEV数据集，通过对比不同的翻译模型在医学领域进行越南语-英语机器翻译，结果显示微调"vinai-translate"获得最佳性能，同时公开数据集促进进一步研究。

    

    在医学领域，越南语-英语的机器翻译仍然是一个未充分探讨的研究领域。本文介绍了MedEV - 一个专为医学领域构建的高质量越南语-英语平行数据集，包括约360K个句对。我们对Google翻译、ChatGPT（gpt-3.5-turbo）、最先进的越南语-英语神经机器翻译模型以及预训练的双语/多语序列到序列模型在我们的新MedEV数据集上进行了广泛实验比较。实验结果表明，通过针对每个翻译方向微调"vinai-translate"能取得最佳性能。我们公开发布了我们的数据集以促进进一步的研究。

    arXiv:2403.19161v1 Announce Type: new  Abstract: Machine translation for Vietnamese-English in the medical domain is still an under-explored research area. In this paper, we introduce MedEV -- a high-quality Vietnamese-English parallel dataset constructed specifically for the medical domain, comprising approximately 360K sentence pairs. We conduct extensive experiments comparing Google Translate, ChatGPT (gpt-3.5-turbo), state-of-the-art Vietnamese-English neural machine translation models and pre-trained bilingual/multilingual sequence-to-sequence models on our new MedEV dataset. Experimental results show that the best performance is achieved by fine-tuning "vinai-translate" for each translation direction. We publicly release our dataset to promote further research.
    
[^45]: 在直接偏好优化中将长度与质量分离

    Disentangling Length from Quality in Direct Preference Optimization

    [https://arxiv.org/abs/2403.19159](https://arxiv.org/abs/2403.19159)

    针对直接偏好优化中的长度问题展开研究，揭示了DPO中显著的利用情况，并将其与分布外引导联系起来。

    

    Reinforcement Learning from Human Feedback (RLHF)是最近大型语言模型成功的关键组成部分。然而，RLHF被认为利用了人类偏好中的偏见，比如冗长性。精心格式化和雄辩的答案通常会被用户更高评价，即使它们在帮助性和客观性上较低。一些方法已经被开发来控制这些偏见，在古典RLHF文献中这个问题已有所探讨，但对于直接对齐算法如直接偏好优化（DPO）这个问题相对较少探索。与古典RLHF不同，DPO不训练单独的奖励模型或直接使用强化学习，因此之前用来控制冗长性的方法无法直接应用于这种情况。我们的工作做出了几点贡献。首次在DPO环境中研究长度问题，显示DPO中存在显著的利用，并将其与分布外引导相关联。

    arXiv:2403.19159v1 Announce Type: new  Abstract: Reinforcement Learning from Human Feedback (RLHF) has been a crucial component in the recent success of Large Language Models. However, RLHF is know to exploit biases in human preferences, such as verbosity. A well-formatted and eloquent answer is often more highly rated by users, even when it is less helpful and objective. A number of approaches have been developed to control those biases in the classical RLHF literature, but the problem remains relatively under-explored for Direct Alignment Algorithms such as Direct Preference Optimization (DPO). Unlike classical RLHF, DPO does not train a separate reward model or use reinforcement learning directly, so previous approaches developed to control verbosity cannot be directly applied to this setting. Our work makes several contributions. For the first time, we study the length problem in the DPO setting, showing significant exploitation in DPO and linking it to out-of-distribution bootstra
    
[^46]: STaR-GATE: 教授语言模型询问澄清问题

    STaR-GATE: Teaching Language Models to Ask Clarifying Questions

    [https://arxiv.org/abs/2403.19154](https://arxiv.org/abs/2403.19154)

    通过奖励语言模型生成有用问题来自我改进的方法，提问者通过询问角色扮演者来引出偏好，从而迭代微调以增加任务高质量响应的概率。

    

    当提示语言模型完成任务时，用户通常会遗漏重要的细节。虽然提问可以解决这种歧义，但模型往往很难提出好问题。我们探讨了语言模型通过奖励模型生成有用问题来自我改进的能力，这是一种简单方法，我们称之为STaR-GATE。我们生成了一个包含25,500个独特人物-任务提示的合成数据集，以模拟预训练语言模型--提问者--与一个其偏好未知的角色扮演者之间的对话。通过提问，提问者从角色扮演者那里引出偏好。提问者在那些增加高质量响应概率的问题上进行迭代微调，这些问题是由具有对角色扮演者访问权限的预言者生成的。

    arXiv:2403.19154v1 Announce Type: cross  Abstract: When prompting language models to complete a task, users often leave important aspects unsaid. While asking questions could resolve this ambiguity \citep[GATE;][]{li2023eliciting}, models often struggle to ask good questions. We explore a language model's ability to self-improve \citep[STaR;][]{zelikman2022star} by rewarding the model for generating useful questions -- a simple method we dub STaR-GATE. We generate a synthetic dataset of 25,500 unique persona-task prompts to simulate conversations between a pretrained language model -- the \texttt{Questioner} -- and a \texttt{Roleplayer} whose preferences are unknown to the \texttt{Questioner}. By asking questions, the \texttt{Questioner} elicits preferences from the \texttt{Roleplayer}. The \texttt{Questioner} is iteratively finetuned on questions that increase the probability of high-quality responses to the task, which are generated by an \texttt{Oracle} with access to the \texttt{Ro
    
[^47]: 用于机器翻译的图鲁语资源

    A Tulu Resource for Machine Translation

    [https://arxiv.org/abs/2403.19142](https://arxiv.org/abs/2403.19142)

    迁移学习方法使得即使源语言和目标语言之间没有平行数据，也能训练出一个机器翻译系统，从而克服了低资源语言机器翻译开发中的一个重大障碍。

    

    我们呈现了第一个用于英语-图鲁语翻译的平行数据集。图鲁语属于南德拉维达语系，主要分布在印度西南部，约有250万人口。我们通过将人类翻译整合到多语种机器翻译资源FLORES-200中来构建我们的数据集。此外，我们利用该数据集来评估开发我们的英语-图鲁语机器翻译模型。在模型的训练中，我们利用了相关南德拉维达语言的资源。我们采用迁移学习方法，利用高资源语言和低资源语言之间的相似性。这种方法使得即使源语言和目标语言之间没有平行数据，也能训练出一个机器翻译系统，从而克服了低资源语言机器翻译开发中的一个重大障碍。我们的英语-图鲁语系统...

    arXiv:2403.19142v1 Announce Type: new  Abstract: We present the first parallel dataset for English-Tulu translation. Tulu, classified within the South Dravidian linguistic family branch, is predominantly spoken by approximately 2.5 million individuals in southwestern India. Our dataset is constructed by integrating human translations into the multilingual machine translation resource FLORES-200. Furthermore, we use this dataset for evaluation purposes in developing our English-Tulu machine translation model. For the model's training, we leverage resources available for related South Dravidian languages. We adopt a transfer learning approach that exploits similarities between high-resource and low-resource languages. This method enables the training of a machine translation system even in the absence of parallel data between the source and target language, thereby overcoming a significant obstacle in machine translation development for low-resource languages. Our English-Tulu system, tr
    
[^48]: 通过简化不重要的层压缩大型语言模型

    Compressing Large Language Models by Streamlining the Unimportant Layer

    [https://arxiv.org/abs/2403.19135](https://arxiv.org/abs/2403.19135)

    通过观察大型语言模型中不同层对隐藏状态的影响程度，提出了LLM-Streamline方法，包括层剪枝和层替换，用于压缩模型并保持性能。

    

    大型语言模型(LLM)已广泛应用于各种自然语言任务和领域，但其适用性受到模型参数的限制。因此，越来越多的人关注表现出高性能的紧凑模型。在这项研究中，我们观察到LLM的不同层对隐藏状态有不同程度的扰动，这使我们能够识别出不那么重要的层。基于这一现象，我们提出了LLM-Streamline，包括两部分：层剪枝，根据目标稀疏度移除模型中一组连续的最不重要的层；层替换，训练一个轻量级模型来替换被剪枝的层，从而缓解由剪枝造成的性能下降。在实验中，我们利用了多层感知器(MLP)和一个transformer层等结构作为轻量级模型。

    arXiv:2403.19135v1 Announce Type: cross  Abstract: Large language models (LLM) have been extensively applied in various natural language tasks and domains, but their applicability is constrained by the large number of parameters of the models. Consequently, there is an increasing emphasis on compact models that exhibit high performance. In this study, we observe that different layers in LLM have varying degrees of perturbation on the hidden states, which allows us to identify less important layers. Based on this phenomenon, we propose LLM-Streamline, which consists of two parts: layer pruning, where we remove a set of consecutive layers with the lowest importance in the model according to the target sparsity; and layer replacement, where we train a lightweight model to substitute the pruned layers, thereby mitigating the performance degradation caused by pruning. In our experiments, we utilize structures such as a multi-layer perceptron (MLP) and a transformer layer as lightweight mode
    
[^49]: 代码大型语言模型的代码比较调优

    Code Comparison Tuning for Code Large Language Models

    [https://arxiv.org/abs/2403.19121](https://arxiv.org/abs/2403.19121)

    提出了一种简单有效的代码比较调优方法，用于改进代码大型语言模型的bug-fixing能力。

    

    我们提出了一种称为代码比较调优（CCT）的简单而有效的调优方法，用于改进代码大型语言模型（Code LLMs）以更好地处理微妙的代码错误。具体而言，我们在指令调优中集成了比较的概念，包括在标记和序列级别上，使模型能够分辨代码中甚至最细微的偏差。为了比较原始代码与包含手动添加的代码错误的错误版本，我们使用标记级别的优先损失进行详细的标记级别比较。此外，我们结合代码段创建新的指令调优样本，用于序列级别比较，增强模型的错误修复能力。在HumanEvalFix基准测试上的实验结果显示，CCT在各种代码LLMs上的pass@1分数比指令调优高出最多4分，并且广泛的分析证明了我们方法的有效性。

    arXiv:2403.19121v1 Announce Type: new  Abstract: We present Code Comparison Tuning (CCT), a simple and effective tuning method for code large language models (Code LLMs) to better handle subtle code errors. Specifically, we integrate the concept of comparison into instruction tuning, both at the token and sequence levels, enabling the model to discern even the slightest deviations in code. To compare the original code with an erroneous version containing manually added code errors, we use token-level preference loss for detailed token-level comparisons. Additionally, we combine code segments to create a new instruction tuning sample for sequence-level comparisons, enhancing the model's bug-fixing capability. Experimental results on the HumanEvalFix benchmark show that CCT surpasses instruction tuning in pass@1 scores by up to 4 points across diverse code LLMs, and extensive analysis demonstrates the effectiveness of our method.
    
[^50]: MFORT-QA: 多跳少样本开放式丰富表格问答

    MFORT-QA: Multi-hop Few-shot Open Rich Table Question Answering

    [https://arxiv.org/abs/2403.19116](https://arxiv.org/abs/2403.19116)

    本文介绍了MFORT-QA方法，通过Few-Shot Learning和大语言模型，实现了在表格数据中进行多跳少样本的开放式丰富问答。

    

    在当今快节奏的行业中，专业人士每天面临着总结大量文档并从中提取关键信息的挑战。这些度量经常隐藏在表格和/或其嵌套的超链接中。为了应对这一挑战，开发了表格问答（QA）方法来提取相关信息。然而，传统的表格QA训练任务并不总是能确保提取准确答案，这些任务会向问题提供一个表格和一个或多个来自黄金单元格坐标的答案。近期大语言模型（LLM）的进展为使用提示从表格数据中提取信息开辟了新的可能性。本文介绍了Multi-hop Few-shot Open Rich Table QA（MFORT-QA）方法，该方法包括两个主要步骤。

    arXiv:2403.19116v1 Announce Type: cross  Abstract: In today's fast-paced industry, professionals face the challenge of summarizing a large number of documents and extracting vital information from them on a daily basis. These metrics are frequently hidden away in tables and/or their nested hyperlinks. To address this challenge, the approach of Table Question Answering (QA) has been developed to extract the relevant information. However, traditional Table QA training tasks that provide a table and an answer(s) from a gold cell coordinate(s) for a question may not always ensure extracting the accurate answer(s). Recent advancements in Large Language Models (LLMs) have opened up new possibilities for extracting information from tabular data using prompts. In this paper, we introduce the Multi-hop Few-shot Open Rich Table QA (MFORT-QA) approach, which consists of two major steps. The first step involves Few-Shot Learning (FSL), where relevant tables and associated contexts of hyperlinks ar
    
[^51]: 顶级排行榜 = 顶级编程能力，永远吗？EvoEval: 通过LLM演化编码基准

    Top Leaderboard Ranking = Top Coding Proficiency, Always? EvoEval: Evolving Coding Benchmarks via LLM

    [https://arxiv.org/abs/2403.19114](https://arxiv.org/abs/2403.19114)

    EvoEval通过将现有基准演化为不同的目标领域，创建了一个新的程序合成基准套件，以充分评估LLM编码能力。

    

    LLM已成为生成代码任务的首选，LLM的训练、开发和使用随着专门用于生成代码的LLM的指数增长而增加。为了评估LLM在编码上的能力，学术界和行业从业者依赖于流行的人工制定的基准。然而，之前的基准只包含了数量和种类非常有限的问题。此外，由于流行度和年龄，许多基准容易发生数据泄漏，其中示例解决方案可以很容易地在网络上找到，因此可能出现在训练数据中。这些限制不可避免地导致我们要探讨：现有基准的排行榜表现是否可靠且全面足以衡量LLM的程序合成能力？为了解决这个问题，我们引入EvoEval--一个通过将现有基准演化为不同的目标领域而创建的程序合成基准套件，用于全面评估LLM编码。

    arXiv:2403.19114v1 Announce Type: cross  Abstract: LLMs have become the go-to choice for code generation tasks, with an exponential increase in the training, development, and usage of LLMs specifically for code generation. To evaluate the ability of LLMs on code, both academic and industry practitioners rely on popular handcrafted benchmarks. However, prior benchmarks contain only a very limited set of problems, both in quantity and variety. Further, due to popularity and age, many benchmarks are prone to data leakage where example solutions can be readily found on the web and thus potentially in training data. Such limitations inevitably lead us to inquire: Is the leaderboard performance on existing benchmarks reliable and comprehensive enough to measure the program synthesis ability of LLMs? To address this, we introduce EvoEval -- a program synthesis benchmark suite created by evolving existing benchmarks into different targeted domains for a comprehensive evaluation of LLM coding a
    
[^52]: FACTOID: 用于幻觉检测的事实推理（FACTOID: FACtual enTailment fOr hallucInation Detection）

    FACTOID: FACtual enTailment fOr hallucInation Detection

    [https://arxiv.org/abs/2403.19113](https://arxiv.org/abs/2403.19113)

    本文表明传统的文本蕴涵方法无法有效地发现大型语言模型生成的内容中存在的幻觉问题。

    

    大型语言模型（LLMs）的广泛应用带来了许多好处，但幻觉是一个重要的问题。为应对这一问题，检索增强生成（RAG）作为一种高度有前途的范式出现，通过在事实信息中接地来提升LLMs的输出。RAG依赖于文本蕴涵（TE）或类似方法，检查LLMs生成的文本是否被检索文档支持或反驳。本文认为传统的TE方法不适用于发现LLMs生成内容中的幻觉。例如，考虑一个关于“美国对乌克兰战争立场”的提示。AI生成的文本表示，“美国总统巴拉克·奥巴马说美国不会派兵进入乌克兰”，然而在战争期间，美国总统是乔·拜登，这与事实不符。此外，当前的TE系统无法准确注释给定的文本和识别幻觉。

    arXiv:2403.19113v1 Announce Type: cross  Abstract: The widespread adoption of Large Language Models (LLMs) has facilitated numerous benefits. However, hallucination is a significant concern. In response, Retrieval Augmented Generation (RAG) has emerged as a highly promising paradigm to improve LLM outputs by grounding them in factual information. RAG relies on textual entailment (TE) or similar methods to check if the text produced by LLMs is supported or contradicted, compared to retrieved documents. This paper argues that conventional TE methods are inadequate for spotting hallucinations in content generated by LLMs. For instance, consider a prompt about the 'USA's stance on the Ukraine war''. The AI-generated text states, ...U.S. President Barack Obama says the U.S. will not put troops in Ukraine...'' However, during the war the U.S. president is Joe Biden which contradicts factual reality. Moreover, current TE systems are unable to accurately annotate the given text and identify th
    
[^53]: 用于个性化文本到图像生成的自动化黑盒提示工程

    Automated Black-box Prompt Engineering for Personalized Text-to-Image Generation

    [https://arxiv.org/abs/2403.19103](https://arxiv.org/abs/2403.19103)

    PRISM是一种算法，可以自动识别人类可解释且易传递的提示，从而有效生成所需概念，仅使用黑盒访问T2I模型。

    

    提示工程对于控制文本到图像（T2I）生成模型的输出是有效的，但由于需要手动制作提示而导致工作繁重。这一挑战促使了自动提示生成算法的发展。然而，这些方法通常在T2I模型之间的可传递性方面遇到困难，需要对基础模型进行白盒访问，并产生非直观的提示。在这项工作中，我们介绍了PRISM，这是一种算法，可以仅使用黑盒访问T2I模型就自动识别人类可解释且易传递的提示，从而有效生成所需概念。受大型语言模型（LLM）越狱的启发，PRISM利用LLM的上下文学习能力来迭代地改进给定参考图像的候选提示分布。我们的实验展示了PRISM在为对象、样式等生成准确提示方面的多样性和有效性。

    arXiv:2403.19103v1 Announce Type: cross  Abstract: Prompt engineering is effective for controlling the output of text-to-image (T2I) generative models, but it is also laborious due to the need for manually crafted prompts. This challenge has spurred the development of algorithms for automated prompt generation. However, these methods often struggle with transferability across T2I models, require white-box access to the underlying model, and produce non-intuitive prompts. In this work, we introduce PRISM, an algorithm that automatically identifies human-interpretable and transferable prompts that can effectively generate desired concepts given only black-box access to T2I models. Inspired by large language model (LLM) jailbreaking, PRISM leverages the in-context learning ability of LLMs to iteratively refine the candidate prompts distribution for given reference images. Our experiments demonstrate the versatility and effectiveness of PRISM in generating accurate prompts for objects, sty
    
[^54]: 没有提示的情况下学习正确性使LLM成为高效推理者

    Learning From Correctness Without Prompting Makes LLM Efficient Reasoner

    [https://arxiv.org/abs/2403.19094](https://arxiv.org/abs/2403.19094)

    本文介绍了一种用于大型语言模型的内在自我修正推理框架LeCo，无需人类反馈、外部工具或手动提示，通过学习正确的推理步骤并基于生成logits来提高推理性能。

    

    大型语言模型（LLMs）在各种任务中表现出色，但仍然存在幻觉、不忠实的推理和有毒内容等局限性。缓解这些问题的一个潜在方法是从人类或外部反馈（例如工具）中学习。本文介绍了一种用于LLMs的内在自我修正推理框架，消除了人类反馈、外部工具和手工提示的需求。提出的框架基于一种多步推理范式Learning from Correctness (LeCo)，在不需要从错误中学习的情况下提高了推理性能。该范式优先学习正确的推理步骤，并基于生成logits来衡量每个推理步骤的置信度。在各种多步推理任务上的实验结果表明，该框架在改善推理方面的有效性。

    arXiv:2403.19094v1 Announce Type: new  Abstract: Large language models (LLMs) have demonstrated outstanding performance across various tasks, yet they still exhibit limitations such as hallucination, unfaithful reasoning, and toxic content. One potential approach to mitigate these issues is learning from human or external feedback (e.g. tools). In this paper, we introduce an intrinsic self-correct reasoning framework for LLMs that eliminates the need for human feedback, external tools, and handcraft prompts. The proposed framework, based on a multi-step reasoning paradigm \textbf{Le}arning from \textbf{Co}rrectness (\textsc{LeCo}), improves reasoning performance without needing to learn from errors. This paradigm prioritizes learning from correct reasoning steps, and a unique method to measure confidence for each reasoning step based on generation logits. Experimental results across various multi-step reasoning tasks demonstrate the effectiveness of the framework in improving reasoning
    
[^55]: CAUSE: 在面向任务型对话系统中利用反事实评估用户满意度估计

    CAUSE: Counterfactual Assessment of User Satisfaction Estimation in Task-Oriented Dialogue Systems

    [https://arxiv.org/abs/2403.19056](https://arxiv.org/abs/2403.19056)

    本文通过利用大型语言模型生成满意感知的反事实对话来增加任务型对话系统的原始对话集合，以改善用户满意度估计的鲁棒性。

    

    先前关于任务型对话系统中用户满意度估计的工作中一个重要但未被探索的方面是对其在识别用户不满意方面的鲁棒性进行评估：当前用于任务型对话系统中用户满意度估计的基准测试高度倾向于用户满意的对话。具有更平衡满意度标签集合对性能的影响是未知的。然而，通过更多的不满对话样本平衡数据需要进一步的数据收集和人工注释，这是昂贵和耗时的。本工作中，我们利用大型语言模型（LLMs）并解锁其生成满意感知反事实对话的能力，以增加测试集合的原始对话集合。我们收集人工注释以确保生成样本的可靠性。我们评估两个开源LLM作为用户满意度估计器。

    arXiv:2403.19056v1 Announce Type: new  Abstract: An important unexplored aspect in previous work on user satisfaction estimation for Task-Oriented Dialogue (TOD) systems is their evaluation in terms of robustness for the identification of user dissatisfaction: current benchmarks for user satisfaction estimation in TOD systems are highly skewed towards dialogues for which the user is satisfied. The effect of having a more balanced set of satisfaction labels on performance is unknown. However, balancing the data with more dissatisfactory dialogue samples requires further data collection and human annotation, which is costly and time-consuming. In this work, we leverage large language models (LLMs) and unlock their ability to generate satisfaction-aware counterfactual dialogues to augment the set of original dialogues of a test collection. We gather human annotations to ensure the reliability of the generated samples. We evaluate two open-source LLMs as user satisfaction estimators on our
    
[^56]: 使用公共社交媒体数据评估大型语言模型在健康相关文本分类任务中的表现

    Evaluating Large Language Models for Health-Related Text Classification Tasks with Public Social Media Data

    [https://arxiv.org/abs/2403.19031](https://arxiv.org/abs/2403.19031)

    综合实验表明，利用LLMs进行数据增强可以...

    

    大型语言模型（LLMs）在NLP任务中展现出卓越的成功。然而，几乎没有研究试图评估它们在基于社交媒体的健康相关自然语言处理任务中的表现，这些任务传统上很难获得高分。我们在6个文本分类任务上对一个基于支持向量机（SVMs）的监督经典机器学习模型，三个基于RoBERTa、BERTweet和SocBERT的监督预训练语言模型（PLMs），以及两个基于GPT3.5和GPT4的LLM分类器进行了基准测试。我们开发了三种利用LLMs进行文本分类的方法：将LLMs用作零次分类器，将LLMs用作注释器为监督分类器注释训练数据，以及利用LLMs进行少量示例来增加手动注释数据。我们全面的实验表明，利用LLMs进行数据增强可以...

    arXiv:2403.19031v1 Announce Type: cross  Abstract: Large language models (LLMs) have demonstrated remarkable success in NLP tasks. However, there is a paucity of studies that attempt to evaluate their performances on social media-based health-related natural language processing tasks, which have traditionally been difficult to achieve high scores in. We benchmarked one supervised classic machine learning model based on Support Vector Machines (SVMs), three supervised pretrained language models (PLMs) based on RoBERTa, BERTweet, and SocBERT, and two LLM based classifiers (GPT3.5 and GPT4), across 6 text classification tasks. We developed three approaches for leveraging LLMs for text classification: employing LLMs as zero-shot classifiers, us-ing LLMs as annotators to annotate training data for supervised classifiers, and utilizing LLMs with few-shot examples for augmentation of manually annotated data. Our comprehensive experiments demonstrate that employ-ing data augmentation using LLM
    
[^57]: 朝向LLM-RecSys对齐与文本ID学习的方向

    Towards LLM-RecSys Alignment with Textual ID Learning

    [https://arxiv.org/abs/2403.19021](https://arxiv.org/abs/2403.19021)

    通过提出IDGen，将每个推荐项目表示为独特、简洁、语义丰富的文本ID，从而使得基于大型语言模型的推荐更好地与自然语言生成对齐。

    

    基于大型语言模型(LLMs)的生成式推荐已经将传统的基于排名的推荐方式转变为文本生成范例。然而，与固有操作人类词汇的标准NLP任务相反，目前生成式推荐领域的研究在如何在文本生成范式中以简洁而有意义的ID表示有效编码推荐项目方面存在困难。为了更好地对齐LLMs与推荐需求，我们提出了IDGen，使用人类语言标记将每个项目表示为独特、简洁、语义丰富、与平台无关的文本ID。这通过在基于LLM的推荐系统旁训练文本ID生成器来实现，使个性化推荐能够无缝集成到自然语言生成中。值得注意的是，由于用户历史记录以自然语言表达并与原始数据集解耦，我们的方法提出了潜在的

    arXiv:2403.19021v1 Announce Type: cross  Abstract: Generative recommendation based on Large Language Models (LLMs) have transformed the traditional ranking-based recommendation style into a text-to-text generation paradigm. However, in contrast to standard NLP tasks that inherently operate on human vocabulary, current research in generative recommendations struggles to effectively encode recommendation items within the text-to-text framework using concise yet meaningful ID representations. To better align LLMs with recommendation needs, we propose IDGen, representing each item as a unique, concise, semantically rich, platform-agnostic textual ID using human language tokens. This is achieved by training a textual ID generator alongside the LLM-based recommender, enabling seamless integration of personalized recommendations into natural language generation. Notably, as user history is expressed in natural language and decoupled from the original dataset, our approach suggests the potenti
    
[^58]: ReflectSumm: 一个用于课程反思摘要的基准数据集

    ReflectSumm: A Benchmark for Course Reflection Summarization

    [https://arxiv.org/abs/2403.19012](https://arxiv.org/abs/2403.19012)

    ReflectSumm是一个旨在总结学生反思性写作的数据集，可以帮助开发和评估针对现实场景的新型摘要技术，为进一步研究提供了基准。

    

    这篇论文介绍了ReflectSumm，一个专门设计用于总结学生反思性写作的新型摘要数据集。ReflectSumm的目标是促进开发和评估针对现实场景的新型摘要技术，这些场景具有少量训练数据，%具有潜在在意见总结领域和特别是教育领域中的影响。该数据集涵盖了各种摘要任务，并包括全面的元数据，可以探索各种研究问题并支持不同的应用。为展示其效用，我们使用多个最先进的基准进行了广泛评估。结果为促进这一领域的进一步研究提供了基准。

    arXiv:2403.19012v1 Announce Type: cross  Abstract: This paper introduces ReflectSumm, a novel summarization dataset specifically designed for summarizing students' reflective writing. The goal of ReflectSumm is to facilitate developing and evaluating novel summarization techniques tailored to real-world scenarios with little training data, %practical tasks with potential implications in the opinion summarization domain in general and the educational domain in particular. The dataset encompasses a diverse range of summarization tasks and includes comprehensive metadata, enabling the exploration of various research questions and supporting different applications. To showcase its utility, we conducted extensive evaluations using multiple state-of-the-art baselines. The results provide benchmarks for facilitating further research in this area.
    
[^59]: "对不起，再次来吗？提示——通过注入[PAUSE]优化改写来增强理解力和减少幻觉"

    "Sorry, Come Again?" Prompting -- Enhancing Comprehension and Diminishing Hallucination with [PAUSE]-injected Optimal Paraphrasing

    [https://arxiv.org/abs/2403.18976](https://arxiv.org/abs/2403.18976)

    介绍了一种新的提示策略“Sorry, Come Again (SCA)”来避免大规模语言模型（LLMs）产生幻觉，通过进行最佳的改写和注入[PAUSE]标记来增强理解力。

    

    Hallucination已经成为当代大规模语言模型（LLMs）中最脆弱的方面。本文介绍了Sorry, Come Again (SCA)提示，旨在通过：(i) 最佳的改写和(ii) 注入[PAUSE]标记来延迟LLMs的生成，以避免LLM产生幻觉。首先，我们对21个LLMs的提示的语言细微差别进行了深入分析：正式性、可读性和具体性，并阐明了这些差别是如何导致产生幻觉的。提示的可读性、正式性或具体性较低会给LLMs带来理解挑战，类似于人类所面临的挑战。在这种情况下，LLM倾向于根据其想象力（联想记忆）推测和生成内容来填补这些信息缺失。尽管这些猜测偶尔可能与事实信息一致，但其准确性并不保证，经常导致幻觉。

    arXiv:2403.18976v1 Announce Type: cross  Abstract: Hallucination has emerged as the most vulnerable aspect of contemporary Large Language Models (LLMs). In this paper, we introduce the Sorry, Come Again (SCA) prompting, aimed to avoid LLM hallucinations by enhancing comprehension through: (i) optimal paraphrasing and (ii) injecting [PAUSE] tokens to delay LLM generation. First, we provide an in-depth analysis of linguistic nuances: formality, readability, and concreteness of prompts for 21 LLMs, and elucidate how these nuances contribute to hallucinated generation. Prompts with lower readability, formality, or concreteness pose comprehension challenges for LLMs, similar to those faced by humans. In such scenarios, an LLM tends to speculate and generate content based on its imagination (associative memory) to fill these information gaps. Although these speculations may occasionally align with factual information, their accuracy is not assured, often resulting in hallucination. Recent st
    
[^60]: 一个使用基于BERT的语言模型的带标注医学影像报告的新语料库

    A Novel Corpus of Annotated Medical Imaging Reports and Information Extraction Results Using BERT-based Language Models

    [https://arxiv.org/abs/2403.18975](https://arxiv.org/abs/2403.18975)

    介绍了一个新的医学影像报告语料库，使用基于BERT的语言模型对报告进行标注，并通过事件化模式捕捉临床指示、病变和医学问题。

    

    医学影像对于诊断、监测和治疗许多健康状况至关重要，包括肿瘤学、神经学、心血管和肌肉骨骼疾病。放射科医师通过叙述性报告来解读这些复杂的、非结构化的影像，并表达他们的评估，这些报告在很大程度上仍然是非结构化的。这种非结构化叙述必须转换为结构化的语义表示，以促进次要应用，例如回顾分析或临床决策支持。在这里，我们介绍了带标注医学影像报告语料库(CAMIR)，其中包括来自三种影像模态类型的609个带标注放射学报告：计算机断层扫描、磁共振成像和正电子发射断层扫描-计算机断层扫描。报告使用基于事件的模式进行标注，捕捉临床指示、病变和医学问题。每个事件包括一个触发器和…

    arXiv:2403.18975v1 Announce Type: new  Abstract: Medical imaging is critical to the diagnosis, surveillance, and treatment of many health conditions, including oncological, neurological, cardiovascular, and musculoskeletal disorders, among others. Radiologists interpret these complex, unstructured images and articulate their assessments through narrative reports that remain largely unstructured. This unstructured narrative must be converted into a structured semantic representation to facilitate secondary applications such as retrospective analyses or clinical decision support. Here, we introduce the Corpus of Annotated Medical Imaging Reports (CAMIR), which includes 609 annotated radiology reports from three imaging modality types: Computed Tomography, Magnetic Resonance Imaging, and Positron Emission Tomography-Computed Tomography. Reports were annotated using an event-based schema that captures clinical indications, lesions, and medical problems. Each event consists of a trigger and
    
[^61]: 一种用于快速准确意图识别的拟合意图分类和澄清框架

    Conformal Intent Classification and Clarification for Fast and Accurate Intent Recognition

    [https://arxiv.org/abs/2403.18973](https://arxiv.org/abs/2403.18973)

    提出了一种拟合意图分类和澄清框架，能够将意图分类器的不确定性分数转化为澄清问题，快速准确地解决用户查询，并具有超出范围检测能力。

    

    我们提出了一种名为拟合意图分类和澄清（CICC）的框架，用于针对任务导向对话系统的快速准确意图分类。该框架将任何意图分类器的启发式不确定性分数转化为一个澄清问题，该问题被保证包含真正意图并且在预定义的置信水平上。通过区分少量可能的意图，用户查询可以快速准确地解决。此外，我们提议扩展该框架以进行超出范围的检测。通过使用七个意图识别数据集进行比较评估，我们发现CICC生成了小型澄清问题并且具有超出范围检测的能力。CICC可以帮助从业者和研究人员大幅改善对话代理的用户体验，通过特定的澄清问题。

    arXiv:2403.18973v1 Announce Type: new  Abstract: We present Conformal Intent Classification and Clarification (CICC), a framework for fast and accurate intent classification for task-oriented dialogue systems. The framework turns heuristic uncertainty scores of any intent classifier into a clarification question that is guaranteed to contain the true intent at a pre-defined confidence level. By disambiguating between a small number of likely intents, the user query can be resolved quickly and accurately. Additionally, we propose to augment the framework for out-of-scope detection. In a comparative evaluation using seven intent recognition datasets we find that CICC generates small clarification questions and is capable of out-of-scope detection. CICC can help practitioners and researchers substantially in improving the user experience of dialogue agents with specific clarification questions.
    
[^62]: 从概念到实现的大型语言模型综述

    A Survey on Large Language Models from Concept to Implementation

    [https://arxiv.org/abs/2403.18969](https://arxiv.org/abs/2403.18969)

    Transformer模型在改革传统任务和推进跨行业研究和开发中产生革命性影响。

    

    最近基于Transformer架构构建的大型语言模型(LLMs)的发展极大拓宽了自然语言处理(NLP)应用的范围，超越了最初在聊天机器人技术中的应用。本文研究了这些模型的多方面应用，着重介绍了GPT系列。这项探索聚焦于人工智能(AI)驱动工具在改革传统编码和问题解决等任务上的革命性影响，同时在跨越不同行业的研究和开发中开辟新路径。从代码解释和图像描述到促进交互式系统的搭建和推进计算领域，Transformer模型体现了深度学习、数据分析和神经网络设计的协同作用。本综述深入探讨了Transformer模型的最新研究，突出了

    arXiv:2403.18969v1 Announce Type: cross  Abstract: Recent advancements in Large Language Models (LLMs), particularly those built on Transformer architectures, have significantly broadened the scope of natural language processing (NLP) applications, transcending their initial use in chatbot technology. This paper investigates the multifaceted applications of these models, with an emphasis on the GPT series. This exploration focuses on the transformative impact of artificial intelligence (AI) driven tools in revolutionizing traditional tasks like coding and problem-solving, while also paving new paths in research and development across diverse industries. From code interpretation and image captioning to facilitating the construction of interactive systems and advancing computational domains, Transformer models exemplify a synergy of deep learning, data analysis, and neural network design. This survey provides an in-depth look at the latest research in Transformer models, highlighting the
    
[^63]: 利用大规模视觉语言模型调节不安全用户生成内容游戏中的违法在线图片推广

    Moderating Illicit Online Image Promotion for Unsafe User-Generated Content Games Using Large Vision-Language Models

    [https://arxiv.org/abs/2403.18957](https://arxiv.org/abs/2403.18957)

    该研究旨在调查不安全用户生成内容游戏中的违法推广威胁，收集了一组包含性暴力和暴力内容的真实图像数据集。

    

    在线用户生成内容游戏（UGCGs）在儿童和青少年中越来越受欢迎，用于社交互动和更有创意的在线娱乐。然而，它们存在着更高的暴露不良内容的风险，引发了人们对儿童和青少年在线安全的日益关注。我们采取了第一步研究对不安全UGCGs的违法推广进行威胁性分析。我们收集了一组现实世界数据集，包括2,924张展示不同性暴力和暴力内容的图像，这些内容被游戏创建者用于推广UGCGs。

    arXiv:2403.18957v1 Announce Type: cross  Abstract: Online user-generated content games (UGCGs) are increasingly popular among children and adolescents for social interaction and more creative online entertainment. However, they pose a heightened risk of exposure to explicit content, raising growing concerns for the online safety of children and adolescents. Despite these concerns, few studies have addressed the issue of illicit image-based promotions of unsafe UGCGs on social media, which can inadvertently attract young users. This challenge arises from the difficulty of obtaining comprehensive training data for UGCG images and the unique nature of these images, which differ from traditional unsafe content. In this work, we take the first step towards studying the threat of illicit promotions of unsafe UGCGs. We collect a real-world dataset comprising 2,924 images that display diverse sexually explicit and violent content used to promote UGCGs by their game creators. Our in-depth studi
    
[^64]: 将自由文本放射学笔记转变为具有生成变换器的结构化报告

    Reshaping Free-Text Radiology Notes Into Structured Reports With Generative Transformers

    [https://arxiv.org/abs/2403.18938](https://arxiv.org/abs/2403.18938)

    提出了一个从自由文本放射学报告中提取信息的流程，利用自然语言处理（NLP）和基于Transformer的模型来处理自动的SR注册表填写。

    

    背景：放射学报告通常以自由文本格式编写，使临床信息难以提取和使用。 最近，各种医学学会推荐采用结构化报告（SR），由于其提供的优势（如标准化、完整性和信息检索），结构化报告（SR）的采用得到了推荐。 我们提出了一个从自由文本放射学报告中提取信息的流程，与一个国家介入和医学放射学会提出的参考SR注册表项目相匹配，重点放在对具有淋巴瘤的患者进行CT分期上。

    arXiv:2403.18938v1 Announce Type: cross  Abstract: BACKGROUND: Radiology reports are typically written in a free-text format, making clinical information difficult to extract and use. Recently the adoption of structured reporting (SR) has been recommended by various medical societies thanks to the advantages it offers, e.g. standardization, completeness and information retrieval. We propose a pipeline to extract information from free-text radiology reports, that fits with the items of the reference SR registry proposed by a national society of interventional and medical radiology, focusing on CT staging of patients with lymphoma. METHODS: Our work aims to leverage the potential of Natural Language Processing (NLP) and Transformer-based models to deal with automatic SR registry filling. With the availability of 174 radiology reports, we investigate a rule-free generative Question Answering approach based on a domain-specific version of T5 (IT5). Two strategies (batch-truncation and ex-p
    
[^65]: SemEval任务1：非洲和亚洲语言的语义文本相关性

    SemEval Task 1: Semantic Textual Relatedness for African and Asian Languages

    [https://arxiv.org/abs/2403.18933](https://arxiv.org/abs/2403.18933)

    这个任务涉及14种非洲和亚洲语言的语义文本相关性，旨在考察跨语言的语义相关性现象。

    

    我们介绍了第一个关于语义文本相关性（STR）的共享任务。而先前的共享任务主要关注语义相似性，我们则调查了跨越14种语言（包括南非荷兰语、阿尔及利亚阿拉伯语、阿姆哈拉语、英语、豪萨语、印地语、印尼语、基尼亚鲁安达语、马拉地语、摩洛哥阿拉伯语、现代标准阿拉伯语、旁遮普语、西班牙语和泰卢固语）的更广泛的语义相关性现象。这些语言来自五个不同的语系，并主要在非洲和亚洲地区使用，这些地区的特点是自然语言处理资源的相对有限。数据集中的每个实例都是一个与分数相关联的句对，该分数表示两个句子之间的语义文本相关程度。参与系统被要求在三个主要轨道中的14种语言中按它们在意义上的接近程度（即它们的语义相关性程度）对句对进行排名：(a) 监督，(b) 无监督

    arXiv:2403.18933v1 Announce Type: new  Abstract: We present the first shared task on Semantic Textual Relatedness (STR). While earlier shared tasks primarily focused on semantic similarity, we instead investigate the broader phenomenon of semantic relatedness across 14 languages: Afrikaans, Algerian Arabic, Amharic, English, Hausa, Hindi, Indonesian, Kinyarwanda, Marathi, Moroccan Arabic, Modern Standard Arabic, Punjabi, Spanish, and Telugu. These languages originate from five distinct language families and are predominantly spoken in Africa and Asia -- regions characterised by the relatively limited availability of NLP resources. Each instance in the datasets is a sentence pair associated with a score that represents the degree of semantic textual relatedness between the two sentences. Participating systems were asked to rank sentence pairs by their closeness in meaning (i.e., their degree of semantic relatedness) in the 14 languages in three main tracks: (a) supervised, (b) unsupervi
    
[^66]: 在大型语言模型中测量政治偏见：言论内容和表达方式分析

    Measuring Political Bias in Large Language Models: What Is Said and How It Is Said

    [https://arxiv.org/abs/2403.18932](https://arxiv.org/abs/2403.18932)

    提出通过分析大型语言模型生成的政治议题内容和风格来测量其政治偏见，主张应该有由大型语言模型生成的政治偏见的细粒度和可解释性衡量。

    

    我们提出通过分析大型语言模型生成的政治议题内容和风格来测量其政治偏见。现有的基准和测量方法关注性别和种族偏见，但是大型语言模型中存在政治偏见，可能导致下游应用中的极化和其他危害。为了向用户提供透明度，我们主张应该有由大型语言模型生成的政治偏见的细粒度和可解释性测量。我们提出的测量方法既考虑了生殖权利和气候变化等不同政治议题的内容（生成物的实质），也考虑了这种偏见的风格（词汇的极性）。我们测量了十一个开源大型语言模型的政治偏见，并展示了我们提出的框架在扩展到其他主题时既易于扩展又具有可解释性。

    arXiv:2403.18932v1 Announce Type: cross  Abstract: We propose to measure political bias in LLMs by analyzing both the content and style of their generated content regarding political issues. Existing benchmarks and measures focus on gender and racial biases. However, political bias exists in LLMs and can lead to polarization and other harms in downstream applications. In order to provide transparency to users, we advocate that there should be fine-grained and explainable measures of political biases generated by LLMs. Our proposed measure looks at different political issues such as reproductive rights and climate change, at both the content (the substance of the generation) and the style (the lexical polarity) of such bias. We measured the political bias in eleven open-sourced LLMs and showed that our proposed framework is easily scalable to other topics and is explainable.
    
[^67]: 用更稀疏的选择提高稀疏模型的效率

    Enhancing Efficiency in Sparse Models with Sparser Selection

    [https://arxiv.org/abs/2403.18926](https://arxiv.org/abs/2403.18926)

    提出了一种新颖的MoE模型\tool，通过利用小型专家和基于阈值的路由器，使标记能够选择性地仅涉及到必要的参数，从而在减少MoE层计算负载50%以上的同时提高模型性能。

    

    稀疏模型，包括稀疏的专家混合（MoE）模型，已经成为缩放Transformer模型的有效方法。然而，它们通常存在计算效率低的问题，因为大量参数通过将值乘以零或低激活值无谓参与计算。为了解决这一问题，我们提出了一种名为\tool 的新颖MoE模型，旨在提升稀疏MoE模型的功效和效率。 \tool 利用小型专家和基于阈值的路由器，使标记能够选择性地仅涉及到必要的参数。我们在语言建模和机器翻译任务上进行了大量实验，结果表明\tool 可以在不牺牲性能的情况下，将MoE层的计算负载减少50\%以上，同时提高模型性能。此外，我们展示了\tool 的通用性，通过将其应用于密集模型，在推断期间实现稀疏计算。

    arXiv:2403.18926v1 Announce Type: cross  Abstract: Sparse models, including sparse Mixture-of-Experts (MoE) models, have emerged as an effective approach for scaling Transformer models. However, they often suffer from computational inefficiency since a significant number of parameters are unnecessarily involved in computations via multiplying values by zero or low activation values. To address this issue, we present \tool, a novel MoE designed to enhance both the efficacy and efficiency of sparse MoE models. \tool leverages small experts and a threshold-based router to enable tokens to selectively engage only essential parameters. Our extensive experiments on language modeling and machine translation tasks demonstrate that \tool can enhance model performance while decreasing the computation load at MoE layers by over 50\% without sacrificing performance. Furthermore, we present the versatility of \tool by applying it to dense models, enabling sparse computation during inference. We pro
    
[^68]: 编码器LLMs骨干的定向可视化

    Targeted Visualization of the Backbone of Encoder LLMs

    [https://arxiv.org/abs/2403.18872](https://arxiv.org/abs/2403.18872)

    本文研究了将DeepView方法应用于自然语言处理领域，以减少编码器模型存在的风险并解释模型决策过程。

    

    基于注意力机制的大型语言模型(LLMs)是自然语言处理(NLP)中的最新技术。其中最常见的两种架构是编码器，如BERT，和解码器，如GPT模型。尽管编码器模型取得了成功，但它们也存在一些风险，包括偏见问题或易受对抗性攻击的影响，这表明了需要可解释的AI来检测这些问题。虽然目前存在各种关注预测单个输入的局部可解释性方法，但基于降维的用于分类检查的全局方法，并且在其他领域出现并超越仅在嵌入空间中使用t-SNE的方法，在NLP中并不十分广泛传播。为了缩小这一差距，我们研究了DeepView方法在NLP领域的应用，该方法用于在二维中可视化决策函数的一部分以及数据集。

    arXiv:2403.18872v1 Announce Type: cross  Abstract: Attention based Large Language Models (LLMs) are the state-of-the-art in natural language processing (NLP). The two most common architectures are encoders such as BERT, and decoders like the GPT models. Despite the success of encoder models, on which we focus in this work, they also bear several risks, including issues with bias or their susceptibility for adversarial attacks, signifying the necessity for explainable AI to detect such issues. While there does exist various local explainability methods focusing on the prediction of single inputs, global methods based on dimensionality reduction for classification inspection, which have emerged in other domains and that go further than just using t-SNE in the embedding space, are not widely spread in NLP.   To reduce this gap, we investigate the application of DeepView, a method for visualizing a part of the decision function together with a data set in two dimensions, to the NLP domain.
    
[^69]: JEP-KD：基于联合嵌入预测架构的视觉语音识别知识蒸馏

    JEP-KD: Joint-Embedding Predictive Architecture Based Knowledge Distillation for Visual Speech Recognition

    [https://arxiv.org/abs/2403.18843](https://arxiv.org/abs/2403.18843)

    该论文提出了一种基于联合嵌入预测架构的知识蒸馏方法JEP-KD，旨在通过引入生成网络在嵌入层内增强视频编码器的语义特征提取能力，从而更有效地利用音频特征，逐步减少视觉语音识别与自动语音识别之间的性能差距。

    

    视觉语音识别（VSR）任务通常被认为具有比自动语音识别（ASR）更低的理论性能上限，这是由于通过视觉方式传达语义信息的固有限制。为了减轻这一挑战，本文介绍了一种先进的知识蒸馏方法，使用一个名为JEP-KD的Joint-Embedding Predictive Architecture（JEPA），旨在更有效地利用音频特征进行模型训练。JEP-KD的核心在于在嵌入层内包含一个生成网络，增强了视频编码器对语义特征提取的能力，并使其与预先训练的ASR模型编码器的音频特征更加接近。该方法旨在逐渐减少VSR和ASR之间的性能差距。此外，还建立了一套全面的多模态、多阶段训练方案，以增强JEP-KD框架的稳健性。

    arXiv:2403.18843v1 Announce Type: cross  Abstract: Visual Speech Recognition (VSR) tasks are generally recognized to have a lower theoretical performance ceiling than Automatic Speech Recognition (ASR), owing to the inherent limitations of conveying semantic information visually. To mitigate this challenge, this paper introduces an advanced knowledge distillation approach using a Joint-Embedding Predictive Architecture (JEPA), named JEP-KD, designed to more effectively utilize audio features during model training. Central to JEP-KD is the inclusion of a generative network within the embedding layer, which enhances the video encoder's capacity for semantic feature extraction and brings it into closer alignment with the audio features from a pre-trained ASR model's encoder. This approach aims to progressively reduce the performance gap between VSR and ASR. Moreover, a comprehensive multimodal, multistage training regimen for the JEP-KD framework is established, bolstering the robustness 
    
[^70]: 在多模态大型语言模型中量化和减轻单模态偏差：因果关系视角

    Quantifying and Mitigating Unimodal Biases in Multimodal Large Language Models: A Causal Perspective

    [https://arxiv.org/abs/2403.18346](https://arxiv.org/abs/2403.18346)

    提出了一个因果框架用于解释多模态大型语言模型在视觉问答问题中的偏差，并引入了一个新的挑战性数据集MORE，同时提出两种减轻单模态偏差的策略。

    

    大型语言模型（LLMs）的最新进展促进了多模态LLMs（MLLMs）的发展。尽管它们具有令人印象深刻的能力，但MLLMs通常过度依赖单模态偏差（例如语言偏差和视觉偏差），导致在复杂多模态任务中给出不正确答案。为了调查这个问题，我们提出了一个因果框架来解释视觉问答（VQA）问题中的偏差。在我们的框架内，我们设计了一个因果图来阐明MLLMs对VQA问题的预测，并通过深入的因果分析评估偏差的因果效果。受因果图的启发，我们引入了一个新颖的MORE数据集，包含12,000个VQA实例。该数据集旨在挑战MLLMs的能力，需要多跳推理和克服单模态偏差。此外，我们提出了两种策略来减轻单模态偏差并增强MLLMs的推理能力。

    arXiv:2403.18346v1 Announce Type: new  Abstract: Recent advancements in Large Language Models (LLMs) have facilitated the development of Multimodal LLMs (MLLMs). Despite their impressive capabilities, MLLMs often suffer from an over-reliance on unimodal biases (e.g., language bias and vision bias), leading to incorrect answers in complex multimodal tasks. To investigate this issue, we propose a causal framework to interpret the biases in Visual Question Answering (VQA) problems. Within our framework, we devise a causal graph to elucidate the predictions of MLLMs on VQA problems, and assess the causal effect of biases through an in-depth causal analysis. Motivated by the causal graph, we introduce a novel MORE dataset, consisting of 12,000 VQA instances. This dataset is designed to challenge MLLMs' abilities, necessitating multi-hop reasoning and the surmounting of unimodal biases. Furthermore, we propose two strategies to mitigate unimodal biases and enhance MLLMs' reasoning capabiliti
    
[^71]: 中国 offensive 语言检测：现状与未来方向

    Chinese Offensive Language Detection:Current Status and Future Directions

    [https://arxiv.org/abs/2403.18314](https://arxiv.org/abs/2403.18314)

    总体而言，这篇论文讨论了在中文中检测 offensive 语言的挑战，并强调了开发解决这一问题的特定模型和工具。

    

    虽然社交媒体平台正在做出相当大的努力监测和规范用户生成内容，但在数字空间中，恶意语言（如仇恨言论或网络欺凌）的普遍存在仍然是一个重要挑战。鉴于维护文明和尊重的在线环境的重要性，迫切需要能够实时检测恶意言论的自动系统。然而，为了开发处理汉语等语言的有效系统，面临着重大挑战，因为这些语言的复杂和微妙性使得自动处理变得困难。本文全面总结了中国 offensive 语言检测情况，审查了当前的基准和方法，并重点介绍了用于解决在这种复杂语言中检测恶意语言的独特挑战的特定模型和工具。

    arXiv:2403.18314v1 Announce Type: cross  Abstract: Despite the considerable efforts being made to monitor and regulate user-generated content on social media platforms, the pervasiveness of offensive language, such as hate speech or cyberbullying, in the digital space remains a significant challenge. Given the importance of maintaining a civilized and respectful online environment, there is an urgent and growing need for automatic systems capable of detecting offensive speech in real time. However, developing effective systems for processing languages such as Chinese presents a significant challenge, owing to the language's complex and nuanced nature, which makes it difficult to process automatically. This paper provides a comprehensive overview of offensive language detection in Chinese, examining current benchmarks and approaches and highlighting specific models and tools for addressing the unique challenges of detecting offensive language in this complex language. The primary object
    
[^72]: 噢！我们冷冻：通过信号传播分析改进大型语言模型的量化知识蒸馏

    Oh! We Freeze: Improving Quantized Knowledge Distillation via Signal Propagation Analysis for Large Language Models

    [https://arxiv.org/abs/2403.18159](https://arxiv.org/abs/2403.18159)

    通过信号传播分析，提出了一种改进大型语言模型的量化知识蒸馏方法，并提供了ov-freeze稳定KD-QAT过程的洞察。

    

    大型生成模型，如大型语言模型（LLMs）和扩散模型分别在NLP和计算机视觉领域引起了革命。然而，它们的推理速度慢，计算和内存需求高，这使得在边缘设备上部署它们变得具有挑战性。在这项研究中，我们提出了一种轻量级的量化感知微调技术，使用知识蒸馏（KD-QAT）来改善使用常用数据集改进4位重量量化的LLMs的性能，以实现流行的语言使用案例，在设备聊天应用中。为了改进这种微调范式，作为主要贡献，我们通过经验研究训练过程中的梯度传播，提供对KD-QAT稳定性的洞察，以更好地理解基于KD-QAT的方法对低位量化误差的脆弱性。根据我们的见解，我们提出了ov-freeze，一种稳定KD-QAT过程的简单技术。最后，我们进行了实验

    arXiv:2403.18159v1 Announce Type: cross  Abstract: Large generative models, such as large language models (LLMs) and diffusion models have as revolutionized the fields of NLP and computer vision respectively. However, their slow inference, high computation and memory requirement makes it challenging to deploy them on edge devices. In this study, we propose a light-weight quantization aware fine tuning technique using knowledge distillation (KD-QAT) to improve the performance of 4-bit weight quantized LLMs using commonly available datasets to realize a popular language use case, on device chat applications. To improve this paradigm of finetuning, as main contributions, we provide insights into stability of KD-QAT by empirically studying the gradient propagation during training to better understand the vulnerabilities of KD-QAT based approaches to low-bit quantization errors. Based on our insights, we propose ov-freeze, a simple technique to stabilize the KD-QAT process. Finally, we expe
    
[^73]: 通过特定掩码损失改善预训练语言模型的敏感性：以生物医学实体识别为例

    Improving Pre-trained Language Model Sensitivity via Mask Specific losses: A case study on Biomedical NER

    [https://arxiv.org/abs/2403.18025](https://arxiv.org/abs/2403.18025)

    提出了Mask Specific Language Modeling（MSLM）方法来改善LM在微调过程中对目标领域知识的敏感性，通过加权领域特定术语的重要性进行学习。

    

    将语言模型（LMs）调整到新领域通常通过在特定领域数据上微调预训练LM（PLM）来实现。微调将新知识引入LM，使它能够理解和有效执行目标域任务。然而，微调可能会无意中变得不够敏感，如果它忽视了源域和目标域之间的广泛差异（例如在词义上）。为了解决微调不敏感的问题，我们提出了Mask Specific Language Modeling（MSLM），一种通过在微调过程中适当加权领域特定术语（DS-terms）的重要性来有效获取目标领域知识的方法。MSLM同时屏蔽DS术语和通用词，然后通过确保LM受到更大惩罚来学习特定于掩码的损失。

    arXiv:2403.18025v1 Announce Type: cross  Abstract: Adapting language models (LMs) to novel domains is often achieved through fine-tuning a pre-trained LM (PLM) on domain-specific data. Fine-tuning introduces new knowledge into an LM, enabling it to comprehend and efficiently perform a target domain task. Fine-tuning can however be inadvertently insensitive if it ignores the wide array of disparities (e.g in word meaning) between source and target domains. For instance, words such as chronic and pressure may be treated lightly in social conversations, however, clinically, these words are usually an expression of concern. To address insensitive fine-tuning, we propose Mask Specific Language Modeling (MSLM), an approach that efficiently acquires target domain knowledge by appropriately weighting the importance of domain-specific terms (DS-terms) during fine-tuning. MSLM jointly masks DS-terms and generic words, then learns mask-specific losses by ensuring LMs incur larger penalties for in
    
[^74]: DORE：一份用于葡萄牙语定义生成的数据集

    DORE: A Dataset For Portuguese Definition Generation

    [https://arxiv.org/abs/2403.18018](https://arxiv.org/abs/2403.18018)

    DORE是第一个用于葡萄牙语的定义生成数据集，填补了这一领域的空白，包含超过10万个定义，并评估了多种基于深度学习的模型。

    

    arXiv:2403.18018v1 公告类型：新的 摘要：定义建模（DM）是自动为特定单词生成词典定义的任务。具有DM能力的计算系统可以在多个受众中受益，因为DM被视为监督自然语言生成问题，这些系统需要大量带注释的数据集来训练机器学习（ML）模型。已经发布了一些用于英语和其他高资源语言的DM数据集。尽管葡萄牙语在大多数自然语言处理任务中被认为是一种中/高资源语言，且被2亿多母语人口使用，但目前尚无葡萄牙语的DM数据集。在这项研究中，我们通过引入DORE填补了这一空白；这是第一个用于葡萄牙语的定义建模数据集，包含超过10万个定义。我们还在DORE上评估了几种基于深度学习的DM模型，并报告了结果。

    arXiv:2403.18018v1 Announce Type: new  Abstract: Definition modelling (DM) is the task of automatically generating a dictionary definition for a specific word. Computational systems that are capable of DM can have numerous applications benefiting a wide range of audiences. As DM is considered a supervised natural language generation problem, these systems require large annotated datasets to train the machine learning (ML) models. Several DM datasets have been released for English and other high-resource languages. While Portuguese is considered a mid/high-resource language in most natural language processing tasks and is spoken by more than 200 million native speakers, there is no DM dataset available for Portuguese. In this research, we fill this gap by introducing DORE; the first dataset for Definition MOdelling for PoRtuguEse containing more than 100,000 definitions. We also evaluate several deep learning based DM models on DORE and report the results. The dataset and the findings o
    
[^75]: LISA：用于高效内存大型语言模型微调的逐层重要性采样

    LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning

    [https://arxiv.org/abs/2403.17919](https://arxiv.org/abs/2403.17919)

    逐层重要性采样的新方法LISA在微调任务中表现出色，记忆成本低且优于传统方法。

    

    机器学习领域自大型语言模型（LLMs）首次出现以来取得了令人瞩目的进展，然而它们巨大的内存消耗已成为大规模训练的主要障碍。虽然已经提出了诸如低秩调整（LoRA）之类的参数高效微调技术来缓解这一问题，但在大多数大规模微调设置中，它们的性能仍无法与完整参数训练相匹配。为弥补这一不足，我们研究了LoRA在微调任务中的逐层特性，并观察到不同层之间权重范数的异常偏斜。利用这一关键观察，我们发现了一个令人惊讶简单的训练策略，在记忆成本低于LoRA的情况下，在广泛的设置中优于LoRA和完整参数训练。我们将其命名为Layerwise Importance Sampled AdamW（LISA），这是LoRA的一个有希望的替代方案，应用了

    arXiv:2403.17919v1 Announce Type: cross  Abstract: The machine learning community has witnessed impressive advancements since the first appearance of large language models (LLMs), yet their huge memory consumption has become a major roadblock to large-scale training. Parameter Efficient Fine-Tuning techniques such as Low-Rank Adaptation (LoRA) have been proposed to alleviate this problem, but their performance still fails to match full parameter training in most large-scale fine-tuning settings. Attempting to complement this deficiency, we investigate layerwise properties of LoRA on fine-tuning tasks and observe an uncommon skewness of weight norms across different layers. Utilizing this key observation, a surprisingly simple training strategy is discovered, which outperforms both LoRA and full parameter training in a wide range of settings with memory costs as low as LoRA. We name it Layerwise Importance Sampled AdamW (LISA), a promising alternative for LoRA, which applies the idea of
    
[^76]: 多项选择题是否真的能够检测LLMs的能力？

    Can multiple-choice questions really be useful in detecting the abilities of LLMs?

    [https://arxiv.org/abs/2403.17752](https://arxiv.org/abs/2403.17752)

    多项选择题虽然被广泛用于评估大型语言模型，但在测试LLMs能力时存在一定局限性，特别是在需要长篇生成答案的情况下，我们发现LLMs在双语MCQs中表现出顺序敏感性。

    

    多项选择题(MCQs)由于其简单和高效而被广泛用于评估大型语言模型(LLMs)。然而，人们对于MCQs是否能真正衡量LLMs的能力存在疑虑，特别是在需要长篇生成(LFG)答案的知识密集型场景中。任务与评估方法之间的不匹配需要对MCQ的效用进行深入分析，而我们在本文中通过评估两种语言（中文和英文）的四个问答(QA)数据集上的九个LLMs来进行。我们发现一个重要问题：LLMs在双语MCQs中表现出一种顺序敏感性，偏向于位于特定位置的答案，即第一个位置。我们通过比较直接输出、token logit和嵌入来量化MCQs和长篇生成问题(LFGQs)之间的差距。我们的结果显示MCQs和长篇生成的答案之间存在相对较低的相关性。

    arXiv:2403.17752v1 Announce Type: new  Abstract: Multiple-choice questions (MCQs) are widely used in the evaluation of large language models (LLMs) due to their simplicity and efficiency. However, there are concerns about whether MCQs can truly measure LLM's capabilities, particularly in knowledge-intensive scenarios where long-form generation (LFG) answers are required. The misalignment between the task and the evaluation method demands a thoughtful analysis of MCQ's efficacy, which we undertake in this paper by evaluating nine LLMs on four question-answering (QA) datasets in two languages: Chinese and English. We identify a significant issue: LLMs exhibit an order sensitivity in bilingual MCQs, favoring answers located at specific positions, i.e., the first position. We further quantify the gap between MCQs and long-form generation questions (LFGQs) by comparing their direct outputs, token logits, and embeddings. Our results reveal a relatively low correlation between answers from MC
    
[^77]: DANCER：针对自动语音识别的实体描述增强命名实体校正器

    DANCER: Entity Description Augmented Named Entity Corrector for Automatic Speech Recognition

    [https://arxiv.org/abs/2403.17645](https://arxiv.org/abs/2403.17645)

    DANCER提出了一种新颖的Description Augmented Named entity CorrEctoR（DANCER）模型，通过利用实体描述为自动语音识别中的NEC提供额外信息，帮助缓解NE列表中的音素混淆问题。

    

    最近提出了一系列用于ASR的快速轻量级命名实体校正（NEC）模型，通常构建在音素级编辑距离算法基础上，并展现出令人印象深刻的NEC性能。然而，随着命名实体（NE）列表的增加，NE列表中的音素混淆问题变得更加严重；例如，同音异义词的问题大大增加。鉴此，我们提出了一种新颖的描述增强型命名实体校正器（称为DANCER），利用实体描述提供额外信息，以便在ASR转录中为NEC提供辅助减轻音素混淆。

    arXiv:2403.17645v1 Announce Type: new  Abstract: End-to-end automatic speech recognition (E2E ASR) systems often suffer from mistranscription of domain-specific phrases, such as named entities, sometimes leading to catastrophic failures in downstream tasks. A family of fast and lightweight named entity correction (NEC) models for ASR have recently been proposed, which normally build on phonetic-level edit distance algorithms and have shown impressive NEC performance. However, as the named entity (NE) list grows, the problems of phonetic confusion in the NE list are exacerbated; for example, homophone ambiguities increase substantially. In view of this, we proposed a novel Description Augmented Named entity CorrEctoR (dubbed DANCER), which leverages entity descriptions to provide additional information to facilitate mitigation of phonetic confusion for NEC on ASR transcription. To this end, an efficient entity description augmented masked language model (EDA-MLM) comprised of a dense re
    
[^78]: 逐步合成：工具、模板和LLM作为数据生成器用于基于推理的图表VQA

    Synthesize Step-by-Step: Tools, Templates and LLMs as Data Generators for Reasoning-Based Chart VQA

    [https://arxiv.org/abs/2403.16385](https://arxiv.org/abs/2403.16385)

    使用LLM作为数据生成器，通过逐步合成策略将复杂问题分解为逐步子问题，利用外部工具生成最终答案，以解决图表VQA模型在复杂推理问题上的表现不佳。

    

    理解图表和图形等数据可视化需要对视觉元素和数字进行推理。尽管在提取式问题上表现出色，但当前的图表视觉问答（chart VQA）模型在复杂推理问题上表现不佳。本文通过数据增强来解决推理能力不足的问题。我们利用已经表现出强大推理能力的大型语言模型（LLMs）作为自动数据标注器，为图表图像生成问题-答案注释。我们方法的关键创新在于“逐步合成”策略：基于LLM的数据生成器学习将复杂问题分解为逐步子问题（原理），然后使用外部工具（即Python）推导出最终答案。这种逐步生成过程是在使用基于模板的QA生成管道生成的合成数据上训练的。实验结果突出显示

    arXiv:2403.16385v1 Announce Type: cross  Abstract: Understanding data visualizations like charts and plots requires reasoning about both visual elements and numerics. Although strong in extractive questions, current chart visual question answering (chart VQA) models suffer on complex reasoning questions. In this work, we address the lack of reasoning ability by data augmentation. We leverage Large Language Models (LLMs), which have shown to have strong reasoning ability, as an automatic data annotator that generates question-answer annotations for chart images. The key innovation in our method lies in the Synthesize Step-by-Step strategy: our LLM-based data generator learns to decompose the complex question into step-by-step sub-questions (rationales), which are then used to derive the final answer using external tools, i.e. Python. This step-wise generation procedure is trained on synthetic data generated using a template-based QA generation pipeline. Experimental results highlight th
    
[^79]: WoLF: 用于胸部X线图理解的大型语言模型框架

    WoLF: Large Language Model Framework for CXR Understanding

    [https://arxiv.org/abs/2403.15456](https://arxiv.org/abs/2403.15456)

    WoLF框架提出了对于CXR的全面理解的改进，包括使用额外的健康相关数据、重构报告以提供更有组织的信息、以及改进生成答案的细致评估。

    

    通过现代视觉语言模型(VLMs)取得了对胸部X线图(CXR)理解方面的显着方法进展，展示了令人印象深刻的视觉问答(VQA)和CXR报告生成能力。然而，现有的CXR理解框架仍存在几个程序上的缺陷。(1)以往的方法仅使用CXR报告，这对于全面的视觉问答(VQA)来说是不够的，特别是当需要额外的健康相关数据如用药历史和先前的诊断时。(2)以往的方法使用未经处理的CXR报告，这些报告往往结构随意。虽然现代语言模型可以理解各种文本格式，但为了提供更清晰、有组织的基于解剖学的信息，重构报告可能会增强它们的实用性。(3)目前用于CXR-VQA的评估方法主要强调语言正确性，缺乏对生成答案的微妙评估能力。

    arXiv:2403.15456v1 Announce Type: new  Abstract: Significant methodological strides have been made toward Chest X-ray (CXR) understanding via modern vision-language models (VLMs), demonstrating impressive Visual Question Answering (VQA) and CXR report generation abilities. However, existing CXR understanding frameworks still possess several procedural caveats. (1) Previous methods solely use CXR reports, which are insufficient for comprehensive Visual Question Answering (VQA), especially when additional health-related data like medication history and prior diagnoses are needed. (2) Previous methods use raw CXR reports, which are often arbitrarily structured. While modern language models can understand various text formats, restructuring reports for clearer, organized anatomy-based information could enhance their usefulness. (3) Current evaluation methods for CXR-VQA primarily emphasize linguistic correctness, lacking the capability to offer nuanced assessments of the generated answers.
    
[^80]: 想象增强生成：学习想象更丰富的背景来进行大型语言模型问题回答

    Imagination Augmented Generation: Learning to Imagine Richer Context for Question Answering over Large Language Models

    [https://arxiv.org/abs/2403.15268](https://arxiv.org/abs/2403.15268)

    提出了一种新颖的知识增强框架，即想象增强生成（IAG），通过想象力，而非依赖外部资源，来补充大型语言模型中可能存在的知识缺陷，并提出了一种想象更丰富背景的方法（IMcQA）来解决问题回答中的挑战。

    

    检索增强生成和生成增强生成已被提出来增强大型语言模型（LLMs）上的问题回答所需的知识。然而，前者依赖于外部资源，而且两者都需要将显式文档合并到上下文中，导致更长的上下文，从而消耗更多资源。最近的研究表明，LLMs已经建模了丰富的知识，尽管没有被有效地触发或激活。在此启发下，我们提出了一种新颖的知识增强框架，即想象增强生成（IAG），它模拟了人类通过想象力在仅凭想象回答问题时弥补知识缺陷的能力，而不依赖外部资源。在IAG的指导下，我们提出了一种用于问题回答的想象更丰富背景的方法（IMcQA），通过以下两个模块获得更丰富的背景：通过生成简单的想象实现显式想象

    arXiv:2403.15268v1 Announce Type: new  Abstract: Retrieval-Augmented-Generation and Gener-ation-Augmented-Generation have been proposed to enhance the knowledge required for question answering over Large Language Models (LLMs). However, the former depends on external resources, and both require incorporating the explicit documents into the context, which results in longer contexts that lead to more resource consumption. Recent works indicate that LLMs have modeled rich knowledge, albeit not effectively triggered or activated. Inspired by this, we propose a novel knowledge-augmented framework, Imagination-Augmented-Generation (IAG), which simulates the human capacity to compensate for knowledge deficits while answering questions solely through imagination, without relying on external resources. Guided by IAG, we propose an imagine richer context method for question answering (IMcQA), which obtains richer context through the following two modules: explicit imagination by generating a sho
    
[^81]: 通过知识编辑实现对大型语言模型的去毒化

    Detoxifying Large Language Models via Knowledge Editing

    [https://arxiv.org/abs/2403.14472](https://arxiv.org/abs/2403.14472)

    本文研究了使用知识编辑技术对大型语言模型进行去毒化，在构建了SafeEdit基准的基础上，提出了一种简单而有效的方法 DINM，可以通过少量调整步骤减少模型的毒性，同时对各种去毒方法的内部机制进行了深入分析。

    

    本文研究了使用知识编辑技术来对大型语言模型（LLMs）进行去毒化。我们构建了一个名为SafeEdit的基准，涵盖了九种不安全类别，具有各种强大的攻击提示，并配备了全面的度量标准进行系统评估。我们进行了实验，比较了知识编辑方法与之前的基准线，结果表明知识编辑有潜力在对LLMs进行去毒化时，在对一般性能的影响相对有限。然后，我们提出了一个简单但有效的基准线，称为通过术中神经监测去毒化（DINM），通过仅一次实例的少量调整步骤减少LLMs的毒性。我们进一步对各种去毒方法的内部机制进行了深入分析，表明先前的方法如SFT和DPO可能仅抑制有毒参数的激活，而DINM则减轻有毒参数的毒性。

    arXiv:2403.14472v1 Announce Type: cross  Abstract: This paper investigates using knowledge editing techniques to detoxify Large Language Models (LLMs). We construct a benchmark, SafeEdit, which covers nine unsafe categories with various powerful attack prompts and equips comprehensive metrics for systematic evaluation. We conduct experiments to compare knowledge editing approaches with previous baselines, indicating that knowledge editing has the potential to efficiently detoxify LLMs with limited impact on general performance. Then, we propose a simple yet effective baseline, dubbed Detoxifying with Intraoperative Neural Monitoring (DINM), to diminish the toxicity of LLMs within a few tuning steps via only one instance. We further provide an in-depth analysis of the internal mechanism for various detoxify approaches, demonstrating that previous methods like SFT and DPO may merely suppress the activations of toxic parameters, while DINM mitigates the toxicity of the toxic parameters to
    
[^82]: 自适应检索增强大型语言模型：通过问题复杂度学习调适

    Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity

    [https://arxiv.org/abs/2403.14403](https://arxiv.org/abs/2403.14403)

    通过新颖的自适应QA框架，根据查询的复杂度动态选择适合的检索增强大型语言模型策略，提高了回答准确性。

    

    检索增强大型语言模型（LLMs）将外部知识库中的非参数知识纳入LLMs，已成为提高多种任务中回答准确性的有希望方法，如问答（QA）。然而，尽管有各种方法处理不同复杂度的查询，但它们要么处理简单查询时产生不必要的计算开销，要么未能充分解决复杂的多步查询；然而，并非所有用户请求都只能划分为简单或复杂类别中的一种。在这项研究中，我们提出了一种新颖的自适应QA框架，该框架可以动态选择从最简单到最复杂的（检索增强）LLMs策略，这取决于查询的复杂度。此外，这个选择过程是通过一个分类器实现的，该分类器是一个较小的LM，训练以预测传入查询的复杂度级别。

    arXiv:2403.14403v1 Announce Type: cross  Abstract: Retrieval-Augmented Large Language Models (LLMs), which incorporate the non-parametric knowledge from external knowledge bases into LLMs, have emerged as a promising approach to enhancing response accuracy in several tasks, such as Question-Answering (QA). However, even though there are various approaches dealing with queries of different complexities, they either handle simple queries with unnecessary computational overhead or fail to adequately address complex multi-step queries; yet, not all user requests fall into only one of the simple or complex categories. In this work, we propose a novel adaptive QA framework, that can dynamically select the most suitable strategy for (retrieval-augmented) LLMs from the simplest to the most sophisticated ones based on the query complexity. Also, this selection process is operationalized with a classifier, which is a smaller LM trained to predict the complexity level of incoming queries with aut
    
[^83]: 当SMILES拥有语言：使用文本分类方法对药物SMILES字符串进行药物分类

    When SMILES have Language: Drug Classification using Text Classification Methods on Drug SMILES Strings

    [https://arxiv.org/abs/2403.12984](https://arxiv.org/abs/2403.12984)

    将药物SMILES字符串视为句子并利用文本分类方法进行药物分类，证实了通过简单的自然语言处理方法解决复杂问题的可能性

    

    复杂的化学结构，如药物，通常由SMILES字符串来定义，作为分子和键的序列。这些SMILES字符串在不同的基于机器学习的药物相关研究和表示工作中使用。在这项工作中，我们摆脱复杂的表示法，提出了一个问题：如果我们将药物SMILES视为常规句子，并进行文本分类以进行药物分类会怎样？我们的实验证实了这种可能性，获得了非常有竞争力的分数。该研究探讨了将每个原子和键视为句子组件的概念，利用基本的自然语言处理方法对药物类型进行分类，表明复杂的问题也可以用更简单的视角来解决。数据和代码可在此处找到：https://github.com/azminewasi/Drug-Classification-NLP。

    arXiv:2403.12984v1 Announce Type: cross  Abstract: Complex chemical structures, like drugs, are usually defined by SMILES strings as a sequence of molecules and bonds. These SMILES strings are used in different complex machine learning-based drug-related research and representation works. Escaping from complex representation, in this work, we pose a single question: What if we treat drug SMILES as conventional sentences and engage in text classification for drug classification? Our experiments affirm the possibility with very competitive scores. The study explores the notion of viewing each atom and bond as sentence components, employing basic NLP methods to categorize drug types, proving that complex problems can also be solved with simpler perspectives. The data and code are available here: https://github.com/azminewasi/Drug-Classification-NLP.
    
[^84]: 通向统一多模式个性化：大型视觉语言模型用于生成推荐和更多领域

    Towards Unified Multi-Modal Personalization: Large Vision-Language Models for Generative Recommendation and Beyond

    [https://arxiv.org/abs/2403.10667](https://arxiv.org/abs/2403.10667)

    本文旨在建立一个统一的多模态个性化系统(UniMP)，有效利用多模态数据同时消除与任务和模态特定定制相关的复杂性。

    

    开发一个能够有效利用异构资源并满足各种个性化需求的通用模型一直是社区渴望的目标。我们日常的选择，尤其是在时尚和零售等领域，很大程度上受多模态数据的影响，比如图片和文本描述。这些模态不仅提供直观的指导，还迎合个性化用户偏好。然而，当前主流的个性化方法主要聚焦于基于ID或文本的推荐问题，未能理解涵盖各种任务或模态的信息。本文的目标是建立一个统一的多模态个性化系统(UniMP)，能够有效利用多模态数据，同时消除与任务和模态特定定制相关的复杂性。我们认为基础生成建模的进展提供了

    arXiv:2403.10667v1 Announce Type: cross  Abstract: Developing a universal model that can effectively harness heterogeneous resources and respond to a wide range of personalized needs has been a longstanding community aspiration. Our daily choices, especially in domains like fashion and retail, are substantially shaped by multi-modal data, such as pictures and textual descriptions. These modalities not only offer intuitive guidance but also cater to personalized user preferences. However, the predominant personalization approaches mainly focus on the ID or text-based recommendation problem, failing to comprehend the information spanning various tasks or modalities. In this paper, our goal is to establish a Unified paradigm for Multi-modal Personalization systems (UniMP), which effectively leverages multi-modal data while eliminating the complexities associated with task- and modality-specific customization. We argue that the advancements in foundational generative modeling have provided
    
[^85]: FluoroSAM: 用于X光图像分割的语言对齐基础模型

    FluoroSAM: A Language-aligned Foundation Model for X-ray Image Segmentation

    [https://arxiv.org/abs/2403.08059](https://arxiv.org/abs/2403.08059)

    FluoroSAM是用于X光图像的分割的语言对齐基础模型，提供了一种在X光成像领域具有广泛适用性的自动图像分析工具。

    

    自动X光图像分割将加速诊断和介入精准医学领域的研究和发展。先前的研究已经提出了适用于解决特定图像分析问题的特定任务模型，但这些模型的效用受限于特定任务领域，要拓展到更广泛的应用则需要额外的数据、标签和重新训练工作。最近，基础模型（FMs） - 训练在大量高度变化数据上的机器学习模型因此使得广泛适用性成为可能 - 已经成为自动图像分析的有希望的工具。现有的用于医学图像分析的FMs聚焦于对象被明显可见边界清晰定义的场景和模式，如内窥镜手术工具分割。相比之下，X光成像通常没有提供这种清晰的边界或结构先验。在X光图像形成期间，复杂的三维

    arXiv:2403.08059v1 Announce Type: cross  Abstract: Automated X-ray image segmentation would accelerate research and development in diagnostic and interventional precision medicine. Prior efforts have contributed task-specific models capable of solving specific image analysis problems, but the utility of these models is restricted to their particular task domain, and expanding to broader use requires additional data, labels, and retraining efforts. Recently, foundation models (FMs) -- machine learning models trained on large amounts of highly variable data thus enabling broad applicability -- have emerged as promising tools for automated image analysis. Existing FMs for medical image analysis focus on scenarios and modalities where objects are clearly defined by visually apparent boundaries, such as surgical tool segmentation in endoscopy. X-ray imaging, by contrast, does not generally offer such clearly delineated boundaries or structure priors. During X-ray image formation, complex 3D
    
[^86]: 小型语言模型能成为顺序推荐系统的良好推理者吗？

    Can Small Language Models be Good Reasoners for Sequential Recommendation?

    [https://arxiv.org/abs/2403.04260](https://arxiv.org/abs/2403.04260)

    提出了逐步知识提取框架（SLIM），为顺序推荐系统解决了大型语言模型（LLMs）高资源需求的难题，使其能以资源高效的方式享受LLMs的出色推理能力。

    

    大型语言模型（LLMs）由于其出色的语言理解和生成能力，为顺序推荐开拓了新的领域。然而，要成功实现由LLMs赋能的顺序推荐还有许多挑战需要解决。首先，用户行为模式通常复杂，仅仅依靠LLMs的一步推理可能会导致错误或与任务无关的响应。其次，LLMs（例如ChatGPT-175B）极高的资源需求是难以承受且在实际顺序推荐系统中不切实际的。本文提出了一个新颖的逐步知识提取框架用于推荐（SLIM），为顺序推荐器以“瘦”（即资源高效）的方式享受LLMs出色的推理能力铺平了一条有前途的道路。我们引入基于用户行为序列的CoT提示来实现更好的推荐。

    arXiv:2403.04260v1 Announce Type: cross  Abstract: Large language models (LLMs) open up new horizons for sequential recommendations, owing to their remarkable language comprehension and generation capabilities. However, there are still numerous challenges that should be addressed to successfully implement sequential recommendations empowered by LLMs. Firstly, user behavior patterns are often complex, and relying solely on one-step reasoning from LLMs may lead to incorrect or task-irrelevant responses. Secondly, the prohibitively resource requirements of LLM (e.g., ChatGPT-175B) are overwhelmingly high and impractical for real sequential recommender systems. In this paper, we propose a novel Step-by-step knowLedge dIstillation fraMework for recommendation (SLIM), paving a promising path for sequential recommenders to enjoy the exceptional reasoning capabilities of LLMs in a "slim" (i.e., resource-efficient) manner. We introduce CoT prompting based on user behavior sequences for the larg
    
[^87]: OffLanDat：通过提示工程生成的大型语言模型生成的社区基础隐式攻击性语言数据集

    OffLanDat: A Community Based Implicit Offensive Language Dataset Generated by Large Language Model Through Prompt Engineering

    [https://arxiv.org/abs/2403.02472](https://arxiv.org/abs/2403.02472)

    介绍了一个通过提示工程生成的大型语言模型创建的社区基础隐式攻击性语言数据集OffLanDat，为38个不同目标群体提供数据。

    

    社交媒体上攻击性语言的普遍存在对社会福祉产生了不良影响。因此，有必要高度重视解决这一问题。攻击性语言既存在明确形式，也存在隐式形式，后者更具挑战性。当前在该领域的研究遇到几个挑战。首先，现有数据集主要依赖于收集包含明确攻击性关键词的文本，这使得捕捉不包含这些关键词且隐含攻击性内容的任务具有挑战性。其次，通常的方法论倾向于仅关注文本分析，忽视社区信息可以提供的宝贵见解。在这篇研究论文中，我们介绍了一个新的数据集OffLanDat，这是由ChatGPT生成的基于社区的隐式攻击性语言数据集，其中包含38个不同目标群体的数据。

    arXiv:2403.02472v1 Announce Type: new  Abstract: The widespread presence of offensive languages on social media has resulted in adverse effects on societal well-being. As a result, it has become very important to address this issue with high priority. Offensive languages exist in both explicit and implicit forms, with the latter being more challenging to detect. Current research in this domain encounters several challenges. Firstly, the existing datasets primarily rely on the collection of texts containing explicit offensive keywords, making it challenging to capture implicitly offensive contents that are devoid of these keywords. Secondly, usual methodologies tend to focus solely on textual analysis, neglecting the valuable insights that community information can provide. In this research paper, we introduce a novel dataset OffLanDat, a community based implicit offensive language dataset generated by ChatGPT containing data for 38 different target groups. Despite limitations in genera
    
[^88]: 《检索是有益还是有害？深入探讨检索增强对语言模型效果的影响》

    Retrieval Helps or Hurts? A Deeper Dive into the Efficacy of Retrieval Augmentation to Language Models

    [https://arxiv.org/abs/2402.13492](https://arxiv.org/abs/2402.13492)

    该研究深入探讨了如何通过检索增强语言模型，构建了新的QA数据集WiTQA，以实体和关系组合的影响为重点进行了详细分析。

    

    虽然大型语言模型（LMs）表现出色，但当需要查询其预训练记忆之外的信息时，它们在提供准确回答时会遇到挑战。虽然利用相关外部信息来增强它们可以缓解这些问题，但未考虑检索的必要性可能会对整体性能产生负面影响。此前的研究主要关注实体如何影响检索模型与LMs中的知识回忆，其他方面相对未被探索。本研究旨在通过探索实体和关系组合的影响来提供更详细、以事实为中心的分析。为实现这一目标，我们构建了一个名为WiTQA（Wikipedia Triple Question Answers）的新问题回答（QA）数据集。此数据集包括关于不同受欢迎程度实体和关系的问题，每个问题都附带一段支持性段落。

    arXiv:2402.13492v1 Announce Type: new  Abstract: While large language models (LMs) demonstrate remarkable performance, they encounter challenges in providing accurate responses when queried for information beyond their pre-trained memorization. Although augmenting them with relevant external information can mitigate these issues, failure to consider the necessity of retrieval may adversely affect overall performance. Previous research has primarily focused on examining how entities influence retrieval models and knowledge recall in LMs, leaving other aspects relatively unexplored. In this work, our goal is to offer a more detailed, fact-centric analysis by exploring the effects of combinations of entities and relations. To facilitate this, we construct a new question answering (QA) dataset called WiTQA (Wikipedia Triple Question Answers). This dataset includes questions about entities and relations of various popularity levels, each accompanied by a supporting passage. Our extensive ex
    
[^89]: HU在SemEval-2024任务8A中的表现：对比学习能否学习嵌入以检测机器生成的文本？

    HU at SemEval-2024 Task 8A: Can Contrastive Learning Learn Embeddings to Detect Machine-Generated Text?

    [https://arxiv.org/abs/2402.11815](https://arxiv.org/abs/2402.11815)

    提出了一种基于对比学习的单一模型，用较少的参数实现与基线相当的机器生成文本检测性能

    

    这篇论文描述了我们为SemEval-2024任务8“多生成器、多领域和多语言黑匣子机器生成文本检测”开发的系统。由于大型语言模型（LLM）在虚假文本生成、网络钓鱼、考试作弊甚至抄袭版权材料中的使用，机器生成文本一直是主要关注的问题之一。许多系统已经被开发用于检测机器生成的文本。然而，这些系统中的大部分依赖于文本生成模型，这是一个在实际场景中不切实际的限制，因为通常不可能知道用户用于文本生成的具体模型。在这项工作中，我们提出了基于对比学习的单一模型，其使用基线参数的大约40%（149M比355M），但在测试数据集上表现出了可比的性能（在137个参与者中排名第21）。我们的关键发现是，即使没有多个模型的集成，

    arXiv:2402.11815v1 Announce Type: cross  Abstract: This paper describes our system developed for SemEval-2024 Task 8, "Multigenerator, Multidomain, and Multilingual Black-Box Machine-Generated Text Detection." Machine-generated texts have been one of the main concerns due to the use of large language models (LLM) in fake text generation, phishing, cheating in exams, or even plagiarizing copyright materials. A lot of systems have been developed to detect machine-generated text. Nonetheless, the majority of these systems rely on the text-generating model, a limitation that is impractical in real-world scenarios, as it's often impossible to know which specific model the user has used for text generation. In this work, we propose a single model based on contrastive learning, which uses ~40% of the baseline's parameters (149M vs. 355M) but shows a comparable performance on the test dataset (21st out of 137 participants). Our key finding is that even without an ensemble of multiple models, a
    
[^90]: 英语和德语的句法语言变化：度量、解析器和趋同

    Syntactic Language Change in English and German: Metrics, Parsers, and Convergences

    [https://arxiv.org/abs/2402.11549](https://arxiv.org/abs/2402.11549)

    本文研究英语和德语句法语言变化趋势，使用议会辩论语料库，探讨了句法依存距离最小化及基于树图属性的15个度量标准，揭示了现代解析器在这种变化中的影响。

    

    许多研究表明，人类语言往往会优化语言结构以降低复杂性，增加交流效率。句法依存距离衡量了相关词汇之间的线性距离，通常被认为是语言处理困难和工作记忆负荷的关键指标。本文研究了英语和德语句法语言变化的历时趋势，使用了过去大约160年间的议会辩论语料库。我们基于5个依存句法解析器的观察结果，包括广泛使用的Stanford CoreNLP以及其他4个更新的替代方案。我们的句法语言变化分析超越了线性依存距离，探讨了与依存距离最小化（DDM）相关的15个度量标准，或者基于树图属性，比如树高和度变异。尽管我们有证据表明，最近基于现代树库训练的解析器并未受到重大影响。

    arXiv:2402.11549v1 Announce Type: cross  Abstract: Many studies have shown that human languages tend to optimize for lower complexity and increased communication efficiency. Syntactic dependency distance, which measures the linear distance between dependent words, is often considered a key indicator of language processing difficulty and working memory load. The current paper looks at diachronic trends in syntactic language change in both English and German, using corpora of parliamentary debates from the last c. 160 years. We base our observations on five dependency parsers, including the widely used Stanford CoreNLP as well as 4 newer alternatives. Our analysis of syntactic language change goes beyond linear dependency distance and explores 15 metrics relevant to dependency distance minimization (DDM) and/or based on tree graph properties, such as the tree height and degree variance. Even though we have evidence that recent parsers trained on modern treebanks are not heavily affected 
    
[^91]: LLMs和人类条件

    LLMs and the Human Condition

    [https://arxiv.org/abs/2402.08403](https://arxiv.org/abs/2402.08403)

    本文提出了将三个成熟的人类决策理论整合到一起，形成了一个目的性人类行动模型。同时，将语言作为行动的观点应用于对话用户界面。通过理解ChatGPT的智能来源，可以在减少资源的同时获得对我们之间关系的认识。

    

    本文介绍了人类决策的三个成熟理论，并描述了如何将它们整合起来提供一个目的性人类行动的模型。同时，将语言作为行动的观点应用于对话用户界面。最近，基于理论的人工智能研究遇到了困难，本文旨在重新激发对理解LLMs实际执行的兴趣，而不仅仅是在所有数据上运行难以理解的机器学习例程。当一台售价不到50美元的树莓派电脑比第一台商业Cray超级计算机快400倍时，大型科技公司可以接近拥有无数随机打字并生成有意义文字的猴子。通过理解ChatGPT的表现智能的来源，也许我们可以用更少的资源进行同样的魔术，并在此过程中获得一些关于我们之间关系的理解。

    This paper presents three established theories of human decision-making and describes how they can be integrated to provide a model of purposive human action. Taking seriously the idea of language as action the model is then applied to the conversational user interfaces. Theory based AI research has had a hard time recently and the aim here is to revitalise interest in understanding what LLMs are actually doing other than running poorly understood machine learning routines over all the data the relevant Big Tech company can hoover up. When a raspberry pi computer for under 50USD is up to 400 times faster than the first commercial Cray super computer~\cite{crayVpi}, Big Tech can get really close to having an infinite number of monkeys typing at random and producing text, some of which will make sense. By understanding where ChatGPT's apparent intelligence comes from, perhaps we can perform the magic with fewer resources and at the same time gain some understanding about our relationship
    
[^92]: 重新构想指挥与控制

    Re-Envisioning Command and Control

    [https://arxiv.org/abs/2402.07946](https://arxiv.org/abs/2402.07946)

    重新构想的论文提出了未来指挥与控制（C2）决策需要面对更复杂和挑战性的环境，因此提出了基于人工智能系统与人类强有力伙伴关系的未来C2的愿景。这个愿景的核心是优化C2操作流程，保持协同努力，发展自适应的集体知识系统。

    

    未来的战争将要求在更复杂、快节奏、不结构化和极具挑战性的环境中进行指挥与控制（C2）决策。C2将因被拒绝、退化、间歇和有限的通信以及需要考虑到多个作战领域中的许多数据流而变得更加复杂。然而，当前的C2实践——源自工业时代而非新兴的智能时代——是线性的且耗时。而且，这些方法可能无法在未来战场上与对手保持优势。为了应对这些挑战，我们提出了一种基于人工智能（AI）系统与人类之间强有力伙伴关系的未来C2愿景。这个未来愿景体现在三个运营影响上：优化C2操作流程，保持协同努力，以及发展自适应的集体知识系统。本文阐述了所设想的未来指挥与控制的愿景。

    Future warfare will require Command and Control (C2) decision-making to occur in more complex, fast-paced, ill-structured, and demanding conditions. C2 will be further complicated by operational challenges such as Denied, Degraded, Intermittent, and Limited (DDIL) communications and the need to account for many data streams, potentially across multiple domains of operation. Yet, current C2 practices -- which stem from the industrial era rather than the emerging intelligence era -- are linear and time-consuming. Critically, these approaches may fail to maintain overmatch against adversaries on the future battlefield. To address these challenges, we propose a vision for future C2 based on robust partnerships between humans and artificial intelligence (AI) systems. This future vision is encapsulated in three operational impacts: streamlining the C2 operations process, maintaining unity of effort, and developing adaptive collective knowledge systems. This paper illustrates the envisaged fu
    
[^93]: 可扩展互动式机器学习用于未来指挥与控制

    Scalable Interactive Machine Learning for Future Command and Control

    [https://arxiv.org/abs/2402.06501](https://arxiv.org/abs/2402.06501)

    未来战争将需要指挥与控制（C2）人员在复杂且潜在模糊的情况下以更短的时间内做出决策。本论文通过利用互动式机器学习方法，结合人工智能和人类智能，以提高C2运作的适应性和效率。

    

    未来战争将需要指挥与控制（C2）人员在复杂且潜在模糊的情况下以更短的时间内做出决策。鉴于需要强大的决策过程和决策支持工具，人工智能和人类智能的集成具有革命性地改变C2运作流程的潜力，以确保在快速变化的操作环境中的适应性和效率。我们提议利用最近在互动式机器学习方面取得的突破，人类可以与机器学习算法合作以指导机器学习算法的行为。本文确定了目前科技发展中存在的几个差距，未来的工作应该解决这些差距，以扩展这些方法在复杂的C2环境中发挥作用。特别是，我们描述了三个研究重点领域，共同旨在实现可扩展的互动式机器学习（SIML）：1）开发人工智能与人类交互算法以实现协同规划。

    Future warfare will require Command and Control (C2) personnel to make decisions at shrinking timescales in complex and potentially ill-defined situations. Given the need for robust decision-making processes and decision-support tools, integration of artificial and human intelligence holds the potential to revolutionize the C2 operations process to ensure adaptability and efficiency in rapidly changing operational environments. We propose to leverage recent promising breakthroughs in interactive machine learning, in which humans can cooperate with machine learning algorithms to guide machine learning algorithm behavior. This paper identifies several gaps in state-of-the-art science and technology that future work should address to extend these approaches to function in complex C2 contexts. In particular, we describe three research focus areas that together, aim to enable scalable interactive machine learning (SIML): 1) developing human-AI interaction algorithms to enable planning in co
    
[^94]: COA-GPT：用于军事行动中加速行动方案开发的生成式预训练变压器

    COA-GPT: Generative Pre-trained Transformers for Accelerated Course of Action Development in Military Operations

    [https://arxiv.org/abs/2402.01786](https://arxiv.org/abs/2402.01786)

    COA-GPT是一种利用大型语言模型快速高效生成有效行动方案的算法，它融合了军事学说和领域专业知识，并在军事游戏中的实验中展示了其快速生成战略合理COAs的优势。

    

    军事行动中行动方案（COAs）的开发传统上是一个耗时且复杂的过程。针对这一挑战，本研究介绍了COA-GPT，一种利用大型语言模型（LLMs）快速高效生成有效COAs的新算法。COA-GPT通过上下文学习将军事学说和领域专业知识融入到LLMs中，允许指挥官输入任务信息（包括文本和图像格式），并获得与战略对齐的COAs以供审查和批准。独特的是，COA-GPT不仅加速了COA的开发，在几秒钟内生成初始COAs，还能根据指挥官的反馈实时精细化改进。本研究在《星际争霸II》游戏的军事相关场景中评估了COA-GPT，将其性能与最先进的强化学习算法进行了比较。我们的结果表明COA-GPT在更快生成战略合理的COAs方面具有优势。

    The development of Courses of Action (COAs) in military operations is traditionally a time-consuming and intricate process. Addressing this challenge, this study introduces COA-GPT, a novel algorithm employing Large Language Models (LLMs) for rapid and efficient generation of valid COAs. COA-GPT incorporates military doctrine and domain expertise to LLMs through in-context learning, allowing commanders to input mission information - in both text and image formats - and receive strategically aligned COAs for review and approval. Uniquely, COA-GPT not only accelerates COA development, producing initial COAs within seconds, but also facilitates real-time refinement based on commander feedback. This work evaluates COA-GPT in a military-relevant scenario within a militarized version of the StarCraft II game, comparing its performance against state-of-the-art reinforcement learning algorithms. Our results demonstrate COA-GPT's superiority in generating strategically sound COAs more swiftly, 
    
[^95]: 及时预测结构：推理的回归

    Promptly Predicting Structures: The Return of Inference

    [https://arxiv.org/abs/2401.06877](https://arxiv.org/abs/2401.06877)

    本文提出了一个框架，通过使用结构约束和由此衍生的组合推理，可以过滤大型语言模型预测的不一致结构，从而构建有效的结构化输出，并提高性能。

    

    在自然语言处理领域，基于提示的方法被广泛用于构建零样本和少样本标签预测器。许多自然语言处理任务具有结构特点：即它们的输出由多个相互约束的标签组成。为这类任务标注数据可能会很繁琐。本文探讨了基于提示的范式能否扩展到这种结构化输出任务？我们提出了一个构建零样本和少样本语言结构预测器的框架。我们的关键观点是，我们可以利用结构约束和从中得出的组合推理来过滤大型语言模型预测的不一致结构。我们在两个结构化预测任务和五个数据集上实例化了这个框架。结果表明，在所有情况下，强制实施一致性不仅构造了结构有效的输出，而且提高了性能，超过了不受约束的变体。

    arXiv:2401.06877v2 Announce Type: replace  Abstract: Prompt-based methods have been used extensively across NLP to build zero- and few-shot label predictors. Many NLP tasks are naturally structured: that is, their outputs consist of multiple labels which constrain each other. Annotating data for such tasks can be cumbersome. Can the promise of the prompt-based paradigm be extended to such structured outputs? In this paper, we present a framework for constructing zero- and few-shot linguistic structure predictors. Our key insight is that we can use structural constraints -- and combinatorial inference derived from them -- to filter out inconsistent structures predicted by large language models. We instantiated this framework on two structured prediction tasks, and five datasets. Across all cases, our results show that enforcing consistency not only constructs structurally valid outputs, but also improves performance over the unconstrained variants.
    
[^96]: TimeChat：一种面向长视频理解的时间敏感多模态大型语言模型

    TimeChat: A Time-sensitive Multimodal Large Language Model for Long Video Understanding

    [https://arxiv.org/abs/2312.02051](https://arxiv.org/abs/2312.02051)

    TimeChat是一种时间敏感的多模态大型语言模型，包含时间戳感知帧编码器和滑动视频Q-Former，以实现对长视频进行强大的零-shot时间本地化和推理能力。实验结果表明，在各种视频理解任务上表现出色。

    

    这项工作提出了TimeChat，一种专门为长视频理解设计的时间敏感多模态大型语言模型。 我们的模型包含两个关键的架构贡献：(1)一个时间戳感知帧编码器，将视觉内容与每帧的时间戳绑定在一起；(2)一个滑动视频Q-Former，生成各种长度的视频令牌序列，以适应不同持续时间的视频。此外，我们构建了一个指令调优数据集，涵盖6个任务和总计125K个实例，以进一步提升TimeChat在遵循指令方面的性能。在各种视频理解任务上的实验结果，如密集字幕生成、时间定位和精彩片段检测，展示了TimeChat强大的零-shot时间本地化和推理能力。例如，它在YouCook2上实现了+9.2的F1分数和+2.8的CIDEr，在QVHighlights上实现了+5.8的HIT@1，在Cha上实现了+27.5的R@1（IoU=0.5）。

    arXiv:2312.02051v2 Announce Type: replace-cross  Abstract: This work proposes TimeChat, a time-sensitive multimodal large language model specifically designed for long video understanding. Our model incorporates two key architectural contributions: (1) a timestamp-aware frame encoder that binds visual content with the timestamp of each frame, and (2) a sliding video Q-Former that produces a video token sequence of varying lengths to accommodate videos of various durations. Additionally, we construct an instruction-tuning dataset, encompassing 6 tasks and a total of 125K instances, to further enhance TimeChat's instruction-following performance. Experiment results across various video understanding tasks, such as dense captioning, temporal grounding, and highlight detection, demonstrate TimeChat's strong zero-shot temporal localization and reasoning capabilities. For example, it achieves +9.2 F1 score and +2.8 CIDEr on YouCook2, +5.8 HIT@1 on QVHighlights, and +27.5 R@1 (IoU=0.5) on Cha
    
[^97]: EgoThink: 评估视觉语言模型的第一视角思维能力

    EgoThink: Evaluating First-Person Perspective Thinking Capability of Vision-Language Models

    [https://arxiv.org/abs/2311.15596](https://arxiv.org/abs/2311.15596)

    EgoThink是一个新颖的视觉问答基准，旨在评估视觉语言模型从第一人称视角“思考”的能力。

    

    最近，在传统的下游任务中，视觉语言模型（VLMs）表现出了令人鼓舞的结果。评估研究已经出现来评估它们的能力，但大多数集中在第三人称视角，只有很少涉及第一人称视角的特定任务。为了弥合这一研究空白，我们引入了EgoThink，这是一个包含六个核心能力和十二个详细维度的新颖视觉问答基准。该基准是使用选定的自我中心视频片段构建的，其中包含手动注释的包含第一人称信息的问题-回答对。为了全面评估VLMs，我们在EgoThink上评估了十八种流行的VLMs。

    arXiv:2311.15596v2 Announce Type: replace-cross  Abstract: Vision-language models (VLMs) have recently shown promising results in traditional downstream tasks. Evaluation studies have emerged to assess their abilities, with the majority focusing on the third-person perspective, and only a few addressing specific tasks from the first-person perspective. However, the capability of VLMs to "think" from a first-person perspective, a crucial attribute for advancing autonomous agents and robotics, remains largely unexplored. To bridge this research gap, we introduce EgoThink, a novel visual question-answering benchmark that encompasses six core capabilities with twelve detailed dimensions. The benchmark is constructed using selected clips from egocentric videos, with manually annotated question-answer pairs containing first-person information. To comprehensively assess VLMs, we evaluate eighteen popular VLMs on EgoThink. Moreover, given the open-ended format of the answers, we use GPT-4 as t
    
[^98]: 提示风险控制：大型语言模型负责部署的严格框架

    Prompt Risk Control: A Rigorous Framework for Responsible Deployment of Large Language Models

    [https://arxiv.org/abs/2311.13628](https://arxiv.org/abs/2311.13628)

    提示风险控制是一个轻量级框架，通过严格的信息风险度量族的上限选取提示，帮助减轻大型语言模型负责部署过程中产生意外糟糕响应的风险。

    

    大型语言模型能力的爆炸式增长引发了对如何最好地提示模型执行特定任务的兴趣浪潮。选择一个基于验证集上平均性能的提示可能很诱人，但这可能导致生成出乎意料的糟糕响应，尤其是对于处境最困难的用户。为了减轻这一可能性，我们提出提示风险控制，这是一个轻量级框架，根据信息风险度量族的严格上限选择提示。我们提供了用于产生多种度量上限的方法，包括衡量最坏情况响应和用户群体生成质量不均衡的量，此外，我们扩展了基础统计界定技术，以适应部署中分布变化可能性的情况。在开放式聊天、医学问题等应用上的实验表明了我们方法的有效性。

    arXiv:2311.13628v2 Announce Type: replace-cross  Abstract: The recent explosion in the capabilities of large language models has led to a wave of interest in how best to prompt a model to perform a given task. While it may be tempting to simply choose a prompt based on average performance on a validation set, this can lead to a deployment where unexpectedly poor responses are generated, especially for the worst-off users. To mitigate this prospect, we propose Prompt Risk Control, a lightweight framework for selecting a prompt based on rigorous upper bounds on families of informative risk measures. We offer methods for producing bounds on a diverse set of metrics, including quantities that measure worst-case responses and disparities in generation quality across the population of users. In addition, we extend the underlying statistical bounding techniques to accommodate the possibility of distribution shifts in deployment. Experiments on applications such as open-ended chat, medical que
    
[^99]: MacGyver：大型语言模型是否是创意问题解决者？

    MacGyver: Are Large Language Models Creative Problem Solvers?

    [https://arxiv.org/abs/2311.09682](https://arxiv.org/abs/2311.09682)

    通过创建MACGYVER数据集并与人类比较，研究发现大型语言模型在创意问题解决方面独具挑战性，在知识广度和可行性方面与人类存在独特差异，同时还展示了通过新的提示技术提升大型语言模型的问题解决能力潜力。

    

    我们在一个全新的约束设置中探究了现代大型语言模型的创意问题解决能力。为此，我们创建了MACGYVER，这是一个自动生成的数据集，包含超过1600个特意设计的现实世界问题，旨在引发物体的创新使用，并需要超越常规思维。我们随后向大型语言模型和人类展示我们的数据集，以比较和对比它们的问题解决能力。MACGYVER对这两个群体都具有挑战性，但以独特和互补的方式呈现。例如，人类擅长熟悉的任务，但在特定领域知识上有困难，导致更高的差异。相比之下，大型语言模型暴露于各种专业知识，尝试更广泛的问题，但在提出物理上不可行的行动时失败。最后，我们对大型语言模型进行了详细的错误分析，并展示了通过新的提示技术提高它们的问题解决能力的潜力。

    arXiv:2311.09682v2 Announce Type: replace-cross  Abstract: We explore the creative problem-solving capabilities of modern LLMs in a novel constrained setting. To this end, we create MACGYVER, an automatically generated dataset consisting of over 1,600 real-world problems deliberately designed to trigger innovative usage of objects and necessitate out-of-the-box thinking. We then present our collection to both LLMs and humans to compare and contrast their problem-solving abilities. MACGYVER is challenging for both groups, but in unique and complementary ways. For instance, humans excel in tasks they are familiar with but struggle with domain-specific knowledge, leading to a higher variance. In contrast, LLMs, exposed to a variety of specialized knowledge, attempt broader problems but fail by proposing physically-infeasible actions. Finally, we provide a detailed error analysis of LLMs, and demonstrate the potential of enhancing their problem-solving ability with novel prompting techniqu
    
[^100]: 利用代码提升语境学习对语义解析的改进

    Leveraging Code to Improve In-context Learning for Semantic Parsing

    [https://arxiv.org/abs/2311.09519](https://arxiv.org/abs/2311.09519)

    通过使用通用编程语言代替领域特定语言（DSLs）和增加结构化领域描述提示，本研究显著改善了语境学习（ICL）对语义解析的有效性，提高了准确性并减少了对大量示范的需求。

    

    在这项工作中，我们通过以下两项改进，提高了语境学习（ICL）对语义解析的有效性：（1）使用通用编程语言（如Python）代替DSL，并（2）通过增加结构化领域描述的提示，包括可用的类和函数等。我们展示了这两个变化显著提高了三个流行数据集的准确性。它们的结合导致了显著的改进（例如，在SMCalFlow组合划分上从7.9%到66.5%），几乎在使用强模型时消除了易于i.i.d和更困难的组合划分之间的性能差距，并减少了对大量演示的需求。

    arXiv:2311.09519v2 Announce Type: replace  Abstract: In-context learning (ICL) is an appealing approach for semantic parsing due to its few-shot nature and improved generalization. However, learning to parse to rare domain-specific languages (DSLs) from just a few demonstrations is challenging, limiting the performance of even the most capable LLMs. In this work, we improve the effectiveness of ICL for semantic parsing by (1) using general-purpose programming languages such as Python instead of DSLs, and (2) augmenting prompts with a structured domain description that includes, e.g., the available classes and functions. We show that both these changes significantly improve accuracy across three popular datasets. Combined, they lead to dramatic improvements (e.g. 7.9% to 66.5% on SMCalFlow compositional split), nearly closing the performance gap between easier i.i.d.\ and harder compositional splits when used with a strong model, and reducing the need for a large number of demonstration
    
[^101]: 探究ASR基础模型的新兴音频分类能力

    Investigating the Emergent Audio Classification Ability of ASR Foundation Models

    [https://arxiv.org/abs/2311.09363](https://arxiv.org/abs/2311.09363)

    ASR基础模型Whisper和MMS在不经过额外数据训练或添加新参数的情况下，展现了有希望的零-shot音频分类性能。

    

    arXiv:2311.09363v2 公告类型：替换 摘要：文本和视觉基础模型可以在零-shot设置中执行许多任务，这是一个令人向往的特性，它使这些系统能够应用于普遍和低资源的环境。然而，关于ASR基础模型的零-shot能力的研究要少得多，这些系统通常被微调到特定任务，或受限于与其训练标准和数据注释相匹配的应用程序。在这项工作中，我们调查了Whisper和MMS这两款主要用于语音识别训练的ASR基础模型执行零-shot音频分类的能力。我们在解码器中使用简单的基于模板的文本提示，并利用生成的解码概率来生成零-shot预测。在不对模型进行额外数据训练或添加任何新参数的情况下，我们展示了Whisper在一系列8个音频分类数据集上展现了有希望的零-shot分类性能，胜过了准确性。

    arXiv:2311.09363v2 Announce Type: replace  Abstract: Text and vision foundation models can perform many tasks in a zero-shot setting, a desirable property that enables these systems to be applied in general and low-resource settings. There has been far less work, however, on the zero-shot abilities of ASR foundation models, with these systems typically fine-tuned to specific tasks or constrained to applications that match their training criterion and data annotation. In this work we investigate the ability of Whisper and MMS, ASR foundation models trained primarily for speech recognition, to perform zero-shot audio classification. We use simple template-based text prompts at the decoder and use the resulting decoding probabilities to generate zero-shot predictions. Without training the model on extra data or adding any new parameters, we demonstrate that Whisper shows promising zero-shot classification performance on a range of 8 audio-classification datasets, outperforming the accurac
    
[^102]: LLMRefine：通过细粒度可操作反馈精确定位和优化大型语言模型

    LLMRefine: Pinpointing and Refining Large Language Models via Fine-Grained Actionable Feedback

    [https://arxiv.org/abs/2311.09336](https://arxiv.org/abs/2311.09336)

    LLMRefine提出了一种细粒度反馈模型来指导大型语言模型定位缺陷并进行优化，在机器翻译、长篇问答和主题总结等任务中取得显著的改进。

    

    最近，大型语言模型（LLM）正在利用人类反馈来提高生成质量。然而，在推断过程中获取人类反馈成本高昂。在这项工作中，我们提出了LLMRefine，一种用于优化推理时间的方法，以改进LLM的输出。其核心思想是利用学习的细粒度反馈模型来准确定位缺陷，并引导LLM进行迭代优化。通过将原始LLM作为编辑建议，LLMRefine通过模拟退火搜索无缺陷文本，权衡探索和开发。我们在三个文本生成任务上进行实验，包括机器翻译，长篇问答（QA）和主题总结。LLMRefine在所有基线方法上一贯表现优异，在翻译任务上取得了高达1.7 MetricX点的改进，在ASQA上为8.1 ROUGE-L，在主题总结上为2.2 ROUGE-L。

    arXiv:2311.09336v2 Announce Type: replace  Abstract: Recent large language models (LLM) are leveraging human feedback to improve their generation quality. However, human feedback is costly to obtain, especially during inference. In this work, we propose LLMRefine, an inference time optimization method to refine LLM's output. The core idea is to use a learned fine-grained feedback model to pinpoint defects and guide LLM to refine them iteratively. Using original LLM as a proposal of edits, LLMRefine searches for defect-less text via simulated annealing, trading off the exploration and exploitation. We conduct experiments on three text generation tasks, including machine translation, long-form question answering (QA), and topical summarization. LLMRefine consistently outperforms all baseline approaches, achieving improvements up to 1.7 MetricX points on translation tasks, 8.1 ROUGE-L on ASQA, 2.2 ROUGE-L on topical summarization.
    
[^103]: MILL：大型语言模型进行零-shot查询扩展的相互验证

    MILL: Mutual Verification with Large Language Models for Zero-Shot Query Expansion

    [https://arxiv.org/abs/2310.19056](https://arxiv.org/abs/2310.19056)

    该论文提出了一种利用大型语言模型进行相互验证的零-shot查询扩展框架，有效解决了查询扩展中已有方法的限制和缺陷。

    

    论文提出了一种新颖的零shot查询扩展框架，利用大型语言模型进行相互验证。具体来说，首先设计了一种查询-查询-文档生成方法，利用LLMs的零-shot推理能力生成多样化的子查询和相应的文档。然后，一个相互验证过程协同生成和检索的文档以实现最佳扩展。我们提出的方法完全是零-shot的。

    arXiv:2310.19056v3 Announce Type: replace-cross  Abstract: Query expansion, pivotal in search engines, enhances the representation of user information needs with additional terms. While existing methods expand queries using retrieved or generated contextual documents, each approach has notable limitations. Retrieval-based methods often fail to accurately capture search intent, particularly with brief or ambiguous queries. Generation-based methods, utilizing large language models (LLMs), generally lack corpus-specific knowledge and entail high fine-tuning costs. To address these gaps, we propose a novel zero-shot query expansion framework utilizing LLMs for mutual verification. Specifically, we first design a query-query-document generation method, leveraging LLMs' zero-shot reasoning ability to produce diverse sub-queries and corresponding documents. Then, a mutual verification process synergizes generated and retrieved documents for optimal expansion. Our proposed method is fully zero
    
[^104]: 优化大语言模型的少样本推理成功与提示空间

    Prompt Space Optimizing Few-shot Reasoning Success with Large Language Models

    [https://arxiv.org/abs/2306.03799](https://arxiv.org/abs/2306.03799)

    提示工程是增强大语言模型能力的必要技术，我们提出了Prompt Space方法，通过文本嵌入和矩阵分解构建提示空间来解决当前方法缺乏确定最佳提示的问题，并取得显著优越表现。

    

    提示工程是增强大语言模型（LLMs）能力的必要技术，通过提供明确和具体的指示。它使LLMs在各种任务中表现出色，如算术推理、问答、总结、关系提取、机器翻译和情感分析。研究人员一直在积极探索不同的提示工程策略，如Chain of Thought（CoT）、Zero-CoT和In-context学习。然而，一个未解决的问题源于当前方法缺乏确定最佳提示的坚实数学解决方案。为了解决提示工程中的这一问题，我们提出了一种新的有效方法称为Prompt Space。我们的方法利用文本嵌入通过矩阵分解获得基向量，然后构建一个表示所有提示的空间。Prompt Space在性能上显著优于最先进的提示范例。

    arXiv:2306.03799v2 Announce Type: replace  Abstract: Prompt engineering is an essential technique for enhancing the abilities of large language models (LLMs) by providing explicit and specific instructions. It enables LLMs to excel in various tasks, such as arithmetic reasoning, question answering, summarization, relation extraction, machine translation, and sentiment analysis. Researchers have been actively exploring different prompt engineering strategies, such as Chain of Thought (CoT), Zero-CoT, and In-context learning. However, an unresolved problem arises from the fact that current approaches lack a solid mathematical solution for determining optimal prompts. To address this issue in prompt engineering, we propose a new and effective approach called Prompt Space. Our methodology utilizes text embeddings to obtain basis vectors by matrix decomposition, and then constructs a space for representing all prompts. Prompt Space significantly outperforms state-of-the-art prompt paradigms
    
[^105]: 用于英语新闻文章句子级主观性检测的语料库

    A Corpus for Sentence-level Subjectivity Detection on English News Articles

    [https://arxiv.org/abs/2305.18034](https://arxiv.org/abs/2305.18034)

    该研究开发了新的标注指南，建立了用于英语新闻文章句子级主观性检测的语料库，并表明多语境训练的模型在该任务上取得了最佳性能。

    

    我们制定了用于句子级主观性检测的新颖标注指南，不局限于特定语言的线索。我们利用这些指南收集了NewsSD-ENG，这是从有争议话题的英语新闻文章中提取的638个客观句子和411个主观句子的语料库。我们的语料库为英语及其他语言的主观性检测铺平了道路，而无需依赖于词典或机器翻译等特定语言工具。我们在单语、多语和跨语言设置下评估了最先进的多语言变压器模型在该任务上的表现。为此，我们重新注释了现有的意大利语语料库。我们发现，在多语境中训练的模型在该任务上取得了最佳性能。

    arXiv:2305.18034v2 Announce Type: replace  Abstract: We develop novel annotation guidelines for sentence-level subjectivity detection, which are not limited to language-specific cues. We use our guidelines to collect NewsSD-ENG, a corpus of 638 objective and 411 subjective sentences extracted from English news articles on controversial topics. Our corpus paves the way for subjectivity detection in English and across other languages without relying on language-specific tools, such as lexicons or machine translation. We evaluate state-of-the-art multilingual transformer-based models on the task in mono-, multi-, and cross-language settings. For this purpose, we re-annotate an existing Italian corpus. We observe that models trained in the multilingual setting achieve the best performance on the task.
    
[^106]: PrOnto：为859种语言进行语言模型评估

    PrOnto: Language Model Evaluations for 859 Languages

    [https://arxiv.org/abs/2305.12612](https://arxiv.org/abs/2305.12612)

    本研究提出了一种新的评估数据集构建方法，可以为任何具有新约翻译的语言提供预训练语言模型评估的评估数据集，无需手动标注，通过将语句与英文OntoNotes中的语句对齐并投影标注到目标语言。这项工作使得在859种语言中进行语言模型评估成为可能。

    

    arXiv:2305.12612v2 公告类型：替换 摘要：评估数据集对于衡量预训练语言模型的质量至关重要。然而，由于数据集标注成本较高，这些资源对于除英语以外的大多数语言来说是稀缺的，这使得评估语言模型的质量变得困难。在这项工作中，我们提出了一种新的评估数据集构建方法，该方法使得任何一种具有新约翻译的语言都能获得一套适用于预训练语言模型评估的评估数据集。该方法的关键在于将语句与英文OntoNotes新约部分中的语句进行对齐，然后将英文标注投影到目标语言中，无需手动标注。我们将该方法应用于859种语言的1051种新约翻译，并将其公开可用。另外，我们进行了实验证明了我们的方法对于创建能够评估任务的功效。

    arXiv:2305.12612v2 Announce Type: replace  Abstract: Evaluation datasets are critical resources for measuring the quality of pretrained language models. However, due to the high cost of dataset annotation, these resources are scarce for most languages other than English, making it difficult to assess the quality of language models. In this work, we present a new method for evaluation dataset construction which enables any language with a New Testament translation to receive a suite of evaluation datasets suitable for pretrained language model evaluation. The method critically involves aligning verses with those in the New Testament portion of English OntoNotes, and then projecting annotations from English to the target language, with no manual annotation required. We apply this method to 1051 New Testament translations in 859 and make them publicly available. Additionally, we conduct experiments which demonstrate the efficacy of our method for creating evaluation tasks which can assess
    
[^107]: 通过符号验证评估逐步推理

    Evaluating Step-by-Step Reasoning through Symbolic Verification

    [https://arxiv.org/abs/2212.08686](https://arxiv.org/abs/2212.08686)

    文中研究了预训练语言模型（LMs）通过解释或思维链（CoT）进行推理，在推理机制上提出了一种神经符号方法，通过学习逻辑规则和示例进行迭代推理，支持LMs输出自动验证

    

    预训练语言模型（LMs）展示了在上下文学习中使用解释或思维链（CoT）获得卓越的推理表现。我们构建了包含等效（自然、符号）数据对的合成数据集，其中符号示例包含来自非参数知识库（KBs）的一阶逻辑规则和谓词，支持对中间推理结果的自动验证。我们提出从包含逻辑规则和相应示例的演示中学习，以迭代地在知识库上进行推理，恢复Prolog的向后链接算法，并支持LMs输出的自动验证。

    arXiv:2212.08686v2 Announce Type: replace  Abstract: Pre-trained language models (LMs) have shown remarkable reasoning performance using explanations or chain-of-thoughts (CoT)) for in-context learning. On the other hand, these reasoning tasks are usually presumed to be more approachable for symbolic programming. To understand the mechanism of reasoning of LMs, we curate synthetic datasets containing equivalent (natural, symbolic) data pairs, where symbolic examples contain first-order logic rules and predicates from non-parametric knowledge bases (KBs), supporting automated verification of intermediate reasoning results. Then we revisit neuro-symbolic approaches and propose to learn from demonstrations containing logic rules and corresponding examples to iteratively reason over KBs, recovering Prolog's backward chaining algorithm and supporting automated verification of LMs' outputs. Comprehensive experiments are included to systematically compare LMLP with CoT in deductive reasoning 
    
[^108]: SOLD：僧伽罗语攻击性语言数据集

    SOLD: Sinhala Offensive Language Dataset

    [https://arxiv.org/abs/2212.00851](https://arxiv.org/abs/2212.00851)

    本文介绍了一种新的低资源语言——僧伽罗语攻击性语言识别数据集(SOLD)，填补了目前攻击性语言识别研究局限于高资源语言的空白。

    

    在线攻击性内容的普遍存在，比如仇恨言论和网络欺凌，已成为全球性现象。这引起了人工智能（AI）和自然语言处理（NLP）社区的兴趣，促使开发各种系统，能够自动检测潜在有害内容。然而，除了少数几个例外情况外，大多数关于这一主题的数据集都处理英语和少数其他高资源语言。因此，攻击性语言识别研究一直局限于这些语言。本文通过处理僧伽罗语攻击性语言识别来填补这一空白，僧伽罗语是斯里兰卡有超过1700万人口使用的低资源印欧语言。我们介绍了僧伽罗语攻击性语言数据集（SOLD），并在该数据集上展示了多个实验。

    arXiv:2212.00851v2 Announce Type: replace-cross  Abstract: The widespread of offensive content online, such as hate speech and cyber-bullying, is a global phenomenon. This has sparked interest in the artificial intelligence (AI) and natural language processing (NLP) communities, motivating the development of various systems trained to detect potentially harmful content automatically. These systems require annotated datasets to train the machine learning (ML) models. However, with a few notable exceptions, most datasets on this topic have dealt with English and a few other high-resource languages. As a result, the research in offensive language identification has been limited to these languages. This paper addresses this gap by tackling offensive language identification in Sinhala, a low-resource Indo-Aryan language spoken by over 17 million people in Sri Lanka. We introduce the Sinhala Offensive Language Dataset (SOLD) and present multiple experiments on this dataset. SOLD is a manuall
    
[^109]: 增量处理在非增量编码器时代：增量NLU的双向模型的经验评估

    Incremental Processing in the Age of Non-Incremental Encoders: An Empirical Assessment of Bidirectional Models for Incremental NLU

    [https://arxiv.org/abs/2010.05330](https://arxiv.org/abs/2010.05330)

    双向模型在增量界面下的表现得到了支持，而全向BERT模型在增量访问方面受到较大影响，可通过调整训练机制缓解。

    

    虽然人类以增量方式处理语言，但目前在自然语言处理中使用的最佳语言编码器不是增量的。我们研究了当必须基于到达某个时间步的部分输入提供部分输出时，即在交互式系统中可能发生的情况下，双向LSTMs和Transformers在增量界面下的行为。我们在各种NLU数据集上测试了五种模型，并使用三种增量评估指标比较它们的性能。结果支持使用双向编码器以增量模式，并保留大部分非增量质量的可能性。在增量访问方面，表现更好的非增量性能“全向”BERT模型受到更大影响。通过调整训练机制可以缓解这一问题。

    arXiv:2010.05330v2 Announce Type: replace  Abstract: While humans process language incrementally, the best language encoders currently used in NLP do not. Both bidirectional LSTMs and Transformers assume that the sequence that is to be encoded is available in full, to be processed either forwards and backwards (BiLSTMs) or as a whole (Transformers). We investigate how they behave under incremental interfaces, when partial output must be provided based on partial input seen up to a certain time step, which may happen in interactive systems. We test five models on various NLU datasets and compare their performance using three incremental evaluation metrics. The results support the possibility of using bidirectional encoders in incremental mode while retaining most of their non-incremental quality. The "omni-directional" BERT model, which achieves better non-incremental performance, is impacted more by the incremental access. This can be alleviated by adapting the training regime (truncat
    
[^110]: 大型语言模型的知识编辑全面研究

    A Comprehensive Study of Knowledge Editing for Large Language Models. (arXiv:2401.01286v1 [cs.CL])

    [http://arxiv.org/abs/2401.01286](http://arxiv.org/abs/2401.01286)

    本研究全面研究了大型语言模型的知识编辑，旨在有效修改模型的行为，同时保持整体性能。

    

    大型语言模型(LLM)在理解和生成与人类交流紧密相似的文本方面展现出了非凡的能力。然而，其主要限制在于训练过程中的显著计算需求，这是由于其广泛的参数化造成的。这一挑战在于世界的动态性，需要频繁更新LLM以修正过时的信息或集成新知识，从而确保其持续的相关性。许多应用需要在训练后进行持续的模型调整，以解决缺陷或不良行为。近年来，对于LLM的知识编辑技术的兴趣越来越高，在特定领域内有效地修改LLM的行为，同时保持整体性能在各种输入中的表现。本文首先定义了知识编辑的目标和挑战，然后综述了现有的知识编辑方法和技术，并讨论了其应用和未来发展的方向。

    Large Language Models (LLMs) have shown extraordinary capabilities in understanding and generating text that closely mirrors human communication. However, a primary limitation lies in the significant computational demands during training, arising from their extensive parameterization. This challenge is further intensified by the dynamic nature of the world, necessitating frequent updates to LLMs to correct outdated information or integrate new knowledge, thereby ensuring their continued relevance. Note that many applications demand continual model adjustments post-training to address deficiencies or undesirable behaviors. There is an increasing interest in efficient, lightweight methods for on-the-fly model modifications. To this end, recent years have seen a burgeoning in the techniques of knowledge editing for LLMs, which aim to efficiently modify LLMs' behaviors within specific domains while preserving overall performance across various inputs. In this paper, we first define the kno
    
[^111]: 关于上下文学习的校准研究

    A Study on the Calibration of In-context Learning. (arXiv:2312.04021v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.04021](http://arxiv.org/abs/2312.04021)

    本研究关注上下文学习（ICL），通过定制提示来调整静态语言模型（LMs），研究了在各种自然语言理解和推理任务中性能和校准之间的平衡。研究发现随着ICL示例数量的增加，模型的校准会先增加而后得到改善，而校准误差主要出现在低样本场景下。此外，微调和CoT提示等方法可能导致校准误差和不可靠的自然语言解释，提示需要针对可靠性场景开发新的方法。

    

    准确的不确定性量化对于语言模型（LMs）的安全部署至关重要，以前的研究已经证明了现代LMs校准性的改进。我们的研究重点是上下文学习（ICL），一种通过定制提示来调整静态LMs的常见方法，并研究在广泛的自然语言理解和推理任务中性能和校准之间的平衡。通过全面的实验，我们观察到，随着ICL示例数量的增加，模型最初会出现增加的校准误差，然后才能实现更好的校准，而校准误差往往在低样本场景下出现。此外，我们发现以提高可用性为目标的方法，如微调和CoT提示，可能导致校准误差和不可靠的自然语言解释，这表明在期望模型可靠性的场景中可能需要新的方法。

    Accurate uncertainty quantification is crucial for the safe deployment of language models (LMs), and prior research has demonstrated improvements in the calibration of modern LMs. Our study focuses on in-context learning (ICL), a prevalent method for adapting static LMs through tailored prompts, and examines the balance between performance and calibration across a broad spectrum of natural language understanding and reasoning tasks. Through comprehensive experiments, we observe that, with an increasing number of ICL examples, models initially exhibit increased miscalibration before achieving better calibration and miscalibration tends to arise in low-shot settings. Moreover, we find that methods aimed at improving usability, such as fine-tuning and chain-of-thought (CoT) prompting, can lead to miscalibration and unreliable natural language explanations, suggesting that new methods may be required for scenarios where models are expected to be reliable.
    
[^112]: 大型语言模型是有效的文本排序器，具有两两排名提示

    Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting. (arXiv:2306.17563v1 [cs.IR])

    [http://arxiv.org/abs/2306.17563](http://arxiv.org/abs/2306.17563)

    本论文提出了一种名为PRP的新技术，通过使用两两排名提示来显著减轻大型语言模型（LLM）的负担，并首次在标准基准测试中实现了最先进的排名性能。

    

    使用大型语言模型（LLM）通过直接将查询和候选文档输入提示进行文档排序是一个有趣且实用的问题。然而，迄今为止取得了有限的成功，研究人员发现很难在基准数据集上超越精调基准排序器。我们分析了现有方法使用的点对点和列表排序提示，并认为现成的LLM没有完全理解这些排序公式，可能是由于LLM的训练方式的特性。在本文中，我们提出了一种名为两两排名提示（PRP）的新技术，大大减轻了LLM的负担。我们的结果是文献中首次使用中等规模的开源LLM在标准基准测试中实现了最先进的排名性能。在TREC-DL2020上，基于20B参数的Flan-UL2模型的PRP超过了文献中基于商业黑盒GPT-4的最佳方法。

    Ranking documents using Large Language Models (LLMs) by directly feeding the query and candidate documents into the prompt is an interesting and practical problem. However, there has been limited success so far, as researchers have found it difficult to outperform fine-tuned baseline rankers on benchmark datasets. We analyze pointwise and listwise ranking prompts used by existing methods and argue that off-the-shelf LLMs do not fully understand these ranking formulations, possibly due to the nature of how LLMs are trained. In this paper, we propose to significantly reduce the burden on LLMs by using a new technique called Pairwise Ranking Prompting (PRP). Our results are the first in the literature to achieve state-of-the-art ranking performance on standard benchmarks using moderate-sized open-sourced LLMs. On TREC-DL2020, PRP based on the Flan-UL2 model with 20B parameters outperforms the previous best approach in the literature, which is based on the blackbox commercial GPT-4 that ha
    
[^113]: 自我提示的大型语言模型用于零样本开放域问答

    Self-Prompting Large Language Models for Zero-Shot Open-Domain QA. (arXiv:2212.08635v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.08635](http://arxiv.org/abs/2212.08635)

    本论文提出了一种自我提示框架，可以有效利用大型语言模型的参数中存储的知识和指令理解能力，以实现零样本开放域问答，并且实验证明该方法在三个广泛使用的ODQA数据集中显著优于现有的最先进方法。

    

    开放域问答目标在于回答关于事实的问题，而无需提供特定的背景文档。在零样本设置下，由于没有数据来训练类似检索器-阅读器的定制模型，因此此任务更加具有挑战性。最近，像GPT-3这样的大型语言模型已经通过直接提示方法在零样本开放域问答中展示了其强大的能力，但是这些方法仍然远远不能充分发挥LLM的强大功能，而只是以隐式方式调用它们而已。本文提出了一个自我提示框架，以明确利用LLM参数中存储的大量知识和其强大的指令理解能力。具体而言，我们逐步提示LLM生成多个伪QA对，并从头开始生成背景段落和解释，然后使用生成的元素进行上下文学习。实验结果表明，我们的方案在三个广泛使用的ODQA数据集上显著超过了先前的SOTA方法。

    Open-Domain Question Answering (ODQA) aims at answering factoid questions without explicitly providing specific background documents. In a zero-shot setting, this task is more challenging since no data is available to train customized models like Retriever-Readers. Recently, Large Language Models (LLMs) like GPT-3 have shown their power in zero-shot ODQA with direct prompting methods, but these methods are still far from releasing the full powerfulness of LLMs only in an implicitly invoking way. In this paper, we propose a Self-Prompting framework to explicitly utilize the massive knowledge stored in the parameters of LLMs and their strong instruction understanding abilities. Concretely, we prompt LLMs step by step to generate multiple pseudo QA pairs with background passages and explanations from scratch and then use those generated elements for in-context learning. Experimental results show our method surpasses previous SOTA methods significantly on three widely-used ODQA datasets, a
    

