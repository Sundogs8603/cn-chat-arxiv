# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Measuring and Improving Chain-of-Thought Reasoning in Vision-Language Models.](http://arxiv.org/abs/2309.04461) | 本研究探索了视觉-语言模型展示人类推理能力的能力，并提出了一种基于思维链的一致性度量。通过一个流水线和已有数据集，建立了一个基准来测量这种推理能力。 |
| [^2] | [CSPRD: A Financial Policy Retrieval Dataset for Chinese Stock Market.](http://arxiv.org/abs/2309.04389) | 本研究引入中国股票政策检索数据集（CSPRD），提供了700+条标注的招股说明书段落，通过词汇、嵌入和经过微调的双编码模型的实验证明了CSPRD的有效性和改进潜力。 |
| [^3] | [MoEController: Instruction-based Arbitrary Image Manipulation with Mixture-of-Expert Controllers.](http://arxiv.org/abs/2309.04372) | 本论文提出了一种基于混合专家控制器(MoEController)的指令驱动任意图像操作方法，通过对不同类型的人类指令进行适配，使得模型能够处理各种开放域图像操作任务。使用大型语言模型和条件图像合成模型生成训练数据集，并采用MOE技术和任务特定的适应性训练对模型进行训练。 |
| [^4] | [Beyond Static Datasets: A Deep Interaction Approach to LLM Evaluation.](http://arxiv.org/abs/2309.04369) | 该论文提出了一种基于深度交互的LLM评估框架，突破了静态数据集的限制，能够评估LLM在动态实际场景中的能力，并适用于多种实际任务。 |
| [^5] | [Encoding Multi-Domain Scientific Papers by Ensembling Multiple CLS Tokens.](http://arxiv.org/abs/2309.04333) | 本研究提出了Multi2SPE方法，通过使用多个CLS标记来编码多领域科学论文，能够更好地适应不同的科学领域，并在引文预测任务中减少了多达25％的误差。 |
| [^6] | [Fuzzy Fingerprinting Transformer Language-Models for Emotion Recognition in Conversations.](http://arxiv.org/abs/2309.04292) | 本文提出将模糊指纹和大型语言模型相结合，用于对话情感识别，以获得更简单和更可解释的分类器，并在DailyDialog ERC基准数据集上取得最先进的结果。 |
| [^7] | [From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting.](http://arxiv.org/abs/2309.04269) | 在本研究中，我们提出了一种使用“密度链”提示的方法，将GPT-4生成的摘要从稀疏转化为稠密。人们更喜欢密度链摘要，因为它们更具概括性和融合性，并且几乎与人工写作的摘要一样密集。 |
| [^8] | [UQ at #SMM4H 2023: ALEX for Public Health Analysis with Social Media.](http://arxiv.org/abs/2309.04213) | 本文提出了一种名为ALEX的框架，通过采用LLMs解释机制来改进社交媒体上的公共卫生分析性能。该方法通过数据增强和平衡训练解决了数据不平衡问题，并有效利用了LLMs的能力。 |
| [^9] | [The CALLA Dataset: Probing LLMs' Interactive Knowledge Acquisition from Chinese Medical Literature.](http://arxiv.org/abs/2309.04198) | 该研究介绍了CALLA数据集，用于探索LLMs从中文医学文献中获取交互式知识。通过自由对话事实核查任务，评估了LLMs掌握医学知识的能力，并发现了一种称为“事实跟随响应”的现象。为了提供更准确的评估方法，人工构建了两种角度的测试数据：一种与事实一致，一种与事实不一致。 |
| [^10] | [Knowledge-tuning Large Language Models with Structured Medical Knowledge Bases for Reliable Response Generation in Chinese.](http://arxiv.org/abs/2309.04175) | 本研究提出了一种使用结构化医学知识库进行知识调整的方法，以提高大型语言模型在中文可靠响应生成方面的准确性和领域适应能力。 |
| [^11] | [Manifold-based Verbalizer Space Re-embedding for Tuning-free Prompt-based Classification.](http://arxiv.org/abs/2309.04174) | 本研究提出了一种无需调参的基于流形的语言转换器嵌入方法，通过保留同一类中的局部特性来进行分类，实验证明其与自动化的语言转换器效果相当。 |
| [^12] | [GLS-CSC: A Simple but Effective Strategy to Mitigate Chinese STM Models' Over-Reliance on Superficial Clue.](http://arxiv.org/abs/2309.04162) | 本研究提出了GLS-CSC，一种用于缓解中文STM模型对表面线索过度依赖的简单但有效的策略。通过分析编辑距离特征的影响，我们证明GLS-CSC能够提高中文STM模型的鲁棒性和泛化性能。 |
| [^13] | [Cross-Utterance Conditioned VAE for Speech Generation.](http://arxiv.org/abs/2309.04156) | 该论文提出了一种跨发言条件化变分自编码器框架，利用预训练语言模型和变分自编码器来增强语音合成的韵律，并确保自然语音生成。该框架的核心组件是跨发言CVAE，通过提取周围句子的声学、说话人和文本特征来生成上下文敏感的韵律特征，有效模拟人类韵律生成。同时，该论文还提出了两个实用算法：CUC-VAE TTS用于文本到语音合成和CUC-VAE SE用于语音编辑。 |
| [^14] | [NESTLE: a No-Code Tool for Statistical Analysis of Legal Corpus.](http://arxiv.org/abs/2309.04146) | NESTLE是一个无代码工具，用于进行大规模法律语料库的统计分析。它提供了搜索引擎、端到端的信息提取系统和一个大语言模型，可以通过聊天界面进行操作，使用户可以搜索目标文件、提取信息并可视化数据。 |
| [^15] | [RST-style Discourse Parsing Guided by Document-level Content Structures.](http://arxiv.org/abs/2309.04141) | 本研究提出了一种基于RST的话语解析流水线，通过结合文档级内容结构，使用结构感知的新闻内容句子表示，提高了大文本范围话语关系的预测性能。 |
| [^16] | [Meta predictive learning model of natural languages.](http://arxiv.org/abs/2309.04106) | 该论文提出了一种基于预测编码框架的均场学习模型，通过假设突触权重遵循脉冲和斑点分布并只对分布进行训练，成功地应用于手写数字分类。 |
| [^17] | [Unsupervised Multi-document Summarization with Holistic Inference.](http://arxiv.org/abs/2309.04087) | 本文提出了一种新的整体框架，用于无监督的多文档提取式综述。通过将整体波束搜索推理方法与名为SRI的整体度量相结合，平衡了同一主题的文档中子集句子的重要性和多样性，并在不同设置下通过实验证明了方法的有效性。 |
| [^18] | [Evaluation and Mitigation of Agnosia in Multimodal Large Language Models.](http://arxiv.org/abs/2309.04041) | 本文针对多模态大型语言模型中存在的失识症问题，提出了一种评估和缓解的框架EMMA。通过类比神经心理学中的失识症现象，定义了MLLM中的失识症，并提出了相应的评估和治疗方法。评估模块通过创建多样化的视觉问答示例来评估失识症程度，治疗模块则采用修正和增强的训练方法来减轻和纠正失识症。 |
| [^19] | [Multiple Representation Transfer from Large Language Models to End-to-End ASR Systems.](http://arxiv.org/abs/2309.04031) | 本研究探索了将大型语言模型的多个表示转移到端到端自动语音识别系统中的技术，并证明了此方法的有效性。 |
| [^20] | [TIDE: Textual Identity Detection for Evaluating and Augmenting Classification and Language Models.](http://arxiv.org/abs/2309.04027) | 本文介绍了TIDE（Textual Identity Detection）方法来改善分类器和语言模型中的文本公平性。通过创建一个包含身份词汇和语境的数据集，以及开发一个身份注释和增强工具，可以提高机器学习公平性技术的效果。 |
| [^21] | [Evaluation of large language models for discovery of gene set function.](http://arxiv.org/abs/2309.04019) | 本研究评估了OpenAI的GPT-4大型语言模型在发现基因集合功能方面的能力，并发现它能根据嵌入的生物医学知识生成与Gene Ontology中具名基因集合非常相似的名称，同时在基因组学数据中发现的基因集合中，GPT-4的命名更具信息量，得到了人工审核的基本验证。 |
| [^22] | [ConDA: Contrastive Domain Adaptation for AI-generated Text Detection.](http://arxiv.org/abs/2309.03992) | 创新点：提出了一种基于对比域适应的框架 ConDA，用于检测由大型语言模型生成的新闻文本。这种方法解决了获取标记训练数据的困难，通过利用未标记的目标数据进行无监督域适应。 |
| [^23] | [LanSER: Language-Model Supported Speech Emotion Recognition.](http://arxiv.org/abs/2309.03978) | LanSER是一种基于语言模型的语音情绪识别方法，通过预先训练的大型语言模型进行弱监督学习，从而使得可以利用未标记数据。实验证明，使用这种弱监督训练的模型在标准SER数据集上表现优于其他基线模型，并且能够模拟语音的韵律内容。 |
| [^24] | [On Large Language Models' Selection Bias in Multi-Choice Questions.](http://arxiv.org/abs/2309.03882) | 本研究发现大型语言模型在多项选择题中存在选择偏差，即倾向于选择特定位置上的选项。研究指出这一偏差的主要原因是选项编号，提出了一种名为PriDe的方法来减轻偏差，并展示了其高精度和稳定性。 |
| [^25] | [Exploring an LM to generate Prolog Predicates from Mathematics Questions.](http://arxiv.org/abs/2309.03667) | 该论文调查了将语言模型用于从数学问题中生成Prolog谓词的潜力，并展示了通过微调模型和使用思维链的方法来提高模型的准确性。结果表明，生成Prolog代码的模型在性能上超过了基准模型。 |
| [^26] | [All Labels Together: Low-shot Intent Detection with an Efficient Label Semantic Encoding Paradigm.](http://arxiv.org/abs/2309.03563) | 这项工作中，我们提出了一个端到端的One-to-All系统，可以在少样本场景下通过比较输入话语与所有标签候选项来充分利用标签语义。实验证明该方法在低资源情况下表现出最先进的性能，并通过预训练策略实现了跨领域零样本泛化。 |
| [^27] | [Large Content And Behavior Models To Understand, Simulate, And Optimize Content And Behavior.](http://arxiv.org/abs/2309.00359) | 该论文提出了使用大型内容和行为模型来理解、模拟和优化内容和行为。大型语言模型虽然在任务泛化能力方面取得了进展，但还无法解决预测和优化通信以实现期望接收者行为的问题。其中的一个原因可能是训练语料库中缺少"行为标记"。 |
| [^28] | [Simple LLM Prompting is State-of-the-Art for Robust and Multilingual Dialogue Evaluation.](http://arxiv.org/abs/2308.16797) | 该论文提出了一个新颖的框架，通过利用当前评估模型的优势和新建立的提示大型语言模型(LLM)范式，实现了稳健的、多语言的对话评估指标。实证结果表明，这个框架在多个基准测试中取得了最先进的结果，并在DSTC11 Track 4中的稳健和多语言任务中排名第一。 |
| [^29] | [When Do Program-of-Thoughts Work for Reasoning?.](http://arxiv.org/abs/2308.15452) | 提出了复杂性影响推理分数（CIRS）来衡量编程语言对推理能力的影响，发现并非所有复杂性的代码数据都可以被学习或理解，适当的复杂性水平对于改善推理能力至关重要。 |
| [^30] | [Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation.](http://arxiv.org/abs/2308.15363) | 本文提出了一个大规模语言模型(LLMs)赋能的文本到SQL任务的基准评估，并基于实验结果提出了一种新的集成解决方案DAIL-SQL，刷新了Spider榜单并实现了86.6%的执行准确率。同时，强调了在提示工程中的词汇效率以实现高效经济的LLM-based文本到SQL解决方案，此外还对在上下文学习中应用开源LLMs进行了研究，并进行了任务特定的性能优化。 |
| [^31] | [From Quantity to Quality: Boosting LLM Performance with Self-Guided Data Selection for Instruction Tuning.](http://arxiv.org/abs/2308.12032) | 该论文引入了一种自我引导的方法，让LLM能够自主地选择高质量的指令数据，通过引入指令遵循难度指标（IFD），大幅提高了模型训练效率，并在知名数据集上进行了验证，展示了优于传统数据输入的结果。 |
| [^32] | [Comparing How a Chatbot References User Utterances from Previous Chatting Sessions: An Investigation of Users' Privacy Concerns and Perceptions.](http://arxiv.org/abs/2308.04879) | 本研究比较了三种不同方式的聊天机器人如何引用用户之前的对话，并发现逐字引用和释义引用的聊天机器人更智能和引人入胜，但逐字引用会引起隐私关注。 |
| [^33] | [ValiTex -- a uniform validation framework for computational text-based measures of social science constructs.](http://arxiv.org/abs/2307.02863) | ValiTex是一个统一的验证框架，旨在帮助学者们基于文本数据来度量社会科学构建。它借鉴了心理测量学的传统，通过概念模型和动态检查表提供了验证的结构和步骤。 |
| [^34] | [A Conditional Generative Chatbot using Transformer Model.](http://arxiv.org/abs/2306.02074) | 本研究提出了一种使用Transformer模型的条件生成式聊天机器人，通过结合Wasserstein生成对抗网络和Transformer模型，在生成器部分使用完整的Transformer模型生成答案，鉴别器部分仅使用Transformer模型的编码器部分，从而解决了序列模型在生成聊天回答时准确性不高的问题。 |
| [^35] | [Entity Tracking in Language Models.](http://arxiv.org/abs/2305.02363) | 本文探究了大型语言模型追踪实体状态的能力，发现经过大量代码预训练的GPT-3.5模型表现最好，即使训练和评估中几乎没有词汇重叠的情况下，仍然可以获得不错的效果。 |
| [^36] | [MQAG: Multiple-choice Question Answering and Generation for Assessing Information Consistency in Summarization.](http://arxiv.org/abs/2301.12307) | MQAG提出了一种基于多选题答案生成和回答的方法来评估摘要中的信息一致性，通过计算预测的答案分布之间的统计距离来近似判断源文档和摘要之间的信息一致性。 |
| [^37] | [TikTalk: A Video-Based Dialogue Dataset for Multi-Modal Chitchat in Real World.](http://arxiv.org/abs/2301.05880) | TikTalk是一个基于视频的多模态对话数据集，用于研究智能且类似人类的闲聊机器人。数据集包含从流行视频分享平台收集的38K个视频和367K个用户对话。与其他数据集相比，TikTalk提供了更丰富的上下文类型，同时也增加了从复杂的多模态信息中生成个性化回答的难度。数据集中还更频繁地引用了外部知识，为多模态对话模型提供了新的挑战。 |
| [^38] | [Less is More: A Lightweight and Robust Neural Architecture for Discourse Parsing.](http://arxiv.org/abs/2210.09537) | 本文提出了一个轻量级神经网络结构，通过移除复杂的特征提取器，仅利用自注意力模块间接利用预训练的神经语言模型，以提高篇章分析任务的泛化能力和鲁棒性。实验证明，这个轻量级结构只有两个自注意力层，却具有更好的性能，并且拥有较少的参数和处理时间。 |
| [^39] | [Detecting Text Formality: A Study of Text Classification Approaches.](http://arxiv.org/abs/2204.08975) | 这项研究提供了首个系统研究文本形式性检测方法，并提供了在单语言和多语言任务中表现最佳的Char BiLSTM模型。 |

# 详细

[^1]: 测量和改进视觉-语言模型中的思维链推理

    Measuring and Improving Chain-of-Thought Reasoning in Vision-Language Models. (arXiv:2309.04461v1 [cs.CL])

    [http://arxiv.org/abs/2309.04461](http://arxiv.org/abs/2309.04461)

    本研究探索了视觉-语言模型展示人类推理能力的能力，并提出了一种基于思维链的一致性度量。通过一个流水线和已有数据集，建立了一个基准来测量这种推理能力。

    

    最近，视觉-语言模型（VLMs）作为能解析关于视觉内容的自然查询并生成类人输出的视觉助手，展示出了强大的功效。在这项工作中，我们探索了这些模型展示基于所感知信息的类人推理的能力。为了解决关于它们的推理能力到底有多一致和有多基于实际的一个重要疑虑，我们还测量了这些模型的推理一致性。我们通过提出一种基于思维链（CoT）的一致性度量来实现这一目标。然而，这样的评估需要涵盖高层次推理和细节推理链的基准，这是一项昂贵的任务。我们通过提出LLM-Human-in-the-Loop流水线来应对这一挑战，该流水线显著降低了成本，同时确保生成高质量的数据集。基于这个流水线和现有的粗粒度注释数据集，我们构建了CURE基准来同时测量两者。

    Vision-language models (VLMs) have recently demonstrated strong efficacy as visual assistants that can parse natural queries about the visual content and generate human-like outputs. In this work, we explore the ability of these models to demonstrate human-like reasoning based on the perceived information. To address a crucial concern regarding the extent to which their reasoning capabilities are fully consistent and grounded, we also measure the reasoning consistency of these models. We achieve this by proposing a chain-of-thought (CoT) based consistency measure. However, such an evaluation requires a benchmark that encompasses both high-level inference and detailed reasoning chains, which is costly. We tackle this challenge by proposing a LLM-Human-in-the-Loop pipeline, which notably reduces cost while simultaneously ensuring the generation of a high-quality dataset. Based on this pipeline and the existing coarse-grained annotated dataset, we build the CURE benchmark to measure both 
    
[^2]: CSPRD: 中国股票市场金融政策检索数据集

    CSPRD: A Financial Policy Retrieval Dataset for Chinese Stock Market. (arXiv:2309.04389v1 [cs.CL])

    [http://arxiv.org/abs/2309.04389](http://arxiv.org/abs/2309.04389)

    本研究引入中国股票政策检索数据集（CSPRD），提供了700+条标注的招股说明书段落，通过词汇、嵌入和经过微调的双编码模型的实验证明了CSPRD的有效性和改进潜力。

    

    在最近几年，预训练语言模型（PLMs）取得了突破性进展，引起了相当多的研究关注，并在稠密段落检索方法上取得了有希望的性能，其目的是检索给定问题的相关段落。然而，大部分现有的数据集主要使用了通常常识的事实性查询来评估模型，而金融和经济等专业领域由于缺乏大规模的高质量数据集和专家注释而未被探索。在这项工作中，我们引入了一个新的任务，即政策检索，通过引入中国股票政策检索数据集（CSPRD），该数据集提供了由有经验的专家对来自我们收集的中国政策语料库中的10k+条目的相关文章进行标注的700+条招股说明书段落。对词汇、嵌入和经过微调的双编码模型的实验证明了我们所提出的CSPRD的有效性，但也提示了改进的丰富潜力。

    In recent years, great advances in pre-trained language models (PLMs) have sparked considerable research focus and achieved promising performance on the approach of dense passage retrieval, which aims at retrieving relative passages from massive corpus with given questions. However, most of existing datasets mainly benchmark the models with factoid queries of general commonsense, while specialised fields such as finance and economics remain unexplored due to the deficiency of large-scale and high-quality datasets with expert annotations. In this work, we propose a new task, policy retrieval, by introducing the Chinese Stock Policy Retrieval Dataset (CSPRD), which provides 700+ prospectus passages labeled by experienced experts with relevant articles from 10k+ entries in our collected Chinese policy corpus. Experiments on lexical, embedding and fine-tuned bi-encoder models show the effectiveness of our proposed CSPRD yet also suggests ample potential for improvement. Our best performing
    
[^3]: MoEController: 使用混合专家控制器的基于指令的任意图像操作

    MoEController: Instruction-based Arbitrary Image Manipulation with Mixture-of-Expert Controllers. (arXiv:2309.04372v1 [cs.CV])

    [http://arxiv.org/abs/2309.04372](http://arxiv.org/abs/2309.04372)

    本论文提出了一种基于混合专家控制器(MoEController)的指令驱动任意图像操作方法，通过对不同类型的人类指令进行适配，使得模型能够处理各种开放域图像操作任务。使用大型语言模型和条件图像合成模型生成训练数据集，并采用MOE技术和任务特定的适应性训练对模型进行训练。

    

    最近，基于扩散模型的文本引导图像生成取得了惊人的进展，在开放域图像操作任务中产生了令人着迷的结果。 然而，由于图像操作任务的复杂性和多样性，目前很少有模型具有完全的零样本能力，既可以进行全局操作，又可以进行局部图像编辑。 在这项工作中，我们提出了一种使用混合专家控制器（MOE）的方法，将扩散模型的文本引导能力与不同类型的人类指令相对齐，使我们的模型能够使用自然语言指令处理各种开放域图像操作任务。 首先，我们使用大型语言模型（ChatGPT）和条件图像合成模型（ControlNet）生成大量全局图像转换数据集，以及基于指令的局部图像编辑数据集。 然后，使用MOE技术和任务特定的适应性训练对大规模数据集进行训练，我们的条件扩散模型可以对图像进行全局和局部编辑。

    Diffusion-model-based text-guided image generation has recently made astounding progress, producing fascinating results in open-domain image manipulation tasks. Few models, however, currently have complete zero-shot capabilities for both global and local image editing due to the complexity and diversity of image manipulation tasks. In this work, we propose a method with a mixture-of-expert (MOE) controllers to align the text-guided capacity of diffusion models with different kinds of human instructions, enabling our model to handle various open-domain image manipulation tasks with natural language instructions. First, we use large language models (ChatGPT) and conditional image synthesis models (ControlNet) to generate a large number of global image transfer dataset in addition to the instruction-based local image editing dataset. Then, using an MOE technique and task-specific adaptation training on a large-scale dataset, our conditional diffusion model can edit images globally and loc
    
[^4]: 超越静态数据集：深度交互方法用于LLM评估

    Beyond Static Datasets: A Deep Interaction Approach to LLM Evaluation. (arXiv:2309.04369v1 [cs.CL])

    [http://arxiv.org/abs/2309.04369](http://arxiv.org/abs/2309.04369)

    该论文提出了一种基于深度交互的LLM评估框架，突破了静态数据集的限制，能够评估LLM在动态实际场景中的能力，并适用于多种实际任务。

    

    大型语言模型（LLM）在各种实际任务中取得了进展，这激发了对LLM评估的需求。现有的LLM评估方法主要依赖于静态数据集的监督信号，无法评估LLM在动态实际场景中的能力，而这些场景中深度交互广泛存在。其他的LLM评估方法基于人工评估，成本高且耗时，并且无法进行大规模的LLM评估。为了解决上述问题，我们提出了一种新颖的基于深度交互的LLM评估框架。在我们提出的框架中，通过精心设计的评估任务，可以评估LLM在实际领域中与其他LLM的深度交互中的性能。此外，我们提出的框架是一种通用的评估方法，可应用于诸多实际任务，如机器翻译和代码生成。通过广泛的实验证明了我们提出的方法的有效性。

    Large Language Models (LLMs) have made progress in various real-world tasks, which stimulates requirements for the evaluation of LLMs. Existing LLM evaluation methods are mainly supervised signal-based which depends on static datasets and cannot evaluate the ability of LLMs in dynamic real-world scenarios where deep interaction widely exists. Other LLM evaluation methods are human-based which are costly and time-consuming and are incapable of large-scale evaluation of LLMs. To address the issues above, we propose a novel Deep Interaction-based LLM-evaluation framework. In our proposed framework, LLMs' performances in real-world domains can be evaluated from their deep interaction with other LLMs in elaborately designed evaluation tasks. Furthermore, our proposed framework is a general evaluation method that can be applied to a host of real-world tasks such as machine translation and code generation. We demonstrate the effectiveness of our proposed method through extensive experiments o
    
[^5]: 使用多个CLS标记集合对多领域科学论文进行编码

    Encoding Multi-Domain Scientific Papers by Ensembling Multiple CLS Tokens. (arXiv:2309.04333v1 [cs.CL])

    [http://arxiv.org/abs/2309.04333](http://arxiv.org/abs/2309.04333)

    本研究提出了Multi2SPE方法，通过使用多个CLS标记来编码多领域科学论文，能够更好地适应不同的科学领域，并在引文预测任务中减少了多达25％的误差。

    

    许多科学文档上的有用任务，如主题分类和引文预测，涉及跨越多个科学领域的语料库。通常，这些任务通过使用来自Transformer的单个CLS标记的向量嵌入来完成。在本文中，我们认为使用多个CLS标记可以使Transformer更好地专注于多个科学领域。我们提出了Multi2SPE：它鼓励多个CLS标记学习聚合标记嵌入的不同方式，然后将它们相加以创建单个向量表示。我们还提出了我们的新的多领域基准测试数据集Multi-SciDocs，以测试多领域设置下的科学论文向量编码器。我们证明Multi2SPE在多领域引文预测中减少了多达25％的误差，同时除了一次BERT前向传递之外，只需要极少量的计算量。

    Many useful tasks on scientific documents, such as topic classification and citation prediction, involve corpora that span multiple scientific domains. Typically, such tasks are accomplished by representing the text with a vector embedding obtained from a Transformer's single CLS token. In this paper, we argue that using multiple CLS tokens could make a Transformer better specialize to multiple scientific domains. We present Multi2SPE: it encourages each of multiple CLS tokens to learn diverse ways of aggregating token embeddings, then sums them up together to create a single vector representation. We also propose our new multi-domain benchmark, Multi-SciDocs, to test scientific paper vector encoders under multi-domain settings. We show that Multi2SPE reduces error by up to 25 percent in multi-domain citation prediction, while requiring only a negligible amount of computation in addition to one BERT forward pass.
    
[^6]: 模糊指纹转换器语言模型用于对话情感识别

    Fuzzy Fingerprinting Transformer Language-Models for Emotion Recognition in Conversations. (arXiv:2309.04292v1 [cs.CL])

    [http://arxiv.org/abs/2309.04292](http://arxiv.org/abs/2309.04292)

    本文提出将模糊指纹和大型语言模型相结合，用于对话情感识别，以获得更简单和更可解释的分类器，并在DailyDialog ERC基准数据集上取得最先进的结果。

    

    模糊指纹已成功用作可解释的文本分类技术，但与大多数其他技术一样，在性能上已被大型预训练语言模型（例如BERT或RoBERTa）大大超越。这些模型在几个自然语言处理任务中取得了最先进的结果，即对话情感识别（ERC），但缺乏可解释性和说明性。在本文中，我们提出将这两种方法结合起来进行ERC，以获得更简单和更可解释的基于大型语言模型的分类器。我们提出将话语及其之前的对话转化为预训练的RoBERTa，并获取上下文嵌入的话语表示，然后将其提供给适应的模糊指纹分类模块。我们在广泛使用的DailyDialog ERC基准数据集上验证了我们的方法，结果显示我们使用了更轻量级的模型获得了最先进的水平。

    Fuzzy Fingerprints have been successfully used as an interpretable text classification technique, but, like most other techniques, have been largely surpassed in performance by Large Pre-trained Language Models, such as BERT or RoBERTa. These models deliver state-of-the-art results in several Natural Language Processing tasks, namely Emotion Recognition in Conversations (ERC), but suffer from the lack of interpretability and explainability. In this paper, we propose to combine the two approaches to perform ERC, as a means to obtain simpler and more interpretable Large Language Models-based classifiers. We propose to feed the utterances and their previous conversational turns to a pre-trained RoBERTa, obtaining contextual embedding utterance representations, that are then supplied to an adapted Fuzzy Fingerprint classification module. We validate our approach on the widely used DailyDialog ERC benchmark dataset, in which we obtain state-of-the-art level results using a much lighter mode
    
[^7]: 从稀疏到稠密：使用密度链提示的GPT-4总结

    From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting. (arXiv:2309.04269v1 [cs.CL])

    [http://arxiv.org/abs/2309.04269](http://arxiv.org/abs/2309.04269)

    在本研究中，我们提出了一种使用“密度链”提示的方法，将GPT-4生成的摘要从稀疏转化为稠密。人们更喜欢密度链摘要，因为它们更具概括性和融合性，并且几乎与人工写作的摘要一样密集。

    

    选择在摘要中包含的“正确”信息量是一项困难的任务。一个好的摘要应该是详细和以实体为中心的，同时又不过于密集和难以理解。为了更好地理解这种权衡，我们使用了一种称为“密度链”（CoD）提示的方式，来产生越来越稠密的GPT-4摘要。具体而言，GPT-4首先生成一个初始的实体稀疏摘要，然后逐步加入缺失的突出实体，而不增加长度。 CoD生成的摘要更为概括，展示了更多的融合，并且比使用普通提示生成的GPT-4摘要具有更少的引导偏见。我们在100篇CNN DailyMail文章上进行了一个人类偏好研究，发现人们更喜欢比普通提示生成的GPT-4摘要更稠密，几乎与人工撰写的摘要一样密集。定性分析支持了信息量和可读性之间存在权衡的观点。

    Selecting the ``right'' amount of information to include in a summary is a difficult task. A good summary should be detailed and entity-centric without being overly dense and hard to follow. To better understand this tradeoff, we solicit increasingly dense GPT-4 summaries with what we refer to as a ``Chain of Density'' (CoD) prompt. Specifically, GPT-4 generates an initial entity-sparse summary before iteratively incorporating missing salient entities without increasing the length. Summaries generated by CoD are more abstractive, exhibit more fusion, and have less of a lead bias than GPT-4 summaries generated by a vanilla prompt. We conduct a human preference study on 100 CNN DailyMail articles and find that that humans prefer GPT-4 summaries that are more dense than those generated by a vanilla prompt and almost as dense as human written summaries. Qualitative analysis supports the notion that there exists a tradeoff between informativeness and readability. 500 annotated CoD summaries
    
[^8]: UQ在#SMM4H 2023上的论文：利用社交媒体进行公共卫生分析的ALEX方法

    UQ at #SMM4H 2023: ALEX for Public Health Analysis with Social Media. (arXiv:2309.04213v1 [cs.CL])

    [http://arxiv.org/abs/2309.04213](http://arxiv.org/abs/2309.04213)

    本文提出了一种名为ALEX的框架，通过采用LLMs解释机制来改进社交媒体上的公共卫生分析性能。该方法通过数据增强和平衡训练解决了数据不平衡问题，并有效利用了LLMs的能力。

    

    随着社交媒体的普及，与公共卫生相关的活动也越来越多。目前的公共卫生分析技术涉及到流行的模型，如BERT和大型语言模型（LLMs）。然而，为公共卫生域训练LLMs的成本尤其昂贵。此外，社交媒体中这种域内数据集往往存在不平衡的问题。为应对这些挑战，可以通过数据增强和平衡训练来解决数据不平衡的问题。此外，可以通过适当设置模型的引导方式有效利用LLMs的能力。本文提出了一种新颖的ALEX框架，通过采用LLMs解释机制来提高社交媒体上的公共卫生分析性能。结果显示，我们的ALEX模型在Social Media Mining for Health 2023 （SMM4H）的任务2和任务4中获得了最佳性能，并在任务1中得到了较高的评分[1]。我们的代码已在 https:/ /github 上发布。

    As social media becomes increasingly popular, more and more activities related to public health emerge. Current techniques for public health analysis involve popular models such as BERT and large language models (LLMs). However, the costs of training in-domain LLMs for public health are especially expensive. Furthermore, such kinds of in-domain datasets from social media are generally imbalanced. To tackle these challenges, the data imbalance issue can be overcome by data augmentation and balanced training. Moreover, the ability of the LLMs can be effectively utilized by prompting the model properly. In this paper, a novel ALEX framework is proposed to improve the performance of public health analysis on social media by adopting an LLMs explanation mechanism. Results show that our ALEX model got the best performance among all submissions in both Task 2 and Task 4 with a high score in Task 1 in Social Media Mining for Health 2023 (SMM4H)[1]. Our code has been released at https:// github
    
[^9]: CALLA数据集：从中文医学文献中探索LLMs的交互式知识获取

    The CALLA Dataset: Probing LLMs' Interactive Knowledge Acquisition from Chinese Medical Literature. (arXiv:2309.04198v1 [cs.CL])

    [http://arxiv.org/abs/2309.04198](http://arxiv.org/abs/2309.04198)

    该研究介绍了CALLA数据集，用于探索LLMs从中文医学文献中获取交互式知识。通过自由对话事实核查任务，评估了LLMs掌握医学知识的能力，并发现了一种称为“事实跟随响应”的现象。为了提供更准确的评估方法，人工构建了两种角度的测试数据：一种与事实一致，一种与事实不一致。

    

    大型语言模型（LLMs）在医学领域的应用引起了研究人员的兴趣。最近的研究集中于通过医学知识图构建指导微调（IFT）数据，以丰富LLMs的交互式医学知识。然而，作为丰富的医学知识来源的医学文献仍未被开发利用。我们的工作引入了CALLA数据集，以探索LLMs从中国医学文献中获取交互式知识。它通过自由对话事实核查任务评估LLMs掌握医学知识的能力。我们发现一种现象称为“事实跟随响应”，LLMs倾向于确认问题中提到的事实，并对挑战这些事实表现出不情愿。为消除这种现象导致的不准确评估，对于黄金事实，我们从两个角度人工构建测试数据：一个与事实一致，一个与事实不一致。根据这些测试数据，我们为LLMs评估其对医学知识的掌握能力提供了更准确的方法。

    The application of Large Language Models (LLMs) to the medical domain has stimulated the interest of researchers. Recent studies have focused on constructing Instruction Fine-Tuning (IFT) data through medical knowledge graphs to enrich the interactive medical knowledge of LLMs. However, the medical literature serving as a rich source of medical knowledge remains unexplored. Our work introduces the CALLA dataset to probe LLMs' interactive knowledge acquisition from Chinese medical literature. It assesses the proficiency of LLMs in mastering medical knowledge through a free-dialogue fact-checking task. We identify a phenomenon called the ``fact-following response``, where LLMs tend to affirm facts mentioned in questions and display a reluctance to challenge them. To eliminate the inaccurate evaluation caused by this phenomenon, for the golden fact, we artificially construct test data from two perspectives: one consistent with the fact and one inconsistent with the fact. Drawing from the 
    
[^10]: 使用结构化医学知识库对大型语言模型进行知识调整，实现中文可靠响应生成

    Knowledge-tuning Large Language Models with Structured Medical Knowledge Bases for Reliable Response Generation in Chinese. (arXiv:2309.04175v1 [cs.CL])

    [http://arxiv.org/abs/2309.04175](http://arxiv.org/abs/2309.04175)

    本研究提出了一种使用结构化医学知识库进行知识调整的方法，以提高大型语言模型在中文可靠响应生成方面的准确性和领域适应能力。

    

    大型语言模型（LLMs）在一般领域的自然语言处理（NLP）任务中取得了显著的成功。然而，由于领域知识的限制，LLMs有时会生成具有关于医学事实的幻觉的响应。这些缺点在医学背景下使用LLMs时存在潜在的风险。为了解决这个挑战，我们提出了知识调整，通过利用结构化医学知识库来使LLMs能够高效掌握领域知识并实现可靠的响应生成。我们还发布了cMedKnowQA，一个从医学知识库构建的中文医学知识问答数据集，以评估LLMs的医学知识水平。实验结果表明，经过cMedKnowQA的知识调整的LLMs，在响应生成方面可以表现出比原始指导调整更高水平的准确性，并为LLMs的领域适应提供了一种可靠的新方式。

    Large Language Models (LLMs) have demonstrated remarkable success in diverse natural language processing (NLP) tasks in general domains. However, LLMs sometimes generate responses with the hallucination about medical facts due to limited domain knowledge. Such shortcomings pose potential risks in the utilization of LLMs within medical contexts. To address this challenge, we propose knowledge-tuning, which leverages structured medical knowledge bases for the LLMs to grasp domain knowledge efficiently and facilitate reliable response generation. We also release cMedKnowQA, a Chinese medical knowledge question-answering dataset constructed from medical knowledge bases to assess the medical knowledge proficiency of LLMs. Experimental results show that the LLMs which are knowledge-tuned with cMedKnowQA, can exhibit higher levels of accuracy in response generation compared with vanilla instruction-tuning and offer a new reliable way for the domain adaptation of LLMs.
    
[^11]: 基于流形的无调参提示分类的重新嵌入方法

    Manifold-based Verbalizer Space Re-embedding for Tuning-free Prompt-based Classification. (arXiv:2309.04174v1 [cs.CL])

    [http://arxiv.org/abs/2309.04174](http://arxiv.org/abs/2309.04174)

    本研究提出了一种无需调参的基于流形的语言转换器嵌入方法，通过保留同一类中的局部特性来进行分类，实验证明其与自动化的语言转换器效果相当。

    

    提示分类通过利用[MASK]标记的遗漏问题形式来适应任务，然后通过预定义的语言转换器将填充的标记映射到标签上。最近的研究已经探索了使用语言转换器嵌入来减少这一过程中的劳动力。然而，所有现有的研究都需要对预训练模型或附加可训练嵌入进行调参过程。同时，由于表示空间中潜在的非线性流形，高维语言转换器嵌入之间的距离不应该使用欧氏距离来衡量。在本研究中，我们提出了一种无调参基于流形的空间重新嵌入方法，称为具有内类近邻约束的局部线性嵌入（LLE-INC），用于语言转换器嵌入，它保留了同一类中的局部特性作为分类的引导。实验结果表明，即使不进行任何参数调优，我们的LLE-INC与自动化的语言转换器相媲美。

    Prompt-based classification adapts tasks to a cloze question format utilizing the [MASK] token and the filled tokens are then mapped to labels through pre-defined verbalizers. Recent studies have explored the use of verbalizer embeddings to reduce labor in this process. However, all existing studies require a tuning process for either the pre-trained models or additional trainable embeddings. Meanwhile, the distance between high-dimensional verbalizer embeddings should not be measured by Euclidean distance due to the potential for non-linear manifolds in the representation space. In this study, we propose a tuning-free manifold-based space re-embedding method called Locally Linear Embedding with Intra-class Neighborhood Constraint (LLE-INC) for verbalizer embeddings, which preserves local properties within the same class as guidance for classification. Experimental results indicate that even without tuning any parameters, our LLE-INC is on par with automated verbalizers with parameter 
    
[^12]: GLS-CSC: 一种简单但有效的策略来减少中文STM模型对表面线索的依赖

    GLS-CSC: A Simple but Effective Strategy to Mitigate Chinese STM Models' Over-Reliance on Superficial Clue. (arXiv:2309.04162v1 [cs.CL])

    [http://arxiv.org/abs/2309.04162](http://arxiv.org/abs/2309.04162)

    本研究提出了GLS-CSC，一种用于缓解中文STM模型对表面线索过度依赖的简单但有效的策略。通过分析编辑距离特征的影响，我们证明GLS-CSC能够提高中文STM模型的鲁棒性和泛化性能。

    

    预训练模型在中文短文本匹配任务中取得了成功，但它们往往依赖于表面线索，导致缺乏鲁棒性的预测。为了解决这个问题，分析和减少表面线索对STM模型的影响至关重要。本研究旨在调查编辑距离特征对STM模型的过度依赖情况，编辑距离常被用来衡量中文文本对的语义相似度，可以被认为是表面线索。为了减少STM模型对表面线索的依赖，我们提出了一种名为Gradually Learn Samples Containing Superficial Clue (GLS-CSC)的新的重采样训练策略。通过对领域内（I.D.）、鲁棒性（Rob.）和领域外（O.O.D.）测试集的全面评估，我们证明了GLS-CSC在增强中文STM模型的鲁棒性和泛化性方面优于现有方法。此外，我们对现有方法进行了详细分析，并揭示了它们的共同点。

    Pre-trained models have achieved success in Chinese Short Text Matching (STM) tasks, but they often rely on superficial clues, leading to a lack of robust predictions. To address this issue, it is crucial to analyze and mitigate the influence of superficial clues on STM models. Our study aims to investigate their over-reliance on the edit distance feature, commonly used to measure the semantic similarity of Chinese text pairs, which can be considered a superficial clue. To mitigate STM models' over-reliance on superficial clues, we propose a novel resampling training strategy called Gradually Learn Samples Containing Superficial Clue (GLS-CSC). Through comprehensive evaluations of In-Domain (I.D.), Robustness (Rob.), and Out-Of-Domain (O.O.D.) test sets, we demonstrate that GLS-CSC outperforms existing methods in terms of enhancing the robustness and generalization of Chinese STM models. Moreover, we conduct a detailed analysis of existing methods and reveal their commonality.
    
[^13]: 跨发言条件化VAE语音生成

    Cross-Utterance Conditioned VAE for Speech Generation. (arXiv:2309.04156v1 [cs.SD])

    [http://arxiv.org/abs/2309.04156](http://arxiv.org/abs/2309.04156)

    该论文提出了一种跨发言条件化变分自编码器框架，利用预训练语言模型和变分自编码器来增强语音合成的韵律，并确保自然语音生成。该框架的核心组件是跨发言CVAE，通过提取周围句子的声学、说话人和文本特征来生成上下文敏感的韵律特征，有效模拟人类韵律生成。同时，该论文还提出了两个实用算法：CUC-VAE TTS用于文本到语音合成和CUC-VAE SE用于语音编辑。

    

    由神经网络驱动的语音合成系统在多媒体制作中有着潜力，但常常面临产生有表现力的语音和无缝编辑的问题。为此，我们提出了跨发言条件化变分自编码器语音合成(CUC-VAE S2)框架，以增强韵律并确保自然语音生成。该框架利用预训练语言模型的强大表现能力和变分自编码器(VAEs)的再表达能力。CUC-VAE S2框架的核心组件是跨发言CVAE，它从周围的句子中提取声学、说话人和文本特征，以生成上下文敏感的韵律特征，更准确地模拟人类韵律生成。我们进一步提出了两个针对不同语音合成应用的实用算法：CUC-VAE TTS以进行文本到语音合成和CUC-VAE SE以进行语音编辑。CUC-VAE TTS是该框架的直接应用，使得能够将任意文本转成语音。

    Speech synthesis systems powered by neural networks hold promise for multimedia production, but frequently face issues with producing expressive speech and seamless editing. In response, we present the Cross-Utterance Conditioned Variational Autoencoder speech synthesis (CUC-VAE S2) framework to enhance prosody and ensure natural speech generation. This framework leverages the powerful representational capabilities of pre-trained language models and the re-expression abilities of variational autoencoders (VAEs). The core component of the CUC-VAE S2 framework is the cross-utterance CVAE, which extracts acoustic, speaker, and textual features from surrounding sentences to generate context-sensitive prosodic features, more accurately emulating human prosody generation. We further propose two practical algorithms tailored for distinct speech synthesis applications: CUC-VAE TTS for text-to-speech and CUC-VAE SE for speech editing. The CUC-VAE TTS is a direct application of the framework, de
    
[^14]: NESTLE：一种用于法律语料库统计分析的无代码工具

    NESTLE: a No-Code Tool for Statistical Analysis of Legal Corpus. (arXiv:2309.04146v1 [cs.CL])

    [http://arxiv.org/abs/2309.04146](http://arxiv.org/abs/2309.04146)

    NESTLE是一个无代码工具，用于进行大规模法律语料库的统计分析。它提供了搜索引擎、端到端的信息提取系统和一个大语言模型，可以通过聊天界面进行操作，使用户可以搜索目标文件、提取信息并可视化数据。

    

    大规模法律语料库的统计分析可以提供有价值的法律见解。为了进行这样的分析，需要使用文档检索工具选择语料库的子集，使用信息提取（IE）系统对文本进行结构化，并对数据进行可视化以进行统计分析。每个过程都需要专业工具或编程技能，然而还没有全面的无代码工具可用。尤其是对于IE，如果IE系统的本体中没有预定义的目标信息，那么需要自己构建系统。在这里，我们提供了NESTLE，一种用于大规模法律语料库统计分析的无代码工具。通过NESTLE，用户可以通过聊天界面搜索目标文件、提取信息，并通过辅助GUI进行细致级别的控制来可视化结构化数据。NESTLE由三个主要组件组成：搜索引擎、端到端的IE系统和一个大语言模型（LLM），它将各个组件连接起来。

    The statistical analysis of large scale legal corpus can provide valuable legal insights. For such analysis one needs to (1) select a subset of the corpus using document retrieval tools, (2) structuralize text using information extraction (IE) systems, and (3) visualize the data for the statistical analysis. Each process demands either specialized tools or programming skills whereas no comprehensive unified "no-code" tools have been available. Especially for IE, if the target information is not predefined in the ontology of the IE system, one needs to build their own system. Here we provide NESTLE, a no code tool for large-scale statistical analysis of legal corpus. With NESTLE, users can search target documents, extract information, and visualize the structured data all via the chat interface with accompanying auxiliary GUI for the fine-level control. NESTLE consists of three main components: a search engine, an end-to-end IE system, and a Large Language Model (LLM) that glues the who
    
[^15]: 由文档级内容结构指导的基于RST的话语解析

    RST-style Discourse Parsing Guided by Document-level Content Structures. (arXiv:2309.04141v1 [cs.CL])

    [http://arxiv.org/abs/2309.04141](http://arxiv.org/abs/2309.04141)

    本研究提出了一种基于RST的话语解析流水线，通过结合文档级内容结构，使用结构感知的新闻内容句子表示，提高了大文本范围话语关系的预测性能。

    

    修辞结构理论(RST)基于话语解析探索了从从子句、句子到大文本范围如何组成一个整体话语，并以分层树的形式呈现修辞结构。现有的RST解析流水线在构建修辞结构时缺乏对文档级内容结构的了解，导致在预测大文本范围的话语关系时性能相对较低。基于意识到高级内容相关信息在促进话语关系识别方面的价值，我们提出了一种新的RST-DP流水线，该流水线融入了从新闻话语建模任务中得出的结构感知的新闻内容句子表示。通过仅增加几个额外的层次，这个增强的流水线在各种RST解析指标上展现了有希望的性能。

    Rhetorical Structure Theory based Discourse Parsing (RST-DP) explores how clauses, sentences, and large text spans compose a whole discourse and presents the rhetorical structure as a hierarchical tree. Existing RST parsing pipelines construct rhetorical structures without the knowledge of document-level content structures, which causes relatively low performance when predicting the discourse relations for large text spans. Recognizing the value of high-level content-related information in facilitating discourse relation recognition, we propose a novel pipeline for RST-DP that incorporates structure-aware news content sentence representations derived from the task of News Discourse Profiling. By incorporating only a few additional layers, this enhanced pipeline exhibits promising performance across various RST parsing metrics.
    
[^16]: 自然语言的元预测学习模型

    Meta predictive learning model of natural languages. (arXiv:2309.04106v1 [cs.CL])

    [http://arxiv.org/abs/2309.04106](http://arxiv.org/abs/2309.04106)

    该论文提出了一种基于预测编码框架的均场学习模型，通过假设突触权重遵循脉冲和斑点分布并只对分布进行训练，成功地应用于手写数字分类。

    

    基于自注意机制的大型语言模型不仅在自然语言本身上取得了令人惊讶的表现，而且在各种不同性质的任务中也表现出色。然而，关于语言处理，我们的人脑可能不是按照同样的原理运作。因此，关于大型语言模型采用的人工自我监督与脑计算之间的联系引起了一场辩论。在脑计算中最有影响力的假设之一是预测编码框架，该框架提出通过局部学习来最小化预测误差。然而，预测编码和相关的学分分配在语言处理中的作用仍然未知。在这里，我们提出了一个基于预测编码框架的均场学习模型，假设每个连接的突触权重遵循脉冲和斑点分布，只对分布进行训练。这种元预测学习在手写数字分类上得到了成功验证。

    Large language models based on self-attention mechanisms have achieved astonishing performances not only in natural language itself, but also in a variety of tasks of different nature. However, regarding processing language, our human brain may not operate using the same principle. Then, a debate is established on the connection between brain computation and artificial self-supervision adopted in large language models. One of most influential hypothesis in brain computation is the predictive coding framework, which proposes to minimize the prediction error by local learning. However, the role of predictive coding and the associated credit assignment in language processing remains unknown. Here, we propose a mean-field learning model within the predictive coding framework, assuming that the synaptic weight of each connection follows a spike and slab distribution, and only the distribution is trained. This meta predictive learning is successfully validated on classifying handwritten digi
    
[^17]: 无监督多文档综述的整体推理方法

    Unsupervised Multi-document Summarization with Holistic Inference. (arXiv:2309.04087v1 [cs.CL])

    [http://arxiv.org/abs/2309.04087](http://arxiv.org/abs/2309.04087)

    本文提出了一种新的整体框架，用于无监督的多文档提取式综述。通过将整体波束搜索推理方法与名为SRI的整体度量相结合，平衡了同一主题的文档中子集句子的重要性和多样性，并在不同设置下通过实验证明了方法的有效性。

    

    多文档综述旨在从一组关于同一主题的文档中获取核心信息。本文提出了一种新的整体框架用于无监督的多文档提取式综述。我们的方法将整体波束搜索推理方法与名为子集代表指标（SRI）的整体度量相结合。SRI平衡了来自源文档的句子子集的重要性和多样性，并可在无监督和自适应的方式下计算。为了证明我们方法的有效性，我们在小规模和大规模多文档综述数据集上进行了大量实验，包括无监督和自适应设置。根据结果的ROUGE评分和多样性指标，经过显著的差距，所提出的方法优于强基准线。我们的研究结果还表明，多样性对提高多文档综述的性能至关重要。

    Multi-document summarization aims to obtain core information from a collection of documents written on the same topic. This paper proposes a new holistic framework for unsupervised multi-document extractive summarization. Our method incorporates the holistic beam search inference method associated with the holistic measurements, named Subset Representative Index (SRI). SRI balances the importance and diversity of a subset of sentences from the source documents and can be calculated in unsupervised and adaptive manners. To demonstrate the effectiveness of our method, we conduct extensive experiments on both small and large-scale multi-document summarization datasets under both unsupervised and adaptive settings. The proposed method outperforms strong baselines by a significant margin, as indicated by the resulting ROUGE scores and diversity measures. Our findings also suggest that diversity is essential for improving multi-document summary performance.
    
[^18]: 评估和缓解多模态大型语言模型中的失识症

    Evaluation and Mitigation of Agnosia in Multimodal Large Language Models. (arXiv:2309.04041v1 [cs.CV])

    [http://arxiv.org/abs/2309.04041](http://arxiv.org/abs/2309.04041)

    本文针对多模态大型语言模型中存在的失识症问题，提出了一种评估和缓解的框架EMMA。通过类比神经心理学中的失识症现象，定义了MLLM中的失识症，并提出了相应的评估和治疗方法。评估模块通过创建多样化的视觉问答示例来评估失识症程度，治疗模块则采用修正和增强的训练方法来减轻和纠正失识症。

    

    尽管多模态大型语言模型（MLLMs）被广泛用于各种视觉语言任务，但观察到它们有时会误解视觉输入，甚至在简单情况下未能遵循文本指令，导致无关的回复、错误和无根据的主张。我们将这一观察类比于神经心理学中的一种现象，即失识症，即无法正确处理感觉模态和认识事物（例如，对象、颜色、关系）。在我们的研究中，我们采用这一类似的概念来定义“MLLM中的失识症”，我们的目标是全面评估和缓解MLLM中的失识症。受到神经心理学中的诊断和治疗过程的启发，我们提出了一种新的框架EMMA（评估和缓解多模态失识症）。在EMMA中，我们开发了一个评估模块，用于自动创建细粒度和多样化的视觉问答示例，全面评估MLLM中的失识症程度。我们还提出了一种治疗模块，使用修正和增强的训练方法来减轻和纠正MLLM中的失识症。

    While Multimodal Large Language Models (MLLMs) are widely used for a variety of vision-language tasks, one observation is that they sometimes misinterpret visual inputs or fail to follow textual instructions even in straightforward cases, leading to irrelevant responses, mistakes, and ungrounded claims. This observation is analogous to a phenomenon in neuropsychology known as Agnosia, an inability to correctly process sensory modalities and recognize things (e.g., objects, colors, relations). In our study, we adapt this similar concept to define "agnosia in MLLMs", and our goal is to comprehensively evaluate and mitigate such agnosia in MLLMs. Inspired by the diagnosis and treatment process in neuropsychology, we propose a novel framework EMMA (Evaluation and Mitigation of Multimodal Agnosia). In EMMA, we develop an evaluation module that automatically creates fine-grained and diverse visual question answering examples to assess the extent of agnosia in MLLMs comprehensively. We also d
    
[^19]: 大型语言模型到端到端ASR系统的多重表示转移

    Multiple Representation Transfer from Large Language Models to End-to-End ASR Systems. (arXiv:2309.04031v1 [cs.CL])

    [http://arxiv.org/abs/2309.04031](http://arxiv.org/abs/2309.04031)

    本研究探索了将大型语言模型的多个表示转移到端到端自动语音识别系统中的技术，并证明了此方法的有效性。

    

    将大型语言模型的知识转移是将语言知识整合到端到端自动语音识别系统的一种有前途的技术。然而，现有的工作只能转移LLM的单个表示（例如，预训练BERT的最后一层），而文本的表示在本质上是非唯一的，可以通过不同层、上下文和模型以各种方式获得。在这项工作中，我们探索了各种技术来获得和转移LLMs的多个表示到基于传导器的ASR系统中。尽管在概念上简单，但我们证明了将LLMs的多个表示转移可以是转移单个表示的有效替代方法。

    Transferring the knowledge of large language models (LLMs) is a promising technique to incorporate linguistic knowledge into end-to-end automatic speech recognition (ASR) systems. However, existing works only transfer a single representation of LLM (e.g. the last layer of pretrained BERT), while the representation of a text is inherently non-unique and can be obtained variously from different layers, contexts and models. In this work, we explore a wide range of techniques to obtain and transfer multiple representations of LLMs into a transducer-based ASR system. While being conceptually simple, we show that transferring multiple representations of LLMs can be an effective alternative to transferring only a single representation.
    
[^20]: TIDE: 用于评估和增强分类和语言模型的文本身份检测

    TIDE: Textual Identity Detection for Evaluating and Augmenting Classification and Language Models. (arXiv:2309.04027v1 [cs.CL])

    [http://arxiv.org/abs/2309.04027](http://arxiv.org/abs/2309.04027)

    本文介绍了TIDE（Textual Identity Detection）方法来改善分类器和语言模型中的文本公平性。通过创建一个包含身份词汇和语境的数据集，以及开发一个身份注释和增强工具，可以提高机器学习公平性技术的效果。

    

    机器学习模型可以继承不公正和不平衡数据集中的意外偏见。在文本数据集中，评估和去偏这些数据集和模型尤其困难，因为种族、性别和性取向等敏感属性可能不可用。当这些模型投放到社会中时，它们可能对历史上弱势群体产生不公平的结果。本文提出了一个与方法相结合的数据集，以改善分类器和语言模型中的文本公平性。我们创建了一个更全面的身份词汇表TIDAL，包括15,123个身份术语和相关的语境，涵盖了三个人口统计类别。我们利用TIDAL开发了一个身份注释和增强工具，可以用于改善身份语境的可用性和机器学习公平性技术的效果。我们使用人类贡献者对我们的方法进行了评估，并进行了重点关注数据集和模型去偏的实验。

    Machine learning models can perpetuate unintended biases from unfair and imbalanced datasets. Evaluating and debiasing these datasets and models is especially hard in text datasets where sensitive attributes such as race, gender, and sexual orientation may not be available. When these models are deployed into society, they can lead to unfair outcomes for historically underrepresented groups. In this paper, we present a dataset coupled with an approach to improve text fairness in classifiers and language models. We create a new, more comprehensive identity lexicon, TIDAL, which includes 15,123 identity terms and associated sense context across three demographic categories. We leverage TIDAL to develop an identity annotation and augmentation tool that can be used to improve the availability of identity context and the effectiveness of ML fairness techniques. We evaluate our approaches using human contributors, and additionally run experiments focused on dataset and model debiasing. Resul
    
[^21]: 评估大型语言模型在发现基因集合功能方面的应用

    Evaluation of large language models for discovery of gene set function. (arXiv:2309.04019v1 [q-bio.GN])

    [http://arxiv.org/abs/2309.04019](http://arxiv.org/abs/2309.04019)

    本研究评估了OpenAI的GPT-4大型语言模型在发现基因集合功能方面的能力，并发现它能根据嵌入的生物医学知识生成与Gene Ontology中具名基因集合非常相似的名称，同时在基因组学数据中发现的基因集合中，GPT-4的命名更具信息量，得到了人工审核的基本验证。

    

    基因集合分析是功能基因组学的重要方法，但它依赖于手动创建的基因功能数据库，这些数据库的不完整和不具备生物学上下文的特点。本文评估了OpenAI的GPT-4大型语言模型的能力，从其嵌入的生物医学知识中发展出有关常见基因功能的假设。我们创建了一个GPT-4流水线，用于用总结其共识功能的名称标记基因集合，并通过分析文本和引文进行证实。在与Gene Ontology中的具名基因集合进行基准测试时，GPT-4在50%的情况下生成了非常相似的名称，而在大多数其他情况下，则恢复了更一般概念的名称。在基因组学数据中发现的基因集合中，与基因集合富集相比，GPT-4的命名更具信息量，其支持性陈述和引文在人工审核中得到了基本验证。快速综合常见基因功能的能力使得大型语言模型成为有价值的功能基因组学助手。

    Gene set analysis is a mainstay of functional genomics, but it relies on manually curated databases of gene functions that are incomplete and unaware of biological context. Here we evaluate the ability of OpenAI's GPT-4, a Large Language Model (LLM), to develop hypotheses about common gene functions from its embedded biomedical knowledge. We created a GPT-4 pipeline to label gene sets with names that summarize their consensus functions, substantiated by analysis text and citations. Benchmarking against named gene sets in the Gene Ontology, GPT-4 generated very similar names in 50% of cases, while in most remaining cases it recovered the name of a more general concept. In gene sets discovered in 'omics data, GPT-4 names were more informative than gene set enrichment, with supporting statements and citations that largely verified in human review. The ability to rapidly synthesize common gene functions positions LLMs as valuable functional genomics assistants.
    
[^22]: ConDA: 基于对比域适应的AI生成文本检测

    ConDA: Contrastive Domain Adaptation for AI-generated Text Detection. (arXiv:2309.03992v1 [cs.CL])

    [http://arxiv.org/abs/2309.03992](http://arxiv.org/abs/2309.03992)

    创新点：提出了一种基于对比域适应的框架 ConDA，用于检测由大型语言模型生成的新闻文本。这种方法解决了获取标记训练数据的困难，通过利用未标记的目标数据进行无监督域适应。

    

    大型语言模型（LLMs）越来越多地被用于各种用途的文本生成，包括新闻报道。鉴于这些LLMs可能被恶意使用来大规模生成虚假信息，构建有效的检测AI生成文本的工具显得尤为重要。由于新的LLMs不断被开发，获取用于监督式检测器的标记训练数据成为一个瓶颈。然而，可能存在大量未标记的文本数据，没有关于其生成器的信息。在这项工作中，我们解决了此数据问题，即检测AI生成的新闻文本，并将问题框架化为无监督域适应任务。这里的域是不同的文本生成器，即LLMs，我们假设只能访问标记的源数据和未标记的目标数据。我们开发了一个名为ConDA的对比域适应框架，将标准的域适应技术与表示能力相结合。

    Large language models (LLMs) are increasingly being used for generating text in a variety of use cases, including journalistic news articles. Given the potential malicious nature in which these LLMs can be used to generate disinformation at scale, it is important to build effective detectors for such AI-generated text. Given the surge in development of new LLMs, acquiring labeled training data for supervised detectors is a bottleneck. However, there might be plenty of unlabeled text data available, without information on which generator it came from. In this work we tackle this data problem, in detecting AI-generated news text, and frame the problem as an unsupervised domain adaptation task. Here the domains are the different text generators, i.e. LLMs, and we assume we have access to only the labeled source data and unlabeled target data. We develop a Contrastive Domain Adaptation framework, called ConDA, that blends standard domain adaptation techniques with the representation power 
    
[^23]: LanSER: 基于语言模型的语音情绪识别

    LanSER: Language-Model Supported Speech Emotion Recognition. (arXiv:2309.03978v1 [cs.CL])

    [http://arxiv.org/abs/2309.03978](http://arxiv.org/abs/2309.03978)

    LanSER是一种基于语言模型的语音情绪识别方法，通过预先训练的大型语言模型进行弱监督学习，从而使得可以利用未标记数据。实验证明，使用这种弱监督训练的模型在标准SER数据集上表现优于其他基线模型，并且能够模拟语音的韵律内容。

    

    语音情绪识别（SER）模型通常依赖于昂贵的人工标注数据进行训练，使得对大型语音数据集和微妙情绪分类的扩展方法困难重重。我们提出了LanSER，一种通过预训练的大型语言模型通过弱监督学习来推测弱情绪标签，从而实现对未标记数据的使用。对于受到分类约束的弱标签推测，我们采用了一种文本蕴涵方法，通过自动语音识别提取的语音转录中选择一个具有最高蕴涵得分的情绪标签。我们的实验结果表明，使用这种弱监督训练的大型数据集预训练的模型在标准SER数据集上的性能超过其他基线模型，并显示出改进的标签效率。尽管只在文本上推测出的标签进行预训练，我们展示了所得到的表示似乎能够模拟语音的韵律内容。

    Speech emotion recognition (SER) models typically rely on costly human-labeled data for training, making scaling methods to large speech datasets and nuanced emotion taxonomies difficult. We present LanSER, a method that enables the use of unlabeled data by inferring weak emotion labels via pre-trained large language models through weakly-supervised learning. For inferring weak labels constrained to a taxonomy, we use a textual entailment approach that selects an emotion label with the highest entailment score for a speech transcript extracted via automatic speech recognition. Our experimental results show that models pre-trained on large datasets with this weak supervision outperform other baseline models on standard SER datasets when fine-tuned, and show improved label efficiency. Despite being pre-trained on labels derived only from text, we show that the resulting representations appear to model the prosodic content of speech.
    
[^24]: 关于大型语言模型在多项选择题中的选择偏差问题

    On Large Language Models' Selection Bias in Multi-Choice Questions. (arXiv:2309.03882v1 [cs.CL])

    [http://arxiv.org/abs/2309.03882](http://arxiv.org/abs/2309.03882)

    本研究发现大型语言模型在多项选择题中存在选择偏差，即倾向于选择特定位置上的选项。研究指出这一偏差的主要原因是选项编号，提出了一种名为PriDe的方法来减轻偏差，并展示了其高精度和稳定性。

    

    多项选择题（MCQs）是大型语言模型（LLMs）研究中常见且重要的任务格式。我们的工作表明，LLMs在MCQs中存在固有的“选择偏差”，即LLMs倾向于选择特定位置上的选项（如“选项C”）。这种偏差在各种LLMs中普遍存在，使得它们在MCQs中对选项位置变化的性能变得脆弱。我们发现导致选择偏差的一个主要原因是选项编号，即与选项相关的ID符号A/B/C/D。为了减轻选择偏差，我们提出了一种新方法称为PriDe。PriDe首先将观察到的模型预测分布分解为对选项内容的内在预测和对选项ID的先验分布。然后，它通过在少量测试样本上对选项内容进行排列组合来估计先验，从而用于消除后续测试样本的偏差。我们证明了作为一种无标签、推断时间方法，PriDe可以实现高精度且稳定的解决方案。

    Multi-choice questions (MCQs) serve as a common yet important task format in the research of large language models (LLMs). Our work shows that LLMs exhibit an inherent "selection bias" in MCQs, which refers to LLMs' preferences to select options located at specific positions (like "Option C"). This bias is prevalent across various LLMs, making their performance vulnerable to option position changes in MCQs. We identify that one primary cause resulting in selection bias is option numbering, i.e., the ID symbols A/B/C/D associated with the options. To mitigate selection bias, we propose a new method called PriDe. PriDe first decomposes the observed model prediction distribution into an intrinsic prediction over option contents and a prior distribution over option IDs. It then estimates the prior by permutating option contents on a small number of test samples, which is used to debias the subsequent test samples. We demonstrate that, as a label-free, inference-time method, PriDe achieves 
    
[^25]: 从数学问题中生成Prolog谓词的语言模型的探索

    Exploring an LM to generate Prolog Predicates from Mathematics Questions. (arXiv:2309.03667v1 [cs.CL])

    [http://arxiv.org/abs/2309.03667](http://arxiv.org/abs/2309.03667)

    该论文调查了将语言模型用于从数学问题中生成Prolog谓词的潜力，并展示了通过微调模型和使用思维链的方法来提高模型的准确性。结果表明，生成Prolog代码的模型在性能上超过了基准模型。

    

    最近，由ChatGPT驱动的自然语言处理（NLP）的兴趣急剧增加。ChatGPT是一个基于Transformer的大规模生成语言模型，展示了在各种基于自然语言的任务上的多样性。然而，大型语言模型在需要推理的数学问题解决中通常表现较差。先前的研究已经证明了通过思维链激励在增强推理能力方面的有效性。现在，我们的目标是研究是否通过微调模型来生成逻辑语言（Prolog）代码，并将这些代码传递给编译器可以进一步提高准确性。因此，我们使用思维链来微调LLaMA7B作为基准模型，并开发其他用于生成Prolog代码、Prolog代码+思维链、思维链+Prolog代码的微调LLaMA7B模型。结果显示，Prolog生成模型超过了基准模型的性能，而还依然思维链。

    Recently, there has been a surge in interest in NLP driven by ChatGPT. ChatGPT, a transformer-based generative language model of substantial scale, exhibits versatility in performing various tasks based on natural language. Nevertheless, large language models often exhibit poor performance in solving mathematics questions that require reasoning. Prior research has demonstrated the effectiveness of chain-of-thought prompting in enhancing reasoning capabilities. Now, we aim to investigate whether fine-tuning a model for the generation of Prolog codes, a logic language, and subsequently passing these codes to a compiler can further improve accuracy. Consequently, we employ chain-of-thought to fine-tune LLaMA7B as a baseline model and develop other fine-tuned LLaMA7B models for the generation of Prolog code, Prolog code + chain-of-thought, and chain-of-thought + Prolog code, respectively. The results reveal that the Prolog generation model surpasses the baseline in performance, while the c
    
[^26]: 全部标签在一起：基于高效的标签语义编码范式的低资源意图检测

    All Labels Together: Low-shot Intent Detection with an Efficient Label Semantic Encoding Paradigm. (arXiv:2309.03563v1 [cs.CL])

    [http://arxiv.org/abs/2309.03563](http://arxiv.org/abs/2309.03563)

    这项工作中，我们提出了一个端到端的One-to-All系统，可以在少样本场景下通过比较输入话语与所有标签候选项来充分利用标签语义。实验证明该方法在低资源情况下表现出最先进的性能，并通过预训练策略实现了跨领域零样本泛化。

    

    在意图检测任务中，利用意图标签的有意义的语义信息对于少样本场景可能特别有益。然而，现有的少样本意图检测方法要么忽略了意图标签，（例如将意图视为索引），要么没有充分利用这些信息（例如仅使用部分意图标签）。在这项工作中，我们提出了一个端到端的One-to-All系统，可以将输入话语与所有标签候选项进行比较。系统可以通过这种方式充分利用标签语义。在三个少样本意图检测任务上的实验证明，当训练资源极为有限时，One-to-All特别有效，在1-shot、3-shot和5-shot设置中实现了最先进的性能。此外，我们还提出了一种新颖的预训练策略，利用了从释义得到的间接监督信号，实现了对意图检测任务的跨领域零样本泛化。我们的代码位于https://github.com/jian

    In intent detection tasks, leveraging meaningful semantic information from intent labels can be particularly beneficial for few-shot scenarios. However, existing few-shot intent detection methods either ignore the intent labels, (e.g. treating intents as indices) or do not fully utilize this information (e.g. only using part of the intent labels). In this work, we present an end-to-end One-to-All system that enables the comparison of an input utterance with all label candidates. The system can then fully utilize label semantics in this way. Experiments on three few-shot intent detection tasks demonstrate that One-to-All is especially effective when the training resource is extremely scarce, achieving state-of-the-art performance in 1-, 3- and 5-shot settings. Moreover, we present a novel pretraining strategy for our model that utilizes indirect supervision from paraphrasing, enabling zero-shot cross-domain generalization on intent detection tasks. Our code is at https://github.com/jian
    
[^27]: 大型内容和行为模型用于理解、模拟和优化内容和行为

    Large Content And Behavior Models To Understand, Simulate, And Optimize Content And Behavior. (arXiv:2309.00359v1 [cs.CL])

    [http://arxiv.org/abs/2309.00359](http://arxiv.org/abs/2309.00359)

    该论文提出了使用大型内容和行为模型来理解、模拟和优化内容和行为。大型语言模型虽然在任务泛化能力方面取得了进展，但还无法解决预测和优化通信以实现期望接收者行为的问题。其中的一个原因可能是训练语料库中缺少"行为标记"。

    

    香农在引入信息理论的经典论文中将通信分为三个层次：技术层、语义层和效果层。技术层关注的是准确重构传输的符号，而语义层和效果层则涉及推断出的意义及其对接收者的影响。得益于电信技术，第一层问题已经取得了较大的进步，如互联网。大型语言模型（LLM）在第二个目标方面取得了一些进展，但第三层仍然基本上未被触及。第三个问题涉及预测和优化通信以实现期望的接收者行为。LLM在各种任务中显示出了广泛的泛化能力，但无法解决这个问题。表现不佳的原因之一可能是LLM的训练语料库中缺少"行为标记"。行为标记定义了在一次通信中的接收者行为，如分享、点赞、点击、购买、转推等。

    Shannon, in his seminal paper introducing information theory, divided the communication into three levels: technical, semantic, and effectivenss. While the technical level is concerned with accurate reconstruction of transmitted symbols, the semantic and effectiveness levels deal with the inferred meaning and its effect on the receiver. Thanks to telecommunications, the first level problem has produced great advances like the internet. Large Language Models (LLMs) make some progress towards the second goal, but the third level still remains largely untouched. The third problem deals with predicting and optimizing communication for desired receiver behavior. LLMs, while showing wide generalization capabilities across a wide range of tasks, are unable to solve for this. One reason for the underperformance could be a lack of "behavior tokens" in LLMs' training corpora. Behavior tokens define receiver behavior over a communication, such as shares, likes, clicks, purchases, retweets, etc. W
    
[^28]: 简单的LLM提示是稳健且多语言对话评价的最先进技术

    Simple LLM Prompting is State-of-the-Art for Robust and Multilingual Dialogue Evaluation. (arXiv:2308.16797v1 [cs.CL])

    [http://arxiv.org/abs/2308.16797](http://arxiv.org/abs/2308.16797)

    该论文提出了一个新颖的框架，通过利用当前评估模型的优势和新建立的提示大型语言模型(LLM)范式，实现了稳健的、多语言的对话评估指标。实证结果表明，这个框架在多个基准测试中取得了最先进的结果，并在DSTC11 Track 4中的稳健和多语言任务中排名第一。

    

    尽管在自动对话评价指标的开发上已经付出了大量的研究工作，但对评价非英语对话的思考却很少。与此同时，确保指标对语义相似的回答不变也是一个被忽视的问题。为了实现稳健性和多语言性对话评估指标的期望属性，我们提出了一个新颖的框架，利用当前评估模型的优势和新建立的提示大型语言模型(LLM)范式。实证结果表明，我们的框架在多个基准测试中以平均斯皮尔曼相关得分创造了最先进的结果，并在DSTC11 Track 4“开放域对话系统的自动评价指标”中的稳健和多语言任务中排名第一，证明了提示LLM的评估能力。

    Despite significant research effort in the development of automatic dialogue evaluation metrics, little thought is given to evaluating dialogues other than in English. At the same time, ensuring metrics are invariant to semantically similar responses is also an overlooked topic. In order to achieve the desired properties of robustness and multilinguality for dialogue evaluation metrics, we propose a novel framework that takes advantage of the strengths of current evaluation models with the newly-established paradigm of prompting Large Language Models (LLMs). Empirical results show our framework achieves state of the art results in terms of mean Spearman correlation scores across several benchmarks and ranks first place on both the Robust and Multilingual tasks of the DSTC11 Track 4 "Automatic Evaluation Metrics for Open-Domain Dialogue Systems", proving the evaluation capabilities of prompted LLMs.
    
[^29]: 什么时候编程思维对推理起作用?

    When Do Program-of-Thoughts Work for Reasoning?. (arXiv:2308.15452v1 [cs.CL])

    [http://arxiv.org/abs/2308.15452](http://arxiv.org/abs/2308.15452)

    提出了复杂性影响推理分数（CIRS）来衡量编程语言对推理能力的影响，发现并非所有复杂性的代码数据都可以被学习或理解，适当的复杂性水平对于改善推理能力至关重要。

    

    大型语言模型（LLM）的推理能力在体现出人工智能领域中起着关键作用。尽管像编程思维提示这样的方法对于使用编程语言来解决复杂推理任务的LLM非常有效，但代码数据对推理能力的具体影响仍未充分探索。为了填补这一空白，我们提出了复杂性影响推理分数（CIRS），它结合了结构和逻辑属性，以衡量代码和推理能力之间的相关性。具体而言，我们使用抽象语法树来编码结构信息，并通过考虑难度和圈复杂度来计算逻辑复杂性。通过实证分析，我们发现并非所有复杂性的代码数据都可以被LLM学习或理解。最佳复杂性水平对于通过编程辅助提示改善推理能力至关重要。然后我们设计了一个自动合成的方法...

    The reasoning capabilities of Large Language Models (LLMs) play a pivotal role in the realm of embodied artificial intelligence. Although there are effective methods like program-of-thought prompting for LLMs which uses programming language to tackle complex reasoning tasks, the specific impact of code data on the improvement of reasoning capabilities remains under-explored. To address this gap, we propose complexity-impacted reasoning score (CIRS), which combines structural and logical attributes, to measure the correlation between code and reasoning abilities. Specifically, we use the abstract syntax tree to encode the structural information and calculate logical complexity by considering the difficulty and the cyclomatic complexity. Through an empirical analysis, we find not all code data of complexity can be learned or understood by LLMs. Optimal level of complexity is critical to the improvement of reasoning abilities by program-aided prompting. Then we design an auto-synthesizing
    
[^30]: 大语言模型赋能文本到SQL的研究：一个基准评估

    Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation. (arXiv:2308.15363v1 [cs.DB])

    [http://arxiv.org/abs/2308.15363](http://arxiv.org/abs/2308.15363)

    本文提出了一个大规模语言模型(LLMs)赋能的文本到SQL任务的基准评估，并基于实验结果提出了一种新的集成解决方案DAIL-SQL，刷新了Spider榜单并实现了86.6%的执行准确率。同时，强调了在提示工程中的词汇效率以实现高效经济的LLM-based文本到SQL解决方案，此外还对在上下文学习中应用开源LLMs进行了研究，并进行了任务特定的性能优化。

    

    大语言模型(LLMs)已经成为文本到SQL任务的一种新范式。然而，缺乏一个系统性的基准阻碍了设计有效、高效和经济的LLM-based文本到SQL解决方案的发展。为了解决这一挑战，本文首先对现有的提示工程方法进行了系统性和广泛的比较，包括问题表示、示例选择和示例组织，并根据实验结果详细阐述了它们的优缺点。基于这些发现，我们提出了一种新的集成解决方案，名为DAIL-SQL，刷新了Spider榜单，达到了86.6%的执行准确率，建立了一个新的标杆。为了实现高效经济的LLM-based文本到SQL解决方案，我们强调提示工程中的词汇效率，并在此度量下比较了之前的研究。此外，我们还研究了上下文学习中的开源LLMs，并用任务特定的监督进行了进一步的性能优化。

    Large language models (LLMs) have emerged as a new paradigm for Text-to-SQL task. However, the absence of a systematical benchmark inhibits the development of designing effective, efficient and economic LLM-based Text-to-SQL solutions. To address this challenge, in this paper, we first conduct a systematical and extensive comparison over existing prompt engineering methods, including question representation, example selection and example organization, and with these experimental results, we elaborates their pros and cons. Based on these findings, we propose a new integrated solution, named DAIL-SQL, which refreshes the Spider leaderboard with 86.6% execution accuracy and sets a new bar. Towards an efficient and economic LLM-based Text-to-SQL solution, we emphasize the token efficiency in prompt engineering and compare the prior studies under this metric. Additionally, we investigate open-source LLMs in in-context learning, and further enhance their performance with task-specific superv
    
[^31]: 从数量到质量：利用自我引导数据选择方法提升LLM性能以进行指令调优

    From Quantity to Quality: Boosting LLM Performance with Self-Guided Data Selection for Instruction Tuning. (arXiv:2308.12032v1 [cs.CL])

    [http://arxiv.org/abs/2308.12032](http://arxiv.org/abs/2308.12032)

    该论文引入了一种自我引导的方法，让LLM能够自主地选择高质量的指令数据，通过引入指令遵循难度指标（IFD），大幅提高了模型训练效率，并在知名数据集上进行了验证，展示了优于传统数据输入的结果。

    

    在大型语言模型领域，指令数据的质量和数量之间的平衡已成为一个焦点。鉴于此，我们引入了一种自我引导的方法，让LLM能够自主地识别和选择大规模开源数据集中的精选样本，有效减少了指令调优的手动筛选和潜在成本。我们的关键创新是指令遵循难度（IFD）指标，它成为了一个决定性工具，用于识别模型期望响应和自主生成能力之间的差异。通过灵活应用IFD，我们能够找到精选样本，从而大幅提升模型训练效率。在Alpaca和WizardLM等知名数据集上的实证验证支持我们的发现；仅使用传统数据输入的10%，我们的策略展示了改进的结果。这种自我引导挑选和IFD指标的综合意味着LLM优化的一个变革性飞跃，有望同时提高模型性能和降低成本。

    In the realm of Large Language Models, the balance between instruction data quality and quantity has become a focal point. Recognizing this, we introduce a self-guided methodology for LLMs to autonomously discern and select cherry samples from vast open-source datasets, effectively minimizing manual curation and potential cost for instruction tuning an LLM. Our key innovation, the Instruction-Following Difficulty (IFD) metric, emerges as a pivotal tool to identify discrepancies between a model's expected responses and its autonomous generation prowess. Through the adept application of IFD, cherry samples are pinpointed, leading to a marked uptick in model training efficiency. Empirical validations on renowned datasets like Alpaca and WizardLM underpin our findings; with a mere 10% of conventional data input, our strategy showcases improved results. This synthesis of self-guided cherry-picking and the IFD metric signifies a transformative leap in the optimization of LLMs, promising both
    
[^32]: 比较聊天机器人如何引用用户之前聊天会话的研究：对用户隐私关注和感知的调查

    Comparing How a Chatbot References User Utterances from Previous Chatting Sessions: An Investigation of Users' Privacy Concerns and Perceptions. (arXiv:2308.04879v1 [cs.HC] CROSS LISTED)

    [http://arxiv.org/abs/2308.04879](http://arxiv.org/abs/2308.04879)

    本研究比较了三种不同方式的聊天机器人如何引用用户之前的对话，并发现逐字引用和释义引用的聊天机器人更智能和引人入胜，但逐字引用会引起隐私关注。

    

    聊天机器人能够记忆和引用之前的对话，但这是否增强了用户的参与度还是侵犯了隐私？为了探讨这种权衡，我们研究了聊天机器人如何引用用户之前对话的形式，以及对用户的感知和隐私关注的影响。在为期三周的纵向随机组实验中，我们让169名参与者向一个聊天机器人谈论他们的使用牙线的习惯，并将聊天机器人分为三组：(1-None)：不明确引用以前用户的话语，(2-Verbatim)：逐字引用以前的话语，(3-Paraphrase)：使用释义来引用以前的话语。参与者认为逐字引用和释义引用的聊天机器人更智能和引人入胜。然而，逐字引用的聊天机器人也引起了参与者的隐私关注。为了了解为什么人们更倾向于某些条件或担心隐私问题，我们进行了半结构化访谈，共有15名参与者。我们讨论了我们的发现带来的影响。

    Chatbots are capable of remembering and referencing previous conversations, but does this enhance user engagement or infringe on privacy? To explore this trade-off, we investigated the format of how a chatbot references previous conversations with a user and its effects on a user's perceptions and privacy concerns. In a three-week longitudinal between-subjects study, 169 participants talked about their dental flossing habits to a chatbot that either, (1-None): did not explicitly reference previous user utterances, (2-Verbatim): referenced previous utterances verbatim, or (3-Paraphrase): used paraphrases to reference previous utterances. Participants perceived Verbatim and Paraphrase chatbots as more intelligent and engaging. However, the Verbatim chatbot also raised privacy concerns with participants. To gain insights as to why people prefer certain conditions or had privacy concerns, we conducted semi-structured interviews with 15 participants. We discuss implications from our finding
    
[^33]: ValiTex -- 一种用于计算文本的社会科学构建度量的统一验证框架

    ValiTex -- a uniform validation framework for computational text-based measures of social science constructs. (arXiv:2307.02863v1 [cs.CL])

    [http://arxiv.org/abs/2307.02863](http://arxiv.org/abs/2307.02863)

    ValiTex是一个统一的验证框架，旨在帮助学者们基于文本数据来度量社会科学构建。它借鉴了心理测量学的传统，通过概念模型和动态检查表提供了验证的结构和步骤。

    

    关于如何验证计算文本的社会科学构建度量的指导是分散的。虽然学者们普遍认识到验证他们的文本度量的重要性，但他们通常缺乏共同的术语和统一的框架来进行验证。本文介绍了一个名为ValiTex的新验证框架，旨在帮助学者们基于文本数据来度量社会科学构建。该框架借鉴了心理测量学中长期存在的传统，同时扩展了框架以适用于计算文本分析的目的。ValiTex包括两个组成部分，一个是概念模型，一个是动态检查表。概念模型提供了一个通用的结构，可以指导验证的不同阶段，动态检查表定义了具体的验证步骤，并提供了哪些步骤可能被认为是推荐的（即提供相关和必要的验证证据）或可选的（即对提供额外信息有用的）。

    Guidance on how to validate computational text-based measures of social science constructs is fragmented. Whereas scholars are generally acknowledging the importance of validating their text-based measures, they often lack common terminology and a unified framework to do so. This paper introduces a new validation framework called ValiTex, designed to assist scholars to measure social science constructs based on textual data. The framework draws on a long-established tradition within psychometrics while extending the framework for the purpose of computational text analysis. ValiTex consists of two components, a conceptual model, and a dynamic checklist. Whereas the conceptual model provides a general structure along distinct phases on how to approach validation, the dynamic checklist defines specific validation steps and provides guidance on which steps might be considered recommendable (i.e., providing relevant and necessary validation evidence) or optional (i.e., useful for providing 
    
[^34]: 使用Transformer模型的条件生成式聊天机器人

    A Conditional Generative Chatbot using Transformer Model. (arXiv:2306.02074v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.02074](http://arxiv.org/abs/2306.02074)

    本研究提出了一种使用Transformer模型的条件生成式聊天机器人，通过结合Wasserstein生成对抗网络和Transformer模型，在生成器部分使用完整的Transformer模型生成答案，鉴别器部分仅使用Transformer模型的编码器部分，从而解决了序列模型在生成聊天回答时准确性不高的问题。

    

    聊天机器人作为人类用户和机器之间的沟通工具，旨在基于用户输入进行适当的回答。在最近的方法中，结合自然语言处理和序列模型来构建生成式聊天机器人。这些模型的主要挑战是它们的序列性质，导致结果不够准确。为了解决这个挑战，在本文中，提出了一种新颖的架构，使用条件Wasserstein生成对抗网络和Transformer模型进行聊天机器人的答案生成。虽然所提出模型的生成器由完整的Transformer模型组成以生成答案，但鉴别器仅包括Transformer模型的编码器部分，后跟一个分类器。据我们所知，这是第一次使用嵌入式Transformer模型来提出生成式聊天机器人，其同时在生成器和鉴别器模型中使用。依靠Transformer模型的并行计算，结果具有更好的准确性。

    A Chatbot serves as a communication tool between a human user and a machine to achieve an appropriate answer based on the human input. In more recent approaches, a combination of Natural Language Processing and sequential models are used to build a generative Chatbot. The main challenge of these models is their sequential nature, which leads to less accurate results. To tackle this challenge, in this paper, a novel architecture is proposed using conditional Wasserstein Generative Adversarial Networks and a transformer model for answer generation in Chatbots. While the generator of the proposed model consists of a full transformer model to generate an answer, the discriminator includes only the encoder part of a transformer model followed by a classifier. To the best of our knowledge, this is the first time that a generative Chatbot is proposed using the embedded transformer in both generator and discriminator models. Relying on the parallel computing of the transformer model, the resul
    
[^35]: 语言模型中的实体跟踪

    Entity Tracking in Language Models. (arXiv:2305.02363v1 [cs.CL])

    [http://arxiv.org/abs/2305.02363](http://arxiv.org/abs/2305.02363)

    本文探究了大型语言模型追踪实体状态的能力，发现经过大量代码预训练的GPT-3.5模型表现最好，即使训练和评估中几乎没有词汇重叠的情况下，仍然可以获得不错的效果。

    

    追踪操作对象的状态并跟踪它们随文本或对话的展开而发生的关系变化是理解话语的关键前提。尽管如此，对于大型语言模型（LLM）追踪话语实体的能力进行了很少的系统调查。在这项工作中，我们提出了一项任务，以探究语言模型在给定初始状态的英文描述和一系列状态更改操作的情况下能够推断出实体的最终状态的程度。

    Keeping track of how states and relations of entities change as a text or dialog unfolds is a key prerequisite to discourse understanding. Despite this fact, there have been few systematic investigations into the ability of large language models (LLMs) to track discourse entities. In this work, we present a task to probe to what extent a language model can infer the final state of an entity given an English description of the initial state and a series of state-changing operations. We use this task to first investigate whether Flan-T5, GPT-3 and GPT-3.5 can track the state of entities, and find that only GPT-3.5 models, which have been pretrained on large amounts of code, exhibit this ability. We then investigate whether smaller models pretrained primarily on text can learn to track entities, through finetuning T5 on several training/evaluation splits. While performance degrades for more complex splits, we find that even for splits with almost no lexical overlap between training and ev
    
[^36]: MQAG: 用于评估摘要中信息一致性的多选题答案生成和回答方法

    MQAG: Multiple-choice Question Answering and Generation for Assessing Information Consistency in Summarization. (arXiv:2301.12307v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.12307](http://arxiv.org/abs/2301.12307)

    MQAG提出了一种基于多选题答案生成和回答的方法来评估摘要中的信息一致性，通过计算预测的答案分布之间的统计距离来近似判断源文档和摘要之间的信息一致性。

    

    最先进的摘要系统可以生成非常流畅的摘要。然而，这些摘要可能包含事实上的不一致或源文档中不存在的信息。因此，评估摘要质量的一个重要组成部分是确定源文档和摘要之间的信息一致性。现有的方法通常基于词汇匹配或基于表示的方法。在这项工作中，我们引入了一种基于标准信息理论度量的替代方案，直接比较源文档和摘要中的信息。我们提出了一个多选题答案生成和回答框架MQAG，通过计算在自动生成的多选题上摘要和源文档答案分布之间的统计距离来近似信息一致性。该方法利用多选题答案概率，因为预测的答案分布可以共同预测摘要和源文档的信息一致性。

    State-of-the-art summarization systems can generate highly fluent summaries. These summaries, however, may contain factual inconsistencies and/or information not present in the source. Hence, an important component of assessing the quality of summaries is to determine whether there is information consistency between the source and the summary. Existing approaches are typically based on lexical matching or representation-based methods. In this work, we introduce an alternative scheme based on standard information-theoretic measures in which the information present in the source and summary is directly compared. We propose a Multiple-choice Question Answering and Generation framework, MQAG, which approximates the information consistency by computing the expected statistical distance between summary and source answer distributions over automatically generated multiple-choice questions. This approach exploits multiple-choice answer probabilities, as predicted answer distributions can be co
    
[^37]: TikTalk: 一个用于多模态真实世界闲聊的基于视频的对话数据集

    TikTalk: A Video-Based Dialogue Dataset for Multi-Modal Chitchat in Real World. (arXiv:2301.05880v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.05880](http://arxiv.org/abs/2301.05880)

    TikTalk是一个基于视频的多模态对话数据集，用于研究智能且类似人类的闲聊机器人。数据集包含从流行视频分享平台收集的38K个视频和367K个用户对话。与其他数据集相比，TikTalk提供了更丰富的上下文类型，同时也增加了从复杂的多模态信息中生成个性化回答的难度。数据集中还更频繁地引用了外部知识，为多模态对话模型提供了新的挑战。

    

    为了促进多模态上下文中智能和人类化聊天机器人的研究，我们引入了一个新的基于视频的多模态对话数据集，称为TikTalk。我们从一个流行的视频分享平台收集了38K个视频，以及用户在其下发布的367K个对话。用户根据他们观看视频时的多模态经验进行自发性对话，这有助于重现真实世界的闲聊环境。与之前的多模态对话数据集相比，TikTalk中更丰富的上下文类型导致了更多样化的对话，但也增加了从复杂的多模态信息中捕捉人类兴趣并生成个性化回答的难度。此外，我们的数据集中更频繁地引用了外部知识。这些事实揭示了多模态对话模型面临的新挑战。我们定量地展示了TikTalk的特点，提出了一个基于视频的多模态闲聊任务，并评估了几种对话基线模型。

    To facilitate the research on intelligent and human-like chatbots with multi-modal context, we introduce a new video-based multi-modal dialogue dataset, called TikTalk. We collect 38K videos from a popular video-sharing platform, along with 367K conversations posted by users beneath them. Users engage in spontaneous conversations based on their multi-modal experiences from watching videos, which helps recreate real-world chitchat context. Compared to previous multi-modal dialogue datasets, the richer context types in TikTalk lead to more diverse conversations, but also increase the difficulty in capturing human interests from intricate multi-modal information to generate personalized responses. Moreover, external knowledge is more frequently evoked in our dataset. These facts reveal new challenges for multi-modal dialogue models. We quantitatively demonstrate the characteristics of TikTalk, propose a video-based multi-modal chitchat task, and evaluate several dialogue baselines. Experi
    
[^38]: Less is More: 用于篇章分析的轻量级和鲁棒的神经网络结构

    Less is More: A Lightweight and Robust Neural Architecture for Discourse Parsing. (arXiv:2210.09537v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.09537](http://arxiv.org/abs/2210.09537)

    本文提出了一个轻量级神经网络结构，通过移除复杂的特征提取器，仅利用自注意力模块间接利用预训练的神经语言模型，以提高篇章分析任务的泛化能力和鲁棒性。实验证明，这个轻量级结构只有两个自注意力层，却具有更好的性能，并且拥有较少的参数和处理时间。

    

    复杂的特征提取器被广泛用于构建文本表示，然而这些复杂的特征提取器使得自然语言处理系统在训练数据集相对较小的情况下容易过拟合，尤其是对于一些篇章分析任务。因此，我们提出了一种替代性的轻量级神经网络结构，移除了多个复杂的特征提取器，只利用可学习的自注意力模块来间接利用预训练的神经语言模型，以最大程度地保留预训练语言模型的泛化能力。对于三个常见的篇章分析任务的实验表明，基于最新的预训练语言模型的轻量级结构仅包含两个自注意力层，具有更好的泛化能力和鲁棒性。同时，它在较少的可学习参数和较少的处理时间下实现了可比较甚至更好的系统性能。

    Complex feature extractors are widely employed for text representation building. However, these complex feature extractors make the NLP systems prone to overfitting especially when the downstream training datasets are relatively small, which is the case for several discourse parsing tasks. Thus, we propose an alternative lightweight neural architecture that removes multiple complex feature extractors and only utilizes learnable self-attention modules to indirectly exploit pretrained neural language models, in order to maximally preserve the generalizability of pre-trained language models. Experiments on three common discourse parsing tasks show that powered by recent pretrained language models, the lightweight architecture consisting of only two self-attention layers obtains much better generalizability and robustness. Meanwhile, it achieves comparable or even better system performance with fewer learnable parameters and less processing time.
    
[^39]: 检测文本形式性：一项关于文本分类方法的研究

    Detecting Text Formality: A Study of Text Classification Approaches. (arXiv:2204.08975v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2204.08975](http://arxiv.org/abs/2204.08975)

    这项研究提供了首个系统研究文本形式性检测方法，并提供了在单语言和多语言任务中表现最佳的Char BiLSTM模型。

    

    形式性是文本文档的重要特征之一。对文本形式性水平的自动检测对于各种自然语言处理任务有潜在好处。之前，为多种语言引入了两个大规模数据集，包含形式性标注——GYAFC和X-FORMAL。然而，它们主要用于训练风格转移模型。同时，文本形式性的单独检测也可能是一个有用的应用。本研究提出了我们所知的第一项系统研究形式性检测方法，基于统计、基于神经网络和基于Transformer的机器学习方法，并提供了性能最佳的模型供公众使用。我们进行了三种类型的实验——单语言、多语言和跨语言。研究表明，在单语言和多语言形式性分类任务中，Char BiLSTM模型优于基于Transformer的模型。

    Formality is one of the important characteristics of text documents. The automatic detection of the formality level of a text is potentially beneficial for various natural language processing tasks. Before, two large-scale datasets were introduced for multiple languages featuring formality annotation -- GYAFC and X-FORMAL. However, they were primarily used for the training of style transfer models. At the same time, the detection of text formality on its own may also be a useful application. This work proposes the first to our knowledge systematic study of formality detection methods based on statistical, neural-based, and Transformer-based machine learning methods and delivers the best-performing models for public usage. We conducted three types of experiments -- monolingual, multilingual, and cross-lingual. The study shows the overcome of Char BiLSTM model over Transformer-based ones for the monolingual and multilingual formality classification task, while Transformer-based classifie
    

