# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [VisoGender: A dataset for benchmarking gender bias in image-text pronoun resolution.](http://arxiv.org/abs/2306.12424) | VisoGender是一个用于评估视觉语言模型中职业相关性别偏见的数据集。研究显示，最先进的模型缺乏正确解析复杂场景中性别的推理能力，生成字幕的模型通常比类似CLIP的模型更精确和更少偏见。 |
| [^2] | [LMFlow: An Extensible Toolkit for Finetuning and Inference of Large Foundation Models.](http://arxiv.org/abs/2306.12420) | LMFlow是一个可扩展和轻量级的工具包，为大型基础模型提供完整的微调工作流程，以支持在有限的计算资源下进行个性化训练，并支持连续预训练和指令微调以适应不同的专业任务。 |
| [^3] | [Solving Dialogue Grounding Embodied Task in a Simulated Environment using Further Masked Language Modeling.](http://arxiv.org/abs/2306.12387) | 本研究提出了一种通过采用最先进的语言模型方法，基于对话引导行动任务来增强AI系统对多模态理解和任务导向的理解，实现了一个针对Minecraft数据集上集体建筑任务的语言建模方法，实验结果表明了该方法的卓越性。 |
| [^4] | [Iterated Piecewise Affine (IPA) Approximation for Language Modeling.](http://arxiv.org/abs/2306.12317) | 迭代分段仿射插值（IPA）逼近法可以用于语言建模，与变压器解码器架构类似，并在交叉熵损失下的小序列长度下优于变压器1.5％。 |
| [^5] | [Medical ministrations through web scraping.](http://arxiv.org/abs/2306.12310) | 通过Web抓取对医疗治疗进行数据收集和分析，帮助医疗保健提供者确定患者最有效的治疗方法。 |
| [^6] | [SIFTER: A Task-specific Alignment Strategy for Enhancing Sentence Embeddings.](http://arxiv.org/abs/2306.12280) | SIFTER 是一种适应不同任务需求的任务特定对齐策略，用于增强句子嵌入。 |
| [^7] | [Solving and Generating NPR Sunday Puzzles with Large Language Models.](http://arxiv.org/abs/2306.12255) | 本文探究了大型语言模型用于解决和生成 NPR Sunday Puzzles 的能力。研究表明，大型语言模型可以有效解决许多 PUZZLEQA 谜题，但目前尚无法生成谜题。 |
| [^8] | [Bidirectional End-to-End Learning of Retriever-Reader Paradigm for Entity Linking.](http://arxiv.org/abs/2306.12245) | BEER^2是一种用于Retriever和Reader的双向端到端训练框架，通过检索器和阅读器之间的相互学习，共同进步，实现端到端EL。 |
| [^9] | [Limits for Learning with Language Models.](http://arxiv.org/abs/2306.12213) | 本论文研究了语言模型的学习限制，证明了大型语言模型无法学习某些基本的语义属性，包括语义蕴含和一致性，并且无法学习超出可数集层次结构第一层的概念，这限制了它们在语言意义方面的能力。 |
| [^10] | [Investigating Pre-trained Language Models on Cross-Domain Datasets, a Step Closer to General AI.](http://arxiv.org/abs/2306.12205) | 本文研究了预训练语言模型在跨领域任务中的表现，结果表明预训练模型可以是实现通用人工智能的重要一步。 |
| [^11] | [Opening the Black Box: Analyzing Attention Weights and Hidden States in Pre-trained Language Models for Non-language Tasks.](http://arxiv.org/abs/2306.12198) | 本论文揭示了预训练语言模型在非语言任务中的内部运作，具体使用约束算术问题探索模型的注意力权重分数和隐藏状态，并发现了有前途的结果，该模型以略微结构化的方式解决分层问题，类似于人类解决问题的策略。 |
| [^12] | [Feature Interactions Reveal Linguistic Structure in Language Models.](http://arxiv.org/abs/2306.12181) | 研究特征交互在神经网络中的重要性，提出了一种灰箱方法来分析交互特征的作用，揭示了某些方法能够反映目标模型的内部运作。 |
| [^13] | [Mixture Encoder for Joint Speech Separation and Recognition.](http://arxiv.org/abs/2306.12173) | 本论文提出了一种中间方法，同时利用显式语音分离和直接在ASR模块中合并混合语音信息，通过交换跨说话者上下文信息的层，实现了在SMS-WSJ任务上相对于纯模块化设置的单词错误率7%的相对改进。 |
| [^14] | [Which Spurious Correlations Impact Reasoning in NLI Models? A Visual Interactive Diagnosis through Data-Constrained Counterfactuals.](http://arxiv.org/abs/2306.12146) | 该论文提出了一种针对NLI模型进行推理的人机交互的仪表板，发现了几类伪相关性并将其分为三类：语义相关性、逻辑谬误和偏见，其中包括增加训练数据和创建对抗测试套件来评估NLI模型的鲁棒性。 |
| [^15] | [Mass-Producing Failures of Multimodal Systems with Language Models.](http://arxiv.org/abs/2306.12105) | 本文介绍了一种MultiMon系统，可以自动识别多模态系统中的系统性失败，揭示CLIP文本编码器的14个系统性失败，每个都由数百个不同的输入组成，这些输入会导致其他大多数最先进的多模态系统的失败。 |
| [^16] | [Towards Accurate Translation via Semantically Appropriate Application of Lexical Constraints.](http://arxiv.org/abs/2306.12089) | 本研究关注基于语义相关的词法约束在翻译中的应用，提出解决同形异义词问题的同形异义词消歧模块和PLUMCOT方法，并提供了评估基准HOLLY。 |
| [^17] | [Modeling Hierarchical Reasoning Chains by Linking Discourse Units and Key Phrases for Reading Comprehension.](http://arxiv.org/abs/2306.12069) | 提出了一个基于全局图网络的方法，既处理话语层面又处理单词层面的上下文，并通过分层交互机制对节点级别和类型级别的关系进行建模，以提供更细粒度的关系提取，该方法在逻辑推理QA数据集和自然语言推理数据集上优于现有的最先进方法。 |
| [^18] | [Sample Attackability in Natural Language Adversarial Attacks.](http://arxiv.org/abs/2306.12043) | 本文研究了自然语言处理领域中，哪些样本最易受到对抗攻击或最具鲁棒性的问题，并扩展了该领域中的“样本攻击能力/鲁棒性”的定义。实验发现，基于深度学习的检测器可以更好地识别出一个看不见的目标模型中最易受攻击和最具鲁棒性的样本。 |
| [^19] | [Strategies in Transfer Learning for Low-Resource Speech Synthesis: Phone Mapping, Features Input, and Source Language Selection.](http://arxiv.org/abs/2306.12040) | 本文比较了在低资源语言的TTS中使用基于PHOIBLE的音素映射方法和使用语音特征输入的转移学习策略。结果表明两种方法都可以提高输出质量，但后者表现更好。此外，作者还提出了在转移学习中选择源语言的标准，并发现基于角频率相似性的音频频率是有效的，而语言距离则没有预期的效果。 |
| [^20] | [Visual-Aware Text-to-Speech.](http://arxiv.org/abs/2306.12020) | 本文提出了一个新的视觉感知的文本到语音（VA-TTS）任务，用于在面对面的交流中，基于文本输入和接收者的序列视觉反馈来合成语音，并设计了一个基准模型进行语音合成，实验证明在多模态对话数据集上生成更自然的音频，具有场景适当的韵律和语调。 |
| [^21] | [A Semi-Autoregressive Graph Generative Model for Dependency Graph Parsing.](http://arxiv.org/abs/2306.12018) | 提出了一种半自回归的依存解析器，成功捕获了节点和边缘之间的显式依赖关系，取得了最先进的结果。 |
| [^22] | [3HAN: A Deep Neural Network for Fake News Detection.](http://arxiv.org/abs/2306.12014) | 3HAN是一种基于深度学习的虚假新闻自动检测器。通过三层分层注意网络，它可以构建一个对新闻进行完整有效表示的新闻向量，并给文章不同部分分配不同的重要性，实现了高准确率的虚假新闻检测，并且提供了可理解的输出结果。 |
| [^23] | [Interactive Molecular Discovery with Natural Language.](http://arxiv.org/abs/2306.11976) | 本文提出了一种交互式分子设计任务，通过自然语言描述和编辑目标分子。我们设计了ChatMol模型用于生成和编辑分子，并测试了其在分子任务上的优越性。 |
| [^24] | [Towards Understanding What Code Language Models Learned.](http://arxiv.org/abs/2306.11943) | 本研究探究了预先训练的代码语言模型的能力，证明其能够超越表面形式特征，学习精确而形式化定义的代码的计算语义。 |
| [^25] | [Opportunities and Risks of LLMs for Scalable Deliberation with Polis.](http://arxiv.org/abs/2306.11932) | 本文探讨了LLMs在促进、调节和总结Polis可扩展协商中的机会和风险，试验表明总结能力使得公共参与具有巨大潜力，但是LLMs的上下文限制对结果的影响很大。同时，我们讨论了原则和技术来表征和减轻这些风险。 |
| [^26] | [Evaluation of Chinese-English Machine Translation of Emotion-Loaded Microblog Texts: A Human Annotated Dataset for the Quality Assessment of Emotion Translation.](http://arxiv.org/abs/2306.11900) | 本文评估了Google翻译对情感化文本的中英翻译效果，发现50%的翻译输出没有保留原始情感信息，情感词汇和语言现象是这些翻译错误的原因。 |
| [^27] | [Exploring New Frontiers in Agricultural NLP: Investigating the Potential of Large Language Models for Food Applications.](http://arxiv.org/abs/2306.11892) | 本文探索利用与食品相关的文本语料库为基础预训练转换器语言模型的能力，以实现语义匹配任务。通过微调预训练的转换器语言模型AgriBERT，并利用外部知识如FoodOn本体论等，同时借助ChatGPT外部知识源，可以进一步增强模型对与食品相关的概念和关系的理解。 |
| [^28] | [Open-Domain Text Evaluation via Meta Distribution Modeling.](http://arxiv.org/abs/2306.11879) | 本文提出了一种新颖的开放领域文本生成模型评估方法——元分布方法（MDM），该方法将两个概率分布的对比映射到质量度量上，可以视为分布的分布，其可用于开放领域文本生成的评估。 |
| [^29] | [Retrieval-Based Transformer for Table Augmentation.](http://arxiv.org/abs/2306.11843) | 本文提出了一种自动数据处理的新方法，其中使用基于检索的Transformer模型来解决表格增强任务，并采用自学习策略来训练模型以重构原始值或标题，以便减轻数据分析师在数据处理中的工作量。 |
| [^30] | [EvolveMT: an Ensemble MT Engine Improving Itself with Usage Only.](http://arxiv.org/abs/2306.11823) | EvolveMT是一个可以高效组合多个机器翻译引擎的系统，该系统通过在线学习技术动态适应领域或机器翻译引擎的改变，从而实现可靠的翻译结果，并且只需使用本身进行改进，消除了额外训练的必要性。 |
| [^31] | [Learning to Generate Better Than Your LLM.](http://arxiv.org/abs/2306.11816) | 本论文研究了基于强化学习算法 RLGF，用于在 GPT-3 等动态黑匣子指导下微调大型语言模型 LLM 的条件文本生成，相比通用 RL 算法，该算法在 IMDB 和 CommonGen 任务中表现更好。 |
| [^32] | [Visually grounded few-shot word learning in low-resource settings.](http://arxiv.org/abs/2306.11371) | 本论文提出了一个可以在低资源环境中只用少量样本学习新词汇及其视觉表示的视觉语音模型，可应用于Yoruba等低资源语言的多模态少量示例学习。 |
| [^33] | [Adversarial Robustness of Prompt-based Few-Shot Learning for Natural Language Understanding.](http://arxiv.org/abs/2306.11066) | 本文针对几种FSL方法的鲁棒性指出，与全微调模型相比，纯FSL模型面对对抗扰动会带来不可忽视的任务性能下降。但使用无标签数据生成提示或使用多个提示可以显著提高鲁棒性，在某些情况下甚至胜过全微调模型。 |
| [^34] | [Fine-Tuning Language Models for Scientific Writing Support.](http://arxiv.org/abs/2306.10974) | 本文提出了一种用于科技写作支持的语言模型微调方法，包括评估句子科学性、划分段落和润色建议等功能，并对模型进行偏见测试和上下文分析。 |
| [^35] | [BayLing: Bridging Cross-lingual Alignment and Instruction Following through Interactive Translation for Large Language Models.](http://arxiv.org/abs/2306.10968) | BayLing是一个指令遵循的LLM，通过交互式翻译将语言生成和指令遵循的能力从英语转移到其他语言，使得在非英语语言上也能够实现与最先进的LLMs相同的性能，而且不需要语言特定数据或指令。 |
| [^36] | [Can ChatGPT pass the Vietnamese National High School Graduation Examination?.](http://arxiv.org/abs/2306.09170) | ChatGPT使用在越南高中毕业考试中表现出一定的水平，展示了AI动力聊天机器人在教育领域的潜力。 |
| [^37] | [$\textit{WHAT}$, $\textit{WHEN}$, and $\textit{HOW}$ to Ground: Designing User Persona-Aware Conversational Agents for Engaging Dialogue.](http://arxiv.org/abs/2306.03361) | 本文提出了一种针对商业环境的、能够平衡对话流畅性和趋向于理解对话系统的个性化开放领域对话系统方法，通过加权数据集混合、负角色信息增强方法，以及设计个性化对话数据集，解决了 $\textit{WHAT}$、$\textit{WHEN}$和$\textit{HOW}$ 等问题，同时提高了对话系统响应的可控性和解释性。 |
| [^38] | [OpenPI-C: A Better Benchmark and Stronger Baseline for Open-Vocabulary State Tracking.](http://arxiv.org/abs/2306.00887) | 本文提出了一个更干净的OpenPI-C数据集和一个基于聚类的评估指标，并通过增强模型的时间依赖性和实体感知能力来提高开放词汇状态跟踪的性能。 |
| [^39] | [Controlling Learned Effects to Reduce Spurious Correlations in Text Classifiers.](http://arxiv.org/abs/2305.16863) | 该论文提出了一种自动化的增强算法，以适当改变新增输入的标签，从而最小化误导性相关性，并提高了少数群体的准确性，同时保持了总体准确性。 |
| [^40] | [ConvXAI: Delivering Heterogeneous AI Explanations via Conversations to Support Human-AI Scientific Writing.](http://arxiv.org/abs/2305.09770) | ConvXAI是一个基于对话的XAI系统，它集成了多种XAI类型，并将实际用户需求嵌入设计中，以提高实用性。 |
| [^41] | [Multimodal Sentiment Analysis: A Survey.](http://arxiv.org/abs/2305.07611) | 本综述介绍了多模态情感分析的定义、发展和挑战，讨论了最新的数据集和先进模型，并提出了有前途的研究方向和构建更好性能的建议。 |
| [^42] | [Geotechnical Parrot Tales (GPT): Overcoming GPT hallucinations with prompt engineering for geotechnical applications.](http://arxiv.org/abs/2304.02138) | 本文探讨了如何利用GPT在岩土工程应用中的全部潜力，着重讨论及时工程的重要性，并开发了一个统一的自然语言接口，用于处理复杂的岩土工程任务和数据分析。 |
| [^43] | [PATCorrect: Non-autoregressive Phoneme-augmented Transformer for ASR Error Correction.](http://arxiv.org/abs/2302.05040) | PATCorrect是一种基于音素增强的非自回归变换器，利用文本和音素模态的表示来最大限度地降低ASR系统中的单词错误率，并在低延迟需求的实际生产系统中表现出鲁棒性。 |
| [^44] | [Design and analysis of tweet-based election models for the 2021 Mexican legislative election.](http://arxiv.org/abs/2301.00626) | 研究使用推特数据进行选举结果预测，结果表明带有地理属性的数据模型比传统民意调查方法更能准确预测选举结果。 |
| [^45] | [VRDU: A Benchmark for Visually-rich Document Understanding.](http://arxiv.org/abs/2211.15421) | 本研究提出了一个名为VRDU的基准测试，以更全面地反映实际文档的复杂性，其中包含具有挑战性的丰富模式、复杂模板和多样的布局。该基准测试可用于评估文档中提取结构化数据的模型。 |
| [^46] | [Peekaboo: Text to Image Diffusion Models are Zero-Shot Segmentors.](http://arxiv.org/abs/2211.13224) | 本文介绍了一种名为Peekaboo的技术，可以用于使用现成的文本到图像扩散模型进行无监督语义细分并基础，而无需任何重新培训。这项技术的推理时间优化过程可以在与自然语言提示相关联的情况下生成分割掩模。 |

# 详细

[^1]: VisoGender：一份用于评估图像-文本代词解析中性别偏见的数据集

    VisoGender: A dataset for benchmarking gender bias in image-text pronoun resolution. (arXiv:2306.12424v1 [cs.CV])

    [http://arxiv.org/abs/2306.12424](http://arxiv.org/abs/2306.12424)

    VisoGender是一个用于评估视觉语言模型中职业相关性别偏见的数据集。研究显示，最先进的模型缺乏正确解析复杂场景中性别的推理能力，生成字幕的模型通常比类似CLIP的模型更精确和更少偏见。

    

    我们介绍了一个新的数据集VisoGender，用于评估视觉语言模型中的性别偏见。我们专注于职业相关的性别偏见，受Winograd和Winogender模式的启发，其中每个图像都与包含场景中主语和宾语代词关系的标题相关联。VisoGender在职业角色中平衡了性别代表，支持两种偏见评估方式：i）解决偏见，我们评估男性和女性解决准确性之间的差异；ii）检索偏见，我们比较在性别中立的搜索查询中检索到的男性和女性专业人员的比例。我们对几种最先进的视觉语言模型进行了基准测试，并发现它们缺乏正确解析复杂场景中性别的推理能力。虽然性别偏见的方向和幅度取决于任务和评估的模型，但生成字幕的模型通常比类似CLIP的模型更精确和更少偏见。

    We introduce VisoGender, a novel dataset for benchmarking gender bias in vision-language models. We focus on occupation-related gender biases, inspired by Winograd and Winogender schemas, where each image is associated with a caption containing a pronoun relationship of subjects and objects in the scene. VisoGender is balanced by gender representation in professional roles, supporting bias evaluation in two ways: i) resolution bias, where we evaluate the difference between gender resolution accuracies for men and women and ii) retrieval bias, where we compare ratios of male and female professionals retrieved for a gender-neutral search query. We benchmark several state-of-the-art vision-language models and find that they lack the reasoning abilities to correctly resolve gender in complex scenes. While the direction and magnitude of gender bias depends on the task and the model being evaluated, captioning models generally are more accurate and less biased than CLIP-like models. Dataset 
    
[^2]: LMFlow：用于大型基础模型微调和推理的可扩展工具包

    LMFlow: An Extensible Toolkit for Finetuning and Inference of Large Foundation Models. (arXiv:2306.12420v1 [cs.CL])

    [http://arxiv.org/abs/2306.12420](http://arxiv.org/abs/2306.12420)

    LMFlow是一个可扩展和轻量级的工具包，为大型基础模型提供完整的微调工作流程，以支持在有限的计算资源下进行个性化训练，并支持连续预训练和指令微调以适应不同的专业任务。

    

    大型基础模型展现出比传统方法更接近人类智能的能力，已经引起了人工智能界的广泛关注。然而，大部分模型在专业任务应用中仍然表现出明显的缺陷，需要微调才能获得令人满意的性能。随着可用模型和专业任务数量的增加，通用微调的工作变得非常棘手。在本文中，我们采取了第一步解决这个问题。我们介绍了一个可扩展和轻量级的工具包LMFlow，旨在简化大型基础模型的微调和推理。LMFlow为大型基础模型提供了完整的微调工作流程，支持在有限的计算资源下进行个性化训练。此外，它还支持连续预训练、指令微调等功能，以更好地适应不同的专业任务。

    Large foundation models have demonstrated a great ability to achieve general human-level intelligence far beyond traditional approaches. As the technique keeps attracting attention from the AI community, more and more large foundation models have become publically available. However, most of those models exhibit a major deficiency in specialized-task applications, where the step of finetuning is still required for obtaining satisfactory performance. As the number of available models and specialized tasks keeps growing, the job of general finetuning becomes highly nontrivial. In this paper, we take the first step to address this issue. We introduce an extensible and lightweight toolkit, LMFlow, which aims to simplify the finetuning and inference of general large foundation models. LMFlow offers a complete finetuning workflow for a large foundation model to support personalized training with limited computing resources. Furthermore, it supports continuous pretraining, instruction tuning,
    
[^3]: 采用进一步掩码语言建模解决模拟环境下对话引导行动任务

    Solving Dialogue Grounding Embodied Task in a Simulated Environment using Further Masked Language Modeling. (arXiv:2306.12387v1 [cs.CL])

    [http://arxiv.org/abs/2306.12387](http://arxiv.org/abs/2306.12387)

    本研究提出了一种通过采用最先进的语言模型方法，基于对话引导行动任务来增强AI系统对多模态理解和任务导向的理解，实现了一个针对Minecraft数据集上集体建筑任务的语言建模方法，实验结果表明了该方法的卓越性。

    

    为了有效地辅助人类用户，增强AI系统的有效沟通技能是至关重要的，这需要从系统方面采取积极的措施来辨别特定情况并与用户恰当地互动以解决这些场景。本研究选择Minecraft数据集中的一个集体建筑任务。我们的方法采用语言建模，通过使用最先进的语言模型方法提高任务理解，这些模型专注于基于多模态理解和任务导向的对话理解任务。这种专注有助于深入了解这些模型如何解释和响应各种输入和任务。实验结果提供了我们所提出的方法卓越性的有力证据。这展示了实质性的改进，并指向了未来研究在这个领域的一个有前途的方向。

    Enhancing AI systems with efficient communication skills that align with human understanding is crucial for their effective assistance to human users. Proactive initiatives from the system side are needed to discern specific circumstances and interact aptly with users to solve these scenarios. In this research, we opt for a collective building assignment taken from the Minecraft dataset. Our proposed method employs language modeling to enhance task understanding through state-of-the-art (SOTA) methods using language models. These models focus on grounding multi-modal understandinging and task-oriented dialogue comprehension tasks. This focus aids in gaining insights into how well these models interpret and respond to a variety of inputs and tasks. Our experimental results provide compelling evidence of the superiority of our proposed method. This showcases a substantial improvement and points towards a promising direction for future research in this domain.
    
[^4]: 迭代分段仿射插值（IPA）逼近于语言建模的应用

    Iterated Piecewise Affine (IPA) Approximation for Language Modeling. (arXiv:2306.12317v1 [cs.CL])

    [http://arxiv.org/abs/2306.12317](http://arxiv.org/abs/2306.12317)

    迭代分段仿射插值（IPA）逼近法可以用于语言建模，与变压器解码器架构类似，并在交叉熵损失下的小序列长度下优于变压器1.5％。

    

    本文介绍了一种简单的一阶泰勒展开法来逼近一个通用的函数F: R^{n x m} -> R^{n x m} 并将其应用于语言建模。为了增强基本的泰勒展开，我们引入了迭代和分段建模，从而命名算法为迭代分段仿射插值（IPA）逼近。最终算法表现出与变压器解码器架构相似的有趣特征。通过比较IPA和变压器的参数，我们观察到在较小的序列长度下，IPA在下一个令牌预测任务中使用交叉熵损失比变压器高1.5％。

    In this work, we demonstrate the application of a simple first-order Taylor expansion to approximate a generic function $F: R^{n \times m} \to R^{n \times m}$ and utilize it in language modeling. To enhance the basic Taylor expansion, we introduce iteration and piecewise modeling, leading us to name the algorithm the Iterative Piecewise Affine (IPA) approximation. The final algorithm exhibits interesting resemblances to the Transformers decoder architecture. By comparing parameter arrangements in IPA and Transformers, we observe a strikingly similar performance, with IPA outperforming Transformers by 1.5\% in the next token prediction task with cross-entropy loss for smaller sequence lengths.
    
[^5]: 通过Web抓取进行医疗治疗

    Medical ministrations through web scraping. (arXiv:2306.12310v1 [cs.CL])

    [http://arxiv.org/abs/2306.12310](http://arxiv.org/abs/2306.12310)

    通过Web抓取对医疗治疗进行数据收集和分析，帮助医疗保健提供者确定患者最有效的治疗方法。

    

    Web抓取是一种可以自动从网站中提取数据的技术。在医疗领域，Web抓取可以用于收集有关医疗程序、治疗和医疗服务提供者的信息。这些信息可以用于改善患者护理、监测医疗服务质量并确定改进的领域。Web抓取在医疗治疗中尤其有用，可以帮助医疗保健提供者确定患者最有效的治疗方法。

    Web scraping is a technique that allows us to extract data from websites automatically. in the field of medicine, web scraping can be used to collect information about medical procedures, treatments, and healthcare providers. this information can be used to improve patient care, monitor the quality of healthcare services, and identify areas for improvement. one area where web scraping can be particularly useful is in medical ministrations. medical ministrations are the actions taken to provide medical care to patients, and web scraping can help healthcare providers identify the most effective ministrations for their patients. for example, healthcare providers can use web scraping to collect data about the symptoms and medical histories of their patients, and then use this information to determine the most appropriate ministrations. they can also use web scraping to gather information about the latest medical research and clinical trials, which can help them stay up-to-date with the lat
    
[^6]: SIFTER: 一种用于增强句子嵌入的任务特定对齐策略

    SIFTER: A Task-specific Alignment Strategy for Enhancing Sentence Embeddings. (arXiv:2306.12280v1 [cs.CL])

    [http://arxiv.org/abs/2306.12280](http://arxiv.org/abs/2306.12280)

    SIFTER 是一种适应不同任务需求的任务特定对齐策略，用于增强句子嵌入。

    

    预训练模型后进行微调已成为自然语言处理任务中的主流方法。虽然预训练模型具有泛化的优势，但它们的表现在不同领域任务中仍可能存在显著差异。这是因为不同领域的数据分布不同，并且不同的下游任务对句子的敏感程度也不同。该论文提出了一种用于增强句子嵌入的任务特定对齐策略 SIFTER，以适应不同任务需求。

    The paradigm of pre-training followed by fine-tuning on downstream tasks has become the mainstream method in natural language processing tasks. Although pre-trained models have the advantage of generalization, their performance may still vary significantly across different domain tasks. This is because the data distribution in different domains varies. For example, the different parts of the sentence 'He married Smt. Dipali Ghosh in 1947 and led a very happy married life' may have different impact for downstream tasks. For similarity calculations, words such as 'led' and 'life' are more important. On the other hand, for sentiment analysis, the word 'happy' is crucial. This indicates that different downstream tasks have different levels of sensitivity to sentence components. Our starting point is to scale information of the model and data according to the specifics of downstream tasks, enhancing domain information of relevant parts for these tasks and reducing irrelevant elements for di
    
[^7]: 用大型语言模型解决和生成 NPR Sunday Puzzles。

    Solving and Generating NPR Sunday Puzzles with Large Language Models. (arXiv:2306.12255v1 [cs.CL])

    [http://arxiv.org/abs/2306.12255](http://arxiv.org/abs/2306.12255)

    本文探究了大型语言模型用于解决和生成 NPR Sunday Puzzles 的能力。研究表明，大型语言模型可以有效解决许多 PUZZLEQA 谜题，但目前尚无法生成谜题。

    

    我们使用 PUZZLEQA 数据集探究了大型语言模型解决和生成 NPR Sunday Puzzle 游戏节目谜题的能力，该数据集包含 15 年的节目谜题。我们使用四个大型语言模型在 PUZZLEQA 上进行了评估，包括多项选择和自由回答格式，并探讨了两种提示工程技术以提高自由回答表现：思维链推理和提示摘要。我们发现，最先进的大型语言模型可以解决许多 PUZZLEQA 谜题：最好的模型 GPT-3.5 达到了 50.2% 的松散准确率。然而，在我们的少量样本谜题生成实验中，我们发现模型无法生成谜题：GPT-3.5 生成的谜题答案不符合生成的规则。谜题生成仍然是未来工作的一项挑战性任务。

    We explore the ability of large language models to solve and generate puzzles from the NPR Sunday Puzzle game show using PUZZLEQA, a dataset comprising 15 years of on-air puzzles. We evaluate four large language models using PUZZLEQA, in both multiple choice and free response formats, and explore two prompt engineering techniques to improve free response performance: chain-of-thought reasoning and prompt summarization. We find that state-of-the-art large language models can solve many PUZZLEQA puzzles: the best model, GPT-3.5, achieves 50.2% loose accuracy. However, in our few-shot puzzle generation experiment, we find no evidence that models can generate puzzles: GPT-3.5 generates puzzles with answers that do not conform to the generated rules. Puzzle generation remains a challenging task for future work.
    
[^8]: 实体链接的检索器-阅读器范式的双向端到端学习

    Bidirectional End-to-End Learning of Retriever-Reader Paradigm for Entity Linking. (arXiv:2306.12245v1 [cs.CL])

    [http://arxiv.org/abs/2306.12245](http://arxiv.org/abs/2306.12245)

    BEER^2是一种用于Retriever和Reader的双向端到端训练框架，通过检索器和阅读器之间的相互学习，共同进步，实现端到端EL。

    

    实体链接（EL）是信息提取和知识图谱的基本任务，它的一般形式（即端到端EL）旨在首先在给定输入文档中找到提及，并将提及链接到特定知识库中的相应实体。最近，检索器-阅读器范式促进了端到端EL的进展，受益于密集的实体检索和机器阅读理解的优势。然而，现有研究仅以流水线方式单独训练检索器和阅读器，忽略了检索器和阅读器之间交互带来的益处。为了使检索器-阅读器范式更完美地执行端到端EL，我们提出了BEER$^2$，一种用于Retriever and Reader的双向端到端训练框架。通过我们设计的双向端到端训练，BEER$^2$指导检索器和阅读器互相学习，共同进步，并最终实现端到端EL。

    Entity Linking (EL) is a fundamental task for Information Extraction and Knowledge Graphs. The general form of EL (i.e., end-to-end EL) aims to first find mentions in the given input document and then link the mentions to corresponding entities in a specific knowledge base. Recently, the paradigm of retriever-reader promotes the progress of end-to-end EL, benefiting from the advantages of dense entity retrieval and machine reading comprehension. However, the existing study only trains the retriever and the reader separately in a pipeline manner, which ignores the benefit that the interaction between the retriever and the reader can bring to the task. To advance the retriever-reader paradigm to perform more perfectly on end-to-end EL, we propose BEER$^2$, a Bidirectional End-to-End training framework for Retriever and Reader. Through our designed bidirectional end-to-end training, BEER$^2$ guides the retriever and the reader to learn from each other, make progress together, and ultimate
    
[^9]: 语言模型的学习限制

    Limits for Learning with Language Models. (arXiv:2306.12213v1 [cs.CL])

    [http://arxiv.org/abs/2306.12213](http://arxiv.org/abs/2306.12213)

    本论文研究了语言模型的学习限制，证明了大型语言模型无法学习某些基本的语义属性，包括语义蕴含和一致性，并且无法学习超出可数集层次结构第一层的概念，这限制了它们在语言意义方面的能力。

    

    随着大型语言模型（LLMs）的出现，NLP的趋势已经转向在大量数据上训练LLMs，以解决各种语言理解和生成任务。LLM的成功列表很长，也很多样化。尽管如此，最近的几篇论文提供了经验性的证据表明，LLMs未能捕捉语言意义的重要方面。本文侧重于普遍量化，通过证明LLMs无法学习某些基本的语义属性（如正式语义中定义的语义蕴含和一致性），为这些经验性发现提供了理论基础。 更普遍地说，我们展示了LLMs无法学习超出可数集层次结构（Borel Hierarchy）第一层的概念，这对于LLMs的能力施加了严格限制，无论其大小，都无法捕捉许多语言意义方面的内容。这意味着，LLMs将继续在需要蕴含和深刻语言理解的任务中没有正式保证地运行。

    With the advent of large language models (LLMs), the trend in NLP has been to train LLMs on vast amounts of data to solve diverse language understanding and generation tasks. The list of LLM successes is long and varied. Nevertheless, several recent papers provide empirical evidence that LLMs fail to capture important aspects of linguistic meaning. Focusing on universal quantification, we provide a theoretical foundation for these empirical findings by proving that LLMs cannot learn certain fundamental semantic properties including semantic entailment and consistency as they are defined in formal semantics. More generally, we show that LLMs are unable to learn concepts beyond the first level of the Borel Hierarchy, which imposes severe limits on the ability of LMs, both large and small, to capture many aspects of linguistic meaning. This means that LLMs will continue to operate without formal guarantees on tasks that require entailments and deep linguistic understanding.
    
[^10]: 探究预训练语言模型在跨领域数据集上的表现，迈向通用人工智能的一步。

    Investigating Pre-trained Language Models on Cross-Domain Datasets, a Step Closer to General AI. (arXiv:2306.12205v1 [cs.CL])

    [http://arxiv.org/abs/2306.12205](http://arxiv.org/abs/2306.12205)

    本文研究了预训练语言模型在跨领域任务中的表现，结果表明预训练模型可以是实现通用人工智能的重要一步。

    

    最近，预训练语言模型已成为微调各种语言任务的强有力工具。理想情况下，当模型在大量数据上进行预训练时，希望其能获得隐式知识。本文研究了预训练语言模型在泛化到不同非语言任务的能力。特别是，我们测试了来自不同领域的任务，如计算机视觉、分层数据推理和蛋白质折叠预测。我们使用的四个预训练模型，T5、BART、BERT 和 GPT-2 都取得了优异的成绩。它们的表现很相似，且它们的表现比从头开始训练的 transformers 要好得多。例如，在 Listops 数据集上，预训练语言模型的平均准确率为 58.7％，而从头开始训练的 transformers 的平均准确率为 29.0％。跨三种类型的数据集所展示的显著改进表明，预训练语言模型可能是实现通用人工智能的有前途的一步。

    Pre-trained language models have recently emerged as a powerful tool for fine-tuning a variety of language tasks. Ideally, when models are pre-trained on large amount of data, they are expected to gain implicit knowledge. In this paper, we investigate the ability of pre-trained language models to generalize to different non-language tasks. In particular, we test them on tasks from different domains such as computer vision, reasoning on hierarchical data, and protein fold prediction. The four pre-trained models that we used, T5, BART, BERT, and GPT-2 achieve outstanding results. They all have similar performance and they outperform transformers that are trained from scratch by a large margin. For instance, pre-trained language models perform better on the Listops dataset, with an average accuracy of 58.7\%, compared to transformers trained from scratch, which have an average accuracy of 29.0\%. The significant improvement demonstrated across three types of datasets suggests that pre-tra
    
[^11]: 揭开黑匣子：分析预训练语言模型在非语言任务中的注意力权重和隐藏状态

    Opening the Black Box: Analyzing Attention Weights and Hidden States in Pre-trained Language Models for Non-language Tasks. (arXiv:2306.12198v1 [cs.CL])

    [http://arxiv.org/abs/2306.12198](http://arxiv.org/abs/2306.12198)

    本论文揭示了预训练语言模型在非语言任务中的内部运作，具体使用约束算术问题探索模型的注意力权重分数和隐藏状态，并发现了有前途的结果，该模型以略微结构化的方式解决分层问题，类似于人类解决问题的策略。

    

    由于大多数先进模型的“黑匣子”特性，研究深度学习语言模型一直是一个重要的研究领域。随着基于transformers的预训练语言模型的最近进展及其在日常生活中的不断集成，解决这个问题变得更加紧迫。为了实现可解释的AI模型，必须理解涉及的过程步骤，并将其与人类思维过程进行比较。因此，在本文中，我们使用简单易懂的非语言任务来探索这些模型的内部运作。具体来说，我们将预训练语言模型应用于具有分层结构的约束算术问题，以分析其注意力权重分数和隐藏状态。调查结果显示出令人鼓舞的结果，模型以略微结构化的方式解决分层问题，类似于人类解决问题的策略。

    Investigating deep learning language models has always been a significant research area due to the ``black box" nature of most advanced models. With the recent advancements in pre-trained language models based on transformers and their increasing integration into daily life, addressing this issue has become more pressing. In order to achieve an explainable AI model, it is essential to comprehend the procedural steps involved and compare them with human thought processes. Thus, in this paper, we use simple, well-understood non-language tasks to explore these models' inner workings. Specifically, we apply a pre-trained language model to constrained arithmetic problems with hierarchical structure, to analyze their attention weight scores and hidden states. The investigation reveals promising results, with the model addressing hierarchical problems in a moderately structured manner, similar to human problem-solving strategies. Additionally, by inspecting the attention weights layer by laye
    
[^12]: 特征交互揭示语言模型中的语言结构

    Feature Interactions Reveal Linguistic Structure in Language Models. (arXiv:2306.12181v1 [cs.CL])

    [http://arxiv.org/abs/2306.12181](http://arxiv.org/abs/2306.12181)

    研究特征交互在神经网络中的重要性，提出了一种灰箱方法来分析交互特征的作用，揭示了某些方法能够反映目标模型的内部运作。

    

    我们研究特征指派方法的特征交互。在可解释性研究中，理解特征交互越来越被认为是一个重要的挑战，因为交互特征对神经网络的成功至关重要。特征交互让一个模型为其输入建立层次结构表示，并可能成为研究语言模型中语言结构的理想起点。然而，揭示这些交互精确的作用也是困难的，而且已经提出了各种各样的交互指派方法。在本文中，我们关注的问题是哪种方法最忠实地反映目标模型的内部运作。我们制定了一个灰箱方法，通过使用PCFGs在正式语言分类任务上完美训练模型。我们展示了在特定的配置下，一些方法确实能够揭示交互作用。

    We study feature interactions in the context of feature attribution methods for post-hoc interpretability. In interpretability research, getting to grips with feature interactions is increasingly recognised as an important challenge, because interacting features are key to the success of neural networks. Feature interactions allow a model to build up hierarchical representations for its input, and might provide an ideal starting point for the investigation into linguistic structure in language models. However, uncovering the exact role that these interactions play is also difficult, and a diverse range of interaction attribution methods has been proposed. In this paper, we focus on the question which of these methods most faithfully reflects the inner workings of the target models. We work out a grey box methodology, in which we train models to perfection on a formal language classification task, using PCFGs. We show that under specific configurations, some methods are indeed able to u
    
[^13]: 联合语音分离与识别的混合编码器

    Mixture Encoder for Joint Speech Separation and Recognition. (arXiv:2306.12173v1 [cs.CL])

    [http://arxiv.org/abs/2306.12173](http://arxiv.org/abs/2306.12173)

    本论文提出了一种中间方法，同时利用显式语音分离和直接在ASR模块中合并混合语音信息，通过交换跨说话者上下文信息的层，实现了在SMS-WSJ任务上相对于纯模块化设置的单词错误率7%的相对改进。

    

    多说话人自动语音识别对于许多现实世界的应用程序至关重要，但需要特定的建模技术。现有的方法可以分为模块化和端到端方法。模块化方法使用单说话人ASR系统分离说话人并识别他们。端到端模型直接在一个强大的神经网络中处理重叠的语音。本文提出了一种介于两者之间的方法，利用类似于模块化方法的显式语音分离，但也直接在ASR模块中合并混合语音信息，以减轻语音分离器造成的错误传播。我们还探索了一种通过结合个体说话人信息的层来交换跨说话者上下文信息的方法。我们的系统通过单独和联合训练阶段进行优化，在SMS-WSJ任务上相对于纯模块化设置的单词错误率实现了7%的相对改进。

    Multi-speaker automatic speech recognition (ASR) is crucial for many real-world applications, but it requires dedicated modeling techniques. Existing approaches can be divided into modular and end-to-end methods. Modular approaches separate speakers and recognize each of them with a single-speaker ASR system. End-to-end models process overlapped speech directly in a single, powerful neural network. This work proposes a middle-ground approach that leverages explicit speech separation similarly to the modular approach but also incorporates mixture speech information directly into the ASR module in order to mitigate the propagation of errors made by the speech separator. We also explore a way to exchange cross-speaker context information through a layer that combines information of the individual speakers. Our system is optimized through separate and joint training stages and achieves a relative improvement of 7% in word error rate over a purely modular setup on the SMS-WSJ task.
    
[^14]: 哪些伪相关对NLI模型的推理产生影响？基于数据限制的反事实推理的视觉交互式诊断。

    Which Spurious Correlations Impact Reasoning in NLI Models? A Visual Interactive Diagnosis through Data-Constrained Counterfactuals. (arXiv:2306.12146v1 [cs.CL])

    [http://arxiv.org/abs/2306.12146](http://arxiv.org/abs/2306.12146)

    该论文提出了一种针对NLI模型进行推理的人机交互的仪表板，发现了几类伪相关性并将其分为三类：语义相关性、逻辑谬误和偏见，其中包括增加训练数据和创建对抗测试套件来评估NLI模型的鲁棒性。

    

    我们提出了一个人机交互的仪表板，用于诊断NLI模型依赖于进行预测的潜在伪特征。该仪表板使用户能够通过受GPT-3建议启发而生成不同的和具有挑战性的例子。此外，用户可以从经过训练的NLI模型中获得有关新生成的示例的挑战性的反馈，并根据反馈进行改进。通过我们的调查，我们发现了几类影响NLI模型推理的伪相关性，我们将其分为三类：语义相关性、逻辑谬误和偏见。基于我们的发现，我们确定和描述了各种研究机会，包括增加训练数据和创建对抗测试套件来评估NLI模型的鲁棒性。

    We present a human-in-the-loop dashboard tailored to diagnosing potential spurious features that NLI models rely on for predictions. The dashboard enables users to generate diverse and challenging examples by drawing inspiration from GPT-3 suggestions. Additionally, users can receive feedback from a trained NLI model on how challenging the newly created example is and make refinements based on the feedback. Through our investigation, we discover several categories of spurious correlations that impact the reasoning of NLI models, which we group into three categories: Semantic Relevance, Logical Fallacies, and Bias. Based on our findings, we identify and describe various research opportunities, including diversifying training data and assessing NLI models' robustness by creating adversarial test suites.
    
[^15]: 通过语言模型批量生产多模态系统的失败

    Mass-Producing Failures of Multimodal Systems with Language Models. (arXiv:2306.12105v1 [cs.LG])

    [http://arxiv.org/abs/2306.12105](http://arxiv.org/abs/2306.12105)

    本文介绍了一种MultiMon系统，可以自动识别多模态系统中的系统性失败，揭示CLIP文本编码器的14个系统性失败，每个都由数百个不同的输入组成，这些输入会导致其他大多数最先进的多模态系统的失败。

    

    部署的多模态系统可能以评估人员未曾预见的方式失败。为了在部署前找到这些失败，我们介绍了MultiMon，这是一个能够自动识别系统性失败的系统，能够提供可推广的、自然语言描述模型失败模式的例子。为了揭示系统性失败，MultiMon从语料库中抓取错误协议的示例：输入产生相同的输出，但不应该如此。然后它会激活一个语言模型（例如GPT-4）来查找系统性失败的模式并用自然语言描述它们。我们使用MultiMon找到了CLIP文本编码器的14个系统性失败（例如“忽略量词”，每个都由数百个不同的输入组成（例如“一个带有一些/许多书的书架”）。因为CLIP是大多数最先进的多模态系统的基础，这些输入会导致Midjourney 5.1、DALL-E、VideoFusion等系统失败。MultiMon也可以指导针对特定用例的相关故障，例如自驾车系统。

    Deployed multimodal systems can fail in ways that evaluators did not anticipate. In order to find these failures before deployment, we introduce MultiMon, a system that automatically identifies systematic failures -generalizable, natural-language descriptions of patterns of model failures. To uncover systematic failures, MultiMon scrapes a corpus for examples of erroneous agreement: inputs that produce the same output, but should not. It then prompts a language model (e.g., GPT-4) to find systematic patterns of failure and describe them in natural language. We use MultiMon to find 14 systematic failures (e.g., "ignores quantifiers") of the CLIP text-encoder, each comprising hundreds of distinct inputs (e.g., "a shelf with a few/many books"). Because CLIP is the backbone for most state-of-the-art multimodal systems, these inputs produce failures in Midjourney 5.1, DALL-E, VideoFusion, and others. MultiMon can also steer towards failures relevant to specific use cases, such as self-dri
    
[^16]: 基于语义相关的词法约束在精确翻译中的应用研究

    Towards Accurate Translation via Semantically Appropriate Application of Lexical Constraints. (arXiv:2306.12089v1 [cs.CL])

    [http://arxiv.org/abs/2306.12089](http://arxiv.org/abs/2306.12089)

    本研究关注基于语义相关的词法约束在翻译中的应用，提出解决同形异义词问题的同形异义词消歧模块和PLUMCOT方法，并提供了评估基准HOLLY。

    

    词法约束神经机器翻译(LNMT)旨在将用户提供的术语纳入翻译中。尽管具有实用优势，但现有研究并未在具有挑战性的现实条件下评估LNMT模型。本文重点关注当前LNMT研究评估过程中存在的两个重要但鲜有研究的问题。模型需要应对训练过程中未见过的挑战性词汇约束，例如同形异义词。为此，我们首先设计了一个同形异义词消歧模块来区分同形异义词的含义。此外，我们提出了PLUMCOT，它通过使用预训练的语言模型与强化指针网络的复制机制来直接监督复制评分，从而整合了上下文丰富信息。我们还发布了HOLLY，一种评估基准，用于评估模型应对同形异义词及训练中未见词汇限制的能力。实验在HOLLY和之前的测试环境中进行

    Lexically-constrained NMT (LNMT) aims to incorporate user-provided terminology into translations. Despite its practical advantages, existing work has not evaluated LNMT models under challenging real-world conditions. In this paper, we focus on two important but under-studied issues that lie in the current evaluation process of LNMT studies. The model needs to cope with challenging lexical constraints that are "homographs" or "unseen" during training. To this end, we first design a homograph disambiguation module to differentiate the meanings of homographs. Moreover, we propose PLUMCOT, which integrates contextually rich information about unseen lexical constraints from pre-trained language models and strengthens a copy mechanism of the pointer network via direct supervision of a copying score. We also release HOLLY, an evaluation benchmark for assessing the ability of a model to cope with "homographic" and "unseen" lexical constraints. Experiments on HOLLY and the previous test setup s
    
[^17]: 将话语单元和关键词联系起来对阅读理解进行层次推理链建模

    Modeling Hierarchical Reasoning Chains by Linking Discourse Units and Key Phrases for Reading Comprehension. (arXiv:2306.12069v1 [cs.CL])

    [http://arxiv.org/abs/2306.12069](http://arxiv.org/abs/2306.12069)

    提出了一个基于全局图网络的方法，既处理话语层面又处理单词层面的上下文，并通过分层交互机制对节点级别和类型级别的关系进行建模，以提供更细粒度的关系提取，该方法在逻辑推理QA数据集和自然语言推理数据集上优于现有的最先进方法。

    

    机器阅读理解面临逻辑推理方面的新挑战，旨在理解给定上下文中所涉及的隐含逻辑关系并对其进行推理。由于逻辑复杂性，逻辑关系存在于不同的粒度级别。然而，大多数现有的推理方法分别关注实体感知或话语为基础的信息，但忽略了可能具有相互影响的层次关系。本文提出了一个基于全局图网络（HGN）的方法，既处理话语层面又处理单词层面的上下文，作为逻辑推理的基础，以提供更细粒度的关系提取。具体而言，通过分层交互机制对节点级别和类型级别的关系进行建模，这些关系可以解释为推理过程中的桥梁，以改进MRC系统的解释能力。实验结果表明，我们提出的方法在逻辑推理QA数据集（ReClor和LogiQA）和自然语言推理数据集（RACE和SWAG）上优于现有的最先进方法。

    Machine reading comprehension (MRC) poses new challenges over logical reasoning, which aims to understand the implicit logical relations entailed in the given contexts and perform inference over them. Due to the complexity of logic, logical relations exist at different granularity levels. However, most existing methods of logical reasoning individually focus on either entity-aware or discourse-based information but ignore the hierarchical relations that may even have mutual effects. In this paper, we propose a holistic graph network (HGN) which deals with context at both discourse level and word level, as the basis for logical reasoning, to provide a more fine-grained relation extraction. Specifically, node-level and type-level relations, which can be interpreted as bridges in the reasoning process, are modeled by a hierarchical interaction mechanism to improve the interpretation of MRC systems. Experimental results on logical reasoning QA datasets (ReClor and LogiQA) and natural langu
    
[^18]: 自然语言对抗攻击中的样本攻击能力研究

    Sample Attackability in Natural Language Adversarial Attacks. (arXiv:2306.12043v1 [cs.CL])

    [http://arxiv.org/abs/2306.12043](http://arxiv.org/abs/2306.12043)

    本文研究了自然语言处理领域中，哪些样本最易受到对抗攻击或最具鲁棒性的问题，并扩展了该领域中的“样本攻击能力/鲁棒性”的定义。实验发现，基于深度学习的检测器可以更好地识别出一个看不见的目标模型中最易受攻击和最具鲁棒性的样本。

    

    自然语言处理领域的对抗攻击研究已经在设计强大的攻击方法和防御方法方面取得了重大进展。然而，很少有研究努力去确定哪些源样本是最易受攻击或最具鲁棒性，即在一个看不见的目标模型上，我们是否可以确定哪些样本最容易受到对抗攻击。本文正式扩展了自然语言处理攻击中样本攻击能力/鲁棒性的定义。在两个流行的自然语言处理数据集、四种最先进的模型和四种不同的自然语言对抗攻击方法上的实验表明，样本不确定性不能充分描述攻击性/鲁棒性样本的特征，因此基于深度学习的检测器可以更好地识别出一个看不见的目标模型中最易受攻击和最具鲁棒性的样本。然而，进一步的分析发现，在不同的自然语言处理攻击方法中，对于哪些样本被认为是最易受攻击/最具鲁棒性，不存在明显的一致性。

    Adversarial attack research in natural language processing (NLP) has made significant progress in designing powerful attack methods and defence approaches. However, few efforts have sought to identify which source samples are the most attackable or robust, i.e. can we determine for an unseen target model, which samples are the most vulnerable to an adversarial attack. This work formally extends the definition of sample attackability/robustness for NLP attacks. Experiments on two popular NLP datasets, four state of the art models and four different NLP adversarial attack methods, demonstrate that sample uncertainty is insufficient for describing characteristics of attackable/robust samples and hence a deep learning based detector can perform much better at identifying the most attackable and robust samples for an unseen target model. Nevertheless, further analysis finds that there is little agreement in which samples are considered the most attackable/robust across different NLP attack 
    
[^19]: 低资源语音合成中的转移学习策略：音素映射，特征输入和源语言选择

    Strategies in Transfer Learning for Low-Resource Speech Synthesis: Phone Mapping, Features Input, and Source Language Selection. (arXiv:2306.12040v1 [cs.CL])

    [http://arxiv.org/abs/2306.12040](http://arxiv.org/abs/2306.12040)

    本文比较了在低资源语言的TTS中使用基于PHOIBLE的音素映射方法和使用语音特征输入的转移学习策略。结果表明两种方法都可以提高输出质量，但后者表现更好。此外，作者还提出了在转移学习中选择源语言的标准，并发现基于角频率相似性的音频频率是有效的，而语言距离则没有预期的效果。

    

    我们比较了基于PHOIBLE的音素映射方法和使用语音特征输入在低资源语言的TTS中的转移学习。我们使用多种源语言（英语，芬兰语，印地语，日语和俄语）和目标语言（保加利亚语，格鲁吉亚语，哈萨克语，斯瓦希里语，乌尔都语和乌兹别克语）测试方法的语言独立性，增强研究结果的适用性。我们使用自动语音识别的字符误差率和预测的平均意见分数进行评估。结果表明，音素映射和特征输入都可以提高输出质量，后者表现更好，但这些效果也取决于具体的语言组合。我们还将最近提出的基于角频率相似性的音频频率（ASPF）与基于家族树的距离度量进行比较，作为在转移学习中选择源语言的标准。如果使用基于标签的电话输入，则ASPF证明有效，而语言距离则没有预期的效果。

    We compare using a PHOIBLE-based phone mapping method and using phonological features input in transfer learning for TTS in low-resource languages. We use diverse source languages (English, Finnish, Hindi, Japanese, and Russian) and target languages (Bulgarian, Georgian, Kazakh, Swahili, Urdu, and Uzbek) to test the language-independence of the methods and enhance the findings' applicability. We use Character Error Rates from automatic speech recognition and predicted Mean Opinion Scores for evaluation. Results show that both phone mapping and features input improve the output quality and the latter performs better, but these effects also depend on the specific language combination. We also compare the recently-proposed Angular Similarity of Phone Frequencies (ASPF) with a family tree-based distance measure as a criterion to select source languages in transfer learning. ASPF proves effective if label-based phone input is used, while the language distance does not have expected effects.
    
[^20]: 视觉感知的语音合成

    Visual-Aware Text-to-Speech. (arXiv:2306.12020v1 [eess.AS])

    [http://arxiv.org/abs/2306.12020](http://arxiv.org/abs/2306.12020)

    本文提出了一个新的视觉感知的文本到语音（VA-TTS）任务，用于在面对面的交流中，基于文本输入和接收者的序列视觉反馈来合成语音，并设计了一个基准模型进行语音合成，实验证明在多模态对话数据集上生成更自然的音频，具有场景适当的韵律和语调。

    

    动态地合成能够主动响应听众的语音在面对面的交互中至关重要。例如，演讲者可以利用听众的面部表情来调整语调、重读音节或停顿。在本文中，我们提出了一个新的视觉感知的文本到语音（VA-TTS）任务，用于在面对面的交流中，基于文本输入和接收者的序列视觉反馈（如点头、微笑）来合成语音。不同于传统的文本到语音，VA-TTS强调了视觉模态的影响。在这个新任务上，我们设计了一个基准模型，用于融合音素语言信息和听众的视觉信号来进行语音合成。对多模态对话数据集ViCo-X的广泛实验验证了我们的提议，生成了更自然的音频，并具有场景适当的韵律和语调。

    Dynamically synthesizing talking speech that actively responds to a listening head is critical during the face-to-face interaction. For example, the speaker could take advantage of the listener's facial expression to adjust the tones, stressed syllables, or pauses. In this work, we present a new visual-aware text-to-speech (VA-TTS) task to synthesize speech conditioned on both textual inputs and sequential visual feedback (e.g., nod, smile) of the listener in face-to-face communication. Different from traditional text-to-speech, VA-TTS highlights the impact of visual modality. On this newly-minted task, we devise a baseline model to fuse phoneme linguistic information and listener visual signals for speech synthesis. Extensive experiments on multimodal conversation dataset ViCo-X verify our proposal for generating more natural audio with scenario-appropriate rhythm and prosody.
    
[^21]: 一种半自回归图生成模型用于依存关系图解析

    A Semi-Autoregressive Graph Generative Model for Dependency Graph Parsing. (arXiv:2306.12018v1 [cs.CL])

    [http://arxiv.org/abs/2306.12018](http://arxiv.org/abs/2306.12018)

    提出了一种半自回归的依存解析器，成功捕获了节点和边缘之间的显式依赖关系，取得了最先进的结果。

    

    近年来，神经依存解析取得了令人瞩目的进展。根据对图联合概率的不同分解方法，现有解析器可以大致分为自回归和非自回归模式。然而，当将有向边视为显式依赖关系时，我们发现依存图中存在独立和相互依赖的组件混合，标志着先前的模型无法准确捕捉节点和边缘之间的显式依赖关系。基于这一特性，我们设计了一个半自回归的依存解析器，通过加入节点组和边组自回归地并将节点嵌入一次性的方式来生成依存图。我们的模型成功捕获了节点和边缘之间的显式依赖关系，并在多个基准数据集上实现了最先进的结果。

    Recent years have witnessed the impressive progress in Neural Dependency Parsing. According to the different factorization approaches to the graph joint probabilities, existing parsers can be roughly divided into autoregressive and non-autoregressive patterns. The former means that the graph should be factorized into multiple sequentially dependent components, then it can be built up component by component. And the latter assumes these components to be independent so that they can be outputted in a one-shot manner. However, when treating the directed edge as an explicit dependency relationship, we discover that there is a mixture of independent and interdependent components in the dependency graph, signifying that both aforementioned models fail to precisely capture the explicit dependencies among nodes and edges. Based on this property, we design a Semi-Autoregressive Dependency Parser to generate dependency graphs via adding node groups and edge groups autoregressively while pouring 
    
[^22]: 3HAN：基于深度神经网络的虚假新闻检测模型

    3HAN: A Deep Neural Network for Fake News Detection. (arXiv:2306.12014v1 [cs.LG])

    [http://arxiv.org/abs/2306.12014](http://arxiv.org/abs/2306.12014)

    3HAN是一种基于深度学习的虚假新闻自动检测器。通过三层分层注意网络，它可以构建一个对新闻进行完整有效表示的新闻向量，并给文章不同部分分配不同的重要性，实现了高准确率的虚假新闻检测，并且提供了可理解的输出结果。

    

    虚假新闻的迅速传播是一个需要AI解决方案的严重问题。我们使用基于深度学习的三层分层注意网络（3HAN）构建一个自动检测器，用于快速、准确地检测虚假新闻。 3HAN通过逐层自下而上的方式构建新闻向量：对输入新闻文章的有效表示。在新闻中，标题是虚假新闻的一个区别特征，同时文章中的相对较少的单词和句子比其余部分更为重要。3HAN由于具有三层注意力的机制，给文章的不同部分分配不同的重要性。通过对大型真实数据集的实验，我们观察到了3HAN的高效性，准确率达到了96.77％。与其他深度学习模型不同，3HAN通过对文章不同部分的注意权重提供了可理解的输出结果。

    The rapid spread of fake news is a serious problem calling for AI solutions. We employ a deep learning based automated detector through a three level hierarchical attention network (3HAN) for fast, accurate detection of fake news. 3HAN has three levels, one each for words, sentences, and the headline, and constructs a news vector: an effective representation of an input news article, by processing an article in an hierarchical bottom-up manner. The headline is known to be a distinguishing feature of fake news, and furthermore, relatively few words and sentences in an article are more important than the rest. 3HAN gives a differential importance to parts of an article, on account of its three layers of attention. By experiments on a large real-world data set, we observe the effectiveness of 3HAN with an accuracy of 96.77%. Unlike some other deep learning models, 3HAN provides an understandable output through the attention weights given to different parts of an article, which can be visu
    
[^23]: 使用自然语言的交互式分子发现

    Interactive Molecular Discovery with Natural Language. (arXiv:2306.11976v1 [cs.CL])

    [http://arxiv.org/abs/2306.11976](http://arxiv.org/abs/2306.11976)

    本文提出了一种交互式分子设计任务，通过自然语言描述和编辑目标分子。我们设计了ChatMol模型用于生成和编辑分子，并测试了其在分子任务上的优越性。

    

    自然语言被期望成为大型语言模型时代各种人机交互的关键媒介。在生物化学领域，围绕分子（例如，属性预测、分子挖掘等）的一系列任务具有重要意义，但技术门槛很高。将自然语言中的分子表达与化学语言相结合，不仅可以大大提高任务的解释性、降低操作难度，而且还可以融合散布在互补材料中的化学知识，深入理解分子。基于这些优势，我们提出了交互式分子设计，这是一项采用自然语言描述和编辑目标分子的新任务。为更好地完成此任务，我们设计了ChatMol，一种知识丰富且多功能的生成预训练模型，通过注入实验性质信息，分子空间知识以及自然语言和分子之间的关联进行增强。 ChatMol可以为分子生成信息丰富的描述，更正给定的分子，甚至可以通过互动对话迭代地设计具有所需属性的分子。我们在几个分子任务上测试了ChatMol，并证明其优于传统方法。

    Natural language is expected to be a key medium for various human-machine interactions in the era of large language models. When it comes to the biochemistry field, a series of tasks around molecules (e.g., property prediction, molecule mining, etc.) are of great significance while having a high technical threshold. Bridging the molecule expressions in natural language and chemical language can not only hugely improve the interpretability and reduce the operation difficulty of these tasks, but also fuse the chemical knowledge scattered in complementary materials for a deeper comprehension of molecules. Based on these benefits, we propose the conversational molecular design, a novel task adopting natural language for describing and editing target molecules. To better accomplish this task, we design ChatMol, a knowledgeable and versatile generative pre-trained model, enhanced by injecting experimental property information, molecular spatial knowledge, and the associations between natural
    
[^24]: 探究代码语言模型所学习的内容

    Towards Understanding What Code Language Models Learned. (arXiv:2306.11943v1 [cs.SE])

    [http://arxiv.org/abs/2306.11943](http://arxiv.org/abs/2306.11943)

    本研究探究了预先训练的代码语言模型的能力，证明其能够超越表面形式特征，学习精确而形式化定义的代码的计算语义。

    

    预先训练的语言模型在各种自然语言任务中都非常有效，但有人认为它们的能力不足以完全学习语言的意义或理解语言。为了了解语言模型能够学习某种形式的意义的程度，我们研究它们捕捉代码语义的能力，超越表层频率和共现的限制。与以往研究模型语言特征的探究相比，我们在一种可以客观地、简单明了地评估模型学习语义能力的环境下研究预训练模型。本文研究了这样的模型是否能捕捉精确而形式化定义的代码的语义。通过对代码片段的操纵实验，我们展示了代码预先训练模型学习了代码的计算语义的强有力的表征，超越了代码表面特征。

    Pre-trained language models are effective in a variety of natural language tasks, but it has been argued their capabilities fall short of fully learning meaning or understanding language. To understand the extent to which language models can learn some form of meaning, we investigate their ability to capture semantics of code beyond superficial frequency and co-occurrence. In contrast to previous research on probing models for linguistic features, we study pre-trained models in a setting that allows for objective and straightforward evaluation of a model's ability to learn semantics. In this paper, we examine whether such models capture the semantics of code, which is precisely and formally defined. Through experiments involving the manipulation of code fragments, we show that code pre-trained models of code learn a robust representation of the computational semantics of code that goes beyond superficial features of form alone
    
[^25]: LLMs在Polis可扩展协商中的机会与风险

    Opportunities and Risks of LLMs for Scalable Deliberation with Polis. (arXiv:2306.11932v1 [cs.SI])

    [http://arxiv.org/abs/2306.11932](http://arxiv.org/abs/2306.11932)

    本文探讨了LLMs在促进、调节和总结Polis可扩展协商中的机会和风险，试验表明总结能力使得公共参与具有巨大潜力，但是LLMs的上下文限制对结果的影响很大。同时，我们讨论了原则和技术来表征和减轻这些风险。

    

    Polis是一个利用机器智能扩大协商过程的平台。本文探讨了将大型语言模型（LLMs）应用于促进、调节和总结Polis参与过程中面临的机会和风险。特别是，通过使用Anthropic的Claude进行试点实验，我们证明LLMs确实可以增强人类智能，帮助更有效地运行Polis对话。我们发现，总结能力使得集体意义形成练习中的公共参与具有巨大的潜力。然而，LLMs的上下文限制对结果的洞见和质量有重要影响。但是，这些机会也伴随着风险。我们讨论了其中一些风险，以及表征和减轻这些风险的原则和技术，以及可能采用LLMs的其他协商或政治系统的影响。最后，我们概述了未来研究的途径，包括开发结合人类和LLM智能的混合方法以实现更好的结果。

    Polis is a platform that leverages machine intelligence to scale up deliberative processes. In this paper, we explore the opportunities and risks associated with applying Large Language Models (LLMs) towards challenges with facilitating, moderating and summarizing the results of Polis engagements. In particular, we demonstrate with pilot experiments using Anthropic's Claude that LLMs can indeed augment human intelligence to help more efficiently run Polis conversations. In particular, we find that summarization capabilities enable categorically new methods with immense promise to empower the public in collective meaning-making exercises. And notably, LLM context limitations have a significant impact on insight and quality of these results.  However, these opportunities come with risks. We discuss some of these risks, as well as principles and techniques for characterizing and mitigating them, and the implications for other deliberative or political systems that may employ LLMs. Finally
    
[^26]: 情感化微博文本的中英机器翻译的评估：一个用于情感翻译的质量评估的人工标注数据集

    Evaluation of Chinese-English Machine Translation of Emotion-Loaded Microblog Texts: A Human Annotated Dataset for the Quality Assessment of Emotion Translation. (arXiv:2306.11900v1 [cs.CL])

    [http://arxiv.org/abs/2306.11900](http://arxiv.org/abs/2306.11900)

    本文评估了Google翻译对情感化文本的中英翻译效果，发现50%的翻译输出没有保留原始情感信息，情感词汇和语言现象是这些翻译错误的原因。

    

    本文评估了Google翻译在情感化文本翻译方面的效果，提出了基于多维度质量度量和详细错误分析的评估框架。通过分析结果，我们发现大约50%的机器翻译输出没有保留原始的情感信息。在进一步分析错误的过程中，我们发现情感词汇和语言现象（如多义词、否定、缩写等）是这些翻译错误的常见原因。

    In this paper, we focus on how current Machine Translation (MT) tools perform on the translation of emotion-loaded texts by evaluating outputs from Google Translate according to a framework proposed in this paper. We propose this evaluation framework based on the Multidimensional Quality Metrics (MQM) and perform a detailed error analysis of the MT outputs. From our analysis, we observe that about 50% of the MT outputs fail to preserve the original emotion. After further analysis of the errors, we find that emotion carrying words and linguistic phenomena such as polysemous words, negation, abbreviation etc., are common causes for these translation errors.
    
[^27]: 探索农业自然语言处理的新前沿：研究大型语言模型在食品应用中的潜力。

    Exploring New Frontiers in Agricultural NLP: Investigating the Potential of Large Language Models for Food Applications. (arXiv:2306.11892v1 [cs.CL])

    [http://arxiv.org/abs/2306.11892](http://arxiv.org/abs/2306.11892)

    本文探索利用与食品相关的文本语料库为基础预训练转换器语言模型的能力，以实现语义匹配任务。通过微调预训练的转换器语言模型AgriBERT，并利用外部知识如FoodOn本体论等，同时借助ChatGPT外部知识源，可以进一步增强模型对与食品相关的概念和关系的理解。

    

    本文探索运用与食品相关的文本语料库为基础预训练转换器语言模型的有效性，从而开拓农业自然语言处理的新前沿。特别是，我们关注语义匹配这个任务，该任务涉及建立食品描述和营养数据之间的映射关系。为了完成这一任务，我们通过使用FoodOn本体论等外部知识来微调预训练的转换器语言模型AgriBERT。为了推进农业自然语言处理领域，我们提出了两个新的探索途径：(1) 利用基于GPT的模型作为基准和(2) 利用ChatGPT作为外部知识源。在许多自然语言处理任务中，ChatGPT已被证明是一个强有力的基准，我们相信它具有潜力提高我们的模型在语义匹配任务中的表现，并增强模型对与食品相关的概念和关系的理解。此外，我们还实验了其他应用。

    This paper explores new frontiers in agricultural natural language processing by investigating the effectiveness of using food-related text corpora for pretraining transformer-based language models. In particular, we focus on the task of semantic matching, which involves establishing mappings between food descriptions and nutrition data. To accomplish this, we fine-tune a pre-trained transformer-based language model, AgriBERT, on this task, utilizing an external source of knowledge, such as the FoodOn ontology. To advance the field of agricultural NLP, we propose two new avenues of exploration: (1) utilizing GPT-based models as a baseline and (2) leveraging ChatGPT as an external source of knowledge. ChatGPT has shown to be a strong baseline in many NLP tasks, and we believe it has the potential to improve our model in the task of semantic matching and enhance our model's understanding of food-related concepts and relationships. Additionally, we experiment with other applications, such
    
[^28]: 基于元分布建模的开放领域文本评估

    Open-Domain Text Evaluation via Meta Distribution Modeling. (arXiv:2306.11879v1 [cs.CL])

    [http://arxiv.org/abs/2306.11879](http://arxiv.org/abs/2306.11879)

    本文提出了一种新颖的开放领域文本生成模型评估方法——元分布方法（MDM），该方法将两个概率分布的对比映射到质量度量上，可以视为分布的分布，其可用于开放领域文本生成的评估。

    

    最近，基于大型预训练语言模型（LLMs）的开放领域文本生成模型取得了显著的性能提升。然而，为了控制和评估这些模型是否达到所需属性仍然是一个挑战，因为传统的基于参考文本的度量标准如BLEU、ROUGE和METEOR对于开放式生成任务来说是不足够的。同样地，虽然具备训练鉴别器的度量标准表现出了希望的前景，但是获取高质量的训练数据则是一项非常困难的任务。本文提出了一种新颖的方法来评估开放领域文本生成——元分布方法（MDM）。通过考虑LLMs参数数量上升和性能提升之间的相关性，MDM 创造了一个映射，将两个概率分布的对比（一个已知优于另一个）映射到质量度量上，该度量可以视为分布的分布，即元分布。我们研究了MDM在评估开放领域文本生成中的应用。

    Recent advances in open-domain text generation models powered by large pre-trained language models (LLMs) have achieved remarkable performance. However, evaluating and controlling these models for desired attributes remains a challenge, as traditional reference-based metrics such as BLEU, ROUGE, and METEOR are insufficient for open-ended generation tasks. Similarly, while trainable discriminator-based evaluation metrics show promise, obtaining high-quality training data is a non-trivial task. In this paper, we introduce a novel approach to evaluate open-domain generation - the Meta-Distribution Methods (MDM). Drawing on the correlation between the rising parameter counts and the improving performance of LLMs, MDM creates a mapping from the contrast of two probabilistic distributions -- one known to be superior to the other -to quality measures, which can be viewed as a distribution of distributions i.e. Meta-Distribution. We investigate MDM for open-domain text generation evaluation 
    
[^29]: 基于检索的Transformer模型用于表格增强

    Retrieval-Based Transformer for Table Augmentation. (arXiv:2306.11843v1 [cs.CL])

    [http://arxiv.org/abs/2306.11843](http://arxiv.org/abs/2306.11843)

    本文提出了一种自动数据处理的新方法，其中使用基于检索的Transformer模型来解决表格增强任务，并采用自学习策略来训练模型以重构原始值或标题，以便减轻数据分析师在数据处理中的工作量。

    

    数据准备（也称数据整理）通常被认为是进行分析或构建机器学习模型时最耗费时间和精力的步骤之一。本文引入了一种自动数据处理的新方法，以试图减轻最终用户（例如数据分析师）在从数据湖中构建动态表格数据的过程中的工作量。我们旨在解决表格增强任务，包括行/列填充和数据插补。给定一组表格，我们提出了一种检索增强的自学习Transformer模型。我们的自学习策略是从语料库中随机去除表格，并训练检索模型以在给定部分表格作为输入的情况下重构原始值或标题。我们采用这种策略来首先训练密集的神经检索模型

    Data preparation, also called data wrangling, is considered one of the most expensive and time-consuming steps when performing analytics or building machine learning models. Preparing data typically involves collecting and merging data from complex heterogeneous, and often large-scale data sources, such as data lakes. In this paper, we introduce a novel approach toward automatic data wrangling in an attempt to alleviate the effort of end-users, e.g. data analysts, in structuring dynamic views from data lakes in the form of tabular data. We aim to address table augmentation tasks, including row/column population and data imputation. Given a corpus of tables, we propose a retrieval augmented self-trained transformer model. Our self-learning strategy consists in randomly ablating tables from the corpus and training the retrieval-based model to reconstruct the original values or headers given the partial tables as input. We adopt this strategy to first train the dense neural retrieval mode
    
[^30]: EvolveMT：一种仅通过使用改进自身的集成MT引擎

    EvolveMT: an Ensemble MT Engine Improving Itself with Usage Only. (arXiv:2306.11823v1 [cs.CL])

    [http://arxiv.org/abs/2306.11823](http://arxiv.org/abs/2306.11823)

    EvolveMT是一个可以高效组合多个机器翻译引擎的系统，该系统通过在线学习技术动态适应领域或机器翻译引擎的改变，从而实现可靠的翻译结果，并且只需使用本身进行改进，消除了额外训练的必要性。

    

    本文介绍了EvolveMT，它可以高效地组合多个机器翻译（MT）引擎。该系统通过利用在线学习技术为每个段落选择单个引擎的输出，以预测每个翻译请求的最合适系统。神经质量估计度量监督该方法，无需参考翻译。该系统的在线学习能力允许动态适应领域或机器翻译引擎的改变，因此消除了额外训练的必要性。 EvolveMT基于源语句特征选择要调用的翻译引擎子集。探索程度可根据所需的质量-成本平衡进行配置。定制数据集的结果表明，EvolveMT在成本更低的情况下实现了类似于从所有翻译中选择每个段落的最佳翻译的MT质量估计器所实现的翻译准确性。据我们所知，EvolveMT是第一个仅通过使用自身改进的集成MT引擎。

    This paper presents EvolveMT for efficiently combining multiple machine translation (MT) engines. The proposed system selects the output from a single engine for each segment by utilizing online learning techniques to predict the most suitable system for every translation request. A neural quality estimation metric supervises the method without requiring reference translations. The online learning capability of this system allows for dynamic adaptation to alterations in the domain or machine translation engines, thereby obviating the necessity for additional training. EvolveMT selects a subset of translation engines to be called based on the source sentence features. The degree of exploration is configurable according to the desired quality-cost trade-off. Results from custom datasets demonstrate that EvolveMT achieves similar translation accuracy at a lower cost than selecting the best translation of each segment from all translations using an MT quality estimator. To our knowledge, E
    
[^31]: 学会生成比你的LMM更好的文本

    Learning to Generate Better Than Your LLM. (arXiv:2306.11816v1 [cs.LG])

    [http://arxiv.org/abs/2306.11816](http://arxiv.org/abs/2306.11816)

    本论文研究了基于强化学习算法 RLGF，用于在 GPT-3 等动态黑匣子指导下微调大型语言模型 LLM 的条件文本生成，相比通用 RL 算法，该算法在 IMDB 和 CommonGen 任务中表现更好。

    

    强化学习(RL)已经成为一种强大的范例，用于优化大型语言模型 (LLM) 条件文本生成。特别地，最近的LLM，如ChatGPT和GPT - 4能够与用户进行流畅的对话，并融合了RL和人类反馈。本研究受到学习搜索算法的启发，并利用文本生成的关键特性，探索了超出通用RL算法如PPO之外的强化学习算法。特别地，我们扩展了RL算法，使其能够与动态黑匣子的指导LLM如GPT-3进行交互，并提出了具有引导反馈的RL(RLGF)，这是一套用于LLM微调的RL算法。我们在GRUE基准测试的IMDB正向评论和CommonGen文本生成任务上进行了实验。我们展示了我们的RL算法比监督学习(SL)和默认PPO基线表现更高，证明了与指导LLM互动的好处。

    Reinforcement learning (RL) has emerged as a powerful paradigm for fine-tuning Large Language Models (LLMs) for conditional text generation. In particular, recent LLMs such as ChatGPT and GPT-4 can engage in fluent conversations with users by incorporating RL and feedback from humans. Inspired by learning-to-search algorithms and capitalizing on key properties of text generation, we seek to investigate reinforcement learning algorithms beyond general purpose algorithms such as Proximal policy optimization (PPO). In particular, we extend RL algorithms to allow them to interact with a dynamic black-box guide LLM such as GPT-3 and propose RL with guided feedback (RLGF), a suite of RL algorithms for LLM fine-tuning. We experiment on the IMDB positive review and CommonGen text generation task from the GRUE benchmark. We show that our RL algorithms achieve higher performance than supervised learning (SL) and default PPO baselines, demonstrating the benefit of interaction with the guide LLM. 
    
[^32]: 低资源环境中的视觉基础少量示例词汇学习

    Visually grounded few-shot word learning in low-resource settings. (arXiv:2306.11371v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2306.11371](http://arxiv.org/abs/2306.11371)

    本论文提出了一个可以在低资源环境中只用少量样本学习新词汇及其视觉表示的视觉语音模型，可应用于Yoruba等低资源语言的多模态少量示例学习。

    

    我们提出了一个视觉语音模型，在只有少量词-图像实例对的情况下学习新单词及其视觉表示。我们的方法可以在自然词-图像对上工作，但使用更少的示例，并且可以应用于实际低资源语言Yoruba的多模态少量示例学习中。

    We propose a visually grounded speech model that learns new words and their visual depictions from just a few word-image example pairs. Given a set of test images and a spoken query, we ask the model which image depicts the query word. Previous work has simplified this few-shot learning problem by either using an artificial setting with digit word-image pairs or by using a large number of examples per class. Moreover, all previous studies were performed using English speech-image data. We propose an approach that can work on natural word-image pairs but with less examples, i.e. fewer shots, and then illustrate how this approach can be applied for multimodal few-shot learning in a real low-resource language, Yoruba. Our approach involves using the given word-image example pairs to mine new unsupervised word-image training pairs from large collections of unlabelledspeech and images. Additionally, we use a word-to-image attention mechanism to determine word-image similarity. With this new
    
[^33]: 基于提示的少样本学习在自然语言理解中的对抗鲁棒性研究

    Adversarial Robustness of Prompt-based Few-Shot Learning for Natural Language Understanding. (arXiv:2306.11066v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.11066](http://arxiv.org/abs/2306.11066)

    本文针对几种FSL方法的鲁棒性指出，与全微调模型相比，纯FSL模型面对对抗扰动会带来不可忽视的任务性能下降。但使用无标签数据生成提示或使用多个提示可以显著提高鲁棒性，在某些情况下甚至胜过全微调模型。

    

    现有的少样本学习（Few-shot learning，FSL）方法通过基于提示的微调在自然语言理解（NLU）任务上取得了显著的结果。本文对几种最先进的FSL方法进行了广泛的研究，以评估它们对于对抗扰动的鲁棒性。研究表明，相对于全微调模型，纯FSL方法面对对抗扰动会出现明显的任务性能下降，但使用无标签数据进行提示生成或在训练中使用多个提示，可以在某些情况下显著提高FSL方法的鲁棒性，甚至超过全微调模型的性能表现。此外，我们发现模型大小和类型选择在对抗鲁棒性上也有显著的影响。

    State-of-the-art few-shot learning (FSL) methods leverage prompt-based fine-tuning to obtain remarkable results for natural language understanding (NLU) tasks. While much of the prior FSL methods focus on improving downstream task performance, there is a limited understanding of the adversarial robustness of such methods. In this work, we conduct an extensive study of several state-of-the-art FSL methods to assess their robustness to adversarial perturbations. To better understand the impact of various factors towards robustness (or the lack of it), we evaluate prompt-based FSL methods against fully fine-tuned models for aspects such as the use of unlabeled data, multiple prompts, number of few-shot examples, model size and type. Our results on six GLUE tasks indicate that compared to fully fine-tuned models, vanilla FSL methods lead to a notable relative drop in task performance (i.e., are less robust) in the face of adversarial perturbations. However, using (i) unlabeled data for pro
    
[^34]: 面向科技写作支持的语言模型微调

    Fine-Tuning Language Models for Scientific Writing Support. (arXiv:2306.10974v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.10974](http://arxiv.org/abs/2306.10974)

    本文提出了一种用于科技写作支持的语言模型微调方法，包括评估句子科学性、划分段落和润色建议等功能，并对模型进行偏见测试和上下文分析。

    

    本文旨在为科技作者提供科技性判断，划分段落，以及提供润色建议的辅助功能。首先，我们提出了一个回归模型，该模型是根据从同行评审的科技论文和非科技文本中提取的科技句子语料训练得到的，用于评估一个句子的科学性。我们研究了方程式和引文对该评分的影响，以测试该模型是否存在偏见。其次，我们创建了一个映射，将AI和机器学习标准论文布局中的标题映射到一个最可能的段落，以将句子分类到其所属的段落中。我们研究了上下文对段落分类性能的影响。最后，我们提出了一个润色器，它为给定的句子提供了替代方案，包括单词替换、添加语句和结构变化，以改善写作风格。我们在句子级别对各种大型语言模型进行了训练。

    We support scientific writers in determining whether a written sentence is scientific, to which section it belongs, and suggest paraphrasings to improve the sentence. Firstly, we propose a regression model trained on a corpus of scientific sentences extracted from peer-reviewed scientific papers and non-scientific text to assign a score that indicates the scientificness of a sentence. We investigate the effect of equations and citations on this score to test the model for potential biases. Secondly, we create a mapping of section titles to a standard paper layout in AI and machine learning to classify a sentence to its most likely section. We study the impact of context, i.e., surrounding sentences, on the section classification performance. Finally, we propose a paraphraser, which suggests an alternative for a given sentence that includes word substitutions, additions to the sentence, and structural changes to improve the writing style. We train various large language models on senten
    
[^35]: BayLing：通过交互式翻译连接跨语言对齐和指令追踪，为大型语言模型提供支持。

    BayLing: Bridging Cross-lingual Alignment and Instruction Following through Interactive Translation for Large Language Models. (arXiv:2306.10968v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.10968](http://arxiv.org/abs/2306.10968)

    BayLing是一个指令遵循的LLM，通过交互式翻译将语言生成和指令遵循的能力从英语转移到其他语言，使得在非英语语言上也能够实现与最先进的LLMs相同的性能，而且不需要语言特定数据或指令。

    

    大型语言模型（LLMs）展示了惊人的语言理解和生成能力。从基础LLMs发展为指令追踪LLMs，指令调优在将LLMs与人类偏好对齐方面起着至关重要的作用。然而，现有的LLMs通常专注于英语，导致非英语语言表现较差。为了提高非英语语言的性能，需要收集基础LLMs的语言特定的训练数据，并构建语言特定的指令以进行指令调优，这两者都是沉重的负担。为了最小化人类工作量，我们提出通过交互式翻译任务将语言生成和指令遵循的能力从英语转移到其他语言。我们开发了BayLing，一种指令遵循LLM，利用LLaMA作为基础LLM，自动构建交互式翻译指令以进行指令调优。对英语、中文和西班牙语三种语言的广泛评估表明，BayLing在不需要语言特定数据或指令的情况下实现了与最先进的LLMs相当的性能。

    Large language models (LLMs) have demonstrated remarkable prowess in language understanding and generation. Advancing from foundation LLMs to instructionfollowing LLMs, instruction tuning plays a vital role in aligning LLMs to human preferences. However, the existing LLMs are usually focused on English, leading to inferior performance in non-English languages. In order to improve the performance for non-English languages, it is necessary to collect language-specific training data for foundation LLMs and construct language-specific instructions for instruction tuning, both of which are heavy loads. To minimize human workload, we propose to transfer the capabilities of language generation and instruction following from English to other languages through an interactive translation task. We have developed BayLing, an instruction-following LLM by utilizing LLaMA as the foundation LLM and automatically constructing interactive translation instructions for instructing tuning. Extensive assess
    
[^36]: ChatGPT 能通过越南高中毕业考试吗？

    Can ChatGPT pass the Vietnamese National High School Graduation Examination?. (arXiv:2306.09170v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.09170](http://arxiv.org/abs/2306.09170)

    ChatGPT使用在越南高中毕业考试中表现出一定的水平，展示了AI动力聊天机器人在教育领域的潜力。

    

    本研究文章强调了 AI 动力聊天机器人在教育中的潜力，并介绍了使用 ChatGPT，一种大型语言模型，完成越南高中毕业考试（VNHSGE）的结果。研究数据集包括文学测试案例中的 30 篇文章和设计给其他科目的 1,700 道多项选择题。结果显示 ChatGPT 能够通过考试，并得到了平均 6-7 分的成绩，展示了这项技术革命教育领域的潜力。 ChatGPT 表现的分析显示其在包括数学、英语、物理、化学、生物、历史、地理、公民教育和文学在内的一系列学科中都很熟练，这表明其支持学习者具有潜力。但需要进一步研究 ChatGPT 在更复杂的考试问题上的表现以及其支持不同背景学习者的潜力。随着技术的不断发展，AI 动力聊天机器人在教育领域的潜在应用是广泛而有前景的。

    This research article highlights the potential of AI-powered chatbots in education and presents the results of using ChatGPT, a large language model, to complete the Vietnamese National High School Graduation Examination (VNHSGE). The study dataset included 30 essays in the literature test case and 1,700 multiple-choice questions designed for other subjects. The results showed that ChatGPT was able to pass the examination with an average score of 6-7, demonstrating the technology's potential to revolutionize the educational landscape. The analysis of ChatGPT performance revealed its proficiency in a range of subjects, including mathematics, English, physics, chemistry, biology, history, geography, civic education, and literature, which suggests its potential to provide effective support for learners. However, further research is needed to assess ChatGPT performance on more complex exam questions and its potential to support learners in different contexts. As technology continues to evo
    
[^37]: 设计用户角色感知的对话代理进行有趣的对话：$\textit{WHAT}$, $\textit{WHEN}$, and $\textit{HOW}$ to Ground

    $\textit{WHAT}$, $\textit{WHEN}$, and $\textit{HOW}$ to Ground: Designing User Persona-Aware Conversational Agents for Engaging Dialogue. (arXiv:2306.03361v1 [cs.CL])

    [http://arxiv.org/abs/2306.03361](http://arxiv.org/abs/2306.03361)

    本文提出了一种针对商业环境的、能够平衡对话流畅性和趋向于理解对话系统的个性化开放领域对话系统方法，通过加权数据集混合、负角色信息增强方法，以及设计个性化对话数据集，解决了 $\textit{WHAT}$、$\textit{WHEN}$和$\textit{HOW}$ 等问题，同时提高了对话系统响应的可控性和解释性。

    

    本文提出了一种建立个性化开放领域对话系统以解决商业设置中涉及个性化对话响应与非正式响应交替的$\textit{WWH}$（$\textit{WHAT}$、$\textit{WHEN}$和$\textit{HOW}$）问题的方法。所提出的方法涉及加权数据集混合、负角色信息增强方法以及设计个性化对话数据集，以应对个性化、开放领域对话系统中$\textit{WWH}$的挑战。本文有效地平衡了对话流畅性和趋向于理解对话系统，同时还引入了响应类型标签来提高可控性和解释性。这些方法的组合导致了更加流畅的对话，证明了基于主观人类评估和客观评估的实验结果。

    This paper presents a method for building a personalized open-domain dialogue system to address the $\textit{WWH}$ ($\textit{WHAT}$, $\textit{WHEN}$, and $\textit{HOW}$) problem for natural response generation in a commercial setting, where personalized dialogue responses are heavily interleaved with casual response turns. The proposed approach involves weighted dataset blending, negative persona information augmentation methods, and the design of personalized conversation datasets to address the challenges of $\textit{WWH}$ in personalized, open-domain dialogue systems. Our work effectively balances dialogue fluency and tendency to ground, while also introducing a response-type label to improve the controllability and explainability of the grounded responses. The combination of these methods leads to more fluent conversations, as evidenced by subjective human evaluations as well as objective evaluations.
    
[^38]: OpenPI-C：开放词汇状态跟踪的更好基准和更强基础

    OpenPI-C: A Better Benchmark and Stronger Baseline for Open-Vocabulary State Tracking. (arXiv:2306.00887v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.00887](http://arxiv.org/abs/2306.00887)

    本文提出了一个更干净的OpenPI-C数据集和一个基于聚类的评估指标，并通过增强模型的时间依赖性和实体感知能力来提高开放词汇状态跟踪的性能。

    

    开放词汇状态跟踪是一种在不限制状态空间和实体空间的情况下跟踪实体状态变化的更实用的状态跟踪方法。目前，OpenPI是唯一为开放词汇状态跟踪注释的数据集。然而，我们发现数据集质量和评估指标存在问题。针对数据集，我们分别在程序级别、步骤级别和状态变化级别上分类了3种问题，并利用多轮人工判断构建了干净的OpenPI-C数据集。针对评估指标，我们提出了一种基于聚类的指标，以修复原始指标对重复的偏好。在模型方面，我们通过恢复状态跟踪的两个关键属性，即时间依赖性和实体感知能力，增强了seq2seq生成基线模型。在执行操作后，世界状态从根本上依赖于先前状态。我们通过动态记忆库对这种依赖关系进行建模，并允许模型注意到实体。

    Open-vocabulary state tracking is a more practical version of state tracking that aims to track state changes of entities throughout a process without restricting the state space and entity space. OpenPI is to date the only dataset annotated for open-vocabulary state tracking. However, we identify issues with the dataset quality and evaluation metric. For the dataset, we categorize 3 types of problems on the procedure level, step level and state change level respectively, and build a clean dataset OpenPI-C using multiple rounds of human judgment. For the evaluation metric, we propose a cluster-based metric to fix the original metric's preference for repetition.  Model-wise, we enhance the seq2seq generation baseline by reinstating two key properties for state tracking: temporal dependency and entity awareness. The state of the world after an action is inherently dependent on the previous state. We model this dependency through a dynamic memory bank and allow the model to attend to the 
    
[^39]: 控制学习效应以降低文本分类器中的误导性相关性

    Controlling Learned Effects to Reduce Spurious Correlations in Text Classifiers. (arXiv:2305.16863v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.16863](http://arxiv.org/abs/2305.16863)

    该论文提出了一种自动化的增强算法，以适当改变新增输入的标签，从而最小化误导性相关性，并提高了少数群体的准确性，同时保持了总体准确性。

    

    针对NLP分类器学习训练特征和目标标签之间误导性相关性的问题，一种常见的方法是使模型的预测对这些特征具有不变性。然而，当这些特征对目标标签有非零因果效应并且对预测很重要时，这种方法可能会产生反作用。因此，我们使用因果推断文献中的方法，提出了一种算法，将学习到的特征对模型预测的效应规范化为特征对标签的估计效应。这导致了一种自动化的增强方法，利用特征的估计效应适当地改变新增的输入的标签。在毒性和IMDB评论数据集上，所提出的算法最小化了误导性相关性，并提高了少数群体（即打破误导性相关性的样本）的准确性，同时也提高了总体准确性。

    To address the problem of NLP classifiers learning spurious correlations between training features and target labels, a common approach is to make the model's predictions invariant to these features. However, this can be counter-productive when the features have a non-zero causal effect on the target label and thus are important for prediction. Therefore, using methods from the causal inference literature, we propose an algorithm to regularize the learnt effect of the features on the model's prediction to the estimated effect of feature on label. This results in an automated augmentation method that leverages the estimated effect of a feature to appropriately change the labels for new augmented inputs. On toxicity and IMDB review datasets, the proposed algorithm minimises spurious correlations and improves the minority group (i.e., samples breaking spurious correlations) accuracy, while also improving the total accuracy compared to standard training.
    
[^40]: ConvXAI：通过对话提供异构的AI解释，支持人机科技写作

    ConvXAI: Delivering Heterogeneous AI Explanations via Conversations to Support Human-AI Scientific Writing. (arXiv:2305.09770v1 [cs.HC])

    [http://arxiv.org/abs/2305.09770](http://arxiv.org/abs/2305.09770)

    ConvXAI是一个基于对话的XAI系统，它集成了多种XAI类型，并将实际用户需求嵌入设计中，以提高实用性。

    

    尽管已经提出了各种各样的人工智能解释（XAI）方法来解释AI系统，但目前的方法是否对人类实用仍存在不一致的发现。为了改善XAI方法的实用性，一系列研究确定了现实世界中多样化和动态的用户需求与现有XAI方法之间的差距。虽然之前的研究设想将多种XAI方法集成到通用XAI界面（例如，基于对话或GUI的XAI系统）中以减轻这些差距，但缺少针对这些系统如何设计以满足实际用户需求的研究。在本研究中，我们提出了ConvXAI，这是一个基于对话的XAI系统，它结合了多种XAI类型，并赋予用户通过通用的XAI对话界面提出各种XAI问题的能力。特别地，我们创新地将实际用户需求（即，基于格式研究的四个原则）嵌入ConvXAI设计中，以提高实用性。

    While various AI explanation (XAI) methods have been proposed to interpret AI systems, whether the state-of-the-art XAI methods are practically useful for humans remains inconsistent findings. To improve the usefulness of XAI methods, a line of studies identifies the gaps between the diverse and dynamic real-world user needs with the status quo of XAI methods. Although prior studies envision mitigating these gaps by integrating multiple XAI methods into the universal XAI interfaces (e.g., conversational or GUI-based XAI systems), there is a lack of work investigating how these systems should be designed to meet practical user needs. In this study, we present ConvXAI, a conversational XAI system that incorporates multiple XAI types, and empowers users to request a variety of XAI questions via a universal XAI dialogue interface. Particularly, we innovatively embed practical user needs (i.e., four principles grounding on the formative study) into ConvXAI design to improve practical useful
    
[^41]: 多模态情感分析：综述

    Multimodal Sentiment Analysis: A Survey. (arXiv:2305.07611v1 [cs.CL])

    [http://arxiv.org/abs/2305.07611](http://arxiv.org/abs/2305.07611)

    本综述介绍了多模态情感分析的定义、发展和挑战，讨论了最新的数据集和先进模型，并提出了有前途的研究方向和构建更好性能的建议。

    

    多模态情感分析已成为人工智能领域的重要研究领域。随着深度学习的最新进展，这项技术已经达到了新的高度。它在应用和研究方面具有巨大的潜力，因此成为了一个热门研究课题。本综述提供了多模态情感分析的定义、背景和发展概述。它还涵盖了最新的数据集和先进模型，强调了该技术的挑战和未来前景。最后，它展望了未来的研究方向。需要指出的是，本综述为有前途的研究方向和构建更好性能的多模态情感分析模型提供了建设性的建议，有助于该领域的研究者。

    Multimodal sentiment analysis has become an important research area in the field of artificial intelligence. With the latest advances in deep learning, this technology has reached new heights. It has great potential for both application and research, making it a popular research topic. This review provides an overview of the definition, background, and development of multimodal sentiment analysis. It also covers recent datasets and advanced models, emphasizing the challenges and future prospects of this technology. Finally, it looks ahead to future research directions. It should be noted that this review provides constructive suggestions for promising research directions and building better performing multimodal sentiment analysis models, which can help researchers in this field.
    
[^42]: 土木鹦鹉传奇(GPT)：利用及时工程克服GPT幻觉以在岩土工程中应用

    Geotechnical Parrot Tales (GPT): Overcoming GPT hallucinations with prompt engineering for geotechnical applications. (arXiv:2304.02138v1 [cs.CL])

    [http://arxiv.org/abs/2304.02138](http://arxiv.org/abs/2304.02138)

    本文探讨了如何利用GPT在岩土工程应用中的全部潜力，着重讨论及时工程的重要性，并开发了一个统一的自然语言接口，用于处理复杂的岩土工程任务和数据分析。

    

    大型语言模型（LLM）的普及，如OpenAI的ChatGPT，可能会彻底改变包括岩土工程在内的各个行业。 但是，GPT模型有时会生成听起来很有道理但错误的输出，导致幻觉产生。 本文讨论了在缓解这些风险和利用GPT在岩土工程应用中的全部潜力方面，及时工程的重要性。 我们探讨了与LLM相关的挑战和陷阱，并强调了上下文在确保准确和有价值的响应方面的作用。 此外，我们还研究了特定于上下文的搜索引擎的开发以及LLM成为复杂任务（例如数据分析和设计）的自然界面的潜力。 我们还开发了一个统一的自然语言接口，用于处理复杂的岩土工程任务和数据分析。 通过将GPT集成到岩土工程工作流中，专业人员可以简化他们的工作并发展可持续性。

    The widespread adoption of large language models (LLMs), such as OpenAI's ChatGPT, could revolutionized various industries, including geotechnical engineering. However, GPT models can sometimes generate plausible-sounding but false outputs, leading to hallucinations. In this article, we discuss the importance of prompt engineering in mitigating these risks and harnessing the full potential of GPT for geotechnical applications. We explore the challenges and pitfalls associated with LLMs and highlight the role of context in ensuring accurate and valuable responses. Furthermore, we examine the development of context-specific search engines and the potential of LLMs to become a natural interface for complex tasks, such as data analysis and design. We also develop a unified interface using natural language to handle complex geotechnical engineering tasks and data analysis. By integrating GPT into geotechnical engineering workflows, professionals can streamline their work and develop sustain
    
[^43]: PATCorrect：基于音素增强的非自回归变换器用于ASR错误修正

    PATCorrect: Non-autoregressive Phoneme-augmented Transformer for ASR Error Correction. (arXiv:2302.05040v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.05040](http://arxiv.org/abs/2302.05040)

    PATCorrect是一种基于音素增强的非自回归变换器，利用文本和音素模态的表示来最大限度地降低ASR系统中的单词错误率，并在低延迟需求的实际生产系统中表现出鲁棒性。

    

    自动语音识别(ASR)系统产生的语音到文本错误会对下游模型造成负面影响。最近，已经开发了错误修正模型作为后处理文本编辑方法，以优化ASR输出。然而，目前尚未对符合工业级生产系统低延迟需求的高效模型进行充分研究。我们提出了PATCorrect这一新型非自回归(NAR)方法，基于多模态融合，利用文本和音素模态的表示，以降低单词错误率(WER)，并在不同质量的输入转录情况下表现出鲁棒性。我们证明PATCorrect在英语语料上表现优于最先进的NAR方法，与仅使用文本模态的方法相比，总体WER降低了11.62%，而其他方法的WER降低率为9.46%。此外，其推理延迟在毫秒级别，非常适合需要低延迟系统的使用。

    Speech-to-text errors made by automatic speech recognition (ASR) systems negatively impact downstream models. Error correction models as a post-processing text editing method have been recently developed for refining the ASR outputs. However, efficient models that meet the low latency requirements of industrial grade production systems have not been well studied. We propose PATCorrect-a novel non-autoregressive (NAR) approach based on multi-modal fusion leveraging representations from both text and phoneme modalities, to reduce word error rate (WER) and perform robustly with varying input transcription quality. We demonstrate that PATCorrect consistently outperforms state-of-the-art NAR method on English corpus across different upstream ASR systems, with an overall 11.62% WER reduction (WERR) compared to 9.46% WERR achieved by other methods using text only modality. Besides, its inference latency is at tens of milliseconds, making it ideal for systems with low latency requirements.
    
[^44]: 基于推特的选举模型在2021年墨西哥立法选举中的设计与分析

    Design and analysis of tweet-based election models for the 2021 Mexican legislative election. (arXiv:2301.00626v2 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2301.00626](http://arxiv.org/abs/2301.00626)

    研究使用推特数据进行选举结果预测，结果表明带有地理属性的数据模型比传统民意调查方法更能准确预测选举结果。

    

    利用在线社交媒体模拟和预测真实人类行为是政治、政府、学术界和产业界感兴趣的积极尝试。自2006年创建以来，Twitter一直被提出作为一个潜在的实验室，可用于衡量和预测社会行为。本研究分析了2021年墨西哥立法选举的用户基础，使用了一组在选举日前六个月内涉及选举的1500万条推文的数据集。我们探讨了不同的选举模型，将政治偏好分配给执政党或反对派。我们发现，使用带有地理属性的数据的模型比传统的民意调查方法更能准确地确定选举结果。这些结果证明，在线公共数据的分析可以优于传统的民意调查方法来预测选举结果。

    Modelling and forecasting real-life human behaviour using online social media is an active endeavour of interest in politics, government, academia, and industry. Since its creation in 2006, Twitter has been proposed as a potential laboratory that could be used to gauge and predict social behaviour. During the last decade, the user base of Twitter has been growing and becoming more representative of the general population. Here we analyse this user base in the context of the 2021 Mexican Legislative Election. To do so, we use a dataset of 15 million election-related tweets in the six months preceding election day. We explore different election models that assign political preference to either the ruling parties or the opposition. We find that models using data with geographical attributes determine the results of the election with better precision and accuracy than conventional polling methods. These results demonstrate that analysis of public online data can outperform conventional pol
    
[^45]: VRDU：面向视觉丰富的文档理解的基准测试

    VRDU: A Benchmark for Visually-rich Document Understanding. (arXiv:2211.15421v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.15421](http://arxiv.org/abs/2211.15421)

    本研究提出了一个名为VRDU的基准测试，以更全面地反映实际文档的复杂性，其中包含具有挑战性的丰富模式、复杂模板和多样的布局。该基准测试可用于评估文档中提取结构化数据的模型。

    

    理解丰富视觉化业务文档以提取结构化数据和自动化业务工作流程在学术界和工业界都受到关注。虽然最近的多模式语言模型取得了令人印象深刻的成果，但我们发现现有的基准测试不反映工业中实际文档的复杂性。在这项工作中，我们确定了更全面的基准测试的必要条件，并提出了一个称为Visually Rich Document Understanding (VRDU)的基准测试。VRDU包含两个数据集，代表了多种挑战：丰富的模式，包括各种数据类型以及分层实体; 复杂的模板，包括表格和多列布局; 以及单个文档类型中不同布局（模板）的多样性。我们设计了少样本和常规实验设置，以及一个精心设计的匹配算法来评估提取结果。我们报告了强基线的性能，并提供了三个观察结果：(1)通用n的推广。

    Understanding visually-rich business documents to extract structured data and automate business workflows has been receiving attention both in academia and industry. Although recent multi-modal language models have achieved impressive results, we find that existing benchmarks do not reflect the complexity of real documents seen in industry. In this work, we identify the desiderata for a more comprehensive benchmark and propose one we call Visually Rich Document Understanding (VRDU). VRDU contains two datasets that represent several challenges: rich schema including diverse data types as well as hierarchical entities, complex templates including tables and multi-column layouts, and diversity of different layouts (templates) within a single document type. We design few-shot and conventional experiment settings along with a carefully designed matching algorithm to evaluate extraction results. We report the performance of strong baselines and offer three observations: (1) generalizing to n
    
[^46]: Peekaboo：文本到图像扩散模型是零-shot细分器

    Peekaboo: Text to Image Diffusion Models are Zero-Shot Segmentors. (arXiv:2211.13224v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.13224](http://arxiv.org/abs/2211.13224)

    本文介绍了一种名为Peekaboo的技术，可以用于使用现成的文本到图像扩散模型进行无监督语义细分并基础，而无需任何重新培训。这项技术的推理时间优化过程可以在与自然语言提示相关联的情况下生成分割掩模。

    

    最近，文本到图像扩散模型展示了在从自然语言提示中创建逼真图像方面的显着能力。然而，鲜有研究探讨如何利用这些模型进行语义定位或基础。在这项工作中，我们探讨了一个现成的文本到图像扩散模型，它没有接触到本地化信息的训练如何在无需细分特定重新训练的情况下，以自然语言提示为条件建立各种语义短语。我们引入了一个推理时间优化过程，能够在与自然语言提示相关联的情况下生成分割掩模。我们的提议——Peekaboo，是一种首款无训练开放词汇无监督语义接地技术，利用扩散模型。我们在Pascal VOC数据集上对Peekaboo进行了评估，用于无监督语义细分，以及在RefCOCO数据集上对其进行了评估，用于引用细分，显示具有有希望的结果的竞争优势。我们还展示了如何使用Peekaboo通过条件自然语言提示来生成带透明背景的图像。

    Recently, text-to-image diffusion models have shown remarkable capabilities in creating realistic images from natural language prompts. However, few works have explored using these models for semantic localization or grounding. In this work, we explore how an off-the-shelf text-to-image diffusion model, trained without exposure to localization information, can ground various semantic phrases without segmentation-specific re-training. We introduce an inference time optimization process capable of generating segmentation masks conditioned on natural language prompts. Our proposal, Peekaboo, is a first-of-its-kind zero-shot, open-vocabulary, unsupervised semantic grounding technique leveraging diffusion models without any training. We evaluate Peekaboo on the Pascal VOC dataset for unsupervised semantic segmentation and the RefCOCO dataset for referring segmentation, showing results competitive with promising results. We also demonstrate how Peekaboo can be used to generate images with tr
    

