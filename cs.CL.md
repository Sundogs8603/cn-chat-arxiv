# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Parallel Neurosymbolic Integration with Concordia.](http://arxiv.org/abs/2306.00480) | 康科迪亚框架是一个支持各种概率理论，克服了现有技术的限制的并行的神经符号结构，成功应用于集合活动检测、实体链接和推荐任务，提高了最新准确性。 |
| [^2] | [Make Your Pre-trained Model Reversible: From Parameter to Memory Efficient Fine-Tuning.](http://arxiv.org/abs/2306.00477) | 本研究尝试实现在预训练语言模型中运用可逆模型实现高效的微调，并发现在初始化微调时保留PLM的起点非常重要。 |
| [^3] | [A big data approach towards sarcasm detection in Russian.](http://arxiv.org/abs/2306.00445) | 本文介绍了一种针对俄语文本的大数据方法，旨在检测文本中的讽刺。作者提出了一组可用于屈折和文本合成的算法，并在一个公开可用的网络服务中实现。对这些算法的性能进行了测试和比较，同时用于估计俄语不同词性的形态变异性和复杂性。 |
| [^4] | [Responsibility Perspective Transfer for Italian Femicide News.](http://arxiv.org/abs/2306.00437) | 本文介绍了一项新任务，旨在通过自动修改性别暴力描述来改变读者对于施暴者责任程度的理解。我们使用了多种方法进行句子重写，并采用问卷研究和自动评价指标对模型进行评估。 |
| [^5] | [How Many Answers Should I Give? An Empirical Study of Multi-Answer Reading Comprehension.](http://arxiv.org/abs/2306.00435) | 研究设计分类法来分类常见多答案阅读理解实例，分析模型范例处理不同类型多答案实例的效果，发现某些模型范例更擅长捕获问题关键信息，而其他范例则更适合建立问题和上下文之间的关系。生成模型整合不同范例的优势，具有前景。 |
| [^6] | [Divide, Conquer, and Combine: Mixture of Semantic-Independent Experts for Zero-Shot Dialogue State Tracking.](http://arxiv.org/abs/2306.00434) | 本文提出了一种通过“分解、征服和组合”解耦语义的方法，利用专家混合机制的性能和鲁棒性，从而显著并一致地提高了面向零样本对话状态追踪的性能。 |
| [^7] | [End-to-end Knowledge Retrieval with Multi-modal Queries.](http://arxiv.org/abs/2306.00424) | 该论文提出了一个新的多模态检索任务，引入了一个名为“ReViz”的检索模型，可以直接处理文本和图像输入以实现端到端的知识检索，同时提出了一种有效的预训练任务，并在两个数据集上展示了优越的检索性能。 |
| [^8] | [Uncertainty-Aware Unlikelihood Learning Improves Generative Aspect Sentiment Quad Prediction.](http://arxiv.org/abs/2306.00418) | 本文提出了一种新的方法来控制标记级的生成、提高原始学习和减少错误，其中包括蒙特卡洛dropout、边缘非似然学习和最小化熵。在四个公共数据集上的广泛实验表明，该方法有效地提高了情感四元组预测的性能。 |
| [^9] | [Towards hate speech detection in low-resource languages: Comparing ASR to acoustic word embeddings on Wolof and Swahili.](http://arxiv.org/abs/2306.00410) | 本文研究了在低资源语言中进行仇恨言论检测的方法。在控制实验中，ASR模型表现更好，但在实际应用中，AWE模型表现更为鲁棒。 |
| [^10] | [BiSync: A Bilingual Editor for Synchronized Monolingual Texts.](http://arxiv.org/abs/2306.00400) | BiSync是一款双语写作助手，允许用户自由地使用两种语言撰写文本，同时保持两种单语文本同步，还包括其他功能，例如显示替代前缀翻译和释义，旨在促进撰写过程。 |
| [^11] | [Preference-grounded Token-level Guidance for Language Model Fine-tuning.](http://arxiv.org/abs/2306.00398) | 本论文通过设计一个交替训练过程，在序列级别偏好与标记级别训练指导之间进行迭代，并利用学习到的指导改进LM。实验证明该方法在多个文本生成任务中表现良好。 |
| [^12] | [Developing and Building Ontologies in Cyber Security.](http://arxiv.org/abs/2306.00377) | 通过比较不同本体论，该论文提供了有关网络安全本体论领域的未来方向。 |
| [^13] | [CFL: Causally Fair Language Models Through Token-level Attribute Controlled Generation.](http://arxiv.org/abs/2306.00374) | 本文提出了一种使用因果平均处理效应（ATE）分数和反事实增强方法的CFL体系架构，通过插入式方式对预训练的LM进行解毒，实现了因果公平的语言模型。此方法不会对模型困惑产生太大影响，还减轻了意外的偏置问题。 |
| [^14] | [Focused Prefix Tuning for Controllable Text Generation.](http://arxiv.org/abs/2306.00369) | 本文提出了针对可控文本生成的焦点前缀调整方法，实验结果表明在单属性控制任务中实现了更好的控制准确性和文本流畅度，在多属性控制任务中实现了与最先进方法相当的控制准确性，并保持了控制新属性而无需重新训练现有模型的灵活性。 |
| [^15] | [CAISA at SemEval-2023 Task 8: Counterfactual Data Augmentation for Mitigating Class Imbalance in Causal Claim Identification.](http://arxiv.org/abs/2306.00346) | 该论文提出了一种针对类别不平衡问题的新颖反事实数据增广方法，该方法通过动词替换进行，用于医学因果关系提取，并且与其他3种数据增广技术相比较，在少数类方面有显著提高。 |
| [^16] | [CapText: Large Language Model-based Caption Generation From Image Context and Description.](http://arxiv.org/abs/2306.00301) | 研究提出了一种基于大型语言模型的图像字幕生成方法，从文本描述和上下文中生成字幕，而不直接处理图像。在CIDEr指标上，优于当前最先进的图像文本对齐模型。 |
| [^17] | [Training-free Neural Architecture Search for RNNs and Transformers.](http://arxiv.org/abs/2306.00288) | 本文研究了适用于语言模型任务的循环神经网络和Transformer的无训练神经网络结构搜索算法，并开发了一个新的性能预测指标hidden covariance，可显著优化现有指标。 |
| [^18] | [AfriNames: Most ASR models "butcher" African Names.](http://arxiv.org/abs/2306.00253) | 该论文探讨了自动语音识别模型在处理非洲名字时的性能问题，并提出了多语言预训练和数据增强等策略，通过微调ASR模型在多个非洲口音上，显著减少了模型误差，相对WER提高了81.5％。 |
| [^19] | [From Pixels to UI Actions: Learning to Follow Instructions via Graphical User Interfaces.](http://arxiv.org/abs/2306.00245) | 本文提出了一种基于像素级别的预训练方法，建立了一种模拟人类概念界面和混合动作空间的代理，实现了在GUI指令遵循任务的MiniWob++基准测试中超越人类工作者的目标。 |
| [^20] | [Using Visual Cropping to Enhance Fine-Detail Question Answering of BLIP-Family Models.](http://arxiv.org/abs/2306.00228) | 本文研究如何通过使用视觉裁剪来提高BLIP模型在细节问题上的表现能力。 |
| [^21] | [Diffusion Brush: A Latent Diffusion Model-based Editing Tool for AI-generated Images.](http://arxiv.org/abs/2306.00219) | 本论文提出了一种名为扩散画笔的基于潜在扩散模型的AI图像微调工具，可以有效地根据目标区域修改AI合成图像并保留原始上下文。与其他最先进的图像修复技术进行比较，该方法在用户研究中表现出更好的可用性和有效性。 |
| [^22] | [FEED PETs: Further Experimentation and Expansion on the Disambiguation of Potentially Euphemistic Terms.](http://arxiv.org/abs/2306.00217) | 本研究扩展了潜在委婉语消歧任务，首先注释了模糊性对性能的影响，并在三种不同的语言中提供了新颖的委婉语语料库。通过使用多语言Transformer模型，该研究建立了初步的结果，为未来的工作提供了基础。 |
| [^23] | [Strategies for improving low resource speech to text translation relying on pre-trained ASR models.](http://arxiv.org/abs/2306.00208) | 本论文介绍了针对低资源语音转文本翻译的改进策略，利用编码器-解码器框架以及多语种自动语音识别系统初步提升性能，在训练和解码时使用CTC作为额外的目标进一步优化结果，在Tamasheq-法语数据上达到了7.3的BLEU得分。 |
| [^24] | [An Invariant Learning Characterization of Controlled Text Generation.](http://arxiv.org/abs/2306.00198) | 本文提出了一种控制文本生成的不变学习方法，解决了生成的文本分布转移的问题。 |
| [^25] | [Factually Consistent Summarization via Reinforcement Learning with Textual Entailment Feedback.](http://arxiv.org/abs/2306.00186) | 本研究使用带有文本蕴含奖励的强化学习来实现抽象摘要系统的事实一致性，从而提高了生成的摘要的忠实度、明显性和简洁性。 |
| [^26] | [Contrastive Hierarchical Discourse Graph for Scientific Document Summarization.](http://arxiv.org/abs/2306.00177) | 本文提出了CHANGES，一种对比分层图神经网络，用于提取科学论文的摘要。该模型能够使用分层话语图和图对比学习模块，学习有效的句子表示，并在实验中证明了其有效性和在建模科学论文时捕捉分层结构信息的重要性。 |
| [^27] | [Automated Annotation with Generative AI Requires Validation.](http://arxiv.org/abs/2306.00176) | 本文探讨了利用生成式大型语言模型进行文本注释的自动化流程，强调必须针对人类生成的标签验证它们的性能，验证结果表明LLM的性能很有前途，但高度依赖于数据集和注释任务类型。 |
| [^28] | [Measuring the Robustness of Natural Language Processing Models to Domain Shifts.](http://arxiv.org/abs/2306.00168) | 本文探讨了自然领域转移设置下微调和小样本学习模型的DR挑战，引入了一个DR基准，提出了DR挑战的两个视角：源域降低（SD）和目标域降低（TD），并发现两者之一通常是正值，强调了评估DR挑战的两个视角的重要性。 |
| [^29] | [A Sequence-to-Sequence&Set Model for Text-to-Table Generation.](http://arxiv.org/abs/2306.00137) | 这篇论文提出了一种序列、序列和集合模型，以解决文本到表格生成任务中的两个常见问题。与现有方法相比，该模型更具灵活性和实用性，可产生更准确的结果。 |
| [^30] | [Pre-Trained Language-Meaning Models for Multilingual Parsing and Generation.](http://arxiv.org/abs/2306.00124) | 本文提出了一种基于DRS的多语言预训练语言-语义模型，可以同时处理自然语言文本和意义表示，并通过跨语言迁移学习来提高非英语任务的性能。实验表明，该模型在多语言DRS解析和DRS到文本生成任务上表现最佳，且可以大大降低多语言语义注释的成本。 |
| [^31] | [Multilingual Multi-Figurative Language Detection.](http://arxiv.org/abs/2306.00121) | 该论文提出了多语言多比喻语言建模的框架，并提供了基准句子级比喻语言检测。通过基于模板的提示学习，统一了跨多个修辞手法和语言相关的多个检测任务，实验结果表明其比强大的基线模型更加优秀。 |
| [^32] | [MuseCoco: Generating Symbolic Music from Text.](http://arxiv.org/abs/2306.00110) | MuseCoco是一种从文本描述中生成符号音乐的系统，具备高效和灵活等特点，为音乐家提供了更好的音乐生成方式。 |
| [^33] | [MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training.](http://arxiv.org/abs/2306.00107) | 提出了一个带有大规模自监督训练的音乐理解模型MERT，利用了教师模型并采用了一种优于传统的语音和音频方法的组合方式。 |
| [^34] | [ManagerTower: Aggregating the Insights of Uni-Modal Experts for Vision-Language Representation Learning.](http://arxiv.org/abs/2306.00103) | 提出了ManagerTower，一种新型的VL模型体系结构，可以集合并组合不同级别的预先训练的单模态专家的见解，并可以自适应地聚合单模态语义知识以促进更全面的跨模态对齐和融合。仅使用4M VLP数据，ManagerTower在各种下游VL任务中都取得了更好的性能，尤其是在VQAv2测试标准下达到了79.15%的准确率，在Flickr30K上的IR@1为86.56% TR@1为95.64%。 |
| [^35] | [Self-Verification Improves Few-Shot Clinical Information Extraction.](http://arxiv.org/abs/2306.00024) | 本文探索了一种利用自我验证的通用缓解框架，该框架利用语言模型为其自我提取提供权威性并检查其自己的输出。在临床信息提取任务中，该方法能够显著提高各种LLMs的准确性，并展示了极好的可解释性和认知增强效果。 |
| [^36] | [Explaining Hate Speech Classification with Model Agnostic Methods.](http://arxiv.org/abs/2306.00021) | 本文旨在解释仇恨言论分类，采用双向变形器模型BERT进行预测，并提供后验的模型无关和代理可解释性方法，以支持模型的解释性并防止模型偏差。 |
| [^37] | [GPT4GEO: How a Language Model Sees the World's Geography.](http://arxiv.org/abs/2306.00020) | 研究调查了GPT-4的地理知识水平，并探讨其在地理数据分析等领域的应用潜力。 |
| [^38] | [Utilization of Multinomial Naive Bayes Algorithm and Term Frequency Inverse Document Frequency (TF-IDF Vectorizer) in Checking the Credibility of News Tweet in the Philippines.](http://arxiv.org/abs/2306.00018) | 本文利用多项式朴素贝叶斯算法和TF-IDF向量化器检查菲律宾新闻推文的可信度，在训练和预测中表现良好。建议进一步改进语料库收集，并使用集成机器学习来加强预测。 |
| [^39] | [Towards Explainable and Language-Agnostic LLMs: Symbolic Reverse Engineering of Language at Scale.](http://arxiv.org/abs/2306.00017) | 本文提出结合符号表示和自下而上的逆向工程的方法，解决大规模语言模型在真正语言理解上的局限性，实现可解释的、语言无关的LLMs。 |
| [^40] | [PreQuant: A Task-agnostic Quantization Approach for Pre-trained Language Models.](http://arxiv.org/abs/2306.00014) | 本文提出了一种新颖的“量化前微调”框架 PreQuant，可用于预训练语言模型的通用量化，有效降低了模型的复杂度和使用成本。 |
| [^41] | [Machine Learning Approach for Cancer Entities Association and Classification.](http://arxiv.org/abs/2306.00013) | 本研究利用命名实体识别和文本分类的机器学习方法自动从大量生物医学文献中提取癌症相关实体和实体间关系，以帮助推进癌症研究进展。 |
| [^42] | [Brainformers: Trading Simplicity for Efficiency.](http://arxiv.org/abs/2306.00008) | Brainformers 是一个新的深度神经网络模型，它通过使用多样层级的结构完善了 Transformer 的设计缺陷，具有更高效的训练收敛和更快的步骤时间，表现出更优秀的性能。 |
| [^43] | [Datasets for Portuguese Legal Semantic Textual Similarity: Comparing weak supervision and an annotation process approaches.](http://arxiv.org/abs/2306.00007) | 本文提供了四个法律领域的数据集，其中两个未标记，另外两个使用启发式标签进行了标记，旨在用于文本语义相似性任务。研究比较了弱监督和传统注释过程方法，表明弱监督可以达到与传统方法相当的性能。 |
| [^44] | [A Two-Stage Decoder for Efficient ICD Coding.](http://arxiv.org/abs/2306.00005) | 本文提出了一个基于两阶段解码机制的模型，利用代码的层次属性将预测分解为两个步骤，实现对ICD代码的高效预测。 |
| [^45] | [Decision-Oriented Dialogue for Human-AI Collaboration.](http://arxiv.org/abs/2305.20076) | 该论文探讨了一类以决策为导向的人机对话任务，以及在会议论文审稿人分配、城市多步行程规划和旅行计划协商等场景中，人工智能助手和用户不同的能力如何结合以达到最佳决策。论文通过构建对话环境并进行人机对话收集数据，发现当前人工智能助手在此类任务中的局限性。 |
| [^46] | [Beam Tree Recursive Cells.](http://arxiv.org/abs/2305.19999) | 本论文提出了一种支持反向传播的递归神经网络框架——束搜索递归单元（BT-Cell），用于扩展递归神经网络，实现对潜在结构的感知；此外，我们提出了一种放松束搜索中硬前k算子的方法，以实现更好的梯度信号传递。在评估中发现，BT-Cell在合成和实际数据的多个具有结构敏感性的任务中表现优异。 |
| [^47] | [DC CoMix TTS: An End-to-End Expressive TTS with Discrete Code Collaborated with Mixer.](http://arxiv.org/abs/2305.19567) | 本文提出了一种基于离散码和混合器相协作的端到端表现力TTS，它采用新的输入表示和简单的架构来实现改进的韵律建模，证明了其有效性。 |
| [^48] | [Representation Of Lexical Stylistic Features In Language Models' Embedding Space.](http://arxiv.org/abs/2305.18657) | 本文展示了预训练语言模型嵌入空间中的词汇文体特征，并提出了仅使用少量种子对每个文体概念得出向量表示的方法。研究发现静态嵌入空间更准确地编码了单词和短语的特征，而上下文化的语言模型则在句子级别上表现更好。 |
| [^49] | [Conformal Prediction with Large Language Models for Multi-Choice Question Answering.](http://arxiv.org/abs/2305.18404) | 本研究探讨了如何利用符合性预测技术，在多项选择题回答任务中为语言模型提供不确定性量化。我们发现符合性预测的不确定性估计与预测准确性密切相关。 |
| [^50] | [Neural Task Synthesis for Visual Programming.](http://arxiv.org/abs/2305.18342) | 该论文提出了一种基于神经符号技术的可视化编程任务合成方法NeurTaskSyn。该方法能够针对规范中给出的解决方案代码所需要的编程概念和对可视化任务的限制，自动生成编程任务。 |
| [^51] | [Translatotron 3: Speech to Speech Translation with Monolingual Data.](http://arxiv.org/abs/2305.17547) | Translatotron 3提出了一种新方法，使用单语数据进行语音到语音翻译，无需配对的数据或专业建模，展示了保留语言/非语言信息的能力。 |
| [^52] | [FACTUAL: A Benchmark for Faithful and Consistent Textual Scene Graph Parsing.](http://arxiv.org/abs/2305.17497) | 研究提出了一个新数据集FACTUAL-MR，该数据集用于准确文本场景图解析，这样可以避免现有解析器出现的准确性和一致性问题，该方法在各种视觉语言任务中具有重要意义。 |
| [^53] | [Heterogeneous Value Evaluation for Large Language Models.](http://arxiv.org/abs/2305.17147) | 本文提出了一种自动对齐评估方法A2EHV，采用异质价值系统，并基于价值合理性和社会价值定向框架评估代理人行为的社会偏好，结果表明比传统对齐方法更合理。 |
| [^54] | [Ghost in the Minecraft: Generally Capable Agents for Open-World Enviroments via Large Language Models with Text-based Knowledge and Memory.](http://arxiv.org/abs/2305.17144) | 本文提出了Ghost in the Minecraft (GITM)框架，利用大型语言模型与基于文本的知识和记忆，创造了一种在Minecraft中具备通用能力的智能体，可在以文本为基础的复杂编程环境中熟练导航。 |
| [^55] | [Emotion Experiencer Recognition as a Prerequisite for Experiencer-Specific Emotion Analysis.](http://arxiv.org/abs/2305.16731) | 本文提出了一种用于检测情感体验者并为其分配情感的自动方法，并进行了相关的实验。该方法的实现具有挑战性，但展示了在文本中检测情感体验者的可行性。 |
| [^56] | [NLP Reproducibility For All: Understanding Experiences of Beginners.](http://arxiv.org/abs/2305.16579) | 通过对93名NLP初学者的调查，发现研究作者提供完整文档、更好的代码实践和更易于获取的数据文件是初学者成功复现最近NLP论文结果的关键，建议NLP研究人员注重这些方面，更好地支持初学者。 |
| [^57] | [Neural Natural Language Processing for Long Texts: A Survey of the State-of-the-Art.](http://arxiv.org/abs/2305.16259) | 本文简要概述了长文本的神经自然语言处理的现状，主要包括文档分类和摘要，涵盖了情感分析，同时还探讨了长文本NLP的主要挑战、问题和解决方案。 |
| [^58] | [LFTK: Handcrafted Features in Computational Linguistics.](http://arxiv.org/abs/2305.15878) | 该论文收集和分类了超过220个受欢迎的手工语言特征，设计了一个多语言的手工语言特征提取系统，以系统性的可扩展方式实现，并在几个任务特定的数据集上进行了相关性分析研究。 |
| [^59] | [Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective.](http://arxiv.org/abs/2305.15408) | 本文从理论层面探究了带有“思维链”提示的大型语言模型在解决基本数学和决策问题中的能力，发现自回归Transformer大小恒定即可解决任务，揭示了“思维链”提示的背后机制。 |
| [^60] | [LMs with a Voice: Spoken Language Modeling beyond Speech Tokens.](http://arxiv.org/abs/2305.15255) | SPECTRON是一个新颖的语音延续模型，通过利用预训练的语言模型和语音编码器进行端到端的训练来生成文本和语音输出，在语义内容和讲话者保护方面超越了现有的口语语言模型。 |
| [^61] | [BeamSearchQA: Large Language Models are Strong Zero-Shot QA Solver.](http://arxiv.org/abs/2305.14766) | BeamSearchQA利用大型语言模型进行迭代式生成问题，以捕捉隐含知识并优化问答过程，在NQ和WebQ测试集上分别达到了71.7％和46.7％的F1分数，显着优于现有的最先进方法。 |
| [^62] | [Large Language Models are Frame-level Directors for Zero-shot Text-to-Video Generation.](http://arxiv.org/abs/2305.14330) | 本文引入了一个新的框架——DirecT2V，利用大型语言模型作为导演，从一个抽象的用户提示中生成零样本文本到视频生成的连贯且连贯的视频。该框架使用LLM导演将用户输入分为每一帧的提示，通过值映射和双softmax过滤器来保持时间一致和防止对象折叠。 |
| [^63] | [A Pilot Study on Dialogue-Level Dependency Parsing for Chinese.](http://arxiv.org/abs/2305.12441) | 该论文研究了中文对话级依存句法分析的初步工作，在新构建了的高质量人工标注语料库上，通过零样本和小样本的数据学习，采用了基于信号的将见到的句法依存转换成元素话语单位之间的未见依存的方法，通过单视角和多视角的数据选择来访问可靠的伪标记实例，取得良好的实验结果。 |
| [^64] | [On the Off-Target Problem of Zero-Shot Multilingual Neural Machine Translation.](http://arxiv.org/abs/2305.10930) | 零样本多语言神经机器翻译容易出现“离谱问题”，本文提出的简单且有效的算法LAVS可以通过增加语言之间的KL分歧显著降低这个问题。 |
| [^65] | [Deep Learning Methods for Extracting Metaphorical Names of Flowers and Plants.](http://arxiv.org/abs/2305.10833) | 本研究使用深度学习模型识别对话中基于隐喻的花和植物名称，鉴别模型表现优于GPT-3.5，最好的表现器在任务中报告了92.2349％的F1分数。 |
| [^66] | [ChatGPT as a Text Simplification Tool to Remove Bias.](http://arxiv.org/abs/2305.06166) | ChatGPT作为文本简化工具可以去除语言模型在训练过程中对某些特定群体的偏见，减少模型的歧视性。（注：ChatGPT是一种基于Transformer的自然语言处理模型） |
| [^67] | [How to Unleash the Power of Large Language Models for Few-shot Relation Extraction?.](http://arxiv.org/abs/2305.01555) | 本文通过使用GPT-3.5模型在少样本关系抽取中，实现在四个不同数据集上的新的最优性能，并提出了与任务相关的指导说明和约束模式下的数据生成方法。 |
| [^68] | [Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation.](http://arxiv.org/abs/2305.00955) | 本文调查研究了利用人类反馈改进自然语言生成方面的最近研究，包括对反馈的全面形式化、反馈的格式和目的的描述，和提出使用反馈的两种方法。我们还讨论了用于人类反馈数据收集的现有数据集，和相关的担忧。 |
| [^69] | [Exploring Challenges of Deploying BERT-based NLP Models in Resource-Constrained Embedded Devices.](http://arxiv.org/abs/2304.11520) | 本文探究了在资源受限的嵌入式设备上部署基于BERT的NLP模型的挑战，并得出结论：虽然DistilBERT和TinyBERT等轻量级模型相对占用更少内存，但它们在复杂的NLP任务上表现较差；ResNet-based BERT模型可以在精度和资源效率之间取得良好的平衡，适合在嵌入式设备上部署。 |
| [^70] | [Emergent and Predictable Memorization in Large Language Models.](http://arxiv.org/abs/2304.11158) | 该论文的研究发现中间检查点比完全训练的模型更好地预测模型的记忆化行为，并且发现了大型语言模型中记忆化得分的分布规律。 |
| [^71] | [Towards an Understanding and Explanation for Mixed-Initiative Artificial Scientific Text Detection.](http://arxiv.org/abs/2304.05011) | 本论文通过定量实验明确了机器生成和人类撰写的科技论文之间的关键差异，并提出了一种混合智能工作流，旨在有效解决科技论文检测中存在的挑战。 |
| [^72] | [Query-Utterance Attention with Joint modeling for Query-Focused Meeting Summarization.](http://arxiv.org/abs/2303.04487) | 本文提出了一种基于查询-话语注意力和联合建模的查询感知框架，它使用密集检索模块计算话语级别与查询的相关性，并将标记级别的查询关联性和话语级别的查询关联性结合起来，实现生成一个更与查询相关的摘要。经过对两个基准数据集上的测试，表明该方法优于现有的QFMS模型。 |
| [^73] | [Almanac: Retrieval-Augmented Language Models for Clinical Medicine.](http://arxiv.org/abs/2303.01229) | Almanac是一个带有检索能力的大型语言模型框架，为临床医学的指南和治疗建议提供了事实性、完备性和安全性的增强。该模型有望成为临床决策过程中的有效工具。 |
| [^74] | [Large Language Models Are State-of-the-Art Evaluators of Translation Quality.](http://arxiv.org/abs/2302.14520) | 该论文介绍了一种基于GPT模型的翻译质量评估方法GEMBA，并展示了它在零-shot提示、多种模式下与WMT22度量共享任务的MQM人类标签相比取得了最先进的准确性，这为大型语言模型在翻译质量评估中的实用性提供了首次的证明。 |
| [^75] | [Multimodal Speech Recognition for Language-Guided Embodied Agents.](http://arxiv.org/abs/2302.14030) | 本文提出在语言引导的合身代理中使用多模态ASR模型来减少语音指令的转录错误，并通过考虑视觉上下文来提高转录结果。模型能够恢复多达30％的被屏蔽单词，并且训练基于文本的合身代理在遵循多模态ASR模型转录的指令下能够更高效地完成任务。 |
| [^76] | [Let's have a chat! A Conversation with ChatGPT: Technology, Applications, and Limitations.](http://arxiv.org/abs/2302.13817) | 本文讨论了聊天机器人的历史概述以及ChatGPT背后的技术，强调了它在医疗保健、教育和研究中的潜在应用，并指出了其隐私和道德方面的担忧以及当前版本的重要限制。 |
| [^77] | [ProsAudit, a prosodic benchmark for self-supervised speech models.](http://arxiv.org/abs/2302.12057) | ProsAudit是一个自监督语音模型韵律基准测试，由原型句法任务和词汇任务两部分组成。研究发现模型大小对表现有明显影响，词汇任务中母语模型表现优异，但非母语模型表现较差。 |
| [^78] | [Level Generation Through Large Language Models.](http://arxiv.org/abs/2302.05817) | 该研究探讨了使用大型语言模型(LLMs)生成Sokoban游戏关卡，并发现随着数据集大小的增加，LLMs的性能得到了很大的提高。未来工作的前景也被讨论了。 |
| [^79] | [Bag of Tricks for Training Data Extraction from Language Models.](http://arxiv.org/abs/2302.04460) | 本文总结了一些技巧用于改进语言模型训练数据提取，提出了在文本生成和文本排名中可以使用的技巧，实验证明这些技巧对于提高训练数据提取的效果非常重要。 |
| [^80] | [Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery.](http://arxiv.org/abs/2302.03668) | 该论文提出了一种基于梯度的离散优化方法，用于自动生成文本提示，进而控制现代生成模型的输出。该方法可以优化文本到图像和文本到文本的应用，为API用户提供了轻松生成、发现、混合和匹配图像概念的能力，同时自动发现硬提示可以有效地提高模型性能。 |
| [^81] | [Grounding Language Models to Images for Multimodal Inputs and Outputs.](http://arxiv.org/abs/2301.13823) | 该论文提出一种有效的方法，将仅处理文本的语言模型与图像进行联系，使其能够处理任意交错的图像和文本数据，并生成与检索图像交错的自由形式文本。该方法在环境相关的图像检索和多模态对话等任务中表现十分优异，是利用预训练语言模型解决视觉场景下交互问题的有效解决方案。 |
| [^82] | [Communication Drives the Emergence of Language Universals in Neural Agents: Evidence from the Word-order/Case-marking Trade-off.](http://arxiv.org/abs/2301.13083) | 本文研究了神经代理语言学习与通信框架，成功复制了语序/格标交换这一广泛存在的语言普遍规律，实现了更真实的语言演变模拟，并帮助我们更好地理解影响语言普遍规律的认知和社会因素。 |
| [^83] | [A Survey on In-context Learning.](http://arxiv.org/abs/2301.00234) | 本文调查和总结了上下文学习(ICL)的进展和挑战，ICL已成为自然语言处理(NLP)的新范式，探索ICL以评估和推广大型语言模型(LLM)的能力已成为一种新趋势。本文提出了ICL的正式定义，并总结了高级技术，最后讨论了ICL的挑战以及进一步研究的潜在方向。 |
| [^84] | [DISCO: Distilling Phrasal Counterfactuals with Large Language Models.](http://arxiv.org/abs/2212.10534) | 本文提出了一种名为DISCO的自动化方法，可利用大型语言模型生成高质量反事实数据，用于训练模型，以实现自然语言推理等任务的因果推理，相比于传统数据训练方法，效果更好且可扩展和高效。 |
| [^85] | [Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters.](http://arxiv.org/abs/2212.10001) | 本文通过实验证明，即使在使用无效推理步骤的情况下，CoT提示也可以实现CoT推理，并显示出其他方面对于CoT的有效性更为关键，这有助于深入了解CoT提示的有效性并提出改进策略。 |
| [^86] | [Reasoning with Language Model Prompting: A Survey.](http://arxiv.org/abs/2212.09597) | 本文提供了使用语言模型提示进行推理的前沿研究综合调查。讨论了新兴推理能力出现的潜在原因，并提供系统资源帮助初学者。 |
| [^87] | [Teaching Small Language Models to Reason.](http://arxiv.org/abs/2212.08410) | 本文研究了如何通过知识蒸馏，将大型语言模型的推理能力传递到小型语言模型中，并证明这样的方法可以提高小型模型在算术、常识和符号推理方面的性能。 |
| [^88] | [Super-CLEVR: A Virtual Benchmark to Diagnose Domain Robustness in Visual Reasoning.](http://arxiv.org/abs/2212.00259) | 本文提出了一个虚拟基准Super-CLEVR，使得我们可以通过分离视觉问题应对领域转移中的各种因素，探究VQA方法的领域泛化能力。作者在四个VQA领域变量上测试了四种方法和一种新方法P-NSVQA，结果表明P-NSVQA比其他方法的性能更好，Super-CLEVR是分析VQA领域泛化的有效工具。 |
| [^89] | [Reward Gaming in Conditional Text Generation.](http://arxiv.org/abs/2211.08714) | 在条件文本生成中，使用强化学习（RL）进行训练时，噪声、自然发生的虚假相关性和协变量漂移可能会导致不良模式被错误地赋予高奖励值，这可能会导致奖励博弈，需要解决。 |
| [^90] | [MT Metrics Correlate with Human Ratings of Simultaneous Speech Translation.](http://arxiv.org/abs/2211.08633) | 本文表明了离线指标与人工连续评分之间存在良好的相关性，可以在同时翻译模式中可靠地用于机器翻译的评估，从而减轻了大规模人工评估的需要。 |
| [^91] | [Speaking Multiple Languages Affects the Moral Bias of Language Models.](http://arxiv.org/abs/2211.07733) | 本文研究发现，预训练的多语言语言模型具有不同程度的道德偏见，英语方面的偏见比其他语言更强。具体而言，在英语训练的多语言语言模型更倾向于优先考虑个体化的道德基础而非束缚性的道德基础，这对跨语言转移和设计伦理自然语言处理系统具有重要的影响。 |
| [^92] | [Emergent Linguistic Structures in Neural Networks are Fragile.](http://arxiv.org/abs/2210.17406) | 本文提出了一个框架来评估语言模型对于语法的表述的一致性和稳健性，通过多项实验证据表明，神经网络中 emergent 语言结构是脆弱的。 |
| [^93] | [Arithmetic Sampling: Parallel Diverse Decoding for Large Language Models.](http://arxiv.org/abs/2210.15458) | 本文章提出了一种算术采样框架，该方法可兼容常见的采样变化，具有可证明的束多样性和令人尴尬的并行性，从原始模型提供无偏和一致的期望。在WMT机器翻译中表现出良好的效果。 |
| [^94] | [Automatic Creation of Named Entity Recognition Datasets by Querying Phrase Representations.](http://arxiv.org/abs/2210.07586) | 本篇论文提出了一种名为HighGEN的新框架，通过使用短语嵌入搜索方法生成实体丰富的伪字典，在使用嵌入距离验证过程减少误报的基础上生成高覆盖率的NER数据集。 |
| [^95] | [SQuId: Measuring Speech Naturalness in Many Languages.](http://arxiv.org/abs/2210.06324) | SQuId是一个使用一百万个评分进行训练并在65个语言环境下进行测试的多语言自然度预测模型，该模型的训练在许多环境中始终优于单一环境的基线，并展现了比竞争基线更出色的表现;研究还突出了跨语言细调的有效性，以及非语言效果如声音畸变在跨语言细调中的作用。 |
| [^96] | [Best Prompts for Text-to-Image Models and How to Find Them.](http://arxiv.org/abs/2209.11711) | 本文研究了文字到图像模型中最佳提示的组成和优化方法，采用人类反馈和遗传算法进行学习，实现了以美学角度进行呈现的专业人类艺术作品的生成。 |
| [^97] | [Do Large Language Models know what humans know?.](http://arxiv.org/abs/2209.01515) | 本文测试了语言暴露假说，评估语言模型是否能够像人类一样感知书面文本中角色的知识状态。结果显示，语言模型虽然超过了偶然行为，但表现不如人类，暗示着仅靠语言暴露难以完全解释人类这种认知能力。 |
| [^98] | [Claim-Dissector: An Interpretable Fact-Checking System with Joint Re-ranking and Veracity Prediction.](http://arxiv.org/abs/2207.14116) | Claim-Dissector是一款联合重排和真实性预测的可解释的事实核查系统，可以识别与声明相关的证据，并确定声明的真实性。该系统的个人贡献以及证据所支持或反驳声明的贡献都可以被识别。 |
| [^99] | [GENEVA: Benchmarking Generalizability for Event Argument Extraction with Hundreds of Event Types and Argument Roles.](http://arxiv.org/abs/2205.12505) | 本文提出了一个大而全的EAE本体论，105个事件和220个论元角色的包含在内，利用这个本体论创建了一种多样化的通用性基准测试数据集GENEVA，共包含四个测试套件，旨在评估模型处理有限数据的能力。 |
| [^100] | [Aerial Vision-and-Dialog Navigation.](http://arxiv.org/abs/2205.12219) | 本文介绍了一种名为AVDN的无人机导航方法，该方法通过自然语言对话来控制无人机的导航，为解决无人机控制的人体负担、多任务操作、以及残疾人和手部占用者控制无人机的难题提供了新思路。 |
| [^101] | [SMARAGD: Learning SMatch for Accurate and Rapid Approximate Graph Distance.](http://arxiv.org/abs/2203.13226) | 本文提出了SMARAGD算法，用于进行准确快速的近似图距离，并使用神经网络以线性时间或恒定时间近似Smatch分数，通过数据增强和图像匿名化，大幅减少了近似误差。 |

# 详细

[^1]: 与康科迪亚并行的神经符号一体化

    Parallel Neurosymbolic Integration with Concordia. (arXiv:2306.00480v1 [cs.AI])

    [http://arxiv.org/abs/2306.00480](http://arxiv.org/abs/2306.00480)

    康科迪亚框架是一个支持各种概率理论，克服了现有技术的限制的并行的神经符号结构，成功应用于集合活动检测、实体链接和推荐任务，提高了最新准确性。

    

    并行的神经符号结构通过将逻辑理论的知识提取到深度模型中，在NLP中得到有效应用。然而，现有技术仍存在一些限制，包括支持受限形式的逻辑理论，并依赖于逻辑和深度网络之间的独立性假设。本文提出了康科迪亚框架，克服了现有技术的限制。康科迪亚框架既不关注深度网络，也不关注逻辑理论，支持各种概率理论。框架可以支持两个组件的监督训练和神经组件的无监督训练。康科迪亚已成功应用于NLP和数据分类以外的任务，提高了集合活动检测、实体链接和推荐任务的最新准确性。

    Parallel neurosymbolic architectures have been applied effectively in NLP by distilling knowledge from a logic theory into a deep model.However, prior art faces several limitations including supporting restricted forms of logic theories and relying on the assumption of independence between the logic and the deep network. We present Concordia, a framework overcoming the limitations of prior art. Concordia is agnostic both to the deep network and the logic theory offering support for a wide range of probabilistic theories. Our framework can support supervised training of both components and unsupervised training of the neural component. Concordia has been successfully applied to tasks beyond NLP and data classification, improving the accuracy of state-of-the-art on collective activity detection, entity linking and recommendation tasks.
    
[^2]: 使预训练模型具有可逆性：从参数到内存高效的微调

    Make Your Pre-trained Model Reversible: From Parameter to Memory Efficient Fine-Tuning. (arXiv:2306.00477v1 [cs.CL])

    [http://arxiv.org/abs/2306.00477](http://arxiv.org/abs/2306.00477)

    本研究尝试实现在预训练语言模型中运用可逆模型实现高效的微调，并发现在初始化微调时保留PLM的起点非常重要。

    

    预训练语言模型（PLM）的参数高效微调已经成为一种非常成功的方法，只需训练少量参数而不会降低性能，并随着PLM越来越大而成为事实上的学习范式。然而，现有的PEFT方法不具备内存效率，因为它们仍需要存储大部分中间激活值以便计算梯度，类似于微调。一个减少激活内存的有效方法是应用可逆模型，这样中间激活值就无需缓存，可以重新计算。然而，将PLM修改为它的可逆变体并进行PEFT并不是一件容易的事，因为可逆模型具有与当前发布的PLM不同的体系结构。本文首先调查现有PEFT方法成功的关键因素，认识到在初始化PEFT时保留PLM的起点是至关重要的。

    Parameter-efficient fine-tuning (PEFT) of pre-trained language models (PLMs) has emerged as a highly successful approach, with training only a small number of parameters without sacrificing performance and becoming the de-facto learning paradigm with the increasing size of PLMs. However, existing PEFT methods are not memory-efficient, because they still require caching most of the intermediate activations for the gradient calculation, akin to fine-tuning. One effective way to reduce the activation memory is to apply a reversible model, so the intermediate activations are not necessary to be cached and can be recomputed. Nevertheless, modifying a PLM to its reversible variant with PEFT is not straightforward, since the reversible model has a distinct architecture from the currently released PLMs. In this paper, we first investigate what is a key factor for the success of existing PEFT methods, and realize that it's essential to preserve the PLM's starting point when initializing a PEFT 
    
[^3]: 一种基于大数据的俄语讽刺检测方法

    A big data approach towards sarcasm detection in Russian. (arXiv:2306.00445v1 [cs.CL])

    [http://arxiv.org/abs/2306.00445](http://arxiv.org/abs/2306.00445)

    本文介绍了一种针对俄语文本的大数据方法，旨在检测文本中的讽刺。作者提出了一组可用于屈折和文本合成的算法，并在一个公开可用的网络服务中实现。对这些算法的性能进行了测试和比较，同时用于估计俄语不同词性的形态变异性和复杂性。

    

    本文提出了一组针对俄罗斯语言屈折和自动文本合成的确定性算法，并在公开可用的网络服务www.passare.ru中实现。该服务提供了单词屈折、词匹配和生成语法正确的俄语文本的功能。所选代码和数据集可在https://github.com/passare-ru/PassareFunctions/中获得。针对OpenCorpora注释语料库对屈折功能的性能进行了测试，与其他解决方案进行了比较，并用于估计俄语不同词性的形态变异性和复杂性。

    We present a set of deterministic algorithms for Russian inflection and automated text synthesis. These algorithms are implemented in a publicly available web-service www.passare.ru. This service provides functions for inflection of single words, word matching and synthesis of grammatically correct Russian text. Selected code and datasets are available at https://github.com/passare-ru/PassareFunctions/ Performance of the inflectional functions has been tested against the annotated corpus of Russian language OpenCorpora, compared with that of other solutions, and used for estimating the morphological variability and complexity of different parts of speech in Russian.
    
[^4]: 意大利女性被害新闻的责任视角转移

    Responsibility Perspective Transfer for Italian Femicide News. (arXiv:2306.00437v1 [cs.CL])

    [http://arxiv.org/abs/2306.00437](http://arxiv.org/abs/2306.00437)

    本文介绍了一项新任务，旨在通过自动修改性别暴力描述来改变读者对于施暴者责任程度的理解。我们使用了多种方法进行句子重写，并采用问卷研究和自动评价指标对模型进行评估。

    

    不同的语言表述可以导致对真实世界事件的不同理解。以往研究表明，不同的性别暴力描述会影响读者对于暴力行为谁应承担责任的理解，进而强化将受害人视为部分有责任的刻板印象。为了提高人们对于写作视角的意识，促进对于不同视角的理解，我们引入一项新任务，即自动修改性别暴力描述，以改变对于施暴者责任程度的理解。我们提供了一个准平行的数据集，其中包含对于施暴者责任感低和高的句子，并采用无监督（基于mBART）、零样本和少样本（基于GPT3）方法进行句子重写。我们使用问卷研究和自动评价指标来评估我们的模型。

    Different ways of linguistically expressing the same real-world event can lead to different perceptions of what happened. Previous work has shown that different descriptions of gender-based violence (GBV) influence the reader's perception of who is to blame for the violence, possibly reinforcing stereotypes which see the victim as partly responsible, too. As a contribution to raise awareness on perspective-based writing, and to facilitate access to alternative perspectives, we introduce the novel task of automatically rewriting GBV descriptions as a means to alter the perceived level of responsibility on the perpetrator. We present a quasi-parallel dataset of sentences with low and high perceived responsibility levels for the perpetrator, and experiment with unsupervised (mBART-based), zero-shot and few-shot (GPT3-based) methods for rewriting sentences. We evaluate our models using a questionnaire study and a suite of automatic metrics.
    
[^5]: 我应该给几个答案？多答案阅读理解的实证研究

    How Many Answers Should I Give? An Empirical Study of Multi-Answer Reading Comprehension. (arXiv:2306.00435v1 [cs.CL])

    [http://arxiv.org/abs/2306.00435](http://arxiv.org/abs/2306.00435)

    研究设计分类法来分类常见多答案阅读理解实例，分析模型范例处理不同类型多答案实例的效果，发现某些模型范例更擅长捕获问题关键信息，而其他范例则更适合建立问题和上下文之间的关系。生成模型整合不同范例的优势，具有前景。

    

    多答案现象意味着问题可能在文档中有多个答案，人类可以处理得很好，但对于机器阅读理解系统来说很具有挑战性。本研究设计了一个分类法来分类常见的多答案阅读理解实例，并分析多答案挑战的来源，同时分析了不同模型范例如何处理不同类型的多答案实例。我们发现，某些范例很好地捕获了问题中的关键信息，而另一些范例则更好地建立了问题和上下文之间的关系。因此，我们探索了利用不同模型范例的优势的策略。实验结果表明，生成模型是整合不同模型范例的有前途的平台。

    The multi-answer phenomenon, where a question may have multiple answers scattered in the document, can be well handled by humans but is challenging enough for machine reading comprehension (MRC) systems. Despite recent progress in multi-answer MRC, there lacks a systematic analysis of how this phenomenon arises and how to better address it. In this work, we design a taxonomy to categorize commonly-seen multi-answer MRC instances, with which we inspect three multi-answer datasets and analyze where the multi-answer challenge comes from. We further analyze how well different paradigms of current multi-answer MRC models deal with different types of multi-answer instances. We find that some paradigms capture well the key information in the questions while others better model the relationship between questions and contexts. We thus explore strategies to make the best of the strengths of different paradigms. Experiments show that generation models can be a promising platform to incorporate di
    
[^6]: 分解、征服和组合：面向零样本对话状态追踪的混合无语义专家

    Divide, Conquer, and Combine: Mixture of Semantic-Independent Experts for Zero-Shot Dialogue State Tracking. (arXiv:2306.00434v1 [cs.CL])

    [http://arxiv.org/abs/2306.00434](http://arxiv.org/abs/2306.00434)

    本文提出了一种通过“分解、征服和组合”解耦语义的方法，利用专家混合机制的性能和鲁棒性，从而显著并一致地提高了面向零样本对话状态追踪的性能。

    

    对话状态追踪（DST）的零样本迁移学习有助于处理各种面向任务的对话领域，而无需收集领域内数据的成本。现有的工作主要研究常见的数据或模型级别的增强方法来增强泛化性能，但未能有效地解耦样本语义，限制了DST的零样本性能。本文提出了一种简单有效的“分解、征服和组合”解决方案，明确地解耦了已知数据的语义，并利用专家混合机制的性能和鲁棒性。具体地，我们将已知数据划分为语义独立子集，并训练相应的专家，在我们设计的集合推理下，将新的未见样本映射并推断出混合型专家。在T5-Adapter上对MultiWOZ2.1进行了大量实验，结果表明我们的方案显著且一致地提高了零样本性能，在设置上实现了SOTA水平。

    Zero-shot transfer learning for Dialogue State Tracking (DST) helps to handle a variety of task-oriented dialogue domains without the cost of collecting in-domain data. Existing works mainly study common data- or model-level augmentation methods to enhance the generalization but fail to effectively decouple the semantics of samples, limiting the zero-shot performance of DST. In this paper, we present a simple and effective "divide, conquer and combine" solution, which explicitly disentangles the semantics of seen data, and leverages the performance and robustness with the mixture-of-experts mechanism. Specifically, we divide the seen data into semantically independent subsets and train corresponding experts, the newly unseen samples are mapped and inferred with mixture-of-experts with our designed ensemble inference. Extensive experiments on MultiWOZ2.1 upon the T5-Adapter show our schema significantly and consistently improves the zero-shot performance, achieving the SOTA on settings 
    
[^7]: 多模态查询的端到端知识检索

    End-to-end Knowledge Retrieval with Multi-modal Queries. (arXiv:2306.00424v1 [cs.CL])

    [http://arxiv.org/abs/2306.00424](http://arxiv.org/abs/2306.00424)

    该论文提出了一个新的多模态检索任务，引入了一个名为“ReViz”的检索模型，可以直接处理文本和图像输入以实现端到端的知识检索，同时提出了一种有效的预训练任务，并在两个数据集上展示了优越的检索性能。

    

    我们研究了多模态查询下的知识检索，即包含图像和文本的查询的任务，这是与之前的跨模态检索研究不同的挑战性任务。我们创建了一个名为ReMuQ的新数据集，用于评估这个任务的进展。ReMuQ需要一个系统通过整合来自文本和图像查询的内容来检索大规模语料库中的知识。我们引入了一个叫做“ReViz”的检索模型，这个模型可以直接处理输入的文本和图像，以端到端方式检索相关知识，而不依赖于像目标检测器或标题生成器等中间模块。我们介绍了一种新的预训练任务，有效地学习多模态查询下的知识检索，并在下游任务中提高了性能。我们展示了在零-shot设置下，在两个数据集（ReMuQ和OK-VQA）上的检索性能优越以及在这些数据集上微调后进一步的性能提升。

    We investigate knowledge retrieval with multi-modal queries, i.e. queries containing information split across image and text inputs, a challenging task that differs from previous work on cross-modal retrieval. We curate a new dataset called ReMuQ for benchmarking progress on this task. ReMuQ requires a system to retrieve knowledge from a large corpus by integrating contents from both text and image queries. We introduce a retriever model ``ReViz'' that can directly process input text and images to retrieve relevant knowledge in an end-to-end fashion without being dependent on intermediate modules such as object detectors or caption generators. We introduce a new pretraining task that is effective for learning knowledge retrieval with multimodal queries and also improves performance on downstream tasks. We demonstrate superior performance in retrieval on two datasets (ReMuQ and OK-VQA) under zero-shot settings as well as further improvements when finetuned on these datasets.
    
[^8]: “不确定性感知的非似然学习提高生成式情感四元组预测”

    Uncertainty-Aware Unlikelihood Learning Improves Generative Aspect Sentiment Quad Prediction. (arXiv:2306.00418v1 [cs.CL])

    [http://arxiv.org/abs/2306.00418](http://arxiv.org/abs/2306.00418)

    本文提出了一种新的方法来控制标记级的生成、提高原始学习和减少错误，其中包括蒙特卡洛dropout、边缘非似然学习和最小化熵。在四个公共数据集上的广泛实验表明，该方法有效地提高了情感四元组预测的性能。

    

    最近，基于方面的情感分析领域广泛关注了情感四元组预测。现有的研究通过预训练的生成式语言模型提取出四元组，将原始句子转化为模板化的目标序列。然而，以前的研究只关注生成什么，而忽略了不需要生成的内容。我们认为考虑负样本也会带来潜在的好处。本文提出了一种模板无关的方法来控制标记级的生成，同时提高原始学习和减少错误。具体来说，我们引入了蒙特卡洛dropout来理解预训练语言模型的内置不确定性，获取噪声和错误信息。我们进一步提出边缘非似然学习来抑制不确定性感知的错误标记。最后，我们引入了最小化熵来平衡边缘非似然学习的影响。在四个公共数据集上的广泛实验表明，我们提出的方法在提高情感四元组预测的性能方面是有效的。

    Recently, aspect sentiment quad prediction has received widespread attention in the field of aspect-based sentiment analysis. Existing studies extract quadruplets via pre-trained generative language models to paraphrase the original sentence into a templated target sequence. However, previous works only focus on what to generate but ignore what not to generate. We argue that considering the negative samples also leads to potential benefits. In this work, we propose a template-agnostic method to control the token-level generation, which boosts original learning and reduces mistakes simultaneously. Specifically, we introduce Monte Carlo dropout to understand the built-in uncertainty of pre-trained language models, acquiring the noises and errors. We further propose marginalized unlikelihood learning to suppress the uncertainty-aware mistake tokens. Finally, we introduce minimization entropy to balance the effects of marginalized unlikelihood learning. Extensive experiments on four public
    
[^9]: 对低资源语言进行仇恨言论检测：比较ASR和Wolof以及Swahili中基于声学词嵌入的方法

    Towards hate speech detection in low-resource languages: Comparing ASR to acoustic word embeddings on Wolof and Swahili. (arXiv:2306.00410v1 [cs.CL])

    [http://arxiv.org/abs/2306.00410](http://arxiv.org/abs/2306.00410)

    本文研究了在低资源语言中进行仇恨言论检测的方法。在控制实验中，ASR模型表现更好，但在实际应用中，AWE模型表现更为鲁棒。

    

    我们考虑通过关键词识别在广播中检测仇恨言论。一种方法是为目标低资源语言建立一个自动语音识别（ASR）系统。我们将此与使用基于声学词嵌入（AWE）模型进行比较，该模型将语音段映射到一个空间，其中匹配的词有相似的向量。具体来说，我们使用一个在资源丰富的语言中训练的多语言AWE模型，在未见过的目标语言数据中检测关键词。与ASR相比，AWE方法仅需要少量的关键词样本。在Wolof和Swahili的控制实验中，由仅五分钟的数据训练的ASR模型优于AWE方法。但是在实际野外测试的Swahili广播中，使用一分钟的模板数据的AWE模型更加鲁棒，提供类似于30小时标记数据训练的ASR系统的性能。

    We consider hate speech detection through keyword spotting on radio broadcasts. One approach is to build an automatic speech recognition (ASR) system for the target low-resource language. We compare this to using acoustic word embedding (AWE) models that map speech segments to a space where matching words have similar vectors. We specifically use a multilingual AWE model trained on labelled data from well-resourced languages to spot keywords in data in the unseen target language. In contrast to ASR, the AWE approach only requires a few keyword exemplars. In controlled experiments on Wolof and Swahili where training and test data are from the same domain, an ASR model trained on just five minutes of data outperforms the AWE approach. But in an in-the-wild test on Swahili radio broadcasts with actual hate speech keywords, the AWE model (using one minute of template data) is more robust, giving similar performance to an ASR system trained on 30 hours of labelled data.
    
[^10]: BiSync：用于同步单语文本的双语编辑器

    BiSync: A Bilingual Editor for Synchronized Monolingual Texts. (arXiv:2306.00400v1 [cs.CL])

    [http://arxiv.org/abs/2306.00400](http://arxiv.org/abs/2306.00400)

    BiSync是一款双语写作助手，允许用户自由地使用两种语言撰写文本，同时保持两种单语文本同步，还包括其他功能，例如显示替代前缀翻译和释义，旨在促进撰写过程。

    

    在我们全球化的世界中，越来越多情况需要人们使用一种或多种外语进行沟通。在书面沟通的情况下，熟练掌握外语的用户可以借助计算机辅助翻译（CAT）技术。然而，这些技术往往需要用户访问外部资源，如词典、术语表、双语语料库等，从而中断并严重阻碍其写作过程。为了使写作过程更加平稳，我们提出了 BiSync，一种双语写作助手，允许用户自由地使用两种语言撰写文本，同时保持两种单语文本同步。我们还包括其他功能，例如显示替代前缀翻译和释义，旨在促进撰写过程。

    In our globalized world, a growing number of situations arise where people are required to communicate in one or several foreign languages. In the case of written communication, users with a good command of a foreign language may find assistance from computer-aided translation (CAT) technologies. These technologies often allow users to access external resources, such as dictionaries, terminologies or bilingual concordancers, thereby interrupting and considerably hindering the writing process. In addition, CAT systems assume that the source sentence is fixed and also restrict the possible changes on the target side. In order to make the writing process smoother, we present BiSync, a bilingual writing assistant that allows users to freely compose text in two languages, while maintaining the two monolingual texts synchronized. We also include additional functionalities, such as the display of alternative prefix translations and paraphrases, which are intended to facilitate the authoring o
    
[^11]: 基于偏好的语言模型微调中的标记级指导

    Preference-grounded Token-level Guidance for Language Model Fine-tuning. (arXiv:2306.00398v1 [cs.CL])

    [http://arxiv.org/abs/2306.00398](http://arxiv.org/abs/2306.00398)

    本论文通过设计一个交替训练过程，在序列级别偏好与标记级别训练指导之间进行迭代，并利用学习到的指导改进LM。实验证明该方法在多个文本生成任务中表现良好。

    

    将偏好与语言模型（LMs）相匹配是自然语言生成中的一个重要问题。关键挑战是偏好通常在序列级别上提供，而LM训练和生成都发生在标记级别上。因此，偏好和LM训练损失之间存在颗粒度不匹配，这可能会复杂化学习问题。本文通过开发一种交替训练过程解决了这个问题，在序列级别偏好与标记级别训练指导之间进行迭代，并利用学习到的指导改进LM。为了学习指导，我们设计了一个框架，将模仿学习中的成对偏好学习扩展到可变长度LM生成和利用多个生成之间的偏好。对于LM训练，基于监督数据量，我们提出了两种利用学习到的指导的极简主义学习目标。在实验中，我们的方法在多个文本生成任务中表现良好，表明我们的指导提高了生成序列的质量，允许更精细的控制。

    Aligning language models (LMs) with preferences is an important problem in natural language generation. A key challenge is that preferences are typically provided at the sequence level while LM training and generation both occur at the token level. There is, therefore, a granularity mismatch between the preference and the LM training losses, which may complicate the learning problem. In this paper, we address this issue by developing an alternate training process, where we iterate between grounding the sequence-level preference into token-level training guidance, and improving the LM with the learned guidance. For guidance learning, we design a framework that extends the pairwise-preference learning in imitation learning to both variable-length LM generation and utilizing the preference among multiple generations. For LM training, based on the amount of supervised data, we present two minimalist learning objectives that utilize the learned guidance. In experiments, our method performs 
    
[^12]: 在网络安全中开发和构建本体论

    Developing and Building Ontologies in Cyber Security. (arXiv:2306.00377v1 [cs.CR])

    [http://arxiv.org/abs/2306.00377](http://arxiv.org/abs/2306.00377)

    通过比较不同本体论，该论文提供了有关网络安全本体论领域的未来方向。

    

    网络安全是我们现代社会中最受关注的学科之一。我们在网络安全领域工作，选择了网络安全本体论作为研究主题。我们汇集了最新和以前的本体论，并根据不同的分析因素进行比较，以找到最佳方案。选择此主题的原因是汇集来自不同时代的不同本体论。因为研究中包括的SLR大多研究单个本体论。如果任何研究人员想要研究本体论，他必须研究每个单独的本体论并选择最适合他研究的。因此，我们汇集了不同类型的本体论，并相互比较以得到最佳方案。通过系统性过程认真选择了2010年至2020年间的24篇论文，并进行了分类。最后，本SLR呈现给研究人员有关网络安全本体论领域的有前途的未来方向。

    Cyber Security is one of the most arising disciplines in our modern society. We work on Cybersecurity domain and in this the topic we chose is Cyber Security Ontologies. In this we gather all latest and previous ontologies and compare them on the basis of different analyzing factors to get best of them. Reason to select this topic is to assemble different ontologies from different era of time. Because, researches that included in this SLR is mostly studied single ontology. If any researcher wants to study ontologies, he has to study every single ontology and select which one is best for his research. So, we assemble different types of ontology and compare them against each other to get best of them. A total 24 papers between years 2010-2020 are carefully selected through systematic process and classified accordingly. Lastly, this SLR have been presented to provide the researchers promising future directions in the domain of cybersecurity ontologies.
    
[^13]: CFL：通过基于Token级属性控制的生成实现因果公平的语言模型

    CFL: Causally Fair Language Models Through Token-level Attribute Controlled Generation. (arXiv:2306.00374v1 [cs.CL])

    [http://arxiv.org/abs/2306.00374](http://arxiv.org/abs/2306.00374)

    本文提出了一种使用因果平均处理效应（ATE）分数和反事实增强方法的CFL体系架构，通过插入式方式对预训练的LM进行解毒，实现了因果公平的语言模型。此方法不会对模型困惑产生太大影响，还减轻了意外的偏置问题。

    

    我们提出了一种方法来控制语言模型（LMs）的属性，用于文本生成任务，该方法使用因果平均处理效应（ATE）分数和反事实增强。我们探索了这种方法，在LM解毒的背景下提出了CFL（causally fair language）体系结构，以插入式方式对预训练的LM进行解毒。我们的体系结构基于结构因果模型（SCM），数学透明且与许多现有解毒技术相比计算效率高。我们还提出了几个新的度量标准，旨在更好地理解LM在有害文本生成环境中的行为。此外，我们在\RTP(RTP)基准测试中实现了最先进的毒性退化性能。我们的实验表明，CFL实现了这种解毒，对模型困惑没有太大影响。我们还通过对BOLD数据集的实验展示了CFL的减轻意外偏置问题的能力。

    We propose a method to control the attributes of Language Models (LMs) for the text generation task using Causal Average Treatment Effect (ATE) scores and counterfactual augmentation. We explore this method, in the context of LM detoxification, and propose the Causally Fair Language (CFL) architecture for detoxifying pre-trained LMs in a plug-and-play manner. Our architecture is based on a Structural Causal Model (SCM) that is mathematically transparent and computationally efficient as compared with many existing detoxification techniques. We also propose several new metrics that aim to better understand the behaviour of LMs in the context of toxic text generation. Further, we achieve state of the art performance for toxic degeneration, which are computed using \RTP (RTP) benchmark. Our experiments show that CFL achieves such a detoxification without much impact on the model perplexity. We also show that CFL mitigates the unintended bias problem through experiments on the BOLD dataset.
    
[^14]: 针对可控文本生成的焦点前缀调整方法

    Focused Prefix Tuning for Controllable Text Generation. (arXiv:2306.00369v1 [cs.CL])

    [http://arxiv.org/abs/2306.00369](http://arxiv.org/abs/2306.00369)

    本文提出了针对可控文本生成的焦点前缀调整方法，实验结果表明在单属性控制任务中实现了更好的控制准确性和文本流畅度，在多属性控制任务中实现了与最先进方法相当的控制准确性，并保持了控制新属性而无需重新训练现有模型的灵活性。

    

    在可控文本生成数据集中，存在未标注属性，可能会为使用其进行训练的模型提供无关的学习信号，从而降低它们的性能。我们提出了焦点前缀调整（FPT）来缓解这个问题，并使控制能够专注于所需属性。实验结果表明，与基线模型相比，在单属性控制任务中，FPT可以实现更好的控制准确性和文本流畅度。在多属性控制任务中，FPT实现了与最先进方法相当的控制准确性，同时保持了控制新属性而无需重新训练现有模型的灵活性。

    In a controllable text generation dataset, there exist unannotated attributes that could provide irrelevant learning signals to models that use it for training and thus degrade their performance. We propose focused prefix tuning(FPT) to mitigate the problem and to enable the control to focus on the desired attribute. Experimental results show that FPT can achieve better control accuracy and text fluency than baseline models in single-attribute control tasks. In multi-attribute control tasks, FPT achieves comparable control accuracy with the state-of-the-art approach while keeping the flexibility to control new attributes without retraining existing models.
    
[^15]: SemEval2023任务8中的CAISA：反事实数据增广用于减轻因果关系提取中的类别不平衡问题

    CAISA at SemEval-2023 Task 8: Counterfactual Data Augmentation for Mitigating Class Imbalance in Causal Claim Identification. (arXiv:2306.00346v1 [cs.CL])

    [http://arxiv.org/abs/2306.00346](http://arxiv.org/abs/2306.00346)

    该论文提出了一种针对类别不平衡问题的新颖反事实数据增广方法，该方法通过动词替换进行，用于医学因果关系提取，并且与其他3种数据增广技术相比较，在少数类方面有显著提高。

    

    类别不平衡问题会导致机器学习模型在少数类和整个数据集上产生不理想的表现。使用数据增广技术来增加样本数量是解决这个问题的一种方式。我们提出了一种新颖的通过动词替换进行反事实数据增广的方法，用于医学因果关系提取。此外，我们还研究了该方法的影响，并将其与其他3种数据增广技术进行了比较，结果显示该方法可以显著（相对）提高少数类的性能。

    The class imbalance problem can cause machine learning models to produce an undesirable performance on the minority class as well as the whole dataset. Using data augmentation techniques to increase the number of samples is one way to tackle this problem. We introduce a novel counterfactual data augmentation by verb replacement for the identification of medical claims. In addition, we investigate the impact of this method and compare it with 3 other data augmentation techniques, showing that the proposed method can result in a significant (relative) improvement in the minority class.
    
[^16]: CapText: 基于大型语言模型的图像内容和描述生成字幕

    CapText: Large Language Model-based Caption Generation From Image Context and Description. (arXiv:2306.00301v1 [cs.LG])

    [http://arxiv.org/abs/2306.00301](http://arxiv.org/abs/2306.00301)

    研究提出了一种基于大型语言模型的图像字幕生成方法，从文本描述和上下文中生成字幕，而不直接处理图像。在CIDEr指标上，优于当前最先进的图像文本对齐模型。

    

    尽管深度学习模型在图像到文本数据集上表现良好，但在实践中难以用于图像字幕生成，因为传统的图片字幕往往是与图像相关的，并且提供有关图像的补充信息，而模型往往生成描述图像视觉特征的“描述”。在字幕生成方面的研究已探索了使用模型在提供对应的描述或上下文信息的情况下生成字幕的方法。我们提出并评估了一种新的方法，该方法利用现有的大型语言模型从文本描述和上下文中生成字幕，而不直接处理图像。我们证明，在微调后，我们的方法在 CIDEr 指标上胜过了当前最先进的图像文本对齐模型，如 OSCAR-VinVL。

    While deep-learning models have been shown to perform well on image-to-text datasets, it is difficult to use them in practice for captioning images. This is because \textit{captions} traditionally tend to be context-dependent and offer complementary information about an image, while models tend to produce \textit{descriptions} that describe the visual features of the image. Prior research in caption generation has explored the use of models that generate captions when provided with the images alongside their respective descriptions or contexts. We propose and evaluate a new approach, which leverages existing large language models to generate captions from textual descriptions and context alone, without ever processing the image directly. We demonstrate that after fine-tuning, our approach outperforms current state-of-the-art image-text alignment models like OSCAR-VinVL on this task on the CIDEr metric.
    
[^17]: 无训练神经网络结构搜索在RNN和Transformer上的应用

    Training-free Neural Architecture Search for RNNs and Transformers. (arXiv:2306.00288v1 [cs.LG])

    [http://arxiv.org/abs/2306.00288](http://arxiv.org/abs/2306.00288)

    本文研究了适用于语言模型任务的循环神经网络和Transformer的无训练神经网络结构搜索算法，并开发了一个新的性能预测指标hidden covariance，可显著优化现有指标。

    

    神经网络结构搜索(NAS)可以自动创建新的有效的神经网络架构，为手动设计复杂架构提供了一种选择。然而，传统的NAS算法速度较慢，需要大量计算力。最近的研究探讨了用于图像分类架构的无训练NAS指标，极大地加速了搜索算法。本文研究针对语言建模任务的循环神经网络(RNN)和BERT-based transformer架构的无训练NAS指标。首先，我们开发了一个名为hidden covariance的新的无训练指标，可以预测训练后RNN架构的性能，并显著优于现有的无训练指标。其次，我们发现目前的转换器搜索空间范例

    Neural architecture search (NAS) has allowed for the automatic creation of new and effective neural network architectures, offering an alternative to the laborious process of manually designing complex architectures. However, traditional NAS algorithms are slow and require immense amounts of computing power. Recent research has investigated training-free NAS metrics for image classification architectures, drastically speeding up search algorithms. In this paper, we investigate training-free NAS metrics for recurrent neural network (RNN) and BERT-based transformer architectures, targeted towards language modeling tasks. First, we develop a new training-free metric, named hidden covariance, that predicts the trained performance of an RNN architecture and significantly outperforms existing training-free metrics. We experimentally evaluate the effectiveness of the hidden covariance metric on the NAS-Bench-NLP benchmark. Second, we find that the current search space paradigm for transformer
    
[^18]: AfriNames：大多数ASR模型“屠戮”非洲人的名字

    AfriNames: Most ASR models "butcher" African Names. (arXiv:2306.00253v1 [cs.CL])

    [http://arxiv.org/abs/2306.00253](http://arxiv.org/abs/2306.00253)

    该论文探讨了自动语音识别模型在处理非洲名字时的性能问题，并提出了多语言预训练和数据增强等策略，通过微调ASR模型在多个非洲口音上，显著减少了模型误差，相对WER提高了81.5％。

    

    有效的对话代理必须准确捕捉命名实体，以最小化下游任务的错误，例如，要求语音助手播放特定艺术家的音轨，启动导航到特定位置，或为患者记录实验室结果。但是，当出现诸如“Ukachukwu”（伊博语）、“Lakicia”（斯瓦希里语）或“Ingabire”（卢旺达语）等命名实体时，自动语音识别（ASR）模型的性能显著降低，将错误传递到下游系统。我们将这个问题建模为分布偏移，并演示了通过多语言预训练、智能数据增强策略来增加非洲命名实体的表示，并在多个非洲口音上微调多语言ASR模型可以减轻模型偏差。结果表明，与基线相比，经过微调的模型在包含非洲命名实体的样本上相对WER改进了81.5％。

    Useful conversational agents must accurately capture named entities to minimize error for downstream tasks, for example, asking a voice assistant to play a track from a certain artist, initiating navigation to a specific location, or documenting a laboratory result for a patient. However, where named entities such as ``Ukachukwu`` (Igbo), ``Lakicia`` (Swahili), or ``Ingabire`` (Rwandan) are spoken, automatic speech recognition (ASR) models' performance degrades significantly, propagating errors to downstream systems. We model this problem as a distribution shift and demonstrate that such model bias can be mitigated through multilingual pre-training, intelligent data augmentation strategies to increase the representation of African-named entities, and fine-tuning multilingual ASR models on multiple African accents. The resulting fine-tuned models show an 81.5\% relative WER improvement compared with the baseline on samples with African-named entities.
    
[^19]: 从像素到用户界面操作：通过图形用户界面学习遵循指令

    From Pixels to UI Actions: Learning to Follow Instructions via Graphical User Interfaces. (arXiv:2306.00245v1 [cs.LG])

    [http://arxiv.org/abs/2306.00245](http://arxiv.org/abs/2306.00245)

    本文提出了一种基于像素级别的预训练方法，建立了一种模拟人类概念界面和混合动作空间的代理，实现了在GUI指令遵循任务的MiniWob++基准测试中超越人类工作者的目标。

    

    先前为了构建操作图形用户界面（GUI）的数字化代理，大多数工作都依赖基于文本的表示（从HTML或其他结构化数据源派生），这些表示并不总是容易获取。这些输入表示通常与自定义的任务特定动作空间相关联。本文旨在创建使用与人类通常使用的相同概念界面-通过基于像素的屏幕截图和对应于键盘和鼠标操作的通用动作空间与数字世界交互的代理。在近期关于像素级预训练方法的基础上，我们首次展示了这样的代理在GUI指令遵循任务的MiniWob ++基准测试中能够超越人类工作者。

    Much of the previous work towards digital agents for graphical user interfaces (GUIs) has relied on text-based representations (derived from HTML or other structured data sources), which are not always readily available. These input representations have been often coupled with custom, task-specific action spaces. This paper focuses on creating agents that interact with the digital world using the same conceptual interface that humans commonly use -via pixel-based screenshots and a generic action space corresponding to keyboard and mouse actions. Building upon recent progress in pixel-based pretraining, we show, for the first time, that it is possible for such agents to outperform human crowdworkers on the MiniWob++ benchmark of GUI-based instruction following tasks.
    
[^20]: 使用视觉裁剪来增强BLIP模型细节问题回答的能力

    Using Visual Cropping to Enhance Fine-Detail Question Answering of BLIP-Family Models. (arXiv:2306.00228v1 [cs.CV])

    [http://arxiv.org/abs/2306.00228](http://arxiv.org/abs/2306.00228)

    本文研究如何通过使用视觉裁剪来提高BLIP模型在细节问题上的表现能力。

    

    视觉问答是一项具有挑战性的任务，需要感知、语言和背景知识系统之间的无缝交互。虽然最近视觉和自然语言模型的进展如BLIP已经提高了这项任务的性能，但我们缺乏理解这些模型在不同类型的问题和推理类型上表现的能力。鉴于我们对BLIP家族模型进行的初步分析显示出回答细节问题方面的困难，我们研究以下问题：能否使用视觉裁剪来提高最先进的视觉问答模型在细节问题上的性能？考虑到BLIP家族模型的最近成功，我们研究了一个零样本和一个微调的BLIP模型。我们定义了三个受控的子集，以衡量裁剪是否有助于模型性能。除了人工裁剪外，我们还设计了两种基于多模态嵌入的自动裁剪策略，这些策略以CLIP为基础。

    Visual Question Answering is a challenging task, as it requires seamless interaction between perceptual, linguistic, and background knowledge systems. While the recent progress of visual and natural language models like BLIP has led to improved performance on this task, we lack understanding of the ability of such models to perform on different kinds of questions and reasoning types. As our initial analysis of BLIP-family models revealed difficulty with answering fine-detail questions, we investigate the following question: Can visual cropping be employed to improve the performance of state-of-the-art visual question answering models on fine-detail questions? Given the recent success of the BLIP-family models, we study a zero-shot and a fine-tuned BLIP model. We define three controlled subsets of the popular VQA-v2 benchmark to measure whether cropping can help model performance. Besides human cropping, we devise two automatic cropping strategies based on multi-modal embedding by CLIP 
    
[^21]: 扩散画笔：基于潜在扩散模型的AI生成图像编辑工具

    Diffusion Brush: A Latent Diffusion Model-based Editing Tool for AI-generated Images. (arXiv:2306.00219v1 [cs.CV])

    [http://arxiv.org/abs/2306.00219](http://arxiv.org/abs/2306.00219)

    本论文提出了一种名为扩散画笔的基于潜在扩散模型的AI图像微调工具，可以有效地根据目标区域修改AI合成图像并保留原始上下文。与其他最先进的图像修复技术进行比较，该方法在用户研究中表现出更好的可用性和有效性。

    

    文本到图像的生成模型在生成高质量图像方面取得了显著的进展。然而，由于模型限制，生成的图像经常包含不良的伪影或其他错误。现有的微调生成图像的技术要么耗时（手动编辑），要么产生不够完美的结果（修补），要么会导致整体图像产生意想不到的变化（变体选择和提示微调）。本文提出了一种名为扩散画笔的基于潜在扩散模型的AI图像微调工具，可以有效地微调AI合成图像中所需的区域。我们的方法在反向扩散过程中在目标区域引入了新的随机噪声模式，使模型能够在保留其他区域原始上下文的同时，高效地对指定区域进行更改。我们通过艺术家进行的用户研究评估了我们方法的可用性和有效性，将我们的技术与其他最先进的图像修复技术进行了比较。

    Text-to-image generative models have made remarkable advancements in generating high-quality images. However, generated images often contain undesirable artifacts or other errors due to model limitations. Existing techniques to fine-tune generated images are time-consuming (manual editing), produce poorly-integrated results (inpainting), or result in unexpected changes across the entire image (variation selection and prompt fine-tuning). In this work, we present Diffusion Brush, a Latent Diffusion Model-based (LDM) tool to efficiently fine-tune desired regions within an AI-synthesized image. Our method introduces new random noise patterns at targeted regions during the reverse diffusion process, enabling the model to efficiently make changes to the specified regions while preserving the original context for the rest of the image. We evaluate our method's usability and effectiveness through a user study with artists, comparing our technique against other state-of-the-art image inpaintin
    
[^22]: FEED PETs：关于潜在委婉说语的消歧更多实验与扩展

    FEED PETs: Further Experimentation and Expansion on the Disambiguation of Potentially Euphemistic Terms. (arXiv:2306.00217v1 [cs.CL])

    [http://arxiv.org/abs/2306.00217](http://arxiv.org/abs/2306.00217)

    本研究扩展了潜在委婉语消歧任务，首先注释了模糊性对性能的影响，并在三种不同的语言中提供了新颖的委婉语语料库。通过使用多语言Transformer模型，该研究建立了初步的结果，为未来的工作提供了基础。

    

    研究表明Transformer在英语委婉语消歧任务中表现良好，即在特定语境中将潜在的委婉语（PET）分类为委婉语或非委婉语。本研究从两个方面扩展任务。首先，我们为模糊性注释PET，这是与委婉语相关的语言属性，并发现Transformer通常更擅长分类模糊的PET，这表明影响性能的数据中存在语言差异。其次，我们提供了三种不同语言的新颖委婉语语料库：约鲁巴语、西班牙语和中文普通话。我们使用多语言Transformer模型mBERT和XLM-RoBERTa在每种语言中执行委婉语消歧实验，建立初步结果，为未来工作提供了基础和参考。

    Transformers have been shown to work well for the task of English euphemism disambiguation, in which a potentially euphemistic term (PET) is classified as euphemistic or non-euphemistic in a particular context. In this study, we expand on the task in two ways. First, we annotate PETs for vagueness, a linguistic property associated with euphemisms, and find that transformers are generally better at classifying vague PETs, suggesting linguistic differences in the data that impact performance. Second, we present novel euphemism corpora in three different languages: Yoruba, Spanish, and Mandarin Chinese. We perform euphemism disambiguation experiments in each language using multilingual transformer models mBERT and XLM-RoBERTa, establishing preliminary results from which to launch future work.
    
[^23]: 基于预训练的ASR模型的低资源语音转文本翻译的改进策略

    Strategies for improving low resource speech to text translation relying on pre-trained ASR models. (arXiv:2306.00208v1 [cs.CL])

    [http://arxiv.org/abs/2306.00208](http://arxiv.org/abs/2306.00208)

    本论文介绍了针对低资源语音转文本翻译的改进策略，利用编码器-解码器框架以及多语种自动语音识别系统初步提升性能，在训练和解码时使用CTC作为额外的目标进一步优化结果，在Tamasheq-法语数据上达到了7.3的BLEU得分。

    

    本文提出了改进低资源语音转文本翻译的技术和发现。我们在英语-葡萄牙语和Tamasheq-法语两种语言对的模拟和真实低资源环境下进行了实验。使用编码器-解码器框架来进行翻译，我们的结果表明，多语种自动语音识别系统在低资源情况下作为良好的初始化。此外，在训练和解码时使用CTC作为额外的翻译目标有助于重新排序内部表示并改进最终的翻译。通过实验，我们试图确定对于低资源环境中的改进最有贡献的各种因素（初始化，目标和超参数）。只使用300个小时的预训练数据，我们的模型在Tamasheq-法语数据上达到了7.3的BLEU得分，优于IWSLT 2022的之前发表的作品1.6个点。

    This paper presents techniques and findings for improving the performance of low-resource speech to text translation (ST). We conducted experiments on both simulated and real-low resource setups, on language pairs English - Portuguese, and Tamasheq - French respectively. Using the encoder-decoder framework for ST, our results show that a multilingual automatic speech recognition system acts as a good initialization under low-resource scenarios. Furthermore, using the CTC as an additional objective for translation during training and decoding helps to reorder the internal representations and improves the final translation. Through our experiments, we try to identify various factors (initializations, objectives, and hyper-parameters) that contribute the most for improvements in low-resource setups. With only 300 hours of pre-training data, our model achieved 7.3 BLEU score on Tamasheq - French data, outperforming prior published works from IWSLT 2022 by 1.6 points.
    
[^24]: 控制文本生成的不变学习特征描述

    An Invariant Learning Characterization of Controlled Text Generation. (arXiv:2306.00198v1 [cs.CL])

    [http://arxiv.org/abs/2306.00198](http://arxiv.org/abs/2306.00198)

    本文提出了一种控制文本生成的不变学习方法，解决了生成的文本分布转移的问题。

    

    控制生成是指创建包含所需样式或语义属性的文本的问题。许多方法将这个问题归结为训练所需属性的预测器。在实际应用中，生成的文本可能来自各种分布。本文通过不变学习的方式解决了控制生成中分布转移的问题。

    Controlled generation refers to the problem of creating text that contains stylistic or semantic attributes of interest. Many approaches reduce this problem to training a predictor of the desired attribute. For example, researchers hoping to deploy a large language model to produce non-toxic content may use a toxicity classifier to filter generated text. In practice, the generated text to classify, which is determined by user prompts, may come from a wide range of distributions. In this paper, we show that the performance of controlled generation may be poor if the distributions of text in response to user prompts differ from the distribution the predictor was trained on. To address this problem, we cast controlled generation under distribution shift as an invariant learning problem: the most effective predictor should be invariant across multiple text environments. We then discuss a natural solution that arises from this characterization and propose heuristics for selecting natural en
    
[^25]: 通过使用文本蕴含反馈的强化学习实现事实一致性摘要

    Factually Consistent Summarization via Reinforcement Learning with Textual Entailment Feedback. (arXiv:2306.00186v1 [cs.CL])

    [http://arxiv.org/abs/2306.00186](http://arxiv.org/abs/2306.00186)

    本研究使用带有文本蕴含奖励的强化学习来实现抽象摘要系统的事实一致性，从而提高了生成的摘要的忠实度、明显性和简洁性。

    

    尽管当代的文本生成系统表现出表面上的成功，但它们往往会生成与其输入不相符的错误文本。这种现象在摘要等任务中更加突出，因为生成的摘要应该得到其来源文章的证实。本研究利用最近在文本蕴含模型上的进展来直接解决抽象摘要系统中的这个问题。我们使用强化学习与无需参考的文本蕴含奖励来优化事实的一致性，并探索随之而来的权衡，因为改进的一致性可能会以摘要的信息量少或更提取为代价。根据自动指标和人类评估，我们的结果显示，我们的方法显着提高了生成的摘要的忠实度、明显性和简洁性。

    Despite the seeming success of contemporary grounded text generation systems, they often tend to generate factually inconsistent text with respect to their input. This phenomenon is emphasized in tasks like summarization, in which the generated summaries should be corroborated by their source article. In this work, we leverage recent progress on textual entailment models to directly address this problem for abstractive summarization systems. We use reinforcement learning with reference-free, textual entailment rewards to optimize for factual consistency and explore the ensuing trade-offs, as improved consistency may come at the cost of less informative or more extractive summaries. Our results, according to both automatic metrics and human evaluation, show that our method considerably improves the faithfulness, salience, and conciseness of the generated summaries.
    
[^26]: 面向科学文献摘要的对比分层话语图模型

    Contrastive Hierarchical Discourse Graph for Scientific Document Summarization. (arXiv:2306.00177v1 [cs.CL])

    [http://arxiv.org/abs/2306.00177](http://arxiv.org/abs/2306.00177)

    本文提出了CHANGES，一种对比分层图神经网络，用于提取科学论文的摘要。该模型能够使用分层话语图和图对比学习模块，学习有效的句子表示，并在实验中证明了其有效性和在建模科学论文时捕捉分层结构信息的重要性。

    

    在扩展的结构上下文条件下，科学论文摘要成为一项具有挑战性的任务。本文提出了一个名为CHANGES的对比分层图神经网络，以提取科学论文摘要。该模型将科学论文表示为一个分层的话语图，并使用专门设计的分层图信息聚合方法学习有效的句子表示。同时，本文还提出了一个图对比学习模块，以学习全局的主题感知句子表示。在PubMed和arXiv基准数据集上的大量实验结果证明了CHANGES的有效性以及在建模科学论文时捕捉分层结构信息的重要性。

    The extended structural context has made scientific paper summarization a challenging task. This paper proposes CHANGES, a contrastive hierarchical graph neural network for extractive scientific paper summarization. CHANGES represents a scientific paper with a hierarchical discourse graph and learns effective sentence representations with dedicated designed hierarchical graph information aggregation. We also propose a graph contrastive learning module to learn global theme-aware sentence representations. Extensive experiments on the PubMed and arXiv benchmark datasets prove the effectiveness of CHANGES and the importance of capturing hierarchical structure information in modeling scientific papers.
    
[^27]: 基于生成式人工智能的自动标注需要验证

    Automated Annotation with Generative AI Requires Validation. (arXiv:2306.00176v1 [cs.CL])

    [http://arxiv.org/abs/2306.00176](http://arxiv.org/abs/2306.00176)

    本文探讨了利用生成式大型语言模型进行文本注释的自动化流程，强调必须针对人类生成的标签验证它们的性能，验证结果表明LLM的性能很有前途，但高度依赖于数据集和注释任务类型。

    

    生成式大型语言模型（LLM）可以成为文本注释过程的强大工具，但由于提示质量，文本数据特定性和概念难度等原因，它们的性能在注释任务方面存在差异。因为即使LLM技术得到改进，这些挑战仍将存在，所以我们认为使用LLM的任何自动标注过程都必须针对人类生成的标签验证LLM的性能。为此，我们概述了一个工作流程，以一种原则性和有效率的方式利用LLM的注释潜力。使用GPT-4，我们通过在高影响期刊的最新社会科学文章中复制11个数据集的27个标注任务来验证这种方法。我们发现，对于文本注释，LLM的性能很有前途，但高度取决于数据集和注释任务类型，这强调了按任务验证的必要性。我们提供易于使用的软件，旨在实现我们的工作流程并简化操作。

    Generative large language models (LLMs) can be a powerful tool for augmenting text annotation procedures, but their performance varies across annotation tasks due to prompt quality, text data idiosyncrasies, and conceptual difficulty. Because these challenges will persist even as LLM technology improves, we argue that any automated annotation process using an LLM must validate the LLM's performance against labels generated by humans. To this end, we outline a workflow to harness the annotation potential of LLMs in a principled, efficient way. Using GPT-4, we validate this approach by replicating 27 annotation tasks across 11 datasets from recent social science articles in high-impact journals. We find that LLM performance for text annotation is promising but highly contingent on both the dataset and the type of annotation task, which reinforces the necessity to validate on a task-by-task basis. We make available easy-to-use software designed to implement our workflow and streamline the
    
[^28]: 衡量自然语言处理模型面对领域转移的鲁棒性

    Measuring the Robustness of Natural Language Processing Models to Domain Shifts. (arXiv:2306.00168v1 [cs.CL])

    [http://arxiv.org/abs/2306.00168](http://arxiv.org/abs/2306.00168)

    本文探讨了自然领域转移设置下微调和小样本学习模型的DR挑战，引入了一个DR基准，提出了DR挑战的两个视角：源域降低（SD）和目标域降低（TD），并发现两者之一通常是正值，强调了评估DR挑战的两个视角的重要性。

    

    大型语言模型在各种任务中表现出了很好的性能，包括微调、小样本学习和零样本学习。然而，它们在没有标记数据的领域中的性能仍然落后于有标记数据的领域，我们称之为领域鲁棒性（DR）挑战。现有的DR研究存在不一致的设置、缺乏评估任务的多样性和过多依靠挑战集。在本文中，我们探讨了自然领域转移设置下微调和小样本学习模型的DR挑战。我们引入了一个DR基准，包括多样化的NLP任务，包括句子和标记级分类、问答和生成，每个任务都由几个领域组成。我们提出了DR挑战的两个视角：源域降低（SD）和目标域降低（TD），它们交替作为参考点来比较源域和目标域的性能。我们发现，在重大比例的领域转移中，SD或TD之一是正的，但不是两者都正，强调了评估DR挑战的两个视角的重要性。我们的基准允许在模型、任务和设置上公平比较DR，并提供有关NLP模型DR性质的见解。

    Large Language Models have shown promising performance on various tasks, including fine-tuning, few-shot learning, and zero-shot learning. However, their performance on domains without labeled data still lags behind those with labeled data, which we refer as the Domain Robustness (DR) challenge. Existing research on DR suffers from disparate setups, lack of evaluation task variety, and reliance on challenge sets. In this paper, we explore the DR challenge of both fine-tuned and few-shot learning models in natural domain shift settings. We introduce a DR benchmark comprising diverse NLP tasks, including sentence and token-level classification, QA, and generation, each task consists of several domains. We propose two views of the DR challenge: Source Drop (SD) and Target Drop (TD), which alternate between the source and target in-domain performance as reference points. We find that in significant proportions of domain shifts, either SD or TD is positive, but not both, emphasizing the imp
    
[^29]: 一种文本到表格生成的序列到序列&集合模型

    A Sequence-to-Sequence&Set Model for Text-to-Table Generation. (arXiv:2306.00137v1 [cs.CL])

    [http://arxiv.org/abs/2306.00137](http://arxiv.org/abs/2306.00137)

    这篇论文提出了一种序列、序列和集合模型，以解决文本到表格生成任务中的两个常见问题。与现有方法相比，该模型更具灵活性和实用性，可产生更准确的结果。

    

    最近，文本到表格生成任务因其广泛应用而受到越来越多的关注。在这个方面，主导模型将该任务形式化为序列到序列生成任务，并通过在训练期间将每个表格串行化为令牌序列，通过从上到下连接所有行。然而，它存在两个严重缺陷：1）预定义的顺序在训练期间引入了错误的偏差，高度惩罚行之间的顺序移动；2）当模型输出长标记序列时，错误传播问题变得严重。在本文中，我们首先进行了初步研究，以证明大多数行的生成是和顺序无关的。此外，我们提出了一种新的序列到序列&集合文本到表格生成模型。具体而言，除了文本编码器之外，我们的模型还配备了一个表头生成器，以顺序方式首先输出表头，即表格的第一行。

    Recently, the text-to-table generation task has attracted increasing attention due to its wide applications. In this aspect, the dominant model formalizes this task as a sequence-to-sequence generation task and serializes each table into a token sequence during training by concatenating all rows in a top-down order. However, it suffers from two serious defects: 1) the predefined order introduces a wrong bias during training, which highly penalizes shifts in the order between rows; 2) the error propagation problem becomes serious when the model outputs a long token sequence. In this paper, we first conduct a preliminary study to demonstrate the generation of most rows is order-insensitive. Furthermore, we propose a novel sequence-to-sequence&set text-to-table generation model. Specifically, in addition to a text encoder encoding the input text, our model is equipped with a table header generator to first output a table header, i.e., the first row of the table, in the manner of sequence 
    
[^30]: 面向多语言解析和生成的预训练语言-语义模型

    Pre-Trained Language-Meaning Models for Multilingual Parsing and Generation. (arXiv:2306.00124v1 [cs.CL])

    [http://arxiv.org/abs/2306.00124](http://arxiv.org/abs/2306.00124)

    本文提出了一种基于DRS的多语言预训练语言-语义模型，可以同时处理自然语言文本和意义表示，并通过跨语言迁移学习来提高非英语任务的性能。实验表明，该模型在多语言DRS解析和DRS到文本生成任务上表现最佳，且可以大大降低多语言语义注释的成本。

    

    预训练语言模型（PLMs）在自然语言处理（NLP）中取得了巨大成功，并近期被用于计算语义任务。然而，这些任务并没有充分受益于PLMs，因为意义表示并未在预训练阶段显式包括。本文引入了基于语篇表示结构（DRSs）的多语言预训练语言-语义模型，将自然语言文本和意义表示同时包含在一个模型中，并设计了一种新的策略来减少预训练和微调目标之间的差距。由于DRS是语言中立的，该模型采用跨语言迁移学习进一步提高非英语任务的性能。自动评估结果表明，我们的方法在多语言DRS解析和DRS到文本生成任务上都取得了最佳性能。关于生成任务的自动度量和人类判断之间的相关性分析进一步验证了我们模型的有效性。人类评估结果还表明，我们的模型可以大大降低多语言语义注释的成本。

    Pre-trained language models (PLMs) have achieved great success in NLP and have recently been used for tasks in computational semantics. However, these tasks do not fully benefit from PLMs since meaning representations are not explicitly included in the pre-training stage. We introduce multilingual pre-trained language-meaning models based on Discourse Representation Structures (DRSs), including meaning representations besides natural language texts in the same model, and design a new strategy to reduce the gap between the pre-training and fine-tuning objectives. Since DRSs are language neutral, cross-lingual transfer learning is adopted to further improve the performance of non-English tasks. Automatic evaluation results show that our approach achieves the best performance on both the multilingual DRS parsing and DRS-to-text generation tasks. Correlation analysis between automatic metrics and human judgements on the generation task further validates the effectiveness of our model. Huma
    
[^31]: 多语言多比喻语言检测

    Multilingual Multi-Figurative Language Detection. (arXiv:2306.00121v1 [cs.CL])

    [http://arxiv.org/abs/2306.00121](http://arxiv.org/abs/2306.00121)

    该论文提出了多语言多比喻语言建模的框架，并提供了基准句子级比喻语言检测。通过基于模板的提示学习，统一了跨多个修辞手法和语言相关的多个检测任务，实验结果表明其比强大的基线模型更加优秀。

    

    比喻语言有助于人们表达抽象概念、唤起比字面表达更强的情感，从而使文本更加有创造力和吸引力。尽管比喻语言理解在自然语言处理中得到了广泛研究，但在多语言环境和考虑多个修辞手法时，其研究仍然非常有限。为了弥补这一差距，我们引入了多语言多比喻语言建模，并提供了一个基准句子级比喻语言检测，涵盖了三种常见的修辞手法和七种语言。具体而言，我们基于基于模板的提示学习开发了一个比喻语言检测框架。通过这样做，我们统一了跨多个修辞手法和语言相关的多个检测任务，而无需特定于任务或语言的模块。实验结果表明，我们的框架优于几个强大的基线模型。

    Figures of speech help people express abstract concepts and evoke stronger emotions than literal expressions, thereby making texts more creative and engaging. Due to its pervasive and fundamental character, figurative language understanding has been addressed in Natural Language Processing, but it's highly understudied in a multilingual setting and when considering more than one figure of speech at the same time. To bridge this gap, we introduce multilingual multi-figurative language modelling, and provide a benchmark for sentence-level figurative language detection, covering three common figures of speech and seven languages. Specifically, we develop a framework for figurative language detection based on template-based prompt learning. In so doing, we unify multiple detection tasks that are interrelated across multiple figures of speech and languages, without requiring task- or language-specific modules. Experimental results show that our framework outperforms several strong baselines
    
[^32]: MuseCoco: 从文本生成符号音乐

    MuseCoco: Generating Symbolic Music from Text. (arXiv:2306.00110v1 [cs.SD])

    [http://arxiv.org/abs/2306.00110](http://arxiv.org/abs/2306.00110)

    MuseCoco是一种从文本描述中生成符号音乐的系统，具备高效和灵活等特点，为音乐家提供了更好的音乐生成方式。

    

    从文本描述中生成音乐是一种用户友好的方式，因为文本是相对易于用户参与的界面。而有些方法利用文本来控制音乐音频的生成，但是编辑生成音频的音乐元素对于用户来说是具有挑战性的。相比之下，符号音乐具有易于编辑的优点，使用户更容易操作特定的音乐元素。本文介绍了MuseCoco，它利用音乐属性作为桥梁，将任务分解为文本到属性理解和属性到音乐生成的两个阶段，从而生成符号音乐。MuseCoCo代表音乐作曲副驾驶，使音乐家可以直接从给定的文本描述中生成音乐，与从头开始创作相比，大大提高了效率。该系统具有两个主要优点：数据高效。在属性到音乐生成阶段，属性可以直接进行编码，而不需要大量的音乐数据。其次，此系统具有高级别的灵活性，因为它可以通过变更文本输入来生成多样化且有个性的符号音乐。

    Generating music from text descriptions is a user-friendly mode since the text is a relatively easy interface for user engagement. While some approaches utilize texts to control music audio generation, editing musical elements in generated audio is challenging for users. In contrast, symbolic music offers ease of editing, making it more accessible for users to manipulate specific musical elements. In this paper, we propose MuseCoco, which generates symbolic music from text descriptions with musical attributes as the bridge to break down the task into text-to-attribute understanding and attribute-to-music generation stages. MuseCoCo stands for Music Composition Copilot that empowers musicians to generate music directly from given text descriptions, offering a significant improvement in efficiency compared to creating music entirely from scratch. The system has two main advantages: Firstly, it is data efficient. In the attribute-to-music generation stage, the attributes can be directly e
    
[^33]: MERT:带有大规模自监督训练的声学音乐理解模型

    MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training. (arXiv:2306.00107v1 [cs.SD])

    [http://arxiv.org/abs/2306.00107](http://arxiv.org/abs/2306.00107)

    提出了一个带有大规模自监督训练的音乐理解模型MERT，利用了教师模型并采用了一种优于传统的语音和音频方法的组合方式。

    

    自监督学习（SSL）最近在视觉、文本和语音领域中已被证明是训练通用模型的一种很有前景的范例，对于跨越音乐领域的应用，尤其是对于调性和音高这样的特殊音乐知识的建模颇具挑战性。为了解决这一问题，我们提出了一个基于大规模自监督训练的声学音乐理解模型，即MERT。在我们的探索中，我们确定了更优秀的教师模型组合，这种组合方法在性能方面优于传统的语音和音频方法。

    Self-supervised learning (SSL) has recently emerged as a promising paradigm for training generalisable models on large-scale data in the fields of vision, text, and speech. Although SSL has been proven effective in speech and audio, its application to music audio has yet to be thoroughly explored. This is primarily due to the distinctive challenges associated with modelling musical knowledge, particularly its tonal and pitched characteristics of music. To address this research gap, we propose an acoustic Music undERstanding model with large-scale self-supervised Training (MERT), which incorporates teacher models to provide pseudo labels in the masked language modelling (MLM) style acoustic pre-training. In our exploration, we identified a superior combination of teacher models, which outperforms conventional speech and audio approaches in terms of performance. This combination includes an acoustic teacher based on Residual Vector Quantization - Variational AutoEncoder (RVQ-VAE) and a m
    
[^34]: ManagerTower：聚合单模态专家见解用于视觉语言表示学习

    ManagerTower: Aggregating the Insights of Uni-Modal Experts for Vision-Language Representation Learning. (arXiv:2306.00103v1 [cs.CV])

    [http://arxiv.org/abs/2306.00103](http://arxiv.org/abs/2306.00103)

    提出了ManagerTower，一种新型的VL模型体系结构，可以集合并组合不同级别的预先训练的单模态专家的见解，并可以自适应地聚合单模态语义知识以促进更全面的跨模态对齐和融合。仅使用4M VLP数据，ManagerTower在各种下游VL任务中都取得了更好的性能，尤其是在VQAv2测试标准下达到了79.15%的准确率，在Flickr30K上的IR@1为86.56% TR@1为95.64%。

    

    两塔视觉语言模型已经在各种下游视觉语言任务上显示出有希望的改进。尽管最先进的工作通过构建编码器之间的桥梁来提高性能，但它遭受了单模态表示的逐层利用效果不佳的困境，并且不能灵活地利用不同级别的单模态语义知识。在这项工作中，我们提出了ManagerTower，这是一种新型的VL模型体系结构，它集合并组合了预先训练的不同级别的单模态专家的见解。在每个跨模态层中引入的管理器可以自适应地聚合单模态语义知识，以促进更全面的跨模态对齐和融合。ManagerTower在有和没有视觉语言预训练(VLP)的情况下都优于以前的强基线。仅使用4M VLP数据，ManagerTower在各种下游VL任务中都取得了更好的性能，尤其是在VQAv2测试标准下达到了79.15%的准确率，在Flickr30K上的IR@1为86.56% TR@1为95.64%。Code and check

    Two-Tower Vision-Language (VL) models have shown promising improvements on various downstream VL tasks. Although the most advanced work improves performance by building bridges between encoders, it suffers from ineffective layer-by-layer utilization of uni-modal representations and cannot flexibly exploit different levels of uni-modal semantic knowledge. In this work, we propose ManagerTower, a novel VL model architecture that gathers and combines the insights of pre-trained uni-modal experts at different levels. The managers introduced in each cross-modal layer can adaptively aggregate uni-modal semantic knowledge to facilitate more comprehensive cross-modal alignment and fusion. ManagerTower outperforms previous strong baselines both with and without Vision-Language Pre-training (VLP). With only 4M VLP data, ManagerTower achieves superior performances on various downstream VL tasks, especially 79.15% accuracy on VQAv2 Test-Std, 86.56% IR@1 and 95.64% TR@1 on Flickr30K. Code and check
    
[^35]: 自我验证改善少样本临床信息提取

    Self-Verification Improves Few-Shot Clinical Information Extraction. (arXiv:2306.00024v1 [cs.CL])

    [http://arxiv.org/abs/2306.00024](http://arxiv.org/abs/2306.00024)

    本文探索了一种利用自我验证的通用缓解框架，该框架利用语言模型为其自我提取提供权威性并检查其自己的输出。在临床信息提取任务中，该方法能够显著提高各种LLMs的准确性，并展示了极好的可解释性和认知增强效果。

    

    从非结构化文本中提取患者信息是卫生决策支持和临床研究的关键任务。大型语言模型（LLM）展示了通过少量上下文学习加速临床管理的潜力，相较于需要更昂贵的人工注释的监督学习。然而，尽管现代LLM（如GPT-4）取得了巨大进步，它们仍然存在精度和可解释性等问题，特别是在关键任务领域（如健康）。在这里，我们通过自我验证，探索了一种通用的缓解框架，该框架利用LLM为其自我提取提供权威性并检查自己的输出。这得益于验证和生成之间的不对称性，后者通常比前者容易得多。实验结果表明，我们的方法在标准临床信息提取任务中，对于各种LLM都能持续提高准确性。此外，自我验证产生了极好的可解释性和认知增强效果。

    Extracting patient information from unstructured text is a critical task in health decision-support and clinical research. Large language models (LLMs) have shown the potential to accelerate clinical curation via few-shot in-context learning, in contrast to supervised learning which requires much more costly human annotations. However, despite drastic advances in modern LLMs such as GPT-4, they still struggle with issues regarding accuracy and interpretability, especially in mission-critical domains such as health. Here, we explore a general mitigation framework using self-verification, which leverages the LLM to provide provenance for its own extraction and check its own outputs. This is made possible by the asymmetry between verification and generation, where the latter is often much easier than the former. Experimental results show that our method consistently improves accuracy for various LLMs in standard clinical information extraction tasks. Additionally, self-verification yields
    
[^36]: 采用模型无关方法解释仇恨言论分类

    Explaining Hate Speech Classification with Model Agnostic Methods. (arXiv:2306.00021v1 [cs.CL])

    [http://arxiv.org/abs/2306.00021](http://arxiv.org/abs/2306.00021)

    本文旨在解释仇恨言论分类，采用双向变形器模型BERT进行预测，并提供后验的模型无关和代理可解释性方法，以支持模型的解释性并防止模型偏差。

    

    机器学习和人工智能在自然语言处理和深度学习领域取得了显著突破。随着社交媒体的广泛使用，对话中的仇恨言论检测也在自然语言处理研究人员中变得越来越受欢迎。然而，正如最近的趋势所表明的那样，在AI模型中加入可解释性和可解释性维度的需求已经得到深刻的认识。本文的研究目标是要在仇恨言论预测与系统生成的解释之间搭建桥梁。通过首先预测文本的分类，然后提供一个后验的模型无关和代理可解释性方法来支持模型的解释性并防止模型偏差。采用双向变形器模型BERT进行预测，因为它在自然语言处理的机器学习模型中具有最先进的效率。

    There have been remarkable breakthroughs in Machine Learning and Artificial Intelligence, notably in the areas of Natural Language Processing and Deep Learning. Additionally, hate speech detection in dialogues has been gaining popularity among Natural Language Processing researchers with the increased use of social media. However, as evidenced by the recent trends, the need for the dimensions of explainability and interpretability in AI models has been deeply realised. Taking note of the factors above, the research goal of this paper is to bridge the gap between hate speech prediction and the explanations generated by the system to support its decision. This has been achieved by first predicting the classification of a text and then providing a posthoc, model agnostic and surrogate interpretability approach for explainability and to prevent model bias. The bidirectional transformer model BERT has been used for prediction because of its state of the art efficiency over other Machine Lea
    
[^37]: GPT4GEO：一个语言模型如何看待世界地理

    GPT4GEO: How a Language Model Sees the World's Geography. (arXiv:2306.00020v1 [cs.CL])

    [http://arxiv.org/abs/2306.00020](http://arxiv.org/abs/2306.00020)

    研究调查了GPT-4的地理知识水平，并探讨其在地理数据分析等领域的应用潜力。

    

    大型语言模型（LLM）在涉及问题回答、生成连贯文本和代码的广泛任务中展现出了卓越的能力。全面理解LLM的优点和缺点对于安全、下游应用和性能改进都有益处。在本研究中，我们调查了GPT-4获得事实地理知识的程度，并能否将这些知识用于解释性推理，这对于涉及地理数据的应用（如地理空间分析、供应链管理和灾难响应）尤其重要。为此，我们设计并进行了一系列多样化的实验，从定位、距离和高度估计等事实任务开始，到生成国家轮廓和旅游网络、在约束条件下寻找路线和供应链分析等更复杂的问题。我们提供了GPT-4（没有插件或Internet访问）了解和不了解世界地理的广泛描述，并讨论了在地理空间领域应用的影响。

    Large language models (LLMs) have shown remarkable capabilities across a broad range of tasks involving question answering and the generation of coherent text and code. Comprehensively understanding the strengths and weaknesses of LLMs is beneficial for safety, downstream applications and improving performance. In this work, we investigate the degree to which GPT-4 has acquired factual geographic knowledge and is capable of using this knowledge for interpretative reasoning, which is especially important for applications that involve geographic data, such as geospatial analysis, supply chain management, and disaster response. To this end, we design and conduct a series of diverse experiments, starting from factual tasks such as location, distance and elevation estimation to more complex questions such as generating country outlines and travel networks, route finding under constraints and supply chain analysis. We provide a broad characterisation of what GPT-4 (without plugins or Interne
    
[^38]: 利用多项式朴素贝叶斯算法和Term Frequency Inverse Document Frequency (TF-IDF向量化器)检查菲律宾新闻推文的可信度。

    Utilization of Multinomial Naive Bayes Algorithm and Term Frequency Inverse Document Frequency (TF-IDF Vectorizer) in Checking the Credibility of News Tweet in the Philippines. (arXiv:2306.00018v1 [cs.CL])

    [http://arxiv.org/abs/2306.00018](http://arxiv.org/abs/2306.00018)

    本文利用多项式朴素贝叶斯算法和TF-IDF向量化器检查菲律宾新闻推文的可信度，在训练和预测中表现良好。建议进一步改进语料库收集，并使用集成机器学习来加强预测。

    

    新闻媒体的数字化成为进步的良好指标，也是更多威胁的信号。虚假信息或假新闻是其中之一，有必要采取行动来打击虚假信息。本文利用基于真实标注的注释和TF-IDF作为特征提取新闻文章，然后用作Multinomial Naive Bayes的训练数据集。该模型在训练时的准确率为99.46％，在预测未见数据时为88.98％。将假新闻标记为真新闻是预测中的一个关注点，在F1得分中表现为89.68％。这可能会产生负面影响。为了防止这种情况发生，建议进一步改进语料库收集，并使用集成机器学习来加强预测。

    The digitalization of news media become a good indicator of progress and signal to more threats. Media disinformation or fake news is one of these threats, and it is necessary to take any action in fighting disinformation. This paper utilizes ground truth-based annotations and TF-IDF as feature extraction for the news articles which is then used as a training data set for Multinomial Naive Bayes. The model has an accuracy of 99.46% in training and 88.98% in predicting unseen data. Tagging fake news as real news is a concerning point on the prediction that is indicated in the F1 score of 89.68%. This could lead to a negative impact. To prevent this to happen it is suggested to further improve the corpus collection, and use an ensemble machine learning to reinforce the prediction
    
[^39]: 向可解释的、语言无关的LLMs迈进：大规模语言符号逆向工程

    Towards Explainable and Language-Agnostic LLMs: Symbolic Reverse Engineering of Language at Scale. (arXiv:2306.00017v1 [cs.CL])

    [http://arxiv.org/abs/2306.00017](http://arxiv.org/abs/2306.00017)

    本文提出结合符号表示和自下而上的逆向工程的方法，解决大规模语言模型在真正语言理解上的局限性，实现可解释的、语言无关的LLMs。

    

    大型语言模型（LLMs）取得了一个里程碑，无可否认地改变了人工智能（AI）中许多信仰。然而，当涉及真正的语言理解时，这些LLM的许多限制仍然存在，这些限制是深度神经网络底层架构的副产品。此外，由于它们的亚符号性质，这些模型获得有关语言如何运作的任何知识都将被埋在数十亿个微特征（权重）中，其中没有一个单独的特征有意义，使得这些模型无法解释。为了解决这些限制，我们建议将符号表示的强度与我们认为是LLMs成功的关键结合起来，即在规模上成功地进行自下而上的语言逆向工程。因此，我们主张在符号设置下对语言进行自下而上的逆向工程。一些作者提出了这个项目的提示，我们将进行详细讨论。

    Large language models (LLMs) have achieved a milestone that undenia-bly changed many held beliefs in artificial intelligence (AI). However, there remains many limitations of these LLMs when it comes to true language understanding, limitations that are a byproduct of the under-lying architecture of deep neural networks. Moreover, and due to their subsymbolic nature, whatever knowledge these models acquire about how language works will always be buried in billions of microfeatures (weights), none of which is meaningful on its own, making such models hopelessly unexplainable. To address these limitations, we suggest com-bining the strength of symbolic representations with what we believe to be the key to the success of LLMs, namely a successful bottom-up re-verse engineering of language at scale. As such we argue for a bottom-up reverse engineering of language in a symbolic setting. Hints on what this project amounts to have been suggested by several authors, and we discuss in some detail
    
[^40]: 面向预训练语言模型的通用量化方法PreQuant

    PreQuant: A Task-agnostic Quantization Approach for Pre-trained Language Models. (arXiv:2306.00014v1 [cs.CL])

    [http://arxiv.org/abs/2306.00014](http://arxiv.org/abs/2306.00014)

    本文提出了一种新颖的“量化前微调”框架 PreQuant，可用于预训练语言模型的通用量化，有效降低了模型的复杂度和使用成本。

    

    近年来，基于transformer的预训练语言模型（PLMs）已经在许多NLP应用中占据主导地位，但这些模型部署复杂、使用昂贵，因此有效压缩大规模PLMs变得越来越重要。量化是一种可行的解决方案，它用低比特定点格式表示高精度张量。本文提出了一种新颖的“量化前微调”框架PreQuant，它与各种量化策略兼容，并结合“异常值感知参数高效微调”进行校正。

    While transformer-based pre-trained language models (PLMs) have dominated a number of NLP applications, these models are heavy to deploy and expensive to use. Therefore, effectively compressing large-scale PLMs becomes an increasingly important problem. Quantization, which represents high-precision tensors with low-bit fix-point format, is a viable solution. However, most existing quantization methods are task-specific, requiring customized training and quantization with a large number of trainable parameters on each individual task. Inspired by the observation that the over-parameterization nature of PLMs makes it possible to freeze most of the parameters during the fine-tuning stage, in this work, we propose a novel ``quantize before fine-tuning'' framework, PreQuant, that differs from both quantization-aware training and post-training quantization. PreQuant is compatible with various quantization strategies, with outlier-aware parameter-efficient fine-tuning incorporated to correct 
    
[^41]: 癌症实体的关联和分类的机器学习方法

    Machine Learning Approach for Cancer Entities Association and Classification. (arXiv:2306.00013v1 [cs.CL])

    [http://arxiv.org/abs/2306.00013](http://arxiv.org/abs/2306.00013)

    本研究利用命名实体识别和文本分类的机器学习方法自动从大量生物医学文献中提取癌症相关实体和实体间关系，以帮助推进癌症研究进展。

    

    根据世界卫生组织（WHO）的数据，癌症是全球第二大死因。不同类型癌症的科学研究以每年发布大量的研究文章的速度不断增长。与基因相关的药物、诊断、风险、症状、治疗等的信息和知识是帮助探索和推进癌症研究进展的重要因素。手动筛选这么大量的文章非常费时费力，很难制定任何假设。本研究使用两种最为重要的自然语言处理（NLP）功能，实体识别和文本分类，从生物医学文献中发现知识。命名实体识别（NER）借助用户友好的界面和内置字典识别并提取与癌症相关的预定义实体。文本分类采用机器学习方法，帮助探究癌症实体之间的关系。

    According to the World Health Organization (WHO), cancer is the second leading cause of death globally. Scientific research on different types of cancers grows at an ever-increasing rate, publishing large volumes of research articles every year. The insight information and the knowledge of the drug, diagnostics, risk, symptoms, treatments, etc., related to genes are significant factors that help explore and advance the cancer research progression. Manual screening of such a large volume of articles is very laborious and time-consuming to formulate any hypothesis. The study uses the two most non-trivial NLP, Natural Language Processing functions, Entity Recognition, and text classification to discover knowledge from biomedical literature. Named Entity Recognition (NER) recognizes and extracts the predefined entities related to cancer from unstructured text with the support of a user-friendly interface and built-in dictionaries. Text classification helps to explore the insights into the 
    
[^42]: Brainformers：以效率换取简洁性

    Brainformers: Trading Simplicity for Efficiency. (arXiv:2306.00008v1 [cs.LG])

    [http://arxiv.org/abs/2306.00008](http://arxiv.org/abs/2306.00008)

    Brainformers 是一个新的深度神经网络模型，它通过使用多样层级的结构完善了 Transformer 的设计缺陷，具有更高效的训练收敛和更快的步骤时间，表现出更优秀的性能。

    

    Transformer 是自然语言处理和计算机视觉的最近成功的核心技术。Transformer 具有一个几乎统一的骨架，其中层次在前馈和自注意力之间交替以建立深度网络。在本文中，我们研究了这种设计选择，并发现更复杂的块可以更高效地完成任务。根据这个发现，我们提出了一个复杂的块，称为 Brainformer，它由各种形式的层归一化和激活函数、稀疏门控前馈层、密集前馈层、注意力层等多样层级组成。在质量和效率方面，Brainformer 总是优于现有的稠密和稀疏 Transformer。一个具有 80 亿个每个标记激活参数的 Brainformer 模型，相比于其 GLaM 对应物，表现出 2 倍更快的训练收敛和 5 倍更快的步骤时间。在下游任务评估中，Brainformer 也表现得更优秀。

    Transformers are central to recent successes in natural language processing and computer vision. Transformers have a mostly uniform backbone where layers alternate between feed-forward and self-attention in order to build a deep network. Here we investigate this design choice and find that more complex blocks that have different permutations of layer primitives can be more efficient. Using this insight, we develop a complex block, named Brainformer, that consists of a diverse sets of layers such as sparsely gated feed-forward layers, dense feed-forward layers, attention layers, and various forms of layer normalization and activation functions. Brainformer consistently outperforms the state-of-the-art dense and sparse Transformers, in terms of both quality and efficiency. A Brainformer model with 8 billion activated parameters per token demonstrates 2x faster training convergence and 5x faster step time compared to its GLaM counterpart. In downstream task evaluation, Brainformer also de
    
[^43]: 葡语法律语义文本相似性数据集：比较弱监督和注释过程方法

    Datasets for Portuguese Legal Semantic Textual Similarity: Comparing weak supervision and an annotation process approaches. (arXiv:2306.00007v1 [cs.CL])

    [http://arxiv.org/abs/2306.00007](http://arxiv.org/abs/2306.00007)

    本文提供了四个法律领域的数据集，其中两个未标记，另外两个使用启发式标签进行了标记，旨在用于文本语义相似性任务。研究比较了弱监督和传统注释过程方法，表明弱监督可以达到与传统方法相当的性能。

    

    巴西司法机关工作量大，导致司法程序时间长。巴西国家司法委员会在469/2022号决议中制定了数字化文件和流程的正式指导方针，开拓了在法律领域中使用自动技术以帮助日常任务的可能性，尤其是在大量文本的情况下。人工智能技术允许从文本数据中处理和提取有用信息，潜在地加快该过程。然而，多个人工智能技术所需的法律领域数据集很少且难以获得，因为它们需要专家的标签。为了解决这一挑战，本文为法律领域贡献了四个数据集，其中两个具有文档和元数据但未标记，另外两个则标记了启发式标签，旨在用于文本语义相似性任务。此外，为了评估使用弱监督创建语义文本相似性标记数据集的有效性，我们将其与传统的注释过程进行了比较。结果表明，弱监督可以是一个可行的选择，达到了与传统方法相当的性能。

    The Brazilian judiciary has a large workload, resulting in a long time to finish legal proceedings. Brazilian National Council of Justice has established in Resolution 469/2022 formal guidance for document and process digitalization opening up the possibility of using automatic techniques to help with everyday tasks in the legal field, particularly in a large number of texts yielded on the routine of law procedures. Notably, Artificial Intelligence (AI) techniques allow for processing and extracting useful information from textual data, potentially speeding up the process. However, datasets from the legal domain required by several AI techniques are scarce and difficult to obtain as they need labels from experts. To address this challenge, this article contributes with four datasets from the legal domain, two with documents and metadata but unlabeled, and another two labeled with a heuristic aiming at its use in textual semantic similarity tasks. Also, to evaluate the effectiveness of 
    
[^44]: 一种用于高效ICD编码的两阶段解码器

    A Two-Stage Decoder for Efficient ICD Coding. (arXiv:2306.00005v1 [cs.CL])

    [http://arxiv.org/abs/2306.00005](http://arxiv.org/abs/2306.00005)

    本文提出了一个基于两阶段解码机制的模型，利用代码的层次属性将预测分解为两个步骤，实现对ICD代码的高效预测。

    

    医疗保健机构中的临床记录将使用国际疾病分类（ICD）编码标记; 这是一组用于医疗诊断和手术的分类编码。由于嘈杂的临床文档输入和长尾式标签分布，ICD编码是一个具有挑战性的多标签文本分类问题。最近的自动ICD编码方法通过额外的数据和知识库对医疗笔记和代码进行编码以提高性能。然而，他们大多数不反映出人类编码者如何生成代码：首先，编码员选择通用代码类别，然后查找与患者情况相关的具体子类别。受此启发，我们提出了一种两阶段解码机制来预测ICD代码。我们的模型利用代码的层次属性将预测分解为两个步骤：首先，我们预测父代码，然后根据之前的预测预测子代码。公共MIMIC-III数据集上的实验表明，我们的方法在准确性方面具有竞争力。

    Clinical notes in healthcare facilities are tagged with the International Classification of Diseases (ICD) code; a list of classification codes for medical diagnoses and procedures. ICD coding is a challenging multilabel text classification problem due to noisy clinical document inputs and long-tailed label distribution. Recent automated ICD coding efforts improve performance by encoding medical notes and codes with additional data and knowledge bases. However, most of them do not reflect how human coders generate the code: first, the coders select general code categories and then look for specific subcategories that are relevant to a patient's condition. Inspired by this, we propose a two-stage decoding mechanism to predict ICD codes. Our model uses the hierarchical properties of the codes to split the prediction into two steps: At first, we predict the parent code and then predict the child code based on the previous prediction. Experiments on the public MIMIC-III data set show that 
    
[^45]: 以决策为导向的人机对话

    Decision-Oriented Dialogue for Human-AI Collaboration. (arXiv:2305.20076v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.20076](http://arxiv.org/abs/2305.20076)

    该论文探讨了一类以决策为导向的人机对话任务，以及在会议论文审稿人分配、城市多步行程规划和旅行计划协商等场景中，人工智能助手和用户不同的能力如何结合以达到最佳决策。论文通过构建对话环境并进行人机对话收集数据，发现当前人工智能助手在此类任务中的局限性。

    

    我们描述了一类任务，称为以决策为导向的对话，其中人工智能助手必须通过自然语言与一名或多名人类合作，帮助他们做出复杂的决策。我们在三个领域中形式化用户面临日常决策的过程：（1）选择会议论文的审稿人分配，（2）在城市中规划多步行程，以及（3）为一群朋友协商旅行计划。在每个设置中，AI助手和用户具有不同的能力，他们必须结合起来得出最佳决策：助手可以访问和处理大量信息，而用户具有系统外的偏好和限制。对于每个任务，我们构建了一个对话环境，其中代理根据他们达到的最终决策的质量获得奖励。使用这些环境，我们与人们扮演助手的人进行了人机对话。为了比较当前人工智能助手在这些设置中的交流方式，我们提出了基线模型，并将其与人类-人类对话进行比较。我们的结果展示了决策导向对话所面临的挑战，并凸显了当前人工智能助手的局限性。

    We describe a class of tasks called decision-oriented dialogues, in which AI assistants must collaborate with one or more humans via natural language to help them make complex decisions. We formalize three domains in which users face everyday decisions: (1) choosing an assignment of reviewers to conference papers, (2) planning a multi-step itinerary in a city, and (3) negotiating travel plans for a group of friends. In each of these settings, AI assistants and users have disparate abilities that they must combine to arrive at the best decision: assistants can access and process large amounts of information, while users have preferences and constraints external to the system. For each task, we build a dialogue environment where agents receive a reward based on the quality of the final decision they reach. Using these environments, we collect human-human dialogues with humans playing the role of assistant. To compare how current AI assistants communicate in these settings, we present bas
    
[^46]: 束搜索递归单元：一种支持反向传播的递归神经网络框架

    Beam Tree Recursive Cells. (arXiv:2305.19999v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.19999](http://arxiv.org/abs/2305.19999)

    本论文提出了一种支持反向传播的递归神经网络框架——束搜索递归单元（BT-Cell），用于扩展递归神经网络，实现对潜在结构的感知；此外，我们提出了一种放松束搜索中硬前k算子的方法，以实现更好的梯度信号传递。在评估中发现，BT-Cell在合成和实际数据的多个具有结构敏感性的任务中表现优异。

    

    本文提出了一种叫做束搜索递归单元（BT-Cell）的框架，用于扩展支持使用束搜索进行潜在结构感知的递归神经网络（RvNN）。我们进一步通过提出在束搜索中对硬性前k算子的放松来扩展此框架，以更好地传递梯度信号。我们在合成和实际数据的不同代表性分布上评估了我们的模型。实验结果表明，BT-Cell在多个具有挑战性的体现结构敏感性的任务（如ListOps和逻辑推理）上达到了几乎完美的性能，同时在实际数据上与其他基于RvNN的模型具有可比性的性能。此外，我们在ListOps中确定了神经模型在推广到未见过的参数数量上的未知失效案例。代码可在https://github.com/JRC1995/BeamTreeRecursiveCells上获得。

    We propose Beam Tree Recursive Cell (BT-Cell) - a backpropagation-friendly framework to extend Recursive Neural Networks (RvNNs) with beam search for latent structure induction. We further extend this framework by proposing a relaxation of the hard top-k operators in beam search for better propagation of gradient signals. We evaluate our proposed models in different out-of-distribution splits in both synthetic and realistic data. Our experiments show that BTCell achieves near-perfect performance on several challenging structure-sensitive synthetic tasks like ListOps and logical inference while maintaining comparable performance in realistic data against other RvNN-based models. Additionally, we identify a previously unknown failure case for neural models in generalization to unseen number of arguments in ListOps. The code is available at: https://github.com/JRC1995/BeamTreeRecursiveCells.
    
[^47]: DC CoMix TTS：一种与混合器协作的端到端表现力TTS，利用离散码实现改进的韵律建模

    DC CoMix TTS: An End-to-End Expressive TTS with Discrete Code Collaborated with Mixer. (arXiv:2305.19567v1 [cs.SD])

    [http://arxiv.org/abs/2305.19567](http://arxiv.org/abs/2305.19567)

    本文提出了一种基于离散码和混合器相协作的端到端表现力TTS，它采用新的输入表示和简单的架构来实现改进的韵律建模，证明了其有效性。

    

    尽管中性TTS取得了巨大的成功，但内容泄漏仍然是一个挑战。本文提出了一种新的输入表示和简单的架构来实现改进的韵律建模。受最近在TTS中使用离散码取得的成功启发，我们将离散码引入到参考编码器的输入中。具体来说，我们利用音频压缩模型中的向量量化器来利用它已经训练过的多样化的声学信息。此外，我们将修改后的MLP-Mixer应用到参考编码器中，使得架构更加轻盈。因此，我们以端到端的方式训练韵律转移TTS。我们通过主观和客观评估证明了我们方法的有效性。我们在实验中证明了，当离散码作为输入时，参考编码器可以学习到更好的与说话人无关的韵律。另外，即使输入参数更少，我们也可以获得可比较的结果。

    Despite the huge successes made in neutral TTS, content-leakage remains a challenge. In this paper, we propose a new input representation and simple architecture to achieve improved prosody modeling. Inspired by the recent success in the use of discrete code in TTS, we introduce discrete code to the input of the reference encoder. Specifically, we leverage the vector quantizer from the audio compression model to exploit the diverse acoustic information it has already been trained on. In addition, we apply the modified MLP-Mixer to the reference encoder, making the architecture lighter. As a result, we train the prosody transfer TTS in an end-to-end manner. We prove the effectiveness of our method through both subjective and objective evaluations. We demonstrate that the reference encoder learns better speaker-independent prosody when discrete code is utilized as input in the experiments. In addition, we obtain comparable results even when fewer parameters are inputted.
    
[^48]: 语言模型嵌入空间中的词汇文体特征表征

    Representation Of Lexical Stylistic Features In Language Models' Embedding Space. (arXiv:2305.18657v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.18657](http://arxiv.org/abs/2305.18657)

    本文展示了预训练语言模型嵌入空间中的词汇文体特征，并提出了仅使用少量种子对每个文体概念得出向量表示的方法。研究发现静态嵌入空间更准确地编码了单词和短语的特征，而上下文化的语言模型则在句子级别上表现更好。

    

    预训练语言模型嵌入空间编码了关于单词及其关系（如相似性、上义词、一词多义）以及抽象的语义概念（如强度）丰富的信息。本文展示了此空间中的词汇文体特征，如复杂性、正式程度和比喻性。我们证明，仅使用少量种子对可以得出每个文体概念的向量表示。利用这些向量，在相应的嵌入空间中进行简单计算，即可通过这些维度表征新文本。我们在五个数据集上进行实验，发现静态嵌入空间更准确地编码了单词和短语的特征，而上下文化的语言模型则在句子级别上表现更好。上下文化表示在单词级别上的较低性能部分归因于其向量空间的各向异性。

    The representation space of pretrained Language Models (LMs) encodes rich information about words and their relationships (e.g., similarity, hypernymy, polysemy) as well as abstract semantic notions (e.g., intensity). In this paper, we demonstrate that lexical stylistic notions such as complexity, formality, and figurativeness, can also be identified in this space. We show that it is possible to derive a vector representation for each of these stylistic notions from only a small number of seed pairs. Using these vectors, we can characterize new texts in terms of these dimensions by performing simple calculations in the corresponding embedding space. We conduct experiments on five datasets and find that static embeddings encode these features more accurately at the level of words and phrases, whereas contextualized LMs perform better on sentences. The lower performance of contextualized representations at the word level is partially attributable to the anisotropy of their vector space, 
    
[^49]: 基于大语言模型的多项选择题答案确认预测研究

    Conformal Prediction with Large Language Models for Multi-Choice Question Answering. (arXiv:2305.18404v1 [cs.CL])

    [http://arxiv.org/abs/2305.18404](http://arxiv.org/abs/2305.18404)

    本研究探讨了如何利用符合性预测技术，在多项选择题回答任务中为语言模型提供不确定性量化。我们发现符合性预测的不确定性估计与预测准确性密切相关。

    

    随着大型语言模型的广泛开发，对它们进行健壮的不确定性量化技术将成为它们在高风险场景下安全部署的关键。本研究探讨了如何利用符合性预测技术，在多项选择题回答任务中为语言模型提供不确定性量化。我们发现符合性预测的不确定性估计与预测准确性密切相关。这种观察对于下游应用，如选择性分类和过滤低质量预测，可能会有用。我们还研究了符合性预测对于超出主题的问题的交换性假设，这可能是许多实际应用的更为现实的场景。本研究为在需要可靠保证错误率的安全关键情况下更加值得信赖和可靠地使用大型语言模型做出了贡献。

    As large language models continue to be widely developed, robust uncertainty quantification techniques will become crucial for their safe deployment in high-stakes scenarios. In this work, we explore how conformal prediction can be used to provide uncertainty quantification in language models for the specific task of multiple-choice question-answering. We find that the uncertainty estimates from conformal prediction are tightly correlated with prediction accuracy. This observation can be useful for downstream applications such as selective classification and filtering out low-quality predictions. We also investigate the exchangeability assumption required by conformal prediction to out-of-subject questions, which may be a more realistic scenario for many practical applications. Our work contributes towards more trustworthy and reliable usage of large language models in safety-critical situations, where robust guarantees of error rate are required.
    
[^50]: 可视化编程中神经任务合成

    Neural Task Synthesis for Visual Programming. (arXiv:2305.18342v1 [cs.LG])

    [http://arxiv.org/abs/2305.18342](http://arxiv.org/abs/2305.18342)

    该论文提出了一种基于神经符号技术的可视化编程任务合成方法NeurTaskSyn。该方法能够针对规范中给出的解决方案代码所需要的编程概念和对可视化任务的限制，自动生成编程任务。

    

    通过合成新的内容，生成式神经模型在增强编程教育方面具有巨大的潜力。我们旨在设计神经模型，能够根据可视化编程环境下给定的规范自动生成编程任务。尽管近年来像 GPT-4 这样的大型生成模型获得了成功，但我们的初步结果显示，这些模型在合成可视化编程任务方面效果不佳，并且在逻辑和空间推理方面存在困难。我们提出了一种新颖的神经符号技术 NeurTaskSyn，该技术能够针对规范中给出的解决方案代码所需要的编程概念和对可视化任务的限制，合成编程任务。NeurTaskSyn 由两个部分构成：第一个部分通过模仿学习程序进行训练，生成可能的解决方案代码，第二个部分通过强化学习程序进行训练，指导底层符号执行引擎生成可视化任务。

    Generative neural models hold great promise in enhancing programming education by synthesizing new content for students. We seek to design neural models that can automatically generate programming tasks for a given specification in the context of visual programming domains. Despite the recent successes of large generative models like GPT-4, our initial results show that these models are ineffective in synthesizing visual programming tasks and struggle with logical and spatial reasoning. We propose a novel neuro-symbolic technique, NeurTaskSyn, that can synthesize programming tasks for a specification given in the form of desired programming concepts exercised by its solution code and constraints on the visual task. NeurTaskSyn has two components: the first component is trained via imitation learning procedure to generate possible solution codes, and the second component is trained via reinforcement learning procedure to guide an underlying symbolic execution engine that generates visua
    
[^51]: Translatotron 3: 使用单语数据进行语音到语音翻译

    Translatotron 3: Speech to Speech Translation with Monolingual Data. (arXiv:2305.17547v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.17547](http://arxiv.org/abs/2305.17547)

    Translatotron 3提出了一种新方法，使用单语数据进行语音到语音翻译，无需配对的数据或专业建模，展示了保留语言/非语言信息的能力。

    

    本文提出了Translatotron 3的新方法，通过遮蔽自编码器、无监督的嵌入映射和回译将直接语音到语音翻译模型从单声道语音-文本数据集中完全无监督地进行训练。在西班牙语和英语之间的语音到语音翻译任务中，实验结果表明，Translatotron 3优于基准级联系统，在 synthesized Unpaired-Conversational 数据集上报告了18.14 BLEU分数的提高。与需要真实配对数据或专业建模来复制语言/非语言信息的监督方法不同，Translatotron 3展示了它保留了像暂停、说话速度和说话人身份等语言/非语言信息的能力。

    This paper presents Translatotron 3, a novel approach to train a direct speech-to-speech translation model from monolingual speech-text datasets only in a fully unsupervised manner. Translatotron 3 combines masked autoencoder, unsupervised embedding mapping, and back-translation to achieve this goal. Experimental results in speech-to-speech translation tasks between Spanish and English show that Translatotron 3 outperforms a baseline cascade system, reporting 18.14 BLEU points improvement on the synthesized Unpaired-Conversational dataset. In contrast to supervised approaches that necessitate real paired data, which is unavailable, or specialized modeling to replicate para-/non-linguistic information, Translatotron 3 showcases its capability to retain para-/non-linguistic such as pauses, speaking rates, and speaker identity. Audio samples can be found in our website this http URL
    
[^52]: FACTUAL: 一个用于准确文本场景图解析的基准测试

    FACTUAL: A Benchmark for Faithful and Consistent Textual Scene Graph Parsing. (arXiv:2305.17497v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.17497](http://arxiv.org/abs/2305.17497)

    研究提出了一个新数据集FACTUAL-MR，该数据集用于准确文本场景图解析，这样可以避免现有解析器出现的准确性和一致性问题，该方法在各种视觉语言任务中具有重要意义。

    

    文本场景图解析在各种视觉语言应用中变得越来越重要，包括图像描述评估和图像检索。然而，将图像标题转换为场景图的现有解析器经常遭受两种类型的错误。首先，生成的场景图未能捕捉标题或相应图像的真实语义，导致缺乏准确性。其次，生成的场景图具有高度不一致性，相同的语义由不同的注释表示。为了应对这些挑战，我们提出了一个新的数据集，该数据集采用称为FACTUAL-MR的新中间表示对Visual Genome（VG）中的标题进行重新注释。 FACTUAL-MR 可以直接转换为准确和一致的场景图注释。我们的实验结果清楚地表明，在准确性和一致性方面，我们数据集上训练的解析器优于现有方法。这种改进对于需要精确的文本场景图分析的视觉语言任务具有重要意义。

    Textual scene graph parsing has become increasingly important in various vision-language applications, including image caption evaluation and image retrieval. However, existing scene graph parsers that convert image captions into scene graphs often suffer from two types of errors. First, the generated scene graphs fail to capture the true semantics of the captions or the corresponding images, resulting in a lack of faithfulness. Second, the generated scene graphs have high inconsistency, with the same semantics represented by different annotations.  To address these challenges, we propose a novel dataset, which involves re-annotating the captions in Visual Genome (VG) using a new intermediate representation called FACTUAL-MR. FACTUAL-MR can be directly converted into faithful and consistent scene graph annotations. Our experimental results clearly demonstrate that the parser trained on our dataset outperforms existing approaches in terms of faithfulness and consistency. This improvemen
    
[^53]: 大型语言模型的异质价值评估

    Heterogeneous Value Evaluation for Large Language Models. (arXiv:2305.17147v1 [cs.CL])

    [http://arxiv.org/abs/2305.17147](http://arxiv.org/abs/2305.17147)

    本文提出了一种自动对齐评估方法A2EHV，采用异质价值系统，并基于价值合理性和社会价值定向框架评估代理人行为的社会偏好，结果表明比传统对齐方法更合理。

    

    大型语言模型（LLM）的出现使得将它们的价值与人类价值对齐变得至关重要。当前的方法通常尝试将其与一种同质的人类价值对齐，并需要人类验证，但缺乏对对齐所需方面和深度的共识以及造成的人类偏见。在本文中，我们提出了一种自动对齐评估方法A2EHV，该方法采用异质价值系统，（1）是自动化的，以最小化单个人类偏见，并且（2）允许评估针对各种目标值的异质代理人。我们的方法基于价值合理性的概念，它代表了代理人执行最能满足目标价值行为的能力。价值合理性的量化是通过社会心理学中的社会价值定向框架进行的，该框架将价值空间分为四个类别，以评估代理人行为的社会偏好。我们评估了三个模型的价值合理性，结果表明A2EHV方法比传统对齐方法更合理。

    The emergent capabilities of Large Language Models (LLMs) have made it crucial to align their values with those of humans. Current methodologies typically attempt alignment with a homogeneous human value and requires human verification, yet lack consensus on the desired aspect and depth of alignment and resulting human biases. In this paper, we propose A2EHV, an Automated Alignment Evaluation with a Heterogeneous Value system that (1) is automated to minimize individual human biases, and (2) allows assessments against various target values to foster heterogeneous agents. Our approach pivots on the concept of value rationality, which represents the ability for agents to execute behaviors that satisfy a target value the most. The quantification of value rationality is facilitated by the Social Value Orientation framework from social psychology, which partitions the value space into four categories to assess social preferences from agents' behaviors. We evaluate the value rationality of e
    
[^54]: Minecraft中的幽灵：利用基于文本知识和记忆的大型语言模型实现开放世界环境中的通用能力智能体。

    Ghost in the Minecraft: Generally Capable Agents for Open-World Enviroments via Large Language Models with Text-based Knowledge and Memory. (arXiv:2305.17144v1 [cs.AI])

    [http://arxiv.org/abs/2305.17144](http://arxiv.org/abs/2305.17144)

    本文提出了Ghost in the Minecraft (GITM)框架，利用大型语言模型与基于文本的知识和记忆，创造了一种在Minecraft中具备通用能力的智能体，可在以文本为基础的复杂编程环境中熟练导航。

    

    近年来，Minecraft玩法吸引了大量的研究关注，成为开发能够在开放世界环境中运行的智能体的丰富平台。然而，当前的研究主要集中在特定的目标上，例如流行的“ObtainDiamond”任务，并且还没有显示出有效地推广到更广泛任务的能力。此外，“ObtainDiamond”任务的目前最高成功率只有约20％，凸显了现有方法中使用强化学习（RL）控制器的局限性。为了解决这些挑战，我们引入了Ghost in the Minecraft (GITM)，一个新颖的框架，将大型语言模型与基于文本的知识和记忆相结合，旨在创建Minecraft中的通用能力智能体。这些具备LLM中的逻辑和常识能力的智能体可以熟练地在以文本为基础的复杂编程环境中导航。

    The captivating realm of Minecraft has attracted substantial research interest in recent years, serving as a rich platform for developing intelligent agents capable of functioning in open-world environments. However, the current research landscape predominantly focuses on specific objectives, such as the popular "ObtainDiamond" task, and has not yet shown effective generalization to a broader spectrum of tasks. Furthermore, the current leading success rate for the "ObtainDiamond" task stands at around 20%, highlighting the limitations of Reinforcement Learning (RL) based controllers used in existing methods. To tackle these challenges, we introduce Ghost in the Minecraft (GITM), a novel framework integrates Large Language Models (LLMs) with text-based knowledge and memory, aiming to create Generally Capable Agents (GCAs) in Minecraft. These agents, equipped with the logic and common sense capabilities of LLMs, can skillfully navigate complex, sparse-reward environments with text-based 
    
[^55]: 识别情感体验者作为情感分析的先决条件

    Emotion Experiencer Recognition as a Prerequisite for Experiencer-Specific Emotion Analysis. (arXiv:2305.16731v1 [cs.CL])

    [http://arxiv.org/abs/2305.16731](http://arxiv.org/abs/2305.16731)

    本文提出了一种用于检测情感体验者并为其分配情感的自动方法，并进行了相关的实验。该方法的实现具有挑战性，但展示了在文本中检测情感体验者的可行性。

    

    情感角色标注旨在提取文本中描述谁经历情感、为什么以及对谁的信息。这通常是一个具有挑战性的建模任务，如果要回答的主要问题是谁感受到了哪种情感，这可能会过于复杂。本文填补了这一空白，通过自动检测文本中的情感体验者并随后为其分配情感，展示了在文本中检测情感体验者是一项具有挑战性的任务，并呈现了相关的实验结果。

    Emotion role labeling aims at extracting who is described in text to experience an emotion, why, and towards whom. This is often a challenging modelling task which might be overly sophisticated if the main question to answer is who feels which emotion. Recently, Troiano et al. (2022) proposed a data set that focuses on assigning emotion labels and appraisal labels to individual entities in text and Wegge et al. (2022) presented the first modelling experiments. Their experiencer-specific emotion prediction model has, however, only been evaluated on gold-annotated experiencers, due to the unavailability of an automatic experiencer detection approach. We fill this gap with the first experiments to automatically detect emotion experiencers in text and, subsequently, assign them emotions. We show that experiencer detection in text is a challenging task, with a precision of .82 and a recall of .56 (F1 =.66). Consequently, the performance of the experiencer-specific emotion detection pipeline
    
[^56]: 人人可复现的NLP研究：初学者的需求调查

    NLP Reproducibility For All: Understanding Experiences of Beginners. (arXiv:2305.16579v1 [cs.CL])

    [http://arxiv.org/abs/2305.16579](http://arxiv.org/abs/2305.16579)

    通过对93名NLP初学者的调查，发现研究作者提供完整文档、更好的代码实践和更易于获取的数据文件是初学者成功复现最近NLP论文结果的关键，建议NLP研究人员注重这些方面，更好地支持初学者。

    

    随着自然语言处理（NLP）近年来异常火爆，越来越多的人急于进入该领域，但目前的研究复现努力是否足以让这些初学者应用最新的进展还不清楚。为了了解初学者的需求，我们在一个介绍性的NLP课程中开展了一项研究，让学生复现最近NLP论文的结果。令人惊讶的是，我们发现他们的编程技能和对研究论文的理解对完成练习的付出仅有限的影响，相比之下，研究作者的可访问性努力是成功的关键，包括完整的文档、更好的编码实践和更容易获取的数据文件。前进时，我们建议NLP研究人员密切关注这些开源工作的简单方面，并使用初学者的反馈见解提供可操作的想法以更好地支持他们。

    As natural language processing (NLP) has recently seen an unprecedented level of excitement, and more people are eager to enter the field, it is unclear whether current research reproducibility efforts are sufficient for this group of beginners to apply the latest developments. To understand their needs, we conducted a study with 93 students in an introductory NLP course, where students reproduced the results of recent NLP papers. Surprisingly, we find that their programming skill and comprehension of research papers have a limited impact on their effort spent completing the exercise. Instead, we find accessibility efforts by research authors to be the key to success, including complete documentation, better coding practice, and easier access to data files. Going forward, we recommend that NLP researchers pay close attention to these simple aspects of open-sourcing their work, and use insights from beginners' feedback to provide actionable ideas on how to better support them.
    
[^57]: 长文本的神经自然语言处理：现状综述

    Neural Natural Language Processing for Long Texts: A Survey of the State-of-the-Art. (arXiv:2305.16259v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.16259](http://arxiv.org/abs/2305.16259)

    本文简要概述了长文本的神经自然语言处理的现状，主要包括文档分类和摘要，涵盖了情感分析，同时还探讨了长文本NLP的主要挑战、问题和解决方案。

    

    在过去的十年中，深度神经网络（DNN）的采用极大地促进了自然语言处理（NLP）的发展。然而，长文本分析的需求与短文本有很大不同，而网络上传输的文档大小不断增加，使长文本的自动理解成为一项关键的研究领域。本文的两个目标是：a）概述相关的神经构建模块，作为短教程；b）总结长文本NLP的现状，主要关注两个核心任务：文档分类和文档摘要。情感分析也涵盖在内，因为它通常被视为文档分类的特例。此外，本文还讨论了长文本NLP相关的主要挑战、问题和解决方案。最后，介绍了相关的公开的注释数据集，以便促进进一步研究。

    The adoption of Deep Neural Networks (DNNs) has greatly benefited Natural Language Processing (NLP) during the past decade. However, the demands of long document analysis are quite different from those of shorter texts, while the ever increasing size of documents uploaded on-line renders automated understanding of long texts a critical area of research. This article has two goals: a) it overviews the relevant neural building blocks, thus serving as a short tutorial, and b) it surveys the state-of-the-art in long document NLP, mainly focusing on two central tasks: document classification and document summarization. Sentiment analysis for long texts is also covered, since it is typically treated as a particular case of document classification. Additionally, this article discusses the main challenges, issues and current solutions related to long document NLP. Finally, the relevant, publicly available, annotated datasets are presented, in order to facilitate further research.
    
[^58]: LFTK: 计算语言学中的手工特征

    LFTK: Handcrafted Features in Computational Linguistics. (arXiv:2305.15878v1 [cs.CL])

    [http://arxiv.org/abs/2305.15878](http://arxiv.org/abs/2305.15878)

    该论文收集和分类了超过220个受欢迎的手工语言特征，设计了一个多语言的手工语言特征提取系统，以系统性的可扩展方式实现，并在几个任务特定的数据集上进行了相关性分析研究。

    

    过去的研究已经鉴定出了一组丰富的手工语言特征，可以潜在地帮助各种任务。但是，由于这些特征数量庞大，因此难以有效地选择和利用现有的手工特征。加上在研究工作中实现不一致的问题，目前还不存在分类方案或者统一接受的特征名称，这造成了不必要的混乱。此外，大多数现有的手工特征提取库都不是开源的，或者没有得到积极的维护。因此，研究人员经常需要从零开始构建这样的提取系统。我们通过过去的文献收集和分类了超过220个受欢迎的手工特征。然后，我们在几个任务特定的数据集上进行了相关性分析研究，并报告了每个特征的潜在用途。最后，我们设计了一个多语言的手工语言特征提取系统，以系统性的可扩展方式实现。我们开源了我们的系统。

    Past research has identified a rich set of handcrafted linguistic features that can potentially assist various tasks. However, their extensive number makes it difficult to effectively select and utilize existing handcrafted features. Coupled with the problem of inconsistent implementation across research works, there has been no categorization scheme or generally-accepted feature names. This creates unwanted confusion. Also, most existing handcrafted feature extraction libraries are not open-source or not actively maintained. As a result, a researcher often has to build such an extraction system from the ground up.  We collect and categorize more than 220 popular handcrafted features grounded on past literature. Then, we conduct a correlation analysis study on several task-specific datasets and report the potential use cases of each feature. Lastly, we devise a multilingual handcrafted linguistic feature extraction system in a systematically expandable manner. We open-source our system
    
[^59]: 从理论角度揭示“思维链”背后的奥秘

    Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective. (arXiv:2305.15408v1 [cs.LG])

    [http://arxiv.org/abs/2305.15408](http://arxiv.org/abs/2305.15408)

    本文从理论层面探究了带有“思维链”提示的大型语言模型在解决基本数学和决策问题中的能力，发现自回归Transformer大小恒定即可解决任务，揭示了“思维链”提示的背后机制。

    

    最近的研究发现，"思维链"提示能够显著提高大型语言模型（LLMs）的性能，特别是在涉及数学或推理的复杂任务中。尽管获得了巨大的实证成功，但“思维链”背后的机制以及它如何释放LLMs的潜力仍然是神秘的。本文首次从理论上回答了这些问题。具体而言，我们研究了LLMs带有“思维链”在解决基本数学和决策问题中的能力。我们首先给出一个不可能的结果，表明任何有限深度的Transformer都不能直接输出正确的基本算术/方程任务的答案，除非模型大小随着输入长度的增加呈超多项式增长。相反，我们通过构造证明，大小恒定的自回归Transformer足以通过使用常用的数学语言形式生成“思维链”推导来解决这两个任务。

    Recent studies have discovered that Chain-of-Thought prompting (CoT) can dramatically improve the performance of Large Language Models (LLMs), particularly when dealing with complex tasks involving mathematics or reasoning. Despite the enormous empirical success, the underlying mechanisms behind CoT and how it unlocks the potential of LLMs remain elusive. In this paper, we take a first step towards theoretically answering these questions. Specifically, we examine the capacity of LLMs with CoT in solving fundamental mathematical and decision-making problems. We start by giving an impossibility result showing that any bounded-depth Transformer cannot directly output correct answers for basic arithmetic/equation tasks unless the model size grows super-polynomially with respect to the input length. In contrast, we then prove by construction that autoregressive Transformers of a constant size suffice to solve both tasks by generating CoT derivations using a commonly-used math language forma
    
[^60]: 带有语音的LM：超越语音令牌的口语语言建模

    LMs with a Voice: Spoken Language Modeling beyond Speech Tokens. (arXiv:2305.15255v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.15255](http://arxiv.org/abs/2305.15255)

    SPECTRON是一个新颖的语音延续模型，通过利用预训练的语言模型和语音编码器进行端到端的训练来生成文本和语音输出，在语义内容和讲话者保护方面超越了现有的口语语言模型。

    

    我们提出了SPECTRON，一种新颖的方法来适应预训练的语言模型（LM）以执行语音延续。通过利用预训练的语音编码器，我们的模型可以生成文本和语音输出，整个系统都在频谱图上进行端到端的训练。在频谱图领域训练整个模型相对于使用离散语音表示的现有级联方法简化了我们的语音延续系统。我们进一步展示了我们的方法在语义内容和讲话者保护方面超过了现有的口语语言模型，同时也从预先存在的模型中获得了知识传递的好处。我们的网站https://michelleramanovich.github.io/spectron/spectron上可以找到音频样本。

    We present SPECTRON, a novel approach to adapting pre-trained language models (LMs) to perform speech continuation. By leveraging pre-trained speech encoders, our model generates both text and speech outputs with the entire system being trained end-to-end operating directly on spectrograms. Training the entire model in the spectrogram domain simplifies our speech continuation system versus existing cascade methods which use discrete speech representations. We further show our method surpasses existing spoken language models both in semantic content and speaker preservation while also benefiting from the knowledge transferred from pre-existing models. Audio samples can be found in our website https://michelleramanovich.github.io/spectron/spectron
    
[^61]: BeamSearchQA: 大型语言模型是强大的零-shot QA求解器

    BeamSearchQA: Large Language Models are Strong Zero-Shot QA Solver. (arXiv:2305.14766v1 [cs.CL])

    [http://arxiv.org/abs/2305.14766](http://arxiv.org/abs/2305.14766)

    BeamSearchQA利用大型语言模型进行迭代式生成问题，以捕捉隐含知识并优化问答过程，在NQ和WebQ测试集上分别达到了71.7％和46.7％的F1分数，显着优于现有的最先进方法。

    

    开放领域的问答是一个关键任务，通常需要访问外部信息。现有方法通常采用单轮检索-阅读方法，首先检索相关文档，然后基于检索的信息回答问题。然而，在某些情况下，回答问题需要隐含的知识，这些知识不直接从问题本身中获得。在这项工作中，我们提出了一种新的问答流程，称为BeamSearchQA。我们的方法利用大规模语言模型（LLMs）迭代生成关于原始问题的新问题，实现迭代推理过程。通过迭代细化和扩展问题的范围，我们的方法旨在捕捉并利用可能无法通过检索直接获取的隐藏知识。我们在广泛使用的开放领域NQ和WebQ数据集上评估了我们的方法。实验结果表明，BeamSearchQA明显优于现有的最先进方法，在NQ和WebQ测试集上分别达到了71.7％和46.7％的F1分数。

    Open-domain question answering is a crucial task that often requires accessing external information. Existing methods typically adopt a single-turn retrieve-then-read approach, where relevant documents are first retrieved, and questions are then answered based on the retrieved information. However, there are cases where answering a question requires implicit knowledge that is not directly retrievable from the question itself. In this work, we propose a novel question-answering pipeline called eamSearchQA. Our approach leverages large language models(LLMs) to iteratively generate new questions about the original question, enabling an iterative reasoning process. By iteratively refining and expanding the scope of the question, our method aims to capture and utilize hidden knowledge that may not be directly obtainable through retrieval. We evaluate our approach on the widely-used open-domain NQ and WebQ datasets. The experimental results demonstrate that BeamSearchQA significantly outperf
    
[^62]: 大型语言模型是零样本文本到视频生成的帧级导演

    Large Language Models are Frame-level Directors for Zero-shot Text-to-Video Generation. (arXiv:2305.14330v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.14330](http://arxiv.org/abs/2305.14330)

    本文引入了一个新的框架——DirecT2V，利用大型语言模型作为导演，从一个抽象的用户提示中生成零样本文本到视频生成的连贯且连贯的视频。该框架使用LLM导演将用户输入分为每一帧的提示，通过值映射和双softmax过滤器来保持时间一致和防止对象折叠。

    

    在人工智能生成内容（AIGC）的范式中，越来越多的关注点放在将预训练的文本到图像（T2I）模型扩展到文本到视频（T2V）生成上。尽管这些框架很有效，但它们面临着维护一致的叙述和处理从单个用户提示中的快速场景组合或对象位置变化的挑战。本文引入了一个新的框架，称为DirecT2V，它利用针对指令校准的大型语言模型（LLMs）从单个抽象用户提示生成逐帧描述。DirecT2V利用LLM导演将用户输入分为每个帧的单独提示，从而实现包含时间变化的内容和便于一致的视频生成。为了保持时间上的一致性和防止对象折叠，我们提出了一种新的值映射方法和双softmax过滤器。广泛的实验结果验证了DirecT2V框架在零样本T2V生成中产生的视觉连贯和一致的视频生成的有效性。

    In the paradigm of AI-generated content (AIGC), there has been increasing attention in extending pre-trained text-to-image (T2I) models to text-to-video (T2V) generation. Despite their effectiveness, these frameworks face challenges in maintaining consistent narratives and handling rapid shifts in scene composition or object placement from a single user prompt. This paper introduces a new framework, dubbed DirecT2V, which leverages instruction-tuned large language models (LLMs) to generate frame-by-frame descriptions from a single abstract user prompt. DirecT2V utilizes LLM directors to divide user inputs into separate prompts for each frame, enabling the inclusion of time-varying content and facilitating consistent video generation. To maintain temporal consistency and prevent object collapse, we propose a novel value mapping method and dual-softmax filtering. Extensive experimental results validate the effectiveness of the DirecT2V framework in producing visually coherent and consist
    
[^63]: 中文对话级依存句法分析的初步研究。

    A Pilot Study on Dialogue-Level Dependency Parsing for Chinese. (arXiv:2305.12441v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12441](http://arxiv.org/abs/2305.12441)

    该论文研究了中文对话级依存句法分析的初步工作，在新构建了的高质量人工标注语料库上，通过零样本和小样本的数据学习，采用了基于信号的将见到的句法依存转换成元素话语单位之间的未见依存的方法，通过单视角和多视角的数据选择来访问可靠的伪标记实例，取得良好的实验结果。

    

    对话级依存句法分析尤其是中文方面的研究还不足。因此我们借鉴了句法依存理论和修辞结构理论（RST），构建并开发了一个高质量的人工标注语料库，包含850个对话和199,803个依存关系。鉴于此类任务的高昂标注成本，我们研究了零样本和小样本情况。基于现有的句法树库，我们采用了一种基于信号的方法将见到的句法依存转换成元素话语单位之间的未见依存，其中信号是通过掩码语言模型检测得到的。此外，我们应用了单视角和多视角的数据选择来访问可靠的伪标记实例。实验结果表明这些基线的有效性。此外，我们还讨论了有关数据集和方法的几个关键要点。

    Dialogue-level dependency parsing has received insufficient attention, especially for Chinese. To this end, we draw on ideas from syntactic dependency and rhetorical structure theory (RST), developing a high-quality human-annotated corpus, which contains 850 dialogues and 199,803 dependencies. Considering that such tasks suffer from high annotation costs, we investigate zero-shot and few-shot scenarios. Based on an existing syntactic treebank, we adopt a signal-based method to transform seen syntactic dependencies into unseen ones between elementary discourse units (EDUs), where the signals are detected by masked language modeling. Besides, we apply single-view and multi-view data selection to access reliable pseudo-labeled instances. Experimental results show the effectiveness of these baselines. Moreover, we discuss several crucial points about our dataset and approach.
    
[^64]: 零样本多语言神经机器翻译中的“离谱问题”

    On the Off-Target Problem of Zero-Shot Multilingual Neural Machine Translation. (arXiv:2305.10930v1 [cs.CL])

    [http://arxiv.org/abs/2305.10930](http://arxiv.org/abs/2305.10930)

    零样本多语言神经机器翻译容易出现“离谱问题”，本文提出的简单且有效的算法LAVS可以通过增加语言之间的KL分歧显著降低这个问题。

    

    尽管多语言神经机器翻译取得了巨大成功，但它仍然存在“离谱问题”，即将翻译输出到错误的语言中。这个问题在零样本翻译任务中更加明显。本文发现，当编码目标语言信号时失效，会导致离谱问题，并且两种语言词汇之间更接近的词汇距离（即KL分歧）与更高的离谱率有关。此外，本文还发现，仅隔离解码器中不同语言的词汇可以缓解这个问题。基于这些发现，我们提出了一种简单有效的算法Language Aware Vocabulary Sharing (LAVS)来构建多语言词汇表，通过增加语言之间的KL分歧，大大减轻了翻译模型的离谱问题。我们在11种语言的多语言翻译基准测试上进行了实验。实验结果表明，对于90个翻译任务，采用LAVS的离谱率降低了37％至90％。

    While multilingual neural machine translation has achieved great success, it suffers from the off-target issue, where the translation is in the wrong language. This problem is more pronounced on zero-shot translation tasks. In this work, we find that failing in encoding discriminative target language signal will lead to off-target and a closer lexical distance (i.e., KL-divergence) between two languages' vocabularies is related with a higher off-target rate. We also find that solely isolating the vocab of different languages in the decoder can alleviate the problem. Motivated by the findings, we propose Language Aware Vocabulary Sharing (LAVS), a simple and effective algorithm to construct the multilingual vocabulary, that greatly alleviates the off-target problem of the translation model by increasing the KL-divergence between languages. We conduct experiments on a multilingual machine translation benchmark in 11 languages. Experiments show that the off-target rate for 90 translation 
    
[^65]: 深度学习方法用于提取花和植物的隐喻性名称

    Deep Learning Methods for Extracting Metaphorical Names of Flowers and Plants. (arXiv:2305.10833v1 [cs.CL])

    [http://arxiv.org/abs/2305.10833](http://arxiv.org/abs/2305.10833)

    本研究使用深度学习模型识别对话中基于隐喻的花和植物名称，鉴别模型表现优于GPT-3.5，最好的表现器在任务中报告了92.2349％的F1分数。

    

    植物学领域充满了隐喻性术语，这些术语在描述和识别花和植物方面起着重要作用。但是，在对话中识别这些术语是一项艰巨的任务。在翻译过程和词典编纂任务中，这往往导致错误的发生。当涉及到单词和短语时，在机器翻译方面这个过程更具挑战性。自然语言处理（NLP）应用和机器翻译（MT）技术的最新关注点之一是通过深度学习（DL）自动识别对话中基于隐喻的单词。在本研究中，我们使用了十三种流行的变压器模型以及ChatGPT来填补这一空白，并且通过F1得分证明了鉴别模型优于GPT-3.5模型，我们最好的表现器在隐喻花卉和植物名称识别任务中报告了92.2349％的F1分数。

    The domain of Botany is rich with metaphorical terms. Those terms play an important role in the description and identification of flowers and plants. However, the identification of such terms in discourse is an arduous task. This leads in some cases to committing errors during translation processes and lexicographic tasks. The process is even more challenging when it comes to machine translation, both in the cases of single-word terms and multi-word terms. One of the recent concerns of Natural Language Processing (NLP) applications and Machine Translation (MT) technologies is the automatic identification of metaphor-based words in discourse through Deep Learning (DL). In this study, we seek to fill this gap through the use of thirteen popular transformer based models, as well as ChatGPT, and we show that discriminative models perform better than GPT-3.5 model with our best performer reporting 92.2349% F1 score in metaphoric flower and plant names identification task.
    
[^66]: ChatGPT作为去除偏见的文本简化工具

    ChatGPT as a Text Simplification Tool to Remove Bias. (arXiv:2305.06166v1 [cs.CL])

    [http://arxiv.org/abs/2305.06166](http://arxiv.org/abs/2305.06166)

    ChatGPT作为文本简化工具可以去除语言模型在训练过程中对某些特定群体的偏见，减少模型的歧视性。（注：ChatGPT是一种基于Transformer的自然语言处理模型）

    

    在训练期间，语言模型可以捕捉到特定子群体的特定语言信号，如果模型学习了捕捉某个群体的语言，可能会导致歧视。如果模型开始将特定语言与某个特定群体联系起来，基于此语言做出的任何决策都将与其受保护特征有着强烈的相关性。我们探索了一种可能的偏见缓解技术，即文本简化。这个想法的驱动力是简化文本应该标准化语言，使其以一种方式说话，同时保持相同的含义。实验显示，针对敏感属性预测的分类器精度会因使用简化数据而下降高达17%。

    The presence of specific linguistic signals particular to a certain sub-group of people can be picked up by language models during training. This may lead to discrimination if the model has learnt to pick up on a certain group's language. If the model begins to associate specific language with a distinct group, any decisions made based upon this language would hold a strong correlation to a decision based on their protected characteristic. We explore a possible technique for bias mitigation in the form of simplification of text. The driving force of this idea is that simplifying text should standardise language to one way of speaking while keeping the same meaning. The experiment shows promising results as the classifier accuracy for predicting the sensitive attribute drops by up to 17% for the simplified data.
    
[^67]: 如何发挥大语言模型在少样本关系抽取中的能力？

    How to Unleash the Power of Large Language Models for Few-shot Relation Extraction?. (arXiv:2305.01555v1 [cs.CL])

    [http://arxiv.org/abs/2305.01555](http://arxiv.org/abs/2305.01555)

    本文通过使用GPT-3.5模型在少样本关系抽取中，实现在四个不同数据集上的新的最优性能，并提出了与任务相关的指导说明和约束模式下的数据生成方法。

    

    语言模型的扩展已经彻底改变了广泛的自然语言处理任务，但是使用大型语言模型进行少样本关系抽取还没有得到全面探索。本文通过详细实验，研究了使用GPT-3.5进行少样本关系抽取的基本方法——上下文学习和数据生成。为了增强少样本性能，我们进一步提出了与任务相关的指导说明和约束模式下的数据生成。我们观察到，在上下文学习的情况下，可以实现与以前的提示学习方法相当的性能，而使用大型语言模型的数据生成可以推动以前的解决方案以在四个广泛研究的关系抽取数据集上获得新的最先进的少样本结果。我们希望我们的工作可以激发未来对大型语言模型在少样本关系抽取中的能力的研究。代码可以在 \url{https://github.com/zjunlp/DeepKE/tree/main/example/llm} 中找到。

    Scaling language models have revolutionized widespread NLP tasks, yet little comprehensively explored few-shot relation extraction with large language models. In this paper, we investigate principal methodologies, in-context learning and data generation, for few-shot relation extraction via GPT-3.5 through exhaustive experiments. To enhance few-shot performance, we further propose task-related instructions and schema-constrained data generation. We observe that in-context learning can achieve performance on par with previous prompt learning approaches, and data generation with the large language model can boost previous solutions to obtain new state-of-the-art few-shot results on four widely-studied relation extraction datasets. We hope our work can inspire future research for the capabilities of large language models in few-shot relation extraction. Code is available in \url{https://github.com/zjunlp/DeepKE/tree/main/example/llm.
    
[^68]: 架起桥梁：自然语言生成中整合（人类）反馈的调查研究。

    Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation. (arXiv:2305.00955v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.00955](http://arxiv.org/abs/2305.00955)

    本文调查研究了利用人类反馈改进自然语言生成方面的最近研究，包括对反馈的全面形式化、反馈的格式和目的的描述，和提出使用反馈的两种方法。我们还讨论了用于人类反馈数据收集的现有数据集，和相关的担忧。

    

    最近许多自然语言生成方面的进展都是基于利用互联网规模的数据对大型语言模型进行训练。然而，这种范式可能会导致生成有害、不准确和无用内容的模型，而自动评估指标通常无法识别这些行为。随着模型变得更加强大，人类反馈成为评价和改进模型的宝贵信号。本调查旨在概述最近利用人类反馈改进自然语言生成方面的研究。首先，我们介绍了对反馈的全面形式化，并根据这种形式化将现有研究进行分类和组织。接下来，我们讨论了反馈可以通过其格式和目的来描述，并涵盖了提出使用反馈的两种方法（用于训练或解码）：直接使用反馈或训练反馈模型。我们还讨论了用于人类反馈数据收集的现有数据集，以及相关的担忧。

    Many recent advances in natural language generation have been fueled by training large language models on internet-scale data. However, this paradigm can lead to models that generate toxic, inaccurate, and unhelpful content, and automatic evaluation metrics often fail to identify these behaviors. As models become more capable, human feedback is an invaluable signal for evaluating and improving models. This survey aims to provide an overview of the recent research that has leveraged human feedback to improve natural language generation. First, we introduce an encompassing formalization of feedback, and identify and organize existing research into a taxonomy following this formalization. Next, we discuss how feedback can be described by its format and objective, and cover the two approaches proposed to use feedback (either for training or decoding): directly using the feedback or training feedback models. We also discuss existing datasets for human-feedback data collection, and concerns 
    
[^69]: 在资源受限的嵌入式设备上部署基于BERT的NLP模型的挑战探究

    Exploring Challenges of Deploying BERT-based NLP Models in Resource-Constrained Embedded Devices. (arXiv:2304.11520v1 [cs.CL])

    [http://arxiv.org/abs/2304.11520](http://arxiv.org/abs/2304.11520)

    本文探究了在资源受限的嵌入式设备上部署基于BERT的NLP模型的挑战，并得出结论：虽然DistilBERT和TinyBERT等轻量级模型相对占用更少内存，但它们在复杂的NLP任务上表现较差；ResNet-based BERT模型可以在精度和资源效率之间取得良好的平衡，适合在嵌入式设备上部署。

    

    基于BERT的神经架构已经成为许多下游NLP任务的流行先进技术基准。然而，这些架构对数据依赖性强，占用大量内存和能量，经常阻碍它们在许多实时、资源受限的应用程序中的部署。现有的BERT轻量级版本（例如DistilBERT和TinyBERT）通常在复杂的NLP任务上无法表现出良好的性能。更重要的是，从设计师的角度来看，要为特定的NLP任务使用何种“正确的”基于BERT的架构，以在资源可用性和最终用户需求的最小精度之间实现最佳权衡，尚不确定。系统工程师必须花费大量时间进行试错实验，以找到合适的答案。本文在不同的资源限制和精度预算下对BERT-based模型进行了探究性研究，以得出有关此资源/精度权衡的经验性观察结果。我们的研究发现，虽然DistilBERT和TinyBERT等更轻量级的模型相对BERT-base占用的内存要少得多，但它们在复杂的NLP任务中精度的下降是明显的。我们还观察到，特别是基于ResNet的BERT模型，可以在准确性和资源效率之间取得良好的平衡，使其成为在资源受限的嵌入式设备中部署的良好候选模型。

    BERT-based neural architectures have established themselves as popular state-of-the-art baselines for many downstream NLP tasks. However, these architectures are data-hungry and consume a lot of memory and energy, often hindering their deployment in many real-time, resource-constrained applications. Existing lighter versions of BERT (eg. DistilBERT and TinyBERT) often cannot perform well on complex NLP tasks. More importantly, from a designer's perspective, it is unclear what is the "right" BERT-based architecture to use for a given NLP task that can strike the optimal trade-off between the resources available and the minimum accuracy desired by the end user. System engineers have to spend a lot of time conducting trial-and-error experiments to find a suitable answer to this question. This paper presents an exploratory study of BERT-based models under different resource constraints and accuracy budgets to derive empirical observations about this resource/accuracy trade-offs. Our findin
    
[^70]: 大型语言模型中的突现和可预知性记忆

    Emergent and Predictable Memorization in Large Language Models. (arXiv:2304.11158v1 [cs.CL])

    [http://arxiv.org/abs/2304.11158](http://arxiv.org/abs/2304.11158)

    该论文的研究发现中间检查点比完全训练的模型更好地预测模型的记忆化行为，并且发现了大型语言模型中记忆化得分的分布规律。

    

    记忆化是大型语言模型（LLMs）输出其训练数据完全相同序列的倾向，这是安全部署语言模型的关键问题之一。特别地，最小化模型对包含个人可识别信息（PII）等敏感数据点的记忆化是至关重要的。这种不良的记忆化的普及可能会给模型训练者带来问题，甚至可能需要丢弃否则功能良好的模型。因此，我们试图通过推断低计算力试验运行的记忆化行为来预测哪些序列将在大型模型的全局培训期间进行记忆化。我们测量了Pythia模型套件的记忆化，发现中间检查点比较小的已完全训练模型更好地预测了模型的记忆化行为。此外，我们还提供了有关模型和数据记忆化分数分布的进一步新发现。

    Memorization, or the tendency of large language models (LLMs) to output entire sequences from their training data verbatim, is a key concern for safely deploying language models. In particular, it is vital to minimize a model's memorization of sensitive datapoints such as those containing personal identifiable information (PII). The prevalence of such undesirable memorization can pose issues for model trainers, and may even require discarding an otherwise functional model. We therefore seek to predict which sequences will be memorized before a large model's full train-time by extrapolating the memorization behavior of lower-compute trial runs. We measure memorization of the Pythia model suite, and find that intermediate checkpoints are better predictors of a model's memorization behavior than smaller fully-trained models. We additionally provide further novel discoveries on the distribution of memorization scores across models and data.
    
[^71]: 混合智能科技论文检测的理解与解释

    Towards an Understanding and Explanation for Mixed-Initiative Artificial Scientific Text Detection. (arXiv:2304.05011v1 [cs.HC] CROSS LISTED)

    [http://arxiv.org/abs/2304.05011](http://arxiv.org/abs/2304.05011)

    本论文通过定量实验明确了机器生成和人类撰写的科技论文之间的关键差异，并提出了一种混合智能工作流，旨在有效解决科技论文检测中存在的挑战。

    

    大型语言模型（LLM）因其出色的生成人类化文本的能力在各个领域中广受欢迎。然而，其潜在误用引起了社会关注，主要是关于学术抄袭的问题。然而，由于几个挑战，包括：1）缺乏对机器生成和人类撰写的科技论文差异的明确理解、2）由于分布问题导致现有方法的差强人意泛化表现、以及3）检测过程中对人机协作的支持及足够解释性的有限，使得有效的科技论文检测是具有挑战性的。本文首先通过一个定量实验​​​明确了机器生成和人类撰写的科技论文之间的关键差异。然后，我们提出了一种混合智能工作流，结合人类专家的先验知识和机器智能，以及一个可视化分析原型来促进交互。

    Large language models (LLMs) have gained popularity in various fields for their exceptional capability of generating human-like text. Their potential misuse has raised social concerns about plagiarism in academic contexts. However, effective artificial scientific text detection is a non-trivial task due to several challenges, including 1) the lack of a clear understanding of the differences between machine-generated and human-written scientific text, 2) the poor generalization performance of existing methods caused by out-of-distribution issues, and 3) the limited support for human-machine collaboration with sufficient interpretability during the detection process. In this paper, we first identify the critical distinctions between machine-generated and human-written scientific text through a quantitative experiment. Then, we propose a mixed-initiative workflow that combines human experts' prior knowledge with machine intelligence, along with a visual analytics prototype to facilitate e
    
[^72]: 基于查询-话语注意力和联合建模的查询焦点会议摘要

    Query-Utterance Attention with Joint modeling for Query-Focused Meeting Summarization. (arXiv:2303.04487v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.04487](http://arxiv.org/abs/2303.04487)

    本文提出了一种基于查询-话语注意力和联合建模的查询感知框架，它使用密集检索模块计算话语级别与查询的相关性，并将标记级别的查询关联性和话语级别的查询关联性结合起来，实现生成一个更与查询相关的摘要。经过对两个基准数据集上的测试，表明该方法优于现有的QFMS模型。

    

    查询焦点会议摘要（QFMS）旨在根据给定的查询，从会议记录中生成摘要。以往的方法通常将查询与会议记录拼接起来，并使用注意机制隐式地对标记级别的查询相关性进行建模。然而，由于长时间的会议记录导致关键的查询相关信息被稀释，因此原始的基于转换的模型不足以突出与查询相关的关键部分。本文提出了一种基于查询-话语注意力和联合建模的查询感知框架。它使用密集检索模块计算话语级别与查询的相关性。然后，将标记级别的查询关联性和话语级别的查询关联性结合起来，并通过明确的注意机制整合到生成过程中。我们表明，不同颗粒度的查询相关性有助于生成一个更与查询相关的摘要。在两个基准数据集上的实验结果表明，我们提出的方法优于现有的QFMS模型。

    Query-focused meeting summarization (QFMS) aims to generate summaries from meeting transcripts in response to a given query. Previous works typically concatenate the query with meeting transcripts and implicitly model the query relevance only at the token level with attention mechanism. However, due to the dilution of key query-relevant information caused by long meeting transcripts, the original transformer-based model is insufficient to highlight the key parts related to the query. In this paper, we propose a query-aware framework with joint modeling token and utterance based on Query-Utterance Attention. It calculates the utterance-level relevance to the query with a dense retrieval module. Then both token-level query relevance and utterance-level query relevance are combined and incorporated into the generation process with attention mechanism explicitly. We show that the query relevance of different granularities contributes to generating a summary more related to the query. Exper
    
[^73]: Almanac: 检索增强的临床医学语言模型

    Almanac: Retrieval-Augmented Language Models for Clinical Medicine. (arXiv:2303.01229v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.01229](http://arxiv.org/abs/2303.01229)

    Almanac是一个带有检索能力的大型语言模型框架，为临床医学的指南和治疗建议提供了事实性、完备性和安全性的增强。该模型有望成为临床决策过程中的有效工具。

    

    最近，大型语言模型已经在各种自然语言任务中展示出令人印象深刻的零-shot能力，例如摘要、对话生成和问答。虽然在临床医学中有许多有前途的应用，但这些模型在实际环境中的应用往往受到它们生成错误甚至有时是有害言论的限制。在本研究中，我们开发了Almanac，这是一个带有检索能力的大型语言模型框架，用于医疗指南和治疗建议。由5名董事会认证和住院医师评估的130个临床场景的新数据集的表现表明，在所有专业领域中，事实性显著提高（在p值<0.05的情况下增加了18%的平均值），并改善了完备性和安全性。我们的结果表明，大型语言模型有潜力成为临床决策过程中有效的工具，同时也强调了正确性的重要性。

    Large-language models have recently demonstrated impressive zero-shot capabilities in a variety of natural language tasks such as summarization, dialogue generation, and question-answering. Despite many promising applications in clinical medicine, adoption of these models in real-world settings has been largely limited by their tendency to generate incorrect and sometimes even toxic statements. In this study, we develop Almanac, a large language model framework augmented with retrieval capabilities for medical guideline and treatment recommendations. Performance on a novel dataset of clinical scenarios (n = 130) evaluated by a panel of 5 board-certified and resident physicians demonstrates significant increases in factuality (mean of 18% at p-value < 0.05) across all specialties, with improvements in completeness and safety. Our results demonstrate the potential for large language models to be effective tools in the clinical decision-making process, while also emphasizing the importanc
    
[^74]: 大型语言模型是翻译质量评估的最佳方法

    Large Language Models Are State-of-the-Art Evaluators of Translation Quality. (arXiv:2302.14520v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.14520](http://arxiv.org/abs/2302.14520)

    该论文介绍了一种基于GPT模型的翻译质量评估方法GEMBA，并展示了它在零-shot提示、多种模式下与WMT22度量共享任务的MQM人类标签相比取得了最先进的准确性，这为大型语言模型在翻译质量评估中的实用性提供了首次的证明。

    

    我们介绍了一种基于GPT的GEMBA度量方法，用于评估翻译质量，可以在有或没有参考翻译的情况下进行。在评估中，我们针对零-shot提示进行了比较，比较了两种基于参考翻译可用性的模式下的四种提示变量。我们研究了9个GPT模型版本，包括ChatGPT和GPT-4。我们证明了，我们的翻译质量评估方法只适用于GPT 3.5及更大的模型。与WMT22度量共享任务的结果相比，我们的方法在两种模式下与MQM人类标签相比，实现了最先进的准确性。我们的结果对所有三种WMT22度量共享任务的语言对（即英语到德语、英语到俄语和中文到英语）都适用。这为预训练、生成式大型语言模型在翻译质量评估中的实用性提供了首次的展示。我们公开发布了所有代码和用于实验的提示模板。

    We describe GEMBA, a GPT-based metric for assessment of translation quality, which works both with a reference translation and without. In our evaluation, we focus on zero-shot prompting, comparing four prompt variants in two modes, based on the availability of the reference. We investigate nine versions of GPT models, including ChatGPT and GPT-4. We show that our method for translation quality assessment only works with GPT~3.5 and larger models. Comparing to results from WMT22's Metrics shared task, our method achieves state-of-the-art accuracy in both modes when compared to MQM-based human labels. Our results are valid on the system level for all three WMT22 Metrics shared task language pairs, namely English into German, English into Russian, and Chinese into English. This provides a first glimpse into the usefulness of pre-trained, generative large language models for quality assessment of translations. We publicly release all our code and prompt templates used for the experiments 
    
[^75]: 多模态语音识别用于语言引导的合身代理

    Multimodal Speech Recognition for Language-Guided Embodied Agents. (arXiv:2302.14030v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.14030](http://arxiv.org/abs/2302.14030)

    本文提出在语言引导的合身代理中使用多模态ASR模型来减少语音指令的转录错误，并通过考虑视觉上下文来提高转录结果。模型能够恢复多达30％的被屏蔽单词，并且训练基于文本的合身代理在遵循多模态ASR模型转录的指令下能够更高效地完成任务。

    

    语言引导的合身代理的基准测试通常假设基于文本的指令，但实际部署的代理会遇到口头指令。尽管自动语音识别（ASR）模型可以弥合语音输入差距，但错误的ASR转录会损害代理完成任务的能力。本文提出利用多模态ASR模型训练来考虑伴随的视觉环境，从而减少语音指令的转录错误。我们在ALFRED任务完成数据集上合成了口头指令的数据集，并通过系统性地屏蔽口头单词来模拟声学噪声。我们发现，利用视觉观察可以有助于恢复屏蔽的单词，通过多模态ASR模型，恢复的屏蔽单词比单模态基线多达30％。我们还发现，基于文本训练的合身代理通过遵循多模态ASR模型的转录指令更经常地完成任务。

    Benchmarks for language-guided embodied agents typically assume text-based instructions, but deployed agents will encounter spoken instructions. While Automatic Speech Recognition (ASR) models can bridge the input gap, erroneous ASR transcripts can hurt the agents' ability to complete tasks. In this work, we propose training a multimodal ASR model to reduce errors in transcribing spoken instructions by considering the accompanying visual context. We train our model on a dataset of spoken instructions, synthesized from the ALFRED task completion dataset, where we simulate acoustic noise by systematically masking spoken words. We find that utilizing visual observations facilitates masked word recovery, with multimodal ASR models recovering up to 30% more masked words than unimodal baselines. We also find that a text-trained embodied agent successfully completes tasks more often by following transcribed instructions from multimodal ASR models. github.com/Cylumn/embodied-multimodal-asr
    
[^76]: 让我们来聊聊吧！与ChatGPT的对话：技术，应用和限制。

    Let's have a chat! A Conversation with ChatGPT: Technology, Applications, and Limitations. (arXiv:2302.13817v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.13817](http://arxiv.org/abs/2302.13817)

    本文讨论了聊天机器人的历史概述以及ChatGPT背后的技术，强调了它在医疗保健、教育和研究中的潜在应用，并指出了其隐私和道德方面的担忧以及当前版本的重要限制。

    

    一款能够生成像人类一样的句子和写出连贯文章的人工智能聊天机器人ChatGPT的出现引起了世界的关注。本文讨论了聊天机器人的历史概述以及ChatGPT背后的技术。此外，还强调了ChatGPT在各个领域，包括医疗保健，教育和研究中的潜在应用。尽管有着令人期待的结果，但是ChatGPT周围存在着一些隐私和道德方面的担忧。另外，我们还强调了当前版本ChatGPT的一些重要限制。我们还向ChatGPT提出了一些问题，以便它表达自己的看法。

    The emergence of an AI-powered chatbot that can generate human-like sentences and write coherent essays has caught the world's attention. This paper discusses the historical overview of chatbots and the technology behind Chat Generative Pre-trained Transformer, better known as ChatGPT. Moreover, potential applications of ChatGPT in various domains, including healthcare, education, and research, are highlighted. Despite promising results, there are several privacy and ethical concerns surrounding ChatGPT. In addition, we highlight some of the important limitations of the current version of ChatGPT. We also ask ChatGPT to provide its point of view and present its responses to several questions we attempt to answer.
    
[^77]: ProsAudit：自监督语音模型韵律基准测试

    ProsAudit, a prosodic benchmark for self-supervised speech models. (arXiv:2302.12057v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.12057](http://arxiv.org/abs/2302.12057)

    ProsAudit是一个自监督语音模型韵律基准测试，由原型句法任务和词汇任务两部分组成。研究发现模型大小对表现有明显影响，词汇任务中母语模型表现优异，但非母语模型表现较差。

    

    我们提出 ProsAudit，一个用于评估自监督学习（SSL）语音模型中结构韵律知识的英语基准测试。它由两个子任务、相应的指标和一个评估数据集组成。在原型句法任务中，模型必须正确识别强调和弱调的韵律边界。在词汇任务中，模型需要正确区分插入单词和内部的停顿。我们还提供了对这个基准测试的人为评估分数。我们评估了一系列 SSL 模型，并发现它们在两个任务上都能够在未见过的语言上进行评估时表现良好。然而，非母语模型在词汇任务上表现明显较差，突显了该任务中词汇知识的重要性。我们还发现，模型的大小对表现有明显的影响，训练数据更多的模型在这两个子任务中表现更好。

    We present ProsAudit, a benchmark in English to assess structural prosodic knowledge in self-supervised learning (SSL) speech models. It consists of two subtasks, their corresponding metrics, and an evaluation dataset. In the protosyntax task, the model must correctly identify strong versus weak prosodic boundaries. In the lexical task, the model needs to correctly distinguish between pauses inserted between words and within words. We also provide human evaluation scores on this benchmark. We evaluated a series of SSL models and found that they were all able to perform above chance on both tasks, even when evaluated on an unseen language. However, non-native models performed significantly worse than native ones on the lexical task, highlighting the importance of lexical knowledge in this task. We also found a clear effect of size with models trained on more data performing better in the two subtasks.
    
[^78]: 通过大型语言模型进行关卡生成

    Level Generation Through Large Language Models. (arXiv:2302.05817v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.05817](http://arxiv.org/abs/2302.05817)

    该研究探讨了使用大型语言模型(LLMs)生成Sokoban游戏关卡，并发现随着数据集大小的增加，LLMs的性能得到了很大的提高。未来工作的前景也被讨论了。

    

    大型语言模型(LLM)是强大的工具，能够利用自然语言的训练写故事、生成代码和回答问题。但它们能否生成功能性的视频游戏关卡呢？游戏关卡由于功能约束和多维空间关系的复杂性，与LLM在训练期间通常看到的数据种类非常不同。游戏关卡的数据集也很难获得，可能会耗尽这些对数据有强烈需求的模型的能力。我们研究了使用LLMs生成Sokoban游戏关卡，并发现LLMs确实能够实现这一点，并且它的性能随着数据集大小的增加而大幅提高。我们还进行了初步的实验来控制LLM关卡生成器，并讨论了未来工作的有前途的领域。

    Large Language Models (LLMs) are powerful tools, capable of leveraging their training on natural language to write stories, generate code, and answer questions. But can they generate functional video game levels? Game levels, with their complex functional constraints and spatial relationships in more than one dimension, are very different from the kinds of data an LLM typically sees during training. Datasets of game levels are also hard to come by, potentially taxing the abilities of these data-hungry models. We investigate the use of LLMs to generate levels for the game Sokoban, finding that LLMs are indeed capable of doing so, and that their performance scales dramatically with dataset size. We also perform preliminary experiments on controlling LLM level generators and discuss promising areas for future work.
    
[^79]: 语言模型训练数据提取的技巧总结

    Bag of Tricks for Training Data Extraction from Language Models. (arXiv:2302.04460v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.04460](http://arxiv.org/abs/2302.04460)

    本文总结了一些技巧用于改进语言模型训练数据提取，提出了在文本生成和文本排名中可以使用的技巧，实验证明这些技巧对于提高训练数据提取的效果非常重要。

    

    随着语言模型的不断研究，隐私保护变得越来越重要。因此，训练数据提取作为潜在的评估隐私泄露的工具变得非常关键。然而，由于这项任务的困难程度，目前现有的大多数方法仍然不够有效。本文提出了一些技巧用于改进训练数据提取，我们对公开可用的数据集进行了实验。由于大多数现有的提取方法使用生成然后排序的流程（例如，生成潜在的训练数据文本，然后根据特定的标准对它们进行排序），因此我们的研究重点在于文本生成和文本排名的技巧。（例如，采样策略和令牌级标准）。实验结果表明，一些之前被忽视的技巧对于训练数据提取的成功非常关键。基于GPT-Neo 1.3B的评估结果，我们提出的技巧优于现有的方法。

    With the advance of language models, privacy protection is receiving more attention. Training data extraction is therefore of great importance, as it can serve as a potential tool to assess privacy leakage. However, due to the difficulty of this task, most of the existing methods are proof-of-concept and still not effective enough. In this paper, we investigate and benchmark tricks for improving training data extraction using a publicly available dataset. Because most existing extraction methods use a pipeline of generating-then-ranking, i.e., generating text candidates as potential training data and then ranking them based on specific criteria, our research focuses on the tricks for both text generation (e.g., sampling strategy) and text ranking (e.g., token-level criteria). The experimental results show that several previously overlooked tricks can be crucial to the success of training data extraction. Based on the GPT-Neo 1.3B evaluation results, our proposed tricks outperform the b
    
[^80]: 硬提示变简单：用基于梯度的离散优化方法进行提示调节和发现

    Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery. (arXiv:2302.03668v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.03668](http://arxiv.org/abs/2302.03668)

    该论文提出了一种基于梯度的离散优化方法，用于自动生成文本提示，进而控制现代生成模型的输出。该方法可以优化文本到图像和文本到文本的应用，为API用户提供了轻松生成、发现、混合和匹配图像概念的能力，同时自动发现硬提示可以有效地提高模型性能。

    

    现代生成模型的优点在于可以通过基于文本的提示进行控制。传统的“硬”提示是由可解释的词汇和标记构成，必须由人手工制作。此外还有“软”提示，它们由连续的特征向量组成，可以通过强大的优化方法发现，但它们不能很容易地解释，不能在不同模型之间重复使用，也不能用于基于文本的接口。我们提出了一种基于高效梯度优化的方法，来稳健地优化硬文本提示。该方法自动为文本到图像和文本到文本应用生成硬文本提示。在文本到图像的设置中，该方法为扩散模型创建硬提示，使API用户可以轻松生成、发现、混合和匹配图像概念，而不需要事先了解如何提示模型。在文本到文本的设置中，我们展示了自动发现硬提示可以有效地优化模型性能。

    The strength of modern generative models lies in their ability to be controlled through text-based prompts. Typical "hard" prompts are made from interpretable words and tokens, and must be hand-crafted by humans. There are also "soft" prompts, which consist of continuous feature vectors. These can be discovered using powerful optimization methods, but they cannot be easily interpreted, re-used across models, or plugged into a text-based interface.  We describe an approach to robustly optimize hard text prompts through efficient gradient-based optimization. Our approach automatically generates hard text-based prompts for both text-to-image and text-to-text applications. In the text-to-image setting, the method creates hard prompts for diffusion models, allowing API users to easily generate, discover, and mix and match image concepts without prior knowledge on how to prompt the model. In the text-to-text setting, we show that hard prompts can be automatically discovered that are effectiv
    
[^81]: 将语言模型与图像进行联系以处理多模态信息

    Grounding Language Models to Images for Multimodal Inputs and Outputs. (arXiv:2301.13823v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.13823](http://arxiv.org/abs/2301.13823)

    该论文提出一种有效的方法，将仅处理文本的语言模型与图像进行联系，使其能够处理任意交错的图像和文本数据，并生成与检索图像交错的自由形式文本。该方法在环境相关的图像检索和多模态对话等任务中表现十分优异，是利用预训练语言模型解决视觉场景下交互问题的有效解决方案。

    

    我们提出了一种有效的方法，将预训练的仅文本语言模型与视觉领域联系起来，使其能够处理任意交错的图像和文本数据，并生成与检索图像交错的文本。我们利用从大规模文本预训练中学到的语言模型的能力，例如上下文学习和自由形式文本生成。我们保持语言模型冻结，并微调输入和输出线性层以实现跨模态交互。这使得我们的模型能够处理任意交错的图像和文本输入，并生成与检索图像交错的自由形式文本。我们在环境相关的图像检索和多模态对话等任务中取得了强大的零-shot表现，并展示了引人入胜的交互能力。我们的方法适用于任何现成的语言模型，为在视觉场景下利用预训练语言模型提供了一个有效且通用的解决方案。

    We propose an efficient method to ground pretrained text-only language models to the visual domain, enabling them to process arbitrarily interleaved image-and-text data, and generate text interleaved with retrieved images. Our method leverages the abilities of language models learnt from large scale text-only pretraining, such as in-context learning and free-form text generation. We keep the language model frozen, and finetune input and output linear layers to enable cross-modality interactions. This allows our model to process arbitrarily interleaved image-and-text inputs, and generate free-form text interleaved with retrieved images. We achieve strong zero-shot performance on grounded tasks such as contextual image retrieval and multimodal dialogue, and showcase compelling interactive abilities. Our approach works with any off-the-shelf language model and paves the way towards an effective, general solution for leveraging pretrained language models in visually grounded settings.
    
[^82]: 神经代理通信推动语言普遍规律的出现：以语序/格标交换为例证

    Communication Drives the Emergence of Language Universals in Neural Agents: Evidence from the Word-order/Case-marking Trade-off. (arXiv:2301.13083v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.13083](http://arxiv.org/abs/2301.13083)

    本文研究了神经代理语言学习与通信框架，成功复制了语序/格标交换这一广泛存在的语言普遍规律，实现了更真实的语言演变模拟，并帮助我们更好地理解影响语言普遍规律的认知和社会因素。

    

    在基于神经代理的语言演变和变化的模拟中，人工学习者的行为通常与人类学习者不同，这常被归因于这些学习者缺乏适当的认知偏见。然而，也有人提出更自然的语言学习和使用环境可能导致更类似于人类的结果。本文研究了这种后一种说法，重点关注语序/格标交换，一种被广泛证明的语言普遍规律，这种规律在模拟中被证明尤其困难。我们提出了一个新的神经代理语言学习和通信框架（NeLLCom），其中说话和听取的代理首先通过监督学习学习一种小语言，然后通过强化学习对其进行优化以进行沟通。紧密遵循早期人类实验的设置，我们成功复制了这种新框架下的交换，而不是在代理中硬编码特定的偏见。我们认为，这是发展更真实的语言演变模拟和更好地理解影响语言普遍规律的认知和社会因素的重要一步。

    Artificial learners often behave differently from human learners in the context of neural agent-based simulations of language emergence and change. A common explanation is the lack of appropriate cognitive biases in these learners. However, it has also been proposed that more naturalistic settings of language learning and use could lead to more human-like results. We investigate this latter account focusing on the word-order/case-marking trade-off, a widely attested language universal that has proven particularly hard to simulate. We propose a new Neural-agent Language Learning and Communication framework (NeLLCom) where pairs of speaking and listening agents first learn a miniature language via supervised learning, and then optimize it for communication via reinforcement learning. Following closely the setup of earlier human experiments, we succeed in replicating the trade-off with the new framework without hard-coding specific biases in the agents. We see this as an essential step to
    
[^83]: 关于上下文学习的综述

    A Survey on In-context Learning. (arXiv:2301.00234v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.00234](http://arxiv.org/abs/2301.00234)

    本文调查和总结了上下文学习(ICL)的进展和挑战，ICL已成为自然语言处理(NLP)的新范式，探索ICL以评估和推广大型语言模型(LLM)的能力已成为一种新趋势。本文提出了ICL的正式定义，并总结了高级技术，最后讨论了ICL的挑战以及进一步研究的潜在方向。

    

    随着大型语言模型（LLM）的能力不断增强，上下文学习（ICL）已成为自然语言处理（NLP）的新范式，在其中LLM仅基于加入少量示例的上下文进行预测。探索ICL以评估和推广LLM的能力已成为一种新趋势。本文旨在调查和总结ICL的进展和挑战。我们首先提出ICL的正式定义，并澄清其与相关研究的关系。然后，我们组织和讨论高级技术，包括训练策略、演示设计策略以及相关分析。最后，我们讨论了ICL的挑战，并提供了进一步研究的潜在方向。我们希望我们的工作可以鼓励更多的研究，揭示ICL的工作原理并改进ICL。

    With the increasing ability of large language models (LLMs), in-context learning (ICL) has become a new paradigm for natural language processing (NLP), where LLMs make predictions only based on contexts augmented with a few examples. It has been a new trend to explore ICL to evaluate and extrapolate the ability of LLMs. In this paper, we aim to survey and summarize the progress and challenges of ICL. We first present a formal definition of ICL and clarify its correlation to related studies. Then, we organize and discuss advanced techniques, including training strategies, demonstration designing strategies, as well as related analysis. Finally, we discuss the challenges of ICL and provide potential directions for further research. We hope that our work can encourage more research on uncovering how ICL works and improving ICL.
    
[^84]: DISCO: 利用大型语言模型提炼短语反事实数据

    DISCO: Distilling Phrasal Counterfactuals with Large Language Models. (arXiv:2212.10534v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10534](http://arxiv.org/abs/2212.10534)

    本文提出了一种名为DISCO的自动化方法，可利用大型语言模型生成高质量反事实数据，用于训练模型，以实现自然语言推理等任务的因果推理，相比于传统数据训练方法，效果更好且可扩展和高效。

    

    利用反事实增广数据训练的模型可以学习任务的因果结构表达，从而实现稳健的泛化。但对于大多数任务而言，高质量的反事实数据很少且难以大规模生成。当使用众包方法进行生成时，通常规模和多样性都有限。当使用有监督方法时，要将其扩展到新的反事实维度是计算上昂贵的。在这项工作中，我们提出了DISCO（DIStilled COunterfactual Data），一种新的方法，可在规模上自动生成高质量的反事实数据。DISCO工程师使用大型通用语言模型生成提示以生成短语扰动。然后，特定于任务的教师模型过滤这些生成，以提取高质量的反事实数据。虽然是面向任务的，我们应用我们的流程来处理自然语言推理（NLI）任务，并发现在像NLI压力测试这样的挑战性评估中，用DISCO生成的数据训练的相对较小的学生模型比使用传统（非反事实增强）的数据训练的大模型效果更好。我们的方法提供了一个可扩展和高效的解决方案，用于生成反事实数据，为各种自然语言任务的因果推理提供了可能。

    Models trained with counterfactually augmented data learn representations of the causal structure of tasks, enabling robust generalization. However, high-quality counterfactual data is scarce for most tasks and not easily generated at scale. When crowdsourced, such data is typically limited in scale and diversity; when generated using supervised methods, it is computationally expensive to extend to new counterfactual dimensions. In this work, we introduce DISCO (DIStilled COunterfactual Data), a new method for automatically generating high quality counterfactual data at scale. DISCO engineers prompts to generate phrasal perturbations with a large general language model. Then, a task-specific teacher model filters these generations to distill high-quality counterfactual data. While task-agnostic, we apply our pipeline to the task of natural language inference (NLI) and find that on challenging evaluations such as the NLI stress test, comparatively smaller student models trained with DIS
    
[^85]: 探索“Chain-of-Thought”提示的有效性：一个关于重点的实证研究

    Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters. (arXiv:2212.10001v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10001](http://arxiv.org/abs/2212.10001)

    本文通过实验证明，即使在使用无效推理步骤的情况下，CoT提示也可以实现CoT推理，并显示出其他方面对于CoT的有效性更为关键，这有助于深入了解CoT提示的有效性并提出改进策略。

    

    “Chain-of-Thought”（CoT）提示可以极大地提高大型语言模型（LLMs）的多步推理能力。CoT通过在演示中提供一系列的推理步骤，明确鼓励LLM生成解决问题的中间理性，从而实现。尽管CoT取得了成功，但目前仍很少了解什么使CoT提示有效，以及演示的推理步骤的哪些方面对其性能起到贡献。在本文中，我们表明，即使在使用无效推理步骤的情况下，提示也可以实现CoT推理，而使用各种度量方法，提示的性能也可以达到使用CoT时的80-90％以上，同时在推理期间仍会生成连贯的推理链条。进一步的实验表明，理性的其他方面，比如与查询相关和正确排序的推理步骤，对于有效的CoT推理更为重要。总体而言，这些发现深化了我们对CoT提示的理解，并为提高其效果提出了策略。

    Chain-of-Thought (CoT) prompting can dramatically improve the multi-step reasoning abilities of large language models (LLMs). CoT explicitly encourages the LLM to generate intermediate rationales for solving a problem, by providing a series of reasoning steps in the demonstrations. Despite its success, there is still little understanding of what makes CoT prompting effective and which aspects of the demonstrated reasoning steps contribute to its performance. In this paper, we show that CoT reasoning is possible even with invalid demonstrations - prompting with invalid reasoning steps can achieve over 80-90% of the performance obtained using CoT under various metrics, while still generating coherent lines of reasoning during inference. Further experiments show that other aspects of the rationales, such as being relevant to the query and correctly ordering the reasoning steps, are much more important for effective CoT reasoning. Overall, these findings both deepen our understanding of Co
    
[^86]: 使用语言模型提示进行推理：一项调查

    Reasoning with Language Model Prompting: A Survey. (arXiv:2212.09597v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09597](http://arxiv.org/abs/2212.09597)

    本文提供了使用语言模型提示进行推理的前沿研究综合调查。讨论了新兴推理能力出现的潜在原因，并提供系统资源帮助初学者。

    

    推理作为复杂问题解决的重要能力，可以为医疗诊断、谈判等各种实际应用提供后端支持。本文对使用语言模型提示进行推理的前沿研究进行了综合调查。我们介绍了研究成果的比较和总结，并提供了系统资源以帮助初学者。我们还讨论了新兴推理能力出现的潜在原因，并突出了未来的研究方向。资源可在 https://github.com/zjunlp/Prompt4ReasoningPapers 上获取（定期更新）。

    Reasoning, as an essential ability for complex problem-solving, can provide back-end support for various real-world applications, such as medical diagnosis, negotiation, etc. This paper provides a comprehensive survey of cutting-edge research on reasoning with language model prompting. We introduce research works with comparisons and summaries and provide systematic resources to help beginners. We also discuss the potential reasons for emerging such reasoning abilities and highlight future research directions. Resources are available at https://github.com/zjunlp/Prompt4ReasoningPapers (updated periodically).
    
[^87]: 小型语言模型的推理能力训练

    Teaching Small Language Models to Reason. (arXiv:2212.08410v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.08410](http://arxiv.org/abs/2212.08410)

    本文研究了如何通过知识蒸馏，将大型语言模型的推理能力传递到小型语言模型中，并证明这样的方法可以提高小型模型在算术、常识和符号推理方面的性能。

    

    通过思维链的启发，成功地提高了大型语言模型的推理能力，在一系列数据集上实现了最先进的结果。然而，这些推理能力似乎仅在拥有超过1000亿个参数的模型中出现。本文探讨了通过知识蒸馏将这种推理能力传递到小于1000亿个参数的模型中的方法。具体来说，我们通过对较大的教师模型生成的思维链输出进行微调，对学生模型进行了训练。我们的实验表明，所提出的方法可以在算术、常识和符号推理数据集上提高任务性能。例如，T5 XXL在GSM8K数据集上的准确率从8.11%提高到21.99%，当它被PaLM-540B生成的思维链进行微调时。

    Chain of thought prompting successfully improves the reasoning capabilities of large language models, achieving state of the art results on a range of datasets. However, these reasoning capabilities only appear to emerge in models with a size of over 100 billion parameters. In this paper, we explore the transfer of such reasoning capabilities to models with less than 100 billion parameters via knowledge distillation. Specifically, we finetune a student model on the chain of thought outputs generated by a larger teacher model. Our experiments show that the proposed method improves task performance across arithmetic, commonsense and symbolic reasoning datasets. For example, the accuracy of T5 XXL on GSM8K improves from 8.11% to 21.99% when finetuned on PaLM-540B generated chains of thought.
    
[^88]: 超级CLEVR：诊断视觉推理领域稳健性的虚拟基准

    Super-CLEVR: A Virtual Benchmark to Diagnose Domain Robustness in Visual Reasoning. (arXiv:2212.00259v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.00259](http://arxiv.org/abs/2212.00259)

    本文提出了一个虚拟基准Super-CLEVR，使得我们可以通过分离视觉问题应对领域转移中的各种因素，探究VQA方法的领域泛化能力。作者在四个VQA领域变量上测试了四种方法和一种新方法P-NSVQA，结果表明P-NSVQA比其他方法的性能更好，Super-CLEVR是分析VQA领域泛化的有效工具。

    

    视觉问答（VQA）模型经常在分布外数据上表现不佳，并且在领域泛化上遇到困难。由于这个任务的多模态性质，多个变化因素相互交织，使得泛化分析难以分析。这激励我们引入一个虚拟基准，超级CLEVR，其中可以分离VQA领域转移中的不同因素，以便能够将它们的效果独立地进行研究。考虑了四个因素：视觉复杂度、问题冗余、概念分布和概念组成性。通过可控生成的数据，超级CLEVR使我们能够测试VQA方法，在其中测试数据沿着每个轴与训练数据有所不同的情况下。我们研究了四种现有方法，其中包括两种神经符号方法NSCL和NSVQA，以及两种非符号方法FiLM和mDETR；以及我们提出的方法，概率NSVQA（P-NSVQA），它将不确定性推理与NSVQA扩展。在所有情况下，P-NSVQA的性能优于其他方法，我们还展示了，超级CLEVR可以成为分析VQA中领域泛化的有用诊断工具。

    Visual Question Answering (VQA) models often perform poorly on out-of-distribution data and struggle on domain generalization. Due to the multi-modal nature of this task, multiple factors of variation are intertwined, making generalization difficult to analyze. This motivates us to introduce a virtual benchmark, Super-CLEVR, where different factors in VQA domain shifts can be isolated in order that their effects can be studied independently. Four factors are considered: visual complexity, question redundancy, concept distribution and concept compositionality. With controllably generated data, Super-CLEVR enables us to test VQA methods in situations where the test data differs from the training data along each of these axes. We study four existing methods, including two neural symbolic methods NSCL and NSVQA, and two non-symbolic methods FiLM and mDETR; and our proposed method, probabilistic NSVQA (P-NSVQA), which extends NSVQA with uncertainty reasoning. P-NSVQA outperforms other metho
    
[^89]: 条件文本生成中的奖励博弈

    Reward Gaming in Conditional Text Generation. (arXiv:2211.08714v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.08714](http://arxiv.org/abs/2211.08714)

    在条件文本生成中，使用强化学习（RL）进行训练时，噪声、自然发生的虚假相关性和协变量漂移可能会导致不良模式被错误地赋予高奖励值，这可能会导致奖励博弈，需要解决。

    

    为了使条件文本生成模型的输出与所需行为相一致，越来越多的关注点在于使用从人类注释中学习的奖励函数以强化学习（RL）训练模型。在这个框架下，我们确定了三种常见情况，即由噪声引起的虚假相关性、自然发生的虚假相关性和协变量漂移，其中高奖励被错误地分配给不良模式。我们表明，即使学习到的度量在训练奖励函数所使用的数据分布上表现良好，不良模式在文本生成模型的RL训练过程中仍有可能被放大。尽管RL或安全社区已经开始讨论奖励博弈，但在这篇讨论中，我们希望使用具体的条件文本生成示例，重点介绍自然语言生成（NLG）社区中的奖励博弈，并讨论可能的修复措施和未来的研究方向。

    To align conditional text generation model outputs with desired behaviors, there has been an increasing focus on training the model using reinforcement learning (RL) with reward functions learned from human annotations. Under this framework, we identify three common cases where high rewards are incorrectly assigned to undesirable patterns: noise-induced spurious correlation, naturally occurring spurious correlation, and covariate shift. We show that even though learned metrics achieve high performance on the distribution of the data used to train the reward function, the undesirable patterns may be amplified during RL training of the text generation model. While there has been discussion about reward gaming in the RL or safety community, in this discussion piece, we would like to highlight reward gaming in the natural language generation (NLG) community using concrete conditional text generation examples and discuss potential fixes and areas for future work.
    
[^90]: 机器翻译的衡量指标与人工评分相符，在同时翻译中也适用

    MT Metrics Correlate with Human Ratings of Simultaneous Speech Translation. (arXiv:2211.08633v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.08633](http://arxiv.org/abs/2211.08633)

    本文表明了离线指标与人工连续评分之间存在良好的相关性，可以在同时翻译模式中可靠地用于机器翻译的评估，从而减轻了大规模人工评估的需要。

    

    在人工评分和离线机器翻译评估指标（如BLEU、chrF2、BertScore和COMET）之间有几个元评估研究。这些指标已经用于同时语音翻译（SST）的评估，但它们与最近收集的连续评分（CR）的SST的人工评分之间的相关性不清楚。在本文中，我们利用提交给IWSLT 2022年英德SST任务的候选系统的评估，并对CR和上述指标进行了广泛的相关性分析。我们的研究表明，离线指标与CR存在良好的相关性，并可以可靠地用于评估同时翻译模式下的机器翻译，但对测试集大小有一定限制。我们得出结论称，鉴于当前SST的质量水平，这些指标可以用作CR的代理，减轻了大规模人工评估的需要。另外，我们观察到许多指标的相关性在不同的测试集下发生变化。

    There have been several meta-evaluation studies on the correlation between human ratings and offline machine translation (MT) evaluation metrics such as BLEU, chrF2, BertScore and COMET. These metrics have been used to evaluate simultaneous speech translation (SST) but their correlations with human ratings of SST, which has been recently collected as Continuous Ratings (CR), are unclear. In this paper, we leverage the evaluations of candidate systems submitted to the English-German SST task at IWSLT 2022 and conduct an extensive correlation analysis of CR and the aforementioned metrics. Our study reveals that the offline metrics are well correlated with CR and can be reliably used for evaluating machine translation in simultaneous mode, with some limitations on the test set size. We conclude that given the current quality levels of SST, these metrics can be used as proxies for CR, alleviating the need for large scale human evaluation. Additionally, we observe that correlations of the m
    
[^91]: 多语言对语言模型的道德偏见产生影响

    Speaking Multiple Languages Affects the Moral Bias of Language Models. (arXiv:2211.07733v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.07733](http://arxiv.org/abs/2211.07733)

    本文研究发现，预训练的多语言语言模型具有不同程度的道德偏见，英语方面的偏见比其他语言更强。具体而言，在英语训练的多语言语言模型更倾向于优先考虑个体化的道德基础而非束缚性的道德基础，这对跨语言转移和设计伦理自然语言处理系统具有重要的影响。

    

    预训练的多语言语言模型广泛应用于处理多种语言的数据和跨语言转移。然而，这些模型对于每种语言的数据训练量不同，使得它们在英语方面的表现往往要比其他语言好得多。我们研究这是否影响了这些模型对道德准则的捕捉和运用。这些模型是否从英语中捕捉到了道德准则并将其施加到其他语言中？这些模型是否在某些语言中表现出随意的、潜在有害的信念？这两个问题都可能对跨语言转移产生负面影响，从而可能导致有害的结果。本文中，我们运用“道德方向”框架比较了多语言模型在德语、捷克语、阿拉伯语、汉语和英语中的结果，分析了模型在过滤后的平行字幕语料库上的行为，并将模型应用于道德基础问卷，与来自不同国家的人类回答进行比较。我们的实验结果表明，预训练的多语言语言模型存在不同程度的道德偏见，且英语方面的偏见比其他语言更强。具体而言，我们发现在英语训练的多语言语言模型更倾向于优先考虑个体化的道德基础而非束缚性的道德基础。这对跨语言转移和设计伦理自然语言处理系统具有重要的影响。

    Pre-trained multilingual language models (PMLMs) are commonly used when dealing with data from multiple languages and cross-lingual transfer. However, PMLMs are trained on varying amounts of data for each language. In practice this means their performance is often much better on English than many other languages. We explore to what extent this also applies to moral norms. Do the models capture moral norms from English and impose them on other languages? Do the models exhibit random and thus potentially harmful beliefs in certain languages? Both these issues could negatively impact cross-lingual transfer and potentially lead to harmful outcomes. In this paper, we (1) apply the MoralDirection framework to multilingual models, comparing results in German, Czech, Arabic, Chinese, and English, (2) analyse model behaviour on filtered parallel subtitles corpora, and (3) apply the models to a Moral Foundations Questionnaire, comparing with human responses from different countries. Our experime
    
[^92]: 神经网络中的 emergent 语言结构是脆弱的

    Emergent Linguistic Structures in Neural Networks are Fragile. (arXiv:2210.17406v7 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.17406](http://arxiv.org/abs/2210.17406)

    本文提出了一个框架来评估语言模型对于语法的表述的一致性和稳健性，通过多项实验证据表明，神经网络中 emergent 语言结构是脆弱的。

    

    大型语言模型（LLM）在自然语言处理任务中表现强劲。然而，准确度等性能指标并不能衡量模型在代表复杂语言结构方面的质量。本文针对语言模型代表语法的能力，提出了一个评估语言表述的一致性和稳健性的框架。为此，我们介绍了一些稳健性的神经网络模型度量方式，这些度量方式利用最近在通过探测任务从LLM中提取语言结构的先进技术，即用于从语言模型中提取有意义信息的简单任务，如语法重构和根识别。实证上，我们通过分析四种LLM在六个不同的语料库上对语法保持扰动的性能和稳健性来研究所提出的稳健度量方式的表现。我们提供了证据

    Large Language Models (LLMs) have been reported to have strong performance on natural language processing tasks. However, performance metrics such as accuracy do not measure the quality of the model in terms of its ability to robustly represent complex linguistic structure. In this paper, focusing on the ability of language models to represent syntax, we propose a framework to assess the consistency and robustness of linguistic representations. To this end, we introduce measures of robustness of neural network models that leverage recent advances in extracting linguistic constructs from LLMs via probing tasks, i.e., simple tasks used to extract meaningful information about a single facet of a language model, such as syntax reconstruction and root identification. Empirically, we study the performance of four LLMs across six different corpora on the proposed robustness measures by analysing their performance and robustness with respect to syntax-preserving perturbations. We provide evide
    
[^93]: 算术采样：用于大型语言模型的并行多样化解码

    Arithmetic Sampling: Parallel Diverse Decoding for Large Language Models. (arXiv:2210.15458v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.15458](http://arxiv.org/abs/2210.15458)

    本文章提出了一种算术采样框架，该方法可兼容常见的采样变化，具有可证明的束多样性和令人尴尬的并行性，从原始模型提供无偏和一致的期望。在WMT机器翻译中表现出良好的效果。

    

    大型语言模型的解码方法通常在输出多样性和计算并行性之间进行权衡。本文提出了一种框架，根据由大型语言模型隐式定义的算术代码书进行采样，兼容常见的采样变化，满足一定条件下的可证明的束多样性，同时具有令人尴尬的并行性，并从原始模型提供无偏和一致的期望。我们在WMT机器翻译上展示了我们方法的有效性，将预期的BLEU分数奖励的标准差减少了一半以上，同时与先前的最新方法有了相当的表现。

    Decoding methods for large language models often trade-off between diversity of outputs and parallelism of computation. Methods such as beam search and Gumbel top-k sampling can guarantee a different output for each element of the beam, but are not easy to parallelize. Alternatively, methods such as temperature sampling and its modifications (top-k sampling, nucleus sampling, typical decoding, and others), are embarrassingly parallel, but have no guarantees about duplicate samples. We present a framework for sampling according to an arithmetic code book implicitly defined by a large language model, compatible with common sampling variations, with provable beam diversity under certain conditions, as well as being embarrassingly parallel and providing unbiased and consistent expectations from the original model. We demonstrate the effectiveness of our approach on WMT machine translation, more than halving the standard deviation when estimating expected BLEU score reward, and closing the 
    
[^94]: 使用短语表示查询自动生成命名实体识别数据集

    Automatic Creation of Named Entity Recognition Datasets by Querying Phrase Representations. (arXiv:2210.07586v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.07586](http://arxiv.org/abs/2210.07586)

    本篇论文提出了一种名为HighGEN的新框架，通过使用短语嵌入搜索方法生成实体丰富的伪字典，在使用嵌入距离验证过程减少误报的基础上生成高覆盖率的NER数据集。

    

    大多数弱监督的命名实体识别（NER）模型依赖于由专家提供的领域特定词典。然而，在许多没有字典的领域中，这种方法不可行。在最近的一项研究中，使用短语检索模型自动从维基百科中提取实体构建了伪字典，但这些字典的覆盖面往往有限，因为检索器很可能会检索到流行的实体而不是罕见的实体。在本研究中，我们提出了一个新的框架——HighGEN，它使用具有高覆盖率的伪字典生成NER数据集。具体来说，我们使用一种新的搜索方法——短语嵌入搜索来创建富实体字典，该方法鼓励检索器在一个密集的各种实体的空间中搜索。此外，我们使用一种基于实体提及和实体类型之间嵌入距离的新的验证过程，以减少高覆盖率伪标签中的误报噪声。

    Most weakly supervised named entity recognition (NER) models rely on domain-specific dictionaries provided by experts. This approach is infeasible in many domains where dictionaries do not exist. While a phrase retrieval model was used to construct pseudo-dictionaries with entities retrieved from Wikipedia automatically in a recent study, these dictionaries often have limited coverage because the retriever is likely to retrieve popular entities rather than rare ones. In this study, we present a novel framework, HighGEN, that generates NER datasets with high-coverage pseudo-dictionaries. Specifically, we create entity-rich dictionaries with a novel search method, called phrase embedding search, which encourages the retriever to search a space densely populated with various entities. In addition, we use a new verification process based on the embedding distance between candidate entity mentions and entity types to reduce the false-positive noise in weak labels generated by high-coverage 
    
[^95]: SQuId: 在多语言中测量语音自然度

    SQuId: Measuring Speech Naturalness in Many Languages. (arXiv:2210.06324v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.06324](http://arxiv.org/abs/2210.06324)

    SQuId是一个使用一百万个评分进行训练并在65个语言环境下进行测试的多语言自然度预测模型，该模型的训练在许多环境中始终优于单一环境的基线，并展现了比竞争基线更出色的表现;研究还突出了跨语言细调的有效性，以及非语言效果如声音畸变在跨语言细调中的作用。

    

    文本到语音的许多研究都依赖于人类评估，这会产生重大成本并减缓开发进程。在重度多语言应用中，招募和调查评审员可能需要数周时间。我们介绍了SQuId（语音质量识别），这是一个使用一百万个评分进行训练并在65个语言环境下进行测试的多语言自然度预测模型，是迄今为止这种类型中最大的努力。主要的见解是，在许多环境中训练一个模型始终优于单一环境的基线。我们介绍了我们的任务、模型，并展示了它的表现优于基于w2v-BERT和VoiceMOS的竞争基线50.0%。然后，我们演示了跨语言细调的有效性，并强调了它对零样本环境的影响，即没有细调数据的环境。通过一系列分析，我们突出了非语言效果（如声音畸变）在跨语言细调中的作用。最后，我们展示了可能是第一个多语言自然度数据集，其中包含65个环境中超过一百万评分。

    Much of text-to-speech research relies on human evaluation, which incurs heavy costs and slows down the development process. The problem is particularly acute in heavily multilingual applications, where recruiting and polling judges can take weeks. We introduce SQuId (Speech Quality Identification), a multilingual naturalness prediction model trained on over a million ratings and tested in 65 locales-the largest effort of this type to date. The main insight is that training one model on many locales consistently outperforms mono-locale baselines. We present our task, the model, and show that it outperforms a competitive baseline based on w2v-BERT and VoiceMOS by 50.0%. We then demonstrate the effectiveness of cross-locale transfer during fine-tuning and highlight its effect on zero-shot locales, i.e., locales for which there is no fine-tuning data. Through a series of analyses, we highlight the role of non-linguistic effects such as sound artifacts in cross-locale transfer. Finally, we
    
[^96]: 文字到图像模型的最佳提示及其如何找到

    Best Prompts for Text-to-Image Models and How to Find Them. (arXiv:2209.11711v3 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2209.11711](http://arxiv.org/abs/2209.11711)

    本文研究了文字到图像模型中最佳提示的组成和优化方法，采用人类反馈和遗传算法进行学习，实现了以美学角度进行呈现的专业人类艺术作品的生成。

    

    近期，生成模型中的文本引导扩散模型取得了显著进展，使得人工艺术家的作品得以以美学角度进行呈现。然而，必须仔细地组成文本描述，即提示，并用一组澄清的关键词进行增强。由于美学在计算方面很难进行评估，因此需要人类反馈来确定最佳提示公式和关键词组合。在本文中，我们提出了一种人在环的方法来通过遗传算法学习最有用的提示关键词组合。我们还展示了这种方法如何改善描绘相同描述的图像的美学吸引力。

    Recent progress in generative models, especially in text-guided diffusion models, has enabled the production of aesthetically-pleasing imagery resembling the works of professional human artists. However, one has to carefully compose the textual description, called the prompt, and augment it with a set of clarifying keywords. Since aesthetics are challenging to evaluate computationally, human feedback is needed to determine the optimal prompt formulation and keyword combination. In this paper, we present a human-in-the-loop approach to learning the most useful combination of prompt keywords using a genetic algorithm. We also show how such an approach can improve the aesthetic appeal of images depicting the same descriptions.
    
[^97]: 大型语言模型能否像人类一样知道别人的信仰？

    Do Large Language Models know what humans know?. (arXiv:2209.01515v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.01515](http://arxiv.org/abs/2209.01515)

    本文测试了语言暴露假说，评估语言模型是否能够像人类一样感知书面文本中角色的知识状态。结果显示，语言模型虽然超过了偶然行为，但表现不如人类，暗示着仅靠语言暴露难以完全解释人类这种认知能力。

    

    人类能够了解他人的信仰。然而，尚不清楚这种能力在多大程度上是源于天生的生物禀赋，还是来源于儿童发育过程中的经验积累，尤其是通过接受描述他人心理状态的语言而获得的经验。我们通过评估暴露于大量人类语言的模型是否显示对书面段落中角色暗示的知识状态敏感性来测试语言暴露假说的可行性。在预注册的分析中，我们向人类参与者和大型语言模型GPT-3提供了语言版本的误信任务。两者都敏感于他人的信仰，而语言模型显著超过了偶然行为，但它的表现不如人类，并且没有解释他们行为的全部范围--尽管语言模型接受了比一个人一生中接受的语言更多的语言。这表明，虽然从语言暴露中进行的统计学习可能在一定程度上解释了人类如何做到这一点，但它并不能完全解释人类的行为。

    Humans can attribute beliefs to others. However, it is unknown to what extent this ability results from an innate biological endowment or from experience accrued through child development, particularly exposure to language describing others' mental states. We test the viability of the language exposure hypothesis by assessing whether models exposed to large quantities of human language display sensitivity to the implied knowledge states of characters in written passages. In pre-registered analyses, we present a linguistic version of the False Belief Task to both human participants and a Large Language Model, GPT-3. Both are sensitive to others' beliefs, but while the language model significantly exceeds chance behavior, it does not perform as well as the humans, nor does it explain the full extent of their behavior -- despite being exposed to more language than a human would in a lifetime. This suggests that while statistical learning from language exposure may in part explain how huma
    
[^98]: Claim-Dissector: 一款联合重排和真实性预测的可解释的事实核查系统

    Claim-Dissector: An Interpretable Fact-Checking System with Joint Re-ranking and Veracity Prediction. (arXiv:2207.14116v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2207.14116](http://arxiv.org/abs/2207.14116)

    Claim-Dissector是一款联合重排和真实性预测的可解释的事实核查系统，可以识别与声明相关的证据，并确定声明的真实性。该系统的个人贡献以及证据所支持或反驳声明的贡献都可以被识别。

    

    我们提出了Claim-Dissector，一种针对事实核查和分析的新型潜变量模型，给出一个声明和一组检索到的证据，联合学习识别：（i）与给定声明相关的证据，（ii）声明的真实性。我们建议以可解释的方式解开每个证据的相关性概率及其对最终真实性概率的影响-最终真实性概率与每个证据相关性概率的线性整合成比例。通过这种方式，可以识别出每个证据对最终预测概率的个人贡献。在每个证据的相关性概率中，我们的模型还可以进一步区分每个相关证据是支持（S）还是反驳（R）声明。这样可以量化S/R概率对最终结论的贡献或检测有异议的证据。尽管我们的系统具有可解释性，但在FEVER竞赛中，其结果与最先进的结果相当。

    We present Claim-Dissector: a novel latent variable model for fact-checking and analysis, which given a claim and a set of retrieved evidences jointly learns to identify: (i) the relevant evidences to the given claim, (ii) the veracity of the claim. We propose to disentangle the per-evidence relevance probability and its contribution to the final veracity probability in an interpretable way -- the final veracity probability is proportional to a linear ensemble of per-evidence relevance probabilities. In this way, the individual contributions of evidences towards the final predicted probability can be identified. In per-evidence relevance probability, our model can further distinguish whether each relevant evidence is supporting (S) or refuting (R) the claim. This allows to quantify how much the S/R probability contributes to the final verdict or to detect disagreeing evidence.  Despite its interpretable nature, our system achieves results competitive with state-of-the-art on the FEVER 
    
[^99]: GENEVA：“通用性基准测试”事件论元提取，涵盖数百种事件类型和论元角色

    GENEVA: Benchmarking Generalizability for Event Argument Extraction with Hundreds of Event Types and Argument Roles. (arXiv:2205.12505v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.12505](http://arxiv.org/abs/2205.12505)

    本文提出了一个大而全的EAE本体论，105个事件和220个论元角色的包含在内，利用这个本体论创建了一种多样化的通用性基准测试数据集GENEVA，共包含四个测试套件，旨在评估模型处理有限数据的能力。

    

    最近事件论元提取（EAE）的研究关注于提高模型的通用性以适应新的事件类型和领域。然而，标准的评估数据集如ACE和ERE只涵盖不到40种事件类型和25种面向实体的论元角色。数据集的有限多样性和覆盖范围影响了这些数据集对EAE模型通用性的充分评估。本文提出了一个大而全的EAE本体论，在FrameNet的基础上创建了包含115个事件和220个论元角色的本体论，其中许多角色不是实体。我们利用这个本体论进一步引入了GENEVA，一种多样化的通用性基准测试数据集，包括四个测试套件，旨在评估模型处理有限数据的能力。

    Recent works in Event Argument Extraction (EAE) have focused on improving model generalizability to cater to new events and domains. However, standard benchmarking datasets like ACE and ERE cover less than 40 event types and 25 entity-centric argument roles. Limited diversity and coverage hinder these datasets from adequately evaluating the generalizability of EAE models. In this paper, we first contribute by creating a large and diverse EAE ontology. This ontology is created by transforming FrameNet, a comprehensive semantic role labeling (SRL) dataset for EAE, by exploiting the similarity between these two tasks. Then, exhaustive human expert annotations are collected to build the ontology, concluding with 115 events and 220 argument roles, with a significant portion of roles not being entities. We utilize this ontology to further introduce GENEVA, a diverse generalizability benchmarking dataset comprising four test suites, aimed at evaluating models' ability to handle limited data a
    
[^100]: 空中对话与导航：一种基于自然语言的无人机导航方法

    Aerial Vision-and-Dialog Navigation. (arXiv:2205.12219v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2205.12219](http://arxiv.org/abs/2205.12219)

    本文介绍了一种名为AVDN的无人机导航方法，该方法通过自然语言对话来控制无人机的导航，为解决无人机控制的人体负担、多任务操作、以及残疾人和手部占用者控制无人机的难题提供了新思路。

    

    能够与人类进行对话并遵循自然语言指令是智能无人机（即无人机）的关键能力。它可以减轻人们一直握着控制器的负担，允许同时进行多项任务，使残疾人或手部占用者更容易控制无人机。为此，我们介绍了一种名为Aerial Vision-and-Dialog Navigation（AVDN）的无人机导航方法，通过自然语言对话来控制无人机的导航。我们构建了一个带有连续逼真环境的无人机模拟器，并收集了一组新的AVDN数据集，其中包括超过3,000个记录的导航轨迹以及指挥官和跟随者之间的异步人际对话。指挥官提供初始导航指令，并根据需要提供进一步的指导，而跟随者在模拟器中导航无人机并在需要时提问。在数据收集过程中，跟随者对无人机的视觉观察也被记录下来。基于AVDN数据集，我们研究了无人机导航的任务。

    The ability to converse with humans and follow natural language commands is crucial for intelligent unmanned aerial vehicles (a.k.a. drones). It can relieve people's burden of holding a controller all the time, allow multitasking, and make drone control more accessible for people with disabilities or with their hands occupied. To this end, we introduce Aerial Vision-and-Dialog Navigation (AVDN), to navigate a drone via natural language conversation. We build a drone simulator with a continuous photorealistic environment and collect a new AVDN dataset of over 3k recorded navigation trajectories with asynchronous human-human dialogs between commanders and followers. The commander provides initial navigation instruction and further guidance by request, while the follower navigates the drone in the simulator and asks questions when needed. During data collection, followers' attention on the drone's visual observation is also recorded. Based on the AVDN dataset, we study the tasks of aerial
    
[^101]: SMARAGD: 学习SMATCH以获得准确快速的近似图距离

    SMARAGD: Learning SMatch for Accurate and Rapid Approximate Graph Distance. (arXiv:2203.13226v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.13226](http://arxiv.org/abs/2203.13226)

    本文提出了SMARAGD算法，用于进行准确快速的近似图距离，并使用神经网络以线性时间或恒定时间近似Smatch分数，通过数据增强和图像匿名化，大幅减少了近似误差。

    

    常用结构匹配算法（如Smatch）来评估图像结构（如含义表示），但这些算法面临着NP完备问题，使得大规模应用不可行。为了解决这个问题，我们学习了SMARAGD，即用于准确快速近似图距离的语义匹配。我们表明，通过数据增强和图像匿名化可以大幅减少近似误差。

    The similarity of graph structures, such as Meaning Representations (MRs), is often assessed via structural matching algorithms, such as Smatch (Cai and Knight, 2013). However, Smatch involves a combinatorial problem that suffers from NP-completeness, making large-scale applications, e.g., graph clustering or search, infeasible. To alleviate this issue, we learn SMARAGD: Semantic Match for Accurate and Rapid Approximate Graph Distance. We show the potential of neural networks to approximate Smatch scores, i) in linear time using a machine translation framework to predict alignments, or ii) in constant time using a Siamese CNN to directly predict Smatch scores. We show that the approximation error can be substantially reduced through data augmentation and graph anonymization.
    

