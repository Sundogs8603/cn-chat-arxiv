# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Let Me Teach You: Pedagogical Foundations of Feedback for Language Models.](http://arxiv.org/abs/2307.00279) | 这篇观点文章介绍了一个基于教育学理念的反馈框架FELT，用于对大型语言模型进行反馈，以提高模型与人类偏好的一致性。该框架不仅简化了现有的手工设计反馈，还为NLF研究开辟了新方向。 |
| [^2] | [Hierarchical Pretraining for Biomedical Term Embeddings.](http://arxiv.org/abs/2307.00266) | 分层预训练用于生物医学术语嵌入，通过将临床术语表示为语义嵌入并利用低维嵌入作为特征向量，可以提高临床记录的自然语言处理（NLP）效果。 |
| [^3] | [InstructEval: Systematic Evaluation of Instruction Selection Methods.](http://arxiv.org/abs/2307.00259) | InstructEval开发了一个评估套件，用于对指令选择方法进行全面评估。通过使用策划的手动编写的指令，可以显著提高性能。 |
| [^4] | [Image Matters: A New Dataset and Empirical Study for Multimodal Hyperbole Detection.](http://arxiv.org/abs/2307.00209) | 本研究提出了一个新的多模态夸张检测数据集，并使用文本和图像作为两种模态进行研究。同时，评估了不同预训练的多模态编码器在此任务中的表现。该研究探索了夸张检测的跨领域性能。 |
| [^5] | [How far is Language Model from 100% Few-shot Named Entity Recognition in Medical Domain.](http://arxiv.org/abs/2307.00186) | 本文对语言模型在医学领域少样本命名实体识别中的性能进行了调查研究，并探索了提高NER性能的有效实体识别器。 |
| [^6] | [Personality Traits in Large Language Models.](http://arxiv.org/abs/2307.00184) | 该研究介绍了一种综合方法，用于验证大型语言模型（LLMs）生成的文本中展示的人格特质。研究发现，部分LLMs在特定提示配置下模拟的人格可靠且有效，特别是对于更大和经过指导微调的模型。此外，LLMs的输出中的人格特质可以根据需要进行塑造。 |
| [^7] | [Still No Lie Detector for Language Models: Probing Empirical and Conceptual Roadblocks.](http://arxiv.org/abs/2307.00175) | 本文讨论了大型语言模型是否具有信念以及如何衡量它们的问题，并通过实证结果和对最新论证的分析，指出现在仍然没有针对大型语言模型的谎言探测器。 |
| [^8] | [The Integer Linear Programming Inference Cookbook.](http://arxiv.org/abs/2307.00171) | 本论文介绍了一个整数线性规划推理手册，用于将推理问题转化为整数线性规划实例。通过一系列技巧的演示，帮助读者理解如何应用这些方法。论文最后提供了两个示例以说明这些技巧的使用。 |
| [^9] | [What do self-supervised speech models know about words?.](http://arxiv.org/abs/2307.00162) | 通过对自我监督的语音模型进行分析，发现这些模型在不同层中编码了不同的语言信息，也学习了类似音素的子词单元。与单词相关的信息主要在中间的模型层中，同时一些低级信息在更高的层中也得以保留。 |
| [^10] | [SMILE: Evaluation and Domain Adaptation for Social Media Language Understanding.](http://arxiv.org/abs/2307.00135) | 本研究评估了基于Transformer模型的语言模型对社交媒体语言的理解能力，并引入了新的社交媒体语言评估基准（SMILE）。结果表明，社交媒体语言与传统语言存在显著差异，混合社交媒体和传统语言的预训练模型在SMILE评分上表现最好，比其他同规模模型高出4.2个点。 |
| [^11] | [iMETRE: Incorporating Markers of Entity Types for Relation Extraction.](http://arxiv.org/abs/2307.00132) | 本文针对金融数据集REFinD中的关系抽取任务，通过结合带类型实体标记的表示和在数据集上微调的模型，实现了69.65%的F1得分。 |
| [^12] | [Information Extraction in Domain and Generic Documents: Findings from Heuristic-based and Data-driven Approaches.](http://arxiv.org/abs/2307.00130) | 这项研究调查了基于启发式和数据驱动方法在特定领域和通用文档中执行信息提取任务的准确性和泛化能力，并发现没有单一的方法能够展示出超越其他方法的全面优势。 |
| [^13] | [Meta-training with Demonstration Retrieval for Efficient Few-shot Learning.](http://arxiv.org/abs/2307.00119) | 该论文提出了一种具有演示检索的元训练方法，通过使用密集的段落检索器检索与每个示例语义相似的标记演示来提高少样本学习的效果。通过将外部知识与模型参数分离，可以训练出参数高效且泛化能力强的模型。 |
| [^14] | [Ticket-BERT: Labeling Incident Management Tickets with Language Models.](http://arxiv.org/abs/2307.00108) | Ticket-BERT是一个使用语言模型为事件管理票据进行标注的方法，在解决复杂的票据数据和时间敏感性问题方面具有优势。 |
| [^15] | [Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models.](http://arxiv.org/abs/2307.00101) | 本文通过比较研究了大型语言模型（LLMs）在生成描述不同性别认同的人的文本时产生的偏见问题，发现存在对同志人群的偏见。研究者提出了一种基于SHAP分析的思维链触发的事后方法，可以增加句子的regard，为去除LLMs输出偏见提供了一个有希望的途径。 |
| [^16] | [Seeing in Words: Learning to Classify through Language Bottlenecks.](http://arxiv.org/abs/2307.00028) | 本文提出了一种通过语言瓶颈学习分类的方法，利用文本表示特征的视觉模型能够有效分类ImageNet图像，可以增加神经网络的可解释性。 |
| [^17] | [SAHAAYAK 2023 -- the Multi Domain Bilingual Parallel Corpus of Sanskrit to Hindi for Machine Translation.](http://arxiv.org/abs/2307.00021) | SAHAAYAK 2023是一个包含多个领域数据的梵语到印地语的大规模双语平行语料库，该语料库通过多方面的方法制作，将具有普适性和平衡性的数据纳入其中，并应用了广泛的挖掘和清洗技术。 |
| [^18] | [Automated Assignment and Classification of Software Issues.](http://arxiv.org/abs/2307.00009) | 本论文提出了一种自动分配和分类软件问题的方法。通过使用经过精心策划的语言特征和不同的机器学习方法，将问题分配给最相关的团队成员，并将其分类为不同的类别，以提高工作效率和准确性。 |
| [^19] | [Investigating Masking-based Data Generation in Language Models.](http://arxiv.org/abs/2307.00008) | 本研究探索了基于掩码的数据生成在语言模型中的应用，结果表明该方法可以提高模型性能。 |
| [^20] | [SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs.](http://arxiv.org/abs/2306.17842) | 本研究引入了SPAE，使用语义金字塔自编码器实现了冻结LLM执行涉及非语言模态的理解和生成任务。通过将图像转化为LLM可理解的词汇标记，我们的方法成功地提升了冻结LLM在图像理解任务中的性能，超过了现有技术25%以上。 |
| [^21] | [Statler: State-Maintaining Language Models for Embodied Reasoning.](http://arxiv.org/abs/2306.17840) | Statler是一个为LLMs赋予了明确的、维持状态的语言模型，可以解决当代LLMs在长时间范围内推理的困难。 |
| [^22] | [Progressive Multi-task Learning Framework for Chinese Text Error Correction.](http://arxiv.org/abs/2306.17447) | 我们提出了一种面向中文文本错误校正的渐进式多任务学习框架ProTEC，该框架通过引导模型从易到难地学习错误检测、错误类型识别和校正结果生成，以解决过纠正的问题。 |
| [^23] | [LMBot: Distilling Graph Knowledge into Language Model for Graph-less Deployment in Twitter Bot Detection.](http://arxiv.org/abs/2306.17408) | LMBot是一种新颖的推特机器人检测框架，将图神经网络的知识融入到语言模型中，实现了无图形部署，以解决数据依赖性的挑战。 |
| [^24] | [Presenting an approach based on weighted CapsuleNet networks for Arabic and Persian multi-domain sentiment analysis.](http://arxiv.org/abs/2306.17068) | 本文提出了一种基于加权胶囊网络的阿拉伯语和波斯语多领域情感分析方法，通过训练单独的胶囊网络并使用加权度量来实现情感分类，具有较好的准确性和适应性。 |
| [^25] | [Probabilistic Linguistic Knowledge and Token-level Text Augmentation.](http://arxiv.org/abs/2306.16644) | 研究了标记级文本增强的有效性和概率语言知识的作用，实验证明了所研究的五种标记级文本增强技术在语言评估环境下不具备普遍有效性，而且与不同分类模型类型无关。 |
| [^26] | [SparseOptimizer: Sparsify Language Models through Moreau-Yosida Regularization and Accelerate through Compiler Co-design.](http://arxiv.org/abs/2306.15656) | SparseOptimizer是一种深度学习优化器，通过Moreau-Yosida正则化在大型语言模型中引入稀疏性。它采用嵌入的收缩操作符，无需对代码进行修改即可适应各种大型语言模型，并在各种基准数据集上实现与密集型模型相当的性能，同时减少参数数量。 |
| [^27] | [MindDial: Belief Dynamics Tracking with Theory-of-Mind Modeling for Situated Neural Dialogue Generation.](http://arxiv.org/abs/2306.15253) | MindDial是一个使用心智模拟进行信念动态跟踪的对话生成框架，可以在场景化环境中生成自由对话来协商共识。 |
| [^28] | [On the Reliability of Watermarks for Large Language Models.](http://arxiv.org/abs/2306.04634) | 本文研究了大型语言模型水印在混合其他文本来源时的可靠性，并提供了在实际应用中的建议。 |
| [^29] | [LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion.](http://arxiv.org/abs/2306.02561) | 本论文提出了LLM-Blender，它是一个集成框架，旨在利用不同的开源大型语言模型的优秀特性，实现始终如一的卓越性能。PairRanker和GenFuser是该框架的两个模块，PairRanker使用成对比较方法来区分候选输出，并且GenFuser旨在合并排名最高的候选者，以生成改进的输出。 |
| [^30] | [Measuring the Robustness of Natural Language Processing Models to Domain Shifts.](http://arxiv.org/abs/2306.00168) | 本文探讨了自然领域转移设置下微调和小样本学习模型的DR挑战，引入了一个DR基准，提出了DR挑战的两个视角：源域降低（SD）和目标域降低（TD），并发现两者之一通常是正值，强调了评估DR挑战的两个视角的重要性。 |
| [^31] | [W-procer: Weighted Prototypical Contrastive Learning for Medical Few-Shot Named Entity Recognition.](http://arxiv.org/abs/2305.18624) | W-procer是一种基于加权原型对比学习的医学少样本命名实体识别方法，在构建基于原型的对比损失和加权网络方面具有创新性，优于现有的最先进方法。 |
| [^32] | [Practical PCG Through Large Language Models.](http://arxiv.org/abs/2305.18243) | 本研究介绍了如何利用语言模型生成游戏房间，在仅有少量数据的情况下，可以生成多达37%的可玩新颖关卡，该技术有助于解决包含许多局部和全局约束的PCG问题。 |
| [^33] | [Scan and Snap: Understanding Training Dynamics and Token Composition in 1-layer Transformer.](http://arxiv.org/abs/2305.16380) | 本文分析了1层Transformer在下一个标记预测任务中的SGD训练动态，证明了自我关注层充当了“区分性扫描算法”，从而逐步关注到相关标记并排除不相关的标记，总结相关信息在编码表示中。同时研究了标记频率、上下文和初始化自我关注层等对Transformer性能的影响。 |
| [^34] | [MERGE: Fast Private Text Generation.](http://arxiv.org/abs/2305.15769) | 该论文提出了MERGE，一个基于Transformer语言模型的快速私有文本生成框架。实验结果表明，MERGE在保护隐私的同时，实现了26.5倍的加速和80%的通信字节数减少。 |
| [^35] | [Zero-shot Approach to Overcome Perturbation Sensitivity of Prompts.](http://arxiv.org/abs/2305.15689) | 本研究提出了一种零样本方法，自动生成多个类似于基础提示的高质量提示，并使用新的度量方法进行排名，从而克服了提示的扰动敏感性，并在情感分类任务中具有较高的准确性。 |
| [^36] | [Is ChatGPT Fair for Recommendation? Evaluating Fairness in Large Language Model Recommendation.](http://arxiv.org/abs/2305.07609) | 这篇论文介绍了一种新的推荐范式——通过LLM进行推荐，但由于LLMs可能存在社会偏见，需要进一步调查RecLLM所做推荐的公正性。为此，作者提出了一个新的公平性基准——FaiRLLM，并针对音乐和电影推荐场景中的八个敏感属性进行了评估。 |
| [^37] | [How to Index Item IDs for Recommendation Foundation Models.](http://arxiv.org/abs/2305.06569) | 本研究对推荐基础模型的项目索引问题进行了系统检查，提出了一种新的上下文感知索引方法，该方法在项目推荐准确性和文本生成质量方面具有优势。 |
| [^38] | [Analysis of Climate Campaigns on Social Media using Bayesian Model Averaging.](http://arxiv.org/abs/2305.06174) | 本文分析了工业、倡导组织和气候倡导组织在社交媒体上如何影响气候变化的叙事，并提出了一个最小化监督模型组合方法，用于识别Facebook上气候广告的立场。 |
| [^39] | [Can ChatGPT Forecast Stock Price Movements? Return Predictability and Large Language Models.](http://arxiv.org/abs/2304.07619) | 本研究探究了使用ChatGPT及其他大型语言模型预测股市回报的潜力，发现ChatGPT的预测表现优于传统情感分析方法，而基础模型无法准确预测股票价格变化，表明复杂模型可预测能力的崛起。这表明在投资决策过程中引入先进的语言模型可以提高预测准确性并增强定量交易策略的表现。 |
| [^40] | [Understand Legal Documents with Contextualized Large Language Models.](http://arxiv.org/abs/2303.12135) | 本文介绍了针对 SemEval-2023 任务 6 开发的 Legal-BERT-HSLN 模型和 Legal-LUKE 模型，其中 Legal-BERT-HSLN 模型通过考虑句内和句间的上下文信息以预测修辞角色，Legal-LUKE 模型是具有法律上下文和实体知识的模型，以识别法律实体。模型相比基线模型更准确，能够解决在人口众多的国家处理法律文件的问题。 |
| [^41] | [An Overview on Language Models: Recent Developments and Outlook.](http://arxiv.org/abs/2303.05759) | 这篇综述论文介绍了传统语言模型和预训练语言模型的概念、方法和应用，探讨了二者之间的关系，并展望了预训练时代语言建模的未来方向。 |
| [^42] | [Zero-Shot Cross-Lingual Summarization via Large Language Models.](http://arxiv.org/abs/2302.14229) | 本文实验性地使用各种提示来指导大型语言模型从不同的范式执行零样本跨语言摘要，并成功提高了它们的CLS性能。其中，GPT-4实现了零样本CLS的最先进性能，并且在性能方面与最佳方法相当。 |
| [^43] | [Task-Specific Skill Localization in Fine-tuned Language Models.](http://arxiv.org/abs/2302.06600) | 本文提出了针对Fine-tuned语言模型中任务特定技能定位的问题，并提出了一种解决方案，通过优化可以识别出贡献模型性能的非常小的参数子集，使得将Fine-tuned的值嫁接到这个子集上可以获得几乎和Fine-tuned模型一样好的性能。 |
| [^44] | [Bipol: Multi-axes Evaluation of Bias with Explainability in Benchmark Datasets.](http://arxiv.org/abs/2301.12139) | 本研究使用一种新的多维度偏差度量指标bipol，评估了五个英文和两个瑞典的自然语言处理基准数据集中的偏差，并提供了一个新的、包含200万个样本的瑞典偏差标注数据集和用于瑞典偏差检测的多维度词库。 |
| [^45] | [When Not to Trust Language Models: Investigating Effectiveness and Limitations of Parametric and Non-Parametric Memories.](http://arxiv.org/abs/2212.10511) | 本文通过对10个模型和4种增强方法的实验，发现语言模型在记忆不太流行的实际知识方面存在困难，而检索增强的语言模型表现较好，提出了一种检索增强语言模型的简单有效方法。 |
| [^46] | [IndicMT Eval: A Dataset to Meta-Evaluate Machine Translation metrics for Indian Languages.](http://arxiv.org/abs/2212.10180) | 本文填补了对从英文到印度语言的机器翻译系统进行系统性研究的空白，通过创建包含7000个细粒度注释的MQM数据集，发现预训练的指标与注释者分数具有最高的相关性，并指出现有的评估指标不能准确评估印度语言的机器翻译质量。 |
| [^47] | [Human-in-the-loop Evaluation for Early Misinformation Detection: A Case Study of COVID-19 Treatments.](http://arxiv.org/abs/2212.09683) | 该论文提出了一种人机协同评估框架，用于检测新的虚假信息声明并识别支持它们的社交媒体消息。在COVID-19治疗的案例中，基于现代NLP方法开发基线系统，并展示了人类事实核查人员每小时可以识别出违反Twitter关于COVID-19虚假信息方针的124条推文。 |
| [^48] | [PromptBoosting: Black-Box Text Classification with Ten Forward Passes.](http://arxiv.org/abs/2212.09257) | PromptBoosting是一种黑盒文本分类的方法，通过一小组提示和AdaBoost算法将神经语言模型的输出分布构建为大量弱学习器，从而实现了高效的分类器训练过程。 |
| [^49] | [Cracking Double-Blind Review: Authorship Attribution with Deep Learning.](http://arxiv.org/abs/2211.07467) | 该论文提出了一种基于深度学习的作者归属度量方法，通过利用文本内容和参考文献中的作者姓名，可以将匿名手稿正确归属给作者。该方法在迄今为止最大的作者身份识别数据集上进行了训练和评估，在包含多达2000个不同作者的arXiv子集中，取得了前所未有的作者归属准确性。 |
| [^50] | [Language-agnostic Code-Switching in Sequence-To-Sequence Speech Recognition.](http://arxiv.org/abs/2210.08992) | 这项研究提出了一种数据增强方法，用于训练能够转录代码切换（CS）语音的多语言系统。通过将不同源语言的音频和标签连接起来，可以改善模型在转录CS语音上的性能，并在单语测试中超过了单语模型。这种增强技术甚至可以提高模型在训练期间未见过的句间语言切换上的性能。 |
| [^51] | [PASTA: A Dataset for Modeling Participant States in Narratives.](http://arxiv.org/abs/2208.00329) | PASTA是一个新的用于建模叙述中参与者状态的数据集。通过推断隐含的状态和理解状态变化对叙述的影响，PASTA在三个基于状态的推理任务中进行了验证。实验结果显示，现有的语言模型在一定程度上能够进行状态推理，但仍存在局限性。 |
| [^52] | [Few-shot Reranking for Multi-hop QA via Language Model Prompting.](http://arxiv.org/abs/2205.12650) | 本研究提出了PromptRank方法，通过语言模型提供的多跳路径再排名，实现了少样本的多跳问题检索。在HotpotQA数据集上，PromptRank相比于其他方法使用的大量训练样本，仅使用128个训练示例就能达到较高的召回率。 |
| [^53] | [ELQA: A Corpus of Metalinguistic Questions and Answers about English.](http://arxiv.org/abs/2205.00395) | ELQA是一个关于英语的元语言问题与答案的语料库，可以用于研究NLU模型的元语言能力和语言学习应用。 |
| [^54] | [CPTAM: Constituency Parse Tree Aggregation Method.](http://arxiv.org/abs/2201.07905) | 本文提出了一种依存句法树聚合方法，通过估计不同解析器的可靠性，以持续获得高质量的聚合依存句法树。具体来说，通过最小化树之间的经典对称距离度量，罗宾逊-福尔兹距离的加权和，实现了树结构的真实性发现。 |
| [^55] | [A model of interaction semantics.](http://arxiv.org/abs/2007.06258) | 本研究提出了一种交互语义模型，通过构建系统交互模型，并不依赖于字符到概念的“心理”映射，来理解交互中字符的“含义”。 |

# 详细

[^1]: 让我来教你：语言模型的反馈教育基础

    Let Me Teach You: Pedagogical Foundations of Feedback for Language Models. (arXiv:2307.00279v1 [cs.CL])

    [http://arxiv.org/abs/2307.00279](http://arxiv.org/abs/2307.00279)

    这篇观点文章介绍了一个基于教育学理念的反馈框架FELT，用于对大型语言模型进行反馈，以提高模型与人类偏好的一致性。该框架不仅简化了现有的手工设计反馈，还为NLF研究开辟了新方向。

    

    自然语言反馈（NLF）是将大型语言模型（LLMs）与人类偏好对齐的一个越来越受欢迎的途径。尽管NLF可以传达丰富多样的信息，但往往是手工设计的和随意的。在不同的世界中，教育学研究长期以来建立了几种有效的反馈模型。在这篇观点文章中，我们汇编了来自教育学的思想，引入了一种名为FELT的LLMs反馈框架，概述了反馈空间的各种特征以及基于这些变量的反馈内容分类法。我们的分类法不仅提供了对反馈空间的一般映射，还提供了教育学确定的离散类别，使我们能够从经验上证明不同反馈类型对修订生成的影响。除了简化现有的NLF设计，FELT还为NLF研究带来了新的未开发的方向。我们将我们的分类法提供给社区，为映射我们的类别提供指南和示例。

    Natural Language Feedback (NLF) is an increasingly popular avenue to align Large Language Models (LLMs) to human preferences. Despite the richness and diversity of the information it can convey, NLF is often hand-designed and arbitrary. In a different world, research in pedagogy has long established several effective feedback models. In this opinion piece, we compile ideas from pedagogy to introduce FELT, a feedback framework for LLMs that outlines the various characteristics of the feedback space, and a feedback content taxonomy based on these variables. Our taxonomy offers both a general mapping of the feedback space, as well as pedagogy-established discrete categories, allowing us to empirically demonstrate the impact of different feedback types on revised generations. In addition to streamlining existing NLF designs, FELT also brings out new, unexplored directions for research in NLF. We make our taxonomy available to the community, providing guides and examples for mapping our cat
    
[^2]: 分层预训练用于生物医学术语嵌入

    Hierarchical Pretraining for Biomedical Term Embeddings. (arXiv:2307.00266v1 [cs.CL])

    [http://arxiv.org/abs/2307.00266](http://arxiv.org/abs/2307.00266)

    分层预训练用于生物医学术语嵌入，通过将临床术语表示为语义嵌入并利用低维嵌入作为特征向量，可以提高临床记录的自然语言处理（NLP）效果。

    

    电子健康记录（EHR）包含了关于患者的医疗状况和管理的详细说明。通过自然语言处理（NLP）对临床记录进行处理，可以利用临床术语的观察频率作为预测特征，用于临床决策和患者轨迹预测等下游应用。然而，由于大量相似且相关的临床概念，更有效的建模策略是通过表示学习将临床术语表示为语义嵌入，并将低维嵌入作为特征向量用于预测建模。为了实现高效的表示，利用与生物医学知识图谱进行预训练语言模型的微调，可能会生成比仅使用标准语言模型获得的生物医学术语嵌入更好的嵌入。这些嵌入可以有效区分同义词对和不相关的词对。然而，它们常常无法捕捉到不同的程度

    Electronic health records (EHR) contain narrative notes that provide extensive details on the medical condition and management of patients. Natural language processing (NLP) of clinical notes can use observed frequencies of clinical terms as predictive features for downstream applications such as clinical decision making and patient trajectory prediction. However, due to the vast number of highly similar and related clinical concepts, a more effective modeling strategy is to represent clinical terms as semantic embeddings via representation learning and use the low dimensional embeddings as feature vectors for predictive modeling. To achieve efficient representation, fine-tuning pretrained language models with biomedical knowledge graphs may generate better embeddings for biomedical terms than those from standard language models alone. These embeddings can effectively discriminate synonymous pairs of from those that are unrelated. However, they often fail to capture different degrees o
    
[^3]: InstructEval: 系统评估指令选择方法

    InstructEval: Systematic Evaluation of Instruction Selection Methods. (arXiv:2307.00259v1 [cs.CL])

    [http://arxiv.org/abs/2307.00259](http://arxiv.org/abs/2307.00259)

    InstructEval开发了一个评估套件，用于对指令选择方法进行全面评估。通过使用策划的手动编写的指令，可以显著提高性能。

    

    上下文学习 (ICL) 通过使用指令和一小组注释示例来提示一个大型语言模型 (LLM) 来执行任务。最近的工作表明，提示中使用的输入的细节对 ICL 有着重要影响，这激励了指令选择算法的发展。然而，指令选择的影响尚未得到深入探索，现有的分析仅限于模型和任务的浅层子集，这限制了洞察力的普适性。我们开发了一个 ICL 评估套件，以对这些技术进行全面评估。该套件包括来自4个不同模型家族的13个开源LLM，涵盖9个不同的任务，代表了3个分类中各种类型的任务。在本研究中，我们使用我们的基准测试评估了7种受欢迎的指令选择方法相对于ICL相关的五项期望性能。我们发现使用策划的手动编写的指令可以显著地提高性能。

    In-context learning (ICL) performs tasks by prompting a large language model (LLM) using an instruction and a small set of annotated examples called demonstrations. Recent work has shown that the precise details of the inputs used in the prompt significantly impacts ICL, which has incentivized instruction selection algorithms. The effect of instruction-choice however is severely underexplored, with existing analyses being restricted to shallow subsets of models and tasks, which limits the generalizability of their insights. We develop an ICL evaluation suite to conduct a thorough assessment of these techniques. The suite includes 13 open-sourced LLMs of varying scales from 4 distinct model families and covers 9 different tasks, representing a range of task types across 3 categories. In this work, we evaluate the relative performance of 7 popular instruction selection methods using our benchmark over five desiderata relevant to ICL. We discover that using curated manually-written instru
    
[^4]: 图像的重要性：多模态夸张检测的新数据集和实证研究

    Image Matters: A New Dataset and Empirical Study for Multimodal Hyperbole Detection. (arXiv:2307.00209v1 [cs.CV])

    [http://arxiv.org/abs/2307.00209](http://arxiv.org/abs/2307.00209)

    本研究提出了一个新的多模态夸张检测数据集，并使用文本和图像作为两种模态进行研究。同时，评估了不同预训练的多模态编码器在此任务中的表现。该研究探索了夸张检测的跨领域性能。

    

    夸张，即夸大其词，是一种常见的语言现象。夸张检测是理解人类表达的重要部分。已经有几项关于夸张检测的研究，但大多数的研究只关注文本模态。然而，随着社交媒体的发展，人们可以使用各种模态（包括文本、图像、视频等）来表达夸张。在本文中，我们专注于多模态夸张检测。我们从微博（中国的一种社交媒体）创建了一个多模态检测数据集，并对其进行了一些研究。我们将微博的文本和图像视为两种模态，探索了文本和图像在夸张检测中的作用。此外，我们还评估了不同预训练的多模态编码器在这个下游任务上的性能。由于这个数据集是从五个不同的主题构建的，我们还评估了不同领域之间的性能。

    Hyperbole, or exaggeration, is a common linguistic phenomenon. The detection of hyperbole is an important part of understanding human expression. There have been several studies on hyperbole detection, but most of which focus on text modality only. However, with the development of social media, people can create hyperbolic expressions with various modalities, including text, images, videos, etc. In this paper, we focus on multimodal hyperbole detection. We create a multimodal detection dataset\footnote{The dataset will be released to the community.} from Weibo (a Chinese social media) and carry out some studies on it. We treat the text and image from a piece of weibo as two modalities and explore the role of text and image for hyperbole detection. Different pre-trained multimodal encoders are also evaluated on this downstream task to show their performance. Besides, since this dataset is constructed from five different topics, we also evaluate the cross-domain performance of different 
    
[^5]: 从语言模型到医学领域百分之百的少样本命名实体识别有多远

    How far is Language Model from 100% Few-shot Named Entity Recognition in Medical Domain. (arXiv:2307.00186v1 [cs.CL])

    [http://arxiv.org/abs/2307.00186](http://arxiv.org/abs/2307.00186)

    本文对语言模型在医学领域少样本命名实体识别中的性能进行了调查研究，并探索了提高NER性能的有效实体识别器。

    

    最近语言模型的发展引发了强大模型的出现，如小型语言模型（如T5）和大型语言模型（如GPT-4）。这些模型在广泛的任务中表现出卓越的能力，如通用领域中的命名实体识别（NER）。然而，它们在医学领域的效果仍然不确定，由于该领域的特殊性，医学NER的性能总是需要高精度。本文旨在对医学少样本NER中的LMs的性能进行彻底调查，并回答从100％百分比中LMs与医学领域的少样本NER有多远的问题，同时探索一种有效的实体识别器以提高NER的性能。根据我们在2018年到2023年期间进行的广泛实验，我们的研究结果明确表明，LLMs o

    Recent advancements in language models (LMs) have led to the emergence of powerful models such as Small LMs (e.g., T5) and Large LMs (e.g., GPT-4). These models have demonstrated exceptional capabilities across a wide range of tasks, such as name entity recognition (NER) in the general domain. (We define SLMs as pre-trained models with fewer parameters compared to models like GPT-3/3.5/4, such as T5, BERT, and others.) Nevertheless, their efficacy in the medical section remains uncertain and the performance of medical NER always needs high accuracy because of the particularity of the field. This paper aims to provide a thorough investigation to compare the performance of LMs in medical few-shot NER and answer How far is LMs from 100\% Few-shot NER in Medical Domain, and moreover to explore an effective entity recognizer to help improve the NER performance. Based on our extensive experiments conducted on 16 NER models spanning from 2018 to 2023, our findings clearly indicate that LLMs o
    
[^6]: 大型语言模型中的人格特质

    Personality Traits in Large Language Models. (arXiv:2307.00184v1 [cs.CL])

    [http://arxiv.org/abs/2307.00184](http://arxiv.org/abs/2307.00184)

    该研究介绍了一种综合方法，用于验证大型语言模型（LLMs）生成的文本中展示的人格特质。研究发现，部分LLMs在特定提示配置下模拟的人格可靠且有效，特别是对于更大和经过指导微调的模型。此外，LLMs的输出中的人格特质可以根据需要进行塑造。

    

    大型语言模型（LLMs）的出现彻底改变了自然语言处理，使得能够生成连贯且上下文相关的文本。随着LLMs越来越多地用于驱动对话代理，这些模型通过训练大量人工生成的数据获得的人格特质引起了人们的关注。由于人格是决定交流效果的重要因素，我们提出了一种全面的方法来进行验证的心理测量测试，并对从广泛使用的LLMs生成的文本中展示的人格特质进行量化、分析和塑造。我们发现：1）某些LLMs的输出中模拟的人格（在特定的提示配置下）是可靠和有效的；2）LLM模拟的人格的可靠性和有效性的证据对于更大的和经过指导微调的模型更强；3）LLM输出中的人格可以根据需要的维度进行塑造，以模仿特定的人格特点。

    The advent of large language models (LLMs) has revolutionized natural language processing, enabling the generation of coherent and contextually relevant text. As LLMs increasingly power conversational agents, the synthesized personality embedded in these models by virtue of their training on large amounts of human-generated data draws attention. Since personality is an important factor determining the effectiveness of communication, we present a comprehensive method for administering validated psychometric tests and quantifying, analyzing, and shaping personality traits exhibited in text generated from widely-used LLMs. We find that: 1) personality simulated in the outputs of some LLMs (under specific prompting configurations) is reliable and valid; 2) evidence of reliability and validity of LLM-simulated personality is stronger for larger and instruction fine-tuned models; and 3) personality in LLM outputs can be shaped along desired dimensions to mimic specific personality profiles. 
    
[^7]: 语言模型仍然没有谎言探测器：探究经验和概念上的障碍

    Still No Lie Detector for Language Models: Probing Empirical and Conceptual Roadblocks. (arXiv:2307.00175v1 [cs.CL])

    [http://arxiv.org/abs/2307.00175](http://arxiv.org/abs/2307.00175)

    本文讨论了大型语言模型是否具有信念以及如何衡量它们的问题，并通过实证结果和对最新论证的分析，指出现在仍然没有针对大型语言模型的谎言探测器。

    

    本文讨论了大型语言模型（LLM）是否具有信念以及如何衡量它们的问题。首先，我们评估了Azaria和Mitchell（2023）以及Burns等人（2022）提出的两种现有方法，结果表明这些方法在基本方面无法推广。随后我们认为，即使LLM具有信念，这些方法也不太可能在概念上成功。因此，现在仍然没有针对LLM的谎言探测器。在描述了我们的实证结果后，我们退后一步，思考在首次中我们是否应该期待LLM具有类似信念的东西。我们考虑了一些旨在证明LLM不能有信念的最新论证，展示了这些论证是误导性的。我们对围绕LLM中信念的问题的问题提出了更有成效的框架，并强调了该问题的经验性质。最后，我们提出了一些未来工作的具体路径建议。

    We consider the questions of whether or not large language models (LLMs) have beliefs, and, if they do, how we might measure them. First, we evaluate two existing approaches, one due to Azaria and Mitchell (2023) and the other to Burns et al. (2022). We provide empirical results that show that these methods fail to generalize in very basic ways. We then argue that, even if LLMs have beliefs, these methods are unlikely to be successful for conceptual reasons. Thus, there is still no lie-detector for LLMs. After describing our empirical results we take a step back and consider whether or not we should expect LLMs to have something like beliefs in the first place. We consider some recent arguments aiming to show that LLMs cannot have beliefs. We show that these arguments are misguided. We provide a more productive framing of questions surrounding the status of beliefs in LLMs, and highlight the empirical nature of the problem. We conclude by suggesting some concrete paths for future work.
    
[^8]: 整数线性规划推理手册

    The Integer Linear Programming Inference Cookbook. (arXiv:2307.00171v1 [cs.AI])

    [http://arxiv.org/abs/2307.00171](http://arxiv.org/abs/2307.00171)

    本论文介绍了一个整数线性规划推理手册，用于将推理问题转化为整数线性规划实例。通过一系列技巧的演示，帮助读者理解如何应用这些方法。论文最后提供了两个示例以说明这些技巧的使用。

    

    多年来，整数线性规划已被用于模拟自然语言处理问题中的推理。本调查旨在指导读者将新的推理问题框架化为整数线性规划的实例，并以一系列的技巧进行组织。最后，我们将通过两个实例来说明这些技巧的使用。

    Over the years, integer linear programs have been employed to model inference in many natural language processing problems. This survey is meant to guide the reader through the process of framing a new inference problem as an instance of an integer linear program and is structured as a collection of recipes. At the end, we will see two worked examples to illustrate the use of these recipes.
    
[^9]: 自我监督的语音模型对单词的了解程度是什么？

    What do self-supervised speech models know about words?. (arXiv:2307.00162v1 [cs.CL])

    [http://arxiv.org/abs/2307.00162](http://arxiv.org/abs/2307.00162)

    通过对自我监督的语音模型进行分析，发现这些模型在不同层中编码了不同的语言信息，也学习了类似音素的子词单元。与单词相关的信息主要在中间的模型层中，同时一些低级信息在更高的层中也得以保留。

    

    在过去几年中，许多自我监督的语音模型（S3Ms）被引入，为各种语音任务提供了性能和数据效率的改进。有证据表明，不同的S3Ms在不同的层中编码语言信息，而且一些S3Ms似乎学习了类似于音素的子词单元。然而，这些模型捕捉更大的语言单元（如单词）的程度以及单词相关信息的编码位置仍然不清楚。在这项研究中，我们对来自三个S3Ms的不同层的单词片段表示进行了多种分析：wav2vec2、HuBERT和WavLM。我们利用规范相关分析（CCA），一种轻量级的分析工具，来衡量这些表示与单词级语言属性之间的相似性。我们发现最大的单词级语言内容往往出现在中间的模型层，而一些低级信息（如发音）也在更高的层中保留。

    Many self-supervised speech models (S3Ms) have been introduced over the last few years, producing performance and data efficiency improvements for a variety of speech tasks. Evidence is emerging that different S3Ms encode linguistic information in different layers, and also that some S3Ms appear to learn phone-like sub-word units. However, the extent to which these models capture larger linguistic units, such as words, and where word-related information is encoded, remains unclear. In this study, we conduct several analyses of word segment representations extracted from different layers of three S3Ms: wav2vec2, HuBERT, and WavLM. We employ canonical correlation analysis (CCA), a lightweight analysis tool, to measure the similarity between these representations and word-level linguistic properties. We find that the maximal word-level linguistic content tends to be found in intermediate model layers, while some lower-level information like pronunciation is also retained in higher layers 
    
[^10]: SMILE：对社交媒体语言理解的评估和领域适应

    SMILE: Evaluation and Domain Adaptation for Social Media Language Understanding. (arXiv:2307.00135v1 [cs.CL])

    [http://arxiv.org/abs/2307.00135](http://arxiv.org/abs/2307.00135)

    本研究评估了基于Transformer模型的语言模型对社交媒体语言的理解能力，并引入了新的社交媒体语言评估基准（SMILE）。结果表明，社交媒体语言与传统语言存在显著差异，混合社交媒体和传统语言的预训练模型在SMILE评分上表现最好，比其他同规模模型高出4.2个点。

    

    我们研究了基于Transformer模型的语言模型对社交媒体语言理解的能力。社交媒体语言与标准书面语有所不同，然而现有的评估标准未能完全捕捉语言模型在这个在社会、经济和政治层面都非常重要的领域性能。我们量化了社交媒体语言与传统语言之间的差异，并得出结论：无论是在词汇分布还是语言转变速率上，这种差异都是显著的。接下来，我们引入了一个新的社交媒体语言评估基准（SMILE），涵盖了四个社交媒体平台和十一项任务。最后，我们展示了一个学习分词器和混合社交媒体与传统语言进行预训练的方法，获得的语言模型在整体SMILE评分上比相同规模的最佳替代模型高出4.2个点。

    We study the ability of transformer-based language models (LMs) to understand social media language. Social media (SM) language is distinct from standard written language, yet existing benchmarks fall short of capturing LM performance in this socially, economically, and politically important domain. We quantify the degree to which social media language differs from conventional language and conclude that the difference is significant both in terms of token distribution and rate of linguistic shift. Next, we introduce a new benchmark for Social MedIa Language Evaluation (SMILE) that covers four SM platforms and eleven tasks. Finally, we show that learning a tokenizer and pretraining on a mix of social media and conventional language yields an LM that outperforms the best similar-sized alternative by 4.2 points on the overall SMILE score.
    
[^11]: iMETRE：将实体类型的标记融入关系抽取中

    iMETRE: Incorporating Markers of Entity Types for Relation Extraction. (arXiv:2307.00132v1 [cs.CL])

    [http://arxiv.org/abs/2307.00132](http://arxiv.org/abs/2307.00132)

    本文针对金融数据集REFinD中的关系抽取任务，通过结合带类型实体标记的表示和在数据集上微调的模型，实现了69.65%的F1得分。

    

    句子级别的关系抽取旨在根据上下文句子确定两个实体之间的关系。虽然已经有许多尝试解决这个问题的方法，但目前的解决方案仍有很大的改进空间。本文针对金融数据集REFinD中的关系抽取任务进行了研究。我们的方法结合了带类型实体标记的表示和在数据集上微调的各种模型，使我们在验证集上实现了69.65%的F1得分。通过本文，我们讨论了各种方法和可能的局限性。

    Sentence-level relation extraction (RE) aims to identify the relationship between 2 entities given a contextual sentence. While there have been many attempts to solve this problem, the current solutions have a lot of room to improve. In this paper, we approach the task of relationship extraction in the financial dataset REFinD. Our approach incorporates typed entity markers representations and various models finetuned on the dataset, which has allowed us to achieve an F1 score of 69.65% on the validation set. Through this paper, we discuss various approaches and possible limitations.
    
[^12]: 领域和通用文档中的信息提取: 基于启发式和数据驱动方法的发现

    Information Extraction in Domain and Generic Documents: Findings from Heuristic-based and Data-driven Approaches. (arXiv:2307.00130v1 [cs.CL])

    [http://arxiv.org/abs/2307.00130](http://arxiv.org/abs/2307.00130)

    这项研究调查了基于启发式和数据驱动方法在特定领域和通用文档中执行信息提取任务的准确性和泛化能力，并发现没有单一的方法能够展示出超越其他方法的全面优势。

    

    信息提取在自然语言处理中起着非常重要的作用，它对于从非结构化文本数据中提取结构化信息的许多NLP应用都是基础性的。启发式搜索和数据驱动学习是两种主流的实现方法。然而，对于文档类型和长度对IE任务的影响却没有得到足够的关注。为了填补这个空白，本研究调查了基于启发式搜索和数据驱动在特定领域和通用文档中执行两个IE任务：命名实体识别（NER）和语义角色标注（SRL）的准确性和泛化能力。我们提出了两个假设：首先，短文档可能会比长文档产生更好的准确性结果；其次，由于训练文档类型的限制，通用文档可能表现出优于领域相关文档的提取结果。我们的研究结果显示没有单一的方法能够展示出超越其他方法的全面优势。

    Information extraction (IE) plays very important role in natural language processing (NLP) and is fundamental to many NLP applications that used to extract structured information from unstructured text data. Heuristic-based searching and data-driven learning are two main stream implementation approaches. However, no much attention has been paid to document genre and length influence on IE tasks. To fill the gap, in this study, we investigated the accuracy and generalization abilities of heuristic-based searching and data-driven to perform two IE tasks: named entity recognition (NER) and semantic role labeling (SRL) on domain-specific and generic documents with different length. We posited two hypotheses: first, short documents may yield better accuracy results compared to long documents; second, generic documents may exhibit superior extraction outcomes relative to domain-dependent documents due to training document genre limitations. Our findings reveals that no single method demonstr
    
[^13]: 具有演示检索的元训练用于高效的少样本学习

    Meta-training with Demonstration Retrieval for Efficient Few-shot Learning. (arXiv:2307.00119v1 [cs.CL])

    [http://arxiv.org/abs/2307.00119](http://arxiv.org/abs/2307.00119)

    该论文提出了一种具有演示检索的元训练方法，通过使用密集的段落检索器检索与每个示例语义相似的标记演示来提高少样本学习的效果。通过将外部知识与模型参数分离，可以训练出参数高效且泛化能力强的模型。

    

    大型语言模型在少样本自然语言处理任务上取得了令人震惊的结果。然而，这些模型的内存和计算开销很大。元训练允许利用较小的模型进行通用领域和任务无关的少样本泛化；然而，仅使用这些方法会导致模型可能没有足够的参数化或知识来快速适应各种任务。为了解决这个问题，我们提出了具有演示检索的元训练，其中我们使用密集的段落检索器来检索与每个示例语义相似的标记演示，以获得更多的多样化监督。通过将外部知识与模型参数分离，我们可以使用元训练来训练参数高效的模型，在更多种类的任务上具有良好的泛化能力。我们从UnifiedQA和CrossFit构建了一个元训练集，并基于UnifiedQA任务提出了一个演示库。据我们所知，我们的工作是首次将检索与元训练结合使用，以提高少样本学习的效率。

    Large language models show impressive results on few-shot NLP tasks. However, these models are memory and computation-intensive. Meta-training allows one to leverage smaller models for few-shot generalization in a domain-general and task-agnostic manner; however, these methods alone results in models that may not have sufficient parameterization or knowledge to adapt quickly to a large variety of tasks. To overcome this issue, we propose meta-training with demonstration retrieval, where we use a dense passage retriever to retrieve semantically similar labeled demonstrations to each example for more varied supervision. By separating external knowledge from model parameters, we can use meta-training to train parameter-efficient models that generalize well on a larger variety of tasks. We construct a meta-training set from UnifiedQA and CrossFit, and propose a demonstration bank based on UnifiedQA tasks. To our knowledge, our work is the first to combine retrieval with meta-training, to u
    
[^14]: Ticket-BERT:使用语言模型为事件管理票据进行标注

    Ticket-BERT: Labeling Incident Management Tickets with Language Models. (arXiv:2307.00108v1 [cs.CL])

    [http://arxiv.org/abs/2307.00108](http://arxiv.org/abs/2307.00108)

    Ticket-BERT是一个使用语言模型为事件管理票据进行标注的方法，在解决复杂的票据数据和时间敏感性问题方面具有优势。

    

    对于解决优先级事件票据的一个重要方面是高效地使用精细分类来标注这些票据。然而，票据数据通常很复杂，给现代机器学习方法带来了几个独特的挑战：（1）票据既可以由预定义算法的机器生成，也可以由具有不同协议的具有领域专业知识的工程师更新和创建，（2）票据频繁进行修订，通过修改全部或部分票据描述来更新票据状态，（3）票据标注是时间敏感的，需要根据软件和硬件改进的快速生命周期进行知识更新和新的标签。为了解决这些问题，我们介绍了Ticket-BERT，它使用我们提出的票据数据集训练了一个简单但健壮的语言模型来为票据进行标注。实验证明，Ticket-BERT在Azure认知服务上优于基线和最先进的文本分类器。我们进一步将Ticket-BERT封装到一个积极的le...

    An essential aspect of prioritizing incident tickets for resolution is efficiently labeling tickets with fine-grained categories. However, ticket data is often complex and poses several unique challenges for modern machine learning methods: (1) tickets are created and updated either by machines with pre-defined algorithms or by engineers with domain expertise that share different protocols, (2) tickets receive frequent revisions that update ticket status by modifying all or parts of ticket descriptions, and (3) ticket labeling is time-sensitive and requires knowledge updates and new labels per the rapid software and hardware improvement lifecycle. To handle these issues, we introduce Ticket- BERT which trains a simple yet robust language model for labeling tickets using our proposed ticket datasets. Experiments demonstrate the superiority of Ticket-BERT over baselines and state-of-the-art text classifiers on Azure Cognitive Services. We further encapsulate Ticket-BERT with an active le
    
[^15]: 同志人群首先是人：解构大型语言模型中的性别认同刻板印象

    Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models. (arXiv:2307.00101v1 [cs.CL])

    [http://arxiv.org/abs/2307.00101](http://arxiv.org/abs/2307.00101)

    本文通过比较研究了大型语言模型（LLMs）在生成描述不同性别认同的人的文本时产生的偏见问题，发现存在对同志人群的偏见。研究者提出了一种基于SHAP分析的思维链触发的事后方法，可以增加句子的regard，为去除LLMs输出偏见提供了一个有希望的途径。

    

    大型语言模型（LLMs）主要在经过最小化处理的网络文本上进行训练，这些文本展现了创建该内容的人们所持有的各种社会偏见。因此，LLMs生成的文本可能无意中将刻板印象传递给边缘化群体，如LGBTQIA+社群。本文对LLMs生成描述具有不同性别认同的人的文本进行了比较研究。使用regard分数分析文本中的偏见显示出存在对同志人群的可测量偏见。然后，我们展示了一种基于SHAP分析的思维链触发的事后方法可以增加句子的regard，这代表了解决此类情况下LLMs输出偏见的一个有希望的方法。

    Large Language Models (LLMs) are trained primarily on minimally processed web text, which exhibits the same wide range of social biases held by the humans who created that content. Consequently, text generated by LLMs can inadvertently perpetuate stereotypes towards marginalized groups, like the LGBTQIA+ community. In this paper, we perform a comparative study of how LLMs generate text describing people with different sexual identities. Analyzing bias in the text generated by an LLM using regard score shows measurable bias against queer people. We then show that a post-hoc method based on chain-of-thought prompting using SHAP analysis can increase the regard of the sentence, representing a promising approach towards debiasing the output of LLMs in this setting.
    
[^16]: 通过语言瓶颈学习分类的“看见文字”论文

    Seeing in Words: Learning to Classify through Language Bottlenecks. (arXiv:2307.00028v1 [cs.CV])

    [http://arxiv.org/abs/2307.00028](http://arxiv.org/abs/2307.00028)

    本文提出了一种通过语言瓶颈学习分类的方法，利用文本表示特征的视觉模型能够有效分类ImageNet图像，可以增加神经网络的可解释性。

    

    尽管计算机视觉的神经网络在基准测试中取得了高准确性，但它们提取的特征往往是无法解释的。相比之下，人类可以用简洁直观的描述来解释他们的预测。为了将可解释性引入神经网络，我们训练了一个将特征表示为文本的视觉模型。我们展示了这样的模型在对ImageNet图像进行分类时的有效性，并讨论了我们在训练过程中遇到的挑战。

    Neural networks for computer vision extract uninterpretable features despite achieving high accuracy on benchmarks. In contrast, humans can explain their predictions using succinct and intuitive descriptions. To incorporate explainability into neural networks, we train a vision model whose feature representations are text. We show that such a model can effectively classify ImageNet images, and we discuss the challenges we encountered when training it.
    
[^17]: SAHAAYAK 2023 -- 多领域梵语到印地语机器翻译平行语料库

    SAHAAYAK 2023 -- the Multi Domain Bilingual Parallel Corpus of Sanskrit to Hindi for Machine Translation. (arXiv:2307.00021v1 [cs.CL])

    [http://arxiv.org/abs/2307.00021](http://arxiv.org/abs/2307.00021)

    SAHAAYAK 2023是一个包含多个领域数据的梵语到印地语的大规模双语平行语料库，该语料库通过多方面的方法制作，将具有普适性和平衡性的数据纳入其中，并应用了广泛的挖掘和清洗技术。

    

    该数据文章介绍了一种大型稀缺语言对梵语-印地语的双语平行语料库，名为SAHAAYAK 2023。该语料库包含了150万个梵语和印地语之间的句子对。为了使该语料库具有普适性并保持平衡，我们将来自多个领域的数据纳入了该语料库中，包括新闻、日常对话、政治、历史、体育和古代印度文学。我们采用了多方面的方法，以制作一种规模可观的梵语等稀缺语言的多领域语料库。我们的开发方法从创建一个小型手工数据集开始，然后应用了广泛的挖掘、清洗和验证技术。我们使用了三重挖掘过程：从机器可读源中挖掘、从非机器可读源中挖掘以及从现有语料库源中整理。在挖掘后，我们开发了专用的标准化、对齐和语料库清洗流程，并将其应用于该语料库。

    The data article presents the large bilingual parallel corpus of low-resourced language pair Sanskrit-Hindi, named SAHAAYAK 2023. The corpus contains total of 1.5M sentence pairs between Sanskrit and Hindi. To make the universal usability of the corpus and to make it balanced, data from multiple domain has been incorporated into the corpus that includes, News, Daily conversations, Politics, History, Sport, and Ancient Indian Literature. The multifaceted approach has been adapted to make a sizable multi-domain corpus of low-resourced languages like Sanskrit. Our development approach is spanned from creating a small hand-crafted dataset to applying a wide range of mining, cleaning, and verification. We have used the three-fold process of mining: mining from machine-readable sources, mining from non-machine readable sources, and collation from existing corpora sources. Post mining, the dedicated pipeline for normalization, alignment, and corpus cleaning is developed and applied to the cor
    
[^18]: 自动分配和分类软件问题

    Automated Assignment and Classification of Software Issues. (arXiv:2307.00009v1 [cs.CL])

    [http://arxiv.org/abs/2307.00009](http://arxiv.org/abs/2307.00009)

    本论文提出了一种自动分配和分类软件问题的方法。通过使用经过精心策划的语言特征和不同的机器学习方法，将问题分配给最相关的团队成员，并将其分类为不同的类别，以提高工作效率和准确性。

    

    软件问题包含修复、改进或创建新线程的工作单元，在开发过程中促进团队成员之间的沟通。将问题分配给最相关的团队成员并确定问题的类别是一项繁琐且具有挑战性的任务。错误的分类会导致项目延迟和重新工作，给团队成员带来麻烦。本文提出了一组经过精心策划的用于浅层机器学习方法的语言特征，并将浅层方法和集成方法与深度语言模型的性能进行了比较。与现有技术不同的是，我们将问题分配给四种角色（设计师、开发人员、测试人员和领导者），而不是特定的个人或团队，以促进我们解决方案的普遍性。我们还考虑开发人员的经验水平，以反映我们解决方案的工业实践。我们采用分类方法将问题分类为不同的类别，包括错误、新功能、改进等。

    Software issues contain units of work to fix, improve or create new threads during the development and facilitate communication among the team members. Assigning an issue to the most relevant team member and determining a category of an issue is a tedious and challenging task. Wrong classifications cause delays and rework in the project and trouble among the team members. This thesis proposes a set of carefully curated linguistic features for shallow machine learning methods and compares the performance of shallow and ensemble methods with deep language models. Unlike the state-of-the-art, we assign issues to four roles (designer, developer, tester, and leader) rather than to specific individuals or teams to contribute to the generality of our solution. We also consider the level of experience of the developers to reflect the industrial practices in our solution formulation. We employ a classification approach to categorize issues into distinct classes, namely bug, new feature, improve
    
[^19]: 探索基于掩码的数据生成在语言模型中的应用

    Investigating Masking-based Data Generation in Language Models. (arXiv:2307.00008v1 [cs.CL])

    [http://arxiv.org/abs/2307.00008](http://arxiv.org/abs/2307.00008)

    本研究探索了基于掩码的数据生成在语言模型中的应用，结果表明该方法可以提高模型性能。

    

    当BERT问世以来，当前自然语言处理（NLP）的时代已经被预训练语言模型的重要性所定义。BERT和类似结构的模型的一个特点是掩码语言建模的目标，其中部分输入被有意地掩盖，模型被训练以预测这部分被掩码的信息。数据增强是一种数据驱动的技术，广泛应用于机器学习，包括计算机视觉和自然语言处理等研究领域，通过指定的技术人工增加训练数据集以改善模型性能。掩码语言模型（MLM）是BERT的一个重要训练特点，它为基于Transformer的模型在自然语言处理任务中提供了有效的预训练方法。最近的研究利用掩码语言模型生成人工增强数据用于NLP下游任务。实验结果表明，基于掩码的数据增强可以提高模型性能。

    The current era of natural language processing (NLP) has been defined by the prominence of pre-trained language models since the advent of BERT. A feature of BERT and models with similar architecture is the objective of masked language modeling, in which part of the input is intentionally masked and the model is trained to predict this piece of masked information. Data augmentation is a data-driven technique widely used in machine learning, including research areas like computer vision and natural language processing, to improve model performance by artificially augmenting the training data set by designated techniques. Masked language models (MLM), an essential training feature of BERT, have introduced a novel approach to perform effective pre-training on Transformer based models in natural language processing tasks. Recent studies have utilized masked language model to generate artificially augmented data for NLP downstream tasks. The experimental results show that Mask based data au
    
[^20]: SPAE: 基于语义金字塔自编码器的冻结LLM的多模态生成

    SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs. (arXiv:2306.17842v1 [cs.CV])

    [http://arxiv.org/abs/2306.17842](http://arxiv.org/abs/2306.17842)

    本研究引入了SPAE，使用语义金字塔自编码器实现了冻结LLM执行涉及非语言模态的理解和生成任务。通过将图像转化为LLM可理解的词汇标记，我们的方法成功地提升了冻结LLM在图像理解任务中的性能，超过了现有技术25%以上。

    

    本研究引入了Semantic Pyramid AutoEncoder (SPAE)，使冻结的LLM能够执行涉及非语言模态（如图像或视频）的理解和生成任务。SPAE在原始像素和从LLM词汇表中提取的可解释的词汇标记（或单词）之间进行转换。生成的标记捕捉了视觉重建所需的语义含义和细粒度细节，将视觉内容转化为LLM能理解的语言，并使其能够执行各种多模态任务。我们的方法通过在多样化的图像理解和生成任务上，与冻结的PaLM 2和GPT 3.5进行上下文学习实验证实。在相同的设置下，我们的方法是第一个成功使冻结LLM生成图像内容，并在图像理解任务中的性能超过现有技术25%以上的尝试。

    In this work, we introduce Semantic Pyramid AutoEncoder (SPAE) for enabling frozen LLMs to perform both understanding and generation tasks involving non-linguistic modalities such as images or videos. SPAE converts between raw pixels and interpretable lexical tokens (or words) extracted from the LLM's vocabulary. The resulting tokens capture both the semantic meaning and the fine-grained details needed for visual reconstruction, effectively translating the visual content into a language comprehensible to the LLM, and empowering it to perform a wide array of multimodal tasks. Our approach is validated through in-context learning experiments with frozen PaLM 2 and GPT 3.5 on a diverse set of image understanding and generation tasks. Our method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.
    
[^21]: Statler：用于具身推理的保持状态的语言模型

    Statler: State-Maintaining Language Models for Embodied Reasoning. (arXiv:2306.17840v1 [cs.RO])

    [http://arxiv.org/abs/2306.17840](http://arxiv.org/abs/2306.17840)

    Statler是一个为LLMs赋予了明确的、维持状态的语言模型，可以解决当代LLMs在长时间范围内推理的困难。

    

    大型语言模型（LLMs）为机器人执行复杂的机器人推理任务提供了一种有希望的工具。然而，当代LLMs的有限上下文窗口使得在长时间范围内进行推理变得困难。具身任务（例如我们期望一个家庭机器人执行的任务）通常需要规划者考虑很久之前获得的信息（例如，机器人在环境中遇到的许多对象的属性）。通过LLM的隐含内部表示来捕获世界状态的尝试会因为机器人操作历史中可用的与任务和环境相关的信息有限而变得复杂，而依赖通过提示向LLM传递信息的方法则受其有限的上下文窗口的限制。在本文中，我们提出了Statler，一个为LLMs赋予了明确的、作为“记忆”的世界状态表示的框架，这种记忆随时间保持。

    Large language models (LLMs) provide a promising tool that enable robots to perform complex robot reasoning tasks. However, the limited context window of contemporary LLMs makes reasoning over long time horizons difficult. Embodied tasks such as those that one might expect a household robot to perform typically require that the planner consider information acquired a long time ago (e.g., properties of the many objects that the robot previously encountered in the environment). Attempts to capture the world state using an LLM's implicit internal representation is complicated by the paucity of task- and environment-relevant information available in a robot's action history, while methods that rely on the ability to convey information via the prompt to the LLM are subject to its limited context window. In this paper, we propose Statler, a framework that endows LLMs with an explicit representation of the world state as a form of ``memory'' that is maintained over time. Integral to Statler i
    
[^22]: 面向中文文本错误校正的渐进式多任务学习框架

    Progressive Multi-task Learning Framework for Chinese Text Error Correction. (arXiv:2306.17447v1 [cs.CL])

    [http://arxiv.org/abs/2306.17447](http://arxiv.org/abs/2306.17447)

    我们提出了一种面向中文文本错误校正的渐进式多任务学习框架ProTEC，该框架通过引导模型从易到难地学习错误检测、错误类型识别和校正结果生成，以解决过纠正的问题。

    

    中文文本错误校正旨在检测和纠正输入文本中的错误，这有益于人类日常生活和各种下游任务。近期的方法主要采用预训练语言模型(PLM)来解决中文文本错误校正任务，并取得了巨大成功。然而，之前的方法存在过纠正和欠纠正的问题，前者在对精确性要求较高的中文文本错误校正任务中尤为明显。为了缓解过纠正的问题，我们提出了一种新颖的模型无关的渐进式多任务学习框架，命名为ProTEC，它引导一个CTEC模型从简单到困难地学习任务。我们将CTEC任务分为三个子任务，从易到难分别为错误检测、错误类型识别和校正结果生成。在训练过程中，ProTEC将这些子任务纳入多任务训练目标，引导模型逐渐学习文本错误校正。在推理过程中，模型则...

    Chinese Text Error Correction (CTEC) aims to detect and correct errors in the input text, which benefits human's daily life and various downstream tasks. Recent approaches mainly employ Pre-trained Language Models (PLMs) to resolve CTEC task and achieve tremendous success. However, previous approaches suffer from issues of over-correction and under-correction, and the former is especially conspicuous in the precision-critical CTEC task. To mitigate the issue of overcorrection, we propose a novel model-agnostic progressive multitask learning framework for CTEC, named ProTEC, which guides a CTEC model to learn the task from easy to difficult. We divide CTEC task into three sub-tasks from easy to difficult: Error Detection, Error Type Identification, and Correction Result Generation. During the training process, ProTEC guides the model to learn text error correction progressively by incorporating these sub-tasks into a multi-task training objective. During the inference process, the model
    
[^23]: LMBot: 将图形知识融入语言模型以进行无图形部署的推特机器人检测

    LMBot: Distilling Graph Knowledge into Language Model for Graph-less Deployment in Twitter Bot Detection. (arXiv:2306.17408v1 [cs.AI])

    [http://arxiv.org/abs/2306.17408](http://arxiv.org/abs/2306.17408)

    LMBot是一种新颖的推特机器人检测框架，将图神经网络的知识融入到语言模型中，实现了无图形部署，以解决数据依赖性的挑战。

    

    随着恶意行为者使用越来越先进和广泛的机器人来传播错误信息和操纵舆论，推特机器人的检测已成为一项至关重要的任务。尽管基于图形的推特机器人检测方法取得了最先进的性能，但我们发现它们的推理依赖于距离目标用户多跳的邻居用户，并且获取邻居用户是耗时的，并可能引入偏差。与此同时，我们发现在推特机器人检测上微调后，预训练的语言模型在竞争性性能方面取得了良好的表现，并且在部署过程中不需要图形结构。受到这一发现的启发，我们提出了一种新颖的机器人检测框架LMBot，它将图神经网络(GNNs)的知识融入语言模型(LMs)，以在推特机器人检测中进行无图形部署，以应对数据依赖性的挑战。此外，LMBot对基于图形和不使用图形的数据集兼容。具体而言，我们首先将每个用户表示为一段文本

    As malicious actors employ increasingly advanced and widespread bots to disseminate misinformation and manipulate public opinion, the detection of Twitter bots has become a crucial task. Though graph-based Twitter bot detection methods achieve state-of-the-art performance, we find that their inference depends on the neighbor users multi-hop away from the targets, and fetching neighbors is time-consuming and may introduce bias. At the same time, we find that after finetuning on Twitter bot detection, pretrained language models achieve competitive performance and do not require a graph structure during deployment. Inspired by this finding, we propose a novel bot detection framework LMBot that distills the knowledge of graph neural networks (GNNs) into language models (LMs) for graph-less deployment in Twitter bot detection to combat the challenge of data dependency. Moreover, LMBot is compatible with graph-based and graph-less datasets. Specifically, we first represent each user as a tex
    
[^24]: 基于加权CapsuleNet网络的阿拉伯语和波斯语多领域情感分析方法

    Presenting an approach based on weighted CapsuleNet networks for Arabic and Persian multi-domain sentiment analysis. (arXiv:2306.17068v1 [cs.CL])

    [http://arxiv.org/abs/2306.17068](http://arxiv.org/abs/2306.17068)

    本文提出了一种基于加权胶囊网络的阿拉伯语和波斯语多领域情感分析方法，通过训练单独的胶囊网络并使用加权度量来实现情感分类，具有较好的准确性和适应性。

    

    情感分类是自然语言处理中的基本任务，对自由文本进行正面、负面或中性的分类。然而，情感分类模型高度依赖于领域，分类器在一个领域中可能具有合理的准确性，但在另一个领域中由于词语的语义多重性而准确率较低。本文提出了一种新的波斯语/阿拉伯语多领域情感分析方法，使用累积加权胶囊网络的方法。加权胶囊集合由为每个领域训练的单独的胶囊网络和称为领域所属度（DBD）的加权度量组成。这个度量由TF和IDF组成，计算每个文档对于每个领域的依赖关系，然后乘以每个胶囊创建的可能输出。最终，这些乘积的总和是最终输出的标签，并用于确定极性。

    Sentiment classification is a fundamental task in natural language processing, assigning one of the three classes, positive, negative, or neutral, to free texts. However, sentiment classification models are highly domain dependent; the classifier may perform classification with reasonable accuracy in one domain but not in another due to the Semantic multiplicity of words getting poor accuracy. This article presents a new Persian/Arabic multi-domain sentiment analysis method using the cumulative weighted capsule networks approach. Weighted capsule ensemble consists of training separate capsule networks for each domain and a weighting measure called domain belonging degree (DBD). This criterion consists of TF and IDF, which calculates the dependency of each document for each domain separately; this value is multiplied by the possible output that each capsule creates. In the end, the sum of these multiplications is the title of the final output, and is used to determine the polarity. And 
    
[^25]: 概率语言知识与标记级文本增强

    Probabilistic Linguistic Knowledge and Token-level Text Augmentation. (arXiv:2306.16644v1 [cs.CL])

    [http://arxiv.org/abs/2306.16644](http://arxiv.org/abs/2306.16644)

    研究了标记级文本增强的有效性和概率语言知识的作用，实验证明了所研究的五种标记级文本增强技术在语言评估环境下不具备普遍有效性，而且与不同分类模型类型无关。

    

    本文研究了在语言学驱动的评估环境下，标记级文本增强的有效性以及概率语言知识的作用。我们开发了两个文本增强程序REDA和REDA$_{NG}$，它们都实现了五种标记级文本编辑操作：同义词替换(SR)、随机交换(RS)、随机插入(RI)、随机删除(RD)和随机混合(RM)。REDA$_{NG}$利用预训练的n-gram语言模型从REDA的输出中选择最可能的增强文本。我们对中文和英文的二元问题匹配分类任务进行了全面和细致的实验。结果强烈否定了所研究的五种标记级文本增强技术的普遍有效性，无论是同时应用还是分别应用，也无论使用了哪种常见的分类模型类型，包括transformers。此外，概率语言知识的作用是...

    This paper investigates the effectiveness of token-level text augmentation and the role of probabilistic linguistic knowledge within a linguistically-motivated evaluation context. Two text augmentation programs, REDA and REDA$_{NG}$, were developed, both implementing five token-level text editing operations: Synonym Replacement (SR), Random Swap (RS), Random Insertion (RI), Random Deletion (RD), and Random Mix (RM). REDA$_{NG}$ leverages pretrained $n$-gram language models to select the most likely augmented texts from REDA's output. Comprehensive and fine-grained experiments were conducted on a binary question matching classification task in both Chinese and English. The results strongly refute the general effectiveness of the five token-level text augmentation techniques under investigation, whether applied together or separately, and irrespective of various common classification model types used, including transformers. Furthermore, the role of probabilistic linguistic knowledge is 
    
[^26]: SparseOptimizer: 通过Moreau-Yosida正则化来降低语言模型的稀疏性，并通过编译器共同设计来加速

    SparseOptimizer: Sparsify Language Models through Moreau-Yosida Regularization and Accelerate through Compiler Co-design. (arXiv:2306.15656v1 [cs.LG])

    [http://arxiv.org/abs/2306.15656](http://arxiv.org/abs/2306.15656)

    SparseOptimizer是一种深度学习优化器，通过Moreau-Yosida正则化在大型语言模型中引入稀疏性。它采用嵌入的收缩操作符，无需对代码进行修改即可适应各种大型语言模型，并在各种基准数据集上实现与密集型模型相当的性能，同时减少参数数量。

    

    本文介绍了SparseOptimizer，一种新颖的深度学习优化器，通过Moreau-Yosida正则化在大型语言模型（如BERT，ALBERT和GPT）中自然地引入稀疏性。SparseOptimizer设计的关键是嵌入的收缩操作符，它在优化过程中直接引入稀疏性。这个操作符通过坚实的理论框架支持，并包含了一个分析解，从而增强了优化器的鲁棒性和效果。重要的是，SparseOptimizer的即插即用功能消除了对代码修改的需求，使其成为适用于各种大型语言模型的通用适应工具。在GLUE、RACE、SQuAD1和SQuAD2等基准数据集上的实证评估表明，通过SparseOptimizer稀疏化后的SparseBERT和SparseALBERT在性能上与密集型的BERT和ALBERT相当，同时显著减少了参数数量。

    This paper introduces SparseOptimizer, a novel deep learning optimizer that exploits Moreau-Yosida regularization to naturally induce sparsity in large language models such as BERT, ALBERT and GPT. Key to the design of SparseOptimizer is an embedded shrinkage operator, which imparts sparsity directly within the optimization process. This operator, backed by a sound theoretical framework, includes an analytical solution, thereby reinforcing the optimizer's robustness and efficacy. Crucially, SparseOptimizer's plug-and-play functionality eradicates the need for code modifications, making it a universally adaptable tool for a wide array of large language models. Empirical evaluations on benchmark datasets such as GLUE, RACE, SQuAD1, and SQuAD2 confirm that SparseBERT and SparseALBERT, when sparsified using SparseOptimizer, achieve performance comparable to their dense counterparts, BERT and ALBERT, while significantly reducing their parameter count. Further, this work proposes an innovati
    
[^27]: MindDial: 带有心智模拟的信念动态跟踪用于场景化神经对话生成

    MindDial: Belief Dynamics Tracking with Theory-of-Mind Modeling for Situated Neural Dialogue Generation. (arXiv:2306.15253v1 [cs.CL])

    [http://arxiv.org/abs/2306.15253](http://arxiv.org/abs/2306.15253)

    MindDial是一个使用心智模拟进行信念动态跟踪的对话生成框架，可以在场景化环境中生成自由对话来协商共识。

    

    人类在交流中自由表达意义或共识的同时进行对话。尽管大型生成语言模型具有令人印象深刻的对话能力，但它们并未考虑到共享的场景环境中个体的上下文理解差异。本文提出了MindDial，一种新颖的对话框架，可以生成场景化的自由对话来协商共识。我们设计了一个明确的心智模块，可以追踪三个层次的信念，即说话者的信念、说话者对听众信念的预测以及基于前两者之间的共同信念。然后，说话行为分类头将决定是否继续对话、结束此轮对话或采取与任务相关的行动。我们使用了一个共识对齐的数据集MutualFriend，增加了信念动态注释，目标是根据两个代理之间的自由对话找到一个共同的朋友。实验证明，我们的模型在心智状态建模方面取得了良好的效果。

    Humans talk in free-form while negotiating the expressed meanings or common ground. Despite the impressive conversational abilities of the large generative language models, they do not consider the individual differences in contextual understanding in a shared situated environment. In this work, we propose MindDial, a novel conversational framework that can generate situated free-form responses to negotiate common ground. We design an explicit mind module that can track three-level beliefs -- the speaker's belief, the speaker's prediction of the listener's belief, and the common belief based on the gap between the first two. Then the speaking act classification head will decide to continue to talk, end this turn, or take task-related action. We augment a common ground alignment dataset MutualFriend with belief dynamics annotation, of which the goal is to find a single mutual friend based on the free chat between two agents. Experiments show that our model with mental state modeling can
    
[^28]: 论大型语言模型水印的可靠性

    On the Reliability of Watermarks for Large Language Models. (arXiv:2306.04634v1 [cs.LG])

    [http://arxiv.org/abs/2306.04634](http://arxiv.org/abs/2306.04634)

    本文研究了大型语言模型水印在混合其他文本来源时的可靠性，并提供了在实际应用中的建议。

    

    大型语言模型(LLMs)已经开始应用于日常使用，并有能力在未来的十年内产生大量的文本。机器生成的文本可能会取代互联网上的人类写作文本，并有可能被用于恶意目的，如钓鱼攻击和社交媒体机器人。水印是一种简单有效的策略，通过使LLM生成的文本可检测和可记录，来降低这些伤害。然而，一个关键问题仍然存在：在现实中混合了其他的文本来源，被人类写作者或其他语言模型改写，被用于社交和技术领域的各种应用时，水印在实际设置中的可靠性如何？在本文中，我们探讨了不同的检测方案，量化了它们检测水印的能力，并确定在每个情况下需要观察多少机器生成的文本才能可靠地检测水印。我们特别强调了当水印与其他文本来源混合时水印的可靠性，并提供了未来使用LLM生成的文本水印的建议。

    Large language models (LLMs) are now deployed to everyday use and positioned to produce large quantities of text in the coming decade. Machine-generated text may displace human-written text on the internet and has the potential to be used for malicious purposes, such as spearphishing attacks and social media bots. Watermarking is a simple and effective strategy for mitigating such harms by enabling the detection and documentation of LLM-generated text. Yet, a crucial question remains: How reliable is watermarking in realistic settings in the wild? There, watermarked text might be mixed with other text sources, paraphrased by human writers or other language models, and used for applications in a broad number of domains, both social and technical. In this paper, we explore different detection schemes, quantify their power at detecting watermarks, and determine how much machine-generated text needs to be observed in each scenario to reliably detect the watermark. We especially highlight o
    
[^29]: LLM-Blender: 利用成对排名和生成融合集成大型语言模型

    LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion. (arXiv:2306.02561v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.02561](http://arxiv.org/abs/2306.02561)

    本论文提出了LLM-Blender，它是一个集成框架，旨在利用不同的开源大型语言模型的优秀特性，实现始终如一的卓越性能。PairRanker和GenFuser是该框架的两个模块，PairRanker使用成对比较方法来区分候选输出，并且GenFuser旨在合并排名最高的候选者，以生成改进的输出。

    

    本论文提出了LLM-Blender，一个集成框架，旨在通过利用多个开源大型语言模型（LLMs）的不同优势来达到始终如一的卓越性能。我们的框架由两个模块组成：PairRanker和GenFuser，以应对不同示例的最优LLMs可以显着变化的观察。PairRanker使用专门的成对比较方法来区分候选输出之间的微小差异。它联合编码输入文本和一对候选者，使用交叉注意编码器来确定优越者。我们的结果表明，PairRanker与ChatGPT的排名相关性最高。然后，GenFuser旨在合并排名最高的候选者，通过利用它们的优势和减少它们的弱点来生成改进的输出。为了促进大规模评估，我们介绍了一个基准数据集MixInstruct，它是多个指令数据集的混合，具有oracle p。

    We present LLM-Blender, an ensembling framework designed to attain consistently superior performance by leveraging the diverse strengths of multiple open-source large language models (LLMs). Our framework consists of two modules: PairRanker and GenFuser, addressing the observation that optimal LLMs for different examples can significantly vary. PairRanker employs a specialized pairwise comparison method to distinguish subtle differences between candidate outputs. It jointly encodes the input text and a pair of candidates, using cross-attention encoders to determine the superior one. Our results demonstrate that PairRanker exhibits the highest correlation with ChatGPT-based ranking. Then, GenFuser aims to merge the top-ranked candidates, generating an improved output by capitalizing on their strengths and mitigating their weaknesses. To facilitate large-scale evaluation, we introduce a benchmark dataset, MixInstruct, which is a mixture of multiple instruction datasets featuring oracle p
    
[^30]: 衡量自然语言处理模型面对领域转移的鲁棒性

    Measuring the Robustness of Natural Language Processing Models to Domain Shifts. (arXiv:2306.00168v1 [cs.CL])

    [http://arxiv.org/abs/2306.00168](http://arxiv.org/abs/2306.00168)

    本文探讨了自然领域转移设置下微调和小样本学习模型的DR挑战，引入了一个DR基准，提出了DR挑战的两个视角：源域降低（SD）和目标域降低（TD），并发现两者之一通常是正值，强调了评估DR挑战的两个视角的重要性。

    

    大型语言模型在各种任务中表现出了很好的性能，包括微调、小样本学习和零样本学习。然而，它们在没有标记数据的领域中的性能仍然落后于有标记数据的领域，我们称之为领域鲁棒性（DR）挑战。现有的DR研究存在不一致的设置、缺乏评估任务的多样性和过多依靠挑战集。在本文中，我们探讨了自然领域转移设置下微调和小样本学习模型的DR挑战。我们引入了一个DR基准，包括多样化的NLP任务，包括句子和标记级分类、问答和生成，每个任务都由几个领域组成。我们提出了DR挑战的两个视角：源域降低（SD）和目标域降低（TD），它们交替作为参考点来比较源域和目标域的性能。我们发现，在重大比例的领域转移中，SD或TD之一是正的，但不是两者都正，强调了评估DR挑战的两个视角的重要性。我们的基准允许在模型、任务和设置上公平比较DR，并提供有关NLP模型DR性质的见解。

    Large Language Models have shown promising performance on various tasks, including fine-tuning, few-shot learning, and zero-shot learning. However, their performance on domains without labeled data still lags behind those with labeled data, which we refer as the Domain Robustness (DR) challenge. Existing research on DR suffers from disparate setups, lack of evaluation task variety, and reliance on challenge sets. In this paper, we explore the DR challenge of both fine-tuned and few-shot learning models in natural domain shift settings. We introduce a DR benchmark comprising diverse NLP tasks, including sentence and token-level classification, QA, and generation, each task consists of several domains. We propose two views of the DR challenge: Source Drop (SD) and Target Drop (TD), which alternate between the source and target in-domain performance as reference points. We find that in significant proportions of domain shifts, either SD or TD is positive, but not both, emphasizing the imp
    
[^31]: W-procer: 基于加权原型对比学习的医学少样本命名实体识别

    W-procer: Weighted Prototypical Contrastive Learning for Medical Few-Shot Named Entity Recognition. (arXiv:2305.18624v1 [cs.CL])

    [http://arxiv.org/abs/2305.18624](http://arxiv.org/abs/2305.18624)

    W-procer是一种基于加权原型对比学习的医学少样本命名实体识别方法，在构建基于原型的对比损失和加权网络方面具有创新性，优于现有的最先进方法。

    

    对比学习已成为少样本命名实体识别（NER）的一种受欢迎的解决方案。传统配置力求减少具有相同标签的标记之间的距离，并增加具有不同标签的标记之间的距离。然而，在医学领域中存在大量被注释为“O”（即“OUTSIDE”）的实体，并且它们不希望被推离到当前对比学习方法标记为“O”以外的其他实体，这种设定效果不佳，可能会得出含有噪声原型标签的语义表示，尽管存在许多“O”标签实体与有标签实体相关。为解决这个挑战，我们提出了一种名为医学少样本命名实体识别中基于加权原型的对比学习方法（W-PROCER）。我们的方法主要围绕构建基于原型的对比损失和加权网络展开。这些组件在协助在医学领域中的迁移学习方面发挥了至关重要的作用。在实验中，我们将W-PROCER应用于一个公共的医学数据集，并展示了其相对于现有的最先进方法的优异表现。

    Contrastive learning has become a popular solution for few-shot Name Entity Recognization (NER). The conventional configuration strives to reduce the distance between tokens with the same labels and increase the distance between tokens with different labels. The effect of this setup may, however, in the medical domain, there are a lot of entities annotated as OUTSIDE (O), and they are undesirably pushed apart to other entities that are not labeled as OUTSIDE (O) by the current contrastive learning method end up with a noisy prototype for the semantic representation of the label, though there are many OUTSIDE (O) labeled entities are relevant to the labeled entities. To address this challenge, we propose a novel method named Weighted Prototypical Contrastive Learning for Medical Few Shot Named Entity Recognization (W-PROCER). Our approach primarily revolves around constructing the prototype-based contractive loss and weighting network. These components play a crucial role in assisting t
    
[^32]: 通过大型语言模型实现实用的PCG

    Practical PCG Through Large Language Models. (arXiv:2305.18243v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.18243](http://arxiv.org/abs/2305.18243)

    本研究介绍了如何利用语言模型生成游戏房间，在仅有少量数据的情况下，可以生成多达37%的可玩新颖关卡，该技术有助于解决包含许多局部和全局约束的PCG问题。

    

    大型语言模型(LLMs)已经被证明是自然语言处理领域之外的各种领域中非常有用的工具。本研究提供了如何使用LLMs为正在开发中的游戏Metavoidal生成2D游戏房间的实用方向。我们的技术可以通过人类参与的微调，利用GPT-3的能力，仅使用60个手动设计的房间数据，在复杂的游戏场景下，生成37%的可玩新颖关卡，这是针对存在大量局部和全局约束的PCG的。

    Large Language Models (LLMs) have proven to be useful tools in various domains outside of the field of their inception, which was natural language processing. In this study, we provide practical directions on how to use LLMs to generate 2D-game rooms for an under-development game, named Metavoidal. Our technique can harness the power of GPT-3 by Human-in-the-loop fine-tuning which allows our method to create 37% Playable-Novel levels from as scarce data as only 60 hand-designed rooms under a scenario of the non-trivial game, with respect to (Procedural Content Generation) PCG, that has a good amount of local and global constraints.
    
[^33]: 扫描与拍照：理解1层Transformer中的训练动态和标记组成

    Scan and Snap: Understanding Training Dynamics and Token Composition in 1-layer Transformer. (arXiv:2305.16380v1 [cs.CL])

    [http://arxiv.org/abs/2305.16380](http://arxiv.org/abs/2305.16380)

    本文分析了1层Transformer在下一个标记预测任务中的SGD训练动态，证明了自我关注层充当了“区分性扫描算法”，从而逐步关注到相关标记并排除不相关的标记，总结相关信息在编码表示中。同时研究了标记频率、上下文和初始化自我关注层等对Transformer性能的影响。

    

    Transformer架构在多个研究领域表现出了惊人的性能，并成为许多神经网络模型的基础。然而，我们对其如何工作的理解仍然有限。特别是，通过简单的预测性损失，表示如何从梯度训练动态中出现仍然是一个谜。在本文中，针对具有一个自我关注层和一个解码器层的1层Transformer，我们以数学严谨的方式分析其在下一个标记预测任务中的SGD训练动态。我们打开了自我关注层组合输入标记的动态过程的黑盒子，并揭示了底层归纳偏差的本质。具体而言，在没有位置编码、长输入序列和解码器层学习速度快于自我关注层的假设下，我们证明了自我关注层充当了“区分性扫描算法”：从均匀注意力开始，它逐渐关注到相关标记，排除不相关的标记，直到所有相关信息被扫描并总结在编码表示中。我们的分析还显示了标记频率和上下文如何影响注意权重，以及自我关注层初始化如何影响收敛速度。

    Transformer architecture has shown impressive performance in multiple research domains and has become the backbone of many neural network models. However, there is limited understanding on how it works. In particular, with a simple predictive loss, how the representation emerges from the gradient \emph{training dynamics} remains a mystery. In this paper, for 1-layer transformer with one self-attention layer plus one decoder layer, we analyze its SGD training dynamics for the task of next token prediction in a mathematically rigorous manner. We open the black box of the dynamic process of how the self-attention layer combines input tokens, and reveal the nature of underlying inductive bias. More specifically, with the assumption (a) no positional encoding, (b) long input sequence, and (c) the decoder layer learns faster than the self-attention layer, we prove that self-attention acts as a \emph{discriminative scanning algorithm}: starting from uniform attention, it gradually attends mor
    
[^34]: MERGE: 快速的私有文本生成

    MERGE: Fast Private Text Generation. (arXiv:2305.15769v1 [cs.CL])

    [http://arxiv.org/abs/2305.15769](http://arxiv.org/abs/2305.15769)

    该论文提出了MERGE，一个基于Transformer语言模型的快速私有文本生成框架。实验结果表明，MERGE在保护隐私的同时，实现了26.5倍的加速和80%的通信字节数减少。

    

    近年来，人们越来越关注NLP服务和Transformer模型的私有推理。然而，现有的两方隐私保护方法仅考虑NLU场景，而文本生成的私有推理，如翻译、对话和代码补全，仍未解决。此外，将现有的隐私保护方法迁移到NLG模型时，性能表现差，而在训练阶段受到收敛问题的困扰。为了解决这些问题，我们提出了MERGE，这是一个基于Transformer语言模型的快速私有文本生成框架。具体而言，MERGE重用输出隐藏状态作为单词嵌入，以跳过嵌入计算，并重新组织Transformer模块中的线性操作以加速向前过程。基于这两个优化，大量的实验表明，在序列长度为512时，MERGE可实现26.5倍的加速，并减少80\%的通信字节数。

    Recent years have seen increasing concerns about the private inference of NLP services and Transformer models. However, existing two-party privacy-preserving methods solely consider NLU scenarios, while the private inference of text generation such as translation, dialogue, and code completion remains unsolved. Besides, while migrated to NLG models, existing privacy-preserving methods perform poorly in terms of inference speed, and suffer from the convergence problem during the training stage. To address these issues, we propose MERGE, a fast private text generation framework for Transformer-based language models. Specifically, MERGE reuse the output hidden state as the word embedding to bypass the embedding computation, and reorganize the linear operations in the Transformer module to accelerate the forward procedure. Based on these two optimizations, extensive experiments show that MERGE can achieve a 26.5x speedup under the sequence length 512, and reduce 80\% communication bytes, w
    
[^35]: 克服提示扰动敏感性的零样本方法

    Zero-shot Approach to Overcome Perturbation Sensitivity of Prompts. (arXiv:2305.15689v1 [cs.CL])

    [http://arxiv.org/abs/2305.15689](http://arxiv.org/abs/2305.15689)

    本研究提出了一种零样本方法，自动生成多个类似于基础提示的高质量提示，并使用新的度量方法进行排名，从而克服了提示的扰动敏感性，并在情感分类任务中具有较高的准确性。

    

    最近的研究表明，自然语言提示可以帮助利用预训练语言模型学习的知识进行二元句级情感分类任务。具体来说，这些方法利用少量样本学习设置，使用手动或自动生成的提示来微调情感分类模型。然而，这些方法的性能对所使用提示的扰动敏感。此外，这些方法依赖于少量带标签实例进行自动提示生成和提示排序。本研究旨在在零样本设置中为所给定的任务找到高质量的提示。我们的提议方法给定一个基础提示，采用位置、推理和释义技术自动生成多个类似于基础提示的提示，然后使用一种新的度量方法对提示进行排名。我们从实验上证明，排名靠前的提示具有很高的质量，并在提示扰动鲁棒性和整体准确性方面显著优于基础提示和其他现有的提示生成方法。

    Recent studies have demonstrated that natural-language prompts can help to leverage the knowledge learned by pre-trained language models for the binary sentence-level sentiment classification task. Specifically, these methods utilize few-shot learning settings to fine-tune the sentiment classification model using manual or automatically generated prompts. However, the performance of these methods is sensitive to the perturbations of the utilized prompts. Furthermore, these methods depend on a few labeled instances for automatic prompt generation and prompt ranking. This study aims to find high-quality prompts for the given task in a zero-shot setting. Given a base prompt, our proposed approach automatically generates multiple prompts similar to the base prompt employing positional, reasoning, and paraphrasing techniques and then ranks the prompts using a novel metric. We empirically demonstrate that the top-ranked prompts are high-quality and significantly outperform the base prompt an
    
[^36]: ChatGPT是否公平可靠？评估大型语言模型推荐中的公平性

    Is ChatGPT Fair for Recommendation? Evaluating Fairness in Large Language Model Recommendation. (arXiv:2305.07609v1 [cs.IR])

    [http://arxiv.org/abs/2305.07609](http://arxiv.org/abs/2305.07609)

    这篇论文介绍了一种新的推荐范式——通过LLM进行推荐，但由于LLMs可能存在社会偏见，需要进一步调查RecLLM所做推荐的公正性。为此，作者提出了一个新的公平性基准——FaiRLLM，并针对音乐和电影推荐场景中的八个敏感属性进行了评估。

    

    大型语言模型（LLM）的显着成就导致一种新的推荐范式——通过LLM进行推荐（RecLLM）。然而，需要注意LLMs可能包含社会偏见，因此需要进一步调查RecLLM所做推荐的公正性。为了避免RecLLM的潜在风险，有必要从用户的各种敏感属性角度评估RecLLM的公平性。由于RecLLM范式与传统推荐范式之间存在差异，因此直接使用传统推荐的公平性基准是有问题的。为了解决这个困境，我们提出了一个新的基准，称为“通过LLM的推荐的公平性”（FaiRLLM）。该基准包括精心设计的指标和数据集，涵盖两个推荐场景中的八个敏感属性：音乐和电影。通过利用我们的FaiRLLM基准，我们进行了一项评估。

    The remarkable achievements of Large Language Models (LLMs) have led to the emergence of a novel recommendation paradigm -- Recommendation via LLM (RecLLM). Nevertheless, it is important to note that LLMs may contain social prejudices, and therefore, the fairness of recommendations made by RecLLM requires further investigation. To avoid the potential risks of RecLLM, it is imperative to evaluate the fairness of RecLLM with respect to various sensitive attributes on the user side. Due to the differences between the RecLLM paradigm and the traditional recommendation paradigm, it is problematic to directly use the fairness benchmark of traditional recommendation. To address the dilemma, we propose a novel benchmark called Fairness of Recommendation via LLM (FaiRLLM). This benchmark comprises carefully crafted metrics and a dataset that accounts for eight sensitive attributes1 in two recommendation scenarios: music and movies. By utilizing our FaiRLLM benchmark, we conducted an evaluation 
    
[^37]: 如何为推荐基础模型索引项目ID

    How to Index Item IDs for Recommendation Foundation Models. (arXiv:2305.06569v1 [cs.IR])

    [http://arxiv.org/abs/2305.06569](http://arxiv.org/abs/2305.06569)

    本研究对推荐基础模型的项目索引问题进行了系统检查，提出了一种新的上下文感知索引方法，该方法在项目推荐准确性和文本生成质量方面具有优势。

    

    推荐基础模型将推荐任务转换为自然语言任务，利用大型语言模型（LLM）进行推荐。它通过直接生成建议的项目而不是计算传统推荐模型中每个候选项目的排名得分，简化了推荐管道，避免了多段过滤的问题。为了避免在决定要推荐哪些项目时生成过长的文本，为推荐基础模型创建LLM兼容的项目ID是必要的。本研究系统地研究了推荐基础模型的项目索引问题，以P5为代表的主干模型，并使用各种索引方法复制其结果。我们首先讨论了几种微不足道的项目索引方法（如独立索引、标题索引和随机索引）的问题，并表明它们不适用于推荐基础模型，然后提出了一种新的索引方法，称为上下文感知索引。我们表明，这种索引方法在项目推荐准确性和文本生成质量方面优于其他索引方法。

    Recommendation foundation model utilizes large language models (LLM) for recommendation by converting recommendation tasks into natural language tasks. It enables generative recommendation which directly generates the item(s) to recommend rather than calculating a ranking score for each and every candidate item in traditional recommendation models, simplifying the recommendation pipeline from multi-stage filtering to single-stage filtering. To avoid generating excessively long text when deciding which item(s) to recommend, creating LLM-compatible item IDs is essential for recommendation foundation models. In this study, we systematically examine the item indexing problem for recommendation foundation models, using P5 as the representative backbone model and replicating its results with various indexing methods. To emphasize the importance of item indexing, we first discuss the issues of several trivial item indexing methods, such as independent indexing, title indexing, and random inde
    
[^38]: 使用贝叶斯模型平均分析社交媒体上的气候宣传活动

    Analysis of Climate Campaigns on Social Media using Bayesian Model Averaging. (arXiv:2305.06174v1 [cs.CL])

    [http://arxiv.org/abs/2305.06174](http://arxiv.org/abs/2305.06174)

    本文分析了工业、倡导组织和气候倡导组织在社交媒体上如何影响气候变化的叙事，并提出了一个最小化监督模型组合方法，用于识别Facebook上气候广告的立场。

    

    气候变化是我们时代的核心问题，我们正处于一个关键时刻。各种利益集团、社会运动组织和个人在社交媒体上开展针对这个问题的集体行动。此外，社交媒体上的问题倡导活动往往是针对当前社会关注的问题，特别是能源行业面临的问题。本文的目标是分析工业、倡导组织和气候倡导组织如何利用社交媒体影响气候变化的叙事。在这项工作中，我们提出了一个最小化监督模型组合方法，并结合消息主题来识别Facebook上气候广告的立场。最后，我们发布了我们的立场数据集、模型和与气候宣传活动相关的主题，供未来的舆情挖掘和自动检测气候变化立场的研究使用。

    Climate change is the defining issue of our time, and we are at a defining moment. Various interest groups, social movement organizations, and individuals engage in collective action on this issue on social media. In addition, issue advocacy campaigns on social media often arise in response to ongoing societal concerns, especially those faced by energy industries. Our goal in this paper is to analyze how those industries, their advocacy group, and climate advocacy group use social media to influence the narrative on climate change. In this work, we propose a minimally supervised model soup [56] approach combined with messaging themes to identify the stances of climate ads on Facebook. Finally, we release our stance dataset, model, and set of themes related to climate campaigns for future work on opinion mining and the automatic detection of climate change stances.
    
[^39]: ChatGPT是否能够预测股票价格波动？回报可预测性与大语言模型。

    Can ChatGPT Forecast Stock Price Movements? Return Predictability and Large Language Models. (arXiv:2304.07619v1 [q-fin.ST])

    [http://arxiv.org/abs/2304.07619](http://arxiv.org/abs/2304.07619)

    本研究探究了使用ChatGPT及其他大型语言模型预测股市回报的潜力，发现ChatGPT的预测表现优于传统情感分析方法，而基础模型无法准确预测股票价格变化，表明复杂模型可预测能力的崛起。这表明在投资决策过程中引入先进的语言模型可以提高预测准确性并增强定量交易策略的表现。

    

    本文研究了使用情感分析预测股市回报的潜力，探讨了使用ChatGPT以及其他大语言模型在预测股市回报方面的表现。我们使用ChatGPT判断新闻标题对公司股票价格是好消息、坏消息或无关消息。通过计算数字分数，我们发现这些"ChatGPT分数"和随后的日常股票市场回报之间存在正相关性。而且，ChatGPT的表现优于传统的情感分析方法。同时，我们发现GPT-1、GPT-2和BERT等基础模型无法准确预测回报，这表明回报可预测性是复杂模型的一种新兴能力。我们的研究结果表明，将先进的语言模型纳入投资决策过程可以产生更准确的预测，并提高定量交易策略的表现。

    We examine the potential of ChatGPT, and other large language models, in predicting stock market returns using sentiment analysis of news headlines. We use ChatGPT to indicate whether a given headline is good, bad, or irrelevant news for firms' stock prices. We then compute a numerical score and document a positive correlation between these ``ChatGPT scores'' and subsequent daily stock market returns. Further, ChatGPT outperforms traditional sentiment analysis methods. We find that more basic models such as GPT-1, GPT-2, and BERT cannot accurately forecast returns, indicating return predictability is an emerging capacity of complex models. Our results suggest that incorporating advanced language models into the investment decision-making process can yield more accurate predictions and enhance the performance of quantitative trading strategies.
    
[^40]: 利用上下文化的大型语言模型理解法律文件

    Understand Legal Documents with Contextualized Large Language Models. (arXiv:2303.12135v1 [cs.CL])

    [http://arxiv.org/abs/2303.12135](http://arxiv.org/abs/2303.12135)

    本文介绍了针对 SemEval-2023 任务 6 开发的 Legal-BERT-HSLN 模型和 Legal-LUKE 模型，其中 Legal-BERT-HSLN 模型通过考虑句内和句间的上下文信息以预测修辞角色，Legal-LUKE 模型是具有法律上下文和实体知识的模型，以识别法律实体。模型相比基线模型更准确，能够解决在人口众多的国家处理法律文件的问题。

    

    在人口众多的国家，如印度，待处理的法律案件数量不断增加，这已成为一个重大问题。因此，开发有效的技术来处理和理解法律文件将非常有用。在本文中，我们介绍了我们针对 SemEval-2023 任务 6（Modi 等人，2023）所开发的理解法律文本系统。具体来说，我们首先开发了 Legal-BERT-HSLN 模型，该模型考虑了句内和句间的综合上下文信息，以预测修辞角色（子任务 A），然后训练出 Legal-LUKE 模型，该模型具有法律上下文化和实体感知能力，以识别法律实体（子任务 B）。我们的评估表明，我们设计的模型比基线模型更准确，如在子任务 B 中 F1 值提高了达 15.0%。我们在任务排行榜上取得了显著的表现，如 0.834 微平均 F1 值，并在子任务 A 中排名第 5。

    The growth of pending legal cases in populous countries, such as India, has become a major issue. Developing effective techniques to process and understand legal documents is extremely useful in resolving this problem. In this paper, we present our systems for SemEval-2023 Task 6: understanding legal texts (Modi et al., 2023). Specifically, we first develop the Legal-BERT-HSLN model that considers the comprehensive context information in both intra- and inter-sentence levels to predict rhetorical roles (subtask A) and then train a Legal-LUKE model, which is legal-contextualized and entity-aware, to recognize legal entities (subtask B). Our evaluations demonstrate that our designed models are more accurate than baselines, e.g., with an up to 15.0% better F1 score in subtask B. We achieved notable performance in the task leaderboard, e.g., 0.834 micro F1 score, and ranked No.5 out of 27 teams in subtask A.
    
[^41]: 语言模型概述：最新发展和展望

    An Overview on Language Models: Recent Developments and Outlook. (arXiv:2303.05759v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.05759](http://arxiv.org/abs/2303.05759)

    这篇综述论文介绍了传统语言模型和预训练语言模型的概念、方法和应用，探讨了二者之间的关系，并展望了预训练时代语言建模的未来方向。

    

    语言模型研究文本字符串的概率分布，是自然语言处理中最基本的任务之一。它被广泛应用于文本生成、语音识别、机器翻译等领域。传统语言模型旨在以因果方式预测语言序列的概率，而预训练语言模型涵盖更广泛的概念，并可用于因果顺序建模和下游应用的微调。预训练语言模型具有自己的训练范例（通常是自监督的），并在现代NLP系统中作为基础模型。本综述论文从语言单元、架构、训练方法、评估方法和应用五个方面介绍了传统语言模型和预训练语言模型，同时讨论了它们之间的关系，并对预训练时代的语言建模未来方向进行了探讨。

    Language modeling studies the probability distributions over strings of texts. It is one of the most fundamental tasks in natural language processing (NLP). It has been widely used in text generation, speech recognition, machine translation, etc. Conventional language models (CLMs) aim to predict the probability of linguistic sequences in a causal manner, while pre-trained language models (PLMs) cover broader concepts and can be used in both causal sequential modeling and fine-tuning for downstream applications. PLMs have their own training paradigms (usually self-supervised) and serve as foundation models in modern NLP systems. This overview paper provides an introduction to both CLMs and PLMs from five aspects, i.e., linguistic units, architectures, training methods, evaluation methods, and applications. Furthermore, we discuss the relationship between CLMs and PLMs and shed light on the future directions of language modeling in the pre-trained era.
    
[^42]: 基于大语言模型的零样本跨语言摘要

    Zero-Shot Cross-Lingual Summarization via Large Language Models. (arXiv:2302.14229v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.14229](http://arxiv.org/abs/2302.14229)

    本文实验性地使用各种提示来指导大型语言模型从不同的范式执行零样本跨语言摘要，并成功提高了它们的CLS性能。其中，GPT-4实现了零样本CLS的最先进性能，并且在性能方面与最佳方法相当。

    

    给定一个源语言文本，跨语言摘要（CLS）旨在生成另一种目标语言的摘要。最近，大型语言模型（LLM）的出现，比如GPT-3.5、ChatGPT和GPT-4，引起了计算语言学界的广泛关注。然而，目前尚不清楚LLM在CLS上的表现如何。本文实验性地使用各种提示来指导LLM从不同的范式（即端到端和流水线）执行零样本CLS，并对生成的摘要进行初步评估。我们发现，ChatGPT和GPT-4原本更喜欢生成详细信息的长摘要。但这两个LLM在交互式提示的帮助下可以进一步平衡信息量和简洁性，显著提高它们的CLS性能。在三个广泛使用的CLS数据集上的实验结果表明，GPT-4实现了零样本CLS的最先进性能，并且在性能方面与最佳方法相当。

    Given a document in a source language, cross-lingual summarization (CLS) aims to generate a summary in a different target language. Recently, the emergence of Large Language Models (LLMs), such as GPT-3.5, ChatGPT and GPT-4, has attracted wide attention from the computational linguistics community. However, it is not yet known the performance of LLMs on CLS. In this report, we empirically use various prompts to guide LLMs to perform zero-shot CLS from different paradigms (i.e., end-to-end and pipeline), and provide a preliminary evaluation on the generated summaries. We find that ChatGPT and GPT-4 originally prefer to produce lengthy summaries with detailed information. These two LLMs can further balance informativeness and conciseness with the help of an interactive prompt, significantly improving their CLS performance. Experimental results on three widely-used CLS datasets show that GPT-4 achieves state-of-the-art zero-shot CLS performance, and performs competitively compared with th
    
[^43]: 针对任务的技能定位在Fine-tuned语言模型中的应用

    Task-Specific Skill Localization in Fine-tuned Language Models. (arXiv:2302.06600v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.06600](http://arxiv.org/abs/2302.06600)

    本文提出了针对Fine-tuned语言模型中任务特定技能定位的问题，并提出了一种解决方案，通过优化可以识别出贡献模型性能的非常小的参数子集，使得将Fine-tuned的值嫁接到这个子集上可以获得几乎和Fine-tuned模型一样好的性能。

    

    预训练的语言模型可以通过Fine-tuned来解决各种NLP任务，包括少样本情况下的任务。因此，Fine-tuning使得模型能够快速掌握任务特定的“技能”，但是关于这些新学到的技能在庞大模型中的位置的研究还很有限。本文引入了技能定位的概念，并提出了一种解决方案。给定下游任务和在该任务上进行Fine-tuned的模型，利用简单的优化方法可以识别出负责模型性能的非常小的参数子集（占模型参数的约0.01%），这个子集对模型性能的贡献占比超过95%。换句话说，仅将Fine-tuned的值嫁接到预训练模型的这个小子集上，就可以获得几乎和Fine-tuned模型一样好的性能。虽然与最近关于参数高效Fine-tuning的工作相似，但这里的两个新颖之处是：（i）不需要在子集上进行进一步的重新训练（不像“lottery tickets”那样）。（ii）相对于传统的Fine-tuned模型，可以看到显著的改进。

    Pre-trained language models can be fine-tuned to solve diverse NLP tasks, including in few-shot settings. Thus fine-tuning allows the model to quickly pick up task-specific ``skills,'' but there has been limited study of where these newly-learnt skills reside inside the massive model. This paper introduces the term skill localization for this problem and proposes a solution. Given the downstream task and a model fine-tuned on that task, a simple optimization is used to identify a very small subset of parameters ($\sim0.01$% of model parameters) responsible for ($>95$%) of the model's performance, in the sense that grafting the fine-tuned values for just this tiny subset onto the pre-trained model gives performance almost as well as the fine-tuned model. While reminiscent of recent works on parameter-efficient fine-tuning, the novel aspects here are that: (i) No further re-training is needed on the subset (unlike, say, with lottery tickets). (ii) Notable improvements are seen over vanil
    
[^44]: Bipol: 在基准数据集中用可解释性的方式评估多个维度的偏差

    Bipol: Multi-axes Evaluation of Bias with Explainability in Benchmark Datasets. (arXiv:2301.12139v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.12139](http://arxiv.org/abs/2301.12139)

    本研究使用一种新的多维度偏差度量指标bipol，评估了五个英文和两个瑞典的自然语言处理基准数据集中的偏差，并提供了一个新的、包含200万个样本的瑞典偏差标注数据集和用于瑞典偏差检测的多维度词库。

    

    本研究探究了五个英文自然语言处理基准数据集（在superGLUE榜单上），以及两个瑞典数据集的偏差性质，涉及多个维度。这些数据集包括：布尔问题（Boolq）、承诺银行（CB）、Winograd模式挑战（WSC）、Wino-gender诊断（AXg）、文本蕴含识别（RTE）、瑞典CB和SWEDN。偏差可能具有害处，并且已知常见于机器学习模型所学习的数据中。为了减轻数据中的偏差，能够客观估计偏差是至关重要的。我们使用一种新颖的多维度偏差度量指标bipol，并解释该数据集中存在多少偏差。跨语言、多维度的偏差评估并不常见。因此，我们还贡献了一个新的、包含200万个样本的瑞典偏差标注数据集，该数据集是从英文版本翻译而来，并在其中使用了最先进的mT5模型进行训练。此外，我们还为瑞典偏差检测提供了新的多维度词库。我们将代码、模型和新数据集公开发布。

    We investigate five English NLP benchmark datasets (on the superGLUE leaderboard) and two Swedish datasets for bias, along multiple axes. The datasets are the following: Boolean Question (Boolq), CommitmentBank (CB), Winograd Schema Challenge (WSC), Wino-gender diagnostic (AXg), Recognising Textual Entailment (RTE), Swedish CB, and SWEDN. Bias can be harmful and it is known to be common in data, which ML models learn from. In order to mitigate bias in data, it is crucial to be able to estimate it objectively. We use bipol, a novel multi-axes bias metric with explainability, to estimate and explain how much bias exists in these datasets. Multilingual, multi-axes bias evaluation is not very common. Hence, we also contribute a new, large Swedish bias-labelled dataset (of 2 million samples), translated from the English version and train the SotA mT5 model on it. In addition, we contribute new multi-axes lexica for bias detection in Swedish. We make the codes, model, and new dataset publicl
    
[^45]: 何时不信任语言模型：探索参数和非参数记忆的有效性和限制。

    When Not to Trust Language Models: Investigating Effectiveness and Limitations of Parametric and Non-Parametric Memories. (arXiv:2212.10511v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10511](http://arxiv.org/abs/2212.10511)

    本文通过对10个模型和4种增强方法的实验，发现语言模型在记忆不太流行的实际知识方面存在困难，而检索增强的语言模型表现较好，提出了一种检索增强语言模型的简单有效方法。

    

    尽管大型语言模型在各种任务上表现出色，但仍然难以处理需要丰富世界知识的任务，这暗示了仅依靠其参数来编码丰富的世界知识的局限性。本文旨在通过对10个模型和4种增强方法在PopQA上进行大规模知识探测实验，以了解语言模型在记忆事实知识方面的优点和局限性。我们发现，语言模型难以记忆不太流行的实际知识，并且在长尾中，扩展规模无法明显改善记忆实际知识。然后，我们展示了检索增强的语言模型在很大程度上胜过级别大得多的语言模型，而未经协助的语言模型在涉及高流行实体的问题上仍然具有竞争力。基于这些发现，我们设计了一种简单而有效的强大和高效的检索增强语言模型方法，该方法仅在需要时检索非参数记忆。

    Despite their impressive performance on diverse tasks, large language models (LMs) still struggle with tasks requiring rich world knowledge, implying the limitations of relying solely on their parameters to encode a wealth of world knowledge. This paper aims to understand LMs' strengths and limitations in memorizing factual knowledge, by conducting large-scale knowledge probing experiments of 10 models and 4 augmentation methods on PopQA, our new open-domain QA dataset with 14k questions. We find that LMs struggle with less popular factual knowledge, and that scaling fails to appreciably improve memorization of factual knowledge in the long tail. We then show that retrieval-augmented LMs largely outperform orders of magnitude larger LMs, while unassisted LMs remain competitive in questions about high-popularity entities. Based on those findings, we devise a simple, yet effective, method for powerful and efficient retrieval-augmented LMs, which retrieves non-parametric memories only whe
    
[^46]: IndicMT Eval：一份用于对印度语言机器翻译评价指标进行元评估的数据集

    IndicMT Eval: A Dataset to Meta-Evaluate Machine Translation metrics for Indian Languages. (arXiv:2212.10180v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10180](http://arxiv.org/abs/2212.10180)

    本文填补了对从英文到印度语言的机器翻译系统进行系统性研究的空白，通过创建包含7000个细粒度注释的MQM数据集，发现预训练的指标与注释者分数具有最高的相关性，并指出现有的评估指标不能准确评估印度语言的机器翻译质量。

    

    机器翻译系统的快速增长需要进行全面的研究来对正在使用的评估指标进行元评估，从而能够更好地选择最能反映机器翻译质量的指标。遗憾的是，大部分研究都集中在高资源语言，主要是英文，其中的观察结果并不总是适用于其他语言。印度语言与英文在语言上存在差异，并且迄今为止尚未对从英文到印度语言的机器翻译系统进行系统性研究。本文通过创建一个包含7000个细粒度注释的MQM数据集，涵盖了5种印度语言和7个机器翻译系统，并使用该数据集建立了注释者分数和现有自动评估指标得分之间的相关性。我们的结果表明，预训练的指标（如COMET）与注释者分数的相关性最高。此外，我们还发现这些评估指标不总是能准确地评估印度语言的机器翻译质量。

    The rapid growth of machine translation (MT) systems has necessitated comprehensive studies to meta-evaluate evaluation metrics being used, which enables a better selection of metrics that best reflect MT quality. Unfortunately, most of the research focuses on high-resource languages, mainly English, the observations for which may not always apply to other languages. Indian languages, having over a billion speakers, are linguistically different from English, and to date, there has not been a systematic study of evaluating MT systems from English into Indian languages. In this paper, we fill this gap by creating an MQM dataset consisting of 7000 fine-grained annotations, spanning 5 Indian languages and 7 MT systems, and use it to establish correlations between annotator scores and scores obtained using existing automatic metrics. Our results show that pre-trained metrics, such as COMET, have the highest correlations with annotator scores. Additionally, we find that the metrics do not ad
    
[^47]: 人机协同评估早期误传信息检测：COVID-19治疗案例研究。

    Human-in-the-loop Evaluation for Early Misinformation Detection: A Case Study of COVID-19 Treatments. (arXiv:2212.09683v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09683](http://arxiv.org/abs/2212.09683)

    该论文提出了一种人机协同评估框架，用于检测新的虚假信息声明并识别支持它们的社交媒体消息。在COVID-19治疗的案例中，基于现代NLP方法开发基线系统，并展示了人类事实核查人员每小时可以识别出违反Twitter关于COVID-19虚假信息方针的124条推文。

    

    我们提出了一个人机协同评估框架，用于事实核查新的虚假信息声明并识别支持它们的社交媒体消息。我们的方法提取值得核查的声明，这些声明被聚合并排名以便复审。然后使用立场分类器来识别支持新虚假信息申述的推文，进一步检查以确定它们是否违反相关政策。为了展示我们的方法的可行性，我们在COVID-19治疗领域基于现代NLP方法开发了一个基线系统用于人机协同事实核查。使用我们的基线系统，我们展示了人类事实核查人员每小时能够识别出违反Twitter关于COVID-19虚假信息方针的124条推文。我们将提供我们的代码、数据、基线模型和详细注释指南来支持人机协同系统的评估，这些系统可以直接从原始用户生成的内容中识别新的虚假信息。

    We present a human-in-the-loop evaluation framework for fact-checking novel misinformation claims and identifying social media messages that support them. Our approach extracts check-worthy claims, which are aggregated and ranked for review. Stance classifiers are then used to identify tweets supporting novel misinformation claims, which are further reviewed to determine whether they violate relevant policies. To demonstrate the feasibility of our approach, we develop a baseline system based on modern NLP methods for human-in-the-loop fact-checking in the domain of COVID-19 treatments. Using our baseline system, we show that human fact-checkers can identify 124 tweets per hour that violate Twitter's policies on COVID-19 misinformation. We will make our code, data, baseline models, and detailed annotation guidelines available to support the evaluation of human-in-the-loop systems that identify novel misinformation directly from raw user-generated content.
    
[^48]: PromptBoosting：具有十次前向传递的黑盒文本分类

    PromptBoosting: Black-Box Text Classification with Ten Forward Passes. (arXiv:2212.09257v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09257](http://arxiv.org/abs/2212.09257)

    PromptBoosting是一种黑盒文本分类的方法，通过一小组提示和AdaBoost算法将神经语言模型的输出分布构建为大量弱学习器，从而实现了高效的分类器训练过程。

    

    我们描述了PromptBoosting，一种从神经语言模型（LM）构建文本分类器的查询高效过程，其中没有访问LM的参数、梯度或隐藏表示。这种“黑盒”分类器训练形式在大规模LM的训练和推理成本增加时变得越来越重要。但是，现有的黑盒LM分类器学习方法本身计算效率低下，通常使用零阶优化方法在大量的（离散或连续）提示空间中搜索将LM特化到目标任务。PromptBoosting不直接在提示空间进行优化，而是通过无梯度方法获得一小组提示，然后将这些提示与LM输出分布的不同元素配对构建大量弱学习器。然后使用AdaBoost算法对这些弱学习器进行集成。整个学习过程仅需要少量前向传递和n

    We describe PromptBoosting, a query-efficient procedure for building a text classifier from a neural language model (LM) without access to the LM's parameters, gradients, or hidden representations. This form of "black-box" classifier training has become increasingly important as the cost of training and inference in large-scale LMs grows. But existing black-box LM classifier learning approaches are themselves computationally inefficient, typically specializing LMs to the target task by searching in a large space of (discrete or continuous) prompts using zeroth-order optimization methods. Instead of directly optimizing in prompt space, PromptBoosting obtains a small pool of prompts via a gradient-free approach and then constructs a large pool of weak learners by pairing these prompts with different elements of the LM's output distribution. These weak learners are then ensembled using the AdaBoost algorithm. The entire learning process requires only a small number of forward passes and n
    
[^49]: 突破双盲评审: 基于深度学习的作者归属度量

    Cracking Double-Blind Review: Authorship Attribution with Deep Learning. (arXiv:2211.07467v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.07467](http://arxiv.org/abs/2211.07467)

    该论文提出了一种基于深度学习的作者归属度量方法，通过利用文本内容和参考文献中的作者姓名，可以将匿名手稿正确归属给作者。该方法在迄今为止最大的作者身份识别数据集上进行了训练和评估，在包含多达2000个不同作者的arXiv子集中，取得了前所未有的作者归属准确性。

    

    双盲同行评审被认为是学术研究的基石，因为它被认为可以确保一个公正、无偏和以事实为中心的科学讨论。然而，有经验的研究人员通常能准确猜测出匿名投稿的研究组来自何方，从而使同行评审过程产生偏见。在这项工作中，我们提出了一种基于Transformer的神经网络架构，它仅使用文本内容和参考文献中的作者姓名来将匿名手稿归属给一个作者。为了训练和评估我们的方法，我们创建了迄今为止最大的作者身份识别数据集。它利用了全部公开的arXiv研究论文，总计超过200万篇手稿。在包含多达2000个不同作者的arXiv子集中，我们的方法实现了前所未有的作者归属准确性，其中多达73%的论文被正确归属。我们进行了一个扩展性分析，以突出该方法在更大数据集中的适用性。

    Double-blind peer review is considered a pillar of academic research because it is perceived to ensure a fair, unbiased, and fact-centered scientific discussion. Yet, experienced researchers can often correctly guess from which research group an anonymous submission originates, biasing the peer-review process. In this work, we present a transformer-based, neural-network architecture that only uses the text content and the author names in the bibliography to attribute an anonymous manuscript to an author. To train and evaluate our method, we created the largest authorship identification dataset to date. It leverages all research papers publicly available on arXiv amounting to over 2 million manuscripts. In arXiv-subsets with up to 2,000 different authors, our method achieves an unprecedented authorship attribution accuracy, where up to 73% of papers are attributed correctly. We present a scaling analysis to highlight the applicability of the proposed method to even larger datasets when 
    
[^50]: 无语言限制的代码切换在序列到序列语音识别中的应用

    Language-agnostic Code-Switching in Sequence-To-Sequence Speech Recognition. (arXiv:2210.08992v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.08992](http://arxiv.org/abs/2210.08992)

    这项研究提出了一种数据增强方法，用于训练能够转录代码切换（CS）语音的多语言系统。通过将不同源语言的音频和标签连接起来，可以改善模型在转录CS语音上的性能，并在单语测试中超过了单语模型。这种增强技术甚至可以提高模型在训练期间未见过的句间语言切换上的性能。

    

    代码切换（CS）是指交替使用不同语言的单词和短语的现象。尽管现今的神经端到端（E2E）模型在自动语音识别（ASR）任务上表现出卓越的性能，但众所周知这些系统需要海量的数据。然而，现有的转录和对齐的CS语音数据很少。为了解决这个问题，并训练能够转录CS语音的多语言系统，我们提出了一种简单而有效的数据增强方法，即将不同源语言的音频和相应标签连接起来。通过使用这些训练数据，我们的E2E模型在转录CS语音方面得到了改进。它还在单语测试上超过了单语模型。结果表明，这种增强技术甚至可以提高模型在训练期间未见过的句间语言切换上的性能，WER提高了5.03%。

    Code-Switching (CS) is referred to the phenomenon of alternately using words and phrases from different languages. While today's neural end-to-end (E2E) models deliver state-of-the-art performances on the task of automatic speech recognition (ASR) it is commonly known that these systems are very data-intensive. However, there is only a few transcribed and aligned CS speech available. To overcome this problem and train multilingual systems which can transcribe CS speech, we propose a simple yet effective data augmentation in which audio and corresponding labels of different source languages are concatenated. By using this training data, our E2E model improves on transcribing CS speech. It also surpasses monolingual models on monolingual tests. The results show that this augmentation technique can even improve the model's performance on inter-sentential language switches not seen during training by 5,03% WER.
    
[^51]: PASTA: 一份用于建模叙述中参与者状态的数据集

    PASTA: A Dataset for Modeling Participant States in Narratives. (arXiv:2208.00329v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2208.00329](http://arxiv.org/abs/2208.00329)

    PASTA是一个新的用于建模叙述中参与者状态的数据集。通过推断隐含的状态和理解状态变化对叙述的影响，PASTA在三个基于状态的推理任务中进行了验证。实验结果显示，现有的语言模型在一定程度上能够进行状态推理，但仍存在局限性。

    

    叙述中的事件通过参与者的潜在状态被理解为一个连贯整体。通常情况下，这些参与者状态并没有明确提及，而是需要读者进行推断。一个理解叙述的模型应该能够推断这些隐含的状态，甚至可以推理出这些状态的变化对叙述的影响。为了达到这个目标，我们介绍了一个新的众包英文数据集——参与者状态数据集（PASTA）。这个数据集包含了可以推断的参与者状态，每个状态都有一个与之相对应的反事实扰动，以及如果反事实成立则叙述需要进行的变化。我们提出了三个基于状态的推理任务，用于测试模型是否能够推断出一个状态是否被故事所蕴含、在一个反事实状态的条件下对故事进行修正、以及在修正后的故事中最可能的状态变化是什么。实验证明，现今的语言模型在一定程度上能够进行状态推理，但还存在许多局限性。

    The events in a narrative are understood as a coherent whole via the underlying states of their participants. Often, these participant states are not explicitly mentioned, instead left to be inferred by the reader. A model that understands narratives should likewise infer these implicit states, and even reason about the impact of changes to these states on the narrative. To facilitate this goal, we introduce a new crowdsourced English-language, Participant States dataset, PASTA. This dataset contains inferable participant states; a counterfactual perturbation to each state; and the changes to the story that would be necessary if the counterfactual were true. We introduce three state-based reasoning tasks that test for the ability to infer when a state is entailed by a story, to revise a story conditioned on a counterfactual state, and to explain the most likely state change given a revised story. Experiments show that today's LLMs can reason about states to some degree, but there is la
    
[^52]: 通过语言模型提示的少样本多跳问题再排名研究

    Few-shot Reranking for Multi-hop QA via Language Model Prompting. (arXiv:2205.12650v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.12650](http://arxiv.org/abs/2205.12650)

    本研究提出了PromptRank方法，通过语言模型提供的多跳路径再排名，实现了少样本的多跳问题检索。在HotpotQA数据集上，PromptRank相比于其他方法使用的大量训练样本，仅使用128个训练示例就能达到较高的召回率。

    

    我们研究了开放领域问题的少样本多跳问题再排名。为了减少对大量标记的问题-文档对进行检索器训练的需求，我们提出了PromptRank，它依赖于大型语言模型对多跳路径进行再排名。PromptRank首先构建一个基于指令的提示，其中包含一个候选文档路径，然后根据语言模型中给定路径提示的条件概率，计算给定问题和路径之间的相关性得分。与基于大量示例训练的最先进方法相比，PromptRank在只有128个训练示例的情况下在HotpotQA上表现出很强的检索性能——PromptRank的召回率@10为73.6，而PathRetriever为77.8，多跳稠密检索为77.5。代码可在https://github.com/mukhal/PromptRank获得。

    We study few-shot reranking for multi-hop QA with open-domain questions. To alleviate the need for a large number of labeled question-document pairs for retriever training, we propose PromptRank, which relies on large language models prompting for multi-hop path reranking. PromptRank first constructs an instruction-based prompt that includes a candidate document path and then computes the relevance score between a given question and the path based on the conditional likelihood of the question given the path prompt according to a language model. PromptRank yields strong retrieval performance on HotpotQA with only 128 training examples compared to state-of-the-art methods trained on thousands of examples -- 73.6 recall@10 by PromptRank vs. 77.8 by PathRetriever and 77.5 by multi-hop dense retrieval. Code available at https://github.com/mukhal/PromptRank
    
[^53]: ELQA: 一个关于英语的元语言问题与答案的语料库

    ELQA: A Corpus of Metalinguistic Questions and Answers about English. (arXiv:2205.00395v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.00395](http://arxiv.org/abs/2205.00395)

    ELQA是一个关于英语的元语言问题与答案的语料库，可以用于研究NLU模型的元语言能力和语言学习应用。

    

    我们提出了ELQA，一个关于英语语言的问题与答案的语料库。该语料库收集自两个在线论坛，涵盖丰富的主题，包括语法、意义、流利度和词源。答案包括对英语词汇和语法的一般性描述，以及关于特定用法例子的解释（正确和错误）。与大多数自然语言处理数据集不同，这个语料库是元语言的，即它由语言关于语言的内容组成。因此，它可以促进对自然语言理解模型的元语言能力的研究，以及在语言学习领域的教育应用。为了研究这一点，我们在我们的数据集上定义了一个自由形式的问答任务，并对多个大型语言模型进行评估，以分析它们生成元语言答案的能力。

    We present ELQA, a corpus of questions and answers in and about the English language. Collected from two online forums, the >70k questions (from English learners and others) cover wide-ranging topics including grammar, meaning, fluency, and etymology. The answers include descriptions of general properties of English vocabulary and grammar as well as explanations about specific (correct and incorrect) usage examples. Unlike most NLP datasets, this corpus is metalinguistic -- it consists of language about language. As such, it can facilitate investigations of the metalinguistic capabilities of NLU models, as well as educational applications in the language learning domain. To study this, we define a free-form question answering task on our dataset and conduct evaluations on multiple LLMs (Large Language Models) to analyze their capacity to generate metalinguistic answers.
    
[^54]: CPTAM: 依存句法树聚合方法

    CPTAM: Constituency Parse Tree Aggregation Method. (arXiv:2201.07905v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2201.07905](http://arxiv.org/abs/2201.07905)

    本文提出了一种依存句法树聚合方法，通过估计不同解析器的可靠性，以持续获得高质量的聚合依存句法树。具体来说，通过最小化树之间的经典对称距离度量，罗宾逊-福尔兹距离的加权和，实现了树结构的真实性发现。

    

    许多自然语言处理任务使用依存句法分析来根据短语结构语法理解句子的句法结构。许多最先进的依存句法分析器已被提出，但它们对于相同的句子可能会提供不同的结果，特别是对于训练领域之外的语料库。本文采用真实性发现的思想，通过估计不同解析器的可靠性来聚合来自不同解析器的依存句法树，以持续获得高质量的聚合依存句法树。我们将依存句法树聚合问题分为两个步骤：结构聚合和成分标签聚合。具体地，我们提出了第一个用于树结构的真实性发现解决方案，通过最小化两个树之间的经典对称距离度量，即罗宾逊-福尔兹距离的加权和。对不同语言的基准数据集进行了广泛的实验。

    Diverse Natural Language Processing tasks employ constituency parsing to understand the syntactic structure of a sentence according to a phrase structure grammar. Many state-of-the-art constituency parsers are proposed, but they may provide different results for the same sentences, especially for corpora outside their training domains. This paper adopts the truth discovery idea to aggregate constituency parse trees from different parsers by estimating their reliability in the absence of ground truth. Our goal is to consistently obtain high-quality aggregated constituency parse trees. We formulate the constituency parse tree aggregation problem in two steps, structure aggregation and constituent label aggregation. Specifically, we propose the first truth discovery solution for tree structures by minimizing the weighted sum of Robinson-Foulds (RF) distances, a classic symmetric distance metric between two trees. Extensive experiments are conducted on benchmark datasets in different langu
    
[^55]: 交互语义模型

    A model of interaction semantics. (arXiv:2007.06258v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2007.06258](http://arxiv.org/abs/2007.06258)

    本研究提出了一种交互语义模型，通过构建系统交互模型，并不依赖于字符到概念的“心理”映射，来理解交互中字符的“含义”。

    

    本文基于交互语义模型，提出了关于交互中“含义”理解的某种观点。通过构建系统交互模型，我将交互语义模型结构化，类似于形式语言的语义：首先，我确定适当的变量以赋值，然后，我确定解释函数以提供意义。从而得到一个交互语义模型，可以不依赖于从字符到概念的“心理”映射，这与路德维希·维特根斯坦的观点相符。

    Purpose: The purpose of this article is to propose, based on a model of an interaction semantics, a certain understanding of the ''meaning'' of the exchanged characters within an interaction.  Methodology: Based on a model of system interaction, I structure the model of interaction semantics similar to the semantics of a formal language: first, I identify adequate variables in my interaction model to assign values to, and second, I identify the interpretation function to provide meaning. Thereby I arrive at a model of interaction semantics which, in the sense of the late Ludwig Wittgenstein, can do without a 'mental' mapping from characters to concepts.  Findings: The key findings are a better understanding of the tight relation between the informatical approach to model interactions and game theory; of the central 'chicken and egg' problem, any natural language has to solve, namely that to interact sensibly, we have to understand each other and to acquire a common understanding, we ha
    

