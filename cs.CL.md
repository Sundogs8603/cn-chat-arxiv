# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention.](http://arxiv.org/abs/2303.16199) | 本文提出了一种基于适应提示和零初始化注意力机制的轻量级语言模型调整方法，可高效微调LLaMA为指令跟随模型，具有比Alpaca更短的微调时间并具有近似的响应质量。 |
| [^2] | [Towards Countering Essentialism through Social Bias Reasoning.](http://arxiv.org/abs/2303.16173) | 本文探讨了对抗本质论信念的任务，并构建了五种类型的反驳语句进行了实验研究。结果表明，将刻板印象扩大到其他群体是最有效的反击策略。 |
| [^3] | [Reproducibility is Nothing without Correctness: The Importance of Testing Code in NLP.](http://arxiv.org/abs/2303.16166) | 在NLP研究中，我们不能仅凭感知质量假定代码正确性，应该推动采用编码最佳实践以提高实验结果的正确性和可靠性。 |
| [^4] | [Exposing and Addressing Cross-Task Inconsistency in Unified Vision-Language Models.](http://arxiv.org/abs/2303.16133) | 该研究提出了一个基准数据集COCOCON，并提出度量方法来衡量模型一致性，研究发现现有的最先进系统在不同任务之间表现出高度不一致性。 |
| [^5] | [Hallucinations in Large Multilingual Translation Models.](http://arxiv.org/abs/2303.16104) | 这项研究对常规神经机器翻译模型的M2M系列和ChacGPT进行了全面的分析，揭示了大型多语言翻译模型中幻觉的潜在原因，包括输入噪声，低资源语言和模型偏差，强调需要更好的评估和缓解策略以确保安全和可信部署。 |
| [^6] | [Carolina: a General Corpus of Contemporary Brazilian Portuguese with Provenance, Typology and Versioning Information.](http://arxiv.org/abs/2303.16098) | 介绍了首个公开版本的巴西葡萄牙语通用现代语料库Carolina，它使用了增强的来源、类型、版本和文本完整性的网络语料库方法，并且可作为语言学研究和计算机科学研究语言模型的重要资源。 |
| [^7] | [Synthetically generated text for supervised text analysis.](http://arxiv.org/abs/2303.16028) | 本文提出了使用大型语言模型控制生成合成文本的方案，以解决有监督文本模型存在的手动标记文档费用高、检索少量相关文档以进行标注的困难，以及版权和隐私问题等问题。作者提供了生成合成文本的概念概述和指导，讨论了伦理问题，并展示了三种合成文本的应用。 |
| [^8] | [An Experimental Study on Sentiment Classification of Moroccan dialect texts in the web.](http://arxiv.org/abs/2303.15987) | 本研究采用机器学习模型对YouTube评论中的摩洛哥方言进行情感分类，采用多种文本预处理和数据表示技术对文本进行分析，研究该方言的意见和情感表达。 |
| [^9] | [Do Neural Topic Models Really Need Dropout? Analysis of the Effect of Dropout in Topic Modeling.](http://arxiv.org/abs/2303.15973) | 本研究分析了三种常见的神经主题模型（CTM、ProdLDA和ETM），利用四个公开数据集探讨了使用dropout对神经主题模型的质量和预测效果的影响。 |
| [^10] | [A Multi-Granularity Matching Attention Network for Query Intent Classification in E-commerce Retrieval.](http://arxiv.org/abs/2303.15870) | 本文提出了一种名为 MMAN 的多粒度匹配注意力网络，可以全面提取查询和查询类别交互矩阵的特征，从而消除查询和类别之间表达差异的差距，用于查询意图分类。 |
| [^11] | [Soft-prompt tuning to predict lung cancer using primary care free-text Dutch medical notes.](http://arxiv.org/abs/2303.15846) | 本论文研究了使用初级保健医师的患者医疗笔记进行肺癌早期预测的问题，并探讨了针对高度不平衡分类问题的软提示调整和静态词嵌入模型在模型训练中的表现。 |
| [^12] | [Evaluation of ChatGPT for NLP-based Mental Health Applications.](http://arxiv.org/abs/2303.15727) | 本篇论文评估了基于LLM和ChatGPT在心理健康领域的实际应用，显示出其在压力和抑郁症检测方面表现良好，但在自杀风险检测上仍需改进。 |
| [^13] | [Explicit Planning Helps Language Models in Logical Reasoning.](http://arxiv.org/abs/2303.15714) | 本文提出了一个新的系统，使用语言模型进行多步逻辑推理，采用了显式规划来帮助做出更明智的决策，比其他竞争系统表现更好，显式规划在系统性能中起着关键作用。 |
| [^14] | [Bias or Diversity? Unraveling Semantic Discrepancy in U.S. News Headlines.](http://arxiv.org/abs/2303.15708) | 本研究通过收集180万份美国主要媒体机构的新闻标题，揭示了美国新闻媒体中的语义差异，并发现在国内政治和社会问题上，差异可以在一定程度上归因于媒体偏见。 |
| [^15] | [Translate the Beauty in Songs: Jointly Learning to Align Melody and Translate Lyrics.](http://arxiv.org/abs/2303.15705) | 本文提出了一种自适应分组歌词旋律翻译（LTAG）的综合解决方案，可以在翻译源歌词的同时确定每个解码步骤的对齐音符数量。 |
| [^16] | [Model and Evaluation: Towards Fairness in Multilingual Text Classification.](http://arxiv.org/abs/2303.15697) | 本文提出了一种基于对比学习的多语言文本分类解偏模型，不依赖于外部语言资源，可以扩展到任何其他语言。该模型包含四个模块，可以有效降低文本分类中的偏见。 |
| [^17] | [Pre-training Transformers for Knowledge Graph Completion.](http://arxiv.org/abs/2303.15682) | 该论文介绍了一种面向知识图谱补全的归纳式表示模型（iHT），通过大规模预训练，iHT表示可转移且在多个数据集上取得了最先进的结果。 |
| [^18] | [ChatGPT4PCG Competition: Character-like Level Generation for Science Birds.](http://arxiv.org/abs/2303.15662) | 本论文介绍了举办在2023 IEEE游戏会议上的第一届ChatGPT4PCG比赛，目标是让ChatGPT生成具有高稳定性和类似角色的特质来生成具有科学鸟角色级水平的关卡。 |
| [^19] | [Joint embedding in Hierarchical distance and semantic representation learning for link prediction.](http://arxiv.org/abs/2303.15655) | 本文提出了一种名为HIE的知识图谱嵌入模型，它将每个三元组同时建模为距离测量空间和语义测量空间，并在分层感知空间中利用实体和关系的丰富分层信息以获得更好的表示学习效果。 |
| [^20] | [Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning.](http://arxiv.org/abs/2303.15647) | 本文综述了40多种缩小模型规模进行超大模型参数微调的方法，旨在解决大型语言模型训练的不可行性和不切实际性。提供了分类法和方法比较，并重点关注实际效率和千亿级语言模型微调。 |
| [^21] | [ChatGPT as a Factual Inconsistency Evaluator for Abstractive Text Summarization.](http://arxiv.org/abs/2303.15621) | 本文研究了ChatGPT作为抽象文本摘要中事实不一致性评估器的能力，证明其在不需要注释数据和高计算复杂度的情况下，在粗粒度和细粒度的任务中表现出了最先进的性能。 |
| [^22] | [Typhoon: Towards an Effective Task-Specific Masking Strategy for Pre-trained Language Models.](http://arxiv.org/abs/2303.15619) | 本文探讨了一种针对预训练语言模型的任务特定的屏蔽框架，称为Typhoon，可在GLUE基准数据集上实现卓越的下游任务性能，尤其在MRPC数据集上表现优异。 |
| [^23] | [Linguistically Informed ChatGPT Prompts to Enhance Japanese-Chinese Machine Translation: A Case Study on Attributive Clauses.](http://arxiv.org/abs/2303.15587) | 提升日中机器翻译准确性的新方法：使用结合预编辑方案和 ChatGPT 的两步提示策略，平均翻译准确性得分提高超过35％。 |
| [^24] | [Large Language Models are Diverse Role-Players for Summarization Evaluation.](http://arxiv.org/abs/2303.15078) | 本文提出了一种新的基于LLMs的评估框架，通过比较生成的文本和参考文本的客观和主观维度，提供了全面的评估框架。 |
| [^25] | [SmartBook: AI-Assisted Situation Report Generation.](http://arxiv.org/abs/2303.14337) | SmartBook是一种AI辅助的情报报告生成工具，通过消耗大量新闻数据生成一个结构化的情况报告，其中包含多个假设（主张），并与事实依据建立丰富的关联。在Ukraine-Russia危机中，机器生成的报告以时间轴的形式结构化，显著减少了报告时间，并通过生成比人类同行更全面、准确和一致的报告来提高报告质量。 |
| [^26] | [ChatDoctor: A Medical Chat Model Fine-tuned on LLaMA Model using Medical Domain Knowledge.](http://arxiv.org/abs/2303.14070) | 本文介绍了一种在医学领域利用LLaMA模型微调的医疗聊天模型ChatDoctor。经过700多种疾病和其相应症状、药品和医疗检查的收集和处理，这种模型具有理解患者需求、提供建议和帮助的潜力。这些先进的语言模型集成到医疗保健中可以极大地改进医疗专业人员和患者的沟通方式。 |
| [^27] | [DBLP-QuAD: A Question Answering Dataset over the DBLP Scholarly Knowledge Graph.](http://arxiv.org/abs/2303.13351) | 这篇论文在DBLP学术知识图上创建了一个包含10000个问题-答案对的问答数据集，是最大的学术问答数据集。 |
| [^28] | [GETT-QA: Graph Embedding based T2T Transformer for Knowledge Graph Question Answering.](http://arxiv.org/abs/2303.13284) | 本论文提出了GETT-QA系统，该系统使用T5对自然语言问题生成简化的SPARQL查询，并使用截断的KG嵌入提高了知识图谱问答的性能。 |
| [^29] | [Self-supervised Meta-Prompt Learning with Meta-Gradient Regularization for Few-shot Generalization.](http://arxiv.org/abs/2303.12314) | 提出了一种自我监督元提示学习框架SUPMER，包括元梯度正则化，用于少样本泛化，通过锚定的元训练任务和基于课程的任务增强丰富了任务分布，解决了在少样本情况下良好初始化软提示和过拟合的问题。 |
| [^30] | [Two-stage Pipeline for Multilingual Dialect Detection.](http://arxiv.org/abs/2303.03487) | 本篇论文提出了一种两阶段的方言识别系统，在VarDial 2023中超越其他参与者的系统，对多语言方言检测有重要贡献。 |
| [^31] | [EvoPrompting: Language Models for Code-Level Neural Architecture Search.](http://arxiv.org/abs/2302.14838) | EvoPrompting利用语言模型作为自适应变异和交叉操作符来进行神经架构搜索，在MNIST-1D数据集和CLRS算法推理基准上都取得了比人类设计的架构更好的性能表现。 |
| [^32] | [AdapterSoup: Weight Averaging to Improve Generalization of Pretrained Language Models.](http://arxiv.org/abs/2302.07027) | 本文提出了AdapterSoup，一种使用加权平均改善预训练语言模型泛化能力的方法。该方法在不同领域训练的适配器上执行权重空间平均，可以在不需要额外训练的情况下提高对新领域的性能。 |
| [^33] | [KNNs of Semantic Encodings for Rating Prediction.](http://arxiv.org/abs/2302.00412) | 本文提出了一种通过文本语义相似性预测用户评分的方法，并且在评估中表现出优异的性能。 |
| [^34] | [Opportunities and Challenges in Neural Dialog Tutoring.](http://arxiv.org/abs/2301.09919) | 本文研究了神经对话辅导存在的机遇和挑战，发现当前方法在少量概念和可能的教师策略的情况下可以进行较好的辅导模拟与学习，但在不受限制的情况下表现不佳，未来应该集中在解决这些问题上。 |
| [^35] | [TextDescriptives: A Python package for calculating a large variety of metrics from text.](http://arxiv.org/abs/2301.02057) | TextDescriptives是一个Python包，可用于从文本中计算多种指标，已被用于分析临床文本的语言稳定性、预测神经精神疾病的特征以及分析小学生成语言目标。 |
| [^36] | [InferEM: Inferring the Speaker's Intention for Empathetic Dialogue Generation.](http://arxiv.org/abs/2212.06373) | 通过推断对话中最后一次发言来捕捉说话者的意图，提出了一种利用多头注意力的意图融合模块的共情对话生成模型InferEM。模型同时利用前几次发言预测最后一次发言，具有较高的可行性。 |
| [^37] | [PromptCap: Prompt-Guided Image Captioning for VQA with GPT-3.](http://arxiv.org/abs/2211.09699) | 提出了PromptCap，一种使用提示引导的图像字幕生成模型，用于解决基于知识的视觉问答中通用图像字幕无法准确描述视觉实体的问题。 |
| [^38] | [SilverAlign: MT-Based Silver Data Algorithm For Evaluating Word Alignment.](http://arxiv.org/abs/2210.06207) | 本文提出SilverAlign算法，将机器翻译和最小对用于生成银标准数据以评估单词对齐器，解决了低资源语言缺失金标准数据对齐的重要场景问题。 |
| [^39] | [AtteSTNet -- An attention and subword tokenization based approach for code-switched text hate speech detection.](http://arxiv.org/abs/2112.11479) | AtteSTNet是一种基于注意力机制和子词分割的检测混合语言仇恨言论的方法，它不仅与复杂网络相当，而且在各种数据集上性能更好，其极大的简单性和易于维护性是其优点。 |

# 详细

[^1]: LLaMA-Adapter: 零初始化注意力下的语言模型精细调整的高效方法

    LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention. (arXiv:2303.16199v1 [cs.CV])

    [http://arxiv.org/abs/2303.16199](http://arxiv.org/abs/2303.16199)

    本文提出了一种基于适应提示和零初始化注意力机制的轻量级语言模型调整方法，可高效微调LLaMA为指令跟随模型，具有比Alpaca更短的微调时间并具有近似的响应质量。

    

    本文提出了LLaMA-Adapter这一轻量级适应方法，用于将LLaMA高效地微调为一个指令跟随模型。利用52K个自我指导示范，LLaMA-Adapter仅在冻结的LLaMA 7B模型上引入了1.2M个可学习参数，并且在8个A100 GPU上仅耗时不到一个小时进行微调。具体而言，我们采用一组可学习的适应提示，并在较高的变压器层中将它们预置于输入文本令牌之前。然后，提出了一种零初始化注意力机制和零门控机制，该机制可以自适应地将新的指令提示注入LLaMA，并有效地保留了其预先训练的知识。通过高效训练，LLaMA-Adapter能够产生高质量的响应，与完全微调的7B参数的Alpaca相似。此外，我们的方法还可以简单地扩展到多模态输入，例如图像，用于图像相关的LLaMA，在ScienceQA上实现了更强的推理能力。我们在https://github.com/ZrrSkywalker/LLaMA-Adapt发布了我们的代码。

    We present LLaMA-Adapter, a lightweight adaption method to efficiently fine-tune LLaMA into an instruction-following model. Using 52K self-instruct demonstrations, LLaMA-Adapter only introduces 1.2M learnable parameters upon the frozen LLaMA 7B model, and costs less than one hour for fine-tuning on 8 A100 GPUs. Specifically, we adopt a set of learnable adaption prompts, and prepend them to the input text tokens at higher transformer layers. Then, a zero-init attention mechanism with zero gating is proposed, which adaptively injects the new instructional cues into LLaMA, while effectively preserves its pre-trained knowledge. With efficient training, LLaMA-Adapter generates high-quality responses, comparable to Alpaca with fully fine-tuned 7B parameters. Furthermore, our approach can be simply extended to multi-modal input, e.g., images, for image-conditioned LLaMA, which achieves superior reasoning capacity on ScienceQA. We release our code at https://github.com/ZrrSkywalker/LLaMA-Adapt
    
[^2]: 通过社会偏见推理来对抗本质论

    Towards Countering Essentialism through Social Bias Reasoning. (arXiv:2303.16173v1 [cs.CL])

    [http://arxiv.org/abs/2303.16173](http://arxiv.org/abs/2303.16173)

    本文探讨了对抗本质论信念的任务，并构建了五种类型的反驳语句进行了实验研究。结果表明，将刻板印象扩大到其他群体是最有效的反击策略。

    

    本质论信仰在社会刻板印象中起着核心作用，如果不被挑战，可能会导致伤害。本文旨在探讨对抗本质论信念的任务（例如“自由派愚蠢”），并进行了探索性研究。结合心理学和自然语言处理的先前研究，本研究构建了五种类型的反驳语句，并进行了人类实验以研究这些不同策略的有效性。我们的研究还探讨了在选择反驳语句时以多大的明确程度传达本质论信念的作用。我们发现，将刻板印象扩大到其他群体（例如，“保守派也可能愚蠢”）的语句是最受欢迎的反击策略。我们最后讨论了未来工作中的挑战和开放性问题（例如，提高事实性，研究社区特定变化），并强调了在该领域开展工作的重要性。

    Essentialist beliefs (i.e., believing that members of the same group are fundamentally alike) play a central role in social stereotypes and can lead to harm when left unchallenged. In our work, we conduct exploratory studies into the task of countering essentialist beliefs (e.g., ``liberals are stupid''). Drawing on prior work from psychology and NLP, we construct five types of counterstatements and conduct human studies on the effectiveness of these different strategies. Our studies also investigate the role in choosing a counterstatement of the level of explicitness with which an essentialist belief is conveyed. We find that statements that broaden the scope of a stereotype (e.g., to other groups, as in ``conservatives can also be stupid'') are the most popular countering strategy. We conclude with a discussion of challenges and open questions for future work in this area (e.g., improving factuality, studying community-specific variation) and we emphasize the importance of work at th
    
[^3]: 没有正确性的可重复性并不重要：在NLP领域中测试代码的重要性。

    Reproducibility is Nothing without Correctness: The Importance of Testing Code in NLP. (arXiv:2303.16166v1 [cs.CL])

    [http://arxiv.org/abs/2303.16166](http://arxiv.org/abs/2303.16166)

    在NLP研究中，我们不能仅凭感知质量假定代码正确性，应该推动采用编码最佳实践以提高实验结果的正确性和可靠性。

    

    尽管其在研究实验中发挥了关键作用，但代码正确性往往仅基于结果的感知质量而被假定。这带来了错误结果和潜在误导性发现的风险。为了解决这个问题，我们认为当前关注结果重现应该与强调编码最佳实践相辅相成。我们通过一个案例研究来支持我们向NLP社区发出的号召，在这个案例研究中，我们识别出并纠正了广泛使用的最先进Conformer架构的开源实现中的三个Bug。通过在各种语言环境下进行的自动语音识别和翻译的比较实验，我们证明了Bug的存在并不会妨碍获得良好的和可重复的结果，反而可能导致不正确的结论，为未来的研究可能提供错误的指导。为了应对这一问题，这项研究呼吁采用旨在促进NLP研究中正确性的编码最佳实践，并提高实验结果的可靠性。

    Despite its pivotal role in research experiments, code correctness is often presumed only on the basis of the perceived quality of the results. This comes with the risk of erroneous outcomes and potentially misleading findings. To address this issue, we posit that the current focus on result reproducibility should go hand in hand with the emphasis on coding best practices. We bolster our call to the NLP community by presenting a case study, in which we identify (and correct) three bugs in widely used open-source implementations of the state-of-the-art Conformer architecture. Through comparative experiments on automatic speech recognition and translation in various language settings, we demonstrate that the existence of bugs does not prevent the achievement of good and reproducible results and can lead to incorrect conclusions that potentially misguide future research. In response to this, this study is a call to action toward the adoption of coding best practices aimed at fostering cor
    
[^4]: 揭示和解决统一视觉-语言模型中的跨任务不一致问题

    Exposing and Addressing Cross-Task Inconsistency in Unified Vision-Language Models. (arXiv:2303.16133v1 [cs.CV])

    [http://arxiv.org/abs/2303.16133](http://arxiv.org/abs/2303.16133)

    该研究提出了一个基准数据集COCOCON，并提出度量方法来衡量模型一致性，研究发现现有的最先进系统在不同任务之间表现出高度不一致性。

    

    随着通用的视觉模型在不同任务上变得越来越有效，保证它们在各自支持的任务中的一致性是非常重要的。人们认为不一致的人工智能模型是不可靠的，这对于依赖它们输出的大型系统来说是更具挑战性的。由于很难确定预测结果是否一致，因此，评估可能包括不同模态输出的非常异构任务之间的一致性是具有挑战性的。因此，我们提出了基准数据集COCOCON，其中我们使用对多个任务的测试实例进行小型但语义上有意义的修改来创建对比集，以更改金标签，并概述了用于通过对比接近原始和修改后的实例来衡量模型一致性的指标。我们发现，最先进的系统在任务之间表现出惊人的不一致性。

    As general purpose vision models get increasingly effective at a wide set of tasks, it is imperative that they be consistent across the tasks they support. Inconsistent AI models are considered brittle and untrustworthy by human users and are more challenging to incorporate into larger systems that take dependencies on their outputs. Measuring consistency between very heterogeneous tasks that might include outputs in different modalities is challenging since it is difficult to determine if the predictions are consistent with one another. As a solution, we introduce a benchmark dataset, COCOCON, where we use contrast sets created by modifying test instances for multiple tasks in small but semantically meaningful ways to change the gold label, and outline metrics for measuring if a model is consistent by ranking the original and perturbed instances across tasks. We find that state-of-the-art systems suffer from a surprisingly high degree of inconsistent behavior across tasks, especially 
    
[^5]: 大型多语言翻译模型中的幻觉

    Hallucinations in Large Multilingual Translation Models. (arXiv:2303.16104v1 [cs.CL])

    [http://arxiv.org/abs/2303.16104](http://arxiv.org/abs/2303.16104)

    这项研究对常规神经机器翻译模型的M2M系列和ChacGPT进行了全面的分析，揭示了大型多语言翻译模型中幻觉的潜在原因，包括输入噪声，低资源语言和模型偏差，强调需要更好的评估和缓解策略以确保安全和可信部署。

    

    大规模多语言机器翻译系统展示了直接在众多语言之间进行翻译的卓越能力，这使得它们越来越适用于实际应用。然而，在实际应用中，这些模型可能会生成幻觉翻译，这可能会严重破坏用户信任并引发安全问题。本文对常规神经机器翻译模型的M2M系列和ChacGPT进行了全面的分析，这些模型可以提示进行翻译。我们的调查涵盖了广泛的条件，包括各种资源水平和100多个翻译方向，超越了简单的词级幻觉，探索了更复杂的现象，如罕见词替换，事实错误和不合逻辑的句子生成。我们发现了幻觉的潜在原因，包括输入噪声，低资源语言和模型偏差，并强调需要更好的评估和缓解策略，以确保大型多语言翻译模型的安全和可信部署。

    Large-scale multilingual machine translation systems have demonstrated remarkable ability to translate directly between numerous languages, making them increasingly appealing for real-world applications. However, when deployed in the wild, these models may generate hallucinated translations which have the potential to severely undermine user trust and raise safety concerns. Existing research on hallucinations has primarily focused on small bilingual models trained on high-resource languages, leaving a gap in our understanding of hallucinations in massively multilingual models across diverse translation scenarios. In this work, we fill this gap by conducting a comprehensive analysis on both the M2M family of conventional neural machine translation models and ChatGPT, a general-purpose large language model~(LLM) that can be prompted for translation. Our investigation covers a broad spectrum of conditions, spanning over 100 translation directions across various resource levels and going b
    
[^6]: Carolina：一种具有来源、类型和版本信息的巴西葡萄牙语通用现代语料库

    Carolina: a General Corpus of Contemporary Brazilian Portuguese with Provenance, Typology and Versioning Information. (arXiv:2303.16098v1 [cs.CL])

    [http://arxiv.org/abs/2303.16098](http://arxiv.org/abs/2303.16098)

    介绍了首个公开版本的巴西葡萄牙语通用现代语料库Carolina，它使用了增强的来源、类型、版本和文本完整性的网络语料库方法，并且可作为语言学研究和计算机科学研究语言模型的重要资源。

    

    本文介绍了首个公开版本的Carolina语料库，并讨论了它的未来方向。Carolina是一个使用增强的来源、类型、版本和文本完整性的网络语料库方法正在构建中的巴西葡萄牙语文本的大型开放语料库。该语料库旨在作为语言学研究的可靠来源和计算机科学研究语言模型的重要资源，有助于将葡萄牙语从低资源语言中移除。本文介绍了构建语料库的方法，并将其与其他现有方法进行比较，以及语料库的当前状态：Carolina的第一个公开版有653,322,577个标记，分布在7个广泛的类型上。每个文本的标头都用TEI注释标准进行了多个不同的元数据类别的注释。我们还介绍了正在进行的派生作品，并邀请NLP研究人员进行贡献。

    This paper presents the first publicly available version of the Carolina Corpus and discusses its future directions. Carolina is a large open corpus of Brazilian Portuguese texts under construction using web-as-corpus methodology enhanced with provenance, typology, versioning, and text integrality. The corpus aims at being used both as a reliable source for research in Linguistics and as an important resource for Computer Science research on language models, contributing towards removing Portuguese from the set of low-resource languages. Here we present the construction of the corpus methodology, comparing it with other existing methodologies, as well as the corpus current state: Carolina's first public version has $653,322,577$ tokens, distributed over $7$ broad types. Each text is annotated with several different metadata categories in its header, which we developed using TEI annotation standards. We also present ongoing derivative works and invite NLP researchers to contribute with 
    
[^7]: 制造合成文本以进行有监督文本分析

    Synthetically generated text for supervised text analysis. (arXiv:2303.16028v1 [cs.CL])

    [http://arxiv.org/abs/2303.16028](http://arxiv.org/abs/2303.16028)

    本文提出了使用大型语言模型控制生成合成文本的方案，以解决有监督文本模型存在的手动标记文档费用高、检索少量相关文档以进行标注的困难，以及版权和隐私问题等问题。作者提供了生成合成文本的概念概述和指导，讨论了伦理问题，并展示了三种合成文本的应用。

    

    有监督文本模型对政治学家来说是一种宝贵的工具，但存在若干使用障碍，包括手动标记文档的费用，检索少量相关文档以进行标注的困难，以及共享带有注释文档所涉及的版权和隐私问题。本文提出了一个部分解决这三个问题的方案，即使用大型语言模型控制生成合成文本。作者提供了文本生成的概念概述，并指导研究人员何时应该选择不同的合成文本生成技术，讨论了伦理问题，并介绍了一种改进合成文本质量的简单技术。作者展示了合成文本的三种应用：生成描述乌克兰战斗的合成推特，生成描述特定政治事件的合成新闻文章以用于训练事件检测系统，以及一个多语言的民粹主义宣言语料库用于训练

    Supervised text models are a valuable tool for political scientists but present several obstacles to their use, including the expense of hand-labeling documents, the difficulty of retrieving rare relevant documents for annotation, and copyright and privacy concerns involved in sharing annotated documents. This article proposes a partial solution to these three issues, in the form of controlled generation of synthetic text with large language models. I provide a conceptual overview of text generation, guidance on when researchers should prefer different techniques for generating synthetic text, a discussion of ethics, and a simple technique for improving the quality of synthetic text. I demonstrate the usefulness of synthetic text with three applications: generating synthetic tweets describing the fighting in Ukraine, synthetic news articles describing specified political events for training an event detection system, and a multilingual corpus of populist manifesto statements for traini
    
[^8]: 关于摩洛哥方言文本情感分类的实验研究

    An Experimental Study on Sentiment Classification of Moroccan dialect texts in the web. (arXiv:2303.15987v1 [cs.CL])

    [http://arxiv.org/abs/2303.15987](http://arxiv.org/abs/2303.15987)

    本研究采用机器学习模型对YouTube评论中的摩洛哥方言进行情感分类，采用多种文本预处理和数据表示技术对文本进行分析，研究该方言的意见和情感表达。

    

    随着社交媒体网站的迅速增长，自动获取用户反馈成为评估其在线趋势和行为的重要任务。尽管信息大量可用，阿拉伯使用者数量增加，但很少有研究处理阿拉伯方言。本文旨在准确研究在YouTube评论中表达的真实摩洛哥方言文本的观点和情感，使用一些众所周知且常用的情感分析方法进行。通过采用许多文本预处理和数据表示技术，我们旨在比较我们使用最常用的监督分类器进行分类结果：K最近邻（KNN）、支持向量机（SVM）、朴素贝叶斯（NB）和深度学习（DL）分类器，这些都是基于我们收集和手动注释的YouTube摩洛哥方言数据集。

    With the rapid growth of the use of social media websites, obtaining the users' feedback automatically became a crucial task to evaluate their tendencies and behaviors online. Despite this great availability of information, and the increasing number of Arabic users only few research has managed to treat Arabic dialects. The purpose of this paper is to study the opinion and emotion expressed in real Moroccan texts precisely in the YouTube comments using some well-known and commonly used methods for sentiment analysis. In this paper, we present our work of Moroccan dialect comments classification using Machine Learning (ML) models and based on our collected and manually annotated YouTube Moroccan dialect dataset. By employing many text preprocessing and data representation techniques we aim to compare our classification results utilizing the most commonly used supervised classifiers: k-nearest neighbors (KNN), Support Vector Machine (SVM), Naive Bayes (NB), and deep learning (DL) classif
    
[^9]: 神经主题模型真的需要使用dropout吗？关于dropout在主题建模中的影响分析

    Do Neural Topic Models Really Need Dropout? Analysis of the Effect of Dropout in Topic Modeling. (arXiv:2303.15973v1 [cs.CL])

    [http://arxiv.org/abs/2303.15973](http://arxiv.org/abs/2303.15973)

    本研究分析了三种常见的神经主题模型（CTM、ProdLDA和ETM），利用四个公开数据集探讨了使用dropout对神经主题模型的质量和预测效果的影响。

    

    Dropout是一种广泛使用的正则化技巧，用于解决在小数据集上训练的大型前馈神经网络过拟合问题，该问题在测试集上表现不佳。尽管这种正则化技巧在卷积神经网络中的有效性已经得到广泛研究，但对于无监督模型（特别是基于VAE的神经主题模型），缺乏对其的分析。本文在三个广泛使用的神经主题模型（即，情境主题模型（CTM），ProdLDA和嵌入式主题模型（ETM））中，利用四个公开可用数据集，分析了VAE架构的编码器和解码器中dropout的后果。我们从生成的主题的质量和预测性能的角度，表征了这些模型的dropout效应。

    Dropout is a widely used regularization trick to resolve the overfitting issue in large feedforward neural networks trained on a small dataset, which performs poorly on the held-out test subset. Although the effectiveness of this regularization trick has been extensively studied for convolutional neural networks, there is a lack of analysis of it for unsupervised models and in particular, VAE-based neural topic models. In this paper, we have analyzed the consequences of dropout in the encoder as well as in the decoder of the VAE architecture in three widely used neural topic models, namely, contextualized topic model (CTM), ProdLDA, and embedded topic model (ETM) using four publicly available datasets. We characterize the dropout effect on these models in terms of the quality and predictive performance of the generated topics.
    
[^10]: 电商检索中用于查询意图分类的多粒度匹配注意力网络

    A Multi-Granularity Matching Attention Network for Query Intent Classification in E-commerce Retrieval. (arXiv:2303.15870v1 [cs.IR])

    [http://arxiv.org/abs/2303.15870](http://arxiv.org/abs/2303.15870)

    本文提出了一种名为 MMAN 的多粒度匹配注意力网络，可以全面提取查询和查询类别交互矩阵的特征，从而消除查询和类别之间表达差异的差距，用于查询意图分类。

    

    查询意图分类旨在协助客户找到所需产品，已成为电子商务搜索的重要组成部分。现有的查询意图分类模型要么设计更精细的模型以增强查询的表示学习，要么探索标签图和多任务以帮助模型学习外部信息。然而，这些模型无法从查询和类别中捕捉多粒度匹配特征，这使得它们难以弥补非正式查询和类别之间表达差异的差距。本文提出了一种多粒度匹配注意力网络(MMAN)，其包含三个模块：自匹配模块、字符级匹配模块和语义级匹配模块，以全面提取查询和查询类别交互矩阵的特征。通过这种方式，该模型可以消除查询意图分类中查询和类别之间表达差异的差距。

    Query intent classification, which aims at assisting customers to find desired products, has become an essential component of the e-commerce search. Existing query intent classification models either design more exquisite models to enhance the representation learning of queries or explore label-graph and multi-task to facilitate models to learn external information. However, these models cannot capture multi-granularity matching features from queries and categories, which makes them hard to mitigate the gap in the expression between informal queries and categories.  This paper proposes a Multi-granularity Matching Attention Network (MMAN), which contains three modules: a self-matching module, a char-level matching module, and a semantic-level matching module to comprehensively extract features from the query and a query-category interaction matrix. In this way, the model can eliminate the difference in expression between queries and categories for query intent classification. We conduc
    
[^11]: 利用初级保健医师的荷兰医疗笔记预测肺癌的软提示调整

    Soft-prompt tuning to predict lung cancer using primary care free-text Dutch medical notes. (arXiv:2303.15846v1 [cs.CL])

    [http://arxiv.org/abs/2303.15846](http://arxiv.org/abs/2303.15846)

    本论文研究了使用初级保健医师的患者医疗笔记进行肺癌早期预测的问题，并探讨了针对高度不平衡分类问题的软提示调整和静态词嵌入模型在模型训练中的表现。

    

    我们研究了基于上下文词表示的不同自然语言处理（NLP）方法，用于使用荷兰初级保健医师的患者医疗笔记早期预测肺癌的问题。因为肺癌在初级保健中的患病率较低，所以我们还解决了在高度不平衡的类别下进行分类的问题。具体而言，我们使用大型基于Transformer的预训练语言模型（PLMs），并研究：1）如何将\textit {软提示调整} - 一种使用小量训练数据调整PLMs的NLP技术 - 与标准模型微调进行比较； 2）在高度不平衡的设置中，是否简单的静态词嵌入模型（WEMs）可以比PLMs更健壮；以及3）当训练笔记来自少量患者时，模型的表现如何。我们发现，1）软提示调整是标准模型微调的有效替代方案； 2）PLMs比较简单的静态词嵌入模型表现出更好的区分能力但更差的校准能力。

    We investigate different natural language processing (NLP) approaches based on contextualised word representations for the problem of early prediction of lung cancer using free-text patient medical notes of Dutch primary care physicians. Because lung cancer has a low prevalence in primary care, we also address the problem of classification under highly imbalanced classes. Specifically, we use large Transformer-based pretrained language models (PLMs) and investigate: 1) how \textit{soft prompt-tuning} -- an NLP technique used to adapt PLMs using small amounts of training data -- compares to standard model fine-tuning; 2) whether simpler static word embedding models (WEMs) can be more robust compared to PLMs in highly imbalanced settings; and 3) how models fare when trained on notes from a small number of patients. We find that 1) soft-prompt tuning is an efficient alternative to standard model fine-tuning; 2) PLMs show better discrimination but worse calibration compared to simpler stat
    
[^12]: 评估ChatGPT在基于NLP的心理健康应用中的应用

    Evaluation of ChatGPT for NLP-based Mental Health Applications. (arXiv:2303.15727v1 [cs.CL])

    [http://arxiv.org/abs/2303.15727](http://arxiv.org/abs/2303.15727)

    本篇论文评估了基于LLM和ChatGPT在心理健康领域的实际应用，显示出其在压力和抑郁症检测方面表现良好，但在自杀风险检测上仍需改进。

    

    大型语言模型(LLM)在多项自然语言理解任务中具有成功的应用，可能对基于自然语言处理(NLP)的心理健康应用研究也很有帮助。本研究报告了基于LLM的ChatGPT (使用gpt-3.5-turbo后端)在三个文本类心理健康分类任务中的表现: 压力检测 (2类分类)、抑郁症检测(2类分类)和自杀风险检测(5类分类)。我们从公共数据集中获取了三个分类任务的带标注社交媒体帖子。然后使用ChatGPT API对社交媒体帖子进行输入提示分类。我们得到了0.73、0.86和0.37的F1分数，分别用于压力检测、抑郁症检测和自杀风险检测。总体上，ChatGPT在语言处理领域中具备很大的应用前景。

    Large language models (LLM) have been successful in several natural language understanding tasks and could be relevant for natural language processing (NLP)-based mental health application research. In this work, we report the performance of LLM-based ChatGPT (with gpt-3.5-turbo backend) in three text-based mental health classification tasks: stress detection (2-class classification), depression detection (2-class classification), and suicidality detection (5-class classification). We obtained annotated social media posts for the three classification tasks from public datasets. Then ChatGPT API classified the social media posts with an input prompt for classification. We obtained F1 scores of 0.73, 0.86, and 0.37 for stress detection, depression detection, and suicidality detection, respectively. A baseline model that always predicted the dominant class resulted in F1 scores of 0.35, 0.60, and 0.19. The zero-shot classification accuracy obtained with ChatGPT indicates a potential use o
    
[^13]: 显式规划有助于语言模型进行逻辑推理

    Explicit Planning Helps Language Models in Logical Reasoning. (arXiv:2303.15714v1 [cs.CL])

    [http://arxiv.org/abs/2303.15714](http://arxiv.org/abs/2303.15714)

    本文提出了一个新的系统，使用语言模型进行多步逻辑推理，采用了显式规划来帮助做出更明智的决策，比其他竞争系统表现更好，显式规划在系统性能中起着关键作用。

    

    语言模型在各种自然语言处理任务中表现出色。本文提出了一个新颖的系统，采用语言模型进行多步逻辑推理。我们的系统将显式规划纳入到推理过程中，因此可以通过展望未来的效果来做出更明智的决策。在实验中，我们的全套系统在多项选择题答题任务中明显优于其他竞争系统，尽管只有约15亿个参数，但与GPT-3-davinci表现相当。我们进行了多个消融研究以证明显式规划在系统性能中起着关键作用。

    Language models have been shown to perform remarkably well on a wide range of natural language processing tasks. In this paper, we propose a novel system that uses language models to perform multi-step logical reasoning. Our system incorporates explicit planning into its inference procedure, thus able to make more informed reasoning decisions at each step by looking ahead into their future effects. In our experiments, our full system significantly outperforms other competing systems. On a multiple-choice question answering task, our system performs competitively compared to GPT-3-davinci despite having only around 1.5B parameters. We conduct several ablation studies to demonstrate that explicit planning plays a crucial role in the system's performance.
    
[^14]: 偏见还是多样性？揭示美国新闻标题中的语义差异

    Bias or Diversity? Unraveling Semantic Discrepancy in U.S. News Headlines. (arXiv:2303.15708v1 [cs.CL])

    [http://arxiv.org/abs/2303.15708](http://arxiv.org/abs/2303.15708)

    本研究通过收集180万份美国主要媒体机构的新闻标题，揭示了美国新闻媒体中的语义差异，并发现在国内政治和社会问题上，差异可以在一定程度上归因于媒体偏见。

    

    普遍一致认为新闻媒体在其新闻文章中采用意识形态偏见。然而，在测量媒体机构之间的差异并进一步解剖语义差异的源头方面，先前的研究受到了样本大小的限制和范围的限制。在本研究中，我们收集了180万份美国主要媒体机构从2014年至2022年的新闻标题的大型数据集，以全面跟踪和解剖美国新闻媒体中的语义差异。我们采用多元对应分析(MCA)来量化与四个突出主题相关的语义差异 - 国内政治、经济问题、社会问题和外交事务。此外，我们比较媒体标题中最常见的n-gram，提供进一步的定性分析。我们的研究结果表明，在国内政治和社会问题上，差异可以在一定程度上归因于媒体偏见。与此同时，外交报道中的差异则更多地反映了多样性。

    There is a broad consensus that news media outlets incorporate ideological biases in their news articles. However, prior studies on measuring the discrepancies among media outlets and further dissecting the origins of semantic differences suffer from small sample sizes and limited scope. In this study, we collect a large dataset of 1.8 million news headlines from major U.S. media outlets spanning from 2014 to 2022 to thoroughly track and dissect the semantic discrepancy in U.S. news media. We employ multiple correspondence analysis (MCA) to quantify the semantic discrepancy relating to four prominent topics - domestic politics, economic issues, social issues, and foreign affairs. Additionally, we compare the most frequent n-grams in media headlines to provide further qualitative insights into our analysis. Our findings indicate that on domestic politics and social issues, the discrepancy can be attributed to a certain degree of media bias. Meanwhile, the discrepancy in reporting foreig
    
[^15]: 翻译歌曲之美：联合学习对齐旋律与翻译歌词

    Translate the Beauty in Songs: Jointly Learning to Align Melody and Translate Lyrics. (arXiv:2303.15705v1 [cs.CL])

    [http://arxiv.org/abs/2303.15705](http://arxiv.org/abs/2303.15705)

    本文提出了一种自适应分组歌词旋律翻译（LTAG）的综合解决方案，可以在翻译源歌词的同时确定每个解码步骤的对齐音符数量。

    

    歌曲翻译需要翻译歌词并对齐音符，以使结果可以演唱到相应的旋律上，这是一个具有挑战性的问题，在翻译过程的不同方面引起了一些兴趣。本文提出了一种自适应分组歌词旋律翻译（LTAG）的综合解决方案，它是一种新颖的编码器-解码器框架，可以同时翻译源歌词并通过自适应音符分组模块确定每个解码步骤的对齐音符数量。为了解决数据稀缺问题，我们委托少量的训练数据专门用于这个任务，并通过反向翻译使用大量的增强数据。实验结果表明，我们的模型在自动和人工评价中都具有有效性。

    Song translation requires both translation of lyrics and alignment of music notes so that the resulting verse can be sung to the accompanying melody, which is a challenging problem that has attracted some interests in different aspects of the translation process. In this paper, we propose Lyrics-Melody Translation with Adaptive Grouping (LTAG), a holistic solution to automatic song translation by jointly modeling lyrics translation and lyrics-melody alignment. It is a novel encoder-decoder framework that can simultaneously translate the source lyrics and determine the number of aligned notes at each decoding step through an adaptive note grouping module. To address data scarcity, we commissioned a small amount of training data annotated specifically for this task and used large amounts of augmented data through back-translation. Experiments conducted on an English-Chinese song translation data set show the effectiveness of our model in both automatic and human evaluation.
    
[^16]: 模型与评估：面向多语言文本分类的公平性研究

    Model and Evaluation: Towards Fairness in Multilingual Text Classification. (arXiv:2303.15697v1 [cs.CL])

    [http://arxiv.org/abs/2303.15697](http://arxiv.org/abs/2303.15697)

    本文提出了一种基于对比学习的多语言文本分类解偏模型，不依赖于外部语言资源，可以扩展到任何其他语言。该模型包含四个模块，可以有效降低文本分类中的偏见。

    

    最近，越来越多的研究关注于解决文本分类模型中的偏见问题。然而，现有的研究主要集中在单语言文本分类模型的公平性上，对于多语言文本分类的公平性研究仍然非常有限。本文关注于多语言文本分类任务，并提出了一种基于对比学习的解偏框架，旨在为多语言文本分类提供公平性。我们提出的方法不依赖于任何外部语言资源，可以扩展到任何其他语言。该模型包含四个模块：多语言文本表示模块，语言融合模块，文本解偏模块，和文本分类模块。多语言文本表示模块使用多语言预训练语言模型来表示文本，语言融合模块通过对比学习使不同语言的语义空间趋于一致，文本解偏模块使用共现统计量来重新加权文本表示，以减轻敏感属性的影响。我们在几个多语言文本分类基准上评估了我们提出的方法，并表明我们的模型可以在保持竞争性能的同时有效降低文本分类中的偏见。

    Recently, more and more research has focused on addressing bias in text classification models. However, existing research mainly focuses on the fairness of monolingual text classification models, and research on fairness for multilingual text classification is still very limited. In this paper, we focus on the task of multilingual text classification and propose a debiasing framework for multilingual text classification based on contrastive learning. Our proposed method does not rely on any external language resources and can be extended to any other languages. The model contains four modules: multilingual text representation module, language fusion module, text debiasing module, and text classification module. The multilingual text representation module uses a multilingual pre-trained language model to represent the text, the language fusion module makes the semantic spaces of different languages tend to be consistent through contrastive learning, and the text debiasing module uses co
    
[^17]: 面向知识图谱补全的Transformer预训练。

    Pre-training Transformers for Knowledge Graph Completion. (arXiv:2303.15682v1 [cs.CL])

    [http://arxiv.org/abs/2303.15682](http://arxiv.org/abs/2303.15682)

    该论文介绍了一种面向知识图谱补全的归纳式表示模型（iHT），通过大规模预训练，iHT表示可转移且在多个数据集上取得了最先进的结果。

    

    由于图结构的异构性和多关系性，学习知识图谱（KGs）的可转移表示是具有挑战性的。受Transformer基于预训练语言模型在学习文本方面的成功启发，我们引入了一种新型的面向KG补全的归纳式表示模型（iHT），通过大规模预训练，iHT由实体编码器（例如BERT）和邻居感知的关系评分函数组成，两者都由Transformer参数化。我们首先在大型KG数据集Wikidata5M上预训练iHT。我们的方法在匹配评估上实现了新的最先进结果，相对于先前SOTA模型，平均倒数排名提高了25％以上。当在具有实体和关系移位的较小KG上进一步微调时，预训练的iHT表示被证明是可转移的，显着提高了FB15K-237和WN18RR的性能。

    Learning transferable representation of knowledge graphs (KGs) is challenging due to the heterogeneous, multi-relational nature of graph structures. Inspired by Transformer-based pretrained language models' success on learning transferable representation for texts, we introduce a novel inductive KG representation model (iHT) for KG completion by large-scale pre-training. iHT consists of a entity encoder (e.g., BERT) and a neighbor-aware relational scoring function both parameterized by Transformers. We first pre-train iHT on a large KG dataset, Wikidata5M. Our approach achieves new state-of-the-art results on matched evaluations, with a relative improvement of more than 25% in mean reciprocal rank over previous SOTA models. When further fine-tuned on smaller KGs with either entity and relational shifts, pre-trained iHT representations are shown to be transferable, significantly improving the performance on FB15K-237 and WN18RR.
    
[^18]: ChatGPT4PCG比赛：科学鸟角色级生成

    ChatGPT4PCG Competition: Character-like Level Generation for Science Birds. (arXiv:2303.15662v1 [cs.AI])

    [http://arxiv.org/abs/2303.15662](http://arxiv.org/abs/2303.15662)

    本论文介绍了举办在2023 IEEE游戏会议上的第一届ChatGPT4PCG比赛，目标是让ChatGPT生成具有高稳定性和类似角色的特质来生成具有科学鸟角色级水平的关卡。

    

    本文介绍了2023年IEEE游戏会议上的第一届ChatGPT4PCG比赛。本次比赛的目标是让参赛者通过创造性和提示工程技能，为ChatGPT创建有效的提示，使其能够具有高稳定性和类似角色的特质来生成具有科学鸟角色级水平的关卡。为了降低参赛门槛，我们将任务限制在生成大写英文字母。参赛作品的质量由其稳定性和与给定字符的相似性决定。给参赛者提供了一个样例提示供参考。

    This paper presents the first ChatGPT4PCG Competition at the 2023 IEEE Conference on Games. The objective of this competition is for participants to create effective prompts for ChatGPT--enabling it to generate Science Birds levels with high stability and character-like qualities--fully using their creativity as well as prompt engineering skills. ChatGPT is a conversational agent developed by OpenAI. Science Birds is selected as the competition platform because designing an Angry Birds-like level is not a trivial task due to the in-game gravity; the playability of the levels is determined by their stability. To lower the entry barrier to the competition, we limit the task to the generation of capitalized English alphabetical characters. Here, the quality of the generated levels is determined by their stability and similarity to the given characters. A sample prompt is provided to participants for their reference. An experiment is conducted to determine the effectiveness of its modified
    
[^19]: 基于分层距离和语义表示学习的联合嵌入用于链接预测

    Joint embedding in Hierarchical distance and semantic representation learning for link prediction. (arXiv:2303.15655v1 [cs.CL])

    [http://arxiv.org/abs/2303.15655](http://arxiv.org/abs/2303.15655)

    本文提出了一种名为HIE的知识图谱嵌入模型，它将每个三元组同时建模为距离测量空间和语义测量空间，并在分层感知空间中利用实体和关系的丰富分层信息以获得更好的表示学习效果。

    

    链接预测任务旨在预测知识图谱中缺失的实体或关系，并且是下游应用程序的关键。现有的著名模型主要通过将知识图谱三元组表示为距离空间或语义空间来处理此任务。然而，它们不能充分捕捉头尾实体的信息，甚至不能很好地利用分层级别信息。因此，在本文中，我们提出了一个新的知识图谱嵌入模型，用于链接预测任务，即HIE，它同时将每个三元组（h，r，t）建模为距离测量空间和语义测量空间。此外，将HIE引入分层感知空间，以利用实体和关系的丰富分层信息，以获得更好的表示学习效果。具体而言，在距离空间中对头实体应用距离变换操作以获取尾实体，而不是基于平移的模型。

    The link prediction task aims to predict missing entities or relations in the knowledge graph and is essential for the downstream application. Existing well-known models deal with this task by mainly focusing on representing knowledge graph triplets in the distance space or semantic space. However, they can not fully capture the information of head and tail entities, nor even make good use of hierarchical level information. Thus, in this paper, we propose a novel knowledge graph embedding model for the link prediction task, namely, HIE, which models each triplet (\textit{h}, \textit{r}, \textit{t}) into distance measurement space and semantic measurement space, simultaneously. Moreover, HIE is introduced into hierarchical-aware space to leverage rich hierarchical information of entities and relations for better representation learning. Specifically, we apply distance transformation operation on the head entity in distance space to obtain the tail entity instead of translation-based or 
    
[^20]: 缩小规模以实现超大语言模型的参数有效微调指南

    Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning. (arXiv:2303.15647v1 [cs.CL])

    [http://arxiv.org/abs/2303.15647](http://arxiv.org/abs/2303.15647)

    本文综述了40多种缩小模型规模进行超大模型参数微调的方法，旨在解决大型语言模型训练的不可行性和不切实际性。提供了分类法和方法比较，并重点关注实际效率和千亿级语言模型微调。

    

    本文提供了一份系统化的综述和比较，覆盖了2019年2月至2023年2月期间发布的40多篇参数有效微调方法的论文。这些方法旨在通过仅训练小部分参数来解决微调大型语言模型的不可行和不切实际性。我们提供了一个分类法，涵盖了广泛的方法，并对实现效率和微调千亿级语言模型进行了详细的方法比较。

    This paper presents a systematic overview and comparison of parameter-efficient fine-tuning methods covering over 40 papers published between February 2019 and February 2023. These methods aim to resolve the infeasibility and impracticality of fine-tuning large language models by only training a small set of parameters. We provide a taxonomy that covers a broad range of methods and present a detailed method comparison with a specific focus on real-life efficiency and fine-tuning multibillion-scale language models.
    
[^21]: ChatGPT作为抽象文本摘要中事实不一致性评估器

    ChatGPT as a Factual Inconsistency Evaluator for Abstractive Text Summarization. (arXiv:2303.15621v1 [cs.CL])

    [http://arxiv.org/abs/2303.15621](http://arxiv.org/abs/2303.15621)

    本文研究了ChatGPT作为抽象文本摘要中事实不一致性评估器的能力，证明其在不需要注释数据和高计算复杂度的情况下，在粗粒度和细粒度的任务中表现出了最先进的性能。

    

    最近，预训练语言模型大大提高了抽象文本摘要的性能。现有的抽象摘要方法的主要问题是其生成的摘要存在的事实不一致性问题。为缓解这个问题，许多努力将重点放在开发基于自然语言推理和问答等方面的有效事实性评估指标上。然而，它们存在计算复杂度高和依赖注释数据的限制。最近，像ChatGPT这样的大型语言模型不仅显示了强大的自然语言理解能力，而且还在自然语言推理方面表现出众。在本文中，我们通过在粗粒度和细粒度的事实评估任务（包括二进制自然语言推理（NLI）、摘要排名和一致性评级）上评估ChatGPT的零-shot设置下的事实不一致性评估能力。实验结果表明，ChatGPT在所有评估任务上均表现出了最先进的性能。

    The performance of abstractive text summarization has been greatly boosted by pre-trained language models recently. The main concern of existing abstractive summarization methods is the factual inconsistency problem of their generated summary. To alleviate the problem, many efforts have focused on developing effective factuality evaluation metrics based on natural language inference and question answering et al. However, they have limitations of high computational complexity and relying on annotated data. Most recently, large language models such as ChatGPT have shown strong ability in not only natural language understanding but also natural language inference. In this paper, we study the factual inconsistency evaluation ability of ChatGPT under the zero-shot setting by evaluating it on the coarse-grained and fine-grained factuality evaluation tasks including binary natural language inference (NLI), summary ranking, and consistency rating. Experimental results show that ChatGPT outperf
    
[^22]: 台风：针对预训练语言模型的有效特定任务屏蔽策略

    Typhoon: Towards an Effective Task-Specific Masking Strategy for Pre-trained Language Models. (arXiv:2303.15619v1 [cs.CL])

    [http://arxiv.org/abs/2303.15619](http://arxiv.org/abs/2303.15619)

    本文探讨了一种针对预训练语言模型的任务特定的屏蔽框架，称为Typhoon，可在GLUE基准数据集上实现卓越的下游任务性能，尤其在MRPC数据集上表现优异。

    

    通过利用图形处理单元所能提供的高度并行性，变压器架构使自然语言处理领域取得了巨大的进展。在传统的屏蔽语言模型中，使用特殊的MASK标记来提示模型从周围单词中收集情境信息以恢复原本隐藏的信息。在本文中，我们探讨了一种预训练大型语言模型的任务特定的屏蔽框架，以在GLUE基准数据集上实现卓越的下游任务性能。我们基于记号输入梯度开发了自己的屏蔽算法Typhoon，并将其与其他标准基线进行比较。我们发现，Typhoon在MRPC数据集上的性能与整体字屏蔽相当。我们的实现可以在公共Github库中找到。

    Through exploiting a high level of parallelism enabled by graphics processing units, transformer architectures have enabled tremendous strides forward in the field of natural language processing. In a traditional masked language model, special MASK tokens are used to prompt our model to gather contextual information from surrounding words to restore originally hidden information. In this paper, we explore a task-specific masking framework for pre-trained large language models that enables superior performance on particular downstream tasks on the datasets in the GLUE benchmark. We develop our own masking algorithm, Typhoon, based on token input gradients, and compare this with other standard baselines. We find that Typhoon offers performance competitive with whole-word masking on the MRPC dataset. Our implementation can be found in a public Github Repository.
    
[^23]: 提升日中机器翻译的语言学 ChatGPT 智能提示：以定语从句为例的研究

    Linguistically Informed ChatGPT Prompts to Enhance Japanese-Chinese Machine Translation: A Case Study on Attributive Clauses. (arXiv:2303.15587v1 [cs.CL])

    [http://arxiv.org/abs/2303.15587](http://arxiv.org/abs/2303.15587)

    提升日中机器翻译准确性的新方法：使用结合预编辑方案和 ChatGPT 的两步提示策略，平均翻译准确性得分提高超过35％。

    

    在日中翻译语言学领域中，正确翻译定语从句一直是具有挑战性的问题。目前的机器翻译工具经常无法准确地将日语的定语从句翻译为中文，本文从语言学角度探讨了产生这种困难的语言问题，即受修饰名词的语义角色如何影响定语从句的翻译模式选择。为解决这些困难，本文提出了一种预编辑方案，旨在提高翻译准确性。此外，我们提出了一种新的两步提示策略，将这种预编辑方案与 ChatGPT 相结合，ChatGPT 是目前最广泛使用的大语言模型。该提示策略能够在零-shot场景下优化翻译输入，并已经证明可以将平均翻译准确性得分提高超过35％。

    In the field of Japanese-Chinese translation linguistics, the issue of correctly translating attributive clauses has persistently proven to be challenging. Present-day machine translation tools often fail to accurately translate attributive clauses from Japanese to Chinese. In light of this, this paper investigates the linguistic problem underlying such difficulties, namely how does the semantic role of the modified noun affect the selection of translation patterns for attributive clauses, from a linguistic perspective. To ad-dress these difficulties, a pre-edit scheme is proposed, which aims to enhance the accuracy of translation. Furthermore, we propose a novel two-step prompt strategy, which combines this pre-edit scheme with ChatGPT, currently the most widely used large language model. This prompt strategy is capable of optimizing translation input in zero-shot scenarios and has been demonstrated to improve the average translation accuracy score by over 35%.
    
[^24]: 大语言模型是摘要评估的不同角色扮演者

    Large Language Models are Diverse Role-Players for Summarization Evaluation. (arXiv:2303.15078v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.15078](http://arxiv.org/abs/2303.15078)

    本文提出了一种新的基于LLMs的评估框架，通过比较生成的文本和参考文本的客观和主观维度，提供了全面的评估框架。

    

    文本摘要在许多场景中具有广泛的应用。生成文本的质量评估是一个复杂的问题。语言评估的一个大挑战是现有指标和人工评估之间存在明显的分歧。例如，文档摘要的质量可以通过人工注释者从客观方面（如语法和语义的正确性）以及主观维度（如全面性、简洁性和有趣性）进行评估。大多数自动评估方法（如BLUE/ROUGE）可能无法很好地捕捉以上维度。在本文中，我们提出了一个基于LLMs的新的评估框架，通过比较从客观和主观方面生成的文本和参考文本，提供了全面的评估框架。首先，我们提出了基于角色扮演者提示机制的生成的文本的客观和主观维度的建模。此外，我们还引入了一个上下文。。

    Text summarization has a wide range of applications in many scenarios. The evaluation of the quality of the generated text is a complex problem. A big challenge to language evaluation is that there is a clear divergence between existing metrics and human evaluation. For example, the quality of a document summary can be measured by human annotators from both objective aspects, such as grammatical and semantic correctness, as well as subjective dimensions, such as comprehensiveness, succinctness, and interestingness. Most of the automatic evaluation methods like BLUE/ROUGE may be not able to capture the above dimensions well. In this paper, we propose a new evaluation framework based on LLMs, which provides a comprehensive evaluation framework by comparing generated text and reference text from both objective and subjective aspects. First, we propose to model objective and subjective dimensions of generated text based on roleplayers prompting mechanism. Furthermore, we introduce a contex
    
[^25]: SmartBook：AI辅助的情报报告生成

    SmartBook: AI-Assisted Situation Report Generation. (arXiv:2303.14337v1 [cs.CL])

    [http://arxiv.org/abs/2303.14337](http://arxiv.org/abs/2303.14337)

    SmartBook是一种AI辅助的情报报告生成工具，通过消耗大量新闻数据生成一个结构化的情况报告，其中包含多个假设（主张），并与事实依据建立丰富的关联。在Ukraine-Russia危机中，机器生成的报告以时间轴的形式结构化，显著减少了报告时间，并通过生成比人类同行更全面、准确和一致的报告来提高报告质量。

    

    新兴事件，如COVID疫情和乌克兰危机，需要时间敏感的全面了解情况，以便进行适当的决策和有效的行动响应。自动生成情报报告可以大大减少领域专家准备官方人工策划报告的时间、精力和成本。然而，AI研究在这个目标方面非常有限，还没有成功的试验来自动化这种报告生成。我们提出了SmartBook，一种新颖的任务分解，旨在生成情况报告，在大量新闻数据的基础上生成一个结构化的情况报告，其中包含多个假设（主张），并与事实依据建立丰富的关联。我们通过自动生成情报分析报告来实现SmartBook，以协助专家分析师处理乌克兰-俄罗斯危机。机器生成的报告以时间轴的形式结构化，每个事件都与相关的演员、位置和因果关系相关联。我们的评估显示，SmartBook可以显著减少报告时间，并通过生成比人类同行更全面、准确和一致的报告来提高报告质量。

    Emerging events, such as the COVID pandemic and the Ukraine Crisis, require a time-sensitive comprehensive understanding of the situation to allow for appropriate decision-making and effective action response. Automated generation of situation reports can significantly reduce the time, effort, and cost for domain experts when preparing their official human-curated reports. However, AI research toward this goal has been very limited, and no successful trials have yet been conducted to automate such report generation. We propose SmartBook, a novel task formulation targeting situation report generation, which consumes large volumes of news data to produce a structured situation report with multiple hypotheses (claims) summarized and grounded with rich links to factual evidence. We realize SmartBook for the Ukraine-Russia crisis by automatically generating intelligence analysis reports to assist expert analysts. The machine-generated reports are structured in the form of timelines, with ea
    
[^26]: ChatDoctor：使用医学领域知识在LLaMA模型上微调的医疗聊天模型

    ChatDoctor: A Medical Chat Model Fine-tuned on LLaMA Model using Medical Domain Knowledge. (arXiv:2303.14070v1 [cs.CL])

    [http://arxiv.org/abs/2303.14070](http://arxiv.org/abs/2303.14070)

    本文介绍了一种在医学领域利用LLaMA模型微调的医疗聊天模型ChatDoctor。经过700多种疾病和其相应症状、药品和医疗检查的收集和处理，这种模型具有理解患者需求、提供建议和帮助的潜力。这些先进的语言模型集成到医疗保健中可以极大地改进医疗专业人员和患者的沟通方式。

    

    最近，在一般领域中应用的大型语言模型（LLM），例如ChatGPT，已经表现出仿佛是人类讲话般的成功。然而，这样的语言模型并没有经过个别且仔细为医学领域学习，导致诊断准确度低且不能给出正确的医疗诊断、药品等建议。为了解决这个问题，我们收集了700多种疾病及其相应症状、推荐药品和所需医疗检查，然后生成了5K名医患的对话。通过微调医患对话模型，这些模型具有了理解患者需求、提供明智建议并在各种医疗相关领域提供宝贵帮助的巨大潜力。将这些先进的语言模型集成到医疗保健中，可以彻底改变医疗专业人员和患者的沟通方式，最终改善整体质量。

    Recent large language models (LLMs) in the general domain, such as ChatGPT, have shown remarkable success in following instructions and producing human-like responses. However, such language models have not been learned individually and carefully for the medical domain, resulting in poor diagnostic accuracy and inability to give correct recommendations for medical diagnosis, medications, etc. To address this issue, we collected more than 700 diseases and their corresponding symptoms, recommended medications, and required medical tests, and then generated 5K doctor-patient conversations. By fine-tuning models of doctor-patient conversations, these models emerge with great potential to understand patients' needs, provide informed advice, and offer valuable assistance in a variety of medical-related fields. The integration of these advanced language models into healthcare can revolutionize the way healthcare professionals and patients communicate, ultimately improving the overall quality 
    
[^27]: DBLP-QuAD：DBLP学术知识图上的问答数据集

    DBLP-QuAD: A Question Answering Dataset over the DBLP Scholarly Knowledge Graph. (arXiv:2303.13351v1 [cs.DL])

    [http://arxiv.org/abs/2303.13351](http://arxiv.org/abs/2303.13351)

    这篇论文在DBLP学术知识图上创建了一个包含10000个问题-答案对的问答数据集，是最大的学术问答数据集。

    

    本文在DBLP学术知识图上创建了一个问答数据集。DBLP是一个在线计算机科学主要出版物的参考文献信息索引，索引了超过440万篇论文，由220万多位作者发表。我们的数据集包含了10000个问题-答案对以及相应的SPARQL查询，可以在DBLP KG上执行以获得正确的答案。DBLP-QuAD是最大的学术问答数据集。

    In this work we create a question answering dataset over the DBLP scholarly knowledge graph (KG). DBLP is an on-line reference for bibliographic information on major computer science publications that indexes over 4.4 million publications published by more than 2.2 million authors. Our dataset consists of 10,000 question answer pairs with the corresponding SPARQL queries which can be executed over the DBLP KG to fetch the correct answer. DBLP-QuAD is the largest scholarly question answering dataset.
    
[^28]: GETT-QA：基于图嵌入的知识图谱问答中的T2T Transformer

    GETT-QA: Graph Embedding based T2T Transformer for Knowledge Graph Question Answering. (arXiv:2303.13284v1 [cs.CL])

    [http://arxiv.org/abs/2303.13284](http://arxiv.org/abs/2303.13284)

    本论文提出了GETT-QA系统，该系统使用T5对自然语言问题生成简化的SPARQL查询，并使用截断的KG嵌入提高了知识图谱问答的性能。

    

    本文提出了一个名为GETT-QA的端到端知识图谱问答系统。GETT-QA使用了T5，这是一种热门的文本到文本预训练语言模型。该模型以自然语言形式的问题作为输入并生成所需SPARQL查询的简化形式。在简化形式中，模型不直接生成实体和关系ID，而是产生相应的实体和关系标签。标签在随后的步骤中与KG实体和关系ID联系起来。为了进一步改进结果，我们指导模型为每个实体生成KG嵌入的截断版本。截断的KG嵌入使得更精细的搜索从而更有效进行消歧。我们发现，T5能够在不改变损失函数的情况下学习截断的KG嵌入，提高了KGQA的性能。因此，我们在Wikidata的LC-QuAD 2.0和SimpleQuestions-Wikidata数据集上报告了端到端KGQA的强大结果。

    In this work, we present an end-to-end Knowledge Graph Question Answering (KGQA) system named GETT-QA. GETT-QA uses T5, a popular text-to-text pre-trained language model. The model takes a question in natural language as input and produces a simpler form of the intended SPARQL query. In the simpler form, the model does not directly produce entity and relation IDs. Instead, it produces corresponding entity and relation labels. The labels are grounded to KG entity and relation IDs in a subsequent step. To further improve the results, we instruct the model to produce a truncated version of the KG embedding for each entity. The truncated KG embedding enables a finer search for disambiguation purposes. We find that T5 is able to learn the truncated KG embeddings without any change of loss function, improving KGQA performance. As a result, we report strong results for LC-QuAD 2.0 and SimpleQuestions-Wikidata datasets on end-to-end KGQA over Wikidata.
    
[^29]: 具有元梯度正则化的自监督元提示学习用于少样本泛化

    Self-supervised Meta-Prompt Learning with Meta-Gradient Regularization for Few-shot Generalization. (arXiv:2303.12314v1 [cs.CL])

    [http://arxiv.org/abs/2303.12314](http://arxiv.org/abs/2303.12314)

    提出了一种自我监督元提示学习框架SUPMER，包括元梯度正则化，用于少样本泛化，通过锚定的元训练任务和基于课程的任务增强丰富了任务分布，解决了在少样本情况下良好初始化软提示和过拟合的问题。

    

    提示调整是一种参数有效的方法，它学习软提示并使冻结的语言模型执行特定的下游任务。尽管有效，但提示调整在少样本情况下一方面严重依赖于良好的软提示初始化。另一方面，它很容易导致过度拟合。现有的方法利用预训练或监督元学习来初始化软提示，但它们不能对未见下游任务进行数据有效的泛化。为了解决以上问题，本文提出了一种新的自我监督元提示学习框架，其中包括元梯度正则化，用于少样本泛化（SUPMER）。我们首先设计了一组自监督锚定的元训练任务，具有不同的任务格式，并通过基于课程的任务增强进一步丰富了任务分布。然后将一种新的元梯度正则化方法集成到元提示学习中。它元学习在少样本情况下如何转换原始梯度。

    Prompt tuning is a parameter-efficient method, which learns soft prompts and conditions frozen language models to perform specific downstream tasks. Though effective, prompt tuning under few-shot settings on the one hand heavily relies on a good initialization of soft prompts. On the other hand, it can easily result in overfitting. Existing works leverage pre-training or supervised meta-learning to initialize soft prompts but they cannot data-efficiently generalize to unseen downstream tasks. To address the above problems, this paper proposes a novel Self-sUpervised meta-Prompt learning framework with meta-gradient Regularization for few-shot generalization (SUPMER). We first design a set of self-supervised anchor meta-training tasks with different task formats and further enrich the task distribution with curriculum-based task augmentation. Then a novel meta-gradient regularization method is integrated into meta-prompt learning. It meta-learns to transform the raw gradients during few
    
[^30]: 多语言方言检测的两阶段流水线

    Two-stage Pipeline for Multilingual Dialect Detection. (arXiv:2303.03487v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.03487](http://arxiv.org/abs/2303.03487)

    本篇论文提出了一种两阶段的方言识别系统，在VarDial 2023中超越其他参与者的系统，对多语言方言检测有重要贡献。

    

    方言识别对于本地化各种大型语言模型至关重要。本文概述了我们在VarDial 2023共享任务中的方法。我们必须从三种语言中识别出三个或两个方言，这导致了Track-1的9路分类和Track-2的6路分类。我们提出的方法包括两个阶段的系统，在这个领域中超越了其他参与者的系统和以前的工作。我们在Track-1和Track-2上分别获得58.54％和85.61％的得分。我们的代码库是公开的（https://github.com/ankit-vaidya19/EACL_VarDial2023）。

    Dialect Identification is a crucial task for localizing various Large Language Models. This paper outlines our approach to the VarDial 2023 shared task. Here we have to identify three or two dialects from three languages each which results in a 9-way classification for Track-1 and 6-way classification for Track-2 respectively. Our proposed approach consists of a two-stage system and outperforms other participants' systems and previous works in this domain. We achieve a score of 58.54% for Track-1 and 85.61% for Track-2. Our codebase is available publicly (https://github.com/ankit-vaidya19/EACL_VarDial2023).
    
[^31]: EvoPrompting: 适用于代码级神经架构搜索的语言模型

    EvoPrompting: Language Models for Code-Level Neural Architecture Search. (arXiv:2302.14838v1 [cs.NE] CROSS LISTED)

    [http://arxiv.org/abs/2302.14838](http://arxiv.org/abs/2302.14838)

    EvoPrompting利用语言模型作为自适应变异和交叉操作符来进行神经架构搜索，在MNIST-1D数据集和CLRS算法推理基准上都取得了比人类设计的架构更好的性能表现。

    

    鉴于语言模型（LM）在代码生成方面的最新成就，我们探索将LM作为进化神经架构搜索（NAS）算法的自适应变异和交叉操作符的使用。尽管NAS仍然过于困难，以至于仅仅通过提示就难以成功，但我们发现进化提示工程与软提示调整的组合，一种我们称之为EvoPrompting的方法，始终可以发现多样化且性能高的模型。我们首先证明EvoPrompting在MNIST-1D数据集上是有效的，其中EvoPrompting产生的卷积架构变体在准确率和模型大小方面均优于人类专家设计的架构和天真的少数先导提示。然后，我们将我们的方法应用于在CLRS算法推理基准上搜索图神经网络，其中EvoPrompting能够设计出比当前最先进的模型更好的新颖结构。

    Given the recent impressive accomplishments of language models (LMs) for code generation, we explore the use of LMs as adaptive mutation and crossover operators for an evolutionary neural architecture search (NAS) algorithm. While NAS still proves too difficult a task for LMs to succeed at solely through prompting, we find that the combination of evolutionary prompt engineering with soft prompt-tuning, a method we term EvoPrompting, consistently finds diverse and high performing models. We first demonstrate that EvoPrompting is effective on the computationally efficient MNIST-1D dataset, where EvoPrompting produces convolutional architecture variants that outperform both those designed by human experts and naive few-shot prompting in terms of accuracy and model size. We then apply our method to searching for graph neural networks on the CLRS Algorithmic Reasoning Benchmark, where EvoPrompting is able to design novel architectures that outperform current state-of-the-art models on 21 ou
    
[^32]: AdapterSoup：使用加权平均改善预训练语言模型的泛化能力

    AdapterSoup: Weight Averaging to Improve Generalization of Pretrained Language Models. (arXiv:2302.07027v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.07027](http://arxiv.org/abs/2302.07027)

    本文提出了AdapterSoup，一种使用加权平均改善预训练语言模型泛化能力的方法。该方法在不同领域训练的适配器上执行权重空间平均，可以在不需要额外训练的情况下提高对新领域的性能。

    AdapterSoup is a method that uses weight averaging to improve the generalization ability of pretrained language models. It performs weight-space averaging of adapters trained on different domains, and can improve performance to new domains without extra training.

    预训练语言模型（PLMs）在大规模语料库上进行训练，但通常需要专门针对特定领域进行特化。一种参数有效的适应方法建议在语言建模任务上为每个领域训练一个适配器。这导致了良好的领域内得分，但在领域或资源受限的情况下可能不切实际。解决方案是在测试时使用相关领域适配器来处理新领域。在本文中，我们介绍了AdapterSoup，一种在不同领域训练的适配器上执行权重空间平均的方法。我们的方法是令人尴尬的并行的：首先，我们训练一组特定领域的适配器；然后，对于每个新领域，我们确定在测试时应平均哪些适配器。我们进行了大量实验，表明AdapterSoup始终提高了对新领域的性能，而无需额外的训练。我们还探讨了在不同超参数下训练的相同领域适配器的权重平均，并表明它可以保留

    Pretrained language models (PLMs) are trained on massive corpora, but often need to specialize to specific domains. A parameter-efficient adaptation method suggests training an adapter for each domain on the task of language modeling. This leads to good in-domain scores but can be impractical for domain- or resource-restricted settings. A solution is to use a related-domain adapter for the novel domain at test time. In this paper, we introduce AdapterSoup, an approach that performs weight-space averaging of adapters trained on different domains. Our approach is embarrassingly parallel: first, we train a set of domain-specific adapters; then, for each novel domain, we determine which adapters should be averaged at test time. We present extensive experiments showing that AdapterSoup consistently improves performance to new domains without extra training. We also explore weight averaging of adapters trained on the same domain with different hyper-parameters, and show that it preserves the
    
[^33]: 语义编码的KNN用于评分预测

    KNNs of Semantic Encodings for Rating Prediction. (arXiv:2302.00412v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.00412](http://arxiv.org/abs/2302.00412)

    本文提出了一种通过文本语义相似性预测用户评分的方法，并且在评估中表现出优异的性能。

    

    本文探讨了一种文本语义相似性在用户评分预测中的创新应用。该方法表示用户偏好为来自评论文本的文本片段的图形，其中边缘根据语义相似度定义。这种基于文本的记忆方法可以为推荐提供基于评论的解释。方法经过量化评估，突出了以这种方式利用文本优于强记忆和模型合作过滤基线。

    This paper explores a novel application of textual semantic similarity to user-preference representation for rating prediction. The approach represents a user's preferences as a graph of textual snippets from review text, where the edges are defined by semantic similarity. This textual, memory-based approach to rating prediction enables review-based explanations for recommendations. The method is evaluated quantitatively, highlighting that leveraging text in this way outperforms both strong memory-based and model-based collaborative filtering baselines.
    
[^34]: 神经对话辅导中的机遇与挑战

    Opportunities and Challenges in Neural Dialog Tutoring. (arXiv:2301.09919v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.09919](http://arxiv.org/abs/2301.09919)

    本文研究了神经对话辅导存在的机遇和挑战，发现当前方法在少量概念和可能的教师策略的情况下可以进行较好的辅导模拟与学习，但在不受限制的情况下表现不佳，未来应该集中在解决这些问题上。

    

    设计对话辅导系统一直是一项具有挑战性的工作，因为它涉及到对人类辅导者所采用的多样且复杂的教学策略进行建模。尽管在大型语言模型 (LLMs) 和可用的对话语料库方面出现了显著的进展，但对话辅导在很大程度上仍未受到这些进展的影响。本文在两个语言学习对话辅导数据集上对各种生成式语言模型进行了严格分析，使用自动和人工评估来了解这些进展带来的新机会以及我们必须克服的挑战，以构建能在真实教育环境中使用的模型。我们发现，尽管当前方法可以对少量概念和可能的教师策略进行较好的辅导模拟与学习，但在不受限制的情况下表现不佳。我们的人工质量评估显示，模型和基础教学系统在这些不受限制的情况下都具有较低的有效性，这表明未来的研究应该集中在解决这些问题上。

    Designing dialog tutors has been challenging as it involves modeling the diverse and complex pedagogical strategies employed by human tutors. Although there have been significant recent advances in neural conversational systems using large language models (LLMs) and growth in available dialog corpora, dialog tutoring has largely remained unaffected by these advances. In this paper, we rigorously analyze various generative language models on two dialog tutoring datasets for language learning using automatic and human evaluations to understand the new opportunities brought by these advances as well as the challenges we must overcome to build models that would be usable in real educational settings. We find that although current approaches can model tutoring in constrained learning scenarios when the number of concepts to be taught and possible teacher strategies are small, they perform poorly in less constrained scenarios. Our human quality evaluation shows that both models and ground-tr
    
[^35]: TextDescriptives：一个用于从文本中计算多种指标的Python包

    TextDescriptives: A Python package for calculating a large variety of metrics from text. (arXiv:2301.02057v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.02057](http://arxiv.org/abs/2301.02057)

    TextDescriptives是一个Python包，可用于从文本中计算多种指标，已被用于分析临床文本的语言稳定性、预测神经精神疾病的特征以及分析小学生成语言目标。

    

    TextDescriptives是一个Python包，用于计算从文本中获取的多种度量标准。它建立在spaCy之上，并可以轻松集成到现有工作流程中。该包已被用于分析临床文本的语言稳定性，创建用于预测神经精神疾病的特征以及分析小学生语言目标。本文描述了该包及其特点。

    TextDescriptives is a Python package for calculating a large variety of metrics from text. It is built on top of spaCy and can be easily integrated into existing workflows. The package has already been used for analysing the linguistic stability of clinical texts, creating features for predicting neuropsychiatric conditions, and analysing linguistic goals of primary school students. This paper describes the package and its features.
    
[^36]: InferEM: 推断说话者意图的共情对话生成模型

    InferEM: Inferring the Speaker's Intention for Empathetic Dialogue Generation. (arXiv:2212.06373v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.06373](http://arxiv.org/abs/2212.06373)

    通过推断对话中最后一次发言来捕捉说话者的意图，提出了一种利用多头注意力的意图融合模块的共情对话生成模型InferEM。模型同时利用前几次发言预测最后一次发言，具有较高的可行性。

    

    目前，共情回复生成的方法一般直接编码整个对话历史，然后通过解码器生成友好的反馈。这些方法强调建模情境信息，但忽视了捕捉说话者的直接意图。我们认为对话中最后一次发言表达了说话者的意图。因此，我们提出了一种名为InferEM的新模型用于共情回复生成。我们将最后一次发言单独编码，通过基于多头注意力的意图融合模块与整个对话融合以捕捉说话者的意图。此外，我们利用前几次发言预测最后一次发言，以模拟人类的心理，猜测对话者可能提前说些什么。为平衡发言预测和回复生成的优化速率，InferEM还设计了一种多任务学习策略。实验结果证明了该模型的可行性。

    Current approaches to empathetic response generation typically encode the entire dialogue history directly and put the output into a decoder to generate friendly feedback. These methods focus on modelling contextual information but neglect capturing the direct intention of the speaker. We argue that the last utterance in the dialogue empirically conveys the intention of the speaker. Consequently, we propose a novel model named InferEM for empathetic response generation. We separately encode the last utterance and fuse it with the entire dialogue through the multi-head attention based intention fusion module to capture the speaker's intention. Besides, we utilize previous utterances to predict the last utterance, which simulates human's psychology to guess what the interlocutor may speak in advance. To balance the optimizing rates of the utterance prediction and response generation, a multi-task learning strategy is designed for InferEM. Experimental results demonstrate the plausibility
    
[^37]: PromptCap：使用GPT-3的提示引导图像字幕生成进行视觉问答

    PromptCap: Prompt-Guided Image Captioning for VQA with GPT-3. (arXiv:2211.09699v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.09699](http://arxiv.org/abs/2211.09699)

    提出了PromptCap，一种使用提示引导的图像字幕生成模型，用于解决基于知识的视觉问答中通用图像字幕无法准确描述视觉实体的问题。

    

    基于知识的视觉问答涉及需要超越图片以产生正确答案的世界知识的问题。像GPT-3这样的大型语言模型特别适用于此任务，因为它们具有强大的知识检索和推理能力。为了使LM理解图像，先前的工作使用字幕模型将图像转换为文本。然而，在单个字幕句子中总结图像时，要描述哪些视觉实体经常不明确。通用图像字幕经常错过LM回答视觉问题所必需的视觉细节。为了解决这一挑战，我们提出了PromptCap（Prompt-guided image Captioning），一种字幕模型，旨在成为图像和黑盒LM之间更好的连接器。与通用字幕不同，PromptCap采用自然语言提示来控制生成的字幕中要描述的视觉实体。提示包含字幕应回答的问题。

    Knowledge-based visual question answering (VQA) involves questions that require world knowledge beyond the image to yield the correct answer. Large language models (LMs) like GPT-3 are particularly helpful for this task because of their strong knowledge retrieval and reasoning capabilities. To enable LM to understand images, prior work uses a captioning model to convert images into text. However, when summarizing an image in a single caption sentence, which visual entities to describe are often underspecified. Generic image captions often miss visual details essential for the LM to answer visual questions correctly. To address this challenge, we propose PromptCap (Prompt-guided image Captioning), a captioning model designed to serve as a better connector between images and black-box LMs. Different from generic captions, PromptCap takes a natural-language prompt to control the visual entities to describe in the generated caption. The prompt contains a question that the caption should ai
    
[^38]: SilverAlign：用机器翻译生成银标准数据进行单词对齐评估的算法

    SilverAlign: MT-Based Silver Data Algorithm For Evaluating Word Alignment. (arXiv:2210.06207v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.06207](http://arxiv.org/abs/2210.06207)

    本文提出SilverAlign算法，将机器翻译和最小对用于生成银标准数据以评估单词对齐器，解决了低资源语言缺失金标准数据对齐的重要场景问题。

    

    单词对齐在各种自然语言处理任务中非常重要。因此，选择最佳方法以创建单词对齐非常关键。然而，由于金标准数据的稀缺性，这种选择变得困难。我们提出了SilverAlign方法，通过利用机器翻译和最小对生成银标准数据，从而自动创建用于评估单词对齐器的数据。我们展示了在我们的银标准数据上的性能与9种语言对的金标准基准相关性高，使我们的方法成为在金标准数据不可用情况下评估不同领域和语言的有效资源。这解决了低资源语言缺失金标准数据对齐的重要场景问题。

    Word alignments are essential for a variety of NLP tasks. Therefore, choosing the best approaches for their creation is crucial. However, the scarce availability of gold evaluation data makes the choice difficult. We propose SilverAlign, a new method to automatically create silver data for the evaluation of word aligners by exploiting machine translation and minimal pairs. We show that performance on our silver data correlates well with gold benchmarks for 9 language pairs, making our approach a valid resource for evaluation of different domains and languages when gold data are not available. This addresses the important scenario of missing gold data alignments for low-resource languages.
    
[^39]: 基于注意力机制和子词分割的混合语言仇恨言论检测方法

    AtteSTNet -- An attention and subword tokenization based approach for code-switched text hate speech detection. (arXiv:2112.11479v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2112.11479](http://arxiv.org/abs/2112.11479)

    AtteSTNet是一种基于注意力机制和子词分割的检测混合语言仇恨言论的方法，它不仅与复杂网络相当，而且在各种数据集上性能更好，其极大的简单性和易于维护性是其优点。

    

    技术的最新进展导致社交媒体的使用量增加，也导致大量用户生成的数据，其中包括令人讨厌和冒犯的言论。社交媒体上使用的语言通常是英语和育地方语言的组合。在印度，印地语是主要使用的语言，并经常与英语切换，形成印地英语（Hinglish）语言。过去已经采用了不同的机器学习和深度学习技术来对混合时的印地英语仇恨言论进行分类。然而，这些技术使用的循环或卷积机制计算成本高，内存需求大。过去的技术还使用复杂的数据处理方法，使现有技术非常复杂且难以改变数据。提出了一种更简单的方法，不仅与这些复杂网络一样，并且在如HASOC（印欧语言的仇恨言论和冒犯内容识别）此类混合印地英语文本的数据集上超过了性能基准。所提出的方法名为AtteSTNet，它利用注意力机制和子词分割来识别混合语言中的仇恨言论。所提出的方法比以前的技术表现更好，更简单易于维护。

    Recent advancements in technology have led to a boost in social media usage which has ultimately led to large amounts of user-generated data which also includes hateful and offensive speech. The language used in social media is often a combination of English and the native language in the region. In India, Hindi is used predominantly and is often code-switched with English, giving rise to the Hinglish (Hindi+English) language. Various approaches have been made in the past to classify the code-mixed Hinglish hate speech using different machine learning and deep learning-based techniques. However, these techniques make use of recurrence on convolution mechanisms which are computationally expensive and have high memory requirements. Past techniques also make use of complex data processing making the existing techniques very complex and non-sustainable to change in data. Proposed work gives a much simpler approach which is not only at par with these complex networks but also exceeds perfor
    

