# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?](https://arxiv.org/abs/2403.14624) | MathVerse是一个全方位的视觉数学基准测试，旨在公平而深入地评估MLLMs在视觉数学问题解决中的能力。 |
| [^2] | [ReAct Meets ActRe: Autonomous Annotations of Agent Trajectories for Contrastive Self-Training](https://arxiv.org/abs/2403.14589) | 提出了A$^3$T框架，通过ActRe提示代理实现了ReAct风格代理对代理轨迹的自主标注，同时增强了新的轨迹合成能力。 |
| [^3] | [Large Language Models for Multi-Choice Question Classification of Medical Subjects](https://arxiv.org/abs/2403.14582) | 本文评估了大型语言模型在多选题数据上的训练效果，并利用MQ序列BERT方法，在医学科目分类任务中取得了优于最先进结果的准确率。 |
| [^4] | [A Chain-of-Thought Prompting Approach with LLMs for Evaluating Students' Formative Assessment Responses in Science](https://arxiv.org/abs/2403.14565) | 使用大型语言模型（LLMs）进行自动评估中学生科学形成性评估回答，结合思维链推理，人机协同方法成功评分并提供有意义解释，有望提升开放性科学测评的自动评分。 |
| [^5] | [The Era of Semantic Decoding](https://arxiv.org/abs/2403.14562) | 提出了一种名为语义解码的新观点，将LLM、人类输入和各种工具之间的协作过程构建为语义空间中的优化过程，促进了高效输出的构建。 |
| [^6] | [Lexicon-Level Contrastive Visual-Grounding Improves Language Modeling](https://arxiv.org/abs/2403.14551) | 这项研究介绍了LexiContrastive Grounding (LCG)，它结合了视觉监督和文本表示改进策略，在多个单词学习和句子理解基准测试中表现出比标准语言模型更高的学习效率和进步。 |
| [^7] | [EDT: Improving Large Language Models' Generation by Entropy-based Dynamic Temperature Sampling](https://arxiv.org/abs/2403.14541) | 通过提出基于熵的动态温度采样方法，本文在大语言模型的生成中实现了更平衡的性能表现，并在四个不同生成基准上展示了显著优于现有策略的结果。 |
| [^8] | [Building a Language-Learning Game for Brazilian Indigenous Languages: A Case of Study](https://arxiv.org/abs/2403.14515) | 本研究尝试构建一款用于巴西土著语言学习的语言学习游戏，并探讨了相关挑战，设计了具有游戏化特点的工具，实现了从依存树库和图比安语言的词汇数据库自动生成语言练习和问题，并强调了与土著社区建立合作关系和以教育为目的的数据收集过程。 |
| [^9] | [Detoxifying Large Language Models via Knowledge Editing](https://arxiv.org/abs/2403.14472) | 本文研究了使用知识编辑技术对大型语言模型进行去毒化，在构建了SafeEdit基准的基础上，提出了一种简单而有效的方法 DINM，可以通过少量调整步骤减少模型的毒性，同时对各种去毒方法的内部机制进行了深入分析。 |
| [^10] | [ChatGPT Alternative Solutions: Large Language Models Survey](https://arxiv.org/abs/2403.14469) | 大语言模型在多个领域展现出强大能力，ChatGPT是一个基于LLMs的强大AI聊天机器人，在学术界和工业界的合作推动下，LLM研究领域不断取得新突破，预示着人工智能社区将迎来革命性变革。 |
| [^11] | [Recourse for reclamation: Chatting with generative language models](https://arxiv.org/abs/2403.14467) | 这项工作将算法性索赔的概念延伸到生成式语言模型，为用户提供动态设置毒性过滤阈值的新机制，使他们能够实现他们期望的预测，从而增加他们的代理权。 |
| [^12] | [Towards Single-System Illusion in Software-Defined Vehicles -- Automated, AI-Powered Workflow](https://arxiv.org/abs/2403.14460) | 提出了一种基于模型和特征的新方法，通过迭代搜索和优化的过程中出现最终架构，同时保持单一系统错觉特性，并将现代生成式人工智能引入其中，从而实现对车辆软件系统的自动化开发。 |
| [^13] | [Multi-Level Explanations for Generative Language Models](https://arxiv.org/abs/2403.14459) | 本文提出了一个名为MExGen的通用框架，通过引入标量化概念和多级方法处理生成式语言模型的挑战，证明可以提供更贴近本地的解释。 |
| [^14] | [gTBLS: Generating Tables from Text by Conditional Question Answering](https://arxiv.org/abs/2403.14457) | gTBLS通过两阶段方法从文本中生成表格，第一阶段推断表格结构，第二阶段利用结构提出问题并通过微调语言模型来回答，能够在零短配置下利用预训练的大型语言模型，改进了先前方法的效果。 |
| [^15] | [Prediction of Translation Techniques for the Translation Process](https://arxiv.org/abs/2403.14454) | 该研究探讨了针对翻译过程的翻译技术预测，发现在自动识别和应用适当的翻译技术方面，可以进一步优化机器翻译，取得了82%到93%的预测准确率。 |
| [^16] | [More than Just Statistical Recurrence: Human and Machine Unsupervised Learning of M\=aori Word Segmentation across Morphological Processes](https://arxiv.org/abs/2403.14444) | NMS和Morfessor在分割由不同形态过程形成的单词中表现出成功，NMS对模板和其他形态结构线索也表现出敏感，显示出他们的学习过程不仅仅受到统计重复的影响。 |
| [^17] | [Language Models Can Reduce Asymmetry in Information Markets](https://arxiv.org/abs/2403.14443) | 语言模型驱动的智能代理在模拟数字市场中完成买卖信息的任务，通过具备评估信息质量和遗忘能力的特点，成功降低了信息市场的买方检查悖论。 |
| [^18] | [A Multimodal Approach to Device-Directed Speech Detection with Large Language Models](https://arxiv.org/abs/2403.14438) | 探索了一种利用大型语言模型进行设备定向语音检测的多模态方法，相比于文本和音频模型，使用多模态信息能够显著提高相等错误率。 |
| [^19] | [Emergent communication and learning pressures in language models: a language evolution perspective](https://arxiv.org/abs/2403.14427) | 从语言进化的角度研究了新兴沟通文献，发现其在设计和调整模型以恢复自然语言中初始缺失的语言现象方面表现优秀，揭示了关键压力促使恢复最初不显现的人类模式。 |
| [^20] | [Locating and Mitigating Gender Bias in Large Language Models](https://arxiv.org/abs/2403.14409) | 本研究提出了一种将定位和减轻偏见过程融入统一框架的方法，通过因果中介分析追踪大型语言模型中不同组件激活的因果效应，并提出了一种用于减轻职业代词中性别偏见的基于知识编辑的LSDM方法。 |
| [^21] | [Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity](https://arxiv.org/abs/2403.14403) | 通过新颖的自适应QA框架，根据查询的复杂度动态选择适合的检索增强大型语言模型策略，提高了回答准确性。 |
| [^22] | [XLAVS-R: Cross-Lingual Audio-Visual Speech Representation Learning for Noise-Robust Speech Perception](https://arxiv.org/abs/2403.14402) | XLAVS-R是一个跨语言视听语音表示学习模型，通过利用有限的多语言AV预训练数据，简化预训练方案，以提高对噪声的鲁棒性，在下游音频-视觉语音识别和翻译任务中比先前最先进技术提升了高达18.5% WER和4.7 BLEU。 |
| [^23] | [Building Accurate Translation-Tailored LLMs with Language Aware Instruction Tuning](https://arxiv.org/abs/2403.14399) | 通过设计两阶段微调算法，本研究旨在提高LLMs遵循翻译指令的能力，尤其是翻译方向信息。 |
| [^24] | [From Large to Tiny: Distilling and Refining Mathematical Expertise for Math Word Problems with Weakly Supervision](https://arxiv.org/abs/2403.14390) | 提出了一种创新的两阶段框架，巧妙地将数学专业知识从大型语言模型转移到小型语言模型 |
| [^25] | [Editing Knowledge Representation of Language Lodel via Rephrased Prefix Prompts](https://arxiv.org/abs/2403.14381) | 引入了一种名为PSPEM的新方法，通过重新表述前缀提示来编辑语言Lodel的知识表示，解决了知识编辑方法中的低效性、通用性问题，以及提示工程的不透明性。 |
| [^26] | [FIT-RAG: Black-Box RAG with Factual Information and Token Reduction](https://arxiv.org/abs/2403.14374) | FIT-RAG使用事实信息和令牌减少解决了黑匣子RAG系统中存在的事实信息忽视和令牌浪费问题 |
| [^27] | [WikiFactDiff: A Large, Realistic, and Temporally Adaptable Dataset for Atomic Factual Knowledge Update in Causal Language Models](https://arxiv.org/abs/2403.14364) | WikiFactDiff是一个用于因果语言模型中的原子事实知识更新的大型、现实且时间上可适应的数据集，通过描述事实知识在两个日期之间的演变，并提供不同类型基本更新的更新方案和评估指标。 |
| [^28] | [Beyond Surface Similarity: Detecting Subtle Semantic Shifts in Financial Narratives](https://arxiv.org/abs/2403.14341) | 本文介绍了Financial-STS任务，旨在衡量金融叙述对之间微妙的语义相似性，提出了一种LLM增强型流程，以优于现有方法的性能。 |
| [^29] | [$\nabla \tau$: Gradient-based and Task-Agnostic machine Unlearning](https://arxiv.org/abs/2403.14339) | $\nabla \tau$ 是一种旨在高效消除部分训练数据影响的机器遗忘优化框架。 |
| [^30] | [ChainLM: Empowering Large Language Models with Improved Chain-of-Thought Prompting](https://arxiv.org/abs/2403.14312) | 提出了CoTGenius框架，用于自动生成优质CoT提示，并通过它创建了庞大的CoT数据集以提升大型语言模型的推理能力 |
| [^31] | [Is Reference Necessary in the Evaluation of NLG Systems? When and Where?](https://arxiv.org/abs/2403.14275) | 本研究通过实验证明，在自然语言生成系统评估中，无参考指标与人类判断更相关，对语言质量的不足更为敏感，但其在不同任务中的有效性存在差异，并受到候选文本质量的影响。 |
| [^32] | [Scene-Graph ViT: End-to-End Open-Vocabulary Visual Relationship Detection](https://arxiv.org/abs/2403.14270) | 提出了一种简单高效的无解码器架构，用于开放词汇的视觉关系检测，通过Transformer-based图像编码器隐式建模对象之间的关系，使用注意力机制提取关系信息，在混合数据上进行端到端训练，实现了最先进的关系检测性能。 |
| [^33] | [LLM-based Extraction of Contradictions from Patents](https://arxiv.org/abs/2403.14258) | 专利和技术矛盾提取是创新产品开发中的重要灵感来源，而基于LLM的方法可以帮助超越传统关键词方法，实现专利摘要与关键概念提取。 |
| [^34] | [ERD: A Framework for Improving LLM Reasoning for Cognitive Distortion Classification](https://arxiv.org/abs/2403.14255) | ERD提出了一个框架，通过提取与认知失调相关的部分和通过多个代理人进行推理步骤的辩论，改进了基于LLM的认知失调分类性能。 |
| [^35] | [K-Act2Emo: Korean Commonsense Knowledge Graph for Indirect Emotional Expression](https://arxiv.org/abs/2403.14253) | 介绍了针对间接情感表达的韩国常识知识图谱K-Act2Emo，通过实验验证其在训练情感推断模型方面的有效性，微调后的BART知识模型表现优异，达到了与GPT-4 Turbo相媲美的性能水平。 |
| [^36] | [LayoutLLM: Large Language Model Instruction Tuning for Visually Rich Document Understanding](https://arxiv.org/abs/2403.14252) | 提出了一种新的LayoutLLM模型，通过结合大规模语言模型和文档图像理解的优势，实现了对文档图像的理解。 |
| [^37] | [Dermacen Analytica: A Novel Methodology Integrating Multi-Modal Large Language Models with Machine Learning in tele-dermatology](https://arxiv.org/abs/2403.14243) | 本文提出了一种新方法，在远程皮肤病学中整合了多模式大型语言模型与机器学习，旨在通过综合利用大型语言模型、Transformer视觉模型和复杂的机器学习工具，辅助诊断皮肤病变和其他皮肤状况，从而全面解决该领域的诊断流程。 |
| [^38] | [Reinforcement Learning from Reflective Feedback (RLRF): Aligning and Improving LLMs via Fine-Grained Self-Reflection](https://arxiv.org/abs/2403.14238) | RLRF提出了一种新颖的框架，通过细粒度反馈和自我反思机制，可以改进LLMs的核心能力，超越表面调整。 |
| [^39] | [A Unified Framework for Model Editing](https://arxiv.org/abs/2403.14236) | 这个统一框架结合了“定位和编辑”模型编辑技术，最大化保留某些向量表示并记忆新事实信息。 |
| [^40] | [Large-Scale Label Interpretation Learning for Few-Shot Named Entity Recognition](https://arxiv.org/abs/2403.14222) | 通过大规模扩展实体类型数量和粒度，研究了强语义先验对于解释实体类型文本化描述的影响。 |
| [^41] | [Improving the Robustness of Large Language Models via Consistency Alignment](https://arxiv.org/abs/2403.14221) | 通过一致性对齐训练的两阶段框架，有助于提高大型语言模型的鲁棒性和对指令的理解。 |
| [^42] | [Automatic Annotation of Grammaticality in Child-Caregiver Conversations](https://arxiv.org/abs/2403.14208) | 提出了针对儿童-看护者对话中上下文依赖语法的编码方案，并训练并评估了一系列自然语言处理模型，结果显示经过微调的Transformer模型表现最佳。 |
| [^43] | [Context Quality Matters in Training Fusion-in-Decoder for Extractive Open-Domain Question Answering](https://arxiv.org/abs/2403.14197) | 论文探讨了在训练 Fusion-in-Decoder（FiD）时上下文数量和质量对提取式开放域问答任务性能的影响，实验结果表明FiD模型在训练过程中可能会过拟合到上下文质量，导致在不同质量上下文评估时表现出亚优性能。 |
| [^44] | [MMIDR: Teaching Large Language Model to Interpret Multimodal Misinformation via Knowledge Distillation](https://arxiv.org/abs/2403.14171) | 提出了MMIDR框架，用于教导大型语言模型提供解释其多模态虚假信息决策过程的文本解释。 |
| [^45] | [M$^3$AV: A Multimodal, Multigenre, and Multipurpose Audio-Visual Academic Lecture Dataset](https://arxiv.org/abs/2403.14168) | 提出了一种新颖的M$^3$AV音视频学术讲座数据集，包含多模态、多体裁和高质量人工注释，可用于多种音视频识别任务 |
| [^46] | [C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion](https://arxiv.org/abs/2403.14119) | 本文研究了在测试时提示调整过程中通过利用CLIP的固有属性来探讨校准的方法，发现提示选择显著影响了CLIP中的校准，其中导致更高文本特征离散性的提示会产生更好校准的预测。 |
| [^47] | [From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation](https://arxiv.org/abs/2403.14118) | 本文对机器翻译质量评估领域的发展历史进行了全面概述，将方法分为基于手工特征、深度学习和大型语言模型的三类，并探讨了未来研究方向。 |
| [^48] | [A Design Space for Intelligent and Interactive Writing Assistants](https://arxiv.org/abs/2403.14117) | 通过提出一种设计空间，帮助研究人员和设计师在多维空间中检验和探索智能交互式写作助手的各种可能性。 |
| [^49] | [Benchmarking Chinese Commonsense Reasoning of LLMs: From Chinese-Specifics to Reasoning-Memorization Correlations](https://arxiv.org/abs/2403.14112) | CHARM是第一个用于全面深入评估大型语言模型中文常识推理能力的基准，研究发现LLM的语言导向性和任务领域会影响提示策略的有效性，并指出一些LLMs在记忆中文常识方面存在困难，而其他一些LLMs在推理上表现存在差异。 |
| [^50] | [M3: A Multi-Task Mixed-Objective Learning Framework for Open-Domain Multi-Hop Dense Sentence Retrieval](https://arxiv.org/abs/2403.14074) | M3是一个多任务混合目标学习框架，旨在解决仅依赖对比学习可能导致的次优检索性能问题，并取得了在FEVER数据集上的最先进性能。 |
| [^51] | [A Taxonomy of Ambiguity Types for NLP](https://arxiv.org/abs/2403.14072) | 该论文提出了一个英语中常见的歧义类型分类，旨在促进自然语言处理分析，有助于更细致地评估数据集和模型性能。 |
| [^52] | [The NeurIPS 2023 Machine Learning for Audio Workshop: Affective Audio Benchmarks and Novel Data](https://arxiv.org/abs/2403.14048) | NeurIPS 2023音频机器学习研讨会聚集了音频领域的机器学习专家，为解决音频数据获取困难的问题，提供了多个开源数据集和专有数据集。 |
| [^53] | [Ax-to-Grind Urdu: Benchmark Dataset for Urdu Fake News Detection](https://arxiv.org/abs/2403.14037) | 本文提出了乌尔都语虚假新闻检测的首个最大规模公开数据集，填补了地区语言虚假新闻检测领域数据集规模有限的空白。 |
| [^54] | [A New Massive Multilingual Dataset for High-Performance Language Technologies](https://arxiv.org/abs/2403.14009) | 提出了HPLT语言资源，这是一个包括单语和双语语料库的大规模多语言数据集，提供了丰富的资源用于语言建模和机器翻译训练 |
| [^55] | [On Prompt Sensitivity of ChatGPT in Affective Computing](https://arxiv.org/abs/2403.14006) | 该研究介绍了一个用于评估基础模型性能敏感性的方法，针对ChatGPT在情感计算中的提示敏感性进行了研究和评估，涵盖情绪分析、毒性检测和讽刺检测。 |
| [^56] | [Evaluating Unsupervised Dimensionality Reduction Methods for Pretrained Sentence Embeddings](https://arxiv.org/abs/2403.14001) | 评估使用无监督降维方法减小预训练语言模型生成句子嵌入维度，并发现对于一些模型，在降维后性能反而提高了。 |
| [^57] | [Reducing Large Language Model Bias with Emphasis on 'Restricted Industries': Automated Dataset Augmentation and Prejudice Quantification](https://arxiv.org/abs/2403.13925) | 本文提出了一种针对“受限行业”进行自动数据集增强以减少大型语言模型偏见的新机制，并创建了mb-index和db-index两个新的偏见量化指标。 |
| [^58] | [Visually Grounded Speech Models have a Mutual Exclusivity Bias](https://arxiv.org/abs/2403.13922) | 研究探讨了视觉引导的语音模型中的相互排他性偏见，并发现在具有更多视觉知识的模型中存在更强的偏见。 |
| [^59] | [Leveraging Linguistically Enhanced Embeddings for Open Information Extraction](https://arxiv.org/abs/2403.13903) | 首次利用Seq2Seq PLM与语言特征相结合，有效提高了神经网络OIE架构的性能，使其同时获益于预训练语言模型和语言特征。 |
| [^60] | [Train & Constrain: Phonologically Informed Tongue-Twister Generation from Topics and Paraphrases](https://arxiv.org/abs/2403.13901) | 本文提出了一种从主题和释义生成基于音韵学的绕口令的新方法，生成了迄今为止最大的绕口令数据集TwistList 2.0，并进行了自动和人工评估。 |
| [^61] | [Whose Side Are You On? Investigating the Political Stance of Large Language Models](https://arxiv.org/abs/2403.13840) | 本研究提出了一个定量框架和流程，系统调查大型语言模型的政治取向，结果显示这些模型倾向于提供与自由主义或左倾观点更为接近的回应。 |
| [^62] | [SMART: Automatically Scaling Down Language Models with Accuracy Guarantees for Reduced Processing Fees](https://arxiv.org/abs/2403.13835) | 提出了SMART框架，可通过准确性约束最小化自然语言处理任务的推理成本，同时确保结果质量。 |
| [^63] | [Bridging Text and Molecule: A Survey on Multimodal Frameworks for Molecule](https://arxiv.org/abs/2403.13830) | 本文首次系统调研了针对分子研究的多模态框架，重点讨论了文本与分子之间的关联、不同模型架构和预训练任务。同时还深入探讨了大型语言模型以及提示技术在分子领域中的应用。 |
| [^64] | [Measuring Diversity in Co-creative Image Generation](https://arxiv.org/abs/2403.13826) | 提出了一种基于神经网络编码熵的方法，以比较图像集合之间的多样性，而无需真实标准知识且易于计算，并展示了不同预训练网络选择对我们要评估的多样性概念的影响。 |
| [^65] | [Quantitative Analysis of AI-Generated Texts in Academic Research: A Study of AI Presence in Arxiv Submissions using AI Detection Tool](https://arxiv.org/abs/2403.13812) | 论文研究了一种能够检测Arxiv投稿中AI成分的方法，使用物理、数学和计算机科学文章创建数据集，并通过Originality.ai进行分析，准确率达到98%。 |
| [^66] | [RoleInteract: Evaluating the Social Interaction of Role-Playing Agents](https://arxiv.org/abs/2403.13679) | 该论文介绍了RoleInteract，一个旨在评估角色扮演对话代理社交性的基准，覆盖了500个角色、6000多个问题提示和30800个对话话语。 |
| [^67] | [Do Not Worry if You Do Not Have Data: Building Pretrained Language Models Using Translationese](https://arxiv.org/abs/2403.13638) | 本文探讨了使用Translationese合成数据作为预训练语言模型的实用性，展示了在英语以外的语言中使用机器翻译创建的合成数据进行LMs预训练的有效性，并提出了通过使用轻量级TinyLMs预训练来过滤合成数据的方法。 |
| [^68] | [LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models](https://arxiv.org/abs/2403.13372) | LlamaFactory是一个统一框架，整合了一系列前沿的高效训练方法，使用户能够在不需要编码的情况下灵活定制100多种LLMs的微调。 |
| [^69] | [Arcee's MergeKit: A Toolkit for Merging Large Language Models](https://arxiv.org/abs/2403.13257) | 合并不同语言模型的参数，无需额外训练即可创建多任务模型，提升模型性能和多功能性，解决AI中的复杂挑战。 |
| [^70] | [From Representational Harms to Quality-of-Service Harms: A Case Study on Llama 2 Safety Safeguards](https://arxiv.org/abs/2403.13213) | 本文探讨了针对表现性伤害和服务质量伤害的羊驼2安全保障措施的有效性，并指出了大型语言模型在实用性和安全性之间的权衡关系。 |
| [^71] | [RankPrompt: Step-by-Step Comparisons Make Language Models Better Reasoners](https://arxiv.org/abs/2403.12373) | RankPrompt 提出了一种新的提示方法，可以通过自我排序来提高大型语言模型在推理任务中的性能。 |
| [^72] | [A Challenge Dataset and Effective Models for Conversational Stance Detection](https://arxiv.org/abs/2403.11145) | 介绍了一个新的多轮对话立场检测数据集（MT-CSD），提出了一种全局局部注意力网络（GLAN）来解决对话数据中的长距离和短距离依赖性。 |
| [^73] | [m&m's: A Benchmark to Evaluate Tool-Use for multi-step multi-modal Tasks](https://arxiv.org/abs/2403.11085) | m&m's引入了一个包含4K+多步骤多模态任务的基准，涉及33种工具，用于评估LLM作为规划器的设计决策。 |
| [^74] | [Optimizing Language Augmentation for Multilingual Large Language Models: A Case Study on Korean](https://arxiv.org/abs/2403.10882) | 该研究提出了三种策略来增强基于公开可用MLLMs的资源较少的语言的性能，包括扩展词汇、双语数据预训练和指导微调。 |
| [^75] | [Less is More: Data Value Estimation for Visual Instruction Tuning](https://arxiv.org/abs/2403.09559) | 视觉指导调整时需要进行数据价值评估，通过新的数据选择方法TIVE，根据任务级和实例级价值来消除视觉指导数据中的冗余。 |
| [^76] | [Training Small Multimodal Models to Bridge Biomedical Competency Gap: A Case Study in Radiology Imaging](https://arxiv.org/abs/2403.08002) | 本文针对生物医学应用中前沿模型尚存在的多模态能力差距，探讨了训练开源小型多模态模型以弥补临床需求的生物医学能力差距。 |
| [^77] | [Unraveling the Mystery of Scaling Laws: Part I](https://arxiv.org/abs/2403.06563) | 确认缩放定律原则在模型预训练中的重要作用，揭示OpenAI原始缩放定律论文的不完整细节，并探究预测测试损失轨迹可靠公式的挑战 |
| [^78] | [Is this the real life? Is this just fantasy? The Misleading Success of Simulating Social Interactions With LLMs](https://arxiv.org/abs/2403.05020) | 研究发现，使用LLMs进行社交互动的全知模拟比非全知模拟更容易实现社交目标，尽管非全知模拟更接近实际情况。 |
| [^79] | [Uncertainty-Aware Relational Graph Neural Network for Few-Shot Knowledge Graph Completion](https://arxiv.org/abs/2403.04521) | 提出一种不确定性感知的少样本知识图谱补全框架以模拟实体和三元组不确定性，通过学习服从高斯分布的表示来更好地理解有限数据。 |
| [^80] | [NewsBench: Systematic Evaluation of LLMs for Writing Proficiency and Safety Adherence in Chinese Journalistic Editorial Applications](https://arxiv.org/abs/2403.00862) | NewsBench是一个评估LLMs在中国新闻写作水平和安全性遵从能力的基准框架，揭示了在创造性写作任务中LLMs相对不足的新闻伦理遵守方面的需求。 |
| [^81] | [OSCaR: Object State Captioning and State Change Representation](https://arxiv.org/abs/2402.17128) | 本文介绍了一个新的数据集和基准OSCaR，旨在解决描述复杂视觉环境中对象状态变化的问题，为评估多模态大型语言提供了一个新的实验平台。 |
| [^82] | [Assessing the Reasoning Abilities of ChatGPT in the Context of Claim Verification](https://arxiv.org/abs/2402.10735) | 我们提出了一个逻辑推理框架，用于评估ChatGPT在声明验证中的推理能力，发现其在归纳推理方面存在困难，并提出了一种缓解方法。 |
| [^83] | [LLMs and the Human Condition](https://arxiv.org/abs/2402.08403) | 本文提出了将三个成熟的人类决策理论整合到一起，形成了一个目的性人类行动模型。同时，将语言作为行动的观点应用于对话用户界面。通过理解ChatGPT的智能来源，可以在减少资源的同时获得对我们之间关系的认识。 |
| [^84] | [ANLS* -- A Universal Document Processing Metric for Generative Large Language Models](https://arxiv.org/abs/2402.03848) | ANLS*是一种用于生成型模型的新度量方法，针对各种任务包括信息提取和分类任务进行评估。它扩展了现有的ANLS度量方法，可以作为替代方案使用。 |
| [^85] | [EasyInstruct: An Easy-to-use Instruction Processing Framework for Large Language Models](https://arxiv.org/abs/2402.03049) | EasyInstruct是一个易于使用的用于大型语言模型的指令处理框架，通过模块化指令生成、选择和提示，并考虑它们的组合和交互，使指令处理更加方便和高效。 |
| [^86] | [DenseFormer: Enhancing Information Flow in Transformers via Depth Weighted Averaging](https://arxiv.org/abs/2402.02622) | DenseFormer是对Transformer的简单修改，通过在每个transformer块之后进行深度加权平均，提高了模型的困惑度。学到的加权平均权重揭示了信息流的连贯模式，使得DenseFormer具有更高的数据效率，并且在相同困惑度下胜过传统的Transformer模型。 |
| [^87] | [The LLM Surgeon](https://arxiv.org/abs/2312.17244) | 通过数据驱动压缩现有预训练模型，我们提供了一个改进权重更新的通用框架，以更有效地捕捉更多权重之间的相关性，同时保持计算效率。 |
| [^88] | [Generating Explanations to Understand and Repair Embedding-based Entity Alignment](https://arxiv.org/abs/2312.04877) | 该论文提出了一个可以生成解释以理解和修复基于嵌入的实体对齐结果的框架，通过构建匹配子图和对齐依赖图，解决对齐冲突，实验表明其有效性和泛化性。 |
| [^89] | [Prompt Highlighter: Interactive Control for Multi-Modal LLMs](https://arxiv.org/abs/2312.04302) | 提出了一种称为Prompt Highlighter的新型推理方法，通过突出显示特定提示跨度，实现用户在生成过程中交互控制焦点，并基于高亮标记形成正规且无条件的上下文对，从而在没有分类器的情况下引导模型的自回归生成。 |
| [^90] | [CoachLM: Automatic Instruction Revisions Improve the Data Quality in LLM Instruction Tuning](https://arxiv.org/abs/2311.13246) | CoachLM 提出了一种新颖方法来增强指导数据集的质量，通过自动修订样本而非丢弃低质量样本，从而解决了现有方法的局限性。 |
| [^91] | [TableLlama: Towards Open Large Generalist Models for Tables](https://arxiv.org/abs/2311.09206) | 本文旨在开发用于各种基于表格任务的开源大型语言模型，通过构建新数据集TableInstruct和开发第一个面向表格的开源通用模型TableLlama，在表现方面取得了可比或更好的成果。 |
| [^92] | [Self-Improving for Zero-Shot Named Entity Recognition with Large Language](https://arxiv.org/abs/2311.08921) | 本研究提出了一个无需训练的自我改进框架，利用未标记语料库激发大型语言模型的自我学习能力，从而推动零-shot命名实体识别性能边界。 |
| [^93] | [Moral Judgments in Narratives on Reddit: Investigating Moral Sparks via Social Commonsense and Linguistic Signals](https://arxiv.org/abs/2310.19268) | 通过研究Reddit上的道德判断，本研究探讨了社交常识和语言信号对于道德火花的影响，为人类道德判断提供了深入理解。 |
| [^94] | [Language Models Hallucinate, but May Excel at Fact Verification](https://arxiv.org/abs/2310.14564) | 语言模型存在幻觉现象，但研究表明它们可以作为有效的事实验证器，甚至在某些情况下胜过更强大的语言模型。 |
| [^95] | [Effective Structured Prompting by Meta-Learning and Representative Verbalizer](https://arxiv.org/abs/2306.00618) | 通过使用提示池和构建基于实例的提示以及引入新颖的软语言化器，提出了一种通过元学习和代表性语言化器实现有效的结构化提示的方法 |
| [^96] | [Multi-Scale Contrastive Knowledge Co-Distillation for Event Temporal Relation Extraction](https://arxiv.org/abs/2209.00568) | 提出了MulCo：多尺度对比知识共同蒸馏用于全面提高所有类型时间数据集性能 |
| [^97] | [Pre-training Language Model Incorporating Domain-specific Heterogeneous Knowledge into A Unified Representation](https://arxiv.org/abs/2109.01048) | 本文提出了一种名为HKLM的异构知识语言模型，能够统一处理包括非结构化文本、半结构化文本和结构化文本在内的所有文本形式，通过不同的目标学习词知识、实体知识和主题知识，实验证明其性能优于预训练模型。 |
| [^98] | [VQPy: An Object-Oriented Approach to Modern Video Analytics.](http://arxiv.org/abs/2311.01623) | VQPy是一种面向对象的视频分析方法，它使用Python变体作为前端，并具有可扩展的后端，可以自动构建和优化基于视频对象的处理流程。 |
| [^99] | [Knowing What LLMs DO NOT Know: A Simple Yet Effective Self-Detection Method.](http://arxiv.org/abs/2310.17918) | 本文提出了一种新的自我检测方法，用于判断大型语言模型 (LLMs) 无法回答的问题，以避免生成非事实性的回答。通过多样化问题的文本表达，收集答案，并检查生成的答案之间的差异，可以识别出可能生成虚假回答的问题。该方法只需要利用LLMs自身，无需其他外部资源。这种方法在Vicuna、ChatGPT和GPT-4等最新发布的LLMs上得到了有效验证。 |
| [^100] | [A Comprehensive Evaluation of Constrained Text Generation for Large Language Models.](http://arxiv.org/abs/2310.16343) | 该研究全面评估了大型语言模型在约束文本生成方面的应用，研究了LLM的能力和不足，并提供了未来发展的见解。 |
| [^101] | [TiC-CLIP: Continual Training of CLIP Models.](http://arxiv.org/abs/2310.16226) | 该论文提出了用于训练视觉-语言模型的大规模时间连续 (TiC) 基准，使用这些基准评估了现有模型的时间鲁棒性，并展示了一种简单有效的排练方法来持续训练模型。 |
| [^102] | [AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models.](http://arxiv.org/abs/2310.04451) | 本文介绍了一种名为AutoDAN的方法，该方法旨在在对齐的大型语言模型上自动生成隐蔽的越狱提示，以解决现有越狱技术的可扩展性和隐蔽性问题。 |
| [^103] | [Detecting Sexual Content at the Sentence Level in First Millennium Latin Texts.](http://arxiv.org/abs/2309.14974) | 该研究提出使用深度学习方法在句子级别进行语义分类，以加速人文学科和语言学领域中语料库建设的过程。经过评估，该方法在检测性内容方面表现出高精度和真阳性率，并探索了不同的输入嵌入层对模型性能的影响。 |
| [^104] | [SignBank+: Multilingual Sign Language Translation Dataset.](http://arxiv.org/abs/2309.11566) | 该论文介绍了SignBank+，这是一个经过优化的手语翻译数据集，通过简化文本对文本翻译方法，提升了手语机器翻译模型的性能，并为未来的研究提供了一个开放的资源。 |
| [^105] | [Sequence-to-Sequence Spanish Pre-trained Language Models.](http://arxiv.org/abs/2309.11259) | 该论文介绍了一种新的序列到序列的西班牙预训练语言模型，该模型在各种序列到序列任务中表现出了竞争性能，并提供了BART、T5和BERT2BERT-style模型的西班牙版本。 |
| [^106] | [Facilitating NSFW Text Detection in Open-Domain Dialogue Systems via Knowledge Distillation.](http://arxiv.org/abs/2309.09749) | 该论文介绍了CensorChat，一个用于监测NSFW对话的数据集，并利用知识蒸馏技术构建了高效的NSFW内容检测器。 |
| [^107] | [RoDia: A New Dataset for Romanian Dialect Identification from Speech.](http://arxiv.org/abs/2309.03378) | RoDia是第一个用于罗马尼亚方言识别的语音数据集，包含来自五个不同地区的2小时手动标注数据，并提供了一组竞争模型作为未来研究的基准。 |
| [^108] | [Reranking Passages with Coarse-to-Fine Neural Retriever using List-Context Information.](http://arxiv.org/abs/2308.12022) | 本文提出了一种利用列表上下文信息的粗到细神经检索器来重新排序段落。该方法通过将其他候选句子的列表上下文信息纳入段落表示中，增强了段落表示。而且，该方法将列表上下文建模过程分为两个子过程，从而解决了段落注意机制的内存限制问题，允许高效编码大量候选答案的上下文信息。 |
| [^109] | [Metacognitive Prompting Improves Understanding in Large Language Models.](http://arxiv.org/abs/2308.05342) | 元认知提示 (MP) 是一种改进大型语言模型 (LLMs) 理解能力的策略。实验结果表明，使用MP的PaLM在各种自然语言理解任务中接近于GPT-4的性能水平。 |
| [^110] | [Pluggable Neural Machine Translation Models via Memory-augmented Adapters.](http://arxiv.org/abs/2307.06029) | 通过记忆增强的适配器，我们提出了一种可插拔的方法来控制神经机器翻译模型的生成行为。实验证明，我们的方法可以胜过几个代表性的可插拔基准模型。 |
| [^111] | [Gammatonegram Representation for End-to-End Dysarthric Speech Processing Tasks: Speech Recognition, Speaker Identification, and Intelligibility Assessment.](http://arxiv.org/abs/2307.03296) | 该研究提出了一种使用Gamma音图表示语音的方法，通过卷积神经网络实现了语音识别、说话人识别和可理解性评估的功能。 |
| [^112] | [ChatGPT4PCG Competition: Character-like Level Generation for Science Birds.](http://arxiv.org/abs/2303.15662) | 本论文介绍了举办在2023 IEEE游戏会议上的第一届ChatGPT4PCG比赛，目标是让ChatGPT生成具有高稳定性和类似角色的特质来生成具有科学鸟角色级水平的关卡。 |
| [^113] | [ComCLIP: Training-Free Compositional Image and Text Matching.](http://arxiv.org/abs/2211.13854) | 本文提出了一个无需训练的组合图像与文本匹配模型 ComCLIP，通过将输入图像分解为主体、对象和动作子图像，并结合视觉编码器和文本编码器进行逐步匹配，以解决组合图像与文本匹配中的伪匹配问题。 |

# 详细

[^1]: MathVerse：您的多模式LLM是否真正看到了视觉数学问题中的图表？

    MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?

    [https://arxiv.org/abs/2403.14624](https://arxiv.org/abs/2403.14624)

    MathVerse是一个全方位的视觉数学基准测试，旨在公平而深入地评估MLLMs在视觉数学问题解决中的能力。

    

    多模式大型语言模型（MLLMs）取得了显著进展，在视觉环境中表现出色，然而它们在视觉数学问题解决方面的能力仍未充分评估和理解。本研究调查了当前基准测试，将过多的视觉内容融入文本问题中，这有助于MLLM在不真正解释输入图表的情况下推导答案。为此，我们介绍了MathVerse，这是一个全方位的视觉数学基准测试，旨在公平而深入地评估MLLMs。我们精心收集了2,612个高质量的多学科数学问题，其中包含图表，来源于公开渠道。然后，每个问题由人工注释者转化为六个不同版本，每个版本在多模式中提供不同程度的信息内容，共贡献了15K个测试样本。这种方法使得MathVerse能够同时

    arXiv:2403.14624v1 Announce Type: cross  Abstract: The remarkable progress of Multi-modal Large Language Models (MLLMs) has garnered unparalleled attention, due to their superior performance in visual contexts. However, their capabilities in visual math problem-solving remain insufficiently evaluated and understood. We investigate current benchmarks to incorporate excessive visual content within textual questions, which potentially assist MLLMs in deducing answers without truly interpreting the input diagrams. To this end, we introduce MathVerse, an all-around visual math benchmark designed for an equitable and in-depth evaluation of MLLMs. We meticulously collect 2,612 high-quality, multi-subject math problems with diagrams from publicly available sources. Each problem is then transformed by human annotators into six distinct versions, each offering varying degrees of information content in multi-modality, contributing to 15K test samples in total. This approach allows MathVerse to co
    
[^2]: ReAct遇上ActRe：对比性自训练中的代理轨迹自动标注

    ReAct Meets ActRe: Autonomous Annotations of Agent Trajectories for Contrastive Self-Training

    [https://arxiv.org/abs/2403.14589](https://arxiv.org/abs/2403.14589)

    提出了A$^3$T框架，通过ActRe提示代理实现了ReAct风格代理对代理轨迹的自主标注，同时增强了新的轨迹合成能力。

    

    arXiv:2403.14589v1 公告类型：新 文摘：语言代理通过与基础模型推理展示了自主决策能力。最近，人们致力于通过多步推理和行动轨迹作为训练数据来训练语言代理以提高性能。然而，收集这样的轨迹仍需要相当大的人力，无论是通过人工标注还是实施多样化提示框架。在这项工作中，我们提出了A$^3$T，一个允许以ReAct风格自主注释代理轨迹的框架。其中心是一个ActRe提示代理，它解释任意动作的原因。当随机抽取外部动作时，ReAct风格代理可以查询ActRe代理以获取其文本理由。新颖的轨迹然后通过将ActRe的后验推理前置到抽样动作中进行综合合成。通过这种方式，ReAct风格代理可执行

    arXiv:2403.14589v1 Announce Type: new  Abstract: Language agents have demonstrated autonomous decision-making abilities by reasoning with foundation models. Recently, efforts have been made to train language agents for performance improvement, with multi-step reasoning and action trajectories as the training data. However, collecting such trajectories still requires considerable human effort, by either artificial annotations or implementations of diverse prompting frameworks. In this work, we propose A$^3$T, a framework that enables the Autonomous Annotation of Agent Trajectories in the style of ReAct. The central role is an ActRe prompting agent, which explains the reason for an arbitrary action. When randomly sampling an external action, the ReAct-style agent could query the ActRe agent with the action to obtain its textual rationales. Novel trajectories are then synthesized by prepending the posterior reasoning from ActRe to the sampled action. In this way, the ReAct-style agent exe
    
[^3]: 用于医学科目多选题分类的大型语言模型

    Large Language Models for Multi-Choice Question Classification of Medical Subjects

    [https://arxiv.org/abs/2403.14582](https://arxiv.org/abs/2403.14582)

    本文评估了大型语言模型在多选题数据上的训练效果，并利用MQ序列BERT方法，在医学科目分类任务中取得了优于最先进结果的准确率。

    

    本文旨在评估是否可以利用在多选题数据上训练的大型语言模型来区分医学科目。这对于自动问答是一项重要且具有挑战性的任务。为了实现这一目标，我们训练了深度神经网络，用于将问题多类别分类为推断的医学科目。使用我们的多问题(MQ)序列BERT方法，在MedMCQA数据集上表现优于最先进结果，分别在其开发和测试集上具有0.68和0.60的准确率。从这个意义上说，我们展示了人工智能和特别是LLMs在医疗保健领域中用于多分类任务的能力。

    arXiv:2403.14582v1 Announce Type: cross  Abstract: The aim of this paper is to evaluate whether large language models trained on multi-choice question data can be used to discriminate between medical subjects. This is an important and challenging task for automatic question answering. To achieve this goal, we train deep neural networks for multi-class classification of questions into the inferred medical subjects. Using our Multi-Question (MQ) Sequence-BERT method, we outperform the state-of-the-art results on the MedMCQA dataset with an accuracy of 0.68 and 0.60 on their development and test sets, respectively. In this sense, we show the capability of AI and LLMs in particular for multi-classification tasks in the Healthcare domain.
    
[^4]: 基于LLMs的思维链提示方法用于评估科学中学生形成性评估回答

    A Chain-of-Thought Prompting Approach with LLMs for Evaluating Students' Formative Assessment Responses in Science

    [https://arxiv.org/abs/2403.14565](https://arxiv.org/abs/2403.14565)

    使用大型语言模型（LLMs）进行自动评估中学生科学形成性评估回答，结合思维链推理，人机协同方法成功评分并提供有意义解释，有望提升开放性科学测评的自动评分。

    

    这篇论文探讨了使用大型语言模型（LLMs）对K-12科学中的简答测评进行评分和解释。虽然现有方法可以为更结构化的数学和计算机科学测评打分，但它们通常不提供分数的解释。我们的研究侧重于在中学地球科学中应用GPT-4进行自动评估，将少样本学习和主动学习与思维链推理相结合。通过人机协同方法，我们成功对形成性评估回答进行评分并提供有意义的解释。我们方法的系统分析揭示了人机协同技术增强开放性科学测评的自动评分潜力。

    arXiv:2403.14565v1 Announce Type: new  Abstract: This paper explores the use of large language models (LLMs) to score and explain short-answer assessments in K-12 science. While existing methods can score more structured math and computer science assessments, they often do not provide explanations for the scores. Our study focuses on employing GPT-4 for automated assessment in middle school Earth Science, combining few-shot and active learning with chain-of-thought reasoning. Using a human-in-the-loop approach, we successfully score and provide meaningful explanations for formative assessment responses. A systematic analysis of our method's pros and cons sheds light on the potential for human-in-the-loop techniques to enhance automated grading for open-ended science assessments.
    
[^5]: 语义解码时代

    The Era of Semantic Decoding

    [https://arxiv.org/abs/2403.14562](https://arxiv.org/abs/2403.14562)

    提出了一种名为语义解码的新观点，将LLM、人类输入和各种工具之间的协作过程构建为语义空间中的优化过程，促进了高效输出的构建。

    

    最近的研究展现了在LLM（大型语言模型）、人类输入和各种工具之间编排协作以解决LLM固有局限性的想法具有巨大潜力。我们提出了一个名为语义解码的新观点，将这些协作过程构建为语义空间中的优化过程。具体来说，我们将LLM概念化为操纵我们称之为语义标记（已知思想）的有意义信息片段的语义处理器。LLM是众多其他语义处理器之一，包括人类和工具，比如搜索引擎或代码执行器。语义处理器集体参与语义标记的动态交流，逐步构建高效输出。我们称这些在语义空间中进行优化和搜索的协同作用，为语义解码算法。这个概念与已广为研究的语义解码问题直接平行。

    arXiv:2403.14562v1 Announce Type: cross  Abstract: Recent work demonstrated great promise in the idea of orchestrating collaborations between LLMs, human input, and various tools to address the inherent limitations of LLMs. We propose a novel perspective called semantic decoding, which frames these collaborative processes as optimization procedures in semantic space. Specifically, we conceptualize LLMs as semantic processors that manipulate meaningful pieces of information that we call semantic tokens (known thoughts). LLMs are among a large pool of other semantic processors, including humans and tools, such as search engines or code executors. Collectively, semantic processors engage in dynamic exchanges of semantic tokens to progressively construct high-utility outputs. We refer to these orchestrated interactions among semantic processors, optimizing and searching in semantic space, as semantic decoding algorithms. This concept draws a direct parallel to the well-studied problem of s
    
[^6]: 词汇级对比视觉基础改进语言建模

    Lexicon-Level Contrastive Visual-Grounding Improves Language Modeling

    [https://arxiv.org/abs/2403.14551](https://arxiv.org/abs/2403.14551)

    这项研究介绍了LexiContrastive Grounding (LCG)，它结合了视觉监督和文本表示改进策略，在多个单词学习和句子理解基准测试中表现出比标准语言模型更高的学习效率和进步。

    

    今天最准确的语言模型是在比人类语言学习者接收到的语言数据量多得多的情况下训练的，但并没有来自在人类学习中起关键作用的其他感官模式的监督。本文描述了LexiContrastive Grounding (LCG)，一种利用视觉监督来改进文本表征的基于地面语言学习程序。LexiContrastive Grounding将下一个标记预测策略与对比视觉基础目标结合起来，重点放在编码词汇信息的早期层表示上。在多个单词学习和句子理解基准测试中，LexiContrastive Grounding不仅在学习效率上优于标准语言模型，而且在视觉与语言学习程序方面取得了进步。

    arXiv:2403.14551v1 Announce Type: cross  Abstract: Today's most accurate language models are trained on orders of magnitude more language data than human language learners receive - but with no supervision from other sensory modalities that play a crucial role in human learning. Can we make LMs' representations and predictions more accurate (and more human-like) with more ecologically plausible supervision? This paper describes LexiContrastive Grounding (LCG), a grounded language learning procedure that leverages visual supervision to improve textual representations. LexiContrastive Grounding combines a next token prediction strategy with a contrastive visual grounding objective, focusing on early-layer representations that encode lexical information. Across multiple word-learning and sentence-understanding benchmarks, LexiContrastive Grounding not only outperforms standard language-only models in learning efficiency, but also improves upon vision-and-language learning procedures inclu
    
[^7]: 通过基于熵的动态温度采样改进大型语言模型的生成

    EDT: Improving Large Language Models' Generation by Entropy-based Dynamic Temperature Sampling

    [https://arxiv.org/abs/2403.14541](https://arxiv.org/abs/2403.14541)

    通过提出基于熵的动态温度采样方法，本文在大语言模型的生成中实现了更平衡的性能表现，并在四个不同生成基准上展示了显著优于现有策略的结果。

    

    最近，大型语言模型（LLMs）在各种下游语言任务中展现出了出色的性能。温度采样是LLMs生成过程中常用的解码策略。然而，大多数情况下使用固定的温度参数，这可能并非始终是平衡生成质量和多样性的最佳选择。在本文中，我们提出了一种有效的基于熵的动态温度（EDT）采样方法，通过动态选择温度参数实现在生成质量和多样性方面更平衡的性能。此外，我们还展示了4个不同生成基准的模型性能和全面分析。我们的实验表明，EDT在不同任务中明显优于现有策略。

    arXiv:2403.14541v1 Announce Type: new  Abstract: Recently, Large Language Models (LLMs) have demonstrated outstanding performance across a wide range of downstream language tasks. Temperature sampling is a commonly used decoding strategy for LLMs' generation process. However, a fixed temperature parameter is used in most cases, which may not always be an optimal choice for balancing generation quality and diversity. In this paper, we propose an effective Entropy-based Dynamic Temperature (EDT) Sampling method, to achieve a more balanced performance in terms of both generation quality and diversity by dynamically selecting the temperature parameter. Additionally, we also show model performance and comprehensive analyses for 4 different generation benchmarks. Our experiments show that EDT significantly outperforms the existing strategies across different tasks.
    
[^8]: 为巴西土著语言构建语言学习游戏：一个案例研究

    Building a Language-Learning Game for Brazilian Indigenous Languages: A Case of Study

    [https://arxiv.org/abs/2403.14515](https://arxiv.org/abs/2403.14515)

    本研究尝试构建一款用于巴西土著语言学习的语言学习游戏，并探讨了相关挑战，设计了具有游戏化特点的工具，实现了从依存树库和图比安语言的词汇数据库自动生成语言练习和问题，并强调了与土著社区建立合作关系和以教育为目的的数据收集过程。

    

    在这篇论文中，我们讨论了为巴西土著语言构建语言学习游戏的初步尝试以及围绕此问题的挑战。我们呈现了一种带有游戏化特点的工具设计。然后我们描述了一个过程，从依存树库和一个图比安语言的词汇数据库自动生成语言练习和问题。我们讨论了我们原型的局限性，突出了伦理和实际实施方面的问题。最后，我们得出结论，新的数据收集过程应与土著社区建立合作关系，并以教育为目的。

    arXiv:2403.14515v1 Announce Type: new  Abstract: In this paper we discuss a first attempt to build a language learning game for brazilian indigenous languages and the challenges around it. We present a design for the tool with gamification aspects. Then we describe a process to automatically generate language exercises and questions from a dependency treebank and a lexical database for Tupian languages. We discuss the limitations of our prototype highlighting ethical and practical implementation concerns. Finally, we conclude that new data gathering processes should be established in partnership with indigenous communities and oriented for educational purposes.
    
[^9]: 通过知识编辑实现对大型语言模型的去毒化

    Detoxifying Large Language Models via Knowledge Editing

    [https://arxiv.org/abs/2403.14472](https://arxiv.org/abs/2403.14472)

    本文研究了使用知识编辑技术对大型语言模型进行去毒化，在构建了SafeEdit基准的基础上，提出了一种简单而有效的方法 DINM，可以通过少量调整步骤减少模型的毒性，同时对各种去毒方法的内部机制进行了深入分析。

    

    本文研究了使用知识编辑技术来对大型语言模型（LLMs）进行去毒化。我们构建了一个名为SafeEdit的基准，涵盖了九种不安全类别，具有各种强大的攻击提示，并配备了全面的度量标准进行系统评估。我们进行了实验，比较了知识编辑方法与之前的基准线，结果表明知识编辑有潜力在对LLMs进行去毒化时，在对一般性能的影响相对有限。然后，我们提出了一个简单但有效的基准线，称为通过术中神经监测去毒化（DINM），通过仅一次实例的少量调整步骤减少LLMs的毒性。我们进一步对各种去毒方法的内部机制进行了深入分析，表明先前的方法如SFT和DPO可能仅抑制有毒参数的激活，而DINM则减轻有毒参数的毒性。

    arXiv:2403.14472v1 Announce Type: cross  Abstract: This paper investigates using knowledge editing techniques to detoxify Large Language Models (LLMs). We construct a benchmark, SafeEdit, which covers nine unsafe categories with various powerful attack prompts and equips comprehensive metrics for systematic evaluation. We conduct experiments to compare knowledge editing approaches with previous baselines, indicating that knowledge editing has the potential to efficiently detoxify LLMs with limited impact on general performance. Then, we propose a simple yet effective baseline, dubbed Detoxifying with Intraoperative Neural Monitoring (DINM), to diminish the toxicity of LLMs within a few tuning steps via only one instance. We further provide an in-depth analysis of the internal mechanism for various detoxify approaches, demonstrating that previous methods like SFT and DPO may merely suppress the activations of toxic parameters, while DINM mitigates the toxicity of the toxic parameters to
    
[^10]: ChatGPT备选方案：大语言模型调查

    ChatGPT Alternative Solutions: Large Language Models Survey

    [https://arxiv.org/abs/2403.14469](https://arxiv.org/abs/2403.14469)

    大语言模型在多个领域展现出强大能力，ChatGPT是一个基于LLMs的强大AI聊天机器人，在学术界和工业界的合作推动下，LLM研究领域不断取得新突破，预示着人工智能社区将迎来革命性变革。

    

    在最近的时代，大语言模型（LLMs）的壮丽不仅闪耀在自然语言处理领域，而且也将其光辉洒向广泛的应用领域。这种对LLM能力的显著展示引发了该领域内研究贡献的激增，涵盖了各种主题的多样化光谱。这些贡献涵盖了神经网络架构的进步、上下文长度的增强、模型对齐、训练数据集、基准测试、效率改进等。近年来，学术界和工业界之间形成了动态的协同关系，推动了LLM研究领域向新高度迈进。这一旅程中的一个值得注意的里程碑是ChatGPT的推出，这是一个基于LLMs的强大人工智能聊天机器人，引起了广泛的社会关注。LLMs的不断发展技术已经开始重塑整个人工智能社区的格局，承诺进行革命性的转变。

    arXiv:2403.14469v1 Announce Type: cross  Abstract: In recent times, the grandeur of Large Language Models (LLMs) has not only shone in the realm of natural language processing but has also cast its brilliance across a vast array of applications. This remarkable display of LLM capabilities has ignited a surge in research contributions within this domain, spanning a diverse spectrum of topics. These contributions encompass advancements in neural network architecture, context length enhancements, model alignment, training datasets, benchmarking, efficiency improvements, and more. Recent years have witnessed a dynamic synergy between academia and industry, propelling the field of LLM research to new heights. A notable milestone in this journey is the introduction of ChatGPT, a powerful AI chatbot grounded in LLMs, which has garnered widespread societal attention. The evolving technology of LLMs has begun to reshape the landscape of the entire AI community, promising a revolutionary shift i
    
[^11]: 重新索取的权利：与生成式语言模型对话

    Recourse for reclamation: Chatting with generative language models

    [https://arxiv.org/abs/2403.14467](https://arxiv.org/abs/2403.14467)

    这项工作将算法性索赔的概念延伸到生成式语言模型，为用户提供动态设置毒性过滤阈值的新机制，使他们能够实现他们期望的预测，从而增加他们的代理权。

    

    研究人员和开发者越来越多地依赖毒性评分来调节生成式语言模型的输出，在客户服务、信息检索和内容生成等场景中。然而，毒性评分可能使相关信息无法访问，使文化规范僵化或“价值锁定”，阻碍语言重新索取过程，特别是对边缘化群体。在这项工作中，我们将算法性索赔的概念延伸到生成式语言模型：我们为用户提供一种新颖机制，通过动态设置毒性过滤的阈值，使用户能够实现他们所期望的预测。用户因此相对于与基线系统的交互，可以行使更多的代理权。一项试点研究($n=30$)支持我们提出的索赔机制的潜力，表明与固定阈值毒性过滤模型输出相比，在可用性方面有所改进。未来的工作应该探索毒性评分与语言重新索取之间的交叉点。

    arXiv:2403.14467v1 Announce Type: cross  Abstract: Researchers and developers increasingly rely on toxicity scoring to moderate generative language model outputs, in settings such as customer service, information retrieval, and content generation. However, toxicity scoring may render pertinent information inaccessible, rigidify or "value-lock" cultural norms, and prevent language reclamation processes, particularly for marginalized people. In this work, we extend the concept of algorithmic recourse to generative language models: we provide users a novel mechanism to achieve their desired prediction by dynamically setting thresholds for toxicity filtering. Users thereby exercise increased agency relative to interactions with the baseline system. A pilot study ($n = 30$) supports the potential of our proposed recourse mechanism, indicating improvements in usability compared to fixed-threshold toxicity-filtering of model outputs. Future work should explore the intersection of toxicity sco
    
[^12]: 实现软件定义车辆中的单一系统错觉 -- 自动化、人工智能驱动的工作流程

    Towards Single-System Illusion in Software-Defined Vehicles -- Automated, AI-Powered Workflow

    [https://arxiv.org/abs/2403.14460](https://arxiv.org/abs/2403.14460)

    提出了一种基于模型和特征的新方法，通过迭代搜索和优化的过程中出现最终架构，同时保持单一系统错觉特性，并将现代生成式人工智能引入其中，从而实现对车辆软件系统的自动化开发。

    

    我们提出了一种基于模型和特征的新颖方法来开发车辆软件系统，其中最终架构并未明确定义。相反，它是从一系列搜索和优化的迭代过程中出现的，有特定的约束、需求和硬件架构，同时保持单一系统错觉的特性，其中应用在逻辑上统一的环境中运行。所提出的方法的一个关键点是在循环中包含现代生成式人工智能，特别是大型语言模型（LLMs）。随着该领域的最新进展，我们期望LLMs能够辅助处理需求、生成形式系统模型，以及生成软件部署规范和测试代码。结果管道在很大程度上是自动化的，每一步都会生成反馈。

    arXiv:2403.14460v1 Announce Type: cross  Abstract: We propose a novel model- and feature-based approach to development of vehicle software systems, where the end architecture is not explicitly defined. Instead, it emerges from an iterative process of search and optimization given certain constraints, requirements and hardware architecture, while retaining the property of single-system illusion, where applications run in a logically uniform environment. One of the key points of the presented approach is the inclusion of modern generative AI, specifically Large Language Models (LLMs), in the loop. With the recent advances in the field, we expect that the LLMs will be able to assist in processing of requirements, generation of formal system models, as well as generation of software deployment specification and test code. The resulting pipeline is automated to a large extent, with feedback being generated at each step.
    
[^13]: 生成式语言模型的多级解释

    Multi-Level Explanations for Generative Language Models

    [https://arxiv.org/abs/2403.14459](https://arxiv.org/abs/2403.14459)

    本文提出了一个名为MExGen的通用框架，通过引入标量化概念和多级方法处理生成式语言模型的挑战，证明可以提供更贴近本地的解释。

    

    基于扰动的解释方法，如LIME和SHAP，通常应用于文本分类。本文关注它们如何扩展到生成式语言模型。为了解决文本作为输出和长文本输入的挑战，我们提出了一个名为MExGen的通用框架，可以用不同的归因算法实例化。为了处理文本输出，我们引入了将文本映射到实数的标量化概念，并探讨了多种可能性。为了处理长输入，我们采用多级方法，从粗粒度到细粒度，重点关注具有模型查询线性缩放的算法。我们对基于扰动的归因方法进行了系统评估，包括自动化和人工评估，用于摘要和基于上下文的问答。结果表明，我们的框架可以提供更加贴近本地的生成式输出解释。

    arXiv:2403.14459v1 Announce Type: cross  Abstract: Perturbation-based explanation methods such as LIME and SHAP are commonly applied to text classification. This work focuses on their extension to generative language models. To address the challenges of text as output and long text inputs, we propose a general framework called MExGen that can be instantiated with different attribution algorithms. To handle text output, we introduce the notion of scalarizers for mapping text to real numbers and investigate multiple possibilities. To handle long inputs, we take a multi-level approach, proceeding from coarser levels of granularity to finer ones, and focus on algorithms with linear scaling in model queries. We conduct a systematic evaluation, both automated and human, of perturbation-based attribution methods for summarization and context-grounded question answering. The results show that our framework can provide more locally faithful explanations of generated outputs.
    
[^14]: gTBLS：通过条件问答从文本中生成表格

    gTBLS: Generating Tables from Text by Conditional Question Answering

    [https://arxiv.org/abs/2403.14457](https://arxiv.org/abs/2403.14457)

    gTBLS通过两阶段方法从文本中生成表格，第一阶段推断表格结构，第二阶段利用结构提出问题并通过微调语言模型来回答，能够在零短配置下利用预训练的大型语言模型，改进了先前方法的效果。

    

    arXiv:2403.14457v1 公告类型：新的 摘要：将大段的非结构化文本提炼为结构化、简化的形式，如表格，是一个开放的研究问题。自动生成表格的主要挑战之一是确保其句法有效性。之前的方法通过在Transformer的注意力机制中包含额外的参数，以便注意特定的行和列标题来解决这一挑战。与这种单阶段方法相反，本文提出了一种名为生成式表格（gTBLS）的两阶段方法。第一阶段从文本中推断表格结构（行和列标题）。第二阶段利用这些标题提出问题，并微调因果语言模型来回答这些问题。此外，gTBLS方法易于在零短配置中利用预训练的大型语言模型，为在不能进行微调的情况下生成表格提供了解决方案。gTBLS提高了之前方法达到的效果

    arXiv:2403.14457v1 Announce Type: new  Abstract: Distilling large, unstructured text into a structured, condensed form such as tables is an open research problem. One of the primary challenges in automatically generating tables is ensuring their syntactic validity. Prior approaches address this challenge by including additional parameters in the Transformer's attention mechanism to attend to specific rows and column headers. In contrast to this single-stage method, this paper presents a two-stage approach called Generative Tables (gTBLS). The first stage infers table structure (row and column headers) from the text. The second stage formulates questions using these headers and fine-tunes a causal language model to answer them. Furthermore, the gTBLS approach is amenable to the utilization of pre-trained Large Language Models in a zero-shot configuration, presenting a solution for table generation in situations where fine-tuning is not feasible. gTBLS improves prior approaches by up to 
    
[^15]: 针对翻译过程的翻译技术预测

    Prediction of Translation Techniques for the Translation Process

    [https://arxiv.org/abs/2403.14454](https://arxiv.org/abs/2403.14454)

    该研究探讨了针对翻译过程的翻译技术预测，发现在自动识别和应用适当的翻译技术方面，可以进一步优化机器翻译，取得了82%到93%的预测准确率。

    

    机器翻译（MT）涵盖了一系列旨在提高翻译准确性的方法。相比之下，人工翻译的过程依赖于一系列翻译技术，这些技术对确保语言的充分性和流畅性至关重要。本研究表明，如果能在应用之前自动识别这些翻译技术，它们可能进一步优化机器翻译，以有效地引导翻译过程。研究区分了翻译过程的两种场景：从头开始翻译和后期编辑。针对每种场景，设计了一系列特定实验，以预测最适合的翻译技术。研究结果表明，从头开始翻译的预测准确率达到82％，而后期编辑过程表现出更大的潜力，实现了93％的准确率。

    arXiv:2403.14454v1 Announce Type: new  Abstract: Machine translation (MT) encompasses a variety of methodologies aimed at enhancing the accuracy of translations. In contrast, the process of human-generated translation relies on a wide range of translation techniques, which are crucial for ensuring linguistic adequacy and fluency. This study suggests that these translation techniques could further optimize machine translation if they are automatically identified before being applied to guide the translation process effectively. The study differentiates between two scenarios of the translation process: from-scratch translation and post-editing. For each scenario, a specific set of experiments has been designed to forecast the most appropriate translation techniques. The findings indicate that the predictive accuracy for from-scratch translation reaches 82%, while the post-editing process exhibits even greater potential, achieving an accuracy rate of 93%.
    
[^16]: 超越统计重复：人类和机器无监督学习跨形态过程的毛利语词语分割

    More than Just Statistical Recurrence: Human and Machine Unsupervised Learning of M\=aori Word Segmentation across Morphological Processes

    [https://arxiv.org/abs/2403.14444](https://arxiv.org/abs/2403.14444)

    NMS和Morfessor在分割由不同形态过程形成的单词中表现出成功，NMS对模板和其他形态结构线索也表现出敏感，显示出他们的学习过程不仅仅受到统计重复的影响。

    

    非毛利族裔的新西兰人(NMS)能够以一种与流利的毛利语使用者（Panther等人，2024）非常相似的方式分割毛利语单词。这种能力被认为是通过识别和提取统计重复形式而获得的。本文通过比较NMS和Morfessor对由各种形态过程形成的单词的分割，来检验这一假设。NMS和Morfessor均成功地分割由连接过程（构词和词缀化没有变音的过程）形成的单词，但NMS还成功地分割涉及模板（重复和变音）和其他形态结构线索的单词，这意味着他们的学习过程对不仅仅是统计重复敏感。

    arXiv:2403.14444v1 Announce Type: new  Abstract: Non-M\=aori-speaking New Zealanders (NMS)are able to segment M\=aori words in a highlysimilar way to fluent speakers (Panther et al.,2024). This ability is assumed to derive through the identification and extraction of statistically recurrent forms. We examine this assumption by asking how NMS segmentations compare to those produced by Morfessor, an unsupervised machine learning model that operates based on statistical recurrence, across words formed by a variety of morphological processes. Both NMS and Morfessor succeed in segmenting words formed by concatenative processes (compounding and affixation without allomorphy), but NMS also succeed for words that invoke templates (reduplication and allomorphy) and other cues to morphological structure, implying that their learning process is sensitive to more than just statistical recurrence.
    
[^17]: 语言模型可以降低信息市场的不对称性

    Language Models Can Reduce Asymmetry in Information Markets

    [https://arxiv.org/abs/2403.14443](https://arxiv.org/abs/2403.14443)

    语言模型驱动的智能代理在模拟数字市场中完成买卖信息的任务，通过具备评估信息质量和遗忘能力的特点，成功降低了信息市场的买方检查悖论。

    

    这项工作解决了信息市场中买方检查悖论的问题。买方需要获取信息来确定其价值，而卖方需要限制访问以防止盗窃。为了研究这一问题，我们引入一个开源的模拟数字市场，其中由语言模型驱动的智能代理代表外部参与者买卖信息。这个市场的核心机制在于代理人的双重能力：他们不仅能够评估特权信息的质量，还具备遗忘的能力。这种诱导健忘的能力使供应商可以授予临时访问专有信息的权限，显著降低未经授权的保留风险，同时使代理人能够准确评估信息对特定查询或任务的相关性。为了表现优异，代理必须做出理性决策，战略性地探索市场。

    arXiv:2403.14443v1 Announce Type: new  Abstract: This work addresses the buyer's inspection paradox for information markets. The paradox is that buyers need to access information to determine its value, while sellers need to limit access to prevent theft. To study this, we introduce an open-source simulated digital marketplace where intelligent agents, powered by language models, buy and sell information on behalf of external participants. The central mechanism enabling this marketplace is the agents' dual capabilities: they not only have the capacity to assess the quality of privileged information but also come equipped with the ability to forget. This ability to induce amnesia allows vendors to grant temporary access to proprietary information, significantly reducing the risk of unauthorized retention while enabling agents to accurately gauge the information's relevance to specific queries or tasks. To perform well, agents must make rational decisions, strategically explore the marke
    
[^18]: 一种利用大型语言模型进行设备定向语音检测的多模态方法

    A Multimodal Approach to Device-Directed Speech Detection with Large Language Models

    [https://arxiv.org/abs/2403.14438](https://arxiv.org/abs/2403.14438)

    探索了一种利用大型语言模型进行设备定向语音检测的多模态方法，相比于文本和音频模型，使用多模态信息能够显著提高相等错误率。

    

    虚拟助手的交互通常从预定义触发短语开始，然后是用户命令。为了使与助手的交互更直观，我们探讨了是否可以放弃用户必须用触发短语开始每个命令的要求。我们通过三种方式探索了这个任务：首先，我们仅使用从音频波形中获得的声学信息训练分类器。其次，我们将自动语音识别（ASR）系统的解码器输出，例如1-best假设，作为输入特征输入到大型语言模型（LLM）中。最后，我们探讨了一种多模态系统，将声学和词汇特征以及ASR解码器信号结合在LLM中。使用多模态信息相对于仅文本和仅音频模型提高了相等错误率高达39%和61%。增加LLM的大小并通过低秩调整进行训练进一步减少了相对EER值的减少

    arXiv:2403.14438v1 Announce Type: new  Abstract: Interactions with virtual assistants typically start with a predefined trigger phrase followed by the user command. To make interactions with the assistant more intuitive, we explore whether it is feasible to drop the requirement that users must begin each command with a trigger phrase. We explore this task in three ways: First, we train classifiers using only acoustic information obtained from the audio waveform. Second, we take the decoder outputs of an automatic speech recognition (ASR) system, such as 1-best hypotheses, as input features to a large language model (LLM). Finally, we explore a multimodal system that combines acoustic and lexical features, as well as ASR decoder signals in an LLM. Using multimodal information yields relative equal-error-rate improvements over text-only and audio-only models of up to 39% and 61%. Increasing the size of the LLM and training with low-rank adaption leads to further relative EER reductions o
    
[^19]: 语言模型中的紧急沟通和学习压力：语言进化视角

    Emergent communication and learning pressures in language models: a language evolution perspective

    [https://arxiv.org/abs/2403.14427](https://arxiv.org/abs/2403.14427)

    从语言进化的角度研究了新兴沟通文献，发现其在设计和调整模型以恢复自然语言中初始缺失的语言现象方面表现优秀，揭示了关键压力促使恢复最初不显现的人类模式。

    

    语言模型和人类是两种学习系统。发现或促进二者之间的共同点可能会在我们理解语言的习得和演化方面取得重大突破。许多语言进化理论在很大程度上依赖于学习偏好和学习压力。然而，由于学习压力存在着重大差异，对于人类和机器之间的相似性是否足以启发洞见并值得与人类参与者一起进行测试是值得怀疑的。本文从语言进化的角度审视了新兴沟通文献，这是多智能体强化学习的一个子领域。我们发现，新兴沟通文献在设计和调整模型以恢复自然语言的最初不显现的语言现象方面有杰出表现。根据对文献的简要回顾，我们确定了一些在新兴沟通中恢复最初不显现的人类模式的关键压力。

    arXiv:2403.14427v1 Announce Type: new  Abstract: Language models and humans are two types of learning systems. Finding or facilitating commonalities could enable major breakthroughs in our understanding of the acquisition and evolution of language. Many theories of language evolution rely heavily on learning biases and learning pressures. Yet due to substantial differences in learning pressures, it is questionable whether the similarity between humans and machines is sufficient for insights to carry over and to be worth testing with human participants. Here, we review the emergent communication literature, a subfield of multi-agent reinforcement learning, from a language evolution perspective. We find that the emergent communication literature excels at designing and adapting models to recover initially absent linguistic phenomena of natural languages. Based on a short literature review, we identify key pressures that have recovered initially absent human patterns in emergent communica
    
[^20]: 定位和减轻大型语言模型中的性别偏见

    Locating and Mitigating Gender Bias in Large Language Models

    [https://arxiv.org/abs/2403.14409](https://arxiv.org/abs/2403.14409)

    本研究提出了一种将定位和减轻偏见过程融入统一框架的方法，通过因果中介分析追踪大型语言模型中不同组件激活的因果效应，并提出了一种用于减轻职业代词中性别偏见的基于知识编辑的LSDM方法。

    

    大型语言模型（LLM）在广泛语料库上进行预训练，学习事实和人类认知，其中包含人类偏好。然而，这个过程可能无意中导致这些模型获得社会中普遍存在的偏见和刻板印象。先前的研究通常通过单一视角处理偏见问题，集中于定位或减轻偏见。这种有限的视角在促进偏见研究方面造成了障碍，无法协同互补并逐步积累经验。在这项研究中，我们将定位和减轻偏见的过程融入一个统一框架内。首先，我们使用因果中介分析来跟踪大型语言模型中不同组件激活的因果效应。在此基础上，我们提出LSDM（最小二乘减偏方法），这是一种基于知识编辑的方法，用于减轻职业代词中的性别偏见，和比较

    arXiv:2403.14409v1 Announce Type: cross  Abstract: Large language models(LLM) are pre-trained on extensive corpora to learn facts and human cognition which contain human preferences. However, this process can inadvertently lead to these models acquiring biases and stereotypes prevalent in society. Prior research has typically tackled the issue of bias through a one-dimensional perspective, concentrating either on locating or mitigating it. This limited perspective has created obstacles in facilitating research on bias to synergistically complement and progressively build upon one another. In this study, we integrate the processes of locating and mitigating bias within a unified framework. Initially, we use causal mediation analysis to trace the causal effects of different components' activation within a large language model. Building on this, we propose the LSDM (Least Square Debias Method), a knowledge-editing based method for mitigating gender bias in occupational pronouns, and compa
    
[^21]: 自适应检索增强大型语言模型：通过问题复杂度学习调适

    Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity

    [https://arxiv.org/abs/2403.14403](https://arxiv.org/abs/2403.14403)

    通过新颖的自适应QA框架，根据查询的复杂度动态选择适合的检索增强大型语言模型策略，提高了回答准确性。

    

    检索增强大型语言模型（LLMs）将外部知识库中的非参数知识纳入LLMs，已成为提高多种任务中回答准确性的有希望方法，如问答（QA）。然而，尽管有各种方法处理不同复杂度的查询，但它们要么处理简单查询时产生不必要的计算开销，要么未能充分解决复杂的多步查询；然而，并非所有用户请求都只能划分为简单或复杂类别中的一种。在这项研究中，我们提出了一种新颖的自适应QA框架，该框架可以动态选择从最简单到最复杂的（检索增强）LLMs策略，这取决于查询的复杂度。此外，这个选择过程是通过一个分类器实现的，该分类器是一个较小的LM，训练以预测传入查询的复杂度级别。

    arXiv:2403.14403v1 Announce Type: cross  Abstract: Retrieval-Augmented Large Language Models (LLMs), which incorporate the non-parametric knowledge from external knowledge bases into LLMs, have emerged as a promising approach to enhancing response accuracy in several tasks, such as Question-Answering (QA). However, even though there are various approaches dealing with queries of different complexities, they either handle simple queries with unnecessary computational overhead or fail to adequately address complex multi-step queries; yet, not all user requests fall into only one of the simple or complex categories. In this work, we propose a novel adaptive QA framework, that can dynamically select the most suitable strategy for (retrieval-augmented) LLMs from the simplest to the most sophisticated ones based on the query complexity. Also, this selection process is operationalized with a classifier, which is a smaller LM trained to predict the complexity level of incoming queries with aut
    
[^22]: XLAVS-R: 跨语言视听语音表示学习用于噪声鲁棒语音知觉

    XLAVS-R: Cross-Lingual Audio-Visual Speech Representation Learning for Noise-Robust Speech Perception

    [https://arxiv.org/abs/2403.14402](https://arxiv.org/abs/2403.14402)

    XLAVS-R是一个跨语言视听语音表示学习模型，通过利用有限的多语言AV预训练数据，简化预训练方案，以提高对噪声的鲁棒性，在下游音频-视觉语音识别和翻译任务中比先前最先进技术提升了高达18.5% WER和4.7 BLEU。

    

    语音识别和翻译系统对嘈杂的输入表现不佳，在现实环境中经常出现。通过视觉信号增强这些系统有潜力提高对噪声的鲁棒性。然而，视听（AV）数据仅有限可用，并且比仅有音频资源的语言更少。为填补这一空白，我们提出XLAVS-R，一个跨语言视听语音表示模型，用于超过100种语言的噪声鲁棒语音识别和翻译。它旨在最大程度利用有限的多语言AV预训练数据的益处，通过在音频-仅多语言预训练的基础上构建，并简化现有的预训练方案。在MuAViC基准评估上对XLAVS-R进行了广泛评估，显示了其在下游音频-视觉语音识别和翻译任务上的优势，在给出嘈杂的AV输入时，其优于先前最先进技术最高达到18.5% WER和4.7 BLEU。

    arXiv:2403.14402v1 Announce Type: cross  Abstract: Speech recognition and translation systems perform poorly on noisy inputs, which are frequent in realistic environments. Augmenting these systems with visual signals has the potential to improve robustness to noise. However, audio-visual (AV) data is only available in limited amounts and for fewer languages than audio-only resources. To address this gap, we present XLAVS-R, a cross-lingual audio-visual speech representation model for noise-robust speech recognition and translation in over 100 languages. It is designed to maximize the benefits of limited multilingual AV pre-training data, by building on top of audio-only multilingual pre-training and simplifying existing pre-training schemes. Extensive evaluation on the MuAViC benchmark shows the strength of XLAVS-R on downstream audio-visual speech recognition and translation tasks, where it outperforms the previous state of the art by up to 18.5% WER and 4.7 BLEU given noisy AV inputs
    
[^23]: 使用语言感知调节的精确翻译定制LLMs的构建

    Building Accurate Translation-Tailored LLMs with Language Aware Instruction Tuning

    [https://arxiv.org/abs/2403.14399](https://arxiv.org/abs/2403.14399)

    通过设计两阶段微调算法，本研究旨在提高LLMs遵循翻译指令的能力，尤其是翻译方向信息。

    

    翻译定制的大型语言模型（LLMs）展现出出色的翻译能力，甚至能与商业翻译系统相媲美。然而，误翻译问题仍然存在，特别是对于低资源语言，阻碍我们开发准确的基于LLMs的翻译模型。为了缓解误翻译问题并提升LLMs在翻译上的性能，最近的研究要么设计了先进的提示策略以突出翻译指令的功能，要么利用LLMs的现场学习能力通过少量示范。然而，这些方法基本上没有提高LLMs遵循翻译指令的能力，尤其是语言方向信息。在这项工作中，我们设计了一个两阶段微调算法来提高LLMs的指令遵循能力（特别是翻译方向）。

    arXiv:2403.14399v1 Announce Type: cross  Abstract: Translation-tailored Large language models (LLMs) exhibit remarkable translation capabilities, even competing with supervised-trained commercial translation systems. However, off-target translation remains an unsolved problem, especially for low-resource languages, hindering us from developing accurate LLMs-based translation models. To mitigate the off-target translation problem and enhance the performance of LLMs on translation, recent works have either designed advanced prompting strategies to highlight the functionality of translation instructions or exploited the in-context learning ability of LLMs by feeding few-shot demonstrations. However, these methods essentially do not improve LLM's ability to follow translation instructions, especially the language direction information. In this work, we design a two-stage fine-tuning algorithm to improve the instruction-following ability (especially the translation direction) of LLMs. Speci
    
[^24]: 从大到小：利用弱监督对数学问题进行知识提炼和优化

    From Large to Tiny: Distilling and Refining Mathematical Expertise for Math Word Problems with Weakly Supervision

    [https://arxiv.org/abs/2403.14390](https://arxiv.org/abs/2403.14390)

    提出了一种创新的两阶段框架，巧妙地将数学专业知识从大型语言模型转移到小型语言模型

    

    解决数学问题中高昂注释成本的挑战，通过使用中间方程式进行全面监督的最近研究提出了依赖最终答案作为监督信号的弱监督任务设置。现有的主导方法通常采用各种搜索技术来推断中间方程式，但无法保证其与自然语言描述的语义一致性。大型语言模型（LLM）如ChatGPT的崛起为直接解决数学问题打开了新的可能性。然而，LLMs的计算要求使它们在资源紧张的环境中使用时并不理想。鉴于这些挑战，我们引入了一种创新的两阶段框架，巧妙地将数学专业知识从大型语言模型转移到小型语言模型。在\emph{蒸馏阶段}中，我们提出了一系列满足MWP属性的提取过程

    arXiv:2403.14390v1 Announce Type: new  Abstract: Addressing the challenge of high annotation costs in solving Math Word Problems (MWPs) through full supervision with intermediate equations, recent works have proposed weakly supervised task settings that rely solely on the final answer as a supervised signal. Existing leading approaches typically employ various search techniques to infer intermediate equations, but cannot ensure their semantic consistency with natural language descriptions. The rise of Large Language Models (LLMs) like ChatGPT has opened up new possibilities for addressing MWPs directly. However, the computational demands of LLMs make them less than ideal for use in settings where resources are tight. In light of these challenges, we introduce an innovative two-stage framework that adeptly transfers mathematical Expertise from large to tiny language models. In \emph{Distillation Stage}, we propose a series of extraction processes that satisfy the properties of MWPs to d
    
[^25]: 通过重新表述前缀提示来编辑语言Lodel的知识表示

    Editing Knowledge Representation of Language Lodel via Rephrased Prefix Prompts

    [https://arxiv.org/abs/2403.14381](https://arxiv.org/abs/2403.14381)

    引入了一种名为PSPEM的新方法，通过重新表述前缀提示来编辑语言Lodel的知识表示，解决了知识编辑方法中的低效性、通用性问题，以及提示工程的不透明性。

    

    神经语言模型（LMs）已在广泛的语料库上进行了大量培训，以存储关于文本描述的世界各个方面的事实知识。当前技术通常采用知识编辑方法或特定提示来修改LM输出。然而，现有的知识编辑方法成本高昂且低效，难以产生适当的文本。此外，提示工程是不透明的，需要大量努力找到合适的提示。为解决这些问题，我们引入了一种称为PSPEM（前缀软提示编辑方法）的新方法，可以仅通过一次训练而终身使用。它解决了知识编辑方法中的低效性和通用性问题，并通过自动寻找最佳软提示来克服提示工程的不透明性。具体而言，PSPEM利用提示编码器和编码转换器来精炼提示中的关键信息，并使用提示对齐

    arXiv:2403.14381v1 Announce Type: cross  Abstract: Neural language models (LMs) have been extensively trained on vast corpora to store factual knowledge about various aspects of the world described in texts. Current technologies typically employ knowledge editing methods or specific prompts to modify LM outputs. However, existing knowledge editing methods are costly and inefficient, struggling to produce appropriate text. Additionally, prompt engineering is opaque and requires significant effort to find suitable prompts. To address these issues, we introduce a new method called PSPEM (Prefix Soft Prompt Editing Method), that can be used for a lifetime with just one training. It resolves the inefficiencies and generalizability issues in knowledge editing methods and overcomes the opacity of prompt engineering by automatically seeking optimal soft prompts. Specifically, PSPEM utilizes a prompt encoder and an encoding converter to refine key information in prompts and uses prompt alignmen
    
[^26]: FIT-RAG: 具有事实信息和令牌减少的黑匣子RAG

    FIT-RAG: Black-Box RAG with Factual Information and Token Reduction

    [https://arxiv.org/abs/2403.14374](https://arxiv.org/abs/2403.14374)

    FIT-RAG使用事实信息和令牌减少解决了黑匣子RAG系统中存在的事实信息忽视和令牌浪费问题

    

    由于参数数量庞大，对大型语言模型（LLMs）进行微调以更新长尾或过时知识在许多应用中都是不切实际的。为了避免微调，我们可以将LLM视为一个黑匣子（即，冻结LLM的参数）并增加一个检索增强生成（RAG）系统，即黑匣子RAG。最近，黑匣子RAG在知识密集型任务中取得了成功并引起了广泛关注。现有的黑匣子RAG方法通常微调检索器以迎合LLMs的偏好，并将所有检索到的文档串联在一起作为输入，但存在两个问题:（1）对事实信息的忽视。LLM偏好的文档可能不包含给定问题的事实信息，这可能会误导检索器，并损害黑匣子RAG的有效性;（2）令牌的浪费。简单地将所有检索到的文档串联在一起会带来...

    arXiv:2403.14374v1 Announce Type: new  Abstract: Due to the extraordinarily large number of parameters, fine-tuning Large Language Models (LLMs) to update long-tail or out-of-date knowledge is impractical in lots of applications. To avoid fine-tuning, we can alternatively treat a LLM as a black-box (i.e., freeze the parameters of the LLM) and augment it with a Retrieval-Augmented Generation (RAG) system, namely black-box RAG. Recently, black-box RAG has achieved success in knowledge-intensive tasks and has gained much attention. Existing black-box RAG methods typically fine-tune the retriever to cater to LLMs' preferences and concatenate all the retrieved documents as the input, which suffers from two issues: (1) Ignorance of Factual Information. The LLM preferred documents may not contain the factual information for the given question, which can mislead the retriever and hurt the effectiveness of black-box RAG; (2) Waste of Tokens. Simply concatenating all the retrieved documents brin
    
[^27]: WikiFactDiff: 一个大型、现实且时间上可适应的数据集，用于因果语言模型中的原子事实知识更新

    WikiFactDiff: A Large, Realistic, and Temporally Adaptable Dataset for Atomic Factual Knowledge Update in Causal Language Models

    [https://arxiv.org/abs/2403.14364](https://arxiv.org/abs/2403.14364)

    WikiFactDiff是一个用于因果语言模型中的原子事实知识更新的大型、现实且时间上可适应的数据集，通过描述事实知识在两个日期之间的演变，并提供不同类型基本更新的更新方案和评估指标。

    

    大型语言模型的事实性随时间衰减，因为它们的训练之后的事件对它们来说是“未知”的。为了保持模型的最新，一种方法可能是通过事实更新：即在模型中插入、替换或删除某些简单（原子）事实的任务。为了研究这一任务，我们提出了WikiFactDiff，这是一个描述事实知识在两个日期之间演变的数据集，其中包含了被分为三类的一系列简单事实：新事实、过时事实和静态事实。我们描述了由这三种基本更新类型的各种组合产生的多个更新方案。这些事实由主-谓-宾三元组表示；确实，WikiFactDiff是通过比较Wikidata知识库在2021年1月4日和2023年2月27日期间的状态而构建的。这些事实伴随有用于运行更新算法和评估指标的文本化模板和填空测试。

    arXiv:2403.14364v1 Announce Type: new  Abstract: The factuality of large language model (LLMs) tends to decay over time since events posterior to their training are "unknown" to them. One way to keep models up-to-date could be factual update: the task of inserting, replacing, or removing certain simple (atomic) facts within the model. To study this task, we present WikiFactDiff, a dataset that describes the evolution of factual knowledge between two dates as a collection of simple facts divided into three categories: new, obsolete, and static. We describe several update scenarios arising from various combinations of these three types of basic update. The facts are represented by subject-relation-object triples; indeed, WikiFactDiff was constructed by comparing the state of the Wikidata knowledge base at 4 January 2021 and 27 February 2023. Those fact are accompanied by verbalization templates and cloze tests that enable running update algorithms and their evaluation metrics. Contrary t
    
[^28]: 超越表面相似性：检测金融叙述中微妙的语义转变

    Beyond Surface Similarity: Detecting Subtle Semantic Shifts in Financial Narratives

    [https://arxiv.org/abs/2403.14341](https://arxiv.org/abs/2403.14341)

    本文介绍了Financial-STS任务，旨在衡量金融叙述对之间微妙的语义相似性，提出了一种LLM增强型流程，以优于现有方法的性能。

    

    在本文中，我们介绍了Financial-STS任务，这是一个金融领域特定的自然语言处理任务，旨在衡量金融叙述对之间微妙的语义相似性。这些叙述来自同一公司的财务报表，但对应不同时期，例如年度比较。衡量这些配对叙述之间微妙的语义差异使得市场利益相关者能够评估公司财务和运营情况随时间的变化，这对于金融决策至关重要。我们发现现有的预训练嵌入模型和LLM嵌入在识别这些微妙的金融叙述转变方面表现不足。为填补这一空白，我们提出了一个专门针对Financial-STS任务设计的LLM增强型流程。对一个人工注释的数据集的评估表明，我们提出的方法优于现有在经典STS任务和gen任务上训练的方法

    arXiv:2403.14341v1 Announce Type: new  Abstract: In this paper, we introduce the Financial-STS task, a financial domain-specific NLP task designed to measure the nuanced semantic similarity between pairs of financial narratives. These narratives originate from the financial statements of the same company but correspond to different periods, such as year-over-year comparisons. Measuring the subtle semantic differences between these paired narratives enables market stakeholders to gauge changes over time in the company's financial and operational situations, which is critical for financial decision-making. We find that existing pretrained embedding models and LLM embeddings fall short in discerning these subtle financial narrative shifts. To address this gap, we propose an LLM-augmented pipeline specifically designed for the Financial-STS task. Evaluation on a human-annotated dataset demonstrates that our proposed method outperforms existing methods trained on classic STS tasks and gener
    
[^29]: $\nabla \tau$: 基于梯度且任务无关的机器遗忘

    $\nabla \tau$: Gradient-based and Task-Agnostic machine Unlearning

    [https://arxiv.org/abs/2403.14339](https://arxiv.org/abs/2403.14339)

    $\nabla \tau$ 是一种旨在高效消除部分训练数据影响的机器遗忘优化框架。

    

    机器遗忘是一种有选择性地消除模型训练过程中某些数据示例影响的过程，作为从业者遵守最近的数据保护法规的手段，已经引起了显著关注。然而，现有的遗忘方法面临着关键缺点，包括其成本过高，通常与大量超参数相关，以及仅忘记相对较小数据部分的限制。这经常导致从头开始重新训练模型成为更快速和更有效的解决方案。在本研究中，我们介绍了基于梯度且任务无关的机器遗忘（$\nabla \tau$），这是一种旨在高效消除部分训练数据影响的优化框架。它对待遗忘的数据应用自适应梯度上升，同时对其余数据使用标准梯度下降。$\nabla \tau$相对于现有方法提供了多种优势。

    arXiv:2403.14339v1 Announce Type: cross  Abstract: Machine Unlearning, the process of selectively eliminating the influence of certain data examples used during a model's training, has gained significant attention as a means for practitioners to comply with recent data protection regulations. However, existing unlearning methods face critical drawbacks, including their prohibitively high cost, often associated with a large number of hyperparameters, and the limitation of forgetting only relatively small data portions. This often makes retraining the model from scratch a quicker and more effective solution. In this study, we introduce Gradient-based and Task-Agnostic machine Unlearning ($\nabla \tau$), an optimization framework designed to remove the influence of a subset of training data efficiently. It applies adaptive gradient ascent to the data to be forgotten while using standard gradient descent for the remaining data. $\nabla \tau$ offers multiple benefits over existing approache
    
[^30]: ChainLM：借助改进的思维链提示赋能大型语言模型

    ChainLM: Empowering Large Language Models with Improved Chain-of-Thought Prompting

    [https://arxiv.org/abs/2403.14312](https://arxiv.org/abs/2403.14312)

    提出了CoTGenius框架，用于自动生成优质CoT提示，并通过它创建了庞大的CoT数据集以提升大型语言模型的推理能力

    

    Chain-of-Thought (CoT)提示可以增强大型语言模型（LLMs）的推理能力，是解决复杂推理任务的主要方法之一。现有的CoT合成方法通常专注于更简单的推理任务，因此导致CoT提示质量低且不一致。针对这一挑战，我们对CoT提示进行了实证研究，并提出了CoTGenius，这是一个旨在自动生成优质CoT提示的新型框架。CoTGenius基于三种主要的进化策略发展而来，即复杂化、多样化和具体化，同时配备两种过滤机制：进化成功评判和正确性验证。我们进一步利用CoTGenius创建了一个庞大的CoT数据集，并随后在该数据集上对Llama 2-Chat 7B和13B模型进行微调。最终得到的模型被命名为ChainLM。

    arXiv:2403.14312v1 Announce Type: new  Abstract: Chain-of-Thought (CoT) prompting can enhance the reasoning capabilities of large language models (LLMs), establishing itself as a primary approach to solving complex reasoning tasks. Existing CoT synthesis approaches usually focus on simpler reasoning tasks and thus result in low-quality and inconsistent CoT prompts. In response to this challenge, we present an empirical investigation of CoT prompting and introduce CoTGenius, a novel framework designed for the automatic generation of superior CoT prompts. CoTGenius is developed based on three major evolution strategies, i.e., complicate, diversify, and specify-alongside two filtering mechanisms: evolutionary success judgement and correctness verification. We further employ CoTGenius to create an extensive CoT dataset, and subsequently fine-tune the Llama 2-Chat 7B and 13B models on this dataset. We call the resulting model ChainLM. To deal with the cumulative error issue in reasoning ste
    
[^31]: 在自然语言生成系统评估中是否需要参考？何时何地？

    Is Reference Necessary in the Evaluation of NLG Systems? When and Where?

    [https://arxiv.org/abs/2403.14275](https://arxiv.org/abs/2403.14275)

    本研究通过实验证明，在自然语言生成系统评估中，无参考指标与人类判断更相关，对语言质量的不足更为敏感，但其在不同任务中的有效性存在差异，并受到候选文本质量的影响。

    

    大多数评估自然语言生成系统的自动指标都是基于参考的。然而，在许多应用场景中，由于收集人类注释结果的挑战，缺乏可靠的参考。尽管最近在无参考指标方面有了进展，但何时何地可以将其作为参考指标的替代品还不是很清楚。通过采用多种分析方法，本研究全面评估了两种指标在广泛的自然语言生成任务中的表现，涵盖了八个数据集和八个评估模型。基于扎实的实验，结果显示无参考指标与人类判断之间存在更高的相关性，并对语言质量的不足更为敏感。然而，它们的有效性在不同任务之间变化，并受到候选文本质量的影响。因此，重要的是在使用无参考指标之前评估其性能。

    arXiv:2403.14275v1 Announce Type: new  Abstract: The majority of automatic metrics for evaluating NLG systems are reference-based. However, the challenge of collecting human annotation results in a lack of reliable references in numerous application scenarios. Despite recent advancements in reference-free metrics, it has not been well understood when and where they can be used as an alternative to reference-based metrics. In this study, by employing diverse analytical approaches, we comprehensively assess the performance of both metrics across a wide range of NLG tasks, encompassing eight datasets and eight evaluation models. Based on solid experiments, the results show that reference-free metrics exhibit a higher correlation with human judgment and greater sensitivity to deficiencies in language quality. However, their effectiveness varies across tasks and is influenced by the quality of candidate texts. Therefore, it's important to assess the performance of reference-free metrics bef
    
[^32]: 场景图ViT：端到端的开放词汇视觉关系检测

    Scene-Graph ViT: End-to-End Open-Vocabulary Visual Relationship Detection

    [https://arxiv.org/abs/2403.14270](https://arxiv.org/abs/2403.14270)

    提出了一种简单高效的无解码器架构，用于开放词汇的视觉关系检测，通过Transformer-based图像编码器隐式建模对象之间的关系，使用注意力机制提取关系信息，在混合数据上进行端到端训练，实现了最先进的关系检测性能。

    

    视觉关系检测旨在识别图像中的对象及其关系。以往的方法通过在现有目标检测架构中添加单独的关系模块或解码器来处理此任务。这种分离增加了复杂性，阻碍了端到端训练，限制了性能。我们提出了一种简单且高效的无解码器架构，用于开放词汇的视觉关系检测。我们的模型由基于Transformer的图像编码器组成，将对象表示为标记，并隐含地建模它们的关系。为了提取关系信息，我们引入了一个注意力机制，选择可能形成关系的对象对。我们提供了一个单阶段的训练方法，可以在混合对象和关系检测数据上训练此模型。我们的方法在Visual Genome和大词汇GQA基准测试上实现了最先进的关系检测性能，可实现实时性。

    arXiv:2403.14270v1 Announce Type: cross  Abstract: Visual relationship detection aims to identify objects and their relationships in images. Prior methods approach this task by adding separate relationship modules or decoders to existing object detection architectures. This separation increases complexity and hinders end-to-end training, which limits performance. We propose a simple and highly efficient decoder-free architecture for open-vocabulary visual relationship detection. Our model consists of a Transformer-based image encoder that represents objects as tokens and models their relationships implicitly. To extract relationship information, we introduce an attention mechanism that selects object pairs likely to form a relationship. We provide a single-stage recipe to train this model on a mixture of object and relationship detection data. Our approach achieves state-of-the-art relationship detection performance on Visual Genome and on the large-vocabulary GQA benchmark at real-tim
    
[^33]: 基于LLM的专利矛盾提取

    LLM-based Extraction of Contradictions from Patents

    [https://arxiv.org/abs/2403.14258](https://arxiv.org/abs/2403.14258)

    专利和技术矛盾提取是创新产品开发中的重要灵感来源，而基于LLM的方法可以帮助超越传统关键词方法，实现专利摘要与关键概念提取。

    

    从1950年代起，TRIZ就表明专利及其解决的技术矛盾是创新产品开发中重要的灵感来源。然而，TRIZ是一种基于历史专利分析的启发式方法，并未利用当前专利中日益增多的最新技术解决方案。由于专利数量庞大、长度长，且复杂性高，现代专利检索和专利分析需要超越基于关键词的方法。最近专利检索和分析的进展主要集中在基于神经网络AI变压器语言模型（如Google BERT）的密集向量上。例如，它们用于密集检索、问题回答、摘要和关键概念提取。在专利摘要和关键概念提取方法中的一个研究重点是通用的创新概念，以及TRIZ概念。

    arXiv:2403.14258v1 Announce Type: new  Abstract: Already since the 1950s TRIZ shows that patents and the technical contradictions they solve are an important source of inspiration for the development of innovative products. However, TRIZ is a heuristic based on a historic patent analysis and does not make use of the ever-increasing number of latest technological solutions in current patents. Because of the huge number of patents, their length, and, last but not least, their complexity there is a need for modern patent retrieval and patent analysis to go beyond keyword-oriented methods. Recent advances in patent retrieval and analysis mainly focus on dense vectors based on neural AI Transformer language models like Google BERT. They are, for example, used for dense retrieval, question answering or summarization and key concept extraction. A research focus within the methods for patent summarization and key concept extraction are generic inventive concepts respectively TRIZ concepts like
    
[^34]: ERD：一个用于改善认知失调分类的LLM推理框架

    ERD: A Framework for Improving LLM Reasoning for Cognitive Distortion Classification

    [https://arxiv.org/abs/2403.14255](https://arxiv.org/abs/2403.14255)

    ERD提出了一个框架，通过提取与认知失调相关的部分和通过多个代理人进行推理步骤的辩论，改进了基于LLM的认知失调分类性能。

    

    使用大型语言模型（LLMs）改进心理治疗的可访问性近年来受到了重视。从受访者的话语中识别认知失调可以是心理治疗的重要组成部分，特别是对于认知行为疗法。在本文中，我们提出了ERD，通过额外模块的（1）提取与认知失调相关的部分和（2）通过多个代理人进行推理步骤的辩论，提高了基于LLM的认知失调分类性能。我们在一个公共数据集上的实验结果显示，ERD提高了多类F1分数以及二元特异性分数。关于后者的分数，我们的方法在向LLMs提供多代理人辩论摘要时有效地消除了基准方法的偏见，尤其是当该摘要被提供给LLMs时。

    arXiv:2403.14255v1 Announce Type: new  Abstract: Improving the accessibility of psychotherapy with the aid of Large Language Models (LLMs) is garnering a significant attention in recent years. Recognizing cognitive distortions from the interviewee's utterances can be an essential part of psychotherapy, especially for cognitive behavioral therapy. In this paper, we propose ERD, which improves LLM-based cognitive distortion classification performance with the aid of additional modules of (1) extracting the parts related to cognitive distortion, and (2) debating the reasoning steps by multiple agents. Our experimental results on a public dataset show that ERD improves the multi-class F1 score as well as binary specificity score. Regarding the latter score, it turns out that our method is effective in debiasing the baseline method which has high false positive rate, especially when the summary of multi-agent debate is provided to LLMs.
    
[^35]: K-Act2Emo：针对间接情感表达的韩国常识知识图谱

    K-Act2Emo: Korean Commonsense Knowledge Graph for Indirect Emotional Expression

    [https://arxiv.org/abs/2403.14253](https://arxiv.org/abs/2403.14253)

    介绍了针对间接情感表达的韩国常识知识图谱K-Act2Emo，通过实验验证其在训练情感推断模型方面的有效性，微调后的BART知识模型表现优异，达到了与GPT-4 Turbo相媲美的性能水平。

    

    在许多文学作品中，情绪通过对行为、面部表情和外表的描述间接传达，需要对叙事理解进行情感推断。在本文中，我们介绍了K-Act2Emo，一个包含1,900种间接情感表达和可推断出的情绪的韩国常识知识图谱。我们将推理类型分为正面情境的推理、负面情境的推理和表达不是情感线索时的推理。与现有的常识知识图谱不同，K-Act2Emo专注于情感背景，实验结果证实了它对训练情感推断模型的有效性。值得注意的是，使用K-Act2Emo微调的基于BART的知识模型胜过了各种现有的韩国大型语言模型，在性能上达到了与GPT-4 Turbo可比的水平。

    arXiv:2403.14253v1 Announce Type: new  Abstract: In many literary texts, emotions are indirectly conveyed through descriptions of actions, facial expressions, and appearances, necessitating emotion inference for narrative understanding. In this paper, we introduce K-Act2Emo, a Korean commonsense knowledge graph (CSKG) comprising 1,900 indirect emotional expressions and the emotions inferable from them. We categorize reasoning types into inferences in positive situations, inferences in negative situations, and inferences when expressions do not serve as emotional cues. Unlike existing CSKGs, K-Act2Emo specializes in emotional contexts, and experimental results validate its effectiveness for training emotion inference models. Significantly, the BART-based knowledge model fine-tuned with K-Act2Emo outperforms various existing Korean large language models, achieving performance levels comparable to GPT-4 Turbo.
    
[^36]: LayoutLLM：大规模语言模型指令调整用于视觉丰富文档理解

    LayoutLLM: Large Language Model Instruction Tuning for Visually Rich Document Understanding

    [https://arxiv.org/abs/2403.14252](https://arxiv.org/abs/2403.14252)

    提出了一种新的LayoutLLM模型，通过结合大规模语言模型和文档图像理解的优势，实现了对文档图像的理解。

    

    这篇论文提出了LayoutLLM，一种更灵活的文档分析方法，用于理解图像文档。视觉丰富文档理解任务，如文档图像分类和信息提取，由于其重要性而受到重视。现有方法旨在通过整合对图像、文本和布局结构的预训练意识来提升文档理解能力。然而，这些方法需要针对每个任务和数据集进行微调，而且模型训练和操作成本高昂。为了克服这一限制，我们提出了一种新的LayoutLLM，将这些与大规模语言模型（LLMs）相集成。通过利用现有研究在文档图像理解和LLMs卓越的语言理解能力方面的优势，所提出的模型在多模态指令数据集的微调下，可以通过单个模型理解文档图像。

    arXiv:2403.14252v1 Announce Type: cross  Abstract: This paper proposes LayoutLLM, a more flexible document analysis method for understanding imaged documents. Visually Rich Document Understanding tasks, such as document image classification and information extraction, have gained significant attention due to their importance. Existing methods have been developed to enhance document comprehension by incorporating pre-training awareness of images, text, and layout structure. However, these methods require fine-tuning for each task and dataset, and the models are expensive to train and operate. To overcome this limitation, we propose a new LayoutLLM that integrates these with large-scale language models (LLMs). By leveraging the strengths of existing research in document image understanding and LLMs' superior language understanding capabilities, the proposed model, fine-tuned with multimodal instruction datasets, performs an understanding of document images in a single model. Our experime
    
[^37]: Dermacen Analytica: 一种将多模式大型语言模型与机器学习相整合的新方法论在远程皮肤病学中的应用

    Dermacen Analytica: A Novel Methodology Integrating Multi-Modal Large Language Models with Machine Learning in tele-dermatology

    [https://arxiv.org/abs/2403.14243](https://arxiv.org/abs/2403.14243)

    本文提出了一种新方法，在远程皮肤病学中整合了多模式大型语言模型与机器学习，旨在通过综合利用大型语言模型、Transformer视觉模型和复杂的机器学习工具，辅助诊断皮肤病变和其他皮肤状况，从而全面解决该领域的诊断流程。

    

    人工智能的崛起在医学发现、诊断和患者管理领域带来了巨大的希望。然而，所有医学领域的巨大复杂性要求采用一种更复杂的方法，结合机器学习算法、分类器、分割算法以及近来的大型语言模型。本文描述、实施和评估了一种基于人工智能的系统和方法论，旨在协助皮肤病学领域的皮肤病变和其他皮肤状况的诊断过程，旨在全面解决该领域的诊断流程。该工作流程整合了大型语言、基于Transformer的视觉模型和复杂的机器学习工具。这种全面的方法实现了对皮肤病变的微妙解释，模拟并促进了皮肤科医生的工作流程。我们通过彻底的交叉模式评估了我们提出的方法论。

    arXiv:2403.14243v1 Announce Type: cross  Abstract: The rise of Artificial Intelligence creates great promise in the field of medical discovery, diagnostics and patient management. However, the vast complexity of all medical domains require a more complex approach that combines machine learning algorithms, classifiers, segmentation algorithms and, lately, large language models. In this paper, we describe, implement and assess an Artificial Intelligence-empowered system and methodology aimed at assisting the diagnosis process of skin lesions and other skin conditions within the field of dermatology that aims to holistically address the diagnostic process in this domain. The workflow integrates large language, transformer-based vision models and sophisticated machine learning tools. This holistic approach achieves a nuanced interpretation of dermatological conditions that simulates and facilitates a dermatologist's workflow. We assess our proposed methodology through a thorough cross-mode
    
[^38]: 反思反馈中的强化学习（RLRF）：通过细粒度自我反思对LLMs进行调整和改进

    Reinforcement Learning from Reflective Feedback (RLRF): Aligning and Improving LLMs via Fine-Grained Self-Reflection

    [https://arxiv.org/abs/2403.14238](https://arxiv.org/abs/2403.14238)

    RLRF提出了一种新颖的框架，通过细粒度反馈和自我反思机制，可以改进LLMs的核心能力，超越表面调整。

    

    尽管RLHF在将LLMs与人类偏好进行调整方面很有前景，但往往会导致表面调整，优先考虑风格变化而非改善LLMs的下游性能。未明确规定的偏好可能会模糊对齐模型的方向。缺乏探索会限制识别出改善模型的理想输出。为了克服这些挑战，我们提出了一个新颖的框架：反思反馈中的强化学习（RLRF），该框架利用基于详细标准的细粒度反馈，以改进LLMs的核心能力。RLRF采用自我反思机制系统地探索和完善LLMs的回应，然后通过RL算法对模型进行微调，同时结合有希望的回应。在Just-Eval、Factuality和Mathematical Reasoning等实验中，我们展示了RLRF的功效和超越表面调整的转变潜力。

    arXiv:2403.14238v1 Announce Type: cross  Abstract: Despite the promise of RLHF in aligning LLMs with human preferences, it often leads to superficial alignment, prioritizing stylistic changes over improving downstream performance of LLMs. Underspecified preferences could obscure directions to align the models. Lacking exploration restricts identification of desirable outputs to improve the models. To overcome these challenges, we propose a novel framework: Reinforcement Learning from Reflective Feedback (RLRF), which leverages fine-grained feedback based on detailed criteria to improve the core capabilities of LLMs. RLRF employs a self-reflection mechanism to systematically explore and refine LLM responses, then fine-tuning the models via a RL algorithm along with promising responses. Our experiments across Just-Eval, Factuality, and Mathematical Reasoning demonstrate the efficacy and transformative potential of RLRF beyond superficial surface-level adjustment.
    
[^39]: 一个统一的模型编辑框架

    A Unified Framework for Model Editing

    [https://arxiv.org/abs/2403.14236](https://arxiv.org/abs/2403.14236)

    这个统一框架结合了“定位和编辑”模型编辑技术，最大化保留某些向量表示并记忆新事实信息。

    

    模型编辑是一个不断发展的领域，专注于更新模型中嵌入的知识。在各种方法中，ROME和MEMIT作为主要的“定位和编辑”模型编辑技术脱颖而出。而MEMIT可以批量编辑记忆，ROME则一次只能改变一个事实。本文引入了一个统一的框架，将ROME和MEMIT纳入一个单一的概念框架，优化同一目标，我们称之为“保存-记忆”目标。该目标旨在在记忆新事实信息的同时保留某些选定向量的表示。具体来说，ROME使用等式约束优化此目标，而MEMIT采用更灵活的最小二乘约束。除了批量编辑外，MEMIT还可以在多个层面编辑模型。我们将编辑的分布从多个层面分开，区别于优化目标。

    arXiv:2403.14236v1 Announce Type: cross  Abstract: Model editing is a growing area focused on updating the knowledge embedded within models. Among the various methodologies, ROME and MEMIT stand out as leading "locate-and-edit" model editing techniques. While MEMIT enables batched editing of memories, ROME is limited to changing one fact at a time. This paper introduces a unifying framework that brings ROME and MEMIT under a single conceptual umbrella, optimizing for the same goal, which we call the "preservation-memorization" objective. This objective aims to preserve the representations of certain selected vectors while memorizing the representations of new factual information. Specifically, ROME optimizes this objective using an equality constraint, whereas MEMIT employs a more flexible least-square constraint. In addition to making batched edits, MEMIT also edits the model at multiple layers. We disentangle the distribution of edits to multiple layers from the optimization objectiv
    
[^40]: 大规模标签解释学习用于少样本命名实体识别

    Large-Scale Label Interpretation Learning for Few-Shot Named Entity Recognition

    [https://arxiv.org/abs/2403.14222](https://arxiv.org/abs/2403.14222)

    通过大规模扩展实体类型数量和粒度，研究了强语义先验对于解释实体类型文本化描述的影响。

    

    少样本命名实体识别（NER）仅使用少量注释示例在文本中检测命名实体。 一种有前途的研究方向是利用每种实体类型的自然语言描述：例如，常见标签PER可能被表达为“人物实体”。 在初始标签解释学习阶段，模型学习解释这些实体类型的文本化描述。 在随后的少样本标签集扩展阶段，该模型然后给出先前未见实体类型的描述（例如“音乐专辑”）以及可选的少量训练示例，执行该类型的少样本NER。 在本文中，我们系统地探讨了强语义先验对于通过大规模扩展用于标签解释学习的实体类型数量和粒度的影响。 为此，我们利用实体链接基准来创建一个数据集...

    arXiv:2403.14222v1 Announce Type: new  Abstract: Few-shot named entity recognition (NER) detects named entities within text using only a few annotated examples. One promising line of research is to leverage natural language descriptions of each entity type: the common label PER might, for example, be verbalized as ''person entity.'' In an initial label interpretation learning phase, the model learns to interpret such verbalized descriptions of entity types. In a subsequent few-shot tagset extension phase, this model is then given a description of a previously unseen entity type (such as ''music album'') and optionally a few training examples to perform few-shot NER for this type. In this paper, we systematically explore the impact of a strong semantic prior to interpret verbalizations of new entity types by massively scaling up the number and granularity of entity types used for label interpretation learning. To this end, we leverage an entity linking benchmark to create a dataset with
    
[^41]: 通过一致性对齐提高大型语言模型的鲁棒性

    Improving the Robustness of Large Language Models via Consistency Alignment

    [https://arxiv.org/abs/2403.14221](https://arxiv.org/abs/2403.14221)

    通过一致性对齐训练的两阶段框架，有助于提高大型语言模型的鲁棒性和对指令的理解。

    

    大型语言模型(LLMs)在遵循用户指令和生成有用响应方面取得了巨大成功。然而，它们的鲁棒性仍远未达到最佳状态，因为可能由于口头指令中的细微更改而产生明显不一致的响应。最近的文献探讨了这种不一致性问题，强调了继续改善响应生成的鲁棒性的重要性。然而，对系统性分析和解决方案仍然缺乏。在本文中，我们定量定义了不一致性问题，并提出了一个由指令增强监督微调和一致性对齐训练组成的两阶段训练框架。第一阶段通过类似指令增强帮助模型在遵循指令时泛化。在第二阶段，我们提高了多样性，并帮助模型理解哪些响应与人类期望更一致。

    arXiv:2403.14221v1 Announce Type: new  Abstract: Large language models (LLMs) have shown tremendous success in following user instructions and generating helpful responses. Nevertheless, their robustness is still far from optimal, as they may generate significantly inconsistent responses due to minor changes in the verbalized instructions. Recent literature has explored this inconsistency issue, highlighting the importance of continued improvement in the robustness of response generation. However, systematic analysis and solutions are still lacking. In this paper, we quantitatively define the inconsistency problem and propose a two-stage training framework consisting of instruction-augmented supervised fine-tuning and consistency alignment training. The first stage helps a model generalize on following instructions via similar instruction augmentations. In the second stage, we improve the diversity and help the model understand which responses are more aligned with human expectations b
    
[^42]: 儿童-看护者对话中语法正确性的自动注释

    Automatic Annotation of Grammaticality in Child-Caregiver Conversations

    [https://arxiv.org/abs/2403.14208](https://arxiv.org/abs/2403.14208)

    提出了针对儿童-看护者对话中上下文依赖语法的编码方案，并训练并评估了一系列自然语言处理模型，结果显示经过微调的Transformer模型表现最佳。

    

    文法的习得一直是语言习得理论之间的一项核心问题。为了在儿童-看护者对话中进行更快速、更可重复、更大规模的语法研究，自动注释工具可以为繁琐的手动注释提供有效的替代方法。我们提出了一个针对儿童-看护者对话中的上下文依赖语法的编码方案，并对大量转录对话语料库中的4000多个话语进行了注释。基于这些注释，我们训练和评估了一系列自然语言处理模型。我们的结果表明，经过微调的基于Transformer的模型表现最佳，达到了人类之间的注释一致性水平。

    arXiv:2403.14208v1 Announce Type: new  Abstract: The acquisition of grammar has been a central question to adjudicate between theories of language acquisition. In order to conduct faster, more reproducible, and larger-scale corpus studies on grammaticality in child-caregiver conversations, tools for automatic annotation can offer an effective alternative to tedious manual annotation. We propose a coding scheme for context-dependent grammaticality in child-caregiver conversations and annotate more than 4,000 utterances from a large corpus of transcribed conversations. Based on these annotations, we train and evaluate a range of NLP models. Our results show that fine-tuned Transformer-based models perform best, achieving human inter-annotation agreement levels.As a first application and sanity check of this tool, we use the trained models to annotate a corpus almost two orders of magnitude larger than the manually annotated data and verify that children's grammaticality shows a steady in
    
[^43]: 在提取式开放域问答中，训练解码器中的融合技术时，上下文质量很重要

    Context Quality Matters in Training Fusion-in-Decoder for Extractive Open-Domain Question Answering

    [https://arxiv.org/abs/2403.14197](https://arxiv.org/abs/2403.14197)

    论文探讨了在训练 Fusion-in-Decoder（FiD）时上下文数量和质量对提取式开放域问答任务性能的影响，实验结果表明FiD模型在训练过程中可能会过拟合到上下文质量，导致在不同质量上下文评估时表现出亚优性能。

    

    检索增强生成模型通过在生成过程中提供额外相关的外部知识（上下文）来增强语言模型中编码的知识。尽管已经显示出上下文的数量和质量会影响检索增强生成模型在推断过程中的性能，但有限的研究探讨了这些特征如何影响模型训练。本文探讨了模型训练过程中上下文数量和质量如何影响融合解码器（FiD）在提取式开放域问答任务中的性能，FiD是目前的检索增强生成模型。实验结果表明，FiD模型在训练过程中过拟合到上下文质量，并在不同上下文质量的评估中表现出亚优性能。通过实验结果，我们还揭示了使用不同上下文质量训练的FiD模型具有不同的交叉注意力分布模式。

    arXiv:2403.14197v1 Announce Type: new  Abstract: Retrieval-augmented generation models augment knowledge encoded in a language model by providing additional relevant external knowledge (context) during generation. Although it has been shown that the quantity and quality of context impact the performance of retrieval-augmented generation models during inference, limited research explores how these characteristics affect model training. This paper explores how context quantity and quality during model training affect the performance of Fusion-in-Decoder (FiD), the state-of-the-art retrieval-augmented generation model, in extractive open-domain question answering tasks. Experimental results suggest that FiD models overfit to context quality during training and show suboptimal performance when evaluated on different context quality. Through the experimental results, we also reveal FiD models trained with different context quality have different cross-attention distribution patterns. Specif
    
[^44]: 通过知识蒸馏教授大型语言模型解释多模态虚假信息

    MMIDR: Teaching Large Language Model to Interpret Multimodal Misinformation via Knowledge Distillation

    [https://arxiv.org/abs/2403.14171](https://arxiv.org/abs/2403.14171)

    提出了MMIDR框架，用于教导大型语言模型提供解释其多模态虚假信息决策过程的文本解释。

    

    最近，多模态虚假信息的自动检测引起了广泛关注。然而，强大的大型语言模型（LLMs）在多模态虚假信息检测方面的潜力仍未得到充分发掘。此外，如何以成本效益和易于访问的方式教导LLMs解释多模态虚假信息仍然是一个悬而未决的问题。为了解决这个问题，我们提出了MMIDR，这是一个旨在教导LLMs为其多模态虚假信息决策过程提供流畅和高质量文本解释的框架。为了将多模态虚假信息转化为适当的指令执行格式，我们提出了一个数据增强视角和管道。该管道包括一个视觉信息处理模块和一个证据检索模块。随后，我们使用处理过的内容提示专有的LLMs为解释多模态虚假信息的真实性提取原因。

    arXiv:2403.14171v1 Announce Type: new  Abstract: Automatic detection of multimodal misinformation has gained a widespread attention recently. However, the potential of powerful Large Language Models (LLMs) for multimodal misinformation detection remains underexplored. Besides, how to teach LLMs to interpret multimodal misinformation in cost-effective and accessible way is still an open question. To address that, we propose MMIDR, a framework designed to teach LLMs in providing fluent and high-quality textual explanations for their decision-making process of multimodal misinformation. To convert multimodal misinformation into an appropriate instruction-following format, we present a data augmentation perspective and pipeline. This pipeline consists of a visual information processing module and an evidence retrieval module. Subsequently, we prompt the proprietary LLMs with processed contents to extract rationales for interpreting the authenticity of multimodal misinformation. Furthermore
    
[^45]: M$^3$AV：一种多模态、多体裁和多用途的音视频学术讲座数据集

    M$^3$AV: A Multimodal, Multigenre, and Multipurpose Audio-Visual Academic Lecture Dataset

    [https://arxiv.org/abs/2403.14168](https://arxiv.org/abs/2403.14168)

    提出了一种新颖的M$^3$AV音视频学术讲座数据集，包含多模态、多体裁和高质量人工注释，可用于多种音视频识别任务

    

    arXiv:2403.14168v1 公告类型：新摘要：发布开源学术视频录像是在线分享知识的一种新兴和普遍方法。这些视频包含丰富的多模态信息，包括演讲者的语音、面部和身体动作，以及幻灯片中的文本和图片，甚至可能包括论文内容。尽管已构建和发布了多个学术视频数据集，但很少有数据集支持多模态内容识别和理解任务，部分原因是缺乏高质量的人工注释。在本文中，我们提出了一种新颖的多模态、多体裁和多用途的音视频学术讲座数据集(M$^3$AV)，该数据集包括来自五个来源的近367小时的视频，涵盖计算机科学、数学以及医学和生物学等主题。通过对言语和书面文字（尤其是高价值名称实体）的高质量人工注释，该数据集可用于多种音视频识别

    arXiv:2403.14168v1 Announce Type: new  Abstract: Publishing open-source academic video recordings is an emergent and prevalent approach to sharing knowledge online. Such videos carry rich multimodal information including speech, the facial and body movements of the speakers, as well as the texts and pictures in the slides and possibly even the papers. Although multiple academic video datasets have been constructed and released, few of them support both multimodal content recognition and understanding tasks, which is partially due to the lack of high-quality human annotations. In this paper, we propose a novel multimodal, multigenre, and multipurpose audio-visual academic lecture dataset (M$^3$AV), which has almost 367 hours of videos from five sources covering computer science, mathematics, and medical and biology topics. With high-quality human annotations of the spoken and written words, in particular high-valued name entities, the dataset can be used for multiple audio-visual recogn
    
[^46]: C-TPT：通过文本特征离散性的校准测试时提示调整视觉-语言模型

    C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion

    [https://arxiv.org/abs/2403.14119](https://arxiv.org/abs/2403.14119)

    本文研究了在测试时提示调整过程中通过利用CLIP的固有属性来探讨校准的方法，发现提示选择显著影响了CLIP中的校准，其中导致更高文本特征离散性的提示会产生更好校准的预测。

    

    在深度学习中，测试时适应已经引起了人们的关注，作为一种在不需要标记数据的情况下对模型进行微调的方法。一个主要的例证是最近提出的用于大规模视觉-语言模型（如CLIP）的测试时提示调整。然而，这些提示主要是为了提高准确性而开发的，忽视了校准的重要性——量化预测不确定性的关键方面。然而，传统的校准方法依赖大量标记数据，这使得它们在测试时场景下不切实际。为此，本文通过利用CLIP的固有属性，在测试时提示调整过程中探讨校准。通过一系列观察，我们发现提示选择显著影响了CLIP中的校准，其中导致更高文本特征离散性的提示会产生更好校准的预测。

    arXiv:2403.14119v1 Announce Type: cross  Abstract: In deep learning, test-time adaptation has gained attention as a method for model fine-tuning without the need for labeled data. A prime exemplification is the recently proposed test-time prompt tuning for large-scale vision-language models such as CLIP. Unfortunately, these prompts have been mainly developed to improve accuracy, overlooking the importance of calibration-a crucial aspect for quantifying prediction uncertainty. However, traditional calibration methods rely on substantial amounts of labeled data, making them impractical for test-time scenarios. To this end, this paper explores calibration during test-time prompt tuning by leveraging the inherent properties of CLIP. Through a series of observations, we find that the prompt choice significantly affects the calibration in CLIP, where the prompts leading to higher text feature dispersion result in better-calibrated predictions. Introducing the Average Text Feature Dispersion
    
[^47]: 从手工特征到LLMs：机器翻译质量评估简要调查

    From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation

    [https://arxiv.org/abs/2403.14118](https://arxiv.org/abs/2403.14118)

    本文对机器翻译质量评估领域的发展历史进行了全面概述，将方法分为基于手工特征、深度学习和大型语言模型的三类，并探讨了未来研究方向。

    

    机器翻译质量评估（MTQE）是在实时环境中估计机器翻译文本质量的任务，无需参考翻译，对于MT的发展至关重要。本文对QE数据集、标注方法、共享任务、方法论、挑战和未来研究方向进行了全面概述。它从介绍QE的背景和意义开始，然后解释了词级QE、句级QE、文档级QE和可解释QE的概念和评估指标。文章将QE发展历史中产生的方法分为基于手工特征、深度学习和大型语言模型（LLMs）的方法，进一步将基于深度学习的方法分为经典深度学习和包含预训练语言模型的方法。

    arXiv:2403.14118v1 Announce Type: new  Abstract: Machine Translation Quality Estimation (MTQE) is the task of estimating the quality of machine-translated text in real time without the need for reference translations, which is of great importance for the development of MT. After two decades of evolution, QE has yielded a wealth of results. This article provides a comprehensive overview of QE datasets, annotation methods, shared tasks, methodologies, challenges, and future research directions. It begins with an introduction to the background and significance of QE, followed by an explanation of the concepts and evaluation metrics for word-level QE, sentence-level QE, document-level QE, and explainable QE. The paper categorizes the methods developed throughout the history of QE into those based on handcrafted features, deep learning, and Large Language Models (LLMs), with a further division of deep learning-based methods into classic deep learning and those incorporating pre-trained lang
    
[^48]: 一种智能交互式写作助手的设计空间

    A Design Space for Intelligent and Interactive Writing Assistants

    [https://arxiv.org/abs/2403.14117](https://arxiv.org/abs/2403.14117)

    通过提出一种设计空间，帮助研究人员和设计师在多维空间中检验和探索智能交互式写作助手的各种可能性。

    

    在我们这个快速科技发展的时代，写作助手的研究领域已经在各个研究社区中变得日益分散。我们通过提出一种设计空间来解决这一挑战，作为一种结构化的方法来检验和探索智能交互式写作助手的多维空间。通过大型社区协作，我们探讨了写作助手的五个方面：任务、用户、技术、交互和生态系统。在每个方面，我们通过系统审阅115篇论文定义了维度（即方面的基本组成部分）和代码（即每个维度的可能选项）。我们的设计空间旨在为研究人员和设计师提供一个实用工具，帮助他们导航、理解和比较写作助手的各种可能性，并帮助构思和设计新的写作助手。

    arXiv:2403.14117v1 Announce Type: cross  Abstract: In our era of rapid technological advancement, the research landscape for writing assistants has become increasingly fragmented across various research communities. We seek to address this challenge by proposing a design space as a structured way to examine and explore the multidimensional space of intelligent and interactive writing assistants. Through a large community collaboration, we explore five aspects of writing assistants: task, user, technology, interaction, and ecosystem. Within each aspect, we define dimensions (i.e., fundamental components of an aspect) and codes (i.e., potential options for each dimension) by systematically reviewing 115 papers. Our design space aims to offer researchers and designers a practical tool to navigate, comprehend, and compare the various possibilities of writing assistants, and aid in the envisioning and design of new writing assistants.
    
[^49]: 评估大型语言模型中文常识推理能力：从中文特定到推理-记忆关联

    Benchmarking Chinese Commonsense Reasoning of LLMs: From Chinese-Specifics to Reasoning-Memorization Correlations

    [https://arxiv.org/abs/2403.14112](https://arxiv.org/abs/2403.14112)

    CHARM是第一个用于全面深入评估大型语言模型中文常识推理能力的基准，研究发现LLM的语言导向性和任务领域会影响提示策略的有效性，并指出一些LLMs在记忆中文常识方面存在困难，而其他一些LLMs在推理上表现存在差异。

    

    我们介绍了CHARM，这是第一个用于全面深入评估大型语言模型（LLMs）中文常识推理能力的基准，涵盖了全球已知和中文特有的常识。在CHARM上评估了7个英文和12个中文定向LLMs，采用了5种代表性提示策略来提高LLMs的推理能力，比如思维链。我们的研究结果表明，LLM的语言导向性和任务领域影响了提示策略的有效性，这丰富了以往的研究结果。我们构建了紧密关联的推理和记忆任务，并发现一些LLMs在记忆中文常识方面存在困难，影响了它们的推理能力，而其他一些LLMs在推理上表现存在差异，尽管记忆表现相似。我们还评估了LLMs的与记忆无关的推理能力，并分析了典型错误。

    arXiv:2403.14112v1 Announce Type: new  Abstract: We introduce CHARM, the first benchmark for comprehensively and in-depth evaluating the commonsense reasoning ability of large language models (LLMs) in Chinese, which covers both globally known and Chinese-specific commonsense. We evaluated 7 English and 12 Chinese-oriented LLMs on CHARM, employing 5 representative prompt strategies for improving LLMs' reasoning ability, such as Chain-of-Thought. Our findings indicate that the LLM's language orientation and the task's domain influence the effectiveness of the prompt strategy, which enriches previous research findings. We built closely-interconnected reasoning and memorization tasks, and found that some LLMs struggle with memorizing Chinese commonsense, affecting their reasoning ability, while others show differences in reasoning despite similar memorization performance. We also evaluated the LLMs' memorization-independent reasoning abilities and analyzed the typical errors. Our study pr
    
[^50]: M3: 用于开放领域多跳密集句子检索的多任务混合目标学习框架

    M3: A Multi-Task Mixed-Objective Learning Framework for Open-Domain Multi-Hop Dense Sentence Retrieval

    [https://arxiv.org/abs/2403.14074](https://arxiv.org/abs/2403.14074)

    M3是一个多任务混合目标学习框架，旨在解决仅依赖对比学习可能导致的次优检索性能问题，并取得了在FEVER数据集上的最先进性能。

    

    在最近的研究中，对比学习已被证明是一种非常有效的表示学习方法，广泛用于密集检索。然而，我们发现仅依赖对比学习可能会导致次优的检索性能。另一方面，尽管许多检索数据集支持各种超越对比学习的学习目标，但在多任务学习场景中高效地组合它们可能具有挑战性。在本文中，我们介绍了M3，这是一个先进的递归多跳密集句子检索系统，它建立在一种新颖的多任务混合目标方法之上，用于密集文本表示学习，解决了上述挑战。我们的方法在大规模开放领域事实验证基准数据集FEVER上取得了最先进的性能。代码和数据可在以下链接获取: https://github.com/TonyBY/M3

    arXiv:2403.14074v1 Announce Type: cross  Abstract: In recent research, contrastive learning has proven to be a highly effective method for representation learning and is widely used for dense retrieval. However, we identify that relying solely on contrastive learning can lead to suboptimal retrieval performance. On the other hand, despite many retrieval datasets supporting various learning objectives beyond contrastive learning, combining them efficiently in multi-task learning scenarios can be challenging. In this paper, we introduce M3, an advanced recursive Multi-hop dense sentence retrieval system built upon a novel Multi-task Mixed-objective approach for dense text representation learning, addressing the aforementioned challenges. Our approach yields state-of-the-art performance on a large-scale open-domain fact verification benchmark dataset, FEVER. Code and data are available at: https://github.com/TonyBY/M3
    
[^51]: 用于自然语言处理的歧义类型分类

    A Taxonomy of Ambiguity Types for NLP

    [https://arxiv.org/abs/2403.14072](https://arxiv.org/abs/2403.14072)

    该论文提出了一个英语中常见的歧义类型分类，旨在促进自然语言处理分析，有助于更细致地评估数据集和模型性能。

    

    歧义是语言中的一个关键组成部分，它能够实现说话者之间更有效的交流，但在自然语言处理中经常被忽略。最近的研究表明，自然语言处理系统可能难以理解人类语言理解的某些要素，因为它们可能无法像人类在交流中自然地处理那样处理歧义。此外，不同类型的歧义可能有不同的作用，并需要不同的解决方法，我们旨在探究语言模型在不同歧义类型上的能力如何变化。我们提出了英语中常见的歧义类型分类，以促进自然语言处理分析。我们的分类可以帮助在语言歧义数据中进行有意义的划分，从而更细致地评估数据集和模型性能。

    arXiv:2403.14072v1 Announce Type: new  Abstract: Ambiguity is an critical component of language that allows for more effective communication between speakers, but is often ignored in NLP. Recent work suggests that NLP systems may struggle to grasp certain elements of human language understanding because they may not handle ambiguities at the level that humans naturally do in communication. Additionally, different types of ambiguity may serve different purposes and require different approaches for resolution, and we aim to investigate how language models' abilities vary across types. We propose a taxonomy of ambiguity types as seen in English to facilitate NLP analysis. Our taxonomy can help make meaningful splits in language ambiguity data, allowing for more fine-grained assessments of both datasets and model performance.
    
[^52]: NeurIPS 2023音频机器学习研讨会：情感音频基准和新数据

    The NeurIPS 2023 Machine Learning for Audio Workshop: Affective Audio Benchmarks and Novel Data

    [https://arxiv.org/abs/2403.14048](https://arxiv.org/abs/2403.14048)

    NeurIPS 2023音频机器学习研讨会聚集了音频领域的机器学习专家，为解决音频数据获取困难的问题，提供了多个开源数据集和专有数据集。

    

    NeurIPS 2023音频机器学习研讨会汇集了来自各种音频领域的机器学习（ML）专家。 文章指出，有许多有价值的音频驱动的ML任务，从语音情感识别到音频事件检测，但相比于其他ML领域（如计算机视觉或自然语言处理），音频社区相对较少。 其中一个主要限制是可用的数据； 由于音频是一种时间相关的模态，高质量的数据收集耗时且昂贵，这使得学术团体难以将他们的最先进策略应用于一个更大，更具普遍性的数据集。 为鼓励那些获取大型数据集困难的研究人员，研讨会组织者首先概述了几个可供社区使用的开源数据集，并在研讨会期间提供了几个专有数据集。 具体来说，包括三个发声数据集，Hume-Prosody，

    arXiv:2403.14048v1 Announce Type: cross  Abstract: The NeurIPS 2023 Machine Learning for Audio Workshop brings together machine learning (ML) experts from various audio domains. There are several valuable audio-driven ML tasks, from speech emotion recognition to audio event detection, but the community is sparse compared to other ML areas, e.g., computer vision or natural language processing. A major limitation with audio is the available data; with audio being a time-dependent modality, high-quality data collection is time-consuming and costly, making it challenging for academic groups to apply their often state-of-the-art strategies to a larger, more generalizable dataset. In this short white paper, to encourage researchers with limited access to large-datasets, the organizers first outline several open-source datasets that are available to the community, and for the duration of the workshop are making several propriety datasets available. Namely, three vocal datasets, Hume-Prosody, 
    
[^53]: Ax-to-Grind Urdu: 乌尔都语虚假新闻检测的基准数据集

    Ax-to-Grind Urdu: Benchmark Dataset for Urdu Fake News Detection

    [https://arxiv.org/abs/2403.14037](https://arxiv.org/abs/2403.14037)

    本文提出了乌尔都语虚假新闻检测的首个最大规模公开数据集，填补了地区语言虚假新闻检测领域数据集规模有限的空白。

    

    误传信息可能严重影响社会，影响从公众舆论到机构信心和一个国家的政治前景等各个方面。在线网站和在线社交网络上的虚假新闻传播呈现大量增长。各种事实核查网站的新闻主要以英语发布，几乎不提供有关地区语言虚假新闻的信息。因此，无法通过事实核查门户网站来识别乌尔都语虚假新闻传播者。虚假新闻检测(SOTA)方法依赖于适当标记和大规模数据集。地区和资源受限语言的虚假新闻检测由于数据集规模有限和合法词汇资源的缺乏而滞后。先前用于乌尔都语虚假新闻检测的数据集规模有限、领域受限、不公开且未经人工验证，其中新闻是从英语翻译为乌尔都语。本文策划并贡献了首个最大规模的公开可用的乌尔都语数据集。

    arXiv:2403.14037v1 Announce Type: cross  Abstract: Misinformation can seriously impact society, affecting anything from public opinion to institutional confidence and the political horizon of a state. Fake News (FN) proliferation on online websites and Online Social Networks (OSNs) has increased profusely. Various fact-checking websites include news in English and barely provide information about FN in regional languages. Thus the Urdu FN purveyors cannot be discerned using factchecking portals. SOTA approaches for Fake News Detection (FND) count upon appropriately labelled and large datasets. FND in regional and resource-constrained languages lags due to the lack of limited-sized datasets and legitimate lexical resources. The previous datasets for Urdu FND are limited-sized, domain-restricted, publicly unavailable and not manually verified where the news is translated from English into Urdu. In this paper, we curate and contribute the first largest publicly available dataset for Urdu 
    
[^54]: 一份新的用于高性能语言技术的大规模多语言数据集

    A New Massive Multilingual Dataset for High-Performance Language Technologies

    [https://arxiv.org/abs/2403.14009](https://arxiv.org/abs/2403.14009)

    提出了HPLT语言资源，这是一个包括单语和双语语料库的大规模多语言数据集，提供了丰富的资源用于语言建模和机器翻译训练

    

    我们介绍了HPLT（High Performance Language Technologies）语言资源，这是一个新的大规模多语言数据集，包括从CommonCrawl和以前未使用过的互联网档案馆中提取的单语和双语语料库。我们描述了我们用于获取、管理和处理大规模语料库的方法，这些方法依赖于开源软件工具和高性能计算。我们的单语数据集侧重于资源较低至资源中等的语言，涵盖了75种语言和大约5.6万亿个词标记，在文档级别上去重。我们的以英语为中心的平行语料库来源于其单语对应部分，涵盖了18种语言对和超过9600万对齐的句子对，大约有14亿个英语标记。HPLT语言资源是有史以来发布的最大开放文本语料库之一，为语言建模和机器翻译训练提供了重要资源。

    arXiv:2403.14009v1 Announce Type: new  Abstract: We present the HPLT (High Performance Language Technologies) language resources, a new massive multilingual dataset including both monolingual and bilingual corpora extracted from CommonCrawl and previously unused web crawls from the Internet Archive. We describe our methods for data acquisition, management and processing of large corpora, which rely on open-source software tools and high-performance computing. Our monolingual collection focuses on low- to medium-resourced languages and covers 75 languages and a total of ~5.6 trillion word tokens de-duplicated on the document level. Our English-centric parallel corpus is derived from its monolingual counterpart and covers 18 language pairs and more than 96 million aligned sentence pairs with roughly 1.4 billion English tokens. The HPLT language resources are one of the largest open text corpora ever released, providing a great resource for language modeling and machine translation traini
    
[^55]: 论ChatGPT在情感计算中的提示敏感性

    On Prompt Sensitivity of ChatGPT in Affective Computing

    [https://arxiv.org/abs/2403.14006](https://arxiv.org/abs/2403.14006)

    该研究介绍了一个用于评估基础模型性能敏感性的方法，针对ChatGPT在情感计算中的提示敏感性进行了研究和评估，涵盖情绪分析、毒性检测和讽刺检测。

    

    最近的研究已经展示了像ChatGPT这样的基础模型在多个领域，包括情感计算中的新兴能力。然而，访问这些新兴能力是通过提示工程来实现的。尽管存在一些提示技术，但该领域仍在迅速发展，许多提示想法仍需要调查。在这项工作中，我们介绍了一种方法，用于评估并调查基于不同提示或生成参数的基础模型性能的敏感性。我们在情感计算范围内针对ChatGPT执行我们的评估，解决了三个主要问题，即情绪分析、毒性检测和讽刺检测。首先，我们对自回归文本生成中的关键参数进行了敏感性分析，特别是温度参数$T$和Nucleus抽样中的top-$p$参数，指导着保守或创造性

    arXiv:2403.14006v1 Announce Type: cross  Abstract: Recent studies have demonstrated the emerging capabilities of foundation models like ChatGPT in several fields, including affective computing. However, accessing these emerging capabilities is facilitated through prompt engineering. Despite the existence of some prompting techniques, the field is still rapidly evolving and many prompting ideas still require investigation. In this work, we introduce a method to evaluate and investigate the sensitivity of the performance of foundation models based on different prompts or generation parameters. We perform our evaluation on ChatGPT within the scope of affective computing on three major problems, namely sentiment analysis, toxicity detection, and sarcasm detection. First, we carry out a sensitivity analysis on pivotal parameters in auto-regressive text generation, specifically the temperature parameter $T$ and the top-$p$ parameter in Nucleus sampling, dictating how conservative or creative
    
[^56]: 评估预训练句子嵌入的无监督降维方法

    Evaluating Unsupervised Dimensionality Reduction Methods for Pretrained Sentence Embeddings

    [https://arxiv.org/abs/2403.14001](https://arxiv.org/abs/2403.14001)

    评估使用无监督降维方法减小预训练语言模型生成句子嵌入维度，并发现对于一些模型，在降维后性能反而提高了。

    

    预训练语言模型（PLMs）生成的句子嵌入由于在众多下游应用中代表文本时表现出色，受到NLP社区的广泛关注。然而，PLMs生成的句子嵌入的高维度在代表大量句子时存在问题，特别是在内存或计算受限设备上。作为解决方案，我们评估了无监督降维方法，以减小PLMs生成的句子嵌入的维度。实验结果表明，简单的方法如主成分分析（PCA）可以将句子嵌入的维度减少约50％，在多个下游任务中性能未受到显着损失。令人惊讶的是，对一些PLMs生成的句子嵌入进一步降低维度可以改善性能，超过原始高维版本的性能。

    arXiv:2403.14001v1 Announce Type: new  Abstract: Sentence embeddings produced by Pretrained Language Models (PLMs) have received wide attention from the NLP community due to their superior performance when representing texts in numerous downstream applications. However, the high dimensionality of the sentence embeddings produced by PLMs is problematic when representing large numbers of sentences in memory- or compute-constrained devices. As a solution, we evaluate unsupervised dimensionality reduction methods to reduce the dimensionality of sentence embeddings produced by PLMs. Our experimental results show that simple methods such as Principal Component Analysis (PCA) can reduce the dimensionality of sentence embeddings by almost $50\%$, without incurring a significant loss in performance in multiple downstream tasks. Surprisingly, reducing the dimensionality further improves performance over the original high-dimensional versions for the sentence embeddings produced by some PLMs in s
    
[^57]: 减少大型语言模型偏见：重点关注“受限行业”的自动数据集增强和偏见量化

    Reducing Large Language Model Bias with Emphasis on 'Restricted Industries': Automated Dataset Augmentation and Prejudice Quantification

    [https://arxiv.org/abs/2403.13925](https://arxiv.org/abs/2403.13925)

    本文提出了一种针对“受限行业”进行自动数据集增强以减少大型语言模型偏见的新机制，并创建了mb-index和db-index两个新的偏见量化指标。

    

    尽管大型语言模型的能力不断增强，但仍然存在对其产生偏见的担忧。本文提出了一种针对“受限行业”在有限数据情况下通过指定数据集增强来去偏见的新颖自动机制。我们还创建了两个新的衡量指标mb-index和db-index来量化偏见，考虑到偏见是由内在模型架构和数据集共同导致的这一观点。

    arXiv:2403.13925v1 Announce Type: cross  Abstract: Despite the growing capabilities of large language models, there exists concerns about the biases they develop. In this paper, we propose a novel, automated mechanism for debiasing through specified dataset augmentation in the lens of bias producers and in the context of 'restricted industries' with limited data. We additionally create two new additional metrics, the mb-index and db-index, to quantify bias, considering the idea that bias occurs due to both intrinsic model architecture and dataset.
    
[^58]: 视觉引导的语音模型存在相互排他性偏见

    Visually Grounded Speech Models have a Mutual Exclusivity Bias

    [https://arxiv.org/abs/2403.13922](https://arxiv.org/abs/2403.13922)

    研究探讨了视觉引导的语音模型中的相互排他性偏见，并发现在具有更多视觉知识的模型中存在更强的偏见。

    

    当孩子学习新单词时，他们会运用相互排他性（ME）偏见这样的约束：一个新单词会映射到一个新对象而不是一个熟悉的对象。这种偏见已经在计算模型中进行了研究，但只在使用离散词表示作为输入的模型中进行了研究，忽略了口语词的高变异性。我们研究了在从自然图像和连续语音音频中学习的视觉引导的语音模型中的ME偏见。具体来说，我们训练一个模型以熟悉的单词，然后通过询问模型选择一个新对象和一个熟悉对象的方式来测试其ME偏见。为了模拟先前的声学和视觉知识，我们尝试了几种使用预训练语音和视觉网络的初始化策略。我们的研究结果揭示了不同初始化方法下的ME偏见，以及在具有更多先前知识（特别是视觉知识）的模型中更强的偏见。额外的测试

    arXiv:2403.13922v1 Announce Type: new  Abstract: When children learn new words, they employ constraints such as the mutual exclusivity (ME) bias: a novel word is mapped to a novel object rather than a familiar one. This bias has been studied computationally, but only in models that use discrete word representations as input, ignoring the high variability of spoken words. We investigate the ME bias in the context of visually grounded speech models that learn from natural images and continuous speech audio. Concretely, we train a model on familiar words and test its ME bias by asking it to select between a novel and a familiar object when queried with a novel word. To simulate prior acoustic and visual knowledge, we experiment with several initialisation strategies using pretrained speech and vision networks. Our findings reveal the ME bias across the different initialisation approaches, with a stronger bias in models with more prior (in particular, visual) knowledge. Additional tests co
    
[^59]: 利用语言增强嵌入进行开放信息抽取

    Leveraging Linguistically Enhanced Embeddings for Open Information Extraction

    [https://arxiv.org/abs/2403.13903](https://arxiv.org/abs/2403.13903)

    首次利用Seq2Seq PLM与语言特征相结合，有效提高了神经网络OIE架构的性能，使其同时获益于预训练语言模型和语言特征。

    

    开放信息抽取（OIE）是自然语言处理（NLP）中一项结构化预测（SP）任务，旨在从自由文本中提取结构化的$n$-元组，通常是主-谓-宾三元组。输入文本中的词嵌入可以通过语言特征（通常是词性（PoS）和句法依存解析（SynDP）标签）进行增强。然而，过去的增强技术无法利用预训练语言模型（PLM）的强大功能，而PLMs本身很少用于OIE。为了弥合这一差距，我们首次利用Seq2Seq PLM与语言特征进行OIE，通过引入加权相加和线性化连接两种方法。我们的工作可以使任何神经网络OIE架构一次性获得PLMs和语言特征的关键性能提升。在我们的设置中，这显示了对Precision、Recall和F1得分的广泛提高，分别达到24.9%、27.3%和14.9%。

    arXiv:2403.13903v1 Announce Type: new  Abstract: Open Information Extraction (OIE) is a structured prediction (SP) task in Natural Language Processing (NLP) that aims to extract structured $n$-ary tuples - usually subject-relation-object triples - from free text. The word embeddings in the input text can be enhanced with linguistic features, usually Part-of-Speech (PoS) and Syntactic Dependency Parse (SynDP) labels. However, past enhancement techniques cannot leverage the power of pretrained language models (PLMs), which themselves have been hardly used for OIE. To bridge this gap, we are the first to leverage linguistic features with a Seq2Seq PLM for OIE. We do so by introducing two methods - Weighted Addition and Linearized Concatenation. Our work can give any neural OIE architecture the key performance boost from both PLMs and linguistic features in one go. In our settings, this shows wide improvements of up to 24.9%, 27.3% and 14.9% on Precision, Recall and F1 scores respectively 
    
[^60]: 训练与限制：从主题和释义生成基于音韵学的绕口令

    Train & Constrain: Phonologically Informed Tongue-Twister Generation from Topics and Paraphrases

    [https://arxiv.org/abs/2403.13901](https://arxiv.org/abs/2403.13901)

    本文提出了一种从主题和释义生成基于音韵学的绕口令的新方法，生成了迄今为止最大的绕口令数据集TwistList 2.0，并进行了自动和人工评估。

    

    过去在音韵和语音基础的语言生成方面的工作主要集中在领域，如双关语和诗歌。在本文中，我们提出了产生绕口令的新工作-这种语言形式需要在音素级别上进行条件约束，以最大程度地实现声音重叠，同时与输入主题保持语义一致，仍然保持语法正确。我们提出了TwisterLister，这是一个从大型语言模型（LLMs）中生成基于音韵学的绕口令的流程，我们用它来生成TwistList 2.0，到目前为止最大的一个已标记数据集，包含来自人类和LLM作者合作的超过17K个例子。我们的生成流程涉及使用音韵受限词汇以及LLM提示来生成新颖的、非衍生的绕口令实例。此外，我们还提出了对较小规模的自动和人工评估结果。

    arXiv:2403.13901v1 Announce Type: new  Abstract: Previous work in phonologically and phonetically grounded language generation has mainly focused on domains such as puns and poetry. In this article, we present new work on the generation of tongue-twisters - a form of language that is required to be conditioned on a phoneme level to maximize sound overlap, whilst maintaining semantic consistency with an input topic and still being grammatically correct. We present TwisterLister, a pipeline for generating phonologically informed tongue-twisters from Large Language Models (LLMs) that we use to generate TwistList 2.0, the largest annotated dataset of tongue-twisters to date, consisting of 17K+ examples from a combination of human and LLM authors. Our generation pipeline involves the use of a phonologically constrained vocabulary alongside LLM prompting to generate novel, non-derivative tongue-twister examples. We additionally present the results of automatic and human evaluation of smaller
    
[^61]: 你站在哪一边？调查大型语言模型的政治立场

    Whose Side Are You On? Investigating the Political Stance of Large Language Models

    [https://arxiv.org/abs/2403.13840](https://arxiv.org/abs/2403.13840)

    本研究提出了一个定量框架和流程，系统调查大型语言模型的政治取向，结果显示这些模型倾向于提供与自由主义或左倾观点更为接近的回应。

    

    大型语言模型（LLMs）因其在文本生成、摘要和信息检索等日常任务中的应用而备受欢迎。随着LLMs的广泛应用不断增长，确保这些模型产生政治中立的回应变得越来越重要，旨在避免信息泡沫，维护代表公平，并减轻确认偏见。本文提出了一个定量框架和流程，旨在系统地调查LLMs的政治取向。我们的调查深入探讨LLMs在八个极化话题的政治取向，从堕胎到LGBTQ问题跨越。结果表明，在各个话题上，LLMs倾向于提供与自由主义或左倾观点更为接近的回应，而不是与保守主义或右倾观点更为接近的回应。

    arXiv:2403.13840v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have gained significant popularity for their application in various everyday tasks such as text generation, summarization, and information retrieval. As the widespread adoption of LLMs continues to surge, it becomes increasingly crucial to ensure that these models yield responses that are politically impartial, with the aim of preventing information bubbles, upholding fairness in representation, and mitigating confirmation bias. In this paper, we propose a quantitative framework and pipeline designed to systematically investigate the political orientation of LLMs. Our investigation delves into the political alignment of LLMs across a spectrum of eight polarizing topics, spanning from abortion to LGBTQ issues. Across topics, the results indicate that LLMs exhibit a tendency to provide responses that closely align with liberal or left-leaning perspectives rather than conservative or right-leaning ones when us
    
[^62]: 使用准确性保证自动缩减语言模型规模以降低处理费用的SMART

    SMART: Automatically Scaling Down Language Models with Accuracy Guarantees for Reduced Processing Fees

    [https://arxiv.org/abs/2403.13835](https://arxiv.org/abs/2403.13835)

    提出了SMART框架，可通过准确性约束最小化自然语言处理任务的推理成本，同时确保结果质量。

    

    大型语言模型（LLMs）的进步显著提高了自然语言处理（NLP）任务的性能。然而，部署高性能LLMs会产生巨大的成本，主要是由于增加的参数数量旨在提升模型性能。这使得最先进的LLMs对终端用户而言变得更加昂贵。我们引入了SMART，即为降低标记费用而自适应缩放模型，这是一个新颖的LLM框架，旨在最大程度地降低NLP任务的推理成本，同时确保足够的结果质量。它使用户能够以输出的等效性指定准确性约束与最强大的LLM。

    arXiv:2403.13835v1 Announce Type: cross  Abstract: The advancement of Large Language Models (LLMs) has significantly boosted performance in natural language processing (NLP) tasks. However, the deployment of high-performance LLMs incurs substantial costs, primarily due to the increased number of parameters aimed at enhancing model performance. This has made the use of state-of-the-art LLMs more expensive for end-users. AI service providers, such as OpenAI and Anthropic, often offer multiple versions of LLMs with varying prices and performance. However, end-users still face challenges in choosing the appropriate LLM for their tasks that balance result quality with cost.   We introduce SMART, Scaling Models Adaptively for Reduced Token Fees, a novel LLM framework designed to minimize the inference costs of NLP tasks while ensuring sufficient result quality. It enables users to specify an accuracy constraint in terms of the equivalence of outputs to those of the most powerful LLM. SMART t
    
[^63]: 文本与分子之间的桥梁：分子多模态框架综述

    Bridging Text and Molecule: A Survey on Multimodal Frameworks for Molecule

    [https://arxiv.org/abs/2403.13830](https://arxiv.org/abs/2403.13830)

    本文首次系统调研了针对分子研究的多模态框架，重点讨论了文本与分子之间的关联、不同模型架构和预训练任务。同时还深入探讨了大型语言模型以及提示技术在分子领域中的应用。

    

    人工智能在科学研究中展现出巨大潜力。在分子科学领域，它正在改变传统的计算机辅助范式，引领着深度学习的新时代。随着多模态学习和自然语言处理的最新进展，一种新兴趋势是构建多模态框架，以共同建模分子和文本领域知识。本文首次系统地调研了针对分子研究的多模态框架。具体来说，我们从分子深度学习的发展入手，指出涉及文本模态的必要性。接下来，我们关注了文本-分子对齐方法的最新进展，根据它们的架构将当前模型分为两组，并列出相关的预训练任务。此外，我们深入研究了大型语言模型和提示技术在分子任务和预训练中的应用。

    arXiv:2403.13830v1 Announce Type: cross  Abstract: Artificial intelligence has demonstrated immense potential in scientific research. Within molecular science, it is revolutionizing the traditional computer-aided paradigm, ushering in a new era of deep learning. With recent progress in multimodal learning and natural language processing, an emerging trend has targeted at building multimodal frameworks to jointly model molecules with textual domain knowledge. In this paper, we present the first systematic survey on multimodal frameworks for molecules research. Specifically,we begin with the development of molecular deep learning and point out the necessity to involve textual modality. Next, we focus on recent advances in text-molecule alignment methods, categorizing current models into two groups based on their architectures and listing relevant pre-training tasks. Furthermore, we delves into the utilization of large language models and prompting techniques for molecular tasks and prese
    
[^64]: 在共创图像生成中衡量多样性

    Measuring Diversity in Co-creative Image Generation

    [https://arxiv.org/abs/2403.13826](https://arxiv.org/abs/2403.13826)

    提出了一种基于神经网络编码熵的方法，以比较图像集合之间的多样性，而无需真实标准知识且易于计算，并展示了不同预训练网络选择对我们要评估的多样性概念的影响。

    

    质量和多样性已被提出作为评估共创系统生成内容的合理启发式方法，但迄今为止，人们对后者的构成以及如何衡量它尚无统一意见。目前用于评估生成模型多样性的方法存在局限性，在大型预训练生成模型时，这些方法将模型输出与一个可能不存在的真实标准进行比较，或者涉及到不切实际的计算量。我们提出了一种基于神经网络编码熵的替代方法，用于比较图像集合之间的多样性，而无需真实标准知识且易于计算。我们还比较了两个预训练网络，并展示了选择如何与我们想要评估的多样性概念相关联。最后我们讨论了这些测量方法在交互式系统的构思、模型评估以及其他应用领域中的潜在应用。

    arXiv:2403.13826v1 Announce Type: cross  Abstract: Quality and diversity have been proposed as reasonable heuristics for assessing content generated by co-creative systems, but to date there has been little agreement around what constitutes the latter or how to measure it. Proposed approaches for assessing generative models in terms of diversity have limitations in that they compare the model's outputs to a ground truth that in the era of large pre-trained generative models might not be available, or entail an impractical number of computations. We propose an alternative based on entropy of neural network encodings for comparing diversity between sets of images that does not require ground-truth knowledge and is easy to compute. We also compare two pre-trained networks and show how the choice relates to the notion of diversity that we want to evaluate. We conclude with a discussion of the potential applications of these measures for ideation in interactive systems, model evaluation, an
    
[^65]: AI生成文本在学术研究中的定量分析：利用AI检测工具研究Arxiv投稿中的AI存在性

    Quantitative Analysis of AI-Generated Texts in Academic Research: A Study of AI Presence in Arxiv Submissions using AI Detection Tool

    [https://arxiv.org/abs/2403.13812](https://arxiv.org/abs/2403.13812)

    论文研究了一种能够检测Arxiv投稿中AI成分的方法，使用物理、数学和计算机科学文章创建数据集，并通过Originality.ai进行分析，准确率达到98%。

    

    许多人对ChatGPT感兴趣，因为它已成为一个突出的AIGC模型，可以在各种情境下提供高质量的响应，如软件开发和维护。ChatGPT的误用可能引起重大问题，特别是在公共安全和教育领域，尽管其有巨大潜力。研究人员大多选择在Arxiv上发表他们的作品。未来工作的有效性和独创性取决于在这些贡献中检测到AI组件的能力。为了满足这一需求，本研究将分析一种方法，可以查看学术机构用于在Arxiv上发布的刻意制造的内容。为了进行这项研究，使用了物理、数学和计算机科学文章创建了一个数据集。利用新建立的数据集，接下来的步骤是将originality.ai投入使用。统计分析显示，Originality.ai非常精准，准确率达到98%。

    arXiv:2403.13812v1 Announce Type: cross  Abstract: Many people are interested in ChatGPT since it has become a prominent AIGC model that provides high-quality responses in various contexts, such as software development and maintenance. Misuse of ChatGPT might cause significant issues, particularly in public safety and education, despite its immense potential. The majority of researchers choose to publish their work on Arxiv. The effectiveness and originality of future work depend on the ability to detect AI components in such contributions. To address this need, this study will analyze a method that can see purposely manufactured content that academic organizations use to post on Arxiv. For this study, a dataset was created using physics, mathematics, and computer science articles. Using the newly built dataset, the following step is to put originality.ai through its paces. The statistical analysis shows that Originality.ai is very accurate, with a rate of 98%.
    
[^66]: RoleInteract：评估角色扮演代理的社交互动

    RoleInteract: Evaluating the Social Interaction of Role-Playing Agents

    [https://arxiv.org/abs/2403.13679](https://arxiv.org/abs/2403.13679)

    该论文介绍了RoleInteract，一个旨在评估角色扮演对话代理社交性的基准，覆盖了500个角色、6000多个问题提示和30800个对话话语。

    

    大型语言模型（LLMs）推动了各种AI对话代理的发展，包括模仿不同角色和人类行为的角色扮演对话代理。本文引入了RoleInteract，这是第一个旨在系统评估角色扮演对话代理在社交方面表现的基准。该基准从各种来源构建，涵盖了超过500个角色、6000多个问题提示和30800个多轮角色扮演话语。

    arXiv:2403.13679v1 Announce Type: new  Abstract: Large language models (LLMs) have advanced the development of various AI conversational agents, including role-playing conversational agents that mimic diverse characters and human behaviors. While prior research has predominantly focused on enhancing the conversational capability, role-specific knowledge, and stylistic attributes of these agents, there has been a noticeable gap in assessing their social intelligence. In this paper, we introduce RoleInteract, the first benchmark designed to systematically evaluate the sociality of role-playing conversational agents at both individual and group levels of social interactions. The benchmark is constructed from a variety of sources and covers a wide range of 500 characters and over 6,000 question prompts and 30,800 multi-turn role-playing utterances. We conduct comprehensive evaluations on this benchmark using mainstream open-source and closed-source LLMs. We find that agents excelling in in
    
[^67]: 不必担心如果您没有数据：利用Translationese构建预训练语言模型

    Do Not Worry if You Do Not Have Data: Building Pretrained Language Models Using Translationese

    [https://arxiv.org/abs/2403.13638](https://arxiv.org/abs/2403.13638)

    本文探讨了使用Translationese合成数据作为预训练语言模型的实用性，展示了在英语以外的语言中使用机器翻译创建的合成数据进行LMs预训练的有效性，并提出了通过使用轻量级TinyLMs预训练来过滤合成数据的方法。

    

    在本文中，我们探讨了将机器翻译创建的合成数据Translationese用作预训练语言模型（LMs）的实用性。预训练需要大量的单语数据，对于英语以外的语言，这些数据大部分是不可用的。近年来，人们越来越关注使用合成数据来解决这种数据稀缺性问题。我们以英语和Indic语言为例，将网络抓取的单语文档（干净的）翻译成目标语言。然后，我们在这些Translationese数据（合成数据）上训练包含28M和85M参数的语言模型。我们展示了它们在下游自然语言理解和生成任务中的性能与在干净数据上预训练的LMs相比，NLU任务的性能仅差3.56％，NLG任务的差异为1.51％。此外，我们提出了使用在干净数据上预训练的轻量级TinyLMs来高效过滤合成数据的方法，这显著提高了性能。

    arXiv:2403.13638v1 Announce Type: new  Abstract: In this paper, we explore the utility of \textit{Translationese} as synthetic data created using machine translation for pre-training language models (LMs). Pre-training requires vast amounts of monolingual data, which is mostly unavailable for languages other than English. Recently, there has been a growing interest in using synthetic data to address this data scarcity. We take the case of English and Indic languages and translate web-crawled monolingual documents (clean) into the target language. Then, we train language models containing 28M and 85M parameters on this translationese data (synthetic). We show that their performance on downstream natural language understanding and generative tasks is only 3.56\% poorer on NLU tasks and 1.51\% on NLG tasks than LMs pre-trained on clean data. Further, we propose the use of lightweight \textit{TinyLMs} pre-trained on clean data to filter synthetic data efficiently which significantly improv
    
[^68]: LlamaFactory：100多种语言模型的统一高效微调

    LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models

    [https://arxiv.org/abs/2403.13372](https://arxiv.org/abs/2403.13372)

    LlamaFactory是一个统一框架，整合了一系列前沿的高效训练方法，使用户能够在不需要编码的情况下灵活定制100多种LLMs的微调。

    

    高效的微调对于将大型语言模型（LLMs）适应下游任务至关重要。然而，在不同模型上实现这些方法需要非平凡的努力。我们提出了LlamaFactory，这是一个统一框架，集成了一套前沿的高效训练方法。它允许用户通过内置的Web UI LlamaBoard 灵活定制100多种LLMs的微调，无需编码。我们在语言建模和文本生成任务上经验性地验证了我们框架的效率和有效性。已发布在 https://github.com/hiyouga/LLaMA-Factory，并已获得超过13,000颗星和1,600个分支。

    arXiv:2403.13372v1 Announce Type: new  Abstract: Efficient fine-tuning is vital for adapting large language models (LLMs) to downstream tasks. However, it requires non-trivial efforts to implement these methods on different models. We present LlamaFactory, a unified framework that integrates a suite of cutting-edge efficient training methods. It allows users to flexibly customize the fine-tuning of 100+ LLMs without the need for coding through the built-in web UI LlamaBoard. We empirically validate the efficiency and effectiveness of our framework on language modeling and text generation tasks. It has been released at https://github.com/hiyouga/LLaMA-Factory and already received over 13,000 stars and 1,600 forks.
    
[^69]: Arcee的MergeKit：用于合并大型语言模型的工具包

    Arcee's MergeKit: A Toolkit for Merging Large Language Models

    [https://arxiv.org/abs/2403.13257](https://arxiv.org/abs/2403.13257)

    合并不同语言模型的参数，无需额外训练即可创建多任务模型，提升模型性能和多功能性，解决AI中的复杂挑战。

    

    开源语言模型领域的快速扩张为通过合并其参数来结合这些模型检查点的能力提供了机会。迁移学习的进步导致了大量针对特定任务进行微调的模型的开发，这些模型通常专门针对个别任务进行专门化，无法利用彼此的优势。模型合并促进了多任务模型的创建，无需额外的训练，为增强模型性能和多功能性提供了一个有前途的途径。通过保留原始模型的固有能力，模型合并解决了人工智能中的复杂挑战，包括灾难性遗忘和多任务学习的困难。为了支持这一不断扩大的研究领域，我们介绍了MergeKit，这是一个全面的、开源的库，旨在促进模型合并的应用。

    arXiv:2403.13257v1 Announce Type: new  Abstract: The rapid expansion of the open-source language model landscape presents an opportunity to merge the competencies of these model checkpoints by combining their parameters. Advances in transfer learning, the process of fine-tuning pre-trained models for specific tasks, has resulted in the development of vast amounts of task-specific models, typically specialized in individual tasks and unable to utilize each other's strengths. Model merging facilitates the creation of multitask models without the need for additional training, offering a promising avenue for enhancing model performance and versatility. By preserving the intrinsic capabilities of the original models, model merging addresses complex challenges in AI - including the difficulties of catastrophic forgetting and multi-task learning. To support this expanding area of research, we introduce MergeKit, a comprehensive, open-source library designed to facilitate the application of mo
    
[^70]: 从表现性伤害到服务质量伤害:羊驼2安全保障的案例研究

    From Representational Harms to Quality-of-Service Harms: A Case Study on Llama 2 Safety Safeguards

    [https://arxiv.org/abs/2403.13213](https://arxiv.org/abs/2403.13213)

    本文探讨了针对表现性伤害和服务质量伤害的羊驼2安全保障措施的有效性，并指出了大型语言模型在实用性和安全性之间的权衡关系。

    

    近期大型语言模型（LLM）的进展导致它们在各个领域被广泛采用。然而，这些进步也引入了额外的安全风险，并引发了对其对已经边缘化人群的不利影响的担忧。尽管存在越来越多的减轻措施来开发安全保障措施，比如监督式的安全定向微调和利用来自人类反馈的安全强化学习，但关于这些模型的安全性和内在偏见仍存在多重关注。此外，先前的研究已经证明，为了安全而优化的模型通常会展示夸大的安全行为，比如出于预防措施而倾向于不回应某些请求。因此，文献中已经记录了这些模型在实用性和安全性之间的明显权衡。在本文中，我们进一步研究了安全措施的有效性，通过评估...

    arXiv:2403.13213v1 Announce Type: cross  Abstract: Recent progress in large language models (LLMs) has led to their widespread adoption in various domains. However, these advancements have also introduced additional safety risks and raised concerns regarding their detrimental impact on already marginalized populations. Despite growing mitigation efforts to develop safety safeguards, such as supervised safety-oriented fine-tuning and leveraging safe reinforcement learning from human feedback, multiple concerns regarding the safety and ingrained biases in these models remain. Furthermore, previous work has demonstrated that models optimized for safety often display exaggerated safety behaviors, such as a tendency to refrain from responding to certain requests as a precautionary measure. As such, a clear trade-off between the helpfulness and safety of these models has been documented in the literature. In this paper, we further investigate the effectiveness of safety measures by evaluatin
    
[^71]: RankPrompt：逐步比较使语言模型成为更好的推理者

    RankPrompt: Step-by-Step Comparisons Make Language Models Better Reasoners

    [https://arxiv.org/abs/2403.12373](https://arxiv.org/abs/2403.12373)

    RankPrompt 提出了一种新的提示方法，可以通过自我排序来提高大型语言模型在推理任务中的性能。

    

    大型语言模型（LLMs）在各种推理任务中取得了令人印象深刻的表现。然而，即使像ChatGPT这样的最先进的LLMs在推理过程中也容易出现逻辑错误。现有的解决方案，包括部署特定于任务的验证器或在多个推理路径上投票，要么需要大量人类注释，要么在存在不一致响应的场景中失败。为了解决这些挑战，我们介绍了RankPrompt，这是一种新的提示方法，使LLMs能够自行对其响应进行排序而无需额外资源。RankPrompt将排序问题分解为多个响应之间的一系列比较，利用LLMs自动生成比较链作为上下文示例的固有能力。我们在11个算术推理和常识推理任务上的实验表明，RankPrompt显著提高了ChatGPT和GPT-4的推理性能。

    arXiv:2403.12373v1 Announce Type: new  Abstract: Large Language Models (LLMs) have achieved impressive performance across various reasoning tasks. However, even state-of-the-art LLMs such as ChatGPT are prone to logical errors during their reasoning processes. Existing solutions, which include deploying task-specific verifiers or voting over multiple reasoning paths, either require extensive human annotations or fail in scenarios with inconsistent responses. To address these challenges, we introduce RankPrompt, a new prompting method that enables LLMs to self-rank their responses without additional resources. RankPrompt breaks down the ranking problem into a series of comparisons among diverse responses, leveraging the inherent capabilities of LLMs to generate chains of comparison as contextual exemplars. Our experiments across 11 arithmetic and commonsense reasoning tasks show that RankPrompt significantly enhances the reasoning performance of ChatGPT and GPT-4, with improvements of u
    
[^72]: 一项用于对话立场检测的挑战数据集和有效模型

    A Challenge Dataset and Effective Models for Conversational Stance Detection

    [https://arxiv.org/abs/2403.11145](https://arxiv.org/abs/2403.11145)

    介绍了一个新的多轮对话立场检测数据集（MT-CSD），提出了一种全局局部注意力网络（GLAN）来解决对话数据中的长距离和短距离依赖性。

    

    先前的立场检测研究通常集中在评估单个实例内的立场，从而在有效建模关于同一特定主题的多方讨论方面存在局限性，这在真实社交媒体互动中自然发生。这种限制主要是由于缺乏真实复制真实社交媒体背景的数据集，阻碍了对话立场检测的研究进展。在本文中，我们介绍了一个新的多轮对话立场检测数据集（称为\textbf{MT-CSD}），涵盖了用于对话立场检测的多个目标。为了从这一具有挑战性的数据集中获取立场，我们提出了一个全局局部注意力网络（\textbf{GLAN}），以解决对话数据中固有的长距离和短距离依赖性。值得注意的是，即使是GLAN这样的最先进的立场检测方法，在......

    arXiv:2403.11145v1 Announce Type: new  Abstract: Previous stance detection studies typically concentrate on evaluating stances within individual instances, thereby exhibiting limitations in effectively modeling multi-party discussions concerning the same specific topic, as naturally transpire in authentic social media interactions. This constraint arises primarily due to the scarcity of datasets that authentically replicate real social media contexts, hindering the research progress of conversational stance detection. In this paper, we introduce a new multi-turn conversation stance detection dataset (called \textbf{MT-CSD}), which encompasses multiple targets for conversational stance detection. To derive stances from this challenging dataset, we propose a global-local attention network (\textbf{GLAN}) to address both long and short-range dependencies inherent in conversational data. Notably, even state-of-the-art stance detection methods, exemplified by GLAN, exhibit an accuracy of on
    
[^73]: m&m's: 一个用于评估多步骤多模态任务工具使用的基准

    m&m's: A Benchmark to Evaluate Tool-Use for multi-step multi-modal Tasks

    [https://arxiv.org/abs/2403.11085](https://arxiv.org/abs/2403.11085)

    m&m's引入了一个包含4K+多步骤多模态任务的基准，涉及33种工具，用于评估LLM作为规划器的设计决策。

    

    现实世界中的多模态问题很少由单个机器学习模型解决，通常需要多步骤计算计划，涉及拼接多个模型。 工具增强型LLM极有可能自动化生成这种计算计划。然而，缺乏用于评估LLM作为多步骤多模态任务规划器的标准化基准，阻碍了对规划器设计决策的系统研究。LLM是否应一次性生成整个计划还是逐步生成？它们是否应该直接使用Python代码调用工具，还是通过类似JSON的结构化数据格式？反馈是否改善规划？为了回答这些问题以及更多问题，我们介绍了m&m's：一个基准，包含4K+个涉及33种工具的多步骤多模态任务，其中包括多模态模型、(免费)公共API和图像处理模块。对于每个任务查询，我们提供使用这种方法自动生成的计划。

    arXiv:2403.11085v1 Announce Type: cross  Abstract: Real-world multi-modal problems are rarely solved by a single machine learning model, and often require multi-step computational plans that involve stitching several models. Tool-augmented LLMs hold tremendous promise for automating the generation of such computational plans. However, the lack of standardized benchmarks for evaluating LLMs as planners for multi-step multi-modal tasks has prevented a systematic study of planner design decisions. Should LLMs generate a full plan in a single shot or step-by-step? Should they invoke tools directly with Python code or through structured data formats like JSON? Does feedback improve planning? To answer these questions and more, we introduce m&m's: a benchmark containing 4K+ multi-step multi-modal tasks involving 33 tools that include multi-modal models, (free) public APIs, and image processing modules. For each of these task queries, we provide automatically generated plans using this realis
    
[^74]: 优化多语言大语言模型的语言增强：以韩语为例的案例研究

    Optimizing Language Augmentation for Multilingual Large Language Models: A Case Study on Korean

    [https://arxiv.org/abs/2403.10882](https://arxiv.org/abs/2403.10882)

    该研究提出了三种策略来增强基于公开可用MLLMs的资源较少的语言的性能，包括扩展词汇、双语数据预训练和指导微调。

    

    大型语言模型（LLMs）使用预训练来预测下一个单词；然而，它们的扩展需要大量计算资源。许多大型科技公司和研究机构已经开发了多语言LLMs（MLLMs）以满足当前需求，但忽视了资源较少的语言（LRLs）。本研究提出了三种策略来增强基于公开可用MLLMs的LRLs的性能。首先，扩展LRLs的MLLM词汇以增强表达性。其次，使用双语数据进行预训练以对齐高资源语言和低资源语言。第三，构建高质量的小规模指导数据集，并进行指导微调以增强LRL。实验采用了Llama2模型，以韩语作为LRL，并在八项任务中对其与其他已开发的LLMs进行了定量评估。此外，基于人类评估进行了定性评估。

    arXiv:2403.10882v1 Announce Type: cross  Abstract: Large language models (LLMs) use pretraining to predict the subsequent word; however, their expansion requires significant computing resources. Numerous big tech companies and research institutes have developed multilingual LLMs (MLLMs) to meet current demands, overlooking less-resourced languages (LRLs). This study proposed three strategies to enhance the performance of LRLs based on the publicly available MLLMs. First, the MLLM vocabularies of LRLs were expanded to enhance expressiveness. Second, bilingual data were used for pretraining to align the high- and less-resourced languages. Third, a high-quality small-scale instruction dataset was constructed and instruction-tuning was performed to augment the LRL. The experiments employed the Llama2 model and Korean was used as the LRL, which was quantitatively evaluated against other developed LLMs across eight tasks. Furthermore, a qualitative assessment was performed based on human eva
    
[^75]: 数据价值评估对视觉指导调整的影响

    Less is More: Data Value Estimation for Visual Instruction Tuning

    [https://arxiv.org/abs/2403.09559](https://arxiv.org/abs/2403.09559)

    视觉指导调整时需要进行数据价值评估，通过新的数据选择方法TIVE，根据任务级和实例级价值来消除视觉指导数据中的冗余。

    

    视觉指导调整是构建多模式大语言模型（MLLMs）的关键，大大提高了大语言模型（LLMs）在视觉场景中的推理能力。然而，现有的MLLMs主要依赖于多个高度多样化的视觉指导数据集的混合训练（甚至超过一百万条指导），这可能引入数据冗余。为了调查这个问题，我们进行了一系列实证研究，揭示了视觉指导数据集内存在显著冗余，并显示大大减少几个指导数据集的数量甚至不会影响性能。根据研究结果，我们提出了一种新的数据选择方法TIVE，以消除视觉指导数据中的冗余。TIVE首先根据计算的梯度估计视觉指导的任务级和实例级价值。然后，根据估计的价值，TIVE确定了任务级和实例级指导选择策略。

    arXiv:2403.09559v1 Announce Type: new  Abstract: Visual instruction tuning is the key to building multimodal large language models (MLLMs), which greatly improves the reasoning capabilities of large language models (LLMs) in vision scenario. However, existing MLLMs mostly rely on a mixture of multiple highly diverse visual instruction datasets for training (even more than a million instructions), which may introduce data redundancy. To investigate this issue, we conduct a series of empirical studies, which reveal a significant redundancy within the visual instruction datasets, and show that greatly reducing the amount of several instruction dataset even do not affect the performance. Based on the findings, we propose a new data selection approach TIVE, to eliminate redundancy within visual instruction data. TIVE first estimates the task-level and instance-level value of the visual instructions based on computed gradients. Then, according to the estimated values, TIVE determines the tas
    
[^76]: 训练小型多模态模型以填补生物医学能力差距：以放射学成像为例

    Training Small Multimodal Models to Bridge Biomedical Competency Gap: A Case Study in Radiology Imaging

    [https://arxiv.org/abs/2403.08002](https://arxiv.org/abs/2403.08002)

    本文针对生物医学应用中前沿模型尚存在的多模态能力差距，探讨了训练开源小型多模态模型以弥补临床需求的生物医学能力差距。

    

    放大基础模型的尺度规律和非凡表现激励了在生物医学领域开发和利用这些大型模型。然而，尽管在一些生物医学基准测试中取得了早期有希望的结果，但在这些模型能够应用于真实世界的应用之前仍然存在一些重大挑战。像GPT-4V这样的前沿模型在生物医学应用中仍存在重大的多模态能力差距。此外，访问、成本、延迟和合规等实际问题使临床医生难以直接在私人患者数据上使用私人托管的最先进大型模型。在本文中，我们探讨训练开源小型多模态模型（SMMs）来填补未满足的临床需求的生物医学能力差距。为了最大化数据效率，我们采用模块化方法，将用于图像和文本模态的最先进预训练模型纳入，并侧重于t

    arXiv:2403.08002v1 Announce Type: new  Abstract: The scaling laws and extraordinary performance of large foundation models motivate the development and utilization of such large models in biomedicine. However, despite early promising results on some biomedical benchmarks, there are still major challenges that need to be addressed before these models can be used in real-world applications. Frontier models such as GPT-4V still have major competency gaps in multimodal capabilities for biomedical applications. Moreover, pragmatic issues such as access, cost, latency, and compliance make it hard for clinicians to use privately-hosted state-of-the-art large models directly on private patient data. In this paper, we explore training open-source small multimodal models (SMMs) to bridge biomedical competency gaps for unmet clinical needs. To maximize data efficiency, we adopt a modular approach by incorporating state-of-the-art pre-trained models for image and text modalities, and focusing on t
    
[^77]: 揭开缩放定律之谜：第一部分

    Unraveling the Mystery of Scaling Laws: Part I

    [https://arxiv.org/abs/2403.06563](https://arxiv.org/abs/2403.06563)

    确认缩放定律原则在模型预训练中的重要作用，揭示OpenAI原始缩放定律论文的不完整细节，并探究预测测试损失轨迹可靠公式的挑战

    

    缩放定律原则表明在模型大小、数据集大小和训练过程中使用的计算资源等变量之间存在幂定律相关性。这些原则在优化模型预训练的各个方面中起着至关重要的作用，最终有助于大型语言模型（如GPT-4、Llama和Gemini）的成功。然而，OpenAI的原始缩放定律论文并未披露推导精确缩放定律公式所必需的完整细节，他们的结论仅基于包含高达15亿参数的模型。尽管一些后续作品试图揭示这些细节并扩展到更大的模型，但它们经常忽略了重要因素的训练依赖性，如学习速率、上下文长度和批量大小，导致它们未能建立一个可靠的预测测试损失轨迹的公式。在本技术报告中，我们确认了缩放

    arXiv:2403.06563v1 Announce Type: cross  Abstract: Scaling law principles indicate a power-law correlation between loss and variables such as model size, dataset size, and computational resources utilized during training. These principles play a vital role in optimizing various aspects of model pre-training, ultimately contributing to the success of large language models such as GPT-4, Llama and Gemini. However, the original scaling law paper by OpenAI did not disclose the complete details necessary to derive the precise scaling law formulas, and their conclusions are only based on models containing up to 1.5 billion parameters. Though some subsequent works attempt to unveil these details and scale to larger models, they often neglect the training dependency of important factors such as the learning rate, context length and batch size, leading to their failure to establish a reliable formula for predicting the test loss trajectory. In this technical report, we confirm that the scaling 
    
[^78]: 模拟社交互动成功性的误导性：以LLMs为例

    Is this the real life? Is this just fantasy? The Misleading Success of Simulating Social Interactions With LLMs

    [https://arxiv.org/abs/2403.05020](https://arxiv.org/abs/2403.05020)

    研究发现，使用LLMs进行社交互动的全知模拟比非全知模拟更容易实现社交目标，尽管非全知模拟更接近实际情况。

    

    最近大型语言模型（LLM）的进展使得社交模拟更加丰富，能够使用基于LLM的代理人研究各种社交现象。然而，大多数工作在这些模拟中采用了一种全知的透视（例如，单个LLM生成所有交谈者），这与人类具有的非全知、信息不对称的互动根本不符。为了研究这些差异，我们开发了一个评估框架，在各种设定（全知、非全知）中使用LLMs模拟社交互动。我们的实验表明，通过全知方式模拟的交谈者在实现社交目标方面比非全知代理人更成功，尽管后者更符合现实设置。此外，我们表明从全知模拟中学习可以改善交互的自然性，但在合作场景中几乎不能增强目标实现。

    arXiv:2403.05020v1 Announce Type: cross  Abstract: Recent advances in large language models (LLM) have enabled richer social simulations, allowing for the study of various social phenomena with LLM-based agents. However, most work has used an omniscient perspective on these simulations (e.g., single LLM to generate all interlocutors), which is fundamentally at odds with the non-omniscient, information asymmetric interactions that humans have. To examine these differences, we develop an evaluation framework to simulate social interactions with LLMs in various settings (omniscient, non-omniscient). Our experiments show that interlocutors simulated omnisciently are much more successful at accomplishing social goals compared to non-omniscient agents, despite the latter being the more realistic setting. Furthermore, we demonstrate that learning from omniscient simulations improves the apparent naturalness of interactions but scarcely enhances goal achievement in cooperative scenarios. Our f
    
[^79]: 不确定性感知关系图神经网络用于少样本知识图谱补全

    Uncertainty-Aware Relational Graph Neural Network for Few-Shot Knowledge Graph Completion

    [https://arxiv.org/abs/2403.04521](https://arxiv.org/abs/2403.04521)

    提出一种不确定性感知的少样本知识图谱补全框架以模拟实体和三元组不确定性，通过学习服从高斯分布的表示来更好地理解有限数据。

    

    少样本知识图谱补全旨在在给定少量案例参考实体对的情况下查询某种关系的未知事实。本文提出了一种新颖的不确定性感知少样本知识图谱补全框架（UFKGC），以模拟不确定性，更好地理解有限数据，通过学习服从高斯分布的表示来避免由实体和三元组不确定性导致的噪声副作用，先为源实体对的不确定性范围设计不确定性表示，然后将特征表示转换为高斯分布。为了更好地整合具有不确定特征的邻居以用于实体特征，我们设计了一种不确定性感知的关系图神经网络（UR-GNN）进行卷积操作。

    arXiv:2403.04521v1 Announce Type: new  Abstract: Few-shot knowledge graph completion (FKGC) aims to query the unseen facts of a relation given its few-shot reference entity pairs. The side effect of noises due to the uncertainty of entities and triples may limit the few-shot learning, but existing FKGC works neglect such uncertainty, which leads them more susceptible to limited reference samples with noises. In this paper, we propose a novel uncertainty-aware few-shot KG completion framework (UFKGC) to model uncertainty for a better understanding of the limited data by learning representations under Gaussian distribution. Uncertainty representation is first designed for estimating the uncertainty scope of the entity pairs after transferring feature representations into a Gaussian distribution. Further, to better integrate the neighbors with uncertainty characteristics for entity features, we design an uncertainty-aware relational graph neural network (UR-GNN) to conduct convolution ope
    
[^80]: NewsBench：系统性评估LLM在中国新闻编辑应用中的写作水平和安全性遵从能力

    NewsBench: Systematic Evaluation of LLMs for Writing Proficiency and Safety Adherence in Chinese Journalistic Editorial Applications

    [https://arxiv.org/abs/2403.00862](https://arxiv.org/abs/2403.00862)

    NewsBench是一个评估LLMs在中国新闻写作水平和安全性遵从能力的基准框架，揭示了在创造性写作任务中LLMs相对不足的新闻伦理遵守方面的需求。

    

    这项研究提出了NewsBench，这是一个新颖的基准框架，旨在评估大型语言模型（LLMs）在中国新闻写作水平（JWP）和安全性遵从（SA）方面的能力，弥补了新闻伦理与人工智能利用风险之间的差距。NewsBench包括5个编辑应用中的1,267项任务，7个方面（包括安全性和新闻写作，以及4个详细要面），涵盖24个新闻主题领域，采用基于两种GPT-4的自动评估协议，并经过人类评估验证。我们对11个LLM的全面分析突出了GPT-4和ERNIE Bot作为表现最佳，但在创造性写作任务中揭示了新闻伦理遵守方面的相对不足。这些发现强调了AI生成的新闻内容需要提高伦理指导，标志着以新闻标准和安全性对齐AI能力迈出了一步。

    arXiv:2403.00862v1 Announce Type: cross  Abstract: This study presents NewsBench, a novel benchmark framework developed to evaluate the capability of Large Language Models (LLMs) in Chinese Journalistic Writing Proficiency (JWP) and their Safety Adherence (SA), addressing the gap between journalistic ethics and the risks associated with AI utilization. Comprising 1,267 tasks across 5 editorial applications, 7 aspects (including safety and journalistic writing with 4 detailed facets), and spanning 24 news topics domains, NewsBench employs two GPT-4 based automatic evaluation protocols validated by human assessment. Our comprehensive analysis of 11 LLMs highlighted GPT-4 and ERNIE Bot as top performers, yet revealed a relative deficiency in journalistic ethic adherence during creative writing tasks. These findings underscore the need for enhanced ethical guidance in AI-generated journalistic content, marking a step forward in aligning AI capabilities with journalistic standards and safet
    
[^81]: OSCaR:对象状态字幕和状态变化表示

    OSCaR: Object State Captioning and State Change Representation

    [https://arxiv.org/abs/2402.17128](https://arxiv.org/abs/2402.17128)

    本文介绍了一个新的数据集和基准OSCaR，旨在解决描述复杂视觉环境中对象状态变化的问题，为评估多模态大型语言提供了一个新的实验平台。

    

    arXiv:2402.17128v3 公告类型: 跨 面向人类在真实世界环境中的交互视角，智能模型推断和理解对象状态的变化能力是人工智能研究的一个重要且具有挑战性的方面。该任务涉及描述复杂的视觉环境，识别活跃对象，以及通过语言解释它们的变化。传统方法将对象字幕和状态变化检测进行隔离，提供了对动态环境的有限视图。此外，依赖于一小套符号化词汇来表示变化限制了语言的表达力。为了解决这些挑战，在本文中，我们介绍了对象状态字幕和状态变化表示（OSCaR）数据集和基准。OSCaR包括来自各种主观视角视频集合的14,084个带注释视频片段，涵盖近1,000个独特对象。它为评估多模态大型语言提供了一个新的实验平台。

    arXiv:2402.17128v3 Announce Type: cross  Abstract: The capability of intelligent models to extrapolate and comprehend changes in object states is a crucial yet demanding aspect of AI research, particularly through the lens of human interaction in real-world settings. This task involves describing complex visual environments, identifying active objects, and interpreting their changes as conveyed through language. Traditional methods, which isolate object captioning and state change detection, offer a limited view of dynamic environments. Moreover, relying on a small set of symbolic words to represent changes has restricted the expressiveness of the language. To address these challenges, in this paper, we introduce the Object State Captioning and State Change Representation (OSCaR) dataset and benchmark. OSCaR consists of 14,084 annotated video segments with nearly 1,000 unique objects from various egocentric video collections. It sets a new testbed for evaluating multimodal large langua
    
[^82]: 在声明验证的背景下评估ChatGPT的推理能力

    Assessing the Reasoning Abilities of ChatGPT in the Context of Claim Verification

    [https://arxiv.org/abs/2402.10735](https://arxiv.org/abs/2402.10735)

    我们提出了一个逻辑推理框架，用于评估ChatGPT在声明验证中的推理能力，发现其在归纳推理方面存在困难，并提出了一种缓解方法。

    

    当前有关LLMs的推理能力的辩论正在日益激烈。我们从声明/谣言验证的角度来审视这个问题。我们提出了第一个逻辑推理框架，旨在将任何声明或传言与证据结合，拆分成验证所需的基本推理步骤。基于我们的框架，我们整理了两个注释集合，其中包括来自维基百科的合成数据集和源自Twitter上流传的谣言的真实数据集。我们使用它们来评估GPT-3.5-Turbo和GPT-4（以下简称为ChatGPT）在我们框架的背景下的推理能力，并提供了彻底的分析。我们的研究表明，ChatGPT在归纳推理方面存在困难，尽管可以通过使用手动的思维链路（Chain of Thought，CoT）来缓解这一问题，而非零编码（Zero Shot，ZS）和ZS CoT方法。我们的研究有助于不断增长的研究领域，表明Cha

    arXiv:2402.10735v1 Announce Type: new  Abstract: The reasoning capabilities of LLMs are currently hotly debated. We examine the issue from the perspective of claim/rumour verification. We propose the first logical reasoning framework designed to break down any claim or rumor paired with evidence into the atomic reasoning steps necessary for verification. Based on our framework, we curate two annotated collections of such claim/evidence pairs: a synthetic dataset from Wikipedia and a real-world set stemming from rumours circulating on Twitter. We use them to evaluate the reasoning capabilities of GPT-3.5-Turbo and GPT-4 (hereinafter referred to as ChatGPT) within the context of our framework, providing a thorough analysis. Our results show that ChatGPT struggles in abductive reasoning, although this can be somewhat mitigated by using manual Chain of Thought (CoT) as opposed to Zero Shot (ZS) and ZS CoT approaches. Our study contributes to the growing body of research suggesting that Cha
    
[^83]: LLMs和人类条件

    LLMs and the Human Condition

    [https://arxiv.org/abs/2402.08403](https://arxiv.org/abs/2402.08403)

    本文提出了将三个成熟的人类决策理论整合到一起，形成了一个目的性人类行动模型。同时，将语言作为行动的观点应用于对话用户界面。通过理解ChatGPT的智能来源，可以在减少资源的同时获得对我们之间关系的认识。

    

    本文介绍了人类决策的三个成熟理论，并描述了如何将它们整合起来提供一个目的性人类行动的模型。同时，将语言作为行动的观点应用于对话用户界面。最近，基于理论的人工智能研究遇到了困难，本文旨在重新激发对理解LLMs实际执行的兴趣，而不仅仅是在所有数据上运行难以理解的机器学习例程。当一台售价不到50美元的树莓派电脑比第一台商业Cray超级计算机快400倍时，大型科技公司可以接近拥有无数随机打字并生成有意义文字的猴子。通过理解ChatGPT的表现智能的来源，也许我们可以用更少的资源进行同样的魔术，并在此过程中获得一些关于我们之间关系的理解。

    This paper presents three established theories of human decision-making and describes how they can be integrated to provide a model of purposive human action. Taking seriously the idea of language as action the model is then applied to the conversational user interfaces. Theory based AI research has had a hard time recently and the aim here is to revitalise interest in understanding what LLMs are actually doing other than running poorly understood machine learning routines over all the data the relevant Big Tech company can hoover up. When a raspberry pi computer for under 50USD is up to 400 times faster than the first commercial Cray super computer~\cite{crayVpi}, Big Tech can get really close to having an infinite number of monkeys typing at random and producing text, some of which will make sense. By understanding where ChatGPT's apparent intelligence comes from, perhaps we can perform the magic with fewer resources and at the same time gain some understanding about our relationship
    
[^84]: ANLS* -- 一种适用于生成型大语言模型的通用文档处理度量方法

    ANLS* -- A Universal Document Processing Metric for Generative Large Language Models

    [https://arxiv.org/abs/2402.03848](https://arxiv.org/abs/2402.03848)

    ANLS*是一种用于生成型模型的新度量方法，针对各种任务包括信息提取和分类任务进行评估。它扩展了现有的ANLS度量方法，可以作为替代方案使用。

    

    传统上，在文档分类和信息提取等任务中，区分模型一直是主要选择。这些模型做出的预测可以分为有限数量的预定义类别，便于进行二元真假评估，并能直接计算F1分数等指标。然而，生成型大语言模型（GLLMs）的最新进展促使领域发生了转变，因为它们具备了强大的零-shot能力，消除了下游数据集和计算昂贵的微调的需求。然而，评估GLLMs存在挑战，因为对于GLLMs的预测，不能应用于区分模型所使用的二元真假评估方法。本文引入了一种用于生成型模型的新度量方法，称为ANLS*，用于评估各种任务，包括信息提取和分类任务。ANLS*度量方法扩展了现有ANLS度量方法，可作为一种即插即用的替代方案。

    Traditionally, discriminative models have been the predominant choice for tasks like document classification and information extraction. These models make predictions that fall into a limited number of predefined classes, facilitating a binary true or false evaluation and enabling the direct calculation of metrics such as the F1 score. However, recent advancements in generative large language models (GLLMs) have prompted a shift in the field due to their enhanced zero-shot capabilities, which eliminate the need for a downstream dataset and computationally expensive fine-tuning. However, evaluating GLLMs presents a challenge as the binary true or false evaluation used for discriminative models is not applicable to the predictions made by GLLMs. This paper introduces a new metric for generative models called ANLS* for evaluating a wide variety of tasks, including information extraction and classification tasks. The ANLS* metric extends existing ANLS metrics as a drop-in-replacement and i
    
[^85]: EasyInstruct：一个易于使用的用于大型语言模型的指令处理框架

    EasyInstruct: An Easy-to-use Instruction Processing Framework for Large Language Models

    [https://arxiv.org/abs/2402.03049](https://arxiv.org/abs/2402.03049)

    EasyInstruct是一个易于使用的用于大型语言模型的指令处理框架，通过模块化指令生成、选择和提示，并考虑它们的组合和交互，使指令处理更加方便和高效。

    

    近年来，指令调整已经引起了越来越多的关注，并成为增强大型语言模型（LLMs）能力的一种关键技术。为了构建高质量的指令数据集，已经提出了许多指令处理方法，旨在在数据数量和数据质量之间达到精巧的平衡。然而，由于各种指令处理方法之间仍然存在不一致，目前没有标准的开源指令处理实现框架可供社区使用，这使得从业者无法进一步开发和推进。为了促进指令处理的研究和开发，我们提出了EasyInstruct，一个易于使用的用于LLMs的指令处理框架，它将指令生成、选择和提示模块化，并考虑它们的组合和交互。EasyInstruct已经在https://github.com/zjunlp/EasyInstruct上公开发布，并得到了积极维护。

    In recent years, instruction tuning has gained increasing attention and emerged as a crucial technique to enhance the capabilities of Large Language Models (LLMs). To construct high-quality instruction datasets, many instruction processing approaches have been proposed, aiming to achieve a delicate balance between data quantity and data quality. Nevertheless, due to inconsistencies that persist among various instruction processing methods, there is no standard open-source instruction processing implementation framework available for the community, which hinders practitioners from further developing and advancing. To facilitate instruction processing research and development, we present EasyInstruct, an easy-to-use instruction processing framework for LLMs, which modularizes instruction generation, selection, and prompting, while also considering their combination and interaction. EasyInstruct is publicly released and actively maintained at https://github.com/zjunlp/EasyInstruct, along 
    
[^86]: DenseFormer: 通过深度加权平均增强Transformer中的信息流

    DenseFormer: Enhancing Information Flow in Transformers via Depth Weighted Averaging

    [https://arxiv.org/abs/2402.02622](https://arxiv.org/abs/2402.02622)

    DenseFormer是对Transformer的简单修改，通过在每个transformer块之后进行深度加权平均，提高了模型的困惑度。学到的加权平均权重揭示了信息流的连贯模式，使得DenseFormer具有更高的数据效率，并且在相同困惑度下胜过传统的Transformer模型。

    

    从Vaswani等人（2017）的Transformer架构现已普遍应用于各个应用领域，从自然语言处理到语音处理和图像理解。我们提出了DenseFormer，这是对标准架构的简单修改，提高了模型的困惑度，而不增加其大小-对于拥有100B参数范围的大规模模型，只需添加几千个参数。我们的方法在每个transformer块之后依靠额外的平均步骤，计算当前和过去表示的加权平均-我们将这个操作称为深度加权平均（DWA）。学到的DWA权重展现了信息流的连贯模式，揭示了来自远层的激活的强大且结构化的重复使用。实验证明DenseFormer具有更高的数据效率，能够达到比更深的transformer模型相同的困惑度，并且在相同困惑度下，这些新模型在性能上超过了transformer基准模型。

    The transformer architecture from Vaswani et al. (2017) is now ubiquitous across application domains, from natural language processing to speech processing and image understanding. We propose DenseFormer, a simple modification to the standard architecture that improves the perplexity of the model without increasing its size -- adding a few thousand parameters for large-scale models in the 100B parameters range. Our approach relies on an additional averaging step after each transformer block, which computes a weighted average of current and past representations -- we refer to this operation as Depth-Weighted-Average (DWA). The learned DWA weights exhibit coherent patterns of information flow, revealing the strong and structured reuse of activations from distant layers. Experiments demonstrate that DenseFormer is more data efficient, reaching the same perplexity of much deeper transformer models, and that for the same perplexity, these new models outperform transformer baselines in terms
    
[^87]: LLM外科医生

    The LLM Surgeon

    [https://arxiv.org/abs/2312.17244](https://arxiv.org/abs/2312.17244)

    通过数据驱动压缩现有预训练模型，我们提供了一个改进权重更新的通用框架，以更有效地捕捉更多权重之间的相关性，同时保持计算效率。

    

    最先进的语言模型越来越庞大，以期在大量可用的文本数据集上实现最佳性能。然而，Transformer架构的巨大规模使得在计算、环境或设备特定约束下部署模型变得困难。我们探讨了对现有预训练模型进行数据驱动压缩作为训练较小模型的替代方法。为此，我们将目标损失景观的Kronecker分解曲率近似扩展到大型语言模型中。通过这样做，我们既可以计算可删除结构的动态分配，也可以更新剩余权重以考虑删除。我们提供了一个通用框架，用于非结构化、半结构化和结构化修剪，并改进了权重更新以捕捉更多权重之间的相关性，同时保持计算效率。实验证明...

    arXiv:2312.17244v2 Announce Type: replace-cross  Abstract: State-of-the-art language models are becoming increasingly large in an effort to achieve the highest performance on large corpora of available textual data. However, the sheer size of the Transformer architectures makes it difficult to deploy models within computational, environmental or device-specific constraints. We explore data-driven compression of existing pretrained models as an alternative to training smaller models from scratch. To do so, we scale Kronecker-factored curvature approximations of the target loss landscape to large language models. In doing so, we can compute both the dynamic allocation of structures that can be removed as well as updates of remaining weights that account for the removal. We provide a general framework for unstructured, semi-structured and structured pruning and improve upon weight updates to capture more correlations between weights, while remaining computationally efficient. Experimental
    
[^88]: 生成解释以理解和修复基于嵌入的实体对齐

    Generating Explanations to Understand and Repair Embedding-based Entity Alignment

    [https://arxiv.org/abs/2312.04877](https://arxiv.org/abs/2312.04877)

    该论文提出了一个可以生成解释以理解和修复基于嵌入的实体对齐结果的框架，通过构建匹配子图和对齐依赖图，解决对齐冲突，实验表明其有效性和泛化性。

    

    实体对齐（EA）旨在在不同知识图中寻找相同的实体，这是数据库研究中一个长期存在的任务。最近的研究利用深度学习将实体嵌入向量空间，并通过最近邻搜索来对齐它们。尽管基于嵌入的EA在近年取得了显著的成功，但缺乏对齐决策的解释。在本文中，我们提出了第一个能够为理解和修复基于嵌入的EA结果生成解释的框架。给定由嵌入模型产生的EA对，我们首先比较其邻近实体和关系，构建一个匹配子图作为局部解释。然后构建一个对齐依赖图，以抽象的角度理解该对。最后，我们通过基于依赖图解决三种类型的对齐冲突来修复这对。对各种EA数据集的实验表明了其有效性和泛化性。

    arXiv:2312.04877v3 Announce Type: replace  Abstract: Entity alignment (EA) seeks identical entities in different knowledge graphs, which is a long-standing task in the database research. Recent work leverages deep learning to embed entities in vector space and align them via nearest neighbor search. Although embedding-based EA has gained marked success in recent years, it lacks explanations for alignment decisions. In this paper, we present the first framework that can generate explanations for understanding and repairing embedding-based EA results. Given an EA pair produced by an embedding model, we first compare its neighbor entities and relations to build a matching subgraph as a local explanation. We then construct an alignment dependency graph to understand the pair from an abstract perspective. Finally, we repair the pair by resolving three types of alignment conflicts based on dependency graphs. Experiments on a variety of EA datasets demonstrate the effectiveness, generalizatio
    
[^89]: Prompt Highlighter: 多模态LLM互动控制的研究

    Prompt Highlighter: Interactive Control for Multi-Modal LLMs

    [https://arxiv.org/abs/2312.04302](https://arxiv.org/abs/2312.04302)

    提出了一种称为Prompt Highlighter的新型推理方法，通过突出显示特定提示跨度，实现用户在生成过程中交互控制焦点，并基于高亮标记形成正规且无条件的上下文对，从而在没有分类器的情况下引导模型的自回归生成。

    

    这项研究关注多模态LLMs（LLMs和VLMs）推理中的一个关键方面：显式可控文本生成。多模态LLMs通过语义生成的能力增强了多模态理解，但由于其自回归生成的特性，解释性较差且更加依赖提示内容。尽管操作提示格式可以改进输出，但设计针对每个任务的具体和精确提示可能具有挑战性且效果不佳。为了解决这一问题，我们引入了一种新颖的推理方法，Prompt Highlighter，使用户能够突出显示特定提示跨度以在生成过程中交互控制焦点。受无分类器扩散引导的启发，我们基于突出显示的标记形成常规和无条件的上下文对，证明了模型中的自回归生成可以以无分类器的方式进行引导。值得注意的是，在推理过程中，我们发现，引导过程可以显著提高输出质量并增强模型的解释能力，同时减轻了对提示内容的依赖。

    arXiv:2312.04302v2 Announce Type: replace-cross  Abstract: This study targets a critical aspect of multi-modal LLMs' (LLMs&VLMs) inference: explicit controllable text generation. Multi-modal LLMs empower multi-modality understanding with the capability of semantic generation yet bring less explainability and heavier reliance on prompt contents due to their autoregressive generative nature. While manipulating prompt formats could improve outputs, designing specific and precise prompts per task can be challenging and ineffective. To tackle this issue, we introduce a novel inference method, Prompt Highlighter, which enables users to highlight specific prompt spans to interactively control the focus during generation. Motivated by the classifier-free diffusion guidance, we form regular and unconditional context pairs based on highlighted tokens, demonstrating that the autoregressive generation in models can be guided in a classifier-free way. Notably, we find that, during inference, guidin
    
[^90]: CoachLM：自动指导修订提高LLM指导调整中的数据质量

    CoachLM: Automatic Instruction Revisions Improve the Data Quality in LLM Instruction Tuning

    [https://arxiv.org/abs/2311.13246](https://arxiv.org/abs/2311.13246)

    CoachLM 提出了一种新颖方法来增强指导数据集的质量，通过自动修订样本而非丢弃低质量样本，从而解决了现有方法的局限性。

    

    指导调整对于使语言学习模型（LLM）能够回应人类指令至关重要。用于调整的指令对的质量极大影响LLM的性能。然而，人工创建高质量指令数据集成本高，导致LLM的自动生成指令对被广泛采纳作为一种流行的替代方法。为了确保LLM生成的指导数据集的高质量，提出了几种方法。然而，现有方法要么通过过滤大量样本来降低数据集完整性，要么不适合工业应用。在本文中，我们提出CoachLM，一个新颖的方法，通过对数据集中的样本进行自动修订来增强指导数据集的质量。CoachLM是从专家修订的样本中训练出来的，并显著增加了

    arXiv:2311.13246v2 Announce Type: replace  Abstract: Instruction tuning is crucial for enabling Language Learning Models (LLMs) in responding to human instructions. The quality of instruction pairs used for tuning greatly affects the performance of LLMs. However, the manual creation of high-quality instruction datasets is costly, leading to the adoption of automatic generation of instruction pairs by LLMs as a popular alternative. To ensure the high quality of LLM-generated instruction datasets, several approaches have been proposed. Nevertheless, existing methods either compromise dataset integrity by filtering a large proportion of samples, or are unsuitable for industrial applications. In this paper, instead of discarding low-quality samples, we propose CoachLM, a novel approach to enhance the quality of instruction datasets through automatic revisions on samples in the dataset. CoachLM is trained from the samples revised by human experts and significantly increases the proportion o
    
[^91]: TableLlama：面向表格的开放大型通用模型

    TableLlama: Towards Open Large Generalist Models for Tables

    [https://arxiv.org/abs/2311.09206](https://arxiv.org/abs/2311.09206)

    本文旨在开发用于各种基于表格任务的开源大型语言模型，通过构建新数据集TableInstruct和开发第一个面向表格的开源通用模型TableLlama，在表现方面取得了可比或更好的成果。

    

    半结构化表格是无处不在的。目前的方法通常需要对表格进行预训练或特殊的模型架构设计，受限于特定的表格类型，或对表格和任务有简化的假设。本文旨在开发开源的大型语言模型（LLMs），作为各种基于表格任务的通用工具的第一步。为此，我们构建了一个包含各种真实表格和任务的新数据集TableInstruct，以用于指令调整和评估LLMs。我们进一步利用LongLoRA对Llama 2 (7B)进行微调，开发了第一个面向表格的开源通用模型TableLlama，以应对长上下文挑战。我们在同领域和跨领域环境下进行了实验。在8个同领域任务中的7个任务中，TableLlama在性能上实现了与SOT相当或更好的表现。

    arXiv:2311.09206v2 Announce Type: replace  Abstract: Semi-structured tables are ubiquitous. There has been a variety of tasks that aim to automatically interpret, augment, and query tables. Current methods often require pretraining on tables or special model architecture design, are restricted to specific table types, or have simplifying assumptions about tables and tasks. This paper makes the first step towards developing open-source large language models (LLMs) as generalists for a diversity of table-based tasks. Towards that end, we construct TableInstruct, a new dataset with a variety of realistic tables and tasks, for instruction tuning and evaluating LLMs. We further develop the first open-source generalist model for tables, TableLlama, by fine-tuning Llama 2 (7B) with LongLoRA to address the long context challenge. We experiment under both in-domain setting and out-of-domain setting. On 7 out of 8 in-domain tasks, TableLlama achieves comparable or better performance than the SOT
    
[^92]: 利用大型语言模型进行零-shot命名实体识别的自我改进

    Self-Improving for Zero-Shot Named Entity Recognition with Large Language

    [https://arxiv.org/abs/2311.08921](https://arxiv.org/abs/2311.08921)

    本研究提出了一个无需训练的自我改进框架，利用未标记语料库激发大型语言模型的自我学习能力，从而推动零-shot命名实体识别性能边界。

    

    最近，探索将强大的大型语言模型(LLMs)应用于命名实体识别(NER)任务引起了很大关注。本研究通过提出一个无需训练的自我改进框架，利用未标记语料库来激发LLMs的自我学习能力，从而推动LLMs在零-shot NER上的性能边界。首先，我们使用LLMs对未标注语料库进行自一致性预测，并获得自我注释数据集。其次，我们探索各种策略来选择可靠的注释，形成一个可靠的自我注释数据集。最后，对于每个测试输入，我们从可靠的自我注释数据集中检索演示，并通过上下文学习进行推断。在四个基准测试上的实验表明，我们的框架取得了显著的性能提升。通过全面的实验分析，我们发现增加未标记语料库的规模或迭代次数

    arXiv:2311.08921v2 Announce Type: replace  Abstract: Exploring the application of powerful large language models (LLMs) on the named entity recognition (NER) task has drawn much attention recently. This work pushes the performance boundary of zero-shot NER with LLMs by proposing a training-free self-improving framework, which utilizes an unlabeled corpus to stimulate the self-learning ability of LLMs. First, we use the LLM to make predictions on the unlabeled corpus using self-consistency and obtain a self-annotated dataset. Second, we explore various strategies to select reliable annotations to form a reliable self-annotated dataset. Finally, for each test input, we retrieve demonstrations from the reliable self-annotated dataset and perform inference via in-context learning. Experiments on four benchmarks show substantial performance improvements achieved by our framework. Through comprehensive experimental analysis, we find that increasing the size of unlabeled corpus or iterations 
    
[^93]: Reddit上关于叙事中的道德判断：通过社交常识和语言信号调查道德火花

    Moral Judgments in Narratives on Reddit: Investigating Moral Sparks via Social Commonsense and Linguistic Signals

    [https://arxiv.org/abs/2310.19268](https://arxiv.org/abs/2310.19268)

    通过研究Reddit上的道德判断，本研究探讨了社交常识和语言信号对于道德火花的影响，为人类道德判断提供了深入理解。

    

    arXiv:2310.19268v2 公告类型：替换-跨 文摘：机器伦理确保人工智能（AI）模型和代理的道德行为。研究现实生活中的应用有助于学习在许多情况下实践道德，为了更好地理解不同背景下的人类道德复杂性提供了宝贵的数据。在本文中，我们研究社交媒体平台，以理解现实生活中的伦理情景和人类道德判断。我们研究了一个名为r/AmITheAsshole的热门Reddit子社区中的帖子，作者和评论者在这里分享谁应该受到责备的道德判断。我们采用计算技术来研究影响道德判断的潜在推理。我们关注原始帖子中的节选，我们将其命名为道德火花，评论者包括这些节选以表明他们判断的动机是什么。为此，我们研究了（1）激活社交常识的事件和（2）语言信号如何影响道德火花的分配及其子初始化。

    arXiv:2310.19268v2 Announce Type: replace-cross  Abstract: Machine ethics ensures ethical conduct in Artificial Intelligence (AI) models and agents. Examining real-life applications benefit learning practical ethics in many situations, offering valuable data to grasp the complexities of human ethics in diverse contexts. In this paper, we examine social media platforms for understanding real-life ethical scenarios and human moral judgments. We examine posts from a popular Reddit subreddit (i.e., a subcommunity) called r/AmITheAsshole, where authors and commenters share their moral judgments on who is blameworthy. We employ computational techniques to investigate the underlying reasoning influencing moral judgments. We focus on excerpts-which we term moral sparks-from original posts that commenters include to indicate what motivates their judgments. To this end, we examine how (1) events activating social commonsense and (2) linguistic signals affect moral sparks assignment and their sub
    
[^94]: 语言模型存在幻觉，但在事实验证方面可能表现出色

    Language Models Hallucinate, but May Excel at Fact Verification

    [https://arxiv.org/abs/2310.14564](https://arxiv.org/abs/2310.14564)

    语言模型存在幻觉现象，但研究表明它们可以作为有效的事实验证器，甚至在某些情况下胜过更强大的语言模型。

    

    自然语言处理(NLP)的最新进展很大程度上要归功于大型语言模型(LLMs)的显著进步。然而，LLMs经常会“幻觉”，导致产生与事实不符的输出。我们精心设计的人类评估证实了严重的幻觉问题，发现即使GPT-3.5的事实输出不到25%。这凸显了事实验证器的重要性，以衡量和激励进展。我们的系统调查确认了LLMs可以被重新用作有效的事实验证器，与人类判断具有很强的相关性。令人惊讶的是，在我们的研究中，表现最差的生成器FLAN-T5-11B作为事实验证器表现最佳，甚至优于GPT3.5和ChatGPT等更优秀的LLMs。深入研究，我们分析了这些LLMs对高质量证据的依赖，以及它们在鲁棒性和泛化能力方面的不足。我们的研究提出了一些见解。

    arXiv:2310.14564v2 Announce Type: replace  Abstract: Recent progress in natural language processing (NLP) owes much to remarkable advances in large language models (LLMs). Nevertheless, LLMs frequently "hallucinate," resulting in non-factual outputs. Our carefully-designed human evaluation substantiates the serious hallucination issue, revealing that even GPT-3.5 produces factual outputs less than 25% of the time. This underscores the importance of fact verifiers in order to measure and incentivize progress. Our systematic investigation affirms that LLMs can be repurposed as effective fact verifiers with strong correlations with human judgments. Surprisingly, FLAN-T5-11B, the least factual generator in our study, performs the best as a fact verifier, even outperforming more capable LLMs like GPT3.5 and ChatGPT. Delving deeper, we analyze the reliance of these LLMs on high-quality evidence, as well as their deficiencies in robustness and generalization ability. Our study presents insigh
    
[^95]: 通过元学习和代表性语言化器实现有效的结构化提示

    Effective Structured Prompting by Meta-Learning and Representative Verbalizer

    [https://arxiv.org/abs/2306.00618](https://arxiv.org/abs/2306.00618)

    通过使用提示池和构建基于实例的提示以及引入新颖的软语言化器，提出了一种通过元学习和代表性语言化器实现有效的结构化提示的方法

    

    预训练的遮蔽语言模型（MLM）的提示调整在自然语言处理任务中显示出有限标记示例的良好性能。它为下游任务调整提示，并使用语言化器来连接预测的标记和标签预测。由于训练数据有限，提示初始化对于提示调整至关重要。最近，MetaPrompting（Hou等，2022）使用元学习来学习所有特定任务提示的共享初始化。然而，当任务复杂时，单一初始化无法获得所有任务和样本的良好提示。此外，由于MLM通常很大，MetaPrompting需要调整整个MLM，导致计算和内存负担沉重。为了解决这些问题，我们使用提示池提取更多任务知识，并通过注意力构建基于实例的提示。我们进一步提出了一种新颖的软语言化器（RepVerb）...（剩余内容未提供）

    arXiv:2306.00618v2 Announce Type: replace-cross  Abstract: Prompt tuning for pre-trained masked language models (MLM) has shown promising performance in natural language processing tasks with few labeled examples. It tunes a prompt for the downstream task, and a verbalizer is used to bridge the predicted token and label prediction. Due to the limited training data, prompt initialization is crucial for prompt tuning. Recently, MetaPrompting (Hou et al., 2022) uses meta-learning to learn a shared initialization for all task-specific prompts. However, a single initialization is insufficient to obtain good prompts for all tasks and samples when the tasks are complex. Moreover, MetaPrompting requires tuning the whole MLM, causing a heavy burden on computation and memory as the MLM is usually large. To address these issues, we use a prompt pool to extract more task knowledge and construct instance-dependent prompts via attention. We further propose a novel soft verbalizer (RepVerb) which con
    
[^96]: 多尺度对比知识共同蒸馏用于事件时间关系抽取

    Multi-Scale Contrastive Knowledge Co-Distillation for Event Temporal Relation Extraction

    [https://arxiv.org/abs/2209.00568](https://arxiv.org/abs/2209.00568)

    提出了MulCo：多尺度对比知识共同蒸馏用于全面提高所有类型时间数据集性能

    

    事件时间关系抽取（ETRE）是一个关键但具有挑战性的问题。事件对位于不同距离的话语中，我们称之为接近性带。关于位于更远（即“长”）或更近（即“短”）接近性带的事件对的时间顺序传达方式不同。目前ETRE模型往往在位于短或长接近性带的事件上表现良好，但不能同时表现良好。然而，现实世界中的自然文本包含所有类型的时间事件对。在本文中，我们提出了MulCo：多尺度对比知识共同蒸馏，这是一种融合方法，可以跨多个事件对接近性带共享知识，以提高对所有类型时间数据集的性能。我们的实验结果表明MulCo成功地整合了跨短和长接近性带的与时间推理相关的语言线索。

    arXiv:2209.00568v2 Announce Type: replace-cross  Abstract: Event Temporal Relation Extraction (ETRE) is a crucial yet challenging problem. Event pairs are situated within a discourse at different distances, which we refer to as proximity bands. The temporal ordering communicated about event pairs situated at more remote (i.e., ``long'') or less remote (i.e., ``short'') proximity bands is encoded differently. SOTA ETRE models have tended to perform well on events situated at either short or long proximity bands, but not both. Yet, real-world, natural texts contain all types of temporal event-pairs. In this paper, we present MulCo: Multi-Scale Contrastive Knowledge Co-Distillation, a fusion approach that shares knowledge across multiple event pair proximity bands in order to improve performance on all types of temporal datasets. Our experimental results show that MulCo successfully integrates linguistic cues pertaining to temporal reasoning across both short and long proximity bands and 
    
[^97]: 将领域特定的异构知识融入统一表示的预训练语言模型

    Pre-training Language Model Incorporating Domain-specific Heterogeneous Knowledge into A Unified Representation

    [https://arxiv.org/abs/2109.01048](https://arxiv.org/abs/2109.01048)

    本文提出了一种名为HKLM的异构知识语言模型，能够统一处理包括非结构化文本、半结构化文本和结构化文本在内的所有文本形式，通过不同的目标学习词知识、实体知识和主题知识，实验证明其性能优于预训练模型。

    

    现有技术从不同角度扩展了BERT，例如设计不同的预训练任务、不同的语义粒度和不同的模型架构。很少有模型考虑从不同的文本格式扩展BERT。在本文中，我们提出了一种异构知识语言模型（HKLM），一种统一的面向所有形式文本的预训练语言模型（PLM），包括非结构化文本、半结构化文本和结构化文本。为了捕捉这些多格式知识之间的相应关系，我们的方法使用掩码语言模型目标来学习词知识，使用三元分类目标和标题匹配目标分别学习实体知识和主题知识。为了获得前述多格式文本，我们在旅游领域构建了一个语料库，并在5个旅游NLP数据集上进行了实验。结果表明，我们的方法胜过了预训练模型。

    arXiv:2109.01048v3 Announce Type: replace  Abstract: Existing technologies expand BERT from different perspectives, e.g. designing different pre-training tasks, different semantic granularities, and different model architectures. Few models consider expanding BERT from different text formats. In this paper, we propose a heterogeneous knowledge language model (\textbf{HKLM}), a unified pre-trained language model (PLM) for all forms of text, including unstructured text, semi-structured text, and well-structured text. To capture the corresponding relations among these multi-format knowledge, our approach uses masked language model objective to learn word knowledge, uses triple classification objective and title matching objective to learn entity knowledge and topic knowledge respectively. To obtain the aforementioned multi-format text, we construct a corpus in the tourism domain and conduct experiments on 5 tourism NLP datasets. The results show that our approach outperforms the pre-train
    
[^98]: VQPy：一种面向现代视频分析的面向对象方法。

    VQPy: An Object-Oriented Approach to Modern Video Analytics. (arXiv:2311.01623v1 [cs.CV])

    [http://arxiv.org/abs/2311.01623](http://arxiv.org/abs/2311.01623)

    VQPy是一种面向对象的视频分析方法，它使用Python变体作为前端，并具有可扩展的后端，可以自动构建和优化基于视频对象的处理流程。

    

    视频分析广泛应用于当今系统和服务中。在视频分析的前沿是用户开发的视频查询，以找到特定感兴趣的对象。基于视频对象（例如人，动物，汽车等）与传统面向对象语言建模的对象相似的洞察力，我们提出了一种面向视频分析的面向对象方法。这种方法名为VQPy，包括一个前端（一种Python变体，其中包含用户可以表达视频对象及其交互的结构）和一个可扩展的后端，可以基于视频对象自动生成和优化管道。我们已经实施和开源了VQPy，它已经作为Cisco DeepVision框架的一部分产品化。

    Video analytics is widely used in contemporary systems and services. At the forefront of video analytics are video queries that users develop to find objects of particular interest. Building upon the insight that video objects (e.g., human, animals, cars, etc.), the center of video analytics, are similar in spirit to objects modeled by traditional object-oriented languages, we propose to develop an object-oriented approach to video analytics. This approach, named VQPy, consists of a frontend$\unicode{x2015}$a Python variant with constructs that make it easy for users to express video objects and their interactions$\unicode{x2015}$as well as an extensible backend that can automatically construct and optimize pipelines based on video objects. We have implemented and open-sourced VQPy, which has been productized in Cisco as part of its DeepVision framework.
    
[^99]: 知道LLMs不知道什么：一种简单而有效的自我检测方法

    Knowing What LLMs DO NOT Know: A Simple Yet Effective Self-Detection Method. (arXiv:2310.17918v1 [cs.CL])

    [http://arxiv.org/abs/2310.17918](http://arxiv.org/abs/2310.17918)

    本文提出了一种新的自我检测方法，用于判断大型语言模型 (LLMs) 无法回答的问题，以避免生成非事实性的回答。通过多样化问题的文本表达，收集答案，并检查生成的答案之间的差异，可以识别出可能生成虚假回答的问题。该方法只需要利用LLMs自身，无需其他外部资源。这种方法在Vicuna、ChatGPT和GPT-4等最新发布的LLMs上得到了有效验证。

    

    大型语言模型（LLMs）在自然语言处理（NLP）任务中展现出巨大的潜力。然而，最近的文献揭示了LLMs会偶尔生成非事实性的回答，这影响了它们进一步利用的可靠性。在本文中，我们提出了一种新颖的自我检测方法，用于检测LLMs不知道的问题，以避免生成非事实性的结果。具体来说，我们首先使给定问题的文本表达多样化，并收集相应的答案。然后，我们检查生成的答案之间的差异，以识别模型可能生成虚假回答的问题。所有以上步骤都可以通过提示LLMs自身来完成，而无需参考任何其他外部资源。我们进行了全面的实验，并证明了我们方法在最近发布的LLMs（如Vicuna、ChatGPT和GPT-4）上的有效性。

    Large Language Models (LLMs) have shown great potential in Natural Language Processing (NLP) tasks. However, recent literature reveals that LLMs generate nonfactual responses intermittently, which impedes the LLMs' reliability for further utilization. In this paper, we propose a novel self-detection method to detect which questions that a LLM does not know that are prone to generate nonfactual results. Specifically, we first diversify the textual expressions for a given question and collect the corresponding answers. Then we examine the divergencies between the generated answers to identify the questions that the model may generate falsehoods. All of the above steps can be accomplished by prompting the LLMs themselves without referring to any other external resources. We conduct comprehensive experiments and demonstrate the effectiveness of our method on recently released LLMs, e.g., Vicuna, ChatGPT, and GPT-4.
    
[^100]: 对大型语言模型的约束文本生成进行了全面评估

    A Comprehensive Evaluation of Constrained Text Generation for Large Language Models. (arXiv:2310.16343v1 [cs.CL])

    [http://arxiv.org/abs/2310.16343](http://arxiv.org/abs/2310.16343)

    该研究全面评估了大型语言模型在约束文本生成方面的应用，研究了LLM的能力和不足，并提供了未来发展的见解。

    

    自然语言生成 (NLG) 和大型语言模型 (LLM) 的进步使得在各种任务中能够生成熟练的文本。然而，由于LLM的不透明性，将复杂的约束集成到神经文本生成中仍然具有挑战性。本研究调查了LLM的约束文本生成，其中在LLM的生成过程中应用了预定义的约束。我们的研究考察了多个LLM，包括ChatGPT和GPT-4，并将约束分为词汇、结构和关系类型。我们还提出了各种基准来促进公平评估。研究解决了一些关键研究问题，包括LLM与约束的遵守程度。结果揭示了LLM集成约束的能力和不足，并为未来发展约束文本生成提供了见解。代码和数据集将在被接受后发布。

    Advancements in natural language generation (NLG) and large language models (LLMs) have led to proficient text generation in various tasks. However, integrating intricate constraints into neural text generation, due to LLMs' opacity, remains challenging. This study investigates constrained text generation for LLMs, where predefined constraints are applied during LLM's generation process. Our research examines multiple LLMs, including ChatGPT and GPT-4, categorizing constraints into lexical, structural, and relation-based types. We also present various benchmarks to facilitate fair evaluation. The study addresses some key research questions, including the extent of LLMs' compliance with constraints. Results illuminate LLMs' capacity and deficiency to incorporate constraints and provide insights for future developments in constrained text generation. Codes and datasets will be released upon acceptance.
    
[^101]: TiC-CLIP: CLIP模型的持续训练

    TiC-CLIP: Continual Training of CLIP Models. (arXiv:2310.16226v1 [cs.CV])

    [http://arxiv.org/abs/2310.16226](http://arxiv.org/abs/2310.16226)

    该论文提出了用于训练视觉-语言模型的大规模时间连续 (TiC) 基准，使用这些基准评估了现有模型的时间鲁棒性，并展示了一种简单有效的排练方法来持续训练模型。

    

    保持大型基础模型与最新数据保持同步本身就是昂贵的。为了避免不断重新训练的高成本，持续训练这些模型至关重要。这个问题被缺乏大规模连续学习基准或基线所加剧。我们引入了用于训练视觉-语言模型的第一批 Web 规模时间连续（TiC）基准：TiC-DataCompt、TiC-YFCC 和 TiC-RedCaps，其中包含超过 127 亿个时间戳图像-文本对，跨越了 9 年的时间（2014-2022）。我们首先使用这些基准来策划各种动态评估，以衡量现有模型的时间鲁棒性。我们展示了 OpenAI 的 CLIP 模型（使用 2020 年的数据进行训练）在我们策划的从 2021 年到 2022 年的检索任务中，失去了约 8% 的零-shot准确率，而与 OpenCLIP 存储库中最近训练的模型相比。然后，我们研究如何高效地对时间连续数据进行训练。我们证明了一种简单的排练方法，从上次的训练中继续训练，可以实现有效的训练。

    Keeping large foundation models up to date on latest data is inherently expensive. To avoid the prohibitive costs of constantly retraining, it is imperative to continually train these models. This problem is exacerbated by the lack of any large scale continual learning benchmarks or baselines. We introduce the first set of web-scale Time-Continual (TiC) benchmarks for training vision-language models: TiC-DataCompt, TiC-YFCC, and TiC-RedCaps with over 12.7B timestamped image-text pairs spanning 9 years (2014--2022). We first use our benchmarks to curate various dynamic evaluations to measure temporal robustness of existing models. We show OpenAI's CLIP (trained on data up to 2020) loses $\approx 8\%$ zero-shot accuracy on our curated retrieval task from 2021--2022 compared with more recently trained models in OpenCLIP repository. We then study how to efficiently train models on time-continuous data. We demonstrate that a simple rehearsal-based approach that continues training from the l
    
[^102]: AutoDAN: 在对齐的大型语言模型上生成隐蔽的越狱提示

    AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models. (arXiv:2310.04451v1 [cs.CL])

    [http://arxiv.org/abs/2310.04451](http://arxiv.org/abs/2310.04451)

    本文介绍了一种名为AutoDAN的方法，该方法旨在在对齐的大型语言模型上自动生成隐蔽的越狱提示，以解决现有越狱技术的可扩展性和隐蔽性问题。

    

    对齐的大型语言模型(LLM)是强大的语言理解和决策工具，通过与人类反馈进行广泛对齐而创建。然而，这些大型模型仍然容易受到越狱攻击的影响，攻击者可以操纵提示来引发对齐的LLM不应给出的恶意输出。研究越狱提示可以让我们深入了解LLM的局限性，并进一步指导我们如何保护它们。不幸的是，现有的越狱技术存在以下问题：(1) 可扩展性问题，攻击大量依赖手工制作提示；(2) 隐蔽性问题，攻击依赖基于标记的算法生成常常语义无意义的提示，容易通过基本困惑度测试检测。针对这些挑战，我们想回答这个问题：能否开发一种能够自动生成隐蔽越狱提示的方法？在本文中，我们介绍了AutoDAN方法。

    The aligned Large Language Models (LLMs) are powerful language understanding and decision-making tools that are created through extensive alignment with human feedback. However, these large models remain susceptible to jailbreak attacks, where adversaries manipulate prompts to elicit malicious outputs that should not be given by aligned LLMs. Investigating jailbreak prompts can lead us to delve into the limitations of LLMs and further guide us to secure them. Unfortunately, existing jailbreak techniques suffer from either (1) scalability issues, where attacks heavily rely on manual crafting of prompts, or (2) stealthiness problems, as attacks depend on token-based algorithms to generate prompts that are often semantically meaningless, making them susceptible to detection through basic perplexity testing. In light of these challenges, we intend to answer this question: Can we develop an approach that can automatically generate stealthy jailbreak prompts? In this paper, we introduce Auto
    
[^103]: 在一千年前的拉丁文本中检测句子级别的性内容

    Detecting Sexual Content at the Sentence Level in First Millennium Latin Texts. (arXiv:2309.14974v1 [cs.CL])

    [http://arxiv.org/abs/2309.14974](http://arxiv.org/abs/2309.14974)

    该研究提出使用深度学习方法在句子级别进行语义分类，以加速人文学科和语言学领域中语料库建设的过程。经过评估，该方法在检测性内容方面表现出高精度和真阳性率，并探索了不同的输入嵌入层对模型性能的影响。

    

    在这项研究中，我们提出使用深度学习方法在句子级别进行语义分类，以加快人文学科和语言学领域中语料库建设的过程，这是一项传统且耗时的任务。我们引入了一个新颖的语料库，包括约2500个句子，涵盖了从公元前300年到公元900年的性语义学（医学，情色等）。我们评估了各种句子分类方法和不同的输入嵌入层，并表明它们都比简单的基于标记的搜索方法更好。我们探索了个人言语和社会言语元数据嵌入（世纪，作者，写作类型）的整合，但发现这导致了过拟合。我们的结果表明了这种方法的有效性，使用HAN分别达到了70.60%的高精度和86.33%的真阳性率（TPR）。我们评估了数据集大小对模型性能的影响（420而不是2013），并显示出，尽管我们的模型性能可能稍有下降，但性能仍然稳定。

    In this study, we propose to evaluate the use of deep learning methods for semantic classification at the sentence level to accelerate the process of corpus building in the field of humanities and linguistics, a traditional and time-consuming task. We introduce a novel corpus comprising around 2500 sentences spanning from 300 BCE to 900 CE including sexual semantics (medical, erotica, etc.). We evaluate various sentence classification approaches and different input embedding layers, and show that all consistently outperform simple token-based searches. We explore the integration of idiolectal and sociolectal metadata embeddings (centuries, author, type of writing), but find that it leads to overfitting. Our results demonstrate the effectiveness of this approach, achieving high precision and true positive rates (TPR) of respectively 70.60% and 86.33% using HAN. We evaluate the impact of the dataset size on the model performances (420 instead of 2013), and show that, while our models per
    
[^104]: SignBank +：多语种手语翻译数据集

    SignBank+: Multilingual Sign Language Translation Dataset. (arXiv:2309.11566v1 [cs.CL])

    [http://arxiv.org/abs/2309.11566](http://arxiv.org/abs/2309.11566)

    该论文介绍了SignBank+，这是一个经过优化的手语翻译数据集，通过简化文本对文本翻译方法，提升了手语机器翻译模型的性能，并为未来的研究提供了一个开放的资源。

    

    该研究通过关注数据集的质量和简化翻译系统，推进手语机器翻译领域。我们引入了SignBank+，这是SignBank数据集的优化版本，经过清理以适用于机器翻译。与以往采用复杂的分解技术进行翻译的方法不同，我们主张采用简化的文本对文本翻译方法。我们的评估表明，在SignBank+数据集上训练的模型超过了原始数据集上的模型，建立了一个新的基准，并为未来的研究提供了一个开放的资源。

    This work advances the field of sign language machine translation by focusing on dataset quality and simplification of the translation system. We introduce SignBank+, a clean version of the SignBank dataset, optimized for machine translation. Contrary to previous works that employ complex factorization techniques for translation, we advocate for a simplified text-to-text translation approach. Our evaluation shows that models trained on SignBank+ surpass those on the original dataset, establishing a new benchmark and providing an open resource for future research.
    
[^105]: 序列到序列的西班牙预训练语言模型

    Sequence-to-Sequence Spanish Pre-trained Language Models. (arXiv:2309.11259v1 [cs.CL])

    [http://arxiv.org/abs/2309.11259](http://arxiv.org/abs/2309.11259)

    该论文介绍了一种新的序列到序列的西班牙预训练语言模型，该模型在各种序列到序列任务中表现出了竞争性能，并提供了BART、T5和BERT2BERT-style模型的西班牙版本。

    

    近年来，预训练语言模型的重大进展为许多非英语语言版本的开发铺平了道路，其中特别关注了仅编码器和仅解码器的架构。虽然西班牙语语言模型包括BERT、RoBERTa和GPT在自然语言理解和生成方面展现出了优势，但在涉及输入输出对的序列到序列任务中，缺乏编码器-解码器模型。本文通过引入实施和评估著名的仅在西班牙语语料库上进行预训练的编码器-解码器架构，开创了新的领域。具体而言，我们提出了BART、T5和BERT2BERT风格模型的西班牙语版本，并对它们在各种序列到序列任务上进行了全面评估，包括摘要、重述和生成式问答。我们的研究结果强调了所有模型的竞争性能，其中BART和T5表现出色。

    In recent years, substantial advancements in pre-trained language models have paved the way for the development of numerous non-English language versions, with a particular focus on encoder-only and decoder-only architectures. While Spanish language models encompassing BERT, RoBERTa, and GPT have exhibited prowess in natural language understanding and generation, there remains a scarcity of encoder-decoder models designed for sequence-to-sequence tasks involving input-output pairs. This paper breaks new ground by introducing the implementation and evaluation of renowned encoder-decoder architectures, exclusively pre-trained on Spanish corpora. Specifically, we present Spanish versions of BART, T5, and BERT2BERT-style models and subject them to a comprehensive assessment across a diverse range of sequence-to-sequence tasks, spanning summarization, rephrasing, and generative question answering. Our findings underscore the competitive performance of all models, with BART and T5 emerging a
    
[^106]: 通过知识蒸馏促进开放域对话系统中NSFW文本的检测

    Facilitating NSFW Text Detection in Open-Domain Dialogue Systems via Knowledge Distillation. (arXiv:2309.09749v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.09749](http://arxiv.org/abs/2309.09749)

    该论文介绍了CensorChat，一个用于监测NSFW对话的数据集，并利用知识蒸馏技术构建了高效的NSFW内容检测器。

    

    在开放域对话系统中，对话中的NSFW（不适合上班）内容可能对用户产生严重影响。然而，在对话上下文中检测NSFW语言，尤其是性爱内容方面的研究明显滞后。为了解决这个问题，我们引入了CensorChat，一个旨在检测NSFW对话的对话监控数据集。利用涉及GPT-4和ChatGPT的知识蒸馏技术，该数据集提供了一种经济高效的构建NSFW内容检测器的方法。该过程涉及收集真实的人机交互数据，并将其分解为单个话语和单轮对话，其中聊天机器人提供最后一句话。使用ChatGPT对无标签数据进行注释，作为训练集。使用ChatGPT和GPT-4作为注释器构建了合理性验证集和测试集，并使用自我批评策略解决标记中的差异。BERT模型用于微调。

    NSFW (Not Safe for Work) content, in the context of a dialogue, can have severe side effects on users in open-domain dialogue systems. However, research on detecting NSFW language, especially sexually explicit content, within a dialogue context has significantly lagged behind. To address this issue, we introduce CensorChat, a dialogue monitoring dataset aimed at NSFW dialogue detection. Leveraging knowledge distillation techniques involving GPT-4 and ChatGPT, this dataset offers a cost-effective means of constructing NSFW content detectors. The process entails collecting real-life human-machine interaction data and breaking it down into single utterances and single-turn dialogues, with the chatbot delivering the final utterance. ChatGPT is employed to annotate unlabeled data, serving as a training set. Rationale validation and test sets are constructed using ChatGPT and GPT-4 as annotators, with a self-criticism strategy for resolving discrepancies in labeling. A BERT model is fine-tun
    
[^107]: RoDia: 一份用于罗马尼亚方言识别的新数据集

    RoDia: A New Dataset for Romanian Dialect Identification from Speech. (arXiv:2309.03378v1 [cs.CL])

    [http://arxiv.org/abs/2309.03378](http://arxiv.org/abs/2309.03378)

    RoDia是第一个用于罗马尼亚方言识别的语音数据集，包含来自五个不同地区的2小时手动标注数据，并提供了一组竞争模型作为未来研究的基准。

    

    方言识别是语音处理和语言技术中关键的任务，可以增强诸如语音识别、说话人验证等各种应用。尽管大多数研究都集中在广为使用的语言的方言识别上，但对于罗马尼亚这种资源有限的低资源语言的方言识别却没有得到足够的关注。为了填补这一研究空白，我们引入了RoDia，这是第一个用于罗马尼亚方言识别的语音数据集。RoDia数据集包含了来自罗马尼亚五个不同地区的各种语音样本，涵盖了城市和农村环境，总共有2小时的手动标注语音数据。除了我们的数据集之外，我们还介绍了一组可作为未来研究基准的竞争模型。最高得分的模型的宏F1分数为59.83%，微F1分数为62.08%，说明该任务具有挑战性。因此，我们认为RoDia是一个有价值的资源。

    Dialect identification is a critical task in speech processing and language technology, enhancing various applications such as speech recognition, speaker verification, and many others. While most research studies have been dedicated to dialect identification in widely spoken languages, limited attention has been given to dialect identification in low-resource languages, such as Romanian. To address this research gap, we introduce RoDia, the first dataset for Romanian dialect identification from speech. The RoDia dataset includes a varied compilation of speech samples from five distinct regions of Romania, covering both urban and rural environments, totaling 2 hours of manually annotated speech data. Along with our dataset, we introduce a set of competitive models to be used as baselines for future research. The top scoring model achieves a macro F1 score of 59.83% and a micro F1 score of 62.08%, indicating that the task is challenging. We thus believe that RoDia is a valuable resource
    
[^108]: 利用列表上下文信息的粗到细神经检索器对段落进行重新排序

    Reranking Passages with Coarse-to-Fine Neural Retriever using List-Context Information. (arXiv:2308.12022v1 [cs.CL])

    [http://arxiv.org/abs/2308.12022](http://arxiv.org/abs/2308.12022)

    本文提出了一种利用列表上下文信息的粗到细神经检索器来重新排序段落。该方法通过将其他候选句子的列表上下文信息纳入段落表示中，增强了段落表示。而且，该方法将列表上下文建模过程分为两个子过程，从而解决了段落注意机制的内存限制问题，允许高效编码大量候选答案的上下文信息。

    

    段落重新排序是许多应用程序中的关键任务，特别是在处理大规模文档时。传统的神经架构在为问题检索最佳段落方面存在限制，因为它们通常将问题与每个段落分开匹配，很少考虑其他段落中的上下文信息，而这些信息可以提供比较和参考信息。本文提出了一种列表上下文注意机制，通过将来自其他候选句子的列表上下文信息纳入段落表示中来增强段落表示。所提出的粗到细（C2F）神经检索器通过将列表上下文建模过程分为两个子过程来解决段落注意机制的内存限制问题，从而允许对大量候选答案的上下文信息进行高效编码。这种方法可以广泛用于一次性编码任意数量的候选答案的上下文信息。

    Passage reranking is a crucial task in many applications, particularly when dealing with large-scale documents. Traditional neural architectures are limited in retrieving the best passage for a question because they usually match the question to each passage separately, seldom considering contextual information in other passages that can provide comparison and reference information. This paper presents a list-context attention mechanism to augment the passage representation by incorporating the list-context information from other candidates. The proposed coarse-to-fine (C2F) neural retriever addresses the out-of-memory limitation of the passage attention mechanism by dividing the list-context modeling process into two sub-processes, allowing for efficient encoding of context information from a large number of candidate answers. This method can be generally used to encode context information from any number of candidate answers in one pass. Different from most multi-stage information re
    
[^109]: 元认知提示改善大型语言模型的理解能力

    Metacognitive Prompting Improves Understanding in Large Language Models. (arXiv:2308.05342v1 [cs.CL])

    [http://arxiv.org/abs/2308.05342](http://arxiv.org/abs/2308.05342)

    元认知提示 (MP) 是一种改进大型语言模型 (LLMs) 理解能力的策略。实验结果表明，使用MP的PaLM在各种自然语言理解任务中接近于GPT-4的性能水平。

    

    在大型语言模型 (LLMs) 中，通过有效的提示设计，任务特定性能一直在不断提高。尽管最近关于提示的研究增强了LLMs的推理能力，但在进一步提高它们的理解能力方面仍存在差距。在本研究中，我们介绍了元认知提示 (MP)，这是一种受人类内省推理过程启发的策略。使用MP，LLMs经历一系列有结构、自我意识的评估，利用其丰富的内在知识和新的见解。我们的实验涉及五个常见的LLMs：Llama2、Vicuna、PaLM、GPT-3.5和GPT-4，它们都涵盖了来自GLUE和SuperGLUE基准测试的各种通用自然语言理解 (NLU) 任务。结果表明，虽然GPT-4在大多数任务中始终表现出色，但配备MP的PaLM接近其性能水平。此外，跨模型和数据集，MP始终优于现有的提示方法。

    In Large Language Models (LLMs), there have been consistent advancements in task-specific performance, largely influenced by effective prompt design. While recent research on prompting has enhanced the reasoning capabilities of LLMs, a gap remains in further improving their understanding abilities. In this study, we introduce metacognitive prompting (MP), a strategy inspired by human introspective reasoning processes. Using MP, LLMs undergo a systematic series of structured, self-aware evaluations, drawing on both their vast inherent knowledge and new insights. Our experiments involve five prevalent LLMs: Llama2, Vicuna, PaLM, GPT-3.5, and GPT-4, all of which span various general natural language understanding (NLU) tasks from the GLUE and SuperGLUE benchmarks. Results indicate that, although GPT-4 consistently excels in most tasks, PaLM, when equipped with MP, approaches its performance level. Furthermore, across models and datasets, MP consistently outperforms existing prompting meth
    
[^110]: 通过记忆增强的适配器实现可插拔的神经机器翻译模型

    Pluggable Neural Machine Translation Models via Memory-augmented Adapters. (arXiv:2307.06029v1 [cs.CL])

    [http://arxiv.org/abs/2307.06029](http://arxiv.org/abs/2307.06029)

    通过记忆增强的适配器，我们提出了一种可插拔的方法来控制神经机器翻译模型的生成行为。实验证明，我们的方法可以胜过几个代表性的可插拔基准模型。

    

    尽管神经机器翻译（NMT）模型在普通领域表现出色，但是控制其生成行为以满足不同用户需求仍然具有一定挑战性。鉴于每个用户需求都需要从头开始学习新模型的高昂训练成本和数据稀缺的挑战，我们提出了一种记忆增强适配器，以可插拔的方式引导预训练的NMT模型。具体而言，我们基于用户提供的文本样本构建了一个多粒度记忆，并提出了一种新的适配器架构来结合模型表示和检索结果。同时，我们提出了一种使用记忆丢弃的训练策略，以减少NMT模型和记忆之间的虚假依赖关系。我们在风格和领域特定实验中验证了我们的方法，结果表明，我们的方法可以胜过几个代表性的可插拔基准模型。

    Although neural machine translation (NMT) models perform well in the general domain, it remains rather challenging to control their generation behavior to satisfy the requirement of different users. Given the expensive training cost and the data scarcity challenge of learning a new model from scratch for each user requirement, we propose a memory-augmented adapter to steer pretrained NMT models in a pluggable manner. Specifically, we construct a multi-granular memory based on the user-provided text samples and propose a new adapter architecture to combine the model representations and the retrieved results. We also propose a training strategy using memory dropout to reduce spurious dependencies between the NMT model and the memory. We validate our approach on both style- and domain-specific experiments and the results indicate that our method can outperform several representative pluggable baselines.
    
[^111]: 用于端到端功能性言语处理任务的Gamma音图表示：语音识别、说话人识别和可理解性评估

    Gammatonegram Representation for End-to-End Dysarthric Speech Processing Tasks: Speech Recognition, Speaker Identification, and Intelligibility Assessment. (arXiv:2307.03296v1 [eess.AS])

    [http://arxiv.org/abs/2307.03296](http://arxiv.org/abs/2307.03296)

    该研究提出了一种使用Gamma音图表示语音的方法，通过卷积神经网络实现了语音识别、说话人识别和可理解性评估的功能。

    

    发音障碍是一种影响人类言语系统并降低个人发音质量和可理解性的残疾。由于这种影响，常规的言语处理系统无法在受损的言语上正常工作。这种残疾通常与身体残疾相关。因此，设计一个能够通过接收语音命令在智能家居中执行一些任务的系统，将是一个重要的成就。在这项工作中，我们引入了Gamma音图作为一种有效的方法来表示具有区分性细节的音频文件，该方法用作卷积神经网络的输入。换句话说，我们将每个语音文件转换成图像，并提出了图像识别系统来对不同场景下的语音进行分类。所提出的卷积神经网络基于预训练的Alexnet的迁移学习方法。在这项研究中，评估了所提出系统在语音识别、说话人识别和可理解性评估方面的效率。

    Dysarthria is a disability that causes a disturbance in the human speech system and reduces the quality and intelligibility of a person's speech. Because of this effect, the normal speech processing systems can not work properly on impaired speech. This disability is usually associated with physical disabilities. Therefore, designing a system that can perform some tasks by receiving voice commands in the smart home can be a significant achievement. In this work, we introduce gammatonegram as an effective method to represent audio files with discriminative details, which is used as input for the convolutional neural network. On the other word, we convert each speech file into an image and propose image recognition system to classify speech in different scenarios. Proposed CNN is based on the transfer learning method on the pre-trained Alexnet. In this research, the efficiency of the proposed system for speech recognition, speaker identification, and intelligibility assessment is evaluat
    
[^112]: ChatGPT4PCG比赛：科学鸟角色级生成

    ChatGPT4PCG Competition: Character-like Level Generation for Science Birds. (arXiv:2303.15662v1 [cs.AI])

    [http://arxiv.org/abs/2303.15662](http://arxiv.org/abs/2303.15662)

    本论文介绍了举办在2023 IEEE游戏会议上的第一届ChatGPT4PCG比赛，目标是让ChatGPT生成具有高稳定性和类似角色的特质来生成具有科学鸟角色级水平的关卡。

    

    本文介绍了2023年IEEE游戏会议上的第一届ChatGPT4PCG比赛。本次比赛的目标是让参赛者通过创造性和提示工程技能，为ChatGPT创建有效的提示，使其能够具有高稳定性和类似角色的特质来生成具有科学鸟角色级水平的关卡。为了降低参赛门槛，我们将任务限制在生成大写英文字母。参赛作品的质量由其稳定性和与给定字符的相似性决定。给参赛者提供了一个样例提示供参考。

    This paper presents the first ChatGPT4PCG Competition at the 2023 IEEE Conference on Games. The objective of this competition is for participants to create effective prompts for ChatGPT--enabling it to generate Science Birds levels with high stability and character-like qualities--fully using their creativity as well as prompt engineering skills. ChatGPT is a conversational agent developed by OpenAI. Science Birds is selected as the competition platform because designing an Angry Birds-like level is not a trivial task due to the in-game gravity; the playability of the levels is determined by their stability. To lower the entry barrier to the competition, we limit the task to the generation of capitalized English alphabetical characters. Here, the quality of the generated levels is determined by their stability and similarity to the given characters. A sample prompt is provided to participants for their reference. An experiment is conducted to determine the effectiveness of its modified
    
[^113]: ComCLIP: 无需训练的组合图像与文本匹配

    ComCLIP: Training-Free Compositional Image and Text Matching. (arXiv:2211.13854v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.13854](http://arxiv.org/abs/2211.13854)

    本文提出了一个无需训练的组合图像与文本匹配模型 ComCLIP，通过将输入图像分解为主体、对象和动作子图像，并结合视觉编码器和文本编码器进行逐步匹配，以解决组合图像与文本匹配中的伪匹配问题。

    

    对比语言-图像预训练（CLIP）已经展示了在图像与文本匹配方面的很好的零样本性能。然而，将 CLIP 这样的视觉-语言预训练模型适应于更具挑战性的组合图像与文本匹配仍然具有挑战性，这需要模型理解组合词概念和视觉组件。为了实现更好的零样本图像与文本匹配中的组合泛化能力，本文从因果关系的角度研究了该问题：单个实体的错误语义本质上是导致匹配失败的混淆因素。因此，我们提出了一种新颖的“无需训练”的组合 CLIP 模型（ComCLIP）。ComCLIP将输入图像分解为主体、对象和动作子图像，并组合 CLIP 的视觉编码器和文本编码器，以在组合文本嵌入和子图像嵌入之上进行逐步匹配。通过这种方式，ComCLIP 可以减轻伪匹配问题。

    Contrastive Language-Image Pretraining (CLIP) has demonstrated great zero-shot performance for matching images and text. However, it is still challenging to adapt vision-lanaguage pretrained models like CLIP to compositional image and text matching -- a more challenging image and text matching task requiring the model understanding of compositional word concepts and visual components. Towards better compositional generalization in zero-shot image and text matching, in this paper, we study the problem from a causal perspective: the erroneous semantics of individual entities are essentially confounders that cause the matching failure. Therefore, we propose a novel \textbf{\textit{training-free}} compositional CLIP model (ComCLIP). ComCLIP disentangles input images into subjects, objects, and action sub-images and composes CLIP's vision encoder and text encoder to perform evolving matching over compositional text embedding and sub-image embeddings. In this way, ComCLIP can mitigate spurio
    

