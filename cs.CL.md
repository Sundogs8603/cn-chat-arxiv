# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming Ability in Multi-Agent Environments](https://arxiv.org/abs/2403.11807) | 通过博弈论视角评估LLMs的决策能力，结果表明GPT-3.5在稳健性方面表现良好，但泛化能力有限，而GPT-4则优于其他模型。 |
| [^2] | [ChartThinker: A Contextual Chain-of-Thought Approach to Optimized Chart Summarization](https://arxiv.org/abs/2403.11236) | 该研究提出了一种名为ChartThinker的创新图表摘要方法，利用上下文思维和策略性的上下文检索实现深度分析，旨在提高生成摘要的逻辑连贯性和准确性。 |
| [^3] | [Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context](https://arxiv.org/abs/2403.05530) | Gemini 1.5 Pro是一种高效计算的多模态混合模型，能在数百万标记的上下文中回忆和推理信息，达到近乎完美的长上下文检索任务召回率，改进了长文档问答、长视频问答和长上下文ASR的最新技术水平。 |
| [^4] | [The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning](https://arxiv.org/abs/2403.03218) | WMDP基准是一个公开发布的数据集，包含4157个多项选择问题，用作生物安全、网络安全和化学安全危险知识的代理测量。 |
| [^5] | [RulePrompt: Weakly Supervised Text Classification with Prompting PLMs and Self-Iterative Logical Rules](https://arxiv.org/abs/2403.02932) | 提出了使用逻辑表达来表征类别含义的规则Prompt方法，结合PLMs和自迭代逻辑规则实现弱监督文本分类 |
| [^6] | [Prescribing Large Language Models for Perioperative Care: What's The Right Dose for Pre-trained Models?](https://arxiv.org/abs/2402.17493) | 通过评估临床大型语言模型在术后风险预测中的应用，研究探讨了使用不同训练策略的模型在围手术期护理中的潜在效果。 |
| [^7] | [DEEM: Dynamic Experienced Expert Modeling for Stance Detection](https://arxiv.org/abs/2402.15264) | 本文提出了一种Dynamic Experienced Expert Modeling（DEEM）方法，利用生成的经验专家使LLMs能够以半参数化方式进行推理，提高了在立场检测任务中的性能。 |
| [^8] | [Scaling the Authoring of AutoTutors with Large Language Models](https://arxiv.org/abs/2402.09216) | 本文研究使用大型语言模型（LLMs）来撰写智能辅导系统的潜力，提出了保留传统辅导系统结构和教学法的方法。 |
| [^9] | [ChemLLM: A Chemical Large Language Model](https://arxiv.org/abs/2402.06852) | ChemLLM是第一个专门用于化学领域的大型语言模型，利用新颖的指令构建方法将结构化知识转化为对话形式，具有平滑对话交互的能力，并在化学的三个主要任务中击败了GPT-3.5。 |
| [^10] | [VerAs: Verify then Assess STEM Lab Reports](https://arxiv.org/abs/2402.05224) | VerAs是一个端到端的神经架构，用于验证和评估STEM实验报告。它通过利用多个维度的分析评估标准，以及针对学生提供详细反馈，帮助他们提高科学写作技巧。 |
| [^11] | [Benchmarking LLMs via Uncertainty Quantification.](http://arxiv.org/abs/2401.12794) | 这项研究提出了一种通过不确定性量化来对LLMs进行基准测试的方法，并引入了一种不确定性感知评估指标UAcc。研究结果显示，高准确度的LLMs可能具有较低的确定性，而大规模LLMs可能比较小规模LLMs更不确定。指令微调倾向于增加LLMs的不确定性。 |
| [^12] | [Large Language Models can Learn Rules.](http://arxiv.org/abs/2310.07064) | 大型语言模型(LLMs)在各种推理任务中展示了令人印象深刻的性能。为了提高提示方法的准确性和一致性，我们提出了Hypotheses-to-Theories (HtT)框架，用于学习LLMs推理的规则库，从而改进了现有的提示方法。 |
| [^13] | [SpeechAlign: a Framework for Speech Translation Alignment Evaluation.](http://arxiv.org/abs/2309.11585) | SpeechAlign是一个用于评估语音模型中源目标对齐的框架，通过引入新的数据集和指标，为模型评估提供了一个可访问的评估框架，并且用于基准测试开源的语音翻译模型。 |
| [^14] | [ControlRetriever: Harnessing the Power of Instructions for Controllable Retrieval.](http://arxiv.org/abs/2308.10025) | ControlRetriever是一种有参数隔离架构的通用且高效的方法，借助于任务特定的指令，能够控制密集检索模型直接执行各种检索任务，提高检索效果。 |
| [^15] | [DoDo Learning: DOmain-DemOgraphic Transfer in Language Models for Detecting Abuse Targeted at Public Figures.](http://arxiv.org/abs/2307.16811) | 该研究旨在通过探索跨领域和跨人口的文本分类动态，构建更通用的滥用分类器。研究发现，少量多样的数据对于模型的通用化和适应非常有益。 |
| [^16] | [Brainformers: Trading Simplicity for Efficiency.](http://arxiv.org/abs/2306.00008) | Brainformers 是一个新的深度神经网络模型，它通过使用多样层级的结构完善了 Transformer 的设计缺陷，具有更高效的训练收敛和更快的步骤时间，表现出更优秀的性能。 |
| [^17] | [Retrieving Texts based on Abstract Descriptions.](http://arxiv.org/abs/2305.12517) | 本研究针对语义检索问题，提出了一种基于摘要描述的文本检索模型，通过改进当前的文本嵌入方法，在标准最近邻搜索中取得了显著性能提升。 |

# 详细

[^1]: LLM的决策水平在多智能体环境中的评估究竟如何？

    How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming Ability in Multi-Agent Environments

    [https://arxiv.org/abs/2403.11807](https://arxiv.org/abs/2403.11807)

    通过博弈论视角评估LLMs的决策能力，结果表明GPT-3.5在稳健性方面表现良好，但泛化能力有限，而GPT-4则优于其他模型。

    

    决策是一个复杂的任务，需要各种能力，为评估大型语言模型（LLMs）提供了一个极好的框架。我们的研究通过博弈论的视角探究LLMs的决策能力。我们专注于支持多个智能体同时参与的游戏，引入了我们的框架GAMA-Bench，包括八个经典的多智能体游戏。我们设计了一个评分方案，定量评估模型在这些游戏中的表现。通过GAMA-Bench，我们研究了LLMs的稳健性、泛化能力和增强策略。结果显示，虽然GPT-3.5表现出令人满意的稳健性，但其泛化能力相对有限。然而，通过一些方法如“思维链”，其性能可以得到提高。此外，我们对各种LLMs进行评估，发现GPT-4胜过其他模型。

    arXiv:2403.11807v1 Announce Type: new  Abstract: Decision-making, a complicated task requiring various types of abilities, presents an excellent framework for assessing Large Language Models (LLMs). Our research investigates LLMs' decision-making capabilities through the lens of a well-established field, Game Theory. We focus specifically on games that support the participation of more than two agents simultaneously. Subsequently, we introduce our framework, GAMA-Bench, including eight classical multi-agent games. We design a scoring scheme to assess a model's performance in these games quantitatively. Through GAMA-Bench, we investigate LLMs' robustness, generalizability, and enhancement strategies. Results reveal that while GPT-3.5 shows satisfying robustness, its generalizability is relatively limited. However, its performance can be improved through approaches such as Chain-of-Thought. Additionally, we conduct evaluations across various LLMs and find that GPT-4 outperforms other mod
    
[^2]: ChartThinker：一种优化图表摘要的上下文思维方法

    ChartThinker: A Contextual Chain-of-Thought Approach to Optimized Chart Summarization

    [https://arxiv.org/abs/2403.11236](https://arxiv.org/abs/2403.11236)

    该研究提出了一种名为ChartThinker的创新图表摘要方法，利用上下文思维和策略性的上下文检索实现深度分析，旨在提高生成摘要的逻辑连贯性和准确性。

    

    arXiv：2403.11236v1 公告类型：新型 摘要：数据可视化是呈现数据和挖掘其宝贵见解的重要手段。通过自然语言处理技术进行图表摘要的任务有助于深入分析图表数据。然而，现有方法在视觉-语言匹配和推理能力方面仍然存在明显不足。为解决这些局限性，本研究构建了一个大规模数据集，其中包含全面的图表标题配对和每个图表的微调说明。由于该数据集涵盖了各种主题和视觉风格，可以从训练数据的角度获得更好的匹配度。此外，我们提出了一种创新的图表摘要方法ChartThinker，它基于思维链和上下文检索策略综合深度分析，旨在提高生成摘要的逻辑连贯性和准确性。建立在精心策划Data

    arXiv:2403.11236v1 Announce Type: new  Abstract: Data visualization serves as a critical means for presenting data and mining its valuable insights. The task of chart summarization, through natural language processing techniques, facilitates in-depth data analysis of charts. However, there still are notable deficiencies in terms of visual-language matching and reasoning ability for existing approaches. To address these limitations, this study constructs a large-scale dataset of comprehensive chart-caption pairs and fine-tuning instructions on each chart. Thanks to the broad coverage of various topics and visual styles within this dataset, better matching degree can be achieved from the view of training data. Moreover, we propose an innovative chart summarization method, ChartThinker, which synthesizes deep analysis based on chains of thought and strategies of context retrieval, aiming to improve the logical coherence and accuracy of the generated summaries. Built upon the curated datas
    
[^3]: Gemini 1.5：解锁跨数百万标记上下文的多模态理解

    Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context

    [https://arxiv.org/abs/2403.05530](https://arxiv.org/abs/2403.05530)

    Gemini 1.5 Pro是一种高效计算的多模态混合模型，能在数百万标记的上下文中回忆和推理信息，达到近乎完美的长上下文检索任务召回率，改进了长文档问答、长视频问答和长上下文ASR的最新技术水平。

    

    在这份报告中，我们介绍了Gemini家族的最新模型Gemini 1.5 Pro，这是一个高效计算的多模态专家混合模型，能够回忆和推理数百万标记上下文中的细粒度信息，包括多个长文档和几小时的视频和音频。Gemini 1.5 Pro在各种形式的长上下文检索任务中实现了近乎完美的召回率，改进了长文档问答、长视频问答和长上下文ASR的最新技术水平，并在广泛一系列基准测试中与Gemini 1.0 Ultra的最新技术水平相匹敌甚至超过。在研究Gemini 1.5 Pro长上下文能力的极限时，我们发现在至少10M标记的范围内继续改进下一个标记的预测，并且几乎完美地达到了超过99%的检索率，这是对现有模型如Claude 2.1（200k）和GPT-4 Turbo（128k）的世代性飞跃。最后，我们突出了大型语言模型在新领域的令人惊讶的新能力。

    arXiv:2403.05530v1 Announce Type: cross  Abstract: In this report, we present the latest model of the Gemini family, Gemini 1.5 Pro, a highly compute-efficient multimodal mixture-of-experts model capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio. Gemini 1.5 Pro achieves near-perfect recall on long-context retrieval tasks across modalities, improves the state-of-the-art in long-document QA, long-video QA and long-context ASR, and matches or surpasses Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Studying the limits of Gemini 1.5 Pro's long-context ability, we find continued improvement in next-token prediction and near-perfect retrieval (>99%) up to at least 10M tokens, a generational leap over existing models such as Claude 2.1 (200k) and GPT-4 Turbo (128k). Finally, we highlight surprising new capabilities of large language models at the
    
[^4]: WMDP基准：通过遗忘测量和减少恶意使用

    The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning

    [https://arxiv.org/abs/2403.03218](https://arxiv.org/abs/2403.03218)

    WMDP基准是一个公开发布的数据集，包含4157个多项选择问题，用作生物安全、网络安全和化学安全危险知识的代理测量。

    

    arXiv:2403.03218v1 公告类型：交叉领域 摘要：白宫关于人工智能的行政命令强调了大型语言模型(LLMs)赋予恶意行为者开发生物、网络和化学武器的风险。为了衡量这些恶意使用的风险，政府机构和主要人工智能实验室正在开发LLMs的危险能力评估。然而，当前的评估是私人的，阻碍了进一步研究如何减少风险。此外，它们仅专注于几条高度特定的恶意使用途径。为了填补这些空白，我们公开发布了大规模杀伤性武器代理（WMDP）基准，这是一个包含4157个多项选择问题的数据集，作为生物安全、网络安全和化学安全危险知识的代理测量。WMDP由一组学术界和技术顾问联合开发，并在公开发布前严格过滤以消除敏感信息。WMDP有两个服务

    arXiv:2403.03218v1 Announce Type: cross  Abstract: The White House Executive Order on Artificial Intelligence highlights the risks of large language models (LLMs) empowering malicious actors in developing biological, cyber, and chemical weapons. To measure these risks of malicious use, government institutions and major AI labs are developing evaluations for hazardous capabilities in LLMs. However, current evaluations are private, preventing further research into mitigating risk. Furthermore, they focus on only a few, highly specific pathways for malicious use. To fill these gaps, we publicly release the Weapons of Mass Destruction Proxy (WMDP) benchmark, a dataset of 4,157 multiple-choice questions that serve as a proxy measurement of hazardous knowledge in biosecurity, cybersecurity, and chemical security. WMDP was developed by a consortium of academics and technical consultants, and was stringently filtered to eliminate sensitive information prior to public release. WMDP serves two r
    
[^5]: RulePrompt: 弱监督文本分类与提示PLMs和自迭代逻辑规则

    RulePrompt: Weakly Supervised Text Classification with Prompting PLMs and Self-Iterative Logical Rules

    [https://arxiv.org/abs/2403.02932](https://arxiv.org/abs/2403.02932)

    提出了使用逻辑表达来表征类别含义的规则Prompt方法，结合PLMs和自迭代逻辑规则实现弱监督文本分类

    

    弱监督文本分类（WSTC），又称零样本或无数据文本分类，在动态和开放的Web环境中吸引了越来越多的关注，因为它仅需要每个类别的有限种子词（标签名称）而不需要标记数据就能对大量文本进行分类。本文首先提出了一种新型的基于规则的知识形式，使用逻辑表达来表征类别的含义。然后，我们借助PLMs和自迭代逻辑规则来实现弱监督文本分类。

    arXiv:2403.02932v1 Announce Type: new  Abstract: Weakly supervised text classification (WSTC), also called zero-shot or dataless text classification, has attracted increasing attention due to its applicability in classifying a mass of texts within the dynamic and open Web environment, since it requires only a limited set of seed words (label names) for each category instead of labeled data. With the help of recently popular prompting Pre-trained Language Models (PLMs), many studies leveraged manually crafted and/or automatically identified verbalizers to estimate the likelihood of categories, but they failed to differentiate the effects of these category-indicative words, let alone capture their correlations and realize adaptive adjustments according to the unlabeled corpus. In this paper, in order to let the PLM effectively understand each category, we at first propose a novel form of rule-based knowledge using logical expressions to characterize the meanings of categories. Then, we d
    
[^6]: 为围手术期护理开具大型语言模型：预训练模型的正确剂量是多少？

    Prescribing Large Language Models for Perioperative Care: What's The Right Dose for Pre-trained Models?

    [https://arxiv.org/abs/2402.17493](https://arxiv.org/abs/2402.17493)

    通过评估临床大型语言模型在术后风险预测中的应用，研究探讨了使用不同训练策略的模型在围手术期护理中的潜在效果。

    

    术后风险预测可以指导有效的围手术期护理管理和规划。我们旨在评估临床大型语言模型(LLMs)是否可以使用不同的训练策略预测术后风险。研究主要涉及2018年至2021年间来自Barnes Jewish医院系统的84,875份记录。方法在Beth Israel Deaconess的MIMIC数据集上进行了复制。两项研究的平均随访时间基于术后ICU住院时间小于7天。对于BJH数据集，结果包括30天死亡率、肺栓塞（PE）和肺炎。对BioGPT、ClinicalBERT和BioClinicalBERT实施了三种域自适应和微调策略：自监督目标；结合半监督微调的标签；以及通过多任务学习进行基础建模。模型性能使用接收器操作特征下的面积进行了比较。

    arXiv:2402.17493v1 Announce Type: new  Abstract: Postoperative risk predictions can inform effective perioperative care management and planning. We aimed to assess whether clinical large language models (LLMs) can predict postoperative risks using clinical texts with various training strategies. The main cohort involved 84,875 records from Barnes Jewish Hospital (BJH) system between 2018 and 2021. Methods were replicated on Beth Israel Deaconess's MIMIC dataset. Both studies had mean duration of follow-up based on the length of postoperative ICU stay less than 7 days. For the BJH dataset, outcomes included 30-day mortality, pulmonary embolism (PE) and pneumonia. Three domain adaptation and finetuning strategies were implemented for BioGPT, ClinicalBERT and BioClinicalBERT: self-supervised objectives; incorporating labels with semi-supervised fine-tuning; and foundational modelling through multi-task learning. Model performance was compared using the area under the receiver operating ch
    
[^7]: DEEM：面向立场检测的动态体验专家建模

    DEEM: Dynamic Experienced Expert Modeling for Stance Detection

    [https://arxiv.org/abs/2402.15264](https://arxiv.org/abs/2402.15264)

    本文提出了一种Dynamic Experienced Expert Modeling（DEEM）方法，利用生成的经验专家使LLMs能够以半参数化方式进行推理，提高了在立场检测任务中的性能。

    

    最近的研究初步尝试使用大型语言模型（LLMs）来解决立场检测任务，展现了有希望的结果。然而，考虑到立场检测通常需要详细的背景知识，传统的推理方法可能会忽视领域知识，以进行专业和准确的分析。因此，LLMs的推理仍有改进空间，尤其在利用LLMs的生成能力模拟特定专家（即多智能体）来检测立场方面。与现有需要详细描述并使用固定专家的多智能体作品不同，本文提出了一种Dynamic Experienced Expert Modeling（DEEM）方法，可以利用生成的经验专家，并让LLMs以半参数化方式进行推理，使专家更具普适性和可靠性。实验结果表明，DEEM在三个场景上一直达到最佳结果。

    arXiv:2402.15264v1 Announce Type: new  Abstract: Recent work has made a preliminary attempt to use large language models (LLMs) to solve the stance detection task, showing promising results. However, considering that stance detection usually requires detailed background knowledge, the vanilla reasoning method may neglect the domain knowledge to make a professional and accurate analysis. Thus, there is still room for improvement of LLMs reasoning, especially in leveraging the generation capability of LLMs to simulate specific experts (i.e., multi-agents) to detect the stance. In this paper, different from existing multi-agent works that require detailed descriptions and use fixed experts, we propose a Dynamic Experienced Expert Modeling (DEEM) method which can leverage the generated experienced experts and let LLMs reason in a semi-parametric way, making the experts more generalizable and reliable. Experimental results demonstrate that DEEM consistently achieves the best results on thre
    
[^8]: 使用大型语言模型扩展AutoTutor的创作

    Scaling the Authoring of AutoTutors with Large Language Models

    [https://arxiv.org/abs/2402.09216](https://arxiv.org/abs/2402.09216)

    本文研究使用大型语言模型（LLMs）来撰写智能辅导系统的潜力，提出了保留传统辅导系统结构和教学法的方法。

    

    大型语言模型（LLMs）在教育领域有多种用途，从自动题目生成到作文评估。本文探讨了使用大型语言模型（LLMs）来撰写智能辅导系统的潜力。LLMs的一个常见问题是它们容易偏离所期望的教学策略，例如泄露答案给学生，总体上提供的保证很少。我们认为，虽然带有某些限制的LLMs可以取代学科专家的位置，但整体的教学设计仍需手工制作以取得最佳学习效果。基于这一原则，我们创建了一个示例的端到端辅导系统，命名为MWPTutor，它使用LLMs填充预定义有限状态转换器的状态空间。这种方法保留了多年来由学习科学家开发的传统辅导系统的结构和教学法，同时引入了额外的灵活性。

    arXiv:2402.09216v1 Announce Type: new Abstract: Large Language Models (LLMs) have found several use cases in education, ranging from automatic question generation to essay evaluation. In this paper, we explore the potential of using Large Language Models (LLMs) to author Intelligent Tutoring Systems. A common pitfall of LLMs is their straying from desired pedagogical strategies such as leaking the answer to the student, and in general, providing no guarantees. We posit that while LLMs with certain guardrails can take the place of subject experts, the overall pedagogical design still needs to be handcrafted for the best learning results. Based on this principle, we create a sample end-to-end tutoring system named MWPTutor, which uses LLMs to fill in the state space of a pre-defined finite state transducer. This approach retains the structure and the pedagogy of traditional tutoring systems that has been developed over the years by learning scientists but brings in additional flexibility
    
[^9]: ChemLLM: 一个化学大型语言模型

    ChemLLM: A Chemical Large Language Model

    [https://arxiv.org/abs/2402.06852](https://arxiv.org/abs/2402.06852)

    ChemLLM是第一个专门用于化学领域的大型语言模型，利用新颖的指令构建方法将结构化知识转化为对话形式，具有平滑对话交互的能力，并在化学的三个主要任务中击败了GPT-3.5。

    

    大型语言模型（LLM）在化学应用中取得了令人瞩目的进展，包括分子属性预测、分子生成、实验协议设计等。然而，该领域缺乏一个专门针对化学领域设计的基于对话的模型。这个挑战来自于事实，大多数化学数据和科学知识主要存储在结构化数据库中，直接使用这些结构化数据会影响模型维持连贯对话的能力。为了解决这个问题，我们开发了一种新颖的基于模板的指令构建方法，将结构化知识转化为简洁对话形式，适合于语言模型的训练。通过利用这种方法，我们开发了ChemLLM，第一个专门用于化学的大型语言模型，能够在化学领域的各种任务中进行平滑对话交互。ChemLLM在化学的三个主要任务，即名称转换、分子生成和实验协议设计方面，击败了GPT-3.5。

    Large language models (LLMs) have made impressive progress in chemistry applications, including molecular property prediction, molecular generation, experimental protocol design, etc. However, the community lacks a dialogue-based model specifically designed for chemistry. The challenge arises from the fact that most chemical data and scientific knowledge are primarily stored in structured databases, and the direct use of these structured data compromises the model's ability to maintain coherent dialogue. To tackle this issue, we develop a novel template-based instruction construction method that transforms structured knowledge into plain dialogue, making it suitable for language model training. By leveraging this approach, we develop ChemLLM, the first large language model dedicated to chemistry, capable of performing various tasks across chemical disciplines with smooth dialogue interaction. ChemLLM beats GPT-3.5 on all three principal tasks in chemistry, i.e., name conversion, molecu
    
[^10]: VerAs: 验证然后评估STEM实验报告

    VerAs: Verify then Assess STEM Lab Reports

    [https://arxiv.org/abs/2402.05224](https://arxiv.org/abs/2402.05224)

    VerAs是一个端到端的神经架构，用于验证和评估STEM实验报告。它通过利用多个维度的分析评估标准，以及针对学生提供详细反馈，帮助他们提高科学写作技巧。

    

    随着STEM教育对批判性思维能力的日益关注，科学写作在注重探究技能的课程中发挥着越来越重要的作用。最近发布的一份数据集是基于一套探究型物理课程的两组大学水平的实验报告，依赖于利用多个维度的分析评估标准，指定学科知识和优秀解释的一般组成部分。每个分析维度都以6分制进行评估，以提供详细反馈，帮助学生提高科学写作技巧。手动评估可能较慢，并且在大班中对所有学生进行一致性校准可能很困难。尽管在STEM学科的开放性问题的自动评估上已经有很多工作，但在实验报告等长篇写作中的工作要少得多。我们提出了一个端到端的神经架构，其中包括独立的验证器和评估模块，灵感来源于开放领域问题回答的方法。

    With an increasing focus in STEM education on critical thinking skills, science writing plays an ever more important role in curricula that stress inquiry skills. A recently published dataset of two sets of college level lab reports from an inquiry-based physics curriculum relies on analytic assessment rubrics that utilize multiple dimensions, specifying subject matter knowledge and general components of good explanations. Each analytic dimension is assessed on a 6-point scale, to provide detailed feedback to students that can help them improve their science writing skills. Manual assessment can be slow, and difficult to calibrate for consistency across all students in large classes. While much work exists on automated assessment of open-ended questions in STEM subjects, there has been far less work on long-form writing such as lab reports. We present an end-to-end neural architecture that has separate verifier and assessment modules, inspired by approaches to Open Domain Question Answ
    
[^11]: 通过不确定性量化对LLMs进行基准测试

    Benchmarking LLMs via Uncertainty Quantification. (arXiv:2401.12794v1 [cs.CL])

    [http://arxiv.org/abs/2401.12794](http://arxiv.org/abs/2401.12794)

    这项研究提出了一种通过不确定性量化来对LLMs进行基准测试的方法，并引入了一种不确定性感知评估指标UAcc。研究结果显示，高准确度的LLMs可能具有较低的确定性，而大规模LLMs可能比较小规模LLMs更不确定。指令微调倾向于增加LLMs的不确定性。

    

    随着各个机构开源大型语言模型（LLMs）的增多，彰显了对综合评估方法的迫切需求。然而，当前的评估平台，如广为人知的HuggingFace开放的LLM排行榜，忽视了一个关键方面--不确定性，而不确定性对于全面评估LLMs至关重要。为了弥补这一差距，我们引入了一种新的LLMs基准测试方法，将不确定性量化集成进去。我们的研究涵盖了五个典型的自然语言处理任务中的八个LLMs（LLM系列）。此外，我们引入了一种考虑了预测准确性和预测不确定性的不确定性感知评估指标UAcc。我们的研究结果显示：I）准确度越高的LLMs可能会表现出较低的确定性；II）规模较大的LLMs可能与较小的LLMs相比显示出更大的不确定性；III）指令微调倾向于增加LLMs的不确定性。通过考虑不确定性，我们的方法可以更全面地评估LLMs的性能。

    The proliferation of open-source Large Language Models (LLMs) from various institutions has highlighted the urgent need for comprehensive evaluation methods. However, current evaluation platforms, such as the widely recognized HuggingFace open LLM leaderboard, neglect a crucial aspect -- uncertainty, which is vital for thoroughly assessing LLMs. To bridge this gap, we introduce a new benchmarking approach for LLMs that integrates uncertainty quantification. Our examination involves eight LLMs (LLM series) spanning five representative natural language processing tasks. Additionally, we introduce an uncertainty-aware evaluation metric, UAcc, which takes into account both prediction accuracy and prediction uncertainty. Our findings reveal that: I) LLMs with higher accuracy may exhibit lower certainty; II) Larger-scale LLMs may display greater uncertainty compared to their smaller counterparts; and III) Instruction-finetuning tends to increase the uncertainty of LLMs. By taking uncertainty
    
[^12]: 大型语言模型可以学习规则

    Large Language Models can Learn Rules. (arXiv:2310.07064v1 [cs.AI])

    [http://arxiv.org/abs/2310.07064](http://arxiv.org/abs/2310.07064)

    大型语言模型(LLMs)在各种推理任务中展示了令人印象深刻的性能。为了提高提示方法的准确性和一致性，我们提出了Hypotheses-to-Theories (HtT)框架，用于学习LLMs推理的规则库，从而改进了现有的提示方法。

    

    当给出一些示例和中间步骤时，大型语言模型(LLMs)在各种推理任务中展示了令人印象深刻的性能。然而，依赖LLM中的隐式知识的提示方法在隐式知识错误或与任务不一致时往往会产生错误的答案。为解决这个问题，我们提出了"假设到理论" (HtT) 框架，用于学习LLMs推理的规则库。HtT包括两个阶段，归纳阶段和演绎阶段。在归纳阶段，首先要求LLM根据一组训练示例生成和验证规则。出现并导致正确答案的规则将被收集形成一个规则库。在演绎阶段，然后要求LLM使用学习的规则库进行推理以回答测试问题。在数值推理和关系推理问题上的实验证明，HtT改进了现有的提示方法，使其性能提升。

    When prompted with a few examples and intermediate steps, large language models (LLMs) have demonstrated impressive performance in various reasoning tasks. However, prompting methods that rely on implicit knowledge in an LLM often hallucinate incorrect answers when the implicit knowledge is wrong or inconsistent with the task. To tackle this problem, we present Hypotheses-to-Theories (HtT), a framework that learns a rule library for reasoning with LLMs. HtT contains two stages, an induction stage and a deduction stage. In the induction stage, an LLM is first asked to generate and verify rules over a set of training examples. Rules that appear and lead to correct answers sufficiently often are collected to form a rule library. In the deduction stage, the LLM is then prompted to employ the learned rule library to perform reasoning to answer test questions. Experiments on both numerical reasoning and relational reasoning problems show that HtT improves existing prompting methods, with an 
    
[^13]: SpeechAlign:一种用于语音翻译对齐评估的框架

    SpeechAlign: a Framework for Speech Translation Alignment Evaluation. (arXiv:2309.11585v1 [cs.CL])

    [http://arxiv.org/abs/2309.11585](http://arxiv.org/abs/2309.11585)

    SpeechAlign是一个用于评估语音模型中源目标对齐的框架，通过引入新的数据集和指标，为模型评估提供了一个可访问的评估框架，并且用于基准测试开源的语音翻译模型。

    

    语音到语音和语音到文本翻译目前是研究的动态领域。为了对这些领域做出贡献，我们提出了SpeechAlign，一种评估语音模型中源目标对齐这一未被充分研究的领域的框架。我们的框架有两个核心组成部分。首先，为了解决缺乏合适的评估数据集的问题，我们介绍了Speech Gold Alignment数据集，该数据集是在英德文本翻译的黄金对齐数据集基础上构建的。其次，我们引入了两个新的指标，语音对齐错误率（SAER）和时间加权语音对齐错误率（TW-SAER），用于评估语音模型中的对齐质量。通过发布SpeechAlign，我们提供了一个可访问的评估框架用于模型评估，并且我们使用它来对开源的语音翻译模型进行基准测试。

    Speech-to-Speech and Speech-to-Text translation are currently dynamic areas of research. To contribute to these fields, we present SpeechAlign, a framework to evaluate the underexplored field of source-target alignment in speech models. Our framework has two core components. First, to tackle the absence of suitable evaluation datasets, we introduce the Speech Gold Alignment dataset, built upon a English-German text translation gold alignment dataset. Secondly, we introduce two novel metrics, Speech Alignment Error Rate (SAER) and Time-weighted Speech Alignment Error Rate (TW-SAER), to evaluate alignment quality in speech models. By publishing SpeechAlign we provide an accessible evaluation framework for model assessment, and we employ it to benchmark open-source Speech Translation models.
    
[^14]: ControlRetriever: 发挥指令的力量进行可控检索

    ControlRetriever: Harnessing the Power of Instructions for Controllable Retrieval. (arXiv:2308.10025v1 [cs.CL])

    [http://arxiv.org/abs/2308.10025](http://arxiv.org/abs/2308.10025)

    ControlRetriever是一种有参数隔离架构的通用且高效的方法，借助于任务特定的指令，能够控制密集检索模型直接执行各种检索任务，提高检索效果。

    

    最近的研究表明，缺乏专门的训练数据的密集检索模型在各种检索任务中往往难以表现出色，因为不同的检索任务通常涉及不同的搜索意图。为解决这一挑战，在本工作中，我们引入了ControlRetriever，一种通用且高效的方法，采用参数隔离的架构，能够控制密集检索模型直接执行各种检索任务，发挥自然语言中明确描述检索意图的指令的力量。借助已在文本到图像生成中证明强大的ControlNet的基础，ControlRetriever将不同的检索模型赋予了可控性检索的新能力，同时还受到任务特定指令的指导。此外，我们提出了一种新颖的基于LLM引导的指令合成和迭代训练策略，通过广泛生成的检索数据迭代调整ControlRetriever。

    Recent studies have shown that dense retrieval models, lacking dedicated training data, struggle to perform well across diverse retrieval tasks, as different retrieval tasks often entail distinct search intents. To address this challenge, in this work we introduce ControlRetriever, a generic and efficient approach with a parameter isolated architecture, capable of controlling dense retrieval models to directly perform varied retrieval tasks, harnessing the power of instructions that explicitly describe retrieval intents in natural language. Leveraging the foundation of ControlNet, which has proven powerful in text-to-image generation, ControlRetriever imbues different retrieval models with the new capacity of controllable retrieval, all while being guided by task-specific instructions. Furthermore, we propose a novel LLM guided Instruction Synthesizing and Iterative Training strategy, which iteratively tunes ControlRetriever based on extensive automatically-generated retrieval data wit
    
[^15]: DoDo学习: 语言模型中用于检测针对公众人物的滥用的领域-人口转移

    DoDo Learning: DOmain-DemOgraphic Transfer in Language Models for Detecting Abuse Targeted at Public Figures. (arXiv:2307.16811v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.16811](http://arxiv.org/abs/2307.16811)

    该研究旨在通过探索跨领域和跨人口的文本分类动态，构建更通用的滥用分类器。研究发现，少量多样的数据对于模型的通用化和适应非常有益。

    

    公众人物在社交媒体上受到了不成比例的滥用，这对他们在公众生活中的积极参与产生了影响。自动化系统可以大规模识别滥用，但标记训练数据既昂贵又复杂，可能会造成伤害。因此，系统的高效性和通用性是可取的，可以处理在线滥用的共享和特定方面。我们探索交叉群体文本分类的动态，以了解训练在一个领域或人口统计上的分类器在其他领域或人口统计上的转移情况，从而构建更通用的滥用分类器。我们使用我们的创新DODO数据集，其中包含28,000个标记条目，在跨领域（体育和政治）和跨人口（女性和男性）的四个领域-人口对中，微调语言模型来分类针对公众人物的推文。我们发现，（i）少量多样的数据对通用化和模型适应非常有益；（ii）模型的转移更容易。

    Public figures receive a disproportionate amount of abuse on social media, impacting their active participation in public life. Automated systems can identify abuse at scale but labelling training data is expensive, complex and potentially harmful. So, it is desirable that systems are efficient and generalisable, handling both shared and specific aspects of online abuse. We explore the dynamics of cross-group text classification in order to understand how well classifiers trained on one domain or demographic can transfer to others, with a view to building more generalisable abuse classifiers. We fine-tune language models to classify tweets targeted at public figures across DOmains (sport and politics) and DemOgraphics (women and men) using our novel DODO dataset, containing 28,000 labelled entries, split equally across four domain-demographic pairs. We find that (i) small amounts of diverse data are hugely beneficial to generalisation and model adaptation; (ii) models transfer more eas
    
[^16]: Brainformers：以效率换取简洁性

    Brainformers: Trading Simplicity for Efficiency. (arXiv:2306.00008v1 [cs.LG])

    [http://arxiv.org/abs/2306.00008](http://arxiv.org/abs/2306.00008)

    Brainformers 是一个新的深度神经网络模型，它通过使用多样层级的结构完善了 Transformer 的设计缺陷，具有更高效的训练收敛和更快的步骤时间，表现出更优秀的性能。

    

    Transformer 是自然语言处理和计算机视觉的最近成功的核心技术。Transformer 具有一个几乎统一的骨架，其中层次在前馈和自注意力之间交替以建立深度网络。在本文中，我们研究了这种设计选择，并发现更复杂的块可以更高效地完成任务。根据这个发现，我们提出了一个复杂的块，称为 Brainformer，它由各种形式的层归一化和激活函数、稀疏门控前馈层、密集前馈层、注意力层等多样层级组成。在质量和效率方面，Brainformer 总是优于现有的稠密和稀疏 Transformer。一个具有 80 亿个每个标记激活参数的 Brainformer 模型，相比于其 GLaM 对应物，表现出 2 倍更快的训练收敛和 5 倍更快的步骤时间。在下游任务评估中，Brainformer 也表现得更优秀。

    Transformers are central to recent successes in natural language processing and computer vision. Transformers have a mostly uniform backbone where layers alternate between feed-forward and self-attention in order to build a deep network. Here we investigate this design choice and find that more complex blocks that have different permutations of layer primitives can be more efficient. Using this insight, we develop a complex block, named Brainformer, that consists of a diverse sets of layers such as sparsely gated feed-forward layers, dense feed-forward layers, attention layers, and various forms of layer normalization and activation functions. Brainformer consistently outperforms the state-of-the-art dense and sparse Transformers, in terms of both quality and efficiency. A Brainformer model with 8 billion activated parameters per token demonstrates 2x faster training convergence and 5x faster step time compared to its GLaM counterpart. In downstream task evaluation, Brainformer also de
    
[^17]: 基于摘要描述的文本检索

    Retrieving Texts based on Abstract Descriptions. (arXiv:2305.12517v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12517](http://arxiv.org/abs/2305.12517)

    本研究针对语义检索问题，提出了一种基于摘要描述的文本检索模型，通过改进当前的文本嵌入方法，在标准最近邻搜索中取得了显著性能提升。

    

    虽然针对文本的信息提取，指令优化的大型语言模型表现优异，但对于在大规模文档集合中定位符合给定描述的文本（语义检索）并不适用。基于嵌入向量的相似度搜索可以通过查询执行检索，但嵌入中的相似度定义不明确且不一致，并且对于许多用例来说都是次优的。那么，什么是有效检索的好的查询表示？我们确定了根据内容的摘要描述检索句子的明确定义且一致的任务。我们展示了当前文本嵌入的不足，并提出了一种替代模型，在标准最近邻搜索中的表现显著提升。该模型使用通过提示LLM获得的正负样本对进行训练。虽然很容易从LLM中获得训练材料，但LLM无法直接执行检索任务。

    While instruction-tuned Large Language Models (LLMs) excel at extracting information from text, they are not suitable for locating texts conforming to a given description in a large document collection (semantic retrieval). Similarity search over embedding vectors does allow to perform retrieval by query, but the similarity reflected in the embedding is ill-defined and non-consistent, and is sub-optimal for many use cases. What, then, is a good query representation for effective retrieval?  We identify the well defined and consistent task of retrieving sentences based on abstract descriptions of their content. We demonstrate the inadequacy of current text embeddings and propose an alternative model that significantly improves when used in standard nearest neighbor search. The model is trained using positive and negative pairs sourced through prompting a LLM. While it is easy to source the training material from an LLM, the retrieval task cannot be performed by the LLM directly. This de
    

