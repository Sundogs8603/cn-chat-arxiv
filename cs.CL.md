# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [CB2: Collaborative Natural Language Interaction Research Platform.](http://arxiv.org/abs/2303.08127) | CB2是一个用于研究基于任务的合作自然语言交互的平台，在3D游戏环境中提供了后端服务器和各种工具和流程。它在可扩展的研究中展示了学习的指令跟随模型。 |
| [^2] | [Do Transformers Parse while Predicting the Masked Word?.](http://arxiv.org/abs/2303.08117) | 本文探讨了预训练语言模型是否实际上进行解析以及为什么能捕捉解析结构，证明了类似于BERT或RoBERTa这样的掩码语言模型可以近似执行英语PCFG的Inside-Outside算法。 |
| [^3] | [Simfluence: Modeling the Influence of Individual Training Examples by Simulating Training Runs.](http://arxiv.org/abs/2303.08114) | 本文提出了一种新的训练数据归因方法Simfluence，通过建立一个训练过程模拟器，可以追溯模型在任何给定样例上的预测结果到特定的有影响力的训练样例，从而研究训练样例间交互作用。 |
| [^4] | [Verbal behavior without syntactic structures: beyond Skinner and Chomsky.](http://arxiv.org/abs/2303.08080) | 语言的认知不能仅仅局限于语法结构研究，其模式化、动态的、多模态的、具有目的性及促进他人和自身理想行为（或思考）的特质可能是一个新的、可行的语言理论。 |
| [^5] | [Happy-GLL: modular, reusable and complete top-down parsers for parameterized nonterminals.](http://arxiv.org/abs/2303.08044) | 本文提出了 Happy-GLL 解析器生成器的后端，该后端支持参数化非终结符的模块化和可重用，从而提供了一种生成模块化、可重用和完整解析器的策略。 |
| [^6] | [TQ-Net: Mixed Contrastive Representation Learning For Heterogeneous Test Questions.](http://arxiv.org/abs/2303.08039) | 本文研究了一种混合对比表示学习方法（MCL2）用于异构测试问题的表示学习，与现有的文本表示方法相比具有更好的效果。 |
| [^7] | [Progress Note Understanding -- Assessment and Plan Reasoning: Overview of the 2022 N2C2 Track 3 Shared Task.](http://arxiv.org/abs/2303.08038) | 该论文介绍了2022 N2C2临床挑战赛中关于进展笔记理解-评估和计划推理的任务，旨在开发并评估自动预测因果相关概念的NLP系统。 |
| [^8] | [BODEGA: Benchmark for Adversarial Example Generation in Credibility Assessment.](http://arxiv.org/abs/2303.08032) | BODEGA是一个基准测试，用于模拟真实的内容管理场景，在四个误传检测任务上测试受害模型和攻击方法。测试结果表明，在某些情况下，即使进行微小的文本修改，也可以欺骗最准确的分类器。 |
| [^9] | [Optimizing Deep Learning Model Parameters with the Bees Algorithm for Improved Medical Text Classification.](http://arxiv.org/abs/2303.08021) | 本文使用蜜蜂算法优化了深度学习模型参数，提高了医学文本分类的准确性，最高准确率在英语数据集上达到了99.63%，在阿拉伯语数据集上达到了88%。 |
| [^10] | [Detection of Abuse in Financial Transaction Descriptions Using Machine Learning.](http://arxiv.org/abs/2303.08016) | 本文针对银行服务中的技术辅助虐待问题，开发了一个利用深度学习模型来识别和评分交易以识别虐待行为的系统。 |
| [^11] | [Does ChatGPT resemble humans in language use?.](http://arxiv.org/abs/2303.08014) | ChatGPT在大部分语言处理实验中与人类表现相似，能够产生人类一样的语言使用特征。但在两个实验中存在偏差，说明人类和机器语言处理之间仍存在重大差异。 |
| [^12] | [Data-Efficient Learning of Natural Language to Linear Temporal Logic Translators for Robot Task Specification.](http://arxiv.org/abs/2303.08006) | 本篇论文提出了一种基于学习的方法，通过算法生成 LTL 公式，转换成结构化英语来综合生成多样化的自然语言语料库，从而实现对于自然语言命令的 LTL 规格翻译，而且不需要大量的人工标记数据集。 |
| [^13] | [Evaluation of ChatGPT as a Question Answering System for Answering Complex Questions.](http://arxiv.org/abs/2303.07992) | 本论文评估了基于ChatGPT模型的问答系统在回答复杂问题方面的能力，通过一个分类框架对潜在的问题特征进行分类，通过黑盒测试规范CheckList评估模型性能。 |
| [^14] | [Finding the Needle in a Haystack: Unsupervised Rationale Extraction from Long Text Classifiers.](http://arxiv.org/abs/2303.07991) | 该论文研究了无监督理由提取的文档分类背景下，长文本分类器中的表现，并提出了一种比Longformer驱动的基线明显更好的RoBERTa句子级组合软注意力结构。 |
| [^15] | [A Theory of Emergent In-Context Learning as Implicit Structure Induction.](http://arxiv.org/abs/2303.07971) | 本文推导了一个信息理论界限，展示了在自然语言数据具有足够的组成结构的情况下，从一般的下一个标记预测中获得上下文学习能力。为验证理论预测，本文引入了一个受控制的设置来诱导上下文学习，证明了经过训练的Transformer可以为一系列任务执行上下文学习。 |
| [^16] | [Improving Accented Speech Recognition with Multi-Domain Training.](http://arxiv.org/abs/2303.07924) | 本文介绍了使用四种不同法语口音来创建微调数据集，以提高预训练ASR模型对口音的识别能力，并成功将错误率在非洲和比利时口音上降低高达25%。 |
| [^17] | [The Learnability of In-Context Learning.](http://arxiv.org/abs/2303.07895) | 本文提出了首个基于PAC的上下文可学习性框架，并使用其为上下文学习设置提供了首个有限样本复杂度结果。 |
| [^18] | [Geolocation Predicting of Tweets Using BERT-Based Models.](http://arxiv.org/abs/2303.07865) | 该论文提出基于BERT模型的推文地理位置预测方法，可以实现全球和美国上的中位误差分别小于30公里和15公里的定位精度。 |
| [^19] | [X-ReCoSa: Multi-Scale Context Aggregation For Multi-Turn Dialogue Generation.](http://arxiv.org/abs/2303.07833) | 提出了一种新的对话模型 X-ReCoSa，实现了多层次上下文聚合，将上下文表示和句子表示结合，以提高分层对话模型的效果。 |
| [^20] | [Efficient Image-Text Retrieval via Keyword-Guided Pre-Screening.](http://arxiv.org/abs/2303.07740) | 本文提出了一种基于关键词引导的预处理框架，可以用于在图像和文本之间进行快速高效的关键词匹配，以排除大量的无关样本。多任务学习方案以实现高性能关键词预测，并在检索中引入倒排索引，以实现高效的关键词匹配。 |
| [^21] | [Good Neighbors Are All You Need for Chinese Grapheme-to-Phoneme Conversion.](http://arxiv.org/abs/2303.07726) | Reinforcer模型使用邻近字符关系强化语言模型，解决了中文G2P中语言模型编码句子过于普遍和词边界分割不一致性的问题，获得了最先进的性能。 |
| [^22] | [Improving Prosody for Cross-Speaker Style Transfer by Semi-Supervised Style Extractor and Hierarchical Modeling in Speech Synthesis.](http://arxiv.org/abs/2303.07711) | 该论文提出了强度受控的半监督风格提取器以及分层韵律预测器来改善音频跨发言人风格转移中的韵律问题，解除了一对多映射和数据不平衡问题。 |
| [^23] | [Dual-Attention Model for Aspect-Level Sentiment Classification.](http://arxiv.org/abs/2303.07689) | 本文提出了一种面向方面级情感分类的双重注意力模型，使用依存标签为注意力机制执行任务，对三个数据集均有良好表现。 |
| [^24] | [Dynamic Alignment Mask CTC: Improved Mask-CTC with Aligned Cross Entropy.](http://arxiv.org/abs/2303.07687) | 本文提出了动态对齐遮罩CTC算法，采用了动态规划的方法来最小化交叉熵损失，同时使用动态矫正方法创建新的训练样本，使得该算法能够提高语音识别性能。 |
| [^25] | [QI-TTS: Questioning Intonation Control for Emotional Speech Synthesis.](http://arxiv.org/abs/2303.07682) | 本文提出了 QI-TTS，一种用于情感语音合成的疑问语调控制方法。通过使用一个多风格提取器和相对属性控制音节层面的语调强度，可以更好地表达发言者的疑问意图以及情感状态。 |
| [^26] | [Query2doc: Query Expansion with Large Language Models.](http://arxiv.org/abs/2303.07678) | 本论文提出了一种名为query2doc的查询扩展方法，使用大型语言模型生成伪文档来改善稀疏和密集检索系统，取得了在多个数据集上提高 BM25 性能的结果。 |
| [^27] | [RenewNAT: Renewing Potential Translation for Non-Autoregressive Transformer.](http://arxiv.org/abs/2303.07665) | 研究提出了一个非自回归神经机器翻译模型——RenewNAT，它结合了完全和迭代NAT模型的优点，通过一次传递以高效和有效的方式生成潜在翻译结果并更新它们，实现了相对于传统NAT模型的显著性能改进。 |
| [^28] | [Cross-lingual Alzheimer's Disease detection based on paralinguistic and pre-trained features.](http://arxiv.org/abs/2303.07650) | 该论文研究了跨语言阿尔茨海默病检测，使用平行语言和预训练特征提取声学和语言特征，实现了69.6%的分类准确率和4.788的均方根误差。 |
| [^29] | [I3D: Transformer architectures with input-dependent dynamic depth for speech recognition.](http://arxiv.org/abs/2303.07624) | 本篇论文提出了一种新的基于输入依赖性动态深度的Transformer编码器，即I3D，在推理时采用类似数量的层次的情况下，优于普通的Transformer和通过迭代层级修剪得到的静态修剪模型，有望在语音识别中实现性能效率最大化。 |
| [^30] | [The Life Cycle of Knowledge in Big Language Models: A Survey.](http://arxiv.org/abs/2303.07616) | 本综述总结了大语言模型中知识的生命周期，探讨了知识如何在 PLMs 中循环流动，总结了现有研究的限制和未来发展方向。 |
| [^31] | [Exploring ChatGPT's Ability to Rank Content: A Preliminary Study on Consistency with Human Preferences.](http://arxiv.org/abs/2303.07610) | 本研究探索了ChatGPT在内容排序方面的能力，通过排名测试集验证其排名偏好与人类相似，这意味着ChatGPT的零样本排名能力可用于减轻排序任务的注释压力。 |
| [^32] | [Input-length-shortening and text generation via attention values.](http://arxiv.org/abs/2303.07585) | 本文研究了BERT模型的注意力机制，提出了如何利用注意力缩短输入长度和控制条件文本生成的问题，并在文本分类任务中进行应用。研究发现BERT的早期层为文本分类分配了更关键的注意力分数。 |
| [^33] | [Diffusion Models in NLP: A Survey.](http://arxiv.org/abs/2303.07576) | 本文总结了在自然语言处理中，扩散模型在文本生成和驱动图像生成方面等应用中表现出的创纪录性能，并深入分析并总结相关文献资料。 |
| [^34] | [Audio Visual Language Maps for Robot Navigation.](http://arxiv.org/abs/2303.07522) | 该论文提出了一种音视语言地图(AVLMaps)，用于存储跨模态信息，实现机器人根据多模态查询在地图中索引目标的导航方式。在模拟实验中，AVLMaps实现了从多模态提示的零次学习式多模态目标导航，并提供了更好的召回率。 |
| [^35] | [AMOM: Adaptive Masking over Masking for Conditional Masked Language Model.](http://arxiv.org/abs/2303.07457) | 本文提出了一种适应性 Masking over Masking 策略来增强条件 Masked 语言模型的细化能力和优化效率，这种策略在神经机器翻译、摘要和代码生成任务中取得了显著的性能提升。 |
| [^36] | [MetaTroll: Few-shot Detection of State-Sponsored Trolls with Transformer Adapters.](http://arxiv.org/abs/2303.07354) | MetaTroll是一种使用Transformer Adapter的少样本巨魔检测模型，可以适应新的运动，并解决由于持续适应而导致模型遗忘的问题。 |
| [^37] | [Are Models Trained on Indian Legal Data Fair?.](http://arxiv.org/abs/2303.07247) | 本文从印度的法律领域出发，通过对在印地语法律文档上训练的模型在保释预测任务中的算法偏见传递进行了初步调查。结果表明，决策树模型在与印度教徒和穆斯林相关的输入特征上具有0.237的整体公平性差距。 |
| [^38] | [Large Language Models in the Workplace: A Case Study on Prompt Engineering for Job Type Classification.](http://arxiv.org/abs/2303.07142) | 本文探索了工作场所中的职业分类任务，并利用任务提示工程设计了良好的提示，成功地将大型语言模型（LLMs）应用于该任务中，取得了出色的表现，优于传统方法。 |
| [^39] | [Dual Path Modeling for Semantic Matching by Perceiving Subtle Conflicts.](http://arxiv.org/abs/2302.12530) | 本文提出了双路径建模框架来增强模型感知句子对中微妙差异的能力，并设计了DPM-Net来识别语义关系，在多个数据集上均实现了一致的改进。 |
| [^40] | [Time-aware Multiway Adaptive Fusion Network for Temporal Knowledge Graph Question Answering.](http://arxiv.org/abs/2302.12529) | 本论文提出了一种时间感知多路自适应融合网络，用于解决时态知识图问答问题，取得了比现有方法更好的性能。 |
| [^41] | [Large Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks.](http://arxiv.org/abs/2302.08399) | 大型语言模型在微小的理论任务改动上容易失败，表明在直觉心理学模型评估中需要持怀疑态度，且失败案例应被重视。 |
| [^42] | [GLADIS: A General and Large Acronym Disambiguation Benchmark.](http://arxiv.org/abs/2302.01860) | 该论文构建了一个名为GLADIS的通用大型缩写消歧基准，包括一个更大的缩写词典、一个包含1.6亿个句子的预训练语料库和覆盖通用、科学和生物医学领域的三个数据集。在此基础上预训练了一种语言模型AcroBERT，以用于通用缩写消歧。 |
| [^43] | [TriNet: stabilizing self-supervised learning from complete or slow collapse on ASR.](http://arxiv.org/abs/2301.00656) | 本文提出的TriNet采用三分支结构，可防止自监督学习在ASR中的崩溃，并在下游ASR任务中比SOTA方法Data2vec实现了6.06%的相对单词错误率降低（WERR）。 |
| [^44] | [A Concept Knowledge Graph for User Next Intent Prediction at Alipay.](http://arxiv.org/abs/2301.00503) | 本文提出了一种基于概念知识图谱的用户下一步意图预测技术，实现了在支付宝网络平台上对1亿活跃用户的服务，并且在保持可解释性的情况下，有效地提高了下游任务的性能表现。 |
| [^45] | [SuS-X: Training-Free Name-Only Transfer of Vision-Language Models.](http://arxiv.org/abs/2211.16198) | 本文提出了SuS-X，一种无需训练的基于名称的视觉语言模型迁移方法，具有较高的零样本分类能力。 |
| [^46] | [Navigation as Attackers Wish? Towards Building Byzantine-Robust Embodied Agents under Federated Learning.](http://arxiv.org/abs/2211.14769) | 本文研究了联邦学习体系下代理人学习中可能出现的攻击和防御策略，建立了全联邦拜占庭鲁棒的代理人学习模型。其中，导航即攻击者所愿（NAW）是一种简单而有效的攻击策略，而基于离群点检测的防御训练方法可以有效减轻NAW攻击的影响，提高代理人学习的全局鲁棒性。 |
| [^47] | [Active Relation Discovery: Towards General and Label-aware Open Relation Extraction.](http://arxiv.org/abs/2211.04215) | 本论文提出了一个活跃关系发现(ARD)框架，用于解决开放关系抽取中区分已知和新关系以及标记新关系类型的问题。实验证明，该框架在常规和更通用的设置上都显著优于以前的最先进方法。 |
| [^48] | [Suffix Retrieval-Augmented Language Modeling.](http://arxiv.org/abs/2211.03053) | 提出一种后缀检索增强语言模型 (SUREALM)，该模型以自回归的方式模拟双向上下文效应。采用嵌入检索器,在序列生成过程中搜索具有相似单词历史的训练句子数据存储。在DSTC9口语对话语料库上的表现优于竞争基线。 |
| [^49] | [Efficient Speech Translation with Dynamic Latent Perceivers.](http://arxiv.org/abs/2210.16264) | 本研究提出一种采用Perceiver编码器和Dynamic Latent Access(DLA)训练的语音翻译模型，该模型能够在MuST-C数据集的三种语言对上达到Transformer基线模型的性能水平，并且在推断时易于适应不同的计算预算，翻译质量没有显著下降。 |
| [^50] | [Neural inhibition during speech planning contributes to contrastive hyperarticulation.](http://arxiv.org/abs/2209.12278) | 本文提出了一个动态神经场模型，解释了语音对齐时间的超发音现象。通过对单词的最小对手进行抑制，实现了对比性超发音。伪单词实验结果表明，超发音现象与实时语音计划和制作有关。与实际单词相比，伪单词中超发音现象的程度和范围有所降低，表明词汇和音位计划层之间的交互激活在超发音上起到了作用。 |
| [^51] | [Ordinal analysis of lexical patterns.](http://arxiv.org/abs/2208.11175) | 通过对11种主要语言的语料进行序数模式分析，发现不同的语言有着独特的模式结构分布，这些分布的波动可以确定文本的历史时期和作者，这强调了序数时间序列分析在语言学研究中的重要性。 |
| [^52] | [Human heuristics for AI-generated language are flawed.](http://arxiv.org/abs/2206.07271) | 人们很难辨别AI生成的语言形式，因为通常采用的判断启发式算法出现了一些缺陷，需要使用更为复杂的语言分析工具和教育来提高人们的判断力。 |
| [^53] | [Improving CTC-based ASR Models with Gated Interlayer Collaboration.](http://arxiv.org/abs/2205.12462) | 本文提出了一种基于门控层间协作（GIC）机制来改进CTC-based模型性能的方法，在CTC-based模型中引入文本信息来提升模型性能，三个实验都表明该方法优于其他强基准。 |
| [^54] | [Relphormer: Relational Graph Transformer for Knowledge Graph Representations.](http://arxiv.org/abs/2205.10852) | Relphormer是一种新的Transformer变体，用于知识图谱表示。它引入了Triple2Seq和增强式自我注意机制，以解决基本Transformer架构在捕捉知识图谱结构和语义信息方面的不足。 |
| [^55] | [From Discrimination to Generation: Knowledge Graph Completion with Generative Transformer.](http://arxiv.org/abs/2202.02113) | 本文介绍了一种将知识图谱补全转化为生成任务的方法，同时引入了关系引导演示和实体感知分层解码来实现更好的表示学习和快速推断。实验结果表明，这种方法具有比基线更好或相当的性能，并且比以往的方法更快。同时，作者还发布了一个新的大规模中文知识图谱数据集AliopenKG500。 |
| [^56] | [Knowledge Graph Augmented Network Towards Multiview Representation Learning for Aspect-based Sentiment Analysis.](http://arxiv.org/abs/2201.04831) | 本文提出了一种名为KGAN的模型，通过知识图谱增强网络，将外部知识和上下文、句法信息相结合，从多个角度捕获情感特征，实现了多视角的表示学习。 |
| [^57] | [DECAR: Deep Clustering for learning general-purpose Audio Representations.](http://arxiv.org/abs/2110.08895) | 本文提出了一种基于深度聚类的自监督方法DECAR，用于学习通用的音频表示。该方法建立在先前自学习算法的基础之上，利用离线聚类的伪标签来解决预测任务，并在大规模Audioset数据集的平衡子集上进行了验证。 |
| [^58] | [Pretrained Language Models are Symbolic Mathematics Solvers too!.](http://arxiv.org/abs/2110.03501) | 本文研究表明，大规模语言模型可以训练为序列到序列任务，解决复杂的数学方程。文章提出了一种预训练并微调Transformer模型解决符号数学任务的方法，使用的训练样本比当前深度学习技术少1.5个数量级，且在积分任务上达到了可比较的准确性。 |
| [^59] | [Thought Flow Nets: From Single Predictions to Trains of Model Thought.](http://arxiv.org/abs/2107.12220) | 本文探讨了给模型第二次、第三次甚至第k次思考机会的思路流网络，其利用自我校正机制和梯度更新能够纠正自身预测，该方法可显著提高模型性能。 |
| [^60] | [To Understand Representation of Layer-aware Sequence Encoders as Multi-order-graph.](http://arxiv.org/abs/2101.06397) | 本文提出了一种解释基于自我注意力网络的序列编码器表示的方式，将其视为多阶图结构，并提出了一种名为多阶图的模型来描述这些图结构，并将SAN模型的编码转换为MoG的生成。此外，还引入了一个名为Graph-Transformer的模型来增强捕获多个不同阶级的子图的能力，并关注高阶子图，从而进一步提高了模型的表现。 |

# 详细

[^1]: CB2：合作自然语言交互研究平台

    CB2: Collaborative Natural Language Interaction Research Platform. (arXiv:2303.08127v1 [cs.LG])

    [http://arxiv.org/abs/2303.08127](http://arxiv.org/abs/2303.08127)

    CB2是一个用于研究基于任务的合作自然语言交互的平台，在3D游戏环境中提供了后端服务器和各种工具和流程。它在可扩展的研究中展示了学习的指令跟随模型。

    

    CB2 是一个多智能体平台，用于研究基于任务的情境下的合作自然语言交互。它包括一个 3D 游戏环境、一个后端服务器，可为人类智能体提供训练模型，以及各种工具和流程，以实现可扩展性的研究。我们在 https://cb2.ai 上展示了一个具有学习指令跟随模型的系统演示。

    CB2 is a multi-agent platform to study collaborative natural language interaction in a grounded task-oriented scenario. It includes a 3D game environment, a backend server designed to serve trained models to human agents, and various tools and processes to enable scalable studies. We deploy CB2 at https://cb2.ai as a system demonstration with a learned instruction following model.
    
[^2]: 转换器在预测掩码单词时是否解析？

    Do Transformers Parse while Predicting the Masked Word?. (arXiv:2303.08117v1 [cs.CL])

    [http://arxiv.org/abs/2303.08117](http://arxiv.org/abs/2303.08117)

    本文探讨了预训练语言模型是否实际上进行解析以及为什么能捕捉解析结构，证明了类似于BERT或RoBERTa这样的掩码语言模型可以近似执行英语PCFG的Inside-Outside算法。

    

    已经证明，预训练的语言模型在使用类似于掩码语言建模这样的无监督损失函数进行训练时，可以对语言结构进行编码，例如依赖关系和组成成分分析树。但是人们对于这些模型是否实际上进行解析或仅进行与解析弱相关的一些计算存在疑问。本文在生成建模的上下文中一步步回答了上述问题，探讨了(a)是否有可能明确描述具有现实嵌入维度，头数等的转换器，能够进行解析甚至近似解析；(b)预训练模型为什么能够捕捉解析结构？我们展示了类似于BERT或RoBERTa这样的中等大小的掩码语言模型可以近似执行英语PCFG（Marcus等，1993）的Inside-Outside算法。我们还展示了，在PCFG生成语言建模损失上，Inside-Outside算法是最优的。

    Pre-trained language models have been shown to encode linguistic structures, e.g. dependency and constituency parse trees, in their embeddings while being trained on unsupervised loss functions like masked language modeling. Some doubts have been raised whether the models actually are doing parsing or only some computation weakly correlated with it. We study questions: (a) Is it possible to explicitly describe transformers with realistic embedding dimension, number of heads, etc. that are capable of doing parsing -- or even approximate parsing? (b) Why do pre-trained models capture parsing structure? This paper takes a step toward answering these questions in the context of generative modeling with PCFGs. We show that masked language models like BERT or RoBERTa of moderate sizes can approximately execute the Inside-Outside algorithm for the English PCFG [Marcus et al, 1993]. We also show that the Inside-Outside algorithm is optimal for masked language modeling loss on the PCFG-generate
    
[^3]: Simfluence：通过模拟训练过程建模单个训练样例的影响

    Simfluence: Modeling the Influence of Individual Training Examples by Simulating Training Runs. (arXiv:2303.08114v1 [cs.LG])

    [http://arxiv.org/abs/2303.08114](http://arxiv.org/abs/2303.08114)

    本文提出了一种新的训练数据归因方法Simfluence，通过建立一个训练过程模拟器，可以追溯模型在任何给定样例上的预测结果到特定的有影响力的训练样例，从而研究训练样例间交互作用。

    

    训练数据归因（TDA）方法可以追溯模型在任何给定示例上的预测结果到特定的有影响力的训练示例。现有方法通过为每个训练示例分配一个标量影响分数来实现，假设影响是可加的。但实际上，我们观察到由于诸如示例之间的冗余、训练顺序和课程学习效应等因素，训练示例以高度非可加的方式相互作用。为了研究这种交互作用，我们提出了Simfluence，这是一种新的TDA范式，目标不是为每个示例生成单个的影响分数，而是一个训练过程模拟器：用户可以询问“如果我的模型训练了示例 z1、z2、……、zn，它在示例ztest上的表现会如何？”；然后模拟器应该输出一个模拟的训练过程，它是一个时间序列，在模拟的每个步骤都预测了在ztest上的损失。这使用户能够回答反事实问题。

    Training data attribution (TDA) methods offer to trace a model's prediction on any given example back to specific influential training examples. Existing approaches do so by assigning a scalar influence score to each training example, under a simplifying assumption that influence is additive. But in reality, we observe that training examples interact in highly non-additive ways due to factors such as inter-example redundancy, training order, and curriculum learning effects.  To study such interactions, we propose Simfluence, a new paradigm for TDA where the goal is not to produce a single influence score per example, but instead a training run simulator: the user asks, ``If my model had trained on example $z_1$, then $z_2$, ..., then $z_n$, how would it behave on $z_{test}$?''; the simulator should then output a simulated training run, which is a time series predicting the loss on $z_{test}$ at every step of the simulated run. This enables users to answer counterfactual questions about
    
[^4]: 语法结构外的言语行为：超越斯金纳和乔姆斯基

    Verbal behavior without syntactic structures: beyond Skinner and Chomsky. (arXiv:2303.08080v1 [cs.CL])

    [http://arxiv.org/abs/2303.08080](http://arxiv.org/abs/2303.08080)

    语言的认知不能仅仅局限于语法结构研究，其模式化、动态的、多模态的、具有目的性及促进他人和自身理想行为（或思考）的特质可能是一个新的、可行的语言理论。

    

    什么是语言认知？自乔姆斯基革命以来，对这个问题的一个普遍回答是：拥有产生语法结构的生成式语法。数十年过去了，任何语言的近似语法结构都未被制定出来。通用语法是天生具有的，这个理念已经证明是毫无成果的。试图展示语法如何从经验中学习也屡屡失败。为了摆脱这个僵局，我们必须重新发现语言与所有其他人类行为的相似性：动态的、社交的、多模态的、有模式的、有目的性的，其目的是促进他人和自己的理想行为（或思考）。最近对行为塑造和结构的心理、计算、神经生物学和进化方面的了解，可能会指引我们走向一种新的、可行的语言理论。

    What does it mean to know language? Since the Chomskian revolution, one popular answer to this question has been: to possess a generative grammar that exclusively licenses certain syntactic structures. Decades later, not even an approximation to such a grammar, for any language, has been formulated; the idea that grammar is universal and innately specified has proved barren; and attempts to show how it could be learned from experience invariably come up short. To move on from this impasse, we must rediscover the extent to which language is like any other human behavior: dynamic, social, multimodal, patterned, and purposive, its purpose being to promote desirable actions (or thoughts) in others and self. Recent psychological, computational, neurobiological, and evolutionary insights into the shaping and structure of behavior may then point us toward a new, viable account of language.
    
[^5]: Happy-GLL:模块化、可重用和完整的支持参数化非终结符的自顶向下解析器

    Happy-GLL: modular, reusable and complete top-down parsers for parameterized nonterminals. (arXiv:2303.08044v1 [cs.CL])

    [http://arxiv.org/abs/2303.08044](http://arxiv.org/abs/2303.08044)

    本文提出了 Happy-GLL 解析器生成器的后端，该后端支持参数化非终结符的模块化和可重用，从而提供了一种生成模块化、可重用和完整解析器的策略。

    

    解析器生成器和解析器组合库是生成解析器的最流行的工具。解析器组合器使用主机语言以高阶函数的形式提供可重用的组件，并将解析器作为参数。很少有解析器生成器通过抽象支持这种重用，而且生成的解析器像产生它们的语法部分一样模块化和可重用。本文提出了一种策略，基于 GL算法的 FUN-GLL变体，从具有参数化非终结符的语法描述生成模块化、可重用和完整的自顶向下解析器。该策略作为 Happy 解析器生成器的一种新的后端来展示和讨论。Happy 语法可以包含参数化非终结符，在这些非终结符中，参数抽象了语法符号，通过授权抽象机制定义可重用的语法运算符。然而，现有的 Happy 后端不能完全发挥参数化非终结符的潜力。所提出的 Happy-GLL 后端解决了这个问题，允许在 Happy 语法中使用模块化和可重用的参数化非终结符。

    Parser generators and parser combinator libraries are the most popular tools for producing parsers. Parser combinators use the host language to provide reusable components in the form of higher-order functions with parsers as parameters. Very few parser generators support this kind of reuse through abstraction and even fewer generate parsers that are as modular and reusable as the parts of the grammar for which they are produced. This paper presents a strategy for generating modular, reusable and complete top-down parsers from syntax descriptions with parameterized nonterminals, based on the FUN-GLL variant of the GLL algorithm.  The strategy is discussed and demonstrated as a novel back-end for the Happy parser generator. Happy grammars can contain `parameterized nonterminals' in which parameters abstract over grammar symbols, granting an abstraction mechanism to define reusable grammar operators. However, the existing Happy back-ends do not deliver on the full potential of parameteri
    
[^6]: TQ-Net：混合对比表示学习用于异构测试问题的研究

    TQ-Net: Mixed Contrastive Representation Learning For Heterogeneous Test Questions. (arXiv:2303.08039v1 [cs.CL])

    [http://arxiv.org/abs/2303.08039](http://arxiv.org/abs/2303.08039)

    本文研究了一种混合对比表示学习方法（MCL2）用于异构测试问题的表示学习，与现有的文本表示方法相比具有更好的效果。

    

    近年来，越来越多的人通过网络学习以便获取海量学习材料（例如测试问题/笔记），因此准确理解学习材料成为重要问题，对许多教育应用程序至关重要。先前的研究侧重于使用语言模型来表示问题数据。然而，测试问题（TQ）通常是异构的和多模式的，例如，一些问题仅包含文本，而另一些问题包含超出其文字描述的图像信息。在这种情况下，有监督和无监督方法都难以学习问题的融合表示。同时，传统方法如图像说明也无法解决这个问题，因为图像可能包含互补而不是复制的信息。本文首先通过两阶段的无监督实例级对比训练方法（MCL:混合无监督对比学习）改进了先前的单独文本表示。然后，我们提出了一种新颖的Mixed Contrastive Learning（MCL2）方法，其中融合了图像和文本模态，采用多实例和多级特征融合用于TQ表示学习。在两个TQ数据集上的实验结果表明，我们提出的方法优于几个最先进的基线，并在TQ分类和问题类型预测方面取得了更好的结果。

    Recently, more and more people study online for the convenience of access to massive learning materials (e.g. test questions/notes), thus accurately understanding learning materials became a crucial issue, which is essential for many educational applications. Previous studies focus on using language models to represent the question data. However, test questions (TQ) are usually heterogeneous and multi-modal, e.g., some of them may only contain text, while others half contain images with information beyond their literal description. In this context, both supervised and unsupervised methods are difficult to learn a fused representation of questions. Meanwhile, this problem cannot be solved by conventional methods such as image caption, as the images may contain information complementary rather than duplicate to the text. In this paper, we first improve previous text-only representation with a two-stage unsupervised instance level contrastive based pre-training method (MCL: Mixture Unsupe
    
[^7]: 进展笔记理解-评估和计划推理：2022 N2C2Track 3共享任务概述

    Progress Note Understanding -- Assessment and Plan Reasoning: Overview of the 2022 N2C2 Track 3 Shared Task. (arXiv:2303.08038v1 [cs.AI])

    [http://arxiv.org/abs/2303.08038](http://arxiv.org/abs/2303.08038)

    该论文介绍了2022 N2C2临床挑战赛中关于进展笔记理解-评估和计划推理的任务，旨在开发并评估自动预测因果相关概念的NLP系统。

    

    每日进展笔记是电子健康记录（EHR）中常见的类型，医疗保健提供者在其中记录患者的每日进展和治疗计划。 EHR旨在记录为患者提供的所有护理，但它也会使笔记膨胀并包含分散诊断和治疗计划的多余信息。 在EHR中应用自然语言处理（NLP）是一个不断增长的领域，其中大部分方法都用于信息提取。很少有任务使用NLP方法进行下游诊断决策支持。我们介绍了2022年国家自然语言处理临床挑战赛（N2C2）Track 3：进展笔记理解-评估和计划推理，作为新一套任务的一步。 评估和计划推理任务侧重于进展笔记的最关键组成部分，即包含健康问题和诊断的评估和计划子部分。 该任务的目标是开发并评估自动预测评估和计划推理中因果相关概念的NLP系统。

    Daily progress notes are common types in the electronic health record (EHR) where healthcare providers document the patient's daily progress and treatment plans. The EHR is designed to document all the care provided to patients, but it also enables note bloat with extraneous information that distracts from the diagnoses and treatment plans. Applications of natural language processing (NLP) in the EHR is a growing field with the majority of methods in information extraction. Few tasks use NLP methods for downstream diagnostic decision support. We introduced the 2022 National NLP Clinical Challenge (N2C2) Track 3: Progress Note Understanding - Assessment and Plan Reasoning as one step towards a new suite of tasks. The Assessment and Plan Reasoning task focuses on the most critical components of progress notes, Assessment and Plan subsections where health problems and diagnoses are contained. The goal of the task was to develop and evaluate NLP systems that automatically predict causal re
    
[^8]: BODEGA: 针对可信度评估中对抗性样本生成的基准测试

    BODEGA: Benchmark for Adversarial Example Generation in Credibility Assessment. (arXiv:2303.08032v1 [cs.CL])

    [http://arxiv.org/abs/2303.08032](http://arxiv.org/abs/2303.08032)

    BODEGA是一个基准测试，用于模拟真实的内容管理场景，在四个误传检测任务上测试受害模型和攻击方法。测试结果表明，在某些情况下，即使进行微小的文本修改，也可以欺骗最准确的分类器。

    

    文本分类方法被广泛应用于检测不可信内容，如假新闻、社交媒体机器人、宣传等。较为准确的模型（可能基于深度神经网络）有助于管理公共电子平台，并经常导致内容创建者面临提交拒绝或已发布文本的撤下。为了避免进一步被检测，内容创建者尝试产生一个稍微修改过的文本版本（即攻击对抗性样本），利用分类器的弱点导致不同的输出。本文介绍了BODEGA：一个基准测试，用于在模拟内容管理的真实用例中测试受害模型和攻击方法在四个误传检测任务上的表现。我们还系统地测试了受欢迎的文本分类器对可用攻击技术的鲁棒性，并发现在某些情况下，即使在文本中进行微小的修改也可以欺骗最准确的分类器。

    Text classification methods have been widely investigated as a way to detect content of low credibility: fake news, social media bots, propaganda, etc. Quite accurate models (likely based on deep neural networks) help in moderating public electronic platforms and often cause content creators to face rejection of their submissions or removal of already published texts. Having the incentive to evade further detection, content creators try to come up with a slightly modified version of the text (known as an attack with an adversarial example) that exploit the weaknesses of classifiers and result in a different output. Here we introduce BODEGA: a benchmark for testing both victim models and attack methods on four misinformation detection tasks in an evaluation framework designed to simulate real use-cases of content moderation. We also systematically test the robustness of popular text classifiers against available attacking techniques and discover that, indeed, in some cases barely signif
    
[^9]: 用蜜蜂算法优化深度学习模型参数，提高医学文本分类准确性

    Optimizing Deep Learning Model Parameters with the Bees Algorithm for Improved Medical Text Classification. (arXiv:2303.08021v1 [cs.CL])

    [http://arxiv.org/abs/2303.08021](http://arxiv.org/abs/2303.08021)

    本文使用蜜蜂算法优化了深度学习模型参数，提高了医学文本分类的准确性，最高准确率在英语数据集上达到了99.63%，在阿拉伯语数据集上达到了88%。

    

    本文介绍了一种使用蜜蜂算法对深度学习模型进行参数优化的新机制，这是一种最近很有前途的群智能算法。优化问题是在给定初始超参数的情况下，通过确定的迭代次数来最大化基于医学文本分类疾病的准确性。实验包括两个不同的数据集：英语和阿拉伯语。使用长短期记忆 (LSTM) 和蜜蜂算法，在英语数据集上获得了99.63%的最高准确率，在阿拉伯语数据集上使用AraBERT获得了88%的最高准确率。

    This paper introduces a novel mechanism to obtain the optimal parameters of a deep learning model using the Bees Algorithm, which is a recent promising swarm intelligence algorithm. The optimization problem is to maximize the accuracy of classifying ailments based on medical text given the initial hyper-parameters to be adjusted throughout a definite number of iterations. Experiments included two different datasets: English and Arabic. The highest accuracy achieved is 99.63% on the English dataset using Long Short-Term Memory (LSTM) along with the Bees Algorithm, and 88% on the Arabic dataset using AraBERT.
    
[^10]: 使用机器学习检测金融交易描述中的虐待行为

    Detection of Abuse in Financial Transaction Descriptions Using Machine Learning. (arXiv:2303.08016v1 [cs.CL])

    [http://arxiv.org/abs/2303.08016](http://arxiv.org/abs/2303.08016)

    本文针对银行服务中的技术辅助虐待问题，开发了一个利用深度学习模型来识别和评分交易以识别虐待行为的系统。

    

    自从新支付平台（NPP）引入了将消息作为付款描述的较长格式后，人们现在发现它被用于沟通，在某些情况下，该系统被用作定向的家庭暴力形式。这种利用技术实现的虐待行为在识别、采取措施和纠正这种行为方面带来了新的挑战。澳大利亚联邦银行的人工智能实验室（CBA AI Labs）利用自然语言处理（NLP）中深度学习模型的进步开发了一个新系统，定期评分所有交易，并在数百万条记录中识别高风险虐待情况。

    Since introducing changes to the New Payments Platform (NPP) to include longer messages as payment descriptions, it has been identified that people are now using it for communication, and in some cases, the system was being used as a targeted form of domestic and family violence. This type of tech-assisted abuse poses new challenges in terms of identification, actions and approaches to rectify this behaviour. Commonwealth Bank of Australia's Artificial Intelligence Labs team (CBA AI Labs) has developed a new system using advances in deep learning models for natural language processing (NLP) to create a powerful abuse detector that periodically scores all the transactions, and identifies cases of high-risk abuse in millions of records. In this paper, we describe the problem of tech-assisted abuse in the context of banking services, outline the developed model and its performance, and the operating framework more broadly.
    
[^11]: ChatGPT是否和人类在语言使用上相似?

    Does ChatGPT resemble humans in language use?. (arXiv:2303.08014v1 [cs.CL])

    [http://arxiv.org/abs/2303.08014](http://arxiv.org/abs/2303.08014)

    ChatGPT在大部分语言处理实验中与人类表现相似，能够产生人类一样的语言使用特征。但在两个实验中存在偏差，说明人类和机器语言处理之间仍存在重大差异。

    

    大型语言模型(LLM)和以LLM为驱动的聊天机器人(如ChatGPT)在理解和生成语言方面表现出色。然而，在认知层面上，它们的内部机制仍然是黑匣子，不清楚LLM和聊天机器人是否能够发展出人类的语言使用特征。我们对ChatGPT进行了12个实验，每个实验注册前进行了1000次运行。在其中的10个实验中，ChatGPT复制了人类语言使用的模式。它将不熟悉的单词与不同的含义进行关联，根据单词形式继续访问最近遇到的歧义词汇的含义，重用最近的语句结构，重新解释可能被噪声干扰的不合理语句，忽略错误，进行合理推断，根据它们的顺序和接近程度将因果关系与不同的话语实体相关联，并实时更正一致性错误。然而，在两个实验中，ChatGPT显示出与人类表现的偏差，这表明人类和机器语言处理之间仍存在重大差异。

    Large language models (LLMs) and LLM-driven chatbots such as ChatGPT have shown remarkable capacities in comprehending and producing language. However, their internal workings remain a black box in cognitive terms, and it is unclear whether LLMs and chatbots can develop humanlike characteristics in language use. Cognitive scientists have devised many experiments that probe, and have made great progress in explaining, how people process language. We subjected ChatGPT to 12 of these experiments, pre-registered and with 1,000 runs per experiment. In 10 of them, ChatGPT replicated the human pattern of language use. It associated unfamiliar words with different meanings depending on their forms, continued to access recently encountered meanings of ambiguous words, reused recent sentence structures, reinterpreted implausible sentences that were likely to have been corrupted by noise, glossed over errors, drew reasonable inferences, associated causality with different discourse entities accor
    
[^12]: 基于数据有效学习的机器人任务规格自然语言到线性时间逻辑翻译器

    Data-Efficient Learning of Natural Language to Linear Temporal Logic Translators for Robot Task Specification. (arXiv:2303.08006v1 [cs.CL])

    [http://arxiv.org/abs/2303.08006](http://arxiv.org/abs/2303.08006)

    本篇论文提出了一种基于学习的方法，通过算法生成 LTL 公式，转换成结构化英语来综合生成多样化的自然语言语料库，从而实现对于自然语言命令的 LTL 规格翻译，而且不需要大量的人工标记数据集。

    

    为了使机器人能够服务于更广泛的受众，赋予其理解自然语言命令并用线性时间逻辑（LTL）等形式语言定义具体任务规格的能力至关重要。本文提出了一种基于学习的方法，能够将自然语言命令翻译成 LTL 规格，而且只需要非常有限的受试者标注训练数据。与现有的自然语言到LTL翻译器相比，这种方法不需要大量的人工标记数据集，而是通过算法生成LTL公式，转换成结构化英语，然后利用现代大型语言模型（LLMs）的改写能力来综合生成多样化的自然语言语料库。

    To make robots accessible to a broad audience, it is critical to endow them with the ability to take universal modes of communication, like commands given in natural language, and extract a concrete desired task specification, defined using a formal language like linear temporal logic (LTL). In this paper, we present a learning-based approach for translating from natural language commands to LTL specifications with very limited human-labeled training data. This is in stark contrast to existing natural-language to LTL translators, which require large human-labeled datasets, often in the form of labeled pairs of LTL formulas and natural language commands, to train the translator. To reduce reliance on human data, our approach generates a large synthetic training dataset through algorithmic generation of LTL formulas, conversion to structured English, and then exploiting the paraphrasing capabilities of modern large language models (LLMs) to synthesize a diverse corpus of natural language
    
[^13]: 评估 ChatGPT 作为回答复杂问题的问答系统

    Evaluation of ChatGPT as a Question Answering System for Answering Complex Questions. (arXiv:2303.07992v1 [cs.CL])

    [http://arxiv.org/abs/2303.07992](http://arxiv.org/abs/2303.07992)

    本论文评估了基于ChatGPT模型的问答系统在回答复杂问题方面的能力，通过一个分类框架对潜在的问题特征进行分类，通过黑盒测试规范CheckList评估模型性能。

    

    ChatGPT 是一个强大的大型语言模型，已在自然语言理解方面取得了显著进展。然而，该模型的性能和局限性仍需要进行广泛评估。由于 ChatGPT 覆盖维基百科等资源并支持自然语言问答，因此它引起了作为传统知识库问答（KBQA）模型替代品的关注。复杂问题回答是 KBQA 的一项挑战性任务，全面测试了模型在语义解析和推理方面的能力。为了评估 ChatGPT 作为一个使用自己知识回答复杂问题的问答系统的性能，我们提出了一个框架来评估其回答复杂问题的能力。我们的方法涉及对复杂问题的潜在特征进行分类，并使用多个标签描述每个测试问题，以识别组合推理。根据 Ribeir 提出的 CheckList 的黑盒测试规范，我们评估了ChatGPT模型的性能。

    ChatGPT is a powerful large language model (LLM) that has made remarkable progress in natural language understanding. Nevertheless, the performance and limitations of the model still need to be extensively evaluated. As ChatGPT covers resources such as Wikipedia and supports natural language question answering, it has garnered attention as a potential replacement for traditional knowledge based question answering (KBQA) models. Complex question answering is a challenge task of KBQA, which comprehensively tests the ability of models in semantic parsing and reasoning. To assess the performance of ChatGPT as a question answering system (QAS) using its own knowledge, we present a framework that evaluates its ability to answer complex questions. Our approach involves categorizing the potential features of complex questions and describing each test question with multiple labels to identify combinatorial reasoning. Following the black-box testing specifications of CheckList proposed by Ribeir
    
[^14]: 在长文本分类器中无监督地提取理由

    Finding the Needle in a Haystack: Unsupervised Rationale Extraction from Long Text Classifiers. (arXiv:2303.07991v1 [cs.CL])

    [http://arxiv.org/abs/2303.07991](http://arxiv.org/abs/2303.07991)

    该论文研究了无监督理由提取的文档分类背景下，长文本分类器中的表现，并提出了一种比Longformer驱动的基线明显更好的RoBERTa句子级组合软注意力结构。

    

    长序列转换器旨在通过语言模型改进较长文本的表示，并提高它们在下游文档级任务中的性能。然而，人们对长格式模型中令牌级别预测的质量尚不太了解。我们研究了这种架构在无监督理由提取的文档分类背景下的性能。我们发现当与Longformer语言模型结合使用时，标准软量注意方法表现显着较差。我们提出了一种组合软量关注架构，它将RoBERTa应用于句子，以在令牌级别提取可信理由。我们发现这种方法在情感分类数据集上明显优于Longformer衍生基线，并且展现出明显更低的运行时间。

    Long-sequence transformers are designed to improve the representation of longer texts by language models and their performance on downstream document-level tasks. However, not much is understood about the quality of token-level predictions in long-form models. We investigate the performance of such architectures in the context of document classification with unsupervised rationale extraction. We find standard soft attention methods to perform significantly worse when combined with the Longformer language model. We propose a compositional soft attention architecture that applies RoBERTa sentence-wise to extract plausible rationales at the token-level. We find this method to significantly outperform Longformer-driven baselines on sentiment classification datasets, while also exhibiting significantly lower runtimes.
    
[^15]: 一种关于隐含结构归纳的上下文中涌现学习理论

    A Theory of Emergent In-Context Learning as Implicit Structure Induction. (arXiv:2303.07971v1 [cs.CL])

    [http://arxiv.org/abs/2303.07971](http://arxiv.org/abs/2303.07971)

    本文推导了一个信息理论界限，展示了在自然语言数据具有足够的组成结构的情况下，从一般的下一个标记预测中获得上下文学习能力。为验证理论预测，本文引入了一个受控制的设置来诱导上下文学习，证明了经过训练的Transformer可以为一系列任务执行上下文学习。

    

    大规模语言模型的扩展引发了涌现式上下文学习的能力，即基于示例演示进行学习。尽管取得了一些进展，但对这种现象的理论理解仍然有限。我们认为，上下文学习依赖于自然语言数据中发现的组合性操作的重新组合。在基于语言学假设的情况下，我们推导出了一种信息理论界限，展示了当预训练分布具有足够的组成结构时，如何从一般的下一个标记预测中获得上下文学习能力。第二个界限为提示LLM输出朝着答案的中间步骤的实证成功提供了理论基础。为了验证理论预测，我们引入了一个受控制的设置来诱导上下文学习。与以往方法不同，它考虑到语言的组合本质。经过训练的Transformer可以为一系列任务执行上下文学习，这与在自然语言数据上预训练的 Transformer 保持一致。

    Scaling large language models (LLMs) leads to an emergent capacity to learn in-context from example demonstrations. Despite progress, theoretical understanding of this phenomenon remains limited. We argue that in-context learning relies on recombination of compositional operations found in natural language data. We derive an information-theoretic bound showing how in-context learning abilities arise from generic next-token prediction when the pretraining distribution has sufficient amounts of compositional structure, under linguistically motivated assumptions. A second bound provides a theoretical justification for the empirical success of prompting LLMs to output intermediate steps towards an answer. To validate theoretical predictions, we introduce a controlled setup for inducing in-context learning; unlike previous approaches, it accounts for the compositional nature of language. Trained transformers can perform in-context learning for a range of tasks, in a manner consistent with t
    
[^16]: 多领域训练在提高口音语音识别方面的应用

    Improving Accented Speech Recognition with Multi-Domain Training. (arXiv:2303.07924v1 [cs.LG])

    [http://arxiv.org/abs/2303.07924](http://arxiv.org/abs/2303.07924)

    本文介绍了使用四种不同法语口音来创建微调数据集，以提高预训练ASR模型对口音的识别能力，并成功将错误率在非洲和比利时口音上降低高达25%。

    

    随着自监督学习的增长，自动语音识别系统在广泛数据集上已经实现了接近人类的性能。然而，它们仍然缺乏泛化能力，并且不具备对口音变化等领域转移的稳健性。在本文中，我们使用代表四种不同法语口音的语音音频来创建微调数据集，以提高预训练ASR模型的稳健性。通过在训练集中包含不同的口音，我们得到了领域内和领域外的改进。数字实验表明，在与单领域训练相比，我们可以将错误率在非洲和比利时口音上降低高达25%（相对值），同时在标准法语上保持良好的性能。

    Thanks to the rise of self-supervised learning, automatic speech recognition (ASR) systems now achieve near-human performance on a wide variety of datasets. However, they still lack generalization capability and are not robust to domain shifts like accent variations. In this work, we use speech audio representing four different French accents to create fine-tuning datasets that improve the robustness of pre-trained ASR models. By incorporating various accents in the training set, we obtain both in-domain and out-of-domain improvements. Our numerical experiments show that we can reduce error rates by up to 25% (relative) on African and Belgian accents compared to single-domain training while keeping a good performance on standard French.
    
[^17]: 在上下文学习的可学习性

    The Learnability of In-Context Learning. (arXiv:2303.07895v1 [cs.CL])

    [http://arxiv.org/abs/2303.07895](http://arxiv.org/abs/2303.07895)

    本文提出了首个基于PAC的上下文可学习性框架，并使用其为上下文学习设置提供了首个有限样本复杂度结果。

    

    在现代语言模型参数扩展到数十亿个的情况下出现了令人惊讶且重要的上下文学习现象。在不修改大型语言模型的权重的情况下，只需将这些任务的训练样例与其输入连接即可将其调整为执行各种下游自然语言任务。虽然对于大型语言模型的许多实际应用具有破坏性，但这种新兴的学习范式从理论角度尚不为人所知。本文提出了一个首次基于PAC的上下文可学习性框架，并利用它为上下文学习设置提供了首个有限样本复杂度结果。我们的框架包括一个初始预训练阶段，它将一个函数拟合到预训练分布中，然后是第二个上下文学习阶段，它保持该函数不变，并将下游任务的训练样例连接到其输入中。我们使用我们的框架来

    In-context learning is a surprising and important phenomenon that emerged when modern language models were scaled to billions of learned parameters. Without modifying a large language model's weights, it can be tuned to perform various downstream natural language tasks simply by including concatenated training examples of these tasks in its input. Though disruptive for many practical applications of large language models, this emergent learning paradigm is not well understood from a theoretical perspective. In this paper, we propose a first-of-its-kind PAC based framework for in-context learnability, and use it to provide the first finite sample complexity results for the in-context learning setup. Our framework includes an initial pretraining phase, which fits a function to the pretraining distribution, and then a second in-context learning phase, which keeps this function constant and concatenates training examples of the downstream task in its input. We use our framework in order to
    
[^18]: 基于BERT模型的推文地理位置预测

    Geolocation Predicting of Tweets Using BERT-Based Models. (arXiv:2303.07865v1 [cs.CL])

    [http://arxiv.org/abs/2303.07865](http://arxiv.org/abs/2303.07865)

    该论文提出基于BERT模型的推文地理位置预测方法，可以实现全球和美国上的中位误差分别小于30公里和15公里的定位精度。

    

    该研究旨在解决推文/用户地理位置预测任务，并提供了处理文本大数据地理标记的灵活方法。该方法采用基于神经网络的自然语言处理来估计坐标对（经度，纬度）和二维高斯混合模型（GMM）。提出的模型的范围已经在Twitter数据集上使用预训练的BERT模型进行调整。性能指标表明，对于在推文内容和元数据上训练和评估的模型，全球范围内的中位误差小于30公里，美国范围内的中位误差小于15公里。

    This research is aimed to solve the tweet/user geolocation prediction task and provide a flexible methodology for the geotagging of textual big data. The suggested approach implements neural networks for natural language processing (NLP) to estimate the location as coordinate pairs (longitude, latitude) and two-dimensional Gaussian Mixture Models (GMMs). The scope of proposed models has been finetuned on a Twitter dataset using pretrained Bidirectional Encoder Representations from Transformers (BERT) as base models. Performance metrics show a median error of fewer than 30 km on a worldwide-level, and fewer than 15 km on the US-level datasets for the models trained and evaluated on text features of tweets' content and metadata context.
    
[^19]: X-ReCoSa: 多层次上下文聚合的多轮对话生成

    X-ReCoSa: Multi-Scale Context Aggregation For Multi-Turn Dialogue Generation. (arXiv:2303.07833v1 [cs.CL])

    [http://arxiv.org/abs/2303.07833](http://arxiv.org/abs/2303.07833)

    提出了一种新的对话模型 X-ReCoSa，实现了多层次上下文聚合，将上下文表示和句子表示结合，以提高分层对话模型的效果。

    

    在多轮对话生成中，回复不仅与上下文的主题和背景有关，还与上下文中句子中的单词和短语有关。然而，目前广泛使用的分层对话模型仅依靠话语级别编码器的上下文表示，忽略了单词级别编码器的句子表示。这必然会在解码和生成的过程中丢失信息。本文提出了一种新的对话模型X-ReCoSa，以解决这个问题，该模型聚合了多层次上下文信息，适用于分层对话模型。具体来说，我们将生成解码器分为上部和下部，即意图部分和生成部分。首先，意图部分将上下文表示作为输入，生成回复的意图。然后，生成部分根据句子表示生成单词。因此，分层信息已被融合到结果中。

    In multi-turn dialogue generation, responses are not only related to the topic and background of the context but also related to words and phrases in the sentences of the context. However, currently widely used hierarchical dialog models solely rely on context representations from the utterance-level encoder, ignoring the sentence representations output by the word-level encoder. This inevitably results in a loss of information while decoding and generating. In this paper, we propose a new dialog model X-ReCoSa to tackle this problem which aggregates multi-scale context information for hierarchical dialog models. Specifically, we divide the generation decoder into upper and lower parts, namely the intention part and the generation part. Firstly, the intention part takes context representations as input to generate the intention of the response. Then the generation part generates words depending on sentence representations. Therefore, the hierarchical information has been fused into res
    
[^20]: 通过关键词引导的预处理实现高效的图像文本检索

    Efficient Image-Text Retrieval via Keyword-Guided Pre-Screening. (arXiv:2303.07740v1 [cs.CV])

    [http://arxiv.org/abs/2303.07740](http://arxiv.org/abs/2303.07740)

    本文提出了一种基于关键词引导的预处理框架，可以用于在图像和文本之间进行快速高效的关键词匹配，以排除大量的无关样本。多任务学习方案以实现高性能关键词预测，并在检索中引入倒排索引，以实现高效的关键词匹配。

    

    针对目前图像文本检索方法在性能方面蓬勃发展，但存在$N$相关时间复杂度的问题，影响了它们在实际应用中的使用。本文提出了一种简单有效的基于关键词引导的预处理框架，可用于图像文本检索。具体来说，我们将图像和文本数据转换为关键词，并在模态之间执行关键词匹配以排除大量无关的样本，然后再输入到检索网络中。对于关键词预测，我们将其转换为多标签分类问题，提出了一种多任务学习方案，通过将多标签分类器附加到图像文本检索网络中以实现轻量级和高性能的关键词预测。对于关键词匹配，我们在搜索引擎中引入倒排索引，实现了对预检索中的时间和空间复杂度双赢的情况。在两个广泛使用的数据集上进行了广泛的实验。

    Under the flourishing development in performance, current image-text retrieval methods suffer from $N$-related time complexity, which hinders their application in practice. Targeting at efficiency improvement, this paper presents a simple and effective keyword-guided pre-screening framework for the image-text retrieval. Specifically, we convert the image and text data into the keywords and perform the keyword matching across modalities to exclude a large number of irrelevant gallery samples prior to the retrieval network. For the keyword prediction, we transfer it into a multi-label classification problem and propose a multi-task learning scheme by appending the multi-label classifiers to the image-text retrieval network to achieve a lightweight and high-performance keyword prediction. For the keyword matching, we introduce the inverted index in the search engine and create a win-win situation on both time and space complexities for the pre-screening. Extensive experiments on two widel
    
[^21]: 仅需好的邻居：基于邻近字符关系强化的中文字素到音素转换方法

    Good Neighbors Are All You Need for Chinese Grapheme-to-Phoneme Conversion. (arXiv:2303.07726v1 [cs.CL])

    [http://arxiv.org/abs/2303.07726](http://arxiv.org/abs/2303.07726)

    Reinforcer模型使用邻近字符关系强化语言模型，解决了中文G2P中语言模型编码句子过于普遍和词边界分割不一致性的问题，获得了最先进的性能。

    

    大多数中文字素到音素（G2P）系统采用三阶段架构，首先将输入序列转化为字符嵌入，使用语言模型获取语言信息，然后基于整个输入序列的全局上下文预测音素。然而，仅凭语言知识往往是不充分的。语言模型经常编码句子的过于普遍的结构，并未涵盖使用语音知识所需的特定情况。此外，需要一个手工后处理系统来解决与字符音调相关的问题。然而，系统在词边界分割上存在不一致性，从而降低了G2P系统的性能。为了解决这些问题，我们提出了Reinforcer模型，通过强调邻近字符之间的语音信息来为语言模型提供强大的引导偏差，以帮助消除发音的歧义。实验结果表明，与先前的中文G2P系统相比，Reinforcer模型在各种指标上实现了最先进的性能。

    Most Chinese Grapheme-to-Phoneme (G2P) systems employ a three-stage framework that first transforms input sequences into character embeddings, obtains linguistic information using language models, and then predicts the phonemes based on global context about the entire input sequence. However, linguistic knowledge alone is often inadequate. Language models frequently encode overly general structures of a sentence and fail to cover specific cases needed to use phonetic knowledge. Also, a handcrafted post-processing system is needed to address the problems relevant to the tone of the characters. However, the system exhibits inconsistency in the segmentation of word boundaries which consequently degrades the performance of the G2P system. To address these issues, we propose the Reinforcer that provides strong inductive bias for language models by emphasizing the phonological information between neighboring characters to help disambiguate pronunciations. Experimental results show that the R
    
[^22]: 通过半监督风格提取器和分层建模改进音频跨发言人风格转移的韵律

    Improving Prosody for Cross-Speaker Style Transfer by Semi-Supervised Style Extractor and Hierarchical Modeling in Speech Synthesis. (arXiv:2303.07711v1 [cs.SD])

    [http://arxiv.org/abs/2303.07711](http://arxiv.org/abs/2303.07711)

    该论文提出了强度受控的半监督风格提取器以及分层韵律预测器来改善音频跨发言人风格转移中的韵律问题，解除了一对多映射和数据不平衡问题。

    

    在语音合成中，跨发言人风格转移旨在将源发言人的风格转移到目标发言人音色的合成语音中。在大多数方法中，合成的细粒度韵律特征通常表示源发言人的平均风格，类似于一对多问题（即，多个韵律变化对应于同一文本）。为了解决这个问题，提出了一种强度受控的半监督风格提取器，以解开风格与内容和音色之间的联系，改善全局风格嵌入的表示和可解释性，这可以缓解韵律预测中的一对多映射和数据不平衡问题。提出了一种分层韵律预测器来改善韵律建模。我们发现，使用易于预测的源发言人韵律特征可以实现更好的风格转移。此外，提出了一种讲话人间循环一致性损失，以帮助模型学习未观察到的目标说话者的特征。

    Cross-speaker style transfer in speech synthesis aims at transferring a style from source speaker to synthesized speech of a target speaker's timbre. In most previous methods, the synthesized fine-grained prosody features often represent the source speaker's average style, similar to the one-to-many problem(i.e., multiple prosody variations correspond to the same text). In response to this problem, a strength-controlled semi-supervised style extractor is proposed to disentangle the style from content and timbre, improving the representation and interpretability of the global style embedding, which can alleviate the one-to-many mapping and data imbalance problems in prosody prediction. A hierarchical prosody predictor is proposed to improve prosody modeling. We find that better style transfer can be achieved by using the source speaker's prosody features that are easily predicted. Additionally, a speaker-transfer-wise cycle consistency loss is proposed to assist the model in learning un
    
[^23]: 面向方面级情感分类的双重注意力模型

    Dual-Attention Model for Aspect-Level Sentiment Classification. (arXiv:2303.07689v1 [cs.CL])

    [http://arxiv.org/abs/2303.07689](http://arxiv.org/abs/2303.07689)

    本文提出了一种面向方面级情感分类的双重注意力模型，使用依存标签为注意力机制执行任务，对三个数据集均有良好表现。

    

    本文提出了一种新颖的面向方面级情感分类的双重注意力模型(DAM)。尽管许多现有的方法，如支持向量机用于人工设计特征、基于注意力机制的长短时记忆网络和基于依存句法分析的图神经网络，都有不错的性能，但我认为它们都缺少一个重要的句法信息：依存标签。基于这个想法，本文提出了一种使用依存标签为注意力机制执行任务的模型。我们在三个数据集上评估了所提出的方法：笔记本电脑和餐厅数据集来自SemEval 2014，最后一个是Twitter数据集。实验结果表明，双重注意力模型在所有三个数据集上具有良好的性能。

    I propose a novel dual-attention model(DAM) for aspect-level sentiment classification. Many methods have been proposed, such as support vector machines for artificial design features, long short-term memory networks based on attention mechanisms, and graph neural networks based on dependency parsing. While these methods all have decent performance, I think they all miss one important piece of syntactic information: dependency labels. Based on this idea, this paper proposes a model using dependency labels for the attention mechanism to do this task. We evaluate the proposed approach on three datasets: laptop and restaurant are from SemEval 2014, and the last one is a twitter dataset. Experimental results show that the dual attention model has good performance on all three datasets.
    
[^24]: 动态对齐遮罩CTC: 通过对齐交叉熵进行改进的遮罩CTC

    Dynamic Alignment Mask CTC: Improved Mask-CTC with Aligned Cross Entropy. (arXiv:2303.07687v1 [cs.SD])

    [http://arxiv.org/abs/2303.07687](http://arxiv.org/abs/2303.07687)

    本文提出了动态对齐遮罩CTC算法，采用了动态规划的方法来最小化交叉熵损失，同时使用动态矫正方法创建新的训练样本，使得该算法能够提高语音识别性能。

    

    与传统的自回归模型相比，非自回归模型由于可以同时预测所有目标令牌，因此极大地提高了语音识别的解码效率。本文提出了动态对齐遮罩CTC，引入了两种方法：（1）对齐的交叉熵（AXE），通过动态规划找到最小化交叉熵损失的单调对齐；（2）动态矫正，通过将一些遮罩替换为模型预测的令牌，创建新的训练样本。AXE忽略了预测和实际句子之间的绝对位置对齐，而是关注以相对顺序匹配的令牌。动态矫正方法使模型能够模拟非遮罩但可能错误的令牌，即使它们具有较高的置信度。我们在WSJ数据集上的实验表明，不仅AXE损失，而且矫正方法都可以提高遮罩CTC的WER性能。

    Because of predicting all the target tokens in parallel, the non-autoregressive models greatly improve the decoding efficiency of speech recognition compared with traditional autoregressive models. In this work, we present dynamic alignment Mask CTC, introducing two methods: (1) Aligned Cross Entropy (AXE), finding the monotonic alignment that minimizes the cross-entropy loss through dynamic programming, (2) Dynamic Rectification, creating new training samples by replacing some masks with model predicted tokens. The AXE ignores the absolute position alignment between prediction and ground truth sentence and focuses on tokens matching in relative order. The dynamic rectification method makes the model capable of simulating the non-mask but possible wrong tokens, even if they have high confidence. Our experiments on WSJ dataset demonstrated that not only AXE loss but also the rectification method could improve the WER performance of Mask CTC.
    
[^25]: QI-TTS: 用于情感语音合成的疑问语调控制

    QI-TTS: Questioning Intonation Control for Emotional Speech Synthesis. (arXiv:2303.07682v1 [cs.SD])

    [http://arxiv.org/abs/2303.07682](http://arxiv.org/abs/2303.07682)

    本文提出了 QI-TTS，一种用于情感语音合成的疑问语调控制方法。通过使用一个多风格提取器和相对属性控制音节层面的语调强度，可以更好地表达发言者的疑问意图以及情感状态。

    

    近期的情感语音合成模型主要关注合成表达情感的语音，但一些细粒度的风格，例如语调，被忽略了。本文提出了 QI-TTS，旨在更好地转移和控制语调，在转移情感的同时传递发言者的疑问意图。我们提出了一个多风格提取器，从两个不同层次提取风格信息。虽然句子层次表示情感，但最终的音节层次则表示语调。为了进行细粒度的语调控制，我们使用相对属性来表示音节层次的语调强度。实验验证了 QI-TTS 在情感语音合成中提高语调表现力的有效性。

    Recent expressive text to speech (TTS) models focus on synthesizing emotional speech, but some fine-grained styles such as intonation are neglected. In this paper, we propose QI-TTS which aims to better transfer and control intonation to further deliver the speaker's questioning intention while transferring emotion from reference speech. We propose a multi-style extractor to extract style embedding from two different levels. While the sentence level represents emotion, the final syllable level represents intonation. For fine-grained intonation control, we use relative attributes to represent intonation intensity at the syllable level.Experiments have validated the effectiveness of QI-TTS for improving intonation expressiveness in emotional speech synthesis.
    
[^26]: Query2doc: 基于大型语言模型的查询扩展方法

    Query2doc: Query Expansion with Large Language Models. (arXiv:2303.07678v1 [cs.IR])

    [http://arxiv.org/abs/2303.07678](http://arxiv.org/abs/2303.07678)

    本论文提出了一种名为query2doc的查询扩展方法，使用大型语言模型生成伪文档来改善稀疏和密集检索系统，取得了在多个数据集上提高 BM25 性能的结果。

    

    本论文介绍了一种简单但有效的查询扩展方法，称为query2doc，可改善稀疏和密集检索系统。该方法首先利用小批量提示大型语言模型生成伪文档，然后使用生成的伪文档扩展查询。大型语言模型经过训练，能够记忆知识，从而生成的伪文档通常包含高度相关的信息，有助于查询消岐和指导检索器。实验结果表明，在不进行任何模型微调的情况下，query2doc 在 MS-MARCO 和 TREC DL 等 ad-hoc IR 数据集上将 BM25 的性能提高了 3% 到 15%。此外，我们的方法还在领域内和领域外的结果方面受益于最先进的密集检索器。

    This paper introduces a simple yet effective query expansion approach, denoted as query2doc, to improve both sparse and dense retrieval systems. The proposed method first generates pseudo-documents by few-shot prompting large language models (LLMs), and then expands the query with generated pseudo-documents. LLMs are trained on web-scale text corpora and are adept at knowledge memorization. The pseudo-documents from LLMs often contain highly relevant information that can aid in query disambiguation and guide the retrievers. Experimental results demonstrate that query2doc boosts the performance of BM25 by 3% to 15% on ad-hoc IR datasets, such as MS-MARCO and TREC DL, without any model fine-tuning. Furthermore, our method also benefits state-of-the-art dense retrievers in terms of both in-domain and out-of-domain results.
    
[^27]: RenewNAT: 非自回归Transformer的更新潜在翻译

    RenewNAT: Renewing Potential Translation for Non-Autoregressive Transformer. (arXiv:2303.07665v1 [cs.CL])

    [http://arxiv.org/abs/2303.07665](http://arxiv.org/abs/2303.07665)

    研究提出了一个非自回归神经机器翻译模型——RenewNAT，它结合了完全和迭代NAT模型的优点，通过一次传递以高效和有效的方式生成潜在翻译结果并更新它们，实现了相对于传统NAT模型的显著性能改进。

    

    非自回归神经机器翻译(NAT)模型被提出来加速推理过程同时保持相对高的性能。然而，现有的NAT模型很难实现所期望的效率-质量权衡。一方面，完全NAT模型在高效推理方面表现不及其自回归对应物。另一方面，迭代NAT模型可以实现可比的性能，但减弱了速度优势。在本文中，我们提出了RenewNAT，一个高效有效的灵活框架，结合了完全和迭代NAT模型的优点。RenewNAT首先生成潜在的翻译结果，然后在单次传递中更新它们。它可以在不引入额外的模型参数和解码延迟的情况下实现显著的性能改进。在各种翻译基准测试中的实验结果（例如，\textbf{4} WMT）表明，我们的...

    Non-autoregressive neural machine translation (NAT) models are proposed to accelerate the inference process while maintaining relatively high performance. However, existing NAT models are difficult to achieve the desired efficiency-quality trade-off. For one thing, fully NAT models with efficient inference perform inferior to their autoregressive counterparts. For another, iterative NAT models can, though, achieve comparable performance while diminishing the advantage of speed. In this paper, we propose RenewNAT, a flexible framework with high efficiency and effectiveness, to incorporate the merits of fully and iterative NAT models. RenewNAT first generates the potential translation results and then renews them in a single pass. It can achieve significant performance improvements at the same expense as traditional NAT models (without introducing additional model parameters and decoding latency). Experimental results on various translation benchmarks (e.g., \textbf{4} WMT) show that our
    
[^28]: 基于平行语言和预训练特征的跨语言阿尔茨海默病检测

    Cross-lingual Alzheimer's Disease detection based on paralinguistic and pre-trained features. (arXiv:2303.07650v1 [cs.CL])

    [http://arxiv.org/abs/2303.07650](http://arxiv.org/abs/2303.07650)

    该论文研究了跨语言阿尔茨海默病检测，使用平行语言和预训练特征提取声学和语言特征，实现了69.6%的分类准确率和4.788的均方根误差。

    

    本文介绍我们在ICASSP-SPGC-2023 ADReSS-M挑战任务中的提交，旨在研究哪些声学特征可以跨语言应用于阿尔茨海默病（AD）的预测中。我们使用openSmile工具包提取平行语言特征和XLSR-53提取声学特征。此外，我们将语音转录为文本后提取语言特征。这些特征被用作我们方法中的AD检测指标。我们的方法在分类任务上实现了69.6％的准确率，在回归任务上的均方根误差（RMSE）为4.788。结果表明，我们的方法有望在跨语言AD检测方面发挥作用。

    We present our submission to the ICASSP-SPGC-2023 ADReSS-M Challenge Task, which aims to investigate which acoustic features can be generalized and transferred across languages for Alzheimer's Disease (AD) prediction. The challenge consists of two tasks: one is to classify the speech of AD patients and healthy individuals, and the other is to infer Mini Mental State Examination (MMSE) score based on speech only. The difficulty is mainly embodied in the mismatch of the dataset, in which the training set is in English while the test set is in Greek. We extract paralinguistic features using openSmile toolkit and acoustic features using XLSR-53. In addition, we extract linguistic features after transcribing the speech into text. These features are used as indicators for AD detection in our method. Our method achieves an accuracy of 69.6% on the classification task and a root mean squared error (RMSE) of 4.788 on the regression task. The results show that our proposed method is expected to 
    
[^29]: I3D: 基于输入依赖性动态深度的Transformer结构用于语音识别

    I3D: Transformer architectures with input-dependent dynamic depth for speech recognition. (arXiv:2303.07624v1 [cs.CL])

    [http://arxiv.org/abs/2303.07624](http://arxiv.org/abs/2303.07624)

    本篇论文提出了一种新的基于输入依赖性动态深度的Transformer编码器，即I3D，在推理时采用类似数量的层次的情况下，优于普通的Transformer和通过迭代层级修剪得到的静态修剪模型，有望在语音识别中实现性能效率最大化。

    

    基于Transformer的端到端语音识别已经取得了非常大的成功。但是，由于其大的尺寸和计算开销，使得在某些真实世界的应用中难以部署这些模型。模型压缩技术可以减小模型尺寸并加快推理速度，但压缩模型具有固定的结构，这可能是次优的。我们提出了一种新的Transformer编码器，称为输入依赖性动态深度（I3D），以实现强大的性能效率折衷。在推理时采用类似数量的层次的情况下，基于I3D的模型优于普通的Transformer和通过迭代层级修剪得到的静态修剪模型。我们还对门概率和输入依赖性进行了有趣的分析，这有助于我们更好地理解深度编码器。

    Transformer-based end-to-end speech recognition has achieved great success. However, the large footprint and computational overhead make it difficult to deploy these models in some real-world applications. Model compression techniques can reduce the model size and speed up inference, but the compressed model has a fixed architecture which might be suboptimal. We propose a novel Transformer encoder with Input-Dependent Dynamic Depth (I3D) to achieve strong performance-efficiency trade-offs. With a similar number of layers at inference time, I3D-based models outperform the vanilla Transformer and the static pruned model via iterative layer pruning. We also present interesting analysis on the gate probabilities and the input-dependency, which helps us better understand deep encoders.
    
[^30]: 大语言模型中知识的生命周期：综述

    The Life Cycle of Knowledge in Big Language Models: A Survey. (arXiv:2303.07616v1 [cs.CL])

    [http://arxiv.org/abs/2303.07616](http://arxiv.org/abs/2303.07616)

    本综述总结了大语言模型中知识的生命周期，探讨了知识如何在 PLMs 中循环流动，总结了现有研究的限制和未来发展方向。

    

    知识在人工智能中起着至关重要的作用。最近，预训练语言模型（PLMs）的广泛成功引起了人们对语言模型如何获取、维护、更新和使用知识的重视。尽管有大量相关研究，但仍然缺乏一个统一的视角来了解知识在学习、调整和应用过程中在语言模型内部如何循环，这可能阻碍我们进一步了解当前进展的联系或实现现有限制。在本综述中，我们将PLMs重新视为基于知识的系统，将PLMs中知识的生命周期分为五个关键时期，并调查了知识在建立、维护和使用时的循环方式。为此，我们系统地审查了知识生命周期的每个时期的现有研究，总结了主要挑战和当前限制，并讨论了未来的方向。

    Knowledge plays a critical role in artificial intelligence. Recently, the extensive success of pre-trained language models (PLMs) has raised significant attention about how knowledge can be acquired, maintained, updated and used by language models. Despite the enormous amount of related studies, there still lacks a unified view of how knowledge circulates within language models throughout the learning, tuning, and application processes, which may prevent us from further understanding the connections between current progress or realizing existing limitations. In this survey, we revisit PLMs as knowledge-based systems by dividing the life circle of knowledge in PLMs into five critical periods, and investigating how knowledge circulates when it is built, maintained and used. To this end, we systematically review existing studies of each period of the knowledge life cycle, summarize the main challenges and current limitations, and discuss future directions.
    
[^31]: 探索ChatGPT在内容排序方面的能力：与人类偏好一致性的初步研究

    Exploring ChatGPT's Ability to Rank Content: A Preliminary Study on Consistency with Human Preferences. (arXiv:2303.07610v1 [cs.CL])

    [http://arxiv.org/abs/2303.07610](http://arxiv.org/abs/2303.07610)

    本研究探索了ChatGPT在内容排序方面的能力，通过排名测试集验证其排名偏好与人类相似，这意味着ChatGPT的零样本排名能力可用于减轻排序任务的注释压力。

    

    作为自然语言助手，ChatGPT能够执行各种任务，包括但不限于文章生成、代码完成和数据分析。此外，ChatGPT在内容评估方面始终表现出卓越的准确性和可靠性，展示出模仿人类偏好的能力。为了进一步探索ChatGPT在这方面的潜力，进行了一项研究以评估其排序内容的能力。为此，创建了一个测试集，包括广泛的用例，利用五个模型生成相应的回应。然后，指示ChatGPT对这些模型生成的回应进行排序。测试集的结果表明，ChatGPT的排序偏好与人类在一定程度上一致。这个初步的实验发现意味着ChatGPT的零样本排序能力可用于减轻许多排序任务中的注释压力。

    As a natural language assistant, ChatGPT is capable of performing various tasks, including but not limited to article generation, code completion, and data analysis. Furthermore, ChatGPT has consistently demonstrated a remarkable level of accuracy and reliability in terms of content evaluation, exhibiting the capability of mimicking human preferences. To further explore ChatGPT's potential in this regard, a study is conducted to assess its ability to rank content. In order to do so, a test set consisting of prompts is created, covering a wide range of use cases, and five models are utilized to generate corresponding responses. ChatGPT is then instructed to rank the responses generated by these models. The results on the test set show that ChatGPT's ranking preferences are consistent with human to a certain extent. This preliminary experimental finding implies that ChatGPT's zero-shot ranking capability could be used to reduce annotation pressure in a number of ranking tasks.
    
[^32]: 利用注意力值缩短输入长度和生成文本

    Input-length-shortening and text generation via attention values. (arXiv:2303.07585v1 [cs.CL])

    [http://arxiv.org/abs/2303.07585](http://arxiv.org/abs/2303.07585)

    本文研究了BERT模型的注意力机制，提出了如何利用注意力缩短输入长度和控制条件文本生成的问题，并在文本分类任务中进行应用。研究发现BERT的早期层为文本分类分配了更关键的注意力分数。

    

    在自然语言处理中，识别影响任务性能的词语是一个挑战。最近，使用注意力机制的Transformer模型已经解决了这个问题，通过为一些词分配更高的注意力（即相关性）分数。由于注意力机制的高计算成本，Transformer模型通常由于硬件限制而有输入长度限制。这个限制适用于许多Transformer，包括知名的双向编码器表示的Transformer（BERT）模型。本文研究了BERT的注意力分配机制，关注以下两个问题：（1）如何利用注意力缩短输入长度？（2）如何利用注意力作为条件文本生成的控制机制？我们将这些问题应用于文本分类任务。我们发现BERT的早期层为文本分类分配了更关键的注意力分数。

    Identifying words that impact a task's performance more than others is a challenge in natural language processing. Transformers models have recently addressed this issue by incorporating an attention mechanism that assigns greater attention (i.e., relevance) scores to some words than others. Because of the attention mechanism's high computational cost, transformer models usually have an input-length limitation caused by hardware constraints. This limitation applies to many transformers, including the well-known bidirectional encoder representations of the transformer (BERT) model. In this paper, we examined BERT's attention assignment mechanism, focusing on two questions: (1) How can attention be employed to reduce input length? (2) How can attention be used as a control mechanism for conditional text generation? We investigated these questions in the context of a text classification task. We discovered that BERT's early layers assign more critical attention scores for text classificat
    
[^33]: NLP 中的扩散模型：一项调查研究

    Diffusion Models in NLP: A Survey. (arXiv:2303.07576v1 [cs.CL])

    [http://arxiv.org/abs/2303.07576](http://arxiv.org/abs/2303.07576)

    本文总结了在自然语言处理中，扩散模型在文本生成和驱动图像生成方面等应用中表现出的创纪录性能，并深入分析并总结相关文献资料。

    

    扩散模型已成为一个强大的深层生成模型系列，在许多应用中显示了创记录的性能。本文首先概述和推导了扩散模型的基本理论，然后回顾了扩散模型在自然语言处理领域中的研究成果，从文本生成、文本驱动的图像生成等四个方面进行分析和总结了相关的文献资料，并最终记录了这个主题文献综述研究的经验和感受。

    Diffusion models have become a powerful family of deep generative models, with record-breaking performance in many applications. This paper first gives an overview and derivation of the basic theory of diffusion models, then reviews the research results of diffusion models in the field of natural language processing, from text generation, text-driven image generation and other four aspects, and analyzes and summarizes the relevant literature materials sorted out, and finally records the experience and feelings of this topic literature review research.
    
[^34]: 机器人导航的音视语言地图

    Audio Visual Language Maps for Robot Navigation. (arXiv:2303.07522v1 [cs.RO])

    [http://arxiv.org/abs/2303.07522](http://arxiv.org/abs/2303.07522)

    该论文提出了一种音视语言地图(AVLMaps)，用于存储跨模态信息，实现机器人根据多模态查询在地图中索引目标的导航方式。在模拟实验中，AVLMaps实现了从多模态提示的零次学习式多模态目标导航，并提供了更好的召回率。

    

    与世界的互动是一种多感官的体验，但是许多机器人仍然主要依赖视觉感知来绘制和导航他们的环境。本文提出了音视语言地图(AVLMaps)，这是一个统一的3D空间地图表示，用于存储来自音频、视觉和语言线索的跨模态信息。在导航的情境下，我们展示了AVLMaps能够使机器人系统根据多模态查询(例如，文本描述、图像或地标的音频片段)在地图中索引目标。特别是，添加音频信息使机器人能够更可靠地消除目标位置的歧义性。在模拟实验中，我们展示了AVLMaps能够实现从多模态提示进行零次学习的多模态目标导航，并在模糊场景中提供50%更好的召回率。

    While interacting in the world is a multi-sensory experience, many robots continue to predominantly rely on visual perception to map and navigate in their environments. In this work, we propose Audio-Visual-Language Maps (AVLMaps), a unified 3D spatial map representation for storing cross-modal information from audio, visual, and language cues. AVLMaps integrate the open-vocabulary capabilities of multimodal foundation models pre-trained on Internet-scale data by fusing their features into a centralized 3D voxel grid. In the context of navigation, we show that AVLMaps enable robot systems to index goals in the map based on multimodal queries, e.g., textual descriptions, images, or audio snippets of landmarks. In particular, the addition of audio information enables robots to more reliably disambiguate goal locations. Extensive experiments in simulation show that AVLMaps enable zero-shot multimodal goal navigation from multimodal prompts and provide 50% better recall in ambiguous scenar
    
[^35]: AMOM: 适应性 Masking over Masking 用于条件 Masked 语言模型

    AMOM: Adaptive Masking over Masking for Conditional Masked Language Model. (arXiv:2303.07457v1 [cs.CL])

    [http://arxiv.org/abs/2303.07457](http://arxiv.org/abs/2303.07457)

    本文提出了一种适应性 Masking over Masking 策略来增强条件 Masked 语言模型的细化能力和优化效率，这种策略在神经机器翻译、摘要和代码生成任务中取得了显著的性能提升。

    

    基于 Transformer 的自回归方法已经在各种序列生成任务中取得了令人满意的性能，例如神经机器翻译、摘要和代码生成，但是推理效率较低。为了加速推理阶段，过去几年中提出了许多非自回归策略。其中，条件 Masked 语言模型 (CMLM) 是最通用的框架之一，因为它可以支持许多不同的序列生成场景，并在这些任务上取得非常有竞争力的性能。在本文中，我们进一步引入了一种简单而有效的适应性 Masking over Masking 策略来增强解码器的细化能力并使编码器的优化更加容易。在总共 \textbf{15} 个数据集上的 \textbf{3} 个不同任务（神经机器翻译、摘要和代码生成）的实验确认：我们提出的简单方法取得了显著的性能提升。

    Transformer-based autoregressive (AR) methods have achieved appealing performance for varied sequence-to-sequence generation tasks, e.g., neural machine translation, summarization, and code generation, but suffer from low inference efficiency. To speed up the inference stage, many non-autoregressive (NAR) strategies have been proposed in the past few years. Among them, the conditional masked language model (CMLM) is one of the most versatile frameworks, as it can support many different sequence generation scenarios and achieve very competitive performance on these tasks. In this paper, we further introduce a simple yet effective adaptive masking over masking strategy to enhance the refinement capability of the decoder and make the encoder optimization easier. Experiments on \textbf{3} different tasks (neural machine translation, summarization, and code generation) with \textbf{15} datasets in total confirm that our proposed simple method achieves significant performance improvement ove
    
[^36]: MetaTroll: 使用Transformer Adapter进行少样本提取国家赞助的巨魔检测

    MetaTroll: Few-shot Detection of State-Sponsored Trolls with Transformer Adapters. (arXiv:2303.07354v1 [cs.CL])

    [http://arxiv.org/abs/2303.07354](http://arxiv.org/abs/2303.07354)

    MetaTroll是一种使用Transformer Adapter的少样本巨魔检测模型，可以适应新的运动，并解决由于持续适应而导致模型遗忘的问题。

    

    国家赞助的巨魔是社交媒体影响运动的主要参与者，自动巨魔检测对大规模打击错误信息很重要。现有的巨魔检测模型是基于已知运动的训练数据开发的（例如：俄罗斯互联网研究机构对2016年美国大选的影响运动），当处理对新目标的新型运动时，无法胜任。在元学习框架下，我们提出了基于文本的巨魔检测模型MetaTroll，其可以使用极少量的标记样本适应并适用于新的运动，从而实现高度可移植性和参数效率。我们在MetaTroll中引入了“特定于运动”的转换适配器，以“记忆”运动特定知识，以解决由于持续适应而导致模型“遗忘”如何检测旧运动的问题。我们的实验表明，MetaTroll明显优于基线和同类最先进的方法。

    State-sponsored trolls are the main actors of influence campaigns on social media and automatic troll detection is important to combat misinformation at scale. Existing troll detection models are developed based on training data for known campaigns (e.g.\ the influence campaign by Russia's Internet Research Agency on the 2016 US Election), and they fall short when dealing with {\em novel} campaigns with new targets. We propose MetaTroll, a text-based troll detection model based on the meta-learning framework that enables high portability and parameter-efficient adaptation to new campaigns using only a handful of labelled samples for few-shot transfer. We introduce \textit{campaign-specific} transformer adapters to MetaTroll to ``memorise'' campaign-specific knowledge so as to tackle catastrophic forgetting, where a model ``forgets'' how to detect trolls from older campaigns due to continual adaptation. Our experiments demonstrate that MetaTroll substantially outperforms baselines and s
    
[^37]: 印度法律数据训练的模型是否公平？

    Are Models Trained on Indian Legal Data Fair?. (arXiv:2303.07247v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.07247](http://arxiv.org/abs/2303.07247)

    本文从印度的法律领域出发，通过对在印地语法律文档上训练的模型在保释预测任务中的算法偏见传递进行了初步调查。结果表明，决策树模型在与印度教徒和穆斯林相关的输入特征上具有0.237的整体公平性差距。

    

    自然语言处理和人工智能的最新进展与应用在多个领域（如法律、医疗和心理健康）取得了很大成功。最近提出了基于人工智能的语言模型（如判决预测）用于法律领域。然而，这些模型从训练数据中捕捉到了社会偏见。虽然NLP领域的偏见和公平性已经得到研究，但大多数研究主要定位在西方背景下。本文从印度的法律领域出发，对公平性进行了初步调查。我们重点研究了在印地语法律文档上训练的模型在保释预测任务中传递学习到的算法偏见。我们使用群体平等评估公平性差距，并展示了一个决策树模型在保释预测任务中，在与印度教徒和穆斯林相关的输入特征上具有0.237的整体公平性差距。此外，我们强调了对印度法律领域的公平性研究的必要性。

    Recent advances and applications of language technology and artificial intelligence have enabled much success across multiple domains like law, medical and mental health. AI-based Language Models, like Judgement Prediction, have recently been proposed for the legal sector. However, these models are strife with encoded social biases picked up from the training data. While bias and fairness have been studied across NLP, most studies primarily locate themselves within a Western context. In this work, we present an initial investigation of fairness from the Indian perspective in the legal domain. We highlight the propagation of learnt algorithmic biases in the bail prediction task for models trained on Hindi legal documents. We evaluate the fairness gap using demographic parity and show that a decision tree model trained for the bail prediction task has an overall fairness disparity of 0.237 between input features associated with Hindus and Muslims. Additionally, we highlight the need for 
    
[^38]: 工作场所中的大型语言模型：一个关于任务提示工程在职业类型分类中的实证研究

    Large Language Models in the Workplace: A Case Study on Prompt Engineering for Job Type Classification. (arXiv:2303.07142v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.07142](http://arxiv.org/abs/2303.07142)

    本文探索了工作场所中的职业分类任务，并利用任务提示工程设计了良好的提示，成功地将大型语言模型（LLMs）应用于该任务中，取得了出色的表现，优于传统方法。

    

    本文通过探索多种文本分类方法，包括基于监督学习的传统模型如支持向量机（SVMs）以及最先进的深度学习方法，如DeBERTa，以及大型语言模型（LLMs）在少样本和零样本分类情况下的应用，来研究实际工作场所中的职业分类任务。为了完成此任务，我们采用了任务提示工程的技术，即设计提示以引导LLMs达到所需的输出。具体来说，我们评估了两种商业可用的最先进的基于GPT-3.5的语言模型，text-davinci-003和gpt-3.5-turbo。我们还对提示工程的不同方面对模型性能的影响进行了详细的分析。我们的结果表明，在良好设计的提示的帮助下，LLMs在职业类型分类任务上可以达到出色的表现，优于传统方法如SVMs，甚至优于最先进的深度学习方法如DeBERTa。

    This case study investigates the task of job classification in a real-world setting, where the goal is to determine whether an English-language job posting is appropriate for a graduate or entry-level position. We explore multiple approaches to text classification, including supervised approaches such as traditional models like Support Vector Machines (SVMs) and state-of-the-art deep learning methods such as DeBERTa. We compare them with Large Language Models (LLMs) used in both few-shot and zero-shot classification settings. To accomplish this task, we employ prompt engineering, a technique that involves designing prompts to guide the LLMs towards the desired output. Specifically, we evaluate the performance of two commercially available state-of-the-art GPT-3.5-based language models, text-davinci-003 and gpt-3.5-turbo. We also conduct a detailed analysis of the impact of different aspects of prompt engineering on the model's performance. Our results show that, with a well-designed pr
    
[^39]: 感知微妙冲突的语义匹配双路径建模

    Dual Path Modeling for Semantic Matching by Perceiving Subtle Conflicts. (arXiv:2302.12530v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.12530](http://arxiv.org/abs/2302.12530)

    本文提出了双路径建模框架来增强模型感知句子对中微妙差异的能力，并设计了DPM-Net来识别语义关系，在多个数据集上均实现了一致的改进。

    

    基于Transformer的预训练模型在语义匹配方面取得了巨大的进展。然而，现有的模型仍然缺乏捕捉微妙差异的能力。在句子对中修改、添加和删除单词可能使得模型难以预测它们之间的关系。为了缓解这个问题，我们提出了一个新颖的双路径建模框架，通过分别建模亲和和差异语义来增强模型感知句子对中微妙差异的能力。基于这个双路径建模框架，我们设计了双路径建模网络（DPM-Net）来识别语义关系。我们在10个广泛研究的语义匹配和鲁棒性测试数据集上进行了大量实验，实验结果表明，我们提出的方法相对于基线方法实现了一致的改进。

    Transformer-based pre-trained models have achieved great improvements in semantic matching. However, existing models still suffer from insufficient ability to capture subtle differences. The modification, addition and deletion of words in sentence pairs may make it difficult for the model to predict their relationship. To alleviate this problem, we propose a novel Dual Path Modeling Framework to enhance the model's ability to perceive subtle differences in sentence pairs by separately modeling affinity and difference semantics. Based on dual-path modeling framework we design the Dual Path Modeling Network (DPM-Net) to recognize semantic relations. And we conduct extensive experiments on 10 well-studied semantic matching and robustness test datasets, and the experimental results show that our proposed method achieves consistent improvements over baselines.
    
[^40]: 时间感知多路自适应融合网络用于时态知识图问答

    Time-aware Multiway Adaptive Fusion Network for Temporal Knowledge Graph Question Answering. (arXiv:2302.12529v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.12529](http://arxiv.org/abs/2302.12529)

    本论文提出了一种时间感知多路自适应融合网络，用于解决时态知识图问答问题，取得了比现有方法更好的性能。

    

    知识图谱因其在自然语言处理方面的广泛应用而受到越来越多的关注。然而，它在时态问答方面的使用案例尚未得到很好的探索。现有大多数方法都基于预训练语言模型开发，这可能无法学习有关于时态知识图QA任务方面的实体的时态专用表示。为了缓解这个问题，我们提出了一种新颖的时间感知多路自适应（TMA）融合网络。受人类逐步推理行为的启发，对于每个给定的问题，TMA首先从KG中提取相关概念，然后将其馈送到多路自适应模块以生成问题的时态特定表示。该表示可以与预先训练的KG嵌入相结合以生成最终预测。实验结果验证了所提出的模型在两个基准数据集上实现了比现有最先进方法更好的性能。

    Knowledge graphs (KGs) have received increasing attention due to its wide applications on natural language processing. However, its use case on temporal question answering (QA) has not been well-explored. Most of existing methods are developed based on pre-trained language models, which might not be capable to learn \emph{temporal-specific} presentations of entities in terms of temporal KGQA task. To alleviate this problem, we propose a novel \textbf{T}ime-aware \textbf{M}ultiway \textbf{A}daptive (\textbf{TMA}) fusion network. Inspired by the step-by-step reasoning behavior of humans. For each given question, TMA first extracts the relevant concepts from the KG, and then feeds them into a multiway adaptive module to produce a \emph{temporal-specific} representation of the question. This representation can be incorporated with the pre-trained KG embedding to generate the final prediction. Empirical results verify that the proposed model achieves better performance than the state-of-the
    
[^41]: 大型语言模型在 Theory-of-Mind 任务的微小改变上失败

    Large Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks. (arXiv:2302.08399v5 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.08399](http://arxiv.org/abs/2302.08399)

    大型语言模型在微小的理论任务改动上容易失败，表明在直觉心理学模型评估中需要持怀疑态度，且失败案例应被重视。

    

    直觉心理学是常识推理的支柱。在机器智能中复制这种推理是迈向类人工智能的一个重要基石。最近，有几项任务和基准用于检查大型语言模型中这种推理，特别关注心灵理论任务中的信念归属。这些任务既有成功案例也有失败案例。我们特别考虑了一个最近声称的成功案例，并展示了维持ToM原则的小幅变化使结果大相径庭。我们认为，一般来说，在直觉心理学模型评估中，零假设应该持怀疑态度，并且离群故障案例应该超过平均成功率。我们还考虑了更强大的LLM（Large-Large Models）在理解心理学任务上可能取得的未来成功对人类ToM任务意味着什么。

    Intuitive psychology is a pillar of common-sense reasoning. The replication of this reasoning in machine intelligence is an important stepping-stone on the way to human-like artificial intelligence. Several recent tasks and benchmarks for examining this reasoning in Large-Large Models have focused in particular on belief attribution in Theory-of-Mind tasks. These tasks have shown both successes and failures. We consider in particular a recent purported success case, and show that small variations that maintain the principles of ToM turn the results on their head. We argue that in general, the zero-hypothesis for model evaluation in intuitive psychology should be skeptical, and that outlying failure cases should outweigh average success rates. We also consider what possible future successes on Theory-of-Mind tasks by more powerful LLMs would mean for ToM tasks with people.
    
[^42]: GLADIS: 一个通用的大型缩写消歧基准

    GLADIS: A General and Large Acronym Disambiguation Benchmark. (arXiv:2302.01860v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.01860](http://arxiv.org/abs/2302.01860)

    该论文构建了一个名为GLADIS的通用大型缩写消歧基准，包括一个更大的缩写词典、一个包含1.6亿个句子的预训练语料库和覆盖通用、科学和生物医学领域的三个数据集。在此基础上预训练了一种语言模型AcroBERT，以用于通用缩写消歧。

    

    缩写消歧对于理解各种来源的自然语言都至关重要，包括生物医学报告、科学论文和搜索引擎查询。然而，现有的缩写消歧基准和工具仅适用于特定领域，先前的基准的规模也相对较小。为了加速缩写消歧的研究，我们构建了一个名为GLADIS的新基准，包括三个部分：(1)一个含有1.5M缩写和6.4M长格式的更大的缩写词典; (2)一个包含1.6亿个句子的预训练语料库; (3)覆盖通用、科学和生物医学领域的三个数据集。我们在我们构建的语料库上预先训练了一种语言模型AcroBERT以进行通用缩写消歧，并展示了我们新基准的挑战和价值。

    Acronym Disambiguation (AD) is crucial for natural language understanding on various sources, including biomedical reports, scientific papers, and search engine queries. However, existing acronym disambiguation benchmarks and tools are limited to specific domains, and the size of prior benchmarks is rather small. To accelerate the research on acronym disambiguation, we construct a new benchmark named GLADIS with three components: (1) a much larger acronym dictionary with 1.5M acronyms and 6.4M long forms; (2) a pre-training corpus with 160 million sentences; (3) three datasets that cover the general, scientific, and biomedical domains. We then pre-train a language model, \emph{AcroBERT}, on our constructed corpus for general acronym disambiguation, and show the challenges and values of our new benchmark.
    
[^43]: TriNet：防止自监督学习在ASR中完全或缓慢崩溃的稳定方法

    TriNet: stabilizing self-supervised learning from complete or slow collapse on ASR. (arXiv:2301.00656v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2301.00656](http://arxiv.org/abs/2301.00656)

    本文提出的TriNet采用三分支结构，可防止自监督学习在ASR中的崩溃，并在下游ASR任务中比SOTA方法Data2vec实现了6.06%的相对单词错误率降低（WERR）。

    

    自监督学习模型面临着突然的信息崩溃或缓慢的维度崩溃的挑战。本文提出了TriNet，通过引入一种新颖的三分支结构来防止崩溃和稳定预训练。TriNet学习自监督学习的潜在嵌入空间，并将其并入到一个更高级别的空间中以预测由冻结的教师生成的虚假目标向量。实验结果显示，所提出的方法显著稳定和加速了预训练，并在下游基准ASR任务中相对于最先进的Data2vec实现了6.06％的相对单词错误率降低（WERR）。我们会在https://github.com/tencent-ailab/ 上发布我们的代码。

    Self-supervised learning (SSL) models confront challenges of abrupt informational collapse or slow dimensional collapse. We propose TriNet, which introduces a novel triple-branch architecture for preventing collapse and stabilizing the pre-training. TriNet learns the SSL latent embedding space and incorporates it to a higher level space for predicting pseudo target vectors generated by a frozen teacher. Our experimental results show that the proposed method notably stabilizes and accelerates pre-training and achieves a relative word error rate reduction (WERR) of 6.06% compared to the state-of-the-art (SOTA) Data2vec for a downstream benchmark ASR task. We will release our code at https://github.com/tencent-ailab/.
    
[^44]: 支付宝用户下一步意图预测的概念知识图谱

    A Concept Knowledge Graph for User Next Intent Prediction at Alipay. (arXiv:2301.00503v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.00503](http://arxiv.org/abs/2301.00503)

    本文提出了一种基于概念知识图谱的用户下一步意图预测技术，实现了在支付宝网络平台上对1亿活跃用户的服务，并且在保持可解释性的情况下，有效地提高了下游任务的性能表现。

    

    本文介绍了使用概念知识图谱进行用户下一步意图预测的技术。该系统已在支付宝网络平台上部署，为超过1亿活跃用户提供服务。我们提出AlipayKG，用于显式地描述用户意图的离线概念知识图谱，模拟了用户的历史行为、丰富的内容以及它们之间的关系。我们提出了一种基于Transformer的模型，将来自知识图谱的专家规则整合到模型中以推断在线用户的下一步意图。实验结果表明，所提出的系统可以有效地提高下游任务的性能，同时保持可解释性。

    This paper illustrates the technologies of user next intent prediction with a concept knowledge graph. The system has been deployed on the Web at Alipay, serving more than 100 million daily active users. To explicitly characterize user intent, we propose AlipayKG, which is an offline concept knowledge graph in the Life-Service domain modeling the historical behaviors of users, the rich content interacted by users and the relations between them. We further introduce a Transformer-based model which integrates expert rules from the knowledge graph to infer the online user's next intent. Experimental results demonstrate that the proposed system can effectively enhance the performance of the downstream tasks while retaining explainability.
    
[^45]: SuS-X：无需训练的基于名称的视觉语言模型迁移方法

    SuS-X: Training-Free Name-Only Transfer of Vision-Language Models. (arXiv:2211.16198v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.16198](http://arxiv.org/abs/2211.16198)

    本文提出了SuS-X，一种无需训练的基于名称的视觉语言模型迁移方法，具有较高的零样本分类能力。

    

    对比语言-图像预训练（CLIP）已成为训练大规模视觉语言模型的一种简单而有效的方法。尽管CLIP在多种下游任务的零样本分类和检索方面展示出卓越的性能，但要发挥其全部潜力，微调仍然是必要的。微调整个CLIP模型会消耗资源且不稳定。此外，最近的方法虽然旨在避免对下游任务进行微调，但仍需要访问目标分布中的图像。本文探索了另一种方法——无需训练的“仅基于名称迁移”的方法。我们提出了一种新颖的方法SuS-X，由两个关键构建块——SuS和TIP-X组成，既不需要密集的微调，也不需要昂贵的标记数据。SuS-X在19个基准数据集上实现了最先进的零样本分类结果。

    Contrastive Language-Image Pre-training (CLIP) has emerged as a simple yet effective way to train large-scale vision-language models. CLIP demonstrates impressive zero-shot classification and retrieval on diverse downstream tasks. However, to leverage its full potential, fine-tuning still appears to be necessary. Fine-tuning the entire CLIP model can be resource-intensive and unstable. Moreover, recent methods that aim to circumvent this need for fine-tuning still require access to images from the target distribution. In this paper, we pursue a different approach and explore the regime of training-free "name-only transfer" in which the only knowledge we possess about the downstream task comprises the names of downstream target categories. We propose a novel method, SuS-X, consisting of two key building blocks -- SuS and TIP-X, that requires neither intensive fine-tuning nor costly labelled data. SuS-X achieves state-of-the-art zero-shot classification results on 19 benchmark datasets. 
    
[^46]: 向导航即攻击者所愿？建立拜占庭鲁棒性的联邦学习体系下的代理人

    Navigation as Attackers Wish? Towards Building Byzantine-Robust Embodied Agents under Federated Learning. (arXiv:2211.14769v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.14769](http://arxiv.org/abs/2211.14769)

    本文研究了联邦学习体系下代理人学习中可能出现的攻击和防御策略，建立了全联邦拜占庭鲁棒的代理人学习模型。其中，导航即攻击者所愿（NAW）是一种简单而有效的攻击策略，而基于离群点检测的防御训练方法可以有效减轻NAW攻击的影响，提高代理人学习的全局鲁棒性。

    

    联邦化体系下的代理人学习通过在本地客户端（即不同环境）中保持数据来保护个人视觉环境的数据隐私。然而，在联邦学习下，由于本地数据对服务器是不可访问的，攻击者可能轻易地污染本地客户端的训练数据，从而在不被通知的情况下在代理人中建立后门。使用这样的代理人会对人类构成潜在危害，因为攻击者可以轻松地通过后门操纵代理人进行导航和控制。为了实现全联邦拜占庭鲁棒的代理人学习，在本文中，我们研究了视觉与语言导航（VLN）任务中的攻击和防御，其中代理人需要跟随自然语言指令来导航室内环境。首先，我们介绍了一种简单而有效的攻击策略，即导航即攻击者所愿（NAW），其中恶意客户端通过操纵本地轨迹数据来向全局模型植入后门。结果表明，NAW可以实现高攻击成功率，而且性能下降微不足道。为了防止NAW攻击，我们提出了一种防御训练方法，该方法利用离群点检测的概念来识别和删除恶意客户端。我们在VLN任务上的实验表明，所提出的防御方法可以有效地减轻NAW攻击的影响，提高联邦化体系下代理人学习的全局鲁棒性。

    Federated embodied agent learning protects the data privacy of individual visual environments by keeping data locally at each client (the individual environment) during training. However, since the local data is inaccessible to the server under federated learning, attackers may easily poison the training data of the local client to build a backdoor in the agent without notice. Deploying such an agent raises the risk of potential harm to humans, as the attackers may easily navigate and control the agent as they wish via the backdoor. Towards Byzantine-robust federated embodied agent learning, in this paper, we study the attack and defense for the task of vision-and-language navigation (VLN), where the agent is required to follow natural language instructions to navigate indoor environments. First, we introduce a simple but effective attack strategy, Navigation as Wish (NAW), in which the malicious client manipulates local trajectory data to implant a backdoor into the global model. Resu
    
[^47]: 活跃关系发现：通向通用和标签感知的开放关系抽取

    Active Relation Discovery: Towards General and Label-aware Open Relation Extraction. (arXiv:2211.04215v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.04215](http://arxiv.org/abs/2211.04215)

    本论文提出了一个活跃关系发现(ARD)框架，用于解决开放关系抽取中区分已知和新关系以及标记新关系类型的问题。实验证明，该框架在常规和更通用的设置上都显著优于以前的最先进方法。

    

    开放关系抽取(OpenRE)旨在发现开放领域的新关系。以前的OpenRE方法主要存在两个问题：(1)无法充分区分已知关系和新关系。当将常规测试设置扩展到更通用的设置时，其中测试数据可能也来自已知类别，现有方法的性能显著下降。(2)在实际应用之前必须进行二次标注。现有方法无法为新关系标记人类可读和有意义的类型，这是下游任务迫切需要的。为解决这些问题，我们提出了活跃关系发现(ARD)框架，它利用关系异常值检测来区分已知和新关系，并涉及主动学习用于标记新关系。对三个真实数据集的大量实验证明，ARD在常规和我们提出的更通用的设置上都显著优于以前的最先进方法。

    Open Relation Extraction (OpenRE) aims to discover novel relations from open domains. Previous OpenRE methods mainly suffer from two problems: (1) Insufficient capacity to discriminate between known and novel relations. When extending conventional test settings to a more general setting where test data might also come from seen classes, existing approaches have a significant performance decline. (2) Secondary labeling must be performed before practical application. Existing methods cannot label human-readable and meaningful types for novel relations, which is urgently required by the downstream tasks. To address these issues, we propose the Active Relation Discovery (ARD) framework, which utilizes relational outlier detection for discriminating known and novel relations and involves active learning for labeling novel relations. Extensive experiments on three real-world datasets show that ARD significantly outperforms previous state-of-the-art methods on both conventional and our propos
    
[^48]: 后缀检索增强语言建模

    Suffix Retrieval-Augmented Language Modeling. (arXiv:2211.03053v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.03053](http://arxiv.org/abs/2211.03053)

    提出一种后缀检索增强语言模型 (SUREALM)，该模型以自回归的方式模拟双向上下文效应。采用嵌入检索器,在序列生成过程中搜索具有相似单词历史的训练句子数据存储。在DSTC9口语对话语料库上的表现优于竞争基线。

    

    因果语言建模（LM）使用单词历史来预测下一个单词。相反，BERT利用句子中的双向单词信息来预测蒙面位置的单词。虽然BERT在序列编码方面很有效，但它本质上是非因果的，不适用于序列生成。在本文中，我们提出了一种新颖的语言模型，后缀检索增强语言模型（SUREALM），它以自回归的方式模拟双向上下文效应。SUREALM采用嵌入检索器，在序列生成过程中搜索具有相似单词历史的训练句子数据存储。特别是，检索到的句子的后缀部分模拟了“未来”上下文。我们在DSTC9口语对话语料库上评估了我们的模型，并显示了与竞争基线相比，在验证集和测试集上有良好的单词困惑度降低。

    Causal language modeling (LM) uses word history to predict the next word. BERT, on the other hand, makes use of bi-directional word information in a sentence to predict words at masked positions. While BERT is effective in sequence encoding, it is non-causal by nature and is not designed for sequence generation. In this paper, we propose a novel language model, SUffix REtrieval-Augmented LM (SUREALM), that simulates a bi-directional contextual effect in an autoregressive manner. SUREALM employs an embedding retriever to search for training sentences in a data store that share similar word history during sequence generation. In particular, the suffix portions of the retrieved sentences mimick the "future" context. We evaluated our proposed model on the DSTC9 spoken dialogue corpus and showed promising word perplexity reduction on the validation and test set compared to competitive baselines.
    
[^49]: 动态潜在感知器高效语音翻译技术

    Efficient Speech Translation with Dynamic Latent Perceivers. (arXiv:2210.16264v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.16264](http://arxiv.org/abs/2210.16264)

    本研究提出一种采用Perceiver编码器和Dynamic Latent Access(DLA)训练的语音翻译模型，该模型能够在MuST-C数据集的三种语言对上达到Transformer基线模型的性能水平，并且在推断时易于适应不同的计算预算，翻译质量没有显著下降。

    

    近年来，Transformer网络架构逐渐成为语音翻译领域的主流，实现了翻译质量的显著提升。但由于语音信号的长度较长，而Transformer的复杂度呈二次增长，因此为了使其适用于语音翻译，必须采用下采样策略。相反，本研究提出采用Perceiver编码器将语音输入映射到固定长度的潜在表征，从而简化了计算复杂度。此外，我们引入一种新的Perceiver训练方法Dynamic Latent Access(DLA)，通过解锁更大潜在空间而不增加计算负担。采用DLA的语音到文本Perceiver模型能够在MuST-C数据集的三种语言对上达到Transformer基线模型的性能水平。DLA训练的模型易于在推断时适应DLA，可以根据不同的计算预算灵活部署，翻译质量没有显著下降。

    Transformers have been the dominant architecture for Speech Translation in recent years, achieving significant improvements in translation quality. Since speech signals are longer than their textual counterparts, and due to the quadratic complexity of the Transformer, a down-sampling step is essential for its adoption in Speech Translation. Instead, in this research, we propose to ease the complexity by using a Perceiver encoder to map the speech inputs to a fixed-length latent representation. Furthermore, we introduce a novel way of training Perceivers, with Dynamic Latent Access (DLA), unlocking larger latent spaces without any additional computational overhead. Speech-to-Text Perceivers with DLA can match the performance of Transformer baselines across three language pairs in MuST-C. Finally, a DLA-trained model is easily adaptable to DLA at inference, and can be flexibly deployed with various computational budgets, without significant drops in translation quality.
    
[^50]: 语音计划中的神经抑制有助于对比性超发音

    Neural inhibition during speech planning contributes to contrastive hyperarticulation. (arXiv:2209.12278v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.12278](http://arxiv.org/abs/2209.12278)

    本文提出了一个动态神经场模型，解释了语音对齐时间的超发音现象。通过对单词的最小对手进行抑制，实现了对比性超发音。伪单词实验结果表明，超发音现象与实时语音计划和制作有关。与实际单词相比，伪单词中超发音现象的程度和范围有所降低，表明词汇和音位计划层之间的交互激活在超发音上起到了作用。

    

    先前的研究表明，单词在能够将它们与最小对手区分的语音维度上存在超发音现象。本文提出了一个动态神经场模型，用于解释这种对比性超发音现象。该模型通过对单词的最小对手的抑制作用，来实现语音对齐时间的超发音。我们进行了一项新的实验，研究了伪单词中的失音塞辅音语音对齐时间的对比性超发音。结果显示，在伪单词中存在对比性超发音现象，说明超发音现象与实时语音计划和制作有关。与实际单词中的超发音相比，伪单词中超发音现象的范围和程度有所降低，表明词汇和音位计划层之间的交互激活在超发音上起到了作用。我们讨论了我们的模型在统一从对比性超发音到音位邻域效应和语音痕迹效应等一些明显不同的现象中的潜力。

    Previous work has demonstrated that words are hyperarticulated on dimensions of speech that differentiate them from a minimal pair competitor. This phenomenon has been termed contrastive hyperarticulation (CH). We present a dynamic neural field (DNF) model of voice onset time (VOT) planning that derives CH from an inhibitory influence of the minimal pair competitor during planning. We test some predictions of the model with a novel experiment investigating CH of voiceless stop consonant VOT in pseudowords. The results demonstrate a CH effect in pseudowords, consistent with a basis for the effect in the real-time planning and production of speech. The scope and magnitude of CH in pseudowords was reduced compared to CH in real words, consistent with a role for interactive activation between lexical and phonological levels of planning. We discuss the potential of our model to unify an apparently disparate set of phenomena, from CH to phonological neighborhood effects to phonetic trace eff
    
[^51]: 词汇模式的序数分析

    Ordinal analysis of lexical patterns. (arXiv:2208.11175v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2208.11175](http://arxiv.org/abs/2208.11175)

    通过对11种主要语言的语料进行序数模式分析，发现不同的语言有着独特的模式结构分布，这些分布的波动可以确定文本的历史时期和作者，这强调了序数时间序列分析在语言学研究中的重要性。

    

    单词是连接思想和事物的基本语言单位，但单词不会单独出现在文本序列中。句法规则的存在导致邻近单词之间存在相关性。使用序数模式方法，我们对11种主要语言的词汇统计关系进行了分析。我们发现，语言利用各种不同方式来表达单词关系，产生了独特的模式结构分布。此外，对于给定语言的这些模式分布的波动，可以帮助我们确定文本撰写的历史时期和作者。综上所述，我们的结果强调序数时间序列分析在语言类型学、历史语言学和文体学中的相关性。

    Words are fundamental linguistic units that connect thoughts and things through meaning. However, words do not appear independently in a text sequence. The existence of syntactic rules induces correlations among neighboring words. Using an ordinal pattern approach, we present an analysis of lexical statistical connections for 11 major languages. We find that the diverse manners that languages utilize to express word relations give rise to unique pattern structural distributions. Furthermore, fluctuations of these pattern distributions for a given language can allow us to determine both the historical period when the text was written and its author. Taken together, our results emphasize the relevance of ordinal time series analysis in linguistic typology, historical linguistics and stylometry.
    
[^52]: 人类对于AI语言生成的启发式算法存在缺陷

    Human heuristics for AI-generated language are flawed. (arXiv:2206.07271v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2206.07271](http://arxiv.org/abs/2206.07271)

    人们很难辨别AI生成的语言形式，因为通常采用的判断启发式算法出现了一些缺陷，需要使用更为复杂的语言分析工具和教育来提高人们的判断力。

    

    人工智能生成的语言越来越多地与人类交流相互融合。在聊天、邮件和社交媒体中，AI系统建议单词、完成句子或产生整个对话。人们通常无法鉴别AI产生的语言，而将其视为人类编写的语言，这引发了有关新形式欺骗和操纵的担忧。本文研究了人类如何分辨AI生成的最为个人化和重要的语言形式之一——口头自我表述。在六个实验中，参与者（N=4,600）无法在专业、酒店以及约会情境中发现最先进的AI语言模型所生成的自我表述。语言特征的计算分析表明，人类对于AI生成的语言判断存在启发式算法的缺陷，例如将第一人称代词、缩略词使用或家庭话题与人类编写的语言联系在一起。我们实验证明了这些启发式算法无法准确识别AI生成的语言，建议使用更为复杂的语言分析工具和教育来改善人类的判断力。

    Human communication is increasingly intermixed with language generated by AI. Across chat, email, and social media, AI systems suggest words, complete sentences, or produce entire conversations. AI-generated language is often not identified as such but presented as language written by humans, raising concerns about novel forms of deception and manipulation. Here, we study how humans discern whether verbal self-presentations, one of the most personal and consequential forms of language, were generated by AI. In six experiments, participants (N = 4,600) were unable to detect self-presentations generated by state-of-the-art AI language models in professional, hospitality, and dating contexts. A computational analysis of language features shows that human judgments of AI-generated language are hindered by intuitive but flawed heuristics such as associating first-person pronouns, use of contractions, or family topics with human-written language. We experimentally demonstrate that these heur
    
[^53]: 基于门控层间协作改进CTC ASR 模型

    Improving CTC-based ASR Models with Gated Interlayer Collaboration. (arXiv:2205.12462v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.12462](http://arxiv.org/abs/2205.12462)

    本文提出了一种基于门控层间协作（GIC）机制来改进CTC-based模型性能的方法，在CTC-based模型中引入文本信息来提升模型性能，三个实验都表明该方法优于其他强基准。

    

    CTC-based ASR 模型在没有外部语言模型的情况下往往缺乏对条件依赖和文本交互的建模能力。本文提出了一种基于门控层间协作（GIC）机制来改进CTC-based模型性能的方法，将文本信息引入模型，从而放松CTC-based模型的条件独立假设。具体而言，我们将标记嵌入的加权和视为每个位置的文本表示，其中位置特定的权重是通过层间辅助CTC losses构建的softmax概率分布。然后，通过开发门控单元将文本表示与声学特征融合。在AISHELL-1，TEDLIUM2 和 AIDATATANG corpus 上的实验表明，所提出的方法优于几个强基准。

    The CTC-based automatic speech recognition (ASR) models without the external language model usually lack the capacity to model conditional dependencies and textual interactions. In this paper, we present a Gated Interlayer Collaboration (GIC) mechanism to improve the performance of CTC-based models, which introduces textual information into the model and thus relaxes the conditional independence assumption of CTC-based models. Specifically, we consider the weighted sum of token embeddings as the textual representation for each position, where the position-specific weights are the softmax probability distribution constructed via inter-layer auxiliary CTC losses. The textual representations are then fused with acoustic features by developing a gate unit. Experiments on AISHELL-1, TEDLIUM2, and AIDATATANG corpora show that the proposed method outperforms several strong baselines.
    
[^54]: Relphormer：关系图转换器用于知识图谱表示

    Relphormer: Relational Graph Transformer for Knowledge Graph Representations. (arXiv:2205.10852v5 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.10852](http://arxiv.org/abs/2205.10852)

    Relphormer是一种新的Transformer变体，用于知识图谱表示。它引入了Triple2Seq和增强式自我注意机制，以解决基本Transformer架构在捕捉知识图谱结构和语义信息方面的不足。

    

    Transformer已经在自然语言处理、计算机视觉和图形挖掘等广泛领域中取得了remarkable的性能。然而，基本的Transformer架构在知识图谱（KG）表示中并没有取得很好的改进，其中平移距离模型支配了这个领域。需注意的是，基本的Transformer架构难以捕捉到知识图谱的内在异构结构和语义信息。为此，我们提出了一种新的用于知识图谱表示的Transformer变体，名为Relphormer。具体来说，我们引入了Triple2Seq，可以动态地采样上下文化的子图序列作为输入，以缓解异构性问题。我们提出了一种新的增强式自我注意机制，用于对关系信息进行编码，并保持实体和关系内的语义信息。此外，我们利用掩蔽式知识建模来实现通用的知识图形表示。

    Transformers have achieved remarkable performance in widespread fields, including natural language processing, computer vision and graph mining. However, vanilla Transformer architectures have not yielded promising improvements in the Knowledge Graph (KG) representations, where the translational distance paradigm dominates this area. Note that vanilla Transformer architectures struggle to capture the intrinsically heterogeneous structural and semantic information of knowledge graphs. To this end, we propose a new variant of Transformer for knowledge graph representations dubbed Relphormer. Specifically, we introduce Triple2Seq which can dynamically sample contextualized sub-graph sequences as the input to alleviate the heterogeneity issue. We propose a novel structure-enhanced self-attention mechanism to encode the relational information and keep the semantic information within entities and relations. Moreover, we utilize masked knowledge modeling for general knowledge graph representa
    
[^55]: 从区分到生成：基于生成变换器的知识图谱补全

    From Discrimination to Generation: Knowledge Graph Completion with Generative Transformer. (arXiv:2202.02113v7 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2202.02113](http://arxiv.org/abs/2202.02113)

    本文介绍了一种将知识图谱补全转化为生成任务的方法，同时引入了关系引导演示和实体感知分层解码来实现更好的表示学习和快速推断。实验结果表明，这种方法具有比基线更好或相当的性能，并且比以往的方法更快。同时，作者还发布了一个新的大规模中文知识图谱数据集AliopenKG500。

    

    知识图谱补全解决了扩展缺失三元组的问题。本文提出了一种称作GenKGC的方法，将知识图谱补全转化为预训练语言模型的序列到序列生成任务。我们进一步引入了关系引导演示和实体感知分层解码，以实现更好的表示学习和快速推断。在三个数据集上的实验结果显示，我们的方法可以获得比基线更好或相当的性能，并与以前具有预训练语言模型的方法相比，实现更快的推断速度。我们还发布了一个新的大规模中文知识图谱数据集AliopenKG500，供研究目的使用。代码和数据集可在https://github.com/zjunlp/PromptKG/tree/main/GenKGC中获得。

    Knowledge graph completion aims to address the problem of extending a KG with missing triples. In this paper, we provide an approach GenKGC, which converts knowledge graph completion to sequence-to-sequence generation task with the pre-trained language model. We further introduce relation-guided demonstration and entity-aware hierarchical decoding for better representation learning and fast inference. Experimental results on three datasets show that our approach can obtain better or comparable performance than baselines and achieve faster inference speed compared with previous methods with pre-trained language models. We also release a new large-scale Chinese knowledge graph dataset AliopenKG500 for research purpose. Code and datasets are available in https://github.com/zjunlp/PromptKG/tree/main/GenKGC.
    
[^56]: 基于知识图谱增强网络的多视角表示学习用于方面情感分析

    Knowledge Graph Augmented Network Towards Multiview Representation Learning for Aspect-based Sentiment Analysis. (arXiv:2201.04831v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2201.04831](http://arxiv.org/abs/2201.04831)

    本文提出了一种名为KGAN的模型，通过知识图谱增强网络，将外部知识和上下文、句法信息相结合，从多个角度捕获情感特征，实现了多视角的表示学习。

    

    方面情感分析（ABSA）是情感分析的一项细粒度任务。为了更好地理解长句子并获取准确的方面特定信息，通常需要语言和常识知识。然而，大多数现有方法采用复杂和低效的方法来包含外部知识，例如直接搜索图形节点。此外，外部知识和语言信息之间的互补性还没有得到彻底研究。为此，我们提出了一种知识图增强网络KGAN，旨在有效地将外部知识与明确的句法和上下文信息相结合。特别地，KGAN从多个不同的角度捕获情感特征表示，即基于上下文、句法和知识的。首先，KGAN并行学习上下文和句法表示，以充分提取语义特征。然后，KGAN将外部知识与上下文和句法信息相融合。

    Aspect-based sentiment analysis (ABSA) is a fine-grained task of sentiment analysis. To better comprehend long complicated sentences and obtain accurate aspect-specific information, linguistic and commonsense knowledge are generally required in this task. However, most current methods employ complicated and inefficient approaches to incorporate external knowledge, e.g., directly searching the graph nodes. Additionally, the complementarity between external knowledge and linguistic information has not been thoroughly studied. To this end, we propose a knowledge graph augmented network KGAN, which aims to effectively incorporate external knowledge with explicitly syntactic and contextual information. In particular, KGAN captures the sentiment feature representations from multiple different perspectives, i.e., context-, syntaxand knowledge-based. First, KGAN learns the contextual and syntactic representations in parallel to fully extract the semantic features. Then, KGAN integrates the k
    
[^57]: DECAR: 基于深度聚类的通用音频表示学习方法

    DECAR: Deep Clustering for learning general-purpose Audio Representations. (arXiv:2110.08895v4 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2110.08895](http://arxiv.org/abs/2110.08895)

    本文提出了一种基于深度聚类的自监督方法DECAR，用于学习通用的音频表示。该方法建立在先前自学习算法的基础之上，利用离线聚类的伪标签来解决预测任务，并在大规模Audioset数据集的平衡子集上进行了验证。

    

    本文提出了DECAR，一种自监督的音频通用表示预训练方法。我们的系统基于聚类，利用离线聚类步骤提供目标标签，作为伪标签来解决预测任务。我们在计算机视觉领域的自监督学习的最新进展基础上，设计了一个轻量级、易于使用的自监督预训练方案。我们在大规模Audioset数据集的平衡子集上预训练DECAR嵌入，并将这些表示传递到9个下游分类任务，包括语音、音乐、动物声音和声学场景。此外，我们进行了消融研究，并公开了所有代码和预训练模型。

    We introduce DECAR, a self-supervised pre-training approach for learning general-purpose audio representations. Our system is based on clustering: it utilizes an offline clustering step to provide target labels that act as pseudo-labels for solving a prediction task. We develop on top of recent advances in self-supervised learning for computer vision and design a lightweight, easy-to-use self-supervised pre-training scheme. We pre-train DECAR embeddings on a balanced subset of the large-scale Audioset dataset and transfer those representations to 9 downstream classification tasks, including speech, music, animal sounds, and acoustic scenes. Furthermore, we conduct ablation studies identifying key design choices and also make all our code and pre-trained models publicly available.
    
[^58]: 预训练语言模型也是符号数学求解器！

    Pretrained Language Models are Symbolic Mathematics Solvers too!. (arXiv:2110.03501v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2110.03501](http://arxiv.org/abs/2110.03501)

    本文研究表明，大规模语言模型可以训练为序列到序列任务，解决复杂的数学方程。文章提出了一种预训练并微调Transformer模型解决符号数学任务的方法，使用的训练样本比当前深度学习技术少1.5个数量级，且在积分任务上达到了可比较的准确性。

    

    解决符号数学问题一直是需要组合推理和重复的人类创造力的领域。但是，最近的研究表明，诸如transformer之类的大规模语言模型是通用的，并且令人惊讶的是，它们可以被训练为用于解决复杂的数学方程的序列到序列任务。这些大型Transformer模型需要极其庞大的训练数据才能泛化到未见过的符号数学问题。在本文中，我们提出一种样本有效的方式来解决符号任务，首先通过语言翻译对Transformer模型进行预训练，然后微调预训练的Transformer模型以解决符号数学的下游任务。我们在积分任务上使用了大约1.5个数量级的训练样本，达到了与预先训练模型相当的准确性，而与针对符号数学的深度学习的最新技术相比使用了较少的训练样本。微分方程的测试准确性为...

    Solving symbolic mathematics has always been of in the arena of human ingenuity that needs compositional reasoning and recurrence. However, recent studies have shown that large-scale language models such as transformers are universal and surprisingly can be trained as a sequence-to-sequence task to solve complex mathematical equations. These large transformer models need humongous amounts of training data to generalize to unseen symbolic mathematics problems. In this paper, we present a sample efficient way of solving the symbolic tasks by first pretraining the transformer model with language translation and then fine-tuning the pretrained transformer model to solve the downstream task of symbolic mathematics. We achieve comparable accuracy on the integration task with our pretrained model while using around $1.5$ orders of magnitude less number of training samples with respect to the state-of-the-art deep learning for symbolic mathematics. The test accuracy on differential equation ta
    
[^59]: 思路流网络：从单一预测到模型思路的串联

    Thought Flow Nets: From Single Predictions to Trains of Model Thought. (arXiv:2107.12220v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2107.12220](http://arxiv.org/abs/2107.12220)

    本文探讨了给模型第二次、第三次甚至第k次思考机会的思路流网络，其利用自我校正机制和梯度更新能够纠正自身预测，该方法可显著提高模型性能。

    

    当人类解决复杂问题时，通常会创建一系列思路（涉及直觉决策、反思、错误更正等）以达成决定。但是，如今的模型大多被训练为将输入映射到单一且固定的输出。本文研究了如何让模型有第二、第三和第 k 次思考的机会。我们从黑格尔的辩证法中获得灵感，提出了思路流的概念，创建了一系列预测。我们提出了一个自我校正机制，它被训练用于估计模型的正确性，并基于正确性预测的梯度执行迭代预测更新。我们以问答为例介绍了我们的方法，并进行了广泛的实验，证明了（i）我们的方法能够纠正自己的预测，（ii）它能够显著提高模型的性能。此外，我们对思路流的语义校验进行了定性分析。

    When humans solve complex problems, they typically create a sequence of ideas (involving an intuitive decision, reflection, error correction, etc.) in order to reach a conclusive decision. Contrary to this, today's models are mostly trained to map an input to one single and fixed output. In this paper, we investigate how we can give models the opportunity of a second, third and $k$-th thought. Taking inspiration from Hegel's dialectics, we propose the concept of a thought flow which creates a sequence of predictions. We present a self-correction mechanism that is trained to estimate the model's correctness and performs iterative prediction updates based on the correctness prediction's gradient. We introduce our method at the example of question answering and conduct extensive experiments that demonstrate (i) our method's ability to correct its own predictions and (ii) its potential to notably improve model performances. In addition, we conduct a qualitative analysis of thought flow cor
    
[^60]: 理解基于层感知序列编码器的表示为多阶图的模型

    To Understand Representation of Layer-aware Sequence Encoders as Multi-order-graph. (arXiv:2101.06397v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2101.06397](http://arxiv.org/abs/2101.06397)

    本文提出了一种解释基于自我注意力网络的序列编码器表示的方式，将其视为多阶图结构，并提出了一种名为多阶图的模型来描述这些图结构，并将SAN模型的编码转换为MoG的生成。此外，还引入了一个名为Graph-Transformer的模型来增强捕获多个不同阶级的子图的能力，并关注高阶子图，从而进一步提高了模型的表现。

    

    本文提出了一种自我注意力网络（SAN）序列编码器表示的解释方式，将模型捕获的信息和模型的编码分别视为图结构和这些图结构的生成。该解释适用于现有的基于SAN的模型，并可以解释捕获结构或语言信息的能力、模型深度和句子长度之间的关系，并且可以扩展到其他模型，如基于递归神经网络的模型。

    In this paper, we propose an explanation of representation for self-attention network (SAN) based neural sequence encoders, which regards the information captured by the model and the encoding of the model as graph structure and the generation of these graph structures respectively. The proposed explanation applies to existing works on SAN-based models and can explain the relationship among the ability to capture the structural or linguistic information, depth of model, and length of sentence, and can also be extended to other models such as recurrent neural network based models. We also propose a revisited multigraph called Multi-order-Graph (MoG) based on our explanation to model the graph structures in the SAN-based model as subgraphs in MoG and convert the encoding of SAN-based model to the generation of MoG. Based on our explanation, we further introduce a Graph-Transformer by enhancing the ability to capture multiple subgraphs of different orders and focusing on subgraphs of high
    

