# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis.](http://arxiv.org/abs/2310.10477) | 该论文介绍了一种基于错误分析的对齐策略，通过暴露大型语言模型的错误输出并进行评估，以理解内部原因。通过这种方法，有毒回应可以转化为模型对齐的指导调谐语料，从而提高模型的安全性并训练其进行自我批评。 |
| [^2] | [Can We Edit Multimodal Large Language Models?.](http://arxiv.org/abs/2310.08475) | 本文提出了编辑多模式大型语言模型（MLLMs）的挑战，并构建了一个新的基准用于评估和比较不同编辑方法的效果。实验结果表明，编辑多模式LLMs仍然存在困难，但这项工作为NLP社区提供了宝贵的见解。 |
| [^3] | [Augmenting conformers with structured state space models for online speech recognition.](http://arxiv.org/abs/2309.08551) | 本文研究通过将结构化状态空间序列模型（S4）与卷积相结合，增强在线语音识别的神经编码器，并在Librispeech的测试集上取得了较低的识别错误率。 |
| [^4] | [PromptTTS++: Controlling Speaker Identity in Prompt-Based Text-to-Speech Using Natural Language Descriptions.](http://arxiv.org/abs/2309.08140) | PromptTTS++是一种基于提示的文本转语音系统，可以使用自然语言描述控制说话者身份。与现有研究不同，该方法利用说话者提示来学习自然语言描述与声学特征的映射。 |
| [^5] | [CoLLD: Contrastive Layer-to-layer Distillation for Compressing Multilingual Pre-trained Speech Encoders.](http://arxiv.org/abs/2309.07707) | CoLLD是一种用于压缩预训练语音编码器的对比层与层蒸馏方法，通过学生模型复制大教师模型的行为来提高性能，并在多语种任务中取得了优异表现。 |
| [^6] | [Improving Code Generation by Dynamic Temperature Sampling.](http://arxiv.org/abs/2309.02772) | 通过动态温度采样的AdapT方法，我们提出了一种针对代码生成的新的解码策略，通过调整温度系数来解决难以预测的代码标记，并取得了显著效果。 |
| [^7] | [Audio Generation with Multiple Conditional Diffusion Model.](http://arxiv.org/abs/2308.11940) | 本论文提出了一种使用多条件扩散模型进行音频生成的方法。通过引入内容和风格等额外条件，增强了现有模型的可控性。这种方法可以精确控制生成音频的时间顺序、音高和能量。由于缺乏合适的数据集和评估指标，作者整合了现有数据集并进行了实验验证。 |
| [^8] | [Zhongjing: Enhancing the Chinese Medical Capabilities of Large Language Model through Expert Feedback and Real-world Multi-turn Dialogue.](http://arxiv.org/abs/2308.03549) | 本研究介绍了中精，这是一种基于LLaMA的中文医学LLM，通过整个训练流程，并结合人类反馈，以及引入一个中文多轮医学对话数据集CMtMedQA，大大提升了模型在复杂对话和主动询问发起方面的能力。 |
| [^9] | [EnrichEvent: Enriching Social Data with Contextual Information for Emerging Event Extraction.](http://arxiv.org/abs/2307.16082) | 本文提出了一个利用词汇、语义和上下文表示的框架，旨在解决现有事件检测方法在识别新兴社交事件方面的局限性，并提供了对社交数据进行丰富的上下文化处理的方法。 |
| [^10] | [A Comprehensive Overview of Large Language Models.](http://arxiv.org/abs/2307.06435) | 大语言模型的综合概述，分析了各种新的架构和训练策略，讨论了LLM的特点和功能，并总结了重要的研究发现和关键的架构和训练策略。 |
| [^11] | [Is ChatGPT a Good Personality Recognizer? A Preliminary Study.](http://arxiv.org/abs/2307.03952) | 这篇论文进行了初步评估，探索了ChatGPT在文本中识别人格的能力，特别是通过面向层级的提示策略。论文比较了ChatGPT和传统神经网络、RoBERTa在两个实际数据集上的表现。 |
| [^12] | [Active Sparse Conversations for Improved Audio-Visual Embodied Navigation.](http://arxiv.org/abs/2306.04047) | 本文提出了CAVEN - 一种具有对话功能的音频视觉导航代理，能够向人类/神谕提出导航问题并处理神谕回答以协助自主导航。该系统基于多模态分层强化学习方法，并使用三个低级策略进行引导。 |
| [^13] | [ChatGPT an ENFJ, Bard an ISTJ: Empirical Study on Personalities of Large Language Models.](http://arxiv.org/abs/2305.19926) | 本研究通过采用特质理论框架，实验证明了ChatGPT始终表现出ENFJ型人格，无论指令或情境如何。研究揭示了LLMs的个性化，有助于促进人与机器之间更好的沟通和协作。 |
| [^14] | [What indeed can GPT models do in chemistry? A comprehensive benchmark on eight tasks.](http://arxiv.org/abs/2305.18365) | 本文建立了包括 8 个实际化学任务的综合基准测试，有力地证明了 LLM 在实际化学中的能力。 |
| [^15] | [A Survey on Out-of-Distribution Detection in NLP.](http://arxiv.org/abs/2305.03236) | 这篇论文首次综述了最新的OOD检测方法在自然语言处理中的应用。根据算法使用的数据，将方法分成三类，并介绍了相关数据集、应用和度量方法。 |
| [^16] | [Identification of Negative Transfers in Multitask Learning Using Surrogate Models.](http://arxiv.org/abs/2303.14582) | 本文提出了一种通过代理建模来解决多任务学习中负迁移问题的方法，能够识别哪些源任务的子集会对目标任务有帮助。 |
| [^17] | [Editing Language Model-based Knowledge Graph Embeddings.](http://arxiv.org/abs/2301.10405) | 本文提出了一种新的任务——编辑基于语言模型的知识图谱嵌入，旨在实现对KG嵌入的数据高效和快速更新。针对这一任务，提出了一个简单而强大的方案——KGEditor，可以更好地更新特定事实而不影响其余部分的性能。 |

# 详细

[^1]: 从挫折中获得智慧：通过错误分析对齐大型语言模型

    Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis. (arXiv:2310.10477v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.10477](http://arxiv.org/abs/2310.10477)

    该论文介绍了一种基于错误分析的对齐策略，通过暴露大型语言模型的错误输出并进行评估，以理解内部原因。通过这种方法，有毒回应可以转化为模型对齐的指导调谐语料，从而提高模型的安全性并训练其进行自我批评。

    

    大型语言模型（LLMs）的快速发展既带来了机遇，也带来了挑战，特别是在意外生成有害和有毒回应方面。传统的对齐方法致力于引导LLMs朝着期望的性能发展并保护它们免受恶意内容的侵害，而本研究提出了一种基于错误分析的全新对齐策略，通过有意暴露LLMs的缺陷输出并进行深入评估，以完全理解内部原因，通过自然语言分析。因此，有毒回应可以转化为模型对齐的指导调谐语料，LLMs不仅可以避免生成有缺陷的回应，还可以训练其进行自我批评，发挥其辨别有毒内容的内在能力。实验结果表明，所提出的方法在安全指令遵循方面优于传统的对齐技术，同时还保持了卓越的效率。

    The rapid advancement of large language models (LLMs) presents both opportunities and challenges, particularly concerning unintentional generation of harmful and toxic responses. While the traditional alignment methods strive to steer LLMs towards desired performance and shield them from malicious content, this study proposes a novel alignment strategy rooted in mistake analysis by exposing LLMs to flawed outputs purposefully and then conducting a thorough assessment to fully comprehend internal reasons via natural language analysis. Thus, toxic responses can be transformed into instruction tuning corpus for model alignment, and LLMs can not only be deterred from generating flawed responses but also trained to self-criticize, leveraging its innate ability to discriminate toxic content. Experimental results demonstrate that the proposed method outperforms conventional alignment techniques for safety instruction following, while maintaining superior efficiency.
    
[^2]: 我们能编辑多模式大型语言模型吗？

    Can We Edit Multimodal Large Language Models?. (arXiv:2310.08475v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.08475](http://arxiv.org/abs/2310.08475)

    本文提出了编辑多模式大型语言模型（MLLMs）的挑战，并构建了一个新的基准用于评估和比较不同编辑方法的效果。实验结果表明，编辑多模式LLMs仍然存在困难，但这项工作为NLP社区提供了宝贵的见解。

    

    本文关注编辑多模式大型语言模型（MLLMs）。与编辑单模式LLMs相比，多模式模型的编辑更具挑战性，需要更高级别的审查和慎重考虑。为了促进这一领域的研究，我们构建了一个新的基准，称为MMEdit，用于编辑多模式LLMs，并建立了一套创新的度量标准进行评估。我们进行了包括各种模型编辑基线的综合实验，并分析了编辑多模式LLMs的不同组件的影响。根据经验，我们发现之前的基线在某种程度上可以实现编辑多模式LLMs，但效果仍然不理想，表明这个任务可能存在的困难。我们希望我们的工作能为NLP社区提供见解。代码和数据集可在https://github.com/zjunlp/EasyEdit获取。

    In this paper, we focus on editing Multimodal Large Language Models (MLLMs). Compared to editing single-modal LLMs, multimodal model editing is more challenging, which demands a higher level of scrutiny and careful consideration in the editing process. To facilitate research in this area, we construct a new benchmark, dubbed MMEdit, for editing multimodal LLMs and establishing a suite of innovative metrics for evaluation. We conduct comprehensive experiments involving various model editing baselines and analyze the impact of editing different components for multimodal LLMs. Empirically, we notice that previous baselines can implement editing multimodal LLMs to some extent, but the effect is still barely satisfactory, indicating the potential difficulty of this task. We hope that our work can provide the NLP community with insights. Code and dataset are available in https://github.com/zjunlp/EasyEdit.
    
[^3]: 在线语音识别中结构化状态空间模型增强构型

    Augmenting conformers with structured state space models for online speech recognition. (arXiv:2309.08551v1 [cs.CL])

    [http://arxiv.org/abs/2309.08551](http://arxiv.org/abs/2309.08551)

    本文研究通过将结构化状态空间序列模型（S4）与卷积相结合，增强在线语音识别的神经编码器，并在Librispeech的测试集上取得了较低的识别错误率。

    

    在线语音识别是一种重要且具有挑战性的ASR系统应用场景，其中模型只能访问左侧上下文。本文研究通过结合结构化状态空间序列模型（S4）增强在线ASR的神经编码器，S4是一类提供了访问任意长左侧上下文的参数高效方式的模型。我们进行了系统的消融实验，比较了S4模型的各个变种，并提出了两种将其与卷积相结合的新方法。我们发现，最有效的设计是使用具有实值循环权重的小型S4模型与本地卷积相叠加，使它们可以互补地工作。我们的最佳模型在来自Librispeech的测试集上取得了4.01%/8.53%的WER，优于经过详细调优的Conformers。

    Online speech recognition, where the model only accesses context to the left, is an important and challenging use case for ASR systems. In this work, we investigate augmenting neural encoders for online ASR by incorporating structured state-space sequence models (S4), which are a family of models that provide a parameter-efficient way of accessing arbitrarily long left context. We perform systematic ablation studies to compare variants of S4 models and propose two novel approaches that combine them with convolutions. We find that the most effective design is to stack a small S4 using real-valued recurrent weights with a local convolution, allowing them to work complementarily. Our best model achieves WERs of 4.01%/8.53% on test sets from Librispeech, outperforming Conformers with extensively tuned convolution.
    
[^4]: PromptTTS++：使用自然语言描述控制提示式文本转语音中的说话者身份

    PromptTTS++: Controlling Speaker Identity in Prompt-Based Text-to-Speech Using Natural Language Descriptions. (arXiv:2309.08140v1 [eess.AS])

    [http://arxiv.org/abs/2309.08140](http://arxiv.org/abs/2309.08140)

    PromptTTS++是一种基于提示的文本转语音系统，可以使用自然语言描述控制说话者身份。与现有研究不同，该方法利用说话者提示来学习自然语言描述与声学特征的映射。

    

    我们提出了PromptTTS++，一种基于提示的文本转语音（TTS）合成系统，它允许使用自然语言描述来控制说话者身份。为了在基于提示的TTS框架中控制说话者身份，我们引入了说话者提示的概念，该提示描述了语音特征（如中性、年轻、老年和沉闷），旨在与说话风格大致独立。由于目前没有包含说话者提示的大规模数据集，我们首先使用LibriTTS-R语料库构建了一个基于手动注释的说话者提示数据集。然后，我们采用基于扩散的声学模型与混合密度网络来建模训练数据中的多样化说话者因素。与之前仅依赖样式提示的研究不同，样式提示仅描述了说话者个性化的有限方面，如音调、说话速度和能量，我们的方法利用额外的说话者提示来有效地学习从自然语言描述到声学特征的映射。

    We propose PromptTTS++, a prompt-based text-to-speech (TTS) synthesis system that allows control over speaker identity using natural language descriptions. To control speaker identity within the prompt-based TTS framework, we introduce the concept of speaker prompt, which describes voice characteristics (e.g., gender-neutral, young, old, and muffled) designed to be approximately independent of speaking style. Since there is no large-scale dataset containing speaker prompts, we first construct a dataset based on the LibriTTS-R corpus with manually annotated speaker prompts. We then employ a diffusion-based acoustic model with mixture density networks to model diverse speaker factors in the training data. Unlike previous studies that rely on style prompts describing only a limited aspect of speaker individuality, such as pitch, speaking speed, and energy, our method utilizes an additional speaker prompt to effectively learn the mapping from natural language descriptions to the acoustic f
    
[^5]: CoLLD: 对多语种预训练语音编码器的对比层与层蒸馏进行压缩

    CoLLD: Contrastive Layer-to-layer Distillation for Compressing Multilingual Pre-trained Speech Encoders. (arXiv:2309.07707v1 [cs.CL])

    [http://arxiv.org/abs/2309.07707](http://arxiv.org/abs/2309.07707)

    CoLLD是一种用于压缩预训练语音编码器的对比层与层蒸馏方法，通过学生模型复制大教师模型的行为来提高性能，并在多语种任务中取得了优异表现。

    

    大规模自监督预训练语音编码器在语音识别和翻译任务中表现优于传统方法。由于开发这些大模型的成本较高，为新任务构建新编码器并将其部署到设备应用中是不可行的。先前的研究提出了模型压缩方法来解决这个问题，但这些方法仅针对较小模型和不太实际的任务。因此，我们提出了对比层与层蒸馏（CoLLD），一种新颖的知识蒸馏方法，通过利用掩蔽预测和对比学习，训练学生模型复制大教师模型的行为来压缩预训练语音编码器。CoLLD在多语种语音到文本翻译和识别基准上胜过先前的方法，弥合了小模型和大模型之间的差距。

    Large-scale self-supervised pre-trained speech encoders outperform conventional approaches in speech recognition and translation tasks. Due to the high cost of developing these large models, building new encoders for new tasks and deploying them to on-device applications are infeasible. Prior studies propose model compression methods to address this issue, but those works focus on smaller models and less realistic tasks. Thus, we propose Contrastive Layer-to-layer Distillation (CoLLD), a novel knowledge distillation method to compress pre-trained speech encoders by leveraging masked prediction and contrastive learning to train student models to copy the behavior of a large teacher model. CoLLD outperforms prior methods and closes the gap between small and large models on multilingual speech-to-text translation and recognition benchmarks.
    
[^6]: 通过动态温度采样改进代码生成

    Improving Code Generation by Dynamic Temperature Sampling. (arXiv:2309.02772v1 [cs.SE])

    [http://arxiv.org/abs/2309.02772](http://arxiv.org/abs/2309.02772)

    通过动态温度采样的AdapT方法，我们提出了一种针对代码生成的新的解码策略，通过调整温度系数来解决难以预测的代码标记，并取得了显著效果。

    

    最近，大型语言模型（LLM）在代码生成方面取得了令人印象深刻的结果。然而，现有的解码策略是针对自然语言生成设计的，忽视了自然语言和编程语言之间的差异。由于这个疏忽，如何设计更好的代码生成解码策略仍然是一个未解决的问题。在本文中，我们进行了第一次系统研究，探索了一种专门用于代码生成的解码策略。通过对代码标记丢失分布的分析，我们发现代码标记可以分为两类：难以预测的挑战性标记和易于推断的自信标记。其中，挑战性标记主要出现在代码块的开头。受到上述发现的启发，我们提出了一种简单而有效的方法：自适应温度（AdapT）采样，它在解码不同的标记时动态调整温度系数。我们在采样挑战性标记时应用较大的温度值。同时，在采样自信标记时应用较小的温度值。

    Recently, Large Language Models (LLMs) have shown impressive results in code generation. However, existing decoding strategies are designed for Natural Language (NL) generation, overlooking the differences between NL and programming languages (PL). Due to this oversight, a better decoding strategy for code generation remains an open question. In this paper, we conduct the first systematic study to explore a decoding strategy specialized in code generation. With an analysis of loss distributions of code tokens, we find that code tokens can be divided into two categories: challenging tokens that are difficult to predict and confident tokens that can be easily inferred. Among them, the challenging tokens mainly appear at the beginning of a code block. Inspired by the above findings, we propose a simple yet effective method: Adaptive Temperature (AdapT) sampling, which dynamically adjusts the temperature coefficient when decoding different tokens. We apply a larger temperature when samplin
    
[^7]: 使用多条件扩散模型进行音频生成

    Audio Generation with Multiple Conditional Diffusion Model. (arXiv:2308.11940v1 [cs.SD])

    [http://arxiv.org/abs/2308.11940](http://arxiv.org/abs/2308.11940)

    本论文提出了一种使用多条件扩散模型进行音频生成的方法。通过引入内容和风格等额外条件，增强了现有模型的可控性。这种方法可以精确控制生成音频的时间顺序、音高和能量。由于缺乏合适的数据集和评估指标，作者整合了现有数据集并进行了实验验证。

    

    基于文本的音频生成模型有其局限性，因为它们无法包含音频中的所有信息，仅依靠文本会导致受控性受限。为了解决这个问题，我们提出了一种新颖的模型，通过引入额外的条件（包括内容（时间戳）和风格（音高曲线和能量曲线））作为文本的补充，增强了现有预训练文本到音频模型的可控性。这种方法实现了对生成音频的时间顺序、音高和能量的精细控制。为了保持生成的多样性，我们使用一个可训练的控制条件编码器，该编码器由一个大型语言模型增强，并使用一个可训练的融合网络来编码和融合额外的条件，同时保持预训练文本到音频模型的权重不变。由于缺乏合适的数据集和评估指标，我们将现有数据集整合为一个新的数据集，包括音频和相应的条件，并使用一个可训练的控制条件编码器，该编码器由一个大型语言模型增强，并使用一个可训练的融合网络来编码和融合额外的条件，同时保持预训练文本到音频模型的权重不变。

    Text-based audio generation models have limitations as they cannot encompass all the information in audio, leading to restricted controllability when relying solely on text. To address this issue, we propose a novel model that enhances the controllability of existing pre-trained text-to-audio models by incorporating additional conditions including content (timestamp) and style (pitch contour and energy contour) as supplements to the text. This approach achieves fine-grained control over the temporal order, pitch, and energy of generated audio. To preserve the diversity of generation, we employ a trainable control condition encoder that is enhanced by a large language model and a trainable Fusion-Net to encode and fuse the additional conditions while keeping the weights of the pre-trained text-to-audio model frozen. Due to the lack of suitable datasets and evaluation metrics, we consolidate existing datasets into a new dataset comprising the audio and corresponding conditions and use a 
    
[^8]: Zhongjing: 通过专家反馈和真实的多轮对话增强大型语言模型的中医能力

    Zhongjing: Enhancing the Chinese Medical Capabilities of Large Language Model through Expert Feedback and Real-world Multi-turn Dialogue. (arXiv:2308.03549v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.03549](http://arxiv.org/abs/2308.03549)

    本研究介绍了中精，这是一种基于LLaMA的中文医学LLM，通过整个训练流程，并结合人类反馈，以及引入一个中文多轮医学对话数据集CMtMedQA，大大提升了模型在复杂对话和主动询问发起方面的能力。

    

    最近大型语言模型（LLM）的进展在理解和回应用户意图方面取得了显著突破。然而，在某些专业领域（如中医学）中，它们在常规使用中的表现仍然落后。目前将中医纳入LLM的方法主要依赖于使用单轮和精简对话数据进行监督微调（SFT）。这些模型缺乏医生一样的主动询问和多轮理解的能力，并且不能始终与专家的安全和专业性对齐回复。本研究中，我们介绍了中医基于LLaMA的中文医学LLM——中精，它实现了从预训练到强化学习的整个训练流程，并利用人类反馈（RLHF）。此外，我们还介绍了一个包含70,000个真实医患对话的中文多轮医学对话数据集CMtMedQA，它极大地增强了模型在复杂对话和主动询问发起方面的能力。

    Recent advances in Large Language Models (LLMs) have achieved remarkable breakthroughs in understanding and responding to user intents. However, their performance lag behind general use cases in some expertise domains, such as Chinese medicine. Existing efforts to incorporate Chinese medicine into LLMs rely on Supervised Fine-Tuning (SFT) with single-turn and distilled dialogue data. These models lack the ability for doctor-like proactive inquiry and multi-turn comprehension and cannot always align responses with safety and professionalism experts. In this work, we introduce Zhongjing, the first Chinese medical LLaMA-based LLM that implements an entire training pipeline from pre-training to reinforcement learning with human feedback (RLHF). Additionally, we introduce a Chinese multi-turn medical dialogue dataset of 70,000 authentic doctor-patient dialogues, CMtMedQA, which significantly enhances the model's capability for complex dialogue and proactive inquiry initiation. We define a r
    
[^9]: EnrichEvent: 使用上下文信息为新出现的事件提供丰富的社交数据

    EnrichEvent: Enriching Social Data with Contextual Information for Emerging Event Extraction. (arXiv:2307.16082v1 [cs.CL])

    [http://arxiv.org/abs/2307.16082](http://arxiv.org/abs/2307.16082)

    本文提出了一个利用词汇、语义和上下文表示的框架，旨在解决现有事件检测方法在识别新兴社交事件方面的局限性，并提供了对社交数据进行丰富的上下文化处理的方法。

    

    社交平台已成为传播和讨论真实事件信息的关键平台，为及早发现有新闻价值的事件提供了良好的机会。然而，现有的大多数事件检测方法仅利用关键词突发性或网络结构来检测热点事件。因此，对于事件和社交数据的复杂性而言，它们往往无法在达到趋势状态之前识别出新出现的社交事件。社交数据，例如推文，具有拼写错误、不完整性、歧义性和语言不规范性，以及意见方面的变化。此外，利用有限的上下文知识来学习事件的演变特征对于机器学习模型几乎是不可行的。为了解决这些问题，本文提出了一个利用流式社交数据的词汇、语义和上下文表示的框架。

    Social platforms have emerged as a crucial platform for disseminating and discussing information about real-life events, which offers an excellent opportunity for early detection of newsworthy events. However, most existing approaches for event detection solely exploit keyword burstiness or network structures to detect hot events. Thus, they often fail to identify emerging social events before reaching a trending state regarding the challenging nature of events and social data. Social data, e.g., tweets, is characterized by misspellings, incompleteness, ambiguity, and irregular language, as well as variation in aspects of opinions. Moreover, learning the evolving characteristics of the events utilizing limited contextual knowledge is almost infeasible for machine learning models. To address these problems, in this paper, we propose a framework that exploits the lexical, semantic, and contextual representations of streaming social data. In particular, we leverage contextual knowledge to
    
[^10]: 大语言模型的综合概述

    A Comprehensive Overview of Large Language Models. (arXiv:2307.06435v1 [cs.CL])

    [http://arxiv.org/abs/2307.06435](http://arxiv.org/abs/2307.06435)

    大语言模型的综合概述，分析了各种新的架构和训练策略，讨论了LLM的特点和功能，并总结了重要的研究发现和关键的架构和训练策略。

    

    大语言模型（LLM）展示了出色的泛化能力，导致了众多模型的发展。这些模型提出了各种新的架构，通过改进的训练策略来调整现有的架构，增加上下文长度，使用高质量的训练数据，并增加训练时间以超越基线。分析新的发展对于识别增强训练稳定性和改进LLM泛化能力的变化至关重要。本综述论文全面分析了LLM的架构及其分类、训练策略、训练数据集和性能评估，并讨论未来的研究方向。此外，本文还讨论了LLM的基本构建块和概念，并提供了LLM的完整概述，包括其重要特点和功能。最后，本文总结了LLM研究的重要发现，并整合了关键的架构和训练策略。

    Large Language Models (LLMs) have shown excellent generalization capabilities that have led to the development of numerous models. These models propose various new architectures, tweaking existing architectures with refined training strategies, increasing context length, using high-quality training data, and increasing training time to outperform baselines. Analyzing new developments is crucial for identifying changes that enhance training stability and improve generalization in LLMs. This survey paper comprehensively analyses the LLMs architectures and their categorization, training strategies, training datasets, and performance evaluations and discusses future research directions. Moreover, the paper also discusses the basic building blocks and concepts behind LLMs, followed by a complete overview of LLMs, including their important features and functions. Finally, the paper summarizes significant findings from LLM research and consolidates essential architectural and training strateg
    
[^11]: ChatGPT是一个好的人格识别器吗？初步研究。

    Is ChatGPT a Good Personality Recognizer? A Preliminary Study. (arXiv:2307.03952v1 [cs.CL])

    [http://arxiv.org/abs/2307.03952](http://arxiv.org/abs/2307.03952)

    这篇论文进行了初步评估，探索了ChatGPT在文本中识别人格的能力，特别是通过面向层级的提示策略。论文比较了ChatGPT和传统神经网络、RoBERTa在两个实际数据集上的表现。

    

    近年来，人格被视为一种有价值的个人因素，被纳入了许多任务，如情感分析和产品推荐。这导致了对基于文本的人格识别任务的广泛关注，该任务旨在根据给定的文本识别个体的人格。考虑到ChatGPT近期在各种自然语言处理任务中展现出的显著能力，我们对ChatGPT在基于文本的人格识别任务上的表现进行了初步评估，以生成有效的人格数据。具体而言，我们采用了各种提示策略，探索ChatGPT从给定的文本中识别人格的能力，尤其是我们设计的面向层级的提示策略，用于指导ChatGPT在指定层次分析给定的文本。我们将ChatGPT在两个代表性的实际数据集上与传统的神经网络、微调的RoBERTa以及相应的最新任务的性能进行了比较。

    In recent years, personality has been regarded as a valuable personal factor being incorporated into numerous tasks such as sentiment analysis and product recommendation. This has led to widespread attention to text-based personality recognition task, which aims to identify an individual's personality based on given text. Considering that ChatGPT has recently exhibited remarkable abilities on various natural language processing tasks, we provide a preliminary evaluation of ChatGPT on text-based personality recognition task for generating effective personality data. Concretely, we employ a variety of prompting strategies to explore ChatGPT's ability in recognizing personality from given text, especially the level-oriented prompting strategy we designed for guiding ChatGPT in analyzing given text at a specified level. We compare the performance of ChatGPT on two representative real-world datasets with traditional neural network, fine-tuned RoBERTa, and corresponding state-of-the-art task
    
[^12]: 用于改进视听融合导航的主动稀疏对话

    Active Sparse Conversations for Improved Audio-Visual Embodied Navigation. (arXiv:2306.04047v1 [cs.CV])

    [http://arxiv.org/abs/2306.04047](http://arxiv.org/abs/2306.04047)

    本文提出了CAVEN - 一种具有对话功能的音频视觉导航代理，能够向人类/神谕提出导航问题并处理神谕回答以协助自主导航。该系统基于多模态分层强化学习方法，并使用三个低级策略进行引导。

    

    为了高效地导航到一个听觉目标，一个具有固定自主权的实体必须不仅要有能力有效地使用视听线索, 而且还要有能力在不牺牲自主性的情况下主动寻求人类/神谕的帮助，例如，当不确定导航到哪里寻找嘈杂或间歇性听觉目标时。因此，我们提出了CAVEN-一种具有对话功能的音频视觉导航代理，能够向人类/神谕提出导航问题并处理神谕的自由形式自然语言回答。在CAVEN的核心是一个多模态分层强化学习(RL)设置，它配备了一个高级策略，该策略经过训练，可以在每一步从三个低级策略中选择一个，即：(i)使用视听线索进行导航，或(ii)向神谕提出问题并接收短或详细的回答，或(iii)提问普遍问题(当不确定该问什么时)并获得指导

    Efficient navigation towards an audio-goal necessitates an embodied agent to not only possess the ability to use audio-visual cues effectively, but also be equipped to actively (but occasionally) seek human/oracle assistance without sacrificing autonomy, e.g., when it is uncertain of where to navigate towards locating a noisy or sporadic audio goal. To this end, we present CAVEN -- a conversational audio-visual embodied navigation agent that is capable of posing navigation questions to a human/oracle and processing the oracle responses; both in free-form natural language. At the core of CAVEN is a multimodal hierarchical reinforcement learning (RL) setup that is equipped with a high-level policy that is trained to choose from one of three low-level policies (at every step), namely: (i) to navigate using audio-visual cues, or (ii) to frame a question to the oracle and receive a short or detailed response, or (iii) ask generic questions (when unsure of what to ask) and receive instructio
    
[^13]: ChatGPT是ENFJ，Bard是ISTJ：大型语言模型的个性实证研究。

    ChatGPT an ENFJ, Bard an ISTJ: Empirical Study on Personalities of Large Language Models. (arXiv:2305.19926v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.19926](http://arxiv.org/abs/2305.19926)

    本研究通过采用特质理论框架，实验证明了ChatGPT始终表现出ENFJ型人格，无论指令或情境如何。研究揭示了LLMs的个性化，有助于促进人与机器之间更好的沟通和协作。

    

    大型语言模型（LLMs）在人工智能领域取得了显著进展，大大重塑了人机交互。我们不仅关注LLMs的性能，还从心理学角度探索它们的特点，认识到了理解它们行为特征的重要性。本研究采用心理学的一个框架——特质理论研究LLMs所展示的行为模式。我们首先关注评估ChatGPT所展示的人格类型的一致性。此外，实验涉及七种附加语言的跨语言影响，以及六种其他LLMs的研究。此外，该研究还调查了ChatGPT是否能够展示对指令或情境线索的人格变化。研究结果表明，无论指令或情境如何，ChatGPT始终保持其ENFJ人格。通过揭示LLMs的个性化，我们预计我们的解决方案可以促进人与机器之间更好的沟通和协作。

    Large Language Models (LLMs) have made remarkable advancements in the field of artificial intelligence, significantly reshaping the human-computer interaction. We not only focus on the performance of LLMs, but also explore their features from a psychological perspective, acknowledging the importance of understanding their behavioral characteristics. Our study examines the behavioral patterns displayed by LLMs by employing trait theory, a psychological framework. We first focus on evaluating the consistency of personality types exhibited by ChatGPT. Furthermore, experiments include cross-lingual effects on seven additional languages, and the investigation of six other LLMs. Moreover, the study investigates whether ChatGPT can exhibit personality changes in response to instructions or contextual cues. The findings show that ChatGPT consistently maintains its ENFJ personality regardless of instructions or contexts. By shedding light on the personalization of LLMs, we anticipate that our s
    
[^14]: GPT 模型在化学领域到底有怎样的应用？八个任务的综合基准测试。

    What indeed can GPT models do in chemistry? A comprehensive benchmark on eight tasks. (arXiv:2305.18365v1 [cs.CL])

    [http://arxiv.org/abs/2305.18365](http://arxiv.org/abs/2305.18365)

    本文建立了包括 8 个实际化学任务的综合基准测试，有力地证明了 LLM 在实际化学中的能力。

    

    具有强大自然语言处理能力的大型语言模型已被广泛应用于科学、金融和软件工程等领域。但是，LLM 是否有能力推动化学领域的进展仍不清楚。本文建立了包含 8 个实际化学任务的综合基准测试，包括名称预测、属性预测、产量预测、反应预测、反合成（从产物预测反应物）、基于文本的分子设计、分子字幕和试剂选择。我们使用广泛认可的数据集，包括 BBBP、Tox21、PubChem、USPTO 和 ChEBI，有力地证明了 LLM 在实际化学中的能力。在精心选择的示例中，对三种 GPT 模型（GPT-4、GPT-3.5 和 DaVinci-003）在零样本和少样本有上下文学习的设置中进行了评估。

    Large Language Models (LLMs) with strong abilities in natural language processing tasks have emerged and have been rapidly applied in various kinds of areas such as science, finance and software engineering. However, the capability of LLMs to advance the field of chemistry remains unclear. In this paper,we establish a comprehensive benchmark containing 8 practical chemistry tasks, including 1) name prediction, 2) property prediction, 3) yield prediction, 4) reaction prediction, 5) retrosynthesis (prediction of reactants from products), 6)text-based molecule design, 7) molecule captioning, and 8) reagent selection. Our analysis draws on widely recognized datasets including BBBP, Tox21, PubChem, USPTO, and ChEBI, facilitating a broad exploration of the capacities of LLMs within the context of practical chemistry. Three GPT models (GPT-4, GPT-3.5,and Davinci-003) are evaluated for each chemistry task in zero-shot and few-shot in-context learning settings with carefully selected demonstrat
    
[^15]: 自然语言处理中基于外部分布检测的综述

    A Survey on Out-of-Distribution Detection in NLP. (arXiv:2305.03236v1 [cs.CL])

    [http://arxiv.org/abs/2305.03236](http://arxiv.org/abs/2305.03236)

    这篇论文首次综述了最新的OOD检测方法在自然语言处理中的应用。根据算法使用的数据，将方法分成三类，并介绍了相关数据集、应用和度量方法。

    

    在现实世界中，基于外部分布（OOD）的检测对于机器学习系统的可靠和安全的部署至关重要。过去几年取得了极大进展。本文重点关注自然语言处理方法，并首次综述了OOD检测方面的最新进展。首先，我们给出OOD检测的正式定义，并讨论了几个相关领域。然后，根据算法使用的数据，将最近的算法分成三类：（1）可用OOD数据，（2）OOD数据不可用+内部分布（ID）标签可用，（3）OOD数据不可用+ID标签不可用。第三，介绍数据集、应用和度量方法。最后，总结现有工作并提出潜在的未来研究课题。

    Out-of-distribution (OOD) detection is essential for the reliable and safe deployment of machine learning systems in the real world. Great progress has been made over the past years. This paper presents the first review of recent advances in OOD detection with a particular focus on natural language processing approaches. First, we provide a formal definition of OOD detection and discuss several related fields. We then categorize recent algorithms into three classes according to the data they used: (1) OOD data available, (2) OOD data unavailable + in-distribution (ID) label available, and (3) OOD data unavailable + ID label unavailable. Third, we introduce datasets, applications, and metrics. Finally, we summarize existing work and present potential future research topics.
    
[^16]: 利用代理模型识别多任务学习中的负迁移

    Identification of Negative Transfers in Multitask Learning Using Surrogate Models. (arXiv:2303.14582v1 [cs.LG])

    [http://arxiv.org/abs/2303.14582](http://arxiv.org/abs/2303.14582)

    本文提出了一种通过代理建模来解决多任务学习中负迁移问题的方法，能够识别哪些源任务的子集会对目标任务有帮助。

    

    多任务学习广泛应用于通过增加多个相关源任务来训练低资源目标任务。然而，将所有源任务与目标任务简单组合并不总是能提高目标任务的预测性能，因为会存在负迁移。因此，多任务学习的一个关键问题是识别哪些源任务的子集会对目标任务有益。这个问题在计算上很具有挑战性，因为子集的数量随着源任务的数量呈指数级增长。在本文中，我们介绍了一种通过代理建模来解决此问题的有效方法。在代理建模中，我们对源任务进行采样（随机），并预先计算它们的多任务学习表现；然后，我们用线性回归模型来逼近预先计算的表现，该模型也可用于预测未采样的子集的表现。我们在几个合成示例和一个现实世界的多语言情感分析任务上证明了我们方法的有效性。

    Multitask learning is widely used in practice to train a low-resource target task by augmenting it with multiple related source tasks. Yet, naively combining all the source tasks with a target task does not always improve the prediction performance for the target task due to negative transfers. Thus, a critical problem in multitask learning is identifying subsets of source tasks that would benefit the target task. This problem is computationally challenging since the number of subsets grows exponentially with the number of source tasks; efficient heuristics for subset selection does not always capture the relationship between task subsets and multitask learning performances. In this paper, we introduce an efficient procedure to address this problem via surrogate modeling. In surrogate modeling, we sample (random) subsets of source tasks and precompute their multitask learning performances; Then, we approximate the precomputed performances with a linear regression model that can also be
    
[^17]: 基于语言模型的知识图谱嵌入编辑

    Editing Language Model-based Knowledge Graph Embeddings. (arXiv:2301.10405v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.10405](http://arxiv.org/abs/2301.10405)

    本文提出了一种新的任务——编辑基于语言模型的知识图谱嵌入，旨在实现对KG嵌入的数据高效和快速更新。针对这一任务，提出了一个简单而强大的方案——KGEditor，可以更好地更新特定事实而不影响其余部分的性能。

    

    近几十年来，使用语言模型进行知识图谱（KG）嵌入已经取得了实证成功。但是，基于语言模型的KG嵌入通常作为静态工件部署，修改起来具有挑战性，需要重新训练。为了解决这个问题，本文提出了一种新的任务，即编辑基于语言模型的KG嵌入。该任务旨在实现对KG嵌入的数据高效和快速更新，而不影响其余部分的性能。我们构建了四个新数据集：E-FB15k237、A-FB15k237、E-WN18RR 和 A-WN18RR，并评估了几种知识编辑基线，证明了之前的模型处理该任务的能力有限。我们进一步提出了一个简单但强大的基线——KGEditor，它利用超网络的附加参数层来编辑/添加事实。全面的实验结果表明，当更新特定事实而不影响其余部分的性能时，KGEditor 的表现更好。

    Recently decades have witnessed the empirical success of framing Knowledge Graph (KG) embeddings via language models. However, language model-based KG embeddings are usually deployed as static artifacts, which are challenging to modify without re-training after deployment. To address this issue, we propose a new task of editing language model-based KG embeddings in this paper. The proposed task aims to enable data-efficient and fast updates to KG embeddings without damaging the performance of the rest. We build four new datasets: E-FB15k237, A-FB15k237, E-WN18RR, and A-WN18RR, and evaluate several knowledge editing baselines demonstrating the limited ability of previous models to handle the proposed challenging task. We further propose a simple yet strong baseline dubbed KGEditor, which utilizes additional parametric layers of the hyper network to edit/add facts. Comprehensive experimental results demonstrate that KGEditor can perform better when updating specific facts while not affec
    

