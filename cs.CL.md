# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [MT-Ranker: Reference-free machine translation evaluation by inter-system ranking.](http://arxiv.org/abs/2401.17099) | MT-Ranker 提出了一种无参考机器翻译评估方法，通过系统间排名来解决了传统用回归方法产生绝对翻译质量分数的不足，提供了更具解释性和一致性的评分结果，并在没有参考的情况下应用于实际场景中。 |
| [^2] | [StrokeNUWA: Tokenizing Strokes for Vector Graphic Synthesis.](http://arxiv.org/abs/2401.17093) | StrokeNUWA是一个探索在矢量图形上更好的视觉表示的研究，引入了一种新的“笔画标记”表示方法，能够在矢量图形生成任务中显著提升性能。 |
| [^3] | [NNOSE: Nearest Neighbor Occupational Skill Extraction.](http://arxiv.org/abs/2401.17092) | NNOSE是一种利用多个数据集有效提取职业技能的方法，通过检索其他数据集中的邻近技能来提高技能提取的性能，而无需进行额外的微调。 |
| [^4] | [SemScore: Automated Evaluation of Instruction-Tuned LLMs based on Semantic Textual Similarity.](http://arxiv.org/abs/2401.17072) | 这项研究提出了一个名为SemScore的评估指标，通过语义文本相似度直接比较模型输出和黄金目标回应，用于评估指令调校大型语言模型。实验证明，SemScore指标在与人工评估的相关性方面表现优于其他评估指标。 |
| [^5] | [CRUD-RAG: A Comprehensive Chinese Benchmark for Retrieval-Augmented Generation of Large Language Models.](http://arxiv.org/abs/2401.17043) | 这篇论文构建了一个大规模且更全面的中文基准测试，评估了检索增强生成系统的所有组件在各种应用场景中的性能。 |
| [^6] | [Taking Action Towards Graceful Interaction: The Effects of Performing Actions on Modelling Policies for Instruction Clarification Requests.](http://arxiv.org/abs/2401.17039) | 执行动作作为辅助任务对于指示澄清请求（iCR）策略的学习贡献有限，但可以从预测的不确定性中提取信息。基于Transformer的模型在何时提问指示CR方面表现不佳，而何时提问的任务可以更成功地进行建模。 |
| [^7] | [Distinguishing Fictional Voices: a Study of Authorship Verification Models for Quotation Attribution.](http://arxiv.org/abs/2401.16968) | 本文研究了辨别虚构声音的作者验证模型，通过在英语小说的语料库中对角色的引语进行风格表示。结果表明，在某些模型中，捕捉到的风格和主题信息能够准确区分不同的角色，但在归属引语方面并不一定比仅有语义的模型更好。 |
| [^8] | [Two Heads Are Better Than One: Integrating Knowledge from Knowledge Graphs and Large Language Models for Entity Alignment.](http://arxiv.org/abs/2401.16960) | 本研究提出了一种大型语言模型增强的实体对齐框架（LLMEA），将知识图谱中的结构知识与大型语言模型中的语义知识相结合，以提升实体对齐的效果。 |
| [^9] | [Cross-Lingual Transfer from Related Languages: Treating Low-Resource Maltese as Multilingual Code-Switching.](http://arxiv.org/abs/2401.16895) | 本研究关注马耳他语这种混合语言，采用了一种新颖的数据集和分类器来提高跨语言转移能力，解决了混合语言文字差异的问题。 |
| [^10] | [State Value Generation with Prompt Learning and Self-Training for Low-Resource Dialogue State Tracking.](http://arxiv.org/abs/2401.16862) | 提出了一种用于低资源对话状态跟踪的状态值生成框架，通过提示学习和自训练来改善状态值生成，并在实验中取得了最先进的性能。 |
| [^11] | [H2O-Danube-1.8B Technical Report.](http://arxiv.org/abs/2401.16818) | H2O-Danube-1.8B 是一个在 1T 个标记上训练的 18 亿语言模型，具有高度竞争力的指标。同时，他们还发布了一个经过微调和优化训练的聊天模型，进一步推动语言模型的经济民主化。 |
| [^12] | [Can Large Language Models be Trusted for Evaluation? Scalable Meta-Evaluation of LLMs as Evaluators via Agent Debate.](http://arxiv.org/abs/2401.16788) | 本论文提出了ScaleEval，一个基于代理辩论的元评估框架，通过利用多个交流型LLM代理的能力来有效、可靠、高效地评估LLMs在不同任务和场景中作为评估者的性能。 |
| [^13] | [Detecting Racist Text in Bengali: An Ensemble Deep Learning Framework.](http://arxiv.org/abs/2401.16748) | 本文提出了一种检测孟加拉语中种族主义文本的集成深度学习框架，成功实现了87.94%的准确率。模型的最佳表现是使用MCNN-LSTM模型，并采用BERT嵌入和RNN/LSTM模型进行训练。最终采用集成方法来提高整体性能。 |
| [^14] | [MT-Eval: A Multi-Turn Capabilities Evaluation Benchmark for Large Language Models.](http://arxiv.org/abs/2401.16745) | MT-Eval是一个用于评估大型语言模型多轮对话能力的综合性基准，通过分析人类-LLM对话，将交互模式分为四类，并创建了多轮查询来评估模型的性能。 |
| [^15] | [Engineering A Large Language Model From Scratch.](http://arxiv.org/abs/2401.16736) | Atinuke是一种基于Transformer的神经网络，通过在处理时序数据的层与注意机制交织在一起，模拟人类语言，从而优化各种语言任务的性能。 |
| [^16] | [Towards Generating Informative Textual Description for Neurons in Language Models.](http://arxiv.org/abs/2401.16731) | 本文提出了一种新颖而可伸缩的框架，将文本描述与语言模型中的神经元联系起来，从而解释模型中理解的信息。通过使用生成语言模型发现人可解释的描述符，并使用无监督方法解释神经元，通过定性和定量分析证明了该方法的有效性。 |
| [^17] | [Recent Advances in Hate Speech Moderation: Multimodality and the Role of Large Models.](http://arxiv.org/abs/2401.16727) | 这项综合调查总结了最近在仇恨言论审核方面的进展，重点介绍了大型语言模型和大型多模态模型的作用。研究发现了文本、视觉和听觉元素在传播仇恨言论中的微妙相互作用，并强调了大型模型对审核能力的重新定义。同时，研究还指出了在少数语言和文化背景下的研究差距和处理低资源环境的需求。 |
| [^18] | [Prospects for inconsistency detection using large language models and sheaves.](http://arxiv.org/abs/2401.16713) | 利用大型语言模型进行逻辑一致性评估，并采用层群理论方法将其扩展到法律、司法和社交媒体等超文本中进行全局评估，有助于提高政府的一致性并应对误导信息和相关问题。 |
| [^19] | [The Detection and Understanding of Fictional Discourse.](http://arxiv.org/abs/2401.16678) | 本文介绍了虚构话语检测的分类实验，利用了多样的数据集和新的特征集。虚构话语的检测有助于丰富大型文化遗产档案，并帮助更广泛地理解虚构叙事的特质。 |
| [^20] | [History-Aware Conversational Dense Retrieval.](http://arxiv.org/abs/2401.16659) | 该论文提出了一种历史感知的对话式稠密检索系统，通过上下文去噪的查询重构以及根据历史轮次的实际影响自动挖掘监督信号改进了现有的对话式稠密检索方法。 |
| [^21] | [OWSM v3.1: Better and Faster Open Whisper-Style Speech Models based on E-Branchformer.](http://arxiv.org/abs/2401.16658) | 该论文介绍了OWSM v3.1基于E-Branchformer的更好和更快的开放式Whisper风格语音模型。这个模型通过提高性能和效率，超越了之前的版本，并实现了更快的推理速度。该论文还公开发布了相关的数据和模型。 |
| [^22] | [Recovering Mental Representations from Large Language Models with Markov Chain Monte Carlo.](http://arxiv.org/abs/2401.16657) | 本文研究了使用马尔可夫链蒙特卡洛（MCMC）方法从大型语言模型中恢复心智表示的方法，并且发现使用基于MCMC的自适应采样算法可以显著提高效率和性能，这对于进行贝叶斯推理具有潜在意义。 |
| [^23] | [Gradient-Based Language Model Red Teaming.](http://arxiv.org/abs/2401.16656) | 本文介绍了一种基于梯度的语言模型红队测试（GBRT）方法，通过自动生成的多样化提示来触发语言模型生成不安全回应。通过使用安全分类器评分和反向传播来更新提示，GBRT在发现触发语言模型生成不安全回应的提示方面更加有效。 |
| [^24] | [Incoherent Probability Judgments in Large Language Models.](http://arxiv.org/abs/2401.16646) | 在本论文中，研究人员通过对大型语言模型(LLMs)进行实验证明，这些模型产生的概率判断经常是不连贯的，显示出类似于人类一样的非理性偏差。他们还提出了将自回归LLMs与隐性贝叶斯推断联系起来的解释。 |
| [^25] | [TeenyTinyLlama: open-source tiny language models trained in Brazilian Portuguese.](http://arxiv.org/abs/2401.16640) | 这篇论文开发了用于低资源环境中的开放式基础模型，以巴西葡萄牙语为例，发布在GitHub和Hugging Face上供社区使用和进一步开发。 |
| [^26] | [Breaking Free Transformer Models: Task-specific Context Attribution Promises Improved Generalizability Without Fine-tuning Pre-trained LLMs.](http://arxiv.org/abs/2401.16638) | 本文提出了一种框架，通过任务特定的上下文归因来提高模型在下游任务中的性能，而不需要对预训练的语言模型进行微调，从而保持了模型的泛化性能。 |
| [^27] | [Improving Reinforcement Learning from Human Feedback with Efficient Reward Model Ensemble.](http://arxiv.org/abs/2401.16635) | 本论文提出一种通过高效的奖励模型集成来改进人工反馈强化学习的方法，以解决由于奖励模型预测不准确而导致RLHF输出与人类价值观不一致的问题。 |
| [^28] | [ToPro: Token-Level Prompt Decomposition for Cross-Lingual Sequence Labeling Tasks.](http://arxiv.org/abs/2401.16589) | 这项研究提出了一种名为ToPro的方法，用于跨语言序列标注任务。该方法通过将输入句子分解为单个词汇并应用提示模板，在零样本跨语言转移中实现了优于其他微调方法的性能，并在结构不同的语言上取得了最先进的结果。 |
| [^29] | [A Linguistic Comparison between Human and ChatGPT-Generated Conversations.](http://arxiv.org/abs/2401.16587) | 本研究比较了人类和ChatGPT生成的对话的语言差异，发现ChatGPT在社交、分析、认知、关注焦点和积极情绪等方面表现出色，但人类对话更具变异性和真实性，尽管在情绪方面无显著差异。同时，该研究还提供了一个新颖的、由ChatGPT生成的对话组成的数据集。 |
| [^30] | [Massively Multilingual Text Translation For Low-Resource Languages.](http://arxiv.org/abs/2401.16582) | 该论文提出了一种将翻译资源从资源丰富的语言利用到资源有限的语言的方法，以满足低资源语言的翻译需求，并提高翻译质量和效率。 |
| [^31] | [Leveraging Professional Radiologists' Expertise to Enhance LLMs' Evaluation for Radiology Reports.](http://arxiv.org/abs/2401.16578) | 该论文提出了一种方法，将专业放射科医生的专业知识与大型语言模型相结合，来提升自动生成报告的自动评估。实验结果显示，该方法的模型在评估中表现优于传统的度量标准。 |
| [^32] | [LLMs as On-demand Customizable Service.](http://arxiv.org/abs/2401.16577) | 提出了一种分层、分布式的LLM架构概念，通过在通用计算机和物联网设备上提供按需访问的可定制服务，解决了LLMs训练、部署和访问过程中的挑战，并能够实现资源和应用需求的最佳平衡。 |
| [^33] | [Beyond Image-Text Matching: Verb Understanding in Multimodal Transformers Using Guided Masking.](http://arxiv.org/abs/2401.16575) | 本研究提出了一种新的探测策略，名为引导遮罩，在多模态Transformer模型中通过消除不同的模态来评估其对动词的理解能力。研究结果表明，这些模型能够准确预测正确的动词，与先前从图像-文本匹配探测技术中得出的结论形成对比。 |
| [^34] | [Autoencoder-Based Domain Learning for Semantic Communication with Conceptual Spaces.](http://arxiv.org/abs/2401.16569) | 这篇论文研究了基于概念空间的语义通信，提出了一个自编码器学习的框架，解决了无法捕捉和量化“意义”的问题。 |
| [^35] | [Multi-class Regret Detection in Hindi Devanagari Script.](http://arxiv.org/abs/2401.16561) | 本研究聚焦于印地语社交媒体上的后悔表达，建立了一个新的数据集，并通过研究后悔语言表达的特征和相关领域，揭示了后悔的来源和影响。 |
| [^36] | [Diverse, but Divisive: LLMs Can Exaggerate Gender Differences in Opinion Related to Harms of Misinformation.](http://arxiv.org/abs/2401.16558) | 本论文探讨了使用大型语言模型（LLM）用于优先排序误导性信息伤害时可能出现的问题。作者将性别作为主要变量，研究LLM在评估错误信息的危害性时是否能够反映不同性别群体的观点，结果发现LLM可能夸大了性别差异。 |
| [^37] | [SelectLLM: Can LLMs Select Important Instructions to Annotate?.](http://arxiv.org/abs/2401.16553) | 这项工作提出了一种名为SelectLLM的新方法，利用LLMs选择高质量指令。通过提示LLMs估计每个无标签指令的有用性和影响力，并使用聚类算法将指令分为多个聚类。 |
| [^38] | [GuReT: Distinguishing Guilt and Regret related Text.](http://arxiv.org/abs/2401.16541) | 本文介绍了GuReT数据集，用于研究内疚和后悔之间的关系，并探索其在文本中的独特特征。通过使用机器学习和深度学习技术，结果表明基于变压器的模型在内疚和后悔识别任务中表现出优于传统机器学习方法的性能。 |
| [^39] | [InfoLossQA: Characterizing and Recovering Information Loss in Text Simplification.](http://arxiv.org/abs/2401.16475) | InfoLossQA是一个针对文本简化中信息损失的特征化与恢复的框架，通过提供问答对的形式，帮助读者更深入地了解文本。实验结果表明，信息损失频繁发生，而QA对则能提供哪些信息被丢失的总结。 |
| [^40] | [ReGAL: Refactoring Programs to Discover Generalizable Abstractions.](http://arxiv.org/abs/2401.16467) | ReGAL提出了一种用于发现通用抽象的程序重构方法，可以通过重构代码学习可重用的函数库，利用这些共享函数库可以更准确地预测程序。 |
| [^41] | [Credit Risk Meets Large Language Models: Building a Risk Indicator from Loan Descriptions in P2P Lending.](http://arxiv.org/abs/2401.16458) | 本文研究了如何利用P2P借贷平台上借款人提供的文本描述来构建风险指标。结果显示，利用大型语言模型生成的风险评分可以明显提高信用风险分类器的性能。 |
| [^42] | [KAUCUS: Knowledge Augmented User Simulators for Training Language Model Assistants.](http://arxiv.org/abs/2401.16454) | KAUCUS引入了知识增强用户模拟器框架，可以生成多样化的模拟器助手交互，并能够快速引入外部知识，从而提高语言模型助手的训练效果。 |
| [^43] | [FaKnow: A Unified Library for Fake News Detection.](http://arxiv.org/abs/2401.16441) | FaKnow是一个统一的虚假新闻检测算法库，包含多种常用的模型和工具，并解决了不同框架下的可重复性和冗余问题。 |
| [^44] | [An Information Retrieval and Extraction Tool for Covid-19 Related Papers.](http://arxiv.org/abs/2401.16430) | 该论文开发了一个集信息检索和提取于一体的工具，应用于COVID-19 Open Research Dataset (CORD-19)。主要目的是为研究人员提供一个更好的COVID-19相关论文的搜索工具，帮助他们找到参考论文并突出显示文本中的相关实体。 |
| [^45] | [Combining topic modelling and citation network analysis to study case law from the European Court on Human Rights on the right to respect for private and family life.](http://arxiv.org/abs/2401.16429) | 本文研究了结合主题建模和引用网络分析的方法，用来研究欧洲人权法院关于尊重私密和家庭生活的案例法。通过这种方法，可以找到和组织具有相似主题和引用模式的案例法，并且通过结合这两种技术能够得到更好的结果。 |
| [^46] | [A RAG-based Question Answering System Proposal for Understanding Islam: MufassirQAS LLM.](http://arxiv.org/abs/2401.15378) | 基于RAG的MufassirQAS问答系统利用NLP技术建立联系并准确回答复杂问题，提高了LLMs的准确性和透明度，帮助理解伊斯兰教的复杂性和教义深度。 |
| [^47] | [Equipping Language Models with Tool Use Capability for Tabular Data Analysis in Finance.](http://arxiv.org/abs/2401.15328) | 在金融数据分析领域，通过为语言模型添加工具使用能力，我们成功解决了大型语言模型在处理异构金融数据和保证精度时所面临的挑战，并取得了显著的改进。 |
| [^48] | [Under the Surface: Tracking the Artifactuality of LLM-Generated Data.](http://arxiv.org/abs/2401.14698) | 本研究是针对大型语言模型（LLM）生成的人工数据的追踪研究，将各种类型的LLM生成文本数据进行了汇总和测试，并揭示了隐藏的质量和多样性问题。这是第一次对LLM生成数据进行综合分析和比较，并引发了对人工数据质量的关注。 |
| [^49] | [A Comparative Analysis of Noise Reduction Methods in Sentiment Analysis on Noisy Bengali Texts.](http://arxiv.org/abs/2401.14360) | 本文通过比较分析了噪声减少方法在噪声孟加拉文本情感分析中的效果，并提出了更适用的噪声减少方法的需求。 |
| [^50] | [Investigating the Efficacy of Large Language Models for Code Clone Detection.](http://arxiv.org/abs/2401.13802) | 这项研究探索了大型语言模型在代码克隆检测任务中的应用。 |
| [^51] | [In-Context Language Learning: Architectures and Algorithms.](http://arxiv.org/abs/2401.12973) | 本文通过研究一个新的问题家族——上下文语言学习（ICLL），探讨了大规模神经语言模型在上下文学习中的能力。在ICLL中，模型通过生成与给定形式语言相同的字符串来进行上下文学习。研究结果对于理解真实场景中的上下文学习以及神经语言模型的发展具有重要意义。 |
| [^52] | [SLANG: New Concept Comprehension of Large Language Models.](http://arxiv.org/abs/2401.12585) | 本研究提出了一个新的基准SLANG，旨在增强大型语言模型LLMs对互联网上新概念的理解能力，同时提出了一种基于因果推断的基准方法FOCUS，能帮助LLMs更好地理解新的短语和用法模式。 |
| [^53] | [Location Sensitive Embedding for Knowledge Graph Embedding.](http://arxiv.org/abs/2401.10893) | 这篇论文介绍了一种新颖的位置敏感嵌入（LSE）方法，该方法通过关系特定的映射来修改头实体，将关系概念化为线性变换。LSE在知识图谱嵌入领域具有理论基础，同时提出了更高效的变体LSEd。实验证明LSEd在链接预测任务上具有竞争力。 |
| [^54] | [Noise Contrastive Estimation-based Matching Framework for Low-resource Security Attack Pattern Recognition.](http://arxiv.org/abs/2401.10337) | 该论文提出了一种基于噪声对比估计的低资源安全攻击模式识别匹配框架，通过直接语义相似度决定文本与攻击模式之间的关联，以降低大量类别、标签分布不均和标签空间复杂性带来的学习难度。 |
| [^55] | [Instant Answering in E-Commerce Buyer-Seller Messaging.](http://arxiv.org/abs/2401.09785) | 通过使用低延迟的序列到序列方法，我们成功地将电子商务顾客的消息转化为简洁的问题，从而实现了在电子商务买卖双方在线消息中的即时回答。实验证明，我们的方法在问题理解和回答率方面相对增加了很多，对于提高顾客的购物体验非常有效。 |
| [^56] | [Augmenting Math Word Problems via Iterative Question Composing.](http://arxiv.org/abs/2401.09003) | 本研究通过引入MMIQC数据集和迭代组合问题(IQC)的新颖增强方法，成功提高了大型语言模型的数学推理能力，在竞赛级数学问题上取得了优于先前最佳结果的准确率。 |
| [^57] | [RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture.](http://arxiv.org/abs/2401.08406) | 本文评估了检索增强生成（RAG）和微调两种方法在大型语言模型上的性能差异，并提出了适用于农业数据集的管道和权衡。 |
| [^58] | [LEGO:Language Enhanced Multi-modal Grounding Model.](http://arxiv.org/abs/2401.06071) | LEGO是一种语言增强的多模态关联模型，它能够在各种任务中实现细粒度的理解和精确的标识能力。 |
| [^59] | [TwinBooster: Synergising Large Language Models with Barlow Twins and Gradient Boosting for Enhanced Molecular Property Prediction.](http://arxiv.org/abs/2401.04478) | TwinBooster结合了大语言模型、Barlow Twins和梯度提升，通过整合生物检测方法和分子指纹，实现了对未见过的生物检测方法和分子属性的精确预测，该方法在数据稀缺的情况下展现出了优秀的性能。 |
| [^60] | [From LLM to Conversational Agent: A Memory Enhanced Architecture with Fine-Tuning of Large Language Models.](http://arxiv.org/abs/2401.02777) | 这项工作介绍了一种名为RAISE的架构，它将大型语言模型（LLMs）如GPT-4整合到对话代理中，通过引入双组件记忆系统来增强代理在多轮对话中的可控性和适应性。预liminary evaluations表明，RAISE在房地产销售领域具有优势，并具有广泛应用的潜力。 |
| [^61] | [State of What Art? A Call for Multi-Prompt LLM Evaluation.](http://arxiv.org/abs/2401.00595) | 本研究呼吁使用多个提示来评估大语言模型（LLMs），以解决单提示评估的脆弱性，并提供了关于当前LLMs真正优势和局限性的见解。 |
| [^62] | [Auto311: A Confidence-guided Automated System for Non-emergency Calls.](http://arxiv.org/abs/2312.14185) | Auto311是第一个处理非紧急电话的自动化系统，它通过减轻非紧急电话负担，提供快速有效的响应。通过预测事件类型并生成个性化的案件报告，并从对话上下文中提取关键信息来完善报告，系统与主叫人之间的对话结构得到优化。 |
| [^63] | [Locating Factual Knowledge in Large Language Models: Exploring the Residual Stream and Analyzing Subvalues in Vocabulary Space.](http://arxiv.org/abs/2312.12141) | 通过探索剩余流和分析词汇空间中的子值，我们定位了大型语言模型中的事实知识，并找到了存储了有关“法国，首都，巴黎”的知识的位置。 |
| [^64] | [Toward A Reinforcement-Learning-Based System for Adjusting Medication to Minimize Speech Disfluency.](http://arxiv.org/abs/2312.11509) | 这个论文介绍了一种基于强化学习的系统，该系统可以根据患者言语不流畅程度自动调整药物，通过对药物组合的强化学习算法的优化，能够收敛到良好的用药方案。 |
| [^65] | [SEF-VC: Speaker Embedding Free Zero-Shot Voice Conversion with Cross Attention.](http://arxiv.org/abs/2312.08676) | SEF-VC是一种无说话人嵌入的语音转换模型，通过交叉注意力机制从参考语音中学习并融入说话人音色，具有稳定的训练和优越的语音转换性能。与强零样本语音转换基线相比，在生成高质量语音的同时能够更好地保持与目标参考的相似性，即使对于很短的参考语音。 |
| [^66] | [Toxic language detection: a systematic review of Arabic datasets.](http://arxiv.org/abs/2312.07228) | 这项研究提供了对阿拉伯语在线毒性语言数据集的全面调研，并通过分析现有数据集的差距和问题，为未来的研究提供了建议。 |
| [^67] | [Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs.](http://arxiv.org/abs/2312.05934) | 该研究比较了无监督的微调和检索增强生成（RAG）这两种常见方法在LLMs中的应用。结果发现，RAG在现有知识和新知识上表现出更好的性能，而LLMs通过无监督的微调学习新的事实信息较困难。 |
| [^68] | [MultiGPrompt for Multi-Task Pre-Training and Prompting on Graphs.](http://arxiv.org/abs/2312.03731) | 本文提出了一种名为MultiGPrompt的多任务预训练和提示框架，用于在图形表示学习中提高鲁棒性和减少标注成本。 |
| [^69] | [Self-Infilling Code Generation.](http://arxiv.org/abs/2311.17972) | 本文介绍了自补代码生成的通用框架，利用自补机制实现了中断和循环机制，使传统解码进程变得非单调。利用中断机制可以推迟生成代码，增强对输出的控制；利用循环机制可以循环更新和同步生成的每个部分。 |
| [^70] | [War and Peace (WarAgent): Large Language Model-based Multi-Agent Simulation of World Wars.](http://arxiv.org/abs/2311.17227) | 本研究提出了一个名为WarAgent的大语言模型驱动的多智能体AI系统，用于模拟历史国际冲突，并通过评估其效果和研究智能体之间的相互作用，探讨了战争的引发因素和条件。 |
| [^71] | [Novel Preprocessing Technique for Data Embedding in Engineering Code Generation Using Large Language Model.](http://arxiv.org/abs/2311.16267) | 本论文提出了一种新的预处理技术，通过利用大型语言模型（LLM）来增强工程代码生成中的性能。该技术包括利用LLM的数据拆分和数据翻新技术提高嵌入空间的语义表示，引入基于LLM的密度链条和自适应文本翻新算法评估数据翻新可信度，开发隐式知识扩展和思考提示技术，以及通过重构现有脚本生成新的高质量脚本。在使用工程模拟软件RedHawk-SC作为案例研究时，这些技术的有效性得到了证明，能够扩展和分类脚本，并在与IKEC结合使用时提高检索增强生成方法的性能。 |
| [^72] | [Meta Prompting for AGI Systems.](http://arxiv.org/abs/2311.11482) | 本文全面研究了元提示技术，这是一种创新方法，重塑了大型语言模型、多模态模型和人工智能系统在问题解决和数据解释方面的应用。通过强调信息的结构和句法，元提示将复杂问题拆解为简单的子问题，提高了效率，并且能够与少样本方法进行公平的比较。同时，本文还提出了元提示用于自动生成提示的方法。 |
| [^73] | [Conversation Understanding using Relational Temporal Graph Neural Networks with Auxiliary Cross-Modality Interaction.](http://arxiv.org/abs/2311.04507) | 本论文提出了一个名为CORECT的神经网络框架，通过关系时态图神经网络和辅助跨模态交互的方式有效地捕捉对话中的情感信息。 |
| [^74] | [One-Shot Sensitivity-Aware Mixed Sparsity Pruning for Large Language Models.](http://arxiv.org/abs/2310.09499) | 我们提出了一种基于敏感度感知混合稀疏化剪枝的方法，可以在不重新训练的情况下将大型语言模型剪枝至至少50％的稀疏性，同时保持稀疏性水平和减少剪枝引起的误差。此外，该方法还与量化兼容，可以进一步压缩语言模型。 |
| [^75] | [EMO: Earth Mover Distance Optimization for Auto-Regressive Language Modeling.](http://arxiv.org/abs/2310.04691) | EMO提出了地球移动距离优化（EMO）来解决语言模型中的退化现象。EMO利用了地球移动距离的特性，并引入了一个可行的上界来简化训练。经过评估，发现EMO在语言模型上有显著的改进。 |
| [^76] | [Syllable-level lyrics generation from melody exploiting character-level language model.](http://arxiv.org/abs/2310.00863) | 该论文提出了一种利用字符级语言模型从旋律中生成音节级歌词的方法，并通过融合语言模型知识和生成器网络进行优化。通过探索ChatGPT的评估方法，以及人工评估，证明了该方法提高了生成歌词的连贯性和正确性。 |
| [^77] | [Creativity Support in the Age of Large Language Models: An Empirical Study Involving Emerging Writers.](http://arxiv.org/abs/2309.12570) | 本文通过实证研究探讨了大型语言模型（LLM）在协助专业作家方面的效用，并发现作家们更倾向于在翻译和审查阶段中寻求LLM的帮助。 |
| [^78] | [MAPLE: Mobile App Prediction Leveraging Large Language model Embeddings.](http://arxiv.org/abs/2309.08648) | MAPLE是一个利用大型语言模型嵌入进行移动应用预测的模型，通过严格测试验证了其在解密复杂模式和理解用户环境方面的能力，并强调了语言模型在不同领域中的广泛适用性。 |
| [^79] | [Data Distribution Bottlenecks in Grounding Language Models to Knowledge Bases.](http://arxiv.org/abs/2309.08345) | 本文通过实验调查揭示了语言模型在与知识库进行连接时的数据分布瓶颈，包括推广到未见域、适应语言变体和在不同数据集之间的可转移性等方面。即使采用数据增强技术，先进的语言模型在多个方面表现出较差的性能。 |
| [^80] | [Ambiguity-Aware In-Context Learning with Large Language Models.](http://arxiv.org/abs/2309.07900) | 在上下文学习中，选择与测试输入语义相似的演示有助于提高下游性能，但是考虑到语言模型关于任务的现有知识能够更好地指导演示选择。 |
| [^81] | [Circuit Breaking: Removing Model Behaviors with Targeted Ablation.](http://arxiv.org/abs/2309.05973) | 本论文提出了一种通过有针对性的消融模型组件之间的因果路径来去除语言模型中不良行为的新方法。在减少GPT-2毒性语言生成方面，仅消融12条因果边中的11.6K可以有效减轻毒性生成，并在其他输入上的性能下降很小。 |
| [^82] | [Efficient Benchmarking (of Language Models).](http://arxiv.org/abs/2308.11696) | 本研究提出了一种名为"Efficient Benchmarking"的问题，旨在智能地减少语言模型评估的计算成本而不降低可靠性，并使用一种名为Decision Impact on Reliability（DIoR）的新度量来评估决策的可靠性。通过HELM基准测试的案例研究，发现只需删除一个低排名模型即可改变领先者，并仅需少量示例即可得到正确的基准测试排名。 |
| [^83] | [Evaluating the Generation Capabilities of Large Chinese Language Models.](http://arxiv.org/abs/2308.04823) | 本文首次对大型中文语言模型在多个学科领域的生成能力进行了全面评估，并提出了Gscore作为衡量生成结果质量的综合指数。 |
| [^84] | [Give Us the Facts: Enhancing Large Language Models with Knowledge Graphs for Fact-aware Language Modeling.](http://arxiv.org/abs/2306.11489) | 这篇论文研究了如何通过知识图谱增强大型语言模型，提高其生成内容的准确性和对用户查询的回复能力。 |
| [^85] | [ReactGenie: An Object-Oriented State Abstraction for Complex Multimodal Interactions Using Large Language Models.](http://arxiv.org/abs/2306.09649) | ReactGenie是一个支持构建复杂的多模态移动应用程序的编程框架，通过使用共享的面向对象状态抽象，使得不同模态可以无缝集成和组合，从而实现了多模态交互的支持。 |
| [^86] | [Textually Pretrained Speech Language Models.](http://arxiv.org/abs/2305.13009) | 本论文提出了一种使用预训练的文本语言模型训练语音语言模型的方法，通过对模型设计选择和数据集规模的经验性分析，构建了参数数量和训练数据最多的语音语言模型，并引入了两个Spoken版本的文本基准，以进一步改善模型评估和推动未来研究。 |
| [^87] | [Scaling laws for language encoding models in fMRI.](http://arxiv.org/abs/2305.11863) | 本文揭示了基于fMRI的语言编码模型预测性能与模型大小呈对数线性关系，在125M到30B参数模型进行规模扩展时，表现提高了约15％。 |
| [^88] | [Solving NLP Problems through Human-System Collaboration: A Discussion-based Approach.](http://arxiv.org/abs/2305.11789) | 本研究提出了一种基于讨论的方法，旨在通过人机协作解决自然语言处理难题。提出了一个可以进行对话并修正预测的系统，通过实验证明该系统可以通过与人类的讨论提高准确性高达25%。 |
| [^89] | [Incorporating Attribution Importance for Improving Faithfulness Metrics.](http://arxiv.org/abs/2305.10496) | 本研究提出了一种软删除标准来评估归因方法的忠实度，该方法随机遮盖标记的部分向量表示，这种方法比现有的硬删除标准更准确。 |
| [^90] | [Qualifying Chinese Medical Licensing Examination with Knowledge Enhanced Generative Pre-training Model.](http://arxiv.org/abs/2305.10163) | 本研究通过在ChatGPT中集成医学领域知识和启用少样本学习的新方法，在中国国家医学执业医师资格考试中取得成功，这为建立在自然语言处理技术和医学领域知识的创新应用提供了可能。 |
| [^91] | [Active Continual Learning: Labelling Queries in a Sequence of Tasks.](http://arxiv.org/abs/2305.03923) | 本文考虑了一系列主动学习任务的主动连续学习问题，研究了不同场景下多种主动和连续学习算法之间的有效性和相互作用，并提出了遗忘-学习曲线方法来平衡不忘旧知识和快速学习的两个目标。 |
| [^92] | [Translationese Reduction using Abstract Meaning Representation.](http://arxiv.org/abs/2304.11501) | 研究使用抽象意义表示（AMR）作为跨语言方案可以减少翻译语言学数量。 |
| [^93] | [News and Load: A Quantitative Exploration of Natural Language Processing Applications for Forecasting Day-ahead Electricity System Demand.](http://arxiv.org/abs/2301.07535) | 本文利用自然语言处理技术研究了电力需求和社会事件之间的关联，并通过分析词频、公众情感、主题分布和词嵌入等文本特征，改进了次日的电力需求预测。研究结果提供了新的视角，证实了从非结构化文本中改进预测的可行性。 |
| [^94] | [Multi-modal Molecule Structure-text Model for Text-based Retrieval and Editing.](http://arxiv.org/abs/2212.10789) | 本论文介绍了一种名为MoleculeSTM的多模态分子结构-文本模型，通过联合学习化学结构和文本描述，可以实现基于文本的检索和编辑。通过构建大型的多模态数据集，并设计挑战性的零样本任务进行验证，该模型展示了开放词汇和组合性的特性。 |
| [^95] | [Localization vs. Semantics: Visual Representations in Unimodal and Multimodal Models.](http://arxiv.org/abs/2212.00281) | 本文比较分析了现有视觉与语言模型和仅视觉模型中的视觉表示，发现视觉与语言模型在标签预测任务上表现更好，而仅视觉模型在需要更局部信息的密集预测任务上表现更强。 |

# 详细

[^1]: MT-Ranker: 无参考机器翻译评估方法——通过系统间排名

    MT-Ranker: Reference-free machine translation evaluation by inter-system ranking. (arXiv:2401.17099v1 [cs.CL])

    [http://arxiv.org/abs/2401.17099](http://arxiv.org/abs/2401.17099)

    MT-Ranker 提出了一种无参考机器翻译评估方法，通过系统间排名来解决了传统用回归方法产生绝对翻译质量分数的不足，提供了更具解释性和一致性的评分结果，并在没有参考的情况下应用于实际场景中。

    

    传统上，机器翻译（MT）评估被视为回归问题，即产生一个绝对的翻译质量分数。这种方法存在两个限制：一是分数缺乏可解释性，人类标注员很难给出一致的分数；二是大多数评分方法基于（参考，翻译）对，限制了它们在实际场景中没有参考的情况下的适用性。实际上，我们常常关心一个新的MT系统是否比某些竞争对手更好或更差。此外，无参考MT评估在实践中越来越实用和必要。不幸的是，这两个实践考虑因素尚未共同探索。在这项工作中，我们将无参考MT评估转化为一个成对排名问题。给定源句子和一对翻译，我们的系统预测哪个翻译更好。除了提出这种新的公式，我们进一步证明了这种新的范式可以表现出更好的性能。

    Traditionally, Machine Translation (MT) Evaluation has been treated as a regression problem -- producing an absolute translation-quality score. This approach has two limitations: i) the scores lack interpretability, and human annotators struggle with giving consistent scores; ii) most scoring methods are based on (reference, translation) pairs, limiting their applicability in real-world scenarios where references are absent. In practice, we often care about whether a new MT system is better or worse than some competitors. In addition, reference-free MT evaluation is increasingly practical and necessary. Unfortunately, these two practical considerations have yet to be jointly explored. In this work, we formulate the reference-free MT evaluation into a pairwise ranking problem. Given the source sentence and a pair of translations, our system predicts which translation is better. In addition to proposing this new formulation, we further show that this new paradigm can demonstrate superior
    
[^2]: StrokeNUWA：用于矢量图形合成的笔画分词

    StrokeNUWA: Tokenizing Strokes for Vector Graphic Synthesis. (arXiv:2401.17093v1 [cs.CV])

    [http://arxiv.org/abs/2401.17093](http://arxiv.org/abs/2401.17093)

    StrokeNUWA是一个探索在矢量图形上更好的视觉表示的研究，引入了一种新的“笔画标记”表示方法，能够在矢量图形生成任务中显著提升性能。

    

    为了利用LLMs进行视觉合成，传统方法通过专门的视觉模块将光栅图像信息转换为离散的网格标记，从而破坏了模型捕捉视觉场景的真实语义表示的能力。本文认为，一种替代图像表示方法，即矢量图形，可以通过实现对图像信息更自然、更语义连贯的分割来有效克服这一限制。因此，我们引入了StrokeNUWA，这是一项开创性工作，探索在矢量图形上更好的视觉表示“笔画标记”，它本质上具有丰富的视觉语义，与LLMs自然兼容且高度压缩。配备笔画标记，StrokeNUWA在矢量图形生成任务中可以显著超越传统的基于LLM和优化方法，在各种指标上取得了非凡的成绩。此外，StrokeNUWA在推理方面的速度比之前的方法提高了94倍，并具有非常出色的SVG代码压缩。

    To leverage LLMs for visual synthesis, traditional methods convert raster image information into discrete grid tokens through specialized visual modules, while disrupting the model's ability to capture the true semantic representation of visual scenes. This paper posits that an alternative representation of images, vector graphics, can effectively surmount this limitation by enabling a more natural and semantically coherent segmentation of the image information. Thus, we introduce StrokeNUWA, a pioneering work exploring a better visual representation ''stroke tokens'' on vector graphics, which is inherently visual semantics rich, naturally compatible with LLMs, and highly compressed. Equipped with stroke tokens, StrokeNUWA can significantly surpass traditional LLM-based and optimization-based methods across various metrics in the vector graphic generation task. Besides, StrokeNUWA achieves up to a 94x speedup in inference over the speed of prior methods with an exceptional SVG code com
    
[^3]: NNOSE：最近邻职业技能提取

    NNOSE: Nearest Neighbor Occupational Skill Extraction. (arXiv:2401.17092v1 [cs.CL])

    [http://arxiv.org/abs/2401.17092](http://arxiv.org/abs/2401.17092)

    NNOSE是一种利用多个数据集有效提取职业技能的方法，通过检索其他数据集中的邻近技能来提高技能提取的性能，而无需进行额外的微调。

    

    劳动力市场正在快速变化，引发了对从文本中自动提取职业技能的增加兴趣。随着英语基准工作描述数据集的出现，需要处理它们的多样性的系统。我们解决了职业技能数据集任务中的复杂性，通过合并和利用多个数据集来提取技能，从而在数据集中识别少见的技能，并克服数据集间技能的稀缺性。特别地，我们研究了语言模型的检索增强，采用外部数据存储来以数据集统一的方式检索相似的技能。我们提出的方法NNOSE（Nearest Neighbor Occupational Skill Extraction）通过从数据存储中检索其他数据集中的邻近技能有效地利用多个数据集。这在不需要额外微调的情况下提高了技能提取的性能。

    The labor market is changing rapidly, prompting increased interest in the automatic extraction of occupational skills from text. With the advent of English benchmark job description datasets, there is a need for systems that handle their diversity well. We tackle the complexity in occupational skill datasets tasks -- combining and leveraging multiple datasets for skill extraction, to identify rarely observed skills within a dataset, and overcoming the scarcity of skills across datasets. In particular, we investigate the retrieval-augmentation of language models, employing an external datastore for retrieving similar skills in a dataset-unifying manner. Our proposed method, \textbf{N}earest \textbf{N}eighbor \textbf{O}ccupational \textbf{S}kill \textbf{E}xtraction (NNOSE) effectively leverages multiple datasets by retrieving neighboring skills from other datasets in the datastore. This improves skill extraction \emph{without} additional fine-tuning. Crucially, we observe a performance g
    
[^4]: SemScore: 基于语义文本相似度的指令调校大型语言模型的自动评估

    SemScore: Automated Evaluation of Instruction-Tuned LLMs based on Semantic Textual Similarity. (arXiv:2401.17072v1 [cs.CL])

    [http://arxiv.org/abs/2401.17072](http://arxiv.org/abs/2401.17072)

    这项研究提出了一个名为SemScore的评估指标，通过语义文本相似度直接比较模型输出和黄金目标回应，用于评估指令调校大型语言模型。实验证明，SemScore指标在与人工评估的相关性方面表现优于其他评估指标。

    

    最近，指令调校的大型语言模型（LLMs）在生成适合自然语言指令的回应方面展示出了令人瞩目的进展。然而，许多当前的研究依赖于手动评估来判断生成回应的质量。由于这种手动评估耗时，不容易扩展到对多个模型和模型变体的评估。在本短文中，我们提出了一种简单但非常有效的评估指标SemScore，通过语义文本相似度（STS）直接将模型输出与黄金目标回应进行比较。我们对12个知名的指令调校LLMs的模型输出进行了基于8个广泛使用的文本生成评估指标的比较评估。我们发现我们提出的SemScore指标在与人工评估的相关性方面优于所有其他、在许多情况下更复杂的评估指标。这些发现表明我们提出的指标对于评估指令调校LLMs的实用性。

    Instruction-tuned Large Language Models (LLMs) have recently showcased remarkable advancements in their ability to generate fitting responses to natural language instructions. However, many current works rely on manual evaluation to judge the quality of generated responses. Since such manual evaluation is time-consuming, it does not easily scale to the evaluation of multiple models and model variants. In this short paper, we propose a straightforward but remarkably effective evaluation metric called SemScore, in which we directly compare model outputs to gold target responses using semantic textual similarity (STS). We conduct a comparative evaluation of the model outputs of 12 prominent instruction-tuned LLMs using 8 widely-used evaluation metrics for text generation. We find that our proposed SemScore metric outperforms all other, in many cases more complex, evaluation metrics in terms of correlation to human evaluation. These findings indicate the utility of our proposed metric for 
    
[^5]: CRUD-RAG: 用于检索增强生成的大型语言模型的全面中文基准

    CRUD-RAG: A Comprehensive Chinese Benchmark for Retrieval-Augmented Generation of Large Language Models. (arXiv:2401.17043v1 [cs.CL])

    [http://arxiv.org/abs/2401.17043](http://arxiv.org/abs/2401.17043)

    这篇论文构建了一个大规模且更全面的中文基准测试，评估了检索增强生成系统的所有组件在各种应用场景中的性能。

    

    检索增强生成（RAG）是一种通过整合外部知识源来增强大型语言模型（LLM）能力的技术。该方法解决了LLM的常见限制，包括过时的信息和产生不准确的“虚构”内容的倾向。然而，评估RAG系统具有挑战性，因为现有的基准测试在范围和多样性上存在限制。大多数当前的基准测试主要评估问答应用，忽视了RAG可能有优势的更广泛的场景。此外，它们只评估RAG流程中LLM组件的性能，并忽视检索组件和外部知识数据库的影响。为了解决这些问题，本文构建了一个大规模且更全面的基准测试，并在各种RAG应用场景中评估了RAG系统的所有组件。

    Retrieval-Augmented Generation (RAG) is a technique that enhances the capabilities of large language models (LLMs) by incorporating external knowledge sources. This method addresses common LLM limitations, including outdated information and the tendency to produce inaccurate "hallucinated" content. However, the evaluation of RAG systems is challenging, as existing benchmarks are limited in scope and diversity. Most of the current benchmarks predominantly assess question-answering applications, overlooking the broader spectrum of situations where RAG could prove advantageous. Moreover, they only evaluate the performance of the LLM component of the RAG pipeline in the experiments, and neglect the influence of the retrieval component and the external knowledge database. To address these issues, this paper constructs a large-scale and more comprehensive benchmark, and evaluates all the components of RAG systems in various RAG application scenarios. Specifically, we have categorized the ran
    
[^6]: 向优雅互动迈进：执行动作对指示澄清请求建模策略的影响

    Taking Action Towards Graceful Interaction: The Effects of Performing Actions on Modelling Policies for Instruction Clarification Requests. (arXiv:2401.17039v1 [cs.CL])

    [http://arxiv.org/abs/2401.17039](http://arxiv.org/abs/2401.17039)

    执行动作作为辅助任务对于指示澄清请求（iCR）策略的学习贡献有限，但可以从预测的不确定性中提取信息。基于Transformer的模型在何时提问指示CR方面表现不佳，而何时提问的任务可以更成功地进行建模。

    

    澄清请求是解决指示遵循互动中的沟通问题（例如由于歧义或模糊不清）的一种机制。尽管它们很重要，但即使是熟练的模型也难以产生或解释这种修复行为。在这项工作中，我们测试了关于将动作作为辅助任务在建模iCR策略中的影响的三个假设。与最初的预期相反，我们得出结论，其对学习iCR策略的贡献有限，但仍然可以从预测的不确定性中提取一些信息。我们进一步提供证据，即即使是动机充分的基于Transformer的模型也无法学习到什么时候提问指示CR的良好策略，而决定何时提问可以更成功地进行建模。考虑到这些发现的影响，我们进一步讨论了基于数据驱动范式学习元通信行为的缺点。

    Clarification requests are a mechanism to help solve communication problems, e.g. due to ambiguity or underspecification, in instruction-following interactions. Despite their importance, even skilful models struggle with producing or interpreting such repair acts. In this work, we test three hypotheses concerning the effects of action taking as an auxiliary task in modelling iCR policies. Contrary to initial expectations, we conclude that its contribution to learning an iCR policy is limited, but some information can still be extracted from prediction uncertainty. We present further evidence that even well-motivated, Transformer-based models fail to learn good policies for when to ask Instruction CRs (iCRs), while the task of determining what to ask about can be more successfully modelled. Considering the implications of these findings, we further discuss the shortcomings of the data-driven paradigm for learning meta-communication acts.
    
[^7]: 辨别虚构声音：引文归属的作者验证模型研究

    Distinguishing Fictional Voices: a Study of Authorship Verification Models for Quotation Attribution. (arXiv:2401.16968v1 [cs.CL])

    [http://arxiv.org/abs/2401.16968](http://arxiv.org/abs/2401.16968)

    本文研究了辨别虚构声音的作者验证模型，通过在英语小说的语料库中对角色的引语进行风格表示。结果表明，在某些模型中，捕捉到的风格和主题信息能够准确区分不同的角色，但在归属引语方面并不一定比仅有语义的模型更好。

    

    最近自动检测直接引语的讲话者的方法常常忽视关于角色的一般信息，而倾向于上下文中找到的局部信息，例如周围实体的提及。在这项工作中，我们探索了对角色进行风格表示的方法，通过使用现成的预训练作者验证模型在英语小说的大语料库（项目对话小说语料库）中编码他们的引语。结果表明，在一些这些模型中捕捉到的风格和主题信息的组合能够准确地区分不同的角色，但当归因引语时，不一定优于仅有语义的模型。然而，这些结果在不同的小说中有所变化，因此需要进行更多专门针对文学文本和角色研究设计的文体测量模型的研究。

    Recent approaches to automatically detect the speaker of an utterance of direct speech often disregard general information about characters in favor of local information found in the context, such as surrounding mentions of entities. In this work, we explore stylistic representations of characters built by encoding their quotes with off-the-shelf pretrained Authorship Verification models in a large corpus of English novels (the Project Dialogism Novel Corpus). Results suggest that the combination of stylistic and topical information captured in some of these models accurately distinguish characters among each other, but does not necessarily improve over semantic-only models when attributing quotes. However, these results vary across novels and more investigation of stylometric models particularly tailored for literary texts and the study of characters should be conducted.
    
[^8]: 两个头胜于一: 为实体对齐整合知识图谱和大型语言模型的知识

    Two Heads Are Better Than One: Integrating Knowledge from Knowledge Graphs and Large Language Models for Entity Alignment. (arXiv:2401.16960v1 [cs.CL])

    [http://arxiv.org/abs/2401.16960](http://arxiv.org/abs/2401.16960)

    本研究提出了一种大型语言模型增强的实体对齐框架（LLMEA），将知识图谱中的结构知识与大型语言模型中的语义知识相结合，以提升实体对齐的效果。

    

    实体对齐是创建更全面的知识图谱的先决条件，涉及在不同的知识图谱中定位等价实体。目前的实体对齐方法主要利用知识嵌入模型获取包含各种相似性（结构、关系和属性）的实体嵌入。然后通过基于注意力的信息融合机制进行集成。尽管取得了一定的进展，但由于固有的异质性，有效利用多方面的信息仍然具有挑战性。此外，虽然大型语言模型（LLM）通过隐式捕捉实体语义，在各种下游任务上表现出色，但这种隐式知识尚未被用于实体对齐。在本研究中，我们提出了一个增强实体对齐的大型语言模型增强实体对齐框架（LLMEA），将知识图谱中的结构知识与LLM中的语义知识相结合，以增强实体对齐。

    Entity alignment, which is a prerequisite for creating a more comprehensive Knowledge Graph (KG), involves pinpointing equivalent entities across disparate KGs. Contemporary methods for entity alignment have predominantly utilized knowledge embedding models to procure entity embeddings that encapsulate various similarities-structural, relational, and attributive. These embeddings are then integrated through attention-based information fusion mechanisms. Despite this progress, effectively harnessing multifaceted information remains challenging due to inherent heterogeneity. Moreover, while Large Language Models (LLMs) have exhibited exceptional performance across diverse downstream tasks by implicitly capturing entity semantics, this implicit knowledge has yet to be exploited for entity alignment. In this study, we propose a Large Language Model-enhanced Entity Alignment framework (LLMEA), integrating structural knowledge from KGs with semantic knowledge from LLMs to enhance entity alig
    
[^9]: 跨语言转移研究：将低资源马耳他语视为多语言代码切换

    Cross-Lingual Transfer from Related Languages: Treating Low-Resource Maltese as Multilingual Code-Switching. (arXiv:2401.16895v1 [cs.CL])

    [http://arxiv.org/abs/2401.16895](http://arxiv.org/abs/2401.16895)

    本研究关注马耳他语这种混合语言，采用了一种新颖的数据集和分类器来提高跨语言转移能力，解决了混合语言文字差异的问题。

    

    尽管多语言语言模型在未见过的语言上表现出令人印象深刻的跨语言转移能力，但在与多语言模型的预训练数据中使用的语言存在文字差异时，其在下游任务中的性能受到影响。使用音译提供了一种直接而有效的方法，可以将资源丰富的语言的文字与目标语言的文字对齐，从而增强跨语言转移能力。然而，对于混合语言来说，这种方法并不是最佳选择，因为只有语言的某个子集从跨语言转移中受益，而其余部分受到阻碍。在这项工作中，我们专注于马耳他语，这是一种受到阿拉伯语、意大利语和英语重大影响，并且采用拉丁文脚本的闪米特语言。我们提供了一个新的数据集，其中包含了单词级别的词源学注释。我们使用这个数据集训练了一个分类器，使我们能够明智决策如何处理马耳他语的每个标记。

    Although multilingual language models exhibit impressive cross-lingual transfer capabilities on unseen languages, the performance on downstream tasks is impacted when there is a script disparity with the languages used in the multilingual model's pre-training data. Using transliteration offers a straightforward yet effective means to align the script of a resource-rich language with a target language, thereby enhancing cross-lingual transfer capabilities. However, for mixed languages, this approach is suboptimal, since only a subset of the language benefits from the cross-lingual transfer while the remainder is impeded. In this work, we focus on Maltese, a Semitic language, with substantial influences from Arabic, Italian, and English, and notably written in Latin script. We present a novel dataset annotated with word-level etymology. We use this dataset to train a classifier that enables us to make informed decisions regarding the appropriate processing of each token in the Maltese la
    
[^10]: 使用提示学习和自训练的低资源对话状态跟踪中的状态值生成

    State Value Generation with Prompt Learning and Self-Training for Low-Resource Dialogue State Tracking. (arXiv:2401.16862v1 [cs.CL])

    [http://arxiv.org/abs/2401.16862](http://arxiv.org/abs/2401.16862)

    提出了一种用于低资源对话状态跟踪的状态值生成框架，通过提示学习和自训练来改善状态值生成，并在实验中取得了最先进的性能。

    

    最近，低资源对话状态跟踪（DST）越来越受到关注。首先获取状态值，然后基于值来生成槽位类型在这项任务中取得了很大进展。然而，获取状态值仍然是一个未被深入研究的问题。现有的基于抽取的方法无法捕捉需要上下文理解的值，并且也不具有泛化性。为了解决这些问题，我们提出了一种基于状态值生成的新框架（SVAG），将DST分解为状态值生成和领域槽生成。具体而言，我们提出了生成状态值的方法，并使用自训练进一步改善状态值生成。此外，我们设计了一个估计器，旨在在自训练期间检测不完整生成和错误生成的伪标签数据选择。在MultiWOZ 2.1数据集上的实验结果表明，我们的方法只有不到10亿个参数，就实现了最先进的性能。

    Recently, low-resource dialogue state tracking (DST) has received increasing attention. First obtaining state values then based on values to generate slot types has made great progress in this task. However, obtaining state values is still an under-studied problem. Existing extraction-based approaches cannot capture values that require the understanding of context and are not generalizable either. To address these issues, we propose a novel State VAlue Generation based framework (SVAG), decomposing DST into state value generation and domain slot generation. Specifically, we propose to generate state values and use self-training to further improve state value generation. Moreover, we design an estimator aiming at detecting incomplete generation and incorrect generation for pseudo-labeled data selection during self-training. Experimental results on the MultiWOZ 2.1 dataset show that our method which has only less than 1 billion parameters achieves state-of-the-art performance under the d
    
[^11]: H2O-Danube-1.8B 技术报告

    H2O-Danube-1.8B Technical Report. (arXiv:2401.16818v1 [cs.CL])

    [http://arxiv.org/abs/2401.16818](http://arxiv.org/abs/2401.16818)

    H2O-Danube-1.8B 是一个在 1T 个标记上训练的 18 亿语言模型，具有高度竞争力的指标。同时，他们还发布了一个经过微调和优化训练的聊天模型，进一步推动语言模型的经济民主化。

    

    我们介绍了 H2O-Danube-1.8B，这是一个在 1T 个标记上训练的 18 亿语言模型，遵循 LLama 2 和 Mistral 的核心原则。我们利用和改进了各种大规模语言模型预训练的技术。尽管我们的模型训练所使用的总标记数量明显少于相似规模的参考模型，但它在众多基准测试中展现出了高度竞争力的指标。我们还发布了一个经过监督微调和直接偏好优化训练的聊天模型。我们以 Apache 2.0 许可证将 H2O-Danube-1.8B 开放，进一步推动 LLMs 的经济民主化，让更广泛的受众受益。

    We present H2O-Danube-1.8B, a 1.8B language model trained on 1T tokens following the core principles of LLama 2 and Mistral. We leverage and refine various techniques for pre-training large language models. Although our model is trained on significantly fewer total tokens compared to reference models of similar size, it exhibits highly competitive metrics across a multitude of benchmarks. We additionally release a chat model trained with supervised fine-tuning followed by direct preference optimization. We make H2O-Danube-1.8B openly available under Apache 2.0 license further democratizing LLMs to a wider audience economically.
    
[^12]: 大型语言模型作为评估者是否可信？通过代理辩论进行可扩展的元评估来评估LLMs

    Can Large Language Models be Trusted for Evaluation? Scalable Meta-Evaluation of LLMs as Evaluators via Agent Debate. (arXiv:2401.16788v1 [cs.CL])

    [http://arxiv.org/abs/2401.16788](http://arxiv.org/abs/2401.16788)

    本论文提出了ScaleEval，一个基于代理辩论的元评估框架，通过利用多个交流型LLM代理的能力来有效、可靠、高效地评估LLMs在不同任务和场景中作为评估者的性能。

    

    尽管大型语言模型（LLMs）在各种任务和场景中具有实用性，但要在不同的上下文中可靠地评估LLMs仍然具有挑战性。现代评估方法通常使用LLMs来评估LLMs生成的响应。然而，用于评估这些LLMs作为评估者的元评估通常受现有基准的覆盖范围限制，或者需要大量的人工标注。这凸显了迫切需要可扩展的元评估方法，能够有效、可靠、高效地评估LLMs在各种任务和场景中作为评估者的性能，特别是在潜在的新的、用户定义的场景中。为了填补这一空白，我们提出了ScaleEval，这是一个代理辩论辅助的元评估框架，利用多个交流型LLM代理的能力。这个框架支持多轮讨论，以帮助人工标注者判断最具能力的

    Despite the utility of Large Language Models (LLMs) across a wide range of tasks and scenarios, developing a method for reliably evaluating LLMs across varied contexts continues to be challenging. Modern evaluation approaches often use LLMs to assess responses generated by LLMs. However, the meta-evaluation conducted to assess the effectiveness of these LLMs as evaluators is typically constrained by the coverage of existing benchmarks or requires extensive human annotation. This underscores the urgency of methods for scalable meta-evaluation that can effectively, reliably, and efficiently evaluate the performance of LLMs as evaluators across diverse tasks and scenarios, particularly in potentially new, user-defined scenarios. To fill this gap, we propose ScaleEval, an agent-debate-assisted meta-evaluation framework that leverages the capabilities of multiple communicative LLM agents. This framework supports multi-round discussions to assist human annotators in discerning the most capab
    
[^13]: 在孟加拉语中检测种族主义文本：一种集成深度学习框架

    Detecting Racist Text in Bengali: An Ensemble Deep Learning Framework. (arXiv:2401.16748v1 [cs.CL])

    [http://arxiv.org/abs/2401.16748](http://arxiv.org/abs/2401.16748)

    本文提出了一种检测孟加拉语中种族主义文本的集成深度学习框架，成功实现了87.94%的准确率。模型的最佳表现是使用MCNN-LSTM模型，并采用BERT嵌入和RNN/LSTM模型进行训练。最终采用集成方法来提高整体性能。

    

    种族主义是我们国家以及全世界的一个令人担忧的现象。每天我们在日常生活和虚拟生活中都会遇到一些种族主义言论。虽然我们可以在虚拟生活中消除这种种族主义（例如社交媒体），但在本文中，我们尝试使用自然语言处理和深度学习技术来检测这些种族主义言论。我们建立了一个新颖的孟加拉语数据集。此外，我们对数据集进行了标注并进行了数据标签验证。经过广泛利用深度学习方法，我们使用集成方法成功实现了87.94％的文本检测准确率。我们使用BERT嵌入应用了RNN和LSTM模型。然而，在所有这些模型中，MCNN-LSTM模型表现最好。最后，采用集成方法来结合所有模型结果，以提高整体性能。

    Racism is an alarming phenomenon in our country as well as all over the world. Every day we have come across some racist comments in our daily life and virtual life. Though we can eradicate this racism from virtual life (such as Social Media). In this paper, we have tried to detect those racist comments with NLP and deep learning techniques. We have built a novel dataset in the Bengali Language. Further, we annotated the dataset and conducted data label validation. After extensive utilization of deep learning methodologies, we have successfully achieved text detection with an impressive accuracy rate of 87.94\% using the Ensemble approach. We have applied RNN and LSTM models using BERT Embeddings. However, the MCNN-LSTM model performed highest among all those models. Lastly, the Ensemble approach has been followed to combine all the model results to increase overall performance.
    
[^14]: MT-Eval：面向大型语言模型的多轮能力评估基准

    MT-Eval: A Multi-Turn Capabilities Evaluation Benchmark for Large Language Models. (arXiv:2401.16745v1 [cs.CL])

    [http://arxiv.org/abs/2401.16745](http://arxiv.org/abs/2401.16745)

    MT-Eval是一个用于评估大型语言模型多轮对话能力的综合性基准，通过分析人类-LLM对话，将交互模式分为四类，并创建了多轮查询来评估模型的性能。

    

    大型语言模型(LLMs)在各种真实场景下越来越多地用于复杂的多轮对话。然而，现有的评估基准主要集中在单轮评估上，忽视了模型在多轮交互中的能力。为了填补这一空白，我们引入了MT-Eval，一个综合性的基准用于评估多轮对话能力。通过分析人类-LLM对话，我们将交互模式分为四类：回忆、扩展、修改和跟进。我们通过增加现有数据集或使用GPT-4创建新的示例构建了每个类别的多轮查询，以避免数据泄漏。为了研究影响多轮能力的因素，我们创建了1170个多轮查询的单轮版本，并进行了性能比较。我们对11个知名LLM进行评估表明，尽管闭源模型通常优于开源模型，但某些开源模型超过了GPT-3.5-Turbo。

    Large language models (LLMs) are increasingly relied upon for complex multi-turn conversations across diverse real-world applications. However, existing benchmarks predominantly focus on single-turn evaluations, overlooking the models' capabilities in multi-turn interactions. To address this gap, we introduce MT-Eval, a comprehensive benchmark designed to evaluate multi-turn conversational abilities. By analyzing human-LLM conversations, we categorize interaction patterns into four types: recollection, expansion, refinement, and follow-up. We construct multi-turn queries for each category either by augmenting existing datasets or by creating new examples with GPT-4 to avoid data leakage. To study the factors impacting multi-turn abilities, we create single-turn versions of the 1170 multi-turn queries and compare performance. Our evaluation of 11 well-known LLMs shows that while closed-source models generally surpass open-source ones, certain open-source models exceed GPT-3.5-Turbo in s
    
[^15]: 从零开始构建一个大型语言模型

    Engineering A Large Language Model From Scratch. (arXiv:2401.16736v1 [cs.CL])

    [http://arxiv.org/abs/2401.16736](http://arxiv.org/abs/2401.16736)

    Atinuke是一种基于Transformer的神经网络，通过在处理时序数据的层与注意机制交织在一起，模拟人类语言，从而优化各种语言任务的性能。

    

    深度学习在自然语言处理（NLP）领域的普及导致了能够理解和生成人类语言的创新技术的开发和发布。Atinuke是一种基于Transformer的神经网络，通过利用独特的配置，在各种语言任务上优化性能。该架构通过将处理时序数据的层与注意机制交织在一起，从而在输入和输出之间建立有意义的关联。由于其拓扑结构和超参数调整的配置，它可以提取特征并学习复杂的映射，从而模仿人类语言。Atinuke是模块化、可扩展的，并可以与现有的机器学习流程无缝集成。softmax、嵌入和多头注意力等高级矩阵操作使得对文本、声音和视觉信号的细致处理成为可能。通过将现代深度学习技术与软件设计原则和数学方法相结合

    The proliferation of deep learning in natural language processing (NLP) has led to the development and release of innovative technologies capable of understanding and generating human language with remarkable proficiency. Atinuke, a Transformer-based neural network, optimises performance across various language tasks by utilising a unique configuration. The architecture interweaves layers for processing sequential data with attention mechanisms to draw meaningful affinities between inputs and outputs. Due to the configuration of its topology and hyperparameter tuning, it can emulate human-like language by extracting features and learning complex mappings. Atinuke is modular, extensible, and integrates seamlessly with existing machine learning pipelines. Advanced matrix operations like softmax, embeddings, and multi-head attention enable nuanced handling of textual, acoustic, and visual signals. By unifying modern deep learning techniques with software design principles and mathematical
    
[^16]: 为语言模型中的神经元生成信息性文本描述的研究

    Towards Generating Informative Textual Description for Neurons in Language Models. (arXiv:2401.16731v1 [cs.CL])

    [http://arxiv.org/abs/2401.16731](http://arxiv.org/abs/2401.16731)

    本文提出了一种新颖而可伸缩的框架，将文本描述与语言模型中的神经元联系起来，从而解释模型中理解的信息。通过使用生成语言模型发现人可解释的描述符，并使用无监督方法解释神经元，通过定性和定量分析证明了该方法的有效性。

    

    近期基于Transformer的语言模型的发展使其能够捕捉到各种世界知识并适应具有有限资源的下游任务。然而，这些模型理解哪些信息尚不清楚，而在识别它们方面的神经元级贡献基本上是未知的。神经元解释的传统方法要么依赖于有限的预定义描述符，要么需要手动注释以训练一个能够解释主模型神经元的次要模型。本文以BERT为例，尝试摆脱这些限制，提出了一种新颖而可伸缩的框架，将文本描述与神经元联系起来。我们利用生成语言模型的潜力，在数据集中发现人可解释的描述符，并使用无监督方法解释带有这些描述符的神经元。通过各种定性和定量分析，我们展示了这种方法的有效性。

    Recent developments in transformer-based language models have allowed them to capture a wide variety of world knowledge that can be adapted to downstream tasks with limited resources. However, what pieces of information are understood in these models is unclear, and neuron-level contributions in identifying them are largely unknown. Conventional approaches in neuron explainability either depend on a finite set of pre-defined descriptors or require manual annotations for training a secondary model that can then explain the neurons of the primary model. In this paper, we take BERT as an example and we try to remove these constraints and propose a novel and scalable framework that ties textual descriptions to neurons. We leverage the potential of generative language models to discover human-interpretable descriptors present in a dataset and use an unsupervised approach to explain neurons with these descriptors. Through various qualitative and quantitative analyses, we demonstrate the effe
    
[^17]: 最近在仇恨言论审核方面的进展：多模态和大型模型的作用

    Recent Advances in Hate Speech Moderation: Multimodality and the Role of Large Models. (arXiv:2401.16727v1 [cs.CL])

    [http://arxiv.org/abs/2401.16727](http://arxiv.org/abs/2401.16727)

    这项综合调查总结了最近在仇恨言论审核方面的进展，重点介绍了大型语言模型和大型多模态模型的作用。研究发现了文本、视觉和听觉元素在传播仇恨言论中的微妙相互作用，并强调了大型模型对审核能力的重新定义。同时，研究还指出了在少数语言和文化背景下的研究差距和处理低资源环境的需求。

    

    在网络交流的不断发展中，审核仇恨言论（HS）面临着复杂的挑战，这是由数字内容的多模态特性所带来的。这项综合调查深入研究了HS审核的最新进展，着重介绍了大型语言模型（LLMs）和大型多模态模型（LMMs）的崛起角色。我们的研究从对当前文献的全面分析开始，揭示了文本、视觉和听觉元素在传播HS中的微妙相互作用。我们发现了一个明显的趋势，即将这些模态整合在一起，主要是因为HS的传播具有复杂性和微妙性。对于由LLMs和LMMs带来的进展，我们特别强调了其对检测和审核能力边界的重新定义。我们确定了研究中存在的现有差距，特别是在少数语言和文化的背景下，以及在处理低资源环境中需要解决方案的需求。

    In the evolving landscape of online communication, moderating hate speech (HS) presents an intricate challenge, compounded by the multimodal nature of digital content. This comprehensive survey delves into the recent strides in HS moderation, spotlighting the burgeoning role of large language models (LLMs) and large multimodal models (LMMs). Our exploration begins with a thorough analysis of current literature, revealing the nuanced interplay between textual, visual, and auditory elements in propagating HS. We uncover a notable trend towards integrating these modalities, primarily due to the complexity and subtlety with which HS is disseminated. A significant emphasis is placed on the advances facilitated by LLMs and LMMs, which have begun to redefine the boundaries of detection and moderation capabilities. We identify existing gaps in research, particularly in the context of underrepresented languages and cultures, and the need for solutions to handle low-resource settings. The survey
    
[^18]: 利用大型语言模型和层群理论检测不一致性的前景

    Prospects for inconsistency detection using large language models and sheaves. (arXiv:2401.16713v1 [cs.CY])

    [http://arxiv.org/abs/2401.16713](http://arxiv.org/abs/2401.16713)

    利用大型语言模型进行逻辑一致性评估，并采用层群理论方法将其扩展到法律、司法和社交媒体等超文本中进行全局评估，有助于提高政府的一致性并应对误导信息和相关问题。

    

    我们证明大型语言模型可以对逻辑一致性进行合理的数值评估。我们还概述了一种基于层群理论的数学方法，将这些评估提升到法律、司法和社交媒体等超文本中，并全局评估它们的一致性。这种方法有望增强政府的一致性，以及打击误导信息和相关问题。

    We demonstrate that large language models can produce reasonable numerical ratings of the logical consistency of claims. We also outline a mathematical approach based on sheaf theory for lifting such ratings to hypertexts such as laws, jurisprudence, and social media and evaluating their consistency globally. This approach is a promising avenue to increasing consistency in and of government, as well as to combating mis- and disinformation and related ills.
    
[^19]: 虚构话语的检测与理解

    The Detection and Understanding of Fictional Discourse. (arXiv:2401.16678v1 [cs.CL])

    [http://arxiv.org/abs/2401.16678](http://arxiv.org/abs/2401.16678)

    本文介绍了虚构话语检测的分类实验，利用了多样的数据集和新的特征集。虚构话语的检测有助于丰富大型文化遗产档案，并帮助更广泛地理解虚构叙事的特质。

    

    本文介绍了与虚构话语检测任务相关的分类实验。我们利用了各种各样的数据集，包括当代专业出版的小说、来自Hathi Trust的历史小说、粉丝所写文、来自Reddit的故事、民间传说、GPT生成的故事以及英语世界文学作品。此外，我们还引入了一组新的“超词义”特征集，以促进语义概括的目标。虚构话语的检测可以帮助丰富我们对大型文化遗产档案的了解，并有助于更广泛地理解虚构叙事的独特特质。

    In this paper, we present a variety of classification experiments related to the task of fictional discourse detection. We utilize a diverse array of datasets, including contemporary professionally published fiction, historical fiction from the Hathi Trust, fanfiction, stories from Reddit, folk tales, GPT-generated stories, and anglophone world literature. Additionally, we introduce a new feature set of word "supersenses" that facilitate the goal of semantic generalization. The detection of fictional discourse can help enrich our knowledge of large cultural heritage archives and assist with the process of understanding the distinctive qualities of fictional storytelling more broadly.
    
[^20]: 历史感知的对话式稠密检索

    History-Aware Conversational Dense Retrieval. (arXiv:2401.16659v1 [cs.IR])

    [http://arxiv.org/abs/2401.16659](http://arxiv.org/abs/2401.16659)

    该论文提出了一种历史感知的对话式稠密检索系统，通过上下文去噪的查询重构以及根据历史轮次的实际影响自动挖掘监督信号改进了现有的对话式稠密检索方法。

    

    对话搜索通过实现用户和系统之间的多轮交互，实现了复杂信息检索的便利。支持这种交互需要对对话输入有全面的理解，以便根据历史信息制定良好的搜索查询。特别是，搜索查询应包括来自先前对话回合的相关信息。然而，目前的对话式稠密检索方法主要依赖于对经过精调的预训练专门检索器进行整个对话式搜索会话的优化，这可能会变得冗长和嘈杂。此外，现有方法受现有数据集中手动监督信号数量的限制。为了解决上述问题，我们提出了一种历史感知的对话式稠密检索(HAConvDR)系统，它结合了两个思想：上下文去噪的查询重构和根据历史轮次的实际影响进行自动挖掘监督信号。

    Conversational search facilitates complex information retrieval by enabling multi-turn interactions between users and the system. Supporting such interactions requires a comprehensive understanding of the conversational inputs to formulate a good search query based on historical information. In particular, the search query should include the relevant information from the previous conversation turns. However, current approaches for conversational dense retrieval primarily rely on fine-tuning a pre-trained ad-hoc retriever using the whole conversational search session, which can be lengthy and noisy. Moreover, existing approaches are limited by the amount of manual supervision signals in the existing datasets. To address the aforementioned issues, we propose a History-Aware Conversational Dense Retrieval (HAConvDR) system, which incorporates two ideas: context-denoised query reformulation and automatic mining of supervision signals based on the actual impact of historical turns. Experime
    
[^21]: OWSM v3.1: 基于E-Branchformer的更好和更快的开放式Whisper风格语音模型

    OWSM v3.1: Better and Faster Open Whisper-Style Speech Models based on E-Branchformer. (arXiv:2401.16658v1 [cs.CL])

    [http://arxiv.org/abs/2401.16658](http://arxiv.org/abs/2401.16658)

    该论文介绍了OWSM v3.1基于E-Branchformer的更好和更快的开放式Whisper风格语音模型。这个模型通过提高性能和效率，超越了之前的版本，并实现了更快的推理速度。该论文还公开发布了相关的数据和模型。

    

    最近的研究倡导采用完全开放的基础模型来推动透明度和开放科学。作为一个初步的步骤，开放式Whisper风格语音模型(OWSM)使用公开可用的数据和开源工具重新复制了OpenAI的Whisper。为了复制Whisper，之前的OWSM v1到v3模型仍然基于Transformer，这可能导致性能不如其他最先进的语音编码器。在这项工作中，我们旨在提高OWSM的性能和效率，而无需额外的训练数据。我们提出了基于E-Branchformer的OWSM v3.1模型，有两个规模，即100M和1B。1B模型是目前公开可用的最大的基于E-Branchformer的语音模型。它在大部分评估基准上表现出比之前的OWSM v3更好的性能，同时演示了高达25%的更快推理速度。我们公开发布数据准备脚本、预训练模型和训练日志。

    Recent studies have advocated for fully open foundation models to promote transparency and open science. As an initial step, the Open Whisper-style Speech Model (OWSM) reproduced OpenAI's Whisper using publicly available data and open-source toolkits. With the aim of reproducing Whisper, the previous OWSM v1 through v3 models were still based on Transformer, which might lead to inferior performance compared to other state-of-the-art speech encoders. In this work, we aim to improve the performance and efficiency of OWSM without extra training data. We present E-Branchformer based OWSM v3.1 models at two scales, i.e., 100M and 1B. The 1B model is the largest E-Branchformer based speech model that has been made publicly available. It outperforms the previous OWSM v3 in a vast majority of evaluation benchmarks, while demonstrating up to 25% faster inference speed. We publicly release the data preparation scripts, pre-trained models and training logs.
    
[^22]: 从大型语言模型中通过马尔可夫链蒙特卡洛恢复心智表示

    Recovering Mental Representations from Large Language Models with Markov Chain Monte Carlo. (arXiv:2401.16657v1 [cs.AI])

    [http://arxiv.org/abs/2401.16657](http://arxiv.org/abs/2401.16657)

    本文研究了使用马尔可夫链蒙特卡洛（MCMC）方法从大型语言模型中恢复心智表示的方法，并且发现使用基于MCMC的自适应采样算法可以显著提高效率和性能，这对于进行贝叶斯推理具有潜在意义。

    

    通过模拟采样算法进行人类研究已被证明是一种有效的方法，可以高效地探索和理解其心智表示。我们提出相同的方法可以用来研究大型语言模型（LLMs）的表示。虽然人类或LLMs都可以通过内省的方式直接揭示其心智表示，但我们表明，使用LLMs作为一种采样算法的元素可以提高效率。我们探索了在使用直接采样和马尔可夫链蒙特卡洛（MCMC）进行LLMs插问时恢复人类化表示程度的程度。我们发现使用基于MCMC的自适应采样算法可以显著提高效率和性能。我们还强调了我们的方法潜力，可以产生一种更通用的使用LLMs进行贝叶斯推理的方法。

    Simulating sampling algorithms with people has proven a useful method for efficiently probing and understanding their mental representations. We propose that the same methods can be used to study the representations of Large Language Models (LLMs). While one can always directly prompt either humans or LLMs to disclose their mental representations introspectively, we show that increased efficiency can be achieved by using LLMs as elements of a sampling algorithm. We explore the extent to which we recover human-like representations when LLMs are interrogated with Direct Sampling and Markov chain Monte Carlo (MCMC). We found a significant increase in efficiency and performance using adaptive sampling algorithms based on MCMC. We also highlight the potential of our method to yield a more general method of conducting Bayesian inference \textit{with} LLMs.
    
[^23]: 基于梯度的语言模型红队测试

    Gradient-Based Language Model Red Teaming. (arXiv:2401.16656v1 [cs.CL])

    [http://arxiv.org/abs/2401.16656](http://arxiv.org/abs/2401.16656)

    本文介绍了一种基于梯度的语言模型红队测试（GBRT）方法，通过自动生成的多样化提示来触发语言模型生成不安全回应。通过使用安全分类器评分和反向传播来更新提示，GBRT在发现触发语言模型生成不安全回应的提示方面更加有效。

    

    红队测试是一种常见的策略，用于识别生成式语言模型中的弱点，通过产生对抗性提示来触发语言模型生成不安全的回应。红队测试对于模型对齐和评估都非常重要，但由于需要人工操作，劳动强度大且难以扩展。本文提出了一种基于梯度的红队测试（GBRT）方法，用于自动生成多样化的提示，能够引起语言模型输出不安全的回应。GBRT是一种提示学习方法，通过使用安全分类器对语言模型的响应进行评分，并通过冻结的安全分类器和语言模型进行反向传播来更新提示。为了提高输入提示的连贯性，我们引入了两个变种，通过添加真实性损失和微调预训练模型来生成提示，而不是直接学习提示。实验证明，GBRT能够更有效地找到能够触发语言模型生成不安全回应的提示。

    Red teaming is a common strategy for identifying weaknesses in generative language models (LMs), where adversarial prompts are produced that trigger an LM to generate unsafe responses. Red teaming is instrumental for both model alignment and evaluation, but is labor-intensive and difficult to scale when done by humans. In this paper, we present Gradient-Based Red Teaming (GBRT), a red teaming method for automatically generating diverse prompts that are likely to cause an LM to output unsafe responses. GBRT is a form of prompt learning, trained by scoring an LM response with a safety classifier and then backpropagating through the frozen safety classifier and LM to update the prompt. To improve the coherence of input prompts, we introduce two variants that add a realism loss and fine-tune a pretrained model to generate the prompts instead of learning the prompts directly. Our experiments show that GBRT is more effective at finding prompts that trigger an LM to generate unsafe responses 
    
[^24]: 大型语言模型中的不连贯概率判断

    Incoherent Probability Judgments in Large Language Models. (arXiv:2401.16646v1 [cs.CL])

    [http://arxiv.org/abs/2401.16646](http://arxiv.org/abs/2401.16646)

    在本论文中，研究人员通过对大型语言模型(LLMs)进行实验证明，这些模型产生的概率判断经常是不连贯的，显示出类似于人类一样的非理性偏差。他们还提出了将自回归LLMs与隐性贝叶斯推断联系起来的解释。

    

    针对下一个词预测训练的自回归大型语言模型(LLMs)展示出出色的连贯文本生成能力。但它们是否同样擅长形成连贯的概率判断？我们使用概率身份和重复判断来评估LLMs生成的概率判断的连贯性。我们的结果显示，这些模型产生的判断经常是不连贯的，显示出人类一样的概率理论规则偏离。此外，当要求对同一事件进行判断时，LLMs产生的概率判断的均值-方差关系呈现出人类所见到的倒U形状。我们提出这些非理性的偏离可以通过将自回归LLMs与隐性贝叶斯推断联系起来，并与人类概率判断的贝叶斯抽样器模型进行类比来解释。

    Autoregressive Large Language Models (LLMs) trained for next-word prediction have demonstrated remarkable proficiency at producing coherent text. But are they equally adept at forming coherent probability judgments? We use probabilistic identities and repeated judgments to assess the coherence of probability judgments made by LLMs. Our results show that the judgments produced by these models are often incoherent, displaying human-like systematic deviations from the rules of probability theory. Moreover, when prompted to judge the same event, the mean-variance relationship of probability judgments produced by LLMs shows an inverted-U-shaped like that seen in humans. We propose that these deviations from rationality can be explained by linking autoregressive LLMs to implicit Bayesian inference and drawing parallels with the Bayesian Sampler model of human probability judgments.
    
[^25]: TeenyTinyLlama：基于巴西葡萄牙语训练的开源微型语言模型

    TeenyTinyLlama: open-source tiny language models trained in Brazilian Portuguese. (arXiv:2401.16640v1 [cs.CL])

    [http://arxiv.org/abs/2401.16640](http://arxiv.org/abs/2401.16640)

    这篇论文开发了用于低资源环境中的开放式基础模型，以巴西葡萄牙语为例，发布在GitHub和Hugging Face上供社区使用和进一步开发。

    

    大型语言模型（LLMs）在自然语言处理方面取得了显著的进展，但在各种语言中的进展还不平衡。虽然大多数LLMs是在像英语这样的高资源语言中训练的，但多语言模型通常比单语言模型表现稍差。此外，它们的多语言基础有时会限制它们产生的副产品，如计算需求和许可制度。在本研究中，我们记录了为在低资源环境中使用而量身定制的开放式基础模型的开发过程、其局限性和优势。这就是TeenyTinyLlama：两个用于巴西葡萄牙语文本生成的紧凑型模型。我们在GitHub和Hugging Face上以宽松的Apache 2.0许可证发布它们，供社区使用和进一步开发。详见https://github.com/Nkluge-correa/TeenyTinyLlama

    Large language models (LLMs) have significantly advanced natural language processing, but their progress has yet to be equal across languages. While most LLMs are trained in high-resource languages like English, multilingual models generally underperform monolingual ones. Additionally, aspects of their multilingual foundation sometimes restrict the byproducts they produce, like computational demands and licensing regimes. In this study, we document the development of open-foundation models tailored for use in low-resource settings, their limitations, and their benefits. This is the TeenyTinyLlama pair: two compact models for Brazilian Portuguese text generation. We release them under the permissive Apache 2.0 license on GitHub and Hugging Face for community use and further development. See https://github.com/Nkluge-correa/TeenyTinyLlama
    
[^26]: 打破Transformer模型的束缚：任务特定的上下文归因提供了在不微调预训练LLMs的情况下提高泛化性能的承诺

    Breaking Free Transformer Models: Task-specific Context Attribution Promises Improved Generalizability Without Fine-tuning Pre-trained LLMs. (arXiv:2401.16638v1 [cs.CL])

    [http://arxiv.org/abs/2401.16638](http://arxiv.org/abs/2401.16638)

    本文提出了一种框架，通过任务特定的上下文归因来提高模型在下游任务中的性能，而不需要对预训练的语言模型进行微调，从而保持了模型的泛化性能。

    

    在自然语言处理（NLP）分类任务中，对特定数据集进行大型预训练语言模型（LLMs）的微调是一种常用策略。然而，这种方法通常会导致模型的泛化性能下降。在本文中，我们提出了一个框架，通过利用任务特定的上下文归因，实现了泛化性能的保持，并提升了下游任务的性能。我们展示了任何Transformer模型的文本表示的线性变换，使用任务特定的概念运算符，会得到一个投影到潜在概念空间上的结果，本文中称之为上下文归因。特定的概念运算符在监督学习阶段通过新颖的损失函数进行优化。所提出的框架表明，对于每个任务目标的文本表示进行上下文归因可以改善鉴别器函数的能力，从而实现更好的分类性能。

    Fine-tuning large pre-trained language models (LLMs) on particular datasets is a commonly employed strategy in Natural Language Processing (NLP) classification tasks. However, this approach usually results in a loss of models generalizability. In this paper, we present a framework that allows for maintaining generalizability, and enhances the performance on the downstream task by utilizing task-specific context attribution. We show that a linear transformation of the text representation from any transformer model using the task-specific concept operator results in a projection onto the latent concept space, referred to as context attribution in this paper. The specific concept operator is optimized during the supervised learning stage via novel loss functions. The proposed framework demonstrates that context attribution of the text representation for each task objective can improve the capacity of the discriminator function and thus achieve better performance for the classification tas
    
[^27]: 通过高效的奖励模型集成改进人工反馈强化学习

    Improving Reinforcement Learning from Human Feedback with Efficient Reward Model Ensemble. (arXiv:2401.16635v1 [cs.LG])

    [http://arxiv.org/abs/2401.16635](http://arxiv.org/abs/2401.16635)

    本论文提出一种通过高效的奖励模型集成来改进人工反馈强化学习的方法，以解决由于奖励模型预测不准确而导致RLHF输出与人类价值观不一致的问题。

    

    人工反馈强化学习（RLHF）是一种广泛使用的方法，用于将大型语言模型与人类价值观对齐。然而，RLHF依赖于通过有限的人类偏好数据训练的奖励模型，这可能导致不准确的预测。因此，RLHF可能产生与人类价值观不一致的输出。为了缓解这个问题，我们提出了一种奖励集成方法，可以使奖励模型做出更准确的预测。考虑到使用基于大型语言模型的奖励模型集成可能具有计算和资源昂贵的问题，我们探索了包括线性层集成和基于LoRA的集成在内的高效集成方法。实证上，我们使用我们的集成奖励模型运行Best-of-$n$和Proximal Policy Optimization，并验证我们的集成方法有助于改善RLHF输出的对齐性能。

    Reinforcement Learning from Human Feedback (RLHF) is a widely adopted approach for aligning large language models with human values. However, RLHF relies on a reward model that is trained with a limited amount of human preference data, which could lead to inaccurate predictions. As a result, RLHF may produce outputs that are misaligned with human values. To mitigate this issue, we contribute a reward ensemble method that allows the reward model to make more accurate predictions. As using an ensemble of large language model-based reward models can be computationally and resource-expensive, we explore efficient ensemble methods including linear-layer ensemble and LoRA-based ensemble. Empirically, we run Best-of-$n$ and Proximal Policy Optimization with our ensembled reward models, and verify that our ensemble methods help improve the alignment performance of RLHF outputs.
    
[^28]: ToPro: 跨语言序列标注任务的基于Token级别的提示分解

    ToPro: Token-Level Prompt Decomposition for Cross-Lingual Sequence Labeling Tasks. (arXiv:2401.16589v1 [cs.CL])

    [http://arxiv.org/abs/2401.16589](http://arxiv.org/abs/2401.16589)

    这项研究提出了一种名为ToPro的方法，用于跨语言序列标注任务。该方法通过将输入句子分解为单个词汇并应用提示模板，在零样本跨语言转移中实现了优于其他微调方法的性能，并在结构不同的语言上取得了最先进的结果。

    

    基于提示的方法已成功应用于多语言预训练语言模型的零样本跨语言理解。然而，大多数之前的研究主要关注句子级别的分类任务，只有少数考虑到了词汇级别的标注任务，如命名实体识别（NER）和词性标注（POS）。在本文中，我们提出了基于Token级别的提示分解（ToPro），该方法可用于词汇级别的序列标注任务。ToPro方法将输入句子分解为单个词汇，并对每个词汇应用一个提示模板。我们在多语言NER和POS标注数据集上的实验表明，基于ToPro的微调在零样本跨语言转移中优于Vanilla微调和Prompt-Tuning，尤其对于结构与源语言英语不同的语言。我们的方法在使用mT5模型时也获得了最先进的性能。

    Prompt-based methods have been successfully applied to multilingual pretrained language models for zero-shot cross-lingual understanding. However, most previous studies primarily focused on sentence-level classification tasks, and only a few considered token-level labeling tasks such as Named Entity Recognition (NER) and Part-of-Speech (POS) tagging. In this paper, we propose Token-Level Prompt Decomposition (ToPro), which facilitates the prompt-based method for token-level sequence labeling tasks. The ToPro method decomposes an input sentence into single tokens and applies one prompt template to each token. Our experiments on multilingual NER and POS tagging datasets demonstrate that ToPro-based fine-tuning outperforms Vanilla fine-tuning and Prompt-Tuning in zero-shot cross-lingual transfer, especially for languages that are typologically different from the source language English. Our method also attains state-of-the-art performance when employed with the mT5 model. Besides, our exp
    
[^29]: 人类与ChatGPT生成对话之间的语言对比

    A Linguistic Comparison between Human and ChatGPT-Generated Conversations. (arXiv:2401.16587v1 [cs.CL])

    [http://arxiv.org/abs/2401.16587](http://arxiv.org/abs/2401.16587)

    本研究比较了人类和ChatGPT生成的对话的语言差异，发现ChatGPT在社交、分析、认知、关注焦点和积极情绪等方面表现出色，但人类对话更具变异性和真实性，尽管在情绪方面无显著差异。同时，该研究还提供了一个新颖的、由ChatGPT生成的对话组成的数据集。

    

    本研究探讨了人类和LLM生成的对话之间的语言差异，使用了由ChatGPT-3.5生成的19.5K个对话作为EmpathicDialogues数据集的补充。研究采用Linguistic Inquiry and Word Count (LIWC) 分析，比较了ChatGPT生成的对话和人类对话在118个语言类别上的差异。结果显示人类对话具有更大的变异性和真实性，但ChatGPT在社交过程、分析风格、认知、关注焦点和积极情绪色彩等方面表现出色，这进一步证明了LLMs“比真人更像真人”的最新发现。然而，在ChatGPT和人类对话之间没有找到积极或消极情绪的显著差异。对话嵌入的分类器分析表明，尽管对话中没有明确提及情绪，但对情感价值的隐性编码存在。研究还提供了一个新颖的、由两个ChatGPT生成的对话组成的数据集。

    This study explores linguistic differences between human and LLM-generated dialogues, using 19.5K dialogues generated by ChatGPT-3.5 as a companion to the EmpathicDialogues dataset. The research employs Linguistic Inquiry and Word Count (LIWC) analysis, comparing ChatGPT-generated conversations with human conversations across 118 linguistic categories. Results show greater variability and authenticity in human dialogues, but ChatGPT excels in categories such as social processes, analytical style, cognition, attentional focus, and positive emotional tone, reinforcing recent findings of LLMs being "more human than human." However, no significant difference was found in positive or negative affect between ChatGPT and human dialogues. Classifier analysis of dialogue embeddings indicates implicit coding of the valence of affect despite no explicit mention of affect in the conversations. The research also contributes a novel, companion ChatGPT-generated dataset of conversations between two i
    
[^30]: 大规模多语言文本翻译对于低资源语言

    Massively Multilingual Text Translation For Low-Resource Languages. (arXiv:2401.16582v1 [cs.CL])

    [http://arxiv.org/abs/2401.16582](http://arxiv.org/abs/2401.16582)

    该论文提出了一种将翻译资源从资源丰富的语言利用到资源有限的语言的方法，以满足低资源语言的翻译需求，并提高翻译质量和效率。

    

    将翻译应用于资源极为有限的语言，既有文化目的，也有人道主义目的，旨在拯救和复兴这些语言，并满足由COVID-19大流行加速的当地社区的日常需求。在许多人道主义工作中，对资源极其有限的语言进行翻译通常不需要一个通用的翻译引擎，而是需要一个专门的针对特定文本的翻译引擎。例如，医疗记录、卫生程序、政府通信、紧急程序和宗教文本都属于有限的文本。尽管还不存在适用于所有语言的通用翻译引擎，但是可能可以将多语言已知的有限文本翻译成新的、资源有限的语言，从而减少人工翻译的工作量。我们试图利用来自资源丰富的语言的翻译资源，高效地为多语言已知的常规文本提供最佳的翻译质量，在新的资源有限的语言环境中实现翻译。

    Translation into severely low-resource languages has both the cultural goal of saving and reviving those languages and the humanitarian goal of assisting the everyday needs of local communities that are accelerated by the recent COVID-19 pandemic. In many humanitarian efforts, translation into severely low-resource languages often does not require a universal translation engine, but a dedicated text-specific translation engine. For example, healthcare records, hygienic procedures, government communication, emergency procedures and religious texts are all limited texts. While generic translation engines for all languages do not exist, translation of multilingually known limited texts into new, low-resource languages may be possible and reduce human translation effort. We attempt to leverage translation resources from rich-resource languages to efficiently produce best possible translation quality for well known texts, which are available in multiple languages, in a new, low-resource lan
    
[^31]: 发挥专业放射科医生的专长，提升放射学报告的LLM评估

    Leveraging Professional Radiologists' Expertise to Enhance LLMs' Evaluation for Radiology Reports. (arXiv:2401.16578v1 [cs.CL])

    [http://arxiv.org/abs/2401.16578](http://arxiv.org/abs/2401.16578)

    该论文提出了一种方法，将专业放射科医生的专业知识与大型语言模型相结合，来提升自动生成报告的自动评估。实验结果显示，该方法的模型在评估中表现优于传统的度量标准。

    

    在放射学领域，人工智能（AI）已经大大推进了报告生成，但自动生成报告的自动评估仍然具有挑战性。目前的度量标准，如传统自然语言生成（NLG）和临床效能（CE），往往无法捕捉临床背景的语义复杂性，或者过分强调临床细节，降低了报告的清晰性。为了解决这些问题，我们提出的方法将专业放射科医生的专业知识与大型语言模型（LLMs），如GPT-3.5和GPT-4 1，相结合。利用上下文指导学习（ICIL）和思维链（CoT）推理，我们的方法使LLM的评估与放射科医生的标准保持一致，实现了人工智能生成报告与人类生成报告之间的详细比较。这进一步通过回归模型来综合句子评估分数。实验结果表明，我们的“详细GPT-4（5次训练）”模型获得了0.48的分数，优于METEOR指标。

    In radiology, Artificial Intelligence (AI) has significantly advanced report generation, but automatic evaluation of these AI-produced reports remains challenging. Current metrics, such as Conventional Natural Language Generation (NLG) and Clinical Efficacy (CE), often fall short in capturing the semantic intricacies of clinical contexts or overemphasize clinical details, undermining report clarity. To overcome these issues, our proposed method synergizes the expertise of professional radiologists with Large Language Models (LLMs), like GPT-3.5 and GPT-4 1. Utilizing In-Context Instruction Learning (ICIL) and Chain of Thought (CoT) reasoning, our approach aligns LLM evaluations with radiologist standards, enabling detailed comparisons between human and AI generated reports. This is further enhanced by a Regression model that aggregates sentence evaluation scores. Experimental results show that our ''Detailed GPT-4 (5-shot)'' model achieves a 0.48 score, outperforming the METEOR metric 
    
[^32]: LLM作为按需可定制的服务

    LLMs as On-demand Customizable Service. (arXiv:2401.16577v1 [cs.CL])

    [http://arxiv.org/abs/2401.16577](http://arxiv.org/abs/2401.16577)

    提出了一种分层、分布式的LLM架构概念，通过在通用计算机和物联网设备上提供按需访问的可定制服务，解决了LLMs训练、部署和访问过程中的挑战，并能够实现资源和应用需求的最佳平衡。

    

    大型语言模型（LLMs）展示了卓越的语言理解和生成能力。然而，训练、部署和访问这些模型都存在显著的挑战，包括资源密集需求、长时间训练和可扩展性问题。为了解决这些问题，我们引入了一个分层、分布式的LLM架构概念，旨在增强LLMs在异构计算平台上的可访问性和可部署性，包括通用计算机（如笔记本电脑）和物联网设备（如嵌入式系统）。通过引入"分层"方法，所提出的架构使LLMs可以按需访问，作为可定制的服务。这种方法还可以确保可用计算资源和用户应用需求之间的最佳权衡。我们预见到，分层LLM的概念将赋予广泛的众包用户基础利用LLM的能力，从而促进技术进步。

    Large Language Models (LLMs) have demonstrated remarkable language understanding and generation capabilities. However, training, deploying, and accessing these models pose notable challenges, including resource-intensive demands, extended training durations, and scalability issues. To address these issues, we introduce a concept of hierarchical, distributed LLM architecture that aims at enhancing the accessibility and deployability of LLMs across heterogeneous computing platforms, including general-purpose computers (e.g., laptops) and IoT-style devices (e.g., embedded systems). By introducing a "layered" approach, the proposed architecture enables on-demand accessibility to LLMs as a customizable service. This approach also ensures optimal trade-offs between the available computational resources and the user's application needs. We envision that the concept of hierarchical LLM will empower extensive, crowd-sourced user bases to harness the capabilities of LLMs, thereby fostering advan
    
[^33]: 超越图像-文本匹配：使用引导遮罩的多模态Transformer中的动词理解。

    Beyond Image-Text Matching: Verb Understanding in Multimodal Transformers Using Guided Masking. (arXiv:2401.16575v1 [cs.CL])

    [http://arxiv.org/abs/2401.16575](http://arxiv.org/abs/2401.16575)

    本研究提出了一种新的探测策略，名为引导遮罩，在多模态Transformer模型中通过消除不同的模态来评估其对动词的理解能力。研究结果表明，这些模型能够准确预测正确的动词，与先前从图像-文本匹配探测技术中得出的结论形成对比。

    

    主要的探测方法依赖于图像-文本匹配任务的零-shot性能，以更细粒度地了解近期多模态图像-语言Transformer模型学习到的表示。评估是在精心策划的数据集上进行的，重点关注计数、关系、属性等。本研究介绍了一种名为引导遮罩的替代探测策略。所提出的方法使用遮罩来消除不同的模态，并评估模型准确预测被遮罩的单词的能力。我们着重研究考虑ROI特征的多模态模型，这些特征是通过物体检测器获得的输入标记。我们使用引导遮罩在ViLBERT、LXMERT、UNITER和VisualBERT上研究动词的理解，并展示了这些模型能够准确预测正确的动词。这与先前从图像-文本匹配探测技术中得出的经常无法成功的情况形成对比。

    The dominant probing approaches rely on the zero-shot performance of image-text matching tasks to gain a finer-grained understanding of the representations learned by recent multimodal image-language transformer models. The evaluation is carried out on carefully curated datasets focusing on counting, relations, attributes, and others. This work introduces an alternative probing strategy called guided masking. The proposed approach ablates different modalities using masking and assesses the model's ability to predict the masked word with high accuracy. We focus on studying multimodal models that consider regions of interest (ROI) features obtained by object detectors as input tokens. We probe the understanding of verbs using guided masking on ViLBERT, LXMERT, UNITER, and VisualBERT and show that these models can predict the correct verb with high accuracy. This contrasts with previous conclusions drawn from image-text matching probing techniques that frequently fail in situations requir
    
[^34]: 基于自编码器的概念空间语义通信的领域学习

    Autoencoder-Based Domain Learning for Semantic Communication with Conceptual Spaces. (arXiv:2401.16569v1 [cs.LG])

    [http://arxiv.org/abs/2401.16569](http://arxiv.org/abs/2401.16569)

    这篇论文研究了基于概念空间的语义通信，提出了一个自编码器学习的框架，解决了无法捕捉和量化“意义”的问题。

    

    与准确传递符号相比，以准确传递意义为目标的语义通信已成为一个越来越受关注的领域。这种范式通常利用人工智能和机器学习的现代发展，以提高通信系统的效率和鲁棒性。然而，对于捕捉和量化“意义”的细节缺乏一个标准模型，许多领先的语义通信方法采用黑盒框架，对模型的具体学习内容知之甚少。一种解决方案是利用概念空间框架，以几何方式明确建模意义。虽然以前使用概念空间研究语义通信的工作已经取得了良好的结果，但这些先前的尝试涉及手工制作概念空间模型，严重限制了该方法的可扩展性和实用性。在这项工作中，我们开发了一个学习框架，用于学习一个自编码器，实现概念空间语义通信。

    Communication with the goal of accurately conveying meaning, rather than accurately transmitting symbols, has become an area of growing interest. This paradigm, termed semantic communication, typically leverages modern developments in artificial intelligence and machine learning to improve the efficiency and robustness of communication systems. However, a standard model for capturing and quantifying the details of "meaning" is lacking, with many leading approaches to semantic communication adopting a black-box framework with little understanding of what exactly the model is learning. One solution is to utilize the conceptual spaces framework, which models meaning explicitly in a geometric manner. Though prior work studying semantic communication with conceptual spaces has shown promising results, these previous attempts involve hand-crafting a conceptual space model, severely limiting the scalability and practicality of the approach. In this work, we develop a framework for learning a 
    
[^35]: 印地语天城字母脚本中的多类后悔检测

    Multi-class Regret Detection in Hindi Devanagari Script. (arXiv:2401.16561v1 [cs.CL])

    [http://arxiv.org/abs/2401.16561](http://arxiv.org/abs/2401.16561)

    本研究聚焦于印地语社交媒体上的后悔表达，建立了一个新的数据集，并通过研究后悔语言表达的特征和相关领域，揭示了后悔的来源和影响。

    

    近年来，社交媒体上使用印地语的人数大幅增加。后悔是我们日常生活中常见的情感体验。许多社交媒体上的使用者经常分享他们的后悔经历和意见。如果有机会，这可能会导致对自己的选择进行重新评估和对不同选择的渴望。因此，了解后悔的来源对于研究其对行为和决策的影响至关重要。本研究聚焦于后悔以及它如何在印地语中表达，特别是在各种社交媒体平台上。在我们的研究中，我们提供了一个新颖的数据集，来自三个不同的来源，每个句子都被手动分类为“行动后悔”、“不作为后悔”和“无后悔”中的一类。接下来，我们使用该数据集研究印地语文本中的后悔语言表达，并确定与后悔最频繁相关的文本领域。我们的研究结果表明，个体们最常与后悔相关的领域是...

    The number of Hindi speakers on social media has increased dramatically in recent years. Regret is a common emotional experience in our everyday life. Many speakers on social media, share their regretful experiences and opinions regularly. It might cause a re-evaluation of one's choices and a desire to make a different option if given the chance. As a result, knowing the source of regret is critical for investigating its impact on behavior and decision-making. This study focuses on regret and how it is expressed, specifically in Hindi, on various social media platforms. In our study, we present a novel dataset from three different sources, where each sentence has been manually classified into one of three classes "Regret by action", "Regret by inaction", and "No regret". Next, we use this dataset to investigate the linguistic expressions of regret in Hindi text and also identify the textual domains that are most frequently associated with regret. Our findings indicate that individuals 
    
[^36]: 多样但有分歧：LLM可能夸大与错误信息有关的伤害问题上的性别差异

    Diverse, but Divisive: LLMs Can Exaggerate Gender Differences in Opinion Related to Harms of Misinformation. (arXiv:2401.16558v1 [cs.CY])

    [http://arxiv.org/abs/2401.16558](http://arxiv.org/abs/2401.16558)

    本论文探讨了使用大型语言模型（LLM）用于优先排序误导性信息伤害时可能出现的问题。作者将性别作为主要变量，研究LLM在评估错误信息的危害性时是否能够反映不同性别群体的观点，结果发现LLM可能夸大了性别差异。

    

    误导性和虚假信息的普遍传播对社会构成了重大威胁。专业的事实核查人员在应对此威胁时发挥着关键作用，但问题规模巨大迫使他们必须对有限的资源进行优先排序。这种优先排序可能考虑到一系列因素，如对特定人群造成的伤害风险不同。本文研究了使用大型语言模型（LLM）来促进此类优先排序可能带来的潜在影响。因为事实核查影响着社会各个多样化部分，所以重要的是在对索赔的优先排序过程中反映多样化的观点。本文旨在调查LLM在评估错误信息的危害性时，能否反映不同群体的观点，重点关注性别作为主要变量。我们提出了两个核心问题：（1）带有明确性别指称的提示在美国社会相关主题上是否反映了性别差异的程度

    The pervasive spread of misinformation and disinformation poses a significant threat to society. Professional fact-checkers play a key role in addressing this threat, but the vast scale of the problem forces them to prioritize their limited resources. This prioritization may consider a range of factors, such as varying risks of harm posed to specific groups of people. In this work, we investigate potential implications of using a large language model (LLM) to facilitate such prioritization. Because fact-checking impacts a wide range of diverse segments of society, it is important that diverse views are represented in the claim prioritization process. This paper examines whether a LLM can reflect the views of various groups when assessing the harms of misinformation, focusing on gender as a primary variable. We pose two central questions: (1) To what extent do prompts with explicit gender references reflect gender differences in opinion in the United States on topics of social relevance
    
[^37]: SelectLLM：LLMs能否选择重要的指令进行注释？

    SelectLLM: Can LLMs Select Important Instructions to Annotate?. (arXiv:2401.16553v1 [cs.CL])

    [http://arxiv.org/abs/2401.16553](http://arxiv.org/abs/2401.16553)

    这项工作提出了一种名为SelectLLM的新方法，利用LLMs选择高质量指令。通过提示LLMs估计每个无标签指令的有用性和影响力，并使用聚类算法将指令分为多个聚类。

    

    使用大量且多样化的指令数据集训练大型语言模型(LLMs)可以使模型理解和遵循人类指令。最近的研究表明，使用一小组高质量的指令可以超过使用大量更嘈杂的指令。由于指令是无标签的，且响应是自然文本，传统的主动学习方案无法直接应用于选择无标签指令。在这项工作中，我们提出了一种新的指令选择方法，称为SelectLLM，它利用LLMs选择高质量指令。我们的高级思想是利用LLMs通过提示来估计每个指令在没有相应标签（即响应）的情况下的有用性和影响力。SelectLLM包括两个步骤：使用聚类算法（例如CoreSet）将无标签指令划分为多个聚类，然后提示LLMs在其中选择高质量指令。

    Training large language models (LLMs) with a large and diverse instruction dataset aligns the models to comprehend and follow human instructions. Recent works have shown that using a small set of high-quality instructions can outperform using large yet more noisy ones. Because instructions are unlabeled and their responses are natural text, traditional active learning schemes with the model's confidence cannot be directly applied to the selection of unlabeled instructions. In this work, we propose a novel method for instruction selection, called SelectLLM, that leverages LLMs for the selection of high-quality instructions. Our high-level idea is to use LLMs to estimate the usefulness and impactfulness of each instruction without the corresponding labels (i.e., responses), via prompting. SelectLLM involves two steps: dividing the unlabelled instructions using a clustering algorithm (e.g., CoreSet) to multiple clusters, and then prompting LLMs to choose high-quality instructions within e
    
[^38]: GuReT：区分与内疚相关和后悔相关的文本

    GuReT: Distinguishing Guilt and Regret related Text. (arXiv:2401.16541v1 [cs.CL])

    [http://arxiv.org/abs/2401.16541](http://arxiv.org/abs/2401.16541)

    本文介绍了GuReT数据集，用于研究内疚和后悔之间的关系，并探索其在文本中的独特特征。通过使用机器学习和深度学习技术，结果表明基于变压器的模型在内疚和后悔识别任务中表现出优于传统机器学习方法的性能。

    

    人类决策和情绪（特别是内疚和后悔）之间错综复杂的关系对行为和幸福感有重要影响。然而，在计算模型中往往忽视了这些情绪的微妙区别和相互作用。本文介绍了一个特定的数据集，用于剖析内疚和后悔之间的关系及其独特的文本标志，弥补了情感计算研究中的一个显著空白。我们的方法将内疚和后悔识别视为二分类任务，并采用三种机器学习和六种基于变压器的深度学习技术对新创建的数据集进行基准测试。该研究还采用了链状思维和树状思维等创新推理方法来评估模型的解释逻辑。结果表明，基于变压器的模型具有明显的性能优势，相比于最好的机器学习分类器的85.3%的宏F1分数，可以达到90.4%的宏F1分数，展示了其较强的能力。

    The intricate relationship between human decision-making and emotions, particularly guilt and regret, has significant implications on behavior and well-being. Yet, these emotions subtle distinctions and interplay are often overlooked in computational models. This paper introduces a dataset tailored to dissect the relationship between guilt and regret and their unique textual markers, filling a notable gap in affective computing research. Our approach treats guilt and regret recognition as a binary classification task and employs three machine learning and six transformer-based deep learning techniques to benchmark the newly created dataset. The study further implements innovative reasoning methods like chain-of-thought and tree-of-thought to assess the models interpretive logic. The results indicate a clear performance edge for transformer-based models, achieving a 90.4% macro F1 score compared to the 85.3% scored by the best machine learning classifier, demonstrating their superior ca
    
[^39]: InfoLossQA: 文本简化中信息损失的特征化与恢复

    InfoLossQA: Characterizing and Recovering Information Loss in Text Simplification. (arXiv:2401.16475v1 [cs.CL])

    [http://arxiv.org/abs/2401.16475](http://arxiv.org/abs/2401.16475)

    InfoLossQA是一个针对文本简化中信息损失的特征化与恢复的框架，通过提供问答对的形式，帮助读者更深入地了解文本。实验结果表明，信息损失频繁发生，而QA对则能提供哪些信息被丢失的总结。

    

    文本简化旨在使专业文本对普通读者更易理解，但常常导致信息删除和模糊不清。本研究提出了InfoLossQA框架，用以特征化和恢复由简化引起的信息损失，以问答（QA）对的形式呈现。基于“问题讨论”理论，这些QA对旨在帮助读者深入了解文本。我们对该框架进行了一系列实验。首先，我们收集了由104个医学研究科学摘要的104个LLM简化中所衍生的1000个语言学家策划的QA对数据集。我们对这些数据的分析表明，信息损失经常发生，并且QA对可以高层次地总结出哪些信息被丢失。其次，我们设计了两种方法来完成此任务：端到端促使开源和商业化语言模型的方法，以及自然语言推理流水线的方法。通过一种新颖的评估框架，考虑了QA对的正确性。

    Text simplification aims to make technical texts more accessible to laypeople but often results in deletion of information and vagueness. This work proposes InfoLossQA, a framework to characterize and recover simplification-induced information loss in form of question-and-answer (QA) pairs. Building on the theory of Question Under Discussion, the QA pairs are designed to help readers deepen their knowledge of a text. We conduct a range of experiments with this framework. First, we collect a dataset of 1,000 linguist-curated QA pairs derived from 104 LLM simplifications of scientific abstracts of medical studies. Our analyses of this data reveal that information loss occurs frequently, and that the QA pairs give a high-level overview of what information was lost. Second, we devise two methods for this task: end-to-end prompting of open-source and commercial language models, and a natural language inference pipeline. With a novel evaluation framework considering the correctness of QA pai
    
[^40]: ReGAL: 用于发现通用抽象的程序重构方法

    ReGAL: Refactoring Programs to Discover Generalizable Abstractions. (arXiv:2401.16467v1 [cs.SE])

    [http://arxiv.org/abs/2401.16467](http://arxiv.org/abs/2401.16467)

    ReGAL提出了一种用于发现通用抽象的程序重构方法，可以通过重构代码学习可重用的函数库，利用这些共享函数库可以更准确地预测程序。

    

    虽然大型语言模型（LLMs）越来越多地被用于程序合成，但它们缺乏开发有用抽象所需的全局视角；它们通常一次预测一个程序，经常重复相同的功能。从头开始生成冗余代码既低效又容易出错。为了解决这个问题，我们提出了用于通用抽象学习的重构方法（ReGAL），通过代码重构来学习可重用函数库，即在不改变代码执行输出的情况下重组代码。ReGAL从一小组现有程序中学习，通过执行验证和细化抽象。我们发现，ReGAL发现的共享函数库使得在不同领域预测程序变得更加容易。在三个数据集（LOGO图形生成、日期推理和基于Minecraft的文字游戏TextCraft）上，开源和专有的LLMs在使用ReGAL函数库预测程序时准确性得到提高。

    While large language models (LLMs) are increasingly being used for program synthesis, they lack the global view needed to develop useful abstractions; they generally predict programs one at a time, often repeating the same functionality. Generating redundant code from scratch is both inefficient and error-prone. To address this, we propose Refactoring for Generalizable Abstraction Learning (ReGAL), a gradient-free method for learning a library of reusable functions via code refactorization, i.e. restructuring code without changing its execution output. ReGAL learns from a small set of existing programs, iteratively verifying and refining its abstractions via execution. We find that the shared function libraries discovered by ReGAL make programs easier to predict across diverse domains. On three datasets (LOGO graphics generation, Date reasoning, and TextCraft, a Minecraft-based text game), both open-source and proprietary LLMs improve in accuracy when predicting programs with ReGAL fun
    
[^41]: 信用风险与大型语言模型相结合：从P2P借贷的贷款描述中构建风险指标。

    Credit Risk Meets Large Language Models: Building a Risk Indicator from Loan Descriptions in P2P Lending. (arXiv:2401.16458v1 [q-fin.RM])

    [http://arxiv.org/abs/2401.16458](http://arxiv.org/abs/2401.16458)

    本文研究了如何利用P2P借贷平台上借款人提供的文本描述来构建风险指标。结果显示，利用大型语言模型生成的风险评分可以明显提高信用风险分类器的性能。

    

    P2P借贷作为一种独特的融资机制，通过在线平台将借款人与放款人联系起来。然而，P2P借贷面临信息不对称的挑战，因为放款人往往缺乏足够的数据来评估借款人的信用价值。本文提出了一种新颖的方法来解决这个问题，即利用借款人在贷款申请过程中提供的文本描述。我们的方法涉及使用大型语言模型（LLM）处理这些文本描述，LLM是一种能够识别文本中的模式和语义的强大工具。将迁移学习应用于将LLM适应特定任务。我们从Lending Club数据集的分析结果显示，BERT生成的风险评分显著提高了信用风险分类器的性能。然而，基于LLM的系统固有的不透明性，以及潜在偏差的不确定性，限制了其应用。

    Peer-to-peer (P2P) lending has emerged as a distinctive financing mechanism, linking borrowers with lenders through online platforms. However, P2P lending faces the challenge of information asymmetry, as lenders often lack sufficient data to assess the creditworthiness of borrowers. This paper proposes a novel approach to address this issue by leveraging the textual descriptions provided by borrowers during the loan application process. Our methodology involves processing these textual descriptions using a Large Language Model (LLM), a powerful tool capable of discerning patterns and semantics within the text. Transfer learning is applied to adapt the LLM to the specific task at hand.  Our results derived from the analysis of the Lending Club dataset show that the risk score generated by BERT, a widely used LLM, significantly improves the performance of credit risk classifiers. However, the inherent opacity of LLM-based systems, coupled with uncertainties about potential biases, unders
    
[^42]: KAUCUS: 知识增强用户模拟器用于训练语言模型助手

    KAUCUS: Knowledge Augmented User Simulators for Training Language Model Assistants. (arXiv:2401.16454v1 [cs.HC])

    [http://arxiv.org/abs/2401.16454](http://arxiv.org/abs/2401.16454)

    KAUCUS引入了知识增强用户模拟器框架，可以生成多样化的模拟器助手交互，并能够快速引入外部知识，从而提高语言模型助手的训练效果。

    

    通过创建一个能够生成有用交互数据的模拟器，可以开发出一个有效的多轮指令跟随助手。理想的用户模拟器除了依靠其内在权重外，还应能够快速引入外部知识来模拟互联网上多样化的文本。以往的用户模拟器通常缺乏多样性，主要是封闭领域的，并且需要严格的模式，使得它们无法快速扩展以融入外部知识。在这方面，我们介绍了一个名为Kaucus的知识增强用户模拟器框架，以概述创建多样化用户模拟器的过程，并能够无缝地利用外部知识，同时受益于下游助手模型的训练。通过两个基于GPT-J的模拟器，即检索增强模拟器和摘要控制模拟器，我们生成多样化的模拟器助手交互。

    An effective multi-turn instruction-following assistant can be developed by creating a simulator that can generate useful interaction data. Apart from relying on its intrinsic weights, an ideal user simulator should also be able to bootstrap external knowledge rapidly in its raw form to simulate the multifarious diversity of text available over the internet. Previous user simulators generally lacked diversity, were mostly closed domain, and necessitated rigid schema making them inefficient to rapidly scale to incorporate external knowledge. In this regard, we introduce, Kaucus, a Knowledge-Augmented User Simulator framework, to outline a process of creating diverse user simulators, that can seamlessly exploit external knowledge as well as benefit downstream assistant model training. Through two GPT-J based simulators viz., a Retrieval Augmented Simulator and a Summary Controlled Simulator we generate diverse simulator-assistant interactions. Through reward and preference model-based ev
    
[^43]: FaKnow: 一个用于虚假新闻检测的统一库

    FaKnow: A Unified Library for Fake News Detection. (arXiv:2401.16441v1 [cs.LG])

    [http://arxiv.org/abs/2401.16441](http://arxiv.org/abs/2401.16441)

    FaKnow是一个统一的虚假新闻检测算法库，包含多种常用的模型和工具，并解决了不同框架下的可重复性和冗余问题。

    

    在过去的几年中，基于深度学习的大量虚假新闻检测算法应运而生。然而，它们往往在不同的框架下开发，每个框架又要求使用不同的方法，因此阻碍了可重复性。此外，这些虚假新闻检测模型的代码开发中存在大量的冗余。为了解决这些问题，我们提出了FaKnow，一个统一且全面的虚假新闻检测算法库。它涵盖了多种常用的虚假新闻检测模型，包括基于内容和基于社会环境的方法。该库涵盖了模型训练和评估流程的完整范围，在一个统一框架内有效组织了数据、模型和训练程序。此外，它还提供了一系列辅助功能和工具，包括可视化和日志记录。我们的工作为虚假新闻检测的标准化和统一化做出了贡献。

    Over the past years, a large number of fake news detection algorithms based on deep learning have emerged. However, they are often developed under different frameworks, each mandating distinct utilization methodologies, consequently hindering reproducibility. Additionally, a substantial amount of redundancy characterizes the code development of such fake news detection models. To address these concerns, we propose FaKnow, a unified and comprehensive fake news detection algorithm library. It encompasses a variety of widely used fake news detection models, categorized as content-based and social context-based approaches. This library covers the full spectrum of the model training and evaluation process, effectively organizing the data, models, and training procedures within a unified framework. Furthermore, it furnishes a series of auxiliary functionalities and tools, including visualization, and logging. Our work contributes to the standardization and unification of fake news detection 
    
[^44]: 一个针对Covid-19相关论文的信息检索和提取工具

    An Information Retrieval and Extraction Tool for Covid-19 Related Papers. (arXiv:2401.16430v1 [cs.IR])

    [http://arxiv.org/abs/2401.16430](http://arxiv.org/abs/2401.16430)

    该论文开发了一个集信息检索和提取于一体的工具，应用于COVID-19 Open Research Dataset (CORD-19)。主要目的是为研究人员提供一个更好的COVID-19相关论文的搜索工具，帮助他们找到参考论文并突出显示文本中的相关实体。

    

    背景：COVID-19大流行对全球的卫生系统造成了严重影响。其严重性以及个人和组织开展对策研究的兴趣增加，导致科学期刊中出现了大量新的研究。目标：我们旨在开发一种将信息检索（IR）和提取（IE）的方面应用于COVID-19 Open Research Dataset（CORD-19）的新颖工具。本文的主要重点是为研究人员提供一个更好的COVID-19相关论文的搜索工具，帮助他们找到参考论文并突出显示文本中的相关实体。方法：我们应用隐含狄利克雷分配（LDA）来根据研究方面对CORD-19中所有英文摘要的主题进行建模。提取每个摘要的相关命名实体，并将其链接到相应的UMLS概念。使用正则表达式和K最近邻算法来对相关论文进行排名。结果：我们的工具已经实现了...

    Background: The COVID-19 pandemic has caused severe impacts on health systems worldwide. Its critical nature and the increased interest of individuals and organizations to develop countermeasures to the problem has led to a surge of new studies in scientific journals. Objetive: We sought to develop a tool that incorporates, in a novel way, aspects of Information Retrieval (IR) and Extraction (IE) applied to the COVID-19 Open Research Dataset (CORD-19). The main focus of this paper is to provide researchers with a better search tool for COVID-19 related papers, helping them find reference papers and hightlight relevant entities in text. Method: We applied Latent Dirichlet Allocation (LDA) to model, based on research aspects, the topics of all English abstracts in CORD-19. Relevant named entities of each abstract were extracted and linked to the corresponding UMLS concept. Regular expressions and the K-Nearest Neighbors algorithm were used to rank relevant papers. Results: Our tool has s
    
[^45]: 结合主题建模和引用网络分析研究欧洲人权法院关于尊重私人和家庭生活权利的案例法

    Combining topic modelling and citation network analysis to study case law from the European Court on Human Rights on the right to respect for private and family life. (arXiv:2401.16429v1 [cs.IR])

    [http://arxiv.org/abs/2401.16429](http://arxiv.org/abs/2401.16429)

    本文研究了结合主题建模和引用网络分析的方法，用来研究欧洲人权法院关于尊重私密和家庭生活的案例法。通过这种方法，可以找到和组织具有相似主题和引用模式的案例法，并且通过结合这两种技术能够得到更好的结果。

    

    随着HUDOC等法律案例法数据库的快速增长，为了处理如此大规模的数据集，法律研究人员找到高效的方法变得至关重要。这种案例法数据库通常包含案件的文本内容以及它们之间的引用。本文重点研究了来自欧洲人权法院关于欧洲人权公约第8条关于尊重私人和家庭生活、家庭和通信权利的案例法。在本研究中，我们演示并比较了主题建模和引用网络在根据一般主题和引用模式找到和组织第8条案例法方面的潜力。另外，我们还探索了结合这两种技术是否比仅应用其中一种方法效果更好。我们在一组手工收集和注释的关于驱逐的第8条案例法独特数据集上评估了组合方法的有效性。我们的结果表明，结合使用这两种方法能够取得更好的效果。

    As legal case law databases such as HUDOC continue to grow rapidly, it has become essential for legal researchers to find efficient methods to handle such large-scale data sets. Such case law databases usually consist of the textual content of cases together with the citations between them. This paper focuses on case law from the European Court of Human Rights on Article 8 of the European Convention of Human Rights, the right to respect private and family life, home and correspondence. In this study, we demonstrate and compare the potential of topic modelling and citation network to find and organize case law on Article 8 based on their general themes and citation patterns, respectively. Additionally, we explore whether combining these two techniques leads to better results compared to the application of only one of the methods. We evaluate the effectiveness of the combined method on a unique manually collected and annotated dataset of Aricle 8 case law on evictions. The results of our
    
[^46]: 基于RAG的理解伊斯兰教问题回答系统提案：MufassirQAS LLM

    A RAG-based Question Answering System Proposal for Understanding Islam: MufassirQAS LLM. (arXiv:2401.15378v1 [cs.CL])

    [http://arxiv.org/abs/2401.15378](http://arxiv.org/abs/2401.15378)

    基于RAG的MufassirQAS问答系统利用NLP技术建立联系并准确回答复杂问题，提高了LLMs的准确性和透明度，帮助理解伊斯兰教的复杂性和教义深度。

    

    学习和理解宗教存在复杂性和教义深度的挑战。问答机器人作为解决这些挑战的问题回答系统，可以帮助。LLM聊天机器人利用自然语言处理技术建立主题之间的联系，准确回答复杂问题。这些能力使其成为用于宗教启蒙的问题回答聊天机器人的理想选择。然而，LLM也有生成虚假信息的倾向，称为幻觉。聊天机器人的回答可能包含侮辱个人宗教信仰、跨宗派冲突和有争议或敏感的话题的内容。它需要避免这种情况，而不会宣扬仇恨言论或冒犯某些群体的人或他们的信仰。本研究使用基于向量数据库的检索增强生成（RAG）方法来提高LLMs的准确性和透明度。我们的问答系统称为"MufassirQAS"。我们创建了一个模型来评估该系统并证明其在解决宗教行业问题中的效果。

    There exist challenges in learning and understanding religions as the presence of complexity and depth of religious doctrines and teachings. Chatbots as question-answering systems can help in solving these challenges. LLM chatbots use NLP techniques to establish connections between topics and accurately respond to complex questions. These capabilities make it perfect to be used in enlightenment on religion as a question answering chatbot. However, LLMs also have a tendency to generate false information, known as hallucination. The responses of the chatbots can include content that insults personal religious beliefs, interfaith conflicts, and controversial or sensitive topics. It needs to avoid such cases without promoting hate speech or offending certain groups of people or their beliefs. This study uses a vector database-based Retrieval Augmented Generation (RAG) approach to enhance the accuracy and transparency of LLMs. Our question-answering system is called as "MufassirQAS". We cre
    
[^47]: 在金融数据分析中，为语言模型添加工具使用能力

    Equipping Language Models with Tool Use Capability for Tabular Data Analysis in Finance. (arXiv:2401.15328v1 [cs.CL])

    [http://arxiv.org/abs/2401.15328](http://arxiv.org/abs/2401.15328)

    在金融数据分析领域，通过为语言模型添加工具使用能力，我们成功解决了大型语言模型在处理异构金融数据和保证精度时所面临的挑战，并取得了显著的改进。

    

    大型语言模型(LLMs)展示了一系列的推理能力，但在金融等专业领域中遇到了错误传播和产生幻觉等挑战，其中数据异构性和精度至关重要。为了克服这些限制，我们探索了语言模型通过外部工具增强能力，将某些推理步骤转移到更适合该任务的外部工具上，而不仅仅依赖LLM的内在能力。具体而言，我们使用金融领域的问答数据集，在LLaMA-2 13B Chat模型上进行有监督的微调，使其既充当“任务路由器”又充当“任务解决器”。该“任务路由器”动态将问题定向到LLM内部回答或通过工具集中的正确工具外部回答。我们的工具增强型SFT模型Raven相比基础模型和仅有SFT的基准模型分别提高了35.2%和5.06%，在竞争力方面具有很高的水平。

    Large language models (LLMs) have exhibited an array of reasoning capabilities but face challenges like error propagation and hallucination, particularly in specialised areas like finance, where data is heterogeneous, and precision is paramount. We explore the potential of language model augmentation with external tools to mitigate these limitations and offload certain reasoning steps to external tools that are more suited for the task, instead of solely depending on the LLM's inherent abilities. More concretely, using financial domain question-answering datasets, we apply supervised fine-tuning on a LLaMA-2 13B Chat model to act both as a 'task router' and 'task solver'. The 'task router' dynamically directs a question to either be answered internally by the LLM or externally via the right tool from the tool set. Our tool-equipped SFT model, Raven, demonstrates an improvement of 35.2% and 5.06% over the base model and SFT-only baselines, respectively, and is highly competitive with st
    
[^48]: 反思LLM生成数据的真实性：对LLM生成数据的追踪研究

    Under the Surface: Tracking the Artifactuality of LLM-Generated Data. (arXiv:2401.14698v1 [cs.CL])

    [http://arxiv.org/abs/2401.14698](http://arxiv.org/abs/2401.14698)

    本研究是针对大型语言模型（LLM）生成的人工数据的追踪研究，将各种类型的LLM生成文本数据进行了汇总和测试，并揭示了隐藏的质量和多样性问题。这是第一次对LLM生成数据进行综合分析和比较，并引发了对人工数据质量的关注。

    

    本研究探讨了大型语言模型（LLM）在生成人工数据方面的不断扩大的作用。LLM越来越多地用于生成多种输出，包括注释、偏好、指令提示、模拟对话和自由文本。由于这些LLM生成数据形式在应用中经常交叉，它们相互影响，并引发了对训练循环中合并的人工数据质量和多样性的重大关注，形成了一个人工数据生态系统。据我们所知，这是第一项研究将各种类型的LLM生成文本数据汇总起来，从更严格受限的数据如“任务标签”到更自由的“自由文本”。然后我们对LLM生成的人工数据的质量和影响进行了压力测试，并与人工数据在各种现有基准上进行比较。尽管人工数据能够匹配人类表现，但本文揭示了隐藏的巨大隐患。

    This work delves into the expanding role of large language models (LLMs) in generating artificial data. LLMs are increasingly employed to create a variety of outputs, including annotations, preferences, instruction prompts, simulated dialogues, and free text. As these forms of LLM-generated data often intersect in their application, they exert mutual influence on each other and raise significant concerns about the quality and diversity of the artificial data incorporated into training cycles, leading to an artificial data ecosystem. To the best of our knowledge, this is the first study to aggregate various types of LLM-generated text data, from more tightly constrained data like "task labels" to more lightly constrained "free-form text". We then stress test the quality and implications of LLM-generated artificial data, comparing it with human data across various existing benchmarks. Despite artificial data's capability to match human performance, this paper reveals significant hidden d
    
[^49]: 噪声孟加拉语文本情感分析中噪声减少方法的比较分析

    A Comparative Analysis of Noise Reduction Methods in Sentiment Analysis on Noisy Bengali Texts. (arXiv:2401.14360v1 [cs.CL])

    [http://arxiv.org/abs/2401.14360](http://arxiv.org/abs/2401.14360)

    本文通过比较分析了噪声减少方法在噪声孟加拉文本情感分析中的效果，并提出了更适用的噪声减少方法的需求。

    

    尽管孟加拉语被认为是资源有限的语言，但情感分析已经成为文献研究的一个重要主题。然而，在噪声孟加拉文本领域，对情感分析的探索仍然不足。本文介绍了一个由人工标注的数据集（NC-SentNoB），用于识别预存在的情感分析数据集中大约15K个噪声孟加拉文本中的十种不同类型的噪声。我们首先通过将输入噪声文本划分为多个标签来识别噪声类型，然后引入基线噪声减少方法来减少噪声，以进行情感分析。最后，我们评估了针对噪声和减少噪声文本进行微调的情感分析模型的性能，并进行比较。实验结果表明，所使用的噪声减少方法不尽如人意，强调了需要更适用的噪声减少方法的需求。

    While Bengali is considered a language with limited resources, sentiment analysis has been a subject of extensive research in the literature. Nevertheless, there is a scarcity of exploration into sentiment analysis specifically in the realm of noisy Bengali texts. In this paper, we introduce a dataset (NC-SentNoB) that we annotated manually to identify ten different types of noise found in a pre-existing sentiment analysis dataset comprising of around 15K noisy Bengali texts. At first, given an input noisy text, we identify the noise type, addressing this as a multi-label classification task. Then, we introduce baseline noise reduction methods to alleviate noise prior to conducting sentiment analysis. Finally, we assess the performance of fine-tuned sentiment analysis models with both noisy and noise-reduced texts to make comparisons. The experimental findings indicate that the noise reduction methods utilized are not satisfactory, highlighting the need for more suitable noise reductio
    
[^50]: 研究大型语言模型在代码克隆检测方面的功效

    Investigating the Efficacy of Large Language Models for Code Clone Detection. (arXiv:2401.13802v1 [cs.SE])

    [http://arxiv.org/abs/2401.13802](http://arxiv.org/abs/2401.13802)

    这项研究探索了大型语言模型在代码克隆检测任务中的应用。

    

    大型语言模型（LLMs）在各种自然语言处理和软件工程任务中表现出了显著的成功，例如代码生成。LLMs主要在基于提示的零/少样本范式中被用于指导模型完成任务。本研究探索了LLMs在代码克隆检测（CCD）这一非生成任务中的适用性。

    Large Language Models (LLMs) have demonstrated remarkable success in various natural language processing and software engineering tasks, such as code generation. The LLMs are mainly utilized in the prompt-based zero/few-shot paradigm to guide the model in accomplishing the task. %\textbf{Goal:} GPT-based models are one of the popular ones studied for tasks such as code comment generation or test generation. These tasks are `generative' tasks. However, there is limited research on the usage of LLMs for `non-generative' tasks such as classification using the prompt-based paradigm. In this preliminary exploratory study, we investigated the applicability of LLMs for Code Clone Detection (CCD), a non-generative task. %\textbf{Method:} By building a mono-lingual and cross-lingual CCD dataset derived from CodeNet, we first investigated two different prompts using ChatGPT to detect \textcolor{black}{Type-4} code clones in Java-Java and Java-Ruby pairs in a zero-shot setting. We \textcolor{blac
    
[^51]: 上下文语言学习：架构与算法

    In-Context Language Learning: Architectures and Algorithms. (arXiv:2401.12973v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.12973](http://arxiv.org/abs/2401.12973)

    本文通过研究一个新的问题家族——上下文语言学习（ICLL），探讨了大规模神经语言模型在上下文学习中的能力。在ICLL中，模型通过生成与给定形式语言相同的字符串来进行上下文学习。研究结果对于理解真实场景中的上下文学习以及神经语言模型的发展具有重要意义。

    

    大规模神经语言模型展现了在上下文学习中令人惊叹的能力：它们能够从输入的数据集中推断出新的函数。目前，我们对于上下文学习何时以及如何发生的了解主要来自于在极其简单的学习问题上训练的语言模型，例如线性回归和关联记忆。然而，这些模型问题与在大型文本语料库上训练的语言模型展现的“真正”上下文学习之间存在显著差距，后者不仅涉及检索和函数近似，还包括了自由生成语言和其他结构化输出。本文通过研究一个被称为上下文语言学习（ICLL）的新型问题家族，来探讨上下文学习。在ICLL中，语言模型被呈现一组来自形式语言的字符串，并需要生成与该语言相同的其他字符串。我们重点研究了通过随机有限自动机生成的正则语言的上下文学习。我们评估了多种神经序列模型（包括几种常用的模型）。

    Large-scale neural language models exhibit a remarkable capacity for in-context learning (ICL): they can infer novel functions from datasets provided as input. Most of our current understanding of when and how ICL arises comes from LMs trained on extremely simple learning problems like linear regression and associative recall. There remains a significant gap between these model problems and the "real" ICL exhibited by LMs trained on large text corpora, which involves not just retrieval and function approximation but free-form generation of language and other structured outputs. In this paper, we study ICL through the lens of a new family of model problems we term in context language learning (ICLL). In ICLL, LMs are presented with a set of strings from a formal language, and must generate additional strings from the same language. We focus on in-context learning of regular languages generated by random finite automata. We evaluate a diverse set of neural sequence models (including seve
    
[^52]: SLANG: 大型语言模型对新概念的理解

    SLANG: New Concept Comprehension of Large Language Models. (arXiv:2401.12585v1 [cs.CL])

    [http://arxiv.org/abs/2401.12585](http://arxiv.org/abs/2401.12585)

    本研究提出了一个新的基准SLANG，旨在增强大型语言模型LLMs对互联网上新概念的理解能力，同时提出了一种基于因果推断的基准方法FOCUS，能帮助LLMs更好地理解新的短语和用法模式。

    

    语言的动态性，尤其在互联网上的俚语和表情包等方面的体现，给大型语言模型（LLMs）的适应性带来了严峻挑战。传统上，这些模型通常仅绑定在静态数据集上，很难跟上在线社区中快速语言进化的步伐。本研究解决了弥合这一差距的迫切需求，旨在增强LLMs对互联网上新概念的理解能力，同时避免高成本和不切实际的持续重训练。为应对这个问题，我们提出了一个新的评估LLMs在理解新兴语言趋势方面能力的基准 - SLANG，并提出了一种基于因果推断的基准方法 FOCUS，它能增强LLMs对新的短语和用法模式的理解。该方法包括对语言转变的真实世界实例进行详细研究，作为背景依据，以形成更精确和具有上下文相关性的新连接。

    The dynamic nature of language, particularly evident in the realm of slang and memes on the Internet, poses serious challenges to the adaptability of large language models (LLMs). Traditionally anchored to static datasets, these models often struggle to keep up with the rapid linguistic evolution characteristic of online communities. This research addresses the critical need to bridge this gap, aiming to enhance LLMs' comprehension of evolving new concepts on the internet, without the high cost and impracticality of continual retraining. To address this issue, we propose a new benchmark $\textbf{SLANG}$ to assess LLMs' proficiency in comprehending emerging linguistic trends and a baseline approach $\textbf{FOCUS}$, which uses causal inference to enhance LLMs to understand new phrases and usage patterns. This approach involves scrutinizing real-world instances of linguistic shifts, serving as contextual beacons, to form more precise and contextually relevant connections between newly em
    
[^53]: 知识图谱嵌入的位置敏感嵌入

    Location Sensitive Embedding for Knowledge Graph Embedding. (arXiv:2401.10893v1 [cs.IR])

    [http://arxiv.org/abs/2401.10893](http://arxiv.org/abs/2401.10893)

    这篇论文介绍了一种新颖的位置敏感嵌入（LSE）方法，该方法通过关系特定的映射来修改头实体，将关系概念化为线性变换。LSE在知识图谱嵌入领域具有理论基础，同时提出了更高效的变体LSEd。实验证明LSEd在链接预测任务上具有竞争力。

    

    知识图谱嵌入将知识图谱转化为连续的、低维度的空间，有助于推理和补全任务。该领域主要分为传统的距离模型和语义匹配模型。传统的距离模型面临的关键挑战是无法有效区分图谱中的“头实体”和“尾实体”。为了解决这个问题，提出了新颖的位置敏感嵌入（LSE）方法。LSE通过关系特定的映射修改头实体，将关系概念化为线性变换而不仅仅是平移。LSE的理论基础，包括其表示能力和与现有模型的联系，都进行了详细研究。一种更简化的变体LSEd利用对角矩阵进行变换以提高实用性能。在对四个大规模数据集进行链接预测的测试中，LSEd要么表现更好，要么具有竞争力。

    Knowledge graph embedding transforms knowledge graphs into a continuous, low-dimensional space, facilitating inference and completion tasks. This field is mainly divided into translational distance models and semantic matching models. A key challenge in translational distance models is their inability to effectively differentiate between 'head' and 'tail' entities in graphs. To address this, the novel location-sensitive embedding (LSE) method has been developed. LSE innovatively modifies the head entity using relation-specific mappings, conceptualizing relations as linear transformations rather than mere translations. The theoretical foundations of LSE, including its representational capabilities and its connections to existing models, have been thoroughly examined. A more streamlined variant, LSEd, employs a diagonal matrix for transformations to enhance practical efficiency. In tests conducted on four large-scale datasets for link prediction, LSEd either outperforms or is competitive
    
[^54]: 基于噪声对比估计的低资源安全攻击模式识别匹配框架

    Noise Contrastive Estimation-based Matching Framework for Low-resource Security Attack Pattern Recognition. (arXiv:2401.10337v1 [cs.LG])

    [http://arxiv.org/abs/2401.10337](http://arxiv.org/abs/2401.10337)

    该论文提出了一种基于噪声对比估计的低资源安全攻击模式识别匹配框架，通过直接语义相似度决定文本与攻击模式之间的关联，以降低大量类别、标签分布不均和标签空间复杂性带来的学习难度。

    

    战术、技术和程序（TTPs）是网络安全领域中复杂的攻击模式，在文本知识库中有详细的描述。在网络安全写作中识别TTPs，通常称为TTP映射，是一个重要而具有挑战性的任务。传统的学习方法通常以经典的多类或多标签分类设置为目标。由于存在大量的类别（即TTPs），标签分布的不均衡和标签空间的复杂层次结构，这种设置限制了模型的学习能力。我们采用了一种不同的学习范式来解决这个问题，其中将文本与TTP标签之间的直接语义相似度决定为文本分配给TTP标签，从而减少了仅仅在大型标签空间上竞争的复杂性。为此，我们提出了一种具有有效的基于采样的学习比较机制的神经匹配架构，促进学习过程。

    Tactics, Techniques and Procedures (TTPs) represent sophisticated attack patterns in the cybersecurity domain, described encyclopedically in textual knowledge bases. Identifying TTPs in cybersecurity writing, often called TTP mapping, is an important and challenging task. Conventional learning approaches often target the problem in the classical multi-class or multilabel classification setting. This setting hinders the learning ability of the model due to a large number of classes (i.e., TTPs), the inevitable skewness of the label distribution and the complex hierarchical structure of the label space. We formulate the problem in a different learning paradigm, where the assignment of a text to a TTP label is decided by the direct semantic similarity between the two, thus reducing the complexity of competing solely over the large labeling space. To that end, we propose a neural matching architecture with an effective sampling-based learn-to-compare mechanism, facilitating the learning pr
    
[^55]: 电子商务买卖双方在线消息中的即时回答

    Instant Answering in E-Commerce Buyer-Seller Messaging. (arXiv:2401.09785v1 [cs.CL])

    [http://arxiv.org/abs/2401.09785](http://arxiv.org/abs/2401.09785)

    通过使用低延迟的序列到序列方法，我们成功地将电子商务顾客的消息转化为简洁的问题，从而实现了在电子商务买卖双方在线消息中的即时回答。实验证明，我们的方法在问题理解和回答率方面相对增加了很多，对于提高顾客的购物体验非常有效。

    

    电子商务顾客经常寻求详细的产品信息以做出购买决策，通常通过直接向卖家发送扩展查询来联系。这种手动回复要求增加了额外的成本，并且在响应时间波动范围从几小时到几天时干扰了顾客的购物体验。我们旨在使用领先的电子商务商店中的特定领域联合问答（QA）系统自动处理顾客对卖家的询问。主要挑战是将当前为单个问题设计的QA系统调整为解决详细的顾客查询。我们通过一种低延迟的序列到序列方法——MESSAGE-TO-QUESTION（M2Q）来解决这个问题，它通过从消息中识别和提取最重要的信息来将买家消息重新构建成简洁的问题。与基线的评估显示，M2Q在问题理解方面相对增加了757%，在联合问答系统中的回答率增加了1746%。实际部署表明，自动化回答系统可以以一个平均的回答速率快4.67倍。

    E-commerce customers frequently seek detailed product information for purchase decisions, commonly contacting sellers directly with extended queries. This manual response requirement imposes additional costs and disrupts buyer's shopping experience with response time fluctuations ranging from hours to days. We seek to automate buyer inquiries to sellers in a leading e-commerce store using a domain-specific federated Question Answering (QA) system. The main challenge is adapting current QA systems, designed for single questions, to address detailed customer queries. We address this with a low-latency, sequence-to-sequence approach, MESSAGE-TO-QUESTION ( M2Q ). It reformulates buyer messages into succinct questions by identifying and extracting the most salient information from a message. Evaluation against baselines shows that M2Q yields relative increases of 757% in question understanding, and 1,746% in answering rate from the federated QA system. Live deployment shows that automatic a
    
[^56]: 通过迭代组合问题来增强数学问题求解

    Augmenting Math Word Problems via Iterative Question Composing. (arXiv:2401.09003v1 [cs.CL])

    [http://arxiv.org/abs/2401.09003](http://arxiv.org/abs/2401.09003)

    本研究通过引入MMIQC数据集和迭代组合问题(IQC)的新颖增强方法，成功提高了大型语言模型的数学推理能力，在竞赛级数学问题上取得了优于先前最佳结果的准确率。

    

    尽管在改善大型语言模型(LLMs)的数学推理能力方面取得了一定进展，但在不使用外部工具的情况下解决竞赛级数学问题仍然对开源LLMs具有挑战性。在这项工作中，我们介绍了MMIQC数据集，这是一个混合处理的网络数据和合成问题-响应对的混合数据集，以提供基础模型更好的数学推理能力。通过在MMIQC上对Mistral-7B(arXiv:2310.06825)进行微调获得的模型Mistral-7B-MMIQC，在MATH(arXiv:2103.03874)上达到了36.0%的准确率，比之前(model size $\sim$7B)的最佳结果高出5.8%。我们的实验还表明，改进的一个重要部分归功于我们的新颖增强方法IQC(迭代组合问题)，其中我们迭代地要求LLM从给定的种子问题中组合新问题，并从另一个LLM中进行拒绝抽样。MMIQC现已在https://huggingface.co/datasets/Vivacem/MMIQC上发布。

    Despite recent progress in improving the mathematical reasoning ability of large language models(LLMs), solving competition-level math problems without the use of external tools remains challenging for open-source LLMs. In this work, we introduce the MMIQC dataset, a mixture of processed web data and synthetic question-response pairs, to equip base models with better mathematical reasoning skills. Mistral-7B-MMIQC, the model obtained by fine-tuning Mistral-7B(arXiv:2310.06825) on MMIQC, achieves 36.0\% accuracy on MATH(arXiv:2103.03874), 5.8\% higher than the previous (model size $\sim$7B) SOTA. Our experiments also show that a large part of the improvement attributes to our novel augmentation method IQC(Iterative Question Composing), where we iteratively ask an LLM to compose new questions from the given seed problems and do rejection sampling from another LLM. MMIQC has now been released on https://huggingface.co/datasets/Vivacem/MMIQC.
    
[^57]: RAG vs Fine-tuning: 管道，权衡以及在农业上的个案研究

    RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture. (arXiv:2401.08406v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.08406](http://arxiv.org/abs/2401.08406)

    本文评估了检索增强生成（RAG）和微调两种方法在大型语言模型上的性能差异，并提出了适用于农业数据集的管道和权衡。

    

    在构建大型语言模型应用程序时，开发者通常有两种常见方法来整合专有和领域特定的数据：检索增强生成（RAG）和微调。RAG利用外部数据增强提示信息，而微调则将附加知识整合到模型中。然而，这两种方法的优缺点并不为人所理解。在本文中，我们提出了一个微调和RAG的管道，并对多种流行的大型语言模型（包括Llama2-13B，GPT-3.5和GPT-4）进行了权衡。我们的管道由多个阶段组成，包括从PDF中提取信息，生成问题和答案，将其用于微调，并利用GPT-4评估结果。我们提出了评估RAG和微调管道不同阶段性能的指标。我们对农业数据集进行了深入研究。作为一个产业，农业在人工智能的应用方面并没有得到很大的渗透。

    There are two common ways in which developers are incorporating proprietary and domain-specific data when building applications of Large Language Models (LLMs): Retrieval-Augmented Generation (RAG) and Fine-Tuning. RAG augments the prompt with the external data, while fine-Tuning incorporates the additional knowledge into the model itself. However, the pros and cons of both approaches are not well understood. In this paper, we propose a pipeline for fine-tuning and RAG, and present the tradeoffs of both for multiple popular LLMs, including Llama2-13B, GPT-3.5, and GPT-4. Our pipeline consists of multiple stages, including extracting information from PDFs, generating questions and answers, using them for fine-tuning, and leveraging GPT-4 for evaluating the results. We propose metrics to assess the performance of different stages of the RAG and fine-Tuning pipeline. We conduct an in-depth study on an agricultural dataset. Agriculture as an industry has not seen much penetration of AI, an
    
[^58]: LEGO: 语言增强的多模态关联模型

    LEGO:Language Enhanced Multi-modal Grounding Model. (arXiv:2401.06071v1 [cs.CV])

    [http://arxiv.org/abs/2401.06071](http://arxiv.org/abs/2401.06071)

    LEGO是一种语言增强的多模态关联模型，它能够在各种任务中实现细粒度的理解和精确的标识能力。

    

    多模态大型语言模型在不同模态的各种任务中展现出了令人印象深刻的性能。然而，现有的多模态模型主要强调捕捉每种模态内的全局信息，而忽视了跨模态感知局部信息的重要性。因此，这些模型缺乏有效理解输入数据细粒度细节的能力，从而限制了它们在需要更细致理解的任务中的性能。为了解决这个限制，迫切需要开发能够在多个模态之间进行细粒度理解的模型，从而增强它们在各种任务中的适用性。在本文中，我们提出了LEGO，一种语言增强的多模态关联模型。除了像其他多模态模型一样捕捉全局信息外，我们提出的模型在需要详细理解输入内的局部信息的任务中表现出色。它展示了精确的标识能力。

    Multi-modal large language models have demonstrated impressive performance across various tasks in different modalities. However, existing multi-modal models primarily emphasize capturing global information within each modality while neglecting the importance of perceiving local information across modalities. Consequently, these models lack the ability to effectively understand the fine-grained details of input data, limiting their performance in tasks that require a more nuanced understanding. To address this limitation, there is a compelling need to develop models that enable fine-grained understanding across multiple modalities, thereby enhancing their applicability to a wide range of tasks. In this paper, we propose LEGO, a language enhanced multi-modal grounding model. Beyond capturing global information like other multi-modal models, our proposed model excels at tasks demanding a detailed understanding of local information within the input. It demonstrates precise identification 
    
[^59]: TwinBooster: 结合Barlow Twins和梯度提升的大语言模型协同增强分子属性预测

    TwinBooster: Synergising Large Language Models with Barlow Twins and Gradient Boosting for Enhanced Molecular Property Prediction. (arXiv:2401.04478v1 [q-bio.BM])

    [http://arxiv.org/abs/2401.04478](http://arxiv.org/abs/2401.04478)

    TwinBooster结合了大语言模型、Barlow Twins和梯度提升，通过整合生物检测方法和分子指纹，实现了对未见过的生物检测方法和分子属性的精确预测，该方法在数据稀缺的情况下展现出了优秀的性能。

    

    药物发现和开发的成功依赖于对分子活性和属性的精确预测。虽然基于计算的分子属性预测显示出了显著的潜力，但其使用迄今为止仅限于大量数据可用的检测方法。在本研究中，我们使用经过微调的大语言模型，结合了基于文本信息的生物检测方法，并使用了一种新颖的自监督学习方法的Siamese神经网络Barlow Twins。该架构利用检测方法信息和分子指纹提取真实的分子信息。TwinBooster通过提供最先进的零样本学习任务，实现了对未见过的生物检测方法和分子的属性预测。值得注意的是，我们的人工智能流水线在FS-Mol基准测试上表现出优秀的性能。这一突破展示了深度学习在通常数据稀缺的关键属性预测任务中的应用。

    The success of drug discovery and development relies on the precise prediction of molecular activities and properties. While in silico molecular property prediction has shown remarkable potential, its use has been limited so far to assays for which large amounts of data are available. In this study, we use a fine-tuned large language model to integrate biological assays based on their textual information, coupled with Barlow Twins, a Siamese neural network using a novel self-supervised learning approach. This architecture uses both assay information and molecular fingerprints to extract the true molecular information. TwinBooster enables the prediction of properties of unseen bioassays and molecules by providing state-of-the-art zero-shot learning tasks. Remarkably, our artificial intelligence pipeline shows excellent performance on the FS-Mol benchmark. This breakthrough demonstrates the application of deep learning to critical property prediction tasks where data is typically scarce.
    
[^60]: 从LLM到对话代理：具有大型语言模型微调的记忆增强架构

    From LLM to Conversational Agent: A Memory Enhanced Architecture with Fine-Tuning of Large Language Models. (arXiv:2401.02777v1 [cs.CL])

    [http://arxiv.org/abs/2401.02777](http://arxiv.org/abs/2401.02777)

    这项工作介绍了一种名为RAISE的架构，它将大型语言模型（LLMs）如GPT-4整合到对话代理中，通过引入双组件记忆系统来增强代理在多轮对话中的可控性和适应性。预liminary evaluations表明，RAISE在房地产销售领域具有优势，并具有广泛应用的潜力。

    

    本文介绍了RAISE（Scratchpad和Examples辅助推理和行为）,一种先进的架构，增强了将GPT-4等大型语言模型（LLMs）整合到对话代理中的能力。RAISE是ReAct框架的改进版本，包括一个双组件记忆系统，模仿人类的短期记忆和长期记忆，以保持对话的上下文和连续性。它包括了一个全面的代理构建情景，包括对话选择，场景提取，CoT完成和场景增强等阶段，最终导致LLMs的训练阶段。这种方法似乎提高了代理在复杂的多轮对话中的可控性和适应性。我们在房地产销售环境中的初步评估表明，RAISE相对于传统代理有一些优势，表明它在更广泛的应用中具有潜力。通过提供一个强大的框架来开发更具上下文感知和多功能的对话代理，这项工作为AI领域做出了贡献。

    This paper introduces RAISE (Reasoning and Acting through Scratchpad and Examples), an advanced architecture enhancing the integration of Large Language Models (LLMs) like GPT-4 into conversational agents. RAISE, an enhancement of the ReAct framework, incorporates a dual-component memory system, mirroring human short-term and long-term memory, to maintain context and continuity in conversations. It entails a comprehensive agent construction scenario, including phases like Conversation Selection, Scene Extraction, CoT Completion, and Scene Augmentation, leading to the LLMs Training phase. This approach appears to enhance agent controllability and adaptability in complex, multi-turn dialogues. Our preliminary evaluations in a real estate sales context suggest that RAISE has some advantages over traditional agents, indicating its potential for broader applications. This work contributes to the AI field by providing a robust framework for developing more context-aware and versatile convers
    
[^61]: 状态是什么艺术？多提示LLM评估的呼吁。

    State of What Art? A Call for Multi-Prompt LLM Evaluation. (arXiv:2401.00595v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.00595](http://arxiv.org/abs/2401.00595)

    本研究呼吁使用多个提示来评估大语言模型（LLMs），以解决单提示评估的脆弱性，并提供了关于当前LLMs真正优势和局限性的见解。

    

    大语言模型（LLMs）的最新进展导致了各种评估基准的创建。这些基准通常依赖于单个指令模板来评估特定任务上的所有LLMs。在本文中，我们全面分析了通过单提示评估获得的结果的脆弱性，纳入了6.5M个实例，涉及20种不同的LLMs和来自3个基准的39个任务。为了改进分析的鲁棒性，我们提议使用一组多样化的提示来评估LLMs。我们讨论了特定用例（例如LLM开发人员与对特定下游任务感兴趣的开发人员）的定制评估指标，确保更可靠和有意义的LLM能力评估。然后，我们实施这些标准，并对多个模型进行评估，提供了关于当前LLMs真正优势和局限性的见解。

    Recent advances in large language models (LLMs) have led to the development of various evaluation benchmarks. These benchmarks typically rely on a single instruction template for evaluating all LLMs on a specific task. In this paper, we comprehensively analyze the brittleness of results obtained via single-prompt evaluations across 6.5M instances, involving 20 different LLMs and 39 tasks from 3 benchmarks. To improve robustness of the analysis, we propose to evaluate LLMs with a set of diverse prompts instead. We discuss tailored evaluation metrics for specific use cases (e.g., LLM developers vs. developers interested in a specific downstream task), ensuring a more reliable and meaningful assessment of LLM capabilities. We then implement these criteria and conduct evaluations of multiple models, providing insights into the true strengths and limitations of current LLMs.
    
[^62]: Auto311: 一种基于信心指导的自动非紧急通话系统

    Auto311: A Confidence-guided Automated System for Non-emergency Calls. (arXiv:2312.14185v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.14185](http://arxiv.org/abs/2312.14185)

    Auto311是第一个处理非紧急电话的自动化系统，它通过减轻非紧急电话负担，提供快速有效的响应。通过预测事件类型并生成个性化的案件报告，并从对话上下文中提取关键信息来完善报告，系统与主叫人之间的对话结构得到优化。

    

    紧急和非紧急响应系统是地方政府提供的基本服务，对于保护生命、环境和财产至关重要。有效处理（非）紧急电话对公共安全和福祉至关重要。通过减轻非紧急电话的负担，亟需911求助的居民将获得快速有效的响应。我们与纳什维尔紧急通信部门合作，分析了11,796个非紧急呼叫录音，并开发了Auto311，第一个处理311非紧急呼叫的自动化系统，该系统（1）有效动态地预测正在进行的非紧急事件类型，以在通话过程中生成个性化的案件报告；（2）从对话上下文中提取关键信息，完成生成的报告；（3）以优化的信心水平安排系统和主叫人之间的对话结构。我们使用实际数据评估了该系统的有效性。

    Emergency and non-emergency response systems are essential services provided by local governments and critical to protecting lives, the environment, and property. The effective handling of (non-)emergency calls is critical for public safety and well-being. By reducing the burden through non-emergency callers, residents in critical need of assistance through 911 will receive a fast and effective response. Collaborating with the Department of Emergency Communications (DEC) in Nashville, we analyzed 11,796 non-emergency call recordings and developed Auto311, the first automated system to handle 311 non-emergency calls, which (1) effectively and dynamically predicts ongoing non-emergency incident types to generate tailored case reports during the call; (2) itemizes essential information from dialogue contexts to complete the generated reports; and (3) strategically structures system-caller dialogues with optimized confidence. We used real-world data to evaluate the system's effectiveness a
    
[^63]: 在大型语言模型中定位事实知识：探索剩余流和分析词汇空间中的子值。

    Locating Factual Knowledge in Large Language Models: Exploring the Residual Stream and Analyzing Subvalues in Vocabulary Space. (arXiv:2312.12141v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.12141](http://arxiv.org/abs/2312.12141)

    通过探索剩余流和分析词汇空间中的子值，我们定位了大型语言模型中的事实知识，并找到了存储了有关“法国，首都，巴黎”的知识的位置。

    

    通过探索剩余流和分析词汇空间中的子值，我们找到了大型语言模型中事实知识的位置。我们发现当投影到词汇空间时，子值具有可人类解释的概念的原因。子值的softmax之前的值通过一个加法函数相加，因此词汇空间中前几个标记的概率会增加。基于此，我们发现使用对数概率增加来计算层和子值的重要性比概率增加更好，因为对数概率增加的曲线呈线性单调增形状。此外，我们计算内积来评估前馈网络（FFN）的子值被前面的层激活的程度。根据我们的方法，我们找到了事实知识“法国，首都，巴黎”存储的位置。具体来说，注意力层存储“巴黎与法国相关”。FFN层存储“巴黎是一个首都/城市”，由注意力子值激活。

    We find the location of factual knowledge in large language models by exploring the residual stream and analyzing subvalues in vocabulary space. We find the reason why subvalues have human-interpretable concepts when projecting into vocabulary space. The before-softmax values of subvalues are added by an addition function, thus the probability of top tokens in vocabulary space will increase. Based on this, we find using log probability increase to compute the significance of layers and subvalues is better than probability increase, since the curve of log probability increase has a linear monotonically increasing shape. Moreover, we calculate the inner products to evaluate how much a feed-forward network (FFN) subvalue is activated by previous layers. Base on our methods, we find where factual knowledge <France, capital, Paris> is stored. Specifically, attention layers store "Paris is related to France". FFN layers store "Paris is a capital/city", activated by attention subvalues relate
    
[^64]: 面向基于强化学习的药物调整系统以减少言语不流畅的论文翻译

    Toward A Reinforcement-Learning-Based System for Adjusting Medication to Minimize Speech Disfluency. (arXiv:2312.11509v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.11509](http://arxiv.org/abs/2312.11509)

    这个论文介绍了一种基于强化学习的系统，该系统可以根据患者言语不流畅程度自动调整药物，通过对药物组合的强化学习算法的优化，能够收敛到良好的用药方案。

    

    我们提出了一种基于强化学习的系统，该系统可以自动为患有与心理健康相关的言语不流畅的虚拟患者开具药物处方，并根据零成本频繁测量结果，调整药物和剂量。我们展示了系统的两个组成部分：一个在我们构建的大型数据集上检测和评估言语不流畅的模块，以及一个可以自动找到良好药物组合的强化学习算法。为了支持这两个模块，我们从文献中收集了关于药物治疗言语不流畅的效果的数据，并建立了一个可信的患者模拟系统。我们证明了在某些情况下，强化学习系统能够收敛到一个良好的用药方案。我们收集并对可能存在言语不流畅的人群进行了数据标注，并使用该数据集演示了我们的方法。我们的工作是一个概念验证:

    We propose a Reinforcement-Learning-based system that would automatically prescribe a hypothetical patient medication that may help the patient with their mental-health-related speech disfluency, and adjust the medication and the dosages in response to zero-cost frequent measurement of the fluency of the patient. We demonstrate the components of the system: a module that detects and evaluates speech disfluency on a large dataset we built, and a Reinforcement Learning algorithm that automatically finds good combinations of medications. To support the two modules, we collect data on the effect of psychiatric medications for speech disfluency from the literature, and build a plausible patient simulation system. We demonstrate that the Reinforcement Learning system is, under some circumstances, able to converge to a good medication regime. We collect and label a dataset of people with possible speech disfluency and demonstrate our methods using that dataset. Our work is a proof of concept:
    
[^65]: SEF-VC: 无说话人嵌入的零样本语音转换与交叉注意力

    SEF-VC: Speaker Embedding Free Zero-Shot Voice Conversion with Cross Attention. (arXiv:2312.08676v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2312.08676](http://arxiv.org/abs/2312.08676)

    SEF-VC是一种无说话人嵌入的语音转换模型，通过交叉注意力机制从参考语音中学习并融入说话人音色，具有稳定的训练和优越的语音转换性能。与强零样本语音转换基线相比，在生成高质量语音的同时能够更好地保持与目标参考的相似性，即使对于很短的参考语音。

    

    零样本语音转换旨在将源说话人的音色转换为任意未见过的目标说话人的音色，同时保持语言内容不变。尽管通过提供目标说话人的说话人嵌入可以控制生成语音的说话人相似性，但说话人相似性仍然落后于真实录音。在本文中，我们提出了SEF-VC，一种无说话人嵌入的语音转换模型，通过强大的位置无关的交叉注意力机制从参考语音中学习并融入说话人音色，然后以非自回归方式从HuBERT语义标记中重构波形。SEF-VC的简洁设计增强了其训练稳定性和语音转换性能。客观和主观评估证明，SEF-VC优于强零样本语音转换基线，能够生成与目标参考的更高相似性的高质量语音，即使对于很短的参考语音。

    Zero-shot voice conversion (VC) aims to transfer the source speaker timbre to arbitrary unseen target speaker timbre, while keeping the linguistic content unchanged. Although the voice of generated speech can be controlled by providing the speaker embedding of the target speaker, the speaker similarity still lags behind the ground truth recordings. In this paper, we propose SEF-VC, a speaker embedding free voice conversion model, which is designed to learn and incorporate speaker timbre from reference speech via a powerful position-agnostic cross-attention mechanism, and then reconstruct waveform from HuBERT semantic tokens in a non-autoregressive manner. The concise design of SEF-VC enhances its training stability and voice conversion performance. Objective and subjective evaluations demonstrate the superiority of SEF-VC to generate high-quality speech with better similarity to target reference than strong zero-shot VC baselines, even for very short reference speeches.
    
[^66]: 毒性语言检测：阿拉伯语数据集的系统综述

    Toxic language detection: a systematic review of Arabic datasets. (arXiv:2312.07228v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.07228](http://arxiv.org/abs/2312.07228)

    这项研究提供了对阿拉伯语在线毒性语言数据集的全面调研，并通过分析现有数据集的差距和问题，为未来的研究提供了建议。

    

    近年来，阿拉伯语的毒性语言检测已成为一个活跃的研究领域，并且对于回顾用于训练开发解决方案的现有数据集已成为一个迫切的需求。本文对阿拉伯语在线毒性语言的现有数据集进行了全面调研。我们系统地收集了总共54个可用数据集及其对应的论文，并进行了细致的分析，考虑了18个标准，涵盖了可用性细节、内容、注释过程和重复使用性四个主要维度。这次分析使我们能够识别出现有的差距，并对未来的研究工作提出建议。为方便研究社区，分析的数据集列表已经维护在GitHub仓库中（https://github.com/Imene1/Arabic-toxic-language）。

    The detection of toxic language in the Arabic language has emerged as an active area of research in recent years, and reviewing the existing datasets employed for training the developed solutions has become a pressing need. This paper offers a comprehensive survey of Arabic datasets focused on online toxic language. We systematically gathered a total of 54 available datasets and their corresponding papers and conducted a thorough analysis, considering 18 criteria across four primary dimensions: availability details, content, annotation process, and reusability. This analysis enabled us to identify existing gaps and make recommendations for future research works. For the convenience of the research community, the list of the analysed datasets is maintained in a GitHub repository (https://github.com/Imene1/Arabic-toxic-language).
    
[^67]: Fine-Tuning还是检索？比较在LLMs中的知识注入

    Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs. (arXiv:2312.05934v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2312.05934](http://arxiv.org/abs/2312.05934)

    该研究比较了无监督的微调和检索增强生成（RAG）这两种常见方法在LLMs中的应用。结果发现，RAG在现有知识和新知识上表现出更好的性能，而LLMs通过无监督的微调学习新的事实信息较困难。

    

    大型语言模型（LLMs）在其预训练的权重中封装了大量的事实信息，正如它们能够在不同领域回答各种问题所证明的那样。然而，这种知识本质上是有限的，很大程度上依赖于训练数据的特性。因此，使用外部数据集来整合新的信息或改进LLMs在已见信息上的能力面临着重大挑战。在这个研究中，我们比较了两种常见的方法：无监督的微调和检索增强生成（RAG）。我们在不同主题的各种知识密集型任务上评估了这两种方法。我们的发现表明，虽然无监督的微调能够提供一定的改进，但RAG在现有知识和完全新知识上始终表现出更好的性能。此外，我们发现LLMs很难通过无监督的微调来学习新的事实信息，并且暴露

    Large language models (LLMs) encapsulate a vast amount of factual information within their pre-trained weights, as evidenced by their ability to answer diverse questions across different domains. However, this knowledge is inherently limited, relying heavily on the characteristics of the training data. Consequently, using external datasets to incorporate new information or refine the capabilities of LLMs on previously seen information poses a significant challenge. In this study, we compare two common approaches: unsupervised fine-tuning and retrieval-augmented generation (RAG). We evaluate both approaches on a variety of knowledge-intensive tasks across different topics. Our findings reveal that while unsupervised fine-tuning offers some improvement, RAG consistently outperforms it, both for existing knowledge encountered during training and entirely new knowledge. Moreover, we find that LLMs struggle to learn new factual information through unsupervised fine-tuning, and that exposing
    
[^68]: 多个任务预训练和图形提示的MultiGPrompt

    MultiGPrompt for Multi-Task Pre-Training and Prompting on Graphs. (arXiv:2312.03731v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.03731](http://arxiv.org/abs/2312.03731)

    本文提出了一种名为MultiGPrompt的多任务预训练和提示框架，用于在图形表示学习中提高鲁棒性和减少标注成本。

    

    图形可以固有地对Web上相互连接的对象进行建模，从而支持一系列Web应用，比如网络分析和内容推荐。最近，图神经网络（GNNs）已经成为图表示学习的主流技术。然而，在端到端监督框架中，它们的有效性与任务特定标签的可用性密切相关。为了减少标注成本并增强在少样本设置中的鲁棒性，基于自监督任务的预训练已经成为一种有前途的方法，而提示则被提出来进一步缩小预训练任务与下游任务之间的目标差距。虽然已经对基于提示的图形学习进行了初步的探索，但它们主要利用单个预训练任务，导致从预训练数据中可能学习的通用知识的子集受限。因此，在本文中，我们提出了一种新颖的多任务预训练和提示框架MultiGPrompt，用于进一步提高对图形的表示学习。

    Graphs can inherently model interconnected objects on the Web, thereby facilitating a series of Web applications, such as web analyzing and content recommendation. Recently, Graph Neural Networks (GNNs) have emerged as a mainstream technique for graph representation learning. However, their efficacy within an end-to-end supervised framework is significantly tied to the availabilityof task-specific labels. To mitigate labeling costs and enhance robustness in few-shot settings, pre-training on self-supervised tasks has emerged as a promising method, while prompting has been proposed to further narrow the objective gap between pretext and downstream tasks. Although there has been some initial exploration of prompt-based learning on graphs, they primarily leverage a single pretext task, resulting in a limited subset of general knowledge that could be learned from the pre-training data. Hence, in this paper, we propose MultiGPrompt, a novel multi-task pre-training and prompting framework to
    
[^69]: 自补代码生成

    Self-Infilling Code Generation. (arXiv:2311.17972v2 [cs.PL] UPDATED)

    [http://arxiv.org/abs/2311.17972](http://arxiv.org/abs/2311.17972)

    本文介绍了自补代码生成的通用框架，利用自补机制实现了中断和循环机制，使传统解码进程变得非单调。利用中断机制可以推迟生成代码，增强对输出的控制；利用循环机制可以循环更新和同步生成的每个部分。

    

    本文介绍了一种自补代码生成的通用框架，它将补充操作融入自回归解码中。我们的方法利用了最近的能够进行填充的代码语言模型可以自动进行填充的观察结果：补充操作旨在根据预定义的前缀和后缀填充中间内容，而自补机制顺序生成这些周围上下文和被填充内容。我们利用这种能力在传统解码中引入了新颖的中断和循环机制，使其进化为非单调过程。中断机制允许推迟生成特定的代码，直到确定的后缀建立，增强对输出的控制。同时，循环机制利用自补和从左到右解码的互补性，可以循环更新和同步每个生成部分。我们进行了大量实验来证明我们的方法的有效性。

    This work introduces self-infilling code generation, a general framework that incorporates infilling operations into auto-regressive decoding. Our approach capitalizes on the observation that recent infilling-capable code language models can self-infill: whereas infilling operations aim to fill in the middle based on a predefined prefix and suffix, self-infilling sequentially generates both such surrounding context and the infilled content. We utilize this capability to introduce novel interruption and looping mechanisms in conventional decoding, evolving it into a non-monotonic process. Interruptions allow for postponing the generation of specific code until a definitive suffix is established, enhancing control over the output. Meanwhile, the looping mechanism, which leverages the complementary nature of self-infilling and left-to-right decoding, can iteratively update and synchronize each piece of generation cyclically. Extensive experiments are conducted to demonstrate that our prop
    
[^70]: 战争与和平（WarAgent）：基于大语言模型的世界大战多智能体模拟

    War and Peace (WarAgent): Large Language Model-based Multi-Agent Simulation of World Wars. (arXiv:2311.17227v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2311.17227](http://arxiv.org/abs/2311.17227)

    本研究提出了一个名为WarAgent的大语言模型驱动的多智能体AI系统，用于模拟历史国际冲突，并通过评估其效果和研究智能体之间的相互作用，探讨了战争的引发因素和条件。

    

    我们能否在历史的十字路口避免战争？这个问题在人类历史上一直被个人、学者、决策者和组织追求。在这项研究中，我们尝试根据人工智能（AI）和大语言模型（LLM）的最新进展来回答这个问题。我们提出了一种名为WarAgent的LLM驱动的多智能体AI系统，以模拟参与国家，在历史上的国际冲突，包括第一次世界大战（WWI）、第二次世界大战（WWII）和中国古代的战国时期（WSP）中的决策和后果。通过评估模拟的有效性，我们研究了尖端AI系统在研究复杂的集体人类行为，如国际冲突在不同环境下的能力的进展和局限性。在这些模拟中，智能体之间的相互作用也为考察引发战争的触发因素和条件提供了一种新视角。我们的发现为了解战争的触发因素和条件提供了新的观点。

    Can we avoid wars at the crossroads of history? This question has been pursued by individuals, scholars, policymakers, and organizations throughout human history. In this research, we attempt to answer the question based on the recent advances of Artificial Intelligence (AI) and Large Language Models (LLMs). We propose \textbf{WarAgent}, an LLM-powered multi-agent AI system, to simulate the participating countries, their decisions, and the consequences, in historical international conflicts, including the World War I (WWI), the World War II (WWII), and the Warring States Period (WSP) in Ancient China. By evaluating the simulation effectiveness, we examine the advancements and limitations of cutting-edge AI systems' abilities in studying complex collective human behaviors such as international conflicts under diverse settings. In these simulations, the emergent interactions among agents also offer a novel perspective for examining the triggers and conditions that lead to war. Our findin
    
[^71]: 使用大型语言模型在工程代码生成中的数据嵌入的新型预处理技术

    Novel Preprocessing Technique for Data Embedding in Engineering Code Generation Using Large Language Model. (arXiv:2311.16267v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.16267](http://arxiv.org/abs/2311.16267)

    本论文提出了一种新的预处理技术，通过利用大型语言模型（LLM）来增强工程代码生成中的性能。该技术包括利用LLM的数据拆分和数据翻新技术提高嵌入空间的语义表示，引入基于LLM的密度链条和自适应文本翻新算法评估数据翻新可信度，开发隐式知识扩展和思考提示技术，以及通过重构现有脚本生成新的高质量脚本。在使用工程模拟软件RedHawk-SC作为案例研究时，这些技术的有效性得到了证明，能够扩展和分类脚本，并在与IKEC结合使用时提高检索增强生成方法的性能。

    

    我们提出了四个主要贡献来改善大型语言模型（LLM）在生成特定领域代码时的性能：（i）利用基于LLM的数据拆分和数据翻新技术来提高嵌入空间的语义表示；（ii）引入由LLM驱动的密度链条以用于翻新可信度（CoDRC），以及用于评估数据翻新可靠性的自适应文本翻新（ATR）算法；（iii）开发隐式知识扩展和思考（IKEC）提示技术；（iv）通过有效重构现有脚本来使用LLM生成新的高质量脚本。我们以工程模拟软件RedHawk-SC为案例研究，展示了我们的数据预处理方法在扩展和分类脚本方面的有效性。当与IKEC结合使用时，这些技术可以增强检索增强生成（RAG）方法以检索更相关的信息，最终实现73.33％的“共现百分比”。

    We present four main contributions to enhance the performance of Large Language Models (LLMs) in generating domain-specific code: (i) utilizing LLM-based data splitting and data renovation techniques to improve the semantic representation of embeddings' space; (ii) introducing the Chain of Density for Renovation Credibility (CoDRC), driven by LLMs, and the Adaptive Text Renovation (ATR) algorithm for assessing data renovation reliability; (iii) developing the Implicit Knowledge Expansion and Contemplation (IKEC) Prompt technique; and (iv) effectively refactoring existing scripts to generate new and high-quality scripts with LLMs. By using engineering simulation software RedHawk-SC as a case study, we demonstrate the effectiveness of our data pre-processing method for expanding and categorizing scripts. When combined with IKEC, these techniques enhance the Retrieval-Augmented Generation (RAG) method in retrieving more relevant information, ultimately achieving a 73.33% "Percentage of Co
    
[^72]: AGI系统的元提示

    Meta Prompting for AGI Systems. (arXiv:2311.11482v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2311.11482](http://arxiv.org/abs/2311.11482)

    本文全面研究了元提示技术，这是一种创新方法，重塑了大型语言模型、多模态模型和人工智能系统在问题解决和数据解释方面的应用。通过强调信息的结构和句法，元提示将复杂问题拆解为简单的子问题，提高了效率，并且能够与少样本方法进行公平的比较。同时，本文还提出了元提示用于自动生成提示的方法。

    

    本文介绍了元提示(meta prompting)的全面研究，这是一种创新技术，重新塑造了大型语言模型(LLMs)、多模态基础模型和人工智能系统在问题解决和数据解释方面的利用。基于类型理论和范畴论，元提示注重信息的结构和句法，而不是传统以内容为中心的方法。本文探讨了元提示的形式定义，并将其与少样本提示(few-shot prompting)区分开来，并强调其在各种人工智能应用中的有效性。重点关注将元提示扩展到复杂推理任务上，展示如何将复杂问题拆分成较为简单的子问题，提高令牌效率，并使问题求解的比较更加公平，尤其是与少样本示例方法相比。此外，本文还引入了元提示用于提示任务，允许LLMs以迭代的元编程形式自动生成新的提示。

    This paper presents a comprehensive study of Meta Prompting, an innovative technique reshaping the utilization of large language models (LLMs), multi-modal foundation models, and AI systems in problem-solving and data interpretation. Grounded in type theory and category theory, Meta Prompting emphasizes the structure and syntax of information over traditional content-centric methods. The paper explores the formal definitions of Meta Prompting (MP), sets it apart from Few-Shot Prompting, and underlines its effectiveness in various AI applications. A key focus is on extending Meta Prompting to complex reasoning tasks, showing how it effectively deconstructs intricate problems into simpler sub-problems, enhancing token efficiency and enabling more equitable problem-solving comparisons, especially against few-shot example methods. Additionally, the paper introduces Meta Prompting for Prompting Tasks, allowing LLMs to self-generate new prompts in an iterative, metaprogramming-like manner. T
    
[^73]: 使用具有辅助跨模态交互的关系时态图神经网络进行对话理解

    Conversation Understanding using Relational Temporal Graph Neural Networks with Auxiliary Cross-Modality Interaction. (arXiv:2311.04507v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.04507](http://arxiv.org/abs/2311.04507)

    本论文提出了一个名为CORECT的神经网络框架，通过关系时态图神经网络和辅助跨模态交互的方式有效地捕捉对话中的情感信息。

    

    情绪识别是人类对话理解的一个关键任务，随着多模态数据的引入，如语言、声音和面部表情，这变得更具挑战性。作为一种典型的解决方案，利用全局和局部上下文信息来预测对话中每个句子（即话语）的情绪标签。具体而言，全局表示可以通过建模对话级别的跨模态交互来捕捉。局部表示通常是通过说话者或情绪变化的时间信息来推断的，忽视了话语级别的重要因素。此外，大多数现有方法采用统一输入的多模态融合特征，而不利用模态特定的表示。为了解决这些问题，我们提出了关系时态图神经网络与辅助跨模态交互（CORECT），这是一个有效捕捉对话中情感信息的神经网络框架。

    Emotion recognition is a crucial task for human conversation understanding. It becomes more challenging with the notion of multimodal data, e.g., language, voice, and facial expressions. As a typical solution, the global- and the local context information are exploited to predict the emotional label for every single sentence, i.e., utterance, in the dialogue. Specifically, the global representation could be captured via modeling of cross-modal interactions at the conversation level. The local one is often inferred using the temporal information of speakers or emotional shifts, which neglects vital factors at the utterance level. Additionally, most existing approaches take fused features of multiple modalities in an unified input without leveraging modality-specific representations. Motivating from these problems, we propose the Relational Temporal Graph Neural Network with Auxiliary Cross-Modality Interaction (CORECT), an novel neural network framework that effectively captures convers
    
[^74]: 一种用于大型语言模型的一次敏感度感知混合稀疏化剪枝方法

    One-Shot Sensitivity-Aware Mixed Sparsity Pruning for Large Language Models. (arXiv:2310.09499v1 [cs.CL])

    [http://arxiv.org/abs/2310.09499](http://arxiv.org/abs/2310.09499)

    我们提出了一种基于敏感度感知混合稀疏化剪枝的方法，可以在不重新训练的情况下将大型语言模型剪枝至至少50％的稀疏性，同时保持稀疏性水平和减少剪枝引起的误差。此外，该方法还与量化兼容，可以进一步压缩语言模型。

    

    从生成预训练变压器（GPT）系列中的各种大型语言模型（LLMs）在各种文本生成任务中取得了卓越的性能。然而，由于高推理延迟，巨大的模型大小阻碍了它们在实际应用中的实用性。因此，通过量化、剪枝和其他方法提高LLMs的效率成为LLM研究的一个关键问题。在这项工作中，我们提出了一种基于Hessian敏感度感知混合稀疏化剪枝的方法，可以将LLMs剪枝至至少50%的稀疏性，而无需重新训练。它根据敏感度自适应地分配稀疏性，使我们能够降低剪枝引起的误差，同时保持整体稀疏性水平。当稀疏度非常高时，所提出的方法的优势更加明显。此外，我们的方法与量化兼容，可以进一步压缩LLMs。

    Various Large Language Models(LLMs) from the Generative Pretrained Transformer~(GPT) family have achieved outstanding performances in a wide range of text generation tasks. However, the enormous model sizes have hindered their practical use in real-world applications due to high inference latency. Therefore, improving the efficiencies of LLMs through quantization, pruning, and other means has been a key issue in LLM studies. In this work, we propose a method based on Hessian sensitivity-aware mixed sparsity pruning to prune LLMs to at least 50\% sparsity without the need of any retraining. It allocates sparsity adaptively based on sensitivity, allowing us to reduce pruning-induced error while maintaining the overall sparsity level. The advantages of the proposed method exhibit even more when the sparsity is extremely high. Furthermore, our method is compatible with quantization, enabling further compression of LLMs.
    
[^75]: EMO: Earth Mover Distance Optimization for Auto-Regressive Language Modeling. (arXiv:2310.04691v2 [cs.CL] UPDATED)

    EMO: Earth Mover Distance Optimization for Auto-Regressive Language Modeling. (arXiv:2310.04691v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.04691](http://arxiv.org/abs/2310.04691)

    EMO提出了地球移动距离优化（EMO）来解决语言模型中的退化现象。EMO利用了地球移动距离的特性，并引入了一个可行的上界来简化训练。经过评估，发现EMO在语言模型上有显著的改进。

    

    神经语言模型是人文本的概率模型。它们主要通过最大似然估计（MLE）进行训练，该方法等同于最小化经验数据分布和模型分布之间的前向交叉熵。然而，当从这些模型学习的分布解码时，仍然经常观察到各种退化现象。我们确定前向交叉熵作为人与模型分布对齐的距离度量是次优的，原因有：（1）召回优化，（2）负样本多样性忽视和（3）训练测试不匹配。在本文中，我们提出了用于自回归语言模型的地球移动距离优化（EMO）。EMO利用地球移动距离的内在特性来解决上述挑战。由于直接计算的复杂性，我们进一步引入了一种可行的EMO上界来简化端到端训练。经过广泛评估之后，发现我们的方法在语言模型上有显著的改进。

    Neural language models are probabilistic models of human text. They are predominantly trained using maximum likelihood estimation (MLE), which is equivalent to minimizing the forward cross-entropy between the empirical data distribution and the model distribution. However, various degeneration phenomena are still widely observed when decoding from the distributions learned by such models. We establish that the forward cross-entropy is suboptimal as a distance metric for aligning human and model distribution due to its (1) recall-prioritization (2) negative diversity ignorance and (3) train-test mismatch. In this paper, we propose Earth Mover Distance Optimization (EMO) for auto-regressive language modeling. EMO capitalizes on the inherent properties of earth mover distance to address the aforementioned challenges. Due to the high complexity of direct computation, we further introduce a feasible upper bound for EMO to ease end-to-end training. Upon extensive evaluation of language model
    
[^76]: 从旋律中利用字符级语言模型生成音节级歌词

    Syllable-level lyrics generation from melody exploiting character-level language model. (arXiv:2310.00863v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.00863](http://arxiv.org/abs/2310.00863)

    该论文提出了一种利用字符级语言模型从旋律中生成音节级歌词的方法，并通过融合语言模型知识和生成器网络进行优化。通过探索ChatGPT的评估方法，以及人工评估，证明了该方法提高了生成歌词的连贯性和正确性。

    

    生成与伴奏旋律紧密相关的歌词涉及建立音乐音符与歌词音节之间的映射。这个过程需要对音节级、词级和句级语义意义上的音乐约束和语义模式有深入的理解。然而，公开的音节级预训练语言模型并不存在。为了解决这些具有挑战性的问题，我们提出利用以字符级语言模型进行音节级歌词生成。特别地，我们的方法将语言模型的语言知识融入音节级Transformer生成器网络的束搜索过程中。此外，通过探索基于ChatGPT的生成歌词评估方法，以及人工主观评估，我们证明了我们的方法增强了生成歌词的连贯性和正确性，消除了训练昂贵的新模型的需求。

    The generation of lyrics tightly connected to accompanying melodies involves establishing a mapping between musical notes and syllables of lyrics. This process requires a deep understanding of music constraints and semantic patterns at syllable-level, word-level, and sentence-level semantic meanings. However, pre-trained language models specifically designed at the syllable level are publicly unavailable. To solve these challenging issues, we propose to exploit fine-tuning character-level language models for syllable-level lyrics generation from symbolic melody. In particular, our method endeavors to incorporate linguistic knowledge of the language model into the beam search process of a syllable-level Transformer generator network. Additionally, by exploring ChatGPT-based evaluation for generated lyrics, along with human subjective evaluation, we demonstrate that our approach enhances the coherence and correctness of the generated lyrics, eliminating the need to train expensive new la
    
[^77]: 大型语言模型下的创造力支持: 一项涉及新兴作家的实证研究

    Creativity Support in the Age of Large Language Models: An Empirical Study Involving Emerging Writers. (arXiv:2309.12570v1 [cs.HC])

    [http://arxiv.org/abs/2309.12570](http://arxiv.org/abs/2309.12570)

    本文通过实证研究探讨了大型语言模型（LLM）在协助专业作家方面的效用，并发现作家们更倾向于在翻译和审查阶段中寻求LLM的帮助。

    

    大型语言模型（LLM）的发展使得其能够遵循指令并参与对话互动，引发了在各种支持工具中利用它们的兴趣增加。我们通过一项实证用户研究（n=30）探讨了现代LLM在协助专业作家方面的效用。我们的合作写作界面设计基于将写作视为一个目标导向的思维过程的认知过程模型，涵盖了非线性的认知活动：规划、翻译和审查。参与者被要求提交一份后完成调查，以提供关于LLM作为写作合作者潜力和问题的反馈。通过分析作家-LLM互动,我们发现作家在三种类型的认知活动中都寻求LLM的帮助，但他们发现LLM在翻译和审查方面更有帮助。通过分析互动和调查结果，我们的发现强调了未来研究的方向。

    The development of large language models (LLMs) capable of following instructions and engaging in conversational interactions sparked increased interest in their utilization across various support tools. We investigate the utility of modern LLMs in assisting professional writers via an empirical user study (n=30). The design of our collaborative writing interface is grounded in the cognitive process model of writing that views writing as a goal-oriented thinking process encompassing non-linear cognitive activities: planning, translating, and reviewing. Participants are asked to submit a post-completion survey to provide feedback on the potential and pitfalls of LLMs as writing collaborators. Upon analyzing the writer-LLM interactions, we find that while writers seek LLM's help across all three types of cognitive activities, they find LLMs more helpful in translation and reviewing. Our findings from analyzing both the interactions and the survey responses highlight future research direc
    
[^78]: MAPLE: 基于大型语言模型嵌入的移动应用预测

    MAPLE: Mobile App Prediction Leveraging Large Language model Embeddings. (arXiv:2309.08648v1 [cs.CL])

    [http://arxiv.org/abs/2309.08648](http://arxiv.org/abs/2309.08648)

    MAPLE是一个利用大型语言模型嵌入进行移动应用预测的模型，通过严格测试验证了其在解密复杂模式和理解用户环境方面的能力，并强调了语言模型在不同领域中的广泛适用性。

    

    尽管移动应用的发展迅速，但由于复杂的用户行为和不断演变的环境，预测应用的使用仍然是一个严峻的挑战。为了解决这些问题，本文介绍了Mobile App Prediction Leveraging Large Language Model Embeddings (MAPLE)模型。这种创新的方法利用大型语言模型(LLM)来准确预测应用的使用情况。通过对两个公开数据集进行严格测试，MAPLE的能力在解密复杂模式和理解用户环境方面得到了验证。这些强大的结果证实了MAPLE在不同场景中的多功能性和弹性。尽管其主要设计面向应用预测，但结果也强调了LLM在不同领域中的广泛适用性。通过这项研究，我们强调了LLM在应用使用预测中的潜力，并建议在建模各种领域中的人类行为方面，它们具有变革能力。

    Despite the rapid advancement of mobile applications, predicting app usage remains a formidable challenge due to intricate user behaviours and ever-evolving contexts. To address these issues, this paper introduces the Mobile App Prediction Leveraging Large Language Model Embeddings (MAPLE) model. This innovative approach utilizes Large Language Models (LLMs) to predict app usage accurately. Rigorous testing on two public datasets highlights MAPLE's capability to decipher intricate patterns and comprehend user contexts. These robust results confirm MAPLE's versatility and resilience across various scenarios. While its primary design caters to app prediction, the outcomes also emphasize the broader applicability of LLMs in different domains. Through this research, we emphasize the potential of LLMs in app usage prediction and suggest their transformative capacity in modelling human behaviours across diverse fields.
    
[^79]: 语言模型在与知识库进行连接时的数据分布瓶颈

    Data Distribution Bottlenecks in Grounding Language Models to Knowledge Bases. (arXiv:2309.08345v1 [cs.CL])

    [http://arxiv.org/abs/2309.08345](http://arxiv.org/abs/2309.08345)

    本文通过实验调查揭示了语言模型在与知识库进行连接时的数据分布瓶颈，包括推广到未见域、适应语言变体和在不同数据集之间的可转移性等方面。即使采用数据增强技术，先进的语言模型在多个方面表现出较差的性能。

    

    语言模型（LM）已经展示了在理解和生成自然语言和形式语言方面的卓越能力。尽管取得了这些进展，但它们与大规模知识库等现实环境的整合仍然是一个欠发展的领域，影响了语义解析等应用，并且容易出现“产生虚假信息”的问题。本文通过实验调查揭示了LM在处理知识库问答（KBQA）任务时所遇到的健壮性挑战。研究覆盖了训练和推断之间数据分布不一致的场景，例如推广到未见域、适应各种语言变体和在不同数据集之间的可转移性。我们的全面实验揭示了即使在采用我们提出的数据增强技术的情况下，先进的小型和大型语言模型在多个方面表现出较差的性能。

    Language models (LMs) have already demonstrated remarkable abilities in understanding and generating both natural and formal language. Despite these advances, their integration with real-world environments such as large-scale knowledge bases (KBs) remains an underdeveloped area, affecting applications such as semantic parsing and indulging in "hallucinated" information. This paper is an experimental investigation aimed at uncovering the robustness challenges that LMs encounter when tasked with knowledge base question answering (KBQA). The investigation covers scenarios with inconsistent data distribution between training and inference, such as generalization to unseen domains, adaptation to various language variations, and transferability across different datasets. Our comprehensive experiments reveal that even when employed with our proposed data augmentation techniques, advanced small and large language models exhibit poor performance in various dimensions. While the LM is a promisin
    
[^80]: 具有大型语言模型的上下文学习中的歧义感知

    Ambiguity-Aware In-Context Learning with Large Language Models. (arXiv:2309.07900v1 [cs.CL])

    [http://arxiv.org/abs/2309.07900](http://arxiv.org/abs/2309.07900)

    在上下文学习中，选择与测试输入语义相似的演示有助于提高下游性能，但是考虑到语言模型关于任务的现有知识能够更好地指导演示选择。

    

    在上下文学习（In-context learning, ICL）中，仅向LLMs展示少量任务特定演示已经导致了下游增益，无需进行任务特定的微调。然而，LLMs对于提示选择非常敏感，因此一个关键的研究问题是如何为ICL选择好的演示。一种有效的策略是利用ICL演示和测试输入之间的语义相似性，并使用文本检索器，然而这种方法并不考虑LLM关于该任务的现有知识，因此并不最优。根据之前的工作（Min等，2022），我们已经知道与演示配对的标签会对模型预测造成偏见。这引导我们提出了一个假设：考虑到LLM关于任务的现有知识，特别是与输出标签空间相关的知识，是否有助于更好的演示选择策略。通过在三个文本分类任务上进行广泛的实验，我们发现不仅选择语义相似的ICL演示是有益的，同时也要考虑LLM关于任务的现有知识以获得更好的演示选择策略。

    In-context learning (ICL) i.e. showing LLMs only a few task-specific demonstrations has led to downstream gains with no task-specific fine-tuning required. However, LLMs are sensitive to the choice of prompts, and therefore a crucial research question is how to select good demonstrations for ICL. One effective strategy is leveraging semantic similarity between the ICL demonstrations and test inputs by using a text retriever, which however is sub-optimal as that does not consider the LLM's existing knowledge about that task. From prior work (Min et al., 2022), we already know that labels paired with the demonstrations bias the model predictions. This leads us to our hypothesis whether considering LLM's existing knowledge about the task, especially with respect to the output label space can help in a better demonstration selection strategy. Through extensive experimentation on three text classification tasks, we find that it is beneficial to not only choose semantically similar ICL demon
    
[^81]: 切断电路: 通过有针对性的消融去除模型行为

    Circuit Breaking: Removing Model Behaviors with Targeted Ablation. (arXiv:2309.05973v1 [cs.CL])

    [http://arxiv.org/abs/2309.05973](http://arxiv.org/abs/2309.05973)

    本论文提出了一种通过有针对性的消融模型组件之间的因果路径来去除语言模型中不良行为的新方法。在减少GPT-2毒性语言生成方面，仅消融12条因果边中的11.6K可以有效减轻毒性生成，并在其他输入上的性能下降很小。

    

    语言模型通常会表现出在预训练目标上提高性能但在下游任务上降低性能的行为。我们提出了一种新颖的方法，通过消融模型组件之间的一小部分因果路径，以禁用与不良行为有关的计算电路，从而去除不良行为。在拥有模型表现差的小型输入数据集的情况下，我们学会了消融一小部分重要的因果路径。在减少GPT-2毒性语言生成方面，我们发现消融仅仅12条因果边中的11.6K，可以减轻毒性生成，同时在其他输入上的性能下降很小。

    Language models often exhibit behaviors that improve performance on a pre-training objective but harm performance on downstream tasks. We propose a novel approach to removing undesirable behaviors by ablating a small number of causal pathways between model components, with the intention of disabling the computational circuit responsible for the bad behavior. Given a small dataset of inputs where the model behaves poorly, we learn to ablate a small number of important causal pathways. In the setting of reducing GPT-2 toxic language generation, we find ablating just 12 of the 11.6K causal edges mitigates toxic generation with minimal degradation of performance on other inputs.
    
[^82]: 有效的语言模型基准测试

    Efficient Benchmarking (of Language Models). (arXiv:2308.11696v1 [cs.CL])

    [http://arxiv.org/abs/2308.11696](http://arxiv.org/abs/2308.11696)

    本研究提出了一种名为"Efficient Benchmarking"的问题，旨在智能地减少语言模型评估的计算成本而不降低可靠性，并使用一种名为Decision Impact on Reliability（DIoR）的新度量来评估决策的可靠性。通过HELM基准测试的案例研究，发现只需删除一个低排名模型即可改变领先者，并仅需少量示例即可得到正确的基准测试排名。

    

    语言模型的多功能性增加导致了一类全面评估广泛能力的基准测试的出现。这些基准测试与大规模计算成本相关，每个模型需要数千个GPU小时。然而，关于评估效率方面的问题在文献中讨论较少。本文提出了一种名为"Efficient Benchmarking"的问题，即在不损害可靠性的情况下智能地减少语言模型评估的计算成本。通过使用HELM基准测试作为示例，我们研究了不同基准测试设计选择如何影响计算-可靠性权衡。我们提出使用一种名为Decision Impact on Reliability（DIoR）的新度量来评估这些决策的可靠性。例如，我们发现仅通过从基准测试中删除一个低排名模型，当前在HELM上的领先者可能会改变，并且观察到只需一小部分示例即可获得正确的基准测试排名。

    The increasing versatility of language models LMs has given rise to a new class of benchmarks that comprehensively assess a broad range of capabilities. Such benchmarks are associated with massive computational costs reaching thousands of GPU hours per model. However the efficiency aspect of these evaluation efforts had raised little discussion in the literature. In this work we present the problem of Efficient Benchmarking namely intelligently reducing the computation costs of LM evaluation without compromising reliability. Using the HELM benchmark as a test case we investigate how different benchmark design choices affect the computation-reliability tradeoff. We propose to evaluate the reliability of such decisions by using a new measure Decision Impact on Reliability DIoR for short. We find for example that the current leader on HELM may change by merely removing a low-ranked model from the benchmark and observe that a handful of examples suffice to obtain the correct benchmark rank
    
[^83]: 评估大型中文语言模型的生成能力

    Evaluating the Generation Capabilities of Large Chinese Language Models. (arXiv:2308.04823v1 [cs.CL])

    [http://arxiv.org/abs/2308.04823](http://arxiv.org/abs/2308.04823)

    本文首次对大型中文语言模型在多个学科领域的生成能力进行了全面评估，并提出了Gscore作为衡量生成结果质量的综合指数。

    

    本文介绍了CG-Eval，这是第一个对大型中文语言模型在多个学科领域生成能力进行全面评估的研究。通过在科学工程、人文社科、数学计算、医师资格考试、司法考试和注册会计师考试六个学科中生成准确和相关的回答，评估了这些模型的性能。本文还提出了Gscore，这是一个由多个度量指标加权求和得到的综合指数，用于衡量模型生成结果与参考答案的质量。测试数据和测试结果可在此http URL找到。

    This paper presents CG-Eval, the first comprehensive evaluation of the generation capabilities of large Chinese language models across a wide range of academic disciplines. The models' performance was assessed based on their ability to generate accurate and relevant responses to different types of questions in six disciplines, namely, Science and Engineering, Humanities and Social Sciences, Mathematical Calculations, Medical Practitioner Qualification Examination, Judicial Examination, and Certified Public Accountant Examination. This paper also presents Gscore, a composite index derived from the weighted sum of multiple metrics to measure the quality of model's generation against a reference. The test data and test results can be found at this http URL
    
[^84]: 为事实感知语言建模增强大型语言模型的知识图谱

    Give Us the Facts: Enhancing Large Language Models with Knowledge Graphs for Fact-aware Language Modeling. (arXiv:2306.11489v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.11489](http://arxiv.org/abs/2306.11489)

    这篇论文研究了如何通过知识图谱增强大型语言模型，提高其生成内容的准确性和对用户查询的回复能力。

    

    最近，ChatGPT作为一个代表性的大型语言模型（LLM），因其强大的新兴能力而受到了相当大的关注。一些研究人员认为，LLMs有可能取代知识图谱（KGs）这样的结构化知识库，成为参数化知识库。然而，虽然LLMs擅长基于大语料库学习概率语言模式，并与人类进行对话，但它们与之前较小的预训练语言模型（PLMs）一样，在生成基于知识的内容时仍然难以回忆事实。为了克服这些局限性，研究人员提出了通过知识图谱增强数据驱动的PLMs，将明确的事实知识融入PLMs，从而提高其生成需要事实知识的文本的性能，并为用户查询提供更多见解的回复。本文回顾了有关使用KG增强PLMs的研究，详细介绍了现有的知识图谱增强预训练模型PLM的方法。

    Recently, ChatGPT, a representative large language model (LLM), has gained considerable attention due to its powerful emergent abilities. Some researchers suggest that LLMs could potentially replace structured knowledge bases like knowledge graphs (KGs) and function as parameterized knowledge bases. However, while LLMs are proficient at learning probabilistic language patterns based on large corpus and engaging in conversations with humans, they, like previous smaller pre-trained language models (PLMs), still have difficulty in recalling facts while generating knowledge-grounded contents. To overcome these limitations, researchers have proposed enhancing data-driven PLMs with knowledge-based KGs to incorporate explicit factual knowledge into PLMs, thus improving their performance to generate texts requiring factual knowledge and providing more informed responses to user queries. This paper reviews the studies on enhancing PLMs with KGs, detailing existing knowledge graph enhanced pre-t
    
[^85]: ReactGenie：使用大型语言模型的面向对象状态抽象来支持复杂的多模态交互

    ReactGenie: An Object-Oriented State Abstraction for Complex Multimodal Interactions Using Large Language Models. (arXiv:2306.09649v1 [cs.HC])

    [http://arxiv.org/abs/2306.09649](http://arxiv.org/abs/2306.09649)

    ReactGenie是一个支持构建复杂的多模态移动应用程序的编程框架，通过使用共享的面向对象状态抽象，使得不同模态可以无缝集成和组合，从而实现了多模态交互的支持。

    

    多模态交互已被证明比传统的图形界面更加灵活、高效和适应各种用户和任务。然而，现有的多模态开发框架要么不能很好地处理多模态命令的复杂性和组合性，要么需要开发人员编写大量代码来支持这些多模态交互。本文提出了ReactGenie，这是一个编程框架，使用共享的面向对象状态抽象来支持构建复杂的多模态移动应用程序。具有不同模态的共享状态抽象使得使用ReactGenie的开发人员能够无缝地集成和组合这些模态以实现多模态交互。ReactGenie是构建图形应用程序的现有工作流程的自然扩展，就像使用React-Redux一样。开发人员只需要添加一些注释和示例来指示自然语言如何映射到用户可访问的状态即可。

    Multimodal interactions have been shown to be more flexible, efficient, and adaptable for diverse users and tasks than traditional graphical interfaces. However, existing multimodal development frameworks either do not handle the complexity and compositionality of multimodal commands well or require developers to write a substantial amount of code to support these multimodal interactions. In this paper, we present ReactGenie, a programming framework that uses a shared object-oriented state abstraction to support building complex multimodal mobile applications. Having different modalities share the same state abstraction allows developers using ReactGenie to seamlessly integrate and compose these modalities to deliver multimodal interaction.  ReactGenie is a natural extension to the existing workflow of building a graphical app, like the workflow with React-Redux. Developers only have to add a few annotations and examples to indicate how natural language is mapped to the user-accessible
    
[^86]: 文本预训练的语音语言模型

    Textually Pretrained Speech Language Models. (arXiv:2305.13009v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.13009](http://arxiv.org/abs/2305.13009)

    本论文提出了一种使用预训练的文本语言模型训练语音语言模型的方法，通过对模型设计选择和数据集规模的经验性分析，构建了参数数量和训练数据最多的语音语言模型，并引入了两个Spoken版本的文本基准，以进一步改善模型评估和推动未来研究。

    

    语音语言模型（SpeechLMs）仅处理和生成音频数据，没有文字监督。在这项工作中，我们提出了TWIST，一种使用预训练的文本语言模型进行SpeechLMs训练的方法。我们通过自动和人工评估表明，TWIST在各个方面都优于冷启动的SpeechLM。我们经验性地分析了不同的模型设计选择（如语音分词器、预训练的文本模型和数据集大小）的影响。我们发现模型和数据集规模在构建性能更好的SpeechLMs方面都起着重要作用。基于我们的观察，我们介绍了迄今为止参数数量和训练数据最多的SpeechLM（据我们所知）。此外，我们还引入了两个Spoken版本的StoryCloze文本基准，以进一步改善模型评估并推动该领域的未来研究。我们公开提供语音样本、代码和模型：https://pages.cs.huji.ac.il/

    Speech language models (SpeechLMs) process and generate acoustic data only, without textual supervision. In this work, we propose TWIST, a method for training SpeechLMs using a warm-start from a pretrained textual language models. We show using both automatic and human evaluations that TWIST outperforms a cold-start SpeechLM across the board. We empirically analyze the effect of different model design choices such as the speech tokenizer, the pretrained textual model, and the dataset size. We find that model and dataset scale both play an important role in constructing better-performing SpeechLMs. Based on our observations, we present the largest (to the best of our knowledge) SpeechLM both in terms of number of parameters and training data. We additionally introduce two spoken versions of the StoryCloze textual benchmark to further improve model evaluation and advance future research in the field. We make speech samples, code and models publicly available: https://pages.cs.huji.ac.il/
    
[^87]: 基于fMRI的语言编码模型的规模定律研究

    Scaling laws for language encoding models in fMRI. (arXiv:2305.11863v1 [cs.CL])

    [http://arxiv.org/abs/2305.11863](http://arxiv.org/abs/2305.11863)

    本文揭示了基于fMRI的语言编码模型预测性能与模型大小呈对数线性关系，在125M到30B参数模型进行规模扩展时，表现提高了约15％。

    

    基于变压器的单向语言模型的表示已被证明能够有效地预测大脑对自然语言的反应。然而，大多数比较语言模型与大脑的研究都使用了类似GPT-2大小的语言模型。本研究测试了是否更大的开源模型（如OPT和LLaMA系列）更适用于预测使用fMRI记录的大脑反应。结果显示，在从125M到30B参数模型进行规模扩展时，大脑预测性能与模型大小呈对数线性关系，跨3个受试者的保留测试集相关性表现提高了约15％。当扩展fMRI训练集的大小时，我们也观察到了类似的对数线性行为。我们还对使用HuBERT，WavLM和Whisper的声学编码模型进行了规模定律研究，发现模型大小的增加带来了类似的改进。我们还使用噪音天花板分析了这些大规模且高性能的编码模型。

    Representations from transformer-based unidirectional language models are known to be effective at predicting brain responses to natural language. However, most studies comparing language models to brains have used GPT-2 or similarly sized language models. Here we tested whether larger open-source models such as those from the OPT and LLaMA families are better at predicting brain responses recorded using fMRI. Mirroring scaling results from other contexts, we found that brain prediction performance scales log-linearly with model size from 125M to 30B parameter models, with ~15% increased encoding performance as measured by correlation with a held-out test set across 3 subjects. Similar log-linear behavior was observed when scaling the size of the fMRI training set. We also characterized scaling for acoustic encoding models that use HuBERT, WavLM, and Whisper, and we found comparable improvements with model size. A noise ceiling analysis of these large, high-performance encoding models 
    
[^88]: 通过人机协作解决自然语言处理难题：一种基于讨论的方法

    Solving NLP Problems through Human-System Collaboration: A Discussion-based Approach. (arXiv:2305.11789v1 [cs.CL])

    [http://arxiv.org/abs/2305.11789](http://arxiv.org/abs/2305.11789)

    本研究提出了一种基于讨论的方法，旨在通过人机协作解决自然语言处理难题。提出了一个可以进行对话并修正预测的系统，通过实验证明该系统可以通过与人类的讨论提高准确性高达25%。

    

    人类通过讨论、解释并相互赞同或反对等方式共同解决共同问题。同样，如果系统在解决任务时能与人类进行讨论，它可以提高系统的性能和可靠性。在之前的可解释性研究中，系统只能做出预测，人类只能就这些预测提问，而没有彼此间的意见交换。本研究旨在创建一个数据集和计算框架，使系统可以通过对话进行讨论和修正预测。通过实验证明，所提出的系统可以与人类进行有益的讨论，将自然语言推理任务的准确性提高了高达25个百分点。

    Humans work together to solve common problems by having discussions, explaining, and agreeing or disagreeing with each other. Similarly, if a system can have discussions with humans when solving tasks, it can improve the system's performance and reliability. In previous research on explainability, it has only been possible for the system to make predictions and for humans to ask questions about them rather than having a mutual exchange of opinions. This research aims to create a dataset and computational framework for systems that discuss and refine their predictions through dialogue. Through experiments, we show that the proposed system can have beneficial discussions with humans improving the accuracy by up to 25 points in the natural language inference task.
    
[^89]: 融合归因重要性以提高忠实度评估的方法

    Incorporating Attribution Importance for Improving Faithfulness Metrics. (arXiv:2305.10496v1 [cs.CL])

    [http://arxiv.org/abs/2305.10496](http://arxiv.org/abs/2305.10496)

    本研究提出了一种软删除标准来评估归因方法的忠实度，该方法随机遮盖标记的部分向量表示，这种方法比现有的硬删除标准更准确。

    

    特征归因方法是提供对模型推理过程进行预测的流行方法。一个更加准确的归因方法标志着它更加忠实，它可以更加准确地反映哪些部分的输入对预测更加重要。然而，现有的忠实度评估方法，如充分性和全面性，只使用一种硬删除标准，即完全删除或保留由给定归因方法排名最高的顶部标记，并观察预测可能性的变化。因此，这种硬删除标准忽略了每个标记的重要性，把它们全部等同地处理。在本文中，我们提出了一个简单而有效的软删除标准。我们不会完全删除或保留输入中的标记，而是随机地遮盖代表归因方法重要性的部分标记向量表示。基于各种自然语言处理任务和不同的归因方法进行的广泛实验表明，我们的方法显著优于现有的评估方法。

    Feature attribution methods (FAs) are popular approaches for providing insights into the model reasoning process of making predictions. The more faithful a FA is, the more accurately it reflects which parts of the input are more important for the prediction. Widely used faithfulness metrics, such as sufficiency and comprehensiveness use a hard erasure criterion, i.e. entirely removing or retaining the top most important tokens ranked by a given FA and observing the changes in predictive likelihood. However, this hard criterion ignores the importance of each individual token, treating them all equally for computing sufficiency and comprehensiveness. In this paper, we propose a simple yet effective soft erasure criterion. Instead of entirely removing or retaining tokens from the input, we randomly mask parts of the token vector representations proportionately to their FA importance. Extensive experiments across various natural language processing tasks and different FAs show that our sof
    
[^90]: 基于知识增强的生成预训练模型在中国医学执业医师资格考试上的应用研究

    Qualifying Chinese Medical Licensing Examination with Knowledge Enhanced Generative Pre-training Model. (arXiv:2305.10163v1 [cs.CL])

    [http://arxiv.org/abs/2305.10163](http://arxiv.org/abs/2305.10163)

    本研究通过在ChatGPT中集成医学领域知识和启用少样本学习的新方法，在中国国家医学执业医师资格考试中取得成功，这为建立在自然语言处理技术和医学领域知识的创新应用提供了可能。

    

    生成式预训练模型（GPT），如ChatGPT，在各种自然语言处理任务中展现出了出色的性能。尽管ChatGPT已被整合到各个领域的工作流中以提高效率，但其微调过程的灵活性不足，阻碍了其在需要广泛领域专业知识和语义知识的领域，如医疗保健，的应用。在本文中，我们评估了ChatGPT在中国国家医学执业医师资格考试（CNMLE）中的表现，并提出了一种新的方法来改进ChatGPT，即从两个方面集成医学领域知识和启用少样本学习。通过使用简单但有效的检索方法，将医学背景知识提取为语义指令来指导ChatGPT的推断。类似地，相关的医疗问题被识别并作为演示输入给ChatGPT。实验结果表明，直接应用ChatGPT无法在CNMLE上获得合格分数（51分），只有基于知识增强训练的模型成功通过考试。

    Generative Pre-Training (GPT) models like ChatGPT have demonstrated exceptional performance in various Natural Language Processing (NLP) tasks. Although ChatGPT has been integrated into the overall workflow to boost efficiency in many domains, the lack of flexibility in the finetuning process hinders its applications in areas that demand extensive domain expertise and semantic knowledge, such as healthcare. In this paper, we evaluate ChatGPT on the China National Medical Licensing Examination (CNMLE) and propose a novel approach to improve ChatGPT from two perspectives: integrating medical domain knowledge and enabling few-shot learning. By using a simple but effective retrieval method, medical background knowledge is extracted as semantic instructions to guide the inference of ChatGPT. Similarly, relevant medical questions are identified and fed as demonstrations to ChatGPT. Experimental results show that directly applying ChatGPT fails to qualify the CNMLE at a score of 51 (i.e., onl
    
[^91]: 主动的连续学习：在任务序列中标记查询。

    Active Continual Learning: Labelling Queries in a Sequence of Tasks. (arXiv:2305.03923v1 [cs.LG])

    [http://arxiv.org/abs/2305.03923](http://arxiv.org/abs/2305.03923)

    本文考虑了一系列主动学习任务的主动连续学习问题，研究了不同场景下多种主动和连续学习算法之间的有效性和相互作用，并提出了遗忘-学习曲线方法来平衡不忘旧知识和快速学习的两个目标。

    

    在连续学习（CL）中，获取新知识并不忘记已学内容是其核心。而任务是按顺序出现的，训练数据的准备和注释则通常是独立的，因此需要连续学习来适应新的监督学习任务。本文考虑了一系列主动学习（AL）任务的主动连续学习（ACL）中未被充分探索的问题，每个任务包括一个未标记的数据池和一个注释预算。我们研究了几种AL和CL算法在不同领域，类别和任务增量场景中的有效性和相互作用。实验揭示了不忘旧知识和快速学习在CL和AL中之间的权衡。尽管在以前任务的注释收集上条件查询策略会提高领域和任务增量学习的任务性能，但我们提出的遗忘-学习曲线则更好地平衡了这两个目标。

    Acquiring new knowledge without forgetting what has been learned in a sequence of tasks is the central focus of continual learning (CL). While tasks arrive sequentially, the training data are often prepared and annotated independently, leading to CL of incoming supervised learning tasks. This paper considers the under-explored problem of active continual learning (ACL) for a sequence of active learning (AL) tasks, where each incoming task includes a pool of unlabelled data and an annotation budget. We investigate the effectiveness and interplay between several AL and CL algorithms in the domain, class and task-incremental scenarios. Our experiments reveal the trade-off between two contrasting goals of not forgetting the old knowledge and the ability to quickly learn in CL and AL. While conditioning the query strategy on the annotations collected for the previous tasks leads to improved task performance on the domain and task incremental learning, our proposed forgetting-learning profil
    
[^92]: 使用抽象意义表示减少翻译语言的特征

    Translationese Reduction using Abstract Meaning Representation. (arXiv:2304.11501v1 [cs.CL])

    [http://arxiv.org/abs/2304.11501](http://arxiv.org/abs/2304.11501)

    研究使用抽象意义表示（AMR）作为跨语言方案可以减少翻译语言学数量。

    

    翻译文本或话语具有与本地语言不同的几个明显特征。这种现象被称为翻译语言学，已经有了很好的文献记录，当出现在训练或测试集中时，会影响模型性能。但是，减少人工翻译文本中翻译语言学的研究工作还很少。我们假设抽象意义表示（AMR）作为一种从表面形式抽象出来的语义表示，可以用作减少翻译语言学数量的一种跨语言方案。通过将英文翻译解析成AMR图，然后从该AMR生成文本，我们可以获得更接近非翻译语言文本的文本，通过宏观级别的度量，我们展示了使用AMR作为跨语言方案可以实现减少翻译语言学，我们将我们的结果与另外两种方法进行了比较：基于往返机器翻译的方法和基于句法控制生成的方法。

    Translated texts or utterances bear several hallmarks distinct from texts originating in the language. This phenomenon, known as translationese, is well-documented, and when found in training or test sets can affect model performance. Still, work to mitigate the effect of translationese in human translated text is understudied. We hypothesize that Abstract Meaning Representation (AMR), a semantic representation which abstracts away from the surface form, can be used as an interlingua to reduce the amount of translationese in translated texts. By parsing English translations into an AMR graph and then generating text from that AMR, we obtain texts that more closely resemble non-translationese by macro-level measures. We show that across four metrics, and qualitatively, using AMR as an interlingua enables the reduction of translationese and we compare our results to two additional approaches: one based on round-trip machine translation and one based on syntactically controlled generation
    
[^93]: 新闻和负荷：基于自然语言处理的用于预测次日电力系统需求的量化探索

    News and Load: A Quantitative Exploration of Natural Language Processing Applications for Forecasting Day-ahead Electricity System Demand. (arXiv:2301.07535v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.07535](http://arxiv.org/abs/2301.07535)

    本文利用自然语言处理技术研究了电力需求和社会事件之间的关联，并通过分析词频、公众情感、主题分布和词嵌入等文本特征，改进了次日的电力需求预测。研究结果提供了新的视角，证实了从非结构化文本中改进预测的可行性。

    

    电力需求与天气之间的关系在电力系统中得到了确认，同时也强调了假日和重大事件等行为和社会因素的重要性。本研究利用成熟的自然语言处理（NLP）和需求预测技术，探索了电力需求与更细致的社会事件信息之间的关联。结果表明，词频、公众情感、主题分布和词嵌入等文本特征可以改善次日预测。这些特征中包含了全球大流行、政治、国际冲突、交通等社会事件。通过讨论因果效应和相关性，提出了关联机制的解释。本研究认为可以为传统的电力需求分析提供新的视角，证实了从非结构化文本中改进预测的可行性。

    The relationship between electricity demand and weather is well established in power systems, along with the importance of behavioral and social aspects such as holidays and significant events. This study explores the link between electricity demand and more nuanced information about social events. This is done using mature Natural Language Processing (NLP) and demand forecasting techniques. The results indicate that day-ahead forecasts are improved by textual features such as word frequencies, public sentiments, topic distributions, and word embeddings. The social events contained in these features include global pandemics, politics, international conflicts, transportation, etc. Causality effects and correlations are discussed to propose explanations for the mechanisms behind the links highlighted. This study is believed to bring a new perspective to traditional electricity demand analysis. It confirms the feasibility of improving forecasts from unstructured text, with potential conse
    
[^94]: 多模态分子结构-文本模型用于基于文本的检索和编辑

    Multi-modal Molecule Structure-text Model for Text-based Retrieval and Editing. (arXiv:2212.10789v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.10789](http://arxiv.org/abs/2212.10789)

    本论文介绍了一种名为MoleculeSTM的多模态分子结构-文本模型，通过联合学习化学结构和文本描述，可以实现基于文本的检索和编辑。通过构建大型的多模态数据集，并设计挑战性的零样本任务进行验证，该模型展示了开放词汇和组合性的特性。

    

    药物发现中正在越来越广泛地采用人工智能，然而，现有研究主要利用分子的化学结构，忽视了化学领域中可用的丰富文本知识。将文本知识纳入考虑可以实现新的药物设计目标，适应基于文本的指导和预测复杂的生物活性。在这里，我们提出了一种多模态的分子结构-文本模型MoleculeSTM，通过联合学习分子的化学结构和文本描述来实现，采用对比学习策略。为了训练MoleculeSTM，我们构建了一个大型的多模态数据集，名为PubChemSTM，包含超过28万个化学结构-文本对。为了展示MoleculeSTM的有效性和实用性，我们设计了两个基于文本指令的挑战性零样本任务，包括结构-文本检索和分子编辑。MoleculeSTM具有两个主要特性：开放词汇和通过自然语言实现组合性。

    There is increasing adoption of artificial intelligence in drug discovery. However, existing studies use machine learning to mainly utilize the chemical structures of molecules but ignore the vast textual knowledge available in chemistry. Incorporating textual knowledge enables us to realize new drug design objectives, adapt to text-based instructions and predict complex biological activities. Here we present a multi-modal molecule structure-text model, MoleculeSTM, by jointly learning molecules' chemical structures and textual descriptions via a contrastive learning strategy. To train MoleculeSTM, we construct a large multi-modal dataset, namely, PubChemSTM, with over 280,000 chemical structure-text pairs. To demonstrate the effectiveness and utility of MoleculeSTM, we design two challenging zero-shot tasks based on text instructions, including structure-text retrieval and molecule editing. MoleculeSTM has two main properties: open vocabulary and compositionality via natural language.
    
[^95]: 定位 vs. 语义：单模态和多模态模型中的视觉表示

    Localization vs. Semantics: Visual Representations in Unimodal and Multimodal Models. (arXiv:2212.00281v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.00281](http://arxiv.org/abs/2212.00281)

    本文比较分析了现有视觉与语言模型和仅视觉模型中的视觉表示，发现视觉与语言模型在标签预测任务上表现更好，而仅视觉模型在需要更局部信息的密集预测任务上表现更强。

    

    尽管通过视觉与语言预训练取得了令人印象深刻的进展，但目前尚不清楚这种联合学习范式是否有助于理解每个个体模态。在本研究中，我们通过探究广泛的任务，对比分析现有的视觉与语言模型和仅视觉模型中的视觉表示，旨在以细致的方式评估学习表示的质量。有趣的是，我们的实证观察表明，视觉与语言模型在标签预测任务（如对象和属性预测）方面表现更好，而仅视觉模型在需要更局部信息的密集预测任务上表现更强。我们希望我们的研究能够阐明语言在视觉学习中的作用，并成为各种预训练模型的经验指南。代码将在https://github.com/Lizw14/visual_probing发布。

    Despite the impressive advancements achieved through vision-and-language pretraining, it remains unclear whether this joint learning paradigm can help understand each individual modality. In this work, we conduct a comparative analysis of the visual representations in existing vision-and-language models and vision-only models by probing a broad range of tasks, aiming to assess the quality of the learned representations in a nuanced manner. Interestingly, our empirical observations suggest that vision-and-language models are better at label prediction tasks like object and attribute prediction, while vision-only models are stronger at dense prediction tasks that require more localized information. We hope our study sheds light on the role of language in visual learning, and serves as an empirical guide for various pretrained models. Code will be released at https://github.com/Lizw14/visual_probing
    

