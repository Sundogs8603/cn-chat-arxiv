# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Neural Machine Translation For Low Resource Languages.](http://arxiv.org/abs/2304.07869) | 该论文研究了低资源语言的神经机器翻译，并构建了一个基于 \texttt{mBART.CC25} 语言模型的模型，利用后向翻译和迁移学习等 NLP 和深度学习技术进行增强，以达到最先进的结果。 |
| [^2] | [VISAR: A Human-AI Argumentative Writing Assistant with Visual Programming and Rapid Draft Prototyping.](http://arxiv.org/abs/2304.07810) | VISAR是一个AI写作助手，旨在帮助作者提升写作体验和输出。它可以在写作上下文中随时帮助作者构思和修改目标，通过可视化编程来组织论证结构，并提供推荐来增加说服力。自动草案原型可以用来验证计划。 |
| [^3] | [EasyNER: A Customizable Easy-to-Use Pipeline for Deep Learning- and Dictionary-based Named Entity Recognition from Medical Text.](http://arxiv.org/abs/2304.07805) | EasyNER是一种用于在医学研究文章中识别命名实体的端到端工具。它基于深度学习模型和字典方法，并且易于使用和定制。在COVID-19相关文章数据集上的应用证明了其可以准确地识别所需实体。 |
| [^4] | [It's All in the Embedding! Fake News Detection Using Document Embeddings.](http://arxiv.org/abs/2304.07781) | 本文提出一种基于文本嵌入的假新闻检测方法，利用新闻文章的时间和主题背景，可有效检测假新闻。 |
| [^5] | [SikuGPT: A Generative Pre-trained Model for Intelligent Information Processing of Ancient Texts from the Perspective of Digital Humanities.](http://arxiv.org/abs/2304.07778) | 本文提出了一种基于《四库全书》语料库的生成式预训练模型SikuGPT，其在处理古籍时的表现优于其他模型，有助于促进古籍信息和中国古代文化的国际传播。 |
| [^6] | [Syntactic Complexity Identification, Measurement, and Reduction Through Controlled Syntactic Simplification.](http://arxiv.org/abs/2304.07774) | 本研究提出了一种控制简化方法，可在不丢失信息的情况下，基于句子中的实际信息三元组简化句子，以进行知识图谱的创建。 |
| [^7] | [A Comprehensive Evaluation of the Copy Mechanism for Natural Language to SPARQL Query Generation.](http://arxiv.org/abs/2304.07772) | 本研究综合评估自然语言到SPARQL查询生成中的复制机制，通过大量实验研究预训练和非预训练模型、问题注释格式以及使用复制机制的影响，并证明了在这些方面的优化可以提高性能。 |
| [^8] | [MisRoB{\AE}RTa: Transformers versus Misinformation.](http://arxiv.org/abs/2304.07759) | 本文提出了一种新型基于Transformer的深度神经网络集成体系结构MisRoB{\AE}RTa，用于不实信息检测，并在大型现实世界新闻文章数据集上进行了测试和评估。 |
| [^9] | [USNID: A Framework for Unsupervised and Semi-supervised New Intent Discovery.](http://arxiv.org/abs/2304.07699) | 该论文提出了一个名为USNID的框架，用于无监督和半监督的新意图发现，解决了利用有限或无标记数据时难以捕捉复杂语义的问题，并设计了聚类机制来提高自我监督目标的质量，从而发现细粒度的意图簇。 |
| [^10] | [MLRegTest: A Benchmark for the Machine Learning of Regular Languages.](http://arxiv.org/abs/2304.07687) | 本文提出了一个名为MLRegTest的新基准测试，其包含了来自1,800个正则语言的数据集。该测试根据逻辑复杂度和逻辑文字种类组织语言，并可以帮助我们了解机器学习系统在学习不同种类的长距离依赖方面的性能。 |
| [^11] | [ArguGPT: evaluating, understanding and identifying argumentative essays generated by GPT models.](http://arxiv.org/abs/2304.07666) | 该研究提出了ArguGPT，它是由7个GPT模型生成的论证文章语料库，旨在解决AI生成内容带来的挑战，研究结果表明教师首次接触机器生成的论文时只有61%的准确度，但经过一轮训练后提高到了67%。 |
| [^12] | [TransDocs: Optical Character Recognition with word to word translation.](http://arxiv.org/abs/2304.07637) | 本研究采用LSTM-based seq2seq架构和带有注意力机制的深度学习模型，将OCR技术与词级翻译相结合，提高了文档转换的性能。 |
| [^13] | [Detecting Out-of-Context Multimodal Misinformation with interpretable neural-symbolic model.](http://arxiv.org/abs/2304.07633) | 本论文提出了一种可解释的神经符号模型，用于检测上下文不符的虚假多模态信息，帮助事实检查网站进行记录澄清。 |
| [^14] | [Neural Approaches to Entity-Centric Information Extraction.](http://arxiv.org/abs/2304.07625) | 本文介绍了实体中心的信息提取方法，通过考虑实体概念，提出构建按实体概念工作的应用程序的新思路，且该方法可以有效地提高实体链接任务的效果。 |
| [^15] | [Can ChatGPT Forecast Stock Price Movements? Return Predictability and Large Language Models.](http://arxiv.org/abs/2304.07619) | 本研究探究了使用ChatGPT及其他大型语言模型预测股市回报的潜力，发现ChatGPT的预测表现优于传统情感分析方法，而基础模型无法准确预测股票价格变化，表明复杂模型可预测能力的崛起。这表明在投资决策过程中引入先进的语言模型可以提高预测准确性并增强定量交易策略的表现。 |
| [^16] | [Robust Educational Dialogue Act Classifiers with Low-Resource and Imbalanced Datasets.](http://arxiv.org/abs/2304.07499) | 本文提出了一种新型的教育对话行为分类器MIREX，它采用互信息最小化损失来提高对不平衡和低资源数据情景下数据的鲁棒性，并在实验中展现出较好的效果。 |
| [^17] | [Tractable Control for Autoregressive Language Generation.](http://arxiv.org/abs/2304.07438) | 本文提出了一种在自回归文本生成中使用可操作概率模型来强制实施限制的控制方法GeLaTo，并取得了在常见的约束文本生成测试上的最先进性能。 |
| [^18] | [Improving Patient Pre-screening for Clinical Trials: Assisting Physicians with Large Language Models.](http://arxiv.org/abs/2304.07396) | 本文研究了使用大型语言模型InstructGPT辅助医生预筛选患者是否符合临床试验资格。通过10个合成患者简况的性能评估，展示了LLMs在识别筛选资格标准、单独分类、整体分类、以及需要筛选资格标准的百分比上的表现。 |
| [^19] | [Zero-Shot Multi-Label Topic Inference with Sentence Encoders.](http://arxiv.org/abs/2304.07382) | 本文研究了如何利用句子编码器进行“零样本主题推断”任务，并通过实验证明了Sentence-BERT在通用性方面优于其他编码器，而在效率方面则优先选择通用句子编码器。 |
| [^20] | [The Self-Perception and Political Biases of ChatGPT.](http://arxiv.org/abs/2304.07333) | 本文针对OpenAI的语言模型ChatGPT进行自我认知和政治偏见分析，测试结果显示ChatGPT偏向进步观点。 |
| [^21] | [OpenAssistant Conversations -- Democratizing Large Language Model Alignment.](http://arxiv.org/abs/2304.07327) | 释放了OpenAssistant Conversations，这是一个由全球超过1,000名参与者进行人工生成和人工注释的助手风格对话语料库，可以通过SFT和RLHF有效地用于LLM对齐，提高模型性能和可用性。 |
| [^22] | [Language Instructed Reinforcement Learning for Human-AI Coordination.](http://arxiv.org/abs/2304.07297) | 本文提出了一种称之为instructRL的新的框架，它通过自然语言指令来指定对人工智能搭档的预期策略，解决在缺乏高质量人类行为数据的领域中多智能体强化学习收敛于人类不偏爱的策略的问题，从而提高了人工智能协作的性能。 |
| [^23] | [Vax-Culture: A Dataset for Studying Vaccine Discourse on Twitter.](http://arxiv.org/abs/2304.06858) | 本文介绍了一个推特疫苗数据集Vax-Culture，它旨在找出推广疫苗错误信息的文化和政治信念的重叠部分，帮助开发机器学习模型以自动检测疫苗错误信息帖子并应对其负面影响。 |
| [^24] | [SpectFormer: Frequency and Attention is what you need in a Vision Transformer.](http://arxiv.org/abs/2304.06446) | 本文提出了结合多头注意力和谱层的Spectformer架构，可以得到更好的性能表现，提高了top-1准确率2%。 |
| [^25] | [DoctorGLM: Fine-tuning your Chinese Doctor is not a Herculean Task.](http://arxiv.org/abs/2304.01097) | 使用中文医学对话数据库，微调ChatGLM-6B模型，实现易于部署的以医疗为目的的LLM，从而提高医疗建议的精度和推广LLM的可行性。 |
| [^26] | [A Survey of Large Language Models.](http://arxiv.org/abs/2303.18223) | 本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。 |
| [^27] | [Large Language Models Can Be Used to Estimate the Ideologies of Politicians in a Zero-Shot Learning Setting.](http://arxiv.org/abs/2303.12057) | 本文展示了在零-shot学习环境下，大型语言模型可以用于评估政治家的意识形态，为我们更好地理解政治功能提供了有用的信息。 |
| [^28] | [Disambiguation of Company names via Deep Recurrent Networks.](http://arxiv.org/abs/2303.05391) | 本研究提出了一种利用深度递归网络进行公司名称消歧的方法，相较于标准字符串匹配算法具有更优的表现，还采用主动学习来优化样本标记效率。 |
| [^29] | [xCodeEval: A Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and Retrieval.](http://arxiv.org/abs/2303.03004) | xCodeEval是一个大规模多语言多任务的基准，用于评估预训练的大型语言模型生成、修复、翻译和检索代码的能力，并解决了以往仅关注特定任务和缺乏训练数据的问题。 |
| [^30] | [E2E Spoken Entity Extraction for Virtual Agents.](http://arxiv.org/abs/2302.10186) | 本文研究了利用预训练语音编码器从语音中直接提取实体的方法，无需文本转录，且在口语实体识别任务中表现优异。 |
| [^31] | [Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation.](http://arxiv.org/abs/2302.09664) | 本文提出了一种测量大型语言模型中不确定性的方法，引入了语义熵以克服自然语言中的“语义等价性”，该方法是无监督的，并且对于问题回答数据集上的模型准确性具有更好的预测性能。 |
| [^32] | [Knowledge Enhanced Semantic Communication Receiver.](http://arxiv.org/abs/2302.07727) | 提出了一个知识增强的语义通信框架，其中接收器可以更积极地利用知识库中的事实进行语义推理和解码，并通过知识提取器和基于GCN的语义解码器实现了更好的性能，不影响发射端的神经网络结构。 |
| [^33] | [Is Multimodal Vision Supervision Beneficial to Language?.](http://arxiv.org/abs/2302.05016) | 本文探讨了使用视觉监督训练的语言表示是否比普通语言表示在自然语言理解和常识推理基准测试方面表现更好。结果表明，大多数任务中，普通的语言表示表现出更好的性能。 |
| [^34] | [GLIGEN: Open-Set Grounded Text-to-Image Generation.](http://arxiv.org/abs/2301.07093) | GLIGEN是一种开放式基于语言关联性和预训练的文本到图像生成方法，通过门控机制注入连结信息，能够实现零样本的基于关键字和边界框的文本到图像生成，性能优于现有的监督布局到图像的基线。 |
| [^35] | [VaxxHesitancy: A Dataset for Studying Hesitancy Towards COVID-19 Vaccination on Twitter.](http://arxiv.org/abs/2301.06660) | 该论文介绍了一份用于研究推特上 COVID-19 疫苗犹豫的数据集，疫苗犹豫一直是一个普遍的问题，了解公众对 COVID-19 疫苗犹豫的原因非常重要。 |
| [^36] | [Efficiently Trained Low-Resource Mongolian Text-to-Speech System Based On FullConv-TTS.](http://arxiv.org/abs/2211.01948) | 该论文提出了一个基于全卷积神经网络训练的低资源蒙古语文本到语音系统，相较于传统的包含循环神经网络的TTS模型，训练时间更短且音频合成质量不降低。 |
| [^37] | [Modeling structure-building in the brain with CCG parsing and large language models.](http://arxiv.org/abs/2210.16147) | 本研究使用CCG和大型语言模型模拟人类神经信号，发现比无上下文文法更具表达力的CCG更适合表达语法结构。 |
| [^38] | [Schema-aware Reference as Prompt Improves Data-Efficient Knowledge Graph Construction.](http://arxiv.org/abs/2210.10709) | 提出了一种以检索增强的架构感知参考作为提示的方法，可动态利用人类注释和弱监督数据所继承的架构和知识，指导生成具有更好语义连贯性和一致性的结构化知识，从而在数据效率和知识质量方面具有优越性。 |
| [^39] | [A New Path: Scaling Vision-and-Language Navigation with Synthetic Instructions and Imitation Learning.](http://arxiv.org/abs/2210.03112) | 该论文研究了使用合成指令的大规模扩充方法，通过构建导航轨迹并使用高质量的多语言导航指令生成器Marky生成基于图像的指令，以及使用图像到图像GAN在新的视角上合成图像观察。这些方法得到了更强的视觉语言导航模型。 |
| [^40] | [DecAF: Joint Decoding of Answers and Logical Forms for Question Answering over Knowledge Bases.](http://arxiv.org/abs/2210.00063) | DecAF 提出了一种联合生成逻辑形式和直接答案的新型框架，结合了它们的优点以获取最终答案；同时，它还采用了简单的自由文本检索，相比以往的方法更易于适应不同的数据集。 |
| [^41] | [LUT-GEMM: Quantized Matrix Multiplication based on LUTs for Efficient Inference in Large-Scale Generative Language Models.](http://arxiv.org/abs/2206.09557) | 本文介绍了一种基于LUT的量化矩阵乘法，用于大规模生成式语言模型的高效推理。采用仅针对权重的量化策略，并提出了LUT-GEMM内核加速量化矩阵乘法，实现压缩比和准确性之间的灵活平衡。 |
| [^42] | [Least-to-Most Prompting Enables Complex Reasoning in Large Language Models.](http://arxiv.org/abs/2205.10625) | 本文提出最少到最多提示的策略，能够帮助大规模语言模型实现复杂推理并推广到难度更高的问题。通过这种策略结合GPT-3 code-davinci-002模型能够完美解决组合泛化基准SCAN中的所有分割。 |
| [^43] | [TraVLR: Now You See It, Now You Don't! A Bimodal Dataset for Evaluating Visio-Linguistic Reasoning.](http://arxiv.org/abs/2111.10756) | 提出了TraVLR数据集，可以用于评估V+L模型的表现，数据集合成，包括四个V+L推理任务，同时使用双模式冗余编码来评估其泛化能力。 |
| [^44] | [Unified Instance and Knowledge Alignment Pretraining for Aspect-based Sentiment Analysis.](http://arxiv.org/abs/2110.13398) | 本论文提出了一种统一实例和知识对齐预训练框架，能够有效解决预训练和下游ABSA数据集之间的领域偏移问题，提高了基于方面的情感分析的性能，达到了最先进水平。 |
| [^45] | [DeliData: A dataset for deliberation in multi-party problem solving.](http://arxiv.org/abs/2108.05271) | 该文介绍了第一个公开可用的群体协商数据集，500个小组对话和14k个话语，64%的小组成员能够找到比他们单独找到的更好的解决方案。同时提出了一种新的注释模式用于捕捉协商线索，并使用该数据集评估了两种生成协商话语的方法。 |

# 详细

[^1]: 低资源语言的神经机器翻译

    Neural Machine Translation For Low Resource Languages. (arXiv:2304.07869v1 [cs.CL])

    [http://arxiv.org/abs/2304.07869](http://arxiv.org/abs/2304.07869)

    该论文研究了低资源语言的神经机器翻译，并构建了一个基于 \texttt{mBART.CC25} 语言模型的模型，利用后向翻译和迁移学习等 NLP 和深度学习技术进行增强，以达到最先进的结果。

    

    由于自然语言的内在复杂性和流动性，神经机器翻译是一个具有挑战性的任务。尽管近年来在几种语言对中取得了最先进的表现，但在多语言神经机器翻译 (MNMT) 领域看到了很多关注，却没有进行全面调查以确定哪些方法表现良好。该项目的目标是研究低资源语言的领域，并构建一个神经机器翻译模型，以实现最先进的结果。该项目旨在建立在 \texttt{mBART.CC25} 语言模型基础上，并探索利用各种 NLP 和深度学习技术（如后向翻译和迁移学习）来增强它的策略。该实现试图解开 NMT 应用程序的架构，并确定不同的组件，这些组件为我们提供了修改所述应用程序的机会。

    Neural Machine translation is a challenging task due to the inherent complex nature and the fluidity that natural languages bring. Nonetheless, in recent years, it has achieved state-of-the-art performance in several language pairs. Although, a lot of traction can be seen in the areas of multilingual neural machine translation (MNMT) in the recent years, there are no comprehensive survey done to identify what approaches work well. The goal of this project is to investigate the realm of low resource languages and build a Neural Machine Translation model to achieve state-of-the-art results. The project looks to build upon the \texttt{mBART.CC25} \cite{liu2020multilingual} language model and explore strategies to augment it with various NLP and Deep Learning techniques like back translation and transfer learning. This implementation tries to unpack the architecture of the NMT application and determine the different components which offers us opportunities to amend the said application wit
    
[^2]: VISAR：一种带有可视化编程和快速草案原型的人工智能论证写作助手

    VISAR: A Human-AI Argumentative Writing Assistant with Visual Programming and Rapid Draft Prototyping. (arXiv:2304.07810v1 [cs.HC])

    [http://arxiv.org/abs/2304.07810](http://arxiv.org/abs/2304.07810)

    VISAR是一个AI写作助手，旨在帮助作者提升写作体验和输出。它可以在写作上下文中随时帮助作者构思和修改目标，通过可视化编程来组织论证结构，并提供推荐来增加说服力。自动草案原型可以用来验证计划。

    

    在辩论写作中，作者必须构思分层写作目标，确保其论点的说服力，并通过起草来修订和组织他们的计划。最近大型语言模型（LLM）的进展使得通过聊天界面进行交互式文本生成（例如ChatGPT）成为可能。然而，这种方法常常忽略了隐含的写作上下文和用户意图，缺乏用户控制和自主权，并且提供有限的帮助来进行意义构建和修订写作计划。为了应对这些挑战，我们引入了VISAR，一种AI支持的写作助手系统，旨在帮助作者在其写作上下文中构思和修订分层目标，通过同步文本编辑和可视化编程组织论证结构，并通过论证火花推荐增强说服力。VISAR允许用户使用自动草案原型探索、实验和验证他们的写作计划。一个受控实验室研究证实，VISAR可以通过客观和主观评估，有效地改善用户的写作体验和结果。

    In argumentative writing, writers must brainstorm hierarchical writing goals, ensure the persuasiveness of their arguments, and revise and organize their plans through drafting. Recent advances in large language models (LLMs) have made interactive text generation through a chat interface (e.g., ChatGPT) possible. However, this approach often neglects implicit writing context and user intent, lacks support for user control and autonomy, and provides limited assistance for sensemaking and revising writing plans. To address these challenges, we introduce VISAR, an AI-enabled writing assistant system designed to help writers brainstorm and revise hierarchical goals within their writing context, organize argument structures through synchronized text editing and visual programming, and enhance persuasiveness with argumentation spark recommendations. VISAR allows users to explore, experiment with, and validate their writing plans using automatic draft prototyping. A controlled lab study confi
    
[^3]: EasyNER：一种可定制的易于使用的医学文本深度学习和基于字典的命名实体识别工具

    EasyNER: A Customizable Easy-to-Use Pipeline for Deep Learning- and Dictionary-based Named Entity Recognition from Medical Text. (arXiv:2304.07805v1 [q-bio.QM])

    [http://arxiv.org/abs/2304.07805](http://arxiv.org/abs/2304.07805)

    EasyNER是一种用于在医学研究文章中识别命名实体的端到端工具。它基于深度学习模型和字典方法，并且易于使用和定制。在COVID-19相关文章数据集上的应用证明了其可以准确地识别所需实体。

    

    医学研究已经产生了大量出版物，PubMed数据库已经收录了超过3,500万篇研究文章。整合这些分散在大量文献中的知识可以提供有关生理机制和导致新型医学干预的疾病过程的关键见解。然而，对于研究人员来说，利用这些信息成为一个巨大挑战，因为数据的规模和复杂性远远超出了人类的处理能力。在COVID-19大流行的紧急情况下，这尤其成为问题。自动化文本挖掘可以帮助从大量医学研究文章中提取和连接信息。文本挖掘的第一步通常是识别特定类别的关键字（例如所有蛋白质或疾病名称），即命名实体识别（NER）。本文提出了一种端到端的NER工具EasyNER，用于识别医学研究文章中的典型实体，包括疾病名称、药物名称和蛋白质名称。EasyNER基于深度学习模型和基于字典的方法，旨在对自然语言处理具有不同经验水平的研究人员易于使用和定制。我们将EasyNER应用于COVID-19相关文章的数据集中并展示它可以准确地识别感兴趣的实体，为下游分析提供有用的信息。

    Medical research generates a large number of publications with the PubMed database already containing >35 million research articles. Integration of the knowledge scattered across this large body of literature could provide key insights into physiological mechanisms and disease processes leading to novel medical interventions. However, it is a great challenge for researchers to utilize this information in full since the scale and complexity of the data greatly surpasses human processing abilities. This becomes especially problematic in cases of extreme urgency like the COVID-19 pandemic. Automated text mining can help extract and connect information from the large body of medical research articles. The first step in text mining is typically the identification of specific classes of keywords (e.g., all protein or disease names), so called Named Entity Recognition (NER). Here we present an end-to-end pipeline for NER of typical entities found in medical research articles, including diseas
    
[^4]: 文本嵌入精准检测假新闻

    It's All in the Embedding! Fake News Detection Using Document Embeddings. (arXiv:2304.07781v1 [cs.CL])

    [http://arxiv.org/abs/2304.07781](http://arxiv.org/abs/2304.07781)

    本文提出一种基于文本嵌入的假新闻检测方法，利用新闻文章的时间和主题背景，可有效检测假新闻。

    

    随着媒体的数字化进程和社交媒体的兴起，个性化社交媒体已成为新的常态。然而，数字化进程增加了流传假信息、错误信息和变形信息的风险，从而导致了假新闻这一有害现象的出现。这些信息可以扭曲公众对特定话题的看法，并且缺乏传统新闻的严谨性。为了开发有效的工具来检测假新闻，自然语言处理和机器学习技术至关重要。本文提出了一种基于文本嵌入的假新闻检测方法，利用新闻文章的时间和主题背景。实验结果表明，我们的方法在各种数据集上均取得了较高的准确度，并且超越了基线模型和其他最先进的方法。

    With the current shift in the mass media landscape from journalistic rigor to social media, personalized social media is becoming the new norm. Although the digitalization progress of the media brings many advantages, it also increases the risk of spreading disinformation, misinformation, and malformation through the use of fake news. The emergence of this harmful phenomenon has managed to polarize society and manipulate public opinion on particular topics, e.g., elections, vaccinations, etc. Such information propagated on social media can distort public perceptions and generate social unrest while lacking the rigor of traditional journalism. Natural Language Processing and Machine Learning techniques are essential for developing efficient tools that can detect fake news. Models that use the context of textual data are essential for resolving the fake news detection problem, as they manage to encode linguistic features within the vector representation of words. In this paper, we propos
    
[^5]: SikuGPT：一种面向数字人文学古籍智能化信息处理的生成式预训练模型，（arXiv：2304.07778v1 [cs.CL]）

    SikuGPT: A Generative Pre-trained Model for Intelligent Information Processing of Ancient Texts from the Perspective of Digital Humanities. (arXiv:2304.07778v1 [cs.CL])

    [http://arxiv.org/abs/2304.07778](http://arxiv.org/abs/2304.07778)

    本文提出了一种基于《四库全书》语料库的生成式预训练模型SikuGPT，其在处理古籍时的表现优于其他模型，有助于促进古籍信息和中国古代文化的国际传播。

    

    人工智能技术的快速发展促进了数字人文研究的繁荣。在这一背景下，需要转变研究方法，以适应AIGC浪潮下数字人文研究的重要组成部分--古籍智能化处理的新发展趋势。本研究基于《四库全书》语料库提出了一种名为SikuGPT的GPT模型。该模型在诸如语言内翻译和文本分类等任务中的性能超过了其他面向古籍处理的GPT类型模型。SikuGPT处理传统汉语古籍的能力有助于促进古代信息和知识服务的组织以及中国古代文化的国际传播。

    The rapid advance in artificial intelligence technology has facilitated the prosperity of digital humanities research. Against such backdrop, research methods need to be transformed in the intelligent processing of ancient texts, which is a crucial component of digital humanities research, so as to adapt to new development trends in the wave of AIGC. In this study, we propose a GPT model called SikuGPT based on the corpus of Siku Quanshu. The model's performance in tasks such as intralingual translation and text classification exceeds that of other GPT-type models aimed at processing ancient texts. SikuGPT's ability to process traditional Chinese ancient texts can help promote the organization of ancient information and knowledge services, as well as the international dissemination of Chinese ancient culture.
    
[^6]: 控制语法简化的句法复杂性鉴别、度量和减少

    Syntactic Complexity Identification, Measurement, and Reduction Through Controlled Syntactic Simplification. (arXiv:2304.07774v1 [cs.CL])

    [http://arxiv.org/abs/2304.07774](http://arxiv.org/abs/2304.07774)

    本研究提出了一种控制简化方法，可在不丢失信息的情况下，基于句子中的实际信息三元组简化句子，以进行知识图谱的创建。

    

    文本简化是自然语言处理中的一个领域，可以通过简化方式探索更易懂的文本。但是，了解并从结构化的文本中提取知识通常很难，因为它通常采用复合句和复杂句式。现有的基于神经网络的方法能够简化句子以提高可读性，同时使用简单的英语替换词和摘要句子和段落。但是，在从结构化的文本中创建知识图谱的过程中，摘要长句子和替换词是不可取的，因为这可能导致信息丢失。因此，本研究提出一种基于句子中的实际信息三元组的控制简化方法。我们提出了一种基于经典句法依存的方法

    Text simplification is one of the domains in Natural Language Processing (NLP) that offers an opportunity to understand the text in a simplified manner for exploration. However, it is always hard to understand and retrieve knowledge from unstructured text, which is usually in the form of compound and complex sentences. There are state-of-the-art neural network-based methods to simplify the sentences for improved readability while replacing words with plain English substitutes and summarising the sentences and paragraphs. In the Knowledge Graph (KG) creation process from unstructured text, summarising long sentences and substituting words is undesirable since this may lead to information loss. However, KG creation from text requires the extraction of all possible facts (triples) with the same mentions as in the text. In this work, we propose a controlled simplification based on the factual information in a sentence, i.e., triple. We present a classical syntactic dependency-based approac
    
[^7]: 自然语言到SPARQL查询生成的复制机制综合评估

    A Comprehensive Evaluation of the Copy Mechanism for Natural Language to SPARQL Query Generation. (arXiv:2304.07772v1 [cs.CL])

    [http://arxiv.org/abs/2304.07772](http://arxiv.org/abs/2304.07772)

    本研究综合评估自然语言到SPARQL查询生成中的复制机制，通过大量实验研究预训练和非预训练模型、问题注释格式以及使用复制机制的影响，并证明了在这些方面的优化可以提高性能。

    

    近年来，神经机器翻译（NMT）领域在SPARQL查询生成方面有了显著的增长。最近，将复制机制与传统的编码器-解码器架构相结合，并使用预训练的编码器-解码器，创造了新的性能基准。本文展示了大量的实验，复制并扩展了最近的基于NMT的SPARQL生成研究，比较了预训练和非预训练模型、问题注释格式以及对于非预训练和预训练模型使用复制机制的影响。我们的结果表明，对于非预训练模型和预训练模型，添加复制机制或使用问题注释都可以提高性能，并为三个流行数据集设置了新的基准。

    In recent years, the field of neural machine translation (NMT) for SPARQL query generation has witnessed a significant growth. Recently, the incorporation of the copy mechanism with traditional encoder-decoder architectures and the use of pre-trained encoder-decoders have set new performance benchmarks. This paper presents a large variety of experiments that replicate and expand upon recent NMT-based SPARQL generation studies, comparing pre-trained and non-pre-trained models, question annotation formats, and the use of a copy mechanism for non-pre-trained and pre-trained models. Our results show that either adding the copy mechanism or using a question annotation improves performances for nonpre-trained models and for pre-trained models, setting new baselines for three popular datasets.
    
[^8]: MisRoB{\AE}RTa：变形金刚对抗不实信息

    MisRoB{\AE}RTa: Transformers versus Misinformation. (arXiv:2304.07759v1 [cs.CL])

    [http://arxiv.org/abs/2304.07759](http://arxiv.org/abs/2304.07759)

    本文提出了一种新型基于Transformer的深度神经网络集成体系结构MisRoB{\AE}RTa，用于不实信息检测，并在大型现实世界新闻文章数据集上进行了测试和评估。

    

    不实信息被认为是我们民主的价值观和原则的威胁。这种内容在社交媒体上的传播会使社会极端化，并通过扭曲公众的看法并引发社会动荡而破坏公共话语，同时缺乏传统新闻的严谨性。在多个具有知名度的自然语言处理任务中，Transformer和迁移学习被证明是最先进的方法。在本文中，我们提出了MisRoB{\AE}RTa，这是一种新颖的基于Transformer的深度神经网络集成体系结构，用于不实信息检测。MisRoB{\AE}RTa利用了两个Transformer（BART和RoBERTa）来提高分类性能。我们还对多个Transformer在不实信息检测任务上的性能进行了基准测试和评估。对于训练和测试，我们使用了一个带有10个类别标签的大型现实世界新闻文章数据集，解决了当前研究中的两个缺点：将数据集的规模从小到大，并将焦点从社交媒体移动到新闻领域。

    Misinformation is considered a threat to our democratic values and principles. The spread of such content on social media polarizes society and undermines public discourse by distorting public perceptions and generating social unrest while lacking the rigor of traditional journalism. Transformers and transfer learning proved to be state-of-the-art methods for multiple well-known natural language processing tasks. In this paper, we propose MisRoB{\AE}RTa, a novel transformer-based deep neural ensemble architecture for misinformation detection. MisRoB{\AE}RTa takes advantage of two transformers (BART \& RoBERTa) to improve the classification performance. We also benchmarked and evaluated the performances of multiple transformers on the task of misinformation detection. For training and testing, we used a large real-world news articles dataset labeled with 10 classes, addressing two shortcomings in the current research: increasing the size of the dataset from small to large, and moving th
    
[^9]: USNID: 无监督和半监督新意图发现的框架

    USNID: A Framework for Unsupervised and Semi-supervised New Intent Discovery. (arXiv:2304.07699v1 [cs.CL])

    [http://arxiv.org/abs/2304.07699](http://arxiv.org/abs/2304.07699)

    该论文提出了一个名为USNID的框架，用于无监督和半监督的新意图发现，解决了利用有限或无标记数据时难以捕捉复杂语义的问题，并设计了聚类机制来提高自我监督目标的质量，从而发现细粒度的意图簇。

    

    新意图发现对自然语言处理非常有价值，使我们更好地理解用户需求并提供友好的服务。然而，在有限或没有标记数据的情况下，大多数现有方法难以捕捉离散文本表示的复杂语义。为了解决这个问题，我们提出了一种名为USNID的新框架，用于无监督和半监督新意图发现，具有三个关键技术：充分利用无监督或半监督数据挖掘浅层语义相似性关系；设计聚类机制解决簇分配不一致的问题；捕获无监督或半监督数据中的高级语义，通过同时优化聚类和自我监督来发现细粒度的意图簇。

    New intent discovery is of great value to natural language processing, allowing for a better understanding of user needs and providing friendly services. However, most existing methods struggle to capture the complicated semantics of discrete text representations when limited or no prior knowledge of labeled data is available. To tackle this problem, we propose a novel framework called USNID for unsupervised and semi-supervised new intent discovery, which has three key technologies. First, it takes full use of unsupervised or semi-supervised data to mine shallow semantic similarity relations and provide well-initialized representations for clustering. Second, it designs a centroid-guided clustering mechanism to address the issue of cluster allocation inconsistency and provide high-quality self-supervised targets for representation learning. Third, it captures high-level semantics in unsupervised or semi-supervised data to discover fine-grained intent-wise clusters by optimizing both cl
    
[^10]: MLRegTest：机器学习正则语言的基准测试

    MLRegTest: A Benchmark for the Machine Learning of Regular Languages. (arXiv:2304.07687v1 [cs.LG])

    [http://arxiv.org/abs/2304.07687](http://arxiv.org/abs/2304.07687)

    本文提出了一个名为MLRegTest的新基准测试，其包含了来自1,800个正则语言的数据集。该测试根据逻辑复杂度和逻辑文字种类组织语言，并可以帮助我们了解机器学习系统在学习不同种类的长距离依赖方面的性能。

    

    评估机器学习系统对已知分类器的学习能力允许细致地检查它们可以学习哪些模式，并在将它们应用于未知分类器的学习时建立信心。本文提出了一个名为MLRegTest的新的序列分类机器学习系统基准测试，其中包含来自1,800个正则语言的训练、开发和测试集。不同类型的形式语言代表着不同种类的长距离依赖，并正确地识别序列中的长距离依赖是机器学习系统成功泛化的已知挑战。MLRegTest根据它们的逻辑复杂度（单调二阶，一阶，命题或单项式表达式）和逻辑文字的种类（字符串，定级字符串，子序列或两者的组合）组织其语言。逻辑复杂度和文字的选择提供了一种系统方法来理解不同种类的长距离依赖和机器学习系统在处理它们时的性能。

    Evaluating machine learning (ML) systems on their ability to learn known classifiers allows fine-grained examination of the patterns they can learn, which builds confidence when they are applied to the learning of unknown classifiers. This article presents a new benchmark for ML systems on sequence classification called MLRegTest, which contains training, development, and test sets from 1,800 regular languages.  Different kinds of formal languages represent different kinds of long-distance dependencies, and correctly identifying long-distance dependencies in sequences is a known challenge for ML systems to generalize successfully. MLRegTest organizes its languages according to their logical complexity (monadic second order, first order, propositional, or monomial expressions) and the kind of logical literals (string, tier-string, subsequence, or combinations thereof). The logical complexity and choice of literal provides a systematic way to understand different kinds of long-distance d
    
[^11]: ArguGPT：评估、理解和识别由GPT模型生成的论证文章

    ArguGPT: evaluating, understanding and identifying argumentative essays generated by GPT models. (arXiv:2304.07666v1 [cs.CL])

    [http://arxiv.org/abs/2304.07666](http://arxiv.org/abs/2304.07666)

    该研究提出了ArguGPT，它是由7个GPT模型生成的论证文章语料库，旨在解决AI生成内容带来的挑战，研究结果表明教师首次接触机器生成的论文时只有61%的准确度，但经过一轮训练后提高到了67%。

    

    人工智能生成的内容（AIGC）对全球教育工作者提出了巨大的挑战。教师们需要能够用肉眼或工具检测出由大型语言模型生成的文本。需要更多地了解AIGC的词汇、句法和风格特征。为了解决这些英语教学方面的挑战，我们首先提出了ArguGPT，这是一个由7个GPT模型生成的4038篇有平衡的论证文章语料库，这些论证文章是在以下三个来源的论文提示下生成的：（1）课堂或家庭作业练习，（2）托福和（3）GRE写作任务。机器生成的文本与大致相等数量的人工编写的文章配对，这些文章的三个得分级别匹配论文提示。然后，我们雇用英语教师来区分机器论文和人工论文。结果表明，当教师们首次接触机器生成的论文时，他们仅能以61%的准确度检测出它们。但经过一轮训练后，这个数字提高到了67%。

    AI generated content (AIGC) presents considerable challenge to educators around the world. Instructors need to be able to detect such text generated by large language models, either with the naked eye or with the help of some tools. There is also growing need to understand the lexical, syntactic and stylistic features of AIGC. To address these challenges in English language teaching, we first present ArguGPT, a balanced corpus of 4,038 argumentative essays generated by 7 GPT models in response to essay prompts from three sources: (1) in-class or homework exercises, (2) TOEFL and (3) GRE writing tasks. Machine-generated texts are paired with roughly equal number of human-written essays with three score levels matched in essay prompts. We then hire English instructors to distinguish machine essays from human ones. Results show that when first exposed to machine-generated essays, the instructors only have an accuracy of 61% in detecting them. But the number rises to 67% after one round of
    
[^12]: TransDocs：基于词级翻译的光学字符识别技术

    TransDocs: Optical Character Recognition with word to word translation. (arXiv:2304.07637v1 [cs.CV])

    [http://arxiv.org/abs/2304.07637](http://arxiv.org/abs/2304.07637)

    本研究采用LSTM-based seq2seq架构和带有注意力机制的深度学习模型，将OCR技术与词级翻译相结合，提高了文档转换的性能。

    

    虽然OCR技术已经应用于各种应用，但其输出并不总是准确的，导致错配字词。本研究旨在运用机器学习技术改善OCR技术，将OCR技术与基于LSTM的序列到序列深度学习模型整合以进行文档翻译，并基于ANKI数据集进行英语到西班牙语的翻译。本研究通过比较使用LSTM-based seq2seq架构和带有注意力机制的深度学习模型预训练OCR的性能，展示了端到端模型的性能表现。本研究面向对OCR技术及其在文档翻译中应用感兴趣的研究人员和实践者。

    While OCR has been used in various applications, its output is not always accurate, leading to misfit words. This research work focuses on improving the optical character recognition (OCR) with ML techniques with integration of OCR with long short-term memory (LSTM) based sequence to sequence deep learning models to perform document translation. This work is based on ANKI dataset for English to Spanish translation. In this work, I have shown comparative study for pre-trained OCR while using deep learning model using LSTM-based seq2seq architecture with attention for machine translation. End-to-end performance of the model has been expressed in BLEU-4 score. This research paper is aimed at researchers and practitioners interested in OCR and its applications in document translation.
    
[^13]: 采用可解释的符号化神经模型检测上下文不符的多模态谣言

    Detecting Out-of-Context Multimodal Misinformation with interpretable neural-symbolic model. (arXiv:2304.07633v1 [cs.CL])

    [http://arxiv.org/abs/2304.07633](http://arxiv.org/abs/2304.07633)

    本论文提出了一种可解释的神经符号模型，用于检测上下文不符的虚假多模态信息，帮助事实检查网站进行记录澄清。

    

    近年来，虚假信息的演化持续增长，旨在影响公众舆论。与传统的谣言或虚假新闻编辑主要依赖于生成和/或伪造的图像、文本和视频不同，当前的虚假信息创作者更倾向于使用上下文不匹配的多媒体内容（例如，不匹配的图像和标题）来欺骗公众和虚假新闻检测系统。这种新型的虚假信息不仅增加了检测的难度，也增加了澄清的难度，因为每个单独的模态都足够接近真实信息。为了解决这个问题，在本文中，我们探讨了如何实现可解释的跨模态去上下文检测，同时识别不匹配的对和跨模态矛盾，这对事实检查网站的记录澄清非常有帮助。所提出的模型首先通过抽象多模态信息，基于Abstract M进行符号化分解，得到一组事实查询。

    Recent years have witnessed the sustained evolution of misinformation that aims at manipulating public opinions. Unlike traditional rumors or fake news editors who mainly rely on generated and/or counterfeited images, text and videos, current misinformation creators now more tend to use out-of-context multimedia contents (e.g. mismatched images and captions) to deceive the public and fake news detection systems. This new type of misinformation increases the difficulty of not only detection but also clarification, because every individual modality is close enough to true information. To address this challenge, in this paper we explore how to achieve interpretable cross-modal de-contextualization detection that simultaneously identifies the mismatched pairs and the cross-modal contradictions, which is helpful for fact-check websites to document clarifications. The proposed model first symbolically disassembles the text-modality information to a set of fact queries based on the Abstract M
    
[^14]: 实体中心信息提取的神经方法

    Neural Approaches to Entity-Centric Information Extraction. (arXiv:2304.07625v1 [cs.CL])

    [http://arxiv.org/abs/2304.07625](http://arxiv.org/abs/2304.07625)

    本文介绍了实体中心的信息提取方法，通过考虑实体概念，提出构建按实体概念工作的应用程序的新思路，且该方法可以有效地提高实体链接任务的效果。

    

    人工智能对我们的日常生活有着巨大的影响，包括语音助手、人脸识别、聊天机器人、自动驾驶汽车等等应用。自然语言处理是人工智能和语言学的跨学科领域，致力于研究文本理解。本论文探讨了自然语言处理中涉及到的一个非常特殊的领域，即实体（如人名、组织机构名、地名）在文本中的理解。我们首先引入了一种完全不同的，以实体为中心的文本信息视角，提出应该构建能够按实体概念工作的应用程序，而不是使用文本中的个体提及来理解其含义。接下来，我们提出了更详细的模型，介绍了实体中心方法如何用于实体链接任务。本文研究表明，这种方法可以提高实体链接任务的效果。

    Artificial Intelligence (AI) has huge impact on our daily lives with applications such as voice assistants, facial recognition, chatbots, autonomously driving cars, etc. Natural Language Processing (NLP) is a cross-discipline of AI and Linguistics, dedicated to study the understanding of the text. This is a very challenging area due to unstructured nature of the language, with many ambiguous and corner cases. In this thesis we address a very specific area of NLP that involves the understanding of entities (e.g., names of people, organizations, locations) in text. First, we introduce a radically different, entity-centric view of the information in text. We argue that instead of using individual mentions in text to understand their meaning, we should build applications that would work in terms of entity concepts. Next, we present a more detailed model on how the entity-centric approach can be used for the entity linking task. In our work, we show that this task can be improved by conside
    
[^15]: ChatGPT是否能够预测股票价格波动？回报可预测性与大语言模型。

    Can ChatGPT Forecast Stock Price Movements? Return Predictability and Large Language Models. (arXiv:2304.07619v1 [q-fin.ST])

    [http://arxiv.org/abs/2304.07619](http://arxiv.org/abs/2304.07619)

    本研究探究了使用ChatGPT及其他大型语言模型预测股市回报的潜力，发现ChatGPT的预测表现优于传统情感分析方法，而基础模型无法准确预测股票价格变化，表明复杂模型可预测能力的崛起。这表明在投资决策过程中引入先进的语言模型可以提高预测准确性并增强定量交易策略的表现。

    

    本文研究了使用情感分析预测股市回报的潜力，探讨了使用ChatGPT以及其他大语言模型在预测股市回报方面的表现。我们使用ChatGPT判断新闻标题对公司股票价格是好消息、坏消息或无关消息。通过计算数字分数，我们发现这些"ChatGPT分数"和随后的日常股票市场回报之间存在正相关性。而且，ChatGPT的表现优于传统的情感分析方法。同时，我们发现GPT-1、GPT-2和BERT等基础模型无法准确预测回报，这表明回报可预测性是复杂模型的一种新兴能力。我们的研究结果表明，将先进的语言模型纳入投资决策过程可以产生更准确的预测，并提高定量交易策略的表现。

    We examine the potential of ChatGPT, and other large language models, in predicting stock market returns using sentiment analysis of news headlines. We use ChatGPT to indicate whether a given headline is good, bad, or irrelevant news for firms' stock prices. We then compute a numerical score and document a positive correlation between these ``ChatGPT scores'' and subsequent daily stock market returns. Further, ChatGPT outperforms traditional sentiment analysis methods. We find that more basic models such as GPT-1, GPT-2, and BERT cannot accurately forecast returns, indicating return predictability is an emerging capacity of complex models. Our results suggest that incorporating advanced language models into the investment decision-making process can yield more accurate predictions and enhance the performance of quantitative trading strategies.
    
[^16]: 低资源和不平衡数据集下的鲁棒教育对话行为分类器

    Robust Educational Dialogue Act Classifiers with Low-Resource and Imbalanced Datasets. (arXiv:2304.07499v1 [cs.CL])

    [http://arxiv.org/abs/2304.07499](http://arxiv.org/abs/2304.07499)

    本文提出了一种新型的教育对话行为分类器MIREX，它采用互信息最小化损失来提高对不平衡和低资源数据情景下数据的鲁棒性，并在实验中展现出较好的效果。

    

    对话行为可以代表在辅导对话期间发生的教练员或学生的对话动作。在教育对话中自动识别对话行为对于基于对话的智能辅导系统的设计是重要的。许多先前的研究采用机器学习模型对辅导对话中的对话行为进行分类，并投入大量精力使用有限的训练数据（即低资源数据场景）来优化分类准确性。然而，除了分类准确性之外，分类器的鲁棒性也很重要，这可以反映分类器学习不同类别分布的模式的能力。我们注意到，许多先前的教育对话行为分类研究采用交叉熵（CE）损失来优化低资源数据中的DA分类器。这些研究中的DA分类器往往以牺牲少数类的代价来优先考虑大多数类的准确性，从而可能导致在少数类上性能差。在这篇论文中，我们提出了一种新型的DA分类器MIREX，它采用互信息最小化损失来提高DA分类器在不平衡和低资源数据情景下的鲁棒性。实验结果表明，MIREX在不平衡和低资源的DA数据集上优于现有方法。

    Dialogue acts (DAs) can represent conversational actions of tutors or students that take place during tutoring dialogues. Automating the identification of DAs in tutoring dialogues is significant to the design of dialogue-based intelligent tutoring systems. Many prior studies employ machine learning models to classify DAs in tutoring dialogues and invest much effort to optimize the classification accuracy by using limited amounts of training data (i.e., low-resource data scenario). However, beyond the classification accuracy, the robustness of the classifier is also important, which can reflect the capability of the classifier on learning the patterns from different class distributions. We note that many prior studies on classifying educational DAs employ cross entropy (CE) loss to optimize DA classifiers on low-resource data with imbalanced DA distribution. The DA classifiers in these studies tend to prioritize accuracy on the majority class at the expense of the minority class which 
    
[^17]: 可操作的自回归语言生成控制方法

    Tractable Control for Autoregressive Language Generation. (arXiv:2304.07438v1 [cs.CL])

    [http://arxiv.org/abs/2304.07438](http://arxiv.org/abs/2304.07438)

    本文提出了一种在自回归文本生成中使用可操作概率模型来强制实施限制的控制方法GeLaTo，并取得了在常见的约束文本生成测试上的最先进性能。

    

    尽管自回归大语言模型在文本生成方面取得了成功，但生成满足复杂限制的文本仍然是一个重大挑战：即使是最简单的词汇限制也使条件分布$\Pr(\text{text} | \alpha)$的采样变得不可计算。为了克服这个挑战，我们提出使用可操作的概率模型将词汇限制强加于自回归文本生成中，我们将其称为 GeLaTo。为了证明这个框架的有效性，我们使用了精简的隐马尔可夫模型来控制从GPT2到自回归的生成。GeLaTo在约束文本生成的具有挑战性的基准测试CommonGen上取得了最先进的性能，大幅击败了各种强基线。我们的工作不仅为控制大型语言模型开辟了新的途径，还激励人们开发更具表现力的可操作概率模型。

    Despite the success of autoregressive large language models in text generation, it remains a major challenge to generate text that satisfies complex constraints: sampling from the conditional distribution $\Pr(\text{text} | \alpha)$ is intractable for even the simplest lexical constraints $\alpha$. To overcome this challenge, we propose to use tractable probabilistic models to impose lexical constraints in autoregressive text generation, which we refer to as GeLaTo. To demonstrate the effectiveness of this framework, we use distilled hidden Markov models to control autoregressive generation from GPT2. GeLaTo achieves state-of-the-art performance on CommonGen, a challenging benchmark for constrained text generation, beating a wide range of strong baselines by a large margin. Our work not only opens up new avenues for controlling large language models but also motivates the development of more expressive tractable probabilistic models.
    
[^18]: 改善临床试验的患者预筛选：利用大型语言模型辅助医生

    Improving Patient Pre-screening for Clinical Trials: Assisting Physicians with Large Language Models. (arXiv:2304.07396v1 [cs.LG])

    [http://arxiv.org/abs/2304.07396](http://arxiv.org/abs/2304.07396)

    本文研究了使用大型语言模型InstructGPT辅助医生预筛选患者是否符合临床试验资格。通过10个合成患者简况的性能评估，展示了LLMs在识别筛选资格标准、单独分类、整体分类、以及需要筛选资格标准的百分比上的表现。

    

    考虑到患者的临床试验，医生需要进行繁琐的检查，以确定患者是否符合文本基准。大型语言模型（LLMs）已被证明在临床信息提取和临床推理方面表现良好，但尚未在现实场景中得到应用。本文研究了使用InstructGPT辅助医生根据患者的医疗简况确定其是否符合临床试验的资格。使用一次性、选择-推理和思维链策略相结合的提示策略，我们研究了LLMs在10个合成患者简况上的表现。在四个级别上评估了性能：能否从临床试验中给出的医疗简况中识别筛选资格标准；能否为每个单独的标准分类是否符合患者；整体分类是否符合临床试验资格以及需要筛选资格标准的百分比。

    Physicians considering clinical trials for their patients are met with the laborious process of checking many text based eligibility criteria. Large Language Models (LLMs) have shown to perform well for clinical information extraction and clinical reasoning, including medical tests, but not yet in real-world scenarios. This paper investigates the use of InstructGPT to assist physicians in determining eligibility for clinical trials based on a patient's summarised medical profile. Using a prompting strategy combining one-shot, selection-inference and chain-of-thought techniques, we investigate the performance of LLMs on 10 synthetically created patient profiles. Performance is evaluated at four levels: ability to identify screenable eligibility criteria from a trial given a medical profile; ability to classify for each individual criterion whether the patient qualifies; the overall classification whether a patient is eligible for a clinical trial and the percentage of criteria to be scr
    
[^19]: 利用句子编码器进行零样本多标签主题推断

    Zero-Shot Multi-Label Topic Inference with Sentence Encoders. (arXiv:2304.07382v1 [cs.CL])

    [http://arxiv.org/abs/2304.07382](http://arxiv.org/abs/2304.07382)

    本文研究了如何利用句子编码器进行“零样本主题推断”任务，并通过实验证明了Sentence-BERT在通用性方面优于其他编码器，而在效率方面则优先选择通用句子编码器。

    

    句子编码器在许多下游文本挖掘任务中表现优秀，因此被认为是相当通用。受到这一启发，我们进行了一项详细研究，探讨如何利用这些句子编码器进行“零样本主题推断”任务，其中主题是由用户实时定义/提供的。在七个不同的数据集上进行的大量实验表明，相比其他编码器，Sentence-BERT表现出卓越的通用性，而当效率成为首要考虑因素时，可以优先选择通用句子编码器。

    Sentence encoders have indeed been shown to achieve superior performances for many downstream text-mining tasks and, thus, claimed to be fairly general. Inspired by this, we performed a detailed study on how to leverage these sentence encoders for the "zero-shot topic inference" task, where the topics are defined/provided by the users in real-time. Extensive experiments on seven different datasets demonstrate that Sentence-BERT demonstrates superior generality compared to other encoders, while Universal Sentence Encoder can be preferred when efficiency is a top priority.
    
[^20]: ChatGPT的自我认知和政治偏见分析

    The Self-Perception and Political Biases of ChatGPT. (arXiv:2304.07333v1 [cs.CY])

    [http://arxiv.org/abs/2304.07333](http://arxiv.org/abs/2304.07333)

    本文针对OpenAI的语言模型ChatGPT进行自我认知和政治偏见分析，测试结果显示ChatGPT偏向进步观点。

    

    本篇文章分析OpenAI的大型语言模型ChatGPT的自我认知和政治偏见。考虑到已经出现的第一个小规模报告和研究声称ChatGPT在政治上偏向进步和自由主义观点，本文旨在进一步澄清这一问题。为此，作者让ChatGPT回答政治罗盘测试等类似问卷，并针对G7成员国的特定政治进行测试，每个测试重复十次，发现ChatGPT似乎对进步观点具有偏见。

    This contribution analyzes the self-perception and political biases of OpenAI's Large Language Model ChatGPT. Taking into account the first small-scale reports and studies that have emerged, claiming that ChatGPT is politically biased towards progressive and libertarian points of view, this contribution aims to provide further clarity on this subject. For this purpose, ChatGPT was asked to answer the questions posed by the political compass test as well as similar questionnaires that are specific to the respective politics of the G7 member states. These eight tests were repeated ten times each and revealed that ChatGPT seems to hold a bias towards progressive views. The political compass test revealed a bias towards progressive and libertarian views, with the average coordinates on the political compass being (-6.48, -5.99) (with (0, 0) the center of the compass, i.e., centrism and the axes ranging from -10 to 10), supporting the claims of prior research. The political questionnaires f
    
[^21]: OpenAssistant Conversations -- 民主化大型语言模型的对齐方法

    OpenAssistant Conversations -- Democratizing Large Language Model Alignment. (arXiv:2304.07327v1 [cs.CL])

    [http://arxiv.org/abs/2304.07327](http://arxiv.org/abs/2304.07327)

    释放了OpenAssistant Conversations，这是一个由全球超过1,000名参与者进行人工生成和人工注释的助手风格对话语料库，可以通过SFT和RLHF有效地用于LLM对齐，提高模型性能和可用性。

    

    对齐大型语言模型（LLM）与人类偏好的技术已被证明可以显著提高可用性并推动其快速应用，如ChatGPT所示。 监督微调（SFT）和根据人类反馈进行的强化学习（RLHF）等对齐技术大大降低了有效发挥LLM能力所需的技能和领域知识，提高了它们在各个领域的可访问性和实用性。 然而，像RLHF这样的最先进的对齐技术依赖于高质量的人类反馈数据，这些数据往往昂贵且保密。 为了民主化大规模对齐的研究，我们发布了OpenAssistant Conversations，这是一个由全球超过1,000名参与者进行人工生成和人工注释的助手风格对话语料库，包含161,443条消息，分布在66,497个对话树中，并在35种不同的语言中用461,292个质量评分进行注释。我们的实验表明，OpenAssistant Conversations可以通过SFT和RLHF有效地用于LLM对齐，从而提高模型性能和可用性。我们发布语料库，使更广泛的研究社区能够进一步研究民主化LLM的能力，从而改善人类交互。

    Aligning large language models (LLMs) with human preferences has proven to drastically improve usability and has driven rapid adoption as demonstrated by ChatGPT. Alignment techniques such as supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF) greatly reduce the required skill and domain knowledge to effectively harness the capabilities of LLMs, increasing their accessibility and utility across various domains. However, state-of-the-art alignment techniques like RLHF rely on high-quality human feedback data, which is expensive to create and often remains proprietary. In an effort to democratize research on large-scale alignment, we release OpenAssistant Conversations, a human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages distributed across 66,497 conversation trees, in 35 different languages, annotated with 461,292 quality ratings. The corpus is a product of a worldwide crowd-sourcing effort involving over 1
    
[^22]: 语言指导下的强化学习以实现人工智能协作

    Language Instructed Reinforcement Learning for Human-AI Coordination. (arXiv:2304.07297v1 [cs.AI])

    [http://arxiv.org/abs/2304.07297](http://arxiv.org/abs/2304.07297)

    本文提出了一种称之为instructRL的新的框架，它通过自然语言指令来指定对人工智能搭档的预期策略，解决在缺乏高质量人类行为数据的领域中多智能体强化学习收敛于人类不偏爱的策略的问题，从而提高了人工智能协作的性能。

    

    人工智能的一个基本问题是如何让智能体能够和人类有效地协作。本文提出了一种称之为instructRL的新的框架，让人们可以通过自然语言指令来指定对人工智能搭档的预期策略，以此解决在缺乏较高质量的人类行为数据的领域中，由于多智能体强化学习常常会收敛到人类并不偏爱的策略的不足。我们使用预先训练的大型语言模型来生成一个在人类指令下的先验策略，并将其用于约束强化学习目标。这导致强化学习智能体收敛到与人类喜好一致的均衡点。通过概念证明环境和具有挑战性的Hanabi基准，证明了instructRL收敛于满足给定指令的类似人类智能体的策略。最后，我们证明了知道语言指令显著提高了人工智能协作的性能。

    One of the fundamental quests of AI is to produce agents that coordinate well with humans. This problem is challenging, especially in domains that lack high quality human behavioral data, because multi-agent reinforcement learning (RL) often converges to different equilibria from the ones that humans prefer. We propose a novel framework, instructRL, that enables humans to specify what kind of strategies they expect from their AI partners through natural language instructions. We use pretrained large language models to generate a prior policy conditioned on the human instruction and use the prior to regularize the RL objective. This leads to the RL agent converging to equilibria that are aligned with human preferences. We show that instructRL converges to human-like policies that satisfy the given instructions in a proof-of-concept environment as well as the challenging Hanabi benchmark. Finally, we show that knowing the language instruction significantly boosts human-AI coordination pe
    
[^23]: Vax-Culture: 用于研究推特上疫苗讨论的数据集

    Vax-Culture: A Dataset for Studying Vaccine Discourse on Twitter. (arXiv:2304.06858v1 [cs.SI])

    [http://arxiv.org/abs/2304.06858](http://arxiv.org/abs/2304.06858)

    本文介绍了一个推特疫苗数据集Vax-Culture，它旨在找出推广疫苗错误信息的文化和政治信念的重叠部分，帮助开发机器学习模型以自动检测疫苗错误信息帖子并应对其负面影响。

    

    COVID-19疫情期间，疫苗犹豫继续是公共卫生官员面临的主要挑战。由于该犹豫破坏了疫苗运动，许多研究人员试图确定其根本原因，并发现社交媒体平台上反疫苗错误信息的不断增长是该问题的关键因素。我们将推特作为误导内容的来源，并旨在提取推广疫苗错误信息的文化和政治信念的重叠部分。为此，我们收集了一个与疫苗有关的推文数据集，并借助专业沟通和新闻背景的注释人员进行注释。我们最终希望这可以带来有效和有针对性的公共卫生通信策略，以接触那些持反疫苗信仰者。此外，这些信息有助于开发机器学习模型以自动检测疫苗错误信息帖子并应对其负面影响。

    Vaccine hesitancy continues to be a main challenge for public health officials during the COVID-19 pandemic. As this hesitancy undermines vaccine campaigns, many researchers have sought to identify its root causes, finding that the increasing volume of anti-vaccine misinformation on social media platforms is a key element of this problem. We explored Twitter as a source of misleading content with the goal of extracting overlapping cultural and political beliefs that motivate the spread of vaccine misinformation. To do this, we have collected a data set of vaccine-related Tweets and annotated them with the help of a team of annotators with a background in communications and journalism. Ultimately we hope this can lead to effective and targeted public health communication strategies for reaching individuals with anti-vaccine beliefs. Moreover, this information helps with developing Machine Learning models to automatically detect vaccine misinformation posts and combat their negative impa
    
[^24]: SpectFormer: 频率和注意力是视觉Transformer所需要的。

    SpectFormer: Frequency and Attention is what you need in a Vision Transformer. (arXiv:2304.06446v1 [cs.CV])

    [http://arxiv.org/abs/2304.06446](http://arxiv.org/abs/2304.06446)

    本文提出了结合多头注意力和谱层的Spectformer架构，可以得到更好的性能表现，提高了top-1准确率2%。

    

    视觉Transformer已成功地应用于图像识别任务中。其种类包括基于多头自我注意力机制（如ViT、DeIT）和基于谱层（如Fnet、GFNet、AFNO）的模型。本文发现，多头注意力和谱层都对Transformer起到重要作用，将两者结合可以得到更好的性能表现。因此提出了新的Spectformer架构，将多头注意力和谱层融合起来。实验表明，Spectformer可恰当地捕捉特征表示，与其他Transformer表征相比，可以提高top-1准确率2%。

    Vision transformers have been applied successfully for image recognition tasks. There have been either multi-headed self-attention based (ViT \cite{dosovitskiy2020image}, DeIT, \cite{touvron2021training}) similar to the original work in textual models or more recently based on spectral layers (Fnet\cite{lee2021fnet}, GFNet\cite{rao2021global}, AFNO\cite{guibas2021efficient}). We hypothesize that both spectral and multi-headed attention plays a major role. We investigate this hypothesis through this work and observe that indeed combining spectral and multi-headed attention layers provides a better transformer architecture. We thus propose the novel Spectformer architecture for transformers that combines spectral and multi-headed attention layers. We believe that the resulting representation allows the transformer to capture the feature representation appropriately and it yields improved performance over other transformer representations. For instance, it improves the top-1 accuracy by 2
    
[^25]: DoctorGLM：让中文医生调整不再是一个艰巨的任务

    DoctorGLM: Fine-tuning your Chinese Doctor is not a Herculean Task. (arXiv:2304.01097v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.01097](http://arxiv.org/abs/2304.01097)

    使用中文医学对话数据库，微调ChatGLM-6B模型，实现易于部署的以医疗为目的的LLM，从而提高医疗建议的精度和推广LLM的可行性。

    

    近期大型语言模型（LLM），包括ChatGPT和GPT-4，在理解和回应人类指令方面取得了显着进展。然而，这些模型通常在英语方面表现更好，并没有明确地针对医学领域进行训练，导致诊断、药物推荐和其他医疗建议的精度不尽如人意。此外，训练和部署对话模型仍被认为对医院来说是不可能的，这阻碍了LLM的推广。为了解决这些挑战，我们利用ChatGPT的帮助收集了中文的医学对话数据库，并采用了多种技术来训练一个易于部署的LLM。值得注意的是，我们能够在单个A100 80G上以13个小时的时间对ChatGLM-6B进行微调，这意味着拥有一个以医疗为目的的LLM可能非常实惠。DoctorGLM目前是一项早期的工程尝试，包含各种错误。我们与广大社区分享，并邀请反馈和建议改进。

    The recent progress of large language models (LLMs), including ChatGPT and GPT-4, in comprehending and responding to human instructions has been remarkable. Nevertheless, these models typically perform better in English and have not been explicitly trained for the medical domain, resulting in suboptimal precision in diagnoses, drug recommendations, and other medical advice. Additionally, training and deploying a dialogue model is still believed to be impossible for hospitals, hindering the promotion of LLMs. To tackle these challenges, we have collected databases of medical dialogues in Chinese with ChatGPT's help and adopted several techniques to train an easy-deploy LLM. Remarkably, we were able to fine-tune the ChatGLM-6B on a single A100 80G in 13 hours, which means having a healthcare-purpose LLM can be very affordable. DoctorGLM is currently an early-stage engineering attempt and contain various mistakes. We are sharing it with the broader community to invite feedback and suggest
    
[^26]: 大型语言模型综述

    A Survey of Large Language Models. (arXiv:2303.18223v1 [cs.CL])

    [http://arxiv.org/abs/2303.18223](http://arxiv.org/abs/2303.18223)

    本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。

    

    语言本质上是一个由语法规则控制的复杂精细的人类表达系统，对于开发理解和掌握语言的能力的AI算法来说是一项重大挑战。作为主要方法之一，语言建模在过去二十年里广泛研究用于语言理解和生成，从统计语言模型演化为神经语言模型。最近，通过在大规模语料库上预训练Transformer模型，提出了预训练语言模型（PLMs），在解决各种NLP任务方面显示出强大的能力。由于研究人员发现模型缩放可以导致性能改进，他们进一步通过增加模型规模来研究缩放效应，有趣的是，当参数规模超过一定水平时，这些扩大的语言模型不仅可以实现显着的性能提升，而且还显示出一些小规模语言模型所没有的特殊能力。

    Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale langu
    
[^27]: 大型语言模型可以在零-shot学习环境下用于评估政治家的意识形态

    Large Language Models Can Be Used to Estimate the Ideologies of Politicians in a Zero-Shot Learning Setting. (arXiv:2303.12057v1 [cs.CY])

    [http://arxiv.org/abs/2303.12057](http://arxiv.org/abs/2303.12057)

    本文展示了在零-shot学习环境下，大型语言模型可以用于评估政治家的意识形态，为我们更好地理解政治功能提供了有用的信息。

    

    大型语言模型（LLMs）中蕴含的大量知识可以为社会科学中的可观测性和测量问题提供新的解决方案。本文研究了其中一种模型在衡量立法者的潜在意识形态方面的效用，这有助于我们更好地理解塑造政策的政治功能，以及政治行为者代表其选民的方式。我们通过提示ChatGPT在两两比较中选择更自由派（或保守派）的参议员，将第116届美国国会的参议员按照自由派-保守派的光谱进行缩放。我们展示了LLM在重复迭代中产生了稳定的答案，没有产生幻觉，并且不仅仅是从单一来源中复制信息。这个新尺度与现有的自由派-保守派尺度（如NOMINATE）强相关，但也在几个重要方面存在差异，比如正确定位一些路径依赖和自由派派别的议员。

    The mass aggregation of knowledge embedded in large language models (LLMs) holds the promise of new solutions to problems of observability and measurement in the social sciences. We examine the utility of one such model for a particularly difficult measurement task: measuring the latent ideology of lawmakers, which allows us to better understand functions that are core to democracy, such as how politics shape policy and how political actors represent their constituents. We scale the senators of the 116th United States Congress along the liberal-conservative spectrum by prompting ChatGPT to select the more liberal (or conservative) senator in pairwise comparisons. We show that the LLM produced stable answers across repeated iterations, did not hallucinate, and was not simply regurgitating information from a single source. This new scale strongly correlates with pre-existing liberal-conservative scales such as NOMINATE, but also differs in several important ways, such as correctly placin
    
[^28]: 基于深度递归网络的公司名称消歧

    Disambiguation of Company names via Deep Recurrent Networks. (arXiv:2303.05391v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.05391](http://arxiv.org/abs/2303.05391)

    本研究提出了一种利用深度递归网络进行公司名称消歧的方法，相较于标准字符串匹配算法具有更优的表现，还采用主动学习来优化样本标记效率。

    

    命名实体消歧是自然语言处理的一个任务，其目标是识别对应于同一命名实体的文本记录。本研究的任务是根据公司的书面名称消除歧义。我们提出了一种连续LSTM网络方法来提取公司名称字符串的嵌入，进而使用这种表示来识别真正表示同一公司（即相同实体）的公司名称对。考虑到手动标记字符串对是一项费力的任务，我们分析了主动学习方法如何优先选择样本进行标记从而使整个学习流程更加高效。经实证，我们的Siamese网络优于多种基于标准字符串匹配算法的基准方法。

    Name Entity Disambiguation is the Natural Language Processing task of identifying textual records corresponding to the same Named Entity, i.e. real-world entities represented as a list of attributes (names, places, organisations, etc.). In this work, we face the task of disambiguating companies on the basis of their written names. We propose a Siamese LSTM Network approach to extract -- via supervised learning -- an embedding of company name strings in a (relatively) low dimensional vector space and use this representation to identify pairs of company names that actually represent the same company (i.e. the same Entity).  Given that the manual labelling of string pairs is a rather onerous task, we analyse how an Active Learning approach to prioritise the samples to be labelled leads to a more efficient overall learning pipeline.  With empirical investigations, we show that our proposed Siamese Network outperforms several benchmark approaches based on standard string matching algorithms
    
[^29]: xCodeEval：一个用于代码理解、生成、翻译和检索的大规模多语言多任务基准

    xCodeEval: A Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and Retrieval. (arXiv:2303.03004v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.03004](http://arxiv.org/abs/2303.03004)

    xCodeEval是一个大规模多语言多任务的基准，用于评估预训练的大型语言模型生成、修复、翻译和检索代码的能力，并解决了以往仅关注特定任务和缺乏训练数据的问题。

    

    解决问题的能力是智能的标志，并且一直是 AI 的目标。能够创建作为问题解决方案的程序的 AI 系统，或者协助开发人员编写程序，都可以提高生产率并使编程更易于访问。最近，预训练的大型语言模型在从自然语言描述生成新代码、修复有问题的代码、在不同语言之间进行代码翻译以及检索相关代码片段方面展示出了令人印象深刻的能力。然而，这些模型的评估通常是分散在仅一个或两个特定任务上，在少数语言、在部分粒度水平（例如函数级别）上进行，并且在许多情况下缺乏适当的训练数据。更为令人担忧的是，在大多数情况下，生成的代码的评估是以仅仅词汇重叠为基础，而不是实际执行，而两段代码段的语义相似性（或等效性）仅取决于它们的“执行相似性”。

    The ability to solve problems is a hallmark of intelligence and has been an enduring goal in AI. AI systems that can create programs as solutions to problems or assist developers in writing programs can increase productivity and make programming more accessible. Recently, pre-trained large language models have shown impressive abilities in generating new codes from natural language descriptions, repairing buggy codes, translating codes between languages, and retrieving relevant code segments. However, the evaluation of these models has often been performed in a scattered way on only one or two specific tasks, in a few languages, at a partial granularity (e.g., function) level and in many cases without proper training data. Even more concerning is that in most cases the evaluation of generated codes has been done in terms of mere lexical overlap rather than actual execution whereas semantic similarity (or equivalence) of two code segments depends only on their ``execution similarity'', 
    
[^30]: 虚拟代理人的端到端口语化实体提取

    E2E Spoken Entity Extraction for Virtual Agents. (arXiv:2302.10186v4 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2302.10186](http://arxiv.org/abs/2302.10186)

    本文研究了利用预训练语音编码器从语音中直接提取实体的方法，无需文本转录，且在口语实体识别任务中表现优异。

    

    本文重新构想了语音处理中的一些方面，特别是关于从语音中直接提取实体，而无需中间文本表示。在人与计算机的对话中，从语音中提取实体，如姓名、邮政地址和电子邮件地址，是一项具有挑战性的任务。我们研究了微调预训练语音编码器对从语音中直接提取可读性强的实体的影响，而无需进行文本转录。我们说明这种直接方法优化了编码器，以仅转录语音中与实体相关的部分，忽略了多余的部分，如搭档语或实体拼写。在企业虚拟代理人的对话上下文中，我们展示了一步法的方法优于典型的两步法，即首先产生词汇转录，然后进行基于文本的实体提取以识别口语实体。

    This paper reimagines some aspects of speech processing using speech encoders, specifically about extracting entities directly from speech, with no intermediate textual representation. In human-computer conversations, extracting entities such as names, postal addresses and email addresses from speech is a challenging task. In this paper, we study the impact of fine-tuning pre-trained speech encoders on extracting spoken entities in human-readable form directly from speech without the need for text transcription. We illustrate that such a direct approach optimizes the encoder to transcribe only the entity relevant portions of speech, ignoring the superfluous portions such as carrier phrases and spellings of entities. In the context of dialogs from an enterprise virtual agent, we demonstrate that the 1-step approach outperforms the typical 2-step cascade of first generating lexical transcriptions followed by text-based entity extraction for identifying spoken entities.
    
[^31]: 语义不确定性：自然语言生成不确定性估计中的语言不变量

    Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation. (arXiv:2302.09664v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.09664](http://arxiv.org/abs/2302.09664)

    本文提出了一种测量大型语言模型中不确定性的方法，引入了语义熵以克服自然语言中的“语义等价性”，该方法是无监督的，并且对于问题回答数据集上的模型准确性具有更好的预测性能。

    

    我们介绍了一种测量大型语言模型中不确定性的方法。对于像问答任务这样的任务，了解何时可以信任基础模型的自然语言输出至关重要。我们发现，由于“语义等价性”，测量自然语言的不确定性是有挑战性的——不同的句子可以表示相同的意思。为了克服这些挑战，我们引入了语义熵——一种包含共享含义所创建的语言不变量的熵。我们的方法是无监督的，仅使用单个模型，并且不需要修改现成的语言模型。在全面的消融研究中，我们展示了语义熵对于问题回答数据集上的模型准确性比可比基线更具有预测性。

    We introduce a method to measure uncertainty in large language models. For tasks like question answering, it is essential to know when we can trust the natural language outputs of foundation models. We show that measuring uncertainty in natural language is challenging because of "semantic equivalence" -- different sentences can mean the same thing. To overcome these challenges we introduce semantic entropy -- an entropy which incorporates linguistic invariances created by shared meanings. Our method is unsupervised, uses only a single model, and requires no modifications to off-the-shelf language models. In comprehensive ablation studies we show that the semantic entropy is more predictive of model accuracy on question answering data sets than comparable baselines.
    
[^32]: 知识增强的语义通信接收器

    Knowledge Enhanced Semantic Communication Receiver. (arXiv:2302.07727v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.07727](http://arxiv.org/abs/2302.07727)

    提出了一个知识增强的语义通信框架，其中接收器可以更积极地利用知识库中的事实进行语义推理和解码，并通过知识提取器和基于GCN的语义解码器实现了更好的性能，不影响发射端的神经网络结构。

    

    近年来，随着深度学习和自然语言处理技术的快速发展，语义通信已成为通信领域的热门话题。尽管现有的基于深度学习的语义通信方法已经显示出许多优势，但它们仍然没有充分利用先前的知识。此外，大多数现有的语义通信方法侧重于发射端的语义编码，而我们认为，接收方的语义解码能力也应该受到关注。在本文中，我们提出了一个知识增强的语义通信框架，其中接收器可以更积极地利用知识库中的事实进行语义推理和解码，而不影响发射端的神经网络结构，仅影响其参数。具体来说，我们设计了基于transformer的知识提取器，以查找接收到的嘈杂数据中的相关事实三元组，并提出了基于图卷积网络（GCN）的语义解码器以更好地理解单词之间的语义关系。我们在两个常用数据集上评估了我们提出的框架，并实现了最先进的性能。

    In recent years, with the rapid development of deep learning and natural language processing technologies, semantic communication has become a topic of great interest in the field of communication. Although existing deep learning-based semantic communication approaches have shown many advantages, they still do not make sufficient use of prior knowledge. Moreover, most existing semantic communication methods focus on the semantic encoding at the transmitter side, while we believe that the semantic decoding capability of the receiver should also be concerned. In this paper, we propose a knowledge enhanced semantic communication framework in which the receiver can more actively utilize the facts in the knowledge base for semantic reasoning and decoding, on the basis of only affecting the parameters rather than the structure of the neural networks at the transmitter side. Specifically, we design a transformer-based knowledge extractor to find relevant factual triples for the received noisy
    
[^33]: 多模态视觉监督对语言有益吗？

    Is Multimodal Vision Supervision Beneficial to Language?. (arXiv:2302.05016v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.05016](http://arxiv.org/abs/2302.05016)

    本文探讨了使用视觉监督训练的语言表示是否比普通语言表示在自然语言理解和常识推理基准测试方面表现更好。结果表明，大多数任务中，普通的语言表示表现出更好的性能。

    

    视觉（图像和视频）-语言（VL）预训练是最近流行的模式，它在多模态任务如图像检索、视频检索、视觉问题回答等方面取得了最先进的结果。这些模型以无监督的方式进行训练，并且非常受益于补充模态监督。在本文中，我们探讨了使用视觉监督训练的语言表示是否比普通语言表示在自然语言理解和常识推理基准测试方面表现更好。我们将试验不同的图像-文本模型，如ALBEF、BLIP、METER等，以及视频-文本模型，如ALPRO、Frozen-in-Time（FiT）、VIOLET等。我们将这些模型的独立文本编码器的语言表示与通过视觉监督学习的文本编码器的语言表示进行比较。我们的实验表明，大多数任务中，普通的语言表示表现出更好的性能。

    Vision (image and video) - Language (VL) pre-training is the recent popular paradigm that achieved state-of-the-art results on multi-modal tasks like image-retrieval, video-retrieval, visual question answering etc. These models are trained in an unsupervised way and greatly benefit from the complementary modality supervision. In this paper, we explore if the language representations trained using vision supervision perform better than vanilla language representations on Natural Language Understanding and commonsense reasoning benchmarks. We experiment with a diverse set of image-text models such as ALBEF, BLIP, METER and video-text models like ALPRO, Frozen-in-Time (FiT), VIOLET. We compare the performance of language representations of stand-alone text encoders of these models to the language representations of text encoders learnt through vision supervision. Our experiments suggest that vanilla language representations show superior performance on most of the tasks. These results she
    
[^34]: GLIGEN：开放式基于文本的图像生成方法

    GLIGEN: Open-Set Grounded Text-to-Image Generation. (arXiv:2301.07093v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.07093](http://arxiv.org/abs/2301.07093)

    GLIGEN是一种开放式基于语言关联性和预训练的文本到图像生成方法，通过门控机制注入连结信息，能够实现零样本的基于关键字和边界框的文本到图像生成，性能优于现有的监督布局到图像的基线。

    

    大规模的文本到图像扩散模型取得了令人惊叹的进展。然而，现状是仅使用文本输入，这可能会限制可控性。在这项工作中，我们提出了GLIGEN，基于语言关联的图像生成方法，这是一种新颖的方法，它建立在现有预训练的文本到图像扩散模型的基础上，并使其能够依赖于语言关联性输入。为了保留预训练模型的广泛概念知识，我们冻结所有权重，并通过门控机制将连结信息注入到新的可训练层中。我们的模型实现了开放式基于关键字和边界框的文本到图像生成，而且连结能力在新的空间配置和概念上具有良好的普适性。GLIGEN在COCO和LVIS的零样本表现优于现有的监督布局到图像的基线。

    Large-scale text-to-image diffusion models have made amazing advances. However, the status quo is to use text input alone, which can impede controllability. In this work, we propose GLIGEN, Grounded-Language-to-Image Generation, a novel approach that builds upon and extends the functionality of existing pre-trained text-to-image diffusion models by enabling them to also be conditioned on grounding inputs. To preserve the vast concept knowledge of the pre-trained model, we freeze all of its weights and inject the grounding information into new trainable layers via a gated mechanism. Our model achieves open-world grounded text2img generation with caption and bounding box condition inputs, and the grounding ability generalizes well to novel spatial configurations and concepts. GLIGEN's zero-shot performance on COCO and LVIS outperforms that of existing supervised layout-to-image baselines by a large margin.
    
[^35]: VaxxHesitancy: 一份用于研究推特上对 COVID-19 疫苗犹豫的数据集。

    VaxxHesitancy: A Dataset for Studying Hesitancy Towards COVID-19 Vaccination on Twitter. (arXiv:2301.06660v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.06660](http://arxiv.org/abs/2301.06660)

    该论文介绍了一份用于研究推特上 COVID-19 疫苗犹豫的数据集，疫苗犹豫一直是一个普遍的问题，了解公众对 COVID-19 疫苗犹豫的原因非常重要。

    

    疫苗犹豫一直是一个普遍的问题，随着社交媒体的普及，人们开始在网上表达他们对疫苗的担忧，同时也与支持和反对疫苗的人发表内容。自从第一次提到 COVID-19 疫苗以来，社交媒体用户就在发布关于他们的担忧和支持疫苗有效性的内容。了解公众对 COVID-19 疫苗犹豫的原因非常重要，对于需要制定行动以更好地告知人群以增加疫苗接种率的政策制定者来说尤其如此。在 COVID-19 的情况下，疫苗快速开发与反疫苗虚假信息的增长相伴，自动检测公民对疫苗接种的态度成为必需。这是一个重要的计算社会科学任务，需要数据分析才能获得更多洞见。

    Vaccine hesitancy has been a common concern, probably since vaccines were created and, with the popularisation of social media, people started to express their concerns about vaccines online alongside those posting pro- and anti-vaccine content. Predictably, since the first mentions of a COVID-19 vaccine, social media users posted about their fears and concerns or about their support and belief into the effectiveness of these rapidly developing vaccines. Identifying and understanding the reasons behind public hesitancy towards COVID-19 vaccines is important for policy markers that need to develop actions to better inform the population with the aim of increasing vaccine take-up. In the case of COVID-19, where the fast development of the vaccines was mirrored closely by growth in anti-vaxx disinformation, automatic means of detecting citizen attitudes towards vaccination became necessary. This is an important computational social sciences task that requires data analysis in order to gai
    
[^36]: 基于全卷积神经网络训练的低资源蒙古语文本到语音系统的高效实现

    Efficiently Trained Low-Resource Mongolian Text-to-Speech System Based On FullConv-TTS. (arXiv:2211.01948v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.01948](http://arxiv.org/abs/2211.01948)

    该论文提出了一个基于全卷积神经网络训练的低资源蒙古语文本到语音系统，相较于传统的包含循环神经网络的TTS模型，训练时间更短且音频合成质量不降低。

    

    循环神经网络(RNN)已经成为了序列数据建模的标准技术，也被用于构建一些新奇的文本到语音模型。但是，包含RNN组件的TTS模型要求GPU性能高且训练时间长。相反，研究发现基于CNN的序列合成技术可以大大减少TTS模型的训练时间，同时由于其高度并行化，可以保证一定的性能。我们提出了一个基于深度卷积神经网络的新型文本到语音系统，不使用任何RNN组件(循环单元)。同时，通过一系列的数据增强方法，如时间扭曲，频率屏蔽和时间屏蔽等，提高了我们模型的普适性和鲁棒性。最终的实验结果表明，仅使用CNN组件的TTS模型可以减少与Tacotron等传统TTS模型相比的训练时间，同时确保合成音频的质量。

    Recurrent Neural Networks (RNNs) have become the standard modeling technique for sequence data, and are used in a number of novel text-to-speech models. However, training a TTS model including RNN components has certain requirements for GPU performance and takes a long time. In contrast, studies have shown that CNN-based sequence synthesis technology can greatly reduce training time in text-to-speech models while ensuring a certain performance due to its high parallelism. We propose a new text-to-speech system based on deep convolutional neural networks that does not employ any RNN components (recurrent units). At the same time, we improve the generality and robustness of our model through a series of data augmentation methods such as Time Warping, Frequency Mask, and Time Mask. The final experimental results show that the TTS model using only the CNN component can reduce the training time compared to the classic TTS models such as Tacotron while ensuring the quality of the synthesized
    
[^37]: 用CCG解析和大型语言模型建模大脑中的结构建造

    Modeling structure-building in the brain with CCG parsing and large language models. (arXiv:2210.16147v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.16147](http://arxiv.org/abs/2210.16147)

    本研究使用CCG和大型语言模型模拟人类神经信号，发现比无上下文文法更具表达力的CCG更适合表达语法结构。

    

    为了模拟自然环境下语言理解的行为和神经相关性，研究人员借助自然语言处理和机器学习等广泛覆盖的工具。在显式建模句法结构方面，以前的工作主要依赖于无上下文文法（CFG），但这种形式主义对于人类语言来说并不足够表达。组合范畴语法（CCG）是充分表达语法的直接组合模型，具有灵活的从属关系，可以进行增量解释。本研究评估了比CFG更具表达力的CCG是否为人类神经信号提供了比CFG更好的模型，这些神经信号是在听有声书故事时收集的。我们进一步测试了处理可选附加语的CCG变体之间的差异。这些评估是针对具有变压器神经网络语言模型的下一个单词可预测性估计的基线进行的。

    To model behavioral and neural correlates of language comprehension in naturalistic environments researchers have turned to broad-coverage tools from natural-language processing and machine learning. Where syntactic structure is explicitly modeled, prior work has relied predominantly on context-free grammars (CFG), yet such formalisms are not sufficiently expressive for human languages. Combinatory Categorial Grammars (CCGs) are sufficiently expressive directly compositional models of grammar with flexible constituency that affords incremental interpretation. In this work we evaluate whether a more expressive CCG provides a better model than a CFG for human neural signals collected with fMRI while participants listen to an audiobook story. We further test between variants of CCG that differ in how they handle optional adjuncts. These evaluations are carried out against a baseline that includes estimates of next-word predictability from a Transformer neural network language model. Such 
    
[^38]: 以架构感知参考作为提示提高了数据有效的知识图谱构建

    Schema-aware Reference as Prompt Improves Data-Efficient Knowledge Graph Construction. (arXiv:2210.10709v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.10709](http://arxiv.org/abs/2210.10709)

    提出了一种以检索增强的架构感知参考作为提示的方法，可动态利用人类注释和弱监督数据所继承的架构和知识，指导生成具有更好语义连贯性和一致性的结构化知识，从而在数据效率和知识质量方面具有优越性。

    

    随着预训练语言模型的发展，许多基于提示的方法被提出并在数据有效的知识图谱构建中取得了令人瞩目的表现。然而，现有的基于提示的学习方法仍存在几个潜在的限制：（i）自然语言和预定义模式的输出结构化知识之间的语义差距，这意味着模型无法充分利用受限模板的语义知识；（ii）基于局部个体实例的表示学习限制了性能，给定了不充足的特征，这些特征不能释放预先训练语言模型的潜在类比能力。受这些观察的启发，我们提出了一种检索增强的方法，使用检索得到的架构感知参考作为提示，提高了数据有效的知识图谱构建的语义连贯性和一致性。在两个标准数据集上的实验结果表明，相比现有的基于提示和非提示的方法，我们提出的方法在数据效率和知识质量方面具有优越性。

    With the development of pre-trained language models, many prompt-based approaches to data-efficient knowledge graph construction have been proposed and achieved impressive performance. However, existing prompt-based learning methods for knowledge graph construction are still susceptible to several potential limitations: (i) semantic gap between natural language and output structured knowledge with pre-defined schema, which means model cannot fully exploit semantic knowledge with the constrained templates; (ii) representation learning with locally individual instances limits the performance given the insufficient features, which are unable to unleash the potential analogical capability of pre-trained language models. Motivated by these observations, we propose a retrieval-augmented approach, which retrieves schema-aware Reference As Prompt (RAP), for data-efficient knowledge graph construction. It can dynamically leverage schema and knowledge inherited from human-annotated and weak-supe
    
[^39]: 一条新路: 用合成指令和模仿学习扩展视觉语言导航模型的规模

    A New Path: Scaling Vision-and-Language Navigation with Synthetic Instructions and Imitation Learning. (arXiv:2210.03112v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.03112](http://arxiv.org/abs/2210.03112)

    该论文研究了使用合成指令的大规模扩充方法，通过构建导航轨迹并使用高质量的多语言导航指令生成器Marky生成基于图像的指令，以及使用图像到图像GAN在新的视角上合成图像观察。这些方法得到了更强的视觉语言导航模型。

    

    最近在视觉语言导航（VLN）中的研究使用强化学习代理在逼真的环境中执行自然语言导航指令，以实现机器人遵循人类指令的目标。然而，研究表明由于人类指令数据稀缺且训练环境缺乏多样性，这些代理仍然难以理解复杂的语言和空间语言。我们调查了使用合成指令的大规模扩充。我们利用Marky，一种高品质的多语言导航指令生成器，创建了500多个室内环境，通过这些全景图构建导航轨迹，并为每个轨迹生成了一个基于图像的指令。我们还使用图像到图像GAN在新的视角上合成图像观察。通过这些方法得到了更强的视觉语言导航模型。

    Recent studies in Vision-and-Language Navigation (VLN) train RL agents to execute natural-language navigation instructions in photorealistic environments, as a step towards robots that can follow human instructions. However, given the scarcity of human instruction data and limited diversity in the training environments, these agents still struggle with complex language grounding and spatial language understanding. Pretraining on large text and image-text datasets from the web has been extensively explored but the improvements are limited. We investigate large-scale augmentation with synthetic instructions. We take 500+ indoor environments captured in densely-sampled 360 degree panoramas, construct navigation trajectories through these panoramas, and generate a visually-grounded instruction for each trajectory using Marky, a high-quality multilingual navigation instruction generator. We also synthesize image observations from novel viewpoints using an image-to-image GAN. The resulting d
    
[^40]: DecAF：针对知识库问答的答案和逻辑形式联合解码

    DecAF: Joint Decoding of Answers and Logical Forms for Question Answering over Knowledge Bases. (arXiv:2210.00063v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.00063](http://arxiv.org/abs/2210.00063)

    DecAF 提出了一种联合生成逻辑形式和直接答案的新型框架，结合了它们的优点以获取最终答案；同时，它还采用了简单的自由文本检索，相比以往的方法更易于适应不同的数据集。

    

    知识库问答旨在使用知识库中的实体和关系等事实信息回答自然语言问题。先前的方法要么生成可在知识库上执行以获取最终答案的逻辑形式，要么直接预测答案。实验证据表明，前者通常能产生更准确的答案，但由于生成的逻辑形式可能存在语法和语义错误的潜在问题，因此存在无法执行的问题。在本文中，我们提出了一种新颖的框架 DecAF，它联合生成逻辑形式和直接答案，然后将它们的优点结合起来得到最终答案。此外，与大多数先前的方法不同，DecAF 基于简单的自由文本检索，而不依赖任何实体链接工具--这种简化使其适应不同的数据集更加容易。DecAF 在 WebQSP、FreebaseQA 和 GrailQA 基准测试中取得了新的最高准确性，同时在 CommonsenseQA 基准测试上取得了具有竞争力的结果。

    Question answering over knowledge bases (KBs) aims to answer natural language questions with factual information such as entities and relations in KBs. Previous methods either generate logical forms that can be executed over KBs to obtain final answers or predict answers directly. Empirical results show that the former often produces more accurate answers, but it suffers from non-execution issues due to potential syntactic and semantic errors in the generated logical forms. In this work, we propose a novel framework DecAF that jointly generates both logical forms and direct answers, and then combines the merits of them to get the final answers. Moreover, different from most of the previous methods, DecAF is based on simple free-text retrieval without relying on any entity linking tools -- this simplification eases its adaptation to different datasets. DecAF achieves new state-of-the-art accuracy on WebQSP, FreebaseQA, and GrailQA benchmarks, while getting competitive results on the Com
    
[^41]: LUT-GEMM：基于LUT的量化矩阵乘法，用于大规模生成式语言模型的高效推理

    LUT-GEMM: Quantized Matrix Multiplication based on LUTs for Efficient Inference in Large-Scale Generative Language Models. (arXiv:2206.09557v3 [cs.DC] UPDATED)

    [http://arxiv.org/abs/2206.09557](http://arxiv.org/abs/2206.09557)

    本文介绍了一种基于LUT的量化矩阵乘法，用于大规模生成式语言模型的高效推理。采用仅针对权重的量化策略，并提出了LUT-GEMM内核加速量化矩阵乘法，实现压缩比和准确性之间的灵活平衡。

    

    最近自监督学习的先进技术与Transformer架构的结合极大地提高了自然语言处理（NLP）的性能。然而，强大的NLP模型需要越来越大的模型尺寸，从而导致大量的计算和内存需求。本文介绍了一种针对大规模生成式语言模型的高效推理框架。为了减少模型大小，我们采用了一种仅针对权重的量化策略，同时保留了激活函数的完整精度。因此，我们通过非均匀或均匀量化技术获得每个权重的低于4位的量化。我们提出的LUT-GEMM内核加速了量化矩阵乘法，提供了压缩比和准确性之间的灵活平衡。与早期仅适用于权重量化的矩阵乘法内核不同，LUT-GEMM有效地消除了资源消耗更大的反量化过程。

    The recent advancements in self-supervised learning, combined with the Transformer architecture, have enabled natural language processing (NLP) to achieve remarkably low perplexity. However, powerful NLP models necessitate increasing model size, leading to substantial computational and memory requirements. In this paper, we introduce an efficient inference framework tailored for large-scale generative language models. To reduce the model size, we employ a weight-only quantization strategy while preserving full precision for activations. As a result, we attain sub-4-bit quantization for each weight through non-uniform or uniform quantization techniques. Our proposed kernel, called LUT-GEMM, then accelerates quantized matrix multiplications, offering a flexible balance between compression ratio and accuracy. Unlike earlier matrix multiplication kernels that accommodated weight-only quantization, LUT-GEMM efficiently eliminates the resource-demanding dequantization process for both unifor
    
[^42]: 最少到最多提示可以使大规模语言模型实现复杂推理

    Least-to-Most Prompting Enables Complex Reasoning in Large Language Models. (arXiv:2205.10625v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2205.10625](http://arxiv.org/abs/2205.10625)

    本文提出最少到最多提示的策略，能够帮助大规模语言模型实现复杂推理并推广到难度更高的问题。通过这种策略结合GPT-3 code-davinci-002模型能够完美解决组合泛化基准SCAN中的所有分割。

    

    思维链提示在各种自然语言推理任务中表现出卓越的性能。然而，它在需要解决比提示中的示例更难的问题时表现不佳。为了克服这种易于困难泛化的挑战，我们提出了一种新的提示策略，即最少到最多提示。该策略的关键思想是将复杂问题分解成一系列更简单的子问题，然后按顺序解决它们。解决每个子问题都得益于先前解决的子问题的答案。我们在符号操作、组合推理和数学推理相关的任务上的实验结果表明，最少到最多提示能够推广到比提示中更难的问题。一个值得注意的发现是，在使用最少到最多提示与GPT-3 code-davinci-002模型的情况下，它可以以完美的准确性解决组合泛化基准SCAN中的任何分割(包括具有挑战性的零样本分割)，尽管之前无法在没有微调的情况下解决任何分割点。

    Chain-of-thought prompting has demonstrated remarkable performance on various natural language reasoning tasks. However, it tends to perform poorly on tasks which requires solving problems harder than the exemplars shown in the prompts. To overcome this challenge of easy-to-hard generalization, we propose a novel prompting strategy, least-to-most prompting. The key idea in this strategy is to break down a complex problem into a series of simpler subproblems and then solve them in sequence. Solving each subproblem is facilitated by the answers to previously solved subproblems. Our experimental results on tasks related to symbolic manipulation, compositional generalization, and math reasoning reveal that least-to-most prompting is capable of generalizing to more difficult problems than those seen in the prompts. A notable finding is that when the GPT-3 code-davinci-002 model is used with least-to-most prompting, it can solve the compositional generalization benchmark SCAN in any split (i
    
[^43]: TraVLR: 现在你看到它了，现在你没看到它了！一个用于评估视觉语言推理的双模数据集。

    TraVLR: Now You See It, Now You Don't! A Bimodal Dataset for Evaluating Visio-Linguistic Reasoning. (arXiv:2111.10756v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2111.10756](http://arxiv.org/abs/2111.10756)

    提出了TraVLR数据集，可以用于评估V+L模型的表现，数据集合成，包括四个V+L推理任务，同时使用双模式冗余编码来评估其泛化能力。

    

    已经开发了许多视觉语言（V+L）表示学习方法，但现有的数据集不能充分评估它们在统一空间中表示视觉和语言概念的程度。我们针对V+L模型提出了几种新颖的评估设置，包括跨模态传递。此外，现有的V+L基准经常报告整个数据集的全局准确性得分，这使得难以确定模型失败和成功的具体推理任务。我们提出了TraVLR，这是一个合成数据集，包括四个V+L推理任务。TraVLR的合成性质使我们能够沿任务相关维度限制其训练和测试分布，从而评估超出分布的泛化。TraVLR中的每个示例都以两种模态冗余编码场景，使得在训练或测试期间可以删除或添加其中的任一模态而不会失去相关信息。我们比较了四个最先进的V+L模型的性能。

    Numerous visio-linguistic (V+L) representation learning methods have been developed, yet existing datasets do not adequately evaluate the extent to which they represent visual and linguistic concepts in a unified space. We propose several novel evaluation settings for V+L models, including cross-modal transfer. Furthermore, existing V+L benchmarks often report global accuracy scores on the entire dataset, making it difficult to pinpoint the specific reasoning tasks that models fail and succeed at. We present TraVLR, a synthetic dataset comprising four V+L reasoning tasks. TraVLR's synthetic nature allows us to constrain its training and testing distributions along task-relevant dimensions, enabling the evaluation of out-of-distribution generalisation. Each example in TraVLR redundantly encodes the scene in two modalities, allowing either to be dropped or added during training or testing without losing relevant information. We compare the performance of four state-of-the-art V+L models,
    
[^44]: 统一实例和知识对齐预训练用于基于方面的情感分析

    Unified Instance and Knowledge Alignment Pretraining for Aspect-based Sentiment Analysis. (arXiv:2110.13398v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2110.13398](http://arxiv.org/abs/2110.13398)

    本论文提出了一种统一实例和知识对齐预训练框架，能够有效解决预训练和下游ABSA数据集之间的领域偏移问题，提高了基于方面的情感分析的性能，达到了最先进水平。

    

    基于方面的情感分析（ABSA）旨在确定对某个方面的情感倾向。由于昂贵且有限的标记数据，预训练策略已成为ABSA的事实标准。然而，预训练和下游ABSA数据集之间总是存在严重的领域偏移，直接微调时的知识转移效果不佳，导致下游任务表现亚优化。为了缓解这种领域偏移，我们引入了一个统一的对齐预训练框架，包括实例和知识层面的对齐，将其融入到预训练和微调流程中。具体而言，我们首先设计了一种新颖的分阶段检索采样方法，从大规模的预训练数据集中选择与目标领域相关的实例，从而实现预训练和目标领域实例的对齐（第一阶段）。然后，我们引入了基于知识指导的策略，进一步桥接知识层面的领域差异。我们在基准ABSA数据集上评估了我们的方法，并展示了其超越强基线的卓越性能。我们的方法在多个ABSA数据集上实现了最先进的结果，包括SemEval 2014任务4、SemEval 2015任务12和SemEval 2016任务5。

    Aspect-based Sentiment Analysis (ABSA) aims to determine the sentiment polarity towards an aspect. Because of the expensive and limited labelled data, the pretraining strategy has become the de-facto standard for ABSA. However, there always exists severe domain shift between the pretraining and downstream ABSA datasets, hindering the effective knowledge transfer when directly finetuning and making the downstream task performs sub-optimal. To mitigate such domain shift, we introduce a unified alignment pretraining framework into the vanilla pretrain-finetune pipeline with both instance- and knowledge-level alignments. Specifically, we first devise a novel coarse-to-fine retrieval sampling approach to select target domain-related instances from the large-scale pretraining dataset, thus aligning the instances between pretraining and target domains (First Stage). Then, we introduce a knowledge guidance-based strategy to further bridge the domain gap at the knowledge level. In practice, we 
    
[^45]: DeliData: 用于多方问题解决中的协商数据集

    DeliData: A dataset for deliberation in multi-party problem solving. (arXiv:2108.05271v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2108.05271](http://arxiv.org/abs/2108.05271)

    该文介绍了第一个公开可用的群体协商数据集，500个小组对话和14k个话语，64%的小组成员能够找到比他们单独找到的更好的解决方案。同时提出了一种新的注释模式用于捕捉协商线索，并使用该数据集评估了两种生成协商话语的方法。

    

    群体协商使人们能够协作解决问题，但由于缺乏资源，这方面的研究尚不完善。为此，我们引入了第一个公开可用的数据集，其中包含解决一个已经确立的认知任务的协作对话，包括500个小组对话和14k个话语。在这些对话中，64％的小组成员能够找到比他们单独找到的更好的解决方案，在最终解决方案为正确答案的小组中，有43.8％的小组中没有任何参与者自己就能正确解决任务。此外，我们提出了一种新的注释模式，捕捉协商线索，并公开了所有14k个注释过的话语。最后，我们使用提出的数据集开发和评估了两种生成协商话语的方法。数据收集平台、数据集和注释语料库可在https://delibot.xyz上公开获得。

    Group deliberation enables people to collaborate and solve problems, however, it is understudied due to a lack of resources. To this end, we introduce the first publicly available dataset containing collaborative conversations on solving a well-established cognitive task, consisting of 500 group dialogues and 14k utterances. In 64% of these conversations, the group members are able to find a better solution than they had identified individually, and in 43.8% of the groups who had a correct answer as their final solution, none of the participants had solved the task correctly by themselves. Furthermore, we propose a novel annotation schema that captures deliberation cues and release all 14k utterances annotated with it. Finally, we use the proposed dataset to develop and evaluate two methods for generating deliberation utterances. The data collection platform, dataset and annotated corpus are publicly available at https://delibot.xyz.
    

