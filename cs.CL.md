# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Reinforcement learning for question answering in programming domain using public community scoring as a human feedback.](http://arxiv.org/abs/2401.10882) | 本研究通过整合强化学习和Stack Overflow评分，提高了GPT Neo在编程问答中的性能，同时指出传统语言度量方法在编程领域的局限性。 |
| [^2] | [Pruning for Protection: Increasing Jailbreak Resistance in Aligned LLMs Without Fine-Tuning.](http://arxiv.org/abs/2401.10862) | 本文研究了剪枝对齐的LLMs的保护措施，发现剪枝LLM参数可以显著增强其抵抗“越狱”提示攻击的能力，并且对其他LLM行为也可能有更普遍的效果。同时，引入了一个有害任务数据集，证明剪枝有助于集中注意力在与任务相关的标记上。突出的聊天模型表现出很高的易感性。 |
| [^3] | [Advancements in eHealth Data Analytics through Natural Language Processing and Deep Learning.](http://arxiv.org/abs/2401.10850) | 通过自然语言处理和深度学习在eHealth数据分析中的进展，可以有效处理和解释医疗领域的大量文本数据，从而提高医疗服务和整个医疗领域的效率和知识水平。 |
| [^4] | [Using LLMs to discover emerging coded antisemitic hate-speech emergence in extremist social media.](http://arxiv.org/abs/2401.10841) | 这项研究提出了一种方法，可以检测新出现的编码恶意术语，为极端社交媒体中的反犹太恶意言论提供了解决方案。 |
| [^5] | [A survey on recent advances in named entity recognition.](http://arxiv.org/abs/2401.10825) | 这篇综述调查了最近的命名实体识别研究进展，并提供了对不同算法性能的深度比较，还探讨了数据集特征对方法行为的影响。 |
| [^6] | [Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads.](http://arxiv.org/abs/2401.10774) | Medusa是一个能够提升LLM推理性能的简洁框架，通过增加多个解码头以实现并行预测多个后续标记，并通过树状注意力机制和并行处理来减少解码步骤。 |
| [^7] | [Mitigating Hallucinations of Large Language Models via Knowledge Consistent Alignment.](http://arxiv.org/abs/2401.10768) | 本文提出了一种称为知识一致性对齐（KCA）的方法，通过减少训练数据中外部知识和预训练语料库中内在知识之间的不一致性，从而缓解了大型语言模型产生幻觉的问题。实验结果表明，KCA方法在多个基准测试中取得了优异的性能。 |
| [^8] | [Multimodal Sentiment Analysis with Missing Modality: A Knowledge-Transfer Approach.](http://arxiv.org/abs/2401.10747) | 本文提出了一种知识迁移方法，用于在缺失模态下进行多模态情感分析。通过翻译不同模态之间的内容以重构缺失的音频模态，并利用跨模态注意机制进行情感预测，实验证明了该方法在多个数据集上表现出显著的改进和与完整多模态监督方法相媲美的效果。 |
| [^9] | [Structured Code Representations Enable Data-Efficient Adaptation of Code Language Models.](http://arxiv.org/abs/2401.10716) | 本研究探索了使用结构化的代码表示来提高代码语言模型的数据效率适应性，通过使用解析树进行预训练和微调，即使只对表面形式进行预训练，也能在各种代码任务上取得显著改进。 |
| [^10] | [Q&A Prompts: Discovering Rich Visual Clues through Mining Question-Answer Prompts for VQA requiring Diverse World Knowledge.](http://arxiv.org/abs/2401.10712) | 本论文提出了一种叫做Q&A提示的方法，通过挖掘图像中的问题-回答对来发现丰富的视觉线索，以帮助AI模型更好地理解复杂视觉问题，提高跨模态推理能力。 |
| [^11] | [Weakly Supervised Gaussian Contrastive Grounding with Large Multimodal Models for Video Question Answering.](http://arxiv.org/abs/2401.10711) | 本论文提出了一种使用大型多模型的弱监督高斯对比基础模型来处理视频问答问题的方法。通过将问题和答案对作为事件描述，找到多个关键帧作为目标时刻，并利用这些时刻作为伪标签来强制LMMs进行推理。所提出的方法使用轻量级的基于高斯的对比基础模块（GCG）来学习时效结构。 |
| [^12] | [LangBridge: Multilingual Reasoning Without Multilingual Supervision.](http://arxiv.org/abs/2401.10695) | LangBridge是一种无需多语言监督的多语言推理方法，通过连接两个模型来适应多语言推理任务，尽管只使用英文数据进行训练，但它显著提高了语言模型对低资源语言的性能。 |
| [^13] | [A Simple Framework to Accelerate Multilingual Language Model for Monolingual Text Generation.](http://arxiv.org/abs/2401.10660) | 这项研究介绍了一种新颖的框架，旨在加速非英语语言的文本生成。通过预测更大的语言单元并针对目标语言进行调整，该框架降低了解码步骤的数量，并将生成速度提高了1.9倍。 |
| [^14] | [Attentive Fusion: A Transformer-based Approach to Multimodal Hate Speech Detection.](http://arxiv.org/abs/2401.10653) | 这项研究基于Transformer框架和"关注融合"层，采用多模态方法识别仇恨言论，突破了传统的文本分析限制。 |
| [^15] | [Sowing the Wind, Reaping the Whirlwind: The Impact of Editing Language Models.](http://arxiv.org/abs/2401.10647) | 本文研究了通过编辑语言模型的复杂后果，发现在增强模型准确性与保持道德完整性之间存在悖论。我们发现，尽管注入准确信息对模型的可靠性很重要，但它可能破坏模型的基本框架，导致不可预测和潜在的不安全行为。 |
| [^16] | [PHOENIX: Open-Source Language Adaption for Direct Preference Optimization.](http://arxiv.org/abs/2401.10580) | 该论文介绍了一种开源的语言适应方法PHOENIX，用于直接优化偏好。研究构建在最新的改进基础上，并将直接偏好优化方法应用于德语。 |
| [^17] | [Self-training from Self-memory in Data-to-text Generation.](http://arxiv.org/abs/2401.10567) | 本文提出了一种在数据到文本生成中的自我记忆自我训练（STSM）模型，通过利用自我记忆作为训练子集，并使用预定义条件验证其质量。实验证明，这种方法可以以较高的性能进行训练，并在两个数据集上进行了实验。 |
| [^18] | [OrchMoE: Efficient Multi-Adapter Learning with Task-Skill Synergy.](http://arxiv.org/abs/2401.10559) | OrchMoE通过利用模块化技能架构和自动任务识别，提升了参数效率微调领域的性能，实现了对多任务学习的重大进展。 |
| [^19] | [Multilingual acoustic word embeddings for zero-resource languages.](http://arxiv.org/abs/2401.10543) | 该研究发展了一种多语言声学词嵌入方法，用于解决缺乏标注数据的零资源语言的挑战。通过使用神经网络和多语言转移，该方法在零资源语言上取得了比现有模型更好的性能。研究还展示了该方法在仇恨言论检测和语义查询中的应用潜力。 |
| [^20] | [Speech Swin-Transformer: Exploring a Hierarchical Transformer with Shifted Windows for Speech Emotion Recognition.](http://arxiv.org/abs/2401.10536) | Speech Swin-Transformer是一种层次化的语音Transformer，利用平移窗口聚合多尺度情感特征，用于语音情感识别。该方法通过分割语音频谱图为段级补丁，利用本地窗口Transformer和平移窗口Transformer探索补丁内部的情感信息，并取得了显著的成功。 |
| [^21] | [The "Colonial Impulse" of Natural Language Processing: An Audit of Bengali Sentiment Analysis Tools and Their Identity-based Biases.](http://arxiv.org/abs/2401.10535) | 本研究审查了在孟加拉社群中经历殖民主义影响的情感分析工具，发现它们可能存在基于身份的偏见，并提出了警示。 |
| [^22] | [Mementos: A Comprehensive Benchmark for Multimodal Large Language Model Reasoning over Image Sequences.](http://arxiv.org/abs/2401.10529) | Mementos是一个新的基准测试，旨在评估多模态大型语言模型在图像序列推理中的能力。研究发现，现有的MLLM在准确描述图像序列的动态信息方面存在困难，容易导致物体及其行为的错误描述或错觉。 |
| [^23] | [Cross-lingual Editing in Multilingual Language Models.](http://arxiv.org/abs/2401.10521) | 本论文介绍了跨语言模型编辑（XME）范式，通过在一种语言中编辑事实并观察其对其他语言的更新传播，研究了多语言语言模型中的模型编辑技术（MET）的性能限制。 |
| [^24] | [A match made in consistency heaven: when large language models meet evolutionary algorithms.](http://arxiv.org/abs/2401.10510) | 大型语言模型和进化算法的结合具有强大的一致性，包括标记嵌入和基因型-表现型映射、位置编码和适应性塑造、位置嵌入和选择、注意力和交叉、前馈神经网络和突变、模型训练和参数更新以及多任务学习和多目标优化等多个核心特征。本文分析了现有的耦合研究，并为未来的研究提供了基本路线和关键挑战。 |
| [^25] | [FinSQL: Model-Agnostic LLMs-based Text-to-SQL Framework for Financial Analysis.](http://arxiv.org/abs/2401.10506) | 本论文提出了一种面向金融分析的基于LLMs的模型无关的文本到SQL框架FinSQL，同时还提供了一个实用的金融分析文本到SQL基准数据集BULL，从提示构造和参数化的角度为金融文本到SQL提供了系统化的处理。 |
| [^26] | [Knowledge Fusion of Large Language Models.](http://arxiv.org/abs/2401.10491) | 本文介绍了一种大型语言模型知识融合的方法，通过将现有预训练的语言模型合并为一个更强大的模型，从而提高目标模型的能力，验证实验结果证实了该方法的有效性。 |
| [^27] | [Generative Dense Retrieval: Memory Can Be a Burden.](http://arxiv.org/abs/2401.10487) | 本文提出了生成式密集检索（GDR）范式，通过在查询和文档之间实现簇间匹配和细粒度的簇内匹配，缓解了生成式检索面临的记忆准确性差、记忆混淆和记忆更新成本高的问题。 |
| [^28] | [Escape Sky-high Cost: Early-stopping Self-Consistency for Multi-step Reasoning.](http://arxiv.org/abs/2401.10480) | 本文提出了一种称为提前停止自一致性（ESC）的简单且可扩展的采样策略，用于降低多步推理任务中自一致性的成本，通过大量实验证明了其有效性。 |
| [^29] | [Name Tagging Under Domain Shift via Metric Learning for Life Sciences.](http://arxiv.org/abs/2401.10472) | 本论文通过度量学习提出了一种处理生命科学领域下领域漂移的命名标签的方法，通过将源实体和目标实体投影到特征空间的不同区域来减轻源实体错误标记为目标实体的问题。 |
| [^30] | [DeepEdit: Knowledge Editing as Decoding with Constraints.](http://arxiv.org/abs/2401.10471) | DeepEdit是一种神经符号方法，通过更好的推理一致性和对更新知识的意识，提高了大型语言模型的知识编辑能力，对多跳问题数据集MQuaKE取得了显著的进展。 |
| [^31] | [Data-driven grapheme-to-phoneme representations for a lexicon-free text-to-speech.](http://arxiv.org/abs/2401.10465) | 这篇论文通过使用自监督学习的方法，消除了传统G2P系统所面临的字典生成问题和固定音素表示问题，提出了一种无需字典的数据驱动音素表示方法，实验证明其与传统方法相比具有相当或稍微更好的效果。 |
| [^32] | [Critical Data Size of Language Models from a Grokking Perspective.](http://arxiv.org/abs/2401.10463) | 本文从理解的角度探讨了语言模型中的关键数据规模，证明了只有当语言模型达到关键大小时才会发生泛化，同时揭示了更大的模型需要更多数据的趋势。 |
| [^33] | [Contextualized Automatic Speech Recognition with Attention-Based Bias Phrase Boosted Beam Search.](http://arxiv.org/abs/2401.10449) | 本论文提出了一种基于注意力的上下文偏差方法，可以通过编辑短语列表进行定制，并结合特殊标记来有效地训练，以便在输入语音数据中检测偏差短语。此外，还提出了一种基于偏差短语索引概率的偏差短语增强束搜索算法，能进一步提高上下文化性能，实验证明该方法能够持续改善字错误率。 |
| [^34] | [Investigating Training Strategies and Model Robustness of Low-Rank Adaptation for Language Modeling in Speech Recognition.](http://arxiv.org/abs/2401.10447) | 本研究研究了语音识别中低秩适应的训练策略和模型鲁棒性。通过引入不同的LoRA训练策略，实现了相对词错误率的降低，并研究了模型对输入扰动的稳定性。实验结果表明，高级LoRA变体导致了某些扰动的性能下降。 |
| [^35] | [Large Language Models are Efficient Learners of Noise-Robust Speech Recognition.](http://arxiv.org/abs/2401.10446) | 本文通过引入噪声信息作为条件器，并从N-best列表中提取语言空间噪声嵌入，教会了大型语言模型（LLMs）进行噪声去除，从而实现了噪声鲁棒语音识别的生成式错误纠正（GER）。 |
| [^36] | [Breaking the Curse of Multilinguality with Cross-lingual Expert Language Models.](http://arxiv.org/abs/2401.10440) | 本论文提出了一种称为X-ELM的跨语言专家语言模型，通过独立训练语言模型的子集来减轻多语言竞争，为多语言处理带来提升。实验表明，X-ELM在各种语言上优于联合训练的多语言模型，并且可以适应新语言的迭代添加。 |
| [^37] | [Can Large Language Model Summarizers Adapt to Diverse Scientific Communication Goals?.](http://arxiv.org/abs/2401.10415) | 本研究探讨了大型语言模型在科学摘要任务中的可控性。通过控制风格特征，非微调的语言模型在评论生成任务中优于人类，同时基于关键词的引导可以改善模型的可控性。然而，模型在生成长摘要和高度抽象的简化摘要方面有限。总体而言，大型语言模型在摘要任务中表现出强大的通用能力，但在复杂控制方面有限。 |
| [^38] | [Learning High-Quality and General-Purpose Phrase Representations.](http://arxiv.org/abs/2401.10407) | 本论文提出了一种改进的框架来学习高质量和通用性的短语表示。该框架在无上下文的情况下学习短语表示，通过短语类型分类和有效地融合字符级信息来提高表示的精确性和灵活性。此外，还采用了三种粒度的数据增强方法以增加训练数据的多样性。 |
| [^39] | [Inconsistent dialogue responses and how to recover from them.](http://arxiv.org/abs/2401.10353) | 本研究探讨了对话系统中一致性问题的评估和增强方法。我们开发了一个数据集来研究不一致性，并引入了一组任务，专注于对话一致性的检测和解决。实验结果表明，我们的数据集显著地促进了对话系统中不一致性的识别和解决，然而目前的大型语言模型在解决不一致性方面表现出良好的特点，但在检测方面仍然存在困难。 |
| [^40] | [Bridging Cultural Nuances in Dialogue Agents through Cultural Value Surveys.](http://arxiv.org/abs/2401.10352) | 通过引入cuDialog，我们提出了一种以文化为视角的对话生成基准，并开发了能够从对话中提取文化属性的基准模型。实验结果显示，结合文化价值调查可以提高对话代理的对个性化和对话质量的预测准确性。 |
| [^41] | [Noise Contrastive Estimation-based Matching Framework for Low-resource Security Attack Pattern Recognition.](http://arxiv.org/abs/2401.10337) | 该论文提出了一种基于噪声对比估计的低资源安全攻击模式识别匹配框架，通过直接语义相似度决定文本与攻击模式之间的关联，以降低大量类别、标签分布不均和标签空间复杂性带来的学习难度。 |
| [^42] | [DrugAssist: A Large Language Model for Molecule Optimization.](http://arxiv.org/abs/2401.10334) | DrugAssist是一个交互式分子优化模型，通过人机对话实现优化，利用LLM的强交互性和泛化能力，在药物发现中取得了领先的结果。 |
| [^43] | [Top in Chinese Data Processing: English Code Models.](http://arxiv.org/abs/2401.10286) | 在中文数据处理中，基于代码的语言模型在非编程中文任务中表现出色，尤其是在对中文幻觉敏感的任务中。此研究为讨论“中文房间”思想实验提供了独特的视角。 |
| [^44] | [A systematic review of geospatial location embedding approaches in large language models: A path to spatial AI systems.](http://arxiv.org/abs/2401.10279) | 这篇论文系统综述了在大型语言模型中的地理位置嵌入方法，提出了四种主要的嵌入主题，并强调了在空间形态和生成模态方面进一步发展的需求。 |
| [^45] | [Knowledge graph driven recommendation model of graph neural network.](http://arxiv.org/abs/2401.10244) | 提出了一种基于知识图谱的图神经网络推荐模型KGLN，通过合并节点特征、调整聚合权重和迭代演化，提高了个性化推荐的准确性和效果。在实验中相对于已有基准方法，KGLN在不同数据集上的AUC提高了0.3%至5.9%和1.1%至8.2%。 |
| [^46] | [Better Explain Transformers by Illuminating Important Information.](http://arxiv.org/abs/2401.09972) | 通过在层间相关传播方法之上使用精细化的信息流，该论文提出了一种解释Transformer模型的方法，突出重要信息并消除无关信息。实验证明，在处理分类和问答任务时，这种方法相比其他八种基线模型更加出色。 |
| [^47] | [Aligning Large Language Models with Counterfactual DPO.](http://arxiv.org/abs/2401.09566) | 本文研究了在大型语言模型中使用反事实对抗优化框架，以实现风格对齐，避免人类干预，并成功培养出可取行为和减轻不可取行为。 |
| [^48] | [Efficient slot labelling.](http://arxiv.org/abs/2401.09343) | 本文提出了一种高效的槽位标注方法，相较于基于大型预训练语言模型的方法，具有更低的计算需求和训练参数量，并在实际工业场景中表现出色。 |
| [^49] | [RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning.](http://arxiv.org/abs/2401.08326) | RoTBench是一个多级基准，用于评估大型语言模型在工具学习中的鲁棒性。研究发现，LLMs在真实世界的噪声下表现出的稳定性需得到提高。 |
| [^50] | [Directed Regular and Context-Free Languages.](http://arxiv.org/abs/2401.07106) | 该论文研究了决定给定语言是否是定向语言的问题，并且证明了定向性问题在正则语言和上下文无关语言中的复杂性。 |
| [^51] | [INACIA: Integrating Large Language Models in Brazilian Audit Courts: Opportunities and Challenges.](http://arxiv.org/abs/2401.05273) | 本文介绍了INACIA系统，这是一个将大型语言模型整合到巴西审计法院中的系统，可以自动化案件分析的各个阶段，并展示了其在从案件文件中提取信息、评估合法性和生成司法建议方面的潜力。 |
| [^52] | [Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding.](http://arxiv.org/abs/2401.04398) | 这篇论文提出了Chain-of-Table框架，通过在推理链中使用表格数据作为中间思维的代理，利用大型语言模型在表格理解任务中进行推理，实现了动态演化的表格推理链。 |
| [^53] | [Improving Text Embeddings with Large Language Models.](http://arxiv.org/abs/2401.00368) | 本文介绍了一种使用只用合成数据和少量训练步骤获取高质量文本嵌入的简单方法，并且在没有使用标记数据的情况下，在竞争激烈的文本嵌入基准上取得了强大的性能。 |
| [^54] | [KnowledgeNavigator: Leveraging Large Language Models for Enhanced Reasoning over Knowledge Graph.](http://arxiv.org/abs/2312.15880) | KnowledgeNavigator是一种利用大型语言模型和知识图谱增强推理的框架，通过检索和过滤外部知识来解决LLM在长逻辑链和复杂推理场景中的知识限制问题。 |
| [^55] | [A ripple in time: a discontinuity in American history.](http://arxiv.org/abs/2312.01185) | 该论文通过使用向量嵌入和非线性降维方法，发现GPT-2与UMAP的结合可以提供更好的分离和聚类效果。同时，经过微调的DistilBERT模型可用于识别总统和演讲的年份。 |
| [^56] | [Enhancing Summarization Performance through Transformer-Based Prompt Engineering in Automated Medical Reporting.](http://arxiv.org/abs/2311.13274) | 通过使用两种不同的提示策略，shot prompting和pattern prompting，该研究提高了自动医学报告的性能，通过使用ROUGE分数和人工评估证明了其优越性。 |
| [^57] | [A Survey of Graph Meets Large Language Model: Progress and Future Directions.](http://arxiv.org/abs/2311.12399) | 本综述对将大型语言模型(LLMs)与图结合的现有方法进行了全面的回顾和分析，提出了一个新的分类法，并讨论了未来研究的有希望的方向。 |
| [^58] | [How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition.](http://arxiv.org/abs/2310.05492) | 本研究探讨了大规模语言模型在监督微调过程中，特别是数学推理和代码生成能力方面，数据组合的影响。实验结果显示，较大模型在相同数据量下表现出更好的性能，通过增加微调数据和模型参数，数学推理和代码生成能力得到显著提升。 |
| [^59] | [MULTISCRIPT: Multimodal Script Learning for Supporting Open Domain Everyday Tasks.](http://arxiv.org/abs/2310.04965) | 该论文提出了一个新的基准挑战MultiScript，旨在解决现有脚本学习方法对于开放领域日常任务的限制。论文介绍了两个多模式脚本学习任务，并提供了对应的输入和输出要求。 |
| [^60] | [LLMCarbon: Modeling the end-to-end Carbon Footprint of Large Language Models.](http://arxiv.org/abs/2309.14393) | 本研究提出了LLMCarbon，一个针对密集型和MoE LLMs设计的端到端碳足迹预测模型，解决了现有工具的限制，并显著提升了估计的准确性。 |
| [^61] | [Exploring Self-Reinforcement for Improving Learnersourced Multiple-Choice Question Explanations with Large Language Models.](http://arxiv.org/abs/2309.10444) | 本文提出了一个自我强化大型语言模型框架，自动生成和评估学生生成的解释，用于改进学生资源共享中学生生成的多项选择题的解释质量。 |
| [^62] | [How Transferable are Attribute Controllers on Pretrained Multilingual Translation Models?.](http://arxiv.org/abs/2309.08565) | 本文研究了如何将预训练的多语言翻译模型中的属性控制器迁移到没有监督数据的语言。通过全面分析不同数据场景下的训练和推断时控制技术，揭示了它们在零样本性能和领域鲁棒性上的相对优势和劣势。 |
| [^63] | [Large Language Models for Information Retrieval: A Survey.](http://arxiv.org/abs/2308.07107) | 本综述将大型语言模型（LLMs）在信息检索中的发展进行了综述，探讨了其在捕捉上下文信号和语义细微之处方面的优势和挑战，以及与传统检索方法的结合的重要性。 |
| [^64] | [UniversalNER: Targeted Distillation from Large Language Models for Open Named Entity Recognition.](http://arxiv.org/abs/2308.03279) | 本文提出了一种从大型语言模型中进行目标蒸馏的方法，用于训练能够在开放式命名实体识别中表现出色的学生模型。通过使用指导调整和面向任务的方法，将ChatGPT蒸馏成更小的UniversalNER模型。实验结果表明，UniversalNER在各种领域的命名实体识别任务上取得了卓越的准确性，超过了原始的大型语言模型。 |
| [^65] | [Scaling TransNormer to 175 Billion Parameters.](http://arxiv.org/abs/2307.14995) | 本论文提出了TransNormerLLM，这是第一个基于线性注意力的大型语言模型，在准确性和效率方面优于传统基于softmax注意力的模型。通过引入位置嵌入、线性注意力加速、门控机制等先进改进，并利用Lightning Attention技术加速线性注意力，以及采用张量归一化方案加速模型，提高了TransNormer的性能。 |
| [^66] | [Generative User-Experience Research for Developing Domain-specific Natural Language Processing Applications.](http://arxiv.org/abs/2306.16143) | 本论文提出了一种在开发领域特定自然语言处理应用中整合生成式用户体验研究的方法。该方法将领域用户纳入原型开发的不同阶段，以更好地了解用户需求和评估用户价值的变化。 |
| [^67] | [Measuring the Robustness of Natural Language Processing Models to Domain Shifts.](http://arxiv.org/abs/2306.00168) | 本文探讨了自然领域转移设置下微调和小样本学习模型的DR挑战，引入了一个DR基准，提出了DR挑战的两个视角：源域降低（SD）和目标域降低（TD），并发现两者之一通常是正值，强调了评估DR挑战的两个视角的重要性。 |
| [^68] | [MCWDST: a Minimum-Cost Weighted Directed Spanning Tree Algorithm for Real-Time Fake News Mitigation in Social Media.](http://arxiv.org/abs/2302.12190) | 本论文提出了一种用于社交媒体实时虚假新闻缓解的算法，通过使用新的深度学习架构来检测假新闻并采取实时的网络感知策略来减少其传播。 |
| [^69] | [Improving Faithfulness of Abstractive Summarization by Controlling Confounding Effect of Irrelevant Sentences.](http://arxiv.org/abs/2212.09726) | 通过控制无关句子的混淆效应，本文提出了一种改进抽象摘要准确性的方法，并在AnswerSumm数据集上实现了20\%的准确性提升。 |

# 详细

[^1]: 使用公共社区评分作为人类反馈，在编程领域中使用强化学习进行问答的研究

    Reinforcement learning for question answering in programming domain using public community scoring as a human feedback. (arXiv:2401.10882v1 [cs.CL])

    [http://arxiv.org/abs/2401.10882](http://arxiv.org/abs/2401.10882)

    本研究通过整合强化学习和Stack Overflow评分，提高了GPT Neo在编程问答中的性能，同时指出传统语言度量方法在编程领域的局限性。

    

    本研究通过整合人类反馈的强化学习和来自Stack Overflow的评分，探讨了在编程领域中提高GPT Neo 125M在社区问答中的性能的方法。采用了两种不同的奖励模型训练策略进行微调，通过Proximal Policy Optimization (PPO)实现。这种方法在性能改进方面与GPT Neo 2.7B参数变体相当。此外，还引入了辅助评分机制，显示了传统语言度量在编程领域中评估响应的局限性。通过准确的分析，本文研究了将强化学习从人类反馈应用于编程社区问答的复杂性，并强调了需要领域特定的评估方法的必要性。

    In this study, we investigate the enhancement of the GPT Neo 125M performance in Community Question Answering (CQA) with a focus on programming, through the integration of Reinforcement Learning from Human Feedback (RLHF) and the utilization of scores from Stack Overflow. Two distinct reward model training strategies are employed for fine-tuning with Proximal Policy Optimization (PPO). Notably, the improvements in performance achieved through this method are comparable to those of GPT Neo 2.7B parameter variant. Additionally, an auxiliary scoring mechanism is introduced, which demonstrates the limitations of conventional linguistic metrics in evaluating responses in the programming domain. Through accurate analysis, this paper looks at the divergence between traditional linguistic metrics and our human-preferences-based reward model, underscoring the imperative for domain-specific evaluation methods. By elucidating the complexities involved in applying RLHF to programming CQA and accen
    
[^2]: 基于剪枝的保护: 在不进行微调的情况下增加对齐的LLMs的越狱抵抗力

    Pruning for Protection: Increasing Jailbreak Resistance in Aligned LLMs Without Fine-Tuning. (arXiv:2401.10862v1 [cs.LG])

    [http://arxiv.org/abs/2401.10862](http://arxiv.org/abs/2401.10862)

    本文研究了剪枝对齐的LLMs的保护措施，发现剪枝LLM参数可以显著增强其抵抗“越狱”提示攻击的能力，并且对其他LLM行为也可能有更普遍的效果。同时，引入了一个有害任务数据集，证明剪枝有助于集中注意力在与任务相关的标记上。突出的聊天模型表现出很高的易感性。

    

    大型语言模型（LLMs）容易受到“越狱”提示的攻击，这种攻击可以诱使这些模型生成有害和违法内容。本文表明，剪枝LLM参数多达20％可以显著增加它们对此类攻击的抵抗力，而无需额外训练并且不损害其在标准基准测试中的性能。有趣的是，我们发现剪枝后观察到的增强安全性与模型的初始安全训练水平相关，这暗示剪枝的效果可能更普遍，也可能适用于超出安全性范畴的其他LLM行为。另外，我们还介绍了一个包含五个类别、插入到十个不同越狱提示中的225个有害任务的精选数据集，表明剪枝有助于LLMs集中注意力在越狱提示中与任务相关的标记上。最后，我们的实验揭示了突出的聊天模型（如LLaMA-2 Chat，Vicuna和Mistral Instruct）具有很高的易感性。

    Large Language Models (LLMs) are vulnerable to `Jailbreaking' prompts, a type of attack that can coax these models into generating harmful and illegal content. In this paper, we show that pruning up to 20% of LLM parameters markedly increases their resistance to such attacks without additional training and without sacrificing their performance in standard benchmarks. Intriguingly, we discovered that the enhanced safety observed post-pruning correlates to the initial safety training level of the model, hinting that the effect of pruning could be more general and may hold for other LLM behaviors beyond safety. Additionally, we introduce a curated dataset of 225 harmful tasks across five categories, inserted into ten different Jailbreaking prompts, showing that pruning aids LLMs in concentrating attention on task-relevant tokens in jailbreaking prompts. Lastly, our experiments reveal that the prominent chat models, such as LLaMA-2 Chat, Vicuna, and Mistral Instruct exhibit high susceptibi
    
[^3]: 通过自然语言处理和深度学习在eHealth数据分析中的进展

    Advancements in eHealth Data Analytics through Natural Language Processing and Deep Learning. (arXiv:2401.10850v1 [cs.CL])

    [http://arxiv.org/abs/2401.10850](http://arxiv.org/abs/2401.10850)

    通过自然语言处理和深度学习在eHealth数据分析中的进展，可以有效处理和解释医疗领域的大量文本数据，从而提高医疗服务和整个医疗领域的效率和知识水平。

    

    医疗环境通常被称为“信息丰富”但也“知识匮乏”。医疗系统从各种来源收集大量数据，包括实验室报告、医疗信函、医疗工具或程序的日志、医疗处方等。这些庞大的数据集可以提供有关医疗服务和整个医疗领域的宝贵知识和信息，例如通过分析患者症状进行疾病预测或通过发现疾病的行为因素进行疾病预防。不幸的是，只有相对较少的文本eHealth数据被处理和解释，其中一个重要因素是在执行大数据操作时的困难。在医疗领域，检测特定领域的多词术语是一项关键任务，因为它们可以用几个词来定义一个整个概念。术语可以定义为一个语言结构或概念，它由一个或多个词组成。

    The healthcare environment is commonly referred to as "information-rich" but also "knowledge poor". Healthcare systems collect huge amounts of data from various sources: lab reports, medical letters, logs of medical tools or programs, medical prescriptions, etc. These massive sets of data can provide great knowledge and information that can improve the medical services, and overall the healthcare domain, such as disease prediction by analyzing the patient's symptoms or disease prevention, by facilitating the discovery of behavioral factors for diseases. Unfortunately, only a relatively small volume of the textual eHealth data is processed and interpreted, an important factor being the difficulty in efficiently performing Big Data operations. In the medical field, detecting domain-specific multi-word terms is a crucial task as they can define an entire concept with a few words. A term can be defined as a linguistic structure or a concept, and it is composed of one or more words with a s
    
[^4]: 使用LLMs发现极端社交媒体中的编码反犹太恶意言论的出现

    Using LLMs to discover emerging coded antisemitic hate-speech emergence in extremist social media. (arXiv:2401.10841v1 [cs.CL])

    [http://arxiv.org/abs/2401.10841](http://arxiv.org/abs/2401.10841)

    这项研究提出了一种方法，可以检测新出现的编码恶意术语，为极端社交媒体中的反犹太恶意言论提供了解决方案。

    

    网络仇恨言论的蔓延给社交媒体平台带来了一个难题。一个特殊的挑战与使用编码语言的群体有关，这些群体既想为其用户创造归属感，又想回避检测。编码语言发展迅速，并且随着时间的推移使用方式不同。本文提出了一种检测新出现的编码恶意术语的方法论。该方法在在线反犹太言论的环境中进行了测试。该方法考虑了从社交媒体平台上抓取的帖子，通常是极端主义用户使用的。帖子是使用与以前已知的针对犹太人的仇恨言论相关的种子表达式进行抓取的。该方法首先通过识别每个帖子最具代表性的表达式，并计算它们在整个语料库中的频率。过滤掉语法不一致的表达式和之前遇到过的表达式，以便关注新出现的良好形式的术语。然后进行了语义评估。

    Online hate speech proliferation has created a difficult problem for social media platforms. A particular challenge relates to the use of coded language by groups interested in both creating a sense of belonging for its users and evading detection. Coded language evolves quickly and its use varies over time. This paper proposes a methodology for detecting emerging coded hate-laden terminology. The methodology is tested in the context of online antisemitic discourse. The approach considers posts scraped from social media platforms, often used by extremist users. The posts are scraped using seed expressions related to previously known discourse of hatred towards Jews. The method begins by identifying the expressions most representative of each post and calculating their frequency in the whole corpus. It filters out grammatically incoherent expressions as well as previously encountered ones so as to focus on emergent well-formed terminology. This is followed by an assessment of semantic s
    
[^5]: 最新进展的命名实体识别综述

    A survey on recent advances in named entity recognition. (arXiv:2401.10825v1 [cs.CL])

    [http://arxiv.org/abs/2401.10825](http://arxiv.org/abs/2401.10825)

    这篇综述调查了最近的命名实体识别研究进展，并提供了对不同算法性能的深度比较，还探讨了数据集特征对方法行为的影响。

    

    命名实体识别旨在从文本中提取出命名真实世界对象的子字符串，并确定其类型（例如，是否指人物或组织）。在本综述中，我们首先概述了最近流行的方法，同时还关注了基于图和变换器的方法，包括很少在其他综述中涉及的大型语言模型（LLMs）。其次，我们重点介绍了针对稀缺注释数据集设计的方法。第三，我们评估了主要命名实体识别实现在各种具有不同特征（领域、规模和类别数）的数据集上的性能。因此，我们提供了一种从未同时考虑的算法的深度比较。我们的实验揭示了数据集特征如何影响我们比较的方法的行为。

    Named Entity Recognition seeks to extract substrings within a text that name real-world objects and to determine their type (for example, whether they refer to persons or organizations). In this survey, we first present an overview of recent popular approaches, but we also look at graph- and transformer- based methods including Large Language Models (LLMs) that have not had much coverage in other surveys. Second, we focus on methods designed for datasets with scarce annotations. Third, we evaluate the performance of the main NER implementations on a variety of datasets with differing characteristics (as regards their domain, their size, and their number of classes). We thus provide a deep comparison of algorithms that are never considered together. Our experiments shed some light on how the characteristics of datasets affect the behavior of the methods that we compare.
    
[^6]: Medusa: 多解码头的简洁LLM推理加速框架

    Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads. (arXiv:2401.10774v1 [cs.LG])

    [http://arxiv.org/abs/2401.10774](http://arxiv.org/abs/2401.10774)

    Medusa是一个能够提升LLM推理性能的简洁框架，通过增加多个解码头以实现并行预测多个后续标记，并通过树状注意力机制和并行处理来减少解码步骤。

    

    大型语言模型（LLMs）中的推理过程通常受限于自回归解码过程中的并行性缺失，使得大多数操作受限于加速器的内存带宽。虽然已经提出了类似于推测解码的方法来解决这个问题，但由于获得和维护独立的草稿模型所涉及的挑战，它们的实施受到了阻碍。在本文中，我们提出了一种高效的方法，通过添加额外的解码头来增强LLM推理，以并行预测多个后续标记。Medusa利用基于树的注意力机制，在每个解码步骤中同时构造多个候选延续并进行验证。通过利用并行处理，Medusa在单步延迟方面仅引入了最小的开销，同时大大降低了所需的解码步骤数。

    The inference process in Large Language Models (LLMs) is often limited due to the absence of parallelism in the auto-regressive decoding process, resulting in most operations being restricted by the memory bandwidth of accelerators. While methods such as speculative decoding have been suggested to address this issue, their implementation is impeded by the challenges associated with acquiring and maintaining a separate draft model. In this paper, we present Medusa, an efficient method that augments LLM inference by adding extra decoding heads to predict multiple subsequent tokens in parallel. Using a tree-based attention mechanism, Medusa constructs multiple candidate continuations and verifies them simultaneously in each decoding step. By leveraging parallel processing, Medusa introduces only minimal overhead in terms of single-step latency while substantially reducing the number of decoding steps required.  We present two levels of fine-tuning procedures for Medusa to meet the needs o
    
[^7]: 缓解大型语言模型的幻觉问题：通过知识一致性对齐

    Mitigating Hallucinations of Large Language Models via Knowledge Consistent Alignment. (arXiv:2401.10768v1 [cs.CL])

    [http://arxiv.org/abs/2401.10768](http://arxiv.org/abs/2401.10768)

    本文提出了一种称为知识一致性对齐（KCA）的方法，通过减少训练数据中外部知识和预训练语料库中内在知识之间的不一致性，从而缓解了大型语言模型产生幻觉的问题。实验结果表明，KCA方法在多个基准测试中取得了优异的性能。

    

    虽然大型语言模型在对齐后在各种任务上表现出色，但它们仍可能产生与上下文或世界知识自信矛盾的响应，这被称为“幻觉”现象。本文展示了通过减少训练数据中的外部知识与预训练语料库中继承的内在知识之间的不一致性，可以缓解对齐中的幻觉问题。具体而言，我们引入了一种新颖的知识一致性对齐（KCA）方法，该方法通过根据外部知识自动制定考试来评估大型语言模型的理解能力。对于包含知识不一致性的数据，KCA实施了几种简单而高效的处理策略。我们通过使用不同背景和规模的大型语言模型在六个基准测试中展示了所提出的KCA方法在缓解幻觉方面的卓越性能。

    While Large Language Models (LLMs) have proven to be exceptional on a variety of tasks after alignment, they may still produce responses that contradict the context or world knowledge confidently, a phenomenon known as ``hallucination''. In this paper, we demonstrate that reducing the inconsistency between the external knowledge encapsulated in the training data and the intrinsic knowledge inherited in the pretraining corpus could mitigate hallucination in alignment. Specifically, we introduce a novel knowledge consistent alignment (KCA) approach, which involves automatically formulating examinations based on external knowledge for accessing the comprehension of LLMs. For data encompassing knowledge inconsistency, KCA implements several simple yet efficient strategies for processing. We illustrate the superior performance of the proposed KCA approach in mitigating hallucinations across six benchmarks using LLMs of different backbones and scales. Furthermore, we confirm the correlation 
    
[^8]: 缺失模态下的多模态情感分析:一种知识迁移方法

    Multimodal Sentiment Analysis with Missing Modality: A Knowledge-Transfer Approach. (arXiv:2401.10747v1 [cs.SD])

    [http://arxiv.org/abs/2401.10747](http://arxiv.org/abs/2401.10747)

    本文提出了一种知识迁移方法，用于在缺失模态下进行多模态情感分析。通过翻译不同模态之间的内容以重构缺失的音频模态，并利用跨模态注意机制进行情感预测，实验证明了该方法在多个数据集上表现出显著的改进和与完整多模态监督方法相媲美的效果。

    

    多模态情感分析旨在通过视觉、语言和声音线索来识别个体表达的情绪。然而，现有研究大多假设在训练和测试过程中所有模态都是可用的，这使得它们的算法容易受到缺失模态的影响。在本文中，我们提出了一种新颖的知识迁移网络，用于在不同模态之间进行翻译，以重构缺失的音频模态。此外，我们还开发了一种跨模态注意机制，以保留重构和观察到的模态的最大信息，用于情感预测。在三个公开数据集上进行的大量实验证明了相对于基线算法的显著改进，并实现了与具有完整多模态监督的先前方法相媲美的结果。

    Multimodal sentiment analysis aims to identify the emotions expressed by individuals through visual, language, and acoustic cues. However, most of the existing research efforts assume that all modalities are available during both training and testing, making their algorithms susceptible to the missing modality scenario. In this paper, we propose a novel knowledge-transfer network to translate between different modalities to reconstruct the missing audio modalities. Moreover, we develop a cross-modality attention mechanism to retain the maximal information of the reconstructed and observed modalities for sentiment prediction. Extensive experiments on three publicly available datasets demonstrate significant improvements over baselines and achieve comparable results to the previous methods with complete multi-modality supervision.
    
[^9]: 结构化代码表示使得代码语言模型的数据效率适应变得可能

    Structured Code Representations Enable Data-Efficient Adaptation of Code Language Models. (arXiv:2401.10716v1 [cs.CL])

    [http://arxiv.org/abs/2401.10716](http://arxiv.org/abs/2401.10716)

    本研究探索了使用结构化的代码表示来提高代码语言模型的数据效率适应性，通过使用解析树进行预训练和微调，即使只对表面形式进行预训练，也能在各种代码任务上取得显著改进。

    

    目前为代码任务定制的语言模型常常采用自然语言处理中的预训练-微调范式，将源代码建模为纯文本。然而，这种方法忽视了编程语言中固有的明确结构。在这项工作中，我们通过进一步预训练和微调，探索了对预训练的代码模型进行数据效率适应的方法，将程序表示为解析树（也称为具体语法树），并在序列化的解析树上进行预训练和微调。尽管我们适应的模型仅在程序的表面形式上进行了预训练，但我们发现在不改变模型架构的情况下，在解析树上进行少量的连续预训练和微调可以在各种代码任务上改进基线方法。当训练样本有限时，这种改进尤为显著，证明了整合程序结构的有效性。

    Current language models tailored for code tasks often adopt the pre-training-then-fine-tuning paradigm from natural language processing, modeling source code as plain text. This approach, however, overlooks the unambiguous structures inherent in programming languages. In this work, we explore data-efficient adaptation of pre-trained code models by further pre-training and fine-tuning them with program structures. Specifically, we represent programs as parse trees -- also known as concrete syntax trees (CSTs) -- and adapt pre-trained models on serialized CSTs. Although the models that we adapt have been pre-trained only on the surface form of programs, we find that a small amount of continual pre-training and fine-tuning on CSTs without changing the model architecture yields improvements over the baseline approach across various code tasks. The improvements are found to be particularly significant when there are limited training examples, demonstrating the effectiveness of integrating p
    
[^10]: Q&A提示：通过挖掘问题-回答提示来发现丰富的视觉线索，以满足对多样世界知识的视觉问答的需求

    Q&A Prompts: Discovering Rich Visual Clues through Mining Question-Answer Prompts for VQA requiring Diverse World Knowledge. (arXiv:2401.10712v1 [cs.CV])

    [http://arxiv.org/abs/2401.10712](http://arxiv.org/abs/2401.10712)

    本论文提出了一种叫做Q&A提示的方法，通过挖掘图像中的问题-回答对来发现丰富的视觉线索，以帮助AI模型更好地理解复杂视觉问题，提高跨模态推理能力。

    

    随着多模态大型语言模型的突破，回答需要高级推理能力和世界知识的复杂视觉问题比以往任何时候都更重要。然而，为AI模型配备强大的跨模态推理能力仍然具有挑战性，因为人类的认知方案尚未系统地被理解。在本文中，我们相信，如果我们能尽可能收集给定图像中的视觉线索，我们将能更准确地识别图像，更好地理解问题，更容易回忆相关知识，并最终推理出答案。我们通过在图像中挖掘问题-回答对来发现这些丰富的视觉线索，并将它们作为提示发送到多模态大型语言模型中。我们称之为Q&A提示的方法。具体而言，我们首先使用训练集中的图像-答案对和相应的问题作为输入和输出来训练一个视觉问题生成模型。

    With the breakthrough of multi-modal large language models, answering complex visual questions that demand advanced reasoning abilities and world knowledge has become a much more important testbed for developing AI models than ever. However, equipping AI models with robust cross-modality reasoning ability remains challenging since the cognition scheme of humans has not been understood systematically. In this paper, we believe that if we can collect visual clues in the given image as much as possible, we will recognize the image more accurately, understand the question better, recall relevant knowledge more easily, and finally reason out the answer. We discover these rich visual clues by mining question-answer pairs in images and sending them into multi-modal large language models as prompts. We call the proposed method Q&A Prompts. Specifically, we first use the image-answer pairs and the corresponding questions in the training set as inputs and outputs to train a visual question gener
    
[^11]: 使用大型多模型的弱监督高斯对比基础模型来处理视频问答问题

    Weakly Supervised Gaussian Contrastive Grounding with Large Multimodal Models for Video Question Answering. (arXiv:2401.10711v1 [cs.CV])

    [http://arxiv.org/abs/2401.10711](http://arxiv.org/abs/2401.10711)

    本论文提出了一种使用大型多模型的弱监督高斯对比基础模型来处理视频问答问题的方法。通过将问题和答案对作为事件描述，找到多个关键帧作为目标时刻，并利用这些时刻作为伪标签来强制LMMs进行推理。所提出的方法使用轻量级的基于高斯的对比基础模块（GCG）来学习时效结构。

    

    视频问答（VideoQA）旨在基于观察到的视频信息回答自然语言问题。尽管大型多模型（LMMs）在图像语言理解和推理方面取得了近期的成功，但它们在处理视频问答方面还不足够，仅仅是将均匀采样的帧作为视觉输入，忽略了与问题相关的视觉线索。此外，现有的视频问答数据集中没有针对问题关键时间戳的人工注释。基于此，我们提出了一种新的弱监督框架，强制LMMs使用问题关键时刻作为视觉输入推理出答案。具体来说，我们将问题和答案对合并为事件描述，以找到多个关键帧作为目标时刻，这些时刻将作为伪标签。通过将这些伪标签作为额外的弱监督，我们设计了一个轻量级的基于高斯的对比基础模块（GCG）。GCG学习多个高斯函数来描述时效结构。

    Video Question Answering (VideoQA) aims to answer natural language questions based on the information observed in videos. Despite the recent success of Large Multimodal Models (LMMs) in image-language understanding and reasoning, they deal with VideoQA insufficiently by simply taking uniformly sampled frames as visual inputs, which ignores question-relevant visual clues. Moreover, there are no human annotations for question-critical timestamps in existing VideoQA datasets. In light of this, we propose a novel weakly supervised framework to enforce the LMMs to reason out the answers with question-critical moments as visual inputs. Specifically, we fuse the question and answer pairs as event descriptions to find multiple keyframes as target moments, which will be pseudo-labels. With these pseudo-labels as additionally weak supervision, we devise a lightweight Gaussian-based Contrastive Grounding (GCG) module. GCG learns multiple Gaussian functions to characterize the temporal structure o
    
[^12]: LangBridge: 无多语言监督的多语言推理方法

    LangBridge: Multilingual Reasoning Without Multilingual Supervision. (arXiv:2401.10695v1 [cs.CL])

    [http://arxiv.org/abs/2401.10695](http://arxiv.org/abs/2401.10695)

    LangBridge是一种无需多语言监督的多语言推理方法，通过连接两个模型来适应多语言推理任务，尽管只使用英文数据进行训练，但它显著提高了语言模型对低资源语言的性能。

    

    我们引入LangBridge，这是一种零监督方式，用于适应多语言推理任务，无需多语言监督。LangBridge通过连接两个模型来运作，每个模型专门处理不同方面：(1)一个专门处理多种语言的模型（例如mT5编码器），和(2)一个专门处理推理的模型（例如Orca 2）。LangBridge通过在两个模型之间引入最少的可训练参数来连接它们。尽管只利用英文数据进行训练，但LangBridge显著提升了语言模型在数学推理、编码和逻辑推理方面对低资源语言的性能。我们的分析表明，LangBridge的有效性源于多语言表示的不受语言限制的特性。我们公开发布了我们的代码和模型。

    We introduce LangBridge, a zero-shot approach to adapt language models for multilingual reasoning tasks without multilingual supervision. LangBridge operates by bridging two models, each specialized in different aspects: (1) one specialized in understanding multiple languages (e.g., mT5 encoder) and (2) one specialized in reasoning (e.g., Orca 2). LangBridge connects the two models by introducing minimal trainable parameters between them. Despite utilizing only English data for training, LangBridge considerably enhances the performance of language models on low-resource languages across mathematical reasoning, coding, and logical reasoning. Our analysis suggests that the efficacy of LangBridge stems from the language-agnostic characteristics of multilingual representations. We publicly release our code and models.
    
[^13]: 一种用于单语文本生成的加速多语言语言模型的简单框架

    A Simple Framework to Accelerate Multilingual Language Model for Monolingual Text Generation. (arXiv:2401.10660v1 [cs.CL])

    [http://arxiv.org/abs/2401.10660](http://arxiv.org/abs/2401.10660)

    这项研究介绍了一种新颖的框架，旨在加速非英语语言的文本生成。通过预测更大的语言单元并针对目标语言进行调整，该框架降低了解码步骤的数量，并将生成速度提高了1.9倍。

    

    最近大型语言模型的进展不仅在英语而且在非英语语言中都促进了复杂的语言任务的执行。然而，大多数语言模型的标记器（如Llama）在以英语为中心的语料库上训练，倾向于在非英语语言中过分分割标记。这个问题在非罗马字母语言中尤为明显，这些语言通常在字符或Unicode级别上被划分，导致文本生成速度较慢。为了解决这个问题，我们的研究介绍了一个新颖的框架，旨在加速这些语言的文本生成。该框架预测比传统的多语言标记器更大的语言单元，并且专门针对目标语言进行了调整，从而减少了解码所需的步骤数。我们的实证结果表明，与标准解码相比，所提出的框架将生成速度提高了1.9倍，同时保持了预先训练模型的性能。

    Recent advancements in large language models have facilitated the execution of complex language tasks, not only in English but also in non-English languages. However, the tokenizers of most language models, such as Llama, trained on English-centric corpora, tend to excessively fragment tokens in non-English languages. This issue is especially pronounced in non-roman alphabetic languages, which are often divided at a character or even Unicode level, leading to slower text generation. To address this, our study introduces a novel framework designed to expedite text generation in these languages. This framework predicts larger linguistic units than those of conventional multilingual tokenizers and is specifically tailored to the target language, thereby reducing the number of decoding steps required. Our empirical results demonstrate that the proposed framework increases the generation speed by a factor of 1.9 compared to standard decoding while maintaining the performance of a pre-traine
    
[^14]: 基于Transformer的多模态仇恨言论检测方法：关注融合

    Attentive Fusion: A Transformer-based Approach to Multimodal Hate Speech Detection. (arXiv:2401.10653v1 [cs.CL])

    [http://arxiv.org/abs/2401.10653](http://arxiv.org/abs/2401.10653)

    这项研究基于Transformer框架和"关注融合"层，采用多模态方法识别仇恨言论，突破了传统的文本分析限制。

    

    随着社交媒体使用量的激增和指数增长，审查社交媒体内容中是否存在任何仇恨内容变得非常重要。研究者们自过去十年以来一直致力于区分宣传仇恨和非宣传仇恨的内容。传统上，主要关注的是对文本内容的分析。然而，最近的研究也开始涉及对基于音频的内容的识别。然而，研究表明仅仅依赖音频或基于文本的内容可能是无效的，因为近期的激增表明个体在言辞和写作中经常使用讽刺。为了克服这些挑战，我们提出了一种基于Transformer框架的方法，利用音频和文本表示来判断一段言辞是否宣传了仇恨，同时引入了我们自己的层称为"关注融合"。

    With the recent surge and exponential growth of social media usage, scrutinizing social media content for the presence of any hateful content is of utmost importance. Researchers have been diligently working since the past decade on distinguishing between content that promotes hatred and content that does not. Traditionally, the main focus has been on analyzing textual content. However, recent research attempts have also commenced into the identification of audio-based content. Nevertheless, studies have shown that relying solely on audio or text-based content may be ineffective, as recent upsurge indicates that individuals often employ sarcasm in their speech and writing. To overcome these challenges, we present an approach to identify whether a speech promotes hate or not utilizing both audio and textual representations. Our methodology is based on the Transformer framework that incorporates both audio and text sampling, accompanied by our very own layer called "Attentive Fusion". Th
    
[^15]: 播风撩起风暴：编辑语言模型的影响

    Sowing the Wind, Reaping the Whirlwind: The Impact of Editing Language Models. (arXiv:2401.10647v1 [cs.CL])

    [http://arxiv.org/abs/2401.10647](http://arxiv.org/abs/2401.10647)

    本文研究了通过编辑语言模型的复杂后果，发现在增强模型准确性与保持道德完整性之间存在悖论。我们发现，尽管注入准确信息对模型的可靠性很重要，但它可能破坏模型的基本框架，导致不可预测和潜在的不安全行为。

    

    在人工智能领域中，红队测试或越狱大型语言模型（LLM）的概念已成为一个重要的研究领域。通过对模型进行编辑，揭示了这种修改的复杂后果，发现了增强模型准确性与保持其道德完整性之间的复杂关系。我们的深入分析揭示了一个令人惊讶的悖论：虽然注入准确信息对于模型的可靠性至关重要，但它却可能破坏模型的基本框架，导致不可预测和潜在的不安全行为。此外，我们提出了一个基准数据集NicheHazardQA，用于研究模型在相同和跨领域中的不安全行为。这一方面的研究揭示了编辑如何影响模型的安全度量和保护机制。

    In the rapidly advancing field of artificial intelligence, the concept of Red-Teaming or Jailbreaking large language models (LLMs) has emerged as a crucial area of study. This approach is especially significant in terms of assessing and enhancing the safety and robustness of these models. This paper investigates the intricate consequences of such modifications through model editing, uncovering a complex relationship between enhancing model accuracy and preserving its ethical integrity. Our in-depth analysis reveals a striking paradox: while injecting accurate information is crucial for model reliability, it can paradoxically destabilize the model's foundational framework, resulting in unpredictable and potentially unsafe behaviors. Additionally, we propose a benchmark dataset NicheHazardQA to investigate this unsafe behavior both within the same and cross topical domain. This aspect of our research sheds light on how the edits, impact the model's safety metrics and guardrails. Our find
    
[^16]: PHOENIX: 开源语言适应，用于直接偏好优化

    PHOENIX: Open-Source Language Adaption for Direct Preference Optimization. (arXiv:2401.10580v1 [cs.CL])

    [http://arxiv.org/abs/2401.10580](http://arxiv.org/abs/2401.10580)

    该论文介绍了一种开源的语言适应方法PHOENIX，用于直接优化偏好。研究构建在最新的改进基础上，并将直接偏好优化方法应用于德语。

    

    在最近几年中，大型语言模型变得非常重要，并在解决各种任务中展示出卓越的结果。然而，尽管取得了这些成就，但在大型语言模型的上下文中还有许多问题尚未解答。除了在推理中最佳使用模型和将结果与期望规范对齐之外，将模型转移到其他语言仍然是一个尚未开发完善的研究领域。最近发布的Llama-2和Zephyr等模型提供了关于架构改进和使用人类反馈的新见解。然而，关于如何将这些技术适配到其他语言的洞见仍然很少。在本文中，我们基于最新的改进，将直接偏好优化(DPO)方法应用到德语中。该模型可在https://huggingface.co/DRXD1000/Phoenix找到。

    Large language models have gained immense importance in recent years and have demonstrated outstanding results in solving various tasks. However, despite these achievements, many questions remain unanswered in the context of large language models. Besides the optimal use of the models for inference and the alignment of the results to the desired specifications, the transfer of models to other languages is still an underdeveloped area of research. The recent publication of models such as Llama-2 and Zephyr has provided new insights into architectural improvements and the use of human feedback. However, insights into adapting these techniques to other languages remain scarce. In this paper, we build on latest improvements and apply the Direct Preference Optimization(DPO) approach to the German language. The model is available at https://huggingface.co/DRXD1000/Phoenix.
    
[^17]: 数据到文本生成中的自我记忆自我训练模型

    Self-training from Self-memory in Data-to-text Generation. (arXiv:2401.10567v1 [cs.CL])

    [http://arxiv.org/abs/2401.10567](http://arxiv.org/abs/2401.10567)

    本文提出了一种在数据到文本生成中的自我记忆自我训练（STSM）模型，通过利用自我记忆作为训练子集，并使用预定义条件验证其质量。实验证明，这种方法可以以较高的性能进行训练，并在两个数据集上进行了实验。

    

    本文介绍了一种新颖的自我记忆自我训练模型（STSM）在数据到文本生成中的应用，使得模型可以在子集上进行自我训练，其中包括从训练模型和/或新数据中直接推断出的自我记忆。通过两个预定义条件来验证自我记忆的质量：（1）D2T模型的输出中包含所有源数值，（2）T2D模型的输出能够转换回源数据。如果D2T的输出包含所有源数值，我们使用贪婪算法生成较短的输出。随后，我们使用T2D模型来确认这些输出能够捕捉输入关系，通过演示它们将文本转换回数据的能力。在30%的数据集上，我们的D2T模型可以在相同的设置中以与完全训练相竞争的性能进行训练。我们在两个数据集（E2E NLG和DART）上对我们的模型进行了实验。

    This paper introduces a novel training model, self-training from self-memory (STSM) in data-to-text generation (DTG), allowing the model to self-train on subsets, including self-memory as outputs inferred directly from the trained models and/or the new data. The quality of self-memory is validated by two models, data-to-text (D2T) and text-to-data (T2D), by two pre-defined conditions: (1) the appearance of all source values in the outputs of the D2T model and (2) the ability to convert back to source data in the outputs in the T2D model. We utilize a greedy algorithm to generate shorter D2T outputs if they contain all source values. Subsequently, we use the T2D model to confirm that these outputs can capture input relationships by demonstrating their capacity to convert text back into data. With 30% of the dataset, we can train the D2T model with a competitive performance compared to full training in the same setup. We experiment with our model on two datasets, E2E NLG and DART. STSM o
    
[^18]: OrchMoE：具有任务-技能协同效应的高效多适配器学习

    OrchMoE: Efficient Multi-Adapter Learning with Task-Skill Synergy. (arXiv:2401.10559v1 [cs.LG])

    [http://arxiv.org/abs/2401.10559](http://arxiv.org/abs/2401.10559)

    OrchMoE通过利用模块化技能架构和自动任务识别，提升了参数效率微调领域的性能，实现了对多任务学习的重大进展。

    

    我们通过创新的多适配器方法OrchMoE推进了参数效率微调（PEFT）领域，利用模块化技能架构增强神经网络的前向传递。与依赖显式任务识别输入的先前模型不同，OrchMoE自动识别任务类别，简化学习过程。这是通过一个整合机制实现的，包括自动任务分类模块和任务-技能分配模块，共同推断任务特定的分类并调整技能分配矩阵。我们在“超自然指令”数据集上进行了广泛的评估，该数据集包含1,600个多样的指令任务，结果表明OrchMoE在性能和样本利用效率方面明显优于可比的多适配器基线，并且在相同参数限制下运行。这些发现表明，OrchMoE在多任务学习方面取得了重大进展。

    We advance the field of Parameter-Efficient Fine-Tuning (PEFT) with our novel multi-adapter method, OrchMoE, which capitalizes on modular skill architecture for enhanced forward transfer in neural networks. Unlike prior models that depend on explicit task identification inputs, OrchMoE automatically discerns task categories, streamlining the learning process. This is achieved through an integrated mechanism comprising an Automatic Task Classification module and a Task-Skill Allocation module, which collectively deduce task-specific classifications and tailor skill allocation matrices. Our extensive evaluations on the 'Super Natural Instructions' dataset, featuring 1,600 diverse instructional tasks, indicate that OrchMoE substantially outperforms comparable multi-adapter baselines in terms of both performance and sample utilization efficiency, all while operating within the same parameter constraints. These findings suggest that OrchMoE offers a significant leap forward in multi-task le
    
[^19]: 零资源语言的多语言声学词嵌入

    Multilingual acoustic word embeddings for zero-resource languages. (arXiv:2401.10543v1 [eess.AS])

    [http://arxiv.org/abs/2401.10543](http://arxiv.org/abs/2401.10543)

    该研究发展了一种多语言声学词嵌入方法，用于解决缺乏标注数据的零资源语言的挑战。通过使用神经网络和多语言转移，该方法在零资源语言上取得了比现有模型更好的性能。研究还展示了该方法在仇恨言论检测和语义查询中的应用潜力。

    

    该研究解决了在缺乏标注数据的零资源语言中开发语音应用的挑战。具体而言，它使用声学词嵌入（AWE）-将可变时长的语音片段转换为固定维度的表示-并使用多语言转移，在多个资源丰富的语言的标注数据上进行训练。该研究引入了一种新的神经网络，在零资源语言上表现优于现有的AWE模型。研究还探讨了资源丰富语言的选择对结果的影响。AWE应用于斯瓦希里语广播中的仇恨言论检测的关键词识别系统中，展示了在实际场景中的鲁棒性。此外，新颖的语义AWE模型改进了语义查询示例搜索。

    This research addresses the challenge of developing speech applications for zero-resource languages that lack labelled data. It specifically uses acoustic word embedding (AWE) -- fixed-dimensional representations of variable-duration speech segments -- employing multilingual transfer, where labelled data from several well-resourced languages are used for pertaining. The study introduces a new neural network that outperforms existing AWE models on zero-resource languages. It explores the impact of the choice of well-resourced languages. AWEs are applied to a keyword-spotting system for hate speech detection in Swahili radio broadcasts, demonstrating robustness in real-world scenarios. Additionally, novel semantic AWE models improve semantic query-by-example search.
    
[^20]: Speech Swin-Transformer: 探索具有平移窗口的层次转换器在语音情感识别中的应用

    Speech Swin-Transformer: Exploring a Hierarchical Transformer with Shifted Windows for Speech Emotion Recognition. (arXiv:2401.10536v1 [cs.CL])

    [http://arxiv.org/abs/2401.10536](http://arxiv.org/abs/2401.10536)

    Speech Swin-Transformer是一种层次化的语音Transformer，利用平移窗口聚合多尺度情感特征，用于语音情感识别。该方法通过分割语音频谱图为段级补丁，利用本地窗口Transformer和平移窗口Transformer探索补丁内部的情感信息，并取得了显著的成功。

    

    Swin-Transformer在计算机视觉领域取得了显著的成功，利用其基于Transformer的层次化特征表示。在语音信号中，情感信息在不同尺度的语音特征上分布，例如词语、短语和话语。在此启发下，本文提出了一种利用平移窗口对多尺度情感特征进行聚合的层次化语音Transformer，用于语音情感识别（SER），称为Speech Swin-Transformer。具体而言，我们首先将语音频谱图在时域分割为段级补丁，由多个帧补丁组成。然后，使用一系列Swin块对这些段级补丁进行编码，其中利用本地窗口Transformer来探索每个段级补丁中帧补丁之间的本地帧间情感信息。之后，我们还设计了一个平移窗口Transformer，以补偿靠近段级补丁边界的补丁相关性。最后，我们通过实验证明了Speech Swin-Transformer在语音情感识别中的有效性。

    Swin-Transformer has demonstrated remarkable success in computer vision by leveraging its hierarchical feature representation based on Transformer. In speech signals, emotional information is distributed across different scales of speech features, e.\,g., word, phrase, and utterance. Drawing above inspiration, this paper presents a hierarchical speech Transformer with shifted windows to aggregate multi-scale emotion features for speech emotion recognition (SER), called Speech Swin-Transformer. Specifically, we first divide the speech spectrogram into segment-level patches in the time domain, composed of multiple frame patches. These segment-level patches are then encoded using a stack of Swin blocks, in which a local window Transformer is utilized to explore local inter-frame emotional information across frame patches of each segment patch. After that, we also design a shifted window Transformer to compensate for patch correlations near the boundaries of segment patches. Finally, we em
    
[^21]: 自然语言处理中的“殖民冲动”: 孟加拉情感分析工具及其基于身份的偏见的审查

    The "Colonial Impulse" of Natural Language Processing: An Audit of Bengali Sentiment Analysis Tools and Their Identity-based Biases. (arXiv:2401.10535v1 [cs.CL])

    [http://arxiv.org/abs/2401.10535](http://arxiv.org/abs/2401.10535)

    本研究审查了在孟加拉社群中经历殖民主义影响的情感分析工具，发现它们可能存在基于身份的偏见，并提出了警示。

    

    尽管殖民主义在社会历史上对人们的身份产生了各种影响，但这些殖民的价值观和偏见仍通过社会技术系统得到了延续。一类社会技术系统，情感分析工具，也可能延续殖民的价值观和偏见，然而，对这些工具可能如何与殖民主义的延续相关联的关注却较少，尽管它们经常被用来指导各种实践（例如，内容管理）。在本文中，我们探讨了在经历和继续经历殖民主义影响的孟加拉社群背景下，情感分析工具可能存在的偏见。我们根据当地孟加拉社群中受殖民主义影响最大的身份类别，重点关注了性别、宗教和国籍。我们对在Python包索引(PyPI)和GitHub上提供的所有孟加拉情感分析工具进行了算法审查。尽管语义内容相似，但我们发现这些工具在处理与孟加拉社群有关的情感时存在偏见。

    While colonization has sociohistorically impacted people's identities across various dimensions, those colonial values and biases continue to be perpetuated by sociotechnical systems. One category of sociotechnical systems--sentiment analysis tools--can also perpetuate colonial values and bias, yet less attention has been paid to how such tools may be complicit in perpetuating coloniality, although they are often used to guide various practices (e.g., content moderation). In this paper, we explore potential bias in sentiment analysis tools in the context of Bengali communities that have experienced and continue to experience the impacts of colonialism. Drawing on identity categories most impacted by colonialism amongst local Bengali communities, we focused our analytic attention on gender, religion, and nationality. We conducted an algorithmic audit of all sentiment analysis tools for Bengali, available on the Python package index (PyPI) and GitHub. Despite similar semantic content and
    
[^22]: Mementos: 一种针对图像序列的多模态大型语言模型推理的综合基准测试

    Mementos: A Comprehensive Benchmark for Multimodal Large Language Model Reasoning over Image Sequences. (arXiv:2401.10529v1 [cs.CV])

    [http://arxiv.org/abs/2401.10529](http://arxiv.org/abs/2401.10529)

    Mementos是一个新的基准测试，旨在评估多模态大型语言模型在图像序列推理中的能力。研究发现，现有的MLLM在准确描述图像序列的动态信息方面存在困难，容易导致物体及其行为的错误描述或错觉。

    

    多模态大型语言模型（MLLMs）在处理各种视觉语言任务方面展示了高超的能力。然而，目前的MLLM基准测试主要用于评估基于单个图像的静态信息的推理能力，而现代MLLM在从图像序列中进行推断的能力，在理解不断变化的世界方面的重要性却被较少研究。为了解决这一挑战，本文引入了一个新的基准测试Mementos，用于评估MLLM的序列图像推理能力。Mementos包括4761个具有不同长度的多样的图像序列。我们还采用了GPT-4辅助方法来评估MLLM的推理性能。通过对Mementos中包括GPT-4V和Gemini在内的九个最新MLLM进行仔细评估，我们发现它们在准确描述所给图像序列的动态信息方面存在困难，往往导致对象及其对应行为的错误描述或错觉。

    Multimodal Large Language Models (MLLMs) have demonstrated proficiency in handling a variety of visual-language tasks. However, current MLLM benchmarks are predominantly designed to evaluate reasoning based on static information about a single image, and the ability of modern MLLMs to extrapolate from image sequences, which is essential for understanding our ever-changing world, has been less investigated. To address this challenge, this paper introduces Mementos, a new benchmark designed to assess MLLMs' sequential image reasoning abilities. Mementos features 4,761 diverse image sequences with varying lengths. We also employ a GPT-4 assisted method to evaluate MLLM reasoning performance. Through a careful evaluation of nine recent MLLMs on Mementos, including GPT-4V and Gemini, we find that they struggle to accurately describe dynamic information about given image sequences, often leading to hallucinations/misrepresentations of objects and their corresponding behaviors. Our quantitati
    
[^23]: 多语言语言模型中的跨语言编辑

    Cross-lingual Editing in Multilingual Language Models. (arXiv:2401.10521v1 [cs.CL])

    [http://arxiv.org/abs/2401.10521](http://arxiv.org/abs/2401.10521)

    本论文介绍了跨语言模型编辑（XME）范式，通过在一种语言中编辑事实并观察其对其他语言的更新传播，研究了多语言语言模型中的模型编辑技术（MET）的性能限制。

    

    大规模语言模型（LLM）的训练需要大量的数据和计算资源，而更新过时的LLM需要大量的工作和资源。虽然出现了许多模型编辑技术（MET）以便在不重新训练的情况下高效更新模型输出，但在多语言LLM中，其中的知识以多种语言存储，这仍然是一个未深入研究的领域。本研究介绍了跨语言模型编辑（XME）范式，在该范式中，一个事实在一种语言中被编辑，观察其在其他语言中的更新传播。为了研究XME范式，我们使用BLOOM、mBERT和XLM-RoBERTa进行了实验，使用了两种写作脚本，即拉丁语（英语、法语和西班牙语）和印地语（印地语、古吉拉特语和孟加拉语）。结果显示，在XME设置下，当前最先进的MET存在明显的性能限制，特别是当涉及的语言属于两个不同的语族时。

    The training of large language models (LLMs) necessitates substantial data and computational resources, and updating outdated LLMs entails significant efforts and resources. While numerous model editing techniques (METs) have emerged to efficiently update model outputs without retraining, their effectiveness in multilingual LLMs, where knowledge is stored in diverse languages, remains an underexplored research area. This research paper introduces the cross-lingual model editing (\textbf{XME}) paradigm, wherein a fact is edited in one language, and the subsequent update propagation is observed across other languages. To investigate the XME paradigm, we conducted experiments using BLOOM, mBERT, and XLM-RoBERTa using the two writing scripts: \textit{Latin} (English, French, and Spanish) and \textit{Indic} (Hindi, Gujarati, and Bengali). The results reveal notable performance limitations of state-of-the-art METs under the XME setting, mainly when the languages involved belong to two distin
    
[^24]: 天作之合：大型语言模型与进化算法的结合

    A match made in consistency heaven: when large language models meet evolutionary algorithms. (arXiv:2401.10510v1 [cs.NE])

    [http://arxiv.org/abs/2401.10510](http://arxiv.org/abs/2401.10510)

    大型语言模型和进化算法的结合具有强大的一致性，包括标记嵌入和基因型-表现型映射、位置编码和适应性塑造、位置嵌入和选择、注意力和交叉、前馈神经网络和突变、模型训练和参数更新以及多任务学习和多目标优化等多个核心特征。本文分析了现有的耦合研究，并为未来的研究提供了基本路线和关键挑战。

    

    预训练的大型语言模型（LLMs）在生成创造性的自然文本方面具有强大的能力。进化算法（EAs）可以发现复杂实际问题的多样解决方案。本文通过比较文本序列生成和进化的共同特点和方向性，阐述了LLMs与EAs之间的强大一致性，包括多个一对一的核心特征：标记嵌入和基因型-表现型映射、位置编码和适应性塑造、位置嵌入和选择、注意力和交叉、前馈神经网络和突变、模型训练和参数更新以及多任务学习和多目标优化。在这种一致性视角下，分析了现有的耦合研究，包括进化微调和LLM增强型EAs。借助这些洞见，我们概述了未来在LLMs和EAs耦合方面的基本研究路线，并突出了其中的关键挑战。

    Pre-trained large language models (LLMs) have powerful capabilities for generating creative natural text. Evolutionary algorithms (EAs) can discover diverse solutions to complex real-world problems. Motivated by the common collective and directionality of text sequence generation and evolution, this paper illustrates the strong consistency of LLMs and EAs, which includes multiple one-to-one key characteristics: token embedding and genotype-phenotype mapping, position encoding and fitness shaping, position embedding and selection, attention and crossover, feed-forward neural network and mutation, model training and parameter update, and multi-task learning and multi-objective optimization. Based on this consistency perspective, existing coupling studies are analyzed, including evolutionary fine-tuning and LLM-enhanced EAs. Leveraging these insights, we outline a fundamental roadmap for future research in coupling LLMs and EAs, while highlighting key challenges along the way. The consist
    
[^25]: FinSQL：面向金融分析的基于模型无关的基于LLMs的文本到SQL框架

    FinSQL: Model-Agnostic LLMs-based Text-to-SQL Framework for Financial Analysis. (arXiv:2401.10506v1 [cs.CL])

    [http://arxiv.org/abs/2401.10506](http://arxiv.org/abs/2401.10506)

    本论文提出了一种面向金融分析的基于LLMs的模型无关的文本到SQL框架FinSQL，同时还提供了一个实用的金融分析文本到SQL基准数据集BULL，从提示构造和参数化的角度为金融文本到SQL提供了系统化的处理。

    

    这项研究关注的是文本到SQL的领域，该领域为操作关系数据库提供了无代码接口，在金融分析中引起了广泛关注；因为金融专业人员可能不擅长SQL编程。然而，迄今为止，还没有为金融分析提供实用的文本到SQL基准数据集，并且现有的文本到SQL方法没有考虑到金融应用中数据库的独特特点，如通常存在的宽表。为了解决这些问题，我们收集了一个实用的金融分析文本到SQL基准数据集，并提出了一种基于模型无关的大型语言模型（LLMs）的金融分析文本到SQL框架。这个基准数据集BULL是从恒生科技公司的实际金融分析业务中收集的，包括基金、股票和宏观经济的数据库。除此之外，提出的基于LLMs的文本到SQL框架FinSQL从提示构造和参数化的角度为金融文本到SQL提供了系统化的处理。

    Text-to-SQL, which provides zero-code interface for operating relational databases, has gained much attention in financial analysis; because, financial professionals may not well-skilled in SQL programming. However, until now, there is no practical Text-to-SQL benchmark dataset for financial analysis, and existing Text-to-SQL methods have not considered the unique characteristics of databases in financial applications, such as commonly existing wide tables. To address these issues, we collect a practical Text-to-SQL benchmark dataset and propose a model-agnostic Large Language Model (LLMs)-based Text-to-SQL framework for financial analysis. The benchmark dataset, BULL, is collected from the practical financial analysis business of Hundsun Technologies Inc., including databases for fund, stock, and macro economy. Besides, the proposed LLMs-based Text-to-SQL framework, FinSQL, provides a systematic treatment for financial Text-to-SQL from the perspectives of prompt construction, paramete
    
[^26]: 大型语言模型的知识融合

    Knowledge Fusion of Large Language Models. (arXiv:2401.10491v1 [cs.CL])

    [http://arxiv.org/abs/2401.10491](http://arxiv.org/abs/2401.10491)

    本文介绍了一种大型语言模型知识融合的方法，通过将现有预训练的语言模型合并为一个更强大的模型，从而提高目标模型的能力，验证实验结果证实了该方法的有效性。

    

    尽管从头开始训练大型语言模型（LLMs）可以生成具有独特功能和优势的模型，但这将带来巨大的成本，并可能导致冗余的能力。相反，一种具有成本效益和强大功能的方法是将现有的预训练LLMs合并为一个更强大的模型。然而，由于这些LLMs的不同架构，直接混合它们的权重是不切实际的。在本文中，我们引入了LLMs的知识融合的概念，旨在将现有LLMs的能力结合起来并转移到单个LLM中。通过利用源LLMs的生成分布，我们外部化它们的集体知识和独特优势，从而可能提高目标模型的能力超过任何单个源LLM的能力。我们使用具有不同架构的三个流行LLMs —— Llama-2、MPT和OpenLLaMA在各种基准和任务中验证了我们的方法。我们的研究结果证实了融合这三个LLMs的能力。

    While training large language models (LLMs) from scratch can generate models with distinct functionalities and strengths, it comes at significant costs and may result in redundant capabilities. Alternatively, a cost-effective and compelling approach is to merge existing pre-trained LLMs into a more potent model. However, due to the varying architectures of these LLMs, directly blending their weights is impractical. In this paper, we introduce the notion of knowledge fusion for LLMs, aimed at combining the capabilities of existing LLMs and transferring them into a single LLM. By leveraging the generative distributions of source LLMs, we externalize their collective knowledge and unique strengths, thereby potentially elevating the capabilities of the target model beyond those of any individual source LLM. We validate our approach using three popular LLMs with different architectures--Llama-2, MPT, and OpenLLaMA--across various benchmarks and tasks. Our findings confirm that the fusion of
    
[^27]: 生成式密集检索：记忆可以是一个负担

    Generative Dense Retrieval: Memory Can Be a Burden. (arXiv:2401.10487v1 [cs.IR])

    [http://arxiv.org/abs/2401.10487](http://arxiv.org/abs/2401.10487)

    本文提出了生成式密集检索（GDR）范式，通过在查询和文档之间实现簇间匹配和细粒度的簇内匹配，缓解了生成式检索面临的记忆准确性差、记忆混淆和记忆更新成本高的问题。

    

    生成式检索 (GR) 在小规模语料库的情况下表现出色，通过记忆模型参数来隐式地实现查询和文档的深度交互。然而，这种记忆机制面临三个问题：(1) 对文档的细粒度特征的记忆准确性较差；(2) 随着语料库规模的增加，记忆混淆程度越来越严重；(3) 对新文档的记忆更新成本巨大。为了缓解这些问题，我们提出了生成式密集检索（GDR）的范式。具体而言，GDR首先使用有限的内存容量，从查询到相关文档簇实现簇间匹配。然后，引入无记忆的密集检索（DR）匹配机制，从簇到相关文档进行细粒度的簇内匹配。这种从粗到细的过程最大化了GR深度交互和DR的优势。

    Generative Retrieval (GR), autoregressively decoding relevant document identifiers given a query, has been shown to perform well under the setting of small-scale corpora. By memorizing the document corpus with model parameters, GR implicitly achieves deep interaction between query and document. However, such a memorizing mechanism faces three drawbacks: (1) Poor memory accuracy for fine-grained features of documents; (2) Memory confusion gets worse as the corpus size increases; (3) Huge memory update costs for new documents. To alleviate these problems, we propose the Generative Dense Retrieval (GDR) paradigm. Specifically, GDR first uses the limited memory volume to achieve inter-cluster matching from query to relevant document clusters. Memorizing-free matching mechanism from Dense Retrieval (DR) is then introduced to conduct fine-grained intra-cluster matching from clusters to relevant documents. The coarse-to-fine process maximizes the advantages of GR's deep interaction and DR's s
    
[^28]: 逃离高昂成本：多步推理的提前停止自一致性

    Escape Sky-high Cost: Early-stopping Self-Consistency for Multi-step Reasoning. (arXiv:2401.10480v1 [cs.CL])

    [http://arxiv.org/abs/2401.10480](http://arxiv.org/abs/2401.10480)

    本文提出了一种称为提前停止自一致性（ESC）的简单且可扩展的采样策略，用于降低多步推理任务中自一致性的成本，通过大量实验证明了其有效性。

    

    自一致性是一种广泛应用于思维链推理的解码策略。尽管在各种多步推理任务中带来了显著的性能提升，但自一致性是一种高成本的方法，需要进行多次预设大小的抽样。本文提出了一种简单且可扩展的采样过程——提前停止自一致性（ESC），以极大降低自一致性的成本，同时不损害性能。在此基础上，还进一步推导了一种控制方案，可以动态选择不同任务和模型的性能和成本平衡。为了证明ESC的有效性，我们在三个常见的推理任务类别上进行了大量实验：算术推理、常识推理和符号推理。实验结果表明，在包括MATH在内的六个基准测试中，ESC将思维链推理的平均抽样次数显著减少了（-33.8%）。

    Self-consistency (SC) has been a widely used decoding strategy for chain-of-thought reasoning. Despite bringing significant performance improvements across a variety of multi-step reasoning tasks, it is a high-cost method that requires multiple sampling with the preset size. In this paper, we propose a simple and scalable sampling process, \textbf{E}arly-Stopping \textbf{S}elf-\textbf{C}onsistency (ESC), to greatly reduce the cost of SC without sacrificing performance. On this basis, one control scheme for ESC is further derivated to dynamically choose the performance-cost balance for different tasks and models. To demonstrate ESC's effectiveness, we conducted extensive experiments on three popular categories of reasoning tasks: arithmetic, commonsense and symbolic reasoning over language models with varying scales. The empirical results show that ESC reduces the average number of sampling of chain-of-thought reasoning by a significant margin on six benchmarks, including MATH (-33.8%),
    
[^29]: 生命科学领域通过度量学习对领域漂移下的命名标签进行处理

    Name Tagging Under Domain Shift via Metric Learning for Life Sciences. (arXiv:2401.10472v1 [cs.CL])

    [http://arxiv.org/abs/2401.10472](http://arxiv.org/abs/2401.10472)

    本论文通过度量学习提出了一种处理生命科学领域下领域漂移的命名标签的方法，通过将源实体和目标实体投影到特征空间的不同区域来减轻源实体错误标记为目标实体的问题。

    

    命名标签是信息抽取（IE）的关键组成部分，尤其在生物医学和化学等科学领域，大型语言模型（LLM），例如ChatGPT，表现不佳。我们研究了将迁移学习应用于增强在生物医学领域（源领域）训练的命名标签模型在化学领域（目标领域）中的使用。在少样本学习设置中训练这样的模型的一种常见做法是在标记的源数据上预训练模型，然后在少量标记的目标示例上进行微调。在我们的实验中，我们观察到这样的模型容易将源实体错误标记为目标实体，因为源实体经常出现在文本中。为了解决这个问题，我们提出了一种模型，将知识从源领域转移到目标领域，但同时将源实体和目标实体投影到特征空间的不同区域。

    Name tagging is a key component of Information Extraction (IE), particularly in scientific domains such as biomedicine and chemistry, where large language models (LLMs), e.g., ChatGPT, fall short. We investigate the applicability of transfer learning for enhancing a name tagging model trained in the biomedical domain (the source domain) to be used in the chemical domain (the target domain). A common practice for training such a model in a few-shot learning setting is to pretrain the model on the labeled source data, and then, to finetune it on a hand-full of labeled target examples. In our experiments we observed that such a model is prone to mis-labeling the source entities, which can often appear in the text, as the target entities. To alleviate this problem, we propose a model to transfer the knowledge from the source domain to the target domain, however, at the same time, to project the source entities and target entities into separate regions of the feature space. This diminishes 
    
[^30]: DeepEdit: 带有约束的解码式知识编辑

    DeepEdit: Knowledge Editing as Decoding with Constraints. (arXiv:2401.10471v1 [cs.CL])

    [http://arxiv.org/abs/2401.10471](http://arxiv.org/abs/2401.10471)

    DeepEdit是一种神经符号方法，通过更好的推理一致性和对更新知识的意识，提高了大型语言模型的知识编辑能力，对多跳问题数据集MQuaKE取得了显著的进展。

    

    我们将大型语言模型（LLMs）的知识编辑视为带有约束的解码过程。我们提出了DeepEdit（基于深度优先搜索的渐进式解码知识编辑），这是一种神经符号方法，通过更好的推理一致性、问题相关性和对更新知识的意识来改进知识编辑。DeepEdit可灵活应用于所有黑盒LLMs：不需要访问模型参数、表示或输出词汇分布。DeepEdit逐步产生高质量的推理步骤，以实现有效的知识编辑。它利用深度优先搜索来修改LLMs的输出，从而提高输出对问题的相关性和对更新知识的意识。在知识编辑方面，DeepEdit在控制LLMs产生更简洁的推理方面表现出色。在MQuaKE上，DeepEdit在定量上取得了显著的进展，这是一个具有挑战性的多跳问题数据集。

    We develop a new perspective of knowledge editing for large language models (LLMs) as decoding with constraints. We propose DeepEdit (Depth-first Search based Progressive Decoding for Knowledge Editing), a neuro-symbolic method that improves knowledge editing with better coherence of reasoning, relevance to the question, and awareness of updated knowledge. DeepEdit can be flexibly applied to all black-box LLMs: it does not require any access to the model parameters, representations, or output vocabulary distributions. DeepEdit progressively produces the high-quality reasoning steps towards effective knowledge editing. It utilizes a depth-first search to revise the LLMs' output, which improves the output's informativeness to the input question and awareness of the updated knowledge. Qualitatively, DeepEdit effectively controls LLMs to produce more succinct reasoning in accord with knowledge editing. Quantitatively, DeepEdit yields significant gains on MQuaKE, a challenging multi-hop que
    
[^31]: 数据驱动的字素到音素表示法用于无字典文本转语音

    Data-driven grapheme-to-phoneme representations for a lexicon-free text-to-speech. (arXiv:2401.10465v1 [cs.CL])

    [http://arxiv.org/abs/2401.10465](http://arxiv.org/abs/2401.10465)

    这篇论文通过使用自监督学习的方法，消除了传统G2P系统所面临的字典生成问题和固定音素表示问题，提出了一种无需字典的数据驱动音素表示方法，实验证明其与传统方法相比具有相当或稍微更好的效果。

    

    字素到音素（G2P）是任何现代高质量文本转语音（TTS）系统中的重要第一步。当前大多数G2P系统依赖于专家编制的精心手工编写的字典。这带来了一个双重问题。首先，字典是使用固定的音素集生成的，通常是ARPABET或IPA，这可能不是最优化地表示所有语言的音素的方式。其次，生产这样一个专家字典所需的工时非常高。本文通过使用自监督学习的最新进展，而不是固定表示法，消除了这两个问题，从而获得了数据驱动的音素表示法。我们将我们的无字典方法与使用精心编写的字典的强基线进行了比较。此外，我们证明了我们的数据驱动无字典方法在平均意见分数（MOS）方面与常规基于规则或基于字典的神经G2P相当或稍微更好，同时不使用任何先验语言知识。

    Grapheme-to-Phoneme (G2P) is an essential first step in any modern, high-quality Text-to-Speech (TTS) system. Most of the current G2P systems rely on carefully hand-crafted lexicons developed by experts. This poses a two-fold problem. Firstly, the lexicons are generated using a fixed phoneme set, usually, ARPABET or IPA, which might not be the most optimal way to represent phonemes for all languages. Secondly, the man-hours required to produce such an expert lexicon are very high. In this paper, we eliminate both of these issues by using recent advances in self-supervised learning to obtain data-driven phoneme representations instead of fixed representations. We compare our lexicon-free approach against strong baselines that utilize a well-crafted lexicon. Furthermore, we show that our data-driven lexicon-free method performs as good or even marginally better than the conventional rule-based or lexicon-based neural G2Ps in terms of Mean Opinion Score (MOS) while using no prior language
    
[^32]: 从理解的角度探讨语言模型的关键数据规模

    Critical Data Size of Language Models from a Grokking Perspective. (arXiv:2401.10463v1 [cs.CL])

    [http://arxiv.org/abs/2401.10463](http://arxiv.org/abs/2401.10463)

    本文从理解的角度探讨了语言模型中的关键数据规模，证明了只有当语言模型达到关键大小时才会发生泛化，同时揭示了更大的模型需要更多数据的趋势。

    

    我们探讨了语言模型中的关键数据规模，这是从快速记忆到缓慢泛化的一个基本转变阈值。我们将这个相变形式化为Grokking配置下的数据效率假说，并确定了语言模型训练动力学中的数据不足、充足和过剩阶段。我们通过重新调整初始化和权重衰减，开发出了一种Grokking配置，稳定地在简化的语言模型上重现了Grokking。我们表明只有当语言模型达到关键大小时才会发生泛化。我们分析了样本级和模型级的Grokking，验证了提出的数据效率假说。我们的实验揭示了语言数据集的关键数据集大小处发生的更平滑的相变。随着模型大小的增加，这个临界点也变得更大，这表明更大的模型需要更多的数据。我们的研究结果加深了对语言模型训练的理解，提供了一种新颖的视角。

    We explore the critical data size in language models, a threshold that marks a fundamental shift from quick memorization to slow generalization. We formalize the phase transition under the grokking configuration into the Data Efficiency Hypothesis and identify data insufficiency, sufficiency, and surplus regimes in language models training dynamics. We develop a grokking configuration to reproduce grokking on simplistic language models stably by rescaling initialization and weight decay. We show that generalization occurs only when language models reach a critical size. We analyze grokking across sample-wise and model-wise, verifying the proposed data efficiency hypothesis. Our experiments reveal smoother phase transitions occurring at the critical dataset size for language datasets. As the model size increases, this critical point also becomes larger, indicating that larger models require more data. Our results deepen the understanding of language model training, offering a novel pers
    
[^33]: 带有注意力偏差短语增强束搜索的上下文化自动语音识别

    Contextualized Automatic Speech Recognition with Attention-Based Bias Phrase Boosted Beam Search. (arXiv:2401.10449v1 [eess.AS])

    [http://arxiv.org/abs/2401.10449](http://arxiv.org/abs/2401.10449)

    本论文提出了一种基于注意力的上下文偏差方法，可以通过编辑短语列表进行定制，并结合特殊标记来有效地训练，以便在输入语音数据中检测偏差短语。此外，还提出了一种基于偏差短语索引概率的偏差短语增强束搜索算法，能进一步提高上下文化性能，实验证明该方法能够持续改善字错误率。

    

    端到端自动语音识别方法表现出出色的性能。然而，由于这些方法的性能与训练数据中的上下文密切相关，对于未知用户上下文（例如技术术语、个人姓名和播放列表），端到端自动语音识别方法无法实现预期的效果。因此，端到端自动语音识别方法必须能够轻松进行上下文化。本文提出了一种基于注意力的上下文偏差方法，可以使用可编辑的短语列表（称为偏差列表）进行定制。所提出的方法可以通过结合偏差短语索引损失和特殊标记来有效地训练，以便在输入语音数据中检测偏差短语。此外，为了进一步改善推理过程中的上下文化性能，我们提出了一种基于偏差短语索引概率的偏差短语增强束搜索算法。实验结果表明，所提出的方法始终可以改善字错误率。

    End-to-end (E2E) automatic speech recognition (ASR) methods exhibit remarkable performance. However, since the performance of such methods is intrinsically linked to the context present in the training data, E2E-ASR methods do not perform as desired for unseen user contexts (e.g., technical terms, personal names, and playlists). Thus, E2E-ASR methods must be easily contextualized by the user or developer. This paper proposes an attention-based contextual biasing method that can be customized using an editable phrase list (referred to as a bias list). The proposed method can be trained effectively by combining a bias phrase index loss and special tokens to detect the bias phrases in the input speech data. In addition, to improve the contextualization performance during inference further, we propose a bias phrase boosted (BPB) beam search algorithm based on the bias phrase index probability. Experimental results demonstrate that the proposed method consistently improves the word error ra
    
[^34]: 语音识别中低秩适应的训练策略和模型鲁棒性研究

    Investigating Training Strategies and Model Robustness of Low-Rank Adaptation for Language Modeling in Speech Recognition. (arXiv:2401.10447v1 [cs.CL])

    [http://arxiv.org/abs/2401.10447](http://arxiv.org/abs/2401.10447)

    本研究研究了语音识别中低秩适应的训练策略和模型鲁棒性。通过引入不同的LoRA训练策略，实现了相对词错误率的降低，并研究了模型对输入扰动的稳定性。实验结果表明，高级LoRA变体导致了某些扰动的性能下降。

    

    随着资源有限的硬件设备的普及，使用低秩适应（LoRA）与冻结预训练语言模型（PLMs）已成为一种主流、资源高效的建模方法。本研究首先探讨了如何通过引入各种LoRA训练策略来提高模型性能，在公开的Librispeech数据集上实现了相对词错误率降低3.50％，在消息领域的内部数据集上实现了3.67％的降低。为了进一步评估基于LoRA的二次传递语音识别模型的稳定性，我们研究了对输入扰动的鲁棒性。这些扰动源于同音字替代和一种名为N-best Perturbation-based Rescoring Robustness（NPRR）的新度量标准，这两种方法都用于衡量重评分模型性能的相对降解程度。我们的实验结果表明，虽然LoRA的高级变体（例如动态秩分配的LoRA）导致了$1$-best扰动的性能下降。

    The use of low-rank adaptation (LoRA) with frozen pretrained language models (PLMs) has become increasing popular as a mainstream, resource-efficient modeling approach for memory-constrained hardware. In this study, we first explore how to enhance model performance by introducing various LoRA training strategies, achieving relative word error rate reductions of 3.50\% on the public Librispeech dataset and of 3.67\% on an internal dataset in the messaging domain. To further characterize the stability of LoRA-based second-pass speech recognition models, we examine robustness against input perturbations. These perturbations are rooted in homophone replacements and a novel metric called N-best Perturbation-based Rescoring Robustness (NPRR), both designed to measure the relative degradation in the performance of rescoring models. Our experimental results indicate that while advanced variants of LoRA, such as dynamic rank-allocated LoRA, lead to performance degradation in $1$-best perturbati
    
[^35]: 大型语言模型是噪声鲁棒语音识别的高效学习者

    Large Language Models are Efficient Learners of Noise-Robust Speech Recognition. (arXiv:2401.10446v1 [cs.CL])

    [http://arxiv.org/abs/2401.10446](http://arxiv.org/abs/2401.10446)

    本文通过引入噪声信息作为条件器，并从N-best列表中提取语言空间噪声嵌入，教会了大型语言模型（LLMs）进行噪声去除，从而实现了噪声鲁棒语音识别的生成式错误纠正（GER）。

    

    最近对大型语言模型（LLMs）的进展促进了自动语音识别（ASR）的生成式错误纠正（GER），利用LLMs的丰富语言知识和强大的推理能力来改善识别结果。最新的研究提出了一个GER基准测试，并使用HyPoradise数据集通过高效的LLM微调从ASR N-best假设到地面真实转录的映射，这显示出极大的效果，但在噪声鲁棒ASR方面缺乏具体性。在这项工作中，我们将基准测试扩展到噪声条件下，并研究是否可以教会LLMs像噪声鲁棒ASR一样执行去噪。其中一个解决方案是将噪声信息作为条件器引入LLM中。然而，直接从音频编码器中引入噪声嵌入可能会对LLM微调造成损害，因为存在跨模态差距。因此，我们提出了从N-best列表中提取语言空间噪声嵌入来表示源语音的噪声条件的方法。

    Recent advances in large language models (LLMs) have promoted generative error correction (GER) for automatic speech recognition (ASR), which leverages the rich linguistic knowledge and powerful reasoning ability of LLMs to improve recognition results. The latest work proposes a GER benchmark with HyPoradise dataset to learn the mapping from ASR N-best hypotheses to ground-truth transcription by efficient LLM finetuning, which shows great effectiveness but lacks specificity on noise-robust ASR. In this work, we extend the benchmark to noisy conditions and investigate if we can teach LLMs to perform denoising for GER just like what robust ASR do}, where one solution is introducing noise information as a conditioner into LLM. However, directly incorporating noise embeddings from audio encoder could harm the LLM tuning due to cross-modality gap. To this end, we propose to extract a language-space noise embedding from the N-best list to represent the noise conditions of source speech, whic
    
[^36]: 用跨语言专家语言模型突破多语言环境的难题

    Breaking the Curse of Multilinguality with Cross-lingual Expert Language Models. (arXiv:2401.10440v1 [cs.CL])

    [http://arxiv.org/abs/2401.10440](http://arxiv.org/abs/2401.10440)

    本论文提出了一种称为X-ELM的跨语言专家语言模型，通过独立训练语言模型的子集来减轻多语言竞争，为多语言处理带来提升。实验表明，X-ELM在各种语言上优于联合训练的多语言模型，并且可以适应新语言的迭代添加。

    

    尽管多语言语言模型在非英语自然语言处理（NLP）中很受欢迎，但由于模型参数之间的跨语言竞争，它们往往表现不及单语语言模型。我们提出了跨语言专家语言模型（X-ELM），通过对多语言语料库的子集进行独立训练，来减轻这种竞争。这个过程使X-ELM针对不同语言进行专门训练，同时作为一个多语言集合保持有效。我们的实验表明，在给定相同计算预算的情况下，X-ELM在所有考虑的语言上优于联合训练的多语言模型，并且这些收益可以转移到下游任务中。X-ELM在性能改进方面提供了额外的好处：可以迭代地添加新的专家，适应新语言而不会产生灾难性的遗忘。此外，训练是异步进行的，减少了多语言训练的硬件要求，实现多语言建模的民主化。

    Despite their popularity in non-English NLP, multilingual language models often underperform monolingual ones due to inter-language competition for model parameters. We propose Cross-lingual Expert Language Models (X-ELM), which mitigate this competition by independently training language models on subsets of the multilingual corpus. This process specializes X-ELMs to different languages while remaining effective as a multilingual ensemble. Our experiments show that when given the same compute budget, X-ELM outperforms jointly trained multilingual models across all considered languages and that these gains transfer to downstream tasks. X-ELM provides additional benefits over performance improvements: new experts can be iteratively added, adapting X-ELM to new languages without catastrophic forgetting. Furthermore, training is asynchronous, reducing the hardware requirements for multilingual training and democratizing multilingual modeling.
    
[^37]: 大型语言模型摘要机能否适应不同科学传播目标？

    Can Large Language Model Summarizers Adapt to Diverse Scientific Communication Goals?. (arXiv:2401.10415v1 [cs.CL])

    [http://arxiv.org/abs/2401.10415](http://arxiv.org/abs/2401.10415)

    本研究探讨了大型语言模型在科学摘要任务中的可控性。通过控制风格特征，非微调的语言模型在评论生成任务中优于人类，同时基于关键词的引导可以改善模型的可控性。然而，模型在生成长摘要和高度抽象的简化摘要方面有限。总体而言，大型语言模型在摘要任务中表现出强大的通用能力，但在复杂控制方面有限。

    

    在这项工作中，我们研究了大型语言模型 (LLMs) 在科学摘要任务中的可控性。我们确定了表征论文评论、摘要和简化摘要等不同类型摘要的关键风格和内容覆盖因素。通过控制风格特征，我们发现非微调的LLMs在MuP评论生成任务中表现优于人类，无论是在与参考摘要的相似度还是在人类偏好方面。此外，我们还表明，我们可以通过基于关键词的无分类器引导 (CFG) 来改善LLMs的可控性，在arXiv和PubMed上实现与强微调基线相当的词汇重叠。然而，我们的结果还表明，LLMs无法一致地生成超过8个句子的长摘要。此外，这些模型在生成高度抽象的简化摘要方面能力有限。虽然LLMs表现出很强的通用摘要能力，但在不昂贵的微调措施下，对内容的复杂控制能力有限。

    In this work, we investigate the controllability of large language models (LLMs) on scientific summarization tasks. We identify key stylistic and content coverage factors that characterize different types of summaries such as paper reviews, abstracts, and lay summaries. By controlling stylistic features, we find that non-fine-tuned LLMs outperform humans in the MuP review generation task, both in terms of similarity to reference summaries and human preferences. Also, we show that we can improve the controllability of LLMs with keyword-based classifier-free guidance (CFG) while achieving lexical overlap comparable to strong fine-tuned baselines on arXiv and PubMed. However, our results also indicate that LLMs cannot consistently generate long summaries with more than 8 sentences. Furthermore, these models exhibit limited capacity to produce highly abstractive lay summaries. Although LLMs demonstrate strong generic summarization competency, sophisticated content control without costly fi
    
[^38]: 学习高质量和通用性的短语表示

    Learning High-Quality and General-Purpose Phrase Representations. (arXiv:2401.10407v1 [cs.CL])

    [http://arxiv.org/abs/2401.10407](http://arxiv.org/abs/2401.10407)

    本论文提出了一种改进的框架来学习高质量和通用性的短语表示。该框架在无上下文的情况下学习短语表示，通过短语类型分类和有效地融合字符级信息来提高表示的精确性和灵活性。此外，还采用了三种粒度的数据增强方法以增加训练数据的多样性。

    

    短语表示在数据科学和自然语言处理中起着重要作用，有利于实体对齐、记录链接、模糊连接和释义分类等各种任务。目前最先进的方法是使用对比学习来微调预训练的语言模型以获取短语嵌入。然而，我们已经发现了需要改进的方面。首先，这些预训练模型往往过于复杂，并需要在具有上下文句子的语料库上进行预训练。其次，利用短语类型和形态给出更精确和更灵活的短语表示。我们提出了一种改进的框架以以无上下文的方式学习短语表示。该框架将短语类型分类作为辅助任务，并更有效地将字符级信息融入短语表示。此外，我们设计了三种粒度的数据增强方法，以增加训练数据的多样性。

    Phrase representations play an important role in data science and natural language processing, benefiting various tasks like Entity Alignment, Record Linkage, Fuzzy Joins, and Paraphrase Classification. The current state-of-the-art method involves fine-tuning pre-trained language models for phrasal embeddings using contrastive learning. However, we have identified areas for improvement. First, these pre-trained models tend to be unnecessarily complex and require to be pre-trained on a corpus with context sentences. Second, leveraging the phrase type and morphology gives phrase representations that are both more precise and more flexible. We propose an improved framework to learn phrase representations in a context-free fashion. The framework employs phrase type classification as an auxiliary task and incorporates character-level information more effectively into the phrase representation. Furthermore, we design three granularities of data augmentation to increase the diversity of train
    
[^39]: 不一致的对话回应及其恢复方法

    Inconsistent dialogue responses and how to recover from them. (arXiv:2401.10353v1 [cs.CL])

    [http://arxiv.org/abs/2401.10353](http://arxiv.org/abs/2401.10353)

    本研究探讨了对话系统中一致性问题的评估和增强方法。我们开发了一个数据集来研究不一致性，并引入了一组任务，专注于对话一致性的检测和解决。实验结果表明，我们的数据集显著地促进了对话系统中不一致性的识别和解决，然而目前的大型语言模型在解决不一致性方面表现出良好的特点，但在检测方面仍然存在困难。

    

    对话系统的一个关键问题是保持其自身的偏好、观点、信念和事实的一致性，这被证明是一个困难的问题。在本研究中，我们研究了评估和增强对话系统话语一致性的方法。首先，我们开发了一个数据集来研究不一致性，其中包括由注释者编写的不一致的对话回应、不一致性的解释和恢复话语。这涵盖了不一致性的生命周期，即引入、理解和解决。在此基础上，我们介绍了一组以对话一致性为中心的任务，具体关注其检测和解决。我们的实验结果表明，我们的数据集显著帮助了鉴别和解决对话不一致性的进展，并且目前流行的大型语言模型（如ChatGPT）在解决不一致性方面表现出良好的特点，但在检测方面仍然存在困难。

    One critical issue for chat systems is to stay consistent about preferences, opinions, beliefs and facts of itself, which has been shown a difficult problem. In this work, we study methods to assess and bolster utterance consistency of chat systems. A dataset is first developed for studying the inconsistencies, where inconsistent dialogue responses, explanations of the inconsistencies, and recovery utterances are authored by annotators. This covers the life span of inconsistencies, namely introduction, understanding, and resolution. Building on this, we introduce a set of tasks centered on dialogue consistency, specifically focused on its detection and resolution. Our experimental findings indicate that our dataset significantly helps the progress in identifying and resolving conversational inconsistencies, and current popular large language models like ChatGPT which are good at resolving inconsistencies however still struggle with detection.
    
[^40]: 通过文化价值调查，弥合对话代理中的文化细微差别

    Bridging Cultural Nuances in Dialogue Agents through Cultural Value Surveys. (arXiv:2401.10352v1 [cs.CL])

    [http://arxiv.org/abs/2401.10352](http://arxiv.org/abs/2401.10352)

    通过引入cuDialog，我们提出了一种以文化为视角的对话生成基准，并开发了能够从对话中提取文化属性的基准模型。实验结果显示，结合文化价值调查可以提高对话代理的对个性化和对话质量的预测准确性。

    

    对话代理与文化的交互领域是一个引人注目但相对未被探索的领域。各种社会文化方面，从沟通风格和信念到共享的隐喻和知识，都深刻地影响着这些交互。为了更深入地研究这一动态，我们引入了cuDialog，这是一个以文化为视角的对话生成基准。我们还开发了能够从对话交流中提取文化属性的基准模型，旨在提高对话代理的预测准确性和质量。为了有效地共同学习文化理解和多轮对话预测，我们提出将文化维度与对话编码特征相结合。我们的实验结果表明，加入文化价值调查能够增强与参考文献和文化标记的一致性，显示出它对个性化和对话质量的重要影响。为了进一步促进对话代理与文化的交互探索。

    The cultural landscape of interactions with dialogue agents is a compelling yet relatively unexplored territory. It's clear that various sociocultural aspects -- from communication styles and beliefs to shared metaphors and knowledge -- profoundly impact these interactions. To delve deeper into this dynamic, we introduce cuDialog, a first-of-its-kind benchmark for dialogue generation with a cultural lens. We also develop baseline models capable of extracting cultural attributes from dialogue exchanges, with the goal of enhancing the predictive accuracy and quality of dialogue agents. To effectively co-learn cultural understanding and multi-turn dialogue predictions, we propose to incorporate cultural dimensions with dialogue encoding features. Our experimental findings highlight that incorporating cultural value surveys boosts alignment with references and cultural markers, demonstrating its considerable influence on personalization and dialogue quality. To facilitate further explorati
    
[^41]: 基于噪声对比估计的低资源安全攻击模式识别匹配框架

    Noise Contrastive Estimation-based Matching Framework for Low-resource Security Attack Pattern Recognition. (arXiv:2401.10337v1 [cs.LG])

    [http://arxiv.org/abs/2401.10337](http://arxiv.org/abs/2401.10337)

    该论文提出了一种基于噪声对比估计的低资源安全攻击模式识别匹配框架，通过直接语义相似度决定文本与攻击模式之间的关联，以降低大量类别、标签分布不均和标签空间复杂性带来的学习难度。

    

    战术、技术和程序（TTPs）是网络安全领域中复杂的攻击模式，在文本知识库中有详细的描述。在网络安全写作中识别TTPs，通常称为TTP映射，是一个重要而具有挑战性的任务。传统的学习方法通常以经典的多类或多标签分类设置为目标。由于存在大量的类别（即TTPs），标签分布的不均衡和标签空间的复杂层次结构，这种设置限制了模型的学习能力。我们采用了一种不同的学习范式来解决这个问题，其中将文本与TTP标签之间的直接语义相似度决定为文本分配给TTP标签，从而减少了仅仅在大型标签空间上竞争的复杂性。为此，我们提出了一种具有有效的基于采样的学习比较机制的神经匹配架构，促进学习过程。

    Tactics, Techniques and Procedures (TTPs) represent sophisticated attack patterns in the cybersecurity domain, described encyclopedically in textual knowledge bases. Identifying TTPs in cybersecurity writing, often called TTP mapping, is an important and challenging task. Conventional learning approaches often target the problem in the classical multi-class or multilabel classification setting. This setting hinders the learning ability of the model due to a large number of classes (i.e., TTPs), the inevitable skewness of the label distribution and the complex hierarchical structure of the label space. We formulate the problem in a different learning paradigm, where the assignment of a text to a TTP label is decided by the direct semantic similarity between the two, thus reducing the complexity of competing solely over the large labeling space. To that end, we propose a neural matching architecture with an effective sampling-based learn-to-compare mechanism, facilitating the learning pr
    
[^42]: DrugAssist：一个用于分子优化的大型语言模型

    DrugAssist: A Large Language Model for Molecule Optimization. (arXiv:2401.10334v1 [q-bio.QM])

    [http://arxiv.org/abs/2401.10334](http://arxiv.org/abs/2401.10334)

    DrugAssist是一个交互式分子优化模型，通过人机对话实现优化，利用LLM的强交互性和泛化能力，在药物发现中取得了领先的结果。

    

    最近，大型语言模型（LLMs）在各种任务上展现出令人印象深刻的性能，吸引了越来越多的尝试将LLMs应用于药物发现领域。然而，在药物发现流程中，分子优化是一个关键任务，但目前LLMs在这个领域的参与很少。大多数现有方法仅关注捕捉数据中提供的化学结构的潜在模式，而没有利用专家反馈。这些非交互式方法忽视了药物发现过程实际上需要专家经验和迭代改进的事实。为了填补这个空白，我们提出了DrugAssist，一个通过人机对话利用LLM的强交互性和泛化能力进行分子优化的交互式模型。DrugAssist在单一和多个性质优化方面取得了领先的结果，同时展示了巨大的潜力。

    Recently, the impressive performance of large language models (LLMs) on a wide range of tasks has attracted an increasing number of attempts to apply LLMs in drug discovery. However, molecule optimization, a critical task in the drug discovery pipeline, is currently an area that has seen little involvement from LLMs. Most of existing approaches focus solely on capturing the underlying patterns in chemical structures provided by the data, without taking advantage of expert feedback. These non-interactive approaches overlook the fact that the drug discovery process is actually one that requires the integration of expert experience and iterative refinement. To address this gap, we propose DrugAssist, an interactive molecule optimization model which performs optimization through human-machine dialogue by leveraging LLM's strong interactivity and generalizability. DrugAssist has achieved leading results in both single and multiple property optimization, simultaneously showcasing immense pot
    
[^43]: 中文数据处理中的佼佼者：英文代码模型

    Top in Chinese Data Processing: English Code Models. (arXiv:2401.10286v1 [cs.CL])

    [http://arxiv.org/abs/2401.10286](http://arxiv.org/abs/2401.10286)

    在中文数据处理中，基于代码的语言模型在非编程中文任务中表现出色，尤其是在对中文幻觉敏感的任务中。此研究为讨论“中文房间”思想实验提供了独特的视角。

    

    尽管在语言模型的应用中，任务与训练语料之间的对齐是一个基本的共识，但我们的一系列实验和我们设计的评估指标表明，基于代码的大型语言模型(LLMs)在非编程中文任务中的表现明显优于与任务紧密匹配的训练数据。此外，在对中文幻觉敏感程度较高的任务中，展示较少中文语言特征的模型表现更好。我们的实验结果可以通过简单地用代码模型替换基础模型，在中文数据处理任务中，如为检索增强生成(RAG)准备数据，很容易得到复制。此外，我们的研究为讨论“中文房间”思想实验提供了独特的视角。

    While the alignment between tasks and training corpora is a fundamental consensus in the application of language models, our series of experiments and the metrics we designed reveal that code-based Large Language Models (LLMs) significantly outperform models trained on data that is closely matched to the tasks in non-coding Chinese tasks. Moreover, in tasks high sensitivity to Chinese hallucinations, models exhibiting fewer linguistic features of the Chinese language achieve better performance. Our experimental results can be easily replicated in Chinese data processing tasks, such as preparing data for Retrieval-Augmented Generation (RAG), by simply replacing the base model with a code-based model. Additionally, our research offers a distinct perspective for discussion on the philosophical "Chinese Room" thought experiment.
    
[^44]: 大型语言模型中地理位置嵌入方法的系统综述：迈向空间人工智能系统的路径

    A systematic review of geospatial location embedding approaches in large language models: A path to spatial AI systems. (arXiv:2401.10279v1 [cs.IR])

    [http://arxiv.org/abs/2401.10279](http://arxiv.org/abs/2401.10279)

    这篇论文系统综述了在大型语言模型中的地理位置嵌入方法，提出了四种主要的嵌入主题，并强调了在空间形态和生成模态方面进一步发展的需求。

    

    地理位置嵌入（GLE）帮助大型语言模型（LLM）吸收和分析空间数据。GLE在地理人工智能（GeoAI）中的出现是由于我们复杂当代空间中对更深入的地理认知的需求以及LLM在生成人工智能中提取深层含义的成功。我们在Google Scholar、Science Direct和arXiv上搜索了关于地理位置嵌入和LLM的论文，并审查了着重于通过LLM实现更深入空间“知识”的文章。我们筛选了304个标题、30个摘要和18篇全文论文，揭示了四个GLE主题 - 实体位置嵌入（ELE）、文档位置嵌入（DLE）、序列位置嵌入（SLE）和令牌位置嵌入（TLE）。综述以表格和叙述的形式呈现，包括“空间”和“LLM”之间的对话。尽管GLE通过叠加空间数据有助于理解空间，但强调了在空间形态和生成模态方面的进一步发展的需求。

    Geospatial Location Embedding (GLE) helps a Large Language Model (LLM) assimilate and analyze spatial data. GLE emergence in Geospatial Artificial Intelligence (GeoAI) is precipitated by the need for deeper geospatial awareness in our complex contemporary spaces and the success of LLMs in extracting deep meaning in Generative AI. We searched Google Scholar, Science Direct, and arXiv for papers on geospatial location embedding and LLM and reviewed articles focused on gaining deeper spatial "knowing" through LLMs. We screened 304 titles, 30 abstracts, and 18 full-text papers that reveal four GLE themes - Entity Location Embedding (ELE), Document Location Embedding (DLE), Sequence Location Embedding (SLE), and Token Location Embedding (TLE). Synthesis is tabular and narrative, including a dialogic conversation between "Space" and "LLM." Though GLEs aid spatial understanding by superimposing spatial data, they emphasize the need to advance in the intricacies of spatial modalities and gener
    
[^45]: 基于知识图谱驱动的图神经网络推荐模型

    Knowledge graph driven recommendation model of graph neural network. (arXiv:2401.10244v1 [cs.IR])

    [http://arxiv.org/abs/2401.10244](http://arxiv.org/abs/2401.10244)

    提出了一种基于知识图谱的图神经网络推荐模型KGLN，通过合并节点特征、调整聚合权重和迭代演化，提高了个性化推荐的准确性和效果。在实验中相对于已有基准方法，KGLN在不同数据集上的AUC提高了0.3%至5.9%和1.1%至8.2%。

    

    提出了一种新的基于图神经网络的推荐模型KGLN，该模型利用知识图谱（KG）信息，提高了个性化推荐的准确性和效果。该模型首先利用单层神经网络将图中的个体节点特征合并，然后通过结合影响因素调整相邻实体的聚合权重。通过迭代，模型从单层逐渐演变为多层，使实体能够获取丰富的多阶关联实体信息。最后，将实体和用户的特征结合起来产生推荐分数。通过比较不同聚合方法和影响因素的效果，评估了模型的性能。在使用MovieLen-1M和Book-Crossing数据集进行测试时，KGLN相对于LibFM和D等已有基准方法，AUC（ROC曲线下的面积）提高了0.3%至5.9%和1.1%至8.2%。

    A new graph neural network-based recommendation model called KGLN, which leverages Knowledge Graph (KG) information, was developed to enhance the accuracy and effectiveness of personalized recommendations. This model begins by using a single-layer neural network to merge individual node features in the graph. It then adjusts the aggregation weights of neighboring entities by incorporating influence factors. The model evolves from a single layer to multiple layers through iteration, enabling entities to access extensive multi-order associated entity information. The final step involves integrating features of entities and users to produce a recommendation score. The model's performance was evaluated by comparing its effects on various aggregation methods and influence factors. In tests using the MovieLen-1M and Book-Crossing datasets, KGLN showed an AUC (Area Under the ROC curve) improvement of 0.3% to 5.9% and 1.1% to 8.2%, respectively, over established benchmark methods like LibFM, D
    
[^46]: 通过突出重要信息来更好地解释Transformer模型

    Better Explain Transformers by Illuminating Important Information. (arXiv:2401.09972v1 [cs.CL])

    [http://arxiv.org/abs/2401.09972](http://arxiv.org/abs/2401.09972)

    通过在层间相关传播方法之上使用精细化的信息流，该论文提出了一种解释Transformer模型的方法，突出重要信息并消除无关信息。实验证明，在处理分类和问答任务时，这种方法相比其他八种基线模型更加出色。

    

    基于Transformer的模型在各种自然语言处理（NLP）任务中表现出色，吸引了无数努力来解释其内部工作原理。现有方法通过关注原始梯度和注意力来解释Transformer，将非相关信息通常视为解释计算的一部分，导致结果混乱。在这项工作中，我们提出了一种在层间相关传播（LRP）方法之上通过精细化信息流来突出重要信息并消除无关信息的方法。具体而言，我们考虑将句法和位置头识别为重要注意力头，并专注于从这些重要头部获得的相关性。实验结果表明，无关信息确实会扭曲输出的归因分数，因此在解释计算过程中应该对其进行屏蔽。与八种基线模型在分类和问答数据集上的比较结果显示，我们的方法在结果上不断地表现优秀。

    Transformer-based models excel in various natural language processing (NLP) tasks, attracting countless efforts to explain their inner workings. Prior methods explain Transformers by focusing on the raw gradient and attention as token attribution scores, where non-relevant information is often considered during explanation computation, resulting in confusing results. In this work, we propose highlighting the important information and eliminating irrelevant information by a refined information flow on top of the layer-wise relevance propagation (LRP) method. Specifically, we consider identifying syntactic and positional heads as important attention heads and focus on the relevance obtained from these important heads. Experimental results demonstrate that irrelevant information does distort output attribution scores and then should be masked during explanation computation. Compared to eight baselines on both classification and question-answering datasets, our method consistently outperfo
    
[^47]: 使用反事实对抗优化实现大型语言模型的对齐

    Aligning Large Language Models with Counterfactual DPO. (arXiv:2401.09566v1 [cs.CL])

    [http://arxiv.org/abs/2401.09566](http://arxiv.org/abs/2401.09566)

    本文研究了在大型语言模型中使用反事实对抗优化框架，以实现风格对齐，避免人类干预，并成功培养出可取行为和减轻不可取行为。

    

    大型语言模型(LLMs)的进步在各种应用中展示了卓越的能力。这些模型在生成上下文连贯且涵盖广泛主题的文本补全方面表现出色。然而，它们训练所需的大量数据使得在预训练和指令调整阶段对齐响应风格变得具有挑战性。因此，通常会采用额外的对齐阶段，进一步使用人类偏好数据对模型进行训练，以更好地将其输出与人类期望对齐。虽然这个过程本身并没有引入新的能力，但它突出了模型固有的生成风格。本文研究了在直接偏好优化(DPO)框架内利用反事实提示来对齐模型的风格，而不依赖人类干预。我们证明了这种方法有效地培养了可取的行为，减轻了不可取的行为。

    Advancements in large language models (LLMs) have demonstrated remarkable capabilities across a diverse range of applications. These models excel in generating text completions that are contextually coherent and cover an extensive array of subjects. However, the vast datasets required for their training make aligning response styles during the pretraining and instruction tuning phases challenging. Consequently, an additional alignment phase is typically employed, wherein the model is further trained with human preference data to better align its outputs with human expectations. While this process doesn't introduce new capabilities per se, it does accentuate generation styles innate to the model. This paper explores the utilization of counterfactual prompting within the framework of Direct Preference Optimization (DPO) to align the model's style without relying on human intervention. We demonstrate that this method effectively instils desirable behaviour, mitigates undesirable ones, and
    
[^48]: 高效的槽位标注

    Efficient slot labelling. (arXiv:2401.09343v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.09343](http://arxiv.org/abs/2401.09343)

    本文提出了一种高效的槽位标注方法，相较于基于大型预训练语言模型的方法，具有更低的计算需求和训练参数量，并在实际工业场景中表现出色。

    

    槽位标注是对话系统的重要组成部分，旨在在每个用户回合中找到重要的参数。常见的方法包括使用BERT或RoBERTa等大型预训练语言模型（PLMs），但它们面临高计算需求和对预训练数据的依赖等挑战。在这项工作中，我们提出了一种轻量级方法，其性能与最先进的基于PLM的方法相当或更好，同时可训练参数几乎少了10倍。这使得它特别适用于实际工业场景。

    Slot labelling is an essential component of any dialogue system, aiming to find important arguments in every user turn. Common approaches involve large pre-trained language models (PLMs) like BERT or RoBERTa, but they face challenges such as high computational requirements and dependence on pre-training data. In this work, we propose a lightweight method which performs on par or better than the state-of-the-art PLM-based methods, while having almost 10x less trainable parameters. This makes it especially applicable for real-life industry scenarios.
    
[^49]: RoTBench: 评估大型语言模型在工具学习中的鲁棒性的多级基准

    RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning. (arXiv:2401.08326v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.08326](http://arxiv.org/abs/2401.08326)

    RoTBench是一个多级基准，用于评估大型语言模型在工具学习中的鲁棒性。研究发现，LLMs在真实世界的噪声下表现出的稳定性需得到提高。

    

    工具学习作为大型语言模型（LLMs）与物理世界之间互动的重要手段，引起了广泛的兴趣。当前的研究主要强调LLMs在结构良好的环境中利用工具的能力，但忽视了它们在面对真实世界中不可避免的噪声时的稳定性。为了弥合这一差距，我们引入了RoTBench，这是一个用于评估LLMs在工具学习中鲁棒性的多级基准。具体而言，我们建立了五个外部环境，每个环境都具有不同级别的噪声（即清洁、轻微、中等、重度和联合），对模型在工具选择、参数识别和内容填充三个关键阶段的抗干扰能力进行了深入分析。六个广泛使用的模型的实验表明，提高LLMs在工具学习中的鲁棒性迫在眉睫。例如，当没有实质性的噪声存在时，GPT-4的性能甚至从80.00下降到58.10。

    Tool learning has generated widespread interest as a vital means of interaction between Large Language Models (LLMs) and the physical world. Current research predominantly emphasizes LLMs' capacity to utilize tools in well-structured environments while overlooking their stability when confronted with the inevitable noise of the real world. To bridge this gap, we introduce RoTBench, a multi-level benchmark for evaluating the robustness of LLMs in tool learning. Specifically, we establish five external environments, each featuring varying levels of noise (i.e., Clean, Slight, Medium, Heavy, and Union), providing an in-depth analysis of the model's resilience across three critical phases: tool selection, parameter identification, and content filling. Experiments involving six widely-used models underscore the urgent necessity for enhancing the robustness of LLMs in tool learning. For instance, the performance of GPT-4 even drops significantly from 80.00 to 58.10 when there is no substanti
    
[^50]: 定向的正则和上下文无关语言

    Directed Regular and Context-Free Languages. (arXiv:2401.07106v2 [cs.FL] UPDATED)

    [http://arxiv.org/abs/2401.07106](http://arxiv.org/abs/2401.07106)

    该论文研究了决定给定语言是否是定向语言的问题，并且证明了定向性问题在正则语言和上下文无关语言中的复杂性。

    

    我们研究决定给定语言是否是定向语言的问题。一个语言L是\emph{定向}的，如果L中的每对单词都有一个共同的（散乱的）超级词在L中。决定定向性是与向下封闭集合的理想分解相关的基本问题。另一个动机是决定两个\emph{定向的}上下文无关语言是否具有相同的向下闭包可以在多项式时间内决定，而对于一般的上下文无关语言，这个问题被称为coNEXP-complete。我们证明了作为NFAs给出的正则语言的定向性问题属于$AC^1$，因此在多项式时间内。此外，对于固定字母表大小，它是NL-complete的。此外，我们还证明了对于上下文无关语言，定向性问题是PSPACE-complete的。

    We study the problem of deciding whether a given language is directed. A language $L$ is \emph{directed} if every pair of words in $L$ have a common (scattered) superword in $L$. Deciding directedness is a fundamental problem in connection with ideal decompositions of downward closed sets. Another motivation is that deciding whether two \emph{directed} context-free languages have the same downward closures can be decided in polynomial time, whereas for general context-free languages, this problem is known to be coNEXP-complete.  We show that the directedness problem for regular languages, given as NFAs, belongs to $AC^1$, and thus polynomial time. Moreover, it is NL-complete for fixed alphabet sizes. Furthermore, we show that for context-free languages, the directedness problem is PSPACE-complete.
    
[^51]: INACIA：将大型语言模型整合到巴西审计法院中的机会和挑战

    INACIA: Integrating Large Language Models in Brazilian Audit Courts: Opportunities and Challenges. (arXiv:2401.05273v1 [cs.CL])

    [http://arxiv.org/abs/2401.05273](http://arxiv.org/abs/2401.05273)

    本文介绍了INACIA系统，这是一个将大型语言模型整合到巴西审计法院中的系统，可以自动化案件分析的各个阶段，并展示了其在从案件文件中提取信息、评估合法性和生成司法建议方面的潜力。

    

    本文介绍了INACIA（基于人工智能的辅助指令系统），这是一个开创性的系统，旨在将大型语言模型（LLMs）整合到巴西联邦审计法院（TCU）的运营框架中。该系统自动化了案件分析的各个阶段，包括基本信息提取、可受理性审查、Periculum in mora和Fumus boni iuris分析以及建议生成。通过一系列实验，我们展示了INACIA从案件文件中提取相关信息、评估其合法性并生成司法建议的潜力。利用验证数据集和LLMs，我们的评估方法提供了一种创新的方法来评估系统性能，与人类判断高度相关。结果突显了INACIA处理复杂法律任务的能力，表明其适用于增加法律系统的效率和司法公正性。

    This paper introduces INACIA (Instru\c{c}\~ao Assistida com Intelig\^encia Artificial), a groundbreaking system designed to integrate Large Language Models (LLMs) into the operational framework of Brazilian Federal Court of Accounts (TCU). The system automates various stages of case analysis, including basic information extraction, admissibility examination, Periculum in mora and Fumus boni iuris analyses, and recommendations generation. Through a series of experiments, we demonstrate INACIA's potential in extracting relevant information from case documents, evaluating its legal plausibility, and generating judicial recommendations. Utilizing a validation dataset alongside LLMs, our evaluation methodology presents an innovative approach to assessing system performance, correlating highly with human judgment. The results highlight INACIA's proficiency in handling complex legal tasks, indicating its suitability for augmenting efficiency and judicial fairness within legal systems. The pap
    
[^52]: Chain-of-Table: 在推理链中演化表格用于表格理解

    Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding. (arXiv:2401.04398v1 [cs.CL])

    [http://arxiv.org/abs/2401.04398](http://arxiv.org/abs/2401.04398)

    这篇论文提出了Chain-of-Table框架，通过在推理链中使用表格数据作为中间思维的代理，利用大型语言模型在表格理解任务中进行推理，实现了动态演化的表格推理链。

    

    基于大型语言模型（LLMs）的表格推理是解决许多表格理解任务（如基于表格的问答和事实验证）的一种有前景的方法。与通常的推理相比，基于表格的推理需要从自由形式问题和半结构化表格数据中提取潜在语义。Chain-of-Thought及其类似方法将推理链以文本上下文的形式纳入其中，但如何有效利用表格数据在推理链中仍然是一个开放的问题。我们提出了Chain-of-Table框架，其中表格数据以作为中间思维的代理明确地用于推理链中。具体地，我们使用上下文学习指导LLMs来迭代生成操作并更新表格，以代表一个表格推理链。因此，LLMs可以根据之前操作的结果动态地规划下一个操作。这种表格的持续演化形成了一个链。

    Table-based reasoning with large language models (LLMs) is a promising direction to tackle many table understanding tasks, such as table-based question answering and fact verification. Compared with generic reasoning, table-based reasoning requires the extraction of underlying semantics from both free-form questions and semi-structured tabular data. Chain-of-Thought and its similar approaches incorporate the reasoning chain in the form of textual context, but it is still an open question how to effectively leverage tabular data in the reasoning chain. We propose the Chain-of-Table framework, where tabular data is explicitly used in the reasoning chain as a proxy for intermediate thoughts. Specifically, we guide LLMs using in-context learning to iteratively generate operations and update the table to represent a tabular reasoning chain. LLMs can therefore dynamically plan the next operation based on the results of the previous ones. This continuous evolution of the table forms a chain, 
    
[^53]: 用大型语言模型改善文本嵌入

    Improving Text Embeddings with Large Language Models. (arXiv:2401.00368v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.00368](http://arxiv.org/abs/2401.00368)

    本文介绍了一种使用只用合成数据和少量训练步骤获取高质量文本嵌入的简单方法，并且在没有使用标记数据的情况下，在竞争激烈的文本嵌入基准上取得了强大的性能。

    

    在本文中，我们介绍了一种新颖且简单的方法，仅使用合成数据和少于1k个训练步骤即可获得高质量的文本嵌入。与现有方法不同，现有方法往往依赖多阶段中间预训练，使用数十亿个弱监督文本对进行训练，然后再使用少量标记数据进行微调，我们的方法不需要构建复杂的训练流程，也不依赖于通常受任务多样性和语言覆盖范围限制的手动收集的数据集。我们利用专有的LLM来为近100种语言的数十万个文本嵌入任务生成多样的合成数据。然后，我们使用标准的对比损失在合成数据上微调开源的只有解码器的LLM。实验证明，我们的方法在竞争激烈的文本嵌入基准上取得了出色的性能，而且没有使用任何标记数据。此外，当与合成数据和标记数据的混合进行微调时，我们的模型创造了新的

    In this paper, we introduce a novel and simple method for obtaining high-quality text embeddings using only synthetic data and less than 1k training steps. Unlike existing methods that often depend on multi-stage intermediate pre-training with billions of weakly-supervised text pairs, followed by fine-tuning with a few labeled datasets, our method does not require building complex training pipelines or relying on manually collected datasets that are often constrained by task diversity and language coverage. We leverage proprietary LLMs to generate diverse synthetic data for hundreds of thousands of text embedding tasks across nearly 100 languages. We then fine-tune open-source decoder-only LLMs on the synthetic data using standard contrastive loss. Experiments demonstrate that our method achieves strong performance on highly competitive text embedding benchmarks without using any labeled data. Furthermore, when fine-tuned with a mixture of synthetic and labeled data, our model sets new
    
[^54]: KnowledgeNavigator: 利用大型语言模型增强知识图谱推理

    KnowledgeNavigator: Leveraging Large Language Models for Enhanced Reasoning over Knowledge Graph. (arXiv:2312.15880v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.15880](http://arxiv.org/abs/2312.15880)

    KnowledgeNavigator是一种利用大型语言模型和知识图谱增强推理的框架，通过检索和过滤外部知识来解决LLM在长逻辑链和复杂推理场景中的知识限制问题。

    

    大型语言模型（LLM）以其强大的自然语言理解和零-shot能力，在各种下游任务上取得了出色的表现，但LLM仍然面临知识限制的问题。特别是在需要长逻辑链或复杂推理的场景中，LLM的幻想和知识限制限制了它在问答中的表现。在本文中，我们提出了一种新颖的框架KnowledgeNavigator，通过高效准确地检索知识图谱中的外部知识，并将其作为增强LLM推理的关键因素来解决这些挑战。具体而言，KnowledgeNavigator首先挖掘和增强给定问题的潜在约束以引导推理。然后，在LLM和问题的指导下，通过对知识图谱的迭代推理检索和过滤支持回答的外部知识。最后，KnowledgeNavigator将结构化知识构建成有效的提示。

    Large language model (LLM) has achieved outstanding performance on various downstream tasks with its powerful natural language understanding and zero-shot capability, but LLM still suffers from knowledge limitation. Especially in scenarios that require long logical chains or complex reasoning, the hallucination and knowledge limitation of LLM limit its performance in question answering (QA). In this paper, we propose a novel framework KnowledgeNavigator to address these challenges by efficiently and accurately retrieving external knowledge from knowledge graph and using it as a key factor to enhance LLM reasoning. Specifically, KnowledgeNavigator first mines and enhances the potential constraints of the given question to guide the reasoning. Then it retrieves and filters external knowledge that supports answering through iterative reasoning on knowledge graph with the guidance of LLM and the question. Finally, KnowledgeNavigator constructs the structured knowledge into effective prompt
    
[^55]: 时间中的涟漪：美国历史中的不连续性

    A ripple in time: a discontinuity in American history. (arXiv:2312.01185v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.01185](http://arxiv.org/abs/2312.01185)

    该论文通过使用向量嵌入和非线性降维方法，发现GPT-2与UMAP的结合可以提供更好的分离和聚类效果。同时，经过微调的DistilBERT模型可用于识别总统和演讲的年份。

    

    在这篇论文中，我们使用来自Kaggle的国情咨文数据集对美国历史的总体时间线及咨文本身的特点和性质进行了一些令人惊讶（也有些不那么令人惊讶）的观察。我们的主要方法是使用向量嵌入，如BERT（DistilBERT）和GPT-2。虽然广泛认为BERT（及其变体）最适合NLP分类任务，但我们发现GPT-2结合UMAP等非线性降维方法可以提供更好的分离和更强的聚类效果。这使得GPT-2 + UMAP成为一个有趣的替代方案。在我们的情况下，不需要对模型进行微调，预训练的GPT-2模型就足够好用。我们还使用了经过微调的DistilBERT模型来检测哪位总统发表了哪篇演讲，并取得了非常好的结果（准确率为93\% - 95\%，具体取决于运行情况）。为了确定写作年份，我们还执行了一个类似的任务。

    In this note we use the State of the Union Address (SOTU) dataset from Kaggle to make some surprising (and some not so surprising) observations pertaining to the general timeline of American history, and the character and nature of the addresses themselves. Our main approach is using vector embeddings, such as BERT (DistilBERT) and GPT-2.  While it is widely believed that BERT (and its variations) is most suitable for NLP classification tasks, we find out that GPT-2 in conjunction with nonlinear dimension reduction methods such as UMAP provide better separation and stronger clustering. This makes GPT-2 + UMAP an interesting alternative. In our case, no model fine-tuning is required, and the pre-trained out-of-the-box GPT-2 model is enough.  We also used a fine-tuned DistilBERT model for classification detecting which President delivered which address, with very good results (accuracy 93\% - 95\% depending on the run). An analogous task was performed to determine the year of writing, an
    
[^56]: 通过基于Transformer的提示工程提高自动医疗报告中的摘要性能

    Enhancing Summarization Performance through Transformer-Based Prompt Engineering in Automated Medical Reporting. (arXiv:2311.13274v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.13274](http://arxiv.org/abs/2311.13274)

    通过使用两种不同的提示策略，shot prompting和pattern prompting，该研究提高了自动医学报告的性能，通过使用ROUGE分数和人工评估证明了其优越性。

    

    定制医疗提示使得大型语言模型（LLM）能够有效地处理医学对话摘要。医学报告的过程常常耗时长，对医疗专业人员来说是一个问题。通过生成自动化的医学报告，实施医学对话摘要技术可以有效缓解这个时间限制。在这项研究中，我们采用了两种不同的提示策略，即shot prompting和pattern prompting，以提高自动医学报告的性能。使用ROUGE分数和专家小组的人工评估来评估自动医学报告的效果。两次shot prompting方法与范围和领域上下文相结合优于其他方法，并取得了

    Customized medical prompts enable Large Language Models (LLM) to effectively address medical dialogue summarization. The process of medical reporting is often time-consuming for healthcare professionals. Implementing medical dialogue summarization techniques presents a viable solution to alleviate this time constraint by generating automated medical reports. The effectiveness of LLMs in this process is significantly influenced by the formulation of the prompt, which plays a crucial role in determining the quality and relevance of the generated reports. In this research, we used a combination of two distinct prompting strategies, known as shot prompting and pattern prompting to enhance the performance of automated medical reporting. The evaluation of the automated medical reports is carried out using the ROUGE score and a human evaluation with the help of an expert panel. The two-shot prompting approach in combination with scope and domain context outperforms other methods and achieves 
    
[^57]: 图遇上大型语言模型：进展与未来方向的综述

    A Survey of Graph Meets Large Language Model: Progress and Future Directions. (arXiv:2311.12399v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2311.12399](http://arxiv.org/abs/2311.12399)

    本综述对将大型语言模型(LLMs)与图结合的现有方法进行了全面的回顾和分析，提出了一个新的分类法，并讨论了未来研究的有希望的方向。

    

    图在表示和分析诸如引用网络、社交网络和生物数据等实际应用中扮演着重要角色。最近，大型语言模型(LLMs)在各个领域取得了巨大的成功，并且已经被应用于图相关任务中，超越了基于图神经网络(GNNs)的传统方法，并取得了最先进的性能。在本综述中，我们首先对将LLMs与图结合的现有方法进行全面的回顾和分析。首先，我们提出了一个新的分类法，根据LLMs在图相关任务中扮演的角色(即增强器、预测器和对齐组件)，将现有方法组织为三个类别。然后，我们系统地调查了分类法三个类别中的代表性方法。最后，我们讨论了现有研究的局限性，并突出了未来研究的有希望的方向。

    Graph plays a significant role in representing and analyzing complex relationships in real-world applications such as citation networks, social networks, and biological data. Recently, Large Language Models (LLMs), which have achieved tremendous success in various domains, have also been leveraged in graph-related tasks to surpass traditional Graph Neural Networks (GNNs) based methods and yield state-of-the-art performance. In this survey, we first present a comprehensive review and analysis of existing methods that integrate LLMs with graphs. First of all, we propose a new taxonomy, which organizes existing methods into three categories based on the role (i.e., enhancer, predictor, and alignment component) played by LLMs in graph-related tasks. Then we systematically survey the representative methods along the three categories of the taxonomy. Finally, we discuss the remaining limitations of existing studies and highlight promising avenues for future research. The relevant papers are 
    
[^58]: 大规模语言模型对监督微调数据组合的影响

    How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition. (arXiv:2310.05492v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.05492](http://arxiv.org/abs/2310.05492)

    本研究探讨了大规模语言模型在监督微调过程中，特别是数学推理和代码生成能力方面，数据组合的影响。实验结果显示，较大模型在相同数据量下表现出更好的性能，通过增加微调数据和模型参数，数学推理和代码生成能力得到显著提升。

    

    大规模语言模型（LLMs）具备大量的预训练标记和参数，展现出数学推理、代码生成和指令跟随等能力。这些能力通过监督微调（SFT）进一步增强。开源社区已经研究了针对每种能力的临时SFT，而专有LLMs可以适用于所有能力。因此，研究如何通过SFT解锁多重能力变得重要。在本研究中，我们特别关注SFT过程中数学推理、代码生成和人类对齐能力之间的数据组合。从规模的角度，我们研究了模型能力与各种因素之间的关系，包括数据量、数据组合比例、模型参数和SFT策略。我们的实验发现不同的能力表现出不同的扩展模式，较大的模型通常在相同的数据量下表现出更优异的性能。数学推理和代码生成能力通过微调数据和模型参数的增加而获得显著的性能提升。

    Large language models (LLMs) with enormous pre-training tokens and parameter amounts emerge abilities, including math reasoning, code generation, and instruction following. These abilities are further enhanced by supervised fine-tuning (SFT). The open-source community has studied on ad-hoc SFT for each ability, while proprietary LLMs are versatile for all abilities. It is important to investigate how to unlock them with multiple abilities via SFT. In this study, we specifically focus on the data composition between mathematical reasoning, code generation, and general human-aligning abilities during SFT. From a scaling perspective, we investigate the relationship between model abilities and various factors including data amounts, data composition ratio, model parameters, and SFT strategies. Our experiments reveal that different abilities exhibit different scaling patterns, and larger models generally show superior performance with the same amount of data. Mathematical reasoning and code
    
[^59]: MULTISCRIPT: 多模式脚本学习用于支持开放领域的日常任务

    MULTISCRIPT: Multimodal Script Learning for Supporting Open Domain Everyday Tasks. (arXiv:2310.04965v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.04965](http://arxiv.org/abs/2310.04965)

    该论文提出了一个新的基准挑战MultiScript，旨在解决现有脚本学习方法对于开放领域日常任务的限制。论文介绍了两个多模式脚本学习任务，并提供了对应的输入和输出要求。

    

    从视频演示中自动生成脚本（即文本描述的关键步骤序列）并推理后续步骤对于现代AI虚拟助手来引导人们完成日常任务，尤其是陌生任务至关重要。然而，当前的生成式脚本学习方法很大程度上依赖于结构良好的前置步骤的文本和/或图像描述，或者限于特定领域，导致与真实世界中用户场景存在差距。为了解决这些限制，我们提出了一个新的基准挑战——MultiScript，其中包含两个关于面向任务的多模式脚本学习的新任务：（1）多模式脚本生成，和（2）后续步骤预测。对于这两个任务，输入包括目标任务名称和演示视频，预期输出为（1）基于演示视频的结构化步骤描述的序列，和（2）针对每个步骤的单一文本描述。

    Automatically generating scripts (i.e. sequences of key steps described in text) from video demonstrations and reasoning about the subsequent steps are crucial to the modern AI virtual assistants to guide humans to complete everyday tasks, especially unfamiliar ones. However, current methods for generative script learning rely heavily on well-structured preceding steps described in text and/or images or are limited to a certain domain, resulting in a disparity with real-world user scenarios. To address these limitations, we present a new benchmark challenge -- MultiScript, with two new tasks on task-oriented multimodal script learning: (1) multimodal script generation, and (2) subsequent step prediction. For both tasks, the input consists of a target task name and a video illustrating what has been done to complete the target task, and the expected output is (1) a sequence of structured step descriptions in text based on the demonstration video, and (2) a single text description for th
    
[^60]: LLMCarbon: 对大型语言模型的端到端碳足迹建模

    LLMCarbon: Modeling the end-to-end Carbon Footprint of Large Language Models. (arXiv:2309.14393v1 [cs.CL])

    [http://arxiv.org/abs/2309.14393](http://arxiv.org/abs/2309.14393)

    本研究提出了LLMCarbon，一个针对密集型和MoE LLMs设计的端到端碳足迹预测模型，解决了现有工具的限制，并显著提升了估计的准确性。

    

    大型语言模型（LLMs）的碳足迹是一个重要关注点，包括它们的训练、推理、实验和存储过程中的排放，包括运营和固定碳排放。一个重要方面是在LLMs训练之前准确估计其碳影响，这在很大程度上依赖于GPU的使用。现有研究已报告了LLMs训练的碳足迹，但只有一个工具mlco2能够在实际训练之前预测新的神经网络的碳足迹。然而，mlco2存在一些严重的限制。它不能扩展其对密集或专家混合（MoE）LLMs的估计，忽视了关键的架构参数，仅关注GPU，并不能建模固化的碳足迹。为了解决这些问题，我们引入了LLMCarbon，一个为密集型和MoE LLMs设计的端到端碳足迹预测模型。与mlco2相比，LLMCarbon显著增强了准确性。

    The carbon footprint associated with large language models (LLMs) is a significant concern, encompassing emissions from their training, inference, experimentation, and storage processes, including operational and embodied carbon emissions. An essential aspect is accurately estimating the carbon impact of emerging LLMs even before their training, which heavily relies on GPU usage. Existing studies have reported the carbon footprint of LLM training, but only one tool, mlco2, can predict the carbon footprint of new neural networks prior to physical training. However, mlco2 has several serious limitations. It cannot extend its estimation to dense or mixture-of-experts (MoE) LLMs, disregards critical architectural parameters, focuses solely on GPUs, and cannot model embodied carbon footprints. Addressing these gaps, we introduce \textit{LLMCarbon}, an end-to-end carbon footprint projection model designed for both dense and MoE LLMs. Compared to mlco2, LLMCarbon significantly enhances the ac
    
[^61]: 利用大型语言模型探索自我强化以改进学生生成的多项选择题解释

    Exploring Self-Reinforcement for Improving Learnersourced Multiple-Choice Question Explanations with Large Language Models. (arXiv:2309.10444v1 [cs.AI])

    [http://arxiv.org/abs/2309.10444](http://arxiv.org/abs/2309.10444)

    本文提出了一个自我强化大型语言模型框架，自动生成和评估学生生成的解释，用于改进学生资源共享中学生生成的多项选择题的解释质量。

    

    学生资源共享涉及学生生成和分享学习资源。在学生生成多项选择题时，创建解释是一个关键步骤，因为它有助于对相关概念的深入理解。然而，学生往往由于主题理解有限和仅仅重申问题、干扰因素和正确答案的倾向而难以编写有效的解释。为了帮助支撑这个任务，在这项工作中，我们提出了一个自我强化的大型语言模型框架，旨在自动生成和评估解释。该框架由三个模块组成，生成与学生对齐的解释，评估这些解释以确保其质量，并迭代增强解释。如果一个解释的评估分数低于定义的阈值，框架会迭代地优化和重新评估解释。重要的是，我们的框架模拟了一个学生学习的过程。

    Learnersourcing involves students generating and sharing learning resources with their peers. When learnersourcing multiple-choice questions, creating explanations for the generated questions is a crucial step as it facilitates a deeper understanding of the related concepts. However, it is often difficult for students to craft effective explanations due to limited subject understanding and a tendency to merely restate the question stem, distractors, and correct answer. To help scaffold this task, in this work we propose a self-reinforcement large-language-model framework, with the goal of generating and evaluating explanations automatically. Comprising three modules, the framework generates student-aligned explanations, evaluates these explanations to ensure their quality and iteratively enhances the explanations. If an explanation's evaluation score falls below a defined threshold, the framework iteratively refines and reassesses the explanation. Importantly, our framework emulates th
    
[^62]: 预训练多语言翻译模型上的属性控制器能否迁移到其他语言？

    How Transferable are Attribute Controllers on Pretrained Multilingual Translation Models?. (arXiv:2309.08565v1 [cs.CL])

    [http://arxiv.org/abs/2309.08565](http://arxiv.org/abs/2309.08565)

    本文研究了如何将预训练的多语言翻译模型中的属性控制器迁移到没有监督数据的语言。通过全面分析不同数据场景下的训练和推断时控制技术，揭示了它们在零样本性能和领域鲁棒性上的相对优势和劣势。

    

    最近，将机器翻译模型定制为符合细粒度属性（如形式）已取得了巨大进展。然而，当前方法大多依赖于至少一些带有属性注释的监督数据。因此，数据稀缺仍然是将此定制能力普及到更广泛语言范围，尤其是低资源语言的一个瓶颈。鉴于最近在预训练大规模多语言翻译模型方面取得的进展，我们将它们作为对没有监督数据的语言进行属性控制能力迁移的基础。在这项工作中，我们基于预训练的NLLB-200模型对属性控制器的迁移进行了全面分析。我们研究了在各种数据场景下的训练和推断时控制技术，并揭示了它们在零样本性能和领域鲁棒性上的相对优势和劣势。我们显示出两种范式是互补的，通过一致的改进来证明。

    Customizing machine translation models to comply with fine-grained attributes such as formality has seen tremendous progress recently. However, current approaches mostly rely on at least some supervised data with attribute annotation. Data scarcity therefore remains a bottleneck to democratizing such customization possibilities to a wider range of languages, lower-resource ones in particular. Given recent progress in pretrained massively multilingual translation models, we use them as a foundation to transfer the attribute controlling capabilities to languages without supervised data. In this work, we present a comprehensive analysis of transferring attribute controllers based on a pretrained NLLB-200 model. We investigate both training- and inference-time control techniques under various data scenarios, and uncover their relative strengths and weaknesses in zero-shot performance and domain robustness. We show that both paradigms are complementary, as shown by consistent improvements o
    
[^63]: 信息检索中的大型语言模型：一项综述

    Large Language Models for Information Retrieval: A Survey. (arXiv:2308.07107v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.07107](http://arxiv.org/abs/2308.07107)

    本综述将大型语言模型（LLMs）在信息检索中的发展进行了综述，探讨了其在捕捉上下文信号和语义细微之处方面的优势和挑战，以及与传统检索方法的结合的重要性。

    

    作为信息获取的主要手段，信息检索（IR）系统，如搜索引擎，已经融入到我们的日常生活中。这些系统还作为对话、问答和推荐系统的组成部分。IR的发展轨迹从基于词项的方法起步，逐渐发展成与先进的神经模型相融合。尽管神经模型擅长捕捉复杂的上下文信号和语义细微之处，从而改变了IR的格局，但它们仍然面临着数据稀缺、可解释性以及生成上下文合理但潜在不准确响应的挑战。这种演变需要传统方法（如基于词项的稀疏检索方法与快速响应）和现代神经架构（如具有强大语言理解能力的语言模型）的结合。与此同时，大型语言模型（LLMs），如ChatGPT和GPT-4的出现，引起了一场革命

    As a primary means of information acquisition, information retrieval (IR) systems, such as search engines, have integrated themselves into our daily lives. These systems also serve as components of dialogue, question-answering, and recommender systems. The trajectory of IR has evolved dynamically from its origins in term-based methods to its integration with advanced neural models. While the neural models excel at capturing complex contextual signals and semantic nuances, thereby reshaping the IR landscape, they still face challenges such as data scarcity, interpretability, and the generation of contextually plausible yet potentially inaccurate responses. This evolution requires a combination of both traditional methods (such as term-based sparse retrieval methods with rapid response) and modern neural architectures (such as language models with powerful language understanding capacity). Meanwhile, the emergence of large language models (LLMs), typified by ChatGPT and GPT-4, has revolu
    
[^64]: UniversalNER：从大型语言模型中进行目标蒸馏，用于开放式命名实体识别

    UniversalNER: Targeted Distillation from Large Language Models for Open Named Entity Recognition. (arXiv:2308.03279v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.03279](http://arxiv.org/abs/2308.03279)

    本文提出了一种从大型语言模型中进行目标蒸馏的方法，用于训练能够在开放式命名实体识别中表现出色的学生模型。通过使用指导调整和面向任务的方法，将ChatGPT蒸馏成更小的UniversalNER模型。实验结果表明，UniversalNER在各种领域的命名实体识别任务上取得了卓越的准确性，超过了原始的大型语言模型。

    

    大型语言模型（LLMs）展示了卓越的泛化能力，例如理解任意实体和关系。指导调整已被证明可以有效地将LLMs蒸馏成更高效的模型，如Alpaca和Vicuna。然而，这种学生模型在下游应用中仍然远远落后于原始LLMs。在本文中，我们探索了定向蒸馏与面向任务的指导调整，以训练能够在开放式信息提取等广泛应用类中表现出色的学生模型。通过以命名实体识别（NER）为案例研究，我们展示了如何将ChatGPT蒸馏成更小的UniversalNER模型用于开放式NER。为了评估，我们组合了迄今为止最大的NER基准，包括9个多样领域的43个数据集，如生物医学、编程、社交媒体、法律、金融。在不使用任何直接监督的情况下，UniversalNER在数万种实体类型上实现了卓越的NER准确性，超过了gen。

    Large language models (LLMs) have demonstrated remarkable generalizability, such as understanding arbitrary entities and relations. Instruction tuning has proven effective for distilling LLMs into more cost-efficient models such as Alpaca and Vicuna. Yet such student models still trail the original LLMs by large margins in downstream applications. In this paper, we explore targeted distillation with mission-focused instruction tuning to train student models that can excel in a broad application class such as open information extraction. Using named entity recognition (NER) for case study, we show how ChatGPT can be distilled into much smaller UniversalNER models for open NER. For evaluation, we assemble the largest NER benchmark to date, comprising 43 datasets across 9 diverse domains such as biomedicine, programming, social media, law, finance. Without using any direct supervision, UniversalNER attains remarkable NER accuracy across tens of thousands of entity types, outperforming gen
    
[^65]: 将TransNormer扩展到1750亿参数

    Scaling TransNormer to 175 Billion Parameters. (arXiv:2307.14995v1 [cs.CL])

    [http://arxiv.org/abs/2307.14995](http://arxiv.org/abs/2307.14995)

    本论文提出了TransNormerLLM，这是第一个基于线性注意力的大型语言模型，在准确性和效率方面优于传统基于softmax注意力的模型。通过引入位置嵌入、线性注意力加速、门控机制等先进改进，并利用Lightning Attention技术加速线性注意力，以及采用张量归一化方案加速模型，提高了TransNormer的性能。

    

    我们提出了TransNormerLLM，这是第一个基于线性注意力的大型语言模型（LLM），在准确性和效率两方面都优于传统的基于softmax注意力的模型。TransNormerLLM从之前的线性注意力架构TransNormer发展而来，通过引入位置嵌入、线性注意力加速、门控机制、张量归一化、推理加速和稳定化等先进改进。具体地，我们使用LRPE与指数衰减结合，既避免了注意力稀释问题，又使模型保留了标记之间的全局交互。此外，我们提出了Lightning Attention，一种先进的技术，可以将线性注意力加速超过两倍，并将内存使用量减少了四倍。为了进一步提高TransNormer的性能，我们利用门控机制平滑训练，并采用新的张量归一化方案加速模型，从而取得了令人印象深刻的效果。

    We present TransNormerLLM, the first linear attention-based Large Language Model (LLM) that outperforms conventional softmax attention-based models in terms of both accuracy and efficiency. TransNormerLLM evolves from the previous linear attention architecture TransNormer by making advanced modifications that include positional embedding, linear attention acceleration, gating mechanism, tensor normalization, inference acceleration and stabilization. Specifically, we use LRPE together with an exponential decay to avoid attention dilution issues while allowing the model to retain global interactions between tokens. Additionally, we propose Lightning Attention, a cutting-edge technique that accelerates linear attention by more than twice in runtime and reduces memory usage by a remarkable four times. To further enhance the performance of TransNormer, we leverage a gating mechanism to smooth training and a new tensor normalization scheme to accelerate the model, resulting in an impressive 
    
[^66]: 为开发领域特定自然语言处理应用而进行的生成式用户体验研究

    Generative User-Experience Research for Developing Domain-specific Natural Language Processing Applications. (arXiv:2306.16143v1 [cs.CL])

    [http://arxiv.org/abs/2306.16143](http://arxiv.org/abs/2306.16143)

    本论文提出了一种在开发领域特定自然语言处理应用中整合生成式用户体验研究的方法。该方法将领域用户纳入原型开发的不同阶段，以更好地了解用户需求和评估用户价值的变化。

    

    用户体验（UX）是人机交互（HCI）研究的一部分，专注于提高系统用户的直观性、透明度、简洁性和信任度。大多数针对机器学习（ML）或自然语言处理（NLP）的UX研究都采用数据驱动的方法，即没有关注用户需求，并仅仅将领域用户用于可用性评估。此外，更典型的UX方法是先针对用户的可用性进行定制，而不是首先了解用户需求。本文提出了一种将生成式UX研究整合到开发领域NLP应用中的方法。生成式UX研究将领域用户纳入原型开发的初始阶段，即构思和概念评估阶段，以及最后一阶段评估用户价值的变化。案例研究中，我们报道了一个针对过程工业中日常操作的领域特定语义搜索的完整原型开发过程。

    User experience (UX) is a part of human-computer interaction (HCI) research and focuses on increasing intuitiveness, transparency, simplicity, and trust for system users. Most of the UX research for machine learning (ML) or natural language processing (NLP) focuses on a data-driven methodology, i.e., it fails to focus on users' requirements, and engages domain users mainly for usability evaluation. Moreover, more typical UX methods tailor the systems towards user usability, unlike learning about the user needs first. The paper proposes a methodology for integrating generative UX research into developing domain NLP applications. Generative UX research employs domain users at the initial stages of prototype development, i.e., ideation and concept evaluation, and the last stage for evaluating the change in user value. In the case study, we report the full-cycle prototype development of a domain-specific semantic search for daily operations in the process industry. Our case study shows tha
    
[^67]: 衡量自然语言处理模型面对领域转移的鲁棒性

    Measuring the Robustness of Natural Language Processing Models to Domain Shifts. (arXiv:2306.00168v1 [cs.CL])

    [http://arxiv.org/abs/2306.00168](http://arxiv.org/abs/2306.00168)

    本文探讨了自然领域转移设置下微调和小样本学习模型的DR挑战，引入了一个DR基准，提出了DR挑战的两个视角：源域降低（SD）和目标域降低（TD），并发现两者之一通常是正值，强调了评估DR挑战的两个视角的重要性。

    

    大型语言模型在各种任务中表现出了很好的性能，包括微调、小样本学习和零样本学习。然而，它们在没有标记数据的领域中的性能仍然落后于有标记数据的领域，我们称之为领域鲁棒性（DR）挑战。现有的DR研究存在不一致的设置、缺乏评估任务的多样性和过多依靠挑战集。在本文中，我们探讨了自然领域转移设置下微调和小样本学习模型的DR挑战。我们引入了一个DR基准，包括多样化的NLP任务，包括句子和标记级分类、问答和生成，每个任务都由几个领域组成。我们提出了DR挑战的两个视角：源域降低（SD）和目标域降低（TD），它们交替作为参考点来比较源域和目标域的性能。我们发现，在重大比例的领域转移中，SD或TD之一是正的，但不是两者都正，强调了评估DR挑战的两个视角的重要性。我们的基准允许在模型、任务和设置上公平比较DR，并提供有关NLP模型DR性质的见解。

    Large Language Models have shown promising performance on various tasks, including fine-tuning, few-shot learning, and zero-shot learning. However, their performance on domains without labeled data still lags behind those with labeled data, which we refer as the Domain Robustness (DR) challenge. Existing research on DR suffers from disparate setups, lack of evaluation task variety, and reliance on challenge sets. In this paper, we explore the DR challenge of both fine-tuned and few-shot learning models in natural domain shift settings. We introduce a DR benchmark comprising diverse NLP tasks, including sentence and token-level classification, QA, and generation, each task consists of several domains. We propose two views of the DR challenge: Source Drop (SD) and Target Drop (TD), which alternate between the source and target in-domain performance as reference points. We find that in significant proportions of domain shifts, either SD or TD is positive, but not both, emphasizing the imp
    
[^68]: MCWDST: 一种用于社交媒体实时虚假新闻缓解的最小成本加权有向生成树算法

    MCWDST: a Minimum-Cost Weighted Directed Spanning Tree Algorithm for Real-Time Fake News Mitigation in Social Media. (arXiv:2302.12190v2 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2302.12190](http://arxiv.org/abs/2302.12190)

    本论文提出了一种用于社交媒体实时虚假新闻缓解的算法，通过使用新的深度学习架构来检测假新闻并采取实时的网络感知策略来减少其传播。

    

    互联网的广泛普及和手持设备的可用性使得社交媒体具有类似报纸的影响力。人们可以在社交媒体上即时获取廉价的信息。然而，这种便利性也带来了危险，任何用户都可以自由发布任何内容，而不论其真实性。因此，需要检测虚假信息，也称为假新闻。本文提出了一个端到端的解决方案，可以准确地检测假新闻，并在实时中免于传播它们的网络节点上进行免疫。为了检测假新闻，我们提出了两种新的堆栈深度学习架构，利用卷积和双向LSTM层。为了缓解假新闻的传播，我们提出了一种实时网络感知策略，它（1）为检测到的节点构建了一个最小成本加权的有向生成树，并且（2）通过使用一种新的分数化危险性方法来免疫该树中的节点。

    The widespread availability of internet access and handheld devices confers to social media a power similar to the one newspapers used to have. People seek affordable information on social media and can reach it within seconds. Yet this convenience comes with dangers; any user may freely post whatever they please and the content can stay online for a long period, regardless of its truthfulness. A need to detect untruthful information, also known as fake news, arises. In this paper, we present an end-to-end solution that accurately detects fake news and immunizes network nodes that spread them in real-time. To detect fake news, we propose two new stack deep learning architectures that utilize convolutional and bidirectional LSTM layers. To mitigate the spread of fake news, we propose a real-time network-aware strategy that (1) constructs a minimum-cost weighted directed spanning tree for a detected node, and (2) immunizes nodes in that tree by scoring their harmfulness using a novel ran
    
[^69]: 通过控制无关句子的混淆效应，提高抽象摘要的准确性

    Improving Faithfulness of Abstractive Summarization by Controlling Confounding Effect of Irrelevant Sentences. (arXiv:2212.09726v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09726](http://arxiv.org/abs/2212.09726)

    通过控制无关句子的混淆效应，本文提出了一种改进抽象摘要准确性的方法，并在AnswerSumm数据集上实现了20\%的准确性提升。

    

    尽管最先进的摘要系统在生成看似流利的摘要方面取得了令人印象深刻的进展，但缺乏事实正确性仍然是一个问题。本文表明，无关的输入文本部分可能导致事实不一致，作为混淆因素。为此，我们利用因果效应的信息理论度量来量化混淆的程度，并准确衡量其对摘要性能的影响。基于从理论结果中得出的见解，当有人工注释的相关句子可用时，我们设计了一个简单的多任务模型来控制这种混淆。关键是，我们对数据分布进行了原则性的刻画，从而确保了使用人工注释的相关句子来生成准确的摘要。我们的方法在AnswerSumm上（参考文献：fabbri2021answersumm）上强基准的基础上将准确性得分提高了20\%。

    Lack of factual correctness is an issue that still plagues state-of-the-art summarization systems despite their impressive progress on generating seemingly fluent summaries. In this paper, we show that factual inconsistency can be caused by irrelevant parts of the input text, which act as confounders. To that end, we leverage information-theoretic measures of causal effects to quantify the amount of confounding and precisely quantify how they affect the summarization performance. Based on insights derived from our theoretical results, we design a simple multi-task model to control such confounding by leveraging human-annotated relevant sentences when available. Crucially, we give a principled characterization of data distributions where such confounding can be large thereby necessitating the use of human annotated relevant sentences to generate factual summaries. Our approach improves faithfulness scores by 20\% over strong baselines on AnswerSumm \citep{fabbri2021answersumm}, a conver
    

