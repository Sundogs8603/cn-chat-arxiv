# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Personalize Segment Anything Model with One Shot.](http://arxiv.org/abs/2305.03048) | 本文提出了一种无需训练的SAM个性化方法PerSAM，只需要一张带有参考掩模的单张图像即可定位和分割目标概念，还提出了高效的一次性微调变体PerSAM-F，旨在解决掩模不确定性问题。 |
| [^2] | [Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision.](http://arxiv.org/abs/2305.03047) | 这篇论文提出了SELF-ALIGN方法，使用基于原则的推理和LLMs的生成能力以最少的人类监督实现AI代理的自我对齐。 |
| [^3] | [What changes when you randomly choose BPE merge operations? Not much.](http://arxiv.org/abs/2305.03029) | 本文提出了三个随机BPE变体，在翻译到形态丰富的语言时，随机选择合并操作对下游机器翻译任务影响很小。标准BPE虽然被广泛使用，但存在着有趣的潜在变化宇宙值得探究。 |
| [^4] | [Panda LLM: Training Data and Evaluation for Open-Sourced Chinese Instruction-Following Large Language Models.](http://arxiv.org/abs/2305.03025) | 该项目研究了如何通过指令调整来提升开源大型语言模型的性能，探讨了训练数据的因素对指令调整模型性能的影响，并通过量化分析来为聊天模型的持续发展提供有价值的洞察力。 |
| [^5] | [Sentence Embedding Leaks More Information than You Expect: Generative Embedding Inversion Attack to Recover the Whole Sentence.](http://arxiv.org/abs/2305.03010) | 本论文提出了一种生成式嵌入逆向攻击方法，使用该方法可以只基于句子嵌入来重构输入序列，从而实现信息泄露的攻击。本方法在分类指标上优于先前的嵌入逆向攻击，生成的句子连贯且上下文相关。同时，该研究对自然语言处理中的隐私和安全问题提出了警醒，并呼吁进一步研究开发针对此类攻击的防御机制。 |
| [^6] | [NatCS: Eliciting Natural Customer Support Dialogues.](http://arxiv.org/abs/2305.03007) | 该论文介绍了NatCS，这是一个多领域口头客户服务对话集。相对于先前的数据集，利用自然语言现象，NatCS更能代表真实人际对话，并提供比现有数据集更为现实的基准供面向自然客户支持对话系统的应用。 |
| [^7] | [Adaptive Selection of Anchor Items for CUR-based k-NN search with Cross-Encoders.](http://arxiv.org/abs/2305.02996) | 本文提出了一种自适应锚点选择方法，可以在保持较小的计算成本的同时，实现与随机抽样锚点相当或者更好的k-NN召回性能。 |
| [^8] | [On the nonlinear correlation of ML performance between data subpopulations.](http://arxiv.org/abs/2305.02995) | 在不同数据子群体间，机器学习模型的内部准确性和外部准确性之间的相关性是非线性的，呈现出“月亮形”的相关性。 |
| [^9] | [SemEval-2023 Task 7: Multi-Evidence Natural Language Inference for Clinical Trial Data.](http://arxiv.org/abs/2305.02993) | 本论文介绍SemEval 2023的任务七，旨在进行临床试验数据的多证据自然语言推理，该任务难度较大，证据选择任务相对于蕴含任务表现更佳。 |
| [^10] | [End-to-end spoken language understanding using joint CTC loss and self-supervised, pretrained acoustic encoders.](http://arxiv.org/abs/2305.02937) | 本文提出了一种使用联合CTC损失和预训练声学编码器的基于端到端的口语理解模型，该方法实现了在两个数据集上超越SOTA模型的效果。 |
| [^11] | [An automatically discovered chain-of-thought prompt generalizes to novel models and datasets.](http://arxiv.org/abs/2305.02897) | 本文研究了一系列零照顾提示在六个最新发布的语言模型和问题回答数据集的实验中的表现，发现自动提示发现的CoT提示可在新模型和数据集上表现良好，并在应用于GPT-4模型时取得最佳结果。 |
| [^12] | [2x Faster Language Model Pre-training via Masked Structural Growth.](http://arxiv.org/abs/2305.02869) | 本文提出了掩码结构成长（MSG），可以加速语言模型的预训练，其中包括全维度成长进程和独立于新权重初始化的函数严格保留成长操作。 |
| [^13] | [CausalAPM: Generalizable Literal Disentanglement for NLU Debiasing.](http://arxiv.org/abs/2305.02865) | CausalAPM是一个通用的NLU文本解缠框架，它将文字和语义信息投射到独立的特征子空间中，并限制了文字信息在后续预测中的参与程度。该框架可以有效地应对数据集偏置问题，提高了推广性能而不损失性能水平。 |
| [^14] | [ReMask: A Robust Information-Masking Approach for Domain Counterfactual Generation.](http://arxiv.org/abs/2305.02858) | 本文提出一种三步领域混淆方法，包括基于频率和注意力规范的遮盖、遮盖领域特定提示信息，以及揭示领域通用上下文。实验证明这种方法在领域转移方面有较好效果。 |
| [^15] | [Semantic Space Grounded Weighted Decoding for Multi-Attribute Controllable Dialogue Generation.](http://arxiv.org/abs/2305.02820) | 该文介绍了名为DASC的可控生成框架，它利用属性语义空间的加权解码来实现多属性生成，并能够在多个方面实现最先进的控制精度和高质量的生成响应。 |
| [^16] | [Interpretable Sentence Representation with Variational Autoencoders and Attention.](http://arxiv.org/abs/2305.02810) | 本论文提出了使用VAEs和Transformers构建两种具有归纳偏差的模型，用于提高自然语言处理中表示学习技术的解释性和数据效率，能够将潜在表示中的信息分离为可理解的概念。实验结果表明这些模型提供了直观且可解释的表示形式，具有实用性。 |
| [^17] | [The Elephant in the Room: Analyzing the Presence of Big Tech in Natural Language Processing Research.](http://arxiv.org/abs/2305.02797) | 本文研究了工业界在自然语言处理研究中的存在和影响。研究发现在过去五年中，工业界的存在与影响呈现急剧增长，一些公司占据了大部分出版物，并向学术研究人员提供资金支持。 |
| [^18] | [BranchNorm: Robustly Scaling Extremely Deep Transformers.](http://arxiv.org/abs/2305.02790) | BranchNorm提出了一种新的方法，通过动态重新调整Transformer的非残差分支，理论上稳定了训练，并在随后的训练阶段中促进了更好的收敛。实验结果表明，BranchNorm在训练稳定性和收敛性能之间取得了更好的平衡。 |
| [^19] | [Automated Code generation for Information Technology Tasks in YAML through Large Language Models.](http://arxiv.org/abs/2305.02783) | 这项研究提出了一种名为Ansible Wisdom的自然语言转Ansible-YAML代码的工具，可自动化生成Ansible脚本，提高IT自动化生产力，并相比现有技术达到或更好的性能水平。 |
| [^20] | [Unified Model Learning for Various Neural Machine Translation.](http://arxiv.org/abs/2305.02777) | 本文提出了一种统一学习方法，即统一模型学习，可以同时适用于翻译各种任务数据，并实现智能按需翻译，相对现有的特定数据集模型能够得到明显的改进。 |
| [^21] | [The Politics of Language Choice: How the Russian-Ukrainian War Influences Ukrainians' Language Use on Twitter.](http://arxiv.org/abs/2305.02770) | 本文研究了俄乌战争期间乌克兰人在 Twitter 上的语言使用，发现在战争爆发前已经出现从俄语向乌克兰语转变的趋势，而战争爆发后这种趋势加速了，并且许多使用俄语的用户在战争期间转变成使用乌克兰语。 |
| [^22] | [VendorLink: An NLP approach for Identifying & Linking Vendor Migrants & Potential Aliases on Darknet Markets.](http://arxiv.org/abs/2305.02763) | 本论文提出了一种名为VendorLink的NLP方法，能够有效地识别和链接暗网市场上的供应商被迁移和潜在别名，减少非法市场的匿名性，具有重要的实际意义。 |
| [^23] | [A Survey on Proactive Dialogue Systems: Problems, Methods, and Prospects.](http://arxiv.org/abs/2305.02750) | 本综述全面概述了不同类型对话中对话代理主动性的突出问题和先进设计，讨论了符合实际应用需求但需要未来更大研究重点的挑战，激发更多的会话 AI 进展到下一级别。 |
| [^24] | [Unsupervised Dialogue Topic Segmentation with Topic-aware Utterance Representation.](http://arxiv.org/abs/2305.02747) | 本文提出一种利用未标记的对话数据进行无监督对话主题分割的方法，通过邻近话语匹配和伪分割学习主题感知的话语表示，实验显示其明显优于强基准方法。 |
| [^25] | [An Asynchronous Updating Reinforcement Learning Framework for Task-oriented Dialog System.](http://arxiv.org/abs/2305.02718) | 本文提出了一种异步更新强化学习框架 (AURL) 来训练面向任务型对话系统，解决了不同模块互相影响的问题。同时，采用课程学习来解决数据分布不平衡问题，并引入多个用户模型来增加对话的多样性。该方法在公共数据集上取得了31.37%的对话成功率改进。 |
| [^26] | [Big Data and Large Numbers. Interpreting Zipf's Law.](http://arxiv.org/abs/2305.02687) | 该论文揭示了大数性质对于解释齐普夫定律的影响，指出齐普夫定律噪音是这种影响的例子，并分析了权力分布和类似分布在种群是有限的、排名和元素计数是自然数的情况下的特性。 |
| [^27] | [Neighboring Words Affect Human Interpretation of Saliency Explanations.](http://arxiv.org/abs/2305.02679) | 相邻单词可以影响解释者对单词重要性的理解，应该考虑文本中其他因素的影响来替代单词级别的显著性解释方法。 |
| [^28] | [Learning Language-Specific Layers for Multilingual Machine Translation.](http://arxiv.org/abs/2305.02665) | 本文介绍了语言特异Transformer层（LSLs），这使我们能够增加模型容量，同时保持正向传递中使用的计算量和参数数量不变，从而提高多语机器翻译的质量。 |
| [^29] | [Towards Weakly-Supervised Hate Speech Classification Across Datasets.](http://arxiv.org/abs/2305.02637) | 该论文提出使用极度弱的监督方法，只依赖于类别名称而不是注释数据中的类别示例，解决当前仇恨言论识别的研究存在的数据创建策略不系统和不同注释方案问题，并展示了有效性。 |
| [^30] | [Conformal Nucleus Sampling.](http://arxiv.org/abs/2305.02633) | 本研究探讨了符合语言模型的核心抽样，并采用符合性预测进行校准。结果表明，OPT模型过于自信，并且校准显示出中度的逆比例缩放与模型大小。 |
| [^31] | [A framework for the emergence and analysis of language in social learning agents.](http://arxiv.org/abs/2305.02632) | 本研究提出了一个模拟语言特征的通信协议，用于分析个体和共享抽象的形成及其对任务表现的影响。通过优化信息内容以最大化学生奖励改善了信息编码，提高了学习表现。 |
| [^32] | [Affective Reasoning at Utterance Level in Conversations: A Causal Discovery Approach.](http://arxiv.org/abs/2305.02615) | 本文提出了一种新的会话情感因果发现方法（CACD），并通过设计公共骨架和生成替代隐含原因解决了因果模型的不确定性和隐含原因的不可观察性的问题。这种方法可以在变长会话中发现因果关系。 |
| [^33] | [DN at SemEval-2023 Task 12: Low-Resource Language Text Classification via Multilingual Pretrained Language Model Fine-tuning.](http://arxiv.org/abs/2305.02607) | 该论文介绍了针对SemEval-2023低资源非洲语言文本分类任务的解决方案，使用多语言预训练语言模型进行微调取得了第三名成绩，并突显了开发针对低资源语言的有效方法的重要性。 |
| [^34] | [From Statistical Methods to Deep Learning, Automatic Keyphrase Prediction: A Survey.](http://arxiv.org/abs/2305.02579) | 本文综述了关键词预测的代表性研究，分析了主要模型、数据集和评估指标，特别关注了基于深度学习的关键词预测，并进行了实验比较代表性模型，为深入分析它们的优缺点提供了可比性的数据支持。 |
| [^35] | [RetroMAE-2: Duplex Masked Auto-Encoder For Pre-Training Retrieval-Oriented Language Models.](http://arxiv.org/abs/2305.02564) | 本文提出了一种名为DupMAE的预训练方法，利用两个自动编码任务来提高语义表示质量，扩展了当前方法，使所有上下文嵌入都可以用于联合预训练检索任务。 |
| [^36] | [Analyzing Hong Kong's Legal Judgments from a Computational Linguistics point-of-view.](http://arxiv.org/abs/2305.02558) | 本文提供了多种基于统计、机器学习和深度学习等方法来有效地分析香港的法律判决，并从中提取关键信息，解决了价格高和资源缺乏的问题。 |
| [^37] | [Faithful Question Answering with Monte-Carlo Planning.](http://arxiv.org/abs/2305.02556) | 本文提出了基于蒙特卡洛规划的FAME问答系统，通过组织中间推理步骤作为结构化蕴含树来忠实回答问题。通过引入蒙特卡洛规划算法，FAME在保持忠实推理的同时，在领域通用的问答基准数据集上实现了最先进的性能。 |
| [^38] | [FormNetV2: Multimodal Graph Contrastive Learning for Form Document Information Extraction.](http://arxiv.org/abs/2305.02549) | 该论文提出了一种用于表格文档信息提取的多模态图形对比学习策略（FormNetV2），该方法能够统一所有模态的自监督预训练到一个损失中，并在多个基准测试中取得了最佳表现。 |
| [^39] | [PersonaLLM: Investigating the Ability of GPT-3.5 to Express Personality Traits and Gender Differences.](http://arxiv.org/abs/2305.02547) | 本文探究了基于LLMs模拟代理的行为，称之为LLM Personas，在分配大五人格类型和性别角色时是否可以生成具有一致性的个性化特质的内容。 |
| [^40] | [Language, Time Preferences, and Consumer Behavior: Evidence from Large Language Models.](http://arxiv.org/abs/2305.02531) | 本研究分析了大型语言模型在不同语言提示下的奖励时间偏好，并发现GPT在具有较弱未来时态的语言下表现出更大的耐心，这与使用该语言的人类的偏好相似。 |
| [^41] | [ANetQA: A Large-scale Benchmark for Fine-grained Compositional Reasoning over Untrimmed Videos.](http://arxiv.org/abs/2305.02519) | ANetQA是一个新的大规模基准测试，支持对未剪辑视频进行精细的组合推理。与现有的基准测试不同，ANetQA的问题类型需要精细的组成式推理，并覆盖多样化的信息类型，可以更加全面地评估VideoQA模型的性能。 |
| [^42] | [USTC-NELSLIP at SemEval-2023 Task 2: Statistical Construction and Dual Adaptation of Gazetteer for Multilingual Complex NER.](http://arxiv.org/abs/2305.02517) | 本文介绍了USTC-NELSLIP团队为SemEval-2023任务2开发的系统，该系统提出了一种名为“SCDAG”的方法，用于多语言复杂命名实体识别，该方法通过构建辞书和适应语言模型的表示来提高识别精度，在印地语赛道上排名第一。 |
| [^43] | [AutoML-GPT: Automatic Machine Learning with GPT.](http://arxiv.org/abs/2305.02499) | AutoML-GPT 是一种基于 GPT 的自动机器学习方法，利用大型语言模型动态地利用各种人工智能模型，自动化训练管道，节约了选择模型架构、优化算法和调整超参数的人力和时间成本。 |
| [^44] | [ChatGPT-steered Editing Instructor for Customization of Abstractive Summarization.](http://arxiv.org/abs/2305.02483) | 本文提出了一个三个代理的生成方案，包括生成器、辅导员和编辑器，以增强生成输出的自定义。在两个摘要总结数据集上进行的实验结果表明，我们的方法可以生成更好的输出。 |
| [^45] | [Toward the Automated Construction of Probabilistic Knowledge Graphs for the Maritime Domain.](http://arxiv.org/abs/2305.02471) | 该论文研究了海事领域的概率知识图谱的自动构建，以利用含有丰富信息的未结构化软数据，并解决了软数据提取方面的问题。 |
| [^46] | [Task-Optimized Adapters for an End-to-End Task-Oriented Dialogue System.](http://arxiv.org/abs/2305.02468) | 本文提出了一种端到端任务导向对话系统，通过在预训练网络的固定层后添加少量参数的任务优化适配器来独立地学习每个任务，并通过强化学习提高DST和NLG模块的性能。 |
| [^47] | [Cognitive Reframing of Negative Thoughts through Human-Language Model Interaction.](http://arxiv.org/abs/2305.02466) | 本文研究如何使用语言模型帮助人们重构负面思想，定义了七个用于重构思想的语言属性框架，并开发了自动化指标。实验发现使用模型辅助的参与者更有可能产生符合七个语言属性的重构思想，表明该模型在帮助人们重构负面思想上是成功的。 |
| [^48] | [Transfer and Active Learning for Dissonance Detection: Addressing the Rare-Class Challenge.](http://arxiv.org/abs/2305.02459) | 本文提出并探究了基于转移和主动学习的稀有类问题的解决方案，包括利用在密切相关任务上训练的模型和评估获取策略来解决共振检测的稀有类问题，并且发现了一种名为PRC的有效的策略来指导注释。 |
| [^49] | [Quantifying the Dissimilarity of Texts.](http://arxiv.org/abs/2305.02457) | 本文比较了使用三种不同的文本表示方式和三个不同的聚类任务的性能，并发现基于单词频率的广义Jensen-Shannon分歧在所有任务中表现良好。最佳方法的选择最终取决于任务。 |
| [^50] | [Lift Yourself Up: Retrieval-augmented Text Generation with Self Memory.](http://arxiv.org/abs/2305.02437) | 本文提出了一种新的检索增强文本生成模型Selfmem，通过迭代生成自我记忆池并采用记忆选择器，使检索更加自适应，提高了文本生成的质量和多样性。 |
| [^51] | [evaluating bert and parsbert for analyzing persian advertisement data.](http://arxiv.org/abs/2305.02426) | 本文评估了Bert和ParsBERT在分析波斯广告数据中的应用，并发现ParsBERT在预测广告发布百分比方面的性能优于mBERT。 |
| [^52] | [Backdoor Learning on Sequence to Sequence Models.](http://arxiv.org/abs/2305.02424) | 本文探讨了序列到序列模型对后门攻击的鲁棒性问题，发现只注入0.2％的样本即可让模型生成指定的关键词和整个句子，利用字节对编码创建多个新触发器对后门检测带来了新挑战，提出的方法在多个任务上可以达到90％以上的攻击成功率。 |
| [^53] | [PTP: Boosting Stability and Performance of Prompt Tuning with Perturbation-Based Regularizer.](http://arxiv.org/abs/2305.02423) | PTP算法引入基于扰动的正则化器来平滑loss图像，提升prompt tuning性能和稳定性，在四个测试数据集中获得了显著优于现有方法的表现。 |
| [^54] | [Plan, Eliminate, and Track -- Language Models are Good Teachers for Embodied Agents.](http://arxiv.org/abs/2305.02412) | 本文介绍了Plan，Eliminate，和Track（PET）框架，该框架利用预先训练的大型语言模型（LLM）帮助智能体简化控制任务，从而解决了LLM直接作为智能体所面临的一些限制和问题。 |
| [^55] | [Defending against Insertion-based Textual Backdoor Attacks via Attribution.](http://arxiv.org/abs/2305.02394) | 本文提出了一种基于归因的管道AttDef，用于防御两种插入式污染攻击BadNL和InSent，该管道可以成功缓解插入式文本后门攻击并在四个基准数据集上平均提高了56.59%至79.97%和15.25%至48.34%的准确率。 |
| [^56] | [Approximating CKY with Transformers.](http://arxiv.org/abs/2305.02386) | 本文研究了Transformer模型逼近CKY算法的能力，提出了一种用梯度预测解析的方法，在标准基准测试中表现竞争力更好，同时速度更快。在随机PCFG下解析时，性能下降，但加入额外的归纳偏差是有帮助的。 |
| [^57] | [PeaCoK: Persona Commonsense Knowledge for Consistent and Engaging Narratives.](http://arxiv.org/abs/2305.02364) | PeaCoK构建了一个大规模的角色常识知识图，包含约10万个经过人类验证的角色事实。该知识图展现了在以前的人类交互行为研究中确定的五个角色知识维度，并区分了常识和情感层面。 |
| [^58] | [Entity Tracking in Language Models.](http://arxiv.org/abs/2305.02363) | 本文探究了大型语言模型追踪实体状态的能力，发现经过大量代码预训练的GPT-3.5模型表现最好，即使训练和评估中几乎没有词汇重叠的情况下，仍然可以获得不错的效果。 |
| [^59] | [Using Language Models on Low-end Hardware.](http://arxiv.org/abs/2305.02350) | 本论文评估了在低端硬件上使用固定语言模型来训练文本分类网络的可行性，并发现在某些情况下，不对语言模型进行微调可以在更快的训练中产生竞争性的效果，仅需要原先内存的四分之一即可。 |
| [^60] | [A Statistical Exploration of Text Partition Into Constituents: The Case of the Priestly Source in the Books of Genesis and Exodus.](http://arxiv.org/abs/2305.02170) | 为了验证文本分组的假设，我们提出了一个统计文本探索的流程，并在圣经的前两卷书中应用此流程，成功地识别并探索了司祭派别和非司祭派别之间的统计明显的文体差异。 |
| [^61] | [Doc2SoarGraph: Discrete Reasoning over Visually-Rich Table-Text Documents with Semantic-Oriented Hierarchical Graphs.](http://arxiv.org/abs/2305.01938) | 本文提出了 Doc2SoarGraph 框架，利用语义导向分层图结构中元素之间的差异和相关性，在富含视觉表格文本的TAT-DQA问题下实现了离散推理，表现出了最佳的实验结果。 |
| [^62] | [Improving Contrastive Learning of Sentence Embeddings from AI Feedback.](http://arxiv.org/abs/2305.01918) | 本文提出了一种利用人工智能反馈改进句子嵌入对比学习方法的方式，可以提高对比学习样本对的质量，并结合人类反馈来提供更好的监督信号。 |
| [^63] | [Causality-aware Concept Extraction based on Knowledge-guided Prompting.](http://arxiv.org/abs/2305.01876) | 该论文提出了一种基于因果感知的知识引导提示方法，将其作为干预器装备到基于预训练语言模型的句子提取器中，以缓解概念偏差。在代表性的多语言KG数据集上进行广泛实验，获得了最先进的结果。 |
| [^64] | [Towards Imperceptible Document Manipulations against Neural Ranking Models.](http://arxiv.org/abs/2305.01860) | 该论文提出了一种针对神经排序模型的不易被检测到的对抗性攻击框架，称为“几乎不可察觉文档操作”（IDEM）。IDEM使用生成语言模型生成连结句，无法引入易于检测的错误，并且使用单独的位置合并策略来平衡扰动文本的相关性和连贯性，实验结果表明，IDEM可以在保持高人类评估得分的同时优于强基线。 |
| [^65] | [Few-shot In-context Learning for Knowledge Base Question Answering.](http://arxiv.org/abs/2305.01750) | 该论文提出了KB-BINDER框架，通过少量的上下文演示实现了在多个知识库问答数据集上的背景学习，大大提高了KBQA问题的可解性。 |
| [^66] | [Interpreting Vision and Language Generative Models with Semantic Visual Priors.](http://arxiv.org/abs/2304.14986) | 本研究提出了一种利用SHAP框架和视觉先验知识生成全面、有意义解释的方法，相较于传统方法具有更低的计算成本、更高的解释表现力，并可以推广到其他模型上。 |
| [^67] | [DataComp: In search of the next generation of multimodal datasets.](http://arxiv.org/abs/2304.14108) | DataComp是一个基准测试，旨在通过提出新的训练集来解决数据集在机器学习生态系统中的缺陷。它提供了一个多规模设计的实验测试平台，使用12.8B个图像-文本对的新候选池，让研究人员可以通过设计新的过滤技术或策划新的数据源并评估它们的新数据集来进行创新。 |
| [^68] | [Unsupervised Story Discovery from Continuous News Streams via Scalable Thematic Embedding.](http://arxiv.org/abs/2304.04099) | 本研究提出了一种新颖的主题嵌入方法和一个可扩展的无监督在线故事发现框架USTORY，可以动态表示文章和故事，并考虑它们共享的时间主题和新颖性，以帮助人们消化大量的新闻流。 |
| [^69] | [A Survey of Large Language Models.](http://arxiv.org/abs/2303.18223) | 本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。 |
| [^70] | [Improving Few-Shot Generalization by Exploring and Exploiting Auxiliary Data.](http://arxiv.org/abs/2302.00674) | 本文提出了一种在少样本学习过程中假定有辅助数据的训练范式FLAD，并针对自动混合辅助和目标数据的方法局限，提出了两种计算复杂度独立于辅助数据集数量的算法，通过FLAD和这两种算法的比较，可以发现这两种算法的表现更好。 |
| [^71] | [Large Language Models Are Implicitly Topic Models: Explaining and Finding Good Demonstrations for In-Context Learning.](http://arxiv.org/abs/2301.11916) | 本研究发现，大型语言模型可以被视为隐式的主题模型，并提出了一种算法，从注释数据中选择最佳示范，大大提高了上下文学习的能力。 |
| [^72] | [SeqDiffuSeq: Text Diffusion Model with Encoder-Decoder Transformers for Sequence-to-Sequence Generation.](http://arxiv.org/abs/2212.10325) | 本文提出了一种名为SeqDiffuSeq的文本扩散模型，用于序列生成，采用了编码器-解码器Transformer架构和自适应噪声调度技术，旨在探索扩散模型在自然语言生成方面的性能表现。 |
| [^73] | [Reasoning with Language Model Prompting: A Survey.](http://arxiv.org/abs/2212.09597) | 本文提供了使用语言模型提示进行推理的前沿研究综合调查。讨论了新兴推理能力出现的潜在原因，并提供系统资源帮助初学者。 |
| [^74] | [I2D2: Inductive Knowledge Distillation with NeuroLogic and Self-Imitation.](http://arxiv.org/abs/2212.09246) | 本论文探究了通过常识蒸馏算法强化小型语言模型的能力，挑战大型模型的常识获取能力，提出了一种不依赖规模的学习算法方案。 |
| [^75] | [Summary-Oriented Vision Modeling for Multimodal Abstractive Summarization.](http://arxiv.org/abs/2212.07672) | 本论文提出了一种以总结为导向的多模态视觉建模方法，通过设计辅助任务，有效提高了抽象总结的质量，实验结果表明该方法在多种语言 上都取得了较好的效果。 |
| [^76] | [xTrimoABFold: De novo Antibody Structure Prediction without MSA.](http://arxiv.org/abs/2212.00735) | xTrimoABFold是一种基于深度抗体语言模型的新型抗体结构预测方法，无需多序列比对，有望促进高通量药物设计的应用。 |
| [^77] | [Solving Math Word Problems via Cooperative Reasoning induced Language Models.](http://arxiv.org/abs/2210.16257) | 该论文提出了一种基于合作推理诱导的语言模型——CoRe，可以高效地解决数学应用题。实验表明，CoRe 在准确性和效率方面优于现有最先进的方法。 |
| [^78] | [Is It Worth the (Environmental) Cost? Limited Evidence for Temporal Adaptation via Continuous Training.](http://arxiv.org/abs/2210.07365) | 本研究发现，在社交媒体数据的下游任务中，经过时间调整的英语模型性能并不会随时间改善，而没有经过时间调整的预训练模型实际上更加有效和高效。 |
| [^79] | [Few-shot Incremental Event Detection.](http://arxiv.org/abs/2209.01979) | 本文提出了少样本增量事件检测任务，针对学习检测带有极少标签数据的新事件类别并保留检测旧类别能力的问题，提出了一套由聚类模块和知识蒸馏模块组成的解决框架，并在 IFSED 数据集上进行了实验验证。 |
| [^80] | [Modular and On-demand Bias Mitigation with Attribute-Removal Subnetworks.](http://arxiv.org/abs/2205.15171) | 提出一种新颖的模块化偏差缓解方法，在推理时间按需集成到核心模型中的独立去偏置子网络，在性别、种族和年龄等受保护属性的分类任务中，该方法在缓解偏差方面是有效的，并且在精度和灵活性方面优于现有技术方法。 |
| [^81] | [MiniDisc: Minimal Distillation Schedule for Language Model Compression.](http://arxiv.org/abs/2205.14570) | 本研究提出了一个叫做MiniDisc的最小蒸馏计划，可以在最少一次尝试中调度最优的教师助手，用于实现语言模型压缩。 |
| [^82] | [ECOLA: Enhanced Temporal Knowledge Embeddings with Contextualized Language Representations.](http://arxiv.org/abs/2203.09590) | 本文讨论如何将文本数据与时间知识嵌入相结合以加强时间知识嵌入表征的质量，提出了ECOLA方法，该方法考虑了时间因素，并将文本信息注入到时间知识嵌入中。 |
| [^83] | [QNLP in Practice: Running Compositional Models of Meaning on a Quantum Computer.](http://arxiv.org/abs/2102.12846) | 本文介绍了在嘈杂的中间规模量子计算机上进行的首个大于100个句子数据集的NLP实验结果，成功地训练了解决简单句子分类任务的NLP模型，证明了组合模型的含义与量子理论具有形式相似性。 |
| [^84] | [Simplified TinyBERT: Knowledge Distillation for Document Retrieval.](http://arxiv.org/abs/2009.07531) | 本文提出了一种基于知识蒸馏的文档检索模型Simplified TinyBERT，它在提供15倍速度提升的情况下比BERT-Base表现更好。 |

# 详细

[^1]: 个性化一次性分割模型

    Personalize Segment Anything Model with One Shot. (arXiv:2305.03048v1 [cs.CV])

    [http://arxiv.org/abs/2305.03048](http://arxiv.org/abs/2305.03048)

    本文提出了一种无需训练的SAM个性化方法PerSAM，只需要一张带有参考掩模的单张图像即可定位和分割目标概念，还提出了高效的一次性微调变体PerSAM-F，旨在解决掩模不确定性问题。

    

    在大数据预训练的推动下，分割任何物体模型（SAM）已被证明是一个强大且高效的框架，革新了分割模型领域。尽管SAM非常通用，但自动为特定视觉概念定制SAM而不需要手动提示，如在不同图像中自动分割你的宠物狗等， 还未深入研究。本文提出了一种无需训练的SAM个性化方法，称为PerSAM。只需要一张带有参考掩模的单张图像，PerSAM首先通过位置先验定位目标概念，并通过三种技术来在其他图像或视频中分割它：目标引导注意力，目标语义提示和级联后处理。这样，我们有效地适应了SAM的私人使用而无需任何训练。为了进一步缓解掩模的不确定性，我们提出了一个高效的一次性微调变体，即PerSAM-F。冻结整个SAM，我们引入了两个可学习权重用于多尺度掩模，仅训练2个参数即可。

    Driven by large-data pre-training, Segment Anything Model (SAM) has been demonstrated as a powerful and promptable framework, revolutionizing the segmentation models. Despite the generality, customizing SAM for specific visual concepts without man-powered prompting is under explored, e.g., automatically segmenting your pet dog in different images. In this paper, we propose a training-free Personalization approach for SAM, termed as PerSAM. Given only a single image with a reference mask, PerSAM first localizes the target concept by a location prior, and segments it within other images or videos via three techniques: target-guided attention, target-semantic prompting, and cascaded post-refinement. In this way, we effectively adapt SAM for private use without any training. To further alleviate the mask ambiguity, we present an efficient one-shot fine-tuning variant, PerSAM-F. Freezing the entire SAM, we introduce two learnable weights for multi-scale masks, only training 2 parameters wit
    
[^2]: 原则驱动自我对齐的最小人力监督的语言模型从零开始构建

    Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision. (arXiv:2305.03047v1 [cs.LG])

    [http://arxiv.org/abs/2305.03047](http://arxiv.org/abs/2305.03047)

    这篇论文提出了SELF-ALIGN方法，使用基于原则的推理和LLMs的生成能力以最少的人类监督实现AI代理的自我对齐。

    

    最近的AI助手代理，如ChatGPT，主要依赖于监督微调和人类反馈的强化学习来对齐大型语言模型的输出与人类意图，确保它们是有用的、道德的、可靠的。然而，这种依赖性可能会极大地限制AI助手代理的真正潜力，因为获得人类监督的成本很高，相关问题有质量、可靠性、多样性、自一致性和不良偏见。为了解决这些挑战，我们提出了一种新的方法 SELF-ALIGN，它结合了基于原则的推理和LLMs的生成能力，以最少的人类监督实现AI代理的自我对齐。方法包括四个阶段：第一，我们使用LLM生成合成提示，使用主题引导方法增加提示多样性；第二，我们使用一小组人工编写的AI模型原则，并指导AI模型遵循；

    Recent AI-assistant agents, such as ChatGPT, predominantly rely on supervised fine-tuning (SFT) with human annotations and reinforcement learning from human feedback (RLHF) to align the output of large language models (LLMs) with human intentions, ensuring they are helpful, ethical, and reliable. However, this dependence can significantly constrain the true potential of AI-assistant agents due to the high cost of obtaining human supervision and the related issues on quality, reliability, diversity, self-consistency, and undesirable biases. To address these challenges, we propose a novel approach called SELF-ALIGN, which combines principle-driven reasoning and the generative power of LLMs for the self-alignment of AI agents with minimal human supervision. Our approach encompasses four stages: first, we use an LLM to generate synthetic prompts, and a topic-guided method to augment the prompt diversity; second, we use a small set of human-written principles for AI models to follow, and gu
    
[^3]: 随机选择BPE合并操作会带来什么变化？不多。

    What changes when you randomly choose BPE merge operations? Not much. (arXiv:2305.03029v1 [cs.CL])

    [http://arxiv.org/abs/2305.03029](http://arxiv.org/abs/2305.03029)

    本文提出了三个随机BPE变体，在翻译到形态丰富的语言时，随机选择合并操作对下游机器翻译任务影响很小。标准BPE虽然被广泛使用，但存在着有趣的潜在变化宇宙值得探究。

    

    我们介绍了三个简单的随机BPE变体，并探讨了随机选择合并操作是否会对下游机器翻译任务产生实质性影响。我们着重翻译到形态丰富的语言，假设这个任务可能对选择子词的方法表现出敏感性。使用贝叶斯线性模型进行分析表明，其中两个变体与标准BPE相比表现几乎无法区分，而另一个变体的性能下降程度比我们预期的要小。我们得出结论，尽管标准BPE被广泛使用，但存在一个有趣的潜在变化宇宙值得探究。我们的代码可在以下网址找到：https://github.com/bltlab/random-bpe。

    We introduce three simple randomized variants of byte pair encoding (BPE) and explore whether randomizing the selection of merge operations substantially affects a downstream machine translation task. We focus on translation into morphologically rich languages, hypothesizing that this task may show sensitivity to the method of choosing subwords. Analysis using a Bayesian linear model indicates that two of the variants perform nearly indistinguishably compared to standard BPE while the other degrades performance less than we anticipated. We conclude that although standard BPE is widely used, there exists an interesting universe of potential variations on it worth investigating. Our code is available at: https://github.com/bltlab/random-bpe.
    
[^4]: Panda LLM：训练数据和评估针对开源汉语指令跟随大语言模型的性能

    Panda LLM: Training Data and Evaluation for Open-Sourced Chinese Instruction-Following Large Language Models. (arXiv:2305.03025v1 [cs.CL])

    [http://arxiv.org/abs/2305.03025](http://arxiv.org/abs/2305.03025)

    该项目研究了如何通过指令调整来提升开源大型语言模型的性能，探讨了训练数据的因素对指令调整模型性能的影响，并通过量化分析来为聊天模型的持续发展提供有价值的洞察力。

    

    该项目着重于通过指令调整来增强开源大型语言模型，并对其性能进行全面评估。我们探讨了各种训练数据因素，如数量、质量和语言分布，对在公开高质量指令数据集上训练的中英双语指令调整模型性能的影响。我们的目标是通过定量分析来补充评估，为开源聊天模型的持续发展提供有价值的洞察力。我们的模型、数据和代码都是公开的，供其他人使用和建立。

    This project focuses on enhancing open-source large language models through instruction-tuning and providing comprehensive evaluations of their performance. We explore how various training data factors, such as quantity, quality, and linguistic distribution, influence the performance of instruction-tuned models trained on publicly accessible high-quality instruction datasets for both English and Chinese languages. Our goal is to supplement evaluation with quantitative analyses, providing valuable insights for the continued advancement of open-source chat models. Our model, data, and code are publicly available for others to use and build upon.
    
[^5]: 句子嵌入泄露的信息比您想象的要多：生成式嵌入逆向攻击用于恢复整个句子

    Sentence Embedding Leaks More Information than You Expect: Generative Embedding Inversion Attack to Recover the Whole Sentence. (arXiv:2305.03010v1 [cs.CL])

    [http://arxiv.org/abs/2305.03010](http://arxiv.org/abs/2305.03010)

    本论文提出了一种生成式嵌入逆向攻击方法，使用该方法可以只基于句子嵌入来重构输入序列，从而实现信息泄露的攻击。本方法在分类指标上优于先前的嵌入逆向攻击，生成的句子连贯且上下文相关。同时，该研究对自然语言处理中的隐私和安全问题提出了警醒，并呼吁进一步研究开发针对此类攻击的防御机制。

    

    句子级别的表示对于各种自然语言处理任务都有益处。人们普遍认为向量表示可以捕捉到丰富的语言属性。目前，大型语言模型(LMs)在句子嵌入方面实现了最先进的性能。然而，一些最新的研究表明，从LMs中获得的向量表示可能会导致信息泄露。在这项工作中，我们进一步研究了信息泄露问题，并提出了一种生成式嵌入逆向攻击(GEIA)，旨在仅基于其句子嵌入来重构输入序列。鉴于对语言模型的黑盒访问，我们将句子嵌入视为初始标记的表示，并训练或微调一个强大的解码器模型直接解码整个序列。我们进行了广泛的实验，证明我们的生成逆向攻击在分类指标上优于先前的嵌入逆向攻击，并生成连贯且上下文相关的句子。此外，我们进行了一系列削减研究，以表明所提出的攻击是有效且稳健的。我们的工作突显了自然语言处理中隐私和安全的重要性，并呼吁进一步研究开发针对此类攻击的防御机制。

    Sentence-level representations are beneficial for various natural language processing tasks. It is commonly believed that vector representations can capture rich linguistic properties. Currently, large language models (LMs) achieve state-of-the-art performance on sentence embedding. However, some recent works suggest that vector representations from LMs can cause information leakage. In this work, we further investigate the information leakage issue and propose a generative embedding inversion attack (GEIA) that aims to reconstruct input sequences based only on their sentence embeddings. Given the black-box access to a language model, we treat sentence embeddings as initial tokens' representations and train or fine-tune a powerful decoder model to decode the whole sequences directly. We conduct extensive experiments to demonstrate that our generative inversion attack outperforms previous embedding inversion attacks in classification metrics and generates coherent and contextually simil
    
[^6]: NatCS: 引发自然客服对话

    NatCS: Eliciting Natural Customer Support Dialogues. (arXiv:2305.03007v1 [cs.CL])

    [http://arxiv.org/abs/2305.03007](http://arxiv.org/abs/2305.03007)

    该论文介绍了NatCS，这是一个多领域口头客户服务对话集。相对于先前的数据集，利用自然语言现象，NatCS更能代表真实人际对话，并提供比现有数据集更为现实的基准供面向自然客户支持对话系统的应用。

    

    尽管越来越多的应用程序基于自然的客户支持对话，但公开可用的数据集极少反映出这些环境中对话的预期特征。现有的面向任务的对话数据集，主要收集为基准对话系统，主要是在人与机器人之间的书面对话环境中，这些数据集并不代表真实的客户支持对话，也不能提供应用于自然数据的系统的现实基准。为了弥补这一差距，我们引入了NatCS，这是一个多领域的口语客户服务对话集。我们描述了我们采集人工合成对话的过程，这些对话是基于观察到的真实对话中的自然语言现象。与先前的对话数据集相比，我们采用这种方法收集的对话在多个指标上更能代表真实的人际对话。最后，我们展示了NatCS的潜在用途，包括...

    Despite growing interest in applications based on natural customer support conversations, there exist remarkably few publicly available datasets that reflect the expected characteristics of conversations in these settings. Existing task-oriented dialogue datasets, which were collected to benchmark dialogue systems mainly in written human-to-bot settings, are not representative of real customer support conversations and do not provide realistic benchmarks for systems that are applied to natural data. To address this gap, we introduce NatCS, a multi-domain collection of spoken customer service conversations. We describe our process for collecting synthetic conversations between customers and agents based on natural language phenomena observed in real conversations. Compared to previous dialogue datasets, the conversations collected with our approach are more representative of real human-to-human conversations along multiple metrics. Finally, we demonstrate potential uses of NatCS, includ
    
[^7]: 带有交叉编码器的CUR k-NN搜索的自适应锚定项选择

    Adaptive Selection of Anchor Items for CUR-based k-NN search with Cross-Encoders. (arXiv:2305.02996v1 [cs.IR])

    [http://arxiv.org/abs/2305.02996](http://arxiv.org/abs/2305.02996)

    本文提出了一种自适应锚点选择方法，可以在保持较小的计算成本的同时，实现与随机抽样锚点相当或者更好的k-NN召回性能。

    

    本文提出了一种自适应锚点选择方法，以改善ANNCUR模型中高前k项的逼近误差和召回率。该方法可以在保持较小的计算成本的同时，实现与随机抽样锚点相当或者更好的k-NN召回性能。

    Cross-encoder models, which jointly encode and score a query-item pair, are typically prohibitively expensive for k-nearest neighbor search. Consequently, k-NN search is performed not with a cross-encoder, but with a heuristic retrieve (e.g., using BM25 or dual-encoder) and re-rank approach. Recent work proposes ANNCUR (Yadav et al., 2022) which uses CUR matrix factorization to produce an embedding space for efficient vector-based search that directly approximates the cross-encoder without the need for dual-encoders. ANNCUR defines this shared query-item embedding space by scoring the test query against anchor items which are sampled uniformly at random. While this minimizes average approximation error over all items, unsuitably high approximation error on top-k items remains and leads to poor recall of top-k (and especially top-1) items. Increasing the number of anchor items is a straightforward way of improving the approximation error and hence k-NN recall of ANNCUR but at the cost o
    
[^8]: 关于数据子群体间机器学习模型性能的非线性相关性

    On the nonlinear correlation of ML performance between data subpopulations. (arXiv:2305.02995v1 [cs.LG])

    [http://arxiv.org/abs/2305.02995](http://arxiv.org/abs/2305.02995)

    在不同数据子群体间，机器学习模型的内部准确性和外部准确性之间的相关性是非线性的，呈现出“月亮形”的相关性。

    

    理解机器学习模型在不同数据分布下的性能对于可靠的应用至关重要。尽管最新的经验研究认为训练数据内部的准确性和新数据外部的准确性之间存在近乎完美的线性相关性，但我们在各种数据集、模型和训练时期进行了严格的实验和分析，发现在子群体转移下，内部准确性和外部准确性之间的相关性更为微妙，并且在上升阶段存在“月亮形”的相关性（抛物线上升曲线）。

    Understanding the performance of machine learning (ML) models across diverse data distributions is critically important for reliable applications. Despite recent empirical studies positing a near-perfect linear correlation between in-distribution (ID) and out-of-distribution (OOD) accuracies, we empirically demonstrate that this correlation is more nuanced under subpopulation shifts. Through rigorous experimentation and analysis across a variety of datasets, models, and training epochs, we demonstrate that OOD performance often has a nonlinear correlation with ID performance in subpopulation shifts. Our findings, which contrast previous studies that have posited a linear correlation in model performance during distribution shifts, reveal a "moon shape" correlation (parabolic uptrend curve) between the test performance on the majority subpopulation and the minority subpopulation. This non-trivial nonlinear correlation holds across model architectures, hyperparameters, training durations
    
[^9]: SemEval-2023任务7: 临床试验数据的多证据自然语言推理

    SemEval-2023 Task 7: Multi-Evidence Natural Language Inference for Clinical Trial Data. (arXiv:2305.02993v1 [cs.CL])

    [http://arxiv.org/abs/2305.02993](http://arxiv.org/abs/2305.02993)

    本论文介绍SemEval 2023的任务七，旨在进行临床试验数据的多证据自然语言推理，该任务难度较大，证据选择任务相对于蕴含任务表现更佳。

    

    本篇论文介绍SemEval 2023任务7的结果，该任务主要涉及临床试验数据中的多证据自然语言推理（NLI4CT），由两个子任务组成：一个是自然语言推理（NLI）任务，另一个是证据选择任务。这两个任务需要进行医学和数字推理，这对于开发能够进行大规模医疗证据解释和检索、提供个性化基于证据的保健具有重要意义。第1个子任务“蕴含任务”收到了来自40位参赛者的643份提交，第2个子任务“证据选择任务”收到了来自23位参赛者的364份提交。这两个任务具有挑战性，大部分提交的系统在蕴含任务上未能明显优于大多数类基线，而我们观察到证据选择任务的表现明显优于蕴含任务。增加模型参数会导致模型在测试集上表现更差。

    This paper describes the results of SemEval 2023 task 7 -- Multi-Evidence Natural Language Inference for Clinical Trial Data (NLI4CT) -- consisting of 2 tasks, a Natural Language Inference (NLI) task, and an evidence selection task on clinical trial data. The proposed challenges require multi-hop biomedical and numerical reasoning, which are of significant importance to the development of systems capable of large-scale interpretation and retrieval of medical evidence, to provide personalized evidence-based care.  Task 1, the entailment task, received 643 submissions from 40 participants, and Task 2, the evidence selection task, received 364 submissions from 23 participants. The tasks are challenging, with the majority of submitted systems failing to significantly outperform the majority class baseline on the entailment task, and we observe significantly better performance on the evidence selection task than on the entailment task. Increasing the number of model parameters leads to a di
    
[^10]: 使用联合CTC损失和自监督预训练的声学编码器的端到端口语理解

    End-to-end spoken language understanding using joint CTC loss and self-supervised, pretrained acoustic encoders. (arXiv:2305.02937v1 [cs.CL])

    [http://arxiv.org/abs/2305.02937](http://arxiv.org/abs/2305.02937)

    本文提出了一种使用联合CTC损失和预训练声学编码器的基于端到端的口语理解模型，该方法实现了在两个数据集上超越SOTA模型的效果。

    

    在口语理解任务中，由于缺乏文本信息，直接从声音信号中提取语义意义是具有挑战性的。流行的端到端（E2E）口语理解模型利用序列到序列自动语音识别（ASR）模型提取文本嵌入作为输入来推断语义，但是这需要昂贵的自回归解码。在这项工作中，我们利用自监督声学编码器，Fine-tuned Connectionist Temporal Classification（CTC）来提取文本嵌入，并使用联合CTC和SLU损失进行话语级口语理解任务。实验表明，我们的模型在DSTC2数据集上对话行为分类模型取得了4％的绝对改进，并在SLURP数据集上超越了SOTA SLU模型1.3％的绝对改进。

    It is challenging to extract semantic meanings directly from audio signals in spoken language understanding (SLU), due to the lack of textual information. Popular end-to-end (E2E) SLU models utilize sequence-to-sequence automatic speech recognition (ASR) models to extract textual embeddings as input to infer semantics, which, however, require computationally expensive auto-regressive decoding. In this work, we leverage self-supervised acoustic encoders fine-tuned with Connectionist Temporal Classification (CTC) to extract textual embeddings and use joint CTC and SLU losses for utterance-level SLU tasks. Experiments show that our model achieves 4% absolute improvement over the the state-of-the-art (SOTA) dialogue act classification model on the DSTC2 dataset and 1.3% absolute improvement over the SOTA SLU model on the SLURP dataset.
    
[^11]: 自动发现的思维链提示可以推广到新模型和数据集

    An automatically discovered chain-of-thought prompt generalizes to novel models and datasets. (arXiv:2305.02897v1 [cs.CL])

    [http://arxiv.org/abs/2305.02897](http://arxiv.org/abs/2305.02897)

    本文研究了一系列零照顾提示在六个最新发布的语言模型和问题回答数据集的实验中的表现，发现自动提示发现的CoT提示可在新模型和数据集上表现良好，并在应用于GPT-4模型时取得最佳结果。

    

    新兴的思维链（CoT）推理能力有望提高大型语言模型（LLM）的性能和可解释性。然而，对于先前模型所制定的提示策略如何适用于新模型和不同数据集仍存在不确定性。在这项小型研究中，我们比较了一系列零照顾提示（zero-shot prompts）的性能，以诱导CoT推理，在6个最新发布的LLM（davinci-002，davinci-003，GPT-3.5-turbo，GPT-4，Flan-T5-xxl和Cohere command-xlarge）上与包括科学和医学领域的六个问答数据集混合在一起。我们发现，通过自动提示发现的CoT提示在实验条件下表现出鲁棒性，并在应用于最先进的GPT-4模型时产生最佳结果。

    Emergent chain-of-thought (CoT) reasoning capabilities promise to improve performance and explainability of large language models (LLMs). However, uncertainties remain about how prompting strategies formulated for previous model generations generalize to new model generations and different datasets. In this small-scale study we compare the performance of a range of zero-shot prompts for inducing CoT reasoning across six recently released LLMs (davinci-002, davinci-003, GPT-3.5-turbo, GPT-4, Flan-T5-xxl and Cohere command-xlarge) on a mixture of six question-answering datasets, including datasets from scientific and medical domains. We find that a CoT prompt that was previously discovered through automated prompt discovery shows robust performance across experimental conditions and produces best results when applied to the state-of-the-art model GPT-4.
    
[^12]: 通过掩码结构成长实现2倍语言模型预训练加速

    2x Faster Language Model Pre-training via Masked Structural Growth. (arXiv:2305.02869v1 [cs.CL])

    [http://arxiv.org/abs/2305.02869](http://arxiv.org/abs/2305.02869)

    本文提出了掩码结构成长（MSG），可以加速语言模型的预训练，其中包括全维度成长进程和独立于新权重初始化的函数严格保留成长操作。

    

    在当今自然语言处理研究中，加速大型语言模型预训练是一个关键问题。本文旨在通过从小型Transformer结构逐步扩展到大型结构，加快预训练进程。这种渐进式成长的主要研究问题有两个，即成长进程和成长操作。对于成长进程，现有研究已经探索了深度和前馈层的多阶段扩展，但每个维度对进程效率的影响仍然是一个未解决的问题。而对于成长操作，现有研究依赖于新权重的初始化来继承原有的知识，只实现了非严格的函数保留，从而限制了进一步的训练动态优化。为解决这些问题，本文提出了掩码结构成长（MSG），其中包括涉及所有可能维度的成长进程和独立于新权重初始化的函数严格保留成长操作。实验证明，MSG可显著加速语言模型预训练。

    Acceleration of large language model pre-training is a critical issue in present NLP research. In this paper, we focus on speeding up pre-training by progressively growing from a small Transformer structure to a large one. There are two main research problems related to progressive growth: growth schedule and growth operator. For growth schedule, existing work has explored multi-stage expansion of depth and feedforward layers. However, the impact of each dimension on the schedule's efficiency is still an open question. For growth operator, existing work relies on the initialization of new weights to inherit knowledge, and achieve only non-strict function preservation, limiting further optimization of training dynamics. To address these issues, we propose Masked Structural Growth (MSG), including growth schedules involving all possible dimensions and strictly function-preserving growth operators that is independent of the initialization of new weights. Experiments show that MSG is signi
    
[^13]: CausalAPM: 用于NLU去偏置的通用文本解缠框架

    CausalAPM: Generalizable Literal Disentanglement for NLU Debiasing. (arXiv:2305.02865v1 [cs.CL])

    [http://arxiv.org/abs/2305.02865](http://arxiv.org/abs/2305.02865)

    CausalAPM是一个通用的NLU文本解缠框架，它将文字和语义信息投射到独立的特征子空间中，并限制了文字信息在后续预测中的参与程度。该框架可以有效地应对数据集偏置问题，提高了推广性能而不损失性能水平。

    

    数据集偏置问题越来越引起人们对NLU模型推广能力的关注。本文从因果推断的角度分析了数据集偏置问题的原因，提出了CausalAPM，一种通用的文本解缠框架来解决偏置问题。该方法将文字和语义信息投射到独立的特征子空间中，并限制了文字信息在后续预测中的参与程度。在三个NLP基准测试中广泛的实验表明，我们的框架显著提高了OOD的推广性能，同时保持了ID的性能水平。

    Dataset bias, i.e., the over-reliance on dataset-specific literal heuristics, is getting increasing attention for its detrimental effect on the generalization ability of NLU models. Existing works focus on eliminating dataset bias by down-weighting problematic data in the training process, which induce the omission of valid feature information while mitigating bias. In this work, We analyze the causes of dataset bias from the perspective of causal inference and propose CausalAPM, a generalizable literal disentangling framework to ameliorate the bias problem from feature granularity. The proposed approach projects literal and semantic information into independent feature subspaces, and constrains the involvement of literal information in subsequent predictions. Extensive experiments on three NLP benchmarks (MNLI, FEVER, and QQP) demonstrate that our proposed framework significantly improves the OOD generalization performance while maintaining ID performance.
    
[^14]: ReMask：一种针对领域反事实生成的稳健信息遮盖方法

    ReMask: A Robust Information-Masking Approach for Domain Counterfactual Generation. (arXiv:2305.02858v1 [cs.CL])

    [http://arxiv.org/abs/2305.02858](http://arxiv.org/abs/2305.02858)

    本文提出一种三步领域混淆方法，包括基于频率和注意力规范的遮盖、遮盖领域特定提示信息，以及揭示领域通用上下文。实验证明这种方法在领域转移方面有较好效果。

    

    领域偏移是NLP中的一个重大挑战，因此许多方法采用学习领域不变特征来减轻推理阶段的领域偏移。然而，这种方法无法利用与任务相关的领域特定细微差别。为避免这种缺点，领域反事实生成旨在将源域中的文本转换为给定的目标域。然而，由于数据的有限性，这种基于频率的方法经常会错过一些有效和虚假的领域标记关联。因此，我们采用了一种三步领域混淆方法，其中包括基于频率和注意力规范的遮盖、遮盖领域特定提示信息，以及揭示领域通用上下文。我们的实验实证表明，来自我们遮盖文本的反事实样本在12个领域情感分类设置中有10个实现了改进的领域转移，相对于最先进技术平均提高了2%的准确率。

    Domain shift is a big challenge in NLP, thus, many approaches resort to learning domain-invariant features to mitigate the inference phase domain shift. Such methods, however, fail to leverage the domain-specific nuances relevant to the task at hand. To avoid such drawbacks, domain counterfactual generation aims to transform a text from the source domain to a given target domain. However, due to the limited availability of data, such frequency-based methods often miss and lead to some valid and spurious domain-token associations. Hence, we employ a three-step domain obfuscation approach that involves frequency and attention norm-based masking, to mask domain-specific cues, and unmasking to regain the domain generic context. Our experiments empirically show that the counterfactual samples sourced from our masked text lead to improved domain transfer on 10 out of 12 domain sentiment classification settings, with an average of 2% accuracy improvement over the state-of-the-art for unsuperv
    
[^15]: 基于语义空间的多属性可控对话生成中的加权解码

    Semantic Space Grounded Weighted Decoding for Multi-Attribute Controllable Dialogue Generation. (arXiv:2305.02820v1 [cs.CL])

    [http://arxiv.org/abs/2305.02820](http://arxiv.org/abs/2305.02820)

    该文介绍了名为DASC的可控生成框架，它利用属性语义空间的加权解码来实现多属性生成，并能够在多个方面实现最先进的控制精度和高质量的生成响应。

    

    控制聊天机器人生成具有个性、情感和对话行为等多个属性的话语是一个实际有用但鲜有研究的问题。我们提出了一种新颖的可控生成框架DASC，它通过加权解码范式具有强大的可控性，同时在属性语义空间的基础上提高了生成质量。然后，多属性生成通过多个属性嵌入的插值直观地实现。实验表明，DASC在三个方面可控生成任务中可以实现最先进的控制精度，同时产生有趣而合理的响应，即使在分布鲁棒性测试中也是如此。属性语义空间中学习到的有意义的表示的可视化也支持其有效性。

    Controlling chatbot utterance generation with multiple attributes such as personalities, emotions and dialogue acts is a practically useful but under-studied problem. We propose a novel controllable generation framework called DASC that possesses strong controllability with weighted decoding paradigm, while improving generation quality with the grounding in an attribute semantics space. Generation with multiple attributes is then intuitively implemented with an interpolation of multiple attribute embeddings. Experiments show that DASC can achieve state-of-the-art control accuracy in 3-aspect controllable generation tasks while also producing interesting and reasonably sensible responses, even if in an out-of-distribution robustness test. Visualization of the meaningful representations learned in the attribute semantic space also supports its effectiveness.
    
[^16]: 用变分自编码器和注意力机制实现可解释的句子表示

    Interpretable Sentence Representation with Variational Autoencoders and Attention. (arXiv:2305.02810v1 [cs.CL])

    [http://arxiv.org/abs/2305.02810](http://arxiv.org/abs/2305.02810)

    本论文提出了使用VAEs和Transformers构建两种具有归纳偏差的模型，用于提高自然语言处理中表示学习技术的解释性和数据效率，能够将潜在表示中的信息分离为可理解的概念。实验结果表明这些模型提供了直观且可解释的表示形式，具有实用性。

    

    本论文旨在增强自然语言处理中最近一些表示学习技术的解释性，同时考虑到缺乏注释数据的情况下进行研究的方法。我们选择利用变分自编码器（VAEs），因为它们在将观察结果与隐藏的生成因素联系起来方面很有效，并且在数据效率学习和可解释表示学习方面也很有效。我们首先删除半监督VAEs运行方案中的不必要组件，使得它们更快速、更小、更易于设计。其次，我们使用VAEs和Transformer构建了两个具有归纳偏差的模型，将潜在表示中的信息分离成可理解的概念，而不需要注释数据。我们的实验证明，这些模型提供了直观且可解释的表示形式，对自然语言处理中的下游任务非常有用。

    In this thesis, we develop methods to enhance the interpretability of recent representation learning techniques in natural language processing (NLP) while accounting for the unavailability of annotated data. We choose to leverage Variational Autoencoders (VAEs) due to their efficiency in relating observations to latent generative factors and their effectiveness in data-efficient learning and interpretable representation learning. As a first contribution, we identify and remove unnecessary components in the functioning scheme of semi-supervised VAEs making them faster, smaller and easier to design. Our second and main contribution is to use VAEs and Transformers to build two models with inductive bias to separate information in latent representations into understandable concepts without annotated data. The first model, Attention-Driven VAE (ADVAE), is able to separately represent and control information about syntactic roles in sentences. The second model, QKVAE, uses separate latent va
    
[^17]: 房间里的大象：分析大型科技公司在自然语言处理研究中的存在

    The Elephant in the Room: Analyzing the Presence of Big Tech in Natural Language Processing Research. (arXiv:2305.02797v1 [cs.CL])

    [http://arxiv.org/abs/2305.02797](http://arxiv.org/abs/2305.02797)

    本文研究了工业界在自然语言处理研究中的存在和影响。研究发现在过去五年中，工业界的存在与影响呈现急剧增长，一些公司占据了大部分出版物，并向学术研究人员提供资金支持。

    

    自然语言处理的深度学习方法的最新进展，创造了新的商业机会，并且使得NLP研究对产业发展至关重要。作为NLP领域的大玩家之一，连同政府和大学一起，跟踪产业对研究的影响非常重要。在本研究中，我们致力于量化和表征工业界在NLP社区中的存在。使用具有78,187篇NLP出版物和701个NLP作者简历的全面元数据语料库，我们探索了自上世纪90年代以来该领域中的工业存在。我们发现，NLP作者中的工业存在在过去五年中急剧增长（从2017年到2022年的增长率为180％）。一些公司占据了大部分出版物，并通过拨款和实习为学术研究人员提供资金支持。我们的研究表明，工业界对自然语言处理研究的存在和影响是显著的。

    Recent advances in deep learning methods for natural language processing (NLP) have created new business opportunities and made NLP research critical for industry development. As one of the big players in the field of NLP, together with governments and universities, it is important to track the influence of industry on research. In this study, we seek to quantify and characterize industry presence in the NLP community over time. Using a corpus with comprehensive metadata of 78,187 NLP publications and 701 resumes of NLP publication authors, we explore the industry presence in the field since the early 90s. We find that industry presence among NLP authors has been steady before a steep increase over the past five years (180% growth from 2017 to 2022). A few companies account for most of the publications and provide funding to academic researchers through grants and internships. Our study shows that the presence and impact of the industry on natural language processing research are signi
    
[^18]: BranchNorm: 鲁棒地扩展极深的Transformer

    BranchNorm: Robustly Scaling Extremely Deep Transformers. (arXiv:2305.02790v1 [cs.LG])

    [http://arxiv.org/abs/2305.02790](http://arxiv.org/abs/2305.02790)

    BranchNorm提出了一种新的方法，通过动态重新调整Transformer的非残差分支，理论上稳定了训练，并在随后的训练阶段中促进了更好的收敛。实验结果表明，BranchNorm在训练稳定性和收敛性能之间取得了更好的平衡。

    

    最近，DeepNorm将Transformer扩展到极深（即1000层），展示了深度扩展的潜力。为了稳定深度模型的训练，DeepNorm试图将模型更新约束为一个恒定值。尽管应用这种约束可以使模型在早期训练阶段受益，但可能导致整个训练过程中模型训练不足。在本文中，我们提出了BranchNorm，它根据训练期间动态重新调整Transformer的非残差分支。BranchNorm不仅在早期阶段理论上稳定了训练，而且在随后的训练阶段中促进了更好的收敛。多个翻译任务的实验结果表明，BranchNorm在训练稳定性和收敛性能之间取得了更好的平衡。

    Recently, DeepNorm scales Transformers into extremely deep (i.e., 1000 layers) and reveals the promising potential of deep scaling. To stabilize the training of deep models, DeepNorm (Wang et al., 2022) attempts to constrain the model update to a constant value. Although applying such a constraint can benefit the early stage of model training, it may lead to undertrained models during the whole training procedure. In this paper, we propose BranchNorm, which dynamically rescales the non-residual branch of Transformer in accordance with the training period. BranchNorm not only theoretically stabilizes the training with smooth gradient norms at the early stage, but also encourages better convergence in the subsequent training stage. Experiment results on multiple translation tasks demonstrate that BranchNorm achieves a better trade-off between training stability and converge performance.
    
[^19]: 大语言模型在信息技术任务中自动生成YAML代码

    Automated Code generation for Information Technology Tasks in YAML through Large Language Models. (arXiv:2305.02783v1 [cs.SE])

    [http://arxiv.org/abs/2305.02783](http://arxiv.org/abs/2305.02783)

    这项研究提出了一种名为Ansible Wisdom的自然语言转Ansible-YAML代码的工具，可自动化生成Ansible脚本，提高IT自动化生产力，并相比现有技术达到或更好的性能水平。

    

    由于大语言模型在代码生成方面的不断提升，在通用编程语言方面的受益最大，而针对IT自动化等领域特定语言的研究较少。本研究聚焦于Ansible-YAML的生成，提出了一种名为Ansible Wisdom的自然语言转Ansible-YAML代码的工具，旨在提高IT自动化生产力。研究采用基于Transformer的模型，并通过新的包含Ansible-YAML的数据集进行扩展训练。同时，还开发了两个用于捕捉此领域特征的YAML和Ansible性能指标。结果表明，Ansible Wisdom可以精确地从自然语言提示中生成Ansible脚本，并且其性能可与现有技术的状态相媲美或更好。

    The recent improvement in code generation capabilities due to the use of large language models has mainly benefited general purpose programming languages. Domain specific languages, such as the ones used for IT Automation, have received far less attention, despite involving many active developers and being an essential component of modern cloud platforms. This work focuses on the generation of Ansible-YAML, a widely used markup language for IT Automation. We present Ansible Wisdom, a natural-language to Ansible-YAML code generation tool, aimed at improving IT automation productivity. Ansible Wisdom is a transformer-based model, extended by training with a new dataset containing Ansible-YAML. We also develop two novel performance metrics for YAML and Ansible to capture the specific characteristics of this domain. Results show that Ansible Wisdom can accurately generate Ansible script from natural language prompts with performance comparable or better than existing state of the art code 
    
[^20]: 各种神经机器翻译的统一模型学习

    Unified Model Learning for Various Neural Machine Translation. (arXiv:2305.02777v1 [cs.CL])

    [http://arxiv.org/abs/2305.02777](http://arxiv.org/abs/2305.02777)

    本文提出了一种统一学习方法，即统一模型学习，可以同时适用于翻译各种任务数据，并实现智能按需翻译，相对现有的特定数据集模型能够得到明显的改进。

    

    现有的神经机器翻译(NMT)研究主要集中在根据来自不同任务(例如，文档翻译和聊天翻译)的数据开发特定于数据集的模型。虽然特定于数据集的模型已经取得了令人瞩目的性能，但每个数据集需要设计、训练和存储一个模型，这很麻烦。在这项工作中，我们的目标是将这些翻译任务统一到更普遍的设置中。具体而言，我们提出了一个“多才多艺”的模型，即适用于不同任务数据的统一模型学习(NMT)，可以同时在多种环境下进行良好的翻译，并在理论上可以尽可能多地扩展。通过统一学习，UMLNMT能够跨多个任务进行联合训练，实现智能按需翻译。在七个广泛使用的翻译任务，包括句子翻译、文档翻译和聊天翻译中，我们的UMLNMT相对于特定数据集模型表现出了明显的改进。

    Existing neural machine translation (NMT) studies mainly focus on developing dataset-specific models based on data from different tasks (e.g., document translation and chat translation). Although the dataset-specific models have achieved impressive performance, it is cumbersome as each dataset demands a model to be designed, trained, and stored. In this work, we aim to unify these translation tasks into a more general setting. Specifically, we propose a ``versatile'' model, i.e., the Unified Model Learning for NMT (UMLNMT) that works with data from different tasks, and can translate well in multiple settings simultaneously, and theoretically it can be as many as possible. Through unified learning, UMLNMT is able to jointly train across multiple tasks, implementing intelligent on-demand translation. On seven widely-used translation tasks, including sentence translation, document translation, and chat translation, our UMLNMT results in substantial improvements over dataset-specific model
    
[^21]: 语言选择的政治：俄乌战争如何影响乌克兰人在 Twitter 上的语言使用。

    The Politics of Language Choice: How the Russian-Ukrainian War Influences Ukrainians' Language Use on Twitter. (arXiv:2305.02770v1 [cs.CY])

    [http://arxiv.org/abs/2305.02770](http://arxiv.org/abs/2305.02770)

    本文研究了俄乌战争期间乌克兰人在 Twitter 上的语言使用，发现在战争爆发前已经出现从俄语向乌克兰语转变的趋势，而战争爆发后这种趋势加速了，并且许多使用俄语的用户在战争期间转变成使用乌克兰语。

    

    语言使用天生是政治的，并经常用作文化身份的载体，同时也是国家建设的基础。本文研究了俄乌战争期间（2020年1月至2022年10月），基于超过62,000位用户发布的400万条地理标记推文中，乌克兰公民的语言选择和推文活动。使用统计模型，区分了Twitter上用户的流入流出所引起的样本效应和用户行为变化所引起的行为效应。我们观察到，在战争爆发之前已经有一个稳定的从俄语向乌克兰语的转变，而这一过程在战争爆发后迅速加速。我们将这些变化主要归因于用户行为的改变。值得注意的是，许多使用俄语的用户在战争期间会转变成使用乌克兰语。

    The use of language is innately political and often a vehicle of cultural identity as well as the basis for nation building. Here, we examine language choice and tweeting activity of Ukrainian citizens based on more than 4 million geo-tagged tweets from over 62,000 users before and during the Russian-Ukrainian War, from January 2020 to October 2022. Using statistical models, we disentangle sample effects, arising from the in- and outflux of users on Twitter, from behavioural effects, arising from behavioural changes of the users. We observe a steady shift from the Russian language towards the Ukrainian language already before the war, which drastically speeds up with its outbreak. We attribute these shifts in large part to users' behavioural changes. Notably, we find that many Russian-tweeting users perform a hard-switch to Ukrainian as a result of the war.
    
[^22]: VendorLink：一种NLP方法用于识别和链接暗网市场上的供应商被迁移和潜在别名

    VendorLink: An NLP approach for Identifying & Linking Vendor Migrants & Potential Aliases on Darknet Markets. (arXiv:2305.02763v1 [cs.CY])

    [http://arxiv.org/abs/2305.02763](http://arxiv.org/abs/2305.02763)

    本论文提出了一种名为VendorLink的NLP方法，能够有效地识别和链接暗网市场上的供应商被迁移和潜在别名，减少非法市场的匿名性，具有重要的实际意义。

    

    暗网上的匿名性使得供应商可以使用多个供应商别名或频繁迁移市场而不被发现。因此，在暗网上发现非法市场及其联系人是具有挑战性的。为了识别非法市场和供应商之间的关系，我们提出了VendorLink，这是一种基于NLP的方法，通过检查写作模式来验证、识别和链接七个公共暗网市场上的唯一供应商帐户。与现有文献不同，VendorLink利用有监督的预训练的优势来执行封闭集供应商验证、开放集供应商识别和低资源市场适应任务。通过VendorLink，我们在Alphabay-Dreams-Silk数据集中揭示了15个移民和71个潜在别名，在Valhalla-Berlusconi数据集中揭示了17个移民和3个潜在别名，在Traderoute-Agora数据集中揭示了75个移民和10个潜在别名。

    The anonymity on the Darknet allows vendors to stay undetected by using multiple vendor aliases or frequently migrating between markets. Consequently, illegal markets and their connections are challenging to uncover on the Darknet. To identify relationships between illegal markets and their vendors, we propose VendorLink, an NLP-based approach that examines writing patterns to verify, identify, and link unique vendor accounts across text advertisements (ads) on seven public Darknet markets. In contrast to existing literature, VendorLink utilizes the strength of supervised pre-training to perform closed-set vendor verification, open-set vendor identification, and low-resource market adaption tasks. Through VendorLink, we uncover (i) 15 migrants and 71 potential aliases in the Alphabay-Dreams-Silk dataset, (ii) 17 migrants and 3 potential aliases in the Valhalla-Berlusconi dataset, and (iii) 75 migrants and 10 potential aliases in the Traderoute-Agora dataset. Altogether, our approach ca
    
[^23]: 主动对话系统综述：问题、方法和展望

    A Survey on Proactive Dialogue Systems: Problems, Methods, and Prospects. (arXiv:2305.02750v1 [cs.CL])

    [http://arxiv.org/abs/2305.02750](http://arxiv.org/abs/2305.02750)

    本综述全面概述了不同类型对话中对话代理主动性的突出问题和先进设计，讨论了符合实际应用需求但需要未来更大研究重点的挑战，激发更多的会话 AI 进展到下一级别。

    

    主动对话系统与广泛的现实世界对话应用相关，使对话代理能够引导对话方向，以实现预定义的目标或满足系统方面的特定目标。它通过先进技术赋能以进展到需要战略性和激励性交互的更复杂任务。在本综述中，我们全面概述了不同类型对话中对话代理主动性的突出问题和先进设计。此外，我们还讨论了符合实际应用需求但需要未来更大研究重点的挑战。我们希望这篇主动对话系统的第一篇综述可以为社区提供快速访问和整体图片，激发更多的会话 AI 进展到下一级别。

    Proactive dialogue systems, related to a wide range of real-world conversational applications, equip the conversational agent with the capability of leading the conversation direction towards achieving pre-defined targets or fulfilling certain goals from the system side. It is empowered by advanced techniques to progress to more complicated tasks that require strategical and motivational interactions. In this survey, we provide a comprehensive overview of the prominent problems and advanced designs for conversational agent's proactivity in different types of dialogues. Furthermore, we discuss challenges that meet the real-world application needs but require a greater research focus in the future. We hope that this first survey of proactive dialogue systems can provide the community with a quick access and an overall picture to this practical problem, and stimulate more progresses on conversational AI to the next level.
    
[^24]: 无监督对话主题分割及话语表示中主题感知方法

    Unsupervised Dialogue Topic Segmentation with Topic-aware Utterance Representation. (arXiv:2305.02747v1 [cs.CL])

    [http://arxiv.org/abs/2305.02747](http://arxiv.org/abs/2305.02747)

    本文提出一种利用未标记的对话数据进行无监督对话主题分割的方法，通过邻近话语匹配和伪分割学习主题感知的话语表示，实验显示其明显优于强基准方法。

    

    对话主题分割在各种对话建模任务中起着重要作用。现有的DTS方法要么关注语义相似性，要么关注对话连贯性来评估主题相似性以进行无监督对话分割。但主题相似性不能通过语义相似性或对话连贯性的方式来完全识别。此外，未标记的对话数据中包含有用的话语关系提示，但这些提示未被充分利用。在本文中，我们提出了一种新颖的无监督DTS框架，通过邻近话语匹配和伪分割从未标记的对话数据中学习主题感知的话语表示。在两个基准数据集（DialSeg711和Doc2Dial）上的广泛实验表明，我们的方法显著优于强基准方法。为了可复现性，我们在https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/dial-start上提供了我们的代码和数据。

    Dialogue Topic Segmentation (DTS) plays an essential role in a variety of dialogue modeling tasks. Previous DTS methods either focus on semantic similarity or dialogue coherence to assess topic similarity for unsupervised dialogue segmentation. However, the topic similarity cannot be fully identified via semantic similarity or dialogue coherence. In addition, the unlabeled dialogue data, which contains useful clues of utterance relationships, remains underexploited. In this paper, we propose a novel unsupervised DTS framework, which learns topic-aware utterance representations from unlabeled dialogue data through neighboring utterance matching and pseudo-segmentation. Extensive experiments on two benchmark datasets (i.e., DialSeg711 and Doc2Dial) demonstrate that our method significantly outperforms the strong baseline methods. For reproducibility, we provide our code and data at:https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/dial-start.
    
[^25]: 面向任务型对话系统的异步更新强化学习框架

    An Asynchronous Updating Reinforcement Learning Framework for Task-oriented Dialog System. (arXiv:2305.02718v1 [cs.CL])

    [http://arxiv.org/abs/2305.02718](http://arxiv.org/abs/2305.02718)

    本文提出了一种异步更新强化学习框架 (AURL) 来训练面向任务型对话系统，解决了不同模块互相影响的问题。同时，采用课程学习来解决数据分布不平衡问题，并引入多个用户模型来增加对话的多样性。该方法在公共数据集上取得了31.37%的对话成功率改进。

    

    许多对话系统中已经应用了强化学习来进行训练。先前的方法将对话系统分成多个模块，包括对话状态跟踪 (DST) 和对话策略 (DP)，并同时训练这些模块。然而，不同模块在训练过程中会相互影响。来自 DST 的误差可能会误导对话策略，系统操作也会给 DST 模块带来额外的困难。为了缓解这个问题，我们提出了一种异步更新强化学习框架 (AURL)，在合作设置下异步地更新 DST 模块和 DP 模块。此外，采用课程学习来解决强化学习采样过程中的数据分布不平衡问题，并引入多个用户模型来增加对话的多样性。公共 SSD-PHONE 数据集上的结果表明，我们的方法在对话成功率方面取得了显著的31.37%改进。代码可在 https://github.com/thu-coai/AURL-Dialog-System 上获得。

    Reinforcement learning has been applied to train the dialog systems in many works. Previous approaches divide the dialog system into multiple modules including DST (dialog state tracking) and DP (dialog policy), and train these modules simultaneously. However, different modules influence each other during training. The errors from DST might misguide the dialog policy, and the system action brings extra difficulties for the DST module. To alleviate this problem, we propose Asynchronous Updating Reinforcement Learning framework (AURL) that updates the DST module and the DP module asynchronously under a cooperative setting. Furthermore, curriculum learning is implemented to address the problem of unbalanced data distribution during reinforcement learning sampling, and multiple user models are introduced to increase the dialog diversity. Results on the public SSD-PHONE dataset show that our method achieves a compelling result with a 31.37% improvement on the dialog success rate. The code i
    
[^26]: 大数据和大数的解释：解读齐普夫定律

    Big Data and Large Numbers. Interpreting Zipf's Law. (arXiv:2305.02687v1 [physics.soc-ph])

    [http://arxiv.org/abs/2305.02687](http://arxiv.org/abs/2305.02687)

    该论文揭示了大数性质对于解释齐普夫定律的影响，指出齐普夫定律噪音是这种影响的例子，并分析了权力分布和类似分布在种群是有限的、排名和元素计数是自然数的情况下的特性。

    

    一些大数据领域的实证事实属于大数性质的影响。齐普夫定律噪音就是这种现象的例子。我们揭示了权力分布和类似分布的几个特性，这些分布发生在种群是有限的、排名和元素计数是自然数的情况下。讨论了这些特性对解释齐普夫定律的影响。

    It turns out that some empirical facts in Big Data are the effects of properties of large numbers. Zipf's law noise is an example of such an artefact. We expose several properties of the power law distributions and of similar distribution that occur when the population is finite and the rank and counts of elements in the population are natural numbers. Consequences in the interpretation of Zipf's law are discussed.
    
[^27]: 相邻单词影响人类对显著性解释的理解

    Neighboring Words Affect Human Interpretation of Saliency Explanations. (arXiv:2305.02679v1 [cs.CL])

    [http://arxiv.org/abs/2305.02679](http://arxiv.org/abs/2305.02679)

    相邻单词可以影响解释者对单词重要性的理解，应该考虑文本中其他因素的影响来替代单词级别的显著性解释方法。

    

    单词级别的显著性解释（“单词热图”）经常用于在基于文本的模型中传达特征归因。最近的研究发现，诸如单词长度等表面因素可能会扭曲传达的显著性评分的人类解读。我们进行了一项用户研究，以研究一个单词的相邻单词的标记如何影响解释者对显著性解释中单词的重要性的感知。我们发现相邻单词对单词的重要性评分有显著影响。具体来说，我们确定了影响基于相邻方向（左侧与右侧）以及短语和搭配的先验语言和计算度量值（与不相关的相邻单词）。我们的结果让人质疑在文本为基础的显著性解释是否应该继续在单词级别上进行传达，并为替代显著性解释方法的未来研究提供信息。

    Word-level saliency explanations ("heat maps over words") are often used to communicate feature-attribution in text-based models. Recent studies found that superficial factors such as word length can distort human interpretation of the communicated saliency scores. We conduct a user study to investigate how the marking of a word's neighboring words affect the explainee's perception of the word's importance in the context of a saliency explanation. We find that neighboring words have significant effects on the word's importance rating. Concretely, we identify that the influence changes based on neighboring direction (left vs. right) and a-priori linguistic and computational measures of phrases and collocations (vs. unrelated neighboring words). Our results question whether text-based saliency explanations should be continued to be communicated at word level, and inform future research on alternative saliency explanation methods.
    
[^28]: 学习多语机器翻译的语言特异层

    Learning Language-Specific Layers for Multilingual Machine Translation. (arXiv:2305.02665v1 [cs.CL])

    [http://arxiv.org/abs/2305.02665](http://arxiv.org/abs/2305.02665)

    本文介绍了语言特异Transformer层（LSLs），这使我们能够增加模型容量，同时保持正向传递中使用的计算量和参数数量不变，从而提高多语机器翻译的质量。

    

    多语机器翻译可以提高非英语语言之间的翻译质量，在许多方面都有优势，例如更低的延迟（无需翻译两次）和减少错误级联（例如，在通过英语进行翻译时避免丢失性别和礼貌等信息）。但是，添加更多语言会减少每种语言的模型容量，通常通过增加总体模型大小来抵消，从而使训练更加困难，推理速度变慢。在这项工作中，我们引入了语言特异Transformer层（LSLs），它们使我们能够增加模型容量，同时保持正向传递中使用的计算量和参数数量不变。关键思想是让编码器的某些层为源语言或目标语言特异，同时保持其余层共享。我们使用神经架构搜索启发式方法研究了放置这些层的最佳方法，并实现了1.3 chrF（1.5 spBLE）的改进。

    Multilingual Machine Translation promises to improve translation quality between non-English languages. This is advantageous for several reasons, namely lower latency (no need to translate twice), and reduced error cascades (e.g., avoiding losing gender and formality information when translating through English). On the downside, adding more languages reduces model capacity per language, which is usually countered by increasing the overall model size, making training harder and inference slower. In this work, we introduce Language-Specific Transformer Layers (LSLs), which allow us to increase model capacity, while keeping the amount of computation and the number of parameters used in the forward pass constant. The key idea is to have some layers of the encoder be source or target language-specific, while keeping the remaining layers shared. We study the best way to place these layers using a neural architecture search inspired approach, and achieve an improvement of 1.3 chrF (1.5 spBLE
    
[^29]: 面向跨数据集的弱监督仇恨言论分类

    Towards Weakly-Supervised Hate Speech Classification Across Datasets. (arXiv:2305.02637v1 [cs.CL])

    [http://arxiv.org/abs/2305.02637](http://arxiv.org/abs/2305.02637)

    该论文提出使用极度弱的监督方法，只依赖于类别名称而不是注释数据中的类别示例，解决当前仇恨言论识别的研究存在的数据创建策略不系统和不同注释方案问题，并展示了有效性。

    

    如多位学者指出的那样，当前针对仇恨言论（HS）识别的研究特点是不系统的数据创建策略和不同的注释方案。因此，监督学习模型往往对它们未被训练的数据集进行泛化性能差，并且不同HS分类法标记的数据集所训练的模型的性能无法比较。为了解决这个问题，我们提出了一种极度弱的监督方法，只依赖于类别名称而不是注释数据中的类别示例。我们展示了一种最先进的弱监督文本分类模型在各种数据集内和跨数据集的情况下的有效性。此外，我们对HS分类模型通用性较差的原因进行了深入的定量和定性分析。

    As pointed out by several scholars, current research on hate speech (HS) recognition is characterized by unsystematic data creation strategies and diverging annotation schemata. Subsequently, supervised-learning models tend to generalize poorly to datasets they were not trained on, and the performance of the models trained on datasets labeled using different HS taxonomies cannot be compared. To ease this problem, we propose applying extremely weak supervision that only relies on the class name rather than on class samples from the annotated data. We demonstrate the effectiveness of a state-of-the-art weakly-supervised text classification model in various in-dataset and cross-dataset settings. Furthermore, we conduct an in-depth quantitative and qualitative analysis of the source of poor generalizability of HS classification models.
    
[^30]: 符合语言模型的核心抽样

    Conformal Nucleus Sampling. (arXiv:2305.02633v1 [cs.CL])

    [http://arxiv.org/abs/2305.02633](http://arxiv.org/abs/2305.02633)

    本研究探讨了符合语言模型的核心抽样，并采用符合性预测进行校准。结果表明，OPT模型过于自信，并且校准显示出中度的逆比例缩放与模型大小。

    

    语言模型生成文本的过程是基于依次抽样下一个单词。基于核心（top-p）抽样的解码过程会从最小可能的单词集中选择，这些单词的累计概率超过概率p。在本研究中，我们评估了在各种语言环境下，top-p集是否真正与其概率含义对齐。我们采用了符合性预测，这是一种校准程序，根据所需的置信水平，专注于构建最小预测集，以校准参数p作为下一个单词分布熵的函数。我们发现OPT模型过于自信，校准显示出中度的逆比例缩放与模型大小。

    Language models generate text based on successively sampling the next word. A decoding procedure based on nucleus (top-$p$) sampling chooses from the smallest possible set of words whose cumulative probability exceeds the probability $p$. In this work, we assess whether a top-$p$ set is indeed aligned with its probabilistic meaning in various linguistic contexts. We employ conformal prediction, a calibration procedure that focuses on the construction of minimal prediction sets according to a desired confidence level, to calibrate the parameter $p$ as a function of the entropy of the next word distribution. We find that OPT models are overconfident, and that calibration shows a moderate inverse scaling with model size.
    
[^31]: 一种社交学习代理中语言出现与分析的框架

    A framework for the emergence and analysis of language in social learning agents. (arXiv:2305.02632v1 [cs.CL])

    [http://arxiv.org/abs/2305.02632](http://arxiv.org/abs/2305.02632)

    本研究提出了一个模拟语言特征的通信协议，用于分析个体和共享抽象的形成及其对任务表现的影响。通过优化信息内容以最大化学生奖励改善了信息编码，提高了学习表现。

    

    人工神经网络（ANNs）越来越被用作研究模型，但它们的普适性和表征不变性仍存在问题。生物神经网络在社交约束下演化形成可传达的表征，展示了泛化能力。本研究提出了一种合作代理之间的通信协议，用于分析个体和共享抽象的形成及其对任务表现的影响。该通信协议旨在通过低维表示编码高维信息，模拟语言特征。使用网格世界迷宫和强化学习，教师ANNs向学生ANN传递压缩消息，以便更好地完成任务。通过这种方式，学生实现了更高的目标发现率，并在不同的任务世界中推广了目标位置。进一步优化信息内容以最大化学生奖励改善了信息编码，表明精确的表征可以在通信协议中得到实现。

    Artificial neural networks (ANNs) are increasingly used as research models, but questions remain about their generalizability and representational invariance. Biological neural networks under social constraints evolved to enable communicable representations, demonstrating generalization capabilities. This study proposes a communication protocol between cooperative agents to analyze the formation of individual and shared abstractions and their impact on task performance. This communication protocol aims to mimic language features by encoding high-dimensional information through low-dimensional representation. Using grid-world mazes and reinforcement learning, teacher ANNs pass a compressed message to a student ANN for better task completion. Through this, the student achieves a higher goal-finding rate and generalizes the goal location across task worlds. Further optimizing message content to maximize student reward improves information encoding, suggesting that an accurate representati
    
[^32]: 会话中的情感推理：因果发现方法的应用

    Affective Reasoning at Utterance Level in Conversations: A Causal Discovery Approach. (arXiv:2305.02615v1 [cs.CL])

    [http://arxiv.org/abs/2305.02615](http://arxiv.org/abs/2305.02615)

    本文提出了一种新的会话情感因果发现方法（CACD），并通过设计公共骨架和生成替代隐含原因解决了因果模型的不确定性和隐含原因的不可观察性的问题。这种方法可以在变长会话中发现因果关系。

    

    情感推理任务是包括会话中的情感识别、情感-原因对抽取和情感-原因跨度识别在内的一组新兴的基于情感的任务。现有的方法在假设表面关系时忽略了基本的因果模型，因为骨架的不确定性和隐含原因的不可观察性。本文解决了上述两个问题，并进一步提出了会话情感因果发现（CACD）方法。这是一种新颖的因果发现方法，展示了如何通过设计公共骨架和生成替代隐含原因来发现会话中的因果关系。CACD包含两个步骤：（i）为变长会话中的所有话语建立一个中心化的单一图节点因果骨架；（ii）因果自编码器（CAE）通过生成隐含原因和已知显式原因来修正骨架，从而产生因果表示。

    The affective reasoning task is a set of emerging affect-based tasks in conversation, including Emotion Recognition in Conversation (ERC),Emotion-Cause Pair Extraction (ECPE), and Emotion-Cause Span Recognition (ECSR). Existing methods make various assumptions on the apparent relationship while neglecting the essential causal model due to the nonuniqueness of skeletons and unobservability of implicit causes. This paper settled down the above two problems and further proposed Conversational Affective Causal Discovery (CACD). It is a novel causal discovery method showing how to discover causal relationships in a conversation via designing a common skeleton and generating a substitute for implicit causes. CACD contains two steps: (i) building a common centering one graph node causal skeleton for all utterances in variable-length conversations; (ii) Causal Auto-Encoder (CAE) correcting the skeleton to yield causal representation through generated implicit causes and known explicit causes. 
    
[^33]: SemEval-2023任务12中的低资源语言文本分类：通过多语言预训练语言模型微调

    DN at SemEval-2023 Task 12: Low-Resource Language Text Classification via Multilingual Pretrained Language Model Fine-tuning. (arXiv:2305.02607v1 [cs.CL])

    [http://arxiv.org/abs/2305.02607](http://arxiv.org/abs/2305.02607)

    该论文介绍了针对SemEval-2023低资源非洲语言文本分类任务的解决方案，使用多语言预训练语言模型进行微调取得了第三名成绩，并突显了开发针对低资源语言的有效方法的重要性。

    

    最近几年，情感分析在自然语言处理中变得非常重要。然而，大部分用于情感分析的模型和数据集都是针对高资源语言，比如英语和中文开发的，而低资源语言，特别是非洲语言，往往鲜有研究。AfriSenti-SemEval 2023共享任务12旨在填补这一空白，通过在低资源的非洲语言上评估情感分析模型。在本文中，我们介绍了我们针对共享任务的解决方案，我们使用了不同的多语言XLM-R模型，并使用在非洲方言上重新训练并在目标语言上微调的分类头训练了这些模型。我们的团队在Subtask B，Track 16: Multilingual中取得了第三好的成绩，证明了我们的方法的有效性。虽然我们的模型在多语言数据上表现出了相对不错的结果，但在某些语言上表现较差。我们的发现强调了开发更多针对低资源语言的有效方法的重要性。

    In recent years, sentiment analysis has gained significant importance in natural language processing. However, most existing models and datasets for sentiment analysis are developed for high-resource languages, such as English and Chinese, leaving low-resource languages, particularly African languages, largely unexplored. The AfriSenti-SemEval 2023 Shared Task 12 aims to fill this gap by evaluating sentiment analysis models on low-resource African languages. In this paper, we present our solution to the shared task, where we employed different multilingual XLM-R models with classification head trained on various data, including those retrained in African dialects and fine-tuned on target languages. Our team achieved the third-best results in Subtask B, Track 16: Multilingual, demonstrating the effectiveness of our approach. While our model showed relatively good results on multilingual data, it performed poorly in some languages. Our findings highlight the importance of developing more
    
[^34]: 从统计方法到深度学习，自动关键词预测：一次综述

    From Statistical Methods to Deep Learning, Automatic Keyphrase Prediction: A Survey. (arXiv:2305.02579v1 [cs.CL])

    [http://arxiv.org/abs/2305.02579](http://arxiv.org/abs/2305.02579)

    本文综述了关键词预测的代表性研究，分析了主要模型、数据集和评估指标，特别关注了基于深度学习的关键词预测，并进行了实验比较代表性模型，为深入分析它们的优缺点提供了可比性的数据支持。

    

    关键词预测旨在生成高度总结给定文档的短语（关键词）。近年来，研究人员从不同的视角对这个任务进行了深入的研究。本文从主要模型、数据集和评估指标的角度全面总结了代表性的研究。我们分析了多达167篇先前的作品，比以前的调查实现了更大范围的覆盖。特别是，我们高度关注基于深度学习的关键词预测，在近年来引起了越来越多的关注。此外，我们进行了几组实验，仔细比较了代表性模型。据我们所知，我们的工作是第一个使用相同常用数据集和评估指标来比较这些模型的尝试，有助于深入分析它们的优缺点。最后，我们讨论了未来该任务的可能研究方向。

    Keyphrase prediction aims to generate phrases (keyphrases) that highly summarizes a given document. Recently, researchers have conducted in-depth studies on this task from various perspectives. In this paper, we comprehensively summarize representative studies from the perspectives of dominant models, datasets and evaluation metrics. Our work analyzes up to 167 previous works, achieving greater coverage of this task than previous surveys. Particularly, we focus highly on deep learning-based keyphrase prediction, which attracts increasing attention of this task in recent years. Afterwards, we conduct several groups of experiments to carefully compare representative models. To the best of our knowledge, our work is the first attempt to compare these models using the identical commonly-used datasets and evaluation metric, facilitating in-depth analyses of their disadvantages and advantages. Finally, we discuss the possible research directions of this task in the future.
    
[^35]: RetroMAE-2：用于预训练检索导向语言模型的双工掩码自动编码器

    RetroMAE-2: Duplex Masked Auto-Encoder For Pre-Training Retrieval-Oriented Language Models. (arXiv:2305.02564v1 [cs.CL])

    [http://arxiv.org/abs/2305.02564](http://arxiv.org/abs/2305.02564)

    本文提出了一种名为DupMAE的预训练方法，利用两个自动编码任务来提高语义表示质量，扩展了当前方法，使所有上下文嵌入都可以用于联合预训练检索任务。

    

    为了更好地支持信息检索任务，例如网络搜索和开放领域问答，人们正在努力开发检索导向语言模型，例如RetroMAE和许多其他模型。本文提出了一种新的预训练方法，称为DupMAE，旨在提高预训练模型的所有上下文嵌入的语义表示质量。它利用了两个互补的自动编码任务：一个基于[CLS]嵌入重建输入句子。

    To better support information retrieval tasks such as web search and open-domain question answering, growing effort is made to develop retrieval-oriented language models, e.g., RetroMAE and many others. Most of the existing works focus on improving the semantic representation capability for the contextualized embedding of the [CLS] token. However, recent study shows that the ordinary tokens besides [CLS] may provide extra information, which help to produce a better representation effect. As such, it's necessary to extend the current methods where all contextualized embeddings can be jointly pre-trained for the retrieval tasks. In this work, we propose a novel pre-training method called Duplex Masked Auto-Encoder, a.k.a. DupMAE. It is designed to improve the quality of semantic representation where all contextualized embeddings of the pre-trained model can be leveraged. It takes advantage of two complementary auto-encoding tasks: one reconstructs the input sentence on top of the [CLS] e
    
[^36]: 以计算语言学视角分析香港的法律判决

    Analyzing Hong Kong's Legal Judgments from a Computational Linguistics point-of-view. (arXiv:2305.02558v1 [cs.CL])

    [http://arxiv.org/abs/2305.02558](http://arxiv.org/abs/2305.02558)

    本文提供了多种基于统计、机器学习和深度学习等方法来有效地分析香港的法律判决，并从中提取关键信息，解决了价格高和资源缺乏的问题。

    

    利用计算语言学从法律判决中提取有用信息是信息检索领域早期提出的问题之一。目前，存在多个商业供应商自动化执行这些任务。然而，在分析香港法院系统的判决时，存在价格过高和缺乏资源的关键瓶颈。本文提供了几种基于统计学、机器学习、深度学习和零样本学习的方法，以有效地分析香港法院系统的法律判决。所提出的方法包括：（1）引文网络图生成，（2）PageRank算法，（3）关键词分析和摘要，（4）情感极性，以及（5）段落分类，以便能够提取单个判决以及群体判决的关键见解。这将使对香港判决的整体分析变得不那么繁琐。

    Analysis and extraction of useful information from legal judgments using computational linguistics was one of the earliest problems posed in the domain of information retrieval. Presently, several commercial vendors exist who automate such tasks. However, a crucial bottleneck arises in the form of exorbitant pricing and lack of resources available in analysis of judgements mete out by Hong Kong's Legal System. This paper attempts to bridge this gap by providing several statistical, machine learning, deep learning and zero-shot learning based methods to effectively analyze legal judgments from Hong Kong's Court System. The methods proposed consists of: (1) Citation Network Graph Generation, (2) PageRank Algorithm, (3) Keyword Analysis and Summarization, (4) Sentiment Polarity, and (5) Paragrah Classification, in order to be able to extract key insights from individual as well a group of judgments together. This would make the overall analysis of judgments in Hong Kong less tedious and m
    
[^37]: 基于蒙特卡洛规划的忠实问答系统

    Faithful Question Answering with Monte-Carlo Planning. (arXiv:2305.02556v1 [cs.CL])

    [http://arxiv.org/abs/2305.02556](http://arxiv.org/abs/2305.02556)

    本文提出了基于蒙特卡洛规划的FAME问答系统，通过组织中间推理步骤作为结构化蕴含树来忠实回答问题。通过引入蒙特卡洛规划算法，FAME在保持忠实推理的同时，在领域通用的问答基准数据集上实现了最先进的性能。

    

    虽然大型语言模型在问答方面的表现令人瞩目，但如何展现模型忠实遵循的中间推理步骤仍具挑战性。本文提出了FAME（基于蒙特卡洛规划的忠实问答系统），以对忠实的推理步骤进行问答。推理步骤被组织为结构化蕴含树，它展示了前提如何被用于产生证明回答正确性的中间结论。我们将任务定义为离散决策问题，并通过推理环境和控制器的交互来解决它。环境是模块化的，并包含几个基本的任务导向模块，而控制器则提出操作来组装这些模块。由于搜索空间可能很大，我们引入了蒙特卡洛规划算法来进行向前搜索，并选择最终将导致高质量步骤的操作。FAME在DROP数据集上实现了最先进的性能，这是一个领域通用的问答基准，同时保持了忠实的推理步骤。

    Although large language models demonstrate remarkable question-answering performances, revealing the intermediate reasoning steps that the models faithfully follow remains challenging. In this paper, we propose FAME (FAithful question answering with MontE-carlo planning) to answer questions based on faithful reasoning steps. The reasoning steps are organized as a structured entailment tree, which shows how premises are used to produce intermediate conclusions that can prove the correctness of the answer. We formulate the task as a discrete decision-making problem and solve it through the interaction of a reasoning environment and a controller. The environment is modular and contains several basic task-oriented modules, while the controller proposes actions to assemble the modules. Since the search space could be large, we introduce a Monte-Carlo planning algorithm to do a look-ahead search and select actions that will eventually lead to high-quality steps. FAME achieves state-of-the-ar
    
[^38]: FormNetV2：用于表格文档信息提取的多模态图形对比学习

    FormNetV2: Multimodal Graph Contrastive Learning for Form Document Information Extraction. (arXiv:2305.02549v1 [cs.CL])

    [http://arxiv.org/abs/2305.02549](http://arxiv.org/abs/2305.02549)

    该论文提出了一种用于表格文档信息提取的多模态图形对比学习策略（FormNetV2），该方法能够统一所有模态的自监督预训练到一个损失中，并在多个基准测试中取得了最佳表现。

    

    自监督预训练技术的出现导致了多模态学习在表格文档理解中的激增。然而，现有的扩展掩码语言建模到其他模态的方法需要仔细的多任务调整、复杂的重构目标设计或额外的预训练数据。在FormNetV2中，我们引入了一种集中的多模态图对比学习策略，以统一所有模态的自监督预训练到一个损失中。图对比目标最大化多模态表示的一致性，为所有模态提供自然的相互作用，而不需要特殊的定制。此外，我们在连接图边缘的一对标记的边框内提取图像特征，捕捉更有针对性的视觉线索，而无需加载经过复杂和单独预训练的图像嵌入器。FormNetV2在FUNSD、CORD、SROIE和Payment基准测试中确立了最新的最佳表现水平。

    The recent advent of self-supervised pre-training techniques has led to a surge in the use of multimodal learning in form document understanding. However, existing approaches that extend the mask language modeling to other modalities require careful multi-task tuning, complex reconstruction target designs, or additional pre-training data. In FormNetV2, we introduce a centralized multimodal graph contrastive learning strategy to unify self-supervised pre-training for all modalities in one loss. The graph contrastive objective maximizes the agreement of multimodal representations, providing a natural interplay for all modalities without special customization. In addition, we extract image features within the bounding box that joins a pair of tokens connected by a graph edge, capturing more targeted visual cues without loading a sophisticated and separately pre-trained image embedder. FormNetV2 establishes new state-of-the-art performance on FUNSD, CORD, SROIE and Payment benchmarks with 
    
[^39]: PersonaLLM: 探究GPT-3.5表达个性特征和性别差异的能力

    PersonaLLM: Investigating the Ability of GPT-3.5 to Express Personality Traits and Gender Differences. (arXiv:2305.02547v1 [cs.CL])

    [http://arxiv.org/abs/2305.02547](http://arxiv.org/abs/2305.02547)

    本文探究了基于LLMs模拟代理的行为，称之为LLM Personas，在分配大五人格类型和性别角色时是否可以生成具有一致性的个性化特质的内容。

    

    尽管大型语言模型在各个行业的聊天机器人设计中有许多用途，并且研究表明个性化聊天机器人在满足不同人格特征方面的重要性，但很少有研究评估个性化LLM的行为是否能够准确、一致地反映某些人格特征。我们考虑研究基于LLM的模拟代理的行为，称之为LLM personas，并使用GPT-3.5（text-davinci-003）进行案例研究，以研究LLM在分配大五人格类型和性别角色时是否可以生成具有一致性的个性化特质的内容。我们创建了320个LLM personas（每种大五人格类型有5个女性和5个男性），并提示他们完成经典的44项大五人格问卷（BFI），然后撰写一个关于他们童年的800字故事。结果表明，LLM personas的自我报告的BFI分数与他们分配的人格类型一致。

    Despite the many use cases for large language models (LLMs) in the design of chatbots in various industries and the research showing the importance of personalizing chatbots to cater to different personality traits, little work has been done to evaluate whether the behaviors of personalized LLMs can reflect certain personality traits accurately and consistently. We consider studying the behavior of LLM-based simulated agents which refer to as LLM personas and present a case study with GPT-3.5 (text-davinci-003) to investigate whether LLMs can generate content with consistent, personalized traits when assigned Big Five personality types and gender roles. We created 320 LLM personas (5 females and 5 males for each of the 32 Big Five personality types) and prompted them to complete the classic 44-item Big Five Inventory (BFI) and then write an 800-word story about their childhood. Results showed that LLM personas' self-reported BFI scores are consistent with their assigned personality typ
    
[^40]: 语言、时间偏好和消费行为：大型语言模型的证据

    Language, Time Preferences, and Consumer Behavior: Evidence from Large Language Models. (arXiv:2305.02531v1 [econ.GN])

    [http://arxiv.org/abs/2305.02531](http://arxiv.org/abs/2305.02531)

    本研究分析了大型语言模型在不同语言提示下的奖励时间偏好，并发现GPT在具有较弱未来时态的语言下表现出更大的耐心，这与使用该语言的人类的偏好相似。

    

    语言对我们对时间和奖励的感知有很大的影响。这引发了一个问题，即当以不同的语言询问大型语言模型时，它们是否显示出不同的奖励时间偏好，并且它们的选择是否类似于人类的选择。本研究分析了GPT-3.5（以下简称GPT）在多种语言提示下的响应，探索了较小、较早的奖励和较大、较晚的奖励之间的偏好。我们的结果显示，当以语义含义较弱的未来时态参考（FTR），如德语和汉语，为提示语时，GPT表现出更大的耐心，相比英语和法语等具有强大FTR的语言。这些发现与现有文献一致，并表明了GPT的选择与这些语言的使用者的偏好之间的关联。然而，进一步的分析揭示了较早或较晚奖励的偏好并没有随着奖励差异系统地改变，这表明了一种词典序优先的选择。

    Language has a strong influence on our perceptions of time and rewards. This raises the question of whether large language models, when asked in different languages, show different preferences for rewards over time and if their choices are similar to those of humans. In this study, we analyze the responses of GPT-3.5 (hereafter referred to as GPT) to prompts in multiple languages, exploring preferences between smaller, sooner rewards and larger, later rewards. Our results show that GPT displays greater patience when prompted in languages with weak future tense references (FTR), such as German and Mandarin, compared to languages with strong FTR, like English and French. These findings are consistent with existing literature and suggest a correlation between GPT's choices and the preferences of speakers of these languages. However, further analysis reveals that the preference for earlier or later rewards does not systematically change with reward gaps, indicating a lexicographic preferen
    
[^41]: ANetQA：一个用于未剪辑视频精细组合推理的大规模基准测试

    ANetQA: A Large-scale Benchmark for Fine-grained Compositional Reasoning over Untrimmed Videos. (arXiv:2305.02519v1 [cs.CV])

    [http://arxiv.org/abs/2305.02519](http://arxiv.org/abs/2305.02519)

    ANetQA是一个新的大规模基准测试，支持对未剪辑视频进行精细的组合推理。与现有的基准测试不同，ANetQA的问题类型需要精细的组成式推理，并覆盖多样化的信息类型，可以更加全面地评估VideoQA模型的性能。

    

    建立基准测试来系统地分析视频问答（VideoQA）模型的不同能力具有挑战性但至关重要。现有的基准测试通常使用非组成形简单问题并遭受语言偏见，使得深入诊断模型弱点变得困难。最近的基准测试AGQA提出了一种有前途的范例，它可以从预注释场景图中自动生成QA对，使其能够以颗粒化的控制度量多样化的推理能力。然而，它的问题在于无法理解视频中细粒度的语义，因为这样的信息在其场景图中没有呈现。因此，我们提出了ANetQA，这是一个大规模基准测试，支持从ActivityNet的具有挑战性的未剪辑视频中进行精细的组合推理。与AGQA类似，ANetQA中的QA对是从已注释的视频场景图中自动生成的。ANetQA 的细粒度特性体现在以下几个方面：（i）未剪辑的视频，包含复杂动作以及多个动作序列；（ii）覆盖多样化的信息类型，包括对象、场景、属性等；（iii）丰富的问题类型，需要精细的组成式推理。

    Building benchmarks to systemically analyze different capabilities of video question answering (VideoQA) models is challenging yet crucial. Existing benchmarks often use non-compositional simple questions and suffer from language biases, making it difficult to diagnose model weaknesses incisively. A recent benchmark AGQA poses a promising paradigm to generate QA pairs automatically from pre-annotated scene graphs, enabling it to measure diverse reasoning abilities with granular control. However, its questions have limitations in reasoning about the fine-grained semantics in videos as such information is absent in its scene graphs. To this end, we present ANetQA, a large-scale benchmark that supports fine-grained compositional reasoning over the challenging untrimmed videos from ActivityNet. Similar to AGQA, the QA pairs in ANetQA are automatically generated from annotated video scene graphs. The fine-grained properties of ANetQA are reflected in the following: (i) untrimmed videos with
    
[^42]: USTC-NELSLIP在SemEval-2023任务2中的应用：针对多语言复杂命名实体识别进行统计构建和双重适应性辞书的设计

    USTC-NELSLIP at SemEval-2023 Task 2: Statistical Construction and Dual Adaptation of Gazetteer for Multilingual Complex NER. (arXiv:2305.02517v1 [cs.CL])

    [http://arxiv.org/abs/2305.02517](http://arxiv.org/abs/2305.02517)

    本文介绍了USTC-NELSLIP团队为SemEval-2023任务2开发的系统，该系统提出了一种名为“SCDAG”的方法，用于多语言复杂命名实体识别，该方法通过构建辞书和适应语言模型的表示来提高识别精度，在印地语赛道上排名第一。

    

    本文描述了USTC-NELSLIP团队为SemEval-2023 任务2多语言复杂命名实体识别（MultiCoNER II）开发的系统。提出了一种名为“统计构建和双重适应性辞书（SCDAG）”的方法，用于多语言复杂命名实体识别。该方法首先利用基于统计的方法构建辞书。其次，通过最小化句子级和实体级之间的KL散度，适应辞书网络和语言模型的表示。最后，这两个网络被集成用于监督式命名实体识别训练。该方法应用于使用Wikidata构建的辞书上的XLM-R，表现出跨不同语言的很好的泛化能力。 实验结果和详细分析验证了该方法的有效性。在该任务中，官方结果显示我们的系统在印地语赛道上排名第一。

    This paper describes the system developed by the USTC-NELSLIP team for SemEval-2023 Task 2 Multilingual Complex Named Entity Recognition (MultiCoNER II). A method named Statistical Construction and Dual Adaptation of Gazetteer (SCDAG) is proposed for Multilingual Complex NER. The method first utilizes a statistics-based approach to construct a gazetteer. Secondly, the representations of gazetteer networks and language models are adapted by minimizing the KL divergence between them at both the sentence-level and entity-level. Finally, these two networks are then integrated for supervised named entity recognition (NER) training. The proposed method is applied to XLM-R with a gazetteer built from Wikidata, and shows great generalization ability across different tracks. Experimental results and detailed analysis verify the effectiveness of the proposed method. The official results show that our system ranked 1st on one track (Hindi) in this task.
    
[^43]: AutoML-GPT: 基于 GPT 的自动机器学习

    AutoML-GPT: Automatic Machine Learning with GPT. (arXiv:2305.02499v1 [cs.CL])

    [http://arxiv.org/abs/2305.02499](http://arxiv.org/abs/2305.02499)

    AutoML-GPT 是一种基于 GPT 的自动机器学习方法，利用大型语言模型动态地利用各种人工智能模型，自动化训练管道，节约了选择模型架构、优化算法和调整超参数的人力和时间成本。

    

    AI 任务涵盖了广泛的领域和领域。虽然为特定任务和应用程序设计了众多 AI 模型，但它们通常需要大量的人力投入来查找正确的模型架构、优化算法和超参数。最近，像 ChatGPT 这样的大型语言模型 (LLM) 在推理、理解和交互的各个方面展现出了卓越的能力。因此，我们提出了开发面向任务的提示并自动利用 LLM 自动化训练管道的想法。为了实现这个概念，我们推出了 AutoML-GPT，它采用 GPT 作为连接多种 AI 模型的桥梁，并动态地使用优化超参数训练模型。AutoML-GPT 从模型和数据卡中动态获取用户请求，并组成相应的提示段落。最终，通过这个提示段落，AutoML-GPT 将自动从数据处理到模型架构、超参数调整进行实验。

    AI tasks encompass a wide range of domains and fields. While numerous AI models have been designed for specific tasks and applications, they often require considerable human efforts in finding the right model architecture, optimization algorithm, and hyperparameters. Recent advances in large language models (LLMs) like ChatGPT show remarkable capabilities in various aspects of reasoning, comprehension, and interaction. Consequently, we propose developing task-oriented prompts and automatically utilizing LLMs to automate the training pipeline. To implement this concept, we present the AutoML-GPT, which employs GPT as the bridge to diverse AI models and dynamically trains models with optimized hyperparameters. AutoML-GPT dynamically takes user requests from the model and data cards and composes the corresponding prompt paragraph. Ultimately, with this prompt paragraph, AutoML-GPT will automatically conduct the experiments from data processing to model architecture, hyperparameter tuning,
    
[^44]: ChatGPT引导的编辑辅助工具用于摘要汇总自定义

    ChatGPT-steered Editing Instructor for Customization of Abstractive Summarization. (arXiv:2305.02483v1 [cs.CL])

    [http://arxiv.org/abs/2305.02483](http://arxiv.org/abs/2305.02483)

    本文提出了一个三个代理的生成方案，包括生成器、辅导员和编辑器，以增强生成输出的自定义。在两个摘要总结数据集上进行的实验结果表明，我们的方法可以生成更好的输出。

    

    尽管大型语言模型（如ChatGPT）的生成质量令人印象深刻，但根据特定用户需求调整其输出仍然是一项挑战。本文提出了一个三个代理的生成方案——生成器、辅导员和编辑器，以增强生成输出的自定义。生成器产生初始输出，针对用户需求的辅导员产生编辑指导，而编辑器产生符合用户偏好的修订输出。无法训练的大型语言模型（ChatGPT）既充当生成器又充当编辑器，而较小的模型则充当用户特定的辅导员，引导生成过程朝向用户需求的方向发展。辅导员使用编辑者引导的强化学习进行培训，利用大规模编辑模型的反馈来优化指导生成。在两个摘要总结数据集上进行的实验结果表明，我们的方法可以生成更好的输出。

    Tailoring outputs of large language models, such as ChatGPT, to specific user needs remains a challenge despite their impressive generation quality. In this paper, we propose a tri-agent generation pipeline consisting of a generator, an instructor, and an editor to enhance the customization of generated outputs. The generator produces an initial output, the user-specific instructor generates editing instructions, and the editor generates a revised output aligned with user preferences. The inference-only large language model (ChatGPT) serves as both the generator and the editor, while a smaller model acts as the user-specific instructor to guide the generation process toward user needs. The instructor is trained using editor-steered reinforcement learning, leveraging feedback from the large-scale editor model to optimize instruction generation. Experimental results on two abstractive summarization datasets demonstrate the effectiveness of our approach in generating outputs that better f
    
[^45]: 面向海事领域概率知识图谱的自动构建

    Toward the Automated Construction of Probabilistic Knowledge Graphs for the Maritime Domain. (arXiv:2305.02471v1 [cs.AI])

    [http://arxiv.org/abs/2305.02471](http://arxiv.org/abs/2305.02471)

    该论文研究了海事领域的概率知识图谱的自动构建，以利用含有丰富信息的未结构化软数据，并解决了软数据提取方面的问题。

    

    国际海上犯罪变得越来越复杂，并常与更广泛的犯罪网络有关。仅融合与物理移动相关的数据（即由物理传感器或硬数据生成的数据）来检测海上威胁是不够的。这导致了研究和开发工作，旨在将硬数据与其他类型的数据（特别是人工生成的软数据）相结合。现有研究通常假设输入的软数据以结构化格式提供，或者集中于提取某些相关实体或概念以配合或注释硬数据。对于从未结构化格式（如情报报告和新闻文章）中提取与感兴趣情况隐含相关的丰富信息，关注度要少得多。为了利用这些来源中潜在有用和丰富的信息，需要提取不仅相关的实体和概念，还需要提取隐含于大量软数据中的相关情境的丰富知识。

    International maritime crime is becoming increasingly sophisticated, often associated with wider criminal networks. Detecting maritime threats by means of fusing data purely related to physical movement (i.e., those generated by physical sensors, or hard data) is not sufficient. This has led to research and development efforts aimed at combining hard data with other types of data (especially human-generated or soft data). Existing work often assumes that input soft data is available in a structured format, or is focused on extracting certain relevant entities or concepts to accompany or annotate hard data. Much less attention has been given to extracting the rich knowledge about the situations of interest implicitly embedded in the large amount of soft data existing in unstructured formats (such as intelligence reports and news articles). In order to exploit the potentially useful and rich information from such sources, it is necessary to extract not only the relevant entities and conc
    
[^46]: 面向任务的端到端对话系统中的任务优化适配器

    Task-Optimized Adapters for an End-to-End Task-Oriented Dialogue System. (arXiv:2305.02468v1 [cs.CL])

    [http://arxiv.org/abs/2305.02468](http://arxiv.org/abs/2305.02468)

    本文提出了一种端到端任务导向对话系统，通过在预训练网络的固定层后添加少量参数的任务优化适配器来独立地学习每个任务，并通过强化学习提高DST和NLG模块的性能。

    

    任务导向对话系统旨在通过跟踪对话状态和生成适当的响应来执行特定任务，帮助用户实现定义的目标。最近，基于大型数据集预训练的端到端对话模型在对话系统中表现出了很好的性能。然而，它们共享相同的参数以训练对话系统的任务(NLU，DST，NLG)，因此每个任务的调试都很具有挑战性。此外，相较于PLM，将大量参数微调来创建面向任务的聊天机器人需要大量的努力，这使得非专家难以处理。因此，我们打算训练相对轻量级和快速的模型。本文提出了一种具有任务优化适配器的端到端任务导向对话系统，每个任务独立学习，在预训练网络的固定层之后仅添加少量参数。我们还通过强化学习提高了DST和NLG模块的性能，克服了学习曲线。

    Task-Oriented Dialogue (TOD) systems are designed to carry out specific tasks by tracking dialogue states and generating appropriate responses to help users achieve defined goals. Recently, end-to-end dialogue models pre-trained based on large datasets have shown promising performance in the conversational system. However, they share the same parameters to train tasks of the dialogue system (NLU, DST, NLG), so debugging each task is challenging. Also, they require a lot of effort to fine-tune large parameters to create a task-oriented chatbot, making it difficult for non-experts to handle. Therefore, we intend to train relatively lightweight and fast models compared to PLM. In this paper, we propose an End-to-end TOD system with Task-Optimized Adapters which learn independently per task, adding only small number of parameters after fixed layers of pre-trained network. We also enhance the performance of the DST and NLG modules through reinforcement learning, overcoming the learning curv
    
[^47]: 通过人类语言模型交互的负面思维认知重构

    Cognitive Reframing of Negative Thoughts through Human-Language Model Interaction. (arXiv:2305.02466v1 [cs.CL])

    [http://arxiv.org/abs/2305.02466](http://arxiv.org/abs/2305.02466)

    本文研究如何使用语言模型帮助人们重构负面思想，定义了七个用于重构思想的语言属性框架，并开发了自动化指标。实验发现使用模型辅助的参与者更有可能产生符合七个语言属性的重构思想，表明该模型在帮助人们重构负面思想上是成功的。

    

    克服负面思想的一种有效疗法是用更有希望的“重构思想”取而代之。虽然治疗可以帮助人们练习和学习认知重构负面思想，但临床医生短缺和心理健康的污名化通常会限制人们接受治疗。本文通过人类中心的方法研究如何语言模型可以帮助人们重构负面思想。我们基于心理学文献，定义了七个可以用来重构思想的语言属性框架。我们开发了自动化指标来衡量这些属性，并通过心理健康从业者的专家判断进行验证。我们收集了从从业者收集的 600 种情境、思想和重构数据集，并用它来训练一个检索增强的上下文学习模型，有效地生成重新构思和控制它们的语言属性。为了调查“高质量”重构的构成，我们进行了一个由IRB批准的用户研究，将参与者分配到“模型辅助重构”或控制条件。我们发现使用模型辅助的参与者更有可能产生符合七个语言属性的重构思想，表明我们的模型成功地帮助人们重构负面思想。

    A proven therapeutic technique to overcome negative thoughts is to replace them with a more hopeful "reframed thought." Although therapy can help people practice and learn this Cognitive Reframing of Negative Thoughts, clinician shortages and mental health stigma commonly limit people's access to therapy. In this paper, we conduct a human-centered study of how language models may assist people in reframing negative thoughts. Based on psychology literature, we define a framework of seven linguistic attributes that can be used to reframe a thought. We develop automated metrics to measure these attributes and validate them with expert judgements from mental health practitioners. We collect a dataset of 600 situations, thoughts and reframes from practitioners and use it to train a retrieval-enhanced in-context learning model that effectively generates reframed thoughts and controls their linguistic attributes. To investigate what constitutes a "high-quality" reframe, we conduct an IRB-appr
    
[^48]: 转移学习与主动学习用于共鸣检测：解决稀有类挑战

    Transfer and Active Learning for Dissonance Detection: Addressing the Rare-Class Challenge. (arXiv:2305.02459v1 [cs.CL])

    [http://arxiv.org/abs/2305.02459](http://arxiv.org/abs/2305.02459)

    本文提出并探究了基于转移和主动学习的稀有类问题的解决方案，包括利用在密切相关任务上训练的模型和评估获取策略来解决共振检测的稀有类问题，并且发现了一种名为PRC的有效的策略来指导注释。

    

    尽管基于变压器的系统使得使用更少的训练样例能够得到更高的准确性，但对于稀有类任务（即类别标签非常少见的情况，例如<5%的样本），数据采集障碍仍然存在。主动学习一般被提出用于缓解这种挑战，但选择策略，即选择稀有类示例的标准，尚未得到系统评估。此外，变压器可以实现迭代迁移学习方法。我们提出并研究了转移和主动学习解决了通过利用在密切相关任务上训练的模型和评估获取策略来解决共振检测的稀有类问题，其中包括一种提出的稀有类概率（PRC）方法。我们针对特定的稀有类问题（从社交媒体中收集认知共振的语言样本）进行了这些实验。我们发现PRC是指导注释的简单而有效的策略，最终可以提高性能，并且转移学习可以在稀缺数据情况下提供显著的改进。

    While transformer-based systems have enabled greater accuracies with fewer training examples, data acquisition obstacles still persist for rare-class tasks -- when the class label is very infrequent (e.g. < 5% of samples). Active learning has in general been proposed to alleviate such challenges, but choice of selection strategy, the criteria by which rare-class examples are chosen, has not been systematically evaluated. Further, transformers enable iterative transfer-learning approaches. We propose and investigate transfer- and active learning solutions to the rare class problem of dissonance detection through utilizing models trained on closely related tasks and the evaluation of acquisition strategies, including a proposed probability-of-rare-class (PRC) approach. We perform these experiments for a specific rare class problem: collecting language samples of cognitive dissonance from social media. We find that PRC is a simple and effective strategy to guide annotations and ultimately
    
[^49]: 量化文本差异

    Quantifying the Dissimilarity of Texts. (arXiv:2305.02457v1 [cs.CL])

    [http://arxiv.org/abs/2305.02457](http://arxiv.org/abs/2305.02457)

    本文比较了使用三种不同的文本表示方式和三个不同的聚类任务的性能，并发现基于单词频率的广义Jensen-Shannon分歧在所有任务中表现良好。最佳方法的选择最终取决于任务。

    

    量化两个文本的差异是自然语言处理任务的重要方面，包括语义信息检索、主题分类和文档聚类等。本文比较了使用三种不同的文本表示方式（词汇、词频分布和向量嵌入）和三个简单任务（按作者、主题和时间段对文本进行聚类）的不同差异度量的属性和性能。通过使用Project Gutenberg数据库, 我们发现基于单词频率的广义Jensen-Shannon分歧在所有任务中表现良好，基于向量嵌入表示的D导致小文本性能更强，而最佳方法的选择最终取决于任务。我们还在理论上和数值上研究了两个文本长度因子h变化时，不同D的行为。我们证明了...

    Quantifying the dissimilarity of two texts is an important aspect of a number of natural language processing tasks, including semantic information retrieval, topic classification, and document clustering. In this paper, we compared the properties and performance of different dissimilarity measures $D$ using three different representations of texts -- vocabularies, word frequency distributions, and vector embeddings -- and three simple tasks -- clustering texts by author, subject, and time period. Using the Project Gutenberg database, we found that the generalised Jensen--Shannon divergence applied to word frequencies performed strongly across all tasks, that $D$'s based on vector embedding representations led to stronger performance for smaller texts, and that the optimal choice of approach was ultimately task-dependent. We also investigated, both analytically and numerically, the behaviour of the different $D$'s when the two texts varied in length by a factor $h$. We demonstrated that
    
[^50]: 运用自我记忆的检索增强文本生成模型

    Lift Yourself Up: Retrieval-augmented Text Generation with Self Memory. (arXiv:2305.02437v1 [cs.CL])

    [http://arxiv.org/abs/2305.02437](http://arxiv.org/abs/2305.02437)

    本文提出了一种新的检索增强文本生成模型Selfmem，通过迭代生成自我记忆池并采用记忆选择器，使检索更加自适应，提高了文本生成的质量和多样性。

    

    相较于传统文本生成模型，检索增强文本生成模型能够直接迭代人类编写的参考库，并从中检索出相应的信息，以生成更优质的文本。但当前文献存在一个关键问题：检索到的记忆来自于固定的语料库，其质量存在一定局限性，可能会限制记忆增强模型的潜力。本文提出一种名为Selfmem的框架，该框架通过迭代地采用检索增强生成器自身以生成无限制的自我记忆池，并使用记忆选择器为下一轮生成选择一个生成的记忆。相结合，这两个主要问题提出了运用自我记忆的检索增强文本生成模型。

    With direct access to human-written reference as memory, retrieval-augmented generation has achieved much progress in a wide range of text generation tasks. Since better memory would typically prompt better generation~(we define this as primal problem), previous works mainly focus on how to retrieve better memory. However, one fundamental limitation exists for current literature: the memory is retrieved from a fixed corpus and is bounded by the quality of the corpus. Due to the finite retrieval space, bounded memory would greatly limit the potential of the memory-augmented generation model. In this paper, by exploring the duality of the primal problem: better generation also prompts better memory, we propose a framework called Selfmem, which iteratively adopts a retrieval-augmented generator itself to generate an unbounded memory pool and uses a memory selector to pick one generated memory for the next generation round. By combining the primal and dual problem, a retrieval-augmented ge
    
[^51]: 对Bert和ParsBERT在分析波斯广告数据中的应用进行评估

    evaluating bert and parsbert for analyzing persian advertisement data. (arXiv:2305.02426v1 [cs.CL])

    [http://arxiv.org/abs/2305.02426](http://arxiv.org/abs/2305.02426)

    本文评估了Bert和ParsBERT在分析波斯广告数据中的应用，并发现ParsBERT在预测广告发布百分比方面的性能优于mBERT。

    

    本文讨论了互联网对现代交易的影响及由此产生的数据对机构改进市场营销的重要性。文章以Divar作为示例，在伊朗进行在线购买和销售产品与服务的市场，举办了一个预测汽车销售广告发布百分比的竞赛。由于数据集提供了丰富的波斯文本数据，作者使用Hazm库和两个最先进的语言模型，mBERT和ParsBERT来分析它。本文的主要目标是比较mBERT和ParsBERT在Divar数据集上的性能。作者提供了有关数据挖掘、波斯语言和两种语言模型的背景，检查数据集的组成和统计特征，并提供了他们对两种方法的微调和训练配置的详细说明。最终，他们评估和比较了mBERT和ParsBERT在预测汽车销售广告发布百分比方面的有效性，结果显示ParsBERT在准确度和f1分数方面均优于mBERT。

    This paper discusses the impact of the Internet on modern trading and the importance of data generated from these transactions for organizations to improve their marketing efforts. The paper uses the example of Divar, an online marketplace for buying and selling products and services in Iran, and presents a competition to predict the percentage of a car sales ad that would be published on the Divar website. Since the dataset provides a rich source of Persian text data, the authors use the Hazm library, a Python library designed for processing Persian text, and two state-of-the-art language models, mBERT and ParsBERT, to analyze it. The paper's primary objective is to compare the performance of mBERT and ParsBERT on the Divar dataset. The authors provide some background on data mining, Persian language, and the two language models, examine the dataset's composition and statistical features, and provide details on their fine-tuning and training configurations for both approaches. They pr
    
[^52]: 序列到序列模型的后门学习

    Backdoor Learning on Sequence to Sequence Models. (arXiv:2305.02424v1 [cs.CL])

    [http://arxiv.org/abs/2305.02424](http://arxiv.org/abs/2305.02424)

    本文探讨了序列到序列模型对后门攻击的鲁棒性问题，发现只注入0.2％的样本即可让模型生成指定的关键词和整个句子，利用字节对编码创建多个新触发器对后门检测带来了新挑战，提出的方法在多个任务上可以达到90％以上的攻击成功率。

    

    后门攻击已成为构建可信机器学习系统的新兴研究领域。虽然很多研究已经研究了对图像或文本分类的后门攻击的隐藏危险，但对于输出空间为无限和离散的模型在后门攻击下的鲁棒性却了解有限。本文探讨了一个更具挑战性的问题，即测试序列到序列(seq2seq)模型是否容易受到后门攻击。具体而言，我们发现只注入0.2％的样本即可使seq2seq模型生成指定的关键词，甚至整个句子。此外，我们利用字节对编码(Byte Pair Encoding, BPE)来创建多个新触发器，这给后门检测带来了新的挑战，因为这些后门是不固定的。我们进行了大量机器翻译和文本摘要实验，展示了我们提出的方法在多个任务上可以达到90％以上的攻击成功率。

    Backdoor learning has become an emerging research area towards building a trustworthy machine learning system. While a lot of works have studied the hidden danger of backdoor attacks in image or text classification, there is a limited understanding of the model's robustness on backdoor attacks when the output space is infinite and discrete. In this paper, we study a much more challenging problem of testing whether sequence-to-sequence (seq2seq) models are vulnerable to backdoor attacks. Specifically, we find by only injecting 0.2\% samples of the dataset, we can cause the seq2seq model to generate the designated keyword and even the whole sentence. Furthermore, we utilize Byte Pair Encoding (BPE) to create multiple new triggers, which brings new challenges to backdoor detection since these backdoors are not static. Extensive experiments on machine translation and text summarization have been conducted to show our proposed methods could achieve over 90\% attack success rate on multiple 
    
[^53]: PTP：利用基于扰动的正则化器提升Prompt Tuning的稳定性和性能

    PTP: Boosting Stability and Performance of Prompt Tuning with Perturbation-Based Regularizer. (arXiv:2305.02423v1 [cs.CL])

    [http://arxiv.org/abs/2305.02423](http://arxiv.org/abs/2305.02423)

    PTP算法引入基于扰动的正则化器来平滑loss图像，提升prompt tuning性能和稳定性，在四个测试数据集中获得了显著优于现有方法的表现。

    

    最近的研究表明，在下游自然语言理解任务上，使用prompt tuning比微调方法更能发挥大型语言模型的力量。然而，现有的prompt tuning方法存在训练不稳定性问题，因为不同随机种子下的分数方差相当大。为了解决这个关键问题，我们首先调查并发现，普通的prompt tuning的损失函数图像在可视化时呈峭壁状，输入数据的微小变化可以导致损失函数图像的剧烈波动。这是导致prompt tuning不稳定性的一个重要因素。基于这个观察结果，我们将平滑损失函数图像的基于扰动的正则化器引入到prompt tuning中。我们提出了一种名为PTP的新算法，它不仅可以显著减轻训练不稳定性，还可以提高prompt tuning的性能。我们设计了两种基于扰动的正则化器，并在四个受欢迎的NLU数据集上进行了广泛实验。实验结果表明，PTP在超级GLUE和GLUE上分别获得了高达3.9％和2.0％的性能提升，可明显优于现有的prompt tuning方法。此外，PTP还可以提高prompt tuning的鲁棒性，使多次运行获得的性能标准偏差更小。

    Recent studies show that prompt tuning can better leverage the power of large language models than fine-tuning on downstream natural language understanding tasks. However, the existing prompt tuning methods have training instability issues, as the variance of scores under different random seeds is quite large. To address this critical problem, we first investigate and find that the loss landscape of vanilla prompt tuning is precipitous when it is visualized, where a slight change of input data can cause a big fluctuation in the loss landscape. This is an essential factor that leads to the instability of prompt tuning. Based on this observation, we introduce perturbation-based regularizers, which can smooth the loss landscape, into prompt tuning. We propose a new algorithm, called Prompt Tuning with Perturbation-based regularizer~(PTP), which can not only alleviate training instability dramatically but also boost the performance of prompt tuning. We design two kinds of perturbation-base
    
[^54]: 计划、消除和跟踪——语言模型是具备体验的智能体的良师益友。

    Plan, Eliminate, and Track -- Language Models are Good Teachers for Embodied Agents. (arXiv:2305.02412v1 [cs.CL])

    [http://arxiv.org/abs/2305.02412](http://arxiv.org/abs/2305.02412)

    本文介绍了Plan，Eliminate，和Track（PET）框架，该框架利用预先训练的大型语言模型（LLM）帮助智能体简化控制任务，从而解决了LLM直接作为智能体所面临的一些限制和问题。

    

    预训练的大型语言模型(LLMs)可以捕捉到关于世界的程序化知识。最近的研究利用LLM产生的抽象计划来简化具有挑战性的控制任务，通过动作打分或动作建模（微调）来实现。然而，变压器架构继承了几个限制，使得LLM难以直接作为智能体：例如有限的输入长度，微调的效率，预训练的偏见以及与非文本环境的不兼容性。为了与低级别可训练的执行器保持兼容性，我们建议使用LLMs中的知识来简化控制问题，而不是解决问题。 我们提出了Plan，Eliminate和Track（PET）框架。计划模块将任务描述转化为高层次子任务的列表。消除模块从当前子任务的观察中屏蔽不相关的对象和容器。最后，跟踪模块确定智能体是否已经实现了当前子任务。

    Pre-trained large language models (LLMs) capture procedural knowledge about the world. Recent work has leveraged LLM's ability to generate abstract plans to simplify challenging control tasks, either by action scoring, or action modeling (fine-tuning). However, the transformer architecture inherits several constraints that make it difficult for the LLM to directly serve as the agent: e.g. limited input lengths, fine-tuning inefficiency, bias from pre-training, and incompatibility with non-text environments. To maintain compatibility with a low-level trainable actor, we propose to instead use the knowledge in LLMs to simplify the control problem, rather than solving it. We propose the Plan, Eliminate, and Track (PET) framework. The Plan module translates a task description into a list of high-level sub-tasks. The Eliminate module masks out irrelevant objects and receptacles from the observation for the current sub-task. Finally, the Track module determines whether the agent has accompli
    
[^55]: 基于归因的防御插入式文本后门攻击

    Defending against Insertion-based Textual Backdoor Attacks via Attribution. (arXiv:2305.02394v1 [cs.CL])

    [http://arxiv.org/abs/2305.02394](http://arxiv.org/abs/2305.02394)

    本文提出了一种基于归因的管道AttDef，用于防御两种插入式污染攻击BadNL和InSent，该管道可以成功缓解插入式文本后门攻击并在四个基准数据集上平均提高了56.59%至79.97%和15.25%至48.34%的准确率。

    

    文本后门攻击是一种新型攻击模式，已被证明在训练期间向模型添加后门是有效的。防御此类后门攻击已变得紧迫和重要。本文提出了一种名为AttDef的高效归因管道，用于防御两种插入式污染攻击BadNL和InSent。具体而言，我们将具有较大归因分数的令牌视为潜在触发器，因为较大的归因词对于错误预测结果做出较大贡献，因此更有可能是污染触发器。此外，我们进一步利用外部预训练语言模型来区分输入是否被污染。我们展示了我们的方法可以在两种常见的攻击场景（污染训练数据和测试数据）中具有足够的泛化性，这一点持续改善了之前的方法。例如，AttDef在四个基准数据集上可以成功缓解两种攻击，平均准确率为79.97%（提高了56.59%）和48.34%（提高了15.25%），证明了它在防御插入式文本后门攻击方面的有效性。

    Textual backdoor attack, as a novel attack model, has been shown to be effective in adding a backdoor to the model during training. Defending against such backdoor attacks has become urgent and important. In this paper, we propose AttDef, an efficient attribution-based pipeline to defend against two insertion-based poisoning attacks, BadNL and InSent. Specifically, we regard the tokens with larger attribution scores as potential triggers since larger attribution words contribute more to the false prediction results and therefore are more likely to be poison triggers. Additionally, we further utilize an external pre-trained language model to distinguish whether input is poisoned or not. We show that our proposed method can generalize sufficiently well in two common attack scenarios (poisoning training data and testing data), which consistently improves previous methods. For instance, AttDef can successfully mitigate both attacks with an average accuracy of 79.97% (56.59% up) and 48.34% 
    
[^56]: 用Transformer逼近CKY算法

    Approximating CKY with Transformers. (arXiv:2305.02386v1 [cs.CL])

    [http://arxiv.org/abs/2305.02386](http://arxiv.org/abs/2305.02386)

    本文研究了Transformer模型逼近CKY算法的能力，提出了一种用梯度预测解析的方法，在标准基准测试中表现竞争力更好，同时速度更快。在随机PCFG下解析时，性能下降，但加入额外的归纳偏差是有帮助的。

    

    本文研究了Transformer模型逼近CKY算法的能力，直接预测句子的解析，避免了CKY算法对句子长度的三次依赖。在标准的组成句分析基准测试中，我们发现这种方法比使用CKY的可比分析器取得了竞争或更好的性能，同时速度更快。我们还评估了在随机PCFG下进行解析的可行性。在这里，我们发现在语法变得更加模糊的情况下，性能下降，这表明Transformer没有完全捕捉到CKY计算。然而，我们也发现，结合额外的归纳偏差是有帮助的，并提出了一种新方法，利用相对于图表表示的梯度来预测解析，类比于CKY算法与图表相关的一个分区函数变体的子梯度。

    We investigate the ability of transformer models to approximate the CKY algorithm, using them to directly predict a parse and thus avoid the CKY algorithm's cubic dependence on sentence length. We find that on standard constituency parsing benchmarks this approach achieves competitive or better performance than comparable parsers that make use of CKY, while being faster. We also evaluate the viability of this approach for parsing under random PCFGs. Here we find that performance declines as the grammar becomes more ambiguous, suggesting that the transformer is not fully capturing the CKY computation. However, we also find that incorporating additional inductive bias is helpful, and we propose a novel approach that makes use of gradients with respect to chart representations in predicting the parse, in analogy with the CKY algorithm being the subgradient of a partition function variant with respect to the chart.
    
[^57]: PeaCoK: 维持一致并引人入胜的叙述所需的角色常识知识

    PeaCoK: Persona Commonsense Knowledge for Consistent and Engaging Narratives. (arXiv:2305.02364v1 [cs.CL])

    [http://arxiv.org/abs/2305.02364](http://arxiv.org/abs/2305.02364)

    PeaCoK构建了一个大规模的角色常识知识图，包含约10万个经过人类验证的角色事实。该知识图展现了在以前的人类交互行为研究中确定的五个角色知识维度，并区分了常识和情感层面。

    

    维持一致且引人入胜的叙述需要对话或故事代理人理解说话者或听众的角色如何与叙述相关联。具体来说，这些代理人必须推断他们听众的角色，以产生符合他们兴趣的陈述。他们还必须学习在整个叙述中保持一致的说话者角色，以便他们的对等方感到参与其中并且是一段逼真的对话或故事。然而，角色是多样化和复杂的：它们包含大量丰富的相互关联的世界知识，这对于强大的一般叙述系统而言是具有挑战性的（例如，歌手擅长唱歌，并可能曾参加过音乐学院）。在这项工作中，我们构建了一个新的大规模角色常识知识图PeaCoK，其中包含约10万个经过人类验证的角色事实。我们的知识图表现了在以前的人类交互行为研究中确定的五个角色知识维度，并区分了常识和情感层面。

    Sustaining coherent and engaging narratives requires dialogue or storytelling agents to understand how the personas of speakers or listeners ground the narrative. Specifically, these agents must infer personas of their listeners to produce statements that cater to their interests. They must also learn to maintain consistent speaker personas for themselves throughout the narrative, so that their counterparts feel involved in a realistic conversation or story.  However, personas are diverse and complex: they entail large quantities of rich interconnected world knowledge that is challenging to robustly represent in general narrative systems (e.g., a singer is good at singing, and may have attended conservatoire). In this work, we construct a new large-scale persona commonsense knowledge graph, PeaCoK, containing ~100K human-validated persona facts. Our knowledge graph schematizes five dimensions of persona knowledge identified in previous studies of human interactive behaviours, and disti
    
[^58]: 语言模型中的实体跟踪

    Entity Tracking in Language Models. (arXiv:2305.02363v1 [cs.CL])

    [http://arxiv.org/abs/2305.02363](http://arxiv.org/abs/2305.02363)

    本文探究了大型语言模型追踪实体状态的能力，发现经过大量代码预训练的GPT-3.5模型表现最好，即使训练和评估中几乎没有词汇重叠的情况下，仍然可以获得不错的效果。

    

    追踪操作对象的状态并跟踪它们随文本或对话的展开而发生的关系变化是理解话语的关键前提。尽管如此，对于大型语言模型（LLM）追踪话语实体的能力进行了很少的系统调查。在这项工作中，我们提出了一项任务，以探究语言模型在给定初始状态的英文描述和一系列状态更改操作的情况下能够推断出实体的最终状态的程度。

    Keeping track of how states and relations of entities change as a text or dialog unfolds is a key prerequisite to discourse understanding. Despite this fact, there have been few systematic investigations into the ability of large language models (LLMs) to track discourse entities. In this work, we present a task to probe to what extent a language model can infer the final state of an entity given an English description of the initial state and a series of state-changing operations. We use this task to first investigate whether Flan-T5, GPT-3 and GPT-3.5 can track the state of entities, and find that only GPT-3.5 models, which have been pretrained on large amounts of code, exhibit this ability. We then investigate whether smaller models pretrained primarily on text can learn to track entities, through finetuning T5 on several training/evaluation splits. While performance degrades for more complex splits, we find that even for splits with almost no lexical overlap between training and ev
    
[^59]: 在低端硬件上使用语言模型

    Using Language Models on Low-end Hardware. (arXiv:2305.02350v1 [cs.CL])

    [http://arxiv.org/abs/2305.02350](http://arxiv.org/abs/2305.02350)

    本论文评估了在低端硬件上使用固定语言模型来训练文本分类网络的可行性，并发现在某些情况下，不对语言模型进行微调可以在更快的训练中产生竞争性的效果，仅需要原先内存的四分之一即可。

    

    本文评估了在低端硬件上使用固定语言模型来训练文本分类网络的可行性。我们将语言模型与CNN架构相结合，并组成了包括单标签和多标签分类的话题、情感和风格的8组数据集的综合基准。我们的观察总结成一个权衡列表，并得出结论，即在某些情况下，不对语言模型进行微调可以在更快的训练中产生竞争性的效果，仅需要原先内存的四分之一即可。

    This paper evaluates the viability of using fixed language models for training text classification networks on low-end hardware. We combine language models with a CNN architecture and put together a comprehensive benchmark with 8 datasets covering single-label and multi-label classification of topic, sentiment, and genre. Our observations are distilled into a list of trade-offs, concluding that there are scenarios, where not fine-tuning a language model yields competitive effectiveness at faster training, requiring only a quarter of the memory compared to fine-tuning.
    
[^60]: 一种文本分组的统计探索：《创世记》和《出埃及记》中司祭派别的情况

    A Statistical Exploration of Text Partition Into Constituents: The Case of the Priestly Source in the Books of Genesis and Exodus. (arXiv:2305.02170v1 [cs.CL])

    [http://arxiv.org/abs/2305.02170](http://arxiv.org/abs/2305.02170)

    为了验证文本分组的假设，我们提出了一个统计文本探索的流程，并在圣经的前两卷书中应用此流程，成功地识别并探索了司祭派别和非司祭派别之间的统计明显的文体差异。

    

    我们提出了一个统计文本探索的流程，提供了一种基于文体学的解释，并对文本的假设分组进行了统计验证。给定文本的参数化，我们的流程：（1）检测文学特征，以产生假设分组和无监督分组之间的最佳重叠，（2）执行假设检验分析，量化最佳重叠的统计显著性，同时保留更可能被分组的文本单位之间的隐式相关性，以及（3）提取和量化对分类最负责的特征的重要性，并估计它们的统计稳定性和聚类-wise丰度。我们将这个流程应用于圣经中的前两卷书，圣经学者们认为，其中一种文体成分特别突出，即司祭派别。我们确定并探索了司祭派别和非司祭派别之间的统计明显的文体差异。

    We present a pipeline for a statistical textual exploration, offering a stylometry-based explanation and statistical validation of a hypothesized partition of a text. Given a parameterization of the text, our pipeline: (1) detects literary features yielding the optimal overlap between the hypothesized and unsupervised partitions, (2) performs a hypothesis-testing analysis to quantify the statistical significance of the optimal overlap, while conserving implicit correlations between units of text that are more likely to be grouped, and (3) extracts and quantifies the importance of features most responsible for the classification, estimates their statistical stability and cluster-wise abundance.  We apply our pipeline to the first two books in the Bible, where one stylistic component stands out in the eyes of biblical scholars, namely, the Priestly component. We identify and explore statistically significant stylistic differences between the Priestly and non-Priestly components.
    
[^61]: Doc2SoarGraph：基于语义导向分层图的富含视觉表格文档的离散推理

    Doc2SoarGraph: Discrete Reasoning over Visually-Rich Table-Text Documents with Semantic-Oriented Hierarchical Graphs. (arXiv:2305.01938v1 [cs.CL])

    [http://arxiv.org/abs/2305.01938](http://arxiv.org/abs/2305.01938)

    本文提出了 Doc2SoarGraph 框架，利用语义导向分层图结构中元素之间的差异和相关性，在富含视觉表格文本的TAT-DQA问题下实现了离散推理，表现出了最佳的实验结果。

    

    近两年来，对于表格文本文档（例如财务报告）的离散推理越来越受到关注。现有的工作大多通过手动选择和转换文档页面到结构化的表格和段落来简化这一挑战，从而阻碍其实际应用。在这项工作中，我们探究了一种更为现实的问题设置，即以 TAT-DQA 的形式回答富含视觉表格文本的问题。具体而言，我们提出了一种新颖的 Doc2SoarGraph 框架，通过利用语义导向分层图结构中不同元素之间的差异和相关性，提高了其离散推理能力。我们对 TAT-DQA 数据集进行了广泛的实验，结果显示，我们的提出的框架在测试集上的精确匹配（EM）和 F1 得分方面分别比最佳基线模型分别提高了 17.73% 和 16.91%，实现了新的最先进技术水平。

    Discrete reasoning over table-text documents (e.g., financial reports) gains increasing attention in recent two years. Existing works mostly simplify this challenge by manually selecting and transforming document pages to structured tables and paragraphs, hindering their practical application. In this work, we explore a more realistic problem setting in the form of TAT-DQA, i.e. to answer the question over a visually-rich table-text document. Specifically, we propose a novel Doc2SoarGraph framework with enhanced discrete reasoning capability by harnessing the differences and correlations among different elements (e.g., quantities, dates) of the given question and document with Semantic-oriented hierarchical Graph structures. We conduct extensive experiments on TAT-DQA dataset, and the results show that our proposed framework outperforms the best baseline model by 17.73% and 16.91% in terms of Exact Match (EM) and F1 score respectively on the test set, achieving the new state-of-the-art
    
[^62]: 改进句子嵌入的对比学习方法，利用人工智能反馈

    Improving Contrastive Learning of Sentence Embeddings from AI Feedback. (arXiv:2305.01918v1 [cs.CL])

    [http://arxiv.org/abs/2305.01918](http://arxiv.org/abs/2305.01918)

    本文提出了一种利用人工智能反馈改进句子嵌入对比学习方法的方式，可以提高对比学习样本对的质量，并结合人类反馈来提供更好的监督信号。

    

    对比学习已成为自然语言处理中句子嵌入学习中的流行方法。然而，自然语言的离散性使得通过数据增强方法生成的正负样本对的质量难以保证。虽然有监督的对比学习可以通过人类反馈标签生成更准确的样本对，但仍缺乏细粒度的训练信号。本文提出了一种基于AI反馈来改进句子嵌入对比学习的方法（CLAIF），利用大型预训练语言模型 (LLMs) 的AI反馈构建带有细粒度样本相似度分数的样本对，以改进对比学习。此外，我们结合人工反馈和AI反馈为对比学习中的句子嵌入提供更好的监督信号。实验结果表明，我们的方法达到了最先进的水平。

    Contrastive learning has become a popular approach in natural language processing, particularly for the learning of sentence embeddings. However, the discrete nature of natural language makes it difficult to ensure the quality of positive and negative sample pairs generated through data augmentation methods. Although supervised contrastive learning can produce more accurate sample pairs with human feedback labels, it still lacks fine-grained training signals. In this paper, we propose to improve \textbf{C}ontrastive \textbf{L}earning of sentence embeddings from \textbf{AI} \textbf{F}eedback \textbf{(CLAIF)}. Our method utilizes AI feedback from large pre-trained language models (LLMs) to construct sample pairs with fine-grained sample similarity scores to improve contrastive learning. Besides, we combine human feedback and AI feedback to provide better supervision signals for supervised contrastive learning of sentence embeddings. Experimental results show that our method achieves stat
    
[^63]: 基于因果感知的知识引导句子提取

    Causality-aware Concept Extraction based on Knowledge-guided Prompting. (arXiv:2305.01876v1 [cs.CL])

    [http://arxiv.org/abs/2305.01876](http://arxiv.org/abs/2305.01876)

    该论文提出了一种基于因果感知的知识引导提示方法，将其作为干预器装备到基于预训练语言模型的句子提取器中，以缓解概念偏差。在代表性的多语言KG数据集上进行广泛实验，获得了最先进的结果。

    

    概念有助于自然语言理解，但现有的知识图谱（KG）中远未完善。最近，预训练语言模型（PLM）已被广泛用于基于文本的概念提取（CE）。然而，PLM往往从大量语料库的共现关联中进行预训练知识挖掘，而非Token之间的真实因果关系。因此，预训练知识混淆了PLM，导致提取基于虚假共现相关性的有偏概念，不可避免地导致低精度。本文通过结构因果模型（SCM）提出了一种知识引导提示方法，将其作为干预器装备到基于PLM的提取器中，以减轻概念偏差。提示采用现有KG中的给定实体主题来缓解实体和有偏概念之间的虚假共现相关性。我们在代表性的多语言KG数据集上进行了广泛的实验，证明了我们提出的提示显著改进了提取性能，并达到了最先进的结果。

    Concepts benefit natural language understanding but are far from complete in existing knowledge graphs (KGs). Recently, pre-trained language models (PLMs) have been widely used in text-based concept extraction (CE). However, PLMs tend to mine the co-occurrence associations from massive corpus as pre-trained knowledge rather than the real causal effect between tokens.As a result, the pre-trained knowledge confounds PLMs to extract biased concepts based on spurious co-occurrence correlations, inevitably resulting in low precision. In this paper, through the lens of a Structural Causal Model (SCM), we propose equipping the PLM-based extractor with a knowledge-guided prompt as an intervention to alleviate concept bias. The prompt adopts the topic of the given entity from the existing knowledge in KGs to mitigate the spurious co-occurrence correlations between entities and biased concepts. Our extensive experiments on representative multilingual KG datasets justify that our proposed prompt 
    
[^64]: 针对神经排序模型的几乎不可察觉的文档篡改

    Towards Imperceptible Document Manipulations against Neural Ranking Models. (arXiv:2305.01860v1 [cs.IR])

    [http://arxiv.org/abs/2305.01860](http://arxiv.org/abs/2305.01860)

    该论文提出了一种针对神经排序模型的不易被检测到的对抗性攻击框架，称为“几乎不可察觉文档操作”（IDEM）。IDEM使用生成语言模型生成连结句，无法引入易于检测的错误，并且使用单独的位置合并策略来平衡扰动文本的相关性和连贯性，实验结果表明，IDEM可以在保持高人类评估得分的同时优于强基线。

    

    对抗性攻击已经开始应用于发现神经排序模型（NRMs）中的潜在漏洞，但是当前攻击方法常常会引入语法错误，无意义的表达，或不连贯的文本片段，这些都很容易被检测到。此外，当前方法严重依赖于使用与真实的NRM相似的模拟NRM来保证攻击效果，这使得它们在实践中难以使用。为了解决这些问题，我们提出了一个称为“几乎不可察觉文档操作”（IDEM）的框架，用于生成对算法和人类来说都不太明显的对抗文档。IDEM指示一个经过良好建立的生成语言模型（例如BART）生成连接句，而不会引入易于检测的错误，并采用单独的逐位置合并策略来平衡扰动文本的相关性和连贯性。在流行的MS MARCO基准上的实验结果表明，IDEM可以在保持高人类评估得分的同时，优于强基线。

    Adversarial attacks have gained traction in order to identify potential vulnerabilities in neural ranking models (NRMs), but current attack methods often introduce grammatical errors, nonsensical expressions, or incoherent text fragments, which can be easily detected. Additionally, current methods rely heavily on the use of a well-imitated surrogate NRM to guarantee the attack effect, which makes them difficult to use in practice. To address these issues, we propose a framework called Imperceptible DocumEnt Manipulation (IDEM) to produce adversarial documents that are less noticeable to both algorithms and humans. IDEM instructs a well-established generative language model, such as BART, to generate connection sentences without introducing easy-to-detect errors, and employs a separate position-wise merging strategy to balance relevance and coherence of the perturbed text. Experimental results on the popular MS MARCO benchmark demonstrate that IDEM can outperform strong baselines while 
    
[^65]: 基于少样本背景学习的知识库问答

    Few-shot In-context Learning for Knowledge Base Question Answering. (arXiv:2305.01750v1 [cs.CL])

    [http://arxiv.org/abs/2305.01750](http://arxiv.org/abs/2305.01750)

    该论文提出了KB-BINDER框架，通过少量的上下文演示实现了在多个知识库问答数据集上的背景学习，大大提高了KBQA问题的可解性。

    

    知识库问答被认为是一个难以解决的问题，因为需要应对各种可能的自然语言问题。此外，不同知识库架构项之间的异构性通常需要针对不同的知识库问答（KBQA）数据集进行专门的训练。为了处理多种KBQA数据集上的问题，我们提出了KB-BINDER，该框架可以进行少量样本的背景学习，并将不同的KBQA数据集统一。首先，KB-BINDER利用像Codex这样的大型语言模型通过模仿少量演示来生成特定问题的逻辑形式作为草稿。其次，KB-BINDER基于知识库来绑定生成的草稿至可执行形式，通过BM25分数匹配。在四个公开的异构KBQA数据集上的实验结果表明，KB-BINDER可以在少量上下文演示的情况下取得强大的性能，在某些情况下超过了最先进的方法。

    Question answering over knowledge bases is considered a difficult problem due to the challenge of generalizing to a wide variety of possible natural language questions. Additionally, the heterogeneity of knowledge base schema items between different knowledge bases often necessitates specialized training for different knowledge base question-answering (KBQA) datasets. To handle questions over diverse KBQA datasets with a unified training-free framework, we propose KB-BINDER, which for the first time enables few-shot in-context learning over KBQA tasks. Firstly, KB-BINDER leverages large language models like Codex to generate logical forms as the draft for a specific question by imitating a few demonstrations. Secondly, KB-BINDER grounds on the knowledge base to bind the generated draft to an executable one with BM25 score matching. The experimental results on four public heterogeneous KBQA datasets show that KB-BINDER can achieve a strong performance with only a few in-context demonstr
    
[^66]: 利用语义视觉先验解释视觉和语言生成模型

    Interpreting Vision and Language Generative Models with Semantic Visual Priors. (arXiv:2304.14986v1 [cs.CV])

    [http://arxiv.org/abs/2304.14986](http://arxiv.org/abs/2304.14986)

    本研究提出了一种利用SHAP框架和视觉先验知识生成全面、有意义解释的方法，相较于传统方法具有更低的计算成本、更高的解释表现力，并可以推广到其他模型上。

    

    在应用于图像到文本模型时，可解释性方法通常提供逐个标记的解释，即为所生成的序列中的每个标记计算视觉解释。这些解释计算成本高，无法全面解释模型的输出。因此，这些模型通常需要某种近似方法，最终会导致误导性的解释。本文提出了一种基于SHAP的框架，该框架允许利用输出序列的含义表示生成全面、有意义的解释。此外，通过利用视觉主干网络中的语义先验知识，我们提取了任意数量的特征，并能够在大规模模型上高效计算Shapley值，同时生成高度明确的视觉解释。我们证明了我们的方法在更低的计算成本下生成语义上更具表现力的解释，并且可以推广到其他模型上。

    When applied to Image-to-text models, interpretability methods often provide token-by-token explanations namely, they compute a visual explanation for each token of the generated sequence. Those explanations are expensive to compute and unable to comprehensively explain the model's output. Therefore, these models often require some sort of approximation that eventually leads to misleading explanations. We develop a framework based on SHAP, that allows for generating comprehensive, meaningful explanations leveraging the meaning representation of the output sequence as a whole. Moreover, by exploiting semantic priors in the visual backbone, we extract an arbitrary number of features that allows the efficient computation of Shapley values on large-scale models, generating at the same time highly meaningful visual explanations. We demonstrate that our method generates semantically more expressive explanations than traditional methods at a lower compute cost and that it can be generalized o
    
[^67]: DataComp：寻找下一代多模态数据集

    DataComp: In search of the next generation of multimodal datasets. (arXiv:2304.14108v1 [cs.CV])

    [http://arxiv.org/abs/2304.14108](http://arxiv.org/abs/2304.14108)

    DataComp是一个基准测试，旨在通过提出新的训练集来解决数据集在机器学习生态系统中的缺陷。它提供了一个多规模设计的实验测试平台，使用12.8B个图像-文本对的新候选池，让研究人员可以通过设计新的过滤技术或策划新的数据源并评估它们的新数据集来进行创新。

    

    大型的多模态数据集在近期的突破中起到了关键作用，比如CLIP、Stable Diffusion和GPT-4等。与此同时，数据集很少得到与模型架构或训练算法同等的研究关注。为了解决这个在机器学习生态系统中的缺陷，我们介绍了DataComp，一个基准测试，其中训练代码是固定的，研究人员通过提出新的训练集来进行创新。我们提供了一个基于Common Crawl的新候选池，其中包含12.8B个图像-文本对的数据集实验测试平台。参加我们基准测试的研究人员可以设计新的过滤技术或策划新的数据源，并通过运行我们标准化的CLIP训练代码并在38个下游测试集上进行测试来评估他们的新数据集。我们的基准测试包含多个规模，四个候选池大小和相应的计算预算，在训练期间涵盖了从12.8M到12.8B个样本。这种多规模设计有助于研究规模趋势，并为研究人员提供了更多的选择余地。

    Large multimodal datasets have been instrumental in recent breakthroughs such as CLIP, Stable Diffusion, and GPT-4. At the same time, datasets rarely receive the same research attention as model architectures or training algorithms. To address this shortcoming in the machine learning ecosystem, we introduce DataComp, a benchmark where the training code is fixed and researchers innovate by proposing new training sets. We provide a testbed for dataset experiments centered around a new candidate pool of 12.8B image-text pairs from Common Crawl. Participants in our benchmark design new filtering techniques or curate new data sources and then evaluate their new dataset by running our standardized CLIP training code and testing on 38 downstream test sets. Our benchmark consists of multiple scales, with four candidate pool sizes and associated compute budgets ranging from 12.8M to 12.8B samples seen during training. This multi-scale design facilitates the study of scaling trends and makes the
    
[^68]: 通过可扩展的主题嵌入从连续新闻流中无监督地发现故事

    Unsupervised Story Discovery from Continuous News Streams via Scalable Thematic Embedding. (arXiv:2304.04099v1 [cs.IR])

    [http://arxiv.org/abs/2304.04099](http://arxiv.org/abs/2304.04099)

    本研究提出了一种新颖的主题嵌入方法和一个可扩展的无监督在线故事发现框架USTORY，可以动态表示文章和故事，并考虑它们共享的时间主题和新颖性，以帮助人们消化大量的新闻流。

    

    无监督地发现实时相关新闻文章故事，有助于人们在不需要昂贵人工注释的情况下消化大量的新闻流。现有的无监督在线故事发现研究的普遍方法是用符号或基于图的嵌入来表示新闻文章，并将它们逐步聚类成故事。最近的大型语言模型有望进一步改善嵌入，但是通过无差别地编码文章中的所有信息来直接采用这些模型无法有效处理富含文本且不断发展的新闻流。在这项工作中，我们提出了一种新颖的主题嵌入方法，使用现成的预训练句子编码器来动态表示文章和故事，并考虑它们共享的时间主题。为了实现无监督在线故事发现的想法，引入了一个可扩展框架USTORY，包括两个主要技术，即主题和时间感知的动态嵌入和新颖性感知的自适应聚类。

    Unsupervised discovery of stories with correlated news articles in real-time helps people digest massive news streams without expensive human annotations. A common approach of the existing studies for unsupervised online story discovery is to represent news articles with symbolic- or graph-based embedding and incrementally cluster them into stories. Recent large language models are expected to improve the embedding further, but a straightforward adoption of the models by indiscriminately encoding all information in articles is ineffective to deal with text-rich and evolving news streams. In this work, we propose a novel thematic embedding with an off-the-shelf pretrained sentence encoder to dynamically represent articles and stories by considering their shared temporal themes. To realize the idea for unsupervised online story discovery, a scalable framework USTORY is introduced with two main techniques, theme- and time-aware dynamic embedding and novelty-aware adaptive clustering, fuel
    
[^69]: 大型语言模型综述

    A Survey of Large Language Models. (arXiv:2303.18223v1 [cs.CL])

    [http://arxiv.org/abs/2303.18223](http://arxiv.org/abs/2303.18223)

    本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。

    

    语言本质上是一个由语法规则控制的复杂精细的人类表达系统，对于开发理解和掌握语言的能力的AI算法来说是一项重大挑战。作为主要方法之一，语言建模在过去二十年里广泛研究用于语言理解和生成，从统计语言模型演化为神经语言模型。最近，通过在大规模语料库上预训练Transformer模型，提出了预训练语言模型（PLMs），在解决各种NLP任务方面显示出强大的能力。由于研究人员发现模型缩放可以导致性能改进，他们进一步通过增加模型规模来研究缩放效应，有趣的是，当参数规模超过一定水平时，这些扩大的语言模型不仅可以实现显着的性能提升，而且还显示出一些小规模语言模型所没有的特殊能力。

    Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale langu
    
[^70]: 探索和利用辅助数据来改善小样本泛化问题

    Improving Few-Shot Generalization by Exploring and Exploiting Auxiliary Data. (arXiv:2302.00674v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.00674](http://arxiv.org/abs/2302.00674)

    本文提出了一种在少样本学习过程中假定有辅助数据的训练范式FLAD，并针对自动混合辅助和目标数据的方法局限，提出了两种计算复杂度独立于辅助数据集数量的算法，通过FLAD和这两种算法的比较，可以发现这两种算法的表现更好。

    

    小样本学习在许多实际应用中都有价值，但学习一个通用的模型且不过度拟合少数标记数据点是具有挑战性的。本文关注辅助数据的小样本学习（FLAD），一种在少样本学习过程中假定有辅助数据的训练范式，以期提高泛化性能。先前的工作已经提出了自动混合辅助和目标数据的方法，但这些方法通常随辅助数据集的数量呈线性（或更差）缩放，从而限制了它们的实用性。在本文中，我们将FLAD与在多臂老虎机设置中至关重要的探索与利用困境联系起来，并推导出算法，其计算复杂度独立于辅助数据集的数量，从而使我们能够扩展到比先前方法多100倍的辅助数据集。我们提出了两种算法——EXP3-FLAD和UCB1-FLAD，并将它们与先前只进行探索或利用的FLAD方法进行了比较，发现这些算法表现更好。

    Few-shot learning is valuable in many real-world applications, but learning a generalizable model without overfitting to the few labeled datapoints is challenging. In this work, we focus on Few-shot Learning with Auxiliary Data (FLAD), a training paradigm that assumes access to auxiliary data during few-shot learning in hopes of improving generalization. Previous works have proposed automated methods for mixing auxiliary and target data, but these methods typically scale linearly (or worse) with the number of auxiliary datasets, limiting their practicality. In this work we relate FLAD to the explore-exploit dilemma that is central to the multi-armed bandit setting and derive algorithms whose computational complexity is independent of the number of auxiliary datasets, allowing us to scale to 100x more auxiliary datasets than prior methods. We propose two algorithms -- EXP3-FLAD and UCB1-FLAD -- and compare them with prior FLAD methods that either explore or exploit, finding that the com
    
[^71]: 大型语言模型可被视为隐含的主题模型：解释和寻找好的示范以实现上下文学习

    Large Language Models Are Implicitly Topic Models: Explaining and Finding Good Demonstrations for In-Context Learning. (arXiv:2301.11916v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.11916](http://arxiv.org/abs/2301.11916)

    本研究发现，大型语言模型可以被视为隐式的主题模型，并提出了一种算法，从注释数据中选择最佳示范，大大提高了上下文学习的能力。

    

    近年来，预训练的大型语言模型表现出了在推理时实现少量样本学习能力的显著效率，被称为上下文学习。 然而，现有文献强调这种能力对少量样本示范的选择很敏感。本研究旨在通过贝叶斯视角研究上下文学习现象，将大型语言模型视为从示范中隐含地推断出相关信息的主题模型。在此前提下，我们提出了一种算法，用于从一组注释数据中选择最佳示范，并证明相对于随机选择基线的平均值，在八个不同的真实文本分类数据集上平均每个 GPT2 和 GPT3 模型有显着的 12.5% 的提升。我们的实证发现支持我们的假设，即大型语言模型可被视为隐含的主题模型。

    In recent years, pre-trained large language models have demonstrated remarkable efficiency in achieving an inference-time few-shot learning capability known as in-context learning. However, existing literature has highlighted the sensitivity of this capability to the selection of few-shot demonstrations. The underlying mechanisms by which this capability arises from regular language model pretraining objectives remain poorly understood. In this study, we aim to examine the in-context learning phenomenon through a Bayesian lens, viewing large language models as topic models that implicitly infer task-related information from demonstrations. On this premise, we propose an algorithm for selecting optimal demonstrations from a set of annotated data and demonstrate a significant 12.5% improvement relative to the random selection baseline, averaged over eight GPT2 and GPT3 models on eight different real-world text classification datasets. Our empirical findings support our hypothesis that la
    
[^72]: SeqDiffuSeq: 一种使用编码器-解码器Transformer的文本扩散模型用于序列生成

    SeqDiffuSeq: Text Diffusion Model with Encoder-Decoder Transformers for Sequence-to-Sequence Generation. (arXiv:2212.10325v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10325](http://arxiv.org/abs/2212.10325)

    本文提出了一种名为SeqDiffuSeq的文本扩散模型，用于序列生成，采用了编码器-解码器Transformer架构和自适应噪声调度技术，旨在探索扩散模型在自然语言生成方面的性能表现。

    

    扩散模型是一种新的生成建模范式，在图像、音频和视频生成方面取得了巨大成功。然而，考虑到文本的离散分类性质，将连续扩散模型扩展到自然语言并不是微不足道的，而且文本扩散模型研究较少。序列生成是自然语言处理中至关重要的话题之一。在本文中，我们将扩散模型应用于序列生成，探索扩散模型的优越生成性能能否转移到自然语言领域。我们提出SeqDiffuSeq，一种用于序列生成的文本扩散模型。SeqDiffuSeq使用编码器-解码器Transformer架构来建模去噪函数。为了提高生成质量，SeqDiffuSeq结合了自我调节技术和一个新提出的自适应噪声调度技术。自适应噪声调度具有均匀去噪的困难

    Diffusion model, a new generative modelling paradigm, has achieved great success in image, audio, and video generation. However, considering the discrete categorical nature of text, it is not trivial to extend continuous diffusion models to natural language, and text diffusion models are less studied. Sequence-to-sequence text generation is one of the essential natural language processing topics. In this work, we apply diffusion models to approach sequence-to-sequence text generation, and explore whether the superiority generation performance of diffusion model can transfer to natural language domain. We propose SeqDiffuSeq, a text diffusion model for sequence-to-sequence generation. SeqDiffuSeq uses an encoder-decoder Transformers architecture to model denoising function. In order to improve generation quality, SeqDiffuSeq combines the self-conditioning technique and a newly proposed adaptive noise schedule technique. The adaptive noise schedule has the difficulty of denoising evenly 
    
[^73]: 使用语言模型提示进行推理：一项调查

    Reasoning with Language Model Prompting: A Survey. (arXiv:2212.09597v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09597](http://arxiv.org/abs/2212.09597)

    本文提供了使用语言模型提示进行推理的前沿研究综合调查。讨论了新兴推理能力出现的潜在原因，并提供系统资源帮助初学者。

    

    推理作为复杂问题解决的重要能力，可以为医疗诊断、谈判等各种实际应用提供后端支持。本文对使用语言模型提示进行推理的前沿研究进行了综合调查。我们介绍了研究成果的比较和总结，并提供了系统资源以帮助初学者。我们还讨论了新兴推理能力出现的潜在原因，并突出了未来的研究方向。资源可在 https://github.com/zjunlp/Prompt4ReasoningPapers 上获取（定期更新）。

    Reasoning, as an essential ability for complex problem-solving, can provide back-end support for various real-world applications, such as medical diagnosis, negotiation, etc. This paper provides a comprehensive survey of cutting-edge research on reasoning with language model prompting. We introduce research works with comparisons and summaries and provide systematic resources to help beginners. We also discuss the potential reasons for emerging such reasoning abilities and highlight future research directions. Resources are available at https://github.com/zjunlp/Prompt4ReasoningPapers (updated periodically).
    
[^74]: I2D2: 基于NeuroLogic和自我模仿的归纳知识蒸馏

    I2D2: Inductive Knowledge Distillation with NeuroLogic and Self-Imitation. (arXiv:2212.09246v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09246](http://arxiv.org/abs/2212.09246)

    本论文探究了通过常识蒸馏算法强化小型语言模型的能力，挑战大型模型的常识获取能力，提出了一种不依赖规模的学习算法方案。

    

    尽管预训练语言模型在规模方面不断强化，但仍缺乏坚实的常识功能。然而，规模似乎是制胜法宝；毕竟，最大的模型似乎已经获得了最多的常识功能。这篇论文探究了似乎不可能实现的匹配：如果小型语言模型（如GPT-2）通过新颖的常识蒸馏算法得到动力，它们是否能赢过比它们大数个数量级并且更优秀的模型（如GPT-3）？我们所提出的关键智力问题是，是否可能设计一种学习算法，它并不受到规模的好处，而却有竞争力的常识获取水平。在本文中，我们研究了常识知识的生成模型，重点关注生成通用语句的任务，即关于日常概念的常识事实陈述。

    Pre-trained language models, despite their rapid advancements powered by scale, still fall short of robust commonsense capabilities. And yet, scale appears to be the winning recipe; after all, the largest models seem to have acquired the largest amount of commonsense capabilities. Or is it?  In this paper, we investigate the possibility of a seemingly impossible match: can smaller language models with dismal commonsense capabilities (i.e., GPT-2), ever win over models that are orders of magnitude larger and better (i.e., GPT-3), if the smaller models are powered with novel commonsense distillation algorithms? The key intellectual question we ask here is whether it is possible, if at all, to design a learning algorithm that does not benefit from scale, yet leads to a competitive level of commonsense acquisition. In this work, we study the generative models of commonsense knowledge, focusing on the task of generating generics, statements of commonsense facts about everyday concepts, e.g.
    
[^75]: 以总结为导向的多模态视觉建模用于抽象总结

    Summary-Oriented Vision Modeling for Multimodal Abstractive Summarization. (arXiv:2212.07672v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.07672](http://arxiv.org/abs/2212.07672)

    本论文提出了一种以总结为导向的多模态视觉建模方法，通过设计辅助任务，有效提高了抽象总结的质量，实验结果表明该方法在多种语言 上都取得了较好的效果。

    

    多模态抽象总结(MAS)旨在给定多模态数据(文本和图像)产生简洁摘要。现有研究主要集中在如何有效使用文章视觉特征的角度，已经在高资源的英文数据集上取得了令人印象深刻的成功。但是，对从摘要视觉特征的角度来看的少关注，这可能会限制模型的性能，特别是在低和零资源场景下。在本文中，我们提出通过总结导向的视觉特征来提高总结质量。为此，我们设计了两个辅助任务，包括视觉到总结任务和掩码图像建模任务。与主要摘要任务一起，通过所有这些任务的训练目标对MAS模型进行优化。通过这种方式，MAS模型可以通过捕获总结导向的视觉特征来得到更准确的总结。 在44种语言上进行了实验，包括中...

    Multimodal abstractive summarization (MAS) aims to produce a concise summary given the multimodal data (text and vision). Existing studies mainly focus on how to effectively use the visual features from the perspective of an article, having achieved impressive success on the high-resource English dataset. However, less attention has been paid to the visual features from the perspective of the summary, which may limit the model performance, especially in the low- and zero-resource scenarios. In this paper, we propose to improve the summary quality through summary-oriented visual features. To this end, we devise two auxiliary tasks including vision to summary task and masked image modeling task. Together with the main summarization task, we optimize the MAS model via the training objectives of all these tasks. By these means, the MAS model can be enhanced by capturing the summary-oriented visual features, thereby yielding more accurate summaries. Experiments on 44 languages, covering mid
    
[^76]: xTrimoABFold：无多序列比对的新型抗体结构预测方法

    xTrimoABFold: De novo Antibody Structure Prediction without MSA. (arXiv:2212.00735v2 [q-bio.QM] CROSS LISTED)

    [http://arxiv.org/abs/2212.00735](http://arxiv.org/abs/2212.00735)

    xTrimoABFold是一种基于深度抗体语言模型的新型抗体结构预测方法，无需多序列比对，有望促进高通量药物设计的应用。

    

    在抗体工程领域，设计一个新型抗体以正确地结合特定抗原的表位是一项重要的任务。了解抗体结构和其表位可以促进对其功能的机制理解。因此，从其序列预测抗体结构一直是一项高度有价值的任务，而AlphaFold2提供了一种基于蛋白质序列预测蛋白质结构的解决方案，但对于抗体，特别是对于抗体的互补决定区（CDRs），其预测效率和准确性有限制。

    In the field of antibody engineering, an essential task is to design a novel antibody whose paratopes bind to a specific antigen with correct epitopes. Understanding antibody structure and its paratope can facilitate a mechanistic understanding of its function. Therefore, antibody structure prediction from its sequence alone has always been a highly valuable problem for de novo antibody design. AlphaFold2, a breakthrough in the field of structural biology, provides a solution to predict protein structure based on protein sequences and computationally expensive coevolutionary multiple sequence alignments (MSAs). However, the computational efficiency and undesirable prediction accuracy of antibodies, especially on the complementarity-determining regions (CDRs) of antibodies limit their applications in the industrially high-throughput drug design. To learn an informative representation of antibodies, we employed a deep antibody language model (ALM) on curated sequences from the observed a
    
[^77]: 通过合作推理诱导的语言模型解决数学应用题

    Solving Math Word Problems via Cooperative Reasoning induced Language Models. (arXiv:2210.16257v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.16257](http://arxiv.org/abs/2210.16257)

    该论文提出了一种基于合作推理诱导的语言模型——CoRe，可以高效地解决数学应用题。实验表明，CoRe 在准确性和效率方面优于现有最先进的方法。

    

    大规模预训练语言模型 (PLMs) 为需要高水平智能的挑战性问题（如数学应用题）带来了新的机遇。然而，直接应用现有的 PLMs 到数学应用题上会失败，因为其生成的过程缺乏足够的监督，缺乏像人类一样的快速适应性。我们注意到人类的推理过程有一个双重推理框架，包括一个即时反应系统 (system 1) 和一个精细推理系统 (system 2)，整个推理过程由它们的交互决定。这启发我们开发了一种合作推理诱导的 PLM 模型，称为 Cooperative Reasoning (CoRe)，得到了一个像人类推理结构的架构，其中 system 1 作为生成器，system 2 作为验证器。在我们的方法中，生成器负责产生推理路径，验证器用于监督评估以获取可靠的反馈信息。我们在基准数据集上评估了我们的模型，实验结果表明，CoRe 在准确性和效率方面优于现有最先进的方法。

    Large-scale pre-trained language models (PLMs) bring new opportunities to challenging problems, especially those that need high-level intelligence, such as the math word problem (MWPs). However, directly applying existing PLMs to MWPs can fail as the generation process lacks sufficient supervision and thus lacks fast adaptivity as humans. We notice that human reasoning has a dual reasoning framework that consists of an immediate reaction system (system 1) and a delicate reasoning system (system 2), where the entire reasoning is determined by their interaction. This inspires us to develop a cooperative reasoning-induced PLM for solving MWPs, called Cooperative Reasoning (CoRe), resulting in a human-like reasoning architecture with system 1 as the generator and system 2 as the verifier. In our approach, the generator is responsible for generating reasoning paths, and the verifiers are used to supervise the evaluation in order to obtain reliable feedback for the generator. We evaluate our
    
[^78]: 以环境成本为代价进行持续训练是否值得？对于时间适应性的证据不足。

    Is It Worth the (Environmental) Cost? Limited Evidence for Temporal Adaptation via Continuous Training. (arXiv:2210.07365v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.07365](http://arxiv.org/abs/2210.07365)

    本研究发现，在社交媒体数据的下游任务中，经过时间调整的英语模型性能并不会随时间改善，而没有经过时间调整的预训练模型实际上更加有效和高效。

    

    语言不断变化和演变，从而导致语言模型很快过时。因此，我们应该通过新数据不断更新我们的模型，使其暴露于新的事件和事实中。然而，这需要额外的计算，也就意味着新的碳排放。有没有可衡量的效益可以证明这个成本是合理的呢？本文寻找实证证据来支持持续训练。我们重现了现有的基准测试，并扩展了它们，包括额外的时间段、模型和任务。我们的结果表明，针对社交媒体数据的英语模型经过时间调整后的下游任务性能不会随时间改善。没有经过时间调整的预训练模型实际上更加有效和高效。然而，我们也注意到缺乏合适的时间基准。我们的研究结果促使人们对何时以及如何适应语言模型在可持续性方面进行批判性的反思。

    Language is constantly changing and evolving, leaving language models to become quickly outdated. Consequently, we should continuously update our models with new data to expose them to new events and facts. However, that requires additional computing, which means new carbon emissions. Do any measurable benefits justify this cost? This paper looks for empirical evidence to support continuous training. We reproduce existing benchmarks and extend them to include additional time periods, models, and tasks. Our results show that the downstream task performance of temporally adapted English models for social media data do not improve over time. Pretrained models without temporal adaptation are actually significantly more effective and efficient. However, we also note a lack of suitable temporal benchmarks. Our findings invite a critical reflection on when and how to temporally adapt language models, accounting for sustainability.
    
[^79]: 少样本增量事件检测

    Few-shot Incremental Event Detection. (arXiv:2209.01979v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.01979](http://arxiv.org/abs/2209.01979)

    本文提出了少样本增量事件检测任务，针对学习检测带有极少标签数据的新事件类别并保留检测旧类别能力的问题，提出了一套由聚类模块和知识蒸馏模块组成的解决框架，并在 IFSED 数据集上进行了实验验证。

    

    事件检测任务可以从文本中快速检测事件，并为下游的自然语言处理任务提供有力的支持。大多数这样的方法只能检测一组固定的预定义事件类别。扩展它们以检测新类别，而不失去检测旧类别的能力，需要耗费大量成本从头开始重新训练模型。增量学习可以有效解决这个问题，但是需要大量新类别的标记数据。然而，在实践中，新事件类别缺乏高质量的标记数据，导致很难获得足够的训练数据。针对上述问题，我们定义了一个新任务即"少样本增量事件检测"，旨在学习仅有少量数据的新事件类别的检测，同时尽可能地保留检测旧类别的能力。我们基于FewEvent创建了IFSED基准数据集，提出了两个基准测试IFSED-K和IFSED-C以评估模型的性能。为了解决这个任务，我们提出了一个由聚类模块和知识蒸馏模块组成的新框架，用于识别新事件实例和知识传输。在基准数据集上的实验证明了我们的框架可以有效地解决少样本增量事件检测任务。

    Event detection tasks can enable the quick detection of events from texts and provide powerful support for downstream natural language processing tasks. Most such methods can only detect a fixed set of predefined event classes. To extend them to detect a new class without losing the ability to detect old classes requires costly retraining of the model from scratch. Incremental learning can effectively solve this problem, but it requires abundant data of new classes. In practice, however, the lack of high-quality labeled data of new event classes makes it difficult to obtain enough data for model training. To address the above mentioned issues, we define a new task, few-shot incremental event detection, which focuses on learning to detect a new event class with limited data, while retaining the ability to detect old classes to the extent possible. We created a benchmark dataset IFSED for the few-shot incremental event detection task based on FewEvent and propose two benchmarks, IFSED-K 
    
[^80]: 带有属性删除子网络的模块化和按需偏差缓解方法

    Modular and On-demand Bias Mitigation with Attribute-Removal Subnetworks. (arXiv:2205.15171v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.15171](http://arxiv.org/abs/2205.15171)

    提出一种新颖的模块化偏差缓解方法，在推理时间按需集成到核心模型中的独立去偏置子网络，在性别、种族和年龄等受保护属性的分类任务中，该方法在缓解偏差方面是有效的，并且在精度和灵活性方面优于现有技术方法。

    

    社会偏见反映在大型预训练语言模型及其在下游任务中的微调版本中。常见的处理偏差的方法引入了额外的优化标准，并更新模型以达到新的去偏置状态。然而，在实践中，最终用户和从业人员可能更喜欢切换回原始模型，或仅对特定子集的保护属性应用去偏置。为了实现这一点，我们提出了一种新颖的模块化偏差缓解方法，包括独立高度稀疏的去偏置子网络，其中每个去偏置模块可以在推理时间按需集成到核心模型中。我们的方法借鉴了“diff”剪枝的概念，并提出了一种适合于各种表示分离优化的新型训练方式。我们在具有性别、种族和年龄等受保护属性的三个分类任务上进行了实验。结果表明，我们的模块化方法在缓解偏差方面是有效的，并且在精度和灵活性方面优于现有技术方法。

    Societal biases are reflected in large pre-trained language models and their fine-tuned versions on downstream tasks. Common in-processing bias mitigation approaches, such as adversarial training and mutual information removal, introduce additional optimization criteria, and update the model to reach a new debiased state. However, in practice, end-users and practitioners might prefer to switch back to the original model, or apply debiasing only on a specific subset of protected attributes. To enable this, we propose a novel modular bias mitigation approach, consisting of stand-alone highly sparse debiasing subnetworks, where each debiasing module can be integrated into the core model on-demand at inference time. Our approach draws from the concept of \emph{diff} pruning, and proposes a novel training regime adaptable to various representation disentanglement optimizations. We conduct experiments on three classification tasks with gender, race, and age as protected attributes. The resul
    
[^81]: MiniDisc: 最小蒸馏计划用于语言模型压缩

    MiniDisc: Minimal Distillation Schedule for Language Model Compression. (arXiv:2205.14570v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.14570](http://arxiv.org/abs/2205.14570)

    本研究提出了一个叫做MiniDisc的最小蒸馏计划，可以在最少一次尝试中调度最优的教师助手，用于实现语言模型压缩。

    

    最近的研究发现，在教师模型和学生模型之间存在较大的容量差距时，语言模型蒸馏的效果不佳，引入了教师助手辅助蒸馏来弥补差距。然而，现有的基于教师助手的方法需要大量的尝试才能调度出最优的教师助手。为此，我们提出了一种最小蒸馏计划（MiniDisc），可以在最少一次尝试中调度最优的教师助手。MiniDisc是基于教师助手的规模-性能的权衡来度量教师助手的最优性，并可以在不对学生进行实验的情况下调度最优的教师助手。

    Recent studies have uncovered that language model distillation is less effective when facing a large capacity gap between the teacher and the student, and introduced teacher assistant-based distillation to bridge the gap. As a connection, the scale and the performance of the teacher assistant is of vital importance to bring the knowledge from the teacher to the student. However, existing teacher assistant-based methods require maximally many trials before scheduling an optimal teacher assistant. To this end, we propose a minimal distillation schedule (MiniDisc) for scheduling the optimal teacher assistant in minimally one trial. In particular, motivated by the finding that the performance of the student is positively correlated to the scale-performance tradeoff of the teacher assistant, MiniDisc is designed with a $\lambda$-tradeoff to measure the optimality of the teacher assistant without trial distillation to the student. MiniDisc then can schedule the optimal teacher assistant with
    
[^82]: ECOLA: 使用上下文化的语言表示增强时间知识嵌入

    ECOLA: Enhanced Temporal Knowledge Embeddings with Contextualized Language Representations. (arXiv:2203.09590v5 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.09590](http://arxiv.org/abs/2203.09590)

    本文讨论如何将文本数据与时间知识嵌入相结合以加强时间知识嵌入表征的质量，提出了ECOLA方法，该方法考虑了时间因素，并将文本信息注入到时间知识嵌入中。

    

    传统的知识嵌入模型不能充分利用丰富的文本信息，因此已经进行了大量的研究以利用文本来增强知识嵌入。然而，现有的增强方法无法应用于包含时间依赖事件知识和复杂时间动态的时间知识图（tKG）。 特别是，现有的增强方法通常假定知识嵌入是独立于时间的。相反，在tKG模型中，实体嵌入通常会不断演化，这就提出了将时间相关文本与实体对齐的挑战。因此，我们在本文中提出了研究如何将文本数据与时间知识嵌入相结合来增强时间知识嵌入。作为这项任务的一种方法，我们提出了使用上下文化的语言表示增强时间知识嵌入（ECOLA），它考虑了时间因素，并将文本信息注入到时间知识嵌入中。为了评估ECOLA，我们引入了三个数据集

    Since conventional knowledge embedding models cannot take full advantage of the abundant textual information, there have been extensive research efforts in enhancing knowledge embedding using texts. However, existing enhancement approaches cannot apply to temporal knowledge graphs (tKGs), which contain time-dependent event knowledge with complex temporal dynamics. Specifically, existing enhancement approaches often assume knowledge embedding is time-independent. In contrast, the entity embedding in tKG models usually evolves, which poses the challenge of aligning temporally relevant texts with entities. To this end, we propose to study enhancing temporal knowledge embedding with textual data in this paper. As an approach to this task, we propose Enhanced Temporal Knowledge Embeddings with Contextualized Language Representations (ECOLA), which takes the temporal aspect into account and injects textual information into temporal knowledge embedding. To evaluate ECOLA, we introduce three n
    
[^83]: 实践中的QNLP：在量子计算机上运行组合模型的含义。

    QNLP in Practice: Running Compositional Models of Meaning on a Quantum Computer. (arXiv:2102.12846v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2102.12846](http://arxiv.org/abs/2102.12846)

    本文介绍了在嘈杂的中间规模量子计算机上进行的首个大于100个句子数据集的NLP实验结果，成功地训练了解决简单句子分类任务的NLP模型，证明了组合模型的含义与量子理论具有形式相似性。

    

    量子自然语言处理（QNLP）涉及设计和实现旨在在量子硬件上运行的NLP模型。在本文中，我们介绍了在嘈杂的中间规模量子（NISQ）计算机上进行的首个大于100个句子数据集的NLP实验结果。利用由Coecke、Sadrzadeh和Clark（2010）提出的含义组合模型与量子理论的形式相似性，我们创建了具有自然映射到量子电路的句子表示。我们使用这些表示来实现并成功训练在量子硬件上解决简单句子分类任务的NLP模型。我们进行了量子模拟，比较了Coecke等人的语法敏感模型与使用较少或无语法的两个基线，具体而言，我们实现了“词袋”模型的量子模拟，其中根本不考虑语法，以及单词序列模型的量子模拟，仅尊重单词顺序。

    Quantum Natural Language Processing (QNLP) deals with the design and implementation of NLP models intended to be run on quantum hardware. In this paper, we present results on the first NLP experiments conducted on Noisy Intermediate-Scale Quantum (NISQ) computers for datasets of size greater than 100 sentences. Exploiting the formal similarity of the compositional model of meaning by Coecke, Sadrzadeh and Clark (2010) with quantum theory, we create representations for sentences that have a natural mapping to quantum circuits. We use these representations to implement and successfully train NLP models that solve simple sentence classification tasks on quantum hardware. We conduct quantum simulations that compare the syntax-sensitive model of Coecke et al. with two baselines that use less or no syntax; specifically, we implement the quantum analogues of a "bag-of-words" model, where syntax is not taken into account at all, and of a word-sequence model, where only word order is respected.
    
[^84]: 简化版TinyBERT: 用于文档检索的知识蒸馏

    Simplified TinyBERT: Knowledge Distillation for Document Retrieval. (arXiv:2009.07531v2 [cs.IR] CROSS LISTED)

    [http://arxiv.org/abs/2009.07531](http://arxiv.org/abs/2009.07531)

    本文提出了一种基于知识蒸馏的文档检索模型Simplified TinyBERT，它在提供15倍速度提升的情况下比BERT-Base表现更好。

    

    尽管利用BERT模型进行文档排序十分有效，但这种方法的高计算成本限制了其使用。因此，本文首先在文档排序任务上实证研究了两个知识蒸馏模型的有效性。此外，在最近提出的TinyBERT模型基础上，提出了两种简化方案。两个不同并且广泛使用的基准测试的评估表明，具有所提出简化方案的Simplified TinyBERT不仅提升了TinyBERT，而且在提供15倍速度提升的情况下也明显优于BERT-Base。

    Despite the effectiveness of utilizing the BERT model for document ranking, the high computational cost of such approaches limits their uses. To this end, this paper first empirically investigates the effectiveness of two knowledge distillation models on the document ranking task. In addition, on top of the recently proposed TinyBERT model, two simplifications are proposed. Evaluations on two different and widely-used benchmarks demonstrate that Simplified TinyBERT with the proposed simplifications not only boosts TinyBERT, but also significantly outperforms BERT-Base when providing 15$\times$ speedup.
    

