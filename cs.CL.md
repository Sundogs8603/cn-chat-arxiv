# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty.](http://arxiv.org/abs/2401.15077) | EAGLE是一个无损加速语言模型推理的框架，通过在次顶层特征层面上自回归推理，并解决采样不确定性问题，实现了比传统方法更快3倍的速度。 |
| [^2] | [Pairing Orthographically Variant Literary Words to Standard Equivalents Using Neural Edit Distance Models.](http://arxiv.org/abs/2401.15068) | 在本研究中，我们提出了一个新的语料库，用于配对19世纪美国文学作品中的正字异形词汇。我们训练了一组神经编辑距离模型，并与在L2英语学习者的正字错误语料库上训练的模型进行了比较。我们发现文学正字变异对字符串配对方法带来了独特的挑战。 |
| [^3] | [Deep learning-based approach for tomato classification in complex scenes.](http://arxiv.org/abs/2401.15055) | 提出了一种基于深度学习的番茄成熟监测方法，能够在复杂场景中检测成熟番茄并进行采摘。 |
| [^4] | [LongFin: A Multimodal Document Understanding Model for Long Financial Domain Documents.](http://arxiv.org/abs/2401.15050) | LongFin是一个多模态文档理解模型，能够处理长金融领域文档，解决了现有模型在处理长文档时的限制问题。 |
| [^5] | [Health Text Simplification: An Annotated Corpus for Digestive Cancer Education and Novel Strategies for Reinforcement Learning.](http://arxiv.org/abs/2401.15043) | 该论文介绍了一个用于健康文本简化研究的消化癌症教育材料的注释语料库，并探索了基于大型语言模型的简化方法，包括微调、增强学习、增强学习与人类反馈、领域自适应和基于提示的应用。 |
| [^6] | [PROXYQA: An Alternative Framework for Evaluating Long-Form Text Generation with Large Language Models.](http://arxiv.org/abs/2401.15042) | PROXYQA是一个用于评估大型语言模型长篇文本生成的替代框架，通过生成详尽的内容，并利用评估器和生成内容作为背景环境，根据评估器回答代理问题的表现来评估生成内容的质量。 |
| [^7] | [SliceGPT: Compress Large Language Models by Deleting Rows and Columns.](http://arxiv.org/abs/2401.15024) | SliceGPT是一种新的事后训练稀疏化方案，通过将每个权重矩阵替换为较小的矩阵以减小网络的维度，可以在保持高任务性能的同时减少模型参数。 |
| [^8] | [Airavata: Introducing Hindi Instruction-tuned LLM.](http://arxiv.org/abs/2401.15006) | "Airavata"是一个针对印地语进行指令调整的LLM，通过微调OpenHathi和IndicInstruct数据集，提供更好的协助任务性能，并计划扩展到所有22种计划Indic语言。 |
| [^9] | [Embedding-based search in JetBrains IDEs.](http://arxiv.org/abs/2401.14975) | 该论文介绍了在JetBrains IDE中实施的基于嵌入式的搜索功能，通过机器学习方法提高了搜索项的可发现性。 |
| [^10] | [Do LLMs Dream of Ontologies?.](http://arxiv.org/abs/2401.14931) | 本文研究了通用预训练大型语言模型（LLMs）是否记忆了已知本体论的信息以及记忆的程度，结果显示LLMs部分地了解本体论的概念，记忆程度与其在Web上的流行程度成正比。 |
| [^11] | [Comparison of parameters of vowel sounds of russian and english languages.](http://arxiv.org/abs/2401.14890) | 俄罗斯语和英语的元音音素参数进行比较，为多语种语音识别系统提供通用模型，准确识别不确定语言的语音。 |
| [^12] | [The Power of Noise: Redefining Retrieval for RAG Systems.](http://arxiv.org/abs/2401.14887) | 本研究通过分析和评估检索增强生成（RAG）系统中的信息检索（IR）组件，填补了目前研究中忽视的领域，在有效的RAG的提示表述中，不相关文档的包含可能会对系统性能产生负面影响。 |
| [^13] | [F-Eval: Asssessing Fundamental Abilities with Refined Evaluation Methods.](http://arxiv.org/abs/2401.14869) | F-Eval是一个双语评估基准，用于评估大型语言模型的基本能力，包括表达、常识和逻辑。它采用多种任务形式进行评估，包括客观任务和主观任务，并提出了新的评估方法来解决无参考的主观任务评估问题。 |
| [^14] | [ChemDFM: Dialogue Foundation Model for Chemistry.](http://arxiv.org/abs/2401.14818) | ChemDFM是首个面向化学智能的大型语言模型，它通过对化学文献和数据的训练，具备了存储、理解和推理化学知识和语言的能力，并且在化学领域的性能上优于其他开源模型。 |
| [^15] | [Large Language Model Adaptation for Financial Sentiment Analysis.](http://arxiv.org/abs/2401.14777) | 本文研究了针对金融领域的大规模语言模型适应方法，并重点关注金融情感分析。通过在金融文件和说明书上进行精细调优，展示了基础模型在目标领域的适应能力。 |
| [^16] | [Turn-taking and Backchannel Prediction with Acoustic and Large Language Model Fusion.](http://arxiv.org/abs/2401.14717) | 这个论文提出了一种利用声学和语言模型进行交替和回应预测的方法，通过融合这两种模型，可以在口语对话中实现更加自然和对话式的互动。 |
| [^17] | [Under the Surface: Tracking the Artifactuality of LLM-Generated Data.](http://arxiv.org/abs/2401.14698) | 本研究是针对大型语言模型（LLM）生成的人工数据的追踪研究，将各种类型的LLM生成文本数据进行了汇总和测试，并揭示了隐藏的质量和多样性问题。这是第一次对LLM生成数据进行综合分析和比较，并引发了对人工数据质量的关注。 |
| [^18] | [Taiyi-Diffusion-XL: Advancing Bilingual Text-to-Image Generation with Large Vision-Language Model Support.](http://arxiv.org/abs/2401.14688) | Taiyi-Diffusion-XL是一个中英双语文本到图像生成模型，通过对CLIP和Stable-Diffusion-XL的能力进行扩展，并通过双语连续预训练来实现。模型通过将常用的汉字整合到CLIP的分词器和嵌入层中，以及使用大型视觉语言模型丰富文本提示，提供了更好的图像标题和高质量的视觉效果。实验证明，该模型在双语图像-文本检索中表现出色。 |
| [^19] | [MasonTigers@LT-EDI-2024: An Ensemble Approach towards Detecting Homophobia and Transphobia in Social Media Comments.](http://arxiv.org/abs/2401.14681) | MasonTigers@LT-EDI-2024团队提出了一种集成方法，用于在十种语言中检测社交媒体评论中的恐同和恶意性别认知，取得了较好的性能表现。 |
| [^20] | [MaLLaM -- Malaysia Large Language Model.](http://arxiv.org/abs/2401.14680) | MaLLaM是马来西亚大型语言模型，通过使用大型数据集和预训练的BPE分词器，在马来语的自然语言理解和生成任务中取得了竞争力，并展示了在捕捉和理解马来西亚语言细微差异方面的有效性，为提升自然语言理解和生成打下了基础。 |
| [^21] | [UNIT-DSR: Dysarthric Speech Reconstruction System Using Speech Unit Normalization.](http://arxiv.org/abs/2401.14664) | UNIT-DSR系统是一种使用语音单元标准化的发音障碍语音重建系统，通过利用自监督学习和语音单元约束发音障碍内容恢复，提升了训练效率和重建质量。 |
| [^22] | [Scientific Large Language Models: A Survey on Biological & Chemical Domains.](http://arxiv.org/abs/2401.14656) | 这篇论文介绍了科学大型语言模型在生物和化学领域的综述，分析了最新进展，并提出了科学LLMs的重要性。 |
| [^23] | [A Korean Legal Judgment Prediction Dataset for Insurance Disputes.](http://arxiv.org/abs/2401.14654) | 这篇论文介绍了一种面向保险争议的韩国法律判决预测数据集，研究发现在数据有限的情况下，使用句子转换器微调方法可以实现与大型数据集相似的性能。 |
| [^24] | [Benchmarking Large Language Models in Complex Question Answering Attribution using Knowledge Graphs.](http://arxiv.org/abs/2401.14640) | 该研究介绍了一种用于评估问题回答归因的新方法，并通过对大型语言模型进行基准测试，发现现有的评估器在细粒度的归因设置下表现不佳，同时在复杂的引文-陈述推理中也存在弱点。 |
| [^25] | [T-Rex: Text-assisted Retrosynthesis Prediction.](http://arxiv.org/abs/2401.14637) | T-Rex是一种利用文本信息辅助反向合成预测的方法，在两个数据集上表现出色，优于基于图结构的方法。 |
| [^26] | [An Empirical Investigation of Domain Adaptation Ability for Chinese Spelling Check Models.](http://arxiv.org/abs/2401.14630) | 该论文通过构建领域特定术语的新数据集，对各种典型的中文拼写检查（CSC）模型的领域适应能力进行了全面评估，结果表明这些模型在新领域中的性能显著下降。 |
| [^27] | [Toward Practical Automatic Speech Recognition and Post-Processing: a Call for Explainable Error Benchmark Guideline.](http://arxiv.org/abs/2401.14625) | 传统ASR评估方法无法全面了解特定脆弱性，同时后处理阶段也缺乏详细信息，这对用户友好性产生负面影响。为了解决这个问题，需要综合考虑语音层面和文本层面，并提出了错误可解释性基准指南。 |
| [^28] | [Query of CC: Unearthing Large Scale Domain-Specific Knowledge from Public Corpora.](http://arxiv.org/abs/2401.14624) | 本论文提出了一种通过大型语言模型来收集特定领域知识的高效方法，通过该方法构建了一个高质量的名为“Knowledge Pile”的数据集，实验证明其显著改善了特定领域的数据稀缺问题。 |
| [^29] | [Alternative Speech: Complementary Method to Counter-Narrative for Better Discourse.](http://arxiv.org/abs/2401.14616) | 该论文引入了“替代性言论”作为直接对抗仇恨言论的新方法，并提供了构建所需数据集的指导。替代性言论通过提供实际可行的替代方案，考虑环境因素并促使演讲者改变，为解决社会问题提供有用工具。将替代性言论与对抗叙事结合使用可以更有效地对抗仇恨言论，补充了对抗叙事的能力。 |
| [^30] | [Enhancing Diagnostic Accuracy through Multi-Agent Conversations: Using Large Language Models to Mitigate Cognitive Bias.](http://arxiv.org/abs/2401.14589) | 本研究旨在通过利用大型语言模型和多智能体对话的方式来减轻临床决策中的认知偏差，并评估其对提高诊断准确性的有效性。 |
| [^31] | [Detecting Structured Language Alternations in Historical Documents by Combining Language Identification with Fourier Analysis.](http://arxiv.org/abs/2401.14569) | 本研究提出了一种结合语言识别和傅里叶分析的方法，用于检测历史文献中亚美尼亚土耳其语的结构化语言交替。 |
| [^32] | [Language Modelling Approaches to Adaptive Machine Translation.](http://arxiv.org/abs/2401.14559) | 自适应机器翻译中的语言建模方法，通过利用大型语言模型(LLMs)来在特定上下文中学习、改进翻译质量，解决了在域适应中因缺乏域内数据而导致翻译不一致的问题。 |
| [^33] | [Do Not (Always) Look Right: Investigating the Capabilities of Decoder-Based Large Language Models for Sequence Labeling.](http://arxiv.org/abs/2401.14556) | 本文研究了基于解码器的大型语言模型在序列标注方面的能力，并探索了提高它们性能的策略。 |
| [^34] | [Relative Value Biases in Large Language Models.](http://arxiv.org/abs/2401.14530) | 该研究发现大型语言模型在做选择时表现出了与人类和动物相似的相对价值偏差，这对于理解人类选择中的背景依赖性机制具有重要意义。 |
| [^35] | [MEDs for PETs: Multilingual Euphemism Disambiguation for Potentially Euphemistic Terms.](http://arxiv.org/abs/2401.14526) | 本研究讨论了跨多语言的委婉语处理，并通过多语言转换器模型成功消歧潜在委婉术语。结果显示多语言模型在该任务上的表现优于单语言模型，从而证明多语言数据对于跨语言委婉语的计算特性具有额外的潜力。 |
| [^36] | [Evaluating GPT-3.5's Awareness and Summarization Abilities for European Constitutional Texts with Shared Topics.](http://arxiv.org/abs/2401.14524) | 本研究通过利用GPT-3.5模型，在多国宪法文本中进行宝贵的摘要总结，特别关注于与公民权利和义务相关的欧洲国家宪法段落，结果显示其能够准确、连贯且忠实地捕捉到RD主题。 |
| [^37] | [Empathy and the Right to Be an Exception: What LLMs Can and Cannot Do.](http://arxiv.org/abs/2401.14523) | LLMs既有能力归因于信念、欲望、意图和情感，也能在准确性方面不断提高，但他们无法通过共情方法来尊重个体成为例外的权利。他们仅通过识别语言模式判断案件相似性，而无法考虑个体的内部心理状态。我们提出了共情的方法。 |
| [^38] | [K-QA: A Real-World Medical Q&A Benchmark.](http://arxiv.org/abs/2401.14493) | 本研究构建了K-QA数据集，包含1212个真实世界医疗对话中的患者问题，并聘请内部医生回答和分解。研究还制定了两个基于NLI的评估指标，用于评估模型的召回率和精确度。研究结果对于提升大型语言模型在临床环境下的准确性具有重要意义。 |
| [^39] | [LongHealth: A Question Answering Benchmark with Long Clinical Documents.](http://arxiv.org/abs/2401.14490) | LongHealth是一个具有长篇临床文档的问答基准，用于评估大型语言模型在处理真实世界中的长篇临床数据方面的能力。最高准确性观察在信息提取任务中，Mixtral-8x7B-Instruct-v0.1在从单个和多个病患文档中检索信息的任务中表现最好。 |
| [^40] | [Wordflow: Social Prompt Engineering for Large Language Models.](http://arxiv.org/abs/2401.14447) | 本文提出了一种名为Wordflow的工具，通过社交提示工程的方式让非专家用户更好地使用大型语言模型（LLMs），并可以轻松创建、运行、共享和发现LLM提示。通过利用现代网络技术，Wordflow允许用户在浏览器中本地和私下运行LLM。 |
| [^41] | [Semantic Sensitivities and Inconsistent Predictions: Measuring the Fragility of NLI Models.](http://arxiv.org/abs/2401.14440) | 这份论文研究发现，最先进的NLI模型对微小的语义保持表面形式变化非常敏感，导致推断结果不一致。其行为与对组合语义的有效理解不同，这对当前NLI模型的可靠性提出了挑战。 |
| [^42] | [DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence.](http://arxiv.org/abs/2401.14196) | DeepSeek-Coder是一系列开源代码模型，通过在高质量项目级代码语料库上进行预训练和采用填空任务和16K窗口来增强代码生成和填充，不仅在多个基准测试中取得了与开源代码模型同样的最新表现，而且超过了现有的闭源模型。 |
| [^43] | [CMMU: A Benchmark for Chinese Multi-modal Multi-type Question Understanding and Reasoning.](http://arxiv.org/abs/2401.14011) | CMMU是一个用于中文多模态多类型问题理解和推理的基准测试，涵盖了从小学到高中的知识，提供了多项选择题、多项回答题和填空题三种类型的问题，对于评估多模态大型语言模型的智能水平具有重要意义。 |
| [^44] | [Unfair TOS: An Automated Approach using Customized BERT.](http://arxiv.org/abs/2401.11207) | 本研究利用定制的BERT与SVC的集成，针对ToS文档中的不公平条款进行了SOTA级别的检测，取得了出色的结果。 |
| [^45] | [Gaussian Adaptive Attention is All You Need: Robust Contextual Representations Across Multiple Modalities.](http://arxiv.org/abs/2401.11143) | 该论文提出了一个名为GAAM的多头高斯自适应注意力机制，用于增强跨多个模态的信息聚合。通过将可学习的均值和方差纳入注意力机制中，GAAM能够动态地重新调整特征的重要性，从而在处理非平稳数据时取得了显著的性能提升，超过了目前现有的注意力技术。该方法的适应性强且参数数量较少，具有改进现有注意力框架的潜力。 |
| [^46] | [Chem-FINESE: Validating Fine-Grained Few-shot Entity Extraction through Text Reconstruction.](http://arxiv.org/abs/2401.10189) | 这篇论文提出了一种名为Chem-FINESE的方法来处理化学领域中细粒度少样本实体提取的问题。该方法通过使用序列到序列的实体提取器和自我验证模块来从输入句子中提取命名实体并重构原始输入句子。实验证明了该方法的有效性和可行性。 |
| [^47] | [Better Explain Transformers by Illuminating Important Information.](http://arxiv.org/abs/2401.09972) | 通过在层间相关传播方法之上使用精细化的信息流，该论文提出了一种解释Transformer模型的方法，突出重要信息并消除无关信息。实验证明，在处理分类和问答任务时，这种方法相比其他八种基线模型更加出色。 |
| [^48] | [DevEval: Evaluating Code Generation in Practical Software Projects.](http://arxiv.org/abs/2401.06401) | 本文提出了一个名为DevEval的新基准测试，用于评估实际软件项目中的代码生成。与之前的基准测试相比，DevEval在真实的项目分布、充足的依赖和足够规模的项目背景等方面更贴合实际。通过对五个流行的大型语言模型进行评估，我们揭示了它们在代码生成中的实际能力。 |
| [^49] | [ArabIcros: AI-Powered Arabic Crossword Puzzle Generation for Educational Applications.](http://arxiv.org/abs/2312.01339) | 本文介绍了基于人工智能技术的阿拉伯语填字游戏生成器ArabIcros，利用先进的语言模型生成独特且具有挑战性的线索，并通过教育性填字游戏提升学习体验，改变传统学习方法的格局。 |
| [^50] | [Personalised Distillation: Empowering Open-Sourced LLMs with Adaptive Learning for Code Generation.](http://arxiv.org/abs/2310.18628) | 通过个性化蒸馏，将闭源LLMs的能力传递给开源LLMs，并在代码生成任务中表现出比标准蒸馏更好的性能，只使用三分之一的数据。 |
| [^51] | [Product Attribute Value Extraction using Large Language Models.](http://arxiv.org/abs/2310.12537) | 本文研究使用大型语言模型作为预训练的替代方法，解决了传统属性/值提取技术中需要大量训练数据和对未知属性值的挑战问题。 |
| [^52] | [ECoFLaP: Efficient Coarse-to-Fine Layer-Wise Pruning for Vision-Language Models.](http://arxiv.org/abs/2310.02998) | ECoFLaP提出了一种高效的粗到细的逐层剪枝方法，解决了大型视觉语言模型在压缩和部署时的计算和能耗问题。 |
| [^53] | [ChaCha: Leveraging Large Language Models to Prompt Children to Share Their Emotions about Personal Events.](http://arxiv.org/abs/2309.12244) | ChaCha是一个利用大型语言模型（LLMs）的聊天机器人，鼓励儿童分享个人事件和相关情绪。通过一个探索性研究，发现儿童将ChaCha视为亲密的朋友，并愿意与其分享各种主题的故事。 |
| [^54] | [Dual-Modal Attention-Enhanced Text-Video Retrieval with Triplet Partial Margin Contrastive Learning.](http://arxiv.org/abs/2309.11082) | 本文提出了一种双模态注意增强的文本-视频检索方法，通过引入新颖的对比学习技术，能够准确衡量跨模态相似性和挖掘难负样本。 |
| [^55] | [OYXOY: A Modern NLP Test Suite for Modern Greek.](http://arxiv.org/abs/2309.07009) | 本文提出了一种适用于希腊语自然语言处理的现代NLP测试套件，其中包含四个专家验证的评估任务，用于自然语言推理、词义消歧和隐喻检测。创新之处在于推理数据集首次标记了所有可能的推理标签，并且展示了一种对于资源匮乏语言获取数据集的成本效益方法。 |
| [^56] | [HC3 Plus: A Semantic-Invariant Human ChatGPT Comparison Corpus.](http://arxiv.org/abs/2309.02731) | 本文介绍了HC3 Plus，一个语义不变的人类ChatGPT对比语料库。与以往的工作相比，该语料库考虑了更多类型的任务，包括语义不变任务。研究发现，在语义不变任务中检测模型生成的文本更加困难。通过大量任务指令微调和Tk-instruct，建立了一个更强大的模型。 |
| [^57] | [FlexKBQA: A Flexible LLM-Powered Framework for Few-Shot Knowledge Base Question Answering.](http://arxiv.org/abs/2308.12060) | FlexKBQA使用大型语言模型(LLMs)作为程序翻译器，通过自动化算法从知识库中抽样多样的程序，将其转换为自然语言问题，从而解决少样本知识库问答任务的挑战。 |
| [^58] | [LogPrompt: Prompt Engineering Towards Zero-Shot and Interpretable Log Analysis.](http://arxiv.org/abs/2308.07610) | LogPrompt是一种新颖的零样本和可解释的日志分析方法，通过利用大型语言模型和专为日志任务设计的高级提示策略，实现了对日志的分析，提高了模型的性能和可解释性。 |
| [^59] | [Forget Demonstrations, Focus on Learning from Textual Instructions.](http://arxiv.org/abs/2308.03795) | 本研究提出了一种从文本指令中学习任务的方法，通过自动找出定义中的关键句子和使用排名目标，实现了最先进的性能。 |
| [^60] | [MeetEval: A Toolkit for Computation of Word Error Rates for Meeting Transcription Systems.](http://arxiv.org/abs/2307.11394) | MeetEval是一个计算会议转录系统字错误率的工具包，它通过时间约束来提高匹配质量并加速匹配算法。 |
| [^61] | [Analyzing Dataset Annotation Quality Management in the Wild.](http://arxiv.org/abs/2307.08153) | 该论文调查分析了自然语言数据集的创建过程中的质量管理实践，并提供了相应的建议。研究表明，流行数据集中存在较多的错误注释、偏见或注释伪像。这项研究的贡献是在这一领域进行了大规模的实证分析，并提出了实践指南。 |
| [^62] | [Learning to Retrieve In-Context Examples for Large Language Models.](http://arxiv.org/abs/2307.07164) | 本文提出了一个新颖的框架，通过迭代训练密集检索器来为大型语言模型识别高质量的上下文示例，从而显著提高了上下文学习性能，并展示了在训练期间对未见过任务的泛化能力。 |
| [^63] | [Multiple output samples per input in a single-output Gaussian process.](http://arxiv.org/abs/2306.02719) | 本文提出了在单输出高斯过程中允许单个输入具有多个输出样本的方法，以利用可用的输出不确定性信息。通过在speechocean762数据集上的评估，展示了该方法能够计算出更接近多个人工评级器参考输出集的测试集输出分布。 |
| [^64] | [ChatGPT Evaluation on Sentence Level Relations: A Focus on Temporal, Causal, and Discourse Relations.](http://arxiv.org/abs/2304.14827) | 本论文评估了ChatGPT在句子级别的时间、因果和语篇关系任务中的性能，发现其在检测和推理因果关系上表现出色，但在识别时间顺序方面可能存在问题。 |
| [^65] | [Are Character-level Translations Worth the Wait? Comparing Character- and Subword-level Models for Machine Translation.](http://arxiv.org/abs/2302.14220) | 本文比较了字符级别和子词级别的预训练模型在机器翻译方面的效果，结果表明字符级别建模在形似单词和稀有单词的翻译方面具有更好的效果，在训练数据有限的情况下尤为明显。 |
| [^66] | [A* shortest string decoding for non-idempotent semirings.](http://arxiv.org/abs/2204.07236) | 该论文提出了一种对非幂等半环上的带权有限状态自动机进行最短字符串解码的算法，通过使用等价确定性自动机的反向最短距离作为启发式，可以有效地找到最短字符串。 |

# 详细

[^1]: EAGLE: 推测采样需要重新思考特征不确定性

    EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty. (arXiv:2401.15077v1 [cs.LG])

    [http://arxiv.org/abs/2401.15077](http://arxiv.org/abs/2401.15077)

    EAGLE是一个无损加速语言模型推理的框架，通过在次顶层特征层面上自回归推理，并解决采样不确定性问题，实现了比传统方法更快3倍的速度。

    

    自回归解码使得大型语言模型（LLMs）的推理变得耗时。我们提出了一个简单的框架，EAGLE（用于提高语言模型效率的外推算法），实现了无损加速。与传统的推测采样方法不同，EAGLE在更规律的（次顶层）特征层面上自回归进行编写，并通过整合提前一个时间步的标记来解决下一个特征预测问题中的采样不确定性。EAGLE所提供的加速是无损的：它不需要微调目标LLM，并且生成的文本与原始的自回归解码的分布相同。截至本文提交时，EAGLE是已知推测采样家族中速度最快的框架。在MT-bench上，EAGLE比原始解码快3倍，比Lookahead快2倍，比Medusa快1.6倍。使用gpt-fast，EAGLE平均每秒达到160个标记与LLaMA2-Chat搭配。

    Auto-regressive decoding makes the inference of Large Language Models (LLMs) time-consuming. We propose a simple framework, EAGLE (Extrapolation Algorithm for Greater Language-model Efficiency), for lossless acceleration. Unlike traditional speculative sampling methods, EAGLE operates the drafting process auto-regressively at the more regular (second-top-layer) feature level and addresses the sampling uncertainty issues in the next-feature prediction problems by integrating tokens from one time step ahead. The acceleration provided by EAGLE is lossless: it involves no fine-tuning of the target LLM, and the generated text maintains the same distribution as that of vanilla auto-regressive decoding. As of the submission of this paper, EAGLE is the fastest known framework within the speculative sampling family. On MT-bench, EAGLE is 3x faster than vanilla decoding, 2x faster than Lookahead, and 1.6x faster than Medusa. Using gpt-fast, EAGLE attains on average 160 tokens/s with LLaMA2-Chat 
    
[^2]: 使用神经编辑距离模型将正字异形文学词汇与标准对应词配对

    Pairing Orthographically Variant Literary Words to Standard Equivalents Using Neural Edit Distance Models. (arXiv:2401.15068v1 [cs.CL])

    [http://arxiv.org/abs/2401.15068](http://arxiv.org/abs/2401.15068)

    在本研究中，我们提出了一个新的语料库，用于配对19世纪美国文学作品中的正字异形词汇。我们训练了一组神经编辑距离模型，并与在L2英语学习者的正字错误语料库上训练的模型进行了比较。我们发现文学正字变异对字符串配对方法带来了独特的挑战。

    

    我们提出了一个新的语料库，其中包含19世纪美国文学作品中的正字异形词汇，并对其进行了对应的“标准”词对的标注。我们训练了一组神经编辑距离模型，将这些变体与它们的标准形式进行配对，并将这些模型的性能与训练在L2英语学习者的正字错误语料库上的一组神经编辑距离模型的性能进行比较。最后，我们分析了这些模型在不同负训练样本生成策略下的相对性能，并对文学正字变异对字符串配对方法带来的独特挑战提出了结论性的意见。

    We present a novel corpus consisting of orthographically variant words found in works of 19th century U.S. literature annotated with their corresponding "standard" word pair. We train a set of neural edit distance models to pair these variants with their standard forms, and compare the performance of these models to the performance of a set of neural edit distance models trained on a corpus of orthographic errors made by L2 English learners. Finally, we analyze the relative performance of these models in the light of different negative training sample generation strategies, and offer concluding remarks on the unique challenge literary orthographic variation poses to string pairing methodologies.
    
[^3]: 基于深度学习的复杂场景中番茄分类的方法

    Deep learning-based approach for tomato classification in complex scenes. (arXiv:2401.15055v1 [cs.CV])

    [http://arxiv.org/abs/2401.15055](http://arxiv.org/abs/2401.15055)

    提出了一种基于深度学习的番茄成熟监测方法，能够在复杂场景中检测成熟番茄并进行采摘。

    

    追踪番茄成熟是一项耗时且劳动密集的任务。结合人工智能技术和计算机视觉技术可以帮助用户优化监测植物成熟状态的过程。为此，我们提出了一种基于深度学习的番茄成熟监测方法，适用于复杂场景。目标是及时检测成熟番茄并进行采摘。该方法分为两个部分。首先，场景图像被传输到预处理层，该过程可检测到感兴趣区域（包含番茄的图像区域）。然后，这些图像被用作成熟度检测层的输入。该层基于深度神经网络学习算法，对其提供的番茄缩略图进行分类，共分为五个类别：绿色、易碎、粉色、淡红、成熟红。实验基于从互联网上收集的图像，通过使用番茄关键词进行搜索获得。

    Tracking ripening tomatoes is time consuming and labor intensive. Artificial intelligence technologies combined with those of computer vision can help users optimize the process of monitoring the ripening status of plants. To this end, we have proposed a tomato ripening monitoring approach based on deep learning in complex scenes. The objective is to detect mature tomatoes and harvest them in a timely manner. The proposed approach is declined in two parts. Firstly, the images of the scene are transmitted to the pre-processing layer. This process allows the detection of areas of interest (area of the image containing tomatoes). Then, these images are used as input to the maturity detection layer. This layer, based on a deep neural network learning algorithm, classifies the tomato thumbnails provided to it in one of the following five categories: green, brittle, pink, pale red, mature red. The experiments are based on images collected from the internet gathered through searches using tom
    
[^4]: LongFin：一种面向长金融领域文档的多模态文档理解模型

    LongFin: A Multimodal Document Understanding Model for Long Financial Domain Documents. (arXiv:2401.15050v1 [cs.CL])

    [http://arxiv.org/abs/2401.15050](http://arxiv.org/abs/2401.15050)

    LongFin是一个多模态文档理解模型，能够处理长金融领域文档，解决了现有模型在处理长文档时的限制问题。

    

    文档AI是一个不断发展的研究领域，其专注于理解和从扫描和数字文档中提取信息，以使日常业务操作更加高效。虽然已经引入了许多下游任务和数据集来促进训练能够解析和提取各种文档类型（如收据和扫描表单）信息的AI模型，但是现有的数据集和模型都无法解决工业环境中出现的关键挑战。现有数据集主要由单页组成的短文档构成，而现有模型受限于最大长度的限制，通常限制在512个标记。因此，在金融服务中实际应用这些方法会受到严重限制，因为文档可能跨越多个页面。为了解决这些挑战，我们引入了LongFin，一种能够编码多达4K个标记的多模态文档AI模型。同时，我们还提出了LongForms

    Document AI is a growing research field that focuses on the comprehension and extraction of information from scanned and digital documents to make everyday business operations more efficient. Numerous downstream tasks and datasets have been introduced to facilitate the training of AI models capable of parsing and extracting information from various document types such as receipts and scanned forms. Despite these advancements, both existing datasets and models fail to address critical challenges that arise in industrial contexts. Existing datasets primarily comprise short documents consisting of a single page, while existing models are constrained by a limited maximum length, often set at 512 tokens. Consequently, the practical application of these methods in financial services, where documents can span multiple pages, is severely impeded. To overcome these challenges, we introduce LongFin, a multimodal document AI model capable of encoding up to 4K tokens. We also propose the LongForms
    
[^5]: 健康文本简化：消化癌症教育的注释语料库和增强学习的新策略

    Health Text Simplification: An Annotated Corpus for Digestive Cancer Education and Novel Strategies for Reinforcement Learning. (arXiv:2401.15043v1 [cs.CL])

    [http://arxiv.org/abs/2401.15043](http://arxiv.org/abs/2401.15043)

    该论文介绍了一个用于健康文本简化研究的消化癌症教育材料的注释语料库，并探索了基于大型语言模型的简化方法，包括微调、增强学习、增强学习与人类反馈、领域自适应和基于提示的应用。

    

    目标：健康教育材料的阅读水平显著影响信息的可理解性和可接触性，特别是对于少数族裔人群。许多患者教育资源超过了广泛接受的标准的阅读水平和复杂性。在健康信息中，急需高性能的文本简化模型以增强传播和识字能力。这种需要在癌症教育中尤为迫切，有效的预防和筛查教育可以大大减少发病率和死亡率。方法：我们引入了简化的消化癌症（SimpleDC）并行语料库，用于健康文本简化研究。利用SimpleDC和现有的Med-EASi语料库，我们探索了基于大型语言模型（LLM）的简化方法，包括微调、增强学习（RL）、增强学习与人类反馈（RLHF）、领域自适应和基于提示的应用。

    Objective: The reading level of health educational materials significantly influences information understandability and accessibility, particularly for minoritized populations. Many patient educational resources surpass the reading level and complexity of widely accepted standards. There is a critical need for high-performing text simplification models in health information to enhance dissemination and literacy. This need is particularly acute in cancer education, where effective prevention and screening education can substantially reduce morbidity and mortality.  Methods: We introduce Simplified Digestive Cancer (SimpleDC), a parallel corpus of cancer education materials tailored for health text simplification research. Utilizing SimpleDC alongside the existing Med-EASi corpus, we explore Large Language Model (LLM)-based simplification methods, including fine-tuning, reinforcement learning (RL), reinforcement learning with human feedback (RLHF), domain adaptation, and prompt-based app
    
[^6]: PROXYQA：一种用于评估大型语言模型长篇文本生成的替代框架

    PROXYQA: An Alternative Framework for Evaluating Long-Form Text Generation with Large Language Models. (arXiv:2401.15042v1 [cs.CL])

    [http://arxiv.org/abs/2401.15042](http://arxiv.org/abs/2401.15042)

    PROXYQA是一个用于评估大型语言模型长篇文本生成的替代框架，通过生成详尽的内容，并利用评估器和生成内容作为背景环境，根据评估器回答代理问题的表现来评估生成内容的质量。

    

    大型语言模型（LLM）在长篇文本理解任务中取得了显著的成功。然而，它们生成长篇内容（如报告和文章）的能力尚未得到充分探索。当前的基准不足以充分评估LLMs生成信息丰富且全面的内容，因此需要一种更严格的评估方法。在本研究中，我们介绍了一种名为\textsc{ProxyQA}的框架，用于评估长篇文本生成，包括深入人工策划的涵盖多个领域的“元问题”。每个元问题都包含相应的带注释答案的“代理问题”。LLMs被要求根据这些元问题生成详尽的内容。利用评估器并将生成的内容作为背景环境，\textsc{ProxyQA}根据评估器回答“代理问题”的表现评估生成内容的质量。我们检验了多个LLMs，重点关注了...

    Large Language Models (LLMs) have exhibited remarkable success in long-form context comprehension tasks. However, their capacity to generate long contents, such as reports and articles, remains insufficiently explored. Current benchmarks do not adequately assess LLMs' ability to produce informative and comprehensive content, necessitating a more rigorous evaluation approach. In this study, we introduce \textsc{ProxyQA}, a framework for evaluating long-form text generation, comprising in-depth human-curated \textit{meta-questions} spanning various domains. Each meta-question contains corresponding \textit{proxy-questions} with annotated answers. LLMs are prompted to generate extensive content in response to these meta-questions. Utilizing an evaluator and incorporating generated content as background context, \textsc{ProxyQA} evaluates the quality of generated content based on the evaluator's performance in answering the \textit{proxy-questions}. We examine multiple LLMs, emphasizing \t
    
[^7]: SliceGPT: 通过删除行和列来压缩大型语言模型

    SliceGPT: Compress Large Language Models by Deleting Rows and Columns. (arXiv:2401.15024v1 [cs.LG])

    [http://arxiv.org/abs/2401.15024](http://arxiv.org/abs/2401.15024)

    SliceGPT是一种新的事后训练稀疏化方案，通过将每个权重矩阵替换为较小的矩阵以减小网络的维度，可以在保持高任务性能的同时减少模型参数。

    

    大型语言模型已成为自然语言处理的基石，但使用它们需要大量计算和内存资源。稀疏化方法可以缓解这些资源限制，并且最近的研究表明训练好的模型可以进行事后的稀疏化处理。现有的稀疏化技术面临着挑战，因为它们需要额外的数据结构，并且在当前硬件上速度受限。在本文中，我们提出了一种新的事后训练稀疏化方案SliceGPT，该方案用较小的（稠密的）矩阵替换每个权重矩阵，从而减小网络的嵌入维度。通过大量的实验，我们展示了SliceGPT在保持相应稠密模型的99%、99%和90%的零-shot任务性能的同时，可以移除LLAMA2-70B、OPT 66B和Phi-2模型中多达25%的模型参数（包括嵌入）。我们的切片模型在较少的GPU上运行并且更快，无需额外的代码优化。

    Large language models have become the cornerstone of natural language processing, but their use comes with substantial costs in terms of compute and memory resources. Sparsification provides a solution to alleviate these resource constraints, and recent works have shown that trained models can be sparsified post-hoc. Existing sparsification techniques face challenges as they need additional data structures and offer constrained speedup with current hardware. In this paper we present SliceGPT, a new post-training sparsification scheme which replaces each weight matrix with a smaller (dense) matrix, reducing the embedding dimension of the network. Through extensive experimentation, we show that SliceGPT can remove up to 25% of the model parameters (including embeddings) for LLAMA2-70B, OPT 66B and Phi-2 models while maintaining 99%, 99% and 90% zero-shot task performance of the dense model respectively. Our sliced models run on fewer GPUs and run faster without any additional code optimi
    
[^8]: Airavata: 引入针对印地语指令调整的LLM

    Airavata: Introducing Hindi Instruction-tuned LLM. (arXiv:2401.15006v1 [cs.CL])

    [http://arxiv.org/abs/2401.15006](http://arxiv.org/abs/2401.15006)

    "Airavata"是一个针对印地语进行指令调整的LLM，通过微调OpenHathi和IndicInstruct数据集，提供更好的协助任务性能，并计划扩展到所有22种计划Indic语言。

    

    我们宣布首次发布了"Airavata"，这是一个针对印地语进行指令调整的LLM。通过将OpenHathi与各种指令调整的印地语数据集进行微调，Airavata更适合辅助任务。除了模型外，我们还分享了IndicInstruct数据集，这是一组用于进一步研究Indic LLM的多样化指令调整数据集。此外，我们还提供了评估基准和评估框架，以评估LLM在印地语任务中的性能。目前，Airavata支持印地语，但我们计划将其扩展到所有22种计划Indic语言。您可以在https://ai4bharat.github.io/airavata上访问所有工件。

    We announce the initial release of "Airavata," an instruction-tuned LLM for Hindi. Airavata was created by fine-tuning OpenHathi with diverse, instruction-tuning Hindi datasets to make it better suited for assistive tasks. Along with the model, we also share the IndicInstruct dataset, which is a collection of diverse instruction-tuning datasets to enable further research for Indic LLMs. Additionally, we present evaluation benchmarks and a framework for assessing LLM performance across tasks in Hindi. Currently, Airavata supports Hindi, but we plan to expand this to all 22 scheduled Indic languages. You can access all artifacts at https://ai4bharat.github.io/airavata.
    
[^9]: 基于嵌入式的JetBrains IDE的搜索功能

    Embedding-based search in JetBrains IDEs. (arXiv:2401.14975v1 [cs.SE])

    [http://arxiv.org/abs/2401.14975](http://arxiv.org/abs/2401.14975)

    该论文介绍了在JetBrains IDE中实施的基于嵌入式的搜索功能，通过机器学习方法提高了搜索项的可发现性。

    

    大多数现代集成开发环境（IDE）和代码编辑器都具有通过可用功能和项目中的项进行搜索的功能。在JetBrains IDE中，这个功能称为"搜索全部"：它允许用户从一个入口点搜索文件、操作、类、符号、设置以及版本控制系统(VCS)历史记录中的任何内容。然而，它仅通过不考虑语义的算法获取候选项，比如同义词、复杂的单词排列、词性修改和拼写错误等。在这项工作中，我们描述了我们实施的机器学习方法，以提高搜索项的可发现性。我们还分享了在这个过程中遇到的障碍以及如何克服它们。

    Most modern Integrated Development Environments (IDEs) and code editors have a feature to search across available functionality and items in an open project. In JetBrains IDEs, this feature is called Search Everywhere: it allows users to search for files, actions, classes, symbols, settings, and anything from VCS history from a single entry point. However, it works with the candidates obtained by algorithms that don't account for semantics, e.g., synonyms, complex word permutations, part of the speech modifications, and typos. In this work, we describe the machine learning approach we implemented to improve the discoverability of search items. We also share the obstacles encountered during this process and how we overcame them.
    
[^10]: LLM是否能记忆本体论？

    Do LLMs Dream of Ontologies?. (arXiv:2401.14931v1 [cs.CL])

    [http://arxiv.org/abs/2401.14931](http://arxiv.org/abs/2401.14931)

    本文研究了通用预训练大型语言模型（LLMs）是否记忆了已知本体论的信息以及记忆的程度，结果显示LLMs部分地了解本体论的概念，记忆程度与其在Web上的流行程度成正比。

    

    大型语言模型（LLMs）最近在自动文本理解和生成方面取得了革命性的进展。这些模型的性能依赖于底层神经网络体系结构的参数数量，这使得LLMs能够记忆训练过程中接触到的大量数据的一部分。本文研究了通用预训练LLMs是否记忆了已知本体论的信息以及记忆的程度。我们的结果表明，LLMs部分地了解本体论：它们可以记忆文本中提到的本体论概念，但其对概念的记忆程度似乎与其在Web上的流行程度成比例变化，因为Web是它们训练材料的主要来源。此外，我们提出了新的度量标准，通过测量不同提示重复、查询语言和确定度的输出一致性来估计LLMs对本体论信息的记忆程度。

    Large language models (LLMs) have recently revolutionized automated text understanding and generation. The performance of these models relies on the high number of parameters of the underlying neural architectures, which allows LLMs to memorize part of the vast quantity of data seen during the training. This paper investigates whether and to what extent general-purpose pre-trained LLMs have memorized information from known ontologies. Our results show that LLMs partially know ontologies: they can, and do indeed, memorize concepts from ontologies mentioned in the text, but the level of memorization of their concepts seems to vary proportionally to their popularity on the Web, the primary source of their training material. We additionally propose new metrics to estimate the degree of memorization of ontological information in LLMs by measuring the consistency of the output produced across different prompt repetitions, query languages, and degrees of determinism.
    
[^11]: 俄罗斯语和英语元音音素参数的比较

    Comparison of parameters of vowel sounds of russian and english languages. (arXiv:2401.14890v1 [cs.SD])

    [http://arxiv.org/abs/2401.14890](http://arxiv.org/abs/2401.14890)

    俄罗斯语和英语的元音音素参数进行比较，为多语种语音识别系统提供通用模型，准确识别不确定语言的语音。

    

    在多语种语音识别系统中，通常会出现一种情况，即语言事先不知道，但信号已经接收并正在处理中。针对这种情况，需要一种广义模型，它能够对语音的音素差异作出响应，并根据这些差异正确地识别所需语言的语音。为了构建这样一个模型，需要设定音素参数的值，然后比较类似的音素，确定重要的差异。

    In multilingual speech recognition systems, a situation can often arise when the language is not known in advance, but the signal has already been received and is being processed. For such cases, some generalized model is needed that will be able to respond to phonetic differences and, depending on them, correctly recog-nize speech in the desired language. To build such a model, it is necessary to set the values of phonetic parameters, and then compare similar sounds, establishing significant differences.
    
[^12]: 噪声的力量：重新定义RAG系统的检索

    The Power of Noise: Redefining Retrieval for RAG Systems. (arXiv:2401.14887v1 [cs.IR])

    [http://arxiv.org/abs/2401.14887](http://arxiv.org/abs/2401.14887)

    本研究通过分析和评估检索增强生成（RAG）系统中的信息检索（IR）组件，填补了目前研究中忽视的领域，在有效的RAG的提示表述中，不相关文档的包含可能会对系统性能产生负面影响。

    

    检索增强生成（RAG）系统相对于传统的大型语言模型（LLMs）代表了一个重大进步。RAG系统通过整合通过信息检索（IR）阶段检索的外部数据来增强其生成能力，克服了标准LLMs的限制，后者仅限于其预先训练的知识和有限的上下文窗口。这个领域的大部分研究主要集中在RAG系统内LLMs的生成方面。我们的研究填补了这一空白，通过全面而批判性地分析IR组件对RAG系统的影响。本文分析了一个检索器在有效的RAG的提示表述中应该具备的特征，重点关注应该检索哪种类型的文档。我们评估了各种因素，如文档与提示的相关性，它们的位置以及上下文中包含的数量。我们的发现揭示出，包含不相关的文档可能会…

    Retrieval-Augmented Generation (RAG) systems represent a significant advancement over traditional Large Language Models (LLMs). RAG systems enhance their generation ability by incorporating external data retrieved through an Information Retrieval (IR) phase, overcoming the limitations of standard LLMs, which are restricted to their pre-trained knowledge and limited context window. Most research in this area has predominantly concentrated on the generative aspect of LLMs within RAG systems. Our study fills this gap by thoroughly and critically analyzing the influence of IR components on RAG systems. This paper analyzes which characteristics a retriever should possess for an effective RAG's prompt formulation, focusing on the type of documents that should be retrieved. We evaluate various elements, such as the relevance of the documents to the prompt, their position, and the number included in the context. Our findings reveal, among other insights, that including irrelevant documents can
    
[^13]: F-Eval:使用优化的评估方法评估基本能力

    F-Eval: Asssessing Fundamental Abilities with Refined Evaluation Methods. (arXiv:2401.14869v1 [cs.CL])

    [http://arxiv.org/abs/2401.14869](http://arxiv.org/abs/2401.14869)

    F-Eval是一个双语评估基准，用于评估大型语言模型的基本能力，包括表达、常识和逻辑。它采用多种任务形式进行评估，包括客观任务和主观任务，并提出了新的评估方法来解决无参考的主观任务评估问题。

    

    大型语言模型（LLMs）因其前所未有的性能而受到广泛关注，导致越来越多的研究评估LLMs。然而，这些评估基准仅限于评估指令遵循能力，忽视了在预训练阶段出现的基本能力。先前的主观评估方法主要依赖于由API模型评分。然而，在没有参考文献的情况下，大模型显示出有限的能力来区分细微差异。为了弥合这一差距，我们提出了F-Eval，一个双语评估基准，用于评估基本能力，包括表达、常识和逻辑。F-Eval中的任务包括多项选择客观任务、开放式客观任务、基于参考的主观任务和无参考的主观任务。对于无参考的主观任务，我们设计了新的评估方法，作为替代API模型评分的方法。我们对13个先进的LLMs进行了评估。

    Large language models (LLMs) garner significant attention for their unprecedented performance, leading to an increasing number of researches evaluating LLMs. However, these evaluation benchmarks are limited to assessing the instruction-following capabilities, overlooking the fundamental abilities that emerge during the pre-training stage. Previous subjective evaluation methods mainly reply on scoring by API models. However, in the absence of references, large models have shown limited ability to discern subtle differences. To bridge the gap, we propose F-Eval, a bilingual evaluation benchmark to evaluate the fundamental abilities, including expression, commonsense and logic. The tasks in F-Eval include multi-choice objective tasks, open-ended objective tasks, reference-based subjective tasks and reference-free subjective tasks. For reference-free subjective tasks, we devise new evaluation methods, serving as alternatives to scoring by API models. We conduct evaluations on 13 advanced L
    
[^14]: ChemDFM: 化学领域对话基础模型

    ChemDFM: Dialogue Foundation Model for Chemistry. (arXiv:2401.14818v1 [cs.CL])

    [http://arxiv.org/abs/2401.14818](http://arxiv.org/abs/2401.14818)

    ChemDFM是首个面向化学智能的大型语言模型，它通过对化学文献和数据的训练，具备了存储、理解和推理化学知识和语言的能力，并且在化学领域的性能上优于其他开源模型。

    

    大型语言模型(LLMs)在自然语言处理的一般领域取得了巨大成功。它们的任务概括和自由对话能力可以极大地帮助设计化学智能(CGI)，以协助化学领域的实际研究。然而，在化学领域中存在专业语言和知识，如高度信息化的SMILES符号表示法，阻碍了一般领域LLMs在化学领域的性能。为此，我们开发了ChemDFM，这是首个面向CGI的LLM。ChemDFM-13B是在化学文献、教科书、说明书以及各种一般领域的数据中训练的34B令牌。因此，它可以存储、理解和推理化学知识和语言，同时具有先进的自由形式语言理解能力。广泛的定量评估表明，ChemDFM可以明显优于代表性的开源LLMs。此外，ChemDFM还可以...

    Large language models (LLMs) have established great success in the general domain of natural language processing. Their emerging task generalization and free-form dialogue capabilities can greatly help to design Chemical General Intelligence (CGI) to assist real-world research in chemistry. However, the existence of specialized language and knowledge in the field of chemistry, such as the highly informative SMILES notation, hinders the performance of general-domain LLMs in chemistry. To this end, we develop ChemDFM, the first LLM towards CGI. ChemDFM-13B is trained on 34B tokens from chemical literature, textbooks, and instructions as well as various data from the general domain. Therefore, it can store, understand, and reason over chemical knowledge and languages while still possessing advanced free-form language comprehension capabilities. Extensive quantitative evaluation shows that ChemDFM can significantly outperform the representative open-sourced LLMs. Moreover, ChemDFM can also
    
[^15]: 用于金融情感分析的大规模语言模型适应

    Large Language Model Adaptation for Financial Sentiment Analysis. (arXiv:2401.14777v1 [cs.CL])

    [http://arxiv.org/abs/2401.14777](http://arxiv.org/abs/2401.14777)

    本文研究了针对金融领域的大规模语言模型适应方法，并重点关注金融情感分析。通过在金融文件和说明书上进行精细调优，展示了基础模型在目标领域的适应能力。

    

    最近，自然语言处理（NLP）在金融机构中变得越来越重要，因为它可以提供有关公司和市场的金融文件的高度有价值的见解。然而，金融领域的景观对NLP提出了额外的挑战，因为文本的复杂性和特定术语的使用。即使使用具有出色的自然语言理解和生成能力的大规模语言模型（LLM），通用语言模型在专门针对金融的任务上也往往表现不佳。本文提出了一项关于以金融领域为目标的LLM适应方法研究，并高度关注金融情感分析。为此，我们使用了各种广泛的策略来适应两个参数低于15亿的基础模型。我们展示了通过在金融文档和说明书上进行精细调优，这些基础模型可以适应目标领域。此外，我们观察到小型LLM具有相似的适应能力。

    Natural language processing (NLP) has recently gained relevance within financial institutions by providing highly valuable insights into companies and markets' financial documents. However, the landscape of the financial domain presents extra challenges for NLP, due to the complexity of the texts and the use of specific terminology. Generalist language models tend to fall short in tasks specifically tailored for finance, even when using large language models (LLMs) with great natural language understanding and generative capabilities. This paper presents a study on LLM adaptation methods targeted at the financial domain and with high emphasis on financial sentiment analysis. To this purpose, two foundation models with less than 1.5B parameters have been adapted using a wide range of strategies. We show that through careful fine-tuning on both financial documents and instructions, these foundation models can be adapted to the target domain. Moreover, we observe that small LLMs have comp
    
[^16]: 用声学和大型语言模型融合进行交替和回应预测

    Turn-taking and Backchannel Prediction with Acoustic and Large Language Model Fusion. (arXiv:2401.14717v1 [cs.CL])

    [http://arxiv.org/abs/2401.14717](http://arxiv.org/abs/2401.14717)

    这个论文提出了一种利用声学和语言模型进行交替和回应预测的方法，通过融合这两种模型，可以在口语对话中实现更加自然和对话式的互动。

    

    我们提出了一种连续预测口语对话中交替和回应位置的方法，通过融合神经声学模型和大型语言模型（LLM）。在Switchboard人际对话数据集上的实验表明，我们的方法始终优于单模态的基线模型。我们还开发了一种新颖的多任务指令微调策略，以进一步从LLM编码的知识中受益，从而提高了性能。我们的方法展示了使用组合的LLM和声学模型在人类和语音AI代理之间实现更自然和对话式互动的潜力。

    We propose an approach for continuous prediction of turn-taking and backchanneling locations in spoken dialogue by fusing a neural acoustic model with a large language model (LLM). Experiments on the Switchboard human-human conversation dataset demonstrate that our approach consistently outperforms the baseline models with single modality. We also develop a novel multi-task instruction fine-tuning strategy to further benefit from LLM-encoded knowledge for understanding the tasks and conversational contexts, leading to additional improvements. Our approach demonstrates the potential of combined LLMs and acoustic models for a more natural and conversational interaction between humans and speech-enabled AI agents.
    
[^17]: 反思LLM生成数据的真实性：对LLM生成数据的追踪研究

    Under the Surface: Tracking the Artifactuality of LLM-Generated Data. (arXiv:2401.14698v1 [cs.CL])

    [http://arxiv.org/abs/2401.14698](http://arxiv.org/abs/2401.14698)

    本研究是针对大型语言模型（LLM）生成的人工数据的追踪研究，将各种类型的LLM生成文本数据进行了汇总和测试，并揭示了隐藏的质量和多样性问题。这是第一次对LLM生成数据进行综合分析和比较，并引发了对人工数据质量的关注。

    

    本研究探讨了大型语言模型（LLM）在生成人工数据方面的不断扩大的作用。LLM越来越多地用于生成多种输出，包括注释、偏好、指令提示、模拟对话和自由文本。由于这些LLM生成数据形式在应用中经常交叉，它们相互影响，并引发了对训练循环中合并的人工数据质量和多样性的重大关注，形成了一个人工数据生态系统。据我们所知，这是第一项研究将各种类型的LLM生成文本数据汇总起来，从更严格受限的数据如“任务标签”到更自由的“自由文本”。然后我们对LLM生成的人工数据的质量和影响进行了压力测试，并与人工数据在各种现有基准上进行比较。尽管人工数据能够匹配人类表现，但本文揭示了隐藏的巨大隐患。

    This work delves into the expanding role of large language models (LLMs) in generating artificial data. LLMs are increasingly employed to create a variety of outputs, including annotations, preferences, instruction prompts, simulated dialogues, and free text. As these forms of LLM-generated data often intersect in their application, they exert mutual influence on each other and raise significant concerns about the quality and diversity of the artificial data incorporated into training cycles, leading to an artificial data ecosystem. To the best of our knowledge, this is the first study to aggregate various types of LLM-generated text data, from more tightly constrained data like "task labels" to more lightly constrained "free-form text". We then stress test the quality and implications of LLM-generated artificial data, comparing it with human data across various existing benchmarks. Despite artificial data's capability to match human performance, this paper reveals significant hidden d
    
[^18]: Taiyi-Diffusion-XL: 借助大型视觉语言模型支持推进双语文本到图像生成

    Taiyi-Diffusion-XL: Advancing Bilingual Text-to-Image Generation with Large Vision-Language Model Support. (arXiv:2401.14688v1 [cs.CL])

    [http://arxiv.org/abs/2401.14688](http://arxiv.org/abs/2401.14688)

    Taiyi-Diffusion-XL是一个中英双语文本到图像生成模型，通过对CLIP和Stable-Diffusion-XL的能力进行扩展，并通过双语连续预训练来实现。模型通过将常用的汉字整合到CLIP的分词器和嵌入层中，以及使用大型视觉语言模型丰富文本提示，提供了更好的图像标题和高质量的视觉效果。实验证明，该模型在双语图像-文本检索中表现出色。

    

    最近在文本到图像模型中的进展显著提升了图像生成能力，然而在双语或中文语言支持方面仍存在明显的开源模型缺口。为了解决这个需求，我们提出了Taiyi-Diffusion-XL，这是一个新的中英双语文本到图像模型，通过对CLIP和Stable-Diffusion-XL能力的扩展，并通过双语连续预训练的过程来开发。这种方法包括通过将最常用的汉字整合到CLIP的分词器和嵌入层中来扩展词汇量的高效方法，同时还加入了绝对位置编码扩展。此外，我们通过大型视觉语言模型来丰富文本提示，从而提供更好的图像标题和更高的视觉质量。这些增强措施随后应用于下游的文本到图像模型。我们的实证结果表明，开发的CLIP模型在双语图像-文本检索方面表现出色。此外，双语预训练过程中的整合使该模型在中英文场景下具有均衡的表现。

    Recent advancements in text-to-image models have significantly enhanced image generation capabilities, yet a notable gap of open-source models persists in bilingual or Chinese language support. To address this need, we present Taiyi-Diffusion-XL, a new Chinese and English bilingual text-to-image model which is developed by extending the capabilities of CLIP and Stable-Diffusion-XL through a process of bilingual continuous pre-training. This approach includes the efficient expansion of vocabulary by integrating the most frequently used Chinese characters into CLIP's tokenizer and embedding layers, coupled with an absolute position encoding expansion. Additionally, we enrich text prompts by large vision-language model, leading to better images captions and possess higher visual quality. These enhancements are subsequently applied to downstream text-to-image models. Our empirical results indicate that the developed CLIP model excels in bilingual image-text retrieval.Furthermore, the bilin
    
[^19]: MasonTigers@LT-EDI-2024：一种用于检测社交媒体评论中的恐同和恶意性别认知的集成方法

    MasonTigers@LT-EDI-2024: An Ensemble Approach towards Detecting Homophobia and Transphobia in Social Media Comments. (arXiv:2401.14681v1 [cs.CL])

    [http://arxiv.org/abs/2401.14681](http://arxiv.org/abs/2401.14681)

    MasonTigers@LT-EDI-2024团队提出了一种集成方法，用于在十种语言中检测社交媒体评论中的恐同和恶意性别认知，取得了较好的性能表现。

    

    本文描述了我们在LT-EDI 2024研讨会的任务2中针对十种语言检测恐同和/或恶意性别认知的方法和结果。我们的方法包括单语言transformer和集成方法，利用每种方法的优势来提高模型的性能。集成模型表现良好，我们的团队MasonTigers在十种语言中的八种中都排名前五，以宏观F1分数衡量。我们的工作强调了集成方法在多语言情境下的有效性，解决了语言特定任务的复杂性。

    In this paper, we describe our approaches and results for Task 2 of the LT-EDI 2024 Workshop, aimed at detecting homophobia and/or transphobia across ten languages. Our methodologies include monolingual transformers and ensemble methods, capitalizing on the strengths of each to enhance the performance of the models. The ensemble models worked well, placing our team, MasonTigers, in the top five for eight of the ten languages, as measured by the macro F1 score. Our work emphasizes the efficacy of ensemble methods in multilingual scenarios, addressing the complexities of language-specific tasks.
    
[^20]: MaLLaM -- 马来西亚大型语言模型

    MaLLaM -- Malaysia Large Language Model. (arXiv:2401.14680v1 [cs.CL])

    [http://arxiv.org/abs/2401.14680](http://arxiv.org/abs/2401.14680)

    MaLLaM是马来西亚大型语言模型，通过使用大型数据集和预训练的BPE分词器，在马来语的自然语言理解和生成任务中取得了竞争力，并展示了在捕捉和理解马来西亚语言细微差异方面的有效性，为提升自然语言理解和生成打下了基础。

    

    针对马来西亚语境下从头预训练的大型语言模型的不足，我们使用349GB的大型数据集（相当于90亿个标记），使用我们预训练的字节对编码（BPE）分词器，在1.1亿、30亿和50亿参数上训练了模型。MaLLaM在马来语的自然语言理解和生成任务中做出了贡献。尽管只是使用了90亿个标记的较小数据集进行了训练，我们经过指令调整的MaLLaM模型表现出了竞争力。与ChatGPT3.5和Malaysian Mistral相比，MaLLaM的指令调整模型展示了显著的熟练度，突出了我们方法在捕捉和理解马来西亚语言细微差异方面的有效性。MaLLaM模型在该领域中起到了重要作用，提供了与马来西亚语境紧密联系的全面语言表示。这项努力旨在为提升自然语言理解和生成铺平道路。

    Addressing the gap in Large Language Model pretrained from scratch with Malaysian context, We trained models with 1.1 billion, 3 billion, and 5 billion parameters on a substantial 349GB dataset, equivalent to 90 billion tokens based on our pretrained Byte Pair Encoding (BPE) tokenizer for a single epoch. MaLLaM contributes to enhanced natural language understanding and generation tasks in the Malay language. Although trained on a smaller dataset of 90 billion tokens, our instruction-tuned MaLLaM models perform competitively. When compared to ChatGPT3.5 and Malaysian Mistral, MaLLaM's instruction-tuned models demonstrate notable proficiency, underscoring the effectiveness of our approach in capturing and understanding the nuances of the Malaysian language. MaLLaM models mark a significant contribution to the field, providing comprehensive language representations grounded in Malaysian context. This endeavor aims to pave the way for enhanced natural language understanding and generation 
    
[^21]: UNIT-DSR: 使用语音单元标准化的发音障碍语音重建系统

    UNIT-DSR: Dysarthric Speech Reconstruction System Using Speech Unit Normalization. (arXiv:2401.14664v1 [cs.SD])

    [http://arxiv.org/abs/2401.14664](http://arxiv.org/abs/2401.14664)

    UNIT-DSR系统是一种使用语音单元标准化的发音障碍语音重建系统，通过利用自监督学习和语音单元约束发音障碍内容恢复，提升了训练效率和重建质量。

    

    发音障碍语音重建（DSR）系统旨在将发音障碍的语音自动转换为听起来正常的语音。该技术能够改善受神经运动障碍影响的演讲者与人们的交流，并提升他们的社交融入度。基于NED（神经编码器-解码器）的系统相较于基于GAN（生成对抗网络）的方法在重建语音的可懂度方面有了显著提高，但该方法仍受到级联流程和内容编码器的辅助任务导致的训练效率不高的限制，而这可能会影响重建的质量。受到自监督语音表示学习和离散语音单元的启发，我们提出了Unit-DSR系统，利用HuBERT的强大领域自适应能力来提升训练效率，并利用语音单元在离散语言空间中约束发音障碍内容的恢复。与NED方法相比，Unit-DSR系统具有更好的性能。

    Dysarthric speech reconstruction (DSR) systems aim to automatically convert dysarthric speech into normal-sounding speech. The technology eases communication with speakers affected by the neuromotor disorder and enhances their social inclusion. NED-based (Neural Encoder-Decoder) systems have significantly improved the intelligibility of the reconstructed speech as compared with GAN-based (Generative Adversarial Network) approaches, but the approach is still limited by training inefficiency caused by the cascaded pipeline and auxiliary tasks of the content encoder, which may in turn affect the quality of reconstruction. Inspired by self-supervised speech representation learning and discrete speech units, we propose a Unit-DSR system, which harnesses the powerful domain-adaptation capacity of HuBERT for training efficiency improvement and utilizes speech units to constrain the dysarthric content restoration in a discrete linguistic space. Compared with NED approaches, the Unit-DSR system
    
[^22]: 科学大型语言模型：生物和化学领域的综述

    Scientific Large Language Models: A Survey on Biological & Chemical Domains. (arXiv:2401.14656v1 [cs.CL])

    [http://arxiv.org/abs/2401.14656](http://arxiv.org/abs/2401.14656)

    这篇论文介绍了科学大型语言模型在生物和化学领域的综述，分析了最新进展，并提出了科学LLMs的重要性。

    

    大型语言模型（LLMs）已成为提升自然语言理解的一种变革性力量，对于人工智能的发展迈出了重要的一步。LLMs的应用已超越传统的语言界限，包括在各种科学学科内开发的专门语言系统。这种不断增长的兴趣导致了科学LLMs的出现，这是一种专门为促进科学发现而设计的新型子类。作为人工智能科学社区中的新兴领域，科学LLMs值得全面探索。然而，目前缺乏系统且最新的综述介绍它们。在本文中，我们将系统地勾画“科学语言”的概念，并全面审查科学LLMs的最新进展。考虑到科学学科的广泛领域，我们的分析采用了一种聚焦的视角，专注于生物和化学领域。

    Large Language Models (LLMs) have emerged as a transformative power in enhancing natural language comprehension, representing a significant stride toward artificial general intelligence. The application of LLMs extends beyond conventional linguistic boundaries, encompassing specialized linguistic systems developed within various scientific disciplines. This growing interest has led to the advent of scientific LLMs, a novel subclass specifically engineered for facilitating scientific discovery. As a burgeoning area in the community of AI for Science, scientific LLMs warrant comprehensive exploration. However, a systematic and up-to-date survey introducing them is currently lacking. In this paper, we endeavor to methodically delineate the concept of "scientific language", whilst providing a thorough review of the latest advancements in scientific LLMs. Given the expansive realm of scientific disciplines, our analysis adopts a focused lens, concentrating on the biological and chemical dom
    
[^23]: 面向保险争议的韩国法律判决预测数据集

    A Korean Legal Judgment Prediction Dataset for Insurance Disputes. (arXiv:2401.14654v1 [cs.CL])

    [http://arxiv.org/abs/2401.14654](http://arxiv.org/abs/2401.14654)

    这篇论文介绍了一种面向保险争议的韩国法律判决预测数据集，研究发现在数据有限的情况下，使用句子转换器微调方法可以实现与大型数据集相似的性能。

    

    本文介绍了一种面向保险争议的韩国法律判决预测（LJP）数据集。成功预测保险争议的LJP模型可以使保险公司及其客户受益。它可以通过预测如果进行争议调解过程，结果将如何出现来节省双方的时间和金钱。正如低资源语言经常面临的情况一样，该特定任务的可用数据量有限。为了缓解这个问题，我们研究了如何在数据有限的情况下实现良好的性能。在我们的实验中，我们证明了句子转换器微调（SetFit）（Tunstall等，2022）是在数据有限的情况下的标准微调的良好替代方法。使用SetFit方法在我们的数据上进行微调的模型与韩国LJP基准模型（Hwang等，2022）在性能上显示出相似的表现，尽管数据规模要小得多。

    This paper introduces a Korean legal judgment prediction (LJP) dataset for insurance disputes. Successful LJP models on insurance disputes can benefit insurance companies and their customers. It can save both sides' time and money by allowing them to predict how the result would come out if they proceed to the dispute mediation process. As is often the case with low-resource languages, there is a limitation on the amount of data available for this specific task. To mitigate this issue, we investigate how one can achieve a good performance despite the limitation in data. In our experiment, we demonstrate that Sentence Transformer Fine-tuning (SetFit, Tunstall et al., 2022) is a good alternative to standard fine-tuning when training data are limited. The models fine-tuned with the SetFit approach on our data show similar performance to the Korean LJP benchmark models (Hwang et al., 2022) despite the much smaller data size.
    
[^24]: 在复杂问题回答归因中使用知识图谱对大型语言模型进行基准测试

    Benchmarking Large Language Models in Complex Question Answering Attribution using Knowledge Graphs. (arXiv:2401.14640v1 [cs.CL])

    [http://arxiv.org/abs/2401.14640](http://arxiv.org/abs/2401.14640)

    该研究介绍了一种用于评估问题回答归因的新方法，并通过对大型语言模型进行基准测试，发现现有的评估器在细粒度的归因设置下表现不佳，同时在复杂的引文-陈述推理中也存在弱点。

    

    问题回答的归因是为生成的陈述提供引用, 并且引起了广泛的研究关注。目前的自动评估归因的方法往往基于大型语言模型(LLM), 但仍然不足, 特别是在识别归因之间细微差别和引用与陈述之间的复杂关系方面。为了比较这些归因评估方法并开发新的方法, 我们引入了一组细粒度的类别(即支持, 不足, 矛盾和无关), 用于衡量归因, 并通过利用知识图谱(KG)为问题-回答对自动生成不同类别的归因, 开发了一个复杂的归因问题回答(CAQA)基准。我们的分析显示, 现有的评估器在细粒度的归因设置下表现不佳, 在复杂的引文-陈述推理中存在弱点。

    The attribution of question answering is to provide citations for supporting generated statements, and has attracted wide research attention. The current methods for automatically evaluating the attribution, which are often based on Large Language Models (LLMs), are still inadequate, particularly in recognizing subtle differences between attributions, and complex relationships between citations and statements. To compare these attribution evaluation methods and develop new ones, we introduce a set of fine-grained categories (i.e., supportive, insufficient, contradictory and irrelevant) for measuring the attribution, and develop a Complex Attributed Question Answering (CAQA) benchmark by leveraging knowledge graphs (KGs) for automatically generating attributions of different categories to question-answer pairs. Our analysis reveals that existing evaluators perform poorly under fine-grained attribution settings and exhibit weaknesses in complex citation-statement reasoning. Our CAQA benc
    
[^25]: T-Rex: 文本辅助的反向合成预测

    T-Rex: Text-assisted Retrosynthesis Prediction. (arXiv:2401.14637v1 [cs.CL])

    [http://arxiv.org/abs/2401.14637](http://arxiv.org/abs/2401.14637)

    T-Rex是一种利用文本信息辅助反向合成预测的方法，在两个数据集上表现出色，优于基于图结构的方法。

    

    作为计算化学中的基础任务，反向合成预测旨在识别一组反应物来合成目标分子。现有的无模板方法只考虑目标分子的图结构，往往不能很好地推广到罕见的反应类型和大分子。在这里，我们提出了T-Rex，一种使用预训练文本语言模型（如ChatGPT）来辅助生成反应物的反向合成预测方法。T-Rex首先利用ChatGPT为目标分子生成描述，并基于描述和分子图对候选反应中心进行排名。然后，通过查询每个反应物的描述，并检查哪组反应物最能合成目标分子，重新对这些候选进行排名。我们观察到T-Rex在两个数据集上明显优于基于图的最先进方法，这表明考虑文本信息的有效性。

    As a fundamental task in computational chemistry, retrosynthesis prediction aims to identify a set of reactants to synthesize a target molecule. Existing template-free approaches only consider the graph structures of the target molecule, which often cannot generalize well to rare reaction types and large molecules. Here, we propose T-Rex, a text-assisted retrosynthesis prediction approach that exploits pre-trained text language models, such as ChatGPT, to assist the generation of reactants. T-Rex first exploits ChatGPT to generate a description for the target molecule and rank candidate reaction centers based both the description and the molecular graph. It then re-ranks these candidates by querying the descriptions for each reactants and examines which group of reactants can best synthesize the target molecule. We observed that T-Rex substantially outperformed graph-based state-of-the-art approaches on two datasets, indicating the effectiveness of considering text information. We furt
    
[^26]: 《对中文拼写检查模型的领域适应能力进行实证研究》

    An Empirical Investigation of Domain Adaptation Ability for Chinese Spelling Check Models. (arXiv:2401.14630v1 [cs.CL])

    [http://arxiv.org/abs/2401.14630](http://arxiv.org/abs/2401.14630)

    该论文通过构建领域特定术语的新数据集，对各种典型的中文拼写检查（CSC）模型的领域适应能力进行了全面评估，结果表明这些模型在新领域中的性能显著下降。

    

    中文拼写检查（CSC）是自然语言处理（NLP）领域中一项有意义的任务，旨在检测中文文本中的拼写错误，然后对这些错误进行纠正。然而，CSC模型基于预训练的语言模型，这些模型在一般语料库上进行训练。因此，当面临涉及特定领域术语的下游任务时，它们的性能可能会下降。在本文中，我们通过构建三个包含财经、医疗和法律领域丰富领域特定术语的新数据集，对各种典型的CSC模型的领域适应能力进行了全面评估。然后，我们在相应领域特定的测试数据集中进行了实证研究，以确定几种典型CSC模型的跨域适应能力。我们还测试了流行的大型语言模型ChatGPT的性能。实验证明，在新领域中，CSC模型的性能显著下降。

    Chinese Spelling Check (CSC) is a meaningful task in the area of Natural Language Processing (NLP) which aims at detecting spelling errors in Chinese texts and then correcting these errors. However, CSC models are based on pretrained language models, which are trained on a general corpus. Consequently, their performance may drop when confronted with downstream tasks involving domain-specific terms. In this paper, we conduct a thorough evaluation about the domain adaption ability of various typical CSC models by building three new datasets encompassing rich domain-specific terms from the financial, medical, and legal domains. Then we conduct empirical investigations in the corresponding domain-specific test datasets to ascertain the cross-domain adaptation ability of several typical CSC models. We also test the performance of the popular large language model ChatGPT. As shown in our experiments, the performances of the CSC models drop significantly in the new domains.
    
[^27]: 迈向实用的自动语音识别和后处理：关于可解释错误基准指南的呼吁

    Toward Practical Automatic Speech Recognition and Post-Processing: a Call for Explainable Error Benchmark Guideline. (arXiv:2401.14625v1 [cs.CL])

    [http://arxiv.org/abs/2401.14625](http://arxiv.org/abs/2401.14625)

    传统ASR评估方法无法全面了解特定脆弱性，同时后处理阶段也缺乏详细信息，这对用户友好性产生负面影响。为了解决这个问题，需要综合考虑语音层面和文本层面，并提出了错误可解释性基准指南。

    

    自动语音识别（ASR）的结果作为下游任务的输入，极大地影响着最终用户的满意度。因此，诊断和增强ASR模型中存在的弱点具有重要意义。然而，传统的ASR系统评估方法生成一个单一的、综合的定量指标，无法提供对特定弱点的全面洞察。这种缺乏细节也延伸到后处理阶段，进一步混淆了潜在的弱点。尽管ASR模型有能力准确识别话语，但读者感知度较差可能对用户满意度产生负面影响，从而在识别准确度和用户友好性之间产生一种权衡。为了有效解决这个问题，必须同时考虑到语音层面（对于识别准确性至关重要）和文本层面（对于用户友好性至关重要）。因此，我们提议开发一个错误可解释性基准指南。

    Automatic speech recognition (ASR) outcomes serve as input for downstream tasks, substantially impacting the satisfaction level of end-users. Hence, the diagnosis and enhancement of the vulnerabilities present in the ASR model bear significant importance. However, traditional evaluation methodologies of ASR systems generate a singular, composite quantitative metric, which fails to provide comprehensive insight into specific vulnerabilities. This lack of detail extends to the post-processing stage, resulting in further obfuscation of potential weaknesses. Despite an ASR model's ability to recognize utterances accurately, subpar readability can negatively affect user satisfaction, giving rise to a trade-off between recognition accuracy and user-friendliness. To effectively address this, it is imperative to consider both the speech-level, crucial for recognition accuracy, and the text-level, critical for user-friendliness. Consequently, we propose the development of an Error Explainable B
    
[^28]: CC查询：从公开文献中发现大规模领域特定知识

    Query of CC: Unearthing Large Scale Domain-Specific Knowledge from Public Corpora. (arXiv:2401.14624v1 [cs.CL])

    [http://arxiv.org/abs/2401.14624](http://arxiv.org/abs/2401.14624)

    本论文提出了一种通过大型语言模型来收集特定领域知识的高效方法，通过该方法构建了一个高质量的名为“Knowledge Pile”的数据集，实验证明其显著改善了特定领域的数据稀缺问题。

    

    大型语言模型在各种任务中展示了显著的潜力，然而特定领域的开源模型和数据仍然非常稀缺。之前的研究主要集中在手动指定资源和收集特定领域的高质量数据，这消耗了大量时间和精力。为了解决这个问题，我们提出了一种基于大型语言模型的高效数据收集方法“CC查询”。该方法通过大型语言模型引导种子信息，并从公开文献中检索相关数据。它不仅收集了特定领域的知识相关数据，还揭示了潜在的推理过程数据。通过应用这种方法，我们构建了一个名为“Knowledge Pile”的高质量数据集，涵盖了包括STEM科学和人文科学在内的四个主要领域。实验结果表明，“Knowledge Pile”显著改善了

    Large language models have demonstrated remarkable potential in various tasks, however, there remains a significant scarcity of open-source models and data for specific domains. Previous works have primarily focused on manually specifying resources and collecting high-quality data on specific domains, which significantly consume time and effort. To address this limitation, we propose an efficient data collection method~\textit{Query of CC} based on large language models. This method bootstraps seed information through a large language model and retrieves related data from public corpora. It not only collects knowledge-related data for specific domains but unearths the data with potential reasoning procedures. Through the application of this method, we have curated a high-quality dataset called~\textsc{Knowledge Pile}, encompassing four major domains, including stem and humanities sciences, among others. Experimental results demonstrate that~\textsc{Knowledge Pile} significantly improve
    
[^29]: 替代性言论：补充对抗叙事的方法以改善讨论（arXiv:2401.14616v1 [cs.CL]）

    Alternative Speech: Complementary Method to Counter-Narrative for Better Discourse. (arXiv:2401.14616v1 [cs.CL])

    [http://arxiv.org/abs/2401.14616](http://arxiv.org/abs/2401.14616)

    该论文引入了“替代性言论”作为直接对抗仇恨言论的新方法，并提供了构建所需数据集的指导。替代性言论通过提供实际可行的替代方案，考虑环境因素并促使演讲者改变，为解决社会问题提供有用工具。将替代性言论与对抗叙事结合使用可以更有效地对抗仇恨言论，补充了对抗叙事的能力。

    

    我们引入了“替代性言论”的概念，作为直接对抗仇恨言论和补充叙事限制的新方式。替代性言论通过在真实场景中提供言论级别的修正，考虑周围环境并促使演讲者改变，为仇恨言论提供实际可行的替代方案。此外，替代性言论可以与对抗叙事一起对抗仇恨言论，为解决种族歧视和性别不平等等社会问题提供有用工具。我们提出了这个新概念，并提供了构建所需数据集的详细指导。通过讨论，我们证明将替代性言论与对抗叙事相结合可以是对抗仇恨言论更有效的策略，补充了对抗叙事的具体性和引导能力。本文提出了处理仇恨言论的另一种视角，提供了可行的补救措施来补充当前的限制。

    We introduce the concept of "Alternative Speech" as a new way to directly combat hate speech and complement the limitations of counter-narrative. An alternative speech provides practical alternatives to hate speech in real-world scenarios by offering speech-level corrections to speakers while considering the surrounding context and promoting speakers to reform. Further, an alternative speech can combat hate speech alongside counter-narratives, offering a useful tool to address social issues such as racial discrimination and gender inequality. We propose the new concept and provide detailed guidelines for constructing the necessary dataset. Through discussion, we demonstrate that combining alternative speech and counter-narrative can be a more effective strategy for combating hate speech by complementing specificity and guiding capacity of counter-narrative. This paper presents another perspective for dealing with hate speech, offering viable remedies to complement the constraints of cu
    
[^30]: 通过多智能体对话提高诊断准确度：利用大型语言模型减少认知偏差

    Enhancing Diagnostic Accuracy through Multi-Agent Conversations: Using Large Language Models to Mitigate Cognitive Bias. (arXiv:2401.14589v1 [cs.CL])

    [http://arxiv.org/abs/2401.14589](http://arxiv.org/abs/2401.14589)

    本研究旨在通过利用大型语言模型和多智能体对话的方式来减轻临床决策中的认知偏差，并评估其对提高诊断准确性的有效性。

    

    背景：临床决策中的认知偏差显著导致诊断错误和次优患者结果。解决这些偏差问题在医疗领域面临巨大挑战。本研究通过利用大型语言模型（LLMs）在多智能体框架中减轻这些偏差的作用。我们通过多智能体对话模拟临床决策过程，并评估其对改善诊断准确性的有效性。方法：从文献中找到了总共16个已发表和未发表的病例报告，其中认知偏差导致误诊。在多智能体系统中，我们利用 GPT-4 Turbo 促进四个模拟智能体之间的交互，以复制临床团队动态。每个智能体都有独特的角色：1) 在考虑讨论后进行初步和最终诊断。2) 充当魔鬼的代言人，以纠正确认偏差和锚定偏差。3) 充当导师和促进者。

    Background: Cognitive biases in clinical decision-making significantly contribute to errors in diagnosis and suboptimal patient outcomes. Addressing these biases presents a formidable challenge in the medical field. This study explores the role of large language models (LLMs) in mitigating these biases through the utilization of a multi-agent framework. We simulate the clinical decision-making processes through multi-agent conversation and evaluate its efficacy in improving diagnostic accuracy. Methods: A total of 16 published and unpublished case reports where cognitive biases have resulted in misdiagnoses were identified from the literature. In the multi-agent system, we leveraged GPT-4 Turbo to facilitate interactions among four simulated agents to replicate clinical team dynamics. Each agent has a distinct role: 1) To make the initial and final diagnosis after considering the discussions, 2) The devil's advocate and correct confirmation and anchoring bias, 3) The tutor and facilita
    
[^31]: 结合语言识别和傅里叶分析，在历史文献中检测结构化语言交替的方法

    Detecting Structured Language Alternations in Historical Documents by Combining Language Identification with Fourier Analysis. (arXiv:2401.14569v1 [cs.CL])

    [http://arxiv.org/abs/2401.14569](http://arxiv.org/abs/2401.14569)

    本研究提出了一种结合语言识别和傅里叶分析的方法，用于检测历史文献中亚美尼亚土耳其语的结构化语言交替。

    

    本研究提出了一种通用的工作流程，用于识别非标准语言和书写组合（亚美尼亚土耳其语）的历史语言文献。我们引入了检测文献中结构化语言交替频率的任务。

    In this study, we present a generalizable workflow to identify documents in a historic language with a nonstandard language and script combination, Armeno-Turkish. We introduce the task of detecting distinct patterns of multilinguality based on the frequency of structured language alternations within a document.
    
[^32]: 自适应机器翻译的语言建模方法

    Language Modelling Approaches to Adaptive Machine Translation. (arXiv:2401.14559v1 [cs.CL])

    [http://arxiv.org/abs/2401.14559](http://arxiv.org/abs/2401.14559)

    自适应机器翻译中的语言建模方法，通过利用大型语言模型(LLMs)来在特定上下文中学习、改进翻译质量，解决了在域适应中因缺乏域内数据而导致翻译不一致的问题。

    

    一致性是高质量翻译的关键要求。在特定领域项目中，遵循预定义的术语和适应更正后的翻译尤为重要。机器翻译在域适应方面取得了显著进展。然而，在翻译环境中，由于缺乏专门的数据集和术语，或者可用的域内翻译不一致且不准确，导致域内数据稀缺现象普遍存在。在没有足够域内数据用于微调机器翻译模型的情况下，生成与相关上下文一致的翻译是具有挑战性的。虽然实时适应可以利用较少量的域内数据实时改进翻译质量，但由于受到上下文限制和效率约束，仍然具有挑战性。最近，大型语言模型（LLMs）展示了在上下文中学习的有趣能力，通过学习复制特定的输入输出来改进翻译效果。

    Consistency is a key requirement of high-quality translation. It is especially important to adhere to pre-approved terminology and adapt to corrected translations in domain-specific projects. Machine translation (MT) has achieved significant progress in the area of domain adaptation. However, in-domain data scarcity is common in translation settings, due to the lack of specialised datasets and terminology, or inconsistency and inaccuracy of available in-domain translations. In such scenarios where there is insufficient in-domain data to fine-tune MT models, producing translations that are consistent with the relevant context is challenging. While real-time adaptation can make use of smaller amounts of in-domain data to improve the translation on the fly, it remains challenging due to supported context limitations and efficiency constraints. Large language models (LLMs) have recently shown interesting capabilities of in-context learning, where they learn to replicate certain input-outpu
    
[^33]: 不一定总是向右看：研究基于解码器的大型语言模型在序列标注中的能力

    Do Not (Always) Look Right: Investigating the Capabilities of Decoder-Based Large Language Models for Sequence Labeling. (arXiv:2401.14556v1 [cs.CL])

    [http://arxiv.org/abs/2401.14556](http://arxiv.org/abs/2401.14556)

    本文研究了基于解码器的大型语言模型在序列标注方面的能力，并探索了提高它们性能的策略。

    

    基于掩码语言建模（MLM）目标的预训练语言模型在自然语言理解（NLU）任务中表现出色。虽然与相似规模的因果语言建模解码器相比，经过微调的MLM-based编码器始终表现优异，但最近将解码器模型扩展至数十亿参数的趋势使得大型语言模型（LLMs）能够与MLM-based编码器相抗衡。尽管规模扩大了它们在NLU任务中的能力，但LLMs在信息提取（IE）任务中，尤其是序列标注（SL）任务方面仍然落后于SOTA结果。然而，LLMs的SL性能是由其固有的限制决定的还是可以改进的，仍然不清楚。为了解决这个问题，我们探索了改进"开放式"LLMs（Llama2和Mistral）在IE任务中的SL性能的策略。我们研究了解码器块组内的双向信息流，应用了层次逐层移除或启用因果掩码（CM）进来LLM微调。这种方法产生了...

    Pre-trained language models based on masked language modeling (MLM) objective excel in natural language understanding (NLU) tasks. While fine-tuned MLM-based encoders consistently outperform causal language modeling decoders of comparable size, a recent trend of scaling decoder models to multiple billion parameters resulted in large language models (LLMs), making them competitive with MLM-based encoders. Although scale amplifies their prowess in NLU tasks, LLMs fall short of SOTA results in information extraction (IE) tasks, many framed as sequence labeling (SL). However, whether this is an intrinsic limitation of LLMs or whether their SL performance can be improved remains unclear. To address this, we explore strategies to enhance the SL performance of "open" LLMs (Llama2 and Mistral) on IE tasks. We investigate bidirectional information flow within groups of decoder blocks, applying layer-wise removal or enforcement of the causal mask (CM) during LLM fine-tuning. This approach yields
    
[^34]: 大型语言模型中的相对价值偏差

    Relative Value Biases in Large Language Models. (arXiv:2401.14530v1 [cs.CL])

    [http://arxiv.org/abs/2401.14530](http://arxiv.org/abs/2401.14530)

    该研究发现大型语言模型在做选择时表现出了与人类和动物相似的相对价值偏差，这对于理解人类选择中的背景依赖性机制具有重要意义。

    

    人类和动物在强化学习方面的研究表明，即使那些选项与较低的绝对奖励相关，他们更倾向于选择过去相对更好结果的选项。本研究测试了大型语言模型是否会表现出类似的偏差。我们让gpt-4-1106-preview(GPT-4 Turbo)和Llama-2-70B在最大化回报的目标下反复在选项对之间进行选择。每个提示中都包含了先前结果的完整记录。两个模型表现出了与人类和动物观察到的相对价值决策偏差类似的行为。更明确地进行结果之间的相对比较会放大这种偏差，而促使模型估计预期结果会使偏差消失。这些结果对于了解人类选择中贡献到背景依赖性的潜在机制具有重要意义。

    Studies of reinforcement learning in humans and animals have demonstrated a preference for options that yielded relatively better outcomes in the past, even when those options are associated with lower absolute reward. The present study tested whether large language models would exhibit a similar bias. We had gpt-4-1106-preview (GPT-4 Turbo) and Llama-2-70B make repeated choices between pairs of options with the goal of maximizing payoffs. A complete record of previous outcomes was included in each prompt. Both models exhibited relative value decision biases similar to those observed in humans and animals. Making relative comparisons among outcomes more explicit magnified the bias, whereas prompting the models to estimate expected outcomes caused the bias to disappear. These results have implications for the potential mechanisms that contribute to context-dependent choice in human agents.
    
[^35]: MEDs for PETs: 多语言委婉语消歧为潜在委婉术语

    MEDs for PETs: Multilingual Euphemism Disambiguation for Potentially Euphemistic Terms. (arXiv:2401.14526v1 [cs.CL])

    [http://arxiv.org/abs/2401.14526](http://arxiv.org/abs/2401.14526)

    本研究讨论了跨多语言的委婉语处理，并通过多语言转换器模型成功消歧潜在委婉术语。结果显示多语言模型在该任务上的表现优于单语言模型，从而证明多语言数据对于跨语言委婉语的计算特性具有额外的潜力。

    

    本研究调查了跨多语言的委婉语计算处理，委婉语是一种普遍的语言现象。我们使用一种多语言转换器模型（XLM-RoBERTa）来消除多语言和跨语言环境中的潜在委婉术语（PETs）的歧义。符合当前趋势，我们证明跨语言的零样本学习是可能的。我们还展示了在统计上存在显著优势的情况下，多语言模型在该任务上的表现比单语言模型更好，这表明多语言数据为模型学习关于跨语言委婉语计算性质提供了额外的机会。在后续分析中，我们着重考察了包括死亡和身体功能在内的通用委婉术语类别。我们测试了跨语言数据是否比同一领域的语言内数据更重要，以进一步了解跨语言转移的性质。

    This study investigates the computational processing of euphemisms, a universal linguistic phenomenon, across multiple languages. We train a multilingual transformer model (XLM-RoBERTa) to disambiguate potentially euphemistic terms (PETs) in multilingual and cross-lingual settings. In line with current trends, we demonstrate that zero-shot learning across languages takes place. We also show cases where multilingual models perform better on the task compared to monolingual models by a statistically significant margin, indicating that multilingual data presents additional opportunities for models to learn about cross-lingual, computational properties of euphemisms. In a follow-up analysis, we focus on universal euphemistic "categories" such as death and bodily functions among others. We test to see whether cross-lingual data of the same domain is more important than within-language data of other domains to further understand the nature of the cross-lingual transfer.
    
[^36]: 评估GPT-3.5在共享主题的欧洲宪法文本中的意识和摘要能力

    Evaluating GPT-3.5's Awareness and Summarization Abilities for European Constitutional Texts with Shared Topics. (arXiv:2401.14524v1 [cs.CL])

    [http://arxiv.org/abs/2401.14524](http://arxiv.org/abs/2401.14524)

    本研究通过利用GPT-3.5模型，在多国宪法文本中进行宝贵的摘要总结，特别关注于与公民权利和义务相关的欧洲国家宪法段落，结果显示其能够准确、连贯且忠实地捕捉到RD主题。

    

    宪法是支撑政府和社会结构的基础法律文件。因此，它们不仅是国家文化和社会独特性的反映，还有助于确定普遍重要的主题，如公民的权利和义务（RD）。在这项工作中，我们利用著名的GPT-3.5，利用生成式大型语言模型来理解超越国界的宪法段落。我们研究的一个重要贡献是抽象摘要在多源宪法文本集合上的新应用，重点关注与RD主题相关的欧洲国家宪法段落。我们的结果表明，GPT-3.5具有意义，能够产生涵盖欧洲国家RD主题的信息丰富、连贯和忠实的摘要。

    Constitutions are foundational legal documents that underpin the governmental and societal structures. As such, they are a reflection of a nation's cultural and social uniqueness, but also contribute to establish topics of universal importance, like citizens' rights and duties (RD). In this work, using the renowned GPT-3.5, we leverage generative large language models to understand constitutional passages that transcend national boundaries. A key contribution of our study is the introduction of a novel application of abstractive summarization on a multi-source collection of constitutional texts, with a focus on European countries' constitution passages related to RD topics. Our results show the meaningfulness of GPT-3.5 to produce informative, coherent and faithful summaries capturing RD topics across European countries.
    
[^37]: 共情与成为一个例外的权利：LLMs可以做什么，不能做什么

    Empathy and the Right to Be an Exception: What LLMs Can and Cannot Do. (arXiv:2401.14523v1 [cs.CY])

    [http://arxiv.org/abs/2401.14523](http://arxiv.org/abs/2401.14523)

    LLMs既有能力归因于信念、欲望、意图和情感，也能在准确性方面不断提高，但他们无法通过共情方法来尊重个体成为例外的权利。他们仅通过识别语言模式判断案件相似性，而无法考虑个体的内部心理状态。我们提出了共情的方法。

    

    大语言模型（LLMs）性能的进步导致一些研究者提出了人工智能（AI）中理论心智（ToM）的出现。LLMs能够归因于信念、欲望、意图和情感，并且它们在准确性方面会有所提高。与人类特有的共情方法不同，它们通过识别数据集中通常不包括的语言模式来学习归因心理状态。我们问LLMs的无法共情是否会妨碍它们尊重个体成为一个例外的权利，即是否会妨碍它们基于对个体的个性敏感性进行性格评估和行为预测。LLMs能否认真考虑个体的主张，即他们的情况是基于信念、欲望和意图等内部心理状态而不同，还是仅限于基于其与他人的相似之处来判断该案件？我们提出共情的方法

    Advances in the performance of large language models (LLMs) have led some researchers to propose the emergence of theory of mind (ToM) in artificial intelligence (AI). LLMs can attribute beliefs, desires, intentions, and emotions, and they will improve in their accuracy. Rather than employing the characteristically human method of empathy, they learn to attribute mental states by recognizing linguistic patterns in a dataset that typically do not include that individual. We ask whether LLMs' inability to empathize precludes them from honoring an individual's right to be an exception, that is, from making assessments of character and predictions of behavior that reflect appropriate sensitivity to a person's individuality. Can LLMs seriously consider an individual's claim that their case is different based on internal mental states like beliefs, desires, and intentions, or are they limited to judging that case based on its similarities to others? We propose that the method of empathy has 
    
[^38]: K-QA：一个真实世界的医疗问答基准

    K-QA: A Real-World Medical Q&A Benchmark. (arXiv:2401.14493v1 [cs.CL])

    [http://arxiv.org/abs/2401.14493](http://arxiv.org/abs/2401.14493)

    本研究构建了K-QA数据集，包含1212个真实世界医疗对话中的患者问题，并聘请内部医生回答和分解。研究还制定了两个基于NLI的评估指标，用于评估模型的召回率和精确度。研究结果对于提升大型语言模型在临床环境下的准确性具有重要意义。

    

    确保大型语言模型（LLMs）提供的回答准确性是至关重要的，特别是在临床环境中，错误的信息可能直接影响患者健康。为了解决这个挑战，我们构建了K-QA数据集，其中包含1212个由K Health（一家AI驱动的临床平台）上的真实对话中的患者问题。我们聘请一组内部医生来回答并手动分解K-QA的子集为自包含的陈述。此外，我们制定了两个基于NLI的评估指标，近似于召回率和精确度：（1）全面性，衡量生成回答中所含的基本临床信息的百分比，（2）虚构率，衡量LLM回答所矛盾的医生策划回复中的陈述数量。最后，我们使用K-QA和这些指标来评估几种最先进的模型，以及上下文学习和医学导向增强检索的影响。

    Ensuring the accuracy of responses provided by large language models (LLMs) is crucial, particularly in clinical settings where incorrect information may directly impact patient health. To address this challenge, we construct K-QA, a dataset containing 1,212 patient questions originating from real-world conversations held on K Health (an AI-driven clinical platform). We employ a panel of in-house physicians to answer and manually decompose a subset of K-QA into self-contained statements. Additionally, we formulate two NLI-based evaluation metrics approximating recall and precision: (1) comprehensiveness, measuring the percentage of essential clinical information in the generated answer and (2) hallucination rate, measuring the number of statements from the physician-curated response contradicted by the LLM answer. Finally, we use K-QA along with these metrics to evaluate several state-of-the-art models, as well as the effect of in-context learning and medically-oriented augmented retri
    
[^39]: LongHealth:一份具有长篇临床文档的问答基准

    LongHealth: A Question Answering Benchmark with Long Clinical Documents. (arXiv:2401.14490v1 [cs.CL])

    [http://arxiv.org/abs/2401.14490](http://arxiv.org/abs/2401.14490)

    LongHealth是一个具有长篇临床文档的问答基准，用于评估大型语言模型在处理真实世界中的长篇临床数据方面的能力。最高准确性观察在信息提取任务中，Mixtral-8x7B-Instruct-v0.1在从单个和多个病患文档中检索信息的任务中表现最好。

    

    背景：最近大型语言模型（LLMs）的进展在医疗保健领域有潜在的好处，尤其是在处理大量的病患记录方面。然而，现有的基准未能充分评估LLMs在处理现实世界中的长篇临床数据方面的能力。方法：我们提出了LongHealth基准，包括20个详细的虚构病例，涵盖各种疾病，每个案例包含5090至6754个字。该基准通过三个类别的400个多项选择题，挑战LLMs从大型临床文档中提取并解释信息。结果：我们评估了九种开源LLMs，其中最少有16,000个标记，并且还包括了OpenAI的专有和成本效益的GPT-3.5 Turbo进行比较。 Mixtral-8x7B-Instruct-v0.1在从单个和多个病患文档中检索信息的任务中观察到最高的准确性。然而，所有的LLMs在处理有关否定和排序的任务时表现不佳。

    Background: Recent advancements in large language models (LLMs) offer potential benefits in healthcare, particularly in processing extensive patient records. However, existing benchmarks do not fully assess LLMs' capability in handling real-world, lengthy clinical data.  Methods: We present the LongHealth benchmark, comprising 20 detailed fictional patient cases across various diseases, with each case containing 5,090 to 6,754 words. The benchmark challenges LLMs with 400 multiple-choice questions in three categories: information extraction, negation, and sorting, challenging LLMs to extract and interpret information from large clinical documents.  Results: We evaluated nine open-source LLMs with a minimum of 16,000 tokens and also included OpenAI's proprietary and cost-efficient GPT-3.5 Turbo for comparison. The highest accuracy was observed for Mixtral-8x7B-Instruct-v0.1, particularly in tasks focused on information retrieval from single and multiple patient documents. However, all m
    
[^40]: Wordflow: 大型语言模型的社交提示工程

    Wordflow: Social Prompt Engineering for Large Language Models. (arXiv:2401.14447v1 [cs.HC])

    [http://arxiv.org/abs/2401.14447](http://arxiv.org/abs/2401.14447)

    本文提出了一种名为Wordflow的工具，通过社交提示工程的方式让非专家用户更好地使用大型语言模型（LLMs），并可以轻松创建、运行、共享和发现LLM提示。通过利用现代网络技术，Wordflow允许用户在浏览器中本地和私下运行LLM。

    

    大型语言模型（LLMs）需要精心设计的提示才能有效使用。对于非专家来说，这是一个具有挑战性的过程，因为他们对人工智能技术不那么熟悉。虽然研究人员提出了一些技术和工具来帮助LLM用户设计提示，但这些作品主要针对的是AI应用开发者而不是非专家。为了填补这一研究空白，我们提出了社交提示工程，这是一种利用社交计算技术促进协作提示设计的新范式。为了研究社交提示工程，我们介绍了Wordflow，一个开源的社交文本编辑器，使普通用户可以轻松创建、运行、共享和发现LLM提示。此外，通过利用现代网络技术，Wordflow允许用户在其浏览器中本地和私下运行LLM。两个使用场景突出了社交提示工程和我们的工具如何增强普通人与LLM的交互。

    Large language models (LLMs) require well-crafted prompts for effective use. Prompt engineering, the process of designing prompts, is challenging, particularly for non-experts who are less familiar with AI technologies. While researchers have proposed techniques and tools to assist LLM users in prompt design, these works primarily target AI application developers rather than non-experts. To address this research gap, we propose social prompt engineering, a novel paradigm that leverages social computing techniques to facilitate collaborative prompt design. To investigate social prompt engineering, we introduce Wordflow, an open-source and social text editor that enables everyday users to easily create, run, share, and discover LLM prompts. Additionally, by leveraging modern web technologies, Wordflow allows users to run LLMs locally and privately in their browsers. Two usage scenarios highlight how social prompt engineering and our tool can enhance laypeople's interaction with LLMs. Wor
    
[^41]: 语义敏感性和不一致的预测：衡量NLI模型的脆弱性

    Semantic Sensitivities and Inconsistent Predictions: Measuring the Fragility of NLI Models. (arXiv:2401.14440v1 [cs.CL])

    [http://arxiv.org/abs/2401.14440](http://arxiv.org/abs/2401.14440)

    这份论文研究发现，最先进的NLI模型对微小的语义保持表面形式变化非常敏感，导致推断结果不一致。其行为与对组合语义的有效理解不同，这对当前NLI模型的可靠性提出了挑战。

    

    最近对基于transformer的自然语言理解（NLU）模型的新能力进行的研究表明，它们具备对词汇和组合语义的理解。然而，我们提供了证据表明这些说法应该持保留态度：我们发现目前最先进的自然语言推理（NLI）模型对微小的保留语义的表面形式变化敏感，这导致推断过程中出现大量不一致的模型决策。值得注意的是，这种行为与对组合语义的有效和深入理解不同，而在标准基准测试中评估模型准确度或探究句法、单调性和逻辑鲁棒性推理时均不会出现。我们提出了一个新颖的框架来衡量语义敏感性的程度。为此，我们使用含有微小保留语义的表面形式输入噪声的对抗生成样例来评估NLI模型。

    Recent studies of the emergent capabilities of transformer-based Natural Language Understanding (NLU) models have indicated that they have an understanding of lexical and compositional semantics. We provide evidence that suggests these claims should be taken with a grain of salt: we find that state-of-the-art Natural Language Inference (NLI) models are sensitive towards minor semantics preserving surface-form variations, which lead to sizable inconsistent model decisions during inference. Notably, this behaviour differs from valid and in-depth comprehension of compositional semantics, however does neither emerge when evaluating model accuracy on standard benchmarks nor when probing for syntactic, monotonic, and logically robust reasoning. We propose a novel framework to measure the extent of semantic sensitivity. To this end, we evaluate NLI models on adversarially generated examples containing minor semantics-preserving surface-form input noise. This is achieved using conditional text
    
[^42]: DeepSeek-Coder: 在大型语言模型与编程相遇的时候--代码智能的崛起

    DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence. (arXiv:2401.14196v1 [cs.SE])

    [http://arxiv.org/abs/2401.14196](http://arxiv.org/abs/2401.14196)

    DeepSeek-Coder是一系列开源代码模型，通过在高质量项目级代码语料库上进行预训练和采用填空任务和16K窗口来增强代码生成和填充，不仅在多个基准测试中取得了与开源代码模型同样的最新表现，而且超过了现有的闭源模型。

    

    大型语言模型的快速发展为软件开发中的代码智能带来了革命。然而，闭源模型的主导地位限制了广泛的研究和开发。为了解决这个问题，我们介绍了DeepSeek-Coder系列，这是一系列开源代码模型，大小从1.3B到33B，从头开始在2万亿个标记上进行训练。这些模型在高质量项目级代码语料库上进行了预训练，并采用填空任务和16K窗口来增强代码生成和填充。我们广泛的评估表明，DeepSeek-Coder不仅在多个基准测试中取得了与开源代码模型同样的最新表现，而且超过了现有的Codex和GPT-3.5等闭源模型。此外，DeepSeek-Coder模型采用了宽松的许可证，既允许研究，也允许无限制的商业使用。

    The rapid development of large language models has revolutionized code intelligence in software development. However, the predominance of closed-source models has restricted extensive research and development. To address this, we introduce the DeepSeek-Coder series, a range of open-source code models with sizes from 1.3B to 33B, trained from scratch on 2 trillion tokens. These models are pre-trained on a high-quality project-level code corpus and employ a fill-in-the-blank task with a 16K window to enhance code generation and infilling. Our extensive evaluations demonstrate that DeepSeek-Coder not only achieves state-of-the-art performance among open-source code models across multiple benchmarks but also surpasses existing closed-source models like Codex and GPT-3.5. Furthermore, DeepSeek-Coder models are under a permissive license that allows for both research and unrestricted commercial use.
    
[^43]: CMMU: 一个用于中文多模态多类型问题理解与推理的基准测试

    CMMU: A Benchmark for Chinese Multi-modal Multi-type Question Understanding and Reasoning. (arXiv:2401.14011v1 [cs.CL])

    [http://arxiv.org/abs/2401.14011](http://arxiv.org/abs/2401.14011)

    CMMU是一个用于中文多模态多类型问题理解和推理的基准测试，涵盖了从小学到高中的知识，提供了多项选择题、多项回答题和填空题三种类型的问题，对于评估多模态大型语言模型的智能水平具有重要意义。

    

    多模态大型语言模型（MLLMs）已经取得了显著的进展，并展现出强大的知识理解和推理能力。然而，评估MLLM的智能水平所需的领域特定知识掌握仍然是一个挑战。当前用于领域特定知识的多模态基准测试主要集中在英语多项选择题上，并且在评估的全面性方面存在局限性。为此，我们引入了CMMU，一个用于中文多模态多类型问题理解和推理的新型基准测试。CMMU包含7个学科的3603个问题，涵盖了从小学到高中的知识。这些问题可以分为多项选择题、多项回答题和填空题三类，对MLLMs提出更大的挑战。此外，我们提出了一种严格的评估策略，称为ShiftCheck，用于评估多项选择题。

    Multi-modal large language models(MLLMs) have achieved remarkable progress and demonstrated powerful knowledge comprehension and reasoning abilities. However, the mastery of domain-specific knowledge, which is essential for evaluating the intelligence of MLLMs, continues to be a challenge. Current multi-modal benchmarks for domain-specific knowledge concentrate on multiple-choice questions and are predominantly available in English, which imposes limitations on the comprehensiveness of the evaluation. To this end, we introduce CMMU, a novel benchmark for multi-modal and multi-type question understanding and reasoning in Chinese. CMMU consists of 3,603 questions in 7 subjects, covering knowledge from primary to high school. The questions can be categorized into 3 types: multiple-choice, multiple-response, and fill-in-the-blank, bringing greater challenges to MLLMs. In addition, we propose a rigorous evaluation strategy called ShiftCheck for assessing multiple-choice questions. The strat
    
[^44]: 不公平的服务条款：使用定制的BERT的自动化方法

    Unfair TOS: An Automated Approach using Customized BERT. (arXiv:2401.11207v1 [cs.CL])

    [http://arxiv.org/abs/2401.11207](http://arxiv.org/abs/2401.11207)

    本研究利用定制的BERT与SVC的集成，针对ToS文档中的不公平条款进行了SOTA级别的检测，取得了出色的结果。

    

    服务条款(Terms of Service，ToS)是任何协议的重要组成部分，它定义了服务提供商和最终用户之间的法律关系。它们不仅确定和界定了相互的权利和责任，还为用户提供了与使用数字空间有关的合同重要方面的信息。这些方面包括责任限制、数据保护等各种主题。用户倾向于在使用任何应用程序或服务之前接受ToS而不进行阅读。这种无知可能使他们在需要采取任何行动时处于较弱的状况。现有的检测或分类不公平条款的方法已经过时且表现不佳。在这篇研究论文中，我们以前所未有的Fine-tuning BERT与SVC（支持向量分类器）相结合，提出了关于ToS文档中不公平条款检测的SOTA（最新技术）结果。研究表明了出色的性能。

    Terms of Service (ToS) form an integral part of any agreement as it defines the legal relationship between a service provider and an end-user. Not only do they establish and delineate reciprocal rights and responsibilities, but they also provide users with information on essential aspects of contracts that pertain to the use of digital spaces. These aspects include a wide range of topics, including limitation of liability, data protection, etc. Users tend to accept the ToS without going through it before using any application or service. Such ignorance puts them in a potentially weaker situation in case any action is required. Existing methodologies for the detection or classification of unfair clauses are however obsolete and show modest performance. In this research paper, we present SOTA(State of The Art) results on unfair clause detection from ToS documents based on unprecedented Fine-tuning BERT in integration with SVC(Support Vector Classifier). The study shows proficient perform
    
[^45]: 高斯自适应注意力是唯一所需的：跨多个模态的健壮上下文表示

    Gaussian Adaptive Attention is All You Need: Robust Contextual Representations Across Multiple Modalities. (arXiv:2401.11143v1 [cs.LG])

    [http://arxiv.org/abs/2401.11143](http://arxiv.org/abs/2401.11143)

    该论文提出了一个名为GAAM的多头高斯自适应注意力机制，用于增强跨多个模态的信息聚合。通过将可学习的均值和方差纳入注意力机制中，GAAM能够动态地重新调整特征的重要性，从而在处理非平稳数据时取得了显著的性能提升，超过了目前现有的注意力技术。该方法的适应性强且参数数量较少，具有改进现有注意力框架的潜力。

    

    我们提出了多头高斯自适应注意力机制（GAAM），一种新颖的概率注意力框架，并设计了高斯自适应变压器（GAT），旨在增强跨多个模态（包括语音、文本和视觉）的信息聚合。GAAM将可学习的均值和方差融入其注意力机制中，采用多头框架实现，使其能够集体建模任何概率分布，以动态重新调整特征重要性。该方法在处理高度非平稳数据时表现出显著改进，通过识别特征空间中的关键元素，超越了现有的注意力技术在模型性能上的状态（精度增加约20%）。GAAM与基于点积的注意力模型兼容，并具有相对较低的参数数量，展示了其适应性和提升现有注意力框架的潜力。在实证方面，GAAM表现出卓越的适应性和功效。

    We propose the Multi-Head Gaussian Adaptive Attention Mechanism (GAAM), a novel probabilistic attention framework, and the Gaussian Adaptive Transformer (GAT), designed to enhance information aggregation across multiple modalities, including Speech, Text and Vision. GAAM integrates learnable mean and variance into its attention mechanism, implemented in a Multi-Headed framework enabling it to collectively model any Probability Distribution for dynamic recalibration of feature significance. This method demonstrates significant improvements, especially with highly non-stationary data, surpassing the state-of-the-art attention techniques in model performance (up to approximately +20% in accuracy) by identifying key elements within the feature space. GAAM's compatibility with dot-product-based attention models and relatively low number of parameters showcases its adaptability and potential to boost existing attention frameworks. Empirically, GAAM exhibits superior adaptability and efficacy
    
[^46]: Chem-FINESE: 通过文本重构验证细粒度少样本实体提取

    Chem-FINESE: Validating Fine-Grained Few-shot Entity Extraction through Text Reconstruction. (arXiv:2401.10189v1 [cs.CL])

    [http://arxiv.org/abs/2401.10189](http://arxiv.org/abs/2401.10189)

    这篇论文提出了一种名为Chem-FINESE的方法来处理化学领域中细粒度少样本实体提取的问题。该方法通过使用序列到序列的实体提取器和自我验证模块来从输入句子中提取命名实体并重构原始输入句子。实验证明了该方法的有效性和可行性。

    

    在化学领域中，细粒度少样本实体提取面临两个独特的挑战。首先，与一般领域的实体提取任务相比，化学论文中的句子通常包含更多的实体。此外，实体提取模型通常难以提取长尾类型的实体。在本文中，我们提出了一种新颖的基于序列到序列的少样本实体提取方法Chem-FINESE来解决这两个挑战。我们的Chem-FINESE包含两个组件：一个序列到序列的实体提取器用于从输入句子中提取命名实体，以及一个序列到序列的自我验证模块用于从提取的实体中重构原始输入句子。受到一个好的实体提取系统需要忠实提取实体的事实启发，我们的新自我验证模块利用实体提取结果来重构原始输入句子。此外，我们设计了一种新的对比损失来减少在提取过程中的过度复制。

    Fine-grained few-shot entity extraction in the chemical domain faces two unique challenges. First, compared with entity extraction tasks in the general domain, sentences from chemical papers usually contain more entities. Moreover, entity extraction models usually have difficulty extracting entities of long-tailed types. In this paper, we propose Chem-FINESE, a novel sequence-to-sequence (seq2seq) based few-shot entity extraction approach, to address these two challenges. Our Chem-FINESE has two components: a seq2seq entity extractor to extract named entities from the input sentence and a seq2seq self-validation module to reconstruct the original input sentence from extracted entities. Inspired by the fact that a good entity extraction system needs to extract entities faithfully, our new self-validation module leverages entity extraction results to reconstruct the original input sentence. Besides, we design a new contrastive loss to reduce excessive copying during the extraction proces
    
[^47]: 通过突出重要信息来更好地解释Transformer模型

    Better Explain Transformers by Illuminating Important Information. (arXiv:2401.09972v1 [cs.CL])

    [http://arxiv.org/abs/2401.09972](http://arxiv.org/abs/2401.09972)

    通过在层间相关传播方法之上使用精细化的信息流，该论文提出了一种解释Transformer模型的方法，突出重要信息并消除无关信息。实验证明，在处理分类和问答任务时，这种方法相比其他八种基线模型更加出色。

    

    基于Transformer的模型在各种自然语言处理（NLP）任务中表现出色，吸引了无数努力来解释其内部工作原理。现有方法通过关注原始梯度和注意力来解释Transformer，将非相关信息通常视为解释计算的一部分，导致结果混乱。在这项工作中，我们提出了一种在层间相关传播（LRP）方法之上通过精细化信息流来突出重要信息并消除无关信息的方法。具体而言，我们考虑将句法和位置头识别为重要注意力头，并专注于从这些重要头部获得的相关性。实验结果表明，无关信息确实会扭曲输出的归因分数，因此在解释计算过程中应该对其进行屏蔽。与八种基线模型在分类和问答数据集上的比较结果显示，我们的方法在结果上不断地表现优秀。

    Transformer-based models excel in various natural language processing (NLP) tasks, attracting countless efforts to explain their inner workings. Prior methods explain Transformers by focusing on the raw gradient and attention as token attribution scores, where non-relevant information is often considered during explanation computation, resulting in confusing results. In this work, we propose highlighting the important information and eliminating irrelevant information by a refined information flow on top of the layer-wise relevance propagation (LRP) method. Specifically, we consider identifying syntactic and positional heads as important attention heads and focus on the relevance obtained from these important heads. Experimental results demonstrate that irrelevant information does distort output attribution scores and then should be masked during explanation computation. Compared to eight baselines on both classification and question-answering datasets, our method consistently outperfo
    
[^48]: DevEval: 评估实际软件项目中的代码生成

    DevEval: Evaluating Code Generation in Practical Software Projects. (arXiv:2401.06401v1 [cs.SE])

    [http://arxiv.org/abs/2401.06401](http://arxiv.org/abs/2401.06401)

    本文提出了一个名为DevEval的新基准测试，用于评估实际软件项目中的代码生成。与之前的基准测试相比，DevEval在真实的项目分布、充足的依赖和足够规模的项目背景等方面更贴合实际。通过对五个流行的大型语言模型进行评估，我们揭示了它们在代码生成中的实际能力。

    

    如何评估大型语言模型（LLMs）在代码生成中的表现是一个开放的问题。许多基准测试已经提出，但是与实际软件项目不一致，例如虚构的程序分布，依赖不足和小规模项目背景。因此，LLMs在实际项目中的能力还不清楚。在本文中，我们提出了一个名为DevEval的新基准测试，与开发人员在实际项目中的经验相吻合。DevEval通过一个严格的流程收集到了来自119个实际项目的2690个样本，涵盖10个领域。与之前的基准测试相比，DevEval在多个维度上与实际项目相吻合，例如真实的程序分布，充足的依赖和足够规模的项目背景。我们在DevEval上评估了五个流行的LLMs（例如gpt-4，gpt-3.5-turbo，CodeLLaMa和StarCoder），并揭示了它们在代码生成中的实际能力。例如，gpt-3.5-turbo的最高Pass@1只有42。

    How to evaluate Large Language Models (LLMs) in code generation is an open question. Many benchmarks have been proposed but are inconsistent with practical software projects, e.g., unreal program distributions, insufficient dependencies, and small-scale project contexts. Thus, the capabilities of LLMs in practical projects are still unclear. In this paper, we propose a new benchmark named DevEval, aligned with Developers' experiences in practical projects. DevEval is collected through a rigorous pipeline, containing 2,690 samples from 119 practical projects and covering 10 domains. Compared to previous benchmarks, DevEval aligns to practical projects in multiple dimensions, e.g., real program distributions, sufficient dependencies, and enough-scale project contexts. We assess five popular LLMs on DevEval (e.g., gpt-4, gpt-3.5-turbo, CodeLLaMa, and StarCoder) and reveal their actual abilities in code generation. For instance, the highest Pass@1 of gpt-3.5-turbo only is 42 in our experim
    
[^49]: ArabIcros: 基于人工智能的阿拉伯语填字游戏生成器用于教育应用

    ArabIcros: AI-Powered Arabic Crossword Puzzle Generation for Educational Applications. (arXiv:2312.01339v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.01339](http://arxiv.org/abs/2312.01339)

    本文介绍了基于人工智能技术的阿拉伯语填字游戏生成器ArabIcros，利用先进的语言模型生成独特且具有挑战性的线索，并通过教育性填字游戏提升学习体验，改变传统学习方法的格局。

    

    本文介绍了第一款由先进人工智能技术驱动的阿拉伯语填字游戏生成器。该系统利用GPT4、GPT3-Davinci、GPT3-Curie、GPT3-Babbage、GPT3-Ada和BERT等最新的大型语言模型，生成独特且具有挑战性的线索。基于包含超过50,000个线索-答案对的数据集，生成器采用微调、少量/零样本学习策略和严格的质量检查协议，以生成高质量的线索-答案对。值得注意的是，教育性填字游戏有助于增强记忆力、扩展词汇量和促进问题解决能力，从而通过有趣和吸引人的方式增强学习体验，改变传统学习方法的格局。整个系统可以被用作强大的教育工具，融合人工智能和创新的学习技术，为阿拉伯语填字游戏和技术与教育交叉领域带来变革时代。

    This paper presents the first Arabic crossword puzzle generator driven by advanced AI technology. Leveraging cutting-edge large language models including GPT4, GPT3-Davinci, GPT3-Curie, GPT3-Babbage, GPT3-Ada, and BERT, the system generates distinctive and challenging clues. Based on a dataset comprising over 50,000 clue-answer pairs, the generator employs fine-tuning, few/zero-shot learning strategies, and rigorous quality-checking protocols to enforce the generation of high-quality clue-answer pairs. Importantly, educational crosswords contribute to enhancing memory, expanding vocabulary, and promoting problem-solving skills, thereby augmenting the learning experience through a fun and engaging approach, reshaping the landscape of traditional learning methods. The overall system can be exploited as a powerful educational tool that amalgamates AI and innovative learning techniques, heralding a transformative era for Arabic crossword puzzles and the intersection of technology and educa
    
[^50]: 个性化蒸馏：为代码生成赋能自适应学习的开源LLMs

    Personalised Distillation: Empowering Open-Sourced LLMs with Adaptive Learning for Code Generation. (arXiv:2310.18628v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.18628](http://arxiv.org/abs/2310.18628)

    通过个性化蒸馏，将闭源LLMs的能力传递给开源LLMs，并在代码生成任务中表现出比标准蒸馏更好的性能，只使用三分之一的数据。

    

    随着强大的闭源LLMs（ChatGPT，GPT-4）的崛起，越来越多的人对将闭源LLMs的功能蒸馏到较小的开源LLMs中表示兴趣。以往的蒸馏方法通常是引导ChatGPT生成一组指令和答案，以供学生模型学习。然而，这种标准蒸馏方法忽视了学生模型的优点和条件。受现代教学原则的启发，我们设计了一种个性化蒸馏过程，其中学生首先尝试解决一个任务，然后老师提供自适应的改进方法来帮助学生提高。个性化蒸馏不同于提供给学生老师的先验知识，它使学生模型能够进行个性化学习，只在自己犯错误的示例上进行学习，并改进自己的解决方案。在代码生成方面，个性化蒸馏始终优于只使用三分之一数据的标准蒸馏方法。

    With the rise of powerful closed-sourced LLMs (ChatGPT, GPT-4), there are increasing interests in distilling the capabilies of close-sourced LLMs to smaller open-sourced LLMs. Previous distillation methods usually prompt ChatGPT to generate a set of instructions and answers, for the student model to learn. However, such standard distillation approach neglects the merits and conditions of the student model. Inspired by modern teaching principles, we design a personalised distillation process, in which the student attempts to solve a task first, then the teacher provides an adaptive refinement for the student to improve. Instead of feeding the student with teacher's prior, personalised distillation enables personalised learning for the student model, as it only learns on examples it makes mistakes upon and learns to improve its own solution. On code generation, personalised distillation consistently outperforms standard distillation with only one third of the data. With only 2.5-3K perso
    
[^51]: 使用大型语言模型进行产品属性值提取

    Product Attribute Value Extraction using Large Language Models. (arXiv:2310.12537v1 [cs.CL])

    [http://arxiv.org/abs/2310.12537](http://arxiv.org/abs/2310.12537)

    本文研究使用大型语言模型作为预训练的替代方法，解决了传统属性/值提取技术中需要大量训练数据和对未知属性值的挑战问题。

    

    电子商务应用（如面向属性的产品搜索或产品比较）基于结构化的产品描述，如属性/值对。电子商务平台上的供应商不提供结构化的产品描述，而是使用标题或描述来描述产品。为了处理这样的产品，有必要从文本产品属性中提取属性/值对。现有技术中，属性/值提取方法依赖于预训练的语言模型（如BERT）。这些模型在属性/值提取方面存在两个主要缺点：（一）模型需要大量的与任务相关的训练数据；（二）优化后的模型在推广到训练数据中未包含的属性值方面面临挑战。本文探讨了大型语言模型（LLMs）作为训练数据效率高且鲁棒性强的替代方法在属性/值提取中的潜力。我们考虑了托管的LLMs，如GPT-3.5和GPT-4。

    E-commerce applications such as faceted product search or product comparison are based on structured product descriptions like attribute/value pairs. The vendors on e-commerce platforms do not provide structured product descriptions but describe offers using titles or descriptions. To process such offers, it is necessary to extract attribute/value pairs from textual product attributes. State-of-the-art attribute/value extraction techniques rely on pre-trained language models (PLMs), such as BERT. Two major drawbacks of these models for attribute/value extraction are that (i) the models require significant amounts of task-specific training data and (ii) the fine-tuned models face challenges in generalizing to attribute values not included in the training data. This paper explores the potential of large language models (LLMs) as a training data-efficient and robust alternative to PLM-based attribute/value extraction methods. We consider hosted LLMs, such as GPT-3.5 and GPT-4, as well as 
    
[^52]: ECoFLaP: 高效的粗到细的逐层剪枝方法用于视觉语言模型

    ECoFLaP: Efficient Coarse-to-Fine Layer-Wise Pruning for Vision-Language Models. (arXiv:2310.02998v1 [cs.CV])

    [http://arxiv.org/abs/2310.02998](http://arxiv.org/abs/2310.02998)

    ECoFLaP提出了一种高效的粗到细的逐层剪枝方法，解决了大型视觉语言模型在压缩和部署时的计算和能耗问题。

    

    大型视觉语言模型（LVLMs）通过整合不同模态的丰富信息，全面理解世界，并在各种多模态下游任务上取得显著的性能提升。然而，由于其巨大的计算/能耗和碳排放，部署LVLMs往往存在问题。这些问题使得采用传统的迭代全局剪枝变得不可行，因为其需要计算整个大型模型的Hessian矩阵以进行稀疏化。相反，最近的研究提出了逐层剪枝方法，避免了全局剪枝的昂贵计算，并根据层内权重的重要性有效压缩模型。然而，这些方法常常由于缺乏全局视角而导致模型压缩不够优化。为了解决大型模型最近高效剪枝方法的这一局限性，我们提出了高效的粗到细的逐层剪枝方法（ECoFLaP）。

    Large Vision-Language Models (LVLMs) can understand the world comprehensively by integrating rich information from different modalities, achieving remarkable performance improvements on various multimodal downstream tasks. However, deploying LVLMs is often problematic due to their massive computational/energy costs and carbon consumption. Such issues make it infeasible to adopt conventional iterative global pruning, which is costly due to computing the Hessian matrix of the entire large model for sparsification. Alternatively, several studies have recently proposed layer-wise pruning approaches to avoid the expensive computation of global pruning and efficiently compress model weights according to their importance within a layer. However, these methods often suffer from suboptimal model compression due to their lack of a global perspective. To address this limitation in recent efficient pruning methods for large models, we propose Efficient Coarse-to-Fine Layer-Wise Pruning (ECoFLaP), 
    
[^53]: ChaCha：利用大型语言模型引导儿童分享与个人事件相关的情绪

    ChaCha: Leveraging Large Language Models to Prompt Children to Share Their Emotions about Personal Events. (arXiv:2309.12244v1 [cs.HC])

    [http://arxiv.org/abs/2309.12244](http://arxiv.org/abs/2309.12244)

    ChaCha是一个利用大型语言模型（LLMs）的聊天机器人，鼓励儿童分享个人事件和相关情绪。通过一个探索性研究，发现儿童将ChaCha视为亲密的朋友，并愿意与其分享各种主题的故事。

    

    儿童通常通过与家人或他人分享故事和感受来学习辨识和表达情绪，然而，由于儿童正在发展他们的交流技能，父母或兄弟姐妹很难与他们进行情感沟通。本文介绍了ChaCha，一个鼓励和引导儿童分享个人事件和相关情绪的聊天机器人。ChaCha结合了状态机和大型语言模型（LLMs），在进行自由对话的同时保持对话的方向性。通过与20名年龄在8-12岁的儿童进行的探索性研究，我们研究了ChaCha如何促使儿童分享个人事件并引导他们描述相关情绪。参与者认为ChaCha就像一个亲密的朋友，并分享了各种主题的故事，如家庭旅行和个人成就。基于定量和定性发现，我们讨论了利用LLMs设计适合儿童的聊天机器人的机遇。

    Children typically learn to identify and express emotions through sharing their stories and feelings with others, particularly their family. However, it is challenging for parents or siblings to have emotional communication with children since children are still developing their communication skills. We present ChaCha, a chatbot that encourages and guides children to share personal events and associated emotions. ChaCha combines a state machine and large language models (LLMs) to keep the dialogue on track while carrying on free-form conversations. Through an exploratory study with 20 children (aged 8-12), we examine how ChaCha prompts children to share personal events and guides them to describe associated emotions. Participants perceived ChaCha as a close friend and shared their stories on various topics, such as family trips and personal achievements. Based on the quantitative and qualitative findings, we discuss opportunities for leveraging LLMs to design child-friendly chatbots to
    
[^54]: 双模态注意增强的文本-视频检索与三元部分边际对比学习

    Dual-Modal Attention-Enhanced Text-Video Retrieval with Triplet Partial Margin Contrastive Learning. (arXiv:2309.11082v1 [cs.CV])

    [http://arxiv.org/abs/2309.11082](http://arxiv.org/abs/2309.11082)

    本文提出了一种双模态注意增强的文本-视频检索方法，通过引入新颖的对比学习技术，能够准确衡量跨模态相似性和挖掘难负样本。

    

    近年来，网络视频的爆炸性增长使得文本-视频检索对于视频过滤、推荐和搜索变得越来越重要和流行。文本-视频检索旨在将相关的文本/视频排在不相关的文本/视频之前。该任务的核心是准确衡量文本和视频之间的跨模态相似性。最近，对比学习方法在文本-视频检索方面显示出有希望的结果，其中大部分方法侧重于构建正负样本对以学习文本和视频表示。然而，他们在关注难负样本和模拟不同层次的语义相似性方面不够，存在两个问题。为了解决这两个问题，本文使用两个新方法改进了对比学习。首先，为了利用艰难的例子来提高鲁棒的判别能力，我们提出了一种新颖的双模态注意增强模块(DMAE)，从文本和视觉线索中挖掘难负样本。通过进一步引入一个负面样本筛选机制，该方法可以建模不同级别的语义相似性。

    In recent years, the explosion of web videos makes text-video retrieval increasingly essential and popular for video filtering, recommendation, and search. Text-video retrieval aims to rank relevant text/video higher than irrelevant ones. The core of this task is to precisely measure the cross-modal similarity between texts and videos. Recently, contrastive learning methods have shown promising results for text-video retrieval, most of which focus on the construction of positive and negative pairs to learn text and video representations. Nevertheless, they do not pay enough attention to hard negative pairs and lack the ability to model different levels of semantic similarity. To address these two issues, this paper improves contrastive learning using two novel techniques. First, to exploit hard examples for robust discriminative power, we propose a novel Dual-Modal Attention-Enhanced Module (DMAE) to mine hard negative pairs from textual and visual clues. By further introducing a Negat
    
[^55]: OYXOY:适用于现代希腊语的现代NLP测试套件

    OYXOY: A Modern NLP Test Suite for Modern Greek. (arXiv:2309.07009v1 [cs.CL])

    [http://arxiv.org/abs/2309.07009](http://arxiv.org/abs/2309.07009)

    本文提出了一种适用于希腊语自然语言处理的现代NLP测试套件，其中包含四个专家验证的评估任务，用于自然语言推理、词义消歧和隐喻检测。创新之处在于推理数据集首次标记了所有可能的推理标签，并且展示了一种对于资源匮乏语言获取数据集的成本效益方法。

    

    本文是为希腊语自然语言处理开展的一项基础性工作，旨在创建一个基于语言学和技术相关性的评估套件。我们通过引入四个经过专家验证的评估任务来开展这项工作，这些任务专门针对自然语言推理、词义消歧（通过示例比较或选择意义）和隐喻检测。与现有任务的语言适应副本不同的是，我们贡献了两个创新点，这些将与更广泛的资源和评估社区产生共鸣。首先，我们推理数据集是首个标记了不仅仅是\texttt{一}种，而是\texttt{所有}可能推理标签的数据集，考虑到由于歧义性或多义性可能导致的可能转变。其次，我们展示了一种对于资源匮乏语言获取数据集的成本效益方法。通过使用ChatGPT作为语言中立解析器，我们将希腊现代标准词典转换为结构化格式，从中衍生出其他的数据集。

    This paper serves as a foundational step towards the development of a linguistically motivated and technically relevant evaluation suite for Greek NLP. We initiate this endeavor by introducing four expert-verified evaluation tasks, specifically targeted at natural language inference, word sense disambiguation (through example comparison or sense selection) and metaphor detection. More than language-adapted replicas of existing tasks, we contribute two innovations which will resonate with the broader resource and evaluation community. Firstly, our inference dataset is the first of its kind, marking not just \textit{one}, but rather \textit{all} possible inference labels, accounting for possible shifts due to e.g. ambiguity or polysemy. Secondly, we demonstrate a cost-efficient method to obtain datasets for under-resourced languages. Using ChatGPT as a language-neutral parser, we transform the Dictionary of Standard Modern Greek into a structured format, from which we derive the other th
    
[^56]: HC3 Plus：一个语义不变的人类ChatGPT对比语料库

    HC3 Plus: A Semantic-Invariant Human ChatGPT Comparison Corpus. (arXiv:2309.02731v1 [cs.CL])

    [http://arxiv.org/abs/2309.02731](http://arxiv.org/abs/2309.02731)

    本文介绍了HC3 Plus，一个语义不变的人类ChatGPT对比语料库。与以往的工作相比，该语料库考虑了更多类型的任务，包括语义不变任务。研究发现，在语义不变任务中检测模型生成的文本更加困难。通过大量任务指令微调和Tk-instruct，建立了一个更强大的模型。

    

    ChatGPT因其出色的性能而引起了人们的广泛关注，但人们对其潜在风险，尤其是对AI生成内容（AIGC）的检测越来越关注，这对未经训练的人类来说往往很难识别。目前用于检测ChatGPT生成文本的数据集主要集中在问答方面，但往往忽视了具有语义不变性的任务，如摘要、翻译和改写。我们的研究表明，在语义不变任务上检测模型生成的文本更加困难。为了填补这一空白，我们引入了一个更广泛、更全面的数据集，考虑了比以前的工作更多类型的任务，包括语义不变任务。此外，经过大量任务指令微调的模型表现出很强的性能。基于以前的成功，我们进一步指导微调了Tk-instruct，并构建了一个更强大的模型。

    ChatGPT has gained significant interest due to its impressive performance, but people are increasingly concerned about its potential risks, particularly around the detection of AI-generated content (AIGC), which is often difficult for untrained humans to identify. Current datasets utilized for detecting ChatGPT-generated text primarily center around question-answering, yet they tend to disregard tasks that possess semantic-invariant properties, such as summarization, translation, and paraphrasing. Our primary studies demonstrate that detecting model-generated text on semantic-invariant tasks is more difficult. To fill this gap, we introduce a more extensive and comprehensive dataset that considers more types of tasks than previous work, including semantic-invariant tasks. In addition, the model after a large number of task instruction fine-tuning shows a strong powerful performance. Owing to its previous success, we further instruct fine-tuning Tk-instruct and built a more powerful det
    
[^57]: FlexKBQA：一种用于少样本知识库问答的灵活LLM驱动框架

    FlexKBQA: A Flexible LLM-Powered Framework for Few-Shot Knowledge Base Question Answering. (arXiv:2308.12060v1 [cs.CL])

    [http://arxiv.org/abs/2308.12060](http://arxiv.org/abs/2308.12060)

    FlexKBQA使用大型语言模型(LLMs)作为程序翻译器，通过自动化算法从知识库中抽样多样的程序，将其转换为自然语言问题，从而解决少样本知识库问答任务的挑战。

    

    知识库问答（KBQA）是一个关键且具有挑战性的任务，因为知识库中的实体数量庞大，并且用户提出的自然语言问题多样化。不幸的是，大多数KBQA模型在现实场景中性能显著下降，因为高质量的注释数据不足。为了减轻手动注释的负担，我们利用大型语言模型（LLMs）作为程序翻译器，介绍了FlexKBQA来解决少样本KBQA任务中固有的挑战。具体而言，FlexKBQA利用自动化算法从知识库中抽样多样的程序（如SPARQL查询），然后通过LLMs将其转换为自然语言问题。这个合成的数据集有助于训练一个专门的轻量级模型来处理知识库。此外，为了减少合成数据与真实用户问题之间的分布偏移的障碍，FlexKBQA引入了一个执行机制。

    Knowledge base question answering (KBQA) is a critical yet challenging task due to the vast number of entities within knowledge bases and the diversity of natural language questions posed by users. Unfortunately, the performance of most KBQA models tends to decline significantly in real-world scenarios where high-quality annotated data is insufficient. To mitigate the burden associated with manual annotation, we introduce FlexKBQA by utilizing Large Language Models (LLMs) as program translators for addressing the challenges inherent in the few-shot KBQA task. Specifically, FlexKBQA leverages automated algorithms to sample diverse programs, such as SPARQL queries, from the knowledge base, which are subsequently converted into natural language questions via LLMs. This synthetic dataset facilitates training a specialized lightweight model for the KB. Additionally, to reduce the barriers of distribution shift between synthetic data and real user questions, FlexKBQA introduces an executiong
    
[^58]: LogPrompt: 零样本和可解释的日志分析的提示工程

    LogPrompt: Prompt Engineering Towards Zero-Shot and Interpretable Log Analysis. (arXiv:2308.07610v1 [cs.SE])

    [http://arxiv.org/abs/2308.07610](http://arxiv.org/abs/2308.07610)

    LogPrompt是一种新颖的零样本和可解释的日志分析方法，通过利用大型语言模型和专为日志任务设计的高级提示策略，实现了对日志的分析，提高了模型的性能和可解释性。

    

    在现代软件密集型系统中，自动化日志分析对于确保软件维护和工程生命周期的可靠性和弹性至关重要。现有方法通过提供单个预测值而没有解释来执行诸如日志解析和日志异常检测等任务。然而，随着系统事件的增加，分析结果的有限可解释性阻碍了分析人员对其的信任度和采取适当行动的能力。此外，这些方法需要大量的领域内培训数据，并且它们的性能在涉及新域的未见过日志的在线场景中急剧下降（最多下降62.5%），这是由于软件更新的迅速而常见的情况。在本文中，我们提出了一个新颖的零样本和可解释的日志分析方法LogPrompt。LogPrompt利用大型语言模型（LLM）通过一套针对日志任务的高级提示策略执行零样本日志分析任务，从而增强LLM的性能。

    Automated log analysis is crucial in modern software-intensive systems for ensuring reliability and resilience throughout software maintenance and engineering life cycles. Existing methods perform tasks such as log parsing and log anomaly detection by providing a single prediction value without interpretation. However, given the increasing volume of system events, the limited interpretability of analysis results hinders analysts' trust and their ability to take appropriate actions. Moreover, these methods require substantial in-domain training data, and their performance declines sharply (by up to 62.5%) in online scenarios involving unseen logs from new domains, a common occurrence due to rapid software updates. In this paper, we propose LogPrompt, a novel zero-shot and interpretable log analysis approach. LogPrompt employs large language models (LLMs) to perform zero-shot log analysis tasks via a suite of advanced prompt strategies tailored for log tasks, which enhances LLMs' perform
    
[^59]: 忘记演示，专注于从文本指令中学习

    Forget Demonstrations, Focus on Learning from Textual Instructions. (arXiv:2308.03795v1 [cs.CL])

    [http://arxiv.org/abs/2308.03795](http://arxiv.org/abs/2308.03795)

    本研究提出了一种从文本指令中学习任务的方法，通过自动找出定义中的关键句子和使用排名目标，实现了最先进的性能。

    

    本研究针对零示范跨任务泛化的一个更具挑战性但更真实的情境进行研究：从文本指令中学习而无需示范，假设存在一种段落式任务定义但不存在示范。为了更好地从定义中学习任务监督，我们提出了两种策略：首先，自动找出定义中的关键句子；其次，使用排名目标来强制模型在定义中突出显示这些关键部分时生成金标输出的概率更高。这两种策略的共同努力在具有挑战性的基准测试中产生了最先进的性能。我们的代码将在论文的最终版本中发布。

    This work studies a challenging yet more realistic setting for zero-shot cross-task generalization: demonstration-free learning from textual instructions, presuming the existence of a paragraph-style task definition while no demonstrations exist. To better learn the task supervision from the definition, we propose two strategies: first, to automatically find out the critical sentences in the definition; second, a ranking objective to force the model to generate the gold outputs with higher probabilities when those critical parts are highlighted in the definition. The joint efforts of the two strategies yield state-of-the-art performance on the challenging benchmark. Our code will be released in the final version of the paper.
    
[^60]: MeetEval: 一种用于会议转录系统字错误率计算的工具包

    MeetEval: A Toolkit for Computation of Word Error Rates for Meeting Transcription Systems. (arXiv:2307.11394v1 [cs.CL])

    [http://arxiv.org/abs/2307.11394](http://arxiv.org/abs/2307.11394)

    MeetEval是一个计算会议转录系统字错误率的工具包，它通过时间约束来提高匹配质量并加速匹配算法。

    

    MeetEval是一个开源工具包，用于评估各种会议转录系统。它提供了一个统一的界面，用于计算常用的字错误率（WER），包括cpWER、ORC WER和MIMO WER等其他WER定义。我们通过时间约束扩展了cpWER的计算，以确保只有在时间对齐合理的情况下才将单词识别为正确。这样可以更好地匹配假设字符串与参考字符串，更接近实际的转录质量，并且如果系统提供了不准确的时间标注，将对其进行惩罚。由于通常没有单词级别的时间信息，我们提供了一种从片段级别时间（例如一个句子）近似到确切的单词级时间的方法，并且证明了近似方法与具有确切单词级别注释的匹配导致类似的WER。与此同时，时间约束还导致匹配算法的加速，这超过了倾向拼凑的时间约束。

    MeetEval is an open-source toolkit to evaluate all kinds of meeting transcription systems. It provides a unified interface for the computation of commonly used Word Error Rates (WERs), specifically cpWER, ORC WER and MIMO WER along other WER definitions. We extend the cpWER computation by a temporal constraint to ensure that only words are identified as correct when the temporal alignment is plausible. This leads to a better quality of the matching of the hypothesis string to the reference string that more closely resembles the actual transcription quality, and a system is penalized if it provides poor time annotations. Since word-level timing information is often not available, we present a way to approximate exact word-level timings from segment-level timings (e.g., a sentence) and show that the approximation leads to a similar WER as a matching with exact word-level annotations. At the same time, the time constraint leads to a speedup of the matching algorithm, which outweighs the a
    
[^61]: 在实践中分析数据集注释质量管理

    Analyzing Dataset Annotation Quality Management in the Wild. (arXiv:2307.08153v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.08153](http://arxiv.org/abs/2307.08153)

    该论文调查分析了自然语言数据集的创建过程中的质量管理实践，并提供了相应的建议。研究表明，流行数据集中存在较多的错误注释、偏见或注释伪像。这项研究的贡献是在这一领域进行了大规模的实证分析，并提出了实践指南。

    

    数据质量对于训练准确、公正和可信的机器学习模型以及它们的正确评估至关重要。然而，最近的研究表明，即使是用于训练和评估最先进模型的流行数据集中也存在大量的错误注释、偏见或注释伪像。关于注释项目的最佳实践和指南已经存在，但据我们所知，迄今为止还没有进行大规模分析，以研究创建自然语言数据集时实际进行的质量管理以及是否遵循了这些建议。因此，我们首先调查并总结了文献中描述的数据集创建的推荐质量管理实践，并提供了如何应用这些实践的建议。然后，我们编制了一个由591篇科学出版物组成的文本数据集语料库，并针对与质量相关的方面进行了注释，例如注释者管理、一致性、仲裁或数据验证。

    Data quality is crucial for training accurate, unbiased, and trustworthy machine learning models and their correct evaluation. Recent works, however, have shown that even popular datasets used to train and evaluate state-of-the-art models contain a non-negligible amount of erroneous annotations, bias or annotation artifacts. There exist best practices and guidelines regarding annotation projects. But to the best of our knowledge, no large-scale analysis has been performed as of yet on how quality management is actually conducted when creating natural language datasets and whether these recommendations are followed. Therefore, we first survey and summarize recommended quality management practices for dataset creation as described in the literature and provide suggestions on how to apply them. Then, we compile a corpus of 591 scientific publications introducing text datasets and annotate it for quality-related aspects, such as annotator management, agreement, adjudication or data validat
    
[^62]: 学习为大型语言模型检索上下文示例

    Learning to Retrieve In-Context Examples for Large Language Models. (arXiv:2307.07164v1 [cs.CL])

    [http://arxiv.org/abs/2307.07164](http://arxiv.org/abs/2307.07164)

    本文提出了一个新颖的框架，通过迭代训练密集检索器来为大型语言模型识别高质量的上下文示例，从而显著提高了上下文学习性能，并展示了在训练期间对未见过任务的泛化能力。

    

    大型语言模型（LLMs）展示了它们在上下文中学习的能力，使它们能够根据少量的输入-输出示例执行各种任务。然而，上下文学习的有效性在很大程度上依赖于所选示例的质量。在本文中，我们提出了一个新颖的框架，通过迭代训练密集检索器，可以为LLMs识别高质量的上下文示例。我们的框架首先训练基于LLM反馈的奖励模型来评估候选示例的质量，然后通过知识蒸馏训练基于双编码器的密集检索器。我们在30个任务套件上的实验证明，我们的框架显著提高了上下文学习性能。此外，我们还展示了我们的框架在训练期间对未见过任务的泛化能力。深入分析表明，我们的模型通过检索具有相似模式的示例来提高性能，而这种增益在不同规模的LLMs中是一致的。

    Large language models (LLMs) have demonstrated their ability to learn in-context, allowing them to perform various tasks based on a few input-output examples. However, the effectiveness of in-context learning is heavily reliant on the quality of the selected examples. In this paper, we propose a novel framework to iteratively train dense retrievers that can identify high-quality in-context examples for LLMs. Our framework initially trains a reward model based on LLM feedback to evaluate the quality of candidate examples, followed by knowledge distillation to train a bi-encoder based dense retriever. Our experiments on a suite of 30 tasks demonstrate that our framework significantly enhances in-context learning performance. Furthermore, we show the generalization ability of our framework to unseen tasks during training. An in-depth analysis reveals that our model improves performance by retrieving examples with similar patterns, and the gains are consistent across LLMs of varying sizes.
    
[^63]: 单输出高斯过程中的单个输入多个输出样本

    Multiple output samples per input in a single-output Gaussian process. (arXiv:2306.02719v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.02719](http://arxiv.org/abs/2306.02719)

    本文提出了在单输出高斯过程中允许单个输入具有多个输出样本的方法，以利用可用的输出不确定性信息。通过在speechocean762数据集上的评估，展示了该方法能够计算出更接近多个人工评级器参考输出集的测试集输出分布。

    

    标准的高斯过程（GP）只考虑训练集中每个输入的单个输出样本。针对主观任务的数据集，例如口语评估，可以用多个人工评级器的输出标签对输入进行注释。本文提出将GP推广为允许在训练集中有这些多个输出样本，并且利用可用的输出不确定性信息。这与多输出GP不同，因为这里所有的输出样本都来自同一任务。输出密度函数被形式化为观察到所有输出样本的联合似然度量，为了减少计算成本，潜在变量不会重复。测试集预测类似于标准GP的推理方法，唯一不同的是优化的超参数。通过在speechocean762上进行评估，结果表明，该方法使得GP能够计算出与多个人工评级器的参考输出集更相似的测试集输出分布。

    The standard Gaussian Process (GP) only considers a single output sample per input in the training set. Datasets for subjective tasks, such as spoken language assessment, may be annotated with output labels from multiple human raters per input. This paper proposes to generalise the GP to allow for these multiple output samples in the training set, and thus make use of available output uncertainty information. This differs from a multi-output GP, as all output samples are from the same task here. The output density function is formulated to be the joint likelihood of observing all output samples, and latent variables are not repeated to reduce computation cost. The test set predictions are inferred similarly to a standard GP, with a difference being in the optimised hyper-parameters. This is evaluated on speechocean762, showing that it allows the GP to compute a test set output distribution that is more similar to the collection of reference outputs from the multiple human raters.
    
[^64]: ChatGPT在句子级关系上的评估：重点关注时间、因果和语篇关系

    ChatGPT Evaluation on Sentence Level Relations: A Focus on Temporal, Causal, and Discourse Relations. (arXiv:2304.14827v1 [cs.CL])

    [http://arxiv.org/abs/2304.14827](http://arxiv.org/abs/2304.14827)

    本论文评估了ChatGPT在句子级别的时间、因果和语篇关系任务中的性能，发现其在检测和推理因果关系上表现出色，但在识别时间顺序方面可能存在问题。

    

    本文旨在定量评估ChatGPT，在时间关系、因果关系和语篇关系等句间关系方面的性能。考虑到ChatGPT在各种任务中表现出色，我们在13个数据集的整个测试集上进行了广泛的评估，包括时间和因果关系、基于PDTB2.0和基于对话的语篇关系，以及关于对话理解的下游应用。为了获得可靠的结果，我们采用了三种针对每个任务的定制提示模板，包括零-shot提示模板、零-shot提示工程（PE）模板和上下文学习（ICL）提示模板，为所有流行的句对关系分类任务建立了初始基准分数。我们发现，ChatGPT在检测和推理因果关系方面表现出色，但可能不擅长识别句子间的时间顺序。ICL方法特别适用于提高一些数据集上的模型性能。我们的发现为模型改进和有效提示模板的设计提供了一些见解。

    This paper aims to quantitatively evaluate the performance of ChatGPT, an interactive large language model, on inter-sentential relations such as temporal relations, causal relations, and discourse relations. Given ChatGPT's promising performance across various tasks, we conduct extensive evaluations on the whole test sets of 13 datasets, including temporal and causal relations, PDTB2.0-based and dialogue-based discourse relations, and downstream applications on discourse understanding. To achieve reliable results, we adopt three tailored prompt templates for each task, including the zero-shot prompt template, zero-shot prompt engineering (PE) template, and in-context learning (ICL) prompt template, to establish the initial baseline scores for all popular sentence-pair relation classification tasks for the first time. We find that ChatGPT exhibits strong performance in detecting and reasoning about causal relations, while it may not be proficient in identifying the temporal order betwe
    
[^65]: 字符级别的翻译是否值得等待？将字符级别和子词级别模型用于机器翻译的比较

    Are Character-level Translations Worth the Wait? Comparing Character- and Subword-level Models for Machine Translation. (arXiv:2302.14220v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.14220](http://arxiv.org/abs/2302.14220)

    本文比较了字符级别和子词级别的预训练模型在机器翻译方面的效果，结果表明字符级别建模在形似单词和稀有单词的翻译方面具有更好的效果，在训练数据有限的情况下尤为明显。

    

    最近的研究表明，在多种自然语言处理任务中，预先训练的字符级别语言模型与流行的子词模型具有相当的竞争力。然而，对于神经机器翻译方面，它们的有效性鲜有研究。本研究在多种语言和实验条件下，比较了最先进的字符级别和子词级别预训练模型（分别为ByT5和mT5）在机器翻译中的效果，结果表明字符级别建模在翻译方面是有效的，特别是在训练数据有限的情况下。我们的分析表明，字符模型的性能提升在于更好地翻译了形似单词和稀有单词。在评估源文本在驱动模型预测中的重要性时，我们突出ByT5单词级别模式表明字符级别建模的潜在弱点。

    Pretrained character-level language models were recently shown to be competitive with popular subword models across a range of NLP tasks. However, there has been little research on their effectiveness for neural machine translation (NMT). This work performs an extensive comparison across multiple languages and experimental conditions of state-of-the-art character- and subword-level pre-trained models (ByT5 and mT5, respectively) on NMT, showing the effectiveness of character-level modeling in translation, particularly in cases where training data is limited. In our analysis, we show how character models' performance gains are reflected in better translations of orthographically similar words and rare words. While evaluating the importance of source texts in driving model predictions, we highlight ByT5 word-level patterns suggesting an ability to modulate word and character-level information during the translation, providing insights into a potential weakness of character-level modeling
    
[^66]: 非幂等半环中的A*最短字符串解码

    A* shortest string decoding for non-idempotent semirings. (arXiv:2204.07236v2 [cs.FL] UPDATED)

    [http://arxiv.org/abs/2204.07236](http://arxiv.org/abs/2204.07236)

    该论文提出了一种对非幂等半环上的带权有限状态自动机进行最短字符串解码的算法，通过使用等价确定性自动机的反向最短距离作为启发式，可以有效地找到最短字符串。

    

    对于非幂等半环上的带权有限状态自动机，单一最短路径算法是未定义的，因为这样的半环不能保证最短路径的存在。然而，在满足单调性条件的非幂等半环中（如加乘或对数半环），最短字符串的概念是明确定义的。我们描述了一种算法，该算法使用等价确定性自动机（DFA）的反向最短距离作为A*搜索的启发式，通过在一个伴随幂等半环上执行搜索，证明可以返回最短字符串，从而找到带权非确定性自动机上的最短字符串。虽然DFA可能存在指数级更多的状态，但如果在运行中进行确定化，该算法只需要访问其中的一小部分。

    The single shortest path algorithm is undefined for weighted finite-state automata over non-idempotent semirings because such semirings do not guarantee the existence of a shortest path. However, in non-idempotent semirings admitting an order satisfying a monotonicity condition (such as the plus-times or log semirings), the notion of shortest string is well-defined. We describe an algorithm which finds the shortest string for a weighted non-deterministic automaton over such semirings using the backwards shortest distance of an equivalent deterministic automaton (DFA) as a heuristic for A* search performed over a companion idempotent semiring, which is proven to return the shortest string. While there may be exponentially more states in the DFA, this algorithm needs to visit only a small fraction of them if determinization is performed "on the fly".
    

