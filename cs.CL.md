# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Modular Adaptation of Multilingual Encoders to Written Swiss German Dialect.](http://arxiv.org/abs/2401.14400) | 本文利用多语言编码器并通过持续预训练将其适应到瑞士德语，评估结果显示，仅通过添加瑞士德语适配器到模块化编码器，即可获得完全适应性的97.5%性能。此外，在瑞士德语句子检索任务中，适应字符级模型比其他适应策略更有效。 |
| [^2] | [TURNA: A Turkish Encoder-Decoder Language Model for Enhanced Understanding and Generation.](http://arxiv.org/abs/2401.14373) | TURNA是一种用于土耳其语的低资源语言模型，具备自然语言理解和生成任务能力。TURNA通过预训练的编码-解码架构在理解和生成任务中表现优于多语言模型，并能与土耳其语单语模型竞争。 |
| [^3] | [Genie: Achieving Human Parity in Content-Grounded Datasets Generation.](http://arxiv.org/abs/2401.14367) | Genie是一个用于自动生成高质量内容导向数据的方法，通过三个阶段实现：内容准备、生成和过滤。在人类评估中，生成的数据被发现是自然且高质量的，并且通过与使用人工数据训练的模型比较，我们的模型表现相当或更好。 |
| [^4] | [A Comparative Analysis of Noise Reduction Methods in Sentiment Analysis on Noisy Bengali Texts.](http://arxiv.org/abs/2401.14360) | 本文通过比较分析了噪声减少方法在噪声孟加拉文本情感分析中的效果，并提出了更适用的噪声减少方法的需求。 |
| [^5] | [Topologies of Reasoning: Demystifying Chains, Trees, and Graphs of Thoughts.](http://arxiv.org/abs/2401.14295) | 这篇论文探讨了结合结构的提示工程在提高大型语言模型推理性能方面的前景，通过思维链、思维树或思维图的设计来引导整体推理过程。通过大量实例，这种范式显著增强了模型在多个任务中的能力。总的来说，论文提供了一个通用蓝图，为未来的发展铺平道路。 |
| [^6] | [RomanSetu: Efficiently unlocking multilingual capabilities of Large Language Models models via Romanization.](http://arxiv.org/abs/2401.14280) | 本研究提出了一种创新的方法，通过使用罗马化形式的文本作为接口，有效地利用大语言模型的多语言能力。通过在印地语上的实验证明，罗马化文本不仅提高了推理效率，还在有限的预训练下实现了有竞争力的性能。这些发现表明罗马化有潜力弥合大语言模型应用中的语言障碍。 |
| [^7] | [Transformers and Cortical Waves: Encoders for Pulling In Context Across Time.](http://arxiv.org/abs/2401.14267) | 这项研究探讨了transformer网络和大脑皮层波之间的相似性，并指出了皮层波在提取感觉输入序列中的时间上下文方面的潜在应用。 |
| [^8] | [Improving Natural Language Capability of Code Large Language Model.](http://arxiv.org/abs/2401.14242) | 该论文提出了一个新颖框架，通过融合传统自然语言处理工具和代码大型语言模型，提升了代码大型语言模型的自然语言能力。研究者提出了两个模块，AttentionExtractor用于提取关键短语，AttentionCoder利用这些短语生成目标代码。实验结果表明该框架的有效性。 |
| [^9] | [Enhanced Labeling Technique for Reddit Text and Fine-Tuned Longformer Models for Classifying Depression Severity in English and Luganda.](http://arxiv.org/abs/2401.14240) | 本研究通过提出的标注方法对Reddit文本进行分类，并细调了Longformer模型，研究结果表明该模型在英语和卢干达语的抑郁症严重程度分类中表现出色，优于基准模型。 |
| [^10] | [Assessing the Portability of Parameter Matrices Trained by Parameter-Efficient Finetuning Methods.](http://arxiv.org/abs/2401.14228) | 本文研究了通过参数高效微调方法训练的模块的可移植性，发现这些移植的模块在各种情景下表现出优异的性能，可以有效地重复利用任务特定知识。 |
| [^11] | [Commonsense-augmented Memory Construction and Management in Long-term Conversations via Context-aware Persona Refinement.](http://arxiv.org/abs/2401.14215) | 本文提出了一个旨在解决长期对话中角色句子不具信息性的问题的框架，通过利用常识增强的角色扩展，并设计策略将相互矛盾的角色转化为包含丰富说话者信息的句子，以提高回应生成质量。 |
| [^12] | [Explicitly Representing Syntax Improves Sentence-to-layout Prediction of Unexpected Situations.](http://arxiv.org/abs/2401.14212) | 本文研究了句子到布局预测任务中的语法表示对模型性能的影响。实验结果显示，显式表示语法增强了模型对意外情况的预测能力，但对于未在训练集中出现的句子结构仍存在困难。 |
| [^13] | [DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence.](http://arxiv.org/abs/2401.14196) | DeepSeek-Coder是一系列开源代码模型，通过在高质量项目级代码语料库上进行预训练和采用填空任务和16K窗口来增强代码生成和填充，不仅在多个基准测试中取得了与开源代码模型同样的最新表现，而且超过了现有的闭源模型。 |
| [^14] | [Parameter-Efficient Conversational Recommender System as a Language Processing Task.](http://arxiv.org/abs/2401.14194) | 本文将对话推荐系统作为一种语言处理任务进行建模，利用预训练的语言模型来编码项目、理解用户意图，通过语义匹配进行项目推荐，并生成对话。实验证明了该方法的有效性。 |
| [^15] | [How Can Large Language Models Understand Spatial-Temporal Data?.](http://arxiv.org/abs/2401.14192) | 本文提出了一种名为STG-LLM的创新方法，用于使大型语言模型能够理解时空数据并进行预测。该方法利用STG-Tokenizer将复杂的图形数据转化为简洁的标记，再通过STG-Adapter将标记化数据与LLM的理解能力进行连接。通过微调参数，STG-LLM能够有效地把握标记的语义，同时保留LLM的自然语言理解能力。通过广泛的实验验证了STG-LLM的优越性能。 |
| [^16] | [BayesPrompt: Prompting Large-Scale Pre-Trained Language Models on Few-shot Inference via Debiased Domain Abstraction.](http://arxiv.org/abs/2401.14166) | BayesPrompt通过无偏领域抽象解决大规模预训练语言模型在少样本推理中的泛化问题。 |
| [^17] | [True Knowledge Comes from Practice: Aligning LLMs with Embodied Environments via Reinforcement Learning.](http://arxiv.org/abs/2401.14151) | 本研究通过使用大型语言模型（LLMs）作为决策智能体，通过强化学习与具身环境高效互动来解决LLMs与环境之间知识不对齐的问题。通过查询LLMs的联合概率，形成行为策略，并通过两种归一化方法和四个提示设计原则提高策略的稳定性和鲁棒性。最后，通过设计参数高效的训练架构提高学习效率。 |
| [^18] | [Convolutional Neural Networks can achieve binary bail judgement classification.](http://arxiv.org/abs/2401.14135) | 本文研究使用卷积神经网络在印度印地文法律文件上进行二元保释判断分类，取得了93％的准确率，改进了之前的准确率基准。 |
| [^19] | [On the Affinity, Rationality, and Diversity of Hierarchical Topic Modeling.](http://arxiv.org/abs/2401.14113) | 本论文提出了一种名为TraCo的新层次主题模型，通过传输计划依赖方法和上下文感知的解缠码器，改善了主题层次结构的亲和性、合理性和多样性。 |
| [^20] | [CompactifAI: Extreme Compression of Large Language Models using Quantum-Inspired Tensor Networks.](http://arxiv.org/abs/2401.14109) | CompactifAI是一种使用量子启发的张量网络对大型语言模型进行极压缩的创新方法，相比于传统的压缩方法，它更注重模型的相关空间，实现更加可控和精细的压缩。 |
| [^21] | [Ta'keed: The First Generative Fact-Checking System for Arabic Claims.](http://arxiv.org/abs/2401.14067) | Ta'keed是首个用于阿拉伯语论断的生成式事实核查系统，通过基于检索片段的论断真实性评估和LLM-based论断验证，解决了目前阿拉伯语领域缺乏生成解释论断可信度的研究。引入了一个测试黄金标签数据集，并分析了系统生成解释与黄金标准解释之间的语义相似性。研究还探讨了不同片段数量对论断分类准确性的影响。 |
| [^22] | [Towards Goal-oriented Large Language Model Prompting: A Survey.](http://arxiv.org/abs/2401.14043) | 本文调查了大型语言模型(LLM)中目标导向提示工程的重要性。通过对35个代表性研究的回顾，我们发现引导LLM遵循人类的逻辑思维的目标导向提示公式显著提高了LLM的性能。我们还提出了一个新的分类体系，并总结了十个适用任务来展示我们框架的广泛适用性。同时，我们提出了四个未来的方向，以推动目标导向提示工程的进一步发展。 |
| [^23] | [(Chat)GPT v BERT: Dawn of Justice for Semantic Change Detection.](http://arxiv.org/abs/2401.14040) | 本研究探讨了(Chat)GPT和BERT在语义变化检测任务中的性能，结果表明(Chat)GPT的表现明显低于BERT，尤其在长期变化检测方面表现更差。 |
| [^24] | [Accelerating Retrieval-Augmented Language Model Serving with Speculation.](http://arxiv.org/abs/2401.14021) | 提出了RaLMSpec，这是一个使用推测加速检索增强型语言模型服务的框架，通过推测式检索和批量验证提供了通用的加速效果，并通过进一步优化和并发处理，提高了性能。 |
| [^25] | [Unitxt: Flexible, Shareable and Reusable Data Preparation and Evaluation for Generative AI.](http://arxiv.org/abs/2401.14019) | Unitxt是一个灵活、可共享和可复用的数据准备与评估库，针对生成式语言模型进行定制，实现了结构化、模块化和可定制的解决方案。该库集成了常用的库，将处理流程分解为模块化组件，促进了协作和共享。 |
| [^26] | [Towards Uncertainty-Aware Language Agent.](http://arxiv.org/abs/2401.14016) | UALA是一个使用不确定性量化来进行代理和外部世界交互的框架，相比于其他方法，它在多个任务和语言模型尺寸下表现出显著的性能改进，并且在对外部世界的依赖性方面更低。 |
| [^27] | [CMMU: A Benchmark for Chinese Multi-modal Multi-type Question Understanding and Reasoning.](http://arxiv.org/abs/2401.14011) | CMMU是一个用于中文多模态多类型问题理解和推理的基准测试，涵盖了从小学到高中的知识，提供了多项选择题、多项回答题和填空题三种类型的问题，对于评估多模态大型语言模型的智能水平具有重要意义。 |
| [^28] | [ConstraintChecker: A Plugin for Large Language Models to Reason on Commonsense Knowledge Bases.](http://arxiv.org/abs/2401.14003) | ConstraintChecker是一个针对大型语言模型的插件，用于推理常识知识库。它通过提示技术提供和检查显式约束，帮助解决了大型语言模型在处理常识知识库推理时的困难。 |
| [^29] | [Investigate-Consolidate-Exploit: A General Strategy for Inter-Task Agent Self-Evolution.](http://arxiv.org/abs/2401.13996) | 本文介绍了调查-整合-开发（ICE）策略，通过任务间的自进化来提高AI代理的适应性和灵活性。实验证明了ICE的有效性，可以显著减少API调用，同时与GPT-3.5结合使用可以在各种代理任务上达到与GPT-4相当的性能。 |
| [^30] | [Towards Consistent Natural-Language Explanations via Explanation-Consistency Finetuning.](http://arxiv.org/abs/2401.13986) | 本文提出了一种通过解释一致性微调方法，使得大型语言模型（LLMs）在相关示例上生成更一致的自然语言解释。实验证明，该方法在不同领域的问答数据集上相对提高了10.0%的解释一致性，并且能够泛化到其他数据集。 |
| [^31] | [Leeroo Orchestrator: Elevating LLMs Performance Through Model Integration.](http://arxiv.org/abs/2401.13979) | 本研究提出了Leeroo编排器的架构，通过集成多个训练过的LLMs模型，实现了一个新的最先进模型。该编排器在性能上与Mixtral模型相当，并且成本只有其三分之二。当允许更高的成本时，Leeroo编排器的准确性超过了Mixtral模型，并且当集成GPT4时进一步提升。 |
| [^32] | [Adaptive Text Watermark for Large Language Models.](http://arxiv.org/abs/2401.13927) | 这个论文提出了一种自适应的大型语言模型文字水印策略，通过辅助模型测量高熵令牌分布，将水印自适应地添加到具有高熵的令牌分布中，同时保持低熵令牌分布不变，以提高文本质量和水印的稳健性。 |
| [^33] | [LocMoE: A Low-overhead MoE for Large Language Model Training.](http://arxiv.org/abs/2401.13920) | LocMoE提出了一种新的路由策略，通过将部分节点间通信转换为节点内通信，结合负载平衡和局部性，以提高大型语言模型训练的性能。 |
| [^34] | [WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models.](http://arxiv.org/abs/2401.13919) | WebVoyager是一种创新的基于大型多模态模型的Web代理，能够通过与真实网站交互来端到端地完成用户指令。它提出了一个新的Web代理评估协议，并在实际任务中取得了显著的成功率。 |
| [^35] | [No More Distractions: an Adaptive Up-Sampling Algorithm to Reduce Data Artifacts.](http://arxiv.org/abs/2401.13907) | 这项工作提出了一种自适应上采样算法，用于纠正语言模型训练中的数据伪像。经过使用该算法训练的模型在整体和修订的子集上表现显著优于使用原始数据训练的模型。 |
| [^36] | [Dynamic embedded topic models and change-point detection for exploring literary-historical hypotheses.](http://arxiv.org/abs/2401.13905) | 本研究提出了一种新颖的方法，将动态嵌入主题模型和变点检测结合起来，通过探索文学和历史文本中的词汇语义模态的历时变化，为比较文学和古典学的传统学术研究提供了一种简单的无监督模型。这种方法可以适用于任何适合的语料库，未来还可以通过改进和扩展使其适应更多的未处理材料。 |
| [^37] | [A comparative study of zero-shot inference with large language models and supervised modeling in breast cancer pathology classification.](http://arxiv.org/abs/2401.13887) | 本研究比较了大型语言模型与监督建模在乳腺癌病理分类上的零样本推断能力，发现GPT-4模型在所有任务中要么明显优于，要么与最佳的监督模型LSTM-Att模型相当。 |
| [^38] | [Unmasking and Quantifying Racial Bias of Large Language Models in Medical Report Generation.](http://arxiv.org/abs/2401.13867) | 该论文揭示了大型语言模型在医学报告生成中存在的种族偏见，并通过定性和定量分析证明了这些偏见的影响。这些偏见主要表现为对白人种族的高护理成本和住院时间预测，以及在临床医学中面临挑战的情况下呈现过度乐观的生存率。意识到这些偏见的存在和影响，对于在关键的医疗应用中确保公平和准确的结果至关重要。 |
| [^39] | [TPD: Enhancing Student Language Model Reasoning via Principle Discovery and Guidance.](http://arxiv.org/abs/2401.13849) | 通过原则发现和指导提升学生语言模型的推理能力的TPD框架模拟了教师和学生之间的互动，通过生成问题解决指令和纠正原则，从而引导学生模型从教师的指导和自身的错误中进行学习。 |
| [^40] | [The Calibration Gap between Model and Human Confidence in Large Language Models.](http://arxiv.org/abs/2401.13835) | 该论文研究了大型语言模型在传达置信度方面模型和人类之间存在的差距，并发现默认解释会导致用户过高估计模型置信度和准确性。 |
| [^41] | [Automated Root Causing of Cloud Incidents using In-Context Learning with GPT-4.](http://arxiv.org/abs/2401.13810) | 这项研究提出了一种基于上下文学习的自动化云故障溯源方法，使用GPT-4模型，无需进行昂贵的微调操作，可以改进故障根因分析过程，降低服务停机时间、客户影响和手动劳动。 |
| [^42] | [Investigating the Efficacy of Large Language Models for Code Clone Detection.](http://arxiv.org/abs/2401.13802) | 这项研究探索了大型语言模型在代码克隆检测任务中的应用。 |
| [^43] | [A Unified Approach to Emotion Detection and Task-Oriented Dialogue Modeling.](http://arxiv.org/abs/2401.13789) | 提出了一种统一的方法来实现情感检测和任务导向对话建模，通过在信念状态跟踪中引入情感检测实现，并将其融入端到端的任务导向对话系统中。实验证明该方法提高了情感检测和任务结果的性能，并显示用户的情感可以作为回应的上下文条件，对于提高回应的共鸣程度具有帮助。 |
| [^44] | [Tweets to Citations: Unveiling the Impact of Social Media Influencers on AI Research Visibility.](http://arxiv.org/abs/2401.13782) | 本文研究了社交媒体影响者在提高机器学习研究的可见性方面的作用，发现被这些影响者认可的论文引用次数显著增加，中位数引用次数比对照组高2-3倍。此外，该研究还探讨了被展示作者的地理、性别和机构多样性。 |
| [^45] | [Toward Robust Multimodal Learning using Multimodal Foundational Models.](http://arxiv.org/abs/2401.13697) | 该论文提出了一种名为TRML的框架，旨在实现在随机缺失模态的情况下的稳健多模态学习。TRML利用生成的虚拟模态替换缺失的模态，并且通过对齐语义空间来解决模态缺失的问题。 |
| [^46] | [MM-LLMs: Recent Advances in MultiModal Large Language Models.](http://arxiv.org/abs/2401.13601) | 近年来，多模式大语言模型（MM-LLMs）通过成本效益高的训练策略取得了显著进展，扩展了现有的语言模型的多模输入和输出支持。本论文提供了一份综合调查报告，介绍了MM-LLMs的设计和训练方案，整理了现有的MM-LLMs及其性能，总结了关键训练方法，并探讨了未来的研究方向。 |
| [^47] | [SpeechGPT-Gen: Scaling Chain-of-Information Speech Generation.](http://arxiv.org/abs/2401.13527) | SpeechGPT-Gen是一个8亿参数的语音大型语言模型，通过Chain-of-Information Generation方法来解耦语义和感知信息，在语音生成方面提高了效率。 |
| [^48] | [What the Weight?! A Unified Framework for Zero-Shot Knowledge Composition.](http://arxiv.org/abs/2401.12756) | 本研究提出了一个新的零样本模块组合框架，统一了选择、加权和组合参数模块的各种变化。以领域知识和适配器层为场景，通过系统化的统一概念，进行了首次全面的零样本知识组合的基准研究。 |
| [^49] | [Energy-based Automated Model Evaluation.](http://arxiv.org/abs/2401.12689) | 提出了一种基于能量的自动化模型评估方法，通过建立关于个体样本相关信息的元分布统计量，能够更高效和有效地评估机器学习模型的性能，解决了AutoEval框架中的过度自信、存储和计算成本高等问题。 |
| [^50] | [BiTA: Bi-Directional Tuning for Lossless Acceleration in Large Language Models.](http://arxiv.org/abs/2401.12522) | BiTA是一种用于大语言模型的创新方法，通过双向调整实现了无损加速。它采用简化的半自回归生成和草稿验证，通过高效的基于树的解码同时进行候选生成和验证，提高了推理效率。这种方法不需要额外的辅助模型或显著的额外内存开销。 |
| [^51] | [Instructional Fingerprinting of Large Language Models.](http://arxiv.org/abs/2401.12255) | 这项研究提出了一种指纹识别大型语言模型的方法，通过轻量级的指令调整，保护知识产权并确保遵守许可条款。实验证明这种方法不影响模型的正常行为，并且具有鲁棒性和高效训练的特点。 |
| [^52] | [Mementos: A Comprehensive Benchmark for Multimodal Large Language Model Reasoning over Image Sequences.](http://arxiv.org/abs/2401.10529) | Mementos是一个新的基准测试，旨在评估多模态大型语言模型在图像序列推理中的能力。研究发现，现有的MLLM在准确描述图像序列的动态信息方面存在困难，容易导致物体及其行为的错误描述或错觉。 |
| [^53] | [Top in Chinese Data Processing: English Code Models.](http://arxiv.org/abs/2401.10286) | 在中文数据处理中，基于代码的语言模型在非编程中文任务中表现出色，尤其是在对中文幻觉敏感的任务中。此研究为讨论“中文房间”思想实验提供了独特的视角。 |
| [^54] | [Contrastive Perplexity for Controlled Generation: An Application in Detoxifying Large Language Models.](http://arxiv.org/abs/2401.08491) | 这项研究研究了对比学习目标的集成到微调大型语言模型中，以解决其产生不可取内容的问题，并展示了在清洁领域中有效减少有害内容生成的方法。 |
| [^55] | [TrustLLM: Trustworthiness in Large Language Models.](http://arxiv.org/abs/2401.05561) | TrustLLM是对大型语言模型中可信性的全面研究，包括可信性原则的提出、建立基准的方法、评估主流语言模型的可信性，以及对未来挑战的讨论。 |
| [^56] | [Can AI Be as Creative as Humans?.](http://arxiv.org/abs/2401.01623) | 本文引入了一个新概念【相对创造力】，通过将焦点转向AI是否能够与人类具备相同的创造能力，实现对创造力的统计量化评估和直接比较。 |
| [^57] | [Advancing Abductive Reasoning in Knowledge Graphs through Complex Logical Hypothesis Generation.](http://arxiv.org/abs/2312.15643) | 这篇论文介绍了一种复杂逻辑假设生成的任务，作为实现与知识图谱的诱导逻辑推理的初始步骤。研究发现，过监督训练的生成模型可以生成结构上更接近参考假设的逻辑假设。为了解决推广到未见过观察结果的问题，引入了基于知识图谱的强化学习方法（RLF-KG），最小化观察结果与结论之间的差异。 |
| [^58] | [An Adaptive Placement and Parallelism Framework for Accelerating RLHF Training.](http://arxiv.org/abs/2312.11819) | 提出了一种自适应模型部署和并行框架，用于加速RLHF训练。该框架提供了两种灵活的模型部署策略，其中交替策略有助于减少内存冗余和通信成本。 |
| [^59] | [A Survey of Reasoning with Foundation Models.](http://arxiv.org/abs/2312.11562) | 本文调查了使用基础模型进行推理的研究，介绍了最新的推理任务、方法和基准，并讨论了基础模型中推理能力的未来发展方向。 |
| [^60] | [Topic Bias in Emotion Classification.](http://arxiv.org/abs/2312.09043) | 本文研究了情绪分类中的主题偏差问题，发现情绪语料库中的主题与情绪实际上具有相关性，并且情绪分类器容易受到这些主题的干扰。最后，研究者展示了一种去偏差的方法可以减轻主题偏差的影响。 |
| [^61] | [Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs.](http://arxiv.org/abs/2312.05934) | 该研究比较了无监督的微调和检索增强生成（RAG）这两种常见方法在LLMs中的应用。结果发现，RAG在现有知识和新知识上表现出更好的性能，而LLMs通过无监督的微调学习新的事实信息较困难。 |
| [^62] | [Enhancing Task-Oriented Dialogues with Chitchat: a Comparative Study Based on Lexical Diversity and Divergence.](http://arxiv.org/abs/2311.14067) | 本研究通过比较分析了三种闲聊增强方法，旨在确定在多样性方面最有效的方法，并量化了添加的闲聊与原始任务导向语言和常见闲聊数据集之间的差异。研究结果强调了超越任务范围，实现更加多样化和自然交流的对话的重要性。 |
| [^63] | [General Phrase Debiaser: Debiasing Masked Language Models at a Multi-Token Level.](http://arxiv.org/abs/2311.13892) | 本文提出了一种名为“通用短语去偏器”的自动多标记去偏管道，能够有效减轻掩码语言模型中的短语级别偏见，并在标准数据集和指标上取得了最新成果。 |
| [^64] | [Meta Prompting for AGI Systems.](http://arxiv.org/abs/2311.11482) | 本文全面研究了元提示技术，这是一种创新方法，重塑了大型语言模型、多模态模型和人工智能系统在问题解决和数据解释方面的应用。通过强调信息的结构和句法，元提示将复杂问题拆解为简单的子问题，提高了效率，并且能够与少样本方法进行公平的比较。同时，本文还提出了元提示用于自动生成提示的方法。 |
| [^65] | [Leveraging Large Language Models for Collective Decision-Making.](http://arxiv.org/abs/2311.04928) | 本论文提出了一种利用大型语言模型（LLM）促进集体决策的系统，通过管理对话和平衡个人偏好来提供满足成员需求的选项，实现高效协调并不断优化系统性能。 |
| [^66] | [Massive Editing for Large Language Models via Meta Learning.](http://arxiv.org/abs/2311.04661) | 本论文提出了一种通过元学习实现大规模语言模型的大规模编辑的方法。该方法利用超网络来生成参数变化，通过解决最小二乘问题来更新语言模型的参数。通过将计算分离在超网络和语言模型之间，使得可以同时编辑多个事实。该方法在不同架构的语言模型上进行了评估。 |
| [^67] | [Simple Model Also Works: A Novel Emotion Recognition Network in Textual Conversation Based on Curriculum Learning Strategy.](http://arxiv.org/abs/2308.06450) | 本研究提出了一种基于课程学习策略的新型Emotion Recognition Network (ERNetCL)模型，通过简化网络结构并充分建模上下文来高效地捕捉对话中的情感线索，实现了文本对话情感识别的性能优化。 |
| [^68] | [Arithmetic with Language Models: from Memorization to Computation.](http://arxiv.org/abs/2308.01154) | 本研究探索了使用语言模型进行算术计算的能力，发现语言模型可以通过内部的值空间进行计算，并取得了成功的实验结果。 |
| [^69] | [KoBBQ: Korean Bias Benchmark for Question Answering.](http://arxiv.org/abs/2307.16778) | 本文介绍了KoBBQ，一个针对韩国文化的偏见基准数据集，提出了一个通用框架来解决数据集的文化适应性问题，并通过大规模调查收集和验证了反映韩国文化刻板印象的社会偏见和偏见目标。 |
| [^70] | [Disentanglement in a GAN for Unconditional Speech Synthesis.](http://arxiv.org/abs/2307.01673) | 在无条件语音合成中，我们提出了一种名为ASGAN的解耦生成对抗网络模型，该模型借鉴了StyleGAN图像合成模型，并引入了一些新技术。通过学习解耦的潜在空间，ASGAN能够从潜在空间中合成逼真的语音，即使在小字典数据集上也能取得最新成果。 |
| [^71] | [What do self-supervised speech models know about words?.](http://arxiv.org/abs/2307.00162) | 通过对自我监督的语音模型进行分析，发现这些模型在不同层中编码了不同的语言信息，也学习了类似音素的子词单元。与单词相关的信息主要在中间的模型层中，同时一些低级信息在更高的层中也得以保留。 |
| [^72] | [A Positive-Unlabeled Metric Learning Framework for Document-Level Relation Extraction with Incomplete Labeling.](http://arxiv.org/abs/2306.14806) | 我们提出了一种正负样本度量学习框架（P3M）用于具有不完整标注的文档级关系抽取，通过拉近实体嵌入和其对应关系嵌入的距离，同时使其与非类别关系嵌入的距离推远，以提高模型的泛化能力。 |
| [^73] | [System-Level Natural Language Feedback.](http://arxiv.org/abs/2306.13588) | 本文提出了一个通用框架，用于解锁系统级别使用自然语言反馈的方法。我们展示了通过任务度量设计和语言模型提示设计，如何使用反馈在人工交互流程中形式化系统级别的设计决策，以便产生更好的模型，并展示了使用系统级别反馈和实例级别反馈的有效性。 |
| [^74] | [Unifying Large Language Models and Knowledge Graphs: A Roadmap.](http://arxiv.org/abs/2306.08302) | 本文提出了一个前瞻性的统一大型语言模型和知识图谱的路线图，通过三个框架：增强KGs的LLMs，知识增强KGs和LLMs与KGs的联合推理，综合利用两者的优点。 |
| [^75] | [Cross-Lingual Transfer Learning for Low-Resource Speech Translation.](http://arxiv.org/abs/2306.00789) | 提出了一种三步跨语言迁移学习框架，通过在现有框架中增加一步语义知识蒸馏，该方法有效地增强了自动语音翻译中从高资源语言到低资源语言的跨语言迁移能力，显著改善了翻译性能，特别是对于低资源语言，并减少了跨语言迁移间隙(TRFGap)。 |
| [^76] | [OpenPI2.0: An Improved Dataset for Entity Tracking in Texts.](http://arxiv.org/abs/2305.14603) | OpenPI2.0是一个用于实体追踪的改进数据集，它包括规范化实体、显著性注释和下游应用调查等特点。 |
| [^77] | [Democratized Diffusion Language Model.](http://arxiv.org/abs/2305.10818) | 本文提出了一个基于CDCD框架的民主扩散语言模型（DDLM），并通过GLUE基准测试了其知识转移能力，为研究人员提供了DDLM训练和评估流程以及已训练的DDLM模型。 |
| [^78] | [A transformer-based method for zero and few-shot biomedical named entity recognition.](http://arxiv.org/abs/2305.04928) | 本文提出了一种基于Transformer的生物医学领域零样本和少样本NER方法。此方法利用预训练学习给定和潜在类别之间的语义关系，将多类标记分类任务转换为二元标记分类，能够在不同数量的样本情况下达到良好的识别效果。 |
| [^79] | [Zero-shot Clinical Entity Recognition using ChatGPT.](http://arxiv.org/abs/2303.16416) | 本研究探讨了使用 ChatGPT 进行零样本临床实体识别任务，并发现 ChatGPT 在松弛匹配 F1 分数方面显著优于 GPT-3。虽然其性能仍低于 BioClinicalBERT 模型，但我们的研究表明了 ChatGPT 在零样本设置下有很大的临床 NER 任务潜力。 |
| [^80] | [CultureBERT: Measuring Corporate Culture With Transformer-Based Language Models.](http://arxiv.org/abs/2212.00509) | 本文引入了基于Transformer的语言模型来衡量企业文化，通过对员工评价进行分类，相较于传统方法，语言模型在样本外预测中能提高17到30个百分点的准确率。 |
| [^81] | [Retrieval augmentation of large language models for lay language generation.](http://arxiv.org/abs/2211.03818) | CELLS是用于普通语言生成的最大最广泛的平行语料库，通过生成背景解释和简化原始摘要来解决普通语言生成中的关键挑战。 |

# 详细

[^1]: 将多语言编码器模块化地适应瑞士德语方言

    Modular Adaptation of Multilingual Encoders to Written Swiss German Dialect. (arXiv:2401.14400v1 [cs.CL])

    [http://arxiv.org/abs/2401.14400](http://arxiv.org/abs/2401.14400)

    本文利用多语言编码器并通过持续预训练将其适应到瑞士德语，评估结果显示，仅通过添加瑞士德语适配器到模块化编码器，即可获得完全适应性的97.5%性能。此外，在瑞士德语句子检索任务中，适应字符级模型比其他适应策略更有效。

    

    由于缺乏训练数据和方言变化，建立适用于瑞士德语的神经文本编码器具有挑战性。本文在现有多语言编码器的基础上，使用持续的预训练将其适应到瑞士德语。在三个不同的下游任务上进行评估表明，仅添加瑞士德语适配器到模块化编码器能够达到完全整体适应性性能的97.5%。我们进一步发现，在给定标准德语查询的情况下检索瑞士德语句子的任务中，适应字符级模型比其他适应策略更有效。我们在https://github.com/ZurichNLP/swiss-german-text-encoders发布了我们的代码和训练模型。

    Creating neural text encoders for written Swiss German is challenging due to a dearth of training data combined with dialectal variation. In this paper, we build on several existing multilingual encoders and adapt them to Swiss German using continued pre-training. Evaluation on three diverse downstream tasks shows that simply adding a Swiss German adapter to a modular encoder achieves 97.5% of fully monolithic adaptation performance. We further find that for the task of retrieving Swiss German sentences given Standard German queries, adapting a character-level model is more effective than the other adaptation strategies. We release our code and the models trained for our experiments at https://github.com/ZurichNLP/swiss-german-text-encoders
    
[^2]: TURNA: 一种用于增强理解和生成的土耳其编码-解码语言模型

    TURNA: A Turkish Encoder-Decoder Language Model for Enhanced Understanding and Generation. (arXiv:2401.14373v1 [cs.CL])

    [http://arxiv.org/abs/2401.14373](http://arxiv.org/abs/2401.14373)

    TURNA是一种用于土耳其语的低资源语言模型，具备自然语言理解和生成任务能力。TURNA通过预训练的编码-解码架构在理解和生成任务中表现优于多语言模型，并能与土耳其语单语模型竞争。

    

    自然语言处理的最新进展主要偏向于资源丰富且以英语为中心的模型，这导致了与资源稀缺的语言之间存在显著差距。在这项工作中，我们介绍了TURNA语言模型，该模型针对资源稀缺的土耳其语开发，能够进行自然语言理解和生成任务。TURNA使用基于统一框架UL2的编码-解码架构进行预训练，并且我们专门为此目的筛选了一个多样的语料库。我们对TURNA在土耳其语的三个生成任务和五个理解任务上进行了评估。结果表明，TURNA在理解和生成任务上优于多语言模型，并与土耳其语单语模型在理解任务上竞争。TURNA已在https://huggingface.co/boun-tabi-LMG/TURNA 上提供。

    The recent advances in natural language processing have predominantly favored well-resourced English-centric models, resulting in a significant gap with low-resource languages. In this work, we introduce the language model TURNA, which is developed for the low-resource language Turkish and is capable of both natural language understanding and generation tasks. TURNA is pretrained with an encoder-decoder architecture based on the unified framework UL2 with a diverse corpus that we specifically curated for this purpose. We evaluated TURNA with three generation tasks and five understanding tasks for Turkish. The results show that TURNA outperforms several multilingual models in both understanding and generation tasks, and competes with monolingual Turkish models in understanding tasks. TURNA is made available at https://huggingface.co/boun-tabi-LMG/TURNA .
    
[^3]: Genie：实现内容导向数据集生成的人类水平

    Genie: Achieving Human Parity in Content-Grounded Datasets Generation. (arXiv:2401.14367v1 [cs.CL])

    [http://arxiv.org/abs/2401.14367](http://arxiv.org/abs/2401.14367)

    Genie是一个用于自动生成高质量内容导向数据的方法，通过三个阶段实现：内容准备、生成和过滤。在人类评估中，生成的数据被发现是自然且高质量的，并且通过与使用人工数据训练的模型比较，我们的模型表现相当或更好。

    

    对于内容导向生成任务，缺乏高质量的数据被认为是推动这些任务发展的主要障碍。为了解决这个问题，我们提出了Genie，一种用于自动生成高质量内容导向数据的新方法。它包括三个阶段：（a）内容准备，（b）生成：从内容中创建特定任务的示例（例如问题-答案对或摘要），（c）过滤机制，旨在确保生成数据的质量和可信度。我们通过生成三个大规模的合成数据来展示这种方法：长型问题回答（LFQA）、摘要和信息提取。在人类评估中，我们生成的数据被发现是自然且高质量的。此外，我们将使用我们的数据训练的模型与使用人工编写的数据训练的模型进行比较 - 对于LFQA，我们与ELI5和ASQA进行比较，对于摘要，我们与CNN-DailyMail进行比较。我们表明，我们的模型与或超过使用人工数据训练的模型。

    The lack of high-quality data for content-grounded generation tasks has been identified as a major obstacle to advancing these tasks. To address this gap, we propose Genie, a novel method for automatically generating high-quality content-grounded data. It consists of three stages: (a) Content Preparation, (b) Generation: creating task-specific examples from the content (e.g., question-answer pairs or summaries). (c) Filtering mechanism aiming to ensure the quality and faithfulness of the generated data. We showcase this methodology by generating three large-scale synthetic data, making wishes, for Long-Form Question-Answering (LFQA), summarization, and information extraction. In a human evaluation, our generated data was found to be natural and of high quality. Furthermore, we compare models trained on our data with models trained on human-written data -- ELI5 and ASQA for LFQA and CNN-DailyMail for Summarization. We show that our models are on par with or outperforming models trained 
    
[^4]: 噪声孟加拉语文本情感分析中噪声减少方法的比较分析

    A Comparative Analysis of Noise Reduction Methods in Sentiment Analysis on Noisy Bengali Texts. (arXiv:2401.14360v1 [cs.CL])

    [http://arxiv.org/abs/2401.14360](http://arxiv.org/abs/2401.14360)

    本文通过比较分析了噪声减少方法在噪声孟加拉文本情感分析中的效果，并提出了更适用的噪声减少方法的需求。

    

    尽管孟加拉语被认为是资源有限的语言，但情感分析已经成为文献研究的一个重要主题。然而，在噪声孟加拉文本领域，对情感分析的探索仍然不足。本文介绍了一个由人工标注的数据集（NC-SentNoB），用于识别预存在的情感分析数据集中大约15K个噪声孟加拉文本中的十种不同类型的噪声。我们首先通过将输入噪声文本划分为多个标签来识别噪声类型，然后引入基线噪声减少方法来减少噪声，以进行情感分析。最后，我们评估了针对噪声和减少噪声文本进行微调的情感分析模型的性能，并进行比较。实验结果表明，所使用的噪声减少方法不尽如人意，强调了需要更适用的噪声减少方法的需求。

    While Bengali is considered a language with limited resources, sentiment analysis has been a subject of extensive research in the literature. Nevertheless, there is a scarcity of exploration into sentiment analysis specifically in the realm of noisy Bengali texts. In this paper, we introduce a dataset (NC-SentNoB) that we annotated manually to identify ten different types of noise found in a pre-existing sentiment analysis dataset comprising of around 15K noisy Bengali texts. At first, given an input noisy text, we identify the noise type, addressing this as a multi-label classification task. Then, we introduce baseline noise reduction methods to alleviate noise prior to conducting sentiment analysis. Finally, we assess the performance of fine-tuned sentiment analysis models with both noisy and noise-reduced texts to make comparisons. The experimental findings indicate that the noise reduction methods utilized are not satisfactory, highlighting the need for more suitable noise reductio
    
[^5]: 推理的拓扑学：揭秘思维链、树和图

    Topologies of Reasoning: Demystifying Chains, Trees, and Graphs of Thoughts. (arXiv:2401.14295v1 [cs.CL])

    [http://arxiv.org/abs/2401.14295](http://arxiv.org/abs/2401.14295)

    这篇论文探讨了结合结构的提示工程在提高大型语言模型推理性能方面的前景，通过思维链、思维树或思维图的设计来引导整体推理过程。通过大量实例，这种范式显著增强了模型在多个任务中的能力。总的来说，论文提供了一个通用蓝图，为未来的发展铺平道路。

    

    自然语言处理（NLP）领域近年来取得了显著进展，特别是在通过创新的提示技术提高大型语言模型（LLM）性能方面。其中，与结构相结合的提示工程被视为一种有前途的范式，其设计如思维链、思维树或思维图等，通过结构指导整体LLM推理过程。通过大量实例的说明，这种范式显著增强了LLM在逻辑或数学推理、规划或创造性写作等各种任务中的能力。为了方便理解这个不断发展的领域并为未来的发展铺平道路，我们设计了一个有效和高效的LLM推理方案的通用蓝图。为此，我们对提示执行流程进行了深入分析，澄清并明确定义了不同的概念。然后我们建立第一个分类系统

    The field of natural language processing (NLP) has witnessed significant progress in recent years, with a notable focus on improving large language models' (LLM) performance through innovative prompting techniques. Among these, prompt engineering coupled with structures has emerged as a promising paradigm, with designs such as Chain-of-Thought, Tree of Thoughts, or Graph of Thoughts, in which the overall LLM reasoning is guided by a structure such as a graph. As illustrated with numerous examples, this paradigm significantly enhances the LLM's capability to solve numerous tasks, ranging from logical or mathematical reasoning to planning or creative writing. To facilitate the understanding of this growing field and pave the way for future developments, we devise a general blueprint for effective and efficient LLM reasoning schemes. For this, we conduct an in-depth analysis of the prompt execution pipeline, clarifying and clearly defining different concepts. We then build the first taxon
    
[^6]: RomanSetu: 通过罗马化有效地利用大语言模型的多语言能力

    RomanSetu: Efficiently unlocking multilingual capabilities of Large Language Models models via Romanization. (arXiv:2401.14280v1 [cs.CL])

    [http://arxiv.org/abs/2401.14280](http://arxiv.org/abs/2401.14280)

    本研究提出了一种创新的方法，通过使用罗马化形式的文本作为接口，有效地利用大语言模型的多语言能力。通过在印地语上的实验证明，罗马化文本不仅提高了推理效率，还在有限的预训练下实现了有竞争力的性能。这些发现表明罗马化有潜力弥合大语言模型应用中的语言障碍。

    

    本研究解决了将大型语言模型扩展到非英语语言（特别是使用非拉丁字母表的语言）的挑战。我们提出了一种创新的方法，利用罗马化形式的文本作为大语言模型的接口，假设频繁的非正式使用和与英语共享的标记有助于跨语言对齐。我们以印地语为重点，通过印地语到英语的翻译和情感分析任务，证明罗马化文本不仅由于其较低的生产力而显著改善了推理效率，还在有限的预训练中实现了有竞争力的性能。此外，我们的新颖的多脚本提示方法结合了罗马化和原生文本，在进一步提高任务性能方面显示出潜力。这些发现表明罗马化在弥合大语言模型应用中的语言障碍方面具有潜力，未来的工作将致力于将此方法扩展到更多的语言和任务。

    This study addresses the challenge of extending Large Language Models (LLMs) to non-English languages, specifically those using non-Latin scripts. We propose an innovative approach that utilizes the romanized form of text as an interface for LLMs, hypothesizing that its frequent informal use and shared tokens with English enhance cross-lingual alignment. Focusing on Hindi, we demonstrate through Hindi-to-English translation and sentiment analysis tasks that romanized text not only significantly improves inference efficiency due to its lower fertility compared to native text but also achieves competitive performance with limited pre-training. Additionally, our novel multi-script prompting approach, which combines romanized and native texts, shows promise in further enhancing task performance. These findings suggest the potential of romanization in bridging the language gap for LLM applications, with future work aimed at expanding this approach to more languages and tasks.
    
[^7]: Transformers和大脑皮层波：在时间上传递上下文的编码器

    Transformers and Cortical Waves: Encoders for Pulling In Context Across Time. (arXiv:2401.14267v1 [cs.CL])

    [http://arxiv.org/abs/2401.14267](http://arxiv.org/abs/2401.14267)

    这项研究探讨了transformer网络和大脑皮层波之间的相似性，并指出了皮层波在提取感觉输入序列中的时间上下文方面的潜在应用。

    

    类似ChatGPT和其他大语言模型（LLM）的transformer网络的能力已经引起了世界的关注。它们的性能依赖于将完整的输入序列（例如句子中的所有单词）转化为一个长的“编码向量”，使得transformer能够学习自然序列中的长程时间依赖关系。具体而言，“自注意力”应用于这个编码向量，通过计算输入序列中单词对之间的关联，增强了transformer中的时间上下文。我们认为神经活动在单个皮层区域内或整个大脑范围内传播的波可以实现类似的编码原理。通过在每个时刻将最近的输入历史封装为单个空间模式，皮层波可以从感觉输入序列中提取时间上下文，这与计算原理相同。

    The capabilities of transformer networks such as ChatGPT and other Large Language Models (LLMs) have captured the world's attention. The crucial computational mechanism underlying their performance relies on transforming a complete input sequence - for example, all the words in a sentence into a long "encoding vector" - that allows transformers to learn long-range temporal dependencies in naturalistic sequences. Specifically, "self-attention" applied to this encoding vector enhances temporal context in transformers by computing associations between pairs of words in the input sequence. We suggest that waves of neural activity, traveling across single cortical regions or across multiple regions at the whole-brain scale, could implement a similar encoding principle. By encapsulating recent input history into a single spatial pattern at each moment in time, cortical waves may enable temporal context to be extracted from sequences of sensory inputs, the same computational principle used in
    
[^8]: 提升代码大型语言模型的自然语言能力

    Improving Natural Language Capability of Code Large Language Model. (arXiv:2401.14242v1 [cs.CL])

    [http://arxiv.org/abs/2401.14242](http://arxiv.org/abs/2401.14242)

    该论文提出了一个新颖框架，通过融合传统自然语言处理工具和代码大型语言模型，提升了代码大型语言模型的自然语言能力。研究者提出了两个模块，AttentionExtractor用于提取关键短语，AttentionCoder利用这些短语生成目标代码。实验结果表明该框架的有效性。

    

    代码大型语言模型（Code LLMs）表现出色，在代码生成方面取得了显著成绩。然而，现有的大部分工作都集中在提升代码LLMs的编程能力方面，而对其自然语言能力关注较少。为了填补这一空白，我们提出了一个新颖的框架，包括两个模块：AttentionExtractor，负责从用户的自然语言需求中提取关键短语，和AttentionCoder，利用这些提取出的短语生成目标代码来解决需求。该框架通过无缝融合传统自然语言处理工具与代码LLMs开创了一种创新的思路。为了验证该框架的有效性，我们创建了一个新的代码生成基准测试，名为MultiNL-H，涵盖了五种自然语言。广泛的实验结果证明了我们提出的框架的有效性。

    Code large language models (Code LLMs) have demonstrated remarkable performance in code generation. Nonetheless, most existing works focus on boosting code LLMs from the perspective of programming capabilities, while their natural language capabilities receive less attention. To fill this gap, we thus propose a novel framework, comprising two modules: AttentionExtractor, which is responsible for extracting key phrases from the user's natural language requirements, and AttentionCoder, which leverages these extracted phrases to generate target code to solve the requirement. This framework pioneers an innovative idea by seamlessly integrating code LLMs with traditional natural language processing tools. To validate the effectiveness of the framework, we craft a new code generation benchmark, called MultiNL-H, covering five natural languages. Extensive experimental results demonstrate the effectiveness of our proposed framework.
    
[^9]: 基于Reddit文本增强标注技术和细调Longformer模型的英语和卢干达抑郁症严重程度分类研究

    Enhanced Labeling Technique for Reddit Text and Fine-Tuned Longformer Models for Classifying Depression Severity in English and Luganda. (arXiv:2401.14240v1 [cs.CL])

    [http://arxiv.org/abs/2401.14240](http://arxiv.org/abs/2401.14240)

    本研究通过提出的标注方法对Reddit文本进行分类，并细调了Longformer模型，研究结果表明该模型在英语和卢干达语的抑郁症严重程度分类中表现出色，优于基准模型。

    

    抑郁症是全球负担重的、难以控制的心理健康问题之一。专家们可以使用贝克抑郁量表（BDI）问卷早期检测其严重程度，给患者施用适当药物，阻止其进展。由于担心可能的污名化，许多患者转向Reddit等社交媒体平台寻求建议和帮助。本研究从Reddit提取文本以促进诊断过程。它采用了一种提出的标注方法对文本进行分类，并随后对Longformer模型进行了细调。将该模型与基准模型进行了比较，包括朴素贝叶斯、随机森林、支持向量机和梯度提升。我们的研究结果显示，Longformer模型在英语（48%）和卢干达语（45%）的自定义数据集上优于基准模型。

    Depression is a global burden and one of the most challenging mental health conditions to control. Experts can detect its severity early using the Beck Depression Inventory (BDI) questionnaire, administer appropriate medication to patients, and impede its progression. Due to the fear of potential stigmatization, many patients turn to social media platforms like Reddit for advice and assistance at various stages of their journey. This research extracts text from Reddit to facilitate the diagnostic process. It employs a proposed labeling approach to categorize the text and subsequently fine-tunes the Longformer model. The model's performance is compared against baseline models, including Naive Bayes, Random Forest, Support Vector Machines, and Gradient Boosting. Our findings reveal that the Longformer model outperforms the baseline models in both English (48%) and Luganda (45%) languages on a custom-made dataset.
    
[^10]: 评估通过参数高效微调方法训练的参数矩阵的可移植性

    Assessing the Portability of Parameter Matrices Trained by Parameter-Efficient Finetuning Methods. (arXiv:2401.14228v1 [cs.CL])

    [http://arxiv.org/abs/2401.14228](http://arxiv.org/abs/2401.14228)

    本文研究了通过参数高效微调方法训练的模块的可移植性，发现这些移植的模块在各种情景下表现出优异的性能，可以有效地重复利用任务特定知识。

    

    随着训练规模越来越大的语言模型的成本增加，对重复利用先前学到的知识的兴趣也在增加。迁移学习方法表明，重复利用非任务特定知识可以帮助后续特定任务学习。本文研究了相反的情况：将从一个模型移植编码任务特定知识的完整功能模块到另一个模型。我们设计了一项包括1,440个训练/测试运行的研究，以测试通过参数高效微调(PEFT)技术训练的模块的可移植性，以情感分析为示例任务。我们在各种场景中测试了可移植性，涉及不同的PEFT技术和不同的预训练主机模型，等等。我们将移植的模块的性能与(i)从头开始训练的相等模块的性能和(ii)从与移植的模块相同分布的参数中采样训练的模块进行比较。我们发现，移植的模块的性能远远超过所测试的两种替代方案的性能，但需注意一些局限性。

    As the cost of training ever larger language models has grown, so has the interest in reusing previously learnt knowledge. Transfer learning methods have shown how reusing non-task-specific knowledge can help in subsequent task-specific learning. In this paper, we investigate the inverse: porting whole functional modules that encode task-specific knowledge from one model to another. We designed a study comprising 1,440 training/testing runs to test the portability of modules trained by parameter-efficient finetuning (PEFT) techniques, using sentiment analysis as an example task. We test portability in a wide range of scenarios, involving different PEFT techniques and different pretrained host models, among other dimensions. We compare the performance of ported modules with that of equivalent modules trained (i) from scratch, and (ii) from parameters sampled from the same distribution as the ported module. We find that the ported modules far outperform the two alternatives tested, but t
    
[^11]: 通过上下文感知个性化细化，增强长期对话中的常识增强性内存构建和管理

    Commonsense-augmented Memory Construction and Management in Long-term Conversations via Context-aware Persona Refinement. (arXiv:2401.14215v1 [cs.CL])

    [http://arxiv.org/abs/2401.14215](http://arxiv.org/abs/2401.14215)

    本文提出了一个旨在解决长期对话中角色句子不具信息性的问题的框架，通过利用常识增强的角色扩展，并设计策略将相互矛盾的角色转化为包含丰富说话者信息的句子，以提高回应生成质量。

    

    在长期对话中，记忆和利用说话者的角色是生成回应的常见做法。然而，人工编写的数据集通常提供无信息的角色句子，这妨碍了回应质量。本文提出了一个新颖的框架，利用常识增强的角色扩展来解决长期对话中的这些问题。以前的工作侧重于不产生与其他角色相矛盾的角色，我们侧重于根据设计的策略，将相互矛盾的角色转化为包含丰富说话者信息的句子，以此来细化它们的上下文背景。作为多会话情境中角色扩展的先驱，我们的框架通过类人个性细化促进了更好的回应生成。

    Memorizing and utilizing speakers' personas is a common practice for response generation in long-term conversations. Yet, human-authored datasets often provide uninformative persona sentences that hinder response quality. This paper presents a novel framework that leverages commonsense-based persona expansion to address such issues in long-term conversation. While prior work focuses on not producing personas that contradict others, we focus on transforming contradictory personas into sentences that contain rich speaker information, by refining them based on their contextual backgrounds with designed strategies. As the pioneer of persona expansion in multi-session settings, our framework facilitates better response generation via human-like persona refinement. The supplementary video of our work is available at https://caffeine-15bbf.web.app/.
    
[^12]: 显式表示语法改进了意外情况下的句子到布局预测

    Explicitly Representing Syntax Improves Sentence-to-layout Prediction of Unexpected Situations. (arXiv:2401.14212v1 [cs.CL])

    [http://arxiv.org/abs/2401.14212](http://arxiv.org/abs/2401.14212)

    本文研究了句子到布局预测任务中的语法表示对模型性能的影响。实验结果显示，显式表示语法增强了模型对意外情况的预测能力，但对于未在训练集中出现的句子结构仍存在困难。

    

    在自然语言句子中识别视觉实体并将它们排列在二维空间布局中，需要对语言和空间的组合理解。布局预测任务在文本到图像合成中非常有价值，因为它允许对图像进行局部和受控的修复。通过比较性研究表明，我们可以从隐式或显式编码句子语法的语言表示中预测布局，如果句子提到的实体关系与训练中看到的类似。为了测试组合理解能力，我们收集了一个由语法正确的句子和布局组成的测试集，描述了训练过程中可能未曾见过的实体和关系组合。在这个测试集上的性能显著下降，表明当前模型依赖于训练数据中的相关性，并且在理解输入句子的结构方面存在困难。我们提出了一种新的结构损失函数，更好地强化了句子结构。

    Recognizing visual entities in a natural language sentence and arranging them in a 2D spatial layout require a compositional understanding of language and space. This task of layout prediction is valuable in text-to-image synthesis as it allows localized and controlled in-painting of the image. In this comparative study it is shown that we can predict layouts from language representations that implicitly or explicitly encode sentence syntax, if the sentences mention similar entity-relationships to the ones seen during training. To test compositional understanding, we collect a test set of grammatically correct sentences and layouts describing compositions of entities and relations that unlikely have been seen during training. Performance on this test set substantially drops, showing that current models rely on correlations in the training data and have difficulties in understanding the structure of the input sentences. We propose a novel structural loss function that better enforces th
    
[^13]: DeepSeek-Coder: 在大型语言模型与编程相遇的时候--代码智能的崛起

    DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence. (arXiv:2401.14196v1 [cs.SE])

    [http://arxiv.org/abs/2401.14196](http://arxiv.org/abs/2401.14196)

    DeepSeek-Coder是一系列开源代码模型，通过在高质量项目级代码语料库上进行预训练和采用填空任务和16K窗口来增强代码生成和填充，不仅在多个基准测试中取得了与开源代码模型同样的最新表现，而且超过了现有的闭源模型。

    

    大型语言模型的快速发展为软件开发中的代码智能带来了革命。然而，闭源模型的主导地位限制了广泛的研究和开发。为了解决这个问题，我们介绍了DeepSeek-Coder系列，这是一系列开源代码模型，大小从1.3B到33B，从头开始在2万亿个标记上进行训练。这些模型在高质量项目级代码语料库上进行了预训练，并采用填空任务和16K窗口来增强代码生成和填充。我们广泛的评估表明，DeepSeek-Coder不仅在多个基准测试中取得了与开源代码模型同样的最新表现，而且超过了现有的Codex和GPT-3.5等闭源模型。此外，DeepSeek-Coder模型采用了宽松的许可证，既允许研究，也允许无限制的商业使用。

    The rapid development of large language models has revolutionized code intelligence in software development. However, the predominance of closed-source models has restricted extensive research and development. To address this, we introduce the DeepSeek-Coder series, a range of open-source code models with sizes from 1.3B to 33B, trained from scratch on 2 trillion tokens. These models are pre-trained on a high-quality project-level code corpus and employ a fill-in-the-blank task with a 16K window to enhance code generation and infilling. Our extensive evaluations demonstrate that DeepSeek-Coder not only achieves state-of-the-art performance among open-source code models across multiple benchmarks but also surpasses existing closed-source models like Codex and GPT-3.5. Furthermore, DeepSeek-Coder models are under a permissive license that allows for both research and unrestricted commercial use.
    
[^14]: 作为一种语言处理任务的参数高效的对话推荐系统

    Parameter-Efficient Conversational Recommender System as a Language Processing Task. (arXiv:2401.14194v1 [cs.CL])

    [http://arxiv.org/abs/2401.14194](http://arxiv.org/abs/2401.14194)

    本文将对话推荐系统作为一种语言处理任务进行建模，利用预训练的语言模型来编码项目、理解用户意图，通过语义匹配进行项目推荐，并生成对话。实验证明了该方法的有效性。

    

    对话式推荐系统旨在通过自然语言对话来向用户推荐相关的项目。之前的工作通常利用外部知识图谱来提供项目的语义信息，利用语言模型进行对话生成，以及利用推荐模块进行相关项目的排序。这种多组件的组合导致训练过程繁琐，并且导致对话生成和项目推荐之间的语义不配对问题。在本文中，我们使用自然语言表示项目，并将对话式推荐系统作为一种自然语言处理任务进行建模。因此，我们利用预训练的语言模型来编码项目，在对话中理解用户意图，通过语义匹配进行项目推荐，并生成对话。作为一个统一的模型，我们的PECRS（参数高效的对话推荐系统）可以在单个阶段进行优化，而不依赖非文本元数据，如知识图谱。实验证明了我们方法的有效性。

    Conversational recommender systems (CRS) aim to recommend relevant items to users by eliciting user preference through natural language conversation. Prior work often utilizes external knowledge graphs for items' semantic information, a language model for dialogue generation, and a recommendation module for ranking relevant items. This combination of multiple components suffers from a cumbersome training process, and leads to semantic misalignment issues between dialogue generation and item recommendation. In this paper, we represent items in natural language and formulate CRS as a natural language processing task. Accordingly, we leverage the power of pre-trained language models to encode items, understand user intent via conversation, perform item recommendation through semantic matching, and generate dialogues. As a unified model, our PECRS (Parameter-Efficient CRS), can be optimized in a single stage, without relying on non-textual metadata such as a knowledge graph. Experiments on
    
[^15]: 如何让大型语言模型理解时空数据？

    How Can Large Language Models Understand Spatial-Temporal Data?. (arXiv:2401.14192v1 [cs.LG])

    [http://arxiv.org/abs/2401.14192](http://arxiv.org/abs/2401.14192)

    本文提出了一种名为STG-LLM的创新方法，用于使大型语言模型能够理解时空数据并进行预测。该方法利用STG-Tokenizer将复杂的图形数据转化为简洁的标记，再通过STG-Adapter将标记化数据与LLM的理解能力进行连接。通过微调参数，STG-LLM能够有效地把握标记的语义，同时保留LLM的自然语言理解能力。通过广泛的实验验证了STG-LLM的优越性能。

    

    尽管大型语言模型（LLM）在自然语言处理和计算机视觉等任务中占据主导地位，但利用它们的能力进行时空预测仍然具有挑战性。时序文本与复杂的时空数据之间的差异阻碍了该应用的实现。为了解决这个问题，本文提出了STG-LLM，一种创新的方法，为LLM赋予了时空预测的能力。我们通过以下方式解决数据不匹配的问题：1）STG-Tokenizer：这个时空图形标记器将复杂的图形数据转化为简洁的标记，捕捉了空间和时间关系；2）STG-Adapter：这个精简的适配器由线性编码和解码层组成，填补了标记化数据和LLM理解之间的差距。通过仅微调一小部分参数，它可以有效地把握STG-Tokenizer生成的标记的语义，同时保留LLM的原始自然语言理解能力。通过在多种数据集上进行广泛实验，我们验证了STG-LLM的优越性能。

    While Large Language Models (LLMs) dominate tasks like natural language processing and computer vision, harnessing their power for spatial-temporal forecasting remains challenging. The disparity between sequential text and complex spatial-temporal data hinders this application. To address this issue, this paper introduces STG-LLM, an innovative approach empowering LLMs for spatial-temporal forecasting. We tackle the data mismatch by proposing: 1) STG-Tokenizer: This spatial-temporal graph tokenizer transforms intricate graph data into concise tokens capturing both spatial and temporal relationships; 2) STG-Adapter: This minimalistic adapter, consisting of linear encoding and decoding layers, bridges the gap between tokenized data and LLM comprehension. By fine-tuning only a small set of parameters, it can effectively grasp the semantics of tokens generated by STG-Tokenizer, while preserving the original natural language understanding capabilities of LLMs. Extensive experiments on diver
    
[^16]: BayesPrompt: 通过无偏领域抽象在少样本推理上指导大规模预训练语言模型

    BayesPrompt: Prompting Large-Scale Pre-Trained Language Models on Few-shot Inference via Debiased Domain Abstraction. (arXiv:2401.14166v1 [cs.CL])

    [http://arxiv.org/abs/2401.14166](http://arxiv.org/abs/2401.14166)

    BayesPrompt通过无偏领域抽象解决大规模预训练语言模型在少样本推理中的泛化问题。

    

    作为一种基于大规模预训练语言模型（PLMs）的新颖有效的微调范式，prompt-tuning旨在缩小下游任务与预训练目标之间的差距。虽然prompt-tuning在各种任务中取得了持续进展，但这种方法仍然存在一个持久的缺陷：prompt-tuning方法无法泛化到特定的少样本模式。从分布分析的角度来看，我们揭示了这一现象背后的内在问题是PLMs中包含过多的概念知识和目标下游领域的缩减知识，两者共同导致PLMs在普遍的知识嵌入空间中错误地定位与目标领域相对应的知识分布。为此，我们直观地探索了以无偏方式逼近下游任务的完整目标领域，并通过抽象这样的领域生成有区别的提示，从而提供了无歧义的信息。

    As a novel and effective fine-tuning paradigm based on large-scale pre-trained language models (PLMs), prompt-tuning aims to reduce the gap between downstream tasks and pre-training objectives. While prompt-tuning has yielded continuous advancements in various tasks, such an approach still remains a persistent defect: prompt-tuning methods fail to generalize to specific few-shot patterns. From the perspective of distribution analyses, we disclose that the intrinsic issues behind the phenomenon are the over-multitudinous conceptual knowledge contained in PLMs and the abridged knowledge for target downstream domains, which jointly result in that PLMs mis-locate the knowledge distributions corresponding to the target domains in the universal knowledge embedding space. To this end, we intuitively explore to approximate the unabridged target domains of downstream tasks in a debiased manner, and then abstract such domains to generate discriminative prompts, thereby providing the de-ambiguous
    
[^17]: 真知来源于实践：通过强化学习使LLMs与具身环境对齐的方法研究

    True Knowledge Comes from Practice: Aligning LLMs with Embodied Environments via Reinforcement Learning. (arXiv:2401.14151v1 [cs.LG])

    [http://arxiv.org/abs/2401.14151](http://arxiv.org/abs/2401.14151)

    本研究通过使用大型语言模型（LLMs）作为决策智能体，通过强化学习与具身环境高效互动来解决LLMs与环境之间知识不对齐的问题。通过查询LLMs的联合概率，形成行为策略，并通过两种归一化方法和四个提示设计原则提高策略的稳定性和鲁棒性。最后，通过设计参数高效的训练架构提高学习效率。

    

    尽管在众多任务中取得了令人印象深刻的表现，但大型语言模型（LLMs）在解决简单的决策任务上经常失败，原因是LLMs中的知识与环境不对齐。相反，强化学习（RL）智能体从零开始学习策略，这使得它们始终与环境保持一致，但难以将先前的知识整合到其中以进行有效的探索。为了缩小这一差距，我们提出了TWOSOME，一种新颖的在线框架，利用LLMs作为决策智能体，通过RL与具身环境高效互动并实现对齐，而无需任何准备好的数据集或环境的先前知识。首先，我们使用LLMs查询每个有效动作的联合概率以形成行为策略。然后，为了增强策略的稳定性和鲁棒性，我们提出了两种归一化方法，并总结了四个提示设计原则。最后，我们设计了一种新颖的参数高效的训练架构，其中包括一个行为评估和选择算法来提高学习效率。

    Despite the impressive performance across numerous tasks, large language models (LLMs) often fail in solving simple decision-making tasks due to the misalignment of the knowledge in LLMs with environments. On the contrary, reinforcement learning (RL) agents learn policies from scratch, which makes them always align with environments but difficult to incorporate prior knowledge for efficient explorations. To narrow the gap, we propose TWOSOME, a novel general online framework that deploys LLMs as decision-making agents to efficiently interact and align with embodied environments via RL without requiring any prepared datasets or prior knowledge of the environments. Firstly, we query the joint probabilities of each valid action with LLMs to form behavior policies. Then, to enhance the stability and robustness of the policies, we propose two normalization methods and summarize four prompt design principles. Finally, we design a novel parameter-efficient training architecture where the acto
    
[^18]: 卷积神经网络可以实现二元保释判断分类

    Convolutional Neural Networks can achieve binary bail judgement classification. (arXiv:2401.14135v1 [cs.CL])

    [http://arxiv.org/abs/2401.14135](http://arxiv.org/abs/2401.14135)

    本文研究使用卷积神经网络在印度印地文法律文件上进行二元保释判断分类，取得了93％的准确率，改进了之前的准确率基准。

    

    印度法律领域中缺乏机器学习（ML）的实施，该领域的任何研究通常是基于英语数据和高等法院的数据。忽略了印度低级法院和不同地区语言的数据。本文在一组印地文法律文件上部署了卷积神经网络（CNN）架构。我们使用CNN模型进行保释预测任务，取得了93％的总体准确率，这是对印度北方邦20个地区数据的Kapoor等人（2022）设定的准确率基准的改进。

    There is an evident lack of implementation of Machine Learning (ML) in the legal domain in India, and any research that does take place in this domain is usually based on data from the higher courts of law and works with English data. The lower courts and data from the different regional languages of India are often overlooked. In this paper, we deploy a Convolutional Neural Network (CNN) architecture on a corpus of Hindi legal documents. We perform a bail Prediction task with the help of a CNN model and achieve an overall accuracy of 93\% which is an improvement on the benchmark accuracy, set by Kapoor et al. (2022), albeit in data from 20 districts of the Indian state of Uttar Pradesh.
    
[^19]: 关于层次主题建模的亲和性、合理性和多样性的研究

    On the Affinity, Rationality, and Diversity of Hierarchical Topic Modeling. (arXiv:2401.14113v1 [cs.CL])

    [http://arxiv.org/abs/2401.14113](http://arxiv.org/abs/2401.14113)

    本论文提出了一种名为TraCo的新层次主题模型，通过传输计划依赖方法和上下文感知的解缠码器，改善了主题层次结构的亲和性、合理性和多样性。

    

    层次主题建模旨在从语料库中发现潜在主题，并将它们组织成一个层次结构，以便理解具有期望语义粒度的文档。然而，现有工作在产生低亲和性、合理性和多样性的主题层次方面存在困难，这阻碍了文档的理解。为了克服这些挑战，本文提出了传输计划和上下文感知的层次主题模型（TraCo）。我们提出了一种传输计划依赖方法，而不是之前简单的主题依赖方法。它限制依赖关系以确保它们的稀疏性和平衡性，并通过它们对主题层次结构进行正则化。这改善了层次结构的亲和性和多样性。我们还提出了一种上下文感知的解缠码器。它通过解缠编码将不同的语义粒度分配给不同层次的主题，从而有助于层次结构的合理性。在基准数据集上的实验证明了我们方法的有效性。

    Hierarchical topic modeling aims to discover latent topics from a corpus and organize them into a hierarchy to understand documents with desirable semantic granularity. However, existing work struggles with producing topic hierarchies of low affinity, rationality, and diversity, which hampers document understanding. To overcome these challenges, we in this paper propose Transport Plan and Context-aware Hierarchical Topic Model (TraCo). Instead of early simple topic dependencies, we propose a transport plan dependency method. It constrains dependencies to ensure their sparsity and balance, and also regularizes topic hierarchy building with them. This improves affinity and diversity of hierarchies. We further propose a context-aware disentangled decoder. Rather than previously entangled decoding, it distributes different semantic granularity to topics at different levels by disentangled decoding. This facilitates the rationality of hierarchies. Experiments on benchmark datasets demonstra
    
[^20]: CompactifAI: 使用量子启发的张量网络对大型语言模型进行极压缩

    CompactifAI: Extreme Compression of Large Language Models using Quantum-Inspired Tensor Networks. (arXiv:2401.14109v1 [cs.CL])

    [http://arxiv.org/abs/2401.14109](http://arxiv.org/abs/2401.14109)

    CompactifAI是一种使用量子启发的张量网络对大型语言模型进行极压缩的创新方法，相比于传统的压缩方法，它更注重模型的相关空间，实现更加可控和精细的压缩。

    

    大型语言模型（LLM）如ChatGPT和LlaMA在生成人工智能（AI）方面取得了快速进展，但其庞大的规模带来了重要挑战，如巨大的训练和推断成本、较大的能源需求以及现场部署的限制。传统的压缩方法如剪枝、蒸馏和低秩逼近主要关注减少网络中神经元的有效数量，而量化方法则侧重于降低单个权重的数值精度，以减小模型大小同时保持神经元数目不变。虽然这些压缩方法在实践中取得了相对成功，但没有令人信服的理由认为截断神经元的数量是一种最优策略。本文介绍了一种创新的LLM压缩方法CompactifAI，它使用量子启发的张量网络，而不是传统的压缩方法，更注重模型的相关空间，实现更加可控和精细的压缩。

    Large Language Models (LLMs) such as ChatGPT and LlaMA are advancing rapidly in generative Artificial Intelligence (AI), but their immense size poses significant challenges, such as huge training and inference costs, substantial energy demands, and limitations for on-site deployment. Traditional compression methods such as pruning, distillation, and low-rank approximation focus on reducing the effective number of neurons in the network, while quantization focuses on reducing the numerical precision of individual weights to reduce the model size while keeping the number of neurons fixed. While these compression methods have been relatively successful in practice, there's no compelling reason to believe that truncating the number of neurons is an optimal strategy. In this context, this paper introduces CompactifAI, an innovative LLM compression approach using quantum-inspired Tensor Networks that focuses on the model's correlation space instead, allowing for a more controlled, refined an
    
[^21]: Ta'keed: 首个用于阿拉伯语论断的生成式事实核查系统

    Ta'keed: The First Generative Fact-Checking System for Arabic Claims. (arXiv:2401.14067v1 [cs.CL])

    [http://arxiv.org/abs/2401.14067](http://arxiv.org/abs/2401.14067)

    Ta'keed是首个用于阿拉伯语论断的生成式事实核查系统，通过基于检索片段的论断真实性评估和LLM-based论断验证，解决了目前阿拉伯语领域缺乏生成解释论断可信度的研究。引入了一个测试黄金标签数据集，并分析了系统生成解释与黄金标准解释之间的语义相似性。研究还探讨了不同片段数量对论断分类准确性的影响。

    

    本文介绍了Ta'keed，一个可解释的阿拉伯语自动事实核查系统。现有研究通常将论断分类为“真”或“假”，但对于生成论断可信度的解释尤其在阿拉伯语领域的研究有限。Ta'keed通过基于检索片段的论断真实性评估来填补这一空白，利用信息检索和基于LLM的论断验证两个主要组件。我们编制了ArFactEx，一个带有手工证明参考的测试黄金标签数据集，用于评估该系统。初始模型在分类任务中取得了有希望的0.72的F1得分。与黄金标准解释在句法和语义上进行比较，系统生成的解释得到了推荐的语义相似性评估，平均余弦相似度分数为0.76。此外，我们还探讨了不同片段数量对论断分类准确性的影响，揭示....

    This paper introduces Ta'keed, an explainable Arabic automatic fact-checking system. While existing research often focuses on classifying claims as "True" or "False," there is a limited exploration of generating explanations for claim credibility, particularly in Arabic. Ta'keed addresses this gap by assessing claim truthfulness based on retrieved snippets, utilizing two main components: information retrieval and LLM-based claim verification. We compiled the ArFactEx, a testing gold-labelled dataset with manually justified references, to evaluate the system. The initial model achieved a promising F1 score of 0.72 in the classification task. Meanwhile, the system's generated explanations are compared with gold-standard explanations syntactically and semantically. The study recommends evaluating using semantic similarities, resulting in an average cosine similarity score of 0.76. Additionally, we explored the impact of varying snippet quantities on claim classification accuracy, revealin
    
[^22]: 朝着目标导向的大型语言模型提示方法：一项调查

    Towards Goal-oriented Large Language Model Prompting: A Survey. (arXiv:2401.14043v1 [cs.CL])

    [http://arxiv.org/abs/2401.14043](http://arxiv.org/abs/2401.14043)

    本文调查了大型语言模型(LLM)中目标导向提示工程的重要性。通过对35个代表性研究的回顾，我们发现引导LLM遵循人类的逻辑思维的目标导向提示公式显著提高了LLM的性能。我们还提出了一个新的分类体系，并总结了十个适用任务来展示我们框架的广泛适用性。同时，我们提出了四个未来的方向，以推动目标导向提示工程的进一步发展。

    

    大型语言模型(LLM)在各种下游任务中显示出卓越的性能，而提示工程在优化LLM性能中起着关键作用。本文旨在强调设计提示的限制，同时保持人类追求LLM像人类思考的人类学假设。通过对35个代表性研究的回顾，我们展示了目标导向提示公式的重要性，该公式指导LLM遵循人类的逻辑思维，显著提高了LLM的性能。此外，我们引入了一个新的分类体系，将目标导向提示方法分为五个相互关联的阶段，并通过总结十个适用任务来展示我们框架的广泛适用性。最后，我们提出了四个未来的方向，希望进一步强调和推动目标导向提示工程。

    Large Language Models (LLMs) have shown prominent performance in various downstream tasks in which prompt engineering plays a pivotal role in optimizing LLMs' performance. This paper, not as an overview of current prompt engineering methods, aims to highlight the limitation of designing prompts while holding an anthropomorphic assumption that expects LLMs to think like humans. From our review of 35 representative studies, we demonstrate that a goal-oriented prompt formulation, which guides LLMs to follow established human logical thinking, significantly improves the performance of LLMs. Furthermore, We introduce a novel taxonomy that categorizes goal-oriented prompting methods into five interconnected stages and we demonstrate the broad applicability of our framework by summarizing ten applicable tasks. With four future directions proposed, we hope to further emphasize and promote goal-oriented prompt engineering.
    
[^23]: (聊天)GPT v BERT: 语义变化检测之黎明的正义。(arXiv:2401.14040v1 [cs.CL])

    (Chat)GPT v BERT: Dawn of Justice for Semantic Change Detection. (arXiv:2401.14040v1 [cs.CL])

    [http://arxiv.org/abs/2401.14040](http://arxiv.org/abs/2401.14040)

    本研究探讨了(Chat)GPT和BERT在语义变化检测任务中的性能，结果表明(Chat)GPT的表现明显低于BERT，尤其在长期变化检测方面表现更差。

    

    在自然语言处理领域，基于Transformer的语言模型，如BERT和(Chat)GPT，作为具有解决开放性研究问题的巨大能力的词汇超级英雄而出现。本文特别关注语义变化的时间性问题，并评估它们解决Word-in-Context (WiC)任务的两个历时性扩展：TempoWiC和HistoWiC。特别是，我们研究了ChatGPT（和GPT）3.5这样的新型即用技术与当前作为建模语义变化的最先进模型家族BERT之间的潜力。我们的实验是首次尝试使用(Chat)GPT研究语义变化。我们的结果表明，ChatGPT的性能显著低于基础GPT版本。此外，我们的结果表明，(Chat)GPT在检测长期变化方面的表现略低于BERT，但在短期变化检测方面表现明显更差。

    In the universe of Natural Language Processing, Transformer-based language models like BERT and (Chat)GPT have emerged as lexical superheroes with great power to solve open research problems. In this paper, we specifically focus on the temporal problem of semantic change, and evaluate their ability to solve two diachronic extensions of the Word-in-Context (WiC) task: TempoWiC and HistoWiC. In particular, we investigate the potential of a novel, off-the-shelf technology like ChatGPT (and GPT) 3.5 compared to BERT, which represents a family of models that currently stand as the state-of-the-art for modeling semantic change. Our experiments represent the first attempt to assess the use of (Chat)GPT for studying semantic change. Our results indicate that ChatGPT performs significantly worse than the foundational GPT version. Furthermore, our results demonstrate that (Chat)GPT achieves slightly lower performance than BERT in detecting long-term changes but performs significantly worse in de
    
[^24]: 使用推测加速检索增强型语言模型服务

    Accelerating Retrieval-Augmented Language Model Serving with Speculation. (arXiv:2401.14021v1 [cs.LG])

    [http://arxiv.org/abs/2401.14021](http://arxiv.org/abs/2401.14021)

    提出了RaLMSpec，这是一个使用推测加速检索增强型语言模型服务的框架，通过推测式检索和批量验证提供了通用的加速效果，并通过进一步优化和并发处理，提高了性能。

    

    检索增强型语言模型（RaLM）通过将非参数的知识库与参数化的语言模型相结合，已经展示出解决知识密集型自然语言处理（NLP）任务的潜力。与对完全参数化模型进行微调不同，RaLM在适应最新数据和更好的来源归属机制方面具有低成本的优势。在众多的RaLM方法中，迭代式RaLM由于检索器与语言模型之间更频繁的互动而具有更好的生成质量。尽管有这些好处，迭代式RaLM通常会因为频繁的检索步骤而遇到高开销。为此，我们提出了RaLMSpec，这是一个基于推测的框架，通过推测式检索和批量验证，能够在保持相同模型输出的同时，提供通用加速的效果。通过进一步结合预取、最佳推测步幅调度器和异步验证，RaLMSpec能够自动利用并发性和并行性来最大程度地提高性能。

    Retrieval-augmented language models (RaLM) have demonstrated the potential to solve knowledge-intensive natural language processing (NLP) tasks by combining a non-parametric knowledge base with a parametric language model. Instead of fine-tuning a fully parametric model, RaLM excels at its low-cost adaptation to the latest data and better source attribution mechanisms. Among various RaLM approaches, iterative RaLM delivers a better generation quality due to a more frequent interaction between the retriever and the language model. Despite the benefits, iterative RaLM usually encounters high overheads due to the frequent retrieval step. To this end, we propose RaLMSpec, a speculation-inspired framework that provides generic speed-up over iterative RaLM while preserving the same model outputs through speculative retrieval and batched verification. By further incorporating prefetching, optimal speculation stride scheduler, and asynchronous verification, RaLMSpec can automatically exploit t
    
[^25]: Unitxt：用于生成式人工智能的灵活、可共享和可复用数据准备与评估

    Unitxt: Flexible, Shareable and Reusable Data Preparation and Evaluation for Generative AI. (arXiv:2401.14019v1 [cs.CL])

    [http://arxiv.org/abs/2401.14019](http://arxiv.org/abs/2401.14019)

    Unitxt是一个灵活、可共享和可复用的数据准备与评估库，针对生成式语言模型进行定制，实现了结构化、模块化和可定制的解决方案。该库集成了常用的库，将处理流程分解为模块化组件，促进了协作和共享。

    

    在生成式自然语言处理（NLP）的动态环境中，传统的文本处理流程限制了研究的灵活性和可重现性，因为它们针对特定的数据集、任务和模型组合进行了定制。随着系统提示、模型特定格式、指令等越来越复杂，需要转向一种结构化、模块化和可定制的解决方案。为满足这一需求，我们提出了Unitxt，这是一个创新的库，专为生成式语言模型定制的文本数据准备和评估而设计。Unitxt与HuggingFace和LM-eval-harness等常用库进行了本地集成，并将处理流程分解为模块化组件，实现了易于定制和共享的功能。这些组件包括模型特定格式、任务提示和许多其他全面的数据集处理定义。Unitxt-Catalog集中了这些组件，促进了现代文本数据流程中的协作和探索。

    In the dynamic landscape of generative NLP, traditional text processing pipelines limit research flexibility and reproducibility, as they are tailored to specific dataset, task, and model combinations. The escalating complexity, involving system prompts, model-specific formats, instructions, and more, calls for a shift to a structured, modular, and customizable solution. Addressing this need, we present Unitxt, an innovative library for customizable textual data preparation and evaluation tailored to generative language models. Unitxt natively integrates with common libraries like HuggingFace and LM-eval-harness and deconstructs processing flows into modular components, enabling easy customization and sharing between practitioners. These components encompass model-specific formats, task prompts, and many other comprehensive dataset processing definitions. The Unitxt-Catalog centralizes these components, fostering collaboration and exploration in modern textual data workflows. Beyond be
    
[^26]: 面向不确定性感知的语言智能体

    Towards Uncertainty-Aware Language Agent. (arXiv:2401.14016v1 [cs.CL])

    [http://arxiv.org/abs/2401.14016](http://arxiv.org/abs/2401.14016)

    UALA是一个使用不确定性量化来进行代理和外部世界交互的框架，相比于其他方法，它在多个任务和语言模型尺寸下表现出显著的性能改进，并且在对外部世界的依赖性方面更低。

    

    虽然语言智能体通过将大型语言模型置于更多功能的设计核心以及与外部世界的动态交互中取得了令人期待的成功，但现有方法在这些交互过程中忽视了不确定性的概念。我们提出了一种称为不确定性感知的语言智能体（UALA）的框架，该框架使用不确定性量化来编排代理和外部世界之间的交互。与其他知名对手（如ReAct）相比，我们在3个代表性任务（HotpotQA，StrategyQA，MMLU）和各种LLM尺寸上进行了广泛的实验，结果表明UALA在性能方面有显著的改进，同时对外部世界的依赖性显著降低（即，减少了工具调用和标记数）。我们的分析提供了各种见解，包括与代理微调相比，UALA的巨大潜力，并强调在语言模型的口头置信度作为不确定性的代理时的不可靠性。

    While Language Agents have achieved promising success by placing Large Language Models at the core of a more versatile design that dynamically interacts with the external world, the existing approaches neglect the notion of uncertainty during these interactions. We present the Uncertainty-Aware Language Agent (UALA), a framework that orchestrates the interaction between the agent and the external world using uncertainty quantification. Compared with other well-known counterparts like ReAct, our extensive experiments across 3 representative tasks (HotpotQA, StrategyQA, MMLU) and various LLM sizes demonstrates that UALA brings a significant improvement of performance, while having a substantially lower reliance on the external world (i.e., reduced number of tool calls and tokens). Our analyses provide various insights including the great potential of UALA compared with agent fine-tuning, and underscoring the unreliably of verbalised confidence of LLMs as a proxy for uncertainty.
    
[^27]: CMMU: 一个用于中文多模态多类型问题理解与推理的基准测试

    CMMU: A Benchmark for Chinese Multi-modal Multi-type Question Understanding and Reasoning. (arXiv:2401.14011v1 [cs.CL])

    [http://arxiv.org/abs/2401.14011](http://arxiv.org/abs/2401.14011)

    CMMU是一个用于中文多模态多类型问题理解和推理的基准测试，涵盖了从小学到高中的知识，提供了多项选择题、多项回答题和填空题三种类型的问题，对于评估多模态大型语言模型的智能水平具有重要意义。

    

    多模态大型语言模型（MLLMs）已经取得了显著的进展，并展现出强大的知识理解和推理能力。然而，评估MLLM的智能水平所需的领域特定知识掌握仍然是一个挑战。当前用于领域特定知识的多模态基准测试主要集中在英语多项选择题上，并且在评估的全面性方面存在局限性。为此，我们引入了CMMU，一个用于中文多模态多类型问题理解和推理的新型基准测试。CMMU包含7个学科的3603个问题，涵盖了从小学到高中的知识。这些问题可以分为多项选择题、多项回答题和填空题三类，对MLLMs提出更大的挑战。此外，我们提出了一种严格的评估策略，称为ShiftCheck，用于评估多项选择题。

    Multi-modal large language models(MLLMs) have achieved remarkable progress and demonstrated powerful knowledge comprehension and reasoning abilities. However, the mastery of domain-specific knowledge, which is essential for evaluating the intelligence of MLLMs, continues to be a challenge. Current multi-modal benchmarks for domain-specific knowledge concentrate on multiple-choice questions and are predominantly available in English, which imposes limitations on the comprehensiveness of the evaluation. To this end, we introduce CMMU, a novel benchmark for multi-modal and multi-type question understanding and reasoning in Chinese. CMMU consists of 3,603 questions in 7 subjects, covering knowledge from primary to high school. The questions can be categorized into 3 types: multiple-choice, multiple-response, and fill-in-the-blank, bringing greater challenges to MLLMs. In addition, we propose a rigorous evaluation strategy called ShiftCheck for assessing multiple-choice questions. The strat
    
[^28]: ConstraintChecker：用于大型语言模型推理常识知识库的插件

    ConstraintChecker: A Plugin for Large Language Models to Reason on Commonsense Knowledge Bases. (arXiv:2401.14003v1 [cs.CL])

    [http://arxiv.org/abs/2401.14003](http://arxiv.org/abs/2401.14003)

    ConstraintChecker是一个针对大型语言模型的插件，用于推理常识知识库。它通过提示技术提供和检查显式约束，帮助解决了大型语言模型在处理常识知识库推理时的困难。

    

    基于常识知识库的推理（即常识知识库推理）已被探索作为一种通过原始常识知识库和外部先验知识来获取新的常识知识的方法。尽管大型语言模型（LLM）和提示工程技术在各种推理任务中取得了进展，但它们仍然难以处理常识知识库推理。其中一个问题是，它们很难只通过上下文示例从常识知识库中获取显式关系约束，这是因为缺乏符号推理能力（Bengio等人，2021年）。为此，我们提出了一种名为ConstraintChecker的插件，它基于提示技术提供和检查显式约束。在考虑新的知识实例时，ConstraintChecker使用基于规则的模块生成约束列表，然后使用零样本学习模块检查该知识实例是否满足所有约束。然后，获取的约束检查结果被聚合...

    Reasoning over Commonsense Knowledge Bases (CSKB), i.e. CSKB reasoning, has been explored as a way to acquire new commonsense knowledge based on reference knowledge in the original CSKBs and external prior knowledge. Despite the advancement of Large Language Models (LLM) and prompt engineering techniques in various reasoning tasks, they still struggle to deal with CSKB reasoning. One of the problems is that it is hard for them to acquire explicit relational constraints in CSKBs from only in-context exemplars, due to a lack of symbolic reasoning capabilities (Bengio et al., 2021). To this end, we proposed **ConstraintChecker**, a plugin over prompting techniques to provide and check explicit constraints. When considering a new knowledge instance, ConstraintChecker employs a rule-based module to produce a list of constraints, then it uses a zero-shot learning module to check whether this knowledge instance satisfies all constraints. The acquired constraint-checking result is then aggrega
    
[^29]: 调查-整合-开发：一种用于任务间代理自进化的通用策略

    Investigate-Consolidate-Exploit: A General Strategy for Inter-Task Agent Self-Evolution. (arXiv:2401.13996v1 [cs.CL])

    [http://arxiv.org/abs/2401.13996](http://arxiv.org/abs/2401.13996)

    本文介绍了调查-整合-开发（ICE）策略，通过任务间的自进化来提高AI代理的适应性和灵活性。实验证明了ICE的有效性，可以显著减少API调用，同时与GPT-3.5结合使用可以在各种代理任务上达到与GPT-4相当的性能。

    

    本文介绍了一种名为调查-整合-开发（ICE）的新策略，通过任务间的自进化来提高AI代理的适应性和灵活性。与现有的注重任务内学习的方法不同，ICE促进了任务间知识的传递，实现了真正的自进化，类似于人类的经验学习。该策略动态地调查规划和执行轨迹，将其整合为简化的工作流和管道，并利用它们来改进任务执行。我们在XAgent框架上的实验证明了ICE的有效性，可以将API调用减少高达80％，并显著减少模型能力的需求。具体来说，当与GPT-3.5结合使用时，ICE的性能在各种代理任务上与原始GPT-4相匹配。我们认为这种自进化方法代表了代理设计的范式转变，为更强大的AI社区和生态系统做出了贡献，并向全面实现人工智能跨进了一步。

    This paper introduces Investigate-Consolidate-Exploit (ICE), a novel strategy for enhancing the adaptability and flexibility of AI agents through inter-task self-evolution. Unlike existing methods focused on intra-task learning, ICE promotes the transfer of knowledge between tasks for genuine self-evolution, similar to human experience learning. The strategy dynamically investigates planning and execution trajectories, consolidates them into simplified workflows and pipelines, and exploits them for improved task execution. Our experiments on the XAgent framework demonstrate ICE's effectiveness, reducing API calls by as much as 80% and significantly decreasing the demand for the model's capability. Specifically, when combined with GPT-3.5, ICE's performance matches that of raw GPT-4 across various agent tasks. We argue that this self-evolution approach represents a paradigm shift in agent design, contributing to a more robust AI community and ecosystem, and moving a step closer to full 
    
[^30]: 通过解释一致性微调实现一致的自然语言解释

    Towards Consistent Natural-Language Explanations via Explanation-Consistency Finetuning. (arXiv:2401.13986v1 [cs.CL])

    [http://arxiv.org/abs/2401.13986](http://arxiv.org/abs/2401.13986)

    本文提出了一种通过解释一致性微调方法，使得大型语言模型（LLMs）在相关示例上生成更一致的自然语言解释。实验证明，该方法在不同领域的问答数据集上相对提高了10.0%的解释一致性，并且能够泛化到其他数据集。

    

    大型语言模型（LLMs）通常能够生成令人信服、流畅的解释。然而，与人类不同，它们在不同输入上生成的解释常常不一致。例如，LLM在回答问题“麻雀能飞吗？”时可能生成解释“所有鸟都能飞”，但同时在回答与之相关的问题“企鹅能飞吗？”时回答“不行”。解释应该在相关示例中保持一致，以便让人类能够模拟LLM在多个示例上的决策过程。我们提出了解释一致性微调（EC-finetuning）方法，该方法通过适应LLM在相关示例上生成更一致的自然语言解释。EC-finetuning包括在经过精心构建的包含一致解释的合成数据上微调LLM。在各种不同领域的问答数据集上，EC-finetuning在四个微调数据集上相对提高了10.0%的解释一致性，并且在七个外部数据集上具有泛化性能。

    Large language models (LLMs) often generate convincing, fluent explanations. However, different from humans, they often generate inconsistent explanations on different inputs. For example, an LLM may generate the explanation "all birds can fly" when answering the question "Can sparrows fly?" but meanwhile answer "no" to the related question "Can penguins fly?". Explanations should be consistent across related examples so that they allow a human to simulate the LLM's decision process on multiple examples. We propose explanation-consistency finetuning (EC-finetuning), a method that adapts LLMs to generate more consistent natural-language explanations on related examples. EC-finetuning involves finetuning LLMs on synthetic data that is carefully constructed to contain consistent explanations. Across a variety of question-answering datasets in various domains, EC-finetuning yields a 10.0% relative explanation consistency improvement on four finetuning datasets, and generalizes to seven out
    
[^31]: Leeroo Orchestrator: 通过模型集成提高LLMs的性能

    Leeroo Orchestrator: Elevating LLMs Performance Through Model Integration. (arXiv:2401.13979v1 [cs.CL])

    [http://arxiv.org/abs/2401.13979](http://arxiv.org/abs/2401.13979)

    本研究提出了Leeroo编排器的架构，通过集成多个训练过的LLMs模型，实现了一个新的最先进模型。该编排器在性能上与Mixtral模型相当，并且成本只有其三分之二。当允许更高的成本时，Leeroo编排器的准确性超过了Mixtral模型，并且当集成GPT4时进一步提升。

    

    本文提出了一种架构，利用多个训练过的LLMs的集体知识，创建一个新的最先进模型。该框架的核心是一个基于LLM的编排器，能够选择最佳的底层LLM专家进行任务执行。受到强化学习中的自我对弈的启发，我们创建了一个查询生成、编排和评估的循环，为编排器生成训练数据。我们的评估主要针对MMLU基准，在Hugging Face上使用了具有7B、13B和34B参数的模型。结果显示我们的Leeroo编排器实现了与Mixtral模型相当的性能，但只产生了其成本的三分之二。此外，增加允许的成本超过了Mixtral的准确性，达到了75.9%的准确性。当将GPT4集成到底层模型池中时，进一步提升也得到了观察。

    In this paper, we propose an architecture to harness the collective knowledge of multiple trained LLMs to create a new state-of-the-art. At the core of this framework is a LLM-based orchestrator that is adept at picking the right underlying LLM experts for optimal task execution. Inspired by self-play in reinforcement learning, we created a loop of query generation, orchestration, and evaluation to generate training data for the orchestrator. Our evaluation focused on the MMLU benchmark, employing models with 7B, 13B, and 34B parameters available on Hugging Face. The results demonstrate new state-of-the-art open-source models: Our Leeroo orchestrator achieves performance on par with the Mixtral model while incurring only two-thirds of its cost. Moreover, increasing the allowed cost surpasses Mixtral's accuracy by over 5% at the same cost level, reaching an accuracy of 75.9%. Further enhancements were observed when integrating GPT4 into the underlying model pool. The Leeroo orchestrator
    
[^32]: 大型语言模型自适应文字水印

    Adaptive Text Watermark for Large Language Models. (arXiv:2401.13927v1 [cs.CL])

    [http://arxiv.org/abs/2401.13927](http://arxiv.org/abs/2401.13927)

    这个论文提出了一种自适应的大型语言模型文字水印策略，通过辅助模型测量高熵令牌分布，将水印自适应地添加到具有高熵的令牌分布中，同时保持低熵令牌分布不变，以提高文本质量和水印的稳健性。

    

    大型语言模型的发展引发了人们对人工智能生成文本滥用的担忧，而基于大型语言模型生成的文字水印成为潜在解决方案。然而，在保持水印强度、稳健性和无需预先知道提示或模型的情况下检测水印的同时，生成高质量的带水印文本是具有挑战性的。本文提出了一种自适应的水印策略来解决这个问题。为了提高文本质量和保持稳健性，我们根据辅助模型测量的高熵令牌分布自适应地添加水印，而保持低熵令牌分布不变。为了保证安全性并进一步减小水印对文本质量的影响，我们不再使用从随机秘钥生成的固定红/绿名单，而是根据前一个语义嵌入将输出对数比例适应性缩放。

    The advancement of Large Language Models (LLMs) has led to increasing concerns about the misuse of AI-generated text, and watermarking for LLM-generated text has emerged as a potential solution. However, it is challenging to generate high-quality watermarked text while maintaining strong security, robustness, and the ability to detect watermarks without prior knowledge of the prompt or model. This paper proposes an adaptive watermarking strategy to address this problem. To improve the text quality and maintain robustness, we adaptively add watermarking to token distributions with high entropy measured using an auxiliary model and keep the low entropy token distributions untouched. For the sake of security and to further minimize the watermark's impact on text quality, instead of using a fixed green/red list generated from a random secret key, which can be vulnerable to decryption and forgery, we adaptively scale up the output logits in proportion based on the semantic embedding of prev
    
[^33]: LocMoE: 一种用于大型语言模型训练的低开销MoE

    LocMoE: A Low-overhead MoE for Large Language Model Training. (arXiv:2401.13920v1 [cs.LG])

    [http://arxiv.org/abs/2401.13920](http://arxiv.org/abs/2401.13920)

    LocMoE提出了一种新的路由策略，通过将部分节点间通信转换为节点内通信，结合负载平衡和局部性，以提高大型语言模型训练的性能。

    

    混合专家模型（MoE）是一种广泛采用的分布式和集成学习方法，用于大型语言模型（LLM），由于其能够有效稀疏和扩展模型，因此备受青睐。然而，MoE的性能受到负载不平衡和全对全通信的高延迟的限制，同时由于大量的专家容量导致相对冗余的计算。负载不平衡可能是由于现有路由策略始终倾向于选择特定的专家导致的。全对全过程中频繁的节点间通信也显著延长了训练时间。为了缓解上述性能问题，我们提出了一种新的路由策略，通过将部分节点间通信转换为节点内通信，结合负载平衡和局部性。值得注意的是，我们阐明了专家容量的最小阈值，通过将专家的门控权重与分配的标记之间的最大角偏差计算出来。

    The Mixtures-of-Experts (MoE) model is a widespread distributed and integrated learning method for large language models (LLM), which is favored due to its ability to sparsify and expand models efficiently. However, the performance of MoE is limited by load imbalance and high latency of All-To-All communication, along with relatively redundant computation owing to large expert capacity. Load imbalance may result from existing routing policies that consistently tend to select certain experts. The frequent inter-node communication in the All-To-All procedure also significantly prolongs the training time. To alleviate the above performance problems, we propose a novel routing strategy that combines load balance and locality by converting partial inter-node communication to that of intra-node. Notably, we elucidate that there is a minimum threshold for expert capacity, calculated through the maximal angular deviation between the gating weights of the experts and the assigned tokens. We por
    
[^34]: WebVoyager：使用大型多模态模型构建端到端的Web Agent

    WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models. (arXiv:2401.13919v1 [cs.CL])

    [http://arxiv.org/abs/2401.13919](http://arxiv.org/abs/2401.13919)

    WebVoyager是一种创新的基于大型多模态模型的Web代理，能够通过与真实网站交互来端到端地完成用户指令。它提出了一个新的Web代理评估协议，并在实际任务中取得了显著的成功率。

    

    大型语言模型（LLMs）的进步引领了一个由真实世界中自主应用程序的发展所标志的新时代，推动了基于网络的高级代理的创新。现有的网络代理通常只处理一个输入模态，并且仅在简化的网络模拟器或静态的网络快照中进行评估，极大地限制了它们在真实场景中的适用性。为了填补这一差距，我们引入了WebVoyager，一种创新的基于大型多模态模型（LMM）的Web代理，通过与真实网站进行交互，能够端到端地完成用户指令。此外，我们提出了一个新的Web代理评估协议，以解决开放式Web代理任务的自动评估挑战，利用了GPT-4V的强大多模态理解能力。我们通过收集来自15个广泛使用的网站的真实世界任务来创建一个新的基准来评估我们的代理。我们展示了WebVoyager实现了55.7％的任务成功率，显著地.....

    The advancement of large language models (LLMs) leads to a new era marked by the development of autonomous applications in the real world, which drives innovation in the creation of advanced web-based agents. Existing web agents typically only handle one input modality and are evaluated only in simplified web simulators or static web snapshots, greatly limiting their applicability in real-world scenarios. To bridge this gap, we introduce WebVoyager, an innovative Large Multimodal Model (LMM) powered web agent that can complete user instructions end-to-end by interacting with real-world websites. Moreover, we propose a new evaluation protocol for web agents to address the challenges of automatic evaluation of open-ended web agent tasks, leveraging the robust multimodal comprehension capabilities of GPT-4V. We create a new benchmark by gathering real-world tasks from 15 widely used websites to evaluate our agents. We show that WebVoyager achieves a 55.7% task success rate, significantly 
    
[^35]: 没有更多干扰：一种自适应上采样算法以减少数据伪像

    No More Distractions: an Adaptive Up-Sampling Algorithm to Reduce Data Artifacts. (arXiv:2401.13907v1 [cs.CL])

    [http://arxiv.org/abs/2401.13907](http://arxiv.org/abs/2401.13907)

    这项工作提出了一种自适应上采样算法，用于纠正语言模型训练中的数据伪像。经过使用该算法训练的模型在整体和修订的子集上表现显著优于使用原始数据训练的模型。

    

    研究人员最近发现，有时语言模型在基准数据集上达到了很高的准确性，但是对于原始数据集的微小变化无法很好地进行泛化。这有时是由于数据伪像，模型学习了标记和标签之间的虚假关联，而不是语义和逻辑。在这项工作中，我们分析了SNLI数据并可视化了这种虚假关联。我们提出了一种自适应上采样算法来纠正数据伪像，该算法简单而有效，并且不需要人工编辑或注释。我们在SNLI数据中应用该算法进行实验证明，经过纠正后训练的模型在整体和我们纠正的子集上表现明显优于在原始SNLI数据上训练的模型。

    Researchers recently found out that sometimes language models achieve high accuracy on benchmark data set, but they can not generalize very well with even little changes to the original data set. This is sometimes due to data artifacts, model is learning the spurious correlation between tokens and labels, instead of the semantics and logic. In this work, we analyzed SNLI data and visualized such spurious correlations. We proposed an adaptive up-sampling algorithm to correct the data artifacts, which is simple and effective, and does not need human edits or annotation. We did an experiment applying the algorithm to fix the data artifacts in SNLI data and the model trained with corrected data performed significantly better than the model trained with raw SNLI data, overall, as well as on the subset we corrected.
    
[^36]: 动态嵌入主题模型和变点检测用于探索文学-历史假设

    Dynamic embedded topic models and change-point detection for exploring literary-historical hypotheses. (arXiv:2401.13905v1 [cs.CL])

    [http://arxiv.org/abs/2401.13905](http://arxiv.org/abs/2401.13905)

    本研究提出了一种新颖的方法，将动态嵌入主题模型和变点检测结合起来，通过探索文学和历史文本中的词汇语义模态的历时变化，为比较文学和古典学的传统学术研究提供了一种简单的无监督模型。这种方法可以适用于任何适合的语料库，未来还可以通过改进和扩展使其适应更多的未处理材料。

    

    我们提出了一种新颖的动态嵌入主题模型和变点检测的组合方法，用于探索经典和早期基督教拉丁语中词汇语义模态的历时变化。我们展示了几种用于发现和表征输出中的模式，并将它们与比较文学和古典学的传统学术研究相关联的方法。这种简单的无监督模型的语义变化方法可以应用于任何合适的语料库，并通过未来的方向和改进来使更多的未编辑材料达到阈值。

    We present a novel combination of dynamic embedded topic models and change-point detection to explore diachronic change of lexical semantic modality in classical and early Christian Latin. We demonstrate several methods for finding and characterizing patterns in the output, and relating them to traditional scholarship in Comparative Literature and Classics. This simple approach to unsupervised models of semantic change can be applied to any suitable corpus, and we conclude with future directions and refinements aiming to allow noisier, less-curated materials to meet that threshold.
    
[^37]: 通过大型语言模型和监督建模的零样本推断进行乳腺癌病理分类的比较研究

    A comparative study of zero-shot inference with large language models and supervised modeling in breast cancer pathology classification. (arXiv:2401.13887v1 [cs.CL])

    [http://arxiv.org/abs/2401.13887](http://arxiv.org/abs/2401.13887)

    本研究比较了大型语言模型与监督建模在乳腺癌病理分类上的零样本推断能力，发现GPT-4模型在所有任务中要么明显优于，要么与最佳的监督模型LSTM-Att模型相当。

    

    尽管监督机器学习在从临床记录中提取信息方面十分流行，但创建大型注释数据集需要广泛的领域专业知识和耗费时间。与此同时，大型语言模型（LLMs）展示了很强的迁移学习能力。在本研究中，我们探讨了最近的LLMs是否可以减少对大规模数据注释的需求。我们整理了一个手动标注的769个乳腺癌病理报告的数据集（标注了13个类别），来比较GPT-4模型和GPT-3.5模型的零样本分类能力与三种模型架构的监督分类性能：随机森林分类器，具有注意力的长短期记忆网络（LSTM-Att）和UCSF-BERT模型。在所有13个任务中，GPT-4模型的性能要么明显优于最佳的监督模型LSTM-Att模型（平均宏F1得分为0.83 vs. 0.75），要么与其相当。在存在标签之间高度不平衡的任务中，di

    Although supervised machine learning is popular for information extraction from clinical notes, creating large annotated datasets requires extensive domain expertise and is time-consuming. Meanwhile, large language models (LLMs) have demonstrated promising transfer learning capability. In this study, we explored whether recent LLMs can reduce the need for large-scale data annotations. We curated a manually-labeled dataset of 769 breast cancer pathology reports, labeled with 13 categories, to compare zero-shot classification capability of the GPT-4 model and the GPT-3.5 model with supervised classification performance of three model architectures: random forests classifier, long short-term memory networks with attention (LSTM-Att), and the UCSF-BERT model. Across all 13 tasks, the GPT-4 model performed either significantly better than or as well as the best supervised model, the LSTM-Att model (average macro F1 score of 0.83 vs. 0.75). On tasks with high imbalance between labels, the di
    
[^38]: 揭示和量化大型语言模型在医学报告生成中的种族偏见

    Unmasking and Quantifying Racial Bias of Large Language Models in Medical Report Generation. (arXiv:2401.13867v1 [cs.CL])

    [http://arxiv.org/abs/2401.13867](http://arxiv.org/abs/2401.13867)

    该论文揭示了大型语言模型在医学报告生成中存在的种族偏见，并通过定性和定量分析证明了这些偏见的影响。这些偏见主要表现为对白人种族的高护理成本和住院时间预测，以及在临床医学中面临挑战的情况下呈现过度乐观的生存率。意识到这些偏见的存在和影响，对于在关键的医疗应用中确保公平和准确的结果至关重要。

    

    GPT-3.5-turbo和GPT-4等大型语言模型在医疗专业领域具有潜力，但它们在训练过程中可能会无意中继承偏见，可能影响其在医学应用中的效用。尽管过去有一些尝试，但这些偏见的确切影响和程度仍不确定。通过定性和定量分析，我们发现这些模型倾向于为白人种族投射更高的医疗费用和较长的住院时间，并在面临挑战性医学情况时呈现乐观的生存率。这些偏见与现实中的医疗差异相一致，可在生成患者背景、将特定疾病与某些种族相关联以及治疗推荐的差异等方面体现出来。我们的发现强调了将来需要开展研究来解决和减轻语言模型中的偏见问题，特别是在关键的医疗应用中，以确保公正和准确的结果。

    Large language models like GPT-3.5-turbo and GPT-4 hold promise for healthcare professionals, but they may inadvertently inherit biases during their training, potentially affecting their utility in medical applications. Despite few attempts in the past, the precise impact and extent of these biases remain uncertain. Through both qualitative and quantitative analyses, we find that these models tend to project higher costs and longer hospitalizations for White populations and exhibit optimistic views in challenging medical scenarios with much higher survival rates. These biases, which mirror real-world healthcare disparities, are evident in the generation of patient backgrounds, the association of specific diseases with certain races, and disparities in treatment recommendations, etc. Our findings underscore the critical need for future research to address and mitigate biases in language models, especially in critical healthcare applications, to ensure fair and accurate outcomes for all 
    
[^39]: TPD: 通过原则发现和指导提升学生语言模型的推理能力

    TPD: Enhancing Student Language Model Reasoning via Principle Discovery and Guidance. (arXiv:2401.13849v1 [cs.CL])

    [http://arxiv.org/abs/2401.13849](http://arxiv.org/abs/2401.13849)

    通过原则发现和指导提升学生语言模型的推理能力的TPD框架模拟了教师和学生之间的互动，通过生成问题解决指令和纠正原则，从而引导学生模型从教师的指导和自身的错误中进行学习。

    

    大型语言模型(LLM)最近展示出了令人惊叹的推理能力。然而，更大的模型往往在推理任务上超过了较小的模型，因此有效地将这些能力从较大的模型转移到较小的模型是一项挑战。现有的方法往往依赖于大量的微调数据或在推理过程中与优秀的教师LLM进行持续的交互。我们引入了一种基于原则的师生框架，称为“通过原则发现教学”(TPD)，以解决这些限制。受人类学习机制启发，TPD模仿了教师和学生之间的互动，采用基于原则的方法。教师LLM生成问题解决指令和纠正原则，基于学生LLM的错误。这些原则指导指令的完善和从验证集中选择有教育意义的示例。这使得学生模型能够从教师的指导和自己的错误中学习。一旦

    Large Language Models (LLMs) have recently showcased remarkable reasoning abilities. However, larger models often surpass their smaller counterparts in reasoning tasks, posing the challenge of effectively transferring these capabilities from larger models. Existing approaches heavily rely on extensive fine-tuning data or continuous interactions with a superior teacher LLM during inference. We introduce a principle-based teacher-student framework called ``Teaching via Principle Discovery'' (TPD) to address these limitations. Inspired by human learning mechanisms, TPD mimics the interaction between a teacher and a student using a principle-based approach. The teacher LLM generates problem-solving instructions and corrective principles based on the student LLM's errors. These principles guide the refinement of instructions and the selection of instructive examples from a validation set. This enables the student model to learn from both the teacher's guidance and its own mistakes. Once the
    
[^40]: 语言模型中模型和人类置信度之间的校准差距

    The Calibration Gap between Model and Human Confidence in Large Language Models. (arXiv:2401.13835v1 [cs.LG])

    [http://arxiv.org/abs/2401.13835](http://arxiv.org/abs/2401.13835)

    该论文研究了大型语言模型在传达置信度方面模型和人类之间存在的差距，并发现默认解释会导致用户过高估计模型置信度和准确性。

    

    为了使大型语言模型（LLM）能够获得人类的信任，它们需要在某种意义上实现良好的校准，即能够准确评估和传达它们的预测正确的可能性。最近的研究关注了LLM内部置信度评估的质量，但问题仍然是LLM能够如何将这种内部模型置信度传达给人类用户。本文探讨了人类对LLM响应的外部置信度与模型内部置信度之间的差距。通过涉及多项选择题的实验，我们系统地检查了人类用户识别LLM输出可信度的能力。我们的研究重点分为两个方面：（1）评估用户对真实LLM置信度的感知和（2）调查个性化解释对该感知的影响。研究结果显示，LLM的默认解释往往会导致用户过高估计模型的置信度和准确性。通过修改解释的方式可以减小这种误差。

    For large language models (LLMs) to be trusted by humans they need to be well-calibrated in the sense that they can accurately assess and communicate how likely it is that their predictions are correct. Recent work has focused on the quality of internal LLM confidence assessments, but the question remains of how well LLMs can communicate this internal model confidence to human users. This paper explores the disparity between external human confidence in an LLM's responses and the internal confidence of the model. Through experiments involving multiple-choice questions, we systematically examine human users' ability to discern the reliability of LLM outputs. Our study focuses on two key areas: (1) assessing users' perception of true LLM confidence and (2) investigating the impact of tailored explanations on this perception. The research highlights that default explanations from LLMs often lead to user overestimation of both the model's confidence and its' accuracy. By modifying the expl
    
[^41]: 使用GPT-4进行上下文学习的自动化云故障溯源(arXiv:2401.13810v1 [cs.CL])

    Automated Root Causing of Cloud Incidents using In-Context Learning with GPT-4. (arXiv:2401.13810v1 [cs.CL])

    [http://arxiv.org/abs/2401.13810](http://arxiv.org/abs/2401.13810)

    这项研究提出了一种基于上下文学习的自动化云故障溯源方法，使用GPT-4模型，无需进行昂贵的微调操作，可以改进故障根因分析过程，降低服务停机时间、客户影响和手动劳动。

    

    根因分析（RCA）在云服务的故障诊断过程中起着至关重要的作用，需要值班工程师识别主要问题并实施纠正措施，以防止将来的复发。改进故障根因分析过程对于减少服务停机时间、客户影响和手动劳动至关重要。最近人工智能的进展引入了先进的大型语言模型（LLM），如GPT-4，在处理从代码撰写到故障管理等各种AIOps问题方面证明非常有效。然而，GPT-4模型巨大的尺寸在尝试在用户数据上进行微调时存在挑战，因为需要大量的GPU资源，并且随着新数据的出现需要持续进行模型微调。为了解决微调LLM的高成本问题，我们提出了一种基于上下文学习的自动故障溯源方法，它消除了对微调的需要。我们对10万个数据进行了广泛的研究。

    Root Cause Analysis (RCA) plays a pivotal role in the incident diagnosis process for cloud services, requiring on-call engineers to identify the primary issues and implement corrective actions to prevent future recurrences. Improving the incident RCA process is vital for minimizing service downtime, customer impact and manual toil. Recent advances in artificial intelligence have introduced state-of-the-art Large Language Models (LLMs) like GPT-4, which have proven effective in tackling various AIOps problems, ranging from code authoring to incident management. Nonetheless, the GPT-4 model's immense size presents challenges when trying to fine-tune it on user data because of the significant GPU resource demand and the necessity for continuous model fine-tuning with the emergence of new data. To address the high cost of fine-tuning LLM, we propose an in-context learning approach for automated root causing, which eliminates the need for fine-tuning. We conduct extensive study over 100,000
    
[^42]: 研究大型语言模型在代码克隆检测方面的功效

    Investigating the Efficacy of Large Language Models for Code Clone Detection. (arXiv:2401.13802v1 [cs.SE])

    [http://arxiv.org/abs/2401.13802](http://arxiv.org/abs/2401.13802)

    这项研究探索了大型语言模型在代码克隆检测任务中的应用。

    

    大型语言模型（LLMs）在各种自然语言处理和软件工程任务中表现出了显著的成功，例如代码生成。LLMs主要在基于提示的零/少样本范式中被用于指导模型完成任务。本研究探索了LLMs在代码克隆检测（CCD）这一非生成任务中的适用性。

    Large Language Models (LLMs) have demonstrated remarkable success in various natural language processing and software engineering tasks, such as code generation. The LLMs are mainly utilized in the prompt-based zero/few-shot paradigm to guide the model in accomplishing the task. %\textbf{Goal:} GPT-based models are one of the popular ones studied for tasks such as code comment generation or test generation. These tasks are `generative' tasks. However, there is limited research on the usage of LLMs for `non-generative' tasks such as classification using the prompt-based paradigm. In this preliminary exploratory study, we investigated the applicability of LLMs for Code Clone Detection (CCD), a non-generative task. %\textbf{Method:} By building a mono-lingual and cross-lingual CCD dataset derived from CodeNet, we first investigated two different prompts using ChatGPT to detect \textcolor{black}{Type-4} code clones in Java-Java and Java-Ruby pairs in a zero-shot setting. We \textcolor{blac
    
[^43]: 一种统一的情感检测和任务导向对话建模方法

    A Unified Approach to Emotion Detection and Task-Oriented Dialogue Modeling. (arXiv:2401.13789v1 [cs.CL])

    [http://arxiv.org/abs/2401.13789](http://arxiv.org/abs/2401.13789)

    提出了一种统一的方法来实现情感检测和任务导向对话建模，通过在信念状态跟踪中引入情感检测实现，并将其融入端到端的任务导向对话系统中。实验证明该方法提高了情感检测和任务结果的性能，并显示用户的情感可以作为回应的上下文条件，对于提高回应的共鸣程度具有帮助。

    

    在当前基于文本的任务导向对话（TOD）系统中，用户情感检测（ED）经常被忽视，或者通常被视为一项独立的任务，需要额外的训练。相反，我们的工作证明了无缝地统一ED和TOD建模可以带来相互的好处，因此是一种值得考虑的替代方法。我们的方法是通过将ED包含在信念状态跟踪中，并依赖于单一的语言模型，来扩展SimpleToD这个端到端的TOD系统。我们使用GPT-2和Llama-2在EmoWOZ基准测试集上评估了我们的方法，这是一个使用情感进行注释的MultiWOZ版本。我们的结果显示，ED和任务结果的性能普遍提高。我们的研究结果还表明，用户的情感为系统的回应提供了有用的上下文条件，并可以用于进一步改善回应的共鸣程度。

    In current text-based task-oriented dialogue (TOD) systems, user emotion detection (ED) is often overlooked or is typically treated as a separate and independent task, requiring additional training. In contrast, our work demonstrates that seamlessly unifying ED and TOD modeling brings about mutual benefits, and is therefore an alternative to be considered. Our method consists in augmenting SimpleToD, an end-to-end TOD system, by extending belief state tracking to include ED, relying on a single language model. We evaluate our approach using GPT-2 and Llama-2 on the EmoWOZ benchmark, a version of MultiWOZ annotated with emotions. Our results reveal a general increase in performance for ED and task results. Our findings also indicate that user emotions provide useful contextual conditioning for system responses, and can be leveraged to further refine responses in terms of empathy.
    
[^44]: 从推特到引用：揭示社交媒体影响者对人工智能研究可见性的影响

    Tweets to Citations: Unveiling the Impact of Social Media Influencers on AI Research Visibility. (arXiv:2401.13782v1 [cs.DL])

    [http://arxiv.org/abs/2401.13782](http://arxiv.org/abs/2401.13782)

    本文研究了社交媒体影响者在提高机器学习研究的可见性方面的作用，发现被这些影响者认可的论文引用次数显著增加，中位数引用次数比对照组高2-3倍。此外，该研究还探讨了被展示作者的地理、性别和机构多样性。

    

    随着人工智能和机器学习会议上被接受的论文数量达到数千篇，研究人员如何获取和阅读研究论文变得不清楚。本文研究了社交媒体影响者在增强机器学习研究可见性中的作用，特别是他们分享的论文引用次数。我们编制了一个包括8000多篇论文的全面数据集，涵盖了2018年12月至2023年10月的推特，以及基于出版年份、会议地点和摘要主题进行1：1匹配的对照组。我们的分析揭示了这些影响者认可的论文引用次数显著增加，中位数引用次数比对照组高2-3倍。此外，该研究还深入研究了被展示作者的地理、性别和机构多样性。这些发现突显了社交媒体在学术交流中的不断扩大的影响力，并强调了当今数字化时代不断发展的生态系统的重要性。

    As the number of accepted papers at AI and ML conferences reaches into the thousands, it has become unclear how researchers access and read research publications. In this paper, we investigate the role of social media influencers in enhancing the visibility of machine learning research, particularly the citation counts of papers they share. We have compiled a comprehensive dataset of over 8,000 papers, spanning tweets from December 2018 to October 2023, alongside 1:1 matched controls based on publication year, venue, and abstract topics. Our analysis reveals a significant increase in citations for papers endorsed by these influencers, with median citation counts 2-3 times higher than those of the control group. Additionally, the study delves into the geographic, gender, and institutional diversity of highlighted authors. These findings highlight the expanding influence of social media in scholarly communication and underscore the importance of an evolving ecosystem in today's digital a
    
[^45]: 迈向使用多模态基础模型的稳健多模态学习

    Toward Robust Multimodal Learning using Multimodal Foundational Models. (arXiv:2401.13697v1 [cs.CV])

    [http://arxiv.org/abs/2401.13697](http://arxiv.org/abs/2401.13697)

    该论文提出了一种名为TRML的框架，旨在实现在随机缺失模态的情况下的稳健多模态学习。TRML利用生成的虚拟模态替换缺失的模态，并且通过对齐语义空间来解决模态缺失的问题。

    

    现有的多模态情感分析任务高度依赖于训练集和测试集是完整的多模态数据的假设，然而这个假设在现实场景中往往很难成立：多模态数据往往在现实世界中是不完整的。因此，在存在随机缺失模态的场景中，一种稳健的多模态模型将会更受欢迎。最近，基于CLIP的多模态基础模型通过学习图像和文本对的跨模态语义对齐，在众多多模态任务中展示了令人印象深刻的性能，但是这些多模态基础模型也无法直接解决涉及模态缺失的场景。为了缓解这个问题，我们提出了一个简单而有效的框架，即TRML（Toward Robust Multimodal Learning using Multimodal Foundational Models）。TRML利用生成的虚拟模态替换缺失的模态，并且对生成的模态和缺失的模态之间的语义空间进行对齐。具体来说，我们设计了一个缺失模态生成模块，可以生成缺失的模态，然后通过特征对齐模块来学习模态之间的对齐关系。

    Existing multimodal sentiment analysis tasks are highly rely on the assumption that the training and test sets are complete multimodal data, while this assumption can be difficult to hold: the multimodal data are often incomplete in real-world scenarios. Therefore, a robust multimodal model in scenarios with randomly missing modalities is highly preferred. Recently, CLIP-based multimodal foundational models have demonstrated impressive performance on numerous multimodal tasks by learning the aligned cross-modal semantics of image and text pairs, but the multimodal foundational models are also unable to directly address scenarios involving modality absence. To alleviate this issue, we propose a simple and effective framework, namely TRML, Toward Robust Multimodal Learning using Multimodal Foundational Models. TRML employs generated virtual modalities to replace missing modalities, and aligns the semantic spaces between the generated and missing modalities. Concretely, we design a missin
    
[^46]: MM-LLMs: 多模式大语言模型的最新进展

    MM-LLMs: Recent Advances in MultiModal Large Language Models. (arXiv:2401.13601v1 [cs.CL])

    [http://arxiv.org/abs/2401.13601](http://arxiv.org/abs/2401.13601)

    近年来，多模式大语言模型（MM-LLMs）通过成本效益高的训练策略取得了显著进展，扩展了现有的语言模型的多模输入和输出支持。本论文提供了一份综合调查报告，介绍了MM-LLMs的设计和训练方案，整理了现有的MM-LLMs及其性能，总结了关键训练方法，并探讨了未来的研究方向。

    

    在过去的一年中，多模式大语言模型（MM-LLMs）取得了显著的进展，通过成本效益高的训练策略，增强了现有的LLMs对多模输入或输出的支持。这些结果模型不仅保留了LLMs固有的推理和决策能力，还赋予了各种多模任务。本文提供了一份综合性的调查报告，旨在促进对MM-LLMs的进一步研究。具体而言，我们首先概述了模型架构和训练流程的一般设计方案。随后，我们简要介绍了26种现有的MM-LLMs，每种都以其具体的公式为特征。此外，我们还回顾了MM-LLMs在主流基准测试上的性能，并总结了提高MM-LLMs效力的关键训练方法。最后，我们探讨了MM-LLMs的有前途的方向，同时还为该领域的最新发展提供了实时追踪网站。我们希望这份调查报告能够促进对MM-LLMs的进一步研究。

    In the past year, MultiModal Large Language Models (MM-LLMs) have undergone substantial advancements, augmenting off-the-shelf LLMs to support MM inputs or outputs via cost-effective training strategies. The resulting models not only preserve the inherent reasoning and decision-making capabilities of LLMs but also empower a diverse range of MM tasks. In this paper, we provide a comprehensive survey aimed at facilitating further research of MM-LLMs. Specifically, we first outline general design formulations for model architecture and training pipeline. Subsequently, we provide brief introductions of $26$ existing MM-LLMs, each characterized by its specific formulations. Additionally, we review the performance of MM-LLMs on mainstream benchmarks and summarize key training recipes to enhance the potency of MM-LLMs. Lastly, we explore promising directions for MM-LLMs while concurrently maintaining a real-time tracking website for the latest developments in the field. We hope that this surv
    
[^47]: SpeechGPT-Gen: 缩放信息链语音生成

    SpeechGPT-Gen: Scaling Chain-of-Information Speech Generation. (arXiv:2401.13527v1 [cs.CL])

    [http://arxiv.org/abs/2401.13527](http://arxiv.org/abs/2401.13527)

    SpeechGPT-Gen是一个8亿参数的语音大型语言模型，通过Chain-of-Information Generation方法来解耦语义和感知信息，在语音生成方面提高了效率。

    

    凭借有效的语音建模，当前的语音大型语言模型（SLLMs）在上下文语音生成和对未见过的说话人的高效泛化方面展示出了出色的能力。然而，现有的信息建模过程受到一定冗余的限制，导致语音生成效率低下。我们提出了信息链生成（CoIG）的方法，用于解耦大规模语音生成中的语义和感知信息。在此基础上，我们开发了SpeechGPT-Gen，一个8亿参数的SLLM，能够高效地进行语义和感知信息建模。它包括一个基于LLM的自回归模型用于语义信息建模，以及一个使用流匹配进行感知信息建模的非自回归模型。此外，我们引入了将语义信息注入先验分布以增强流匹配效率的新方法。广泛的实验结果表明…

    Benefiting from effective speech modeling, current Speech Large Language Models (SLLMs) have demonstrated exceptional capabilities in in-context speech generation and efficient generalization to unseen speakers. However, the prevailing information modeling process is encumbered by certain redundancies, leading to inefficiencies in speech generation. We propose Chain-of-Information Generation (CoIG), a method for decoupling semantic and perceptual information in large-scale speech generation. Building on this, we develop SpeechGPT-Gen, an 8-billion-parameter SLLM efficient in semantic and perceptual information modeling. It comprises an autoregressive model based on LLM for semantic information modeling and a non-autoregressive model employing flow matching for perceptual information modeling. Additionally, we introduce the novel approach of infusing semantic information into the prior distribution to enhance the efficiency of flow matching. Extensive experimental results demonstrate th
    
[^48]: What the Weight?! 零样本知识组合的统一框架

    What the Weight?! A Unified Framework for Zero-Shot Knowledge Composition. (arXiv:2401.12756v1 [cs.CL])

    [http://arxiv.org/abs/2401.12756](http://arxiv.org/abs/2401.12756)

    本研究提出了一个新的零样本模块组合框架，统一了选择、加权和组合参数模块的各种变化。以领域知识和适配器层为场景，通过系统化的统一概念，进行了首次全面的零样本知识组合的基准研究。

    

    模型中所封装的知识是确定其在下游任务中最终性能的核心因素。自然语言处理领域的许多研究都集中在存储和调整不同类型知识的有效方法上，例如在专用的模块化结构中，以及如何通过学习额外的参数来有效地组合这些知识。然而，鉴于存在许多可能的选项，对于这些组合中涉及的机制缺乏全面的理解，因此目前仍不清楚应该使用哪些策略。为了填补这一研究空白，我们提出了一个新的零样本模块组合框架，它涵盖了现有的一些选择、加权和组合参数模块的变化，统一了这些概念。在聚焦领域知识和适配器层的情景下，我们的框架提供了一个系统化的统一概念，使我们能够进行首次全面的各种零样本知识组合的基准研究。

    The knowledge encapsulated in a model is the core factor determining its final performance on downstream tasks. Much research in NLP has focused on efficient methods for storing and adapting different types of knowledge, e.g., in dedicated modularized structures, and on how to effectively combine these, e.g., by learning additional parameters. However, given the many possible options, a thorough understanding of the mechanisms involved in these compositions is missing, and hence it remains unclear which strategies to utilize. To address this research gap, we propose a novel framework for zero-shot module composition, which encompasses existing and some novel variations for selecting, weighting, and combining parameter modules under a single unified notion. Focusing on the scenario of domain knowledge and adapter layers, our framework provides a systematic unification of concepts, allowing us to conduct the first comprehensive benchmarking study of various zero-shot knowledge compositio
    
[^49]: 基于能量的自动化模型评估

    Energy-based Automated Model Evaluation. (arXiv:2401.12689v1 [cs.LG])

    [http://arxiv.org/abs/2401.12689](http://arxiv.org/abs/2401.12689)

    提出了一种基于能量的自动化模型评估方法，通过建立关于个体样本相关信息的元分布统计量，能够更高效和有效地评估机器学习模型的性能，解决了AutoEval框架中的过度自信、存储和计算成本高等问题。

    

    传统的机器学习模型评估协议依赖于标记的、假设独立同分布的测试数据集，而这在实际应用中往往并不常见。自动模型评估（AutoEval）提出了一种替代传统工作流程的方法，通过形成一个接近预测性能的测试管线，而无需真实标签的存在。尽管AutoEval框架近年来取得了一些成功，但仍存在过度自信、存储和计算成本高的问题。因此，我们提出了一种新颖的度量方式——元分布能量（MDE），它可以使AutoEval框架更加高效和有效。MDE的核心是建立一个关于个体样本相关信息（能量）的元分布统计量，然后通过基于能量的学习提供更平滑的表示能力。我们通过将MDE与分类损失相连接，进一步提供了理论洞见。我们还提供了大量实验证据来验证我们的方法。

    The conventional evaluation protocols on machine learning models rely heavily on a labeled, i.i.d-assumed testing dataset, which is not often present in real world applications. The Automated Model Evaluation (AutoEval) shows an alternative to this traditional workflow, by forming a proximal prediction pipeline of the testing performance without the presence of ground-truth labels. Despite its recent successes, the AutoEval frameworks still suffer from an overconfidence issue, substantial storage and computational cost. In that regard, we propose a novel measure -- Meta-Distribution Energy (MDE) -- that allows the AutoEval framework to be both more efficient and effective. The core of the MDE is to establish a meta-distribution statistic, on the information (energy) associated with individual samples, then offer a smoother representation enabled by energy-based learning. We further provide our theoretical insights by connecting the MDE with the classification loss. We provide extensive
    
[^50]: BiTA: 大语言模型中无损加速的双向调整

    BiTA: Bi-Directional Tuning for Lossless Acceleration in Large Language Models. (arXiv:2401.12522v1 [cs.CL])

    [http://arxiv.org/abs/2401.12522](http://arxiv.org/abs/2401.12522)

    BiTA是一种用于大语言模型的创新方法，通过双向调整实现了无损加速。它采用简化的半自回归生成和草稿验证，通过高效的基于树的解码同时进行候选生成和验证，提高了推理效率。这种方法不需要额外的辅助模型或显著的额外内存开销。

    

    大型语言模型（LLMs）通常在推理过程中使用自回归生成，导致高内存带宽需求和延迟延长。为了减轻这种效率低下的问题，我们提出了一种创新方法——双向调整以实现无损加速（BiTA），通过简化的半自回归生成和草稿验证来加速LLMs。受启发于提示调整的概念，我们使用一种参数高效的设计，称为双向调整，来增强LLMs在半自回归生成方面的能力。采用高效的基于树的解码，模型可以同时进行草稿候选生成和验证，确保输出结果与它们的自回归对应物在贪婪抽样下完全相同。BiTA作为一个轻量级的插件模块，可以无缝增强现有LLMs的推理效率，而无需额外的辅助模型或承担显著的额外内存开销。通过应用提出的BiTA，LLaMA-2-70B-Chat实现了

    Large language models (LLMs) commonly employ autoregressive generation during inference, leading to high memory bandwidth demand and consequently extended latency. To mitigate this inefficiency, we present Bi-directional Tuning for lossless Acceleration (BiTA), an innovative method expediting LLMs via streamlined semi-autoregressive generation and draft verification. Inspired by the concept of prompt tuning, we enhance LLMs with a parameter-efficient design called bi-directional tuning for the capability in semi-autoregressive generation. Employing efficient tree-based decoding, the models perform draft candidate generation and verification in parallel, ensuring outputs identical to their autoregressive counterparts under greedy sampling. BiTA serves as a lightweight plug-in module, seamlessly boosting the inference efficiency of existing LLMs without requiring additional assistance models or incurring significant extra memory costs. Applying the proposed BiTA, LLaMA-2-70B-Chat achieve
    
[^51]: 大型语言模型的指令指纹识别

    Instructional Fingerprinting of Large Language Models. (arXiv:2401.12255v1 [cs.CR])

    [http://arxiv.org/abs/2401.12255](http://arxiv.org/abs/2401.12255)

    这项研究提出了一种指纹识别大型语言模型的方法，通过轻量级的指令调整，保护知识产权并确保遵守许可条款。实验证明这种方法不影响模型的正常行为，并且具有鲁棒性和高效训练的特点。

    

    从零开始训练大型语言模型（LLM）的巨大成本使得对模型进行指纹识别以保护知识产权成为必要，通过所有权认证并确保下游用户和开发者遵守许可条款（如限制商业使用）。在这项研究中，我们提出了LLM指纹识别的试点研究，作为一种非常轻量级的指令调整形式。模型发布者指定一个机密的私钥，并将其植入为一个指令后门，当密钥存在时，导致LLM生成特定的文本。对11个常用LLMs的结果表明，这种方法轻量级且不影响模型的正常行为。它还可以防止发布者过度宣称，对指纹猜测和参数高效训练保持鲁棒性，并支持类似于MIT许可证的多阶段指纹识别。代码可在https://cnut1648.github.io/Model-Fingerprint/中获得。

    The exorbitant cost of training Large language models (LLMs) from scratch makes it essential to fingerprint the models to protect intellectual property via ownership authentication and to ensure downstream users and developers comply with their license terms (e.g. restricting commercial use). In this study, we present a pilot study on LLM fingerprinting as a form of very lightweight instruction tuning. Model publisher specifies a confidential private key and implants it as an instruction backdoor that causes the LLM to generate specific text when the key is present. Results on 11 popularly-used LLMs showed that this approach is lightweight and does not affect the normal behavior of the model. It also prevents publisher overclaim, maintains robustness against fingerprint guessing and parameter-efficient training, and supports multi-stage fingerprinting akin to MIT License. Code is available in https://cnut1648.github.io/Model-Fingerprint/.
    
[^52]: Mementos: 一种针对图像序列的多模态大型语言模型推理的综合基准测试

    Mementos: A Comprehensive Benchmark for Multimodal Large Language Model Reasoning over Image Sequences. (arXiv:2401.10529v1 [cs.CV])

    [http://arxiv.org/abs/2401.10529](http://arxiv.org/abs/2401.10529)

    Mementos是一个新的基准测试，旨在评估多模态大型语言模型在图像序列推理中的能力。研究发现，现有的MLLM在准确描述图像序列的动态信息方面存在困难，容易导致物体及其行为的错误描述或错觉。

    

    多模态大型语言模型（MLLMs）在处理各种视觉语言任务方面展示了高超的能力。然而，目前的MLLM基准测试主要用于评估基于单个图像的静态信息的推理能力，而现代MLLM在从图像序列中进行推断的能力，在理解不断变化的世界方面的重要性却被较少研究。为了解决这一挑战，本文引入了一个新的基准测试Mementos，用于评估MLLM的序列图像推理能力。Mementos包括4761个具有不同长度的多样的图像序列。我们还采用了GPT-4辅助方法来评估MLLM的推理性能。通过对Mementos中包括GPT-4V和Gemini在内的九个最新MLLM进行仔细评估，我们发现它们在准确描述所给图像序列的动态信息方面存在困难，往往导致对象及其对应行为的错误描述或错觉。

    Multimodal Large Language Models (MLLMs) have demonstrated proficiency in handling a variety of visual-language tasks. However, current MLLM benchmarks are predominantly designed to evaluate reasoning based on static information about a single image, and the ability of modern MLLMs to extrapolate from image sequences, which is essential for understanding our ever-changing world, has been less investigated. To address this challenge, this paper introduces Mementos, a new benchmark designed to assess MLLMs' sequential image reasoning abilities. Mementos features 4,761 diverse image sequences with varying lengths. We also employ a GPT-4 assisted method to evaluate MLLM reasoning performance. Through a careful evaluation of nine recent MLLMs on Mementos, including GPT-4V and Gemini, we find that they struggle to accurately describe dynamic information about given image sequences, often leading to hallucinations/misrepresentations of objects and their corresponding behaviors. Our quantitati
    
[^53]: 中文数据处理中的佼佼者：英文代码模型

    Top in Chinese Data Processing: English Code Models. (arXiv:2401.10286v1 [cs.CL])

    [http://arxiv.org/abs/2401.10286](http://arxiv.org/abs/2401.10286)

    在中文数据处理中，基于代码的语言模型在非编程中文任务中表现出色，尤其是在对中文幻觉敏感的任务中。此研究为讨论“中文房间”思想实验提供了独特的视角。

    

    尽管在语言模型的应用中，任务与训练语料之间的对齐是一个基本的共识，但我们的一系列实验和我们设计的评估指标表明，基于代码的大型语言模型(LLMs)在非编程中文任务中的表现明显优于与任务紧密匹配的训练数据。此外，在对中文幻觉敏感程度较高的任务中，展示较少中文语言特征的模型表现更好。我们的实验结果可以通过简单地用代码模型替换基础模型，在中文数据处理任务中，如为检索增强生成(RAG)准备数据，很容易得到复制。此外，我们的研究为讨论“中文房间”思想实验提供了独特的视角。

    While the alignment between tasks and training corpora is a fundamental consensus in the application of language models, our series of experiments and the metrics we designed reveal that code-based Large Language Models (LLMs) significantly outperform models trained on data that is closely matched to the tasks in non-coding Chinese tasks. Moreover, in tasks high sensitivity to Chinese hallucinations, models exhibiting fewer linguistic features of the Chinese language achieve better performance. Our experimental results can be easily replicated in Chinese data processing tasks, such as preparing data for Retrieval-Augmented Generation (RAG), by simply replacing the base model with a code-based model. Additionally, our research offers a distinct perspective for discussion on the philosophical "Chinese Room" thought experiment.
    
[^54]: 对比困惑度在受控生成中的应用：清洁大型语言模型

    Contrastive Perplexity for Controlled Generation: An Application in Detoxifying Large Language Models. (arXiv:2401.08491v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.08491](http://arxiv.org/abs/2401.08491)

    这项研究研究了对比学习目标的集成到微调大型语言模型中，以解决其产生不可取内容的问题，并展示了在清洁领域中有效减少有害内容生成的方法。

    

    大型语言模型产生不可取和事实不正确的内容在很大程度上是一个挑战和未解决的问题。本文研究了对比学习目标的集成，用于微调语言模型以进行隐式知识编辑和受控文本生成。通过对比方式优化训练目标，即对齐文本的困惑度。为了以自监督的方式训练模型，我们利用现成的语言模型来生成训练数据。我们展示了在清洁领域的适用性。在此过程中，所提出的方法显著减少了生成有害内容的数量，同时保留了对于常识推理和阅读理解等下游任务的实用性。所提出的方法在概念上简单但经验上强大。

    The generation of undesirable and factually incorrect content of large language models poses a significant challenge and remains largely an unsolved issue. This paper studies the integration of a contrastive learning objective for fine-tuning LLMs for implicit knowledge editing and controlled text generation. Optimizing the training objective entails aligning text perplexities in a contrastive fashion. To facilitate training the model in a self-supervised fashion, we leverage an off-the-shelf LLM for training data generation. We showcase applicability in the domain of detoxification. Herein, the proposed approach leads to a significant decrease in the generation of toxic content while preserving general utility for downstream tasks such as commonsense reasoning and reading comprehension. The proposed approach is conceptually simple but empirically powerful.
    
[^55]: TrustLLM: 大型语言模型中的可信性

    TrustLLM: Trustworthiness in Large Language Models. (arXiv:2401.05561v1 [cs.CL])

    [http://arxiv.org/abs/2401.05561](http://arxiv.org/abs/2401.05561)

    TrustLLM是对大型语言模型中可信性的全面研究，包括可信性原则的提出、建立基准的方法、评估主流语言模型的可信性，以及对未来挑战的讨论。

    

    大型语言模型（LLMs），如ChatGPT，因其出色的自然语言处理能力而引起了广泛关注。然而，这些LLMs在可信性方面存在许多挑战。因此，确保LLMs的可信性成为一个重要的话题。本文介绍了TrustLLM，它是对LLMs中可信性的全面研究，包括不同维度的可信性原则、建立基准、评估和分析主流LLMs的可信性，以及对开放挑战和未来方向的讨论。具体而言，我们首先提出了涵盖八个不同维度的可信LLMs原则。基于这些原则，我们进一步建立了一个跨六个维度的基准，包括真实性、安全性、公平性、鲁棒性、隐私性和机器伦理学。然后，我们在TrustLLM中展示了一个评估16个主流LLMs的研究，涵盖了30多个数据集。

    Large language models (LLMs), exemplified by ChatGPT, have gained considerable attention for their excellent natural language processing capabilities. Nonetheless, these LLMs present many challenges, particularly in the realm of trustworthiness. Therefore, ensuring the trustworthiness of LLMs emerges as an important topic. This paper introduces TrustLLM, a comprehensive study of trustworthiness in LLMs, including principles for different dimensions of trustworthiness, established benchmark, evaluation, and analysis of trustworthiness for mainstream LLMs, and discussion of open challenges and future directions. Specifically, we first propose a set of principles for trustworthy LLMs that span eight different dimensions. Based on these principles, we further establish a benchmark across six dimensions including truthfulness, safety, fairness, robustness, privacy, and machine ethics. We then present a study evaluating 16 mainstream LLMs in TrustLLM, consisting of over 30 datasets. Our find
    
[^56]: AI是否能像人类一样具备创造力？

    Can AI Be as Creative as Humans?. (arXiv:2401.01623v1 [cs.AI])

    [http://arxiv.org/abs/2401.01623](http://arxiv.org/abs/2401.01623)

    本文引入了一个新概念【相对创造力】，通过将焦点转向AI是否能够与人类具备相同的创造能力，实现对创造力的统计量化评估和直接比较。

    

    创造力是社会进步和创新的基石，但其评估仍然是一个复杂且主观的任务。随着先进的生成型AI模型的出现，能够完成曾经只属于人类创造力的任务，探索AI的创造潜力变得至关重要，以确保其负责任的发展和应用。本文通过引入一个名为“相对创造力”的新概念来解决定义和评估创造力的复杂性。我们不再试图对创造力进行普遍定义，而是将焦点转向AI是否能够与一位假设的人类具备相同的创造能力。这种观点借鉴了图灵测试的思想，并扩展其范围以解决评估创造力中所固有的挑战和主观性。这种方法的转变使得对AI创造力的统计量化评估成为可能，我们将其称为统计创造力。这种方法允许直接比较AI与特定人类的创造能力。

    Creativity serves as a cornerstone for societal progress and innovation, but its assessment remains a complex and often subjective endeavor. With the rise of advanced generative AI models capable of tasks once reserved for human creativity, the study of AI's creative potential becomes imperative for its responsible development and application. This paper addresses the complexities in defining and evaluating creativity by introducing a new concept called Relative Creativity. Instead of trying to define creativity universally, we shift the focus to whether AI can match the creative abilities of a hypothetical human. This perspective draws inspiration from the Turing Test, expanding upon it to address the challenges and subjectivities inherent in evaluating creativity. This methodological shift facilitates a statistically quantifiable evaluation of AI's creativity, which we term Statistical Creativity. This approach allows for direct comparisons of AI's creative abilities with those of sp
    
[^57]: 通过复杂逻辑假设生成在知识图谱中推进诱导推理

    Advancing Abductive Reasoning in Knowledge Graphs through Complex Logical Hypothesis Generation. (arXiv:2312.15643v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2312.15643](http://arxiv.org/abs/2312.15643)

    这篇论文介绍了一种复杂逻辑假设生成的任务，作为实现与知识图谱的诱导逻辑推理的初始步骤。研究发现，过监督训练的生成模型可以生成结构上更接近参考假设的逻辑假设。为了解决推广到未见过观察结果的问题，引入了基于知识图谱的强化学习方法（RLF-KG），最小化观察结果与结论之间的差异。

    

    诱导推理是通过做出有根据的猜测来解释观察结果的过程。尽管许多应用需要使用知识进行解释，但将诱导推理与结构化知识（如知识图谱）结合使用的方法仍然尚未得到广泛探索。为了填补这一空白，本文介绍了复杂逻辑假设生成的任务，作为实现与知识图谱的诱导逻辑推理的初始步骤。在这个任务中，我们的目标是生成一个复杂的逻辑假设，以解释一组观察结果。我们发现，经过监督训练的生成模型可以生成结构上更接近参考假设的逻辑假设。然而，当推广到未见过的观察结果时，这种训练目标并不能保证更好的假设生成。为了解决这个问题，我们引入了基于知识图谱的强化学习方法（RLF-KG），该方法最小化观察结果与结论之间的差异。

    Abductive reasoning is the process of making educated guesses to provide explanations for observations. Although many applications require the use of knowledge for explanations, the utilization of abductive reasoning in conjunction with structured knowledge, such as a knowledge graph, remains largely unexplored. To fill this gap, this paper introduces the task of complex logical hypothesis generation, as an initial step towards abductive logical reasoning with KG. In this task, we aim to generate a complex logical hypothesis so that it can explain a set of observations. We find that the supervised trained generative model can generate logical hypotheses that are structurally closer to the reference hypothesis. However, when generalized to unseen observations, this training objective does not guarantee better hypothesis generation. To address this, we introduce the Reinforcement Learning from Knowledge Graph (RLF-KG) method, which minimizes differences between observations and conclusio
    
[^58]: 一种用于加速RLHF训练的自适应部署和并行框架

    An Adaptive Placement and Parallelism Framework for Accelerating RLHF Training. (arXiv:2312.11819v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.11819](http://arxiv.org/abs/2312.11819)

    提出了一种自适应模型部署和并行框架，用于加速RLHF训练。该框架提供了两种灵活的模型部署策略，其中交替策略有助于减少内存冗余和通信成本。

    

    最近，像ChatGPT或InstructGPT这样的大型语言模型（LLM）在人工智能领域产生了重大影响。许多研究尝试复现复杂的InstructGPT的训练流程，即基于人类反馈的强化学习（RLHF）。然而，主流的分布式RLHF训练方法通常采用固定的模型部署策略，称为Flattening策略。该策略将RLHF中涉及的四个相互依赖的模型视为单个实体，将它们分配到所有设备上，并应用于单个模型设计的并行技术，而不考虑每个模型固有的不同工作负载。结果，该策略加剧了RLHF训练中的生成瓶颈，并降低了整体训练效率。为了解决这些问题，我们提出了一种自适应模型部署框架，提供了两种灵活的模型部署策略。交替策略有助于减少内存冗余和通信成本。

    Recently, ChatGPT or InstructGPT like large language models (LLM) has made a significant impact in the AI world. Many works have attempted to reproduce the complex InstructGPT's training pipeline, namely Reinforcement Learning with Human Feedback (RLHF). However, the mainstream distributed RLHF training methods typically adopt a fixed model placement strategy, referred to as the Flattening strategy. This strategy treats all four interdependent models involved in RLHF as a single entity, distributing them across all devices and applying parallelism techniques designed for a single model, regardless of the different workloads inherent to each model. As a result, this strategy exacerbates the generation bottlenecks in the RLHF training and degrades the overall training efficiency. To address these issues, we propose an adaptive model placement framework that offers two flexible model placement strategies. The Interleaving strategy helps reduce memory redundancy and communication costs of 
    
[^59]: 使用基础模型进行推理的调查

    A Survey of Reasoning with Foundation Models. (arXiv:2312.11562v5 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2312.11562](http://arxiv.org/abs/2312.11562)

    本文调查了使用基础模型进行推理的研究，介绍了最新的推理任务、方法和基准，并讨论了基础模型中推理能力的未来发展方向。

    

    推理是复杂问题解决的关键能力，在谈判、医学诊断和刑事调查等各种现实世界环境中起着重要作用。它在人工通用智能（AGI）领域中作为一种基本方法学。随着基础模型（如大型语言模型）的不断发展，越来越多的研究者对它们在推理任务中的能力产生了兴趣。在本文中，我们介绍了用于推理的开创性基础模型，并突出了各种推理任务、方法和基准的最新进展。我们还深入探讨了基础模型中推理能力的潜在未来发展方向，并讨论了多模式学习、自主代理和超级对齐在推理背景下的相关性。通过讨论这些未来研究方向，我们希望激发研究者们在这一领域的探索，推动进一步的发展。

    Reasoning, a crucial ability for complex problem-solving, plays a pivotal role in various real-world settings such as negotiation, medical diagnosis, and criminal investigation. It serves as a fundamental methodology in the field of Artificial General Intelligence (AGI). With the ongoing development of foundation models, e.g., Large Language Models (LLMs), there is a growing interest in exploring their abilities in reasoning tasks. In this paper, we introduce seminal foundation models proposed or adaptable for reasoning, highlighting the latest advancements in various reasoning tasks, methods, and benchmarks. We then delve into the potential future directions behind the emergence of reasoning abilities within foundation models. We also discuss the relevance of multimodal learning, autonomous agents, and super alignment in the context of reasoning. By discussing these future research directions, we hope to inspire researchers in their exploration of this field, stimulate further advance
    
[^60]: 情绪分类中的主题偏差

    Topic Bias in Emotion Classification. (arXiv:2312.09043v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.09043](http://arxiv.org/abs/2312.09043)

    本文研究了情绪分类中的主题偏差问题，发现情绪语料库中的主题与情绪实际上具有相关性，并且情绪分类器容易受到这些主题的干扰。最后，研究者展示了一种去偏差的方法可以减轻主题偏差的影响。

    

    情绪语料库通常是基于关键词/标签搜索或通过询问研究参与者生成文本实例来采样的。无论哪种情况，这些语料库都不是代表领域整体的均匀样本。我们假设这种数据获取方式导致了这些语料库中过度呈现的主题之间不切实际的相关性，从而损害了模型的泛化能力。这种主题偏差可能会导致错误的预测，例如对于实例"I organized the service for my aunt's funeral."，尽管与悲伤情绪标记的实例中的葬礼事件过度呈现，但更适合的情绪是自豪。在本文中，我们从数据和建模角度研究了这种主题偏差。我们首先通过主题建模自动标记了一组情绪语料库，并展示了情绪实际上与特定主题相关。此外，我们发现情绪分类器受到这些主题的干扰。最后，我们展示了已建立的去偏差方法可以减轻主题偏差的影响。

    Emotion corpora are typically sampled based on keyword/hashtag search or by asking study participants to generate textual instances. In any case, these corpora are not uniform samples representing the entirety of a domain. We hypothesize that this practice of data acquisition leads to unrealistic correlations between overrepresented topics in these corpora that harm the generalizability of models. Such topic bias could lead to wrong predictions for instances like "I organized the service for my aunt's funeral." when funeral events are over-represented for instances labeled with sadness, despite the emotion of pride being more appropriate here. In this paper, we study this topic bias both from the data and the modeling perspective. We first label a set of emotion corpora automatically via topic modeling and show that emotions in fact correlate with specific topics. Further, we see that emotion classifiers are confounded by such topics. Finally, we show that the established debiasing met
    
[^61]: Fine-Tuning还是检索？比较在LLMs中的知识注入

    Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs. (arXiv:2312.05934v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2312.05934](http://arxiv.org/abs/2312.05934)

    该研究比较了无监督的微调和检索增强生成（RAG）这两种常见方法在LLMs中的应用。结果发现，RAG在现有知识和新知识上表现出更好的性能，而LLMs通过无监督的微调学习新的事实信息较困难。

    

    大型语言模型（LLMs）在其预训练的权重中封装了大量的事实信息，正如它们能够在不同领域回答各种问题所证明的那样。然而，这种知识本质上是有限的，很大程度上依赖于训练数据的特性。因此，使用外部数据集来整合新的信息或改进LLMs在已见信息上的能力面临着重大挑战。在这个研究中，我们比较了两种常见的方法：无监督的微调和检索增强生成（RAG）。我们在不同主题的各种知识密集型任务上评估了这两种方法。我们的发现表明，虽然无监督的微调能够提供一定的改进，但RAG在现有知识和完全新知识上始终表现出更好的性能。此外，我们发现LLMs很难通过无监督的微调来学习新的事实信息，并且暴露

    Large language models (LLMs) encapsulate a vast amount of factual information within their pre-trained weights, as evidenced by their ability to answer diverse questions across different domains. However, this knowledge is inherently limited, relying heavily on the characteristics of the training data. Consequently, using external datasets to incorporate new information or refine the capabilities of LLMs on previously seen information poses a significant challenge. In this study, we compare two common approaches: unsupervised fine-tuning and retrieval-augmented generation (RAG). We evaluate both approaches on a variety of knowledge-intensive tasks across different topics. Our findings reveal that while unsupervised fine-tuning offers some improvement, RAG consistently outperforms it, both for existing knowledge encountered during training and entirely new knowledge. Moreover, we find that LLMs struggle to learn new factual information through unsupervised fine-tuning, and that exposing
    
[^62]: 通过词汇多样性和差异的比较研究，增强任务导向对话中的闲聊

    Enhancing Task-Oriented Dialogues with Chitchat: a Comparative Study Based on Lexical Diversity and Divergence. (arXiv:2311.14067v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.14067](http://arxiv.org/abs/2311.14067)

    本研究通过比较分析了三种闲聊增强方法，旨在确定在多样性方面最有效的方法，并量化了添加的闲聊与原始任务导向语言和常见闲聊数据集之间的差异。研究结果强调了超越任务范围，实现更加多样化和自然交流的对话的重要性。

    

    作为最新的发展，为了使对话更加多样化和引人入胜，任务导向对话（TODs）已经与闲聊结合。这种增强对TODs特别有价值，因为TODs通常局限于狭窄的领域，从而使消除重复和可预测的回答成为一项重大挑战。本文通过比较分析了三种闲聊增强方法，并旨在确定在多样性方面最有效的方法。此外，我们量化了添加的闲聊、原始任务导向语言以及典型闲聊数据集中的闲聊之间的差异，并突出了每种比较的前20个差异关键词。我们的研究结果对于讨论未来增强TODs的方法具有指导意义，强调了超越任务范围，实现更加多样化和自然交流的对话的重要性。

    As a recent development, task-oriented dialogues (TODs) have been enriched with chitchat in an effort to make dialogues more diverse and engaging. This enhancement is particularly valuable as TODs are often confined to narrow domains, making the mitigation of repetitive and predictable responses a significant challenge. This paper presents a comparative analysis of three chitchat enhancements, aiming to identify the most effective approach in terms of diversity. Additionally, we quantify the divergence between the added chitchat, the original task-oriented language, and chitchat typically found in chitchat datasets, highlighting the top 20 divergent keywords for each comparison. Our findings drive a discussion on future enhancements for augmenting TODs, emphasizing the importance of grounding dialogues beyond the task to achieve more diverse and natural exchanges.
    
[^63]: 通用短语去偏器：在多标记级别上消除掩码语言模型中的偏见

    General Phrase Debiaser: Debiasing Masked Language Models at a Multi-Token Level. (arXiv:2311.13892v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.13892](http://arxiv.org/abs/2311.13892)

    本文提出了一种名为“通用短语去偏器”的自动多标记去偏管道，能够有效减轻掩码语言模型中的短语级别偏见，并在标准数据集和指标上取得了最新成果。

    

    预训练语言模型所揭示的社会偏见和不受欢迎的刻板印象正在成为其应用的障碍。与针对词级别的众多去偏方法相比，对于短语级别的偏见关注相对较少，限制了学科领域去偏的性能。在本文中，我们提出了一种名为“通用短语去偏器”的自动多标记去偏管道，能够减轻掩码语言模型中的短语级别偏见。具体而言，我们的方法包括一个“短语过滤阶段”，从维基百科页面中生成刻板印象的短语，以及一个“模型去偏阶段”，可以在多标记级别上去偏模型以应对短语上的偏见挑战。后者寻找触发模型偏见的提示，然后将其用于去偏。标准数据集和评估指标上的最新成果表明，我们的方法可以显著减少职业和加强性别偏见。

    The social biases and unwelcome stereotypes revealed by pretrained language models are becoming obstacles to their application. Compared to numerous debiasing methods targeting word level, there has been relatively less attention on biases present at phrase level, limiting the performance of debiasing in discipline domains. In this paper, we propose an automatic multi-token debiasing pipeline called \textbf{General Phrase Debiaser}, which is capable of mitigating phrase-level biases in masked language models. Specifically, our method consists of a \textit{phrase filter stage} that generates stereotypical phrases from Wikipedia pages as well as a \textit{model debias stage} that can debias models at the multi-token level to tackle bias challenges on phrases. The latter searches for prompts that trigger model's bias, and then uses them for debiasing. State-of-the-art results on standard datasets and metrics show that our approach can significantly reduce gender biases on both career and 
    
[^64]: AGI系统的元提示

    Meta Prompting for AGI Systems. (arXiv:2311.11482v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2311.11482](http://arxiv.org/abs/2311.11482)

    本文全面研究了元提示技术，这是一种创新方法，重塑了大型语言模型、多模态模型和人工智能系统在问题解决和数据解释方面的应用。通过强调信息的结构和句法，元提示将复杂问题拆解为简单的子问题，提高了效率，并且能够与少样本方法进行公平的比较。同时，本文还提出了元提示用于自动生成提示的方法。

    

    本文介绍了元提示(meta prompting)的全面研究，这是一种创新技术，重新塑造了大型语言模型(LLMs)、多模态基础模型和人工智能系统在问题解决和数据解释方面的利用。基于类型理论和范畴论，元提示注重信息的结构和句法，而不是传统以内容为中心的方法。本文探讨了元提示的形式定义，并将其与少样本提示(few-shot prompting)区分开来，并强调其在各种人工智能应用中的有效性。重点关注将元提示扩展到复杂推理任务上，展示如何将复杂问题拆分成较为简单的子问题，提高令牌效率，并使问题求解的比较更加公平，尤其是与少样本示例方法相比。此外，本文还引入了元提示用于提示任务，允许LLMs以迭代的元编程形式自动生成新的提示。

    This paper presents a comprehensive study of Meta Prompting, an innovative technique reshaping the utilization of large language models (LLMs), multi-modal foundation models, and AI systems in problem-solving and data interpretation. Grounded in type theory and category theory, Meta Prompting emphasizes the structure and syntax of information over traditional content-centric methods. The paper explores the formal definitions of Meta Prompting (MP), sets it apart from Few-Shot Prompting, and underlines its effectiveness in various AI applications. A key focus is on extending Meta Prompting to complex reasoning tasks, showing how it effectively deconstructs intricate problems into simpler sub-problems, enhancing token efficiency and enabling more equitable problem-solving comparisons, especially against few-shot example methods. Additionally, the paper introduces Meta Prompting for Prompting Tasks, allowing LLMs to self-generate new prompts in an iterative, metaprogramming-like manner. T
    
[^65]: 利用大型语言模型进行集体决策

    Leveraging Large Language Models for Collective Decision-Making. (arXiv:2311.04928v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.04928](http://arxiv.org/abs/2311.04928)

    本论文提出了一种利用大型语言模型（LLM）促进集体决策的系统，通过管理对话和平衡个人偏好来提供满足成员需求的选项，实现高效协调并不断优化系统性能。

    

    在各种工作环境中，如会议安排、合作和项目规划中，集体决策是必不可少的，但由于个体偏好多样性、工作焦点不同和成员之间的权力动态等因素，常常具有挑战性。为了解决这个问题，我们提出了一种利用大型语言模型（LLM）来促进群体决策的系统，通过管理对话和平衡个人偏好来实现。我们的系统旨在从对话中提取个体偏好，并提出满足成员偏好的选项。我们特别将此系统应用于企业会议安排。我们利用LLM创建了合成员工配置文件，并模拟了大规模的对话，通过利用LLM评估系统表现来作为开展用户研究的新方法。我们的结果表明，系统能实现成员与LLM系统之间的高效协调，并随着时间的推移对其提出的选项进行改进和完善，确保优化系统性能。

    In various work contexts, such as meeting scheduling, collaborating, and project planning, collective decision-making is essential but often challenging due to diverse individual preferences, varying work focuses, and power dynamics among members. To address this, we propose a system leveraging Large Language Models (LLMs) to facilitate group decision-making by managing conversations and balancing preferences among individuals. Our system aims to extract individual preferences from conversations and suggest options that satisfy the preferences of the members. We specifically apply this system to corporate meeting scheduling. We create synthetic employee profiles and simulate conversations at scale, leveraging LLMs to evaluate the system performance as a novel approach to conducting a user study. Our results indicate efficient coordination with reduced interactions between the members and the LLM-based system. The system refines and improves its proposed options over time, ensuring that
    
[^66]: 通过元学习实现大规模语言模型的大规模编辑

    Massive Editing for Large Language Models via Meta Learning. (arXiv:2311.04661v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.04661](http://arxiv.org/abs/2311.04661)

    本论文提出了一种通过元学习实现大规模语言模型的大规模编辑的方法。该方法利用超网络来生成参数变化，通过解决最小二乘问题来更新语言模型的参数。通过将计算分离在超网络和语言模型之间，使得可以同时编辑多个事实。该方法在不同架构的语言模型上进行了评估。

    

    虽然大规模语言模型（LLM）通过对预训练语料库学习知识成为可能，但所获得的知识随着时间的推移可能是基本不正确或过时的，这需要在训练后纠正语言模型（LM）的知识。一种有前景的方法是利用超网络生成参数偏移，然而现有的超网络在同步编辑操作数量方面存在扩展性不足的问题。为解决这个问题，我们提出了大规模语言模型编辑网络（MALMEN），它将参数偏移聚合形式化为最小二乘问题，并使用正规方程更新LM参数。为适应在有限内存预算下同时编辑多个事实，我们将超网络和LM上的计算分离，使得两个神经网络都可以具有任意批量大小。我们的方法通过对具有不同架构的LM（例如BERT-base）进行高达数千个事实的编辑进行了评估。

    While large language models (LLMs) have enabled learning knowledge from the pre-training corpora, the acquired knowledge may be fundamentally incorrect or outdated over time, which necessitates rectifying the knowledge of the language model (LM) after the training. A promising approach involves employing a hyper-network to generate parameter shift, whereas existing hyper-networks suffer from inferior scalability in synchronous editing operation amount. To mitigate the problem, we propose the MAssive Language Model Editing Network (MALMEN), which formulates the parameter shift aggregation as the least square problem, subsequently updating the LM parameters using the normal equation. To accommodate editing multiple facts simultaneously with limited memory budgets, we separate the computation on the hyper-network and LM, enabling arbitrary batch size on both neural networks. Our method is evaluated by editing up to thousands of facts on LMs with different architectures, i.e., BERT-base, G
    
[^67]: 简单模型也有效：基于课程学习策略的文本对话情感识别网络的新模型

    Simple Model Also Works: A Novel Emotion Recognition Network in Textual Conversation Based on Curriculum Learning Strategy. (arXiv:2308.06450v1 [cs.CL])

    [http://arxiv.org/abs/2308.06450](http://arxiv.org/abs/2308.06450)

    本研究提出了一种基于课程学习策略的新型Emotion Recognition Network (ERNetCL)模型，通过简化网络结构并充分建模上下文来高效地捕捉对话中的情感线索，实现了文本对话情感识别的性能优化。

    

    对话情感识别（ERC）已成为对话机器人和问答系统等领域的研究热点。如何高效地获取上下文中的情感线索一直是ERC任务中的关键挑战之一。现有的方法未能充分建模上下文，并采用复杂的网络结构，导致计算资源消耗过大而没有实质性的性能提升。在本文中，我们提出了一种基于课程学习策略的新型Emotion Recognition Network（ERNetCL）。该方法主要由Temporal Encoder（TE）、Spatial Encoder（SE）和Curriculum Learning（CL） loss组成。我们利用TE和SE以简洁的方式结合了以前方法的优点，以有效地捕捉对话中的时间和空间上下文信息。为了模拟人类从易到难的课程学习方式，我们将CL的思想应用到ERC任务中，逐步优化网络构架。

    Emotion Recognition in Conversation (ERC) has emerged as a research hotspot in domains such as conversational robots and question-answer systems. How to efficiently and adequately retrieve contextual emotional cues has been one of the key challenges in the ERC task. Existing efforts do not fully model the context and employ complex network structures, resulting in excessive computational resource overhead without substantial performance improvement. In this paper, we propose a novel Emotion Recognition Network based on Curriculum Learning strategy (ERNetCL). The proposed ERNetCL primarily consists of Temporal Encoder (TE), Spatial Encoder (SE), and Curriculum Learning (CL) loss. We utilize TE and SE to combine the strengths of previous methods in a simplistic manner to efficiently capture temporal and spatial contextual information in the conversation. To simulate the way humans learn curriculum from easy to hard, we apply the idea of CL to the ERC task to progressively optimize the ne
    
[^68]: 使用语言模型进行算术运算：从记忆到计算

    Arithmetic with Language Models: from Memorization to Computation. (arXiv:2308.01154v1 [cs.AI])

    [http://arxiv.org/abs/2308.01154](http://arxiv.org/abs/2308.01154)

    本研究探索了使用语言模型进行算术计算的能力，发现语言模型可以通过内部的值空间进行计算，并取得了成功的实验结果。

    

    更好地理解最近的大型语言模型的出现性计算和问题解决能力对于进一步改进它们并拓宽其适用性至关重要。本研究探讨了一个训练用于预测下一个标记的语言模型如何在训练数据之外执行算术计算。二进制加法和乘法是一个很好的测试基础，因为它们需要一个非常小的词汇表，并且在输入/输出上展示了相关的不连续性，使得对新数据进行平滑的输入插值无效。我们成功地训练了一个轻量级的语言模型来学习这些任务，并进行了一系列实验证明其外推能力和内部信息处理。我们的研究结果支持这样一个假设，即语言模型作为一个编码-回归-解码机器，一旦将输入标记表示映射到合适的内部值空间，计算就在值空间中进行。

    A better understanding of the emergent computation and problem-solving capabilities of recent large language models is of paramount importance to further improve them and broaden their applicability. This work investigates how a language model, trained to predict the next token, can perform arithmetic computations generalizing beyond training data. Binary addition and multiplication constitute a good testbed for this purpose, since they require a very small vocabulary and exhibit relevant input/output discontinuities making smooth input interpolation ineffective for novel data. We successfully trained a light language model to learn these tasks and ran a number of experiments to investigate the extrapolation capabilities and internal information processing. Our findings support the hypotheses that the language model works as an Encoding-Regression-Decoding machine where the computation takes place in the value space once the input token representation is mapped to an appropriate intern
    
[^69]: KoBBQ: 针对问答的韩国偏见基准

    KoBBQ: Korean Bias Benchmark for Question Answering. (arXiv:2307.16778v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.16778](http://arxiv.org/abs/2307.16778)

    本文介绍了KoBBQ，一个针对韩国文化的偏见基准数据集，提出了一个通用框架来解决数据集的文化适应性问题，并通过大规模调查收集和验证了反映韩国文化刻板印象的社会偏见和偏见目标。

    

    偏见问答的基准（BBQ）旨在评估语言模型（LMs）的社会偏见，但是将此基准适应于美国以外的文化背景并不简单，因为社会偏见在很大程度上取决于文化背景。本文介绍了KoBBQ，一个韩国偏见基准数据集，并提出了一个通用框架来解决数据集的文化适应性问题。我们的框架将BBQ数据集分为三类——简单转换（可以在文化翻译后直接使用）、目标修改（需要在目标群体中进行本地化）和样本删除（不适合韩国文化），并添加了四个针对韩国文化特定的偏见类别。我们进行了大规模调查，收集和验证了反映韩国文化刻板印象的社会偏见和偏见目标。最终的KoBBQ数据集包含了268个模板和76,048个样本，涵盖了12个社会分类。

    The Bias Benchmark for Question Answering (BBQ) is designed to evaluate social biases of language models (LMs), but it is not simple to adapt this benchmark to cultural contexts other than the US because social biases depend heavily on the cultural context. In this paper, we present KoBBQ, a Korean bias benchmark dataset, and we propose a general framework that addresses considerations for cultural adaptation of a dataset. Our framework includes partitioning the BBQ dataset into three classes--Simply-Transferred (can be used directly after cultural translation), Target-Modified (requires localization in target groups), and Sample-Removed (does not fit Korean culture)-- and adding four new categories of bias specific to Korean culture. We conduct a large-scale survey to collect and validate the social biases and the targets of the biases that reflect the stereotypes in Korean culture. The resulting KoBBQ dataset comprises 268 templates and 76,048 samples across 12 categories of social b
    
[^70]: 无条件语音合成中的生成对抗网络中的解耦技术

    Disentanglement in a GAN for Unconditional Speech Synthesis. (arXiv:2307.01673v1 [eess.AS])

    [http://arxiv.org/abs/2307.01673](http://arxiv.org/abs/2307.01673)

    在无条件语音合成中，我们提出了一种名为ASGAN的解耦生成对抗网络模型，该模型借鉴了StyleGAN图像合成模型，并引入了一些新技术。通过学习解耦的潜在空间，ASGAN能够从潜在空间中合成逼真的语音，即使在小字典数据集上也能取得最新成果。

    

    我们是否能够开发一个模型，能够直接从潜在空间合成逼真的语音，而无需显式条件？尽管过去十年中进行了几次尝试，之前的对抗性和扩散性方法仍然难以实现，即使在小字典数据集上也是如此。为了解决这个问题，我们提出了AudioStyleGAN(ASGAN)——一种用于无条件语音合成的生成对抗网络，旨在学习一个解耦潜在空间。在StyleGAN系列图像合成模型的基础上构建ASGAN，它将采样噪声映射到一个解耦潜在向量，然后将其映射到一个音频特征序列，以在每一层中抑制信号混叠。为了成功训练ASGAN，我们引入了一些新技术，包括对自适应鉴别器增强的修改，使其以概率方式跳过鉴别器更新。我们将其应用于小字典的谷歌语音命令数字数据集上，在该数据集上实现了无条件语音合成方面的最新成果。

    Can we develop a model that can synthesize realistic speech directly from a latent space, without explicit conditioning? Despite several efforts over the last decade, previous adversarial and diffusion-based approaches still struggle to achieve this, even on small-vocabulary datasets. To address this, we propose AudioStyleGAN (ASGAN) -- a generative adversarial network for unconditional speech synthesis tailored to learn a disentangled latent space. Building upon the StyleGAN family of image synthesis models, ASGAN maps sampled noise to a disentangled latent vector which is then mapped to a sequence of audio features so that signal aliasing is suppressed at every layer. To successfully train ASGAN, we introduce a number of new techniques, including a modification to adaptive discriminator augmentation which probabilistically skips discriminator updates. We apply it on the small-vocabulary Google Speech Commands digits dataset, where it achieves state-of-the-art results in unconditional
    
[^71]: 自我监督的语音模型对单词的了解程度是什么？

    What do self-supervised speech models know about words?. (arXiv:2307.00162v1 [cs.CL])

    [http://arxiv.org/abs/2307.00162](http://arxiv.org/abs/2307.00162)

    通过对自我监督的语音模型进行分析，发现这些模型在不同层中编码了不同的语言信息，也学习了类似音素的子词单元。与单词相关的信息主要在中间的模型层中，同时一些低级信息在更高的层中也得以保留。

    

    在过去几年中，许多自我监督的语音模型（S3Ms）被引入，为各种语音任务提供了性能和数据效率的改进。有证据表明，不同的S3Ms在不同的层中编码语言信息，而且一些S3Ms似乎学习了类似于音素的子词单元。然而，这些模型捕捉更大的语言单元（如单词）的程度以及单词相关信息的编码位置仍然不清楚。在这项研究中，我们对来自三个S3Ms的不同层的单词片段表示进行了多种分析：wav2vec2、HuBERT和WavLM。我们利用规范相关分析（CCA），一种轻量级的分析工具，来衡量这些表示与单词级语言属性之间的相似性。我们发现最大的单词级语言内容往往出现在中间的模型层，而一些低级信息（如发音）也在更高的层中保留。

    Many self-supervised speech models (S3Ms) have been introduced over the last few years, producing performance and data efficiency improvements for a variety of speech tasks. Evidence is emerging that different S3Ms encode linguistic information in different layers, and also that some S3Ms appear to learn phone-like sub-word units. However, the extent to which these models capture larger linguistic units, such as words, and where word-related information is encoded, remains unclear. In this study, we conduct several analyses of word segment representations extracted from different layers of three S3Ms: wav2vec2, HuBERT, and WavLM. We employ canonical correlation analysis (CCA), a lightweight analysis tool, to measure the similarity between these representations and word-level linguistic properties. We find that the maximal word-level linguistic content tends to be found in intermediate model layers, while some lower-level information like pronunciation is also retained in higher layers 
    
[^72]: 用于具有不完整标注的文档级关系抽取的正负样本度量学习框架

    A Positive-Unlabeled Metric Learning Framework for Document-Level Relation Extraction with Incomplete Labeling. (arXiv:2306.14806v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.14806](http://arxiv.org/abs/2306.14806)

    我们提出了一种正负样本度量学习框架（P3M）用于具有不完整标注的文档级关系抽取，通过拉近实体嵌入和其对应关系嵌入的距离，同时使其与非类别关系嵌入的距离推远，以提高模型的泛化能力。

    

    文档级关系抽取的目标是识别跨多个句子的实体之间的关系。最近，文档级关系抽取中的不完整标注问题引起了越来越多的关注，一些研究采用正负样本学习等方法来解决这个问题，但仍有很大的改进空间。受此启发，我们提出了一种正样本增强和正样本混合的正负样本度量学习框架（P3M）。具体而言，我们将文档级关系抽取形式化为度量学习问题。我们旨在拉近实体对嵌入和它们对应的关系嵌入之间的距离，同时将它们与非类别关系嵌入的距离推远。此外，我们将正负样本学习方法应用于该损失目标。为了提高模型的泛化能力，我们使用了dropout来增加正样本，并提出了正-非类别混合方法。大量实验证明了P3M的改进效果。

    The goal of document-level relation extraction (RE) is to identify relations between entities that span multiple sentences. Recently, incomplete labeling in document-level RE has received increasing attention, and some studies have used methods such as positive-unlabeled learning to tackle this issue, but there is still a lot of room for improvement. Motivated by this, we propose a positive-augmentation and positive-mixup positive-unlabeled metric learning framework (P3M). Specifically, we formulate document-level RE as a metric learning problem. We aim to pull the distance closer between entity pair embedding and their corresponding relation embedding, while pushing it farther away from the none-class relation embedding. Additionally, we adapt the positive-unlabeled learning to this loss objective. In order to improve the generalizability of the model, we use dropout to augment positive samples and propose a positive-none-class mixup method. Extensive experiments show that P3M improve
    
[^73]: 系统级自然语言反馈

    System-Level Natural Language Feedback. (arXiv:2306.13588v1 [cs.CL])

    [http://arxiv.org/abs/2306.13588](http://arxiv.org/abs/2306.13588)

    本文提出了一个通用框架，用于解锁系统级别使用自然语言反馈的方法。我们展示了通过任务度量设计和语言模型提示设计，如何使用反馈在人工交互流程中形式化系统级别的设计决策，以便产生更好的模型，并展示了使用系统级别反馈和实例级别反馈的有效性。

    

    自然语言反馈包含了丰富的用户体验信息。现有研究聚焦于实例级别的方法，即将反馈用于细化特定例子，而忽略了其系统范围的应用。本文提出了一个通用框架，用于解锁系统级别使用自然语言反馈的方法。我们展示了如何使用反馈在人工交互流程中形式化系统级别的设计决策，以便产生更好的模型。具体而言，这是通过以下两方面实现的：(i) 任务度量设计; (ii) 用于改进模型响应的语言模型提示设计。我们进行了两项案例研究，来改进搜索查询生成和对话响应生成，展示了使用系统级别反馈的有效性。我们表明系统级别反馈和实例级别反馈的组合带来了进一步的收益，并且由人类撰写的实例级别反馈导致比GPT-3.5撰写的反馈更加扎实。

    Natural language (NL) feedback contains rich information about the user experience. Existing studies focus on an instance-level approach, where feedback is used to refine specific examples, disregarding its system-wide application. This paper proposes a general framework for unlocking the system-level use of NL feedback. We show how to use feedback to formalize system-level design decisions in a human-in-the-loop-process -- in order to produce better models. In particular this is done through: (i) metric design for tasks; and (ii) language model prompt design for refining model responses. We conduct two case studies of this approach for improving search query generation and dialog response generation, demonstrating the effectiveness of the use of system-level feedback. We show the combination of system-level feedback and instance-level feedback brings further gains, and that human written instance-level feedback results in more grounded refinements than GPT-3.5 written ones, underlying
    
[^74]: 统一大型语言模型和知识图谱: 一条路线图

    Unifying Large Language Models and Knowledge Graphs: A Roadmap. (arXiv:2306.08302v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.08302](http://arxiv.org/abs/2306.08302)

    本文提出了一个前瞻性的统一大型语言模型和知识图谱的路线图，通过三个框架：增强KGs的LLMs，知识增强KGs和LLMs与KGs的联合推理，综合利用两者的优点。

    

    大型语言模型（LLM）如ChatGPT和GPT4正在自然语言处理和人工智能领域掀起新的热潮，由于它们的突现能力和一般化能力。然而，LLM是黑盒模型，往往不能捕捉和获取实际知识。相比之下，知识图谱（KGs）如维基百科和华普则是明确存储丰富实际知识的结构化知识模型。KGs可以通过为推理和可解释性提供外部知识来增强LLMs。同时，KGs的构建困难，自然而然地演化，这挑战了现有的KGs方法来生成新事实并表示未见过的知识。因此，统一LLMs和KGs并同时利用它们的优点是有益的。本文介绍了一个前瞻性的统一LLMs和KGs的路线图。我们的路线图包括三个一般框架，即1）增强KGs的LLMs，它们将知识表示为LM的一部分，从而能够捕捉丰富的实体关系，2）知识增强KGs，它们将LLMs用作知识表示学习的优秀工具，3）LLMs与KGs的联合推理，其中LLMs和KGs相互增强，从而获得更准确的推理模型。

    Large language models (LLMs), such as ChatGPT and GPT4, are making new waves in the field of natural language processing and artificial intelligence, due to their emergent ability and generalizability. However, LLMs are black-box models, which often fall short of capturing and accessing factual knowledge. In contrast, Knowledge Graphs (KGs), Wikipedia and Huapu for example, are structured knowledge models that explicitly store rich factual knowledge. KGs can enhance LLMs by providing external knowledge for inference and interpretability. Meanwhile, KGs are difficult to construct and evolving by nature, which challenges the existing methods in KGs to generate new facts and represent unseen knowledge. Therefore, it is complementary to unify LLMs and KGs together and simultaneously leverage their advantages. In this article, we present a forward-looking roadmap for the unification of LLMs and KGs. Our roadmap consists of three general frameworks, namely, 1) KG-enhanced LLMs, which incorpo
    
[^75]: 低资源语音翻译的跨语言迁移学习

    Cross-Lingual Transfer Learning for Low-Resource Speech Translation. (arXiv:2306.00789v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.00789](http://arxiv.org/abs/2306.00789)

    提出了一种三步跨语言迁移学习框架，通过在现有框架中增加一步语义知识蒸馏，该方法有效地增强了自动语音翻译中从高资源语言到低资源语言的跨语言迁移能力，显著改善了翻译性能，特别是对于低资源语言，并减少了跨语言迁移间隙(TRFGap)。

    

    本文提出了一种新颖的三步跨语言迁移学习框架，用于增强自动语音翻译中从高资源语言到低资源语言的跨语言迁移能力。该方法将语义知识蒸馏步骤集成到现有的两步跨语言迁移学习框架XLS-R中。这一额外的步骤旨在通过使用无标签语音进行自监督学习来对多语言语音编码器进行预训练以编码语义知识。我们提出的三步跨语言迁移学习框架解决了XLS-R框架中高资源语言和低资源语言之间存在的大的跨语言迁移差距。我们通过在CoVoST-2基准测试上进行广泛实验和比较来验证我们的提议，结果显示在翻译性能方面取得了显著改进，特别是对于低资源语言，并且跨语言迁移间隙(TRFGap)有明显减少。

    The paper presents a novel three-step transfer learning framework for enhancing cross-lingual transfer from high- to low-resource languages in the downstream application of Automatic Speech Translation. The approach integrates a semantic knowledge-distillation step into the existing two-step cross-lingual transfer learning framework XLS-R. This extra step aims to encode semantic knowledge in the multilingual speech encoder pre-trained via Self-Supervised Learning using unlabeled speech. Our proposed three-step cross-lingual transfer learning framework addresses the large cross-lingual transfer gap (TRFGap) observed in the XLS-R framework between high-resource and low-resource languages. We validate our proposal through extensive experiments and comparisons on the CoVoST-2 benchmark, showing significant improvements in translation performance, especially for low-resource languages, and a notable reduction in the TRFGap.
    
[^76]: OpenPI2.0: 一种用于实体追踪的改进数据集

    OpenPI2.0: An Improved Dataset for Entity Tracking in Texts. (arXiv:2305.14603v1 [cs.CL])

    [http://arxiv.org/abs/2305.14603](http://arxiv.org/abs/2305.14603)

    OpenPI2.0是一个用于实体追踪的改进数据集，它包括规范化实体、显著性注释和下游应用调查等特点。

    

    将文本表示为实体信息一直被认为在事件推理中非常有效。我们提出了OpenPI2.0，这是一个用于追踪程序性文本中实体状态的改进数据集。OpenPI2.0不仅具有规范化实体以促进评估，还包括涵盖人工标签和自动预测的显著性注释。关于实体显著性，我们提供了有关注释主观性、建模可行性以及在问题回答和经典计划等任务中的下游应用的调查。

    Representing texts as information about entities has long been deemed effective in event reasoning. We propose OpenPI2.0, an improved dataset for tracking entity states in procedural texts. OpenPI2.0 features not only canonicalized entities that facilitate evaluation, but also salience annotations including both manual labels and automatic predictions. Regarding entity salience, we provide a survey on annotation subjectivity, modeling feasibility, and downstream applications in tasks such as question answering and classical planning.
    
[^77]: 民主扩散语言模型

    Democratized Diffusion Language Model. (arXiv:2305.10818v1 [cs.LG])

    [http://arxiv.org/abs/2305.10818](http://arxiv.org/abs/2305.10818)

    本文提出了一个基于CDCD框架的民主扩散语言模型（DDLM），并通过GLUE基准测试了其知识转移能力，为研究人员提供了DDLM训练和评估流程以及已训练的DDLM模型。

    

    尽管扩散模型在自然语言处理中有潜在好处，但目前公开的实现、训练模型或可重现的训练程序并不存在。为解决这些挑战，我们提出了基于CDCD框架的民主扩散语言模型（DDLM）。我们提出了一种用C4数据集简化的DDLM训练流程，并对训练模型的行为进行了深入分析。此外，我们引入了一种用于速度更快的采样的新型早期退出策略，该策略针对使用得分插值训练的模型。由于此前没有研究旨在使用预训练扩散LM解决下游任务（例如分类任务），我们在GLUE基准上进行了实验，以研究DDLM的知识转移能力。通过本文，我们提出了可供其他研究人员使用的DDLM训练和评估流程以及预先训练的DDLM模型，这些模型可在未来的D相关的研究中使用。

    Despite the potential benefits of Diffusion Models for NLP applications, publicly available implementations, trained models, or reproducible training procedures currently need to be publicly available. We present the Democratized Diffusion Language Model (DDLM), based on the Continuous Diffusion for Categorical Data (CDCD) framework, to address these challenges. We propose a simplified training procedure for DDLM using the C4 dataset and perform an in-depth analysis of the trained model's behavior. Furthermore, we introduce a novel early-exiting strategy for faster sampling with models trained with score interpolation. Since no previous works aimed at solving downstream tasks with pre-trained Diffusion LM (e.g., classification tasks), we experimented with GLUE Benchmark to study the ability of DDLM to transfer knowledge. With this paper, we propose available training and evaluation pipelines to other researchers and pre-trained DDLM models, which could be used in future research with D
    
[^78]: 基于Transformer的零样本和少样本生物医学命名实体识别方法

    A transformer-based method for zero and few-shot biomedical named entity recognition. (arXiv:2305.04928v1 [cs.CL])

    [http://arxiv.org/abs/2305.04928](http://arxiv.org/abs/2305.04928)

    本文提出了一种基于Transformer的生物医学领域零样本和少样本NER方法。此方法利用预训练学习给定和潜在类别之间的语义关系，将多类标记分类任务转换为二元标记分类，能够在不同数量的样本情况下达到良好的识别效果。

    

    在生物医学领域中，有监督的命名实体识别（NER）依赖于具有给定命名实体的大量注释文本，其创建可能耗时且昂贵。此外，提取新实体通常需要进行额外的注释任务和重新训练模型。为解决这些挑战，本文提出了一种基于Transformer的生物医学领域零样本和少样本NER方法。该方法基于将多类标记分类任务转换为二元标记分类（标记包含搜索的实体或不包含搜索的实体），并在更多的数据集和生物医学实体上进行预训练，从而可学习到给定和潜在类别之间的语义关系。在9种不同的生物医学实体上，我们在零样本NER、一次样本NER、10次样本NER和100次样本NER上实现了平均F1得分分别为35.44％、50.10％、69.94％和79.51％。

    Supervised named entity recognition (NER) in the biomedical domain is dependent on large sets of annotated texts with the given named entities, whose creation can be time-consuming and expensive. Furthermore, the extraction of new entities often requires conducting additional annotation tasks and retraining the model. To address these challenges, this paper proposes a transformer-based method for zero- and few-shot NER in the biomedical domain. The method is based on transforming the task of multi-class token classification into binary token classification (token contains the searched entity or does not contain the searched entity) and pre-training on a larger amount of datasets and biomedical entities, from where the method can learn semantic relations between the given and potential classes. We have achieved average F1 scores of 35.44% for zero-shot NER, 50.10% for one-shot NER, 69.94% for 10-shot NER, and 79.51% for 100-shot NER on 9 diverse evaluated biomedical entities with PubMed
    
[^79]: 利用ChatGPT进行零样本临床实体识别

    Zero-shot Clinical Entity Recognition using ChatGPT. (arXiv:2303.16416v1 [cs.CL])

    [http://arxiv.org/abs/2303.16416](http://arxiv.org/abs/2303.16416)

    本研究探讨了使用 ChatGPT 进行零样本临床实体识别任务，并发现 ChatGPT 在松弛匹配 F1 分数方面显著优于 GPT-3。虽然其性能仍低于 BioClinicalBERT 模型，但我们的研究表明了 ChatGPT 在零样本设置下有很大的临床 NER 任务潜力。

    

    本研究探讨了OpenAI开发的大型语言模型ChatGPT在2010年i2b2挑战中指定的临床命名实体识别任务中的潜力，使用两种不同的提示策略进行了零样本设置。同时，我们将其性能与GPT-3在类似的零样本设置下进行了比较，以及使用MTSamples的一组合成的临床笔记对BioClinicalBERT模型进行优化微调。研究结果显示，ChatGPT在零样本设置中表现优异，精确匹配和松弛匹配的F1分别为0.418（vs.0.250）和0.620（vs.0.480），相比之下，GPT-3的表现较差。另外，提示策略极大地影响了ChatGPT的性能，在两种不同提示策略下松弛匹配的F1分别为0.628和0.541。虽然ChatGPT的性能仍低于受监督的BioClinicalBERT模型（即松弛匹配F1分数分别为0.628和0.870），但我们的研究表明了ChatGPT在零样本设置下临床NER任务中的巨大潜力。

    In this study, we investigated the potential of ChatGPT, a large language model developed by OpenAI, for the clinical named entity recognition task defined in the 2010 i2b2 challenge, in a zero-shot setting with two different prompt strategies. We compared its performance with GPT-3 in a similar zero-shot setting, as well as a fine-tuned BioClinicalBERT model using a set of synthetic clinical notes from MTSamples. Our findings revealed that ChatGPT outperformed GPT-3 in the zero-shot setting, with F1 scores of 0.418 (vs.0.250) and 0.620 (vs. 0.480) for exact- and relaxed-matching, respectively. Moreover, prompts affected ChatGPT's performance greatly, with relaxed-matching F1 scores of 0.628 vs.0.541 for two different prompt strategies. Although ChatGPT's performance was still lower than that of the supervised BioClinicalBERT model (i.e., relaxed-matching F1 scores of 0.628 vs. 0.870), our study demonstrates the great potential of ChatGPT for clinical NER tasks in a zero-shot setting, 
    
[^80]: CultureBERT：使用基于Transformer的语言模型来衡量企业文化

    CultureBERT: Measuring Corporate Culture With Transformer-Based Language Models. (arXiv:2212.00509v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.00509](http://arxiv.org/abs/2212.00509)

    本文引入了基于Transformer的语言模型来衡量企业文化，通过对员工评价进行分类，相较于传统方法，语言模型在样本外预测中能提高17到30个百分点的准确率。

    

    本文将基于Transformer的语言模型引入到文献中，用于衡量企业文化的文本文档。我们编制了一个独特的员工评价数据集，并由人工评估者对这些评价进行标记，以了解这些评价对公司企业文化的揭示程度。利用这个数据集，我们对最先进的基于Transformer的语言模型进行微调，以执行相同的分类任务。在样本外的预测中，我们的语言模型将员工评价与人工评估者的分类一致性比传统的文本分类方法提高了17到30个百分点。我们将模型公开提供。

    This paper introduces transformer-based language models to the literature measuring corporate culture from text documents. We compile a unique data set of employee reviews that were labeled by human evaluators with respect to the information the reviews reveal about the firms' corporate culture. Using this data set, we fine-tune state-of-the-art transformer-based language models to perform the same classification task. In out-of-sample predictions, our language models classify 17 to 30 percentage points more of employee reviews in line with human evaluators than traditional approaches of text classification. We make our models publicly available.
    
[^81]: 大型语言模型在普通语言生成中的检索增强

    Retrieval augmentation of large language models for lay language generation. (arXiv:2211.03818v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.03818](http://arxiv.org/abs/2211.03818)

    CELLS是用于普通语言生成的最大最广泛的平行语料库，通过生成背景解释和简化原始摘要来解决普通语言生成中的关键挑战。

    

    最近的普通语言生成系统利用在平行语料库上训练的Transformer模型增加了健康信息的可访问性。然而，这些模型的适用性受到可用语料库的规模和主题广度的限制。我们介绍了CELLS，这是用于普通语言生成的最大（63k对）和最广泛涉及的（12个期刊）平行语料库。摘要和相应的普通语言摘要由领域专家撰写，确保了我们数据集的质量。此外，专家撰写的常规语言摘要的定性评估揭示了背景解释作为增加可访问性的关键策略。这种解释对于神经模型的生成来说具有挑战性，因为它不仅仅是简化，还添加了源数据中缺少的内容。我们从CELLS中衍生出两个专门的配对语料库，以解决普通语言生成中的关键挑战：生成背景解释和简化原始摘要。

    Recent lay language generation systems have used Transformer models trained on a parallel corpus to increase health information accessibility. However, the applicability of these models is constrained by the limited size and topical breadth of available corpora. We introduce CELLS, the largest (63k pairs) and broadest-ranging (12 journals) parallel corpus for lay language generation. The abstract and the corresponding lay language summary are written by domain experts, assuring the quality of our dataset. Furthermore, qualitative evaluation of expert-authored plain language summaries has revealed background explanation as a key strategy to increase accessibility. Such explanation is challenging for neural models to generate because it goes beyond simplification by adding content absent from the source. We derive two specialized paired corpora from CELLS to address key challenges in lay language generation: generating background explanations and simplifying the original abstract. We ado
    

