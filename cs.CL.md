# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Large Language Models to the Rescue: Reducing the Complexity in Scientific Workflow Development Using ChatGPT.](http://arxiv.org/abs/2311.01825) | 本研究调查了使用大型语言模型ChatGPT支持科学工作流时的效率。通过在两个科学领域进行三个用户研究，研究结果显示LLMs能够高效解释工作流，但在组件交换和有目的工作方面的性能较低。 |
| [^2] | [Support or Refute: Analyzing the Stance of Evidence to Detect Out-of-Context Mis- and Disinformation.](http://arxiv.org/abs/2311.01766) | 本研究提出了一种基于多模态证据的立场抽取网络（SEN）来检测上下文错误的误导信息。通过考虑不同证据的立场，我们提供了一种更准确的检测方法，并引入了基于共现关系的支持-反驳分数。这种方法在公共大规模数据上进行的实验证明了其有效性。 |
| [^3] | [PsyCoT: Psychological Questionnaire as Powerful Chain-of-Thought for Personality Detection.](http://arxiv.org/abs/2310.20256) | 提出一种名为PsyCoT的新颖个性检测方法，将心理问卷作为思维链条进行个性识别，并利用大型语言模型来增强对个性的合理推断能力。 |
| [^4] | [Generating Continuations in Multilingual Idiomatic Contexts.](http://arxiv.org/abs/2310.20195) | 本论文测试了生成性语言模型在多语种惯用语境中生成延续的能力，并发现模型在字面和惯用上下文中的表现相似，并且在两种语言中均具有鲁棒性。 |
| [^5] | [BioInstruct: Instruction Tuning of Large Language Models for Biomedical Natural Language Processing.](http://arxiv.org/abs/2310.19975) | BioInstruct是一个用于生物医学自然语言处理的大型语言模型指令调整方法，通过引入针对性指令数据集BioInstruct，通过GPT-4语言模型进行精调，优化了模型在生物医学自然语言处理中的性能。 |
| [^6] | [ArcheType: A Novel Framework for Open-Source Column Type Annotation using Large Language Models.](http://arxiv.org/abs/2310.18208) | ArcheType是一种使用大型语言模型进行开源列类型注释的新框架，通过改进上下文采样和标签重新映射，实现了全面的零样本解决方案。 |
| [^7] | [Disentangled Representation Learning with Large Language Models for Text-Attributed Graphs.](http://arxiv.org/abs/2310.18152) | 本文提出了一个名为Disentangled Graph-Text Learner (DGTL)的模型，通过引入定制的解缠图神经网络（GNN）层，使得大型语言模型（LLMs）能够更好地理解文本属性图（TAGs）中的复杂结构关系。 |
| [^8] | [Language and Mental Health: Measures of Emotion Dynamics from Text as Linguistic Biosocial Markers.](http://arxiv.org/abs/2310.17369) | 本研究首次研究了推文情绪动态和心理健康障碍之间的关系，发现推文情绪动态与用户自我披露的诊断有关，为心理健康的评估提供了新的方法。 |
| [^9] | [GlotLID: Language Identification for Low-Resource Languages.](http://arxiv.org/abs/2310.16248) | GlotLID-M是一个满足广泛覆盖、可靠性和效率要求的语言识别模型，具有1665个可识别语言，并在实验中表现出色。它解决了低资源LID面临的挑战，并有望提高数据集质量和增强访问能力。 |
| [^10] | [TRAMS: Training-free Memory Selection for Long-range Language Modeling.](http://arxiv.org/abs/2310.15494) | TRAMS是一种训练免费的长程语言建模记忆选择策略，它能够提高Transformer架构在长程语言建模方面的效果，并且不需要额外的训练或参数。 |
| [^11] | [Robust Training for Conversational Question Answering Models with Reinforced Reformulation Generation.](http://arxiv.org/abs/2310.13505) | 这项研究提出了一种新的框架REIGN，通过生成训练问题的改写，并使用深度强化学习来指导对话问答模型，增加模型对表面形式变化的鲁棒性，同时在不同的基准上进行零-shot应用。 |
| [^12] | [VIBE: Topic-Driven Temporal Adaptation for Twitter Classification.](http://arxiv.org/abs/2310.10191) | VIBE是一种解决Twitter分类中语言特征演变问题的模型，通过建模潜在主题演变以适应动态环境，并且在大规模Twitter实验中展现了良好的性能。 |
| [^13] | [Loose lips sink ships: Mitigating Length Bias in Reinforcement Learning from Human Feedback.](http://arxiv.org/abs/2310.05199) | 本文提出了一种创新的解决方案，通过应用“专家的乘积”（PoE）技术来减轻强化学习中的长度偏差问题。在这个框架中，主要的专家关注理解人类意图，而偏见专家则致力于识别和捕捉长度偏差。 |
| [^14] | [Enhancing Financial Sentiment Analysis via Retrieval Augmented Large Language Models.](http://arxiv.org/abs/2310.04027) | 本文通过引入检索增强型的大型语言模型框架，提升金融情感分析的效果，并解决了传统模型在参数规模和训练数据范围方面的限制。 |
| [^15] | [RA-DIT: Retrieval-Augmented Dual Instruction Tuning.](http://arxiv.org/abs/2310.01352) | 本论文介绍了一种轻量级的微调方法RA-DIT，通过为任何语言模型添加检索能力来提高性能。该方法分为两个步骤：一是更新语言模型以更好地利用检索到的信息，二是更新检索器以返回更相关的结果。实验证明每个步骤都能显著提高性能，同时使用两个步骤可以获得额外的收益。 |
| [^16] | [From Base to Conversational: Japanese Instruction Dataset and Tuning Large Language Models.](http://arxiv.org/abs/2309.03412) | 通过构建日语指令数据集并进行指令调整，验证了日语指令数据集的有效性，并表明通过指令调整可以提高下游任务的性能。 |
| [^17] | [Comparative Topic Modeling for Determinants of Divergent Report Results Applied to Macular Degeneration Studies.](http://arxiv.org/abs/2309.00312) | 本研究提出了一种比较话题建模方法，用于分析马克白彦病研究中存在矛盾结果的报告。通过对比不同话题与显著结果的相关性，找到了与黄斑变性研究中显著结果报告相关的八种化合物。 |
| [^18] | [Quantifying and Analyzing Entity-level Memorization in Large Language Models.](http://arxiv.org/abs/2308.15727) | 本研究提出了一种细粒度的、实体级的定义来量化大型语言模型中的记忆能力，并提出了一种高效提取敏感实体的方法。实验证明了语言模型在不同设置下重构敏感实体的能力。 |
| [^19] | [DS4DH at #SMM4H 2023: Zero-Shot Adverse Drug Events Normalization using Sentence Transformers and Reciprocal-Rank Fusion.](http://arxiv.org/abs/2308.12877) | 本文介绍了DS4DH在#SMM4H 2023中开发的不良药物事件规范化系统的性能评估，该系统利用句子转换和倒数排名融合进行零样本规范化。实验结果表明该方法在共享任务中表现优异，可有效应用于社交媒体文本挖掘中的不良药物事件规范化。 |
| [^20] | [Large Language Models in Cryptocurrency Securities Cases: Can ChatGPT Replace Lawyers?.](http://arxiv.org/abs/2308.06032) | 本研究探讨了在加密货币证券案件中，大型语言模型（LLMs）是否能够准确判断违法行为，并比较了由LLM和律师撰写的投诉书对陪审团决策的影响。研究发现，目前的LLMs在法律推理方面表现较弱，但随着未来模型的改进，其潜力有望提升。 |
| [^21] | [Predicting Perfect Quality Segments in MT Output with Fine-Tuned OpenAI LLM: Is it possible to capture editing distance patterns from historical data?.](http://arxiv.org/abs/2308.00158) | 本研究探讨了使用Fine-Tuned的OpenAI LLM进行翻译质量估计的能力，实验证明可以通过Fine-Tuned的ChatGPT来预测机器翻译的质量，但仍有改进的空间。 |
| [^22] | [A Theory for Emergence of Complex Skills in Language Models.](http://arxiv.org/abs/2307.15936) | 本文提出了一个统计框架，通过分析语言模型的交叉熵损失与基本语言任务的能力之间的关系，揭示了语言模型中复杂技能产生的机制。研究结果表明，通过扩展定律，预训练模型能够高效学习，并表现出违反通常泛化理论的能力。 |
| [^23] | [Turkish Native Language Identification.](http://arxiv.org/abs/2307.14850) | 这项研究首次将母语识别应用于土耳其语,通过分析作者不同语言的写作来预测作者的母语。研究使用了土耳其学习者语料库和三个句法特征来展示其有效性。 |
| [^24] | [EmotionPrompt: Leveraging Psychology for Large Language Models Enhancement via Emotional Stimulus.](http://arxiv.org/abs/2307.11760) | EmotionPrompt是一个基于心理学的方法，通过将情感刺激融入到提示中，提升了大型语言模型在各项任务上的性能，并且同时改善了其真实性和信息量。 |
| [^25] | [AlpaGasus: Training A Better Alpaca with Fewer Data.](http://arxiv.org/abs/2307.08701) | 这项研究提出了一种用于训练语言模型的数据筛选策略AlpaGasus，通过使用强大的语言模型过滤掉低质量数据，它在测试中表现出比原始模型更好的性能，并提供了更快的训练速度。 |
| [^26] | [A Novel Site-Agnostic Multimodal Deep Learning Model to Identify Pro-Eating Disorder Content on Social Media.](http://arxiv.org/abs/2307.06775) | 本研究创建了一个多模态深度学习模型，将文本和视觉数据相结合，能够准确识别社交媒体上的促进饮食紊乱的内容。最有效的模型是RoBERTa自然语言处理模型和MaxViT图像分类模型的融合模型，准确率和F1分数分别达到95.9%和0.959。 |
| [^27] | [Sparse Modular Activation for Efficient Sequence Modeling.](http://arxiv.org/abs/2306.11197) | 本论文引入了稀疏模块激活 (SMA) 机制，用于高效的序列建模。这种机制可以动态地稀疏激活序列元素的子模块，减少计算和内存消耗。 |
| [^28] | [Energy-Based Cross Attention for Bayesian Context Update in Text-to-Image Diffusion Models.](http://arxiv.org/abs/2306.09869) | 本论文提出了能量交叉注意力的EBM框架，通过更新和转移上下文向量，隐式最小化能量函数的嵌套层次，优化文本到图像扩散模型的语义对齐问题，实现零样本组合生成。 |
| [^29] | [Benchmarking Foundation Models with Language-Model-as-an-Examiner.](http://arxiv.org/abs/2306.04181) | 本文提出了一种新的基准测试框架，使用语言模型作为考官，可以无参考方式评估答案。这个框架解决了过去基准测试流程中的测试泄漏和评估自动化问题，并允许易于扩展，可以采用不同的语言模型作为考官。 |
| [^30] | [Exploring Hybrid Linguistic Features for Turkish Text Readability.](http://arxiv.org/abs/2306.03774) | 本文结合神经网络模型和各语言层面上的特征，开发出一种先进的土耳其文本可读性工具，发现了影响土耳其文本可读性的关键语言特征。 |
| [^31] | [SciLit: A Platform for Joint Scientific Literature Discovery, Summarization and Citation Generation.](http://arxiv.org/abs/2306.03535) | SciLit 是一个能够自动检索、摘要和引用相关论文的平台，它可以从数百万篇文献中高效地推荐论文，并提供具有上下文关联的引用句子。 |
| [^32] | [Evaluating Emotion Arcs Across Languages: Bridging the Global Divide in Sentiment Analysis.](http://arxiv.org/abs/2306.02213) | 本研究首次对自动生成的情感曲线进行了系统和定量的评估，并比较了机器学习模型和词典方法两种生成情感曲线的方式。通过在不同语言的多个数据集上进行实验，我们发现虽然词典方法在实例级情感分类方面表现较差，但在聚合信息时生成情感曲线的准确性非常高。此外，我们还展示了通过自动翻译英语情感词典，可以在资源较少的情况下生成高质量的情感曲线。 |
| [^33] | [Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective.](http://arxiv.org/abs/2305.15408) | 本文从理论层面探究了带有“思维链”提示的大型语言模型在解决基本数学和决策问题中的能力，发现自回归Transformer大小恒定即可解决任务，揭示了“思维链”提示的背后机制。 |
| [^34] | [Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples.](http://arxiv.org/abs/2305.15269) | 该研究使用OOD案例测试了大型语言模型的普遍演绎推理能力，并通过构建新的推理数据集进行了探究。研究结果表明，这些模型能够推广到更复杂的证明。 |
| [^35] | [Adapting Language Models to Compress Contexts.](http://arxiv.org/abs/2305.14788) | 本论文提出了一种将预训练的语言模型改进为自动压缩器的方法，能够将长篇文本压缩成紧凑的摘要向量，提高上下文的利用效率和降低计算成本，同时通过在上下文学习中的应用，证明了该方法能够提高精度并降低推断成本。 |
| [^36] | [Bridging Continuous and Discrete Spaces: Interpretable Sentence Representation Learning via Compositional Operations.](http://arxiv.org/abs/2305.14599) | 本文提出了InterSent框架，探索将不同的组合属性纳入句子嵌入空间中使嵌入变换变为组合句子操作，实现了可解释的句子表示学习。 |
| [^37] | [FOCUS: Effective Embedding Initialization for Specializing Pretrained Multilingual Models on a Single Language.](http://arxiv.org/abs/2305.14481) | 本文提出了FOCUS，在多语言源模型设置下，该方法使用重叠标记组合有效地初始化预训练的模型权重，提高了这种方法在适应新语言时的性能表现。 |
| [^38] | [ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models.](http://arxiv.org/abs/2305.14323) | 这项研究提出了一个基于工具增强的链式思维推理框架 ChatCoT，用于基于聊天的大型语言模型，通过聊天的方式实现多轮推理，巧妙地结合了思维链跟踪和工具操作的方法，提高了大型语言模型的推理能力。 |
| [^39] | [Let's Think Frame by Frame: Evaluating Video Chain of Thought with Video Infilling and Prediction.](http://arxiv.org/abs/2305.13903) | 该论文提出了一种新的研究方向 VideoCOT，利用视觉-语言模型的多模态生成能力，以增强视频推理，同时减少处理数百或数千帧的计算复杂度。在VIP数据集上，我们基于各种视觉-语言模型进行了基准测试，展示了使用视觉-语言模型进行VideoCOT的潜力。 |
| [^40] | [C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models.](http://arxiv.org/abs/2305.08322) | C-Eval是第一个专为中文基础模型评估而设计的全面套件，涵盖52个不同学科的多级别选择题和挑战性科目。评估结果表明，只有GPT-4能够达到超过60％的平均准确率，还有改进空间。 |
| [^41] | [Semantic Space Grounded Weighted Decoding for Multi-Attribute Controllable Dialogue Generation.](http://arxiv.org/abs/2305.02820) | 该文介绍了名为DASC的可控生成框架，它利用属性语义空间的加权解码来实现多属性生成，并能够在多个方面实现最先进的控制精度和高质量的生成响应。 |
| [^42] | [Approximating CKY with Transformers.](http://arxiv.org/abs/2305.02386) | 本文研究了Transformer模型逼近CKY算法的能力，提出了一种用梯度预测解析的方法，在标准基准测试中表现竞争力更好，同时速度更快。在随机PCFG下解析时，性能下降，但加入额外的归纳偏差是有帮助的。 |
| [^43] | [Safety Analysis in the Era of Large Language Models: A Case Study of STPA using ChatGPT.](http://arxiv.org/abs/2304.01246) | 本文研究了大型语言模型在系统论过程分析（STPA）中的应用，并采用ChatGPT对自动紧急制动（AEB）系统进行了案例研究。结果表明，重复双工交互方法是最有效的，并显着提高了STPA的质量。本研究证明，LLMs可以应用于安全分析，并为安全关键系统提供有价值的见解。 |
| [^44] | [An Experimental Study on Sentiment Classification of Moroccan dialect texts in the web.](http://arxiv.org/abs/2303.15987) | 本研究采用机器学习模型对YouTube评论中的摩洛哥方言进行情感分类，采用多种文本预处理和数据表示技术对文本进行分析，研究该方言的意见和情感表达。 |
| [^45] | [Is BERT Blind? Exploring the Effect of Vision-and-Language Pretraining on Visual Language Understanding.](http://arxiv.org/abs/2303.12513) | 本文调查了视觉语言预训练对仅文本任务的表现是否有提高。作者提出了一套视觉语言理解任务，证明了多模态训练的文本编码器在视觉推理方面的优越性。 |
| [^46] | [xCodeEval: A Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and Retrieval.](http://arxiv.org/abs/2303.03004) | xCodeEval是一个大规模多语言多任务的基准，用于评估预训练的大型语言模型生成、修复、翻译和检索代码的能力，并解决了以往仅关注特定任务和缺乏训练数据的问题。 |
| [^47] | [CiteBench: A benchmark for Scientific Citation Text Generation.](http://arxiv.org/abs/2212.09577) | CiteBench是一个科学引文文本生成基准测试，旨在解决研究加速导致的解读和总结先前工作的困难。该基准测试可以进行标准化评估，研究不同任务设计和领域的引文文本生成模型。对多个基线模型的大量测试发现了新的见解。 |
| [^48] | [Interpretable Sequence Classification Via Prototype Trajectory.](http://arxiv.org/abs/2007.01777) | ProtoryNet是一种基于原型轨迹的可解释深度神经网络，它通过捕捉时间模式和原型的近似程度来进行文本分类，并实现了直观和细致的推理过程解释。 |

# 详细

[^1]: 大型语言模型拯救行动：使用ChatGPT减少科学工作流开发的复杂性

    Large Language Models to the Rescue: Reducing the Complexity in Scientific Workflow Development Using ChatGPT. (arXiv:2311.01825v1 [cs.DC])

    [http://arxiv.org/abs/2311.01825](http://arxiv.org/abs/2311.01825)

    本研究调查了使用大型语言模型ChatGPT支持科学工作流时的效率。通过在两个科学领域进行三个用户研究，研究结果显示LLMs能够高效解释工作流，但在组件交换和有目的工作方面的性能较低。

    

    科学工作流系统越来越受欢迎，用于在大型数据集上表达和执行复杂的数据分析流程，因为它们通过在大型计算集群上的自动并行化提供了可复制性、可靠性和可扩展性的分析。然而，由于涉及许多黑盒工具和必要的深层基础设施栈，实现工作流非常困难。与此同时，用户支持工具很少，并且可用示例的数量远远低于传统编程语言。为了解决这些挑战，我们研究了大型语言模型（LLMs），特别是ChatGPT，在处理科学工作流时支持用户的效率。我们在两个科学领域进行了三个用户研究，评估了ChatGPT的理解、适应和扩展工作流的能力。我们的结果表明，LLMs可以有效解释工作流，但在交换组件或有目的的工作方面性能较低。

    Scientific workflow systems are increasingly popular for expressing and executing complex data analysis pipelines over large datasets, as they offer reproducibility, dependability, and scalability of analyses by automatic parallelization on large compute clusters. However, implementing workflows is difficult due to the involvement of many black-box tools and the deep infrastructure stack necessary for their execution. Simultaneously, user-supporting tools are rare, and the number of available examples is much lower than in classical programming languages. To address these challenges, we investigate the efficiency of Large Language Models (LLMs), specifically ChatGPT, to support users when dealing with scientific workflows. We performed three user studies in two scientific domains to evaluate ChatGPT for comprehending, adapting, and extending workflows. Our results indicate that LLMs efficiently interpret workflows but achieve lower performance for exchanging components or purposeful wo
    
[^2]: 支持还是反驳：分析证据立场以检测上下文错误的误导信息

    Support or Refute: Analyzing the Stance of Evidence to Detect Out-of-Context Mis- and Disinformation. (arXiv:2311.01766v1 [cs.CL])

    [http://arxiv.org/abs/2311.01766](http://arxiv.org/abs/2311.01766)

    本研究提出了一种基于多模态证据的立场抽取网络（SEN）来检测上下文错误的误导信息。通过考虑不同证据的立场，我们提供了一种更准确的检测方法，并引入了基于共现关系的支持-反驳分数。这种方法在公共大规模数据上进行的实验证明了其有效性。

    

    在线误导信息已经成为一个国家级的社会问题，是各种在线伤害的主要来源之一。其中一种常见的误导信息形式是上下文错误（OOC）信息，其中不同的信息被错误地关联起来，例如真实图像与虚假的文本标题或误导性的文本描述。尽管一些研究试图通过外部证据来抵御上下文错误的误导信息，但它们往往忽视了不同立场的不同证据的作用。受到证据立场代表不同检测结果的偏见的启发，我们提出了一种能够在统一框架中提取多模态证据的立场的立场抽取网络（SEN）。此外，我们还引入了基于命名实体的共现关系计算的支持-反驳分数到文本SEN中。对公共大规模数据的大量实验证明了我们的方法的有效性。

    Mis- and disinformation online have become a major societal problem as major sources of online harms of different kinds. One common form of mis- and disinformation is out-of-context (OOC) information, where different pieces of information are falsely associated, e.g., a real image combined with a false textual caption or a misleading textual description. Although some past studies have attempted to defend against OOC mis- and disinformation through external evidence, they tend to disregard the role of different pieces of evidence with different stances. Motivated by the intuition that the stance of evidence represents a bias towards different detection results, we propose a stance extraction network (SEN) that can extract the stances of different pieces of multi-modal evidence in a unified framework. Moreover, we introduce a support-refutation score calculated based on the co-occurrence relations of named entities into the textual SEN. Extensive experiments on a public large-scale data
    
[^3]: PsyCoT: 将心理问卷作为强大的思维链条用于个性检测

    PsyCoT: Psychological Questionnaire as Powerful Chain-of-Thought for Personality Detection. (arXiv:2310.20256v1 [cs.CL])

    [http://arxiv.org/abs/2310.20256](http://arxiv.org/abs/2310.20256)

    提出一种名为PsyCoT的新颖个性检测方法，将心理问卷作为思维链条进行个性识别，并利用大型语言模型来增强对个性的合理推断能力。

    

    最近大型语言模型（LLM）的进展，如ChatGPT，展示了在各种NLP任务中remarkable的零-shot表现。然而，LLM在个性检测方面的潜力，即通过写作文本来识别个体的个性，仍然未被充分探索。受到心理问卷的启发，心理问卷由心理学家精心设计，通过一系列有针对性的项目评估个体的个性特征，我们认为这些项目可以被视为一组良好结构化的思维链条过程。通过整合这些过程，LLM可以增强其从文本输入中对个性的合理推断能力。基于此，我们提出了一种新颖的个性检测方法，称为PsyCoT，它模仿个体以多轮对话方式完成心理问卷的方式。具体而言，我们将LLM作为一个在文本处理方向上具有专长的AI助手使用。

    Recent advances in large language models (LLMs), such as ChatGPT, have showcased remarkable zero-shot performance across various NLP tasks. However, the potential of LLMs in personality detection, which involves identifying an individual's personality from their written texts, remains largely unexplored. Drawing inspiration from Psychological Questionnaires, which are carefully designed by psychologists to evaluate individual personality traits through a series of targeted items, we argue that these items can be regarded as a collection of well-structured chain-of-thought (CoT) processes. By incorporating these processes, LLMs can enhance their capabilities to make more reasonable inferences on personality from textual input. In light of this, we propose a novel personality detection method, called PsyCoT, which mimics the way individuals complete psychological questionnaires in a multi-turn dialogue manner. In particular, we employ a LLM as an AI assistant with a specialization in tex
    
[^4]: 在多语种惯用语境下生成延续

    Generating Continuations in Multilingual Idiomatic Contexts. (arXiv:2310.20195v1 [cs.CL])

    [http://arxiv.org/abs/2310.20195](http://arxiv.org/abs/2310.20195)

    本论文测试了生成性语言模型在多语种惯用语境中生成延续的能力，并发现模型在字面和惯用上下文中的表现相似，并且在两种语言中均具有鲁棒性。

    

    处理惯用或字面多词表达是理解和生成任何语言的关键方面。为包含惯用（或字面）表达的叙述生成具有上下文相关的延续的任务可以让我们测试生成性语言模型（LMs）理解非组合性比喻文本的纤细语言能力。我们使用两种不同语言（英语和葡萄牙语）的数据集在三种不同的训练设置下（零样本、少样本和微调）进行了一系列实验。我们的结果表明，模型在生成字面上下文的延续时略优于惯用上下文，但差距很小。此外，本研究中研究的模型在两种语言中表现出同样出色的性能，表明生成模型在执行此任务时具有鲁棒性。

    The ability to process idiomatic or literal multiword expressions is a crucial aspect of understanding and generating any language. The task of generating contextually relevant continuations for narratives containing idiomatic (or literal) expressions can allow us to test the ability of generative language models (LMs) in understanding nuanced language containing non-compositional figurative text. We conduct a series of experiments using datasets in two distinct languages (English and Portuguese) under three different training settings (zero-shot, few-shot, and fine-tuned). Our results suggest that the models are only slightly better at generating continuations for literal contexts than idiomatic contexts, with exceedingly small margins. Furthermore, the models studied in this work perform equally well across both languages, indicating the robustness of generative models in performing this task.
    
[^5]: BioInstruct:用于生物医学自然语言处理的大型语言模型指令调整

    BioInstruct: Instruction Tuning of Large Language Models for Biomedical Natural Language Processing. (arXiv:2310.19975v1 [cs.CL])

    [http://arxiv.org/abs/2310.19975](http://arxiv.org/abs/2310.19975)

    BioInstruct是一个用于生物医学自然语言处理的大型语言模型指令调整方法，通过引入针对性指令数据集BioInstruct，通过GPT-4语言模型进行精调，优化了模型在生物医学自然语言处理中的性能。

    

    大型语言模型通过在大量数据上进行预训练，然后进行特定领域的指令调整，在许多自然语言处理任务中取得了巨大成功。然而，在生物医学领域只发表了很少的指令。为了解决这个问题，我们引入了BioInstruct，这是一个定制的任务特定指令数据集，包含超过25,000个示例。通过使用三个人工筛选的指令样本，以GPT-4语言模型作为提示，精调大型语言模型，我们旨在优化其在生物医学自然语言处理中的性能。我们对LLaMA LLMs (1&2,7B&13B)进行了指令调整，并在生物医学自然语言处理应用中进行了评估，包括信息提取、问答和文本生成。我们还评估了指令如何对模型性能的贡献，使用了多任务学习原则。

    Large language models (LLMs) has achieved a great success in many natural language processing (NLP) tasks. This is achieved by pretraining of LLMs on vast amount of data and then instruction tuning to specific domains. However, only a few instructions in the biomedical domain have been published. To address this issue, we introduce BioInstruct, a customized task-specific instruction dataset containing more than 25,000 examples. This dataset was generated attractively by prompting a GPT-4 language model with a three-seed-sample of 80 human-curated instructions. By fine-tuning LLMs using the BioInstruct dataset, we aim to optimize the LLM's performance in biomedical natural language processing (BioNLP). We conducted instruction tuning on the LLaMA LLMs (1\&2, 7B\&13B) and evaluated them on BioNLP applications, including information extraction, question answering, and text generation. We also evaluated how instructions contributed to model performance using multi-tasking learning principl
    
[^6]: ArcheType：一种使用大型语言模型进行开源列类型注释的新框架

    ArcheType: A Novel Framework for Open-Source Column Type Annotation using Large Language Models. (arXiv:2310.18208v1 [cs.CL])

    [http://arxiv.org/abs/2310.18208](http://arxiv.org/abs/2310.18208)

    ArcheType是一种使用大型语言模型进行开源列类型注释的新框架，通过改进上下文采样和标签重新映射，实现了全面的零样本解决方案。

    

    现有的深度学习方法在语义列类型注释（CTA）方面存在重要缺点：它们依赖于在训练时固定的语义类型；需要大量的每个类型的训练样本并产生大量运行时推断成本；即使类型保持不变，它们的性能也可能在评估新数据集时下降。大型语言模型在广泛的任务上展示了强大的零样本分类性能，本文探讨了它们在CTA中的应用。我们介绍了ArcheType，一种简单实用的方法，用于上下文采样、提示序列化、模型查询和标签重新映射，从而使大型语言模型能够完全以零样本方式解决列类型注释问题。我们分别对我们方法的每个组成部分进行了分析，并确定出改进上下文采样和标签重新映射提供了最一致的性能提升。

    Existing deep-learning approaches to semantic column type annotation (CTA) have important shortcomings: they rely on semantic types which are fixed at training time; require a large number of training samples per type and incur large run-time inference costs; and their performance can degrade when evaluated on novel datasets, even when types remain constant. Large language models have exhibited strong zero-shot classification performance on a wide range of tasks and in this paper we explore their use for CTA. We introduce ArcheType, a simple, practical method for context sampling, prompt serialization, model querying, and label remapping, which enables large language models to solve column type annotation problems in a fully zero-shot manner. We ablate each component of our method separately, and establish that improvements to context sampling and label remapping provide the most consistent gains. ArcheType establishes new state-of-the-art performance on both zero-shot and fine-tuned C
    
[^7]: 使用大型语言模型进行文本属性图的解缠表征学习

    Disentangled Representation Learning with Large Language Models for Text-Attributed Graphs. (arXiv:2310.18152v1 [cs.CL])

    [http://arxiv.org/abs/2310.18152](http://arxiv.org/abs/2310.18152)

    本文提出了一个名为Disentangled Graph-Text Learner (DGTL)的模型，通过引入定制的解缠图神经网络（GNN）层，使得大型语言模型（LLMs）能够更好地理解文本属性图（TAGs）中的复杂结构关系。

    

    文本属性图（TAGs）在网络上非常常见，对于该类图，如引用网络、电子商务网络和社交网络的研究在网络社区中引起了相当大的关注。最近，大型语言模型（LLMs）在各种任务上展示了出色的能力。然而，现有的工作仅仅依靠提示信息来传达图结构信息给LLMs，因此对于TAGs中复杂的结构关系了解不足。为解决这个问题，本文提出了解缠图文学习器（DGTL）模型，能够增强LLMs对TAGs的推理和预测能力。我们的DGTL模型通过定制的解缠图神经网络（GNN）层将图结构信息纳入其中，使得LLMs能够捕捉多个结构因素中隐藏的复杂关系。

    Text-attributed graphs (TAGs) are prevalent on the web and research over TAGs such as citation networks, e-commerce networks and social networks has attracted considerable attention in the web community. Recently, large language models (LLMs) have demonstrated exceptional capabilities across a wide range of tasks. However, the existing works focus on harnessing the potential of LLMs solely relying on prompts to convey graph structure information to LLMs, thus suffering from insufficient understanding of the complex structural relationships within TAGs. To address this problem, in this paper we present the Disentangled Graph-Text Learner (DGTL) model, which is able to enhance the reasoning and predicting capabilities of LLMs for TAGs. Our proposed DGTL model incorporates graph structure information through tailored disentangled graph neural network (GNN) layers, enabling LLMs to capture the intricate relationships hidden in text-attributed graphs from multiple structural factors. Furthe
    
[^8]: 语言和心理健康：从文本中测量情绪动态作为语言生物社会标记。

    Language and Mental Health: Measures of Emotion Dynamics from Text as Linguistic Biosocial Markers. (arXiv:2310.17369v1 [cs.CL])

    [http://arxiv.org/abs/2310.17369](http://arxiv.org/abs/2310.17369)

    本研究首次研究了推文情绪动态和心理健康障碍之间的关系，发现推文情绪动态与用户自我披露的诊断有关，为心理健康的评估提供了新的方法。

    

    心理病理学研究表明，情绪随时间的变化模式——情绪动态——是心理健康的指标。传统上，情绪变化的模式是通过情绪的自我报告来确定的；然而，已知存在准确性、偏见和便利性等问题。最近的方法通过研究个人日常发言来确定情绪动态，解决了许多这些问题，但目前尚不清楚这些发言情绪动态的测量值是否与心理健康诊断相关。在这里，我们首次研究了推文情绪动态与心理健康障碍之间的关系。我们发现，我们研究的每个情绪动态度量值都因用户自我披露的诊断而有所变化。例如，平均情绪价值较高（即文本较积极）的控制组与患有注意力缺陷多动障碍（ADHD）、抑郁症（MDD）和创伤后应激障碍（PTSD）的用户相比显著较高。情绪价值变异性在控制组中显著较低。

    Research in psychopathology has shown that, at an aggregate level, the patterns of emotional change over time -- emotion dynamics -- are indicators of one's mental health. One's patterns of emotion change have traditionally been determined through self-reports of emotions; however, there are known issues with accuracy, bias, and convenience. Recent approaches to determining emotion dynamics from one's everyday utterances, addresses many of these concerns, but it is not yet known whether these measures of utterance emotion dynamics (UED) correlate with mental health diagnoses. Here, for the first time, we study the relationship between tweet emotion dynamics and mental health disorders. We find that each of the UED metrics studied varied by the user's self-disclosed diagnosis. For example: average valence was significantly higher (i.e., more positive text) in the control group compared to users with ADHD, MDD, and PTSD. Valence variability was significantly lower in the control group co
    
[^9]: GlotLID: 低资源语言的语言识别

    GlotLID: Language Identification for Low-Resource Languages. (arXiv:2310.16248v1 [cs.CL])

    [http://arxiv.org/abs/2310.16248](http://arxiv.org/abs/2310.16248)

    GlotLID-M是一个满足广泛覆盖、可靠性和效率要求的语言识别模型，具有1665个可识别语言，并在实验中表现出色。它解决了低资源LID面临的挑战，并有望提高数据集质量和增强访问能力。

    

    最近有几篇论文发表了针对约300种高资源和中资源语言的语言识别（LID）的良好解决方案。然而，目前没有可用的LID满足以下要求：（i）涵盖广泛的低资源语言，（ii）经过严格评估且可靠，（iii）高效易用。在这里，我们发布了GlotLID-M，一个满足广泛覆盖、可靠性和效率要求的LID模型。它可以识别1665种语言，在覆盖范围上相比之前的工作有了大幅增加。在我们的实验中，GlotLID-M在平衡F1分数和假阳性率（FPR）方面优于四个基准模型（CLD3，FT176，OpenLID和NLLB）。我们分析了低资源LID面临的独特挑战：不正确的语料库元数据，来自高资源语言的泄漏，难以区分密切相关的语言，处理宏语言与方言，以及一般的噪声数据。我们希望将GlotLID-M集成到数据集创建流程中，以提高质量和增强访问能力。

    Several recent papers have published good solutions for language identification (LID) for about 300 high-resource and medium-resource languages. However, there is no LID available that (i) covers a wide range of low-resource languages, (ii) is rigorously evaluated and reliable and (iii) efficient and easy to use. Here, we publish GlotLID-M, an LID model that satisfies the desiderata of wide coverage, reliability and efficiency. It identifies 1665 languages, a large increase in coverage compared to prior work. In our experiments, GlotLID-M outperforms four baselines (CLD3, FT176, OpenLID and NLLB) when balancing F1 and false positive rate (FPR). We analyze the unique challenges that low-resource LID poses: incorrect corpus metadata, leakage from high-resource languages, difficulty separating closely related languages, handling of macrolanguage vs varieties and in general noisy data. We hope that integrating GlotLID-M into dataset creation pipelines will improve quality and enhance acces
    
[^10]: TRAMS:训练免费的长程语言建模记忆选择

    TRAMS: Training-free Memory Selection for Long-range Language Modeling. (arXiv:2310.15494v1 [cs.CL])

    [http://arxiv.org/abs/2310.15494](http://arxiv.org/abs/2310.15494)

    TRAMS是一种训练免费的长程语言建模记忆选择策略，它能够提高Transformer架构在长程语言建模方面的效果，并且不需要额外的训练或参数。

    

    Transformer架构对于众多AI模型至关重要，但在长程语言建模方面仍面临挑战。尽管已经设计了几种特定的Transformer架构来解决长程依赖的问题，但现有的方法如Transformer-XL存在大量无效记忆的问题。本研究提出了一种即插即用的策略，称为TRAining-free Memory Selection（TRAMS），它根据一个简单的指标选择参与注意力计算的标记。该策略允许我们保留与当前查询具有高关注分数可能性的标记，并忽略其他标记。我们在单词级基准（WikiText-103）和字符级基准（enwik8）上测试了我们的方法，结果表明在不进行额外训练或添加额外参数的情况下取得了改进。

    The Transformer architecture is crucial for numerous AI models, but it still faces challenges in long-range language modeling. Though several specific transformer architectures have been designed to tackle issues of long-range dependencies, existing methods like Transformer-XL are plagued by a high percentage of ineffective memories. In this study, we present a plug-and-play strategy, known as TRAining-free Memory Selection (TRAMS), that selects tokens participating in attention calculation based on one simple metric. This strategy allows us to keep tokens that are likely to have a high attention score with the current queries and ignore the other ones. We have tested our approach on the word-level benchmark (WikiText-103) and the character-level benchmark (enwik8), and the results indicate an improvement without having additional training or adding additional parameters.
    
[^11]: 具有强化改写生成的对话问答模型的鲁棒训练

    Robust Training for Conversational Question Answering Models with Reinforced Reformulation Generation. (arXiv:2310.13505v1 [cs.CL])

    [http://arxiv.org/abs/2310.13505](http://arxiv.org/abs/2310.13505)

    这项研究提出了一种新的框架REIGN，通过生成训练问题的改写，并使用深度强化学习来指导对话问答模型，增加模型对表面形式变化的鲁棒性，同时在不同的基准上进行零-shot应用。

    

    知识图谱（KG）上的对话问答（ConvQA）模型通常在黄金QA对的基准上进行训练和测试。这意味着训练仅限于在相应数据集中见到的表面形式，评估仅针对一小部分问题。通过我们的提出的框架REIGN，我们采取了几个步骤来解决这个受限的学习设置。首先，我们系统地生成训练问题的改写，以提高模型对表面形式变化的鲁棒性。这是一个特别具有挑战性的问题，因为这些问题的不完整性。其次，我们使用深度强化学习将ConvQA模型引导到更高的性能，只提供那些有助于提高回答质量的改写。第三，我们展示了在一个基准上训练主要模型组件并将其零-shot应用于另一个的可行性。最后，为了对训练模型的鲁棒性进行严格评估，我们使用和重新配置初始的改写、测试语料。

    Models for conversational question answering (ConvQA) over knowledge graphs (KGs) are usually trained and tested on benchmarks of gold QA pairs. This implies that training is limited to surface forms seen in the respective datasets, and evaluation is on a small set of held-out questions. Through our proposed framework REIGN, we take several steps to remedy this restricted learning setup. First, we systematically generate reformulations of training questions to increase robustness of models to surface form variations. This is a particularly challenging problem, given the incomplete nature of such questions. Second, we guide ConvQA models towards higher performance by feeding it only those reformulations that help improve their answering quality, using deep reinforcement learning. Third, we demonstrate the viability of training major model components on one benchmark and applying them zero-shot to another. Finally, for a rigorous evaluation of robustness for trained models, we use and re
    
[^12]: VIBE：Twitter分类的主题驱动时间自适应

    VIBE: Topic-Driven Temporal Adaptation for Twitter Classification. (arXiv:2310.10191v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.10191](http://arxiv.org/abs/2310.10191)

    VIBE是一种解决Twitter分类中语言特征演变问题的模型，通过建模潜在主题演变以适应动态环境，并且在大规模Twitter实验中展现了良好的性能。

    

    语言特征在现实世界的社交媒体中不断变化，导致文本分类在动态环境下的性能下降。为了解决这个挑战，我们研究了时间自适应，即在过去数据上训练的模型在未来进行测试。先前的大部分工作都集中在继续预训练或知识更新上，这可能会影响它们在噪声社交媒体数据上的性能。为了解决这个问题，我们通过建模潜在主题演变来反映特征变化，并提出了一种新的模型VIBE：Evolutions的变分信息瓶颈。具体而言，我们首先使用两个信息瓶颈(Bottleneck)正则化器来区分过去和未来的主题。然后，这些区分的主题通过时间戳和类别标签预测进行多任务训练，作为自适应特征。在自适应学习过程中，VIBE利用训练数据时间之后创建的在线流程中检索到的无标签数据。在三个分类任务的大规模Twitter实验中，我们的方法展示了良好的性能。

    Language features are evolving in real-world social media, resulting in the deteriorating performance of text classification in dynamics. To address this challenge, we study temporal adaptation, where models trained on past data are tested in the future. Most prior work focused on continued pretraining or knowledge updating, which may compromise their performance on noisy social media data. To tackle this issue, we reflect feature change via modeling latent topic evolution and propose a novel model, VIBE: Variational Information Bottleneck for Evolutions. Concretely, we first employ two Information Bottleneck (IB) regularizers to distinguish past and future topics. Then, the distinguished topics work as adaptive features via multi-task training with timestamp and class label prediction. In adaptive learning, VIBE utilizes retrieved unlabeled data from online streams created posterior to training data time. Substantial Twitter experiments on three classification tasks show that our mode
    
[^13]: 宽松的嘴唇会使船沉没：减轻强化学习中的长度偏差问题

    Loose lips sink ships: Mitigating Length Bias in Reinforcement Learning from Human Feedback. (arXiv:2310.05199v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.05199](http://arxiv.org/abs/2310.05199)

    本文提出了一种创新的解决方案，通过应用“专家的乘积”（PoE）技术来减轻强化学习中的长度偏差问题。在这个框架中，主要的专家关注理解人类意图，而偏见专家则致力于识别和捕捉长度偏差。

    

    人类反馈强化学习是重要的桥梁，将大型语言模型与人类和社会价值观对齐。这种对齐需要大量的人类反馈语料库来学习奖励模型，然后用于微调语言模型。然而，我们发现奖励模型常常会找到绕过预期目标的捷径，错误地假设人类更喜欢较长的回答。长度偏差的出现常常会导致模型倾向于较长的输出，但并不意味着这些输出中有更多有用的信息。在本文中，我们提出了一种创新的解决方案，应用了“专家的乘积”（PoE）技术来将奖励建模与序列长度的影响分离。在我们的框架中，主要的专家关注理解人类意图，而偏见专家则致力于识别和捕捉长度偏差。为了进一步增强偏见的学习，我们引入了扰动进入偏差部分。

    Reinforcement learning from human feedback serves as a crucial bridge, aligning large language models with human and societal values. This alignment requires a vast corpus of human feedback to learn a reward model, which is subsequently used to finetune language models. However, we have identified that the reward model often finds shortcuts to bypass its intended objectives, misleadingly assuming that humans prefer longer responses. The emergence of length bias often induces the model to favor longer outputs, yet it doesn't equate to an increase in helpful information within these outputs. In this paper, we propose an innovative solution, applying the Product-of-Experts (PoE) technique to separate reward modeling from the influence of sequence length. In our framework, the main expert concentrates on understanding human intents, while the biased expert targets the identification and capture of length bias. To further enhance the learning of bias, we introduce perturbations into the bia
    
[^14]: 通过检索增强的大型语言模型提升金融情感分析

    Enhancing Financial Sentiment Analysis via Retrieval Augmented Large Language Models. (arXiv:2310.04027v1 [cs.CL])

    [http://arxiv.org/abs/2310.04027](http://arxiv.org/abs/2310.04027)

    本文通过引入检索增强型的大型语言模型框架，提升金融情感分析的效果，并解决了传统模型在参数规模和训练数据范围方面的限制。

    

    金融情感分析对于估值和投资决策至关重要。然而，传统的自然语言处理模型受其参数规模和训练数据集范围的限制，其泛化能力和在该领域的有效性受到了限制。最近，以广泛语料库进行预训练的大型语言模型（LLMs）由于其令人称赞的零样本能力，在各种自然语言处理任务中展示了优越的性能。然而，直接将LLMs应用于金融情感分析存在挑战：LLMs的预训练目标与情感标签预测之间的差异可能会 compromise其预测性能。此外，金融新闻的简洁性，常常缺乏足够的上下文，也可能会显著降低LLMs的情感分析可靠性。为了解决这些挑战，我们提出了一个用于金融情感分析的检索增强型LLMs框架。

    Financial sentiment analysis is critical for valuation and investment decision-making. Traditional NLP models, however, are limited by their parameter size and the scope of their training datasets, which hampers their generalization capabilities and effectiveness in this field. Recently, Large Language Models (LLMs) pre-trained on extensive corpora have demonstrated superior performance across various NLP tasks due to their commendable zero-shot abilities. Yet, directly applying LLMs to financial sentiment analysis presents challenges: The discrepancy between the pre-training objective of LLMs and predicting the sentiment label can compromise their predictive performance. Furthermore, the succinct nature of financial news, often devoid of sufficient context, can significantly diminish the reliability of LLMs' sentiment analysis. To address these challenges, we introduce a retrieval-augmented LLMs framework for financial sentiment analysis. This framework includes an instruction-tuned L
    
[^15]: RA-DIT: 检索增强的双重指令调优

    RA-DIT: Retrieval-Augmented Dual Instruction Tuning. (arXiv:2310.01352v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.01352](http://arxiv.org/abs/2310.01352)

    本论文介绍了一种轻量级的微调方法RA-DIT，通过为任何语言模型添加检索能力来提高性能。该方法分为两个步骤：一是更新语言模型以更好地利用检索到的信息，二是更新检索器以返回更相关的结果。实验证明每个步骤都能显著提高性能，同时使用两个步骤可以获得额外的收益。

    

    检索增强语言模型（RALMs）通过访问外部数据存储中的长尾和最新知识来提高性能，但构建起来具有挑战性。现有的方法要么需要昂贵的检索特定修改来进行语言模型预训练，要么使用事后集成数据存储的方法，导致性能不理想。我们引入了一种轻量级的微调方法——检索增强的双重指令调优（RA-DIT），通过为任何语言模型添加检索能力来实现。我们的方法分为两个不同的微调步骤：（1）一个更新预训练的语言模型以更好地利用检索到的信息，（2）另一个更新检索器以返回更相关的结果，符合语言模型的偏好。通过在需要知识利用和上下文意识的任务上进行微调，我们证明了每个阶段都能显著提高性能，并且同时使用两个阶段可以获得额外的收益。我们的最佳模型是RA-DIT 65B。

    Retrieval-augmented language models (RALMs) improve performance by accessing long-tail and up-to-date knowledge from external data stores, but are challenging to build. Existing approaches require either expensive retrieval-specific modifications to LM pre-training or use post-hoc integration of the data store that leads to suboptimal performance. We introduce Retrieval-Augmented Dual Instruction Tuning (RA-DIT), a lightweight fine-tuning methodology that provides a third option by retrofitting any LLM with retrieval capabilities. Our approach operates in two distinct fine-tuning steps: (1) one updates a pre-trained LM to better use retrieved information, while (2) the other updates the retriever to return more relevant results, as preferred by the LM. By fine-tuning over tasks that require both knowledge utilization and contextual awareness, we demonstrate that each stage yields significant performance improvements, and using both leads to additional gains. Our best model, RA-DIT 65B,
    
[^16]: 从基础到对话式：日语指令数据集和调整大型语言模型

    From Base to Conversational: Japanese Instruction Dataset and Tuning Large Language Models. (arXiv:2309.03412v1 [cs.CL])

    [http://arxiv.org/abs/2309.03412](http://arxiv.org/abs/2309.03412)

    通过构建日语指令数据集并进行指令调整，验证了日语指令数据集的有效性，并表明通过指令调整可以提高下游任务的性能。

    

    对于大型语言模型（LLMs）能够变得交互性来说，指令调整是至关重要的。尽管存在许多英文的指令调整数据集，但其他语言缺乏明显。而且，它们在非英语语言中的效果尚未得到很好的验证。我们通过扩展和筛选现有数据集构建了一个日语指令数据集，并将该数据集应用于一个日语预训练基础模型。我们使用我们的指令数据集对日语和英语现有模型进行了低秩适应（LoRA）调整。我们从数量和质量两个角度评估了这些模型。结果确认了日语指令数据集的有效性。结果还表明，即使是相对较小的LLMs，通过指令调整也能提高下游任务的性能。我们的指令数据集、调整模型和实现均可在网上公开获取。

    Instruction tuning is essential for large language models (LLMs) to become interactive. While many instruction tuning datasets exist in English, there is a noticeable lack in other languages. Also, their effectiveness has not been well verified in non-English languages. We construct a Japanese instruction dataset by expanding and filtering existing datasets and apply the dataset to a Japanese pre-trained base model. We performed Low-Rank Adaptation (LoRA) tuning on both Japanese and English existing models using our instruction dataset. We evaluated these models from both quantitative and qualitative perspectives. As a result, the effectiveness of Japanese instruction datasets is confirmed. The results also indicate that even with relatively small LLMs, performances in downstream tasks would be improved through instruction tuning. Our instruction dataset, tuned models, and implementation are publicly available online.
    
[^17]: 用于马克白彦病研究的不同报告结果的比较话题建模

    Comparative Topic Modeling for Determinants of Divergent Report Results Applied to Macular Degeneration Studies. (arXiv:2309.00312v1 [cs.CL])

    [http://arxiv.org/abs/2309.00312](http://arxiv.org/abs/2309.00312)

    本研究提出了一种比较话题建模方法，用于分析马克白彦病研究中存在矛盾结果的报告。通过对比不同话题与显著结果的相关性，找到了与黄斑变性研究中显著结果报告相关的八种化合物。

    

    话题建模和文本挖掘是自然语言处理的子集，适用于进行元分析和系统审查。对于证据综述，上述NLP方法通常用于特定主题的文献搜索或从报告中提取值以自动化SR和MA的关键阶段。相反，本文提出了一种比较话题建模方法，用于分析同一广义研究问题上存在矛盾结果的报告。具体而言，目标是通过根据其比例发生和在显著结果报告中的一致性分布对其进行排名，找到与感兴趣的结果显著相关的话题。该方法在涉及补充营养化合物是否显著有益于黄斑变性(MD)的广泛范围的研究中进行了测试。确定了八种化合物与显著结果报告的特定相关性。

    Topic modeling and text mining are subsets of Natural Language Processing with relevance for conducting meta-analysis (MA) and systematic review (SR). For evidence synthesis, the above NLP methods are conventionally used for topic-specific literature searches or extracting values from reports to automate essential phases of SR and MA. Instead, this work proposes a comparative topic modeling approach to analyze reports of contradictory results on the same general research question. Specifically, the objective is to find topics exhibiting distinct associations with significant results for an outcome of interest by ranking them according to their proportional occurrence and consistency of distribution across reports of significant results. The proposed method was tested on broad-scope studies addressing whether supplemental nutritional compounds significantly benefit macular degeneration (MD). Eight compounds were identified as having a particular association with reports of significant r
    
[^18]: 在大型语言模型中量化和分析实体级记忆

    Quantifying and Analyzing Entity-level Memorization in Large Language Models. (arXiv:2308.15727v1 [cs.CL])

    [http://arxiv.org/abs/2308.15727](http://arxiv.org/abs/2308.15727)

    本研究提出了一种细粒度的、实体级的定义来量化大型语言模型中的记忆能力，并提出了一种高效提取敏感实体的方法。实验证明了语言模型在不同设置下重构敏感实体的能力。

    

    大型语言模型（LLMs）被证明能够记忆其训练数据，这可以通过特定设计的提示提取出来。随着数据集规模的不断增长，由记忆引起的隐私风险引起了越来越多的关注。量化语言模型的记忆能力有助于评估潜在的隐私风险。然而，以往关于量化记忆的研究需要访问精确的原始数据或产生相当大的计算开销，这对于实际应用中的语言模型来说很困难。因此，我们提出了一种细粒度的、实体级的定义，用于以更接近实际场景的条件和度量方式来量化记忆。此外，我们还提出了一种从自回归语言模型中高效提取敏感实体的方法。我们基于提出的方法进行了大量的实验证明了语言模型在不同设置下的重构敏感实体的能力。

    Large language models (LLMs) have been proven capable of memorizing their training data, which can be extracted through specifically designed prompts. As the scale of datasets continues to grow, privacy risks arising from memorization have attracted increasing attention. Quantifying language model memorization helps evaluate potential privacy risks. However, prior works on quantifying memorization require access to the precise original data or incur substantial computational overhead, making it difficult for applications in real-world language models. To this end, we propose a fine-grained, entity-level definition to quantify memorization with conditions and metrics closer to real-world scenarios. In addition, we also present an approach for efficiently extracting sensitive entities from autoregressive language models. We conduct extensive experiments based on the proposed, probing language models' ability to reconstruct sensitive entities under different settings. We find that languag
    
[^19]: DS4DH在#SMM4H 2023上：使用句子转换和倒数排名融合进行零样本不良药物事件规范化

    DS4DH at #SMM4H 2023: Zero-Shot Adverse Drug Events Normalization using Sentence Transformers and Reciprocal-Rank Fusion. (arXiv:2308.12877v1 [cs.CL])

    [http://arxiv.org/abs/2308.12877](http://arxiv.org/abs/2308.12877)

    本文介绍了DS4DH在#SMM4H 2023中开发的不良药物事件规范化系统的性能评估，该系统利用句子转换和倒数排名融合进行零样本规范化。实验结果表明该方法在共享任务中表现优异，可有效应用于社交媒体文本挖掘中的不良药物事件规范化。

    

    本文概述了由数据科学与数字健康团队开发的用于社交媒体挖掘健康应用2023共享任务5的不良药物事件规范化系统的性能评估。共享任务5旨在将Twitter中的不良药物事件提及标准化为医疗法规活动术语字典中的标准概念。我们的系统采用两阶段方法：BERT微调实体识别，然后使用句子转换和倒数排名融合进行零样本规范化。该方法的精确度为44.9%，召回率为40.5%，F1分数为42.6%。它的性能超过了共享任务5中位数表现10%，并在所有参与者中展示了最高性能。这些结果证实了我们方法的有效性和在社交媒体文本挖掘领域中进行不良药物事件规范化的潜在应用。

    This paper outlines the performance evaluation of a system for adverse drug event normalization, developed by the Data Science for Digital Health group for the Social Media Mining for Health Applications 2023 shared task 5. Shared task 5 targeted the normalization of adverse drug event mentions in Twitter to standard concepts from the Medical Dictionary for Regulatory Activities terminology. Our system hinges on a two-stage approach: BERT fine-tuning for entity recognition, followed by zero-shot normalization using sentence transformers and reciprocal-rank fusion. The approach yielded a precision of 44.9%, recall of 40.5%, and an F1-score of 42.6%. It outperformed the median performance in shared task 5 by 10% and demonstrated the highest performance among all participants. These results substantiate the effectiveness of our approach and its potential application for adverse drug event normalization in the realm of social media text mining.
    
[^20]: 加密货币证券案件中的大型语言模型：ChatGPT能否取代律师？

    Large Language Models in Cryptocurrency Securities Cases: Can ChatGPT Replace Lawyers?. (arXiv:2308.06032v1 [cs.AI])

    [http://arxiv.org/abs/2308.06032](http://arxiv.org/abs/2308.06032)

    本研究探讨了在加密货币证券案件中，大型语言模型（LLMs）是否能够准确判断违法行为，并比较了由LLM和律师撰写的投诉书对陪审团决策的影响。研究发现，目前的LLMs在法律推理方面表现较弱，但随着未来模型的改进，其潜力有望提升。

    

    大型语言模型（LLMs）可以增强对法律系统的访问。然而，关于它们在进行法律任务方面的有效性的实证研究非常有限。我们研究涉及加密货币的证券案件，作为AI可以支持法律过程的众多情境之一，研究LLMs的法律推理和起草能力。我们检查以下两个方面：a）LLM能否准确确定事实模式中可能存在的违法行为，b）基于LLM和律师撰写的投诉书，陪审团的决策是否有所差异。我们将真实案例中的事实模式输入GPT-3.5，并评估其确定正确潜在违法行为并排除虚假违法行为的能力。其次，我们请模拟陪审员评估LLM和律师撰写的投诉书。GPT-3.5的法律推理能力较弱，但我们预期未来模型的改进，特别是考虑到它建议的违法行为往往是正确的（它仅仅过于保守）。

    Large Language Models (LLMs) could enhance access to the legal system. However, empirical research on their effectiveness in conducting legal tasks is scant. We study securities cases involving cryptocurrencies as one of numerous contexts where AI could support the legal process, studying LLMs' legal reasoning and drafting capabilities. We examine whether a) an LLM can accurately determine which laws are potentially being violated from a fact pattern, and b) whether there is a difference in juror decision-making based on complaints written by a lawyer compared to an LLM. We feed fact patterns from real-life cases to GPT-3.5 and evaluate its ability to determine correct potential violations from the scenario and exclude spurious violations. Second, we had mock jurors assess complaints written by the LLM and lawyers. GPT-3.5's legal reasoning skills proved weak, though we expect improvement in future models, particularly given the violations it suggested tended to be correct (it merely m
    
[^21]: 使用Fine-Tuned的OpenAI LLM预测机器翻译输出中的完美质量段落：是否可以从历史数据中捕捉编辑距离模式？

    Predicting Perfect Quality Segments in MT Output with Fine-Tuned OpenAI LLM: Is it possible to capture editing distance patterns from historical data?. (arXiv:2308.00158v1 [cs.CL])

    [http://arxiv.org/abs/2308.00158](http://arxiv.org/abs/2308.00158)

    本研究探讨了使用Fine-Tuned的OpenAI LLM进行翻译质量估计的能力，实验证明可以通过Fine-Tuned的ChatGPT来预测机器翻译的质量，但仍有改进的空间。

    

    翻译质量估计（TQE）是将输出翻译部署到使用中之前的重要步骤。 TQE对于评估机器翻译（MT）和人工翻译（HT）的质量也是至关重要的，而不需要查看参考翻译。在这项工作中，我们检查了最先进的大型语言模型（LLMs）是否可以为TQE任务和它们的能力进行Fine-Tune。我们以ChatGPT为例，将TQE视为二元分类任务。使用英意和英德训练语料库，我们的实验结果显示，通过ChatGPT的API Fine-Tuned可以在预测翻译质量方面获得相对较高的得分，即是否需要编辑翻译，但肯定有改进准确性的空间。英意双语摘要可在论文中找到。

    Translation Quality Estimation (TQE) is an important step before deploying the output translation into usage. TQE is also critical in assessing machine translation (MT) and human translation (HT) quality without seeing the reference translations. In this work, we examine if the state-of-the-art large language models (LLMs) can be fine-tuned for the TQE task and their capability. We take ChatGPT as one example and approach TQE as a binary classification task. Using English-Italian and English-German training corpus, our experimental results show that fine-tuned ChatGPT via its API can achieve a relatively high score on predicting translation quality, i.e. if the translation needs to be edited, but there is definitely space to improve the accuracy. English-Italiano bilingual Abstract is available in the paper.
    
[^22]: 语言模型中复杂技能产生的理论

    A Theory for Emergence of Complex Skills in Language Models. (arXiv:2307.15936v1 [cs.LG])

    [http://arxiv.org/abs/2307.15936](http://arxiv.org/abs/2307.15936)

    本文提出了一个统计框架，通过分析语言模型的交叉熵损失与基本语言任务的能力之间的关系，揭示了语言模型中复杂技能产生的机制。研究结果表明，通过扩展定律，预训练模型能够高效学习，并表现出违反通常泛化理论的能力。

    

    当语言模型的参数集合和训练语料库扩大时，新的技能将在 AI 产品中出现的主要驱动因素。这种现象尚不为人所理解，并且通过对基于梯度训练的数学分析提供机械解释似乎很困难。本文采用不同的方法，使用著名的（和经验性的）LLM扩展定律和简单的统计框架来分析出现。贡献包括：（a）一个统计框架将LLM的交叉熵损失与语言任务基本技能的能力相关联。（b）数学分析表明，扩展定律意味着强烈的归纳偏见，使预训练模型能够学习得非常高效。我们非正式地称之为“弹弓泛化”，因为表面上看，它似乎提供了在技能水平上违反通常泛化理论的能力。（c）弹弓泛化的一个关键例子，即在执行任务时的能力。

    A major driver of AI products today is the fact that new skills emerge in language models when their parameter set and training corpora are scaled up. This phenomenon is poorly understood, and a mechanistic explanation via mathematical analysis of gradient-based training seems difficult. The current paper takes a different approach, analysing emergence using the famous (and empirical) Scaling Laws of LLMs and a simple statistical framework. Contributions include: (a) A statistical framework that relates cross-entropy loss of LLMs to competence on the basic skills that underlie language tasks. (b) Mathematical analysis showing that the Scaling Laws imply a strong form of inductive bias that allows the pre-trained model to learn very efficiently. We informally call this {\em slingshot generalization} since naively viewed it appears to give competence levels at skills that violate usual generalization theory. (c) A key example of slingshot generalization, that competence at executing task
    
[^23]: 在这篇论文中，我们介绍了首次将母语识别（Native Language Identification，NLI）应用于土耳其语的研究。

    Turkish Native Language Identification. (arXiv:2307.14850v1 [cs.CL])

    [http://arxiv.org/abs/2307.14850](http://arxiv.org/abs/2307.14850)

    这项研究首次将母语识别应用于土耳其语,通过分析作者不同语言的写作来预测作者的母语。研究使用了土耳其学习者语料库和三个句法特征来展示其有效性。

    

    在这篇论文中，我们首次将母语识别（NLI）应用于土耳其语。NLI 是通过分析作者不同语言的写作来预测作者的母语。尽管大多数NLI研究都侧重于英语，我们的研究将其范围扩展到土耳其语。我们使用了最近构建的土耳其学习者语料库，并结合了三个句法特征（CFG 产生规则，词性n-gram和函数词）与L2文本，以展示它们在该任务中的有效性。

    In this paper, we present the first application of Native Language Identification (NLI) for the Turkish language. NLI involves predicting the writer's first language by analysing their writing in different languages. While most NLI research has focused on English, our study extends its scope to Turkish. We used the recently constructed Turkish Learner Corpus and employed a combination of three syntactic features (CFG production rules, part-of-speech n-grams and function words) with L2 texts to demonstrate their effectiveness in this task.
    
[^24]: EmotionPrompt: 通过情感刺激提升大型语言模型的关键心理学方法

    EmotionPrompt: Leveraging Psychology for Large Language Models Enhancement via Emotional Stimulus. (arXiv:2307.11760v1 [cs.CL])

    [http://arxiv.org/abs/2307.11760](http://arxiv.org/abs/2307.11760)

    EmotionPrompt是一个基于心理学的方法，通过将情感刺激融入到提示中，提升了大型语言模型在各项任务上的性能，并且同时改善了其真实性和信息量。

    

    大型语言模型（LLMs）在推理、语言理解和数学问题解决等许多领域取得了显著的性能，并被视为人工通用智能（AGI）的关键步骤。然而，LLMs对提示的敏感性仍然是其日常应用的主要瓶颈。本文从心理学中汲取灵感，提出了EmotionPrompt来探索情感智能以提升LLMs的性能。EmotionPrompt基于一个非常简单明了的原则：将情感刺激融入到提示中。实验结果表明，我们的方法在相同的单一提示模板上，与原始的零样本提示和Zero-shot-CoT相比，在8个任务上都显著优于多种模型：ChatGPT、Vicuna-13b、Bloom和T5。此外，观察到EmotionPrompt能够提高真实性和信息量。我们相信EmotionPrompt为探索跨学科知识开辟了一条新的道路。

    Large language models (LLMs) have achieved significant performance in many fields such as reasoning, language understanding, and math problem-solving, and are regarded as a crucial step to artificial general intelligence (AGI). However, the sensitivity of LLMs to prompts remains a major bottleneck for their daily adoption. In this paper, we take inspiration from psychology and propose EmotionPrompt to explore emotional intelligence to enhance the performance of LLMs. EmotionPrompt operates on a remarkably straightforward principle: the incorporation of emotional stimulus into prompts. Experimental results demonstrate that our \method, using the same single prompt templates, significantly outperforms original zero-shot prompt and Zero-shot-CoT on 8 tasks with diverse models: ChatGPT, Vicuna-13b, Bloom, and T5. Further, EmotionPrompt was observed to improve both truthfulness and informativeness. We believe that EmotionPrompt heralds a novel avenue for exploring interdisciplinary knowledg
    
[^25]: AlpaGasus: 用更少数据训练更好的羊驼

    AlpaGasus: Training A Better Alpaca with Fewer Data. (arXiv:2307.08701v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.08701](http://arxiv.org/abs/2307.08701)

    这项研究提出了一种用于训练语言模型的数据筛选策略AlpaGasus，通过使用强大的语言模型过滤掉低质量数据，它在测试中表现出比原始模型更好的性能，并提供了更快的训练速度。

    

    大型语言模型通过在有监督的指令/回复数据上进行指令微调（IFT）来增强其遵循指令的能力。然而，广泛使用的IFT数据集（例如：Alpaca的52k数据）出乎意料地包含许多具有不正确或不相关回复的低质量实例，这些实例会误导和对IFT产生不利影响。在本文中，我们提出了一种简单而有效的数据选择策略，该策略使用强大的语言模型（例如：ChatGPT）自动识别并过滤掉低质量数据。为此，我们引入了AlpaGasus，它仅在从52k Alpaca数据中过滤得到的9k高质量数据上进行微调。AlpaGasus在多个测试数据集和人工评估中均显著优于原始的Alpaca，由GPT-4进行评估。其13B变种在测试任务上的性能与其教师模型语言模型（即生成52k数据的Text-Davinci-003）的性能匹配率超过90％。它还提供了5.7倍更快的训练速度，将7B变种的训练时间从80分钟减少到了...

    Large language models~(LLMs) strengthen instruction-following capability through instruction-finetuning (IFT) on supervised instruction/response data. However, widely used IFT datasets (e.g., Alpaca's 52k data) surprisingly contain many low-quality instances with incorrect or irrelevant responses, which are misleading and detrimental to IFT. In this paper, we propose a simple and effective data selection strategy that automatically identifies and filters out low-quality data using a strong LLM (e.g., ChatGPT). To this end, we introduce AlpaGasus, which is finetuned on only 9k high-quality data filtered from the 52k Alpaca data. AlpaGasus significantly outperforms the original Alpaca as evaluated by GPT-4 on multiple test sets and the controlled human evaluation. Its 13B variant matches $>90\%$ performance of its teacher LLM (i.e., Text-Davinci-003 generating the 52k data) on test tasks. It also provides 5.7x faster training, reducing the training time for a 7B variant from 80 minutes (
    
[^26]: 一种新型的与平台无关的多模态深度学习模型，用于识别社交媒体上的促进饮食紊乱内容

    A Novel Site-Agnostic Multimodal Deep Learning Model to Identify Pro-Eating Disorder Content on Social Media. (arXiv:2307.06775v1 [cs.LG])

    [http://arxiv.org/abs/2307.06775](http://arxiv.org/abs/2307.06775)

    本研究创建了一个多模态深度学习模型，将文本和视觉数据相结合，能够准确识别社交媒体上的促进饮食紊乱的内容。最有效的模型是RoBERTa自然语言处理模型和MaxViT图像分类模型的融合模型，准确率和F1分数分别达到95.9%和0.959。

    

    在过去的十年中，饮食紊乱的诊断和与之相关的死亡数量大幅增加，尤其是在新冠疫情期间。这种巨大增长部分来源于疫情的压力，但也与社交媒体的暴露增加有关，社交媒体上充斥着促进饮食紊乱的内容。这些内容可以诱发观看者的饮食紊乱。本研究旨在创建一个多模态深度学习模型，能够基于视觉和文本数据的组合判断给定的社交媒体帖子是否促进饮食紊乱。从Twitter收集了一个带有标签的推文数据集，对其进行了十二个深度学习模型的训练和测试。根据模型的性能，最有效的深度学习模型是RoBERTa自然语言处理模型和MaxViT图像分类模型的多模态融合模型，准确率和F1分数分别达到95.9%和0.959。RoBERTa和MaxViT融合模型可以有效地识别社交媒体上的促进饮食紊乱的内容。

    Over the last decade, there has been a vast increase in eating disorder diagnoses and eating disorder-attributed deaths, reaching their zenith during the Covid-19 pandemic. This immense growth derived in part from the stressors of the pandemic but also from increased exposure to social media, which is rife with content that promotes eating disorders. Such content can induce eating disorders in viewers. This study aimed to create a multimodal deep learning model capable of determining whether a given social media post promotes eating disorders based on a combination of visual and textual data. A labeled dataset of Tweets was collected from Twitter, upon which twelve deep learning models were trained and tested. Based on model performance, the most effective deep learning model was the multimodal fusion of the RoBERTa natural language processing model and the MaxViT image classification model, attaining accuracy and F1 scores of 95.9% and 0.959 respectively. The RoBERTa and MaxViT fusion
    
[^27]: 稀疏模块激活用于高效的序列建模

    Sparse Modular Activation for Efficient Sequence Modeling. (arXiv:2306.11197v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.11197](http://arxiv.org/abs/2306.11197)

    本论文引入了稀疏模块激活 (SMA) 机制，用于高效的序列建模。这种机制可以动态地稀疏激活序列元素的子模块，减少计算和内存消耗。

    

    线性状态空间模型 (SSM) 在各种序列建模任务中表现出了很强的性能，因为它们有效地编码了循环结构。然而，在更综合的任务中，如语言建模和机器翻译中，基于自注意力的模型仍然优于SSM。同时使用SSM和自注意力的混合模型通常显示出有希望的性能，但当前方法将注意力模块静态且均匀地应用于输入序列中的所有元素，导致了质量和效率之间的次优权衡。在这项工作中，我们引入了稀疏模块激活 (SMA)，这是一种通用机制，使神经网络能够以可微分的方式稀疏地动态激活序列元素的子模块。通过允许每个元素跳过非激活的子模块，SMA可以在序列建模的训练和推理阶段降低计算和内存消耗。作为SMA的一个特定实例，我们设计了一种新颖的神经网络模型。

    Linear State Space Models (SSMs) have demonstrated strong performance in a variety of sequence modeling tasks due to their efficient encoding of the recurrent structure. However, in more comprehensive tasks like language modeling and machine translation, self-attention-based models still outperform SSMs. Hybrid models employing both SSM and self-attention generally show promising performance, but current approaches apply attention modules statically and uniformly to all elements in the input sequences, leading to sub-optimal quality-efficiency trade-offs. In this work, we introduce Sparse Modular Activation (SMA), a general mechanism enabling neural networks to sparsely and dynamically activate sub-modules for sequence elements in a differentiable manner. Through allowing each element to skip non-activated sub-modules, SMA reduces computation and memory consumption at both training and inference stages of sequence modeling. As a specific instantiation of SMA, we design a novel neural a
    
[^28]: 文本到图像扩散模型中的能量交叉注意力用于贝叶斯上下文更新

    Energy-Based Cross Attention for Bayesian Context Update in Text-to-Image Diffusion Models. (arXiv:2306.09869v1 [cs.CV])

    [http://arxiv.org/abs/2306.09869](http://arxiv.org/abs/2306.09869)

    本论文提出了能量交叉注意力的EBM框架，通过更新和转移上下文向量，隐式最小化能量函数的嵌套层次，优化文本到图像扩散模型的语义对齐问题，实现零样本组合生成。

    

    尽管文本到图像扩散模型在图像生成任务中表现出色，但最近的研究提出了一个问题，即生成的图像有时无法捕捉到文本提示的预期语义内容，这种现象通常被称为语义错位。为了解决这个问题，我们提出了一种新颖的基于能量的模型（EBM）框架。具体而言，我们首先在去噪自编码器的每个交叉注意力层中制定潜在图像表示和文本嵌入的EBM。然后，我们获得上下文向量的对数后验梯度，可以更新和转移到后续的交叉注意力层，从而隐式地最小化嵌套层次的能量函数。我们的潜在EBMs还允许零样本组合生成，即通过不同上下文的交叉注意力输出的线性组合。通过大量实验，我们证明了所提出的方法在处理各种图像生成任务方面非常有效，并可以显著降低文本提示和生成图像之间的语义错位现象。

    Despite the remarkable performance of text-to-image diffusion models in image generation tasks, recent studies have raised the issue that generated images sometimes cannot capture the intended semantic contents of the text prompts, which phenomenon is often called semantic misalignment. To address this, here we present a novel energy-based model (EBM) framework. Specifically, we first formulate EBMs of latent image representations and text embeddings in each cross-attention layer of the denoising autoencoder. Then, we obtain the gradient of the log posterior of context vectors, which can be updated and transferred to the subsequent cross-attention layer, thereby implicitly minimizing a nested hierarchy of energy functions. Our latent EBMs further allow zero-shot compositional generation as a linear combination of cross-attention outputs from different contexts. Using extensive experiments, we demonstrate that the proposed method is highly effective in handling various image generation 
    
[^29]: 基于语言模型的“考官”对基础模型进行基准测试

    Benchmarking Foundation Models with Language-Model-as-an-Examiner. (arXiv:2306.04181v1 [cs.CL])

    [http://arxiv.org/abs/2306.04181](http://arxiv.org/abs/2306.04181)

    本文提出了一种新的基准测试框架，使用语言模型作为考官，可以无参考方式评估答案。这个框架解决了过去基准测试流程中的测试泄漏和评估自动化问题，并允许易于扩展，可以采用不同的语言模型作为考官。

    

    已经建立了许多基准测试来评估基础模型在开放式问答方面的表现，它是测试模型理解和生成语言的能力的全面测试。大多数工作集中在提出新的数据集，然而，我们在之前的基准测试流程中看到了两个主要问题，即测试泄漏和评估自动化。在本文中，我们提出了一种新的基准测试框架，语言模型作为考官（LMAE），其中LM作为知识渊博的考官，根据其知识制定问题并以无参考方式评估答案。我们的框架允许易于扩展，因为可以采用各种LM作为考官，并且可以不断更新问题，给予更多样化的触发主题。为了更全面和公正地评估，我们设计了三个策略：（1）我们指示LM考官在许多领域生成问题。

    Numerous benchmarks have been established to assess the performance of foundation models on open-ended question answering, which serves as a comprehensive test of a model's ability to understand and generate language in a manner similar to humans. Most of these works focus on proposing new datasets, however, we see two main issues within previous benchmarking pipelines, namely testing leakage and evaluation automation. In this paper, we propose a novel benchmarking framework, Language-Model-as-an-Examiner, where the LM serves as a knowledgeable examiner that formulates questions based on its knowledge and evaluates responses in a reference-free manner. Our framework allows for effortless extensibility as various LMs can be adopted as the examiner, and the questions can be constantly updated given more diverse trigger topics. For a more comprehensive and equitable evaluation, we devise three strategies: (1) We instruct the LM examiner to generate questions across a multitude of domains 
    
[^30]: 使用混合语言特征提高土耳其文本可读性的研究

    Exploring Hybrid Linguistic Features for Turkish Text Readability. (arXiv:2306.03774v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.03774](http://arxiv.org/abs/2306.03774)

    本文结合神经网络模型和各语言层面上的特征，开发出一种先进的土耳其文本可读性工具，发现了影响土耳其文本可读性的关键语言特征。

    

    本文首次对土耳其文本的自动可读性评估进行了全面研究。我们结合了最先进的神经网络模型和词汇、形态句法、语法和话语水平的语言特征，开发了一个先进的可读性工具。我们评估了传统可读性公式与现代自动方法的效果，并确定了影响土耳其文本可读性的关键语言特征。

    This paper presents the first comprehensive study on automatic readability assessment of Turkish texts. We combine state-of-the-art neural network models with linguistic features at lexical, morphosyntactic, syntactic and discourse levels to develop an advanced readability tool. We evaluate the effectiveness of traditional readability formulas compared to modern automated methods and identify key linguistic features that determine the readability of Turkish texts.
    
[^31]: SciLit: 一种联合科学文献发现、摘要和引文生成平台

    SciLit: A Platform for Joint Scientific Literature Discovery, Summarization and Citation Generation. (arXiv:2306.03535v1 [cs.CL])

    [http://arxiv.org/abs/2306.03535](http://arxiv.org/abs/2306.03535)

    SciLit 是一个能够自动检索、摘要和引用相关论文的平台，它可以从数百万篇文献中高效地推荐论文，并提供具有上下文关联的引用句子。

    

    科学写作涉及检索、总结和引用相关论文，这在大规模和快速发展的领域中可能是耗时的过程。通过将这些过程相互操作，自然语言处理 (NLP) 提供了创建端到端辅助写作工具的机会。我们提出了SciLit，这是一个流水线，可以自动推荐相关论文，提取亮点，并建议一个引用句子作为论文的引用，考虑到用户提供的上下文和关键词。SciLit可以高效地从数百万篇论文的大型数据库中推荐论文，使用两阶段的预取和重新排名文献搜索系统，灵活处理论文数据库的添加和删除。我们提供了一个方便的用户界面，显示推荐的论文作为摘要，并提供与提供的上下文对齐并提到所选关键词的摘要引文。

    Scientific writing involves retrieving, summarizing, and citing relevant papers, which can be time-consuming processes in large and rapidly evolving fields. By making these processes inter-operable, natural language processing (NLP) provides opportunities for creating end-to-end assistive writing tools. We propose SciLit, a pipeline that automatically recommends relevant papers, extracts highlights, and suggests a reference sentence as a citation of a paper, taking into consideration the user-provided context and keywords. SciLit efficiently recommends papers from large databases of hundreds of millions of papers using a two-stage pre-fetching and re-ranking literature search system that flexibly deals with addition and removal of a paper database. We provide a convenient user interface that displays the recommended papers as extractive summaries and that offers abstractively-generated citing sentences which are aligned with the provided context and which mention the chosen keyword(s).
    
[^32]: 跨语言评估情感曲线：弥合情感分析中的全球差异

    Evaluating Emotion Arcs Across Languages: Bridging the Global Divide in Sentiment Analysis. (arXiv:2306.02213v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.02213](http://arxiv.org/abs/2306.02213)

    本研究首次对自动生成的情感曲线进行了系统和定量的评估，并比较了机器学习模型和词典方法两种生成情感曲线的方式。通过在不同语言的多个数据集上进行实验，我们发现虽然词典方法在实例级情感分类方面表现较差，但在聚合信息时生成情感曲线的准确性非常高。此外，我们还展示了通过自动翻译英语情感词典，可以在资源较少的情况下生成高质量的情感曲线。

    

    情感曲线捕捉了一个人（或一个群体）随时间变化的情感状态。它们被广泛应用于工业和研究领域；然而，对于自动生成的情感曲线的评估工作很少。这是因为建立真实（黄金）情感曲线的困难。我们的工作首次对自动生成的情感曲线进行了系统和定量的评估。我们还比较了两种常见的情感曲线生成方法：机器学习（ML）模型和仅词典（LexO）方法。通过在9种语言的18个不同数据集上进行实验，我们表明尽管在实例级情感分类方面表现差，但LexO方法在从数百个实例中聚合信息时生成情感曲线的准确性非常高。我们还通过对六种非洲土著语言以及阿拉伯语和西班牙语的实验表明，英语情感词典的自动翻译可以用于生成高质量的情感曲线，而资源开销相对较小。

    Emotion arcs capture how an individual (or a population) feels over time. They are widely used in industry and research; however, there is little work on evaluating the automatically generated arcs. This is because of the difficulty of establishing the true (gold) emotion arc. Our work, for the first time, systematically and quantitatively evaluates automatically generated emotion arcs. We also compare two common ways of generating emotion arcs: Machine-Learning (ML) models and Lexicon-Only (LexO) methods. By running experiments on 18 diverse datasets in 9 languages, we show that despite being markedly poor at instance level emotion classification, LexO methods are highly accurate at generating emotion arcs when aggregating information from hundreds of instances. We also show, through experiments on six indigenous African languages, as well as Arabic, and Spanish, that automatic translations of English emotion lexicons can be used to generate high-quality emotion arcs in less-resource 
    
[^33]: 从理论角度揭示“思维链”背后的奥秘

    Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective. (arXiv:2305.15408v1 [cs.LG])

    [http://arxiv.org/abs/2305.15408](http://arxiv.org/abs/2305.15408)

    本文从理论层面探究了带有“思维链”提示的大型语言模型在解决基本数学和决策问题中的能力，发现自回归Transformer大小恒定即可解决任务，揭示了“思维链”提示的背后机制。

    

    最近的研究发现，"思维链"提示能够显著提高大型语言模型（LLMs）的性能，特别是在涉及数学或推理的复杂任务中。尽管获得了巨大的实证成功，但“思维链”背后的机制以及它如何释放LLMs的潜力仍然是神秘的。本文首次从理论上回答了这些问题。具体而言，我们研究了LLMs带有“思维链”在解决基本数学和决策问题中的能力。我们首先给出一个不可能的结果，表明任何有限深度的Transformer都不能直接输出正确的基本算术/方程任务的答案，除非模型大小随着输入长度的增加呈超多项式增长。相反，我们通过构造证明，大小恒定的自回归Transformer足以通过使用常用的数学语言形式生成“思维链”推导来解决这两个任务。

    Recent studies have discovered that Chain-of-Thought prompting (CoT) can dramatically improve the performance of Large Language Models (LLMs), particularly when dealing with complex tasks involving mathematics or reasoning. Despite the enormous empirical success, the underlying mechanisms behind CoT and how it unlocks the potential of LLMs remain elusive. In this paper, we take a first step towards theoretically answering these questions. Specifically, we examine the capacity of LLMs with CoT in solving fundamental mathematical and decision-making problems. We start by giving an impossibility result showing that any bounded-depth Transformer cannot directly output correct answers for basic arithmetic/equation tasks unless the model size grows super-polynomially with respect to the input length. In contrast, we then prove by construction that autoregressive Transformers of a constant size suffice to solve both tasks by generating CoT derivations using a commonly-used math language forma
    
[^34]: 使用OOD案例测试大型语言模型的普遍演绎推理能力

    Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples. (arXiv:2305.15269v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.15269](http://arxiv.org/abs/2305.15269)

    该研究使用OOD案例测试了大型语言模型的普遍演绎推理能力，并通过构建新的推理数据集进行了探究。研究结果表明，这些模型能够推广到更复杂的证明。

    

    鉴于证明空间的庞大，任何具有普遍演绎推理能力的模型必须能够推理更复杂的证明。最近的研究表明，大型语言模型(LLMs)在给定推理链条提示的情况下具有某些抽象演绎推理能力。然而，它们主要是在使用莫德斯坦斯或特定大小的证明上进行测试，并且与上下文示例的分布相同。为了衡量LLM的普遍演绎推理能力，我们测试了广泛的演绎规则，并测量它们推理更复杂证明的能力，方法包括深度泛化、宽度泛化和组合泛化。为了便于系统的探索，我们构建了一个新的合成和可编程推理数据集，可以对演绎规则和证明复杂性进行控制。我们对四个具有不同大小和训练目标的LLMs进行了实验，结果显示它们能够推广到复杂的证明。

    Given the intractably large size of the space of proofs, any model that is capable of general deductive reasoning must generalize to proofs of greater complexity. Recent studies have shown that large language models (LLMs) possess some abstract deductive reasoning ability given chain-of-thought prompts. However, they have primarily been tested on proofs using modus ponens or of a specific size, and from the same distribution as the in-context examples. To measure the general deductive reasoning ability of LLMs, we test on a broad set of deduction rules and measure their ability to generalize to more complex proofs from simpler demonstrations from multiple angles: depth-, width-, and compositional generalization. To facilitate systematic exploration, we construct a new synthetic and programmable reasoning dataset that enables control over deduction rules and proof complexity. Our experiments on four LLMs of various sizes and training objectives show that they are able to generalize to c
    
[^35]: 将语言模型改进为自动压缩器以提高模型上下文的利用效率

    Adapting Language Models to Compress Contexts. (arXiv:2305.14788v1 [cs.CL])

    [http://arxiv.org/abs/2305.14788](http://arxiv.org/abs/2305.14788)

    本论文提出了一种将预训练的语言模型改进为自动压缩器的方法，能够将长篇文本压缩成紧凑的摘要向量，提高上下文的利用效率和降低计算成本，同时通过在上下文学习中的应用，证明了该方法能够提高精度并降低推断成本。

    

    基于Transformer的语言模型是功能强大且广泛应用的工具，但其有限的上下文窗口和高计算成本约束了其实用性。本文提出了将预训练的语言模型改进为自动压缩器，能够将长篇文本压缩成紧凑的摘要向量，从而提高上下文的利用效率和降低计算成本。同时，摘要向量通过无监督学习的方式进行训练，并作为软提示被模型使用。

    Transformer-based language models (LMs) are powerful and widely-applicable tools, but their usefulness is constrained by a finite context window and the expensive computational cost of processing long text documents. We propose to adapt pre-trained LMs into AutoCompressors. These models are capable of compressing long contexts into compact summary vectors, which are then accessible to the model as soft prompts. Summary vectors are trained with an unsupervised objective, whereby long documents are processed in segments and summary vectors from all previous segments are used in language modeling. We fine-tune OPT models on sequences of up to 30,720 tokens and show that AutoCompressors can utilize long contexts to improve perplexity. We evaluate AutoCompressors on in-context learning by compressing task demonstrations. We find that summary vectors are good substitutes for plain-text demonstrations, increasing accuracy while reducing inference cost. Finally, we explore the benefits of pre-
    
[^36]: 连续和离散空间的桥梁: 通过组合操作进行可解释的句子表示学习

    Bridging Continuous and Discrete Spaces: Interpretable Sentence Representation Learning via Compositional Operations. (arXiv:2305.14599v1 [cs.CL])

    [http://arxiv.org/abs/2305.14599](http://arxiv.org/abs/2305.14599)

    本文提出了InterSent框架，探索将不同的组合属性纳入句子嵌入空间中使嵌入变换变为组合句子操作，实现了可解释的句子表示学习。

    

    传统的句子嵌入模型将句子编码为向量表示，以捕捉诸如句子语义相似性之类的有用属性。然而，除了相似性外，句子语义还可以通过组合操作（如句子融合或差异）进行解释。不清楚是否可以直接将句子的组合语义反映为嵌入空间中的组合操作。为了更有效地连接连续嵌入和离散文本空间，我们探索了将各种组合性质合并到句子嵌入空间中的可行性，从而允许我们将嵌入变换解释为组合句子操作。我们提出了InterSent，一种学习可解释的句子嵌入的端到端框架，它支持嵌入空间中的组合句子操作。我们的方法优化操作器网络和瓶颈编码器-解码器模型，以产生有意义的生成句子。

    Traditional sentence embedding models encode sentences into vector representations to capture useful properties such as the semantic similarity between sentences. However, in addition to similarity, sentence semantics can also be interpreted via compositional operations such as sentence fusion or difference. It is unclear whether the compositional semantics of sentences can be directly reflected as compositional operations in the embedding space. To more effectively bridge the continuous embedding and discrete text spaces, we explore the plausibility of incorporating various compositional properties into the sentence embedding space that allows us to interpret embedding transformations as compositional sentence operations. We propose InterSent, an end-to-end framework for learning interpretable sentence embeddings that supports compositional sentence operations in the embedding space. Our method optimizes operator networks and a bottleneck encoder-decoder model to produce meaningful an
    
[^37]: FOCUS：基于单语言的预训练多语言模型的有效嵌入初始化方法

    FOCUS: Effective Embedding Initialization for Specializing Pretrained Multilingual Models on a Single Language. (arXiv:2305.14481v1 [cs.CL])

    [http://arxiv.org/abs/2305.14481](http://arxiv.org/abs/2305.14481)

    本文提出了FOCUS，在多语言源模型设置下，该方法使用重叠标记组合有效地初始化预训练的模型权重，提高了这种方法在适应新语言时的性能表现。

    

    在低资源语言中获得高质量的语言模型需要大量的数据和计算。使用在高资源语言上预训练的模型权重作为温启动，可以减少此需求。为了适应新语言，需要对预训练的词汇表和嵌入进行调整。在以前的工作中，针对适应后的词汇表的嵌入初始化大多聚焦于单语言源模型。本文研究了多语言源模型设置，并提出了FOCUS-快速重叠标记组合使用Sparsemax的新型嵌入初始化方法，当适应XLM-R时，它的表现优于以前的工作。FOCUS将新增的标记表示为预训练和新词汇表之间的重叠标记组合。这些重叠标记是基于辅助标记嵌入空间中的语义相似性进行选择的。我们实现的FOCUS公开在GitHub上。

    Using model weights pretrained on a high-resource language as a warm start can reduce the need for data and compute to obtain high-quality language models in low-resource languages. To accommodate the new language, the pretrained vocabulary and embeddings need to be adapted. Previous work on embedding initialization for such adapted vocabularies has mostly focused on monolingual source models. In this paper, we investigate the multilingual source model setting and propose FOCUS - Fast Overlapping Token Combinations Using Sparsemax, a novel embedding initialization method that outperforms previous work when adapting XLM-R. FOCUS represents newly added tokens as combinations of tokens in the overlap of the pretrained and new vocabularies. The overlapping tokens are selected based on semantic similarity in an auxiliary token embedding space. Our implementation of FOCUS is publicly available on GitHub.
    
[^38]: ChatCoT: 基于工具增强的链式思维推理在基于聊天大语言模型上的应用

    ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models. (arXiv:2305.14323v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.14323](http://arxiv.org/abs/2305.14323)

    这项研究提出了一个基于工具增强的链式思维推理框架 ChatCoT，用于基于聊天的大型语言模型，通过聊天的方式实现多轮推理，巧妙地结合了思维链跟踪和工具操作的方法，提高了大型语言模型的推理能力。

    

    虽然大型语言模型在各种评估基准中取得了出色的表现，但它们在需要特定知识和多次推理的复杂推理任务中仍然存在困难。为了提高推理能力，我们提出了一种基于工具增强的链式思维推理框架 ChatCoT，用于基于聊天的大型语言模型。在 ChatCoT 中，我们将链式思维推理建模为多轮对话，通过聊天的方式更自然地利用工具。在每个轮次中，LLM 能够交互工具或进行推理。我们的方法可以有效利用基于聊天的 LLM 的多轮对话能力，并以统一的方式集成思维链跟踪和工具操作。特别地，我们通过工具、任务和推理格式初始化对话的早期轮次，并提出了一个迭代的工具增强推理步骤来逐步进行工具增强推理。实验结果在两个任务上展示了 ChatCoT 的有效性。

    Although large language models (LLMs) have achieved excellent performance in a variety of evaluation benchmarks, they still struggle in complex reasoning tasks which require specific knowledge and multi-hop reasoning. To improve the reasoning abilities, we propose \textbf{ChatCoT}, a tool-augmented chain-of-thought reasoning framework for chat-based LLMs. In ChatCoT, we model the chain-of-thought~(CoT) reasoning as multi-turn conversations, to utilize tools in a more natural way through chatting. At each turn, LLMs can either interact with tools or perform the reasoning. Our approach can effectively leverage the multi-turn conversation ability of chat-based LLMs, and integrate the thought chain following and tools manipulation in a unified way. Specially, we initialize the early turns of the conversation by the tools, tasks and reasoning format, and propose an iterative \emph{tool-augmented reasoning} step to perform step-by-step tool-augmented reasoning. The experiment results on two 
    
[^39]: 让我们逐帧思考：使用视频插帧和预测评估视频思维链

    Let's Think Frame by Frame: Evaluating Video Chain of Thought with Video Infilling and Prediction. (arXiv:2305.13903v1 [cs.CL])

    [http://arxiv.org/abs/2305.13903](http://arxiv.org/abs/2305.13903)

    该论文提出了一种新的研究方向 VideoCOT，利用视觉-语言模型的多模态生成能力，以增强视频推理，同时减少处理数百或数千帧的计算复杂度。在VIP数据集上，我们基于各种视觉-语言模型进行了基准测试，展示了使用视觉-语言模型进行VideoCOT的潜力。

    

    尽管在2023年构成了所有互联网流量的65％，但视频内容在生成AI研究中却被低估了。与此同时，最近的大型语言模型（LLM）已越来越多地与视觉模态融合。将视频与LLM整合是下一步自然的发展方向，那么这个鸿沟如何被填补？为了推进视频推理，我们提出了一个新的研究方向，即基于视频关键帧的VideoCOT，它利用了视觉-语言模型的多模态生成能力，以增强视频推理，同时减少处理数百或数千帧的计算复杂度。我们介绍了VIP，一种可以用来评估VideoCOT的推断时间数据集，其中包含1）各种带有关键帧的真实生活视频以及相应的非结构化和结构化场景描述，2）两个新的视频推理任务：视频插帧和场景预测。我们在VIP上对各种视觉-语言模型进行了基准测试，展示了使用视觉-语言模型进行VideoCOT的潜力。

    Despite constituting 65% of all internet traffic in 2023, video content is underrepresented in generative AI research. Meanwhile, recent large language models (LLMs) have become increasingly integrated with capabilities in the visual modality. Integrating video with LLMs is a natural next step, so how can this gap be bridged? To advance video reasoning, we propose a new research direction of VideoCOT on video keyframes, which leverages the multimodal generative abilities of vision-language models to enhance video reasoning while reducing the computational complexity of processing hundreds or thousands of frames. We introduce VIP, an inference-time dataset that can be used to evaluate VideoCOT, containing 1) a variety of real-life videos with keyframes and corresponding unstructured and structured scene descriptions, and 2) two new video reasoning tasks: video infilling and scene prediction. We benchmark various vision-language models on VIP, demonstrating the potential to use vision-la
    
[^40]: C-Eval: 用于基础模型的多级多学科中文评估套件

    C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models. (arXiv:2305.08322v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.08322](http://arxiv.org/abs/2305.08322)

    C-Eval是第一个专为中文基础模型评估而设计的全面套件，涵盖52个不同学科的多级别选择题和挑战性科目。评估结果表明，只有GPT-4能够达到超过60％的平均准确率，还有改进空间。

    

    随着大型语言模型（LLM）的快速发展，迫切需要新的自然语言处理基准来评估这些模型的高级知识和推理能力。我们介绍了C-Eval，这是第一个专为中文语境下基础模型评估而设计的全面评估套件。C-Eval包含四个难度级别的选择题：初中、高中、大学和专业水平。这些题目涵盖52个不同的学科，包括人文、科学和工程学科。C-Eval还配备了C-Eval Hard，这是C-Eval中一些极具挑战性的科目，需要高级推理能力才能解决。我们对包括英文和中文模型在内的最先进的LLM在C-Eval上进行了全面评估。结果表明，只有GPT-4可以实现超过60％的平均准确率，这表明当前的LLM仍有很大的改进空间。我们期望C-Eval将有助于分析重要的优势和短板。

    New NLP benchmarks are urgently needed to align with the rapid development of large language models (LLMs). We present C-Eval, the first comprehensive Chinese evaluation suite designed to assess advanced knowledge and reasoning abilities of foundation models in a Chinese context. C-Eval comprises multiple-choice questions across four difficulty levels: middle school, high school, college, and professional. The questions span 52 diverse disciplines, ranging from humanities to science and engineering. C-Eval is accompanied by C-Eval Hard, a subset of very challenging subjects in C-Eval that requires advanced reasoning abilities to solve. We conduct a comprehensive evaluation of the most advanced LLMs on C-Eval, including both English- and Chinese-oriented models. Results indicate that only GPT-4 could achieve an average accuracy of over 60%, suggesting that there is still significant room for improvement for current LLMs. We anticipate C-Eval will help analyze important strengths and sho
    
[^41]: 基于语义空间的多属性可控对话生成中的加权解码

    Semantic Space Grounded Weighted Decoding for Multi-Attribute Controllable Dialogue Generation. (arXiv:2305.02820v1 [cs.CL])

    [http://arxiv.org/abs/2305.02820](http://arxiv.org/abs/2305.02820)

    该文介绍了名为DASC的可控生成框架，它利用属性语义空间的加权解码来实现多属性生成，并能够在多个方面实现最先进的控制精度和高质量的生成响应。

    

    控制聊天机器人生成具有个性、情感和对话行为等多个属性的话语是一个实际有用但鲜有研究的问题。我们提出了一种新颖的可控生成框架DASC，它通过加权解码范式具有强大的可控性，同时在属性语义空间的基础上提高了生成质量。然后，多属性生成通过多个属性嵌入的插值直观地实现。实验表明，DASC在三个方面可控生成任务中可以实现最先进的控制精度，同时产生有趣而合理的响应，即使在分布鲁棒性测试中也是如此。属性语义空间中学习到的有意义的表示的可视化也支持其有效性。

    Controlling chatbot utterance generation with multiple attributes such as personalities, emotions and dialogue acts is a practically useful but under-studied problem. We propose a novel controllable generation framework called DASC that possesses strong controllability with weighted decoding paradigm, while improving generation quality with the grounding in an attribute semantics space. Generation with multiple attributes is then intuitively implemented with an interpolation of multiple attribute embeddings. Experiments show that DASC can achieve state-of-the-art control accuracy in 3-aspect controllable generation tasks while also producing interesting and reasonably sensible responses, even if in an out-of-distribution robustness test. Visualization of the meaningful representations learned in the attribute semantic space also supports its effectiveness.
    
[^42]: 用Transformer逼近CKY算法

    Approximating CKY with Transformers. (arXiv:2305.02386v1 [cs.CL])

    [http://arxiv.org/abs/2305.02386](http://arxiv.org/abs/2305.02386)

    本文研究了Transformer模型逼近CKY算法的能力，提出了一种用梯度预测解析的方法，在标准基准测试中表现竞争力更好，同时速度更快。在随机PCFG下解析时，性能下降，但加入额外的归纳偏差是有帮助的。

    

    本文研究了Transformer模型逼近CKY算法的能力，直接预测句子的解析，避免了CKY算法对句子长度的三次依赖。在标准的组成句分析基准测试中，我们发现这种方法比使用CKY的可比分析器取得了竞争或更好的性能，同时速度更快。我们还评估了在随机PCFG下进行解析的可行性。在这里，我们发现在语法变得更加模糊的情况下，性能下降，这表明Transformer没有完全捕捉到CKY计算。然而，我们也发现，结合额外的归纳偏差是有帮助的，并提出了一种新方法，利用相对于图表表示的梯度来预测解析，类比于CKY算法与图表相关的一个分区函数变体的子梯度。

    We investigate the ability of transformer models to approximate the CKY algorithm, using them to directly predict a parse and thus avoid the CKY algorithm's cubic dependence on sentence length. We find that on standard constituency parsing benchmarks this approach achieves competitive or better performance than comparable parsers that make use of CKY, while being faster. We also evaluate the viability of this approach for parsing under random PCFGs. Here we find that performance declines as the grammar becomes more ambiguous, suggesting that the transformer is not fully capturing the CKY computation. However, we also find that incorporating additional inductive bias is helpful, and we propose a novel approach that makes use of gradients with respect to chart representations in predicting the parse, in analogy with the CKY algorithm being the subgradient of a partition function variant with respect to the chart.
    
[^43]: 大语言模型时代的安全分析：聊天GPT在STPA案例研究中的应用

    Safety Analysis in the Era of Large Language Models: A Case Study of STPA using ChatGPT. (arXiv:2304.01246v1 [cs.CL])

    [http://arxiv.org/abs/2304.01246](http://arxiv.org/abs/2304.01246)

    本文研究了大型语言模型在系统论过程分析（STPA）中的应用，并采用ChatGPT对自动紧急制动（AEB）系统进行了案例研究。结果表明，重复双工交互方法是最有效的，并显着提高了STPA的质量。本研究证明，LLMs可以应用于安全分析，并为安全关键系统提供有价值的见解。

    

    大型语言模型（LLMs），如ChatGPT和BERT，由于其具有类似于人类的对话，在许多知识领域中具有详细和明确的答案，正在引领一场新的人工智能热潮。虽然LLMs正在迅速应用于许多人工智能应用领域，但我们对以下问题感兴趣：安全关键系统的安全分析是否可以利用LLMs？为了回答这个问题，我们使用ChatGPT对自动紧急制动（AEB）系统的系统论过程分析（STPA）进行了案例研究。STPA是最普遍的危险分析技术之一，但它存在诸多局限性，例如高复杂性和主观性，本文旨在探讨ChatGPT的应用，以解决这些局限性。具体而言，通过考虑其与人类专家的交互，研究了三种将ChatGPT纳入STPA中的方法：一次性单工交互、重复单工交互和重复双工交互。比较结果表明：（i）在没有人类专家的情况下使用ChatGPT不能为STPA提供足够的信息；（ii）一次性单工交互对STPA有帮助，但不如重复交互有效；（iii）重复双工交互一致优于其他方法，并显着提高了STPA的质量。我们的研究表明，LLMs可以应用于安全分析，并为AEB以外的其他安全关键系统提供有价值的见解。

    Large Language Models (LLMs), such as ChatGPT and BERT, are leading a new AI heatwave due to its human-like conversations with detailed and articulate answers across many domains of knowledge. While LLMs are being quickly applied to many AI application domains, we are interested in the following question: Can safety analysis for safety-critical systems make use of LLMs? To answer, we conduct a case study of Systems Theoretic Process Analysis (STPA) on Automatic Emergency Brake (AEB) systems using ChatGPT. STPA, one of the most prevalent techniques for hazard analysis, is known to have limitations such as high complexity and subjectivity, which this paper aims to explore the use of ChatGPT to address. Specifically, three ways of incorporating ChatGPT into STPA are investigated by considering its interaction with human experts: one-off simplex interaction, recurring simplex interaction, and recurring duplex interaction. Comparative results reveal that: (i) using ChatGPT without human exp
    
[^44]: 关于摩洛哥方言文本情感分类的实验研究

    An Experimental Study on Sentiment Classification of Moroccan dialect texts in the web. (arXiv:2303.15987v1 [cs.CL])

    [http://arxiv.org/abs/2303.15987](http://arxiv.org/abs/2303.15987)

    本研究采用机器学习模型对YouTube评论中的摩洛哥方言进行情感分类，采用多种文本预处理和数据表示技术对文本进行分析，研究该方言的意见和情感表达。

    

    随着社交媒体网站的迅速增长，自动获取用户反馈成为评估其在线趋势和行为的重要任务。尽管信息大量可用，阿拉伯使用者数量增加，但很少有研究处理阿拉伯方言。本文旨在准确研究在YouTube评论中表达的真实摩洛哥方言文本的观点和情感，使用一些众所周知且常用的情感分析方法进行。通过采用许多文本预处理和数据表示技术，我们旨在比较我们使用最常用的监督分类器进行分类结果：K最近邻（KNN）、支持向量机（SVM）、朴素贝叶斯（NB）和深度学习（DL）分类器，这些都是基于我们收集和手动注释的YouTube摩洛哥方言数据集。

    With the rapid growth of the use of social media websites, obtaining the users' feedback automatically became a crucial task to evaluate their tendencies and behaviors online. Despite this great availability of information, and the increasing number of Arabic users only few research has managed to treat Arabic dialects. The purpose of this paper is to study the opinion and emotion expressed in real Moroccan texts precisely in the YouTube comments using some well-known and commonly used methods for sentiment analysis. In this paper, we present our work of Moroccan dialect comments classification using Machine Learning (ML) models and based on our collected and manually annotated YouTube Moroccan dialect dataset. By employing many text preprocessing and data representation techniques we aim to compare our classification results utilizing the most commonly used supervised classifiers: k-nearest neighbors (KNN), Support Vector Machine (SVM), Naive Bayes (NB), and deep learning (DL) classif
    
[^45]: BERT是否盲目？探索视觉语言预训练对视觉语言理解的影响。

    Is BERT Blind? Exploring the Effect of Vision-and-Language Pretraining on Visual Language Understanding. (arXiv:2303.12513v1 [cs.CV])

    [http://arxiv.org/abs/2303.12513](http://arxiv.org/abs/2303.12513)

    本文调查了视觉语言预训练对仅文本任务的表现是否有提高。作者提出了一套视觉语言理解任务，证明了多模态训练的文本编码器在视觉推理方面的优越性。

    

    大多数人使用视觉想象来理解和推理语言，但是像BERT这样的模型使用在仅包括文本的预训练过程中获取的知识来推理语言。在本文中，我们调查了视觉语言预训练是否可以提高在涉及隐含视觉推理的仅文本任务上的表现，重点是零样本探测方法。我们提出了一套用于探测文本编码器模型视觉推理能力的视觉语言理解（VLU）任务，以及各种非视觉自然语言理解（NLU）任务用于比较。我们还贡献了一种新型的零样本知识探测方法，Stroop probing，用于将像CLIP这样的模型应用于仅文本任务，而不需要像BERT模型的掩码语言建模头那样的预测头。我们证明了SOTA多模态训练的文本编码器在VLU任务上优于单模态训练的文本编码器，但在NLU任务上不及它们。

    Most humans use visual imagination to understand and reason about language, but models such as BERT reason about language using knowledge acquired during text-only pretraining. In this work, we investigate whether vision-and-language pretraining can improve performance on text-only tasks that involve implicit visual reasoning, focusing primarily on zero-shot probing methods. We propose a suite of visual language understanding (VLU) tasks for probing the visual reasoning abilities of text encoder models, as well as various non-visual natural language understanding (NLU) tasks for comparison. We also contribute a novel zero-shot knowledge probing method, Stroop probing, for applying models such as CLIP to text-only tasks without needing a prediction head such as the masked language modelling head of models like BERT. We show that SOTA multimodally trained text encoders outperform unimodally trained text encoders on the VLU tasks while being underperformed by them on the NLU tasks, lendin
    
[^46]: xCodeEval：一个用于代码理解、生成、翻译和检索的大规模多语言多任务基准

    xCodeEval: A Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and Retrieval. (arXiv:2303.03004v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.03004](http://arxiv.org/abs/2303.03004)

    xCodeEval是一个大规模多语言多任务的基准，用于评估预训练的大型语言模型生成、修复、翻译和检索代码的能力，并解决了以往仅关注特定任务和缺乏训练数据的问题。

    

    解决问题的能力是智能的标志，并且一直是 AI 的目标。能够创建作为问题解决方案的程序的 AI 系统，或者协助开发人员编写程序，都可以提高生产率并使编程更易于访问。最近，预训练的大型语言模型在从自然语言描述生成新代码、修复有问题的代码、在不同语言之间进行代码翻译以及检索相关代码片段方面展示出了令人印象深刻的能力。然而，这些模型的评估通常是分散在仅一个或两个特定任务上，在少数语言、在部分粒度水平（例如函数级别）上进行，并且在许多情况下缺乏适当的训练数据。更为令人担忧的是，在大多数情况下，生成的代码的评估是以仅仅词汇重叠为基础，而不是实际执行，而两段代码段的语义相似性（或等效性）仅取决于它们的“执行相似性”。

    The ability to solve problems is a hallmark of intelligence and has been an enduring goal in AI. AI systems that can create programs as solutions to problems or assist developers in writing programs can increase productivity and make programming more accessible. Recently, pre-trained large language models have shown impressive abilities in generating new codes from natural language descriptions, repairing buggy codes, translating codes between languages, and retrieving relevant code segments. However, the evaluation of these models has often been performed in a scattered way on only one or two specific tasks, in a few languages, at a partial granularity (e.g., function) level and in many cases without proper training data. Even more concerning is that in most cases the evaluation of generated codes has been done in terms of mere lexical overlap rather than actual execution whereas semantic similarity (or equivalence) of two code segments depends only on their ``execution similarity'', 
    
[^47]: CiteBench：科学引文文本生成基准测试

    CiteBench: A benchmark for Scientific Citation Text Generation. (arXiv:2212.09577v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09577](http://arxiv.org/abs/2212.09577)

    CiteBench是一个科学引文文本生成基准测试，旨在解决研究加速导致的解读和总结先前工作的困难。该基准测试可以进行标准化评估，研究不同任务设计和领域的引文文本生成模型。对多个基线模型的大量测试发现了新的见解。

    

    科学通过逐步建立在科学出版物中记录的先前知识体系的基础上提高。许多领域的研究加速使得跟上最新发展并总结不断增长的先前工作的困难。为了解决这个问题，引文文本生成的任务旨在在给定需要引用的论文和引用论文的情境的情况下生成准确的文本摘要。现有的引文文本生成研究基于广泛分歧的任务定义，这使得系统地研究这个任务变得困难。为了应对这个挑战，我们提出了CiteBench：一个引文文本生成基准测试，它统一了多个不同的数据集，使得可以对任务设计和领域中的引文文本生成模型进行标准化评估。使用这个新的基准测试，我们调查了多个强基准的性能，测试了它们在数据集之间的可转移性，并提供了对任务的新见解。

    Science progresses by incrementally building upon the prior body of knowledge documented in scientific publications. The acceleration of research across many fields makes it hard to stay up-to-date with the recent developments and to summarize the ever-growing body of prior work. To target this issue, the task of citation text generation aims to produce accurate textual summaries given a set of papers-to-cite and the citing paper context. Existing studies in citation text generation are based upon widely diverging task definitions, which makes it hard to study this task systematically. To address this challenge, we propose CiteBench: a benchmark for citation text generation that unifies multiple diverse datasets and enables standardized evaluation of citation text generation models across task designs and domains. Using the new benchmark, we investigate the performance of multiple strong baselines, test their transferability between the datasets, and deliver new insights into the task 
    
[^48]: 可解释的序列分类通过原型轨迹

    Interpretable Sequence Classification Via Prototype Trajectory. (arXiv:2007.01777v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2007.01777](http://arxiv.org/abs/2007.01777)

    ProtoryNet是一种基于原型轨迹的可解释深度神经网络，它通过捕捉时间模式和原型的近似程度来进行文本分类，并实现了直观和细致的推理过程解释。

    

    我们提出了一种新颖的用于文本分类的可解释深度神经网络，称为ProtoryNet，它基于原型轨迹的新概念。受现代语言学中的原型理论的启发，ProtoryNet通过为文本序列中的每个句子找到最相似的原型，并将每个句子与相应的活动原型的接近程度输入到RNN主干中进行预测。然后，RNN主干捕捉到原型的时间模式，我们称之为原型轨迹。原型轨迹能够直观而细致地解释RNN模型的推理过程，类似于人类分析文本的方式。我们还设计了原型修剪过程，以减少模型使用的原型总数，以提高解释性。在多个公共数据集上的实验证明，ProtoryNet比基线的基于原型的深度神经网络更准确，并减少了与现有模型相比的性能差距。

    We propose a novel interpretable deep neural network for text classification, called ProtoryNet, based on a new concept of prototype trajectories. Motivated by the prototype theory in modern linguistics, ProtoryNet makes a prediction by finding the most similar prototype for each sentence in a text sequence and feeding an RNN backbone with the proximity of each sentence to the corresponding active prototype. The RNN backbone then captures the temporal pattern of the prototypes, which we refer to as prototype trajectories. Prototype trajectories enable intuitive and fine-grained interpretation of the reasoning process of the RNN model, in resemblance to how humans analyze texts. We also design a prototype pruning procedure to reduce the total number of prototypes used by the model for better interpretability. Experiments on multiple public data sets show that ProtoryNet is more accurate than the baseline prototype-based deep neural net and reduces the performance gap compared to state-o
    

