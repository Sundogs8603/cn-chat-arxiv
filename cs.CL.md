# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Verbs in Action: Improving verb understanding in video-language models.](http://arxiv.org/abs/2304.06708) | 本文提出了一个新的动词聚焦对比框架，通过利用预训练的大型语言模型和执行细粒度的动词短语对齐损失来改善基于CLIP的视频语言模型的动词理解能力，实现了在三个聚焦于动词理解的下游任务的零样本性能最先进的结果。 |
| [^2] | [Diagnostic Benchmark and Iterative Inpainting for Layout-Guided Image Generation.](http://arxiv.org/abs/2304.06671) | 本文提出了布局引导下图像生成的诊断基准LayoutBench，对数量、位置、大小和形状四种空间控制技能进行了研究，发现好的ID布局控制在任意布局的野外环境下可能不具有良好的推广性。接着，我们提出了一种新的基准方法IterInpaint通过修复逐步生成前景和背景区域，显现出在OOD布局方面更强的通用性。 |
| [^3] | [G2T: A simple but versatile framework for topic modeling based on pretrained language model and community detection.](http://arxiv.org/abs/2304.06653) | G2T是一种基于预训练语言模型和社区检测的主题建模框架，自动评估表明，G2T在多个数据集上均与当前最先进的方法相比表现更好。 |
| [^4] | [How Useful are Educational Questions Generated by Large Language Models?.](http://arxiv.org/abs/2304.06638) | 本文研究通过结合CTG和问题分类生成的输出，通过教师评估证明这些生成的问题质量高且足够有用，有极大的应用潜力。 |
| [^5] | [PGTask: Introducing the Task of Profile Generation from Dialogues.](http://arxiv.org/abs/2304.06634) | 对话系统的个性化需要个人资料信息，而从对话中提取/生成个人资料信息是一项基本需求。为此，我们提出了档案生成任务（PGTask）并提供了相关的数据集和基准，该任务使得研究者可以更好地了解档案生成任务的挑战和可能的解决方案。 |
| [^6] | [Exploring the State of the Art in Legal QA Systems.](http://arxiv.org/abs/2304.06623) | 法律问题回答系统的研究面临着复杂性和多样性等挑战，但其在客户服务、教育、研究和跨语言交流等方面具有广泛应用。 |
| [^7] | [ChatGPT-4 Outperforms Experts and Crowd Workers in Annotating Political Twitter Messages with Zero-Shot Learning.](http://arxiv.org/abs/2304.06588) | 本文评估了ChatGPT-4在政治Twitter相关推文注释任务中的表现，结果显示它在准确性、可靠性和偏见方面皆优于人类标注，尤其是它能通过零样本学习准确注释需要基于上下文知识和作者意向的推文，这将使得规模化的文本数据研究成为可能，并在社会科学的解释性研究中产生巨大影响。 |
| [^8] | [Are LLMs All You Need for Task-Oriented Dialogue?.](http://arxiv.org/abs/2304.06556) | LLM在任务导向型对话中表现不如专门的任务特定模型，但如果提供正确的槽值，仍有引导对话成功结束的能力，并且可通过真实信念状态分布或域内示例的访问获得更好的表现。 |
| [^9] | [One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era.](http://arxiv.org/abs/2304.06488) | ChatGPT是生成式AI的一小步，也是AGI的一大步，我们进行了综述，并对其如何演变为AIGC展望不同于以往的通用AI生成内容的发展道路。 |
| [^10] | [Masakhane-Afrisenti at SemEval-2023 Task 12: Sentiment Analysis using Afro-centric Language Models and Adapters for Low-resource African Languages.](http://arxiv.org/abs/2304.06459) | 该论文介绍了在SemEval-2023任务12中使用Afro-centric语言模型和适配器进行非洲低资源语言的情感分析。使用预训练的Afro-centric语言模型可以提高性能。使用适配器方法可以实现对于有限资源语言的零样本迁移。 |
| [^11] | [PDF-VQA: A New Dataset for Real-World VQA on PDF Documents.](http://arxiv.org/abs/2304.06447) | 该研究提出了一个新的文档VQA数据集PDF-VQA，以多个页面的完整文档作为研究对象，通过机器学习模型识别与处理文档元素、结构和内容等方面，为解决真实世界中的文档理解问题提供新的资源。 |
| [^12] | [SpectFormer: Frequency and Attention is what you need in a Vision Transformer.](http://arxiv.org/abs/2304.06446) | 本文提出了结合多头注意力和谱层的Spectformer架构，可以得到更好的性能表现，提高了top-1准确率2%。 |
| [^13] | [Emergence of Symbols in Neural Networks for Semantic Understanding and Communication.](http://arxiv.org/abs/2304.06377) | 本文介绍了一种名为SEA-net的神经网络解决方案，可以生成符号，实现语义理解和交流。这些符号可以捕捉到组成性语义信息，并呈现类似自然语言的内在结构。 |
| [^14] | [Towards hypergraph cognitive networks as feature-rich models of knowledge.](http://arxiv.org/abs/2304.06375) | 本研究提出了特征丰富认知超图作为人类记忆定量模型来预测概念特征，与成对连接和缺乏特征的网络模型相比，特征丰富认知超图表现更好，并且涉及更高阶关联的超链接在具有相似心理语言学特征的概念之间优先形成，这反映了共享认知维度的存在。 |
| [^15] | [Sign Language Translation from Instructional Videos.](http://arxiv.org/abs/2304.06371) | 本论文描述了如何使用I3D视频特征培训Transformer模型，据此对How2Sign数据集进行手语翻译。作者提供了公共代码和首个开源实现。 |
| [^16] | [AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models.](http://arxiv.org/abs/2304.06364) | AGIEval是一个以人为中心设计的基准测试工具，用于评估基础模型在人类中心标准化考试上的表现。GPT-4在SAT、LSAT和数学比赛方面超越了人类平均表现，展示了当代基础模型在人类级任务中的非凡性能。 |
| [^17] | [Computational modeling of semantic change.](http://arxiv.org/abs/2304.06337) | 本文概述了语义变化的计算建模方法，讨论了不同模型在处理语义变化时的优缺点以及评估结果的途径。 |
| [^18] | [Rule-based detection of access to education and training in Germany.](http://arxiv.org/abs/2304.06307) | 本研究提出了一种基于规则的新方法，通过自动检测德国培训提供和广告中的教育和培训准入，以帮助匹配培训寻求者和提供者。 |
| [^19] | [LasUIE: Unifying Information Extraction with Latent Adaptive Structure-aware Generative Language Model.](http://arxiv.org/abs/2304.06248) | 本论文基于已有的生成语言模型，提出了一种结构感知GLM模型，通过异构结构感知器后训练，引入了句法知识，提出了结构广播器引导更好的生成，以及引入了面向任务的结构微调机制。在三个基准数据集上实验表明，该模型优于现有模型，展示了结构感知在信息提取中的有效性。 |
| [^20] | [LeafAI: query generator for clinical cohort discovery rivaling a human programmer.](http://arxiv.org/abs/2304.06203) | 该研究开发了一个名为LeafAI的系统，可以生成数据模型不受限制的查询，同时为复杂的临床试验资格标准提供新颖的逻辑推理能力。 |
| [^21] | [Using large language models for (de-)formalization and natural argumentation exercises for beginner's students.](http://arxiv.org/abs/2304.06186) | 本研究描述了两个系统，利用大型语言模型，自动纠正初学者在逻辑语言转化和自然语言论证方面的问题。 |
| [^22] | [LINGO : Visually Debiasing Natural Language Instructions to Support Task Diversity.](http://arxiv.org/abs/2304.06184) | 本论文介绍了针对自然语言任务指令中的偏见进行分析的新工具LINGO，展示了如何通过视觉分析来支持用户纠正偏见。 |
| [^23] | [Detection of Fake Generated Scientific Abstracts.](http://arxiv.org/abs/2304.06148) | 本研究使用GPT-3模型生成科学论文摘要，并通过各种文本表征方法结合机器学习模型，探讨识别机器写作文本的有效性。研究分析了模型的性能，揭示了人工智能生成文本的能力和局限性。 |
| [^24] | [Social Biases through the Text-to-Image Generation Lens.](http://arxiv.org/abs/2304.06034) | 本文研究了文本到图像生成技术中存在的社会偏见，主要集中在职业、人格特征和日常情境等方面。实验证明，这些模型存在排除特定人群的职业偏见。 |
| [^25] | [Learning Homographic Disambiguation Representation for Neural Machine Translation.](http://arxiv.org/abs/2304.05860) | 本文提出了一种利用同义词句子建立同形异义词词级消歧表示（HDR）以改进神经机器翻译的方法。 |
| [^26] | [Measuring Gender Bias in West Slavic Language Models.](http://arxiv.org/abs/2304.05783) | 本研究分析了西斯拉夫语言模型中的性别偏差，发现捷克语、波兰语和斯洛伐克语均存在相似程度的性别偏见。这一研究填补了研究非英语语言模型性别偏见的空白。 |
| [^27] | [Distinguishing ChatGPT(-3.5, -4)-generated and human-written papers through Japanese stylometric analysis.](http://arxiv.org/abs/2304.05534) | 本研究通过比较GPT(-3.5和-4)生成的日语文体特征与人类写作的学术论文，证明了它们在文体特征上有显著区别。 |
| [^28] | [Are Large Language Models Ready for Healthcare? A Comparative Study on Clinical Language Understanding.](http://arxiv.org/abs/2304.05368) | 本研究全面评估了大型语言模型在临床语言理解任务上的表现，并引入自问自答提示策略来提高LLMs在医疗保健相关任务中的效果。 |
| [^29] | [OpenAGI: When LLM Meets Domain Experts.](http://arxiv.org/abs/2304.04370) | 基于大型语言模型的OpenAGI平台通过整合领域专家模型和自然语言问答形式，实现复杂任务解决。 |
| [^30] | [Unlocking the Potential of ChatGPT: A Comprehensive Exploration of its Applications, Advantages, Limitations, and Future Directions in Natural Language Processing.](http://arxiv.org/abs/2304.02017) | 本文全面探讨了ChatGPT在自然语言处理中的应用、优点和局限性，强调了使用这个强大工具时的道德考虑，为人工智能和NLP领域的讨论做出了贡献。 |
| [^31] | [ChatGPT as a Factual Inconsistency Evaluator for Abstractive Text Summarization.](http://arxiv.org/abs/2303.15621) | 本文研究了ChatGPT作为抽象文本摘要中事实不一致性评估器的能力，证明其在不需要注释数据和高计算复杂度的情况下，在粗粒度和细粒度的任务中表现出了最先进的性能。 |
| [^32] | [Hulk: Graph Neural Networks for Optimizing Regionally Distributed Computing Systems.](http://arxiv.org/abs/2302.13741) | 本文提出了一种基于图神经网络以优化区域分布式计算系统的方法，称为 Hulk。该方法能够提高分布式训练的效率，减少数据通信的开销，实现最佳的模型分布式部署。 |
| [^33] | [Towards Inferential Reproducibility of Machine Learning Research.](http://arxiv.org/abs/2302.04054) | 本研究提出利用线性混合效应模型（LMEM）来分析机器学习性能评估分数，并考虑多个方差来源及其与数据特性相互作用，从而评估可靠性和可复制性，促进对机器学习算法行为的更全面理解。 |
| [^34] | [Active Learning for Multilingual Semantic Parser.](http://arxiv.org/abs/2301.12920) | 本研究提出了一种多语言语义解析的主动学习方法(AL-MSP), 选择一个现有数据集的子集进行翻译，通过优先选择多样化逻辑形式结构和更多词汇选择的示例，以及一种新的无需额外注释成本的超参数调整方法，有效减少了翻译成本，并取得了比其他基线更好的解析性能。 |
| [^35] | [RPN: A Word Vector Level Data Augmentation Algorithm in Deep Learning for Language Understanding.](http://arxiv.org/abs/2212.05961) | RPN是一种基于词向量级别的数据增强算法，通过引入噪声修改原始文本的词嵌入，更好地捕捉自然语言变化，并在自然语言理解任务中表现出优异的性能。 |
| [^36] | [SQA3D: Situated Question Answering in 3D Scenes.](http://arxiv.org/abs/2210.07474) | 本文提出了一个新的任务，即评估具有场景理解能力的代理人在三维场景中的情境问答。基于650个场景的数据集为智能代理人的推理能力考察提供了广泛且大量的问题，这对当前的多模式，特别是3D推理模型提出了很大挑战。 |
| [^37] | [Multilingual BERT has an accent: Evaluating English influences on fluency in multilingual models.](http://arxiv.org/abs/2210.05619) | 本文研究了多语言模型的语言流畅性问题，发现高资源语言的语法结构会对低资源语言产生影响，导致多语言BERT具有英语语音特色。 |
| [^38] | [PePe: Personalized Post-editing Model utilizing User-generated Post-edits.](http://arxiv.org/abs/2209.10139) | 本文提出了一种个性化的自动后编辑框架PePe，在一个实时的机器翻译系统中，通过收集用户后编辑数据，结合判别模块和用户特定参数，能够有效地生成考虑到不同个人行为的句子，并在多个度量标准上优于其他基线模型。 |
| [^39] | [Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge.](http://arxiv.org/abs/2202.07138) | 本文提出了一个框架，将AI规划与自然语言处理相结合，利用显式和隐式知识来改善生成自然语言的效果。 |

# 详细

[^1]: 动词行动：改进视频语言模型中的动词理解

    Verbs in Action: Improving verb understanding in video-language models. (arXiv:2304.06708v1 [cs.CV])

    [http://arxiv.org/abs/2304.06708](http://arxiv.org/abs/2304.06708)

    本文提出了一个新的动词聚焦对比框架，通过利用预训练的大型语言模型和执行细粒度的动词短语对齐损失来改善基于CLIP的视频语言模型的动词理解能力，实现了在三个聚焦于动词理解的下游任务的零样本性能最先进的结果。

    

    理解动词对于模型化人与物体在空间和时间上如何相互作用以及与环境相互作用至关重要。最近，基于CLIP的最先进的视频语言模型在动词理解方面受限，且严重依赖名词，限制了它们在需要动作和时间理解的实际视频应用中的性能。在本文中，我们通过提出一种新的动词聚焦对比（VFC）框架，改善基于CLIP的视频语言模型的动词理解能力。该框架由两个主要组成部分组成：（1）利用预训练的大型语言模型（LLM）创建跨模态对比学习的硬负例，以及通过校准策略平衡正负对中概念的出现来平衡正负对；（2）执行细粒度的动词短语对齐损失。我们的方法在三个聚焦于动词理解的下游任务的零样本表现方面实现了最先进的结果：视频t...

    Understanding verbs is crucial to modelling how people and objects interact with each other and the environment through space and time. Recently, state-of-the-art video-language models based on CLIP have been shown to have limited verb understanding and to rely extensively on nouns, restricting their performance in real-world video applications that require action and temporal understanding. In this work, we improve verb understanding for CLIP-based video-language models by proposing a new Verb-Focused Contrastive (VFC) framework. This consists of two main components: (1) leveraging pretrained large language models (LLMs) to create hard negatives for cross-modal contrastive learning, together with a calibration strategy to balance the occurrence of concepts in positive and negative pairs; and (2) enforcing a fine-grained, verb phrase alignment loss. Our method achieves state-of-the-art results for zero-shot performance on three downstream tasks that focus on verb understanding: video-t
    
[^2]: 布局引导下的图像生成的诊断基准和迭代修复

    Diagnostic Benchmark and Iterative Inpainting for Layout-Guided Image Generation. (arXiv:2304.06671v1 [cs.CV])

    [http://arxiv.org/abs/2304.06671](http://arxiv.org/abs/2304.06671)

    本文提出了布局引导下图像生成的诊断基准LayoutBench，对数量、位置、大小和形状四种空间控制技能进行了研究，发现好的ID布局控制在任意布局的野外环境下可能不具有良好的推广性。接着，我们提出了一种新的基准方法IterInpaint通过修复逐步生成前景和背景区域，显现出在OOD布局方面更强的通用性。

    

    空间控制是可控图像生成的核心能力。在布局引导下的图像生成方面的进展已经显示出在具有类似空间配置的内分布（ID）数据集上有良好的结果。然而，当面对任意不确定的布局的离线分布样本时，这些模型的表现还不清楚。在本文中，我们提出了LayoutBench，这是一种对布局引导下的图像生成进行诊断的基准，它检查了四种空间控制技能：数量，位置，大小和形状。我们对两种最近代表性的布局引导下的图像生成方法进行了基准测试，并观察到良好的ID布局控制可能无法很好地推广到任意布局的野外环境（例如，边界上的对象）。接下来，我们提出了一个新的基准方法IterInpaint，它通过修复逐步生成前景和背景区域，展示出在LayoutBench的OOD布局上更强的通用性。我们进行了数量和定性评估，表明IterInpaint相对于现有方法具有更好的生成多样和视觉上令人愉悦的图像和可控的空间布局。

    Spatial control is a core capability in controllable image generation. Advancements in layout-guided image generation have shown promising results on in-distribution (ID) datasets with similar spatial configurations. However, it is unclear how these models perform when facing out-of-distribution (OOD) samples with arbitrary, unseen layouts. In this paper, we propose LayoutBench, a diagnostic benchmark for layout-guided image generation that examines four categories of spatial control skills: number, position, size, and shape. We benchmark two recent representative layout-guided image generation methods and observe that the good ID layout control may not generalize well to arbitrary layouts in the wild (e.g., objects at the boundary). Next, we propose IterInpaint, a new baseline that generates foreground and background regions in a step-by-step manner via inpainting, demonstrating stronger generalizability than existing models on OOD layouts in LayoutBench. We perform quantitative and q
    
[^3]: G2T: 基于预训练语言模型和社区检测的主题建模框架

    G2T: A simple but versatile framework for topic modeling based on pretrained language model and community detection. (arXiv:2304.06653v1 [cs.CL])

    [http://arxiv.org/abs/2304.06653](http://arxiv.org/abs/2304.06653)

    G2T是一种基于预训练语言模型和社区检测的主题建模框架，自动评估表明，G2T在多个数据集上均与当前最先进的方法相比表现更好。

    

    先前的研究表明，基于聚类的主题模型能够通过适当的词语筛选方法聚类高质量的句子嵌入，生成比生成式概率主题模型更好的主题。然而，这些方法存在选择合适参数的困难以及不完整的模型忽略单词与主题及主题与文本之间的定量关系的问题。为了解决这些问题，我们提出了一种简洁但有效的主题建模框架，即图主题（G2T）。

    It has been reported that clustering-based topic models, which cluster high-quality sentence embeddings with an appropriate word selection method, can generate better topics than generative probabilistic topic models. However, these approaches suffer from the inability to select appropriate parameters and incomplete models that overlook the quantitative relation between words with topics and topics with text. To solve these issues, we propose graph to topic (G2T), a simple but effective framework for topic modelling. The framework is composed of four modules. First, document representation is acquired using pretrained language models. Second, a semantic graph is constructed according to the similarity between document representations. Third, communities in document semantic graphs are identified, and the relationship between topics and documents is quantified accordingly. Fourth, the word--topic distribution is computed based on a variant of TFIDF. Automatic evaluation suggests that G2
    
[^4]: 大型语言模型生成的教育问题有多有用？

    How Useful are Educational Questions Generated by Large Language Models?. (arXiv:2304.06638v1 [cs.CL])

    [http://arxiv.org/abs/2304.06638](http://arxiv.org/abs/2304.06638)

    本文研究通过结合CTG和问题分类生成的输出，通过教师评估证明这些生成的问题质量高且足够有用，有极大的应用潜力。

    

    由大型语言模型进行可控文本生成（CTG）对于教师和学生来说有着巨大的潜力，特别是高质量和多样性的问题生成可以大幅减轻教师的负担，提高他们教学内容的质量。最近在该领域的研究已经取得了进展，但未能表明真正的教师评判生成的问题在课堂环境中是否足够有用，或者问题是否存在错误和/或教学内容的帮助不大。本文通过人类评估教师的方式，评估通过结合CTG和问题分类（Bloom's和难度分类）生成的输出的质量和有用性。结果表明生成的问题质量高且足够有用，展示了在课堂环境中广泛使用的潜力。

    Controllable text generation (CTG) by large language models has a huge potential to transform education for teachers and students alike. Specifically, high quality and diverse question generation can dramatically reduce the load on teachers and improve the quality of their educational content. Recent work in this domain has made progress with generation, but fails to show that real teachers judge the generated questions as sufficiently useful for the classroom setting; or if instead the questions have errors and/or pedagogically unhelpful content. We conduct a human evaluation with teachers to assess the quality and usefulness of outputs from combining CTG and question taxonomies (Bloom's and a difficulty taxonomy). The results demonstrate that the questions generated are high quality and sufficiently useful, showing their promise for widespread use in the classroom setting.
    
[^5]: PGTask：介绍从对话中生成档案的任务

    PGTask: Introducing the Task of Profile Generation from Dialogues. (arXiv:2304.06634v1 [cs.CL])

    [http://arxiv.org/abs/2304.06634](http://arxiv.org/abs/2304.06634)

    对话系统的个性化需要个人资料信息，而从对话中提取/生成个人资料信息是一项基本需求。为此，我们提出了档案生成任务（PGTask）并提供了相关的数据集和基准，该任务使得研究者可以更好地了解档案生成任务的挑战和可能的解决方案。

    

    最近的研究尝试通过将个人资料信息融入模型来个性化对话系统。然而，这种知识信息稀少且难以获取，这使得从对话中提取/生成个人资料信息成为一项基本需求。为了克服这一限制，我们引入了档案生成任务（PGTask）。我们为此问题提供了一个新的数据集，其中包括与相关话语对齐的档案句子，从对话语料库中提取。此外，利用最先进的方法，我们为这个新数据集提供了一个档案生成的基准。我们的实验揭示了档案生成的挑战，并希望这引入了一个新的研究方向。

    Recent approaches have attempted to personalize dialogue systems by leveraging profile information into models. However, this knowledge is scarce and difficult to obtain, which makes the extraction/generation of profile information from dialogues a fundamental asset. To surpass this limitation, we introduce the Profile Generation Task (PGTask). We contribute with a new dataset for this problem, comprising profile sentences aligned with related utterances, extracted from a corpus of dialogues. Furthermore, using state-of-the-art methods, we provide a benchmark for profile generation on this novel dataset. Our experiments disclose the challenges of profile generation, and we hope that this introduces a new research direction.
    
[^6]: 探索法律问题回答系统的现状

    Exploring the State of the Art in Legal QA Systems. (arXiv:2304.06623v1 [cs.CL])

    [http://arxiv.org/abs/2304.06623](http://arxiv.org/abs/2304.06623)

    法律问题回答系统的研究面临着复杂性和多样性等挑战，但其在客户服务、教育、研究和跨语言交流等方面具有广泛应用。

    

    回答与法律领域相关的问题是一项复杂的任务，主要是由于复杂的法律文档系统的复杂性和多样性。为法律问题提供准确的答案通常需要相关领域的专业知识，这使得即使对于人类专家来说，这项任务也更具挑战性。问答系统（QA）旨在生成对以人类语言提出的问题的答案。它们使用自然语言处理来理解问题并搜索信息以找到相关答案。QA具有各种实际应用，包括客户服务、教育、研究和跨语言交流。然而，它们面临着诸如改进自然语言理解和处理复杂和模糊问题等挑战。

    Answering questions related to the legal domain is a complex task, primarily due to the intricate nature and diverse range of legal document systems. Providing an accurate answer to a legal query typically necessitates specialized knowledge in the relevant domain, which makes this task all the more challenging, even for human experts. QA (Question answering systems) are designed to generate answers to questions asked in human languages. They use natural language processing to understand questions and search through information to find relevant answers. QA has various practical applications, including customer service, education, research, and cross-lingual communication. However, they face challenges such as improving natural language understanding and handling complex and ambiguous questions. Answering questions related to the legal domain is a complex task, primarily due to the intricate nature and diverse range of legal document systems. Providing an accurate answer to a legal query
    
[^7]: ChatGPT-4在政治Twitter信息注释中通过零样本学习胜过专家和众包工作者

    ChatGPT-4 Outperforms Experts and Crowd Workers in Annotating Political Twitter Messages with Zero-Shot Learning. (arXiv:2304.06588v1 [cs.CL])

    [http://arxiv.org/abs/2304.06588](http://arxiv.org/abs/2304.06588)

    本文评估了ChatGPT-4在政治Twitter相关推文注释任务中的表现，结果显示它在准确性、可靠性和偏见方面皆优于人类标注，尤其是它能通过零样本学习准确注释需要基于上下文知识和作者意向的推文，这将使得规模化的文本数据研究成为可能，并在社会科学的解释性研究中产生巨大影响。

    

    本文评估了大型语言模型ChatGPT-4在政治相关推文注释任务中的准确性、可靠性和偏见。与专家和众包工作者标注进行比较，研究使用2020年美国选举期间的政治相关推文作为数据集，提供了可靠的准确性评测基准。实验发现，ChatGPT-4的准确性更高、可靠性更高，并且偏见相等或更低。该模型能够准确注释需要基于上下文知识进行推理和作者意向的推文，这些能力被传统上视为是人类独有的。研究结果表明，LLM在社会科学中使用文本数据进行解释性研究方面将产生巨大的影响，并使得规模化的文本数据研究成为可能。

    This paper assesses the accuracy, reliability and bias of the Large Language Model (LLM) ChatGPT-4 on the text analysis task of classifying the political affiliation of a Twitter poster based on the content of a tweet. The LLM is compared to manual annotation by both expert classifiers and crowd workers, generally considered the gold standard for such tasks. We use Twitter messages from United States politicians during the 2020 election, providing a ground truth against which to measure accuracy. The paper finds that ChatGPT-4 has achieves higher accuracy, higher reliability, and equal or lower bias than the human classifiers. The LLM is able to correctly annotate messages that require reasoning on the basis of contextual knowledge, and inferences around the author's intentions - traditionally seen as uniquely human abilities. These findings suggest that LLM will have substantial impact on the use of textual data in the social sciences, by enabling interpretive research at a scale.
    
[^8]: LLM是否足以用于任务导向型对话？

    Are LLMs All You Need for Task-Oriented Dialogue?. (arXiv:2304.06556v1 [cs.CL])

    [http://arxiv.org/abs/2304.06556](http://arxiv.org/abs/2304.06556)

    LLM在任务导向型对话中表现不如专门的任务特定模型，但如果提供正确的槽值，仍有引导对话成功结束的能力，并且可通过真实信念状态分布或域内示例的访问获得更好的表现。

    

    基于指令的大型语言模型（LLM）因其通过对话与用户交互的能力而受到广泛关注。本文旨在评估它们在已建立的任务导向型对话基准测试中完成多轮任务并与外部数据库交互的能力。我们发现，对于显式信念状态跟踪，LLM表现不如专门的任务特定模型。尽管如此，如果提供正确的插槽值，它们表现出引导对话成功结束的能力。此外，如果具有真实信念状态分布或域内示例的访问权限，该能力会得到改善。

    Instructions-tuned Large Language Models (LLMs) gained recently huge popularity thanks to their ability to interact with users through conversation. In this work we aim to evaluate their ability to complete multi-turn tasks and interact with external databases in the context of established task-oriented dialogue benchmarks. We show that for explicit belief state tracking, LLMs underperform compared to specialized task-specific models. Nevertheless, they show ability to guide the dialogue to successful ending if given correct slot values. Furthermore this ability improves with access to true belief state distribution or in-domain examples.
    
[^9]: 生成式AI的一小步，AGI的一大步：AIGC时代中ChatGPT的全面调查

    One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era. (arXiv:2304.06488v1 [cs.CY])

    [http://arxiv.org/abs/2304.06488](http://arxiv.org/abs/2304.06488)

    ChatGPT是生成式AI的一小步，也是AGI的一大步，我们进行了综述，并对其如何演变为AIGC展望不同于以往的通用AI生成内容的发展道路。

    

    OpenAI 最近发布了GPT-4（又称为ChatGPT plus），该模型被证明是生成式AI（GAI）迈出的一小步，但对于人工通用智能（AGI）来说则是一个重大的飞跃。自2022年11月正式发布以来，ChatGPT便迅速吸引了众多用户，引起了广泛的媒体关注，相关的学术文章也超过了500篇。因此，有必要进行一次综述，我们的工作就是填补这一空白。总的来说，我们是第一个从技术、应用和挑战三个方面全面调查ChatGPT的团队，并展望了ChatGPT如何演变以实现通用的AI生成内容（AIGC），这将是AGI发展的重要里程碑。

    OpenAI has recently released GPT-4 (a.k.a. ChatGPT plus), which is demonstrated to be one small step for generative AI (GAI), but one giant leap for artificial general intelligence (AGI). Since its official release in November 2022, ChatGPT has quickly attracted numerous users with extensive media coverage. Such unprecedented attention has also motivated numerous researchers to investigate ChatGPT from various aspects. According to Google scholar, there are more than 500 articles with ChatGPT in their titles or mentioning it in their abstracts. Considering this, a review is urgently needed, and our work fills this gap. Overall, this work is the first to survey ChatGPT with a comprehensive review of its underlying technology, applications, and challenges. Moreover, we present an outlook on how ChatGPT might evolve to realize general-purpose AIGC (a.k.a. AI-generated content), which will be a significant milestone for the development of AGI.
    
[^10]: Masakhane-Afrisenti在SemEval-2023任务12中的应用：使用非洲中心语言模型和适配器进行低资源非洲语言的情感分析

    Masakhane-Afrisenti at SemEval-2023 Task 12: Sentiment Analysis using Afro-centric Language Models and Adapters for Low-resource African Languages. (arXiv:2304.06459v1 [cs.CL])

    [http://arxiv.org/abs/2304.06459](http://arxiv.org/abs/2304.06459)

    该论文介绍了在SemEval-2023任务12中使用Afro-centric语言模型和适配器进行非洲低资源语言的情感分析。使用预训练的Afro-centric语言模型可以提高性能。使用适配器方法可以实现对于有限资源语言的零样本迁移。

    

    AfriSenti-SemEval共享任务12旨在为12种非洲语言执行单语情感分类（子任务A）、多语言情感分类（子任务B）和零样本情感分类（任务C）。对于子任务A，我们使用传统的机器学习分类器、非洲中心语言模型和特定语言模型进行了实验。对于任务B，我们微调了支持任务中多种语言的多语言预训练语言模型。对于任务C，我们使用参数高效的适配器方法，利用目标语言的单语文本实现有效的零样本迁移。我们的发现表明，使用预训练的非洲中心语言模型可以改善低资源非洲语言的性能。我们还使用适配器进行零样本任务的实验，结果表明，使用有限的资源可以获得有前途的结果。

    AfriSenti-SemEval Shared Task 12 of SemEval-2023. The task aims to perform monolingual sentiment classification (sub-task A) for 12 African languages, multilingual sentiment classification (sub-task B), and zero-shot sentiment classification (task C). For sub-task A, we conducted experiments using classical machine learning classifiers, Afro-centric language models, and language-specific models. For task B, we fine-tuned multilingual pre-trained language models that support many of the languages in the task. For task C, we used we make use of a parameter-efficient Adapter approach that leverages monolingual texts in the target language for effective zero-shot transfer. Our findings suggest that using pre-trained Afro-centric language models improves performance for low-resource African languages. We also ran experiments using adapters for zero-shot tasks, and the results suggest that we can obtain promising results by using adapters with a limited amount of resources.
    
[^11]: PDF-VQA: 一个新的用于PDF文件真实世界VQA的数据集

    PDF-VQA: A New Dataset for Real-World VQA on PDF Documents. (arXiv:2304.06447v1 [cs.CV])

    [http://arxiv.org/abs/2304.06447](http://arxiv.org/abs/2304.06447)

    该研究提出了一个新的文档VQA数据集PDF-VQA，以多个页面的完整文档作为研究对象，通过机器学习模型识别与处理文档元素、结构和内容等方面，为解决真实世界中的文档理解问题提供新的资源。

    

    基于文档的视觉问答（VQA）研究文档图像的文档理解问题。我们提出了一个新的基于文档的VQA数据集PDF-VQA，从文档元素识别、文档布局结构理解以及上下文理解和关键信息提取等各个方面全面探讨文档理解问题。我们的PDF-VQA数据集将文档理解的规模从单个文档页面扩展到询问多个页面的完整文档。我们还提出了一个新的基于图形的VQA模型，明确地集成了不同文档元素之间的空间和层次结构关系，以提高文档结构的理解能力。该性能与多个基线模型相比较，可以适用于不同的问题类型和任务。

    Document-based Visual Question Answering examines the document understanding of document images in conditions of natural language questions. We proposed a new document-based VQA dataset, PDF-VQA, to comprehensively examine the document understanding from various aspects, including document element recognition, document layout structural understanding as well as contextual understanding and key information extraction. Our PDF-VQA dataset extends the current scale of document understanding that limits on the single document page to the new scale that asks questions over the full document of multiple pages. We also propose a new graph-based VQA model that explicitly integrates the spatial and hierarchically structural relationships between different document elements to boost the document structural understanding. The performances are compared with several baselines over different question types and tasks\footnote{The full dataset will be released after paper acceptance.
    
[^12]: SpectFormer: 频率和注意力是视觉Transformer所需要的。

    SpectFormer: Frequency and Attention is what you need in a Vision Transformer. (arXiv:2304.06446v1 [cs.CV])

    [http://arxiv.org/abs/2304.06446](http://arxiv.org/abs/2304.06446)

    本文提出了结合多头注意力和谱层的Spectformer架构，可以得到更好的性能表现，提高了top-1准确率2%。

    

    视觉Transformer已成功地应用于图像识别任务中。其种类包括基于多头自我注意力机制（如ViT、DeIT）和基于谱层（如Fnet、GFNet、AFNO）的模型。本文发现，多头注意力和谱层都对Transformer起到重要作用，将两者结合可以得到更好的性能表现。因此提出了新的Spectformer架构，将多头注意力和谱层融合起来。实验表明，Spectformer可恰当地捕捉特征表示，与其他Transformer表征相比，可以提高top-1准确率2%。

    Vision transformers have been applied successfully for image recognition tasks. There have been either multi-headed self-attention based (ViT \cite{dosovitskiy2020image}, DeIT, \cite{touvron2021training}) similar to the original work in textual models or more recently based on spectral layers (Fnet\cite{lee2021fnet}, GFNet\cite{rao2021global}, AFNO\cite{guibas2021efficient}). We hypothesize that both spectral and multi-headed attention plays a major role. We investigate this hypothesis through this work and observe that indeed combining spectral and multi-headed attention layers provides a better transformer architecture. We thus propose the novel Spectformer architecture for transformers that combines spectral and multi-headed attention layers. We believe that the resulting representation allows the transformer to capture the feature representation appropriately and it yields improved performance over other transformer representations. For instance, it improves the top-1 accuracy by 2
    
[^13]: 神经网络中符号的出现与语义理解和交流

    Emergence of Symbols in Neural Networks for Semantic Understanding and Communication. (arXiv:2304.06377v1 [cs.AI])

    [http://arxiv.org/abs/2304.06377](http://arxiv.org/abs/2304.06377)

    本文介绍了一种名为SEA-net的神经网络解决方案，可以生成符号，实现语义理解和交流。这些符号可以捕捉到组成性语义信息，并呈现类似自然语言的内在结构。

    

    能够创造有意义的符号，并熟练地将它们用于更高的认知功能，如交流、推理、规划等，是人类智能的重要和独特之处。 目前，深度神经网络仍远远落后于人类创造符号进行这些高级认知功能的能力。本文提出了一种名为SEA-net的解决方案，使神经网络具有符号创造、语义理解和交流能力。SEA-net生成动态配置网络以执行特定任务的符号。这些符号捕捉了组成性语义信息，使系统能够通过纯符号操作或交流获得新功能。此外，我们发现这些自动生成的符号呈现出类似自然语言的内在结构，表明在人类大脑和人工神经网络中生成和理解符号的共同框架。我们希望这将成为将来发展人工智能的助推器。

    Being able to create meaningful symbols and proficiently use them for higher cognitive functions such as communication, reasoning, planning, etc., is essential and unique for human intelligence. Current deep neural networks are still far behind human's ability to create symbols for such higher cognitive functions. Here we propose a solution, named SEA-net, to endow neural networks with ability of symbol creation, semantic understanding and communication. SEA-net generates symbols that dynamically configure the network to perform specific tasks. These symbols capture compositional semantic information that enables the system to acquire new functions purely by symbolic manipulation or communication. In addition, we found that these self-generated symbols exhibit an intrinsic structure resembling that of natural language, suggesting a common framework underlying the generation and understanding of symbols in both human brains and artificial neural networks. We hope that it will be instrum
    
[^14]: 超图认知网络作为知识的特征丰富模型

    Towards hypergraph cognitive networks as feature-rich models of knowledge. (arXiv:2304.06375v1 [cs.CL])

    [http://arxiv.org/abs/2304.06375](http://arxiv.org/abs/2304.06375)

    本研究提出了特征丰富认知超图作为人类记忆定量模型来预测概念特征，与成对连接和缺乏特征的网络模型相比，特征丰富认知超图表现更好，并且涉及更高阶关联的超链接在具有相似心理语言学特征的概念之间优先形成，这反映了共享认知维度的存在。

    

    语义网络是理解如何从记忆中检索相关概念的有用工具。然而，大多数现有的网络方法使用成对连接表示记忆召回模式。成对连接忽略了更高阶的关联，即一次涉及两个以上概念的关系。这些更高阶的交互可能与大脑灰质结构特征，如兴奋、愉悦、熟悉度、性别等有关。我们通过引入特征丰富认知超图来克服这些限制，作为人类记忆的定量模型：（i）一起回忆的概念可以同时参与包含两个以上概念的超链接（认知超图方面）；（ii）每个概念都具有心理语言学特征向量（特征丰富方面）。我们从词汇联想数据中构建超图，并使用机器学习特征评估方法来预测概念特征。我们的结果表明，相对于成对连接和缺乏特征的网络模型，特征丰富认知超图在预测心理语言学特征方面表现更好。此外，我们还表明，涉及更高阶关联的超链接优先形成在具有相似心理语言学特征的概念之间。这表明，人类记忆的结构涉及反映共享认知维度的更高阶关联，这些维度可以用于将概念组织成语义空间。

    Semantic networks provide a useful tool to understand how related concepts are retrieved from memory. However, most current network approaches use pairwise links to represent memory recall patterns. Pairwise connections neglect higher-order associations, i.e. relationships between more than two concepts at a time. These higher-order interactions might covariate with (and thus contain information about) how similar concepts are along psycholinguistic dimensions like arousal, valence, familiarity, gender and others. We overcome these limits by introducing feature-rich cognitive hypergraphs as quantitative models of human memory where: (i) concepts recalled together can all engage in hyperlinks involving also more than two concepts at once (cognitive hypergraph aspect), and (ii) each concept is endowed with a vector of psycholinguistic features (feature-rich aspect). We build hypergraphs from word association data and use evaluation methods from machine learning features to predict concep
    
[^15]: 从指导视频中进行手语翻译

    Sign Language Translation from Instructional Videos. (arXiv:2304.06371v1 [cs.CL])

    [http://arxiv.org/abs/2304.06371](http://arxiv.org/abs/2304.06371)

    本论文描述了如何使用I3D视频特征培训Transformer模型，据此对How2Sign数据集进行手语翻译。作者提供了公共代码和首个开源实现。

    

    自动手语翻译（SLT）到口语语言的进展大部分都是基于规模有限、领域受限的数据集进行评估的。本论文通过提供首个基于大规模数据集"How2Sign"的基准结果，推动了该领域的最新研究进展。我们使用I3D视频特征对Transformer进行训练，使用降低的BLEU分数作为验证的参考指标代替广泛使用的BLEU分数。我们报告了8.03的BLEU分数，并发布了首个开源实现，以推动进一步的进展。

    The advances in automatic sign language translation (SLT) to spoken languages have been mostly benchmarked with datasets of limited size and restricted domains. Our work advances the state of the art by providing the first baseline results on How2Sign, a large and broad dataset.  We train a Transformer over I3D video features, using the reduced BLEU as a reference metric for validation, instead of the widely used BLEU score. We report a result of 8.03 on the BLEU score, and publish the first open-source implementation of its kind to promote further advances.
    
[^16]: AGIEval：一个以人为中心的基准评估基础模型的工具

    AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models. (arXiv:2304.06364v1 [cs.CL])

    [http://arxiv.org/abs/2304.06364](http://arxiv.org/abs/2304.06364)

    AGIEval是一个以人为中心设计的基准测试工具，用于评估基础模型在人类中心标准化考试上的表现。GPT-4在SAT、LSAT和数学比赛方面超越了人类平均表现，展示了当代基础模型在人类级任务中的非凡性能。

    

    评估基础模型解决人类级别任务的通用能力是它们在发展和应用AGI（人工通用智能）中的重要方面。传统基准测试依赖于人造数据集，可能无法准确代表人类水平能力。在本文中，我们介绍了AGIEval，一个专门设计用于评估基础模型在人类中心标准化考试的基准测试工具，例如大学入学考试，法律学校入学考试，数学竞赛和律师资格考试。我们使用这个基准测试工具评估了几种最先进的基础模型，包括 GPT-4，ChatGPT 和Text-Davinci-003。令人印象深刻的是，GPT-4在SAT、LSAT和数学比赛方面超越了人类平均表现，SAT数学测试的准确率达到了95%，在中国国家大学英语考试的英语测试中准确率也达到了92.5%。这展示了当代基础模型在人类级任务中的非凡性能，并凸显了AGI未来发展的潜力。

    Evaluating the general abilities of foundation models to tackle human-level tasks is a vital aspect of their development and application in the pursuit of Artificial General Intelligence (AGI). Traditional benchmarks, which rely on artificial datasets, may not accurately represent human-level capabilities. In this paper, we introduce AGIEval, a novel benchmark specifically designed to assess foundation model in the context of human-centric standardized exams, such as college entrance exams, law school admission tests, math competitions, and lawyer qualification tests. We evaluate several state-of-the-art foundation models, including GPT-4, ChatGPT, and Text-Davinci-003, using this benchmark. Impressively, GPT-4 surpasses average human performance on SAT, LSAT, and math competitions, attaining a 95% accuracy rate on the SAT Math test and a 92.5% accuracy on the English test of the Chinese national college entrance exam. This demonstrates the extraordinary performance of contemporary fou
    
[^17]: 语义变化的计算建模

    Computational modeling of semantic change. (arXiv:2304.06337v1 [cs.CL])

    [http://arxiv.org/abs/2304.06337](http://arxiv.org/abs/2304.06337)

    本文概述了语义变化的计算建模方法，讨论了不同模型在处理语义变化时的优缺点以及评估结果的途径。

    

    本章节概述了使用大规模语料库和半大规模语料库进行计算建模来研究语义变化的方法。我们旨在提供一个正确理解相关方法和评估技术的钥匙，同时也探讨了计算研究语义变化的重要方面。我们讨论了不同类别的模型在处理语义变化时的优缺点，以及可以用于评估结果的途径。

    In this chapter we provide an overview of computational modeling for semantic change using large and semi-large textual corpora. We aim to provide a key for the interpretation of relevant methods and evaluation techniques, and also provide insights into important aspects of the computational study of semantic change. We discuss the pros and cons of different classes of models with respect to the properties of the data from which one wishes to model semantic change, and which avenues are available to evaluate the results.
    
[^18]: 基于规则的德国教育和培训准入检测

    Rule-based detection of access to education and training in Germany. (arXiv:2304.06307v1 [cs.CL])

    [http://arxiv.org/abs/2304.06307](http://arxiv.org/abs/2304.06307)

    本研究提出了一种基于规则的新方法，通过自动检测德国培训提供和广告中的教育和培训准入，以帮助匹配培训寻求者和提供者。

    

    随着转型过程的不断深入，德国劳动力市场对职业培训、再培训和继续教育高度依赖。为了匹配培训寻求者和提供者，本研究提出了一种新的方法，通过对德国培训提供和广告中的教育和培训准入进行自动检测。我们特别关注以下几个方面：（a）普通学校和教育学位以及毕业证书，（b）专业经验，（c）以前的学徒培训和（d）由德国联邦劳动机构提供的技能列表。该新方法结合了几种方法：首先，我们提供了教育同义词的映射，将不同的资格证书组合并添加过时的术语。其次，我们提供基于规则的匹配，以确定专业经验或学徒培训的需求。但是，由于数据架构不兼容或非标准化要求（例如初始测试或面试），并不是所有准入要求都能够匹配。尽管如此，我们仍能使用这些检测到的准入需求来帮助更好地匹配培训寻求者和培训提供商。

    As a result of transformation processes, the German labor market is highly dependent on vocational training, retraining and continuing education. To match training seekers and offers, we present a novel approach towards the automated detection of access to education and training in German training offers and advertisements. We will in particular focus on (a) general school and education degrees and schoolleaving certificates, (b) professional experience, (c) a previous apprenticeship and (d) a list of skills provided by the German Federal Employment Agency. This novel approach combines several methods: First, we provide a mapping of synonyms in education combining different qualifications and adding deprecated terms. Second, we provide a rule-based matching to identify the need for professional experience or apprenticeship. However, not all access requirements can be matched due to incompatible data schemata or non-standardizes requirements, e.g initial tests or interviews. While we ca
    
[^19]: LasUIE:利用潜在自适应结构感知生成语言模型统一信息提取

    LasUIE: Unifying Information Extraction with Latent Adaptive Structure-aware Generative Language Model. (arXiv:2304.06248v1 [cs.CL])

    [http://arxiv.org/abs/2304.06248](http://arxiv.org/abs/2304.06248)

    本论文基于已有的生成语言模型，提出了一种结构感知GLM模型，通过异构结构感知器后训练，引入了句法知识，提出了结构广播器引导更好的生成，以及引入了面向任务的结构微调机制。在三个基准数据集上实验表明，该模型优于现有模型，展示了结构感知在信息提取中的有效性。

    

    最近的研究通过一个生成语言模型（GLM）普遍地建模所有典型的信息提取任务（UIE），将各种IE预测统一为GLM下的线性分层表达，显示出很大的潜力。句法结构信息是IE社区广泛利用的一种有效特征，也应有益于UIE，本文提出了一种新颖的结构感知GLM，充分释放了句法知识对UIE的影响力。采用异构结构感知器来后训练现有的GLM，无监督地引入了丰富的异构结构表示。特别的，提出一种结构广播器，将各种潜在树压缩成明确的高阶森林，在解码期间有助于引导更好的生成。最后，引入一种面向任务的结构微调机制，进一步调整学习到的结构，使其更符合最终任务的需要。超过12,000个句子进行了注释，构建了三个基准数据集来评估所提出的模型。广泛的实验表明，所提出的模型在所有三个基准数据集上都明显优于现有模型，证明了我们所提出的结构感知方法的有效性。

    Universally modeling all typical information extraction tasks (UIE) with one generative language model (GLM) has revealed great potential by the latest study, where various IE predictions are unified into a linearized hierarchical expression under a GLM. Syntactic structure information, a type of effective feature which has been extensively utilized in IE community, should also be beneficial to UIE. In this work, we propose a novel structure-aware GLM, fully unleashing the power of syntactic knowledge for UIE. A heterogeneous structure inductor is explored to unsupervisedly induce rich heterogeneous structural representations by post-training an existing GLM. In particular, a structural broadcaster is devised to compact various latent trees into explicit high-order forests, helping to guide a better generation during decoding. We finally introduce a task-oriented structure fine-tuning mechanism, further adjusting the learned structures to most coincide with the end-task's need. Over 12
    
[^20]: LeafAI：临床队列发现的查询生成器与人类程序员不相上下

    LeafAI: query generator for clinical cohort discovery rivaling a human programmer. (arXiv:2304.06203v1 [cs.CL])

    [http://arxiv.org/abs/2304.06203](http://arxiv.org/abs/2304.06203)

    该研究开发了一个名为LeafAI的系统，可以生成数据模型不受限制的查询，同时为复杂的临床试验资格标准提供新颖的逻辑推理能力。

    

    目的：在临床研究中，确定研究资格的患者是关键步骤。然而，准确的查询设计通常需要广泛的技术和生物医学专业知识。我们试图创建一个系统，能够生成数据模型不受限制的查询，同时为复杂的临床试验资格标准提供新颖的逻辑推理能力。材料和方法：从资格标准创建查询的任务需要解决几个文本处理问题，包括命名实体识别和关系提取、序列到序列转换、归一化和推理。我们结合了深度学习和基于规则的模块以及统一医学语言系统（UMLS）和链接本体，建立了一个知识库。为了实现数据模型不受限制的查询创建，我们介绍了一种使用UMLS概念标记数据库模式元素的新方法。为了评估我们的系统LeafAI，我们与两个具有临床应用背景的真实世界数据库进行了比较。

    Objective: Identifying study-eligible patients within clinical databases is a critical step in clinical research. However, accurate query design typically requires extensive technical and biomedical expertise. We sought to create a system capable of generating data model-agnostic queries while also providing novel logical reasoning capabilities for complex clinical trial eligibility criteria.  Materials and Methods: The task of query creation from eligibility criteria requires solving several text-processing problems, including named entity recognition and relation extraction, sequence-to-sequence transformation, normalization, and reasoning. We incorporated hybrid deep learning and rule-based modules for these, as well as a knowledge base of the Unified Medical Language System (UMLS) and linked ontologies. To enable data-model agnostic query creation, we introduce a novel method for tagging database schema elements using UMLS concepts. To evaluate our system, called LeafAI, we compare
    
[^21]: 使用大型语言模型进行初学者的（非）形式化和自然论证练习

    Using large language models for (de-)formalization and natural argumentation exercises for beginner's students. (arXiv:2304.06186v1 [cs.CL])

    [http://arxiv.org/abs/2304.06186](http://arxiv.org/abs/2304.06186)

    本研究描述了两个系统，利用大型语言模型，自动纠正初学者在逻辑语言转化和自然语言论证方面的问题。

    

    我们描述了两个系统，使用文本达芬奇-003，一个大型语言模型，自动纠正（i）自然语言与命题逻辑语言和一阶谓词逻辑语言之间转化的练习; 和（ii）在非数学场景下用自然语言编写简单论点的练习。

    We describe two systems that use text-davinci-003, a large language model, for the automatized correction of (i) exercises in translating back and forth between natural language and the languages of propositional logic and first-order predicate logic and (ii) exercises in writing simple arguments in natural language in non-mathematical scenarios.
    
[^22]: LINGO：通过视觉去偏见化自然语言指令以支持任务多样性

    LINGO : Visually Debiasing Natural Language Instructions to Support Task Diversity. (arXiv:2304.06184v1 [cs.HC])

    [http://arxiv.org/abs/2304.06184](http://arxiv.org/abs/2304.06184)

    本论文介绍了针对自然语言任务指令中的偏见进行分析的新工具LINGO，展示了如何通过视觉分析来支持用户纠正偏见。

    

    跨任务泛化是自然语言理解中定义精通的重要结果。最近的预训练语言模型通过文本指令和一小组示例来定义和举例说明任务，从而模仿了人类的这种学习方式。但分析模型接收到的任务指令中的“偏见”是一个困难的问题，并且尚未得到充分探索。为了帮助我们了解这个问题，研究人员开发了一种新的视觉分析界面LINGO来支持有效的任务驱动工作流程，以(1)帮助识别自然语言任务指令中的偏见，(2)通过对接收到的文本进行视觉分析来支持用户思考和纠正该类偏见。

    Cross-task generalization is a significant outcome that defines mastery in natural language understanding. Humans show a remarkable aptitude for this, and can solve many different types of tasks, given definitions in the form of textual instructions and a small set of examples. Recent work with pre-trained language models mimics this learning style: users can define and exemplify a task for the model to attempt as a series of natural language prompts or instructions. While prompting approaches have led to higher cross-task generalization compared to traditional supervised learning, analyzing 'bias' in the task instructions given to the model is a difficult problem, and has thus been relatively unexplored. For instance, are we truly modeling a task, or are we modeling a user's instructions? To help investigate this, we develop LINGO, a novel visual analytics interface that supports an effective, task-driven workflow to (1) help identify bias in natural language task instructions, (2) al
    
[^23]: 检测虚假生成的科学摘要

    Detection of Fake Generated Scientific Abstracts. (arXiv:2304.06148v1 [cs.CL])

    [http://arxiv.org/abs/2304.06148](http://arxiv.org/abs/2304.06148)

    本研究使用GPT-3模型生成科学论文摘要，并通过各种文本表征方法结合机器学习模型，探讨识别机器写作文本的有效性。研究分析了模型的性能，揭示了人工智能生成文本的能力和局限性。

    

    大规模语言模型和公开可用的ChatGPT的广泛应用标志着人工智能融入人们日常生活的重要转折点。学术界已经注意到这些技术进步，并表达了关于区分真实和人工生成信息的困难的担忧。因此，研究人员一直在努力开发有效的系统来识别机器生成的文本。在本研究中，我们利用GPT-3模型通过人工智能生成科学论文摘要，并探讨与机器学习模型相结合的各种文本表征方法，以便识别机器写作的文本。我们分析了模型的性能，并解决了分析结果时引发的几个研究问题。通过进行这项研究，我们揭示了人工智能生成文本的能力和局限性。

    The widespread adoption of Large Language Models and publicly available ChatGPT has marked a significant turning point in the integration of Artificial Intelligence into people's everyday lives. The academic community has taken notice of these technological advancements and has expressed concerns regarding the difficulty of discriminating between what is real and what is artificially generated. Thus, researchers have been working on developing effective systems to identify machine-generated text. In this study, we utilize the GPT-3 model to generate scientific paper abstracts through Artificial Intelligence and explore various text representation methods when combined with Machine Learning models with the aim of identifying machine-written text. We analyze the models' performance and address several research questions that rise during the analysis of the results. By conducting this research, we shed light on the capabilities and limitations of Artificial Intelligence generated text.
    
[^24]: 从文本到图像生成角度审视社会偏见

    Social Biases through the Text-to-Image Generation Lens. (arXiv:2304.06034v1 [cs.CY])

    [http://arxiv.org/abs/2304.06034](http://arxiv.org/abs/2304.06034)

    本文研究了文本到图像生成技术中存在的社会偏见，主要集中在职业、人格特征和日常情境等方面。实验证明，这些模型存在排除特定人群的职业偏见。

    

    文本到图像 (T2I) 生成技术通过将给定的文本描述作为提示，生成高逼真度的插图，为创作者、设计师和普通用户提供了新的应用。然而，这些模型是在大量的网络数据上训练的，这也带来了潜在的有害偏见风险。本文通过研究和量化常见的社会偏见，如职业、人格特征和日常情境在（被感知的）性别、年龄、种族和地理位置上的表现，采用多维度方法来探究生成图片中的社会偏见。通过广泛的自动化和人类评估实验，我们展示了两种流行的 T2I 模型 (DALLE-v2 和 Stable Diffusion) 的发现。结果表明，中性提示存在严重的职业偏见，主要是排除某些人群。

    Text-to-Image (T2I) generation is enabling new applications that support creators, designers, and general end users of productivity software by generating illustrative content with high photorealism starting from a given descriptive text as a prompt. Such models are however trained on massive amounts of web data, which surfaces the peril of potential harmful biases that may leak in the generation process itself. In this paper, we take a multi-dimensional approach to studying and quantifying common social biases as reflected in the generated images, by focusing on how occupations, personality traits, and everyday situations are depicted across representations of (perceived) gender, age, race, and geographical location. Through an extensive set of both automated and human evaluation experiments we present findings for two popular T2I models: DALLE-v2 and Stable Diffusion. Our results reveal that there exist severe occupational biases of neutral prompts majorly excluding groups of people 
    
[^25]: 学习同形异义词消歧表示以改进神经机器翻译

    Learning Homographic Disambiguation Representation for Neural Machine Translation. (arXiv:2304.05860v1 [cs.CL])

    [http://arxiv.org/abs/2304.05860](http://arxiv.org/abs/2304.05860)

    本文提出了一种利用同义词句子建立同形异义词词级消歧表示（HDR）以改进神经机器翻译的方法。

    

    同形异义词在神经机器翻译中一直是难点。本文提出一种在潜在空间中解决同形异义词问题的新方法。首先，我们利用“HDR-encoder”在自然语言推理任务中学习通用句子表示。然后，利用WordNet中的同义词句子建立同形异义词词级消歧表示（HDR），调整预训练的HDR-encoder。最后，我们将预训练的HDR-encoder与基于Transformer的NMT在不同方案中相结合来提高翻译准确性。四个翻译方向的实验表明了本方法在增强NMT系统处理同形异义词方面的有效性。

    Homographs, words with the same spelling but different meanings, remain challenging in Neural Machine Translation (NMT). While recent works leverage various word embedding approaches to differentiate word sense in NMT, they do not focus on the pivotal components in resolving ambiguities of homographs in NMT: the hidden states of an encoder. In this paper, we propose a novel approach to tackle homographic issues of NMT in the latent space. We first train an encoder (aka "HDR-encoder") to learn universal sentence representations in a natural language inference (NLI) task. We further fine-tune the encoder using homograph-based synset sentences from WordNet, enabling it to learn word-level homographic disambiguation representations (HDR). The pre-trained HDR-encoder is subsequently integrated with a transformer-based NMT in various schemes to improve translation accuracy. Experiments on four translation directions demonstrate the effectiveness of the proposed method in enhancing the perfor
    
[^26]: 捷克语、波兰语和斯洛伐克语中的性别偏见量化研究

    Measuring Gender Bias in West Slavic Language Models. (arXiv:2304.05783v1 [cs.CL])

    [http://arxiv.org/abs/2304.05783](http://arxiv.org/abs/2304.05783)

    本研究分析了西斯拉夫语言模型中的性别偏差，发现捷克语、波兰语和斯洛伐克语均存在相似程度的性别偏见。这一研究填补了研究非英语语言模型性别偏见的空白。

    

    预训练模型会将基础数据集中的偏见延续到下游任务。然而，这些研究大多基于英语的单语言模型，而针对扩展到英语以外的语言的语言模型中的偏见的研究很少。本文通过分析西斯拉夫语言模型中的性别偏差来填补这一空白。我们首次引入了基于模板的数据集（包括捷克语、波兰语和斯洛伐克语），以测量针对男性、女性和非二进制主体的性别偏见。我们使用单语和多语言模型来完成这些句子，并评估它们是否适合于被遮盖的语言建模任务。接下来，我们通过量化生成单词的有毒性和性别特征来测量西斯拉夫语言模型中的性别偏见。我们发现这些语言模型生成的语句会因主体的性别而产生伤害性的完成度。令人惊讶的是，捷克语、斯洛伐克语和波兰语均显示出相似程度的性别偏见。本研究对于关于语言模型中存在的偏见的日益增长的研究体系做出贡献，并为评估和减少西斯拉夫语言中的性别偏见奠定了基础。

    Pre-trained language models have been known to perpetuate biases from the underlying datasets to downstream tasks. However, these findings are predominantly based on monolingual language models for English, whereas there are few investigative studies of biases encoded in language models for languages beyond English. In this paper, we fill this gap by analysing gender bias in West Slavic language models. We introduce the first template-based dataset in Czech, Polish, and Slovak for measuring gender bias towards male, female and non-binary subjects. We complete the sentences using both mono- and multilingual language models and assess their suitability for the masked language modelling objective. Next, we measure gender bias encoded in West Slavic language models by quantifying the toxicity and genderness of the generated words. We find that these language models produce hurtful completions that depend on the subject's gender. Perhaps surprisingly, Czech, Slovak, and Polish language mode
    
[^27]: 通过日语文体分析区分ChatGPT(-3.5,-4)的生成文本与人类写作的论文

    Distinguishing ChatGPT(-3.5, -4)-generated and human-written papers through Japanese stylometric analysis. (arXiv:2304.05534v1 [cs.CL])

    [http://arxiv.org/abs/2304.05534](http://arxiv.org/abs/2304.05534)

    本研究通过比较GPT(-3.5和-4)生成的日语文体特征与人类写作的学术论文，证明了它们在文体特征上有显著区别。

    

    文本生成的人工智能，包括OpenAI的GPT-3.5和GPT-4，引起了全球广泛关注。本研究比较了GPT(-3.5和-4)生成和人类撰写的日语文体特征。通过多维尺度分析，将216个文本（36位单一作者的72篇学术论文、72篇GPT-3.5生成的文本和72篇GPT-4生成的文本）根据词性的二元组，词尾的二元组，逗号的位置和功能词的比例分成三类，结果显示出GPT(-3.5，-4)和人类之间在文体特征上有明显差异。

    Text-generative artificial intelligence (AI), including ChatGPT, equipped with GPT-3.5 and GPT-4, from OpenAI, has attracted considerable attention worldwide. In this study, first, we compared Japanese stylometric features generated by GPT (-3.5 and -4) and those written by humans. In this work, we performed multi-dimensional scaling (MDS) to confirm the classification of 216 texts into three classes (72 academic papers written by 36 single authors, 72 texts generated by GPT-3.5, and 72 texts generated by GPT-4 on the basis of the titles of the aforementioned papers) focusing on the following stylometric features: (1) bigrams of parts-of-speech, (2) bigram of postpositional particle words, (3) positioning of commas, and (4) rate of function words. MDS revealed distinct distributions at each stylometric feature of GPT (-3.5 and -4) and human. Although GPT-4 is more powerful than GPT-3.5 because it has more parameters, both GPT (-3.5 and -4) distributions are likely to overlap. These res
    
[^28]: 大型语言模型在医疗保健领域中准备就绪了吗？临床语言理解的比较研究。

    Are Large Language Models Ready for Healthcare? A Comparative Study on Clinical Language Understanding. (arXiv:2304.05368v1 [cs.CL])

    [http://arxiv.org/abs/2304.05368](http://arxiv.org/abs/2304.05368)

    本研究全面评估了大型语言模型在临床语言理解任务上的表现，并引入自问自答提示策略来提高LLMs在医疗保健相关任务中的效果。

    

    大型语言模型（LLMs）在各个领域取得了显著的进展，包括医疗保健领域。然而，临床语言理解任务的专业性质带来了独特的挑战和限制，需要进一步研究。在本研究中，我们对最先进的LLMs——GPT-3.5、GPT-4和Bard进行了全面评估，该评估范围涵盖了各种任务，包括命名实体识别、关系提取、自然语言推理、语义文本相似性、文档分类和问答。我们还引入了一种新的提示策略——自问自答提示（SQP），旨在通过引发与相关临床场景相关的信息性问题和答案，定制化提高LLMs的性能。我们的评估强调了任务特定的学习策略和提示技术对于提高LLMs在医疗保健相关任务中的有效性的重要性。

    Large language models (LLMs) have made significant progress in various domains, including healthcare. However, the specialized nature of clinical language understanding tasks presents unique challenges and limitations that warrant further investigation. In this study, we conduct a comprehensive evaluation of state-of-the-art LLMs, namely GPT-3.5, GPT-4, and Bard, within the realm of clinical language understanding tasks. These tasks span a diverse range, including named entity recognition, relation extraction, natural language inference, semantic textual similarity, document classification, and question-answering. We also introduce a novel prompting strategy, self-questioning prompting (SQP), tailored to enhance LLMs' performance by eliciting informative questions and answers pertinent to the clinical scenarios at hand. Our evaluation underscores the significance of task-specific learning strategies and prompting techniques for improving LLMs' effectiveness in healthcare-related tasks.
    
[^29]: OpenAGI：当LLM遇到领域专家

    OpenAGI: When LLM Meets Domain Experts. (arXiv:2304.04370v1 [cs.AI])

    [http://arxiv.org/abs/2304.04370](http://arxiv.org/abs/2304.04370)

    基于大型语言模型的OpenAGI平台通过整合领域专家模型和自然语言问答形式，实现复杂任务解决。

    

    人类具有将基本技能组合成复杂技能以解决复杂任务的显著能力。这种能力对于人工智能同样重要，因此，我们断言，除了开发大型综合智能模型外，将不同领域专家模型应用于复杂任务解决能力同样关键，以在人工智能通用智能的追求中使其具备这种能力。最近的大型语言模型（LLM）的发展证明其具有出色的学习和推理能力，使它们成为选择、综合和执行外部模型以解决复杂任务的控制器的有前途的选择。在这个项目中，我们开发了一个名为OpenAGI的开源AGI研究平台，专门设计为提供复杂的多步骤任务，并配有任务特定的数据集、评估指标和各种可扩展模型。OpenAGI将复杂任务阐释为自然语言问答，旨在促进领域专家和语言模型之间的协同作用。

    Human intelligence has the remarkable ability to assemble basic skills into complex ones so as to solve complex tasks. This ability is equally important for Artificial Intelligence (AI), and thus, we assert that in addition to the development of large, comprehensive intelligent models, it is equally crucial to equip such models with the capability to harness various domain-specific expert models for complex task-solving in the pursuit of Artificial General Intelligence (AGI). Recent developments in Large Language Models (LLMs) have demonstrated remarkable learning and reasoning abilities, making them promising as a controller to select, synthesize, and execute external models to solve complex tasks. In this project, we develop OpenAGI, an open-source AGI research platform, specifically designed to offer complex, multi-step tasks and accompanied by task-specific datasets, evaluation metrics, and a diverse range of extensible models. OpenAGI formulates complex tasks as natural language q
    
[^30]: 解锁ChatGPT的潜力：对其在自然语言处理中应用、优点、局限性和未来方向的全面探讨

    Unlocking the Potential of ChatGPT: A Comprehensive Exploration of its Applications, Advantages, Limitations, and Future Directions in Natural Language Processing. (arXiv:2304.02017v1 [cs.CL])

    [http://arxiv.org/abs/2304.02017](http://arxiv.org/abs/2304.02017)

    本文全面探讨了ChatGPT在自然语言处理中的应用、优点和局限性，强调了使用这个强大工具时的道德考虑，为人工智能和NLP领域的讨论做出了贡献。

    

    ChatGPT是人工智能领域中广泛应用的强大工具，已成功应用于聊天机器人、内容生成、语言翻译、个性化推荐和医疗诊断治疗。它的多功能性和准确性使其成为自然语言处理（NLP）的强大工具。但是，ChatGPT也存在局限性，例如其倾向于产生有偏见的响应以及存在潜在的有害语言模式。本文全面概述了ChatGPT及其应用、优点和局限性，并强调了在真实场景中使用这个强大工具时道德考虑的重要性。最后，本文通过提供提示工程技术的见解，为关于人工智能及其对视觉和NLP领域的影响的持续讨论做出了贡献。

    ChatGPT is a powerful tool in the field of artificial intelligence that has been widely used in various applications. ChatGPT has been applied successfully in chatbots, content generation, language translation, personalized recommendations, and medical diagnosis and treatment. Its versatility and accuracy make it a powerful tool for natural language processing (NLP). However, there are also limitations to ChatGPT, such as its tendency to produce biased responses and its potential to perpetuate harmful language patterns. This article provides a comprehensive overview of ChatGPT, its applications, advantages, and limitations. Additionally, the paper emphasizes the importance of ethical considerations when using this robust tool in real-world scenarios. Finally, This paper contributes to ongoing discussions surrounding artificial intelligence and its impact on vision and NLP domains by providing insights into prompt engineering techniques.
    
[^31]: ChatGPT作为抽象文本摘要中事实不一致性评估器

    ChatGPT as a Factual Inconsistency Evaluator for Abstractive Text Summarization. (arXiv:2303.15621v1 [cs.CL])

    [http://arxiv.org/abs/2303.15621](http://arxiv.org/abs/2303.15621)

    本文研究了ChatGPT作为抽象文本摘要中事实不一致性评估器的能力，证明其在不需要注释数据和高计算复杂度的情况下，在粗粒度和细粒度的任务中表现出了最先进的性能。

    

    最近，预训练语言模型大大提高了抽象文本摘要的性能。现有的抽象摘要方法的主要问题是其生成的摘要存在的事实不一致性问题。为缓解这个问题，许多努力将重点放在开发基于自然语言推理和问答等方面的有效事实性评估指标上。然而，它们存在计算复杂度高和依赖注释数据的限制。最近，像ChatGPT这样的大型语言模型不仅显示了强大的自然语言理解能力，而且还在自然语言推理方面表现出众。在本文中，我们通过在粗粒度和细粒度的事实评估任务（包括二进制自然语言推理（NLI）、摘要排名和一致性评级）上评估ChatGPT的零-shot设置下的事实不一致性评估能力。实验结果表明，ChatGPT在所有评估任务上均表现出了最先进的性能。

    The performance of abstractive text summarization has been greatly boosted by pre-trained language models recently. The main concern of existing abstractive summarization methods is the factual inconsistency problem of their generated summary. To alleviate the problem, many efforts have focused on developing effective factuality evaluation metrics based on natural language inference and question answering et al. However, they have limitations of high computational complexity and relying on annotated data. Most recently, large language models such as ChatGPT have shown strong ability in not only natural language understanding but also natural language inference. In this paper, we study the factual inconsistency evaluation ability of ChatGPT under the zero-shot setting by evaluating it on the coarse-grained and fine-grained factuality evaluation tasks including binary natural language inference (NLI), summary ranking, and consistency rating. Experimental results show that ChatGPT outperf
    
[^32]: Hulk: 用图神经网络优化区域分布式计算系统

    Hulk: Graph Neural Networks for Optimizing Regionally Distributed Computing Systems. (arXiv:2302.13741v2 [cs.DC] UPDATED)

    [http://arxiv.org/abs/2302.13741](http://arxiv.org/abs/2302.13741)

    本文提出了一种基于图神经网络以优化区域分布式计算系统的方法，称为 Hulk。该方法能够提高分布式训练的效率，减少数据通信的开销，实现最佳的模型分布式部署。

    

    大型深度学习模型在各种应用中均表现出极大的潜力，然而模型的训练过程由于参数数量会极大，通常有数千亿个参数，因此训练变得非常具有挑战性。常见的分布式训练方法，如数据并行、张量并行和流水线并行，需要在整个过程中进行大量数据通信，导致在物理上分布的远程系统中一些机器的等待时间变得很长。为了解决这个问题，我们提出了一种新型解决方案，称为 Hulk，它利用改进后的图神经网络来优化分布式计算系统。Hulk 不仅可以优化不同国家甚至同一个城市内不同区域之间的数据通信效率，而且还可以提供模型的最佳分布式部署。例如，它可以将某些层放在特定区域的机器上或传递特定的参数。

    Large deep learning models have shown great potential for delivering exceptional results in various applications. However, the training process can be incredibly challenging due to the models' vast parameter sizes, often consisting of hundreds of billions of parameters. Common distributed training methods, such as data parallelism, tensor parallelism, and pipeline parallelism, demand significant data communication throughout the process, leading to prolonged wait times for some machines in physically distant distributed systems. To address this issue, we propose a novel solution called Hulk, which utilizes a modified graph neural network to optimize distributed computing systems. Hulk not only optimizes data communication efficiency between different countries or even different regions within the same city, but also provides optimal distributed deployment of models in parallel. For example, it can place certain layers on a machine in a specific region or pass specific parameters of a m
    
[^33]: 追求机器学习研究的推理复现性

    Towards Inferential Reproducibility of Machine Learning Research. (arXiv:2302.04054v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.04054](http://arxiv.org/abs/2302.04054)

    本研究提出利用线性混合效应模型（LMEM）来分析机器学习性能评估分数，并考虑多个方差来源及其与数据特性相互作用，从而评估可靠性和可复制性，促进对机器学习算法行为的更全面理解。

    

    机器学习评估的可靠性——即在复制的模型训练运行中观察到的评估分数的一致性——受到几种非确定性来源的影响，可以被视为测量噪声。目前的趋势是去除噪声，以强制研究结果的可复制性，忽略了实现层面固有的非确定性以及算法噪声因素和数据特性之间的关键相互作用效应。这限制了从这些实验中可以得出的结论范围。我们提出的方法是将几个方差来源，包括它们与数据特性的相互作用，纳入机器学习评估的显著性和可靠性分析中，以期从训练模型的特定实例得出推理结论, 而非去除噪声。我们展示如何使用线性混合效应模型（LMEM）来分析性能评估分数，并用广义似然比检验进行统计推断。我们的方法提供了一种系统的方式来考虑算法和数据相关的噪声来源，并使我们能够量化各个方差来源对机器学习实验的可靠性和可复制性的影响。我们在一系列合成和真实数据集上演示了我们方法的实用性，并说明了我们的方法如何促进对机器学习算法行为的更全面理解。

    Reliability of machine learning evaluation -- the consistency of observed evaluation scores across replicated model training runs -- is affected by several sources of nondeterminism which can be regarded as measurement noise. Current tendencies to remove noise in order to enforce reproducibility of research results neglect inherent nondeterminism at the implementation level and disregard crucial interaction effects between algorithmic noise factors and data properties. This limits the scope of conclusions that can be drawn from such experiments. Instead of removing noise, we propose to incorporate several sources of variance, including their interaction with data properties, into an analysis of significance and reliability of machine learning evaluation, with the aim to draw inferences beyond particular instances of trained models. We show how to use linear mixed effects models (LMEMs) to analyze performance evaluation scores, and to conduct statistical inference with a generalized lik
    
[^34]: 多语言语义解析的主动学习

    Active Learning for Multilingual Semantic Parser. (arXiv:2301.12920v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.12920](http://arxiv.org/abs/2301.12920)

    本研究提出了一种多语言语义解析的主动学习方法(AL-MSP), 选择一个现有数据集的子集进行翻译，通过优先选择多样化逻辑形式结构和更多词汇选择的示例，以及一种新的无需额外注释成本的超参数调整方法，有效减少了翻译成本，并取得了比其他基线更好的解析性能。

    

    当前的多语言语义解析(MSP) 数据集几乎都是通过将现有数据集中的话语从资源丰富的语言翻译到目标语言而收集的。但是，手动翻译成本高昂。为了减少翻译工作量，本文提出了第一个MSP的主动学习过程(AL-MSP)。AL-MSP只选择现有数据集的子集进行翻译。我们还提出了一种新的选择方法，优先选择多样化逻辑形式结构和更多词汇选择的示例，以及一种无需额外注释成本的新的超参数调整方法。我们的实验表明，通过理想的选择方法，AL-MSP显著减少了翻译成本。我们的选择方法与适当的超参数可以在两个多语言数据集上获得比其他基线更好的解析性能。

    Current multilingual semantic parsing (MSP) datasets are almost all collected by translating the utterances in the existing datasets from the resource-rich language to the target language. However, manual translation is costly. To reduce the translation effort, this paper proposes the first active learning procedure for MSP (AL-MSP). AL-MSP selects only a subset from the existing datasets to be translated. We also propose a novel selection method that prioritizes the examples diversifying the logical form structures with more lexical choices, and a novel hyperparameter tuning method that needs no extra annotation cost. Our experiments show that AL-MSP significantly reduces translation costs with ideal selection methods. Our selection method with proper hyperparameters yields better parsing performance than the other baselines on two multilingual datasets.
    
[^35]: RPN: 一种深度学习中基于词向量的数据增强算法，用于语言理解

    RPN: A Word Vector Level Data Augmentation Algorithm in Deep Learning for Language Understanding. (arXiv:2212.05961v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.05961](http://arxiv.org/abs/2212.05961)

    RPN是一种基于词向量级别的数据增强算法，通过引入噪声修改原始文本的词嵌入，更好地捕捉自然语言变化，并在自然语言理解任务中表现出优异的性能。

    

    数据增强是机器学习中广泛使用以提高模型性能的技术。然而，现有的自然语言理解数据增强技术可能无法完全捕捉到自然语言的复杂变化，并且在大型数据集中应用起来具有挑战性。本文提出了一种新颖的数据增强技术——随机位置噪声（RPN）算法，它在词向量级别上进行操作。RPN通过根据选定词向量的现有值引入噪声修改原始文本的词嵌入，允许更细粒度的修改并更好地捕捉自然语言变化。与传统的数据增强方法不同，RPN不需要计算图中的梯度来进行虚拟样本更新，使其更容易应用于大型数据集。实验结果表明，在各种自然语言理解任务中，包括情感分析等，RPN始终优于现有数据增强技术。

    Data augmentation is a widely used technique in machine learning to improve model performance. However, existing data augmentation techniques in natural language understanding (NLU) may not fully capture the complexity of natural language variations, and they can be challenging to apply to large datasets. This paper proposes the Random Position Noise (RPN) algorithm, a novel data augmentation technique that operates at the word vector level. RPN modifies the word embeddings of the original text by introducing noise based on the existing values of selected word vectors, allowing for more fine-grained modifications and better capturing natural language variations. Unlike traditional data augmentation methods, RPN does not require gradients in the computational graph during virtual sample updates, making it simpler to apply to large datasets. Experimental results demonstrate that RPN consistently outperforms existing data augmentation techniques across various NLU tasks, including sentime
    
[^36]: SQA3D：三维场景中的情境问答

    SQA3D: Situated Question Answering in 3D Scenes. (arXiv:2210.07474v5 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.07474](http://arxiv.org/abs/2210.07474)

    本文提出了一个新的任务，即评估具有场景理解能力的代理人在三维场景中的情境问答。基于650个场景的数据集为智能代理人的推理能力考察提供了广泛且大量的问题，这对当前的多模式，特别是3D推理模型提出了很大挑战。

    

    我们提出了一个新的任务来评估具有场景理解能力的代理人：三维场景中的情境问答（SQA3D）。给定一个场景上下文（例如三维扫描），SQA3D要求经过测试的代理人首先理解其在文本描述下的3D场景中的情境（位置、方向等），然后在该情境下进行推理，回答一个问题。基于来自ScanNet的650个场景，我们提供了一个数据集，其中心围绕6.8k个唯一情境，20.4k的描述和33.4k多样的推理问题。这些问题涵盖了对智能代理人范围广泛的推理能力的考察，从空间关系理解到常识理解、导航和多跳推理。SQA3D对当前的多模式尤其是3D推理模型提出了重大挑战。我们评估了各种最先进的方法，并发现最佳结果仅达到了47.20%的总体得分，而业余水平的表现更为糟糕。

    We propose a new task to benchmark scene understanding of embodied agents: Situated Question Answering in 3D Scenes (SQA3D). Given a scene context (e.g., 3D scan), SQA3D requires the tested agent to first understand its situation (position, orientation, etc.) in the 3D scene as described by text, then reason about its surrounding environment and answer a question under that situation. Based upon 650 scenes from ScanNet, we provide a dataset centered around 6.8k unique situations, along with 20.4k descriptions and 33.4k diverse reasoning questions for these situations. These questions examine a wide spectrum of reasoning capabilities for an intelligent agent, ranging from spatial relation comprehension to commonsense understanding, navigation, and multi-hop reasoning. SQA3D imposes a significant challenge to current multi-modal especially 3D reasoning models. We evaluate various state-of-the-art approaches and find that the best one only achieves an overall score of 47.20%, while amateu
    
[^37]: 多语言BERT带有语音特色：评估英语对多语言模型流畅性的影响。

    Multilingual BERT has an accent: Evaluating English influences on fluency in multilingual models. (arXiv:2210.05619v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.05619](http://arxiv.org/abs/2210.05619)

    本文研究了多语言模型的语言流畅性问题，发现高资源语言的语法结构会对低资源语言产生影响，导致多语言BERT具有英语语音特色。

    

    多语言语言模型可以通过利用高资源语言来提高低资源语言的自然语言处理性能，但它们也会降低所有语言的平均性能（“多语言诅咒”）。本文显示多语言模型的另一个问题：高资源语言的语法结构会渗入低资源语言，这种现象被称为语法结构偏差。我们通过一种新方法比较多语言模型的流畅性与单语西班牙语和希腊语模型的流畅性，展示了这种模型的偏差：测试它们对两种精心选择的可变语法结构的偏好（西班牙语中的可选省略代词和希腊语中的可选主语-谓语调序）。我们发现，与我们的单语控制语言模型相比，多语言BERT偏向于类似英语的设置（显式代词和主-谓-宾语调序）。通过我们的案例研究，我们希望揭示多语言模型能够以精细的方式影响自然语言处理流畅性的细节。

    While multilingual language models can improve NLP performance on low-resource languages by leveraging higher-resource languages, they also reduce average performance on all languages (the 'curse of multilinguality'). Here we show another problem with multilingual models: grammatical structures in higher-resource languages bleed into lower-resource languages, a phenomenon we call grammatical structure bias. We show this bias via a novel method for comparing the fluency of multilingual models to the fluency of monolingual Spanish and Greek models: testing their preference for two carefully-chosen variable grammatical structures (optional pronoun-drop in Spanish and optional Subject-Verb ordering in Greek). We find that multilingual BERT is biased toward the English-like setting (explicit pronouns and Subject-Verb-Object ordering) as compared to our monolingual control language model. With our case studies, we hope to bring to light the fine-grained ways in which multilingual models can 
    
[^38]: PePe: 利用用户生成的后编辑实现个性化的后编辑模型

    PePe: Personalized Post-editing Model utilizing User-generated Post-edits. (arXiv:2209.10139v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.10139](http://arxiv.org/abs/2209.10139)

    本文提出了一种个性化的自动后编辑框架PePe，在一个实时的机器翻译系统中，通过收集用户后编辑数据，结合判别模块和用户特定参数，能够有效地生成考虑到不同个人行为的句子，并在多个度量标准上优于其他基线模型。

    

    在先进的机器翻译任务中，将个人的偏好加以考虑至关重要。尽管机器翻译已经取得了近期的重大进展，但是正确反映个人风格仍然是一个具有挑战性的任务。在本论文中，我们引入了一个个性化的自动后编辑框架来解决这个难题，这个框架能够有效地生成考虑到不同个人行为的句子。为了构建这个框架，我们首先从实时机器翻译系统中收集包含用户偏好的后编辑数据。具体而言，真实用户输入想要翻译的源语句，并根据用户的风格偏好编辑机器翻译的输出。接着，我们提出了一个模型，在APE框架上结合了一个判别模块和用户特定的参数。实验结果表明，所提出的方法在四种不同的度量标准（即BLEU，TER，YiSi-1和人类评估）上优于其他基线模型。

    Incorporating personal preference is crucial in advanced machine translation tasks. Despite the recent advancement of machine translation, it remains a demanding task to properly reflect personal style. In this paper, we introduce a personalized automatic post-editing framework to address this challenge, which effectively generates sentences considering distinct personal behaviors. To build this framework, we first collect post-editing data that connotes the user preference from a live machine translation system. Specifically, real-world users enter source sentences for translation and edit the machine-translated outputs according to the user's preferred style. We then propose a model that combines a discriminator module and user-specific parameters on the APE framework. Experimental results show that the proposed method outperforms other baseline models on four different metrics (i.e., BLEU, TER, YiSi-1, and human evaluation).
    
[^39]: 将AI规划与自然语言处理集成：显式和隐式知识的组合

    Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge. (arXiv:2202.07138v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2202.07138](http://arxiv.org/abs/2202.07138)

    本文提出了一个框架，将AI规划与自然语言处理相结合，利用显式和隐式知识来改善生成自然语言的效果。

    

    自然语言处理旨在研究代理人和人类之间的交互，处理和分析大量的自然语言数据。大规模的语言模型在当前自然语言处理中起着重要作用。然而，语言模型的发展带来了可解释性和复杂性的挑战。一种方法是将逻辑关系和规则引入自然语言处理模型中，例如利用自动规划技术。自动规划即AI规划，侧重于构建符号域模型并综合规划，以基于域模型将初始状态转换为目标。最近，有许多与这两个领域相关的工作，可以产生显式知识，例如操作模型的前提条件和效果，并从隐式知识（例如神经模型）中学习。有效地将AI规划与自然语言处理集成可以改善人与机器之间的交流。本文提出了一个框架，该框架结合显式和隐式知识，用于将AI规划与自然语言处理相结合。具体而言，我们首先使用AI规划技术构建域模型并推理自然语言中的逻辑关系。然后，我们利用大规模预训练的语言模型从隐式知识中学习，并改善自然语言的生成。最后，我们在一个真实的数据到文本生成任务上展示了我们的方法的有效性。

    Natural language processing (NLP) aims at investigating the interactions between agents and humans, processing and analyzing large amounts of natural language data. Large-scale language models play an important role in current natural language processing. However, the challenges of explainability and complexity come along with the developments of language models. One way is to introduce logical relations and rules into natural language processing models, such as making use of Automated Planning. Automated planning (AI planning) focuses on building symbolic domain models and synthesizing plans to transit initial states to goals based on domain models. Recently, there have been plenty of works related to these two fields, which have the abilities to generate explicit knowledge, e.g., preconditions and effects of action models, and learn from tacit knowledge, e.g., neural models, respectively. Integrating AI planning and natural language processing effectively improves the communication b
    

