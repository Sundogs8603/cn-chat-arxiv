# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Contrastive Loss is All You Need to Recover Analogies as Parallel Lines.](http://arxiv.org/abs/2306.08221) | 本论文提出使用对比损失方法可以达到和词嵌入模型相同的类比恢复效果，且在训练时间上有大幅度的提升；并证明了对比损失能够创造出具有平行结构的词嵌入。 |
| [^2] | [Operationalising Representation in Natural Language Processing.](http://arxiv.org/abs/2306.08193) | 本文介绍了一个框架，通过使用探测分类器来评估组件是否表示属性，填补了自然语言处理中关于“表示”的哲学空白。 |
| [^3] | [Assessing the Effectiveness of GPT-3 in Detecting False Political Statements: A Case Study on the LIAR Dataset.](http://arxiv.org/abs/2306.08190) | 本文评估了GPT-3模型在LIAR数据集上检测虚假政治陈述的效果，并证明其准确性高于其他最先进的模型，且使用零样本学习可接近最先进的性能。 |
| [^4] | [Language models are not naysayers: An analysis of language models on negation benchmarks.](http://arxiv.org/abs/2306.08189) | 本研究系统评估了当前一代自回归语言模型（LLMs）处理否定的能力，发现LLMs存在无法捕捉否定词汇语义、不能推理的问题等限制。 |
| [^5] | [INT2.1: Towards Fine-Tunable Quantized Large Language Models with Error Correction through Low-Rank Adaptation.](http://arxiv.org/abs/2306.08162) | 该论文提出了一种通过低秩自适应纠错的方法，从而可以显著地减少精细调整VRAM需求，并纠正量化大语言模型中的量化误差，使消费者笔记本电脑可以对70亿个参数的大语言模型进行精细调整，生成连贯的英文文本。 |
| [^6] | [h2oGPT: Democratizing Large Language Models.](http://arxiv.org/abs/2306.08161) | 本文介绍了h2oGPT，这是一套开源代码库，用于创建和使用基于GPTs的大语言模型（LLMs），包括100％私有文档搜索。目标是创建真正开源的替代封闭源GPTs，提高人工智能的开发和可靠性。 |
| [^7] | [Survey on Sociodemographic Bias in Natural Language Processing.](http://arxiv.org/abs/2306.08158) | 本文调查了209篇关于NLP模型偏见的论文，其中大部分涉及社会人口统计偏见。研究者提出了社会人口统计偏见的定义，并确定了NLP偏见研究的三个主要类别。当前去偏见技术只是隐藏了偏见而不是真正去除它，需要进一步改进。 |
| [^8] | [Large-scale Language Model Rescoring on Long-form Data.](http://arxiv.org/abs/2306.08133) | 本文研究了大规模语言模型对长视频ASR的影响，证明与最大熵基线相比，使用LLM能够最多减少8％的Word Error Rate和30％的Salient Term Error Rate。经过改进的格处理和携带上下文的组合可以获得更好的效果。 |
| [^9] | [AVIS: Autonomous Visual Information Seeking with Large Language Models.](http://arxiv.org/abs/2306.08129) | 本文提出了一个基于大型语言模型的自主信息检索视觉问答框架AVIS，可以解决视觉问题所需的外部知识获取问题。 |
| [^10] | [PersonaPKT: Building Personalized Dialogue Agents via Parameter-efficient Knowledge Transfer.](http://arxiv.org/abs/2306.08126) | 本文提出了PersonaPKT，一种轻量级迁移学习方法，可以在没有明确个性描述的情况下构建符合角色的对话模型，该方法通过将每个个性表示为一个连续向量，直接从同一角色产生的少量对话样本中学习隐含的个性特定特征，并能够高效构建个性化对话代理并增强隐私保护。 |
| [^11] | [Beyond Black Box AI-Generated Plagiarism Detection: From Sentence to Document Level.](http://arxiv.org/abs/2306.08122) | 该论文提出了一种新的自然语言处理方法，可对学术写作中的抄袭行为进行有效检测，不仅在句子级别上进行评估，还在文档级别上提供可量化指标。该方法的准确率高达94％，具有较强的适应性和可靠性，能够不断随着LLM技术的发展而不断改进。 |
| [^12] | [CipherSniffer: Classifying Cipher Types.](http://arxiv.org/abs/2306.08116) | 本文将解密任务作为分类问题来解决，并创建了一个包含各种类型的密码数据集，最终评估了各种Tokenizer-Model组合在此任务中的性能。 |
| [^13] | [AutoML in the Age of Large Language Models: Current Challenges, Future Opportunities and Risks.](http://arxiv.org/abs/2306.08107) | 论文探讨了AutoML和LLMs之间的共生关系，并指出这两个领域的融合有望颠覆NLP和AutoML两个领域，同时也存在风险。 |
| [^14] | [FLamE: Few-shot Learning from Natural Language Explanations.](http://arxiv.org/abs/2306.08042) | FLamE是一个利用GPT-3生成自然语言解释用于RoBERTa微调的少样本学习框架，在自然语言推理任务上展现出较好的性能，但是人生成的解释大多不能充分地证明分类决策，标签特定线索在解释中起着重要作用。 |
| [^15] | [Curatr: A Platform for Semantic Analysis and Curation of Historical Literary Texts.](http://arxiv.org/abs/2306.08020) | Curatr是一个在线平台，可以基于机器学习支持的语义搜索来进行历史文学文本的筛选，提供主题词典的生成，帮助研究人员快速从大量的数字化文本中挑选出相关的子语料库。 |
| [^16] | [Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models.](http://arxiv.org/abs/2306.08018) | Mol-Instructions是一个专门为生物分子领域设计的综合指令数据集，可以显著提高大语言模型在生物领域中的适应能力和认知敏锐度。 |
| [^17] | [A Novel Scheme to classify Read and Spontaneous Speech.](http://arxiv.org/abs/2306.08012) | 本文提出了一种利用DeepSpeech音频到字母识别引擎的新方案来分类朗读和自发语音。利用该方法可以非常有效地识别这两种类型的语音。 |
| [^18] | [Improving Zero-Shot Detection of Low Prevalence Chest Pathologies using Domain Pre-trained Language Models.](http://arxiv.org/abs/2306.08000) | 该论文研究了如何利用领域预训练语言模型CX-BERT、BlueBERT和ClinicalBERT提高CLIP-like模型对低患病率胸部病症的零样本检测。实验结果表明，预训练的文本塔对于低患病率疾病的检测有显著的性能提升。这提示了未来可使用不同训练语言模型的集成模型进行进一步研究。 |
| [^19] | [MSSRNet: Manipulating Sequential Style Representation for Unsupervised Text Style Transfer.](http://arxiv.org/abs/2306.07994) | 本文提出了一种新方法，通过为每个词汇分配单独的风格向量来对文本进行风格转换，并引入基于教师-学生学习的对抗性培训框架，以提高培训稳定性，实现了双风格转换和多风格转换两种情况下的明显提高的风格转换准确性和内容保留。 |
| [^20] | [Utilizing Social Media Attributes for Enhanced Keyword Detection: An IDF-LDA Model Applied to Sina Weibo.](http://arxiv.org/abs/2306.07978) | 本文提出了一种新的方法，将逆文档频率（IDF）和潜在狄利克雷分配（LDA）模型相结合，以更好地应对社交媒体数据的不同属性，通过基于点赞数、评论数和转发数等属性对每个文档的重要性进行加权，从而有效地过滤噪声并识别最相关的关键词。 |
| [^21] | [TrojPrompt: A Black-box Trojan Attack on Pre-trained Language Models.](http://arxiv.org/abs/2306.06815) | 本文开创性地研究了基于 prompt 学习的预训练语言模型 API 的特洛伊易感性，并提出了一种自动黑盒框架——TrojPrompt，用于生成通用和隐蔽的触发器，并将特洛伊木马插入硬提示。 |
| [^22] | [Mind2Web: Towards a Generalist Agent for the Web.](http://arxiv.org/abs/2306.06070) | Mind2Web是第一个用于开发和评估通用Web代理的数据集，可以按照语言指令完成任意网站上的复杂任务。此数据集提供了三个必要元素：1）多样的领域、网站和任务，2）使用真实网站而非模拟和简化网站，3）广泛的用户交互模式。研究者使用Mind2Web进行了初步探索，使用小型LM过滤可以显着提高任务完成率的效果。 |
| [^23] | [Xiezhi: An Ever-Updating Benchmark for Holistic Domain Knowledge Evaluation.](http://arxiv.org/abs/2306.05783) | Xiezhi是一种全面综合的评估套件，设有516个多项选择问题，覆盖了从13个不同学科跨越的15个专业领域，并对47个先进的LLMs进行评估，结果表明LLMs在大多数领域超越人类，但在一些领域表现不佳。 |
| [^24] | [COVER: A Heuristic Greedy Adversarial Attack on Prompt-based Learning in Language Models.](http://arxiv.org/abs/2306.05659) | 本文提出了一种启发式贪心对抗攻击，针对基于提示的模板在PLMs中可能存在的漏洞，通过字符级和单词级的破坏方法进行攻击，取得了较高的攻击成功率。 |
| [^25] | [KIT's Multilingual Speech Translation System for IWSLT 2023.](http://arxiv.org/abs/2306.05320) | 本文介绍了一个为IWSLT 2023多语言翻译贡献的翻译系统，其重点在于翻译科学会议演讲。用“检索式方法”（kNN-MT）进行有效的适应，该系统采用适配器轻松集成来自数据增强的增量训练数据，并展示级联系统更容易适应特定目标领域的优势。 |
| [^26] | [INSTRUCTEVAL: Towards Holistic Evaluation of Instruction-Tuned Large Language Models.](http://arxiv.org/abs/2306.04757) | INSTRUCTEVAL是一个专注于指导调整的大型语言模型评估的综合套件，它采取了全面的方法来评估模型的性能，包括解决问题、写作能力和与人类价值观的一致性等特征。 |
| [^27] | [Zambezi Voice: A Multilingual Speech Corpus for Zambian Languages.](http://arxiv.org/abs/2306.04428) | Zambezi Voice是针对赞比亚语的多语种语音语料库，含有160小时无标签音频和80小时有标签数据，可用于语音识别和多语种语音处理研究。该数据集是为赞比亚语创造的第一个多语种语音数据集。 |
| [^28] | [ConTextual Masked Auto-Encoder for Retrieval-based Dialogue Systems.](http://arxiv.org/abs/2306.04357) | 本研究提出了一种针对对话响应选择的后训练技术Dial-MAE，利用生成方法更好地压缩对话语义至密集向量，并提高对话响应选择准确性。 |
| [^29] | [MidMed: Towards Mixed-Type Dialogues for Medical Consultation.](http://arxiv.org/abs/2306.02923) | 本文提出MidMed，一个面向医疗咨询的混合类型对话系统，涵盖五种对话类型和四个部门。提出指导式的医学对话生成框架InsMed，实验结果表明在多个评估指标上实现了最先进的性能。 |
| [^30] | [Learning from Partially Annotated Data: Example-aware Creation of Gap-filling Exercises for Language Learning.](http://arxiv.org/abs/2306.01584) | 本文提出了一种从已有的例子练习生成新的区别感知型填空练习，无需深度标注，特别针对语言学习中的语法练习；使用了一种新的神经网络模型并提供了相应的法语语法数据集，结果表明该模型在这类任务中表现优于竞争基准。 |
| [^31] | [PassGPT: Password Modeling and (Guided) Generation with Large Language Models.](http://arxiv.org/abs/2306.01545) | 本研究使用大型语言模型PassGPT进行密码建模和生成，该模型比基于GAN的现有方法更准确，能生成符合任意限制的密码，为提高密码强度估计器提供了潜在的帮助。 |
| [^32] | [How Ready are Pre-trained Abstractive Models and LLMs for Legal Case Judgement Summarization?.](http://arxiv.org/abs/2306.01248) | 这篇论文探讨了是否可以使用预训练的抽象模型和大型语言模型来自动生成法律案例判决的摘要，并在印度的法庭案例判决中进行了相关实验分析。 |
| [^33] | [Revisiting Hate Speech Benchmarks: From Data Curation to System Deployment.](http://arxiv.org/abs/2306.01105) | 该论文介绍了GOTHate数据集，并详细比较了该数据集与现有的仇恨言论数据集，研究了模型如何捕捉中立的恶意内容中的仇恨信号。研究发现，GOTHate很难在纯文本环境下进行分类，并介绍了如何通过添加内生信号来提高模型性能。 |
| [^34] | [Parallel Neurosymbolic Integration with Concordia.](http://arxiv.org/abs/2306.00480) | 康科迪亚框架是一个支持各种概率理论，克服了现有技术的限制的并行的神经符号结构，成功应用于集合活动检测、实体链接和推荐任务，提高了最新准确性。 |
| [^35] | [Generating Images with Multimodal Language Models.](http://arxiv.org/abs/2305.17216) | 该论文提出了一种方法，将大型语言模型与预训练的图像编码器和解码器模型进行融合，能生成具有连贯性的图像输出，同时也能进行图像检索和多模态对话。 |
| [^36] | [Learning to Imagine: Visually-Augmented Natural Language Generation.](http://arxiv.org/abs/2305.16944) | 本研究提出了一种称为LIVE的方法，通过视觉增强学习生成自然语言的想象，并针对每个句子进行动态合成，大量实验测试表明它可以有效提高生成质量。 |
| [^37] | [GDA: Generative Data Augmentation Techniques for Relation Extraction Tasks.](http://arxiv.org/abs/2305.16663) | GDA是一个专门用于关系文本增强的技术，通过采用两个互补模块，保持语义和语法结构的一致性，并使用实体提示扩展上下文。实验结果表明GDA超越了现有增强技术，实现了最先进的性能。 |
| [^38] | [Scaling Data-Constrained Language Models.](http://arxiv.org/abs/2305.16264) | 研究人员研究了在数据受限制的情况下缩放语言模型，并提出了一个计算最优性的缩放定律，考虑到重复令牌和过量参数的价值递减。 |
| [^39] | [Bhasha-Abhijnaanam: Native-script and romanized Language Identification for 22 Indic languages.](http://arxiv.org/abs/2305.15814) | 该研究提供了22种印度宪法中列出的所有21种本土文字和罗马字母的公开语言鉴别（LID）数据和模型。IndicLID是上述语言的本土和罗马化脚本的语言鉴别器，还提出了解决罗马化文本的LID问题的方案。 |
| [^40] | [Diffusion Models in NLP: A Survey.](http://arxiv.org/abs/2305.14671) | 本文全面综述了扩散模型在NLP中的各种应用，比较了其与自回归模型的优劣，指出扩散模型在并行生成、文本插值、词级别控制等方面具有明显优势。 |
| [^41] | [WebIE: Faithful and Robust Information Extraction on the Web.](http://arxiv.org/abs/2305.14293) | WebIE提出了一个大规模的、实体关联闭合的IE数据集，以更好地反映网络数据，并评估了生成式IE模型的性能，表现出良好的结果。 |
| [^42] | [LLM-Pruner: On the Structural Pruning of Large Language Models.](http://arxiv.org/abs/2305.11627) | 本文提出了一种方法，名为LLM-Pruner，采用结构修剪的方式在保留大多数功能的同时，压缩LLM的结构，以减少LLM在部署、推理和训练阶段中的大小和复杂度。 |
| [^43] | [Interactive Text-to-SQL Generation via Editable Step-by-Step Explanations.](http://arxiv.org/abs/2305.07372) | 本文介绍一种交互机制，允许用户直接编辑一步步解释错误SQL以修复SQL错误，实验证明方法提高了31.6％的执行准确性。用户研究表明，该方法帮助用户以更少的时间和更高的信心解决了更多的SQL任务。 |
| [^44] | [LMs stand their Ground: Investigating the Effect of Embodiment in Figurative Language Interpretation by Language Models.](http://arxiv.org/abs/2305.03445) | 本文研究调查了具身化策略对语言模型解释比喻性语言的影响。结果表明，更大的模型在处理行为更具体化的隐喻性句子时表现更佳。 |
| [^45] | [Language, Time Preferences, and Consumer Behavior: Evidence from Large Language Models.](http://arxiv.org/abs/2305.02531) | 本研究分析了大型语言模型在不同语言提示下的奖励时间偏好，并发现GPT在具有较弱未来时态的语言下表现出更大的耐心，这与使用该语言的人类的偏好相似。 |
| [^46] | [GPTutor: a ChatGPT-powered programming tool for code explanation.](http://arxiv.org/abs/2305.01863) | 本文介绍了一种名为GPTutor的ChatGPT动力编程工具，它是一个使用ChatGPT API的Visual Studio Code扩展，通过设计提示词，可以对所选代码进行精简、准确的解释。 |
| [^47] | [Contextual Multilingual Spellchecker for User Queries.](http://arxiv.org/abs/2305.01082) | 本文提出了一个上下文多语种用户查询拼写检查器，它非常快速、可扩展，并根据特定产品的需求调整其词汇表和拼写输出，以满足用户的需求。 |
| [^48] | [Tool Learning with Foundation Models.](http://arxiv.org/abs/2304.08354) | 基于基础模型的工具学习结合了专用工具和基础模型的优势，实现了问题解决的增强精度、效率和自动化。本文对工具学习进行了系统研究，提出了涵盖两种类型学习的通用工具学习框架，并分析了它们的独特挑战、机会和未来方向。 |
| [^49] | [Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca.](http://arxiv.org/abs/2304.08177) | 这篇论文提出了一种方法，通过扩展LLaMA现有的词汇表，增加了20,000个中文标记，从而提高其编码效率和对汉语语义的理解能力，并在中文数据上进行二次预训练和精细调整模型，以改善LLaMA对中文的理解和生成能力。 |
| [^50] | [OpenAGI: When LLM Meets Domain Experts.](http://arxiv.org/abs/2304.04370) | 基于大型语言模型的OpenAGI平台通过整合领域专家模型和自然语言问答形式，实现复杂任务解决。 |
| [^51] | [LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention.](http://arxiv.org/abs/2303.16199) | 本文提出了一种基于适应提示和零初始化注意力机制的轻量级语言模型调整方法，可高效微调LLaMA为指令跟随模型，具有比Alpaca更短的微调时间并具有近似的响应质量。 |
| [^52] | [Learning Transductions and Alignments with RNN Seq2seq Models.](http://arxiv.org/abs/2303.06841) | 本文研究了RNN seq2seq模型在学习四种转换任务方面的能力，并发现其只能逼近符合训练或分布内数据的映射，不能学习底层函数；文章建立了一个新的复杂性层次结构，用于无注意力RNN seq2seq模型，而不是字符串转换的复杂性层次结构。 |
| [^53] | [Pretraining Language Models with Human Preferences.](http://arxiv.org/abs/2302.08582) | 本论文探索了用人类反馈替代传统互联网文本来预训练语言模型的方法，其中条件训练是最优和简单的方法，可将不良内容的生成速率降低一个数量级，同时保持语言模型在下游任务上的性能。 |
| [^54] | [Large language models predict human sensory judgments across six modalities.](http://arxiv.org/abs/2302.01308) | 本研究表明，最先进的大型语言模型能预测人类在六个感官模态下的感知评判，并能提供从语言中提取感知信息的下限。 |
| [^55] | [Grounding Language Models to Images for Multimodal Inputs and Outputs.](http://arxiv.org/abs/2301.13823) | 该论文提出一种有效的方法，将仅处理文本的语言模型与图像进行联系，使其能够处理任意交错的图像和文本数据，并生成与检索图像交错的自由形式文本。该方法在环境相关的图像检索和多模态对话等任务中表现十分优异，是利用预训练语言模型解决视觉场景下交互问题的有效解决方案。 |
| [^56] | [Probing Out-of-Distribution Robustness of Language Models with Parameter-Efficient Transfer Learning.](http://arxiv.org/abs/2301.11660) | 本文评估了各种参数高效的迁移学习方法对不同规模的语言模型在三个不同的意图分类任务中检测超分布（OOD）的能力，旨在为语言模型的超分布鲁棒性提供参考。 |
| [^57] | [Prompt-Augmented Linear Probing: Scaling beyond the Limit of Few-shot In-Context Learners.](http://arxiv.org/abs/2212.10873) | 本论文提出了一种混合线性探测和上下文学习的方法，结合了两者的优点，旨在提高模型在少样本和零样本情况下的性能表现。 |
| [^58] | [Is GPT-3 a Good Data Annotator?.](http://arxiv.org/abs/2212.10450) | 本文通过比较和分析，评估了GPT-3作为数据注释器的性能，探讨了其作为通用NLP数据注释器的潜力。 |
| [^59] | [Needle in a Haystack: An Analysis of High-Agreement Workers on MTurk for Summarization.](http://arxiv.org/abs/2212.10397) | 本研究调查了在MTurk上高一致性工作者对自动摘要的评估，通过两步筛选找到高质量的工作者，为其他具有挑战性注释任务的招募提供了最佳实践。 |
| [^60] | [DOC: Improving Long Story Coherence With Detailed Outline Control.](http://arxiv.org/abs/2212.10077) | 该论文提出了一个名为 Detailed Outline Control(DOC) 的框架，通过详细大纲和详细控制器来提高生成长篇故事时的情节连贯性和大纲相关性，人类评估证实该方法在这些方面显著优于基线方法，并且更适用于交互生成设置。 |
| [^61] | [Efficient Self-supervised Learning with Contextualized Target Representations for Vision, Speech and Language.](http://arxiv.org/abs/2212.07525) | 本文提出了一种上下文化目标表示自监督学习的高效性改进方法，称为data2vec 2.0，它在多项任务中取得了和其他算法相当的准确率，但需要的预训练时间较短。 |
| [^62] | [Inconsistency Ranking-based Noisy Label Detection for High-quality Data.](http://arxiv.org/abs/2212.00239) | 本文提出了一种基于不一致性排名的自动无噪声标签检测技术，将其用于自动语音识别（ASV）任务作为概念验证。实验结果表明，该解决方案可以提高大规模说话人识别数据集的高效清洗能力。 |
| [^63] | [Reducing Hallucinations in Neural Machine Translation with Feature Attribution.](http://arxiv.org/abs/2211.09878) | 本文通过特征归因方法研究了神经机器翻译中幻觉的产生原因，提出了一种新的损失函数，可以有效地降低幻觉的产生并且不需要重新训练模型。 |
| [^64] | [ATCO2 corpus: A Large-Scale Dataset for Research on Automatic Speech Recognition and Natural Language Understanding of Air Traffic Control Communications.](http://arxiv.org/abs/2211.04054) | ATCO2语料库是一个旨在促进空中交通管制通信自动语音识别和自然语言理解研究的大规模数据集，包括数据收集和预处理、语音数据的伪注释，以及提取与空中交通管制相关的命名实体。 |
| [^65] | [PromptCast: A New Prompt-based Learning Paradigm for Time Series Forecasting.](http://arxiv.org/abs/2210.08964) | 提出了一种新的时间序列预测范式——基于提示的时间序列预测（PromptCast），将数字输入和输出转化为提示，并以句子到句子的方式提出预测任务，可以直接应用于语言模型。 |
| [^66] | [MAMO: Masked Multimodal Modeling for Fine-Grained Vision-Language Representation Learning.](http://arxiv.org/abs/2210.04183) | 本文提出了一种联合掩膜多模态建模方法，以学习细粒度的多模态表示，通过隐式和显式目标来恢复联合掩膜信号以提高细化的图像-文本交互。 |
| [^67] | [Learning Dynamic Contextualised Word Embeddings via Template-based Temporal Adaptation.](http://arxiv.org/abs/2208.10734) | 本文提出一种基于时间适应的动态上下文词嵌入学习方法，使用感知时间的模板生成提示，通过微调预训练的MLM得到DCWE，实验结果表明该方法在困惑度和下游任务上优于现有方法。 |
| [^68] | [PLAtE: A Large-scale Dataset for List Page Web Extraction.](http://arxiv.org/abs/2205.12386) | 这个工作介绍了一个名为PLAtE的大规模列表页网络抽取数据集，用于从产品评论页面中提取商品列表和产品属性。数据集由52,898个项目和156,014个属性组成，是第一个大规模的列表页网络抽取数据集。 |
| [^69] | [A Taxonomy of Prompt Modifiers for Text-To-Image Generation.](http://arxiv.org/abs/2204.13988) | 本文基于为期3个月的民族学研究，确定了网络社区中使用的六种文本到图像生成提示修饰器的分类学，为研究文本到图像生成的实践提供了一个概念起点，并提供了AI生成艺术的实践者改进图像的可能性。 |
| [^70] | [Detection of sepsis during emergency department triage using machine learning.](http://arxiv.org/abs/2204.07657) | 本研究利用机器学习开发出一种检测急诊科分诊前败血症的模型，其性能优于标准败血症筛查算法。 |
| [^71] | [Focusing on Potential Named Entities During Active Label Acquisition.](http://arxiv.org/abs/2111.03837) | 本文提出了几个AL句子查询评估函数，关注潜在正面标记，并使用更好的数据驱动的正常化方法，以最小化NER注释成本。 |
| [^72] | [Self-conditioning pre-trained language models.](http://arxiv.org/abs/2110.02802) | 本文探究了预训练语言模型(TLMs)的生成机制，并提出了一种自我调节的方法，利用TLMs中自然存在的专家单元来检测输入中的概念并对生成的文本进行调节。该方法即使在没有微调或使用额外参数的情况下也是有效的，可以纠正文本生成中的性别偏差。 |
| [^73] | [WARM: A Weakly (+Semi) Supervised Model for Solving Math word Problems.](http://arxiv.org/abs/2104.06722) | 研究提出了一种弱监督模型WARM来解决用于自然语言处理中的数学题。通过仅用期望答案作为监督，该方法通过学习生成方程来解决问题，并在无需使用方程作为监督的情况下，成功实现了相比最先进的弱监督方法更高的精度提升。 |

# 详细

[^1]: 对比损失对于恢复类比关系为平行线就足够了

    Contrastive Loss is All You Need to Recover Analogies as Parallel Lines. (arXiv:2306.08221v1 [cs.CL])

    [http://arxiv.org/abs/2306.08221](http://arxiv.org/abs/2306.08221)

    本论文提出使用对比损失方法可以达到和词嵌入模型相同的类比恢复效果，且在训练时间上有大幅度的提升；并证明了对比损失能够创造出具有平行结构的词嵌入。

    

    虽然静态词嵌入模型已知将语言类比关系表示为高维空间中的平行线，但为什么它们导致这样的几何结构的基本机制仍然不明确。我们发现，在分布信息上应用基本对比样式的方法与流行的词嵌入模型在类比恢复任务上表现相当，同时在训练时间上实现了巨大的加速。此外，我们证明对比损失足以在词嵌入中创建这些平行结构，并建立起共现统计数据与所得到的词嵌入的几何结构之间的精确关系。

    While static word embedding models are known to represent linguistic analogies as parallel lines in high-dimensional space, the underlying mechanism as to why they result in such geometric structures remains obscure. We find that an elementary contrastive-style method employed over distributional information performs competitively with popular word embedding models on analogy recovery tasks, while achieving dramatic speedups in training time. Further, we demonstrate that a contrastive loss is sufficient to create these parallel structures in word embeddings, and establish a precise relationship between the co-occurrence statistics and the geometric structure of the resulting word embeddings.
    
[^2]: 自然语言处理中的表示实践

    Operationalising Representation in Natural Language Processing. (arXiv:2306.08193v1 [cs.CL])

    [http://arxiv.org/abs/2306.08193](http://arxiv.org/abs/2306.08193)

    本文介绍了一个框架，通过使用探测分类器来评估组件是否表示属性，填补了自然语言处理中关于“表示”的哲学空白。

    

    尽管“表示”在认知科学哲学中具有核心地位，但在当代自然语言处理实践中，几乎没有哲学领域的先前研究与之涉及。本文旨在填补这一空白：结合认知科学的思想，提出了一个框架来评估神经自然语言处理模型组件所作出的表示性声明，并提出三个评估组件是否表示属性的标准，并使用探测分类器来实现这些标准的操作化，探测分类器是NLP（和更广泛的深度学习）中流行的分析技术。操作化一个在哲学上受到启发的“表示”概念的项目应该引起科学哲学家和自然语言处理实践者的兴趣。对于哲学家来说，这提供了一个测试有关表示的本质的论据的新颖场地，并帮助NLPers组织有关探测实验的大量文献，提出了新的经验研究方向。

    Despite its centrality in the philosophy of cognitive science, there has been little prior philosophical work engaging with the notion of representation in contemporary NLP practice. This paper attempts to fill that lacuna: drawing on ideas from cognitive science, I introduce a framework for evaluating the representational claims made about components of neural NLP models, proposing three criteria with which to evaluate whether a component of a model represents a property and operationalising these criteria using probing classifiers, a popular analysis technique in NLP (and deep learning more broadly).  The project of operationalising a philosophically-informed notion of representation should be of interest to both philosophers of science and NLP practitioners. It affords philosophers a novel testing-ground for claims about the nature of representation, and helps NLPers organise the large literature on probing experiments, suggesting novel avenues for empirical research.
    
[^3]: GPT-3在LIAR数据集中检测虚假政治陈述的效果评估：一项案例研究

    Assessing the Effectiveness of GPT-3 in Detecting False Political Statements: A Case Study on the LIAR Dataset. (arXiv:2306.08190v1 [cs.CL])

    [http://arxiv.org/abs/2306.08190](http://arxiv.org/abs/2306.08190)

    本文评估了GPT-3模型在LIAR数据集上检测虚假政治陈述的效果，并证明其准确性高于其他最先进的模型，且使用零样本学习可接近最先进的性能。

    

    检测政治虚假陈述对于维护信息完整性和防止信息误传在社会中至关重要。历史上，最先进的机器学习模型采用了各种方法来检测欺骗性陈述，包括使用元数据、n-gram分析以及语言学和风格学特征。最近，基于大型语言模型的最新进展，比如GPT-3，已经在广泛的任务上实现了最先进的性能。在本研究中，我们在LIAR数据集上使用GPT-3进行了实验，并获得了比最先进模型更高的准确率，而不使用任何附加的元数据或语言学特征。此外，我们使用一个精心设计的提示进行了零样本学习，并实现了接近最先进的性能。这种方法的一个优点是模型提供了一个解释报告，说明它是如何得出预测的。

    The detection of political fake statements is crucial for maintaining information integrity and preventing the spread of misinformation in society. Historically, state-of-the-art machine learning models employed various methods for detecting deceptive statements. These methods include the use of metadata (W. Wang et al., 2018), n-grams analysis (Singh et al., 2021), and linguistic (Wu et al., 2022) and stylometric (Islam et al., 2020) features. Recent advancements in large language models, such as GPT-3 (Brown et al., 2020) have achieved state-of-the-art performance on a wide range of tasks. In this study, we conducted experiments with GPT-3 on the LIAR dataset (W. Wang et al., 2018) and achieved higher accuracy than state-of-the-art models without using any additional meta or linguistic features. Additionally, we experimented with zero-shot learning using a carefully designed prompt and achieved near state-of-the-art performance. An advantage of this approach is that the model provide
    
[^4]: 语言模型不是否定者：对否定基准测试中语言模型的分析。

    Language models are not naysayers: An analysis of language models on negation benchmarks. (arXiv:2306.08189v1 [cs.CL])

    [http://arxiv.org/abs/2306.08189](http://arxiv.org/abs/2306.08189)

    本研究系统评估了当前一代自回归语言模型（LLMs）处理否定的能力，发现LLMs存在无法捕捉否定词汇语义、不能推理的问题等限制。

    

    否定已被证明是被掩蔽语言模型（如BERT）的主要瓶颈。然而，目前并没有全面研究大型自回归语言模型（“LLMs”）是否仍然存在这一发现。随着研究和应用LLMs体积的日益增长，我们退后一步，评估当前一代LLMs处理否定的能力，而这是对于语言理解至关重要的基本语言现象。我们评估不同的LLMs-包括开源的GPT-NEO、GPT-3和InstructGPT-对一系列否定基准测试进行评估。通过对模型大小和提示进行系统实验，我们发现LLMs存在几个限制，包括对否定存在的不敏感性、无法捕捉否定的词汇语义以及无法在否定情况下进行推理。

    Negation has been shown to be a major bottleneck for masked language models, such as BERT. However, whether this finding still holds for larger-sized auto-regressive language models (``LLMs'') has not been studied comprehensively. With the ever-increasing volume of research and applications of LLMs, we take a step back to evaluate the ability of current-generation LLMs to handle negation, a fundamental linguistic phenomenon that is central to language understanding. We evaluate different LLMs -- including the open-source GPT-neo, GPT-3, and InstructGPT -- against a wide range of negation benchmarks. Through systematic experimentation with varying model sizes and prompts, we show that LLMs have several limitations including insensitivity to the presence of negation, an inability to capture the lexical semantics of negation, and a failure to reason under negation.
    
[^5]: INT2.1：通过低秩自适应纠错实现精细可调的量化大语言模型

    INT2.1: Towards Fine-Tunable Quantized Large Language Models with Error Correction through Low-Rank Adaptation. (arXiv:2306.08162v1 [cs.CL])

    [http://arxiv.org/abs/2306.08162](http://arxiv.org/abs/2306.08162)

    该论文提出了一种通过低秩自适应纠错的方法，从而可以显著地减少精细调整VRAM需求，并纠正量化大语言模型中的量化误差，使消费者笔记本电脑可以对70亿个参数的大语言模型进行精细调整，生成连贯的英文文本。

    

    我们提出了一种方法，可以显著地减少精细调整VRAM需求，并纠正量化大语言模型中的量化误差。首先，我们使用低秩自适应（LoRA）开发了一种极其内存高效的量化模型精细调整方法（EMEF），并根据它构建了一个错误修正算法，旨在最小化量化过程中引起的误差。我们的方法可以将内存要求降低多达5.6倍，从而使消费者笔记本电脑可以对70亿个参数的大语言模型进行精细调整。同时，我们提出了一种低秩纠错（LREC）方法，利用增加的LoRA层来改善量化模型与其浮点数对应物之间的差距。我们的纠错框架可以生成连贯的英文文本，实现了完全功能的INT2量化大语言模型。据我们所知，这是第一个能够达到这种性能的INT2大语言模型。

    We introduce a method that dramatically reduces fine-tuning VRAM requirements and rectifies quantization errors in quantized Large Language Models. First, we develop an extremely memory-efficient fine-tuning (EMEF) method for quantized models using Low-Rank Adaptation (LoRA), and drawing upon it, we construct an error-correcting algorithm designed to minimize errors induced by the quantization process. Our method reduces the memory requirements by up to 5.6 times, which enables fine-tuning a 7 billion parameter Large Language Model (LLM) on consumer laptops. At the same time, we propose a Low-Rank Error Correction (LREC) method that exploits the added LoRA layers to ameliorate the gap between the quantized model and its float point counterpart. Our error correction framework leads to a fully functional INT2 quantized LLM with the capacity to generate coherent English text. To the best of our knowledge, this is the first INT2 Large Language Model that has been able to reach such a perfo
    
[^6]: h2oGPT：民主化大语言模型

    h2oGPT: Democratizing Large Language Models. (arXiv:2306.08161v1 [cs.CL])

    [http://arxiv.org/abs/2306.08161](http://arxiv.org/abs/2306.08161)

    本文介绍了h2oGPT，这是一套开源代码库，用于创建和使用基于GPTs的大语言模型（LLMs），包括100％私有文档搜索。目标是创建真正开源的替代封闭源GPTs，提高人工智能的开发和可靠性。

    

    基于生成预训练变压器（GPTs），大语言模型（LLMs）如GPT-4因其在自然语言处理方面的现实应用而成为人工智能革命的一部分。然而，它们也带来了许多重大的风险，如存在有偏见、私人或有害文本和未经授权的版权材料。本文介绍了h2oGPT，这是一套开源代码库，用于创建和使用基于GPTs的大语言模型（LLMs）。该项目的目标是创建世界上最好的真正开源的替代封闭源GPTs。与开源社区合作，作为其一部分，我们开源了几个LLM，其参数从7亿到400亿，可在完全自由的Apache 2.0许可下商用。我们的发布包括使用自然语言的100％私有文档搜索。开源语言模型有助于促进人工智能的发展并使其更加可靠。

    Foundation Large Language Models (LLMs) such as GPT-4 represent a revolution in AI due to their real-world applications though natural language processing. However, they also pose many significant risks such as the presence of biased, private, or harmful text, and the unauthorized inclusion of copyrighted material.  We introduce h2oGPT, a suite of open-source code repositories for the creation and use of Large Language Models (LLMs) based on Generative Pretrained Transformers (GPTs). The goal of this project is to create the world's best truly open-source alternative to closed-source GPTs. In collaboration with and as part of the incredible and unstoppable open-source community, we open-source several fine-tuned h2oGPT models from 7 to 40 Billion parameters, ready for commercial use under fully permissive Apache 2.0 licenses. Included in our release is 100% private document search using natural language.  Open-source language models help boost AI development and make it more accessible
    
[^7]: 自然语言处理中社会人口统计偏见的调查

    Survey on Sociodemographic Bias in Natural Language Processing. (arXiv:2306.08158v1 [cs.CL])

    [http://arxiv.org/abs/2306.08158](http://arxiv.org/abs/2306.08158)

    本文调查了209篇关于NLP模型偏见的论文，其中大部分涉及社会人口统计偏见。研究者提出了社会人口统计偏见的定义，并确定了NLP偏见研究的三个主要类别。当前去偏见技术只是隐藏了偏见而不是真正去除它，需要进一步改进。

    

    深度神经网络在训练过程中往往会学习到非预期的偏见，这在实际应用中可能会产生有害的影响。本文对209篇关于NLP模型中偏见的论文进行了调查，其中大部分论文涉及社会人口统计偏见。为了更好地理解偏见与真实世界的危害之间的区别，我们借鉴心理学和行为经济学的思想，提出了社会人口统计偏见的定义。我们确定了NLP偏见研究的三个主要类别：偏见类型、量化偏见和去偏见。我们认为当前对于量化偏见的方法存在可靠性问题，许多偏见度量并不涉及真实世界中的偏见，当前的去偏见技术是表面的，只是隐藏了偏见，而不是真正去除它。最后，我们提供了未来工作的建议。

    Deep neural networks often learn unintended biases during training, which might have harmful effects when deployed in real-world settings. This paper surveys 209 papers on bias in NLP models, most of which address sociodemographic bias. To better understand the distinction between bias and real-world harm, we turn to ideas from psychology and behavioral economics to propose a definition for sociodemographic bias. We identify three main categories of NLP bias research: types of bias, quantifying bias, and debiasing. We conclude that current approaches on quantifying bias face reliability issues, that many of the bias metrics do not relate to real-world biases, and that current debiasing techniques are superficial and hide bias rather than removing it. Finally, we provide recommendations for future work.
    
[^8]: 基于大规模语言模型的长形式数据重新评分研究

    Large-scale Language Model Rescoring on Long-form Data. (arXiv:2306.08133v1 [eess.AS])

    [http://arxiv.org/abs/2306.08133](http://arxiv.org/abs/2306.08133)

    本文研究了大规模语言模型对长视频ASR的影响，证明与最大熵基线相比，使用LLM能够最多减少8％的Word Error Rate和30％的Salient Term Error Rate。经过改进的格处理和携带上下文的组合可以获得更好的效果。

    

    本文研究了大规模语言模型（LLM）对YouTube视频的自动语音识别（ASR）的影响，这些视频被用作长形式ASR的源。我们证明在美国英语（en-us）和印度英语（en-in）长形式ASR测试集上，相对于基于最大熵的语言模型强一次通过基线，我们实现了高达8％的相对Word Error Rate（WER）降低和高达30％的相对Salient Term Error Rate（STER）降低。经过改进的格处理导致带有正确（非树形）有向图拓扑和携带前一段最佳假设的上下文的格的显着获胜。我们还发现，基于大量可用数据（如C4）的LLMs和传统神经LMs的组合的性能提升是累加的，并且显着优于具有最大熵LM的强一次通过基线。

    In this work, we study the impact of Large-scale Language Models (LLM) on Automated Speech Recognition (ASR) of YouTube videos, which we use as a source for long-form ASR. We demonstrate up to 8\% relative reduction in Word Error Eate (WER) on US English (en-us) and code-switched Indian English (en-in) long-form ASR test sets and a reduction of up to 30\% relative on Salient Term Error Rate (STER) over a strong first-pass baseline that uses a maximum-entropy based language model. Improved lattice processing that results in a lattice with a proper (non-tree) digraph topology and carrying context from the 1-best hypothesis of the previous segment(s) results in significant wins in rescoring with LLMs. We also find that the gains in performance from the combination of LLMs trained on vast quantities of available data (such as C4) and conventional neural LMs is additive and significantly outperforms a strong first-pass baseline with a maximum entropy LM.
    
[^9]: AVIS:利用大型语言模型的自主视觉信息检索

    AVIS: Autonomous Visual Information Seeking with Large Language Models. (arXiv:2306.08129v1 [cs.CV])

    [http://arxiv.org/abs/2306.08129](http://arxiv.org/abs/2306.08129)

    本文提出了一个基于大型语言模型的自主信息检索视觉问答框架AVIS，可以解决视觉问题所需的外部知识获取问题。

    

    本文提出了一种利用大型语言模型（LLM）实现自主信息检索的视觉问答框架AVIS。我们的方法利用LLM动态地制定利用外部工具的策略，并调查它们的输出，从而获取提供所提出问题所需的不可或缺的知识。回答需要外部知识的视觉问题，如“这幅图像所描绘的建筑物是为了纪念哪个事件？”，是一项复杂的任务。这个任务呈现出一个组合搜索空间，需要一系列行动，包括调用API、分析它们的响应并做出明智的决策。我们进行了一个用户研究，收集了人类面对这个任务时各种各样的决策实例。然后利用这些数据设计了一个由三个组件组成的系统：一个由LLM驱动的规划器，动态确定下一个要使用的工具；一个由LLM驱动的推理器，分析并提取关键信息。

    In this paper, we propose an autonomous information seeking visual question answering framework, AVIS. Our method leverages a Large Language Model (LLM) to dynamically strategize the utilization of external tools and to investigate their outputs, thereby acquiring the indispensable knowledge needed to provide answers to the posed questions. Responding to visual questions that necessitate external knowledge, such as "What event is commemorated by the building depicted in this image?", is a complex task. This task presents a combinatorial search space that demands a sequence of actions, including invoking APIs, analyzing their responses, and making informed decisions. We conduct a user study to collect a variety of instances of human decision-making when faced with this task. This data is then used to design a system comprised of three components: an LLM-powered planner that dynamically determines which tool to use next, an LLM-powered reasoner that analyzes and extracts key information 
    
[^10]: PersonaPKT：通过参数高效的知识迁移构建个性化对话代理

    PersonaPKT: Building Personalized Dialogue Agents via Parameter-efficient Knowledge Transfer. (arXiv:2306.08126v1 [cs.CL])

    [http://arxiv.org/abs/2306.08126](http://arxiv.org/abs/2306.08126)

    本文提出了PersonaPKT，一种轻量级迁移学习方法，可以在没有明确个性描述的情况下构建符合角色的对话模型，该方法通过将每个个性表示为一个连续向量，直接从同一角色产生的少量对话样本中学习隐含的个性特定特征，并能够高效构建个性化对话代理并增强隐私保护。

    

    大型预训练语言模型（PLM）驱动的个性化对话代理（DA）通常依赖于明确的角色描述来保持个性的一致性。然而，这些描述可能并不总是可用或可能存在隐私问题。为了解决这个问题，本文引入了PersonaPKT，这是一种轻量级的迁移学习方法，可以在没有明确个性描述的情况下构建符合角色的对话模型。通过将每个个性表示为一个连续向量，PersonaPKT直接从同一角色产生的少量对话样本中学习隐含的个性特定特征，并在PLM骨干上增加少于0.1％的可训练参数。实验证明，PersonaPKT可以高效地构建个性化DA，并在保持良好的响应生成质量的同时，在角色的一致性方面优于各种基线。此外，它通过避免明确的个性描述来增强隐私保护。

    Personalized dialogue agents (DAs) powered by large pre-trained language models (PLMs) often rely on explicit persona descriptions to maintain personality consistency. However, such descriptions may not always be available or may pose privacy concerns. To tackle this bottleneck, we introduce PersonaPKT, a lightweight transfer learning approach that can build persona-consistent dialogue models without explicit persona descriptions. By representing each persona as a continuous vector, PersonaPKT learns implicit persona-specific features directly from a small number of dialogue samples produced by the same persona, adding less than 0.1% trainable parameters for each persona on top of the PLM backbone. Empirical results demonstrate that PersonaPKT effectively builds personalized DAs with high storage efficiency, outperforming various baselines in terms of persona consistency while maintaining good response generation quality. In addition, it enhances privacy protection by avoiding explicit
    
[^11]: 从句子到文档层面的AI生成抄袭检测：超越黑匣子方法

    Beyond Black Box AI-Generated Plagiarism Detection: From Sentence to Document Level. (arXiv:2306.08122v1 [cs.CL])

    [http://arxiv.org/abs/2306.08122](http://arxiv.org/abs/2306.08122)

    该论文提出了一种新的自然语言处理方法，可对学术写作中的抄袭行为进行有效检测，不仅在句子级别上进行评估，还在文档级别上提供可量化指标。该方法的准确率高达94％，具有较强的适应性和可靠性，能够不断随着LLM技术的发展而不断改进。

    

    学术写作中对大型语言模型（LLMs）越来越依赖导致了抄袭现象的增加。现有的AI生成文本分类器准确性有限，往往产生误报。我们提出一种新方法，利用自然语言处理（NLP）技术，提供句子和文档级别的可量化指标，方便人类评估者进行解释。我们的方法采用多方面的方法，生成给定问题的多个释义版本，将它们输入LLM以生成答案。通过使用基于余弦相似度的对比损失函数，将生成的句子与学生回答中的句子匹配。我们的方法在分类人类和AI文本方面的准确性达到了94％，为学术环境中的抄袭检测提供了强大而适应性强的解决方案。该方法随着LLM技术的发展而不断改进，减少了新模型训练或重新配置的需求，并提供了比传统黑匣子方法更透明的评估方式。

    The increasing reliance on large language models (LLMs) in academic writing has led to a rise in plagiarism. Existing AI-generated text classifiers have limited accuracy and often produce false positives. We propose a novel approach using natural language processing (NLP) techniques, offering quantifiable metrics at both sentence and document levels for easier interpretation by human evaluators. Our method employs a multi-faceted approach, generating multiple paraphrased versions of a given question and inputting them into the LLM to generate answers. By using a contrastive loss function based on cosine similarity, we match generated sentences with those from the student's response. Our approach achieves up to 94% accuracy in classifying human and AI text, providing a robust and adaptable solution for plagiarism detection in academic settings. This method improves with LLM advancements, reducing the need for new model training or reconfiguration, and offers a more transparent way of ev
    
[^12]: CipherSniffer: 分类密码类型

    CipherSniffer: Classifying Cipher Types. (arXiv:2306.08116v1 [cs.CL])

    [http://arxiv.org/abs/2306.08116](http://arxiv.org/abs/2306.08116)

    本文将解密任务作为分类问题来解决，并创建了一个包含各种类型的密码数据集，最终评估了各种Tokenizer-Model组合在此任务中的性能。

    

    密码是加密通信的强有力工具。有很多不同的密码类型，这使得使用暴力破解来解密密码的计算费用昂贵。本文将解密任务作为分类问题来框架化。首先，我们创建了一个置换、替换、文本反转、单词反转、句子移位和未加密文本的数据集。然后，我们评估了各种Tokenizer-Model组合在此任务中的表现。

    Ciphers are a powerful tool for encrypting communication. There are many different cipher types, which makes it computationally expensive to solve a cipher using brute force. In this paper, we frame the decryption task as a classification problem. We first create a dataset of transpositions, substitutions, text reversals, word reversals, sentence shifts, and unencrypted text. Then, we evaluate the performance of various tokenizer-model combinations on this task.
    
[^13]: 巨型语言模型时代的AutoML：当前挑战，未来机遇和风险。

    AutoML in the Age of Large Language Models: Current Challenges, Future Opportunities and Risks. (arXiv:2306.08107v1 [cs.LG])

    [http://arxiv.org/abs/2306.08107](http://arxiv.org/abs/2306.08107)

    论文探讨了AutoML和LLMs之间的共生关系，并指出这两个领域的融合有望颠覆NLP和AutoML两个领域，同时也存在风险。

    

    在过去的几年中，自然语言处理（NLP）和自动化机器学习（AutoML）领域取得了显著的成果。特别是在NLP领域，巨型语言模型（LLMs）最近经历了一系列突破。我们设想，两个领域通过紧密的融合可以彼此推动极限。为了展示这一愿景，我们探索了AutoML和LLMs之间的共生关系潜力，着重探讨了它们如何互相受益。我们特别研究了从不同角度增强LLMs的AutoML方法的机会以及利用AutoML进一步改进LLMs的挑战。为此，我们调查了现有工作，并对其中的风险进行了批判性评估。我们坚信，两个领域的融合有可能颠覆NLP和AutoML两个领域。通过强调可想象的协同作用和风险，我们旨在促进在交叉点的进一步探索。

    The fields of both Natural Language Processing (NLP) and Automated Machine Learning (AutoML) have achieved remarkable results over the past years. In NLP, especially Large Language Models (LLMs) have experienced a rapid series of breakthroughs very recently. We envision that the two fields can radically push the boundaries of each other through tight integration. To showcase this vision, we explore the potential of a symbiotic relationship between AutoML and LLMs, shedding light on how they can benefit each other. In particular, we investigate both the opportunities to enhance AutoML approaches with LLMs from different perspectives and the challenges of leveraging AutoML to further improve LLMs. To this end, we survey existing work, and we critically assess risks. We strongly believe that the integration of the two fields has the potential to disrupt both fields, NLP and AutoML. By highlighting conceivable synergies, but also risks, we aim to foster further exploration at the intersect
    
[^14]: FLamE: 自然语言解释下的少样本学习

    FLamE: Few-shot Learning from Natural Language Explanations. (arXiv:2306.08042v1 [cs.CL])

    [http://arxiv.org/abs/2306.08042](http://arxiv.org/abs/2306.08042)

    FLamE是一个利用GPT-3生成自然语言解释用于RoBERTa微调的少样本学习框架，在自然语言推理任务上展现出较好的性能，但是人生成的解释大多不能充分地证明分类决策，标签特定线索在解释中起着重要作用。

    

    自然语言解释在理论上具有为模型推理提供丰富信息的潜力。然而，Lampinen等人的最新研究表明，自然语言解释在提高分类方面的效用有限。为了有效地从解释中学习，我们提出了FLamE，这是一个两阶段的少样本学习框架，首先使用GPT-3生成解释，然后使用生成的解释对较小的模型（例如RoBERTa）进行微调。自然语言推理实验表明，与强基线相比，FLamE具有很好的效果，在e-SNLI数据集上的准确性比GPT-3 Babbage提高了17.6％，比GPT-3 Davinci提高了5.7％。尽管提高了分类性能，但是人类评估出人生成的大部分解释都不能充分地证明分类决策。额外的分析表明，标签特定线索（如中立标签的“不知道”）在生成解释中发挥了重要作用。

    Natural language explanations have the potential to provide rich information that in principle guides model reasoning. Yet, recent work by Lampinen et al. (2022) has shown limited utility of natural language explanations in improving classification. To effectively learn from explanations, we present FLamE, a two-stage few-shot learning framework that first generates explanations using GPT-3, and then finetunes a smaller model (e.g., RoBERTa) with generated explanations. Our experiments on natural language inference demonstrate effectiveness over strong baselines, increasing accuracy by 17.6% over GPT-3 Babbage and 5.7% over GPT-3 Davinci in e-SNLI. Despite improving classification performance, human evaluation surprisingly reveals that the majority of generated explanations does not adequately justify classification decisions. Additional analyses point to the important role of label-specific cues (e.g., "not know" for the neutral label) in generated explanations.
    
[^15]: Curatr：历史文学文本语义分析与筛选平台。

    Curatr: A Platform for Semantic Analysis and Curation of Historical Literary Texts. (arXiv:2306.08020v1 [cs.CL])

    [http://arxiv.org/abs/2306.08020](http://arxiv.org/abs/2306.08020)

    Curatr是一个在线平台，可以基于机器学习支持的语义搜索来进行历史文学文本的筛选，提供主题词典的生成，帮助研究人员快速从大量的数字化文本中挑选出相关的子语料库。

    

    数字化历史和现代文学文本的持续增加提供了人文学科新研究的丰富可能性，然而这些集合的规模和多样性，也面临着特殊的挑战。本文介绍了Curatr，一个基于机器学习支持的语义搜索在线平台，旨在为数字人文学科学者提供文学文本的探索和筛选。该平台提供了一个文本挖掘工作流，通过将神经词嵌入与专业领域知识相结合，实现了主题词典的生成，可以让研究人员从大量的18世纪和19世纪数字化文本中筛选相关子语料库。

    The increasing availability of digital collections of historical and contemporary literature presents a wealth of possibilities for new research in the humanities. The scale and diversity of such collections however, presents particular challenges in identifying and extracting relevant content. This paper presents Curatr, an online platform for the exploration and curation of literature with machine learning-supported semantic search, designed within the context of digital humanities scholarship. The platform provides a text mining workflow that combines neural word embeddings with expert domain knowledge to enable the generation of thematic lexicons, allowing researches to curate relevant sub-corpora from a large corpus of 18th and 19th century digitised texts.
    
[^16]: Mol-Instructions: 一个大规模生物分子指令数据集，为大语言模型提供支持

    Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models. (arXiv:2306.08018v1 [q-bio.QM])

    [http://arxiv.org/abs/2306.08018](http://arxiv.org/abs/2306.08018)

    Mol-Instructions是一个专门为生物分子领域设计的综合指令数据集，可以显著提高大语言模型在生物领域中的适应能力和认知敏锐度。

    

    大语言模型（LLM）以其卓越的任务处理能力和创新的输出，在许多领域推动了重大进展。然而，它们在生物分子研究等专业领域的熟练应用还受到限制。为了解决这个挑战，我们介绍了Mol-Instructions，这是一个经过精心策划、专门针对生物分子领域设计的综合指令数据集。Mol-Instructions由三个关键组成部分组成：分子导向指令、蛋白质导向指令和生物分子文本指令，每个部分都被策划用于增强LLM对生物分子特性和行为的理解和预测能力。通过对代表性LLM的广泛指令调整实验，我们强调了Mol-Instructions在增强大模型在生物分子研究复杂领域内的适应能力和认知敏锐度方面的潜力，从而促进生物分子领域的进一步发展。

    Large Language Models (LLMs), with their remarkable task-handling capabilities and innovative outputs, have catalyzed significant advancements across a spectrum of fields. However, their proficiency within specialized domains such as biomolecular studies remains limited. To address this challenge, we introduce Mol-Instructions, a meticulously curated, comprehensive instruction dataset expressly designed for the biomolecular realm. Mol-Instructions is composed of three pivotal components: molecule-oriented instructions, protein-oriented instructions, and biomolecular text instructions, each curated to enhance the understanding and prediction capabilities of LLMs concerning biomolecular features and behaviors. Through extensive instruction tuning experiments on the representative LLM, we underscore the potency of Mol-Instructions to enhance the adaptability and cognitive acuity of large models within the complex sphere of biomolecular studies, thereby promoting advancements in the biomol
    
[^17]: 一种用于分类朗读和自发语音的新方案

    A Novel Scheme to classify Read and Spontaneous Speech. (arXiv:2306.08012v1 [cs.SD])

    [http://arxiv.org/abs/2306.08012](http://arxiv.org/abs/2306.08012)

    本文提出了一种利用DeepSpeech音频到字母识别引擎的新方案来分类朗读和自发语音。利用该方法可以非常有效地识别这两种类型的语音。

    

    COVID-19疫情导致远程电话采访的增加，因此需要区分音频记录中的朗读和自发语音。本文提出了一种新的方案来识别朗读和自发语音。我们的方法使用预训练的DeepSpeech音频到字母识别引擎从音频中生成字母序列，并从中提取特征来区分朗读和自发语音。我们的实验结果表明，即使是一小组自解释的特征也可以非常有效地分类这两种类型的语音。

    The COVID-19 pandemic has led to an increased use of remote telephonic interviews, making it important to distinguish between scripted and spontaneous speech in audio recordings. In this paper, we propose a novel scheme for identifying read and spontaneous speech. Our approach uses a pre-trained DeepSpeech audio-to-alphabet recognition engine to generate a sequence of alphabets from the audio. From these alphabets, we derive features that allow us to discriminate between read and spontaneous speech. Our experimental results show that even a small set of self-explanatory features can effectively classify the two types of speech very effectively.
    
[^18]: 利用领域预训练语言模型改进低患病率胸部病症的零样本检测

    Improving Zero-Shot Detection of Low Prevalence Chest Pathologies using Domain Pre-trained Language Models. (arXiv:2306.08000v1 [physics.med-ph])

    [http://arxiv.org/abs/2306.08000](http://arxiv.org/abs/2306.08000)

    该论文研究了如何利用领域预训练语言模型CX-BERT、BlueBERT和ClinicalBERT提高CLIP-like模型对低患病率胸部病症的零样本检测。实验结果表明，预训练的文本塔对于低患病率疾病的检测有显著的性能提升。这提示了未来可使用不同训练语言模型的集成模型进行进一步研究。

    

    零样本学习的最新进展使得可以利用成对的图像识别标签数据替代结构化标签，消除了对专家注释数据集的需求。像CLIP-based CheXzero这样的模型利用了这些在胸部X射线解释领域的进步。我们假设，使用CX-BERT、BlueBERT和ClinicalBERT等领域预训练模型，通过替换BERT权重来增加特定领域知识，有可能提高类似于CLIP的模型的性能，但代价是打破原始模型的对齐性。我们评估了具有特定领域预训练的零样本分类模型在检测低患病率病理方面的性能。尽管替换原始CLIP-BERT权重会降低模型在常见病理方面的性能，但我们发现预训练文本塔在低患病率疾病的检测中表现出色。这激发了未来使用不同训练语言模型组合的集成模型的可能性。

    Recent advances in zero-shot learning have enabled the use of paired image-text data to replace structured labels, replacing the need for expert annotated datasets. Models such as CLIP-based CheXzero utilize these advancements in the domain of chest X-ray interpretation. We hypothesize that domain pre-trained models such as CXR-BERT, BlueBERT, and ClinicalBERT offer the potential to improve the performance of CLIP-like models with specific domain knowledge by replacing BERT weights at the cost of breaking the original model's alignment. We evaluate the performance of zero-shot classification models with domain-specific pre-training for detecting low-prevalence pathologies. Even though replacing the weights of the original CLIP-BERT degrades model performance on commonly found pathologies, we show that pre-trained text towers perform exceptionally better on low-prevalence diseases. This motivates future ensemble models with a combination of differently trained language models for maxima
    
[^19]: MSSRNet: 无监督文本风格转换中的顺序风格表示操作

    MSSRNet: Manipulating Sequential Style Representation for Unsupervised Text Style Transfer. (arXiv:2306.07994v1 [cs.CL])

    [http://arxiv.org/abs/2306.07994](http://arxiv.org/abs/2306.07994)

    本文提出了一种新方法，通过为每个词汇分配单独的风格向量来对文本进行风格转换，并引入基于教师-学生学习的对抗性培训框架，以提高培训稳定性，实现了双风格转换和多风格转换两种情况下的明显提高的风格转换准确性和内容保留。

    

    无监督文本风格转移任务旨在将文本重写为目标风格，同时保留其主要内容。传统方法依赖于使用固定大小的向量来调节文本风格，这很难准确传达每个单独令牌的风格强度。事实上，文本的每个令牌都包含不同的风格强度，并对整体风格产生不同的贡献。我们提出的方法通过为文本中的每个令牌分配单独的风格向量来解决这个问题，允许对风格强度进行细粒度的控制和操作。此外，我们引入了一个基于教师-学生学习的对抗性培训框架，以增强培训稳定性并减轻高维优化的复杂性。我们实验的结果证明了我们的方法在双风格转换和多风格转换设置中，具有明显提高的风格转换准确性和内容保留的效果。

    Unsupervised text style transfer task aims to rewrite a text into target style while preserving its main content. Traditional methods rely on the use of a fixed-sized vector to regulate text style, which is difficult to accurately convey the style strength for each individual token. In fact, each token of a text contains different style intensity and makes different contribution to the overall style. Our proposed method addresses this issue by assigning individual style vector to each token in a text, allowing for fine-grained control and manipulation of the style strength. Additionally, an adversarial training framework integrated with teacher-student learning is introduced to enhance training stability and reduce the complexity of high-dimensional optimization. The results of our experiments demonstrate the efficacy of our method in terms of clearly improved style transfer accuracy and content preservation in both two-style transfer and multi-style transfer settings.
    
[^20]: 利用社交媒体属性增强关键词检测：基于IDF-LDA模型应用于新浪微博

    Utilizing Social Media Attributes for Enhanced Keyword Detection: An IDF-LDA Model Applied to Sina Weibo. (arXiv:2306.07978v1 [cs.CL])

    [http://arxiv.org/abs/2306.07978](http://arxiv.org/abs/2306.07978)

    本文提出了一种新的方法，将逆文档频率（IDF）和潜在狄利克雷分配（LDA）模型相结合，以更好地应对社交媒体数据的不同属性，通过基于点赞数、评论数和转发数等属性对每个文档的重要性进行加权，从而有效地过滤噪声并识别最相关的关键词。

    

    随着Twitter和微博等社交媒体的快速发展，从大量实时文本数据流中检测关键词已成为一个关键的问题。关键词检测问题旨在从海量文本数据中搜索重要信息以反映最重要的事件或话题。然而，社交媒体数据通常具有独特的特点：文档通常很短，语言口语化，并且数据很可能具有重要的时间模式。因此，从这些文本流中发现关键信息可能是具有挑战性的。在本文中，我们提出了一种新颖的方法来解决社交媒体中的关键词检测问题。我们的模型将逆文档频率（IDF）和潜在狄利克雷分配（LDA）模型结合起来，以更好地应对社交媒体数据的不同属性，如点赞数、评论数和转发数。通过基于这些属性对每个文档的重要性进行加权，我们的方法可以有效地过滤噪声并识别最相关的关键词。我们在中国流行的微博平台上测试了我们的模型，实验结果表明，我们的方法在精确度、召回率和F1得分方面优于基准模型。

    With the rapid development of social media such as Twitter and Weibo, detecting keywords from a huge volume of text data streams in real-time has become a critical problem. The keyword detection problem aims at searching important information from massive text data to reflect the most important events or topics. However, social media data usually has unique features: the documents are usually short, the language is colloquial, and the data is likely to have significant temporal patterns. Therefore, it could be challenging to discover critical information from these text streams. In this paper, we propose a novel method to address the keyword detection problem in social media. Our model combines the Inverse Document Frequency (IDF) and Latent Dirichlet Allocation (LDA) models to better cope with the distinct attributes of social media data, such as the number of likes, comments, and retweets. By weighting the importance of each document based on these attributes, our method can effectiv
    
[^21]: TrojPrompt：基于黑盒方式的预训练语言模型木马攻击

    TrojPrompt: A Black-box Trojan Attack on Pre-trained Language Models. (arXiv:2306.06815v1 [cs.CR] CROSS LISTED)

    [http://arxiv.org/abs/2306.06815](http://arxiv.org/abs/2306.06815)

    本文开创性地研究了基于 prompt 学习的预训练语言模型 API 的特洛伊易感性，并提出了一种自动黑盒框架——TrojPrompt，用于生成通用和隐蔽的触发器，并将特洛伊木马插入硬提示。

    

    Prompt学习被证明在提高预训练语言模型（PLM）适应性方面非常有效，超越了传统的微调范式，并在专为少样本学习场景量身定制的应用程序和API中展现了杰出的前景。但是，尽管prompt学习的API越来越受欢迎，但它们的安全问题仍未得到充分探索。本文在prompt学习的PLM API的特洛伊易感性方面进行了开创性研究。我们发现，离散提示，少样本和黑盒设置是几个关键挑战，限制了现有后门攻击的适用性。为了解决这些挑战，我们提出了TrojPrompt，这是一种自动的黑盒框架，可有效生成通用的和隐秘的触发器，并将特洛伊木马插入硬提示。具体而言，我们提出了一种API驱动的通用触发器发现算法，通过查询受害者PLM API，为各种输入生成通用触发器。

    Prompt learning has been proven to be highly effective in improving pre-trained language model (PLM) adaptability, surpassing conventional fine-tuning paradigms, and showing exceptional promise in an ever-growing landscape of applications and APIs tailored for few-shot learning scenarios. Despite the growing prominence of prompt learning-based APIs, their security concerns remain underexplored. In this paper, we undertake a pioneering study on the Trojan susceptibility of prompt-learning PLM APIs. We identified several key challenges, including discrete-prompt, few-shot, and black-box settings, which limit the applicability of existing backdoor attacks. To address these challenges, we propose TrojPrompt, an automatic and black-box framework to effectively generate universal and stealthy triggers and insert Trojans into hard prompts. Specifically, we propose a universal API-driven trigger discovery algorithm for generating universal triggers for various inputs by querying victim PLM API
    
[^22]: Mind2Web：面向Web的通用代理

    Mind2Web: Towards a Generalist Agent for the Web. (arXiv:2306.06070v1 [cs.CL])

    [http://arxiv.org/abs/2306.06070](http://arxiv.org/abs/2306.06070)

    Mind2Web是第一个用于开发和评估通用Web代理的数据集，可以按照语言指令完成任意网站上的复杂任务。此数据集提供了三个必要元素：1）多样的领域、网站和任务，2）使用真实网站而非模拟和简化网站，3）广泛的用户交互模式。研究者使用Mind2Web进行了初步探索，使用小型LM过滤可以显着提高任务完成率的效果。

    

    我们介绍了Mind2Web，这是第一个用于开发和评估通用Web代理的数据集，可以按照语言指令完成任意网站上的复杂任务。现有的Web代理数据集要么使用模拟网站，要么仅覆盖有限的网站和任务，因此不适合通用Web代理。通过收集来自31个领域、137个网站的超过2,000个开放式任务和任务的众包操作序列，Mind2Web为构建通用Web代理提供了三个必要元素：1）多样的领域、网站和任务，2）使用真实网站而非模拟和简化网站，3）广泛的用户交互模式。基于Mind2Web，我们进行了使用大型语言模型（LLMs）构建通用Web代理的初步探索。虽然现实世界网站的原始HTML往往太大而无法提供给LLMs，但我们展示了首先用小型LM过滤可以显着提高任务完成率的效果。

    We introduce Mind2Web, the first dataset for developing and evaluating generalist agents for the web that can follow language instructions to complete complex tasks on any website. Existing datasets for web agents either use simulated websites or only cover a limited set of websites and tasks, thus not suitable for generalist web agents. With over 2,000 open-ended tasks collected from 137 websites spanning 31 domains and crowdsourced action sequences for the tasks, Mind2Web provides three necessary ingredients for building generalist web agents: 1) diverse domains, websites, and tasks, 2) use of real-world websites instead of simulated and simplified ones, and 3) a broad spectrum of user interaction patterns. Based on Mind2Web, we conduct an initial exploration of using large language models (LLMs) for building generalist web agents. While the raw HTML of real-world websites are often too large to be fed to LLMs, we show that first filtering it with a small LM significantly improves th
    
[^23]: Xiezhi：一种全面更新的综合领域知识评估基准

    Xiezhi: An Ever-Updating Benchmark for Holistic Domain Knowledge Evaluation. (arXiv:2306.05783v1 [cs.CL])

    [http://arxiv.org/abs/2306.05783](http://arxiv.org/abs/2306.05783)

    Xiezhi是一种全面综合的评估套件，设有516个多项选择问题，覆盖了从13个不同学科跨越的15个专业领域，并对47个先进的LLMs进行评估，结果表明LLMs在大多数领域超越人类，但在一些领域表现不佳。

    

    随着大型语言模型（LLM）的快速发展，急需新的自然语言处理（NLP）基准来实现对齐。我们提出了Xiezhi，这是一个最全面的评估套件，旨在评估综合领域知识。Xiezhi包括跨越13个不同学科的516个多项选择问题，包括22万个问题，并且附带Xiezhi-Specialty和Xiezhi-Interdiscipline，均有15,000个问题。我们对47个先进的LLM在Xiezhi上进行了评估。结果表明，LLM在科学、工程、农学、医学和艺术方面超过了人类的平均表现，但在经济学、法学、教育学、文学、历史和管理方面则表现不佳。我们期望Xiezhi将有助于分析LLM的重要优点和不足之处，该基准已在https://github.com/MikeGu721/XiezhiBenchmark发布。

    New Natural Langauge Process~(NLP) benchmarks are urgently needed to align with the rapid development of large language models (LLMs). We present Xiezhi, the most comprehensive evaluation suite designed to assess holistic domain knowledge. Xiezhi comprises multiple-choice questions across 516 diverse disciplines ranging from 13 different subjects with 220,000 questions and accompanied by Xiezhi-Specialty and Xiezhi-Interdiscipline, both with 15k questions. We conduct evaluation of the 47 cutting-edge LLMs on Xiezhi. Results indicate that LLMs exceed average performance of humans in science, engineering, agronomy, medicine, and art, but fall short in economics, jurisprudence, pedagogy, literature, history, and management. We anticipate Xiezhi will help analyze important strengths and shortcomings of LLMs, and the benchmark is released in https://github.com/MikeGu721/XiezhiBenchmark .
    
[^24]: COVER：一种启发式贪心对抗攻击预训练语言模型中的基于提示学习

    COVER: A Heuristic Greedy Adversarial Attack on Prompt-based Learning in Language Models. (arXiv:2306.05659v1 [cs.CL])

    [http://arxiv.org/abs/2306.05659](http://arxiv.org/abs/2306.05659)

    本文提出了一种启发式贪心对抗攻击，针对基于提示的模板在PLMs中可能存在的漏洞，通过字符级和单词级的破坏方法进行攻击，取得了较高的攻击成功率。

    

    基于提示的学习已被证明是预训练语言模型（PLMs）中一种有效的方式，特别是在像少量样本场景这样的低资源情况下。然而，PLMs的可信度至关重要，并且在基于模板的提示中已经显示出了潜在的漏洞，可能会误导语言模型的预测，引起严重的安全问题。本文通过在黑盒场景中提出基于提示的对抗攻击手段，揭示了PLMs的一些漏洞。首先，我们设计了字符级别和单词级别的启发式方法来破坏手动模板。然后，我们基于上述启发式破坏方法提出了一种贪心算法进行攻击。最后，我们使用BERT系列模型的三个变种和八个数据集的分类任务评估了我们的方法。广泛的实验结果证明了我们的方法在攻击成功率方面的有效性。

    Prompt-based learning has been proved to be an effective way in pre-trained language models (PLMs), especially in low-resource scenarios like few-shot settings. However, the trustworthiness of PLMs is of paramount significance and potential vulnerabilities have been shown in prompt-based templates that could mislead the predictions of language models, causing serious security concerns. In this paper, we will shed light on some vulnerabilities of PLMs, by proposing a prompt-based adversarial attack on manual templates in black box scenarios. First of all, we design character-level and word-level heuristic approaches to break manual templates separately. Then we present a greedy algorithm for the attack based on the above heuristic destructive approaches. Finally, we evaluate our approach with the classification tasks on three variants of BERT series models and eight datasets. And comprehensive experimental results justify the effectiveness of our approach in terms of attack success rate
    
[^25]: KIT的多语言演讲翻译系统在IWSLT 2023上的应用

    KIT's Multilingual Speech Translation System for IWSLT 2023. (arXiv:2306.05320v1 [cs.CL])

    [http://arxiv.org/abs/2306.05320](http://arxiv.org/abs/2306.05320)

    本文介绍了一个为IWSLT 2023多语言翻译贡献的翻译系统，其重点在于翻译科学会议演讲。用“检索式方法”（kNN-MT）进行有效的适应，该系统采用适配器轻松集成来自数据增强的增量训练数据，并展示级联系统更容易适应特定目标领域的优势。

    

    许多现有的语音翻译基准测试都针对高品质录音条件下的以英语为母语的语音，这通常与实际使用情况中的条件不符。在本文中，我们描述了我们为IWSLT 2023多语言轨道设计的语音翻译系统，重点翻译科学会议演讲。测试条件包括口音重的输入语音和术语密集的内容，并且需要翻译成10种资源数量不同的语言。在没有来自目标领域的训练数据的情况下，我们使用了检索式方法（kNN-MT）进行有效的适应（语音翻译+0.8 BLEU）。我们还使用适配器轻松集成来自数据增强的增量训练数据，并展示其与重新训练的性能相匹配。我们观察到，级联系统更容易适应特定目标领域，因为它们是由多个独立模块组成的。我们的级联语音系统远远优于其端到端系统。

    Many existing speech translation benchmarks focus on native-English speech in high-quality recording conditions, which often do not match the conditions in real-life use-cases. In this paper, we describe our speech translation system for the multilingual track of IWSLT 2023, which focuses on the translation of scientific conference talks. The test condition features accented input speech and terminology-dense contents. The tasks requires translation into 10 languages of varying amounts of resources. In absence of training data from the target domain, we use a retrieval-based approach (kNN-MT) for effective adaptation (+0.8 BLEU for speech translation). We also use adapters to easily integrate incremental training data from data augmentation, and show that it matches the performance of re-training. We observe that cascaded systems are more easily adaptable towards specific target domains, due to their separate modules. Our cascaded speech system substantially outperforms its end-to-end 
    
[^26]: INSTRUCTEVAL：面向指导调整的大型语言模型的整体评估

    INSTRUCTEVAL: Towards Holistic Evaluation of Instruction-Tuned Large Language Models. (arXiv:2306.04757v1 [cs.CL])

    [http://arxiv.org/abs/2306.04757](http://arxiv.org/abs/2306.04757)

    INSTRUCTEVAL是一个专注于指导调整的大型语言模型评估的综合套件，它采取了全面的方法来评估模型的性能，包括解决问题、写作能力和与人类价值观的一致性等特征。

    

    指导调整的大型语言模型已经从根本上改变了自然语言处理，已经在诸如对话代理等应用中显示出了巨大的潜力。这些模型，如GPT-4，不仅能够掌握语言，而且可以解决数学、编码、医学和法律等领域的复杂任务。尽管它们具有卓越的能力，但由于许多模型的黑盒性质和缺乏全面的评估研究，对它们的全部潜力仍然缺乏全面的理解。为了解决这些挑战，我们提出了INSTRUCTEVAL，一个更全面的评估套件，专门针对指导调整的大型语言模型。与以往的作品不同，我们的评估包括对模型基于解决问题、写作能力和与人类价值观的一致性的严格评估。我们采取了全面的方法来分析影响模型性能的各种因素，包括预训练基础、指导调整数据和训练。

    Instruction-tuned large language models have revolutionized natural language processing and have shown great potential in applications such as conversational agents. These models, such as GPT-4, can not only master language but also solve complex tasks in areas like mathematics, coding, medicine, and law. Despite their impressive capabilities, there is still a lack of comprehensive understanding regarding their full potential, primarily due to the black-box nature of many models and the absence of holistic evaluation studies. To address these challenges, we present INSTRUCTEVAL, a more comprehensive evaluation suite designed specifically for instruction-tuned large language models. Unlike previous works, our evaluation involves a rigorous assessment of models based on problem-solving, writing ability, and alignment to human values. We take a holistic approach to analyze various factors affecting model performance, including the pretraining foundation, instruction-tuning data, and train
    
[^27]: Zambezi Voice: 一种赞比亚语的多语种语音语料库

    Zambezi Voice: A Multilingual Speech Corpus for Zambian Languages. (arXiv:2306.04428v1 [cs.CL])

    [http://arxiv.org/abs/2306.04428](http://arxiv.org/abs/2306.04428)

    Zambezi Voice是针对赞比亚语的多语种语音语料库，含有160小时无标签音频和80小时有标签数据，可用于语音识别和多语种语音处理研究。该数据集是为赞比亚语创造的第一个多语种语音数据集。

    

    本文介绍了 Zambezi Voice，它是一种针对赞比亚语的开源多语种语音资源。它包含两个数据集合：一组无标签的收音机新闻和谈话节目的音频录音（160小时），以及一组被标注的数据（超过80小时），其中包括从公共可得的文学书籍中源自的文本的朗读语音。该数据集被创建用于语音识别，但可以扩展到有监督和无监督学习方法的多语种语音处理研究。据我们所知，这是为赞比亚语创造的第一个多语种语音数据集。我们通过微调Wav2Vec2.0大规模多语种预训练模型来利用预训练和跨语言转移学习来构建基线模型的端到端（E2E）语音识别模型。该数据集在公共领域下发布，并可通过项目代码库进行访问。请参见 https://github.com/unza-speech-lab/zambezi-v。

    This work introduces Zambezi Voice, an open-source multilingual speech resource for Zambian languages. It contains two collections of datasets: unlabelled audio recordings of radio news and talk shows programs (160 hours) and labelled data (over 80 hours) consisting of read speech recorded from text sourced from publicly available literature books. The dataset is created for speech recognition but can be extended to multilingual speech processing research for both supervised and unsupervised learning approaches. To our knowledge, this is the first multilingual speech dataset created for Zambian languages. We exploit pretraining and cross-lingual transfer learning by finetuning the Wav2Vec2.0 large-scale multilingual pre-trained model to build end-to-end (E2E) speech recognition models for our baseline models. The dataset is released publicly under a Creative Commons BY-NC-ND 4.0 license and can be accessed through the project repository. See https://github.com/unza-speech-lab/zambezi-v
    
[^28]: 用于基于检索的对话系统的上下文掩码自编码器

    ConTextual Masked Auto-Encoder for Retrieval-based Dialogue Systems. (arXiv:2306.04357v1 [cs.CL])

    [http://arxiv.org/abs/2306.04357](http://arxiv.org/abs/2306.04357)

    本研究提出了一种针对对话响应选择的后训练技术Dial-MAE，利用生成方法更好地压缩对话语义至密集向量，并提高对话响应选择准确性。

    

    对话响应选择旨在根据给定的用户和系统话语历史记录从几个候选响应中选择适当的响应。最近的研究通过后训练大多依赖于单纯的掩码语言建模方法来提高对话响应选择的准确性。但是，最近开发的生成方法在IR社区展示了有希望的文本表示能力，这可能会导致更好的对话语义建模。因此，在本文中，我们提出 Dial-MAE（对话上下文掩码自编码器），这是一种简单而有效的针对对话响应选择的后训练技术。 Dial-MAE使用一个不对称的编码器-解码器架构，学习将对话的语义更好地压缩到密集向量中。 Dial-MAE的过程包括由深度编码器创建带有掩码对话上下文的对话嵌入，然后是浅解码器，该解码器使用此嵌入以及上下文向量来生成响应。

    Dialogue response selection aims to select an appropriate response from several candidates based on a given user and system utterance history. Recent studies have been improving the accuracy of dialogue response selection through post-training, mostly relying on naive masked language modeling methods. However, the recently developed generative methods have shown promising text representation capabilities in IR community, which could potentially lead to better dialogue semantics modeling. Thus, in this paper, we propose Dial-MAE (Dialogue Contextual Masking Auto-encoder), a straightforward yet effective post-training technique tailored for dialogue response selection. Dial-MAE uses an asymmetric encoder-decoder architecture that learns to better compress the semantics of the dialogue into dialogue-dense vectors. The process of Dial-MAE involves a deep encoder creating a dialogue embedding with the masked dialogue context, followed by a shallow decoder that uses this embedding along with
    
[^29]: MidMed：面向医疗咨询的混合类型对话系统

    MidMed: Towards Mixed-Type Dialogues for Medical Consultation. (arXiv:2306.02923v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.02923](http://arxiv.org/abs/2306.02923)

    本文提出MidMed，一个面向医疗咨询的混合类型对话系统，涵盖五种对话类型和四个部门。提出指导式的医学对话生成框架InsMed，实验结果表明在多个评估指标上实现了最先进的性能。

    

    大多数医疗对话系统假设在医学咨询之前，患者都有明确的目标（药物查询、手术查询等）。然而，在许多实际情况下，由于缺乏医学知识，患者通常很难确定所需信息并制定明确的目标。本文将这一挑战视为如何构建医学咨询对话系统以帮助患者澄清目标。为了缓解这一挑战，我们提出了一个新的任务，并创建了一个人对人的混合类型医学咨询对话语料库（MidMed），包括诊断、建议、知识引导、问答和闲聊等五种对话类型。MidMed涵盖了四个部门（耳鼻喉科、眼科、皮肤科和消化系统），共有8175段对话。此外，我们在MidMed上建立了基线，并提出了一种指导式的医学对话生成框架（InsMed）来解决这个问题。实验结果表明，我们提出的框架在多个评估指标上实现了最先进的性能。

    Most medical dialogue systems assume that patients have clear goals (medicine querying, surgical operation querying, etc.) before medical consultation. However, in many real scenarios, due to the lack of medical knowledge, it is usually difficult for patients to determine clear goals with all necessary slots. In this paper, we identify this challenge as how to construct medical consultation dialogue systems to help patients clarify their goals. To mitigate this challenge, we propose a novel task and create a human-to-human mixed-type medical consultation dialogue corpus, termed MidMed, covering five dialogue types: task-oriented dialogue for diagnosis, recommendation, knowledge-grounded dialogue, QA, and chitchat. MidMed covers four departments (otorhinolaryngology, ophthalmology, skin, and digestive system), with 8,175 dialogues. Furthermore, we build baselines on MidMed and propose an instruction-guiding medical dialogue generation framework, termed InsMed, to address this task. Expe
    
[^30]: 从部分标注数据中学习：面向语言学习的区别感知型填空练习自动生成

    Learning from Partially Annotated Data: Example-aware Creation of Gap-filling Exercises for Language Learning. (arXiv:2306.01584v1 [cs.CL])

    [http://arxiv.org/abs/2306.01584](http://arxiv.org/abs/2306.01584)

    本文提出了一种从已有的例子练习生成新的区别感知型填空练习，无需深度标注，特别针对语言学习中的语法练习；使用了一种新的神经网络模型并提供了相应的法语语法数据集，结果表明该模型在这类任务中表现优于竞争基准。

    

    做练习（包括练习测试）是学习的一个关键组成部分，创建这样的练习需要教师付出非常大的努力。在数字化教育工具中自动生成练习具有很大的价值。本文特别关注于无需深度标注材料情况下，通过示例练习自动创建语言学习中的填空练习，尤其是语法练习。我们提出了一种新的神经网络模型，专门用于Gap-filling exercise generation任务，并且提供了一个法语语法的现实基准数据集。我们通过实验证明，我们的模型比竞争基准在法语语法Gap-filling exercise generation任务上表现更好，同时只需对部分数据进行标注。

    Since performing exercises (including, e.g., practice tests) forms a crucial component of learning, and creating such exercises requires non-trivial effort from the teacher. There is a great value in automatic exercise generation in digital tools in education. In this paper, we particularly focus on automatic creation of gapfilling exercises for language learning, specifically grammar exercises. Since providing any annotation in this domain requires human expert effort, we aim to avoid it entirely and explore the task of converting existing texts into new gap-filling exercises, purely based on an example exercise, without explicit instruction or detailed annotation of the intended grammar topics. We contribute (i) a novel neural network architecture specifically designed for aforementioned gap-filling exercise generation task, and (ii) a real-world benchmark dataset for French grammar. We show that our model for this French grammar gap-filling exercise generation outperforms a competit
    
[^31]: PassGPT: 大语言模型中的密码建模和（引导式）生成

    PassGPT: Password Modeling and (Guided) Generation with Large Language Models. (arXiv:2306.01545v1 [cs.CL])

    [http://arxiv.org/abs/2306.01545](http://arxiv.org/abs/2306.01545)

    本研究使用大型语言模型PassGPT进行密码建模和生成，该模型比基于GAN的现有方法更准确，能生成符合任意限制的密码，为提高密码强度估计器提供了潜在的帮助。

    

    大语言模型（LLMs）可以成功地模拟自然语言，无需明确的监督，仅通过大量的文本进行训练。本文研究了LLMs在建模密码方面的有效性。我们介绍了PassGPT，它是一个在密码泄露数据上进行训练的LLM，用于生成密码。PassGPT通过猜测两倍于基于生成性对抗网络（GAN）的现有方法中的以前未见过的密码而胜过其它方法。此外，我们介绍了引导式密码生成的概念，利用PassGPT的抽样过程生成符合任意限制的密码，这在当前基于GAN的策略中是缺乏的。最后，我们对PassGPT对密码定义的熵和概率分布进行了深入分析，并讨论了其在增强现有密码强度估计器中的应用。

    Large language models (LLMs) successfully model natural language from vast amounts of text without the need for explicit supervision. In this paper, we investigate the efficacy of LLMs in modeling passwords. We present PassGPT, a LLM trained on password leaks for password generation. PassGPT outperforms existing methods based on generative adversarial networks (GAN) by guessing twice as many previously unseen passwords. Furthermore, we introduce the concept of guided password generation, where we leverage PassGPT sampling procedure to generate passwords matching arbitrary constraints, a feat lacking in current GAN-based strategies. Lastly, we conduct an in-depth analysis of the entropy and probability distribution that PassGPT defines over passwords and discuss their use in enhancing existing password strength estimators.
    
[^32]: 预训练的抽象模型和LLMs在法律案例判决摘要中的应用准备情况？

    How Ready are Pre-trained Abstractive Models and LLMs for Legal Case Judgement Summarization?. (arXiv:2306.01248v1 [cs.CL])

    [http://arxiv.org/abs/2306.01248](http://arxiv.org/abs/2306.01248)

    这篇论文探讨了是否可以使用预训练的抽象模型和大型语言模型来自动生成法律案例判决的摘要，并在印度的法庭案例判决中进行了相关实验分析。

    

    自动摘要法律案例判决一直是采用抽取式摘要方法尝试解决的问题。然而，近年来，具有生成更自然和连贯摘要能力的抽象摘要模型受到越来越多的关注。现在已经有了专门用于法律领域的预训练抽象摘要模型。此外，众所周知，如ChatGPT这样的通用领域预训练大型语言模型(LLMs)能够生成高质量的文本，并具有文本摘要的能力。因此，值得问的是，这些模型是否已准备好用于自动生成案例判决的抽象摘要。为了探讨这个问题，我们将几种最先进的领域特定的抽象性摘要模型和通用领域的LLMs应用于印度法庭案例判决中，并检查所生成摘要的质量。除了摘要质量的标准度量，我们还检查了生成的摘要中可能存在的不一致性和虚构现象。

    Automatic summarization of legal case judgements has traditionally been attempted by using extractive summarization methods. However, in recent years, abstractive summarization models are gaining popularity since they can generate more natural and coherent summaries. Legal domain-specific pre-trained abstractive summarization models are now available. Moreover, general-domain pre-trained Large Language Models (LLMs), such as ChatGPT, are known to generate high-quality text and have the capacity for text summarization. Hence it is natural to ask if these models are ready for off-the-shelf application to automatically generate abstractive summaries for case judgements. To explore this question, we apply several state-of-the-art domain-specific abstractive summarization models and general-domain LLMs on Indian court case judgements, and check the quality of the generated summaries. In addition to standard metrics for summary quality, we check for inconsistencies and hallucinations in the 
    
[^33]: 重新审视仇恨言论基准：从数据筛选到系统应用

    Revisiting Hate Speech Benchmarks: From Data Curation to System Deployment. (arXiv:2306.01105v1 [cs.CL])

    [http://arxiv.org/abs/2306.01105](http://arxiv.org/abs/2306.01105)

    该论文介绍了GOTHate数据集，并详细比较了该数据集与现有的仇恨言论数据集，研究了模型如何捕捉中立的恶意内容中的仇恨信号。研究发现，GOTHate很难在纯文本环境下进行分类，并介绍了如何通过添加内生信号来提高模型性能。

    

    社交媒体上充斥着充满仇恨的内容，其中很多经常伴随着语言和主题的多样性。用于仇恨言论检测的基准数据集没有考虑到这种背离，因为它们主要是使用仇恨词汇编制的。然而，在中立的恶意内容中捕捉仇恨信号变得具有挑战性。因此，设计模拟仇恨现实世界变异性的模型和数据集需要进一步研究。为此，我们提出了GOTHate，这是一个综合了不同语言和主题的大规模代码混合众包数据集，用于从Twitter中检测仇恨言论，包括约51k个帖子。我们详细比较了GOTHate和现有仇恨言论数据集，突出了它的新颖性，并使用10个最近的基准线对其进行了基准测试。我们的广泛实证和基准测试实验表明，在纯文本环境下，很难对GOTHate进行分类。因此，我们研究了如何添加内生信号以增强模型的性能。

    Social media is awash with hateful content, much of which is often veiled with linguistic and topical diversity. The benchmark datasets used for hate speech detection do not account for such divagation as they are predominantly compiled using hate lexicons. However, capturing hate signals becomes challenging in neutrally-seeded malicious content. Thus, designing models and datasets that mimic the real-world variability of hate warrants further investigation.  To this end, we present GOTHate, a large-scale code-mixed crowdsourced dataset of around 51k posts for hate speech detection from Twitter. GOTHate is neutrally seeded, encompassing different languages and topics. We conduct detailed comparisons of GOTHate with the existing hate speech datasets, highlighting its novelty. We benchmark it with 10 recent baselines. Our extensive empirical and benchmarking experiments suggest that GOTHate is hard to classify in a text-only setup. Thus, we investigate how adding endogenous signals enhan
    
[^34]: 与康科迪亚并行的神经符号一体化

    Parallel Neurosymbolic Integration with Concordia. (arXiv:2306.00480v1 [cs.AI])

    [http://arxiv.org/abs/2306.00480](http://arxiv.org/abs/2306.00480)

    康科迪亚框架是一个支持各种概率理论，克服了现有技术的限制的并行的神经符号结构，成功应用于集合活动检测、实体链接和推荐任务，提高了最新准确性。

    

    并行的神经符号结构通过将逻辑理论的知识提取到深度模型中，在NLP中得到有效应用。然而，现有技术仍存在一些限制，包括支持受限形式的逻辑理论，并依赖于逻辑和深度网络之间的独立性假设。本文提出了康科迪亚框架，克服了现有技术的限制。康科迪亚框架既不关注深度网络，也不关注逻辑理论，支持各种概率理论。框架可以支持两个组件的监督训练和神经组件的无监督训练。康科迪亚已成功应用于NLP和数据分类以外的任务，提高了集合活动检测、实体链接和推荐任务的最新准确性。

    Parallel neurosymbolic architectures have been applied effectively in NLP by distilling knowledge from a logic theory into a deep model.However, prior art faces several limitations including supporting restricted forms of logic theories and relying on the assumption of independence between the logic and the deep network. We present Concordia, a framework overcoming the limitations of prior art. Concordia is agnostic both to the deep network and the logic theory offering support for a wide range of probabilistic theories. Our framework can support supervised training of both components and unsupervised training of the neural component. Concordia has been successfully applied to tasks beyond NLP and data classification, improving the accuracy of state-of-the-art on collective activity detection, entity linking and recommendation tasks.
    
[^35]: 用多模态语言模型生成图片

    Generating Images with Multimodal Language Models. (arXiv:2305.17216v1 [cs.CL])

    [http://arxiv.org/abs/2305.17216](http://arxiv.org/abs/2305.17216)

    该论文提出了一种方法，将大型语言模型与预训练的图像编码器和解码器模型进行融合，能生成具有连贯性的图像输出，同时也能进行图像检索和多模态对话。

    

    我们提出了一种方法，将仅包含文本的大型语言模型（LLMs）与预训练的图像编码器和解码器模型进行融合，通过映射它们的嵌入空间。我们的模型展示了广泛的多模态能力：图像检索、新颖图像生成和多模态对话。这是第一种能够在任意交错的图像和文本输入之间进行条件调节，生成连贯图像（和文本）输出的方法。为了在图像生成任务中取得强大的性能，我们提出了一种有效的映射网络，将LLM基于现成的文本到图像生成模型，将文本的隐藏表示转换为视觉模型的嵌入空间，利用LLM强大的文本表示来生成视觉输出。我们的方法在长且复杂语言的任务上优于基准生成模型。除了新颖图像生成之外，我们的模型还能够从文本描述中检索图像，并进行多模态对话。

    We propose a method to fuse frozen text-only large language models (LLMs) with pre-trained image encoder and decoder models, by mapping between their embedding spaces. Our model demonstrates a wide suite of multimodal capabilities: image retrieval, novel image generation, and multimodal dialogue. Ours is the first approach capable of conditioning on arbitrarily interleaved image and text inputs to generate coherent image (and text) outputs. To achieve strong performance on image generation, we propose an efficient mapping network to ground the LLM to an off-the-shelf text-to-image generation model. This mapping network translates hidden representations of text into the embedding space of the visual models, enabling us to leverage the strong text representations of the LLM for visual outputs. Our approach outperforms baseline generation models on tasks with longer and more complex language. In addition to novel image generation, our model is also capable of image retrieval from a prespe
    
[^36]: 学习想象：视觉增强的自然语言生成

    Learning to Imagine: Visually-Augmented Natural Language Generation. (arXiv:2305.16944v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.16944](http://arxiv.org/abs/2305.16944)

    本研究提出了一种称为LIVE的方法，通过视觉增强学习生成自然语言的想象，并针对每个句子进行动态合成，大量实验测试表明它可以有效提高生成质量。

    

    人们往往会想象相关场景来帮助写作。本研究旨在利用视觉信息以与人类相同的方式进行创作。我们提出了一个方法LIVE，使得预训练语言模型（PLMs）能够学习通过视觉增强生成自然语言的想象 。首先，我们基于文本想象场景：我们使用扩散模型依据输入文本合成高质量的图像。其次，我们使用CLIP确定文本是否能以后验方式唤起想象。最后，我们的想象是动态的，我们会针对每个句子进行合成，而不是针对整个段落生成一张图像。在技术上，我们提出了一种新的即插即用融合层，以获取每个文本的视觉增强表示。我们的视觉-文本融合层与Transformer-based架构兼容。我们使用BART和T5进行了四个生成任务的大量实验测试，自动结果和人类评估都表明LIVE能够有效提高生成质量。

    People often imagine relevant scenes to aid in the writing process. In this work, we aim to utilize visual information for composition in the same manner as humans. We propose a method, LIVE, that makes pre-trained language models (PLMs) Learn to Imagine for Visuallyaugmented natural language gEneration. First, we imagine the scene based on the text: we use a diffusion model to synthesize high-quality images conditioned on the input texts. Second, we use CLIP to determine whether the text can evoke the imagination in a posterior way. Finally, our imagination is dynamic, and we conduct synthesis for each sentence rather than generate only one image for an entire paragraph. Technically, we propose a novel plug-and-play fusion layer to obtain visually-augmented representations for each text. Our vision-text fusion layer is compatible with Transformerbased architecture. We have conducted extensive experiments on four generation tasks using BART and T5, and the automatic results and human e
    
[^37]: GDA: 用于关系抽取任务的生成式数据增强技术

    GDA: Generative Data Augmentation Techniques for Relation Extraction Tasks. (arXiv:2305.16663v1 [cs.CL])

    [http://arxiv.org/abs/2305.16663](http://arxiv.org/abs/2305.16663)

    GDA是一个专门用于关系文本增强的技术，通过采用两个互补模块，保持语义和语法结构的一致性，并使用实体提示扩展上下文。实验结果表明GDA超越了现有增强技术，实现了最先进的性能。

    

    在给定足够的训练标注时，关系抽取任务可以在句子中提取出两个实体之间的关系，表现出良好的性能。然而在实践中获得这种标注是费力的。现有的方法采用数据增强技术，在限制的标注范围之外生成伪标注句子。当采用基于规则的增强时，这些技术无法保持原始句子的语义一致性，并且在使用seq2seq模型表达关系时无法保持句子的语法结构， resulting in less diverse augmentations 。本文提出一个专门针对关系文本的增强技术，称为GDA，它使用两个互补模块来保持语义一致性和语法结构。我们采用生成式公式，并设计一个多任务解决方案以实现协同效应。此外，GDA采用实体提示作为生成模型的先验知识，将实体的上下文扩展到句子中。实验结果表明，GDA在两个公共数据集NYT10和SemEval2010 Task 8上实现了最先进的性能，并超越了现有的数据增强技术。

    Relation extraction (RE) tasks show promising performance in extracting relations from two entities mentioned in sentences, given sufficient annotations available during training. Such annotations would be labor-intensive to obtain in practice. Existing work adopts data augmentation techniques to generate pseudo-annotated sentences beyond limited annotations. These techniques neither preserve the semantic consistency of the original sentences when rule-based augmentations are adopted, nor preserve the syntax structure of sentences when expressing relations using seq2seq models, resulting in less diverse augmentations. In this work, we propose a dedicated augmentation technique for relational texts, named GDA, which uses two complementary modules to preserve both semantic consistency and syntax structures. We adopt a generative formulation and design a multi-tasking solution to achieve synergies. Furthermore, GDA adopts entity hints as the prior knowledge of the generative model to augm
    
[^38]: 缩放数据受限的语言模型

    Scaling Data-Constrained Language Models. (arXiv:2305.16264v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.16264](http://arxiv.org/abs/2305.16264)

    研究人员研究了在数据受限制的情况下缩放语言模型，并提出了一个计算最优性的缩放定律，考虑到重复令牌和过量参数的价值递减。

    

    现在扩展语言模型的趋势涉及增加参数计数和训练数据集大小。推断这个趋势表明，训练数据集大小可能很快就会受到互联网上可用文本数据的限制。出于此限制的动机，我们研究在数据受限制的情况下缩放语言模型。具体而言，我们运行了大量的实验，变化数据重复程度和计算预算，范围达到了9000亿个训练令牌和9亿参数模型。我们发现，在有限的数据的情况下，使用高达4次重复数据的训练与使用唯一数据相比对损失的贡献微不足道。然而，使用更多的重复数据，添加计算的价值最终会衰减为零。我们提出并经验证了一个计算最优性的缩放定律，考虑到重复令牌和过量参数的价值递减。最后，我们尝试了缓解数据稀缺的方法。

    The current trend of scaling language models involves increasing both parameter count and training dataset size. Extrapolating this trend suggests that training dataset size may soon be limited by the amount of text data available on the internet. Motivated by this limit, we investigate scaling language models in data-constrained regimes. Specifically, we run a large set of experiments varying the extent of data repetition and compute budget, ranging up to 900 billion training tokens and 9 billion parameter models. We find that with constrained data for a fixed compute budget, training with up to 4 epochs of repeated data yields negligible changes to loss compared to having unique data. However, with more repetition, the value of adding compute eventually decays to zero. We propose and empirically validate a scaling law for compute optimality that accounts for the decreasing value of repeated tokens and excess parameters. Finally, we experiment with approaches mitigating data scarcity,
    
[^39]: Bhasha-Abhijnaanam：22种印度文字和罗马拼音语言鉴别。 (arXiv：2305.15814v1 [cs.CL])

    Bhasha-Abhijnaanam: Native-script and romanized Language Identification for 22 Indic languages. (arXiv:2305.15814v1 [cs.CL])

    [http://arxiv.org/abs/2305.15814](http://arxiv.org/abs/2305.15814)

    该研究提供了22种印度宪法中列出的所有21种本土文字和罗马字母的公开语言鉴别（LID）数据和模型。IndicLID是上述语言的本土和罗马化脚本的语言鉴别器，还提出了解决罗马化文本的LID问题的方案。

    

    我们提供了22个印度宪法中列出的所有21种本土文字和罗马字母的公开语言鉴别（LID）数据和模型。与现有的LID相比，我们的Bhasha-Abhijnaanam在本土文字文本的语言涵盖范围方面更为广泛，并具有竞争力或更好的性能，IndicLID是上述语言的本土和罗马化脚本的语言鉴别器。对于罗马化文本的LID，存在两个主要挑战：缺乏训练数据和当语言相似时，低LID性能。我们提供了简单有效的解决方案。总的来说，在任何语言中，罗马化文本的研究都很有限，我们的研究结果对需要罗马化语言鉴别的其他语言也具有参考意义。

    We create publicly available language identification (LID) datasets and models in all 22 Indian languages listed in the Indian constitution in both native-script and romanized text. First, we create Bhasha-Abhijnaanam, a language identification test set for native-script as well as romanized text which spans all 22 Indic languages. We also train IndicLID, a language identifier for all the above-mentioned languages in both native and romanized script. For native-script text, it has better language coverage than existing LIDs and is competitive or better than other LIDs. IndicLID is the first LID for romanized text in Indian languages. Two major challenges for romanized text LID are the lack of training data and low-LID performance when languages are similar. We provide simple and effective solutions to these problems. In general, there has been limited work on romanized text in any language, and our findings are relevant to other languages that need romanized language identification. Ou
    
[^40]: 自然语言处理中的扩散模型综述

    Diffusion Models in NLP: A Survey. (arXiv:2305.14671v1 [cs.CL])

    [http://arxiv.org/abs/2305.14671](http://arxiv.org/abs/2305.14671)

    本文全面综述了扩散模型在NLP中的各种应用，比较了其与自回归模型的优劣，指出扩散模型在并行生成、文本插值、词级别控制等方面具有明显优势。

    

    本综述论文全面回顾了扩散模型在自然语言处理(NLP)中的应用。扩散模型是一类数学模型，旨在捕捉信息或信号在网络或流形上的扩散。在NLP中，扩散模型已被用于各种应用，如自然语言生成、情感分析、主题建模和机器翻译。本文讨论了NLP中使用的不同扩散模型的公式、优劣点和应用。同时，我们还对扩散模型与其他生成模型进行了全面比较，特别是自回归(AR)模型，还研究了如何将Transformer与扩散模型结合以实现多样化的架构。相比AR模型，扩散模型在并行生成、文本插值、词级别控制(如句法结构)等方面具有明显的优势。

    This survey paper provides a comprehensive review of the use of diffusion models in natural language processing (NLP). Diffusion models are a class of mathematical models that aim to capture the diffusion of information or signals across a network or manifold. In NLP, diffusion models have been used in a variety of applications, such as natural language generation, sentiment analysis, topic modeling, and machine translation. This paper discusses the different formulations of diffusion models used in NLP, their strengths and limitations, and their applications. We also perform a thorough comparison between diffusion models and alternative generative models, specifically highlighting the autoregressive (AR) models, while also examining how diverse architectures incorporate the Transformer in conjunction with diffusion models. Compared to AR models, diffusion models have significant advantages for parallel generation, text interpolation, token-level controls such as syntactic structures a
    
[^41]: WebIE：基于网络的信息提取的准确性和鲁棒性

    WebIE: Faithful and Robust Information Extraction on the Web. (arXiv:2305.14293v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.14293](http://arxiv.org/abs/2305.14293)

    WebIE提出了一个大规模的、实体关联闭合的IE数据集，以更好地反映网络数据，并评估了生成式IE模型的性能，表现出良好的结果。

    

    从原始文本中提取结构化和有实际意义的三元组是信息提取（IE）中的一项基本任务。现有的IE数据集通常是从维基百科文章中收集的，使用超链接将实体与Wikidata知识库链接起来。然而，仅在维基百科上训练的模型在应用于网页领域时存在局限性，因为这些领域经常包含嘈杂或没有任何实际信息的文本。本文提出WebIE，这是第一个大规模的、实体关联闭合的IE数据集，包含从英语Common Crawl语料库中自动收集的160万个句子。WebIE还包括负例，即没有事实三元组的句子，以更好地反映网络数据。我们通过众包对WebIE进行了大约21000个三元组的注释，并介绍了mWebIE，这是注释集在法语、西班牙语、葡萄牙语和印地语中的翻译。我们评估了生成式IE模型在域内、域外和零样本跨语言性能，并发现模型在WebIE数据集上表现出良好

    Extracting structured and grounded fact triples from raw text is a fundamental task in Information Extraction (IE). Existing IE datasets are typically collected from Wikipedia articles, using hyperlinks to link entities to the Wikidata knowledge base. However, models trained only on Wikipedia have limitations when applied to web domains, which often contain noisy text or text that does not have any factual information. We present WebIE, the first large-scale, entity-linked closed IE dataset consisting of 1.6M sentences automatically collected from the English Common Crawl corpus. WebIE also includes negative examples, i.e. sentences without fact triples, to better reflect the data on the web. We annotate ~21K triples from WebIE through crowdsourcing and introduce mWebIE, a translation of the annotated set in four other languages: French, Spanish, Portuguese, and Hindi. We evaluate the in-domain, out-of-domain, and zero-shot cross-lingual performance of generative IE models and find mod
    
[^42]: LLM-Pruner: 关于大型语言模型结构修剪的研究

    LLM-Pruner: On the Structural Pruning of Large Language Models. (arXiv:2305.11627v1 [cs.CL])

    [http://arxiv.org/abs/2305.11627](http://arxiv.org/abs/2305.11627)

    本文提出了一种方法，名为LLM-Pruner，采用结构修剪的方式在保留大多数功能的同时，压缩LLM的结构，以减少LLM在部署、推理和训练阶段中的大小和复杂度。

    

    大型语言模型(LLMs)展示出在语言理解和生成方面令人惊讶的能力。然而，这种能力通常伴随着巨大的模型大小，这在部署、推理和训练阶段都存在显著挑战。我们以任务无关的方式探索了LLM的压缩方法，旨在保留原始LLM的多任务解决和语言生成能力。我们的方法采用结构修剪，在梯度信息的支持下选择性地移除非关键的耦合结构，最大限度地保留了大多数LLM的功能。

    Large language models (LLMs) have shown remarkable capabilities in language understanding and generation. However, such impressive capability typically comes with a substantial model size, which presents significant challenges in both the deployment, inference, and training stages. With LLM being a general-purpose task solver, we explore its compression in a task-agnostic manner, which aims to preserve the multi-task solving and language generation ability of the original LLM. One challenge to achieving this is the enormous size of the training corpus of LLM, which makes both data transfer and model post-training over-burdensome. Thus, we tackle the compression of LLMs within the bound of two constraints: being task-agnostic and minimizing the reliance on the original training dataset. Our method, named LLM-Pruner, adopts structural pruning that selectively removes non-critical coupled structures based on gradient information, maximally preserving the majority of the LLM's functionalit
    
[^43]: 通过可编辑的逐步解释实现交互式文本转SQL

    Interactive Text-to-SQL Generation via Editable Step-by-Step Explanations. (arXiv:2305.07372v1 [cs.DB])

    [http://arxiv.org/abs/2305.07372](http://arxiv.org/abs/2305.07372)

    本文介绍一种交互机制，允许用户直接编辑一步步解释错误SQL以修复SQL错误，实验证明方法提高了31.6％的执行准确性。用户研究表明，该方法帮助用户以更少的时间和更高的信心解决了更多的SQL任务。

    

    关系数据库在大数据时代扮演着重要角色。然而，非专家很难完全释放关系数据库的分析能力，因为他们不熟悉SQL等数据库语言。许多技术已被提出自然语言自动生成SQL，但它们存在以下两个问题：（1）对于复杂查询它们仍会犯很多错误，（2）它们不提供一种灵活的方式，让非专家用户验证和改进不正确的查询。为了解决这些问题，我们引入了一种新的交互机制，允许用户直接编辑一步步解释错误SQL以修复SQL错误。在Spider基准测试上的实验证明，我们的方法至少比三种最先进方法在执行准确性方面提高了31.6％。24名参与者的用户研究进一步表明，我们的方法帮助用户以更少的时间和更高的信心解决了更多的SQL任务。

    Relational databases play an important role in this Big Data era. However, it is challenging for non-experts to fully unleash the analytical power of relational databases, since they are not familiar with database languages such as SQL. Many techniques have been proposed to automatically generate SQL from natural language, but they suffer from two issues: (1) they still make many mistakes, particularly for complex queries, and (2) they do not provide a flexible way for non-expert users to validate and refine the incorrect queries. To address these issues, we introduce a new interaction mechanism that allows users directly edit a step-by-step explanation of an incorrect SQL to fix SQL errors. Experiments on the Spider benchmark show that our approach outperforms three SOTA approaches by at least 31.6% in terms of execution accuracy. A user study with 24 participants further shows that our approach helped users solve significantly more SQL tasks with less time and higher confidence, demo
    
[^44]: LMs固守阵地：探究具身化对语言模型理解比喻性语言的影响

    LMs stand their Ground: Investigating the Effect of Embodiment in Figurative Language Interpretation by Language Models. (arXiv:2305.03445v1 [cs.CL])

    [http://arxiv.org/abs/2305.03445](http://arxiv.org/abs/2305.03445)

    本文研究调查了具身化策略对语言模型解释比喻性语言的影响。结果表明，更大的模型在处理行为更具体化的隐喻性句子时表现更佳。

    

    比喻语言是语言模型的挑战，因为其解释基于单词的使用方式偏离了它们的常规顺序和含义。然而，人类可以轻松理解和诠释隐喻、比喻或习语，因为它们可以从具身隐喻中推导出来。语言是具身化的代理，如果隐喻是传统的和词汇化的，那么一个没有身体的系统就更容易理解具身概念。本文研究表明，在比喻性句子的行动更具体化时，更大的语言模型在解释隐喻句子时表现更好，并排除了与其他特征（例如单词长度或具体性）的多重共线性。

    Figurative language is a challenge for language models since its interpretation is based on the use of words in a way that deviates from their conventional order and meaning. Yet, humans can easily understand and interpret metaphors, similes or idioms as they can be derived from embodied metaphors. Language is a proxy for embodiment and if a metaphor is conventional and lexicalised, it becomes easier for a system without a body to make sense of embodied concepts. Yet, the intricate relation between embodiment and features such as concreteness or age of acquisition has not been studied in the context of figurative language interpretation concerning language models. Hence, the presented study shows how larger language models perform better at interpreting metaphoric sentences when the action of the metaphorical sentence is more embodied. The analysis rules out multicollinearity with other features (e.g. word length or concreteness) and provides initial evidence that larger language model
    
[^45]: 语言、时间偏好和消费行为：大型语言模型的证据

    Language, Time Preferences, and Consumer Behavior: Evidence from Large Language Models. (arXiv:2305.02531v1 [econ.GN])

    [http://arxiv.org/abs/2305.02531](http://arxiv.org/abs/2305.02531)

    本研究分析了大型语言模型在不同语言提示下的奖励时间偏好，并发现GPT在具有较弱未来时态的语言下表现出更大的耐心，这与使用该语言的人类的偏好相似。

    

    语言对我们对时间和奖励的感知有很大的影响。这引发了一个问题，即当以不同的语言询问大型语言模型时，它们是否显示出不同的奖励时间偏好，并且它们的选择是否类似于人类的选择。本研究分析了GPT-3.5（以下简称GPT）在多种语言提示下的响应，探索了较小、较早的奖励和较大、较晚的奖励之间的偏好。我们的结果显示，当以语义含义较弱的未来时态参考（FTR），如德语和汉语，为提示语时，GPT表现出更大的耐心，相比英语和法语等具有强大FTR的语言。这些发现与现有文献一致，并表明了GPT的选择与这些语言的使用者的偏好之间的关联。然而，进一步的分析揭示了较早或较晚奖励的偏好并没有随着奖励差异系统地改变，这表明了一种词典序优先的选择。

    Language has a strong influence on our perceptions of time and rewards. This raises the question of whether large language models, when asked in different languages, show different preferences for rewards over time and if their choices are similar to those of humans. In this study, we analyze the responses of GPT-3.5 (hereafter referred to as GPT) to prompts in multiple languages, exploring preferences between smaller, sooner rewards and larger, later rewards. Our results show that GPT displays greater patience when prompted in languages with weak future tense references (FTR), such as German and Mandarin, compared to languages with strong FTR, like English and French. These findings are consistent with existing literature and suggest a correlation between GPT's choices and the preferences of speakers of these languages. However, further analysis reveals that the preference for earlier or later rewards does not systematically change with reward gaps, indicating a lexicographic preferen
    
[^46]: GPTutor: 一种由ChatGPT驱动的编程工具，用于程序代码解释

    GPTutor: a ChatGPT-powered programming tool for code explanation. (arXiv:2305.01863v1 [cs.HC])

    [http://arxiv.org/abs/2305.01863](http://arxiv.org/abs/2305.01863)

    本文介绍了一种名为GPTutor的ChatGPT动力编程工具，它是一个使用ChatGPT API的Visual Studio Code扩展，通过设计提示词，可以对所选代码进行精简、准确的解释。

    

    学习新的编程技能需要个性化指导。随着ChatGPT API等高级自然语言生成模型的出现，现在有可能创建一个方便的、个性化的AI编程教育辅导系统。本文介绍了一种名为GPTutor的ChatGPT动力编程工具，它是一个使用ChatGPT API的Visual Studio Code扩展，用于提供编程代码解释。

    Learning new programming skills requires tailored guidance. With the emergence of advanced Natural Language Generation models like the ChatGPT API, there is now a possibility of creating a convenient and personalized tutoring system with AI for computer science education. This paper presents GPTutor, a ChatGPT-powered programming tool, which is a Visual Studio Code extension using the ChatGPT API to provide programming code explanations. By integrating Visual Studio Code API, GPTutor can comprehensively analyze the provided code by referencing the relevant source codes. As a result, GPTutor can use designed prompts to explain the selected code with a pop-up message. GPTutor is now published at the Visual Studio Code Extension Marketplace, and its source code is openly accessible on GitHub. Preliminary evaluation indicates that GPTutor delivers the most concise and accurate explanations compared to vanilla ChatGPT and GitHub Copilot. Moreover, the feedback from students and teachers ind
    
[^47]: 上下文多语种用户查询拼写检查器

    Contextual Multilingual Spellchecker for User Queries. (arXiv:2305.01082v1 [cs.CL])

    [http://arxiv.org/abs/2305.01082](http://arxiv.org/abs/2305.01082)

    本文提出了一个上下文多语种用户查询拼写检查器，它非常快速、可扩展，并根据特定产品的需求调整其词汇表和拼写输出，以满足用户的需求。

    

    拼写检查是最基本和广泛使用的搜索功能之一。纠正拼写错误的用户查询不仅增强了用户体验，而且用户也期望能够实现。然而，大多数广泛可用的拼写检查解决方案要么比最新的解决方案精度低，要么速度太慢，无法用于延迟是关键要求的搜索用例。此外，大多数最新的创新架构集中在英语上，并且没有以多语言方式进行培训，并且是针对较长文本的拼写纠正进行培训，这是与对用户查询的拼写纠正不同的范式，其中上下文很少(大多数查询只有1-2个单词)。最后，由于大多数企业有独特的词汇，例如产品名称，现成的拼写解决方案无法满足用户的需求。在这项工作中，我们构建了一个多语言拼写检查器，它非常快速和可扩展，并根据特定产品的需求调整其词汇表和拼写输出。

    Spellchecking is one of the most fundamental and widely used search features. Correcting incorrectly spelled user queries not only enhances the user experience but is expected by the user. However, most widely available spellchecking solutions are either lower accuracy than state-of-the-art solutions or too slow to be used for search use cases where latency is a key requirement. Furthermore, most innovative recent architectures focus on English and are not trained in a multilingual fashion and are trained for spell correction in longer text, which is a different paradigm from spell correction for user queries, where context is sparse (most queries are 1-2 words long). Finally, since most enterprises have unique vocabularies such as product names, off-the-shelf spelling solutions fall short of users' needs. In this work, we build a multilingual spellchecker that is extremely fast and scalable and that adapts its vocabulary and hence speller output based on a specific product's needs. Fu
    
[^48]: 基于基础模型的工具学习

    Tool Learning with Foundation Models. (arXiv:2304.08354v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.08354](http://arxiv.org/abs/2304.08354)

    基于基础模型的工具学习结合了专用工具和基础模型的优势，实现了问题解决的增强精度、效率和自动化。本文对工具学习进行了系统研究，提出了涵盖两种类型学习的通用工具学习框架，并分析了它们的独特挑战、机会和未来方向。

    

    人类拥有非凡的创造和利用工具的能力，使得他们能够克服物理限制并探索新的领域。随着基础模型的出现，AI系统有望像人类一样熟练地使用工具。这种范式即基于基础模型的工具学习，结合了专用工具和基础模型的优势，实现了问题解决的增强精度、效率和自动化。尽管具有巨大潜力，但该领域仍缺乏对关键挑战、机会和未来发展的全面理解。针对这一问题，本文对工具学习进行了系统研究。首先介绍了工具学习的背景，包括其认知起源、基础模型的范式转换和工具和模型的互补作用。然后，我们回顾了现有的工具学习研究，包括基于工具和面向工具的学习。我们制定了一个涵盖两种类型学习的通用工具学习框架，并分析了它们的独特挑战、机会和未来方向。我们预计这种系统的探索将为未来开发具有复杂工具学习能力的AI系统提供一个跳板。

    Humans possess an extraordinary ability to create and utilize tools, allowing them to overcome physical limitations and explore new frontiers. With the advent of foundation models, AI systems have the potential to be equally adept in tool use as humans. This paradigm, i.e., tool learning with foundation models, combines the strengths of specialized tools and foundation models to achieve enhanced accuracy, efficiency, and automation in problem-solving. Despite its immense potential, there is still a lack of a comprehensive understanding of key challenges, opportunities, and future endeavors in this field. To this end, we present a systematic investigation of tool learning in this paper. We first introduce the background of tool learning, including its cognitive origins, the paradigm shift of foundation models, and the complementary roles of tools and models. Then we recapitulate existing tool learning research into tool-augmented and tool-oriented learning. We formulate a general tool l
    
[^49]: 中文LLaMA和Alpaca的高效有效的文本编码

    Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca. (arXiv:2304.08177v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.08177](http://arxiv.org/abs/2304.08177)

    这篇论文提出了一种方法，通过扩展LLaMA现有的词汇表，增加了20,000个中文标记，从而提高其编码效率和对汉语语义的理解能力，并在中文数据上进行二次预训练和精细调整模型，以改善LLaMA对中文的理解和生成能力。

    

    大型语言模型（LLM）已经彻底改变了自然语言处理研究，并显示出朝着人工通用智能（AGI）的有希望的进展。然而，训练和部署LLM的高成本对透明、可访问的学术研究构成了重大障碍。在这篇论文中，我们提出了一种方法，通过扩展LLaMA现有的词汇表，增加了20,000个中文标记，从而提高其编码效率和对汉语语义的理解能力，并在中文数据上进行二次预训练和精细调整模型，以便更好地理解和生成中文文本及其指令。

    Large Language Models (LLMs), such as ChatGPT and GPT-4, have dramatically transformed natural language processing research and shown promising strides towards Artificial General Intelligence (AGI). Nonetheless, the high costs associated with training and deploying LLMs present substantial obstacles to transparent, accessible academic research. While several large language models, such as LLaMA, have been open-sourced by the community, these predominantly focus on English corpora, limiting their usefulness for other languages. In this paper, we propose a method to augment LLaMA with capabilities for understanding and generating Chinese text and its ability to follow instructions. We achieve this by extending LLaMA's existing vocabulary with an additional 20,000 Chinese tokens, thereby improving its encoding efficiency and semantic understanding of Chinese. We further incorporate secondary pre-training using Chinese data and fine-tune the model with Chinese instruction datasets, signifi
    
[^50]: OpenAGI：当LLM遇到领域专家

    OpenAGI: When LLM Meets Domain Experts. (arXiv:2304.04370v1 [cs.AI])

    [http://arxiv.org/abs/2304.04370](http://arxiv.org/abs/2304.04370)

    基于大型语言模型的OpenAGI平台通过整合领域专家模型和自然语言问答形式，实现复杂任务解决。

    

    人类具有将基本技能组合成复杂技能以解决复杂任务的显著能力。这种能力对于人工智能同样重要，因此，我们断言，除了开发大型综合智能模型外，将不同领域专家模型应用于复杂任务解决能力同样关键，以在人工智能通用智能的追求中使其具备这种能力。最近的大型语言模型（LLM）的发展证明其具有出色的学习和推理能力，使它们成为选择、综合和执行外部模型以解决复杂任务的控制器的有前途的选择。在这个项目中，我们开发了一个名为OpenAGI的开源AGI研究平台，专门设计为提供复杂的多步骤任务，并配有任务特定的数据集、评估指标和各种可扩展模型。OpenAGI将复杂任务阐释为自然语言问答，旨在促进领域专家和语言模型之间的协同作用。

    Human intelligence has the remarkable ability to assemble basic skills into complex ones so as to solve complex tasks. This ability is equally important for Artificial Intelligence (AI), and thus, we assert that in addition to the development of large, comprehensive intelligent models, it is equally crucial to equip such models with the capability to harness various domain-specific expert models for complex task-solving in the pursuit of Artificial General Intelligence (AGI). Recent developments in Large Language Models (LLMs) have demonstrated remarkable learning and reasoning abilities, making them promising as a controller to select, synthesize, and execute external models to solve complex tasks. In this project, we develop OpenAGI, an open-source AGI research platform, specifically designed to offer complex, multi-step tasks and accompanied by task-specific datasets, evaluation metrics, and a diverse range of extensible models. OpenAGI formulates complex tasks as natural language q
    
[^51]: LLaMA-Adapter: 零初始化注意力下的语言模型精细调整的高效方法

    LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention. (arXiv:2303.16199v1 [cs.CV])

    [http://arxiv.org/abs/2303.16199](http://arxiv.org/abs/2303.16199)

    本文提出了一种基于适应提示和零初始化注意力机制的轻量级语言模型调整方法，可高效微调LLaMA为指令跟随模型，具有比Alpaca更短的微调时间并具有近似的响应质量。

    

    本文提出了LLaMA-Adapter这一轻量级适应方法，用于将LLaMA高效地微调为一个指令跟随模型。利用52K个自我指导示范，LLaMA-Adapter仅在冻结的LLaMA 7B模型上引入了1.2M个可学习参数，并且在8个A100 GPU上仅耗时不到一个小时进行微调。具体而言，我们采用一组可学习的适应提示，并在较高的变压器层中将它们预置于输入文本令牌之前。然后，提出了一种零初始化注意力机制和零门控机制，该机制可以自适应地将新的指令提示注入LLaMA，并有效地保留了其预先训练的知识。通过高效训练，LLaMA-Adapter能够产生高质量的响应，与完全微调的7B参数的Alpaca相似。此外，我们的方法还可以简单地扩展到多模态输入，例如图像，用于图像相关的LLaMA，在ScienceQA上实现了更强的推理能力。我们在https://github.com/ZrrSkywalker/LLaMA-Adapt发布了我们的代码。

    We present LLaMA-Adapter, a lightweight adaption method to efficiently fine-tune LLaMA into an instruction-following model. Using 52K self-instruct demonstrations, LLaMA-Adapter only introduces 1.2M learnable parameters upon the frozen LLaMA 7B model, and costs less than one hour for fine-tuning on 8 A100 GPUs. Specifically, we adopt a set of learnable adaption prompts, and prepend them to the input text tokens at higher transformer layers. Then, a zero-init attention mechanism with zero gating is proposed, which adaptively injects the new instructional cues into LLaMA, while effectively preserves its pre-trained knowledge. With efficient training, LLaMA-Adapter generates high-quality responses, comparable to Alpaca with fully fine-tuned 7B parameters. Furthermore, our approach can be simply extended to multi-modal input, e.g., images, for image-conditioned LLaMA, which achieves superior reasoning capacity on ScienceQA. We release our code at https://github.com/ZrrSkywalker/LLaMA-Adapt
    
[^52]: 使用RNN模型学习转换和对齐

    Learning Transductions and Alignments with RNN Seq2seq Models. (arXiv:2303.06841v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.06841](http://arxiv.org/abs/2303.06841)

    本文研究了RNN seq2seq模型在学习四种转换任务方面的能力，并发现其只能逼近符合训练或分布内数据的映射，不能学习底层函数；文章建立了一个新的复杂性层次结构，用于无注意力RNN seq2seq模型，而不是字符串转换的复杂性层次结构。

    

    本文研究了循环神经网络序列到序列(RNN seq2seq)模型在学习四种转换任务：恒等、反转、完全重复和二次复制。这些转换在有限状态转换器下被广泛研究，并具有逐渐增加的复杂性。我们发现，RNN seq2seq模型只能逼近符合训练或分布内数据的映射，而不能学习底层函数。尽管注意力机制使学习更加高效和鲁棒，但它并不能克服分布外的泛化限制。我们建立了一个新的复杂性层次结构来学习这四个任务的无注意力RNN seq2seq模型，它可以用正式语言的复杂性层次结构来解释，而不是字符串转换的复杂性层次结构。RNN的变种也在结果中发挥作用。特别地，我们证明简单的RNN seq2seq模型无法计算输入长度。

    The paper studies the capabilities of Recurrent-Neural-Network sequence to sequence (RNN seq2seq) models in learning four transduction tasks: identity, reversal, total reduplication, and quadratic copying. These transductions are traditionally well studied under finite state transducers and attributed with increasing complexity. We find that RNN seq2seq models are only able to approximate a mapping that fits the training or in-distribution data, instead of learning the underlying functions. Although attention makes learning more efficient and robust, it does not overcome the out-of-distribution generalization limitation. We establish a novel complexity hierarchy for learning the four tasks for attention-less RNN seq2seq models, which may be understood in terms of the complexity hierarchy of formal languages, instead of string transductions. RNN variants also play a role in the results. In particular, we show that Simple RNN seq2seq models cannot count the input length.
    
[^53]: 用人类偏好预训练语言模型

    Pretraining Language Models with Human Preferences. (arXiv:2302.08582v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.08582](http://arxiv.org/abs/2302.08582)

    本论文探索了用人类反馈替代传统互联网文本来预训练语言模型的方法，其中条件训练是最优和简单的方法，可将不良内容的生成速率降低一个数量级，同时保持语言模型在下游任务上的性能。

    

    语言模型（LMs）的预训练是为了模仿互联网文本，其中包括如果由LMs生成而违反人类偏好的内容:虚假信息，冒犯性评论，个人可识别信息，质量较低或有缺陷的代码等。在这里，我们探讨了预训练LMs的备选目标，以引导它们生成与人类偏好一致的文本。我们在三项任务中针对人类反馈对五个预训练目标进行基准测试，并研究它们如何影响预训练LMs的一致性和能力之间的权衡。我们发现在我们探索的方法中有一种帕累托最优且简单的方法：条件训练，或学习在奖励模型给出的人类偏好得分条件下的令牌分布。条件训练将不良内容的生成速率降低了一个数量级，无论是在没有提示的情况下生成还是在对抗选择的提示下生成，都如此。此外，条件训练保持了LMs的下游任务性能，表明它是预训练LMs生成与人类偏好一致的文本的可行方法。

    Language models (LMs) are pretrained to imitate internet text, including content that would violate human preferences if generated by an LM: falsehoods, offensive comments, personally identifiable information, low-quality or buggy code, and more. Here, we explore alternative objectives for pretraining LMs in a way that also guides them to generate text aligned with human preferences. We benchmark five objectives for pretraining with human feedback across three tasks and study how they affect the trade-off between alignment and capabilities of pretrained LMs. We find a Pareto-optimal and simple approach among those we explored: conditional training, or learning distribution over tokens conditional on their human preference scores given by a reward model. Conditional training reduces the rate of undesirable content by up to an order of magnitude, both when generating without a prompt and with an adversarially-chosen prompt. Moreover, conditional training maintains the downstream task per
    
[^54]: 大型语言模型可以预测人类在六个感官模态下的感知评判

    Large language models predict human sensory judgments across six modalities. (arXiv:2302.01308v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.01308](http://arxiv.org/abs/2302.01308)

    本研究表明，最先进的大型语言模型能预测人类在六个感官模态下的感知评判，并能提供从语言中提取感知信息的下限。

    

    确定从语言中可以恢复感知世界的程度是哲学和认知科学中长期存在的问题。本研究展示了，最先进的大型语言模型通过提供从语言中提取感知信息的下限，可以为解决这个问题提供新的见解。具体而言，我们从GPT模型中引出了六个心理物理数据集的成对相似度评估结果。我们发现这些评估结果在所有领域中均与人类数据显著相关，回复了众所周知的表现，如颜色环和音高螺旋。令人惊讶的是，我们发现一个在视觉和语言上共同训练的模型（GPT-4）并不一定会导致对视觉模态的特定改进。为了研究特定语言对感知的影响，我们还将这些模型应用于多语言颜色命名任务。我们发现，GPT-4在英语和俄语中复制了跨语言差异，阐明了它们之间的相互作用。

    Determining the extent to which the perceptual world can be recovered from language is a longstanding problem in philosophy and cognitive science. We show that state-of-the-art large language models can unlock new insights into this problem by providing a lower bound on the amount of perceptual information that can be extracted from language. Specifically, we elicit pairwise similarity judgments from GPT models across six psychophysical datasets. We show that the judgments are significantly correlated with human data across all domains, recovering well-known representations like the color wheel and pitch spiral. Surprisingly, we find that a model (GPT-4) co-trained on vision and language does not necessarily lead to improvements specific to the visual modality. To study the influence of specific languages on perception, we also apply the models to a multilingual color-naming task. We find that GPT-4 replicates cross-linguistic variation in English and Russian illuminating the interacti
    
[^55]: 将语言模型与图像进行联系以处理多模态信息

    Grounding Language Models to Images for Multimodal Inputs and Outputs. (arXiv:2301.13823v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.13823](http://arxiv.org/abs/2301.13823)

    该论文提出一种有效的方法，将仅处理文本的语言模型与图像进行联系，使其能够处理任意交错的图像和文本数据，并生成与检索图像交错的自由形式文本。该方法在环境相关的图像检索和多模态对话等任务中表现十分优异，是利用预训练语言模型解决视觉场景下交互问题的有效解决方案。

    

    我们提出了一种有效的方法，将预训练的仅文本语言模型与视觉领域联系起来，使其能够处理任意交错的图像和文本数据，并生成与检索图像交错的文本。我们利用从大规模文本预训练中学到的语言模型的能力，例如上下文学习和自由形式文本生成。我们保持语言模型冻结，并微调输入和输出线性层以实现跨模态交互。这使得我们的模型能够处理任意交错的图像和文本输入，并生成与检索图像交错的自由形式文本。我们在环境相关的图像检索和多模态对话等任务中取得了强大的零-shot表现，并展示了引人入胜的交互能力。我们的方法适用于任何现成的语言模型，为在视觉场景下利用预训练语言模型提供了一个有效且通用的解决方案。

    We propose an efficient method to ground pretrained text-only language models to the visual domain, enabling them to process arbitrarily interleaved image-and-text data, and generate text interleaved with retrieved images. Our method leverages the abilities of language models learnt from large scale text-only pretraining, such as in-context learning and free-form text generation. We keep the language model frozen, and finetune input and output linear layers to enable cross-modality interactions. This allows our model to process arbitrarily interleaved image-and-text inputs, and generate free-form text interleaved with retrieved images. We achieve strong zero-shot performance on grounded tasks such as contextual image retrieval and multimodal dialogue, and showcase compelling interactive abilities. Our approach works with any off-the-shelf language model and paves the way towards an effective, general solution for leveraging pretrained language models in visually grounded settings.
    
[^56]: 使用参数高效的迁移学习评估语言模型的超分布鲁棒性

    Probing Out-of-Distribution Robustness of Language Models with Parameter-Efficient Transfer Learning. (arXiv:2301.11660v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.11660](http://arxiv.org/abs/2301.11660)

    本文评估了各种参数高效的迁移学习方法对不同规模的语言模型在三个不同的意图分类任务中检测超分布（OOD）的能力，旨在为语言模型的超分布鲁棒性提供参考。

    

    随着预训练语言模型（PLM）的规模不断增加，最近提出了许多参数高效的迁移学习方法，以弥补微调成本的巨大代价。尽管大型预训练语言模型（PLMs）和各种参数高效的迁移学习（PETL）方法在各种基准测试中取得了令人印象深刻的结果，但它们是否能有效地处理已分布改变的输入仍不清楚。在本研究中，我们系统地探讨了随着PLM大小增长或改变传输方法，检测超分布（OOD）的能力如何改变。具体而言，我们评估了各种PETL技术，包括微调、Adapter、LoRA和前缀调整，在三个不同的意图分类任务上进行了评估，每个任务都使用不同规模的语言模型。

    As the size of the pre-trained language model (PLM) continues to increase, numerous parameter-efficient transfer learning methods have been proposed recently to compensate for the tremendous cost of fine-tuning. Despite the impressive results achieved by large pre-trained language models (PLMs) and various parameter-efficient transfer learning (PETL) methods on sundry benchmarks, it remains unclear if they can handle inputs that have been distributionally shifted effectively. In this study, we systematically explore how the ability to detect out-of-distribution (OOD) changes as the size of the PLM grows or the transfer methods are altered. Specifically, we evaluated various PETL techniques, including fine-tuning, Adapter, LoRA, and prefix-tuning, on three different intention classification tasks, each utilizing various language models with different scales.
    
[^57]: 提升线性探测：超越少样本学习的极限

    Prompt-Augmented Linear Probing: Scaling beyond the Limit of Few-shot In-Context Learners. (arXiv:2212.10873v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10873](http://arxiv.org/abs/2212.10873)

    本论文提出了一种混合线性探测和上下文学习的方法，结合了两者的优点，旨在提高模型在少样本和零样本情况下的性能表现。

    

    通过上下文学习，大规模语言模型可以高效地进行少样本学习，而无需进行额外的模型微调。然而，由于底层语言模型的固有输入长度限制，上下文学习的性能在可用训练样本数量上并不具有可伸缩性。与此同时，许多研究表明语言模型也是强大的特征提取器，使其能够以黑匣子的方式使用，并实现线性探测范式，即在预先提取的输入表示之上训练轻量级鉴别器。本文提出了prompt-augmented linear probing（PALP），它是线性探测和上下文学习的混合体，兼具二者的优点。PALP继承了线性探测的可伸缩性和使语言模型通过将输入定制为更易理解的形式来派生更有意义表示的能力。在各种数据集的深入调查中，我们验证了PALP在少样本和零样本情况下均胜过最先进的方法。

    Through in-context learning (ICL), large-scale language models are effective few-shot learners without additional model fine-tuning. However, the ICL performance does not scale well with the number of available training samples as it is limited by the inherent input length constraint of the underlying language model. Meanwhile, many studies have revealed that language models are also powerful feature extractors, allowing them to be utilized in a black-box manner and enabling the linear probing paradigm, where lightweight discriminators are trained on top of the pre-extracted input representations. This paper proposes prompt-augmented linear probing (PALP), a hybrid of linear probing and ICL, which leverages the best of both worlds. PALP inherits the scalability of linear probing and the capability of enforcing language models to derive more meaningful representations via tailoring input into a more conceivable form. Throughout in-depth investigations on various datasets, we verified th
    
[^58]: GPT-3是否是一个好的数据注释器？

    Is GPT-3 a Good Data Annotator?. (arXiv:2212.10450v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10450](http://arxiv.org/abs/2212.10450)

    本文通过比较和分析，评估了GPT-3作为数据注释器的性能，探讨了其作为通用NLP数据注释器的潜力。

    

    数据注释是标记用于训练机器学习模型的数据的过程。高质量的注释对于模型学习输入数据与期望输出之间的关系至关重要。由OpenAI开发的大规模语言模型GPT-3在广泛的NLP任务中展示出了令人印象深刻的零次和少次性能。因此，自然而然地想知道它是否可以用于有效地为NLP任务注释数据。在本文中，我们通过与传统数据注释方法的比较以及分析其在一系列任务上的输出，评估GPT-3作为数据注释器的性能。通过这个分析，我们旨在提供关于GPT-3作为NLP通用数据注释器潜力的洞见。

    Data annotation is the process of labeling data that could be used to train machine learning models. Having high-quality annotation is crucial, as it allows the model to learn the relationship between the input data and the desired output. GPT-3, a large-scale language model developed by OpenAI, has demonstrated impressive zero- and few-shot performance on a wide range of NLP tasks. It is therefore natural to wonder whether it can be used to effectively annotate data for NLP tasks. In this paper, we evaluate the performance of GPT-3 as a data annotator by comparing it with traditional data annotation methods and analyzing its output on a range of tasks. Through this analysis, we aim to provide insight into the potential of GPT-3 as a general-purpose data annotator in NLP.
    
[^59]: 弃石成金：MTurk中高一致性工作者对自动摘要的分析

    Needle in a Haystack: An Analysis of High-Agreement Workers on MTurk for Summarization. (arXiv:2212.10397v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10397](http://arxiv.org/abs/2212.10397)

    本研究调查了在MTurk上高一致性工作者对自动摘要的评估，通过两步筛选找到高质量的工作者，为其他具有挑战性注释任务的招募提供了最佳实践。

    

    为避免在低质量注释上浪费昂贵而低效的资源，我们需要一种方法来创建一组可靠的注释者，他们可以有效地完成困难的任务，例如评估自动摘要。因此，我们通过两步流程调查招募高质量的Amazon Mechanical Turk工作者。我们表明，我们可以在他们进行评估之前成功地过滤掉劣质的工作者，并在类似资源约束的情况下获得高度一致的注释。尽管我们的工作者彼此之间以及CloudResearch工作者之间表现出强烈的共识，但他们与专家对数据子集的判断一致性并不像预期那样，需要进一步在正确性方面进行培训。本文仍然作为在其他具有挑战性注释任务中招募合格的注释者的最佳实践。

    To prevent the costly and inefficient use of resources on low-quality annotations, we want a method for creating a pool of dependable annotators who can effectively complete difficult tasks, such as evaluating automatic summarization. Thus, we investigate the recruitment of high-quality Amazon Mechanical Turk workers via a two-step pipeline. We show that we can successfully filter out subpar workers before they carry out the evaluations and obtain high-agreement annotations with similar constraints on resources. Although our workers demonstrate a strong consensus among themselves and CloudResearch workers, their alignment with expert judgments on a subset of the data is not as expected and needs further training in correctness. This paper still serves as a best practice for the recruitment of qualified annotators in other challenging annotation tasks.
    
[^60]: 通过详细的大纲控制提升长篇故事连贯性

    DOC: Improving Long Story Coherence With Detailed Outline Control. (arXiv:2212.10077v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10077](http://arxiv.org/abs/2212.10077)

    该论文提出了一个名为 Detailed Outline Control(DOC) 的框架，通过详细大纲和详细控制器来提高生成长篇故事时的情节连贯性和大纲相关性，人类评估证实该方法在这些方面显著优于基线方法，并且更适用于交互生成设置。

    

    我们提出了一个称为 Detailed Outline Control(DOC)的框架，以提高生成数千字长的故事时的长程情节连贯性。DOC由两个互补组件组成：详细大纲和详细控制器。详细大纲创建一个更详细、层次化的大纲，将创造性负担从主要起草过程转移到规划阶段。详细控制器通过控制故事段落与大纲细节对齐，确保更详细的大纲在生成过程中仍然被尊重。在自动生成的故事的人类评估中，DOC在情节连贯性(22.5% 绝对增益)、大纲相关性(28.2%)和趣味性(20.7%)方面显著优于强大的Re3基线(Yang等人，2022)。人们还评价DOC在交互生成设置方面更易于控制。

    We propose the Detailed Outline Control (DOC) framework for improving long-range plot coherence when automatically generating several-thousand-word-long stories. DOC consists of two complementary components: a detailed outliner and a detailed controller. The detailed outliner creates a more detailed, hierarchically structured outline, shifting creative burden from the main drafting procedure to the planning stage. The detailed controller ensures the more detailed outline is still respected during generation by controlling story passages to align with outline details. In human evaluations of automatically generated stories, DOC substantially outperforms a strong Re3 baseline (Yang et al., 2022) on plot coherence (22.5% absolute gain), outline relevance (28.2%), and interestingness (20.7%). Humans also judged DOC to be much more controllable in an interactive generation setting.
    
[^61]: 面向视觉、语音和语言的上下文化目标表示自监督学习高效性改进

    Efficient Self-supervised Learning with Contextualized Target Representations for Vision, Speech and Language. (arXiv:2212.07525v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.07525](http://arxiv.org/abs/2212.07525)

    本文提出了一种上下文化目标表示自监督学习的高效性改进方法，称为data2vec 2.0，它在多项任务中取得了和其他算法相当的准确率，但需要的预训练时间较短。

    

    当前的自监督学习算法通常是模态特定的，需要大量的计算资源。为了解决这些问题，我们提高了data2vec的训练效率，该学习目标可以推广到多种模态。我们不对掩蔽标记进行编码，使用快速卷积解码器，并分摊构建教师表示的工作。data2vec 2.0受到data2vec引入的丰富上下文化目标表示的益处，可以实现快速自监督学习。在ImageNet-1K图像分类实验中，data2vec 2.0在低16.4倍的预训练时间内与蒙版自编码器的准确率相匹配，在Librispeech语音识别中，它的表现与wav2vec 2.0相当，时间少10.6倍，在GLUE自然语言理解方面，它与重新训练的RoBERTa模型的时间相比减半。在牺牲一定的速度以换取准确性的情况下，使用训练了150个epochs的ViT-L模型可以得到86.8\%的ImageNet-1K top-1准确率。

    Current self-supervised learning algorithms are often modality-specific and require large amounts of computational resources. To address these issues, we increase the training efficiency of data2vec, a learning objective that generalizes across several modalities. We do not encode masked tokens, use a fast convolutional decoder and amortize the effort to build teacher representations. data2vec 2.0 benefits from the rich contextualized target representations introduced in data2vec which enable a fast self-supervised learner. Experiments on ImageNet-1K image classification show that data2vec 2.0 matches the accuracy of Masked Autoencoders in 16.4x lower pre-training time, on Librispeech speech recognition it performs as well as wav2vec 2.0 in 10.6x less time, and on GLUE natural language understanding it matches a retrained RoBERTa model in half the time. Trading some speed for accuracy results in ImageNet-1K top-1 accuracy of 86.8\% with a ViT-L model trained for 150 epochs.
    
[^62]: 基于不一致性排名的高质量无噪声标签检测方法

    Inconsistency Ranking-based Noisy Label Detection for High-quality Data. (arXiv:2212.00239v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.00239](http://arxiv.org/abs/2212.00239)

    本文提出了一种基于不一致性排名的自动无噪声标签检测技术，将其用于自动语音识别（ASV）任务作为概念验证。实验结果表明，该解决方案可以提高大规模说话人识别数据集的高效清洗能力。

    

    深度学习的成功需要高质量的注释和大规模数据，然而实际中，数据集的大小和质量往往存在一个权衡，因为数据的收集和清洗费用高昂且耗时。在使用众包数据集的实际应用中，特别是需要排除噪声标签。为了解决这个问题，本文提出了一种基于不一致性排名的自动无噪声标签检测技术，将其用于自动语音识别（ASV）任务作为概念验证。我们研究了类间和类内不一致性排名，并在不同的噪声设置下比较了几种度量学习损失函数。实验结果表明，该解决方案可以提高大规模说话人识别数据集的高效清洗能力。

    The success of deep learning requires high-quality annotated and massive data. However, the size and the quality of a dataset are usually a trade-off in practice, as data collection and cleaning are expensive and time-consuming. In real-world applications, especially those using crowdsourcing datasets, it is important to exclude noisy labels. To address this, this paper proposes an automatic noisy label detection (NLD) technique with inconsistency ranking for high-quality data. We apply this technique to the automatic speaker verification (ASV) task as a proof of concept. We investigate both inter-class and intra-class inconsistency ranking and compare several metric learning loss functions under different noise settings. Experimental results confirm that the proposed solution could increase both the efficient and effective cleaning of large-scale speaker recognition datasets.
    
[^63]: 用特征归因降低神经机器翻译中的幻觉

    Reducing Hallucinations in Neural Machine Translation with Feature Attribution. (arXiv:2211.09878v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.09878](http://arxiv.org/abs/2211.09878)

    本文通过特征归因方法研究了神经机器翻译中幻觉的产生原因，提出了一种新的损失函数，可以有效地降低幻觉的产生并且不需要重新训练模型。

    

    神经条件语言生成模型在神经机器翻译领域取得了最先进的成果，但是高度依赖于平行训练数据集的质量。当训练数据集质量较低时，这些模型容易出现各种错误类型，包括幻觉，即流畅但与源语言句子无关的输出。这些错误尤其危险，因为在表面上，翻译可能被认为是正确的输出，特别是如果读者不理解源语言。本文提出了一项用于降低神经机器翻译中幻觉的模型理解和规范化的案例研究。我们首先使用特征归因方法研究产生幻觉的NMT模型的行为，然后利用这些方法提出了一种新的损失函数，大大帮助减少幻觉，并且不需要从头重新训练模型。

    Neural conditional language generation models achieve the state-of-the-art in Neural Machine Translation (NMT) but are highly dependent on the quality of parallel training dataset. When trained on low-quality datasets, these models are prone to various error types, including hallucinations, i.e. outputs that are fluent, but unrelated to the source sentences. These errors are particularly dangerous, because on the surface the translation can be perceived as a correct output, especially if the reader does not understand the source language. We present a case study focusing on model understanding and regularisation to reduce hallucinations in NMT. We first use feature attribution methods to study the behaviour of an NMT model that produces hallucinations. We then leverage these methods to propose a novel loss function that substantially helps reduce hallucinations and does not require retraining the model from scratch.
    
[^64]: ATCO2语料库：用于空中交通管制通信自动语音识别和自然语言理解研究的大规模数据集

    ATCO2 corpus: A Large-Scale Dataset for Research on Automatic Speech Recognition and Natural Language Understanding of Air Traffic Control Communications. (arXiv:2211.04054v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.04054](http://arxiv.org/abs/2211.04054)

    ATCO2语料库是一个旨在促进空中交通管制通信自动语音识别和自然语言理解研究的大规模数据集，包括数据收集和预处理、语音数据的伪注释，以及提取与空中交通管制相关的命名实体。

    

    在互联的数字世界中，个人助手、自动语音识别器和对话理解系统变得越来越重要。航空交通管制通信就是其中一个明显的例子。空中交通管制旨在以安全和最优的方式指导飞行器和控制空域。这些基于语音的对话是通过超高频无线电频道在空中交通管制员（ATCO）和飞行员之间进行的。为了将这些新技术纳入ATC（低资源领域），需要大规模的注释数据集来开发数据驱动的AI系统，其中包括自动语音识别（ASR）和自然语言理解（NLU）。在本文中，我们介绍了ATCO2语料库，这是一个旨在促进ATC领域研究的数据集，由于缺乏注释的数据，该领域滞后很多。ATCO2语料库包括1）数据收集和预处理，2）语音数据的伪注释，和3）提取与空中交通管制相关的命名实体。

    Personal assistants, automatic speech recognizers and dialogue understanding systems are becoming more critical in our interconnected digital world. A clear example is air traffic control (ATC) communications. ATC aims at guiding aircraft and controlling the airspace in a safe and optimal manner. These voice-based dialogues are carried between an air traffic controller (ATCO) and pilots via very-high frequency radio channels. In order to incorporate these novel technologies into ATC (low-resource domain), large-scale annotated datasets are required to develop the data-driven AI systems. Two examples are automatic speech recognition (ASR) and natural language understanding (NLU). In this paper, we introduce the ATCO2 corpus, a dataset that aims at fostering research on the challenging ATC field, which has lagged behind due to lack of annotated data. The ATCO2 corpus covers 1) data collection and pre-processing, 2) pseudo-annotations of speech data, and 3) extraction of ATC-related named
    
[^65]: PromptCast：一种新的基于提示的时间序列预测范式

    PromptCast: A New Prompt-based Learning Paradigm for Time Series Forecasting. (arXiv:2210.08964v3 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2210.08964](http://arxiv.org/abs/2210.08964)

    提出了一种新的时间序列预测范式——基于提示的时间序列预测（PromptCast），将数字输入和输出转化为提示，并以句子到句子的方式提出预测任务，可以直接应用于语言模型。

    

    本文提出了一种新的时间序列预测范式——基于提示的时间序列预测（PromptCast）。在这种新的任务中，将原来的数字输入和输出转化为提示，并以句子到句子的方式提出预测任务，使得语言模型可以直接应用于预测的目的。为了支持和促进这个任务的研究，我们还提出了一个大规模的数据集（PISA）。

    This paper presents a new perspective on time series forecasting. In existing time series forecasting methods, the models take a sequence of numerical values as input and yield numerical values as output. The existing SOTA models are largely based on the Transformer architecture, modified with multiple encoding mechanisms to incorporate the context and semantics around the historical data. Inspired by the successes of pre-trained language foundation models, we pose a question about whether these models can also be adapted to solve time-series forecasting. Thus, we propose a new forecasting paradigm: prompt-based time series forecasting (PromptCast). In this novel task, the numerical input and output are transformed into prompts and the forecasting task is framed in a sentence-to-sentence manner, making it possible to directly apply language models for forecasting purposes. To support and facilitate the research of this task, we also present a large-scale dataset (PISA) that includes th
    
[^66]: MAMO：面向细粒度视觉-语言表示学习的掩膜多模态建模方法

    MAMO: Masked Multimodal Modeling for Fine-Grained Vision-Language Representation Learning. (arXiv:2210.04183v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.04183](http://arxiv.org/abs/2210.04183)

    本文提出了一种联合掩膜多模态建模方法，以学习细粒度的多模态表示，通过隐式和显式目标来恢复联合掩膜信号以提高细化的图像-文本交互。

    

    多模态表示学习在各种视觉-语言任务中展现了很大的潜力。然而，当前大部分方法都主要致力于建立全局级别的图像与语言对齐，缺乏有效的细粒度图像-文本交互。为此，本文提出了一种联合掩膜多模态建模方法，以学习细粒度的多模态表示。我们的方法对图像-文本输入进行联合掩膜，并集成了显式和隐式目标来恢复掩膜信号。其中，隐式目标为视觉和语言提供统一且无偏差的目标，模型预测未掩膜输入的潜在多模态表示；显式目标则通过恢复图像块的动量视觉特征和单词标记的概念，进一步丰富多模态表示。通过这样的掩膜建模过程，我们的模型不仅可以学习到细粒度的多模态交互，还能学习到有意义的语义信息。

    Multimodal representation learning has shown promising improvements on various vision-language tasks. Most existing methods excel at building global-level alignment between vision and language while lacking effective fine-grained image-text interaction. In this paper, we propose a jointly masked multimodal modeling method to learn fine-grained multimodal representations. Our method performs joint masking on image-text input and integrates both implicit and explicit targets for the masked signals to recover. The implicit target provides a unified and debiased objective for vision and language, where the model predicts latent multimodal representations of the unmasked input. The explicit target further enriches the multimodal representations by recovering high-level and semantically meaningful information: momentum visual features of image patches and concepts of word tokens. Through such a masked modeling process, our model not only learns fine-grained multimodal interaction, but also a
    
[^67]: 基于模板化时间适应的动态上下文词嵌入学习方法

    Learning Dynamic Contextualised Word Embeddings via Template-based Temporal Adaptation. (arXiv:2208.10734v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2208.10734](http://arxiv.org/abs/2208.10734)

    本文提出一种基于时间适应的动态上下文词嵌入学习方法，使用感知时间的模板生成提示，通过微调预训练的MLM得到DCWE，实验结果表明该方法在困惑度和下游任务上优于现有方法。

    

    动态上下文词嵌入（DCWE）表示单词的语义随时间的变化。本文提出了一种使用感知时间的模板学习预训练掩蔽语言模型（MLM）得到DCWE的方法。本文首先提出一种无监督方法，通过选择与$C_1$和$C_2$相关的“枢轴”（pivot）术语和在各个快照中与特定枢轴术语相关的“锚”（anchor）术语来生成提示。然后，本文提出了一种自动学习时间敏感的模板的方法，从$C_1$和$C_2$中进行学习，无需任何人工监督。接下来，本文使用这些生成的提示通过微调来适应预训练的MLM到$T_2$。多个实验证明，我们的方法在超过强基线9.2点的同时降低了$C_1$测试句子的困惑度，优于现有的动态上下文词嵌入方法。此外，我们还证明了我们的方法对情感分析和命名实体识别等下游任务是有用的。

    Dynamic contextualised word embeddings (DCWEs) represent the temporal semantic variations of words. We propose a method for learning DCWEs by time-adapting a pretrained Masked Language Model (MLM) using time-sensitive templates. Given two snapshots $C_1$ and $C_2$ of a corpus taken respectively at two distinct timestamps $T_1$ and $T_2$, we first propose an unsupervised method to select (a) \emph{pivot} terms related to both $C_1$ and $C_2$, and (b) \emph{anchor} terms that are associated with a specific pivot term in each individual snapshot. We then generate prompts by filling manually compiled templates using the extracted pivot and anchor terms. Moreover, we propose an automatic method to learn time-sensitive templates from $C_1$ and $C_2$, without requiring any human supervision. Next, we use the generated prompts to adapt a pretrained MLM to $T_2$ by fine-tuning using those prompts. Multiple experiments show that our proposed method reduces the perplexity of test sentences in $C_
    
[^68]: PLAtE: 一个大规模的列表页网络抽取数据集

    PLAtE: A Large-scale Dataset for List Page Web Extraction. (arXiv:2205.12386v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.12386](http://arxiv.org/abs/2205.12386)

    这个工作介绍了一个名为PLAtE的大规模列表页网络抽取数据集，用于从产品评论页面中提取商品列表和产品属性。数据集由52,898个项目和156,014个属性组成，是第一个大规模的列表页网络抽取数据集。

    

    最近，神经模型被利用来显著提高从半结构化网站中提取信息的性能。然而，继续进步的障碍是训练这些模型的数据集数量太少。在这项工作中，我们介绍了 PLAtE （Pages of Lists Attribute Extraction）基准数据集作为一个具有挑战性的新网络抽取任务。PLAtE 主要关注购物数据，特别是从包含多个项目的产品评论页面中提取，包含两个任务：（1）查找产品列表分割边界和（2）提取每个产品的属性。PLAtE由来自6,694个页面的52,898个项目和156,014个属性组成，是第一个大规模的列表页网络抽取数据集。我们使用多阶段方法来收集和注释数据集，并将三个最先进的网络抽取模型适应于两个任务，定量和定性比较它们的优缺点。

    Recently, neural models have been leveraged to significantly improve the performance of information extraction from semi-structured websites. However, a barrier for continued progress is the small number of datasets large enough to train these models. In this work, we introduce the PLAtE (Pages of Lists Attribute Extraction) benchmark dataset as a challenging new web extraction task. PLAtE focuses on shopping data, specifically extractions from product review pages with multiple items encompassing the tasks of: (1) finding product-list segmentation boundaries and (2) extracting attributes for each product. PLAtE is composed of 52, 898 items collected from 6, 694 pages and 156, 014 attributes, making it the first largescale list page web extraction dataset. We use a multi-stage approach to collect and annotate the dataset and adapt three state-of-the-art web extraction models to the two tasks comparing their strengths and weaknesses both quantitatively and qualitatively.
    
[^69]: 文本到图像生成的提示修饰分类学

    A Taxonomy of Prompt Modifiers for Text-To-Image Generation. (arXiv:2204.13988v3 [cs.MM] UPDATED)

    [http://arxiv.org/abs/2204.13988](http://arxiv.org/abs/2204.13988)

    本文基于为期3个月的民族学研究，确定了网络社区中使用的六种文本到图像生成提示修饰器的分类学，为研究文本到图像生成的实践提供了一个概念起点，并提供了AI生成艺术的实践者改进图像的可能性。

    

    自2021年以来，文本到图像的生成引起了人们的极大关注。深度生成模型可以从文字输入（“提示”）中合成美丽和引人入胜的数字图像和艺术品。在线社区围绕文本到图像生成和AI生成艺术迅速出现。本文基于为期3个月的民族学研究，确定了网络社区中实践者使用的六种提示修改器。这个新颖的提示修饰分类学为研究文本到图像生成的实践提供了一个概念起点，同时也可能帮助AI生成艺术的实践者改进他们的图像。我们进一步概述了如何在“提示工程”实践中应用提示修饰器。我们讨论了这种新创意实践在人机交互领域的研究机会。文章在从人工智能交互的角度讨论提示工程的更广泛影响后结束。

    Text-to-image generation has seen an explosion of interest since 2021. Today, beautiful and intriguing digital images and artworks can be synthesized from textual inputs ("prompts") with deep generative models. Online communities around text-to-image generation and AI generated art have quickly emerged. This paper identifies six types of prompt modifiers used by practitioners in the online community based on a 3-month ethnographic study. The novel taxonomy of prompt modifiers provides researchers a conceptual starting point for investigating the practice of text-to-image generation, but may also help practitioners of AI generated art improve their images. We further outline how prompt modifiers are applied in the practice of "prompt engineering." We discuss research opportunities of this novel creative practice in the field of Human-Computer Interaction (HCI). The paper concludes with a discussion of broader implications of prompt engineering from the perspective of Human-AI Interactio
    
[^70]: 利用机器学习在急诊科分诊中检测败血症

    Detection of sepsis during emergency department triage using machine learning. (arXiv:2204.07657v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2204.07657](http://arxiv.org/abs/2204.07657)

    本研究利用机器学习开发出一种检测急诊科分诊前败血症的模型，其性能优于标准败血症筛查算法。

    

    身体器官功能障碍的败血症是全球死亡和危重疾病的主要原因之一。本研究的目的是比较标准败血症筛查算法和在电子健康记录分诊数据上训练的机器学习算法在急诊科分诊前（未使用实验室诊断）的败血症检测性能。研究得出机器学习模型的 AUC 为 0.9423，敏感性为 71.09%。

    Sepsis is a life-threatening condition with organ dysfunction and is a leading cause of death and critical illness worldwide. Even a few hours of delay in the treatment of sepsis results in increased mortality. Early detection of sepsis during emergency department triage would allow early initiation of lab analysis, antibiotic administration, and other sepsis treatment protocols. The purpose of this study was to compare sepsis detection performance at ED triage (prior to the use of laboratory diagnostics) of the standard sepsis screening algorithm (SIRS with source of infection) and a machine learning algorithm trained on EHR triage data. A machine learning model (KATE Sepsis) was developed using patient encounters with triage data from 16participating hospitals. KATE Sepsis and standard screening were retrospectively evaluated on the adult population of 512,949 medical records. KATE Sepsis demonstrates an AUC of 0.9423 (0.9401 - 0.9441) with sensitivity of 71.09% (70.12% - 71.98%) and
    
[^71]: 集中关注潜在命名实体的主动标注获取

    Focusing on Potential Named Entities During Active Label Acquisition. (arXiv:2111.03837v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2111.03837](http://arxiv.org/abs/2111.03837)

    本文提出了几个AL句子查询评估函数，关注潜在正面标记，并使用更好的数据驱动的正常化方法，以最小化NER注释成本。

    

    命名实体识别(NER)旨在识别结构化文本中命名实体的提及并将其分类到预定义的命名实体类别中。虽然基于深度学习的预训练语言模型有助于在NER中实现良好的预测性能，但许多特定领域的NER应用仍需要大量标记数据。主动学习(AL)是解决标签获取问题的通用框架，已用于NER任务，以最小化注释成本而不牺牲模型性能。然而，标记的严重不均匀类分布引入了设计有效的NER主动学习查询方法的挑战。我们提出了几个AL句子查询评估函数，更多关注潜在的正面标记，并使用基于句子和标记成本评估策略来评估这些提议的函数。我们还提出了更好的数据驱动的正常化方法，以惩罚过长或过短的句子。

    Named entity recognition (NER) aims to identify mentions of named entities in an unstructured text and classify them into predefined named entity classes. While deep learning-based pre-trained language models help to achieve good predictive performances in NER, many domain-specific NER applications still call for a substantial amount of labeled data. Active learning (AL), a general framework for the label acquisition problem, has been used for NER tasks to minimize the annotation cost without sacrificing model performance. However, the heavily imbalanced class distribution of tokens introduces challenges in designing effective AL querying methods for NER. We propose several AL sentence query evaluation functions that pay more attention to potential positive tokens, and evaluate these proposed functions with both sentence-based and token-based cost evaluation strategies. We also propose a better data-driven normalization approach to penalize sentences that are too long or too short. Our
    
[^72]: 自我调节预训练语言模型

    Self-conditioning pre-trained language models. (arXiv:2110.02802v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2110.02802](http://arxiv.org/abs/2110.02802)

    本文探究了预训练语言模型(TLMs)的生成机制，并提出了一种自我调节的方法，利用TLMs中自然存在的专家单元来检测输入中的概念并对生成的文本进行调节。该方法即使在没有微调或使用额外参数的情况下也是有效的，可以纠正文本生成中的性别偏差。

    

    本文旨在探究预训练的基于Transformer的语言模型(TLMs)指导文本生成的机制。基于Hinton(1999)的专家乘积公式，我们描述了一种生成机制，利用TLMs中自然存在的专家单元来检测输入中的概念，并在生成的文本中对这些概念进行调节。我们阐述了如何确定专家单元以及如何在推理过程中激活它们，以引导生成的输出中出现所需的任何概念。我们发现，激活极少量的单元就足以引导文本生成(在一个拥有345M参数的模型中只需要3个单元)。虽然本研究的目的是更多地了解TLMs的工作原理，但我们证明了我们的方法在没有微调或使用额外参数的情况下对于条件调节是有效的，甚至对于细粒度的同音异义词概念也能够实现。此外，我们还展示了我们的方法可以用于纠正文本生成中的性别偏差。

    In this paper we aim to investigate the mechanisms that guide text generation with pre-trained Transformer-based Language Models (TLMs). Grounded on the Product of Experts formulation by Hinton (1999), we describe a generative mechanism that exploits expert units which naturally exist in TLMs. Such units are responsible for detecting concepts in the input and conditioning text generation on such concepts. We describe how to identify expert units and how to activate them during inference in order to induce any desired concept in the generated output. We find that the activation of a surprisingly small amount of units is sufficient to steer text generation (as little as 3 units in a model with 345M parameters). While the objective of this work is to learn more about how TLMs work, we show that our method is effective for conditioning without fine-tuning or using extra parameters, even on fine-grained homograph concepts. Additionally, we show that our method can be used to correct gender 
    
[^73]: 一种弱监督模型WARM用于解决数学题

    WARM: A Weakly (+Semi) Supervised Model for Solving Math word Problems. (arXiv:2104.06722v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2104.06722](http://arxiv.org/abs/2104.06722)

    研究提出了一种弱监督模型WARM来解决用于自然语言处理中的数学题。通过仅用期望答案作为监督，该方法通过学习生成方程来解决问题，并在无需使用方程作为监督的情况下，成功实现了相比最先进的弱监督方法更高的精度提升。

    

    解决数学问题是自然语言处理中的一个重要而具有挑战性的问题。现有的方法需要通过中间方程获得全部监督，而标注每个数学题的坑人代价昂贵。为了解决方程注释的挑战，我们提出了一种弱监督模型，通过仅需要期望答案作为监督来解决数学问题。

    Solving math word problems (MWPs) is an important and challenging problem in natural language processing. Existing approaches to solve MWPs require full supervision in the form of intermediate equations. However, labeling every MWP with its corresponding equations is a time-consuming and expensive task. In order to address this challenge of equation annotation, we propose a weakly supervised model for solving MWPs by requiring only the final answer as supervision. We approach this problem by first learning to generate the equation using the problem description and the final answer, which we subsequently use to train a supervised MWP solver. We propose and compare various weakly supervised techniques to learn to generate equations directly from the problem description and answer. Through extensive experiments, we demonstrate that without using equations for supervision, our approach achieves accuracy gains of 4.5% and 32% over the state-of-the-art weakly supervised approach, on the stan
    

