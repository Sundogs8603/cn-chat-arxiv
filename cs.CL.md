# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A Survey of Large Language Models.](http://arxiv.org/abs/2303.18223) | 本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。 |
| [^2] | [Assessing Language Model Deployment with Risk Cards.](http://arxiv.org/abs/2303.18190) | 本文提出了一个名为RiskCards的框架，用于系统地评估和记录与语言模型应用相关的各种风险，并将这些风险传达给技术和非技术相关者。 |
| [^3] | [A Multiple Choices Reading Comprehension Corpus for Vietnamese Language Education.](http://arxiv.org/abs/2303.18162) | ViMMRC 2.0是一个针对越南教材中的多项选择阅读理解任务的语料库，共有699篇散文和诗歌以及5,273个问题。该数据集中的问题选项不固定为四个，且问题难度增加，需要使用多步注意力网络与变压器相结合的多阶段方法来处理。 |
| [^4] | [Can AI Chatbots Pass the Fundamentals of Engineering (FE) and Principles and Practice of Engineering (PE) Structural Exams?.](http://arxiv.org/abs/2303.18149) | 本论文探讨了AI聊天机器人能否通过工程基础（FE）和工程原理与实践（PE）考试，研究发现ChatGPT-4在FE考试中得分70.9％，在PE考试中得分46.2％，并且有望通过PE考试。 |
| [^5] | [BERTino: an Italian DistilBERT model.](http://arxiv.org/abs/2303.18121) | 本文介绍了BERTino，一种轻量级的DistilBERT模型，是用于意大利语的第一个替代BERT体系结构的选择，其在多项任务中F1分数与BERTBASE相当并显著提高了训练和推理速度。 |
| [^6] | [UKP-SQuARE v3: A Platform for Multi-Agent QA Research.](http://arxiv.org/abs/2303.18120) | UKP-SQuARE v3是一个支持多智能体系统的QA研究平台，与多数据集模型相比，结合专家智能体可以获得更好的性能提升。 |
| [^7] | [The Edinburgh International Accents of English Corpus: Towards the Democratization of English ASR.](http://arxiv.org/abs/2303.18110) | 爱丁堡国际英语口音语料库（EdAcc）发布，包括英语的广泛多样性和每个说话者的语言背景概况。在 EdAcc 上训练的最佳模型明显优于所有现有模型，这突显了当前英语ASR模型的缺点。这一数据集的公开共享将有助于民主化英语语音识别研究和开发。 |
| [^8] | [Dataset and Baseline System for Multi-lingual Extraction and Normalization of Temporal and Numerical Expressions.](http://arxiv.org/abs/2303.18103) | 该论文描述了一个覆盖14种语言、多元化的时间和数字表达式，包括提取、规范化和解析的多语言数据集(NTX)，并提供了一个强大的基于规则的系统作为评估其他模型的比较基准。 |
| [^9] | [Solving morphological analogies: from retrieval to generation.](http://arxiv.org/abs/2303.18062) | 该论文提出了一个基于深度学习和条件变分自编码器的框架来解决基于类比的推理中的类比检测和解决两个任务，该框架可以生成之前不存在于数据集中的类比。 |
| [^10] | [No Place to Hide: Dual Deep Interaction Channel Network for Fake News Detection based on Data Augmentation.](http://arxiv.org/abs/2303.18049) | 本文提出了一个新的假新闻检测框架，从语义、情感和数据增强的角度挖掘了新闻中的独特关键特征和演化模式，设计了一种考虑评论的语义和情感的双重深度交互通道网络来获取更全面和细粒度的新闻表示，并引入数据增强模块解决样本不足的问题。 |
| [^11] | [Evaluating GPT-4 and ChatGPT on Japanese Medical Licensing Examinations.](http://arxiv.org/abs/2303.18027) | 本文评估了GPT-4、ChatGPT和GPT-3在日本医疗执照考试中的表现，结果发现GPT-4优于其他两者，呈现出LLMs在与英语远离的语言中的潜力，但目前的LLM API存在一些限制，例如建议实施禁止的医疗选择。 |
| [^12] | [Exploiting Multilingualism in Low-resource Neural Machine Translation via Adversarial Learning.](http://arxiv.org/abs/2303.18011) | 本文提出了一种基于去噪对抗自编码器的句子插值方法，以及利用多语种模型生成句子进行奖励计算的Wasserstein-GAN方法来优化多语种神经机器翻译模型的性能。 |
| [^13] | [$\mathcal{E}$ K\'U [MASK]: Integrating Yor\`ub\'a cultural greetings into machine translation.](http://arxiv.org/abs/2303.17972) | 本文研究了将尤鲁巴文化问候语（$\mathcal{E}$ k\'u [MASK]）整合到机器翻译中，通过IkiniYor\`ub\'a数据集，我们发现大规模多语言神经机器翻译（NMT）系统无法准确翻译，而微调现有的NMT模型在翻译中有更好的表现。 |
| [^14] | [Trimming Phonetic Alignments Improves the Inference of Sound Correspondence Patterns from Multilingual Wordlists.](http://arxiv.org/abs/2303.17932) | 本文提出在比较语言学中，通过修剪语音对齐来自动改进对准同源词数据的方法，经测试其效果明显优于其他方法，可以显著提高从多语种词汇表中正确推断音对应模式的能力。 |
| [^15] | [JobHam-place with smart recommend job options and candidate filtering options.](http://arxiv.org/abs/2303.17930) | 本论文设计了一个名为JobHam-place的智能求职系统，其包含工作推荐、简历排名及职位仪表板等功能，通过自动关键字提取和Job/CV排名算法实现，同时提出了一种新的基于词嵌入和余弦相似性的算法来匹配工作要求和求职者技能，实验结果表明系统具有准确的工作推荐和简历排名能力。 |
| [^16] | [Cross-Cultural Transfer Learning for Chinese Offensive Language Detection.](http://arxiv.org/abs/2303.17927) | 本文研究了跨文化迁移学习在中文恶意语言检测上的应用，发现特定文化背景下的偏见会对语言模型的可迁移性产生负面影响。此研究结果支持在模型训练时考虑多元文化背景，以提高恶意语言检测的效果。 |
| [^17] | [Selective Knowledge Distillation for Non-Autoregressive Neural Machine Translation.](http://arxiv.org/abs/2303.17910) | 本论文介绍在非自回归神经机器翻译中引入选择性知识蒸馏和渐进蒸馏方法，并在实验中证明该方法可以在NAT模型的训练数据质量和复杂度之间实现灵活权衡，有助于NAT超越基线。 |
| [^18] | [WebQAmGaze: A Multilingual Webcam Eye-Tracking-While-Reading Dataset.](http://arxiv.org/abs/2303.17876) | WebQAmGaze是一个多语言低成本的阅读时眼动追踪数据集，包括332位参与者的数据，对相关段落的注视似乎能够反映回答理解问题的准确性。这份数据可以推动基于网络摄像头的阅读研究并开辟更便宜、更易获得的数据收集方式。 |
| [^19] | [Can AI Put Gamma-Ray Astrophysicists Out of a Job?.](http://arxiv.org/abs/2303.17853) | 本文评估了使用最先进的转换器模型创作一篇假的科学论文的能力，旨在验证这些模型是否能够仅基于语言信息解释天文观测和源，并为同行评审识别欺诈性生成的科学论文提供潜在手段。结论是，目前天文学家的工作是安全的。 |
| [^20] | [Learning Procedure-aware Video Representation from Instructional Videos and Their Narrations.](http://arxiv.org/abs/2303.17839) | 本文提出了一种从教学视频及其解说中学习过程感知的视频表示方法，联合学习视频表示和深度概率模型可以增强过程推理的新功能，同时对个体步骤的识别也能得到加强。 |
| [^21] | [Exploring the Potential of Large Language models in Traditional Korean Medicine: A Foundation Model Approach to Culturally-Adapted Healthcare.](http://arxiv.org/abs/2303.17807) | 本研究评估了大型语言模型在应用传统韩医的潜力。其中，GPT-4在应用韩国国家中医医生执照考试中取得了57.29%的准确率，潜在应用价值高。 |
| [^22] | [Dialog act guided contextual adapter for personalized speech recognition.](http://arxiv.org/abs/2303.17799) | 本文提出了一种基于对话行为的上下文适配器网络，该网络结合用户目录和对话行为，成功地解决了多轮对话的个性化语音识别问题，相对于无上下文模型实现了58%的平均相对词错误率降低。 |
| [^23] | [CAMEL: Communicative Agents for "Mind" Exploration of Large Scale Language Model Society.](http://arxiv.org/abs/2303.17760) | 本文介绍了一个名为角色扮演的新型交互式代理框架，用于实现语言模型之间的自主合作，并展示了其在生成对话数据方面的有效性。 |
| [^24] | [Design by Contract Framework for Quantum Software.](http://arxiv.org/abs/2303.17750) | 该论文提出了一种基于合约的量子软件设计框架，用于自动确保量子电路构建过程的正确性，这对于验证量子电路的正确性具有重要意义。 |
| [^25] | [Evaluation of GPT and BERT-based models on identifying protein-protein interactions in biomedical text.](http://arxiv.org/abs/2303.17728) | 该论文评估了预先训练的语言模型(GPT和BERT)识别生物医学文本中蛋白质相互作用的性能, 结果显示BERT模型表现最佳，其中PubMedBERT具有最高的精度和F1分数，BioM-ALBERT具有最高的召回率。 |
| [^26] | [What Types of Questions Require Conversation to Answer? A Case Study of AskReddit Questions.](http://arxiv.org/abs/2303.17710) | 本文研究了哪些模糊开放性问题最适合通过对话回答，发现这些问题高度社交和个人化，对未来研究提供了有益的参考。 |
| [^27] | [Task Oriented Conversational Modelling With Subjective Knowledge.](http://arxiv.org/abs/2303.17695) | 本文提出了一种改进知识选择模块的实体检索方法，并探讨了一种潜在的关键字提取方法，以提高任务导向交互建模系统的性能。 |
| [^28] | [Fine-Tuning BERT with Character-Level Noise for Zero-Shot Transfer to Dialects and Closely-Related Languages.](http://arxiv.org/abs/2303.17683) | 本研究使用字符级噪音微调BERT以实现对未见方言和语言的零样本跨语言迁移。本研究发现只有在任务依赖表面级别提示并且源-目标跨语言对具有相对较高的词汇重叠时，在微调过程中引入字符级噪音对跨语言迁移的效果才特别突出。 |
| [^29] | [Self-Refine: Iterative Refinement with Self-Feedback.](http://arxiv.org/abs/2303.17651) | 自我反馈迭代精炼是一种无需监督学习或加强学习的LLMs初始输出优化方法，优于直接生成，被证实在7个不同任务中表现更好。 |
| [^30] | [Comparing Abstractive Summaries Generated by ChatGPT to Real Summaries Through Blinded Reviewers and Text Classification Algorithms.](http://arxiv.org/abs/2303.17650) | 本研究评估了ChatGPT在抽象概括方面的表现，自动化指标和盲审人员评估显示ChatGPT生成的摘要在人类视角下难以分辨真假。 |
| [^31] | [Aligning a medium-size GPT model in English to a small closed domain in Spanish using reinforcement learning.](http://arxiv.org/abs/2303.17649) | 本文介绍了一种将英文GPT模型对齐到西班牙语的小封闭领域中的方法，该方法使用了奖励模型来改进答案的解码和生成，在问答任务中取得了良好的结果。 |
| [^32] | [Detecting and Grounding Important Characters in Visual Stories.](http://arxiv.org/abs/2303.17647) | 该论文介绍了一个新的数据集 VIST-Character ，该数据集为以角色为中心的注释提供了一个标准，针对该数据集，论文提出了两个新任务，即重要人物检测和视觉故事中角色的定位，并基于分布相似性和预训练的视觉语言模型开发了简单的无监督模型。 |
| [^33] | [oBERTa: Improving Sparse Transfer Learning via improved initialization, distillation, and pruning regimes.](http://arxiv.org/abs/2303.17612) | oBERTa是一组易于使用的语言模型，通过改进初始化、蒸馏、剪枝等技术，可以在不需要模型压缩方面的专业知识的情况下提高稀疏迁移学习的效率和准确性。 |
| [^34] | [Assessing Cross-Cultural Alignment between ChatGPT and Human Societies: An Empirical Study.](http://arxiv.org/abs/2303.17466) | 本文通过分析ChatGPT对旨在量化人类文化差异的问题的回答，评估了其文化适应能力。发现ChatGPT在以美国背景为提示时表现出与美国文化的强烈对齐，但其对其他文化的适应能力较差，并且英文提示会抹平文化差异并偏向美国文化。 |
| [^35] | [Did You Mean...? Confidence-based Trade-offs in Semantic Parsing.](http://arxiv.org/abs/2303.16857) | 该论文介绍了如何通过校准的置信分数，平衡解析任务中的成本、标注员负担、准确性、可用性和安全性等多个权衡，提出了一个可以更好地平衡可用性和安全性的DidYouMean系统。 |
| [^36] | [Reproducibility is Nothing without Correctness: The Importance of Testing Code in NLP.](http://arxiv.org/abs/2303.16166) | 在NLP研究中，我们不能仅凭感知质量假定代码正确性，应该推动采用编码最佳实践以提高实验结果的正确性和可靠性。 |
| [^37] | [Prompting Large Language Models to Generate Code-Mixed Texts: The Case of South East Asian Languages.](http://arxiv.org/abs/2303.13592) | 本文探讨了使用大型语言模型（LLMs）生成东南亚五种语言和Singlish的混合代码数据的方法，发现ChatGPT展现出最高的潜力。然而，由于词汇选择错误的影响，ChatGPT和InstructGPT在生成混合代码时的熟练程度受到限制。 |
| [^38] | [ChatGPT and a New Academic Reality: AI-Written Research Papers and the Ethics of the Large Language Models in Scholarly Publishing.](http://arxiv.org/abs/2303.13367) | 本文讨论了使用自然语言处理生成文本的ChatGPT模型，该技术被认为可以成为自动准备学术论文及手稿的潜在模型，然而，其与类似模型潜在的伦理问题需要考虑和解决。 |
| [^39] | [Fairness-guided Few-shot Prompting for Large Language Models.](http://arxiv.org/abs/2303.13217) | 本文提出了一种新的搜索策略-FairPrompt，在保证公正性的前提下，通过评估提示预测偏差，确定近似最优的提示，从而改进大型语言模型的上下文学习性能，实验表明该方法在准确性和公正性方面均优于现有方法。 |
| [^40] | [Rewarding Chatbots for Real-World Engagement with Millions of Users.](http://arxiv.org/abs/2303.06135) | 本文研究了如何通过利用用户反馈来提高聊天机器人的参与度，从而增强其留存能力。具体方法是使用自动伪标签来训练奖励模型，并使用平均对话长度一类的指标来衡量其效果。在试验中，该方法可将聊天机器人的平均对话长度提高70%。 |
| [^41] | [Few-shot Learning for Cross-Target Stance Detection by Aggregating Multimodal Embeddings.](http://arxiv.org/abs/2301.04535) | 本文提出了一种称为CT-TN的模型，在社交媒体中进行跨目标立场检测，利用了任务的社交性质，通过聚合多模态嵌入来解决少样本情境下的问题。实验表明，该模型在六个不同的源-目标目标对上比最先进的跨目标立场检测模型表现更好。 |
| [^42] | [Editing Models with Task Arithmetic.](http://arxiv.org/abs/2212.04089) | 本文提出了一种使用任务向量进行模型编辑的新范式，任务向量可通过算术操作进行修改和组合，可以提高目标任务性能且对控制任务影响较小。 |
| [^43] | [CoP: Factual Inconsistency Detection by Controlling the Preference.](http://arxiv.org/abs/2212.01611) | CoP是一个无监督的框架，通过控制偏好来检测文本的事实不一致性。 实验证明其效果优于现有的最先进模型。 |
| [^44] | [SexWEs: Domain-Aware Word Embeddings via Cross-lingual Semantic Specialisation for Chinese Sexism Detection in Social Media.](http://arxiv.org/abs/2211.08447) | 本文通过利用跨语言的领域感知语义专业化系统，在不采集新歧视数据或搭建跨语言转移学习模型的情况下，实现了对社交媒体中的中文性别歧视的自动检测。 |
| [^45] | [Calibrated Interpretation: Confidence Estimation in Semantic Parsing.](http://arxiv.org/abs/2211.07443) | 该论文研究了常见的生成模型在四个流行的语义解析数据集上的校准性，并分析了与校准误差相关的因素。为了方便将校准纳入语义解析评估中，作者们发布了一个计算校准度量的库。 |
| [^46] | [Exploiting prompt learning with pre-trained language models for Alzheimer's Disease detection.](http://arxiv.org/abs/2210.16539) | 本文提出一种基于提示学习的预训练语言模型方法，加入不流畅特征提高阿尔茨海默病检测性能。实验结果表明该方法在基准数据集上取得了最佳表现，最高准确率达到95.1%。 |
| [^47] | [M-MELD: A Multilingual Multi-Party Dataset for Emotion Recognition in Conversations.](http://arxiv.org/abs/2203.16799) | 本文提出了一个多语言的情感识别数据集M-MELD，扩展了MELD数据集到英语之外的4种语言，提出了一种新颖的架构DiscLSTM，该架构在对话中使用顺序和交际语境进行ERC，具有高效和跨语言传输等特点，表现良好。 |
| [^48] | [From Natural Language to Simulations: Applying GPT-3 Codex to Automate Simulation Modeling of Logistics Systems.](http://arxiv.org/abs/2202.12107) | 该论文展示了自然语言处理的自动化能力应用到物流系统模拟建模中，证明了基于GPT-3 Codex的框架能够生成功能有效的排队和库存控制系统的模拟模型，为简化模拟模型开发工作流程开启了重要大门。 |
| [^49] | [Automated scholarly paper review: Concepts, technologies, and challenges.](http://arxiv.org/abs/2111.07533) | 提出自动学术论文审稿（ASPR）的概念和流程，综述了实现全面计算机化审稿流程的相关文献和技术，同时指出实现中存在的挑战，如文档解析和表达不完美、数据不足、人机交互缺陷和发现低质量文章的难度。 |

# 详细

[^1]: 大型语言模型综述

    A Survey of Large Language Models. (arXiv:2303.18223v1 [cs.CL])

    [http://arxiv.org/abs/2303.18223](http://arxiv.org/abs/2303.18223)

    本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。

    

    语言本质上是一个由语法规则控制的复杂精细的人类表达系统，对于开发理解和掌握语言的能力的AI算法来说是一项重大挑战。作为主要方法之一，语言建模在过去二十年里广泛研究用于语言理解和生成，从统计语言模型演化为神经语言模型。最近，通过在大规模语料库上预训练Transformer模型，提出了预训练语言模型（PLMs），在解决各种NLP任务方面显示出强大的能力。由于研究人员发现模型缩放可以导致性能改进，他们进一步通过增加模型规模来研究缩放效应，有趣的是，当参数规模超过一定水平时，这些扩大的语言模型不仅可以实现显着的性能提升，而且还显示出一些小规模语言模型所没有的特殊能力。

    Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale langu
    
[^2]: 使用风险卡评估语言模型部署

    Assessing Language Model Deployment with Risk Cards. (arXiv:2303.18190v1 [cs.CL])

    [http://arxiv.org/abs/2303.18190](http://arxiv.org/abs/2303.18190)

    本文提出了一个名为RiskCards的框架，用于系统地评估和记录与语言模型应用相关的各种风险，并将这些风险传达给技术和非技术相关者。

    

    本文介绍了RiskCards框架，它是一种用于结构化评估和记录与语言模型应用相关风险的框架。与所有语言一样，由语言模型生成的文本可能是有害的，或用于造成伤害。自动化语言生成不仅增加了规模的因素，还使生成的文本具有更微妙或突发的不良趋势。之前的工作确定了许多不同角色所面临的各种语言模型的危害。现有的分类法确定了语言模型所造成的各种危害类别；基准测试确立了对这些危害的自动化测试；而对模型、任务和数据集的文档标准则鼓励透明报告。然而，目前没有一个以风险为中心的框架，用于记录一个复杂的风险局势，其中某些风险跨越模型和环境，而其他风险则是特定的，其中某些条件可能需要才能将风险转化为危害。RiskCards通过提供一种系统方法来确定、评估和记录与语言模型部署相关的风险，并向技术和非技术相关者传达这些风险，填补了这个方法论上的空白。

    This paper introduces RiskCards, a framework for structured assessment and documentation of risks associated with an application of language models. As with all language, text generated by language models can be harmful, or used to bring about harm. Automating language generation adds both an element of scale and also more subtle or emergent undesirable tendencies to the generated text. Prior work establishes a wide variety of language model harms to many different actors: existing taxonomies identify categories of harms posed by language models; benchmarks establish automated tests of these harms; and documentation standards for models, tasks and datasets encourage transparent reporting. However, there is no risk-centric framework for documenting the complexity of a landscape in which some risks are shared across models and contexts, while others are specific, and where certain conditions may be required for risks to manifest as harms. RiskCards address this methodological gap by prov
    
[^3]: 用于越南语教育的多项选择阅读理解语料库

    A Multiple Choices Reading Comprehension Corpus for Vietnamese Language Education. (arXiv:2303.18162v1 [cs.CL])

    [http://arxiv.org/abs/2303.18162](http://arxiv.org/abs/2303.18162)

    ViMMRC 2.0是一个针对越南教材中的多项选择阅读理解任务的语料库，共有699篇散文和诗歌以及5,273个问题。该数据集中的问题选项不固定为四个，且问题难度增加，需要使用多步注意力网络与变压器相结合的多阶段方法来处理。

    

    机器阅读理解是近年来一个有趣且具有挑战性的任务，其目的在于从文本中提取有用的信息。我们引入了ViMMRC 2.0，这是对之前ViMMRC的扩展，用于越南教材中的多项选择阅读理解任务，这些教材包含了一年级至十二年级学生的阅读文章。该数据集包含了699篇散文和诗歌，以及5,273个问题。与之前的版本不同，新数据集中的问题选项不固定为四个，同时还增加了问题的难度，这使得模型需要寻找正确的选择。电脑必须理解整个阅读文章的上下文、问题以及每个选项的内容才能提取正确答案。因此，我们提出了将多步注意力网络（MAN）与变压器相结合的多阶段方法来处理这个任务。

    Machine reading comprehension has been an interesting and challenging task in recent years, with the purpose of extracting useful information from texts. To attain the computer ability to understand the reading text and answer relevant information, we introduce ViMMRC 2.0 - an extension of the previous ViMMRC for the task of multiple-choice reading comprehension in Vietnamese Textbooks which contain the reading articles for students from Grade 1 to Grade 12. This dataset has 699 reading passages which are prose and poems, and 5,273 questions. The questions in the new dataset are not fixed with four options as in the previous version. Moreover, the difficulty of questions is increased, which challenges the models to find the correct choice. The computer must understand the whole context of the reading passage, the question, and the content of each choice to extract the right answers. Hence, we propose the multi-stage approach that combines the multi-step attention network (MAN) with the
    
[^4]: AI聊天机器人是否能通过工程基础（FE）和工程原理与实践（PE）结构考试？

    Can AI Chatbots Pass the Fundamentals of Engineering (FE) and Principles and Practice of Engineering (PE) Structural Exams?. (arXiv:2303.18149v1 [cs.CL])

    [http://arxiv.org/abs/2303.18149](http://arxiv.org/abs/2303.18149)

    本论文探讨了AI聊天机器人能否通过工程基础（FE）和工程原理与实践（PE）考试，研究发现ChatGPT-4在FE考试中得分70.9％，在PE考试中得分46.2％，并且有望通过PE考试。

    

    在工程界，随着OpenAI ChatGPT-4和Google Bard的发布，聊天机器人技术近年来迅速发展。虽然这些聊天机器人被报道表现良好，甚至通过了各种标准化考试，包括医学和法律考试，但本论文探讨这些聊天机器人是否也能通过工程基础（FE）和工程原理与实践（PE）考试。我们使用多样化的土木和环境工程问题和情景来评估聊天机器人的性能，在FE和PE考试中常见。基于相关性、准确性和清晰度，分析了聊天机器人的响应，然后与National Council of Examiners for Engineering and Surveying (NCEES)的建议进行了比较。我们的报告显示，ChatGPT-4和Bard在FE考试中得分分别为70.9％和39.2％，在PE考试中得分分别为46.2％和41％。显然，目前版本的ChatGPT-4有可能通过PE考试，但在FE考试中成绩较低。

    The engineering community has recently witnessed the emergence of chatbot technology with the release of OpenAI ChatGPT-4 and Google Bard. While these chatbots have been reported to perform well and even pass various standardized tests, including medical and law exams, this forum paper explores whether these chatbots can also pass the Fundamentals of Engineering (FE) and Principles and Practice of Engineering (PE) exams. A diverse range of civil and environmental engineering questions and scenarios are used to evaluate the chatbots' performance, as commonly present in the FE and PE exams. The chatbots' responses were analyzed based on their relevance, accuracy, and clarity and then compared against the recommendations of the National Council of Examiners for Engineering and Surveying (NCEES). Our report shows that ChatGPT-4 and Bard, respectively scored 70.9% and 39.2% in the FE exam and 46.2% and 41% in the PE exam. It is evident that the current version of ChatGPT-4 could potentially
    
[^5]: BERTino：一种意大利DistilBERT模型

    BERTino: an Italian DistilBERT model. (arXiv:2303.18121v1 [cs.CL])

    [http://arxiv.org/abs/2303.18121](http://arxiv.org/abs/2303.18121)

    本文介绍了BERTino，一种轻量级的DistilBERT模型，是用于意大利语的第一个替代BERT体系结构的选择，其在多项任务中F1分数与BERTBASE相当并显著提高了训练和推理速度。

    

    最近引入的Transformer语言表示模型在许多自然语言处理任务中取得了很大的改进。然而，这种体系结构的性能虽然惊人，但由于构成其网络的参数过多，导致计算和存储需求高，限制了它们的可用性。本文介绍了BERTino，一种DistilBERT模型，它是用于意大利语的第一个轻量级替代BERT体系结构的选择。我们对BERTino在意大利ISDT、意大利ParTUT、意大利WikiNER和多类分类任务上进行了评估，在训练和推理速度方面获得了显著提高，并获得了与BERTBASE相当的F1分数。

    The recent introduction of Transformers language representation models allowed great improvements in many natural language processing (NLP) tasks. However, if on one hand the performances achieved by this kind of architectures are surprising, on the other their usability is limited by the high number of parameters which constitute their network, resulting in high computational and memory demands. In this work we present BERTino, a DistilBERT model which proposes to be the first lightweight alternative to the BERT architecture specific for the Italian language. We evaluated BERTino on the Italian ISDT, Italian ParTUT, Italian WikiNER and multiclass classification tasks, obtaining F1 scores comparable to those obtained by a BERTBASE with a remarkable improvement in training and inference speed.
    
[^6]: UKP-SQuARE v3：一个多智能体QA研究平台

    UKP-SQuARE v3: A Platform for Multi-Agent QA Research. (arXiv:2303.18120v1 [cs.CL])

    [http://arxiv.org/abs/2303.18120](http://arxiv.org/abs/2303.18120)

    UKP-SQuARE v3是一个支持多智能体系统的QA研究平台，与多数据集模型相比，结合专家智能体可以获得更好的性能提升。

    

    问题回答（QA）数据集的不断发展已引起研究界对多领域模型的关注。一种常见的方法是使用多数据集模型，这些模型经过多个数据集的训练，以学习它们的规律并防止对单个数据集过度拟合。然而，随着在线代码库（如GitHub或Hugging Face）中QA模型的激增，另一种方法正在变得可行。最近的研究表明，结合专家智能体可以比多数据集模型获得更大的性能提升。为了方便多智能体模型的研究，我们将UKP-SQuARE扩展为支持三种多智能体系统：i）智能体选择，ii）智能体的早期融合，以及iii）智能体的后期融合。我们进行实验以评估它们的推断速度，并与多数据集模型进行性能与速度权衡的讨论。UKP-SQuARE是开源的，公开可用。

    The continuous development of Question Answering (QA) datasets has drawn the research community's attention toward multi-domain models. A popular approach is to use multi-dataset models, which are models trained on multiple datasets to learn their regularities and prevent overfitting to a single dataset. However, with the proliferation of QA models in online repositories such as GitHub or Hugging Face, an alternative is becoming viable. Recent works have demonstrated that combining expert agents can yield large performance gains over multi-dataset models. To ease research in multi-agent models, we extend UKP-SQuARE, an online platform for QA research, to support three families of multi-agent systems: i) agent selection, ii) early-fusion of agents, and iii) late-fusion of agents. We conduct experiments to evaluate their inference speed and discuss the performance vs. speed trade-off compared to multi-dataset models. UKP-SQuARE is open-source and publicly available at this http URL
    
[^7]: 爱丁堡国际英语口音语料库：迈向英语语音识别（ASR）的民主化

    The Edinburgh International Accents of English Corpus: Towards the Democratization of English ASR. (arXiv:2303.18110v1 [cs.CL])

    [http://arxiv.org/abs/2303.18110](http://arxiv.org/abs/2303.18110)

    爱丁堡国际英语口音语料库（EdAcc）发布，包括英语的广泛多样性和每个说话者的语言背景概况。在 EdAcc 上训练的最佳模型明显优于所有现有模型，这突显了当前英语ASR模型的缺点。这一数据集的公开共享将有助于民主化英语语音识别研究和开发。

    

    英语是世界上使用最广泛的语言，每天有数百万人使用英语作为第一或第二语言，在许多不同的语境中使用。因此，英语有许多变体。虽然过去几十年来英语自动语音识别（ASR）取得了许多进展，但通常基于测试数据集报告的结果未能代表今天全球使用的多样化英语。我们提出了首个爱丁堡国际英语口音语料库（EdAcc）的版本。此数据集试图更好地代表英语的广泛多样性，包括约40小时的朋友之间的二元视频通话。与其他数据集不同，EdAcc包括广泛的英语第一语言和第二语言变体以及每个人的语言背景概况。最新公共和商业模型的结果显示，EdAcc强调了当前英语ASR模型的缺点。在680个转录的EdAcc对话上训练的表现最佳的模型在这个数据集上明显优于所有现有模型。该数据集是公开的，我们希望它能为民主化英语ASR研究和开发做出贡献。

    English is the most widely spoken language in the world, used daily by millions of people as a first or second language in many different contexts. As a result, there are many varieties of English. Although the great many advances in English automatic speech recognition (ASR) over the past decades, results are usually reported based on test datasets which fail to represent the diversity of English as spoken today around the globe. We present the first release of The Edinburgh International Accents of English Corpus (EdAcc). This dataset attempts to better represent the wide diversity of English, encompassing almost 40 hours of dyadic video call conversations between friends. Unlike other datasets, EdAcc includes a wide range of first and second-language varieties of English and a linguistic background profile of each speaker. Results on latest public, and commercial models show that EdAcc highlights shortcomings of current English ASR models. The best performing model, trained on 680 t
    
[^8]: 多语种时间和数字表达式的抽取和规范化数据集和基线系统

    Dataset and Baseline System for Multi-lingual Extraction and Normalization of Temporal and Numerical Expressions. (arXiv:2303.18103v1 [cs.CL])

    [http://arxiv.org/abs/2303.18103](http://arxiv.org/abs/2303.18103)

    该论文描述了一个覆盖14种语言、多元化的时间和数字表达式，包括提取、规范化和解析的多语言数据集(NTX)，并提供了一个强大的基于规则的系统作为评估其他模型的比较基准。

    

    在许多自然语言处理和信息检索任务中，时间和数字表达式的理解非常重要。然而，大多数以前的工作仅涵盖了少量的子类型，并且只关注实体抽取，这严重限制了识别到的提及的可用性。为了在下游场景中使用这些实体，子类型的覆盖范围和粒度很重要；并且更加重要的是，提供可以操作的具体值解析。此外，大多数先前的工作仅处理几种语言。在这里，我们描述了一个多语言评估数据集-NTX-涵盖了14种语言的各种时间和数字表达式，并覆盖了提取，规范化和解析。除了数据集之外，我们还提供了一个强大的基于规则的系统作为与在该数据集中评估其他模型的比较的强大基准。数据和代码可在 \url{https://aka.ms/NTX}上获得。

    Temporal and numerical expression understanding is of great importance in many downstream Natural Language Processing (NLP) and Information Retrieval (IR) tasks. However, much previous work covers only a few sub-types and focuses only on entity extraction, which severely limits the usability of identified mentions. In order for such entities to be useful in downstream scenarios, coverage and granularity of sub-types are important; and, even more so, providing resolution into concrete values that can be manipulated. Furthermore, most previous work addresses only a handful of languages. Here we describe a multi-lingual evaluation dataset - NTX - covering diverse temporal and numerical expressions across 14 languages and covering extraction, normalization, and resolution. Along with the dataset we provide a robust rule-based system as a strong baseline for comparisons against other models to be evaluated in this dataset. Data and code are available at \url{https://aka.ms/NTX}.
    
[^9]: 解决形态学类比问题：从检索到生成

    Solving morphological analogies: from retrieval to generation. (arXiv:2303.18062v1 [cs.CL])

    [http://arxiv.org/abs/2303.18062](http://arxiv.org/abs/2303.18062)

    该论文提出了一个基于深度学习和条件变分自编码器的框架来解决基于类比的推理中的类比检测和解决两个任务，该框架可以生成之前不存在于数据集中的类比。

    

    类比推理是人类思维的一种非凡能力，并且已被用来解决难以理解的任务。 基于类比的推理（AR）受到了人工智能社区的越来越多的关注，并在多个机器学习任务中表现出其潜力，例如分类，决策和具有竞争性结果的推荐。 我们提出了一个基于深度学习（DL）的框架来解决AR中的两个关键任务：类比检测和解决。该框架在整个Siganalogies数据集上进行了全面测试，该数据集包含单词之间的形态学类比比例（APs），并且在许多语言中显示出优于符号方法的表现。 之前的工作已经探索了分类问题上的类比神经网络行为（ANNc）和检索问题上的类比神经网络行为（ANNr），以及自编码器（AE）在生成解决方案单词上的潜力。 在本文中，我们通过提出一个基于条件变分自编码器（CVAE）的统一框架来总结并扩展以前的工作，该框架可以共同解决两个任务。我们提出的框架可以生成在数据集中以前不存在的类比。

    Analogical inference is a remarkable capability of human reasoning, and has been used to solve hard reasoning tasks. Analogy based reasoning (AR) has gained increasing interest from the artificial intelligence community and has shown its potential in multiple machine learning tasks such as classification, decision making and recommendation with competitive results. We propose a deep learning (DL) framework to address and tackle two key tasks in AR: analogy detection and solving. The framework is thoroughly tested on the Siganalogies dataset of morphological analogical proportions (APs) between words, and shown to outperform symbolic approaches in many languages. Previous work have explored the behavior of the Analogy Neural Network for classification (ANNc) on analogy detection and of the Analogy Neural Network for retrieval (ANNr) on analogy solving by retrieval, as well as the potential of an autoencoder (AE) for analogy solving by generating the solution word. In this article we sum
    
[^10]: 没有藏身之地：基于数据增强的双重深度交互通道网络用于假新闻检测

    No Place to Hide: Dual Deep Interaction Channel Network for Fake News Detection based on Data Augmentation. (arXiv:2303.18049v1 [cs.CL])

    [http://arxiv.org/abs/2303.18049](http://arxiv.org/abs/2303.18049)

    本文提出了一个新的假新闻检测框架，从语义、情感和数据增强的角度挖掘了新闻中的独特关键特征和演化模式，设计了一种考虑评论的语义和情感的双重深度交互通道网络来获取更全面和细粒度的新闻表示，并引入数据增强模块解决样本不足的问题。

    

    在线社交网络（OSN）因信息传播成本低而成为假新闻的温床。尽管现有方法在新闻内容和传播结构方面已经做出了许多尝试，但是检测假新闻仍面临两个挑战：一是如何挖掘独特的关键特征和演化模式，二是如何解决小样本问题来构建高性能模型。与利用传播拓扑结构的流行方法不同，本文从语义、情感和数据增强的角度提出了一个新的假新闻检测框架，挖掘了新闻参与者在传播过程中的情感演化模式，并设计了一种语义和情感的双重深度交互通道网络，考虑了评论以获得更全面和细粒度的新闻表示。同时，该框架引入了数据增强模块来解决训练样本不足的问题。实验结果表明了我们提出的方法的有效性和优越性。

    Online Social Network (OSN) has become a hotbed of fake news due to the low cost of information dissemination. Although the existing methods have made many attempts in news content and propagation structure, the detection of fake news is still facing two challenges: one is how to mine the unique key features and evolution patterns, and the other is how to tackle the problem of small samples to build the high-performance model. Different from popular methods which take full advantage of the propagation topology structure, in this paper, we propose a novel framework for fake news detection from perspectives of semantic, emotion and data enhancement, which excavates the emotional evolution patterns of news participants during the propagation process, and a dual deep interaction channel network of semantic and emotion is designed to obtain a more comprehensive and fine-grained news representation with the consideration of comments. Meanwhile, the framework introduces a data enhancement mod
    
[^11]: 在日本医疗执照考试中评估GPT-4和ChatGPT

    Evaluating GPT-4 and ChatGPT on Japanese Medical Licensing Examinations. (arXiv:2303.18027v1 [cs.CL])

    [http://arxiv.org/abs/2303.18027](http://arxiv.org/abs/2303.18027)

    本文评估了GPT-4、ChatGPT和GPT-3在日本医疗执照考试中的表现，结果发现GPT-4优于其他两者，呈现出LLMs在与英语远离的语言中的潜力，但目前的LLM API存在一些限制，例如建议实施禁止的医疗选择。

    

    随着大型语言模型（LLMs）在不同语言的使用者中越来越受欢迎，我们认为对它们进行基准测试以更好地理解其在英语以外的语言中的行为、失误和限制至关重要。在本文中，我们评估了LLM API（ChatGPT、GPT-3和GPT-4）在过去5年的日本国家医疗执照考试中的表现。我们的团队包括以日语为母语的NLP研究人员和在日本工作的一名实践心脏病医师。我们的实验表明，GPT-4表现优于ChatGPT和GPT-3，并通过了所有五年的考试，突显LLMs在与英语远离的语言中的潜力。然而，我们的评估还暴露了当前LLM API的一些限制。首先，LLMs有时会选择在日本医疗实践中应该严格避免的禁止选择，例如建议实施安乐死。此外，我们的分析显示，API成本普遍较高，最大上下文大小较小。

    As large language models (LLMs) gain popularity among speakers of diverse languages, we believe that it is crucial to benchmark them to better understand model behaviors, failures, and limitations in languages beyond English. In this work, we evaluate LLM APIs (ChatGPT, GPT-3, and GPT-4) on the Japanese national medical licensing examinations from the past five years. Our team comprises native Japanese-speaking NLP researchers and a practicing cardiologist based in Japan. Our experiments show that GPT-4 outperforms ChatGPT and GPT-3 and passes all five years of the exams, highlighting LLMs' potential in a language that is typologically distant from English. However, our evaluation also exposes critical limitations of the current LLM APIs. First, LLMs sometimes select prohibited choices that should be strictly avoided in medical practice in Japan, such as suggesting euthanasia. Further, our analysis shows that the API costs are generally higher and the maximum context size is smaller fo
    
[^12]: 通过对抗学习利用多语种来进行低资源神经机器翻译

    Exploiting Multilingualism in Low-resource Neural Machine Translation via Adversarial Learning. (arXiv:2303.18011v1 [cs.CL])

    [http://arxiv.org/abs/2303.18011](http://arxiv.org/abs/2303.18011)

    本文提出了一种基于去噪对抗自编码器的句子插值方法，以及利用多语种模型生成句子进行奖励计算的Wasserstein-GAN方法来优化多语种神经机器翻译模型的性能。

    

    生成式对抗网络（GAN）为神经机器翻译（NMT）提供了一种有前途的方法。然而，在训练期间将多个形态语言提供给单个模型会降低NMT的性能。在GAN中，与双语模型类似，多语种NMT仅在模型训练期间考虑一个参考翻译的每个句子。这个单一的参考翻译限制了GAN模型从源句子表示中学习足够的信息。因此，在本文中，我们提出了一种基于去噪对抗自编码器的句子插值（DAASI）方法，通过学习多语种语言对的源句子和目标句子的中间潜在表示来执行句子插值。除了潜在表示之外，我们还使用Wasserstein-GAN方法进行多语种NMT模型，将多种语言的模型生成句子并与参考翻译一起用于奖励计算。这个计算出的奖励优化了表现。

    Generative Adversarial Networks (GAN) offer a promising approach for Neural Machine Translation (NMT). However, feeding multiple morphologically languages into a single model during training reduces the NMT's performance. In GAN, similar to bilingual models, multilingual NMT only considers one reference translation for each sentence during model training. This single reference translation limits the GAN model from learning sufficient information about the source sentence representation. Thus, in this article, we propose Denoising Adversarial Auto-encoder-based Sentence Interpolation (DAASI) approach to perform sentence interpolation by learning the intermediate latent representation of the source and target sentences of multilingual language pairs. Apart from latent representation, we also use the Wasserstein-GAN approach for the multilingual NMT model by incorporating the model generated sentences of multiple languages for reward computation. This computed reward optimizes the perform
    
[^13]: $\mathcal{E}$ K\'U [MASK]: 将尤鲁巴文化问候语整合到机器翻译中

    $\mathcal{E}$ K\'U [MASK]: Integrating Yor\`ub\'a cultural greetings into machine translation. (arXiv:2303.17972v1 [cs.CL])

    [http://arxiv.org/abs/2303.17972](http://arxiv.org/abs/2303.17972)

    本文研究了将尤鲁巴文化问候语（$\mathcal{E}$ k\'u [MASK]）整合到机器翻译中，通过IkiniYor\`ub\'a数据集，我们发现大规模多语言神经机器翻译（NMT）系统无法准确翻译，而微调现有的NMT模型在翻译中有更好的表现。

    

    本文研究了大规模多语言神经机器翻译（NMT）系统在将尤鲁巴语问候语（$\mathcal{E}$ k\'u [MASK]）翻译成英文时的表现。为了评估这些模型，我们介绍了一个尤鲁巴语-英语翻译数据集IkiniYor\`ub\'a，其中包含尤鲁巴语问候语和样例用例。我们分析了包括Google和NLLB在内的不同多语言NMT系统的表现，并显示这些模型在准确翻译尤鲁巴语问候语到英语时存在困难。此外，我们通过在IkiniYor\`ub\'a的训练集上微调现有的NMT模型来训练一个尤鲁巴语-英语模型，与预训练的多语言NMT模型相比，其表现更好，尽管它们经过大量数据的训练。

    This paper investigates the performance of massively multilingual neural machine translation (NMT) systems in translating Yor\`ub\'a greetings ($\mathcal{E}$ k\'u [MASK]), which are a big part of Yor\`ub\'a language and culture, into English. To evaluate these models, we present IkiniYor\`ub\'a, a Yor\`ub\'a-English translation dataset containing some Yor\`ub\'a greetings, and sample use cases. We analysed the performance of different multilingual NMT systems including Google and NLLB and show that these models struggle to accurately translate Yor\`ub\'a greetings into English. In addition, we trained a Yor\`ub\'a-English model by finetuning an existing NMT model on the training split of IkiniYor\`ub\'a and this achieved better performance when compared to the pre-trained multilingual NMT models, although they were trained on a large volume of data.
    
[^14]: 修剪语音对齐改善从多语种词汇表中推断音对应模式的方法

    Trimming Phonetic Alignments Improves the Inference of Sound Correspondence Patterns from Multilingual Wordlists. (arXiv:2303.17932v1 [cs.CL])

    [http://arxiv.org/abs/2303.17932](http://arxiv.org/abs/2303.17932)

    本文提出在比较语言学中，通过修剪语音对齐来自动改进对准同源词数据的方法，经测试其效果明显优于其他方法，可以显著提高从多语种词汇表中正确推断音对应模式的能力。

    

    音对应模式是历史语言比较中同源词检测和音系重建的基础。已经提出了从语音对齐同源词集中自动推断对应模式的方法，但将它们应用于多语种词汇表需要非常好的注释数据集。由于注释是费时费力的，因此找到自动改进对准同源词数据的方法是可取的。受进化生物学中改进对准的修剪技术的启发，我们提出了一种在推断对应关系之前修剪比较语言学中的语音对齐的工作流程。在使用来自不同语言家族的专家注释的大型标准化数据集上测试这些技术后，我们发现最佳修剪技术显著提高了对齐的整体一致性。结果显示在从多语种词汇表中正确推断音对应模式的能力上有明显影响。

    Sound correspondence patterns form the basis of cognate detection and phonological reconstruction in historical language comparison. Methods for the automatic inference of correspondence patterns from phonetically aligned cognate sets have been proposed, but their application to multilingual wordlists requires extremely well annotated datasets. Since annotation is tedious and time consuming, it would be desirable to find ways to improve aligned cognate data automatically. Taking inspiration from trimming techniques in evolutionary biology, which improve alignments by excluding problematic sites, we propose a workflow that trims phonetic alignments in comparative linguistics prior to the inference of correspondence patterns. Testing these techniques on a large standardized collection of ten datasets with expert annotations from different language families, we find that the best trimming technique substantially improves the overall consistency of the alignments. The results show a clear 
    
[^15]: 通过智能推荐工作和过滤求职者的选项的JobHam-place。

    JobHam-place with smart recommend job options and candidate filtering options. (arXiv:2303.17930v1 [cs.CL])

    [http://arxiv.org/abs/2303.17930](http://arxiv.org/abs/2303.17930)

    本论文设计了一个名为JobHam-place的智能求职系统，其包含工作推荐、简历排名及职位仪表板等功能，通过自动关键字提取和Job/CV排名算法实现，同时提出了一种新的基于词嵌入和余弦相似性的算法来匹配工作要求和求职者技能，实验结果表明系统具有准确的工作推荐和简历排名能力。

    

    随着毕业生人数的增加，许多求职应聘者经常遇到找工作的难题，而雇主则经常遇到难以过滤求职者的情况，这可能会对他们的效率产生负面影响。然而，大多数求职网站缺乏工作推荐、简历过滤或排名功能，这些功能没有整合到系统中。因此，本项目将实现一个智能求职系统，其中包含工作推荐、简历排名甚至带有技能和求职者功能的职位仪表板。工作推荐和简历排名从自动关键字提取开始，以Job/CV排名算法结束。自动关键字提取由Job2Skill和基于Bert的CV2Skill模型实现。Job2Skill由文本编码器和基于门控循环单元的层组成，而CV2Skill主要基于Bert，并通过简历实体数据集微调预训练模型。此外，为了将工作要求中的技能与求职者技能匹配，提出了一种基于词嵌入和余弦相似性的新算法。最后，我们系统在真实数据上进行了评估，实验结果表明，提出的系统可以提供准确的工作推荐和简历排名。

    Due to the increasing number of graduates, many applicants experience the situation about finding a job, and employers experience difficulty filtering job applicants, which might negatively impact their effectiveness. However, most job-hunting websites lack job recommendation and CV filtering or ranking functionality, which are not integrated into the system. Thus, a smart job hunter combined with the above functionality will be conducted in this project, which contains job recommendations, CV ranking and even a job dashboard for skills and job applicant functionality. Job recommendation and CV ranking starts from the automatic keyword extraction and end with the Job/CV ranking algorithm. Automatic keyword extraction is implemented by Job2Skill and the CV2Skill model based on Bert. Job2Skill consists of two components, text encoder and Gru-based layers, while CV2Skill is mainly based on Bert and fine-tunes the pre-trained model by the Resume- Entity dataset. Besides, to match skills fr
    
[^16]: 跨文化迁移学习在中文恶意语言检测中的应用

    Cross-Cultural Transfer Learning for Chinese Offensive Language Detection. (arXiv:2303.17927v1 [cs.CL])

    [http://arxiv.org/abs/2303.17927](http://arxiv.org/abs/2303.17927)

    本文研究了跨文化迁移学习在中文恶意语言检测上的应用，发现特定文化背景下的偏见会对语言模型的可迁移性产生负面影响。此研究结果支持在模型训练时考虑多元文化背景，以提高恶意语言检测的效果。

    

    恶意语言的检测是一项具有挑战性的任务，而在不同文化和语言之间进行概括则变得更加困难：除了词汇、句法和语义上的差异外，文化规范和敏感性等语用方面的因素在这种情况下变化很大。本文针对中文恶意语言检测，旨在探究使用来自不同文化背景（韩语和英语）的数据实现迁移学习的影响。我们发现，特定文化对什么被视为恶意的偏见会对语言模型的可迁移性产生负面影响，并且在多元文化数据上进行训练的语言模型对于中文恶意语言检测中的不同特征是敏感的。然而，在少量资源的 Few-shot 学习方案中，我们的研究显示了非英语恶意语言检测的有前途的前景。我们的研究结果强调了跨文化翻译学习在恶意语言检测中的重要性，以及在模型训练中应该纳入多元文化背景。

    Detecting offensive language is a challenging task. Generalizing across different cultures and languages becomes even more challenging: besides lexical, syntactic and semantic differences, pragmatic aspects such as cultural norms and sensitivities, which are particularly relevant in this context, vary greatly. In this paper, we target Chinese offensive language detection and aim to investigate the impact of transfer learning using offensive language detection data from different cultural backgrounds, specifically Korean and English. We find that culture-specific biases in what is considered offensive negatively impact the transferability of language models (LMs) and that LMs trained on diverse cultural data are sensitive to different features in Chinese offensive language detection. In a few-shot learning scenario, however, our study shows promising prospects for non-English offensive language detection with limited resources. Our findings highlight the importance of cross-cultural tra
    
[^17]: 非自回归神经机器翻译中的选择性知识蒸馏

    Selective Knowledge Distillation for Non-Autoregressive Neural Machine Translation. (arXiv:2303.17910v1 [cs.CL])

    [http://arxiv.org/abs/2303.17910](http://arxiv.org/abs/2303.17910)

    本论文介绍在非自回归神经机器翻译中引入选择性知识蒸馏和渐进蒸馏方法，并在实验中证明该方法可以在NAT模型的训练数据质量和复杂度之间实现灵活权衡，有助于NAT超越基线。

    

    通过序列级知识蒸馏的方式，非自回归变压器（NAT）在神经机器翻译任务中取得了巨大的成功。然而，现有的知识蒸馏存在副作用，如将教师机中的错误传播到NAT学生中，这可能限制NAT模型的进一步改进，并且很少在现有研究中讨论。本文通过引入一个NAT评估器来进行选择性知识蒸馏，选择高质量且易于学习的NAT友好目标。此外，我们引入了一种简单而有效的渐进蒸馏方法，以提高NAT性能。在多个WMT语言方向和几个代表性的NAT模型上进行实验结果显示，我们的方法可以实现NAT模型训练数据质量和复杂度之间的灵活权衡，达到了强大的性能。进一步的分析表明，只蒸馏5％的原始翻译就可以帮助NAT超越基线。

    Benefiting from the sequence-level knowledge distillation, the Non-Autoregressive Transformer (NAT) achieves great success in neural machine translation tasks. However, existing knowledge distillation has side effects, such as propagating errors from the teacher to NAT students, which may limit further improvements of NAT models and are rarely discussed in existing research. In this paper, we introduce selective knowledge distillation by introducing an NAT evaluator to select NAT-friendly targets that are of high quality and easy to learn. In addition, we introduce a simple yet effective progressive distillation method to boost NAT performance. Experiment results on multiple WMT language directions and several representative NAT models show that our approach can realize a flexible trade-off between the quality and complexity of training data for NAT models, achieving strong performances. Further analysis shows that distilling only 5% of the raw translations can help an NAT outperform i
    
[^18]: WebQAmGaze: 一份多语言Webcam阅读时眼动追踪数据集

    WebQAmGaze: A Multilingual Webcam Eye-Tracking-While-Reading Dataset. (arXiv:2303.17876v1 [cs.CL])

    [http://arxiv.org/abs/2303.17876](http://arxiv.org/abs/2303.17876)

    WebQAmGaze是一个多语言低成本的阅读时眼动追踪数据集，包括332位参与者的数据，对相关段落的注视似乎能够反映回答理解问题的准确性。这份数据可以推动基于网络摄像头的阅读研究并开辟更便宜、更易获得的数据收集方式。

    

    我们创建了WebQAmGaze，这是一个多语种低成本的阅读时眼动追踪数据集，旨在支持公平透明的自然语言处理模型的开发。WebQAmGaze包括了来自332位参与者阅读英语、西班牙语和德语文本时的网络摄像头眼动数据。每个参与者都会完成两个阅读任务，包括五篇文章的正常阅读和信息寻找任务。经过数据预处理，我们发现对相关段落的注视似乎意味着回答理解问题的正确性。此外，我们与高质量的眼动追踪数据进行了比较分析，结果显示Webcam-ET获得的特征与商业ET设备的特征之间存在中等的相关性。我们相信这份数据可以推动基于网络摄像头的阅读研究并开辟更便宜、更易获得的数据收集方式。WebQAmGaze对于了解问题回答的认知过程以及自然语言处理模型的公平透明具有实用价值。

    We create WebQAmGaze, a multilingual low-cost eye-tracking-while-reading dataset, designed to support the development of fair and transparent NLP models. WebQAmGaze includes webcam eye-tracking data from 332 participants naturally reading English, Spanish, and German texts. Each participant performs two reading tasks composed of five texts, a normal reading and an information-seeking task. After preprocessing the data, we find that fixations on relevant spans seem to indicate correctness when answering the comprehension questions. Additionally, we perform a comparative analysis of the data collected to high-quality eye-tracking data. The results show a moderate correlation between the features obtained with the webcam-ET compared to those of a commercial ET device. We believe this data can advance webcam-based reading studies and open a way to cheaper and more accessible data collection. WebQAmGaze is useful to learn about the cognitive processes behind question answering (QA) and to a
    
[^19]: AI能否让伽玛射线天体物理学家失业？

    Can AI Put Gamma-Ray Astrophysicists Out of a Job?. (arXiv:2303.17853v1 [physics.pop-ph])

    [http://arxiv.org/abs/2303.17853](http://arxiv.org/abs/2303.17853)

    本文评估了使用最先进的转换器模型创作一篇假的科学论文的能力，旨在验证这些模型是否能够仅基于语言信息解释天文观测和源，并为同行评审识别欺诈性生成的科学论文提供潜在手段。结论是，目前天文学家的工作是安全的。

    

    本文中，我们评估了最先进的转换器模型创作一篇文章的能力。这篇文章详细介绍了一种使用不存在的成像大气切伦科夫望远镜(IATC)阵列检测脉冲星风星云的方法。我们进行这项研究的目的是评估这些模型仅基于语言信息解释天文观测和源的能力，并评估在同行评议过程中如何识别诈骗生成的科学论文的潜在手段（考虑到这些工具尚未部署可靠的生成模型数字水印）。我们得出结论，天文学家的工作目前是安全的。

    In what will likely be a litany of generative-model-themed arXiv submissions celebrating April the 1st, we evaluate the capacity of state-of-the-art transformer models to create a paper detailing the detection of a Pulsar Wind Nebula with a non-existent Imaging Atmospheric Cherenkov Telescope (IACT) Array. We do this to evaluate the ability of such models to interpret astronomical observations and sources based on language information alone, and to assess potential means by which fraudulently generated scientific papers could be identified during peer review (given that reliable generative model watermarking has yet to be deployed for these tools). We conclude that our jobs as astronomers are safe for the time being. From this point on, prompts given to ChatGPT and Stable Diffusion are shown in orange, text generated by ChatGPT is shown in black, whereas analysis by the (human) authors is in blue.
    
[^20]: 从教学视频及其解说中学习过程感知的视频表示

    Learning Procedure-aware Video Representation from Instructional Videos and Their Narrations. (arXiv:2303.17839v1 [cs.CV])

    [http://arxiv.org/abs/2303.17839](http://arxiv.org/abs/2303.17839)

    本文提出了一种从教学视频及其解说中学习过程感知的视频表示方法，联合学习视频表示和深度概率模型可以增强过程推理的新功能，同时对个体步骤的识别也能得到加强。

    

    互联网上教学视频及其解说的丰富资源为理解过程活动提供了令人兴奋的途径。本文提出了一种学习视频表示的方法，该表示对基于大规模网络教学视频及其解说的个体步骤及其时间顺序进行编码，而不使用人工注释。方法联合学习视频表示和深度概率模型，以捕获步骤的时间依赖关系和巨大个体差异。实验证明，学习时间排序不仅能够增强过程推理的新功能，还可以加强对个体步骤的识别。我们的模型在步骤分类（在COIN/EPIC-Kitchens上分别增加2.8% / 3.3%）和步骤预测（在COIN上增加7.4%）方面显著提高了最先进的结果。此外，我们的模型在步骤提取的零样本推理方面取得了有希望的结果。

    The abundance of instructional videos and their narrations over the Internet offers an exciting avenue for understanding procedural activities. In this work, we propose to learn video representation that encodes both action steps and their temporal ordering, based on a large-scale dataset of web instructional videos and their narrations, without using human annotations. Our method jointly learns a video representation to encode individual step concepts, and a deep probabilistic model to capture both temporal dependencies and immense individual variations in the step ordering. We empirically demonstrate that learning temporal ordering not only enables new capabilities for procedure reasoning, but also reinforces the recognition of individual steps. Our model significantly advances the state-of-the-art results on step classification (+2.8% / +3.3% on COIN / EPIC-Kitchens) and step forecasting (+7.4% on COIN). Moreover, our model attains promising results in zero-shot inference for step c
    
[^21]: 探索大型语言模型在传统韩医中的潜力：基于基础模型的文化适应保健方法

    Exploring the Potential of Large Language models in Traditional Korean Medicine: A Foundation Model Approach to Culturally-Adapted Healthcare. (arXiv:2303.17807v1 [cs.CL])

    [http://arxiv.org/abs/2303.17807](http://arxiv.org/abs/2303.17807)

    本研究评估了大型语言模型在应用传统韩医的潜力。其中，GPT-4在应用韩国国家中医医生执照考试中取得了57.29%的准确率，潜在应用价值高。

    

    传统韩医注重个体化诊断和治疗，数据有限且过程隐性，使AI建模困难。GPT-3.5和GPT-4等大型语言模型尽管缺乏医学专业培训，但已显示出出色的医疗知识。本研究旨在评估GPT-3.5和GPT-4在应用韩国国家中医医生执照考试中的潜力。结果显示，GPT-3.5和GPT-4分别取得了42.06%和57.29%的准确率，其中GPT-4接近及格水平。

    Introduction: Traditional Korean medicine (TKM) emphasizes individualized diagnosis and treatment, making AI modeling difficult due to limited data and implicit processes. GPT-3.5 and GPT-4, large language models, have shown impressive medical knowledge despite lacking medicine-specific training. This study aimed to assess the capabilities of GPT-3.5 and GPT-4 for TKM using the Korean National Licensing Examination for Korean Medicine Doctors. Methods: GPT-3.5 (February 2023) and GPT-4 (March 2023) models answered 340 questions from the 2022 examination across 12 subjects. Each question was independently evaluated five times in an initialized session. Results: GPT-3.5 and GPT-4 achieved 42.06% and 57.29% accuracy, respectively, with GPT-4 nearing passing performance. There were significant differences in accuracy by subjects, with 83.75% accuracy for neuropsychiatry compared to 28.75% for internal medicine (2). Both models showed high accuracy in recall-based and diagnosis-based questi
    
[^22]: 基于对话行为的上下文适配器用于个性化语音识别

    Dialog act guided contextual adapter for personalized speech recognition. (arXiv:2303.17799v1 [cs.CL])

    [http://arxiv.org/abs/2303.17799](http://arxiv.org/abs/2303.17799)

    本文提出了一种基于对话行为的上下文适配器网络，该网络结合用户目录和对话行为，成功地解决了多轮对话的个性化语音识别问题，相对于无上下文模型实现了58%的平均相对词错误率降低。

    

    针对端到端自动语音识别（E2E ASR）模型中的多轮对话的个性化一直是一个长期的挑战。最近关于上下文适配器的研究解决了使用用户目录的罕见词汇识别。但是，这种适应性没有整合一个重要线索，即在多轮对话场景中可用的对话行为。在这项工作中，我们提出了一个基于对话行为的上下文适配器网络。具体而言，它利用对话行为来选择最相关的用户目录，并基于载体短语和用户目录之间的音频和语义关系创建查询，以更好地引导上下文偏置。在工业语音助手数据集上，我们的模型优于基线模型（仅对话行为编码器模型和上下文适应模型），并且相对于无上下文模型实现了最大的改进：在多轮对话场景中平均相对词错误率降低了58％。

    Personalization in multi-turn dialogs has been a long standing challenge for end-to-end automatic speech recognition (E2E ASR) models. Recent work on contextual adapters has tackled rare word recognition using user catalogs. This adaptation, however, does not incorporate an important cue, the dialog act, which is available in a multi-turn dialog scenario. In this work, we propose a dialog act guided contextual adapter network. Specifically, it leverages dialog acts to select the most relevant user catalogs and creates queries based on both -- the audio as well as the semantic relationship between the carrier phrase and user catalogs to better guide the contextual biasing. On industrial voice assistant datasets, our model outperforms both the baselines - dialog act encoder-only model, and the contextual adaptation, leading to the most improvement over the no-context model: 58% average relative word error rate reduction (WERR) in the multi-turn dialog scenario, in comparison to the prior
    
[^23]: CAMEL: 用于“心智”探索大规模语言模型社群的交互式代理

    CAMEL: Communicative Agents for "Mind" Exploration of Large Scale Language Model Society. (arXiv:2303.17760v1 [cs.AI])

    [http://arxiv.org/abs/2303.17760](http://arxiv.org/abs/2303.17760)

    本文介绍了一个名为角色扮演的新型交互式代理框架，用于实现语言模型之间的自主合作，并展示了其在生成对话数据方面的有效性。

    

    对话式语言模型的快速发展已取得了在复杂任务解决方面的显著进展。然而，它们的成功在很大程度上依赖于人类的指导，以引导对话，这可能是具有挑战性和耗时的。本文探讨了构建可扩展技术以促进交互式代理之间的自主合作并深入了解它们的“认知”过程的潜力。为了解决实现自主合作的挑战，我们提出了一个名为角色扮演的新型交互式代理框架。我们的方法涉及使用启动提示来引导聊天代理完成任务，同时保持与人类意图的一致性。我们展示了如何使用角色扮演来生成对话数据，以研究聊天代理的行为和能力，为研究对话式语言模型提供了有价值的资源。我们的贡献是介绍了一种新型的交互式代理框架，名为角色扮演，用于实现语言模型之间的自主合作，并展示了其在生成对话数据方面的有效性。

    The rapid advancement of conversational and chat-based language models has led to remarkable progress in complex task-solving. However, their success heavily relies on human input to guide the conversation, which can be challenging and time-consuming. This paper explores the potential of building scalable techniques to facilitate autonomous cooperation among communicative agents and provide insight into their "cognitive" processes. To address the challenges of achieving autonomous cooperation, we propose a novel communicative agent framework named role-playing. Our approach involves using inception prompting to guide chat agents toward task completion while maintaining consistency with human intentions. We showcase how role-playing can be used to generate conversational data for studying the behaviors and capabilities of chat agents, providing a valuable resource for investigating conversational language models. Our contributions include introducing a novel communicative agent framewor
    
[^24]: 基于合约的量子软件设计框架

    Design by Contract Framework for Quantum Software. (arXiv:2303.17750v1 [cs.CL])

    [http://arxiv.org/abs/2303.17750](http://arxiv.org/abs/2303.17750)

    该论文提出了一种基于合约的量子软件设计框架，用于自动确保量子电路构建过程的正确性，这对于验证量子电路的正确性具有重要意义。

    

    为了实现可靠的量子软件，最近研究了自动确保量子软件正确性的技术。然而，它们主要关注固定的量子电路，而不是构建量子电路的过程。尽管这是一种常见的方法，但使用不同参数按照相同的过程构建电路的正确性并不保证。为此，我们提出了一种量子软件的合约设计框架。我们的框架提供了一种嵌入python的语言，用于编写关于由某些过程构建的所有量子电路的输入和输出状态的断言。此外，它提供了一种方法，用于编写关于测量结果的统计处理的断言，以确保获得最终结果的过程的正确性。这些断言使用量子计算机模拟器自动检查。为了评估，我们实现了我们的框架，并为一些广泛使用的量子算法编写了assertions。

    To realize reliable quantum software, techniques to automatically ensure the quantum software's correctness have recently been investigated. However, they primarily focus on fixed quantum circuits rather than the procedure of building quantum circuits. Despite being a common approach, the correctness of building circuits using different parameters following the same procedure is not guaranteed. To this end, we propose a design-by-contract framework for quantum software. Our framework provides a python-embedded language to write assertions on the input and output states of all quantum circuits built by certain procedures. Additionally, it provides a method to write assertions about the statistical processing of measurement results to ensure the procedure's correctness for obtaining the final result. These assertions are automatically checked using a quantum computer simulator. For evaluation, we implemented our framework and wrote assertions for some widely used quantum algorithms. Cons
    
[^25]: 基于GPT和BERT的模型在生物医学文本中鉴定蛋白质相互作用的评估

    Evaluation of GPT and BERT-based models on identifying protein-protein interactions in biomedical text. (arXiv:2303.17728v1 [cs.CL])

    [http://arxiv.org/abs/2303.17728](http://arxiv.org/abs/2303.17728)

    该论文评估了预先训练的语言模型(GPT和BERT)识别生物医学文本中蛋白质相互作用的性能, 结果显示BERT模型表现最佳，其中PubMedBERT具有最高的精度和F1分数，BioM-ALBERT具有最高的召回率。

    

    检测蛋白质相互作用(PPIs)对于理解遗传机制、疾病发病机理和药物设计至关重要。然而，随着生物医学文献的快速增长，需要自动化和准确提取PPIs以促进科学知识的发掘。已经预先训练的语言模型，如生成式预训练变压器(GPT)和双向编码器表示变压器(BERT)，在自然语言处理(NLP)任务上表现出有希望的结果。我们使用手动编制的LLL基准语料库评估了各种GPT和BERT模型的PPI识别性能，该语料库包含77个句子中的164个PPIs。BERT模型取得了最佳的性能，其中PubMedBERT具有最高的精度(85.17%)和F1分数(86.47%)，BioM-ALBERT具有最高的召回率(93.83%)。尽管GPT-4没有专门针对生物医学文本进行训练，但其性能可与其他模型相媲美。

    Detecting protein-protein interactions (PPIs) is crucial for understanding genetic mechanisms, disease pathogenesis, and drug design. However, with the fast-paced growth of biomedical literature, there is a growing need for automated and accurate extraction of PPIs to facilitate scientific knowledge discovery. Pre-trained language models, such as generative pre-trained transformer (GPT) and bidirectional encoder representations from transformers (BERT), have shown promising results in natural language processing (NLP) tasks. We evaluated the PPI identification performance of various GPT and BERT models using a manually curated benchmark corpus of 164 PPIs in 77 sentences from learning language in logic (LLL). BERT-based models achieved the best overall performance, with PubMedBERT achieving the highest precision (85.17%) and F1-score (86.47%) and BioM-ALBERT achieving the highest recall (93.83%). Despite not being explicitly trained for biomedical texts, GPT-4 achieved comparable perfo
    
[^26]: 有哪些问题需要进行交谈才能回答？一个 AskReddit 问题案例的研究。

    What Types of Questions Require Conversation to Answer? A Case Study of AskReddit Questions. (arXiv:2303.17710v1 [cs.HC])

    [http://arxiv.org/abs/2303.17710](http://arxiv.org/abs/2303.17710)

    本文研究了哪些模糊开放性问题最适合通过对话回答，发现这些问题高度社交和个人化，对未来研究提供了有益的参考。

    

    自动会话系统（如聊天机器人、语音对话系统和智能音箱）的广泛应用已经深刻地影响了现代数字生活。然而，这些系统主要设计用于回答明确定义的问题，而非支持用户探索复杂的、不明确的问题。本文旨在通过研究哪些模糊的、开放性问题最适合通过对话来回答，推动会话系统的边界。我们首先从 AskReddit 上发布的100万个开放式请求中随机抽取了500个问题，然后招募在线工人回答这些问题的8个询问。我们还执行开放式编码，将问题分类为27个不同的领域。我们发现，人们认为需要交谈才能满意解决的问题是高度社交和个人化的。本文提供了未来研究如何适应用户需求的见解。

    The proliferation of automated conversational systems such as chatbots, spoken-dialogue systems, and smart speakers, has significantly impacted modern digital life. However, these systems are primarily designed to provide answers to well-defined questions rather than to support users in exploring complex, ill-defined questions. In this paper, we aim to push the boundaries of conversational systems by examining the types of nebulous, open-ended questions that can best be answered through conversation. We first sampled 500 questions from one million open-ended requests posted on AskReddit, and then recruited online crowd workers to answer eight inquiries about these questions. We also performed open coding to categorize the questions into 27 different domains. We found that the issues people believe require conversation to resolve satisfactorily are highly social and personal. Our work provides insights into how future research could be geared to align with users' needs.
    
[^27]: 面向任务的主观知识交互建模

    Task Oriented Conversational Modelling With Subjective Knowledge. (arXiv:2303.17695v1 [cs.CL])

    [http://arxiv.org/abs/2303.17695](http://arxiv.org/abs/2303.17695)

    本文提出了一种改进知识选择模块的实体检索方法，并探讨了一种潜在的关键字提取方法，以提高任务导向交互建模系统的性能。

    

    现有的对话模型都是基于数据库和API的系统来处理的。但是，用户的问题经常需要处理这些系统无法处理的信息。然而，这些问题的答案可以在客户评价和常见问题解答中找到。DSTC-11提出了一个由三个部分组成的管道，包括知识寻求回合检测、知识选择和响应生成，从而创建一个基于主观知识的交互式模型。本文着重于改进知识选择模块，以提高整个系统的性能。我们提出了一种实体检索方法，它可以实现准确和更快的知识搜索。我们提出的基于命名实体识别(NER)的实体检索方法比基线模型快了7倍。此外，我们还探讨了一种潜在的关键字提取方法，可以提高知识选择的准确性。初步结果显示了4\%的改进。

    Existing conversational models are handled by a database(DB) and API based systems. However, very often users' questions require information that cannot be handled by such systems. Nonetheless, answers to these questions are available in the form of customer reviews and FAQs. DSTC-11 proposes a three stage pipeline consisting of knowledge seeking turn detection, knowledge selection and response generation to create a conversational model grounded on this subjective knowledge. In this paper, we focus on improving the knowledge selection module to enhance the overall system performance. In particular, we propose entity retrieval methods which result in an accurate and faster knowledge search. Our proposed Named Entity Recognition (NER) based entity retrieval method results in 7X faster search compared to the baseline model. Additionally, we also explore a potential keyword extraction method which can improve the accuracy of knowledge selection. Preliminary results show a 4 \% improvement
    
[^28]: 用字符级噪音微调BERT实现零样本跨方言及相关语言迁移

    Fine-Tuning BERT with Character-Level Noise for Zero-Shot Transfer to Dialects and Closely-Related Languages. (arXiv:2303.17683v1 [cs.CL])

    [http://arxiv.org/abs/2303.17683](http://arxiv.org/abs/2303.17683)

    本研究使用字符级噪音微调BERT以实现对未见方言和语言的零样本跨语言迁移。本研究发现只有在任务依赖表面级别提示并且源-目标跨语言对具有相对较高的词汇重叠时，在微调过程中引入字符级噪音对跨语言迁移的效果才特别突出。

    

    本研究中，我们使用不同形式的字符级噪音进行BERT微调，以实现对未见方言和语言的零样本跨语言迁移。我们在三个句子级分类任务上微调BERT，并在一些未见方言和语言上评估了我们的方法。我们发现，在某些条件下，字符级噪音可以是跨语言迁移的极其有效的工具，而在其他情况下则不太有帮助。具体而言，我们通过任务的性质和源语言和目标语言之间的关系探讨了这些差异，发现在任务依赖表面级别提示并且源-目标跨语言对具有相对较高的词汇重叠时，在微调过程中引入字符级噪音特别有帮助。

    In this work, we induce character-level noise in various forms when fine-tuning BERT to enable zero-shot cross-lingual transfer to unseen dialects and languages. We fine-tune BERT on three sentence-level classification tasks and evaluate our approach on an assortment of unseen dialects and languages. We find that character-level noise can be an extremely effective agent of cross-lingual transfer under certain conditions, while it is not as helpful in others. Specifically, we explore these differences in terms of the nature of the task and the relationships between source and target languages, finding that introduction of character-level noise during fine-tuning is particularly helpful when a task draws on surface level cues and the source-target cross-lingual pair has a relatively high lexical overlap with shorter (i.e., less meaningful) unseen tokens on average.
    
[^29]: 自我反馈迭代精炼：一种无需监督学习或加强学习的LM改进框架

    Self-Refine: Iterative Refinement with Self-Feedback. (arXiv:2303.17651v1 [cs.CL])

    [http://arxiv.org/abs/2303.17651](http://arxiv.org/abs/2303.17651)

    自我反馈迭代精炼是一种无需监督学习或加强学习的LLMs初始输出优化方法，优于直接生成，被证实在7个不同任务中表现更好。

    

    鉴于语言模型(LLMs)不总是能在第一次良好地解决生成问题（如摘要、答案、解释等），我们引入自我反馈迭代精炼（SELF-REFINE）框架，通过迭代反馈和精炼相似地优化LLMs的初始输出。主要思想是：使用LLM生成输出，然后允许同一模型提供其自身输出的多方面反馈，最后利用反馈使相同模型精炼先前生成的输出。我们的迭代精炼框架与早期工作不同，无需监督训练数据或加强学习，并且可以与单个LLM一起使用。我们对七个不同的任务进行了实验，范围从评论重写到数学推理，表明我们的方法优于直接生成。在所有任务中，使用SELF-REFINE生成的输出被人类和自动化指标优先于使用GPT-3.5和GPT-4直接生成的输出，表现得更好。

    Like people, LLMs do not always generate the best text for a given generation problem on their first try (e.g., summaries, answers, explanations). Just as people then refine their text, we introduce SELF-REFINE, a framework for similarly improving initial outputs from LLMs through iterative feedback and refinement. The main idea is to generate an output using an LLM, then allow the same model to provide multi-aspect feedback for its own output; finally, the same model refines its previously generated output given its own feedback. Unlike earlier work, our iterative refinement framework does not require supervised training data or reinforcement learning, and works with a single LLM. We experiment with 7 diverse tasks, ranging from review rewriting to math reasoning, demonstrating that our approach outperforms direct generation. In all tasks, outputs generated with SELF-REFINE are preferred by humans and by automated metrics over those generated directly with GPT-3.5 and GPT-4, improving
    
[^30]: 通过盲审评估和文本分类算法比较ChatGPT生成的抽象摘要和真实摘要

    Comparing Abstractive Summaries Generated by ChatGPT to Real Summaries Through Blinded Reviewers and Text Classification Algorithms. (arXiv:2303.17650v1 [cs.CL])

    [http://arxiv.org/abs/2303.17650](http://arxiv.org/abs/2303.17650)

    本研究评估了ChatGPT在抽象概括方面的表现，自动化指标和盲审人员评估显示ChatGPT生成的摘要在人类视角下难以分辨真假。

    

    大型语言模型（LLMs）因其在各种任务上的出色表现而受到广泛关注。OpenAI开发的ChatGPT是语言模型家族的最新成员，由于其类人的文本生成能力，被一些人称为一项颠覆性技术。尽管网络上有许多ChatGPT的例子来评估其强弱之处，但只有少数系统性的研究存在。为了为ChatGPT的系统性研究做出贡献，我们通过自动化指标和盲审人员评估了ChatGPT在抽象概括方面的表现。我们还构建了自动文本分类器来检测ChatGPT生成的摘要。我们发现，虽然文本分类算法可以区分真实和生成的摘要，但人类无法区分真实摘要和ChatGPT生成的摘要。

    Large Language Models (LLMs) have gathered significant attention due to their impressive performance on a variety of tasks. ChatGPT, developed by OpenAI, is a recent addition to the family of language models and is being called a disruptive technology by a few, owing to its human-like text-generation capabilities. Although, many anecdotal examples across the internet have evaluated ChatGPT's strength and weakness, only a few systematic research studies exist. To contribute to the body of literature of systematic research on ChatGPT, we evaluate the performance of ChatGPT on Abstractive Summarization by the means of automated metrics and blinded human reviewers. We also build automatic text classifiers to detect ChatGPT generated summaries. We found that while text classification algorithms can distinguish between real and generated summaries, humans are unable to distinguish between real summaries and those produced by ChatGPT.
    
[^31]: 利用强化学习将一个中等大小的英文GPT模型对齐到西班牙语的小封闭领域中

    Aligning a medium-size GPT model in English to a small closed domain in Spanish using reinforcement learning. (arXiv:2303.17649v1 [cs.CL])

    [http://arxiv.org/abs/2303.17649](http://arxiv.org/abs/2303.17649)

    本文介绍了一种将英文GPT模型对齐到西班牙语的小封闭领域中的方法，该方法使用了奖励模型来改进答案的解码和生成，在问答任务中取得了良好的结果。

    

    本文提出了一种方法，将原本用于开放领域的中等大小英文GPT模型，对齐到西班牙语的小封闭领域。该模型被精细调整用于问答任务。为了实现这一目标，我们还需要训练和实现另一个神经网络（我们称之为奖励模型），以评分并确定答案是否适用于给定的问题。该组件有助于改进系统回答的解码和生成。 BLEU和perplexity等数字度量标准被用于评估模型，同时也使用人类判断来比较解码技术与其他技术。最终，结果支持了所提出的方法，并确定使用奖励模型来对齐生成回答是可行的。

    In this paper, we propose a methodology to align a medium-sized GPT model, originally trained in English for an open domain, to a small closed domain in Spanish. The application for which the model is finely tuned is the question answering task. To achieve this we also needed to train and implement another neural network (which we called the reward model) that could score and determine whether an answer is appropriate for a given question. This component served to improve the decoding and generation of the answers of the system. Numerical metrics such as BLEU and perplexity were used to evaluate the model, and human judgment was also used to compare the decoding technique with others. Finally, the results favored the proposed method, and it was determined that it is feasible to use a reward model to align the generation of responses.
    
[^32]: 检测和定位视觉故事中的重要人物

    Detecting and Grounding Important Characters in Visual Stories. (arXiv:2303.17647v1 [cs.CL])

    [http://arxiv.org/abs/2303.17647](http://arxiv.org/abs/2303.17647)

    该论文介绍了一个新的数据集 VIST-Character ，该数据集为以角色为中心的注释提供了一个标准，针对该数据集，论文提出了两个新任务，即重要人物检测和视觉故事中角色的定位，并基于分布相似性和预训练的视觉语言模型开发了简单的无监督模型。

    

    人物对于任何故事的情节都是至关重要的。在撰写故事之前建立人物可以提高情节的清晰度和整体叙事的流畅性。然而，以往关于视觉叙事的研究往往聚焦于在图像中检测物体并发现它们之间的关系。在这种方法中，当人物进入生成管道时不会与其他物体区分。结果是一个连贯的事件序列，而不是以角色为中心的故事。为了解决这种限制，我们介绍了 VIST-Character 数据集，该数据集提供了丰富的以角色为中心的注释，包括视觉和文本共指链和角色的重要性评级。基于此数据集，我们提出了两个新任务：重要人物检测和视觉故事中角色的定位。针对这两个任务，我们基于分布相似性和预训练的视觉语言模型，开发了简单的无监督模型。

    Characters are essential to the plot of any story. Establishing the characters before writing a story can improve the clarity of the plot and the overall flow of the narrative. However, previous work on visual storytelling tends to focus on detecting objects in images and discovering relationships between them. In this approach, characters are not distinguished from other objects when they are fed into the generation pipeline. The result is a coherent sequence of events rather than a character-centric story. In order to address this limitation, we introduce the VIST-Character dataset, which provides rich character-centric annotations, including visual and textual co-reference chains and importance ratings for characters. Based on this dataset, we propose two new tasks: important character detection and character grounding in visual stories. For both tasks, we develop simple, unsupervised models based on distributional similarity and pre-trained vision-and-language models. Our new datas
    
[^33]: oBERTa: 通过改进初始化、蒸馏和剪枝来提高稀疏迁移学习

    oBERTa: Improving Sparse Transfer Learning via improved initialization, distillation, and pruning regimes. (arXiv:2303.17612v1 [cs.CL])

    [http://arxiv.org/abs/2303.17612](http://arxiv.org/abs/2303.17612)

    oBERTa是一组易于使用的语言模型，通过改进初始化、蒸馏、剪枝等技术，可以在不需要模型压缩方面的专业知识的情况下提高稀疏迁移学习的效率和准确性。

    

    本文介绍了oBERTa语言模型的范围，它是一组易于使用的语言模型，允许自然语言处理（NLP）从业者在不需要模型压缩方面的专业知识的情况下获得3.8到24.3倍的更快速的模型。oBERTa扩展了现有的剪枝、知识蒸馏和量化工作，并利用冻结的嵌入来改进知识蒸馏，并改进模型初始化，以在广泛的传递任务上提供更高的准确性。在生成oBERTa时，我们探索了高度优化的RoBERTa与BERT在预训练和微调期间剪枝方面的不同之处，并发现它在微调期间不太适合压缩。我们探索了oBERTa在七个具有代表性的NLP任务上的使用，并发现改进的压缩技术使得经过剪枝的oBERTa模型能够匹配BERTBASE的性能，并超过SQUAD V1.1问答数据的Prune OFA Large的性能。

    In this paper, we introduce the range of oBERTa language models, an easy-to-use set of language models, which allows Natural Language Processing (NLP) practitioners to obtain between 3.8 and 24.3 times faster models without expertise in model compression. Specifically, oBERTa extends existing work on pruning, knowledge distillation, and quantization and leverages frozen embeddings to improve knowledge distillation, and improved model initialization to deliver higher accuracy on a a broad range of transfer tasks. In generating oBERTa, we explore how the highly optimized RoBERTa differs from the BERT with respect to pruning during pre-training and fine-tuning and find it less amenable to compression during fine-tuning. We explore the use of oBERTa on a broad seven representative NLP tasks and find that the improved compression techniques allow a pruned oBERTa model to match the performance of BERTBASE and exceed the performance of Prune OFA Large on the SQUAD V1.1 Question Answering data
    
[^34]: 评估ChatGPT与人类社会的跨文化对齐：一项实证研究

    Assessing Cross-Cultural Alignment between ChatGPT and Human Societies: An Empirical Study. (arXiv:2303.17466v1 [cs.CL])

    [http://arxiv.org/abs/2303.17466](http://arxiv.org/abs/2303.17466)

    本文通过分析ChatGPT对旨在量化人类文化差异的问题的回答，评估了其文化适应能力。发现ChatGPT在以美国背景为提示时表现出与美国文化的强烈对齐，但其对其他文化的适应能力较差，并且英文提示会抹平文化差异并偏向美国文化。

    

    近期发布的ChatGPT因其在对话中生成类人回应的卓越能力而广受认可。考虑到其被各国用户使用以及其训练了包含多样文化和社会规范的庞大多语料库，评估其文化适应能力至关重要。本文通过分析ChatGPT对旨在量化人类文化差异的问题的回答来调查其潜在的文化背景。我们的研究表明，当以美国背景为提示时，ChatGPT表现出与美国文化的强烈对齐，但其对其他文化背景的适应能力较差。此外，通过使用不同的提示来探测模型，我们发现英文提示会降低模型回答的差异，抹平文化差异并偏向美国文化。本研究对ChatGPT的文化影响提供了有价值的见解，并强调了进一步研究开发更具文化适应性的语言模型的必要性。

    The recent release of ChatGPT has garnered widespread recognition for its exceptional ability to generate human-like responses in dialogue. Given its usage by users from various nations and its training on a vast multilingual corpus that incorporates diverse cultural and societal norms, it is crucial to evaluate its effectiveness in cultural adaptation. In this paper, we investigate the underlying cultural background of ChatGPT by analyzing its responses to questions designed to quantify human cultural differences. Our findings suggest that, when prompted with American context, ChatGPT exhibits a strong alignment with American culture, but it adapts less effectively to other cultural contexts. Furthermore, by using different prompts to probe the model, we show that English prompts reduce the variance in model responses, flattening out cultural differences and biasing them towards American culture. This study provides valuable insights into the cultural implications of ChatGPT and highl
    
[^35]: “你指的是...？”：语义解析中的置信度权衡

    Did You Mean...? Confidence-based Trade-offs in Semantic Parsing. (arXiv:2303.16857v1 [cs.CL])

    [http://arxiv.org/abs/2303.16857](http://arxiv.org/abs/2303.16857)

    该论文介绍了如何通过校准的置信分数，平衡解析任务中的成本、标注员负担、准确性、可用性和安全性等多个权衡，提出了一个可以更好地平衡可用性和安全性的DidYouMean系统。

    

    我们演示了如何通过一个校准好的模型来平衡任务导向解析中的常见权衡。在一个模拟的标注员交互的实验中，我们展示了校准的置信分数如何平衡成本和标注员负担，用较少的交互提高准确性。然后，我们研究了置信度分数如何帮助优化可用性和安全性的权衡。我们展示了基于置信度阈值的解析错误数量大幅减少的系统DidYouMean，然而这也牺牲了可用性。

    We illustrate how a calibrated model can help balance common trade-offs in task-oriented parsing. In a simulated annotator-in-the-loop experiment, we show that well-calibrated confidence scores allow us to balance cost with annotator load, improving accuracy with a small number of interactions. We then examine how confidence scores can help optimize the trade-off between usability and safety. We show that confidence-based thresholding can substantially reduce the number of incorrect low-confidence programs executed; however, this comes at a cost to usability. We propose the DidYouMean system which better balances usability and safety.
    
[^36]: 没有正确性的可重复性并不重要：在NLP领域中测试代码的重要性。

    Reproducibility is Nothing without Correctness: The Importance of Testing Code in NLP. (arXiv:2303.16166v1 [cs.CL])

    [http://arxiv.org/abs/2303.16166](http://arxiv.org/abs/2303.16166)

    在NLP研究中，我们不能仅凭感知质量假定代码正确性，应该推动采用编码最佳实践以提高实验结果的正确性和可靠性。

    

    尽管其在研究实验中发挥了关键作用，但代码正确性往往仅基于结果的感知质量而被假定。这带来了错误结果和潜在误导性发现的风险。为了解决这个问题，我们认为当前关注结果重现应该与强调编码最佳实践相辅相成。我们通过一个案例研究来支持我们向NLP社区发出的号召，在这个案例研究中，我们识别出并纠正了广泛使用的最先进Conformer架构的开源实现中的三个Bug。通过在各种语言环境下进行的自动语音识别和翻译的比较实验，我们证明了Bug的存在并不会妨碍获得良好的和可重复的结果，反而可能导致不正确的结论，为未来的研究可能提供错误的指导。为了应对这一问题，这项研究呼吁采用旨在促进NLP研究中正确性的编码最佳实践，并提高实验结果的可靠性。

    Despite its pivotal role in research experiments, code correctness is often presumed only on the basis of the perceived quality of the results. This comes with the risk of erroneous outcomes and potentially misleading findings. To address this issue, we posit that the current focus on result reproducibility should go hand in hand with the emphasis on coding best practices. We bolster our call to the NLP community by presenting a case study, in which we identify (and correct) three bugs in widely used open-source implementations of the state-of-the-art Conformer architecture. Through comparative experiments on automatic speech recognition and translation in various language settings, we demonstrate that the existence of bugs does not prevent the achievement of good and reproducible results and can lead to incorrect conclusions that potentially misguide future research. In response to this, this study is a call to action toward the adoption of coding best practices aimed at fostering cor
    
[^37]: 大型语言模型生成混合代码文本的提示：东南亚语言的案例

    Prompting Large Language Models to Generate Code-Mixed Texts: The Case of South East Asian Languages. (arXiv:2303.13592v1 [cs.CL])

    [http://arxiv.org/abs/2303.13592](http://arxiv.org/abs/2303.13592)

    本文探讨了使用大型语言模型（LLMs）生成东南亚五种语言和Singlish的混合代码数据的方法，发现ChatGPT展现出最高的潜力。然而，由于词汇选择错误的影响，ChatGPT和InstructGPT在生成混合代码时的熟练程度受到限制。

    

    尽管混合代码在世界许多地区是一种常见的语言实践，但收集高质量且低成本的混合代码数据仍然是自然语言处理（NLP）研究的重大挑战。最近大型语言模型（LLMs）的普及迫使人们问：这些系统能用于数据生成吗？在本文中，我们探讨了在一个零-shot的方式下如何提示LLMs为东南亚（SEA）的五种语言（印尼语，马来语，中文，塔加路语，越南语）及克里奥尔语S ingl ish创造混合代码数据。我们发现，ChatGPT显示出最大的潜力，当明确定义“混合代码”术语时，能够68%的时间生成混合代码文本。此外，ChatGPT和InstructGPT（davinci-003）生成S ingl ish文本的表现也值得注意，它们在各种提示下的成功率平均为96%。但是，ChatGPT和InstructGPT的混合代码熟练程度受到词汇选择错误的影响，导致语义不正确的输出。

    While code-mixing is a common linguistic practice in many parts of the world, collecting high-quality and low-cost code-mixed data remains a challenge for natural language processing (NLP) research. The proliferation of Large Language Models (LLMs) in recent times compels one to ask: can these systems be used for data generation? In this article, we explore prompting LLMs in a zero-shot manner to create code-mixed data for five languages in South East Asia (SEA) -Indonesian, Malay, Chinese, Tagalog, Vietnamese, as well as the creole language Singlish. We find that ChatGPT shows the most potential, capable of producing code-mixed text 68% of the time when the term "code-mixing" is explicitly defined. Moreover, both ChatGPT and InstructGPT's (davinci-003) performances in generating Singlish texts are noteworthy, averaging a 96% success rate across a variety of prompts. The code-mixing proficiency of ChatGPT and InstructGPT, however, is dampened by word choice errors that lead to semant
    
[^38]: ChatGPT和新的学术现实：AI撰写的研究论文及大语言模型在学术出版中的伦理道德

    ChatGPT and a New Academic Reality: AI-Written Research Papers and the Ethics of the Large Language Models in Scholarly Publishing. (arXiv:2303.13367v1 [cs.CL])

    [http://arxiv.org/abs/2303.13367](http://arxiv.org/abs/2303.13367)

    本文讨论了使用自然语言处理生成文本的ChatGPT模型，该技术被认为可以成为自动准备学术论文及手稿的潜在模型，然而，其与类似模型潜在的伦理问题需要考虑和解决。

    

    本文探讨了OpenAI的ChatGPT，这是一个使用自然语言处理来满足基于文本的用户请求（即聊天机器人）的生成式预训练转换器。讨论了ChatGPT及类似模型背后的历史和原则。然后讨论了这种技术对学术和学术研究出版物可能产生的影响。ChatGPT被视为自动准备论文和其他类型学术手稿的潜在模型。讨论了可能随着大型语言模型（如ChatGPT背后的基础技术GPT-3）的出现和其被学术界和研究人员使用而出现的伦理问题，将其置于人工智能、机器学习和自然语言处理在研究和学术出版方面的更广泛进展的背景下。

    This paper discusses OpenAIs ChatGPT, a generative pre-trained transformer, which uses natural language processing to fulfill text-based user requests (i.e., a chatbot). The history and principles behind ChatGPT and similar models are discussed. This technology is then discussed in relation to its potential impact on academia and scholarly research and publishing. ChatGPT is seen as a potential model for the automated preparation of essays and other types of scholarly manuscripts. Potential ethical issues that could arise with the emergence of large language models like GPT-3, the underlying technology behind ChatGPT, and its usage by academics and researchers, are discussed and situated within the context of broader advancements in artificial intelligence, machine learning, and natural language processing for research and scholarly publishing.
    
[^39]: 大型语言模型的公正引导少样本提示

    Fairness-guided Few-shot Prompting for Large Language Models. (arXiv:2303.13217v1 [cs.CL])

    [http://arxiv.org/abs/2303.13217](http://arxiv.org/abs/2303.13217)

    本文提出了一种新的搜索策略-FairPrompt，在保证公正性的前提下，通过评估提示预测偏差，确定近似最优的提示，从而改进大型语言模型的上下文学习性能，实验表明该方法在准确性和公正性方面均优于现有方法。

    

    大型语言模型已经表现出惊人的能力，能够通过几个输入输出示例构建的提示进行直接应用来解决众多下游任务。但是，先前的研究表明，由于训练示例，示例顺序和提示格式的变化导致上下文学习容易出现高度不稳定性。因此，构建适当的提示对于改进上下文学习的性能至关重要。在这篇文章中，我们从预测偏差的角度重新探讨了这个问题。具体而言，我们引入了一个指标来评估固定提示相对于标签或给定属性的预测偏差。然后我们通过实验证明了预测偏差较大的提示总是导致不令人满意的预测质量。基于这个观察，我们提出了一种新的搜索策略，基于贪婪搜索来确定近似最优的提示，从而改进上下文学习的性能。我们提出的方法叫做"公正提示"，其中融入了公平性约束，以指导搜索不展现出对某些人群的偏见。我们在多种少样本分类任务上证明了FairPrompt的有效性，并展示了它在准确性和公正性方面均优于现有的最先进方法。

    Large language models have demonstrated surprising ability to perform in-context learning, i.e., these models can be directly applied to solve numerous downstream tasks by conditioning on a prompt constructed by a few input-output examples. However, prior research has shown that in-context learning can suffer from high instability due to variations in training examples, example order, and prompt formats. Therefore, the construction of an appropriate prompt is essential for improving the performance of in-context learning. In this paper, we revisit this problem from the view of predictive bias. Specifically, we introduce a metric to evaluate the predictive bias of a fixed prompt against labels or a given attributes. Then we empirically show that prompts with higher bias always lead to unsatisfactory predictive quality. Based on this observation, we propose a novel search strategy based on the greedy search to identify the near-optimal prompt for improving the performance of in-context l
    
[^40]: 基于百万用户的现实世界互动来奖励聊天机器人

    Rewarding Chatbots for Real-World Engagement with Millions of Users. (arXiv:2303.06135v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.06135](http://arxiv.org/abs/2303.06135)

    本文研究了如何通过利用用户反馈来提高聊天机器人的参与度，从而增强其留存能力。具体方法是使用自动伪标签来训练奖励模型，并使用平均对话长度一类的指标来衡量其效果。在试验中，该方法可将聊天机器人的平均对话长度提高70%。

    

    预先训练的大型语言模型的出现，导致部署了一系列的社交聊天机器人。虽然这些聊天机器人展示了其语言能力和流畅性，但它们并不能保证很有吸引力，很容易失去用户。本文研究了开发优先考虑用户参与度以增强留存的社交聊天机器人，具体探讨了使用人工反馈以高效地开发高度有吸引力的聊天机器人。提出的方法使用从用户交互中收集的自动伪标签来训练奖励模型，该模型可用于在推理时拒绝低得分的样本响应，以提高用户参与度。引入了直观的评估指标，例如平均对话长度（MCL），作为衡量已部署聊天机器人参与度水平的代理。在Chai Research平台上对每日的10,000个新聊天机器人用户进行A/B测试，结果表明，这种方法可使MCL增加70％，这相当于将留存时间延长1.5倍。

    The emergence of pretrained large language models has led to the deployment of a range of social chatbots for chitchat. Although these chatbots demonstrate language ability and fluency, they are not guaranteed to be engaging and can struggle to retain users. This work investigates the development of social chatbots that prioritize user engagement to enhance retention, specifically examining the use of human feedback to efficiently develop highly engaging chatbots. The proposed approach uses automatic pseudo-labels collected from user interactions to train a reward model that can be used to reject low-scoring sample responses generated by the chatbot model at inference time. Intuitive evaluation metrics, such as mean conversation length (MCL), are introduced as proxies to measure the level of engagement of deployed chatbots. A/B testing on groups of 10,000 new daily chatbot users on the Chai Research platform shows that this approach increases the MCL by up to 70%, which translates to a
    
[^41]: 融合多模态嵌入的跨目标立场检测的小样本学习

    Few-shot Learning for Cross-Target Stance Detection by Aggregating Multimodal Embeddings. (arXiv:2301.04535v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.04535](http://arxiv.org/abs/2301.04535)

    本文提出了一种称为CT-TN的模型，在社交媒体中进行跨目标立场检测，利用了任务的社交性质，通过聚合多模态嵌入来解决少样本情境下的问题。实验表明，该模型在六个不同的源-目标目标对上比最先进的跨目标立场检测模型表现更好。

    

    尽管立场检测任务越来越受欢迎，但现有方法主要限于使用社交媒体帖子的文本内容进行分类，忽略了任务的社交性质。在跨目标分类场景中，立场检测任务变得尤其具有挑战性，即使在少样本训练设置中，模型也需要预测对于其在训练期间仅看到少量相关示例的新目标的立场。为了利用任务的社交性质解决社交媒体中的跨目标立场检测问题，我们引入了CT-TN，这是一种新的模型，它聚合了数据的文本和网络特征派生的多模态嵌入。我们在六种不同的源-目标目标对的少样本跨目标场景下进行实验。通过将CT-TN与最先进的跨目标立场检测模型进行比较，我们证明了CT-TN模型的有效性。

    Despite the increasing popularity of the stance detection task, existing approaches are predominantly limited to using the textual content of social media posts for the classification, overlooking the social nature of the task. The stance detection task becomes particularly challenging in cross-target classification scenarios, where even in few-shot training settings the model needs to predict the stance towards new targets for which the model has only seen few relevant samples during training. To address the cross-target stance detection in social media by leveraging the social nature of the task, we introduce CT-TN, a novel model that aggregates multimodal embeddings derived from both textual and network features of the data. We conduct experiments in a few-shot cross-target scenario on six different combinations of source-destination target pairs. By comparing CT-TN with state-of-the-art cross-target stance detection models, we demonstrate the effectiveness of our model by achieving
    
[^42]: 使用任务算术编辑模型

    Editing Models with Task Arithmetic. (arXiv:2212.04089v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.04089](http://arxiv.org/abs/2212.04089)

    本文提出了一种使用任务向量进行模型编辑的新范式，任务向量可通过算术操作进行修改和组合，可以提高目标任务性能且对控制任务影响较小。

    

    改变预训练模型的行为方式（比如提高其在下游任务上的表现或减轻预训练期间学习到的偏差）是开发机器学习系统时常见的做法。本文提出了一种围绕“任务向量”来引导神经网络行为的新范式。任务向量指定了一个方向，即预训练模型权重空间中的方向，沿着该方向移动可以提高任务的表现。我们通过从经过微调任务后的相同模型的权重中减去预训练模型的权重来构建任务向量。我们展示了这些任务向量可以通过否定和加法等算术操作进行修改和组合，从而引导生成模型的行为。否定任务向量会降低目标任务的性能，而对控制任务的模型行为影响不大。此外，将任务向量相加可以提高目标任务的性能和控制任务的模型行为。

    Changing how pre-trained models behave -- e.g., improving their performance on a downstream task or mitigating biases learned during pre-training -- is a common practice when developing machine learning systems. In this work, we propose a new paradigm for steering the behavior of neural networks, centered around \textit{task vectors}. A task vector specifies a direction in the weight space of a pre-trained model, such that movement in that direction improves performance on the task. We build task vectors by subtracting the weights of a pre-trained model from the weights of the same model after fine-tuning on a task. We show that these task vectors can be modified and combined together through arithmetic operations such as negation and addition, and the behavior of the resulting model is steered accordingly. Negating a task vector decreases performance on the target task, with little change in model behavior on control tasks. Moreover, adding task vectors together can improve performanc
    
[^43]: CoP: 通过控制偏好检测文本的事实不一致性

    CoP: Factual Inconsistency Detection by Controlling the Preference. (arXiv:2212.01611v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.01611](http://arxiv.org/abs/2212.01611)

    CoP是一个无监督的框架，通过控制偏好来检测文本的事实不一致性。 实验证明其效果优于现有的最先进模型。

    

    抽象化摘要是根据输入文档生成摘要的过程。尽管已经取得了重大进展，但文档与生成的摘要之间的事实不一致性仍然限制了其实际应用。为了分离事实一致性的偏好，我们提出了一个无监督的框架，名为CoP，通过控制提示来控制生成模型的偏好。具体来说，该框架执行一个额外的推理步骤，在其中引入一个文本提示作为额外的输入。通过这种方式，另一个偏好由这个额外推理过程的生成概率描述。利用上述两个偏好之间的差异，即引入文本提示之前和之后的生成模型分配的概率之间的差异，来检测事实不一致性。实验表明，我们提出的CoP可以有效地检测事实不一致性，并在准确性和特异性方面优于现有的最先进模型。

    Abstractive summarization is the process of generating a summary given a document as input. Although significant progress has been made, the factual inconsistency between the document and the generated summary still limits its practical applications. Previous work found that the probabilities assigned by the generation model reflect its preferences for the generated summary, including the preference for factual consistency, and the preference for the language or knowledge prior as well. To separate the preference for factual consistency, we propose an unsupervised framework named CoP by controlling the preference of the generation model with the help of prompt. More specifically, the framework performs an extra inference step in which a text prompt is introduced as an additional input. In this way, another preference is described by the generation probability of this extra inference process. The difference between the above two preferences, i.e. the difference between the probabilities
    
[^44]: SexWEs: 通过跨语言语义专业化实现领域感知词向量来检测社交媒体中的中文性别歧视

    SexWEs: Domain-Aware Word Embeddings via Cross-lingual Semantic Specialisation for Chinese Sexism Detection in Social Media. (arXiv:2211.08447v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.08447](http://arxiv.org/abs/2211.08447)

    本文通过利用跨语言的领域感知语义专业化系统，在不采集新歧视数据或搭建跨语言转移学习模型的情况下，实现了对社交媒体中的中文性别歧视的自动检测。

    

    性别歧视检测的目标是减少针对某些性别群体的负面在线内容。然而，有限的带有性别歧视标签的数据集可用性使得在缺乏资源的语言中识别在线性别歧视成为一个问题。本文解决了自动检测社交媒体中中文性别歧视的任务。我们开发了一个跨语言的领域感知语义专业化系统，以充分利用现有数据。语义专业化是一种通过将外部语言知识（如词汇语义关系）集成到专业化特征空间中来改进预先训练的分布式词向量的技术。为此，我们利用高资源语言（英语）中的性别歧视语义资源来专业化目标语言（中文）中的预先训练的词向量以注入领域知识。

    The goal of sexism detection is to mitigate negative online content targeting certain gender groups of people. However, the limited availability of labeled sexism-related datasets makes it problematic to identify online sexism for low-resource languages. In this paper, we address the task of automatic sexism detection in social media for one low-resource language -- Chinese. Rather than collecting new sexism data or building cross-lingual transfer learning models, we develop a cross-lingual domain-aware semantic specialisation system in order to make the most of existing data. Semantic specialisation is a technique for retrofitting pre-trained distributional word vectors by integrating external linguistic knowledge (such as lexico-semantic relations) into the specialised feature space. To do this, we leverage semantic resources for sexism from a high-resource language (English) to specialise pre-trained word vectors in the target language (Chinese) to inject domain knowledge. We demons
    
[^45]: 校准解释：语义解析中的置信度估计

    Calibrated Interpretation: Confidence Estimation in Semantic Parsing. (arXiv:2211.07443v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.07443](http://arxiv.org/abs/2211.07443)

    该论文研究了常见的生成模型在四个流行的语义解析数据集上的校准性，并分析了与校准误差相关的因素。为了方便将校准纳入语义解析评估中，作者们发布了一个计算校准度量的库。

    

    序列生成模型越来越被用来将语言翻译成可执行程序，即执行语义解析。语义解析旨在执行现实世界中的动作，因此开发安全系统是有必要的，而测量校准则是安全的核心组成部分，因此尤其重要。我们研究常见生成模型在四个流行的语义解析数据集上的校准性，发现其在模型和数据集之间变化巨大。然后，我们分析与校准误差相关的因素，并发布了两个解析数据集的基于置信度的挑战拆分。为了方便将校准纳入语义解析评估中，我们发布了一个用于计算校准度量的库。

    Sequence generation models are increasingly being used to translate language into executable programs, i.e. to perform executable semantic parsing. The fact that semantic parsing aims to execute actions in the real world motivates developing safe systems, which in turn makes measuring calibration -- a central component to safety -- particularly important. We investigate the calibration of common generation models across four popular semantic parsing datasets, finding that it varies across models and datasets. We then analyze factors associated with calibration error and release new confidence-based challenge splits of two parsing datasets. To facilitate the inclusion of calibration in semantic parsing evaluations, we release a library for computing calibration metrics.
    
[^46]: 基于预训练语言模型的提示学习在阿尔茨海默病检测中的应用研究

    Exploiting prompt learning with pre-trained language models for Alzheimer's Disease detection. (arXiv:2210.16539v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.16539](http://arxiv.org/abs/2210.16539)

    本文提出一种基于提示学习的预训练语言模型方法，加入不流畅特征提高阿尔茨海默病检测性能。实验结果表明该方法在基准数据集上取得了最佳表现，最高准确率达到95.1%。

    

    阿尔茨海默病（AD）的早期诊断对于促进预防性护理和延缓疾病进程非常关键，基于语音的自动AD筛查系统为其他临床筛查技术提供了一种非侵入性且更具扩展性的替代方案。预训练语言模型（PLM）如BERT产生的文本嵌入特征被广泛应用在这样的系统中。然而，PLM领域微调通常基于掩蔽词或句子预测成本，这与后端AD检测任务不一致。因此，本文研究了使用基于提示的PLM微调，这种微调一致地使用AD分类错误作为训练目标函数。在PLM微调期间，在提示短语中进一步加入了基于犹豫或暂停填充符令牌频率的不流畅特征。对于使用不同PLMs（BERT和RoBERTa）或使用不同微调范例（传统机器学习和提示学习）的系统，基于决策投票的组合进一步增强了AD检测的性能。在基准AD语音数据集上，所提出的框架达到了高达95.1%的准确率，表现处于同类研究的最前沿。

    Early diagnosis of Alzheimer's disease (AD) is crucial in facilitating preventive care and to delay further progression. Speech based automatic AD screening systems provide a non-intrusive and more scalable alternative to other clinical screening techniques. Textual embedding features produced by pre-trained language models (PLMs) such as BERT are widely used in such systems. However, PLM domain fine-tuning is commonly based on the masked word or sentence prediction costs that are inconsistent with the back-end AD detection task. To this end, this paper investigates the use of prompt-based fine-tuning of PLMs that consistently uses AD classification errors as the training objective function. Disfluency features based on hesitation or pause filler token frequencies are further incorporated into prompt phrases during PLM fine-tuning. The decision voting based combination among systems using different PLMs (BERT and RoBERTa) or systems with different fine-tuning paradigms (conventional ma
    
[^47]: M-MELD：用于对话情感识别的多语言数据集

    M-MELD: A Multilingual Multi-Party Dataset for Emotion Recognition in Conversations. (arXiv:2203.16799v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.16799](http://arxiv.org/abs/2203.16799)

    本文提出了一个多语言的情感识别数据集M-MELD，扩展了MELD数据集到英语之外的4种语言，提出了一种新颖的架构DiscLSTM，该架构在对话中使用顺序和交际语境进行ERC，具有高效和跨语言传输等特点，表现良好。

    

    情感表达是日常人类交流中至关重要的部分。对话情感识别（ERC）是一个新兴的研究领域，其主要任务是识别对话中每个话语背后的情感。尽管过去已经对ERC进行了很多工作，但这些工作仅关注英语语言的ERC，忽略了其他任何语言。在本文中，我们提出了Multilingual MELD（M-MELD），将Multimodal EmotionLines数据集（MELD）扩展到英语之外的4种其他语言，分别为希腊语、波兰语、法语和西班牙语。除了为所有这4种语言建立强大的基线之外，我们还提出了一种新颖的架构DiscLSTM，它在对话中使用顺序和交际语境进行ERC。我们提出的方法计算效率高，可以使用跨语言编码器跨语言传输，并且比大多数单模态文本方法具有更好的性能。

    Expression of emotions is a crucial part of daily human communication. Emotion recognition in conversations (ERC) is an emerging field of study, where the primary task is to identify the emotion behind each utterance in a conversation. Though a lot of work has been done on ERC in the past, these works only focus on ERC in the English language, thereby ignoring any other languages. In this paper, we present Multilingual MELD (M-MELD), where we extend the Multimodal EmotionLines Dataset (MELD) \cite{poria2018meld} to 4 other languages beyond English, namely Greek, Polish, French, and Spanish. Beyond just establishing strong baselines for all of these 4 languages, we also propose a novel architecture, DiscLSTM, that uses both sequential and conversational discourse context in a conversational dialogue for ERC. Our proposed approach is computationally efficient, can transfer across languages using just a cross-lingual encoder, and achieves better performance than most uni-modal text approa
    
[^48]: 从自然语言到模拟：应用GPT-3 Codex自动化物流系统模拟建模

    From Natural Language to Simulations: Applying GPT-3 Codex to Automate Simulation Modeling of Logistics Systems. (arXiv:2202.12107v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2202.12107](http://arxiv.org/abs/2202.12107)

    该论文展示了自然语言处理的自动化能力应用到物流系统模拟建模中，证明了基于GPT-3 Codex的框架能够生成功能有效的排队和库存控制系统的模拟模型，为简化模拟模型开发工作流程开启了重要大门。

    

    本文是首次尝试使用自然语言处理自动化开发物流系统模拟模型。我们证明了在基于经过微调的GPT-3 Codex的框架上能够根据口头描述生成功能有效的排队和库存控制系统模拟模型。在所进行的实验中，GPT-3 Codex展现出对Python编程的深厚技能以及对行业特定词汇的理解。结果，该语言模型能够在给定行业特定场景下，根据流程说明和变量值列表生成单品库存控制系统和单服务器排队系统的模拟模型。这些结果的呈现，以及语言模型持续的迅速进步，打开了简化模拟模型开发工作流程的重要大门，这将有助于加快自动化物流系统的部署。

    Our work is the first attempt to apply Natural Language Processing to automate the development of simulation models of systems vitally important for logistics. We demonstrated that the framework built on top of the fine-tuned GPT-3 Codex, a Transformer-based language model, could produce functionally valid simulations of queuing and inventory control systems given the verbal description. In conducted experiments, GPT-3 Codex demonstrated convincing expertise in Python as well as an understanding of the domain-specific vocabulary. As a result, the language model could produce simulations of a single-product inventory-control system and single-server queuing system given the domain-specific context, a detailed description of the process, and a list of variables with the corresponding values. The demonstrated results, along with the rapid improvement of language models, open the door for significant simplification of the workflow behind the simulation model development, which will allow e
    
[^49]: 自动学术论文审稿：概念、技术与挑战。

    Automated scholarly paper review: Concepts, technologies, and challenges. (arXiv:2111.07533v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2111.07533](http://arxiv.org/abs/2111.07533)

    提出自动学术论文审稿（ASPR）的概念和流程，综述了实现全面计算机化审稿流程的相关文献和技术，同时指出实现中存在的挑战，如文档解析和表达不完美、数据不足、人机交互缺陷和发现低质量文章的难度。

    

    同行评审是研究评价的广泛接受机制，在学术出版中扮演着重要的角色。然而，由于其效率低下和可重复性差，这一机制长期以来备受批评。近年来，人工智能应用于辅助同行评审。尽管如此，在涉及人员的情况下，这些限制仍是不可避免的。本文提出了自动学术论文审稿（ASPR）的概念和流程，并综述了实现全面计算机化审稿流程的相关文献和技术。在审查和讨论的基础上，我们得出结论：ASPR 的每个阶段已经有相应的研究和初步实施。我们还进一步探讨了ASPR存在的挑战。主要困难在于文档解析和表达不完美、数据不足、人机交互缺陷和发现低质量文章的难度。

    Peer review is a widely accepted mechanism for research evaluation, playing a pivotal role in academic publishing. However, criticisms have long been leveled on this mechanism, mostly because of its poor efficiency and low reproducibility. Recent years have seen the application of artificial intelligence (AI) in assisting the peer review process. Nonetheless, with the involvement of humans, such limitations remain inevitable. In this paper, we propose the concept and pipeline of automated scholarly paper review (ASPR) and review the relevant literature and technologies of achieving a full-scale computerized review process. On the basis of the review and discussion, we conclude that there is already corresponding research and preliminary implementation at each stage of ASPR. We further look into the challenges in ASPR with the existing technologies. The major difficulties lie in imperfect document parsing and representation, inadequate data, defective human-computer interaction, and fla
    

