# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Reasoning in Large Language Models Through Symbolic Math Word Problems.](http://arxiv.org/abs/2308.01906) | 本文通过研究数学问题的符号化版本来解决大型语言模型（LLMs）的推理能力问题，该方法探索了一种自我提示的方法，鼓励符号化推理与数值答案保持一致。 |
| [^2] | [How many preprints have actually been printed and why: a case study of computer science preprints on arXiv.](http://arxiv.org/abs/2308.01899) | 这个研究通过计算机科学预印本在arXiv上的案例研究，量化了有多少预印本最终被印刷在同行评审的期刊上。为了解决预印本和最终发表版本的对应问题，引入了基于语义的映射方法使用BERT。 |
| [^3] | [Athena 2.0: Discourse and User Modeling in Open Domain Dialogue.](http://arxiv.org/abs/2308.01887) | Athena 2.0 是 UCSC的会话代理，使用了知识导向的语篇模型和用户模型来实现个性化对话，并在Amazon的社交机器人大挑战中取得了创新广泛关注。 |
| [^4] | [Thespian: Multi-Character Text Role-Playing Game Agents.](http://arxiv.org/abs/2308.01872) | "Thespian"是一种多角色的文本角色扮演游戏智能体框架，具有学习模仿多个角色的能力，并通过柔性提示进行指导。该框架还使用注意机制以少量示例学习新角色，并在多角色学习和少量示例学习方面表现优于现有框架。 |
| [^5] | [Tag Prediction of Competitive Programming Problems using Deep Learning Techniques.](http://arxiv.org/abs/2308.01863) | 本研究使用文本分类技术自动为竞技编程问题进行标签，以帮助程序员找到适合他们知识和兴趣的问题。 |
| [^6] | [Wider and Deeper LLM Networks are Fairer LLM Evaluators.](http://arxiv.org/abs/2308.01862) | 本文通过使用更深入和更广泛的LLM网络来探索在LLM评估中产生更公平结果的可能性。通过自适应生成多个神经元角色，并根据深度网络的层级关系，提供更全面和准确的评估。 |
| [^7] | [ClassEval: A Manually-Crafted Benchmark for Evaluating LLMs on Class-level Code Generation.](http://arxiv.org/abs/2308.01861) | ClassEval是一种手工构建的类级代码生成基准，该研究首次尝试在这一更具挑战性的场景中评估LLMs，并发现现有LLMs在类级代码生成上的性能相对较差。GPT-4和GPT-3.5在类级代码生成方面表现出相对其他LLMs更卓越的优势。 |
| [^8] | [Curricular Transfer Learning for Sentence Encoded Tasks.](http://arxiv.org/abs/2308.01849) | 本文提出了一种课程迁移学习的方法，通过数据入侵和语法分析引导，逐步适应预训练分布，并在MultiWoZ任务中取得了显着的改进。 |
| [^9] | [XNLP: An Interactive Demonstration System for Universal Structured NLP.](http://arxiv.org/abs/2308.01846) | XNLP演示系统是一个通用的、高性能的自然语言处理平台，通过提供通用的建模方法、解释性、可扩展性和互动性，实现了统一XNLP任务。 |
| [^10] | [The Capability of Large Language Models to Measure Psychiatric Functioning.](http://arxiv.org/abs/2308.01834) | 本研究调查了大型语言模型在通过患者采访和临床描述预测精神功能方面的能力，结果显示这些模型在预测抑郁症评分方面表现最好，与人类临床评估者的结果相近，揭示了通用临床语言模型在评估精神状况方面的潜力。 |
| [^11] | [Many-to-Many Spoken Language Translation via Unified Speech and Text Representation Learning with Unit-to-Unit Translation.](http://arxiv.org/abs/2308.01831) | 本文提出了一种使用统一模型学习多语种语音和文本的表示的方法，重点关注语音合成。通过使用自监督语音模型编码的语音特征的量化表示语音音频，并将其视为伪文本来建立统一的语音和文本表示。然后通过训练编码器-解码器结构模型，利用单元到单元翻译目标将口语语言翻译为目标语言。这种方法能够建立对口语语言的理解并将其相关联到不同的语言。 |
| [^12] | [Scaling Relationship on Learning Mathematical Reasoning with Large Language Models.](http://arxiv.org/abs/2308.01825) | 本文研究了大型语言模型在学习数学推理时的规模关系，发现预训练损失更好地预测模型性能，并提出了一种使用拒绝采样微调技术来增强数据集的方法。 |
| [^13] | [Lexicon and Rule-based Word Lemmatization Approach for the Somali Language.](http://arxiv.org/abs/2308.01785) | 本文开发了一个词表和基于规则的索马里文本词形还原方法，为该低资源语言提供了一个开始，并为各种自然语言处理任务的索马里词形还原系统奠定了基础。 |
| [^14] | [Does Correction Remain An Problem For Large Language Models?.](http://arxiv.org/abs/2308.01776) | 本文通过两个实验探讨了在大型语言模型背景下纠错问题的作用，第一个实验是将纠错作为独立任务进行研究，第二个实验则是探讨纠错作为其他NLP任务的准备任务的概念。研究结果将揭示纠错在大型语言模型时代的重要性及其对各种NLP应用的影响。 |
| [^15] | [Supply chain emission estimation using large language models.](http://arxiv.org/abs/2308.01741) | 本论文提出了一个使用领域适应的自然语言处理基础模型估计供应链范围3排放量的框架，通过利用金融交易代理购买的商品和服务，可以准确跟踪范围3排放。实验证明该框架优于最新的文本挖掘技术，并具有相似的性能。 |
| [^16] | [Ambient Adventures: Teaching ChatGPT on Developing Complex Stories.](http://arxiv.org/abs/2308.01734) | 本文研究了通过使用大型语言模型生成故事，并将其映射为行动序列，以在想象游戏中指导代理人进行互动。同时，还设计了一个文本冒险游戏来评估代理人的表现。 |
| [^17] | [Local Large Language Models for Complex Structured Medical Tasks.](http://arxiv.org/abs/2308.01727) | 本文介绍了一种利用本地大型语言模型 (LLMs) 与本地训练相结合的方法，用于处理复杂的结构化医学任务。作者提出的方法通过从病理报告中提取疾病代码来展示其效果，结果表明利用LLaMA模型相较于BERT风格的模型，在各种评估指标上具有明显的优势。而且，LLaMA模型在处理大型数据集方面表现特别出色。 |
| [^18] | [Baby's CoThought: Leveraging Large Language Models for Enhanced Reasoning in Compact Models.](http://arxiv.org/abs/2308.01684) | "Baby's CoThought" 提出了一种利用大型语言模型重组数据训练紧凑语言模型的方法，经过评估发现，在10个语言学、NLU和问答任务中，BabyLM的表现超过RoBERTa-base超过3个点，展现出更好的上下文信息提取能力。 |
| [^19] | [NBIAS: A Natural Language Processing Framework for Bias Identification in Text.](http://arxiv.org/abs/2308.01681) | 本论文提出了一个名为NBIAS的自然语言处理框架，旨在识别文本中的偏见。通过收集来自社交媒体、医疗保健和职位招聘等领域的多样化数据构建数据集，并应用基于Transformer的令牌分类模型来识别偏见词/短语。通过定量和定性评估方法来评估模型的效果。 |
| [^20] | [Evaluating ChatGPT text-mining of clinical records for obesity monitoring.](http://arxiv.org/abs/2308.01666) | 该研究评估了ChatGPT对临床记录中肥胖监测的文本挖掘能力，与之前的正则表达式相比，ChatGPT的召回率更高，但精确度略低。大型语言模型为兽医临床叙述提供了一个有潜力的工具。 |
| [^21] | [Holy Grail 2.0: From Natural Language to Constraint Models.](http://arxiv.org/abs/2308.01589) | 本文通过利用预训练的大型语言模型从文本问题描述中提取模型的方法，探索了一种使约束编程更易于采用的方法。 |
| [^22] | [InterAct: Exploring the Potentials of ChatGPT as a Cooperative Agent.](http://arxiv.org/abs/2308.01552) | 本研究将OpenAI的ChatGPT集成到具身智能体系统中，通过将ChatGPT分配不同角色并与原始语言模型集成，实现了98%的成功率，并在实际环境中展现了ChatGPT在理解和执行复杂任务方面的能力。 |
| [^23] | [Multimodal Neurons in Pretrained Text-Only Transformers.](http://arxiv.org/abs/2308.01544) | 研究了在预训练的文本变压器中如何通过引入视觉信息来实现多模态能力，在变压器的更深处进行模态之间的转换，并介绍了一种识别多模态神经元的方法，展示了它们对特定视觉概念的操作以及对图像字幕生成的因果效应。 |
| [^24] | [Comparing scalable strategies for generating numerical perspectives.](http://arxiv.org/abs/2308.01535) | 本文比较了三种大规模角度生成策略：基于规则的方法、众包系统和使用维基百科数据和语义相似性的模型。研究发现这三种方法的组合优于单一方法，并且在不同情境中有着不同的优势，用户的偏好也有所不同。在最后，文章还讨论了在一个广泛使用的在线文字处理器中应用角度的情况。 |
| [^25] | [Large Language Model Displays Emergent Ability to Interpret Novel Literary Metaphors.](http://arxiv.org/abs/2308.01497) | 最近的研究评估了GPT-4，一种大型语言模型，对来自塞尔维亚诗歌的新颖文学隐喻的解释能力。 |
| [^26] | [Investigating Reinforcement Learning for Communication Strategies in a Task-Initiative Setting.](http://arxiv.org/abs/2308.01479) | 在这项工作中，我们通过分析模拟实验，研究了在任务主动设置中应用强化学习来处理系统和用户之间的引用通信任务，并发现基于一致性的对话策略具有潜力成为有效的策略选择方法。 |
| [^27] | [Reverse Stable Diffusion: What prompt was used to generate this image?.](http://arxiv.org/abs/2308.01472) | 本论文介绍了一种新的任务，即在给定由生成扩散模型生成的图像的情况下预测文本提示。为了解决这个问题，作者结合了多种白盒和黑盒模型，提出了一个新颖的学习框架，该框架能够生成改进的提示，并采用课程学习和无监督领域自适应核学习方法来进一步提高方法的性能。 |
| [^28] | [FinVis-GPT: A Multimodal Large Language Model for Financial Chart Analysis.](http://arxiv.org/abs/2308.01430) | 本文介绍了一种名为FinVis-GPT的多模态大型语言模型，用于金融图表分析。通过结合语言模型的能力和多模态特性，该模型能够解释金融图表并提供有价值的分析。通过实验证明，FinVis-GPT在生成描述、回答问题和预测未来市场趋势等金融图表相关任务上优于现有的多模态语言模型。该研究展示了在金融领域利用多模态语言模型的潜力。 |
| [^29] | [ChatMOF: An Autonomous AI System for Predicting and Generating Metal-Organic Frameworks.](http://arxiv.org/abs/2308.01423) | ChatMOF是一种自主AI系统，用于预测和生成金属-有机骨架。通过利用大规模语言模型，它能够从文本输入中提取关键细节，并提供适当的回应。该系统通过组合代理、工具包和评估器的核心组件，实现了数据检索、性质预测和结构生成等多个任务。研究进一步展示了在材料科学中使用大型语言模型的优势和潜力。 |
| [^30] | [SAP-sLDA: An Interpretable Interface for Exploring Unstructured Text.](http://arxiv.org/abs/2308.01420) | SAP-sLDA提出了一种半监督人类参与的LDA方法，可以在低维投影中学习主题并保留文档之间的语义关系。 |
| [^31] | [An Effective Data Creation Pipeline to Generate High-quality Financial Instruction Data for Large Language Model.](http://arxiv.org/abs/2308.01415) | 本文提出了一个精心设计的数据创建流水线，通过与金融专家的对话和反馈，在大型语言模型中生成了一个高质量的金融指令数据集。实验结果表明，该方法在生成准确、相关和金融风格响应方面取得了显著进展。 |
| [^32] | [HouYi: An open-source large language model specially designed for renewable energy and carbon neutrality field.](http://arxiv.org/abs/2308.01414) | 本论文发布了第一个专门为可再生能源领域设计的开源大型语言模型HouYi及其对应的可再生能源学术论文数据集REAP。HouYi展示了在生成可再生能源领域学术论文段落方面的强大能力，与ChatGPT相当，略优于Clau。 |
| [^33] | [LaFiCMIL: Rethinking Large File Classification from the Perspective of Correlated Multiple Instance Learning.](http://arxiv.org/abs/2308.01413) | LaFiCMIL是一个新的方法，从相关多实例学习的角度解决了Transformer模型输入长度限制的问题，可以用于改进大文件分类任务。 |
| [^34] | [UPB at IberLEF-2023 AuTexTification: Detection of Machine-Generated Text using Transformer Ensembles.](http://arxiv.org/abs/2308.01408) | UPB团队在IberLEF-2023的AuTexTification共享任务中使用Transformer集成模型，通过识别由大型语言模型生成的文本，取得了较高的宏F1分数。 (translated_abstract) |
| [^35] | [Hoodwinked: Deception and Cooperation in a Text-Based Game for Language Models.](http://arxiv.org/abs/2308.01404) | 通过引入一款名为"Hoodwinked"的文本游戏，研究了当前语言模型是否具有欺骗和识别谎言的能力。实验证据表明，杀手经常否认罪行并指责他人，导致投票结果受到影响。更先进的模型在杀手效果上表现出优势。实验证据表明，这种改进是通过在讨论中更强的欺骗能力实现的。 |
| [^36] | [Learning to Model the World with Language.](http://arxiv.org/abs/2308.01399) | 本论文提出了一种通过语言学习对世界进行建模的方法，利用语言帮助代理器预测未来并进行行动。通过学习多模态世界模型，代理器可以预测未来的文本和图像表示，并在模型回滚中进行行动。 |
| [^37] | [Optimizing Machine Translation through Prompt Engineering: An Investigation into ChatGPT's Customizability.](http://arxiv.org/abs/2308.01391) | 本文研究了通过在ChatGPT中运用合适的提示将翻译目的和目标受众融入进去对翻译质量的影响。研究发现，这种方法可以产生灵活的翻译结果，相比传统机器翻译更具定制性。 |
| [^38] | [Empirical Translation Process Research: Past and Possible Future Perspectives.](http://arxiv.org/abs/2308.01368) | 本文追踪了实证翻译过程研究的发展，提出了自由能原理和主动推理作为建模深嵌入式翻译过程的框架，为未来研究提供了激动人心的前景。 |
| [^39] | [Careful Whisper -- leveraging advances in automatic speech recognition for robust and interpretable aphasia subtype classification.](http://arxiv.org/abs/2308.01327) | 本文提出了一种利用自动语音识别对失语症亚型进行分类的方法，通过结合不同模型的技术，能够利用声音录音自动识别并评估言语障碍。该方法在区分失语症患者和健康对照组的录音时表现出与人类水平相近的准确性，并且可以以较高的准确率区分最常见的失语症类型。该方法还可以应用于其他疾病和语言，并有望稳健地提取诊断性的言语生物标志。 |
| [^40] | [DeepSpeed-Chat: Easy, Fast and Affordable RLHF Training of ChatGPT-like Models at All Scales.](http://arxiv.org/abs/2308.01320) | DeepSpeed-Chat是一个新颖的系统，使得ChatGPT-like模型的RLHF培训易于访问，高效且经济实惠。它具有易于使用的训练和推断体验，复制了InstructGPT的训练流程，并集成了各种训练和推断优化，提供了无与伦比的效率和可扩展性。 |
| [^41] | [On the Trustworthiness Landscape of State-of-the-art Generative Models: A Comprehensive Survey.](http://arxiv.org/abs/2307.16680) | 本文综合调查了大规模生成模型的可信度问题，涵盖了隐私、安全、公平性和责任等多个维度，并提出了实际建议和未来发展方向。 |
| [^42] | [Gzip versus bag-of-words for text classification with KNN.](http://arxiv.org/abs/2307.15002) | Gzip与KNN相比较在文本分类中，我们发现通过简单的词袋匹配可以获得类似或更好的准确性，并且更加高效。 |
| [^43] | [Inductive reasoning in humans and large language models.](http://arxiv.org/abs/2306.06548) | 本研究使用GPT-3.5和GPT-4对人类归纳推理中的属性归纳问题进行了实验。结果表明，尽管GPT-3.5有一些困难，但GPT-4的表现与人类相似，除了未能捕捉到前提的非单调性现象。这项工作为人类和机器智能提供了有趣的比较，并提供了用作未来研究基准的两个大型数据集。 |
| [^44] | [Towards Explainable In-the-Wild Video Quality Assessment: A Database and a Language-Prompted Approach.](http://arxiv.org/abs/2305.12726) | 该论文提出了一个以语言提示为基础的方法和一个包含13个与质量相关因素的数据库，用于解决野外视频质量评估中的可解释性问题，该方法通过收集意见和数据来建立多维麦克斯韦数据库，以帮助评估视频质量。 |
| [^45] | [An automatically discovered chain-of-thought prompt generalizes to novel models and datasets.](http://arxiv.org/abs/2305.02897) | 本文研究了一系列零照顾提示在六个最新发布的语言模型和问题回答数据集的实验中的表现，发现自动提示发现的CoT提示可在新模型和数据集上表现良好，并在应用于GPT-4模型时取得最佳结果。 |
| [^46] | [Are LLMs All You Need for Task-Oriented Dialogue?.](http://arxiv.org/abs/2304.06556) | LLM在任务导向型对话中表现不如专门的任务特定模型，但如果提供正确的槽值，仍有引导对话成功结束的能力，并且可通过真实信念状态分布或域内示例的访问获得更好的表现。 |
| [^47] | [OpenAGI: When LLM Meets Domain Experts.](http://arxiv.org/abs/2304.04370) | 基于大型语言模型的OpenAGI平台通过整合领域专家模型和自然语言问答形式，实现复杂任务解决。 |
| [^48] | [BEVBert: Multimodal Map Pre-training for Language-guided Navigation.](http://arxiv.org/abs/2212.04385) | 本论文提出了一种多模态地图预训练方法，用于语言导向导航任务。通过构建局部度量地图和全局拓扑地图，该方法能够准确刻画空间感知和导航依赖关系，从而提高了语言导向导航的性能。 |
| [^49] | [AI Knows Which Words Will Appear in Next Year's Korean CSAT.](http://arxiv.org/abs/2211.15426) | 本文介绍了一种基于文本挖掘和深度学习的方法，可以预测明年韩国CSAT考试中单词的出现概率，方法在准确性和预测误差方面表现出色。 |

# 详细

[^1]: 大型语言模型通过符号化数学问题进行推理

    Reasoning in Large Language Models Through Symbolic Math Word Problems. (arXiv:2308.01906v1 [cs.CL])

    [http://arxiv.org/abs/2308.01906](http://arxiv.org/abs/2308.01906)

    本文通过研究数学问题的符号化版本来解决大型语言模型（LLMs）的推理能力问题，该方法探索了一种自我提示的方法，鼓励符号化推理与数值答案保持一致。

    

    大型语言模型（LLMs）通过解决几乎没有标记数据的下游任务，改变了自然语言处理（NLP）的方式。尽管它们具有多功能的能力，但对它们的推理能力的问题仍然不太清楚。本文通过研究数学问题的符号化版本来解决数学问题的推理问题，因为符号表达是对数值答案的“简明解释”。我们创建并使用了SVAMP数据集的符号化版本，并发现GPT-3的davinci-002模型在符号化数学问题上也具有良好的零样本准确性。为了评估模型推理的准确性，我们不仅考虑准确率，还评估最终答案和推理结果之间的一致性，分别对应于数值和符号化答案的数学问题。我们探索了一种自我提示的方法，鼓励符号化推理与数值答案保持一致，从而使LLM能够提供简明且可验证的推理。

    Large language models (LLMs) have revolutionized NLP by solving downstream tasks with little to no labeled data. Despite their versatile abilities, the larger question of their ability to reason remains ill-understood. This paper addresses reasoning in math word problems (MWPs) by studying symbolic versions of the numeric problems, since a symbolic expression is a "concise explanation" of the numeric answer. We create and use a symbolic version of the SVAMP dataset and find that GPT-3's davinci-002 model also has good zero-shot accuracy on symbolic MWPs. To evaluate the faithfulness of the model's reasoning, we go beyond accuracy and additionally evaluate the alignment between the final answer and the outputted reasoning, which correspond to numeric and symbolic answers respectively for MWPs. We explore a self-prompting approach to encourage the symbolic reasoning to align with the numeric answer, thus equipping the LLM with the ability to provide a concise and verifiable reasoning and
    
[^2]: 有多少预印本实际上被印刷了，以及为什么：计算机科学预印本在arXiv上的案例研究

    How many preprints have actually been printed and why: a case study of computer science preprints on arXiv. (arXiv:2308.01899v1 [cs.DL])

    [http://arxiv.org/abs/2308.01899](http://arxiv.org/abs/2308.01899)

    这个研究通过计算机科学预印本在arXiv上的案例研究，量化了有多少预印本最终被印刷在同行评审的期刊上。为了解决预印本和最终发表版本的对应问题，引入了基于语义的映射方法使用BERT。

    

    预印本在学术界扮演着越来越重要的角色。研究人员在正式提交到期刊或会议之前将他们的手稿发布到预印本服务器上的原因有很多，但预印本的使用也引发了不少争议，尤其是与优先权的声明有关。本文对2008年至2017年期间提交到arXiv的计算机科学预印本进行了案例研究，以量化最终有多少预印本在同行评审的场合中被印刷。在这些已发表的手稿中，有些以不同的标题发表，且未更新arXiv上的预印本。对于这些手稿，传统的模糊匹配方法无法将预印本与最终发表版本对应起来。鉴于这个问题，我们引入了一种基于语义的映射方法，利用Transformers中的Bidirectional Encoder Representations (BERT)。利用这种新的映射方法和多种数据来源...

    Preprints play an increasingly critical role in academic communities. There are many reasons driving researchers to post their manuscripts to preprint servers before formal submission to journals or conferences, but the use of preprints has also sparked considerable controversy, especially surrounding the claim of priority. In this paper, a case study of computer science preprints submitted to arXiv from 2008 to 2017 is conducted to quantify how many preprints have eventually been printed in peer-reviewed venues. Among those published manuscripts, some are published under different titles and without an update to their preprints on arXiv. In the case of these manuscripts, the traditional fuzzy matching method is incapable of mapping the preprint to the final published version. In view of this issue, we introduce a semantics-based mapping method with the employment of Bidirectional Encoder Representations from Transformers (BERT). With this new mapping method and a plurality of data sou
    
[^3]: Athena 2.0: 开放领域对话中的语篇和用户建模。

    Athena 2.0: Discourse and User Modeling in Open Domain Dialogue. (arXiv:2308.01887v1 [cs.CL])

    [http://arxiv.org/abs/2308.01887](http://arxiv.org/abs/2308.01887)

    Athena 2.0 是 UCSC的会话代理，使用了知识导向的语篇模型和用户模型来实现个性化对话，并在Amazon的社交机器人大挑战中取得了创新广泛关注。

    

    会话代理的受欢迎程度不断增长，许多人每天都与它们进行交互。虽然许多会话代理充当个人助手，但它们可以有许多不同的目标。一些是面向任务的，例如提供银行客户支持或进行预订。其他人则旨在表达同情，并与用户建立情感联系。Alexa Prize Challenge旨在创建一个社交机器人，使用户能够进行连贯的对话，涉及用户感兴趣的各种热门话题。在这里，我们介绍了阿蒂娜2.0，UCSC的亚马逊社交机器人大挑战4中的会话代理。阿蒂娜2.0使用新颖的知识导向的语篇模型，跟踪阿蒂娜引入对话中的实体链接，并利用它们来限制命名实体识别和链接，以及共指消解。阿蒂娜2.0还依赖于用户模型，以个性化主题选择和对话的其他方面。

    Conversational agents are consistently growing in popularity and many people interact with them every day. While many conversational agents act as personal assistants, they can have many different goals. Some are task-oriented, such as providing customer support for a bank or making a reservation. Others are designed to be empathetic and to form emotional connections with the user. The Alexa Prize Challenge aims to create a socialbot, which allows the user to engage in coherent conversations, on a range of popular topics that will interest the user. Here we describe Athena 2.0, UCSC's conversational agent for Amazon's Socialbot Grand Challenge 4. Athena 2.0 utilizes a novel knowledge-grounded discourse model that tracks the entity links that Athena introduces into the dialogue, and uses them to constrain named-entity recognition and linking, and coreference resolution. Athena 2.0 also relies on a user model to personalize topic selection and other aspects of the conversation to individ
    
[^4]: Thespian: 多角色文本角色扮演游戏智能体

    Thespian: Multi-Character Text Role-Playing Game Agents. (arXiv:2308.01872v1 [cs.AI])

    [http://arxiv.org/abs/2308.01872](http://arxiv.org/abs/2308.01872)

    "Thespian"是一种多角色的文本角色扮演游戏智能体框架，具有学习模仿多个角色的能力，并通过柔性提示进行指导。该框架还使用注意机制以少量示例学习新角色，并在多角色学习和少量示例学习方面表现优于现有框架。

    

    文本冒险游戏和文本角色扮演游戏是强化学习游戏智能体的重大挑战。文本角色扮演游戏是开放式环境，智能体必须忠实地扮演特定角色。文章考虑到了字符和演员之间的区别，演员智能体能够扮演多个角色。我们提出了一个名为"Thespian"的框架，使其能够学习模仿多个角色，并使用柔性提示来指导其在任何时候扮演特定角色。此外，我们还描述了一个注意机制，允许智能体以少量示例的方式学习基于先前学习的角色的新角色。我们证明了我们的智能体在多角色学习和少量示例学习方面优于现有的智能体框架。

    Text-adventure games and text role-playing games are grand challenges for reinforcement learning game playing agents. Text role-playing games are open-ended environments where an agent must faithfully play a particular character. We consider the distinction between characters and actors, where an actor agent has the ability to play multiple characters. We present a framework we call a thespian agent that can learn to emulate multiple characters along with a soft prompt that can be used to direct it as to which character to play at any time. We further describe an attention mechanism that allows the agent to learn new characters that are based on previously learned characters in a few-shot fashion. We show that our agent outperforms the state of the art agent framework in multi-character learning and few-shot learning.
    
[^5]: 使用深度学习技术预测竞技编程问题的标签

    Tag Prediction of Competitive Programming Problems using Deep Learning Techniques. (arXiv:2308.01863v1 [cs.CL])

    [http://arxiv.org/abs/2308.01863](http://arxiv.org/abs/2308.01863)

    本研究使用文本分类技术自动为竞技编程问题进行标签，以帮助程序员找到适合他们知识和兴趣的问题。

    

    在过去十年中，机器学习和深度学习领域的研究量大幅增加，特别是在自然语言处理方面。竞技编程是一种培养编程能力、逻辑思维和问题解决能力的受欢迎方法。由于问题数量众多、主题、难度和种类繁多，即使对于有经验的程序员来说，遍历这些问题也是具有挑战性的。为了帮助程序员找到适合他们知识和兴趣的问题，需要一种自动化的方法。通过使用文本分类技术对问题进行标签化，可以实现这一目标。文本分类是自然语言处理领域中一个重要的研究任务。本文介绍了一种使用文本分类技术确定竞技编程问题领域的方法。

    In the past decade, the amount of research being done in the fields of machine learning and deep learning, predominantly in the area of natural language processing (NLP), has risen dramatically. A well-liked method for developing programming abilities like logic building and problem solving is competitive programming. It can be tough for novices and even veteran programmers to traverse the wide collection of questions due to the massive number of accessible questions and the variety of themes, levels of difficulty, and questions offered. In order to help programmers find questions that are appropriate for their knowledge and interests, there is a need for an automated method. This can be done using automated tagging of the questions using Text Classification. Text classification is one of the important tasks widely researched in the field of Natural Language Processing. In this paper, we present a way to use text classification techniques to determine the domain of a competitive progra
    
[^6]: 更广泛和更深入的LLM网络能够更公平地评估LLM

    Wider and Deeper LLM Networks are Fairer LLM Evaluators. (arXiv:2308.01862v1 [cs.CL])

    [http://arxiv.org/abs/2308.01862](http://arxiv.org/abs/2308.01862)

    本文通过使用更深入和更广泛的LLM网络来探索在LLM评估中产生更公平结果的可能性。通过自适应生成多个神经元角色，并根据深度网络的层级关系，提供更全面和准确的评估。

    

    测量LLM生成的响应质量是一项具有挑战性的任务，特别是在评估响应是否与人类偏好一致时。一种新颖的方法是使用LLM本身进行评估，并通过多个独立评估来稳定结果，类似于单层窄LLM网络。该网络由固定数量的神经元组成，每个神经元都是相同的LLM。在本文中，我们借鉴了关于深度神经网络的广泛研究来探讨更深入和更广泛的网络是否可以导致更公平的评估。具体而言，受到神经网络中不同神经元负责检测不同概念的观察启发，我们首先为每个评估样本适应性地生成尽可能多的神经元角色。每个角度对应于第一层中特定LLM神经元的角色。在随后的层中，我们遵循深度网络中较高层负责相关性解谜的概念。

    Measuring the quality of responses generated by LLMs is a challenging task, particularly when it comes to evaluating whether the response is aligned with human preference. A novel approach involves using the LLM itself to make evaluation and stabilizing the results through multiple independent evaluations, similar to a single-layer narrow LLM network. This network consists of a fixed number of neurons, with each neuron being the same LLM. In this paper, we draw upon the extensive research on deep neural networks to explore whether deeper and wider networks can lead to fairer evaluations. Specifically, inspired by the observation that different neurons in a neural network are responsible for detecting different concepts, we first adaptively generate as many neuron roles as possible for each evaluation sample. Each perspective corresponds to the role of a specific LLM neuron in the first layer. In subsequent layers, we follow the idea that higher layers in deep networks are responsible f
    
[^7]: ClassEval: 一种手工构建的用于评估LLMs在类级代码生成上的基准

    ClassEval: A Manually-Crafted Benchmark for Evaluating LLMs on Class-level Code Generation. (arXiv:2308.01861v1 [cs.CL])

    [http://arxiv.org/abs/2308.01861](http://arxiv.org/abs/2308.01861)

    ClassEval是一种手工构建的类级代码生成基准，该研究首次尝试在这一更具挑战性的场景中评估LLMs，并发现现有LLMs在类级代码生成上的性能相对较差。GPT-4和GPT-3.5在类级代码生成方面表现出相对其他LLMs更卓越的优势。

    

    在这项工作中，我们首次尝试在更具挑战性的代码生成场景中评估LLMs，即类级代码生成。我们首先手动构建了第一个类级代码生成基准ClassEval，其中包含100个类级Python代码生成任务，总共耗时约500人小时。在此基础上，我们对11个最先进的LLMs在类级代码生成上进行了第一次研究。根据我们的结果，我们得出以下主要发现。首先，我们发现所有现有的LLMs在类级代码生成上的性能要远低于独立的方法级代码生成基准（如HumanEval）；而方法级的编码能力不能等同地反映LLMs在类级编码能力上的表现。其次，我们发现GPT-4和GPT-3.5在类级代码生成上仍然表现出相对其他LLMs更卓越的优势，而二线模型包括Instruct-Starcoder，Instruct-Codegen和Wizardcoder在性能上非常相似。

    In this work, we make the first attempt to evaluate LLMs in a more challenging code generation scenario, i.e. class-level code generation. We first manually construct the first class-level code generation benchmark ClassEval of 100 class-level Python code generation tasks with approximately 500 person-hours. Based on it, we then perform the first study of 11 state-of-the-art LLMs on class-level code generation. Based on our results, we have the following main findings. First, we find that all existing LLMs show much worse performance on class-level code generation compared to on standalone method-level code generation benchmarks like HumanEval; and the method-level coding ability cannot equivalently reflect the class-level coding ability among LLMs. Second, we find that GPT-4 and GPT-3.5 still exhibit dominate superior than other LLMs on class-level code generation, and the second-tier models includes Instruct-Starcoder, Instruct-Codegen, and Wizardcoder with very similar performance. 
    
[^8]: 句子编码任务的课程迁移学习

    Curricular Transfer Learning for Sentence Encoded Tasks. (arXiv:2308.01849v1 [cs.CL])

    [http://arxiv.org/abs/2308.01849](http://arxiv.org/abs/2308.01849)

    本文提出了一种课程迁移学习的方法，通过数据入侵和语法分析引导，逐步适应预训练分布，并在MultiWoZ任务中取得了显着的改进。

    

    微调语言模型是自然语言处理领域许多最先进方法的标准做法。然而，当源任务和目标任务之间的分布漂移时，例如，对话环境下，这些收益往往会减少。本文提出了一种由“数据入侵”和语法分析引导的预训练步骤序列（课程），允许在预训练分布之间进一步逐渐适应。在我们的实验中，与其他已知的预训练方法相比，我们的方法在MultiWoZ任务中取得了显着的改进。

    Fine-tuning language models in a downstream task is the standard approach for many state-of-the-art methodologies in the field of NLP. However, when the distribution between the source task and target task drifts, \textit{e.g.}, conversational environments, these gains tend to be diminished. This article proposes a sequence of pre-training steps (a curriculum) guided by "data hacking" and grammar analysis that allows further gradual adaptation between pre-training distributions. In our experiments, we acquire a considerable improvement from our method compared to other known pre-training approaches for the MultiWoZ task.
    
[^9]: XNLP：通用结构化自然语言处理的交互演示系统

    XNLP: An Interactive Demonstration System for Universal Structured NLP. (arXiv:2308.01846v1 [cs.CL])

    [http://arxiv.org/abs/2308.01846](http://arxiv.org/abs/2308.01846)

    XNLP演示系统是一个通用的、高性能的自然语言处理平台，通过提供通用的建模方法、解释性、可扩展性和互动性，实现了统一XNLP任务。

    

    结构化自然语言处理（XNLP）是自然语言处理的一个重要子集，涉及理解文本的底层语义或句法结构，为许多下游应用程序提供了基本组件。尽管最近有一些努力探索特定类别的XNLP任务的通用解决方案，但统一所有XNLP任务的综合有效方法仍然不完善。与此同时，XNLP演示系统对于研究人员探索各种XNLP任务至关重要，现有平台可能受到限制，例如只支持少数XNLP任务，缺乏互动性和通用性。因此，我们提出了一个先进的XNLP演示平台，其中我们提出利用LLM实现通用XNLP，通过一个模型实现高通用性。总体而言，我们的系统在多个方面取得了进展，包括通用XNLP建模、高性能、可解释性、可扩展性和互动性。

    Structured Natural Language Processing (XNLP) is an important subset of NLP that entails understanding the underlying semantic or syntactic structure of texts, which serves as a foundational component for many downstream applications. Despite certain recent efforts to explore universal solutions for specific categories of XNLP tasks, a comprehensive and effective approach for unifying all XNLP tasks long remains underdeveloped. In the meanwhile, while XNLP demonstration systems are vital for researchers exploring various XNLP tasks, existing platforms can be limited to, e.g., supporting few XNLP tasks, lacking interactivity and universalness. To this end, we propose an advanced XNLP demonstration platform, where we propose leveraging LLM to achieve universal XNLP, with one model for all with high generalizability. Overall, our system advances in multiple aspects, including universal XNLP modeling, high performance, interpretability, scalability, and interactivity, providing a unified p
    
[^10]: 大型语言模型在评估精神状况方面的能力

    The Capability of Large Language Models to Measure Psychiatric Functioning. (arXiv:2308.01834v1 [cs.CL])

    [http://arxiv.org/abs/2308.01834](http://arxiv.org/abs/2308.01834)

    本研究调查了大型语言模型在通过患者采访和临床描述预测精神功能方面的能力，结果显示这些模型在预测抑郁症评分方面表现最好，与人类临床评估者的结果相近，揭示了通用临床语言模型在评估精神状况方面的潜力。

    

    本研究探讨了基于大规模医学知识（Med-PaLM 2）训练的大型语言模型（LLM）在没有经过特定训练的情况下，通过患者采访和临床描述来预测精神功能的能力。通过使用提示来提取估计的临床评分和诊断，分析了145例抑郁症和115例创伤后应激障碍评估以及46例临床案例研究。结果表明，Med-PaLM 2能够在一系列精神疾病中评估精神功能，其中对基于标准评估的抑郁症评分的预测表现最佳（准确率范围= 0.80-0.84），这些预测结果在统计上与人类临床评估者的结果无法区分（t(1,144) = 1.20，p = 0.23）。结果显示了通用临床语言模型在评估精神状况方面的潜力。

    The current work investigates the capability of Large language models (LLMs) that are explicitly trained on large corpuses of medical knowledge (Med-PaLM 2) to predict psychiatric functioning from patient interviews and clinical descriptions without being trained to do so. To assess this, n = 145 depression and n =115 PTSD assessments and n = 46 clinical case studies across high prevalence/high comorbidity disorders (Depressive, Anxiety, Psychotic, trauma and stress, Addictive disorders) were analyzed using prompts to extract estimated clinical scores and diagnoses. Results demonstrate that Med-PaLM 2 is capable of assessing psychiatric functioning across a range of psychiatric conditions with the strongest performance being the prediction of depression scores based on standardized assessments (Accuracy range= 0.80 - 0.84) which were statistically indistinguishable from human clinical raters t(1,144) = 1.20; p = 0.23. Results show the potential for general clinical language models to f
    
[^11]: 通过统一的语音和文本表示学习以及单元到单元的翻译实现多对多口语翻译

    Many-to-Many Spoken Language Translation via Unified Speech and Text Representation Learning with Unit-to-Unit Translation. (arXiv:2308.01831v1 [cs.CL])

    [http://arxiv.org/abs/2308.01831](http://arxiv.org/abs/2308.01831)

    本文提出了一种使用统一模型学习多语种语音和文本的表示的方法，重点关注语音合成。通过使用自监督语音模型编码的语音特征的量化表示语音音频，并将其视为伪文本来建立统一的语音和文本表示。然后通过训练编码器-解码器结构模型，利用单元到单元翻译目标将口语语言翻译为目标语言。这种方法能够建立对口语语言的理解并将其相关联到不同的语言。

    

    在本文中，我们提出了一种使用单个模型学习多语种语音和文本的统一表示的方法，特别关注语音合成的目的。我们使用语音单元表示多语种语音音频，这些语音单元是从自监督语音模型编码的语音特征的量化表示。因此，我们可以将音频视为伪文本并专注于其语言内容，从而构建语音和文本的统一表示。然后，我们提出使用多语种数据训练编码器-解码器结构模型，并采用单元到单元翻译（UTUT）目标。具体而言，通过将编码器与源语言标记和解码器与目标语言标记相关联，优化模型以将口语语言翻译为目标语言的语言。因此，该模型可以建立对口语语言的理解以及如何将其与不同语言相关联的知识。

    In this paper, we propose a method to learn unified representations of multilingual speech and text with a single model, especially focusing on the purpose of speech synthesis. We represent multilingual speech audio with speech units, the quantized representations of speech features encoded from a self-supervised speech model. Therefore, we can focus on their linguistic content by treating the audio as pseudo text and can build a unified representation of speech and text. Then, we propose to train an encoder-decoder structured model with a Unit-to-Unit Translation (UTUT) objective on multilingual data. Specifically, by conditioning the encoder with the source language token and the decoder with the target language token, the model is optimized to translate the spoken language into that of the target language, in a many-to-many language translation setting. Therefore, the model can build the knowledge of how spoken languages are comprehended and how to relate them to different languages
    
[^12]: 使用大型语言模型学习数学推理的规模关系

    Scaling Relationship on Learning Mathematical Reasoning with Large Language Models. (arXiv:2308.01825v1 [cs.CL])

    [http://arxiv.org/abs/2308.01825](http://arxiv.org/abs/2308.01825)

    本文研究了大型语言模型在学习数学推理时的规模关系，发现预训练损失更好地预测模型性能，并提出了一种使用拒绝采样微调技术来增强数据集的方法。

    

    数学推理是大型语言模型（LLMs）的一项具有挑战性的任务，然而关于LLM容量与数学推理之间的规模关系尚未充分探索。本文研究了预训练损失、监督数据量和增强数据量对监督LLM的推理性能的影响。我们发现预训练损失是模型性能的更好指标，而不是模型参数数量。我们使用不同数量的监督数据进行监督微调（SFT），并实证发现数据量与模型性能之间存在对数线性关系，而较好的模型在扩大的监督数据集上改进较小。为了在不需要人工努力的情况下增加更多的数据样本以提高模型性能，我们提出了拒绝采样微调（RFT）。RFT使用监督模型生成和收集正确的推理路径作为增强的微调数据集。我们发现，使用更多不同的推理路径作为增强样本可以提高模型的性能。

    Mathematical reasoning is a challenging task for large language models (LLMs), while the scaling relationship of it with respect to LLM capacity is under-explored. In this paper, we investigate how the pre-training loss, supervised data amount, and augmented data amount influence the reasoning performances of a supervised LLM. We find that pre-training loss is a better indicator of the model's performance than the model's parameter count. We apply supervised fine-tuning (SFT) with different amounts of supervised data and empirically find a log-linear relation between data amount and model performance, and we find better models improve less with enlarged supervised datasets. To augment more data samples for improving model performances without any human effort, we propose to apply Rejection sampling Fine-Tuning (RFT). RFT uses supervised models to generate and collect correct reasoning paths as augmented fine-tuning datasets. We find with augmented samples containing more distinct reaso
    
[^13]: 《索马里语词表和基于规则的词形还原方法》

    Lexicon and Rule-based Word Lemmatization Approach for the Somali Language. (arXiv:2308.01785v1 [cs.CL])

    [http://arxiv.org/abs/2308.01785](http://arxiv.org/abs/2308.01785)

    本文开发了一个词表和基于规则的索马里文本词形还原方法，为该低资源语言提供了一个开始，并为各种自然语言处理任务的索马里词形还原系统奠定了基础。

    

    词形还原是一种自然语言处理技术，用于将单词的词形派生转化为其词根形式以归一化文本。它被用作许多自然语言处理任务（包括文本索引、信息检索和自然语言处理的机器学习等）的核心预处理步骤。本文首次开发了索马里语的文本词形还原，这是一种资源匮乏的语言，以前几乎没有有效采用自然语言处理方法和数据集。我们特别为索马里文本开发了一个词表和基于规则的词形还原器，这是一个为各种自然语言处理任务构建全面索马里语词形还原系统的起点。考虑到语言的词法规则，我们开发了一个包含1247个词根词和7173个词形派生相关术语的初始词表，并丰富了用于词形还原词表中不存在的词的规则。我们在包括新闻文章、社交媒体帖子和文本在内的各种长度的120个文档上测试了算法。

    Lemmatization is a Natural Language Processing (NLP) technique used to normalize text by changing morphological derivations of words to their root forms. It is used as a core pre-processing step in many NLP tasks including text indexing, information retrieval, and machine learning for NLP, among others. This paper pioneers the development of text lemmatization for the Somali language, a low-resource language with very limited or no prior effective adoption of NLP methods and datasets. We especially develop a lexicon and rule-based lemmatizer for Somali text, which is a starting point for a full-fledged Somali lemmatization system for various NLP tasks. With consideration of the language morphological rules, we have developed an initial lexicon of 1247 root words and 7173 derivationally related terms enriched with rules for lemmatizing words not present in the lexicon. We have tested the algorithm on 120 documents of various lengths including news articles, social media posts, and text 
    
[^14]: 大型语言模型是否仍然存在纠错问题？

    Does Correction Remain An Problem For Large Language Models?. (arXiv:2308.01776v1 [cs.CL])

    [http://arxiv.org/abs/2308.01776](http://arxiv.org/abs/2308.01776)

    本文通过两个实验探讨了在大型语言模型背景下纠错问题的作用，第一个实验是将纠错作为独立任务进行研究，第二个实验则是探讨纠错作为其他NLP任务的准备任务的概念。研究结果将揭示纠错在大型语言模型时代的重要性及其对各种NLP应用的影响。

    

    随着GPT等大型语言模型不断提升自然语言处理（NLP）的能力，一个问题出现了：纠错问题是否仍然存在？本文通过进行两个实验，探讨了在大型语言模型的背景下纠错的作用。第一个实验将纠错作为独立的任务，使用GPT类模型和few-shot learning技术进行错误纠正。第二个实验则探讨了纠错作为其他NLP任务的准备任务的概念，检验大型语言模型在包含一定程度噪声或错误的文本上是否能够容忍并表现得足够好。通过解决这些实验，我们旨在揭示在大型语言模型时代纠错的重要性，以及对各种NLP应用的影响。

    As large language models, such as GPT, continue to advance the capabilities of natural language processing (NLP), the question arises: does the problem of correction still persist? This paper investigates the role of correction in the context of large language models by conducting two experiments. The first experiment focuses on correction as a standalone task, employing few-shot learning techniques with GPT-like models for error correction. The second experiment explores the notion of correction as a preparatory task for other NLP tasks, examining whether large language models can tolerate and perform adequately on texts containing certain levels of noise or errors. By addressing these experiments, we aim to shed light on the significance of correction in the era of large language models and its implications for various NLP applications.
    
[^15]: 使用大型语言模型估计供应链排放量

    Supply chain emission estimation using large language models. (arXiv:2308.01741v1 [cs.CL])

    [http://arxiv.org/abs/2308.01741](http://arxiv.org/abs/2308.01741)

    本论文提出了一个使用领域适应的自然语言处理基础模型估计供应链范围3排放量的框架，通过利用金融交易代理购买的商品和服务，可以准确跟踪范围3排放。实验证明该框架优于最新的文本挖掘技术，并具有相似的性能。

    

    大型企业面临着实现可持续发展目标（SDGs）的关键任务，尤其是目标13，专注于应对气候变化及其影响。为了减轻气候变化的影响，减少企业的范围3（供应链排放）至关重要，因为它占总排放清单的90％以上。然而，跟踪范围3排放面临挑战，因为必须从数千个上游和下游供应商中收集数据。为了解决上述挑战，我们提出了一个首创框架，该框架利用领域适应的自然语言处理基础模型，通过使用金融交易作为购买的商品和服务的代理来估计范围3排放。我们将所提出的框架的性能与TF-IDF、word2Vec和零样本学习等最新文本分类模型进行了比较。结果显示，领域适应的基础模型优于最新的文本挖掘技术，并有着相似的性能。

    Large enterprises face a crucial imperative to achieve the Sustainable Development Goals (SDGs), especially goal 13, which focuses on combating climate change and its impacts. To mitigate the effects of climate change, reducing enterprise Scope 3 (supply chain emissions) is vital, as it accounts for more than 90\% of total emission inventories. However, tracking Scope 3 emissions proves challenging, as data must be collected from thousands of upstream and downstream suppliers.To address the above mentioned challenges, we propose a first-of-a-kind framework that uses domain-adapted NLP foundation models to estimate Scope 3 emissions, by utilizing financial transactions as a proxy for purchased goods and services. We compared the performance of the proposed framework with the state-of-art text classification models such as TF-IDF, word2Vec, and Zero shot learning. Our results show that the domain-adapted foundation model outperforms state-of-the-art text mining techniques and performs as
    
[^16]: 环境冒险：教授ChatGPT开发复杂故事

    Ambient Adventures: Teaching ChatGPT on Developing Complex Stories. (arXiv:2308.01734v1 [cs.CL])

    [http://arxiv.org/abs/2308.01734](http://arxiv.org/abs/2308.01734)

    本文研究了通过使用大型语言模型生成故事，并将其映射为行动序列，以在想象游戏中指导代理人进行互动。同时，还设计了一个文本冒险游戏来评估代理人的表现。

    

    想象力的游戏是一种创造力的领域，它可以让机器人以更加拟人化的方式与周围世界进行互动。想象游戏可以看作是将真实的物体和地点作为虚拟场景中的想象物体和地点。我们采用大型语言模型（LLMs）的故事生成能力，使用人类编写的提示来获取用于想象游戏的故事。这些生成的故事将被简化并映射为行动序列，以指导代理人进行想象游戏。为了评估代理人是否能成功完成想象游戏，我们还设计了一个文本冒险游戏，模拟房子作为代理人互动的游乐场。

    Imaginative play is an area of creativity that could allow robots to engage with the world around them in a much more personified way. Imaginary play can be seen as taking real objects and locations and using them as imaginary objects and locations in virtual scenarios. We adopted the story generation capability of large language models (LLMs) to obtain the stories used for imaginary play with human-written prompts. Those generated stories will be simplified and mapped into action sequences that can guide the agent in imaginary play. To evaluate whether the agent can successfully finish the imaginary play, we also designed a text adventure game to simulate a house as the playground for the agent to interact.
    
[^17]: 针对复杂结构化医学任务的本地大型语言模型

    Local Large Language Models for Complex Structured Medical Tasks. (arXiv:2308.01727v1 [cs.CL])

    [http://arxiv.org/abs/2308.01727](http://arxiv.org/abs/2308.01727)

    本文介绍了一种利用本地大型语言模型 (LLMs) 与本地训练相结合的方法，用于处理复杂的结构化医学任务。作者提出的方法通过从病理报告中提取疾病代码来展示其效果，结果表明利用LLaMA模型相较于BERT风格的模型，在各种评估指标上具有明显的优势。而且，LLaMA模型在处理大型数据集方面表现特别出色。

    

    本文介绍了一种将大型语言模型 (LLMs) 的语言推理能力与本地训练的优势相结合，以应对复杂的领域特定任务的方法。具体而言，作者通过从病理报告中提取结构化疾病代码来展示他们的方法。提出的方法利用本地LLMs，可以进行针对特定生成指令的微调，并提供结构化输出。作者收集了一个包含超过15万个未编辑的外科病理报告的数据集，其中包含了外观描述、最终诊断和疾病代码。他们训练了不同的模型架构，包括LLaMA、BERT和LongFormer，并评估了它们的性能。结果显示，基于LLaMA的模型在所有评估指标上明显优于BERT风格的模型，即使精确性大幅降低。LLaMA模型在大型数据集上表现特别出色，展示了它们处理复杂的多任务问题的能力。

    This paper introduces an approach that combines the language reasoning capabilities of large language models (LLMs) with the benefits of local training to tackle complex, domain-specific tasks. Specifically, the authors demonstrate their approach by extracting structured condition codes from pathology reports. The proposed approach utilizes local LLMs, which can be fine-tuned to respond to specific generative instructions and provide structured outputs. The authors collected a dataset of over 150k uncurated surgical pathology reports, containing gross descriptions, final diagnoses, and condition codes. They trained different model architectures, including LLaMA, BERT and LongFormer and evaluated their performance. The results show that the LLaMA-based models significantly outperform BERT-style models across all evaluated metrics, even with extremely reduced precision. The LLaMA models performed especially well with large datasets, demonstrating their ability to handle complex, multi-la
    
[^18]: Baby's CoThought: 利用大型语言模型提高紧凑模型的推理能力

    Baby's CoThought: Leveraging Large Language Models for Enhanced Reasoning in Compact Models. (arXiv:2308.01684v1 [cs.CL])

    [http://arxiv.org/abs/2308.01684](http://arxiv.org/abs/2308.01684)

    "Baby's CoThought" 提出了一种利用大型语言模型重组数据训练紧凑语言模型的方法，经过评估发现，在10个语言学、NLU和问答任务中，BabyLM的表现超过RoBERTa-base超过3个点，展现出更好的上下文信息提取能力。

    

    大型语言模型(LLMs)在各种自然语言理解(NLU)任务中展示出出色的性能，主要是由于它们的上下文学习能力。我们提出的"CoThought"流水线利用LLMs的CoT提示，高效地训练较小的"baby"语言模型(BabyLMs)。我们使用GPT-3.5-turbo对少于100M大小的数据集进行重组，将其转化为面向任务的、可读性强的文本，类似于语言学习者的学校教材。然后，在这个重组后的数据集上，以RoBERTa(Liu等人，2019)的方式对BabyLM进行预训练。在4个基准测试中，我们的BabyLM在10个语言学、NLU和问答任务中的表现优于RoBERTa-base超过3个点，展现出更好的提取上下文信息的能力。这些结果表明，在小型的、由LLM重组的数据上预训练的紧凑语言模型能够更好地理解任务并实现

    Large Language Models (LLMs) demonstrate remarkable performance on a variety of Natural Language Understanding (NLU) tasks, primarily due to their in-context learning ability. This ability is utilized in our proposed "CoThought" pipeline, which efficiently trains smaller "baby" language models (BabyLMs) by leveraging the Chain of Thought (CoT) prompting of LLMs. Our pipeline restructures a dataset of less than 100M in size using GPT-3.5-turbo, transforming it into task-oriented, human-readable texts that are comparable to the school texts for language learners. The BabyLM is then pretrained on this restructured dataset in a RoBERTa (Liu et al., 2019) fashion. In evaluations across 4 benchmarks, our BabyLM outperforms the RoBERTa-base in 10 linguistic, NLU, and question answering tasks by more than 3 points, showing superior ability to extract contextual information. These results suggest that compact LMs pretrained on small, LLM-restructured data can better understand tasks and achieve
    
[^19]: NBIAS: 用于文本中偏见识别的自然语言处理框架

    NBIAS: A Natural Language Processing Framework for Bias Identification in Text. (arXiv:2308.01681v1 [cs.CL])

    [http://arxiv.org/abs/2308.01681](http://arxiv.org/abs/2308.01681)

    本论文提出了一个名为NBIAS的自然语言处理框架，旨在识别文本中的偏见。通过收集来自社交媒体、医疗保健和职位招聘等领域的多样化数据构建数据集，并应用基于Transformer的令牌分类模型来识别偏见词/短语。通过定量和定性评估方法来评估模型的效果。

    

    在文本数据中存在偏见可能导致数据使用时产生倾斜的解释和结果。这些偏见可能会持续强化刻板印象、歧视或其他形式的不公平待遇。在有偏见的数据上训练的算法最终会做出不平等影响某个群体的决策。因此，检测和消除这些偏见至关重要，以确保对数据的公平和道德使用。为此，我们开发了一个全面而强大的框架"NBIAS"，它包括数据层、语料库构建、模型开发层和评估层。数据集由从各个领域收集的多样化数据构建，包括社交媒体、医疗保健和职位招聘门户网站。因此，我们应用了基于Transformer的令牌分类模型，通过一个唯一的命名实体能够识别出偏见词/短语。在评估过程中，我们结合了定量和定性评估方法来评估我们模型的效果。

    Bias in textual data can lead to skewed interpretations and outcomes when the data is used. These biases could perpetuate stereotypes, discrimination, or other forms of unfair treatment. An algorithm trained on biased data ends up making decisions that disproportionately impact a certain group of people. Therefore, it is crucial to detect and remove these biases to ensure the fair and ethical use of data. To this end, we develop a comprehensive and robust framework \textsc{Nbias} that consists of a data layer, corpus contruction, model development layer and an evaluation layer. The dataset is constructed by collecting diverse data from various fields, including social media, healthcare, and job hiring portals. As such, we applied a transformer-based token classification model that is able to identify bias words/ phrases through a unique named entity. In the assessment procedure, we incorporate a blend of quantitative and qualitative evaluations to gauge the effectiveness of our models.
    
[^20]: 评估ChatGPT对肥胖监测中临床记录的文本挖掘能力

    Evaluating ChatGPT text-mining of clinical records for obesity monitoring. (arXiv:2308.01666v1 [cs.IR])

    [http://arxiv.org/abs/2308.01666](http://arxiv.org/abs/2308.01666)

    该研究评估了ChatGPT对临床记录中肥胖监测的文本挖掘能力，与之前的正则表达式相比，ChatGPT的召回率更高，但精确度略低。大型语言模型为兽医临床叙述提供了一个有潜力的工具。

    

    背景：兽医临床叙述仍然是一个很少被利用的资源，用于应对复杂疾病。在这里，我们比较了一个大型语言模型(ChatGPT)和之前开发的正则表达式(RegexT)在识别兽医叙述中超重体况评分(BCS)方面的能力。方法：使用RegexT或将叙述附加到发送给ChatGPT的提示中来提取4,415个匿名临床叙述中的BCS值，迫使模型返回BCS信息。通过手动审查数据进行比较。结果：RegexT的精确度(100%，95% CI 94.81-100%)高于ChatGPT的精确度(89.3%，95% CI 82.75-93.64%)。然而，ChatGPT的召回率(100%，95% CI 96.18-100%)要远高于RegexT的召回率(72.6%，95% CI 63.92-79.94%)。局限性：需要对提示工程进行微调以改善ChatGPT输出。结论：大型语言模型为创建各种机会提供了可能性，并且虽然复杂，但具有直观的界面用于in

    Background: Veterinary clinical narratives remain a largely untapped resource for addressing complex diseases. Here we compare the ability of a large language model (ChatGPT) and a previously developed regular expression (RegexT) to identify overweight body condition scores (BCS) in veterinary narratives. Methods: BCS values were extracted from 4,415 anonymised clinical narratives using either RegexT or by appending the narrative to a prompt sent to ChatGPT coercing the model to return the BCS information. Data were manually reviewed for comparison. Results: The precision of RegexT was higher (100%, 95% CI 94.81-100%) than the ChatGPT (89.3%; 95% CI82.75-93.64%). However, the recall of ChatGPT (100%. 95% CI 96.18-100%) was considerably higher than that of RegexT (72.6%, 95% CI 63.92-79.94%). Limitations: Subtle prompt engineering is needed to improve ChatGPT output. Conclusions: Large language models create diverse opportunities and, whilst complex, present an intuitive interface to in
    
[^21]: 圣杯2.0：从自然语言到约束模型

    Holy Grail 2.0: From Natural Language to Constraint Models. (arXiv:2308.01589v1 [cs.AI])

    [http://arxiv.org/abs/2308.01589](http://arxiv.org/abs/2308.01589)

    本文通过利用预训练的大型语言模型从文本问题描述中提取模型的方法，探索了一种使约束编程更易于采用的方法。

    

    27年前，E. Freuder强调了“约束编程代表了计算机科学对于编程的一个最接近圣杯的方法：用户陈述问题，计算机解决问题”。如今，CP用户拥有强大的建模工具（如Minizinc和CPMpy），可以用它们来表达问题，然后让求解器完成剩下的工作，离目标更近了。然而，这仍然要求CP用户了解形式化方法并遵守它。另一个重要的挑战在于需要专业知识才能有效地对组合问题建模。所有这些限制了CP的广泛应用。在这篇立场论文中，我们探讨了一种利用预训练的大型语言模型从文本问题描述中提取模型的可能方法。具体来说，我们从自然语言处理优化（NL4OPT）挑战中获得灵感，并展示了一个基于分解的提示应用的初步结果。

    Twenty-seven years ago, E. Freuder highlighted that "Constraint programming represents one of the closest approaches computer science has yet made to the Holy Grail of programming: the user states the problem, the computer solves it". Nowadays, CP users have great modeling tools available (like Minizinc and CPMpy), allowing them to formulate the problem and then let a solver do the rest of the job, getting closer to the stated goal. However, this still requires the CP user to know the formalism and respect it. Another significant challenge lies in the expertise required to effectively model combinatorial problems. All this limits the wider adoption of CP. In this position paper, we investigate a possible approach to leverage pre-trained Large Language Models to extract models from textual problem descriptions. More specifically, we take inspiration from the Natural Language Processing for Optimization (NL4OPT) challenge and present early results with a decomposition-based prompting app
    
[^22]: InterAct: 探索将ChatGPT作为合作代理人的潜力

    InterAct: Exploring the Potentials of ChatGPT as a Cooperative Agent. (arXiv:2308.01552v1 [cs.AI])

    [http://arxiv.org/abs/2308.01552](http://arxiv.org/abs/2308.01552)

    本研究将OpenAI的ChatGPT集成到具身智能体系统中，通过将ChatGPT分配不同角色并与原始语言模型集成，实现了98%的成功率，并在实际环境中展现了ChatGPT在理解和执行复杂任务方面的能力。

    

    本研究论文探讨了将OpenAI的ChatGPT集成到具身智能体系统中，评估其对交互决策基准的影响。我们引入InterAct这一概念，将其类比于人们根据自己独特的优势扮演角色的概念。在这种方法中，我们给ChatGPT提供各种提示，将其分配为像检查员和分类员这样的多种角色，然后将它们与原始语言模型集成。我们的研究在AlfWorld中展示了98%的显著成功率，AlfWorld是一个模拟家庭环境中包含6个不同任务的基准测试，强调了良好的提示工程的重要性。结果强调了ChatGPT在理解和高效地执行复杂任务方面的能力，为任务规划的进一步发展铺平了道路。

    This research paper delves into the integration of OpenAI's ChatGPT into embodied agent systems, evaluating its influence on interactive decision-making benchmark. Drawing a parallel to the concept of people assuming roles according to their unique strengths, we introduce InterAct. In this approach, we feed ChatGPT with varied prompts, assigning it a numerous roles like a checker and a sorter, then integrating them with the original language model. Our research shows a remarkable success rate of 98% in AlfWorld, which consists of 6 different tasks in a simulated household environment, emphasizing the significance of proficient prompt engineering. The results highlight ChatGPT's competence in comprehending and performing intricate tasks effectively in real-world settings, thus paving the way for further advancements in task planning.
    
[^23]: 预训练的仅文本变压器中的多模态神经元

    Multimodal Neurons in Pretrained Text-Only Transformers. (arXiv:2308.01544v1 [cs.CV])

    [http://arxiv.org/abs/2308.01544](http://arxiv.org/abs/2308.01544)

    研究了在预训练的文本变压器中如何通过引入视觉信息来实现多模态能力，在变压器的更深处进行模态之间的转换，并介绍了一种识别多模态神经元的方法，展示了它们对特定视觉概念的操作以及对图像字幕生成的因果效应。

    

    语言模型展现了在不同模态下将学习到的表示推广到其他模态下游任务的显著能力。我们研究了一个冻结的文本变压器增加视觉能力的情况，使用了一个自监督视觉编码器和一个在图像到文本任务上学习得到的单一线性映射。映射层的输出不是可以直接解码成描述图像内容的语言，相反，我们发现模态之间的转换发生在变压器的更深处。我们引入了一种识别将视觉表示转换为相应文本的“多模态神经元”的过程，并解码它们注入模型残差流中的概念。通过一系列实验，我们展示了多模态神经元在不同输入中对特定视觉概念进行操作，并对图像字幕生成具有系统性的因果效应。

    Language models demonstrate remarkable capacity to generalize representations learned in one modality to downstream tasks in other modalities. Can we trace this ability to individual neurons? We study the case where a frozen text transformer is augmented with vision using a self-supervised visual encoder and a single linear projection learned on an image-to-text task. Outputs of the projection layer are not immediately decodable into language describing image content; instead, we find that translation between modalities occurs deeper within the transformer. We introduce a procedure for identifying "multimodal neurons" that convert visual representations into corresponding text, and decoding the concepts they inject into the model's residual stream. In a series of experiments, we show that multimodal neurons operate on specific visual concepts across inputs, and have a systematic causal effect on image captioning.
    
[^24]: 比较可扩展的生成数值角度的策略

    Comparing scalable strategies for generating numerical perspectives. (arXiv:2308.01535v1 [cs.HC])

    [http://arxiv.org/abs/2308.01535](http://arxiv.org/abs/2308.01535)

    本文比较了三种大规模角度生成策略：基于规则的方法、众包系统和使用维基百科数据和语义相似性的模型。研究发现这三种方法的组合优于单一方法，并且在不同情境中有着不同的优势，用户的偏好也有所不同。在最后，文章还讨论了在一个广泛使用的在线文字处理器中应用角度的情况。

    

    数值角度帮助人们理解极端和不熟悉的数值（例如，3300亿美元相当于每个美国人1000美元）。尽管研究表明角度是有帮助的，但要在大规模上生成它们是具有挑战性的，因为很难确定什么使某些类比更有帮助，而且因为最有帮助的因素可能因上下文而异。在这里，我们提出并比较了三种大规模角度生成策略：基于规则的方法、众包系统和使用维基百科数据和语义相似性（通过BERT嵌入）生成特定上下文角度的模型。我们发现这三种方法的组合优于单一方法，不同的方法在不同情境中表现出色，用户对不同方法有异质偏好。我们最后讨论了在广泛使用的在线文字处理器中应用角度的情况。

    Numerical perspectives help people understand extreme and unfamiliar numbers (e.g., \$330 billion is about \$1,000 per person in the United States). While research shows perspectives to be helpful, generating them at scale is challenging both because it is difficult to identify what makes some analogies more helpful than others, and because what is most helpful can vary based on the context in which a given number appears. Here we present and compare three policies for large-scale perspective generation: a rule-based approach, a crowdsourced system, and a model that uses Wikipedia data and semantic similarity (via BERT embeddings) to generate context-specific perspectives. We find that the combination of these three approaches dominates any single method, with different approaches excelling in different settings and users displaying heterogeneous preferences across approaches. We conclude by discussing our deployment of perspectives in a widely-used online word processor.
    
[^25]: 大型语言模型展示出对新颖文学隐喻的解释能力

    Large Language Model Displays Emergent Ability to Interpret Novel Literary Metaphors. (arXiv:2308.01497v1 [cs.CL])

    [http://arxiv.org/abs/2308.01497](http://arxiv.org/abs/2308.01497)

    最近的研究评估了GPT-4，一种大型语言模型，对来自塞尔维亚诗歌的新颖文学隐喻的解释能力。

    

    最近在大型语言模型（LLMs）性能方面的进展引发了关于这种通用人工智能（AI）是否能够在足够的训练下展现出高水平人类能力的争论。尽管LLMs在涉及自然语言处理和推理的各种任务中表现出色，但对它们的能力是否延伸到更具创造力的人类能力存在严重分歧。其中一个核心问题是解释新颖隐喻的能力。由于用于训练LLMs的庞大且非策划的文本语料库，设计测试的一个严重障碍就是需要找到新颖但高质量的隐喻，这些隐喻不太可能出现在训练数据中。在这里，我们评估了GPT-4，一种最先进的大型语言模型，对来自塞尔维亚诗歌并翻译为英语的新颖文学隐喻的自然语言解释能力。

    Recent advances in the performance of large language models (LLMs) have sparked debate over whether, given sufficient training, high-level human abilities emerge in such generic forms of artificial intelligence (AI). Despite the exceptional performance of LLMs on a wide range of tasks involving natural language processing and reasoning, there has been sharp disagreement as to whether their abilities extend to more creative human abilities. A core example is the ability to interpret novel metaphors. Given the enormous and non-curated text corpora used to train LLMs, a serious obstacle to designing tests is the requirement of finding novel yet high-quality metaphors that are unlikely to have been included in the training data. Here we assessed the ability of GPT-4, a state-of-the-art large language model, to provide natural-language interpretations of novel literary metaphors drawn from Serbian poetry and translated into English. Despite exhibiting no signs of having been exposed to thes
    
[^26]: 在任务主动设置中研究强化学习在通信策略中的应用

    Investigating Reinforcement Learning for Communication Strategies in a Task-Initiative Setting. (arXiv:2308.01479v1 [cs.CL])

    [http://arxiv.org/abs/2308.01479](http://arxiv.org/abs/2308.01479)

    在这项工作中，我们通过分析模拟实验，研究了在任务主动设置中应用强化学习来处理系统和用户之间的引用通信任务，并发现基于一致性的对话策略具有潜力成为有效的策略选择方法。

    

    许多对话域需要系统向用户呈现细微差别的信息。这样的系统必须在他们说话后进行追问以解答疑问和纠正误解。在这项工作中，我们在一项引用通信任务中探索了这种互动策略。通过模拟，我们分析了初始呈现和随后追问之间的通信权衡，这是用户澄清策略的一个函数。我们将几种基线策略与强化学习得来的策略性进行了比较。我们发现，基于一致性的对话策略表示具有令人惊讶的优势，该方法要求的数据需求很小，选择解释性强，并具有强大的审计能力，但在广泛的用户模型范围内预测结果几乎没有损失。

    Many conversational domains require the system to present nuanced information to users. Such systems must follow up what they say to address clarification questions and repair misunderstandings. In this work, we explore this interactive strategy in a referential communication task. Using simulation, we analyze the communication trade-offs between initial presentation and subsequent followup as a function of user clarification strategy, and compare the performance of several baseline strategies to policies derived by reinforcement learning. We find surprising advantages to coherence-based representations of dialogue strategy, which bring minimal data requirements, explainable choices, and strong audit capabilities, but incur little loss in predicted outcomes across a wide range of user models.
    
[^27]: 反向稳定扩散：生成该图像所使用的提示是什么？

    Reverse Stable Diffusion: What prompt was used to generate this image?. (arXiv:2308.01472v1 [cs.CV])

    [http://arxiv.org/abs/2308.01472](http://arxiv.org/abs/2308.01472)

    本论文介绍了一种新的任务，即在给定由生成扩散模型生成的图像的情况下预测文本提示。为了解决这个问题，作者结合了多种白盒和黑盒模型，提出了一个新颖的学习框架，该框架能够生成改进的提示，并采用课程学习和无监督领域自适应核学习方法来进一步提高方法的性能。

    

    文本到图像扩散模型，如稳定扩散，最近吸引了许多研究人员的兴趣，反向扩散过程在更好地理解生成过程和如何设计提示以获得所需图像方面起着重要作用。为此，我们引入了一种新的任务，即在给定由生成扩散模型生成的图像的情况下预测文本提示。我们结合了一系列白盒和黑盒模型（有和无对扩散网络权重进行访问）来处理所提出的任务。我们提出了一个新颖的学习框架，包括联合提示回归和多标签词汇分类目标，生成改进的提示。为了进一步改进我们的方法，我们采用了一个课程学习过程，促进了具有更低标注噪声（即更好对齐）的图像提示对的学习，并且使用相似性进行无监督领域自适应核学习方法。

    Text-to-image diffusion models such as Stable Diffusion have recently attracted the interest of many researchers, and inverting the diffusion process can play an important role in better understanding the generative process and how to engineer prompts in order to obtain the desired images. To this end, we introduce the new task of predicting the text prompt given an image generated by a generative diffusion model. We combine a series of white-box and black-box models (with and without access to the weights of the diffusion network) to deal with the proposed task. We propose a novel learning framework comprising of a joint prompt regression and multi-label vocabulary classification objective that generates improved prompts. To further improve our method, we employ a curriculum learning procedure that promotes the learning of image-prompt pairs with lower labeling noise (i.e. that are better aligned), and an unsupervised domain-adaptive kernel learning method that uses the similarities b
    
[^28]: FinVis-GPT:一种用于金融图表分析的多模态大型语言模型

    FinVis-GPT: A Multimodal Large Language Model for Financial Chart Analysis. (arXiv:2308.01430v1 [cs.CL])

    [http://arxiv.org/abs/2308.01430](http://arxiv.org/abs/2308.01430)

    本文介绍了一种名为FinVis-GPT的多模态大型语言模型，用于金融图表分析。通过结合语言模型的能力和多模态特性，该模型能够解释金融图表并提供有价值的分析。通过实验证明，FinVis-GPT在生成描述、回答问题和预测未来市场趋势等金融图表相关任务上优于现有的多模态语言模型。该研究展示了在金融领域利用多模态语言模型的潜力。

    

    本文提出了FinVis-GPT，一种专为金融图表分析而设计的新型多模态大型语言模型（LLM）。通过利用LLM的能力，结合指令调整和多模态能力，FinVis-GPT能够解释金融图表并提供有价值的分析。为了训练FinVis-GPT，生成了一个金融任务导向的数据集，用于预训练对齐和指令调整，包括各种类型的金融图表及其相应的描述。由于时间限制，我们通过几个案例研究评估了模型的性能，结果显示FinVis-GPT在生成描述、回答问题和预测未来市场趋势等各种与金融图表相关的任务上优于现有最先进的多模态LLMs。所提出的FinVis-GPT在金融领域利用多模态LLMs方面具有开创性的贡献，我们生成的数据集将被用作今后研究的基础。

    In this paper, we propose FinVis-GPT, a novel multimodal large language model (LLM) specifically designed for financial chart analysis. By leveraging the power of LLMs and incorporating instruction tuning and multimodal capabilities, FinVis-GPT is capable of interpreting financial charts and providing valuable analysis. To train FinVis-GPT, a financial task oriented dataset was generated for pre-training alignment and instruction tuning, comprising various types of financial charts and their corresponding descriptions. We evaluate the model performance via several case studies due to the time limit, and the promising results demonstrated that FinVis-GPT is superior in various financial chart related tasks, including generating descriptions, answering questions and predicting future market trends, surpassing existing state-of-the-art multimodal LLMs. The proposed FinVis-GPT serves as a pioneering effort in utilizing multimodal LLMs in the finance domain and our generated dataset will be
    
[^29]: ChatMOF: 一种自主人工智能系统用于预测和生成金属-有机骨架

    ChatMOF: An Autonomous AI System for Predicting and Generating Metal-Organic Frameworks. (arXiv:2308.01423v1 [cs.CL])

    [http://arxiv.org/abs/2308.01423](http://arxiv.org/abs/2308.01423)

    ChatMOF是一种自主AI系统，用于预测和生成金属-有机骨架。通过利用大规模语言模型，它能够从文本输入中提取关键细节，并提供适当的回应。该系统通过组合代理、工具包和评估器的核心组件，实现了数据检索、性质预测和结构生成等多个任务。研究进一步展示了在材料科学中使用大型语言模型的优势和潜力。

    

    ChatMOF是一个自主人工智能系统，用于预测和生成金属-有机骨架（MOFs）。通过利用大规模语言模型（gpt-3.5-turbo），ChatMOF从文本输入中提取关键细节并提供适当的回应，从而消除了对刚性结构化查询的需求。该系统由三个核心组件（即代理、工具包和评估器）组成，形成一个强大的流水线，管理多种任务，包括数据检索、性质预测和结构生成。该研究进一步探讨了在材料科学中使用大型语言模型（LLMs）人工智能系统的优点和限制，并展示了其对未来发展的变革潜力。

    ChatMOF is an autonomous Artificial Intelligence (AI) system that is built to predict and generate of metal-organic frameworks (MOFs). By leveraging a large-scale language model (gpt-3.5-turbo), ChatMOF extracts key details from textual inputs and delivers appropriate responses, thus eliminating the necessity for rigid structured queries. The system is comprised of three core components (i.e. an agent, a toolkit, and an evaluator) and it forms a robust pipeline that manages a variety of tasks, including data retrieval, property prediction, and structure generation. The study further explores the merits and constraints of using large language models (LLMs) AI system in material sciences using and showcases its transformative potential for future advancements.
    
[^30]: SAP-sLDA: 一个可解释的界面用于探索非结构化文本

    SAP-sLDA: An Interpretable Interface for Exploring Unstructured Text. (arXiv:2308.01420v1 [cs.CL])

    [http://arxiv.org/abs/2308.01420](http://arxiv.org/abs/2308.01420)

    SAP-sLDA提出了一种半监督人类参与的LDA方法，可以在低维投影中学习主题并保留文档之间的语义关系。

    

    一种探索文本语料库的常见方法是通过文档的低维投影，希望主题相似的文档能够在投影空间中聚类在一起。然而，常用的用于降维文本语料库的算法，如潜在狄利克雷分配（LDA），往往会产生无法捕捉文档相似性的人类概念的投影。我们提出了一种半监督人类参与的基于LDA的方法来学习主题，在低维投影中保留语义上有意义的文档之间的关系。在合成语料库上，我们的方法比仅提供少量标签的基线方法产生更易解释的投影。在实际语料库上，我们获得了类似的结果。

    A common way to explore text corpora is through low-dimensional projections of the documents, where one hopes that thematically similar documents will be clustered together in the projected space. However, popular algorithms for dimensionality reduction of text corpora, like Latent Dirichlet Allocation (LDA), often produce projections that do not capture human notions of document similarity. We propose a semi-supervised human-in-the-loop LDA-based method for learning topics that preserve semantically meaningful relationships between documents in low-dimensional projections. On synthetic corpora, our method yields more interpretable projections than baseline methods with only a fraction of labels provided. On a real corpus, we obtain qualitatively similar results.
    
[^31]: 一个有效的数据创建流水线用于为大型语言模型生成高质量的金融指令数据

    An Effective Data Creation Pipeline to Generate High-quality Financial Instruction Data for Large Language Model. (arXiv:2308.01415v1 [cs.CL])

    [http://arxiv.org/abs/2308.01415](http://arxiv.org/abs/2308.01415)

    本文提出了一个精心设计的数据创建流水线，通过与金融专家的对话和反馈，在大型语言模型中生成了一个高质量的金融指令数据集。实验结果表明，该方法在生成准确、相关和金融风格响应方面取得了显著进展。

    

    在大型语言模型的初期阶段，为金融相关任务精调大型语言模型生成高质量的金融数据集非常关键。因此，本文提出了一个精心设计的数据创建流水线来实现这一目的。具体而言，我们使用ChatGPT引发了一个AI投资者和金融专家之间的对话，并融入了人工金融专家的反馈，从而改进了数据集。该流水线产生了一个由103k个多轮对话组成的稳定的指令精调数据集。通过采用外部的GPT-4作为评判者，在该数据集上进行了大量实验来评估模型的性能。有希望的实验结果验证了我们的方法在生成准确、相关和金融风格响应方面取得了显著进展，从而为金融领域的应用提供了一个强大的工具。

    At the beginning era of large language model, it is quite critical to generate a high-quality financial dataset to fine-tune a large language model for financial related tasks. Thus, this paper presents a carefully designed data creation pipeline for this purpose. Particularly, we initiate a dialogue between an AI investor and financial expert using ChatGPT and incorporate the feedback of human financial experts, leading to the refinement of the dataset. This pipeline yielded a robust instruction tuning dataset comprised of 103k multi-turn chats. Extensive experiments have been conducted on this dataset to evaluate the model's performance by adopting an external GPT-4 as the judge. The promising experimental results verify that our approach led to significant advancements in generating accurate, relevant, and financial-style responses from AI models, and thus providing a powerful tool for applications within the financial sector.
    
[^32]: HouYi: 一种专门为可再生能源和碳中和领域设计的开源大型语言模型

    HouYi: An open-source large language model specially designed for renewable energy and carbon neutrality field. (arXiv:2308.01414v1 [cs.CL])

    [http://arxiv.org/abs/2308.01414](http://arxiv.org/abs/2308.01414)

    本论文发布了第一个专门为可再生能源领域设计的开源大型语言模型HouYi及其对应的可再生能源学术论文数据集REAP。HouYi展示了在生成可再生能源领域学术论文段落方面的强大能力，与ChatGPT相当，略优于Clau。

    

    可再生能源对于实现碳中和目标至关重要。大型语言模型（LLMs）的成功应用，如ChatGPT在自动内容生成方面的成功，使得LLMs在可再生能源领域扮演越来越重要的角色。然而，目前还没有专门为可再生能源领域设计的LLM，也没有任何可再生能源的数据集用于训练LLM。因此，本论文发布了第一个面向非商业性可再生能源LLM研究的开源可再生能源学术论文（REAP）数据集。REAP数据集通过从Web of Science搜索1168970篇学术文献的标题和摘要进行收集。基于REAP数据集，通过对通用LLMs进行微调，开发了第一个针对可再生能源的LLM模型HouYi。HouYi在可再生能源领域展示了强大的学术论文段落生成能力。实验结果显示，它在生成可再生能源学术论文方面的能力与ChatGPT相当，在某些方面略优于Clau。

    Renewable energy is important for achieving carbon neutrality goal. With the great success of Large Language Models (LLMs) like ChatGPT in automatic content generation, LLMs are playing an increasingly important role. However, there has not been a specially designed LLM for renewable energy. Meanwhile, there has not been any dataset of renewable energy for training LLMs. Therefore, this paper published the first open-source Renewable Energy Academic Paper (REAP) dataset for non-commercial LLM research of renewable energy. REAP dataset is collected through searching the title and abstract of 1,168,970 academic literatures from Web of Science. Based on REAP dataset, HouYi model, the first LLM for renewable energy, is developed through finetuning general LLMs. HouYi demonstrated powerful academic paper paragraph generation ability in renewable energy field. Experiments show that its ability to generate academic papers on renewable energy is comparable to ChatGPT, slightly outperforms Clau
    
[^33]: LaFiCMIL：从相关多实例学习的角度重新思考大文件分类

    LaFiCMIL: Rethinking Large File Classification from the Perspective of Correlated Multiple Instance Learning. (arXiv:2308.01413v1 [cs.CL])

    [http://arxiv.org/abs/2308.01413](http://arxiv.org/abs/2308.01413)

    LaFiCMIL是一个新的方法，从相关多实例学习的角度解决了Transformer模型输入长度限制的问题，可以用于改进大文件分类任务。

    

    基于Transformer的模型在各种语言任务的性能上取得了革命性的突破。直观上，人们可能会期望文本分类，作为不需要像生成任务那样许多高级表示的任务，能够充分利用Transformer强大的表示能力来进行综合性的处理。然而，实际上，在多类别和多标签分类长文本文档和其他大文件的领域仍然存在较大的改进潜力。Transformer模型的性能主要受到一个重要限制的阻碍：有限的输入长度，比如BERT的512个标记。虽然增加GPU内存可以稍微扩展这个限制，但实际应用中往往受限于有限的GPU资源。在这项工作中，我们从相关多实例学习的角度解决了输入限制问题。所提出的方法LaFiCMIL，作为一个多功能的框架，适用于

    Transformer-based models have revolutionized the performance of a wide range of language tasks. Intuitively, one might expect text classification, which does not necessitate as many high-level representations as generative tasks, to be comprehensively addressed with the powerful representation capabilities of Transformers. However, in reality, there remains significant potential for enhancement, particularly in the areas of multi-class and multi-label classification of lengthy textual documents and other large files. The performance of Transformer-based models is mainly hindered by a major limitation: a restricted input length, e.g., 512 tokens for BERT. While an increase in GPU memory can marginally extend this limit, practical real-world applications often operate under constrained GPU resources. In this work, we tackle the input limit problem from the perspective of correlated multiple instance learning. The proposed approach, LaFiCMIL, serves as a versatile framework applicable to 
    
[^34]: UPB在IberLEF-2023 AuTexTification中使用Transformer集成检测机器生成的文本

    UPB at IberLEF-2023 AuTexTification: Detection of Machine-Generated Text using Transformer Ensembles. (arXiv:2308.01408v1 [cs.CL])

    [http://arxiv.org/abs/2308.01408](http://arxiv.org/abs/2308.01408)

    UPB团队在IberLEF-2023的AuTexTification共享任务中使用Transformer集成模型，通过识别由大型语言模型生成的文本，取得了较高的宏F1分数。 (translated_abstract)

    

    本文描述了UPB团队在IberLEF-2023的AuTexTification共享任务中提交的解决方案。我们参与了第一个子任务，即识别由大型语言模型而不是人类生成的文本文档。组织者为这个子任务提供了一个双语数据集，包括英文和西班牙文的文本，涵盖了法律文本、社交媒体帖子和操作指南等多个领域。我们主要使用基于Transformer的深度学习模型以及训练技巧（如多任务学习和虚拟对抗训练）进行实验，以获得更好的结果。我们提交了三个运行结果，其中两个是集成模型。我们最好的模型在英文数据集上获得了66.63%的宏F1分数，在西班牙文数据集上获得了67.10%的宏F1分数。

    This paper describes the solutions submitted by the UPB team to the AuTexTification shared task, featured as part of IberLEF-2023. Our team participated in the first subtask, identifying text documents produced by large language models instead of humans. The organizers provided a bilingual dataset for this subtask, comprising English and Spanish texts covering multiple domains, such as legal texts, social media posts, and how-to articles. We experimented mostly with deep learning models based on Transformers, as well as training techniques such as multi-task learning and virtual adversarial training to obtain better results. We submitted three runs, two of which consisted of ensemble models. Our best-performing model achieved macro F1-scores of 66.63% on the English dataset and 67.10% on the Spanish dataset.
    
[^35]: 蒙骗：基于文本的游戏中的欺骗与合作研究

    Hoodwinked: Deception and Cooperation in a Text-Based Game for Language Models. (arXiv:2308.01404v1 [cs.CL])

    [http://arxiv.org/abs/2308.01404](http://arxiv.org/abs/2308.01404)

    通过引入一款名为"Hoodwinked"的文本游戏，研究了当前语言模型是否具有欺骗和识别谎言的能力。实验证据表明，杀手经常否认罪行并指责他人，导致投票结果受到影响。更先进的模型在杀手效果上表现出优势。实验证据表明，这种改进是通过在讨论中更强的欺骗能力实现的。

    

    当前的语言模型是否具有欺骗和识别谎言的能力？我们通过引入一款名为“Hoodwinked”的基于文本的游戏，受到“黑帮”和“谁是卧底”游戏的启发，来研究这个问题。玩家们被锁在一个房子里，必须找到一把钥匙才能逃脱，但其中一个玩家被派任务杀死其他人。每次发生谋杀，幸存的玩家们会进行自然语言讨论，然后投票将一名玩家放逐出游戏。我们使用GPT-3、GPT-3.5和GPT-4操控代理进行实验，并发现了欺骗和识别谎言的能力证据。杀手经常否认自己的罪行并指责他人，导致投票结果受到可测量的影响。更先进的模型在24个两两比较中的18个中表现出更高的杀手效果，超越了更小的模型。次要指标提供了证据，表明这种改进并不是通过不同的行动实现的，而是通过在讨论中更强的欺骗能力实现的。总的来说，我们发现了实质性的创新。

    Are current language models capable of deception and lie detection? We study this question by introducing a text-based game called $\textit{Hoodwinked}$, inspired by $\textit{Mafia}$ and $\textit{Among Us}$. Players are locked in a house and must find a key to escape, but one player is tasked with killing the others. Each time a murder is committed, the surviving players have a natural language discussion then vote to banish one player from the game. We conduct experiments with agents controlled by GPT-3, GPT-3.5, and GPT-4 and find evidence of deception and lie detection capabilities. The killer often denies their crime and accuses others, leading to measurable effects on voting outcomes. More advanced models are more effective killers, outperforming smaller models in 18 of 24 pairwise comparisons. Secondary metrics provide evidence that this improvement is not mediated by different actions, but rather by stronger deception capabilities during discussions. Overall, we find substantial
    
[^36]: 通过语言学习对世界建模

    Learning to Model the World with Language. (arXiv:2308.01399v1 [cs.CL])

    [http://arxiv.org/abs/2308.01399](http://arxiv.org/abs/2308.01399)

    本论文提出了一种通过语言学习对世界进行建模的方法，利用语言帮助代理器预测未来并进行行动。通过学习多模态世界模型，代理器可以预测未来的文本和图像表示，并在模型回滚中进行行动。

    

    为了与人类在世界中相互作用，代理器需要理解人们使用的多样化的语言类型，并将其与视觉世界关联起来，并基于语言行动。虽然当前的代理器可以通过任务奖励学习执行简单的语言指令，但我们的目标是建立可以利用传达一般知识、描述世界状态、提供互动反馈等多样化语言的代理器。我们的核心思想是语言帮助代理器预测未来：将会被观察到什么、世界将如何运行以及哪些情况将获得奖励。这个观点将语言理解与未来预测统一为一个强大的自监督学习目标。我们提出了Dynalang，一种学习多模态世界模型的代理器，它可以预测未来的文本和图像表示，并在想像的模型回滚中学习行动。与只使用语言预测动作的传统代理器不同，Dynalang通过过去的语言还可以获取丰富的语言理解能力。

    To interact with humans in the world, agents need to understand the diverse types of language that people use, relate them to the visual world, and act based on them. While current agents learn to execute simple language instructions from task rewards, we aim to build agents that leverage diverse language that conveys general knowledge, describes the state of the world, provides interactive feedback, and more. Our key idea is that language helps agents predict the future: what will be observed, how the world will behave, and which situations will be rewarded. This perspective unifies language understanding with future prediction as a powerful self-supervised learning objective. We present Dynalang, an agent that learns a multimodal world model that predicts future text and image representations and learns to act from imagined model rollouts. Unlike traditional agents that use language only to predict actions, Dynalang acquires rich language understanding by using past language also to 
    
[^37]: 通过提示工程优化机器翻译：ChatGPT可定制性的研究

    Optimizing Machine Translation through Prompt Engineering: An Investigation into ChatGPT's Customizability. (arXiv:2308.01391v1 [cs.CL])

    [http://arxiv.org/abs/2308.01391](http://arxiv.org/abs/2308.01391)

    本文研究了通过在ChatGPT中运用合适的提示将翻译目的和目标受众融入进去对翻译质量的影响。研究发现，这种方法可以产生灵活的翻译结果，相比传统机器翻译更具定制性。

    

    本文探讨将翻译目的和目标受众融入到ChatGPT提示中对翻译质量的影响。研究借鉴了之前的翻译研究、行业实践和ISO标准，强调了翻译过程中预生产阶段的重要性。研究发现，在像ChatGPT这样的大规模语言模型中使用适当的提示可以产生灵活的翻译，这是传统的机器翻译所没有实现的。研究审查了在生成满足特定条件的翻译时，提示对翻译质量的影响。评估从实际翻译师的角度进行，主观和定性相结合，还使用了OpenAI的词嵌入API进行余弦相似度计算。研究结果表明，将翻译目的和目标受众融入到提示中确实可以修改生成的翻译。

    This paper explores the influence of integrating the purpose of the translation and the target audience into prompts on the quality of translations produced by ChatGPT. Drawing on previous translation studies, industry practices, and ISO standards, the research underscores the significance of the pre-production phase in the translation process. The study reveals that the inclusion of suitable prompts in large-scale language models like ChatGPT can yield flexible translations, a feat yet to be realized by conventional Machine Translation (MT). The research scrutinizes the changes in translation quality when prompts are used to generate translations that meet specific conditions. The evaluation is conducted from a practicing translator's viewpoint, both subjectively and qualitatively, supplemented by the use of OpenAI's word embedding API for cosine similarity calculations. The findings suggest that the integration of the purpose and target audience into prompts can indeed modify the gen
    
[^38]: 实证翻译过程研究：过去和可能的未来视角

    Empirical Translation Process Research: Past and Possible Future Perspectives. (arXiv:2308.01368v1 [cs.CL])

    [http://arxiv.org/abs/2308.01368](http://arxiv.org/abs/2308.01368)

    本文追踪了实证翻译过程研究的发展，提出了自由能原理和主动推理作为建模深嵌入式翻译过程的框架，为未来研究提供了激动人心的前景。

    

    在过去的四十年里，人们一直致力于开发和评估实证翻译过程研究（TPR）的模型，但一个全面的框架仍然难以捉摸。本文追踪了CRITT TPR-DB传统中实证TPR的发展，并提出了自由能原理（FEP）和主动推理（AIF）作为建模深嵌入式翻译过程的框架。它引入了量化关联理论（相关性，s-mode，i-mode）基本概念的新方法，并建立了它们与监控模型的关系，将关联性最大化定为最小化自由能的特例。FEP/AIF提供了一个数学严谨的基础，可以建模不同时间线上展开的嵌入式翻译过程的深层时间架构。这个框架为预测性TPR的未来研究开辟了令人兴奋的前景，有望丰富我们对人类翻译过程的理解，并为实践提供了宝贵的参考。

    Over the past four decades, efforts have been made to develop and evaluate models for Empirical Translation Process Research (TPR), yet a comprehensive framework remains elusive. This article traces the evolution of empirical TPR within the CRITT TPR-DB tradition and proposes the Free Energy Principle (FEP) and Active Inference (AIF) as a framework for modeling deeply embedded translation processes. It introduces novel approaches for quantifying fundamental concepts of Relevance Theory (relevance, s-mode, i-mode), and establishes their relation to the Monitor Model, framing relevance maximization as a special case of minimizing free energy. FEP/AIF provides a mathematically rigorous foundation that enables modeling of deep temporal architectures in which embedded translation processes unfold on different timelines. This framework opens up exciting prospects for future research in predictive TPR, likely to enrich our comprehension of human translation processes, and making valuable cont
    
[^39]: Careful Whisper - 利用自动语音识别的进展来进行健壮且易解释的失语症亚型分类

    Careful Whisper -- leveraging advances in automatic speech recognition for robust and interpretable aphasia subtype classification. (arXiv:2308.01327v1 [cs.SD])

    [http://arxiv.org/abs/2308.01327](http://arxiv.org/abs/2308.01327)

    本文提出了一种利用自动语音识别对失语症亚型进行分类的方法，通过结合不同模型的技术，能够利用声音录音自动识别并评估言语障碍。该方法在区分失语症患者和健康对照组的录音时表现出与人类水平相近的准确性，并且可以以较高的准确率区分最常见的失语症类型。该方法还可以应用于其他疾病和语言，并有望稳健地提取诊断性的言语生物标志。

    

    本文提出了一种全自动的方法，通过声音录音识别来辅助评估言语障碍。通过结合连接主义时间分类（CTC）和基于编码器-解码器的自动语音识别模型，我们生成了丰富的声学和清晰的转录。然后，我们应用几种自然语言处理方法从这些转录中提取特征，以生成健康语音的原型。基于这些原型的基本距离度量作为标准机器学习分类器的输入特征，能够在人类水平上区分失语症患者的录音和健康对照组。此外，最常见的失语症类型可以以90%的准确率进行区分。该流程可直接适用于其他疾病和语言，展示了强大的潜力来稳健地提取诊断性言语生物标志。

    This paper presents a fully automated approach for identifying speech anomalies from voice recordings to aid in the assessment of speech impairments. By combining Connectionist Temporal Classification (CTC) and encoder-decoder-based automatic speech recognition models, we generate rich acoustic and clean transcripts. We then apply several natural language processing methods to extract features from these transcripts to produce prototypes of healthy speech. Basic distance measures from these prototypes serve as input features for standard machine learning classifiers, yielding human-level accuracy for the distinction between recordings of people with aphasia and a healthy control group. Furthermore, the most frequently occurring aphasia types can be distinguished with 90% accuracy. The pipeline is directly applicable to other diseases and languages, showing promise for robustly extracting diagnostic speech biomarkers.
    
[^40]: DeepSpeed-Chat: Easy, Fast and Affordable RLHF Training of ChatGPT-like Models at All Scales.

    DeepSpeed-Chat: Easy, Fast and Affordable RLHF Training of ChatGPT-like Models at All Scales. (arXiv:2308.01320v1 [cs.LG])

    [http://arxiv.org/abs/2308.01320](http://arxiv.org/abs/2308.01320)

    DeepSpeed-Chat是一个新颖的系统，使得ChatGPT-like模型的RLHF培训易于访问，高效且经济实惠。它具有易于使用的训练和推断体验，复制了InstructGPT的训练流程，并集成了各种训练和推断优化，提供了无与伦比的效率和可扩展性。

    

    ChatGPT-like模型在人工智能的各种应用中带来了革命，从摘要和编码到翻译，甚至超越了人类表现。然而，当前环境还缺乏一种易于访问、高效且经济实惠的端到端RLHF（强化学习与人类反馈）训练流程，特别是当训练规模达到数十亿参数时。本文介绍了DeepSpeed-Chat，这是一个新颖的系统，使RLHF培训对AI社区可用。DeepSpeed-Chat提供了三个关键能力：一个易于使用的ChatGPT-like模型的训练和推断体验，一个复制InstructGPT训练流程的DeepSpeed-RLHF流水线，以及一个集成了各种训练和推断优化的强大DeepSpeed-RLHF系统。该系统提供了无与伦比的效率和可扩展性，可以训练具有数千亿参数的模型。

    ChatGPT-like models have revolutionized various applications in artificial intelligence, from summarization and coding to translation, matching or even surpassing human performance. However, the current landscape lacks an accessible, efficient, and cost-effective end-to-end RLHF (Reinforcement Learning with Human Feedback) training pipeline for these powerful models, particularly when training at the scale of billions of parameters. This paper introduces DeepSpeed-Chat, a novel system that democratizes RLHF training, making it accessible to the AI community. DeepSpeed-Chat offers three key capabilities: an easy-to-use training and inference experience for ChatGPT-like models, a DeepSpeed-RLHF pipeline that replicates the training pipeline from InstructGPT, and a robust DeepSpeed-RLHF system that combines various optimizations for training and inference in a unified way. The system delivers unparalleled efficiency and scalability, enabling training of models with hundreds of billions of
    
[^41]: 关于最先进生成模型的可信度景观：一项综合调查

    On the Trustworthiness Landscape of State-of-the-art Generative Models: A Comprehensive Survey. (arXiv:2307.16680v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.16680](http://arxiv.org/abs/2307.16680)

    本文综合调查了大规模生成模型的可信度问题，涵盖了隐私、安全、公平性和责任等多个维度，并提出了实际建议和未来发展方向。

    

    扩散模型和大规模语言模型已经成为领先的生成模型，并对人类生活的各个方面产生了革命性的影响。然而，这些模型的实际应用也暴露出固有的风险，突显了它们的双重性质，并引发了对它们可信度的担忧。尽管有大量关于这个主题的文献，但针对大规模生成模型及其可信度的综合调查仍然很少见。为了弥补这一空白，本文调查了涉及这些模型的长期和新兴威胁，涵盖了隐私、安全、公平和责任这四个基本维度。通过这种方式，我们构建了一张详尽的地图，概述了这些模型的可信度，并提供了实际建议和未来的发展方向。这些努力对于促进这些模型的可信度部署至关重要。

    Diffusion models and large language models have emerged as leading-edge generative models and have sparked a revolutionary impact on various aspects of human life. However, the practical implementation of these models has also exposed inherent risks, highlighting their dual nature and raising concerns regarding their trustworthiness. Despite the abundance of literature on this subject, a comprehensive survey specifically delving into the intersection of large-scale generative models and their trustworthiness remains largely absent. To bridge this gap, This paper investigates both the long-standing and emerging threats associated with these models across four fundamental dimensions: privacy, security, fairness, and responsibility. In this way, we construct an extensive map outlining the trustworthiness of these models, while also providing practical recommendations and identifying future directions. These efforts are crucial for promoting the trustworthy deployment of these models, ulti
    
[^42]: Gzip与KNN在文本分类中的对比研究

    Gzip versus bag-of-words for text classification with KNN. (arXiv:2307.15002v1 [cs.CL])

    [http://arxiv.org/abs/2307.15002](http://arxiv.org/abs/2307.15002)

    Gzip与KNN相比较在文本分类中，我们发现通过简单的词袋匹配可以获得类似或更好的准确性，并且更加高效。

    

    最近，基于KNN的文本分类中压缩距离（gzip）的有效性引起了很多关注。在本文中，我们展示了通过更简单的方法可以达到类似或更好的效果，并且可能不需要文本压缩。实际上，我们发现简单的“词袋”匹配可以达到类似或更好的准确性，并且更高效。

    The effectiveness of compression distance in KNN-based text classification ('gzip') has recently garnered lots of attention. In this note, we show that similar or better effectiveness can be achieved with simpler means, and text compression may not be necessary. Indeed, we find that a simple 'bag-of-words' matching can achieve similar or better accuracy, and is more efficient.
    
[^43]: 人类和大型语言模型中的归纳推理

    Inductive reasoning in humans and large language models. (arXiv:2306.06548v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.06548](http://arxiv.org/abs/2306.06548)

    本研究使用GPT-3.5和GPT-4对人类归纳推理中的属性归纳问题进行了实验。结果表明，尽管GPT-3.5有一些困难，但GPT-4的表现与人类相似，除了未能捕捉到前提的非单调性现象。这项工作为人类和机器智能提供了有趣的比较，并提供了用作未来研究基准的两个大型数据集。

    

    大型语言模型的卓越性能引发了人们对其是否能作为普通智能的模型或类似于人类认知的程度的疑问。我们通过将GPT-3.5和GPT-4应用于人类归纳推理中的一个经典问题，即属性归纳，来解决这个问题。通过两个实验，我们获取了人类在多个领域上的属性归纳任务上的判断。尽管GPT-3.5在捕捉人类行为的许多方面上有困难，但GPT-4更加成功：在很大程度上，它的表现与人类的表现在质上相匹配，唯一显著的例外是其未能捕捉到前提的非单调性现象。我们的工作证明了属性归纳可以对人类和机器智能进行有趣的比较，并提供了两个大型数据集，可以作为未来在这一领域中的基准。

    The impressive recent performance of large language models has led many to wonder to what extent they can serve as models of general intelligence or are similar to human cognition. We address this issue by applying GPT-3.5 and GPT-4 to a classic problem in human inductive reasoning known as property induction. Over two experiments, we elicit human judgments on a range of property induction tasks spanning multiple domains. Although GPT-3.5 struggles to capture many aspects of human behaviour, GPT-4 is much more successful: for the most part, its performance qualitatively matches that of humans, and the only notable exception is its failure to capture the phenomenon of premise non-monotonicity. Our work demonstrates that property induction allows for interesting comparisons between human and machine intelligence and provides two large datasets that can serve as benchmarks for future work in this vein.
    
[^44]: 朝着可解释的野外视频质量评估：数据库和以语言提示为基础的方法

    Towards Explainable In-the-Wild Video Quality Assessment: A Database and a Language-Prompted Approach. (arXiv:2305.12726v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.12726](http://arxiv.org/abs/2305.12726)

    该论文提出了一个以语言提示为基础的方法和一个包含13个与质量相关因素的数据库，用于解决野外视频质量评估中的可解释性问题，该方法通过收集意见和数据来建立多维麦克斯韦数据库，以帮助评估视频质量。

    

    野外视频的蓬勃发展大大拓展了视频质量评估（VQA）问题。与通常只关注有限的失真类型的早期定义不同，野外视频上的VQA尤其具有挑战性，因为它可能受到各种失真和多样化内容的影响。虽然主观研究已经收集了这些视频的整体质量得分，但抽象质量得分与具体因素的关系仍然不清楚，这阻碍了VQA方法对质量评估的更具体评估（例如视频的清晰度）。为解决这个问题，我们收集了对13个与质量相关因素（包括捕捉中的真实失真，如运动模糊、噪声、闪烁；由压缩和传输引起的错误；以及对语义内容和审美问题的更高层次体验，如构成、镜头轨迹）下的4,543个野外视频的两百多万个意见，以建立多维度的麦克斯韦数据库。

    The proliferation of in-the-wild videos has greatly expanded the Video Quality Assessment (VQA) problem. Unlike early definitions that usually focus on limited distortion types, VQA on in-the-wild videos is especially challenging as it could be affected by complicated factors, including various distortions and diverse contents. Though subjective studies have collected overall quality scores for these videos, how the abstract quality scores relate with specific factors is still obscure, hindering VQA methods from more concrete quality evaluations (e.g. sharpness of a video). To solve this problem, we collect over two million opinions on 4,543 in-the-wild videos on 13 dimensions of quality-related factors, including in-capture authentic distortions (e.g. motion blur, noise, flicker), errors introduced by compression and transmission, and higher-level experiences on semantic contents and aesthetic issues (e.g. composition, camera trajectory), to establish the multi-dimensional Maxwell dat
    
[^45]: 自动发现的思维链提示可以推广到新模型和数据集

    An automatically discovered chain-of-thought prompt generalizes to novel models and datasets. (arXiv:2305.02897v1 [cs.CL])

    [http://arxiv.org/abs/2305.02897](http://arxiv.org/abs/2305.02897)

    本文研究了一系列零照顾提示在六个最新发布的语言模型和问题回答数据集的实验中的表现，发现自动提示发现的CoT提示可在新模型和数据集上表现良好，并在应用于GPT-4模型时取得最佳结果。

    

    新兴的思维链（CoT）推理能力有望提高大型语言模型（LLM）的性能和可解释性。然而，对于先前模型所制定的提示策略如何适用于新模型和不同数据集仍存在不确定性。在这项小型研究中，我们比较了一系列零照顾提示（zero-shot prompts）的性能，以诱导CoT推理，在6个最新发布的LLM（davinci-002，davinci-003，GPT-3.5-turbo，GPT-4，Flan-T5-xxl和Cohere command-xlarge）上与包括科学和医学领域的六个问答数据集混合在一起。我们发现，通过自动提示发现的CoT提示在实验条件下表现出鲁棒性，并在应用于最先进的GPT-4模型时产生最佳结果。

    Emergent chain-of-thought (CoT) reasoning capabilities promise to improve performance and explainability of large language models (LLMs). However, uncertainties remain about how prompting strategies formulated for previous model generations generalize to new model generations and different datasets. In this small-scale study we compare the performance of a range of zero-shot prompts for inducing CoT reasoning across six recently released LLMs (davinci-002, davinci-003, GPT-3.5-turbo, GPT-4, Flan-T5-xxl and Cohere command-xlarge) on a mixture of six question-answering datasets, including datasets from scientific and medical domains. We find that a CoT prompt that was previously discovered through automated prompt discovery shows robust performance across experimental conditions and produces best results when applied to the state-of-the-art model GPT-4.
    
[^46]: LLM是否足以用于任务导向型对话？

    Are LLMs All You Need for Task-Oriented Dialogue?. (arXiv:2304.06556v1 [cs.CL])

    [http://arxiv.org/abs/2304.06556](http://arxiv.org/abs/2304.06556)

    LLM在任务导向型对话中表现不如专门的任务特定模型，但如果提供正确的槽值，仍有引导对话成功结束的能力，并且可通过真实信念状态分布或域内示例的访问获得更好的表现。

    

    基于指令的大型语言模型（LLM）因其通过对话与用户交互的能力而受到广泛关注。本文旨在评估它们在已建立的任务导向型对话基准测试中完成多轮任务并与外部数据库交互的能力。我们发现，对于显式信念状态跟踪，LLM表现不如专门的任务特定模型。尽管如此，如果提供正确的插槽值，它们表现出引导对话成功结束的能力。此外，如果具有真实信念状态分布或域内示例的访问权限，该能力会得到改善。

    Instructions-tuned Large Language Models (LLMs) gained recently huge popularity thanks to their ability to interact with users through conversation. In this work we aim to evaluate their ability to complete multi-turn tasks and interact with external databases in the context of established task-oriented dialogue benchmarks. We show that for explicit belief state tracking, LLMs underperform compared to specialized task-specific models. Nevertheless, they show ability to guide the dialogue to successful ending if given correct slot values. Furthermore this ability improves with access to true belief state distribution or in-domain examples.
    
[^47]: OpenAGI：当LLM遇到领域专家

    OpenAGI: When LLM Meets Domain Experts. (arXiv:2304.04370v1 [cs.AI])

    [http://arxiv.org/abs/2304.04370](http://arxiv.org/abs/2304.04370)

    基于大型语言模型的OpenAGI平台通过整合领域专家模型和自然语言问答形式，实现复杂任务解决。

    

    人类具有将基本技能组合成复杂技能以解决复杂任务的显著能力。这种能力对于人工智能同样重要，因此，我们断言，除了开发大型综合智能模型外，将不同领域专家模型应用于复杂任务解决能力同样关键，以在人工智能通用智能的追求中使其具备这种能力。最近的大型语言模型（LLM）的发展证明其具有出色的学习和推理能力，使它们成为选择、综合和执行外部模型以解决复杂任务的控制器的有前途的选择。在这个项目中，我们开发了一个名为OpenAGI的开源AGI研究平台，专门设计为提供复杂的多步骤任务，并配有任务特定的数据集、评估指标和各种可扩展模型。OpenAGI将复杂任务阐释为自然语言问答，旨在促进领域专家和语言模型之间的协同作用。

    Human intelligence has the remarkable ability to assemble basic skills into complex ones so as to solve complex tasks. This ability is equally important for Artificial Intelligence (AI), and thus, we assert that in addition to the development of large, comprehensive intelligent models, it is equally crucial to equip such models with the capability to harness various domain-specific expert models for complex task-solving in the pursuit of Artificial General Intelligence (AGI). Recent developments in Large Language Models (LLMs) have demonstrated remarkable learning and reasoning abilities, making them promising as a controller to select, synthesize, and execute external models to solve complex tasks. In this project, we develop OpenAGI, an open-source AGI research platform, specifically designed to offer complex, multi-step tasks and accompanied by task-specific datasets, evaluation metrics, and a diverse range of extensible models. OpenAGI formulates complex tasks as natural language q
    
[^48]: BEVBert: 用于语言导向导航的多模态地图预训练

    BEVBert: Multimodal Map Pre-training for Language-guided Navigation. (arXiv:2212.04385v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.04385](http://arxiv.org/abs/2212.04385)

    本论文提出了一种多模态地图预训练方法，用于语言导向导航任务。通过构建局部度量地图和全局拓扑地图，该方法能够准确刻画空间感知和导航依赖关系，从而提高了语言导向导航的性能。

    

    大规模预训练已经在视觉与语言导航（VLN）任务上显示出了很好的结果。然而，大多数现有的预训练方法采用离散的全景图来学习视觉-文本关联。这要求模型隐式地关联全景图中的不完整、重复的观察数据，这可能影响到智能体的空间理解能力。因此，我们提出了一种新的基于地图的预训练范式，以用于VLN中的空间感知。具体而言，我们构建了一个局部度量地图，明确地汇聚不完整的观察数据并消除重复，同时在一个全局拓扑地图中建模导航依赖关系。这种混合设计可以平衡VLN对短期推理和长期规划的需求。然后，基于混合地图，我们设计了一个预训练框架来学习多模态地图表示，从而增强了空间感知跨模态推理，有助于语言导向导航目标的实现。广泛的实验验证了该方法的有效性。

    Large-scale pre-training has shown promising results on the vision-and-language navigation (VLN) task. However, most existing pre-training methods employ discrete panoramas to learn visual-textual associations. This requires the model to implicitly correlate incomplete, duplicate observations within the panoramas, which may impair an agent's spatial understanding. Thus, we propose a new map-based pre-training paradigm that is spatial-aware for use in VLN. Concretely, we build a local metric map to explicitly aggregate incomplete observations and remove duplicates, while modeling navigation dependency in a global topological map. This hybrid design can balance the demand of VLN for both short-term reasoning and long-term planning. Then, based on the hybrid map, we devise a pre-training framework to learn a multimodal map representation, which enhances spatial-aware cross-modal reasoning thereby facilitating the language-guided navigation goal. Extensive experiments demonstrate the effec
    
[^49]: AI知道明年韩国CSAT中会出现哪些单词

    AI Knows Which Words Will Appear in Next Year's Korean CSAT. (arXiv:2211.15426v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.15426](http://arxiv.org/abs/2211.15426)

    本文介绍了一种基于文本挖掘和深度学习的方法，可以预测明年韩国CSAT考试中单词的出现概率，方法在准确性和预测误差方面表现出色。

    

    本文介绍了基于文本挖掘的单词类别分类方法和基于LSTM的词汇出现模式预测方法。首先描述了基于简单文本出现频率分析的预处理方法。这种方法被开发为数据筛选工具，但显示出比先前作品高4.35~6.21倍的性能。同时，还提出了使用LSTM深度学习方法进行词汇出现模式预测方法。AI使用不同大小的前几次考试的数据窗口进行回归，以预测下一次考试中单词出现的概率。AI在不同数据窗口上预测的值经过加权求和处理，得到一个称为“AI-Score”的单一得分，表示下一年考试中单词出现的概率。所建议的方法在100分范围内显示了100％的准确性，在得分超过60分的区域仅显示了1.7％的预测误差。所有源代码均可在作者的Git上免费获取。

    A text-mining-based word class categorization method and LSTM-based vocabulary pattern prediction method are introduced in this paper. A preprocessing method based on simple text appearance frequency analysis is first described. This method was developed as a data screening tool but showed 4.35 ~ 6.21 times higher than previous works. An LSTM deep learning method is also suggested for vocabulary appearance pattern prediction method. AI performs a regression with various size of data window of previous exams to predict the probabilities of word appearance in the next exam. Predicted values of AI over various data windows are processed into a single score as a weighted sum, which we call an "AI-Score", which represents the probability of word appearance in next year's exam. Suggested method showed 100% accuracy at the range 100-score area and showed only 1.7% error of prediction in the section where the scores were over 60 points. All source codes are freely available at the authors' Git
    

