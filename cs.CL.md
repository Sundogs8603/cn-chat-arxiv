# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A Survey of Large Language Models in Medicine: Principles, Applications, and Challenges](https://rss.arxiv.org/abs/2311.05112) | 本综述提供了医学中大型语言模型（LLMs）的原理、应用和挑战的全面概述。同时回答了医学LLMs的构建、下游性能、实际应用、挑战以及更好构建和利用的问题。旨在为构建有效的医学LLMs提供见解和实用资源。 |
| [^2] | [Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning](https://arxiv.org/abs/2403.02333) | 提出了基于关键点驱动的数据合成框架(KPDDS)，创造了迄今为止最大规模的用于数学推理的合成数据集KPMath，以及进一步增强的KPMath-Plus数据集，实现了零-shot PASS@1精度为39.3%的性能提升。 |
| [^3] | [Contrastive Region Guidance: Improving Grounding in Vision-Language Models without Training](https://arxiv.org/abs/2403.02325) | 引入了对比区域引导（CRG）方法，实现了在视觉-语言模型中无需训练即可使模型响应视觉提示并取得显著改进。 |
| [^4] | [Detection of Non-recorded Word Senses in English and Swedish](https://arxiv.org/abs/2403.02285) | 该研究致力于在英语和瑞典语中检测未记录的词义，通过使用预训练的词-上下文嵌入器和人工注释，成功提高了检测到具有未记录词义的词语用法数量。 |
| [^5] | [Emotion Granularity from Text: An Aggregate-Level Indicator of Mental Health](https://arxiv.org/abs/2403.02281) | 提出从社交媒体的文本中计算情绪细粒度的方法，并研究其在心理健康条件中作为指标的有效性 |
| [^6] | [RIFF: Learning to Rephrase Inputs for Few-shot Fine-tuning of Language Models](https://arxiv.org/abs/2403.02271) | 通过训练少样本释义模型并在训练和测试时用释义丰富数据，可以提高语言模型的性能，超出仅通过参数高效微调的效果。 |
| [^7] | [FENICE: Factuality Evaluation of summarization based on Natural language Inference and Claim Extraction](https://arxiv.org/abs/2403.02270) | 提出了一种基于自然语言推理和主张提取的摘要可信度评估指标 FENICE，解决了自动生成摘要中存在的事实不一致性问题。 |
| [^8] | [Subjective $\textit{Isms}$? On the Danger of Conflating Hate and Offence in Abusive Language Detection](https://arxiv.org/abs/2403.02268) | 论文指出在滥用语言检测中，混淆仇恨和冒犯可能会使研究结果失效，呼吁未来工作需要从理论上将仇恨与冒犯概念进行分离。 |
| [^9] | [KnowPhish: Large Language Models Meet Multimodal Knowledge Graphs for Enhancing Reference-Based Phishing Detection](https://arxiv.org/abs/2403.02253) | 提出了一个自动化知识收集流水线，发布了一个包含20k品牌的大规模多模态品牌知识库KnowPhish，可用于加强现有基于参考的网络钓鱼检测器的性能 |
| [^10] | [Birbal: An efficient 7B instruct-model fine-tuned with curated datasets](https://arxiv.org/abs/2403.02247) | Birbal是一个基于Mistral-7B模型的高效模型，通过在单个RTX 4090上进行16小时微调，成功地整理了高质量指令，使性能提高了35%。 |
| [^11] | [PHAnToM: Personality Has An Effect on Theory-of-Mind Reasoning in Large Language Models](https://arxiv.org/abs/2403.02246) | 通过提示引发特定人格对大型语言模型的心理理论推理能力产生显著影响，特别是来自黑暗三合会的特质对多种LLMs在不同ToM任务中具有较大效应。 |
| [^12] | [Distilled ChatGPT Topic & Sentiment Modeling with Applications in Finance](https://arxiv.org/abs/2403.02185) | ChatGPT被应用于金融领域，通过知识蒸馏和迁移学习融合的训练方法，生成轻量级主题和情感分类模型，成功应用于量化投资场景。 |
| [^13] | [Not all Layers of LLMs are Necessary during Inference](https://arxiv.org/abs/2403.02181) | 推理过程中，根据输入实例的不同难易程度，本文提出了一种名为AdaInfer的算法，可以自适应地使用浅层和深层，从而节省了计算资源。 |
| [^14] | [Masked Thought: Simply Masking Partial Reasoning Steps Can Improve Mathematical Reasoning Learning of Language Models](https://arxiv.org/abs/2403.02178) | 引入对输入的扰动，通过随机掩盖思维链中的某些标记，可显著提高语言模型在推理任务中的学习效果 |
| [^15] | [ProTrix: Building Models for Planning and Reasoning over Tables with Sentence Context](https://arxiv.org/abs/2403.02177) | 提出了一个计划-推理框架，用于在表格上的句子背景中回答用户查询，通过对Llama-2-7B进行微调，构建了ProTrix模型，广泛适用于不同表格任务，并表现出与GPT-3.5-turbo相当的性能水平，可生成准确且忠实的解释。 |
| [^16] | [EEE-QA: Exploring Effective and Efficient Question-Answer Representations](https://arxiv.org/abs/2403.02176) | 该研究探索了新的问题-答案编码方法，通过精细表示、答案候选项嵌入和内存效率提高推断效率。 |
| [^17] | [What has LeBenchmark Learnt about French Syntax?](https://arxiv.org/abs/2403.02173) | 论文探讨了LeBenchmark这个预训练声学模型对法语句法信息的学习情况，结果显示模型在中间层学习到了一些句法信息。 |
| [^18] | [Speech emotion recognition from voice messages recorded in the wild](https://arxiv.org/abs/2403.02167) | 使用Emotional Voice Messages数据库，结合eGeMAPS特征和Transformer模型，实现了在野外录制的语音消息中的语音情感识别，取得了较高的准确度，并比基准模型提高了10%。 |
| [^19] | [Using LLMs for the Extraction and Normalization of Product Attribute Values](https://arxiv.org/abs/2403.02130) | 本文探讨了使用大型语言模型（LLMs）如GPT-3.5和GPT-4从产品标题和描述中提取和规范化属性值的潜力，引入了新的WDC PAVE数据集来支持实验。 |
| [^20] | [LOCR: Location-Guided Transformer for Optical Character Recognition](https://arxiv.org/abs/2403.02127) | LOCR是一种面向光学字符识别的模型，通过在自回归过程中在transformer架构中集成位置引导，能够有效处理学术文档中的重复问题，并在测试集上表现出色。 |
| [^21] | [Leveraging Weakly Annotated Data for Hate Speech Detection in Code-Mixed Hinglish: A Feasibility-Driven Transfer Learning Approach with Large Language Models](https://arxiv.org/abs/2403.02121) | 本研究利用弱标注数据和大型语言模型，针对混合代码的印地语进行仇恨言论检测，探索了零次学习、一次学习和少次学习方法，解决了标记数据的问题。 |
| [^22] | [Modeling Multimodal Social Interactions: New Challenges and Baselines with Densely Aligned Representations](https://arxiv.org/abs/2403.02090) | 提出了三个新的具有挑战性的任务来模拟多人之间的细粒度动态，并为社交推理游戏设置提供了广泛的数据注释；同时提出了一种新颖的多模态基线方法，利用密集对齐的语言-视觉表示。 |
| [^23] | [Automated Generation of Multiple-Choice Cloze Questions for Assessing English Vocabulary Using GPT-turbo 3.5](https://arxiv.org/abs/2403.02078) | 本研究评估了一种利用GPT-turbo 3.5自动生成英语词汇多项选择填空题目的新方法，通过VocaTT引擎的三个步骤实现，结果显示生成的题目有很高的良好形式比例。 |
| [^24] | [Topic Aware Probing: From Sentence Length Prediction to Idiom Identification how reliant are Neural Language Models on Topic?](https://arxiv.org/abs/2403.02009) | 本论文通过主题感知探究方法探讨了Transformer-based模型在处理自然语言时对主题信号的主要依赖程度，并初步结果表明这些模型在中间层中编码了主题信息和非主题信息。 |
| [^25] | [LLM-Oriented Retrieval Tuner](https://arxiv.org/abs/2403.01999) | 通过LMORT，作者提出了一种高效的LLM定向检索调节器，可以实现有效的密集检索，与其他强大的DR模型相比具有竞争力的零-shot检索性能，并保持LLM的生成能力。 |
| [^26] | [Vanilla Transformers are Transfer Capability Teachers](https://arxiv.org/abs/2403.01994) | 混合专家（MoE）变压器在模型预训练性能和传输能力方面表现不如香草变压器，为此提出了迁移能力蒸馏的概念，指出香草模型是迁移能力的有效教师，指导MoE模型实现预训练性能和传输能力的结合。 |
| [^27] | [FakeNewsGPT4: Advancing Multimodal Fake News Detection through Knowledge-Augmented LVLMs](https://arxiv.org/abs/2403.01988) | FakeNewsGPT4是一个新颖框架，通过增加特定于伪造的知识，提升了LVLMs在多模态假新闻检测中的效果。 |
| [^28] | [Transformers for Low-Resource Languages:Is F\'eidir Linn!](https://arxiv.org/abs/2403.01985) | 本研究评估了对低资源的英语-爱尔兰语语言对进行超参数优化的 Transformer 模型，发现正确选择子词模型是翻译性能的最大驱动因素。 |
| [^29] | [Language and Speech Technology for Central Kurdish Varieties](https://arxiv.org/abs/2403.01983) | 本文针对中央库尔德语种开发语言和语音技术，通过电影和电视剧的转录创建语料库，并评估了机器翻译、自动语音识别和语言识别的性能。 |
| [^30] | [SciAssess: Benchmarking LLM Proficiency in Scientific Literature Analysis](https://arxiv.org/abs/2403.01976) | SciAssess介绍了一个专为深度分析科学文献而设计的基准测试，旨在全面评估LLMs在科学领域记忆、理解和分析能力的有效性。 |
| [^31] | [Multi-perspective Improvement of Knowledge Graph Completion with Large Language Models](https://arxiv.org/abs/2403.01972) | 提出了MPIKGC框架，通过从多个角度利用大型语言模型来改善知识图谱补全，扩展实体描述、理解关系和提取结构，弥补了结构不完整和文本质量限制带来的问题 |
| [^32] | [AS-ES Learning: Towards Efficient CoT Learning in Small Models](https://arxiv.org/abs/2403.01969) | AS-ES学习提出了一种新的训练范式，通过高效利用现有CoT数据来实现在小型模型中的高效迭代生成，超越了直接seq2seq训练，在CoT丰富任务上取得了显著表现。 |
| [^33] | [DECIDER: A Rule-Controllable Decoding Strategy for Language Generation by Imitating Dual-System Cognitive Theory](https://arxiv.org/abs/2403.01954) | DECIDER是一种受双系统认知理论启发的规则可控解码策略，通过在预训练语言模型中引入逻辑推理器，有效地遵循给定规则以引导生成方向朝向目标。 |
| [^34] | [VariErr NLI: Separating Annotation Error from Human Label Variation](https://arxiv.org/abs/2403.01931) | 该研究提出了一个新的方法和数据集VariErr，专注于NLI任务中的注释错误和人类标签变化的区分。研究填补了在处理信号非黑白情况下的先前空白。 |
| [^35] | [Analyzing and Adapting Large Language Models for Few-Shot Multilingual NLU: Are We There Yet?](https://arxiv.org/abs/2403.01929) | 本研究对监督微调、监督指导调整和上下文学习三种方法进行了广泛比较，发现监督指导调整在性能和资源之间具有最佳的平衡。 |
| [^36] | [IndicVoices: Towards building an Inclusive Multilingual Speech Dataset for Indian Languages](https://arxiv.org/abs/2403.01926) | IndicVoices致力于建立包容性和代表性的多语音数据集，通过开源数据收集蓝图，提供了全面的起步工具。 |
| [^37] | [To Generate or to Retrieve? On the Effectiveness of Artificial Contexts for Medical Open-Domain Question Answering](https://arxiv.org/abs/2403.01924) | 本文介绍了MedGENIE，这是医学领域多项选择问题回答的第一个生成后阅读框架。 |
| [^38] | [Arabic Text Sentiment Analysis: Reinforcing Human-Performed Surveys with Wider Topic Analysis](https://arxiv.org/abs/2403.01921) | 该研究对阿拉伯文本情感分析进行了全面的深入分析和广泛研究，通过人工调查和机器学习技术强化了现有研究的主题和趋势。 |
| [^39] | [Fostering the Ecosystem of Open Neural Encoders for Portuguese with Albertina PT* Family](https://arxiv.org/abs/2403.01897) | 本文为葡萄牙语的神经编码作出了贡献，扩展了大型语言模型生态系统，并发布了包括亿级参数 Albertina 和 Bertimbau 在内的开源编码器模型，进一步推进了葡萄牙语的神经编码器技术。 |
| [^40] | [FCDS: Fusing Constituency and Dependency Syntax into Document-Level Relation Extraction](https://arxiv.org/abs/2403.01886) | 本研究将短语结构和依存句法融合到文档级关系抽取中，有效利用了文档中的丰富语法信息。 |
| [^41] | [An Improved Traditional Chinese Evaluation Suite for Foundation Model](https://arxiv.org/abs/2403.01858) | TMMLU+是传统中文大规模多任务语言理解数据集的改进版本，规模是前者的六倍，包含66个多样化主题。研究显示传统中文模型仍然落后于简体中文模型，并且目前的大语言模型在平均得分上尚未超过人类表现。 |
| [^42] | [Rethinking LLM Language Adaptation: A Case Study on Chinese Mixtral](https://arxiv.org/abs/2403.01851) | 本文以中文Mixtral为案例，提出了改进的中文语言能力的Mixtral模型，并讨论了在大型语言模型进行语言适应时的关键问题。 |
| [^43] | [CET2: Modelling Topic Transitions for Coherent and Engaging Knowledge-Grounded Conversations](https://arxiv.org/abs/2403.01848) | CET2框架旨在通过建模主题转换选择与对话上下文连贯的知识，为知识驱动的对话系统生成连贯和引人入胜的回复。 |
| [^44] | [Making Pre-trained Language Models Great on Tabular Prediction](https://arxiv.org/abs/2403.01841) | 提出了一种专门为表格数据预测而预训练的语言模型TP-BERTa，通过新颖的相对大小标记化方法和内部特征关注方法解决了预训练语言模型在数值特征值上的不兼容性问题 |
| [^45] | [Model-Based Data-Centric AI: Bridging the Divide Between Academic Ideals and Industrial Pragmatism](https://arxiv.org/abs/2403.01832) | 本文提出了一种新的模型-Based Data-Centric AI 范式，旨在解决学术界数据质量和工业应用之间的差异，并提出了整合模型考虑到数据优化过程中的策略。 |
| [^46] | [NusaBERT: Teaching IndoBERT to be Multilingual and Multicultural](https://arxiv.org/abs/2403.01817) | NusaBERT通过将印度尼西亚的多样化语料库与IndoBERT相结合，实现了在涉及多种语言的任务中 state-of-the-art 的性能表现，为未被充分代表的语言的自然语言理解研究铺平了道路。 |
| [^47] | [Enhancing Multi-Domain Automatic Short Answer Grading through an Explainable Neuro-Symbolic Pipeline](https://arxiv.org/abs/2403.01811) | 通过提出弱监督标注程序和基于合理化线索的神经符号模型，我们在多领域自动简答题评分方面取得了显著进展。 |
| [^48] | [NPHardEval4V: A Dynamic Reasoning Benchmark of Multimodal Large Language Models](https://arxiv.org/abs/2403.01777) | 这项研究介绍了一个旨在评估多模态大型语言模型推理能力的动态基准NPHardEval4V，发现在推理能力方面不同模型存在显著差异，并揭示了相对于LLMs，MLLMs的推理性能较弱。 |
| [^49] | [WebCiteS: Attributed Query-Focused Summarization on Chinese Web Search Results with Citations](https://arxiv.org/abs/2403.01774) | WebCiteS提出了一个带引文的查询焦点摘要任务，并发布了包含7k人工注释摘要及引文的中文数据集，以处理归因中存在的问题。 |
| [^50] | [KeNet:Knowledge-enhanced Doc-Label Attention Network for Multi-label text classification](https://arxiv.org/abs/2403.01767) | KeNet是一种基于知识增强的文档-标签注意力网络，用于解决多标签文本分类中的文档标签关系建立问题。 |
| [^51] | [How Multimodal Integration Boost the Performance of LLM for Optimization: Case Study on Capacitated Vehicle Routing Problems](https://arxiv.org/abs/2403.01757) | 提出了一种使用多模态LLM进行优化的框架，能够更全面地理解优化问题，类似于人类认知过程，并且提供了更细致和有效的分析。 |
| [^52] | [Derivative-Free Optimization for Low-Rank Adaptation in Large Language Models](https://arxiv.org/abs/2403.01754) | 本文将低秩模块添加到模型的每个自注意层中，并采用两种无导数优化方法交替优化这些低秩模块，相比现有基于梯度的参数调整方法，我们的方法在内存使用和收敛速度上显示出明显优势。 |
| [^53] | [Differentially Private Synthetic Data via Foundation Model APIs 2: Text](https://arxiv.org/abs/2403.01749) | 通过基础模型API，我们提出了一种名为Aug-PE的增强PE算法，以产生差分隐私合成文本数据，为解决私有文本数据共享与隐私问题提供了一种前景和可扩展的解决方案。 |
| [^54] | [Decode Neural signal as Speech](https://arxiv.org/abs/2403.01748) | 本文在脑机接口领域探索了MEG信号的脑到文本转换，着重解决了以前主要集中在EEG上、使用“teacher-forcing”以及未完全自回归的问题。 |
| [^55] | [Towards Self-Contained Answers: Entity-Based Answer Rewriting in Conversational Search](https://arxiv.org/abs/2403.01747) | 本文针对会话搜索中的基于实体的答案重写，提出了两种答案重写策略，以改善用户体验。 |
| [^56] | [Brilla AI: AI Contestant for the National Science and Maths Quiz](https://arxiv.org/abs/2403.01699) | 人工智能参赛者Brilla AI在全国科学与数学竞赛中表现优秀，为缺乏合格教师的非洲提供了学习支持。 |
| [^57] | [Hypertext Entity Extraction in Webpage](https://arxiv.org/abs/2403.01698) | 提出了一个新的超文本实体提取数据集HEED和一个基于MoE的实体提取框架MoEEF，有效整合多个特征以提高模型性能。 |
| [^58] | [You Need to Pay Better Attention](https://arxiv.org/abs/2403.01643) | 提出了三种新的注意力机制，在效率和学习能力方面优于标准的多头注意力，提高了Transformer模型的性能和更广泛的部署能力。 |
| [^59] | [Multi-level Product Category Prediction through Text Classification](https://arxiv.org/abs/2403.01638) | 本研究通过应用LSTM和BERT模型，以及数据增强和焦点损失技术，实现了在零售领域中准确预测多个产品类别的效果。 |
| [^60] | [Towards Comprehensive Vietnamese Retrieval-Augmented Generation and Large Language Models](https://arxiv.org/abs/2403.01616) | 该论文旨在推动越南语言理解和生成方面的进展，通过开发和分享开放数据集和预训练模型，特别是针对越南语检索增强生成和大型语言模型。 |
| [^61] | [SCHEMA: State CHangEs MAtter for Procedure Planning in Instructional Videos](https://arxiv.org/abs/2403.01599) | 通过研究步骤和状态之间的因果关系，本文提出了SCHEMA方法，将每个步骤显式表示为状态变化，并追踪教学视频中的状态变化。 |
| [^62] | [Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures](https://arxiv.org/abs/2403.01580) | 本研究通过优化Transformer模型的超参数和子词模型类型，开发了适用于低资源语言对的神经机器翻译系统，并开发了gaHealth，首个针对爱尔兰语健康数据的双语语料库，取得了显著的翻译质量提升。 |
| [^63] | [SERVAL: Synergy Learning between Vertical Models and LLMs towards Oracle-Level Zero-shot Medical Prediction](https://arxiv.org/abs/2403.01570) | 提出SERVAL，一个协同学习流水线，可以通过相互增强，实现LLMs和小模型的垂直能力无监督开发，从而改善领域特定垂直问题的零-shot预测能力。 |
| [^64] | [In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation](https://arxiv.org/abs/2403.01548) | 本研究从内部表征角度深入探讨了大型语言模型幻觉的机制，发现了幻觉的一个显著模式，即在上下文标记的隐藏状态中，正确生成具有更清晰的上下文激活。我们提出了一种基于熵的度量方法，将“锐度”纳入解码过程中，制定了一种受限解码方法，实验证明其在知识寻求和幻觉任务上的有效性。 |
| [^65] | [Leveraging Biomolecule and Natural Language through Multi-Modal Learning: A Survey](https://arxiv.org/abs/2403.01528) | 生物分子与自然语言相结合的多模态学习为全面表示和分析生物分子开辟了新途径。 |
| [^66] | [Revisiting Dynamic Evaluation: Online Adaptation for Large Language Models](https://arxiv.org/abs/2403.01518) | 在线适应可以将参数转变为时间变化状态，提供一种具有内存权重记忆的上下文长度扩展形式，更符合神经科学中记忆概念，且在提升整体预测性能时尤其有趣。 |
| [^67] | [Fantastic Semantics and Where to Find Them: Investigating Which Layers of Generative LLMs Reflect Lexical Semantics](https://arxiv.org/abs/2403.01509) | 通过在每个层的末端探测其隐藏状态，使用一个上下文化的词识别任务，本文具体研究了Llama2的自下而上词汇语义演变，发现较低层的表示编码了词汇语义，而较高层负责预测。 |
| [^68] | [Infusing Knowledge into Large Language Models with Contextual Prompts](https://arxiv.org/abs/2403.01481) | 提出了一种通过从输入文本的上下文中生成提示来进行知识注入的简单但通用方法，能够有效增强大型语言模型的性能。 |
| [^69] | [Align-to-Distill: Trainable Attention Alignment for Knowledge Distillation in Neural Machine Translation](https://arxiv.org/abs/2403.01479) | "本文提出了“Align-to-Distill”（A2D）策略，通过在训练过程中自适应地对齐学生注意力头与其教师对应物，转化了组合映射启发式方法为学习问题，实验结果显示A2D的有效性，对WMT-2022 De->Dsb和WMT-2014 En->De的BLEU分数分别获得高达+3.61和+0.63的提升。" |
| [^70] | [WARDEN: Multi-Directional Backdoor Watermarks for Embedding-as-a-Service Copyright Protection](https://arxiv.org/abs/2403.01472) | 本研究提出了一种名为WARDEN的新方法，通过在嵌入文本中加入多个可能的水印方向，增加了水印消除的难度，以应对EaaS中背门水印被移除的新威胁。 |
| [^71] | [KorMedMCQA: Multi-Choice Question Answering Benchmark for Korean Healthcare Professional Licensing Examinations](https://arxiv.org/abs/2403.01469) | KorMedMCQA是首个从韩国医疗专业执业考试中衍生的多项选择题问答基准，提供了多种大型语言模型的基线实验结果，并在HuggingFace上公开了数据，为韩国医疗环境中的进一步研究和发展提供了可能性。 |
| [^72] | [Answerability in Retrieval-Augmented Open-Domain Question Answering](https://arxiv.org/abs/2403.01461) | 本论文研究了在开放域问答中检索系统的可回答性问题，揭示了使用随机化策略训练模型在泛化到具有高语义重叠的无关文本摘录方面的重要局限性，并提出了一种有效的训练模型的方法。 |
| [^73] | [Logic Rules as Explanations for Legal Case Retrieval](https://arxiv.org/abs/2403.01457) | 本文提出了神经符号增强的法律案例检索（NS-LCR）框架，通过学习案例级别和法律级别的逻辑规则，将规则以神经符号方式集成到检索过程中，以提供逻辑且可解释的解释。 |
| [^74] | [Controlling Cloze-test Question Item Difficulty with PLM-based Surrogate Models for IRT Assessment](https://arxiv.org/abs/2403.01456) | 提出使用预训练语言模型作为代理模型，通过排名规则控制填空测试题目中空白和干扰项的难度水平，有效评估MC填空测试的难度水平 |
| [^75] | [Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge](https://arxiv.org/abs/2403.01432) | 本文研究了微调和检索增强生成两种方法对大型语言模型在处理低频实体问题回答任务中的影响，发现微调显著提高了各种受欢迎程度的实体的性能，而检索增强生成方法则超过了其他方法。 |
| [^76] | [OVEL: Large Language Model as Memory Manager for Online Video Entity Linking](https://arxiv.org/abs/2403.01411) | 提出了面向在线视频的实体链接任务OVEL，专注于在在线视频内容中建立与知识库之间准确和及时的连接，并构建了一个实时交付实体链接数据集LIVE。 |
| [^77] | [What Is Missing in Multilingual Visual Reasoning and How to Fix It](https://arxiv.org/abs/2403.01404) | 本文通过在视觉推理任务上的测试，发现了多语言视觉推理中存在的挑战，并提出了针对性的干预措施，包括翻译-测试方法，视觉编程方法和图像字幕生成方法。 |
| [^78] | [CR-LT-KGQA: A Knowledge Graph Question Answering Dataset Requiring Commonsense Reasoning and Long-Tail Knowledge](https://arxiv.org/abs/2403.01395) | 这项工作提出了一个新的KGQA数据集 CR-LT-KGQA，要求进行常识推理，并关注长尾实体，为那些往往产生妄想的大型语言模型提供利用知识图谱进行基于事实和可归属常识推理的新方法。 |
| [^79] | [Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering](https://arxiv.org/abs/2403.01390) | LLM-based KGQA methods struggle with hallucination on commonsense reasoning questions, hindering their applicability in real-world applications. |
| [^80] | [On the Compressibility of Quantized Large Language Models](https://arxiv.org/abs/2403.01384) | 研究在内存受限设备上应用数据压缩技术以加速量化LLM推理过程的一项初步工作。 |
| [^81] | [Automatic Question-Answer Generation for Long-Tail Knowledge](https://arxiv.org/abs/2403.01382) | 提出了一种自动生成长尾知识问答数据集的自动化方法，并通过预训练的大型语言模型对其进行了实验验证。 |
| [^82] | [Evaluating and Mitigating Number Hallucinations in Large Vision-Language Models: A Consistency Perspective](https://arxiv.org/abs/2403.01373) | 本文评估了大型视觉语言模型中的数字幻觉问题，并提出一种一致性训练方法，可使数字幻觉得到显著改善 |
| [^83] | [Improving Cross-lingual Representation for Semantic Retrieval with Code-switching](https://arxiv.org/abs/2403.01364) | 提出了一种通过代码切换的交替跨语言PTM，首次将代码切换方法应用于跨语言语义检索。 |
| [^84] | [LM4OPT: Unveiling the Potential of Large Language Models in Formulating Mathematical Optimization Problems](https://arxiv.org/abs/2403.01342) | 本研究比较了几种知名的大型语言模型在翻译语言描述为数学优化问题中的表现，发现GPT-4在一次场景中表现出色，并引入了“LM4OPT”框架进行Llama-2-7b的渐进微调。 |
| [^85] | [VNLP: Turkish NLP Package](https://arxiv.org/abs/2403.01309) | VNLP是首个专门针对土耳其语开发的自然语言处理工具包，包含多种NLP工具，其中的标记分类模型基于“上下文模型”，支持多种任务如情感分析、命名实体识别等。 |
| [^86] | [VBART: The Turkish LLM](https://arxiv.org/abs/2403.01308) | VBART是第一个土耳其序列到序列大语言模型，通过与BART和mBART模型结合形成了紧凑型LLM，并在多个任务中表现出色，为土耳其自然语言处理研究开辟了新的可能性。 |
| [^87] | [Improving the Validity of Automatically Generated Feedback via Reinforcement Learning](https://arxiv.org/abs/2403.01304) | 本研究通过提出评估数学反馈的评分标准，展示了GPT-4能够有效地使用它来注释人工编写的和LLM生成的反馈，从而改进了自动生成反馈的有效性和可靠性。 |
| [^88] | [Greed is All You Need: An Evaluation of Tokenizer Inference Methods](https://arxiv.org/abs/2403.01289) | 对 NLP 模型中常用的分词器进行了控制性分析，发现贪婪推理表现良好，而上下文感知分词器 SaGe 在形态对齐方面表现最优。 |
| [^89] | [NoMAD-Attention: Efficient LLM Inference on CPUs Through Multiply-add-free Attention](https://arxiv.org/abs/2403.01273) | NoMAD-Attention提出了一种高效的注意力算法，通过在CPU上使用寄存器内查找取代MAD操作，以实现LLM推断的快速计算。 |
| [^90] | [A comprehensive cross-language framework for harmful content detection with the aid of sentiment analysis](https://arxiv.org/abs/2403.01270) | 本研究引入了首个详细的适用于任何语言的框架，旨在解决跨语言有害内容检测中的挑战 |
| [^91] | [Dissecting Language Models: Machine Unlearning via Selective Pruning](https://arxiv.org/abs/2403.01267) | 介绍了一种针对大型语言模型的机器去学习方法，通过选择性修剪神经元来实现去学习，发现LLMs中的神经元在特定任务中具有不同的重要性。 |
| [^92] | [Accelerating Greedy Coordinate Gradient via Probe Sampling](https://arxiv.org/abs/2403.01251) | 研究引入了一种名为“探查采样”的新算法，通过动态确定草稿模型和目标模型的相似度，来加速贪婪坐标梯度算法，实现高达5.6倍的加速。 |
| [^93] | [SceneCraft: An LLM Agent for Synthesizing 3D Scene as Blender Code](https://arxiv.org/abs/2403.01248) | SceneCraft是一个LLM代理，可将文本描述转换为Blender代码，实现渲染高达一百个三维资产的复杂场景，通过先建模空间关系再编写Python脚本，并借助视觉-语言基础模型进行场景优化和库学习来解决挑战。 |
| [^94] | [Mitigating Catastrophic Forgetting in Large Language Models with Self-Synthesized Rehearsal](https://arxiv.org/abs/2403.01244) | 提出了一种称为Self-Synthesized Rehearsal（SSR）的框架，利用大型语言模型生成合成实例用于持续学习中的复述，以解决大型语言模型遭受灾难性遗忘的问题。 |
| [^95] | [Augmenting Automation: Intent-Based User Instruction Classification with Machine Learning](https://arxiv.org/abs/2403.01242) | 提出了一种通过引入基于意图的用户指令分类和机器学习技术的新颖方法，从而增强自动化系统的灵活性和适应性。 |
| [^96] | [IntactKV: Improving Large Language Model Quantization by Keeping Pivot Tokens Intact](https://arxiv.org/abs/2403.01241) | 本研究提出了IntactKV方法，通过保持关键标记的完整性，改善了大型语言模型的量化过程，进一步降低了量化误差的上限，并取得了显著的性能提升。 |
| [^97] | [Emotion Analysis in NLP: Trends, Gaps and Roadmap for Future Directions](https://arxiv.org/abs/2403.01222) | NLP中情感分析领域存在着趋势和差距，未来方向需考虑情感任务定义、情感框架、情感主观性与NLP应用。 |
| [^98] | [API Is Enough: Conformal Prediction for Large Language Models Without Logit-Access](https://arxiv.org/abs/2403.01216) | 本研究提出了一种针对无需访问对数的API-only LLMs的整体预测方法，旨在最小化预测集大小并确保用户定义的覆盖范围的统计保证。 |
| [^99] | [Pseudo-Label Calibration Semi-supervised Multi-Modal Entity Alignment](https://arxiv.org/abs/2403.01203) | 本研究提出了一种伪标签校准的半监督多模态实体对齐方法，通过引入互信息最大化来过滤模态特定噪音，增强模态不变性共性。 |
| [^100] | [DMoERM: Recipes of Mixture-of-Experts for Effective Reward Modeling](https://arxiv.org/abs/2403.01197) | DMoERM首次将专家混合（MoE）的概念引入奖励建模领域，提出了双层MoE RM（DMoERM），通过稀疏的外层MoE和密集的内层MoE对特定任务进行微调，解决了训练中的多任务干扰和数据噪声问题。 |
| [^101] | [Machine Translation in the Covid domain: an English-Irish case study for LoResMT 2021](https://arxiv.org/abs/2403.01196) | 在LoResMT 2021中，针对Covid数据从英语到爱尔兰语的翻译，通过使用领域自适应技术和扩展领域内Covid数据集训练Transformer架构，成功改善了翻译表现。 |
| [^102] | [RAGged Edges: The Double-Edged Sword of Retrieval-Augmented Chatbots](https://arxiv.org/abs/2403.01193) | 本文探讨了如何利用检索增强生成（RAG）抵制大型语言模型（LLMs）产生的幻觉，结果表明RAG在某些情况下可以提高准确性，但仍需要更强大的解决方案以确保LLMs在实际应用中可靠性。 |
| [^103] | [A Compositional Typed Semantics for Universal Dependencies](https://arxiv.org/abs/2403.01187) | UD类型演算是一个基于广泛使用的语言通用依存句法框架的语义类型和逻辑形式的组合、原则性和与语言无关系统，通过利用依存标签推导具有各种句法结构的句子的正确含义。 |
| [^104] | [Balancing Exploration and Exploitation in LLM using Soft RLLF for Enhanced Negation Understanding](https://arxiv.org/abs/2403.01185) | 通过利用逻辑反馈的强化学习（RLLF）在LLMs中实现探索和开发的平衡，以增强否定理解能力，并通过比较性能验证了这种平衡方法的价值。 |
| [^105] | [DINER: Debiasing Aspect-based Sentiment Analysis with Multi-variable Causal Inference](https://arxiv.org/abs/2403.01166) | 本论文提出了一种基于多变量因果推断的新框架，用于去偏方面级情感分析，从而解决神经网络模型学习虚假相关性的问题。 |
| [^106] | [STAR: Constraint LoRA with Dynamic Active Learning for Data-Efficient Fine-Tuning of Large Language Models](https://arxiv.org/abs/2403.01165) | 本论文提出了一种新颖的方法，有效地将基于不确定性的主动学习和LoRA相结合，以解决大型语言模型数据高效微调中遇到的问题。 |
| [^107] | [BootTOD: Bootstrap Task-oriented Dialogue Representations by Aligning Diverse Responses](https://arxiv.org/abs/2403.01163) | BootTOD通过自助引导框架学习任务导向对话表示，消除了对比对的要求，并使用多个回复目标来模拟人类对话的多样性。 |
| [^108] | [A Survey of AI-generated Text Forensic Systems: Detection, Attribution, and Characterization](https://arxiv.org/abs/2403.01152) | 本文综述了AI生成文本取证系统，重点讨论了检测、归因和特征化三个主要方面，以实现对AI生成文本的实际理解。 |
| [^109] | [ParallelPARC: A Scalable Pipeline for Generating Natural-Language Analogies](https://arxiv.org/abs/2403.01139) | 设计了ParallelPARC流水线，利用大型语言模型生成复杂段落类比数据集，评估各种类比类型，并展示出人类在类比识别中的优势。 |
| [^110] | [LLaMoCo: Instruction Tuning of Large Language Models for Optimization Code Generation](https://arxiv.org/abs/2403.01131) | LLaMoCo是第一个旨在以代码对代码方式调整LLMs以解决优化问题的指令调优框架，通过全面指令集和新颖的两阶段学习策略，实现了优越的性能。 |
| [^111] | [MulCogBench: A Multi-modal Cognitive Benchmark Dataset for Evaluating Chinese and English Computational Language Models](https://arxiv.org/abs/2403.01116) | MulCogBench是一个多模式认知基准数据集，旨在评估中文和英文计算语言模型。通过相似性编码分析发现，语言模型与人类认知数据之间存在显著相似性，并且这种相似性模式受数据模态和调节影响。 |
| [^112] | [Distilling Text Style Transfer With Self-Explanation From LLMs](https://arxiv.org/abs/2403.01106) | CoTeX是一个利用大型语言模型和思维链提示来促进文本风格转移的框架，通过提炼LLMs的能力为处理非平行数据和平行数据的简化模型，在低资源情况下表现优于传统的监督微调和知识蒸馏方法，并通过透明的解释在风格转移过程中有显著优势。 |
| [^113] | [LAB: Large-Scale Alignment for ChatBots](https://arxiv.org/abs/2403.01081) | 介绍了一种名为LAB的方法，旨在克服大型语言模型训练中的可扩展性挑战，通过分类法指导的合成数据生成和多阶段调整框架，实现了对昂贵人工标注和GPT-4等专有模型依赖较少的大规模对齐，提供了一种可扩展、具有成本效益的解决方案，不会出现灾难性遗忘情况，进一步增强了LLM的训练效率。 |
| [^114] | [LLMCRIT: Teaching Large Language Models to Use Criteria](https://arxiv.org/abs/2403.01069) | 提出了一个通用框架，使大型语言模型能够使用全面标准为任务提供自然语言反馈，并在论文引言写作、Python代码编写和Reddit帖子撰写等任务中进行了实证评估。 |
| [^115] | [FaiMA: Feature-aware In-context Learning for Multi-domain Aspect-based Sentiment Analysis](https://arxiv.org/abs/2403.01063) | FaiMA提出了一种新的框架，利用特征感知的上下文学习作为自适应学习机制，用于多领域基于方面的情感分析任务。 |
| [^116] | [Reading Subtext: Evaluating Large Language Models on Short Story Summarization with Writers](https://arxiv.org/abs/2403.01061) | 评估大型语言模型在短篇小说摘要上的表现，发现它们在忠实性和解释潜台词方面存在挑战，但在进行主题分析时表现出思考深度。 |
| [^117] | [Peacock: A Family of Arabic Multimodal Large Language Models and Benchmarks](https://arxiv.org/abs/2403.01031) | 介绍了一系列阿拉伯多模式大语言模型Peacock，展示了其在视觉推理任务上的出色性能和不断出现的方言潜力，并提出了一个用于评估阿拉伯语相关方面的新基准Henna |
| [^118] | [Attribute Structuring Improves LLM-Based Evaluation of Clinical Text Summaries](https://arxiv.org/abs/2403.01002) | 属性结构化框架显著改进了基于LLM的临床文本摘要评估过程，提高了人工评注和自动度量之间的一致性。 |
| [^119] | [Predictions from language models for multiple-choice tasks are not robust under variation of scoring methods](https://arxiv.org/abs/2403.00998) | 本研究比较了不同方法对语言模型在多项选择任务中的项目级别预测的影响，发现LLM的预测结果在评分方法的变化下不稳健，这对确保结果的稳健性和研究诚信至关重要。 |
| [^120] | [Leveraging Prompt-Based Large Language Models: Predicting Pandemic Health Decisions and Outcomes Through Social Media Language](https://arxiv.org/abs/2403.00994) | 该研究利用基于提示的大语言模型框架，研究了社交媒体语言模式与国家卫生趋势之间的关系，首次实现了将社交媒体语言模式与现实公共卫生趋势相联系的方法。 |
| [^121] | [Formulation Comparison for Timeline Construction using LLMs](https://arxiv.org/abs/2403.00990) | 提出一种新颖的评估数据集TimeSET，以改善时间轴构建时的缺失时间信息问题，并通过比较多个任务公式，基于开放的LLMs评估时间轴构建系统。 |
| [^122] | [Merging Text Transformer Models from Different Initializations](https://arxiv.org/abs/2403.00986) | 研究了合并不同初始化的Transformer模型的技术，提出了一种模型合并技术以研究这些模型极小值之间的关系，并发现与模型平均相比，通过我们的方法合并这些模型始终可以获得较低的损失障碍。 |
| [^123] | [LocalRQA: From Generating Data to Locally Training, Testing, and Deploying Retrieval-Augmented QA Systems](https://arxiv.org/abs/2403.00982) | LocalRQA是一个开源工具包，提供多种模型训练算法、评估方法和部署工具，用于构建检索增强问答系统，其训练和部署的模型性能与使用OpenAI的text-ada-002和GPT-4-turbo相当。 |
| [^124] | [MALTO at SemEval-2024 Task 6: Leveraging Synthetic Data for LLM Hallucination Detection](https://arxiv.org/abs/2403.00964) | 引入了数据增强流水线和投票集成，利用合成数据检测LLM幻觉。 |
| [^125] | [AutoRD: An Automatic and End-to-End System for Rare Disease Knowledge Graph Construction Based on Ontologies-enhanced Large Language Models](https://arxiv.org/abs/2403.00953) | AutoRD是一个自动化端到端系统，使用大型语言模型和医学知识图构建罕见疾病知识图，实现了整体F1得分47.3%，相对于基础LLM有14.4%的提升。 |
| [^126] | [MediSwift: Efficient Sparse Pre-trained Biomedical Language Models](https://arxiv.org/abs/2403.00952) | MediSwift在生物医学领域引入了高效稀疏预训练模型，通过75%的权重稀疏性实现了2-2.5倍的训练FLOPs减少，从而显著提高了效率。 |
| [^127] | [Differentially Private Knowledge Distillation via Synthetic Text Generation](https://arxiv.org/abs/2403.00932) | 提出一种利用合成数据进行知识蒸馏的差分私密算法 |
| [^128] | [An Interpretable Ensemble of Graph and Language Models for Improving Search Relevance in E-Commerce](https://arxiv.org/abs/2403.00923) | 该研究提出了一个可解释的图形和语言模型集成方法，用于提高电子商务领域中搜索相关性，弥补了现有模型在实际部署中的泛化能力和可解释性方面的不足。 |
| [^129] | [DiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large Language Models](https://arxiv.org/abs/2403.00896) | DiaHalu是第一个对话级幻觉评估基准，针对大型语言模型在对话级别上的幻觉问题进行研究。 |
| [^130] | [A systematic evaluation of large language models for generating programming code](https://arxiv.org/abs/2403.00894) | GPT-4在生成编程代码方面表现优异，特别是在选择最佳提示策略时，超过了其他大型语言模型和85%的人类参与者。 |
| [^131] | [A Regularization-based Transfer Learning Method for Information Extraction via Instructed Graph Decoder](https://arxiv.org/abs/2403.00891) | 提出了一种基于正则化的信息抽取迁移学习方法，通过指导图解码器实现数据集之间通用知识的迁移 |
| [^132] | [Margin Discrepancy-based Adversarial Training for Multi-Domain Text Classification](https://arxiv.org/abs/2403.00888) | 该研究提出了一种基于边际差异的对抗训练方法，通过在多领域文本分类中进行理论分析和新的泛化界限的建立，解决了在MDTC算法设计中缺乏理论保证的挑战。 |
| [^133] | [SEGAA: A Unified Approach to Predicting Age, Gender, and Emotion in Speech](https://arxiv.org/abs/2403.00887) | 本文提出了一种统一的方法来从语音中预测年龄、性别和情绪，通过深度学习模型探索了单一、多输出和顺序模型的比较，并提出了新颖的多输出学习架构。 |
| [^134] | [Word Order and World Knowledge](https://arxiv.org/abs/2403.00876) | 本研究探讨了词序如何影响语言模型从原始文本中归纳世界知识，发现一些固定词序在不同语言中表现更好或更差，而预训练语言模型中的Wov2Lex假设不成立。 |
| [^135] | [Teach LLMs to Phish: Stealing Private Information from Language Models](https://arxiv.org/abs/2403.00871) | 本研究提出了一种名为“神经钓鱼”的新型实用数据提取攻击，使对手能够成功地从大型语言模型中提取敏感信息，攻击成功率高达10%至50%。 |
| [^136] | [SoftTiger: A Clinical Foundation Model for Healthcare Workflows](https://arxiv.org/abs/2403.00868) | SoftTiger是一个专为医疗工作流设计的临床大型语言模型，通过处理临床笔记的结构化，实现了基本临床任务以及更复杂的下游临床任务的执行。 |
| [^137] | [Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by Exploring Refusal Loss Landscapes](https://arxiv.org/abs/2403.00867) | 本文提出了一种名为Gradient Cuff的方法，通过探索拒绝损失地形图来检测对大语言模型的越狱攻击，成功设计了一种有效的两步检测策略。 |
| [^138] | [LLM-Ensemble: Optimal Large Language Model Ensemble Method for E-commerce Product Attribute Value Extraction](https://arxiv.org/abs/2403.00863) | 提出了一种名为LLM-ensemble的算法，用于集成不同大型语言模型，以提高电子商务产品属性值提取的性能。 |
| [^139] | [NewsBench: Systematic Evaluation of LLMs for Writing Proficiency and Safety Adherence in Chinese Journalistic Editorial Applications](https://arxiv.org/abs/2403.00862) | NewsBench是一个评估LLMs在中国新闻写作水平和安全性遵从能力的基准框架，揭示了在创造性写作任务中LLMs相对不足的新闻伦理遵守方面的需求。 |
| [^140] | [Direct Alignment of Draft Model for Speculative Decoding with Chat-Fine-Tuned LLMs](https://arxiv.org/abs/2403.00858) | 通过提出的框架，我们训练了一种用于Llama 2 Chat 7B或更大模型的草案模型，实现了加速推理，仅占原始大小的1.64％。 |
| [^141] | [Speaker-Independent Dysarthria Severity Classification using Self-Supervised Transformers and Multi-Task Learning](https://arxiv.org/abs/2403.00854) | 提出了一种使用自监督变压器和多任务学习进行说话者无关的运动障碍严重度分类的方法，可自动评估运动障碍的严重程度。 |
| [^142] | [Enhancing Long-Term Recommendation with Bi-level Learnable Large Language Model Planning](https://arxiv.org/abs/2403.00843) | 利用大型语言模型的规划能力来增强长期推荐，使模型在个性化推荐中更有效地理解和应用任务解决原则 |
| [^143] | [EyeGPT: Ophthalmic Assistant with Large Language Models](https://arxiv.org/abs/2403.00840) | EyeGPT是一个专门为眼科设计的大型语言模型，采用角色扮演、微调和检索增强生成等策略，提出了全面的多指标评估框架。 |
| [^144] | [ToolNet: Connecting Large Language Models with Massive Tools via Tool Graph](https://arxiv.org/abs/2403.00839) | ToolNet是一个插拔式框架，通过将工具组织成一个有向图，实现了将大型语言模型与数千个工具连接起来，扩展了工具使用的数量而仅有中等标记消耗的增加。 |
| [^145] | [CLLMs: Consistency Large Language Models](https://arxiv.org/abs/2403.00835) | 提出了一种新方法，通过精细调整目标LLM实现了对雅各比轨迹上固定点的一致性预测，有效提高了生成速度2.4倍到3.4倍。 |
| [^146] | [MedAide: Leveraging Large Language Models for On-Premise Medical Assistance on Edge Devices](https://arxiv.org/abs/2403.00830) | MedAide是一款利用微型语言模型与LangChain集成，为资源受限的边缘设备提供高效医疗诊断和支持的现场医疗聊天机器人，通过模型优化和多样的医疗数据集训练来提升其领域特定能力。 |
| [^147] | [TroubleLLM: Align to Red Team Expert](https://arxiv.org/abs/2403.00829) | TroubleLLM是第一个用于生成关于LLMs安全问题的可控测试提示的LLM，通过广泛实验和人类评估展示了其在生成质量和生成可控性方面的优越性 |
| [^148] | [Deep Learning Detection Method for Large Language Models-Generated Scientific Content](https://arxiv.org/abs/2403.00828) | 提出了一种新的ChatGPT生成科学文本检测方法AI-Catcher，该方法集成了多层感知器（MLP）和卷积神经网络（CNN），是一个多模态模型，用于检测大型语言模型生成的科学内容。 |
| [^149] | [Self-Refinement of Language Models from External Proxy Metrics Feedback](https://arxiv.org/abs/2403.00827) | 本文提出了Proxy Metric-based Self-Refinement (ProMiSe)方法，通过外部指标反馈指导语言模型在质量关键维度上进行自我完善，从而改进响应质量。 |
| [^150] | [LLMGuard: Guarding Against Unsafe LLM Behavior](https://arxiv.org/abs/2403.00826) | LLMGuard是一个监视用户与LLM应用程序互动的工具，可标记违背特定行为或对话主题的内容。 |
| [^151] | [Comparing effectiveness of regularization methods on text classification: Simple and complex model in data shortage situation](https://arxiv.org/abs/2403.00825) | 本文比较了当只有少量带标签数据可用时，简单的词嵌入模型与复杂模型（CNN和BiLSTM）在文本分类中的正则化效果，并探讨了对抗训练和半监督学习方法在提高模型性能方面的作用。 |
| [^152] | [Information Flow Routes: Automatically Interpreting Language Models at Scale](https://arxiv.org/abs/2403.00824) | 这项研究提出了一种自动解释语言模型的方法，通过构建信息流路由图来揭示模型内部的关键节点和操作，相比于现有方法的激活修补，这种方法通过归因实现，在不需要人工干预设计的情况下可以有效地分析模型行为。 |
| [^153] | [Adapting to Teammates in a Cooperative Language Game](https://arxiv.org/abs/2403.00823) | 这项研究提出了第一个适应Codenames游戏的Agent，采用集成方法来确定最佳匹配的内部专家Agent，从而使Agent能够根据特定队友进行适应。 |
| [^154] | [Social Media as a Sensor: Analyzing Twitter Data for Breast Cancer Medication Effects Using Natural Language Processing](https://arxiv.org/abs/2403.00821) | 本文利用自然语言处理分析推特数据，发展了一种基于Transformer的分类器来识别乳腺癌患者/幸存者，并设计了多层规则模型以研究乳腺癌疗法效果。 |
| [^155] | [Retrieval Augmented Generation Systems: Automatic Dataset Creation, Evaluation and Boolean Agent Setup](https://arxiv.org/abs/2403.00820) | 本文提出了一种严格的数据集创建和评估工作流程，用于量化比较不同的RAG策略，同时开发和评估了一个布尔代理RAG设置，使得大语言模型可以节省标记来决定是否查询向量数据库。 |
| [^156] | [DenseMamba: State Space Models with Dense Hidden Connection for Efficient Large Language Models](https://arxiv.org/abs/2403.00818) | DenseSSM是一种新方法，通过密集连接增强了状态空间模型(SSM)，有效地提升了各层之间隐藏信息的流动，在保持训练并行性和推理效率的同时，取得了显著的性能提升。 |
| [^157] | [RAM-EHR: Retrieval Augmentation Meets Clinical Predictions on Electronic Health Records](https://arxiv.org/abs/2403.00815) | RAM-EHR通过增强检索并利用总结知识，提高了针对电子健康记录的临床预测效果。 |
| [^158] | [UrbanGPT: Spatio-Temporal Large Language Models](https://arxiv.org/abs/2403.00813) | 都市GPT旨在建立一个具有强大泛化能力的时空模型，借鉴大型语言模型的成就。 |
| [^159] | [LoRA Meets Dropout under a Unified Framework](https://arxiv.org/abs/2403.00812) | LoRA是一个轻量级的参数高效微调方法，该论文研究了LoRA与dropout方法在模型定制中的矛盾，重新审视了transformer-specific的dropout方法，并建立了它们之间的数学和经验上的等价性和区别。 |
| [^160] | [Cognitive Bias in High-Stakes Decision-Making with LLMs](https://arxiv.org/abs/2403.00811) | 提出了BiasBuster框架，用于揭示、评估和减轻LLMs中的认知偏见，特别是在高风险决策任务中，通过开发包含16,800个提示的数据集和测试多种偏见缓解策略，并提出一种利用LLMs自身来消除其提示中偏见的新方法。 |
| [^161] | [Bootstrapping Cognitive Agents with a Large Language Model](https://arxiv.org/abs/2403.00810) | 通过利用大型语言模型中的知识，我们将认知模型与大语言模型相结合，提出了一种通过具身Agent完成任务的框架，相较于完全基于大语言模型的Agent，具有更好的效率。 |
| [^162] | [Abdelhak at SemEval-2024 Task 9 : Decoding Brainteasers, The Efficacy of Dedicated Models Versus ChatGPT](https://arxiv.org/abs/2403.00809) | 本研究提出了一个专用模型，在解决谜题任务中表现出色，并与ChatGPT进行了比较性能分析，发现专用模型在横向思维和问题解决方面具有明显优势。 |
| [^163] | [IPED: An Implicit Perspective for Relational Triple Extraction based on Diffusion Model](https://arxiv.org/abs/2403.00808) | 提出了一种基于扩散模型的IPED方法，采用隐式答案策略完成表格，在关系三元组提取中取得了有效结果 |
| [^164] | [Enhancing Cloud-Based Large Language Model Processing with Elasticsearch and Transformer Models](https://arxiv.org/abs/2403.00807) | 利用Elasticsearch和Transformer模型提升云端基于大型语言模型的处理，尤其在实现语义搜索方面有显著帮助。 |
| [^165] | [Enhanced User Interaction in Operating Systems through Machine Learning Language Models](https://arxiv.org/abs/2403.00806) | 通过结合交互设计和机器学习，提供更高效、个性化的用户体验，满足用户特定需求，持续改善产品质量和性能。 |
| [^166] | [Uncovering Customer Issues through Topological Natural Language Analysis](https://arxiv.org/abs/2403.00804) | 提出了一种利用自然语言技术和拓扑数据分析监控新兴和热门客户问题的机器学习算法。 |
| [^167] | [Self-Retrieval: Building an Information Retrieval System with One Large Language Model](https://arxiv.org/abs/2403.00801) | 提出了自主检索(Self-Retrieval)，利用一个大型语言模型完全内化信息检索系统的能力，深度利用大型语言模型在信息检索过程中的能力。 |
| [^168] | [Brain-Inspired Two-Stage Approach: Enhancing Mathematical Reasoning by Imitating Human Thought Processes](https://arxiv.org/abs/2403.00800) | 通过模仿人类思维过程，在数学推理任务中提出的Brain方法实现了最先进的性能，并发现计划可以从自然语言、代码或形式语言中明确提取出来。 |
| [^169] | [An Empirical Study of Data Ability Boundary in LLMs' Math Reasoning](https://arxiv.org/abs/2403.00799) | 通过确定最优路径集，本研究拓展了LLMs在数学推理任务中的能力边界，提出了一种监督数据策略，通过混合不同类型数据的最小最优集来累积增强模型能力，并实现了SOTA性能。 |
| [^170] | [Executing Natural Language-Described Algorithms with Large Language Models: An Investigation](https://arxiv.org/abs/2403.00795) | 大语言模型可以有效地执行用自然语言描述的程序，尤其是在不涉及大量数字计算的情况下。 |
| [^171] | [Getting Serious about Humor: Crafting Humor Datasets with Unfunny Large Language Models](https://arxiv.org/abs/2403.00794) | 利用大型语言模型生成合成数据，可以帮助改进幽默检测，特别是通过取消幽默元素来评估模型性能。 |
| [^172] | [$\textit{L+M-24}$: Building a Dataset for Language + Molecules @ ACL 2024](https://arxiv.org/abs/2403.00791) | 这个论文介绍了$\textit{L+M-24}$数据集，该数据集专为ACL 2024年的语言+分子研讨会共享任务而设计，重点关注自然语言在分子设计中的三个关键优势：组合性、功能性和抽象性。 |
| [^173] | [PRECISE Framework: GPT-based Text For Improved Readability, Reliability, and Understandability of Radiology Reports For Patient-Centered Care](https://arxiv.org/abs/2403.00788) | 本研究提出并评估了PRECISE框架，利用GPT-4技术提供更易读的胸部X射线报告，以进一步提高放射学报告的可读性、可靠性和可理解性，有助于推动以患者为中心的护理。 |
| [^174] | [Utilizing BERT for Information Retrieval: Survey, Applications, Resources, and Challenges](https://arxiv.org/abs/2403.00784) | BERT的引入为信息检索领域带来了突破，研究者们将其应用于解决实际问题，并通过综合分析其在信息检索中的应用方法，为学术界和工业界提供了有益的参考。 |
| [^175] | [Ploutos: Towards interpretable stock movement prediction with financial large language model](https://arxiv.org/abs/2403.00782) | 提出了Ploutos，一个新型金融LLM框架，通过PloutosGen和PloutosGPT灵活融合文本和数值信息，提供可解释的股票走势预测 |
| [^176] | [Regional inflation analysis using social network data](https://arxiv.org/abs/2403.00774) | 本研究利用社交网络数据分析了区域通货膨胀的上升和下降趋势，探讨了社交网络讨论对通货膨胀预期的潜在影响。 |
| [^177] | [ROME: Memorization Insights from Text, Probability and Hidden State in Large Language Models](https://arxiv.org/abs/2403.00510) | ROME提出了一种新方法，通过比较记忆和非记忆样本之间的差异，探索大型语言模型中的记忆化，这有助于在不访问训练数据的情况下了解模型记忆的洞察和影响因素。 |
| [^178] | [Multimodal ArXiv: A Dataset for Improving Scientific Comprehension of Large Vision-Language Models](https://arxiv.org/abs/2403.00231) | 提出了Multimodal ArXiv数据集，包括ArXivCap和ArXivQA，用于增强大型视觉-语言模型对科学理解的能力，ArXivQA通过科学图生成问题，显著提高了数学推理准确率。 |
| [^179] | [On the Scaling Laws of Geographical Representation in Language Models](https://arxiv.org/abs/2402.19406) | 地理知识可以在大型语言模型中观察到，随着模型规模增加而一致扩展，但更大的模型无法消除训练数据中的地理偏见。 |
| [^180] | [WanJuan-CC: A Safe and High-Quality Open-sourced English Webtext Dataset](https://arxiv.org/abs/2402.19282) | WanJuan-CC是一个安全高质量的开源英文网络文本数据集，通过处理大规模的Common Crawl数据并经过多项筛选和过滤步骤得到，为语言模型的预训练提供了重要资源。 |
| [^181] | [Let LLMs Take on the Latest Challenges! A Chinese Dynamic Question Answering Benchmark](https://arxiv.org/abs/2402.19248) | 本论文提出了CDQA，一个中文动态问答基准测试，致力于提高中文大型语言模型（LLMs）回答动态问题的能力，并通过高质量数据和精细样本分类实现了对LLMs能力更细致的观察。实验结果表明，CDQA具有挑战性且值得进一步研究。 |
| [^182] | [How to Understand "Support"? An Implicit-enhanced Causal Inference Approach for Weakly-supervised Phrase Grounding](https://arxiv.org/abs/2402.19116) | 提出了一种隐式增强因果推断方法（IECI），用于解决弱监督短语定位任务中的挑战，通过标注高质量数据集进行评估，并相比基线方法展现出明显优势。 |
| [^183] | [Is Crowdsourcing Breaking Your Bank? Cost-Effective Fine-Tuning of Pre-trained Language Models with Proximal Policy Optimization](https://arxiv.org/abs/2402.18284) | 提出了一种自监督文本排序方法，利用近端策略优化对语言模型进行微调，消除了对人工注释员的需求，实验结果表明该方法训练的模型在各项得分方面明显优于基线 |
| [^184] | [Learning or Self-aligning? Rethinking Instruction Fine-tuning](https://arxiv.org/abs/2402.18243) | 本研究揭示了指导微调的潜在机制，发现尝试通过指导微调学习额外世界知识往往难以产生积极影响，重点在于保持内部知识一致性。 |
| [^185] | [A Language Model based Framework for New Concept Placement in Ontologies](https://arxiv.org/abs/2402.17897) | 提出了一种基于语言模型的框架，用于将从文本中提取的新概念插入到本体中，在边搜索、边形成和增强、边选择三个步骤中分别利用神经方法，并在 SNOMED CT 本体和 MedMentions 实体链接基准上进行了评估 |
| [^186] | [JMLR: Joint Medical LLM and Retrieval Training for Enhancing Reasoning and Professional Question Answering Capability](https://arxiv.org/abs/2402.17887) | JMLR通过联合训练信息检索系统和大型语言模型，在医学领域提高问题回答系统性能，降低计算资源需求，增强模型利用医疗知识进行推理和回答问题的能力。 |
| [^187] | [Towards Optimal Learning of Language Models](https://arxiv.org/abs/2402.17759) | 本论文提出了一种关于语言模型最佳学习的理论，通过最大化数据压缩比率来优化学习过程，根据学习定律揭示了最佳学习过程的特性，并在实验中验证了该定理。 |
| [^188] | [Latent Attention for Linear Time Transformers](https://arxiv.org/abs/2402.17512) | 提出了一种基于潜在向量定义注意力的方法，将标准transformer中的注意力机制的时间复杂度从二次方降低到与时间线性相关，表现与标准注意力媲美，但允许上下文窗口扩展到远远超出标准的范围。 |
| [^189] | [Consistency Matters: Explore LLMs Consistency From a Black-Box Perspective](https://arxiv.org/abs/2402.17411) | 该论文探讨了LLMs的一致性问题，提出了一种解决方案，并设计了数据集和基准模型进行实验，结果显示在一致性任务上超过了GPT3.5等模型 |
| [^190] | [Beyond the Known: Investigating LLMs Performance on Out-of-Domain Intent Detection](https://arxiv.org/abs/2402.17256) | 本文综合评估了LLMs在各种实验设置下的表现，发现其展现出强大的零次和少次能力，但与完全资源微调的模型相比仍处于劣势。 |
| [^191] | [LDB: A Large Language Model Debugger via Verifying Runtime Execution Step-by-step](https://arxiv.org/abs/2402.16906) | LDB是一个新颖的调试框架，可以让大型语言模型通过运行时执行信息来完善生成的程序。 |
| [^192] | [Improving LLM-based Machine Translation with Systematic Self-Correction](https://arxiv.org/abs/2402.16379) | 引入了名为TER的系统LLM自校正翻译框架，成功帮助LLMs提高翻译质量，具有更优越的系统性和可解释性。 |
| [^193] | [FuseChat: Knowledge Fusion of Chat Models](https://arxiv.org/abs/2402.16107) | FuseChat通过知识融合将多个对话模型的集体知识转移到目标语言模型中，避免了昂贵的预训练成本。 |
| [^194] | [Citation-Enhanced Generation for LLM-based Chatbot](https://arxiv.org/abs/2402.16063) | 提出一种基于引文增强的LLM聊天机器人生成方法，采用检索模块搜索支持文档来解决幻觉内容产生的问题。 |
| [^195] | [How Large Language Models Encode Context Knowledge? A Layer-Wise Probing Study](https://arxiv.org/abs/2402.16061) | 本文首次通过探究任务研究了大型语言模型逐层编码知识的能力，实验结果显示LLMs更倾向于在上层编码更多的上下文知识。 |
| [^196] | [Query Augmentation by Decoding Semantics from Brain Signals](https://arxiv.org/abs/2402.15708) | 提出了一种名为Brain-Aug的方法，通过从脑信号中解码的语义信息增强查询，可以生成更准确的查询，改善文档排序性能，特别适用于模糊查询。 |
| [^197] | [How (un)ethical are instruction-centric responses of LLMs? Unveiling the vulnerabilities of safety guardrails to harmful queries](https://arxiv.org/abs/2402.15302) | 本研究探讨了大型语言模型（LLMs）对指令中心响应的容忍度，并提出了一个包含复杂查询的数据集，旨在揭示触发不道德响应的方法。 |
| [^198] | [OmniPred: Language Models as Universal Regressors](https://arxiv.org/abs/2402.14547) | 本文提出了OmniPred框架，用于训练语言模型作为通用的端到端回归器，实验证明，在多个任务上训练时，语言模型能够显著优于传统回归模型。 |
| [^199] | [Modality-Aware Integration with Large Language Models for Knowledge-based Visual Question Answering](https://arxiv.org/abs/2402.12728) | 提出了一种模态感知的LLM集成方法（MAIL）用于针对KVQA，通过细致地利用多模态知识来处理图像理解和知识推理。 |
| [^200] | [Transformer-based Causal Language Models Perform Clustering](https://arxiv.org/abs/2402.12151) | Transformer-based因果语言模型通过在隐藏空间内对数据进行聚类来学习任务特定信息，这种聚类过程在学习中动态演变，并有助于处理未见实例。 |
| [^201] | [MRKE: The Multi-hop Reasoning Evaluation of LLMs by Knowledge Edition](https://arxiv.org/abs/2402.11924) | 通过编辑HotpotQA数据集中的新知识，我们引入了一个LLM MHQA评估基准，同时注释和评估了推理链，揭示了当前MHQA基准存在数据污染的潜在风险。 |
| [^202] | [Aligning Large Language Models by On-Policy Self-Judgment](https://arxiv.org/abs/2402.11253) | 本文提出了一个新颖的对齐框架SELF-JUDGE，通过增加式监督微调（JSFT）训练一个同时充当策略和评判器的单一模型，实现了参数高效的基于政策学习，无需额外的奖励模型。 |
| [^203] | [Word Embeddings Revisited: Do LLMs Offer Something New?](https://arxiv.org/abs/2402.11094) | 该论文系统地比较了经典词嵌入技术和基于LLM的词嵌入，发现LLMs倾向于将语义相关的单词更紧密地聚类在一起，并在Bigger Analogy Test Set（BATS）上具有更高的平均准确度。 |
| [^204] | [Leveraging Large Language Models for Enhanced NLP Task Performance through Knowledge Distillation and Optimized Training Strategies](https://arxiv.org/abs/2402.09282) | 该论文介绍了一种利用大型语言模型和优化训练策略提高NLP任务性能的新方法，通过知识蒸馏和采用细思连想提示技术，将GPT-4中提炼的知识应用于BERT模型，在命名实体识别任务上取得了显著的性能提升，并为资源有限或封闭网络环境提供了一种成本效益的解决方案。 |
| [^205] | [Premise Order Matters in Reasoning with Large Language Models](https://arxiv.org/abs/2402.08939) | 对大型语言模型（LLMs）进行推理任务时，论据的顺序非常重要，尤其是在演绎推理任务中，按照提示的真实证明顺序呈现论据可以显著提高模型的准确性。 |
| [^206] | [Extensible Multi-Granularity Fusion Network for Aspect-based Sentiment Analysis](https://arxiv.org/abs/2402.07787) | 这篇论文提出了一种可扩展的多粒度融合网络（EMGF）用于基于方面的情感分析，通过整合不同的语言和结构特征，包括句法依赖、组成、注意力语义和外部知识图谱等，来提高情感分析的性能和准确性。 |
| [^207] | [SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large Language Models](https://arxiv.org/abs/2402.05044) | SALAD-Bench是一个针对大语言模型的全面安全基准，通过其大规模、丰富的分类和多功能性，以及对攻击和防御方法的评估，实现了对LLMs的有效管理和保护。 |
| [^208] | [English Prompts are Better for NLI-based Zero-Shot Emotion Classification than Target-Language Prompts](https://arxiv.org/abs/2402.03223) | 本研究填补了一个研究空白，探讨了在非英文文本中应该使用哪种语言来提示情绪标签。 |
| [^209] | [C-RAG: Certified Generation Risks for Retrieval-Augmented Language Models](https://arxiv.org/abs/2402.03181) | C-RAG是第一个用于认证检索增强语言模型生成风险的框架，通过提供符合风险分析和生成风险的上界，确保生成结果的可信性。 |
| [^210] | [A Truly Joint Neural Architecture for Segmentation and Parsing](https://arxiv.org/abs/2402.02564) | 本文通过引入一个联合神经网络架构，在形态丰富的语言中实现了同时进行形态分割和句法分析的任务。通过提供基于格子的表示法，保留了输入的所有形态模糊性，有效解决了以往基于神经网络的依存句法分析器的局限性。 |
| [^211] | [LQER: Low-Rank Quantization Error Reconstruction for LLMs](https://arxiv.org/abs/2402.02446) | LQER使用低秩逼近和激活引起的尺度矩阵，实现了对LLMs的近乎无损量化，无需知识蒸馏或梯度优化，并大幅减少硬件资源的使用。 |
| [^212] | [Prompt-Driven LLM Safeguarding via Directed Representation Optimization](https://arxiv.org/abs/2401.18018) | 通过研究模型表示的影响，我们发现安全提示并没有明显增强恶意和无害查询之间的区分，并提出了一种名为DRO的方法，用于自动优化安全提示。 |
| [^213] | [DocFinQA: A Long-Context Financial Reasoning Dataset](https://arxiv.org/abs/2401.06915) | 引入了一个长文档财务问答任务，将平均上下文长度从700个词扩展到123k个词，对于大型语言模型在金融领域具有重要挑战。 |
| [^214] | [Learning to Generate Text in Arbitrary Writing Styles](https://arxiv.org/abs/2312.17242) | 提出了通过引导语言模型使用对比训练的表示来生成目标风格的文本的方法，以解决传统基于指令的模型难以重新现出作者特定风格的问题。 |
| [^215] | [Refining GPT-3 Embeddings with a Siamese Structure for Technical Post Duplicate Detection](https://arxiv.org/abs/2312.15068) | 本研究提出了使用孪生结构对GPT-3嵌入进行细化的方法，用于技术帖子的重复检测，解决了现有方法中存在的限制性问题。 |
| [^216] | [Exploring Multimodal Large Language Models for Radiology Report Error-checking](https://arxiv.org/abs/2312.13103) | 本文提出了多模态大型语言模型作为放射科医生检查报告错误的助手，通过引入合成错误并对不同难度级别进行评估，发现该模型在简单级别上在X光和CT扫描数据集上显著提高了性能，并且在MIMIC-CXR数据集上超过了领域专家的准确性。 |
| [^217] | [NoMIRACL: Knowing When You Don't Know for Robust Multilingual Retrieval-Augmented Generation](https://arxiv.org/abs/2312.11361) | 建立了用于评估大型语言模型在多语言环境中检索增强生成中的鲁棒性的NoMIRACL数据集，并提出了两个衡量模型鲁棒性的指标：幻觉率和错误率。 |
| [^218] | [MUFFIN: Curating Multi-Faceted Instructions for Improving Instruction-Following](https://arxiv.org/abs/2312.02436) | MUFFIN是一个新的指示遵循数据集策划方案，通过自动按比例扩大任务，通过多种输入方面使任务丰富多样。 |
| [^219] | [Retrieval-augmented Multi-modal Chain-of-Thoughts Reasoning for Large Language Models](https://arxiv.org/abs/2312.01714) | 本文引入了一种新颖的方法，通过使用检索机制动态自动选择以跨模态和内模态相似性为基础的演示示例，以提高多模态推理中的大型语言模型的性能。 |
| [^220] | [Detection and Analysis of Stress-Related Posts in Reddit Acamedic Communities](https://arxiv.org/abs/2312.01050) | 该研究聚焦于检测和分析Reddit学术社区中与压力相关的帖子，使用自然语言处理和机器学习分类器进行文本分类，发现词袋是最有效的特征。 |
| [^221] | [Ignore This Title and HackAPrompt: Exposing Systemic Vulnerabilities of LLMs through a Global Scale Prompt Hacking Competition](https://arxiv.org/abs/2311.16119) | 通过全球规模的Prompt Hacking竞赛，揭示了LLMs存在的系统漏洞，验证了当前LLMs可以被提示注入攻击操纵。 |
| [^222] | [$\textit{Dial BeInfo for Faithfulness}$: Improving Factuality of Information-Seeking Dialogue via Behavioural Fine-Tuning](https://arxiv.org/abs/2311.09800) | 通过BeInfo方法的行为微调，可以提高信息寻求对话系统对知识来源的准确性和忠实度 |
| [^223] | [MELA: Multilingual Evaluation of Linguistic Acceptability](https://arxiv.org/abs/2311.09033) | MELA是第一个覆盖10种语言的多语言语言可接受性基准，通过分析XLM-R的微调权重，探讨了跨语言迁移困难性，结果表明在上下文示例方面ChatGPT表现良好但仍落后于经过微调的XLM-R。 |
| [^224] | [Translating Legalese: Enhancing Public Understanding of Court Opinions with Legal Summarizers](https://arxiv.org/abs/2311.06534) | 使用人工智能生成的简化摘要可以帮助公众更好地理解司法意见，尤其对于受教育程度较低的人群有显著影响。 |
| [^225] | [Multilingual Jailbreak Challenges in Large Language Models](https://arxiv.org/abs/2310.06474) | 该研究揭示了大语言模型中存在的多语言越狱挑战，包括用户使用非英语提示绕过安全机制的非故意场景和恶意用户利用多语言提示恶意攻击LLMs的故意场景。 |
| [^226] | [Language Models Represent Space and Time](https://arxiv.org/abs/2310.02207) | 现代大型语言模型学习到了丰富的时空表征，包括学习到了空间和时间的线性表征以及个体的“空间神经元”和“时间神经元”。 |
| [^227] | [A Comprehensive Empirical Evaluation of Existing Word Embedding Approaches](https://arxiv.org/abs/2303.07196) | 本文评估了现有词嵌入方法，并发现基于神经网络的方法能更好地捕捉语言的语义和句法规律。 |
| [^228] | [Discovering Latent Knowledge in Language Models Without Supervision](https://arxiv.org/abs/2212.03827) | 通过在语言模型的内部激活中直接发现潜在知识的方式，我们提出了一种纯粹无监督的方法，可以准确回答未标记模型激活的是非问题，并且在大型语言模型中恢复多样知识。 |
| [^229] | [SMiLE: Schema-augmented Multi-level Contrastive Learning for Knowledge Graph Link Prediction](https://arxiv.org/abs/2210.04870) | 提出了一种新颖的基于模式增强的多层对比学习框架（SMiLE），用于知识图谱链接预测，通过利用网络模式作为先验约束来提高链接预测的准确性和上下文一致性。 |
| [^230] | [A Survey on Data Augmentation in Large Model Era.](http://arxiv.org/abs/2401.15422) | 这篇论文综述了大模型驱动的数据增强方法，包括图像增强、文本增强和配对数据增强。这些方法利用大模型的能力，有效提高了数据增强的效果，是解决大模型训练中数据质量不足的重要研究方向。 |
| [^231] | [Tweets to Citations: Unveiling the Impact of Social Media Influencers on AI Research Visibility.](http://arxiv.org/abs/2401.13782) | 本文研究了社交媒体影响者在提高机器学习研究的可见性方面的作用，发现被这些影响者认可的论文引用次数显著增加，中位数引用次数比对照组高2-3倍。此外，该研究还探讨了被展示作者的地理、性别和机构多样性。 |
| [^232] | [AntEval: Quantitatively Evaluating Informativeness and Expressiveness of Agent Social Interactions.](http://arxiv.org/abs/2401.06509) | 本研究通过使用桌面角色扮演游戏规则创建了一个环境，量化评估智能体社交互动的信息性和表达性，旨在克服隐私问题并促使智能体进行有意义、高质量的互动。 |
| [^233] | [From Interpolation to Extrapolation: Complete Length Generalization for Arithmetic Transformers.](http://arxiv.org/abs/2310.11984) | 本文研究了Transformer模型在学习算术算法方面的能力，并通过注意力偏置以及Attention Bias Calibration（ABC）来实现对于长长度的泛化。 |
| [^234] | [Denevil: Towards Deciphering and Navigating the Ethical Values of Large Language Models via Instruction Learning.](http://arxiv.org/abs/2310.11053) | 通过Moral Foundation Theory和DeNEVIL算法，我们研究了大型语言模型的道德价值，并构建了MoralPrompt数据集来评估模型的内在价值。发现大多数模型存在不对齐，需要进一步进行道德价值对齐。 |
| [^235] | [Improved Contextual Recognition In Automatic Speech Recognition Systems By Semantic Lattice Rescoring.](http://arxiv.org/abs/2310.09680) | 通过深度学习模型和transformer的重新评分，我们提出了一种通过语义格重排序来提高自动语音识别系统中上下文识别能力的方法。 |
| [^236] | [DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context Learning.](http://arxiv.org/abs/2310.02954) | 本研究引入了DQ-LoRe框架，它通过双重查询和低秩近似重新排序自动选择用于上下文学习的示例，在复杂推理任务中展示了出色的性能和效果。 |
| [^237] | [Knowledge Sanitization of Large Language Models.](http://arxiv.org/abs/2309.11852) | 这项研究探索了一种用于减轻大型语言模型（LLM）隐私问题的知识净化方法。通过微调模型，使其在被询问敏感信息时生成无害回答，从而有效地减少知识泄漏并保持整体性能。 |
| [^238] | [FaNS: a Facet-based Narrative Similarity Metric.](http://arxiv.org/abs/2309.04823) | 本研究提出了一种基于要素的叙事相似度度量方法FaNS，通过提取经典的五W一H要素并借助大型语言模型，可以更准确地识别出语义上相似的叙事。实验证明，FaNS与传统文本相似度度量方法相比具有更高的相关性（高37%）。 |
| [^239] | [Data Augmentation for Conversational AI.](http://arxiv.org/abs/2309.04739) | 本教程提供了对话式人工智能中数据增强的综述，包括对话增强、开放域和任务导向的对话生成以及评估模型。此外，还讨论了当前的挑战和未来的发展方向，以帮助推动该领域的发展。 |
| [^240] | [Retrieving Evidence from EHRs with LLMs: Possibilities and Challenges.](http://arxiv.org/abs/2309.04550) | 本研究提出了一种使用大型语言模型（LLMs）从未结构化的电子健康记录（EHR）中检索和总结相关证据的方法。通过在零样本条件下训练LLM来推断患者是否患有特定疾病，并且模型可以总结支持的证据。该方法在实践中被证明优于传统的信息检索方法。 |
| [^241] | [MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models.](http://arxiv.org/abs/2308.09729) | 本论文通过使用知识图谱来激发大型语言模型，解决了整合新知识、产生幻觉和决策过程不透明等问题，并通过生成思维导图展示了模型的推理路径，实验证明这种方法可以取得显著的实证增益。 |
| [^242] | [Do Language Models Refer?.](http://arxiv.org/abs/2308.05576) | 论文探讨了语言模型是否具有指称能力，并通过借鉴语言哲学外部主义传统的观点，提出了LMs可以指称的理由。 |
| [^243] | [Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding.](http://arxiv.org/abs/2307.15337) | 本研究提出了一种名为“思维的骨架”的方法，可以通过并行解码来减少大型语言模型的生成延迟。这种方法不仅显著提高了速度，还可以潜在地提高答案质量。 |
| [^244] | [Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models.](http://arxiv.org/abs/2306.08018) | Mol-Instructions是一个专门为生物分子领域设计的综合指令数据集，可以显著提高大语言模型在生物领域中的适应能力和认知敏锐度。 |
| [^245] | [Prompt Injection attack against LLM-integrated Applications.](http://arxiv.org/abs/2306.05499) | 本研究分析了LLM集成应用中的提示注入攻击的复杂性和影响，提出了一种新颖的黑盒提示注入攻击技术HouYi，并揭示了应用程序提示机制中以前未知和严重低估的漏洞。我们的研究呼吁进一步开发全面的防御措施，以抵御LLM集成应用中的提示注入攻击。 |
| [^246] | [Pre-trained Language Model with Prompts for Temporal Knowledge Graph Completion.](http://arxiv.org/abs/2305.07912) | 这篇论文提出了一种基于提示的预训练语言模型（PPT），用于时间知识图谱补全。通过遮盖策略，将TKGC任务转换为遮盖词预测任务，可以利用预训练语言模型中的语义信息。 |
| [^247] | [ChatGPT-steered Editing Instructor for Customization of Abstractive Summarization.](http://arxiv.org/abs/2305.02483) | 本文提出了一个三个代理的生成方案，包括生成器、辅导员和编辑器，以增强生成输出的自定义。在两个摘要总结数据集上进行的实验结果表明，我们的方法可以生成更好的输出。 |
| [^248] | [Personality-aware Human-centric Multimodal Reasoning: A New Task.](http://arxiv.org/abs/2304.02313) | 本文介绍了一个新的个性化情感驱动的多模态推理任务，利用《生活大爆炸》电视剧构建了数据集，考虑个体个性，提出了三种基线方法，证明该任务具有挑战性和前景。 |
| [^249] | [Mismatching-Aware Unsupervised Translation Quality Estimation For Low-Resource Languages.](http://arxiv.org/abs/2208.00463) | 本文提出了一种针对低资源语言的无监督翻译质量评估方法，通过使用XLMRScore和一些改进措施来解决未翻译标记和语言不匹配的问题。 |

# 详细

[^1]: 医学中的大型语言模型调查：原理、应用和挑战

    A Survey of Large Language Models in Medicine: Principles, Applications, and Challenges

    [https://rss.arxiv.org/abs/2311.05112](https://rss.arxiv.org/abs/2311.05112)

    本综述提供了医学中大型语言模型（LLMs）的原理、应用和挑战的全面概述。同时回答了医学LLMs的构建、下游性能、实际应用、挑战以及更好构建和利用的问题。旨在为构建有效的医学LLMs提供见解和实用资源。

    

    大型语言模型（LLMs），如ChatGPT，由于其理解和生成人类语言的能力而受到了广泛关注。在人工智能和临床医学中，LLMs在协助医生进行患者护理方面正在成为一个有前景的研究方向。本综述提供了医学中LLMs的原理、应用和面临的挑战的全面概述。我们回答了以下具体问题：1）如何构建医学LLMs？2）什么是医学LLMs的下游性能评估指标？3）在现实临床实践中，如何利用医学LLMs？4）使用医学LLMs会出现哪些挑战？5）如何更好地构建和利用医学LLMs？本综述旨在提供关于医学中LLMs的机遇和挑战的见解，并作为构建有效的医学LLMs的实用资源。我们还维护并定期更新一个清单

    Large language models (LLMs), such as ChatGPT, have received substantial attention due to their capabilities for understanding and generating human language. LLMs in medicine to assist physicians for patient care are emerging as a promising research direction in both artificial intelligence and clinical medicine. This review provides a comprehensive overview of the principles, applications, and challenges faced by LLMs in medicine. We address the following specific questions: 1) How should medical LLMs be built? 2) What are the measures for the downstream performance of medical LLMs? 3) How should medical LLMs be utilized in real-world clinical practice? 4) What challenges arise from the use of medical LLMs? and 5) How should we better construct and utilize medical LLMs? This review aims to provide insights into the opportunities and challenges of LLMs in medicine, and serve as a practical resource for constructing effective medical LLMs. We also maintain and regularly updated list of 
    
[^2]: 基于关键点驱动的数据合成及其在数学推理上的增强

    Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning

    [https://arxiv.org/abs/2403.02333](https://arxiv.org/abs/2403.02333)

    提出了基于关键点驱动的数据合成框架(KPDDS)，创造了迄今为止最大规模的用于数学推理的合成数据集KPMath，以及进一步增强的KPMath-Plus数据集，实现了零-shot PASS@1精度为39.3%的性能提升。

    

    大型语言模型（LLMs）在复杂推理任务中显示出巨大潜力，但其性能通常受到高质量、以推理为重点的训练数据稀缺的影响。为解决这一挑战，我们提出了基于关键点驱动的数据合成（KPDDS），这是一个新颖的数据合成框架，通过利用来自真实数据源的关键点和示例对生成问题-答案对。KPDDS确保通过严格的质量控制和大规模性能的生成新颖问题。因此，我们提出了KPMath，迄今为止量身定制的最广泛的用于数学推理的合成数据集，包括一百万个以上的问题-答案对。利用KPMath并将其与其他推理密集的语料库进行扩充，我们创建了全面的KPMath-Plus数据集。将Mistral-7B模型在KPMath-Plus上微调，使其在MATH测试集上实现零-shot PASS@1精度达到39.3%，这是一项突破性成就。

    arXiv:2403.02333v1 Announce Type: cross  Abstract: Large language models (LLMs) have shown great potential in complex reasoning tasks, yet their performance is often hampered by the scarcity of high-quality, reasoning-focused training datasets. Addressing this challenge, we propose Key-Point-Driven Data Synthesis (KPDDS), a novel data synthesis framework that synthesizes question-answer pairs by leveraging key points and exemplar pairs from authentic data sources. KPDDS ensures the generation of novel questions with rigorous quality control and substantial scalability. As a result, we present KPMath, the most extensive synthetic dataset tailored for mathematical reasoning to date, comprising over one million question-answer pairs. Utilizing KPMath and augmenting it with additional reasoning-intensive corpora, we create the comprehensive KPMath-Plus dataset. Fine-tuning the Mistral-7B model on KPMath-Plus yields a zero-shot PASS@1 accuracy of 39.3% on the MATH test set, a performance th
    
[^3]: 对比区域引导：在视觉-语言模型中提高定位准确性而无需训练

    Contrastive Region Guidance: Improving Grounding in Vision-Language Models without Training

    [https://arxiv.org/abs/2403.02325](https://arxiv.org/abs/2403.02325)

    引入了对比区域引导（CRG）方法，实现了在视觉-语言模型中无需训练即可使模型响应视觉提示并取得显著改进。

    

    通过突出图像中特别相关的区域，可以改善视觉-语言模型（VLMs）在各种视觉-语言（VL）任务上的性能，引导模型更密切地关注这些感兴趣的区域。我们引入了对比区域引导（CRG），这是一种无需训练的引导方法，可以使开源的VLMs响应视觉提示，并在各种VL任务中取得显著改进。

    arXiv:2403.02325v1 Announce Type: cross  Abstract: Highlighting particularly relevant regions of an image can improve the performance of vision-language models (VLMs) on various vision-language (VL) tasks by guiding the model to attend more closely to these regions of interest. For example, VLMs can be given a "visual prompt", where visual markers such as bounding boxes delineate key image regions. However, current VLMs that can incorporate visual guidance are either proprietary and expensive or require costly training on curated data that includes visual prompts. We introduce Contrastive Region Guidance (CRG), a training-free guidance method that enables open-source VLMs to respond to visual prompts. CRG contrasts model outputs produced with and without visual prompts, factoring out biases revealed by the model when answering without the information required to produce a correct answer (i.e., the model's prior). CRG achieves substantial improvements in a wide variety of VL tasks: When
    
[^4]: 在英语和瑞典语中检测未记录的词义

    Detection of Non-recorded Word Senses in English and Swedish

    [https://arxiv.org/abs/2403.02285](https://arxiv.org/abs/2403.02285)

    该研究致力于在英语和瑞典语中检测未记录的词义，通过使用预训练的词-上下文嵌入器和人工注释，成功提高了检测到具有未记录词义的词语用法数量。

    

    这项研究探讨了在英语和瑞典语中进行未知词义检测的任务。该任务的主要目标是确定特定词语用法的含义是否在词典中有记录。为此，使用一个预训练的上下文词嵌入器来比较词义条目与现代和历史语料库中词语用法，从而在少样本情况下建模这一任务。此外，我们使用人类注释来调整和评估我们的模型。与从语料库中随机抽样相比，我们的模型能够显著增加检测到具有未记录词义的词语用法数量。

    arXiv:2403.02285v1 Announce Type: new  Abstract: This study addresses the task of Unknown Sense Detection in English and Swedish. The primary objective of this task is to determine whether the meaning of a particular word usage is documented in a dictionary or not. For this purpose, sense entries are compared with word usages from modern and historical corpora using a pre-trained Word-in-Context embedder that allows us to model this task in a few-shot scenario. Additionally, we use human annotations to adapt and evaluate our models. Compared to a random sample from a corpus, our model is able to considerably increase the detected number of word usages with non-recorded senses.
    
[^5]: 文本中的情绪细粒度：心理健康的汇总级指标

    Emotion Granularity from Text: An Aggregate-Level Indicator of Mental Health

    [https://arxiv.org/abs/2403.02281](https://arxiv.org/abs/2403.02281)

    提出从社交媒体的文本中计算情绪细粒度的方法，并研究其在心理健康条件中作为指标的有效性

    

    我们在情绪对塑造我们的经历中有共同点，然而，每个人在如何识别、分类和表达情绪方面有很大差异。在心理学中，个体区分情绪概念的能力变化被称为情绪细粒度（通过个体对自己情绪的自我报告来确定）。高情绪细粒度已与更好的心理和身体健康联系在一起；而低情绪细粒度已与应激情绪调节策略和不良健康结果联系在一起。在这项工作中，我们提出从社交媒体中的时间顺序演讲者话语中计算情绪细粒度的计算方法（代替各种偏见的自我报告）。然后我们研究这种文本衍生情绪细粒度措施在作为各种心理健康条件（MHCs）的标记时的有效性。我们建立情绪细粒度的基线措施

    arXiv:2403.02281v1 Announce Type: new  Abstract: We are united in how emotions are central to shaping our experiences; and yet, individuals differ greatly in how we each identify, categorize, and express emotions. In psychology, variation in the ability of individuals to differentiate between emotion concepts is called emotion granularity (determined through self-reports of one's emotions). High emotion granularity has been linked with better mental and physical health; whereas low emotion granularity has been linked with maladaptive emotion regulation strategies and poor health outcomes. In this work, we propose computational measures of emotion granularity derived from temporally-ordered speaker utterances in social media (in lieu of self-reports that suffer from various biases). We then investigate the effectiveness of such text-derived measures of emotion granularity in functioning as markers of various mental health conditions (MHCs). We establish baseline measures of emotion gran
    
[^6]: RIFF: 学习为语言模型的少样本微调改写输入

    RIFF: Learning to Rephrase Inputs for Few-shot Fine-tuning of Language Models

    [https://arxiv.org/abs/2403.02271](https://arxiv.org/abs/2403.02271)

    通过训练少样本释义模型并在训练和测试时用释义丰富数据，可以提高语言模型的性能，超出仅通过参数高效微调的效果。

    

    预训练语言模型（PLMs）可以精确地为下游文本处理任务进行微调。最近，研究人员引入了几种参数高效的微调方法，优化输入提示或调整少量模型参数（例如 LoRA）。在本研究中，我们探讨了改变原始任务的输入文本与参数高效微调方法相结合的影响。为了最有效地重写输入文本，我们使用最大边际似然目标训练了一个少样本释义模型。使用六个少样本文本分类数据集，我们展示了在训练和测试时用释义丰富数据可以提高性能，超出了仅通过参数高效微调可以实现的性能。

    arXiv:2403.02271v1 Announce Type: new  Abstract: Pre-trained Language Models (PLMs) can be accurately fine-tuned for downstream text processing tasks. Recently, researchers have introduced several parameter-efficient fine-tuning methods that optimize input prompts or adjust a small number of model parameters (e.g LoRA). In this study, we explore the impact of altering the input text of the original task in conjunction with parameter-efficient fine-tuning methods. To most effectively rewrite the input text, we train a few-shot paraphrase model with a Maximum-Marginal Likelihood objective. Using six few-shot text classification datasets, we show that enriching data with paraphrases at train and test time enhances the performance beyond what can be achieved with parameter-efficient fine-tuning alone.
    
[^7]: 基于自然语言推理和主张提取的摘要可信度评估

    FENICE: Factuality Evaluation of summarization based on Natural language Inference and Claim Extraction

    [https://arxiv.org/abs/2403.02270](https://arxiv.org/abs/2403.02270)

    提出了一种基于自然语言推理和主张提取的摘要可信度评估指标 FENICE，解决了自动生成摘要中存在的事实不一致性问题。

    

    最近在文本摘要方面取得的进展，尤其是随着大型语言模型（LLMs）的出现，已经表现出显著的性能。然而，一个显著的挑战仍然存在，即大量自动生成的摘要呈现事实不一致，比如幻觉。针对这一问题，出现了各种用于评估摘要一致性的方法。然而，这些新引入的度量标准面临着一些限制，包括缺乏可解释性，专注于短文档摘要（例如新闻文章）以及计算上的不可行性，特别是对于基于LLM的度量标准。为了解决这些缺点，我们提出了基于自然语言推理和主张提取的摘要可信度评估（FENICE），这是一种更具解释性和有效性的可信度导向度量。

    arXiv:2403.02270v1 Announce Type: new  Abstract: Recent advancements in text summarization, particularly with the advent of Large Language Models (LLMs), have shown remarkable performance. However, a notable challenge persists as a substantial number of automatically-generated summaries exhibit factual inconsistencies, such as hallucinations. In response to this issue, various approaches for the evaluation of consistency for summarization have emerged. Yet, these newly-introduced metrics face several limitations, including lack of interpretability, focus on short document summaries (e.g., news articles), and computational impracticality, especially for LLM-based metrics. To address these shortcomings, we propose Factuality Evaluation of summarization based on Natural language Inference and Claim Extraction (FENICE), a more interpretable and efficient factuality-oriented metric. FENICE leverages an NLI-based alignment between information in the source document and a set of atomic facts,
    
[^8]: 主观 $\textit{Isms}$? 论混淆仇恨与冒犯在滥用语言检测中的危险

    Subjective $\textit{Isms}$? On the Danger of Conflating Hate and Offence in Abusive Language Detection

    [https://arxiv.org/abs/2403.02268](https://arxiv.org/abs/2403.02268)

    论文指出在滥用语言检测中，混淆仇恨和冒犯可能会使研究结果失效，呼吁未来工作需要从理论上将仇恨与冒犯概念进行分离。

    

    arXiv:2403.02268v1 类型：跨领域 摘要：自然语言处理研究已经开始接受注释者主观性的概念，这主要受到标记差异的驱动。这种方法将每个注释者的观点视为有效，这对于嵌入主观性的任务(如情感分析)可能非常适用。然而，对于仇恨言论检测等任务，这种构造可能是不恰当的，因为它赋予了所有关于性别歧视或种族主义等议题的立场相同的有效性。我们认为对仇恨和冒犯的混淆可能会使对仇恨言论的研究结果无效，并呼吁未来的工作应该置于理论框架中，将仇恨与其正交概念冒犯分离开来。

    arXiv:2403.02268v1 Announce Type: cross  Abstract: Natural language processing research has begun to embrace the notion of annotator subjectivity, motivated by variations in labelling. This approach understands each annotator's view as valid, which can be highly suitable for tasks that embed subjectivity, e.g., sentiment analysis. However, this construction may be inappropriate for tasks such as hate speech detection, as it affords equal validity to all positions on e.g., sexism or racism. We argue that the conflation of hate and offence can invalidate findings on hate speech, and call for future work to be situated in theory, disentangling hate from its orthogonal concept, offence.
    
[^9]: KnowPhish：大型语言模型遇见多模态知识图谱以增强基于参考的网络钓鱼检测

    KnowPhish: Large Language Models Meet Multimodal Knowledge Graphs for Enhancing Reference-Based Phishing Detection

    [https://arxiv.org/abs/2403.02253](https://arxiv.org/abs/2403.02253)

    提出了一个自动化知识收集流水线，发布了一个包含20k品牌的大规模多模态品牌知识库KnowPhish，可用于加强现有基于参考的网络钓鱼检测器的性能

    

    网络钓鱼攻击已给个人和企业造成了重大损失，因此需要开发强大高效的自动网络钓鱼检测方法。基于参考的网络钓鱼检测器（RBPDs）已成为最先进的方法，它们比较目标网页上的标志与已知标志集。然而，现有RBPDs的主要局限是它们依赖于手动构建的品牌知识库，这使得无法扩展到大量品牌，导致由于知识库中品牌覆盖不足而出现假阴性错误。为了解决这个问题，我们提出了一个自动化知识收集流水线，采用该流水线我们收集并发布了一个大规模多模态品牌知识库KnowPhish，包含20k个品牌和每个品牌的丰富信息。KnowPhish可以用来以即插即用的方式提升现有RBPDs的性能。

    arXiv:2403.02253v1 Announce Type: cross  Abstract: Phishing attacks have inflicted substantial losses on individuals and businesses alike, necessitating the development of robust and efficient automated phishing detection approaches. Reference-based phishing detectors (RBPDs), which compare the logos on a target webpage to a known set of logos, have emerged as the state-of-the-art approach. However, a major limitation of existing RBPDs is that they rely on a manually constructed brand knowledge base, making it infeasible to scale to a large number of brands, which results in false negative errors due to the insufficient brand coverage of the knowledge base. To address this issue, we propose an automated knowledge collection pipeline, using which we collect and release a large-scale multimodal brand knowledge base, KnowPhish, containing 20k brands with rich information about each brand. KnowPhish can be used to boost the performance of existing RBPDs in a plug-and-play manner. A second 
    
[^10]: Birbal: 一种使用精心策划的数据集进行微调的高效7B指令模型

    Birbal: An efficient 7B instruct-model fine-tuned with curated datasets

    [https://arxiv.org/abs/2403.02247](https://arxiv.org/abs/2403.02247)

    Birbal是一个基于Mistral-7B模型的高效模型，通过在单个RTX 4090上进行16小时微调，成功地整理了高质量指令，使性能提高了35%。

    

    LLMOps由于硬件需求而产生重大成本，限制了它们的广泛可及性。此外，模型训练方法和数据缺乏透明度导致大多数模型无法重现。为了解决这些挑战，NeurIPS Workshop推出了LLM Efficiency Challenge，旨在通过在单个GPU（RTX 4090或带有40GB的A100）上在24小时内进行微调以适应各种任务。在这篇系统描述论文中，我们介绍了Birbal，我们基于Mistral-7B模型进行微调的获胜模型，微调时间为16小时。Birbal的成功在于整理了覆盖各种任务的高质量指令，使其性能比第二名Qwen-14B基于提交的性能提高了35%。

    arXiv:2403.02247v1 Announce Type: new  Abstract: LLMOps incur significant costs due to hardware requirements, hindering their widespread accessibility. Additionally, a lack of transparency in model training methods and data contributes to the majority of models being non-reproducible. To tackle these challenges, the LLM Efficiency Challenge was introduced at NeurIPS Workshop, aiming to adapt foundation models on a diverse set of tasks via fine-tuning on a single GPU (RTX 4090 or A100 with 40GB) within a 24-hour timeframe. In this system description paper, we introduce Birbal, our Mistral-7B based winning model, fine-tuned on a single RTX 4090 for 16 hours. Birbal's success lies in curating high-quality instructions covering diverse tasks, resulting in a 35% performance improvement over second-best Qwen-14B based submission.
    
[^11]: PHAnToM：人格对大型语言模型的心理理论推理产生影响

    PHAnToM: Personality Has An Effect on Theory-of-Mind Reasoning in Large Language Models

    [https://arxiv.org/abs/2403.02246](https://arxiv.org/abs/2403.02246)

    通过提示引发特定人格对大型语言模型的心理理论推理能力产生显著影响，特别是来自黑暗三合会的特质对多种LLMs在不同ToM任务中具有较大效应。

    

    大型语言模型（LLMs）方面的最新进展表明，它们在自然语言处理的许多任务中的能力与甚至优于人类。尽管取得了这一进展，LLMs在社会认知推理方面仍然不足，而人类在这方面天生就很擅长。受到心理学研究中某些人格特质与心理理论（ToM）推理之间联系的启发，以及关于提示工程研究在影响LLMs能力方面的超敏感性的启发，本研究调查了使用提示在LLMs中引发人格如何影响它们的ToM推理能力。我们的研究结果表明，某些引发的人格特质可以显著影响LLMs在三种不同的ToM任务中的推理能力。特别是，来自黑暗三合会(Dark Triad)的特质对于像GPT-3.5、Llama 2和Mistral这样的LLMs在不同的ToM任务中具有较大的变量效应。我们发现，具有某些人格特质的LLMs在执行ToM任务时表现出不同的表现。

    arXiv:2403.02246v1 Announce Type: new  Abstract: Recent advances in large language models (LLMs) demonstrate that their capabilities are comparable, or even superior, to humans in many tasks in natural language processing. Despite this progress, LLMs are still inadequate at social-cognitive reasoning, which humans are naturally good at. Drawing inspiration from psychological research on the links between certain personality traits and Theory-of-Mind (ToM) reasoning, and from prompt engineering research on the hyper-sensitivity of prompts in affecting LLMs capabilities, this study investigates how inducing personalities in LLMs using prompts affects their ToM reasoning capabilities. Our findings show that certain induced personalities can significantly affect the LLMs' reasoning capabilities in three different ToM tasks. In particular, traits from the Dark Triad have a larger variable effect on LLMs like GPT-3.5, Llama 2, and Mistral across the different ToM tasks. We find that LLMs tha
    
[^12]: ChatGPT主题和情感建模在金融中的应用优化

    Distilled ChatGPT Topic & Sentiment Modeling with Applications in Finance

    [https://arxiv.org/abs/2403.02185](https://arxiv.org/abs/2403.02185)

    ChatGPT被应用于金融领域，通过知识蒸馏和迁移学习融合的训练方法，生成轻量级主题和情感分类模型，成功应用于量化投资场景。

    

    在这项研究中，利用ChatGPT创建了简化模型，生成易于解释的特征。这些特征用于评估从财报电话会议中得出的财务结果。我们详细介绍了一个融合了知识蒸馏和迁移学习的训练方法，得到了轻量级的主题和情感分类模型，而准确率损失不大。这些模型经过专家标注的数据集评估。论文还探讨了两个实际案例研究，突显了生成的特征如何在量化投资场景中有效利用。

    arXiv:2403.02185v1 Announce Type: cross  Abstract: In this study, ChatGPT is utilized to create streamlined models that generate easily interpretable features. These features are then used to evaluate financial outcomes from earnings calls. We detail a training approach that merges knowledge distillation and transfer learning, resulting in lightweight topic and sentiment classification models without significant loss in accuracy. These models are assessed through a dataset annotated by experts. The paper also delves into two practical case studies, highlighting how the generated features can be effectively utilized in quantitative investing scenarios.
    
[^13]: 推理过程中不是所有LLMs的层都是必要的

    Not all Layers of LLMs are Necessary during Inference

    [https://arxiv.org/abs/2403.02181](https://arxiv.org/abs/2403.02181)

    推理过程中，根据输入实例的不同难易程度，本文提出了一种名为AdaInfer的算法，可以自适应地使用浅层和深层，从而节省了计算资源。

    

    大型语言模型（LLMs）的推理阶段非常昂贵。理想的LLMs推理阶段可以利用更少的计算资源，同时仍保持其能力（例如泛化和上下文学习能力）。本文尝试回答一个问题：“在LLMs推理过程中，我们可以为简单实例使用浅层，并为难以处理的实例使用深层吗？”为了回答这个问题，我们首先通过统计分析跨任务激活的层来指出并非所有层在推理过程中都是必要的。然后，我们提出了一种简单的算法，名为AdaInfer，根据输入实例自适应地确定推理终止时刻。更重要的是，AdaInfer不改变LLMs参数，并在任务之间保持泛化能力。对知名LLMs（即Llama2系列和OPT）的实验证明，AdaInfer节省了平均14.8%的计算资源，甚至在情感方面高达50%。

    arXiv:2403.02181v1 Announce Type: cross  Abstract: The inference phase of Large Language Models (LLMs) is very expensive. An ideal inference stage of LLMs could utilize fewer computational resources while still maintaining its capabilities (e.g., generalization and in-context learning ability). In this paper, we try to answer the question, "During LLM inference, can we use shallow layers for easy instances; and deep layers for hard ones?" To answer this question, we first indicate that Not all Layers are Necessary during Inference by statistically analyzing the activated layers across tasks. Then, we propose a simple algorithm named AdaInfer to determine the inference termination moment based on the input instance adaptively. More importantly, AdaInfer does not alter LLM parameters and maintains generalizability across tasks. Experiments on well-known LLMs (i.e., Llama2 series and OPT) show that AdaInfer saves an average of 14.8% of computational resources, even up to 50% on sentiment 
    
[^14]: 掩面思想:简单地掩盖部分推理步骤可以提高语言模型对数学推理的学习

    Masked Thought: Simply Masking Partial Reasoning Steps Can Improve Mathematical Reasoning Learning of Language Models

    [https://arxiv.org/abs/2403.02178](https://arxiv.org/abs/2403.02178)

    引入对输入的扰动，通过随机掩盖思维链中的某些标记，可显著提高语言模型在推理任务中的学习效果

    

    在推理任务中，即使是一个轻微的错误也可能导致不准确的结果，从而导致大型语言模型在这些领域的性能不佳。我们提出的方法避免了外部资源，而是依赖于引入对输入的扰动。我们的训练方法随机掩盖了链式思维中的某些标记，这种技术对推理任务特别有效。

    arXiv:2403.02178v1 Announce Type: cross  Abstract: In reasoning tasks, even a minor error can cascade into inaccurate results, leading to suboptimal performance of large language models in such domains. Earlier fine-tuning approaches sought to mitigate this by leveraging more precise supervisory signals from human labeling, larger models, or self-sampling, although at a high cost. Conversely, we develop a method that avoids external resources, relying instead on introducing perturbations to the input. Our training approach randomly masks certain tokens within the chain of thought, a technique we found to be particularly effective for reasoning tasks. When applied to fine-tuning with GSM8K, this method achieved a 5% improvement in accuracy over standard supervised fine-tuning with a few codes modified and no additional labeling effort. Furthermore, it is complementary to existing methods. When integrated with related data augmentation methods, it leads to an average improvement of 3% im
    
[^15]: ProTrix: 使用句子背景构建用于规划和推理表格的模型

    ProTrix: Building Models for Planning and Reasoning over Tables with Sentence Context

    [https://arxiv.org/abs/2403.02177](https://arxiv.org/abs/2403.02177)

    提出了一个计划-推理框架，用于在表格上的句子背景中回答用户查询，通过对Llama-2-7B进行微调，构建了ProTrix模型，广泛适用于不同表格任务，并表现出与GPT-3.5-turbo相当的性能水平，可生成准确且忠实的解释。

    

    在各个领域中，表格在传达信息方面起着至关重要的作用，是组织和呈现结构化数据的不可或缺工具。我们提出了一个计划-推理框架，用于回答带有句子背景的表格上的不同类型的用户查询。该框架首先规划上下文中的推理路径，然后将每个步骤分配给基于程序或文本的推理，以达到最终答案。我们根据该框架构建了一个指令调整集TrixtInstruct。我们的数据集涵盖了那些需要结合表格和句子信息来获得规划和推理能力的程序无法解决的查询。我们通过对TrixInstruct上的Llama-2-7B进行微调，提出了ProTrix。我们的实验表明，ProTrix对各种表格任务具有普遍性，并且达到了与GPT-3.5-turbo相当的性能。我们进一步证明ProTrix可以生成准确和忠实的解释来回答复杂的问题。

    arXiv:2403.02177v1 Announce Type: new  Abstract: Tables play a crucial role in conveying information in various domains, serving as indispensable tools for organizing and presenting data in a structured manner. We propose a Plan-then-Reason framework to answer different types of user queries over tables with sentence context. The framework first plans the reasoning paths over the context, then assigns each step to program-based or textual reasoning to reach the final answer. We construct an instruction tuning set TrixInstruct following the framework. Our dataset cover queries that are program-unsolvable or need combining information from tables and sentences to obtain planning and reasoning abilities. We present ProTrix by finetuning Llama-2-7B on TrixInstruct. Our experiments show that ProTrix generalizes to diverse tabular tasks and achieves comparable performance to GPT-3.5-turbo. We further demonstrate that ProTrix can generate accurate and faithful explanations to answer complex f
    
[^16]: EEE-QA: 探索有效和高效的问题-答案表示

    EEE-QA: Exploring Effective and Efficient Question-Answer Representations

    [https://arxiv.org/abs/2403.02176](https://arxiv.org/abs/2403.02176)

    该研究探索了新的问题-答案编码方法，通过精细表示、答案候选项嵌入和内存效率提高推断效率。

    

    当前的问题回答方法依赖于预训练语言模型（PLMs）如RoBERTa。这项工作挑战现有的问题-答案编码约定，探索更精细的表示。我们首先测试了与使用句子开头标记作为问题表示相比，更好质量的各种池化方法。接下来，我们探索了同时将所有答案候选项与问题嵌入的机会。这样可以使答案选择之间进行交叉参考，并通过减少内存使用量来提高推断吞吐量。尽管这些方法简单而有效，但目前尚未在当前框架中得到广泛研究。我们尝试了不同的PLMs，并在是否集成知识图的情况下进行了实验。结果证明了所提出技术的内存效率，在性能上几乎没有牺牲。在实践中，我们的工作在消费级GPU上提高了38-100%的吞吐量，并加速了26-65%。

    arXiv:2403.02176v1 Announce Type: new  Abstract: Current approaches to question answering rely on pre-trained language models (PLMs) like RoBERTa. This work challenges the existing question-answer encoding convention and explores finer representations. We begin with testing various pooling methods compared to using the begin-of-sentence token as a question representation for better quality. Next, we explore opportunities to simultaneously embed all answer candidates with the question. This enables cross-reference between answer choices and improves inference throughput via reduced memory usage. Despite their simplicity and effectiveness, these methods have yet to be widely studied in current frameworks. We experiment with different PLMs, and with and without the integration of knowledge graphs. Results prove that the memory efficacy of the proposed techniques with little sacrifice in performance. Practically, our work enhances 38-100% throughput with 26-65% speedups on consumer-grade G
    
[^17]: LeBenchmark对法语句法学习了什么？

    What has LeBenchmark Learnt about French Syntax?

    [https://arxiv.org/abs/2403.02173](https://arxiv.org/abs/2403.02173)

    论文探讨了LeBenchmark这个预训练声学模型对法语句法信息的学习情况，结果显示模型在中间层学习到了一些句法信息。

    

    这篇论文报告了一系列旨在探究LeBenchmark的实验，LeBenchmark是一个在7000小时的法语口语上训练的预训练声学模型，用于获取句法信息。预训练的声学模型越来越多地用于下游语音任务，如自动语音识别、语音翻译、口语理解或语音解析。 尽管它们是在非常低级的信息（原始语音信号）上训练的，并且没有明确的词汇知识，但它们在需要更高级别语言知识的任务上取得了合理的结果。因此，一个新兴的问题是这些模型是否对句法信息进行编码。我们使用Orf\'eo树库来探究LeBenchmark的每个表示层的句法，并观察到它已经学会了一些句法信息。我们的结果表明，句法信息在网络的中间层更容易被抽取出来，之后是一个非常陡峭的下降。

    arXiv:2403.02173v1 Announce Type: new  Abstract: The paper reports on a series of experiments aiming at probing LeBenchmark, a pretrained acoustic model trained on 7k hours of spoken French, for syntactic information. Pretrained acoustic models are increasingly used for downstream speech tasks such as automatic speech recognition, speech translation, spoken language understanding or speech parsing. They are trained on very low level information (the raw speech signal), and do not have explicit lexical knowledge. Despite that, they obtained reasonable results on tasks that requires higher level linguistic knowledge. As a result, an emerging question is whether these models encode syntactic information. We probe each representation layer of LeBenchmark for syntax, using the Orf\'eo treebank, and observe that it has learnt some syntactic information. Our results show that syntactic information is more easily extractable from the middle layers of the network, after which a very sharp decre
    
[^18]: 从野外录制的语音消息中识别语音情感

    Speech emotion recognition from voice messages recorded in the wild

    [https://arxiv.org/abs/2403.02167](https://arxiv.org/abs/2403.02167)

    使用Emotional Voice Messages数据库，结合eGeMAPS特征和Transformer模型，实现了在野外录制的语音消息中的语音情感识别，取得了较高的准确度，并比基准模型提高了10%。

    

    用于语音情感识别（SER）的情感数据集通常包含表演或引发的语音，限制了它们在现实场景中的适用性。在这项工作中，我们使用了Emotional Voice Messages（EMOVOME）数据库，其中包括来自100名西班牙语使用者在消息应用中的自发语音消息，由专家和非专家标注者以连续和离散的情感进行标记。我们使用了eGeMAPS特征、基于Transformer的模型以及它们的组合来创建讲话者无关的SER模型。我们将结果与参考数据库进行了比较，并分析了标注者和性别公平性的影响。预训练的Unispeech-L模型及其与eGeMAPS的组合取得了最佳结果，在3类valence和arousal预测中分别获得了61.64%和55.57%的Unweighted Accuracy（UA），比基线模型提高了10%。对于情感类别，获得了42.58%的UA。EMOVOME表现不佳。

    arXiv:2403.02167v1 Announce Type: cross  Abstract: Emotion datasets used for Speech Emotion Recognition (SER) often contain acted or elicited speech, limiting their applicability in real-world scenarios. In this work, we used the Emotional Voice Messages (EMOVOME) database, including spontaneous voice messages from conversations of 100 Spanish speakers on a messaging app, labeled in continuous and discrete emotions by expert and non-expert annotators. We created speaker-independent SER models using the eGeMAPS features, transformer-based models and their combination. We compared the results with reference databases and analyzed the influence of annotators and gender fairness. The pre-trained Unispeech-L model and its combination with eGeMAPS achieved the highest results, with 61.64% and 55.57% Unweighted Accuracy (UA) for 3-class valence and arousal prediction respectively, a 10% improvement over baseline models. For the emotion categories, 42.58% UA was obtained. EMOVOME performed low
    
[^19]: 使用LLMs提取和规范化产品属性值

    Using LLMs for the Extraction and Normalization of Product Attribute Values

    [https://arxiv.org/abs/2403.02130](https://arxiv.org/abs/2403.02130)

    本文探讨了使用大型语言模型（LLMs）如GPT-3.5和GPT-4从产品标题和描述中提取和规范化属性值的潜力，引入了新的WDC PAVE数据集来支持实验。

    

    在电子商务网站上的产品提供通常包括文本产品标题和文本产品描述。为了提供诸如分面产品过滤或基于内容的产品推荐等功能，网站需要从非结构化产品描述中提取属性值对。本文探讨了使用大型语言模型（LLMs），如OpenAI的GPT-3.5和GPT-4，从产品标题和产品描述中提取和规范化属性值的潜力。为了进行实验，我们引入了WDC产品属性-值提取（WDC PAVE）数据集。WDC PAVE包含来自提供schema.org注释的87个网站的产品提供。这些提供属于五个不同的类别，每个类别都具有一组特定的属性。该数据集以两种形式提供手动验证的属性-值对：（i）直接提取的值和（ii）规范化的属性值。

    arXiv:2403.02130v1 Announce Type: new  Abstract: Product offers on e-commerce websites often consist of a textual product title and a textual product description. In order to provide features such as faceted product filtering or content-based product recommendation, the websites need to extract attribute-value pairs from the unstructured product descriptions. This paper explores the potential of using large language models (LLMs), such as OpenAI's GPT-3.5 and GPT-4, to extract and normalize attribute values from product titles and product descriptions. For our experiments, we introduce the WDC Product Attribute-Value Extraction (WDC PAVE) dataset. WDC PAVE consists of product offers from 87 websites that provide schema.org annotations. The offers belong to five different categories, each featuring a specific set of attributes. The dataset provides manually verified attribute-value pairs in two forms: (i) directly extracted values and (ii) normalized attribute values. The normalization 
    
[^20]: LOCR：面向光学字符识别的位置引导Transformer

    LOCR: Location-Guided Transformer for Optical Character Recognition

    [https://arxiv.org/abs/2403.02127](https://arxiv.org/abs/2403.02127)

    LOCR是一种面向光学字符识别的模型，通过在自回归过程中在transformer架构中集成位置引导，能够有效处理学术文档中的重复问题，并在测试集上表现出色。

    

    学术文档充斥着文本、方程式、表格和图形，需要全面理解才能准确进行光学字符识别（OCR）。尽管端到端OCR方法在准确性上优于基于布局的方法，但它们通常在处理重复性问题时遇到困难，特别是在“领域外”（OOD）文档中的复杂布局。为了解决这一问题，我们提出了LOCR，一种将位置引导整合到变压器架构中的模型。我们在一个包含来自125K个学术文档页面的超过7700万个文本-位置对的数据集上训练模型，包括单词、表格和数学符号的边界框。LOCR能熟练处理各种格式元素并以Markdown语言生成内容。在我们从arXiv构建的测试集中，衡量方式为编辑距离、BLEU、METEOR和F-measure，LOCR优于所有现有方法。LOCR还将重复频率从4

    arXiv:2403.02127v1 Announce Type: cross  Abstract: Academic documents are packed with texts, equations, tables, and figures, requiring comprehensive understanding for accurate Optical Character Recognition (OCR). While end-to-end OCR methods offer improved accuracy over layout-based approaches, they often grapple with significant repetition issues, especially with complex layouts in Out-Of-Domain (OOD) documents.To tackle this issue, we propose LOCR, a model that integrates location guiding into the transformer architecture during autoregression. We train the model on a dataset comprising over 77M text-location pairs from 125K academic document pages, including bounding boxes for words, tables and mathematical symbols. LOCR adeptly handles various formatting elements and generates content in Markdown language. It outperforms all existing methods in our test set constructed from arXiv, as measured by edit distance, BLEU, METEOR and F-measure.LOCR also reduces repetition frequency from 4
    
[^21]: 在混合代码的印地语中利用弱标注数据进行仇恨言论检测：一种基于可行性驱动的大型语言模型迁移学习方法

    Leveraging Weakly Annotated Data for Hate Speech Detection in Code-Mixed Hinglish: A Feasibility-Driven Transfer Learning Approach with Large Language Models

    [https://arxiv.org/abs/2403.02121](https://arxiv.org/abs/2403.02121)

    本研究利用弱标注数据和大型语言模型，针对混合代码的印地语进行仇恨言论检测，探索了零次学习、一次学习和少次学习方法，解决了标记数据的问题。

    

    大型语言模型的出现推动了各种自然语言处理任务的基准。然而，训练大型语言模型需要大量标记的训练数据。此外，数据标注和训练都是计算昂贵且耗时的。最近，零次和少次学习成为使用大型预训练模型标记数据的可行选择。在混合代码低资源语言中的仇恨言论检测是一个活跃的问题领域，LLM的使用在这方面已被证明是有益的。在这项研究中，我们收集了100条YouTube评论的数据集，并对混合代码的印地语中的粗粒度和细粒度的性别歧视进行了弱标注。由于需要耗费大量人力进行注释，因此采用了弱标注。然后，应用了零次学习、一次学习和少次学习以及提示方法来为评论分配标签，并将其与人工标记进行比较。

    arXiv:2403.02121v1 Announce Type: cross  Abstract: The advent of Large Language Models (LLMs) has advanced the benchmark in various Natural Language Processing (NLP) tasks. However, large amounts of labelled training data are required to train LLMs. Furthermore, data annotation and training are computationally expensive and time-consuming. Zero and few-shot learning have recently emerged as viable options for labelling data using large pre-trained models. Hate speech detection in mix-code low-resource languages is an active problem area where the use of LLMs has proven beneficial. In this study, we have compiled a dataset of 100 YouTube comments, and weakly labelled them for coarse and fine-grained misogyny classification in mix-code Hinglish. Weak annotation was applied due to the labor-intensive annotation process. Zero-shot learning, one-shot learning, and few-shot learning and prompting approaches have then been applied to assign labels to the comments and compare them to human-ass
    
[^22]: 建模多模态社交互动：具有密集对齐表示的新挑战和基线

    Modeling Multimodal Social Interactions: New Challenges and Baselines with Densely Aligned Representations

    [https://arxiv.org/abs/2403.02090](https://arxiv.org/abs/2403.02090)

    提出了三个新的具有挑战性的任务来模拟多人之间的细粒度动态，并为社交推理游戏设置提供了广泛的数据注释；同时提出了一种新颖的多模态基线方法，利用密集对齐的语言-视觉表示。

    

    理解涉及言语和非言语线索的社交互动对有效解释社交情境至关重要。然而，大多数关于多模态社交线索的先前工作主要集中在单人行为上，或依赖于与多方环境中的话语密切对齐的整体视觉表示。它们在建模多方互动的复杂动态方面存在局限。在本文中，我们介绍了三个新的具有挑战性的任务，以建模多人之间的细粒度动态：话语目标识别、代词指代消解和提及玩家预测。我们为社交推理游戏设置中的这些新挑战提供了广泛的数据注释。此外，我们提出了一种新颖的多模态基线，通过将视觉特征与其对应的话语同步，利用密集对齐的语言-视觉表示，这有助于

    arXiv:2403.02090v1 Announce Type: cross  Abstract: Understanding social interactions involving both verbal and non-verbal cues is essential to effectively interpret social situations. However, most prior works on multimodal social cues focus predominantly on single-person behaviors or rely on holistic visual representations that are not densely aligned to utterances in multi-party environments. They are limited in modeling the intricate dynamics of multi-party interactions. In this paper, we introduce three new challenging tasks to model the fine-grained dynamics between multiple people: speaking target identification, pronoun coreference resolution, and mentioned player prediction. We contribute extensive data annotations to curate these new challenges in social deduction game settings. Furthermore, we propose a novel multimodal baseline that leverages densely aligned language-visual representations by synchronizing visual features with their corresponding utterances. This facilitates
    
[^23]: 使用GPT-turbo 3.5自动生成英语词汇多项选择填空题的研究

    Automated Generation of Multiple-Choice Cloze Questions for Assessing English Vocabulary Using GPT-turbo 3.5

    [https://arxiv.org/abs/2403.02078](https://arxiv.org/abs/2403.02078)

    本研究评估了一种利用GPT-turbo 3.5自动生成英语词汇多项选择填空题目的新方法，通过VocaTT引擎的三个步骤实现，结果显示生成的题目有很高的良好形式比例。

    

    评估了一种利用大型语言模型（LLM）自动生成多项选择填空题目的新方法。该VocaTT引擎采用Python编写，包括三个基本步骤：预处理目标词汇列表、利用GPT生成句子和候选单词选项，最后选择合适的选项。通过生成60个以学术词汇为目标的问题来测试系统的效率。结果显示，75%的句子和66.85%的候选词选项形式良好。

    arXiv:2403.02078v1 Announce Type: new  Abstract: A common way of assessing language learners' mastery of vocabulary is via multiple-choice cloze (i.e., fill-in-the-blank) questions. But the creation of test items can be laborious for individual teachers or in large-scale language programs. In this paper, we evaluate a new method for automatically generating these types of questions using large language models (LLM). The VocaTT (vocabulary teaching and training) engine is written in Python and comprises three basic steps: pre-processing target word lists, generating sentences and candidate word options using GPT, and finally selecting suitable word options. To test the efficiency of this system, 60 questions were generated targeting academic words. The generated items were reviewed by expert reviewers who judged the well-formedness of the sentences and word options, adding comments to items judged not well-formed. Results showed a 75% rate of well-formedness for sentences and 66.85% rat
    
[^24]: 主题感知探究：从句子长度预测到习语识别，神经语言模型在多大程度上依赖于主题？

    Topic Aware Probing: From Sentence Length Prediction to Idiom Identification how reliant are Neural Language Models on Topic?

    [https://arxiv.org/abs/2403.02009](https://arxiv.org/abs/2403.02009)

    本论文通过主题感知探究方法探讨了Transformer-based模型在处理自然语言时对主题信号的主要依赖程度，并初步结果表明这些模型在中间层中编码了主题信息和非主题信息。

    

    基于Transformer的神经语言模型在各种自然语言处理任务上实现了最先进的性能。然而，一个开放的问题是这些模型在处理自然语言时在多大程度上依赖于词序/句法或词共现/主题信息。本研究通过探讨Transformer-based模型（如BERT和RoBERTa）在一系列英语探究任务（从简单的词汇任务如句子长度预测到复杂的语义任务如习语标记识别）上的表现与这些任务对主题信息的敏感性，为这一争论做出了贡献。为此，我们提出了一种我们称之为主题感知探究的新颖探究方法。我们的初步结果表明，基于Transformer的模型在其中间层中编码了主题信息和非主题信息。

    arXiv:2403.02009v1 Announce Type: new  Abstract: Transformer-based Neural Language Models achieve state-of-the-art performance on various natural language processing tasks. However, an open question is the extent to which these models rely on word-order/syntactic or word co-occurrence/topic-based information when processing natural language. This work contributes to this debate by addressing the question of whether these models primarily use topic as a signal, by exploring the relationship between Transformer-based models' (BERT and RoBERTa's) performance on a range of probing tasks in English, from simple lexical tasks such as sentence length prediction to complex semantic tasks such as idiom token identification, and the sensitivity of these tasks to the topic information. To this end, we propose a novel probing method which we call topic-aware probing. Our initial results indicate that Transformer-based models encode both topic and non-topic information in their intermediate layers,
    
[^25]: LLM-Oriented Retrieval Tuner

    LLM-Oriented Retrieval Tuner

    [https://arxiv.org/abs/2403.01999](https://arxiv.org/abs/2403.01999)

    通过LMORT，作者提出了一种高效的LLM定向检索调节器，可以实现有效的密集检索，与其他强大的DR模型相比具有竞争力的零-shot检索性能，并保持LLM的生成能力。

    

    密集检索（DR）现在被认为是增强大型语言模型（LLM）如GPT3和GPT-4记忆能力的一种有希望的工具，通过融入外部记忆。然而，由于LLM的文本生成和DR之间的范式差异，将检索和生成任务整合到一个共享的LLM中仍然是一个未解决的挑战。本文提出了一种高效的LLM定向检索调节器，即LMORT，它能够将DR容量与基础LLM解耦，并通过非侵入性地协调LLM的优化对齐和统一层向统一的DR空间，实现了有效和高效的DR，而无需调整LLM本身。在六个BEIR数据集上进行的大量实验证明，我们的方法在保持LLM生成能力的同时，能够实现与一系列强大DR模型相比具有竞争力的零-shot检索性能。

    arXiv:2403.01999v1 Announce Type: new  Abstract: Dense Retrieval (DR) is now considered as a promising tool to enhance the memorization capacity of Large Language Models (LLM) such as GPT3 and GPT-4 by incorporating external memories. However, due to the paradigm discrepancy between text generation of LLM and DR, it is still an open challenge to integrate the retrieval and generation tasks in a shared LLM. In this paper, we propose an efficient LLM-Oriented Retrieval Tuner, namely LMORT, which decouples DR capacity from base LLM and non-invasively coordinates the optimally aligned and uniform layers of the LLM towards a unified DR space, achieving an efficient and effective DR without tuning the LLM itself. The extensive experiments on six BEIR datasets show that our approach could achieve competitive zero-shot retrieval performance compared to a range of strong DR models while maintaining the generation ability of LLM.
    
[^26]: 香草变压器是迁移能力教师

    Vanilla Transformers are Transfer Capability Teachers

    [https://arxiv.org/abs/2403.01994](https://arxiv.org/abs/2403.01994)

    混合专家（MoE）变压器在模型预训练性能和传输能力方面表现不如香草变压器，为此提出了迁移能力蒸馏的概念，指出香草模型是迁移能力的有效教师，指导MoE模型实现预训练性能和传输能力的结合。

    

    最近，由于在模型容量和计算效率方面的优势，混合专家（MoE）变压器引起了越来越多的关注。然而，研究表明，在许多下游任务中，MoE变压器的表现不及香草变压器，这显著降低了MoE模型的实用价值。为了解释这个问题，我们提出模型的预训练性能和迁移能力是影响其下游任务性能的联合决定因素。与香草模型相比，MoE模型的迁移能力较差，导致它们在下游任务中表现不佳。为了解决这个问题，我们引入了迁移能力蒸馏的概念，认为虽然香草模型性能较弱，但它们是迁移能力的有效教师。由香草模型指导的MoE模型可以实现强大的预训练性能和迁移能力，最终

    arXiv:2403.01994v1 Announce Type: new  Abstract: Recently, Mixture of Experts (MoE) Transformers have garnered increasing attention due to their advantages in model capacity and computational efficiency. However, studies have indicated that MoE Transformers underperform vanilla Transformers in many downstream tasks, significantly diminishing the practical value of MoE models. To explain this issue, we propose that the pre-training performance and transfer capability of a model are joint determinants of its downstream task performance. MoE models, in comparison to vanilla models, have poorer transfer capability, leading to their subpar performance in downstream tasks. To address this issue, we introduce the concept of transfer capability distillation, positing that although vanilla models have weaker performance, they are effective teachers of transfer capability. The MoE models guided by vanilla models can achieve both strong pre-training performance and transfer capability, ultimately
    
[^27]: FakeNewsGPT4：通过知识增强的LVLMs推进多模态假新闻检测

    FakeNewsGPT4: Advancing Multimodal Fake News Detection through Knowledge-Augmented LVLMs

    [https://arxiv.org/abs/2403.01988](https://arxiv.org/abs/2403.01988)

    FakeNewsGPT4是一个新颖框架，通过增加特定于伪造的知识，提升了LVLMs在多模态假新闻检测中的效果。

    

    大规模生成的多模态假新闻存在实质性的分布差异，促使需要广义检测器。然而，训练在特定领域内的孤立性限制了传统检测器获得开放世界事实的能力。本文提出了FakeNewsGPT4，这是一个新颖的框架，通过增添特定于伪造的知识来增强大规模视觉-语言模型（LVLMs）进行操纵推理，同时继承丰富的世界知识作为补充。FakeNewsGPT4中的知识增强涉及获取两种伪造特定知识，即语义相关和工件追踪，将它们合并到LVLMs中。

    arXiv:2403.01988v1 Announce Type: new  Abstract: The massive generation of multimodal fake news exhibits substantial distribution discrepancies, prompting the need for generalized detectors. However, the insulated nature of training within specific domains restricts the capability of classical detectors to obtain open-world facts. In this paper, we propose FakeNewsGPT4, a novel framework that augments Large Vision-Language Models (LVLMs) with forgery-specific knowledge for manipulation reasoning while inheriting extensive world knowledge as complementary. Knowledge augmentation in FakeNewsGPT4 involves acquiring two types of forgery-specific knowledge, i.e., semantic correlation and artifact trace, and merging them into LVLMs. Specifically, we design a multi-level cross-modal reasoning module that establishes interactions across modalities for extracting semantic correlations. Concurrently, a dual-branch fine-grained verification module is presented to comprehend localized details to e
    
[^28]: 低资源语言的变压器：Is F\'eidir Linn！

    Transformers for Low-Resource Languages:Is F\'eidir Linn!

    [https://arxiv.org/abs/2403.01985](https://arxiv.org/abs/2403.01985)

    本研究评估了对低资源的英语-爱尔兰语语言对进行超参数优化的 Transformer 模型，发现正确选择子词模型是翻译性能的最大驱动因素。

    

    Transformer 模型是机器翻译领域的最先进技术。然而，一般来说，神经翻译模型在训练数据不足的语言对上常常表现不佳。因此，对于低资源语言对，使用该结构进行实验的研究相对较少。本研究评估了将变压器模型进行超参数优化以翻译低资源的英语-爱尔兰语语言对。我们展示了选择适当的参数会带来相当大的性能提升。最重要的是，正确选择子词模型被证明是翻译性能最大的驱动因素。评估了使用 unigram 和 BPE 方法的 SentencePiece 模型。对模型架构的变化包括修改层数、测试各种正则化技术以及评估用于注意力的最佳头数。

    arXiv:2403.01985v1 Announce Type: cross  Abstract: The Transformer model is the state-of-the-art in Machine Translation. However, in general, neural translation models often under perform on language pairs with insufficient training data. As a consequence, relatively few experiments have been carried out using this architecture on low-resource language pairs. In this study, hyperparameter optimization of Transformer models in translating the low-resource English-Irish language pair is evaluated. We demonstrate that choosing appropriate parameters leads to considerable performance improvements. Most importantly, the correct choice of subword model is shown to be the biggest driver of translation performance. SentencePiece models using both unigram and BPE approaches were appraised. Variations on model architectures included modifying the number of layers, testing various regularisation techniques and evaluating the optimal number of heads for attention. A generic 55k DGT corpus and an i
    
[^29]: 中央库尔德语种的语言和语音技术

    Language and Speech Technology for Central Kurdish Varieties

    [https://arxiv.org/abs/2403.01983](https://arxiv.org/abs/2403.01983)

    本文针对中央库尔德语种开发语言和语音技术，通过电影和电视剧的转录创建语料库，并评估了机器翻译、自动语音识别和语言识别的性能。

    

    库尔德语是一种印欧语言，拥有超过3000万的使用者，被认为是一个方言连续体，以其多样性的语言变体而闻名。先前的研究将库尔德语的语言和语音技术视为宏语言进行处理，导致方言和变体之间存在资源和工具相对匮乏的差异。本文致力于为中央库尔德语种开发语言和语音技术资源迈出一步，通过记录电影和电视剧的转录作为野外工作的替代方式来创建语料库。此外，我们报告了在中央库尔德语种上评估的机器翻译、自动语音识别和语言识别性能作为下游任务。数据和模型已在https://github.com/sinaahmadi/CORDI以开放许可证公开提供。

    arXiv:2403.01983v1 Announce Type: new  Abstract: Kurdish, an Indo-European language spoken by over 30 million speakers, is considered a dialect continuum and known for its diversity in language varieties. Previous studies addressing language and speech technology for Kurdish handle it in a monolithic way as a macro-language, resulting in disparities for dialects and varieties for which there are few resources and tools available. In this paper, we take a step towards developing resources for language and speech technology for varieties of Central Kurdish, creating a corpus by transcribing movies and TV series as an alternative to fieldwork. Additionally, we report the performance of machine translation, automatic speech recognition, and language identification as downstream tasks evaluated on Central Kurdish varieties. Data and models are publicly available under an open license at https://github.com/sinaahmadi/CORDI.
    
[^30]: SciAssess：基准测试LLM在科学文献分析中的熟练程度

    SciAssess: Benchmarking LLM Proficiency in Scientific Literature Analysis

    [https://arxiv.org/abs/2403.01976](https://arxiv.org/abs/2403.01976)

    SciAssess介绍了一个专为深度分析科学文献而设计的基准测试，旨在全面评估LLMs在科学领域记忆、理解和分析能力的有效性。

    

    arXiv:2403.01976v1 公告类型：新 抽象：大型语言模型（LLMs）的最新突破已经彻底改变了自然语言理解和生成，引发了人们对利用这些技术进行细致科学文献分析的兴趣激增。然而，现有的基准测试未能充分评估LLMs在科学领域的熟练程度，特别是在涉及复杂理解和多模态数据的情况下。为此，我们引入了SciAssess，一个专为深度分析科学文献而设计的基准测试，旨在全面评估LLMs的有效性。SciAssess专注于评估LLMs在科学背景下记忆、理解和分析的能力。它包括来自不同科学领域的代表性任务，如一般化学、有机材料和合金材料。严格的质量控制措施确保了其在正确性、匿名化和复制方面的可靠性。

    arXiv:2403.01976v1 Announce Type: new  Abstract: Recent breakthroughs in Large Language Models (LLMs) have revolutionized natural language understanding and generation, igniting a surge of interest in leveraging these technologies for the nuanced field of scientific literature analysis. Existing benchmarks, however, inadequately evaluate the proficiency of LLMs in the scientific domain, especially in scenarios involving complex comprehension and multimodal data. In response, we introduced SciAssess, a benchmark tailored for the in-depth analysis of scientific literature, crafted to provide a thorough assessment of LLMs' efficacy. SciAssess focuses on evaluating LLMs' abilities in memorization, comprehension, and analysis within scientific contexts. It includes representative tasks from diverse scientific fields, such as general chemistry, organic materials, and alloy materials. And rigorous quality control measures ensure its reliability in terms of correctness, anonymization, and copy
    
[^31]: 利用大型语言模型多角度改进知识图谱补全

    Multi-perspective Improvement of Knowledge Graph Completion with Large Language Models

    [https://arxiv.org/abs/2403.01972](https://arxiv.org/abs/2403.01972)

    提出了MPIKGC框架，通过从多个角度利用大型语言模型来改善知识图谱补全，扩展实体描述、理解关系和提取结构，弥补了结构不完整和文本质量限制带来的问题

    

    知识图谱补全（KGC）是一种广泛使用的方法，可以通过为缺失的链接进行预测来解决知识图谱（KGs）的不完整性。基于描述的KGC利用预训练的语言模型学习实体和关系的表示形式，呈现出令人期待的结果。然而，基于描述的KGC的性能仍然受文本质量和不完整结构的限制，因为它缺乏足够的实体描述，并且仅依赖于关系名称，导致结果次优。为了解决这个问题，我们提出了MPIKGC，这是一个通用框架，通过从各种角度查询大型语言模型（LLMs）来补偿上下文化知识的不足，从而提高KGC，其中涉及利用LLMs的推理、解释和总结能力来扩展实体描述，理解关系和提取结构。

    arXiv:2403.01972v1 Announce Type: new  Abstract: Knowledge graph completion (KGC) is a widely used method to tackle incompleteness in knowledge graphs (KGs) by making predictions for missing links. Description-based KGC leverages pre-trained language models to learn entity and relation representations with their names or descriptions, which shows promising results. However, the performance of description-based KGC is still limited by the quality of text and the incomplete structure, as it lacks sufficient entity descriptions and relies solely on relation names, leading to sub-optimal results. To address this issue, we propose MPIKGC, a general framework to compensate for the deficiency of contextualized knowledge and improve KGC by querying large language models (LLMs) from various perspectives, which involves leveraging the reasoning, explanation, and summarization capabilities of LLMs to expand entity descriptions, understand relations, and extract structures, respectively. We conduc
    
[^32]: AS-ES学习：小型模型中高效CoT学习研究

    AS-ES Learning: Towards Efficient CoT Learning in Small Models

    [https://arxiv.org/abs/2403.01969](https://arxiv.org/abs/2403.01969)

    AS-ES学习提出了一种新的训练范式，通过高效利用现有CoT数据来实现在小型模型中的高效迭代生成，超越了直接seq2seq训练，在CoT丰富任务上取得了显著表现。

    

    Chain-of-Thought（CoT）在LLM中是一种关键的新型能力，特别在逻辑推理方面尤为重要。为了在小型模型中引入这种能力，人们尝试通过从大型语言模型（LLMs）生成的CoT数据中提取信息。然而，现有方法往往只是简单地从LLMs生成更多数据并将其加以利用，而忽视了高效利用现有CoT数据的重要性。我们在这里提出了一种新的训练范式AS-ES（抽象片段 - 提取性片段）学习，该方法利用CoT中的固有信息进行迭代生成。实验证明，我们的方法在类似MWP和PET摘要等CoT丰富任务上超越了直接的seq2seq训练，而无需进行数据增强或修改模型本身。此外，我们探讨了小型模型在学习CoT方面效率低下的原因，并解释了为什么AS-ES学习有效，从而深入研究了CoT学习的原理。

    arXiv:2403.01969v1 Announce Type: new  Abstract: Chain-of-Thought (CoT) serves as a critical emerging ability in LLMs, especially when it comes to logical reasoning. Attempts have been made to induce such ability in small models as well by distilling from the data with CoT generated by Large Language Models (LLMs). However, existing methods often simply generate and incorporate more data from LLMs and fail to note the importance of efficiently utilizing existing CoT data. We here propose a new training paradigm AS-ES (Abstractive Segments - Extractive Segments) learning, which exploits the inherent information in CoT for iterative generation. Experiments show that our methods surpass the direct seq2seq training on CoT-extensive tasks like MWP and PET summarization, without data augmentation or altering the model itself. Furthermore, we explore the reason behind the inefficiency of small models in learning CoT and provide an explanation of why AS-ES learning works, giving insights into 
    
[^33]: DECIDERS：一种通过模仿双系统认知理论实现规则可控解码策略的语言生成方法

    DECIDER: A Rule-Controllable Decoding Strategy for Language Generation by Imitating Dual-System Cognitive Theory

    [https://arxiv.org/abs/2403.01954](https://arxiv.org/abs/2403.01954)

    DECIDER是一种受双系统认知理论启发的规则可控解码策略，通过在预训练语言模型中引入逻辑推理器，有效地遵循给定规则以引导生成方向朝向目标。

    

    词典约束解码方法旨在通过某些目标概念控制所生成文本的意义或风格。现有方法过于关注这些目标本身，导致缺乏关于如何实现这些目标的高层推理。然而，人类通常通过遵循某些规则来处理任务，这些规则不仅关注于目标本身，还关注于引发目标发生的语义相关概念。在这项工作中，我们提出了DECIDER，这是一种受到双系统认知理论启发的约束语言生成的规则可控解码策略。具体而言，在DECIDER中，一个预训练语言模型（PLM）配备了一个逻辑推理器，以高层规则作为输入。然后，DECIDER允许规则信号在每个解码步骤中流入PLM。广泛的实验结果表明，DECIDER能够有效地遵循给定的规则，引导生成方向朝向目标进行生成。

    arXiv:2403.01954v1 Announce Type: cross  Abstract: Lexicon-based constrained decoding approaches aim to control the meaning or style of the generated text through certain target concepts. Existing approaches over-focus the targets themselves, leading to a lack of high-level reasoning about how to achieve them. However, human usually tackles tasks by following certain rules that not only focuses on the targets but also on semantically relevant concepts that induce the occurrence of targets. In this work, we present DECIDER, a rule-controllable decoding strategy for constrained language generation inspired by dual-system cognitive theory. Specifically, in DECIDER, a pre-trained language model (PLM) is equiped with a logic reasoner that takes high-level rules as input. Then, the DECIDER allows rule signals to flow into the PLM at each decoding step. Extensive experimental results demonstrate that DECIDER can effectively follow given rules to guide generation direction toward the targets i
    
[^34]: VariErr NLI: 将注释错误与人类标签变化区分开来

    VariErr NLI: Separating Annotation Error from Human Label Variation

    [https://arxiv.org/abs/2403.01931](https://arxiv.org/abs/2403.01931)

    该研究提出了一个新的方法和数据集VariErr，专注于NLI任务中的注释错误和人类标签变化的区分。研究填补了在处理信号非黑白情况下的先前空白。

    

    人类标签变化是由于注释者出于有效原因将不同标签分配给同一项而产生的，而注释错误是指由于无效原因分配标签。这两个问题在自然语言处理基准中普遍存在，但现有研究通常是孤立研究它们。据我们所知，以前没有专注于区分错误与信号的先前工作，特别是在信号超越黑白之处。为了填补这一空白，我们介绍了一种系统方法和一个新数据集VariErr（变异与错误），重点关注英语NLI任务。我们提出了一个包含两轮注释方案的方法，注释者解释每个标签，然后判断标签解释对的有效性。VariErr包含对500个重新注释的NLI项目上的1,933个解释进行的7,574个有效性判断。我们评估了各种自动错误检测（AED）方法和GPT在揭示错误与信号之间的有效性。

    arXiv:2403.01931v1 Announce Type: new  Abstract: Human label variation arises when annotators assign different labels to the same item for valid reasons, while annotation errors occur when labels are assigned for invalid reasons. These two issues are prevalent in NLP benchmarks, yet existing research has studied them in isolation. To the best of our knowledge, there exists no prior work that focuses on teasing apart error from signal, especially in cases where signal is beyond black-and-white. To fill this gap, we introduce a systematic methodology and a new dataset, VariErr (variation versus error), focusing on the NLI task in English. We propose a 2-round annotation scheme with annotators explaining each label and subsequently judging the validity of label-explanation pairs. \name{} contains 7,574 validity judgments on 1,933 explanations for 500 re-annotated NLI items. We assess the effectiveness of various automatic error detection (AED) methods and GPTs in uncovering errors versus 
    
[^35]: 分析和调整大型语言模型以用于少样本多语言自然语言理解：我们到达了吗？

    Analyzing and Adapting Large Language Models for Few-Shot Multilingual NLU: Are We There Yet?

    [https://arxiv.org/abs/2403.01929](https://arxiv.org/abs/2403.01929)

    本研究对监督微调、监督指导调整和上下文学习三种方法进行了广泛比较，发现监督指导调整在性能和资源之间具有最佳的平衡。

    

    监督微调（SFT）、监督指导调整（SIT）和上下文学习（ICL）是三种少样本学习的替代且实际标准方法。ICL由于其简单性和样本效率，最近由于LLM的出现而变得流行。先前的研究仅对这些方法如何用于多语种少样本学习进行了有限的调查，到目前为止，重点主要都是它们的性能。在这项工作中，我们对这三种方法进行了广泛而系统的比较，将它们应用于6种高资源和低资源语言、三种不同的自然语言理解任务以及多种语言和领域设置。重要的是，性能只是比较的一个方面，我们还通过计算成本、推理成本和财务成本的视角来分析这些方法。我们的观察表明，监督指导调整在性能和资源之间具有最佳的平衡。

    arXiv:2403.01929v1 Announce Type: new  Abstract: Supervised fine-tuning (SFT), supervised instruction tuning (SIT) and in-context learning (ICL) are three alternative, de facto standard approaches to few-shot learning. ICL has gained popularity recently with the advent of LLMs due to its simplicity and sample efficiency. Prior research has conducted only limited investigation into how these approaches work for multilingual few-shot learning, and the focus so far has been mostly on their performance. In this work, we present an extensive and systematic comparison of the three approaches, testing them on 6 high- and low-resource languages, three different NLU tasks, and a myriad of language and domain setups. Importantly, performance is only one aspect of the comparison, where we also analyse the approaches through the optics of their computational, inference and financial costs. Our observations show that supervised instruction tuning has the best trade-off between performance and resou
    
[^36]: IndicVoices: 努力建立一个面向印度语言的包容性多语音数据集

    IndicVoices: Towards building an Inclusive Multilingual Speech Dataset for Indian Languages

    [https://arxiv.org/abs/2403.01926](https://arxiv.org/abs/2403.01926)

    IndicVoices致力于建立包容性和代表性的多语音数据集，通过开源数据收集蓝图，提供了全面的起步工具。

    

    我们提出了INDICVOICES，一个包含来自145个印度地区和22种语言的16237名发言者的自然和自发语音的数据集，总计7348小时，其中阅读音频占9％，即兴演讲音频占74％，对话音频占17％。在这7348小时中，已经有1639小时被转录，每种语言的中位数为73小时。通过这篇论文，我们分享了捕捉印度文化、语言和人口多样性的经历，以创建一种独特且具代表性的数据集。具体而言，我们分享了一个开源数据收集蓝图，其中包括标准化协议、集中工具、引人入胜的问题、提示和涵盖多个领域和主题的对话情景的存储库，质量控制机制，全面的转录指南和转录工具。

    arXiv:2403.01926v1 Announce Type: new  Abstract: We present INDICVOICES, a dataset of natural and spontaneous speech containing a total of 7348 hours of read (9%), extempore (74%) and conversational (17%) audio from 16237 speakers covering 145 Indian districts and 22 languages. Of these 7348 hours, 1639 hours have already been transcribed, with a median of 73 hours per language. Through this paper, we share our journey of capturing the cultural, linguistic and demographic diversity of India to create a one-of-its-kind inclusive and representative dataset. More specifically, we share an open-source blueprint for data collection at scale comprising of standardised protocols, centralised tools, a repository of engaging questions, prompts and conversation scenarios spanning multiple domains and topics of interest, quality control mechanisms, comprehensive transcription guidelines and transcription tools. We hope that this open source blueprint will serve as a comprehensive starter kit for 
    
[^37]: 生成还是检索？关于人工环境在医学开放域问答效果的研究

    To Generate or to Retrieve? On the Effectiveness of Artificial Contexts for Medical Open-Domain Question Answering

    [https://arxiv.org/abs/2403.01924](https://arxiv.org/abs/2403.01924)

    本文介绍了MedGENIE，这是医学领域多项选择问题回答的第一个生成后阅读框架。

    

    医学领域的开放域问答需要大量专业知识的支持。近期的努力致力于将知识与模型参数分离，对抗架构规模化，并允许在常见的低资源硬件上进行训练。检索然后阅读的范式已变得普遍，模型预测依赖于来自外部知识库（如PubMed、教科书和UMLS）的相关知识片段。另一条尚未得到充分探索但由于领域特定大型语言模型的出现变得可能的路径是通过提示构建人工环境。因此，“生成还是检索”成为了现代版的哈姆雷特困境。本文提出了MedGENIE，这是医学领域多项选择问答的生成然后阅读框架。我们在MedQA-USMLE、MedMCQA和MMLU上进行了广泛实验，从实践的角度出发，假设最大

    arXiv:2403.01924v1 Announce Type: cross  Abstract: Medical open-domain question answering demands substantial access to specialized knowledge. Recent efforts have sought to decouple knowledge from model parameters, counteracting architectural scaling and allowing for training on common low-resource hardware. The retrieve-then-read paradigm has become ubiquitous, with model predictions grounded on relevant knowledge pieces from external repositories such as PubMed, textbooks, and UMLS. An alternative path, still under-explored but made possible by the advent of domain-specific large language models, entails constructing artificial contexts through prompting. As a result, "to generate or to retrieve" is the modern equivalent of Hamlet's dilemma. This paper presents MedGENIE, the first generate-then-read framework for multiple-choice question answering in medicine. We conduct extensive experiments on MedQA-USMLE, MedMCQA, and MMLU, incorporating a practical perspective by assuming a maxim
    
[^38]: 阿拉伯文本情感分析：通过更广泛的主题分析强化人工调查

    Arabic Text Sentiment Analysis: Reinforcing Human-Performed Surveys with Wider Topic Analysis

    [https://arxiv.org/abs/2403.01921](https://arxiv.org/abs/2403.01921)

    该研究对阿拉伯文本情感分析进行了全面的深入分析和广泛研究，通过人工调查和机器学习技术强化了现有研究的主题和趋势。

    

    arXiv:2403.01921v1 公告类型：新 摘要：情感分析（SA）一直是一个繁荣的研究领域。然而，阿拉伯情感分析（ASA）的任务在研究领域中仍然少见。该研究提供了对现有ASA文本内容研究的首次深入和广泛分析，并确定了它们的共同主题、应用领域、方法、途径、使用的技术和算法。这项深入研究对2002年至2020年间发表的133篇英文ASA论文进行了手工分析，这些论文来自四个学术数据库（SAGE、IEEE、Springer、WILEY）和谷歌学术。广泛研究在2010年至2020年间使用现代自动机器学习技术，如主题建模和时间分析，对开放获取资源上的2297篇ASA出版物进行了强化，以强调之前研究所发现的主题和趋势。主要发现显示了ASA使用的不同方法：机器学习、基于词典的方法和混合方法。

    arXiv:2403.01921v1 Announce Type: new  Abstract: Sentiment analysis (SA) has been, and is still, a thriving research area. However, the task of Arabic sentiment analysis (ASA) is still underrepresented in the body of research. This study offers the first in-depth and in-breadth analysis of existing ASA studies of textual content and identifies their common themes, domains of application, methods, approaches, technologies and algorithms used. The in-depth study manually analyses 133 ASA papers published in the English language between 2002 and 2020 from four academic databases (SAGE, IEEE, Springer, WILEY) and from Google Scholar. The in-breadth study uses modern, automatic machine learning techniques, such as topic modelling and temporal analysis, on Open Access resources, to reinforce themes and trends identified by the prior study, on 2297 ASA publications between 2010-2020. The main findings show the different approaches used for ASA: machine learning, lexicon-based and hybrid appro
    
[^39]: 促进葡萄牙语的开放神经编码器生态系统与Albertina PT*家族

    Fostering the Ecosystem of Open Neural Encoders for Portuguese with Albertina PT* Family

    [https://arxiv.org/abs/2403.01897](https://arxiv.org/abs/2403.01897)

    本文为葡萄牙语的神经编码作出了贡献，扩展了大型语言模型生态系统，并发布了包括亿级参数 Albertina 和 Bertimbau 在内的开源编码器模型，进一步推进了葡萄牙语的神经编码器技术。

    

    为了促进葡萄牙语的神经编码，本文贡献了代表基础编码器模型，代表了一个仍然非常稀缺的针对该语言特别开发的大型语言模型生态系统的扩展，这些模型完全是开放的，即它们是开源的，并在一个开放许可下免费分发，可用于任何目的，包括研究和商业用途。与英语以外的大多数语言一样，葡萄牙语在这些基础语言资源方面资源匮乏，这里有首届拥有 9 亿个参数的 Albertina 和 3.35 亿个参数的 Bertimbau。在以这对模型为首次集合的基础上，我们介绍了最先进的开放式葡萄牙语编码器生态系统的扩展，其中包括一个拥有 15 亿参数的更大型、性能驱动的模型，以及一个拥有 1 亿参数的更小型、效率驱动的模型。在实现这一主要目标的同时，还得到了一些进一步的成果

    arXiv:2403.01897v1 Announce Type: new  Abstract: To foster the neural encoding of Portuguese, this paper contributes foundation encoder models that represent an expansion of the still very scarce ecosystem of large language models specifically developed for this language that are fully open, in the sense that they are open source and openly distributed for free under an open license for any purpose, thus including research and commercial usages. Like most languages other than English, Portuguese is low-resourced in terms of these foundational language resources, there being the inaugural 900 million parameter Albertina and 335 million Bertimbau. Taking this couple of models as an inaugural set, we present the extension of the ecosystem of state-of-the-art open encoders for Portuguese with a larger, top performance-driven model with 1.5 billion parameters, and a smaller, efficiency-driven model with 100 million parameters. While achieving this primary goal, further results that are rele
    
[^40]: FCDS: 将短语结构和依存句法融合到文档级关系抽取中

    FCDS: Fusing Constituency and Dependency Syntax into Document-Level Relation Extraction

    [https://arxiv.org/abs/2403.01886](https://arxiv.org/abs/2403.01886)

    本研究将短语结构和依存句法融合到文档级关系抽取中，有效利用了文档中的丰富语法信息。

    

    文档级关系抽取（DocRE）旨在识别单个文档内实体之间的关系标签。本文提出将短语结构和依存句法融合到DocRE中，利用短语结构聚合整个句子信息并选择目标对的指导性句子，利用依存句法在图结构中进行增强，并根据依存图选择实体对之间的路径。实验结果表明所提出的方法的有效性。

    arXiv:2403.01886v1 Announce Type: cross  Abstract: Document-level Relation Extraction (DocRE) aims to identify relation labels between entities within a single document. It requires handling several sentences and reasoning over them. State-of-the-art DocRE methods use a graph structure to connect entities across the document to capture dependency syntax information. However, this is insufficient to fully exploit the rich syntax information in the document. In this work, we propose to fuse constituency and dependency syntax into DocRE. It uses constituency syntax to aggregate the whole sentence information and select the instructive sentences for the pairs of targets. It exploits the dependency syntax in a graph structure with constituency syntax enhancement and chooses the path between entity pairs based on the dependency graph. The experimental results on datasets from various domains demonstrate the effectiveness of the proposed method. The code is publicly available at this url.
    
[^41]: 一种改进的传统中文基金模型评估套件

    An Improved Traditional Chinese Evaluation Suite for Foundation Model

    [https://arxiv.org/abs/2403.01858](https://arxiv.org/abs/2403.01858)

    TMMLU+是传统中文大规模多任务语言理解数据集的改进版本，规模是前者的六倍，包含66个多样化主题。研究显示传统中文模型仍然落后于简体中文模型，并且目前的大语言模型在平均得分上尚未超过人类表现。

    

    我们提出了TMMLU+，这是一个为传统中文大规模多任务语言理解数据集设计的综合数据集。 TMMLU+是一个包含66个从基础到专业水平的选择题答题数据集。与其前身TMMLU相比，TMMLU+的规模大六倍，主题分布更加平衡。我们在TMMLU+中包含了来自闭源模型以及24个参数范围从1.8B到72B的开源中文大语言模型的基准结果。我们的研究发现传统中文模型仍然落后于简体中文对应模型。此外，目前的大语言模型在平均分数上仍未超过人类表现。我们公开发布了数据集及相应的基准源代码。

    arXiv:2403.01858v1 Announce Type: new  Abstract: We present TMMLU+, a comprehensive dataset designed for the Traditional Chinese massive multitask language understanding dataset. TMMLU+ is a multiple-choice question-answering dataset with 66 subjects from elementary to professional level. Compared to its predecessor, TMMLU, TMMLU+ is six times larger and boasts a more balanced subject distribution. We included benchmark results in TMMLU+ from closed-source models and 24 open-weight Chinese large language models of parameters ranging from 1.8B to 72B. Our findings reveal that Traditional Chinese models still trail behind their Simplified Chinese counterparts. Additionally, current large language models have yet to outperform human performance in average scores. We publicly release our dataset and the corresponding benchmark source code.
    
[^42]: 重新思考LLM语言适应性：以中文Mixtral为例

    Rethinking LLM Language Adaptation: A Case Study on Chinese Mixtral

    [https://arxiv.org/abs/2403.01851](https://arxiv.org/abs/2403.01851)

    本文以中文Mixtral为案例，提出了改进的中文语言能力的Mixtral模型，并讨论了在大型语言模型进行语言适应时的关键问题。

    

    Mixtral是一种代表性的稀疏专家混合(SMoE)语言模型，由于其独特的模型设计和卓越的性能而受到广泛关注。本文以Mixtral-8x7B-v0.1为基础，提出了改进的中文-Mixtral和中文-Mixtral-Instruct，通过进一步的预训练和指导微调提高了中文语言能力。实验结果表明，我们的中文-Mixtral和中文-Mixtral-Instruct成功提升了中文理解和生成性能，同时保留了原始的英文能力。然后，我们讨论了在大型语言模型进行语言适应时的一些关键问题，包括扩展语言特定词汇的必要性以及初始化模型的选择（基础模型vs.指导模型），通过提供实证结果和分析。我们还呈现了每个专家的可视化结果以检验其重要性。

    arXiv:2403.01851v1 Announce Type: cross  Abstract: Mixtral, a representative sparse mixture of experts (SMoE) language model, has received significant attention due to its unique model design and superior performance. Based on Mixtral-8x7B-v0.1, in this paper, we propose Chinese-Mixtral and Chinese-Mixtral-Instruct with improved Chinese language abilities by adopting further pre-training and instruction fine-tuning. Experimental results show that our Chinese-Mixtral and Chinese-Mixtral-Instruct successfully improve Chinese understanding and generation performance while retaining the original English abilities. Then, we discuss several key questions when performing language adaptation on large language models, including the necessity of extending the language-specific vocabulary and the choice of the initialization model (foundation model v.s. instruction model), by providing empirical results and analysis. We also present the visualizations of each expert to examine their importance on
    
[^43]: CET2：建模主题转换以实现连贯和引人入胜的基于知识的对话

    CET2: Modelling Topic Transitions for Coherent and Engaging Knowledge-Grounded Conversations

    [https://arxiv.org/abs/2403.01848](https://arxiv.org/abs/2403.01848)

    CET2框架旨在通过建模主题转换选择与对话上下文连贯的知识，为知识驱动的对话系统生成连贯和引人入胜的回复。

    

    知识驱动的对话系统旨在根据对话上下文和选择的外部知识生成连贯和引人入胜的回复。为了解决先前知识选择方法过于依赖对话上下文或过分强调所选知识中的新信息的问题，导致选择重复或不连贯的知识，进而生成重复或不连贯的回复，我们引入了一种Coherent and Engaging Topic Transition（CET2）框架，用于模拟主题转换以选择恰当与对话上下文连贯的知识，并为主题发展提供足够的知识多样性。我们的CET2框架考虑了知识选择的多个因素，包括从对话上下文到下一个主题的有效转换逻辑以及系统性比较。

    arXiv:2403.01848v1 Announce Type: new  Abstract: Knowledge-grounded dialogue systems aim to generate coherent and engaging responses based on the dialogue contexts and selected external knowledge. Previous knowledge selection methods tend to rely too heavily on the dialogue contexts or over-emphasize the new information in the selected knowledge, resulting in the selection of repetitious or incongruous knowledge and further generating repetitive or incoherent responses, as the generation of the response depends on the chosen knowledge. To address these shortcomings, we introduce a Coherent and Engaging Topic Transition (CET2) framework to model topic transitions for selecting knowledge that is coherent to the context of the conversations while providing adequate knowledge diversity for topic development. Our CET2 framework considers multiple factors for knowledge selection, including valid transition logic from dialogue contexts to the following topics and systematic comparisons betwee
    
[^44]: 在表格预测上优化预训练语言模型的方法

    Making Pre-trained Language Models Great on Tabular Prediction

    [https://arxiv.org/abs/2403.01841](https://arxiv.org/abs/2403.01841)

    提出了一种专门为表格数据预测而预训练的语言模型TP-BERTa，通过新颖的相对大小标记化方法和内部特征关注方法解决了预训练语言模型在数值特征值上的不兼容性问题

    

    深度神经网络（DNN）的可迁移性在图像和语言处理领域取得了显著进展。然而，由于表格之间的异质性，这种DNN的优势在表格数据预测（例如回归或分类任务）上仍未得到充分利用。本文提出了TP-BERTa，这是一种专门为表格数据预测而预训练的语言模型。具体而言，一种新颖的相对大小标记化方法将标量数值特征值转换为离散度高、高维度的标记，并且一种内部特征关注方法整合了特征名称和数值特征值。

    arXiv:2403.01841v1 Announce Type: new  Abstract: The transferability of deep neural networks (DNNs) has made significant progress in image and language processing. However, due to the heterogeneity among tables, such DNN bonus is still far from being well exploited on tabular data prediction (e.g., regression or classification tasks). Condensing knowledge from diverse domains, language models (LMs) possess the capability to comprehend feature names from various tables, potentially serving as versatile learners in transferring knowledge across distinct tables and diverse prediction tasks, but their discrete text representation space is inherently incompatible with numerical feature values in tables. In this paper, we present TP-BERTa, a specifically pre-trained LM model for tabular data prediction. Concretely, a novel relative magnitude tokenization converts scalar numerical feature values to finely discrete, high-dimensional tokens, and an intra-feature attention approach integrates fe
    
[^45]: 基于模型的数据中心人工智能：弥合学术理想与工业实用之间的鸿沟

    Model-Based Data-Centric AI: Bridging the Divide Between Academic Ideals and Industrial Pragmatism

    [https://arxiv.org/abs/2403.01832](https://arxiv.org/abs/2403.01832)

    本文提出了一种新的模型-Based Data-Centric AI 范式，旨在解决学术界数据质量和工业应用之间的差异，并提出了整合模型考虑到数据优化过程中的策略。

    

    本文探讨了学术和工业领域内数据的对比角色，突出了数据中心人工智能和模型无关人工智能方法之间的分歧。我们认为，数据中心人工智能侧重于高质量数据对模型性能的首要性，而模型无关人工智能则优先考虑算法灵活性，往往以牺牲数据质量考虑为代价。这种区别显示，学术界对数据质量的标准往往不能满足工业应用的严格要求，从而导致在实际环境中部署学术模型的潜在问题。通过全面分析，我们解决了这些差异，提出了它们带来的挑战以及弥合差距的策略。此外，我们提出了一种新范式：基于模型的数据中心人工智能，旨在通过将模型考虑融入数据优化过程来调和这些差异。这种方法

    arXiv:2403.01832v1 Announce Type: new  Abstract: This paper delves into the contrasting roles of data within academic and industrial spheres, highlighting the divergence between Data-Centric AI and Model-Agnostic AI approaches. We argue that while Data-Centric AI focuses on the primacy of high-quality data for model performance, Model-Agnostic AI prioritizes algorithmic flexibility, often at the expense of data quality considerations. This distinction reveals that academic standards for data quality frequently do not meet the rigorous demands of industrial applications, leading to potential pitfalls in deploying academic models in real-world settings. Through a comprehensive analysis, we address these disparities, presenting both the challenges they pose and strategies for bridging the gap. Furthermore, we propose a novel paradigm: Model-Based Data-Centric AI, which aims to reconcile these differences by integrating model considerations into data optimization processes. This approach u
    
[^46]: NusaBERT：教授IndoBERT成为一种多语种和多文化的模型

    NusaBERT: Teaching IndoBERT to be Multilingual and Multicultural

    [https://arxiv.org/abs/2403.01817](https://arxiv.org/abs/2403.01817)

    NusaBERT通过将印度尼西亚的多样化语料库与IndoBERT相结合，实现了在涉及多种语言的任务中 state-of-the-art 的性能表现，为未被充分代表的语言的自然语言理解研究铺平了道路。

    

    印度尼西亚的语言形态极其多样，包括700多种语言和方言，使其成为世界上语言最丰富的国家之一。这种多样性，加上广泛实践的代码切换和低资源区域语言的存在，为现代预训练语言模型提出了独特的挑战。为了应对这些挑战，我们开发了NusaBERT，通过扩展IndoBERT的词汇量并利用包括区域语言和方言在内的多样化多语种语料库。通过在各种基准测试中进行严格评估，NusaBERT在涉及印度尼西亚多种语言的任务中展现了最先进的性能，为未被充分代表的语言的未来自然语言理解研究铺平了道路。

    arXiv:2403.01817v1 Announce Type: new  Abstract: Indonesia's linguistic landscape is remarkably diverse, encompassing over 700 languages and dialects, making it one of the world's most linguistically rich nations. This diversity, coupled with the widespread practice of code-switching and the presence of low-resource regional languages, presents unique challenges for modern pre-trained language models. In response to these challenges, we developed NusaBERT, building upon IndoBERT by incorporating vocabulary expansion and leveraging a diverse multilingual corpus that includes regional languages and dialects. Through rigorous evaluation across a range of benchmarks, NusaBERT demonstrates state-of-the-art performance in tasks involving multiple languages of Indonesia, paving the way for future natural language understanding research for under-represented languages.
    
[^47]: 通过可解释的神经符号管道增强多领域自动简答题评分

    Enhancing Multi-Domain Automatic Short Answer Grading through an Explainable Neuro-Symbolic Pipeline

    [https://arxiv.org/abs/2403.01811](https://arxiv.org/abs/2403.01811)

    通过提出弱监督标注程序和基于合理化线索的神经符号模型，我们在多领域自动简答题评分方面取得了显著进展。

    

    使用具有解释性的推理来自动评分简答题，并使评分决定背后的推理可解释是当前变压器模型方法面临的挑战。在ASAG中，通过逻辑推理器探测合理化线索，已经展示出一种有前途的神经符号架构方向。然而，主要挑战之一是需要标注在学生回答中的合理化线索，这仅在少数ASAG数据集中存在。为了克服这一挑战，我们提出了（1）一种用于ASAG数据集中合理化线索的弱监督注释程序，以及（2）一种基于合理化线索的可解释ASAG的神经符号模型。与Short Answer Feedback数据集的最新技术相比，我们的方法在双语、多领域和多问题训练设置中将均方根误差提高了0.24到0.3。这一结果表明，我们的方法为生成高质量评分提供了一个有前途的方向。

    arXiv:2403.01811v1 Announce Type: new  Abstract: Grading short answer questions automatically with interpretable reasoning behind the grading decision is a challenging goal for current transformer approaches. Justification cue detection, in combination with logical reasoners, has shown a promising direction for neuro-symbolic architectures in ASAG. But, one of the main challenges is the requirement of annotated justification cues in the students' responses, which only exist for a few ASAG datasets. To overcome this challenge, we contribute (1) a weakly supervised annotation procedure for justification cues in ASAG datasets, and (2) a neuro-symbolic model for explainable ASAG based on justification cues. Our approach improves upon the RMSE by 0.24 to 0.3 compared to the state-of-the-art on the Short Answer Feedback dataset in a bilingual, multi-domain, and multi-question training setup. This result shows that our approach provides a promising direction for generating high-quality grades
    
[^48]: NPHardEval4V: 多模态大型语言模型的动态推理基准

    NPHardEval4V: A Dynamic Reasoning Benchmark of Multimodal Large Language Models

    [https://arxiv.org/abs/2403.01777](https://arxiv.org/abs/2403.01777)

    这项研究介绍了一个旨在评估多模态大型语言模型推理能力的动态基准NPHardEval4V，发现在推理能力方面不同模型存在显著差异，并揭示了相对于LLMs，MLLMs的推理性能较弱。

    

    理解多模态大型语言模型（MLLMs）的推理能力是一个重要的研究领域。在这项研究中，我们引入了一个动态基准，NPHardEval4V，旨在解决评估MLLM纯粹推理能力方面的现有差距。我们的基准旨在提供一个平台，以解开诸多因素（如图像识别和指令遵循）对模型整体性能的影响，从而专注于评估它们的推理能力。我们的研究发现不同模型在推理能力方面存在显著差异，并突出了相较于LLMs，MLLMs在推理方面表现相对较弱。我们还研究了不同提示样式（包括视觉、文本和结合视觉与文本提示）对MLLM推理能力的影响，展示了多模态输入在模型性能中的不同影响。

    arXiv:2403.01777v1 Announce Type: new  Abstract: Understanding the reasoning capabilities of Multimodal Large Language Models (MLLMs) is an important area of research. In this study, we introduce a dynamic benchmark, NPHardEval4V, aimed at addressing the existing gaps in evaluating the pure reasoning abilities of MLLMs. Our benchmark aims to provide a venue to disentangle the effect of various factors such as image recognition and instruction following, from the overall performance of the models, allowing us to focus solely on evaluating their reasoning abilities. Our findings reveal significant discrepancies in reasoning abilities across different models and highlight the relatively weak performance of MLLMs compared to LLMs in terms of reasoning. We also investigate the impact of different prompting styles, including visual, text, and combined vision and text prompts, on the reasoning abilities of MLLMs, demonstrating the different impacts of multimodal inputs in model performance. U
    
[^49]: WebCiteS: 在中国网页搜索结果上进行带引文的查询焦点摘要

    WebCiteS: Attributed Query-Focused Summarization on Chinese Web Search Results with Citations

    [https://arxiv.org/abs/2403.01774](https://arxiv.org/abs/2403.01774)

    WebCiteS提出了一个带引文的查询焦点摘要任务，并发布了包含7k人工注释摘要及引文的中文数据集，以处理归因中存在的问题。

    

    arXiv:2403.01774v1 声明类型：新摘要：增强大型语言模型（LLMs）中的归因是一项关键任务。一个可行的方法是使LLMs能够引用支持其生成的外部来源。然而，该领域现有数据集和评估方法仍存在明显限制。在这项工作中，我们制定了带引文的查询焦点摘要（AQFS）任务，并提出了WebCiteS，这是一个包含7k人工注释摘要及引文的中文数据集。WebCiteS源自现实用户查询和网页搜索结果，为模型训练和评估提供了宝贵资源。之前关于归因评估的工作未能区分基于事实错误和引文错误。他们亦未能自动验证那些部分依赖多个来源的句子。我们通过开发详细的度量标准并使自动评估器能够将句子分解为子主张以解决这些问题。

    arXiv:2403.01774v1 Announce Type: new  Abstract: Enhancing the attribution in large language models (LLMs) is a crucial task. One feasible approach is to enable LLMs to cite external sources that support their generations. However, existing datasets and evaluation methods in this domain still exhibit notable limitations. In this work, we formulate the task of attributed query-focused summarization (AQFS) and present WebCiteS, a Chinese dataset featuring 7k human-annotated summaries with citations. WebCiteS derives from real-world user queries and web search results, offering a valuable resource for model training and evaluation. Prior works in attribution evaluation do not differentiate between groundedness errors and citation errors. They also fall short in automatically verifying sentences that draw partial support from multiple sources. We tackle these issues by developing detailed metrics and enabling the automatic evaluator to decompose the sentences into sub-claims for fine-grain
    
[^50]: KeNet:基于知识增强的文档-标签注意力网络用于多标签文本分类

    KeNet:Knowledge-enhanced Doc-Label Attention Network for Multi-label text classification

    [https://arxiv.org/abs/2403.01767](https://arxiv.org/abs/2403.01767)

    KeNet是一种基于知识增强的文档-标签注意力网络，用于解决多标签文本分类中的文档标签关系建立问题。

    

    arXiv:2403.01767v1 公告类型:新摘要:多标签文本分类（MLTC）是自然语言处理（NLP）领域中的一项基础任务，涉及将多个标签分配给给定文本。MLTC已经变得非常重要，并广泛应用于各个领域，如主题识别，推荐系统，情感分析和信息检索等。然而，传统的机器学习和深度神经网络尚未解决某些问题，例如，一些文档很简短但具有大量标签以及如何建立标签之间的关系。在MLTC领域，知识的重要性得到了证实是至关重要的。为了解决这个问题，我们提出了一种名为知识增强文档-标签注意力网络（KeNet）的新方法。具体地，我们设计了一个注意力网络，该网络整合了外部知识、标签嵌入和一个全面的…（文章摘要截至）

    arXiv:2403.01767v1 Announce Type: new  Abstract: Multi-Label Text Classification (MLTC) is a fundamental task in the field of Natural Language Processing (NLP) that involves the assignment of multiple labels to a given text. MLTC has gained significant importance and has been widely applied in various domains such as topic recognition, recommendation systems, sentiment analysis, and information retrieval. However, traditional machine learning and Deep neural network have not yet addressed certain issues, such as the fact that some documents are brief but have a large number of labels and how to establish relationships between the labels. It is imperative to additionally acknowledge that the significance of knowledge is substantiated in the realm of MLTC. To address this issue, we provide a novel approach known as Knowledge-enhanced Doc-Label Attention Network (KeNet). Specifically, we design an Attention Network that incorporates external knowledge, label embedding, and a comprehensive
    
[^51]: 多模态集成如何提升LLM在优化中的性能：以容量车辆路径问题为案例研究

    How Multimodal Integration Boost the Performance of LLM for Optimization: Case Study on Capacitated Vehicle Routing Problems

    [https://arxiv.org/abs/2403.01757](https://arxiv.org/abs/2403.01757)

    提出了一种使用多模态LLM进行优化的框架，能够更全面地理解优化问题，类似于人类认知过程，并且提供了更细致和有效的分析。

    

    最近，大型语言模型（LLMs）已明显地将它们定位为解决复杂优化挑战的工具。尽管被认可，现有基于LLM的优化方法的一个主要限制是，在仅依赖于数字文本提示时，尤其是在高维问题中，难以捕捉决策变量之间的关系。鉴于此，我们首先提出使用多模态LLM来增强优化性能，它能够处理文本和视觉提示，深入了解处理的优化问题。这种集成允许更全面地理解优化问题，类似于人类认知过程。我们开发了一个基于多模态LLM的优化框架，模拟人类解决问题的工作流程，从而提供更细致和有效的分析。该方法的有效性通过扩展进行评估。

    arXiv:2403.01757v1 Announce Type: new  Abstract: Recently, large language models (LLMs) have notably positioned them as capable tools for addressing complex optimization challenges. Despite this recognition, a predominant limitation of existing LLM-based optimization methods is their struggle to capture the relationships among decision variables when relying exclusively on numerical text prompts, especially in high-dimensional problems. Keeping this in mind, we first propose to enhance the optimization performance using multimodal LLM capable of processing both textual and visual prompts for deeper insights of the processed optimization problem. This integration allows for a more comprehensive understanding of optimization problems, akin to human cognitive processes. We have developed a multimodal LLM-based optimization framework that simulates human problem-solving workflows, thereby offering a more nuanced and effective analysis. The efficacy of this method is evaluated through exten
    
[^52]: 大型语言模型的低秩适应性无导数优化

    Derivative-Free Optimization for Low-Rank Adaptation in Large Language Models

    [https://arxiv.org/abs/2403.01754](https://arxiv.org/abs/2403.01754)

    本文将低秩模块添加到模型的每个自注意层中，并采用两种无导数优化方法交替优化这些低秩模块，相比现有基于梯度的参数调整方法，我们的方法在内存使用和收敛速度上显示出明显优势。

    

    LoRA等参数高效调整方法可以通过调整部分参数实现与模型调优性能相媲美，但仍需要大量计算资源，因为这一过程涉及计算梯度并在整个模型中执行反向传播。最近，许多工作致力于利用无导数优化方法，避免计算梯度，并展示在少样本设置中增强的鲁棒性。本文在模型的每个自注意力层前置低秩模块，并采用两种无导数优化方法交替优化每层的这些低秩模块。对各种任务和语言模型的广泛结果表明，我们提出的方法取得了实质性改进，并在内存使用和收敛速度上相比现有基于梯度的参数具有明显优势。

    arXiv:2403.01754v1 Announce Type: new  Abstract: Parameter-efficient tuning methods such as LoRA could achieve comparable performance to model tuning by tuning a small portion of the parameters. However, substantial computational resources are still required, as this process involves calculating gradients and performing back-propagation throughout the model. Much effort has recently been devoted to utilizing the derivative-free optimization method to eschew the computation of gradients and showcase an augmented level of robustness in few-shot settings. In this paper, we prepend the low-rank modules into each self-attention layer of the model and employ two derivative-free optimization methods to optimize these low-rank modules at each layer alternately. Extensive results on various tasks and language models demonstrate that our proposed method achieves substantial improvement and exhibits clear advantages in memory usage and convergence speed compared to existing gradient-based paramet
    
[^53]: 通过基础模型API生成差分隐私合成数据2：文本

    Differentially Private Synthetic Data via Foundation Model APIs 2: Text

    [https://arxiv.org/abs/2403.01749](https://arxiv.org/abs/2403.01749)

    通过基础模型API，我们提出了一种名为Aug-PE的增强PE算法，以产生差分隐私合成文本数据，为解决私有文本数据共享与隐私问题提供了一种前景和可扩展的解决方案。

    

    arXiv:2403.01749v1 公告类型：新 抽象：由于学习算法的出现，文本数据变得非常有价值。现实世界中产生的许多高质量文本数据是私密的，因此由于隐私问题无法自由共享或使用。生成具有形式隐私保证（即差分隐私（DP））的私密文本数据的合成副本提供了一种有前途且可扩展的解决方案。然而，现有方法需要在私有数据上对大型语言模型（LLM）进行DP微调，以生成DP合成数据。这种方法对于专有LLM（例如GPT-3.5）并不可行，而且对于开源LLM需要相当大的计算资源。Lin等人（2024）最近引入了私有进化（PE）算法，利用扩散模型只通过API访问生成DP合成图像。在这项工作中，我们提出了增强的PE算法，名为Aug-PE，适用于文本的复杂设置。

    arXiv:2403.01749v1 Announce Type: new  Abstract: Text data has become extremely valuable due to the emergence of machine learning algorithms that learn from it. A lot of high-quality text data generated in the real world is private and therefore cannot be shared or used freely due to privacy concerns. Generating synthetic replicas of private text data with a formal privacy guarantee, i.e., differential privacy (DP), offers a promising and scalable solution. However, existing methods necessitate DP finetuning of large language models (LLMs) on private data to generate DP synthetic data. This approach is not viable for proprietary LLMs (e.g., GPT-3.5) and also demands considerable computational resources for open-source LLMs. Lin et al. (2024) recently introduced the Private Evolution (PE) algorithm to generate DP synthetic images with only API access to diffusion models. In this work, we propose an augmented PE algorithm, named Aug-PE, that applies to the complex setting of text. We use
    
[^54]: 将神经信号解码为语音

    Decode Neural signal as Speech

    [https://arxiv.org/abs/2403.01748](https://arxiv.org/abs/2403.01748)

    本文在脑机接口领域探索了MEG信号的脑到文本转换，着重解决了以前主要集中在EEG上、使用“teacher-forcing”以及未完全自回归的问题。

    

    从脑动态解码语言是脑机接口（BCI）领域中一个重要的开放方向，尤其考虑到大型语言模型的快速增长。相对于需要电极植入手术的侵入性信号，非侵入性神经信号（如EEG、MEG）由于其安全性和普适性而越来越受到关注。然而，在三个方面的探索还不足：1）以前的方法主要集中在EEG上，但没有一个先前的研究解决了MEG信号质量更好的问题；2）以前的工作主要在生成解码过程中使用“teacher-forcing”，这是不切实际的；3）以前的工作大多是基于“BART”而不是完全自回归的，而在其他序列任务中表现更好。在本文中，我们探讨了MEG信号的脑到文本转换在语音解码形式中。我们是第一个在交叉注意力中研究的。

    arXiv:2403.01748v1 Announce Type: cross  Abstract: Decoding language from brain dynamics is an important open direction in the realm of brain-computer interface (BCI), especially considering the rapid growth of large language models. Compared to invasive-based signals which require electrode implantation surgery, non-invasive neural signals (e.g. EEG, MEG) have attracted increasing attention considering their safety and generality. However, the exploration is not adequate in three aspects: 1) previous methods mainly focus on EEG but none of the previous works address this problem on MEG with better signal quality; 2) prior works have predominantly used ``teacher-forcing" during generative decoding, which is impractical; 3) prior works are mostly ``BART-based" not fully auto-regressive, which performs better in other sequence tasks. In this paper, we explore the brain-to-text translation of MEG signals in a speech-decoding formation. Here we are the first to investigate a cross-attentio
    
[^55]: 朝向自包含答案的方向：会话搜索中基于实体的答案重写

    Towards Self-Contained Answers: Entity-Based Answer Rewriting in Conversational Search

    [https://arxiv.org/abs/2403.01747](https://arxiv.org/abs/2403.01747)

    本文针对会话搜索中的基于实体的答案重写，提出了两种答案重写策略，以改善用户体验。

    

    会话信息检索（CIS）是一种新兴的知识获取和探索性搜索范式。传统的网络搜索界面可以轻松探索实体，但在会话环境中受限于带宽有限的界面。本文探讨了在CIS中重写答案的方法，以便用户可以理解答案而无需求助外部服务或来源。具体而言，我们关注突出的实体--对于理解答案至关重要的实体。作为我们的第一个贡献，我们创建了一个带有突出实体注释的对话数据集。我们对收集到的数据进行分析后发现，大多数答案包含了突出实体。作为我们的第二个贡献，我们提出了两种旨在改善CIS中用户体验的答案重写策略。其一通过内联定义突出实体来扩展答案，使答案自包含。

    arXiv:2403.01747v1 Announce Type: cross  Abstract: Conversational information-seeking (CIS) is an emerging paradigm for knowledge acquisition and exploratory search. Traditional web search interfaces enable easy exploration of entities, but this is limited in conversational settings due to the limited-bandwidth interface. This paper explore ways to rewrite answers in CIS, so that users can understand them without having to resort to external services or sources. Specifically, we focus on salient entities -- entities that are central to understanding the answer. As our first contribution, we create a dataset of conversations annotated with entities for saliency. Our analysis of the collected data reveals that the majority of answers contain salient entities. As our second contribution, we propose two answer rewriting strategies aimed at improving the overall user experience in CIS. One approach expands answers with inline definitions of salient entities, making the answer self-contained
    
[^56]: Brilla AI: 全国科学与数学竞赛的人工智能参赛者

    Brilla AI: AI Contestant for the National Science and Maths Quiz

    [https://arxiv.org/abs/2403.01699](https://arxiv.org/abs/2403.01699)

    人工智能参赛者Brilla AI在全国科学与数学竞赛中表现优秀，为缺乏合格教师的非洲提供了学习支持。

    

    非洲大陆缺乏足够的合格教师，这阻碍了提供足够的学习支持。人工智能有可能增强有限数量教师的努力，从而带来更好的学习成果。本文描述并评估了NSMQ AI Grand Challenge的首要成果，该挑战提出了一个强大的现实基准，用于评估此类人工智能：“建立一个人工智能，参加加纳的全国科学与数学竞赛（NSMQ），并获胜——在比赛的所有轮次和阶段中表现优于最优秀的参赛者”。NSMQ是加纳的高中学生每年举行的现场科学与数学竞赛，3队2名学生通过回答生物学、化学、物理和数学问题在5轮比赛中竞争，逐渐晋级至最终冠军的队伍。在本研究中，我们建立了Brilla AI，一个参加NSMQ竞赛的人工智能选手。

    arXiv:2403.01699v1 Announce Type: cross  Abstract: The African continent lacks enough qualified teachers which hampers the provision of adequate learning support. An AI could potentially augment the efforts of the limited number of teachers, leading to better learning outcomes. Towards that end, this work describes and evaluates the first key output for the NSMQ AI Grand Challenge, which proposes a robust, real-world benchmark for such an AI: "Build an AI to compete live in Ghana's National Science and Maths Quiz (NSMQ) competition and win - performing better than the best contestants in all rounds and stages of the competition". The NSMQ is an annual live science and mathematics competition for senior secondary school students in Ghana in which 3 teams of 2 students compete by answering questions across biology, chemistry, physics, and math in 5 rounds over 5 progressive stages until a winning team is crowned for that year. In this work, we built Brilla AI, an AI contestant that we de
    
[^57]: 网页中的超文本实体提取

    Hypertext Entity Extraction in Webpage

    [https://arxiv.org/abs/2403.01698](https://arxiv.org/abs/2403.01698)

    提出了一个新的超文本实体提取数据集HEED和一个基于MoE的实体提取框架MoEEF，有效整合多个特征以提高模型性能。

    

    网页实体提取是研究和应用中的一项基本自然语言处理任务。然而，现今大多数网页实体提取模型都是在力求保留文本内容及其结构信息的结构化数据集上训练的。本文提出了一个名为HEED的超文本实体提取数据集，在电子商务领域收集了文本和相应的显式超文本特征，并进行了高质量手动实体注释。此外，我们提出了一个基于MoE的实体提取框架(MoEEF)，通过多专家混合有效地整合多个特征以提高模型性能，并胜过强基线模型。

    arXiv:2403.01698v1 Announce Type: cross  Abstract: Webpage entity extraction is a fundamental natural language processing task in both research and applications. Nowadays, the majority of webpage entity extraction models are trained on structured datasets which strive to retain textual content and its structure information. However, existing datasets all overlook the rich hypertext features (e.g., font color, font size) which show their effectiveness in previous works. To this end, we first collect a \textbf{H}ypertext \textbf{E}ntity \textbf{E}xtraction \textbf{D}ataset (\textit{HEED}) from the e-commerce domains, scraping both the text and the corresponding explicit hypertext features with high-quality manual entity annotations. Furthermore, we present the \textbf{Mo}E-based \textbf{E}ntity \textbf{E}xtraction \textbf{F}ramework (\textit{MoEEF}), which efficiently integrates multiple features to enhance model performance by Mixture of Experts and outperforms strong baselines, includi
    
[^58]: 您需要更好地关注付费

    You Need to Pay Better Attention

    [https://arxiv.org/abs/2403.01643](https://arxiv.org/abs/2403.01643)

    提出了三种新的注意力机制，在效率和学习能力方面优于标准的多头注意力，提高了Transformer模型的性能和更广泛的部署能力。

    

    我们引入了三种新的注意力机制，这些机制在效率和学习能力方面胜过标准的多头注意力，从而提高了Transformer模型的性能和更广泛的部署能力。我们的第一个贡献是优化注意力，其性能与标准注意力相似，但参数数量少了四分之三，每个头部少了一个矩阵乘法。接下来，我们引入了高效注意力，其性能与标准注意力相当，但参数数量减少了一半，每个头部减少了两个矩阵乘法，并且比标准注意力快两倍。最后，我们介绍了超级注意力，在视觉和自然语言处理任务中明显超越了标准注意力，同时具有更少的参数和矩阵乘法。除了提供严格的数学比较，我们在MN中评估了所提出的注意力机制

    arXiv:2403.01643v1 Announce Type: cross  Abstract: We introduce three new attention mechanisms that outperform standard multi-head attention in terms of efficiency and learning capabilities, thereby improving the performance and broader deployability of Transformer models. Our first contribution is Optimised Attention, which performs similarly to standard attention, but has 3/4 as many parameters and one matrix multiplication fewer per head. Next, we introduce Efficient Attention, which performs on par with standard attention with only 1/2 as many parameters as many parameters and two matrix multiplications fewer per head and is up to twice as fast as standard attention. Lastly, we introduce Super Attention, which surpasses standard attention by a significant margin in both vision and natural language processing tasks while having fewer parameters and matrix multiplications. In addition to providing rigorous mathematical comparisons, we evaluate the presented attention mechanisms on MN
    
[^59]: 通过文本分类进行多层产品类别预测

    Multi-level Product Category Prediction through Text Classification

    [https://arxiv.org/abs/2403.01638](https://arxiv.org/abs/2403.01638)

    本研究通过应用LSTM和BERT模型，以及数据增强和焦点损失技术，实现了在零售领域中准确预测多个产品类别的效果。

    

    本文研究了将先进的机器学习模型，特别是LSTM和BERT，应用于文本分类以预测零售领域中的多个类别。研究表明，应用数据增强技术和焦点损失函数可以显著提高使用牢固的巴西零售数据集将产品分类到多个类别的准确性。LSTM模型，丰富了巴西词嵌入，以及以其理解复杂上下文而闻名的BERT，被改编和优化用于此特定任务。

    arXiv:2403.01638v1 Announce Type: new  Abstract: This article investigates applying advanced machine learning models, specifically LSTM and BERT, for text classification to predict multiple categories in the retail sector. The study demonstrates how applying data augmentation techniques and the focal loss function can significantly enhance accuracy in classifying products into multiple categories using a robust Brazilian retail dataset. The LSTM model, enriched with Brazilian word embedding, and BERT, known for its effectiveness in understanding complex contexts, were adapted and optimized for this specific task. The results showed that the BERT model, with an F1 Macro Score of up to $99\%$ for segments, $96\%$ for categories and subcategories and $93\%$ for name products, outperformed LSTM in more detailed categories. However, LSTM also achieved high performance, especially after applying data augmentation and focal loss techniques. These results underscore the effectiveness of NLP te
    
[^60]: 朝着全面的越南语检索增强生成和大型语言模型迈进

    Towards Comprehensive Vietnamese Retrieval-Augmented Generation and Large Language Models

    [https://arxiv.org/abs/2403.01616](https://arxiv.org/abs/2403.01616)

    该论文旨在推动越南语言理解和生成方面的进展，通过开发和分享开放数据集和预训练模型，特别是针对越南语检索增强生成和大型语言模型。

    

    这篇论文通过开发和传播用于越南语检索增强生成（RAG）和大型语言模型（LLMs）的开放数据集和预训练模型，展示了我们在推动越南语言理解和生成水平方面的贡献。

    arXiv:2403.01616v1 Announce Type: new  Abstract: This paper presents our contributions towards advancing the state of Vietnamese language understanding and generation through the development and dissemination of open datasets and pre-trained models for Vietnamese Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs).
    
[^61]: SCHEMA: State CHangEs MAtter for Procedure Planning in Instructional Videos

    SCHEMA: State CHangEs MAtter for Procedure Planning in Instructional Videos

    [https://arxiv.org/abs/2403.01599](https://arxiv.org/abs/2403.01599)

    通过研究步骤和状态之间的因果关系，本文提出了SCHEMA方法，将每个步骤显式表示为状态变化，并追踪教学视频中的状态变化。

    

    我们研究了在教学视频中的程序规划问题，旨在给出根据部分视觉状态观察生成目标导向的动作步骤序列。这个问题的动机是为了学习一个结构化且可规划的状态和动作空间。我们指出，状态变化对于教学视频中的程序规划很重要，旨在通过研究步骤和状态之间的因果关系建立更为结构化的状态空间。具体地，我们将每个步骤显式地表示为状态变化，并跟踪程序中的状态变化。

    arXiv:2403.01599v1 Announce Type: cross  Abstract: We study the problem of procedure planning in instructional videos, which aims to make a goal-oriented sequence of action steps given partial visual state observations. The motivation of this problem is to learn a structured and plannable state and action space. Recent works succeeded in sequence modeling of steps with only sequence-level annotations accessible during training, which overlooked the roles of states in the procedures. In this work, we point out that State CHangEs MAtter (SCHEMA) for procedure planning in instructional videos. We aim to establish a more structured state space by investigating the causal relations between steps and states in procedures. Specifically, we explicitly represent each step as state changes and track the state changes in procedures. For step representation, we leveraged the commonsense knowledge in large language models (LLMs) to describe the state changes of steps via our designed chain-of-thoug
    
[^62]: 加强低资源语言的神经机器翻译：语料库开发、人类评估和可解释的 AI 架构

    Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures

    [https://arxiv.org/abs/2403.01580](https://arxiv.org/abs/2403.01580)

    本研究通过优化Transformer模型的超参数和子词模型类型，开发了适用于低资源语言对的神经机器翻译系统，并开发了gaHealth，首个针对爱尔兰语健康数据的双语语料库，取得了显著的翻译质量提升。

    

    在当前的机器翻译（MT）领域中，Transformer架构尤其在高资源语言对中脱颖而出。本研究探讨了它在包括英语$\leftrightarrow$爱尔兰语和英语$\leftrightarrow$马拉地语语言对中低资源语言对中的有效性。研究确定了最佳超参数和子词模型类型，显著改善了Transformer模型在低资源语言对中的翻译质量。针对低资源语言的平行数据集的稀缺性可能阻碍MT的发展。为解决这一问题，开发了gaHealth，这是爱尔兰语健康数据的第一个双语语料库。使用这一领域特定数据集开发的模型，在与LoResMT2021共享任务模型相比时，在BLEU评分上表现出非常显著的改进。随后的人类评估使用多维度评估指标进行。

    arXiv:2403.01580v1 Announce Type: cross  Abstract: In the current machine translation (MT) landscape, the Transformer architecture stands out as the gold standard, especially for high-resource language pairs. This research delves into its efficacy for low-resource language pairs including both the English$\leftrightarrow$Irish and English$\leftrightarrow$Marathi language pairs. Notably, the study identifies the optimal hyperparameters and subword model type to significantly improve the translation quality of Transformer models for low-resource language pairs.   The scarcity of parallel datasets for low-resource languages can hinder MT development. To address this, gaHealth was developed, the first bilingual corpus of health data for the Irish language. Focusing on the health domain, models developed using this in-domain dataset exhibited very significant improvements in BLEU score when compared with models from the LoResMT2021 Shared Task. A subsequent human evaluation using the multid
    
[^63]: SERVAL：垂直模型和LLM之间的协同学习，实现零-shot级别的医学预测

    SERVAL: Synergy Learning between Vertical Models and LLMs towards Oracle-Level Zero-shot Medical Prediction

    [https://arxiv.org/abs/2403.01570](https://arxiv.org/abs/2403.01570)

    提出SERVAL，一个协同学习流水线，可以通过相互增强，实现LLMs和小模型的垂直能力无监督开发，从而改善领域特定垂直问题的零-shot预测能力。

    

    近期大型语言模型（LLMs）的发展展示出对通用和常识问题卓越的零-shot能力。然而，LLMs在领域特定垂直问题上的应用仍然落后，主要是由于垂直知识方面的问题和不足。此外，垂直数据注释过程通常需要劳动密集型的专家参与，因此增加了增强模型垂直能力的额外挑战。在本文中，我们提出了SERVAL，一个协同学习流水线，旨在通过相互增强，对LLMs和小模型的垂直能力进行无监督开发。具体来说，SERVAL利用LLMs的零-shot输出作为注释，利用其置信度来从头开始教授一个强大的垂直模型。反过来，训练有素的垂直模型引导LLM微调，以增强其零-shot能力，逐步改进两者。

    arXiv:2403.01570v1 Announce Type: new  Abstract: Recent development of large language models (LLMs) has exhibited impressive zero-shot proficiency on generic and common sense questions. However, LLMs' application on domain-specific vertical questions still lags behind, primarily due to the humiliation problems and deficiencies in vertical knowledge. Furthermore, the vertical data annotation process often requires labor-intensive expert involvement, thereby presenting an additional challenge in enhancing the model's vertical capabilities. In this paper, we propose SERVAL, a synergy learning pipeline designed for unsupervised development of vertical capabilities in both LLMs and small models by mutual enhancement. Specifically, SERVAL utilizes the LLM's zero-shot outputs as annotations, leveraging its confidence to teach a robust vertical model from scratch. Reversely, the trained vertical model guides the LLM fine-tuning to enhance its zero-shot capability, progressively improving both 
    
[^64]: 基于内部表征的上下文锐度作为警报：减少幻觉的一个视角

    In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation

    [https://arxiv.org/abs/2403.01548](https://arxiv.org/abs/2403.01548)

    本研究从内部表征角度深入探讨了大型语言模型幻觉的机制，发现了幻觉的一个显著模式，即在上下文标记的隐藏状态中，正确生成具有更清晰的上下文激活。我们提出了一种基于熵的度量方法，将“锐度”纳入解码过程中，制定了一种受限解码方法，实验证明其在知识寻求和幻觉任务上的有效性。

    

    大型语言模型（LLMs）经常会产生幻觉并产生事实错误，然而我们对它们为什么会犯这些错误的理解仍然有限。在本研究中，我们从内部表征的角度深入探讨LLM幻觉的潜在机制，并发现与幻觉相关的一个突出模式：正确的生成在上下文标记的隐藏状态中具有更清晰的上下文激活，而不正确的生成则没有。利用这一见解，我们提出了一种基于熵的度量来量化上下文隐藏状态之间的“锐度”，并将其纳入解码过程中以制定一种受限解码方法。在各种知识寻求和幻觉基准测试上的实验证明了我们方法的一致有效性，例如，在TruthfulQA上实现了高达8.6点的改进。我们相信这项研究可以提高我们对幻觉的理解。

    arXiv:2403.01548v1 Announce Type: cross  Abstract: Large language models (LLMs) frequently hallucinate and produce factual errors, yet our understanding of why they make these errors remains limited. In this study, we delve into the underlying mechanisms of LLM hallucinations from the perspective of inner representations, and discover a salient pattern associated with hallucinations: correct generations tend to have sharper context activations in the hidden states of the in-context tokens, compared to the incorrect ones. Leveraging this insight, we propose an entropy-based metric to quantify the ``sharpness'' among the in-context hidden states and incorporate it into the decoding process to formulate a constrained decoding approach. Experiments on various knowledge-seeking and hallucination benchmarks demonstrate our approach's consistent effectiveness, for example, achieving up to an 8.6 point improvement on TruthfulQA. We believe this study can improve our understanding of hallucinat
    
[^65]: 利用生物分子和自然语言的多模态学习：一项综述

    Leveraging Biomolecule and Natural Language through Multi-Modal Learning: A Survey

    [https://arxiv.org/abs/2403.01528](https://arxiv.org/abs/2403.01528)

    生物分子与自然语言相结合的多模态学习为全面表示和分析生物分子开辟了新途径。

    

    集成生物分子建模与自然语言（BL）已经成为人工智能、化学和生物学交叉领域中的一个具有前景的跨学科领域。这种方法利用文本数据源中包含的生物分子的丰富多面描述，增强我们对基本理解，并实现生物分子性质预测等计算任务。通过将自然语言中表达的微妙叙述与通过各种分子建模技术描述的生物分子的结构和功能细节融合，打开了全面表征和分析生物分子的新途径。通过将围绕生物分子的上下文语言数据纳入建模中，BL旨在捕捉包含语言传达的符号特性以及数量化结构特征的整体视图。

    arXiv:2403.01528v1 Announce Type: cross  Abstract: The integration of biomolecular modeling with natural language (BL) has emerged as a promising interdisciplinary area at the intersection of artificial intelligence, chemistry and biology. This approach leverages the rich, multifaceted descriptions of biomolecules contained within textual data sources to enhance our fundamental understanding and enable downstream computational tasks such as biomolecule property prediction. The fusion of the nuanced narratives expressed through natural language with the structural and functional specifics of biomolecules described via various molecular modeling techniques opens new avenues for comprehensively representing and analyzing biomolecules. By incorporating the contextual language data that surrounds biomolecules into their modeling, BL aims to capture a holistic view encompassing both the symbolic qualities conveyed through language as well as quantitative structural characteristics. In this r
    
[^66]: 重新审视动态评估: 大型语言模型的在线调整

    Revisiting Dynamic Evaluation: Online Adaptation for Large Language Models

    [https://arxiv.org/abs/2403.01518](https://arxiv.org/abs/2403.01518)

    在线适应可以将参数转变为时间变化状态，提供一种具有内存权重记忆的上下文长度扩展形式，更符合神经科学中记忆概念，且在提升整体预测性能时尤其有趣。

    

    我们考虑在线微调语言模型参数的问题，也即称为动态评估。虽然一般认为这种方法可以提高整体的预测性能，特别是在考虑训练和评估数据之间的分布转移时，我们在这里强调在线调整将参数转变为时间变化状态，并提供了一种具有内存权重记忆的上下文长度扩展形式，更符合神经科学中记忆概念的思路。我们特别关注适应速度（以样本效率衡量）、对整体分布性漂移的敏感性以及执行梯度计算和参数更新的计算负担。我们的实证研究提供了关于何时在线调整尤为有趣的见解。我们强调，在线调整使得上下文长度和内存在概念上的区分模糊化。

    arXiv:2403.01518v1 Announce Type: new  Abstract: We consider the problem of online fine tuning the parameters of a language model at test time, also known as dynamic evaluation. While it is generally known that this approach improves the overall predictive performance, especially when considering distributional shift between training and evaluation data, we here emphasize the perspective that online adaptation turns parameters into temporally changing states and provides a form of context-length extension with memory in weights, more in line with the concept of memory in neuroscience. We pay particular attention to the speed of adaptation (in terms of sample efficiency),sensitivity to the overall distributional drift, and the computational overhead for performing gradient computations and parameter updates. Our empirical study provides insights on when online adaptation is particularly interesting. We highlight that with online adaptation the conceptual distinction between in-context l
    
[^67]: 奇幻语义与寻找之地：探讨生成型LLM的哪些层次反映词汇语义

    Fantastic Semantics and Where to Find Them: Investigating Which Layers of Generative LLMs Reflect Lexical Semantics

    [https://arxiv.org/abs/2403.01509](https://arxiv.org/abs/2403.01509)

    通过在每个层的末端探测其隐藏状态，使用一个上下文化的词识别任务，本文具体研究了Llama2的自下而上词汇语义演变，发现较低层的表示编码了词汇语义，而较高层负责预测。

    

    大型语言模型在一般语言理解任务中取得了显著的成功。然而，作为一个追求下一个标记预测目标的生成方法家族，这些模型的语义演变随着深度并没有得到充分探索，不像它们的前辈，比如BERT类架构。本文具体研究了一款流行LLM，即Llama2的自下而上词汇语义演变，通过在每个层的末端探测其隐藏状态，使用一个上下文化的词识别任务。我们的实验表明，较低层的表示编码了词汇语义，而较高层，其语义归纳较弱，负责预测。这与具有判别目标的模型形成对比，比如掩码语言建模，在那里较高层获得更好的词汇语义。结论进一步得到性能单调增加的支持。

    arXiv:2403.01509v1 Announce Type: new  Abstract: Large language models have achieved remarkable success in general language understanding tasks. However, as a family of generative methods with the objective of next token prediction, the semantic evolution with the depth of these models are not fully explored, unlike their predecessors, such as BERT-like architectures. In this paper, we specifically investigate the bottom-up evolution of lexical semantics for a popular LLM, namely Llama2, by probing its hidden states at the end of each layer using a contextualized word identification task. Our experiments show that the representations in lower layers encode lexical semantics, while the higher layers, with weaker semantic induction, are responsible for prediction. This is in contrast to models with discriminative objectives, such as mask language modeling, where the higher layers obtain better lexical semantics. The conclusion is further supported by the monotonic increase in performance
    
[^68]: 通过上下文提示向大型语言模型灌输知识

    Infusing Knowledge into Large Language Models with Contextual Prompts

    [https://arxiv.org/abs/2403.01481](https://arxiv.org/abs/2403.01481)

    提出了一种通过从输入文本的上下文中生成提示来进行知识注入的简单但通用方法，能够有效增强大型语言模型的性能。

    

    知识注入是增强大型语言模型用于特定领域NLP任务的一种有效方法，而不是从头开始对模型进行大规模数据的预训练。这种增强的LLM通常依赖于来自现有知识图的额外预训练或知识提示，但在许多应用中是不可行的。相反，直接从相关文档中注入知识更具一般性，减轻了对结构化知识图的需求，同时对于通常不在任何知识图中找到的实体也很有用。鉴于这一动机，我们提出了一种简单但具有一般性的知识注入方法，通过从输入文本的上下文中生成提示。我们的实验表明了我们的方法的有效性，我们通过对微调后的LLM进行探测来评估该方法。

    arXiv:2403.01481v1 Announce Type: new  Abstract: Knowledge infusion is a promising method for enhancing Large Language Models for domain-specific NLP tasks rather than pre-training models over large data from scratch. These augmented LLMs typically depend on additional pre-training or knowledge prompts from an existing knowledge graph, which is impractical in many applications. In contrast, knowledge infusion directly from relevant documents is more generalisable and alleviates the need for structured knowledge graphs while also being useful for entities that are usually not found in any knowledge graph. With this motivation, we propose a simple yet generalisable approach for knowledge infusion by generating prompts from the context in the input text. Our experiments show the effectiveness of our approach which we evaluate by probing the fine-tuned LLMs.
    
[^69]: Align-to-Distill: 可训练的注意力对齐在神经机器翻译中的知识蒸馏

    Align-to-Distill: Trainable Attention Alignment for Knowledge Distillation in Neural Machine Translation

    [https://arxiv.org/abs/2403.01479](https://arxiv.org/abs/2403.01479)

    "本文提出了“Align-to-Distill”（A2D）策略，通过在训练过程中自适应地对齐学生注意力头与其教师对应物，转化了组合映射启发式方法为学习问题，实验结果显示A2D的有效性，对WMT-2022 De->Dsb和WMT-2014 En->De的BLEU分数分别获得高达+3.61和+0.63的提升。"

    

    可扩展的深度模型和大规模数据集的出现提高了神经机器翻译的性能。知识蒸馏（KD）通过将知识从教师模型传输到更紧凑的学生模型来提高效率。然而，针对Transformer架构的KD方法通常依赖于启发式方法，特别是在决定要从哪些教师层中蒸馏知识时。本文介绍了“Align-to-Distill”（A2D）策略，旨在通过在训练过程中自适应地对齐学生注意力头与其教师对应物来解决特征映射问题。A2D中的注意力对齐模块执行学生和教师注意力头之间的密集逐头比较，将组合映射启发式方法转化为学习问题。我们的实验展示了A2D的有效性，对WMT-2022 De->Dsb和WMT-2014 En->De的BLEU分数分别获得高达+3.61和+0.63的提升。

    arXiv:2403.01479v1 Announce Type: cross  Abstract: The advent of scalable deep models and large datasets has improved the performance of Neural Machine Translation. Knowledge Distillation (KD) enhances efficiency by transferring knowledge from a teacher model to a more compact student model. However, KD approaches to Transformer architecture often rely on heuristics, particularly when deciding which teacher layers to distill from. In this paper, we introduce the 'Align-to-Distill' (A2D) strategy, designed to address the feature mapping problem by adaptively aligning student attention heads with their teacher counterparts during training. The Attention Alignment Module in A2D performs a dense head-by-head comparison between student and teacher attention heads across layers, turning the combinatorial mapping heuristics into a learning problem. Our experiments show the efficacy of A2D, demonstrating gains of up to +3.61 and +0.63 BLEU points for WMT-2022 De->Dsb and WMT-2014 En->De, respe
    
[^70]: WARDEN：多方向背门水印用于Embedding-as-a-Service版权保护

    WARDEN: Multi-Directional Backdoor Watermarks for Embedding-as-a-Service Copyright Protection

    [https://arxiv.org/abs/2403.01472](https://arxiv.org/abs/2403.01472)

    本研究提出了一种名为WARDEN的新方法，通过在嵌入文本中加入多个可能的水印方向，增加了水印消除的难度，以应对EaaS中背门水印被移除的新威胁。

    

    Embedding as a Service（EaaS）已成为一种广泛采用的解决方案，为自然语言处理（NLP）中的各种下游任务提供特征提取能力。先前的研究表明，EaaS容易受到模型抽取攻击的威胁；然而，通过向文本嵌入添加背门水印，并随后验证攻击模型的发布后，可以缓解这一问题。通过对最近用于EaaS的水印策略EmbMarker的分析，我们设计了一种新颖的CSE（Cluster、Selection、Elimination）攻击，它能够移除背门水印同时保持嵌入的高效性，表明先前的水印方法是可以被突破的。针对这一新威胁，我们提出了一种新的协议，通过整合多种可能的水印方向使水印的移除变得更具挑战性。我们的防御方法WARDEN显著增加了水印消除的难度。

    arXiv:2403.01472v1 Announce Type: cross  Abstract: Embedding as a Service (EaaS) has become a widely adopted solution, which offers feature extraction capabilities for addressing various downstream tasks in Natural Language Processing (NLP). Prior studies have shown that EaaS can be prone to model extraction attacks; nevertheless, this concern could be mitigated by adding backdoor watermarks to the text embeddings and subsequently verifying the attack models post-publication. Through the analysis of the recent watermarking strategy for EaaS, EmbMarker, we design a novel CSE (Clustering, Selection, Elimination) attack that removes the backdoor watermark while maintaining the high utility of embeddings, indicating that the previous watermarking approach can be breached. In response to this new threat, we propose a new protocol to make the removal of watermarks more challenging by incorporating multiple possible watermark directions. Our defense approach, WARDEN, notably increases the ste
    
[^71]: KorMedMCQA: 韩国医疗专业执业考试的多项选择题问答基准

    KorMedMCQA: Multi-Choice Question Answering Benchmark for Korean Healthcare Professional Licensing Examinations

    [https://arxiv.org/abs/2403.01469](https://arxiv.org/abs/2403.01469)

    KorMedMCQA是首个从韩国医疗专业执业考试中衍生的多项选择题问答基准，提供了多种大型语言模型的基线实验结果，并在HuggingFace上公开了数据，为韩国医疗环境中的进一步研究和发展提供了可能性。

    

    我们介绍了KorMedMCQA，这是首个源自韩国医疗专业执业考试的韩语多项选择题问答（MCQA）基准，涵盖了从2012年到2023年的考试内容。该数据集包括医生、护士和药剂师执照考试中的一部分问题，涵盖多种学科。我们对各种大型语言模型进行了基线实验，包括专有/开源、多语言/韩语附加预训练和临床背景预训练模型，突显了进一步增强潜力。我们在HuggingFace上公开了我们的数据，并通过LM-Harness提供了一个评估脚本，邀请在韩国医疗环境中进行进一步探索和发展。

    arXiv:2403.01469v1 Announce Type: new  Abstract: We introduce KorMedMCQA, the first Korean multiple-choice question answering (MCQA) benchmark derived from Korean healthcare professional licensing examinations, covering from the year 2012 to year 2023. This dataset consists of a selection of questions from the license examinations for doctors, nurses, and pharmacists, featuring a diverse array of subjects. We conduct baseline experiments on various large language models, including proprietary/open-source, multilingual/Korean-additional pretrained, and clinical context pretrained models, highlighting the potential for further enhancements. We make our data publicly available on HuggingFace and provide a evaluation script via LM-Harness, inviting further exploration and advancement in Korean healthcare environments.
    
[^72]: 检索增强开放域问答中的可回答性研究

    Answerability in Retrieval-Augmented Open-Domain Question Answering

    [https://arxiv.org/abs/2403.01461](https://arxiv.org/abs/2403.01461)

    本论文研究了在开放域问答中检索系统的可回答性问题，揭示了使用随机化策略训练模型在泛化到具有高语义重叠的无关文本摘录方面的重要局限性，并提出了一种有效的训练模型的方法。

    

    开放域问答检索系统的性能可能表现出次优行为，提供具有不同程度无关性的文本摘录。不幸的是，许多现有的开放域问答数据集缺乏专门针对识别无关文本摘录的示例。先前的尝试致力于解决这一差距问题，但依赖于将问题与随机文本摘录配对的简单方法。本文旨在探讨使用这种随机化策略训练模型的效果，揭示其在泛化到具有高语义重叠的无关文本摘录方面存在重要局限性。结果，我们观察到预测准确性显著下降，从98%下降到1%。为解决这一限制，我们发现了一种有效的训练模型识别此类摘录的方法。通过利用来自SQuAD 2.0数据集的不可回答问题对，我们的模型实现了近乎完美的(~100%)准确率。

    arXiv:2403.01461v1 Announce Type: new  Abstract: The performance of Open-Domain Question Answering (ODQA) retrieval systems can exhibit sub-optimal behavior, providing text excerpts with varying degrees of irrelevance. Unfortunately, many existing ODQA datasets lack examples specifically targeting the identification of irrelevant text excerpts. Previous attempts to address this gap have relied on a simplistic approach of pairing questions with random text excerpts. This paper aims to investigate the effectiveness of models trained using this randomized strategy, uncovering an important limitation in their ability to generalize to irrelevant text excerpts with high semantic overlap. As a result, we observed a substantial decrease in predictive accuracy, from 98% to 1%. To address this limitation, we discovered an efficient approach for training models to recognize such excerpts. By leveraging unanswerable pairs from the SQuAD 2.0 dataset, our models achieve a nearly perfect (~100%) accu
    
[^73]: 逻辑规则作为解释法律案例检索的论文

    Logic Rules as Explanations for Legal Case Retrieval

    [https://arxiv.org/abs/2403.01457](https://arxiv.org/abs/2403.01457)

    本文提出了神经符号增强的法律案例检索（NS-LCR）框架，通过学习案例级别和法律级别的逻辑规则，将规则以神经符号方式集成到检索过程中，以提供逻辑且可解释的解释。

    

    在本文中，我们探讨了使用逻辑规则来解释法律案例检索结果的问题。这项任务对于法律案例检索至关重要，因为用户（如律师或法官）具有高度专业化，需要系统在做出法律决策之前提供逻辑、忠实和可解释的解释。最近，研究工作旨在学习可解释的法律案例检索模型。然而，这些方法通常从法律案例中选择基本原理（关键句）作为解释，未能提供忠实和逻辑正确的解释。在本文中，我们提出了神经符号增强的法律案例检索（NS-LCR）框架，该框架通过学习案例级别和法律级别的逻辑规则来明确地对法律案例的匹配进行推理。然后将学习到的规则以神经符号方式集成到检索过程中。由于逻辑和可解释性的特性...

    arXiv:2403.01457v1 Announce Type: cross  Abstract: In this paper, we address the issue of using logic rules to explain the results from legal case retrieval. The task is critical to legal case retrieval because the users (e.g., lawyers or judges) are highly specialized and require the system to provide logical, faithful, and interpretable explanations before making legal decisions. Recently, research efforts have been made to learn explainable legal case retrieval models. However, these methods usually select rationales (key sentences) from the legal cases as explanations, failing to provide faithful and logically correct explanations. In this paper, we propose Neural-Symbolic enhanced Legal Case Retrieval (NS-LCR), a framework that explicitly conducts reasoning on the matching of legal cases through learning case-level and law-level logic rules. The learned rules are then integrated into the retrieval process in a neuro-symbolic manner. Benefiting from the logic and interpretable natu
    
[^74]: 使用基于PLM的代理模型控制IRT评估中的填空测试题目难度

    Controlling Cloze-test Question Item Difficulty with PLM-based Surrogate Models for IRT Assessment

    [https://arxiv.org/abs/2403.01456](https://arxiv.org/abs/2403.01456)

    提出使用预训练语言模型作为代理模型，通过排名规则控制填空测试题目中空白和干扰项的难度水平，有效评估MC填空测试的难度水平

    

    项目难度在自适应测试中发挥着至关重要的作用。然而，很少有研究集中在生成不同难度水平的问题，特别是针对多项选择（MC）填空测试。我们提出使用预先训练的语言模型（PLMs）作为代理模型，以实现项目反应理论（IRT）评估，避免需要人类测试对象。我们还提出了两种策略来通过排名规则控制空白和干扰项的难度水平，以减少无效干扰项。对基准数据集的实验表明，我们提出的框架和方法可以有效地控制和评估MC填空测试的难度水平。

    arXiv:2403.01456v1 Announce Type: cross  Abstract: Item difficulty plays a crucial role in adaptive testing. However, few works have focused on generating questions of varying difficulty levels, especially for multiple-choice (MC) cloze tests. We propose training pre-trained language models (PLMs) as surrogate models to enable item response theory (IRT) assessment, avoiding the need for human test subjects. We also propose two strategies to control the difficulty levels of both the gaps and the distractors using ranking rules to reduce invalid distractors. Experimentation on a benchmark dataset demonstrates that our proposed framework and methods can effectively control and evaluate the difficulty levels of MC cloze tests.
    
[^75]: 微调与检索增强生成用于不太流行知识的比较

    Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge

    [https://arxiv.org/abs/2403.01432](https://arxiv.org/abs/2403.01432)

    本文研究了微调和检索增强生成两种方法对大型语言模型在处理低频实体问题回答任务中的影响，发现微调显著提高了各种受欢迎程度的实体的性能，而检索增强生成方法则超过了其他方法。

    

    大型语言模型（LLMs）记忆了大量的事实知识，在各种任务和领域表现出色。然而，观察到当处理不太流行或低频概念和实体时，性能会下降，例如在领域特定应用中。本文探讨和评估了检索增强生成（RAG）和通过合成数据进行微调（FT）对定制LLMs处理低频实体问题回答任务的影响。研究结果表明，FT显著提升了各种受欢迎程度的实体的性能，特别是在最受欢迎和最不受欢迎的群体中，而RAG超越了其他方法。另外，检索和数据增强技术的进步加强了RAG和FT方法的成功。

    arXiv:2403.01432v1 Announce Type: new  Abstract: Large language models (LLMs) memorize a vast amount of factual knowledge, exhibiting strong performance across diverse tasks and domains. However, it has been observed that the performance diminishes when dealing with less-popular or low-frequency concepts and entities, for example in domain specific applications. The two prominent approaches to enhance the performance of LLMs on low-frequent topics are: Retrieval Augmented Generation (RAG) and fine-tuning (FT) over synthetic data. This paper explores and evaluates the impact of RAG and FT on customizing LLMs in handling low-frequency entities on question answering task. Our findings indicate that FT significantly boosts the performance across entities of varying popularity, especially in the most and least popular groups, while RAG surpasses other methods. Additionally, the success of both RAG and FT approaches is amplified by advancements in retrieval and data augmentation techniques. 
    
[^76]: OVEL: 大型语言模型作为在线视频实体链接的内存管理器

    OVEL: Large Language Model as Memory Manager for Online Video Entity Linking

    [https://arxiv.org/abs/2403.01411](https://arxiv.org/abs/2403.01411)

    提出了面向在线视频的实体链接任务OVEL，专注于在在线视频内容中建立与知识库之间准确和及时的连接，并构建了一个实时交付实体链接数据集LIVE。

    

    近年来，由于在多模态应用中的重要性，多模态实体链接（MEL）在研究界中越来越受到关注。视频作为一种流行的信息传递方式，已经在人们的日常生活中变得普遍。然而，大多数现有的MEL方法主要集中在链接文本和视觉提及，或是离线视频提及到多模态知识库中的实体，而对于链接在线视频内容中的提及投入的努力有限。在本文中，我们提出了一个名为Online Video Entity Linking OVEL 的任务，旨在建立在线视频中提及与知识库之间的连接，并且具有高准确性和及时性。为了促进OVEL的研究工作，我们特别关注实时交付场景，并构建了一个名为LIVE的实时交付实体链接数据集。此外，我们提出了一个评估指标，考虑了时效性和鲁棒性。

    arXiv:2403.01411v1 Announce Type: new  Abstract: In recent years, multi-modal entity linking (MEL) has garnered increasing attention in the research community due to its significance in numerous multi-modal applications. Video, as a popular means of information transmission, has become prevalent in people's daily lives. However, most existing MEL methods primarily focus on linking textual and visual mentions or offline videos's mentions to entities in multi-modal knowledge bases, with limited efforts devoted to linking mentions within online video content. In this paper, we propose a task called Online Video Entity Linking OVEL, aiming to establish connections between mentions in online videos and a knowledge base with high accuracy and timeliness. To facilitate the research works of OVEL, we specifically concentrate on live delivery scenarios and construct a live delivery entity linking dataset called LIVE. Besides, we propose an evaluation metric that considers timelessness, robustne
    
[^77]: 多语言视觉推理中的缺失及修复方法

    What Is Missing in Multilingual Visual Reasoning and How to Fix It

    [https://arxiv.org/abs/2403.01404](https://arxiv.org/abs/2403.01404)

    本文通过在视觉推理任务上的测试，发现了多语言视觉推理中存在的挑战，并提出了针对性的干预措施，包括翻译-测试方法，视觉编程方法和图像字幕生成方法。

    

    NLP模型今天在支持多语言和多模态方面取得了进展，提高了对各种用户的可访问性。本文通过在一个视觉推理任务上的测试来评估它们的多语言，多模态能力。我们观察到像GPT-4V这样的专有系统现在在该任务上表现最佳，但与开放模型相比存在差距。令人惊讶的是，GPT-4V在英语和其他语言之间表现出类似的性能，表明在不同语言之间开发公平的系统具有潜力。我们对模型失败进行的分析揭示了使这一任务具有挑战性的三个关键方面：多语言性，复杂推理和多模态性。为了解决这些挑战，我们提出了三种有针对性的干预措施，包括一种翻译-测试方法来解决多语言性，一种视觉编程方法来分解复杂推理，以及一种利用图像字幕生成来解决多模态性的新方法。

    arXiv:2403.01404v1 Announce Type: new  Abstract: NLP models today strive for supporting multiple languages and modalities, improving accessibility for diverse users. In this paper, we evaluate their multilingual, multimodal capabilities by testing on a visual reasoning task. We observe that proprietary systems like GPT-4V obtain the best performance on this task now, but open models lag in comparison. Surprisingly, GPT-4V exhibits similar performance between English and other languages, indicating the potential for equitable system development across languages. Our analysis on model failures reveals three key aspects that make this task challenging: multilinguality, complex reasoning, and multimodality. To address these challenges, we propose three targeted interventions including a translate-test approach to tackle multilinguality, a visual programming approach to break down complex reasoning, and a novel method that leverages image captioning to address multimodality. Our interventio
    
[^78]: CR-LT-KGQA：一个需要常识推理和长尾知识的知识图谱问答数据集

    CR-LT-KGQA: A Knowledge Graph Question Answering Dataset Requiring Commonsense Reasoning and Long-Tail Knowledge

    [https://arxiv.org/abs/2403.01395](https://arxiv.org/abs/2403.01395)

    这项工作提出了一个新的KGQA数据集 CR-LT-KGQA，要求进行常识推理，并关注长尾实体，为那些往往产生妄想的大型语言模型提供利用知识图谱进行基于事实和可归属常识推理的新方法。

    

    arXiv:2403.01395v1 公告类型: 新的 摘要: 知识图谱问答（KGQA）是一个旨在通过利用知识图谱（KG）为自然语言（NL）问题提供事实答案的成熟领域。然而，现有的KGQA数据集存在两个重要局限：（1）没有现有的KGQA数据集需要常识推理才能得出答案；（2）现有的KGQA数据集重点关注流行实体，大型语言模型（LLMs）可以直接回答而无需产生妄想和无需利用KG。在这项工作中，我们寻求一个支持常识推理并专注于长尾实体（例如，非主流和最近实体）的新颖KGQA数据集，其中LLMs经常产生妄想，因此需要借助KG进行基于事实且可归属的常识推理的新方法。我们创建了一个新颖的常识推理（CR）和长尾（LT）KGQA数据集，包括两个子任务--问题回答和声明验证。

    arXiv:2403.01395v1 Announce Type: new  Abstract: Knowledge graph question answering (KGQA) is a well-established field that seeks to provide factual answers to natural language (NL) questions by leveraging knowledge graphs (KGs). However, existing KGQA datasets suffer from two significant limitations: (1) no existing KGQA dataset requires commonsense reasoning to arrive at an answer and (2) existing KGQA datasets focus on popular entities for which large language models (LLMs) can directly answer without hallucinating and without leveraging the KG. In this work, we seek a novel KGQA dataset that supports commonsense reasoning and focuses on long-tail entities (e.g., non-mainstream and recent entities) where LLMs frequently hallucinate, and thus create the need for novel methodologies that leverage the KG for factual and attributable commonsense inference. We create a novel Commonsense Reasoning (CR) and Long-Tail (LT) KGQA dataset with two subtasks -- question answering and claim verif
    
[^79]: 正当且充分：可验证的常识知识图问题回答中的大型语言模型

    Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering

    [https://arxiv.org/abs/2403.01390](https://arxiv.org/abs/2403.01390)

    LLM-based KGQA methods struggle with hallucination on commonsense reasoning questions, hindering their applicability in real-world applications.

    

    知识图问题回答（KGQA）方法旨在利用知识图中存储的关系信息来回答自然语言问题。随着大型语言模型（LLMs）的最新进展及其出色的推理能力，利用它们进行KGQA的趋势日益增长。然而，现有方法仅专注于回答事实性问题，例如“Silvio Berlusconi的第一任妻子出生在哪座城市？”，而忽略了涉及常识推理的问题，这是现实世界用户可能更经常提出的，例如“我需要单独的签证才能看到威伦多夫的维纳斯并参加今年夏天的奥运会吗？”。在这项工作中，我们首先观察到，现有基于LLM的KGQA方法在处理这类问题时难以产生真实的答案，尤其是对针对长尾实体的查询（例如非主流和最近的实体），从而阻碍了它们在现实世界应用中的可应用性。

    arXiv:2403.01390v1 Announce Type: new  Abstract: Knowledge Graph Question Answering (KGQA) methods seek to answer Natural Language questions using the relational information stored in Knowledge Graphs (KGs). With the recent advancements of Large Language Models (LLMs) and their remarkable reasoning abilities, there is a growing trend to leverage them for KGQA. However, existing methodologies have only focused on answering factual questions, e.g., "In which city was Silvio Berlusconi's first wife born?", leaving questions involving commonsense reasoning that real-world users may pose more often, e.g., "Do I need separate visas to see the Venus of Willendorf and attend the Olympics this summer?" unaddressed. In this work, we first observe that existing LLM-based methods for KGQA struggle with hallucination on such questions, especially on queries targeting long-tail entities (e.g., non-mainstream and recent entities), thus hindering their applicability in real-world applications especial
    
[^80]: 关于量化大型语言模型的可压缩性

    On the Compressibility of Quantized Large Language Models

    [https://arxiv.org/abs/2403.01384](https://arxiv.org/abs/2403.01384)

    研究在内存受限设备上应用数据压缩技术以加速量化LLM推理过程的一项初步工作。

    

    部署大型语言模型（LLMs）到边缘或移动设备上具有显著优势，如增强数据隐私和实时处理能力。本文研究了将数据压缩技术应用于减少数据移动，从而加速内存受限设备上量化LLM的推理过程的初步步骤。

    arXiv:2403.01384v1 Announce Type: cross  Abstract: Deploying Large Language Models (LLMs) on edge or mobile devices offers significant benefits, such as enhanced data privacy and real-time processing capabilities. However, it also faces critical challenges due to the substantial memory requirement of LLMs. Quantization is an effective way of reducing the model size while maintaining good performance. However, even after quantization, LLMs may still be too big to fit entirely into the limited memory of edge or mobile devices and have to be partially loaded from the storage to complete the inference. In this case, the I/O latency of model loading becomes the bottleneck of the LLM inference latency. In this work, we take a preliminary step of studying applying data compression techniques to reduce data movement and thus speed up the inference of quantized LLM on memory-constrained devices. In particular, we discussed the compressibility of quantized LLMs, the trade-off between the compres
    
[^81]: 长尾知识的自动问答生成

    Automatic Question-Answer Generation for Long-Tail Knowledge

    [https://arxiv.org/abs/2403.01382](https://arxiv.org/abs/2403.01382)

    提出了一种自动生成长尾知识问答数据集的自动化方法，并通过预训练的大型语言模型对其进行了实验验证。

    

    预训练的大型语言模型（LLMs）在开放领域问答中取得了显著的关注。虽然它们在回答与常见知识相关的问题时表现出高准确性，但在学习罕见的长尾知识（尾部实体）时遇到困难。本文提出了一种自动生成专门用于尾部实体的问答数据集的方法，并介绍了相关的研究挑战。我们通过利用预训练的LLMs在我们新生成的长尾问答数据集上进行了大量实验，比较了它们在有无外部资源（包括维基百科和维基数据知识图谱）的情况下的表现。

    arXiv:2403.01382v1 Announce Type: new  Abstract: Pretrained Large Language Models (LLMs) have gained significant attention for addressing open-domain Question Answering (QA). While they exhibit high accuracy in answering questions related to common knowledge, LLMs encounter difficulties in learning about uncommon long-tail knowledge (tail entities). Since manually constructing QA datasets demands substantial human resources, the types of existing QA datasets are limited, leaving us with a scarcity of datasets to study the performance of LLMs on tail entities. In this paper, we propose an automatic approach to generate specialized QA datasets for tail entities and present the associated research challenges. We conduct extensive experiments by employing pretrained LLMs on our newly generated long-tail QA datasets, comparing their performance with and without external resources including Wikipedia and Wikidata knowledge graphs.
    
[^82]: 评估和减少大规模视觉语言模型中的数字幻觉：一种一致性视角

    Evaluating and Mitigating Number Hallucinations in Large Vision-Language Models: A Consistency Perspective

    [https://arxiv.org/abs/2403.01373](https://arxiv.org/abs/2403.01373)

    本文评估了大型视觉语言模型中的数字幻觉问题，并提出一种一致性训练方法，可使数字幻觉得到显著改善

    

    大型视觉语言模型已经展示出在处理文本和视觉内容相关挑战方面的显著功效。然而，这些模型容易出现各种幻觉。本文关注一种新形式的幻觉，称为数字幻觉，指的是模型未能准确识别图像中物体的数量的情况。我们建立了一个数据集，并采用评估指标评估数字幻觉，揭示了这一问题在主流大型视觉语言模型(LVLMs)中的明显普遍性。此外，我们从两个相关视角深入分析了数字幻觉，考察了内在和外在的不一致问题。我们认为这种不一致性是数字幻觉的一个原因，并提出了一种一致性训练方法作为减轻此类幻觉的手段，该方法取得了8%的平均改进。

    arXiv:2403.01373v1 Announce Type: new  Abstract: Large vision language models have demonstrated remarkable efficacy in addressing challenges related to both textual and visual content. Nevertheless, these models are susceptible to various hallucinations. In this paper, we focus on a new form of hallucination, specifically termed as number hallucination, which denotes instances where models fail to accurately identify the quantity of objects in an image. We establish a dataset and employ evaluation metrics to assess number hallucination, revealing a pronounced prevalence of this issue across mainstream large vision language models (LVLMs). Additionally, we delve into a thorough analysis of number hallucination, examining inner and outer inconsistency problem from two related perspectives. We assert that this inconsistency is one cause of number hallucination and propose a consistency training method as a means to alleviate such hallucination, which achieves an average improvement of 8\%
    
[^83]: 通过代码切换改进语义检索的跨语言表示

    Improving Cross-lingual Representation for Semantic Retrieval with Code-switching

    [https://arxiv.org/abs/2403.01364](https://arxiv.org/abs/2403.01364)

    提出了一种通过代码切换的交替跨语言PTM，首次将代码切换方法应用于跨语言语义检索。

    

    arXiv:2403.01364v1 公告类型：新 提要：语义检索（SR）已成为任务导向问答（QA）对话场景中FAQ系统中不可或缺的部分。最近，对于电子商务平台或某些特定业务环境的跨语言智能客户服务系统的需求日益增加。大多数先前的研究直接利用跨语言预训练模型（PTMs）用于多语言知识检索，而其他一些研究也利用持续预训练在对下游任务的PTMs进行微调之前。然而，无论使用哪种模式，先前的工作都忽略了向PTMs告知与SR相关的一些特征，即在不提供与SR相关的任何信号的情况下训练他们的PTMs。为此，在这项工作中，我们提出了一种通过代码切换的交替跨语言PTM用于SR。我们是第一个为跨语言SR使用代码切换方法的研究。此外，我们还介绍了新颖的代码切换持续预训练方法。

    arXiv:2403.01364v1 Announce Type: new  Abstract: Semantic Retrieval (SR) has become an indispensable part of the FAQ system in the task-oriented question-answering (QA) dialogue scenario. The demands for a cross-lingual smart-customer-service system for an e-commerce platform or some particular business conditions have been increasing recently. Most previous studies exploit cross-lingual pre-trained models (PTMs) for multi-lingual knowledge retrieval directly, while some others also leverage the continual pre-training before fine-tuning PTMs on the downstream tasks. However, no matter which schema is used, the previous work ignores to inform PTMs of some features of the downstream task, i.e. train their PTMs without providing any signals related to SR. To this end, in this work, we propose an Alternative Cross-lingual PTM for SR via code-switching. We are the first to utilize the code-switching approach for cross-lingual SR. Besides, we introduce the novel code-switched continual pre-t
    
[^84]: LM4OPT：揭示大型语言模型在制定数学优化问题中潜力

    LM4OPT: Unveiling the Potential of Large Language Models in Formulating Mathematical Optimization Problems

    [https://arxiv.org/abs/2403.01342](https://arxiv.org/abs/2403.01342)

    本研究比较了几种知名的大型语言模型在翻译语言描述为数学优化问题中的表现，发现GPT-4在一次场景中表现出色，并引入了“LM4OPT”框架进行Llama-2-7b的渐进微调。

    

    在自然语言处理这一快速发展的领域中，将语言描述翻译成数学优化问题的数学公式是一项巨大挑战，要求大型语言模型（LLMs）具备复杂的理解和处理能力。本研究比较了几种知名的LLMs，包括GPT-3.5、GPT-4和Llama-2-7b，在零次和一次设置中对这一任务的表现。我们的发现显示出GPT-4在一次场景中的卓越表现。其中心部分是引入了“LM4OPT”，这是一个利用噪声嵌入和专门数据集进行Llama-2-7b渐进微调的框架。然而，这项研究突出了小型模型（如Llama-2-7b）在处理冗长和复杂输入上的上下文理解能力与更大型对应模型之间存在显著差距。我们的实证研究利用了NL4Opt

    arXiv:2403.01342v1 Announce Type: new  Abstract: In the rapidly evolving field of natural language processing, the translation of linguistic descriptions into mathematical formulation of optimization problems presents a formidable challenge, demanding intricate understanding and processing capabilities from Large Language Models (LLMs). This study compares prominent LLMs, including GPT-3.5, GPT-4, and Llama-2-7b, in zero-shot and one-shot settings for this task. Our findings show GPT-4's superior performance, particularly in the one-shot scenario. A central part of this research is the introduction of `LM4OPT,' a progressive fine-tuning framework for Llama-2-7b that utilizes noisy embeddings and specialized datasets. However, this research highlights a notable gap in the contextual understanding capabilities of smaller models such as Llama-2-7b compared to larger counterparts, especially in processing lengthy and complex input contexts. Our empirical investigation, utilizing the NL4Opt
    
[^85]: VNLP：土耳其自然语言处理工具包

    VNLP: Turkish NLP Package

    [https://arxiv.org/abs/2403.01309](https://arxiv.org/abs/2403.01309)

    VNLP是首个专门针对土耳其语开发的自然语言处理工具包，包含多种NLP工具，其中的标记分类模型基于“上下文模型”，支持多种任务如情感分析、命名实体识别等。

    

    在本文中，我们介绍了VNLP：第一个专门针对土耳其语的完整、开源、文档完备、轻量级、可投入生产使用的最先进的自然语言处理（NLP）工具包。它包含各种工具，从最简单的任务，如句子分割和文本规范化，到更高级的任务，如文本和标记分类模型。其标记分类模型基于“上下文模型”，这是一种既是编码器又是自回归模型的新颖架构。VNLP模型解决的NLP任务包括但不限于情感分析、命名实体识别、形态分析和消歧以及词性标注。此外，它配备了预训练的词嵌入和相应的SentencePiece Unigram标记器。VNLP具有开源的GitHub存储库、ReadtheDocs文档、方便安装的PyPi包、Python和逗号

    arXiv:2403.01309v1 Announce Type: cross  Abstract: In this work, we present VNLP: the first dedicated, complete, open-source, well-documented, lightweight, production-ready, state-of-the-art Natural Language Processing (NLP) package for the Turkish language. It contains a wide variety of tools, ranging from the simplest tasks, such as sentence splitting and text normalization, to the more advanced ones, such as text and token classification models. Its token classification models are based on "Context Model", a novel architecture that is both an encoder and an auto-regressive model. NLP tasks solved by VNLP models include but are not limited to Sentiment Analysis, Named Entity Recognition, Morphological Analysis \& Disambiguation and Part-of-Speech Tagging. Moreover, it comes with pre-trained word embeddings and corresponding SentencePiece Unigram tokenizers. VNLP has an open-source GitHub repository, ReadtheDocs documentation, PyPi package for convenient installation, Python and comma
    
[^86]: VBART: 土耳其LLM

    VBART: The Turkish LLM

    [https://arxiv.org/abs/2403.01308](https://arxiv.org/abs/2403.01308)

    VBART是第一个土耳其序列到序列大语言模型，通过与BART和mBART模型结合形成了紧凑型LLM，并在多个任务中表现出色，为土耳其自然语言处理研究开辟了新的可能性。

    

    我们提出了VBART，这是第一个土耳其序列到序列大语言模型（LLMs），在一个大语料库上从头开始进行预训练。VBART是基于BART和mBART模型的好思路构建的紧凑型LLMs，分为Large和XLarge两个尺寸。微调后的VBART模型在提取性文本摘要、标题生成、文本改写、问答和问题生成等任务中超越了先前的最先进结果。它们允许为未来的文本生成任务和数据集进行微调，为土耳其自然语言处理（NLP）研究开辟了新路径。我们的工作表明，拥有为土耳其进行预训练的LLM比多语言模型提高了最多3倍，改进了现有结果，并为训练和推理提供了高效的模型。此外，我们展示了我们的单语分词器比OpenAI的多语言分词器更高效7倍。最后但同样重要的是，我们介绍了一种扩展现有预训

    arXiv:2403.01308v1 Announce Type: new  Abstract: We present VBART, the first Turkish sequence-to-sequence Large Language Models (LLMs) pre-trained on a large corpus from scratch. VBART are compact LLMs based on good ideas leveraged from BART and mBART models and come in two sizes, Large and XLarge. Fine-tuned VBART models surpass the prior state-of-the-art results in abstractive text summarization, title generation, text paraphrasing, question answering and question generation tasks. They allow fine-tuning for future text generation tasks and datasets, carving a new path for Turkish Natural Language Processing (NLP) research. Our work shows that having a pre-trained LLM for Turkish outperforms up to 3x multilingual models, improving existing results and providing efficient models for training and inference. Moreover, we show that our monolingual tokenizer is 7x more efficient than OpenAI's multilingual tokenizer. Last but not least, we introduce a method to enlarge an existing pre-trai
    
[^87]: 通过强化学习提高自动生成反馈的有效性

    Improving the Validity of Automatically Generated Feedback via Reinforcement Learning

    [https://arxiv.org/abs/2403.01304](https://arxiv.org/abs/2403.01304)

    本研究通过提出评估数学反馈的评分标准，展示了GPT-4能够有效地使用它来注释人工编写的和LLM生成的反馈，从而改进了自动生成反馈的有效性和可靠性。

    

    在智能辅导系统和在线学习平台中，通过大型语言模型（LLMs）自动生成反馈具有改善许多学生学习成果的潜力。本研究解决了自动生成和评估反馈的问题，同时考虑了正确性和一致性。

    arXiv:2403.01304v1 Announce Type: new  Abstract: Automatically generating feedback via large language models (LLMs) in intelligent tutoring systems and online learning platforms has the potential to improve the learning outcomes of many students. However, both feedback generation and evaluation are challenging: feedback content has to be valid especially in subjects like math, which requires models to understand the problem, the solution, and where the student's error lies. Feedback also has to be pedagogically valid to reflect effective tutoring strategies, such as explaining possible misconceptions and encouraging the student, among other desirable features. In this work, we address both problems of automatically generating and evaluating feedback while considering both correctness and alignment. First, we propose a rubric for evaluating math feedback and show that GPT-4 is able to effectively use it to annotate human-written and LLM-generated feedback. Second, we propose a framework
    
[^88]: 贪婪是你所需要的一切：对分词推理方法的评估

    Greed is All You Need: An Evaluation of Tokenizer Inference Methods

    [https://arxiv.org/abs/2403.01289](https://arxiv.org/abs/2403.01289)

    对 NLP 模型中常用的分词器进行了控制性分析，发现贪婪推理表现良好，而上下文感知分词器 SaGe 在形态对齐方面表现最优。

    

    虽然 BPE 和 WordPiece 这样的子词分词器通常用于构建 NLP 模型的词汇表，但是将文本解码为这些词汇表中的一系列标记的方法通常未指定，或者不适合它们构建的方法。我们对四种不同算法和三种词汇量大小之间的七种分词器推理方法进行了控制性分析，我们在英语上为此构建了一个新颖的内在评估套件，结合了基于形态学、认知和信息理论的度量。我们展示了对于最常用的分词器，贪婪推理表现出人意料地良好；最近引入的上下文感知分词器 SaGe 在形态对齐方面优于所有其他方法。

    arXiv:2403.01289v1 Announce Type: new  Abstract: While subword tokenizers such as BPE and WordPiece are typically used to build vocabularies for NLP models, the method of decoding text into a sequence of tokens from these vocabularies is often left unspecified, or ill-suited to the method in which they were constructed. We provide a controlled analysis of seven tokenizer inference methods across four different algorithms and three vocabulary sizes, performed on a novel intrinsic evaluation suite we curated for English, combining measures rooted in morphology, cognition, and information theory. We show that for the most commonly used tokenizers, greedy inference performs surprisingly well; and that SaGe, a recently-introduced contextually-informed tokenizer, outperforms all others on morphological alignment.
    
[^89]: NoMAD-Attention: 通过无MAD操作实现CPU上高效LLM推断

    NoMAD-Attention: Efficient LLM Inference on CPUs Through Multiply-add-free Attention

    [https://arxiv.org/abs/2403.01273](https://arxiv.org/abs/2403.01273)

    NoMAD-Attention提出了一种高效的注意力算法，通过在CPU上使用寄存器内查找取代MAD操作，以实现LLM推断的快速计算。

    

    在中央处理单元（CPU）上进行大型语言模型推断具有挑战性，因为注意力计算中存在大量昂贵的MAD矩阵操作。本文认为现代CPU中的单指令多数据（SIMD）寄存器是一种珍贵的宝石，它允许在批处理中进行超低延迟查找。我们利用CPU的这一独特能力提出了NoMAD-Attention，这是一种高效的注意力算法，用于将MAD操作替换为寄存器内查找。通过硬件感知的算法设计，NoMAD-Attention实现了通过重复快速访问SIMD寄存器来计算注意力分数，尽管它们的大小非常有限。此外，NoMAD-Attention适用于预训练的基于注意力的LLM，无需对模型进行微调。实证评估表明，NoMAD-Attention很好地保持了原始LLM的质量，并加速了4位量化的LLaMA-7B-bas。

    arXiv:2403.01273v1 Announce Type: cross  Abstract: Large language model inference on Central Processing Units (CPU) is challenging due to the vast quantities of expensive Multiply-Add (MAD) matrix operations in the attention computations. In this paper, we argue that there is a rare gem in modern CPUs, Single-Instruction-Multiple-Data (SIMD) registers, which allow for ultra-low-latency lookups in batch. We leverage this unique capability of CPUs to propose NoMAD-Attention, an efficient attention algorithm that replaces MAD operations with in-register lookups. Through hardware-aware algorithmic designs, NoMAD-Attention achieves the computation of attention scores using repeated fast accesses to SIMD registers despite their highly limited sizes. Moreover, NoMAD-Attention works with pre-trained attention-based LLMs without model finetuning. Empirical evaluations demonstrate that NoMAD-Attention maintains the quality of the original LLMs well, and speeds up the 4-bit quantized LLaMA-7B-bas
    
[^90]: 借助情感分析的有害内容检测跨语言框架综述

    A comprehensive cross-language framework for harmful content detection with the aid of sentiment analysis

    [https://arxiv.org/abs/2403.01270](https://arxiv.org/abs/2403.01270)

    本研究引入了首个详细的适用于任何语言的框架，旨在解决跨语言有害内容检测中的挑战

    

    在当今数字化世界中，社交媒体在促进沟通和内容共享方面发挥着重要作用。然而，用户生成内容的急剧增长导致了在维护尊重的在线环境方面面临挑战。在一些情况下，用户利用匿名性使用有害语言，这可能会对用户体验产生负面影响并引发严重的社会问题。鉴于手动审核的局限性，已经开发了自动检测系统来解决这一问题。然而，仍然存在一些障碍，包括缺乏有害语言的统一定义，跨语言不足的数据集，需要详细的注释指南，以及最重要的是一个全面的框架。本研究旨在首次引入一个适用于任何语言的详细框架来解决这些挑战。

    arXiv:2403.01270v1 Announce Type: new  Abstract: In today's digital world, social media plays a significant role in facilitating communication and content sharing. However, the exponential rise in user-generated content has led to challenges in maintaining a respectful online environment. In some cases, users have taken advantage of anonymity in order to use harmful language, which can negatively affect the user experience and pose serious social problems. Recognizing the limitations of manual moderation, automatic detection systems have been developed to tackle this problem. Nevertheless, several obstacles persist, including the absence of a universal definition for harmful language, inadequate datasets across languages, the need for detailed annotation guideline, and most importantly, a comprehensive framework. This study aims to address these challenges by introducing, for the first time, a detailed framework adaptable to any language. This framework encompasses various aspects of h
    
[^91]: 解剖语言模型：通过选择性修剪实现机器去学习

    Dissecting Language Models: Machine Unlearning via Selective Pruning

    [https://arxiv.org/abs/2403.01267](https://arxiv.org/abs/2403.01267)

    介绍了一种针对大型语言模型的机器去学习方法，通过选择性修剪神经元来实现去学习，发现LLMs中的神经元在特定任务中具有不同的重要性。

    

    本文引入了一种专门为大型语言模型（LLMs）设计的机器去学习方法。我们提出了一种针对LLMs的选择性修剪方法，根据神经元对特定能力的相对重要性来移除神经元，而非整体网络性能。该方法是一种高效的计算和数据方法，用于识别和删除能够实现特定行为的神经元。我们的研究发现，LLMs中的前馈神经元和注意力神经元是专门化的；也就是说，对于特定任务，某些神经元比其他神经元更为关键。

    arXiv:2403.01267v1 Announce Type: cross  Abstract: Understanding and shaping the behaviour of Large Language Models (LLMs) is increasingly important as applications become more powerful and more frequently adopted. This paper introduces a machine unlearning method specifically designed for LLMs. We introduce a selective pruning method for LLMs that removes neurons based on their relative importance on a targeted capability compared to overall network performance. This approach is a compute- and data-efficient method for identifying and removing neurons that enable specific behaviours. Our findings reveal that both feed-forward and attention neurons in LLMs are specialized; that is, for specific tasks, certain neurons are more crucial than others.
    
[^92]: 通过探查采样加速贪婪坐标梯度

    Accelerating Greedy Coordinate Gradient via Probe Sampling

    [https://arxiv.org/abs/2403.01251](https://arxiv.org/abs/2403.01251)

    研究引入了一种名为“探查采样”的新算法，通过动态确定草稿模型和目标模型的相似度，来加速贪婪坐标梯度算法，实现高达5.6倍的加速。

    

    大型语言模型（LLMs）的安全性已成为一个中心问题，考虑到它们的快速发展和广泛应用。研究表明，贪婪坐标梯度（GCG）在构建包含对抗后缀的提示时非常有效，以破坏被认为是安全的LLMs，但GCG的优化耗时较长，限制了其实用性。为了减少GCG的时间成本并实现对LLMs安全性更全面的研究，在这项工作中，我们研究了一种称为“探查采样”的新算法，以加速GCG算法。该算法的核心是一种机制，动态确定较小草稿模型的预测与目标模型的提示候选预测的相似程度。当目标模型与草稿模型相似时，我们大量依赖于草稿模型来过滤大量潜在提示候选，以减少计算时间。探查采样使用Llam实现高达5.6倍的加速。

    arXiv:2403.01251v1 Announce Type: new  Abstract: Safety of Large Language Models (LLMs) has become a central issue given their rapid progress and wide applications. Greedy Coordinate Gradient (GCG) is shown to be effective in constructing prompts containing adversarial suffixes to break the presumingly safe LLMs, but the optimization of GCG is time-consuming and limits its practicality. To reduce the time cost of GCG and enable more comprehensive studies of LLM safety, in this work, we study a new algorithm called $\texttt{Probe sampling}$ to accelerate the GCG algorithm. At the core of the algorithm is a mechanism that dynamically determines how similar a smaller draft model's predictions are to the target model's predictions for prompt candidates. When the target model is similar to the draft model, we rely heavily on the draft model to filter out a large number of potential prompt candidates to reduce the computation time. Probe sampling achieves up to $5.6$ times speedup using Llam
    
[^93]: SceneCraft：一个用于将文本描述合成为Blender代码的LLM代理

    SceneCraft: An LLM Agent for Synthesizing 3D Scene as Blender Code

    [https://arxiv.org/abs/2403.01248](https://arxiv.org/abs/2403.01248)

    SceneCraft是一个LLM代理，可将文本描述转换为Blender代码，实现渲染高达一百个三维资产的复杂场景，通过先建模空间关系再编写Python脚本，并借助视觉-语言基础模型进行场景优化和库学习来解决挑战。

    

    本文介绍了SceneCraft，一个大型语言模型（LLM）代理，将文本描述转换为Blender可执行的Python脚本，用于渲染高达一百个三维资产的复杂场景。该过程需要复杂的空间规划和布局。我们通过高级抽象、战略规划和库学习的组合来解决这些挑战。SceneCraft首先将场景图建模为蓝图，详细描述场景中各资产之间的空间关系。然后，SceneCraft根据这个图编写Python脚本，将关系转化为资产布局的数值约束。接下来，SceneCraft利用像GPT-V这样的视觉-语言基础模型的感知优势来分析渲染图像并迭代地优化场景。在这个过程之上，SceneCraft具备一个库学习机制，将常见的脚本函数编译为可重复使用的库，促进持续的自我

    arXiv:2403.01248v1 Announce Type: cross  Abstract: This paper introduces SceneCraft, a Large Language Model (LLM) Agent converting text descriptions into Blender-executable Python scripts which render complex scenes with up to a hundred 3D assets. This process requires complex spatial planning and arrangement. We tackle these challenges through a combination of advanced abstraction, strategic planning, and library learning. SceneCraft first models a scene graph as a blueprint, detailing the spatial relationships among assets in the scene. SceneCraft then writes Python scripts based on this graph, translating relationships into numerical constraints for asset layout. Next, SceneCraft leverages the perceptual strengths of vision-language foundation models like GPT-V to analyze rendered images and iteratively refine the scene. On top of this process, SceneCraft features a library learning mechanism that compiles common script functions into a reusable library, facilitating continuous self
    
[^94]: 使用自我生成的复述来减轻大型语言模型中的灾难性遗忘

    Mitigating Catastrophic Forgetting in Large Language Models with Self-Synthesized Rehearsal

    [https://arxiv.org/abs/2403.01244](https://arxiv.org/abs/2403.01244)

    提出了一种称为Self-Synthesized Rehearsal（SSR）的框架，利用大型语言模型生成合成实例用于持续学习中的复述，以解决大型语言模型遭受灾难性遗忘的问题。

    

    大型语言模型（LLMs）在持续学习过程中遭受灾难性遗忘。传统的基于复述的方法依赖于先前的训练数据来保留模型的能力，然而这在现实应用中可能无法实现。为了解决这一挑战，我们提出了一个名为自我生成复述（SSR）的框架，利用LLM生成合成实例进行复述。

    arXiv:2403.01244v1 Announce Type: cross  Abstract: Large language models (LLMs) suffer from catastrophic forgetting during continual learning. Conventional rehearsal-based methods rely on previous training data to retain the model's ability, which may not be feasible in real-world applications. When conducting continual learning based on a publicly-released LLM checkpoint, the availability of the original training data may be non-existent. To address this challenge, we propose a framework called Self-Synthesized Rehearsal (SSR) that uses the LLM to generate synthetic instances for rehearsal. Concretely, we first employ the base LLM for in-context learning to generate synthetic instances. Subsequently, we utilize the latest LLM to refine the instance outputs based on the synthetic inputs, preserving its acquired ability. Finally, we select diverse high-quality synthetic instances for rehearsal in future stages. Experimental results demonstrate that SSR achieves superior or comparable pe
    
[^95]: 用机器学习增强自动化：基于意图的用户指令分类

    Augmenting Automation: Intent-Based User Instruction Classification with Machine Learning

    [https://arxiv.org/abs/2403.01242](https://arxiv.org/abs/2403.01242)

    提出了一种通过引入基于意图的用户指令分类和机器学习技术的新颖方法，从而增强自动化系统的灵活性和适应性。

    

    电动自动化系统在控制电路和设备时提供了方便和效率。传统上，这些系统依赖预定义的命令进行控制，限制了灵活性和适应性。本文提出了一种新颖的方法，通过引入基于意图的用户指令分类和机器学习技术来增强自动化。我们的系统将用户指令表示为意图，允许在不依赖预定义命令的情况下动态控制电路。通过训练在标记的用户指令数据集上的机器学习模型，我们的系统可以从用户输入中对意图进行分类，从而实现更直观和可适应的控制方案。我们展示了基于意图的电动自动化系统的设计和实现，详细说明了用于意图分类的机器学习模型的开发。实验结果证明了我们方法的有效性。

    arXiv:2403.01242v1 Announce Type: cross  Abstract: Electric automation systems offer convenience and efficiency in controlling electrical circuits and devices. Traditionally, these systems rely on predefined commands for control, limiting flexibility and adaptability. In this paper, we propose a novel approach to augment automation by introducing intent-based user instruction classification using machine learning techniques. Our system represents user instructions as intents, allowing for dynamic control of electrical circuits without relying on predefined commands. Through a machine learning model trained on a labeled dataset of user instructions, our system classifies intents from user input, enabling a more intuitive and adaptable control scheme. We present the design and implementation of our intent-based electric automation system, detailing the development of the machine learning model for intent classification. Experimental results demonstrate the effectiveness of our approach i
    
[^96]: IntactKV: 通过保持关键标记完整改进大型语言模型量化

    IntactKV: Improving Large Language Model Quantization by Keeping Pivot Tokens Intact

    [https://arxiv.org/abs/2403.01241](https://arxiv.org/abs/2403.01241)

    本研究提出了IntactKV方法，通过保持关键标记的完整性，改善了大型语言模型的量化过程，进一步降低了量化误差的上限，并取得了显著的性能提升。

    

    大型语言模型在自然语言处理方面表现出色，但需要大量计算。为了减少这一难题，人们已经探索了各种量化方法，然而这些方法会损害大型语言模型的性能。本文揭示了大型语言模型中一个以前被忽视的异常点类型。这些异常点被发现将大部分注意力分配给输入的初始标记，被称为关键标记，这对于量化的大型语言模型的性能至关重要。鉴于此，我们提出了IntactKV，从完整精度模型中无损地生成关键标记的KV缓存。这种方法简单易行，可以轻松与现有的量化解决方案结合。此外，IntactKV可以被校准为额外的大型语言模型参数，以进一步增强量化的大型语言模型。数学分析还证明了IntactKV有效地降低了量化误差的上限。实证结果表明，IntactKV带来了持续的改进，并实现了无损的仅权重量。

    arXiv:2403.01241v1 Announce Type: cross  Abstract: Large language models (LLMs) excel in natural language processing but demand intensive computation. To mitigate this, various quantization methods have been explored, yet they compromise LLM performance. This paper unveils a previously overlooked type of outlier in LLMs. Such outliers are found to allocate most of the attention scores on initial tokens of input, termed as pivot tokens, which is crucial to the performance of quantized LLMs. Given that, we propose IntactKV to generate the KV cache of pivot tokens losslessly from the full-precision model. The approach is simple and easy to combine with existing quantization solutions. Besides, IntactKV can be calibrated as additional LLM parameters to boost the quantized LLMs further. Mathematical analysis also proves that IntactKV effectively reduces the upper bound of quantization error. Empirical results show that IntactKV brings consistent improvement and achieves lossless weight-only
    
[^97]: NLP中的情感分析：趋势、差距和未来方向路线

    Emotion Analysis in NLP: Trends, Gaps and Roadmap for Future Directions

    [https://arxiv.org/abs/2403.01222](https://arxiv.org/abs/2403.01222)

    NLP中情感分析领域存在着趋势和差距，未来方向需考虑情感任务定义、情感框架、情感主观性与NLP应用。

    

    情绪是沟通的一个中心方面。因此，情感分析（EA）是自然语言处理（NLP）中一个迅速发展的领域。然而，关于范围、方向或方法，尚无共识。在本文中，我们对过去十年中的154篇相关NLP出版物进行了彻底审查。基于此审查，我们对四个不同的问题进行了探讨：（1）NLP中如何定义EA任务？（2）什么是最突出的情感框架，以及哪些情感被建模？（3）在人口统计和文化因素方面是否考虑了情绪的主观性？以及（4）EA的主要NLP应用是什么？我们总结了EA和任务、使用的情感框架、现有数据集、方法和应用的趋势。然后我们讨论了四个空白：（1）缺乏人口统计和文化因素，并未考虑到不同文化如何感知情绪的差异，而是假设它们是普遍经历的。

    arXiv:2403.01222v1 Announce Type: new  Abstract: Emotions are a central aspect of communication. Consequently, emotion analysis (EA) is a rapidly growing field in natural language processing (NLP). However, there is no consensus on scope, direction, or methods. In this paper, we conduct a thorough review of 154 relevant NLP publications from the last decade. Based on this review, we address four different questions: (1) How are EA tasks defined in NLP? (2) What are the most prominent emotion frameworks and which emotions are modeled? (3) Is the subjectivity of emotions considered in terms of demographics and cultural factors? and (4) What are the primary NLP applications for EA? We take stock of trends in EA and tasks, emotion frameworks used, existing datasets, methods, and applications. We then discuss four lacunae: (1) the absence of demographic and cultural aspects does not account for the variation in how emotions are perceived, but instead assumes they are universally experienced
    
[^98]: API就够了：无需对数访问的大型语言模型的整体预测

    API Is Enough: Conformal Prediction for Large Language Models Without Logit-Access

    [https://arxiv.org/abs/2403.01216](https://arxiv.org/abs/2403.01216)

    本研究提出了一种针对无需访问对数的API-only LLMs的整体预测方法，旨在最小化预测集大小并确保用户定义的覆盖范围的统计保证。

    

    本研究旨在解决无法访问对数时如何量化大型语言模型（LLMs）中的不确定性这一普遍挑战。整体预测（CP）以其与模型无关和无需分布的特点而闻名，是各种LLMs和数据分布的理想方法。然而，现有的LLMs整体预测方法通常假定可以访问对数，这对于一些仅支持API的LLMs来说是不可用的。此外，已知对数可能存在校准不准确的问题，可能导致整体预测性能下降。为了应对这些挑战，我们提出一种新颖的CP方法，（1）专为无需对数访问的API-only LLMs量身定制; (2) 最小化预测集的大小; 以及(3)确保用户定义的覆盖范围具有统计保证。该方法的核心思想是利用粗粒度（例如，样本频率）和细粒度不确定性概念（例如，语义相似性）来制定不一致性度量。实验结果表明，

    arXiv:2403.01216v1 Announce Type: cross  Abstract: This study aims to address the pervasive challenge of quantifying uncertainty in large language models (LLMs) without logit-access. Conformal Prediction (CP), known for its model-agnostic and distribution-free features, is a desired approach for various LLMs and data distributions. However, existing CP methods for LLMs typically assume access to the logits, which are unavailable for some API-only LLMs. In addition, logits are known to be miscalibrated, potentially leading to degraded CP performance. To tackle these challenges, we introduce a novel CP method that (1) is tailored for API-only LLMs without logit-access; (2) minimizes the size of prediction sets; and (3) ensures a statistical guarantee of the user-defined coverage. The core idea of this approach is to formulate nonconformity measures using both coarse-grained (i.e., sample frequency) and fine-grained uncertainty notions (e.g., semantic similarity). Experimental results on 
    
[^99]: 伪标签校准半监督多模态实体对齐

    Pseudo-Label Calibration Semi-supervised Multi-Modal Entity Alignment

    [https://arxiv.org/abs/2403.01203](https://arxiv.org/abs/2403.01203)

    本研究提出了一种伪标签校准的半监督多模态实体对齐方法，通过引入互信息最大化来过滤模态特定噪音，增强模态不变性共性。

    

    多模态实体对齐(MMEA)旨在识别两个多模态知识图之间的等价实体，以进行整合。不幸的是，之前的研究试图改进多模态信息的交互和融合，却忽视了模态特定噪音在半监督设置中标记和未标记数据的影响。在这项工作中，我们介绍了一种半监督的伪标签校准多模态实体对齐(PCMEA)方法。具体来说，为了生成全面的实体表示，我们首先设计了各种嵌入模块和注意机制来提取视觉、结构、关系和属性特征。接着，我们提出利用互信息最大化来过滤模态特定噪音并增强模态不变性共性。然后，我们将伪标签校准与基于动量的对比融合方法结合起来。

    arXiv:2403.01203v1 Announce Type: cross  Abstract: Multi-modal entity alignment (MMEA) aims to identify equivalent entities between two multi-modal knowledge graphs for integration. Unfortunately, prior arts have attempted to improve the interaction and fusion of multi-modal information, which have overlooked the influence of modal-specific noise and the usage of labeled and unlabeled data in semi-supervised settings. In this work, we introduce a Pseudo-label Calibration Multi-modal Entity Alignment (PCMEA) in a semi-supervised way. Specifically, in order to generate holistic entity representations, we first devise various embedding modules and attention mechanisms to extract visual, structural, relational, and attribute features. Different from the prior direct fusion methods, we next propose to exploit mutual information maximization to filter the modal-specific noise and to augment modal-invariant commonality. Then, we combine pseudo-label calibration with momentum-based contrastive
    
[^100]: DMoERM: 有效奖励建模的混合专家配方

    DMoERM: Recipes of Mixture-of-Experts for Effective Reward Modeling

    [https://arxiv.org/abs/2403.01197](https://arxiv.org/abs/2403.01197)

    DMoERM首次将专家混合（MoE）的概念引入奖励建模领域，提出了双层MoE RM（DMoERM），通过稀疏的外层MoE和密集的内层MoE对特定任务进行微调，解决了训练中的多任务干扰和数据噪声问题。

    

    奖励模型（RM）的性能是改善大型语言模型（LLM）在对齐微调过程中效果的关键因素。 RM训练仍然存在两个挑战：1）使用各种类别数据训练相同的RM可能导致其泛化性能受到多任务干扰的影响；2）人类注释的一致性率通常仅为60%至75%，导致训练数据包含大量噪声。 为了解决这两个挑战，我们首次将专家混合（MoE）的概念引入到RM领域。 我们提出了双层MoE RM（DMoERM）。 外层MoE是一种稀疏模型。 将输入分类成任务类别后，我们将其路由到相应的内层任务特定模型中。 内层MoE是一种密集模型。 我们将特定任务分解为多个能力维度，并分别在每个维度上对LoRA专家进行微调。

    arXiv:2403.01197v1 Announce Type: new  Abstract: The performance of the reward model (RM) is a critical factor in improving the effectiveness of the large language model (LLM) during alignment fine-tuning. There remain two challenges in RM training: 1) training the same RM using various categories of data may cause its generalization performance to suffer from multi-task disturbance, and 2) the human annotation consistency rate is generally only $60\%$ to $75\%$, causing training data to contain a lot of noise. To tackle these two challenges, we introduced the idea of Mixture-of-Experts (MoE) into the field of RM for the first time. We propose the Double-Layer MoE RM (DMoERM). The outer layer MoE is a sparse model. After classifying an input into task categories, we route it to the corresponding inner layer task-specific model. The inner layer MoE is a dense model. We decompose the specific task into multiple capability dimensions and individually fine-tune a LoRA expert on each one. T
    
[^101]: Covid领域的机器翻译：LoResMT 2021中英爱尔兰语案例研究

    Machine Translation in the Covid domain: an English-Irish case study for LoResMT 2021

    [https://arxiv.org/abs/2403.01196](https://arxiv.org/abs/2403.01196)

    在LoResMT 2021中，针对Covid数据从英语到爱尔兰语的翻译，通过使用领域自适应技术和扩展领域内Covid数据集训练Transformer架构，成功改善了翻译表现。

    

    本文针对从英语到爱尔兰语翻译Covid数据的特定领域，开发了LoResMT 2021共享任务的翻译模型。利用来自翻译总司指导处的Covid适配通用55k语料库进行域自适应技术的应用。将微调、混合微调和组合数据集方法与在扩展的领域内数据集上训练的模型进行了比较。作为研究的一部分，开发了一份健康和教育领域的英语-爱尔兰语Covid相关数据集。表现最佳的模型采用了使用扩展的领域内Covid数据集训练的Transformer架构。在本研究中，我们证明扩展8k领域内基准数据集只需再增加5k行，就将BLEU分数提高了27个点。

    arXiv:2403.01196v1 Announce Type: cross  Abstract: Translation models for the specific domain of translating Covid data from English to Irish were developed for the LoResMT 2021 shared task. Domain adaptation techniques, using a Covid-adapted generic 55k corpus from the Directorate General of Translation, were applied. Fine-tuning, mixed fine-tuning and combined dataset approaches were compared with models trained on an extended in-domain dataset. As part of this study, an English-Irish dataset of Covid related data, from the Health and Education domains, was developed. The highest-performing model used a Transformer architecture trained with an extended in-domain Covid dataset. In the context of this study, we have demonstrated that extending an 8k in-domain baseline dataset by just 5k lines improved the BLEU score by 27 points.
    
[^102]: RAGged Edges: Retrieval-Augmented Chatbots的双刃剑

    RAGged Edges: The Double-Edged Sword of Retrieval-Augmented Chatbots

    [https://arxiv.org/abs/2403.01193](https://arxiv.org/abs/2403.01193)

    本文探讨了如何利用检索增强生成（RAG）抵制大型语言模型（LLMs）产生的幻觉，结果表明RAG在某些情况下可以提高准确性，但仍需要更强大的解决方案以确保LLMs在实际应用中可靠性。

    

    大型语言模型（LLMs）如ChatGPT展示了人工智能的显著进展。然而，它们倾向于产生幻觉 - 生成看似正确但错误信息的倾向带来了重大挑战。这个问题很关键，就像最近的法院案例中看到的那样，ChatGPT的使用导致了不存在的法律裁决的引用。本文探讨了如何通过将外部知识与提示集成来使用检索增强生成（RAG）来抵制幻觉。我们通过使用旨在诱导幻觉的提示来对RAG与标准LLMs进行经验评估。我们的结果显示，在某些情况下，RAG可以提高准确性，但当提示直接与模型预训练的理解相矛盾时，RAG仍然会被误导。这些发现突显了幻觉的复杂性以及需要更强大的解决方案以确保LLMs在实际应用中可靠性。我们提供了RAG部署的实用建议。

    arXiv:2403.01193v1 Announce Type: cross  Abstract: Large language models (LLMs) like ChatGPT demonstrate the remarkable progress of artificial intelligence. However, their tendency to hallucinate -- generate plausible but false information -- poses a significant challenge. This issue is critical, as seen in recent court cases where ChatGPT's use led to citations of non-existent legal rulings. This paper explores how Retrieval-Augmented Generation (RAG) can counter hallucinations by integrating external knowledge with prompts. We empirically evaluate RAG against standard LLMs using prompts designed to induce hallucinations. Our results show that RAG increases accuracy in some cases, but can still be misled when prompts directly contradict the model's pre-trained understanding. These findings highlight the complex nature of hallucinations and the need for more robust solutions to ensure LLM reliability in real-world applications. We offer practical recommendations for RAG deployment and 
    
[^103]: 通用依存关系的组合式类型语义

    A Compositional Typed Semantics for Universal Dependencies

    [https://arxiv.org/abs/2403.01187](https://arxiv.org/abs/2403.01187)

    UD类型演算是一个基于广泛使用的语言通用依存句法框架的语义类型和逻辑形式的组合、原则性和与语言无关系统，通过利用依存标签推导具有各种句法结构的句子的正确含义。

    

    语言可能使用不同的句子结构来编码类似的含义。这使得提供一个可以一次性从多种语言句子中推导含义的单一形式规则集变得具有挑战性。为了克服这一挑战，我们可以利用语言通用的意义和句法之间的联系，构建跨语言平行的句法结构。我们引入了UD类型演算，这是一个基于广泛使用的语言通用依存句法框架的语义类型和逻辑形式的组合、原则性和与语言无关系统。我们解释了UD类型演算的基本特征，这些特征都涉及给予依存关系与单词类似的指称。这使得UD-TC能够通过利用依存标签推导具有各种句法结构的句子的正确含义。最后，我们在一个大型现有语料库上呈现评估结果。

    arXiv:2403.01187v1 Announce Type: new  Abstract: Languages may encode similar meanings using different sentence structures. This makes it a challenge to provide a single set of formal rules that can derive meanings from sentences in many languages at once. To overcome the challenge, we can take advantage of language-general connections between meaning and syntax, and build on cross-linguistically parallel syntactic structures. We introduce UD Type Calculus, a compositional, principled, and language-independent system of semantic types and logical forms for lexical items which builds on a widely-used language-general dependency syntax framework. We explain the essential features of UD Type Calculus, which all involve giving dependency relations denotations just like those of words. These allow UD-TC to derive correct meanings for sentences with a wide range of syntactic structures by making use of dependency labels. Finally, we present evaluation results on a large existing corpus of se
    
[^104]: 在LLM中使用Soft RLLF实现探索和开发的平衡，以增强否定理解

    Balancing Exploration and Exploitation in LLM using Soft RLLF for Enhanced Negation Understanding

    [https://arxiv.org/abs/2403.01185](https://arxiv.org/abs/2403.01185)

    通过利用逻辑反馈的强化学习（RLLF）在LLMs中实现探索和开发的平衡，以增强否定理解能力，并通过比较性能验证了这种平衡方法的价值。

    

    在NLP中，调整方法通常侧重于开发而不是探索，这可能导致次优模型。考虑到自然语言的广阔搜索空间，这种有限的探索可能限制它们在复杂、高风险领域中的表现，那里准确的否定理解和逻辑推理能力至关重要。为解决这一问题，我们利用逻辑反馈的强化学习（RLLF）在LLMs中实现探索和开发的有效平衡。我们的方法采用适当的基准数据集进行训练和评估，突出了通过增强否定理解能力来强调探索的重要性。我们将使用RLLF增强的LLMs的性能与未使用RLLF训练的基线模型进行比较，展示了这种平衡方法的价值。此外，我们通过迁移学习展示了我们的方法在法律AI应用中的潜力，并进行了评价。

    arXiv:2403.01185v1 Announce Type: cross  Abstract: Finetuning approaches in NLP often focus on exploitation rather than exploration, which may lead to suboptimal models. Given the vast search space of natural language, this limited exploration can restrict their performance in complex, high-stakes domains, where accurate negation understanding and logical reasoning abilities are crucial. To address this issue, we leverage Reinforcement Learning from Logical Feedback (RLLF) to create an effective balance between exploration and exploitation in LLMs. Our approach employs an appropriate benchmark dataset for training and evaluation, highlighting the importance of exploration in enhancing negation understanding capabilities. We compare the performance of our RLLF-enhanced LLMs with baseline models trained without RLLF, demonstrating the value of this balanced approach. Furthermore, we showcase the potential of our method in legal AI applications by employing transfer learning and evaluatin
    
[^105]: DINER：使用多变量因果推断来去偏方面级情感分析

    DINER: Debiasing Aspect-based Sentiment Analysis with Multi-variable Causal Inference

    [https://arxiv.org/abs/2403.01166](https://arxiv.org/abs/2403.01166)

    本论文提出了一种基于多变量因果推断的新框架，用于去偏方面级情感分析，从而解决神经网络模型学习虚假相关性的问题。

    

    尽管取得了显著进展，基于神经网络的方面级情感分析（ABSA）模型容易从注释偏见中学习到虚假相关性，导致在对抗性数据转换上鲁棒性较差。在去偏解决方案中，基于因果推断的方法引起了许多研究关注，主要可分为因果干预方法和反事实推理方法。然而，目前大多数去偏方法都集中在单变量因果推断上，这对于具有两个输入变量（目标方面和评论）的ABSA并不适用。在本文中，我们提出了一个基于多变量因果推断的新框架用于去偏ABSA。在这个框架中，不同类型的偏见基于不同的因果干预方法得到处理。对于评论分支，偏见被建模为来自上下文的间接混杂，其中实施反向调整干预。

    arXiv:2403.01166v1 Announce Type: cross  Abstract: Though notable progress has been made, neural-based aspect-based sentiment analysis (ABSA) models are prone to learn spurious correlations from annotation biases, resulting in poor robustness on adversarial data transformations. Among the debiasing solutions, causal inference-based methods have attracted much research attention, which can be mainly categorized into causal intervention methods and counterfactual reasoning methods. However, most of the present debiasing methods focus on single-variable causal inference, which is not suitable for ABSA with two input variables (the target aspect and the review). In this paper, we propose a novel framework based on multi-variable causal inference for debiasing ABSA. In this framework, different types of biases are tackled based on different causal intervention methods. For the review branch, the bias is modeled as indirect confounding from context, where backdoor adjustment intervention is 
    
[^106]: STAR: 使用动态主动学习约束LoRA，实现大型语言模型数据高效微调

    STAR: Constraint LoRA with Dynamic Active Learning for Data-Efficient Fine-Tuning of Large Language Models

    [https://arxiv.org/abs/2403.01165](https://arxiv.org/abs/2403.01165)

    本论文提出了一种新颖的方法，有效地将基于不确定性的主动学习和LoRA相结合，以解决大型语言模型数据高效微调中遇到的问题。

    

    大型语言模型(LLMs)通过提示方法展示了少样本学习的强大能力，但对于复杂推理任务仍需监督训练。针对LLMs的参数众多和内存消耗大问题，分别提出了参数高效微调(PEFT)方法和内存高效微调方法。然而，数据高效微调旨在解决大量注释数据消耗的问题，却鲜有研究。一种明显的方式是将PEFT方法与主动学习相结合。然而，实验结果表明这种组合并非简单，并产生较差的结果。通过探针实验，这一观察结果可能由两个主要原因解释：不确定性差距和模型校准不佳。因此，在本文中，我们提出了一种新颖的方法，有效地将基于不确定性的主动学习和LoRA进行整合。

    arXiv:2403.01165v1 Announce Type: cross  Abstract: Though Large Language Models (LLMs) have demonstrated the powerful capabilities of few-shot learning through prompting methods, supervised training is still necessary for complex reasoning tasks. Because of their extensive parameters and memory consumption, both Parameter-Efficient Fine-Tuning (PEFT) methods and Memory-Efficient Fine-Tuning methods have been proposed for LLMs. Nevertheless, the issue of large annotated data consumption, the aim of Data-Efficient Fine-Tuning, remains unexplored. One obvious way is to combine the PEFT method with active learning. However, the experimental results show that such a combination is not trivial and yields inferior results. Through probe experiments, such observation might be explained by two main reasons: uncertainty gap and poor model calibration. Therefore, in this paper, we propose a novel approach to effectively integrate uncertainty-based active learning and LoRA. Specifically, for the u
    
[^107]: 通过对齐多样化回复来引导任务导向对话表示的BootstrapTOD

    BootTOD: Bootstrap Task-oriented Dialogue Representations by Aligning Diverse Responses

    [https://arxiv.org/abs/2403.01163](https://arxiv.org/abs/2403.01163)

    BootTOD通过自助引导框架学习任务导向对话表示，消除了对比对的要求，并使用多个回复目标来模拟人类对话的多样性。

    

    预训练语言模型在许多场景中取得了成功。然而，在任务导向对话中，由于通用文本和任务导向对话之间固有的语言差异，它们的实用性受到限制。当前的任务导向对话预训练方法依赖于对比框架，面临着诸如选择真正例和难负例，以及缺乏多样性等挑战。本文提出了一种称为BootTOD的新型对话预训练模型。它通过自助引导框架学习任务导向对话表示。与对比对应物相反，BootTOD通过对齐上下文和上下文+回复表示来消除对比对的要求。BootTOD还使用多个适当的回复目标来建模人类对话固有的一对多多样性。实验结果表明BootTOD在多样的下游对话任务上优于强大的TOD基线。

    arXiv:2403.01163v1 Announce Type: new  Abstract: Pre-trained language models have been successful in many scenarios. However, their usefulness in task-oriented dialogues is limited due to the intrinsic linguistic differences between general text and task-oriented dialogues. Current task-oriented dialogue pre-training methods rely on a contrastive framework, which faces challenges such as selecting true positives and hard negatives, as well as lacking diversity. In this paper, we propose a novel dialogue pre-training model called BootTOD. It learns task-oriented dialogue representations via a self-bootstrapping framework. Unlike contrastive counterparts, BootTOD aligns context and context+response representations and dismisses the requirements of contrastive pairs. BootTOD also uses multiple appropriate response targets to model the intrinsic one-to-many diversity of human conversations. Experimental results show that BootTOD outperforms strong TOD baselines on diverse downstream dialog
    
[^108]: AI生成文本取证系统综述：检测、归因和特征化

    A Survey of AI-generated Text Forensic Systems: Detection, Attribution, and Characterization

    [https://arxiv.org/abs/2403.01152](https://arxiv.org/abs/2403.01152)

    本文综述了AI生成文本取证系统，重点讨论了检测、归因和特征化三个主要方面，以实现对AI生成文本的实际理解。

    

    我们最近目击了一系列先进的大型语言模型（LLMs）的快速增长，这些模型能够生成高质量的文本。尽管这些LLMs已经在各个领域彻底改变了文本生成，但它们也带来了信息生态系统中的重大风险，比如可能大规模生成令人信服的宣传、错误信息和谣言。本文提供了对AI生成文本取证系统的综述，这是一个应对LLM滥用挑战的新兴领域。我们通过介绍一个详细的分类法，着重介绍了AI生成文本取证领域现有的努力，着眼于三个主要支柱：检测、归因和特征化。这些支柱使人们能够实际理解AI生成的文本，包括识别AI生成内容（检测）、确定涉及的具体AI模型（归因）以及对文本的基本意图进行分类（特征化）。

    arXiv:2403.01152v1 Announce Type: cross  Abstract: We have witnessed lately a rapid proliferation of advanced Large Language Models (LLMs) capable of generating high-quality text. While these LLMs have revolutionized text generation across various domains, they also pose significant risks to the information ecosystem, such as the potential for generating convincing propaganda, misinformation, and disinformation at scale. This paper offers a review of AI-generated text forensic systems, an emerging field addressing the challenges of LLM misuses. We present an overview of the existing efforts in AI-generated text forensics by introducing a detailed taxonomy, focusing on three primary pillars: detection, attribution, and characterization. These pillars enable a practical understanding of AI-generated text, from identifying AI-generated content (detection), determining the specific AI model involved (attribution), and grouping the underlying intents of the text (characterization). Furtherm
    
[^109]: ParallelPARC: 生成自然语言类比的可扩展流水线

    ParallelPARC: A Scalable Pipeline for Generating Natural-Language Analogies

    [https://arxiv.org/abs/2403.01139](https://arxiv.org/abs/2403.01139)

    设计了ParallelPARC流水线，利用大型语言模型生成复杂段落类比数据集，评估各种类比类型，并展示出人类在类比识别中的优势。

    

    Analogy-making对于人类认知至关重要，使我们能够适应新颖情境--这是当前人工智能系统仍然缺乏的能力。大多数类比数据集今天关注简单的类比（例如，词类比）；包含复杂类型类比的数据集通常是手工策划的，并且非常小。我们认为这限制了计算类比的进展。在这项工作中，我们设计了一个数据生成流水线，ParallelPARC（Parallel Paragraph Creator），利用最先进的大型语言模型（LLM）来创建基于段落的复杂类比，以及简单和具有挑战性的干扰项。我们展示了我们的流水线，并创建了ProPara-Logy，一个关于科学过程间类比的数据集。我们发布了一个由人类验证过的金标准数据集，以及一个自动生成的银标准数据集。我们在二进制和多选环境中测试了LLMs和人类对类比的识别，发现人类胜过最佳模型。

    arXiv:2403.01139v1 Announce Type: cross  Abstract: Analogy-making is central to human cognition, allowing us to adapt to novel situations -- an ability that current AI systems still lack. Most analogy datasets today focus on simple analogies (e.g., word analogies); datasets including complex types of analogies are typically manually curated and very small. We believe that this holds back progress in computational analogy. In this work, we design a data generation pipeline, ParallelPARC (Parallel Paragraph Creator) leveraging state-of-the-art Large Language Models (LLMs) to create complex, paragraph-based analogies, as well as distractors, both simple and challenging. We demonstrate our pipeline and create ProPara-Logy, a dataset of analogies between scientific processes. We publish a gold-set, validated by humans, and a silver-set, generated automatically. We test LLMs' and humans' analogy recognition in binary and multiple-choice settings, and found that humans outperform the best mod
    
[^110]: LLaMoCo：用于优化代码生成的大型语言模型指令调优

    LLaMoCo: Instruction Tuning of Large Language Models for Optimization Code Generation

    [https://arxiv.org/abs/2403.01131](https://arxiv.org/abs/2403.01131)

    LLaMoCo是第一个旨在以代码对代码方式调整LLMs以解决优化问题的指令调优框架，通过全面指令集和新颖的两阶段学习策略，实现了优越的性能。

    

    最近的研究探讨了使用大型语言模型（LLMs）进行优化，方法包括从LLMs迭代地寻找下一步解决方案，或直接提示LLMs以获取优化器。然而，这些方法存在固有限制，包括操作效率低、对提示设计敏感度高以及缺乏领域特定知识。我们介绍了LLaMoCo，这是第一个旨在以代码对代码方式调整LLMs以解决优化问题的指令调优框架。具体地，我们建立了一个包含清晰描述的问题提示和有效优化代码的全面指令集。然后我们开发了一种新颖的两阶段学习策略，在指令调优阶段之前，该策略整合了基于对比学习的热身过程，以增强模型微调期间的收敛行为。实验结果表明，通过我们的LLaMoCo精调的CodeGen（350M）模型达到了卓越的性能。

    arXiv:2403.01131v1 Announce Type: cross  Abstract: Recent research explores optimization using large language models (LLMs) by either iteratively seeking next-step solutions from LLMs or directly prompting LLMs for an optimizer. However, these approaches exhibit inherent limitations, including low operational efficiency, high sensitivity to prompt design, and a lack of domain-specific knowledge. We introduce LLaMoCo, the first instruction-tuning framework designed to adapt LLMs for solving optimization problems in a code-to-code manner. Specifically, we establish a comprehensive instruction set containing well-described problem prompts and effective optimization codes. We then develop a novel two-phase learning strategy that incorporates a contrastive learning-based warm-up procedure before the instruction-tuning phase to enhance the convergence behavior during model fine-tuning. The experiment results demonstrate that a CodeGen (350M) model fine-tuned by our LLaMoCo achieves superior 
    
[^111]: MulCogBench：用于评估中文和英文计算语言模型的多模式认知基准数据集

    MulCogBench: A Multi-modal Cognitive Benchmark Dataset for Evaluating Chinese and English Computational Language Models

    [https://arxiv.org/abs/2403.01116](https://arxiv.org/abs/2403.01116)

    MulCogBench是一个多模式认知基准数据集，旨在评估中文和英文计算语言模型。通过相似性编码分析发现，语言模型与人类认知数据之间存在显著相似性，并且这种相似性模式受数据模态和调节影响。

    

    arXiv:2403.01116v1 宣布类型: 新的 摘要: 最近，预训练的计算语言模型在利用人类认为是独有的语言能力方面取得了显著进展。它们的成功引起了人们对这些模型是否像人类一样表示和处理语言的兴趣。为了回答这个问题，本文提出了MulCogBench，这是一个从母语为中文和英文的参与者那里收集的多模式认知基准数据集。它包含各种认知数据，包括主观语义评分，眼动追踪，功能磁共振成像（fMRI）和巨磁脑电图（MEG）。为了评估语言模型与认知数据之间的关系，我们进行了一项相似性编码分析，该分析根据其与文本嵌入的模式相似性对认知数据进行解码。结果显示，语言模型与人类认知数据共享显著相似性，并且相似性模式受数据模态的调节。

    arXiv:2403.01116v1 Announce Type: new  Abstract: Pre-trained computational language models have recently made remarkable progress in harnessing the language abilities which were considered unique to humans. Their success has raised interest in whether these models represent and process language like humans. To answer this question, this paper proposes MulCogBench, a multi-modal cognitive benchmark dataset collected from native Chinese and English participants. It encompasses a variety of cognitive data, including subjective semantic ratings, eye-tracking, functional magnetic resonance imaging (fMRI), and magnetoencephalography (MEG). To assess the relationship between language models and cognitive data, we conducted a similarity-encoding analysis which decodes cognitive data based on its pattern similarity with textual embeddings. Results show that language models share significant similarities with human cognitive data and the similarity patterns are modulated by the data modality and
    
[^112]: 通过从大型语言模型中自我解释提炼文本风格转移

    Distilling Text Style Transfer With Self-Explanation From LLMs

    [https://arxiv.org/abs/2403.01106](https://arxiv.org/abs/2403.01106)

    CoTeX是一个利用大型语言模型和思维链提示来促进文本风格转移的框架，通过提炼LLMs的能力为处理非平行数据和平行数据的简化模型，在低资源情况下表现优于传统的监督微调和知识蒸馏方法，并通过透明的解释在风格转移过程中有显著优势。

    

    文本风格转移（TST）旨在改变文本的风格同时保留其核心内容。鉴于TST的有限平行数据集的限制，我们提出了CoTeX，这是一个利用大型语言模型（LLMs）和思维链（CoT）提示来促进TST的框架。CoTeX将LLMs的复杂重写和推理能力提炼成更简化的模型，能够处理非平行数据和平行数据。通过在四个TST数据集上的实验，CoTeX显示出超越传统监督微调和知识蒸馏方法的能力，特别是在资源匮乏的情况下。我们进行了全面评估，将CoTeX与当前的无监督、监督、上下文学习（ICL）技术以及指导调整的LLMs进行了比较。此外，CoTeX通过提供透明的解释其风格转移过程而脱颖而出。

    arXiv:2403.01106v1 Announce Type: cross  Abstract: Text Style Transfer (TST) seeks to alter the style of text while retaining its core content. Given the constraints of limited parallel datasets for TST, we propose CoTeX, a framework that leverages large language models (LLMs) alongside chain-of-thought (CoT) prompting to facilitate TST. CoTeX distills the complex rewriting and reasoning capabilities of LLMs into more streamlined models capable of working with both non-parallel and parallel data. Through experimentation across four TST datasets, CoTeX is shown to surpass traditional supervised fine-tuning and knowledge distillation methods, particularly in low-resource settings. We conduct a comprehensive evaluation, comparing CoTeX against current unsupervised, supervised, in-context learning (ICL) techniques, and instruction-tuned LLMs. Furthermore, CoTeX distinguishes itself by offering transparent explanations for its style transfer process.
    
[^113]: LAB：针对ChatBots的大规模对齐

    LAB: Large-Scale Alignment for ChatBots

    [https://arxiv.org/abs/2403.01081](https://arxiv.org/abs/2403.01081)

    介绍了一种名为LAB的方法，旨在克服大型语言模型训练中的可扩展性挑战，通过分类法指导的合成数据生成和多阶段调整框架，实现了对昂贵人工标注和GPT-4等专有模型依赖较少的大规模对齐，提供了一种可扩展、具有成本效益的解决方案，不会出现灾难性遗忘情况，进一步增强了LLM的训练效率。

    

    这项工作介绍了LAB（ChatBots的大规模对齐），这是一种旨在克服大型语言模型（LLM）训练中指令调整阶段的可扩展性挑战的创新方法。通过利用基于分类法的合成数据生成过程和多阶段调整框架，LAB显著减少对昂贵的人类注释和诸如GPT-4之类的专有模型的依赖。我们证明，使用LAB训练的模型在几个基准测试中的性能可以与使用传统人类注释或GPT-4生成的合成数据训练的模型相比具有竞争力。因此，在不会出现灾难性遗忘的情况下，提供了一种可扩展、具有成本效益的解决方案，以增强LLM的能力和指令遵循行为，标志着在高效训练各种应用的LLM方面迈出了一步。

    arXiv:2403.01081v1 Announce Type: new  Abstract: This work introduces LAB (Large-scale Alignment for chatBots), a novel methodology designed to overcome the scalability challenges in the instruction-tuning phase of large language model (LLM) training. Leveraging a taxonomy-guided synthetic data generation process and a multi-phase tuning framework, LAB significantly reduces reliance on expensive human annotations and proprietary models like GPT-4. We demonstrate that LAB-trained models can achieve competitive performance across several benchmarks compared to models trained with traditional human-annotated or GPT-4 generated synthetic data. Thus offering a scalable, cost-effective solution for enhancing LLM capabilities and instruction-following behaviors without the drawbacks of catastrophic forgetting, marking a step forward in the efficient training of LLMs for a wide range of applications.
    
[^114]: LLMCRIT:教授大型语言模型使用标准

    LLMCRIT: Teaching Large Language Models to Use Criteria

    [https://arxiv.org/abs/2403.01069](https://arxiv.org/abs/2403.01069)

    提出了一个通用框架，使大型语言模型能够使用全面标准为任务提供自然语言反馈，并在论文引言写作、Python代码编写和Reddit帖子撰写等任务中进行了实证评估。

    

    人类在执行任务时遵循标准，这些标准直接用于评估任务完成的质量。因此，使模型学习使用标准提供反馈可以帮助人类或模型更好地执行任务。然而，现有研究往往只考虑有限的标准或质量评估方面。为了填补这一空白，我们提出了一个通用框架，使大型语言模型（LLMs）能够在完成任务时使用全面的标准提供自然语言反馈。具体来说，我们提出了一个模型-环路框架，从收集的不同写作任务指南中半自动地提取标准，并为每个标准构建上下文演示。我们选择了来自现实场景的三个任务来实现这一想法：论文引言写作、Python代码编写和Reddit帖子撰写，并评估我们的反馈生成。

    arXiv:2403.01069v1 Announce Type: new  Abstract: Humans follow criteria when they execute tasks, and these criteria are directly used to assess the quality of task completion. Therefore, having models learn to use criteria to provide feedback can help humans or models to perform tasks better. However, existing research in this field tends to consider only a limited set of criteria or quality assessment aspects. To fill this gap, we propose a general framework that enables large language models (LLMs) to use comprehensive criteria for a task in delivering natural language feedback on task execution. In particular, we present a model-in-the-loop framework that semi-automatically derives criteria from collected guidelines for different writing tasks and constructs in-context demonstrations for each criterion. We choose three tasks from real-world scenarios to operationalize this idea: paper introduction writing, Python code writing, and Reddit post writing, and evaluate our feedback gener
    
[^115]: FaiMA：针对多领域基于方面的情感分析的特征感知上下文学习

    FaiMA: Feature-aware In-context Learning for Multi-domain Aspect-based Sentiment Analysis

    [https://arxiv.org/abs/2403.01063](https://arxiv.org/abs/2403.01063)

    FaiMA提出了一种新的框架，利用特征感知的上下文学习作为自适应学习机制，用于多领域基于方面的情感分析任务。

    

    多领域基于方面的情感分析（ABSA）旨在捕捉跨多样领域的细粒度情感。尽管现有研究受到方法限制和数据稀缺的限制，狭窄地关注单一领域的应用，但现实情感自然地跨越多个领域。虽然大型语言模型（LLMs）为ABSA提供了有希望的解决方案，但由于难以有效与已建立的技术（包括基于图的模型和语言学）集成，因为修改它们的内部架构并不容易。为了缓解这个问题，我们提出了一个新颖的框架，即针对多领域ABSA的特征感知上下文学习（FaiMA）。FaiMA的核心见解是利用上下文学习（ICL）作为一种特征感知机制，促进多领域ABSA任务中的自适应学习。具体来说，我们采用了一个多头图注意力网络作为一个文本编码器，通过启发式规则来优化。

    arXiv:2403.01063v1 Announce Type: new  Abstract: Multi-domain aspect-based sentiment analysis (ABSA) seeks to capture fine-grained sentiment across diverse domains. While existing research narrowly focuses on single-domain applications constrained by methodological limitations and data scarcity, the reality is that sentiment naturally traverses multiple domains. Although large language models (LLMs) offer a promising solution for ABSA, it is difficult to integrate effectively with established techniques, including graph-based models and linguistics, because modifying their internal architecture is not easy. To alleviate this problem, we propose a novel framework, Feature-aware In-context Learning for Multi-domain ABSA (FaiMA). The core insight of FaiMA is to utilize in-context learning (ICL) as a feature-aware mechanism that facilitates adaptive learning in multi-domain ABSA tasks. Specifically, we employ a multi-head graph attention network as a text encoder optimized by heuristic rul
    
[^116]: 阅读潜台词：在短篇小说摘要上评估大型语言模型与作者合作

    Reading Subtext: Evaluating Large Language Models on Short Story Summarization with Writers

    [https://arxiv.org/abs/2403.01061](https://arxiv.org/abs/2403.01061)

    评估大型语言模型在短篇小说摘要上的表现，发现它们在忠实性和解释潜台词方面存在挑战，但在进行主题分析时表现出思考深度。

    

    我们评估了最近的大型语言模型（LLMs）在摘要长篇文学作品这一具有挑战性的任务上的表现，这些作品可能长度较长，并包含微妙的潜台词或错综复杂的时间线。重要的是，我们直接与作者合作，确保这些作品尚未在网络上分享过（因此对这些模型是未知的），并获得作者本人对摘要质量的明确评价。通过基于叙事理论的定量和定性分析，我们比较了GPT-4、Claude-2.1和LLama-2-70B。我们发现这三个模型在50%以上的摘要中会出现忠实性错误，并且难以解释难以理解的潜台词。然而，在最佳状态下，这些模型可以对故事进行有深度的主题分析。此外，我们还展示了LLMs对摘要质量的判断与作家的反馈不一致。

    arXiv:2403.01061v1 Announce Type: new  Abstract: We evaluate recent Large language Models (LLMs) on the challenging task of summarizing short stories, which can be lengthy, and include nuanced subtext or scrambled timelines. Importantly, we work directly with authors to ensure that the stories have not been shared online (and therefore are unseen by the models), and to obtain informed evaluations of summary quality using judgments from the authors themselves. Through quantitative and qualitative analysis grounded in narrative theory, we compare GPT-4, Claude-2.1, and LLama-2-70B. We find that all three models make faithfulness mistakes in over 50% of summaries and struggle to interpret difficult subtext. However, at their best, the models can provide thoughtful thematic analysis of stories. We additionally demonstrate that LLM judgments of summary quality do not match the feedback from the writers.
    
[^117]: 孔雀：一系列阿拉伯多模式大语言模型及基准

    Peacock: A Family of Arabic Multimodal Large Language Models and Benchmarks

    [https://arxiv.org/abs/2403.01031](https://arxiv.org/abs/2403.01031)

    介绍了一系列阿拉伯多模式大语言模型Peacock，展示了其在视觉推理任务上的出色性能和不断出现的方言潜力，并提出了一个用于评估阿拉伯语相关方面的新基准Henna

    

    多模式大语言模型（MLLMs）在需要复杂推理和语言理解的各种任务中已被证明有效。然而，由于除英语以外的其他语言缺乏高质量的多模式资源，MLLMs的成功仍然相对局限于英语环境。这给开发其他语言的可比较模型带来了重大挑战，甚至包括那些拥有庞大说话人口的语言，如阿拉伯语。为了缓解这一挑战，我们引入了一套综合的阿拉伯MLLMs系列，称为\textit{Peacock}，具有强大的视觉和语言能力。通过全面的定性和定量分析，我们展示了我们的模型在各种视觉推理任务上的出色性能，并进一步展示了它们不断出现的方言潜力。此外，我们还介绍了一个名为\textit{Henna}的新基准，专门用于评估MLLM在与阿拉伯语相关的方面。

    arXiv:2403.01031v1 Announce Type: cross  Abstract: Multimodal large language models (MLLMs) have proven effective in a wide range of tasks requiring complex reasoning and linguistic comprehension. However, due to a lack of high-quality multimodal resources in languages other than English, success of MLLMs remains relatively limited to English-based settings. This poses significant challenges in developing comparable models for other languages, including even those with large speaker populations such as Arabic. To alleviate this challenge, we introduce a comprehensive family of Arabic MLLMs, dubbed \textit{Peacock}, with strong vision and language capabilities. Through comprehensive qualitative and quantitative analysis, we demonstrate the solid performance of our models on various visual reasoning tasks and further show their emerging dialectal potential. Additionally, we introduce ~\textit{Henna}, a new benchmark specifically designed for assessing MLLMs on aspects related to Arabic c
    
[^118]: 属性结构化改进了基于LLM的临床文本摘要评估

    Attribute Structuring Improves LLM-Based Evaluation of Clinical Text Summaries

    [https://arxiv.org/abs/2403.01002](https://arxiv.org/abs/2403.01002)

    属性结构化框架显著改进了基于LLM的临床文本摘要评估过程，提高了人工评注和自动度量之间的一致性。

    

    在健康决策支持和临床研究中，总结临床文本至关重要。大型语言模型（LLMs）已经显示出生成准确的临床文本摘要的潜力，但仍然在与基础和评估相关的问题上存在困难，特别是在健康等安全关键领域。本文中，我们探讨了一种使用属性结构化（AS）作为通用缓解框架，该框架结构化了摘要评估过程。它将评估过程分解为一个基于LLM执行相对简单的结构化和评分任务，而不是完整的综合摘要评估任务。实验表明，AS始终改善了临床文本摘要中人类注释和自动度量之间的对应关系。此外，AS通过短文本形式提供了解释。

    arXiv:2403.01002v1 Announce Type: cross  Abstract: Summarizing clinical text is crucial in health decision-support and clinical research. Large language models (LLMs) have shown the potential to generate accurate clinical text summaries, but still struggle with issues regarding grounding and evaluation, especially in safety-critical domains such as health. Holistically evaluating text summaries is challenging because they may contain unsubstantiated information. Here, we explore a general mitigation framework using Attribute Structuring (AS), which structures the summary evaluation process. It decomposes the evaluation process into a grounded procedure that uses an LLM for relatively simple structuring and scoring tasks, rather than the full task of holistic summary evaluation. Experiments show that AS consistently improves the correspondence between human annotations and automated metrics in clinical text summarization. Additionally, AS yields interpretations in the form of a short te
    
[^119]: 语言模型在多项选择任务中的预测结果在评分方法变化下不稳健

    Predictions from language models for multiple-choice tasks are not robust under variation of scoring methods

    [https://arxiv.org/abs/2403.00998](https://arxiv.org/abs/2403.00998)

    本研究比较了不同方法对语言模型在多项选择任务中的项目级别预测的影响，发现LLM的预测结果在评分方法的变化下不稳健，这对确保结果的稳健性和研究诚信至关重要。

    

    本文系统地比较了不同的方法，用于从语言模型中推导多项选择任务的项目级别预测。它比较了基于自由生成回答、各种基于概率的分数、类似Likert量表风格的评分方法和嵌入相似性的答案选项评分方法。在一个关于语用语言解释的案例研究中，我们发现LLM的预测在选择方法变化下既在单个LLM内部又在不同的LLM之间并不稳健。由于这种变异导致研究者在报告结果时具有显著的自由度，了解这种变异对于确保结果的稳健性和研究诚信至关重要。

    arXiv:2403.00998v1 Announce Type: new  Abstract: This paper systematically compares different methods of deriving item-level predictions of language models for multiple-choice tasks. It compares scoring methods for answer options based on free generation of responses, various probability-based scores, a Likert-scale style rating method, and embedding similarity. In a case study on pragmatic language interpretation, we find that LLM predictions are not robust under variation of method choice, both within a single LLM and across different LLMs. As this variability entails pronounced researcher degrees of freedom in reporting results, knowledge of the variability is crucial to secure robustness of results and research integrity.
    
[^120]: 利用基于提示的大语言模型：通过社交媒体语言预测流行病健康决策和结果

    Leveraging Prompt-Based Large Language Models: Predicting Pandemic Health Decisions and Outcomes Through Social Media Language

    [https://arxiv.org/abs/2403.00994](https://arxiv.org/abs/2403.00994)

    该研究利用基于提示的大语言模型框架，研究了社交媒体语言模式与国家卫生趋势之间的关系，首次实现了将社交媒体语言模式与现实公共卫生趋势相联系的方法。

    

    我们引入了一个多步推理框架，使用基于提示的LLMs来研究社交媒体语言模式与国家健康结果趋势之间的关系。基于模糊轨迹理论，强调健康沟通中因果一致性要义的重要性，我们引入了基于角色的渐进辅导（RBIC），一个基于提示的LLM框架，以大规模识别要义。使用RBIC，我们系统地从反对COVID-19健康措施的subreddit讨论中提取要义（研究1）。然后我们跟踪这些要义在关键事件中的演变（研究2），并评估它们对在线互动的影响（研究3）。最后，我们研究要义量如何与国家健康趋势（如疫苗接种率和住院率）相关联（研究4）。我们的工作首次从实证角度将社交媒体语言模式与现实世界公共卫生趋势联系起来，突显了基于提示的潜力。

    arXiv:2403.00994v1 Announce Type: cross  Abstract: We introduce a multi-step reasoning framework using prompt-based LLMs to examine the relationship between social media language patterns and trends in national health outcomes. Grounded in fuzzy-trace theory, which emphasizes the importance of gists of causal coherence in effective health communication, we introduce Role-Based Incremental Coaching (RBIC), a prompt-based LLM framework, to identify gists at-scale. Using RBIC, we systematically extract gists from subreddit discussions opposing COVID-19 health measures (Study 1). We then track how these gists evolve across key events (Study 2) and assess their influence on online engagement (Study 3). Finally, we investigate how the volume of gists is associated with national health trends like vaccine uptake and hospitalizations (Study 4). Our work is the first to empirically link social media linguistic patterns to real-world public health trends, highlighting the potential of prompt-bas
    
[^121]: 使用LLMs进行时间轴构建的公式比较

    Formulation Comparison for Timeline Construction using LLMs

    [https://arxiv.org/abs/2403.00990](https://arxiv.org/abs/2403.00990)

    提出一种新颖的评估数据集TimeSET，以改善时间轴构建时的缺失时间信息问题，并通过比较多个任务公式，基于开放的LLMs评估时间轴构建系统。

    

    构建时间轴需要确定文章中事件的时间顺序。在以往的时间轴构建数据集中，事件的时间顺序通常通过事件到时间定位或事件到事件配对排序进行注释，这两种方法都存在缺失时间信息的问题。为了缓解这一问题，我们开发了一个新的评估数据集TimeSET，该数据集包括具有文档级顺序标注的单文档时间轴。TimeSET具有基于显著性的事件选择和部分排序，这使得注释工作量更加实用。为了构建更好的自动时间轴构建系统，我们提出了一个新颖的评估框架，通过提示开放的LLMs（Llama 2和Flan-T5）来比较多个任务公式和TimeSET。考虑到识别事件的时间顺序是时间轴构建中的核心子任务，我们进一步在现有事件时间排序数据集上对开放的LLMs进行基准测试。

    arXiv:2403.00990v1 Announce Type: new  Abstract: Constructing a timeline requires identifying the chronological order of events in an article. In prior timeline construction datasets, temporal orders are typically annotated by either event-to-time anchoring or event-to-event pairwise ordering, both of which suffer from missing temporal information. To mitigate the issue, we develop a new evaluation dataset, TimeSET, consisting of single-document timelines with document-level order annotation. TimeSET features saliency-based event selection and partial ordering, which enable a practical annotation workload. Aiming to build better automatic timeline construction systems, we propose a novel evaluation framework to compare multiple task formulations with TimeSET by prompting open LLMs, i.e., Llama 2 and Flan-T5. Considering that identifying temporal orders of events is a core subtask in timeline construction, we further benchmark open LLMs on existing event temporal ordering datasets to ga
    
[^122]: 合并来自不同初始化的文本变换器模型

    Merging Text Transformer Models from Different Initializations

    [https://arxiv.org/abs/2403.00986](https://arxiv.org/abs/2403.00986)

    研究了合并不同初始化的Transformer模型的技术，提出了一种模型合并技术以研究这些模型极小值之间的关系，并发现与模型平均相比，通过我们的方法合并这些模型始终可以获得较低的损失障碍。

    

    最近关于一次性基于排列的模型合并的工作表明，不同初始化的模型之间存在令人印象深刻的低或零障碍模连接。然而，尽管Transformer架构在语言领域中占主导地位，但这一领域的研究尚未延伸到Transformer架构。因此，在这项工作中，我们调查了独立Transformer极小值学习类似特征的程度，并提出了一种模型合并技术，以研究损失景观中这些极小值之间的关系。架构的具体细节，如其残差连接、多头注意力和离散的顺序输入，需要特定的干预措施，以便计算留在相同功能等价类中的模型排列。通过我们的方法合并这些模型，我们发现与对几个在一个maske上训练的模型进行模型平均相比，最小值之间的损失障碍一直较低。

    arXiv:2403.00986v1 Announce Type: cross  Abstract: Recent work on one-shot permutation-based model merging has shown impressive low- or zero-barrier mode connectivity between models from completely different initializations. However, this line of work has not yet extended to the Transformer architecture, despite its dominant popularity in the language domain. Therefore, in this work, we investigate the extent to which separate Transformer minima learn similar features, and propose a model merging technique to investigate the relationship between these minima in the loss landscape. The specifics of the architecture, like its residual connections, multi-headed attention, and discrete, sequential input, require specific interventions in order to compute model permutations that remain within the same functional equivalence class. In merging these models with our method, we consistently find lower loss barriers between minima compared to model averaging for several models trained on a maske
    
[^123]: 从生成数据到本地训练、测试和部署检索增强问答系统的LocalRQA

    LocalRQA: From Generating Data to Locally Training, Testing, and Deploying Retrieval-Augmented QA Systems

    [https://arxiv.org/abs/2403.00982](https://arxiv.org/abs/2403.00982)

    LocalRQA是一个开源工具包，提供多种模型训练算法、评估方法和部署工具，用于构建检索增强问答系统，其训练和部署的模型性能与使用OpenAI的text-ada-002和GPT-4-turbo相当。

    

    检索增强问答系统将检索技术与大型语言模型相结合，提供更准确和丰富信息的答案。许多现有工具包允许用户使用现成模型快速构建这种系统，但在支持研究人员和开发人员定制模型训练、测试和部署过程方面表现不佳。我们提出了一种名为LocalRQA的开源工具包，其中包含了从最新研究中精选的多种模型训练算法、评估方法和部署工具。作为一个展示，我们使用从Databricks和Faire网站获取的在线文档构建问答系统。我们发现使用LocalRQA训练和部署的7B模型在性能上与使用OpenAI的text-ada-002和GPT-4-turbo相当。

    arXiv:2403.00982v1 Announce Type: new  Abstract: Retrieval-augmented question-answering systems combine retrieval techniques with large language models to provide answers that are more accurate and informative. Many existing toolkits allow users to quickly build such systems using off-the-shelf models, but they fall short in supporting researchers and developers to customize the model training, testing, and deployment process. We propose LocalRQA, an open-source toolkit that features a wide selection of model training algorithms, evaluation methods, and deployment tools curated from the latest research. As a showcase, we build QA systems using online documentation obtained from Databricks and Faire's websites. We find 7B-models trained and deployed using LocalRQA reach a similar performance compared to using OpenAI's text-ada-002 and GPT-4-turbo.
    
[^124]: 在SemEval-2024任务6中的MALTO：利用合成数据检测LLM幻觉

    MALTO at SemEval-2024 Task 6: Leveraging Synthetic Data for LLM Hallucination Detection

    [https://arxiv.org/abs/2403.00964](https://arxiv.org/abs/2403.00964)

    引入了数据增强流水线和投票集成，利用合成数据检测LLM幻觉。

    

    在自然语言生成（NLG）中，当代大型语言模型（LLM）面临着一些挑战，例如生成流畅但不准确的输出以及依赖于流畅性为中心的度量。这经常导致神经网络出现“幻觉”。SHROOM挑战旨在自动识别生成文本中的这些幻觉。为了解决这些问题，我们引入了两个关键组件，一个数据增强流水线，包括LLM辅助的伪标记和句子改写，以及一个投票集成来自三个在自然语言推理（NLI）任务上预训练并在不同数据集上微调的模型。

    arXiv:2403.00964v1 Announce Type: new  Abstract: In Natural Language Generation (NLG), contemporary Large Language Models (LLMs) face several challenges, such as generating fluent yet inaccurate outputs and reliance on fluency-centric metrics. This often leads to neural networks exhibiting "hallucinations". The SHROOM challenge focuses on automatically identifying these hallucinations in the generated text. To tackle these issues, we introduce two key components, a data augmentation pipeline incorporating LLM-assisted pseudo-labelling and sentence rephrasing, and a voting ensemble from three models pre-trained on Natural Language Inference (NLI) tasks and fine-tuned on diverse datasets.
    
[^125]: AutoRD：一种基于本体增强的大型语言模型的罕见疾病知识图构建的自动化端到端系统

    AutoRD: An Automatic and End-to-End System for Rare Disease Knowledge Graph Construction Based on Ontologies-enhanced Large Language Models

    [https://arxiv.org/abs/2403.00953](https://arxiv.org/abs/2403.00953)

    AutoRD是一个自动化端到端系统，使用大型语言模型和医学知识图构建罕见疾病知识图，实现了整体F1得分47.3%，相对于基础LLM有14.4%的提升。

    

    目标：我们的目标是创建一个名为AutoRD的端到端系统，该系统自动从临床文本中提取有关罕见疾病的信息。我们进行了各种测试来评估AutoRD的性能，并在本文中强调了其优势和局限性。方法：我们的系统AutoRD是一个软件流水线，涉及数据预处理、实体提取、关系提取、实体校准和知识图构建。我们使用大型语言模型和由开源医学本体发展而来的医学知识图来实现这一目标。我们通过实体提取、关系提取以及知识图构建性能对系统进行定量评估。结果：AutoRD取得了47.3%的整体F1分数，较基础LLM提高了14.4%。具体来说，AutoRD实现了56.1%的整体实体提取F1分数（罕见疾病：83.5%，疾病：35.8%，s

    arXiv:2403.00953v1 Announce Type: cross  Abstract: Objectives: Our objective is to create an end-to-end system called AutoRD, which automates extracting information from clinical text about rare diseases. We have conducted various tests to evaluate the performance of AutoRD and highlighted its strengths and limitations in this paper.   Materials and Methods: Our system, AutoRD, is a software pipeline involving data preprocessing, entity extraction, relation extraction, entity calibration, and knowledge graph construction. We implement this using large language models and medical knowledge graphs developed from open-source medical ontologies. We quantitatively evaluate our system on entity extraction, relation extraction, and the performance of knowledge graph construction.   Results: AutoRD achieves an overall F1 score of 47.3%, a 14.4% improvement compared to the base LLM. In detail, AutoRD achieves an overall entity extraction F1 score of 56.1% (rare_disease: 83.5%, disease: 35.8%, s
    
[^126]: MediSwift：高效稀疏预训练生物医学语言模型

    MediSwift: Efficient Sparse Pre-trained Biomedical Language Models

    [https://arxiv.org/abs/2403.00952](https://arxiv.org/abs/2403.00952)

    MediSwift在生物医学领域引入了高效稀疏预训练模型，通过75%的权重稀疏性实现了2-2.5倍的训练FLOPs减少，从而显著提高了效率。

    

    大型语言模型（LLMs）通常在通用源数据上进行训练，用于各种领域，但最近领域特定的LLMs激增表明它们在领域特定任务（例如生物医学）中的潜力超过了通用型模型。虽然领域特定的预训练提高了效率并导致模型更小，但这些LLMs的训练计算成本仍然很高，构成了预算挑战。我们引入了MediSwift，一套利用领域特定生物医学文本数据上的稀疏预训练的生物医学LM。通过在预训练阶段引入高达75％的权重稀疏性，MediSwift在训练FLOPs方面实现了2-2.5倍的减少。值得注意的是，所有的稀疏预训练均在专门设计用于实现来自非结构化权重稀疏性的加速好处的Cerebras CS-2系统上进行，从而显着提高了MediSwift模型的效率。

    arXiv:2403.00952v1 Announce Type: new  Abstract: Large language models (LLMs) are typically trained on general source data for various domains, but a recent surge in domain-specific LLMs has shown their potential to outperform general-purpose models in domain-specific tasks (e.g., biomedicine). Although domain-specific pre-training enhances efficiency and leads to smaller models, the computational costs of training these LLMs remain high, posing budgeting challenges. We introduce MediSwift, a suite of biomedical LMs that leverage sparse pre-training on domain-specific biomedical text data. By inducing up to 75% weight sparsity during the pre-training phase, MediSwift achieves a 2-2.5x reduction in training FLOPs. Notably, all sparse pre-training was performed on the Cerebras CS-2 system, which is specifically designed to realize the acceleration benefits from unstructured weight sparsity, thereby significantly enhancing the efficiency of the MediSwift models. Through subsequent dense f
    
[^127]: 通过合成文本生成的差分私密知识蒸馏

    Differentially Private Knowledge Distillation via Synthetic Text Generation

    [https://arxiv.org/abs/2403.00932](https://arxiv.org/abs/2403.00932)

    提出一种利用合成数据进行知识蒸馏的差分私密算法

    

    大型语言模型(LLMs)在许多不同的下游任务中实现了最先进的性能。然而，数据隐私的增加紧迫性要求LLMs在私有数据上使用差分隐私(DP)进行训练。同时，还需要压缩LLMs以在资源受限的设备或延迟敏感的应用中进行真实部署。差分隐私和模型压缩通常必须在实现其目标的过程中权衡效用损失。此外，同时实现这两者可能导致更多的效用损失。为此，我们提出了一种新颖的差分私密知识蒸馏算法，该算法利用了由差分私密LLM生成的合成数据。教师模型的知识以两种方式转移到学生模型上：一种是来自合成数据本身的硬标签，另一种是通过在合成数据上评估的教师模型的输出分布。

    arXiv:2403.00932v1 Announce Type: cross  Abstract: Large Language models (LLMs) are achieving state-of-the-art performance in many different downstream tasks. However, the increasing urgency of data privacy requires LLMs to train with Differential Privacy (DP) on private data. Concurrently it is also necessary to compress LLMs for real-life deployments on resource-constrained devices or latency-sensitive applications. Differential privacy and model compression generally must trade off utility loss to achieve their objectives. Moreover, concurrently achieving both can result in even more utility loss. To this end, we propose a novel differentially private knowledge distillation algorithm that exploits synthetic data generated by a differentially private LLM. The knowledge of a teacher model is transferred onto the student in two ways: one way from the synthetic data itself, the hard labels, and the other way by the output distribution of the teacher model evaluated on the synthetic data
    
[^128]: 用于提高电子商务搜索相关性的图形和语言模型可解释的集成

    An Interpretable Ensemble of Graph and Language Models for Improving Search Relevance in E-Commerce

    [https://arxiv.org/abs/2403.00923](https://arxiv.org/abs/2403.00923)

    该研究提出了一个可解释的图形和语言模型集成方法，用于提高电子商务领域中搜索相关性，弥补了现有模型在实际部署中的泛化能力和可解释性方面的不足。

    

    在电子商务领域，搜索相关性的问题是一个具有挑战性的问题，因为它涉及理解用户的简短微妙查询的意图，并将其与目录中的适当产品相匹配。传统上，这个问题是通过使用语言模型（LMs）和图神经网络（GNNs）来应对的，以捕捉语义和产品间行为信号。然而，新架构的快速发展造成了研究和这些技术实际应用之间的鸿沟。评估这些模型在部署中的泛化能力需要对复杂的现实世界数据集进行广泛的实验，这可能并不简单且昂贵。此外，这种模型通常在不为人类所理解的潜在空间表示上运行，这使得评估和比较不同模型的有效性变得困难。这种缺乏可解释性阻碍了开发和ad

    arXiv:2403.00923v1 Announce Type: cross  Abstract: The problem of search relevance in the E-commerce domain is a challenging one since it involves understanding the intent of a user's short nuanced query and matching it with the appropriate products in the catalog. This problem has traditionally been addressed using language models (LMs) and graph neural networks (GNNs) to capture semantic and inter-product behavior signals, respectively. However, the rapid development of new architectures has created a gap between research and the practical adoption of these techniques. Evaluating the generalizability of these models for deployment requires extensive experimentation on complex, real-world datasets, which can be non-trivial and expensive. Furthermore, such models often operate on latent space representations that are incomprehensible to humans, making it difficult to evaluate and compare the effectiveness of different models. This lack of interpretability hinders the development and ad
    
[^129]: DiaHalu：大型语言模型的对话级幻觉评估基准

    DiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large Language Models

    [https://arxiv.org/abs/2403.00896](https://arxiv.org/abs/2403.00896)

    DiaHalu是第一个对话级幻觉评估基准，针对大型语言模型在对话级别上的幻觉问题进行研究。

    

    自从最近几年大型语言模型（LLMs）取得了显著成功，幻觉问题仍然是一个挑战，有许多基准被提出来检测这种幻觉。然而，其中一些基准不是由LLMs自然生成的，而是有意引发的。此外，许多基准仅关注事实上的幻觉，而忽视了忠实度的幻觉。此外，尽管在LLMs时代对话模式被广泛应用，但目前的基准仅集中在句子级和段落级的幻觉上。在这项研究中，我们提出 DiaHalu，这是我们所知的第一个对话级幻觉评估基准。首先，我们将收集的主题集成到系统提示中，促进两个ChatGPT3.5之间的对话。随后，我们手动修改不符合人类语言约定的内容，然后让LLMs重新生成，模拟真实的人类-

    arXiv:2403.00896v1 Announce Type: cross  Abstract: Since large language models (LLMs) achieve significant success in recent years, the hallucination issue remains a challenge, numerous benchmarks are proposed to detect the hallucination. Nevertheless, some of these benchmarks are not naturally generated by LLMs but are intentionally induced. Also, many merely focus on the factuality hallucination while ignoring the faithfulness hallucination. Additionally, although dialogue pattern is more widely utilized in the era of LLMs, current benchmarks only concentrate on sentence-level and passage-level hallucination. In this study, we propose DiaHalu, the first dialogue-level hallucination evaluation benchmark to our knowledge. Initially, we integrate the collected topics into system prompts and facilitate a dialogue between two ChatGPT3.5. Subsequently, we manually modify the contents that do not adhere to human language conventions and then have LLMs re-generate, simulating authentic human-
    
[^130]: 对于生成编程代码的大型语言模型进行系统评估

    A systematic evaluation of large language models for generating programming code

    [https://arxiv.org/abs/2403.00894](https://arxiv.org/abs/2403.00894)

    GPT-4在生成编程代码方面表现优异，特别是在选择最佳提示策略时，超过了其他大型语言模型和85%的人类参与者。

    

    我们系统评估了七个大型语言模型在使用不同提示策略、编程语言和任务难度生成编程代码时的性能。GPT-4在很大程度上优于其他大型语言模型，包括Gemini Ultra和Claude 2。GPT-4的编码性能随不同提示策略而变化。在本研究中评估的大多数LeetCode和GeeksforGeeks编程比赛中，采用最佳提示策略的GPT-4胜过85%的人类参与者。此外，GPT-4表现出在不同编程语言之间翻译代码和从过去错误中学习的强大能力。由GPT-4生成的代码的计算效率与人类程序员相当。这些结果表明，GPT-4有潜力成为在编程代码生成和软件开发中的可靠助手。

    arXiv:2403.00894v1 Announce Type: cross  Abstract: We systematically evaluated the performance of seven large language models in generating programming code using various prompt strategies, programming languages, and task difficulties. GPT-4 substantially outperforms other large language models, including Gemini Ultra and Claude 2. The coding performance of GPT-4 varies considerably with different prompt strategies. In most LeetCode and GeeksforGeeks coding contests evaluated in this study, GPT-4 employing the optimal prompt strategy outperforms 85 percent of human participants. Additionally, GPT-4 demonstrates strong capabilities in translating code between different programming languages and in learning from past errors. The computational efficiency of the code generated by GPT-4 is comparable to that of human programmers. These results suggest that GPT-4 has the potential to serve as a reliable assistant in programming code generation and software development.
    
[^131]: 一种基于正则化的指导图解码器的信息抽取迁移学习方法

    A Regularization-based Transfer Learning Method for Information Extraction via Instructed Graph Decoder

    [https://arxiv.org/abs/2403.00891](https://arxiv.org/abs/2403.00891)

    提出了一种基于正则化的信息抽取迁移学习方法，通过指导图解码器实现数据集之间通用知识的迁移

    

    信息提取（IE）旨在从文本中提取复杂结构化信息。已为各种IE任务构建了大量数据集，导致耗时且劳动密集的数据标注。然而，大多数流行方法侧重于训练特定任务的模型，而不是明确对不同IE任务之间的通用知识进行建模。此外，相同短语可能在不同任务中具有不一致的标签，这对使用统一模型进行知识迁移构成了巨大挑战。在本研究中，我们提出了一种基于正则化的信息抽取（IE）的迁移学习方法，通过一个指导图解码器进行。具体而言，我们首先为所有著名IE任务的数据集构建一个指导池，然后提出一个指导图解码器，根据相应的指导将各种复杂结构均匀地解码为图。通过这种方式，与现有数据集共享的通用知识可以更好地用于迁移学习。

    arXiv:2403.00891v1 Announce Type: cross  Abstract: Information extraction (IE) aims to extract complex structured information from the text. Numerous datasets have been constructed for various IE tasks, leading to time-consuming and labor-intensive data annotations. Nevertheless, most prevailing methods focus on training task-specific models, while the common knowledge among different IE tasks is not explicitly modeled. Moreover, the same phrase may have inconsistent labels in different tasks, which poses a big challenge for knowledge transfer using a unified model. In this study, we propose a regularization-based transfer learning method for IE (TIE) via an instructed graph decoder. Specifically, we first construct an instruction pool for datasets from all well-known IE tasks, and then present an instructed graph decoder, which decodes various complex structures into a graph uniformly based on corresponding instructions. In this way, the common knowledge shared with existing datasets 
    
[^132]: 基于边际差异的多领域文本分类对抗训练

    Margin Discrepancy-based Adversarial Training for Multi-Domain Text Classification

    [https://arxiv.org/abs/2403.00888](https://arxiv.org/abs/2403.00888)

    该研究提出了一种基于边际差异的对抗训练方法，通过在多领域文本分类中进行理论分析和新的泛化界限的建立，解决了在MDTC算法设计中缺乏理论保证的挑战。

    

    多领域文本分类(MDTC)致力于利用相关领域的可用资源，提高目标领域的分类准确性。目前，大多数采用对抗训练和共享-私有范式的MDTC方法表现出尖端性能。然而，这些方法面临着一个不可忽视的挑战：在MDTC算法设计中缺乏理论保证。理论基础的缺乏给MDTC算法的发展造成了重大障碍。为了解决这一问题，我们首先通过将MDTC任务分解为多个领域自适应任务来提供MDTC的理论分析。我们将边际差异作为域差异的度量，并基于Rademacher复杂性建立了一个新的泛化界限。随后，我们提出了一种基于边际差异的对抗训练（MDAT）方法用于MDTC，符合我们的t

    arXiv:2403.00888v1 Announce Type: new  Abstract: Multi-domain text classification (MDTC) endeavors to harness available resources from correlated domains to enhance the classification accuracy of the target domain. Presently, most MDTC approaches that embrace adversarial training and the shared-private paradigm exhibit cutting-edge performance. Unfortunately, these methods face a non-negligible challenge: the absence of theoretical guarantees in the design of MDTC algorithms. The dearth of theoretical underpinning poses a substantial impediment to the advancement of MDTC algorithms. To tackle this problem, we first provide a theoretical analysis of MDTC by decomposing the MDTC task into multiple domain adaptation tasks. We incorporate the margin discrepancy as the measure of domain divergence and establish a new generalization bound based on Rademacher complexity. Subsequently, we propose a margin discrepancy-based adversarial training (MDAT) approach for MDTC, in accordance with our t
    
[^133]: SEGAA: 一种统一的方法来预测语音中的年龄、性别和情绪

    SEGAA: A Unified Approach to Predicting Age, Gender, and Emotion in Speech

    [https://arxiv.org/abs/2403.00887](https://arxiv.org/abs/2403.00887)

    本文提出了一种统一的方法来从语音中预测年龄、性别和情绪，通过深度学习模型探索了单一、多输出和顺序模型的比较，并提出了新颖的多输出学习架构。

    

    人类声音的解释在各种应用中都很重要。本研究探讨了从语音线索中预测年龄、性别和情绪，这是一个具有广泛应用的领域。声音分析技术的进展跨越各个领域，从改善客户互动到增强医疗保健和零售体验。辨识情绪有助于心理健康，而年龄和性别的检测在各种情境中至关重要。探索这些预测的深度学习模型涉及比较单一、多输出和顺序模型，这些模型在本文中得到了重点展示。寻找合适的数据提出了挑战，导致了CREMA-D和EMO-DB数据集的融合。以前的工作在个别预测方面表现出潜力，但有限的研究同时考虑了这三个变量。本文确定了个别模型方法中的缺陷，并倡导我们的新颖多输出学习架构Speech-based Emotion Gender。

    arXiv:2403.00887v1 Announce Type: cross  Abstract: The interpretation of human voices holds importance across various applications. This study ventures into predicting age, gender, and emotion from vocal cues, a field with vast applications. Voice analysis tech advancements span domains, from improving customer interactions to enhancing healthcare and retail experiences. Discerning emotions aids mental health, while age and gender detection are vital in various contexts. Exploring deep learning models for these predictions involves comparing single, multi-output, and sequential models highlighted in this paper. Sourcing suitable data posed challenges, resulting in the amalgamation of the CREMA-D and EMO-DB datasets. Prior work showed promise in individual predictions, but limited research considered all three variables simultaneously. This paper identifies flaws in an individual model approach and advocates for our novel multi-output learning architecture Speech-based Emotion Gender an
    
[^134]: 词序与世界知识

    Word Order and World Knowledge

    [https://arxiv.org/abs/2403.00876](https://arxiv.org/abs/2403.00876)

    本研究探讨了词序如何影响语言模型从原始文本中归纳世界知识，发现一些固定词序在不同语言中表现更好或更差，而预训练语言模型中的Wov2Lex假设不成立。

    

    词序是自然语言中的一个重要概念，在这项工作中，我们研究了词序如何影响使用语言模型从原始文本中归纳世界知识。我们使用词类比来探究这种知识。具体来说，除了自然词序外，我们分别从五种语言中提取了六种固定词序的文本，并在这些文本上对语言模型进行了预训练。最后，我们分析了固定词序在词类比上的实验结果，表明某些固定词序在不同语言中始终表现出色或不佳，尽管具体情况因语言而异，以及ii）Wov2Lex假设在预训练语言模型中不成立，自然词序通常产生平庸的结果。源代码将公开在 https://github.com/lshowway/probing_by_analogy。

    arXiv:2403.00876v1 Announce Type: cross  Abstract: Word order is an important concept in natural language, and in this work, we study how word order affects the induction of world knowledge from raw text using language models. We use word analogies to probe for such knowledge. Specifically, in addition to the natural word order, we first respectively extract texts of six fixed word orders from five languages and then pretrain the language models on these texts. Finally, we analyze the experimental results of the fixed word orders on word analogies and show that i) certain fixed word orders consistently outperform or underperform others, though the specifics vary across languages, and ii) the Wov2Lex hypothesis is not hold in pre-trained language models, and the natural word order typically yields mediocre results. The source code will be made publicly available at https://github.com/lshowway/probing_by_analogy.
    
[^135]: 教会大型语言模型进行钓鱼：从语言模型中窃取私人信息

    Teach LLMs to Phish: Stealing Private Information from Language Models

    [https://arxiv.org/abs/2403.00871](https://arxiv.org/abs/2403.00871)

    本研究提出了一种名为“神经钓鱼”的新型实用数据提取攻击，使对手能够成功地从大型语言模型中提取敏感信息，攻击成功率高达10%至50%。

    

    当大型语言模型在私人数据上训练时，它们可能会将敏感信息记忆并重复。本研究提出了一种新的实用数据提取攻击，称为“神经钓鱼”。这种攻击使对手能够从一个在用户数据上训练的模型中成功率高达10%甚至50%地提取敏感或可识别个人身份的信息，例如信用卡号。攻击仅假设对手可以将少量看似良性的句子插入训练数据集，仅使用对用户数据结构的模糊先验知识。

    arXiv:2403.00871v1 Announce Type: cross  Abstract: When large language models are trained on private data, it can be a significant privacy risk for them to memorize and regurgitate sensitive information. In this work, we propose a new practical data extraction attack that we call "neural phishing". This attack enables an adversary to target and extract sensitive or personally identifiable information (PII), e.g., credit card numbers, from a model trained on user data with upwards of 10% attack success rates, at times, as high as 50%. Our attack assumes only that an adversary can insert as few as 10s of benign-appearing sentences into the training dataset using only vague priors on the structure of the user data.
    
[^136]: SoftTiger: 用于医疗工作流的临床基础模型

    SoftTiger: A Clinical Foundation Model for Healthcare Workflows

    [https://arxiv.org/abs/2403.00868](https://arxiv.org/abs/2403.00868)

    SoftTiger是一个专为医疗工作流设计的临床大型语言模型，通过处理临床笔记的结构化，实现了基本临床任务以及更复杂的下游临床任务的执行。

    

    我们发布并介绍了SoftTiger，一个专为医疗保健工作流设计的临床大型语言模型（CLaM）作为基础模型。临床笔记的叙述性和非结构化特性是医疗智能化的主要障碍。我们致力于按照国际互操作性标准将临床笔记结构化为临床数据，涉及国际患者摘要、临床印象和医疗接触三个关键子任务的数据收集和标注。然后，我们使用公开和验证的临床数据对最先进的LLM进行监督微调。训练过程中，目标模型首先能够支持基本的临床任务，如缩写扩展和时间信息提取，然后学习执行更复杂的下游临床任务，如印象和接触摘要。此外，我们解决了医疗模型中的一些建模挑战。

    arXiv:2403.00868v1 Announce Type: cross  Abstract: We release and introduce SoftTiger, a clinical large language model (CLaM) designed as a foundation model for healthcare workflows. The narrative and unstructured nature of clinical notes is a major obstacle for healthcare intelligentization. We address a critical problem of structuring clinical notes into clinical data, according to international interoperability standards. We collect and annotate data for three critical subtasks, namely, international patient summary, clinical impression and medical encounter. We then supervised fine-tuned a state-of-the-art LLM using public and credentialed clinical data. The training is orchestrated in a way that the target model can first support basic clinical tasks such as abbreviation expansion and temporal information extraction, and then learn to perform more complex downstream clinical tasks such as impression and encounter summary. Moreover, we address, several modeling challenges in the he
    
[^137]: 梯度被罚：通过探索拒绝损失地形图来检测针对大语言模型的越狱攻击

    Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by Exploring Refusal Loss Landscapes

    [https://arxiv.org/abs/2403.00867](https://arxiv.org/abs/2403.00867)

    本文提出了一种名为Gradient Cuff的方法，通过探索拒绝损失地形图来检测对大语言模型的越狱攻击，成功设计了一种有效的两步检测策略。

    

    大型语言模型（LLMs）正成为一种突出的生成式AI工具，用户输入查询，LLM生成答案。为了减少伤害和滥用，人们通过使用先进的训练技术如来自人类反馈的强化学习（RLHF）来将这些LLMs与人类价值观保持一致。然而，最近的研究突显了LLMs对于试图颠覆嵌入的安全防护措施的对抗性越狱尝试的脆弱性。为了解决这一挑战，本文定义并调查了LLMs的拒绝损失，然后提出了一种名为Gradient Cuff的方法来检测越狱尝试。Gradient Cuff利用拒绝损失地形图中观察到的独特特性，包括功能值及其光滑性，设计了一种有效的两步检测策略。

    arXiv:2403.00867v1 Announce Type: cross  Abstract: Large Language Models (LLMs) are becoming a prominent generative AI tool, where the user enters a query and the LLM generates an answer. To reduce harm and misuse, efforts have been made to align these LLMs to human values using advanced training techniques such as Reinforcement Learning from Human Feedback (RLHF). However, recent studies have highlighted the vulnerability of LLMs to adversarial jailbreak attempts aiming at subverting the embedded safety guardrails. To address this challenge, this paper defines and investigates the Refusal Loss of LLMs and then proposes a method called Gradient Cuff to detect jailbreak attempts. Gradient Cuff exploits the unique properties observed in the refusal loss landscape, including functional values and its smoothness, to design an effective two-step detection strategy. Experimental results on two aligned LLMs (LLaMA-2-7B-Chat and Vicuna-7B-V1.5) and six types of jailbreak attacks (GCG, AutoDAN,
    
[^138]: LLM-Ensemble: 用于电子商务产品属性值提取的最佳大型语言模型集成方法

    LLM-Ensemble: Optimal Large Language Model Ensemble Method for E-commerce Product Attribute Value Extraction

    [https://arxiv.org/abs/2403.00863](https://arxiv.org/abs/2403.00863)

    提出了一种名为LLM-ensemble的算法，用于集成不同大型语言模型，以提高电子商务产品属性值提取的性能。

    

    arXiv:2403.00863v1 公告类型:跨领域摘要: 产品属性值提取是自然语言处理（NLP）和当代电子商务行业中至关重要的组成部分。提供精确的产品属性值在确保高质量推荐和提升客户满意度方面至关重要。最近出现的大型语言模型（LLMs）在许多属性提取任务中表现出最新技术水平，而无需进行领域特定的训练数据。然而，由于数据、架构和超参数的多样性，不同LLMs表现出不同的优势和劣势。这种变化使它们彼此互补，没有哪个LLM能完全压倒其他LLM。考虑到LLMs的多样优势和劣势，开发一种利用它们互补潜力的集成方法变得必要。在本文中，我们提出了一种名为LLM-ensemble的新算法，用于集成不同LLMs。

    arXiv:2403.00863v1 Announce Type: cross  Abstract: Product attribute value extraction is a pivotal component in Natural Language Processing (NLP) and the contemporary e-commerce industry. The provision of precise product attribute values is fundamental in ensuring high-quality recommendations and enhancing customer satisfaction. The recently emerging Large Language Models (LLMs) have demonstrated state-of-the-art performance in numerous attribute extraction tasks, without the need for domain-specific training data. Nevertheless, varying strengths and weaknesses are exhibited by different LLMs due to the diversity in data, architectures, and hyperparameters. This variation makes them complementary to each other, with no single LLM dominating all others. Considering the diverse strengths and weaknesses of LLMs, it becomes necessary to develop an ensemble method that leverages their complementary potentials. In this paper, we propose a novel algorithm called LLM-ensemble to ensemble diffe
    
[^139]: NewsBench：系统性评估LLM在中国新闻编辑应用中的写作水平和安全性遵从能力

    NewsBench: Systematic Evaluation of LLMs for Writing Proficiency and Safety Adherence in Chinese Journalistic Editorial Applications

    [https://arxiv.org/abs/2403.00862](https://arxiv.org/abs/2403.00862)

    NewsBench是一个评估LLMs在中国新闻写作水平和安全性遵从能力的基准框架，揭示了在创造性写作任务中LLMs相对不足的新闻伦理遵守方面的需求。

    

    这项研究提出了NewsBench，这是一个新颖的基准框架，旨在评估大型语言模型（LLMs）在中国新闻写作水平（JWP）和安全性遵从（SA）方面的能力，弥补了新闻伦理与人工智能利用风险之间的差距。NewsBench包括5个编辑应用中的1,267项任务，7个方面（包括安全性和新闻写作，以及4个详细要面），涵盖24个新闻主题领域，采用基于两种GPT-4的自动评估协议，并经过人类评估验证。我们对11个LLM的全面分析突出了GPT-4和ERNIE Bot作为表现最佳，但在创造性写作任务中揭示了新闻伦理遵守方面的相对不足。这些发现强调了AI生成的新闻内容需要提高伦理指导，标志着以新闻标准和安全性对齐AI能力迈出了一步。

    arXiv:2403.00862v1 Announce Type: cross  Abstract: This study presents NewsBench, a novel benchmark framework developed to evaluate the capability of Large Language Models (LLMs) in Chinese Journalistic Writing Proficiency (JWP) and their Safety Adherence (SA), addressing the gap between journalistic ethics and the risks associated with AI utilization. Comprising 1,267 tasks across 5 editorial applications, 7 aspects (including safety and journalistic writing with 4 detailed facets), and spanning 24 news topics domains, NewsBench employs two GPT-4 based automatic evaluation protocols validated by human assessment. Our comprehensive analysis of 11 LLMs highlighted GPT-4 and ERNIE Bot as top performers, yet revealed a relative deficiency in journalistic ethic adherence during creative writing tasks. These findings underscore the need for enhanced ethical guidance in AI-generated journalistic content, marking a step forward in aligning AI capabilities with journalistic standards and safet
    
[^140]: 直接与Chat-Fine-Tuned LLMs的草案模型对齐

    Direct Alignment of Draft Model for Speculative Decoding with Chat-Fine-Tuned LLMs

    [https://arxiv.org/abs/2403.00858](https://arxiv.org/abs/2403.00858)

    通过提出的框架，我们训练了一种用于Llama 2 Chat 7B或更大模型的草案模型，实现了加速推理，仅占原始大小的1.64％。

    

    文本生成与大型语言模型（LLMs）由于其自回归本质、巨大的参数数量和有限的内存带宽而被认为是内存密集型，通常导致低令牌速率。猜测解码已被提出作为LLM推理加速的解决方案。然而，在现代开源LLM系列中，例如Llama 2 7B，由于草案模型通常不可用，因此需要训练高质量的草案模型以通过猜测解码实现推理加速。在本文中，我们提出了一个简单的草案模型训练框架，用于直接与Chat-capable目标模型对齐。通过我们提出的框架，我们训练出Llama 2 Chat Drafter 115M，这是一个适用于Llama 2 Chat 7B或更大模型的草案模型，仅占原始大小的1.64％。我们的训练框架仅包括预训练、蒸馏数据集生成和使用知识蒸馏进行微调，没有额外的对齐步骤。

    arXiv:2403.00858v1 Announce Type: cross  Abstract: Text generation with Large Language Models (LLMs) is known to be memory bound due to the combination of their auto-regressive nature, huge parameter counts, and limited memory bandwidths, often resulting in low token rates. Speculative decoding has been proposed as a solution for LLM inference acceleration. However, since draft models are often unavailable in the modern open-source LLM families, e.g., for Llama 2 7B, training a high-quality draft model is required to enable inference acceleration via speculative decoding. In this paper, we propose a simple draft model training framework for direct alignment to chat-capable target models. With the proposed framework, we train Llama 2 Chat Drafter 115M, a draft model for Llama 2 Chat 7B or larger, with only 1.64\% of the original size. Our training framework only consists of pretraining, distillation dataset generation, and finetuning with knowledge distillation, with no additional align
    
[^141]: 使用自监督变压器和多任务学习进行说话者无关的运动障碍严重程度分类

    Speaker-Independent Dysarthria Severity Classification using Self-Supervised Transformers and Multi-Task Learning

    [https://arxiv.org/abs/2403.00854](https://arxiv.org/abs/2403.00854)

    提出了一种使用自监督变压器和多任务学习进行说话者无关的运动障碍严重度分类的方法，可自动评估运动障碍的严重程度。

    

    运动障碍是由于神经系统疾病导致言语肌肉控制能力受损而产生的一种状况，严重影响患者的沟通和生活质量。本研究提出了一种基于变压器的框架，可以从原始语音数据中自动评估运动障碍的严重程度。相较于传统需要人类专家评估的方法，它可以提供客观、可重复、可访问、标准化和具有成本效益的评估。

    arXiv:2403.00854v1 Announce Type: cross  Abstract: Dysarthria, a condition resulting from impaired control of the speech muscles due to neurological disorders, significantly impacts the communication and quality of life of patients. The condition's complexity, human scoring and varied presentations make its assessment and management challenging. This study presents a transformer-based framework for automatically assessing dysarthria severity from raw speech data. It can offer an objective, repeatable, accessible, standardised and cost-effective and compared to traditional methods requiring human expert assessors. We develop a transformer framework, called Speaker-Agnostic Latent Regularisation (SALR), incorporating a multi-task learning objective and contrastive learning for speaker-independent multi-class dysarthria severity classification. The multi-task framework is designed to reduce reliance on speaker-specific characteristics and address the intrinsic intra-class variability of d
    
[^142]: 利用双层可学习大型语言模型规划增强长期推荐

    Enhancing Long-Term Recommendation with Bi-level Learnable Large Language Model Planning

    [https://arxiv.org/abs/2403.00843](https://arxiv.org/abs/2403.00843)

    利用大型语言模型的规划能力来增强长期推荐，使模型在个性化推荐中更有效地理解和应用任务解决原则

    

    传统推荐系统倾向于过分迎合用户的即时兴趣而忽视他们的长期参与。 为了解决这个问题，在推荐决策过程中合并规划能力是至关重要的，以开发能够同时考虑即时兴趣和长期参与的策略。本文提出利用大型语言模型（LLMs）对稀疏数据的显著规划能力用于长期推荐。关键在于使语言模型能够在个性化推荐场景中有效理解和应用任务解决原则，因为模型的预训练可能并未自然包含这些内容。

    arXiv:2403.00843v1 Announce Type: cross  Abstract: Traditional recommendation setting tends to excessively cater to users' immediate interests and neglect their long-term engagement. To address it, it is crucial to incorporate planning capabilities into the recommendation decision-making process to develop policies that take into account both immediate interests and long-term engagement. Despite Reinforcement Learning (RL) can learn planning capacity by maximizing cumulative reward, the scarcity of recommendation data presents challenges such as instability and susceptibility to overfitting when training RL models from scratch.   In this context, we propose to leverage the remarkable planning capabilities over sparse data of Large Language Models (LLMs) for long-term recommendation. The key lies in enabling a language model to understand and apply task-solving principles effectively in personalized recommendation scenarios, as the model's pre-training may not naturally encompass these 
    
[^143]: EyeGPT：具有大型语言模型的眼科助手

    EyeGPT: Ophthalmic Assistant with Large Language Models

    [https://arxiv.org/abs/2403.00840](https://arxiv.org/abs/2403.00840)

    EyeGPT是一个专门为眼科设计的大型语言模型，采用角色扮演、微调和检索增强生成等策略，提出了全面的多指标评估框架。

    

    人工智能（AI）在医疗咨询中引起了重要关注，因为它有望改善临床工作流程并增强医疗交流。然而，由于医学信息的复杂性，使用一般世界知识训练的大型语言模型（LLM）可能没有能力以专家水平处理与医学相关的任务。在这里，我们介绍了EyeGPT，这是一个专门为眼科设计的LLM，采用角色扮演、微调和检索增强生成等三种优化策略。特别地，我们提出了一个全面的评估框架，涵盖了各种眼科分支的多样数据集，不同用户和多样的查询意图。此外，我们考虑了多个评估指标，包括准确性、可理解性、可信度、移情和幻觉比例。

    arXiv:2403.00840v1 Announce Type: cross  Abstract: Artificial intelligence (AI) has gained significant attention in healthcare consultation due to its potential to improve clinical workflow and enhance medical communication. However, owing to the complex nature of medical information, large language models (LLM) trained with general world knowledge might not possess the capability to tackle medical-related tasks at an expert level. Here, we introduce EyeGPT, a specialized LLM designed specifically for ophthalmology, using three optimization strategies including role-playing, finetuning, and retrieval-augmented generation. In particular, we proposed a comprehensive evaluation framework that encompasses a diverse dataset, covering various subspecialties of ophthalmology, different users, and diverse inquiry intents. Moreover, we considered multiple evaluation metrics, including accuracy, understandability, trustworthiness, empathy, and the proportion of hallucinations. By assessing the p
    
[^144]: ToolNet：通过工具图将大型语言模型与海量工具连接起来

    ToolNet: Connecting Large Language Models with Massive Tools via Tool Graph

    [https://arxiv.org/abs/2403.00839](https://arxiv.org/abs/2403.00839)

    ToolNet是一个插拔式框架，通过将工具组织成一个有向图，实现了将大型语言模型与数千个工具连接起来，扩展了工具使用的数量而仅有中等标记消耗的增加。

    

    尽管在各种任务中取得了显著进展，但大型语言模型（LLMs）在正确使用海量外部工具方面仍然存在显著局限。现有的上下文学习方法简单地将工具格式化为一列纯文本描述，并将其输入到LLMs中，然后LLMs生成一系列工具调用序列以逐步解决问题。这种范式忽略了工具之间的内在依赖，并将所有推理负载转移到LLMs上，使其局限于一小部分专门设计的工具。因此，对LLMs来说，要在大量工具库上运行仍然具有挑战性，当面临现实场景时存在着很大限制。本文提出了ToolNet，一个即插即用的框架，通过适度增加标记消耗，将工具的数量扩展到数千个。ToolNet将工具组织成一个有向图。每个节点代表一个工具，加权边表示…

    arXiv:2403.00839v1 Announce Type: new  Abstract: While achieving remarkable progress in a broad range of tasks, large language models (LLMs) remain significantly limited in properly using massive external tools. Existing in-context learning approaches simply format tools into a list of plain text descriptions and input them to LLMs, from which, LLMs generate a sequence of tool calls to solve problems step by step. Such a paradigm ignores the intrinsic dependency between tools and offloads all reasoning loads to LLMs, making them restricted to a limited number of specifically designed tools. It thus remains challenging for LLMs to operate on a library of massive tools, casting a great limitation when confronted with real-world scenarios. This paper proposes ToolNet, a plug-and-play framework that scales up the number of tools to thousands with a moderate increase in token consumption. ToolNet organizes tools into a directed graph. Each node represents a tool, and weighted edges denote t
    
[^145]: CLLMs: 一致性大型语言模型

    CLLMs: Consistency Large Language Models

    [https://arxiv.org/abs/2403.00835](https://arxiv.org/abs/2403.00835)

    提出了一种新方法，通过精细调整目标LLM实现了对雅各比轨迹上固定点的一致性预测，有效提高了生成速度2.4倍到3.4倍。

    

    并行解码方法，如雅可比解码，显示出有望实现更高效的LLM推断，因为它打破了LLM解码过程的顺序性，并将其转换为可并行化计算。然而，在实践中，与传统的自回归（AR）解码相比，雅可比解码很少能在单个固定点迭代步骤中准确预测多个标记，因此在速度上取得的提升相对较小。为了解决这个问题，我们开发了一种新方法，旨在实现从任何状态快速收敛到雅各比轨迹上的固定点。通过精细调整目标LLM，以便在任何输入状态下一致地预测固定点。大量实验证明了我们方法的有效性，在领域特定和开放域基准测试中显示出生成速度提高了2.4倍到3.4倍，同时保持了生成质量。

    arXiv:2403.00835v1 Announce Type: cross  Abstract: Parallel decoding methods such as Jacobi decoding show promise for more efficient LLM inference as it breaks the sequential nature of the LLM decoding process and transforms it into parallelizable computation. However, in practice, it achieves little speedup compared to traditional autoregressive (AR) decoding, primarily because Jacobi decoding seldom accurately predicts more than one token in a single fixed-point iteration step. To address this, we develop a new approach aimed at realizing fast convergence from any state to the fixed point on a Jacobi trajectory. This is accomplished by refining the target LLM to consistently predict the fixed point given any state as input. Extensive experiments demonstrate the effectiveness of our method, showing 2.4$\times$ to 3.4$\times$ improvements in generation speed while preserving generation quality across both domain-specific and open-domain benchmarks.
    
[^146]: MedAide：利用大型语言模型为边缘设备提供现场医疗援助

    MedAide: Leveraging Large Language Models for On-Premise Medical Assistance on Edge Devices

    [https://arxiv.org/abs/2403.00830](https://arxiv.org/abs/2403.00830)

    MedAide是一款利用微型语言模型与LangChain集成，为资源受限的边缘设备提供高效医疗诊断和支持的现场医疗聊天机器人，通过模型优化和多样的医疗数据集训练来提升其领域特定能力。

    

    大型语言模型( LLMs )以其出色的自然语言处理( NLP )功能正在改变各个领域。然而，在资源受限的边缘计算和嵌入式系统中部署 LLMs 存在重大挑战。另一个挑战在于在医疗资源有限、基础设施不完备的偏远地区提供医疗援助。为解决这一问题，我们介绍了 MedAide，一款现场医疗聊天机器人。它利用与 LangChain 集成的微型 LLMs，提供高效的基于边缘的初步医疗诊断和支持。MedAide 通过模型优化在嵌入式边缘设备上实现最小内存占用和延迟，无需服务器基础设施。训练过程使用低秩适应 (LoRA ) 进行优化。此外，该模型在多样化的医疗数据集上进行训练，应用来自人类反馈的强化学习 (RLHF) 来增强其特定领域的能力。

    arXiv:2403.00830v1 Announce Type: new  Abstract: Large language models (LLMs) are revolutionizing various domains with their remarkable natural language processing (NLP) abilities. However, deploying LLMs in resource-constrained edge computing and embedded systems presents significant challenges. Another challenge lies in delivering medical assistance in remote areas with limited healthcare facilities and infrastructure. To address this, we introduce MedAide, an on-premise healthcare chatbot. It leverages tiny-LLMs integrated with LangChain, providing efficient edge-based preliminary medical diagnostics and support. MedAide employs model optimizations for minimal memory footprint and latency on embedded edge devices without server infrastructure. The training process is optimized using low-rank adaptation (LoRA). Additionally, the model is trained on diverse medical datasets, employing reinforcement learning from human feedback (RLHF) to enhance its domain-specific capabilities. The sy
    
[^147]: TroubleLLM: 对齐红队专家

    TroubleLLM: Align to Red Team Expert

    [https://arxiv.org/abs/2403.00829](https://arxiv.org/abs/2403.00829)

    TroubleLLM是第一个用于生成关于LLMs安全问题的可控测试提示的LLM，通过广泛实验和人类评估展示了其在生成质量和生成可控性方面的优越性

    

    大型语言模型（LLMs）已成为各种自然语言任务的最先进解决方案，并被整合到现实世界的应用中。然而，LLMs可能在展现诸如社会偏见和有毒内容等不良安全问题方面具有潜在危害。在部署之前评估其安全问题至关重要。然而，现有方法生成的测试提示的质量和多样性仍然远远不尽人意。这些方法不仅劳动密集且需要大量预算成本，而且测试提示生成的可控性在LLM应用的具体测试领域中缺乏。

    arXiv:2403.00829v1 Announce Type: new  Abstract: Large Language Models (LLMs) become the start-of-the-art solutions for a variety of natural language tasks and are integrated into real-world applications. However, LLMs can be potentially harmful in manifesting undesirable safety issues like social biases and toxic content. It is imperative to assess its safety issues before deployment. However, the quality and diversity of test prompts generated by existing methods are still far from satisfactory. Not only are these methods labor-intensive and require large budget costs, but the controllability of test prompt generation is lacking for the specific testing domain of LLM applications. With the idea of LLM for LLM testing, we propose the first LLM, called TroubleLLM, to generate controllable test prompts on LLM safety issues. Extensive experiments and human evaluation illustrate the superiority of TroubleLLM on generation quality and generation controllability.
    
[^148]: 基于深度学习的大型语言模型生成科学内容的检测方法

    Deep Learning Detection Method for Large Language Models-Generated Scientific Content

    [https://arxiv.org/abs/2403.00828](https://arxiv.org/abs/2403.00828)

    提出了一种新的ChatGPT生成科学文本检测方法AI-Catcher，该方法集成了多层感知器（MLP）和卷积神经网络（CNN），是一个多模态模型，用于检测大型语言模型生成的科学内容。

    

    Large Language Models (LLMs), 如GPT-3和BERT，改变了文本内容的写作和传播方式。这些模型有潜力生成与人类写作无法区分的科学内容。因此，LLMs会给科学界带来严重后果，科学界依赖于出版物的完整性和可靠性。本研究提出了一种新颖的ChatGPT生成的科学文本检测方法，名为AI-Catcher。AI-Catcher集成了两个深度学习模型，多层感知器（MLP）和卷积神经网络（CNN）。MLP学习语言和统计特征的特征表示。CNN从文本内容中提取顺序模式的高级表示。AI-Catcher是一个多模态模型，融合了MLP和CNN导出的隐藏模式。此外，还收集了一个新的ChatGPT生成的科学文本数据集来增强AI生成的文本。

    arXiv:2403.00828v1 Announce Type: cross  Abstract: Large Language Models (LLMs), such as GPT-3 and BERT, reshape how textual content is written and communicated. These models have the potential to generate scientific content that is indistinguishable from that written by humans. Hence, LLMs carry severe consequences for the scientific community, which relies on the integrity and reliability of publications. This research paper presents a novel ChatGPT-generated scientific text detection method, AI-Catcher. AI-Catcher integrates two deep learning models, multilayer perceptron (MLP) and convolutional neural networks (CNN). The MLP learns the feature representations of the linguistic and statistical features. The CNN extracts high-level representations of the sequential patterns from the textual content. AI-Catcher is a multimodal model that fuses hidden patterns derived from MLP and CNN. In addition, a new ChatGPT-Generated scientific text dataset is collected to enhance AI-generated tex
    
[^149]: 来自外部代理指标反馈的语言模型自我完善

    Self-Refinement of Language Models from External Proxy Metrics Feedback

    [https://arxiv.org/abs/2403.00827](https://arxiv.org/abs/2403.00827)

    本文提出了Proxy Metric-based Self-Refinement (ProMiSe)方法，通过外部指标反馈指导语言模型在质量关键维度上进行自我完善，从而改进响应质量。

    

    在文档为基础的响应生成中，期望代理响应不仅与用户的查询相关，还与给定的文档相关。本文引入了基于代理指标的自我完善（ProMiSe），使得大型语言模型能够沿着外部指标反馈引导的质量关键维度优化其初始响应，从而产生更好的最终响应。

    arXiv:2403.00827v1 Announce Type: cross  Abstract: It is often desirable for Large Language Models (LLMs) to capture multiple objectives when providing a response. In document-grounded response generation, for example, agent responses are expected to be relevant to a user's query while also being grounded in a given document. In this paper, we introduce Proxy Metric-based Self-Refinement (ProMiSe), which enables an LLM to refine its own initial response along key dimensions of quality guided by external metrics feedback, yielding an overall better final response. ProMiSe leverages feedback on response quality through principle-specific proxy metrics, and iteratively refines its response one principle at a time. We apply ProMiSe to open source language models Flan-T5-XXL and Llama-2-13B-Chat, to evaluate its performance on document-grounded question answering datasets, MultiDoc2Dial and QuAC, demonstrating that self-refinement improves response quality. We further show that fine-tuning 
    
[^150]: LLMGuard：防范不安全的LLM行为

    LLMGuard: Guarding Against Unsafe LLM Behavior

    [https://arxiv.org/abs/2403.00826](https://arxiv.org/abs/2403.00826)

    LLMGuard是一个监视用户与LLM应用程序互动的工具，可标记违背特定行为或对话主题的内容。

    

    尽管大型语言模型(LLMs)在企业环境中的兴起带来了新的机遇和能力，但也带来了挑战，例如生成不当、偏倚或误导性内容的风险，该内容违反规定并可能涉及法律问题。为了缓解这一问题，我们提出了“LLMGuard”，这是一个工具，可监视用户与LLM应用程序的互动，并标记违背特定行为或对话主题的内容。为了做到这一点，LLMGuard采用了一组探测器。

    arXiv:2403.00826v1 Announce Type: new  Abstract: Although the rise of Large Language Models (LLMs) in enterprise settings brings new opportunities and capabilities, it also brings challenges, such as the risk of generating inappropriate, biased, or misleading content that violates regulations and can have legal concerns. To alleviate this, we present "LLMGuard", a tool that monitors user interactions with an LLM application and flags content against specific behaviours or conversation topics. To do this robustly, LLMGuard employs an ensemble of detectors.
    
[^151]: 在数据短缺情况下比较正则化方法在文本分类中的有效性：简单和复杂模型的比较

    Comparing effectiveness of regularization methods on text classification: Simple and complex model in data shortage situation

    [https://arxiv.org/abs/2403.00825](https://arxiv.org/abs/2403.00825)

    本文比较了当只有少量带标签数据可用时，简单的词嵌入模型与复杂模型（CNN和BiLSTM）在文本分类中的正则化效果，并探讨了对抗训练和半监督学习方法在提高模型性能方面的作用。

    

    文本分类是将文档分配到预定义类别的任务。然而，获取足够标记的文档或对其进行标记是昂贵的。本文研究了当只有少量带标签数据可用时，正则化方法对各种分类模型的影响。我们将简单而有效的基于词嵌入的模型与复杂模型（CNN和BiLSTM）进行比较。在监督学习中，对抗训练可以进一步对模型进行正则化。当有一个未标记数据集可用时，我们可以使用半监督学习方法（如Pi模型和虚拟对抗训练）对模型进行正则化。我们仅使用原始标记训练文档的0.1%至0.5%来评估四个文本分类数据集（AG新闻、DBpedia、Yahoo! Answers、Yelp Polarity）上的正则化效果。简单模型在完全监督学习中表现相对良好，但在对抗性训练的帮助下

    arXiv:2403.00825v1 Announce Type: new  Abstract: Text classification is the task of assigning a document to a predefined class. However, it is expensive to acquire enough labeled documents or to label them. In this paper, we study the regularization methods' effects on various classification models when only a few labeled data are available. We compare a simple word embedding-based model, which is simple but effective, with complex models (CNN and BiLSTM). In supervised learning, adversarial training can further regularize the model. When an unlabeled dataset is available, we can regularize the model using semi-supervised learning methods such as the Pi model and virtual adversarial training. We evaluate the regularization effects on four text classification datasets (AG news, DBpedia, Yahoo! Answers, Yelp Polarity), using only 0.1% to 0.5% of the original labeled training documents. The simple model performs relatively well in fully supervised learning, but with the help of adversaria
    
[^152]: 信息流路由：自动解释规模化语言模型

    Information Flow Routes: Automatically Interpreting Language Models at Scale

    [https://arxiv.org/abs/2403.00824](https://arxiv.org/abs/2403.00824)

    这项研究提出了一种自动解释语言模型的方法，通过构建信息流路由图来揭示模型内部的关键节点和操作，相比于现有方法的激活修补，这种方法通过归因实现，在不需要人工干预设计的情况下可以有效地分析模型行为。

    

    通过模型实现的机制，信息通过网络内部的路由进行传输。这些路由可以被表示为图，其中节点对应于标记表示，边对应于网络内部的操作。我们以自顶向下的方式自动构建这些图，针对每一个预测只保留最重要的节点和边。与现有的依赖于激活修补的工作流相比，我们通过归因来做到这一点：这使我们能够仅通过单次前向传递有效地揭示现有的电路。此外，我们的方法的适用性远远超出了修补：我们不需要人类仔细设计预测模板，可以为任何预测提取信息流路由（不仅仅是在允许的模板之间的预测）。因此，我们可以就模型行为进行一般性讨论，针对特定类型的预测或不同的领域。我们在Llama 2上进行了实验，并展示了这一方法的作用。

    arXiv:2403.00824v1 Announce Type: cross  Abstract: Information flows by routes inside the network via mechanisms implemented in the model. These routes can be represented as graphs where nodes correspond to token representations and edges to operations inside the network. We automatically build these graphs in a top-down manner, for each prediction leaving only the most important nodes and edges. In contrast to the existing workflows relying on activation patching, we do this through attribution: this allows us to efficiently uncover existing circuits with just a single forward pass. Additionally, the applicability of our method is far beyond patching: we do not need a human to carefully design prediction templates, and we can extract information flow routes for any prediction (not just the ones among the allowed templates). As a result, we can talk about model behavior in general, for specific types of predictions, or different domains. We experiment with Llama 2 and show that the rol
    
[^153]: 在合作语言游戏中适应队友

    Adapting to Teammates in a Cooperative Language Game

    [https://arxiv.org/abs/2403.00823](https://arxiv.org/abs/2403.00823)

    这项研究提出了第一个适应Codenames游戏的Agent，采用集成方法来确定最佳匹配的内部专家Agent，从而使Agent能够根据特定队友进行适应。

    

    Codenames游戏最近已成为智能Agent设计领域的一个感兴趣领域。该游戏由于语言和队友之间的协调方式而独具特色。我们提出了第一个适应Codenames游戏的Agent。我们采用一个集成方法，旨在确定，在与特定队友互动过程中，我们内部的哪个专家Agent，每个Agent可能具有自己的语言模型，是最佳匹配的。

    arXiv:2403.00823v1 Announce Type: new  Abstract: The game of Codenames has recently emerged as a domain of interest for intelligent agent design. The game is unique due to the way that language and coordination between teammates play important roles. Previous approaches to designing agents for this game have utilized a single internal language model to determine action choices. This often leads to good performance with some teammates and inferior performance with other teammates, as the agent cannot adapt to any specific teammate. In this paper we present the first adaptive agent for playing Codenames. We adopt an ensemble approach with the goal of determining, during the course of interacting with a specific teammate, which of our internal expert agents, each potentially with its own language model, is the best match. One difficulty faced in this approach is the lack of a single numerical metric that accurately captures the performance of a Codenames team. Prior Codenames research has
    
[^154]: 社交媒体作为传感器：利用自然语言处理分析推特数据以研究乳腺癌药物效果

    Social Media as a Sensor: Analyzing Twitter Data for Breast Cancer Medication Effects Using Natural Language Processing

    [https://arxiv.org/abs/2403.00821](https://arxiv.org/abs/2403.00821)

    本文利用自然语言处理分析推特数据，发展了一种基于Transformer的分类器来识别乳腺癌患者/幸存者，并设计了多层规则模型以研究乳腺癌疗法效果。

    

    乳腺癌是一个重要的公共卫生问题，也是妇女癌症相关死亡的主要原因。尽管乳腺癌治疗取得了进展，药物不依从仍然是一个主要问题。由于电子健康记录通常不捕捉可能揭示关于药物相关经历的患者报告的结果，社交媒体为增进我们对患者治疗经历的理解提供了有吸引力的资源。本文开发了基于自然语言处理（NLP）的方法来研究社交媒体上自动策划的乳腺癌队列发布的信息。我们使用基于Transformer的分类器识别自我报告信息的乳腺癌患者/幸存者，我们从其个人资料中收集了纵向数据。然后，我们设计了一个多层规则模型来开发与乳腺癌疗法相关的sid

    arXiv:2403.00821v1 Announce Type: new  Abstract: Breast cancer is a significant public health concern and is the leading cause of cancer-related deaths among women. Despite advances in breast cancer treatments, medication non-adherence remains a major problem. As electronic health records do not typically capture patient-reported outcomes that may reveal information about medication-related experiences, social media presents an attractive resource for enhancing our understanding of the patients' treatment experiences. In this paper, we developed natural language processing (NLP) based methodologies to study information posted by an automatically curated breast cancer cohort from social media. We employed a transformer-based classifier to identify breast cancer patients/survivors on X (Twitter) based on their self-reported information, and we collected longitudinal data from their profiles. We then designed a multi-layer rule-based model to develop a breast cancer therapy-associated sid
    
[^155]: 检索增强生成系统：自动数据集创建，评估和布尔代理设置

    Retrieval Augmented Generation Systems: Automatic Dataset Creation, Evaluation and Boolean Agent Setup

    [https://arxiv.org/abs/2403.00820](https://arxiv.org/abs/2403.00820)

    本文提出了一种严格的数据集创建和评估工作流程，用于量化比较不同的RAG策略，同时开发和评估了一个布尔代理RAG设置，使得大语言模型可以节省标记来决定是否查询向量数据库。

    

    检索增强生成（RAG）系统在增强大语言模型（LLM）输出中与领域特定和时间敏感数据流行度极高。最近，从简单的RAG设置每次用户输入都查询向量数据库以获取附加信息的方式，正在转变为更复杂形式的RAG。然而，目前各种具体方法仍主要基于大多是偶然证据竞争。本文提出了一个严格的数据集创建和评估工作流程，以定量比较不同的RAG策略。我们使用以这种方式创建的数据集来开发和评估布尔代理RAG设置：一个系统，其中LLM可以决定是否查询向量数据库，从而节省可以用内部知识回答的问题的标记。我们将我们的代码和生成的数据集在线发布。

    arXiv:2403.00820v1 Announce Type: cross  Abstract: Retrieval Augmented Generation (RAG) systems have seen huge popularity in augmenting Large-Language Model (LLM) outputs with domain specific and time sensitive data. Very recently a shift is happening from simple RAG setups that query a vector database for additional information with every user input to more sophisticated forms of RAG. However, different concrete approaches compete on mostly anecdotal evidence at the moment. In this paper we present a rigorous dataset creation and evaluation workflow to quantitatively compare different RAG strategies. We use a dataset created this way for the development and evaluation of a boolean agent RAG setup: A system in which a LLM can decide whether to query a vector database or not, thus saving tokens on questions that can be answered with internal knowledge. We publish our code and generated dataset online.
    
[^156]: DenseMamba: 具有密集隐藏连接的状态空间模型，用于高效大型语言模型

    DenseMamba: State Space Models with Dense Hidden Connection for Efficient Large Language Models

    [https://arxiv.org/abs/2403.00818](https://arxiv.org/abs/2403.00818)

    DenseSSM是一种新方法，通过密集连接增强了状态空间模型(SSM)，有效地提升了各层之间隐藏信息的流动，在保持训练并行性和推理效率的同时，取得了显著的性能提升。

    

    大型语言模型(LLMs)面临着由普遍使用的Transformer架构过高的计算和内存需求而带来的巨大挑战。而状态空间模型(SSM)是一种新型基础网络架构，具有较低的计算复杂度，但其性能尚未完全能与Transformer相媲美。本文引入了DenseSSM，一种增强SSMs中各层之间隐藏信息流动的新方法。通过有选择地将浅层隐藏状态集成到更深层，DenseSSM保留了对最终输出至关重要的细粒度信息。密集连接增强的DenseSSM仍保持了训练的并行性和推理效率。该方法可以广泛适用于RetNet和Mamba等各种SSM类型。在相似的模型大小下，DenseSSM取得了显著的改进，例如DenseRetNet比原始RetNet提高了高达5%的准确率。

    arXiv:2403.00818v1 Announce Type: new  Abstract: Large language models (LLMs) face a daunting challenge due to the excessive computational and memory requirements of the commonly used Transformer architecture. While state space model (SSM) is a new type of foundational network architecture offering lower computational complexity, their performance has yet to fully rival that of Transformers. This paper introduces DenseSSM, a novel approach to enhance the flow of hidden information between layers in SSMs. By selectively integrating shallowlayer hidden states into deeper layers, DenseSSM retains fine-grained information crucial for the final output. Dense connections enhanced DenseSSM still maintains the training parallelizability and inference efficiency. The proposed method can be widely applicable to various SSM types like RetNet and Mamba. With similar model size, DenseSSM achieves significant improvements, exemplified by DenseRetNet outperforming the original RetNet with up to 5% ac
    
[^157]: RAM-EHR: 电子健康记录上的检索增强与临床预测相遇

    RAM-EHR: Retrieval Augmentation Meets Clinical Predictions on Electronic Health Records

    [https://arxiv.org/abs/2403.00815](https://arxiv.org/abs/2403.00815)

    RAM-EHR通过增强检索并利用总结知识，提高了针对电子健康记录的临床预测效果。

    

    我们提出了RAM-EHR，这是一个用于改善电子健康记录（EHR）上临床预测的检索增强（Retrieval Augmentation）流程。RAM-EHR首先收集多个知识来源，将它们转换为文本格式，并使用密集检索来获取与医学概念相关的信息。这一策略解决了与复杂概念名称相关的困难。RAM-EHR然后增广了与一致性正则化代码联合训练的本地EHR预测模型，以捕获来自患者就诊和总结知识的互补信息。在两个EHR数据集上的实验表明，RAM-EHR相对于之前的知识增强基线效果显著（AUROC增益3.4％，AUPR增益7.2％），强调了RAM-EHR的总结知识对临床预测任务的有效性。代码将发布在\url{https://github.com/ritaranx/RAM-EHR}。

    arXiv:2403.00815v1 Announce Type: cross  Abstract: We present RAM-EHR, a Retrieval AugMentation pipeline to improve clinical predictions on Electronic Health Records (EHRs). RAM-EHR first collects multiple knowledge sources, converts them into text format, and uses dense retrieval to obtain information related to medical concepts. This strategy addresses the difficulties associated with complex names for the concepts. RAM-EHR then augments the local EHR predictive model co-trained with consistency regularization to capture complementary information from patient visits and summarized knowledge. Experiments on two EHR datasets show the efficacy of RAM-EHR over previous knowledge-enhanced baselines (3.4% gain in AUROC and 7.2% gain in AUPR), emphasizing the effectiveness of the summarized knowledge from RAM-EHR for clinical prediction tasks. The code will be published at \url{https://github.com/ritaranx/RAM-EHR}.
    
[^158]: UrbanGPT: 时空大型语言模型

    UrbanGPT: Spatio-Temporal Large Language Models

    [https://arxiv.org/abs/2403.00813](https://arxiv.org/abs/2403.00813)

    都市GPT旨在建立一个具有强大泛化能力的时空模型，借鉴大型语言模型的成就。

    

    都市GPT旨在预测并洞察城市环境在时间和空间上不断变化的动态。其目的是预测都市生活各个方面的未来模式、趋势和事件，包括交通、人口流动和犯罪率等。尽管已经付出了大量努力开发神经网络技术以准确预测时空数据，但需注意到很多方法在生成精确的时空表示时严重依赖于有足够标记的数据。不幸的是，在实际都市感知场景中，数据稀缺是一个普遍存在的问题。因此，建立一个具有强大泛化能力的时空模型跨越多样时空学习场景是必要的。受大型语言模型(LLM)卓越成就的启发，我们的目标是

    arXiv:2403.00813v1 Announce Type: cross  Abstract: Spatio-temporal prediction aims to forecast and gain insights into the ever-changing dynamics of urban environments across both time and space. Its purpose is to anticipate future patterns, trends, and events in diverse facets of urban life, including transportation, population movement, and crime rates. Although numerous efforts have been dedicated to developing neural network techniques for accurate predictions on spatio-temporal data, it is important to note that many of these methods heavily depend on having sufficient labeled data to generate precise spatio-temporal representations. Unfortunately, the issue of data scarcity is pervasive in practical urban sensing scenarios. Consequently, it becomes necessary to build a spatio-temporal model with strong generalization capabilities across diverse spatio-temporal learning scenarios. Taking inspiration from the remarkable achievements of large language models (LLMs), our objective is 
    
[^159]: LoRA在统一框架下遇见了Dropout

    LoRA Meets Dropout under a Unified Framework

    [https://arxiv.org/abs/2403.00812](https://arxiv.org/abs/2403.00812)

    LoRA是一个轻量级的参数高效微调方法，该论文研究了LoRA与dropout方法在模型定制中的矛盾，重新审视了transformer-specific的dropout方法，并建立了它们之间的数学和经验上的等价性和区别。

    

    具有显著能力的大型语言模型（LLMs）已成为许多自然语言处理应用中不可或缺的元素，而参数高效微调，特别是LoRA，已经成为模型定制的轻量级方法的流行选择。同时，各种dropout方法最初是为所有参数进行完整微调而设计的，有助于减轻与过多参数冗余相关的过拟合问题。因此，LoRA的可训练参数微不足道与先前dropout方法的有效性之间存在可能的矛盾，这一点之前大多被忽视。为填补这一空白，我们首先确认高效参数的LoRA也容易出现过拟合问题。然后，我们重新审视特定于transformer的dropout方法，从数学和经验上建立它们的等价性和区别。基于这种比较分析，我们引入了一个统一框架进行全面研究，

    arXiv:2403.00812v1 Announce Type: cross  Abstract: With the remarkable capabilities, large language models (LLMs) have emerged as essential elements in numerous NLP applications, while parameter-efficient finetuning, especially LoRA, has gained popularity as a lightweight approach for model customization. Meanwhile, various dropout methods, initially designed for full finetuning with all the parameters updated, alleviates overfitting associated with excessive parameter redundancy. Hence, a possible contradiction arises from negligible trainable parameters of LoRA and the effectiveness of previous dropout methods, which has been largely overlooked. To fill this gap, we first confirm that parameter-efficient LoRA is also overfitting-prone. We then revisit transformer-specific dropout methods, and establish their equivalence and distinctions mathematically and empirically. Building upon this comparative analysis, we introduce a unified framework for a comprehensive investigation, which in
    
[^160]: LLM在高风险决策中的认知偏见

    Cognitive Bias in High-Stakes Decision-Making with LLMs

    [https://arxiv.org/abs/2403.00811](https://arxiv.org/abs/2403.00811)

    提出了BiasBuster框架，用于揭示、评估和减轻LLMs中的认知偏见，特别是在高风险决策任务中，通过开发包含16,800个提示的数据集和测试多种偏见缓解策略，并提出一种利用LLMs自身来消除其提示中偏见的新方法。

    

    大型语言模型(LLMs)在支持日益扩大的决策任务方面具有重要潜力。然而，由于它们在人类(创造的)数据上训练，LLMs可能会继承针对受保护群体的社会偏见，同时也可能受到认知偏见的影响。这种类似于人类的偏见可能会妨碍利用LLM协助做出公平和可解释的决策。我们的工作引入了BiasBuster，一个旨在揭示、评估和减轻LLMs中的认知偏见的框架，特别是在高风险决策任务中。受心理学和认知科学先前研究的启发，我们开发了一个包含16,800个提示的数据集，用于评估不同认知偏见(例如，提示诱导、顺序、固有)。我们测试了各种偏见缓解策略，同时提出了一种新方法，利用LLMs来消除它们自己的提示中的偏见。我们的分析提供了关于不同领域认知偏见存在和影响的全面图景。

    arXiv:2403.00811v1 Announce Type: new  Abstract: Large language models (LLMs) offer significant potential as tools to support an expanding range of decision-making tasks. However, given their training on human (created) data, LLMs can inherit both societal biases against protected groups, as well as be subject to cognitive bias. Such human-like bias can impede fair and explainable decisions made with LLM assistance. Our work introduces BiasBuster, a framework designed to uncover, evaluate, and mitigate cognitive bias in LLMs, particularly in high-stakes decision-making tasks. Inspired by prior research in psychology and cognitive sciences, we develop a dataset containing 16,800 prompts to evaluate different cognitive biases (e.g., prompt-induced, sequential, inherent). We test various bias mitigation strategies, amidst proposing a novel method using LLMs to debias their own prompts. Our analysis provides a comprehensive picture on the presence and effects of cognitive bias across diffe
    
[^161]: 利用大型语言模型引导认知Agent

    Bootstrapping Cognitive Agents with a Large Language Model

    [https://arxiv.org/abs/2403.00810](https://arxiv.org/abs/2403.00810)

    通过利用大型语言模型中的知识，我们将认知模型与大语言模型相结合，提出了一种通过具身Agent完成任务的框架，相较于完全基于大语言模型的Agent，具有更好的效率。

    

    大型语言模型包含世界的杂乱一般知识，但很难进行训练或微调。另一方面，认知架构具有出色的可解释性和更新的灵活性，但需要大量手动工作来实例化。在这项工作中，我们结合了两个世界的优势：用大型语言模型编码的杂乱知识引导认知模型。通过一个做厨房任务的具身Agent，我们展示了我们提出的框架相比完全基于大型语言模型的Agent具有更好的效率。我们的实验表明，大型语言模型是认知架构的信息来源，而认知架构反过来可以验证并更新大型语言模型对特定领域的知识。

    arXiv:2403.00810v1 Announce Type: new  Abstract: Large language models contain noisy general knowledge of the world, yet are hard to train or fine-tune. On the other hand cognitive architectures have excellent interpretability and are flexible to update but require a lot of manual work to instantiate. In this work, we combine the best of both worlds: bootstrapping a cognitive-based model with the noisy knowledge encoded in large language models. Through an embodied agent doing kitchen tasks, we show that our proposed framework yields better efficiency compared to an agent based entirely on large language models. Our experiments indicate that large language models are a good source of information for cognitive architectures, and the cognitive architecture in turn can verify and update the knowledge of large language models to a specific domain.
    
[^162]: Abdelhak在SemEval-2024任务9中的表现：解码谜题，专用模型与ChatGPT的有效性比较

    Abdelhak at SemEval-2024 Task 9 : Decoding Brainteasers, The Efficacy of Dedicated Models Versus ChatGPT

    [https://arxiv.org/abs/2403.00809](https://arxiv.org/abs/2403.00809)

    本研究提出了一个专用模型，在解决谜题任务中表现出色，并与ChatGPT进行了比较性能分析，发现专用模型在横向思维和问题解决方面具有明显优势。

    

    这项研究介绍了一个旨在解决任务9的BRAINTEASER问题的专用模型，这是一个通过句子和单词谜题来评估模型横向思维能力的新挑战。我们的模型表现出显著的效果，在测试阶段中以0.98的总分数在句子谜题解决方面获得了第一名。此外，我们探讨了ChatGPT的比较表现，特别分析了温度设置的变化如何影响其进行横向思维和问题解决的能力。我们的研究结果表明，专用模型和ChatGPT之间存在显著的性能差异，突出了专门方法在增强AI创造性推理方面的潜力。

    arXiv:2403.00809v1 Announce Type: cross  Abstract: This study introduces a dedicated model aimed at solving the BRAINTEASER task 9 , a novel challenge designed to assess models lateral thinking capabilities through sentence and word puzzles. Our model demonstrates remarkable efficacy, securing Rank 1 in sentence puzzle solving during the test phase with an overall score of 0.98. Additionally, we explore the comparative performance of ChatGPT, specifically analyzing how variations in temperature settings affect its ability to engage in lateral thinking and problem-solving. Our findings indicate a notable performance disparity between the dedicated model and ChatGPT, underscoring the potential of specialized approaches in enhancing creative reasoning in AI.
    
[^163]: 基于扩散模型的关系三元组提取的隐式透视IPED

    IPED: An Implicit Perspective for Relational Triple Extraction based on Diffusion Model

    [https://arxiv.org/abs/2403.00808](https://arxiv.org/abs/2403.00808)

    提出了一种基于扩散模型的IPED方法，采用隐式答案策略完成表格，在关系三元组提取中取得了有效结果

    

    关系三元组提取是信息提取领域中的一项基本任务，最近一种基于表填充的前景框架作为一种潜在的实体关系提取基准引起了关注。 但是，固有的缺点，例如冗余信息和不完整三元组识别仍然存在问题。 为了解决这些挑战，我们提出了一种基于扩散模型的隐式角度的关系三元组提取（IPED），这是一种用于提取关系三元组的创新方法。 我们的无分类器解决方案采用隐式策略，使用块覆盖完成表格，避免了显式标记方法的局限性。 另外，我们引入了一个生成模型结构，块去噪扩散模型，与我们的隐式透视合作，并有效地规避了冗余信息干扰。 两个流行数据集上的实验结果表明，I

    arXiv:2403.00808v1 Announce Type: cross  Abstract: Relational triple extraction is a fundamental task in the field of information extraction, and a promising framework based on table filling has recently gained attention as a potential baseline for entity relation extraction. However, inherent shortcomings such as redundant information and incomplete triple recognition remain problematic. To address these challenges, we propose an Implicit Perspective for relational triple Extraction based on Diffusion model (IPED), an innovative approach for extracting relational triples. Our classifier-free solution adopts an implicit strategy using block coverage to complete the tables, avoiding the limitations of explicit tagging methods. Additionally, we introduce a generative model structure, the block-denoising diffusion model, to collaborate with our implicit perspective and effectively circumvent redundant information disruptions. Experimental results on two popular datasets demonstrate that I
    
[^164]: 利用Elasticsearch和Transformer模型增强基于云的大型语言模型处理

    Enhancing Cloud-Based Large Language Model Processing with Elasticsearch and Transformer Models

    [https://arxiv.org/abs/2403.00807](https://arxiv.org/abs/2403.00807)

    利用Elasticsearch和Transformer模型提升云端基于大型语言模型的处理，尤其在实现语义搜索方面有显著帮助。

    

    大型语言模型(LLMs)是一类利用Transformer网络构建的生成式人工智能模型，能够利用大量数据集识别、总结、翻译、预测和生成语言。LLMs承诺改变社会，然而训练这些基础模型面临巨大挑战。在大型语言模型中进行语义向量搜索是一种强大的技术，可以显著增强搜索结果的准确性和相关性。与传统基于关键词的搜索方法不同，语义搜索利用单词的含义和上下文来理解查询背后的意图，并提供更精确的结果。Elasticsearch是一种最流行的工具之一，用于实现语义搜索，是一个专为索引和搜索大数据集设计的可扩展和稳健的搜索引擎。在本文中，我们深入探讨了语义搜索的基础知识，并探讨了如何利用Elasticsearch和Transformer模型。

    arXiv:2403.00807v1 Announce Type: cross  Abstract: Large Language Models (LLMs) are a class of generative AI models built using the Transformer network, capable of leveraging vast datasets to identify, summarize, translate, predict, and generate language. LLMs promise to revolutionize society, yet training these foundational models poses immense challenges. Semantic vector search within large language models is a potent technique that can significantly enhance search result accuracy and relevance. Unlike traditional keyword-based search methods, semantic search utilizes the meaning and context of words to grasp the intent behind queries and deliver more precise outcomes. Elasticsearch emerges as one of the most popular tools for implementing semantic search an exceptionally scalable and robust search engine designed for indexing and searching extensive datasets. In this article, we delve into the fundamentals of semantic search and explore how to harness Elasticsearch and Transformer m
    
[^165]: 通过机器学习语言模型增强操作系统中的用户交互

    Enhanced User Interaction in Operating Systems through Machine Learning Language Models

    [https://arxiv.org/abs/2403.00806](https://arxiv.org/abs/2403.00806)

    通过结合交互设计和机器学习，提供更高效、个性化的用户体验，满足用户特定需求，持续改善产品质量和性能。

    

    随着大型语言模型展示出类似人类的逻辑推理和理解能力，基于大型语言模型的代理是否能模拟真实用户的交互行为，从而构建一个可靠的虚拟推荐A/B测试场景，帮助推荐研究的应用是一个迫切、重要并具有经济价值的问题。交互设计和机器学习的结合能为产品和服务提供更高效、个性化的用户体验。这种个性化服务可以满足用户的特定需求，提高用户满意度和忠诚度。此外，交互系统可以通过提供良好的用户界面和交互体验来理解用户对产品的看法和需求，然后利用机器学习算法改进和优化产品。这种迭代优化过程可以持续改善产品的质量和性能。

    arXiv:2403.00806v1 Announce Type: cross  Abstract: With the large language model showing human-like logical reasoning and understanding ability, whether agents based on the large language model can simulate the interaction behavior of real users, so as to build a reliable virtual recommendation A/B test scene to help the application of recommendation research is an urgent, important and economic value problem. The combination of interaction design and machine learning can provide a more efficient and personalized user experience for products and services. This personalized service can meet the specific needs of users and improve user satisfaction and loyalty. Second, the interactive system can understand the user's views and needs for the product by providing a good user interface and interactive experience, and then use machine learning algorithms to improve and optimize the product. This iterative optimization process can continuously improve the quality and performance of the produc
    
[^166]: 通过拓扑自然语言分析揭示客户问题

    Uncovering Customer Issues through Topological Natural Language Analysis

    [https://arxiv.org/abs/2403.00804](https://arxiv.org/abs/2403.00804)

    提出了一种利用自然语言技术和拓扑数据分析监控新兴和热门客户问题的机器学习算法。

    

    电子商务公司每天处理大量客户服务请求。尽管通常使用简单的注释系统来总结客户联系的主题，但深入探讨每个具体问题可能具有挑战性。为了解决这一挑战，我们提出了一种新颖的机器学习算法，利用自然语言技术和拓扑数据分析来监控新兴和热门客户问题。我们的方法涉及一种端到端的深度学习框架，同时标记每个客户对话记录的主要问题句，并生成句子嵌入向量。然后我们对嵌入向量进行白化处理，并使用它们构建一个无向图。然后，我们根据每个对话记录的拓扑特性来定义热门和新兴问题。

    arXiv:2403.00804v1 Announce Type: cross  Abstract: E-commerce companies deal with a high volume of customer service requests daily. While a simple annotation system is often used to summarize the topics of customer contacts, thoroughly exploring each specific issue can be challenging. This presents a critical concern, especially during an emerging outbreak where companies must quickly identify and address specific issues. To tackle this challenge, we propose a novel machine learning algorithm that leverages natural language techniques and topological data analysis to monitor emerging and trending customer issues. Our approach involves an end-to-end deep learning framework that simultaneously tags the primary question sentence of each customer's transcript and generates sentence embedding vectors. We then whiten the embedding vectors and use them to construct an undirected graph. From there, we define trending and emerging issues based on the topological properties of each transcript. W
    
[^167]: 自主检索：利用一个大型语言模型构建信息检索系统

    Self-Retrieval: Building an Information Retrieval System with One Large Language Model

    [https://arxiv.org/abs/2403.00801](https://arxiv.org/abs/2403.00801)

    提出了自主检索(Self-Retrieval)，利用一个大型语言模型完全内化信息检索系统的能力，深度利用大型语言模型在信息检索过程中的能力。

    

    大型语言模型的兴起改变了信息检索系统在人类获取信息过程中的角色。由于现有信息检索系统具有孤立的架构和有限的相互作用，无法完全适应直接向人类提供信息转变为间接为大型语言模型提供服务的变化。本文提出了自主检索(Self-Retrieval)，这是一个端到端、以大型语言模型驱动的信息检索架构，可以完全内化信息检索系统所需的能力到单个大型语言模型中，并深度利用大型语言模型在信息检索过程中的能力。具体来说，自主检索通过自然语言索引架构将要检索的语料内化为一个大型语言模型。然后整个检索过程被重新定义为文档生成和自我评估的过程，可以使用单个大型语言模型端到端执行。实验结果表明S

    arXiv:2403.00801v1 Announce Type: cross  Abstract: The rise of large language models (LLMs) has transformed the role of information retrieval (IR) systems in the way to humans accessing information. Due to the isolated architecture and the limited interaction, existing IR systems are unable to fully accommodate the shift from directly providing information to humans to indirectly serving large language models. In this paper, we propose Self-Retrieval, an end-to-end, LLM-driven information retrieval architecture that can fully internalize the required abilities of IR systems into a single LLM and deeply leverage the capabilities of LLMs during IR process. Specifically, Self-retrieval internalizes the corpus to retrieve into a LLM via a natural language indexing architecture. Then the entire retrieval process is redefined as a procedure of document generation and self-assessment, which can be end-to-end executed using a single large language model. Experimental results demonstrate that S
    
[^168]: 借鉴人类思维过程的脑启发两阶段方法：通过模仿人类思维过程增强数学推理能力

    Brain-Inspired Two-Stage Approach: Enhancing Mathematical Reasoning by Imitating Human Thought Processes

    [https://arxiv.org/abs/2403.00800](https://arxiv.org/abs/2403.00800)

    通过模仿人类思维过程，在数学推理任务中提出的Brain方法实现了最先进的性能，并发现计划可以从自然语言、代码或形式语言中明确提取出来。

    

    虽然大型语言模型展示了在解决数学问题方面的新能力，但在复杂的多步数学推理任务中仍然存在挑战。为了提高模型在数学推理任务上的表现，先前的工作通过改进数据的质量和数量，在开源模型上进行了监督微调。在本文中，我们提出了一种名为Brain的新方法，通过使用前额叶模型生成计划，然后使用顶叶模型生成代码并执行以获得答案，来模仿人类思维过程以增强数学推理能力。首先，我们通过此方法与基于Code LLaMA 7B的模型相比实现了SOTA性能。其次，我们发现计划可以明确地从自然语言、代码或形式语言中提取出来。我们的代码和数据可以在https://github.com/cyzhh/Brain上公开获取。

    arXiv:2403.00800v1 Announce Type: cross  Abstract: Although large language models demonstrate emergent abilities in solving math word problems, there is a challenging task in complex multi-step mathematical reasoning tasks. To improve model performance on mathematical reasoning tasks, previous work has conducted supervised fine-tuning on open-source models by improving the quality and quantity of data. In this paper, we propose a novel approach, named Brain, to imitate human thought processes to enhance mathematical reasoning abilities, using the Frontal Lobe Model to generate plans, and then employing the Parietal Lobe Model to generate code and execute to obtain answers. First, we achieve SOTA performance in comparison with Code LLaMA 7B based models through this method. Secondly, we find that plans can be explicitly extracted from natural language, code, or formal language. Our code and data are publicly available at https://github.com/cyzhh/Brain.
    
[^169]: LLM在数学推理中数据能力边界的实证研究

    An Empirical Study of Data Ability Boundary in LLMs' Math Reasoning

    [https://arxiv.org/abs/2403.00799](https://arxiv.org/abs/2403.00799)

    通过确定最优路径集，本研究拓展了LLMs在数学推理任务中的能力边界，提出了一种监督数据策略，通过混合不同类型数据的最小最优集来累积增强模型能力，并实现了SOTA性能。

    

    大型语言模型(LLMs)正在展示对数学推理任务的新兴能力，人们越来越关注通过监督微调（SFT）增强开源LLMs的能力。本文旨在探讨一个通用的监督数据策略，以帮助优化和拓展数学推理能力。首先，我们通过识别推理路径的最优路径集确定推理路径增强的能力边界。其次，我们验证模型不同能力可以通过相应类型数据的最小最优集混合来累积增强，而我们的模型MMOS在更低的构建成本下实现了系列基础模型的SOTA性能。此外，我们指出GSM-HARD并不真正困难，当今的LLMs不再缺乏数值稳健性。此外，我们提供一个用于稳健性测试和教育应用的自动问题生成器。我们的代码和数据可公开获取。

    arXiv:2403.00799v1 Announce Type: cross  Abstract: Large language models (LLMs) are displaying emergent abilities for math reasoning tasks,and there is a growing attention on enhancing the ability of open-source LLMs through supervised fine-tuning (SFT).In this paper, we aim to explore a general data strategy for supervised data to help optimize and expand math reasoning ability.Firstly, we determine the ability boundary of reasoning paths augmentation by identifying these paths' minimal optimal set.Secondly, we validate that different abilities of the model can be cumulatively enhanced by Mix of Minimal Optimal Sets of corresponding types of data, while our models MMOS achieve SOTA performance on series base models under much lower construction costs.Besides, we point out GSM-HARD is not really hard and today's LLMs no longer lack numerical robustness.Also, we provide an Auto Problem Generator for robustness testing and educational applications.Our code and data are publicly available
    
[^170]: 用大语言模型执行自然语言描述的算法：一项研究

    Executing Natural Language-Described Algorithms with Large Language Models: An Investigation

    [https://arxiv.org/abs/2403.00795](https://arxiv.org/abs/2403.00795)

    大语言模型可以有效地执行用自然语言描述的程序，尤其是在不涉及大量数字计算的情况下。

    

    使用自然语言描述的计算机程序一直是计算机科学的追求。随着大语言模型（LLMs）展示出的增强自然语言理解能力的出现，这一目标的道路已经被阐明。本文旨在检验现有LLMs理解和执行自然语言中描述的算法的能力。我们从《算法导论》中选取了一个算法测试集，该书是一本包含许多代表性广泛使用的算法的知名教材。为了系统评估LLMs的代码执行能力，我们选择了30个算法，共生成了300个随机抽样实例，并评估了流行的LLMs是否能够理解和执行这些算法。我们的发现表明，特别是GPT-4等LLMs可以有效地执行用自然语言描述的程序，只要不涉及大量数字计算。

    arXiv:2403.00795v1 Announce Type: cross  Abstract: Executing computer programs described in natural language has long been a pursuit of computer science. With the advent of enhanced natural language understanding capabilities exhibited by large language models (LLMs), the path toward this goal has been illuminated. In this paper, we seek to examine the capacity of present-day LLMs to comprehend and execute algorithms outlined in natural language. We established an algorithm test set sourced from Introduction to Algorithm, a well-known textbook that contains many representative widely-used algorithms. To systematically assess LLMs' code execution abilities, we selected 30 algorithms, generated 300 random-sampled instances in total, and evaluated whether popular LLMs can understand and execute these algorithms. Our findings reveal that LLMs, notably GPT-4, can effectively execute programs described in natural language, as long as no heavy numeric computation is involved. We believe our f
    
[^171]: 认真对待幽默：利用不风趣的大型语言模型构建幽默数据集

    Getting Serious about Humor: Crafting Humor Datasets with Unfunny Large Language Models

    [https://arxiv.org/abs/2403.00794](https://arxiv.org/abs/2403.00794)

    利用大型语言模型生成合成数据，可以帮助改进幽默检测，特别是通过取消幽默元素来评估模型性能。

    

    幽默是人类认知和互动的基本要素。然而，尽管自然语言处理方面取得了近期进展，幽默检测仍然是一项具有挑战性的任务，这是因为幽默文本与类似非幽默文本的数据集稀缺。在我们的研究中，我们探讨了大型语言模型（LLMs）能否通过编辑文本生成用于幽默检测的合成数据。我们在现有人类数据集上对LLMs进行基准测试，并展示当前LLMs在“取消风趣”笑话方面显示出令人印象深刻的能力，这是由人类判断和幽默检测的下游任务衡量而得。我们将我们的方法扩展到了一个混合编码的英语-印地语幽默数据集，在那里我们发现GPT-4的合成数据被双语注释员高度评价，并为幽默分类器提供了具有挑战性的对抗性例子。

    arXiv:2403.00794v1 Announce Type: cross  Abstract: Humor is a fundamental facet of human cognition and interaction. Yet, despite recent advances in natural language processing, humor detection remains a challenging task that is complicated by the scarcity of datasets that pair humorous texts with similar non-humorous counterparts. In our work, we investigate whether large language models (LLMs), can generate synthetic data for humor detection via editing texts. We benchmark LLMs on an existing human dataset and show that current LLMs display an impressive ability to `unfun' jokes, as judged by humans and as measured on the downstream task of humor detection. We extend our approach to a code-mixed English-Hindi humor dataset, where we find that GPT-4's synthetic data is highly rated by bilingual annotators and provides challenging adversarial examples for humor classifiers.
    
[^172]: $\textit{L+M-24}$：在ACL 2024年为语言+分子构建数据集

    $\textit{L+M-24}$: Building a Dataset for Language + Molecules @ ACL 2024

    [https://arxiv.org/abs/2403.00791](https://arxiv.org/abs/2403.00791)

    这个论文介绍了$\textit{L+M-24}$数据集，该数据集专为ACL 2024年的语言+分子研讨会共享任务而设计，重点关注自然语言在分子设计中的三个关键优势：组合性、功能性和抽象性。

    

    语言-分子模型已成为分子发现和理解的一个激动人心的方向。然而，由于分子-语言对数据集的稀缺性，训练这些模型具有挑战性。目前已发布的数据集有以下几种类型：1) 小规模且从现有数据库中抓取，2) 大规模但嘈杂且通过在科学文献上执行实体链接来构建，3) 通过将属性预测数据集转换为自然语言使用模板而构建。在本文档中，我们详细介绍了为ACL 2024年的语言+分子研讨会共享任务创建的$\textit{L+M-24}$数据集。特别地，$\textit{L+M-24}$旨在集中关注自然语言在分子设计中的三项关键优势：组合性、功能性和抽象性。

    arXiv:2403.00791v1 Announce Type: cross  Abstract: Language-molecule models have emerged as an exciting direction for molecular discovery and understanding. However, training these models is challenging due to the scarcity of molecule-language pair datasets. At this point, datasets have been released which are 1) small and scraped from existing databases, 2) large but noisy and constructed by performing entity linking on the scientific literature, and 3) built by converting property prediction datasets to natural language using templates. In this document, we detail the $\textit{L+M-24}$ dataset, which has been created for the Language + Molecules Workshop shared task at ACL 2024. In particular, $\textit{L+M-24}$ is designed to focus on three key benefits of natural language in molecule design: compositionality, functionality, and abstraction.
    
[^173]: PRECISE框架：基于GPT的文本以提高放射学报告的可读性、可靠性和可理解性，实现以患者为中心的护理

    PRECISE Framework: GPT-based Text For Improved Readability, Reliability, and Understandability of Radiology Reports For Patient-Centered Care

    [https://arxiv.org/abs/2403.00788](https://arxiv.org/abs/2403.00788)

    本研究提出并评估了PRECISE框架，利用GPT-4技术提供更易读的胸部X射线报告，以进一步提高放射学报告的可读性、可靠性和可理解性，有助于推动以患者为中心的护理。

    

    本研究介绍并评估了PRECISE框架，利用OpenAI的GPT-4来增强患者参与度，提供更清晰、更易读的六年级阅读水平的胸部X射线报告。该框架在500份报告上进行了测试，显示出在可读性、可靠性和可理解性方面的显著改进。统计分析证实了PRECISE方法的有效性，突显了其在促进健康决策中心的护理交付中的潜力。

    arXiv:2403.00788v1 Announce Type: cross  Abstract: This study introduces and evaluates the PRECISE framework, utilizing OpenAI's GPT-4 to enhance patient engagement by providing clearer and more accessible chest X-ray reports at a sixth-grade reading level. The framework was tested on 500 reports, demonstrating significant improvements in readability, reliability, and understandability. Statistical analyses confirmed the effectiveness of the PRECISE approach, highlighting its potential to foster patient-centric care delivery in healthcare decision-making.
    
[^174]: 利用BERT进行信息检索：调研、应用、资源和挑战

    Utilizing BERT for Information Retrieval: Survey, Applications, Resources, and Challenges

    [https://arxiv.org/abs/2403.00784](https://arxiv.org/abs/2403.00784)

    BERT的引入为信息检索领域带来了突破，研究者们将其应用于解决实际问题，并通过综合分析其在信息检索中的应用方法，为学术界和工业界提供了有益的参考。

    

    近年来，深度学习在解决各种自然语言处理（NLP）问题方面得到了显著增长。最初的深度学习模型受到它们顺序或单向性质的限制，因此难以捕捉文本输入之间的上下文关系。从变压器（BERT）中引入的双向编码器表征提供了变压器模型的强大编码器，可以理解更广泛的上下文，并在各种NLP任务中获得最先进的性能。这激发了研究人员和从业者将BERT应用于实际问题，如信息检索（IR）。因此，一项关注将预训练的变压器编码器如BERT应用于IR的普遍方法的综合分析的调查对学术界和工业界都有用。鉴于此，本调查重新审视了各种基于BERT的方法，涵盖了各种方法

    arXiv:2403.00784v1 Announce Type: cross  Abstract: Recent years have witnessed a substantial increase in the use of deep learning to solve various natural language processing (NLP) problems. Early deep learning models were constrained by their sequential or unidirectional nature, such that they struggled to capture the contextual relationships across text inputs. The introduction of bidirectional encoder representations from transformers (BERT) leads to a robust encoder for the transformer model that can understand the broader context and deliver state-of-the-art performance across various NLP tasks. This has inspired researchers and practitioners to apply BERT to practical problems, such as information retrieval (IR). A survey that focuses on a comprehensive analysis of prevalent approaches that apply pretrained transformer encoders like BERT to IR can thus be useful for academia and the industry. In light of this, we revisit a variety of BERT-based methods in this survey, cover a wid
    
[^175]: Ploutos：基于金融大型语言模型实现可解释股票走势预测

    Ploutos: Towards interpretable stock movement prediction with financial large language model

    [https://arxiv.org/abs/2403.00782](https://arxiv.org/abs/2403.00782)

    提出了Ploutos，一个新型金融LLM框架，通过PloutosGen和PloutosGPT灵活融合文本和数值信息，提供可解释的股票走势预测

    

    大型语言模型（LLMs）的最新进展开辟了许多领域的新路径。然而，在金融投资领域中，LLMs 的完整潜力仍然大部分未被利用。对于量化金融的典型基于深度学习的方法有两个主要挑战。首先，它们在股票走势预测中灵活融合文本和数值信息上存在困难。其次，传统方法缺乏清晰性和可解释性，这妨碍了它们在需要预测理由的场景中的应用。为了解决上述挑战，我们提出了 Ploutos，一个由 PloutosGen 和 PloutosGPT 组成的新型金融LLM框架。PloutosGen 包含多个主要专家，可以分析不同的模态数据，如文本和数值，并从不同角度提供量化策略。然后 PloutosGPT 结合它们的见解和预测，生成可解释性的推理。

    arXiv:2403.00782v1 Announce Type: cross  Abstract: Recent advancements in large language models (LLMs) have opened new pathways for many domains. However, the full potential of LLMs in financial investments remains largely untapped. There are two main challenges for typical deep learning-based methods for quantitative finance. First, they struggle to fuse textual and numerical information flexibly for stock movement prediction. Second, traditional methods lack clarity and interpretability, which impedes their application in scenarios where the justification for predictions is essential. To solve the above challenges, we propose Ploutos, a novel financial LLM framework that consists of PloutosGen and PloutosGPT. The PloutosGen contains multiple primary experts that can analyze different modal data, such as text and numbers, and provide quantitative strategies from different perspectives. Then PloutosGPT combines their insights and predictions and generates interpretable rationales. To g
    
[^176]: 利用社交网络数据进行区域通货膨胀分析

    Regional inflation analysis using social network data

    [https://arxiv.org/abs/2403.00774](https://arxiv.org/abs/2403.00774)

    本研究利用社交网络数据分析了区域通货膨胀的上升和下降趋势，探讨了社交网络讨论对通货膨胀预期的潜在影响。

    

    通货膨胀是影响任何国家和地区人口的最重要的宏观经济指标之一。通货膨胀受多种因素影响，其中之一是通货膨胀预期。许多央行在实施以通货膨胀目标为核心的货币政策时考虑到这一因素。本研究基于Vkontakte社交网络的非结构化数据，分析了涉及通货膨胀上升和下降趋势的内容（以鄂木斯克地区为例）。

    arXiv:2403.00774v1 Announce Type: cross  Abstract: Inflation is one of the most important macroeconomic indicators that have a great impact on the population of any country and region. Inflation is influenced by range of factors, one of which is inflation expectations. Many central banks take this factor into consideration while implementing monetary policy within the inflation targeting regime. Nowadays, a lot of people are active users of the Internet, especially social networks. There is a hypothesis that people search, read, and discuss mainly only those issues that are of particular interest to them. It is logical to assume that the dynamics of prices may also be in the focus of user discussions. So, such discussions could be regarded as an alternative source of more rapid information about inflation expectations. This study is based on unstructured data from Vkontakte social network to analyze upward and downward inflationary trends (on the example of the Omsk region). The sample
    
[^177]: ROME: 大型语言模型中文本、概率和隐藏状态的记忆洞察

    ROME: Memorization Insights from Text, Probability and Hidden State in Large Language Models

    [https://arxiv.org/abs/2403.00510](https://arxiv.org/abs/2403.00510)

    ROME提出了一种新方法，通过比较记忆和非记忆样本之间的差异，探索大型语言模型中的记忆化，这有助于在不访问训练数据的情况下了解模型记忆的洞察和影响因素。

    

    探究大型语言模型的记忆化具有重要意义。先前的研究建立了用于量化记忆的指标，探讨了各种影响因素，如数据复制、模型大小和提示长度，并通过将模型输出与训练语料库进行比较来评估记忆化。然而，训练语料库规模巨大且其预处理耗时。为了在不访问训练数据的情况下探索记忆化，我们提出了一种名为ROME的新方法，在此方法中，通过比较记忆化和非记忆化样本之间的差异来探索记忆化。具体来说，模型首先将选定的样本分为记忆化和非记忆化组，并通过文本、概率和隐藏状态的见解比较这两组中的演示。实验结果显示包括词长、词性、词频、均值和方差在内的因素的差异。

    arXiv:2403.00510v1 Announce Type: cross  Abstract: Probing the memorization of large language models holds significant importance. Previous works have established metrics for quantifying memorization, explored various influencing factors, such as data duplication, model size, and prompt length, and evaluated memorization by comparing model outputs with training corpora. However, the training corpora are of enormous scale and its pre-processing is time-consuming. To explore memorization without accessing training data, we propose a novel approach, named ROME, wherein memorization is explored by comparing disparities across memorized and non-memorized. Specifically, models firstly categorize the selected samples into memorized and non-memorized groups, and then comparing the demonstrations in the two groups from the insights of text, probability, and hidden state. Experimental findings show the disparities in factors including word length, part-of-speech, word frequency, mean and varianc
    
[^178]: Multimodal ArXiv: 用于提升大型视觉-语言模型对科学理解的数据集

    Multimodal ArXiv: A Dataset for Improving Scientific Comprehension of Large Vision-Language Models

    [https://arxiv.org/abs/2403.00231](https://arxiv.org/abs/2403.00231)

    提出了Multimodal ArXiv数据集，包括ArXivCap和ArXivQA，用于增强大型视觉-语言模型对科学理解的能力，ArXivQA通过科学图生成问题，显著提高了数学推理准确率。

    

    大型视觉-语言模型（LVLMs），以GPT-4V为例，在涉及自然场景中的具体图像的各种任务中表现出色。然而，由于科学领域训练数据集的稀缺，它们在解释抽象图形（例如几何形状和科学图）方面的能力仍然有限。为了填补这一空白，我们介绍了Multimodal ArXiv，包括ArXivCap和ArXivQA，以增强LVLMs的科学理解。ArXivCap是一个包含来自涵盖各种科学领域的572K份ArXiv论文的6.4M张图像和3.9M个标题的图像标题数据集。借鉴ArXivCap，我们介绍了ArXivQA，这是一个通过提示GPT-4V生成的基于科学图的问答数据集。ArXivQA极大地增强了LVLMs的数学推理能力，在多模态数学推理基准上实现了10.4%的绝对准确率提升。此外，利用ArXivCap，我们设计了四个从视觉到文本的任务。

    arXiv:2403.00231v1 Announce Type: cross  Abstract: Large vision-language models (LVLMs), exemplified by GPT-4V, excel across diverse tasks involving concrete images from natural scenes. However, their ability to interpret abstract figures, such as geometry shapes and scientific plots, remains limited due to a scarcity of training datasets in scientific domains. To fill this gap, we introduce Multimodal ArXiv, consisting of ArXivCap and ArXivQA, for enhancing LVLMs scientific comprehension. ArXivCap is a figure-caption dataset comprising 6.4M images and 3.9M captions sourced from 572K ArXiv papers spanning various scientific domains. Drawing from ArXivCap, we introduce ArXivQA, a question-answering dataset generated by prompting GPT-4V based on scientific figures. ArXivQA greatly enhances LVLMs' mathematical reasoning capabilities, achieving a 10.4% absolute accuracy gain on a multimodal mathematical reasoning benchmark. Furthermore, employing ArXivCap, we devise four vision-to-text tas
    
[^179]: 关于语言模型中地理表示的规模定律研究

    On the Scaling Laws of Geographical Representation in Language Models

    [https://arxiv.org/abs/2402.19406](https://arxiv.org/abs/2402.19406)

    地理知识可以在大型语言模型中观察到，随着模型规模增加而一致扩展，但更大的模型无法消除训练数据中的地理偏见。

    

    语言模型长期以来被证明在其隐藏表示中嵌入了地理信息。最近的一项研究将这一结果扩展到了大型语言模型(LLMs)。本文通过观察语言模型规模扩大时地理知识的演化，提出填补现有和最近文献之间的空白。我们展示了即使对于微小模型，地理知识也是可观测的，并且随着模型大小的增加而一致扩展。值得注意的是，我们发现更大的语言模型无法消除训练数据中固有的地理偏见。

    arXiv:2402.19406v1 Announce Type: cross  Abstract: Language models have long been shown to embed geographical information in their hidden representations. This line of work has recently been revisited by extending this result to Large Language Models (LLMs). In this paper, we propose to fill the gap between well-established and recent literature by observing how geographical knowledge evolves when scaling language models. We show that geographical knowledge is observable even for tiny models, and that it scales consistently as we increase the model size. Notably, we observe that larger language models cannot mitigate the geographical bias that is inherent to the training data.
    
[^180]: WanJuan-CC：一个安全且高质量的开源英文网络文本数据集

    WanJuan-CC: A Safe and High-Quality Open-sourced English Webtext Dataset

    [https://arxiv.org/abs/2402.19282](https://arxiv.org/abs/2402.19282)

    WanJuan-CC是一个安全高质量的开源英文网络文本数据集，通过处理大规模的Common Crawl数据并经过多项筛选和过滤步骤得到，为语言模型的预训练提供了重要资源。

    

    本文介绍了 WanJuan-CC，这是一个安全且高质量的开源英文网络文本数据集，来源于Common Crawl数据。研究解决了为语言模型构建大规模预训练数据集所面临的挑战，这需要大量高质量数据。设计了一个全面的流程来处理Common Crawl数据，包括提取、启发式规则过滤、模糊去重、内容安全过滤和数据质量过滤。从大约680亿个原始英文文档中，我们获得了22万亿标记的安全数据，并从中选出了10万亿标记的高质量数据作为WanJuan-CC的一部分。我们已经开源了这个数据集中的3000亿标记。该论文还提供了与数据质量相关的统计信息，使用户可以根据自己的需求选择适当的数据。为评估数据集的质量和实用性，我们使用WanJuan-CC训练了10亿参数和30亿参数的模型。

    arXiv:2402.19282v1 Announce Type: new  Abstract: This paper presents WanJuan-CC, a safe and high-quality open-sourced English webtext dataset derived from Common Crawl data. The study addresses the challenges of constructing large-scale pre-training datasets for language models, which require vast amounts of high-quality data. A comprehensive process was designed to handle Common Crawl data, including extraction, heuristic rule filtering, fuzzy deduplication, content safety filtering, and data quality filtering. From approximately 68 billion original English documents, we obtained 2.22T Tokens of safe data and selected 1.0T Tokens of high-quality data as part of WanJuan-CC. We have open-sourced 300B Tokens from this dataset. The paper also provides statistical information related to data quality, enabling users to select appropriate data according to their needs. To evaluate the quality and utility of the dataset, we trained 1B-parameter and 3B-parameter models using WanJuan-CC and ano
    
[^181]: 让大型语言模型应对最新挑战！一个中文动态问答基准测试

    Let LLMs Take on the Latest Challenges! A Chinese Dynamic Question Answering Benchmark

    [https://arxiv.org/abs/2402.19248](https://arxiv.org/abs/2402.19248)

    本论文提出了CDQA，一个中文动态问答基准测试，致力于提高中文大型语言模型（LLMs）回答动态问题的能力，并通过高质量数据和精细样本分类实现了对LLMs能力更细致的观察。实验结果表明，CDQA具有挑战性且值得进一步研究。

    

    arXiv:2402.19248v1 公告类型：新  摘要：如何更好地评估大型语言模型（LLMs）的能力是当前LLMs研究的焦点和热点。先前的研究指出，由于大规模迭代更新LLMs的成本极高，它们经常无法很好地回答最新的动态问题。为了促进中文LLMs回答动态问题的能力提升，在本文中，我们引入了 CDQA，一个包含与中国互联网上最新新闻相关的问答对的中文动态问答基准测试。我们通过将人类和模型结合的流程获得高质量数据，并根据答案变化频率精细分类样本，以便更细致地观察LLMs的能力。我们还在CDQA上评估和分析了主流和先进的中文LLMs。广泛的实验和宝贵的见解表明，我们提出的CDQA是具有挑战性且值得进一步研究的。

    arXiv:2402.19248v1 Announce Type: new  Abstract: How to better evaluate the capabilities of Large Language Models (LLMs) is the focal point and hot topic in current LLMs research. Previous work has noted that due to the extremely high cost of iterative updates of LLMs, they are often unable to answer the latest dynamic questions well. To promote the improvement of Chinese LLMs' ability to answer dynamic questions, in this paper, we introduce CDQA, a Chinese Dynamic QA benchmark containing question-answer pairs related to the latest news on the Chinese Internet. We obtain high-quality data through a pipeline that combines humans and models, and carefully classify the samples according to the frequency of answer changes to facilitate a more fine-grained observation of LLMs' capabilities. We have also evaluated and analyzed mainstream and advanced Chinese LLMs on CDQA. Extensive experiments and valuable insights suggest that our proposed CDQA is challenging and worthy of more further stud
    
[^182]: 如何理解“支持”？一种隐式增强因果推断方法用于弱监督短语定位

    How to Understand "Support"? An Implicit-enhanced Causal Inference Approach for Weakly-supervised Phrase Grounding

    [https://arxiv.org/abs/2402.19116](https://arxiv.org/abs/2402.19116)

    提出了一种隐式增强因果推断方法（IECI），用于解决弱监督短语定位任务中的挑战，通过标注高质量数据集进行评估，并相比基线方法展现出明显优势。

    

    弱监督短语定位（WPG）是一个新兴的任务，用于推断细粒度短语-区域匹配，仅利用粗粒度的句子-图像对进行训练。然而，现有关于WPG的研究很大程度上忽略了隐式短语-区域匹配关系，这对于评估模型理解深层多模态语义的能力至关重要。为此，本文提出了一种隐式增强因果推断（IECI）方法来解决对建模隐式关系和突出显性关系的挑战。具体而言，该方法分别利用干预和反事实技术来应对上述两个挑战。此外，还标注了一个高质量的隐式增强数据集来评估IECI，详细评估显示IECI相比最先进基线方法有很大优势。特别地，我们观察到了一个有趣的发现。

    arXiv:2402.19116v1 Announce Type: cross  Abstract: Weakly-supervised Phrase Grounding (WPG) is an emerging task of inferring the fine-grained phrase-region matching, while merely leveraging the coarse-grained sentence-image pairs for training. However, existing studies on WPG largely ignore the implicit phrase-region matching relations, which are crucial for evaluating the capability of models in understanding the deep multimodal semantics. To this end, this paper proposes an Implicit-Enhanced Causal Inference (IECI) approach to address the challenges of modeling the implicit relations and highlighting them beyond the explicit. Specifically, this approach leverages both the intervention and counterfactual techniques to tackle the above two challenges respectively. Furthermore, a high-quality implicit-enhanced dataset is annotated to evaluate IECI and detailed evaluations show the great advantages of IECI over the state-of-the-art baselines. Particularly, we observe an interesting findi
    
[^183]: 众包是否让您破产了？使用近端策略优化对预训练语言模型进行成本效益微调

    Is Crowdsourcing Breaking Your Bank? Cost-Effective Fine-Tuning of Pre-trained Language Models with Proximal Policy Optimization

    [https://arxiv.org/abs/2402.18284](https://arxiv.org/abs/2402.18284)

    提出了一种自监督文本排序方法，利用近端策略优化对语言模型进行微调，消除了对人工注释员的需求，实验结果表明该方法训练的模型在各项得分方面明显优于基线

    

    ChatGPT的广泛使用凸显了从人类反馈中进行强化学习的潜力。然而，其训练流程依赖于人工排序，这是一个资源密集型的过程。为了降低劳动成本，我们提出了一种自监督文本排序方法，用于应用近端策略优化来对语言模型进行微调，同时消除了对人工注释员的需求。我们的方法从概率抽样开始，鼓励语言模型为每个输入生成多样化的响应。然后，我们使用TextRank和ISODATA算法，基于语义对这些响应进行排序和聚类。随后，我们构建了一个奖励模型来学习排名并优化我们的生成策略。我们在三个任务上使用两个语言模型进行的实验结果表明，我们的方法训练的模型在BLEU、GLEU和METEOR得分方面明显优于基线。此外，我们的手动评估显示

    arXiv:2402.18284v1 Announce Type: cross  Abstract: Wide usage of ChatGPT has highlighted the potential of reinforcement learning from human feedback. However, its training pipeline relies on manual ranking, a resource-intensive process. To reduce labor costs, we propose a self-supervised text ranking approach for applying Proximal-Policy-Optimization to fine-tune language models while eliminating the need for human annotators. Our method begins with probabilistic sampling to encourage a language model to generate diverse responses for each input. We then employ TextRank and ISODATA algorithms to rank and cluster these responses based on their semantics. Subsequently, we construct a reward model to learn the rank and optimize our generative policy. Our experimental results, conducted using two language models on three tasks, demonstrate that the models trained by our method considerably outperform baselines regarding BLEU, GLEU, and METEOR scores. Furthermore, our manual evaluation show
    
[^184]: 学习还是自我调整？重新思考指导微调

    Learning or Self-aligning? Rethinking Instruction Fine-tuning

    [https://arxiv.org/abs/2402.18243](https://arxiv.org/abs/2402.18243)

    本研究揭示了指导微调的潜在机制，发现尝试通过指导微调学习额外世界知识往往难以产生积极影响，重点在于保持内部知识一致性。

    

    指导微调（IFT）是构建大型语言模型（LLM）中至关重要的阶段。先前的研究主要关注IFT在行为规范传递和额外世界知识学习中的作用。然而，对IFT潜在机制的理解仍然相当有限。本文设计了一个知识干预框架，以解耦IFT的潜在因素，从而实现对不同因素的个体分析。令人惊讶的是，我们的实验揭示，通过IFT试图学习额外的世界知识往往难以产生积极影响，甚至可能导致明显负面影响。此外，我们发现在IFT之前和之后保持内部知识一致性是实现成功IFT的关键因素。我们的研究结果揭示了IFT的潜在机制，并为最新和潜在未来的研究提供了有力支持。

    arXiv:2402.18243v1 Announce Type: new  Abstract: Instruction Fine-tuning~(IFT) is a critical phase in building large language models~(LLMs). Previous works mainly focus on the IFT's role in the transfer of behavioral norms and the learning of additional world knowledge. However, the understanding of the underlying mechanisms of IFT remains significantly limited. In this paper, we design a knowledge intervention framework to decouple the potential underlying factors of IFT, thereby enabling individual analysis of different factors. Surprisingly, our experiments reveal that attempting to learn additional world knowledge through IFT often struggles to yield positive impacts and can even lead to markedly negative effects. Further, we discover that maintaining internal knowledge consistency before and after IFT is a critical factor for achieving successful IFT. Our findings reveal the underlying mechanisms of IFT and provide robust support for some very recent and potential future works.
    
[^185]: 基于语言模型的本体论中新概念放置框架

    A Language Model based Framework for New Concept Placement in Ontologies

    [https://arxiv.org/abs/2402.17897](https://arxiv.org/abs/2402.17897)

    提出了一种基于语言模型的框架，用于将从文本中提取的新概念插入到本体中，在边搜索、边形成和增强、边选择三个步骤中分别利用神经方法，并在 SNOMED CT 本体和 MedMentions 实体链接基准上进行了评估

    

    我们研究了利用语言模型将从文本中提取的新概念插入本体的任务。我们探索了一个三步方法：边搜索，即找到要插入的候选位置集（即概念之间的包含关系），边形成和增强，利用本体结构生成和增强边候选，以及边选择，最终确定要放置的边。在所有步骤中，我们提出利用神经方法，其中应用基于嵌入的方法和对比学习，如BERT用于边搜索，采用基于BERT微调的多标签边交叉编码器，以及GPT系列、FLAN-T5 和 Llama 2 等大型语言模型（LLM）用于边选择。我们在使用 SNOMED CT 本体和 MedMentions 实体链接基准创建的最新数据集上评估了这些方法。

    arXiv:2402.17897v1 Announce Type: new  Abstract: We investigate the task of inserting new concepts extracted from texts into an ontology using language models. We explore an approach with three steps: edge search which is to find a set of candidate locations to insert (i.e., subsumptions between concepts), edge formation and enrichment which leverages the ontological structure to produce and enhance the edge candidates, and edge selection which eventually locates the edge to be placed into. In all steps, we propose to leverage neural methods, where we apply embedding-based methods and contrastive learning with Pre-trained Language Models (PLMs) such as BERT for edge search, and adapt a BERT fine-tuning-based multi-label Edge-Cross-encoder, and Large Language Models (LLMs) such as GPT series, FLAN-T5, and Llama 2, for edge selection. We evaluate the methods on recent datasets created using the SNOMED CT ontology and the MedMentions entity linking benchmark. The best settings in our fram
    
[^186]: JMLR：联合医疗LLM和检索训练以增强推理和专业问题回答能力

    JMLR: Joint Medical LLM and Retrieval Training for Enhancing Reasoning and Professional Question Answering Capability

    [https://arxiv.org/abs/2402.17887](https://arxiv.org/abs/2402.17887)

    JMLR通过联合训练信息检索系统和大型语言模型，在医学领域提高问题回答系统性能，降低计算资源需求，增强模型利用医疗知识进行推理和回答问题的能力。

    

    随着医疗数据的爆炸性增长和人工智能技术的快速发展，精准医学已经成为增强医疗服务质量和效率的关键。在这种背景下，大型语言模型（LLMs）在医疗知识获取和问题回答系统中发挥越来越重要的作用。为了进一步提高这些系统在医学领域的性能，我们介绍了一种创新方法，在微调阶段同时训练信息检索（IR）系统和LLM。我们称之为联合医疗LLM和检索训练（JMLR）的方法旨在克服传统模型在处理医学问题回答任务时面临的挑战。通过采用同步训练机制，JMLR减少了对计算资源的需求，并增强了模型利用医疗知识进行推理和回答问题的能力。

    arXiv:2402.17887v1 Announce Type: new  Abstract: With the explosive growth of medical data and the rapid development of artificial intelligence technology, precision medicine has emerged as a key to enhancing the quality and efficiency of healthcare services. In this context, Large Language Models (LLMs) play an increasingly vital role in medical knowledge acquisition and question-answering systems. To further improve the performance of these systems in the medical domain, we introduce an innovative method that jointly trains an Information Retrieval (IR) system and an LLM during the fine-tuning phase. This approach, which we call Joint Medical LLM and Retrieval Training (JMLR), is designed to overcome the challenges faced by traditional models in handling medical question-answering tasks. By employing a synchronized training mechanism, JMLR reduces the demand for computational resources and enhances the model's ability to leverage medical knowledge for reasoning and answering question
    
[^187]: 实现语言模型的最佳学习

    Towards Optimal Learning of Language Models

    [https://arxiv.org/abs/2402.17759](https://arxiv.org/abs/2402.17759)

    本论文提出了一种关于语言模型最佳学习的理论，通过最大化数据压缩比率来优化学习过程，根据学习定律揭示了最佳学习过程的特性，并在实验中验证了该定理。

    

    这项工作研究了改进语言模型（LMs）学习的一般原则，旨在减少实现优越性能所需的训练步骤。具体来说，我们提出了一种关于LMs的最佳学习的理论。我们首先提出了一个通过在“LM训练作为无损压缩”视图中最大化数据压缩比率来优化LM学习的目标。然后，我们推导出一个定理，名为学习定律，揭示了在我们的目标下最佳学习过程中动态的特性。随后，我们通过线性分类和现实世界的语言建模任务上的实验验证了该定理。最后，我们经验证明，LMs的最佳学习主要源于改善LMs的缩放定律的系数，为设计实际学习加速方法展示了巨大的前景和重要性。我们的代码可以在https://aka.ms/LearningLaw找到。

    arXiv:2402.17759v1 Announce Type: new  Abstract: This work studies the general principles of improving the learning of language models (LMs), which aims at reducing the necessary training steps for achieving superior performance. Specifically, we present a theory for the optimal learning of LMs. We first propose an objective that optimizes LM learning by maximizing the data compression ratio in an "LM-training-as-lossless-compression" view. Then, we derive a theorem, named Learning Law, to reveal the properties of the dynamics in the optimal learning process under our objective. The theorem is then validated by experiments on a linear classification and a real-world language modeling task. Finally, we empirically verify that the optimal learning of LMs essentially stems from the improvement of the coefficients in the scaling law of LMs, indicating great promise and significance for designing practical learning acceleration methods. Our code can be found at https://aka.ms/LearningLaw.
    
[^188]: Latent Attention for Linear Time Transformers

    Latent Attention for Linear Time Transformers

    [https://arxiv.org/abs/2402.17512](https://arxiv.org/abs/2402.17512)

    提出了一种基于潜在向量定义注意力的方法，将标准transformer中的注意力机制的时间复杂度从二次方降低到与时间线性相关，表现与标准注意力媲美，但允许上下文窗口扩展到远远超出标准的范围。

    

    标准transformer中的注意力机制的时间复杂度随着序列长度的增加呈二次方增长。我们引入一种通过定义潜在向量的注意力来将其降低到与时间线性相关的方法。该方法可以轻松作为标准注意力机制的替代品。我们的“Latte Transformer”模型可用于双向和单向任务，因果版本允许一种在推理语言生成任务中内存和时间高效的递归实现。标准transformer的下一个标记预测随着序列长度线性增长，而Latte Transformer计算下一个标记所需的时间是恒定的。我们的方法的实证表现可与标准注意力媲美，但允许将上下文窗口扩展到远远超出标准注意力实际可行的范围。

    arXiv:2402.17512v1 Announce Type: new  Abstract: The time complexity of the standard attention mechanism in a transformer scales quadratically with the length of the sequence. We introduce a method to reduce this to linear scaling with time, based on defining attention via latent vectors. The method is readily usable as a drop-in replacement for the standard attention mechanism. Our "Latte Transformer" model can be implemented for both bidirectional and unidirectional tasks, with the causal version allowing a recurrent implementation which is memory and time-efficient during inference of language generation tasks. Whilst next token prediction scales linearly with the sequence length for a standard transformer, a Latte Transformer requires constant time to compute the next token. The empirical performance of our method is comparable to standard attention, yet allows scaling to context windows much larger than practical in standard attention.
    
[^189]: 一致性至关重要：从黑盒角度探索LLMs的一致性

    Consistency Matters: Explore LLMs Consistency From a Black-Box Perspective

    [https://arxiv.org/abs/2402.17411](https://arxiv.org/abs/2402.17411)

    该论文探讨了LLMs的一致性问题，提出了一种解决方案，并设计了数据集和基准模型进行实验，结果显示在一致性任务上超过了GPT3.5等模型

    

    现如今，商业和开源学术LLM已成为自然语言处理的主流模型。然而，对LLM一致性的研究仍然不足，这意味着在LLM研究和部署的各个阶段中，其内部参数和能力应保持不变。这一问题存在于工业和学术领域。解决这个问题通常耗时且劳力密集，还有额外的二次部署成本，导致经济和时间损失。为弥补这一空白，我们建立了一个LLM一致性任务数据集，并设计了几个基准。此外，我们选择了不同规模的模型进行主要实验。具体来说，在LightGBM实验中，我们使用传统的自然语言生成度量（如ROUGE、BLEU、METEOR）作为模型训练所需的特征。最终结果超过了人工评估以及GPT3.5和其他模型在主要实验中的表现。

    arXiv:2402.17411v1 Announce Type: new  Abstract: Nowadays both commercial and open-source academic LLM have become the mainstream models of NLP. However, there is still a lack of research on LLM consistency, meaning that throughout the various stages of LLM research and deployment, its internal parameters and capabilities should remain unchanged. This issue exists in both the industrial and academic sectors. The solution to this problem is often time-consuming and labor-intensive, and there is also an additional cost of secondary deployment, resulting in economic and time losses. To fill this gap, we build an LLM consistency task dataset and design several baselines. Additionally, we choose models of diverse scales for the main experiments. Specifically, in the LightGBM experiment, we used traditional NLG metrics (i.e., ROUGE, BLEU, METEOR) as the features needed for model training. The final result exceeds the manual evaluation and GPT3.5 as well as other models in the main experiment
    
[^190]: 超越已知：研究LLMs在领域外意图检测上的表现

    Beyond the Known: Investigating LLMs Performance on Out-of-Domain Intent Detection

    [https://arxiv.org/abs/2402.17256](https://arxiv.org/abs/2402.17256)

    本文综合评估了LLMs在各种实验设置下的表现，发现其展现出强大的零次和少次能力，但与完全资源微调的模型相比仍处于劣势。

    

    领域外（OOD）意图检测旨在检查用户的查询是否超出系统预定义的领域，这对于任务导向对话（TOD）系统的正常运行至关重要。先前的方法通过微调区分模型来解决这个问题。最近，一些研究探索了大型语言模型（LLMs）在各种下游任务中的应用，但它们在OOD检测任务上的能力仍不清楚。本文在各种实验设置下对LLM进行了全面评估，并概述了LLM的优势和劣势。我们发现LLMs表现出强大的零次和少次能力，但与完全资源微调的模型相比仍处于劣势。通过一系列附加分析实验，本文更深入地讨论和总结了LLMs面临的挑战，并为未来工作提供了指导。

    arXiv:2402.17256v1 Announce Type: new  Abstract: Out-of-domain (OOD) intent detection aims to examine whether the user's query falls outside the predefined domain of the system, which is crucial for the proper functioning of task-oriented dialogue (TOD) systems. Previous methods address it by fine-tuning discriminative models. Recently, some studies have been exploring the application of large language models (LLMs) represented by ChatGPT to various downstream tasks, but it is still unclear for their ability on OOD detection task.This paper conducts a comprehensive evaluation of LLMs under various experimental settings, and then outline the strengths and weaknesses of LLMs. We find that LLMs exhibit strong zero-shot and few-shot capabilities, but is still at a disadvantage compared to models fine-tuned with full resource. More deeply, through a series of additional analysis experiments, we discuss and summarize the challenges faced by LLMs and provide guidance for future work including
    
[^191]: LDB：通过逐步验证运行时执行来调试大型语言模型

    LDB: A Large Language Model Debugger via Verifying Runtime Execution Step-by-step

    [https://arxiv.org/abs/2402.16906](https://arxiv.org/abs/2402.16906)

    LDB是一个新颖的调试框架，可以让大型语言模型通过运行时执行信息来完善生成的程序。

    

    大型语言模型（LLMs）在代码生成方面取得了重大进展。最近的研究不仅将单次代码生成，而且还将单元测试和程序验证器整合到LLMs中，以迭代地完善生成的程序。然而，这些工作将生成的程序视为不可分割的实体，这对LLMs在调试程序时存在不足，特别是当程序包含复杂的逻辑流程和数据操作时。相比之下，当人类开发人员调试程序时，他们通常设置断点并有选择地检查运行时执行信息。执行流和中间变量在调试过程中发挥着关键作用，然而现有的代码生成文献中未充分利用它们。本研究引入了大型语言模型调试器（LDB），这是一个新颖的调试框架，可以让LLMs通过运行时执行信息完善其生成的程序。

    arXiv:2402.16906v1 Announce Type: cross  Abstract: Large language models (LLMs) are leading significant progress in code generation. Beyond one-pass code generation, recent works further integrate unit tests and program verifiers into LLMs to iteratively refine the generated programs. However, these works consider the generated programs as an indivisible entity, which falls short for LLMs in debugging the programs, especially when the programs contain complex logic flows and data operations. In contrast, when human developers debug programs, they typically set breakpoints and selectively examine runtime execution information. The execution flow and the intermediate variables play a crucial role in the debugging process, yet they are underutilized in the existing literature on code generation. In this study, we introduce Large Language Model Debugger (LDB), a novel debugging framework that enables LLMs to refine their generated programs with the runtime execution information. Specifical
    
[^192]: 用系统自校正改进基于LLM的机器翻译

    Improving LLM-based Machine Translation with Systematic Self-Correction

    [https://arxiv.org/abs/2402.16379](https://arxiv.org/abs/2402.16379)

    引入了名为TER的系统LLM自校正翻译框架，成功帮助LLMs提高翻译质量，具有更优越的系统性和可解释性。

    

    大型语言模型（LLMs）在机器翻译（MT）领域取得了令人印象深刻的结果。然而，人工仔细评估发现，LLMs生成的翻译仍然包含多个错误。重要的是，将这种错误信息反馈到LLMs中可以实现自校正，并改善翻译性能。受到这些观点的启发，我们引入了一个名为TER的系统LLM自校正翻译框架，代表了在这一方向上的重要进展。我们的研究结果表明：1）我们的自校正框架成功地帮助LLMs提高了多种语言的翻译质量，不管是从高资源语言到低资源语言，还是以英语为中心还是围绕其他语言；2）TER相比先前的方法展示出更优越的系统性和可解释性；3）

    arXiv:2402.16379v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have achieved impressive results in Machine Translation (MT). However, careful evaluations by human reveal that the translations produced by LLMs still contain multiple errors. Importantly, feeding back such error information into the LLMs can lead to self-correction and result in improved translation performance. Motivated by these insights, we introduce a systematic LLM-based self-correcting translation framework, named TER, which stands for Translate, Estimate, and Refine, marking a significant step forward in this direction. Our findings demonstrate that 1) our self-correction framework successfully assists LLMs in improving their translation quality across a wide range of languages, whether it's from high-resource languages to low-resource ones or whether it's English-centric or centered around other languages; 2) TER exhibits superior systematicity and interpretability compared to previous methods; 3)
    
[^193]: FuseChat：对话模型知识融合

    FuseChat: Knowledge Fusion of Chat Models

    [https://arxiv.org/abs/2402.16107](https://arxiv.org/abs/2402.16107)

    FuseChat通过知识融合将多个对话模型的集体知识转移到目标语言模型中，避免了昂贵的预训练成本。

    

    虽然从头开始训练大型语言模型（LLMs）确实可以导致具有独特能力和优势的模型，但这种方法会产生巨大成本，并可能导致竞争能力的潜在冗余。一种替代策略是将现有的LLMs组合成更强大的LLM，从而减少昂贵的预训练的必要性。但是，由于LLMs的多样化架构，直接参数融合被证明是不可行的。最近，FuseLLM引入了知识融合的概念，通过轻量级的持续训练将多个结构多样的LLM的集体知识转移至目标LLM。在本报告中，我们扩展了FuseLLM框架的可扩展性和灵活性，实现了对话LLM的融合，生成了FuseChat。FuseChat包括两个主要阶段。首先，我们对结构和规模不同的源LLMs进行知识融合

    arXiv:2402.16107v1 Announce Type: new  Abstract: While training large language models (LLMs) from scratch can indeed lead to models with distinct capabilities and strengths, this approach incurs substantial costs and may lead to potential redundancy in competencies. An alternative strategy is to combine existing LLMs into a more robust LLM, thereby diminishing the necessity for expensive pre-training. However, due to the diverse architectures of LLMs, direct parameter blending proves to be unfeasible. Recently, \textsc{FuseLLM} introduced the concept of knowledge fusion to transfer the collective knowledge of multiple structurally varied LLMs into a target LLM through lightweight continual training. In this report, we extend the scalability and flexibility of the \textsc{FuseLLM} framework to realize the fusion of chat LLMs, resulting in \textsc{FuseChat}. \textsc{FuseChat} comprises two main stages. Firstly, we undertake knowledge fusion for structurally and scale-varied source LLMs t
    
[^194]: 基于引文增强的LLM聊天机器人生成

    Citation-Enhanced Generation for LLM-based Chatbot

    [https://arxiv.org/abs/2402.16063](https://arxiv.org/abs/2402.16063)

    提出一种基于引文增强的LLM聊天机器人生成方法，采用检索模块搜索支持文档来解决幻觉内容产生的问题。

    

    大型语言模型（LLMs）在各种情景下展现出强大的通用智能，包括将它们集成到聊天机器人中。然而，基于LLM的聊天机器人面临的一个重要挑战是在回复中可能产生虚构内容，这严重限制了它们的适用性。本文提出了一种新颖的后续引用增强生成（CEG）方法，结合检索论证。与先前侧重于预防生成过程中幻觉的研究不同，我们的方法以后续方式解决了这个问题。它结合了一个检索模块来搜索与生成内容相关的支持文档，并采用基于自然语言推理的方法。

    arXiv:2402.16063v1 Announce Type: cross  Abstract: Large language models (LLMs) exhibit powerful general intelligence across diverse scenarios, including their integration into chatbots. However, a vital challenge of LLM-based chatbots is that they may produce hallucinated content in responses, which significantly limits their applicability. Various efforts have been made to alleviate hallucination, such as retrieval augmented generation and reinforcement learning with human feedback, but most of them require additional training and data annotation. In this paper, we propose a novel post-hoc \textbf{C}itation-\textbf{E}nhanced \textbf{G}eneration (\textbf{CEG}) approach combined with retrieval argumentation. Unlike previous studies that focus on preventing hallucinations during generation, our method addresses this issue in a post-hoc way. It incorporates a retrieval module to search for supporting documents relevant to the generated content, and employs a natural language inference-ba
    
[^195]: 大型语言模型如何编码上下文知识？一项逐层探究研究

    How Large Language Models Encode Context Knowledge? A Layer-Wise Probing Study

    [https://arxiv.org/abs/2402.16061](https://arxiv.org/abs/2402.16061)

    本文首次通过探究任务研究了大型语言模型逐层编码知识的能力，实验结果显示LLMs更倾向于在上层编码更多的上下文知识。

    

    先前的研究展示了大型语言模型（LLMs）在检索事实和处理上下文知识方面的引人注目能力。然而，关于LLMs逐层编码知识的能力的研究有限，这挑战了我们对它们内部机制的理解。在本文中，我们致力于通过探究任务来首次研究LLMs逐层的能力。我们利用ChatGPT强大的生成能力构建探究数据集，提供与各种事实相对应的多样且连贯的证据。我们采用$\mathcal V$-usable信息作为验证指标，以更好地反映跨不同层编码上下文知识的能力。我们在有冲突和新获得知识方面的实验表明，LLMs：（1）更倾向于在上层编码更多的上下文知识；（2）主要在与知识相关的实体标记内编码上下文知识

    arXiv:2402.16061v1 Announce Type: new  Abstract: Previous work has showcased the intriguing capability of large language models (LLMs) in retrieving facts and processing context knowledge. However, only limited research exists on the layer-wise capability of LLMs to encode knowledge, which challenges our understanding of their internal mechanisms. In this paper, we devote the first attempt to investigate the layer-wise capability of LLMs through probing tasks. We leverage the powerful generative capability of ChatGPT to construct probing datasets, providing diverse and coherent evidence corresponding to various facts. We employ $\mathcal V$-usable information as the validation metric to better reflect the capability in encoding context knowledge across different layers. Our experiments on conflicting and newly acquired knowledge show that LLMs: (1) prefer to encode more context knowledge in the upper layers; (2) primarily encode context knowledge within knowledge-related entity tokens 
    
[^196]: 从脑信号解码查询语义的查询扩展

    Query Augmentation by Decoding Semantics from Brain Signals

    [https://arxiv.org/abs/2402.15708](https://arxiv.org/abs/2402.15708)

    提出了一种名为Brain-Aug的方法，通过从脑信号中解码的语义信息增强查询，可以生成更准确的查询，改善文档排序性能，特别适用于模糊查询。

    

    查询扩展是用于细化语义不准确查询的关键技术。传统上，查询扩展依赖于从最初检索到的、潜在相关的文档中提取信息。如果最初检索到的文档质量较低，则查询扩展的有效性也会受到限制。我们提出了Brain-Aug，通过将从脑信号解码的语义信息结合到查询中来增强查询。Brain-Aug使用了在脑信号信息构建的提示和面向排名的推理方法生成原始查询的延续部分。对fMRI数据集的实验结果显示，Brain-Aug生成的查询在语义上更准确，导致改进的文档排序性能。脑信号带来的这种改进对于模糊查询特别显著。

    arXiv:2402.15708v1 Announce Type: cross  Abstract: Query augmentation is a crucial technique for refining semantically imprecise queries. Traditionally, query augmentation relies on extracting information from initially retrieved, potentially relevant documents. If the quality of the initially retrieved documents is low, then the effectiveness of query augmentation would be limited as well. We propose Brain-Aug, which enhances a query by incorporating semantic information decoded from brain signals. BrainAug generates the continuation of the original query with a prompt constructed with brain signal information and a ranking-oriented inference approach. Experimental results on fMRI (functional magnetic resonance imaging) datasets show that Brain-Aug produces semantically more accurate queries, leading to improved document ranking performance. Such improvement brought by brain signals is particularly notable for ambiguous queries.
    
[^197]: 有关LLMs指令中心响应的（不道德）程度有多高？揭示安全防护栏对有害查询的漏洞

    How (un)ethical are instruction-centric responses of LLMs? Unveiling the vulnerabilities of safety guardrails to harmful queries

    [https://arxiv.org/abs/2402.15302](https://arxiv.org/abs/2402.15302)

    本研究探讨了大型语言模型（LLMs）对指令中心响应的容忍度，并提出了一个包含复杂查询的数据集，旨在揭示触发不道德响应的方法。

    

    在这项研究中，我们解决了一个围绕大型语言模型（LLMs）安全和道德使用日益关注的问题。尽管这些模型具有潜力，但它们可能会被各种复杂的方法欺骗，产生有害或不道德内容，包括“越狱”技术和有针对性的操纵。我们的工作集中在一个特定问题上：LLMs在要求它们生成以伪代码、程序或软件片段为中心的响应时，有多大程度上可能会被误导，而不是生成普通文本。为了调查这个问题，我们引入了TechHazardQA，一个数据集，其中包含应以文本和以指令为中心格式（例如伪代码）回答的复杂查询，旨在识别不道德响应的触发器。我们查询了一系列LLMs-- Llama-2-13b，Llama-2-7b，Mistral-V2和Mistral 8X7B--并要求它们生成文本和指令为中心的响应。为了评估我们的方法，

    arXiv:2402.15302v1 Announce Type: new  Abstract: In this study, we tackle a growing concern around the safety and ethical use of large language models (LLMs). Despite their potential, these models can be tricked into producing harmful or unethical content through various sophisticated methods, including 'jailbreaking' techniques and targeted manipulation. Our work zeroes in on a specific issue: to what extent LLMs can be led astray by asking them to generate responses that are instruction-centric such as a pseudocode, a program or a software snippet as opposed to vanilla text. To investigate this question, we introduce TechHazardQA, a dataset containing complex queries which should be answered in both text and instruction-centric formats (e.g., pseudocodes), aimed at identifying triggers for unethical responses. We query a series of LLMs -- Llama-2-13b, Llama-2-7b, Mistral-V2 and Mistral 8X7B -- and ask them to generate both text and instruction-centric responses. For evaluation we rep
    
[^198]: OmniPred：语言模型作为通用回归器

    OmniPred: Language Models as Universal Regressors

    [https://arxiv.org/abs/2402.14547](https://arxiv.org/abs/2402.14547)

    本文提出了OmniPred框架，用于训练语言模型作为通用的端到端回归器，实验证明，在多个任务上训练时，语言模型能够显著优于传统回归模型。

    

    在实验设计的广阔领域中，回归一直是一个强大的工具，可以准确预测系统或模型在给定一组参数的情况下的结果指标，但传统上只限于适用于特定任务的方法。在本文中，我们提出了OmniPred，这是一个用于训练语言模型作为通用端到端回归器的框架，使用来自多样真实世界实验的$(x,y)$评估数据。通过使用源自Google Vizier的数据，这是世界上最大的黑盒优化数据库之一，我们的大量实验表明，仅通过数学参数和值的文本表示，语言模型能够进行非常精确的数值回归，如果有机会训练多个任务，则可以显著优于传统的回归模型。

    arXiv:2402.14547v1 Announce Type: cross  Abstract: Over the broad landscape of experimental design, regression has been a powerful tool to accurately predict the outcome metrics of a system or model given a set of parameters, but has been traditionally restricted to methods which are only applicable to a specific task. In this paper, we propose OmniPred, a framework for training language models as universal end-to-end regressors over $(x,y)$ evaluation data from diverse real world experiments. Using data sourced from Google Vizier, one of the largest blackbox optimization databases in the world, our extensive experiments demonstrate that through only textual representations of mathematical parameters and values, language models are capable of very precise numerical regression, and if given the opportunity to train over multiple tasks, can significantly outperform traditional regression models.
    
[^199]: 基于大型语言模型的模态感知集成用于基于知识的视觉问答

    Modality-Aware Integration with Large Language Models for Knowledge-based Visual Question Answering

    [https://arxiv.org/abs/2402.12728](https://arxiv.org/abs/2402.12728)

    提出了一种模态感知的LLM集成方法（MAIL）用于针对KVQA，通过细致地利用多模态知识来处理图像理解和知识推理。

    

    知识驱动的视觉问答（KVQA）已被广泛研究，以利用外部知识如知识图谱（KG）来回答视觉问题。尽管已提出几种尝试利用大型语言模型（LLMs）作为隐含知识源，但由于LLMs可能生成幻觉，因此仍然具有挑战性。此外，多种知识来源，例如图像、知识图谱和LLMs，不能轻易对齐以应对复杂场景。为了解决这些问题，我们提出了一种针对KVQA的新颖的具有模态感知的LLM集成方法（MAIL）。它精心利用多模态知识进行图像理解和知识推理。具体而言，（i）我们提出了一种使用LLMs的两阶段提示策略，将图像密集地融入带有详细视觉特征的场景图中；（ii）我们通过将提到的实体与外部事实联系起来构建一个耦合的概念图；（iii）设计了一个定制的伪孪生图中介融合。

    arXiv:2402.12728v1 Announce Type: cross  Abstract: Knowledge-based visual question answering (KVQA) has been extensively studied to answer visual questions with external knowledge, e.g., knowledge graphs (KGs). While several attempts have been proposed to leverage large language models (LLMs) as an implicit knowledge source, it remains challenging since LLMs may generate hallucinations. Moreover, multiple knowledge sources, e.g., images, KGs and LLMs, cannot be readily aligned for complex scenarios. To tackle these, we present a novel modality-aware integration with LLMs for KVQA (MAIL). It carefully leverages multimodal knowledge for both image understanding and knowledge reasoning. Specifically, (i) we propose a two-stage prompting strategy with LLMs to densely embody the image into a scene graph with detailed visual features; (ii) We construct a coupled concept graph by linking the mentioned entities with external facts. (iii) A tailored pseudo-siamese graph medium fusion is designe
    
[^200]: 基于Transformer的因果语言模型执行聚类

    Transformer-based Causal Language Models Perform Clustering

    [https://arxiv.org/abs/2402.12151](https://arxiv.org/abs/2402.12151)

    Transformer-based因果语言模型通过在隐藏空间内对数据进行聚类来学习任务特定信息，这种聚类过程在学习中动态演变，并有助于处理未见实例。

    

    即使大型语言模型(LLMs)已经展示出在解决各种自然语言任务方面的出色能力，LLM遵循人类指令的能力仍然是一个问题。最近的研究通过额外训练指令遵循任务已经显示出很大改进，然而，导致有效指令遵循能力的机制仍未得到充分理解。本文介绍了一个简化的指令遵循任务，并使用合成数据集分析了基于Transformer的因果语言模型。我们的发现表明，模型通过在其隐藏空间内对数据进行聚类而学习任务特定信息，这种聚类过程在学习过程中动态演变。我们还演示了这种现象如何帮助模型处理未见实例，并在更现实的环境中验证了我们的结果。

    arXiv:2402.12151v1 Announce Type: cross  Abstract: Even though large language models (LLMs) have demonstrated remarkable capability in solving various natural language tasks, the capability of an LLM to follow human instructions is still a concern. Recent works have shown great improvements in the instruction-following capability via additional training for instruction-following tasks. However, the mechanisms responsible for effective instruction-following capabilities remain inadequately understood. Here, we introduce a simplified instruction-following task and use synthetic datasets to analyze a Transformer-based causal language model. Our findings suggest that the model learns task-specific information by clustering data within its hidden space, with this clustering process evolving dynamically during learning. We also demonstrate how this phenomenon assists the model in handling unseen instances and validate our results in a more realistic setting.
    
[^201]: MRKE：通过知识编辑对LLMs进行多跳推理评估

    MRKE: The Multi-hop Reasoning Evaluation of LLMs by Knowledge Edition

    [https://arxiv.org/abs/2402.11924](https://arxiv.org/abs/2402.11924)

    通过编辑HotpotQA数据集中的新知识，我们引入了一个LLM MHQA评估基准，同时注释和评估了推理链，揭示了当前MHQA基准存在数据污染的潜在风险。

    

    虽然大型语言模型（LLMs）在多跳问题回答（MHQA）任务中表现出色，但它们真正的推理能力仍有待探讨。目前的LLM QA评估基准存在一些限制，包括1）数据污染，评估数据可能在预训练阶段暴露给LLMs；以及2）忽视推理链评估。因此，我们引入了一种LLM MHQA评估基准，这是基于编辑现成HotpotQA数据集上的新、前所未有的知识的第一个QA基准；此外，我们还注释和评估了推理链，以子问题和中间答案的形式对应于多跳问题。具体来说，根据观察结果，1）LLMs在原始HotpotQA和我们编辑的数据之间显示性能差距，认为当前的MHQA基准可能存在数据污染的潜在风险，难以评估LLMs的性能。

    arXiv:2402.11924v1 Announce Type: new  Abstract: Although Large Language Models (LLMs) have shown strong performance in Multi-hop Question Answering (MHQA) tasks, their real reasoning ability remains exploration. Current LLM QA evaluation benchmarks have shown limitations, including 1) data contamination, the evaluation data are potentially exposed to LLMs during the pretraining stage; and 2) ignoration of the reasoning chain evaluation. Thus we introduce an LLM MHQA evaluation benchmark, the first QA benchmark based on the new, unprecedented knowledge by editing the off-the-shelf HotpotQA dataset; Besides, we also annotate and evaluate the reasoning chain in the form of sub-questions and intermediate answers corresponding to the multi-hop questions. Specifically, based on the observation, 1) LLMs show a performance gap between the original HotpotQA and our edited data, deeming that current MHQA benchmarks have the potential risk of data contamination that hard to evaluate LLMs' perfor
    
[^202]: 通过基于政策的自我判断来对齐大型语言模型

    Aligning Large Language Models by On-Policy Self-Judgment

    [https://arxiv.org/abs/2402.11253](https://arxiv.org/abs/2402.11253)

    本文提出了一个新颖的对齐框架SELF-JUDGE，通过增加式监督微调（JSFT）训练一个同时充当策略和评判器的单一模型，实现了参数高效的基于政策学习，无需额外的奖励模型。

    

    为了使大型语言模型与人类偏好保持一致，现有研究要么利用单独的奖励模型（RM）执行基于政策的学习，要么通过放弃基于政策的学习和对独立RM的需求简化训练过程。在本文中，我们提出了一个新颖的对齐框架SELF-JUDGE，它既是(1) 基于政策的学习，又是(2) 参数高效的，因为它不需要额外的RM来评估样本进行基于政策的学习。为此，我们提出了增强式监督微调（JSFT）来训练一个单一模型，作为策略和评判器。具体来说，我们将一对一判断任务视为指导式任务的特殊情况，从响应对中选择更好的响应。因此，得到的模型可以评判当前策略的即时响应偏好，从自身初始化。实验结果显示了SELF-JUDGE的有效性，优于基线模型。

    arXiv:2402.11253v1 Announce Type: cross  Abstract: To align large language models with human preferences, existing research either utilizes a separate reward model (RM) to perform on-policy learning or simplifies the training procedure by discarding the on-policy learning and the need for a separate RM. In this paper, we present a novel alignment framework, SELF-JUDGE that is (1) on-policy learning and 2) parameter efficient, as it does not require an additional RM for evaluating the samples for on-policy learning. To this end, we propose Judge-augmented Supervised Fine-Tuning (JSFT) to train a single model acting as both a policy and a judge. Specifically, we view the pairwise judgment task as a special case of the instruction-following task, choosing the better response from a response pair. Thus, the resulting model can judge preferences of on-the-fly responses from current policy initialized from itself. Experimental results show the efficacy of SELF-JUDGE, outperforming baselines 
    
[^203]: 重新审视词嵌入：LLMs是否提供新的东西？

    Word Embeddings Revisited: Do LLMs Offer Something New?

    [https://arxiv.org/abs/2402.11094](https://arxiv.org/abs/2402.11094)

    该论文系统地比较了经典词嵌入技术和基于LLM的词嵌入，发现LLMs倾向于将语义相关的单词更紧密地聚类在一起，并在Bigger Analogy Test Set（BATS）上具有更高的平均准确度。

    

    学习有意义的词嵌入对于训练稳健的语言模型至关重要。最近兴起的大型语言模型（LLMs）为我们提供了许多新的单词/句子/文档嵌入模型。尽管LLMs在各种自然语言处理任务中显示出显着的进步，但仍不清楚性能的提升仅仅是因为规模还是它们生成的底层嵌入与句子-BERT（SBERT）或通用句子编码器（USE）之类的传统编码模型有显著区别。本文通过比较经典词嵌入技术与基于LLM的词嵌入，系统地调查了这个问题，从它们的潜在向量语义方面进行比较。我们的结果显示，LLMs倾向于将语义相关的单词更紧密地聚类在一起，LLMs在Bigger Analogy Test Set（BATS）上的平均准确度也高于经典方法。最后，一些LLMs倾向于产生词嵌入si。

    arXiv:2402.11094v1 Announce Type: new  Abstract: Learning meaningful word embeddings is key to training a robust language model. The recent rise of Large Language Models (LLMs) has provided us with many new word/sentence/document embedding models. Although LLMs have shown remarkable advancement in various NLP tasks, it is still unclear whether the performance improvement is merely because of scale or whether underlying embeddings they produce significantly differ from classical encoding models like Sentence-BERT (SBERT) or Universal Sentence Encoder (USE). This paper systematically investigates this issue by comparing classical word embedding techniques against LLM-based word embeddings in terms of their latent vector semantics. Our results show that LLMs tend to cluster semantically related words more tightly than classical models. LLMs also yield higher average accuracy on the Bigger Analogy Test Set (BATS) over classical methods. Finally, some LLMs tend to produce word embeddings si
    
[^204]: 通过知识蒸馏和优化训练策略，利用大型语言模型提升NLP任务性能

    Leveraging Large Language Models for Enhanced NLP Task Performance through Knowledge Distillation and Optimized Training Strategies

    [https://arxiv.org/abs/2402.09282](https://arxiv.org/abs/2402.09282)

    该论文介绍了一种利用大型语言模型和优化训练策略提高NLP任务性能的新方法，通过知识蒸馏和采用细思连想提示技术，将GPT-4中提炼的知识应用于BERT模型，在命名实体识别任务上取得了显著的性能提升，并为资源有限或封闭网络环境提供了一种成本效益的解决方案。

    

    大型语言模型（LLMs）如GPT-4的整合到传统的自然语言处理（NLP）任务中，为提高模型性能并减少对大量人工注释的依赖打开了新的途径。本文提出了一种利用细思连想（CoT）提示技术从GPT-4中提炼知识，并将其应用于改进较小模型BERT在命名实体识别（NER）任务上的效率和效果的新方法。我们的方法包括两个阶段的训练过程：首先使用GPT-4注释数据进行预训练，然后使用蒸馏和原始人工注释数据的组合对模型进行改进。结果表明，我们的混合训练策略明显优于仅使用人工注释数据训练的模型，在F1分数上表现出卓越的性能，并为资源有限或封闭网络环境提供了一种具有成本效益的解决方案。

    arXiv:2402.09282v1 Announce Type: new Abstract: The integration of Large Language Models (LLMs) like GPT-4 into traditional Natural Language Processing (NLP) tasks has opened new avenues for enhancing model performance while reducing the reliance on extensive human annotations. This paper presents a novel approach that leverages the Chain of Thought (CoT) prompting technique to distill knowledge from GPT-4, subsequently applying it to improve the efficiency and effectiveness of a smaller model, BERT, on Named Entity Recognition (NER) tasks. Our method involves a two-phase training process: initially employing GPT-4 annotated data for pre-training and then refining the model with a combination of distilled and original human-annotated data. The results demonstrate that our mixed-training strategy significantly outperforms models trained solely on human annotations, achieving superior F1-scores and showcasing a cost-effective solution for resource-limited or closed-network settings. The 
    
[^205]: 论据顺序在与大型语言模型推理中起作用

    Premise Order Matters in Reasoning with Large Language Models

    [https://arxiv.org/abs/2402.08939](https://arxiv.org/abs/2402.08939)

    对大型语言模型（LLMs）进行推理任务时，论据的顺序非常重要，尤其是在演绎推理任务中，按照提示的真实证明顺序呈现论据可以显著提高模型的准确性。

    

    大型语言模型（LLMs）在各个领域都取得了惊人的推理性能。然而，在推理任务的领域中，我们发现了一个脆弱性：尽管这种顺序不会改变基本任务，但LLMs对于论据的顺序非常脆弱。特别是，我们观察到当论据顺序与中间推理步骤所需的上下文对齐时，LLMs可以达到最佳性能。例如，在演绎推理任务中，将论据按照提示的真实证明顺序呈现（而不是随机顺序）会极大地提高模型的准确性。我们首先研究了不同LLMs对演绎推理中论据顺序的影响，我们的评估结果表明，调整论据顺序可能导致性能下降超过30％。此外，我们发布了基于GSM8K的基准测试R-GSM来研究顺序效应对数学推理的影响。

    arXiv:2402.08939v1 Announce Type: new Abstract: Large language models (LLMs) have accomplished remarkable reasoning performance in various domains. However, in the domain of reasoning tasks, we discover a frailty: LLMs are surprisingly brittle to the ordering of the premises, despite the fact that such ordering does not alter the underlying task. In particular, we observe that LLMs achieve the best performance when the premise order aligns with the context required in intermediate reasoning steps. For example, in deductive reasoning tasks, presenting the premises in the same order as the ground truth proof in the prompt (as opposed to random ordering) drastically increases the model's accuracy. We first examine the effect of premise ordering on deductive reasoning on a variety of LLMs, and our evaluation shows that permuting the premise order can cause a performance drop of over 30%. In addition, we release the benchmark R-GSM, based on GSM8K, to examine the ordering effect for mathema
    
[^206]: 可扩展的多粒度融合网络用于基于方面的情感分析

    Extensible Multi-Granularity Fusion Network for Aspect-based Sentiment Analysis

    [https://arxiv.org/abs/2402.07787](https://arxiv.org/abs/2402.07787)

    这篇论文提出了一种可扩展的多粒度融合网络（EMGF）用于基于方面的情感分析，通过整合不同的语言和结构特征，包括句法依赖、组成、注意力语义和外部知识图谱等，来提高情感分析的性能和准确性。

    

    基于方面的情感分析（ABSA）评估文本中的情感表达以理解情感信息。先前的研究整合了外部知识，如知识图谱，以加强ABSA模型中的语义特征。最近的研究探讨了在依赖和组成树上使用图神经网络（GNN）进行句法分析。随着ABSA的不断发展，越来越多的创新的语言和结构特征被融入其中（例如潜在图），但这也引入了复杂性和混淆。目前，尚不存在一个可扩展的框架，可以将多样性的语言和结构特征集成到ABSA中。本文介绍了可扩展的多粒度融合（EMGF）网络，它整合了来自句法依赖和组成、注意力语义和外部知识图谱的信息。EMGF配备了多锚点三元学习和正交投影，高效地利用了这些特征的综合潜力。

    Aspect-based Sentiment Analysis (ABSA) evaluates sentiment expressions within a text to comprehend sentiment information. Previous studies integrated external knowledge, such as knowledge graphs, to enhance the semantic features in ABSA models. Recent research has examined the use of Graph Neural Networks (GNNs) on dependency and constituent trees for syntactic analysis. With the ongoing development of ABSA, more innovative linguistic and structural features are being incorporated (e.g. latent graph), but this also introduces complexity and confusion. As of now, a scalable framework for integrating diverse linguistic and structural features into ABSA does not exist. This paper presents the Extensible Multi-Granularity Fusion (EMGF) network, which integrates information from dependency and constituent syntactic, attention semantic , and external knowledge graphs. EMGF, equipped with multi-anchor triplet learning and orthogonal projection, efficiently harnesses the combined potential of 
    
[^207]: SALAD-Bench: 一个针对大语言模型的层次化和全面性安全基准

    SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large Language Models

    [https://arxiv.org/abs/2402.05044](https://arxiv.org/abs/2402.05044)

    SALAD-Bench是一个针对大语言模型的全面安全基准，通过其大规模、丰富的分类和多功能性，以及对攻击和防御方法的评估，实现了对LLMs的有效管理和保护。

    

    在快速发展的大语言模型（LLM）领域中，确保强大的安全措施至关重要。为了满足这一关键需求，我们提出了一种特别设计用于评估LLMs、攻击和防御方法的安全基准，称为SALAD-Bench。SALAD-Bench通过其大规模、丰富多样的特性，以及跨三个层次的细致分类和多功能性，超越了传统基准。SALAD-Bench通过对标准查询和复杂查询（包括攻击、防御修改和多项选择）的精心设计，有效管理其固有的复杂性。为了确保无缝可靠的评估，我们引入了一种创新的评估器：基于LLM的MD-Judge，专注于攻击增强查询的问答对评估。以上组件将SALAD-Bench从标准的LLM安全评估扩展到了LLM攻击和防御方法评估，确保了联合目标的实用性。

    In the rapidly evolving landscape of Large Language Models (LLMs), ensuring robust safety measures is paramount. To meet this crucial need, we propose \emph{SALAD-Bench}, a safety benchmark specifically designed for evaluating LLMs, attack, and defense methods. Distinguished by its breadth, SALAD-Bench transcends conventional benchmarks through its large scale, rich diversity, intricate taxonomy spanning three levels, and versatile functionalities.SALAD-Bench is crafted with a meticulous array of questions, from standard queries to complex ones enriched with attack, defense modifications and multiple-choice. To effectively manage the inherent complexity, we introduce an innovative evaluators: the LLM-based MD-Judge for QA pairs with a particular focus on attack-enhanced queries, ensuring a seamless, and reliable evaluation. Above components extend SALAD-Bench from standard LLM safety evaluation to both LLM attack and defense methods evaluation, ensuring the joint-purpose utility. Our e
    
[^208]: 英文提示比目标语言提示更适用于基于NLI的零-shot情绪分类

    English Prompts are Better for NLI-based Zero-Shot Emotion Classification than Target-Language Prompts

    [https://arxiv.org/abs/2402.03223](https://arxiv.org/abs/2402.03223)

    本研究填补了一个研究空白，探讨了在非英文文本中应该使用哪种语言来提示情绪标签。

    

    文本情绪分类是一个具有挑战性和主观性的任务，由于需要进行认知推论过程来解释文字刺激。此外，情绪类别集合高度依赖于特定领域。例如，文学分析可能需要使用审美情感（例如，发现某物美丽），而社交媒体分析则可以从细粒度的集合中获取好处（例如，将愤怒与烦恼分开），与基本情绪类别相对应。这使得该任务成为了零-shot分类的一个有趣领域，在这种分类中，模型开发时不知道标签集合。不幸的是，大多数情绪分析资源都是英文的，因此，情绪分析的大部分研究都是用英文进行的，包括那些涉及使用提示语言模型的研究。这给我们留下一个研究空白，我们在本文中探讨：在非英文文本中，我们应该用哪种语言提示情绪标签？

    Emotion classification in text is a challenging and subjective task, due to the involved cognitive inference processes that are required to interpret a textual stimulus. In addition, the set of emotion categories is highly domain-specific. For instance, literature analysis might require the use of aesthetic emotions (e.g., finding something beautiful), and social media analysis could benefit from fine-grained sets (e.g., separating anger from annoyance) in contrast to basic emotion categories. This renders the task an interesting field for zero-shot classifications, in which the label set is not known at model development time. Unfortunately, most resources for emotion analysis are English, and therefore, most studies on emotion analysis have been performed in English, including those that involve prompting language models for text labels. This leaves us with a research gap that we address in this paper: In which language should we prompt for emotion labels on non-English texts? This i
    
[^209]: C-RAG: 针对检索增强语言模型的认证生成风险

    C-RAG: Certified Generation Risks for Retrieval-Augmented Language Models

    [https://arxiv.org/abs/2402.03181](https://arxiv.org/abs/2402.03181)

    C-RAG是第一个用于认证检索增强语言模型生成风险的框架，通过提供符合风险分析和生成风险的上界，确保生成结果的可信性。

    

    尽管大型语言模型（LLMs）在各种应用中具备令人印象深刻的能力，但它们仍然存在可信度问题，如幻觉和错位。检索增强语言模型（RAG）被提出来增强生成结果的可信性，通过引入外部知识。但是，对于RAG模型的生成风险的理论理解尚未被研究。本文回答了以下问题：1）RAG是否确实能够降低生成风险，2）如何对RAG和传统LLM的生成风险提供可证明的保证，以及3）哪些充分条件使得RAG模型能够降低生成风险。我们提出了C-RAG，第一个用于认证RAG模型生成风险的框架。具体而言，我们为RAG模型提供了符合风险分析，并确保了生成风险的上界，我们称之为符合生成风险。我们还对一般有界风险下的符合生成风险提供了理论保证。

    Despite the impressive capabilities of large language models (LLMs) across diverse applications, they still suffer from trustworthiness issues, such as hallucinations and misalignments. Retrieval-augmented language models (RAG) have been proposed to enhance the credibility of generations by grounding external knowledge, but the theoretical understandings of their generation risks remains unexplored. In this paper, we answer: 1) whether RAG can indeed lead to low generation risks, 2) how to provide provable guarantees on the generation risks of RAG and vanilla LLMs, and 3) what sufficient conditions enable RAG models to reduce generation risks. We propose C-RAG, the first framework to certify generation risks for RAG models. Specifically, we provide conformal risk analysis for RAG models and certify an upper confidence bound of generation risks, which we refer to as conformal generation risk. We also provide theoretical guarantees on conformal generation risks for general bounded risk f
    
[^210]: 一个真正联合的神经网络架构用于分割和解析

    A Truly Joint Neural Architecture for Segmentation and Parsing

    [https://arxiv.org/abs/2402.02564](https://arxiv.org/abs/2402.02564)

    本文通过引入一个联合神经网络架构，在形态丰富的语言中实现了同时进行形态分割和句法分析的任务。通过提供基于格子的表示法，保留了输入的所有形态模糊性，有效解决了以往基于神经网络的依存句法分析器的局限性。

    

    当代多语言依存句法分析器可以解析多种语言，但对于形态丰富的语言而言，其性能明显低于其他语言。主要挑战是由于输入标记的形态复杂性和模糊性较高，作为树中节点的语言单位事先是未知的。以往的基于神经网络的形态丰富语言的依存句法分析器遵循联合形态-句法假设，即形态分割和句法分析应该在解析过程中一并解决，而不是先进行分割再进行解析的流程。然而，目前的神经网络依存句法分析器采用严格的流水线方法。在本文中，我们引入了一个联合神经网络架构，将基于格子的表示法保留输入的所有形态模糊性，然后将其提供给一个基于弧的模型，该模型能够同时解决形态分割和句法分析任务。我们在希伯来语上进行了实验，该语言形态丰富且模糊性较高，结果表明...

    Contemporary multilingual dependency parsers can parse a diverse set of languages, but for Morphologically Rich Languages (MRLs), performance is attested to be lower than other languages. The key challenge is that, due to high morphological complexity and ambiguity of the space-delimited input tokens, the linguistic units that act as nodes in the tree are not known in advance. Pre-neural dependency parsers for MRLs subscribed to the joint morpho-syntactic hypothesis, stating that morphological segmentation and syntactic parsing should be solved jointly, rather than as a pipeline where segmentation precedes parsing. However, neural state-of-the-art parsers to date use a strict pipeline. In this paper we introduce a joint neural architecture where a lattice-based representation preserving all morphological ambiguity of the input is provided to an arc-factored model, which then solves the morphological segmentation and syntactic parsing tasks at once. Our experiments on Hebrew, a rich and
    
[^211]: LQER: 低秩量化误差重建用于LLMs

    LQER: Low-Rank Quantization Error Reconstruction for LLMs

    [https://arxiv.org/abs/2402.02446](https://arxiv.org/abs/2402.02446)

    LQER使用低秩逼近和激活引起的尺度矩阵，实现了对LLMs的近乎无损量化，无需知识蒸馏或梯度优化，并大幅减少硬件资源的使用。

    

    大型语言模型（LLMs）的训练后量化是具有挑战性的。在这项工作中，我们介绍了低秩量化误差减少（LQER）方法，该方法结合了量化和低秩逼近来恢复模型的能力。LQER利用激活引起的尺度矩阵将量化误差的奇异值分布推向期望的分布，从而实现了在各种LLMs和下游任务上近乎无损的W4A8量化，无需知识蒸馏、网格搜索或基于梯度的迭代优化。与现有方法不同，LQER的计算模式消除了从不规则内存位置收集高精度权重所需的专用Scatter和Gather过程。我们的W4A8 LLMs在六个热门下游任务上实现了近乎无损的性能，同时使用的硬件资源比领先的最新方法少1.36倍。一旦论文被接受，我们将开源我们的框架。

    Post-training quantization of Large Language Models (LLMs) is challenging. In this work, we introduce Low-rank Quantization Error Reduction (LQER), which combines quantization and low-rank approximation to recover the model capability. LQER leverages an activation-induced scale matrix to drive the singular value distribution of quantization error towards a desirable distribution, which enables nearly-lossless W4A8 quantization on various LLMs and downstream tasks without the need for knowledge distillation, grid search, or gradient-base iterative optimization. Unlike existing methods, the computation pattern of LQER eliminates the need for specialized Scatter and Gather processes to collect high-precision weights from irregular memory locations. Our W4A8 LLMs achieve near-lossless performance on six popular downstream tasks, while using 1.36$\times$ fewer hardware resources than the leading state-of-the-art method. We will open-source our framework once the paper is accepted.
    
[^212]: 通过定向表示优化实现的安全提示驱动的大型语言模型(LLM)保护

    Prompt-Driven LLM Safeguarding via Directed Representation Optimization

    [https://arxiv.org/abs/2401.18018](https://arxiv.org/abs/2401.18018)

    通过研究模型表示的影响，我们发现安全提示并没有明显增强恶意和无害查询之间的区分，并提出了一种名为DRO的方法，用于自动优化安全提示。

    

    在大型语言模型(LLM)中，使用安全提示在模型输入之前是一种常见的保护实践，以使其不遵从包含恶意意图的查询。然而，安全提示的工作机制尚未完全理解，这妨碍了自动优化其以改善LLM安全性的潜力。针对这个问题，我们从模型表示的角度调查了安全提示的影响。我们发现在模型的表示空间中，有害和无害的查询可以在很大程度上区分开来，但安全提示并没有明显增强这一区分。相反，不同安全提示导致查询的表示朝着相似的方向移动，使得模型即使在查询无害时也更容易拒绝提供协助。受到这些发现的启发，我们提出了一种名为DRO（定向表示优化）的方法，用于自动安全提示优化。DRO将安全提示视为要优化的表示方向。

    Prepending model inputs with safety prompts is a common practice of safeguarding large language models (LLMs) from complying with queries that contain harmful intents. However, the working mechanisms of safety prompts have not yet been fully understood, which hinders the potential for automatically optimizing them for improved LLM safety. Motivated by this problem, we investigate the impact of safety prompts from the perspective of model representations. We find that in models' representation space, harmful and harmless queries can be largely distinguished, but this is not noticeably enhanced by safety prompts. Instead, the queries' representations are moved by different safety prompts in similar directions, where models become more prone to refusal (i.e., refusing to provide assistance) even when the queries are harmless. Inspired by these findings, we propose a method called DRO (Directed Representation Optimization) for automatic safety prompt optimization. DRO treats safety prompts
    
[^213]: DocFinQA：一个长文本财务推理数据集

    DocFinQA: A Long-Context Financial Reasoning Dataset

    [https://arxiv.org/abs/2401.06915](https://arxiv.org/abs/2401.06915)

    引入了一个长文档财务问答任务，将平均上下文长度从700个词扩展到123k个词，对于大型语言模型在金融领域具有重要挑战。

    

    对于大型语言模型（LLMs）在金融领域发挥作用，需要研究现实任务和数据。金融专业人士经常与长达数百页的文档进行交互，但大多数金融研究数据集仅处理这些文档的简短摘录。为了解决这个问题，我们引入了一个长文档财务问答任务。我们通过在现有FinQA数据集中的7,437个问题中增加完整文档上下文，将FinQA中平均上下文长度从不到700个词扩展到DocFinQA中的123k个词。我们在检索式QA管道和长文本语言模型上进行了大量实验。即使对于最先进的系统，DocFinQA也是一个巨大挑战。我们还对DocFinQA中最长文档进行了案例研究，并发现模型在这些文档上特别困难。解决这些挑战。

    arXiv:2401.06915v2 Announce Type: replace-cross  Abstract: For large language models (LLMs) to be effective in the financial domain -- where each decision can have a significant impact -- it is necessary to investigate realistic tasks and data. Financial professionals often interact with documents that are hundreds of pages long, but most financial research datasets only deal with short excerpts from these documents. To address this, we introduce a long-document financial QA task. We augment 7,437 questions from the existing FinQA dataset with the full-document context, extending the average context length from under 700 words in FinQA to 123k words in DocFinQA. We conduct extensive experiments over retrieval-based QA pipelines and long-context language models. DocFinQA proves a significant challenge for even state-of-the-art systems. We also provide a case-study on the longest documents in DocFinQA and find that models particularly struggle on these documents. Addressing these challen
    
[^214]: 在任意书写风格中生成文本的学习

    Learning to Generate Text in Arbitrary Writing Styles

    [https://arxiv.org/abs/2312.17242](https://arxiv.org/abs/2312.17242)

    提出了通过引导语言模型使用对比训练的表示来生成目标风格的文本的方法，以解决传统基于指令的模型难以重新现出作者特定风格的问题。

    

    先前在风格控制文本生成方面的工作主要集中在任务上，例如模仿多产文学作者的风格，生成正式或非正式文本，并减轻生成文本的有害性。这些风格的丰富展示可用，并且因此现代语言模型通常能够模仿它们，无论是通过提示还是区分控制。然而，在诸如写作助手之类的应用中，期望语言模型能够根据可能很小的写作样本以某位作者特定的风格生成文本。例如，使用特定方言的人可能更喜欢保留相同方言的写作建议。我们发现，通过指导语言模型以对比训练的表示来生成目标风格的文本，可以更好地实现这一目标，这些表示捕捉到了文体的特征。

    arXiv:2312.17242v2 Announce Type: replace  Abstract: Prior work in style-controlled text generation has focused on tasks such as emulating the style of prolific literary authors, producing formal or informal text, and mitigating toxicity of generated text. Plentiful demonstrations of these styles are available, and as a result modern language models are often able to emulate them, either via prompting or discriminative control. However, in applications such as writing assistants, it is desirable for language models to produce text in an author-specific style on the basis of a potentially small writing sample. For example, someone writing in a particular dialect may prefer writing suggestions that retain the same dialect. We find that instruction-tuned language models can struggle to reproduce author-specific style demonstrated in a prompt. Instead, we propose to guide a language model to generate text in a target style using contrastively-trained representations that capture stylometri
    
[^215]: 使用孪生结构对GPT-3嵌入进行细化，用于技术帖子的重复检测

    Refining GPT-3 Embeddings with a Siamese Structure for Technical Post Duplicate Detection

    [https://arxiv.org/abs/2312.15068](https://arxiv.org/abs/2312.15068)

    本研究提出了使用孪生结构对GPT-3嵌入进行细化的方法，用于技术帖子的重复检测，解决了现有方法中存在的限制性问题。

    

    技术在线社区的一个目标是帮助开发者在一个地方找到正确答案。一个问题可以以不同的方式和措辞被提出，导致技术论坛上存在重复帖子。如何发现和链接重复帖子引起开发者社区和研究人员的关注。例如，Stack Overflow采用基于投票的机制来标记和关闭重复帖子。然而，及时处理这些不断出现的重复帖子仍然具有挑战性。因此，已经提出了各种方法来自动检测技术论坛帖子中的重复帖子。现有方法存在局限性，要么依赖于手工制作的相似性度量，无法充分捕捉帖子的语义，要么缺乏监督以提高性能。

    arXiv:2312.15068v2 Announce Type: replace-cross  Abstract: One goal of technical online communities is to help developers find the right answer in one place. A single question can be asked in different ways with different wordings, leading to the existence of duplicate posts on technical forums. The question of how to discover and link duplicate posts has garnered the attention of both developer communities and researchers. For example, Stack Overflow adopts a voting-based mechanism to mark and close duplicate posts. However, addressing these constantly emerging duplicate posts in a timely manner continues to pose challenges. Therefore, various approaches have been proposed to detect duplicate posts on technical forum posts automatically. The existing methods suffer from limitations either due to their reliance on handcrafted similarity metrics which can not sufficiently capture the semantics of posts, or their lack of supervision to improve the performance. Additionally, the efficienc
    
[^216]: 探索用于放射学报告错误检查的多模态大型语言模型

    Exploring Multimodal Large Language Models for Radiology Report Error-checking

    [https://arxiv.org/abs/2312.13103](https://arxiv.org/abs/2312.13103)

    本文提出了多模态大型语言模型作为放射科医生检查报告错误的助手，通过引入合成错误并对不同难度级别进行评估，发现该模型在简单级别上在X光和CT扫描数据集上显著提高了性能，并且在MIMIC-CXR数据集上超过了领域专家的准确性。

    

    本文提出了多模态大型语言模型（LLMs）在临床应用中作为放射科医生检查报告错误的助手之一。我们从真实世界的放射学数据集（包括X光和CT扫描）中创建了一个评估数据集。一部分原始报告被修改，以包含通过引入三种错误类型进行的合成错误："插入"，"删除"和"替换"。评估包含两个难度级别：简单级别用于二进制错误检查，复杂级别用于识别错误类型。在简单级别上，我们的微调模型在MIMIC-CXR和IU X光数据上分别提高了47.4%和25.4%的性能。这种性能提升在未见过的模态CT扫描中也得到了观察，因为该模型的性能比基线模型提高了19.46%。模型在MIMIC-CXR数据集中的准确性也比领域专家高出1.67%。值得注意的是，在测试集的子集（N=21）中。

    arXiv:2312.13103v2 Announce Type: replace  Abstract: This paper proposes one of the first clinical applications of multimodal large language models (LLMs) as an assistant for radiologists to check errors in their reports. We created an evaluation dataset from real-world radiology datasets (including X-rays and CT scans). A subset of original reports was modified to contain synthetic errors by introducing three types of mistakes: "insert", "remove", and "substitute". The evaluation contained two difficulty levels: SIMPLE for binary error-checking and COMPLEX for identifying error types. At the SIMPLE level, our fine-tuned model significantly enhanced performance by 47.4% and 25.4% on MIMIC-CXR and IU X-ray data, respectively. This performance boost is also observed in unseen modality, CT scans, as the model performed 19.46% better than the baseline model. The model also surpassed the domain expert's accuracy in the MIMIC-CXR dataset by 1.67%. Notably, among the subsets (N=21) of the tes
    
[^217]: NoMIRACL: 知道自己不知道的鲁棒多语言检索增强生成

    NoMIRACL: Knowing When You Don't Know for Robust Multilingual Retrieval-Augmented Generation

    [https://arxiv.org/abs/2312.11361](https://arxiv.org/abs/2312.11361)

    建立了用于评估大型语言模型在多语言环境中检索增强生成中的鲁棒性的NoMIRACL数据集，并提出了两个衡量模型鲁棒性的指标：幻觉率和错误率。

    

    arXiv:2312.11361v2 公告类型: 替换 摘要: 检索增强生成（RAG）通过利用外部知识源来将大型语言模型（LLM）输出与现实联系起来，以减少事实幻觉。然而，先前的研究缺乏对不同语言族的全面评估，这使得很难评估LLM对外部检索知识错误的鲁棒性。为了克服这一问题，我们建立了NoMIRACL，这是一个人类注释的数据集，用于评估RAG中LLM对18种在类型上多样化的语言的鲁棒性。NoMIRACL包括一个非相关子集和一个相关子集。非相关子集中的查询包含被判断为不相关的段落，而相关子集中的查询至少包含一个被判断为相关的段落。我们使用两个指标来衡量LLM的鲁棒性：（i）幻觉率，衡量模型倾向于在非相关子集的段落中产生幻觉答案的程度，以及（ii）错误率，衡量模型的不准确度。

    arXiv:2312.11361v2 Announce Type: replace  Abstract: Retrieval-augmented generation (RAG) grounds large language model (LLM) output by leveraging external knowledge sources to reduce factual hallucinations. However, prior works lack a comprehensive evaluation of different language families, making it challenging to evaluate LLM robustness against errors in external retrieved knowledge. To overcome this, we establish NoMIRACL, a human-annotated dataset for evaluating LLM robustness in RAG across 18 typologically diverse languages. NoMIRACL includes both a non-relevant and a relevant subset. Queries in the non-relevant subset contain passages judged as non-relevant, whereas queries in the relevant subset include at least a single judged relevant passage. We measure LLM robustness using two metrics: (i) hallucination rate, measuring model tendency to hallucinate an answer, when the answer is not present in passages in the non-relevant subset, and (ii) error rate, measuring model inaccurac
    
[^218]: MUFFIN: 用于改善指示遵循的多方面指南的策划

    MUFFIN: Curating Multi-Faceted Instructions for Improving Instruction-Following

    [https://arxiv.org/abs/2312.02436](https://arxiv.org/abs/2312.02436)

    MUFFIN是一个新的指示遵循数据集策划方案，通过自动按比例扩大任务，通过多种输入方面使任务丰富多样。

    

    在大型语言模型（LLMs）领域中，加强指示遵循能力通常涉及策划广泛的训练数据。本文引入了一个新的指示遵循数据集策划方案MUFFIN，具体地通过用多种输入方面使任务自动按比例扩大以丰富这些任务。

    arXiv:2312.02436v2 Announce Type: replace-cross  Abstract: In the realm of large language models (LLMs), enhancing instruction-following capability often involves curating expansive training data. This is achieved through two primary schemes: i) Scaling-Inputs: Amplifying (input, output) pairs per task instruction, aiming for better instruction adherence. ii) Scaling Input-Free Tasks: Enlarging tasks, each composed of an (instruction, output) pair (without requiring a separate input anymore). However, LLMs under Scaling-Inputs tend to be overly sensitive to inputs, leading to misinterpretation or non-compliance with instructions. Conversely, Scaling Input-Free Tasks demands a substantial number of tasks but is less effective in instruction following when dealing with instances in Scaling-Inputs. This work introduces MUFFIN, a new scheme of instruction-following dataset curation. Specifically, we automatically Scale Tasks per Input by diversifying these tasks with various input facets. 
    
[^219]: 大型语言模型的检索增强多模态思维链推理

    Retrieval-augmented Multi-modal Chain-of-Thoughts Reasoning for Large Language Models

    [https://arxiv.org/abs/2312.01714](https://arxiv.org/abs/2312.01714)

    本文引入了一种新颖的方法，通过使用检索机制动态自动选择以跨模态和内模态相似性为基础的演示示例，以提高多模态推理中的大型语言模型的性能。

    

    大型语言模型（LLMs）的进步引起了对思维链（CoT）方法的广泛关注，主要是因为它能够增强LLMs在复杂推理任务上的能力。此外，CoT方法的重要性延伸到LLMs在多模态任务上的应用。然而，在多模态推理中选择最佳的CoT演示示例对于LLMs仍然相对较少探索，这是由于多模态示例的固有复杂性。在本文中，我们通过使用检索机制来动态自动地选择基于跨模态和内模态相似性的演示示例，解决了这一挑战。此外，我们采用分层抽样方法将演示示例分类成不同类型的小组，然后分别从不同组中检索示例，以促进演示示例的多样性。

    arXiv:2312.01714v2 Announce Type: replace  Abstract: The advancement of Large Language Models (LLMs) has brought substantial attention to the Chain of Thought (CoT) approach, primarily due to its ability to enhance the capability of LLMs on complex reasoning tasks. Moreover, the significance of CoT approaches extends to the application of LLMs for multi-modal tasks. However, the selection of optimal CoT demonstration examples in multi-modal reasoning remains less explored for LLMs due to the inherent complexity of multi-modal examples. In this paper, we introduce a novel approach that addresses this challenge by using retrieval mechanisms to dynamically and automatically select demonstration examples based on cross-modal and intra-modal similarities. Furthermore, we employ a Stratified Sampling method of categorising demonstration examples into groups based on their types and then retrieving examples from different groups respectively to promote the diversity of demonstration examples.
    
[^220]: Reddit学术社区中与压力有关帖子的检测与分析

    Detection and Analysis of Stress-Related Posts in Reddit Acamedic Communities

    [https://arxiv.org/abs/2312.01050](https://arxiv.org/abs/2312.01050)

    该研究聚焦于检测和分析Reddit学术社区中与压力相关的帖子，使用自然语言处理和机器学习分类器进行文本分类，发现词袋是最有效的特征。

    

    目前，监测压力水平并及早识别心理疾病的重要性不言而喻。文本中的自动压力检测能够积极帮助管理压力，保护心理健康。在当今数字时代，社交媒体平台反映了不同社区内的心理健康和压力水平。该研究侧重于检测和分析Reddit学术社区中与压力有关的帖子。由于在线教育和远程工作，这些社区已经成为学术讨论和支持的中心。我们使用自然语言处理和机器学习分类器将文本分类为有压力或无压力，其中我们的训练数据集是Dreaddit，其中包含来自Reddit的标记数据。接下来，我们收集并分析来自各种学术子社区的帖子。我们发现对于压力检测最有效的个别特征是词袋（Bag of Words），配合逻辑回归。

    arXiv:2312.01050v2 Announce Type: replace  Abstract: Nowadays, the significance of monitoring stress levels and recognizing early signs of mental illness cannot be overstated. Automatic stress detection in text can proactively help manage stress and protect mental well-being. In today's digital era, social media platforms reflect the psychological well-being and stress levels within various communities. This study focuses on detecting and analyzing stress-related posts in Reddit academic communities. Due to online education and remote work, these communities have become central for academic discussions and support. We classify text as stressed or not using natural language processing and machine learning classifiers, with Dreaddit as our training dataset, which contains labeled data from Reddit. Next, we collect and analyze posts from various academic subreddits. We identified that the most effective individual feature for stress detection is the Bag of Words, paired with the Logistic 
    
[^221]: 忽略这个标题并HackAPrompt：通过全球规模的Prompt Hacking竞赛揭示LLMs的系统性漏洞

    Ignore This Title and HackAPrompt: Exposing Systemic Vulnerabilities of LLMs through a Global Scale Prompt Hacking Competition

    [https://arxiv.org/abs/2311.16119](https://arxiv.org/abs/2311.16119)

    通过全球规模的Prompt Hacking竞赛，揭示了LLMs存在的系统漏洞，验证了当前LLMs可以被提示注入攻击操纵。

    

    大型语言模型（LLMs）被部署在直接与用户互动的情境中，例如聊天机器人和写作助手。这些部署容易受到提示注入和越狱（统称为Prompt Hacking）的攻击，即模型被操纵以忽略其原始指令并遵循可能恶意的指令。虽然广为人知作为一种重要的安全威胁，但关于Prompt Hacking的大规模资源和定量研究的资料匮乏。为了填补这一空白，我们发起了一场全球Prompt Hacking竞赛，允许自由形式的人类输入攻击。我们搜集了对三种最先进的LLMs发起的超过60万个对抗性提示，描述了这个数据集，从经验上验证了当前LLMs确实可以通过Prompt Hacking被操纵。我们还提出了一个对抗性提示类型的全面分类本体论。

    arXiv:2311.16119v3 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) are deployed in interactive contexts with direct user engagement, such as chatbots and writing assistants. These deployments are vulnerable to prompt injection and jailbreaking (collectively, prompt hacking), in which models are manipulated to ignore their original instructions and follow potentially malicious ones. Although widely acknowledged as a significant security threat, there is a dearth of large-scale resources and quantitative studies on prompt hacking. To address this lacuna, we launch a global prompt hacking competition, which allows for free-form human input attacks. We elicit 600K+ adversarial prompts against three state-of-the-art LLMs. We describe the dataset, which empirically verifies that current LLMs can indeed be manipulated via prompt hacking. We also present a comprehensive taxonomical ontology of the types of adversarial prompts.
    
[^222]: $\textit{Dial BeInfo for Faithfulness}$: 通过行为微调提高信息寻求对话的准确性

    $\textit{Dial BeInfo for Faithfulness}$: Improving Factuality of Information-Seeking Dialogue via Behavioural Fine-Tuning

    [https://arxiv.org/abs/2311.09800](https://arxiv.org/abs/2311.09800)

    通过BeInfo方法的行为微调，可以提高信息寻求对话系统对知识来源的准确性和忠实度

    

    准确性是信息寻求对话中的一个至关重要的要求：系统应该对用户的查询做出响应，使得这些回复有意义且与系统提供的知识一致。然而，大多数现代大型语言模型存在幻觉现象，即它们生成的回复不受支持或与知识来源相矛盾。为了减轻这一问题并提高信息寻求对话系统的准确性，我们引入了BeInfo，这是一个简单而有效的方法，通过行为调整来帮助信息寻求对话。通过依赖于三个标准数据集，我们展示了通过BeInfo微调的模型在数据集和领域中变得更加忠实于知识来源，无论是在应用零-shot方式时看到的领域还是未看到的领域。此外，我们还展示了BeInfo微调的3B参数模型（如Flan-T5）表现出色能力。

    arXiv:2311.09800v2 Announce Type: replace  Abstract: Factuality is a crucial requirement in information seeking dialogue: the system should respond to the user's queries so that the responses are meaningful and aligned with the knowledge provided to the system. However, most modern large language models suffer from hallucinations, that is, they generate responses not supported by or contradicting the knowledge source. To mitigate the issue and increase faithfulness of information-seeking dialogue systems, we introduce BeInfo, a simple yet effective method that applies behavioural tuning to aid information-seeking dialogue. Relying on three standard datasets, we show that models tuned with BeInfo} become considerably more faithful to the knowledge source both for datasets and domains seen during BeInfo-tuning, as well as on unseen domains, when applied in a zero-shot manner. In addition, we show that the models with 3B parameters (e.g., Flan-T5) tuned with BeInfo demonstrate strong perf
    
[^223]: MELA：多语言语言可接受性评估

    MELA: Multilingual Evaluation of Linguistic Acceptability

    [https://arxiv.org/abs/2311.09033](https://arxiv.org/abs/2311.09033)

    MELA是第一个覆盖10种语言的多语言语言可接受性基准，通过分析XLM-R的微调权重，探讨了跨语言迁移困难性，结果表明在上下文示例方面ChatGPT表现良好但仍落后于经过微调的XLM-R。

    

    最近，针对大型语言模型（LLMs）的基准主要集中在应用驱动的任务，如复杂推理和代码生成上，导致LLMs的纯语言评估严重不足。针对这一背景，我们引入了Multilingual Evaluation of Linguistic Acceptability（MELA），这是第一个涵盖来自多个语言家族的10种语言、共48K个样本的语言可接受性多语言基准。我们建立了常用LLMs和监督模型的基线，使用XLM-R进行跨语言迁移和多任务学习实验。为了实现多语言可解释性，我们分析了微调后的XLM-R的权重，探讨了识别不同语言之间迁移困难性的可能性。我们的结果显示，ChatGPT从上下文示例中受益良多，但仍落后于经过微调的XLM-R，而GPT-4的性能与之相当。

    arXiv:2311.09033v2 Announce Type: replace-cross  Abstract: Recent benchmarks for Large Language Models (LLMs) have mostly focused on application-driven tasks such as complex reasoning and code generation, and this has led to a scarcity in purely linguistic evaluation of LLMs. Against this background, we introduce Multilingual Evaluation of Linguistic Acceptability -- MELA, the first multilingual benchmark on linguistic acceptability with 48K samples covering 10 languages from a diverse set of language families. We establish baselines of commonly used LLMs along with supervised models, and conduct cross-lingual transfer and multi-task learning experiments with XLM-R. In pursuit of multilingual interpretability, we analyze the weights of fine-tuned XLM-R to explore the possibility of identifying transfer difficulty between languages. Our results show that ChatGPT benefits much from in-context examples but still lags behind fine-tuned XLM-R, while the performance of GPT-4 is on par with f
    
[^224]: 用法律摘要器提升公众对法院判决的理解：翻译法律术语

    Translating Legalese: Enhancing Public Understanding of Court Opinions with Legal Summarizers

    [https://arxiv.org/abs/2311.06534](https://arxiv.org/abs/2311.06534)

    使用人工智能生成的简化摘要可以帮助公众更好地理解司法意见，尤其对于受教育程度较低的人群有显著影响。

    

    司法意见被写作具有说服力，并且可以建立公众对法院判决的信任，然而对非专业人士来说理解起来可能会很困难。我们展示了一种使用人工智能助手生成司法意见简化摘要的流程。与现有的专家撰写的摘要相比，这些由人工智能生成的简化摘要更易为公众接触和非专家理解。我们在一项调查实验中展示了这些人工智能摘要有助于调查对象理解裁决的关键特征，并且在被认为质量更高，尤其对于受教育程度较低的调查对象。

    arXiv:2311.06534v2 Announce Type: replace  Abstract: Judicial opinions are written to be persuasive and could build public trust in court decisions, yet they can be difficult for non-experts to understand. We present a pipeline for using an AI assistant to generate simplified summaries of judicial opinions. Compared to existing expert-written summaries, these AI-generated simple summaries are more accessible to the public and more easily understood by non-experts. We show in a survey experiment that the AI summaries help respondents understand the key features of a ruling, and have higher perceived quality, especially for respondents with less formal education.
    
[^225]: 大语言模型中的多语言越狱挑战

    Multilingual Jailbreak Challenges in Large Language Models

    [https://arxiv.org/abs/2310.06474](https://arxiv.org/abs/2310.06474)

    该研究揭示了大语言模型中存在的多语言越狱挑战，包括用户使用非英语提示绕过安全机制的非故意场景和恶意用户利用多语言提示恶意攻击LLMs的故意场景。

    

    虽然大语言模型(LLMs)在各种任务中表现出色，但它们存在潜在的安全问题，例如“越狱”问题，即恶意指令可能操纵LLMs表现出不良行为。尽管已经制定了几种预防措施来减轻与LLMs相关的潜在风险，但这些措施主要集中在英语上。本研究揭示了LLMs中存在的多语言越狱挑战，并考虑了两种潜在的风险场景：非故意和故意。非故意场景涉及用户使用非英语提示查询LLMs并无意中绕过安全机制，而故意场景涉及恶意用户将恶意指令与多语言提示结合起来，故意攻击LLMs。实验结果显示，在非故意场景中，不安全内容的比率增加了。

    arXiv:2310.06474v2 Announce Type: replace  Abstract: While large language models (LLMs) exhibit remarkable capabilities across a wide range of tasks, they pose potential safety concerns, such as the ``jailbreak'' problem, wherein malicious instructions can manipulate LLMs to exhibit undesirable behavior. Although several preventive measures have been developed to mitigate the potential risks associated with LLMs, they have primarily focused on English. In this study, we reveal the presence of multilingual jailbreak challenges within LLMs and consider two potential risky scenarios: unintentional and intentional. The unintentional scenario involves users querying LLMs using non-English prompts and inadvertently bypassing the safety mechanisms, while the intentional scenario concerns malicious users combining malicious instructions with multilingual prompts to deliberately attack LLMs. The experimental results reveal that in the unintentional scenario, the rate of unsafe content increases
    
[^226]: 语言模型代表空间和时间

    Language Models Represent Space and Time

    [https://arxiv.org/abs/2310.02207](https://arxiv.org/abs/2310.02207)

    现代大型语言模型学习到了丰富的时空表征，包括学习到了空间和时间的线性表征以及个体的“空间神经元”和“时间神经元”。

    

    大型语言模型（LLM）的能力引发了关于这些系统到底是仅仅学习了庞大的表面统计信息还是学到了更连贯、基于真实世界的表征的争论。我们通过分析Llama-2系列模型中学到的三个空间数据集（世界、美国、纽约的地点）和三个时间数据集（历史人物、艺术品、新闻头条）的学习表征找到了支持后者的证据。我们发现LLM在多个尺度上学习到了空间和时间的线性表征。这些表征对提示变化具有稳健性，并且在不同实体类型（例如城市和地标）之间是统一的。此外，我们还发现了可靠地编码空间和时间坐标的个体“空间神经元”和“时间神经元”。虽然还需要进一步的研究，但我们的结果表明现代LLM学习到了对真实世界的丰富时空表征。

    arXiv:2310.02207v3 Announce Type: replace-cross  Abstract: The capabilities of large language models (LLMs) have sparked debate over whether such systems just learn an enormous collection of superficial statistics or a set of more coherent and grounded representations that reflect the real world. We find evidence for the latter by analyzing the learned representations of three spatial datasets (world, US, NYC places) and three temporal datasets (historical figures, artworks, news headlines) in the Llama-2 family of models. We discover that LLMs learn linear representations of space and time across multiple scales. These representations are robust to prompting variations and unified across different entity types (e.g. cities and landmarks). In addition, we identify individual "space neurons" and "time neurons" that reliably encode spatial and temporal coordinates. While further investigation is needed, our results suggest modern LLMs learn rich spatiotemporal representations of the real
    
[^227]: 现有词嵌入方法的全面实证评估

    A Comprehensive Empirical Evaluation of Existing Word Embedding Approaches

    [https://arxiv.org/abs/2303.07196](https://arxiv.org/abs/2303.07196)

    本文评估了现有词嵌入方法，并发现基于神经网络的方法能更好地捕捉语言的语义和句法规律。

    

    向量化的词表示帮助无数自然语言处理（NLP）任务捕捉语言的语义和句法规律。本文展示了现有词嵌入方法的特点，并针对许多分类任务进行了分析。我们将这些方法分类为两大组 - 传统方法主要使用矩阵分解来生成词表示，无法很好地捕捉语言的语义和句法规律。另一方面，基于神经网络的方法可以捕捉语言的复杂规律，并在生成的词表示中保留词之间的关系。我们在多个分类任务上报告了实验结果，并强调了一个方法胜过其他方法的情况。

    arXiv:2303.07196v2 Announce Type: replace  Abstract: Vector-based word representations help countless Natural Language Processing (NLP) tasks capture the language's semantic and syntactic regularities. In this paper, we present the characteristics of existing word embedding approaches and analyze them with regard to many classification tasks. We categorize the methods into two main groups - Traditional approaches mostly use matrix factorization to produce word representations, and they are not able to capture the semantic and syntactic regularities of the language very well. On the other hand, Neural-network-based approaches can capture sophisticated regularities of the language and preserve the word relationships in the generated word representations. We report experimental results on multiple classification tasks and highlight the scenarios where one approach performs better than the rest.
    
[^228]: 在不需要监督的情况下发现语言模型中的潜在知识

    Discovering Latent Knowledge in Language Models Without Supervision

    [https://arxiv.org/abs/2212.03827](https://arxiv.org/abs/2212.03827)

    通过在语言模型的内部激活中直接发现潜在知识的方式，我们提出了一种纯粹无监督的方法，可以准确回答未标记模型激活的是非问题，并且在大型语言模型中恢复多样知识。

    

    训练语言模型的现有技术可能与真相不一致：如果我们用模仿学习训练模型，它们可能会重现人类的错误；如果我们训练它们生成人类评价高的文本，它们可能会输出人类评估者无法检测到的错误。我们提出通过在语言模型的内部激活中直接发现潜在知识的方式来规避这个问题，而且是纯粹无监督的方式。具体来说，我们引入了一种方法，能够准确回答只给定未标记模型激活的是非问题。该方法通过在激活空间中找到满足逻辑一致性属性的方向来工作，例如一个陈述及其否定具有相反的真值。我们展示，尽管没有使用监督和模型输出，我们的方法可以恢复大型语言模型中代表多样知识：在6个模型和10个问答数据集上，它表现优异。

    arXiv:2212.03827v2 Announce Type: replace-cross  Abstract: Existing techniques for training language models can be misaligned with the truth: if we train models with imitation learning, they may reproduce errors that humans make; if we train them to generate text that humans rate highly, they may output errors that human evaluators can't detect. We propose circumventing this issue by directly finding latent knowledge inside the internal activations of a language model in a purely unsupervised way. Specifically, we introduce a method for accurately answering yes-no questions given only unlabeled model activations. It works by finding a direction in activation space that satisfies logical consistency properties, such as that a statement and its negation have opposite truth values. We show that despite using no supervision and no model outputs, our method can recover diverse knowledge represented in large language models: across 6 models and 10 question-answering datasets, it outperforms 
    
[^229]: SMiLE：基于模式增强的多层对比学习用于知识图谱链接预测

    SMiLE: Schema-augmented Multi-level Contrastive Learning for Knowledge Graph Link Prediction

    [https://arxiv.org/abs/2210.04870](https://arxiv.org/abs/2210.04870)

    提出了一种新颖的基于模式增强的多层对比学习框架（SMiLE），用于知识图谱链接预测，通过利用网络模式作为先验约束来提高链接预测的准确性和上下文一致性。

    

    链接预测是推断知识图谱中实体之间缺失链接的任务。基于嵌入的方法通过建模三元组中的关系模式在解决此问题方面表现出有效性。然而，链接预测任务通常需要实体邻域中的上下文信息，而大多数现有的基于嵌入的方法未能捕捉到它。此外，很少有关注不同上下文中实体表示的多样性，这经常导致错误的预测结果。在这种情况下，我们认为知识图谱的模式包含特定的上下文信息，并且有助于保持实体在不同上下文中的一致性。在本文中，我们提出了一种新颖的基于模式增强的多层对比学习框架（SMiLE）来进行知识图谱链接预测。

    arXiv:2210.04870v3 Announce Type: replace-cross  Abstract: Link prediction is the task of inferring missing links between entities in knowledge graphs. Embedding-based methods have shown effectiveness in addressing this problem by modeling relational patterns in triples. However, the link prediction task often requires contextual information in entity neighborhoods, while most existing embedding-based methods fail to capture it. Additionally, little attention is paid to the diversity of entity representations in different contexts, which often leads to false prediction results. In this situation, we consider that the schema of knowledge graph contains the specific contextual information, and it is beneficial for preserving the consistency of entities across contexts. In this paper, we propose a novel Schema-augmented Multi-level contrastive LEarning framework (SMiLE) to conduct knowledge graph link prediction. Specifically, we first exploit network schema as the prior constraint to sam
    
[^230]: 大模型时代中的数据增强研究综述

    A Survey on Data Augmentation in Large Model Era. (arXiv:2401.15422v1 [cs.LG])

    [http://arxiv.org/abs/2401.15422](http://arxiv.org/abs/2401.15422)

    这篇论文综述了大模型驱动的数据增强方法，包括图像增强、文本增强和配对数据增强。这些方法利用大模型的能力，有效提高了数据增强的效果，是解决大模型训练中数据质量不足的重要研究方向。

    

    大模型，包括大语言和扩散模型，在近似人类级智能方面显示出卓越的潜力，引起了学术界和工业界的极大关注。然而，训练这些大模型需要大量高质量的数据，并且随着这些模型的持续更新，现有的高质量数据储备可能很快用尽。这个挑战催生了大量关于数据增强方法的研究。利用大模型，这些数据增强技术超越了传统方法。本文综合考虑，提供了大模型驱动的数据增强方法的详尽回顾。我们首先将相关研究分为图像增强、文本增强和配对数据增强三个主要类别。然后，我们深入探讨了与大模型数据增强相关的各种数据后处理技术。

    Large models, encompassing large language and diffusion models, have shown exceptional promise in approximating human-level intelligence, garnering significant interest from both academic and industrial spheres. However, the training of these large models necessitates vast quantities of high-quality data, and with continuous updates to these models, the existing reservoir of high-quality data may soon be depleted. This challenge has catalyzed a surge in research focused on data augmentation methods. Leveraging large models, these data augmentation techniques have outperformed traditional approaches. This paper offers an exhaustive review of large model-driven data augmentation methods, adopting a comprehensive perspective. We begin by establishing a classification of relevant studies into three main categories: image augmentation, text augmentation, and paired data augmentation. Following this, we delve into various data post-processing techniques pertinent to large model-based data au
    
[^231]: 从推特到引用：揭示社交媒体影响者对人工智能研究可见性的影响

    Tweets to Citations: Unveiling the Impact of Social Media Influencers on AI Research Visibility. (arXiv:2401.13782v1 [cs.DL])

    [http://arxiv.org/abs/2401.13782](http://arxiv.org/abs/2401.13782)

    本文研究了社交媒体影响者在提高机器学习研究的可见性方面的作用，发现被这些影响者认可的论文引用次数显著增加，中位数引用次数比对照组高2-3倍。此外，该研究还探讨了被展示作者的地理、性别和机构多样性。

    

    随着人工智能和机器学习会议上被接受的论文数量达到数千篇，研究人员如何获取和阅读研究论文变得不清楚。本文研究了社交媒体影响者在增强机器学习研究可见性中的作用，特别是他们分享的论文引用次数。我们编制了一个包括8000多篇论文的全面数据集，涵盖了2018年12月至2023年10月的推特，以及基于出版年份、会议地点和摘要主题进行1：1匹配的对照组。我们的分析揭示了这些影响者认可的论文引用次数显著增加，中位数引用次数比对照组高2-3倍。此外，该研究还深入研究了被展示作者的地理、性别和机构多样性。这些发现突显了社交媒体在学术交流中的不断扩大的影响力，并强调了当今数字化时代不断发展的生态系统的重要性。

    As the number of accepted papers at AI and ML conferences reaches into the thousands, it has become unclear how researchers access and read research publications. In this paper, we investigate the role of social media influencers in enhancing the visibility of machine learning research, particularly the citation counts of papers they share. We have compiled a comprehensive dataset of over 8,000 papers, spanning tweets from December 2018 to October 2023, alongside 1:1 matched controls based on publication year, venue, and abstract topics. Our analysis reveals a significant increase in citations for papers endorsed by these influencers, with median citation counts 2-3 times higher than those of the control group. Additionally, the study delves into the geographic, gender, and institutional diversity of highlighted authors. These findings highlight the expanding influence of social media in scholarly communication and underscore the importance of an evolving ecosystem in today's digital a
    
[^232]: AntEval: 量化评估智能体社交互动的信息性和表达性

    AntEval: Quantitatively Evaluating Informativeness and Expressiveness of Agent Social Interactions. (arXiv:2401.06509v1 [cs.CL])

    [http://arxiv.org/abs/2401.06509](http://arxiv.org/abs/2401.06509)

    本研究通过使用桌面角色扮演游戏规则创建了一个环境，量化评估智能体社交互动的信息性和表达性，旨在克服隐私问题并促使智能体进行有意义、高质量的互动。

    

    尽管基于大型语言模型（LLM）的智能体已成功地模仿了各种情境中的人类行为，但复杂的、多角色社交互动在扩展环境中的领域仍未充分探索。隐私问题使捕捉和利用复杂的现实生活互动变得困难。更重要的是，缺乏定量评估方法阻碍了高质量智能体互动的追求，导致互动的信息性和表达性有限，表现为肤浅的闲聊而没有清晰的意图。在这项工作中，我们利用桌面角色扮演游戏（TRPG）的规则创建了一个有利于复杂、上下文丰富的互动的环境，强调信息性和表达性。这个虚拟环境减轻了隐私问题，并激励智能体作为游戏目标的一部分进行有意义的、高质量的互动。

    While Large Language Models (LLMs) based agents have successfully mimicked human behaviors in various scenarios, the realm of complex, multi-character social interactions within extended contexts remains underexplored. The challenge is compounded by privacy concerns, making it difficult to capture and utilize intricate real-life interactions. More importantly, the absence of quantitative evaluation methods hampers the pursuit of high-quality agent interactions, often leading to interactions that are limited in informativeness and expressiveness, characterized by superficial small talk without clear intentions. In this work, we leverage the rules of Tabletop Role-Playing Games (TRPG) to create an environment conducive to complex, context-rich interactions, emphasizing informativeness and expressiveness. This virtual setting alleviates privacy concerns and motivates agents to engage in meaningful, high-quality interactions as part of their in-game objectives. To assess these interactions
    
[^233]: 从插值到外推：算术Transformer的完整长度泛化

    From Interpolation to Extrapolation: Complete Length Generalization for Arithmetic Transformers. (arXiv:2310.11984v1 [cs.LG])

    [http://arxiv.org/abs/2310.11984](http://arxiv.org/abs/2310.11984)

    本文研究了Transformer模型在学习算术算法方面的能力，并通过注意力偏置以及Attention Bias Calibration（ABC）来实现对于长长度的泛化。

    

    自从提出以来，Transformer模型在各种任务中展现出了优秀的性能。然而，在算法任务中，长度泛化仍存在一些未解决的问题。在本文中，我们研究了Transformer模型在学习算术算法（如加法和乘法）方面的内在能力。通过实验证明和注意力分析，我们确定了实现最佳长度泛化的几个关键因素。我们展示了Transformer模型能够通过目标指向偏置来泛化到长长度。然后，我们引入了Attention Bias Calibration（ABC），这是一个校准阶段，使模型能够自动学习适当的注意力偏置，我们将其与相对位置编码的机制联系起来。我们证明使用ABC，Transformer模型可以在某些算术任务上实现前所未有的完美长度泛化。

    Since its introduction, the transformer model has demonstrated outstanding performance across various tasks. However, there are still unresolved issues regarding length generalization, particularly in algorithmic tasks. In this paper, we investigate the inherent capabilities of transformer models in learning arithmetic algorithms, such as addition and multiplication. Through experiments and attention analysis, we identify a number of crucial factors for achieving optimal length generalization. We show that transformer models are able to generalize to long lengths with the help of targeted attention biasing. We then introduce Attention Bias Calibration (ABC), a calibration stage that enables the model to automatically learn the proper attention biases, which we link to mechanisms in relative position encoding. We demonstrate that using ABC, the transformer model can achieve unprecedented perfect length generalization on certain arithmetic tasks.
    
[^234]: Denevil: 通过指导学习来解读和引导大型语言模型的道德价值

    Denevil: Towards Deciphering and Navigating the Ethical Values of Large Language Models via Instruction Learning. (arXiv:2310.11053v1 [cs.CL])

    [http://arxiv.org/abs/2310.11053](http://arxiv.org/abs/2310.11053)

    通过Moral Foundation Theory和DeNEVIL算法，我们研究了大型语言模型的道德价值，并构建了MoralPrompt数据集来评估模型的内在价值。发现大多数模型存在不对齐，需要进一步进行道德价值对齐。

    

    大型语言模型（LLM）取得了前所未有的突破，然而它们被越来越多地整合到日常生活中可能会带来由生成的不道德内容引起的社会风险。尽管已经对特定问题如偏见进行了广泛研究，但是从道德哲学的角度来看，LLM的内在价值仍然很少被探索。这项工作利用道德基础理论深入探讨道德价值。我们提出了DeNEVIL，一种新的提示生成算法，旨在动态利用LLM的价值脆弱性并以生成方式揭示伦理违规行为，揭示其潜在的价值倾向。在此基础上，我们构建了MoralPrompt，一个包含2,397个提示的高质量数据集，涵盖500多个价值原则，并对一系列LLM的内在价值进行了基准测试。我们发现大多数模型实质上是不对齐的，需要进一步进行道德价值对齐。

    Large Language Models (LLMs) have made unprecedented breakthroughs, yet their increasing integration into everyday life might raise societal risks due to generated unethical content. Despite extensive study on specific issues like bias, the intrinsic values of LLMs remain largely unexplored from a moral philosophy perspective. This work delves into ethical values utilizing Moral Foundation Theory. Moving beyond conventional discriminative evaluations with poor reliability, we propose DeNEVIL, a novel prompt generation algorithm tailored to dynamically exploit LLMs' value vulnerabilities and elicit the violation of ethics in a generative manner, revealing their underlying value inclinations. On such a basis, we construct MoralPrompt, a high-quality dataset comprising 2,397 prompts covering 500+ value principles, and then benchmark the intrinsic values across a spectrum of LLMs. We discovered that most models are essentially misaligned, necessitating further ethical value alignment. In r
    
[^235]: 通过语义格重排序提高自动语音识别系统中的上下文识别能力

    Improved Contextual Recognition In Automatic Speech Recognition Systems By Semantic Lattice Rescoring. (arXiv:2310.09680v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.09680](http://arxiv.org/abs/2310.09680)

    通过深度学习模型和transformer的重新评分，我们提出了一种通过语义格重排序来提高自动语音识别系统中上下文识别能力的方法。

    

    自动语音识别（ASR）受到了广泛的研究关注。最近的突破使得ASR系统在准确转录口语的能力上取得了重要进展，这是构建对话代理的关键进步。然而，准确辨别上下文相关的单词和短语仍然是一项迫切的挑战。在这项工作中，我们提出了一种通过语义格处理来增强ASR系统中上下文识别能力的新方法，利用深度学习模型在准确交付各种词汇和说话风格的转录方面具有出色的能力。我们的解决方案包括使用隐马尔可夫模型和高斯混合模型（HMM-GMM），以及深度神经网络（DNN）模型，将语言建模和声学建模结合起来，以获得更高的准确性。我们通过使用基于transformer的模型来重新评分单词格，使我们的网络具备了非凡的能力。

    Automatic Speech Recognition (ASR) has witnessed a profound research interest. Recent breakthroughs have given ASR systems different prospects such as faithfully transcribing spoken language, which is a pivotal advancement in building conversational agents. However, there is still an imminent challenge of accurately discerning context-dependent words and phrases. In this work, we propose a novel approach for enhancing contextual recognition within ASR systems via semantic lattice processing leveraging the power of deep learning models in accurately delivering spot-on transcriptions across a wide variety of vocabularies and speaking styles. Our solution consists of using Hidden Markov Models and Gaussian Mixture Models (HMM-GMM) along with Deep Neural Networks (DNN) models integrating both language and acoustic modeling for better accuracy. We infused our network with the use of a transformer-based model to properly rescore the word lattice achieving remarkable capabilities with a palpa
    
[^236]: DQ-LoRe: 用于上下文学习的低秩近似双重查询重新排序

    DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context Learning. (arXiv:2310.02954v1 [cs.CL])

    [http://arxiv.org/abs/2310.02954](http://arxiv.org/abs/2310.02954)

    本研究引入了DQ-LoRe框架，它通过双重查询和低秩近似重新排序自动选择用于上下文学习的示例，在复杂推理任务中展示了出色的性能和效果。

    

    最近自然语言处理领域的新进展，主要是由大型语言模型（LLMs）推动的，展示了它们在上下文学习方面的显著能力。在复杂推理任务中引导LLMs的一个有前途的途径是利用链式思维（CoT）范式中的中间推理步骤。然而，最主要的挑战在于有效地选择示例来促进上下文学习。在这项研究中，我们引入了一个框架，利用双重查询和低秩近似重新排序（DQ-LoRe）来自动选择用于上下文学习的示例。双重查询首先查询LLM以获取LLM生成的知识，例如CoT，然后通过问题和知识查询检索器以获取最终的示例。此外，对于第二个查询，LoRe利用降维技术来改进示例选择，确保与输入问题的知识密切对齐。通过广泛的实验验证了DQ-LoRe框架的有效性和性能。

    Recent advances in natural language processing, primarily propelled by Large Language Models (LLMs), have showcased their remarkable capabilities grounded in in-context learning. A promising avenue for guiding LLMs in intricate reasoning tasks involves the utilization of intermediate reasoning steps within the Chain-of-Thought (CoT) paradigm. Nevertheless, the central challenge lies in the effective selection of exemplars for facilitating in-context learning. In this study, we introduce a framework that leverages Dual Queries and Low-rank approximation Re-ranking (DQ-LoRe) to automatically select exemplars for in-context learning. Dual Queries first query LLM to obtain LLM-generated knowledge such as CoT, then query the retriever to obtain the final exemplars via both question and the knowledge. Moreover, for the second query, LoRe employs dimensionality reduction techniques to refine exemplar selection, ensuring close alignment with the input question's knowledge. Through extensive ex
    
[^237]: 大型语言模型的知识净化

    Knowledge Sanitization of Large Language Models. (arXiv:2309.11852v1 [cs.CL])

    [http://arxiv.org/abs/2309.11852](http://arxiv.org/abs/2309.11852)

    这项研究探索了一种用于减轻大型语言模型（LLM）隐私问题的知识净化方法。通过微调模型，使其在被询问敏感信息时生成无害回答，从而有效地减少知识泄漏并保持整体性能。

    

    我们探索了一种知识净化方法，以减轻与大型语言模型（LLM）相关的隐私问题。在大规模Web数据语料库上训练的LLMs可以记住并潜在地透露敏感或机密信息，引发关键的安全问题。我们的技术通过微调这些模型，促使它们在被询问特定信息时生成无害的回答，例如“我不知道”。在封闭式问答任务的实验结果中，我们简单的方法不仅最大程度地减少了特定知识泄漏，还保留了LLM的整体性能。这两个优点加强了对提取攻击的防御，并减少了产生幻觉等有害内容的发送。

    We explore a knowledge sanitization approach to mitigate the privacy concerns associated with large language models (LLMs). LLMs trained on a large corpus of Web data can memorize and potentially reveal sensitive or confidential information, raising critical security concerns. Our technique fine-tunes these models, prompting them to generate harmless responses such as ``I don't know'' when queried about specific information. Experimental results in a closed-book question-answering task show that our straightforward method not only minimizes particular knowledge leakage but also preserves the overall performance of LLM. These two advantages strengthen the defense against extraction attacks and reduces the emission of harmful content such as hallucinations.
    
[^238]: FaNS：基于要素的叙事相似度度量

    FaNS: a Facet-based Narrative Similarity Metric. (arXiv:2309.04823v1 [cs.CL])

    [http://arxiv.org/abs/2309.04823](http://arxiv.org/abs/2309.04823)

    本研究提出了一种基于要素的叙事相似度度量方法FaNS，通过提取经典的五W一H要素并借助大型语言模型，可以更准确地识别出语义上相似的叙事。实验证明，FaNS与传统文本相似度度量方法相比具有更高的相关性（高37%）。

    

    相似的叙事检索是一项至关重要的任务，因为叙事对于解释和理解事件至关重要，而多个相关的叙事通常有助于创建对所关注事件的整体视图。为了准确识别语义上相似的叙事，本文提出了一种新颖的叙事相似度度量方法，称为基于要素的叙事相似度（FaNS），该方法基于经典的五W一H要素（Who，What，When，Where，Why和How），通过利用最先进的大型语言模型（LLMs）进行提取。与现有的仅关注整体词汇/语义匹配的相似度度量方法不同，FaNS提供了更为细致的匹配，包括六个不同的要素的独立匹配，并将它们组合。为了评估FaNS，我们从第三方新闻门户AllSides收集了一份全面的叙事数据集。实验结果表明，FaNS度量方法与直接度量的传统文本相似度度量方法相比，具有更高的相关性（高37%）。

    Similar Narrative Retrieval is a crucial task since narratives are essential for explaining and understanding events, and multiple related narratives often help to create a holistic view of the event of interest. To accurately identify semantically similar narratives, this paper proposes a novel narrative similarity metric called Facet-based Narrative Similarity (FaNS), based on the classic 5W1H facets (Who, What, When, Where, Why, and How), which are extracted by leveraging the state-of-the-art Large Language Models (LLMs). Unlike existing similarity metrics that only focus on overall lexical/semantic match, FaNS provides a more granular matching along six different facets independently and then combines them. To evaluate FaNS, we created a comprehensive dataset by collecting narratives from AllSides, a third-party news portal. Experimental results demonstrate that the FaNS metric exhibits a higher correlation (37\% higher) than traditional text similarity metrics that directly measur
    
[^239]: 对话式人工智能的数据增强

    Data Augmentation for Conversational AI. (arXiv:2309.04739v1 [cs.CL])

    [http://arxiv.org/abs/2309.04739](http://arxiv.org/abs/2309.04739)

    本教程提供了对话式人工智能中数据增强的综述，包括对话增强、开放域和任务导向的对话生成以及评估模型。此外，还讨论了当前的挑战和未来的发展方向，以帮助推动该领域的发展。

    

    对话系统的发展已经彻底改变了信息获取方式，超越了单一查询的限制。然而，开发对话系统需要大量的训练数据，在资源有限的领域和语言中具有挑战性。传统的数据收集方法，如众包，需要大量的人力和时间，因此在此情景下效率低下。数据增强（DA）是一种缓解对话系统中数据稀缺问题的有效方法。本教程全面且最新地概述了在对话系统中使用的DA方法，包括对话增强、开放域和任务导向的对话生成以及不同的评估模型的范式。我们还讨论了当前的挑战和未来的发展方向，以帮助研究人员和从业者进一步推动这一领域的发展。

    Advancements in conversational systems have revolutionized information access, surpassing the limitations of single queries. However, developing dialogue systems requires a large amount of training data, which is a challenge in low-resource domains and languages. Traditional data collection methods like crowd-sourcing are labor-intensive and time-consuming, making them ineffective in this context. Data augmentation (DA) is an affective approach to alleviate the data scarcity problem in conversational systems. This tutorial provides a comprehensive and up-to-date overview of DA approaches in the context of conversational systems. It highlights recent advances in conversation augmentation, open domain and task-oriented conversation generation, and different paradigms of evaluating these models. We also discuss current challenges and future directions in order to help researchers and practitioners to further advance the field in this area.
    
[^240]: 使用LLMs从电子健康记录中检索证据：可能性与挑战

    Retrieving Evidence from EHRs with LLMs: Possibilities and Challenges. (arXiv:2309.04550v1 [cs.CL])

    [http://arxiv.org/abs/2309.04550](http://arxiv.org/abs/2309.04550)

    本研究提出了一种使用大型语言模型（LLMs）从未结构化的电子健康记录（EHR）中检索和总结相关证据的方法。通过在零样本条件下训练LLM来推断患者是否患有特定疾病，并且模型可以总结支持的证据。该方法在实践中被证明优于传统的信息检索方法。

    

    未结构化的电子健康记录（EHR）数据通常包含与影像数据互补的关键信息，可以为放射科医生的诊断提供帮助。然而，时间限制和与每个患者相关的大量笔记使得手动浏览此类数据以识别相关证据在实践中变得不可行。现代的大型语言模型（LLMs）提供了一种灵活的方式来处理未结构化的EHR数据，并可以提供一种机制来高效地检索和总结与给定查询相关的未结构化证据。在这项工作中，我们提出并评估了一个LLM（Flan-T5 XXL）来实现这个目的。具体而言，在零样本条件下，我们要求LLM推断一个患者是否有或处于某种特定疾病的风险，并在是的情况下提示模型总结支持的证据。通过引入放射科医生进行手动评估，我们发现这种基于LLM的方法提供的输出始终优于标准的信息检索基准方法。

    Unstructured Electronic Health Record (EHR) data often contains critical information complementary to imaging data that would inform radiologists' diagnoses. However, time constraints and the large volume of notes frequently associated with individual patients renders manual perusal of such data to identify relevant evidence infeasible in practice. Modern Large Language Models (LLMs) provide a flexible means of interacting with unstructured EHR data, and may provide a mechanism to efficiently retrieve and summarize unstructured evidence relevant to a given query. In this work, we propose and evaluate an LLM (Flan-T5 XXL) for this purpose. Specifically, in a zero-shot setting we task the LLM to infer whether a patient has or is at risk of a particular condition; if so, we prompt the model to summarize the supporting evidence. Enlisting radiologists for manual evaluation, we find that this LLM-based approach provides outputs consistently preferred to a standard information retrieval base
    
[^241]: MindMap：知识图谱激发大型语言模型的思维图思考方法

    MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models. (arXiv:2308.09729v1 [cs.AI])

    [http://arxiv.org/abs/2308.09729](http://arxiv.org/abs/2308.09729)

    本论文通过使用知识图谱来激发大型语言模型，解决了整合新知识、产生幻觉和决策过程不透明等问题，并通过生成思维导图展示了模型的推理路径，实验证明这种方法可以取得显著的实证增益。

    

    通常，大型语言模型存在无法整合新知识、产生幻觉和决策过程不透明等限制。本文探讨了如何利用知识图谱（KG）来激发大型语言模型，以解决整合最新知识和引发模型思维路径的问题。具体来说，我们构建了一个提示管道，使大型语言模型能够理解KG输入并利用隐含知识和检索到的外部知识进行推理。此外，我们研究了引发大型语言模型执行推理和生成答案的思维导图。研究发现，生成的思维导图基于知识的本体论，展示了大型语言模型的推理路径，从而为生产环境中的推理提供了探索和评估的可能性。对三个问答数据集的实验证明，MindMap提示方法带来了显著的实证增益。

    LLMs usually exhibit limitations in their ability to incorporate new knowledge, the generation of hallucinations, and the transparency of their decision-making process. In this paper, we explore how to prompt LLMs with knowledge graphs (KG), working as a remedy to engage LLMs with up-to-date knowledge and elicit the reasoning pathways from LLMs. Specifically, we build a prompting pipeline that endows LLMs with the capability of comprehending KG inputs and inferring with a combined implicit knowledge and the retrieved external knowledge. In addition, we investigate eliciting the mind map on which LLMs perform the reasoning and generate the answers. It is identified that the produced mind map exhibits the reasoning pathways of LLMs grounded on the ontology of knowledge, hence bringing the prospects of probing and gauging LLM inference in production. The experiments on three question & answering datasets also show that MindMap prompting leads to a striking empirical gain. For instance, pr
    
[^242]: 语言模型是否具有指称能力？

    Do Language Models Refer?. (arXiv:2308.05576v1 [cs.CL])

    [http://arxiv.org/abs/2308.05576](http://arxiv.org/abs/2308.05576)

    论文探讨了语言模型是否具有指称能力，并通过借鉴语言哲学外部主义传统的观点，提出了LMs可以指称的理由。

    

    语言模型（LMs）用语言做什么？大家都同意它们能够生成（大部分）连贯的句子。但是它们用这些字符串表达了什么，还是只是以一种令人信服的语言运用的模拟中胡言乱语？这是一个模糊的问题，有许多方法可以使其明确化。这里我们将解决该问题的一个方面，即，LMs的词语是否指称：即，LMs的输出是否实现了“词语-世界”之间的联系。有初步的理由认为它们不具备指称能力，因为LMs没有像普通语言用户那样与世界互动。借鉴语言哲学的外部主义传统的观点，我们认为表象是误导的，有充分的理由认为LMs可以指称。

    What do language models (LMs) do with language? Everyone agrees that they produce sequences of (mostly) coherent sentences. But are they saying anything with those strings or simply babbling in a convincing simulacrum of language use? This is a vague question, and there are many ways of making it precise. Here we will address one aspect of the question, namely, whether LMs' words refer: that is, whether the outputs of LMs achieve "word-to-world" connections. There is prima facie reason to think they do not since LMs do not interact with the world in the way that ordinary language users do. Drawing on insights from the externalist tradition in philosophy of language, we argue that appearances are misleading and that there is good reason to think that LMs can refer.
    
[^243]: 思维的骨架：大型语言模型可以进行并行解码

    Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding. (arXiv:2307.15337v1 [cs.CL])

    [http://arxiv.org/abs/2307.15337](http://arxiv.org/abs/2307.15337)

    本研究提出了一种名为“思维的骨架”的方法，可以通过并行解码来减少大型语言模型的生成延迟。这种方法不仅显著提高了速度，还可以潜在地提高答案质量。

    

    本研究旨在减少大型语言模型（LLMs）的端到端生成延迟。高生成延迟的一个主要原因是几乎所有最先进的LLMs都采用了顺序解码方法。在本研究中，受到人类的思考和写作过程的启发，我们提出了“思维的骨架”（SoT），它指导LLMs首先生成答案的骨架，然后通过并行API调用或批量解码来并行完成每个骨架点的内容。SoT不仅显著提高了速度（在11个不同的LLMs上提高了最多2.39倍），而且还可以潜在地提高在多个问题类别上的答案质量，包括多样性和相关性。SoT是一种针对效率的数据导向优化的初步尝试，并揭示了将LLMs推动更像人类思考以提高答案质量的潜力。

    This work aims at decreasing the end-to-end generation latency of large language models (LLMs). One of the major causes of the high generation latency is the sequential decoding approach adopted by almost all state-of-the-art LLMs. In this work, motivated by the thinking and writing process of humans, we propose "Skeleton-of-Thought" (SoT), which guides LLMs to first generate the skeleton of the answer, and then conducts parallel API calls or batched decoding to complete the contents of each skeleton point in parallel. Not only does SoT provide considerable speed-up (up to 2.39x across 11 different LLMs), but it can also potentially improve the answer quality on several question categories in terms of diversity and relevance. SoT is an initial attempt at data-centric optimization for efficiency, and reveal the potential of pushing LLMs to think more like a human for answer quality.
    
[^244]: Mol-Instructions: 一个大规模生物分子指令数据集，为大语言模型提供支持

    Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models. (arXiv:2306.08018v1 [q-bio.QM])

    [http://arxiv.org/abs/2306.08018](http://arxiv.org/abs/2306.08018)

    Mol-Instructions是一个专门为生物分子领域设计的综合指令数据集，可以显著提高大语言模型在生物领域中的适应能力和认知敏锐度。

    

    大语言模型（LLM）以其卓越的任务处理能力和创新的输出，在许多领域推动了重大进展。然而，它们在生物分子研究等专业领域的熟练应用还受到限制。为了解决这个挑战，我们介绍了Mol-Instructions，这是一个经过精心策划、专门针对生物分子领域设计的综合指令数据集。Mol-Instructions由三个关键组成部分组成：分子导向指令、蛋白质导向指令和生物分子文本指令，每个部分都被策划用于增强LLM对生物分子特性和行为的理解和预测能力。通过对代表性LLM的广泛指令调整实验，我们强调了Mol-Instructions在增强大模型在生物分子研究复杂领域内的适应能力和认知敏锐度方面的潜力，从而促进生物分子领域的进一步发展。

    Large Language Models (LLMs), with their remarkable task-handling capabilities and innovative outputs, have catalyzed significant advancements across a spectrum of fields. However, their proficiency within specialized domains such as biomolecular studies remains limited. To address this challenge, we introduce Mol-Instructions, a meticulously curated, comprehensive instruction dataset expressly designed for the biomolecular realm. Mol-Instructions is composed of three pivotal components: molecule-oriented instructions, protein-oriented instructions, and biomolecular text instructions, each curated to enhance the understanding and prediction capabilities of LLMs concerning biomolecular features and behaviors. Through extensive instruction tuning experiments on the representative LLM, we underscore the potency of Mol-Instructions to enhance the adaptability and cognitive acuity of large models within the complex sphere of biomolecular studies, thereby promoting advancements in the biomol
    
[^245]: LLM集成应用中的提示注入攻击研究

    Prompt Injection attack against LLM-integrated Applications. (arXiv:2306.05499v1 [cs.CR])

    [http://arxiv.org/abs/2306.05499](http://arxiv.org/abs/2306.05499)

    本研究分析了LLM集成应用中的提示注入攻击的复杂性和影响，提出了一种新颖的黑盒提示注入攻击技术HouYi，并揭示了应用程序提示机制中以前未知和严重低估的漏洞。我们的研究呼吁进一步开发全面的防御措施，以抵御LLM集成应用中的提示注入攻击。

    

    大语言模型(LLM)因其卓越的语言理解和生成能力而在它们周围刺激了一个充满活力的应用生态系统。然而，它们在各种服务中的广泛融合带来了重大的安全风险。本研究将解构实际LLM集成应用中的提示注入攻击的复杂性和影响。最初，我们对十个商业应用程序进行了探索性分析，突出了目前攻击策略在实践中的约束条件。受这些限制的启发，我们随后制定了HouYi，一种新颖的黑盒提示注入攻击技术，它借鉴了传统的Web注入攻击。HouYi分为三个关键元素: 一个无缝集成的预构建提示、一个注入提示诱导上下文分区以及一个恶意载荷，旨在实现攻击目标。利用HouYi，我们揭示了应用程序提示机制中以前未知和严重低估的漏洞，并演示了绕过最先进的检测机制的可行性。我们的研究呼吁进一步研究开发全面的防御措施，以抵御LLM集成应用中的提示注入攻击。

    Large Language Models (LLMs), renowned for their superior proficiency in language comprehension and generation, stimulate a vibrant ecosystem of applications around them. However, their extensive assimilation into various services introduces significant security risks. This study deconstructs the complexities and implications of prompt injection attacks on actual LLM-integrated applications. Initially, we conduct an exploratory analysis on ten commercial applications, highlighting the constraints of current attack strategies in practice. Prompted by these limitations, we subsequently formulate HouYi, a novel black-box prompt injection attack technique, which draws inspiration from traditional web injection attacks. HouYi is compartmentalized into three crucial elements: a seamlessly-incorporated pre-constructed prompt, an injection prompt inducing context partition, and a malicious payload designed to fulfill the attack objectives. Leveraging HouYi, we unveil previously unknown and sev
    
[^246]: 基于提示的预训练语言模型用于时间知识图谱补全

    Pre-trained Language Model with Prompts for Temporal Knowledge Graph Completion. (arXiv:2305.07912v1 [cs.CL])

    [http://arxiv.org/abs/2305.07912](http://arxiv.org/abs/2305.07912)

    这篇论文提出了一种基于提示的预训练语言模型（PPT），用于时间知识图谱补全。通过遮盖策略，将TKGC任务转换为遮盖词预测任务，可以利用预训练语言模型中的语义信息。

    

    时间知识图谱补全（TKGC）是一项重要的任务，它涉及在已知的时间戳上进行推理，以完成缺失部分的事实，并在近年来越来越受到关注。大多数现有方法都集中于基于图神经网络的学习表示，同时粗略地提取时间戳中的信息，并不充分利用关系中隐含的信息。为了解决这些问题，我们提出了一种新的TKGC模型，即基于提示的预训练语言模型（PPT）。我们将一系列采样的四元组转换为预训练语言模型的输入，并将时间戳之间的间隔转换为不同的提示，以形成带有隐含语义信息的连贯句子。我们使用遮盖策略训练我们的模型，将TKGC任务转换为遮盖词预测任务，从而可以利用预训练语言模型中的语义信息。实验结果和广泛的分析表明，

    Temporal Knowledge graph completion (TKGC) is a crucial task that involves reasoning at known timestamps to complete the missing part of facts and has attracted more and more attention in recent years. Most existing methods focus on learning representations based on graph neural networks while inaccurately extracting information from timestamps and insufficiently utilizing the implied information in relations. To address these problems, we propose a novel TKGC model, namely Pre-trained Language Model with Prompts for TKGC (PPT). We convert a series of sampled quadruples into pre-trained language model inputs and convert intervals between timestamps into different prompts to make coherent sentences with implicit semantic information. We train our model with a masking strategy to convert TKGC task into a masked token prediction task, which can leverage the semantic information in pre-trained language models. Experiments on three benchmark datasets and extensive analysis demonstrate that 
    
[^247]: ChatGPT引导的编辑辅助工具用于摘要汇总自定义

    ChatGPT-steered Editing Instructor for Customization of Abstractive Summarization. (arXiv:2305.02483v1 [cs.CL])

    [http://arxiv.org/abs/2305.02483](http://arxiv.org/abs/2305.02483)

    本文提出了一个三个代理的生成方案，包括生成器、辅导员和编辑器，以增强生成输出的自定义。在两个摘要总结数据集上进行的实验结果表明，我们的方法可以生成更好的输出。

    

    尽管大型语言模型（如ChatGPT）的生成质量令人印象深刻，但根据特定用户需求调整其输出仍然是一项挑战。本文提出了一个三个代理的生成方案——生成器、辅导员和编辑器，以增强生成输出的自定义。生成器产生初始输出，针对用户需求的辅导员产生编辑指导，而编辑器产生符合用户偏好的修订输出。无法训练的大型语言模型（ChatGPT）既充当生成器又充当编辑器，而较小的模型则充当用户特定的辅导员，引导生成过程朝向用户需求的方向发展。辅导员使用编辑者引导的强化学习进行培训，利用大规模编辑模型的反馈来优化指导生成。在两个摘要总结数据集上进行的实验结果表明，我们的方法可以生成更好的输出。

    Tailoring outputs of large language models, such as ChatGPT, to specific user needs remains a challenge despite their impressive generation quality. In this paper, we propose a tri-agent generation pipeline consisting of a generator, an instructor, and an editor to enhance the customization of generated outputs. The generator produces an initial output, the user-specific instructor generates editing instructions, and the editor generates a revised output aligned with user preferences. The inference-only large language model (ChatGPT) serves as both the generator and the editor, while a smaller model acts as the user-specific instructor to guide the generation process toward user needs. The instructor is trained using editor-steered reinforcement learning, leveraging feedback from the large-scale editor model to optimize instruction generation. Experimental results on two abstractive summarization datasets demonstrate the effectiveness of our approach in generating outputs that better f
    
[^248]: 个性化情感驱动的多模态推理：一个新的任务

    Personality-aware Human-centric Multimodal Reasoning: A New Task. (arXiv:2304.02313v1 [cs.CL])

    [http://arxiv.org/abs/2304.02313](http://arxiv.org/abs/2304.02313)

    本文介绍了一个新的个性化情感驱动的多模态推理任务，利用《生活大爆炸》电视剧构建了数据集，考虑个体个性，提出了三种基线方法，证明该任务具有挑战性和前景。

    

    多模态推理是一种人工智能领域，旨在从诸如视觉、语言和语音等多模态信号中进行推理和判断，近年来越来越受到关注。不同个性的人可能对同一情境做出不同反应。然而，在以前的研究中，个性这一方面并没有得到很好的考虑。本文提出了一个新的个性化情感驱动的多模态推理任务（Personality-aware HMR），并根据《生活大爆炸》电视剧构建了一个新的数据集，以预测特定时刻特定人物的行为，基于其过去和未来时刻的多模态信息。Myers-Briggs类型指标（MBTI）被注释并用于表示个体的个性。我们通过提出三种基线方法来基准测试该任务，其中两种是从相关任务中进行调整的，而一种是新提出的。实验结果表明，个性化情感驱动的多模态推理是一项具有挑战性和前景的任务，需要考虑个体个性的多模态推理。

    Multimodal reasoning, an area of artificial intelligence that aims at make inferences from multimodal signals such as vision, language and speech, has drawn more and more attention in recent years. People with different personalities may respond differently to the same situation. However, such individual personalities were ignored in the previous studies. In this work, we introduce a new Personality-aware Human-centric Multimodal Reasoning (Personality-aware HMR) task, and accordingly construct a new dataset based on The Big Bang Theory television shows, to predict the behavior of a specific person at a specific moment, given the multimodal information of its past and future moments. The Myers-Briggs Type Indicator (MBTI) was annotated and utilized in the task to represent individuals' personalities. We benchmark the task by proposing three baseline methods, two were adapted from the related tasks and one was newly proposed for our task. The experimental results demonstrate that person
    
[^249]: 针对低资源语言的不匹配感知无监督翻译质量评估

    Mismatching-Aware Unsupervised Translation Quality Estimation For Low-Resource Languages. (arXiv:2208.00463v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2208.00463](http://arxiv.org/abs/2208.00463)

    本文提出了一种针对低资源语言的无监督翻译质量评估方法，通过使用XLMRScore和一些改进措施来解决未翻译标记和语言不匹配的问题。

    

    翻译质量评估（QE）是在没有参考的情况下预测机器翻译（MT）输出质量的任务。这个任务在机器翻译的实际应用中越来越受到关注。在本文中，我们首先提出了XLMRScore，它是通过XLM-RoBERTa（XLMR）模型计算的BERTScore的跨语言对应物。这个度量可以用作简单的无监督QE方法，但使用它会导致两个问题：一是导致意外高翻译分数的未翻译标记，二是在XLMRScore中应用贪婪匹配时源语言和假设语言之间不匹配错误的问题。为了减轻这些问题，我们建议使用未翻译的词替换为未知标记，并跨语言对齐预训练模型以更接近对齐的词。我们在WMT21 QE共享任务的四个低资源语言对上评估了所提出的方法。

    Translation Quality Estimation (QE) is the task of predicting the quality of machine translation (MT) output without any reference. This task has gained increasing attention as an important component in the practical applications of MT. In this paper, we first propose XLMRScore, which is a cross-lingual counterpart of BERTScore computed via the XLM-RoBERTa (XLMR) model. This metric can be used as a simple unsupervised QE method, while employing it results in two issues: firstly, the untranslated tokens leading to unexpectedly high translation scores, and secondly, the issue of mismatching errors between source and hypothesis tokens when applying the greedy matching in XLMRScore. To mitigate these issues, we suggest replacing untranslated words with the unknown token and the cross-lingual alignment of the pre-trained model to represent aligned words closer to each other, respectively. We evaluate the proposed method on four low-resource language pairs of WMT21 QE shared task, as well as
    

