# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [DeTiME: Diffusion-Enhanced Topic Modeling using Encoder-decoder based LLM.](http://arxiv.org/abs/2310.15296) | DeTiME是一种使用基于编码-解码的LLMs增强扩散的主题建模方法，能够产生高度聚类的嵌入和具有增强语义一致性的主题，并能生成与主题相关的内容。 |
| [^2] | [Can We Edit Multimodal Large Language Models?.](http://arxiv.org/abs/2310.08475) | 本文提出了编辑多模式大型语言模型（MLLMs）的挑战，并构建了一个新的基准用于评估和比较不同编辑方法的效果。实验结果表明，编辑多模式LLMs仍然存在困难，但这项工作为NLP社区提供了宝贵的见解。 |
| [^3] | [Natural Language based Context Modeling and Reasoning with LLMs: A Tutorial.](http://arxiv.org/abs/2309.15074) | 本教程介绍了基于大型语言模型的自然语言上下文建模和推理，通过与LLMs交互，使用自然语言进行上下文建模和推理。 |
| [^4] | [Down the Toxicity Rabbit Hole: Investigating PaLM 2 Guardrails.](http://arxiv.org/abs/2309.06415) | 这项研究通过一个新颖的毒性兔子洞框架对PaLM 2的安全反馈进行了稳健性审计，揭示了PaLM 2生成的高度令人不安的毒性内容未被安全守护栏评估为高度不安全。 |
| [^5] | [Multiple Representation Transfer from Large Language Models to End-to-End ASR Systems.](http://arxiv.org/abs/2309.04031) | 本研究探索了将大型语言模型的多个表示转移到端到端自动语音识别系统中的技术，并证明了此方法的有效性。 |
| [^6] | [Translate Meanings, Not Just Words: IdiomKB's Role in Optimizing Idiomatic Translation with Language Models.](http://arxiv.org/abs/2308.13961) | 本研究提出了利用语言模型开发的多语言习语知识库（IdiomKB），通过检索习语的比喻意义，实现对习语的更好翻译。 |
| [^7] | [Knowledge Graph Prompting for Multi-Document Question Answering.](http://arxiv.org/abs/2308.11730) | 这篇论文提出了一种知识图谱引导的方法，用于在多文档问答任务中为大型语言模型（LLMs）提示正确的上下文。通过构建多个文档上的知识图谱，并设计基于语言模型的图遍历器，该方法能够帮助LLMs在MD-QA中进行答案预测。 |
| [^8] | [VisIT-Bench: A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use.](http://arxiv.org/abs/2308.06595) | VisIT-Bench是一个用于评价真实世界中视觉语言模型指示遵循的基准，包含了各种任务并提供了详细描述，可以自动评估多模态生成的质量差距。 |
| [^9] | [SeACo-Paraformer: A Non-Autoregressive ASR System with Flexible and Effective Hotword Customization Ability.](http://arxiv.org/abs/2308.03266) | SeACo-Paraformer是一种具有灵活且有效的热词自定义能力的非自回归ASR系统，在大规模实验中表现优于基线模型，并提出了过滤大规模热词的有效方法。 |
| [^10] | [EnrichEvent: Enriching Social Data with Contextual Information for Emerging Event Extraction.](http://arxiv.org/abs/2307.16082) | 本文提出了一个利用词汇、语义和上下文表示的框架，旨在解决现有事件检测方法在识别新兴社交事件方面的局限性，并提供了对社交数据进行丰富的上下文化处理的方法。 |
| [^11] | [Towards Automatic Boundary Detection for Human-AI Collaborative Hybrid Essay in Education.](http://arxiv.org/abs/2307.12267) | 本研究探索了在教育领域中，由人类和生成性语言模型协作编写的混合文本的AI内容检测方法，将其形式化为识别转换点的任务，以区分人类编写和AI生成的部分。 |
| [^12] | [Voting-based Multimodal Automatic Deception Detection.](http://arxiv.org/abs/2307.07516) | 本文提出了一种基于投票的多模态方法用于自动欺骗检测，通过视频的音频、视觉和文本特征进行检测。实验结果表明，我们的解决方案在欺骗检测中表现优于现有技术。 |
| [^13] | [Exploring Large Language Model for Graph Data Understanding in Online Job Recommendations.](http://arxiv.org/abs/2307.05722) | 本论文探索了大规模语言模型在在线职位推荐中对图数据的理解能力，并提出了新的框架来分析行为图，发现其中的潜在模式和关系。 |
| [^14] | [Automatic Assessment of Divergent Thinking in Chinese Language with TransDis: A Transformer-Based Language Model Approach.](http://arxiv.org/abs/2306.14790) | TransDis是一个基于Transformer的语言模型评分系统，用于评估中文发散性思维的质量和多样性。经过实验证明，TransDis的评分能够有效地预测人工评分，具有与人工评分相似的效度。 |
| [^15] | [MFAS: Emotion Recognition through Multiple Perspectives Fusion Architecture Search Emulating Human Cognition.](http://arxiv.org/abs/2306.09361) | 该论文提出了一种基于多角度融合结构搜索的情感识别框架，模拟人类的认知过程，能够从连续的角度捕捉更全面的情感信息。 |
| [^16] | [Judging LLM-as-a-judge with MT-Bench and Chatbot Arena.](http://arxiv.org/abs/2306.05685) | 研究使用强大的LLM作为评判员，通过引入两个基准测试来确认LLM评判员和人类偏好之间的一致性，并可调整聊天助手的模型架构和微调方法来提高其性能。 |
| [^17] | [Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective.](http://arxiv.org/abs/2305.15408) | 本文从理论层面探究了带有“思维链”提示的大型语言模型在解决基本数学和决策问题中的能力，发现自回归Transformer大小恒定即可解决任务，揭示了“思维链”提示的背后机制。 |
| [^18] | [GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints.](http://arxiv.org/abs/2305.13245) | 该论文介绍了一种将现有的多头语言模型检查点升级为具有多查询注意力（MQA）的模型的方法，并引入了群组查询注意力（GQA）来解决MQA可能导致的质量下降问题。通过升级后的GQA模型，实现了接近多头注意力的质量，并具备与MQA相当的速度。 |
| [^19] | [What You See is What You Read? Improving Text-Image Alignment Evaluation.](http://arxiv.org/abs/2305.10400) | 本研究介绍了SeeTRUE评估集和两种自动文本-图像对齐方法，这些方法在各种对齐任务中均取得了显着改进，在复杂组合或非自然图像的挑战性案例中表现出色。 |
| [^20] | [Dual Use Concerns of Generative AI and Large Language Models.](http://arxiv.org/abs/2305.07882) | 本文建议将双重使用研究框架应用于生成式人工智能和大型语言模型，提出了具体的应用建议，以加强人工智能治理并增强社会对其影响的认识。 |
| [^21] | [Lift Yourself Up: Retrieval-augmented Text Generation with Self Memory.](http://arxiv.org/abs/2305.02437) | 本文提出了一种新的检索增强文本生成模型Selfmem，通过迭代生成自我记忆池并采用记忆选择器，使检索更加自适应，提高了文本生成的质量和多样性。 |
| [^22] | [q2d: Turning Questions into Dialogs to Teach Models How to Search.](http://arxiv.org/abs/2304.14318) | 本文提出了q2d方法，通过自动生成含有查询的对话来教导模型如何发出搜索查询。实验表明，该方法的模型性能接近使用人类标注数据训练的模型，而且具有更好的控制和扩展性。 |
| [^23] | [Polytuplet Loss: A Reverse Approach to Training Reading Comprehension and Logical Reasoning Models.](http://arxiv.org/abs/2304.01046) | 本文研究了一种训练阅读理解和逻辑推理模型的反向方法，利用相对准确性的策略来训练模型，通过Polytuplet Loss函数来确保优先学习答案选择的相对正确性，获得了不错的成果，提出了具有一般性的训练方法和模型架构。 |
| [^24] | [EmotionIC: Emotional Inertia and Contagion-driven Dependency Modelling for Emotion Recognition in Conversation.](http://arxiv.org/abs/2303.11117) | 本文提出了一种新的依赖性建模方法，由情感惯性和感染驱动（EmotionIC），用于在特征提取和分类级别上进行会话情感识别。设计了多项具体方法，包括身份掩码多头注意（IM-MHA）和基于对话门控循环单元(DialogGRU)，以抓取上下文信息，提高模型的性能。 |
| [^25] | [A Comprehensive Capability Analysis of GPT-3 and GPT-3.5 Series Models.](http://arxiv.org/abs/2303.10420) | 本论文分析了GPT-3和GPT-3.5系列模型在自然语言理解任务中的发展趋势，并发现最新的模型在大多数任务中的表现优于前一代，特别是在零样本情况下。 |
| [^26] | [EHRSQL: A Practical Text-to-SQL Benchmark for Electronic Health Records.](http://arxiv.org/abs/2301.07695) | 该论文提出了一个面向电子病历数据的文本转SQL数据集，该数据集具有一系列独特挑战，包括生成SQL查询、理解时间表达式以及区分有无答案的问题。 |
| [^27] | [MENLI: Robust Evaluation Metrics from Natural Language Inference.](http://arxiv.org/abs/2208.07316) | 本文提出了一种基于自然语言推理的鲁棒性评估指标，比现有的摘要评估指标更好，在标准基准测试中表现良好且更加鲁棒，与现有指标相结合可以使评估效果进一步提高。 |
| [^28] | [A Longitudinal Multi-modal Dataset for Dementia Monitoring and Diagnosis.](http://arxiv.org/abs/2109.01537) | 该论文提出了一个纵向多模态数据集，用于痴呆监测和诊断。通过分析语言、言语和语用指标，可以区分神经退行性疾病患者和对照组，从而为痴呆研究提供了宝贵的资源。 |

# 详细

[^1]: DeTiME: 使用基于编码-解码的LLM增强扩散的主题建模方法

    DeTiME: Diffusion-Enhanced Topic Modeling using Encoder-decoder based LLM. (arXiv:2310.15296v1 [cs.CL])

    [http://arxiv.org/abs/2310.15296](http://arxiv.org/abs/2310.15296)

    DeTiME是一种使用基于编码-解码的LLMs增强扩散的主题建模方法，能够产生高度聚类的嵌入和具有增强语义一致性的主题，并能生成与主题相关的内容。

    

    在充满活力的自然语言处理领域，神经主题模型（NTMs）和大型语言模型（LLMs）已成为重要的研究领域。尽管如此，NTMs主要使用来自LLMs的上下文嵌入，这对于聚类或主题生成来说并不是最佳选择。我们的研究通过引入名为DeTiME的新框架来解决这一问题。DeTiME利用编码-解码的LLMs产生高度可聚类的嵌入，与现有方法相比，能够生成既具有优越的聚类性又具有增强的语义一致性的主题。此外，通过利用扩散的能力，我们的框架还提供了生成与已识别主题相关内容的能力。这种双重功能使用户能够同时高效产生高度聚类的主题和相关内容。DeTiME的潜力还包括生成集群化的嵌入。

    In the burgeoning field of natural language processing, Neural Topic Models (NTMs) and Large Language Models (LLMs) have emerged as areas of significant research interest. Despite this, NTMs primarily utilize contextual embeddings from LLMs, which are not optimal for clustering or capable for topic generation. Our study addresses this gap by introducing a novel framework named Diffusion-Enhanced Topic Modeling using Encoder-Decoder-based LLMs (DeTiME). DeTiME leverages ncoder-Decoder-based LLMs to produce highly clusterable embeddings that could generate topics that exhibit both superior clusterability and enhanced semantic coherence compared to existing methods. Additionally, by exploiting the power of diffusion, our framework also provides the capability to generate content relevant to the identified topics. This dual functionality allows users to efficiently produce highly clustered topics and related content simultaneously. DeTiME's potential extends to generating clustered embeddi
    
[^2]: 我们能编辑多模式大型语言模型吗？

    Can We Edit Multimodal Large Language Models?. (arXiv:2310.08475v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.08475](http://arxiv.org/abs/2310.08475)

    本文提出了编辑多模式大型语言模型（MLLMs）的挑战，并构建了一个新的基准用于评估和比较不同编辑方法的效果。实验结果表明，编辑多模式LLMs仍然存在困难，但这项工作为NLP社区提供了宝贵的见解。

    

    本文关注编辑多模式大型语言模型（MLLMs）。与编辑单模式LLMs相比，多模式模型的编辑更具挑战性，需要更高级别的审查和慎重考虑。为了促进这一领域的研究，我们构建了一个新的基准，称为MMEdit，用于编辑多模式LLMs，并建立了一套创新的度量标准进行评估。我们进行了包括各种模型编辑基线的综合实验，并分析了编辑多模式LLMs的不同组件的影响。根据经验，我们发现之前的基线在某种程度上可以实现编辑多模式LLMs，但效果仍然不理想，表明这个任务可能存在的困难。我们希望我们的工作能为NLP社区提供见解。代码和数据集可在https://github.com/zjunlp/EasyEdit获取。

    In this paper, we focus on editing Multimodal Large Language Models (MLLMs). Compared to editing single-modal LLMs, multimodal model editing is more challenging, which demands a higher level of scrutiny and careful consideration in the editing process. To facilitate research in this area, we construct a new benchmark, dubbed MMEdit, for editing multimodal LLMs and establishing a suite of innovative metrics for evaluation. We conduct comprehensive experiments involving various model editing baselines and analyze the impact of editing different components for multimodal LLMs. Empirically, we notice that previous baselines can implement editing multimodal LLMs to some extent, but the effect is still barely satisfactory, indicating the potential difficulty of this task. We hope that our work can provide the NLP community with insights. Code and dataset are available in https://github.com/zjunlp/EasyEdit.
    
[^3]: 基于大型语言模型（LLMs）的自然语言上下文建模与推理：教程

    Natural Language based Context Modeling and Reasoning with LLMs: A Tutorial. (arXiv:2309.15074v1 [cs.CL])

    [http://arxiv.org/abs/2309.15074](http://arxiv.org/abs/2309.15074)

    本教程介绍了基于大型语言模型的自然语言上下文建模和推理，通过与LLMs交互，使用自然语言进行上下文建模和推理。

    

    大型语言模型（LLMs）自2018年以来急剧增长，自引入上下文感知计算系统20年后。上下文感知计算通过考虑普适设备、用户和社会的情况，实现了广泛的创新应用，如辅助生活、基于位置的社交网络服务等。为了识别上下文并相应地做出决策，采用了各种人工智能技术（如本体论和OWL）作为上下文建模和推理的表示方法。最近，随着LLMs的崛起和它们改进的自然语言理解和推理能力，使用自然语言建模上下文并通过与ChatGPT和GPT-4等LLMs交互进行上下文推理变得可行。在本教程中，我们演示了使用文本、提示和自主代理（AutoAgents）使LLMs能够执行上下文建模的方法。

    Large language models (LLMs) have become phenomenally surging, since 2018--two decades after introducing context-awareness into computing systems. Through taking into account the situations of ubiquitous devices, users and the societies, context-aware computing has enabled a wide spectrum of innovative applications, such as assisted living, location-based social network services and so on. To recognize contexts and make decisions for actions accordingly, various artificial intelligence technologies, such as Ontology and OWL, have been adopted as representations for context modeling and reasoning. Recently, with the rise of LLMs and their improved natural language understanding and reasoning capabilities, it has become feasible to model contexts using natural language and perform context reasoning by interacting with LLMs such as ChatGPT and GPT-4. In this tutorial, we demonstrate the use of texts, prompts, and autonomous agents (AutoAgents) that enable LLMs to perform context modeling 
    
[^4]: 深入毒性兔子洞：通过PaLM 2的守护栏调查

    Down the Toxicity Rabbit Hole: Investigating PaLM 2 Guardrails. (arXiv:2309.06415v1 [cs.CL])

    [http://arxiv.org/abs/2309.06415](http://arxiv.org/abs/2309.06415)

    这项研究通过一个新颖的毒性兔子洞框架对PaLM 2的安全反馈进行了稳健性审计，揭示了PaLM 2生成的高度令人不安的毒性内容未被安全守护栏评估为高度不安全。

    

    本文通过引入一种名为“毒性兔子洞”的新型框架，对PaLM 2的安全反馈进行了强化稳健性审计。从一个刻板印象开始，该框架指示PaLM 2生成比刻板印象更具有毒性的内容。每一次迭代，它都要求PaLM 2生成比上一次迭代更具有毒性的内容，直到PaLM 2的安全守护栏发出安全违规警报。我们的实验揭示了极其令人不安的反犹太主义、伊斯兰恐惧症、种族主义、恐同和厌女情绪（仅列举几种）的生成内容，并且这些内容在PaLM 2的安全守护栏评估中并未被视为高度不安全。

    This paper conducts a robustness audit of the safety feedback of PaLM 2 through a novel toxicity rabbit hole framework introduced here. Starting with a stereotype, the framework instructs PaLM 2 to generate more toxic content than the stereotype. Every subsequent iteration it continues instructing PaLM 2 to generate more toxic content than the previous iteration until PaLM 2 safety guardrails throw a safety violation. Our experiments uncover highly disturbing antisemitic, Islamophobic, racist, homophobic, and misogynistic (to list a few) generated content that PaLM 2 safety guardrails do not evaluate as highly unsafe.
    
[^5]: 大型语言模型到端到端ASR系统的多重表示转移

    Multiple Representation Transfer from Large Language Models to End-to-End ASR Systems. (arXiv:2309.04031v1 [cs.CL])

    [http://arxiv.org/abs/2309.04031](http://arxiv.org/abs/2309.04031)

    本研究探索了将大型语言模型的多个表示转移到端到端自动语音识别系统中的技术，并证明了此方法的有效性。

    

    将大型语言模型的知识转移是将语言知识整合到端到端自动语音识别系统的一种有前途的技术。然而，现有的工作只能转移LLM的单个表示（例如，预训练BERT的最后一层），而文本的表示在本质上是非唯一的，可以通过不同层、上下文和模型以各种方式获得。在这项工作中，我们探索了各种技术来获得和转移LLMs的多个表示到基于传导器的ASR系统中。尽管在概念上简单，但我们证明了将LLMs的多个表示转移可以是转移单个表示的有效替代方法。

    Transferring the knowledge of large language models (LLMs) is a promising technique to incorporate linguistic knowledge into end-to-end automatic speech recognition (ASR) systems. However, existing works only transfer a single representation of LLM (e.g. the last layer of pretrained BERT), while the representation of a text is inherently non-unique and can be obtained variously from different layers, contexts and models. In this work, we explore a wide range of techniques to obtain and transfer multiple representations of LLMs into a transducer-based ASR system. While being conceptually simple, we show that transferring multiple representations of LLMs can be an effective alternative to transferring only a single representation.
    
[^6]: 翻译含义，而不仅仅是词语：IdiomKB在利用语言模型优化习语翻译中的作用

    Translate Meanings, Not Just Words: IdiomKB's Role in Optimizing Idiomatic Translation with Language Models. (arXiv:2308.13961v1 [cs.CL])

    [http://arxiv.org/abs/2308.13961](http://arxiv.org/abs/2308.13961)

    本研究提出了利用语言模型开发的多语言习语知识库（IdiomKB），通过检索习语的比喻意义，实现对习语的更好翻译。

    

    为了进行良好的翻译，机器翻译系统和通用语言模型需要对源语言和目标语言以及文化有深入的理解。因此，由于其非组合性的特性，习语对基于Transformer的系统提出了特殊的挑战，因为直译往往会忽略意图。传统方法使用现有的知识库（KB）替换习语，往往缺乏规模和上下文意识。针对这些挑战，我们的方法优先考虑上下文意识和可扩展性，允许在可管理的KB大小的离线存储中存储习语。这确保了更高效的小型模型服务，并提供了对习语表达的更全面的理解。我们介绍了一个使用大型语言模型开发的多语言习语KB（IdiomKB）来解决这个问题。通过检索习语的比喻意义，该KB可以帮助小型模型（如BLOOMZ（7.1B），Alpaca（7B）和InstructGPT（6.7B））实现更好的翻译。

    To translate well, machine translation (MT) systems and general-purposed language models (LMs) need a deep understanding of both source and target languages and cultures. Therefore, idioms, with their non-compositional nature, pose particular challenges for Transformer-based systems, as literal translations often miss the intended meaning. Traditional methods, which replace idioms using existing knowledge bases (KBs), often lack scale and context awareness. Addressing these challenges, our approach prioritizes context awareness and scalability, allowing for offline storage of idioms in a manageable KB size. This ensures efficient serving with smaller models and provides a more comprehensive understanding of idiomatic expressions. We introduce a multilingual idiom KB (IdiomKB) developed using large LMs to address this. This KB facilitates better translation by smaller models, such as BLOOMZ (7.1B), Alpaca (7B), and InstructGPT (6.7B), by retrieving idioms' figurative meanings. We presen
    
[^7]: 多文档问答中的知识图谱引导

    Knowledge Graph Prompting for Multi-Document Question Answering. (arXiv:2308.11730v1 [cs.CL])

    [http://arxiv.org/abs/2308.11730](http://arxiv.org/abs/2308.11730)

    这篇论文提出了一种知识图谱引导的方法，用于在多文档问答任务中为大型语言模型（LLMs）提示正确的上下文。通过构建多个文档上的知识图谱，并设计基于语言模型的图遍历器，该方法能够帮助LLMs在MD-QA中进行答案预测。

    

    大型语言模型（LLMs）的“预训练、提示、预测”范式在开放域问答（OD-QA）中取得了显著的成功。然而，很少有工作在多文档问答（MD-QA）场景下探索这个范式，这是一个要求对不同文档的内容和结构之间的逻辑关联有深入理解的任务。为了填补这一重要的空白，我们提出了一种知识图谱引导（KGP）方法，用于在MD-QA中为LLMs提示正确的上下文，该方法包括图构建模块和图遍历模块。对于图构建，我们使用节点来表示文段或文档结构（例如，页面/表格），而使用边来表示文段之间的语义/词汇相似性或者文档内的结构关系。对于图遍历，我们设计了一个基于LM的图遍历器，它在节点之间导航并收集支持性的文段，以帮助LLMs在MD-QA中进行答案预测。

    The 'pre-train, prompt, predict' paradigm of large language models (LLMs) has achieved remarkable success in open-domain question answering (OD-QA). However, few works explore this paradigm in the scenario of multi-document question answering (MD-QA), a task demanding a thorough understanding of the logical associations among the contents and structures of different documents. To fill this crucial gap, we propose a Knowledge Graph Prompting (KGP) method to formulate the right context in prompting LLMs for MD-QA, which consists of a graph construction module and a graph traversal module. For graph construction, we create a knowledge graph (KG) over multiple documents with nodes symbolizing passages or document structures (e.g., pages/tables), and edges denoting the semantic/lexical similarity between passages or intra-document structural relations. For graph traversal, we design an LM-guided graph traverser that navigates across nodes and gathers supporting passages assisting LLMs in MD
    
[^8]: VisIT-Bench: 一个受真实世界使用启发的视觉语言指示评估基准

    VisIT-Bench: A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use. (arXiv:2308.06595v1 [cs.CL])

    [http://arxiv.org/abs/2308.06595](http://arxiv.org/abs/2308.06595)

    VisIT-Bench是一个用于评价真实世界中视觉语言模型指示遵循的基准，包含了各种任务并提供了详细描述，可以自动评估多模态生成的质量差距。

    

    我们引入了VisIT-Bench（Visual InsTruction Benchmark），这是一个评价用于真实世界使用的视觉语言模型的指示遵循基准。我们的起点是策划了70个“指示家族”，我们认为指示调优的视觉语言模型应该能够解决这些家族。任务不仅限于VQAv2和COCO等评估，涵盖了从基本识别到游戏玩法和创造性生成的各种任务。在策划之后，我们的数据集包括592个测试查询，每个查询都带有一个人工编写的指示条件化的字幕。这些描述展现了特定指示因素，例如对于询问店面对于轮椅用户的易访问性的指示，条件化的字幕描述了斜坡/潜在障碍物。这些描述使得我们可以：1）收集每个实例的人工验证的参考输出；2）使用仅文本的语言模型对候选多模态生成进行自动评估，与人类判断相一致。我们量化了质量差距。

    We introduce VisIT-Bench (Visual InsTruction Benchmark), a benchmark for evaluation of instruction-following vision-language models for real-world use. Our starting point is curating 70 'instruction families' that we envision instruction tuned vision-language models should be able to address. Extending beyond evaluations like VQAv2 and COCO, tasks range from basic recognition to game playing and creative generation. Following curation, our dataset comprises 592 test queries, each with a human-authored instruction-conditioned caption. These descriptions surface instruction-specific factors, e.g., for an instruction asking about the accessibility of a storefront for wheelchair users, the instruction-conditioned caption describes ramps/potential obstacles. These descriptions enable 1) collecting human-verified reference outputs for each instance; and 2) automatic evaluation of candidate multimodal generations using a text-only LLM, aligning with human judgment. We quantify quality gaps be
    
[^9]: SeACo-Paraformer:一种具有灵活且有效的热词自定义能力的非自回归ASR系统

    SeACo-Paraformer: A Non-Autoregressive ASR System with Flexible and Effective Hotword Customization Ability. (arXiv:2308.03266v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2308.03266](http://arxiv.org/abs/2308.03266)

    SeACo-Paraformer是一种具有灵活且有效的热词自定义能力的非自回归ASR系统，在大规模实验中表现优于基线模型，并提出了过滤大规模热词的有效方法。

    

    热词自定义是ASR领域中一个重要的问题，使用户能够自定义实体、人物和其他短语的名称具有价值。过去几年中，ASR上下文建模的隐式和显式建模策略都得到了发展。尽管这些方法表现还不错，但仍存在某些缺点，例如在效果稳定性方面的不稳定性。在本文中，我们提出了一种新颖的基于语义增强的上下文Paraformer (SeACo-Paraformer)的非自回归ASR系统，具有灵活且有效的热词自定义能力。它结合了基于AED模型的准确性、基于NAR模型的效率以及在上下文建模方面的出色表现。在50,000小时的工业大数据实验中，我们提出的模型在自定义和常规ASR任务中优于强基线模型。此外，我们还探索了一种有效的方法来过滤大规模的热词以进一步改进。

    Hotword customization is one of the important issues remained in ASR field it is of value to enable users of ASR systems to customize names of entities, persons and other phrases. The past few years have seen both implicit and explicit modeling strategies for ASR contextualization developed. While these approaches have performed adequately, they still exhibit certain shortcomings such as instability in effectiveness. In this paper we propose Semantic-augmented Contextual-Paraformer (SeACo-Paraformer) a novel NAR based ASR system with flexible and effective hotword customization ability. It combines the accuracy of the AED-based model, the efficiency of the NAR model, and the excellent performance in contextualization. In 50,000 hours industrial big data experiments, our proposed model outperforms strong baselines in customization and general ASR tasks. Besides, we explore an efficient way to filter large scale incoming hotwords for further improvement. The source codes and industrial
    
[^10]: EnrichEvent: 使用上下文信息为新出现的事件提供丰富的社交数据

    EnrichEvent: Enriching Social Data with Contextual Information for Emerging Event Extraction. (arXiv:2307.16082v1 [cs.CL])

    [http://arxiv.org/abs/2307.16082](http://arxiv.org/abs/2307.16082)

    本文提出了一个利用词汇、语义和上下文表示的框架，旨在解决现有事件检测方法在识别新兴社交事件方面的局限性，并提供了对社交数据进行丰富的上下文化处理的方法。

    

    社交平台已成为传播和讨论真实事件信息的关键平台，为及早发现有新闻价值的事件提供了良好的机会。然而，现有的大多数事件检测方法仅利用关键词突发性或网络结构来检测热点事件。因此，对于事件和社交数据的复杂性而言，它们往往无法在达到趋势状态之前识别出新出现的社交事件。社交数据，例如推文，具有拼写错误、不完整性、歧义性和语言不规范性，以及意见方面的变化。此外，利用有限的上下文知识来学习事件的演变特征对于机器学习模型几乎是不可行的。为了解决这些问题，本文提出了一个利用流式社交数据的词汇、语义和上下文表示的框架。

    Social platforms have emerged as a crucial platform for disseminating and discussing information about real-life events, which offers an excellent opportunity for early detection of newsworthy events. However, most existing approaches for event detection solely exploit keyword burstiness or network structures to detect hot events. Thus, they often fail to identify emerging social events before reaching a trending state regarding the challenging nature of events and social data. Social data, e.g., tweets, is characterized by misspellings, incompleteness, ambiguity, and irregular language, as well as variation in aspects of opinions. Moreover, learning the evolving characteristics of the events utilizing limited contextual knowledge is almost infeasible for machine learning models. To address these problems, in this paper, we propose a framework that exploits the lexical, semantic, and contextual representations of streaming social data. In particular, we leverage contextual knowledge to
    
[^11]: 面向教育中人工智能协作混合论文的自动边界检测

    Towards Automatic Boundary Detection for Human-AI Collaborative Hybrid Essay in Education. (arXiv:2307.12267v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.12267](http://arxiv.org/abs/2307.12267)

    本研究探索了在教育领域中，由人类和生成性语言模型协作编写的混合文本的AI内容检测方法，将其形式化为识别转换点的任务，以区分人类编写和AI生成的部分。

    

    最近的大型语言模型（如ChatGPT）能够在提供具体指导的情况下生成类似于人类的流畅回答。尽管承认技术进步带来的便利，教育者也担心学生可能利用语言模型来完成写作任务并将其假冒为自己的原创作品。虽然有很多AI内容检测研究是基于这些担忧进行的，但大多数之前的研究将AI内容检测建模为一个分类问题，假设一个文本要么完全由人类编写，要么完全由AI生成。在本研究中，我们研究了AI内容检测在一个少有探索但却现实的情况下，即检测的文本由人类和生成性语言模型（即混合文本）协作编写。我们首先将检测任务形式化为从给定的混合文本中识别人类编写内容和AI生成内容之间的转换点（边界检测）。

    The recent large language models (LLMs), e.g., ChatGPT, have been able to generate human-like and fluent responses when provided with specific instructions. While admitting the convenience brought by technological advancement, educators also have concerns that students might leverage LLMs to complete their writing assignments and pass them off as their original work. Although many AI content detection studies have been conducted as a result of such concerns, most of these prior studies modeled AI content detection as a classification problem, assuming that a text is either entirely human-written or entirely AI-generated. In this study, we investigated AI content detection in a rarely explored yet realistic setting where the text to be detected is collaboratively written by human and generative LLMs (i.e., hybrid text). We first formalized the detection task as identifying the transition points between human-written content and AI-generated content from a given hybrid text (boundary det
    
[^12]: 基于投票的多模态自动欺骗检测

    Voting-based Multimodal Automatic Deception Detection. (arXiv:2307.07516v1 [cs.LG])

    [http://arxiv.org/abs/2307.07516](http://arxiv.org/abs/2307.07516)

    本文提出了一种基于投票的多模态方法用于自动欺骗检测，通过视频的音频、视觉和文本特征进行检测。实验结果表明，我们的解决方案在欺骗检测中表现优于现有技术。

    

    自动欺骗检测一直是一个热门的研究课题，利用机器学习和深度学习自动检测欺骗给这一旧领域带来了新的光明。在本文中，我们提出了一种基于投票的方法，用于从视频中使用音频、视觉和文本特征进行自动欺骗检测。我们在两个数据集上进行了实验，分别是密歇根大学的真实试验数据集和迈阿密大学的欺骗检测数据集。视频样本被分成图像、音频和手稿的帧。我们提出的多模态投票解决方案包括三个模型。第一个模型是用于从图像中检测欺骗的卷积神经网络（CNN），第二个模型是用于从音频中检测欺骗的Mel频谱图上的支持向量机（SVM），第三个模型是用于从手稿中检测欺骗的支持向量机（SVM）上的Word2Vec。我们提出的解决方案优于现有技术水平。在图像、音频和文本上取得的最佳结果分别为97％、96％、9

    Automatic Deception Detection has been a hot research topic for a long time, using machine learning and deep learning to automatically detect deception, brings new light to this old field. In this paper, we proposed a voting-based method for automatic deception detection from videos using audio, visual and lexical features. Experiments were done on two datasets, the Real-life trial dataset by Michigan University and the Miami University deception detection dataset. Video samples were split into frames of images, audio, and manuscripts. Our Voting-based Multimodal proposed solution consists of three models. The first model is CNN for detecting deception from images, the second model is Support Vector Machine (SVM) on Mel spectrograms for detecting deception from audio and the third model is Word2Vec on Support Vector Machine (SVM) for detecting deception from manuscripts. Our proposed solution outperforms state of the art. Best results achieved on images, audio and text were 97%, 96%, 9
    
[^13]: 探索大规模语言模型在在线职位推荐中对图数据的理解

    Exploring Large Language Model for Graph Data Understanding in Online Job Recommendations. (arXiv:2307.05722v1 [cs.AI])

    [http://arxiv.org/abs/2307.05722](http://arxiv.org/abs/2307.05722)

    本论文探索了大规模语言模型在在线职位推荐中对图数据的理解能力，并提出了新的框架来分析行为图，发现其中的潜在模式和关系。

    

    大规模语言模型（LLMs）在各个领域展示了其出色的能力，彻底改变了自然语言处理任务。然而，它们在职位推荐中对行为图的理解潜力仍然未被充分探索。本文旨在揭示大规模语言模型在理解行为图方面的能力，并利用这种理解来提升在线招聘中的推荐，包括促进非分布式的应用。我们提出了一个新的框架，利用大规模语言模型提供的丰富上下文信息和语义表示来分析行为图并揭示其中的潜在模式和关系。具体而言，我们提出了一个元路径提示构造器，利用LLM推荐器首次理解行为图，并设计了相应的路径增强模块来缓解基于路径的序列输入引入的提示偏差。通过利用将LM的特点引入到行为图的大规模数据分析中，我们取得了显著的实验结果，证明了我们提出的方法的有效性和性能。

    Large Language Models (LLMs) have revolutionized natural language processing tasks, demonstrating their exceptional capabilities in various domains. However, their potential for behavior graph understanding in job recommendations remains largely unexplored. This paper focuses on unveiling the capability of large language models in understanding behavior graphs and leveraging this understanding to enhance recommendations in online recruitment, including the promotion of out-of-distribution (OOD) application. We present a novel framework that harnesses the rich contextual information and semantic representations provided by large language models to analyze behavior graphs and uncover underlying patterns and relationships. Specifically, we propose a meta-path prompt constructor that leverages LLM recommender to understand behavior graphs for the first time and design a corresponding path augmentation module to alleviate the prompt bias introduced by path-based sequence input. By leveragin
    
[^14]: 基于Transformer的语言模型方法在中文发散性思维的自动评估中的应用——TransDis

    Automatic Assessment of Divergent Thinking in Chinese Language with TransDis: A Transformer-Based Language Model Approach. (arXiv:2306.14790v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.14790](http://arxiv.org/abs/2306.14790)

    TransDis是一个基于Transformer的语言模型评分系统，用于评估中文发散性思维的质量和多样性。经过实验证明，TransDis的评分能够有效地预测人工评分，具有与人工评分相似的效度。

    

    语言模型在自动创造力评估中越来越受欢迎，通过生成语义距离来客观地衡量创造性思维的质量。然而，目前缺乏一个针对中文创造性思维评估的自动化系统。为了填补这个空白，我们开发了TransDis，一个采用基于Transformer的语言模型的评分系统，能够为中文中的Alternate Uses Task（AUT）回答提供有效的独创性（质量）和灵活性（多样性）评分。研究1表明，由三个基于Transformer的模型组成的潜在模型评分的原创性因素强烈预测人工原创性评分，而模型评分的灵活性与人工灵活性评分也强相关。准则效度分析表明，模型评分的原创性和灵活性与其他创造力测量正相关，证明与人工评分具有相似的效度。研究2和3表明，TransDis能够快速、准确地评估中文发散性思维的特征。

    Language models have been increasingly popular for automatic creativity assessment, generating semantic distances to objectively measure the quality of creative ideas. However, there is currently a lack of an automatic assessment system for evaluating creative ideas in the Chinese language. To address this gap, we developed TransDis, a scoring system using transformer-based language models, capable of providing valid originality (quality) and flexibility (variety) scores for Alternative Uses Task (AUT) responses in Chinese. Study 1 demonstrated that the latent model-rated originality factor, comprised of three transformer-based models, strongly predicted human originality ratings, and the model-rated flexibility strongly correlated with human flexibility ratings as well. Criterion validity analyses indicated that model-rated originality and flexibility positively correlated to other creativity measures, demonstrating similar validity to human ratings. Study 2 & 3 showed that TransDis e
    
[^15]: MFAS: 基于多角度融合结构搜索的情感识别，模拟人类认知

    MFAS: Emotion Recognition through Multiple Perspectives Fusion Architecture Search Emulating Human Cognition. (arXiv:2306.09361v1 [eess.AS])

    [http://arxiv.org/abs/2306.09361](http://arxiv.org/abs/2306.09361)

    该论文提出了一种基于多角度融合结构搜索的情感识别框架，模拟人类的认知过程，能够从连续的角度捕捉更全面的情感信息。

    

    语音情感识别旨在识别和分析与人类类似的情绪状态。完美的情感识别可以极大地改善各种人机交互任务。受人类理解情感的过程的启发，我们证明了与量化建模相比，从连续的角度理解语音内容，类似于人类的理解，能够使模型捕捉更全面的情感信息。此外，考虑到人类根据语音中存在的某些线索调整情感单词的文本语义的感知，我们设计了一个新的搜索空间并搜索两种信息的最佳融合策略。实验结果进一步验证了调整感知的重要性。基于这些观察结果，我们提出了一种新的框架，称为Multiple perspectives Fusion Architecture Search(MFAS)。

    Speech emotion recognition aims to identify and analyze emotional states in target speech similar to humans. Perfect emotion recognition can greatly benefit a wide range of human-machine interaction tasks. Inspired by the human process of understanding emotions, we demonstrate that compared to quantized modeling, understanding speech content from a continuous perspective, akin to human-like comprehension, enables the model to capture more comprehensive emotional information. Additionally, considering that humans adjust their perception of emotional words in textual semantic based on certain cues present in speech, we design a novel search space and search for the optimal fusion strategy for the two types of information. Experimental results further validate the significance of this perception adjustment. Building on these observations, we propose a novel framework called Multiple perspectives Fusion Architecture Search (MFAS). Specifically, we utilize continuous-based knowledge to capt
    
[^16]: 用MT-Bench和Chatbot Arena评估以LLM为基础的聊天助手

    Judging LLM-as-a-judge with MT-Bench and Chatbot Arena. (arXiv:2306.05685v1 [cs.CL])

    [http://arxiv.org/abs/2306.05685](http://arxiv.org/abs/2306.05685)

    研究使用强大的LLM作为评判员，通过引入两个基准测试来确认LLM评判员和人类偏好之间的一致性，并可调整聊天助手的模型架构和微调方法来提高其性能。

    

    评估基于大语言模型（LLM）的聊天助手会面临挑战，因为它们具有广泛的功能，而现有的基准无法衡量人类偏好。为了解决这个问题，我们探索使用强大的LLM作为评判员，在更加开放的问题上评估这些模型。我们研究了LLM作为评判员的使用和局限性，如位置和冗余偏见以及有限的推理能力，并提出解决方案来迁移其中一些问题。然后，我们通过引入两个基准测试（一个多轮问答集和一个众包竞技平台）来确认LLM评判员和人类偏好之间的一致性。我们的结果显示，像GPT-4这样的强大LLM评判员可以很好地匹配受控和众包人类偏好，达到了80％以上的一致性，与人类一致性水平相同。因此，LLM作为评判员是一种可扩展且可解释的逼近人类偏好的方式，而这些偏好是非常昂贵获取的。此外，我们证明，通过使用LLM作为评判员，可以通过调整聊天助手的模型架构和微调方法来提高其性能。

    Evaluating large language model (LLM) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of LLM-as-a-judge, such as position and verbosity biases and limited reasoning ability, and propose solutions to migrate some of them. We then verify the agreement between LLM judges and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80\% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we
    
[^17]: 从理论角度揭示“思维链”背后的奥秘

    Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective. (arXiv:2305.15408v1 [cs.LG])

    [http://arxiv.org/abs/2305.15408](http://arxiv.org/abs/2305.15408)

    本文从理论层面探究了带有“思维链”提示的大型语言模型在解决基本数学和决策问题中的能力，发现自回归Transformer大小恒定即可解决任务，揭示了“思维链”提示的背后机制。

    

    最近的研究发现，"思维链"提示能够显著提高大型语言模型（LLMs）的性能，特别是在涉及数学或推理的复杂任务中。尽管获得了巨大的实证成功，但“思维链”背后的机制以及它如何释放LLMs的潜力仍然是神秘的。本文首次从理论上回答了这些问题。具体而言，我们研究了LLMs带有“思维链”在解决基本数学和决策问题中的能力。我们首先给出一个不可能的结果，表明任何有限深度的Transformer都不能直接输出正确的基本算术/方程任务的答案，除非模型大小随着输入长度的增加呈超多项式增长。相反，我们通过构造证明，大小恒定的自回归Transformer足以通过使用常用的数学语言形式生成“思维链”推导来解决这两个任务。

    Recent studies have discovered that Chain-of-Thought prompting (CoT) can dramatically improve the performance of Large Language Models (LLMs), particularly when dealing with complex tasks involving mathematics or reasoning. Despite the enormous empirical success, the underlying mechanisms behind CoT and how it unlocks the potential of LLMs remain elusive. In this paper, we take a first step towards theoretically answering these questions. Specifically, we examine the capacity of LLMs with CoT in solving fundamental mathematical and decision-making problems. We start by giving an impossibility result showing that any bounded-depth Transformer cannot directly output correct answers for basic arithmetic/equation tasks unless the model size grows super-polynomially with respect to the input length. In contrast, we then prove by construction that autoregressive Transformers of a constant size suffice to solve both tasks by generating CoT derivations using a commonly-used math language forma
    
[^18]: GQA:从多头检查点训练广义多查询Transformer模型

    GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints. (arXiv:2305.13245v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.13245](http://arxiv.org/abs/2305.13245)

    该论文介绍了一种将现有的多头语言模型检查点升级为具有多查询注意力（MQA）的模型的方法，并引入了群组查询注意力（GQA）来解决MQA可能导致的质量下降问题。通过升级后的GQA模型，实现了接近多头注意力的质量，并具备与MQA相当的速度。

    

    多查询注意力（MQA）仅使用一个键值头，大大加快了解码器推理速度。然而，MQA可能导致质量下降，并且为了更快地推理而训练一个单独的模型可能不是理想的。我们（1）提出了一个方法，利用原始预训练计算量的5％，将现有的多头语言模型检查点升级为具有MQA的模型，并（2）引入了群组查询注意力（GQA），它是多查询注意力的广义形式，使用中间数量的键值头（多于一个，少于查询头的数量）。我们表明，经过升级的GQA实现了与多头注意力相当的速度，并且具有接近的质量。

    Multi-query attention (MQA), which only uses a single key-value head, drastically speeds up decoder inference. However, MQA can lead to quality degradation, and moreover it may not be desirable to train a separate model just for faster inference. We (1) propose a recipe for uptraining existing multi-head language model checkpoints into models with MQA using 5% of original pre-training compute, and (2) introduce grouped-query attention (GQA), a generalization of multi-query attention which uses an intermediate (more than one, less than number of query heads) number of key-value heads. We show that uptrained GQA achieves quality close to multi-head attention with comparable speed to MQA.
    
[^19]: 你看到的就是你读到的? 改进文本-图像对齐评估方法

    What You See is What You Read? Improving Text-Image Alignment Evaluation. (arXiv:2305.10400v1 [cs.CL])

    [http://arxiv.org/abs/2305.10400](http://arxiv.org/abs/2305.10400)

    本研究介绍了SeeTRUE评估集和两种自动文本-图像对齐方法，这些方法在各种对齐任务中均取得了显着改进，在复杂组合或非自然图像的挑战性案例中表现出色。

    

    自动确定文本和相应的图像是否语义上对齐是视觉语言模型面临的一项重要挑战，应用于生成文本到图像和图像到文本任务。在本研究中，我们研究了自动文本-图像对齐评估方法。我们首先介绍了SeeTRUE：一个全面的评估集，涵盖了从文本到图像和图像到文本生成任务的多个数据集，并具有人类的判断，判断给定的文本-图像对是否语义上对齐。然后，我们描述了两种自动确定对齐的方法：第一种是基于问题生成和视觉问题回答模型的管道，第二种是通过微调多模态预训练模型的端到端分类方法。这两种方法在各种文本-图像对齐任务中均超越了先前的方法，在涉及复杂组合或非自然图像的挑战性案例中有显着改进。最后，我们证明即使最先进的模型在这个任务上还有很大的改进空间，这激励了未来在这个领域的研究。

    Automatically determining whether a text and a corresponding image are semantically aligned is a significant challenge for vision-language models, with applications in generative text-to-image and image-to-text tasks. In this work, we study methods for automatic text-image alignment evaluation. We first introduce SeeTRUE: a comprehensive evaluation set, spanning multiple datasets from both text-to-image and image-to-text generation tasks, with human judgements for whether a given text-image pair is semantically aligned. We then describe two automatic methods to determine alignment: the first involving a pipeline based on question generation and visual question answering models, and the second employing an end-to-end classification approach by finetuning multimodal pretrained models. Both methods surpass prior approaches in various text-image alignment tasks, with significant improvements in challenging cases that involve complex composition or unnatural images. Finally, we demonstrate 
    
[^20]: 生成式人工智能和大型语言模型的双重使用问题：实现“受关注的双重使用研究”框架的建议

    Dual Use Concerns of Generative AI and Large Language Models. (arXiv:2305.07882v1 [cs.CY])

    [http://arxiv.org/abs/2305.07882](http://arxiv.org/abs/2305.07882)

    本文建议将双重使用研究框架应用于生成式人工智能和大型语言模型，提出了具体的应用建议，以加强人工智能治理并增强社会对其影响的认识。

    

    我们建议将原本设计用于生命科学领域的“受关注的双重使用研究”（DURC）框架应用于生成式人工智能，具体关注大型语言模型（LLM）。通过在生物研究领域的优势和缺点的证明，我们相信DURC标准可以为LLM重新定义，可能有助于改善人工智能治理。在使用DURC框架时需要权衡的情况下，我们强调其在提高社会对生成式人工智能影响的认识方面的重要政治作用。最后，我们提供一系列具体的建议，以将DURC方法应用于LLM的研究中。

    We suggest the implementation of the Dual Use Research of Concern (DURC) framework, originally designed for life sciences, to the domain of generative AI, with a specific focus on Large Language Models (LLMs). With its demonstrated advantages and drawbacks in biological research, we believe the DURC criteria can be effectively redefined for LLMs, potentially contributing to improved AI governance. Acknowledging the balance that must be struck when employing the DURC framework, we highlight its crucial political role in enhancing societal awareness of the impact of generative AI. As a final point, we offer a series of specific recommendations for applying the DURC approach to LLM research.
    
[^21]: 运用自我记忆的检索增强文本生成模型

    Lift Yourself Up: Retrieval-augmented Text Generation with Self Memory. (arXiv:2305.02437v1 [cs.CL])

    [http://arxiv.org/abs/2305.02437](http://arxiv.org/abs/2305.02437)

    本文提出了一种新的检索增强文本生成模型Selfmem，通过迭代生成自我记忆池并采用记忆选择器，使检索更加自适应，提高了文本生成的质量和多样性。

    

    相较于传统文本生成模型，检索增强文本生成模型能够直接迭代人类编写的参考库，并从中检索出相应的信息，以生成更优质的文本。但当前文献存在一个关键问题：检索到的记忆来自于固定的语料库，其质量存在一定局限性，可能会限制记忆增强模型的潜力。本文提出一种名为Selfmem的框架，该框架通过迭代地采用检索增强生成器自身以生成无限制的自我记忆池，并使用记忆选择器为下一轮生成选择一个生成的记忆。相结合，这两个主要问题提出了运用自我记忆的检索增强文本生成模型。

    With direct access to human-written reference as memory, retrieval-augmented generation has achieved much progress in a wide range of text generation tasks. Since better memory would typically prompt better generation~(we define this as primal problem), previous works mainly focus on how to retrieve better memory. However, one fundamental limitation exists for current literature: the memory is retrieved from a fixed corpus and is bounded by the quality of the corpus. Due to the finite retrieval space, bounded memory would greatly limit the potential of the memory-augmented generation model. In this paper, by exploring the duality of the primal problem: better generation also prompts better memory, we propose a framework called Selfmem, which iteratively adopts a retrieval-augmented generator itself to generate an unbounded memory pool and uses a memory selector to pick one generated memory for the next generation round. By combining the primal and dual problem, a retrieval-augmented ge
    
[^22]: q2d：将问题转换为对话，教导模型如何搜索

    q2d: Turning Questions into Dialogs to Teach Models How to Search. (arXiv:2304.14318v1 [cs.CL])

    [http://arxiv.org/abs/2304.14318](http://arxiv.org/abs/2304.14318)

    本文提出了q2d方法，通过自动生成含有查询的对话来教导模型如何发出搜索查询。实验表明，该方法的模型性能接近使用人类标注数据训练的模型，而且具有更好的控制和扩展性。

    

    最近的对话语言模型有一个激动人心的能力，即能够独立地搜索相关信息，以确定给定对话的响应。然而，获取用于教导模型如何发出搜索查询的训练数据是耗费时间和资源的。在本文中，我们提出了q2d：一种自动生成从问题中获取信息的对话的数据生成流水线。我们提供给一个大型的语言模型（PaLM）来创建问答数据集的对话版本，并使用它来改进与外部搜索API通信以确定对话响应的查询生成模型。与先前依赖于人类编写的带有搜索查询的对话的方法不同，我们的方法允许自动生成基于查询的对话，从而实现更好的控制和规模。我们的实验表明：（1）针对QReCC数据集的查询生成，使用我们的合成数据训练的模型实现了从MNLI中进行传输学习的模型性能的90%--97%，而使用人工标注的查询生成数据训练的模型实现了91%--96%的性能。（2）针对QUAC和CoQA数据集的基础响应选择，使用我们自动生成的对话训练的模型性能仅比使用带有搜索查询的人类生成的对话训练的模型性能低了0.8-2.2％。

    One of the exciting capabilities of recent language models for dialog is their ability to independently search for relevant information to ground a given dialog response. However, obtaining training data to teach models how to issue search queries is time and resource consuming. In this work, we propose q2d: an automatic data generation pipeline that generates information-seeking dialogs from questions. We prompt a large language model (PaLM) to create conversational versions of question answering datasets, and use it to improve query generation models that communicate with external search APIs to ground dialog responses. Unlike previous approaches which relied on human written dialogs with search queries, our method allows to automatically generate query-based grounded dialogs with better control and scale. Our experiments demonstrate that: (1) For query generation on the QReCC dataset, models trained on our synthetically-generated data achieve 90%--97% of the performance of models tr
    
[^23]: “Polytuplet Loss: 训练阅读理解和逻辑推理模型的反向方法”

    Polytuplet Loss: A Reverse Approach to Training Reading Comprehension and Logical Reasoning Models. (arXiv:2304.01046v1 [cs.CL] CROSS LISTED)

    [http://arxiv.org/abs/2304.01046](http://arxiv.org/abs/2304.01046)

    本文研究了一种训练阅读理解和逻辑推理模型的反向方法，利用相对准确性的策略来训练模型，通过Polytuplet Loss函数来确保优先学习答案选择的相对正确性，获得了不错的成果，提出了具有一般性的训练方法和模型架构。

    

    在整个学校教育过程中，学生们将受到阅读理解和逻辑推理的考验。学生们已经开发了各种策略来完成此类考试，其中有些被认为是通常表现优于其他策略的。这样一种策略涉及强调相对准确性而非绝对准确性，理论上可以在不完全掌握解题所需信息的情况下得出正确答案。本文研究了应用这种策略来训练迁移学习模型以解决阅读理解和逻辑推理问题的有效性。这些模型在具有挑战性的阅读理解和逻辑推理基准数据集ReClor上进行了评估。尽管以前的研究集中于逻辑推理技能，但我们专注于一种通用的训练方法和模型架构。我们提出了Polytuplet Loss函数，是三元组损失函数的扩展，以确保优先学习答案选择的相对正确性而非学习绝对正确性。

    Throughout schooling, students are tested on reading comprehension and logical reasoning. Students have developed various strategies for completing such exams, some of which are generally thought to outperform others. One such strategy involves emphasizing relative accuracy over absolute accuracy and can theoretically produce the correct answer without full knowledge of the information required to solve the question. This paper examines the effectiveness of applying such a strategy to train transfer learning models to solve reading comprehension and logical reasoning questions. The models were evaluated on the ReClor dataset, a challenging reading comprehension and logical reasoning benchmark. While previous studies targeted logical reasoning skills, we focus on a general training method and model architecture. We propose the polytuplet loss function, an extension of the triplet loss function, to ensure prioritization of learning the relative correctness of answer choices over learning
    
[^24]: EmotionIC：基于情感惯性和感染的依赖建模可用于对话中的情感识别

    EmotionIC: Emotional Inertia and Contagion-driven Dependency Modelling for Emotion Recognition in Conversation. (arXiv:2303.11117v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.11117](http://arxiv.org/abs/2303.11117)

    本文提出了一种新的依赖性建模方法，由情感惯性和感染驱动（EmotionIC），用于在特征提取和分类级别上进行会话情感识别。设计了多项具体方法，包括身份掩码多头注意（IM-MHA）和基于对话门控循环单元(DialogGRU)，以抓取上下文信息，提高模型的性能。

    

    最近，随着人机界面技术的进步和实施，对话中的情感识别（ERC）吸引了越来越多的关注。然而，以往的建模方法在全局和局部上下文依赖方面丢失了依赖信息的多样性，并且在分类级别不考虑上下文依赖关系。本文提出了一种新的依赖性建模方法，由情感惯性和感染驱动（EmotionIC），用于在特征提取和分类级别上进行会话情感识别。在特征提取级别，我们设计的身份掩码多头注意（IM-MHA）捕捉对话中基于身份的长距离上下文，以包含不同参与者的不同影响构建全局情感氛围，而设计的基于对话门控循环单元(DialogGRU)则聚合了二元对话的情感倾向，并应用于分类过程。

    Emotion Recognition in Conversation (ERC) has attracted growing attention in recent years as a result of the advancement and implementation of human-computer interface technologies. However, previous approaches to modeling global and local context dependencies lost the diversity of dependency information and do not take the context dependency into account at the classification level. In this paper, we propose a novel approach to dependency modeling driven by Emotional Inertia and Contagion (EmotionIC) for conversational emotion recognition at the feature extraction and classification levels. At the feature extraction level, our designed Identity Masked Multi-head Attention (IM-MHA) captures the identity-based long-distant context in the dialogue to contain the diverse influence of different participants and construct the global emotional atmosphere, while the devised Dialogue-based Gate Recurrent Unit (DialogGRU) that aggregates the emotional tendencies of dyadic dialogue is applied to
    
[^25]: GPT-3和GPT-3.5系列模型的全面能力分析

    A Comprehensive Capability Analysis of GPT-3 and GPT-3.5 Series Models. (arXiv:2303.10420v1 [cs.CL])

    [http://arxiv.org/abs/2303.10420](http://arxiv.org/abs/2303.10420)

    本论文分析了GPT-3和GPT-3.5系列模型在自然语言理解任务中的发展趋势，并发现最新的模型在大多数任务中的表现优于前一代，特别是在零样本情况下。

    

    GPT系列模型，如GPT-3、CodeX、InstructGPT、ChatGPT等，由于其出色的自然语言处理能力而受到广泛关注。然而，尽管已有大量研究探讨了GPT系列模型与精调模型在能力上的差异，但对于GPT系列模型的能力随时间演化的研究却受到了限制。为了全面分析GPT系列模型的能力，我们选择了六个代表性模型，包括两个GPT-3系列模型（即davinci和text-davinci-001）和四个GPT-3.5系列模型（即code-davinci-002、text-davinci-002、text-davinci-003和gpt-3.5-turbo）。我们使用21个数据集在九个自然语言理解（NLU）任务上评估它们的表现。特别地，我们比较了每个任务中不同模型在零样本和少样本场景下的性能和鲁棒性。我们广泛的实验表明，GPT系列模型的整体能力继续随时间演化，最新的模型在大多数任务中的表现优于前一代，特别是在零样本情况下。

    GPT series models, such as GPT-3, CodeX, InstructGPT, ChatGPT, and so on, have gained considerable attention due to their exceptional natural language processing capabilities. However, despite the abundance of research on the difference in capabilities between GPT series models and fine-tuned models, there has been limited attention given to the evolution of GPT series models' capabilities over time. To conduct a comprehensive analysis of the capabilities of GPT series models, we select six representative models, comprising two GPT-3 series models (i.e., davinci and text-davinci-001) and four GPT-3.5 series models (i.e., code-davinci-002, text-davinci-002, text-davinci-003, and gpt-3.5-turbo). We evaluate their performance on nine natural language understanding (NLU) tasks using 21 datasets. In particular, we compare the performance and robustness of different models for each task under zero-shot and few-shot scenarios. Our extensive experiments reveal that the overall ability of GPT s
    
[^26]: EHRSQL：面向电子病历的实用文本转SQL基准测试

    EHRSQL: A Practical Text-to-SQL Benchmark for Electronic Health Records. (arXiv:2301.07695v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.07695](http://arxiv.org/abs/2301.07695)

    该论文提出了一个面向电子病历数据的文本转SQL数据集，该数据集具有一系列独特挑战，包括生成SQL查询、理解时间表达式以及区分有无答案的问题。

    

    我们为电子病历（EHR）提供了一个新的文本到SQL数据集。对话是由222个医院工作人员包括医生、护士、保险审查和健康档案团队等手机而来。为了构建关于结构化EHR数据的QA数据集，我们在一所大学医院进行了一次民调并制作了模板话术以创建种子问题。然后，我们手动将它们链接到两个开源的EHR数据库（MIMIC-III和eICU）中，并在数据集中包含了来自民意调查的各种时间表达式和未能回答的问题。我们的数据集提出了一系列独特的挑战：模型需要 1）生成反映医院中各种需求的SQL查询，包括简单的检索和复杂的操作，如计算生存率，2）理解各种时间表达式以回答与时间敏感的医疗问题相关的问题，3）根据预测区分给定问题是可回答还是不可回答。

    We present a new text-to-SQL dataset for electronic health records (EHRs). The utterances were collected from 222 hospital staff, including physicians, nurses, insurance review and health records teams, and more. To construct the QA dataset on structured EHR data, we conducted a poll at a university hospital and templatized the responses to create seed questions. Then, we manually linked them to two open-source EHR databases, MIMIC-III and eICU, and included them with various time expressions and held-out unanswerable questions in the dataset, which were all collected from the poll. Our dataset poses a unique set of challenges: the model needs to 1) generate SQL queries that reflect a wide range of needs in the hospital, including simple retrieval and complex operations such as calculating survival rate, 2) understand various time expressions to answer time-sensitive questions in healthcare, and 3) distinguish whether a given question is answerable or unanswerable based on the predicti
    
[^27]: MENLI: 自然语言推理的鲁棒性评估指标

    MENLI: Robust Evaluation Metrics from Natural Language Inference. (arXiv:2208.07316v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2208.07316](http://arxiv.org/abs/2208.07316)

    本文提出了一种基于自然语言推理的鲁棒性评估指标，比现有的摘要评估指标更好，在标准基准测试中表现良好且更加鲁棒，与现有指标相结合可以使评估效果进一步提高。

    

    最近被提出的基于BERT的文本生成评估指标在标准基准测试中表现良好，但易受到对信息正确性的攻击。我们认为这部分原因是此类模型是基于语义相似性建模的。相反，我们提出一种基于自然语言推理（NLI）的鲁棒性评估指标，这种指标更适合建模。我们设计了一种基于偏好的对抗性攻击框架，并表明我们的NLI基础指标比最近的BERT基础指标更具鲁棒性。在标准基准测试中，我们的NLI基础指标优于现有的摘要评估指标，但低于SOTA MT指标。然而，在现有指标与我们的NLI指标相结合时，我们既获得了更高的对抗鲁棒性（15％-30％），又获得了标准基准测试中更高的质量指标（+5％至30％）。

    Recently proposed BERT-based evaluation metrics for text generation perform well on standard benchmarks but are vulnerable to adversarial attacks, e.g., relating to information correctness. We argue that this stems (in part) from the fact that they are models of semantic similarity. In contrast, we develop evaluation metrics based on Natural Language Inference (NLI), which we deem a more appropriate modeling. We design a preference-based adversarial attack framework and show that our NLI based metrics are much more robust to the attacks than the recent BERT-based metrics. On standard benchmarks, our NLI based metrics outperform existing summarization metrics, but perform below SOTA MT metrics. However, when combining existing metrics with our NLI metrics, we obtain both higher adversarial robustness (15%-30%) and higher quality metrics as measured on standard benchmarks (+5% to 30%).
    
[^28]: 用于痴呆监测和诊断的纵向多模态数据集

    A Longitudinal Multi-modal Dataset for Dementia Monitoring and Diagnosis. (arXiv:2109.01537v1 [cs.CL] CROSS LISTED)

    [http://arxiv.org/abs/2109.01537](http://arxiv.org/abs/2109.01537)

    该论文提出了一个纵向多模态数据集，用于痴呆监测和诊断。通过分析语言、言语和语用指标，可以区分神经退行性疾病患者和对照组，从而为痴呆研究提供了宝贵的资源。

    

    痴呆是一系列神经退行性疾病，影响越来越多的全球老龄人口的记忆和认知能力。自动化分析语言、言语和语用指标作为认知衰退的潜在指标日益受到关注。在这里，我们提出了一个新颖的纵向多模态数据集，该数据集在自然环境下收集了轻度痴呆患者和配对的年龄匹配对照组的数据，时间跨度为几个月。多模态数据包括口头会话，其中的一部分被转录，以及输入和书写的思考内容，以及相关的非语言信息，如笔画和按键。我们详细描述了该数据集，并着重讨论了使用语音模态的任务。后者涉及利用数据的纵向特性来区分对照组和痴呆患者。我们的实验显示，会话间语音的变化在不同的会话之间存在显著差异。

    Dementia is a family of neurogenerative conditions affecting memory and cognition in an increasing number of individuals in our globally aging population. Automated analysis of language, speech and paralinguistic indicators have been gaining popularity as potential indicators of cognitive decline. Here we propose a novel longitudinal multi-modal dataset collected from people with mild dementia and age matched controls over a period of several months in a natural setting. The multi-modal data consists of spoken conversations, a subset of which are transcribed, as well as typed and written thoughts and associated extra-linguistic information such as pen strokes and keystrokes. We describe the dataset in detail and proceed to focus on a task using the speech modality. The latter involves distinguishing controls from people with dementia by exploiting the longitudinal nature of the data. Our experiments showed significant differences in how the speech varied from session to session in the 
    

