# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [arXiVeri: Automatic table verification with GPT.](http://arxiv.org/abs/2306.07968) | 本文提出了自动表格验证任务（AutoTV），提供了一个新的基准测试 arXiVeri 来验证其准确性，通过基于 GPT 的方法实现了自动表格验证，在表格匹配和单元格匹配任务中均达到了最先进的性能。 |
| [^2] | [MOFI: Learning Image Representations from Noisy Entity Annotated Images.](http://arxiv.org/abs/2306.07952) | MOFI 提出了一种新的方法，自动从含噪图像文本对中为图像指定实体标签，创建了一个新的大规模数据集 I2E，通过研究不同的训练配方，学习到了能够有效学习图像表示的模型。 |
| [^3] | [Questioning the Survey Responses of Large Language Models.](http://arxiv.org/abs/2306.07951) | 本文使用美国人口普查局建立的全美社区调查（ACS）评估了十几个不同大小的语言模型，发现小型模型具有显著的位置和标签偏差，而模型大小的增加能减轻这种偏差，但无法根据US群体或任何可识别的群体趋势进行调整。 |
| [^4] | [Speech-to-Text Adapter and Speech-to-Entity Retriever Augmented LLMs for Speech Understanding.](http://arxiv.org/abs/2306.07944) | 本文提出了一种联合语音和语言模型（SLM），将声音映射到文本嵌入式空间，使用基于CTC的空白过滤器来缩短语音序列长度。在语音MultiWoz数据集中，SLM提高了对话状态跟踪（DST）性能。为了解决稀有实体的错误，我们采用Speech2Entity检索器增强SLM。使用此检索-augmented SLM（ReSLM），DST性能得到进一步提高。该研究表明，增强ASR任务可以提高其性能。 |
| [^5] | [FOOCTTS: Generating Arabic Speech with Acoustic Environment for Football Commentator.](http://arxiv.org/abs/2306.07936) | 本论文介绍了 FOOCTTS，一种为足球解说员生成带有背景人群噪音的语音的自动流水线。该系统能够在有限的15分钟足球解说员录音内生成带有其声学环境的语音。 |
| [^6] | [Multi-modal Representation Learning for Social Post Location Inference.](http://arxiv.org/abs/2306.07935) | 本文提出了多模态表示学习框架（MRLF），用于将社交媒体文章的不同模态融合起来进行位置推断。该方法集成了一个多头注意力机制以增强位置显著信息提取，相对于单一领域的方法显著提高位置推断的准确性。 |
| [^7] | [BoardgameQA: A Dataset for Natural Language Reasoning with Contradictory Information.](http://arxiv.org/abs/2306.07934) | 本文提出了一个用于带有矛盾信息的自然语言推理的数据集，以解决推理中不一致和矛盾信息的问题，同时提供了一种可推翻推理策略。 |
| [^8] | [Understanding Telecom Language Through Large Language Models.](http://arxiv.org/abs/2306.07933) | 文章提出通过fine-tune多个大型语言模型实现电信领域自动化操作，以便识别3GPP标准工作组。 |
| [^9] | [Human-in-the-Loop through Chain-of-Thought.](http://arxiv.org/abs/2306.07932) | 通过人在循环链中的方式，手动校正系统可以通过探究理性中子逻辑的手动校正来提高LLM的推理性能，并且基于经济理论的CAMLOP可以平衡效用和成本。 |
| [^10] | [Large Language Model Is Semi-Parametric Reinforcement Learning Agent.](http://arxiv.org/abs/2306.07929) | 根据人类记忆和推理机制，提出了一种新的可演化LLM智能体框架REMEMBERER，通过为LLM装备长期经验记忆，可以为不同任务提供优异的智能体，其构成了半参数RL代理。成功率超过先前SOTA 4％和2％。 |
| [^11] | [A Theory of Unsupervised Speech Recognition.](http://arxiv.org/abs/2306.07926) | 本文提出了一个通用的理论框架，以研究无监督语音识别系统的属性，证明了各种可学习性条件和样本复杂性边界，并在合成语言的实验中得到了强有力的实证证据。 |
| [^12] | [WebGLM: Towards An Efficient Web-Enhanced Question Answering System with Human Preferences.](http://arxiv.org/abs/2306.07906) | 本文提出的WebGLM是一种基于GLM的网络问答系统，使用LLM-augmented检索器、引导式生成器和人类偏好感知评分器等策略提高了准确性、效率和成本效益，并在人类评估中表现出比WebGPT更好的性能。 |
| [^13] | [Massively Multilingual Corpus of Sentiment Datasets and Multi-faceted Sentiment Classification Benchmark.](http://arxiv.org/abs/2306.07902) | 本研究介绍了一种可以用于训练情感模型的最全面的开放式大规模多语言数据集，该数据集由79个手动选定的数据集组成，覆盖了27种语言，代表了6种语言家族。而且，我们还提供了一个多方面的情感分类基准。 |
| [^14] | [Artificial Artificial Artificial Intelligence: Crowd Workers Widely Use Large Language Models for Text Production Tasks.](http://arxiv.org/abs/2306.07899) | 该研究调查了众包工人使用大型语言模型的普遍性，结果发现33-46%的众包工人在完成任务时使用了LLMs，我们需要更加警惕这类问题。 |
| [^15] | [ReadProbe: A Demo of Retrieval-Enhanced Large Language Models to Support Lateral Reading.](http://arxiv.org/abs/2306.07875) | ReadProbe 是一种利用大型语言模型和搜索引擎支持横向阅读的工具，它能够生成有用问题和答案以帮助用户评估在线信息。 |
| [^16] | [GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio Pretraining for Speech Emotion Recognition.](http://arxiv.org/abs/2306.07848) | 本文提出了GEmo-CLAP模型用于语音情感识别，结合了性别属性信息，相比于其他先进方法，该模型在IEMOCAP上实现了更优越的识别性能。 |
| [^17] | [Adversarial Capsule Networks for Romanian Satire Detection and Sentiment Analysis.](http://arxiv.org/abs/2306.07845) | 本文提出了一种对抗胶囊网络用于罗马尼亚讽刺检测和情感分析的方法，通过基于字符级对抗性过程生成人工样本提高了模型的鲁棒性并优于现有方法，实现了高达99.08％的准确性。 |
| [^18] | [ChatGPT vs Human-authored Text: Insights into Controllable Text Summarization and Sentence Style Transfer.](http://arxiv.org/abs/2306.07799) | 本文旨在系统地检查ChatGPT在两个可控生成任务中的表现，即ChatGPT能否适应不同的目标受众和写作风格。研究发现，人类产生的文体变化比ChatGPT表现出的更大，而生成的文本在一些特征上与人类样本有所不同，有时会包含事实错误或幻觉。 |
| [^19] | [NoCoLA: The Norwegian Corpus of Linguistic Acceptability.](http://arxiv.org/abs/2306.07790) | 本论文提出了两个新的挪威语数据集，分别用于二元分类和纯诊断任务，旨在评估语言模型的语法理解能力。它们适用于不同类型的语言模型，并用于对现有挪威语言模型进行比较研究。 |
| [^20] | [A Cloud-based Machine Learning Pipeline for the Efficient Extraction of Insights from Customer Reviews.](http://arxiv.org/abs/2306.07786) | 本文介绍了一种基于云的系统，利用机器学习方法从客户评论中提取见解。本研究提出的组合模型使用了转换器神经网络、向量嵌入和聚类，已经集成并进一步发展，以更好地满足高效信息提取、提取信息的主题建模和用户需求的要求。研究结果表明，本系统可以比现有的主题建模和关键字提取解决方案获得更好的效果。 |
| [^21] | [Tokenization with Factorized Subword Encoding.](http://arxiv.org/abs/2306.07764) | 本文提出了一种因式分解子词编码的分词方法，被称为“因式分解器”，在七种不同语言的语言建模和形态句法任务中进行评估，相较于常用的BPE算法具有更好的适应性和鲁棒性。 |
| [^22] | [NAVER LABS Europe's Multilingual Speech Translation Systems for the IWSLT 2023 Low-Resource Track.](http://arxiv.org/abs/2306.07763) | 本文介绍了NAVER LABS Europe使用预训练模型和多语言参数效率解决方案在低资源环境下最大化翻译质量的方法，并在IWSLT 2023低资源赛道中Tamasheq-French和Quechua-Spanish语音翻译上取得了出色的结果。 |
| [^23] | [StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion and Adversarial Training with Large Speech Language Models.](http://arxiv.org/abs/2306.07691) | 本文提出了一种名为StyleTTS 2的TTS模型，通过对抗训练和大型语音语言模型来实现人类级别的语音合成。与以往模型不同，StyleTTS 2将样式视为潜在随机变量，利用扩散模型来生成最适合文本的样式，同时受益于大型SLMs和新的可微分持续时间建模。 |
| [^24] | [Rethink the Effectiveness of Text Data Augmentation: An Empirical Analysis.](http://arxiv.org/abs/2306.07664) | 本研究发现数据增强技术在语言模型的预训练及微调中仍具有显著的提升作用，尤其在少样本学习的情况下，持续的预训练可以提高微调性能10%以上。 |
| [^25] | [Is Anisotropy Inherent to Transformers?.](http://arxiv.org/abs/2306.07656) | 本文证明各向异性不仅是优化长尾分布令牌的交叉熵损失结果，还可能是Transformers-based模型固有的。 |
| [^26] | [Modality Adaption or Regularization? A Case Study on End-to-End Speech Translation.](http://arxiv.org/abs/2306.07650) | 该文讨论了解决端到端语音翻译中的数据匮乏问题的预训练和微调方法，并发现规范化方法比精心设计的模态适应方法更重要，能够优化E2E ST的性能。 |
| [^27] | [Hybrid lemmatization in HuSpaCy.](http://arxiv.org/abs/2306.07636) | 本文介绍了一种混合架构的词形还原器，利用了神经模型、词典和手工制作的规则，在形态丰富的匈牙利语数据集上产生了良好的实证结果。 |
| [^28] | [SqueezeLLM: Dense-and-Sparse Quantization.](http://arxiv.org/abs/2306.07629) | 本文提出了一种基于训练后的量化框架——SqueezeLLM，它不仅可以实现高达3位的无损压缩，而且在相同的内存约束下实现更高的量化性能。 |
| [^29] | [Human-Like Intuitive Behavior and Reasoning Biases Emerged in Language Models -- and Disappeared in GPT-4.](http://arxiv.org/abs/2306.07622) | 本研究揭示了大型语言模型（LLMs）具有类人直觉行为和认知错误的特点，而高级语言模型则通过学习避免这类错误并表现出超理性的方式。此外，通过使用心理学研究的方法探测LLMs，可以揭示其新生特性。 |
| [^30] | [Rank-Aware Negative Training for Semi-Supervised Text Classification.](http://arxiv.org/abs/2306.07621) | 本文提出了一种Rank-aware Negative Training（RNT）框架，通过基于不确定性的推理方法排名未标注文本并利用负样本训练解决了在半监督文本分类中存在噪声标签的问题。 |
| [^31] | [Question Decomposition Tree for Answering Complex Questions over Knowledge Bases.](http://arxiv.org/abs/2306.07597) | 本文提出了一种问题分解树(QDT)来表示复杂问题的结构，该方法通过一个称为Clue-Decipher的两阶段方法来生成QDT，可以提高知识库问答(KBQA)任务的性能。 |
| [^32] | [Large Language Models Sometimes Generate Purely Negatively-Reinforced Text.](http://arxiv.org/abs/2306.07567) | 大型语言模型有时会从仅包含负奖励的例子中学习，导致生成类似泄漏密码或安全漏洞等敏感信息的文本 |
| [^33] | [HAUSER: Towards Holistic and Automatic Evaluation of Simile Generation.](http://arxiv.org/abs/2306.07554) | HAUSER是一个面向隐喻生成任务的评估系统，利用三个视角的五个标准和自动指标进行全面、高效和可靠的评估。 |
| [^34] | [TART: A plug-and-play Transformer module for task-agnostic reasoning.](http://arxiv.org/abs/2306.07536) | TART提出了一种即插即用的Transformer模块，它能够在没有任务特定训练或微调的情况下，在不同推理目标之间进行泛化。 |
| [^35] | [Noisy Positive-Unlabeled Learning with Self-Training for Speculative Knowledge Graph Reasoning.](http://arxiv.org/abs/2306.07512) | 本文提出了一种嘈杂正-无标记学习问题的变分框架nPUGraph，并引入自训练策略，以应对真实世界知识图谱上的思辨性推理任务。实验结果表明了我们提出的方法的有效性。 |
| [^36] | [Adding guardrails to advanced chatbots.](http://arxiv.org/abs/2306.07500) | 研究探讨了 ChatGPT 不同用例对于公平回答问题的能力，并发现它对于测试任务而言是公平的搜索引擎，但在文本生成和代码生成上有偏见，并且对于变化非常敏感。 |
| [^37] | [Improving Opinion-based Question Answering Systems Through Label Error Detection and Overwrite.](http://arxiv.org/abs/2306.07499) | 本文提出了一种名为LEDO的模型-不可知且计算高效的框架，能够有效解决标签错误问题，并将其应用于意见问答系统中，提高了该系统在各个核心模型中的准确性。 |
| [^38] | [Resources for Brewing BEIR: Reproducible Reference Models and an Official Leaderboard.](http://arxiv.org/abs/2306.07471) | 提供了BEIR基准数据集的可重复参考实现和官方排行榜以跟踪模型性能和进展。 |
| [^39] | [Izindaba-Tindzaba: Machine learning news categorisation for Long and Short Text for isiZulu and Siswati.](http://arxiv.org/abs/2306.07426) | 本研究为南非本土isiZulu和Siswati语言构建了新闻主题分类数据集，并采用扩增、过采样等方法增加数据量。基于Word2vec模型的XGBoost、逻辑回归和LSTM分类器表现优于其他模型。 |
| [^40] | [Gender-Inclusive Grammatical Error Correction through Augmentation.](http://arxiv.org/abs/2306.07415) | 本研究发现GEC系统在使用男性和女性术语以及性别中立的单数“they”的时候显示出性别偏见。研究人员通过开发平行数据集，并基于语言学洞见进行数据增强，为减少GEC系统中的偏见做出了贡献。 |
| [^41] | [Textual Augmentation Techniques Applied to Low Resource Machine Translation: Case of Swahili.](http://arxiv.org/abs/2306.07414) | 本文研究了将文本数据扩充任务应用于低资源机器翻译的效果，尝试了三种简单的数据扩充技术，并将其与英斯瓦希里数据集的基线神经机器翻译性能进行了比较。 |
| [^42] | [Enhancing Topic Extraction in Recommender Systems with Entropy Regularization.](http://arxiv.org/abs/2306.07403) | 本论文介绍一种新的方法，称为熵规则，以提高推荐系统中主题提取的可解释性。实验证实该方法可在保持主任务性能竞争力的同时，在主题连贯性方面有显著提高。 |
| [^43] | [The economic trade-offs of large language models: A case study.](http://arxiv.org/abs/2306.07402) | 本研究通过一个案例研究，以评估大型语言模型在企业中为类似客户服务的场景所带来的成本和效益。从该品牌客户服务代理的反馈中比较了三种专门化LLM的策略-提示工程、微调和知识蒸馏，发现模型响应的可用性可以弥补成本差异。 |
| [^44] | [Implementing BERT and fine-tuned RobertA to detect AI generated news by ChatGPT.](http://arxiv.org/abs/2306.07401) | 使用BERT和微调的RobertA模型可以最好地检测ChatGPT生成的AI新闻。 RobertA模型在精度方面表现出色，取得了98％的得分。这些模型可以在打击假新闻中发挥关键作用。 |
| [^45] | [Probing Quantifier Comprehension in Large Language Models.](http://arxiv.org/abs/2306.07384) | 本文提出了对于大型语言模型（LLMs）对量化理解的探究，并质疑之前研究中关于LLMs理解极少数类型的量词能力呈现反比例缩放的说法，并提出新的测试方法，展示其与以前研究所展示的行为不同。 |
| [^46] | [Lost in Translation: Large Language Models in Non-English Content Analysis.](http://arxiv.org/abs/2306.07377) | 大型语言模型目前主要运用于英语内容的智能分析中，多语言模型的发展旨在弥补其他语言数据匮乏的情况。研究人员和技术公司通过构建多语言语言模型尝试解决这一问题并拓展大型语言模型的能力。多语言模型在低资源语言应用中的实践效果也进行研究。总体而言，AI支持的语言技术的设计和部署需要注意权力、不平等和文化差异。 |
| [^47] | [EriBERTa: A Bilingual Pre-Trained Language Model for Clinical Natural Language Processing.](http://arxiv.org/abs/2306.07373) | EriBERTa是一个针对临床领域预训练的双语语言模型，展示了在理解医学文本和提取有意义信息方面的强大能力，并具有从一种语言向另一种语言进行知识转移的迁移学习能力。 |
| [^48] | [A Comprehensive Survey on Applications of Transformers for Deep Learning Tasks.](http://arxiv.org/abs/2306.07303) | 本文综述了基于Transformer的深度学习任务应用，Transformer能够理解序列数据中的上下文关系且实现并行处理，在NLP、计算机视觉、语音处理、医疗保健和物联网等领域表现出色。 |
| [^49] | [Impact of Experiencing Misrecognition by Teachable Agents on Learning and Rapport.](http://arxiv.org/abs/2306.07302) | 音频识别错误对教学代理人学习和人际关系无显著影响，结果为教学代理人的最优错误恢复策略提供了一些启示。 |
| [^50] | [Medical Data Augmentation via ChatGPT: A Case Study on Medication Identification and Medication Event Classification.](http://arxiv.org/abs/2306.07297) | 本研究利用ChatGPT进行数据增广，显著提高了BERT模型在电子病历药物识别和药物事件分类任务中的表现。 |
| [^51] | [LTCR: Long-Text Chinese Rumor Detection Dataset.](http://arxiv.org/abs/2306.07201) | 该论文提出了LTCR数据集，用于准确检测虚假信息，特别是COVID-19相关的复杂虚假新闻。该数据集包含1,729个真实新闻和500个虚假新闻。基于LTCR数据集，提出了SFD（Salience-aware Fake News Detection Model）算法，具有最高的准确度，虚假新闻回收率和F1分数。 |
| [^52] | [Multimodal Audio-textual Architecture for Robust Spoken Language Understanding.](http://arxiv.org/abs/2306.06819) | 本文提出了一种使用多模态语言理解（MLU）模块的口语理解解决方案，结合了音频和文本模态的自我监督特征，并充分利用了预训练语言模型（BERT和RoBERTa），以减轻由ASR错误传播带来的性能下降。 |
| [^53] | [EaSyGuide : ESG Issue Identification Framework leveraging Abilities of Generative Large Language Models.](http://arxiv.org/abs/2306.06662) | 本文介绍了一种利用生成大语言模型能力的ESG问题识别框架，该框架在多语言环境下对MSCI ESG评级指南定义的35个ESG关键问题实现了卓越的识别成果，为ESG主题的探索做出了贡献。 |
| [^54] | [Multi-Task Training with In-Domain Language Models for Diagnostic Reasoning.](http://arxiv.org/abs/2306.04551) | 本文研究了领域内与领域外语言模型以及多任务与单任务训练的比较，并证明了通过临床训练的多任务语言模型在临床诊断推理任务中表现优异，建立了新的最优性能。 |
| [^55] | [PolyVoice: Language Models for Speech to Speech Translation.](http://arxiv.org/abs/2306.02982) | PolyVoice是一个语音到语音翻译系统框架，它包括两个语言模型并使用离散化的语音单元实现无监督学习，同时可用于非书面语言。实验结果表明，该系统可生成高质量的翻译和音频质量的语音。 |
| [^56] | [Gen-IR @ SIGIR 2023: The First Workshop on Generative Information Retrieval.](http://arxiv.org/abs/2306.02887) | 本研讨会旨在探讨生成式信息检索（IR）的新指标、理论基础、评估方法、任务定义、模型和用户界面等，以探究它是否是IR的范式转变。该研讨会关注先前探索过的技术，并提供一个地点用于探讨和探索如何将生成式IR应用于新领域。 |
| [^57] | [OWQ: Lessons learned from activation outliers for weight quantization in large language models.](http://arxiv.org/abs/2306.02272) | 在大语言模型的推理中，要使用多个服务器贵重的GPU导致显著的成本障碍，OWQ提出的一种后训练量化方法可以在最小质量损失的情况下减少这种限制。它可以通过考虑激活离群值来确定权值量化误差的因素，并为易受攻击的权重分配高精度，具有与OPTQ相当的质量。 |
| [^58] | [DyGen: Learning from Noisy Labels via Dynamics-Enhanced Generative Modeling.](http://arxiv.org/abs/2305.19395) | DyGen是一个动态增强的生成模型，使用嵌入空间中的动态模式可以改善从噪声标签中学习的精度，同时使用共规正则化机制来最小化潜在噪声标签和先验的影响，展示了最先进的性能。 |
| [^59] | [LM-CPPF: Paraphrasing-Guided Data Augmentation for Contrastive Prompt-Based Few-Shot Fine-Tuning.](http://arxiv.org/abs/2305.18169) | 本文提出了一种基于释义引导的数据增强用于对比型Prompt的少样本微调方法。该方法利用基础Prompt的少样本释义生成语言模型完成数据增强。 |
| [^60] | [PaCE: Unified Multi-modal Dialogue Pre-training with Progressive and Compositional Experts.](http://arxiv.org/abs/2305.14839) | 本文提出的PaCE是一个统一、结构化、组合式的多模态对话预训练框架，它利用了几个基本专家的组合，可以适应多个与对话相关的任务，并可以使用有限的对话和广泛的非对话多模态数据进行预训练。 |
| [^61] | [MultiModal-GPT: A Vision and Language Model for Dialogue with Humans.](http://arxiv.org/abs/2305.04790) | MultiModal-GPT是一个用于与人类进行多轮对话的视觉与语言模型，可以遵循人类的各种指令，并且通过联合训练表现得更好。 |
| [^62] | [FormNetV2: Multimodal Graph Contrastive Learning for Form Document Information Extraction.](http://arxiv.org/abs/2305.02549) | 该论文提出了一种用于表格文档信息提取的多模态图形对比学习策略（FormNetV2），该方法能够统一所有模态的自监督预训练到一个损失中，并在多个基准测试中取得了最佳表现。 |
| [^63] | [Energy-based Models as Zero-Shot Planners for Compositional Scene Rearrangement.](http://arxiv.org/abs/2304.14391) | 本文提出一种基于能量模型的零样本场景重新排列规划器，通过语言指导的空间概念来实现长指令以及在训练时从未见过的空间概念组合。本文的模型在指令导向操作基准测试以及组合指令基准测试中表现良好，优于基于语言表达的最先进方法，并且可以成功地解决之前从未见过的复杂指令和场景。 |
| [^64] | [Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark.](http://arxiv.org/abs/2304.03279) | 本文介绍了 MACHIAVELLI 基准测试，用于衡量人工智能代理是否表现出马基雅维利行为，发现了最大化奖励和行为的道德性之间存在权衡，并探索了基于语言模型的方法来减轻这种权衡。 |
| [^65] | [To Asymmetry and Beyond: Structured Pruning of Sequence to Sequence Models for Improved Inference Efficiency.](http://arxiv.org/abs/2304.02721) | 本论文研究了模型大小、结构化剪枝、推断效率和摘要准确性之间的关系，发现使用不对称剪枝可在不大损失模型准确性的情况下，提高推断效率约3倍。 |
| [^66] | [Understand Legal Documents with Contextualized Large Language Models.](http://arxiv.org/abs/2303.12135) | 本文介绍了针对 SemEval-2023 任务 6 开发的 Legal-BERT-HSLN 模型和 Legal-LUKE 模型，其中 Legal-BERT-HSLN 模型通过考虑句内和句间的上下文信息以预测修辞角色，Legal-LUKE 模型是具有法律上下文和实体知识的模型，以识别法律实体。模型相比基线模型更准确，能够解决在人口众多的国家处理法律文件的问题。 |
| [^67] | [eP-ALM: Efficient Perceptual Augmentation of Language Models.](http://arxiv.org/abs/2303.11403) | 本论文提出了一种用对比学习提高语言模型的感知能力的高效方法eP-ALM，可以实现视觉感知信息和文本信息的融合，同时还能在多模态基准测试上实现最先进的结果。 |
| [^68] | [xCodeEval: A Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and Retrieval.](http://arxiv.org/abs/2303.03004) | xCodeEval是一个大规模多语言多任务的基准，用于评估预训练的大型语言模型生成、修复、翻译和检索代码的能力，并解决了以往仅关注特定任务和缺乏训练数据的问题。 |
| [^69] | [Large Language Models Are Reasoning Teachers.](http://arxiv.org/abs/2212.10071) | 本文提出了Fine-tune-CoT，一种使用大型模型作为推理教师让较小模型也能进行复杂推理的方法，可以远远优于基于提示的基线方法，在多个任务上进行了评估。此外，该方法还利用教师模型的能力为每个原始样本生成多个不同的原因解释。 |
| [^70] | [LENS: A Learnable Evaluation Metric for Text Simplification.](http://arxiv.org/abs/2212.09739) | 本文提出了一种用于文本简化的可学习评估度量标准LENS，通过引入SimpeEval语料库作为人类评估数据集，与现有度量标准相比，LENS对人类判断相关性更好，为评估文本简化的未来进展铺平了道路。 |
| [^71] | [Complementary Explanations for Effective In-Context Learning.](http://arxiv.org/abs/2211.13892) | 本文研究了解释对于在上下文学习中的作用机制，证明了解释的分解和自然语言表达对于解释的有效性都有贡献；并且指出，不同的解释集可以提高LLMs的性能，因此提出了一种基于最大边际相关性的实例集合方法。 |
| [^72] | [Transformer-based Text Classification on Unified Bangla Multi-class Emotion Corpus.](http://arxiv.org/abs/2210.06405) | 该论文针对孟加拉语这一低资源语言，提出了基于Transformer的模型进行情感分类的方法。该模型在统一孟加拉多分类情感语料库（UBMEC）上的表现优于多个最先进的模型。 |
| [^73] | [HELP ME THINK: A Simple Prompting Strategy for Non-experts to Create Customized Content with Models.](http://arxiv.org/abs/2208.08232) | HELP ME THINK是一种帮助非专家用户创建定制化内容的简单提示策略，利用GPT3提出相关问题和利用用户答案执行任务，适用于各种需要重要思考的任务。 |
| [^74] | [Contextualized Semantic Distance between Highly Overlapped Texts.](http://arxiv.org/abs/2110.01176) | 本文旨在解决自然语言处理任务中，覆盖文本之间语义距离评估的传统挑战。通过掩码和预测策略，本文提出了邻近分布散度（NDD）来表示重叠部分的语义距离。实验结果表明，NDD对于各种语义差异更为敏感。 |
| [^75] | [A Trio Neural Model for Dynamic Entity Relatedness Ranking.](http://arxiv.org/abs/1808.08316) | 这篇论文提出了一种基于神经网络的方法，通过动态评估实体相关性，利用集体注意作为监督，能学习到丰富而不同的实体表示，能在大规模数据集上比竞争基线获得更好的结果。 |

# 详细

[^1]: arXiVeri：基于 GPT 的自动表格验证

    arXiVeri: Automatic table verification with GPT. (arXiv:2306.07968v1 [cs.CL])

    [http://arxiv.org/abs/2306.07968](http://arxiv.org/abs/2306.07968)

    本文提出了自动表格验证任务（AutoTV），提供了一个新的基准测试 arXiVeri 来验证其准确性，通过基于 GPT 的方法实现了自动表格验证，在表格匹配和单元格匹配任务中均达到了最先进的性能。

    

    没有对科学文献中数字数据的准确转录，科学家就不能得出准确结论。不幸的是，将数字数据从一篇论文复制到另一篇论文的过程容易出现人为错误。本文提出通过新颖的自动表格验证任务（AutoTV）来应对这一挑战，其目标是通过交叉引用引用的来源来验证表格中数字数据的准确性。为了支持该任务，我们提出了一个新的基准测试，arXiVeri，它包括从 arXiv 上的开放获取学术论文中提取的表格数据。我们引入了评估表格验证器在两个关键领域性能的指标：（i）表格匹配，旨在识别引用文献中的来源表格与目标表格对应的表格，和（ii）单元格匹配，旨在准确定位目标表格和来源表格之间的共享单元格，并识别它们的行和列索引。通过利用现代大型语言模型的灵活性能力，我们提出了一种基于 GPT 的 AutoTV 方法，并在 arXiVeri 基准测试上将其性能与几种基线算法进行了比较。实验结果表明，我们提出的方法在表格匹配和单元格匹配任务中均达到了最先进的性能。

    Without accurate transcription of numerical data in scientific documents, a scientist cannot draw accurate conclusions. Unfortunately, the process of copying numerical data from one paper to another is prone to human error. In this paper, we propose to meet this challenge through the novel task of automatic table verification (AutoTV), in which the objective is to verify the accuracy of numerical data in tables by cross-referencing cited sources. To support this task, we propose a new benchmark, arXiVeri, which comprises tabular data drawn from open-access academic papers on arXiv. We introduce metrics to evaluate the performance of a table verifier in two key areas: (i) table matching, which aims to identify the source table in a cited document that corresponds to a target table, and (ii) cell matching, which aims to locate shared cells between a target and source table and identify their row and column indices accurately. By leveraging the flexible capabilities of modern large langua
    
[^2]: MOFI: 从含噪实体标注的图像中学习图像表示

    MOFI: Learning Image Representations from Noisy Entity Annotated Images. (arXiv:2306.07952v1 [cs.CV])

    [http://arxiv.org/abs/2306.07952](http://arxiv.org/abs/2306.07952)

    MOFI 提出了一种新的方法，自动从含噪图像文本对中为图像指定实体标签，创建了一个新的大规模数据集 I2E，通过研究不同的训练配方，学习到了能够有效学习图像表示的模型。

    

    本文提出了一种新的视觉基础模型 MOFI，旨在从含噪实体标注的图像中学习图像表示。MOFI 与以往的工作有两点不同：（i）预训练数据，（ii）训练配方。在数据方面，我们引入了一种新方法，自动从含噪图像文本对中为图像指定实体标签。我们使用命名实体识别模型从 alt-text 中提取实体，然后使用 CLIP 模型选择正确的实体作为图像的标签。这种方法简单易行，不需要昂贵的人工注释，并且可以轻松扩展到从 web 上挖掘的数十亿个图像文本对。通过这种方法，我们创建了 Image-to-Entities（I2E）这一新的大规模数据集，其中包含 10 亿张图像和 200 万个不同的实体，涵盖了野外丰富的视觉概念。基于 I2E 数据集，我们研究了不同的训练配方，包括有监督的预训练、对比度预训练。

    We present MOFI, a new vision foundation model designed to learn image representations from noisy entity annotated images. MOFI differs from previous work in two key aspects: ($i$) pre-training data, and ($ii$) training recipe. Regarding data, we introduce a new approach to automatically assign entity labels to images from noisy image-text pairs. Our approach involves employing a named entity recognition model to extract entities from the alt-text, and then using a CLIP model to select the correct entities as labels of the paired image. The approach is simple, does not require costly human annotation, and can be readily scaled up to billions of image-text pairs mined from the web. Through this method, we have created Image-to-Entities (I2E), a new large-scale dataset with 1 billion images and 2 million distinct entities, covering rich visual concepts in the wild. Building upon the I2E dataset, we study different training recipes, including supervised pre-training, contrastive pre-train
    
[^3]: 对大型语言模型调查响应的质疑

    Questioning the Survey Responses of Large Language Models. (arXiv:2306.07951v1 [cs.CL])

    [http://arxiv.org/abs/2306.07951](http://arxiv.org/abs/2306.07951)

    本文使用美国人口普查局建立的全美社区调查（ACS）评估了十几个不同大小的语言模型，发现小型模型具有显著的位置和标签偏差，而模型大小的增加能减轻这种偏差，但无法根据US群体或任何可识别的群体趋势进行调整。

    

    随着大型语言模型的能力增强，研究人员开始以各种科学动机对这些模型进行调查。本文旨在通过美国人口普查局已经建立的全美社区调查（ACS），就模型的调查响应结果探究所能了解的内容。我们对十几个不同大小的模型进行了评估，这些模型的参数范围从几亿到一万亿不等，使用ACS的问题进行了数十万次的测试，系统地得出了两个主要模式。首先，小型模型存在明显的位置和标签偏差，例如偏向于采用标记为“A”的调查响应。随着模型尺寸的增加，A-偏差虽然有所减少，但也进展缓慢。其次，即使通过随机答案顺序来调整这种标记偏差，模型仍然不会趋向于美国人口统计数据或任何可识别的人口排序。相反，各种模型趋向于均匀随机化。

    As large language models increase in capability, researchers have started to conduct surveys of all kinds on these models with varying scientific motivations. In this work, we examine what we can learn from a model's survey responses on the basis of the well-established American Community Survey (ACS) by the U.S. Census Bureau. Evaluating more than a dozen different models, varying in size from a few hundred million to ten billion parameters, hundreds of thousands of times each on questions from the ACS, we systematically establish two dominant patterns. First, smaller models have a significant position and labeling bias, for example, towards survey responses labeled with the letter "A". This A-bias diminishes, albeit slowly, as model size increases. Second, when adjusting for this labeling bias through randomized answer ordering, models still do not trend toward US population statistics or those of any cognizable population. Rather, models across the board trend toward uniformly rando
    
[^4]: 使用Speech2Text适配器和Speech2Entity检索增强LLM的语音理解模型

    Speech-to-Text Adapter and Speech-to-Entity Retriever Augmented LLMs for Speech Understanding. (arXiv:2306.07944v1 [eess.AS])

    [http://arxiv.org/abs/2306.07944](http://arxiv.org/abs/2306.07944)

    本文提出了一种联合语音和语言模型（SLM），将声音映射到文本嵌入式空间，使用基于CTC的空白过滤器来缩短语音序列长度。在语音MultiWoz数据集中，SLM提高了对话状态跟踪（DST）性能。为了解决稀有实体的错误，我们采用Speech2Entity检索器增强SLM。使用此检索-augmented SLM（ReSLM），DST性能得到进一步提高。该研究表明，增强ASR任务可以提高其性能。

    

    大型语言模型（LLM）已应用于语音领域，但往往由于音频和语言表示不匹配而导致性能下降。为了弥补这一缺陷，本文提出了一种联合语音和语言模型（SLM），采用Speech2Text适配器将声音映射到文本嵌入式空间，避免声音信息丢失。此外，使用基于CTC的空白过滤器可以将语音序列长度缩短至文本长度。在DSTC11挑战赛的语音MultiWoz数据集中，SLM显着提高了对话状态跟踪（DST）性能（从24.7％提高到28.4％的准确率）。为了解决稀有实体的错误，我们采用Speech2Entity检索器增强SLM，该检索器使用语音检索相关实体，并将它们添加到原始SLM输入中作为前缀。使用这种检索-augmented SLM（ReSLM），DST的性能提高至34.6％的准确率。此外，以对话理解任务增强ASR任务可以将ASR性能从9.4％提高到8.5％的词错误率。

    Large Language Models (LLMs) have been applied in the speech domain, often incurring a performance drop due to misaligned between speech and language representations. To bridge this gap, we propose a joint speech and language model (SLM) using a Speech2Text adapter, which maps speech into text token embedding space without speech information loss. Additionally, using a CTC-based blank-filtering, we can reduce the speech sequence length to that of text. In speech MultiWoz dataset (DSTC11 challenge), SLM largely improves the dialog state tracking (DST) performance (24.7% to 28.4% accuracy). Further to address errors on rare entities, we augment SLM with a Speech2Entity retriever, which uses speech to retrieve relevant entities, and then adds them to the original SLM input as a prefix. With this retrieval-augmented SLM (ReSLM), the DST performance jumps to 34.6% accuracy. Moreover, augmenting the ASR task with the dialog understanding task improves the ASR performance from 9.4% to 8.5% WE
    
[^5]: FOOCTTS: 为足球解说员生成带有声音环境的阿拉伯语音

    FOOCTTS: Generating Arabic Speech with Acoustic Environment for Football Commentator. (arXiv:2306.07936v1 [eess.AS])

    [http://arxiv.org/abs/2306.07936](http://arxiv.org/abs/2306.07936)

    本论文介绍了 FOOCTTS，一种为足球解说员生成带有背景人群噪音的语音的自动流水线。该系统能够在有限的15分钟足球解说员录音内生成带有其声学环境的语音。

    

    本文介绍 FOOCTTS，一种为足球解说员生成带有背景人群噪音的语音的自动流水线。该应用程序从用户处获取文本，应用文本预处理（如加元音），接着使用解说员的语音合成器。我们的流水线包括用于数据标记的阿拉伯语自动语音识别，CTC分段，用于匹配语音的转录元音，以及微调TTS。我们的系统能够在有限的15分钟足球解说员录音内生成带有其声学环境的语音。我们的原型是通用的，可以轻松应用于不同的领域和语言。

    This paper presents FOOCTTS, an automatic pipeline for a football commentator that generates speech with background crowd noise. The application gets the text from the user, applies text pre-processing such as vowelization, followed by the commentator's speech synthesizer. Our pipeline included Arabic automatic speech recognition for data labeling, CTC segmentation, transcription vowelization to match speech, and fine-tuning the TTS. Our system is capable of generating speech with its acoustic environment within limited 15 minutes of football commentator recording. Our prototype is generalizable and can be easily applied to different domains and languages.
    
[^6]: 多模态表示学习用于社交媒体文章位置推断

    Multi-modal Representation Learning for Social Post Location Inference. (arXiv:2306.07935v1 [cs.CL])

    [http://arxiv.org/abs/2306.07935](http://arxiv.org/abs/2306.07935)

    本文提出了多模态表示学习框架（MRLF），用于将社交媒体文章的不同模态融合起来进行位置推断。该方法集成了一个多头注意力机制以增强位置显著信息提取，相对于单一领域的方法显著提高位置推断的准确性。

    

    通过社交媒体文章来推断地理位置对于许多实际的基于位置的应用程序非常重要，例如产品营销、兴趣点推荐及COVID-19的追踪。本研究从Instagram收集了带有图像、文本和标签的实际社交媒体文章数据集，提出了一种新颖的多模态表示学习框架（MRLF），它能够将社交媒体文章的不同模态融合起来进行位置推断。MRLF集成了一个多头注意力机制以增强位置显著信息提取，同时相对于单一领域的方法显著提高位置推断的准确性。为了克服用户生成的文本内容的噪声，我们引入了一种新颖的基于注意力的字符感知模块。

    Inferring geographic locations via social posts is essential for many practical location-based applications such as product marketing, point-of-interest recommendation, and infector tracking for COVID-19. Unlike image-based location retrieval or social-post text embedding-based location inference, the combined effect of multi-modal information (i.e., post images, text, and hashtags) for social post positioning receives less attention. In this work, we collect real datasets of social posts with images, texts, and hashtags from Instagram and propose a novel Multi-modal Representation Learning Framework (MRLF) capable of fusing different modalities of social posts for location inference. MRLF integrates a multi-head attention mechanism to enhance location-salient information extraction while significantly improving location inference compared with single domain-based methods. To overcome the noisy user-generated textual content, we introduce a novel attention-based character-aware module 
    
[^7]: BoardgameQA: 一种用于带有矛盾信息的自然语言推理数据集

    BoardgameQA: A Dataset for Natural Language Reasoning with Contradictory Information. (arXiv:2306.07934v1 [cs.CL])

    [http://arxiv.org/abs/2306.07934](http://arxiv.org/abs/2306.07934)

    本文提出了一个用于带有矛盾信息的自然语言推理的数据集，以解决推理中不一致和矛盾信息的问题，同时提供了一种可推翻推理策略。

    

    自然语言文本的自动推理是许多潜在NLP应用和开发强大AI系统的关键要求。本文针对存在不一致和矛盾信息的推理问题提出一种解决策略，将问题形式化为经典的可推翻推理问题，并开发了一种数据集。

    Automated reasoning with unstructured natural text is a key requirement for many potential applications of NLP and for developing robust AI systems. Recently, Language Models (LMs) have demonstrated complex reasoning capacities even without any finetuning. However, existing evaluation for automated reasoning assumes access to a consistent and coherent set of information over which models reason. When reasoning in the real-world, the available information is frequently inconsistent or contradictory, and therefore models need to be equipped with a strategy to resolve such conflicts when they arise. One widely-applicable way of resolving conflicts is to impose preferences over information sources (e.g., based on source credibility or information recency) and adopt the source with higher preference. In this paper, we formulate the problem of reasoning with contradictory information guided by preferences over sources as the classical problem of defeasible reasoning, and develop a dataset ca
    
[^8]: 通过大语言模型理解电信语言

    Understanding Telecom Language Through Large Language Models. (arXiv:2306.07933v1 [cs.CL])

    [http://arxiv.org/abs/2306.07933](http://arxiv.org/abs/2306.07933)

    文章提出通过fine-tune多个大型语言模型实现电信领域自动化操作，以便识别3GPP标准工作组。

    

    人工智能的最新进展为自动化电信网络的许多任务提供了新的可能性。由于出现了包括大型语言模型在内的生成式人工智能，这一进展进一步推动了这一可能性的实现，这被认为是实现自我治理和互动式人工智能代理的基石。本文旨在将LLMs的范例应用于电信领域，具体而言，我们将fine-tune几个LLMs，包括BERT、Distilled BERT、RoBERTa和GPT-2，以适应电信领域的语言，并演示用例来识别第三代合作伙伴项目（3GPP）标准工作组。

    The recent progress of artificial intelligence (AI) opens up new frontiers in the possibility of automating many tasks involved in Telecom networks design, implementation, and deployment. This has been further pushed forward with the evolution of generative artificial intelligence (AI), including the emergence of large language models (LLMs), which is believed to be the cornerstone toward realizing self-governed, interactive AI agents. Motivated by this, in this paper, we aim to adapt the paradigm of LLMs to the Telecom domain. In particular, we fine-tune several LLMs including BERT, distilled BERT, RoBERTa and GPT-2, to the Telecom domain languages, and demonstrate a use case for identifying the 3rd Generation Partnership Project (3GPP) standard working groups. We consider training the selected models on 3GPP technical documents (Tdoc) pertinent to years 2009-2019 and predict the Tdoc categories in years 2020-2023. The results demonstrate that fine-tuning BERT and RoBERTa model achiev
    
[^9]: 人在循环链中。

    Human-in-the-Loop through Chain-of-Thought. (arXiv:2306.07932v1 [cs.CL])

    [http://arxiv.org/abs/2306.07932](http://arxiv.org/abs/2306.07932)

    通过人在循环链中的方式，手动校正系统可以通过探究理性中子逻辑的手动校正来提高LLM的推理性能，并且基于经济理论的CAMLOP可以平衡效用和成本。

    

    尽管强大的语言模型和思维链提示的出现使自动化变得越来越无处不在，但有时在长期或多步逻辑推理方面显示出其弱点。例如，用户在没有人类参与的情况下不总能得到复杂数学问题的理想答案。在这个背景下，我们提出了手动校正系统（MCS）——一个通过思维链提示增强的人工参与系统，探究了理性中子逻辑的手动校正如何提高LLM的推理性能。更进一步考虑到有人参与的系统不仅要提高性能，还要控制成本。因此，我们提出了基于古典经济理论的人在循环链中成本效用分析模型（CAMLOP）来分析、量化和平衡效用和相应的成本。我们使用12个数据集对MCS和CAMLOP进行了实验。

    While the emergence of powerful language models along with Chain-of-thought prompting has made automation more and more omnipresent, it sometimes demonstrates its weakness in long-term or multi-step logical reasoning. For example, users don't always get desirable answers for complex mathematical problems without human involvement. Against this background, we present the Manual Correction System (MCS) -- a human-in-the-loop system enhanced by Chain-of-Thought prompting, which explores how manual correction of sub-logics in rationales can improve LLM's reasoning performance. Moving one step forward, considering a system with human-in-the-loop involves more than having humans improve performance but also controlling the cost. Therefore, we post a Cost-utility Analysis Model for Human-in-the-Loop systems (CAMLOP) based on classical economics theory to analyze, quantify and balance the utility and the corresponding cost. We conduct experiments of MCS and CAMLOP with twelve datasets. A signi
    
[^10]: 大型语言模型是半参数强化学习智能体

    Large Language Model Is Semi-Parametric Reinforcement Learning Agent. (arXiv:2306.07929v1 [cs.CL])

    [http://arxiv.org/abs/2306.07929](http://arxiv.org/abs/2306.07929)

    根据人类记忆和推理机制，提出了一种新的可演化LLM智能体框架REMEMBERER，通过为LLM装备长期经验记忆，可以为不同任务提供优异的智能体，其构成了半参数RL代理。成功率超过先前SOTA 4％和2％。

    

    受认知科学对人类记忆和推理机制的启发，提出了一种新的可演化LLM（大型语言模型）智能体框架REMEMBERER。通过为LLM装备长期经验记忆，REMEMBERER能够利用过去剧集的经验，甚至可以为不同的任务目标提供优异的LLM智能体，这优于具有固定实例或具有短暂工作记忆的LLM智能体。我们进一步介绍了经验记忆的强化学习（RLEM）来更新记忆。因此，整个系统可以从成功和失败的经验中学习，并在不微调LLM参数的情况下发展其能力。以此方式，所提出的REMEMBERER构成了半参数RL代理。在两个RL任务集上进行了大量实验以评估所提出的框架。不同初始化和训练集的平均结果对于成功率超过先前SOTA 4％和2％。

    Inspired by the insights in cognitive science with respect to human memory and reasoning mechanism, a novel evolvable LLM-based (Large Language Model) agent framework is proposed as REMEMBERER. By equipping the LLM with a long-term experience memory, REMEMBERER is capable of exploiting the experiences from the past episodes even for different task goals, which excels an LLM-based agent with fixed exemplars or equipped with a transient working memory. We further introduce Reinforcement Learning with Experience Memory (RLEM) to update the memory. Thus, the whole system can learn from the experiences of both success and failure, and evolve its capability without fine-tuning the parameters of the LLM. In this way, the proposed REMEMBERER constitutes a semi-parametric RL agent. Extensive experiments are conducted on two RL task sets to evaluate the proposed framework. The average results with different initialization and training sets exceed the prior SOTA by 4% and 2% for the success rate 
    
[^11]: 无监督语音识别的一种理论

    A Theory of Unsupervised Speech Recognition. (arXiv:2306.07926v1 [eess.AS])

    [http://arxiv.org/abs/2306.07926](http://arxiv.org/abs/2306.07926)

    本文提出了一个通用的理论框架，以研究无监督语音识别系统的属性，证明了各种可学习性条件和样本复杂性边界，并在合成语言的实验中得到了强有力的实证证据。

    

    无监督语音识别问题指的是从未配对的含有语音和文本的语料库中学习自动语音识别（ASR）系统。虽然存在各种算法来解决这个问题，但缺乏一个理论框架来研究其属性，并解决如超参数敏感性和训练不稳定性等问题。本文提出了一种通用的理论框架，以随机矩阵理论和神经切向核理论为基础，研究ASR-U系统的属性。这样的框架使我们能够证明ASR-U的各种可学习性条件和样本复杂性边界。针对有三类转移图的合成语言的广泛ASR-U实验为我们的理论提供了强有力的实证证据（代码可在cactuswiththoughts / UnsupASRTheory.git中获得）。

    Unsupervised speech recognition (ASR-U) is the problem of learning automatic speech recognition (ASR) systems from unpaired speech-only and text-only corpora. While various algorithms exist to solve this problem, a theoretical framework is missing from studying their properties and addressing such issues as sensitivity to hyperparameters and training instability. In this paper, we proposed a general theoretical framework to study the properties of ASR-U systems based on random matrix theory and the theory of neural tangent kernels. Such a framework allows us to prove various learnability conditions and sample complexity bounds of ASR-U. Extensive ASR-U experiments on synthetic languages with three classes of transition graphs provide strong empirical evidence for our theory (code available at cactuswiththoughts/UnsupASRTheory.git).
    
[^12]: WebGLM: 基于人类偏好的高效网络增强问答系统

    WebGLM: Towards An Efficient Web-Enhanced Question Answering System with Human Preferences. (arXiv:2306.07906v1 [cs.CL])

    [http://arxiv.org/abs/2306.07906](http://arxiv.org/abs/2306.07906)

    本文提出的WebGLM是一种基于GLM的网络问答系统，使用LLM-augmented检索器、引导式生成器和人类偏好感知评分器等策略提高了准确性、效率和成本效益，并在人类评估中表现出比WebGPT更好的性能。

    

    我们提出了WebGLM，一种基于通用语言模型（GLM）的网络增强问答系统。其目标是在保持适用于实际应用的同时，利用网络搜索和检索能力增强预训练的大语言模型（LLM）。为了实现这一目标，我们通过LLM增强的检索器、引导式生成器和人类偏好感知评分器等策略开发了WebGLM。具体而言，我们识别并解决了WebGPT（OpenAI）的局限性，从而为WebGLM提供了准确性、效率和成本效益的优势。此外，我们提出了评估网络增强QA系统的系统性标准。我们进行了多维人类评估和定量削弱研究，结果表明所提出的WebGLM设计优于现有系统。与WebGPT（13B）相比，使用100亿参数的GLM（10B）的WebGLM在人类评估中表现更好，甚至可与WebGPT（175B）相媲美。

    We present WebGLM, a web-enhanced question-answering system based on the General Language Model (GLM). Its goal is to augment a pre-trained large language model (LLM) with web search and retrieval capabilities while being efficient for real-world deployments. To achieve this, we develop WebGLM with strategies for the LLM-augmented retriever, bootstrapped generator, and human preference-aware scorer. Specifically, we identify and address the limitations of WebGPT (OpenAI), through which WebGLM is enabled with accuracy, efficiency, and cost-effectiveness advantages. In addition, we propose systematic criteria for evaluating web-enhanced QA systems. We conduct multi-dimensional human evaluation and quantitative ablation studies, which suggest the outperformance of the proposed WebGLM designs over existing systems. WebGLM with the 10-billion-parameter GLM (10B) is shown to perform better than the similar-sized WebGPT (13B) and even comparably to WebGPT (175B) in human evaluation. The code,
    
[^13]: 大规模多语言情感数据集和多方面情感分类基准的语料库。

    Massively Multilingual Corpus of Sentiment Datasets and Multi-faceted Sentiment Classification Benchmark. (arXiv:2306.07902v1 [cs.CL])

    [http://arxiv.org/abs/2306.07902](http://arxiv.org/abs/2306.07902)

    本研究介绍了一种可以用于训练情感模型的最全面的开放式大规模多语言数据集，该数据集由79个手动选定的数据集组成，覆盖了27种语言，代表了6种语言家族。而且，我们还提供了一个多方面的情感分类基准。

    

    尽管多语言语料库和模型训练取得了令人瞩目的进展，但开发大规模的多语言模型仍然是一个重大挑战。这在文化相关的语言任务中尤其如此。多语言情感分析就是一个例子，其中情感标记可能非常微妙且深深植根于文化中。本文介绍了可用于训练情感模型的最全面的开放式大规模多语言数据集的语料库。该语料库由79个手动选择的数据集组成，它们是基于严格的质量标准从科学文献中报告的超过350个数据集中选出的。该语料库涵盖了27种语言，代表了6种语言家族。数据集可以使用几个语言和功能特征进行查询。此外，我们提供了一个多方面的情感分类基准，总结了对不同的基本模型、训练目标、数据集集合和微调进行的数百个实验。

    Despite impressive advancements in multilingual corpora collection and model training, developing large-scale deployments of multilingual models still presents a significant challenge. This is particularly true for language tasks that are culture-dependent. One such example is the area of multilingual sentiment analysis, where affective markers can be subtle and deeply ensconced in culture. This work presents the most extensive open massively multilingual corpus of datasets for training sentiment models. The corpus consists of 79 manually selected datasets from over 350 datasets reported in the scientific literature based on strict quality criteria. The corpus covers 27 languages representing 6 language families. Datasets can be queried using several linguistic and functional features. In addition, we present a multi-faceted sentiment classification benchmark summarizing hundreds of experiments conducted on different base models, training objectives, dataset collections, and fine-tunin
    
[^14]: 人工人工智能：众包工人广泛使用大型语言模型进行文本生成任务

    Artificial Artificial Artificial Intelligence: Crowd Workers Widely Use Large Language Models for Text Production Tasks. (arXiv:2306.07899v1 [cs.CL])

    [http://arxiv.org/abs/2306.07899](http://arxiv.org/abs/2306.07899)

    该研究调查了众包工人使用大型语言模型的普遍性，结果发现33-46%的众包工人在完成任务时使用了LLMs，我们需要更加警惕这类问题。

    

    大型语言模型（LLMs）是非常出色的数据标注工具，它们可以用于生成高保真度的监督式训练数据，以及调查和实验数据。随着LLMs的广泛采用，人类黄金标准注释对于理解LLMs的能力和其结果的有效性至关重要。然而，众包是获取人类注释的一种重要、廉价的方式，但众包工人有通过使用LLMs来增加其生产率和收入的财务激励，这可能会影响他们的注释。为了调查这个问题，我们对众包工人使用LLMs的普遍性进行了案例研究。我们在Amazon Mechanical Turk上重新运行了一项文摘任务，并通过击键检测和合成文本分类的组合，估计33-46%的众包工人在完成任务时使用了LLMs。尽管对于其他不太友好的LLM任务的泛化尚不清楚，我们的结果呼吁平台、研究人员和从事标注的人们更加警惕LLM相关的问题。

    Large language models (LLMs) are remarkable data annotators. They can be used to generate high-fidelity supervised training data, as well as survey and experimental data. With the widespread adoption of LLMs, human gold--standard annotations are key to understanding the capabilities of LLMs and the validity of their results. However, crowdsourcing, an important, inexpensive way to obtain human annotations, may itself be impacted by LLMs, as crowd workers have financial incentives to use LLMs to increase their productivity and income. To investigate this concern, we conducted a case study on the prevalence of LLM usage by crowd workers. We reran an abstract summarization task from the literature on Amazon Mechanical Turk and, through a combination of keystroke detection and synthetic text classification, estimate that 33-46% of crowd workers used LLMs when completing the task. Although generalization to other, less LLM-friendly tasks is unclear, our results call for platforms, researche
    
[^15]: ReadProbe: 一种支持横向阅读的检索增强大语言模型演示

    ReadProbe: A Demo of Retrieval-Enhanced Large Language Models to Support Lateral Reading. (arXiv:2306.07875v1 [cs.IR])

    [http://arxiv.org/abs/2306.07875](http://arxiv.org/abs/2306.07875)

    ReadProbe 是一种利用大型语言模型和搜索引擎支持横向阅读的工具，它能够生成有用问题和答案以帮助用户评估在线信息。

    

    随着网络不实信息的快速增长和传播，人们需要工具来帮助他们评估在线信息的可信度和准确性。横向阅读是一种跨参考多个信息源的策略，可能是实现这一目标的有效方法。在本文中，我们提出了一个工具，名为 ReadProbe，它支持横向阅读，由 OpenAI 的生成式大语言模型和必应搜索引擎驱动。我们的工具能够为横向阅读生成有用的问题，搜寻网络上相关的文档，并产生良好归因的答案，帮助人们更好地评估在线信息。我们制作了一个基于 Web 的应用程序，演示了 ReadProbe 如何帮助减少被虚假信息误导的风险。我们的代码可在 https://github.com/DakeZhang1998/ReadProbe 上获得，我们的早期版本赢得了全国人工智能虚假信息黑客马拉松的一等奖。

    With the rapid growth and spread of online misinformation, people need tools to help them evaluate the credibility and accuracy of online information. Lateral reading, a strategy that involves cross-referencing information with multiple sources, may be an effective approach to achieving this goal. In this paper, we present ReadProbe, a tool to support lateral reading, powered by generative large language models from OpenAI and the Bing search engine. Our tool is able to generate useful questions for lateral reading, scour the web for relevant documents, and generate well-attributed answers to help people better evaluate online information. We made a web-based application to demonstrate how ReadProbe can help reduce the risk of being misled by false information. The code is available at https://github.com/DakeZhang1998/ReadProbe. An earlier version of our tool won the first prize in a national AI misinformation hackathon.
    
[^16]: GEmo-CLAP: 面向语音情感识别的性别属性增强对比语音-语言预训练模型

    GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio Pretraining for Speech Emotion Recognition. (arXiv:2306.07848v1 [cs.CL])

    [http://arxiv.org/abs/2306.07848](http://arxiv.org/abs/2306.07848)

    本文提出了GEmo-CLAP模型用于语音情感识别，结合了性别属性信息，相比于其他先进方法，该模型在IEMOCAP上实现了更优越的识别性能。

    

    对比语音-语言预训练（CLAP）最近在不同领域取得了惊人的成功。本文提出了一种名为GEmo-CLAP的高效性别属性增强CLAP模型，用于语音情感识别（SER）。具体而言，我们首先利用各种自监督学习的预训练模型构建了一种有效的情感CLAP模型（称为Emo-CLAP），用于SER。然后，考虑到在语音情感建模中性别属性的重要性，我们进一步提出了两种GEmo-CLAP方法，来整合语音信号的情感和性别信息，形成更合理的目标。在IEMOCAP语料库上进行的大量实验表明，我们提出的两种GEmo-CLAP方法始终优于基线Emo-CLAP模型（使用不同的预训练模型），同时与其他最先进的方法相比实现了更优越的识别性能。

    Contrastive Language-Audio Pretraining (CLAP) has recently exhibited impressive success in diverse fields. In this paper, we propose GEmo-CLAP, a kind of efficient gender-attribute-enhanced CLAP model for speech emotion recognition (SER). Specifically, we first build an effective emotion CLAP model termed Emo-CLAP for SER, utilizing various self-supervised learning based pre-trained models. Then, considering the importance of the gender attribute in speech emotion modeling, two GEmo-CLAP approaches are further proposed to integrate the emotion and gender information of speech signals, forming more reasonable objectives. Extensive experiments conducted on the IEMOCAP corpus demonstrate that our proposed two GEmo-CLAP approaches consistently outperform the baseline Emo-CLAP with different pre-trained models, while also achieving superior recognition performance compared with other state-of-the-art methods.
    
[^17]: 对抗胶囊网络用于罗马尼亚讽刺检测和情感分析

    Adversarial Capsule Networks for Romanian Satire Detection and Sentiment Analysis. (arXiv:2306.07845v1 [cs.CL])

    [http://arxiv.org/abs/2306.07845](http://arxiv.org/abs/2306.07845)

    本文提出了一种对抗胶囊网络用于罗马尼亚讽刺检测和情感分析的方法，通过基于字符级对抗性过程生成人工样本提高了模型的鲁棒性并优于现有方法，实现了高达99.08％的准确性。

    

    讽刺检测与情感分析是研究从文本中识别讽刺语气和提取与其目标相关情感的自然语言处理（NLP）任务。在本文中，我们使用对抗训练和胶囊网络改进了广为人知的NLP模型，并应用于罗马尼亚语的讽刺检测和情感分析任务中，通过基于字符级对抗性过程生成人工样本提高了模型的鲁棒性并优于现有方法，实现了高达99.08％的准确性。

    Satire detection and sentiment analysis are intensively explored natural language processing (NLP) tasks that study the identification of the satirical tone from texts and extracting sentiments in relationship with their targets. In languages with fewer research resources, an alternative is to produce artificial examples based on character-level adversarial processes to overcome dataset size limitations. Such samples are proven to act as a regularization method, thus improving the robustness of models. In this work, we improve the well-known NLP models (i.e., Convolutional Neural Networks, Long Short-Term Memory (LSTM), Bidirectional LSTM, Gated Recurrent Units (GRUs), and Bidirectional GRUs) with adversarial training and capsule networks. The fine-tuned models are used for satire detection and sentiment analysis tasks in the Romanian language. The proposed framework outperforms the existing methods for the two tasks, achieving up to 99.08% accuracy, thus confirming the improvements ad
    
[^18]: ChatGPT与人工撰写文本：可控文本摘要和句子风格转移的洞察

    ChatGPT vs Human-authored Text: Insights into Controllable Text Summarization and Sentence Style Transfer. (arXiv:2306.07799v1 [cs.CL])

    [http://arxiv.org/abs/2306.07799](http://arxiv.org/abs/2306.07799)

    本文旨在系统地检查ChatGPT在两个可控生成任务中的表现，即ChatGPT能否适应不同的目标受众和写作风格。研究发现，人类产生的文体变化比ChatGPT表现出的更大，而生成的文本在一些特征上与人类样本有所不同，有时会包含事实错误或幻觉。

    

    大规模语言模型（如ChatGPT）以其出色的能力从简短的自然语言提示生成连贯的文本引起了媒体的重视。本文旨在系统地检查ChatGPT在两个可控生成任务中的表现，即ChatGPT能否适应不同的目标受众（专家与一般人）和写作风格（正式与非正式）。此外，我们评估了生成文本的忠实度，并将模型的表现与人工撰写的文本进行了比较。我们的研究发现，人类产生的文体变化比ChatGPT表现出的更大，而生成的文本在诸如单词类型分布等几个特征上与人类样本有所不同。此外，我们发现当 ChatGPT 将文本适应特定风格时，有时会包含事实错误或幻觉。

    Large-scale language models, like ChatGPT, have garnered significant media attention and stunned the public with their remarkable capacity for generating coherent text from short natural language prompts. In this paper, we aim to conduct a systematic inspection of ChatGPT's performance in two controllable generation tasks, with respect to ChatGPT's ability to adapt its output to different target audiences (expert vs. layman) and writing styles (formal vs. informal). Additionally, we evaluate the faithfulness of the generated text, and compare the model's performance with human-authored texts. Our findings indicate that the stylistic variations produced by humans are considerably larger than those demonstrated by ChatGPT, and the generated texts diverge from human samples in several characteristics, such as the distribution of word types. Moreover, we observe that ChatGPT sometimes incorporates factual errors or hallucinations when adapting the text to suit a specific style.
    
[^19]: NoCoLA：挪威语言接受性语料库

    NoCoLA: The Norwegian Corpus of Linguistic Acceptability. (arXiv:2306.07790v1 [cs.CL])

    [http://arxiv.org/abs/2306.07790](http://arxiv.org/abs/2306.07790)

    本论文提出了两个新的挪威语数据集，分别用于二元分类和纯诊断任务，旨在评估语言模型的语法理解能力。它们适用于不同类型的语言模型，并用于对现有挪威语言模型进行比较研究。

    

    近年来，大量的挪威语言模型出现，但我们缺乏评估其语法理解能力的工具。我们提出了两个新的挪威数据集来完成这项任务。其中NoCoLA_class是一个带监督的二元分类任务，旨在区分可接受和不可接受的句子；而NoCoLA_zero则是一个完全无需进行额外训练即可在零样本方式下评估语言模型语法判断的纯诊断任务。本文详细描述了这两个数据集，展示了如何用它们来为不同类型的语言模型进行比较，并对现有的挪威语言模型进行了比较研究。

    While there has been a surge of large language models for Norwegian in recent years, we lack any tool to evaluate their understanding of grammaticality. We present two new Norwegian datasets for this task. NoCoLA_class is a supervised binary classification task where the goal is to discriminate between acceptable and non-acceptable sentences. On the other hand, NoCoLA_zero is a purely diagnostic task for evaluating the grammatical judgement of a language model in a completely zero-shot manner, i.e. without any further training. In this paper, we describe both datasets in detail, show how to use them for different flavors of language models, and conduct a comparative study of the existing Norwegian language models.
    
[^20]: 一种基于云的机器学习管道，有效从客户评论中提取见解

    A Cloud-based Machine Learning Pipeline for the Efficient Extraction of Insights from Customer Reviews. (arXiv:2306.07786v1 [cs.CL])

    [http://arxiv.org/abs/2306.07786](http://arxiv.org/abs/2306.07786)

    本文介绍了一种基于云的系统，利用机器学习方法从客户评论中提取见解。本研究提出的组合模型使用了转换器神经网络、向量嵌入和聚类，已经集成并进一步发展，以更好地满足高效信息提取、提取信息的主题建模和用户需求的要求。研究结果表明，本系统可以比现有的主题建模和关键字提取解决方案获得更好的效果。

    

    随着机器学习模型的出现，特别是基于神经网络的解决方案，自然语言处理的效率有了显著提高。然而，一些任务仍然具有挑战性，特别是考虑到特定的应用领域。本文提出了一种基于云的系统，可以使用机器学习方法集成到管道中，从客户评论中提取见解。对于主题建模，我们的组合模型使用了基于转换器的自然语言处理神经网络、基于向量嵌入的关键字提取和聚类。我们的模型元素已经集成并进一步发展，以更好地满足高效信息提取、提取信息的主题建模和用户需求的要求。此外，我们的系统可以比这个任务现有的主题建模和关键字提取解决方案获得更好的结果。我们的方法在公开可用的客户评论数据集上得到验证并与其他最先进的方法进行比较。

    The efficiency of natural language processing has improved dramatically with the advent of machine learning models, particularly neural network-based solutions. However, some tasks are still challenging, especially when considering specific domains. In this paper, we present a cloud-based system that can extract insights from customer reviews using machine learning methods integrated into a pipeline. For topic modeling, our composite model uses transformer-based neural networks designed for natural language processing, vector embedding-based keyword extraction, and clustering. The elements of our model have been integrated and further developed to meet better the requirements of efficient information extraction, topic modeling of the extracted information, and user needs. Furthermore, our system can achieve better results than this task's existing topic modeling and keyword extraction solutions. Our approach is validated and compared with other state-of-the-art methods using publicly a
    
[^21]: 因式分解子词编码的分词方法

    Tokenization with Factorized Subword Encoding. (arXiv:2306.07764v1 [cs.CL])

    [http://arxiv.org/abs/2306.07764](http://arxiv.org/abs/2306.07764)

    本文提出了一种因式分解子词编码的分词方法，被称为“因式分解器”，在七种不同语言的语言建模和形态句法任务中进行评估，相较于常用的BPE算法具有更好的适应性和鲁棒性。

    

    近年来，语言模型变得越来越大、越来越复杂，然而这些模型的输入表示仍然依赖于简单和贪婪的子词分词方法。本文提出了一种新颖的分词方法，该方法使用VQ-VAE模型将子词因子化为离散三元组。所提出的分词方法被称为“因式分解器”，并在七种不同语言的语言建模和形态句法任务中进行了评估。结果表明，该方法比常用的字节对编码(BPE)分词算法更适合和更稳健于形态句法任务。

    In recent years, language models have become increasingly larger and more complex. However, the input representations for these models continue to rely on simple and greedy subword tokenization methods. In this paper, we propose a novel tokenization method that factorizes subwords onto discrete triplets using a VQ-VAE model. The effectiveness of the proposed tokenization method, referred to as the Factorizer, is evaluated on language modeling and morpho-syntactic tasks for 7 diverse languages. Results indicate that this method is more appropriate and robust for morphological tasks than the commonly used byte-pair encoding (BPE) tokenization algorithm.
    
[^22]: NAVER LABS Europe的多语言语音翻译系统在IWSLT 2023低资源赛道中的应用

    NAVER LABS Europe's Multilingual Speech Translation Systems for the IWSLT 2023 Low-Resource Track. (arXiv:2306.07763v1 [cs.CL])

    [http://arxiv.org/abs/2306.07763](http://arxiv.org/abs/2306.07763)

    本文介绍了NAVER LABS Europe使用预训练模型和多语言参数效率解决方案在低资源环境下最大化翻译质量的方法，并在IWSLT 2023低资源赛道中Tamasheq-French和Quechua-Spanish语音翻译上取得了出色的结果。

    

    本文介绍了NAVER LABS Europe在IWSLT 2023低资源赛道中Tamasheq-French和Quechua-Spanish语音翻译的系统。我们的工作旨在利用强大的预训练模型和多语言参数效率解决方案，在低资源环境中实现最大化的翻译质量。我们的Tamasheq主要提交版本在IWSLT 2022测试集上优于先前的最优结果7.5 BLEU分数，并在今年的测试集上达到23.6 BLEU，超过第二名参赛者7.7分。对于Quechua，尽管只有两小时的翻译数据，我们还是排名第一，并达到17.7 BLEU。最后，我们展示了我们提出的多语言架构在高资源语言方面也很有竞争力，在使用更少的训练数据和计算资源的情况下，优于IWSLT 2021多语言赛道最佳未加限制的提交结果。

    This paper presents NAVER LABS Europe's systems for Tamasheq-French and Quechua-Spanish speech translation in the IWSLT 2023 Low-Resource track. Our work attempts to maximize translation quality in low-resource settings using multilingual parameter-efficient solutions that leverage strong pre-trained models. Our primary submission for Tamasheq outperforms the previous state of the art by 7.5 BLEU points on the IWSLT 2022 test set, and achieves 23.6 BLEU on this year's test set, outperforming the second best participant by 7.7 points. For Quechua, we also rank first and achieve 17.7 BLEU, despite having only two hours of translation data. Finally, we show that our proposed multilingual architecture is also competitive for high-resource languages, outperforming the best unconstrained submission to the IWSLT 2021 Multilingual track, despite using much less training data and compute.
    
[^23]: StyleTTS 2：通过风格扩散和与大型语音语言模型的对抗训练实现人类级别的语音合成

    StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion and Adversarial Training with Large Speech Language Models. (arXiv:2306.07691v1 [eess.AS])

    [http://arxiv.org/abs/2306.07691](http://arxiv.org/abs/2306.07691)

    本文提出了一种名为StyleTTS 2的TTS模型，通过对抗训练和大型语音语言模型来实现人类级别的语音合成。与以往模型不同，StyleTTS 2将样式视为潜在随机变量，利用扩散模型来生成最适合文本的样式，同时受益于大型SLMs和新的可微分持续时间建模。

    

    本文提出了StyleTTS2，一种文本到语音（TTS）模型，该模型利用风格扩散和与大型语音语言模型（SLM）的对抗性训练来实现人类级别的TTS合成。 StyleTTS 2通过将样式建模为潜在的随机变量通过扩散模型来生成最适合文本的样式，无需参考语音，实现高效的潜在扩散，同时受益于扩散模型提供的多样化语音合成。此外，我们使用大型预先训练的SLMs（例如WavLM）作为鉴别器，并使用我们的新型可微分持续时间建模进行端到端的训练，从而提高了语音的自然度。 StyleTTS 2在单扬声器LJSpeech数据集上超越了人类录音，并在多扬声器VCTK数据集上与之匹配，经过母语为英语的人员评判。此外，当在LibriTTS数据集上进行训练时，我们的模型胜过了以前公开可用的零样本说话人语音合成模型。

    In this paper, we present StyleTTS 2, a text-to-speech (TTS) model that leverages style diffusion and adversarial training with large speech language models (SLMs) to achieve human-level TTS synthesis. StyleTTS 2 differs from its predecessor by modeling styles as a latent random variable through diffusion models to generate the most suitable style for the text without requiring reference speech, achieving efficient latent diffusion while benefiting from the diverse speech synthesis offered by diffusion models. Furthermore, we employ large pre-trained SLMs, such as WavLM, as discriminators with our novel differentiable duration modeling for end-to-end training, resulting in improved speech naturalness. StyleTTS 2 surpasses human recordings on the single-speaker LJSpeech dataset and matches it on the multispeaker VCTK dataset as judged by native English speakers. Moreover, when trained on the LibriTTS dataset, our model outperforms previous publicly available models for zero-shot speaker
    
[^24]: 重新思考文本数据增强的有效性：一个经验分析

    Rethink the Effectiveness of Text Data Augmentation: An Empirical Analysis. (arXiv:2306.07664v1 [cs.CL])

    [http://arxiv.org/abs/2306.07664](http://arxiv.org/abs/2306.07664)

    本研究发现数据增强技术在语言模型的预训练及微调中仍具有显著的提升作用，尤其在少样本学习的情况下，持续的预训练可以提高微调性能10%以上。

    

    最近几年，语言模型在推进自然语言处理领域方面取得了显著进展。然而，数据增强技术对这些语言模型微调表现的影响一直是一个争论的话题。在本研究中，我们评估了三种不同的微调方法结合回译在7个不同的自然语言处理任务中的有效性，包括分类和回归类型，涵盖单句和句子对任务。与优先的假设相反，即数据增强对提高语言模型的微调表现没有贡献，我们的发现表明，持续在增强数据上进行预训练可以有效地改善下游任务的微调表现。在最有利的情况下，持续的预训练可以使微调性能在小样本学习设置下提高10%以上。我们的发现突显出数据增强作为增强语言模型性能的强大工具的潜力。

    In recent years, language models (LMs) have made remarkable progress in advancing the field of natural language processing (NLP). However, the impact of data augmentation (DA) techniques on the fine-tuning (FT) performance of these LMs has been a topic of ongoing debate. In this study, we evaluate the effectiveness of three different FT methods in conjugation with back-translation across an array of 7 diverse NLP tasks, including classification and regression types, covering single-sentence and sentence-pair tasks. Contrary to prior assumptions that DA does not contribute to the enhancement of LMs' FT performance, our findings reveal that continued pre-training on augmented data can effectively improve the FT performance of the downstream tasks. In the most favourable case, continued pre-training improves the performance of FT by more than 10% in the few-shot learning setting. Our finding highlights the potential of DA as a powerful tool for bolstering LMs' performance.
    
[^25]: Transformers的各向异性是否固有？

    Is Anisotropy Inherent to Transformers?. (arXiv:2306.07656v1 [cs.CL])

    [http://arxiv.org/abs/2306.07656](http://arxiv.org/abs/2306.07656)

    本文证明各向异性不仅是优化长尾分布令牌的交叉熵损失结果，还可能是Transformers-based模型固有的。

    

    表征退化问题是基于Transformers的自监督学习方法中普遍观察到的现象。在自然语言处理中，它采用各向异性的形式，这是一种隐藏表示的奇异属性，使它们在角度距离（余弦相似性）方面意外地靠近彼此。一些最近的工作表明，各向异性是优化长尾分布令牌的交叉熵损失的结果。本文证明，即使对于不应直接受到相同后果的具有特定目标的语言模型，各向异性也可以在其上观察到。我们还证明了各向异性问题也会延伸到训练其他模态的Transformers 。我们的观察结果表明，各向异性实际上可能是Transformers-based模型固有的。

    The representation degeneration problem is a phenomenon that is widely observed among self-supervised learning methods based on Transformers. In NLP, it takes the form of anisotropy, a singular property of hidden representations which makes them unexpectedly close to each other in terms of angular distance (cosine-similarity). Some recent works tend to show that anisotropy is a consequence of optimizing the cross-entropy loss on long-tailed distributions of tokens. We show in this paper that anisotropy can also be observed empirically in language models with specific objectives that should not suffer directly from the same consequences. We also show that the anisotropy problem extends to Transformers trained on other modalities. Our observations tend to demonstrate that anisotropy might actually be inherent to Transformers-based models.
    
[^26]: 模态适应还是规范化？一项端到端语音翻译案例研究

    Modality Adaption or Regularization? A Case Study on End-to-End Speech Translation. (arXiv:2306.07650v1 [cs.CL])

    [http://arxiv.org/abs/2306.07650](http://arxiv.org/abs/2306.07650)

    该文讨论了解决端到端语音翻译中的数据匮乏问题的预训练和微调方法，并发现规范化方法比精心设计的模态适应方法更重要，能够优化E2E ST的性能。

    

    预训练和微调是缓解端到端语音翻译(E2E ST)中数据匮乏问题的一种范例。但是，常见的语音和文本数据之间的“模态差距”通常导致预训练和微调之间的不一致输入。然而，我们观察到这种差距发生在微调的早期阶段，但对最终性能没有重大影响。另一方面，我们发现存在另一个差距，我们称之为“能力差距”：高资源任务（如ASR和MT）总是需要一个大型模型来拟合，当模型被重用于低资源任务（E2E ST）时，由于过度拟合会导致次优性能。在一项案例研究中，我们发现规范化方法比精心设计的模态适应方法发挥更重要的作用，该方法在MuST-C数据集上实现了29.0 en-de和40.3 en-fr的效果。代码和模型可在https://github.com/hannlp/TAB上找到。

    Pre-training and fine-tuning is a paradigm for alleviating the data scarcity problem in end-to-end speech translation (E2E ST). The commonplace "modality gap" between speech and text data often leads to inconsistent inputs between pre-training and fine-tuning. However, we observe that this gap occurs in the early stages of fine-tuning, but does not have a major impact on the final performance. On the other hand, we find that there has another gap, which we call the "capacity gap": high resource tasks (such as ASR and MT) always require a large model to fit, when the model is reused for a low resource task (E2E ST), it will get a sub-optimal performance due to the over-fitting. In a case study, we find that the regularization plays a more important role than the well-designed modality adaption method, which achieves 29.0 for en-de and 40.3 for en-fr on the MuST-C dataset. Code and models are available at https://github.com/hannlp/TAB.
    
[^27]: HuSpaCy中的混合词形还原

    Hybrid lemmatization in HuSpaCy. (arXiv:2306.07636v1 [cs.CL])

    [http://arxiv.org/abs/2306.07636](http://arxiv.org/abs/2306.07636)

    本文介绍了一种混合架构的词形还原器，利用了神经模型、词典和手工制作的规则，在形态丰富的匈牙利语数据集上产生了良好的实证结果。

    

    对于形态丰富的语言，词形还原仍然不是一项轻松的任务。先前的研究表明，混合架构通常对这些语言效果更好，可以产生出色的结果。本文介绍了一种混合词形还原器，利用了神经模型、词典和手工制作的规则。我们提出了一种混合架构，并在广泛使用的匈牙利数据集上给出了实证结果。所述方法已经发布为三个HuSpaCy模型。

    Lemmatization is still not a trivial task for morphologically rich languages. Previous studies showed that hybrid architectures usually work better for these languages and can yield great results. This paper presents a hybrid lemmatizer utilizing both a neural model, dictionaries and hand-crafted rules. We introduce a hybrid architecture along with empirical results on a widely used Hungarian dataset. The presented methods are published as three HuSpaCy models.
    
[^28]: SqueezeLLM：密集稀疏量化

    SqueezeLLM: Dense-and-Sparse Quantization. (arXiv:2306.07629v1 [cs.CL])

    [http://arxiv.org/abs/2306.07629](http://arxiv.org/abs/2306.07629)

    本文提出了一种基于训练后的量化框架——SqueezeLLM，它不仅可以实现高达3位的无损压缩，而且在相同的内存约束下实现更高的量化性能。

    

    生成式大型语言模型(LLMs)已经证明在广泛领域的任务中取得了非凡的成果。但是由于其前所未有的资源需求，将这些模型用于推理一直是一个巨大的挑战。这导致现有的部署框架需要使用多GPU推理管道，这通常是复杂和昂贵的，或者使用更小且性能更低的模型。在这项工作中，我们证明了用于LLMs生成推断的主要瓶颈是内存带宽，而不是计算，尤其是单个批次推理。虽然通过使用减少精度来表示模型权重，量化已经成为一种有前途的解决方案，但是以前的努力通常导致性能下降。为了解决这个问题，我们引入SqueezeLLM，这是一种基于训练后的量化框架，不仅可以实现高达3位的无损压缩，而且在相同的内存约束下实现更高的量化性能。

    Generative Large Language Models (LLMs) have demonstrated remarkable results for a wide range of tasks. However, deploying these models for inference has been a significant challenge due to their unprecedented resource requirements. This has forced existing deployment frameworks to use multi-GPU inference pipelines, which are often complex and costly, or to use smaller and less performant models. In this work, we demonstrate that the main bottleneck for generative inference with LLMs is memory bandwidth, rather than compute, specifically for single batch inference. While quantization has emerged as a promising solution by representing model weights with reduced precision, previous efforts have often resulted in notable performance degradation. To address this, we introduce SqueezeLLM, a post-training quantization framework that not only enables lossless compression to ultra-low precisions of up to 3-bit, but also achieves higher quantization performance under the same memory constraint
    
[^29]: 语言模型中出现的类人直觉行为和推理偏差——以及在GPT-4中消失。

    Human-Like Intuitive Behavior and Reasoning Biases Emerged in Language Models -- and Disappeared in GPT-4. (arXiv:2306.07622v1 [cs.CL])

    [http://arxiv.org/abs/2306.07622](http://arxiv.org/abs/2306.07622)

    本研究揭示了大型语言模型（LLMs）具有类人直觉行为和认知错误的特点，而高级语言模型则通过学习避免这类错误并表现出超理性的方式。此外，通过使用心理学研究的方法探测LLMs，可以揭示其新生特性。

    

    大型语言模型（LLM）目前处于将AI系统与人类交流和日常生活交织在一起的前沿。因此，评估它们的新兴能力非常重要。在这项研究中，我们展示了LLM（尤其是GPT-3）表现出惊人的类人直觉行为，以及遵循这种行为而来的认知错误。然而，具有更高认知能力的LLM，特别是ChatGPT和GPT-4，学会了避免屈服于这些错误并表现出超理性的方式。对于我们的实验，我们利用了Cognitive Reflection Test（CRT）及用于研究人类直觉决策的语义幻觉。此外，我们还探究了类人直觉决策的稳定倾向。我们的研究表明，通过心理学方法调查LLM有潜力揭示否则未知的新生特性。

    Large language models (LLMs) are currently at the forefront of intertwining AI systems with human communication and everyday life. Therefore, it is of great importance to evaluate their emerging abilities. In this study, we show that LLMs, most notably GPT-3, exhibit behavior that strikingly resembles human-like intuition -- and the cognitive errors that come with it. However, LLMs with higher cognitive capabilities, in particular ChatGPT and GPT-4, learned to avoid succumbing to these errors and perform in a hyperrational manner. For our experiments, we probe LLMs with the Cognitive Reflection Test (CRT) as well as semantic illusions that were originally designed to investigate intuitive decision-making in humans. Moreover, we probe how sturdy the inclination for intuitive-like decision-making is. Our study demonstrates that investigating LLMs with methods from psychology has the potential to reveal otherwise unknown emergent traits.
    
[^30]: 面向半监督文本分类的排名感知负样本训练

    Rank-Aware Negative Training for Semi-Supervised Text Classification. (arXiv:2306.07621v1 [cs.CL])

    [http://arxiv.org/abs/2306.07621](http://arxiv.org/abs/2306.07621)

    本文提出了一种Rank-aware Negative Training（RNT）框架，通过基于不确定性的推理方法排名未标注文本并利用负样本训练解决了在半监督文本分类中存在噪声标签的问题。

    

    半监督文本分类常常使用自我训练的方法，对有限标注数据进行训练并迭代地对未标注文本进行伪标签预测以供进一步训练。本文提出了一种排名感知负样本训练框架（RNT）以解决学习中存在噪声标签的半监督文本分类问题。为了减轻噪声信息，我们采用基于不确定性的推理方法来排名未标注文本，以其从标注文本中获得的证据支持为依据。此外，我们提出了负样本训练的方法来训练RNT，其中“输入实例不属于对应标签”是RNT的基本概念。直观地，一个真实标签作为补充标签的概率越小，对应的负样本的训练难度就越大。

    Semi-supervised text classification-based paradigms (SSTC) typically employ the spirit of self-training. The key idea is to train a deep classifier on limited labeled texts and then iteratively predict the unlabeled texts as their pseudo-labels for further training. However, the performance is largely affected by the accuracy of pseudo-labels, which may not be significant in real-world scenarios. This paper presents a Rank-aware Negative Training (RNT) framework to address SSTC in learning with noisy label manner. To alleviate the noisy information, we adapt a reasoning with uncertainty-based approach to rank the unlabeled texts based on the evidential support received from the labeled texts. Moreover, we propose the use of negative training to train RNT based on the concept that ``the input instance does not belong to the complementary label''. A complementary label is randomly selected from all labels except the label on-target. Intuitively, the probability of a true label serving as
    
[^31]: 基于问题分解树的知识库问答

    Question Decomposition Tree for Answering Complex Questions over Knowledge Bases. (arXiv:2306.07597v1 [cs.CL])

    [http://arxiv.org/abs/2306.07597](http://arxiv.org/abs/2306.07597)

    本文提出了一种问题分解树(QDT)来表示复杂问题的结构，该方法通过一个称为Clue-Decipher的两阶段方法来生成QDT，可以提高知识库问答(KBQA)任务的性能。

    

    知识库问答(KBQA)近年来引起了广泛关注，特别是针对需要多个事实才能回答的复杂问题。问题分解是回答复杂问题的一种有前途的方法。现有的分解方法将问题分解为子问题，但仅按单一的组合性类型分解不足以解决涉及多种组合性类型的问题。在本文中，我们提出了问题分解树(QDT)来表示复杂问题的结构。受自然语言生成(NLG)近期进展的启发，我们提出了一种称为Clue-Decipher的两阶段方法来生成QDT。它可以利用NLG模型的强大能力，同时保留原始问题。为了验证QDT能够提高KBQA任务的性能，我们设计了一个基于分解的KBQA系统QDTQA。大量实验表明，QDTQA在ComplexWebQuestions数据集上的性能优于之前最先进的方法。

    Knowledge base question answering (KBQA) has attracted a lot of interest in recent years, especially for complex questions which require multiple facts to answer. Question decomposition is a promising way to answer complex questions. Existing decomposition methods split the question into sub-questions according to a single compositionality type, which is not sufficient for questions involving multiple compositionality types. In this paper, we propose Question Decomposition Tree (QDT) to represent the structure of complex questions. Inspired by recent advances in natural language generation (NLG), we present a two-staged method called Clue-Decipher to generate QDT. It can leverage the strong ability of NLG model and simultaneously preserve the original questions. To verify that QDT can enhance KBQA task, we design a decomposition-based KBQA system called QDTQA. Extensive experiments show that QDTQA outperforms previous state-of-the-art methods on ComplexWebQuestions dataset. Besides, ou
    
[^32]: 大型语言模型有时生成纯负反馈文本

    Large Language Models Sometimes Generate Purely Negatively-Reinforced Text. (arXiv:2306.07567v1 [cs.LG])

    [http://arxiv.org/abs/2306.07567](http://arxiv.org/abs/2306.07567)

    大型语言模型有时会从仅包含负奖励的例子中学习，导致生成类似泄漏密码或安全漏洞等敏感信息的文本

    

    在使用对抗性训练时，通常会训练反对最严重失败的案例。然而，这可能会意味着使用包含敏感信息（例如泄露的密码或安全漏洞）的案例作为训练数据。我们可能会认为使用梯度下降算法训练的语言模型永远不会生成仅在与最低奖励相关联的示例中出现的文本片段。本文表明这种假设是错误的：在某些情况下，大型语言模型确实从这种纯负反馈的示例中学习到了东西。我们提出了一种特定的训练设置，使得Pythia-160M能够生成密码的概率略高于随机，尽管仅在对模型不输出这些密码的示例中展示了这些密码。我们的代码可在https://github.com/FabienRoger/Learning-From-Negative-Examples上找到。

    When using adversarial training, it is common practice to train against the most egregious failures. However, this might imply using examples with sensitive information (such as leaked passwords or security vulnerabilities) as training data. One might assume that language models trained with gradient descent never generate text snippets which were only present in examples associated with the lowest possible reward. In this paper, we show that this assumption is wrong: in some situations, large language models do learn from such negatively-reinforced examples. We present a specific training setup that enables Pythia-160M to generate passwords with a probability slightly greater than chance, despite only showing it these passwords on examples where the model is incentivized to not output these passwords. Our code is available at https://github.com/FabienRoger/Learning-From-Negative-Examples
    
[^33]: HAUSER：面向隐喻生成的整体和自动评估方法。

    HAUSER: Towards Holistic and Automatic Evaluation of Simile Generation. (arXiv:2306.07554v1 [cs.CL])

    [http://arxiv.org/abs/2306.07554](http://arxiv.org/abs/2306.07554)

    HAUSER是一个面向隐喻生成任务的评估系统，利用三个视角的五个标准和自动指标进行全面、高效和可靠的评估。

    

    隐喻在创意写作（如故事和对话生成）中起着至关重要的作用。正确的评估指标就像引导隐喻生成研究的灯塔。然而，目前仍未深入探讨应考虑哪些标准，如何将每个标准量化为指标，以及这些指标是否能够对隐喻生成进行全面、高效和可靠的评估。为了解决这些问题，我们建立了HAUSER，这是一个面向隐喻生成任务的整体和自动评估系统，它由三个视角的五个标准和每个标准的自动指标组成。通过大量实验，我们验证了我们的指标与每个视角的人工评分显著相关，比现有的自动指标更好。

    Similes play an imperative role in creative writing such as story and dialogue generation. Proper evaluation metrics are like a beacon guiding the research of simile generation (SG). However, it remains under-explored as to what criteria should be considered, how to quantify each criterion into metrics, and whether the metrics are effective for comprehensive, efficient, and reliable SG evaluation. To address the issues, we establish HAUSER, a holistic and automatic evaluation system for the SG task, which consists of five criteria from three perspectives and automatic metrics for each criterion. Through extensive experiments, we verify that our metrics are significantly more correlated with human ratings from each perspective compared with prior automatic metrics.
    
[^34]: TART: 一种面向任务无关推理的即插即用Transformer模块

    TART: A plug-and-play Transformer module for task-agnostic reasoning. (arXiv:2306.07536v1 [cs.LG])

    [http://arxiv.org/abs/2306.07536](http://arxiv.org/abs/2306.07536)

    TART提出了一种即插即用的Transformer模块，它能够在没有任务特定训练或微调的情况下，在不同推理目标之间进行泛化。

    

    大型语言模型(LLMs)表现出上下文学习能力,能让同一模型执行多个任务,而无需进行任何特定任务的训练。相比之下,传统的自适应方法(如微调)会针对每个特定任务修改基础模型。然而,即使在使用相同示例的情况下,上下文学习一直表现不佳,而大多数现有方法(如提示工程)侧重于LLM的学习表示，以弥补性能差距,而我们的分析实际上揭示了LLM表示包含足够的信息来做出好的预测。因此,我们关注LLM的推理能力,并展示该性能差距存在是由于它们无法执行简单的概率推理任务。这引发了一个有趣的问题: LLM实际上能否以任务无关的方式学习如何推理？我们肯定地回答了这个问题,并提出了TART，它以即插即用的方式在不进行任务特定训练或微调的情况下横跨不同推理目标进行泛化。

    Large language models (LLMs) exhibit in-context learning abilities which enable the same model to perform several tasks without any task-specific training. In contrast, traditional adaptation approaches, such as fine-tuning, modify the underlying models for each specific task. In-context learning, however, consistently underperforms task-specific tuning approaches even when presented with the same examples. While most existing approaches (e.g., prompt engineering) focus on the LLM's learned representations to patch this performance gap, our analysis actually reveal that LLM representations contain sufficient information to make good predictions. As such, we focus on the LLM's reasoning abilities and demonstrate that this performance gap exists due to their inability to perform simple probabilistic reasoning tasks. This raises an intriguing question: Are LLMs actually capable of learning how to reason in a task-agnostic manner? We answer this in the affirmative and propose TART which ge
    
[^35]: 自训练实现嘈杂正-无标记学习，在思辨性知识图谱推理中应用

    Noisy Positive-Unlabeled Learning with Self-Training for Speculative Knowledge Graph Reasoning. (arXiv:2306.07512v1 [cs.LG])

    [http://arxiv.org/abs/2306.07512](http://arxiv.org/abs/2306.07512)

    本文提出了一种嘈杂正-无标记学习问题的变分框架nPUGraph，并引入自训练策略，以应对真实世界知识图谱上的思辨性推理任务。实验结果表明了我们提出的方法的有效性。

    

    本文主要研究真实世界知识图谱（KG）上的思辨性推理任务，其中包括了假负问题（即潜在的真实事实被排除）和假正问题（即不可靠或过时的事实被包括）。现有的方法在思辨性推理能力上表现不佳，因为它们假设一个事实是否正确仅由它在KG中的存在确定，这使得它们容易受到假阴性/假阳性问题的影响。新的推理任务被规定为一种嘈杂正-无标记学习问题。我们提出了一种变分框架nPUGraph，它共同估计已收集和未收集事实的正确性（我们称之为“标签后验概率”），并在训练期间更新模型参数。标签后验概率估计从两个方面促进了思辨性推理。首先，它提高了标签后验概率感知的图表征对抗假阳性关系的鲁棒性。其次，它确定了误导性的未标记数据，并减少了其对模型训练的影响。我们还介绍了一种利用未标记数据的自训练策略，进一步提高了模型的推理能力。在两个知识图推理任务基准测试上的实验结果证明了我们提出的方法的有效性。

    This paper studies speculative reasoning task on real-world knowledge graphs (KG) that contain both \textit{false negative issue} (i.e., potential true facts being excluded) and \textit{false positive issue} (i.e., unreliable or outdated facts being included). State-of-the-art methods fall short in the speculative reasoning ability, as they assume the correctness of a fact is solely determined by its presence in KG, making them vulnerable to false negative/positive issues. The new reasoning task is formulated as a noisy Positive-Unlabeled learning problem. We propose a variational framework, namely nPUGraph, that jointly estimates the correctness of both collected and uncollected facts (which we call \textit{label posterior}) and updates model parameters during training. The label posterior estimation facilitates speculative reasoning from two perspectives. First, it improves the robustness of a label posterior-aware graph encoder against false positive links. Second, it identifies mis
    
[^36]: 在先进聊天机器人中添加护栏

    Adding guardrails to advanced chatbots. (arXiv:2306.07500v1 [cs.CY])

    [http://arxiv.org/abs/2306.07500](http://arxiv.org/abs/2306.07500)

    研究探讨了 ChatGPT 不同用例对于公平回答问题的能力，并发现它对于测试任务而言是公平的搜索引擎，但在文本生成和代码生成上有偏见，并且对于变化非常敏感。

    

    生成式 AI 模型不断变得更加强大。2022 年 11 月 ChatGPT 的推出迎来了 AI 的新时代。ChatGPT 和其他类似的聊天机器人具有一系列的能力，从回答学生家庭作业问题到创造音乐和艺术。已经有人担心 chatbot 可能会取代人类进行各种工作。由于聊天机器人构建在广泛的数据体系上，我们知道它们会带有人类错误和偏见。这些偏见可能对不同人群造成重大伤害和/或不公平。为了了解聊天机器人响应的优势和局限性，我们提出了一篇位论文，探讨了 ChatGPT 的不同用例，以确定公平回答的问题类型和仍然需要改进的类型。我们发现 ChatGPT 对于我们测试的任务而言是一个公平的搜索引擎；然而，在文本生成和代码生成上它存在偏见。我们发现 ChatGPT 对于变化非常敏感。

    Generative AI models continue to become more powerful. The launch of ChatGPT in November 2022 has ushered in a new era of AI. ChatGPT and other similar chatbots have a range of capabilities, from answering student homework questions to creating music and art. There are already concerns that humans may be replaced by chatbots for a variety of jobs. Because of the wide spectrum of data chatbots are built on, we know that they will have human errors and human biases built into them. These biases may cause significant harm and/or inequity toward different subpopulations. To understand the strengths and weakness of chatbot responses, we present a position paper that explores different use cases of ChatGPT to determine the types of questions that are answered fairly and the types that still need improvement. We find that ChatGPT is a fair search engine for the tasks we tested; however, it has biases on both text generation and code generation. We find that ChatGPT is very sensitive to change
    
[^37]: 通过标签错误检测和重写提高基于意见的问答系统

    Improving Opinion-based Question Answering Systems Through Label Error Detection and Overwrite. (arXiv:2306.07499v1 [cs.CL])

    [http://arxiv.org/abs/2306.07499](http://arxiv.org/abs/2306.07499)

    本文提出了一种名为LEDO的模型-不可知且计算高效的框架，能够有效解决标签错误问题，并将其应用于意见问答系统中，提高了该系统在各个核心模型中的准确性。

    

    标签错误是注释数据中普遍存在的问题。大量的标签错误会严重降低深度学习模型的质量。现有的解决标签错误问题的方法主要集中在分类任务上，要么依赖于任务特定的架构，要么需要非常复杂的额外计算，这些都不适合工业使用。在本文中，我们提出了LEDO：一种面向模型的、计算效率高的标签错误检测和重写框架。LEDO基于 Monte Carlo Dropout 和不确定性度量，可以很容易地推广到多个任务和数据集。将LEDO应用于工业意见问答系统中，证明它能有效提高所有核心模型的准确性。具体而言，LEDO为检索模型带来1.1％的MRR增益，为机器阅读理解模型提高1.5％的PR AUC，为排名器的平均精度提高0.9％。

    Label error is a ubiquitous problem in annotated data. Large amounts of label error substantially degrades the quality of deep learning models. Existing methods to tackle the label error problem largely focus on the classification task, and either rely on task specific architecture or require non-trivial additional computations, which is undesirable or even unattainable for industry usage. In this paper, we propose LEDO: a model-agnostic and computationally efficient framework for Label Error Detection and Overwrite. LEDO is based on Monte Carlo Dropout combined with uncertainty metrics, and can be easily generalized to multiple tasks and data sets. Applying LEDO to an industry opinion-based question answering system demonstrates it is effective at improving accuracy in all the core models. Specifically, LEDO brings 1.1% MRR gain for the retrieval model, 1.5% PR AUC improvement for the machine reading comprehension model, and 0.9% rise in the Average Precision for the ranker, on top of
    
[^38]: 《用于编制BEIR的资源：可重复参考模型和官方排行榜》

    Resources for Brewing BEIR: Reproducible Reference Models and an Official Leaderboard. (arXiv:2306.07471v1 [cs.IR])

    [http://arxiv.org/abs/2306.07471](http://arxiv.org/abs/2306.07471)

    提供了BEIR基准数据集的可重复参考实现和官方排行榜以跟踪模型性能和进展。

    

    BEIR是一个跨越18个不同领域/任务组合进行零样本评估的基准数据集，用于信息检索模型。我们目睹了利用预先训练的transformers在监督学习框架下建立检索模型的表示学习方法的日益普及。但这自然会引出一个问题：这些模型在遇到与训练数据不同的查询和文档时有多有效？我们的工作解决了BEIR在实现其全部潜力方面存在的两个缺陷。第一，现代神经方法的复杂性和当前的软件基础设施创建了对新手的进入门槛。为此，我们提供了覆盖两个主要检索模型类的可重复参考实现。第二，虽然BEIR提供了多样化的测试套件，但没有官方排名榜可跟踪模型性能和进展。为解决这个问题，我们为参与者提供了一个官方BEIR排行榜，可提交结果并与最先进的模型进行比较。

    BEIR is a benchmark dataset for zero-shot evaluation of information retrieval models across 18 different domain/task combinations. In recent years, we have witnessed the growing popularity of a representation learning approach to building retrieval models, typically using pretrained transformers in a supervised setting. This naturally begs the question: How effective are these models when presented with queries and documents that differ from the training data? Examples include searching in different domains (e.g., medical or legal text) and with different types of queries (e.g., keywords vs. well-formed questions). While BEIR was designed to answer these questions, our work addresses two shortcomings that prevent the benchmark from achieving its full potential: First, the sophistication of modern neural methods and the complexity of current software infrastructure create barriers to entry for newcomers. To this end, we provide reproducible reference implementations that cover the two m
    
[^39]: Izindaba-Tindzaba：面向isiZulu和Siswati的长短文本机器学习新闻分类

    Izindaba-Tindzaba: Machine learning news categorisation for Long and Short Text for isiZulu and Siswati. (arXiv:2306.07426v1 [cs.CL])

    [http://arxiv.org/abs/2306.07426](http://arxiv.org/abs/2306.07426)

    本研究为南非本土isiZulu和Siswati语言构建了新闻主题分类数据集，并采用扩增、过采样等方法增加数据量。基于Word2vec模型的XGBoost、逻辑回归和LSTM分类器表现优于其他模型。

    

    本文针对南非少数民族本土语言进行了研究与实验，通过新闻主题分类任务构建并标注了isiZulu和Siswati本地语言的新闻数据集，并提出了基于这些分类模型的研究结果。鉴于这些本土南非语言数据的缺乏，我们对数据集进行了扩增和过采样以增加数据量，并解决类别分类不平衡问题。本文共使用了四种不同的分类模型，包括逻辑回归，朴素贝叶斯，XGBoost和LSTM。这些模型是基于三种不同的词嵌入方式进行训练的，包括词袋模型，TFIDF和Word2vec。研究结果显示，基于Word2vec模型的XGBoost，逻辑回归和LSTM性能优于其他模型的组合。

    Local/Native South African languages are classified as low-resource languages. As such, it is essential to build the resources for these languages so that they can benefit from advances in the field of natural language processing. In this work, the focus was to create annotated news datasets for the isiZulu and Siswati native languages based on news topic classification tasks and present the findings from these baseline classification models. Due to the shortage of data for these native South African languages, the datasets that were created were augmented and oversampled to increase data size and overcome class classification imbalance. In total, four different classification models were used namely Logistic regression, Naive bayes, XGBoost and LSTM. These models were trained on three different word embeddings namely Bag-Of-Words, TFIDF and Word2vec. The results of this study showed that XGBoost, Logistic Regression and LSTM, trained from Word2vec performed better than the other combi
    
[^40]: 通过加强实现的方式实现性别包容的语法错误更正

    Gender-Inclusive Grammatical Error Correction through Augmentation. (arXiv:2306.07415v1 [cs.CL])

    [http://arxiv.org/abs/2306.07415](http://arxiv.org/abs/2306.07415)

    本研究发现GEC系统在使用男性和女性术语以及性别中立的单数“they”的时候显示出性别偏见。研究人员通过开发平行数据集，并基于语言学洞见进行数据增强，为减少GEC系统中的偏见做出了贡献。

    

    本文研究发现，GEC系统在使用男性和女性术语以及性别中立的单数“they”的时候显示出性别偏见。我们开发了包含男性和女性术语以及单数“they”的文本的平行数据集，并使用它们来量化三个竞争的GEC系统中的性别偏见。针对性别中立的单数“they”，我们提出了一种基于语言学洞见的新的数据增强技术。我们证明，这种数据增强技术以及类似的针对男性和女性术语的增强技术的改进，可以生成训练数据，从而减少GEC系统的偏见，特别是在单数“they”的情况下，同时保持相同水平的质量。

    In this paper we show that GEC systems display gender bias related to the use of masculine and feminine terms and the gender-neutral singular "they". We develop parallel datasets of texts with masculine and feminine terms and singular "they" and use them to quantify gender bias in three competitive GEC systems. We contribute a novel data augmentation technique for singular "they" leveraging linguistic insights about its distribution relative to plural "they". We demonstrate that both this data augmentation technique and a refinement of a similar augmentation technique for masculine and feminine terms can generate training data that reduces bias in GEC systems, especially with respect to singular "they" while maintaining the same level of quality.
    
[^41]: 文本扩充技术应用于低资源机器翻译：以斯瓦希里语为例

    Textual Augmentation Techniques Applied to Low Resource Machine Translation: Case of Swahili. (arXiv:2306.07414v1 [cs.CL])

    [http://arxiv.org/abs/2306.07414](http://arxiv.org/abs/2306.07414)

    本文研究了将文本数据扩充任务应用于低资源机器翻译的效果，尝试了三种简单的数据扩充技术，并将其与英斯瓦希里数据集的基线神经机器翻译性能进行了比较。

    

    在这项工作中，我们研究了将文本数据扩充任务应用于低资源机器翻译的影响。近年来，人们开始关注如何为资源有限的语种训练机器翻译系统，其中一种流行的方法是使用数据扩充技术。数据扩充旨在增加可用于训练系统的数据量。在机器翻译中，全球大多数语言对被认为是低资源语种，因为它们可用的平行数据很少，而神经机器翻译（NMT）系统的质量很大程度上取决于可用的庞大平行语料库。我们研究并应用了三种简单的数据扩充技术，这些技术在文本分类任务中广泛使用：同义词替换、随机插入和上下文数据扩增，并将它们与英斯瓦希里（En-Sw）数据集的基线神经机器翻译性能进行比较。我们还使用BLEU、ChrF和....

    In this work we investigate the impact of applying textual data augmentation tasks to low resource machine translation. There has been recent interest in investigating approaches for training systems for languages with limited resources and one popular approach is the use of data augmentation techniques. Data augmentation aims to increase the quantity of data that is available to train the system. In machine translation, majority of the language pairs around the world are considered low resource because they have little parallel data available and the quality of neural machine translation (NMT) systems depend a lot on the availability of sizable parallel corpora. We study and apply three simple data augmentation techniques popularly used in text classification tasks; synonym replacement, random insertion and contextual data augmentation and compare their performance with baseline neural machine translation for English-Swahili (En-Sw) datasets. We also present results in BLEU, ChrF and 
    
[^42]: 用熵规则增强推荐系统中的主题提取

    Enhancing Topic Extraction in Recommender Systems with Entropy Regularization. (arXiv:2306.07403v1 [cs.CL])

    [http://arxiv.org/abs/2306.07403](http://arxiv.org/abs/2306.07403)

    本论文介绍一种新的方法，称为熵规则，以提高推荐系统中主题提取的可解释性。实验证实该方法可在保持主任务性能竞争力的同时，在主题连贯性方面有显著提高。

    

    最近，许多推荐系统利用文本数据进行主题提取以提高可解释性。然而，我们的研究发现主题内关键词的连贯性显著不足，导致模型的可解释性较低。本文引入了一种新的方法，称为熵规则，以解决这个问题，从而从推荐系统中提取更加可解释的主题，同时确保主任务的性能保持竞争力。该策略的有效性通过在利用文本数据提取项目嵌入的概率矩阵分解模型的变体上进行实验证实。实验结果表明，在使用词嵌入的余弦相似度量化的主题连贯性方面有显著提高。

    In recent years, many recommender systems have utilized textual data for topic extraction to enhance interpretability. However, our findings reveal a noticeable deficiency in the coherence of keywords within topics, resulting in low explainability of the model. This paper introduces a novel approach called entropy regularization to address the issue, leading to more interpretable topics extracted from recommender systems, while ensuring that the performance of the primary task stays competitively strong. The effectiveness of the strategy is validated through experiments on a variation of the probabilistic matrix factorization model that utilizes textual data to extract item embeddings. The experiment results show a significant improvement in topic coherence, which is quantified by cosine similarity on word embeddings.
    
[^43]: 大型语言模型的经济权衡：以案例研究为例

    The economic trade-offs of large language models: A case study. (arXiv:2306.07402v1 [cs.CL])

    [http://arxiv.org/abs/2306.07402](http://arxiv.org/abs/2306.07402)

    本研究通过一个案例研究，以评估大型语言模型在企业中为类似客户服务的场景所带来的成本和效益。从该品牌客户服务代理的反馈中比较了三种专门化LLM的策略-提示工程、微调和知识蒸馏，发现模型响应的可用性可以弥补成本差异。

    

    通过聊天联系客户服务是一种常见做法。由于雇用客服代理商是昂贵的，许多公司正在转向NLP，通过自动生成可直接使用或修改的响应来协助人类代理商。大型语言模型（LLMs）是这种情况的自然选择；然而，它们的功效必须与训练和服务成本相平衡。本文评估了LLMs在企业中作为响应生成工具可实现的实际成本和影响。我们提出了一个成本框架，用于评估NLP模型在这种情况下的效用，并将其应用于单个品牌作为现有代理协助产品背景下的案例研究。我们使用品牌客户服务代理的反馈比较了三种专门化LLM的策略-提示工程、微调和知识蒸馏。我们发现，模型响应的可用性可以弥补巨大的成本差异。

    Contacting customer service via chat is a common practice. Because employing customer service agents is expensive, many companies are turning to NLP that assists human agents by auto-generating responses that can be used directly or with modifications. Large Language Models (LLMs) are a natural fit for this use case; however, their efficacy must be balanced with the cost of training and serving them. This paper assesses the practical cost and impact of LLMs for the enterprise as a function of the usefulness of the responses that they generate. We present a cost framework for evaluating an NLP model's utility for this use case and apply it to a single brand as a case study in the context of an existing agent assistance product. We compare three strategies for specializing an LLM - prompt engineering, fine-tuning, and knowledge distillation - using feedback from the brand's customer service agents. We find that the usability of a model's responses can make up for a large difference in in
    
[^44]: 实现BERT和微调RobertA来检测ChatGPT生成的人工智能新闻

    Implementing BERT and fine-tuned RobertA to detect AI generated news by ChatGPT. (arXiv:2306.07401v1 [cs.CL])

    [http://arxiv.org/abs/2306.07401](http://arxiv.org/abs/2306.07401)

    使用BERT和微调的RobertA模型可以最好地检测ChatGPT生成的AI新闻。 RobertA模型在精度方面表现出色，取得了98％的得分。这些模型可以在打击假新闻中发挥关键作用。

    

    社交媒体上信息的丰富增加了准确实时谣言检测的必要性。手动识别和验证AI工具生成的假新闻在巨大的信息量每天被生成的情况下是不切实际和耗时的。这引发了对创建自动化系统以找到互联网上假新闻的兴趣增加。本研究表明，经微调的BERT和RobertA模型在检测AI生成的新闻方面取得了最佳成功率。特别是微调过的RobertA在精度方面表现出色，得分为98％。总之，本研究表明，可以使用神经网络来识别ChatGPT生成的伪造新闻。RobertA和BERT模型的出色表现表明这些模型在与假信息作斗争中可以发挥关键作用。

    The abundance of information on social media has increased the necessity of accurate real-time rumour detection. Manual techniques of identifying and verifying fake news generated by AI tools are impracticable and time-consuming given the enormous volume of information generated every day. This has sparked an increase in interest in creating automated systems to find fake news on the Internet. The studies in this research demonstrate that the BERT and RobertA models with fine-tuning had the best success in detecting AI generated news. With a score of 98%, tweaked RobertA in particular showed excellent precision. In conclusion, this study has shown that neural networks can be used to identify bogus news AI generation news created by ChatGPT. The RobertA and BERT models' excellent performance indicates that these models can play a critical role in the fight against misinformation.
    
[^45]: 大型语言模型对量化理解的探究

    Probing Quantifier Comprehension in Large Language Models. (arXiv:2306.07384v1 [cs.CL])

    [http://arxiv.org/abs/2306.07384](http://arxiv.org/abs/2306.07384)

    本文提出了对于大型语言模型（LLMs）对量化理解的探究，并质疑之前研究中关于LLMs理解极少数类型的量词能力呈现反比例缩放的说法，并提出新的测试方法，展示其与以前研究所展示的行为不同。

    

    随着它们的规模增大，大型语言模型（LLMs）在语言理解任务上的表现越来越好。但即使在具体下游任务上表现出高性能，LLMs 在否定或量化理解等简单语言测试中仍然失败。以前测试 LLMs 对于理解量词的能力的研究表明，随着模型的不断增大，它们在理解大多数类型的量词时变得更好，但在理解极少数类型的量词时变得越来越差，从而呈现出反比例缩放法则的情况。本文质疑了在 LLMs 中反比例缩放极少数类型量词理解能力的说法，并表明这是不合适的测试方法的结果。我们还提出了替代方法来测量 LLMs 的量化理解能力，并展示了随着模型的规模增大，这些行为与以前的研究所展示的不同。LLMs 能够不断理解含义的差异。

    With their increasing size, Large language models (LLMs) are becoming increasingly good at language understanding tasks. But even with high performance on specific downstream task, LLMs fail at simple linguistic tests for negation or quantifier understanding. Previous work on testing capability of LLMs on understanding quantifiers suggest that as the size of the models increase, they get better at understanding most-type quantifiers but get increasingly worse at understanding few-type quantifiers, thus presenting a case of an inverse-scaling law. In this paper, we question the claims of inverse scaling of few-type quantifier understanding in LLMs and show that it is a result of inappropriate testing methodology. We also present alternate methods to measure quantifier comprehension in LLMs and show that as the size of the models increase, these behaviours are different from what is shown in previous research. LLMs are consistently able to understand the difference between the meaning of
    
[^46]: 语言模型在非英语内容分析中的应用问题

    Lost in Translation: Large Language Models in Non-English Content Analysis. (arXiv:2306.07377v1 [cs.CL])

    [http://arxiv.org/abs/2306.07377](http://arxiv.org/abs/2306.07377)

    大型语言模型目前主要运用于英语内容的智能分析中，多语言模型的发展旨在弥补其他语言数据匮乏的情况。研究人员和技术公司通过构建多语言语言模型尝试解决这一问题并拓展大型语言模型的能力。多语言模型在低资源语言应用中的实践效果也进行研究。总体而言，AI支持的语言技术的设计和部署需要注意权力、不平等和文化差异。

    

    近年来，大型语言模型（例如Open AI的GPT-4，Meta的LLaMa，Google的PaLM）已成为构建在线语言智能分析和生成AI系统的主要方法。然而，越来越多的自动化系统中介我们在网上的交互，例如聊天机器人，内容审核系统和搜索引擎，主要是为英语而设计的，而在其他世界上的7000种语言中的效果远远不如英语。近期，研究人员和技术公司试图通过构建多语言语言模型来扩展大型语言模型的能力。本文将解释这些多语言模型的工作方式以及探索它们的能力和局限性。其中，第一部分提供了关于大型语言模型的简单技术解释，英语和其他语言之间可用数据的差距以及多语言语言模型如何试图弥合这一差距。第二部分回顾了最近的研究，探索了多语言模型在实践中的有效性，包括低资源语言应用的案例研究。最后，我们考虑了AI支持的语言技术在世界上许多语言中的传播的伦理学意义，并强调在设计和部署AI系统时需要特别注意权力、不平等和文化差异等问题。

    In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa, Google's PaLM) have become the dominant approach for building AI systems to analyze and generate language online. However, the automated systems that increasingly mediate our interactions online -- such as chatbots, content moderation systems, and search engines -- are primarily designed for and work far more effectively in English than in the world's other 7,000 languages. Recently, researchers and technology companies have attempted to extend the capabilities of large language models into languages other than English by building what are called multilingual language models.  In this paper, we explain how these multilingual language models work and explore their capabilities and limits. Part I provides a simple technical explanation of how large language models work, why there is a gap in available data between English and other languages, and how multilingual language models attempt to bridge that gap. Part 
    
[^47]: EriBERTa：用于临床自然语言处理的双语预训练语言模型

    EriBERTa: A Bilingual Pre-Trained Language Model for Clinical Natural Language Processing. (arXiv:2306.07373v1 [cs.CL])

    [http://arxiv.org/abs/2306.07373](http://arxiv.org/abs/2306.07373)

    EriBERTa是一个针对临床领域预训练的双语语言模型，展示了在理解医学文本和提取有意义信息方面的强大能力，并具有从一种语言向另一种语言进行知识转移的迁移学习能力。

    

    临床报告的使用对于提高患者护理至关重要，包括健康研究和治疗监控等多个次要用途。自然语言处理工具已成为从这些报告中提取和处理相关信息的有价值资产。然而，专门针对西班牙语临床领域的语言模型的可用性有限。在本文中，我们介绍EriBERTa，这是一个在广泛的医疗和临床语料库上预训练的双语领域特定语言模型。我们展示了EriBERTa在临床领域中胜过先前的西班牙语语言模型，展示了它在理解医学文本和提取有意义信息方面的强大能力。此外，EriBERTa展现出有希望的迁移学习能力，允许从一种语言向另一种语言进行知识转移。鉴于西班牙语临床数据的稀缺性，这一方面特别有益。

    The utilization of clinical reports for various secondary purposes, including health research and treatment monitoring, is crucial for enhancing patient care. Natural Language Processing (NLP) tools have emerged as valuable assets for extracting and processing relevant information from these reports. However, the availability of specialized language models for the clinical domain in Spanish has been limited.  In this paper, we introduce EriBERTa, a bilingual domain-specific language model pre-trained on extensive medical and clinical corpora. We demonstrate that EriBERTa outperforms previous Spanish language models in the clinical domain, showcasing its superior capabilities in understanding medical texts and extracting meaningful information. Moreover, EriBERTa exhibits promising transfer learning abilities, allowing for knowledge transfer from one language to another. This aspect is particularly beneficial given the scarcity of Spanish clinical data.
    
[^48]: 基于Transformer的深度学习任务应用综述

    A Comprehensive Survey on Applications of Transformers for Deep Learning Tasks. (arXiv:2306.07303v1 [cs.LG])

    [http://arxiv.org/abs/2306.07303](http://arxiv.org/abs/2306.07303)

    本文综述了基于Transformer的深度学习任务应用，Transformer能够理解序列数据中的上下文关系且实现并行处理，在NLP、计算机视觉、语音处理、医疗保健和物联网等领域表现出色。

    

    Transformer是一种深度神经网络，采用自注意机制来理解序列数据中的上下文关系。与传统神经网络或更新版本的循环神经网络（RNN）（如长短期记忆（LSTM））不同，Transformer模型在处理输入序列元素之间的长依赖关系和实现并行处理方面表现出色。因此，基于Transformer的模型在人工智能领域引起了广泛兴趣。这得益于它们在自然语言处理（NLP）任务以及计算机视觉、音频和语音处理、医疗保健和物联网（IoT）等各个领域中的巨大潜力和显著成就。虽然已经出版了几篇综述文章，重点介绍了Transformer在特定领域的贡献、架构差异或性能评估，但仍存在较大的空白。

    Transformer is a deep neural network that employs a self-attention mechanism to comprehend the contextual relationships within sequential data. Unlike conventional neural networks or updated versions of Recurrent Neural Networks (RNNs) such as Long Short-Term Memory (LSTM), transformer models excel in handling long dependencies between input sequence elements and enable parallel processing. As a result, transformer-based models have attracted substantial interest among researchers in the field of artificial intelligence. This can be attributed to their immense potential and remarkable achievements, not only in Natural Language Processing (NLP) tasks but also in a wide range of domains, including computer vision, audio and speech processing, healthcare, and the Internet of Things (IoT). Although several survey papers have been published highlighting the transformer's contributions in specific fields, architectural differences, or performance evaluations, there is still a significant abs
    
[^49]: 教学代理人的应（识别）答错误对学习和人际关系的影响

    Impact of Experiencing Misrecognition by Teachable Agents on Learning and Rapport. (arXiv:2306.07302v1 [cs.HC])

    [http://arxiv.org/abs/2306.07302](http://arxiv.org/abs/2306.07302)

    音频识别错误对教学代理人学习和人际关系无显著影响，结果为教学代理人的最优错误恢复策略提供了一些启示。

    

    虽然使用语音的教学代理人相比于基于打字的代理人具有一些优势，但它们容易出现音频识别错误。这些错误可能会扩散，导致对话流程的意外变化。我们分析了这些变化与学习收益以及学习者与代理人之间的人际关系之间的联系。我们的结果表明，这些变化无论代理人在不产生错误的情况下应该给予何种回应，都与学习收益或人际关系无关。我们还讨论了可从这些发现中推出的适当错误恢复策略对教学代理人的影响。

    While speech-enabled teachable agents have some advantages over typing-based ones, they are vulnerable to errors stemming from misrecognition by automatic speech recognition (ASR). These errors may propagate, resulting in unexpected changes in the flow of conversation. We analyzed how such changes are linked with learning gains and learners' rapport with the agents. Our results show they are not related to learning gains or rapport, regardless of the types of responses the agents should have returned given the correct input from learners without ASR errors. We also discuss the implications for optimal error-recovery policies for teachable agents that can be drawn from these findings.
    
[^50]: 基于ChatGPT的医疗数据增广：基于药物识别和药物事件分类的案例研究

    Medical Data Augmentation via ChatGPT: A Case Study on Medication Identification and Medication Event Classification. (arXiv:2306.07297v1 [cs.CL])

    [http://arxiv.org/abs/2306.07297](http://arxiv.org/abs/2306.07297)

    本研究利用ChatGPT进行数据增广，显著提高了BERT模型在电子病历药物识别和药物事件分类任务中的表现。

    

    在电子病历和临床记录中识别药物、疾病和关联性等关键因素具有广泛的临床应用。本研究旨在探索使用预训练的大型语言模型ChatGPT进行数据增广，以克服电子病历中关键因素标注数据的有限可用性。研究结果表明，提出的数据增广技术显著提高了BERT模型在药物识别和药物事件分类等两个电子病历分析任务中的性能。

    The identification of key factors such as medications, diseases, and relationships within electronic health records and clinical notes has a wide range of applications in the clinical field. In the N2C2 2022 competitions, various tasks were presented to promote the identification of key factors in electronic health records (EHRs) using the Contextualized Medication Event Dataset (CMED). Pretrained large language models (LLMs) demonstrated exceptional performance in these tasks. This study aims to explore the utilization of LLMs, specifically ChatGPT, for data augmentation to overcome the limited availability of annotated data for identifying the key factors in EHRs. Additionally, different pre-trained BERT models, initially trained on extensive datasets like Wikipedia and MIMIC, were employed to develop models for identifying these key variables in EHRs through fine-tuning on augmented datasets. The experimental results of two EHR analysis tasks, namely medication identification and me
    
[^51]: LTCR：长文本中文谣言检测数据集

    LTCR: Long-Text Chinese Rumor Detection Dataset. (arXiv:2306.07201v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.07201](http://arxiv.org/abs/2306.07201)

    该论文提出了LTCR数据集，用于准确检测虚假信息，特别是COVID-19相关的复杂虚假新闻。该数据集包含1,729个真实新闻和500个虚假新闻。基于LTCR数据集，提出了SFD（Salience-aware Fake News Detection Model）算法，具有最高的准确度，虚假新闻回收率和F1分数。

    

    在社交媒体上，虚假信息往往能够迅速传播，从而对公民的行为和社会事件的反应产生负面影响。为更好地检测虚假新闻，尤其是那些较长文本，更难以完整查找的虚假信息，我们提出了一个名为LTCR的长文本中文谣言检测数据集。LTCR数据集为准确检测谣言，特别是与COVID-19相关的复杂虚假新闻提供了重要资源。该数据集包含1,729条真实新闻和500条虚假新闻，其中真实新闻和虚假新闻的平均长度分别约为230和152个字符。我们还提出了名为SFD（Salience-aware Fake News Detection Model）的算法，在LTCR数据集上的测试中，达到了最高的准确度（95.85％），虚假新闻回收率（90.91％）和F1分数（90.60％）。

    False information can spread quickly on social media, negatively influencing the citizens' behaviors and responses to social events. To better detect all of the fake news, especially long texts which are harder to find completely, a Long-Text Chinese Rumor detection dataset named LTCR is proposed. The LTCR dataset provides a valuable resource for accurately detecting misinformation, especially in the context of complex fake news related to COVID-19. The dataset consists of 1,729 and 500 pieces of real and fake news, respectively. The average lengths of real and fake news are approximately 230 and 152 characters. We also propose \method, Salience-aware Fake News Detection Model, which achieves the highest accuracy (95.85%), fake news recall (90.91%) and F-score (90.60%) on the dataset. (https://github.com/Enderfga/DoubleCheck)
    
[^52]: 多模式音文档架构的鲁棒性口语理解

    Multimodal Audio-textual Architecture for Robust Spoken Language Understanding. (arXiv:2306.06819v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.06819](http://arxiv.org/abs/2306.06819)

    本文提出了一种使用多模态语言理解（MLU）模块的口语理解解决方案，结合了音频和文本模态的自我监督特征，并充分利用了预训练语言模型（BERT和RoBERTa），以减轻由ASR错误传播带来的性能下降。

    

    目前的语音助手通常基于级联口语理解（SLU）解决方案，包括自动语音识别（ASR）引擎和自然语言理解（NLU）系统。由于这种方法依靠ASR输出，因此经常遭受所谓的ASR错误传播的影响。在本文中，我们研究了此类ASR错误传播对基于预训练语言模型（PLM）（如BERT和RoBERTa）的最先进NLU系统的影响。此外，提出了一种多模态语言理解（MLU）模块，以减轻由ASR转录中存在的错误引起的SLU性能下降。MLU受益于从音频和文本模态学习的自我监督特征，特别是Wav2Vec用于语音和Bert / RoBERTa用于语言。我们的MLU结合一个编码器网络来嵌入音频信号和一个文本编码器来处理文本转录，然后是一个后期融合层来融合音频和文本逻辑。我们发现，使用这种多模式音文档架构可以有效提高口语理解的鲁棒性。

    Recent voice assistants are usually based on the cascade spoken language understanding (SLU) solution, which consists of an automatic speech recognition (ASR) engine and a natural language understanding (NLU) system. Because such approach relies on the ASR output, it often suffers from the so-called ASR error propagation. In this work, we investigate impacts of this ASR error propagation on state-of-the-art NLU systems based on pre-trained language models (PLM), such as BERT and RoBERTa. Moreover, a multimodal language understanding (MLU) module is proposed to mitigate SLU performance degradation caused by errors present in the ASR transcript. The MLU benefits from self-supervised features learned from both audio and text modalities, specifically Wav2Vec for speech and Bert/RoBERTa for language. Our MLU combines an encoder network to embed the audio signal and a text encoder to process text transcripts followed by a late fusion layer to fuse audio and text logits. We found that the pro
    
[^53]: EaSyGuide：利用生成大语言模型能力的ESG问题识别框架

    EaSyGuide : ESG Issue Identification Framework leveraging Abilities of Generative Large Language Models. (arXiv:2306.06662v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.06662](http://arxiv.org/abs/2306.06662)

    本文介绍了一种利用生成大语言模型能力的ESG问题识别框架，该框架在多语言环境下对MSCI ESG评级指南定义的35个ESG关键问题实现了卓越的识别成果，为ESG主题的探索做出了贡献。

    

    本文介绍了我们参加FinNLP-2023多语言环境、社会和企业治理问题识别（ML-ESG）共享任务的方法。该任务的目标是根据MSCI ESG评级指南定义的35个ESG关键问题对新闻文章进行分类。我们的方法集中在英语和法语子任务上，采用CerebrasGPT、OPT和Pythia模型，以及零-shot和GPT3Mix增强技术。我们利用各种编码器模型，如RoBERTa、DeBERTa和FinBERT，在知识蒸馏和额外训练的基础上进行了试验。我们的方法取得了卓越的成果，在英语文本子任务中获得F1-score 0.69的第一名，在法语文本子任务中获得F1-score 0.78的第二名。这些结果强调了我们的方法在不同语言的新闻文章中识别ESG问题的有效性。我们的研究结果对ESG主题的探索做出了贡献，并强调了技术创新在解决复杂问题上的重要性。

    This paper presents our participation in the FinNLP-2023 shared task on multi-lingual environmental, social, and corporate governance issue identification (ML-ESG). The task's objective is to classify news articles based on the 35 ESG key issues defined by the MSCI ESG rating guidelines. Our approach focuses on the English and French subtasks, employing the CerebrasGPT, OPT, and Pythia models, along with the zero-shot and GPT3Mix Augmentation techniques. We utilize various encoder models, such as RoBERTa, DeBERTa, and FinBERT, subjecting them to knowledge distillation and additional training.  Our approach yielded exceptional results, securing the first position in the English text subtask with F1-score 0.69 and the second position in the French text subtask with F1-score 0.78. These outcomes underscore the effectiveness of our methodology in identifying ESG issues in news articles across different languages. Our findings contribute to the exploration of ESG topics and highlight the po
    
[^54]: 多任务训练结合领域内语言模型进行诊断推理

    Multi-Task Training with In-Domain Language Models for Diagnostic Reasoning. (arXiv:2306.04551v1 [cs.CL])

    [http://arxiv.org/abs/2306.04551](http://arxiv.org/abs/2306.04551)

    本文研究了领域内与领域外语言模型以及多任务与单任务训练的比较，并证明了通过临床训练的多任务语言模型在临床诊断推理任务中表现优异，建立了新的最优性能。

    

    生成人工智能是增强临床诊断决策支持和减少诊断错误的一种有前途的方向。为进一步发展临床人工智能系统，引入了诊断推理基准（DR.BENCH）作为全面的生成人工智能框架，由六个任务组成，代表临床推理的关键组成部分。本文进行了领域内与领域外语言模型以及多任务与单任务训练的比较分析，重点关注 DR.BENCH 的问题总结任务（Gao 等，2023）。我们证明，通过临床训练的多任务语言模型大幅优于其一般领域的对应模型，建立了新的最优性能， ROUGE-L 得分为 28.55。这项研究强调了领域特定训练在优化临床诊断推理任务中的价值。

    Generative artificial intelligence (AI) is a promising direction for augmenting clinical diagnostic decision support and reducing diagnostic errors, a leading contributor to medical errors. To further the development of clinical AI systems, the Diagnostic Reasoning Benchmark (DR.BENCH) was introduced as a comprehensive generative AI framework, comprised of six tasks representing key components in clinical reasoning. We present a comparative analysis of in-domain versus out-of-domain language models as well as multi-task versus single task training with a focus on the problem summarization task in DR.BENCH (Gao et al., 2023). We demonstrate that a multi-task, clinically trained language model outperforms its general domain counterpart by a large margin, establishing a new state-of-the-art performance, with a ROUGE-L score of 28.55. This research underscores the value of domain-specific training for optimizing clinical diagnostic reasoning tasks.
    
[^55]: PolyVoice：语言模型实现的语音到语音翻译系统

    PolyVoice: Language Models for Speech to Speech Translation. (arXiv:2306.02982v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.02982](http://arxiv.org/abs/2306.02982)

    PolyVoice是一个语音到语音翻译系统框架，它包括两个语言模型并使用离散化的语音单元实现无监督学习，同时可用于非书面语言。实验结果表明，该系统可生成高质量的翻译和音频质量的语音。

    

    我们提出了PolyVoice，一个基于语言模型的语音到语音翻译系统框架。我们的框架包括两个语言模型：翻译语言模型和语音合成语言模型。我们使用经过离散化的语音单元，这些单元完全以无监督的方式生成，因此我们的框架可以用于非书面语言。对于语音合成部分，我们采用现有的VALL-E X方法，并构建了一个基于单元的音频语言模型。这赋予了我们的框架保留原始语音的声音特征和说话风格的能力。我们在中文 $\rightarrow$ 英文和英文 $\rightarrow$ 西班牙语对上测试了我们的系统。实验结果表明，我们的系统可以生成高质量的翻译和音频质量的语音。语音样本可在https://speechtranslation.github.io/polyvoice上获取。

    We propose PolyVoice, a language model-based framework for speech-to-speech translation (S2ST) system. Our framework consists of two language models: a translation language model and a speech synthesis language model. We use discretized speech units, which are generated in a fully unsupervised way, and thus our framework can be used for unwritten languages. For the speech synthesis part, we adopt the existing VALL-E X approach and build a unit-based audio language model. This grants our framework the ability to preserve the voice characteristics and the speaking style of the original speech. We examine our system on Chinese $\rightarrow$ English and English $\rightarrow$ Spanish pairs. Experimental results show that our system can generate speech with high translation quality and audio quality. Speech samples are available at https://speechtranslation.github.io/polyvoice.
    
[^56]: 2023年SIGIR会议上的Gen-IR研讨会：生成式信息检索的首个研讨会

    Gen-IR @ SIGIR 2023: The First Workshop on Generative Information Retrieval. (arXiv:2306.02887v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2306.02887](http://arxiv.org/abs/2306.02887)

    本研讨会旨在探讨生成式信息检索（IR）的新指标、理论基础、评估方法、任务定义、模型和用户界面等，以探究它是否是IR的范式转变。该研讨会关注先前探索过的技术，并提供一个地点用于探讨和探索如何将生成式IR应用于新领域。

    

    生成式信息检索（IR）在多个研究社区（例如信息检索、计算机视觉、自然语言处理和机器学习）中得到了显著增长，并在流行媒体上备受关注。已发布了理论、实证和实际用户产品，这些产品可以通过生成文档（通过生成）或直接生成答案来检索文档或回答输入请求。我们想调查端到端生成模型是否只是另一种趋势，还是像某些人所声称的那样，是IR的范式转变。这需要新的指标、理论基础、评估方法、任务定义、模型、用户界面等。本次研讨会的目标是关注先前探索过的生成式IR技术，如文档检索和直接实现的基础答案生成，同时也提供一个地点用于探讨和探索生成式IR如何应用于推荐等新领域。

    Generative information retrieval (IR) has experienced substantial growth across multiple research communities (e.g., information retrieval, computer vision, natural language processing, and machine learning), and has been highly visible in the popular press. Theoretical, empirical, and actual user-facing products have been released that retrieve documents (via generation) or directly generate answers given an input request. We would like to investigate whether end-to-end generative models are just another trend or, as some claim, a paradigm change for IR. This necessitates new metrics, theoretical grounding, evaluation methods, task definitions, models, user interfaces, etc. The goal of this workshop (https://coda.io/@sigir/gen-ir) is to focus on previously explored Generative IR techniques like document retrieval and direct Grounded Answer Generation, while also offering a venue for the discussion and exploration of how Generative IR can be applied to new domains like recommendation s
    
[^57]: OWQ：大语言模型权重量化中激活离群值的启示

    OWQ: Lessons learned from activation outliers for weight quantization in large language models. (arXiv:2306.02272v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.02272](http://arxiv.org/abs/2306.02272)

    在大语言模型的推理中，要使用多个服务器贵重的GPU导致显著的成本障碍，OWQ提出的一种后训练量化方法可以在最小质量损失的情况下减少这种限制。它可以通过考虑激活离群值来确定权值量化误差的因素，并为易受攻击的权重分配高精度，具有与OPTQ相当的质量。

    

    拥有数十亿个参数的大型语言模型(LLMs)通过简单的提示调整和少量的示例，在各种语言任务中展现出令人惊叹的结果，而无需进行任务特定的微调。然而，它们巨大的尺寸要求甚至在推理时使用多个服务器级的GPU，从而产生了显著的成本障碍。为了解决这一限制，我们提出了一种新型的后训练量化方法来量化权重，减少质量损失。虽然已知激活离群值在激活量化中存在问题，但我们的理论分析表明，通过考虑激活离群值，我们可以确定导致权重量化误差的因素。我们提出了一种创新的后训练量化方案，名为Outlier-Aware Weight Quantization (OWQ)，它可以识别易受攻击的权重并为它们分配高精度。我们的大量实验表明，OWQ生成的3.01位模型具有与OPTQ生成的4位模型相当的质量。

    Large language models (LLMs) with hundreds of billions of parameters show impressive results across various language tasks using simple prompt tuning and few-shot examples, without the need for task-specific fine-tuning. However, their enormous size requires multiple server-grade GPUs even for inference, creating a significant cost barrier. To address this limitation, we introduce a novel post-training quantization method for weights with minimal quality degradation. While activation outliers are known to be problematic in activation quantization, our theoretical analysis suggests that we can identify factors contributing to weight quantization errors by considering activation outliers. We propose an innovative PTQ scheme called outlier-aware weight quantization (OWQ), which identifies vulnerable weights and allocates high-precision to them. Our extensive experiments demonstrate that the 3.01-bit models produced by OWQ exhibit comparable quality to the 4-bit models generated by OPTQ.
    
[^58]: DyGen: 通过动态增强的生成建模从噪声标签中学习

    DyGen: Learning from Noisy Labels via Dynamics-Enhanced Generative Modeling. (arXiv:2305.19395v1 [cs.CL])

    [http://arxiv.org/abs/2305.19395](http://arxiv.org/abs/2305.19395)

    DyGen是一个动态增强的生成模型，使用嵌入空间中的动态模式可以改善从噪声标签中学习的精度，同时使用共规正则化机制来最小化潜在噪声标签和先验的影响，展示了最先进的性能。

    

    在许多实际应用中，训练数据可能包含不正确或已损坏的标签，从噪声标签中学习是一个挑战。当使用带有噪声标签的语言模型进行微调时，模型很容易过度拟合标签噪声，导致性能下降。大多数现有的从噪声标签中学习的方法使用静态输入特征进行去噪，但这些方法受限于它们在真实标签分布方面提供的信息，可能导致有偏的或不正确的预测。在这项工作中，我们提出了一个名为DyGen的动态增强生成模型，该模型在语言模型的微调过程中利用嵌入空间中的动态模式来改善噪声标签预测。DyGen使用变分自动编码框架从噪声标签和训练动态中推断真实标签的后验分布。此外，使用共规正则化机制来最小化潜在噪声标签和先验的影响。在存在不同级别的标签噪声情况下，DyGen在两个大规模文本分类数据集上展示了最先进的性能。

    Learning from noisy labels is a challenge that arises in many real-world applications where training data can contain incorrect or corrupted labels. When fine-tuning language models with noisy labels, models can easily overfit the label noise, leading to decreased performance. Most existing methods for learning from noisy labels use static input features for denoising, but these methods are limited by the information they can provide on true label distributions and can result in biased or incorrect predictions. In this work, we propose the Dynamics-Enhanced Generative Model (DyGen), which uses dynamic patterns in the embedding space during the fine-tuning process of language models to improve noisy label predictions. DyGen uses the variational auto-encoding framework to infer the posterior distributions of true labels from noisy labels and training dynamics. Additionally, a co-regularization mechanism is used to minimize the impact of potentially noisy labels and priors. DyGen demonstr
    
[^59]: LM-CPPF: 基于释义引导的数据增强用于对比型Prompt的少样本微调

    LM-CPPF: Paraphrasing-Guided Data Augmentation for Contrastive Prompt-Based Few-Shot Fine-Tuning. (arXiv:2305.18169v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.18169](http://arxiv.org/abs/2305.18169)

    本文提出了一种基于释义引导的数据增强用于对比型Prompt的少样本微调方法。该方法利用基础Prompt的少样本释义生成语言模型完成数据增强。

    

    近年来，预训练语言模型在自然语言处理领域取得了显著进展，但这些模型在少量数据集上的微调仍然存在缺陷。为了解决这个问题，研究人员提出了各种适应性方法。对基础Prompt进行微调是一种较为普遍的方式，尤其适用于大型模型。之前的研究显示，将对比学习添加到对Prompt的微调中是有效的，因为它帮助模型生成更能够区分不同分类之间的嵌入，而且它同时还能从正负示例中学习，更加节省样本。对比学习最重要的组成部分之一是数据增强，在计算机视觉领域得到广泛应用，但对于NLP来说，有效的数据增强仍然具有挑战性。本文提出了LM-CPPF，通过生成式语言模型引导的少样本释义型对比Prompt微调，它利用基础Prompt的少样本释义生成语言模型来完成数据增强。

    In recent years, there has been significant progress in developing pre-trained language models for NLP. However, these models often struggle when fine-tuned on small datasets. To address this issue, researchers have proposed various adaptation approaches. Prompt-based tuning is arguably the most common way, especially for larger models. Previous research shows that adding contrastive learning to prompt-based fine-tuning is effective as it helps the model generate embeddings that are more distinguishable between classes, and it can also be more sample-efficient as the model learns from positive and negative examples simultaneously. One of the most important components of contrastive learning is data augmentation, but unlike computer vision, effective data augmentation for NLP is still challenging. This paper proposes LM-CPPF, Contrastive Paraphrasing-guided Prompt-based Fine-tuning of Language Models, which leverages prompt-based few-shot paraphrasing using generative language models, e
    
[^60]: PaCE：渐进式和组合式专家统一多模态对话预训练

    PaCE: Unified Multi-modal Dialogue Pre-training with Progressive and Compositional Experts. (arXiv:2305.14839v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.14839](http://arxiv.org/abs/2305.14839)

    本文提出的PaCE是一个统一、结构化、组合式的多模态对话预训练框架，它利用了几个基本专家的组合，可以适应多个与对话相关的任务，并可以使用有限的对话和广泛的非对话多模态数据进行预训练。

    

    感知多模态信息并与人类进行对话是人工智能的长期目标。预训练被普遍认为是多模态对话的一种有效方法。然而，由于多模态对话数据的有限可用性，目前关于多模态对话预训练的研究仍相对稀缺。本文提出了一种名为PaCE的统一、结构化、组合式的多模态对话预训练框架，它利用了几个基本专家的组合，以适应多个与对话相关的任务，并可以使用有限的对话和广泛的非对话多模态数据进行预训练。

    Perceiving multi-modal information and fulfilling dialogues with humans is a long-term goal of artificial intelligence. Pre-training is commonly regarded as an effective approach for multi-modal dialogue. However, due to the limited availability of multi-modal dialogue data, there is still scarce research on multi-modal dialogue pre-training. Yet another intriguing challenge emerges from the encompassing nature of multi-modal dialogue, which involves various modalities and tasks. Moreover, new forms of tasks may arise at unpredictable points in the future. Hence, it is essential for designed multi-modal dialogue models to possess sufficient flexibility to adapt to such scenarios. This paper proposes \textbf{PaCE}, a unified, structured, compositional multi-modal dialogue pre-training framework. It utilizes a combination of several fundamental experts to accommodate multiple dialogue-related tasks and can be pre-trained using limited dialogue and extensive non-dialogue multi-modal data.
    
[^61]: 多模态-GPT: 用于与人类对话的视觉与语言模型

    MultiModal-GPT: A Vision and Language Model for Dialogue with Humans. (arXiv:2305.04790v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.04790](http://arxiv.org/abs/2305.04790)

    MultiModal-GPT是一个用于与人类进行多轮对话的视觉与语言模型，可以遵循人类的各种指令，并且通过联合训练表现得更好。

    

    我们提出了一个名为MultiModal-GPT的视觉与语言模型，用于与人类进行多轮对话。 MultiModal-GPT可以遵循人类的各种指令，例如生成详细的字幕，计算感兴趣对象的数量以及回答用户的常见问题。 我们通过OpenFlamingo进行参数有效地微调MultiModal-GPT，并在语言模型的交叉关注部分和自我关注部分中添加了低秩适配器（LoRA）。 我们首先使用视觉和语言数据构建指令模板，用于多模态指令调整，让模型理解和遵循人类指令。 我们发现对话表现的训练数据质量至关重要，其中很少包含简短回答的数据会使模型对任何指令都作出简短回答。为了进一步增强MultiModal-GPT与人类聊天的能力，我们利用仅语言的指令跟随数据联合训练MultiModal-GPT。联合训练显著提高了MultiModal-GPT在对话任务中的表现。

    We present a vision and language model named MultiModal-GPT to conduct multi-round dialogue with humans. MultiModal-GPT can follow various instructions from humans, such as generating a detailed caption, counting the number of interested objects, and answering general questions from users. MultiModal-GPT is parameter-efficiently fine-tuned from OpenFlamingo, with Low-rank Adapter (LoRA) added both in the cross-attention part and the self-attention part of the language model. We first construct instruction templates with vision and language data for multi-modality instruction tuning to make the model understand and follow human instructions. We find the quality of training data is vital for the dialogue performance, where few data containing short answers can lead the model to respond shortly to any instructions. To further enhance the ability to chat with humans of the MultiModal-GPT, we utilize language-only instruction-following data to train the MultiModal-GPT jointly. The joint tra
    
[^62]: FormNetV2：用于表格文档信息提取的多模态图形对比学习

    FormNetV2: Multimodal Graph Contrastive Learning for Form Document Information Extraction. (arXiv:2305.02549v1 [cs.CL])

    [http://arxiv.org/abs/2305.02549](http://arxiv.org/abs/2305.02549)

    该论文提出了一种用于表格文档信息提取的多模态图形对比学习策略（FormNetV2），该方法能够统一所有模态的自监督预训练到一个损失中，并在多个基准测试中取得了最佳表现。

    

    自监督预训练技术的出现导致了多模态学习在表格文档理解中的激增。然而，现有的扩展掩码语言建模到其他模态的方法需要仔细的多任务调整、复杂的重构目标设计或额外的预训练数据。在FormNetV2中，我们引入了一种集中的多模态图对比学习策略，以统一所有模态的自监督预训练到一个损失中。图对比目标最大化多模态表示的一致性，为所有模态提供自然的相互作用，而不需要特殊的定制。此外，我们在连接图边缘的一对标记的边框内提取图像特征，捕捉更有针对性的视觉线索，而无需加载经过复杂和单独预训练的图像嵌入器。FormNetV2在FUNSD、CORD、SROIE和Payment基准测试中确立了最新的最佳表现水平。

    The recent advent of self-supervised pre-training techniques has led to a surge in the use of multimodal learning in form document understanding. However, existing approaches that extend the mask language modeling to other modalities require careful multi-task tuning, complex reconstruction target designs, or additional pre-training data. In FormNetV2, we introduce a centralized multimodal graph contrastive learning strategy to unify self-supervised pre-training for all modalities in one loss. The graph contrastive objective maximizes the agreement of multimodal representations, providing a natural interplay for all modalities without special customization. In addition, we extract image features within the bounding box that joins a pair of tokens connected by a graph edge, capturing more targeted visual cues without loading a sophisticated and separately pre-trained image embedder. FormNetV2 establishes new state-of-the-art performance on FUNSD, CORD, SROIE and Payment benchmarks with 
    
[^63]: 基于能量模型的零样本场景重新排列规划器

    Energy-based Models as Zero-Shot Planners for Compositional Scene Rearrangement. (arXiv:2304.14391v1 [cs.RO])

    [http://arxiv.org/abs/2304.14391](http://arxiv.org/abs/2304.14391)

    本文提出一种基于能量模型的零样本场景重新排列规划器，通过语言指导的空间概念来实现长指令以及在训练时从未见过的空间概念组合。本文的模型在指令导向操作基准测试以及组合指令基准测试中表现良好，优于基于语言表达的最先进方法，并且可以成功地解决之前从未见过的复杂指令和场景。

    

    本文致力于开发一个场景重排框架，可以解释长指令以及在训练时从未见过的空间概念组合。我们提出使用相对对象排列的能量函数来表示语言指导的空间概念。语言解析器将指令映射到相应的能量函数，而开放式视觉语言模型将它们的参数基于场景中的相关对象进行修正。通过梯度下降求解能量函数的总和，并利用基于本地计算机视觉的策略将对象重新定位到推断的目标位置，即可生成目标场景配置。我们在已建立的指令导向操作基准测试以及我们提出的组合指令基准测试中测试了模型，结果表明，我们的模型的绩效优于基于语言表达的最先进方法，并且可以成功地解决之前从未见过的复杂指令和场景。

    Language is compositional; an instruction can express multiple relation constraints to hold among objects in a scene that a robot is tasked to rearrange. Our focus in this work is an instructable scene rearranging framework that generalizes to longer instructions and to spatial concept compositions never seen at training time. We propose to represent language-instructed spatial concepts with energy functions over relative object arrangements. A language parser maps instructions to corresponding energy functions and an open-vocabulary visual-language model grounds their arguments to relevant objects in the scene. We generate goal scene configurations by gradient descent on the sum of energy functions, one per language predicate in the instruction. Local vision-based policies then relocate objects to the inferred goal locations. We test our model on established instruction-guided manipulation benchmarks, as well as benchmarks of compositional instructions we introduce. We show our model 
    
[^64]: 奖励是否合理？在 MACHIAVELLI 基准测试中衡量奖励与道德行为之间的权衡

    Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark. (arXiv:2304.03279v1 [cs.LG])

    [http://arxiv.org/abs/2304.03279](http://arxiv.org/abs/2304.03279)

    本文介绍了 MACHIAVELLI 基准测试，用于衡量人工智能代理是否表现出马基雅维利行为，发现了最大化奖励和行为的道德性之间存在权衡，并探索了基于语言模型的方法来减轻这种权衡。

    

    传统上，人工智能代理被训练成最大化奖励，这可能会激励追求权力和欺骗行为，类似于语言模型中的下一个标记预测可能会激励有害行为。那么代理是否自然而然地学会了马基雅维利行为？我们如何在 GPT-4 等通用模型中衡量这些行为呢？为回答这些问题，我们引入了 MACHIAVELLI 基准测试，该测试涵盖了超过一百万个多样化的情景，重点关注社会决策制定，用于衡量人工代理是否表现出马基雅维利行为。我们数学化了数十种有害行为，并使用我们的注释来评估代理倾向于追求权力，造成功能不良和违反伦理的倾向。我们观察到最大化奖励和行为的道德性之间存在一些紧张关系。为了改善这种权衡，我们研究了基于语言模型的方法，以使代理趋向于采取更少的有害行为。我们的结果显示，MACHIAVELLI 是评估人工代理马基雅维利行为水平的有用基准测试。

    Artificial agents have traditionally been trained to maximize reward, which may incentivize power-seeking and deception, analogous to how next-token prediction in language models (LMs) may incentivize toxicity. So do agents naturally learn to be Machiavellian? And how do we measure these behaviors in general-purpose models such as GPT-4? Towards answering these questions, we introduce MACHIAVELLI, a benchmark of 134 Choose-Your-Own-Adventure games containing over half a million rich, diverse scenarios that center on social decision-making. Scenario labeling is automated with LMs, which are more performant than human annotators. We mathematize dozens of harmful behaviors and use our annotations to evaluate agents' tendencies to be power-seeking, cause disutility, and commit ethical violations. We observe some tension between maximizing reward and behaving ethically. To improve this trade-off, we investigate LM-based methods to steer agents' towards less harmful behaviors. Our results sh
    
[^65]: 超越不对称性：结构剪枝提高序列到序列模型的推断效率

    To Asymmetry and Beyond: Structured Pruning of Sequence to Sequence Models for Improved Inference Efficiency. (arXiv:2304.02721v1 [cs.CL])

    [http://arxiv.org/abs/2304.02721](http://arxiv.org/abs/2304.02721)

    本论文研究了模型大小、结构化剪枝、推断效率和摘要准确性之间的关系，发现使用不对称剪枝可在不大损失模型准确性的情况下，提高推断效率约3倍。

    

    序列到序列语言模型可以用于生成连贯，相关和简洁的抽象摘要。但是，模型大小可能使得在延迟敏感或 Web 规模的实现中部署变得困难。本文研究了模型大小、结构化剪枝、推断效率和广泛使用的摘要数据集上的摘要准确性之间的关系。我们表明，模型准确性与编码器大小有关，而推理效率与解码器有关。使用不对称剪枝可导致推断延迟的近3倍提高，Rouge-2的损失约为1点。此外，我们发现，平均性能降低和不对称性的作用在模型大小和数据集变化方面是一致的。

    Sequence-to-sequence language models can be used to produce abstractive summaries which are coherent, relevant, and concise. Still, model sizes can make deployment in latency-sensitive or web-scale implementations difficult. This paper studies the relationship between model size, structured pruning, inference efficiency, and summarization accuracy on widely used summarization datasets. We show that model accuracy is tied to the encoder size while inference efficiency is connected to the decoder. Using asymmetric pruning can lead to nearly 3x improvement in inference latency with ~1 point loss in Rouge-2. Moreover, we find both the average degradation and the role of asymmetry to be consistent across model sizes and variations in datasets.
    
[^66]: 利用上下文化的大型语言模型理解法律文件

    Understand Legal Documents with Contextualized Large Language Models. (arXiv:2303.12135v1 [cs.CL])

    [http://arxiv.org/abs/2303.12135](http://arxiv.org/abs/2303.12135)

    本文介绍了针对 SemEval-2023 任务 6 开发的 Legal-BERT-HSLN 模型和 Legal-LUKE 模型，其中 Legal-BERT-HSLN 模型通过考虑句内和句间的上下文信息以预测修辞角色，Legal-LUKE 模型是具有法律上下文和实体知识的模型，以识别法律实体。模型相比基线模型更准确，能够解决在人口众多的国家处理法律文件的问题。

    

    在人口众多的国家，如印度，待处理的法律案件数量不断增加，这已成为一个重大问题。因此，开发有效的技术来处理和理解法律文件将非常有用。在本文中，我们介绍了我们针对 SemEval-2023 任务 6（Modi 等人，2023）所开发的理解法律文本系统。具体来说，我们首先开发了 Legal-BERT-HSLN 模型，该模型考虑了句内和句间的综合上下文信息，以预测修辞角色（子任务 A），然后训练出 Legal-LUKE 模型，该模型具有法律上下文化和实体感知能力，以识别法律实体（子任务 B）。我们的评估表明，我们设计的模型比基线模型更准确，如在子任务 B 中 F1 值提高了达 15.0%。我们在任务排行榜上取得了显著的表现，如 0.834 微平均 F1 值，并在子任务 A 中排名第 5。

    The growth of pending legal cases in populous countries, such as India, has become a major issue. Developing effective techniques to process and understand legal documents is extremely useful in resolving this problem. In this paper, we present our systems for SemEval-2023 Task 6: understanding legal texts (Modi et al., 2023). Specifically, we first develop the Legal-BERT-HSLN model that considers the comprehensive context information in both intra- and inter-sentence levels to predict rhetorical roles (subtask A) and then train a Legal-LUKE model, which is legal-contextualized and entity-aware, to recognize legal entities (subtask B). Our evaluations demonstrate that our designed models are more accurate than baselines, e.g., with an up to 15.0% better F1 score in subtask B. We achieved notable performance in the task leaderboard, e.g., 0.834 micro F1 score, and ranked No.5 out of 27 teams in subtask A.
    
[^67]: eP-ALM:语言模型的高效感知增强

    eP-ALM: Efficient Perceptual Augmentation of Language Models. (arXiv:2303.11403v1 [cs.CV])

    [http://arxiv.org/abs/2303.11403](http://arxiv.org/abs/2303.11403)

    本论文提出了一种用对比学习提高语言模型的感知能力的高效方法eP-ALM，可以实现视觉感知信息和文本信息的融合，同时还能在多模态基准测试上实现最先进的结果。

    

    大型语言模型(LLM)迄今为止给世界留下了深刻印象，具有大规模模型所具有的非同寻常的能力。在视觉方面，变压器模型（即ViT）也在追随同一趋势，取得了最具挑战性的基准测试的最佳表现。随着这种单模型的丰富多样，自然会引发一个问题：我们是否需要跟随这个趋势来处理多模态任务？在这项工作中，我们提出将努力集中于现有模型的高效适应，并提出用感知来增强语言模型。现有的适应预训练模型用于视觉语言任务的方法仍然依赖于几个关键组件，从而影响了它们的效率。特别地，他们仍然训练大量的参数，依赖大规模的多模态预训练，使用在巨大的图像-文本数据集上训练的编码器（例如CLIP），并添加了显著的推理开销。此外，这些方法中的大多数关注Zero-Shot和In Context Learning，观察到两种范式之间的巨大差异。在本文中，我们介绍了eP-ALM，一种将视觉感知信息与语言模型相结合的高效方法。我们提出了一种方法，利用对比学习来实现视觉感知和文本信息的融合，具有极小的计算成本。我们的方法不需要任何新的预训练，仍然在多模态基准测试上实现了最先进的结果。

    Large Language Models (LLMs) have so far impressed the world, with unprecedented capabilities that emerge in models at large scales. On the vision side, transformer models (i.e., ViT) are following the same trend, achieving the best performance on challenging benchmarks. With the abundance of such unimodal models, a natural question arises; do we need also to follow this trend to tackle multimodal tasks? In this work, we propose to rather direct effort to efficient adaptations of existing models, and propose to augment Language Models with perception. Existing approaches for adapting pretrained models for vision-language tasks still rely on several key components that hinder their efficiency. In particular, they still train a large number of parameters, rely on large multimodal pretraining, use encoders (e.g., CLIP) trained on huge image-text datasets, and add significant inference overhead. In addition, most of these approaches have focused on Zero-Shot and In Context Learning, with l
    
[^68]: xCodeEval：一个用于代码理解、生成、翻译和检索的大规模多语言多任务基准

    xCodeEval: A Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and Retrieval. (arXiv:2303.03004v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.03004](http://arxiv.org/abs/2303.03004)

    xCodeEval是一个大规模多语言多任务的基准，用于评估预训练的大型语言模型生成、修复、翻译和检索代码的能力，并解决了以往仅关注特定任务和缺乏训练数据的问题。

    

    解决问题的能力是智能的标志，并且一直是 AI 的目标。能够创建作为问题解决方案的程序的 AI 系统，或者协助开发人员编写程序，都可以提高生产率并使编程更易于访问。最近，预训练的大型语言模型在从自然语言描述生成新代码、修复有问题的代码、在不同语言之间进行代码翻译以及检索相关代码片段方面展示出了令人印象深刻的能力。然而，这些模型的评估通常是分散在仅一个或两个特定任务上，在少数语言、在部分粒度水平（例如函数级别）上进行，并且在许多情况下缺乏适当的训练数据。更为令人担忧的是，在大多数情况下，生成的代码的评估是以仅仅词汇重叠为基础，而不是实际执行，而两段代码段的语义相似性（或等效性）仅取决于它们的“执行相似性”。

    The ability to solve problems is a hallmark of intelligence and has been an enduring goal in AI. AI systems that can create programs as solutions to problems or assist developers in writing programs can increase productivity and make programming more accessible. Recently, pre-trained large language models have shown impressive abilities in generating new codes from natural language descriptions, repairing buggy codes, translating codes between languages, and retrieving relevant code segments. However, the evaluation of these models has often been performed in a scattered way on only one or two specific tasks, in a few languages, at a partial granularity (e.g., function) level and in many cases without proper training data. Even more concerning is that in most cases the evaluation of generated codes has been done in terms of mere lexical overlap rather than actual execution whereas semantic similarity (or equivalence) of two code segments depends only on their ``execution similarity'', 
    
[^69]: 大型语言模型是推理教师

    Large Language Models Are Reasoning Teachers. (arXiv:2212.10071v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10071](http://arxiv.org/abs/2212.10071)

    本文提出了Fine-tune-CoT，一种使用大型模型作为推理教师让较小模型也能进行复杂推理的方法，可以远远优于基于提示的基线方法，在多个任务上进行了评估。此外，该方法还利用教师模型的能力为每个原始样本生成多个不同的原因解释。

    

    最近的研究表明，思维链条提示可以引导语言模型逐步解决复杂的推理任务。然而，基于提示的思维链条方法依赖于像GPT-3 175B这样非常大的模型，这在规模上是不可行的。本文提出了Fine-tune-CoT方法，使用这些大型模型作为推理教师，以让较小的模型也能进行复杂推理，从而使模型尺寸要求减少数个数量级。我们在公共模型和复杂任务上评估了该方法，发现Fine-tune-CoT可以在小型模型中实现实质性的推理能力，远远优于基于提示的基线方法，甚至在许多任务中也优于教师模型。此外，我们扩展了该方法，利用教师模型的能力为每个原始样本生成多个不同的原因解释，从而增强了微调数据。

    Recent works have shown that chain-of-thought (CoT) prompting can elicit language models to solve complex reasoning tasks, step-by-step. However, prompt-based CoT methods are dependent on very large models such as GPT-3 175B which are prohibitive to deploy at scale. In this paper, we use these large models as reasoning teachers to enable complex reasoning in smaller models and reduce model size requirements by several orders of magnitude. We propose Fine-tune-CoT, a method that generates reasoning samples from very large teacher models to fine-tune smaller models. We evaluate our method on a wide range of public models and complex tasks. We find that Fine-tune-CoT enables substantial reasoning capability in small models, far outperforming prompt-based baselines and even the teacher model in many tasks. Additionally, we extend our method by leveraging the teacher model's ability to generate multiple distinct rationales for each original sample. Enriching the fine-tuning data with such d
    
[^70]: LENS：一种可学习的文本简化评估指标

    LENS: A Learnable Evaluation Metric for Text Simplification. (arXiv:2212.09739v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09739](http://arxiv.org/abs/2212.09739)

    本文提出了一种用于文本简化的可学习评估度量标准LENS，通过引入SimpeEval语料库作为人类评估数据集，与现有度量标准相比，LENS对人类判断相关性更好，为评估文本简化的未来进展铺平了道路。

    

    最近，使用现代语言模型训练可学习度量标准已成为自动评估机器翻译的一种有前途的方法。然而，现有的用于文本简化的人类评估数据集只有一些基于单一或过时模型的有限注释，使它们不能适用于这种方法。为解决这些问题，我们引入了SimpEval语料库，其中包括：SimpEval_past，包括对24个过去系统2.4K简化的12K人类评分，以及SimpEval_2022，一个具有挑战性的简化基准，包含了对360个简化，包括GPT-3.5生成文本的1K人类评分。在SimpEval上进行训练，我们提出了一种用于文本简化的可学习评估度量标准LENS。广泛的实证结果表明，LENS与人类判断相关性更好，为评估文本简化的未来进展铺平了道路。我们还引入了Rank和Rate，一种人类评估框架，用于对简化进行排名和评分。

    Training learnable metrics using modern language models has recently emerged as a promising method for the automatic evaluation of machine translation. However, existing human evaluation datasets for text simplification have limited annotations that are based on unitary or outdated models, making them unsuitable for this approach. To address these issues, we introduce the SimpEval corpus that contains: SimpEval_past, comprising 12K human ratings on 2.4K simplifications of 24 past systems, and SimpEval_2022, a challenging simplification benchmark consisting of over 1K human ratings of 360 simplifications including GPT-3.5 generated text. Training on SimpEval, we present LENS, a Learnable Evaluation Metric for Text Simplification. Extensive empirical results show that LENS correlates much better with human judgment than existing metrics, paving the way for future progress in the evaluation of text simplification. We also introduce Rank and Rate, a human evaluation framework that rates si
    
[^71]: 有效的上下文学习的互补解释

    Complementary Explanations for Effective In-Context Learning. (arXiv:2211.13892v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.13892](http://arxiv.org/abs/2211.13892)

    本文研究了解释对于在上下文学习中的作用机制，证明了解释的分解和自然语言表达对于解释的有效性都有贡献；并且指出，不同的解释集可以提高LLMs的性能，因此提出了一种基于最大边际相关性的实例集合方法。

    

    大规模的语言模型(LLMs)在从提示中学习解释方面展现出了显著的能力，但对这些解释的功能或为何有效的理解还有限。本文旨在更好地理解解释在上下文学习中的作用机制。我们首先研究了两个不同因素对具有解释提示性能的影响:计算跟踪(解决方案的分解方式)和用于表达提示的自然语言。通过在三个受控任务上扰动解释，我们表明两个因素都有助于解释的有效性。我们进一步研究了如何形成最大有效解释集以解决给定的测试查询。我们发现，LLMs可以从解释集的互补性中受益:不同示例展示的多样推理技能可以提高性能。因此，我们提出了一种基于最大边际相关性的实例集合方法，

    Large language models (LLMs) have exhibited remarkable capabilities in learning from explanations in prompts, but there has been limited understanding of exactly how these explanations function or why they are effective. This work aims to better understand the mechanisms by which explanations are used for in-context learning. We first study the impact of two different factors on the performance of prompts with explanations: the computation trace (the way the solution is decomposed) and the natural language used to express the prompt. By perturbing explanations on three controlled tasks, we show that both factors contribute to the effectiveness of explanations. We further study how to form maximally effective sets of explanations for solving a given test query. We find that LLMs can benefit from the complementarity of the explanation set: diverse reasoning skills shown by different exemplars can lead to better performance. Therefore, we propose a maximal marginal relevance-based exempla
    
[^72]: 基于Transformer的统一孟加拉多分类情感语料库文本分类

    Transformer-based Text Classification on Unified Bangla Multi-class Emotion Corpus. (arXiv:2210.06405v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.06405](http://arxiv.org/abs/2210.06405)

    该论文针对孟加拉语这一低资源语言，提出了基于Transformer的模型进行情感分类的方法。该模型在统一孟加拉多分类情感语料库（UBMEC）上的表现优于多个最先进的模型。

    

    情感分类在研究人们对各种Web 2.0服务的想法方面非常重要。现有研究主要集中在英语上，对低资源语言的研究较少。虽然近年来情感分析，特别是英语中的情感分类已经受到了很多关注，但在孟加拉语这样世界上最流行的语言的情况下却没有进行太多的研究。我们提出了一套完整的方法来识别和提取孟加拉语文本中的情感。我们使用基于Transformer的模型从孟加拉语词汇中构建了一个六类（愤怒、厌恶、害怕、喜悦、悲伤和惊讶）的情感分类器，在最近取得了惊人的结果，尤其是对于高资源语言。我们使用“统一孟加拉多分类情感语料库（UBMEC）”来评估我们模型的性能。UBMEC通过结合两个先前发布的基于机器学习的孟加拉语情感语料库而创建，其中包含超过16,000个孟加拉文本样本。我们提出的模型在准确度、精确度、召回率和F1分数方面优于多个最先进的模型。

    Because of its importance in studying people's thoughts on various Web 2.0 services, emotion classification (EC) is an important undertaking. Existing research, on the other hand, is mostly focused on the English language, with little work on low-resource languages. Though sentiment analysis, particularly the EC in English, has received a lot of attention in recent years, little study has been done in the context of Bangla, one of the world's most widely spoken languages. We propose a complete set of approaches for identifying and extracting emotions from Bangla texts in this research. We provide a Bangla emotion classifier for six classes (anger, disgust, fear, joy, sadness, and surprise) from Bangla words, using transformer-based models which exhibit phenomenal results in recent days, especially for high resource languages. The "Unified Bangla Multi-class Emotion Corpus (UBMEC)" is used to assess the performance of our models. UBMEC was created by combining two previously released ma
    
[^73]: HELP ME THINK：一种帮助非专家使用模型创建定制内容的简单提示策略

    HELP ME THINK: A Simple Prompting Strategy for Non-experts to Create Customized Content with Models. (arXiv:2208.08232v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2208.08232](http://arxiv.org/abs/2208.08232)

    HELP ME THINK是一种帮助非专家用户创建定制化内容的简单提示策略，利用GPT3提出相关问题和利用用户答案执行任务，适用于各种需要重要思考的任务。

    

    控制语言模型生成的文本并定制内容一直是一个长期存在的挑战。现有的提示技术提出了为了提供控制而特定于任务的方法，并缺乏一般性；这为非专业用户找到适合其任务的方法提供了压倒性的选择。这些技术所涉及的工作，如编写示例、解释、指令等，进一步限制了它们在非专业用户中的采用率。在本文中，我们提出了一种名为HELP ME THINK的简单提示策略，鼓励GPT3通过提出一组相关问题和利用用户的答案来执行任务来帮助非专家用户。我们展示了我们的技术HELP ME THINK在各种任务上的功效。具体来说，我们关注难以完成且需要重要思考的任务。我们希望我们的工作将鼓励开发非传统的方式来利用大型语言模型的力量。

    Controlling the text generated by language models and customizing the content has been a long-standing challenge. Existing prompting techniques proposed in pursuit of providing control are task-specific and lack generality; this provides overwhelming choices for non-expert users to find a suitable method for their task. The effort associated with those techniques, such as in writing examples, explanations, instructions, etc. further limits their adoption among non-expert users. In this paper, we propose a simple prompting strategy HELP ME THINK where we encourage GPT3 to help non-expert users by asking a set of relevant questions and leveraging user answers to execute the task. We demonstrate the efficacy of our technique HELP ME THINK on a variety of tasks. Specifically, we focus on tasks that are hard for average humans and require significant thinking to perform. We hope our work will encourage the development of unconventional ways to harness the power of large language models.
    
[^74]: 高度重叠文本的情境化语义距离

    Contextualized Semantic Distance between Highly Overlapped Texts. (arXiv:2110.01176v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2110.01176](http://arxiv.org/abs/2110.01176)

    本文旨在解决自然语言处理任务中，覆盖文本之间语义距离评估的传统挑战。通过掩码和预测策略，本文提出了邻近分布散度（NDD）来表示重叠部分的语义距离。实验结果表明，NDD对于各种语义差异更为敏感。

    

    在文本编辑和语义相似性评估等自然语言处理任务中，文本之间经常会出现重叠。更好地评估重叠句子之间的语义距离有助于语言系统的理解并指导生成。由于传统的语义度量基于单词表示，它们容易受到具有类似表示的重叠部分的干扰。本文旨在通过掩码和预测策略解决这个问题。我们将最长公共序列（LCS）中的单词作为邻近单词，并使用来自预训练语言模型（PLMs）的掩码语言建模（MLM）来预测其位置上的分布。我们的度量指标，即邻近分布散度（NDD），通过计算重叠部分中分布之间的差异来表示语义距离。在语义文本相似性测试中，实验证明NDD对于各种语义差异更为敏感，

    Overlapping frequently occurs in paired texts in natural language processing tasks like text editing and semantic similarity evaluation. Better evaluation of the semantic distance between the overlapped sentences benefits the language system's understanding and guides the generation. Since conventional semantic metrics are based on word representations, they are vulnerable to the disturbance of overlapped components with similar representations. This paper aims to address the issue with a mask-and-predict strategy. We take the words in the longest common sequence (LCS) as neighboring words and use masked language modeling (MLM) from pre-trained language models (PLMs) to predict the distributions on their positions. Our metric, Neighboring Distribution Divergence (NDD), represent the semantic distance by calculating the divergence between distributions in the overlapped parts. Experiments on Semantic Textual Similarity show NDD to be more sensitive to various semantic differences, espec
    
[^75]: 一种三元神经模型用于动态实体相关性排名

    A Trio Neural Model for Dynamic Entity Relatedness Ranking. (arXiv:1808.08316v4 [cs.IR] UPDATED)

    [http://arxiv.org/abs/1808.08316](http://arxiv.org/abs/1808.08316)

    这篇论文提出了一种基于神经网络的方法，通过动态评估实体相关性，利用集体注意作为监督，能学习到丰富而不同的实体表示，能在大规模数据集上比竞争基线获得更好的结果。

    

    测量实体相关性是许多自然语言处理和信息检索应用的基本任务。之前的研究通常在静态设置和非监督方式下研究实体相关性。然而，现实世界中的实体往往涉及许多不同的关系，因此实体关系随时间变得非常动态。在这项工作中，我们提出了一种基于神经网络的方法来动态评估实体相关性，利用集体注意力作为监督。我们的模型能够在联合框架中学习丰富而不同的实体表示。通过对大规模数据集的广泛实验，我们证明了我们的方法比竞争基线获得了更好的结果。

    Measuring entity relatedness is a fundamental task for many natural language processing and information retrieval applications. Prior work often studies entity relatedness in static settings and an unsupervised manner. However, entities in real-world are often involved in many different relationships, consequently entity-relations are very dynamic over time. In this work, we propose a neural networkbased approach for dynamic entity relatedness, leveraging the collective attention as supervision. Our model is capable of learning rich and different entity representations in a joint framework. Through extensive experiments on large-scale datasets, we demonstrate that our method achieves better results than competitive baselines.
    

