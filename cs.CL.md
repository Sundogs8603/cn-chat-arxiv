# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Qwen-VL: A Frontier Large Vision-Language Model with Versatile Abilities.](http://arxiv.org/abs/2308.12966) | Qwen-VL是一种具有多功能能力的前沿大规模视觉-语言模型，它在图像字幕生成、问题回答、视觉定位和灵活交互等任务中表现出卓越性能，优于现有的大规模视觉-语言模型。它在推动多模态人工智能方面做出了重要贡献。 |
| [^2] | [Code Llama: Open Foundation Models for Code.](http://arxiv.org/abs/2308.12950) | Code Llama是一系列用于代码的开放基础模型，具有最先进的性能和填充功能，支持大型输入上下文和零-shot指令跟踪能力。在多个代码基准测试中，Code Llama达到开放模型中最高的性能，同时Python专门化模型在某些测试上超越了Llama 2的70B版本。 |
| [^3] | [Diagnosing Infeasible Optimization Problems Using Large Language Models.](http://arxiv.org/abs/2308.12923) | 本文提出了OptiChat，一种基于自然语言的系统，用于诊断不可行的优化模型。它可以帮助从业人员理解和解释不可行的优化模型，无需具备深厚的优化背景知识。 |
| [^4] | [Can Linguistic Knowledge Improve Multimodal Alignment in Vision-Language Pretraining?.](http://arxiv.org/abs/2308.12898) | 本论文研究了语言知识在多模态对齐中的作用，设计并发布了一个多模态对齐探测基准来检测关键的语言组成部分。 |
| [^5] | [Beyond Document Page Classification: Design, Datasets, and Challenges.](http://arxiv.org/abs/2308.12896) | 本文强调了将文档分类基准测试更接近于现实世界应用的需求，通过提出多页文档分类数据集和不同分类任务，以及高效的多页文档表示，来解决现有基准测试不适用于实际完整文档评估的问题。 |
| [^6] | [Large Language Models Vote: Prompting for Rare Disease Identification.](http://arxiv.org/abs/2308.12890) | 本文提出了一种名为模型投票提示(MVP)的方法，用于改善在少样本学习(FSL)环境下大型语言模型(LLMs)的查询性能。MVP通过提示多个LLMs执行相同的任务，并对生成的输出进行多数投票，从而实现了对罕见病的识别和分类任务的改进。 |
| [^7] | [Inducing Causal Structure for Abstractive Text Summarization.](http://arxiv.org/abs/2308.12888) | 该论文提出了一种使用结构性因果模型来诱导抽象文本摘要中的因果结构的方法。通过引入因果关系，可以缓解训练数据中语言先验的干扰，进而提高摘要模型的效果。研究者还设计了一个因果启发式的序列到序列模型来学习因果表示，以指导摘要生成过程。 |
| [^8] | [DS4DH at #SMM4H 2023: Zero-Shot Adverse Drug Events Normalization using Sentence Transformers and Reciprocal-Rank Fusion.](http://arxiv.org/abs/2308.12877) | 本文介绍了DS4DH在#SMM4H 2023中开发的不良药物事件规范化系统的性能评估，该系统利用句子转换和倒数排名融合进行零样本规范化。实验结果表明该方法在共享任务中表现优异，可有效应用于社交媒体文本挖掘中的不良药物事件规范化。 |
| [^9] | [Text Similarity from Image Contents using Statistical and Semantic Analysis Techniques.](http://arxiv.org/abs/2308.12842) | 该论文介绍了使用统计和语义分析技术从图像内容中进行文本相似性检测的方法，以解决抄袭问题。这种技术不仅覆盖了语义、命名实体、释义等NLP方法，还利用图像内容处理技术来识别图像内容的抄袭实例，确保图像内容的完整性。 |
| [^10] | [Use of LLMs for Illicit Purposes: Threats, Prevention Measures, and Vulnerabilities.](http://arxiv.org/abs/2308.12833) | 本研究回顾了有关大型语言模型（LLMs）的威胁和漏洞的现有科学努力，并提供了一种描述这些威胁、预防措施和由于预防措施不完善而产生的漏洞之间关系的分类。 |
| [^11] | [WavMark: Watermarking for Audio Generation.](http://arxiv.org/abs/2308.12770) | WavMark是一种创新的音频水印技术，可以在短短1秒的音频片段中编码多达32位的水印，对人类感官无感知并且具有强大的韧性。它可以用于合成声音的有效识别和音频版权保护。 |
| [^12] | [Real-time Detection of AI-Generated Speech for DeepFake Voice Conversion.](http://arxiv.org/abs/2308.12734) | 该研究创建了DEEP-VOICE数据集，并通过统计分析和机器学习模型实现了实时检测AI生成语音的目标，以应对DeepFake语音转换带来的道德和隐私问题。 |
| [^13] | [Harnessing the Power of David against Goliath: Exploring Instruction Data Generation without Using Closed-Source Models.](http://arxiv.org/abs/2308.12711) | 本文研究了不依赖闭源模型的方法生成高质量的指令数据，以应对使用闭源模型带来的潜在风险。在探索中，我们将现有的指令生成方法进行了调查，并将效率最高的方法与两种新颖的方法相结合。 |
| [^14] | [Improving Translation Faithfulness of Large Language Models via Augmenting Instructions.](http://arxiv.org/abs/2308.12674) | 通过增强指令来提高大型语言模型的翻译真实性，我们提出了SWIE（分段加权指令嵌入）和一个指令遵循数据集OVERMISS，用于改善模型对指令的理解和提高模型的真实性。 |
| [^15] | [From Chatter to Matter: Addressing Critical Steps of Emotion Recognition Learning in Task-oriented Dialogue.](http://arxiv.org/abs/2308.12648) | 本文提出了一个框架，将闲聊情感识别模型转变为任务导向型，并在数据、特征和目标三方面进行了关键改进。结果表明，该框架在任务导向对话中取得了显著的成果。 |
| [^16] | [Probabilistic Method of Measuring Linguistic Productivity.](http://arxiv.org/abs/2308.12643) | 本文提出了一种新的方法，通过随机组合词缀和词根来衡量语言生产力，避免了对词频的直接依赖。该算法在英语和俄语数据上评估，并提供了关于词缀和词根关系的有价值见解。 |
| [^17] | [Advancing Hungarian Text Processing with HuSpaCy: Efficient and Accurate NLP Pipelines.](http://arxiv.org/abs/2308.12635) | 本文介绍了一套工业级匈牙利文本处理模型，利用HuSpaCy框架实现，通过多项改进在资源效率和准确性之间取得了接近最先进的性能。这些模型具备高准确性和吞吐量，并在所有基本文本处理步骤中展示了竞争性能。 |
| [^18] | [PromptMRG: Diagnosis-Driven Prompts for Medical Report Generation.](http://arxiv.org/abs/2308.12604) | PromptMRG是一种针对医学报告生成的诊断驱动方法，通过诊断感知的提示来提高MRG的诊断准确性。这种方法基于编码器-解码器架构，并具有额外的疾病分类分支。 |
| [^19] | [Mind vs. Mouth: On Measuring Re-judge Inconsistency of Social Bias in Large Language Models.](http://arxiv.org/abs/2308.12578) | 本文研究了大型语言模型中的社会偏见，并发现了一种名为“重新判断不一致性”的现象，即在完成陈述和重新评判过程中存在矛盾。这对于理解语言模型的认知和隐含偏见具有重要意义。 |
| [^20] | [A Small and Fast BERT for Chinese Medical Punctuation Restoration.](http://arxiv.org/abs/2308.12568) | 该论文提出了一种用于中文医学标点修复的快速小型BERT模型。通过结合监督对比学习和辅助预训练任务，该模型在具有较小模型大小的情况下，能够实现与最先进的中文RoBERTa模型相当的95%性能。 |
| [^21] | [CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias.](http://arxiv.org/abs/2308.12539) | CALM是一个用于量化语言模型偏见的多任务基准数据集，相比先前数据集更加多样和可靠，能更好地捕捉评估模型偏见所需的语言变化的广度。 |
| [^22] | [CARE: Co-Attention Network for Joint Entity and Relation Extraction.](http://arxiv.org/abs/2308.12531) | 本论文提出了一种用于联合实体和关系抽取的共同注意力网络（CARE），通过学习分离表示和双向交互来解决特征混淆和子任务交互不足的问题，实验表明该模型在多个基准数据集上具有优越性能。 |
| [^23] | [Large Language Model as Autonomous Decision Maker.](http://arxiv.org/abs/2308.12519) | 本文提出了一种方法JuDec，为大型语言模型(LLMs)赋予了自我判断的能力，使其能够作为自主决策者实现自主判断和决策探索。实验结果显示JuDec在不同任务上表现优异，提高了通过率并降低了成本。 |
| [^24] | [MultiPA: a multi-task speech pronunciation assessment system for a closed and open response scenario.](http://arxiv.org/abs/2308.12490) | MultiPA是一种适用于闭合和开放响应场景的多任务语音发音评估系统，相比之前的系统，它具有更简单的格式要求和更好的兼容性，并且提供了更广泛的评估范围。 |
| [^25] | [GPTEval: A Survey on Assessments of ChatGPT and GPT-4.](http://arxiv.org/abs/2308.12488) | 本文对ChatGPT和GPT-4的先前评估进行了综合分析，关注其语言和推理能力、科学知识和伦理考虑，提出了几个评估大型语言模型的建议。 |
| [^26] | [American Stories: A Large-Scale Structured Text Dataset of Historical U.S. Newspapers.](http://arxiv.org/abs/2308.12477) | 这项研究开发了一种新颖的深度学习流水线，用于从历史美国报纸图像中提取完整的文章文本，以解决现有数据集中布局识别和OCR质量的问题。通过构建高效的架构，实现了高扩展性，并创建了高质量的数据集，可用于预训练大型语言模型，并提升对历史英语和历史世界知识的理解。 |
| [^27] | [Are ChatGPT and GPT-4 Good Poker Players? -- A Pre-Flop Analysis.](http://arxiv.org/abs/2308.12466) | ChatGPT和GPT-4在扑克中显示出高级理解，但不是游戏论理最优的扑克玩家。对模型参数和提示的优化可以提高它们在扑克中的表现。 |
| [^28] | [Evolution of ESG-focused DLT Research: An NLP Analysis of the Literature.](http://arxiv.org/abs/2308.12420) | 本研究通过NLP分析了ESG主导的DLT研究的演化，通过构建引用网络和命名实体识别任务，对DLT在ESG背景下的发展进行了文献综述。 |
| [^29] | [Toward American Sign Language Processing in the Real World: Data, Tasks, and Methods.](http://arxiv.org/abs/2308.12419) | 本论文研究了在现实世界中的自动手语处理，提供了新的数据集、任务和方法，并解决了手指拼写识别问题。 |
| [^30] | [With a Little Help from your own Past: Prototypical Memory Networks for Image Captioning.](http://arxiv.org/abs/2308.12383) | 本文提出了一种典型记忆网络，用于提取图像的语义并生成语义连贯的描述。通过在处理其他训练样本时执行注意力操作，该网络能够利用先前激活的信息。实验证明，该模型在COCO数据集上的性能优于其他基准模型和最先进方法。 |
| [^31] | [Inferring gender from name: a large scale performance evaluation study.](http://arxiv.org/abs/2308.12381) | 本研究评估了从姓名中推断性别的性能，该方法在没有性别信息的情况下是一种可行且广泛应用的方法。其重要性在于研究各种科学学科中对性别差异的模式和决定因素进行分析。 |
| [^32] | [Vision Transformer Adapters for Generalizable Multitask Learning.](http://arxiv.org/abs/2308.12372) | 该论文介绍了一种使用适配器的视觉变换器，用于可泛化的多任务学习，可以在无需重新训练或微调的情况下解决多个密集视觉任务，并且在零样本任务迁移、无监督域自适应和泛化到新领域时具有更好的性能。 |
| [^33] | [Halo: Estimation and Reduction of Hallucinations in Open-Source Weak Large Language Models.](http://arxiv.org/abs/2308.11764) | 本文介绍了一种用于评估和减少开源弱大语言模型中幻觉问题的框架，并探索了知识注入和师生方法等技术来减轻低参数模型中的幻觉问题，实验结果表明，在挑战性领域中，这些模型的幻觉问题得到了减少。 |
| [^34] | [SeamlessM4T-Massively Multilingual & Multimodal Machine Translation.](http://arxiv.org/abs/2308.11596) | 本文介绍了SeamlessM4T，这是一个支持多语言和多模态机器翻译的模型，通过使用大量语音数据和自监督学习，实现了统一的语音到语音翻译、语音到文本翻译、文本到语音翻译和文本到文本翻译，以及自动语音识别的功能。 |
| [^35] | [DiagGPT: An LLM-based Chatbot with Automatic Topic Management for Task-Oriented Dialogue.](http://arxiv.org/abs/2308.08043) | DiagGPT将大型语言模型(LLMs)扩展到任务导向的对话场景，提供了在复杂诊断场景中主动提问和引导用户完成任务的能力。 |
| [^36] | [Natural Language is All a Graph Needs.](http://arxiv.org/abs/2308.07134) | 本论文提出了一种名为InstructGLM的结构化语言模型算法，该算法将大型语言模型与图表学习问题相结合，旨在探索是否可以用语言模型取代图神经网络作为图表的基础模型。 |
| [^37] | [A Massive Scale Semantic Similarity Dataset of Historical English.](http://arxiv.org/abs/2306.17810) | 本研究利用重新数字化的无版权美国本地报纸文章，构建了一个大规模的跨越了70年的语义相似性数据集，并包含近4亿个正向语义相似性对。 |
| [^38] | [Evaluation of ChatGPT on Biomedical Tasks: A Zero-Shot Comparison with Fine-Tuned Generative Transformers.](http://arxiv.org/abs/2306.04504) | 本文评估了ChatGPT在生物医学任务上的表现，发现在生物数据集训练样本较小时，零样例ChatGPT甚至优于精调生成式变压器模型。由此表明ChatGPT具有在生物医学领域成为有价值工具的潜力。 |
| [^39] | [Structure-CLIP: Enhance Multi-modal Language Representations with Structure Knowledge.](http://arxiv.org/abs/2305.06152) | Structure-CLIP使用文本中的结构化知识，使用场景图强化多模态语言表示，从而在图像-文本匹配任务中展现了更好的性能。 |
| [^40] | [Improving Semantic Matching through Dependency-Enhanced Pre-trained Model with Adaptive Fusion.](http://arxiv.org/abs/2210.08471) | 本文提出了一种依赖增强的自适应融合注意力模型，它将依赖信息与原始语义信号自适应融合，以更好地模拟复杂的语义匹配关系。 |
| [^41] | [Automatic Speech Recognition for Speech Assessment of Persian Preschool Children.](http://arxiv.org/abs/2203.12886) | 通过在自动语音识别系统中添加随机频率变调目标，我们改进了对波斯语学前儿童言语评估的准确性。 |
| [^42] | [A Survey of Controllable Text Generation using Transformer-based Pre-trained Language Models.](http://arxiv.org/abs/2201.05337) | 这篇论文综述了基于Transformer预训练语言模型的可控文本生成方法。这些方法利用大规模预训练语言模型生成多样化、流畅的文本，但由于深度神经网络的可解释性较低，需要保证其可控性。 |

# 详细

[^1]: Qwen-VL: 一种具有多功能能力的前沿大规模视觉-语言模型

    Qwen-VL: A Frontier Large Vision-Language Model with Versatile Abilities. (arXiv:2308.12966v1 [cs.CV])

    [http://arxiv.org/abs/2308.12966](http://arxiv.org/abs/2308.12966)

    Qwen-VL是一种具有多功能能力的前沿大规模视觉-语言模型，它在图像字幕生成、问题回答、视觉定位和灵活交互等任务中表现出卓越性能，优于现有的大规模视觉-语言模型。它在推动多模态人工智能方面做出了重要贡献。

    

    我们引入了一系列名为Qwen-VL的大规模视觉-语言模型，旨在感知和理解文本和图像。包括Qwen-VL和Qwen-VL-Chat，这些模型在图像字幕生成、问题回答、视觉定位和灵活交互等任务中表现出卓越的性能。评估范围涵盖了零样本字幕生成、视觉或文档视觉问题回答和 grounding 等各种任务。我们证明了Qwen-VL比现有的大规模视觉-语言模型（LVLMs）表现更优异。我们展示了它们的架构、训练方法、能力和性能，并突出了它们在推动多模态人工智能方面的贡献。代码、演示和模型可以在https://github.com/QwenLM/Qwen-VL找到。

    We introduce the Qwen-VL series, a set of large-scale vision-language models designed to perceive and understand both text and images. Comprising Qwen-VL and Qwen-VL-Chat, these models exhibit remarkable performance in tasks like image captioning, question answering, visual localization, and flexible interaction. The evaluation covers a wide range of tasks including zero-shot captioning, visual or document visual question answering, and grounding. We demonstrate the Qwen-VL outperforms existing Large Vision Language Models (LVLMs). We present their architecture, training, capabilities, and performance, highlighting their contributions to advancing multimodal artificial intelligence. Code, demo and models are available at https://github.com/QwenLM/Qwen-VL.
    
[^2]: Code Llama: 用于代码的开放基础模型

    Code Llama: Open Foundation Models for Code. (arXiv:2308.12950v1 [cs.CL])

    [http://arxiv.org/abs/2308.12950](http://arxiv.org/abs/2308.12950)

    Code Llama是一系列用于代码的开放基础模型，具有最先进的性能和填充功能，支持大型输入上下文和零-shot指令跟踪能力。在多个代码基准测试中，Code Llama达到开放模型中最高的性能，同时Python专门化模型在某些测试上超越了Llama 2的70B版本。

    

    我们发布了Code Llama，这是一系列基于Llama 2的用于代码的大型语言模型，具有开放模型中最先进的性能，填充功能，支持大型输入上下文，并且能够进行零-shot指令跟踪编程任务。我们提供多种版本以覆盖广泛的应用场景：基础模型（Code Llama），Python专门化模型（Code Llama-Python），以及指令跟踪模型（Code Llama-Instruct），每个模型参数分别为7B、13B和34B。所有模型都是在16k标记序列上训练的，可以改善长度不超过100k标记的输入。7B和13B的Code Llama和Code Llama-Instruct变种会根据周围内容进行填充。Code Llama在几个代码基准测试中达到了开放模型中最先进的性能，HumanEval和MBPP分别达到了53%和55%的分数。值得注意的是，Code Llama-Python 7B在HumanEval和MBPP上优于Llama 2 70B，而我们的所有模型都优于其他任何模型。

    We release Code Llama, a family of large language models for code based on Llama 2 providing state-of-the-art performance among open models, infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks. We provide multiple flavors to cover a wide range of applications: foundation models (Code Llama), Python specializations (Code Llama - Python), and instruction-following models (Code Llama - Instruct) with 7B, 13B and 34B parameters each. All models are trained on sequences of 16k tokens and show improvements on inputs with up to 100k tokens. 7B and 13B Code Llama and Code Llama - Instruct variants support infilling based on surrounding content. Code Llama reaches state-of-the-art performance among open models on several code benchmarks, with scores of up to 53% and 55% on HumanEval and MBPP, respectively. Notably, Code Llama - Python 7B outperforms Llama 2 70B on HumanEval and MBPP, and all our models outperform every othe
    
[^3]: 使用大型语言模型诊断不可行的优化问题

    Diagnosing Infeasible Optimization Problems Using Large Language Models. (arXiv:2308.12923v1 [cs.HC])

    [http://arxiv.org/abs/2308.12923](http://arxiv.org/abs/2308.12923)

    本文提出了OptiChat，一种基于自然语言的系统，用于诊断不可行的优化模型。它可以帮助从业人员理解和解释不可行的优化模型，无需具备深厚的优化背景知识。

    

    决策问题可以被表示为数学优化模型，在经济学、工程学与制造业、交通运输和医疗保健等领域有广泛应用。优化模型是在满足一组要求或约束条件的情况下做出最佳决策的数学抽象。部署这些模型的主要障碍之一是帮助从业人员理解和解释这些模型，特别是当它们是不可行的，也就是说没有决策满足所有的约束条件。现有的诊断不可行优化模型的方法往往依赖于专家系统，需要在优化方面具有重要的背景知识。在本文中，我们介绍了OptiChat，这是一种首创的基于自然语言的系统，配备了一个与聊天机器人进行交互式对话的GUI，用于讨论不可行的优化模型。OptiChat可以提供对优化模型的自然语言描述。

    Decision-making problems can be represented as mathematical optimization models, finding wide applications in fields such as economics, engineering and manufacturing, transportation, and health care. Optimization models are mathematical abstractions of the problem of making the best decision while satisfying a set of requirements or constraints. One of the primary barriers to deploying these models in practice is the challenge of helping practitioners understand and interpret such models, particularly when they are infeasible, meaning no decision satisfies all the constraints. Existing methods for diagnosing infeasible optimization models often rely on expert systems, necessitating significant background knowledge in optimization. In this paper, we introduce OptiChat, a first-of-its-kind natural language-based system equipped with a chatbot GUI for engaging in interactive conversations about infeasible optimization models. OptiChat can provide natural language descriptions of the optim
    
[^4]: 语言知识能改进视觉-语言预训练中的多模态对齐吗？

    Can Linguistic Knowledge Improve Multimodal Alignment in Vision-Language Pretraining?. (arXiv:2308.12898v1 [cs.MM])

    [http://arxiv.org/abs/2308.12898](http://arxiv.org/abs/2308.12898)

    本论文研究了语言知识在多模态对齐中的作用，设计并发布了一个多模态对齐探测基准来检测关键的语言组成部分。

    

    多媒体领域对通过多模态预训练神经网络模型感知和表达物理世界展现出了强烈的兴趣，其中视觉-语言相关的研究是当前最吸引人的话题之一。然而，目前对以下两个问题的探索非常有限：1）在视觉-语言预训练中是否可以提取关键的语言知识（如语义和句法），2）这种语言知识如何影响或增强多模态对齐。因此，本文旨在阐明全面的语言知识，包括语义表达和句法结构，对多模态对齐的影响。具体而言，我们设计并发布了SNARE，第一个大规模的多模态对齐探测基准，来检测关键的语言组成部分，如词汇、语义和句法知识，包含了四个任务：语义结构、否定逻辑、属性归属和关系组合。基于我们的实验结果，我们证明了.....

    The multimedia community has shown a significant interest in perceiving and representing the physical world with multimodal pretrained neural network models, and among them, the visual-language pertaining (VLP) is, currently, the most captivating topic. However, there have been few endeavors dedicated to the exploration of 1) whether essential linguistic knowledge (e.g., semantics and syntax) can be extracted during VLP, and 2) how such linguistic knowledge impact or enhance the multimodal alignment. In response, here we aim to elucidate the impact of comprehensive linguistic knowledge, including semantic expression and syntactic structure, on multimodal alignment. Specifically, we design and release the SNARE, the first large-scale multimodal alignment probing benchmark, to detect the vital linguistic components, e.g., lexical, semantic, and syntax knowledge, containing four tasks: Semantic structure, Negation logic, Attribute ownership, and Relationship composition. Based on our prop
    
[^5]: 超越文档页分类：设计、数据集和挑战

    Beyond Document Page Classification: Design, Datasets, and Challenges. (arXiv:2308.12896v1 [cs.CV])

    [http://arxiv.org/abs/2308.12896](http://arxiv.org/abs/2308.12896)

    本文强调了将文档分类基准测试更接近于现实世界应用的需求，通过提出多页文档分类数据集和不同分类任务，以及高效的多页文档表示，来解决现有基准测试不适用于实际完整文档评估的问题。

    

    本文强调了将文档分类基准测试更接近于现实世界应用的需求，即在测试数据的性质上（$X$：多通道、多页、多行业；$Y$：类别分布和标签集的多样性）和考虑的分类任务上（$f$：多页文档、页面流和文档捆绑分类，...）。我们确定了公共的多页文档分类数据集的缺乏，并规范了应用场景中产生的不同分类任务，并激发了以高效的多页文档表示为目标的价值。对提出的多页文档分类数据集进行的实验研究表明，当前的基准测试已经变得无关紧要，并需要更新以评估实际中自然发生的完整文档。这个现实情况检查也呼吁更成熟的评估方法，涵盖校准评估、推理复杂性（时间-内存）和一系列现实分散情况。

    This paper highlights the need to bring document classification benchmarking closer to real-world applications, both in the nature of data tested ($X$: multi-channel, multi-paged, multi-industry; $Y$: class distributions and label set variety) and in classification tasks considered ($f$: multi-page document, page stream, and document bundle classification, ...). We identify the lack of public multi-page document classification datasets, formalize different classification tasks arising in application scenarios, and motivate the value of targeting efficient multi-page document representations. An experimental study on proposed multi-page document classification datasets demonstrates that current benchmarks have become irrelevant and need to be updated to evaluate complete documents, as they naturally occur in practice. This reality check also calls for more mature evaluation methodologies, covering calibration evaluation, inference complexity (time-memory), and a range of realistic distr
    
[^6]: 大型语言模型的投票：用于罕见病识别的提示

    Large Language Models Vote: Prompting for Rare Disease Identification. (arXiv:2308.12890v1 [cs.CL])

    [http://arxiv.org/abs/2308.12890](http://arxiv.org/abs/2308.12890)

    本文提出了一种名为模型投票提示(MVP)的方法，用于改善在少样本学习(FSL)环境下大型语言模型(LLMs)的查询性能。MVP通过提示多个LLMs执行相同的任务，并对生成的输出进行多数投票，从而实现了对罕见病的识别和分类任务的改进。

    

    生成式大型语言模型(LLMs)的出现强调了准确和高效的提示方法的需求。LLMs经常应用于少样本学习(FSL)的情境中，这里任务只使用很少的训练数据执行。FSL在许多人工智能(AI)子领域中变得流行，包括用于健康的AI。罕见病影响人口的一小部分，在数据可用性受限的情况下 inherently 需要FSL技术，尽管人工数据收集和标注费时费力。在本文中，我们提出了模型投票提示(MVP)，这是一种用于改善FSL环境中LLM查询性能的灵活提示方法。MVP通过提示多个LLMs执行相同的任务，然后对生成的输出进行多数投票来实现。该方法在单次罕见病识别和分类任务中相对于任何单个模型在集成模型中实现了改进的结果。我们还发布了一个新颖的罕见病数据集用于FSL。

    The emergence of generative Large Language Models (LLMs) emphasizes the need for accurate and efficient prompting approaches. LLMs are often applied in Few-Shot Learning (FSL) contexts, where tasks are executed with minimal training data. FSL has become popular in many Artificial Intelligence (AI) subdomains, including AI for health. Rare diseases, affecting a small fraction of the population, inherently require FSL techniques due to limited data availability, though manual data collection and annotation is costly and time-consuming. In this paper, we propose Models-Vote Prompting (MVP), a flexible prompting approach for improving the performance of LLM queries in FSL settings. MVP works by prompting numerous LLMs to perform the same tasks and then conducting a majority vote on the resulting outputs. This method achieves improved results to any one model in the ensemble on one-shot rare disease identification and classification tasks. We also release a novel rare disease dataset for FS
    
[^7]: 诱导因果结构进行抽象文本摘要

    Inducing Causal Structure for Abstractive Text Summarization. (arXiv:2308.12888v1 [cs.CL])

    [http://arxiv.org/abs/2308.12888](http://arxiv.org/abs/2308.12888)

    该论文提出了一种使用结构性因果模型来诱导抽象文本摘要中的因果结构的方法。通过引入因果关系，可以缓解训练数据中语言先验的干扰，进而提高摘要模型的效果。研究者还设计了一个因果启发式的序列到序列模型来学习因果表示，以指导摘要生成过程。

    

    数据驱动的抽象摘要模型主要探索相关性而非因果关系。在这些相关性中，可能存在受训练语料库中的语言先验干扰的伪相关性，从而削弱了学习模型的整体效果。为解决这个问题，我们引入了一个结构性因果模型（SCM）来诱导摘要数据的潜在因果结构。我们假设存在几个潜在的因果因素和非因果因素，分别表示文档和摘要的内容和风格。理论上，我们证明了在某些条件下，我们的SCM中的潜在因素可以通过拟合观察到的训练数据来识别出来。基于此，我们提出了一个因果启发式的序列到序列模型（CI-Seq2Seq），用于学习能够模拟因果因素的因果表示，指导我们获取用于生成摘要的因果信息。关键思想是重新构造Va模型，以引入因果关系。

    The mainstream of data-driven abstractive summarization models tends to explore the correlations rather than the causal relationships. Among such correlations, there can be spurious ones which suffer from the language prior learned from the training corpus and therefore undermine the overall effectiveness of the learned model. To tackle this issue, we introduce a Structural Causal Model (SCM) to induce the underlying causal structure of the summarization data. We assume several latent causal factors and non-causal factors, representing the content and style of the document and summary. Theoretically, we prove that the latent factors in our SCM can be identified by fitting the observed training data under certain conditions. On the basis of this, we propose a Causality Inspired Sequence-to-Sequence model (CI-Seq2Seq) to learn the causal representations that can mimic the causal factors, guiding us to pursue causal information for summary generation. The key idea is to reformulate the Va
    
[^8]: DS4DH在#SMM4H 2023上：使用句子转换和倒数排名融合进行零样本不良药物事件规范化

    DS4DH at #SMM4H 2023: Zero-Shot Adverse Drug Events Normalization using Sentence Transformers and Reciprocal-Rank Fusion. (arXiv:2308.12877v1 [cs.CL])

    [http://arxiv.org/abs/2308.12877](http://arxiv.org/abs/2308.12877)

    本文介绍了DS4DH在#SMM4H 2023中开发的不良药物事件规范化系统的性能评估，该系统利用句子转换和倒数排名融合进行零样本规范化。实验结果表明该方法在共享任务中表现优异，可有效应用于社交媒体文本挖掘中的不良药物事件规范化。

    

    本文概述了由数据科学与数字健康团队开发的用于社交媒体挖掘健康应用2023共享任务5的不良药物事件规范化系统的性能评估。共享任务5旨在将Twitter中的不良药物事件提及标准化为医疗法规活动术语字典中的标准概念。我们的系统采用两阶段方法：BERT微调实体识别，然后使用句子转换和倒数排名融合进行零样本规范化。该方法的精确度为44.9%，召回率为40.5%，F1分数为42.6%。它的性能超过了共享任务5中位数表现10%，并在所有参与者中展示了最高性能。这些结果证实了我们方法的有效性和在社交媒体文本挖掘领域中进行不良药物事件规范化的潜在应用。

    This paper outlines the performance evaluation of a system for adverse drug event normalization, developed by the Data Science for Digital Health group for the Social Media Mining for Health Applications 2023 shared task 5. Shared task 5 targeted the normalization of adverse drug event mentions in Twitter to standard concepts from the Medical Dictionary for Regulatory Activities terminology. Our system hinges on a two-stage approach: BERT fine-tuning for entity recognition, followed by zero-shot normalization using sentence transformers and reciprocal-rank fusion. The approach yielded a precision of 44.9%, recall of 40.5%, and an F1-score of 42.6%. It outperformed the median performance in shared task 5 by 10% and demonstrated the highest performance among all participants. These results substantiate the effectiveness of our approach and its potential application for adverse drug event normalization in the realm of social media text mining.
    
[^9]: 使用统计和语义分析技术从图像内容中进行文本相似性检测

    Text Similarity from Image Contents using Statistical and Semantic Analysis Techniques. (arXiv:2308.12842v1 [cs.CL])

    [http://arxiv.org/abs/2308.12842](http://arxiv.org/abs/2308.12842)

    该论文介绍了使用统计和语义分析技术从图像内容中进行文本相似性检测的方法，以解决抄袭问题。这种技术不仅覆盖了语义、命名实体、释义等NLP方法，还利用图像内容处理技术来识别图像内容的抄袭实例，确保图像内容的完整性。

    

    抄袭检测是自然语言处理（NLP）社区中最研究的领域之一。良好的抄袭检测涵盖了所有的NLP方法，包括语义、命名实体、释义等，并生成详细的抄袭报告。跨语言抄袭的检测需要深入了解各种高级方法和算法，以进行有效的文本相似性检查。现今的抄袭者也在提升自己，以避免被发现。他们使用改写、同义词替换、引文不匹配、不同语言的翻译等技术来规避检测。图像内容抄袭检测（ICPD）得到了重视，利用先进的图像内容处理技术来识别抄袭实例，以确保图像内容的完整性。抄袭问题不仅限于文本内容，图片如图表、图形等也具有潜在的抄袭风险。

    Plagiarism detection is one of the most researched areas among the Natural Language Processing(NLP) community. A good plagiarism detection covers all the NLP methods including semantics, named entities, paraphrases etc. and produces detailed plagiarism reports. Detection of Cross Lingual Plagiarism requires deep knowledge of various advanced methods and algorithms to perform effective text similarity checking. Nowadays the plagiarists are also advancing themselves from hiding the identity from being catch in such offense. The plagiarists are bypassed from being detected with techniques like paraphrasing, synonym replacement, mismatching citations, translating one language to another. Image Content Plagiarism Detection (ICPD) has gained importance, utilizing advanced image content processing to identify instances of plagiarism to ensure the integrity of image content. The issue of plagiarism extends beyond textual content, as images such as figures, graphs, and tables also have the pote
    
[^10]: 使用LLMs进行非法目的：威胁、预防措施和漏洞

    Use of LLMs for Illicit Purposes: Threats, Prevention Measures, and Vulnerabilities. (arXiv:2308.12833v1 [cs.CL])

    [http://arxiv.org/abs/2308.12833](http://arxiv.org/abs/2308.12833)

    本研究回顾了有关大型语言模型（LLMs）的威胁和漏洞的现有科学努力，并提供了一种描述这些威胁、预防措施和由于预防措施不完善而产生的漏洞之间关系的分类。

    

    近年来，大型语言模型（LLMs）在工业和学术界的快速发展和分发引起了人们的关注，许多最近的研究都关注了LLMs的安全和安全相关威胁和漏洞，包括在潜在的犯罪活动中。具体来说，已经表明LLMs可以被滥用用于欺诈、冒充和生成恶意软件；而其他作者则考虑了AI对齐的更一般的问题。开发人员和从业人员都需要意识到这些模型的安全问题的存在。在本文中，我们概述了现有的主要是科学努力，以确定和减轻由LLMs引起的威胁和漏洞。我们提供了一个描述由LLMs的生成能力引起的威胁、预防措施以及由于预防措施不完善而产生的漏洞的分类。

    Spurred by the recent rapid increase in the development and distribution of large language models (LLMs) across industry and academia, much recent work has drawn attention to safety- and security-related threats and vulnerabilities of LLMs, including in the context of potentially criminal activities. Specifically, it has been shown that LLMs can be misused for fraud, impersonation, and the generation of malware; while other authors have considered the more general problem of AI alignment. It is important that developers and practitioners alike are aware of security-related problems with such models. In this paper, we provide an overview of existing - predominantly scientific - efforts on identifying and mitigating threats and vulnerabilities arising from LLMs. We present a taxonomy describing the relationship between threats caused by the generative capabilities of LLMs, prevention measures intended to address such threats, and vulnerabilities arising from imperfect prevention measures
    
[^11]: WavMark：用于音频生成的水印技术

    WavMark: Watermarking for Audio Generation. (arXiv:2308.12770v1 [cs.SD])

    [http://arxiv.org/abs/2308.12770](http://arxiv.org/abs/2308.12770)

    WavMark是一种创新的音频水印技术，可以在短短1秒的音频片段中编码多达32位的水印，对人类感官无感知并且具有强大的韧性。它可以用于合成声音的有效识别和音频版权保护。

    

    最近在零-shot语音合成方面的突破使得只用几秒钟的录音就能模仿说话者的声音，并且保持高度的真实感。除了潜在的好处之外，这项强大的技术还带来了明显的风险，包括语音欺诈和冒充说话者。与仅依赖被动方法来检测合成数据的传统方法不同，水印技术提供了一种积极且强大的防御机制来应对这些潜在风险。本文介绍了一种创新的音频水印技术框架，可以在仅1秒的音频片段中编码多达32位的水印。水印对人类感官来说是无法察觉的，并且对各种攻击表现出强大的韧性。它可以作为合成声音的有效标识符，并在音频版权保护的更广泛应用中具有潜力。此外，这个框架具有很高的灵活性，可以将多个水印片段进行组合以实现更加丰富的功能。

    Recent breakthroughs in zero-shot voice synthesis have enabled imitating a speaker's voice using just a few seconds of recording while maintaining a high level of realism. Alongside its potential benefits, this powerful technology introduces notable risks, including voice fraud and speaker impersonation. Unlike the conventional approach of solely relying on passive methods for detecting synthetic data, watermarking presents a proactive and robust defence mechanism against these looming risks. This paper introduces an innovative audio watermarking framework that encodes up to 32 bits of watermark within a mere 1-second audio snippet. The watermark is imperceptible to human senses and exhibits strong resilience against various attacks. It can serve as an effective identifier for synthesized voices and holds potential for broader applications in audio copyright protection. Moreover, this framework boasts high flexibility, allowing for the combination of multiple watermark segments to achi
    
[^12]: 实时检测AI生成的语音用于DeepFake语音转换

    Real-time Detection of AI-Generated Speech for DeepFake Voice Conversion. (arXiv:2308.12734v1 [cs.SD])

    [http://arxiv.org/abs/2308.12734](http://arxiv.org/abs/2308.12734)

    该研究创建了DEEP-VOICE数据集，并通过统计分析和机器学习模型实现了实时检测AI生成语音的目标，以应对DeepFake语音转换带来的道德和隐私问题。

    

    在语音领域中，生成型AI技术使得语音克隆和实时语音转换成为可能，这带来了一系列潜在的道德问题，包括隐私侵犯和虚假陈述。因此，我们亟需一种能够实时检测AI生成语音的方法来应对DeepFake语音转换。为此，我们创建了DEEP-VOICE数据集，其中包含了八位知名人物的真实语音和他们之间相互转换后的语音。通过对语音真实性进行二分类，通过t检验对时间音频特征进行了统计分析，发现其分布存在显著差异。使用超参数优化来对机器学习模型进行训练，以识别语音的来源。

    There are growing implications surrounding generative AI in the speech domain that enable voice cloning and real-time voice conversion from one individual to another. This technology poses a significant ethical threat and could lead to breaches of privacy and misrepresentation, thus there is an urgent need for real-time detection of AI-generated speech for DeepFake Voice Conversion. To address the above emerging issues, the DEEP-VOICE dataset is generated in this study, comprised of real human speech from eight well-known figures and their speech converted to one another using Retrieval-based Voice Conversion. Presenting as a binary classification problem of whether the speech is real or AI-generated, statistical analysis of temporal audio features through t-testing reveals that there are significantly different distributions. Hyperparameter optimisation is implemented for machine learning models to identify the source of speech. Following the training of 208 individual machine learnin
    
[^13]: 发挥大卫对战歌利亚的力量：探索不使用闭源模型的指令数据生成

    Harnessing the Power of David against Goliath: Exploring Instruction Data Generation without Using Closed-Source Models. (arXiv:2308.12711v1 [cs.CL])

    [http://arxiv.org/abs/2308.12711](http://arxiv.org/abs/2308.12711)

    本文研究了不依赖闭源模型的方法生成高质量的指令数据，以应对使用闭源模型带来的潜在风险。在探索中，我们将现有的指令生成方法进行了调查，并将效率最高的方法与两种新颖的方法相结合。

    

    指令调整对于使大规模语言模型（LLMs）能够按照用户的指令完成各种开放领域任务至关重要。指令调整的成功依赖于高质量的指令数据的可用性。由于人工注释的高昂成本和质量不佳，最近的研究一直在深入探索利用强大的闭源模型自动生成指令数据。然而，这些方法存在潜在的风险，因为强大的闭源模型的使用要求严禁利用它们的输出来开发机器学习模型。为了解决这个问题，在这项工作中，我们探索了不依赖闭源模型的替代方法来生成高质量的指令数据。我们的探索包括对各种现有的指令生成方法的研究，最终将效率最高的变体与两种新颖的方法进行整合。

    Instruction tuning is instrumental in enabling Large Language Models~(LLMs) to follow user instructions to complete various open-domain tasks. The success of instruction tuning depends on the availability of high-quality instruction data. Owing to the exorbitant cost and substandard quality of human annotation, recent works have been deeply engaged in the exploration of the utilization of powerful closed-source models to generate instruction data automatically. However, these methods carry potential risks arising from the usage requirements of powerful closed-source models, which strictly forbid the utilization of their outputs to develop machine learning models. To deal with this problem, in this work, we explore alternative approaches to generate high-quality instruction data that do not rely on closed-source models. Our exploration includes an investigation of various existing instruction generation methods, culminating in the integration of the most efficient variant with two novel
    
[^14]: 通过增强指令来提高大型语言模型的翻译真实性

    Improving Translation Faithfulness of Large Language Models via Augmenting Instructions. (arXiv:2308.12674v1 [cs.CL])

    [http://arxiv.org/abs/2308.12674](http://arxiv.org/abs/2308.12674)

    通过增强指令来提高大型语言模型的翻译真实性，我们提出了SWIE（分段加权指令嵌入）和一个指令遵循数据集OVERMISS，用于改善模型对指令的理解和提高模型的真实性。

    

    大型语言模型(LLMs)具有很强的通用能力，目前一个引人注目的挑战是通过低成本的指令调整来激发它们的专门能力，如机器翻译。标准的指令遵循数据是按顺序组织的，包括指令、输入和响应的连接。由于LLMs的注意机制在局部关注上存在局限性，LLMs倾向于在每个位置更多地关注附近的单词或句子。这导致在解码过程中遗忘指令的风险很高。为了缓解上述问题，我们提出了SWIE（分段加权指令嵌入）和一个指令遵循数据集OVERMISS。SWIE通过在后续的输入和响应表示上添加全局指令表示来改善模型对指令的理解。OVERMISS通过将过度翻译和遗漏翻译结果与正确翻译进行比较来提高模型的真实性。我们将我们的方法应用到两个主要的翻译任务中。

    Large Language Models (LLMs) present strong general capabilities, and a current compelling challenge is stimulating their specialized capabilities, such as machine translation, through low-cost instruction tuning. The standard instruction-following data is sequentially organized as the concatenation of an instruction, an input, and a response. As the attention mechanism of LLMs has limitations on local focus, LLMs tend to focus more on the words or sentences nearby at each position. This leads to a high risk of instruction forgetting during decoding. To alleviate the above issues, We propose SWIE (Segment-Weighted Instruction Embedding) and an instruction-following dataset OVERMISS. SWIE improves the model instruction understanding by adding a global instruction representation on the following input and response representations. OVERMISS improves model faithfulness by comparing over-translation and miss-translation results with the correct translation. We apply our methods to two main-
    
[^15]: 从聊天到实质：解决任务导向对话中情感识别学习的关键步骤

    From Chatter to Matter: Addressing Critical Steps of Emotion Recognition Learning in Task-oriented Dialogue. (arXiv:2308.12648v1 [cs.CL])

    [http://arxiv.org/abs/2308.12648](http://arxiv.org/abs/2308.12648)

    本文提出了一个框架，将闲聊情感识别模型转变为任务导向型，并在数据、特征和目标三方面进行了关键改进。结果表明，该框架在任务导向对话中取得了显著的成果。

    

    对话中的情感识别（ERC）是构建类似人类对话代理的关键任务。尽管在闲聊对话方面已经做出了大量努力，但任务导向的对话中的ERC仍然几乎没有得到关注。直接将闲聊ERC模型应用于任务导向的对话（ToDs）会导致性能不佳，因为这些模型忽视了ToDs中情感与任务完成之间的关联。在本文中，我们提出了一个框架，将闲聊ERC模型转变为任务导向型，解决了三个关键方面：数据、特征和目标。首先，我们设计了两种增加罕见情感的方法来提高ERC性能。其次，我们使用对话状态作为辅助特征，将用户目标的关键信息整合进来。最后，我们利用ToDs中的多方面情感定义，设计了一个多任务学习目标和一种新颖的情感距离加权损失函数。我们的框架取得了显著的成果。

    Emotion recognition in conversations (ERC) is a crucial task for building human-like conversational agents. While substantial efforts have been devoted to ERC for chit-chat dialogues, the task-oriented counterpart is largely left unattended. Directly applying chit-chat ERC models to task-oriented dialogues (ToDs) results in suboptimal performance as these models overlook key features such as the correlation between emotions and task completion in ToDs. In this paper, we propose a framework that turns a chit-chat ERC model into a task-oriented one, addressing three critical aspects: data, features and objective. First, we devise two ways of augmenting rare emotions to improve ERC performance. Second, we use dialogue states as auxiliary features to incorporate key information from the goal of the user. Lastly, we leverage a multi-aspect emotion definition in ToDs to devise a multi-task learning objective and a novel emotion-distance weighted loss function. Our framework yields significan
    
[^16]: 随机方法评估语言生产力

    Probabilistic Method of Measuring Linguistic Productivity. (arXiv:2308.12643v1 [cs.CL])

    [http://arxiv.org/abs/2308.12643](http://arxiv.org/abs/2308.12643)

    本文提出了一种新的方法，通过随机组合词缀和词根来衡量语言生产力，避免了对词频的直接依赖。该算法在英语和俄语数据上评估，并提供了关于词缀和词根关系的有价值见解。

    

    本文提出了一种新的衡量语言生产力的方法，该方法客观评估了一个词缀用于构建新复杂词的能力，与其他常用的衡量方法不同的是，它不直接依赖于词频。具体而言，作者建议将语言生产力视为一个词缀与随机词根组合的概率。这种方法的优势包括：首先，词频不会主导生产力的衡量，而是自然地影响基础样本的抽样。其次，我们不仅仅是计算带有词缀的已验证词汇类型，而是模拟构造这些类型，然后检查它们是否出现在语料库中。第三，以语料库为基础的方法和随机设计确保真正的新词和早期构词具有相等的选择机会。所提出的算法在英语和俄语数据上进行了评估。所得结果为我们提供了一些有价值的见解，涉及词缀与词根的关系。

    In this paper I propose a new way of measuring linguistic productivity that objectively assesses the ability of an affix to be used to coin new complex words and, unlike other popular measures, is not directly dependent upon token frequency. Specifically, I suggest that linguistic productivity may be viewed as the probability of an affix to combine with a random base. The advantages of this approach include the following. First, token frequency does not dominate the productivity measure but naturally influences the sampling of bases. Second, we are not just counting attested word types with an affix but rather simulating the construction of these types and then checking whether they are attested in the corpus. Third, a corpus-based approach and randomised design assure that true neologisms and words coined long ago have equal chances to be selected. The proposed algorithm is evaluated both on English and Russian data. The obtained results provide some valuable insights into the relatio
    
[^17]: 使用HuSpaCy推进匈牙利文本处理：高效准确的自然语言处理管道

    Advancing Hungarian Text Processing with HuSpaCy: Efficient and Accurate NLP Pipelines. (arXiv:2308.12635v1 [cs.CL])

    [http://arxiv.org/abs/2308.12635](http://arxiv.org/abs/2308.12635)

    本文介绍了一套工业级匈牙利文本处理模型，利用HuSpaCy框架实现，通过多项改进在资源效率和准确性之间取得了接近最先进的性能。这些模型具备高准确性和吞吐量，并在所有基本文本处理步骤中展示了竞争性能。

    

    本文介绍了一套用于匈牙利文本处理的工业级模型，这些模型在资源效率和准确性之间取得了接近最先进的性能。这些模型是基于spaCy框架实现的，在HuSpaCy工具包的架构上进行了多个改进。与现有的匈牙利语自然语言处理工具相比，我们所有的管道都具备包括标记化、句子边界检测、词性标注、词形特征标注、词形还原、依存句法分析和命名实体识别在内的所有基本文本处理步骤，并且具有高准确性和高吞吐量。我们对提出的改进进行了全面评估，将管道与最先进的工具进行了比较，并在所有文本预处理步骤中展示了新模型的竞争性能。所有实验都可以重现，并且这些管道可以免费使用并采用宽松的许可证。

    This paper presents a set of industrial-grade text processing models for Hungarian that achieve near state-of-the-art performance while balancing resource efficiency and accuracy. Models have been implemented in the spaCy framework, extending the HuSpaCy toolkit with several improvements to its architecture. Compared to existing NLP tools for Hungarian, all of our pipelines feature all basic text processing steps including tokenization, sentence-boundary detection, part-of-speech tagging, morphological feature tagging, lemmatization, dependency parsing and named entity recognition with high accuracy and throughput. We thoroughly evaluated the proposed enhancements, compared the pipelines with state-of-the-art tools and demonstrated the competitive performance of the new models in all text preprocessing steps. All experiments are reproducible and the pipelines are freely available under a permissive license.
    
[^18]: PromptMRG: 诊断驱动的医学报告生成方法

    PromptMRG: Diagnosis-Driven Prompts for Medical Report Generation. (arXiv:2308.12604v1 [cs.CV])

    [http://arxiv.org/abs/2308.12604](http://arxiv.org/abs/2308.12604)

    PromptMRG是一种针对医学报告生成的诊断驱动方法，通过诊断感知的提示来提高MRG的诊断准确性。这种方法基于编码器-解码器架构，并具有额外的疾病分类分支。

    

    自动医学报告生成(MRG)具有很大的研究价值，因为它有潜力减轻放射科医生报告撰写的负担。尽管近年来取得了一些进展，但准确的MRG仍然具有挑战性，因为需要精确的临床理解和临床结果的识别。此外，疾病的不平衡分布使这一挑战更加突出，因为在训练数据中罕见疾病的比例较少，使得它们的诊断性能不可靠。为了解决这些挑战，我们提出了一种诊断驱动的医学报告生成方法(PromptMRG)，这是一种旨在通过诊断感知的提示来提高MRG诊断准确性的新框架。具体而言，PromptMRG基于编码器-解码器架构，有一个额外的疾病分类分支。在生成报告时，从分类分支得到的诊断结果被转化为标记提示，以明确地指导生成过程。

    Automatic medical report generation (MRG) is of great research value as it has the potential to relieve radiologists from the heavy burden of report writing. Despite recent advancements, accurate MRG remains challenging due to the need for precise clinical understanding and the identification of clinical findings. Moreover, the imbalanced distribution of diseases makes the challenge even more pronounced, as rare diseases are underrepresented in training data, making their diagnostic performance unreliable. To address these challenges, we propose diagnosis-driven prompts for medical report generation (PromptMRG), a novel framework that aims to improve the diagnostic accuracy of MRG with the guidance of diagnosis-aware prompts. Specifically, PromptMRG is based on encoder-decoder architecture with an extra disease classification branch. When generating reports, the diagnostic results from the classification branch are converted into token prompts to explicitly guide the generation process
    
[^19]: 理智对话声音：关于在大型语言模型中测量社会偏见的重新判断不一致性的论文

    Mind vs. Mouth: On Measuring Re-judge Inconsistency of Social Bias in Large Language Models. (arXiv:2308.12578v1 [cs.CL])

    [http://arxiv.org/abs/2308.12578](http://arxiv.org/abs/2308.12578)

    本文研究了大型语言模型中的社会偏见，并发现了一种名为“重新判断不一致性”的现象，即在完成陈述和重新评判过程中存在矛盾。这对于理解语言模型的认知和隐含偏见具有重要意义。

    

    最近的研究表明，预训练的大型语言模型(LLMs)具有与人类观察到的认知结构相似的特点，促使研究人员调查LLMs的认知方面。本文着重研究了明确和隐含的社会偏见，这是心理学中一种独特的两级认知结构。文中提出，个体的明确社会偏见，即其在陈述中表达的有意识偏见，可能与其隐含的社会偏见不同，后者代表其无意识偏见。我们提出了一个两阶段的方法，并发现LLMs中的一种并行现象，即社会偏见中的“重新判断不一致性”。在初始阶段，LLM负责自动完成陈述，可能会包含隐含的社会偏见。然而，在随后的阶段，同样的LLM重新评判了其自动生成的有偏见的陈述，但却与之相矛盾。我们提出，这种重新判断的不一致性可能类似于人类不知道其偏见的一致性。

    Recent researches indicate that Pre-trained Large Language Models (LLMs) possess cognitive constructs similar to those observed in humans, prompting researchers to investigate the cognitive aspects of LLMs. This paper focuses on explicit and implicit social bias, a distinctive two-level cognitive construct in psychology. It posits that individuals' explicit social bias, which is their conscious expression of bias in the statements, may differ from their implicit social bias, which represents their unconscious bias. We propose a two-stage approach and discover a parallel phenomenon in LLMs known as "re-judge inconsistency" in social bias. In the initial stage, the LLM is tasked with automatically completing statements, potentially incorporating implicit social bias. However, in the subsequent stage, the same LLM re-judges the biased statement generated by itself but contradicts it. We propose that this re-judge inconsistency can be similar to the inconsistency between human's unaware im
    
[^20]: 用于中文医学标点修复的小型快速BERT模型

    A Small and Fast BERT for Chinese Medical Punctuation Restoration. (arXiv:2308.12568v1 [cs.CL])

    [http://arxiv.org/abs/2308.12568](http://arxiv.org/abs/2308.12568)

    该论文提出了一种用于中文医学标点修复的快速小型BERT模型。通过结合监督对比学习和辅助预训练任务，该模型在具有较小模型大小的情况下，能够实现与最先进的中文RoBERTa模型相当的95%性能。

    

    在临床听写中，没有明确标点符号的自动语音识别（ASR）导致了对听写报告的误解。为了使用ASR提供精确和易懂的临床报告，需要进行自动标点修复。考虑到实际情况，我们提出了一种基于“预训练和微调”范式的快速轻量级预训练模型，用于中文医学标点修复。在这项工作中，我们通过结合监督对比学习和一种新颖的辅助预训练任务（标点符号预测）来提炼预训练模型，使其适用于标点修复。我们在各种提炼模型上的实验表明，相对于最先进的中文RoBERTa模型，我们的模型可以在10%的模型大小的情况下实现95%的性能。

    In clinical dictation, utterances after automatic speech recognition (ASR) without explicit punctuation marks may lead to the misunderstanding of dictated reports. To give a precise and understandable clinical report with ASR, automatic punctuation restoration is required. Considering a practical scenario, we propose a fast and light pre-trained model for Chinese medical punctuation restoration based on 'pretraining and fine-tuning' paradigm. In this work, we distill pre-trained models by incorporating supervised contrastive learning and a novel auxiliary pre-training task (Punctuation Mark Prediction) to make it well-suited for punctuation restoration. Our experiments on various distilled models reveal that our model can achieve 95% performance while 10% model size relative to state-of-the-art Chinese RoBERTa.
    
[^21]: CALM: 一种用于全面评估语言模型偏见的多任务基准数据集

    CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias. (arXiv:2308.12539v1 [cs.CL])

    [http://arxiv.org/abs/2308.12539](http://arxiv.org/abs/2308.12539)

    CALM是一个用于量化语言模型偏见的多任务基准数据集，相比先前数据集更加多样和可靠，能更好地捕捉评估模型偏见所需的语言变化的广度。

    

    随着语言模型（LMs）的不断增强，量化和比较它们在社会和人口学偏见方面的能力以及潜在的危害变得越来越重要。先前的偏见测量数据集对于人工设计模板的扰动敏感，因此不可靠。为了保证可靠性，我们引入了全面评估语言模型偏见（CALM）的基准数据集，用于量化LMs在三个任务上的偏见。我们整合了来自不同领域（如维基百科和新闻文章）的16个现有数据集，过滤出224个模板，并构建了一个包含78,400个示例的数据集。我们通过平均语义相似性和模板长度的变异程度等指标，比较CALM与先前数据集的多样性，并测试其对细微扰动的敏感性。我们展示了我们的数据集相对于先前数据集更加多样和可靠，因此能更好地捕捉评估模型偏见所需的语言变化的广度。我们评估了20个大型语言模型的偏见。

    As language models (LMs) become increasingly powerful, it is important to quantify and compare them for sociodemographic bias with potential for harm. Prior bias measurement datasets are sensitive to perturbations in their manually designed templates, therefore unreliable. To achieve reliability, we introduce the Comprehensive Assessment of Language Model bias (CALM), a benchmark dataset to quantify bias in LMs across three tasks. We integrate 16 existing datasets across different domains, such as Wikipedia and news articles, to filter 224 templates from which we construct a dataset of 78,400 examples. We compare the diversity of CALM with prior datasets on metrics such as average semantic similarity, and variation in template length, and test the sensitivity to small perturbations. We show that our dataset is more diverse and reliable than previous datasets, thus better capture the breadth of linguistic variation required to reliably evaluate model bias. We evaluate 20 large language 
    
[^22]: CARE: 用于联合实体和关系抽取的共同注意力网络

    CARE: Co-Attention Network for Joint Entity and Relation Extraction. (arXiv:2308.12531v1 [cs.CL])

    [http://arxiv.org/abs/2308.12531](http://arxiv.org/abs/2308.12531)

    本论文提出了一种用于联合实体和关系抽取的共同注意力网络（CARE），通过学习分离表示和双向交互来解决特征混淆和子任务交互不足的问题，实验表明该模型在多个基准数据集上具有优越性能。

    

    联合实体和关系抽取是信息抽取的基本任务，包括两个子任务：命名实体识别和关系抽取。大多数现有的联合抽取方法都存在特征混淆或两个子任务之间交互不足的问题。在这项工作中，我们提出了一种用于联合实体和关系抽取的共同注意力网络（CARE）。我们的方法涉及学习每个子任务的分离表示，旨在避免特征重叠。我们的方法的核心是共同注意力模块，它捕捉两个子任务之间的双向交互，使模型能够利用实体信息进行关系预测，反之亦然，从而促进相互增强。在三个联合实体-关系抽取基准数据集（NYT、WebNLG和SciERC）上的广泛实验表明，我们提出的模型达到了卓越的性能，超过了现有的基线模型。

    Joint entity and relation extraction is the fundamental task of information extraction, consisting of two subtasks: named entity recognition and relation extraction. Most existing joint extraction methods suffer from issues of feature confusion or inadequate interaction between two subtasks. In this work, we propose a Co-Attention network for joint entity and Relation Extraction (CARE). Our approach involves learning separate representations for each subtask, aiming to avoid feature overlap. At the core of our approach is the co-attention module that captures two-way interaction between two subtasks, allowing the model to leverage entity information for relation prediction and vice versa, thus promoting mutual enhancement. Extensive experiments on three joint entity-relation extraction benchmark datasets (NYT, WebNLG and SciERC) show that our proposed model achieves superior performance, surpassing existing baseline models.
    
[^23]: 大型语言模型作为自主决策者

    Large Language Model as Autonomous Decision Maker. (arXiv:2308.12519v1 [cs.CL])

    [http://arxiv.org/abs/2308.12519](http://arxiv.org/abs/2308.12519)

    本文提出了一种方法JuDec，为大型语言模型(LLMs)赋予了自我判断的能力，使其能够作为自主决策者实现自主判断和决策探索。实验结果显示JuDec在不同任务上表现优异，提高了通过率并降低了成本。

    

    虽然大型语言模型(LLMs)展示了令人印象深刻的语言理解和上下文学习能力，但它们在解决现实世界任务时仍严重依赖于专家知识的指导。为了发挥LLMs作为自主决策者的潜力，本文提出了一种称为JuDec的方法，赋予LLMs自我判断的能力，使其能够实现自主判断和决策探索。具体而言，在JuDec中，设计了基于Elo的自我判断机制，通过对两个解决方案进行配对比较，为决策步骤分配Elo分数，以判断它们的价值和效用，并相应地引导决策搜索过程朝向最优解。在ToolBench数据集上的实验结果表明，JuDec相对于基准模型具有优势，在不同任务上的通过率提高了10%以上。它提供了更高质量的解决方案并降低了成本(ChatGPT API调用)。

    While large language models (LLMs) exhibit impressive language understanding and in-context learning abilities, their decision-making ability still heavily relies on the guidance of task-specific expert knowledge when solving real-world tasks. To unleash the potential of LLMs as autonomous decision makers, this paper presents an approach JuDec to endow LLMs with the self-judgment ability, enabling LLMs to achieve autonomous judgment and exploration for decision making. Specifically, in JuDec, Elo-based Self-Judgment Mechanism is designed to assign Elo scores to decision steps to judge their values and utilities via pairwise comparisons between two solutions and then guide the decision-searching process toward the optimal solution accordingly. Experimental results on the ToolBench dataset demonstrate JuDec's superiority over baselines, achieving over 10% improvement in Pass Rate on diverse tasks. It offers higher-quality solutions and reduces costs (ChatGPT API calls), highlighting its 
    
[^24]: MultiPA:一种适用于闭合和开放响应场景的多任务语音发音评估系统

    MultiPA: a multi-task speech pronunciation assessment system for a closed and open response scenario. (arXiv:2308.12490v1 [cs.CL])

    [http://arxiv.org/abs/2308.12490](http://arxiv.org/abs/2308.12490)

    MultiPA是一种适用于闭合和开放响应场景的多任务语音发音评估系统，相比之前的系统，它具有更简单的格式要求和更好的兼容性，并且提供了更广泛的评估范围。

    

    自动语音发音评估系统的设计可以分为闭合和开放响应场景，每种场景都有其优点和局限性。具备在两种场景下都能发挥作用的系统能够满足多样化的学习需求，并提供更精确、全面的发音技能评估。本研究提出了一种名为MultiPA的多任务发音评估模型。MultiPA与基于Kaldi的系统相比，具有更简单的格式要求，更好地兼容其他神经网络模型。与先前的开放响应系统相比，MultiPA提供了更广泛的评估范围，包括句子和单词级别的评估。我们的实验结果表明，MultiPA在闭合响应场景下的性能与先前系统相当，并在直接用于开放响应时保持更稳健的性能。

    The design of automatic speech pronunciation assessment can be categorized into closed and open response scenarios, each with strengths and limitations. A system with the ability to function in both scenarios can cater to diverse learning needs and provide a more precise and holistic assessment of pronunciation skills. In this study, we propose a Multi-task Pronunciation Assessment model called MultiPA. MultiPA provides an alternative to Kaldi-based systems in that it has simpler format requirements and better compatibility with other neural network models. Compared with previous open response systems, MultiPA provides a wider range of evaluations, encompassing assessments at both the sentence and word-level. Our experimental results show that MultiPA achieves comparable performance when working in closed response scenarios and maintains more robust performance when directly used for open responses.
    
[^25]: GPTEval: 对ChatGPT和GPT-4评估的调查

    GPTEval: A Survey on Assessments of ChatGPT and GPT-4. (arXiv:2308.12488v1 [cs.AI])

    [http://arxiv.org/abs/2308.12488](http://arxiv.org/abs/2308.12488)

    本文对ChatGPT和GPT-4的先前评估进行了综合分析，关注其语言和推理能力、科学知识和伦理考虑，提出了几个评估大型语言模型的建议。

    

    ChatGPT的出现引发了媒体对其扰乱社会和经济系统潜力的许多猜测。其惊人的语言能力激起学者们对其在不同领域表现的浓厚兴趣。已经有许多研究评估了ChatGPT和GPT-4在不同任务和学科中的能力。然而，缺乏一项综合性的综述总结集体评估结果。本调查的目标是对ChatGPT和GPT-4的先前评估进行深入分析，重点关注其语言和推理能力、科学知识和伦理考虑。此外，对现有评估方法进行了检查，并提出了几个未来研究评估大型语言模型的建议。

    The emergence of ChatGPT has generated much speculation in the press about its potential to disrupt social and economic systems. Its astonishing language ability has aroused strong curiosity among scholars about its performance in different domains. There have been many studies evaluating the ability of ChatGPT and GPT-4 in different tasks and disciplines. However, a comprehensive review summarizing the collective assessment findings is lacking. The objective of this survey is to thoroughly analyze prior assessments of ChatGPT and GPT-4, focusing on its language and reasoning abilities, scientific knowledge, and ethical considerations. Furthermore, an examination of the existing evaluation methods is conducted, offering several recommendations for future research in evaluating large language models.
    
[^26]: 美国故事：一种基于历史美国报纸的大规模结构化文本数据集

    American Stories: A Large-Scale Structured Text Dataset of Historical U.S. Newspapers. (arXiv:2308.12477v1 [cs.CL])

    [http://arxiv.org/abs/2308.12477](http://arxiv.org/abs/2308.12477)

    这项研究开发了一种新颖的深度学习流水线，用于从历史美国报纸图像中提取完整的文章文本，以解决现有数据集中布局识别和OCR质量的问题。通过构建高效的架构，实现了高扩展性，并创建了高质量的数据集，可用于预训练大型语言模型，并提升对历史英语和历史世界知识的理解。

    

    现有的美国公共领域报纸全文数据集没有识别报纸扫描的复杂布局，结果导致数字化内容对文章、标题、字幕、广告等布局区域的文本进行了混合。光学字符识别（OCR）的质量也可能较低。本研究开发了一种新颖的深度学习流水线，用于从报纸图像中提取完整的文章文本，并将其应用于美国国会图书馆公共领域《慢性美国》集合中的近2000万份扫描。该流水线包括布局检测、可读性分类、自定义OCR和跨多个边界框关联文章文本等步骤。为了实现高扩展性，它采用了专为移动电话设计的高效架构。结果产生的美国故事数据集提供了高质量的数据，可以用于对大型语言模型进行预训练，以实现对历史英语和历史世界知识的更好理解。该数据集还可以添加到...

    Existing full text datasets of U.S. public domain newspapers do not recognize the often complex layouts of newspaper scans, and as a result the digitized content scrambles texts from articles, headlines, captions, advertisements, and other layout regions. OCR quality can also be low. This study develops a novel, deep learning pipeline for extracting full article texts from newspaper images and applies it to the nearly 20 million scans in Library of Congress's public domain Chronicling America collection. The pipeline includes layout detection, legibility classification, custom OCR, and association of article texts spanning multiple bounding boxes. To achieve high scalability, it is built with efficient architectures designed for mobile phones. The resulting American Stories dataset provides high quality data that could be used for pre-training a large language model to achieve better understanding of historical English and historical world knowledge. The dataset could also be added to 
    
[^27]: ChatGPT和GPT-4是优秀的扑克玩家吗？——一项Pre-Flop分析。

    Are ChatGPT and GPT-4 Good Poker Players? -- A Pre-Flop Analysis. (arXiv:2308.12466v1 [cs.CL])

    [http://arxiv.org/abs/2308.12466](http://arxiv.org/abs/2308.12466)

    ChatGPT和GPT-4在扑克中显示出高级理解，但不是游戏论理最优的扑克玩家。对模型参数和提示的优化可以提高它们在扑克中的表现。

    

    自ChatGPT和GPT-4问世以来，这些模型已在许多任务中进行了测试。它们在各个领域的熟练程度是显而易见的，但它们在游戏中的能力，特别是在扑克领域的能力，还未被探索。扑克是一种需要在不确定性和不完全信息下做出决策的游戏。在本文中，我们对ChatGPT和GPT-4进行了扑克测试，并评估了它们的扑克技能。我们的研究结果显示，虽然这两个模型都展示了对扑克的高级理解，包括起始手牌的估值、打牌位置以及游戏论理最优(GTO)扑克的其他复杂性，但ChatGPT和GPT-4并不是游戏论理最优的扑克玩家。通过一系列实验，我们首先发现了与使用这些模型玩扑克相关的最佳提示和模型参数的特征。接着，我们观察到了这两个模型具有不同的打牌风格。最终，我们得出结论：GPT-4是

    Since the introduction of ChatGPT and GPT-4, these models have been tested across a large number of tasks. Their adeptness across domains is evident, but their aptitude in playing games and specifically their aptitude in the realm of poker has remained unexplored. Poker is a game that requires decision making under uncertainty and incomplete information. In this paper, we put ChatGPT and GPT-4 through the poker test and evaluate their poker skills. Our findings reveal that while both models display an advanced understanding of poker, encompassing concepts like the valuation of starting hands, playing positions and other intricacies of game theory optimal (GTO) poker, both ChatGPT and GPT-4 are NOT game theory optimal poker players.  Through a series of experiments, we first discover the characteristics of optimal prompts and model parameters for playing poker with these models. Our observations then unveil the distinct playing personas of the two models. We first conclude that GPT-4 is
    
[^28]: ESG主导的DLT研究的演化：对文献进行NLP分析

    Evolution of ESG-focused DLT Research: An NLP Analysis of the Literature. (arXiv:2308.12420v1 [cs.IR])

    [http://arxiv.org/abs/2308.12420](http://arxiv.org/abs/2308.12420)

    本研究通过NLP分析了ESG主导的DLT研究的演化，通过构建引用网络和命名实体识别任务，对DLT在ESG背景下的发展进行了文献综述。

    

    分布式账本技术(DLT)迅速发展，需要全面了解其各个组成部分。然而，针对DLT的环境、可持续性和治理(ESG)组成部分的系统文献综述还不足。为填补这一空白，我们选择了107篇种子文献，构建了一个包含63,083个参考文献的引用网络，并将其精炼为24,539篇文献的语料库进行分析。然后，我们根据一个已建立的技术分类法从46篇论文中标记了命名实体，并通过找出DLT的ESG要素来完善这个分类法。利用基于transformer的语言模型，我们对一个预先训练的语言模型进行了细化调整，用于命名实体识别任务，使用我们标记的数据集。我们利用我们调整后的语言模型对语料库进行了精简，得到了505篇关键论文，通过命名实体和时间图分析，促进了对DLT在ESG背景下的演化的文献综述。

    Distributed Ledger Technologies (DLTs) have rapidly evolved, necessitating comprehensive insights into their diverse components. However, a systematic literature review that emphasizes the Environmental, Sustainability, and Governance (ESG) components of DLT remains lacking. To bridge this gap, we selected 107 seed papers to build a citation network of 63,083 references and refined it to a corpus of 24,539 publications for analysis. Then, we labeled the named entities in 46 papers according to twelve top-level categories derived from an established technology taxonomy and enhanced the taxonomy by pinpointing DLT's ESG elements. Leveraging transformer-based language models, we fine-tuned a pre-trained language model for a Named Entity Recognition (NER) task using our labeled dataset. We used our fine-tuned language model to distill the corpus to 505 key papers, facilitating a literature review via named entities and temporal graph analysis on DLT evolution in the context of ESG. Our con
    
[^29]: 在现实世界中进行美国手语处理:数据、任务和方法研究。

    Toward American Sign Language Processing in the Real World: Data, Tasks, and Methods. (arXiv:2308.12419v1 [cs.CV])

    [http://arxiv.org/abs/2308.12419](http://arxiv.org/abs/2308.12419)

    本论文研究了在现实世界中的自动手语处理，提供了新的数据集、任务和方法，并解决了手指拼写识别问题。

    

    手语是聋人之间通过手势传达意思的主要交流方式。在自然环境中识别手语面临着诸多挑战，如光照、背景杂乱和手势者特征的变化等。本论文研究了在野外环境中的自动手语处理，使用了从互联网收集的手语视频。本论文提供了新的数据集、任务和方法。大部分章节涉及手指拼写任务，这是手语的重要组成部分，但之前的研究并没有广泛研究。我提出了三个新的大规模手语数据集：ChicagoFSWild、ChicagoFSWild+和OpenASL。使用ChicagoFSWild和ChicagoFSWild+，我解决了手指拼写识别问题，即将手指拼写序列转录为文本。我提出了一种基于迭代注意力的端到端方法，可以从原始视频中识别手指拼写，而不需要显式手部检测。

    Sign language, which conveys meaning through gestures, is the chief means of communication among deaf people. Recognizing sign language in natural settings presents significant challenges due to factors such as lighting, background clutter, and variations in signer characteristics. In this thesis, I study automatic sign language processing in the wild, using signing videos collected from the Internet. This thesis contributes new datasets, tasks, and methods. Most chapters of this thesis address tasks related to fingerspelling, an important component of sign language and yet has not been studied widely by prior work. I present three new large-scale ASL datasets in the wild: ChicagoFSWild, ChicagoFSWild+, and OpenASL. Using ChicagoFSWild and ChicagoFSWild+, I address fingerspelling recognition, which consists of transcribing fingerspelling sequences into text. I propose an end-to-end approach based on iterative attention that allows recognition from a raw video without explicit hand dete
    
[^30]: 通过过去的记忆：用于图像字幕生成的典型记忆网络

    With a Little Help from your own Past: Prototypical Memory Networks for Image Captioning. (arXiv:2308.12383v1 [cs.CV])

    [http://arxiv.org/abs/2308.12383](http://arxiv.org/abs/2308.12383)

    本文提出了一种典型记忆网络，用于提取图像的语义并生成语义连贯的描述。通过在处理其他训练样本时执行注意力操作，该网络能够利用先前激活的信息。实验证明，该模型在COCO数据集上的性能优于其他基准模型和最先进方法。

    

    图像字幕生成是一个涉及视觉和语言的任务，目前依赖于基于Transformer的架构来提取图像的语义并将其转化为语义连贯的描述。尽管成功，但注意力机制只考虑当前输入样本的投影加权求和，因此忽略了来自其他样本的相关语义信息。在本文中，我们设计了一个网络，该网络可以通过典型记忆模型在处理其他训练样本时执行注意力操作。我们的记忆通过原型向量的定义来建模过去的键和值的分布，这些原型向量既具有区分性又紧凑。在实验中，我们将所提出模型与精心设计的基准模型和最先进方法进行比较，并研究每个提出的组件的作用。

    Image captioning, like many tasks involving vision and language, currently relies on Transformer-based architectures for extracting the semantics in an image and translating it into linguistically coherent descriptions. Although successful, the attention operator only considers a weighted summation of projections of the current input sample, therefore ignoring the relevant semantic information which can come from the joint observation of other samples. In this paper, we devise a network which can perform attention over activations obtained while processing other training samples, through a prototypical memory model. Our memory models the distribution of past keys and values through the definition of prototype vectors which are both discriminative and compact. Experimentally, we assess the performance of the proposed model on the COCO dataset, in comparison with carefully designed baselines and state-of-the-art approaches, and by investigating the role of each of the proposed components
    
[^31]: 从姓名中推断性别：一个大规模的性能评估研究

    Inferring gender from name: a large scale performance evaluation study. (arXiv:2308.12381v1 [cs.CL])

    [http://arxiv.org/abs/2308.12381](http://arxiv.org/abs/2308.12381)

    本研究评估了从姓名中推断性别的性能，该方法在没有性别信息的情况下是一种可行且广泛应用的方法。其重要性在于研究各种科学学科中对性别差异的模式和决定因素进行分析。

    

    一个人的性别是在进行医学、社会学、政治学和经济学等各种科学学科的研究时一个至关重要的信息。然而，随着大数据的激增，性别信息的获取变得越来越困难。在这种情况下，研究人员需要从可获得的信息中，主要是从人名中推断性别。尽管通过姓名来推断性别可能引发一些伦理问题，但缺乏可行的替代方法意味着研究人员不得不使用这种方法，当目标使手段合理时-在大多数这类研究中，目标是研究性别差异的模式和决定因素。姓名到性别推断的必要性产生了一个越来越多的算法方法和软件产品的领域。这些方法已经在世界各地的学术界、工业界、政府和非政府组织中使用。

    A person's gender is a crucial piece of information when performing research across a wide range of scientific disciplines, such as medicine, sociology, political science, and economics, to name a few. However, in increasing instances, especially given the proliferation of big data, gender information is not readily available. In such cases researchers need to infer gender from readily available information, primarily from persons' names. While inferring gender from name may raise some ethical questions, the lack of viable alternatives means that researchers have to resort to such approaches when the goal justifies the means - in the majority of such studies the goal is to examine patterns and determinants of gender disparities. The necessity of name-to-gender inference has generated an ever-growing domain of algorithmic approaches and software products. These approaches have been used throughout the world in academia, industry, governmental and non-governmental organizations. Neverthe
    
[^32]: Vision Transformer适配器用于可泛化的多任务学习

    Vision Transformer Adapters for Generalizable Multitask Learning. (arXiv:2308.12372v1 [cs.CV])

    [http://arxiv.org/abs/2308.12372](http://arxiv.org/abs/2308.12372)

    该论文介绍了一种使用适配器的视觉变换器，用于可泛化的多任务学习，可以在无需重新训练或微调的情况下解决多个密集视觉任务，并且在零样本任务迁移、无监督域自适应和泛化到新领域时具有更好的性能。

    

    我们引入了第一个多任务视觉变换器适配器，学习可以应用于新任务和领域的通用任务关联性。将其集成到现成的视觉变换器骨干中，我们的适配器可以以参数有效的方式同时解决多个密集视觉任务，而不像现有的多任务变换器那样具有参数的高昂成本。与并行方法相比，我们不需要在添加新任务或领域时进行重新训练或微调。我们在适配器框架中引入了一个任务自适应的注意机制，将基于梯度的任务相似性与基于注意力的相似性结合起来。学习的任务关联性在以下情况下具有泛化能力：零样本任务迁移，无监督域自适应以及不需要对新领域进行微调的泛化。我们证明了我们的方法不仅胜过现有的基于卷积神经网络的多任务方法，还胜过视觉变换器法。

    We introduce the first multitasking vision transformer adapters that learn generalizable task affinities which can be applied to novel tasks and domains. Integrated into an off-the-shelf vision transformer backbone, our adapters can simultaneously solve multiple dense vision tasks in a parameter-efficient manner, unlike existing multitasking transformers that are parametrically expensive. In contrast to concurrent methods, we do not require retraining or fine-tuning whenever a new task or domain is added. We introduce a task-adapted attention mechanism within our adapter framework that combines gradient-based task similarities with attention-based ones. The learned task affinities generalize to the following settings: zero-shot task transfer, unsupervised domain adaptation, and generalization without fine-tuning to novel domains. We demonstrate that our approach outperforms not only the existing convolutional neural network-based multitasking methods but also the vision transformer-bas
    
[^33]: Halo：评估和降低开源弱大语言模型中的幻觉

    Halo: Estimation and Reduction of Hallucinations in Open-Source Weak Large Language Models. (arXiv:2308.11764v1 [cs.CL])

    [http://arxiv.org/abs/2308.11764](http://arxiv.org/abs/2308.11764)

    本文介绍了一种用于评估和减少开源弱大语言模型中幻觉问题的框架，并探索了知识注入和师生方法等技术来减轻低参数模型中的幻觉问题，实验结果表明，在挑战性领域中，这些模型的幻觉问题得到了减少。

    

    大型语言模型(LLMs)已经彻底改变了自然语言处理(NLP)领域。虽然对于研究和实际应用来说方便，但是与其更大规模的对应模型相比，开源的参数较少的LLMs经常出现严重幻觉问题。本文着重于测量和减少BLOOM 7B中的幻觉问题，该模型是公开提供给研究和商业应用的弱开源LLMs的代表。我们引入了HaloCheck，一种轻量级的无需知识的黑盒子框架，用于量化LLMs中幻觉问题的严重程度。此外，我们探索了知识注入和师生方法等技术，以减轻低参数LLMs中的幻觉问题。我们的实验证明了在这些LLMs的挑战性领域中幻觉问题的减少。

    Large Language Models (LLMs) have revolutionized Natural Language Processing (NLP). Although convenient for research and practical applications, open-source LLMs with fewer parameters often suffer from severe hallucinations compared to their larger counterparts. This paper focuses on measuring and reducing hallucinations in BLOOM 7B, a representative of such weaker open-source LLMs that are publicly available for research and commercial applications. We introduce HaloCheck, a lightweight BlackBox knowledge-free framework designed to quantify the severity of hallucinations in LLMs. Additionally, we explore techniques like knowledge injection and teacher-student approaches to alleviate hallucinations in low-parameter LLMs. Our experiments effectively demonstrate the reduction of hallucinations in challenging domains for these LLMs.
    
[^34]: SeamlessM4T-大规模多语言和多模态机器翻译

    SeamlessM4T-Massively Multilingual & Multimodal Machine Translation. (arXiv:2308.11596v1 [cs.CL])

    [http://arxiv.org/abs/2308.11596](http://arxiv.org/abs/2308.11596)

    本文介绍了SeamlessM4T，这是一个支持多语言和多模态机器翻译的模型，通过使用大量语音数据和自监督学习，实现了统一的语音到语音翻译、语音到文本翻译、文本到语音翻译和文本到文本翻译，以及自动语音识别的功能。

    

    创造一种类似于巴别鱼的工具，能够帮助个人在任意两种语言之间进行语音翻译，需要付出什么样的努力？虽然最近在基于文本的模型方面取得了突破，使机器翻译的覆盖范围超过了200种语言，但统一的语音到语音翻译模型还没有取得类似的进展。更具体地说，传统的语音到语音翻译系统依赖于渐进式的级联系统进行翻译，使高性能的统一系统难以实现。为了弥补这些差距，我们引入了SeamlessM4T，一种支持语音到语音翻译、语音到文本翻译、文本到语音翻译、文本到文本翻译以及自动语音识别的单一模型，支持多达100种语言。为了构建这个模型，我们使用了100万小时的开放式语音音频数据，使用了w2v-BERT 2.0来学习自监督的语音表示。随后，我们创建了一个多模态的自动对齐语音翻译的语料库。

    What does it take to create the Babel Fish, a tool that can help individuals translate speech between any two languages? While recent breakthroughs in text-based models have pushed machine translation coverage beyond 200 languages, unified speech-to-speech translation models have yet to achieve similar strides. More specifically, conventional speech-to-speech translation systems rely on cascaded systems that perform translation progressively, putting high-performing unified systems out of reach. To address these gaps, we introduce SeamlessM4T, a single model that supports speech-to-speech translation, speech-to-text translation, text-to-speech translation, text-to-text translation, and automatic speech recognition for up to 100 languages. To build this, we used 1 million hours of open speech audio data to learn self-supervised speech representations with w2v-BERT 2.0. Subsequently, we created a multimodal corpus of automatically aligned speech translations. Filtered and combined with h
    
[^35]: DiagGPT:一种基于LLM的任务导向对话的聊天机器人

    DiagGPT: An LLM-based Chatbot with Automatic Topic Management for Task-Oriented Dialogue. (arXiv:2308.08043v1 [cs.CL])

    [http://arxiv.org/abs/2308.08043](http://arxiv.org/abs/2308.08043)

    DiagGPT将大型语言模型(LLMs)扩展到任务导向的对话场景，提供了在复杂诊断场景中主动提问和引导用户完成任务的能力。

    

    大型语言模型(LLMs)如ChatGPT正变得越来越复杂，展示出与人类相似的能力。这些AI模型在日常生活中辅助人类完成各种任务方面发挥着重要作用。AI作为聊天代理人的重要应用是回答人类在各个领域的问题。目前的LLMs在回答一般问题方面已经显示出熟练的能力。然而，在复杂的诊断场景(如法律或医疗咨询)中，基本的问答对话往往表现不佳。这些场景通常需要任务导向对话(TOD)，其中AI聊天代理需要主动提问并引导用户完成特定任务。以前的微调模型在TOD方面表现不佳，而当前的LLMs并未固有这种能力。在本文中，我们介绍了一种名为DiagGPT (Diagnosis GPT)的创新方法，它将LLMs推广到TOD场景中。

    Large Language Models (LLMs), such as ChatGPT, are becoming increasingly sophisticated, demonstrating capabilities that closely resemble those of humans. These AI models are playing an essential role in assisting humans with a wide array of tasks in daily life. A significant application of AI is its use as a chat agent, responding to human inquiries across various domains. Current LLMs have shown proficiency in answering general questions. However, basic question-answering dialogue often falls short in complex diagnostic scenarios, such as legal or medical consultations. These scenarios typically necessitate Task-Oriented Dialogue (TOD), wherein an AI chat agent needs to proactively pose questions and guide users towards specific task completion. Previous fine-tuning models have underperformed in TOD, and current LLMs do not inherently possess this capability. In this paper, we introduce DiagGPT (Dialogue in Diagnosis GPT), an innovative method that extends LLMs to TOD scenarios. Our e
    
[^36]: 自然语言是图表所需要的全部内容

    Natural Language is All a Graph Needs. (arXiv:2308.07134v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.07134](http://arxiv.org/abs/2308.07134)

    本论文提出了一种名为InstructGLM的结构化语言模型算法，该算法将大型语言模型与图表学习问题相结合，旨在探索是否可以用语言模型取代图神经网络作为图表的基础模型。

    

    大规模预训练语言模型的出现，如ChatGPT，已经在人工智能的各个研究领域中引起了革命。基于Transformer的大型语言模型（LLMs）逐渐取代了CNN和RNN，将计算机视觉和自然语言处理领域统一起来。与相对独立存在的数据（如图像、视频或文本）相比，图表是一种包含丰富结构和关系信息的数据类型。同时，作为最具表现力的媒介之一，自然语言在描述复杂结构方面表现出色。然而，将图表学习问题纳入生成式语言建模框架的现有工作仍然非常有限。随着大型语言模型的重要性不断增长，探索LLMs是否也可以替代GNNs成为图表的基础模型变得至关重要。在本文中，我们提出了InstructGLM（结构化语言模型）算法，系统地设计高度可扩展的模型来处理图表学习问题。

    The emergence of large-scale pre-trained language models, such as ChatGPT, has revolutionized various research fields in artificial intelligence. Transformers-based large language models (LLMs) have gradually replaced CNNs and RNNs to unify fields of computer vision and natural language processing. Compared with the data that exists relatively independently such as images, videos or texts, graph is a type of data that contains rich structural and relational information. Meanwhile, natural language, as one of the most expressive mediums, excels in describing complex structures. However, existing work on incorporating graph learning problems into the generative language modeling framework remains very limited. As the importance of large language models continues to grow, it becomes essential to explore whether LLMs can also replace GNNs as the foundation model for graphs. In this paper, we propose InstructGLM (Instruction-finetuned Graph Language Model), systematically design highly scal
    
[^37]: 一个历史英语的大规模语义相似性数据集

    A Massive Scale Semantic Similarity Dataset of Historical English. (arXiv:2306.17810v1 [cs.CL])

    [http://arxiv.org/abs/2306.17810](http://arxiv.org/abs/2306.17810)

    本研究利用重新数字化的无版权美国本地报纸文章，构建了一个大规模的跨越了70年的语义相似性数据集，并包含近4亿个正向语义相似性对。

    

    各种任务使用在语义相似性数据上训练的语言模型。虽然有多种数据集可捕捉语义相似性，但它们要么是从现代网络数据构建的，要么是由人工标注员在过去十年中创建的相对较小的数据集。本研究利用一种新颖的来源，即重新数字化的无版权美国本地报纸文章，构建了一个大规模的语义相似性数据集，跨越了1920年到1989年的70年，并包含近4亿个正向语义相似性对。在美国本地报纸中，大约一半的文章来自新闻机构的新闻稿，而本地报纸复制了新闻稿的文章，并撰写了自己的标题，这些标题形成了与文章相关的提取性摘要。我们通过利用文档布局和语言理解将文章和标题关联起来。然后，我们使用深度神经方法来检测哪些文章来自相同的基础来源。

    A diversity of tasks use language models trained on semantic similarity data. While there are a variety of datasets that capture semantic similarity, they are either constructed from modern web data or are relatively small datasets created in the past decade by human annotators. This study utilizes a novel source, newly digitized articles from off-copyright, local U.S. newspapers, to assemble a massive-scale semantic similarity dataset spanning 70 years from 1920 to 1989 and containing nearly 400M positive semantic similarity pairs. Historically, around half of articles in U.S. local newspapers came from newswires like the Associated Press. While local papers reproduced articles from the newswire, they wrote their own headlines, which form abstractive summaries of the associated articles. We associate articles and their headlines by exploiting document layouts and language understanding. We then use deep neural methods to detect which articles are from the same underlying source, in th
    
[^38]: 在生物医学任务上评估ChatGPT：与精调生成式变压器的零样例比较。

    Evaluation of ChatGPT on Biomedical Tasks: A Zero-Shot Comparison with Fine-Tuned Generative Transformers. (arXiv:2306.04504v1 [cs.CL])

    [http://arxiv.org/abs/2306.04504](http://arxiv.org/abs/2306.04504)

    本文评估了ChatGPT在生物医学任务上的表现，发现在生物数据集训练样本较小时，零样例ChatGPT甚至优于精调生成式变压器模型。由此表明ChatGPT具有在生物医学领域成为有价值工具的潜力。

    

    ChatGPT是OpenAI开发的大型语言模型。尽管其在各种任务上表现出色，但先前的工作尚未研究其在生物医学领域的能力。因此，本文旨在评估ChatGPT在各种基准生物医学任务上的性能，如关系提取、文档分类、问答和摘要。据我们所知，这是首次对ChatGPT在生物医学领域进行全面评估的工作。有趣的是，在训练集较小的生物医学数据集中，基于我们的评估结果，零样例ChatGPT甚至优于先进的精调生成式变压器模型，如BioGPT和BioBART。这表明ChatGPT在大型文本语料库上的预训练使其在生物医学领域具有相当的专业性。我们的发现表明，ChatGPT在生物医学领域具有成为各种任务的有价值工具的潜力。

    ChatGPT is a large language model developed by OpenAI. Despite its impressive performance across various tasks, no prior work has investigated its capability in the biomedical domain yet. To this end, this paper aims to evaluate the performance of ChatGPT on various benchmark biomedical tasks, such as relation extraction, document classification, question answering, and summarization. To the best of our knowledge, this is the first work that conducts an extensive evaluation of ChatGPT in the biomedical domain. Interestingly, we find based on our evaluation that in biomedical datasets that have smaller training sets, zero-shot ChatGPT even outperforms the state-of-the-art fine-tuned generative transformer models, such as BioGPT and BioBART. This suggests that ChatGPT's pre-training on large text corpora makes it quite specialized even in the biomedical domain. Our findings demonstrate that ChatGPT has the potential to be a valuable tool for various tasks in the biomedical domain that la
    
[^39]: Structure-CLIP: 结合结构知识优化多模态语言表示

    Structure-CLIP: Enhance Multi-modal Language Representations with Structure Knowledge. (arXiv:2305.06152v1 [cs.CL])

    [http://arxiv.org/abs/2305.06152](http://arxiv.org/abs/2305.06152)

    Structure-CLIP使用文本中的结构化知识，使用场景图强化多模态语言表示，从而在图像-文本匹配任务中展现了更好的性能。

    

    大规模的视觉-语言预训练在各种下游任务中展现出了很好的性能，并在多模态理解和生成任务中取得了显著的进展。然而，现有方法在需要对文本进行详细语义理解的图像-文本匹配任务上通常表现较差。尽管已经有一些研究在解决这个问题，但它们没有充分利用句子中存在的结构化知识来增强多模态语言表示，导致性能较差。本文提出了一个端到端的框架Structure-CLIP，该框架结合了从文本中提取的隐式详细语义，以增强精细的语义表示。具体而言，(1)我们使用场景图来更加关注文本中的详细语义学习，并充分探索细粒度语义之间的结构化知识，(2)我们结合场景图的知识强化框架来充分利用这些信息。

    Large-scale vision-language pre-training has shown promising advances on various downstream tasks and achieved significant performance in multi-modal understanding and generation tasks. However, existing methods often perform poorly on image-text matching tasks that require a detailed semantics understanding of the text. Although there have been some works on this problem, they do not sufficiently exploit the structural knowledge present in sentences to enhance multi-modal language representations, which leads to poor performance. In this paper, we present an end-to-end framework Structure-CLIP, which integrates latent detailed semantics from the text to enhance fine-grained semantic representations. Specifically, (1) we use scene graphs in order to pay more attention to the detailed semantic learning in the text and fully explore structured knowledge between fine-grained semantics, and (2) we utilize the knowledge-enhanced framework with the help of the scene graph to make full use of
    
[^40]: 通过结构增强的预训练模型和自适应融合提高语义匹配

    Improving Semantic Matching through Dependency-Enhanced Pre-trained Model with Adaptive Fusion. (arXiv:2210.08471v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.08471](http://arxiv.org/abs/2210.08471)

    本文提出了一种依赖增强的自适应融合注意力模型，它将依赖信息与原始语义信号自适应融合，以更好地模拟复杂的语义匹配关系。

    

    基于Transformer的预训练模型，如BERT，在语义句子匹配方面取得了很大的进展。同时，依赖性先验知识在多个NLP任务中也显示出普遍的益处。然而，如何将依赖性先验结构有效地集成到预训练模型中，以更好地模拟复杂的语义匹配关系，仍未确定。在本文中，我们提出了一种名为DAFA的依赖增强自适应融合注意力模型，这将依赖结构明确地引入预训练模型，并将其自适应地融合到语义信息中。具体地，DAFA首先提出了一个结构敏感范式来构建一个依赖矩阵，以校准注意力权重。它采用自适应融合模块来集成获取的依赖信息和原始语义信号。此外，DAFA重构了注意力计算流程，并提供了更好的可解释性。

    Transformer-based pre-trained models like BERT have achieved great progress on Semantic Sentence Matching. Meanwhile, dependency prior knowledge has also shown general benefits in multiple NLP tasks. However, how to efficiently integrate dependency prior structure into pre-trained models to better model complex semantic matching relations is still unsettled. In this paper, we propose the \textbf{D}ependency-Enhanced \textbf{A}daptive \textbf{F}usion \textbf{A}ttention (\textbf{DAFA}), which explicitly introduces dependency structure into pre-trained models and adaptively fuses it with semantic information. Specifically, \textbf{\emph{(i)}} DAFA first proposes a structure-sensitive paradigm to construct a dependency matrix for calibrating attention weights. It adopts an adaptive fusion module to integrate the obtained dependency information and the original semantic signals. Moreover, DAFA reconstructs the attention calculation flow and provides better interpretability. By applying it o
    
[^41]: 用于评估波斯语学前儿童言语的自动语音识别

    Automatic Speech Recognition for Speech Assessment of Persian Preschool Children. (arXiv:2203.12886v10 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.12886](http://arxiv.org/abs/2203.12886)

    通过在自动语音识别系统中添加随机频率变调目标，我们改进了对波斯语学前儿童言语评估的准确性。

    

    学前评估对教师和家长了解儿童的成长和发展至关重要。COVID-19疫情突显了在线评估学前儿童的必要性。其中一个需要测试的领域是他们的口语能力。由于自动语音识别系统（ASR）是在与儿童不同的频率和振幅特征的声音上进行预训练的，所以无法起到帮助的作用。为了解决这个问题，我们在Wav2Vec 2.0模型的掩模目标中添加了一个称为随机频率变调（RFP）的新目标。此外，我们使用我们新介绍的数据集来对“无意义词”（MW）和“速查自动命名”（RAN）测试进行模型微调。使用掩模与RFP的组合优于Wav2Vec 2.0的掩模目标。

    Preschool evaluation is crucial because it gives teachers and parents influential knowledge about children's growth and development. The COVID-19 pandemic has highlighted the necessity of online assessment for preschool children. One of the areas that should be tested is their ability to speak. Employing an Automatic Speech Recognition (ASR) system would not help since they are pre-trained on voices that differ from children's in terms of frequency and amplitude. Because most of these are pre-trained with data in a specific range of amplitude, their objectives do not make them ready for voices in different amplitudes. To overcome this issue, we added a new objective to the masking objective of the Wav2Vec 2.0 model called Random Frequency Pitch (RFP). In addition, we used our newly introduced dataset to fine-tune our model for Meaningless Words (MW) and Rapid Automatic Naming (RAN) tests. Using masking in concatenation with RFP outperforms the masking objective of Wav2Vec 2.0 by reachi
    
[^42]: 基于Transformer预训练语言模型的可控文本生成综述

    A Survey of Controllable Text Generation using Transformer-based Pre-trained Language Models. (arXiv:2201.05337v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2201.05337](http://arxiv.org/abs/2201.05337)

    这篇论文综述了基于Transformer预训练语言模型的可控文本生成方法。这些方法利用大规模预训练语言模型生成多样化、流畅的文本，但由于深度神经网络的可解释性较低，需要保证其可控性。

    

    可控文本生成是自然语言生成领域中新兴的方向，被认为对于开发更自然、更符合特定应用场景的先进文本生成技术至关重要。近年来，利用大规模预训练语言模型（PLMs），尤其是广泛使用的基于Transformer的PLMs，已成为自然语言生成新范式，可以生成更多样化、更流畅的文本。然而，由于深度神经网络的可解释性较低，这些方法的可控性需要得到保证。为此，基于Transformer的PLMs的可控文本生成已成为一个快速增长但具有挑战性的新研究热点。最近3-4年出现了各种方法，针对可能需要不同类型控制约束的不同CTG任务。在本文中，我们对当前基于Transformer预训练语言模型的可控文本生成方法进行了系统的综述。

    Controllable Text Generation (CTG) is emerging area in the field of natural language generation (NLG). It is regarded as crucial for the development of advanced text generation technologies that are more natural and better meet the specific constraints in practical applications. In recent years, methods using large-scale pre-trained language models (PLMs), in particular the widely used transformer-based PLMs, have become a new paradigm of NLG, allowing generation of more diverse and fluent text. However, due to the lower level of interpretability of deep neural networks, the controllability of these methods need to be guaranteed. To this end, controllable text generation using transformer-based PLMs has become a rapidly growing yet challenging new research hotspot. A diverse range of approaches have emerged in the recent 3-4 years, targeting different CTG tasks which may require different types of controlled constraints. In this paper, we present a systematic critical review on the com
    

