# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [The effect of diversity on group decision-making](https://rss.arxiv.org/abs/2402.01427) | 研究探讨认知多样性及其对群体决策成功的影响。通过分析500个团队讨论的对话记录，我们发现较大的认知多样性与更成功的群体决策相关。 |
| [^2] | [An image speaks a thousand words, but can everyone listen? On translating images for cultural relevance](https://arxiv.org/abs/2404.01247) | 这项工作首次尝试翻译图像以使其具有文化相关性，构建了评估数据集并进行了多方面的人类评估，发现目前图像编辑模型在这一任务上仍存在挑战。 |
| [^3] | [Towards a Framework for Evaluating Explanations in Automated Fact Verification](https://arxiv.org/abs/2403.20322) | 倡导并提出了一个形式化框架，用于系统评估理性化解释，针对自动事实验证任务中不同结构的解释提供了一套评估方法 |
| [^4] | [ToXCL: A Unified Framework for Toxic Speech Detection and Explanation](https://arxiv.org/abs/2403.16685) | ToXCL是一个统一框架，旨在检测和解释隐性毒性言论，解决了传统模型在检测和解释任务中可能遇到的问题。 |
| [^5] | [LLMs Are Few-Shot In-Context Low-Resource Language Learners](https://arxiv.org/abs/2403.16512) | 该研究对25种低资源语言和7种相对较高资源语言上的情境学习（ICL）及其跨语言变体进行了研究，发现了在低资源语言中使用LLMs进行ICL的有效性，提出了替代方法查询对齐，并为低资源语言的ICL提供了宝贵见解。 |
| [^6] | [Detoxifying Large Language Models via Knowledge Editing](https://arxiv.org/abs/2403.14472) | 本文研究了使用知识编辑技术对大型语言模型进行去毒化，在构建了SafeEdit基准的基础上，提出了一种简单而有效的方法 DINM，可以通过少量调整步骤减少模型的毒性，同时对各种去毒方法的内部机制进行了深入分析。 |
| [^7] | [Towards Detecting AI-Generated Text within Human-AI Collaborative Hybrid Texts](https://arxiv.org/abs/2403.03506) | 本研究探索了在人工智能协作混合文本中句子级人工智能生成文本检测的挑战，并提出了一种基于分割的两步骤流程来检测各段落的一致作者句子。 |
| [^8] | [UrbanGPT: Spatio-Temporal Large Language Models](https://arxiv.org/abs/2403.00813) | 都市GPT旨在建立一个具有强大泛化能力的时空模型，借鉴大型语言模型的成就。 |
| [^9] | [M3-VRD: Multimodal Multi-task Multi-teacher Visually-Rich Form Document Understanding](https://arxiv.org/abs/2402.17983) | 这个模型是一个多模态、多任务、多教师的联合细粒度知识蒸馏模型，通过微妙协作令牌和实体表示，处理复杂的表单文档，引入新的损失函数改进知识蒸馏过程，在处理视觉复杂表单文档的结构和内容上表现出色。 |
| [^10] | [HiGPT: Heterogeneous Graph Language Model](https://arxiv.org/abs/2402.16024) | 该论文提出了HiGPT模型，致力于解决异质图学习中存在的泛化限制和分布不稳定性问题。 |
| [^11] | [API-BLEND: A Comprehensive Corpora for Training and Benchmarking API LLMs](https://arxiv.org/abs/2402.15491) | 本文介绍了API-BLEND，一个用于训练和系统测试工具增强型LLMs的大型语料库，旨在解决获取涉及调用工具/API的训练和测试数据的挑战，并模拟真实场景的API任务。 |
| [^12] | [Generation Meets Verification: Accelerating Large Language Model Inference with Smart Parallel Auto-Correct Decoding](https://arxiv.org/abs/2402.11809) | 提出了Smart Parallel Auto-Correct Decoding (SPACE)方法，通过集成半自回归推理和猜测解码，实现了大型语言模型推理加速和并行生成验证令牌的功能。 |
| [^13] | [Universal Prompt Optimizer for Safe Text-to-Image Generation](https://arxiv.org/abs/2402.10882) | 提出了第一个通用提示优化器，用于在黑盒场景中安全生成文本到图像，通过构建毒素-清洁提示对数据集，设计奖励函数，并通过 Proximal Policy Optimization 训练优化器，成功降低各种 T2I 模型生成不安全内容的可能性。 |
| [^14] | [Merging Facts, Crafting Fallacies: Evaluating the Contradictory Nature of Aggregated Factual Claims in Long-Form Generations](https://arxiv.org/abs/2402.05629) | 该论文研究了长文生成中的事实性问题，发现大型语言模型在生成段落时可能会由于实体模糊而将可验证的事实组合成非事实的段落。现有的事实准确度评估方法无法正确评估这些非事实段落，作者提出了一种增强的度量指标来应对这个问题。 |
| [^15] | [Evaluating Gender Bias of Pre-trained Language Models in Natural Language Inference by Considering All Labels](https://arxiv.org/abs/2309.09697) | 提出了一种考虑自然语言推理任务三个标签的预训练语言模型偏见评估方法，通过创造代表不同类型偏见的评估数据组，并实验证明该方法能更好地区分有偏见的、不正确的推理和非有偏见的不正确推理。 |
| [^16] | [Knowledge-augmented Graph Neural Networks with Concept-aware Attention for Adverse Drug Event Detection](https://arxiv.org/abs/2301.10451) | 本研究提出了一种具有概念感知注意力的知识增强图神经网络，用于不良药物事件检测，通过将医学知识和文本图相结合，实现了不同类型节点的特征学习。 |
| [^17] | [MoSECroT: Model Stitching with Static Word Embeddings for Crosslingual Zero-shot Transfer.](http://arxiv.org/abs/2401.04821) | MoSECroT是一个结合静态词向量的模型拼接框架，用于跨语言零样例迁移。它利用相对表示构建了源语言预训练语言模型和目标语言静态词向量的共享空间，从而实现了通过简单交换嵌入从源语言训练数据中进行训练，并在目标语言上进行零样例迁移。 |
| [^18] | [Natural Language Interfaces for Tabular Data Querying and Visualization: A Survey.](http://arxiv.org/abs/2310.17894) | 本调查对表格数据查询和可视化的自然语言界面进行了全面概述，介绍了语义解析等关键技术，并深入探讨了Text-to-SQL和Text-to-Vis问题的最新进展。 |
| [^19] | [Direct Neural Machine Translation with Task-level Mixture of Experts models.](http://arxiv.org/abs/2310.12236) | 在这项工作中，我们研究了任务级MoE在直接神经机器翻译中的应用，并提出了一系列高性能的训练和评估配置，通过这些配置，任务级MoE的直接NMT系统在大量低资源语言对上优于双语和基于中间语言的模型。 |
| [^20] | [Understanding AI Cognition: A Neural Module for Inference Inspired by Human Memory Mechanisms.](http://arxiv.org/abs/2310.09297) | 该论文提出了一个受人类记忆机制启发的神经模块，模拟人类和机器如何对当前输入进行关联推理和问答，并将其与过去的记忆结合起来。通过感知、记忆和推理组件，该模块实现了感知更新、记忆融合和信息检索的功能。 |
| [^21] | [A Semantic Invariant Robust Watermark for Large Language Models.](http://arxiv.org/abs/2310.06356) | 本论文提出了一种对大型语言模型进行语义不变水印的方法，该方法通过利用另一个嵌入式语言模型生成所有前面token的语义嵌入，然后利用训练得到的水印模型将这些语义嵌入转换为水印logits。该方法既具有攻击鲁棒性又具有安全鲁棒性。 |
| [^22] | [Jury: A Comprehensive Evaluation Toolkit.](http://arxiv.org/abs/2310.02040) | 评委是一个统一的评估框架和工具包，旨在解决深度学习中不同系统和指标的评估挑战，并改进度量评估。 |
| [^23] | [You Only Look at Screens: Multimodal Chain-of-Action Agents.](http://arxiv.org/abs/2309.11436) | 本论文提出了一种名为Auto-UI的多模态动作链机器人，通过直接与界面交互，避免了环境解析或依赖于应用程序API的需要，并引入了动作链技术来帮助模型进行决策。 |
| [^24] | [K-pop Lyric Translation: Dataset, Analysis, and Neural-Modelling.](http://arxiv.org/abs/2309.11093) | 研究者介绍了一种新颖的K-pop歌词翻译数据集，该数据集揭示了K-pop歌词翻译的独特特征，并构建了一个神经歌词翻译模型，强调了专用数据集的重要性。 |
| [^25] | [Draft & Verify: Lossless Large Language Model Acceleration via Self-Speculative Decoding.](http://arxiv.org/abs/2309.08168) | 使用自我推测解码的Draft & Verify方法能够加速大型语言模型的推理过程，同时保持输出质量，并不需要额外的训练和内存占用。 |
| [^26] | [Anonymity at Risk? Assessing Re-Identification Capabilities of Large Language Models.](http://arxiv.org/abs/2308.11103) | 本研究评估了大型语言模型在重新识别匿名个人方面的能力，并发现模型大小、输入长度和指令调整是最重要的决定因素。 |
| [^27] | [YORC: Yoruba Reading Comprehension dataset.](http://arxiv.org/abs/2308.09768) | 本文介绍了一个新的多项选择约鲁巴语阅读理解数据集YORC，通过跨语言转移和大型语言模型的使用，提供了该数据集的基准结果和更高层次的结果。 |
| [^28] | [A Hybrid Machine Learning Model for Classifying Gene Mutations in Cancer using LSTM, BiLSTM, CNN, GRU, and GloVe.](http://arxiv.org/abs/2307.14361) | 本研究提出了一个基于多种机器学习算法和嵌入模型的集成模型，用于基因突变在癌症中的分类。实验结果表明，该模型在准确率、精确率、召回率等指标上优于其他传统和最新的转换器模型，并且具有更高的训练效率。 |
| [^29] | [Generating Efficient Training Data via LLM-based Attribute Manipulation.](http://arxiv.org/abs/2307.07099) | 本文提出了一种通过大型语言模型（LLMs）生成精心制作的训练数据来引导少样本学习的方法。通过利用LLMs操作任务特定属性并重构新的句子，我们实现了标签交换数据的生成，与其他基于LLMs的文本生成方法相比具有更好的效果。同时，研究结果还显示了通过LLM引导学习的潜力，即使在更少的监督情况下也能取得良好的表现。 |
| [^30] | [Statler: State-Maintaining Language Models for Embodied Reasoning.](http://arxiv.org/abs/2306.17840) | Statler是一个为LLMs赋予了明确的、维持状态的语言模型，可以解决当代LLMs在长时间范围内推理的困难。 |
| [^31] | [MultiLegalPile: A 689GB Multilingual Legal Corpus.](http://arxiv.org/abs/2306.02069) | MultiLegalPile是一个689GB的多语言法律语料库，包含来自17个司法管辖区的24种语言的不同法律数据源，允许在公平使用下针对预训练NLP模型。该语料库为多语言模型的预训练提供了新的最佳表现，并在LexGLUE上表现最佳。 |
| [^32] | [Generating with Confidence: Uncertainty Quantification for Black-box Large Language Models.](http://arxiv.org/abs/2305.19187) | 本研究提出应对大型语言模型可信度问题的方法，研究黑盒模型中置信度与不确定性量化，并将其应用于选择性自然语言生成。 |
| [^33] | [COKE: A Cognitive Knowledge Graph for Machine Theory of Mind.](http://arxiv.org/abs/2305.05390) | COKE是一个机器心智理论的认知知识图谱，将ToM形式化为一组经手动验证的认知链，可以帮助AI系统在社交智能等任务上具备推理人类心智的能力。 |

# 详细

[^1]: 多样性对群体决策的影响

    The effect of diversity on group decision-making

    [https://rss.arxiv.org/abs/2402.01427](https://rss.arxiv.org/abs/2402.01427)

    研究探讨认知多样性及其对群体决策成功的影响。通过分析500个团队讨论的对话记录，我们发现较大的认知多样性与更成功的群体决策相关。

    

    我们研究了认知多样性的不同方面以及其对群体协商成功的影响。我们使用了500个小型在线团队讨论瓦索卡片选择任务的对话记录进行评估 - DeliData语料库。利用该语料库，我们进行了定量分析，评估了认知多样性的三种不同度量。首先，我们分析了群体规模作为多样性的代理度量的影响。其次，我们评估了初始想法池的大小对结果的影响。最后，我们通过分析讨论的解决方案、讨论模式以及谈话探究如何改善这些特征来研究讨论内容。尽管群体因为加重偏见而名声不佳，我们表明小团队可以通过对话克服直觉偏见，提高个体决策能力。在大样本和不同操作中，我们始终发现认知多样性与群体协商的成功性有关

    We explore different aspects of cognitive diversity and its effect on the success of group deliberation. To evaluate this, we use 500 dialogues from small, online groups discussing the Wason Card Selection task - the DeliData corpus. Leveraging the corpus, we perform quantitative analysis evaluating three different measures of cognitive diversity. First, we analyse the effect of group size as a proxy measure for diversity. Second, we evaluate the effect of the size of the initial idea pool. Finally, we look into the content of the discussion by analysing discussed solutions, discussion patterns, and how conversational probing can improve those characteristics.   Despite the reputation of groups for compounding bias, we show that small groups can, through dialogue, overcome intuitive biases and improve individual decision-making. Across a large sample and different operationalisations, we consistently find that greater cognitive diversity is associated with more successful group deliber
    
[^2]: 图片虽然代表千言万语，但每个人都能听懂吗？关于翻译具有文化相关性的图像

    An image speaks a thousand words, but can everyone listen? On translating images for cultural relevance

    [https://arxiv.org/abs/2404.01247](https://arxiv.org/abs/2404.01247)

    这项工作首次尝试翻译图像以使其具有文化相关性，构建了评估数据集并进行了多方面的人类评估，发现目前图像编辑模型在这一任务上仍存在挑战。

    

    随着多媒体内容的兴起，人类翻译越来越多地关注于文化适应，不仅限于文字，还包括图片等其他形式，以传达相同的含义。虽然有几种应用将受益于这一点，但机器翻译系统仍然局限于处理语言的口头和文字。在这项工作中，我们迈出了翻译图像以使其具有文化相关性的第一步。首先，我们构建了三个包含最先进生成模型的流水线来完成这项任务。接下来，我们构建了一个由两部分组成的评估数据集：i）概念：包括600张跨文化连贯的图像，每张图像专注于单个概念，ii）应用：包括从实际应用中筛选出的100张图像。我们对翻译后的图像进行了多方面的人类评估，以评估其文化相关性和含义保留。我们发现到目前为止，图像编辑模型在这项任务上失败了，但可以...

    arXiv:2404.01247v1 Announce Type: new  Abstract: Given the rise of multimedia content, human translators increasingly focus on culturally adapting not only words but also other modalities such as images to convey the same meaning. While several applications stand to benefit from this, machine translation systems remain confined to dealing with language in speech and text. In this work, we take a first step towards translating images to make them culturally relevant. First, we build three pipelines comprising state-of-the-art generative models to do the task. Next, we build a two-part evaluation dataset: i) concept: comprising 600 images that are cross-culturally coherent, focusing on a single concept per image, and ii) application: comprising 100 images curated from real-world applications. We conduct a multi-faceted human evaluation of translated images to assess for cultural relevance and meaning preservation. We find that as of today, image-editing models fail at this task, but can 
    
[^3]: 在自动事实验证中评估解释的框架

    Towards a Framework for Evaluating Explanations in Automated Fact Verification

    [https://arxiv.org/abs/2403.20322](https://arxiv.org/abs/2403.20322)

    倡导并提出了一个形式化框架，用于系统评估理性化解释，针对自动事实验证任务中不同结构的解释提供了一套评估方法

    

    随着自然语言处理中的深度神经模型变得越来越复杂，也因此变得不透明，解释它们的必要性变得更为重要。越来越多的人对理性化解释产生了兴趣，以提供对预测的简短和连贯的理由。在这篇立场论文中，我们倡导一个形式化框架，用于关于理性化解释的关键概念和属性，以支持系统地评估它们。我们还概述了一个这样的形式化框架，定制于越来越复杂结构的理性化解释，从自由形式的解释到演绎性解释，再到具有最丰富结构的论证性解释。我们聚焦于自动事实验证任务，提供了使用我们的形式化评估解释的示例及其实用性，针对不同结构做出了定制。

    arXiv:2403.20322v1 Announce Type: new  Abstract: As deep neural models in NLP become more complex, and as a consequence opaque, the necessity to interpret them becomes greater. A burgeoning interest has emerged in rationalizing explanations to provide short and coherent justifications for predictions. In this position paper, we advocate for a formal framework for key concepts and properties about rationalizing explanations to support their evaluation systematically. We also outline one such formal framework, tailored to rationalizing explanations of increasingly complex structures, from free-form explanations to deductive explanations, to argumentative explanations (with the richest structure). Focusing on the automated fact verification task, we provide illustrations of the use and usefulness of our formalization for evaluating explanations, tailored to their varying structures.
    
[^4]: ToXCL：毒性言论检测和解释的统一框架

    ToXCL: A Unified Framework for Toxic Speech Detection and Explanation

    [https://arxiv.org/abs/2403.16685](https://arxiv.org/abs/2403.16685)

    ToXCL是一个统一框架，旨在检测和解释隐性毒性言论，解决了传统模型在检测和解释任务中可能遇到的问题。

    

    线上毒性言论的蔓延是一个令人关注的问题，对人群构成威胁。明显的毒性言论包含冒犯性词汇信号，隐性的言论则包含编码或间接语言。因此，模型不仅需要检测隐性毒性言论，还需要解释其毒性。这导致了对有效检测和解释隐性毒性言论的统一框架的独特需求。先前的工作主要将毒性言论的检测和解释任务制定为文本生成问题。然而，使用这种策略训练的模型可能容易受到后续错误传播问题的影响。此外，我们的实验表明，这种模型的检测结果远低于那些仅专注于检测任务的模型。为了弥补这些差距，我们引入了ToXCL，一个用于检测和解释隐性毒性言论的统一框架。

    arXiv:2403.16685v1 Announce Type: new  Abstract: The proliferation of online toxic speech is a pertinent problem posing threats to demographic groups. While explicit toxic speech contains offensive lexical signals, implicit one consists of coded or indirect language. Therefore, it is crucial for models not only to detect implicit toxic speech but also to explain its toxicity. This draws a unique need for unified frameworks that can effectively detect and explain implicit toxic speech. Prior works mainly formulated the task of toxic speech detection and explanation as a text generation problem. Nonetheless, models trained using this strategy can be prone to suffer from the consequent error propagation problem. Moreover, our experiments reveal that the detection results of such models are much lower than those that focus only on the detection task. To bridge these gaps, we introduce ToXCL, a unified framework for the detection and explanation of implicit toxic speech. Our model consists 
    
[^5]: LLMs是少样本情境低资源语言学习器

    LLMs Are Few-Shot In-Context Low-Resource Language Learners

    [https://arxiv.org/abs/2403.16512](https://arxiv.org/abs/2403.16512)

    该研究对25种低资源语言和7种相对较高资源语言上的情境学习（ICL）及其跨语言变体进行了研究，发现了在低资源语言中使用LLMs进行ICL的有效性，提出了替代方法查询对齐，并为低资源语言的ICL提供了宝贵见解。

    

    在情境学习（ICL）的支持下，大型语言模型（LLMs）可以利用短时的情境信息执行各种任务，这为缩小高资源语言和低资源语言之间的差距提供了重要途径。然而，目前只有少数研究探讨了针对低资源语言的ICL，其中大部分集中在相对高资源的语言，比如法语和西班牙语。在这项工作中，我们对25种低资源语言和7种相对较高资源语言上的ICL及其跨语言变体（X-ICL）进行了广泛研究。我们的研究不仅评估了LLMs在低资源语言中使用ICL的有效性，还发现了情境标签对齐的缺陷，并引入了更有效的替代方法：查询对齐。此外，我们为低资源语言的ICL的各个方面提供了宝贵的见解。我们的研究总结了少样本情境学习的重要性。

    arXiv:2403.16512v1 Announce Type: cross  Abstract: In-context learning (ICL) empowers large language models (LLMs) to perform diverse tasks in underrepresented languages using only short in-context information, offering a crucial avenue for narrowing the gap between high-resource and low-resource languages. Nonetheless, there is only a handful of works explored ICL for low-resource languages with most of them focusing on relatively high-resource languages, such as French and Spanish. In this work, we extensively study ICL and its cross-lingual variation (X-ICL) on 25 low-resource and 7 relatively higher-resource languages. Our study not only assesses the effectiveness of ICL with LLMs in low-resource languages but also identifies the shortcomings of in-context label alignment, and introduces a more effective alternative: query alignment. Moreover, we provide valuable insights into various facets of ICL for low-resource languages. Our study concludes the significance of few-shot in-cont
    
[^6]: 通过知识编辑实现对大型语言模型的去毒化

    Detoxifying Large Language Models via Knowledge Editing

    [https://arxiv.org/abs/2403.14472](https://arxiv.org/abs/2403.14472)

    本文研究了使用知识编辑技术对大型语言模型进行去毒化，在构建了SafeEdit基准的基础上，提出了一种简单而有效的方法 DINM，可以通过少量调整步骤减少模型的毒性，同时对各种去毒方法的内部机制进行了深入分析。

    

    本文研究了使用知识编辑技术来对大型语言模型（LLMs）进行去毒化。我们构建了一个名为SafeEdit的基准，涵盖了九种不安全类别，具有各种强大的攻击提示，并配备了全面的度量标准进行系统评估。我们进行了实验，比较了知识编辑方法与之前的基准线，结果表明知识编辑有潜力在对LLMs进行去毒化时，在对一般性能的影响相对有限。然后，我们提出了一个简单但有效的基准线，称为通过术中神经监测去毒化（DINM），通过仅一次实例的少量调整步骤减少LLMs的毒性。我们进一步对各种去毒方法的内部机制进行了深入分析，表明先前的方法如SFT和DPO可能仅抑制有毒参数的激活，而DINM则减轻有毒参数的毒性。

    arXiv:2403.14472v1 Announce Type: cross  Abstract: This paper investigates using knowledge editing techniques to detoxify Large Language Models (LLMs). We construct a benchmark, SafeEdit, which covers nine unsafe categories with various powerful attack prompts and equips comprehensive metrics for systematic evaluation. We conduct experiments to compare knowledge editing approaches with previous baselines, indicating that knowledge editing has the potential to efficiently detoxify LLMs with limited impact on general performance. Then, we propose a simple yet effective baseline, dubbed Detoxifying with Intraoperative Neural Monitoring (DINM), to diminish the toxicity of LLMs within a few tuning steps via only one instance. We further provide an in-depth analysis of the internal mechanism for various detoxify approaches, demonstrating that previous methods like SFT and DPO may merely suppress the activations of toxic parameters, while DINM mitigates the toxicity of the toxic parameters to
    
[^7]: 人工智能生成文本与人工智能协作混合文本中的检测方法

    Towards Detecting AI-Generated Text within Human-AI Collaborative Hybrid Texts

    [https://arxiv.org/abs/2403.03506](https://arxiv.org/abs/2403.03506)

    本研究探索了在人工智能协作混合文本中句子级人工智能生成文本检测的挑战，并提出了一种基于分割的两步骤流程来检测各段落的一致作者句子。

    

    本研究探讨了在人工智能协作混合文本中句子级人工智能生成文本检测的挑战。现有的关于混合文本中AI生成文本检测的研究通常依赖于合成数据集，这些数据集通常涉及带有有限边界的混合文本。我们认为，检测混合文本中AI生成内容的研究应覆盖在真实环境中生成的不同类型混合文本，以更好地指导实际应用。因此，我们的研究利用了CoAuthor数据集，该数据集包括通过人类作者和智能写作系统之间的协作生成的多轮交互中产生的多样化、真实的混合文本。我们采用了两步分割为基础的流程：(i)检测给定混合文本中的各个段落，其中每个段落包含一致作者的句子，以及(ii)分类每个确定段落的作者。我们的实证

    arXiv:2403.03506v1 Announce Type: cross  Abstract: This study explores the challenge of sentence-level AI-generated text detection within human-AI collaborative hybrid texts. Existing studies of AI-generated text detection for hybrid texts often rely on synthetic datasets. These typically involve hybrid texts with a limited number of boundaries. We contend that studies of detecting AI-generated content within hybrid texts should cover different types of hybrid texts generated in realistic settings to better inform real-world applications. Therefore, our study utilizes the CoAuthor dataset, which includes diverse, realistic hybrid texts generated through the collaboration between human writers and an intelligent writing system in multi-turn interactions. We adopt a two-step, segmentation-based pipeline: (i) detect segments within a given hybrid text where each segment contains sentences of consistent authorship, and (ii) classify the authorship of each identified segment. Our empirical 
    
[^8]: UrbanGPT: 时空大型语言模型

    UrbanGPT: Spatio-Temporal Large Language Models

    [https://arxiv.org/abs/2403.00813](https://arxiv.org/abs/2403.00813)

    都市GPT旨在建立一个具有强大泛化能力的时空模型，借鉴大型语言模型的成就。

    

    都市GPT旨在预测并洞察城市环境在时间和空间上不断变化的动态。其目的是预测都市生活各个方面的未来模式、趋势和事件，包括交通、人口流动和犯罪率等。尽管已经付出了大量努力开发神经网络技术以准确预测时空数据，但需注意到很多方法在生成精确的时空表示时严重依赖于有足够标记的数据。不幸的是，在实际都市感知场景中，数据稀缺是一个普遍存在的问题。因此，建立一个具有强大泛化能力的时空模型跨越多样时空学习场景是必要的。受大型语言模型(LLM)卓越成就的启发，我们的目标是

    arXiv:2403.00813v1 Announce Type: cross  Abstract: Spatio-temporal prediction aims to forecast and gain insights into the ever-changing dynamics of urban environments across both time and space. Its purpose is to anticipate future patterns, trends, and events in diverse facets of urban life, including transportation, population movement, and crime rates. Although numerous efforts have been dedicated to developing neural network techniques for accurate predictions on spatio-temporal data, it is important to note that many of these methods heavily depend on having sufficient labeled data to generate precise spatio-temporal representations. Unfortunately, the issue of data scarcity is pervasive in practical urban sensing scenarios. Consequently, it becomes necessary to build a spatio-temporal model with strong generalization capabilities across diverse spatio-temporal learning scenarios. Taking inspiration from the remarkable achievements of large language models (LLMs), our objective is 
    
[^9]: M3-VRD: 多模态多任务多教师视觉丰富表单文档理解

    M3-VRD: Multimodal Multi-task Multi-teacher Visually-Rich Form Document Understanding

    [https://arxiv.org/abs/2402.17983](https://arxiv.org/abs/2402.17983)

    这个模型是一个多模态、多任务、多教师的联合细粒度知识蒸馏模型，通过微妙协作令牌和实体表示，处理复杂的表单文档，引入新的损失函数改进知识蒸馏过程，在处理视觉复杂表单文档的结构和内容上表现出色。

    

    这篇论文提出了一个突破性的多模态、多任务、多教师联合细粒度知识蒸馏模型，用于视觉丰富的表单文档理解。该模型旨在通过促进令牌和实体表示之间的微妙相关性来利用细粒度和粗粒度级别的见解，解决表单文档固有的复杂性。此外，我们引入了新的跨细粒度和跨粗粒度损失函数，以进一步改进多教师知识蒸馏传递过程，呈现分布差距和对表单文档的统一理解。通过在公开可用的表单文档理解数据集上进行全面评估，我们提出的模型始终表现出色地优于现有基线，展示了其在处理复杂视觉表单文档的复杂结构和内容方面的功效。

    arXiv:2402.17983v1 Announce Type: new  Abstract: This paper presents a groundbreaking multimodal, multi-task, multi-teacher joint-grained knowledge distillation model for visually-rich form document understanding. The model is designed to leverage insights from both fine-grained and coarse-grained levels by facilitating a nuanced correlation between token and entity representations, addressing the complexities inherent in form documents. Additionally, we introduce new inter-grained and cross-grained loss functions to further refine diverse multi-teacher knowledge distillation transfer process, presenting distribution gaps and a harmonised understanding of form documents. Through a comprehensive evaluation across publicly available form document understanding datasets, our proposed model consistently outperforms existing baselines, showcasing its efficacy in handling the intricate structures and content of visually complex form documents.
    
[^10]: HiGPT：异质图语言模型

    HiGPT: Heterogeneous Graph Language Model

    [https://arxiv.org/abs/2402.16024](https://arxiv.org/abs/2402.16024)

    该论文提出了HiGPT模型，致力于解决异质图学习中存在的泛化限制和分布不稳定性问题。

    

    异构图学习旨在捕捉异构图中实体之间的复杂关系和多样化关系语义，以获得节点和边的有意义表示。最近在异构图神经网络（HGNNs）领域取得了最先进的性能，通过考虑关系的异质性并使用专门的消息函数和聚合规则。然而，现有的异构图学习框架在泛化到不同的异构图数据集方面存在局限。大多数这些框架都遵循同一数据集上的“预训练”和“微调”范式，这限制了它们适应新的和看不见的数据的能力。这引出了一个问题：“我们是否能够将异质图模型泛化为适应具有节点令牌集和关系类型异质性分布变化的不同下游学习任务？”为了解决这些挑战，我们p

    arXiv:2402.16024v1 Announce Type: new  Abstract: Heterogeneous graph learning aims to capture complex relationships and diverse relational semantics among entities in a heterogeneous graph to obtain meaningful representations for nodes and edges. Recent advancements in heterogeneous graph neural networks (HGNNs) have achieved state-of-the-art performance by considering relation heterogeneity and using specialized message functions and aggregation rules. However, existing frameworks for heterogeneous graph learning have limitations in generalizing across diverse heterogeneous graph datasets. Most of these frameworks follow the "pre-train" and "fine-tune" paradigm on the same dataset, which restricts their capacity to adapt to new and unseen data. This raises the question: "Can we generalize heterogeneous graph models to be well-adapted to diverse downstream learning tasks with distribution shifts in both node token sets and relation type heterogeneity?'' To tackle those challenges, we p
    
[^11]: API-BLEND：用于训练和基准测试API LLM的综合语料库

    API-BLEND: A Comprehensive Corpora for Training and Benchmarking API LLMs

    [https://arxiv.org/abs/2402.15491](https://arxiv.org/abs/2402.15491)

    本文介绍了API-BLEND，一个用于训练和系统测试工具增强型LLMs的大型语料库，旨在解决获取涉及调用工具/API的训练和测试数据的挑战，并模拟真实场景的API任务。

    

    随着对大型语言模型（LLMs）有效使用工具和外部应用程序编程接口（APIs）来规划和完成任务的需求日益增长，对可以获取涉及调用工具/API的足够数量的训练和测试数据的方法引起了极大关注。本文关注识别、整理和转化现有数据集，并介绍API-BLEND，一个用于训练和系统测试工具增强型LLMs的大型语料库。这些数据集模拟涉及API任务的真实场景，如API/工具检测、槽填充以及检测到的API的排序。

    arXiv:2402.15491v1 Announce Type: cross  Abstract: There is a growing need for Large Language Models (LLMs) to effectively use tools and external Application Programming Interfaces (APIs) to plan and complete tasks. As such, there is tremendous interest in methods that can acquire sufficient quantities of train and test data that involve calls to tools / APIs. Two lines of research have emerged as the predominant strategies for addressing this challenge. The first has focused on synthetic data generation techniques, while the second has involved curating task-adjacent datasets which can be transformed into API / Tool-based tasks. In this paper, we focus on the task of identifying, curating, and transforming existing datasets and, in turn, introduce API-BLEND, a large corpora for training and systematic testing of tool-augmented LLMs. The datasets mimic real-world scenarios involving API-tasks such as API / tool detection, slot filling, and sequencing of the detected APIs. We demonstrat
    
[^12]: 智能并行自动纠错解码：加速大型语言模型推理

    Generation Meets Verification: Accelerating Large Language Model Inference with Smart Parallel Auto-Correct Decoding

    [https://arxiv.org/abs/2402.11809](https://arxiv.org/abs/2402.11809)

    提出了Smart Parallel Auto-Correct Decoding (SPACE)方法，通过集成半自回归推理和猜测解码，实现了大型语言模型推理加速和并行生成验证令牌的功能。

    

    这项研究旨在加速拥有数十亿参数的大型语言模型（LLMs）的推理速度。我们提出了“智能并行自动纠错解码”（SPACE），这是一种创新方法，旨在实现LLMs的无损加速。通过集成半自回归推理和猜测解码能力，SPACE独特地使自回归LLMs能够并行生成和验证令牌。这是通过专门的半自回归监督微调过程实现的，该过程使现有LLMs具有同时预测多个令牌的能力。此外，一种自动纠错解码算法促进了单个模型调用内令牌序列的同时生成和验证。通过在一系列LLMs上进行广泛实验证明，SPACE在HumanEval-X上表现出2.7倍至4.0倍的推理加速。

    arXiv:2402.11809v1 Announce Type: cross  Abstract: This research aims to accelerate the inference speed of large language models (LLMs) with billions of parameters. We propose \textbf{S}mart \textbf{P}arallel \textbf{A}uto-\textbf{C}orrect d\textbf{E}coding (SPACE), an innovative approach designed for achieving lossless acceleration of LLMs. By integrating semi-autoregressive inference and speculative decoding capabilities, SPACE uniquely enables autoregressive LLMs to parallelize token generation and verification. This is realized through a specialized semi-autoregressive supervised fine-tuning process that equips existing LLMs with the ability to simultaneously predict multiple tokens. Additionally, an auto-correct decoding algorithm facilitates the simultaneous generation and verification of token sequences within a single model invocation. Through extensive experiments on a range of LLMs, SPACE has demonstrated inference speedup ranging from 2.7x-4.0x on HumanEval-X while maintaini
    
[^13]: 通用提示优化器用于安全文本到图像生成

    Universal Prompt Optimizer for Safe Text-to-Image Generation

    [https://arxiv.org/abs/2402.10882](https://arxiv.org/abs/2402.10882)

    提出了第一个通用提示优化器，用于在黑盒场景中安全生成文本到图像，通过构建毒素-清洁提示对数据集，设计奖励函数，并通过 Proximal Policy Optimization 训练优化器，成功降低各种 T2I 模型生成不安全内容的可能性。

    

    文本到图像（T2I）模型在根据文字提示生成图像方面表现出色。然而，这些模型容易受到不安全输入的影响，从而生成不安全内容，如色情、骚扰和非法活动图像。基于图像检查器、模型微调和嵌入式阻止的现有研究在真实世界应用中不可行。因此，我们提出了第一个用于黑盒场景中安全 T2I 生成的通用提示优化器。

    arXiv:2402.10882v1 Announce Type: cross  Abstract: Text-to-Image (T2I) models have shown great performance in generating images based on textual prompts. However, these models are vulnerable to unsafe input to generate unsafe content like sexual, harassment and illegal-activity images. Existing studies based on image checker, model fine-tuning and embedding blocking are impractical in real-world applications. Hence, \textit{we propose the first universal prompt optimizer for safe T2I generation in black-box scenario}. We first construct a dataset consisting of toxic-clean prompt pairs by GPT-3.5 Turbo. To guide the optimizer to have the ability of converting toxic prompt to clean prompt while preserving semantic information, we design a novel reward function measuring toxicity and text alignment of generated images and train the optimizer through Proximal Policy Optimization. Experiments show that our approach can effectively reduce the likelihood of various T2I models in generating in
    
[^14]: 合并事实，塑造谬误：评估长文生成中聚合事实性主张的矛盾性质

    Merging Facts, Crafting Fallacies: Evaluating the Contradictory Nature of Aggregated Factual Claims in Long-Form Generations

    [https://arxiv.org/abs/2402.05629](https://arxiv.org/abs/2402.05629)

    该论文研究了长文生成中的事实性问题，发现大型语言模型在生成段落时可能会由于实体模糊而将可验证的事实组合成非事实的段落。现有的事实准确度评估方法无法正确评估这些非事实段落，作者提出了一种增强的度量指标来应对这个问题。

    

    大型语言模型（LLMs）产生的长文生成物包含了一系列事实和非事实的主张，这使得评估事实性变得困难。为了以更精细的方式评估长文生成物的事实准确性，先前的研究提出将长文生成物分解为多个可验证的事实并独立验证这些事实。生成物的事实性是所有事实中可验证事实的比例。这些方法假设结合了事实主张形成了一个事实性段落。本文展示了这一假设可能因为实体模糊而被违反。我们展示了LLMs可以生成包含可验证事实的段落，但由于实体模糊，这些事实被结合形成了一个非事实的段落。我们进一步揭示了现有的事实准确度度量指标，包括FActScore和引用回顾，无法正确评估这些非事实段落的事实性。为了解决这个问题，我们引入了一种增强度量指标，D-FActScore，作为一个具体的解决方案。

    Long-form generations from large language models (LLMs) contains a mix of factual and non-factual claims, making evaluating factuality difficult. To evaluate factual precision of long-form generations in a more fine-grained way, prior works propose to decompose long-form generations into multiple verifiable facts and verify those facts independently. The factuality of the generation is the proportion of verifiable facts among all the facts. Such methods assume that combining factual claims forms a factual paragraph. This paper shows that the assumption can be violated due to entity ambiguity. We show that LLMs can generate paragraphs that contain verifiable facts, but the facts are combined to form a non-factual paragraph due to entity ambiguity. We further reveal that existing factual precision metrics, including FActScore and citation recall, cannot properly evaluate the factuality of these non-factual paragraphs. To address this, we introduce an enhanced metric, D-FActScore, specifi
    
[^15]: 在自然语言推理中评估预训练语言模型的性别偏见，考虑所有标签

    Evaluating Gender Bias of Pre-trained Language Models in Natural Language Inference by Considering All Labels

    [https://arxiv.org/abs/2309.09697](https://arxiv.org/abs/2309.09697)

    提出了一种考虑自然语言推理任务三个标签的预训练语言模型偏见评估方法，通过创造代表不同类型偏见的评估数据组，并实验证明该方法能更好地区分有偏见的、不正确的推理和非有偏见的不正确推理。

    

    在多种语言的预训练语言模型（PLMs）中发现了歧视性的性别偏见。在自然语言推理（NLI）中，现有的偏见评估方法专注于三个标签中的一个特定标签的预测结果，例如中性。然而，这种评估方法可能不准确，因为独特的偏见推理与独特的预测标签相关联。为了解决这一限制，我们提出了一种考虑NLI任务的三个标签的PLMs偏见评估方法。我们创建了三个代表不同类型偏见的评估数据组。然后，我们基于每个数据组的相应标签输出定义了一种偏见度量。在实验中，我们引入了一种用于NLI偏见度量的元评估技术，并用它来确认我们的偏见度量可以更好地区分有偏见的，不正确的推理与非偏见的不正确推理，胜过基线，从而导致了m

    arXiv:2309.09697v2 Announce Type: replace  Abstract: Discriminatory gender biases have been found in Pre-trained Language Models (PLMs) for multiple languages. In Natural Language Inference (NLI), existing bias evaluation methods have focused on the prediction results of a specific label out of three labels, such as neutral. However, such evaluation methods can be inaccurate since unique biased inferences are associated with unique prediction labels. Addressing this limitation, we propose a bias evaluation method for PLMs that considers all the three labels of NLI task. We create three evaluation data groups that represent different types of biases. Then, we define a bias measure based on the corresponding label output of each data group. In the experiments, we introduce a meta-evaluation technique for NLI bias measures and use it to confirm that our bias measure can distinguish biased, incorrect inferences from non-biased incorrect inferences better than the baseline, resulting in a m
    
[^16]: 具有概念感知注意力的知识增强图神经网络用于不良药物事件检测

    Knowledge-augmented Graph Neural Networks with Concept-aware Attention for Adverse Drug Event Detection

    [https://arxiv.org/abs/2301.10451](https://arxiv.org/abs/2301.10451)

    本研究提出了一种具有概念感知注意力的知识增强图神经网络，用于不良药物事件检测，通过将医学知识和文本图相结合，实现了不同类型节点的特征学习。

    

    不良药物事件（ADEs）是药物安全的重要方面。各种文本，如生物医学文献、药物评论、社交媒体和医疗论坛上的用户帖子，包含大量关于ADEs的信息。近期的研究应用了基于词嵌入和深度学习的自然语言处理技术来自动化从文本中检测ADEs。然而，它们未探讨如何将药物和不良反应的显式医学知识或相应的特征学习纳入到其中。本文采用描述文档、单词和概念之间关系的异质文本图，并通过统一医学语言系统中的医学知识增强它，提出了一个概念感知注意力机制，该机制为图中不同类型的节点不同地学习特征。我们还利用了预训练语言模型的上下文化嵌入和卷积图神经网络，以进行有效的特征学习。

    arXiv:2301.10451v2 Announce Type: replace  Abstract: Adverse drug events (ADEs) are an important aspect of drug safety. Various texts such as biomedical literature, drug reviews, and user posts on social media and medical forums contain a wealth of information about ADEs. Recent studies have applied word embedding and deep learning -based natural language processing to automate ADE detection from text. However, they did not explore incorporating explicit medical knowledge about drugs and adverse reactions or the corresponding feature learning. This paper adopts the heterogenous text graph which describes relationships between documents, words and concepts, augments it with medical knowledge from the Unified Medical Language System, and proposes a concept-aware attention mechanism which learns features differently for the different types of nodes in the graph. We further utilize contextualized embeddings from pretrained language models and convolutional graph neural networks for effecti
    
[^17]: MoSECroT: 使用静态词向量进行模型拼接实现跨语言零样例迁移

    MoSECroT: Model Stitching with Static Word Embeddings for Crosslingual Zero-shot Transfer. (arXiv:2401.04821v1 [cs.CL])

    [http://arxiv.org/abs/2401.04821](http://arxiv.org/abs/2401.04821)

    MoSECroT是一个结合静态词向量的模型拼接框架，用于跨语言零样例迁移。它利用相对表示构建了源语言预训练语言模型和目标语言静态词向量的共享空间，从而实现了通过简单交换嵌入从源语言训练数据中进行训练，并在目标语言上进行零样例迁移。

    

    基于Transformer的预训练语言模型（PLMs）在各种自然语言处理（NLP）任务中取得了显著的性能。然而，这种模型的预训练需要大量资源，而这些资源几乎只有高资源语言才能获得。相反，静态词向量的训练更容易，可以更节省计算资源和数据量。本文介绍了MoSECroT（Model Stitching with Static Word Embeddings for Crosslingual Zero-shot Transfer）模型拼接与静态词向量结合的新颖且具有挑战性的任务，特别适用于存在静态词向量的低资源语言。为了解决这个任务，我们提出了第一个利用相对表示构建源语言PLM嵌入和目标语言静态词向量之间的共享空间的框架。通过这种方式，我们可以使用源语言训练数据训练PLM，并通过简单地交换嵌入完成从源语言到目标语言的零样例迁移。

    Transformer-based pre-trained language models (PLMs) have achieved remarkable performance in various natural language processing (NLP) tasks. However, pre-training such models can take considerable resources that are almost only available to high-resource languages. On the contrary, static word embeddings are easier to train in terms of computing resources and the amount of data required. In this paper, we introduce MoSECroT Model Stitching with Static Word Embeddings for Crosslingual Zero-shot Transfer), a novel and challenging task that is especially relevant to low-resource languages for which static word embeddings are available. To tackle the task, we present the first framework that leverages relative representations to construct a common space for the embeddings of a source language PLM and the static word embeddings of a target language. In this way, we can train the PLM on source-language training data and perform zero-shot transfer to the target language by simply swapping th
    
[^18]: 对表格数据查询和可视化的自然语言界面：一项调查

    Natural Language Interfaces for Tabular Data Querying and Visualization: A Survey. (arXiv:2310.17894v1 [cs.CL])

    [http://arxiv.org/abs/2310.17894](http://arxiv.org/abs/2310.17894)

    本调查对表格数据查询和可视化的自然语言界面进行了全面概述，介绍了语义解析等关键技术，并深入探讨了Text-to-SQL和Text-to-Vis问题的最新进展。

    

    自然语言处理的出现彻底改变了用户与表格数据的交互方式，实现了从传统的查询语言和手动绘图转向更直观、基于语言的界面。大型语言模型（LLM）如ChatGPT及其后继者进一步推动了这一领域的发展，为自然语言处理技术开辟了新的途径。本调查提供了关于表格数据查询和可视化的自然语言界面的全面概述，这些界面允许用户使用自然语言查询与数据进行交互。我们介绍了这些界面的基本概念和技术，特别强调语义解析，这是实现从自然语言到SQL查询或数据可视化命令转化的关键技术。然后从数据集、方法论、评估指标和系统设计的角度深入探讨了Text-to-SQL和Text-to-Vis问题的最新进展。

    The emergence of natural language processing has revolutionized the way users interact with tabular data, enabling a shift from traditional query languages and manual plotting to more intuitive, language-based interfaces. The rise of large language models (LLMs) such as ChatGPT and its successors has further advanced this field, opening new avenues for natural language processing techniques. This survey presents a comprehensive overview of natural language interfaces for tabular data querying and visualization, which allow users to interact with data using natural language queries. We introduce the fundamental concepts and techniques underlying these interfaces with a particular emphasis on semantic parsing, the key technology facilitating the translation from natural language to SQL queries or data visualization commands. We then delve into the recent advancements in Text-to-SQL and Text-to-Vis problems from the perspectives of datasets, methodologies, metrics, and system designs. Thi
    
[^19]: 使用任务级混合专家模型的直接神经机器翻译

    Direct Neural Machine Translation with Task-level Mixture of Experts models. (arXiv:2310.12236v1 [cs.CL])

    [http://arxiv.org/abs/2310.12236](http://arxiv.org/abs/2310.12236)

    在这项工作中，我们研究了任务级MoE在直接神经机器翻译中的应用，并提出了一系列高性能的训练和评估配置，通过这些配置，任务级MoE的直接NMT系统在大量低资源语言对上优于双语和基于中间语言的模型。

    

    直接神经机器翻译（Direct NMT）是一种在两种非英语语言之间进行翻译的NMT系统。直接NMT系统通常面临由于非英语语言对之间平行数据稀缺导致的限制。已经提出了几种方法来解决这一限制，例如多语NMT和基于中间语言（通过英语进行翻译的NMT）的NMT。任务级混合专家模型（Task-level MoE）是一种基于Transformer模型的推理高效变体，对许多语言对展现了有前景的NMT性能。在任务级MoE中，不同的语言分组可以使用不同的路由策略来优化跨语言学习和推理速度。本文研究了任务级MoE在直接NMT中的适用性，并提出了一系列高性能的训练和评估配置，通过这些任务级MoE基础的直接NMT系统在大量低资源语言对上优于双语和基于中间语言的模型。

    Direct neural machine translation (direct NMT) is a type of NMT system that translates text between two non-English languages. Direct NMT systems often face limitations due to the scarcity of parallel data between non-English language pairs. Several approaches have been proposed to address this limitation, such as multilingual NMT and pivot NMT (translation between two languages via English). Task-level Mixture of expert models (Task-level MoE), an inference-efficient variation of Transformer-based models, has shown promising NMT performance for a large number of language pairs. In Task-level MoE, different language groups can use different routing strategies to optimize cross-lingual learning and inference speed. In this work, we examine Task-level MoE's applicability in direct NMT and propose a series of high-performing training and evaluation configurations, through which Task-level MoE-based direct NMT systems outperform bilingual and pivot-based models for a large number of low an
    
[^20]: 理解人工智能认知：受人类记忆机制启发的推理神经模块

    Understanding AI Cognition: A Neural Module for Inference Inspired by Human Memory Mechanisms. (arXiv:2310.09297v1 [cs.LG])

    [http://arxiv.org/abs/2310.09297](http://arxiv.org/abs/2310.09297)

    该论文提出了一个受人类记忆机制启发的神经模块，模拟人类和机器如何对当前输入进行关联推理和问答，并将其与过去的记忆结合起来。通过感知、记忆和推理组件，该模块实现了感知更新、记忆融合和信息检索的功能。

    

    人类和机器如何将当前的输入与过去的记忆结合起来，进行关联推理和问答，并将感知到的信息置于上下文中，这是认知科学和人工智能中的一个具有挑战性的谜题。受到人脑记忆系统和认知结构的启发，我们提出了一个包含感知、记忆和推理组件的PMI框架。特别地，记忆模块包括工作记忆和长期记忆，其中后者具有更高阶的结构来保留更多的累积知识和经验。通过可区分的竞争写入访问，当前的感知更新工作记忆，之后通过外积关联与长期记忆融合，避免内存溢出并最小化信息冲突。在推理模块中，相关信息从两个单独的记忆源检索并结合，以获得更全面和精确的解释。

    How humans and machines make sense of current inputs for relation reasoning and question-answering while putting the perceived information into context of our past memories, has been a challenging conundrum in cognitive science and artificial intelligence. Inspired by human brain's memory system and cognitive architectures, we propose a PMI framework that consists of perception, memory and inference components. Notably, the memory module comprises working and long-term memory, with the latter endowed with a higher-order structure to retain more accumulated knowledge and experiences. Through a differentiable competitive write access, current perceptions update working memory, which is later merged with long-term memory via outer product associations, averting memory overflow and minimizing information conflicts. In the inference module, relevant information is retrieved from two separate memory origins and associatively integrated to attain a more comprehensive and precise interpretatio
    
[^21]: 大型语言模型的语义不变鲁棒水印

    A Semantic Invariant Robust Watermark for Large Language Models. (arXiv:2310.06356v1 [cs.CR])

    [http://arxiv.org/abs/2310.06356](http://arxiv.org/abs/2310.06356)

    本论文提出了一种对大型语言模型进行语义不变水印的方法，该方法通过利用另一个嵌入式语言模型生成所有前面token的语义嵌入，然后利用训练得到的水印模型将这些语义嵌入转换为水印logits。该方法既具有攻击鲁棒性又具有安全鲁棒性。

    

    大型语言模型的水印算法在检测LLM生成的文本方面取得了极高的准确性。然而，先前的算法在攻击鲁棒性和安全鲁棒性之间存在一个权衡。本文提出了一种对LLM进行语义不变水印的方法，该方法既具有攻击鲁棒性又具有安全鲁棒性。我们的方法通过另一个嵌入式LLM生成所有前面token的语义嵌入，然后通过训练得到的水印模型将这些语义嵌入转换为水印logits。

    Watermark algorithms for large language models (LLMs) have achieved extremely high accuracy in detecting text generated by LLMs. Such algorithms typically involve adding extra watermark logits to the LLM's logits at each generation step. However, prior algorithms face a trade-off between attack robustness and security robustness. This is because the watermark logits for a token are determined by a certain number of preceding tokens; a small number leads to low security robustness, while a large number results in insufficient attack robustness. In this work, we propose a semantic invariant watermarking method for LLMs that provides both attack robustness and security robustness. The watermark logits in our work are determined by the semantics of all preceding tokens. Specifically, we utilize another embedding LLM to generate semantic embeddings for all preceding tokens, and then these semantic embeddings are transformed into the watermark logits through our trained watermark model. Subs
    
[^22]: 评委：一个综合评估工具包

    Jury: A Comprehensive Evaluation Toolkit. (arXiv:2310.02040v1 [cs.CL])

    [http://arxiv.org/abs/2310.02040](http://arxiv.org/abs/2310.02040)

    评委是一个统一的评估框架和工具包，旨在解决深度学习中不同系统和指标的评估挑战，并改进度量评估。

    

    评估在深度学习中扮演着一个至关重要的角色，作为任何基于预测的系统的基本模块。然而，大量的自然语言处理（NLP）任务和各种指标的发展导致了使用不同指标评估不同系统的挑战。为了解决这些问题，我们推出了一个名为评委的工具包，提供了一个统一的评估框架和标准化结构，以跨不同任务和指标进行评估。评委的目标是标准化和改进所有系统的度量评估，并帮助社区克服评估中的挑战。自评委的开源发布以来，已经吸引了广大用户，可在https://github.com/obss/jury 上获得。

    Evaluation plays a critical role in deep learning as a fundamental block of any prediction-based system. However, the vast number of Natural Language Processing (NLP) tasks and the development of various metrics have led to challenges in evaluating different systems with different metrics. To address these challenges, we introduce jury, a toolkit that provides a unified evaluation framework with standardized structures for performing evaluation across different tasks and metrics. The objective of jury is to standardize and improve metric evaluation for all systems and aid the community in overcoming the challenges in evaluation. Since its open-source release, jury has reached a wide audience and is available at https://github.com/obss/jury.
    
[^23]: 你仅关注屏幕：多模态动作链机器人

    You Only Look at Screens: Multimodal Chain-of-Action Agents. (arXiv:2309.11436v1 [cs.CL])

    [http://arxiv.org/abs/2309.11436](http://arxiv.org/abs/2309.11436)

    本论文提出了一种名为Auto-UI的多模态动作链机器人，通过直接与界面交互，避免了环境解析或依赖于应用程序API的需要，并引入了动作链技术来帮助模型进行决策。

    

    自主用户界面（UI）机器人旨在通过与用户界面进行交互，实现任务自动化，无需手动干预。最近的研究探讨了利用大型语言模型（LLM）的能力，以在多样环境中有效参与。为了符合LLM的输入-输出要求，现有方法在沙盒环境中开发，依赖于外部工具和应用程序特定的API将环境解析为文本元素，并解释预测的动作。因此，这些方法常常受到推理效率低和错误传播风险的困扰。为了缓解这些挑战，我们引入了Auto-UI，一种多模态解决方案，它直接与界面交互，避免了对环境解析或依赖于应用程序相关的API的需求。此外，我们提出了一种动作链技术，利用一系列中间先前动作历史和未来动作计划，以帮助模型进行决策。

    Autonomous user interface (UI) agents aim to facilitate task automation by interacting with the user interface without manual intervention. Recent studies have investigated eliciting the capabilities of large language models (LLMs) for effective engagement in diverse environments. To align with the input-output requirement of LLMs, existing approaches are developed under a sandbox setting where they rely on external tools and application-specific APIs to parse the environment into textual elements and interpret the predicted actions. Consequently, those approaches often grapple with inference inefficiency and error propagation risks. To mitigate the challenges, we introduce Auto-UI, a multimodal solution that directly interacts with the interface, bypassing the need for environment parsing or reliance on application-dependent APIs. Moreover, we propose a chain-of-action technique -leveraging a series of intermediate previous action histories and future action plans -- to help the age
    
[^24]: K-pop歌词翻译：数据集、分析与神经建模

    K-pop Lyric Translation: Dataset, Analysis, and Neural-Modelling. (arXiv:2309.11093v1 [cs.CL])

    [http://arxiv.org/abs/2309.11093](http://arxiv.org/abs/2309.11093)

    研究者介绍了一种新颖的K-pop歌词翻译数据集，该数据集揭示了K-pop歌词翻译的独特特征，并构建了一个神经歌词翻译模型，强调了专用数据集的重要性。

    

    歌词翻译作为一个研究了一个世纪的领域，如今吸引着计算语言学研究者的注意。我们在以往研究中发现了两个限制。首先，在歌词翻译研究中，尽管K-pop非常受欢迎，但主要关注的是西方流派和语言，没有研究集中在K-pop上。其次，歌词翻译领域缺乏可公开获得的数据集；据我们所知，目前尚无此类数据集。为了拓宽歌词翻译研究的流派和语言范围，我们引入了一种新颖的可唱歌词翻译数据集，其中约89%为K-pop歌词。该数据集通过逐行和逐节对齐了韩语和英语歌词。我们利用该数据集揭示了K-pop歌词翻译的独特特征，与其他广泛研究的流派区分开，并构建了一个神经歌词翻译模型，从而强调了专用数据集的重要性。

    Lyric translation, a field studied for over a century, is now attracting computational linguistics researchers. We identified two limitations in previous studies. Firstly, lyric translation studies have predominantly focused on Western genres and languages, with no previous study centering on K-pop despite its popularity. Second, the field of lyric translation suffers from a lack of publicly available datasets; to the best of our knowledge, no such dataset exists. To broaden the scope of genres and languages in lyric translation studies, we introduce a novel singable lyric translation dataset, approximately 89\% of which consists of K-pop song lyrics. This dataset aligns Korean and English lyrics line-by-line and section-by-section. We leveraged this dataset to unveil unique characteristics of K-pop lyric translation, distinguishing it from other extensively studied genres, and to construct a neural lyric translation model, thereby underscoring the importance of a dedicated dataset for
    
[^25]: 使用自我推测解码实现无损大型语言模型加速的Draft & Verify方法

    Draft & Verify: Lossless Large Language Model Acceleration via Self-Speculative Decoding. (arXiv:2309.08168v1 [cs.CL])

    [http://arxiv.org/abs/2309.08168](http://arxiv.org/abs/2309.08168)

    使用自我推测解码的Draft & Verify方法能够加速大型语言模型的推理过程，同时保持输出质量，并不需要额外的训练和内存占用。

    

    我们提出了一种新的推理方案，称为自我推测解码，用于加速大型语言模型（LLM），而无需辅助模型。该方法通过两个阶段的过程来实现：起草和验证。起草阶段以稍低质量但更快的速度生成草案标记，这是通过在起草过程中有选择地跳过某些中间层来实现的。随后，验证阶段使用原始LLM在一次前向传递中验证那些起草产生的输出标记。这个过程确保最终输出与未修改的LLM产生的输出完全相同，从而确保输出质量。所提出的方法不需要额外的神经网络训练和额外的内存占用，可以作为一种即插即用且具有成本效益的推理加速解决方案。

    We present a novel inference scheme, self-speculative decoding, for accelerating Large Language Models (LLMs) without the need for an auxiliary model. This approach is characterized by a two-stage process: drafting and verification. The drafting stage generates draft tokens at a slightly lower quality but more quickly, which is achieved by selectively skipping certain intermediate layers during drafting Subsequently, the verification stage employs the original LLM to validate those draft output tokens in one forward pass. This process ensures the final output remains identical to that produced by the unaltered LLM, thereby maintaining output quality. The proposed method requires no additional neural network training and no extra memory footprint, making it a plug-and-play and cost-effective solution for inference acceleration. Benchmarks with LLaMA-2 and its fine-tuned models demonstrated a speedup up to 1.73$\times$.
    
[^26]: 大型语言模型的再识别能力：匿名面临风险吗？

    Anonymity at Risk? Assessing Re-Identification Capabilities of Large Language Models. (arXiv:2308.11103v1 [cs.CL])

    [http://arxiv.org/abs/2308.11103](http://arxiv.org/abs/2308.11103)

    本研究评估了大型语言模型在重新识别匿名个人方面的能力，并发现模型大小、输入长度和指令调整是最重要的决定因素。

    

    在欧盟和瑞士，法院裁决中自然人和法人的匿名性是隐私保护的关键方面。随着大型语言模型（LLMs）的出现，对于匿名人员的大规模再识别的担忧日益增长。根据瑞士联邦最高法院的要求，我们通过使用来自瑞士联邦最高法院的实际法律数据构建了一个概念验证，来探讨LLMs重新识别法院裁决中个人的潜力。在最初的实验之后，我们构建了一个经过匿名化处理的维基百科数据集，作为一个更严格的测试场地来进一步研究研究结果。通过引入并应用文本中再识别人员的新任务，我们还引入了新的性能衡量指标。我们系统地分析了影响成功再识别的因素，确定模型大小、输入长度和指令调整是最重要的决定因素之一。尽管在匿名化处理后，LLMs在重新识别上的成功率很高，但在某些情况下仍然存在风险。

    Anonymity of both natural and legal persons in court rulings is a critical aspect of privacy protection in the European Union and Switzerland. With the advent of LLMs, concerns about large-scale re-identification of anonymized persons are growing. In accordance with the Federal Supreme Court of Switzerland, we explore the potential of LLMs to re-identify individuals in court rulings by constructing a proof-of-concept using actual legal data from the Swiss federal supreme court. Following the initial experiment, we constructed an anonymized Wikipedia dataset as a more rigorous testing ground to further investigate the findings. With the introduction and application of the new task of re-identifying people in texts, we also introduce new metrics to measure performance. We systematically analyze the factors that influence successful re-identifications, identifying model size, input length, and instruction tuning among the most critical determinants. Despite high re-identification rates on
    
[^27]: YORC：约鲁巴语阅读理解数据集

    YORC: Yoruba Reading Comprehension dataset. (arXiv:2308.09768v1 [cs.CL])

    [http://arxiv.org/abs/2308.09768](http://arxiv.org/abs/2308.09768)

    本文介绍了一个新的多项选择约鲁巴语阅读理解数据集YORC，通过跨语言转移和大型语言模型的使用，提供了该数据集的基准结果和更高层次的结果。

    

    本文介绍了YORC：一个基于约鲁巴语高中阅读理解考试的新的多项选择约鲁巴语阅读理解数据集。我们使用已训练的仅编码器模型，通过跨语言转移来提供基准结果，同时还使用大型语言模型（LLMs）如GPT-4提供了结果。

    In this paper, we create YORC: a new multi-choice Yoruba Reading Comprehension dataset that is based on Yoruba high-school reading comprehension examination. We provide baseline results by performing cross-lingual transfer using existing English RACE dataset based on a pre-trained encoder-only model. Additionally, we provide results by prompting large language models (LLMs) like GPT-4.
    
[^28]: 一种基于LSTM、BiLSTM、CNN、GRU和GloVe的混合机器学习模型用于基因突变在癌症中的分类

    A Hybrid Machine Learning Model for Classifying Gene Mutations in Cancer using LSTM, BiLSTM, CNN, GRU, and GloVe. (arXiv:2307.14361v1 [q-bio.QM])

    [http://arxiv.org/abs/2307.14361](http://arxiv.org/abs/2307.14361)

    本研究提出了一个基于多种机器学习算法和嵌入模型的集成模型，用于基因突变在癌症中的分类。实验结果表明，该模型在准确率、精确率、召回率等指标上优于其他传统和最新的转换器模型，并且具有更高的训练效率。

    

    本研究提出了一个集成模型，将LSTM、BiLSTM、CNN、GRU和GloVe结合起来，用于在Kaggle的“个性化医学：重新定义癌症治疗”数据集中对基因突变进行分类。通过与BERT、Electra、Roberta、XLNet、Distilbert以及它们的LSTM集成等知名转换器进行比较，结果显示我们的模型在准确率、精确率、召回率、F1分数和均方误差方面都优于其他模型。令人惊讶的是，它还需要较少的训练时间，实现了性能和效率的完美结合。该研究证明了集成模型在基因突变分类等困难任务中的实用性。

    This study presents an ensemble model combining LSTM, BiLSTM, CNN, GRU, and GloVe to classify gene mutations using Kaggle's Personalized Medicine: Redefining Cancer Treatment dataset. The results were compared against well-known transformers like as BERT, Electra, Roberta, XLNet, Distilbert, and their LSTM ensembles. Our model outperformed all other models in terms of accuracy, precision, recall, F1 score, and Mean Squared Error. Surprisingly, it also needed less training time, resulting in a perfect combination of performance and efficiency. This study demonstrates the utility of ensemble models for difficult tasks such as gene mutation classification.
    
[^29]: 通过基于LLM的属性操作生成高效训练数据

    Generating Efficient Training Data via LLM-based Attribute Manipulation. (arXiv:2307.07099v1 [cs.CL])

    [http://arxiv.org/abs/2307.07099](http://arxiv.org/abs/2307.07099)

    本文提出了一种通过大型语言模型（LLMs）生成精心制作的训练数据来引导少样本学习的方法。通过利用LLMs操作任务特定属性并重构新的句子，我们实现了标签交换数据的生成，与其他基于LLMs的文本生成方法相比具有更好的效果。同时，研究结果还显示了通过LLM引导学习的潜力，即使在更少的监督情况下也能取得良好的表现。

    

    本文提出了一种新颖的方法，链式思维属性操作（CoTAM），通过从大型语言模型（LLMs）中精心制作的数据来引导少样本学习。主要思想是仅对任务目标属性进行更改并创建数据。受到面部属性操作的启发，我们的方法利用LLMs来操作任务特定属性并以受控的方式重构新的句子，从而生成标签交换数据。我们采用链式思维分解和重构来适应LLMs，而不是传统的潜在表示控制方法。在文本分类和其他任务上进行了广泛的实验结果验证了CoTAM相对于其他具有相同数量训练样本的基于LLMs的文本生成方法的优势。分析结果可视化了CoTAM的属性操作效果，并展示了在更少监督的情况下通过LLM引导学习的潜力。

    In this paper, we propose a novel method, Chain-of-Thoughts Attribute Manipulation (CoTAM), to guide few-shot learning by carefully crafted data from Large Language Models (LLMs). The main idea is to create data with changes only in the attribute targeted by the task. Inspired by facial attribute manipulation, our approach generates label-switched data by leveraging LLMs to manipulate task-specific attributes and reconstruct new sentences in a controlled manner. Instead of conventional latent representation controlling, we implement chain-of-thoughts decomposition and reconstruction to adapt the procedure to LLMs. Extensive results on text classification and other tasks verify the advantage of CoTAM over other LLM-based text generation methods with the same number of training examples. Analysis visualizes the attribute manipulation effectiveness of CoTAM and presents the potential of LLM-guided learning with even less supervision.
    
[^30]: Statler：用于具身推理的保持状态的语言模型

    Statler: State-Maintaining Language Models for Embodied Reasoning. (arXiv:2306.17840v1 [cs.RO])

    [http://arxiv.org/abs/2306.17840](http://arxiv.org/abs/2306.17840)

    Statler是一个为LLMs赋予了明确的、维持状态的语言模型，可以解决当代LLMs在长时间范围内推理的困难。

    

    大型语言模型（LLMs）为机器人执行复杂的机器人推理任务提供了一种有希望的工具。然而，当代LLMs的有限上下文窗口使得在长时间范围内进行推理变得困难。具身任务（例如我们期望一个家庭机器人执行的任务）通常需要规划者考虑很久之前获得的信息（例如，机器人在环境中遇到的许多对象的属性）。通过LLM的隐含内部表示来捕获世界状态的尝试会因为机器人操作历史中可用的与任务和环境相关的信息有限而变得复杂，而依赖通过提示向LLM传递信息的方法则受其有限的上下文窗口的限制。在本文中，我们提出了Statler，一个为LLMs赋予了明确的、作为“记忆”的世界状态表示的框架，这种记忆随时间保持。

    Large language models (LLMs) provide a promising tool that enable robots to perform complex robot reasoning tasks. However, the limited context window of contemporary LLMs makes reasoning over long time horizons difficult. Embodied tasks such as those that one might expect a household robot to perform typically require that the planner consider information acquired a long time ago (e.g., properties of the many objects that the robot previously encountered in the environment). Attempts to capture the world state using an LLM's implicit internal representation is complicated by the paucity of task- and environment-relevant information available in a robot's action history, while methods that rely on the ability to convey information via the prompt to the LLM are subject to its limited context window. In this paper, we propose Statler, a framework that endows LLMs with an explicit representation of the world state as a form of ``memory'' that is maintained over time. Integral to Statler i
    
[^31]: MultiLegalPile：689GB的多语言法律语料库

    MultiLegalPile: A 689GB Multilingual Legal Corpus. (arXiv:2306.02069v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.02069](http://arxiv.org/abs/2306.02069)

    MultiLegalPile是一个689GB的多语言法律语料库，包含来自17个司法管辖区的24种语言的不同法律数据源，允许在公平使用下针对预训练NLP模型。该语料库为多语言模型的预训练提供了新的最佳表现，并在LexGLUE上表现最佳。

    

    大型高质量的数据集对于训练大型语言模型(LLMs)至关重要。然而，目前为止，专业领域（如法律）可用的数据集很少，而且经常仅限于英语。我们整理并发布了MultiLegalPile，这是一个包含来自17个司法管辖区的24种语言的689GB语料库。MultiLegalPile语料库包括各种许可证的不同法律数据源，允许在公平使用下针对预训练自然语言处理(NLP)模型，对于Eurlex Resources和Legal mC4子集拥有更宽松的许可证。我们进行了两个RoBERTa模型和一个多语言Longformer的预训练，并分别在每种特定语言子集上进行了24个单语模型的预训练，并在LEXTREME上对它们进行了评估。此外，我们在LexGLUE上对英语和多语言模型进行了评估。我们的多语言模型在LEXTREME上创造了新的最佳表现(SotA)，英语模型则在LexGLUE上表现最佳。我们将数据集、训练模型和代码全部释放在最开放的许可证下。

    Large, high-quality datasets are crucial for training Large Language Models (LLMs). However, so far, there are few datasets available for specialized critical domains such as law and the available ones are often only for the English language. We curate and release MultiLegalPile, a 689GB corpus in 24 languages from 17 jurisdictions. The MultiLegalPile corpus, which includes diverse legal data sources with varying licenses, allows for pretraining NLP models under fair use, with more permissive licenses for the Eurlex Resources and Legal mC4 subsets. We pretrain two RoBERTa models and one Longformer multilingually, and 24 monolingual models on each of the language-specific subsets and evaluate them on LEXTREME. Additionally, we evaluate the English and multilingual models on LexGLUE. Our multilingual models set a new SotA on LEXTREME and our English models on LexGLUE. We release the dataset, the trained models, and all of the code under the most open possible licenses.
    
[^32]: 生成可信的文本：大型语言模型的不确定性量化

    Generating with Confidence: Uncertainty Quantification for Black-box Large Language Models. (arXiv:2305.19187v1 [cs.CL])

    [http://arxiv.org/abs/2305.19187](http://arxiv.org/abs/2305.19187)

    本研究提出应对大型语言模型可信度问题的方法，研究黑盒模型中置信度与不确定性量化，并将其应用于选择性自然语言生成。

    

    近期，专门用于自然语言生成的大型语言模型(LLMs)在各个领域表现出了很好的能力，但是评估LLMs生成的结果的可信度仍然是一个挑战，关于自然语言生成的不确定性量化的研究也较少。此外，现有的文献通常假定对语言模型的白盒访问，这要么是由于最新的LLMs的封闭源代码的性质，要么是由于计算限制。本文研究了黑盒LLMs的不确定性量化问题。我们首先区分了两种密切相关的概念: 只与输入有关的“不确定性”和还与生成的回复有关的“置信度”。然后我们提出并比较了几个置信度/不确定度指标，将它们应用于“选择性自然语言生成”，其中不可靠的结果可以被忽略或者移交给进一步的分析。

    Large language models (LLMs) specializing in natural language generation (NLG) have recently started exhibiting promising capabilities across a variety of domains. However, gauging the trustworthiness of responses generated by LLMs remains an open challenge, with limited research on uncertainty quantification for NLG. Furthermore, existing literature typically assumes white-box access to language models, which is becoming unrealistic either due to the closed-source nature of the latest LLMs or due to computational constraints. In this work, we investigate uncertainty quantification in NLG for $\textit{black-box}$ LLMs. We first differentiate two closely-related notions: $\textit{uncertainty}$, which depends only on the input, and $\textit{confidence}$, which additionally depends on the generated response. We then propose and compare several confidence/uncertainty metrics, applying them to $\textit{selective NLG}$, where unreliable results could either be ignored or yielded for further 
    
[^33]: COKE：机器心智理论的认知知识图谱

    COKE: A Cognitive Knowledge Graph for Machine Theory of Mind. (arXiv:2305.05390v1 [cs.CL])

    [http://arxiv.org/abs/2305.05390](http://arxiv.org/abs/2305.05390)

    COKE是一个机器心智理论的认知知识图谱，将ToM形式化为一组经手动验证的认知链，可以帮助AI系统在社交智能等任务上具备推理人类心智的能力。

    

    心智理论（ToM）是指人类理解和推断他人欲望、信念和意图的能力。获取ToM对人类的社会认知和人际关系起着关键作用。尽管ToM对于社交智能至关重要，但现代AI和NLP系统仍然缺乏该能力，因为它们无法访问训练语料库之下的人类心智状态和认知过程。为了赋予AI系统ToM能力，缩小它们与人类之间的差距，在本文中，我们提出了COKE：第一个机器心智理论的认知知识图谱。具体而言，COKE将ToM形式化为一组45k+经手动验证的认知链，这些链描绘了人类在特定社交环境下的心理活动和随后的行为/情感反应。除此之外，我们还使用预训练的语言模型进一步推广了COKE，并构建了一个强大的认知生成模型COKE+。在自动和人工评估方面的实验结果表明，COKE对于各种与ToM相关的任务，包括社交常识推理、情感识别和可解释对话，具有有效性和可解释性。

    Theory of mind (ToM) refers to humans' ability to understand and infer the desires, beliefs, and intentions of others. The acquisition of ToM plays a key role in humans' social cognition and interpersonal relations. Though indispensable for social intelligence, ToM is still lacking for modern AI and NLP systems since they cannot access the human mental state and cognitive process beneath the training corpus. To empower AI systems with the ToM ability and narrow the gap between them and humans, in this paper, we propose COKE: the first cognitive knowledge graph for machine theory of mind. Specifically, COKE formalizes ToM as a collection of 45k+ manually verified cognitive chains that characterize human mental activities and subsequent behavioral/affective responses when facing specific social circumstances. Beyond that, we further generalize COKE using pre-trained language models and build a powerful cognitive generation model COKE+. Experimental results in both automatic and human eva
    

