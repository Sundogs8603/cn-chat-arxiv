# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Chat2Brain: A Method for Mapping Open-Ended Semantic Queries to Brain Activation Maps.](http://arxiv.org/abs/2309.05021) | Chat2Brain是一种结合了大型语言模型和基本的文本-图像模型的方法，用于将开放型语义查询映射到脑部激活图。它解决了元分析中存在的语义冗余和歧义导致映射不准确的问题。 |
| [^2] | [FOLLOWUPQG: Towards Information-Seeking Follow-up Question Generation.](http://arxiv.org/abs/2309.05007) | 本文引入了一项真实世界的信息获取跟进问题生成任务，通过生成跟进问题来更深入地理解初始问题和答案。构建了数据集FOLLOWUPQG，评估了当前的问题生成模型在生成跟进问题方面的效果，并展示了其作为一个具有挑战性的基准任务的验证。 |
| [^3] | [Mitigating Word Bias in Zero-shot Prompt-based Classifiers.](http://arxiv.org/abs/2309.04992) | 这项研究关注减轻基于提示的分类器中的词偏差问题，并提出了一种无监督的方法来优化类别先验概率，从而提高分类性能。 |
| [^4] | [Retrieval-Augmented Meta Learning for Low-Resource Text Classification.](http://arxiv.org/abs/2309.04979) | 本论文提出了一种基于元学习的方法，称为检索增强元学习（RAML），用于解决低资源文本分类中的泛化性能差问题。该方法不仅使用参数化进行推理，还从外部语料库中检索非参数化知识进行推理，以提高泛化能力和解决元学习中缺乏多样性训练数据的问题。 |
| [^5] | [RGAT: A Deeper Look into Syntactic Dependency Information for Coreference Resolution.](http://arxiv.org/abs/2309.04977) | 本文提出了一种综合预训练BERT和句法关系图注意网络（RGAT）的端到端解析器，以更深入地研究句法依赖信息在指代消解任务中的作用。通过对句法依赖图进行监督学习，并不需要对整个BERT进行微调，我们提高了先前最佳模型的F1分数。 |
| [^6] | [Prompt Learning With Knowledge Memorizing Prototypes For Generalized Few-Shot Intent Detection.](http://arxiv.org/abs/2309.04971) | 本研究提出了一种使用知识记忆原型进行广义少样本意图检测的提示学习方法，通过将任务转化为类增量学习范式来同时分类已知和新意图。进行了大量的实验和分析，结果表明这种方法在广义少样本意图检测中具有优秀的性能。 |
| [^7] | [Prefix-diffusion: A Lightweight Diffusion Model for Diverse Image Captioning.](http://arxiv.org/abs/2309.04965) | Prefix-diffusion是一种轻量级的图像字幕扩散模型，通过在扩散过程中注入前缀图像嵌入来实现多样性，并通过预训练模型和额外的映射网络来减少参数。该模型能够生成多样的字幕，同时保持流畅性和相关性，并取得了有希望的性能。 |
| [^8] | [Multi-document Summarization: A Comparative Evaluation.](http://arxiv.org/abs/2309.04951) | 本文评估了多文档摘要领域的最新模型在不同领域和数据集上的表现，发现通用预训练模型LED在MS$^2$数据集上的性能优于其他模型，为未来的MDS研究提供了宝贵的参考和发展方向。 |
| [^9] | [What's Hard in English RST Parsing? Predictive Models for Error Analysis.](http://arxiv.org/abs/2309.04940) | 英文RST解析的难点主要是长距离依赖关系，并且最终模型能够预测错误发生的位置。 |
| [^10] | [Unsupervised Chunking with Hierarchical RNN.](http://arxiv.org/abs/2309.04919) | 本论文提出了一种无监督的句块化方法，使用分层循环神经网络来建模单词到句块和句块到句子的组合。在实验中取得了显著的改进，将短语F1得分提高了6个百分点。 |
| [^11] | [Distributional Data Augmentation Methods for Low Resource Language.](http://arxiv.org/abs/2309.04862) | 本文提出了两种用于低资源语言的文本增强方法：易于分布式数据增强（EDDA）和类型特定的相似词替换（TSSR）。它们通过使用语义上下文信息和词性标记来改进易于数据增强方法（EDA），从而提高了低资源语言下的预测性能。 |
| [^12] | [Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System.](http://arxiv.org/abs/2309.04858) | 本文介绍了一种方法，可以逆向工程用于生成文本的解码方法，并发现了这些方法对于检测生成文本以及揭示由于解码设置导致的偏见的重要意义。 |
| [^13] | [Speech Emotion Recognition with Distilled Prosodic and Linguistic Affect Representations.](http://arxiv.org/abs/2309.04849) | 该论文提出了EmoDistill，这是一个利用知识蒸馏来学习从语音中获取情感的强大的语言和语音表示的语音情感识别框架。通过在训练过程中利用经过SER微调的预训练语音和语言教师进行信息蒸馏，该方法在IEMOCAP基准测试中实现了最新的最高准确率，表明其在单模态和多模态技术中的优越性能。 |
| [^14] | [Leveraging Large Language Models for Exploiting ASR Uncertainty.](http://arxiv.org/abs/2309.04842) | 这项工作旨在通过利用ASR的n-best列表来解决大型语言模型在口语理解任务上的潜在限制，而无需实质改变ASR和LLM的结构。 |
| [^15] | [Neurons in Large Language Models: Dead, N-gram, Positional.](http://arxiv.org/abs/2309.04827) | 该论文分析了大型语言模型中的神经元行为，发现网络的早期部分是稀疏的，包含许多死亡神经元和专门用于离散特征的活跃神经元。这些活跃神经元的更新不仅推动下一个标记的生成，还专注于移除与触发它们的标记相关的信息。 |
| [^16] | [FaNS: a Facet-based Narrative Similarity Metric.](http://arxiv.org/abs/2309.04823) | 本研究提出了一种基于要素的叙事相似度度量方法FaNS，通过提取经典的五W一H要素并借助大型语言模型，可以更准确地识别出语义上相似的叙事。实验证明，FaNS与传统文本相似度度量方法相比具有更高的相关性（高37%）。 |
| [^17] | [MMHQA-ICL: Multimodal In-context Learning for Hybrid Question Answering over Text, Tables and Images.](http://arxiv.org/abs/2309.04790) | MMHQA-ICL框架结合了强大的异构数据检索器和图像标题模块，提出了一种特定类型的背景下学习策略，使得大型语言模型能够在多模态混合问答任务中取得最先进的结果。 |
| [^18] | [SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment to Cultural Reasoning.](http://arxiv.org/abs/2309.04766) | SeaEval是一个评估多语言基础模型的基准测试，研究了模型在自然语言理解、推理以及对文化实践、细微差别和价值观的理解能力上的表现。重要发现包括模型在给出改写指令时行为各异，受到暴露偏差的影响，对于语义等价的多语言查询的回答不一致，以及模型在情感相关问题上的一致性不同。 |
| [^19] | [Data Augmentation for Conversational AI.](http://arxiv.org/abs/2309.04739) | 本教程提供了对话式人工智能中数据增强的综述，包括对话增强、开放域和任务导向的对话生成以及评估模型。此外，还讨论了当前的挑战和未来的发展方向，以帮助推动该领域的发展。 |
| [^20] | [Towards Better Multi-modal Keyphrase Generation via Visual Entity Enhancement and Multi-granularity Image Noise Filtering.](http://arxiv.org/abs/2309.04734) | 本文提出了一种新的多模态关键词生成模型，通过引入外部视觉实体作为模型输入并使用图像噪声滤波技术，实现了更好的关键词生成效果。 |
| [^21] | [EPA: Easy Prompt Augmentation on Large Language Models via Multiple Sources and Multiple Targets.](http://arxiv.org/abs/2309.04725) | 本论文提出了一种名为EPA的简易提示增强方法，通过自动使用多个来源/目标来扩充演示，从而提高了大型语言模型的性能，减少了用户编写演示的工作量。 |
| [^22] | [Toward Reproducing Network Research Results Using Large Language Models.](http://arxiv.org/abs/2309.04716) | 本文提出使用大型语言模型（LLMs）来重现网络研究结果，通过一个小规模实验证明了其可行性，并以ChatGPT为工具重现了不同发表于著名会议和期刊的网络系统。 |
| [^23] | [Analysis of Disinformation and Fake News Detection Using Fine-Tuned Large Language Model.](http://arxiv.org/abs/2309.04704) | 本研究考虑使用LLM模型通过细调实现虚假信息和假新闻的深入分析，揭示复杂的风格和叙事，并提取命名实体的情感，以此作为监督机器学习模型中的预测性特征。 |
| [^24] | [Code-Style In-Context Learning for Knowledge-Based Question Answering.](http://arxiv.org/abs/2309.04695) | 本论文提出了一种在上下文中学习编程风格的方法，用于解决基于知识的问答中生成逻辑表达式的格式错误问题。 |
| [^25] | [Embedding structure matters: Comparing methods to adapt multilingual vocabularies to new languages.](http://arxiv.org/abs/2309.04679) | 比较了替换跨语言词汇的几种技术，证明了单语转移文献中的方法不适用于多语言模型。专门化的较小词汇对于提高低资源情况下的性能是有效的。 |
| [^26] | [FIAT: Fusing learning paradigms with Instruction-Accelerated Tuning.](http://arxiv.org/abs/2309.04663) | FIAT是一种将上下文学习和完全微调范式融合的新的学习方式，可以在最大模型上进行指令和推理，并且在较小模型上进行参数更新，经过多语言任务测试，比之前的方法都表现更好。 |
| [^27] | [MADLAD-400: A Multilingual And Document-Level Large Audited Dataset.](http://arxiv.org/abs/2309.04662) | MADLAD-400是一种覆盖419种语言的多语言文档级数据集，通过自我审核揭示了局限性，通过训练众多参数的机器翻译模型取得了竞争力，并提供了基准模型给研究界使用。 |
| [^28] | [Exploring Large Language Models for Communication Games: An Empirical Study on Werewolf.](http://arxiv.org/abs/2309.04658) | 本研究探索了大型语言模型在沟通游戏中的应用，提出了一个无需调参的框架，并通过对狼人杀游戏的实证研究展示了其有效性和出现的战略行为。这表明在沟通游戏和相关领域中使用大型语言模型将具备潜在价值。 |
| [^29] | [Efficient Finetuning Large Language Models For Vietnamese Chatbot.](http://arxiv.org/abs/2309.04646) | 本研究针对越南语聊天机器人的开发，通过利用来自Alpaca、GPT4All和Chat-Doctor等开源项目的大规模指令跟随数据集，成功训练了四个模型，此为越南语的首个指令数据集。 |
| [^30] | [Can NLP Models 'Identify', 'Distinguish', and 'Justify' Questions that Don't have a Definitive Answer?.](http://arxiv.org/abs/2309.04635) | 这项研究提出了QnotA数据集，用于研究NLP模型在没有确定答案的问题上的表现。通过全面的实验，证明最先进的模型能够准确识别和提供合理的回答。 |
| [^31] | [Linking Symptom Inventories using Semantic Textual Similarity.](http://arxiv.org/abs/2309.04607) | 该论文介绍了一种使用语义文本相似性（STS）来链接不同的症状清单的方法，通过测试预训练的STS模型在不同的数据源中预测症状严重程度，该方法在相关任务中达到了74.8%的准确率，优于其他模型。 |
| [^32] | [When Less is More: Investigating Data Pruning for Pretraining LLMs at Scale.](http://arxiv.org/abs/2309.04564) | 在这项工作中，研究人员探究了数据修剪对大规模预训练语言模型(LLMs)的影响。通过比较数据质量评估器和修剪预训练语料库后训练的LLMs，他们发现困惑度作为一种简单的技术优于更加计算密集的评分方法。 |
| [^33] | [Three Ways to Improve Verbo-visual Fusion for Dense 3D Visual Grounding.](http://arxiv.org/abs/2309.04561) | 提出了一个稠密三维引用网络ConcreteNet，包含三个新模块，旨在改善具有相同语义类别干扰因素的重复实例的引用性能。 |
| [^34] | [Retrieving Evidence from EHRs with LLMs: Possibilities and Challenges.](http://arxiv.org/abs/2309.04550) | 本研究提出了一种使用大型语言模型（LLMs）从未结构化的电子健康记录（EHR）中检索和总结相关证据的方法。通过在零样本条件下训练LLM来推断患者是否患有特定疾病，并且模型可以总结支持的证据。该方法在实践中被证明优于传统的信息检索方法。 |
| [^35] | [CSPRD: A Financial Policy Retrieval Dataset for Chinese Stock Market.](http://arxiv.org/abs/2309.04389) | 本研究引入中国股票政策检索数据集（CSPRD），提供了700+条标注的招股说明书段落，通过词汇、嵌入和经过微调的双编码模型的实验证明了CSPRD的有效性和改进潜力。 |
| [^36] | [GRASS: Unified Generation Model for Speech Semantic Understanding.](http://arxiv.org/abs/2309.02780) | 本文介绍了一个统一的端到端框架，通过指令微调技术实现了语音语义理解任务。实验证明该模型在微调下游任务后明显优于最先进的模型，并在零样本和少样本场景中取得了竞争性的性能。 |
| [^37] | [CodeApex: A Bilingual Programming Evaluation Benchmark for Large Language Models.](http://arxiv.org/abs/2309.01940) | CodeApex是一个双语编程评估基准，用于评估大型语言模型在编程理解和代码生成任务上的能力。该基准包括多个选择题和算法问题，评估了14个LLM的编程能力，并发现仍有改进空间。 |
| [^38] | [Interdisciplinary Fairness in Imbalanced Research Proposal Topic Inference: A Hierarchical Transformer-based Method with Selective Interpolation.](http://arxiv.org/abs/2309.01717) | 该论文提出了一种基于层次变换器的方法，通过选择性插值来解决在跨学科研究提案和非跨学科研究提案之间规模差异引起的不公平现象。 |
| [^39] | [Task-Based MoE for Multitask Multilingual Machine Translation.](http://arxiv.org/abs/2308.15772) | 本论文介绍了一种基于任务的混合专家模型，将任务信息与MoE模型相结合，在多任务多语言机器翻译中取得了优越的结果，并且能够高效地应用于新的任务。 |
| [^40] | [Exploring Large Language Models for Knowledge Graph Completion.](http://arxiv.org/abs/2308.13916) | 本文研究了利用大型语言模型（LLM）进行知识图谱补全的方法，并引入了一种创新的框架（知识图谱LLM），以提高三元组分类和关系预测的性能。 |
| [^41] | [MLLM-DataEngine: An Iterative Refinement Approach for MLLM.](http://arxiv.org/abs/2308.13566) | 本文提出了一种名为MLLM-DataEngine的迭代改进方法，它通过分析模型弱点，生成适当的增量数据集并迭代地增强模型能力。与以往方法相比，MLLM-DataEngine生成的数据在定位、质量和正确性方面表现更好。 |
| [^42] | [Financial News Analytics Using Fine-Tuned Llama 2 GPT Model.](http://arxiv.org/abs/2308.13032) | 本研究通过精细调整的Llama 2模型实现了金融新闻的多任务分析，包括文本分析、摘要和情感提取等。实验结果显示，提取的命名实体情感可以作为有监督机器学习模型的预测特征。 |
| [^43] | [HopPG: Self-Iterative Program Generation for Multi-Hop Question Answering over Heterogeneous Knowledge.](http://arxiv.org/abs/2308.11257) | 本文提出了一种针对多跳问答的自我迭代程序生成框架（HopPG），该框架解决了处理异构知识和多跳问题时所面临的困难，并利用了前几跳的执行结果来生成下一跳的程序。 |
| [^44] | [Evaluating Large Language Models on Graphs: Performance Insights and Comparative Analysis.](http://arxiv.org/abs/2308.11224) | 本研究评估了四个大型语言模型在图数据上解决分析问题的能力，结果显示LLM在理解图数据、生成正确结果和进行结构推理方面表现出色，但在真实性和矫正能力方面存在一些挑战。 |
| [^45] | [Establishing Trust in ChatGPT BioMedical Generated Text: An Ontology-Based Knowledge Graph to Validate Disease-Symptom Links.](http://arxiv.org/abs/2308.03929) | 本研究通过构建基于本体的知识图谱，利用疾病本体和症状本体构建数学模型，利用事实核查算法和网络中心度指标分析ChatGPT生成的文本与真实医学文献之间的准确性，以验证疾病-症状关系。 |
| [^46] | [From Probabilistic Programming to Complexity-based Programming.](http://arxiv.org/abs/2307.15453) | CompLog是一种基于复杂性的计算框架，通过计算Kolmogorov复杂性替代概率推理，实现计算某种情况意外性的度量，并通过规范的世界和心智模型的描述生成相关描述，并提供对析取和否定的替代方法。 |
| [^47] | [Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback.](http://arxiv.org/abs/2307.15217) | 本文调查了从人类反馈中进行强化学习的开放问题和基本限制，并提出了加强社会监督的审计和披露标准。 |
| [^48] | [Applying QNLP to sentiment analysis in finance.](http://arxiv.org/abs/2307.11788) | 本论文研究了在金融行业中应用量子自然语言处理(QNLP)进行情感分析的实际适用性。利用一种新颖的数据生成方法，我们发现量子增强的长短期记忆(QLSTM)可以更快地训练，并且在软件实现方面接近古典结果。 |
| [^49] | [Deduplicating and Ranking Solution Programs for Suggesting Reference Solutions.](http://arxiv.org/abs/2307.07940) | 本文提出了一种在编程问题中去除重复程序并排名的方法，以鼓励学习者参考不同的解决方法，从而学习更好的解决方案。 |
| [^50] | [Right to be Forgotten in the Era of Large Language Models: Implications, Challenges, and Solutions.](http://arxiv.org/abs/2307.03941) | 本文探讨了在大型语言模型时代的被遗忘权（RTBF）面临的挑战，提供了实施技术解决方案的见解。 |
| [^51] | [$\alpha$-$\beta$-Factorization and the Binary Case of Simon's Congruence.](http://arxiv.org/abs/2306.14192) | 本研究通过介绍$\alpha$-$\beta$-分解的概念，将Simon同余特征化为$1$-普遍性单词，并应用于二元单词的完全刻画和同余指数计算。 |
| [^52] | [Towards Trustworthy Explanation: On Causal Rationalization.](http://arxiv.org/abs/2306.14115) | 该论文介绍了一种新的因果关系解释方法，通过在解释中引入非虚假性和效率，从因果推断的角度定义了因果概率，从而建立了必要和充分解释的主要组成部分，相比现有的基于关联的解释方法，这种方法有更加优越的性能表现。 |
| [^53] | [CamChoice: A Corpus of Multiple Choice Questions and Candidate Response Distributions.](http://arxiv.org/abs/2306.13047) | 本文介绍了CamChoice数据集，该数据集包含多项选择理解问题和真实候选答案选项分布，为候选人分布匹配任务提供了自动评估方式。 |
| [^54] | [LLMatic: Neural Architecture Search via Large Language Models and Quality-Diversity Optimization.](http://arxiv.org/abs/2306.01102) | 本文介绍了利用大语言模型和多样性优化算法相结合的 LLMatic 神经结构搜索算法。该算法在CIFAR-10数据集进行测试，仅进行2000次搜索即可产生高性能网络，即使没有该基准领域的先前知识或任何先前的最佳结果的曝光。 |
| [^55] | [What indeed can GPT models do in chemistry? A comprehensive benchmark on eight tasks.](http://arxiv.org/abs/2305.18365) | 本文建立了包括 8 个实际化学任务的综合基准测试，有力地证明了 LLM 在实际化学中的能力。 |
| [^56] | [Large Language Models Can be Lazy Learners: Analyze Shortcuts in In-Context Learning.](http://arxiv.org/abs/2305.17256) | 本文探讨了大型语言模型在上下文学习中利用提示中的捷径的依赖性，发现大型模型更有可能在推理过程中利用提示中的捷径，这为评估上下文学习的稳健性和检测和缓解提示中捷径的使用提供了新的视角和挑战。 |
| [^57] | [Annotation Imputation to Individualize Predictions: Initial Studies on Distribution Dynamics and Model Predictions.](http://arxiv.org/abs/2305.15070) | 本文提出使用填补方法为所有注释者生成所有示例的意见，从而创建一个不排斥任何注释者观点的数据集，并分析发现填补方法的选择对软标签变化和分布有显著影响。 |
| [^58] | [Document Understanding Dataset and Evaluation (DUDE).](http://arxiv.org/abs/2305.08455) | DUDE推出了一个新的数据集和评估方法，旨在创造一个更实际的基准测试并推动当前方法的边界，以更准确地模拟真实世界的情况 |
| [^59] | [The EarlyBIRD Catches the Bug: On Exploiting Early Layers of Encoder Models for More Efficient Code Classification.](http://arxiv.org/abs/2305.04940) | 本文介绍了一种早期层组合的方法EarlyBIRD，该方法可以有效利用深度自然语言处理模型的资源和可用信息，从而提高代码分类的性能，在缺陷检测方面平均可提高2个点。 |
| [^60] | [Self-Edit: Fault-Aware Code Editor for Code Generation.](http://arxiv.org/abs/2305.04087) | 本文提出了一种故障感知式代码编辑器，通过执行生成的代码并将执行结果包含在在注释中来优化竞技编程任务的代码质量，通过与九个不同的LLMs进行比较，本方法可以在两个竞技编程数据集上显著提高代码的准确性。 |
| [^61] | [Can ChatGPT Forecast Stock Price Movements? Return Predictability and Large Language Models.](http://arxiv.org/abs/2304.07619) | 本研究探究了使用ChatGPT及其他大型语言模型预测股市回报的潜力，发现ChatGPT的预测表现优于传统情感分析方法，而基础模型无法准确预测股票价格变化，表明复杂模型可预测能力的崛起。这表明在投资决策过程中引入先进的语言模型可以提高预测准确性并增强定量交易策略的表现。 |
| [^62] | [ARNOLD: A Benchmark for Language-Grounded Task Learning With Continuous States in Realistic 3D Scenes.](http://arxiv.org/abs/2304.04321) | ARNOLD是一个评估基于语言引导、具有连续状态的现实3D场景任务学习的基准测试，涉及8个语言条件任务，在语言引导下帮助机器人学习理解物体状态和学习连续目标的策略。 |
| [^63] | [A Survey of Large Language Models.](http://arxiv.org/abs/2303.18223) | 本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。 |
| [^64] | [Language as a Latent Sequence: deep latent variable models for semi-supervised paraphrase generation.](http://arxiv.org/abs/2301.02275) | 本文提出了用于半监督释义生成的深度潜变量模型，通过将未标记数据的缺失目标对建模为潜在释义序列，并结合双向学习和改进的权重初始化方案进行训练，实验结果表明这个模型在性能上与最先进的有监督基线模型有竞争力。 |
| [^65] | [Evaluating Human-Language Model Interaction.](http://arxiv.org/abs/2212.09746) | 为了评估人机交互，研究人员开发了一个框架HALIE，该框架捕捉了交互过程、主观体验和偏好概念，并设计了五个任务来涵盖不同形式的交互。 |
| [^66] | [Deep Emotion Recognition in Textual Conversations: A Survey.](http://arxiv.org/abs/2211.09172) | 本调研针对对话中的情感识别进行了探讨，介绍了涉及此任务的挑战和机遇，以及描述了情感分类法和使用该分类法的基准数据集。调研总结了最重要的作品和所使用的深度学习架构，并提供了建议性的情感识别实践，以实现更好的框架。 |
| [^67] | [Discover, Explanation, Improvement: An Automatic Slice Detection Framework for Natural Language Processing.](http://arxiv.org/abs/2211.04476) | 本研究提出了一个自动片段检测框架用于自然语言处理任务，通过发现、解释和改进模型的错误，提供了对模型行为的理解和未来模型设计的见解。 |
| [^68] | [Preventing Verbatim Memorization in Language Models Gives a False Sense of Privacy.](http://arxiv.org/abs/2210.17546) | 防止神经语言模型逐字记忆无法真正保护隐私，本文设计的布隆过滤器虽然防止了所有逐字记忆，但仍然无法防止训练数据泄露，容易被合理修改的“样式转换”提示绕过。 |
| [^69] | [What can we know about that which we cannot even imagine?.](http://arxiv.org/abs/2208.03886) | 这篇文章探讨了关于智能、人类语言和人类数学的问题，强调了人类语言的局限性，以及我们能否对我们无法想象的事物有任何了解。 |
| [^70] | [Predicting Word Learning in Children from the Performance of Computer Vision Systems.](http://arxiv.org/abs/2207.09847) | 通过使用计算机视觉系统的表现作为预测儿童词语学习的难度的代理，我们发现儿童获得不同类别的词语的年龄与视觉分类和字幕系统的表现有关。这些模型捕捉到了词语与视觉现象之间的关系。 |
| [^71] | [A Survey of Knowledge Enhanced Pre-trained Models.](http://arxiv.org/abs/2110.00269) | 本综述提供了关于NLP中知识增强预训练语言模型的综合概述，讨论了预训练语言模型和知识表示学习的进展，并从三个不同的角度对现有的KEPLMs进行了分类，最后概述了未来研究中KEPLMs的潜在方向。 |
| [^72] | [Can Deep Neural Networks Predict Data Correlations from Column Names?.](http://arxiv.org/abs/2107.04553) | 本研究提出在数据库中使用自然语言分析列名以辅助调优和分析工作。通过分析Kaggle数据集创建了一个新的数据相关性分析基准，并研究了语言模型在预测相关性方面的能力。 |
| [^73] | [NewB: 200,000+ Sentences for Political Bias Detection.](http://arxiv.org/abs/2006.03051) | NewB数据集是一个包含来自11个新闻来源对唐纳德·特朗普的200,000多个句子的文本语料库，通过训练深度学习模型预测句子的新闻来源，得到比传统分类系统更准确的结果，对媒体对特朗普的描绘进行了深入分析。 |
| [^74] | [What Are People Asking About COVID-19? A Question Classification Dataset.](http://arxiv.org/abs/2005.12522) | COVID-Q是一个包含1,690个关于COVID-19的问题的数据集，可以帮助我们对这些问题进行分类和聚类，并为开发应用系统或进行模型评估提供领域特定资源。 |
| [^75] | [A Unifying Framework of Bilinear LSTMs.](http://arxiv.org/abs/1910.10294) | 本文提出了一个统一的双线性LSTM框架，通过平衡线性和双线性项的表达能力，实现了对序列数据集中输入特征的非线性交互的利用，以实现更好的性能，同时不增加更多的学习参数。 |

# 详细

[^1]: Chat2Brain：一种将开放型语义查询映射到脑部激活图的方法

    Chat2Brain: A Method for Mapping Open-Ended Semantic Queries to Brain Activation Maps. (arXiv:2309.05021v1 [cs.CL])

    [http://arxiv.org/abs/2309.05021](http://arxiv.org/abs/2309.05021)

    Chat2Brain是一种结合了大型语言模型和基本的文本-图像模型的方法，用于将开放型语义查询映射到脑部激活图。它解决了元分析中存在的语义冗余和歧义导致映射不准确的问题。

    

    多年来，神经科学在文本模态下积累了大量的研究成果，可以用于探索认知过程。元分析是一种典型的方法，成功地利用这些研究结果从文本查询到脑部激活图之间建立联系，但它仍然依赖于理想的查询环境。在实际应用中，用于元分析的文本查询可能会遇到语义冗余和歧义等问题，导致对脑图的映射不准确。另一方面，像ChatGPT这样的大型语言模型(LLMs)在上下文理解和推理等任务中展现出巨大潜力，与人类自然语言具有高度一致性。因此，LLMs可以改进文本模态与神经科学之间的联系，解决元分析存在的挑战。在本研究中，我们提出了一种称为Chat2Brain的方法，将LLMs与基本的文本-图像模型Text2Brain相结合，以映射开放式语义查询到脑部激活图。

    Over decades, neuroscience has accumulated a wealth of research results in the text modality that can be used to explore cognitive processes. Meta-analysis is a typical method that successfully establishes a link from text queries to brain activation maps using these research results, but it still relies on an ideal query environment. In practical applications, text queries used for meta-analyses may encounter issues such as semantic redundancy and ambiguity, resulting in an inaccurate mapping to brain images. On the other hand, large language models (LLMs) like ChatGPT have shown great potential in tasks such as context understanding and reasoning, displaying a high degree of consistency with human natural language. Hence, LLMs could improve the connection between text modality and neuroscience, resolving existing challenges of meta-analyses. In this study, we propose a method called Chat2Brain that combines LLMs to basic text-2-image model, known as Text2Brain, to map open-ended sema
    
[^2]: FOLLOWUPQG:面向信息获取的跟进问题生成

    FOLLOWUPQG: Towards Information-Seeking Follow-up Question Generation. (arXiv:2309.05007v1 [cs.CL])

    [http://arxiv.org/abs/2309.05007](http://arxiv.org/abs/2309.05007)

    本文引入了一项真实世界的信息获取跟进问题生成任务，通过生成跟进问题来更深入地理解初始问题和答案。构建了数据集FOLLOWUPQG，评估了当前的问题生成模型在生成跟进问题方面的效果，并展示了其作为一个具有挑战性的基准任务的验证。

    

    人类出于好奇心而提出跟进问题，这反映了人类创造性的认知过程。我们引入了一个真实世界的信息获取跟进问题生成（FQG）任务，旨在生成能够更深入理解初始问题和答案的跟进问题。我们构建了FOLLOWUPQG数据集，包含了来自Reddit论坛的超过3K个真实世界的（初始问题，答案，跟进问题）元组，提供了对开放性问题的非专业人士友好的解释。与现有数据集相比，FOLLOWUPQG中的问题使用更多样化的实用策略来寻求信息，并展示了更高层次的认知技能（如应用和关联）。我们评估了当前的问题生成模型在生成跟进问题方面的效果，探索如何基于逐步演示生成特定类型的跟进问题。我们的结果验证了FOLLOWUPQG作为一个具有挑战性的基准任务。

    Humans ask follow-up questions driven by curiosity, which reflects a creative human cognitive process. We introduce the task of real-world information-seeking follow-up question generation (FQG), which aims to generate follow-up questions seeking a more in-depth understanding of an initial question and answer. We construct FOLLOWUPQG, a dataset of over 3K real-world (initial question, answer, follow-up question) tuples collected from a Reddit forum providing layman-friendly explanations for open-ended questions. In contrast to existing datasets, questions in FOLLOWUPQG use more diverse pragmatic strategies to seek information, and they also show higher-order cognitive skills (such as applying and relating). We evaluate current question generation models on their efficacy for generating follow-up questions, exploring how to generate specific types of follow-up questions based on step-by-step demonstrations. Our results validate FOLLOWUPQG as a challenging benchmark, as model-generated q
    
[^3]: 减轻零样本基于提示的分类器中的词偏差

    Mitigating Word Bias in Zero-shot Prompt-based Classifiers. (arXiv:2309.04992v1 [cs.CL])

    [http://arxiv.org/abs/2309.04992](http://arxiv.org/abs/2309.04992)

    这项研究关注减轻基于提示的分类器中的词偏差问题，并提出了一种无监督的方法来优化类别先验概率，从而提高分类性能。

    

    基于提示的分类器是一种吸引人的零样本分类方法。然而，提示模板和标签词的精确选择可以在很大程度上影响性能，即使在语义上等效的设置经常显示出显著的性能差异。这种差异部分可以归因于词偏差，其中分类器可能对某些类别有偏见。为了解决这个问题，可以在有标签数据集上优化分类阈值，但这也减弱了基于提示的分类器的某些优势。本文通过研究类别的期望边际概率来解决这个问题。在这里，概率被重新加权，以实现类别之间的统一先验，在无监督的方式下进行。此外，我们建立了类别先验和语言模型字先验之间的理论联系，并提供了以零资源方式设置阈值的能力。我们展示了匹配的类别先验与实际分类概率之间的强相关性。

    Prompt-based classifiers are an attractive approach for zero-shot classification. However, the precise choice of the prompt template and label words can largely influence performance, with semantically equivalent settings often showing notable performance difference. This discrepancy can be partly attributed to word biases, where the classifier may be biased towards classes. To address this problem, it is possible to optimise classification thresholds on a labelled data set, however, this mitigates some of the advantages of prompt-based classifiers. This paper instead approaches this problem by examining the expected marginal probabilities of the classes. Here, probabilities are reweighted to have a uniform prior over classes, in an unsupervised fashion. Further, we draw a theoretical connection between the class priors and the language models' word prior, and offer the ability to set a threshold in a zero-resource fashion. We show that matching class priors correlates strongly with th
    
[^4]: 用于低资源文本分类的检索增强元学习

    Retrieval-Augmented Meta Learning for Low-Resource Text Classification. (arXiv:2309.04979v1 [cs.CL])

    [http://arxiv.org/abs/2309.04979](http://arxiv.org/abs/2309.04979)

    本论文提出了一种基于元学习的方法，称为检索增强元学习（RAML），用于解决低资源文本分类中的泛化性能差问题。该方法不仅使用参数化进行推理，还从外部语料库中检索非参数化知识进行推理，以提高泛化能力和解决元学习中缺乏多样性训练数据的问题。

    

    元学习在低资源文本分类中取得了有希望的性能，这个任务旨在从源类别中的小任务集合（被称为episodes）中传递知识来识别目标类别。然而，由于元学习场景中的有限训练数据和参数化神经网络的固有属性，泛化性能差成为一个迫切需要解决的问题。为了应对这个问题，我们提出了一种基于元学习的方法，称为检索增强元学习（RAML）。它不仅使用参数化进行推理，还从外部语料库中检索非参数化知识进行推理，大大缓解了由于元学习中缺乏多样性训练数据而导致的泛化性能差的问题。这种方法不同于之前仅依赖于参数的模型，它明确强调了非参数化知识的重要性，旨在在参数化和非参数化知识之间取得平衡。

    Meta learning have achieved promising performance in low-resource text classification which aims to identify target classes with knowledge transferred from source classes with sets of small tasks named episodes. However, due to the limited training data in the meta-learning scenario and the inherent properties of parameterized neural networks, poor generalization performance has become a pressing problem that needs to be addressed. To deal with this issue, we propose a meta-learning based method called Retrieval-Augmented Meta Learning(RAML). It not only uses parameterization for inference but also retrieves non-parametric knowledge from an external corpus to make inferences, which greatly alleviates the problem of poor generalization performance caused by the lack of diverse training data in meta-learning. This method differs from previous models that solely rely on parameters, as it explicitly emphasizes the importance of non-parametric knowledge, aiming to strike a balance between p
    
[^5]: RGAT：更深入探索句法依赖信息在指代消解中的作用

    RGAT: A Deeper Look into Syntactic Dependency Information for Coreference Resolution. (arXiv:2309.04977v1 [cs.CL])

    [http://arxiv.org/abs/2309.04977](http://arxiv.org/abs/2309.04977)

    本文提出了一种综合预训练BERT和句法关系图注意网络（RGAT）的端到端解析器，以更深入地研究句法依赖信息在指代消解任务中的作用。通过对句法依赖图进行监督学习，并不需要对整个BERT进行微调，我们提高了先前最佳模型的F1分数。

    

    虽然句法信息对很多自然语言处理任务是有益的，但将其与词语之间的上下文信息相结合来解决指代消解问题仍需进一步探索。本文提出了一种综合预训练BERT和句法关系图注意网络（RGAT）的端到端解析器，以更深入地研究句法依赖信息在指代消解任务中的作用。具体而言，首先提出了RGAT模型，然后用于理解句法依赖图并学习更好的任务特定句法嵌入。构建了一个集成结构，将BERT嵌入和句法嵌入结合起来，为下游任务生成混合表示。我们在一个公共的Gendered Ambiguous Pronouns（GAP）数据集上进行的实验表明，在对句法依赖图进行监督学习的同时，不需要对整个BERT进行微调，我们提高了先前最佳模型（RGCN-wi）的F1分数

    Although syntactic information is beneficial for many NLP tasks, combining it with contextual information between words to solve the coreference resolution problem needs to be further explored. In this paper, we propose an end-to-end parser that combines pre-trained BERT with a Syntactic Relation Graph Attention Network (RGAT) to take a deeper look into the role of syntactic dependency information for the coreference resolution task. In particular, the RGAT model is first proposed, then used to understand the syntactic dependency graph and learn better task-specific syntactic embeddings. An integrated architecture incorporating BERT embeddings and syntactic embeddings is constructed to generate blending representations for the downstream task. Our experiments on a public Gendered Ambiguous Pronouns (GAP) dataset show that with the supervision learning of the syntactic dependency graph and without fine-tuning the entire BERT, we increased the F1-score of the previous best model (RGCN-wi
    
[^6]: 使用知识记忆原型进行广义少样本意图检测的提示学习

    Prompt Learning With Knowledge Memorizing Prototypes For Generalized Few-Shot Intent Detection. (arXiv:2309.04971v1 [cs.CL])

    [http://arxiv.org/abs/2309.04971](http://arxiv.org/abs/2309.04971)

    本研究提出了一种使用知识记忆原型进行广义少样本意图检测的提示学习方法，通过将任务转化为类增量学习范式来同时分类已知和新意图。进行了大量的实验和分析，结果表明这种方法在广义少样本意图检测中具有优秀的性能。

    

    广义少样本意图检测是具有挑战性和现实性的，因为它需要同时对已知和新意图进行分类。以往的广义少样本意图检测方法依赖于情节学习范式，难以扩展到广义设置，因为它们没有明确学习已知类别的分类和已知意图的知识。为了解决这个困境，我们提出将广义少样本意图检测任务转化为类增量学习范式。具体而言，我们提出了一个两阶段的学习框架，通过提示学习在不同阶段顺序学习不同意图的知识。然后，我们利用原型对已知和新意图进行分类。此外，为了在不同阶段实现意图的转移知识，在不同场景下我们设计了两种接近实际应用的知识保留方法。在两个广泛使用的数据集上的大量实验和详细分析表明我们的框架基于提示学习和知识记忆原型可以在广义少样本意图检测中取得优秀的性能。

    Generalized Few-Shot Intent Detection (GFSID) is challenging and realistic because it needs to categorize both seen and novel intents simultaneously. Previous GFSID methods rely on the episodic learning paradigm, which makes it hard to extend to a generalized setup as they do not explicitly learn the classification of seen categories and the knowledge of seen intents. To address the dilemma, we propose to convert the GFSID task into the class incremental learning paradigm. Specifically, we propose a two-stage learning framework, which sequentially learns the knowledge of different intents in various periods via prompt learning. And then we exploit prototypes for categorizing both seen and novel intents. Furthermore, to achieve the transfer knowledge of intents in different stages, for different scenarios we design two knowledge preservation methods which close to realistic applications. Extensive experiments and detailed analyses on two widely used datasets show that our framework base
    
[^7]: 前缀扩散：一种用于多样化图像字幕的轻量级扩散模型

    Prefix-diffusion: A Lightweight Diffusion Model for Diverse Image Captioning. (arXiv:2309.04965v1 [cs.CV])

    [http://arxiv.org/abs/2309.04965](http://arxiv.org/abs/2309.04965)

    Prefix-diffusion是一种轻量级的图像字幕扩散模型，通过在扩散过程中注入前缀图像嵌入来实现多样性，并通过预训练模型和额外的映射网络来减少参数。该模型能够生成多样的字幕，同时保持流畅性和相关性，并取得了有希望的性能。

    

    尽管在图像字幕生成方面取得了很大的进展，但生成的字幕的多样性有限和参数规模较大仍然是这些系统在实际应用中的主要障碍。在这项工作中，我们提出了一种轻量级的图像字幕网络，结合了连续扩散，称为前缀扩散。为了实现多样性，我们设计了一种高效的方法，将前缀图像嵌入到扩散模型的去噪过程中。为了减少可训练的参数，我们使用预训练模型提取图像特征，并进一步设计了额外的映射网络。前缀扩散能够以相对较少的参数生成多样化的字幕，同时保持字幕的流畅性和相关性，从扩散模型的生成能力中受益。我们的工作为扩展图像字幕的扩散模型铺平了道路，并与最近的方法相比取得了有希望的性能。

    While impressive performance has been achieved in image captioning, the limited diversity of the generated captions and the large parameter scale remain major barriers to the real-word application of these systems. In this work, we propose a lightweight image captioning network in combination with continuous diffusion, called Prefix-diffusion. To achieve diversity, we design an efficient method that injects prefix image embeddings into the denoising process of the diffusion model. In order to reduce trainable parameters, we employ a pre-trained model to extract image features and further design an extra mapping network. Prefix-diffusion is able to generate diverse captions with relatively less parameters, while maintaining the fluency and relevance of the captions benefiting from the generative capabilities of the diffusion model. Our work paves the way for scaling up diffusion models for image captioning, and achieves promising performance compared with recent approaches.
    
[^8]: 多文档摘要：一项比较评估

    Multi-document Summarization: A Comparative Evaluation. (arXiv:2309.04951v1 [cs.CL])

    [http://arxiv.org/abs/2309.04951](http://arxiv.org/abs/2309.04951)

    本文评估了多文档摘要领域的最新模型在不同领域和数据集上的表现，发现通用预训练模型LED在MS$^2$数据集上的性能优于其他模型，为未来的MDS研究提供了宝贵的参考和发展方向。

    

    本文旨在评估多文档摘要(MDS)领域的最新模型在不同领域和不同类型数据集上的表现，并研究现有模型的局限性，以确定未来的研究方向。为了填补这个空白，我们进行了广泛的文献评估，以确定最新的模型和数据集。我们对BigSurvey-MDS和MS$^2$数据集上的PRIMERA和PEGASUS模型的性能进行了分析，这些数据集由于领域的不同而带来了独特的挑战。我们的研究结果表明，通用预训练模型LED在MS$^2$数据集上的性能优于PRIMERA和PEGASUS。我们使用ROUGE分数作为性能度量指标，评估了不同数据集上的模型。我们的研究为了解模型的优势和不足提供了宝贵的见解，并为不同领域中准确、鲁棒的模型的发展提供了参考。这项研究对未来的MDS研究具有重要价值。

    This paper is aimed at evaluating state-of-the-art models for Multi-document Summarization (MDS) on different types of datasets in various domains and investigating the limitations of existing models to determine future research directions. To address this gap, we conducted an extensive literature review to identify state-of-the-art models and datasets. We analyzed the performance of PRIMERA and PEGASUS models on BigSurvey-MDS and MS$^2$ datasets, which posed unique challenges due to their varied domains. Our findings show that the General-Purpose Pre-trained Model LED outperforms PRIMERA and PEGASUS on the MS$^2$ dataset. We used the ROUGE score as a performance metric to evaluate the identified models on different datasets. Our study provides valuable insights into the models' strengths and weaknesses, as well as their applicability in different domains. This work serves as a reference for future MDS research and contributes to the development of accurate and robust models which can 
    
[^9]: 英文RST解析中的难点是什么？预测模型用于错误分析

    What's Hard in English RST Parsing? Predictive Models for Error Analysis. (arXiv:2309.04940v1 [cs.CL])

    [http://arxiv.org/abs/2309.04940](http://arxiv.org/abs/2309.04940)

    英文RST解析的难点主要是长距离依赖关系，并且最终模型能够预测错误发生的位置。

    

    尽管自然语言处理（NLP）取得了一些进展，但在修辞结构理论框架下的层级篇章解析仍然具有挑战性，对于这个原因的理解还很有限。在本文中，我们检查并建模了以前工作中与解析困难相关的一些因素：隐含的篇章关系的存在，识别长距离关系的挑战，词汇表外的项目等等。为了评估这些变量的相对重要性，我们还发布了两个带有显式正确和干扰性篇章标记的英文测试集，这些标记与黄金标准的RST关系相关。我们的结果表明，与浅层篇章解析一样，显式/隐式的区分起到了一定作用，但长距离依赖是主要挑战，而缺乏词汇重叠在至少针对特定领域的解析中不是一个大问题。我们的最终模型能够预测错误发生的位置，具有一个很高的准确率。

    Despite recent advances in Natural Language Processing (NLP), hierarchical discourse parsing in the framework of Rhetorical Structure Theory remains challenging, and our understanding of the reasons for this are as yet limited. In this paper, we examine and model some of the factors associated with parsing difficulties in previous work: the existence of implicit discourse relations, challenges in identifying long-distance relations, out-of-vocabulary items, and more. In order to assess the relative importance of these variables, we also release two annotated English test-sets with explicit correct and distracting discourse markers associated with gold standard RST relations. Our results show that as in shallow discourse parsing, the explicit/implicit distinction plays a role, but that long-distance dependencies are the main challenge, while lack of lexical overlap is less of a problem, at least for in-domain parsing. Our final model is able to predict where errors will occur with an ac
    
[^10]: 无监督句块化与分层循环神经网络

    Unsupervised Chunking with Hierarchical RNN. (arXiv:2309.04919v1 [cs.CL])

    [http://arxiv.org/abs/2309.04919](http://arxiv.org/abs/2309.04919)

    本论文提出了一种无监督的句块化方法，使用分层循环神经网络来建模单词到句块和句块到句子的组合。在实验中取得了显著的改进，将短语F1得分提高了6个百分点。

    

    在自然语言处理（NLP）中，预测语言结构，如解析和句块化，主要依赖于人工标注的句法结构。本文介绍了一种无监督的句块化方法，这是一种以非层次化方式对单词进行分组的句法任务。我们提出了一个两层分层循环神经网络（HRNN）来建模单词到句块和句块到句子的组合。我们的方法包括两个阶段的训练过程：使用无监督解析器进行预训练，然后在下游NLP任务上进行微调。在CoNLL-2000数据集上的实验显示，与现有的无监督方法相比，我们取得了显著的改进，将短语F1得分提高了6个百分点。此外，与下游任务的微调还带来了额外的性能提升。有趣的是，我们观察到句块结构在神经模型的下游任务训练过程中是短暂的。本研究对于推动无监督句块化的进展起到了重要作用。

    In Natural Language Processing (NLP), predicting linguistic structures, such as parsing and chunking, has mostly relied on manual annotations of syntactic structures. This paper introduces an unsupervised approach to chunking, a syntactic task that involves grouping words in a non-hierarchical manner. We present a two-layer Hierarchical Recurrent Neural Network (HRNN) designed to model word-to-chunk and chunk-to-sentence compositions. Our approach involves a two-stage training process: pretraining with an unsupervised parser and finetuning on downstream NLP tasks. Experiments on the CoNLL-2000 dataset reveal a notable improvement over existing unsupervised methods, enhancing phrase F1 score by up to 6 percentage points. Further, finetuning with downstream tasks results in an additional performance improvement. Interestingly, we observe that the emergence of the chunking structure is transient during the neural model's downstream-task training. This study contributes to the advancement 
    
[^11]: 低资源语言的分布式数据增强方法

    Distributional Data Augmentation Methods for Low Resource Language. (arXiv:2309.04862v1 [cs.CL])

    [http://arxiv.org/abs/2309.04862](http://arxiv.org/abs/2309.04862)

    本文提出了两种用于低资源语言的文本增强方法：易于分布式数据增强（EDDA）和类型特定的相似词替换（TSSR）。它们通过使用语义上下文信息和词性标记来改进易于数据增强方法（EDA），从而提高了低资源语言下的预测性能。

    

    文本增强是一种从不足资源的语料库中构造合成数据以提高预测性能的技术。合成数据生成在许多领域中很常见。然而，最近，文本增强已经在自然语言处理（NLP）中出现，以提升下游任务的效果。目前最先进的文本增强技术之一是易于数据增强（EDA），它通过注入和替换同义词以及随机排列句子来增加训练数据。EDA的一个主要障碍是需要多功能和完整的同义词词典，在低资源语言中很难找到。为了提高EDA的实用性，我们提出了两种扩展方法：易于分布式数据增强（EDDA）和类型特定的相似词替换（TSSR），它使用语义词上下文信息和词性标记来进行词替换和增强。在广泛的实证评估中，我们展示了所提出方法的实用性

    Text augmentation is a technique for constructing synthetic data from an under-resourced corpus to improve predictive performance. Synthetic data generation is common in numerous domains. However, recently text augmentation has emerged in natural language processing (NLP) to improve downstream tasks. One of the current state-of-the-art text augmentation techniques is easy data augmentation (EDA), which augments the training data by injecting and replacing synonyms and randomly permuting sentences. One major obstacle with EDA is the need for versatile and complete synonym dictionaries, which cannot be easily found in low-resource languages. To improve the utility of EDA, we propose two extensions, easy distributional data augmentation (EDDA) and type specific similar word replacement (TSSR), which uses semantic word context information and part-of-speech tags for word replacement and augmentation. In an extensive empirical evaluation, we show the utility of the proposed methods, measure
    
[^12]: 逆向工程解码策略：在对语言生成系统进行黑盒访问的情况下

    Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System. (arXiv:2309.04858v1 [cs.LG])

    [http://arxiv.org/abs/2309.04858](http://arxiv.org/abs/2309.04858)

    本文介绍了一种方法，可以逆向工程用于生成文本的解码方法，并发现了这些方法对于检测生成文本以及揭示由于解码设置导致的偏见的重要意义。

    

    神经语言模型越来越多地被部署在允许用户输入提示并接收生成文本的API和网站上。许多系统不会透露生成参数。在本文中，我们介绍了一种方法，可以逆向工程用于生成文本的解码方法（即，top-k或nucleus采样）。我们发现所使用的解码策略对于检测生成文本具有重要意义。此外，发现解码策略的过程可以揭示由于选择解码设置而导致的偏见，这严重截断了模型的预测分布。我们在几个开源语言模型家族以及生产系统上（例如，ChatGPT）上执行攻击。

    Neural language models are increasingly deployed into APIs and websites that allow a user to pass in a prompt and receive generated text. Many of these systems do not reveal generation parameters. In this paper, we present methods to reverse-engineer the decoding method used to generate text (i.e., top-$k$ or nucleus sampling). Our ability to discover which decoding strategy was used has implications for detecting generated text. Additionally, the process of discovering the decoding strategy can reveal biases caused by selecting decoding settings which severely truncate a model's predicted distributions. We perform our attack on several families of open-source language models, as well as on production systems (e.g., ChatGPT).
    
[^13]: 通过提取精炼的语音和语言情感表示进行语音情感识别

    Speech Emotion Recognition with Distilled Prosodic and Linguistic Affect Representations. (arXiv:2309.04849v1 [cs.CL])

    [http://arxiv.org/abs/2309.04849](http://arxiv.org/abs/2309.04849)

    该论文提出了EmoDistill，这是一个利用知识蒸馏来学习从语音中获取情感的强大的语言和语音表示的语音情感识别框架。通过在训练过程中利用经过SER微调的预训练语音和语言教师进行信息蒸馏，该方法在IEMOCAP基准测试中实现了最新的最高准确率，表明其在单模态和多模态技术中的优越性能。

    

    我们提出了EmoDistill，这是一个新颖的语音情感识别（SER）框架，利用跨模态知识蒸馏来学习从语音中获取情感的强大的语言和语音表示。在推理过程中，我们的方法仅使用一串语音信号来进行单模态SER，从而减少计算开销并避免运行时的转录和语音特征提取错误。在训练过程中，我们的方法从一对经过SER微调的预训练的语音和语言教师中的嵌入和逻辑层面蒸馏信息。在IEMOCAP基准测试中的实验表明，我们的方法在准确率上优于其他单模态和多模态技术，并达到了77.49％的无权重准确率和78.91％的加权准确率的最新成绩。详细的消融研究还展示了我们方法的每个组件的影响。

    We propose EmoDistill, a novel speech emotion recognition (SER) framework that leverages cross-modal knowledge distillation during training to learn strong linguistic and prosodic representations of emotion from speech. During inference, our method only uses a stream of speech signals to perform unimodal SER thus reducing computation overhead and avoiding run-time transcription and prosodic feature extraction errors. During training, our method distills information at both embedding and logit levels from a pair of pre-trained Prosodic and Linguistic teachers that are fine-tuned for SER. Experiments on the IEMOCAP benchmark demonstrate that our method outperforms other unimodal and multimodal techniques by a considerable margin, and achieves state-of-the-art performance of 77.49% unweighted accuracy and 78.91% weighted accuracy. Detailed ablation studies demonstrate the impact of each component of our method.
    
[^14]: 利用大型语言模型来利用ASR不确定性

    Leveraging Large Language Models for Exploiting ASR Uncertainty. (arXiv:2309.04842v1 [cs.CL])

    [http://arxiv.org/abs/2309.04842](http://arxiv.org/abs/2309.04842)

    这项工作旨在通过利用ASR的n-best列表来解决大型语言模型在口语理解任务上的潜在限制，而无需实质改变ASR和LLM的结构。

    

    尽管大型语言模型在各种自然语言处理（NLP）任务中表现出色，但要在口语理解（SLU）任务上表现出色，它们必须依靠现成的自动语音识别（ASR）系统进行转录，或者配备内置的语音模态。本文关注的是前一种情况，即LLM在SLU任务上的准确性受限于固定ASR系统在口语输入上的准确性。具体而言，我们解决了语音意图分类任务，其中高字词错误率可能限制LLM理解口头意图的能力。我们的目标不是通过设计复杂或专门的架构追求高准确性，而是在不实质改变底层ASR和LLM的情况下，看看我们能走多远，这些模型可以潜在地被多个不相关的任务共享。为此，我们提出使用ASR假设的n-best列表来提示LLM，而不仅仅是容易出错的1-best假设。

    While large language models excel in a variety of natural language processing (NLP) tasks, to perform well on spoken language understanding (SLU) tasks, they must either rely on off-the-shelf automatic speech recognition (ASR) systems for transcription, or be equipped with an in-built speech modality. This work focuses on the former scenario, where LLM's accuracy on SLU tasks is constrained by the accuracy of a fixed ASR system on the spoken input. Specifically, we tackle speech-intent classification task, where a high word-error-rate can limit the LLM's ability to understand the spoken intent. Instead of chasing a high accuracy by designing complex or specialized architectures regardless of deployment costs, we seek to answer how far we can go without substantially changing the underlying ASR and LLM, which can potentially be shared by multiple unrelated tasks. To this end, we propose prompting the LLM with an n-best list of ASR hypotheses instead of only the error-prone 1-best hypoth
    
[^15]: 大型语言模型中的神经元：不活跃，N-gram，位置

    Neurons in Large Language Models: Dead, N-gram, Positional. (arXiv:2309.04827v1 [cs.CL])

    [http://arxiv.org/abs/2309.04827](http://arxiv.org/abs/2309.04827)

    该论文分析了大型语言模型中的神经元行为，发现网络的早期部分是稀疏的，包含许多死亡神经元和专门用于离散特征的活跃神经元。这些活跃神经元的更新不仅推动下一个标记的生成，还专注于移除与触发它们的标记相关的信息。

    

    我们以一种轻量级的方式分析了一类大型语言模型，这可以在单个GPU上进行。具体而言，我们关注的是OPT系列模型，参数范围从125m到66b，并且仅依赖于FFN神经元是否被激活。首先，我们发现网络的早期部分是稀疏的，表示许多离散特征。在这里，许多神经元（在66b模型的某些层中超过70%）是“不活跃的”，即它们在大量多样化的数据上从不激活。同时，许多活跃的神经元专用于离散特征，并且充当标记和n-gram检测器。有趣的是，它们对应的FFN更新不仅促进了下一个标记的候选，这是可以预期的，而且还明确地专注于移除与触发它们的标记（即当前输入）相关的信息。据我们所知，这是第一个在残差流中专门用于移除（而不是添加）信息的机制的例子。

    We analyze a family of large language models in such a lightweight manner that can be done on a single GPU. Specifically, we focus on the OPT family of models ranging from 125m to 66b parameters and rely only on whether an FFN neuron is activated or not. First, we find that the early part of the network is sparse and represents many discrete features. Here, many neurons (more than 70% in some layers of the 66b model) are "dead", i.e. they never activate on a large collection of diverse data. At the same time, many of the alive neurons are reserved for discrete features and act as token and n-gram detectors. Interestingly, their corresponding FFN updates not only promote next token candidates as could be expected, but also explicitly focus on removing the information about triggering them tokens, i.e., current input. To the best of our knowledge, this is the first example of mechanisms specialized at removing (rather than adding) information from the residual stream. With scale, models 
    
[^16]: FaNS：基于要素的叙事相似度度量

    FaNS: a Facet-based Narrative Similarity Metric. (arXiv:2309.04823v1 [cs.CL])

    [http://arxiv.org/abs/2309.04823](http://arxiv.org/abs/2309.04823)

    本研究提出了一种基于要素的叙事相似度度量方法FaNS，通过提取经典的五W一H要素并借助大型语言模型，可以更准确地识别出语义上相似的叙事。实验证明，FaNS与传统文本相似度度量方法相比具有更高的相关性（高37%）。

    

    相似的叙事检索是一项至关重要的任务，因为叙事对于解释和理解事件至关重要，而多个相关的叙事通常有助于创建对所关注事件的整体视图。为了准确识别语义上相似的叙事，本文提出了一种新颖的叙事相似度度量方法，称为基于要素的叙事相似度（FaNS），该方法基于经典的五W一H要素（Who，What，When，Where，Why和How），通过利用最先进的大型语言模型（LLMs）进行提取。与现有的仅关注整体词汇/语义匹配的相似度度量方法不同，FaNS提供了更为细致的匹配，包括六个不同的要素的独立匹配，并将它们组合。为了评估FaNS，我们从第三方新闻门户AllSides收集了一份全面的叙事数据集。实验结果表明，FaNS度量方法与直接度量的传统文本相似度度量方法相比，具有更高的相关性（高37%）。

    Similar Narrative Retrieval is a crucial task since narratives are essential for explaining and understanding events, and multiple related narratives often help to create a holistic view of the event of interest. To accurately identify semantically similar narratives, this paper proposes a novel narrative similarity metric called Facet-based Narrative Similarity (FaNS), based on the classic 5W1H facets (Who, What, When, Where, Why, and How), which are extracted by leveraging the state-of-the-art Large Language Models (LLMs). Unlike existing similarity metrics that only focus on overall lexical/semantic match, FaNS provides a more granular matching along six different facets independently and then combines them. To evaluate FaNS, we created a comprehensive dataset by collecting narratives from AllSides, a third-party news portal. Experimental results demonstrate that the FaNS metric exhibits a higher correlation (37\% higher) than traditional text similarity metrics that directly measur
    
[^17]: MMHQA-ICL: 文本、表格和图像多模态背景下的混合问答的多模若干学习

    MMHQA-ICL: Multimodal In-context Learning for Hybrid Question Answering over Text, Tables and Images. (arXiv:2309.04790v1 [cs.CL])

    [http://arxiv.org/abs/2309.04790](http://arxiv.org/abs/2309.04790)

    MMHQA-ICL框架结合了强大的异构数据检索器和图像标题模块，提出了一种特定类型的背景下学习策略，使得大型语言模型能够在多模态混合问答任务中取得最先进的结果。

    

    在现实世界中，知识常常以多模态和异构的形式存在。解决包括文本、表格和图像在内的混合数据类型的问答任务是一项具有挑战性的任务（MMHQA）。最近，随着大型语言模型（LLM）的崛起，背景下学习（ICL）已成为解决QA问题的最流行的方法。我们提出了用于解决此问题的MMHQA-ICL框架，其中包括更强大的异构数据检索器和图像标题模块。最重要的是，我们提出了一种针对MMHQA的特定类型的背景下学习策略，使LLM能够在这个任务中发挥其强大的性能。我们是第一个在这个任务中使用端到端LLM提示方法的人。实验结果表明，我们的框架在MultimodalQA数据集的少样本设置下优于所有基准线和训练在完整数据集上的方法，达到了最先进的结果。

    In the real world, knowledge often exists in a multimodal and heterogeneous form. Addressing the task of question answering with hybrid data types, including text, tables, and images, is a challenging task (MMHQA). Recently, with the rise of large language models (LLM), in-context learning (ICL) has become the most popular way to solve QA problems. We propose MMHQA-ICL framework for addressing this problems, which includes stronger heterogeneous data retriever and an image caption module. Most importantly, we propose a Type-specific In-context Learning Strategy for MMHQA, enabling LLMs to leverage their powerful performance in this task. We are the first to use end-to-end LLM prompting method for this task. Experimental results demonstrate that our framework outperforms all baselines and methods trained on the full dataset, achieving state-of-the-art results under the few-shot setting on the MultimodalQA dataset.
    
[^18]: SeaEval多语言基础模型：从跨语言对齐到文化推理

    SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment to Cultural Reasoning. (arXiv:2309.04766v1 [cs.CL])

    [http://arxiv.org/abs/2309.04766](http://arxiv.org/abs/2309.04766)

    SeaEval是一个评估多语言基础模型的基准测试，研究了模型在自然语言理解、推理以及对文化实践、细微差别和价值观的理解能力上的表现。重要发现包括模型在给出改写指令时行为各异，受到暴露偏差的影响，对于语义等价的多语言查询的回答不一致，以及模型在情感相关问题上的一致性不同。

    

    我们提出了一种用于多语言基础模型的SeaEval基准测试。除了表征这些模型如何理解和推理自然语言外，我们还研究了它们对文化实践、细微差别和价值观的理解能力。除了标准的准确度指标，我们还调查了基础模型在语义和多语言性维度上的脆弱性。我们的分析涵盖了开源和闭源模型，从而得到了在经典的自然语言处理任务、推理和文化理解方面的实证结果。重要发现包括：（1）大多数模型在给出改写指令时的行为各异；（2）许多模型仍然受到暴露偏差的影响（如位置偏差、大多数标签偏差）；（3）对于根源于事实、科学和常识知识的问题，预期在语义上等价的多语言查询应该得到一致的回答。然而，大多数模型在这些查询上表现出令人意外的不一致性；（4）多语言情况下，模型对于情感相关的问题表现出不同程度的一致性。

    We present SeaEval, a benchmark for multilingual foundation models. In addition to characterizing how these models understand and reason with natural language, we also investigate how well they comprehend cultural practices, nuances, and values. Alongside standard accuracy metrics, we investigate the brittleness of foundation models in the dimensions of semantics and multilinguality. Our analyses span both open-sourced and closed models, leading to empirical results across classic NLP tasks, reasoning, and cultural comprehension. Key findings indicate (1) Most models exhibit varied behavior when given paraphrased instructions. (2) Many models still suffer from exposure bias (e.g., positional bias, majority label bias). (3) For questions rooted in factual, scientific, and commonsense knowledge, consistent responses are expected across multilingual queries that are semantically equivalent. Yet, most models surprisingly demonstrate inconsistent performance on these queries. (4) Multilingu
    
[^19]: 对话式人工智能的数据增强

    Data Augmentation for Conversational AI. (arXiv:2309.04739v1 [cs.CL])

    [http://arxiv.org/abs/2309.04739](http://arxiv.org/abs/2309.04739)

    本教程提供了对话式人工智能中数据增强的综述，包括对话增强、开放域和任务导向的对话生成以及评估模型。此外，还讨论了当前的挑战和未来的发展方向，以帮助推动该领域的发展。

    

    对话系统的发展已经彻底改变了信息获取方式，超越了单一查询的限制。然而，开发对话系统需要大量的训练数据，在资源有限的领域和语言中具有挑战性。传统的数据收集方法，如众包，需要大量的人力和时间，因此在此情景下效率低下。数据增强（DA）是一种缓解对话系统中数据稀缺问题的有效方法。本教程全面且最新地概述了在对话系统中使用的DA方法，包括对话增强、开放域和任务导向的对话生成以及不同的评估模型的范式。我们还讨论了当前的挑战和未来的发展方向，以帮助研究人员和从业者进一步推动这一领域的发展。

    Advancements in conversational systems have revolutionized information access, surpassing the limitations of single queries. However, developing dialogue systems requires a large amount of training data, which is a challenge in low-resource domains and languages. Traditional data collection methods like crowd-sourcing are labor-intensive and time-consuming, making them ineffective in this context. Data augmentation (DA) is an affective approach to alleviate the data scarcity problem in conversational systems. This tutorial provides a comprehensive and up-to-date overview of DA approaches in the context of conversational systems. It highlights recent advances in conversation augmentation, open domain and task-oriented conversation generation, and different paradigms of evaluating these models. We also discuss current challenges and future directions in order to help researchers and practitioners to further advance the field in this area.
    
[^20]: 通过增强视觉实体和多尺度图像噪声滤波，实现更好的多模态关键词生成

    Towards Better Multi-modal Keyphrase Generation via Visual Entity Enhancement and Multi-granularity Image Noise Filtering. (arXiv:2309.04734v1 [cs.CV])

    [http://arxiv.org/abs/2309.04734](http://arxiv.org/abs/2309.04734)

    本文提出了一种新的多模态关键词生成模型，通过引入外部视觉实体作为模型输入并使用图像噪声滤波技术，实现了更好的关键词生成效果。

    

    多模态关键词生成旨在生成一组能够代表输入文本-图像对核心要点的关键词。然而，目前的方法存在两个主要缺点：1）只能使用有限的信息源（如图像标题）提供辅助信息，但这些信息可能无法满足后续关键词生成的需要。2）输入的文本和图像通常不能完全匹配，图像可能会引入噪声。为解决这些问题，本文提出了一种新型的多模态关键词生成模型，它不仅通过外部知识丰富了模型输入，还能有效过滤图像噪声。首先，我们将图像的外部视觉实体作为模型的补充输入，有助于跨模态语义对齐进行关键词生成。其次，我们同时计算...

    Multi-modal keyphrase generation aims to produce a set of keyphrases that represent the core points of the input text-image pair. In this regard, dominant methods mainly focus on multi-modal fusion for keyphrase generation. Nevertheless, there are still two main drawbacks: 1) only a limited number of sources, such as image captions, can be utilized to provide auxiliary information. However, they may not be sufficient for the subsequent keyphrase generation. 2) the input text and image are often not perfectly matched, and thus the image may introduce noise into the model. To address these limitations, in this paper, we propose a novel multi-modal keyphrase generation model, which not only enriches the model input with external knowledge, but also effectively filters image noise. First, we introduce external visual entities of the image as the supplementary input to the model, which benefits the cross-modal semantic alignment for keyphrase generation. Second, we simultaneously calculate 
    
[^21]: EPA: 通过多个来源和多个目标实现大型语言模型上的简易提示增强

    EPA: Easy Prompt Augmentation on Large Language Models via Multiple Sources and Multiple Targets. (arXiv:2309.04725v1 [cs.CL])

    [http://arxiv.org/abs/2309.04725](http://arxiv.org/abs/2309.04725)

    本论文提出了一种名为EPA的简易提示增强方法，通过自动使用多个来源/目标来扩充演示，从而提高了大型语言模型的性能，减少了用户编写演示的工作量。

    

    大型语言模型（LLM）通过任务提示已经在各种自然语言处理任务上展现出了有希望的性能。通过在提示头部添加任务演示可以进一步提高性能，并且通常情况下，使用更多的演示可以达到更好的性能。然而，要求用户编写演示可能会很麻烦。作为一种简单而具有成本效益的解决方法，本文提出了一种名为EPA (Easy Prompt Augmentation)的新方法，旨在在提高模型性能的同时，有效减少用户编写演示的工作量。EPA通过自动使用多个来源/目标来扩充演示，其中每个来源/目标互为释义，从而实现这些目标。

    Large language models (LLMs) have shown promising performance on various NLP tasks via task prompting. And their performance can be further improved by appending task demonstrations to the head of the prompt. And usually, a better performance can be achieved with more demonstrations. However, asking the users to write the demonstrations can be cumbersome. As a simple yet cost-effective workaround, this paper proposes a novel method called EPA (\textbf{E}asy \textbf{P}rompt \textbf{A}ugmentation)\footnote{While this paper considers augmenting prompts via demonstrations, we name it EPA as the name EDA is already taken by a well-known NLP method \citep{wei-zou-2019-eda}.} that effectively minimizes user efforts in writing demonstrations while improving the model performance at the same time. EPA achieves these goals by automatically augmenting the demonstrations with multiple sources/targets, where each of them paraphrases each other. This is well motivated as augmenting data via paraphra
    
[^22]: 利用大型语言模型重现网络研究结果

    Toward Reproducing Network Research Results Using Large Language Models. (arXiv:2309.04716v1 [cs.LG])

    [http://arxiv.org/abs/2309.04716](http://arxiv.org/abs/2309.04716)

    本文提出使用大型语言模型（LLMs）来重现网络研究结果，通过一个小规模实验证明了其可行性，并以ChatGPT为工具重现了不同发表于著名会议和期刊的网络系统。

    

    在网络学术界和工业界中，重现研究结果非常重要。当前的最佳实践通常有三种方法：（1）寻找公开可用的原型；（2）联系作者获取私有原型；以及（3）根据论文描述手动实现原型。然而，大多数已发表的网络研究没有公开原型，而获取私有原型也很困难。因此，大部分重现工作都花费在根据论文描述进行手动实现上，这既耗时又费力，容易出错。本文大胆地提出使用新兴的大型语言模型（LLMs）来重现网络研究结果。特别地，我们首先通过小规模实验证明了其可行性，其中四名具备必要网络知识的学生使用ChatGPT进行了不同发表于著名会议和期刊的网络系统的重现工作。

    Reproducing research results in the networking community is important for both academia and industry. The current best practice typically resorts to three approaches: (1) looking for publicly available prototypes; (2) contacting the authors to get a private prototype; and (3) manually implementing a prototype following the description of the publication. However, most published network research does not have public prototypes and private prototypes are hard to get. As such, most reproducing efforts are spent on manual implementation based on the publications, which is both time and labor consuming and error-prone. In this paper, we boldly propose reproducing network research results using the emerging large language models (LLMs). In particular, we first prove its feasibility with a small-scale experiment, in which four students with essential networking knowledge each reproduces a different networking system published in prominent conferences and journals by prompt engineering ChatGPT
    
[^23]: 通过优化大型语言模型进行虚假信息和假新闻的检测分析

    Analysis of Disinformation and Fake News Detection Using Fine-Tuned Large Language Model. (arXiv:2309.04704v1 [cs.CL])

    [http://arxiv.org/abs/2309.04704](http://arxiv.org/abs/2309.04704)

    本研究考虑使用LLM模型通过细调实现虚假信息和假新闻的深入分析，揭示复杂的风格和叙事，并提取命名实体的情感，以此作为监督机器学习模型中的预测性特征。

    

    本文考虑使用LLM（Llama 2大型语言模型）通过细调进行虚假信息分析和假新闻的检测。采用了基于PEFT/LoRA的细调方法。研究中，该模型对以下任务进行了细调：揭示虚假信息和宣传叙事的文本分析，事实核查，假新闻检测，操纵分析以及提取带有情感的命名实体。所得结果表明，经过细调的Llama 2模型能够对文本进行深入分析，并揭示复杂的风格和叙事。带有情感的命名实体可以作为监督机器学习模型中的预测性特征。

    The paper considers the possibility of fine-tuning Llama 2 large language model (LLM) for the disinformation analysis and fake news detection. For fine-tuning, the PEFT/LoRA based approach was used. In the study, the model was fine-tuned for the following tasks: analysing a text on revealing disinformation and propaganda narratives, fact checking, fake news detection, manipulation analytics, extracting named entities with their sentiments. The obtained results show that the fine-tuned Llama 2 model can perform a deep analysis of texts and reveal complex styles and narratives. Extracted sentiments for named entities can be considered as predictive features in supervised machine learning models.
    
[^24]: 在上下文中学习编程风格以解决基于知识的问答中的问题

    Code-Style In-Context Learning for Knowledge-Based Question Answering. (arXiv:2309.04695v1 [cs.CL])

    [http://arxiv.org/abs/2309.04695](http://arxiv.org/abs/2309.04695)

    本论文提出了一种在上下文中学习编程风格的方法，用于解决基于知识的问答中生成逻辑表达式的格式错误问题。

    

    目前，针对基于知识的问答(KBQA)的方法通常依赖复杂的训练技术和模型框架，导致在实际应用中存在许多限制。最近，大型语言模型(LLMs)中的上下文学习(ICL)能力的出现为KBQA提供了一种简单且无需训练的语义解析范式：给定少量问题及其标记的逻辑表达式作为演示示例，LLMs能够理解任务意图并为新问题生成逻辑表达式。然而，当前强大的LLMs在预训练过程中对逻辑表达式的了解很少，导致格式错误率较高。为了解决这个问题，我们提出了一种针对KBQA的代码风格上下文学习方法，将陌生逻辑表达式的生成过程转换为更为熟悉的代码生成过程。对三个主流数据集的实验结果表明，我们的方法显著减轻了生成逻辑表达式中的格式错误问题。

    Current methods for Knowledge-Based Question Answering (KBQA) usually rely on complex training techniques and model frameworks, leading to many limitations in practical applications. Recently, the emergence of In-Context Learning (ICL) capabilities in Large Language Models (LLMs) provides a simple and training-free semantic parsing paradigm for KBQA: Given a small number of questions and their labeled logical forms as demo examples, LLMs can understand the task intent and generate the logic form for a new question. However, current powerful LLMs have little exposure to logic forms during pre-training, resulting in a high format error rate. To solve this problem, we propose a code-style in-context learning method for KBQA, which converts the generation process of unfamiliar logical form into the more familiar code generation process for LLMs. Experimental results on three mainstream datasets show that our method dramatically mitigated the formatting error problem in generating logic for
    
[^25]: 嵌入结构的重要性：比较适应新语言的多语言词汇方法

    Embedding structure matters: Comparing methods to adapt multilingual vocabularies to new languages. (arXiv:2309.04679v1 [cs.CL])

    [http://arxiv.org/abs/2309.04679](http://arxiv.org/abs/2309.04679)

    比较了替换跨语言词汇的几种技术，证明了单语转移文献中的方法不适用于多语言模型。专门化的较小词汇对于提高低资源情况下的性能是有效的。

    

    预训练的多语言语言模型支持英语以外的现代自然语言处理工具的大部分。用于特定语言化的强大基准是语言适应预训练（LAPT）。但是，在适应过程中保留大型跨语言词汇和嵌入矩阵会带来相当多的多余计算成本。在本研究中，我们提出了几种简单的技术来用紧凑的特定语言词汇替换跨语言词汇。具体而言，我们解决了在词汇专门化后如何重新初始化令牌嵌入矩阵的策略。我们对我们的技术进行了系统的实验比较，此外还加入了最近提出的焦点方法。我们证明了：1）在单语转移文献中的嵌入替换技术不适用于适应多语言模型。2）用较小的专门的词汇替换跨语言词汇提供了一种提高低资源情况下性能的有效方法。

    Pre-trained multilingual language models underpin a large portion of modern NLP tools outside of English. A strong baseline for specializing these models for specific languages is Language-Adaptive Pre-Training (LAPT). However, retaining a large cross-lingual vocabulary and embedding matrix comes at considerable excess computational cost during adaptation. In this study, we propose several simple techniques to replace a cross-lingual vocabulary with a compact, language-specific one. Namely, we address strategies for re-initializing the token embedding matrix after vocabulary specialization. We then provide a systematic experimental comparison of our techniques, in addition to the recently-proposed Focus method. We demonstrate that: 1) Embedding-replacement techniques in the monolingual transfer literature are inadequate for adapting multilingual models. 2) Replacing cross-lingual vocabularies with smaller specialized ones provides an efficient method to improve performance in low-resou
    
[^26]: FIAT: 将学习范式与指令加速调优相融合

    FIAT: Fusing learning paradigms with Instruction-Accelerated Tuning. (arXiv:2309.04663v1 [cs.CL])

    [http://arxiv.org/abs/2309.04663](http://arxiv.org/abs/2309.04663)

    FIAT是一种将上下文学习和完全微调范式融合的新的学习方式，可以在最大模型上进行指令和推理，并且在较小模型上进行参数更新，经过多语言任务测试，比之前的方法都表现更好。

    

    目前用于大型语言模型（LLMs）的学习范式通常分为上下文学习（ICL）和完全微调。每种范式都有其自身的取舍，这取决于可用数据、模型大小、计算成本、易用性和最终质量，但无法在所有情况下都表现良好。在本文中，我们首先以强调它们之间自然联系的方式描述了ICL和微调范式。基于这些联系，我们提出了一种名为FIAT的新学习范式，将这些范式的优点融合在一起，使得在最大模型上可以进行快速工程指令和链式思维推理，同时在参数效率调优的较小模型上使用类似的方法进行参数更新。我们在各种多语言任务上评估了FIAT的有效性，并观察到FIAT在100-10,000个训练样本规模下均比ICL和微调表现更好。我们希望FIAT能提供一种新的解决方案，使得在不同情况下都能取得更好的效果。

    Learning paradigms for large language models (LLMs) currently tend to fall within either in-context learning (ICL) or full fine-tuning. Each of these comes with their own trade-offs based on available data, model size, compute cost, ease-of-use, and final quality with neither solution performing well across-the-board. In this article, we first describe ICL and fine-tuning paradigms in a way that highlights their natural connections. Based on these connections, we propose a new learning paradigm called FIAT that fuses the best of these paradigms together, enabling prompt-engineered instructions and chain-of-thought reasoning with the very largest models while also using similar methods to perform parameter updates on a modestly-sized LLM with parameter-efficient tuning. We evaluate FIAT's effectiveness on a variety of multilingual tasks and observe that FIAT performs better than both ICL and fine-tuning at scales ranging from 100-10,000 training examples. We hope that FIAT provides a pr
    
[^27]: MADLAD-400: 一种多语言和文档级的大规模审核数据集

    MADLAD-400: A Multilingual And Document-Level Large Audited Dataset. (arXiv:2309.04662v1 [cs.CL])

    [http://arxiv.org/abs/2309.04662](http://arxiv.org/abs/2309.04662)

    MADLAD-400是一种覆盖419种语言的多语言文档级数据集，通过自我审核揭示了局限性，通过训练众多参数的机器翻译模型取得了竞争力，并提供了基准模型给研究界使用。

    

    我们介绍了MADLAD-400，这是一个基于CommonCrawl的手动审核的通用领域3T token单语数据集，涵盖了419种语言。我们讨论了通过自我审核MADLAD-400揭示出的局限性，以及数据审核在数据集创建过程中的作用。然后，我们使用公开可用的数据训练并发布了一个涵盖450多种语言、2500亿个标记的10.7B参数的多语言机器翻译模型，并发现它在不同领域上与规模更大的模型相比具有竞争力，并报告了结果。此外，我们还训练了一个8B参数的语言模型，并评估了少样本翻译的结果。我们将基准模型提供给研究界使用。

    We introduce MADLAD-400, a manually audited, general domain 3T token monolingual dataset based on CommonCrawl, spanning 419 languages. We discuss the limitations revealed by self-auditing MADLAD-400, and the role data auditing had in the dataset creation process. We then train and release a 10.7B-parameter multilingual machine translation model on 250 billion tokens covering over 450 languages using publicly available data, and find that it is competitive with models that are significantly larger, and report the results on different domains. In addition, we train a 8B-parameter language model, and assess the results on few-shot translation. We make the baseline models available to the research community.
    
[^28]: 探索大型语言模型在沟通游戏中的应用：对狼人杀的实证研究

    Exploring Large Language Models for Communication Games: An Empirical Study on Werewolf. (arXiv:2309.04658v1 [cs.CL])

    [http://arxiv.org/abs/2309.04658](http://arxiv.org/abs/2309.04658)

    本研究探索了大型语言模型在沟通游戏中的应用，提出了一个无需调参的框架，并通过对狼人杀游戏的实证研究展示了其有效性和出现的战略行为。这表明在沟通游戏和相关领域中使用大型语言模型将具备潜在价值。

    

    沟通游戏，我们把指依赖于自然语言交流的不完全信息游戏称为沟通游戏，在经济学、社会科学和人工智能等领域具有重要的研究价值。本文主要探讨如何在沟通游戏中应用大型语言模型（LLMs），并提出了一个无需调参的框架。我们的方法保持LLMs冻结状态，并利用过去的沟通和经验进行改进。对代表性且被广泛研究的沟通游戏“狼人杀”的实证研究表明，我们的框架可以在不调整LLMs参数的情况下有效地进行狼人杀游戏。更重要的是，我们的实验中出现了战略行为的迹象，这表明在沟通游戏和相关领域中使用LLMs将会是一次富有成果的旅程。

    Communication games, which we refer to as incomplete information games that heavily depend on natural language communication, hold significant research value in fields such as economics, social science, and artificial intelligence. In this work, we explore the problem of how to engage large language models (LLMs) in communication games, and in response, propose a tuning-free framework. Our approach keeps LLMs frozen, and relies on the retrieval and reflection on past communications and experiences for improvement. An empirical study on the representative and widely-studied communication game, ``Werewolf'', demonstrates that our framework can effectively play Werewolf game without tuning the parameters of the LLMs. More importantly, strategic behaviors begin to emerge in our experiments, suggesting that it will be a fruitful journey to engage LLMs in communication games and associated domains.
    
[^29]: 高效调优用于越南聊天机器人的大型语言模型

    Efficient Finetuning Large Language Models For Vietnamese Chatbot. (arXiv:2309.04646v1 [cs.CL])

    [http://arxiv.org/abs/2309.04646](http://arxiv.org/abs/2309.04646)

    本研究针对越南语聊天机器人的开发，通过利用来自Alpaca、GPT4All和Chat-Doctor等开源项目的大规模指令跟随数据集，成功训练了四个模型，此为越南语的首个指令数据集。

    

    大型语言模型（LLMs），如GPT-4、PaLM和LLaMa，在各种自然语言任务中表现出色。最近的指令调优进展使得LLMs能够按照用户指令并产生类似人类回复的能力。然而，训练和实现LLMs所需的高成本对学术研究提出了挑战。此外，越南语言的预训练LLMs和指令调谐数据集的可用性有限。为了解决这些问题，我们利用来自开源项目（Alpaca、GPT4All和Chat-Doctor）的大规模指令跟随数据集，涵盖了通用和特定的医学领域。据我们所知，这是第一个用于越南语的指令数据集。随后，我们利用参数高效调优，通过低秩适应（LoRA）在两个开放的LLMs上：Bloomz（多语言）和GPTJ-6B（越南语），得到四个模型：Bloomz-Chat，Blo

    Large language models (LLMs), such as GPT-4, PaLM, and LLaMa, have been shown to achieve remarkable performance across a variety of natural language tasks. Recent advancements in instruction tuning bring LLMs with ability in following user's instructions and producing human-like responses. However, the high costs associated with training and implementing LLMs pose challenges to academic research. Furthermore, the availability of pretrained LLMs and instruction-tune datasets for Vietnamese language is limited. To tackle these concerns, we leverage large-scale instruction-following datasets from open-source projects, namely Alpaca, GPT4All, and Chat-Doctor, which cover general domain and specific medical domain. To the best of our knowledge, these are the first instructional dataset for Vietnamese. Subsequently, we utilize parameter-efficient tuning through Low-Rank Adaptation (LoRA) on two open LLMs: Bloomz (Multilingual) and GPTJ-6B (Vietnamese), resulting four models: Bloomz-Chat, Blo
    
[^30]: NLP模型能否“识别”，“区分”和“证明”没有确定答案的问题？

    Can NLP Models 'Identify', 'Distinguish', and 'Justify' Questions that Don't have a Definitive Answer?. (arXiv:2309.04635v1 [cs.CL])

    [http://arxiv.org/abs/2309.04635](http://arxiv.org/abs/2309.04635)

    这项研究提出了QnotA数据集，用于研究NLP模型在没有确定答案的问题上的表现。通过全面的实验，证明最先进的模型能够准确识别和提供合理的回答。

    

    尽管最新的自然语言处理（NLP）系统在各种语言理解任务上取得了显著的性能，但它们主要关注的是那些有正确和确定答案的问题。然而，在现实世界的应用中，用户经常提出没有确定答案的问题。错误地回答这样的问题肯定会损害系统的可靠性和可信度。最先进的模型能否准确识别这些问题并提供合理的回答？为了研究上述问题，我们引入了一个名为QnotA的数据集，其中包含五个不同类型的没有确定答案的问题。此外，对于每个QnotA实例，我们还提供一个相应的QA实例，即一个“可以”回答的替代性问题。通过这些数据，我们制定了三个评估任务，以测试系统对QnotA问题的“识别”，“区分”和“证明”的能力。通过全面的实验证明，即使是包括GPT在内的最先进模型也能够进行准确的识别和提供合理的回答。

    Though state-of-the-art (SOTA) NLP systems have achieved remarkable performance on a variety of language understanding tasks, they primarily focus on questions that have a correct and a definitive answer. However, in real-world applications, users often ask questions that don't have a definitive answer. Incorrectly answering such questions certainly hampers a system's reliability and trustworthiness. Can SOTA models accurately identify such questions and provide a reasonable response?  To investigate the above question, we introduce QnotA, a dataset consisting of five different categories of questions that don't have definitive answers. Furthermore, for each QnotA instance, we also provide a corresponding QA instance i.e. an alternate question that ''can be'' answered. With this data, we formulate three evaluation tasks that test a system's ability to 'identify', 'distinguish', and 'justify' QnotA questions. Through comprehensive experiments, we show that even SOTA models including GPT
    
[^31]: 用语义文本相似性链接症状清单

    Linking Symptom Inventories using Semantic Textual Similarity. (arXiv:2309.04607v1 [cs.CL])

    [http://arxiv.org/abs/2309.04607](http://arxiv.org/abs/2309.04607)

    该论文介绍了一种使用语义文本相似性（STS）来链接不同的症状清单的方法，通过测试预训练的STS模型在不同的数据源中预测症状严重程度，该方法在相关任务中达到了74.8%的准确率，优于其他模型。

    

    随着时间的推移，已经开发出了大量的症状清单来衡量临床症状，但这种多样性导致了几个长期存在的问题。最显著的是，来自不同环境和研究的结果不可比较，这限制了可重复性。在这里，我们提出了一种使用语义文本相似性（Semantic Textual Similarity，STS）来链接先前不相容的症状清单中的症状和评分的人工智能（AI）方法。我们测试了四个预训练的STS模型的能力，对来自16个国际数据源的6,607名参与者的四个不同清单中的数千个症状描述对进行相关内容的筛查 - 这通常是一个需要专家小组的具有挑战性的任务。模型的任务是预测六项任务中的四个不同清单中的症状严重程度。STS方法在五个任务中达到了74.8%的准确率，胜过了其他被测试的模型。这项工作表明，结合语境和语义信息可以帮助专家决策过程，从而产生收益。

    An extensive library of symptom inventories has been developed over time to measure clinical symptoms, but this variety has led to several long standing issues. Most notably, results drawn from different settings and studies are not comparable, which limits reproducibility. Here, we present an artificial intelligence (AI) approach using semantic textual similarity (STS) to link symptoms and scores across previously incongruous symptom inventories. We tested the ability of four pre-trained STS models to screen thousands of symptom description pairs for related content - a challenging task typically requiring expert panels. Models were tasked to predict symptom severity across four different inventories for 6,607 participants drawn from 16 international data sources. The STS approach achieved 74.8% accuracy across five tasks, outperforming other models tested. This work suggests that incorporating contextual, semantic information can assist expert decision-making processes, yielding gain
    
[^32]: 当少就意味着更多：探究数据修剪对大规模预训练语言模型( LLMS )的影响

    When Less is More: Investigating Data Pruning for Pretraining LLMs at Scale. (arXiv:2309.04564v1 [cs.CL])

    [http://arxiv.org/abs/2309.04564](http://arxiv.org/abs/2309.04564)

    在这项工作中，研究人员探究了数据修剪对大规模预训练语言模型(LLMs)的影响。通过比较数据质量评估器和修剪预训练语料库后训练的LLMs，他们发现困惑度作为一种简单的技术优于更加计算密集的评分方法。

    

    最近几年，大量的文本数据对于大型语言模型( LLMS )的发展做出了显著贡献。这些数据通常通过从互联网上抓取获取，导致预训练数据集由嘈杂的网络文本构成。过去，为了减小数据集并使其更高质量，采用了以规则为基础的手工启发式过滤器。在这项工作中，我们采取更广泛的视角，探讨了可估算的数据质量，以系统性地衡量预训练数据的质量。我们在大规模上进行了严格比较，包括使用困惑度的简单数据质量评估器，以及更复杂和计算密集的错误L2-范数和记忆化评估。这些指标用于对预训练语料库进行排序和修剪，并随后比较在这些修剪后数据集上训练的LLMs。令人惊讶的是，我们发现困惑度作为一种简单的技术优于更加计算密集的评分方法。

    Large volumes of text data have contributed significantly to the development of large language models (LLMs) in recent years. This data is typically acquired by scraping the internet, leading to pretraining datasets comprised of noisy web text. To date, efforts to prune these datasets down to a higher quality subset have relied on hand-crafted heuristics encoded as rule-based filters. In this work, we take a wider view and explore scalable estimates of data quality that can be used to systematically measure the quality of pretraining data. We perform a rigorous comparison at scale of the simple data quality estimator of perplexity, as well as more sophisticated and computationally intensive estimates of the Error L2-Norm and memorization. These metrics are used to rank and prune pretraining corpora, and we subsequently compare LLMs trained on these pruned datasets. Surprisingly, we find that the simple technique of perplexity outperforms our more computationally expensive scoring metho
    
[^33]: 改进稠密三维视觉引用的三种方法

    Three Ways to Improve Verbo-visual Fusion for Dense 3D Visual Grounding. (arXiv:2309.04561v1 [cs.CV])

    [http://arxiv.org/abs/2309.04561](http://arxiv.org/abs/2309.04561)

    提出了一个稠密三维引用网络ConcreteNet，包含三个新模块，旨在改善具有相同语义类别干扰因素的重复实例的引用性能。

    

    三维视觉引用是指通过自然语言描述来定位三维场景中被引用的物体的任务。该任务在自主室内机器人到AR/VR等各种应用中广泛应用。目前一种常见的解决方案是通过检测来完成三维视觉引用，即通过边界框来定位。然而，在需要进行物理交互的实际应用中，边界框不足以描述物体的几何属性。因此，我们解决了稠密三维视觉引用的问题，即基于引用的三维实例分割。我们提出了一个稠密三维引用网络ConcreteNet，其中包含三个独立的新模块，旨在改进具有相同语义类别干扰因素的具有挑战性的重复实例的引用性能。首先，我们引入了一个自下而上的注意力融合模块，旨在消除实例间关系线索的歧义性。接下来，我们构造一个cont

    3D visual grounding is the task of localizing the object in a 3D scene which is referred by a description in natural language. With a wide range of applications ranging from autonomous indoor robotics to AR/VR, the task has recently risen in popularity. A common formulation to tackle 3D visual grounding is grounding-by-detection, where localization is done via bounding boxes. However, for real-life applications that require physical interactions, a bounding box insufficiently describes the geometry of an object. We therefore tackle the problem of dense 3D visual grounding, i.e. referral-based 3D instance segmentation. We propose a dense 3D grounding network ConcreteNet, featuring three novel stand-alone modules which aim to improve grounding performance for challenging repetitive instances, i.e. instances with distractors of the same semantic class. First, we introduce a bottom-up attentive fusion module that aims to disambiguate inter-instance relational cues, next we construct a cont
    
[^34]: 使用LLMs从电子健康记录中检索证据：可能性与挑战

    Retrieving Evidence from EHRs with LLMs: Possibilities and Challenges. (arXiv:2309.04550v1 [cs.CL])

    [http://arxiv.org/abs/2309.04550](http://arxiv.org/abs/2309.04550)

    本研究提出了一种使用大型语言模型（LLMs）从未结构化的电子健康记录（EHR）中检索和总结相关证据的方法。通过在零样本条件下训练LLM来推断患者是否患有特定疾病，并且模型可以总结支持的证据。该方法在实践中被证明优于传统的信息检索方法。

    

    未结构化的电子健康记录（EHR）数据通常包含与影像数据互补的关键信息，可以为放射科医生的诊断提供帮助。然而，时间限制和与每个患者相关的大量笔记使得手动浏览此类数据以识别相关证据在实践中变得不可行。现代的大型语言模型（LLMs）提供了一种灵活的方式来处理未结构化的EHR数据，并可以提供一种机制来高效地检索和总结与给定查询相关的未结构化证据。在这项工作中，我们提出并评估了一个LLM（Flan-T5 XXL）来实现这个目的。具体而言，在零样本条件下，我们要求LLM推断一个患者是否有或处于某种特定疾病的风险，并在是的情况下提示模型总结支持的证据。通过引入放射科医生进行手动评估，我们发现这种基于LLM的方法提供的输出始终优于标准的信息检索基准方法。

    Unstructured Electronic Health Record (EHR) data often contains critical information complementary to imaging data that would inform radiologists' diagnoses. However, time constraints and the large volume of notes frequently associated with individual patients renders manual perusal of such data to identify relevant evidence infeasible in practice. Modern Large Language Models (LLMs) provide a flexible means of interacting with unstructured EHR data, and may provide a mechanism to efficiently retrieve and summarize unstructured evidence relevant to a given query. In this work, we propose and evaluate an LLM (Flan-T5 XXL) for this purpose. Specifically, in a zero-shot setting we task the LLM to infer whether a patient has or is at risk of a particular condition; if so, we prompt the model to summarize the supporting evidence. Enlisting radiologists for manual evaluation, we find that this LLM-based approach provides outputs consistently preferred to a standard information retrieval base
    
[^35]: CSPRD: 中国股票市场金融政策检索数据集

    CSPRD: A Financial Policy Retrieval Dataset for Chinese Stock Market. (arXiv:2309.04389v1 [cs.CL])

    [http://arxiv.org/abs/2309.04389](http://arxiv.org/abs/2309.04389)

    本研究引入中国股票政策检索数据集（CSPRD），提供了700+条标注的招股说明书段落，通过词汇、嵌入和经过微调的双编码模型的实验证明了CSPRD的有效性和改进潜力。

    

    在最近几年，预训练语言模型（PLMs）取得了突破性进展，引起了相当多的研究关注，并在稠密段落检索方法上取得了有希望的性能，其目的是检索给定问题的相关段落。然而，大部分现有的数据集主要使用了通常常识的事实性查询来评估模型，而金融和经济等专业领域由于缺乏大规模的高质量数据集和专家注释而未被探索。在这项工作中，我们引入了一个新的任务，即政策检索，通过引入中国股票政策检索数据集（CSPRD），该数据集提供了由有经验的专家对来自我们收集的中国政策语料库中的10k+条目的相关文章进行标注的700+条招股说明书段落。对词汇、嵌入和经过微调的双编码模型的实验证明了我们所提出的CSPRD的有效性，但也提示了改进的丰富潜力。

    In recent years, great advances in pre-trained language models (PLMs) have sparked considerable research focus and achieved promising performance on the approach of dense passage retrieval, which aims at retrieving relative passages from massive corpus with given questions. However, most of existing datasets mainly benchmark the models with factoid queries of general commonsense, while specialised fields such as finance and economics remain unexplored due to the deficiency of large-scale and high-quality datasets with expert annotations. In this work, we propose a new task, policy retrieval, by introducing the Chinese Stock Policy Retrieval Dataset (CSPRD), which provides 700+ prospectus passages labeled by experienced experts with relevant articles from 10k+ entries in our collected Chinese policy corpus. Experiments on lexical, embedding and fine-tuned bi-encoder models show the effectiveness of our proposed CSPRD yet also suggests ample potential for improvement. Our best performing
    
[^36]: GRASS: 语音语义理解统一生成模型

    GRASS: Unified Generation Model for Speech Semantic Understanding. (arXiv:2309.02780v1 [cs.CL])

    [http://arxiv.org/abs/2309.02780](http://arxiv.org/abs/2309.02780)

    本文介绍了一个统一的端到端框架，通过指令微调技术实现了语音语义理解任务。实验证明该模型在微调下游任务后明显优于最先进的模型，并在零样本和少样本场景中取得了竞争性的性能。

    

    本文通过引入一个统一的端到端框架，探索了语音语义理解的指令微调技术，该框架根据与任务相关的提示为音频数据生成语义标签。我们使用大量多样的数据进行预训练，其中指令-语音对是通过文本转语音系统构建的。大量实验证明，我们提出的模型在微调下游任务后明显优于最先进的模型。此外，所提出的模型在零样本和少样本场景中实现了竞争性的性能。为了促进未来在语音到语义任务的指令微调方面的研究，我们发布了我们的指令数据集和代码。

    This paper explores the instruction fine-tuning technique for speech semantic understanding by introducing a unified end-to-end (E2E) framework that generates semantic labels conditioned on a task-related prompt for audio data. We pre-train the model using large and diverse data, where instruction-speech pairs are constructed via a text-to-speech (TTS) system. Extensive experiments demonstrate that our proposed model significantly outperforms state-of-the-art (SOTA) models after fine-tuning downstream tasks. Furthermore, the proposed model achieves competitive performance in zero-shot and few-shot scenarios. To facilitate future work on instruction fine-tuning for speech-to-semantic tasks, we release our instruction dataset and code.
    
[^37]: CodeApex：用于大型语言模型的双语编程评估基准

    CodeApex: A Bilingual Programming Evaluation Benchmark for Large Language Models. (arXiv:2309.01940v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.01940](http://arxiv.org/abs/2309.01940)

    CodeApex是一个双语编程评估基准，用于评估大型语言模型在编程理解和代码生成任务上的能力。该基准包括多个选择题和算法问题，评估了14个LLM的编程能力，并发现仍有改进空间。

    

    随着大型语言模型（LLM）的出现，模型的编程能力得到了显著提升，吸引了研究人员日益增长的关注。我们提出了CodeApex，一种双语基准数据集，专注于LLM的编程理解和代码生成能力。CodeApex包括三种类型的多项选择题：概念理解、常识推理和多跳推理，旨在评估LLM在编程理解任务上的能力。此外，CodeApex利用算法问题和相应的测试用例来评估LLM生成的代码质量。我们评估了14个最先进的LLM，包括通用和专门化模型。GPT展现出最佳的编程能力，在这两个任务上的准确率分别达到了约50%和56%。编程任务仍有很大的改进空间。我们希望CodeApex能够为评估编程能力提供参考。

    With the emergence of Large Language Models (LLMs), there has been a significant improvement in the programming capabilities of models, attracting growing attention from researchers. We propose CodeApex, a bilingual benchmark dataset focusing on the programming comprehension and code generation abilities of LLMs. CodeApex comprises three types of multiple-choice questions: conceptual understanding, commonsense reasoning, and multi-hop reasoning, designed to evaluate LLMs on programming comprehension tasks. Additionally, CodeApex utilizes algorithmic questions and corresponding test cases to assess the code quality generated by LLMs. We evaluate 14 state-of-the-art LLMs, including both general-purpose and specialized models. GPT exhibits the best programming capabilities, achieving approximate accuracies of 50% and 56% on the two tasks, respectively. There is still significant room for improvement in programming tasks. We hope that CodeApex can serve as a reference for evaluating the co
    
[^38]: 在不平衡的研究提案主题推理中的跨学科公平性：一种基于层次变换器的具有选择性插值的方法

    Interdisciplinary Fairness in Imbalanced Research Proposal Topic Inference: A Hierarchical Transformer-based Method with Selective Interpolation. (arXiv:2309.01717v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.01717](http://arxiv.org/abs/2309.01717)

    该论文提出了一种基于层次变换器的方法，通过选择性插值来解决在跨学科研究提案和非跨学科研究提案之间规模差异引起的不公平现象。

    

    研究提案主题推理的目标是从资助机构定义的学科体系中获取最合适的学科划分，然后机构将根据这种划分从其数据库中找到合适的同行评审专家。自动化的主题推理可以减少人工主题填写引起的错误，弥补资助机构和项目申请人之间的知识差距，提高系统效率。现有方法将其建模为层次性多标签分类问题，使用生成模型迭代地推理最合适的主题信息。然而，这些方法忽视了跨学科研究提案和非跨学科研究提案之间规模差异，导致自动推理系统将跨学科提案归类为非跨学科，造成在专家分配过程中的不公平现象。我们如何解决这个数据不平衡的问题呢？

    The objective of topic inference in research proposals aims to obtain the most suitable disciplinary division from the discipline system defined by a funding agency. The agency will subsequently find appropriate peer review experts from their database based on this division. Automated topic inference can reduce human errors caused by manual topic filling, bridge the knowledge gap between funding agencies and project applicants, and improve system efficiency. Existing methods focus on modeling this as a hierarchical multi-label classification problem, using generative models to iteratively infer the most appropriate topic information. However, these methods overlook the gap in scale between interdisciplinary research proposals and non-interdisciplinary ones, leading to an unjust phenomenon where the automated inference system categorizes interdisciplinary proposals as non-interdisciplinary, causing unfairness during the expert assignment. How can we address this data imbalance issue und
    
[^39]: 基于任务的混合专家模型用于多任务多语言机器翻译

    Task-Based MoE for Multitask Multilingual Machine Translation. (arXiv:2308.15772v1 [cs.CL])

    [http://arxiv.org/abs/2308.15772](http://arxiv.org/abs/2308.15772)

    本论文介绍了一种基于任务的混合专家模型，将任务信息与MoE模型相结合，在多任务多语言机器翻译中取得了优越的结果，并且能够高效地应用于新的任务。

    

    在训练深度模型的多种应用中，混合专家（MoE）架构已被证明是一种强大的方法。然而，当前的MoE实现是任务无关的，将不同任务的所有标记以相同方式处理。在这项工作中，我们设计了一种新颖的方法，通过共享的动态基于任务的适配器，在MoE模型的不同粒度级别上将任务信息纳入其中。我们的实验证明了我们的方法在多任务多语言机器翻译上的优势。借助任务特定的适配器，我们的模型还可以高效地推广到新的任务。

    Mixture-of-experts (MoE) architecture has been proven a powerful method for diverse tasks in training deep models in many applications. However, current MoE implementations are task agnostic, treating all tokens from different tasks in the same manner. In this work, we instead design a novel method that incorporates task information into MoE models at different granular levels with shared dynamic task-based adapters. Our experiments and analysis show the advantages of our approaches over the dense and canonical MoE models on multi-task multilingual machine translations. With task-specific adapters, our models can additionally generalize to new tasks efficiently.
    
[^40]: 探索大型语言模型用于知识图谱补全

    Exploring Large Language Models for Knowledge Graph Completion. (arXiv:2308.13916v1 [cs.CL])

    [http://arxiv.org/abs/2308.13916](http://arxiv.org/abs/2308.13916)

    本文研究了利用大型语言模型（LLM）进行知识图谱补全的方法，并引入了一种创新的框架（知识图谱LLM），以提高三元组分类和关系预测的性能。

    

    知识图谱在众多人工智能任务中发挥着重要作用，但经常面临不完整性的问题。在本研究中，我们探索了利用大型语言模型（LLM）进行知识图谱补全的方法。我们将知识图谱中的三元组视为文本序列，并引入了一种创新的框架，称为知识图谱LLM（KG-LLM），来对这些三元组进行建模。我们的技术利用三元组的实体和关系描述作为提示，并利用响应进行预测。对各种基准知识图谱的实验表明，我们的方法在三元组分类和关系预测等任务中达到了最先进的性能。我们还发现，微调相对较小的模型（例如LLaMA-7B，ChatGLM-6B）优于最新的ChatGPT和GPT-4。

    Knowledge graphs play a vital role in numerous artificial intelligence tasks, yet they frequently face the issue of incompleteness. In this study, we explore utilizing Large Language Models (LLM) for knowledge graph completion. We consider triples in knowledge graphs as text sequences and introduce an innovative framework called Knowledge Graph LLM (KG-LLM) to model these triples. Our technique employs entity and relation descriptions of a triple as prompts and utilizes the response for predictions. Experiments on various benchmark knowledge graphs demonstrate that our method attains state-of-the-art performance in tasks such as triple classification and relation prediction. We also find that fine-tuning relatively smaller models (e.g., LLaMA-7B, ChatGLM-6B) outperforms recent ChatGPT and GPT-4.
    
[^41]: MLLM-DataEngine：一种MLLM的迭代改进方法

    MLLM-DataEngine: An Iterative Refinement Approach for MLLM. (arXiv:2308.13566v1 [cs.LG])

    [http://arxiv.org/abs/2308.13566](http://arxiv.org/abs/2308.13566)

    本文提出了一种名为MLLM-DataEngine的迭代改进方法，它通过分析模型弱点，生成适当的增量数据集并迭代地增强模型能力。与以往方法相比，MLLM-DataEngine生成的数据在定位、质量和正确性方面表现更好。

    

    尽管在指导数据集构建和基准测试方面，多模态大型语言模型（MLLM）取得了很大的进展，但训练和评估的独立性使得当前的MLLM很难在相对较低的人力成本下进一步提高其能力。本文提出了一种新颖的封闭循环系统MLLM-DataEngine，它连接了数据生成、模型训练和评估。在每个循环迭代中，MLLM-DataEngine首先根据评估结果分析模型的弱点，然后生成合适的增量数据集用于下一次训练迭代，并迭代地增强模型的能力。与先前与基准测试分离的数据收集方法相比，MLLM-DataEngine生成的数据在定位、质量和正确性方面都表现得更好。

    Despite the great advance of Multimodal Large Language Models (MLLMs) in both instruction dataset building and benchmarking, the independence of training and evaluation makes current MLLMs hard to further improve their capability under the guidance of evaluation results with a relatively low human cost. In this paper, we propose MLLM-DataEngine, a novel closed-loop system that bridges data generation, model training, and evaluation. Within each loop iteration, the MLLM-DataEngine first analyze the weakness of the model based on the evaluation results, then generate a proper incremental dataset for the next training iteration and enhance the model capability iteratively. Compared with previous data collection methods which are separate from the benchmarking, the data generated by MLLM-DataEngine shows better targeting, quality, and correctness. For targeting, we propose an Adaptive Bad-case Sampling module, which adjusts the ratio of different types of data within each incremental datas
    
[^42]: 使用精细调整的Llama 2 GPT模型进行金融新闻分析

    Financial News Analytics Using Fine-Tuned Llama 2 GPT Model. (arXiv:2308.13032v1 [cs.CL])

    [http://arxiv.org/abs/2308.13032](http://arxiv.org/abs/2308.13032)

    本研究通过精细调整的Llama 2模型实现了金融新闻的多任务分析，包括文本分析、摘要和情感提取等。实验结果显示，提取的命名实体情感可以作为有监督机器学习模型的预测特征。

    

    本文考虑了使用精细调整的Llama 2 Large Language Model (LLM) 对金融新闻进行多任务分析的可能性。通过PEFT/LoRA方法对模型进行精细调整，主要包括从金融市场角度分析文本、突出文本的主要观点、对文本进行摘要和提取具有适当情感的命名实体等任务。实验结果表明，经过精细调整的Llama 2模型能够进行多任务的金融新闻分析，其响应的结构可以部分为结构化文本，另一部分数据可以采用JSON格式进一步处理。提取的命名实体情感可以被视为具有定量目标变量的监督机器学习模型的预测特征。

    The paper considers the possibility to fine-tune Llama 2 Large Language Model (LLM) for the multitask analysis of financial news. For fine-tuning, the PEFT/LoRA based approach was used. In the study, the model was fine-tuned for the following tasks: analysing a text from financial market perspectives, highlighting main points of a text, summarizing a text and extracting named entities with appropriate sentiments. The obtained results show that the fine-tuned Llama 2 model can perform a multitask financial news analysis with a specified structure of response, part of response can be a structured text and another part of data can have JSON format for further processing. Extracted sentiments for named entities can be considered as predictive features in supervised machine learning models with quantitative target variables.
    
[^43]: HopPG：自我迭代的异构知识多跳问答程序生成

    HopPG: Self-Iterative Program Generation for Multi-Hop Question Answering over Heterogeneous Knowledge. (arXiv:2308.11257v1 [cs.CL])

    [http://arxiv.org/abs/2308.11257](http://arxiv.org/abs/2308.11257)

    本文提出了一种针对多跳问答的自我迭代程序生成框架（HopPG），该框架解决了处理异构知识和多跳问题时所面临的困难，并利用了前几跳的执行结果来生成下一跳的程序。

    

    语义解析方法是基于知识的问答研究中的一个重要分支。它通常基于问题生成可执行程序，并通过知识库进行推理得出答案。由于这种内在机制，它在性能和可解释性方面具有优势。然而，传统的语义解析方法通常在执行之前生成完整的程序，这在处理多跳问题和异构知识时存在困难。首先，完整的多跳程序依赖于多个异构的支持事实，模型很难同时获取这些事实。其次，这些方法忽视了前几跳执行结果与当前跳程序生成之间的交互信息。为了解决这些挑战，我们提出了一种针对异构知识的自我迭代多跳程序生成框架（HopPG），它利用了前几跳的执行结果，并根据它们生成下一跳的程序。

    The semantic parsing-based method is an important research branch for knowledge-based question answering. It usually generates executable programs lean upon the question and then conduct them to reason answers over a knowledge base. Benefit from this inherent mechanism, it has advantages in the performance and the interpretability. However,traditional semantic parsing methods usually generate a complete program before executing it, which struggles with multi-hop question answering over heterogeneous knowledge. Firstly,a complete multi-hop program relies on multiple heterogeneous supporting facts, and it is difficult for models to receive these facts simultaneously. Secondly,these methods ignore the interaction information between the previous-hop execution result and the current-hop program generation. To alleviate these challenges, we propose a self-iterative framework for multi-hop program generation (HopPG) over heterogeneous knowledge, which leverages the previous-hop execution res
    
[^44]: 在图上评估大型语言模型：性能洞察与比较分析

    Evaluating Large Language Models on Graphs: Performance Insights and Comparative Analysis. (arXiv:2308.11224v1 [cs.AI])

    [http://arxiv.org/abs/2308.11224](http://arxiv.org/abs/2308.11224)

    本研究评估了四个大型语言模型在图数据上解决分析问题的能力，结果显示LLM在理解图数据、生成正确结果和进行结构推理方面表现出色，但在真实性和矫正能力方面存在一些挑战。

    

    大型语言模型(LLM)引起了学术界和工业界的广泛关注，然而LLM在图数据上的应用仍然未被充分探索。在本研究中，我们评估了四个LLM在解决几个图数据分析问题时的能力。我们采用了四个不同的评估指标：理解能力、正确性、真实性和矫正能力。我们的结果表明：1) LLM能够有效地理解自然语言中的图数据，并推理图的拓扑结构。2) GPT模型能够生成逻辑和连贯的结果，在正确性方面优于其他替代方案。3) 所有被检测的LLM在结构推理方面都面临挑战，零样本思维链和少样本提示等技术显示出效果下降。4) GPT模型在多答案任务中经常产生错误答案，引发真实性方面的担忧。5) GPT模型对其输出表现出较高的信心，可能阻碍其矫正能力。值得注意的是，GPT-4显示出了不同水平的性能。

    Large Language Models (LLMs) have garnered considerable interest within both academic and industrial. Yet, the application of LLMs to graph data remains under-explored. In this study, we evaluate the capabilities of four LLMs in addressing several analytical problems with graph data. We employ four distinct evaluation metrics: Comprehension, Correctness, Fidelity, and Rectification. Our results show that: 1) LLMs effectively comprehend graph data in natural language and reason with graph topology. 2) GPT models can generate logical and coherent results, outperforming alternatives in correctness. 3) All examined LLMs face challenges in structural reasoning, with techniques like zero-shot chain-of-thought and few-shot prompting showing diminished efficacy. 4) GPT models often produce erroneous answers in multi-answer tasks, raising concerns in fidelity. 5) GPT models exhibit elevated confidence in their outputs, potentially hindering their rectification capacities. Notably, GPT-4 has dem
    
[^45]: ChatGPT生物医学生成文本中建立信任的方法：基于本体的知识图谱用于验证疾病-症状关系

    Establishing Trust in ChatGPT BioMedical Generated Text: An Ontology-Based Knowledge Graph to Validate Disease-Symptom Links. (arXiv:2308.03929v1 [cs.AI])

    [http://arxiv.org/abs/2308.03929](http://arxiv.org/abs/2308.03929)

    本研究通过构建基于本体的知识图谱，利用疾病本体和症状本体构建数学模型，利用事实核查算法和网络中心度指标分析ChatGPT生成的文本与真实医学文献之间的准确性，以验证疾病-症状关系。

    

    方法：通过创新的方法，我们从真实的医学文献和人工智能生成的内容构建了基于本体的知识图谱。我们的目标是区分事实信息和未经验证的数据。我们收集了两个数据集：一个是使用“人类疾病和症状”查询从生物医学文献中编译的，另一个是由ChatGPT生成的模拟文章。利用这些数据集（PubMed和ChatGPT），我们随机选择了10组每组250个摘要，并使用特定的种子。我们的方法主要是利用疾病本体（DOID）和症状本体（SYMP）构建知识图谱，这是一种强大的数学模型，可以进行无偏差的比较。通过使用我们的事实核查算法和网络中心度指标，我们进行了GPT疾病-症状链接分析，以量化在噪声、假设和重要发现中的事实知识的准确性。结果：通过比较不同ChatGPT知识图谱及其PubMed计数获得的结果，我们发现...

    Methods: Through an innovative approach, we construct ontology-based knowledge graphs from authentic medical literature and AI-generated content. Our goal is to distinguish factual information from unverified data. We compiled two datasets: one from biomedical literature using a "human disease and symptoms" query, and another generated by ChatGPT, simulating articles. With these datasets (PubMed and ChatGPT), we curated 10 sets of 250 abstracts each, selected randomly with a specific seed. Our method focuses on utilizing disease ontology (DOID) and symptom ontology (SYMP) to build knowledge graphs, robust mathematical models that facilitate unbiased comparisons. By employing our fact-checking algorithms and network centrality metrics, we conducted GPT disease-symptoms link analysis to quantify the accuracy of factual knowledge amid noise, hypotheses, and significant findings.  Results: The findings obtained from the comparison of diverse ChatGPT knowledge graphs with their PubMed count
    
[^46]: 从概率编程到基于复杂性的编程

    From Probabilistic Programming to Complexity-based Programming. (arXiv:2307.15453v1 [cs.AI])

    [http://arxiv.org/abs/2307.15453](http://arxiv.org/abs/2307.15453)

    CompLog是一种基于复杂性的计算框架，通过计算Kolmogorov复杂性替代概率推理，实现计算某种情况意外性的度量，并通过规范的世界和心智模型的描述生成相关描述，并提供对析取和否定的替代方法。

    

    本文介绍了一种名为CompLog的新型计算框架的主要特点和初步实现。CompLog借鉴了概率编程系统（如ProbLog）的推理机制，并基于Simplicity理论提出了一种新的推理机制，通过ASP程序的min-path搜索计算两种Kolmogorov复杂性，而不是概率推理。该系统使用户能够计算某个情况意外性的ex-post和ex-ante度量，分别对应于后验和先验主观概率。计算基于通过描述性谓词之间的因果和描述性关系加权的世界和心智模型的规范。本文还阐述了几个应用示例：生成相关描述，并提供对析取和否定的替代方法。

    The paper presents the main characteristics and a preliminary implementation of a novel computational framework named CompLog. Inspired by probabilistic programming systems like ProbLog, CompLog builds upon the inferential mechanisms proposed by Simplicity Theory, relying on the computation of two Kolmogorov complexities (here implemented as min-path searches via ASP programs) rather than probabilistic inference. The proposed system enables users to compute ex-post and ex-ante measures of unexpectedness of a certain situation, mapping respectively to posterior and prior subjective probabilities. The computation is based on the specification of world and mental models by means of causal and descriptive relations between predicates weighted by complexity. The paper illustrates a few examples of application: generating relevant descriptions, and providing alternative approaches to disjunction and to negation.
    
[^47]: 从人类反馈中进行强化学习的开放问题和基本限制

    Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback. (arXiv:2307.15217v1 [cs.AI])

    [http://arxiv.org/abs/2307.15217](http://arxiv.org/abs/2307.15217)

    本文调查了从人类反馈中进行强化学习的开放问题和基本限制，并提出了加强社会监督的审计和披露标准。

    

    从人类反馈中进行强化学习（RLHF）是一种训练人工智能系统与人类目标保持一致的技术。RLHF已成为微调最新的大型语言模型（LLM）的核心方法。尽管如此受欢迎，但系统性地系统化其缺陷的公开工作相对较少。在本文中，我们（1）调查了RLHF及相关方法的开放问题和基本限制；（2）概述了了解、改进和补充RLHF的实践技术；以及（3）提出了审计和披露标准以改进RLHF系统的社会监督。我们的工作强调了RLHF的局限性，并强调了以多方面方法开发更安全的人工智能系统的重要性。

    Reinforcement learning from human feedback (RLHF) is a technique for training AI systems to align with human goals. RLHF has emerged as the central method used to finetune state-of-the-art large language models (LLMs). Despite this popularity, there has been relatively little public work systematizing its flaws. In this paper, we (1) survey open problems and fundamental limitations of RLHF and related methods; (2) overview techniques to understand, improve, and complement RLHF in practice; and (3) propose auditing and disclosure standards to improve societal oversight of RLHF systems. Our work emphasizes the limitations of RLHF and highlights the importance of a multi-faceted approach to the development of safer AI systems.
    
[^48]: 在金融行业中应用量子自然语言处理(QNLP)进行情感分析

    Applying QNLP to sentiment analysis in finance. (arXiv:2307.11788v1 [cs.CL])

    [http://arxiv.org/abs/2307.11788](http://arxiv.org/abs/2307.11788)

    本论文研究了在金融行业中应用量子自然语言处理(QNLP)进行情感分析的实际适用性。利用一种新颖的数据生成方法，我们发现量子增强的长短期记忆(QLSTM)可以更快地训练，并且在软件实现方面接近古典结果。

    

    作为一个领域，即使是最微小的质量改进也能产生巨大价值的应用领域，金融是早期量子优势的有前途的候选者。在迅速发展的量子自然语言处理(QNLP)领域中，我们探索了DisCoCat和量子增强的长短期记忆(QNLP)这两种中心方法在金融情感分析问题中的实际适用性。利用一种新颖的基于ChatGPT的数据生成方法，我们进行了一个包含1000多个真实句子的案例研究，发现QLSTM的训练速度比DisCoCat快得多，并且在可用的软件实现中也接近古典结果。

    As an application domain where the slightest qualitative improvements can yield immense value, finance is a promising candidate for early quantum advantage. Focusing on the rapidly advancing field of Quantum Natural Language Processing (QNLP), we explore the practical applicability of the two central approaches DisCoCat and Quantum-Enhanced Long Short-Term Memory (QLSTM) to the problem of sentiment analysis in finance. Utilizing a novel ChatGPT-based data generation approach, we conduct a case study with more than 1000 realistic sentences and find that QLSTMs can be trained substantially faster than DisCoCat while also achieving close to classical results for their available software implementations.
    
[^49]: 为推荐参考解决方案而去重和排名解决方案程序

    Deduplicating and Ranking Solution Programs for Suggesting Reference Solutions. (arXiv:2307.07940v1 [cs.SE])

    [http://arxiv.org/abs/2307.07940](http://arxiv.org/abs/2307.07940)

    本文提出了一种在编程问题中去除重复程序并排名的方法，以鼓励学习者参考不同的解决方法，从而学习更好的解决方案。

    

    在编程教育中，参考其他用户编写的解决方案程序对学习者很有帮助。然而，当前的在线评测系统只是列出用户提交的所有解决方案程序供参考，并根据提交日期、执行时间或用户评分进行排序，忽视了程序能够成为参考的程度。此外，由于存在太多重复和近似重复的程序，用户很难参考多种解决方法。为了激励学习者参考不同的解决方法以学习更好的解决方案，本文提出了一种在每个编程问题中去重和排名常见解决方案程序的方法。基于更多重复的程序采用更常见的方法并可作为参考的假设，我们删除了近似重复的解决方案程序，并根据重复计数对唯一的程序进行排序。实验结果表明这个方法能够有效地去重和排名解决方案程序。

    Referring to the solution programs written by the other users is helpful for learners in programming education. However, current online judge systems just list all solution programs submitted by users for references, and the programs are sorted based on the submission date and time, execution time, or user rating, ignoring to what extent the program can be a reference. In addition, users struggle to refer to a variety of solution approaches since there are too many duplicated and near-duplicated programs. To motivate the learners to refer to various solutions to learn the better solution approaches, in this paper, we propose an approach to deduplicate and rank common solution programs in each programming problem. Based on the hypothesis that the more duplicated programs adopt a more common approach and can be a reference, we remove the near-duplicated solution programs and rank the unique programs based on the duplicate count. The experiments on the solution programs submitted to a rea
    
[^50]: 在大型语言模型时代的被遗忘权：涵义、挑战和解决方案

    Right to be Forgotten in the Era of Large Language Models: Implications, Challenges, and Solutions. (arXiv:2307.03941v1 [cs.CY])

    [http://arxiv.org/abs/2307.03941](http://arxiv.org/abs/2307.03941)

    本文探讨了在大型语言模型时代的被遗忘权（RTBF）面临的挑战，提供了实施技术解决方案的见解。

    

    被遗忘权（RTBF）最初是由谷歌西班牙与埃克斯内塔索委员会(Mario Costeja Gonz\'alez)之间的官司结果而确立的，并且后来被作为欧洲联盟一般数据保护条例（GDPR）下的删除权。RTBF允许个人向组织请求删除个人数据，特别是对于搜索引擎，个人可以向组织发送请求，排除他们的信息在查询结果中出现。然而，随着大型语言模型（LLMs）的发展和其在聊天机器人中的应用，LLM启用的软件系统变得越来越受欢迎。但它们并没有被排除在RTBF之外。相比搜索引擎使用的索引方法，LLMs以一种完全不同的方式存储和处理信息，这为符合RTBF提出了新的挑战。在本文中，我们探讨了这些挑战，并提供了关于如何实施技术解决方案以符合RTBF的见解。

    The Right to be Forgotten (RTBF) was first established as the result of the ruling of Google Spain SL, Google Inc. v AEPD, Mario Costeja Gonz\'alez, and was later included as the Right to Erasure under the General Data Protection Regulation (GDPR) of European Union to allow individuals the right to request personal data be deleted by organizations. Specifically for search engines, individuals can send requests to organizations to exclude their information from the query results. With the recent development of Large Language Models (LLMs) and their use in chatbots, LLM-enabled software systems have become popular. But they are not excluded from the RTBF. Compared with the indexing approach used by search engines, LLMs store, and process information in a completely different way. This poses new challenges for compliance with the RTBF. In this paper, we explore these challenges and provide our insights on how to implement technical solutions for the RTBF, including the use of machine unle
    
[^51]: $\alpha$-$\beta$-分解及Simon同余的二元情况

    $\alpha$-$\beta$-Factorization and the Binary Case of Simon's Congruence. (arXiv:2306.14192v2 [math.CO] UPDATED)

    [http://arxiv.org/abs/2306.14192](http://arxiv.org/abs/2306.14192)

    本研究通过介绍$\alpha$-$\beta$-分解的概念，将Simon同余特征化为$1$-普遍性单词，并应用于二元单词的完全刻画和同余指数计算。

    

    在1991年，H\'ebrard引入了一种单词的分解方法，被证明是研究单词的离散因子（也称为（离散）子串或子序列）的强大工具。基于此，Karandikar和Schnoebelen首先引入了$k$-丰富性的概念，随后Barker等人引入了$k$-普遍性的概念。在2022年，Fleischmann等人通过交集化单词的拱形分解和其逆序来推广了拱形分解。尽管作者仅仅使用这种分解方法来研究最短的缺失离散因子，但在本研究中我们将对这种新的$\alpha$-$\beta$-分解进行研究。我们在$k$-普遍性单词的$\alpha$-$\beta$-分解中将著名的Simon同余特征化为$1$-普遍性单词。此外，我们将这些结果应用于二元单词。在这种特殊情况下，我们得到了类别的完全刻画并计算了同余的指数。最后，我们开始研究三元情况，展示了...

    In 1991 H\'ebrard introduced a factorization of words that turned out to be a powerful tool for the investigation of a word's scattered factors (also known as (scattered) subwords or subsequences). Based on this, first Karandikar and Schnoebelen introduced the notion of $k$-richness and later on Barker et al. the notion of $k$-universality. In 2022 Fleischmann et al. presented a generalization of the arch factorization by intersecting the arch factorization of a word and its reverse. While the authors merely used this factorization for the investigation of shortest absent scattered factors, in this work we investigate this new $\alpha$-$\beta$-factorization as such. We characterize the famous Simon congruence of $k$-universal words in terms of $1$-universal words. Moreover, we apply these results to binary words. In this special case, we obtain a full characterization of the classes and calculate the index of the congruence. Lastly, we start investigating the ternary case, present a fu
    
[^52]: 朝着可信的解释：因果关系解释论文研究

    Towards Trustworthy Explanation: On Causal Rationalization. (arXiv:2306.14115v1 [cs.LG])

    [http://arxiv.org/abs/2306.14115](http://arxiv.org/abs/2306.14115)

    该论文介绍了一种新的因果关系解释方法，通过在解释中引入非虚假性和效率，从因果推断的角度定义了因果概率，从而建立了必要和充分解释的主要组成部分，相比现有的基于关联的解释方法，这种方法有更加优越的性能表现。

    

    随着自然语言处理的最新进展，解释成为了通过选择输入文本的子集来解释黑盒模型中主要变化的一个基本的自我解释图。然而，现有的基于关联的解释方法在两个或多个片段高度互相关联时无法识别真正的解释，因此对预测准确性提供类似的贡献，所谓的虚假性。为了解决这一限制，我们从因果推断的角度新颖地将两个因果期望值（非虚假性和效率）引入了解释中。我们根据一种新提出的解释结构因果模型定义了一系列的因果概率，通过其理论鉴定，建立了必要和充分解释的主要组成部分。我们在真实世界的评论和医疗数据集上证明了所提出的因果关系解释的优越性能。

    With recent advances in natural language processing, rationalization becomes an essential self-explaining diagram to disentangle the black box by selecting a subset of input texts to account for the major variation in prediction. Yet, existing association-based approaches on rationalization cannot identify true rationales when two or more snippets are highly inter-correlated and thus provide a similar contribution to prediction accuracy, so-called spuriousness. To address this limitation, we novelly leverage two causal desiderata, non-spuriousness and efficiency, into rationalization from the causal inference perspective. We formally define a series of probabilities of causation based on a newly proposed structural causal model of rationalization, with its theoretical identification established as the main component of learning necessary and sufficient rationales. The superior performance of the proposed causal rationalization is demonstrated on real-world review and medical datasets w
    
[^53]: CamChoice：一份包含多项选择题和候选答案分布的语料库

    CamChoice: A Corpus of Multiple Choice Questions and Candidate Response Distributions. (arXiv:2306.13047v1 [cs.CL])

    [http://arxiv.org/abs/2306.13047](http://arxiv.org/abs/2306.13047)

    本文介绍了CamChoice数据集，该数据集包含多项选择理解问题和真实候选答案选项分布，为候选人分布匹配任务提供了自动评估方式。

    

    多项选择题是用于衡量候选人在各种领域和任务中能力的普遍评估形式。提出的问题的质量对于测试设计人员非常重要，因此新提出的问题在部署到实际考试之前需要经过几个预测试评估阶段。目前，这个过程是相当手动化的，这可能导致问题开发周期的时间滞后。自动化此过程将大大提高效率，然而目前的数据集不包含足够的预测试分析信息。在本文中，我们介绍了CamChoice：一份包含不同目标级别问题和真实候选答案选项分布的多项选择理解数据集。我们引入了候选人分布匹配任务，提出了几种评估指标，并证明了在RACE++上训练的自动系统可以实现该任务。

    Multiple Choice examinations are a ubiquitous form of assessment that is used to measure the ability of candidates across various domains and tasks. Maintaining the quality of proposed questions is of great importance to test designers, and therefore newly proposed questions go through several pre-test evaluation stages before they can be deployed into real-world exams. This process is currently quite manual, which can lead to time lags in the question development cycle. Automating this process would lead to a large improvement in efficiency, however, current datasets do not contain sufficient pre-test analysis information. In this paper, we introduce CamChoice; a multiple-choice comprehension dataset with questions at different target levels, where questions have the true candidate selected options distributions. We introduce the task of candidate distribution matching, propose several evaluation metrics for the task, and demonstrate that automatic systems trained on RACE++ can be lev
    
[^54]: LLMatic: 基于大语言模型和多样性优化的神经结构搜索

    LLMatic: Neural Architecture Search via Large Language Models and Quality-Diversity Optimization. (arXiv:2306.01102v1 [cs.NE])

    [http://arxiv.org/abs/2306.01102](http://arxiv.org/abs/2306.01102)

    本文介绍了利用大语言模型和多样性优化算法相结合的 LLMatic 神经结构搜索算法。该算法在CIFAR-10数据集进行测试，仅进行2000次搜索即可产生高性能网络，即使没有该基准领域的先前知识或任何先前的最佳结果的曝光。

    

    大型语言模型 (LLMs) 已成为一种强大的工具，可以完成广泛的任务。它们的能力涵盖了许多领域，它们在代码生成领域产生了重大影响。在此情况下，我们将 LLMs 视为变异和交叉工具。同时，多样性优化算法已知可以发现多样性和稳健的解决方案。通过将 LLMs 的代码生成能力与 QD 解决方案的多样性和鲁棒性相结合，我们引入了 LLMatic，一个神经结构搜索 (NAS) 算法。虽然 LLMs 通过提示直接进行 NAS 考验困难，但 LLMatic 利用程序化方法，利用 QD 来进行提示和网络结构，从而创建多样性和高性能网络。我们在 CIFAR-10 图像分类基准测试中测试了 LLMatic，证明它可以在仅进行 2000 次搜索的情况下产生具有竞争力的网络，即使没有该基准领域的先前知识或任何先前的最佳结果的曝光。

    Large Language Models (LLMs) have emerged as powerful tools capable of accomplishing a broad spectrum of tasks. Their abilities span numerous areas, and one area where they have made a significant impact is in the domain of code generation. In this context, we view LLMs as mutation and crossover tools. Meanwhile, Quality-Diversity (QD) algorithms are known to discover diverse and robust solutions. By merging the code-generating abilities of LLMs with the diversity and robustness of QD solutions, we introduce LLMatic, a Neural Architecture Search (NAS) algorithm. While LLMs struggle to conduct NAS directly through prompts, LLMatic uses a procedural approach, leveraging QD for prompts and network architecture to create diverse and highly performant networks. We test LLMatic on the CIFAR-10 image classification benchmark, demonstrating that it can produce competitive networks with just $2,000$ searches, even without prior knowledge of the benchmark domain or exposure to any previous top-p
    
[^55]: GPT 模型在化学领域到底有怎样的应用？八个任务的综合基准测试。

    What indeed can GPT models do in chemistry? A comprehensive benchmark on eight tasks. (arXiv:2305.18365v1 [cs.CL])

    [http://arxiv.org/abs/2305.18365](http://arxiv.org/abs/2305.18365)

    本文建立了包括 8 个实际化学任务的综合基准测试，有力地证明了 LLM 在实际化学中的能力。

    

    具有强大自然语言处理能力的大型语言模型已被广泛应用于科学、金融和软件工程等领域。但是，LLM 是否有能力推动化学领域的进展仍不清楚。本文建立了包含 8 个实际化学任务的综合基准测试，包括名称预测、属性预测、产量预测、反应预测、反合成（从产物预测反应物）、基于文本的分子设计、分子字幕和试剂选择。我们使用广泛认可的数据集，包括 BBBP、Tox21、PubChem、USPTO 和 ChEBI，有力地证明了 LLM 在实际化学中的能力。在精心选择的示例中，对三种 GPT 模型（GPT-4、GPT-3.5 和 DaVinci-003）在零样本和少样本有上下文学习的设置中进行了评估。

    Large Language Models (LLMs) with strong abilities in natural language processing tasks have emerged and have been rapidly applied in various kinds of areas such as science, finance and software engineering. However, the capability of LLMs to advance the field of chemistry remains unclear. In this paper,we establish a comprehensive benchmark containing 8 practical chemistry tasks, including 1) name prediction, 2) property prediction, 3) yield prediction, 4) reaction prediction, 5) retrosynthesis (prediction of reactants from products), 6)text-based molecule design, 7) molecule captioning, and 8) reagent selection. Our analysis draws on widely recognized datasets including BBBP, Tox21, PubChem, USPTO, and ChEBI, facilitating a broad exploration of the capacities of LLMs within the context of practical chemistry. Three GPT models (GPT-4, GPT-3.5,and Davinci-003) are evaluated for each chemistry task in zero-shot and few-shot in-context learning settings with carefully selected demonstrat
    
[^56]: 大型语言模型可能是懒惰的学习者：分析上下文学习中的捷径

    Large Language Models Can be Lazy Learners: Analyze Shortcuts in In-Context Learning. (arXiv:2305.17256v1 [cs.CL])

    [http://arxiv.org/abs/2305.17256](http://arxiv.org/abs/2305.17256)

    本文探讨了大型语言模型在上下文学习中利用提示中的捷径的依赖性，发现大型模型更有可能在推理过程中利用提示中的捷径，这为评估上下文学习的稳健性和检测和缓解提示中捷径的使用提供了新的视角和挑战。

    

    最近，大型语言模型（LLM）在上下文学习中展现出巨大潜力，其中LLM通过几个输入-标签对（提示）的条件来学习新任务。尽管其潜力巨大，但我们对影响最终任务性能和上下文学习稳健性的因素的理解仍然有限。本文旨在通过研究LLM对提示内捷径或假相关的依赖关系来弥补这一知识差距。通过分类和抽取任务的全面实验，我们揭示了LLM是“懒惰学习者”的事实，它往往利用提示中的捷径来获取下游任务的性能提升。此外，我们还发现一个令人惊讶的发现，即较大的模型更有可能在推理过程中利用提示中的捷径。我们的发现为评估上下文学习的稳健性和检测和缓解提示中捷径的使用提供了新的视角和挑战。

    Large language models (LLMs) have recently shown great potential for in-context learning, where LLMs learn a new task simply by conditioning on a few input-label pairs (prompts). Despite their potential, our understanding of the factors influencing end-task performance and the robustness of in-context learning remains limited. This paper aims to bridge this knowledge gap by investigating the reliance of LLMs on shortcuts or spurious correlations within prompts. Through comprehensive experiments on classification and extraction tasks, we reveal that LLMs are "lazy learners" that tend to exploit shortcuts in prompts for downstream tasks. Additionally, we uncover a surprising finding that larger models are more likely to utilize shortcuts in prompts during inference. Our findings provide a new perspective on evaluating robustness in in-context learning and pose new challenges for detecting and mitigating the use of shortcuts in prompts.
    
[^57]: 个性化预测的注释填补：关于分布动态和模型预测的初步研究

    Annotation Imputation to Individualize Predictions: Initial Studies on Distribution Dynamics and Model Predictions. (arXiv:2305.15070v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.15070](http://arxiv.org/abs/2305.15070)

    本文提出使用填补方法为所有注释者生成所有示例的意见，从而创建一个不排斥任何注释者观点的数据集，并分析发现填补方法的选择对软标签变化和分布有显著影响。

    

    通过众包进行数据注释非常费时费钱。由于这些成本，数据集的创建者通常让每个注释者只对一小部分数据进行标注。这导致了稀疏的数据集，其中的示例只被少数注释者标记。这个过程的缺点在于，如果一个注释者没有标注一个特定的示例，他们对它的看法就会被忽视。这在主观的自然语言处理数据集中尤为令人担忧，因为没有一个正确的标签：人们可能会有不同的有效观点。因此，我们提出使用填补方法为所有示例生成所有注释者的意见，从而创建一个不排斥任何注释者观点的数据集。然后，我们使用填补数据集中的数据训练和提示模型，以预测响应和个别注释的分布。在我们对结果的分析中，我们发现填补方法的选择显著影响软标签的变化和分布。

    Annotating data via crowdsourcing is time-consuming and expensive. Due to these costs, dataset creators often have each annotator label only a small subset of the data. This leads to sparse datasets with examples that are marked by few annotators. The downside of this process is that if an annotator doesn't get to label a particular example, their perspective on it is missed. This is especially concerning for subjective NLP datasets where there is no single correct label: people may have different valid opinions. Thus, we propose using imputation methods to generate the opinions of all annotators for all examples, creating a dataset that does not leave out any annotator's view. We then train and prompt models, using data from the imputed dataset, to make predictions about the distribution of responses and individual annotations.  In our analysis of the results, we found that the choice of imputation method significantly impacts soft label changes and distribution. While the imputation 
    
[^58]: 文档理解数据集和评估（DUDE）

    Document Understanding Dataset and Evaluation (DUDE). (arXiv:2305.08455v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.08455](http://arxiv.org/abs/2305.08455)

    DUDE推出了一个新的数据集和评估方法，旨在创造一个更实际的基准测试并推动当前方法的边界，以更准确地模拟真实世界的情况

    

    我们呼吁文档AI社区重新评估当前的方法论，拥抱创建更实际取向的基准测试的挑战。文档理解数据集和评估（DUDE）旨在纠正在理解视觉丰富文档（VRD）方面的研究进展停滞不前的情况。我们提供了一个新的数据集，其中包括与多行业、多领域和多页VRD相关的问题类型、答案和文档布局的创新，具有各种来源和日期。此外，我们通过创建多任务和多领域的评估设置来推动当前方法的边界，这些设置更准确地模拟了真实世界的情况，在这些情况下需要在低资源环境下进行强大的泛化和适应。DUDE旨在成为一个更实际、更长期的基准测试标准，并希望它会引领未来的扩展和贡献，以应对真实世界的挑战。最后，我们的工作说明了以下重要性。

    We call on the Document AI (DocAI) community to reevaluate current methodologies and embrace the challenge of creating more practically-oriented benchmarks. Document Understanding Dataset and Evaluation (DUDE) seeks to remediate the halted research progress in understanding visually-rich documents (VRDs). We present a new dataset with novelties related to types of questions, answers, and document layouts based on multi-industry, multi-domain, and multi-page VRDs of various origins, and dates. Moreover, we are pushing the boundaries of current methods by creating multi-task and multi-domain evaluation setups that more accurately simulate real-world situations where powerful generalization and adaptation under low-resource settings are desired. DUDE aims to set a new standard as a more practical, long-standing benchmark for the community, and we hope that it will lead to future extensions and contributions that address real-world challenges. Finally, our work illustrates the importance o
    
[^59]: 早起的鸟儿捉到虫：利用编码器模型的早期层进行更有效的代码分类

    The EarlyBIRD Catches the Bug: On Exploiting Early Layers of Encoder Models for More Efficient Code Classification. (arXiv:2305.04940v1 [cs.SE])

    [http://arxiv.org/abs/2305.04940](http://arxiv.org/abs/2305.04940)

    本文介绍了一种早期层组合的方法EarlyBIRD，该方法可以有效利用深度自然语言处理模型的资源和可用信息，从而提高代码分类的性能，在缺陷检测方面平均可提高2个点。

    

    现代自然语言处理技术在软件工程任务如漏洞检测和类型推理方面表现出了卓越的优势。然而，训练深度自然语言处理模型需要大量计算资源。本文探讨了一些技术，旨在实现这些模型中资源和可用信息的最佳利用。我们提出了一种通用的方法EarlyBIRD，从预训练的transformer模型的早期层构建代码的复合表示。我们通过比较12种创建复合表示的策略与仅使用最后一个编码器层的标准实践，在CodeBERT模型上实证研究了这种方法的可行性。我们在4个数据集上的评估表明，几个早期层的组合在缺陷检测方面产生更好的性能，而一些组合则改进了多类分类。具体而言，我们获得了平均检测增强2。

    The use of modern Natural Language Processing (NLP) techniques has shown to be beneficial for software engineering tasks, such as vulnerability detection and type inference. However, training deep NLP models requires significant computational resources. This paper explores techniques that aim at achieving the best usage of resources and available information in these models.  We propose a generic approach, EarlyBIRD, to build composite representations of code from the early layers of a pre-trained transformer model. We empirically investigate the viability of this approach on the CodeBERT model by comparing the performance of 12 strategies for creating composite representations with the standard practice of only using the last encoder layer.  Our evaluation on four datasets shows that several early layer combinations yield better performance on defect detection, and some combinations improve multi-class classification. More specifically, we obtain a +2 average improvement of detection 
    
[^60]: 自我编辑：针对代码生成的故障感知式代码编辑器

    Self-Edit: Fault-Aware Code Editor for Code Generation. (arXiv:2305.04087v1 [cs.SE])

    [http://arxiv.org/abs/2305.04087](http://arxiv.org/abs/2305.04087)

    本文提出了一种故障感知式代码编辑器，通过执行生成的代码并将执行结果包含在在注释中来优化竞技编程任务的代码质量，通过与九个不同的LLMs进行比较，本方法可以在两个竞技编程数据集上显著提高代码的准确性。

    

    大型语言模型（LLMs）在竞技编程任务中生成代码的能力已经得到证明，但由于样本数量有限，LLMs仍然存在较低的准确性。受人类编程过程的启发，我们提出了一种生成和编辑的方法，利用LLMs生成的代码的执行结果来提高竞技编程任务的代码质量。我们在问题中提供的示例测试用例上执行生成的代码，并将执行结果包含在补充性注释中。利用这个注释作为指导，我们的故障感知式代码编辑器用于纠正生成的代码中的错误。我们在两个竞技编程数据集上进行了广泛的评估，涵盖了九个不同的LLMs。与直接从LLMs生成相比，我们的方法可以在APPS-dev上将pass@1的平均值提高89％，在APPS-test上提高31％，在HumanEval上提高48％，超过了九个流行的代码生成LLMs，参数大小范围为110M-t。

    Large language models (LLMs) have demonstrated an impressive ability to generate codes on competitive programming tasks. However, with limited sample numbers, LLMs still suffer from poor accuracy. Inspired by the process of human programming, we propose a generate-and-edit approach that utilizes execution results of the generated code from LLMs to improve the code quality on the competitive programming task. We execute the generated code on the example test case provided in the question and wrap execution results into a supplementary comment. Utilizing this comment as guidance, our fault-aware code editor is employed to correct errors in the generated code. We perform extensive evaluations across two competitive programming datasets with nine different LLMs. Compared to directly generating from LLMs, our approach can improve the average of pass@1 by 89\% on APPS-dev, 31\% on APPS-test, and 48\% on HumanEval over nine popular code generation LLMs with parameter sizes ranging from 110M t
    
[^61]: ChatGPT是否能够预测股票价格波动？回报可预测性与大语言模型。

    Can ChatGPT Forecast Stock Price Movements? Return Predictability and Large Language Models. (arXiv:2304.07619v1 [q-fin.ST])

    [http://arxiv.org/abs/2304.07619](http://arxiv.org/abs/2304.07619)

    本研究探究了使用ChatGPT及其他大型语言模型预测股市回报的潜力，发现ChatGPT的预测表现优于传统情感分析方法，而基础模型无法准确预测股票价格变化，表明复杂模型可预测能力的崛起。这表明在投资决策过程中引入先进的语言模型可以提高预测准确性并增强定量交易策略的表现。

    

    本文研究了使用情感分析预测股市回报的潜力，探讨了使用ChatGPT以及其他大语言模型在预测股市回报方面的表现。我们使用ChatGPT判断新闻标题对公司股票价格是好消息、坏消息或无关消息。通过计算数字分数，我们发现这些"ChatGPT分数"和随后的日常股票市场回报之间存在正相关性。而且，ChatGPT的表现优于传统的情感分析方法。同时，我们发现GPT-1、GPT-2和BERT等基础模型无法准确预测回报，这表明回报可预测性是复杂模型的一种新兴能力。我们的研究结果表明，将先进的语言模型纳入投资决策过程可以产生更准确的预测，并提高定量交易策略的表现。

    We examine the potential of ChatGPT, and other large language models, in predicting stock market returns using sentiment analysis of news headlines. We use ChatGPT to indicate whether a given headline is good, bad, or irrelevant news for firms' stock prices. We then compute a numerical score and document a positive correlation between these ``ChatGPT scores'' and subsequent daily stock market returns. Further, ChatGPT outperforms traditional sentiment analysis methods. We find that more basic models such as GPT-1, GPT-2, and BERT cannot accurately forecast returns, indicating return predictability is an emerging capacity of complex models. Our results suggest that incorporating advanced language models into the investment decision-making process can yield more accurate predictions and enhance the performance of quantitative trading strategies.
    
[^62]: ARNOLD：基于连续状态实现的现实3D场景语言引导任务学习基准测试

    ARNOLD: A Benchmark for Language-Grounded Task Learning With Continuous States in Realistic 3D Scenes. (arXiv:2304.04321v1 [cs.AI])

    [http://arxiv.org/abs/2304.04321](http://arxiv.org/abs/2304.04321)

    ARNOLD是一个评估基于语言引导、具有连续状态的现实3D场景任务学习的基准测试，涉及8个语言条件任务，在语言引导下帮助机器人学习理解物体状态和学习连续目标的策略。

    

    在现实世界中，理解物体的连续状态对于任务学习和规划至关重要。然而，大多数任务学习基准测试假定目标状态是离散的(例如二进制状态)，这给学习复杂任务和将学习策略从模拟环境转移到现实世界带来了挑战。此外，状态离散化限制了机器人根据动作和状态的引导遵循人类指令的能力。为了解决这些挑战，我们提出了ARNOLD，这是一个评估基于语言引导、具有连续状态的现实3D场景任务学习的基准测试。ARNOLD由8个语言条件任务组成，涉及理解物体状态和学习连续目标的策略。为了促进语言引导学习，我们提供了模板生成的语言描述的专家演示。我们通过使用最新的语言条件策略学习模型来评估任务的性能。我们的结果表明，ARNOLD为基于连续状态的语言引导任务学习提供了一个具有挑战性的环境，并可用于评估从模拟场景到现实世界的学习策略的泛化。

    Understanding the continuous states of objects is essential for task learning and planning in the real world. However, most existing task learning benchmarks assume discrete(e.g., binary) object goal states, which poses challenges for the learning of complex tasks and transferring learned policy from simulated environments to the real world. Furthermore, state discretization limits a robot's ability to follow human instructions based on the grounding of actions and states. To tackle these challenges, we present ARNOLD, a benchmark that evaluates language-grounded task learning with continuous states in realistic 3D scenes. ARNOLD is comprised of 8 language-conditioned tasks that involve understanding object states and learning policies for continuous goals. To promote language-instructed learning, we provide expert demonstrations with template-generated language descriptions. We assess task performance by utilizing the latest language-conditioned policy learning models. Our results ind
    
[^63]: 大型语言模型综述

    A Survey of Large Language Models. (arXiv:2303.18223v1 [cs.CL])

    [http://arxiv.org/abs/2303.18223](http://arxiv.org/abs/2303.18223)

    本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。

    

    语言本质上是一个由语法规则控制的复杂精细的人类表达系统，对于开发理解和掌握语言的能力的AI算法来说是一项重大挑战。作为主要方法之一，语言建模在过去二十年里广泛研究用于语言理解和生成，从统计语言模型演化为神经语言模型。最近，通过在大规模语料库上预训练Transformer模型，提出了预训练语言模型（PLMs），在解决各种NLP任务方面显示出强大的能力。由于研究人员发现模型缩放可以导致性能改进，他们进一步通过增加模型规模来研究缩放效应，有趣的是，当参数规模超过一定水平时，这些扩大的语言模型不仅可以实现显着的性能提升，而且还显示出一些小规模语言模型所没有的特殊能力。

    Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale langu
    
[^64]: 语言作为潜在序列：用于半监督释义生成的深度潜变量模型

    Language as a Latent Sequence: deep latent variable models for semi-supervised paraphrase generation. (arXiv:2301.02275v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.02275](http://arxiv.org/abs/2301.02275)

    本文提出了用于半监督释义生成的深度潜变量模型，通过将未标记数据的缺失目标对建模为潜在释义序列，并结合双向学习和改进的权重初始化方案进行训练，实验结果表明这个模型在性能上与最先进的有监督基线模型有竞争力。

    

    本文探讨了用于半监督释义生成的深度潜变量模型，其中未标记数据的缺失目标对被建模为潜在释义序列。我们提出了一种名为变分序列自编码重构（VSAR）的新型无监督模型，该模型可在给定观察文本的情况下进行潜在序列推断。为了利用文本对的信息，我们还引入了一种名为双向学习（DDL）的新型监督模型，该模型旨在与我们提出的VSAR模型结合使用。将VSAR与DDL（DDL+VSAR）结合起来使我们能够进行半监督学习。然而，组合模型存在冷启动问题。为了进一步解决这个问题，我们提出了一种改进的权重初始化解决方案，从而导致一个名为知识增强学习（KRL）的新型两阶段训练方案。我们的实证评估表明，组合模型在性能上与最先进的有监督基线模型竞争力持平。

    This paper explores deep latent variable models for semi-supervised paraphrase generation, where the missing target pair for unlabelled data is modelled as a latent paraphrase sequence. We present a novel unsupervised model named variational sequence auto-encoding reconstruction (VSAR), which performs latent sequence inference given an observed text. To leverage information from text pairs, we additionally introduce a novel supervised model we call dual directional learning (DDL), which is designed to integrate with our proposed VSAR model. Combining VSAR with DDL (DDL+VSAR) enables us to conduct semi-supervised learning. Still, the combined model suffers from a cold-start problem. To further combat this issue, we propose an improved weight initialisation solution, leading to a novel two-stage training scheme we call knowledge-reinforced-learning (KRL). Our empirical evaluations suggest that the combined model yields competitive performance against the state-of-the-art supervised basel
    
[^65]: 评估人机语言模型交互

    Evaluating Human-Language Model Interaction. (arXiv:2212.09746v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09746](http://arxiv.org/abs/2212.09746)

    为了评估人机交互，研究人员开发了一个框架HALIE，该框架捕捉了交互过程、主观体验和偏好概念，并设计了五个任务来涵盖不同形式的交互。

    

    许多语言模型（LM）的实际应用，例如写作辅助和代码自动完成，涉及到人机交互。然而，大多数基准测试都是非交互式的，模型在没有人类参与的情况下产生输出。为了评估人机交互，我们开发了一个新的框架，人机语言交互评估（HALIE），该框架定义了交互式系统的组成部分和设计评估指标时要考虑的维度。与标准的非交互式评估相比，HALIE捕捉到了（i）交互过程，而不仅仅是最终输出；（ii）第一人称主观体验，而不仅仅是第三方评估；（iii）除了质量之外的偏好概念（例如享受和所有权）。然后，我们设计了五个任务，涵盖不同形式的交互：社交对话、问答、填字游戏、摘要和隐喻生成。使用四个最先进的LM（OpenAI的GPT-3的三个变体和AI21 Labs的Jurass）

    Many real-world applications of language models (LMs), such as writing assistance and code autocomplete, involve human-LM interaction. However, most benchmarks are non-interactive in that a model produces output without human involvement. To evaluate human-LM interaction, we develop a new framework, Human-AI Language-based Interaction Evaluation (HALIE), that defines the components of interactive systems and dimensions to consider when designing evaluation metrics. Compared to standard, non-interactive evaluation, HALIE captures (i) the interactive process, not only the final output; (ii) the first-person subjective experience, not just a third-party assessment; and (iii) notions of preference beyond quality (e.g., enjoyment and ownership). We then design five tasks to cover different forms of interaction: social dialogue, question answering, crossword puzzles, summarization, and metaphor generation. With four state-of-the-art LMs (three variants of OpenAI's GPT-3 and AI21 Labs' Jurass
    
[^66]: 文字对话中的深度情感识别：一项调研

    Deep Emotion Recognition in Textual Conversations: A Survey. (arXiv:2211.09172v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.09172](http://arxiv.org/abs/2211.09172)

    本调研针对对话中的情感识别进行了探讨，介绍了涉及此任务的挑战和机遇，以及描述了情感分类法和使用该分类法的基准数据集。调研总结了最重要的作品和所使用的深度学习架构，并提供了建议性的情感识别实践，以实现更好的框架。

    

    虽然近年来对话中的情感识别取得了巨大的进展，但新的应用和实施场景带来了新的挑战和机遇。这些挑战包括利用对话语境、说话人和情感动态建模，解释常识表达、非正式语言和讽刺，应对实时情感识别的挑战，识别情感原因，不同数据集中的多种分类法，多语言情感识别以及解释性。本调研首先介绍了情感识别在对话中的应用，详细说明了与此任务相关的挑战和机遇。然后，它介绍了情感分类法和多种使用该分类法的情感识别基准数据集的描述。接下来，它描述了情感识别中最重要的作品，并解释了所使用的深度学习架构。最后，它提供了对于更好的框架的建议性情感识别实践，详细说明了处理主观性的方法。

    While Emotion Recognition in Conversations (ERC) has seen a tremendous advancement in the last few years, new applications and implementation scenarios present novel challenges and opportunities. These range from leveraging the conversational context, speaker and emotion dynamics modelling, to interpreting common sense expressions, informal language and sarcasm, addressing challenges of real time ERC, recognizing emotion causes, different taxonomies across datasets, multilingual ERC to interpretability. This survey starts by introducing ERC, elaborating on the challenges and opportunities pertaining to this task. It proceeds with a description of the emotion taxonomies and a variety of ERC benchmark datasets employing such taxonomies. This is followed by descriptions of the most prominent works in ERC with explanations of the Deep Learning architectures employed. Then, it provides advisable ERC practices towards better frameworks, elaborating on methods to deal with subjectivity in ann
    
[^67]: 发现、解释、改进：一种用于自然语言处理的自动片段检测框架

    Discover, Explanation, Improvement: An Automatic Slice Detection Framework for Natural Language Processing. (arXiv:2211.04476v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.04476](http://arxiv.org/abs/2211.04476)

    本研究提出了一个自动片段检测框架用于自然语言处理任务，通过发现、解释和改进模型的错误，提供了对模型行为的理解和未来模型设计的见解。

    

    预训练的自然语言处理（NLP）模型取得了高整体性能，但仍然存在系统性的错误。与手动错误分析不同，对于自动识别表现不佳的数据组的片段检测模型（SDM）的研究，在计算机视觉领域引起了广泛关注，可以理解模型行为并为未来模型训练和设计提供见解。然而，在NLP任务上，对SDM的研究和其有效性的定量评估还很少。本文通过提出一个名为“Discover, Explain, Improve(DEIM)”的NLP分类任务基准和一个新的SDM模型Edisa来填补这一空白。Edisa发现了一致且表现不佳的数据组；DEIM将它们统一为人类可理解的概念，并提供了全面的评估任务和相应的定量指标。在DEIM的评估中，结果显示Edisa能够准确选择易出错的数据点，并提供了有用的信息。

    Pretrained natural language processing (NLP) models have achieved high overall performance, but they still make systematic errors. Instead of manual error analysis, research on slice detection models (SDM), which automatically identify underperforming groups of datapoints, has caught escalated attention in Computer Vision for both understanding model behaviors and providing insights for future model training and designing. However, little research on SDM and quantitative evaluation of their effectiveness have been conducted on NLP tasks. Our paper fills the gap by proposing a benchmark named "Discover, Explain, Improve (DEIM)" for classification NLP tasks along with a new SDM Edisa. Edisa discovers coherent and underperforming groups of datapoints; DEIM then unites them under human-understandable concepts and provides comprehensive evaluation tasks and corresponding quantitative metrics. The evaluation in DEIM shows that Edisa can accurately select error-prone datapoints with informati
    
[^68]: 防止神经语言模型的逐字记忆会产生虚假隐私保护感

    Preventing Verbatim Memorization in Language Models Gives a False Sense of Privacy. (arXiv:2210.17546v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.17546](http://arxiv.org/abs/2210.17546)

    防止神经语言模型逐字记忆无法真正保护隐私，本文设计的布隆过滤器虽然防止了所有逐字记忆，但仍然无法防止训练数据泄露，容易被合理修改的“样式转换”提示绕过。

    

    通过研究神经语言模型中数据记忆的现象，本研究帮助我们理解与隐私或版权相关的风险，并有助于评估对策。然而逐字记忆定义过于严格，未能捕捉更为微妙的记忆形式。本文基于布隆过滤器设计并实现了一种有效的防御方法，但该“完美”过滤器并不能防止训练数据泄露。

    Studying data memorization in neural language models helps us understand the risks (e.g., to privacy or copyright) associated with models regurgitating training data, and aids in the evaluation of potential countermeasures. Many prior works -- and some recently deployed defenses -- focus on "verbatim memorization", defined as a model generation that exactly matches a substring from the training set. We argue that verbatim memorization definitions are too restrictive and fail to capture more subtle forms of memorization. Specifically, we design and implement an efficient defense based on Bloom filters that perfectly prevents all verbatim memorization. And yet, we demonstrate that this "perfect" filter does not prevent the leakage of training data. Indeed, it is easily circumvented by plausible and minimally modified "style-transfer" prompts -- and in some cases even the non-modified original prompts -- to extract memorized information. For example, instructing the model to output ALL-CA
    
[^69]: 我们能了解甚至无法想象的事物吗？

    What can we know about that which we cannot even imagine?. (arXiv:2208.03886v3 [physics.hist-ph] UPDATED)

    [http://arxiv.org/abs/2208.03886](http://arxiv.org/abs/2208.03886)

    这篇文章探讨了关于智能、人类语言和人类数学的问题，强调了人类语言的局限性，以及我们能否对我们无法想象的事物有任何了解。

    

    在这篇文章中，我将考虑一系列问题。首先，这些问题涉及到智能的生物学功能，特别是人类智能的认知义肢。这将引出关于人类语言的问题，也许是人类迄今为止开发的最重要的认知义肢。虽然传统上对人类语言所包含的认知能力进行赞美，但我将强调人类语言多么有限，因此我们的认知能力也是有限的，尽管语言对其进行了增强。这将引出关于人类数学的问题，因为它最终是以人类语言的形式来表述的，所以也存在深层次的限制。然后，我将结合这些问题，对这篇文章的核心问题提出一个部分性的、有点侧面的答案：我们能够对我们甚至无法构想的事物有何了解？

    In this essay I will consider a sequence of questions. The first questions concern the biological function of intelligence in general, and cognitive prostheses of human intelligence in particular. These will lead into questions concerning human language, perhaps the most important cognitive prosthesis humanity has ever developed. While it is traditional to rhapsodize about the cognitive power encapsulated in human language, I will emphasize how horribly limited human language is -- and therefore how limited our cognitive abilities are, despite their being augmented with language. This will lead to questions of whether human mathematics, being ultimately formulated in terms of human language, is also deeply limited. I will then combine these questions to pose a partial, sort-of, sideways answer to the guiding concern of this essay: what we can ever discern about that we cannot even conceive?
    
[^70]: 从计算机视觉系统的表现预测儿童的词语学习

    Predicting Word Learning in Children from the Performance of Computer Vision Systems. (arXiv:2207.09847v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2207.09847](http://arxiv.org/abs/2207.09847)

    通过使用计算机视觉系统的表现作为预测儿童词语学习的难度的代理，我们发现儿童获得不同类别的词语的年龄与视觉分类和字幕系统的表现有关。这些模型捕捉到了词语与视觉现象之间的关系。

    

    对于儿童和机器学习系统来说，学习一个词最关键的挑战是将该词与描述的视觉现象联系起来。我们通过使用计算机视觉系统的表现作为从视觉线索学习一个词的难度的代理来探究词语学习的这个方面。我们发现儿童获得不同类别的词语的年龄与视觉分类和字幕系统的表现相关，超出了词语频率预期效应。计算机视觉系统的表现与词语的具体性的人类判断相关，而具体性又是儿童词语学习的预测因素，这表明这些模型捕捉到了词语与视觉现象之间的关系。

    For human children as well as machine learning systems, a key challenge in learning a word is linking the word to the visual phenomena it describes. We explore this aspect of word learning by using the performance of computer vision systems as a proxy for the difficulty of learning a word from visual cues. We show that the age at which children acquire different categories of words is correlated with the performance of visual classification and captioning systems, over and above the expected effects of word frequency. The performance of the computer vision systems is correlated with human judgments of the concreteness of words, which are in turn a predictor of children's word learning, suggesting that these models are capturing the relationship between words and visual phenomena.
    
[^71]: 知识增强预训练模型综述

    A Survey of Knowledge Enhanced Pre-trained Models. (arXiv:2110.00269v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2110.00269](http://arxiv.org/abs/2110.00269)

    本综述提供了关于NLP中知识增强预训练语言模型的综合概述，讨论了预训练语言模型和知识表示学习的进展，并从三个不同的角度对现有的KEPLMs进行了分类，最后概述了未来研究中KEPLMs的潜在方向。

    

    预训练语言模型通过自监督学习在大规模文本语料库上学习了信息丰富的词表示，在细调之后在自然语言处理领域取得了有希望的性能。然而，这些模型存在鲁棒性差和可解释性不足的问题。我们将注入知识的预训练语言模型称为知识增强预训练语言模型(KEPLMs)。这些模型表现出深入理解和逻辑推理，并引入了可解释性。在本综述中，我们提供了关于NLP中KEPLMs的综合概述。我们首先讨论了预训练语言模型和知识表示学习的进展。然后，我们从三个不同的角度系统地分类了现有的KEPLMs。最后，我们概述了一些未来研究中KEPLMs的潜在方向。

    Pre-trained language models learn informative word representations on a large-scale text corpus through self-supervised learning, which has achieved promising performance in fields of natural language processing (NLP) after fine-tuning. These models, however, suffer from poor robustness and lack of interpretability. We refer to pre-trained language models with knowledge injection as knowledge-enhanced pre-trained language models (KEPLMs). These models demonstrate deep understanding and logical reasoning and introduce interpretability. In this survey, we provide a comprehensive overview of KEPLMs in NLP. We first discuss the advancements in pre-trained language models and knowledge representation learning. Then we systematically categorize existing KEPLMs from three different perspectives. Finally, we outline some potential directions of KEPLMs for future research.
    
[^72]: 《深度神经网络能否通过列名预测数据相关性?》

    Can Deep Neural Networks Predict Data Correlations from Column Names?. (arXiv:2107.04553v2 [cs.DB] UPDATED)

    [http://arxiv.org/abs/2107.04553](http://arxiv.org/abs/2107.04553)

    本研究提出在数据库中使用自然语言分析列名以辅助调优和分析工作。通过分析Kaggle数据集创建了一个新的数据相关性分析基准，并研究了语言模型在预测相关性方面的能力。

    

    最近的研究提出使用自然语言分析数据库模式元素，以指导调优和分析工作。基本假设是，最先进的语言处理方法，即语言模型，能够从模式文本中提取有关数据属性的信息。本文在数据相关性分析的背景下考察了这一假设：通过分析列名，能否使用语言模型找到具有相关数据的列对？首先，本文引入了一个新颖的数据相关性分析基准，通过分析数千个Kaggle数据集创建(可下载)。其次，它利用该数据来研究语言模型根据列名预测相关性的能力。分析涵盖了不同的语言模型、各种相关性度量指标以及众多准确度指标。它确定了导致成功预测的因素，如列名长度和单词比例等。

    Recent publications suggest using natural language analysis on database schema elements to guide tuning and profiling efforts. The underlying hypothesis is that state-of-the-art language processing methods, so-called language models, are able to extract information on data properties from schema text.  This paper examines that hypothesis in the context of data correlation analysis: is it possible to find column pairs with correlated data by analyzing their names via language models? First, the paper introduces a novel benchmark for data correlation analysis, created by analyzing thousands of Kaggle data sets (and available for download). Second, it uses that data to study the ability of language models to predict correlation, based on column names. The analysis covers different language models, various correlation metrics, and a multitude of accuracy metrics. It pinpoints factors that contribute to successful predictions, such as the length of column names as well as the ratio of words
    
[^73]: 新闻偏见检测的200,000+句子：NewB数据集

    NewB: 200,000+ Sentences for Political Bias Detection. (arXiv:2006.03051v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2006.03051](http://arxiv.org/abs/2006.03051)

    NewB数据集是一个包含来自11个新闻来源对唐纳德·特朗普的200,000多个句子的文本语料库，通过训练深度学习模型预测句子的新闻来源，得到比传统分类系统更准确的结果，对媒体对特朗普的描绘进行了深入分析。

    

    我们介绍了Newspaper Bias Dataset (NewB)，这是一个包含来自11个新闻来源关于唐纳德·特朗普的200,000多个句子的文本语料库。与以前的数据集将句子标记为自由派或保守派不同，NewB涵盖了11家热门媒体源的政治观点，捕捉到比传统的二元分类系统更细致的政治观点。我们训练了两个最先进的深度学习模型，以预测给定句子的新闻来源，结果发现一个循环神经网络的top-1、top-3和top-5准确率分别为33.3%、61.4%和77.6%，明显优于基准逻辑回归模型的准确率分别为18.3%、42.6%和60.8%。利用句子的新闻来源标签，我们使用模型分析了前n个词组，以深入了解媒体来源对特朗普的描绘。我们希望我们数据集的公开发布能鼓励进一步研究自然语言处理的应用。

    We present the Newspaper Bias Dataset (NewB), a text corpus of more than 200,000 sentences from eleven news sources regarding Donald Trump. While previous datasets have labeled sentences as either liberal or conservative, NewB covers the political views of eleven popular media sources, capturing more nuanced political viewpoints than a traditional binary classification system does. We train two state-of-the-art deep learning models to predict the news source of a given sentence from eleven newspapers and find that a recurrent neural network achieved top-1, top-3, and top-5 accuracies of 33.3%, 61.4%, and 77.6%, respectively, significantly outperforming a baseline logistic regression model's accuracies of 18.3%, 42.6%, and 60.8%. Using the news source label of sentences, we analyze the top n-grams with our model to gain meaningful insight into the portrayal of Trump by media sources.We hope that the public release of our dataset will encourage further research in using natural language 
    
[^74]: 人们对COVID-19有哪些问题？一个问题分类数据集

    What Are People Asking About COVID-19? A Question Classification Dataset. (arXiv:2005.12522v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2005.12522](http://arxiv.org/abs/2005.12522)

    COVID-Q是一个包含1,690个关于COVID-19的问题的数据集，可以帮助我们对这些问题进行分类和聚类，并为开发应用系统或进行模型评估提供领域特定资源。

    

    我们介绍了COVID-Q，这是一个包含来自13个来源的1,690个关于COVID-19的问题集合。我们将这些问题分为15个问题类别和207个问题聚类。在我们的数据集中，最常见的问题涉及COVID的传播、预防和社会影响。我们发现，许多在多个来源中出现的问题未被任何可靠机构（如CDC和FDA）的FAQ网站回答。我们在https://github.com/JerryWeiAI/COVID-Q上公开了我们的数据集。对于将问题分类为15个类别，当每个类别训练20个样本时，BERT基准模型的准确率为58.1%。对于问题聚类任务，使用BERT+SiamLoss基准模型的准确率为49.5%。我们希望COVID-Q能够直接用于开发实际系统或作为领域特定资源进行模型评估。

    We present COVID-Q, a set of 1,690 questions about COVID-19 from 13 sources, which we annotate into 15 question categories and 207 question clusters. The most common questions in our dataset asked about transmission, prevention, and societal effects of COVID, and we found that many questions that appeared in multiple sources were not answered by any FAQ websites of reputable organizations such as the CDC and FDA. We post our dataset publicly at https://github.com/JerryWeiAI/COVID-Q. For classifying questions into 15 categories, a BERT baseline scored 58.1% accuracy when trained on 20 examples per category, and for a question clustering task, a BERT + triplet loss baseline achieved 49.5% accuracy. We hope COVID-Q can help either for direct use in developing applied systems or as a domain-specific resource for model evaluation.
    
[^75]: 一个统一的双线性LSTM框架

    A Unifying Framework of Bilinear LSTMs. (arXiv:1910.10294v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1910.10294](http://arxiv.org/abs/1910.10294)

    本文提出了一个统一的双线性LSTM框架，通过平衡线性和双线性项的表达能力，实现了对序列数据集中输入特征的非线性交互的利用，以实现更好的性能，同时不增加更多的学习参数。

    

    本文提出了一个新颖的统一双线性LSTM框架，可以表示和利用序列数据集中输入特征的非线性交互，以实现比线性LSTM更好的性能，同时不会增加更多需要学习的参数。为了实现这一点，我们的统一框架允许通过调整隐藏状态向量的大小与双线性项中权重矩阵的逼近质量之间的权衡来平衡线性和双线性项的表达能力，从而优化我们的双线性LSTM的性能，同时不会增加更多需要学习的参数。我们在几个基于语言的序列学习任务中对我们的双线性LSTM的性能进行了实证评估，以展示其普适性。

    This paper presents a novel unifying framework of bilinear LSTMs that can represent and utilize the nonlinear interaction of the input features present in sequence datasets for achieving superior performance over a linear LSTM and yet not incur more parameters to be learned. To realize this, our unifying framework allows the expressivity of the linear vs. bilinear terms to be balanced by correspondingly trading off between the hidden state vector size vs. approximation quality of the weight matrix in the bilinear term so as to optimize the performance of our bilinear LSTM, while not incurring more parameters to be learned. We empirically evaluate the performance of our bilinear LSTM in several language-based sequence learning tasks to demonstrate its general applicability.
    

