# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Prompt- and Trait Relation-aware Cross-prompt Essay Trait Scoring.](http://arxiv.org/abs/2305.16826) | 本研究提出了一种跨Prompt的作文Trait评分模型，通过作文提示关注和Traint相似性loss，有效解决了作文提示不同的问题，提高了自动化作文评分的准确性和可靠性。 |
| [^2] | [Domain Aligned Prefix Averaging for Domain Generalization in Abstractive Summarization.](http://arxiv.org/abs/2305.16820) | 本文提出了一种轻量级、基于加权平均的领域对齐前缀平均方法（DAPA），用于抽象摘要中的领域泛化，实现了有效的源域扩展以提高性能。 |
| [^3] | [With a Little Push, NLI Models can Robustly and Efficiently Predict Faithfulness.](http://arxiv.org/abs/2305.16819) | 本文证明，在任务自适应数据增强与稳健的推理过程相结合下，纯NLI模型可以胜过更复杂的度量方法。 |
| [^4] | [Songs Across Borders: Singable and Controllable Neural Lyric Translation.](http://arxiv.org/abs/2305.16816) | 本文提出了一种可唱和可控的神经歌词翻译方法，通过将歌词翻译形式化为受约束的翻译问题，将翻译学文献中的理论指导和实际技术转化为驱动的NMT方法，实现了英汉歌词翻译系统，并在长度准确性、韵律准确性和单词边界召回率上得到优秀的成绩，相比朴素的微调能够显著提高翻译质量。 |
| [^5] | [Improved Visual Story Generation with Adaptive Context Modeling.](http://arxiv.org/abs/2305.16811) | 这篇论文提出了一种简单的方法，使用自适应上下文建模改进了视觉故事生成，以提高生成故事的全局一致性和生成语义一致的故事图像，并在PororoSV和FlintstonesSV数据集上实现了最佳结果。 |
| [^6] | [GenQ: Automated Question Generation to Support Caregivers While Reading Stories with Children.](http://arxiv.org/abs/2305.16809) | 本研究设计了一个智能辅导系统（GenQ），可以根据照顾者和孩子之间的对话促进孩子的阅读理解能力，并通过考虑文化背景和语境变化以提高系统效果。 |
| [^7] | [Do GPTs Produce Less Literal Translations?.](http://arxiv.org/abs/2305.16806) | 本研究比较了GPT和NMT生成翻译的文字积极度差异，发现GPT翻译更不准确，但在MT质量评估指标上表现出相似或更好的分数。 |
| [^8] | [Motion-Based Sign Language Video Summarization using Curvature and Torsion.](http://arxiv.org/abs/2305.16801) | 该论文介绍了一种基于曲率和扭矩的手语视频摘要技术，能够选出最具信息量的关键帧。 |
| [^9] | [To Revise or Not to Revise: Learning to Detect Improvable Claims for Argumentative Writing Support.](http://arxiv.org/abs/2305.16799) | 这篇论文探讨了检测辩论文本中需要改进的论点的挑战，通过学习协作编辑行为捕捉隐含的修订模式来开发指导作者改进论点的方法。 |
| [^10] | [Schema-Guided User Satisfaction Modeling for Task-Oriented Dialogues.](http://arxiv.org/abs/2305.16798) | 本文提出了一种新的基于模式的用户满意度建模框架SG-USM，它特别模拟了系统程度的满足用户关于任务属性的偏好程度，以预测用户的满意度水平。 |
| [^11] | [Calibration of Transformer-based Models for Identifying Stress and Depression in Social Media.](http://arxiv.org/abs/2305.16797) | 本文提出了第一个使用校准后的Transformer模型来检测社交媒体上的压力和抑郁症状的研究。 |
| [^12] | [Incorporating Distributions of Discourse Structure for Long Document Abstractive Summarization.](http://arxiv.org/abs/2305.16784) | 本文提出了一种名为'RSTformer'的摘要模型，该模型全面融合了话语关系类型和不确定性，并以修辞结构理论为基础，经过严格评估，表现明显优于现有的模型。 |
| [^13] | [Towards a Common Understanding of Contributing Factors for Cross-Lingual Transfer in Multilingual Language Models: A Review.](http://arxiv.org/abs/2305.16768) | 本文对多语言语言模型 (MLLMs)的跨语言转移能力的不同因素进行了调查和综述，将这些因素分成五类并提供了过去研究的经验证据。本文的工作旨在全面背景和统一MLLMs跨语言转移的现有研究流。 |
| [^14] | [Backpack Language Models.](http://arxiv.org/abs/2305.16765) | 背包语言模型是一种结合了强大的建模性能和可解释性的神经架构。它学习每个单词的多个非上下文感知向量，并将单词表示为上下文依赖的非负线性组合。感知向量可以被解释为单词不同的方面，并可以通过干预这些可解释的钩子以可预测的方式改变模型的行为。该模型在词汇相似性评估中表现优越，甚至优于一个6B参数的Transformer语言模型的单词嵌入。 |
| [^15] | [Leveraging Domain Knowledge for Inclusive and Bias-aware Humanitarian Response Entry Classification.](http://arxiv.org/abs/2305.16756) | 本研究提出了一种以人道主义本体为基础的新型语言模型HumBert，并提供了一种系统的方法来衡量和减少偏见，以实现对人道主义数据分析的有效和道德意识的支持。 |
| [^16] | [Can large language models generate salient negative statements?.](http://arxiv.org/abs/2305.16755) | 本研究探讨了大型语言模型生成真实实体的显著负面陈述的能力，在不同领域中进行了评估，结果发现大型语言模型在处理否定陈述中的事实概念上仍有困难。 |
| [^17] | [Automating the Analysis of Institutional Design in International Agreements.](http://arxiv.org/abs/2305.16750) | 本文研究了从国际协议中自动化提取正式制度设计的知识的方法，并通过对于《无形文化遗产保护公约》的测试分析了正式制度设计中参与者的可见性和重要性之间的关系。 |
| [^18] | [Parameter-Efficient Fine-Tuning without Introducing New Latency.](http://arxiv.org/abs/2305.16742) | 本文提出了一种参数高效微调的方法，以任务不可知的方式生成稀疏掩码，无需添加新参数，避免了额外的推断延迟，并超过了现有方法的效果。 |
| [^19] | [Conjunct Resolution in the Face of Verbal Omissions.](http://arxiv.org/abs/2305.16740) | 本文提出了一个直接在文本中操作的并列解析任务，并利用分割和重构范例来恢复并列结构中缺失的元素。基于实用的动词省略框架，我们整理了一份由真实语料库构成的数据集，用于评估并比较现有解析技术。 |
| [^20] | [AlignScore: Evaluating Factual Consistency with a Unified Alignment Function.](http://arxiv.org/abs/2305.16739) | 本文提出了AlignScore，一种新的综合度量标准，旨在评估各种事实不一致性情况。该方法基于两个文本片段之间的信息对齐，可以适用于不同任务的不同输入/输出。 |
| [^21] | [AMPERE: AMR-Aware Prefix for Generation-Based Event Argument Extraction Model.](http://arxiv.org/abs/2305.16734) | 本论文提出了一种名为AMPERE的方法，面向AMR的前缀生成事件论元抽取模型，该模型成功引入了AMR的信息，提升了生成式模型的性能和泛化能力。 |
| [^22] | [Emotion Experiencer Recognition as a Prerequisite for Experiencer-Specific Emotion Analysis.](http://arxiv.org/abs/2305.16731) | 本文提出了一种用于检测情感体验者并为其分配情感的自动方法，并进行了相关的实验。该方法的实现具有挑战性，但展示了在文本中检测情感体验者的可行性。 |
| [^23] | [Code-Switched Text Synthesis in Unseen Language Pairs.](http://arxiv.org/abs/2305.16724) | 本文介绍了GLOSS模型，旨在解决在缺乏训练数据的情况下合成混合代码文本的问题，并且可以推广到更广泛的语言对。该模型在四个未见过的语言对上的实验中优于其他基线模型和在单语文本上运行的生成模型。 |
| [^24] | [People and Places of Historical Europe: Bootstrapping Annotation Pipeline and a New Corpus of Named Entities in Late Medieval Texts.](http://arxiv.org/abs/2305.16718) | 该论文提出了一个新的NER语料库，从未注释的历史文本中引导注释管道，并训练了一个NER模型来识别历史文献中的人名和地名，实现了较高的精度和召回率。 |
| [^25] | [PIP: Parse-Instructed Prefix for Syntactically Controlled Paraphrase Generation.](http://arxiv.org/abs/2305.16701) | 使用Parse-Instructed Prefix的语法控制释义生成的计算成本降低了10倍，并在两个benchmark上达到了最先进的性能表现。 |
| [^26] | [DKAF: KB Arbitration for Learning Task-Oriented Dialog Systems with Dialog-KB Inconsistencies.](http://arxiv.org/abs/2305.16697) | 本文提出了一个对话-KB仲裁框架（DKAF），可以预测每个训练对话的当代KB快照从而减少对话-KB不一致性。并且，在新建立的基准测试中，实验结果表明DKAF方法优于现有基线，并提高了TOD代理的鲁棒性。 |
| [^27] | [Multiview Identifiers Enhanced Generative Retrieval.](http://arxiv.org/abs/2305.16675) | 该论文提出了一种新型的基于合成标识符的多视角标识符来增强生成式检索，从而提高了检索结果的准确性和多样性。 |
| [^28] | [Score-balanced Loss for Multi-aspect Pronunciation Assessment.](http://arxiv.org/abs/2305.16664) | 本文提出了一种分数平衡损失函数，该损失函数可以解决自动发音评估领域中极度不平衡的数据标签问题，该方法通过重新加权的方式，有效地对稀疏分数预测进行正面反馈。 |
| [^29] | [GDA: Generative Data Augmentation Techniques for Relation Extraction Tasks.](http://arxiv.org/abs/2305.16663) | GDA是一个专门用于关系文本增强的技术，通过采用两个互补模块，保持语义和语法结构的一致性，并使用实体提示扩展上下文。实验结果表明GDA超越了现有增强技术，实现了最先进的性能。 |
| [^30] | [AdaPlanner: Adaptive Planning from Feedback with Language Models.](http://arxiv.org/abs/2305.16653) | LLM代理可以通过Adaplanner自适应改进自己的计划以应对环境反馈，为此提出计划内外的改进策略以及代码风格的LLM提示结构和技能发现机制。 |
| [^31] | [TADA: Task-Agnostic Dialect Adapters for English.](http://arxiv.org/abs/2305.16651) | 本论文提出了一种简单而有效的方法，即任务不可知方言适配器（TADA），通过使用适配器对齐非标准美式英语方言，并将它们与标准美式英语的任务特定适配器组合，从而实现了任务不可知的方言适应，提高了方言英语NLP的广泛可扩展性。 |
| [^32] | [Dramatic Conversation Disentanglement.](http://arxiv.org/abs/2305.16648) | 本文提出了一个用于研究电影和电视剧中语用模式的新数据集，并比较了几种梳理模型的性能，结果表明由女演员扮演的角色虽然少见，但它们更容易启动新的对话线索。 |
| [^33] | [Language Models Can Improve Event Prediction by Few-Shot Abductive Reasoning.](http://arxiv.org/abs/2305.16646) | 本文提出了一个建模和预测框架，在少样本情况下使用语言模型的绝对推理能力来提高事件序列模型的预测精度，经过实验证实可以明显优于最先进的事件序列模型。 |
| [^34] | [Are Fairy Tales Fair? Analyzing Gender Bias in Temporal Narrative Event Chains of Children's Fairy Tales.](http://arxiv.org/abs/2305.16641) | 本论文提出了一种计算机分析方法，通过事件叙述结构自动分析童话的社会偏见，为分析提供动词事件注释方案，并以性别为例进行了案例研究。 |
| [^35] | [Adversarial Multi-task Learning for End-to-end Metaphor Detection.](http://arxiv.org/abs/2305.16638) | 本文提出了一个对抗多任务学习框架，将基本意义鉴别的知识转移到隐喻检测中，缓解了数据稀缺问题，并在四个公共数据集上取得了竞争性的结果。 |
| [^36] | [DataFinder: Scientific Dataset Recommendation from Natural Language Descriptions.](http://arxiv.org/abs/2305.16636) | DataFinder能够根据自然语言描述推荐相关数据集，解决科学家在现有数据集中寻找合适数据集的困难。 |
| [^37] | [Zero is Not Hero Yet: Benchmarking Zero-Shot Performance of LLMs for Financial Tasks.](http://arxiv.org/abs/2305.16633) | 研究比较了零基础LLM和RoBERTa在金融领域的性能表现，发现即使没有标记数据，ChatGPT的表现也很好，但微调后的模型通常表现更好，使用生成模型进行数据注释可能耗时 |
| [^38] | [Evaluation of Question Generation Needs More References.](http://arxiv.org/abs/2305.16626) | 评估QG方法需要更多的参考文献来提高其有效性，单个参考不足以全面评估其潜力。使用多个参考文献的评估方法可以更好地与人类评估相关联。 |
| [^39] | [Bridging the Domain Gaps in Context Representations for k-Nearest Neighbor Neural Machine Translation.](http://arxiv.org/abs/2305.16599) | 本文提出了一种新的方法，可以通过重建原始数据存储库来提高kNN-MT的向下数据检索，解决了上游和下游领域之间的显着差距问题。 |
| [^40] | [NormMark: A Weakly Supervised Markov Model for Socio-cultural Norm Discovery.](http://arxiv.org/abs/2305.16598) | 本文提出了一种使用马尔可夫模型发现社会文化规范的方法，该方法可以在对话的整个过程中捕获隐含特征并提高规范识别的效果。 |
| [^41] | [Neural Architecture Search for Parameter-Efficient Fine-tuning of Large Pre-trained Language Models.](http://arxiv.org/abs/2305.16597) | 本文提出了一种基于神经架构搜索的参数高效微调大型预训练语言模型的方法，通过结构化和非结构化剪枝学习PET结构并在GLUE上进行实验验证，展示了该算法的有效性，探讨了PET架构设计选择对实际性能的影响。 |
| [^42] | [ParaAMR: A Large-Scale Syntactically Diverse Paraphrase Dataset by AMR Back-Translation.](http://arxiv.org/abs/2305.16585) | ParaAMR是一个基于AMR反向翻译创建的大规模语法多样化释义数据集，相比现有的大规模释义数据集在语法上更具多样性，可用于提升自然语言处理任务的性能，包括学习句子嵌入向量、语法控制的释义生成和机器翻译的数据增强。 |
| [^43] | [Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.](http://arxiv.org/abs/2305.16582) | 通过将人类思维过程建模成图形结构，我们提出了“思维图”（GoT）推理辅助大语言模型（LLMs）来完成更加真实的、复杂的思维任务。 |
| [^44] | [An Investigation of Noise in Morphological Inflection.](http://arxiv.org/abs/2305.16581) | 该研究调查了语态变化中噪声的不同类型，并探索了它们对非监督形态学范式完成和语态变化系统的影响。实验发现编码器解码器比复制偏差的模型更为稳健，CMLM预训练可提高transformer模型的稳定性。 |
| [^45] | [NLP Reproducibility For All: Understanding Experiences of Beginners.](http://arxiv.org/abs/2305.16579) | 通过对93名NLP初学者的调查，发现研究作者提供完整文档、更好的代码实践和更易于获取的数据文件是初学者成功复现最近NLP论文结果的关键，建议NLP研究人员注重这些方面，更好地支持初学者。 |
| [^46] | [Nichelle and Nancy: The Influence of Demographic Attributes and Tokenization Length on First Name Biases.](http://arxiv.org/abs/2305.16577) | 本文研究了人口属性和标记长度对社交常识推理模型的影响，发现名字的人口属性和名字标记化长度都是影响社交常识推理模型行为的系统性因素。 |
| [^47] | [Counterfactual reasoning: Testing language models' understanding of hypothetical scenarios.](http://arxiv.org/abs/2305.16572) | 本文通过反事实条件测试了五个预先训练的语言模型的能力，发现这些模型通常能够在反事实情景中覆盖真实世界的知识，但这种效应通常由简单的词汇线索驱动。 |
| [^48] | [Teamwork Is Not Always Good: An Empirical Study of Classifier Drift in Class-incremental Information Extraction.](http://arxiv.org/abs/2305.16559) | 本论文研究了类增量信息提取中分类器漂移如何导致遗忘的问题，并提出了四种解决方案来缓解分类器漂移。 |
| [^49] | [Annotating and Detecting Fine-grained Factual Errors for Dialogue Summarization.](http://arxiv.org/abs/2305.16548) | 本论文提出第一个注释有细粒度事实错误的对话摘要数据集，探索了细粒度事实错误检测作为一个句子级多标签分类问题的挑战，并提出了一种无监督模型，取得了和 SOTA 模型相近的效果。 |
| [^50] | [Label Agnostic Pre-training for Zero-shot Text Classification.](http://arxiv.org/abs/2305.16521) | 本文旨在探究改进预训练语言模型的泛化能力，提高其在零样本情境下的文本分类表现。通过引入隐式和显式预训练策略，注入方面级别的理解，以建立任务层次的表示。 |
| [^51] | [The Dangers of trusting Stochastic Parrots: Faithfulness and Trust in Open-domain Conversational Question Answering.](http://arxiv.org/abs/2305.16519) | 本文研究表明，具备某些高级语言对话行为（如重复用户所说的话）的任务型系统更受欢迎、更值得信任，然而那些一味模仿用户输入的系统却存在诸多不忠实响应的风险。 |
| [^52] | [On the Tool Manipulation Capability of Open-source Large Language Models.](http://arxiv.org/abs/2305.16504) | 本研究探讨了如何通过训练使用示例、上下文演示和生成样式规则来加强开源LLMs以达到与封闭型API的工具操作性能同等甚至更优的效果，并通过ToolBench测试得出了实验结果，同时本文还证明了改进的开源LLMs的鲁棒性。 |
| [^53] | [Prototype-Based Interpretability for Legal Citation Prediction.](http://arxiv.org/abs/2305.16490) | 本论文提出了一种基于样例的法律引文预测方法，结合先例和立法规定思维过程，并引入原型架构增加可解释性，该方法在实现强大性能的同时，考虑了高风险任务在实际社会影响中的重要考虑因素。 |
| [^54] | [Measuring the Effect of Influential Messages on Varying Personas.](http://arxiv.org/abs/2305.16470) | 研究了评估不同群体对影响力信息的反应的任务和所创建的数据集，突出了新任务在建模中引入了个性化，预测了每个反应的情感极性和强度，并让评估和应用更加可靠。 |
| [^55] | [Don't Retrain, Just Rewrite: Countering Adversarial Perturbations by Rewriting Text.](http://arxiv.org/abs/2305.16444) | 本文提出了ATINTER模型，该模型可以重写对抗性输入以使其对于下游文本分类器来说不具有对抗性，在多个数据集和攻击机制的实验中证明了其比现有防御方法更有效，且不会牺牲任务准确性 |
| [^56] | [Neural Machine Translation for Mathematical Formulae.](http://arxiv.org/abs/2305.16433) | 这篇论文解决了神经机器翻译数学公式时面临的词汇量较小、符号序列较长和需要高度精度的问题，并通过使用卷积序列到序列网络实现了较高的准确度。 |
| [^57] | [Not wacky vs. definitely wacky: A study of scalar adverbs in pretrained language models.](http://arxiv.org/abs/2305.16426) | 本文通过研究标量副词，探究了预训练语言模型中“绝对”与“相对”词的表现，在涉及逻辑推理的NLP应用中面临挑战。 |
| [^58] | [Counterfactual Probing for the influence of affect and specificity on Intergroup Bias.](http://arxiv.org/abs/2305.16409) | 本文研究了特异性和情感两个语用特征在不同群体背景下是否会出现系统性变化，并将其与自然语言输出中的新群体偏见框架相联系。初步分析表明，推文的特异性和情感程度与监督的群体关系标签之间存在一定的相关性，而因果推断揭示了神经模型在分类时可靠地使用情感，但其对特异性的使用是不确定的。 |
| [^59] | [Script Normalization for Unconventional Writing of Under-Resourced Languages in Bilingual Communities.](http://arxiv.org/abs/2305.16407) | 本研究解决了在双语社区中非常规母语书写的脚本标准化问题，使用合成数据和transformer-based模型，并表明这种标准化也能提高下游任务的性能。 |
| [^60] | [Context-Aware Attention Layers coupled with Optimal Transport Domain Adaptation methods for recognizing dementia from spontaneous speech.](http://arxiv.org/abs/2305.16406) | 本论文提出一种基于情境感知注意力层及最优传输域自适应方法的语音识别痴呆症的新方法。该方法捕捉了模态内部和模态间的交互，并实现了模型校准。 |
| [^61] | [Are Diffusion Models Vision-And-Language Reasoners?.](http://arxiv.org/abs/2305.16397) | 本文针对扩散-语言图像生成模型进行转换和评估，介绍了生成-鉴别评估基准(GDBench)基于7个视觉语言复杂任务，并发现转换后的模型在组合性任务方面的表现优于CLIP，通过微调可提高其组合性能。 |
| [^62] | [Scan and Snap: Understanding Training Dynamics and Token Composition in 1-layer Transformer.](http://arxiv.org/abs/2305.16380) | 本文分析了1层Transformer在下一个标记预测任务中的SGD训练动态，证明了自我关注层充当了“区分性扫描算法”，从而逐步关注到相关标记并排除不相关的标记，总结相关信息在编码表示中。同时研究了标记频率、上下文和初始化自我关注层等对Transformer性能的影响。 |
| [^63] | [Role-Play with Large Language Models.](http://arxiv.org/abs/2305.16367) | 本文将对话代理行为描述为角色扮演，以避免赋予其人类特征，在此基础上研究代理行为中的欺骗和自我意识。 |
| [^64] | [Decomposing the Enigma: Subgoal-based Demonstration Learning for Formal Theorem Proving.](http://arxiv.org/abs/2305.16366) | 本文提出了一个基于子目标的演示学习框架，通过将基于子目标的学习方法与扩散模型相结合，提高演示的可理解性，并提高LLMs在形式定理证明中的吞吐量。 |
| [^65] | [EDM3: Event Detection as Multi-task Text Generation.](http://arxiv.org/abs/2305.16357) | EDM3是一种新颖的事件检测方法，可以同时执行事件检测及其子任务，减少了误差传播。与先前基于数据集或特定领域的方法不同，EDM3利用现有语言模型的知识进行训练，在多个事件检测数据集上性能表现优异。 |
| [^66] | [PandaGPT: One Model To Instruction-Follow Them All.](http://arxiv.org/abs/2305.16355) | PandaGPT是一种能够同时接受多模态输入，并用于生成复杂任务输出的可学习语言模型。 |
| [^67] | [Betray Oneself: A Novel Audio DeepFake Detection Model via Mono-to-Stereo Conversion.](http://arxiv.org/abs/2305.16353) | 本文提出了一种名为M2S-ADD的新型ADD模型，通过单声道转立体声技术发现伪造音频中的真实性线索，显著提高了检测性能。 |
| [^68] | [Lexinvariant Language Models.](http://arxiv.org/abs/2305.16349) | 本文讨论了一种新型的语言模型，称为Lexinvariant语言模型，该模型不需要任何固定标记嵌入，完全依赖上下文中标记的共现和重复。作者证明可以构建一个lexinvariant LM，以多项式方式与上下文长度成比例地收敛到真实语言模型，其常量因子在词汇表大小下为次线性。 |
| [^69] | [Leveraging LLMs for KPIs Retrieval from Hybrid Long-Document: A Comprehensive Framework and Dataset.](http://arxiv.org/abs/2305.16344) | 本文提出了一个自动化财务信息提取的框架（AFIE），用于提取混合长文档中的关键业绩指标（KPI）。该框架利用LLMs增强了财务报告信息的理解和提取能力，并经过了广泛的实验验证，证明其在GPT-3.5和GPT-4上的有效性，相对于朴素方法，平均精度提高了53.94％和33.77％。 |
| [^70] | [A Distributed Automatic Domain-Specific Multi-Word Term Recognition Architecture using Spark Ecosystem.](http://arxiv.org/abs/2305.16343) | 本论文提出了一种基于Spark生态系统的分布式架构，可自动提取领域特定术语，经实验证明在术语提取准确性方面取得最先进的结果。 |
| [^71] | [InterFormer: Interactive Local and Global Features Fusion for Automatic Speech Recognition.](http://arxiv.org/abs/2305.16342) | 本文提出了InterFormer，用于交互式局部和全局特征融合，以学习更好的ASR表示。通过组合卷积块和变形器块，以及引入BFIM和SFM模块，实现了局部和全局特征的交互和融合，取得了在公共ASR数据集上优异的性能。 |
| [^72] | [Segmented Recurrent Transformer: An Efficient Sequence-to-Sequence Model.](http://arxiv.org/abs/2305.16340) | 本文提出了一种分段循环Transformer（SRformer）来减少计算/内存成本，并使用RAF层处理跨段的信息，从而提高序列处理能力。 |
| [^73] | [Don't Trust GPT When Your Question Is Not In English.](http://arxiv.org/abs/2305.16339) | 在多语言环境下，GPT-3表现较差，特别是当问题不是用英语提出时。这与模型的训练数据和输入问题的语言差异有关。 |
| [^74] | [Think Before You Act: Decision Transformers with Internal Working Memory.](http://arxiv.org/abs/2305.16338) | 该论文提出了具有内部工作记忆模块的决策Transformer方法，以解决使用大型语言模型的决策代理在处理新任务上性能低下的问题。所提出的方法改善了训练效率和泛化能力，并进一步增强了转化决策制定代理对新任务的适应性。 |
| [^75] | [Handling Realistic Label Noise in BERT Text Classification.](http://arxiv.org/abs/2305.16337) | 本文研究了BERT在现实标签噪声存在下的分类性能，发现特征相关的标签噪声和来自注释者分歧的合成标签噪声会导致BERT的分类性能下降。提出不同类型的集成和噪声清理方法以提高鲁棒性。 |
| [^76] | [Robust Representation Learning with Reliable Pseudo-labels Generation via Self-Adaptive Optimal Transport for Short Text Clustering.](http://arxiv.org/abs/2305.16335) | 本文提出了一种健壮短文本聚类（RSTC）模型，通过自适应最优输运的伪标签生成，以及基于类和实例的对比学习的健壮表示学习，帮助提高对不平衡和噪音数据的鲁棒性。 |
| [^77] | [OlaGPT: Empowering LLMs With Human-like Problem-Solving Abilities.](http://arxiv.org/abs/2305.16334) | OlaGPT是一种新颖的智能框架，能够模拟人类在解决复杂推理问题时所采用的各种认知能力和与工具、知识和外部环境信息的交互，可以让大型语言模型具备类人的问题解决能力。 |
| [^78] | [Text Generation with Speech Synthesis for ASR Data Augmentation.](http://arxiv.org/abs/2305.16333) | 本研究探索文本增广对ASR的影响，使用大规模预训练的神经网络来生成合成文本，并通过文本到语音系统转换为合成语音，实验发现，使用神经网络的文本增广方法能够有效提高ASR准确度，可以作为改进ASR系统的一种可行工具。 |
| [^79] | [Semantic Composition in Visually Grounded Language Models.](http://arxiv.org/abs/2305.16328) | 本论文研究了视觉上下文语言模型中的语义组合能力，提出了新的组合视觉问答基准，句法神经模块蒸馏等方法以提高组合能力，并探索了对图像字幕模型的因果追踪以定位重要神经表示。 |
| [^80] | [Large language models in biomedical natural language processing: benchmarks, baselines, and recommendations.](http://arxiv.org/abs/2305.16326) | 本文研究了GPT-3和GPT-4在生物医学自然语言处理中的表现，分析了它们可能产生的错误类型，并提供了使用这些模型的建议。 |
| [^81] | [Talking with Machines: A Comprehensive Survey of Emergent Dialogue Systems.](http://arxiv.org/abs/2305.16324) | 本文全面综述了对话系统的发展历史、基本运作、流行和新兴数据集、关键贡献、评估指标和挑战，展望了该领域的未来前景。 |
| [^82] | [UNITE: A Unified Benchmark for Text-to-SQL Evaluation.](http://arxiv.org/abs/2305.16265) | 提出了一个统一的基准UNITE用于文本到SQL评估，包含来自12个以上领域的自然语言问题、超过3.9K种模式的SQL查询和29K个数据库。研究表明，Codex在跨领域数据集上表现出色，特别设计的编码方法可以提高性能，可机读的数据库的质量对文本到SQL系统的性能至关重要。 |
| [^83] | [Diversity-Aware Coherence Loss for Improving Neural Topic Models.](http://arxiv.org/abs/2305.16199) | 本文提出了一种多样性感知的相干性损失，可以帮助神经主题模型在保持高多样性同时，更好地学习语料库级别的连贯性分数。 |
| [^84] | [Comparative Study of Pre-Trained BERT Models for Code-Mixed Hindi-English Data.](http://arxiv.org/abs/2305.15722) | 本文比较了使用不同预训练Transformer模型的印地语-英语代码混合数据的性能表现，以提高情感分析、情绪识别和仇恨言论识别等自然语言处理任务的性能。 |
| [^85] | [ConvGQR: Generative Query Reformulation for Conversational Search.](http://arxiv.org/abs/2305.15645) | 本文提出了一种新的面向会话搜索的ConvGQR框架，通过结合预训练语言模型来重新构造查询，从而提供更好的搜索查询。 |
| [^86] | [A Simple and Effective Framework for Strict Zero-Shot Hierarchical Classification.](http://arxiv.org/abs/2305.15282) | 本研究提出了一种蕴含-矛盾预测方法，与大型语言模型结合，用于解决分层数据集中的零样例分类问题，成功实现了严格零样例分层分类。 |
| [^87] | [Evaluating OpenAI's Whisper ASR for Punctuation Prediction and Topic Modeling of life histories of the Museum of the Person.](http://arxiv.org/abs/2305.14580) | 本文首次对葡萄牙语中的Whisper ASR进行了标点符号预测方面的研究，并为标点符号预测在主题建模中的应用提供了有益的实验评估。 |
| [^88] | [SPEECH: Structured Prediction with Energy-Based Event-Centric Hyperspheres.](http://arxiv.org/abs/2305.13617) | 这篇论文提出了一种称为SPEECH的模型，它使用能量建模来表示复杂的事件结构，并使用超球来表示事件类别。实验结果表明，SPEECH在事件检测和事件关系抽取任务中表现出卓越的性能。 |
| [^89] | [Decoupled Rationalization with Asymmetric Learning Rates: A Flexible Lipshitz Restraint.](http://arxiv.org/abs/2305.13599) | 本文提出了一种名为DR的灵活的方法，它通过不对称的学习率来解决由合作博弈引发的退化问题，该方法能够在两个基准测试中显著改善表现。 |
| [^90] | [Aligning the Norwegian UD Treebank with Entity and Coreference Information.](http://arxiv.org/abs/2305.13527) | 本文将挪威两种书写形式语料库中的实体和共指标注数据合并到了通用依存语料库（UD treebanks）中，这是第一个加入实体和共指信息的挪威UD treebank，对未来语料库对齐和共指注释工作有帮助。 |
| [^91] | [Gene Set Summarization using Large Language Models.](http://arxiv.org/abs/2305.13338) | 该论文介绍了一种使用大型语言模型来对基因集进行函数概括的方法，名为SPINDOCTOR，可以提供比传统方法更好的性能和可解释性。 |
| [^92] | [Exploring Energy-based Language Models with Different Architectures and Training Methods for Speech Recognition.](http://arxiv.org/abs/2305.12676) | 本文探索了不同的能量函数架构和不同的训练方法，以提高基于能量的语言模型在语音识别中计算句子得分的能力。 |
| [^93] | [Multi-Head State Space Model for Speech Recognition.](http://arxiv.org/abs/2305.12498) | 本文提出了一种多头状态空间（MH-SSM）模型，它能够用于语音识别任务并在LibriSpeech数据集上表现出的新的性能，是变压器变换器的优秀替代方案。同时, MH-SSM层的引入也提高了变压器块的性能，达到了现有最新水平。 |
| [^94] | [Glot500: Scaling Multilingual Corpora and Language Models to 500 Languages.](http://arxiv.org/abs/2305.12182) | Glot500是一个水平扩展的语言模型，覆盖了511种低资源语言。相比于XLM-R基线，Glot500展现出了更好的高资源和低资源语言表现。该模型质量的决定因素包括语料库大小、脚本、相关语言的“帮助”和模型的总容量。 |
| [^95] | [Learning In-context Learning for Named Entity Recognition.](http://arxiv.org/abs/2305.11038) | 本文提出了一种在 PLMs 中注入上下文 NER 能力的方法，只需少量示意实例即可动态识别新类型的实体，在几个基准数据集上达到了最先进的性能。 |
| [^96] | [Uncertainty Guided Label Denoising for Document-level Distant Relation Extraction.](http://arxiv.org/abs/2305.11029) | 本文提出了一种使用不确定性引导的标签去噪技术，可以有效准确地在文档级远程关系抽取中选择可信的伪标签，提高了性能表现，并在DocRED数据集上实现了新的最佳性能。 |
| [^97] | [MolXPT: Wrapping Molecules with Text for Generative Pre-training.](http://arxiv.org/abs/2305.10688) | MolXPT是一个文本包装的统一语言模型，使用SMILES作为输入，可以提高分子模型的性能表现，并且使得基于零shot的分子生成成为可能。 |
| [^98] | [Personality Understanding of Fictional Characters during Book Reading.](http://arxiv.org/abs/2305.10156) | 本文提出了一个NLP领域内尚未研究的问题：情景和细致地理解小说人物个性，并提供了第一个标记数据集PersoNet来解决这个问题。 |
| [^99] | [sustain.AI: a Recommender System to analyze Sustainability Reports.](http://arxiv.org/abs/2305.08711) | sustain.AI是一个智能的、上下文感知的推荐系统，可以帮助审计师、金融投资者以及广大公众高效地分析公司的可持续性报告，并通过与GRI标准匹配来提供更好的推荐精度。 |
| [^100] | [NLG Evaluation Metrics Beyond Correlation Analysis: An Empirical Metric Preference Checklist.](http://arxiv.org/abs/2305.08566) | 本研究提出了一种度量偏好检查表，以超越相关分析评估NLG自动指标，并分析了两种类型的指标及其在三个任务中的效果。 |
| [^101] | [PALR: Personalization Aware LLMs for Recommendation.](http://arxiv.org/abs/2305.07622) | 本文提出了一个称为PALR的框架，将用户的历史行为与LLMs相结合，生成用户喜欢的物品的推荐。与现有的推荐方法相比，我们的PALR框架实现了最先进的性能。 |
| [^102] | [BanglaBook: A Large-scale Bangla Dataset for Sentiment Analysis from Book Reviews.](http://arxiv.org/abs/2305.06595) | BanglaBook 是一个大规模的孟加拉语书评数据集，其中包括 158,065 个样本，针对情感分析分为三个大类，通过使用预训练模型来取代手动构建特征的模型，取得显着的性能优势。 |
| [^103] | [Multilingual LLMs are Better Cross-lingual In-context Learners with Alignment.](http://arxiv.org/abs/2305.05940) | 针对跨语言ICL中无法对准输入输出空间的问题，我们提出了一种新的提示构建策略X-InSTA，可以同时对源语言和目标语言的语境进行编码和对齐，从而提高跨语言ICL的效率。 |
| [^104] | [Boosting Zero-shot Cross-lingual Retrieval by Training on Artificially Code-Switched Data.](http://arxiv.org/abs/2305.05295) | 研究者提出训练排名模型的方法来提高跨语言检索的效率，该模型使用了人工代码切换的数据，并且实验表明在跨语言检索和多语言检索中会带来显著改进，在不影响单语检索的基础上，特别是对于远程语言之间的检索。 |
| [^105] | [Distilling Script Knowledge from Large Language Models for Constrained Language Planning.](http://arxiv.org/abs/2305.05252) | 本文首次定义了受限语言规划任务，提出了一种方法来提高大型语言模型在这个任务中的表现，并提取了一个新颖的受限语言规划数据集。实验证明该方法显著提高了其在约束忠实度方面的能力，并对赋予较小的语言模型受限语言规划能力非常有效。 |
| [^106] | [ANALOGICAL - A New Benchmark for Analogy of Long Text for Large Language Models.](http://arxiv.org/abs/2305.05050) | 本文介绍了一种名为“ANALOGICAL”的新型基准，用以内在评估LLMs在长文本类比中的能力，包括六个复杂级别的长文本类比分类，并使用13个数据集和三种距离度量方法来评估8个LLMs在语义向量空间中识别类比对的能力。 |
| [^107] | [Explanation-based Finetuning Makes Models More Robust to Spurious Cues.](http://arxiv.org/abs/2305.04990) | 本文提出一种新型方法——解释性微调，通过让模型在给出答案的同时生成支持该答案的自由文本解释，来减轻LLMs依赖虚假关联，使得模型对虚假提示更加强韧，并具有广泛适用性。 |
| [^108] | [Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models.](http://arxiv.org/abs/2305.04091) | 本研究提出了一种计划和解决的提示方法来改善零样本思考链推理，该方法包括两个组成部分：制定计划将任务划分为子任务，并按计划执行子任务；将输入提示扩展到包括简单算术计算的示例。实验结果显示，该方法胜过了零样本-CoT。 |
| [^109] | [Self-Edit: Fault-Aware Code Editor for Code Generation.](http://arxiv.org/abs/2305.04087) | 本文提出了一种故障感知式代码编辑器，通过执行生成的代码并将执行结果包含在在注释中来优化竞技编程任务的代码质量，通过与九个不同的LLMs进行比较，本方法可以在两个竞技编程数据集上显著提高代码的准确性。 |
| [^110] | [Chain-of-Skills: A Configurable Model for Open-domain Question Answering.](http://arxiv.org/abs/2305.03130) | 本论文提出了一种模块化检索器可以在数据集间重复使用，支持针对目标领域的灵活技能配置，通过自我监督预训练和微调多个 ODQA 数据集，实现了最新颖的微调检索性能。 |
| [^111] | [PeaCoK: Persona Commonsense Knowledge for Consistent and Engaging Narratives.](http://arxiv.org/abs/2305.02364) | PeaCoK构建了一个大规模的角色常识知识图，包含约10万个经过人类验证的角色事实。该知识图展现了在以前的人类交互行为研究中确定的五个角色知识维度，并区分了常识和情感层面。 |
| [^112] | [A Systematic Study of Knowledge Distillation for Natural Language Generation with Pseudo-Target Training.](http://arxiv.org/abs/2305.02031) | 本文研究如何压缩自然语言生成模型以适应实际应用需求，通过使用知识蒸馏和伪目标训练技术针对特定的自然语言生成任务和数据集进行优化，并取得了显著效果。 |
| [^113] | [FIREBALL: A Dataset of Dungeons and Dragons Actual-Play with Structured Game State Information.](http://arxiv.org/abs/2305.01528) | 本研究介绍了一份包含真实游戏状态信息的Dungeons & Dragons实际游戏数据集FIREBALL，它可以改善自然语言生成的质量。此外，LLMs可以使用FIREBALL中的游戏状态信息来生成更高质量的游戏回合。 |
| [^114] | [A Data-centric Framework for Improving Domain-specific Machine Reading Comprehension Datasets.](http://arxiv.org/abs/2304.00483) | 本文提出了一种数据中心框架，通过回译方法提高领域特定机器阅读理解数据集的质量，从而提高模型性能 |
| [^115] | [Self-Refine: Iterative Refinement with Self-Feedback.](http://arxiv.org/abs/2303.17651) | 自我反馈迭代精炼是一种无需监督学习或加强学习的LLMs初始输出优化方法，优于直接生成，被证实在7个不同任务中表现更好。 |
| [^116] | [A Comprehensive Study on Post-Training Quantization for Large Language Models.](http://arxiv.org/abs/2303.08302) | 本文基于数万个零-shot实验对基于后训练量化的大型语言模型的不同量化组件进行了综合研究，结果发现细粒度量化和后训练量化方法很重要，用粗粒度量化的更高位数比用非常细粒度的更低位数更强大。我们给出了如何为不同大小的\llms利用量化的建议。 |
| [^117] | [Reveal the Unknown: Out-of-Knowledge-Base Mention Discovery with Entity Linking.](http://arxiv.org/abs/2302.07189) | 本文提出了基于BERT的实体链接方法BLINKout，通过与特殊NIL实体匹配来识别没有相应KB实体的实体提及，相较于现有方法具有优势。 |
| [^118] | [Grounding Language Models to Images for Multimodal Inputs and Outputs.](http://arxiv.org/abs/2301.13823) | 该论文提出一种有效的方法，将仅处理文本的语言模型与图像进行联系，使其能够处理任意交错的图像和文本数据，并生成与检索图像交错的自由形式文本。该方法在环境相关的图像检索和多模态对话等任务中表现十分优异，是利用预训练语言模型解决视觉场景下交互问题的有效解决方案。 |
| [^119] | [Gender Neutralization for an Inclusive Machine Translation: from Theoretical Foundations to Open Challenges.](http://arxiv.org/abs/2301.10075) | 研究了性别中性化翻译（GNT）作为一种性别包容性的方法，从英语到意大利语的翻译是一个突出的性别相关的语言翻译问题。研究回顾了一些相关的性别包容性语言指南，探讨了使用GNT的情景，并探讨了在MT中执行GNT的技术挑战和解决方案。 |
| [^120] | [MoralDial: A Framework to Train and Evaluate Moral Dialogue Systems via Moral Discussions.](http://arxiv.org/abs/2212.10720) | MoralDial提出了一个通过模拟特定用户和对话系统之间的道德讨论来训练和评估道德对话系统的框架，并通过判断对话响应与人类价值观之间的关系来评估道德的多个方面。 |
| [^121] | [Self-Instruct: Aligning Language Models with Self-Generated Instructions.](http://arxiv.org/abs/2212.10560) | 本论文提出了一种名为Self-Instruct的框架，通过自身生成指导信息来提高预训练语言模型的指令遵循能力。在超自然指令上，我们展示了与InstructGPT-001相同的性能表现，并在原始模型上获得了33%的改进。 |
| [^122] | [Socratic Pretraining: Question-Driven Pretraining for Controllable Summarization.](http://arxiv.org/abs/2212.10449) | 本论文介绍了一种面向问题驱动的无监督预训练方法，名为Socratic预训练，用于提高摘要任务的可控性，并演示了该方法通过在多个控制策略上进行广泛实验得出的优于其他方法的结果。 |
| [^123] | [Towards Reasoning in Large Language Models: A Survey.](http://arxiv.org/abs/2212.10403) | 本文综述了大型语言模型中的推理研究的现状和未来方向，包括提高和诱导推理能力的技术、评估推理能力的方法和基准，旨在提供一个详细和最新的综述，刺激有意义的讨论和未来的研究。 |
| [^124] | [Tackling Ambiguity with Images: Improved Multimodal Machine Translation and Contrastive Evaluation.](http://arxiv.org/abs/2212.10140) | 本文提出了一种基于强文本机器翻译模型的多模式翻译方法，该方法利用图像解决机器翻译中的歧义问题，同时引入了CoMMuTE数据集以进行对比多语言多模式翻译评估，取得了与强文本模型相当的结果。 |
| [^125] | [DIONYSUS: A Pre-trained Model for Low-Resource Dialogue Summarization.](http://arxiv.org/abs/2212.10018) | 提出了一种名为DIONYSUS的对话摘要模型，它是一个预先训练的编码器-解码器模型，可用于低资源的对话摘要，自监督的方法用于预训练。该模型的创新点在于利用不同的伪摘要，并基于对话中信息分布的分析来选择最佳的伪摘要，提高了在新领域中对话摘要的表现。 |
| [^126] | [Python Code Generation by Asking Clarification Questions.](http://arxiv.org/abs/2212.09885) | 本文提出了一个新的方法来解决自然语言描述中存在歧义的问题--通过提问澄清问题，本文提出的方法在预训练语言模型性能上取得了显著改善。 |
| [^127] | [Unsupervised Summarization Re-ranking.](http://arxiv.org/abs/2212.09593) | 该论文提出了一种无监督的摘要再排序方法，可以将无监督模型的摘要表现提高，缩小其与有监督模型之间的性能差距。 |
| [^128] | [Query Enhanced Knowledge-Intensive Conversation via Unsupervised Joint Modeling.](http://arxiv.org/abs/2212.09588) | 本文提出了一个无监督的查询增强方法QKConv，用于知识密集型对话，并在三个数据集上进行了实验。实验结果表明，QKConv的表现比所有无监督方法都要好，并且与有监督方法具有竞争性的性能。 |
| [^129] | [I2D2: Inductive Knowledge Distillation with NeuroLogic and Self-Imitation.](http://arxiv.org/abs/2212.09246) | 本论文探究了通过常识蒸馏算法强化小型语言模型的能力，挑战大型模型的常识获取能力，提出了一种不依赖规模的学习算法方案。 |
| [^130] | [OASum: Large-Scale Open Domain Aspect-based Summarization.](http://arxiv.org/abs/2212.09233) | 本文提出了一种大规模开放领域基于特定方面的摘要生成方法，通过对维基百科进行众包知识的利用，构建了高质量的OASum数据集，并在七个下游数据集上进行训练。该方法可以进行多样化的方面基础的总结生成。 |
| [^131] | [Don't Forget Your ABC's: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems.](http://arxiv.org/abs/2212.09180) | 本文提出了一种可靠的维度化评估人机聊天的新方法，并评估了一组最先进的开放领域聊天机器人，为未来聊天导向对话系统的发展提供了基准。 |
| [^132] | [Rarely a problem? Language models exhibit inverse scaling in their predictions following few-type quantifiers.](http://arxiv.org/abs/2212.08700) | 本文研究了语言模型处理“few-”类型量词的能力，结果显示所有模型对这种量词都表现不佳，且较大的模型表现更差。这种反比例缩放的现象表明大型模型越来愈反映在线人类处理，而不是离线处理。这可能挑战使用语言模型作为自然语言系统基础的做法。 |
| [^133] | [UnitY: Two-pass Direct Speech-to-speech Translation with Discrete Units.](http://arxiv.org/abs/2212.08055) | UnitY是一种通过两遍翻译生成最佳结果的语音翻译方法，能够比单遍语音到单元翻译模型在ASR-BLEU值和解码速度上表现更好。 |
| [^134] | [DAMP: Doubly Aligned Multilingual Parser for Task-Oriented Dialogue.](http://arxiv.org/abs/2212.08054) | 本文介绍了一种面向任务型对话的双重对齐多语言解析器，可以大幅提高多语言和代码切换语义解析系统的零-shot性能，提高mBERT转移性能。 |
| [^135] | [Multi-VALUE: A Framework for Cross-Dialectal English NLP.](http://arxiv.org/abs/2212.08011) | 该论文介绍了一个跨方言的英文NLP框架Multi-VALUE，该框架可以将标准美式英语映射为50种英语方言的合成形式，用于评估、实现英式方言临近性，并在非标准方言上进行压力测试。 |
| [^136] | [Visually-augmented pretrained language models for NLP tasks without images.](http://arxiv.org/abs/2212.07937) | 该研究提出了一种无需检索或生成图像的视觉增强微调方法，可以普遍地应用于各种PLM或NLP任务，并在不同规模的BERT、RoBERTa、BART和T5上持续地提高性能。 |
| [^137] | [Pre-trained Language Models Can be Fully Zero-Shot Learners.](http://arxiv.org/abs/2212.06950) | 本文提出了一种名为NPPrompt的方法，它可以使预训练语言模型成为完全零-shot学习器。相比于现有方法，NPPrompt不需要使用人工标注数据或者构建提示，只需使用预训练的语言模型。NPPrompt在文本分类、文本蕴含、相似文本检索和改写等任务上的表现大幅优于以前最好的完全零-shot方法。 |
| [^138] | [Nonparametric Masked Language Modeling.](http://arxiv.org/abs/2212.01349) | NPM是第一个使用非参数分布替换softmax的遮蔽语言模型，可以更好地处理稀有模式和预测罕见或几乎未见过的单词，并在16项任务上超过了更大的参数模型。 |
| [^139] | [Zero-Shot Rumor Detection with Propagation Structure via Prompt Learning.](http://arxiv.org/abs/2212.01117) | 本文提出了一种基于Prompt学习和传播结构的零样本谣言检测框架，其能够有效地检测不同领域和语言的谣言，并可适应非预料中断事件的影响。 |
| [^140] | [Soft Alignment Objectives for Robust Adaptation of Language Generation.](http://arxiv.org/abs/2211.16550) | 本研究提出了一种基于预测令牌与参考语义相似性的新型训练目标，可以在领域自适应中缓解灾难性遗忘，同时又可以保持调整质量，并且计算成本增加可忽略不计。 |
| [^141] | [Contrastive Novelty-Augmented Learning: Anticipating Outliers with Large Language Models.](http://arxiv.org/abs/2211.15718) | CoNAL方法可以帮助分类模型降低在新颖类别上的过度自信，提高检测和放弃这些类别示例的能力。 |
| [^142] | [SongRewriter: A Chinese Song Rewriting System with Controllable Content and Rhyme Scheme.](http://arxiv.org/abs/2211.15037) | SongRewriter是一种中文歌曲改编系统，可以重新编写现有歌曲的歌词生成与旋律相配的歌词，可帮助没有旋律组成知识的用户，易于控制生成过程。 |
| [^143] | [Towards Robust Low-Resource Fine-Tuning with Multi-View Compressed Representations.](http://arxiv.org/abs/2211.08794) | 本文提出了一种利用多视角压缩表示降低预训练语言模型微调过程中过拟合问题的方法，经过测试在低资源NLP任务中表现良好。 |
| [^144] | [Hierarchical Pronunciation Assessment with Multi-Aspect Attention.](http://arxiv.org/abs/2211.08102) | 本论文提出了一种多层次多方面注意力的发音评估模型，能够更好地捕捉音素、单词和话语的语言层次结构，并在评估准确性、流畅度和完整性方面取得了最先进的结果。 |
| [^145] | [GreenPLM: Cross-Lingual Transfer of Monolingual Pre-Trained Language Models at Almost No Cost.](http://arxiv.org/abs/2211.06993) | GreenPLM是一个节能有效的框架，可利用双语词典实现几乎无成本的跨语言转移预训练语言模型，有效解决了跨语言访问预训练模型和减少大规模模型训练能源消耗的问题，并在18种语言的BERT模型中验证了其效果。 |
| [^146] | [RQUGE: Reference-Free Metric for Evaluating Question Generation by Answering the Question.](http://arxiv.org/abs/2211.01482) | RQUGE是一种新的度量标准方法，通过候选问题是否可以回答来评估问题生成质量, 比现有指标更加稳健，可以在不需要人工提供参考问题的情况下使用。 |
| [^147] | [Preventing Verbatim Memorization in Language Models Gives a False Sense of Privacy.](http://arxiv.org/abs/2210.17546) | 防止神经语言模型逐字记忆无法真正保护隐私，本文设计的布隆过滤器虽然防止了所有逐字记忆，但仍然无法防止训练数据泄露，容易被合理修改的“样式转换”提示绕过。 |
| [^148] | [JECC: Commonsense Reasoning Tasks Derived from Interactive Fictions.](http://arxiv.org/abs/2210.15456) | 本文提出了一个新的常识推理数据集JECC，基于人类互动小说游戏的演示步骤。与现有基准不同的是，该数据集评估的是功能性的常识知识规则。因此，为了在这些任务上表现良好，模型需要利用这种常识知识来推断行动的结果，而不是仅仅依赖于记忆事实。 |
| [^149] | [Experiencer-Specific Emotion and Appraisal Prediction.](http://arxiv.org/abs/2210.12078) | 本研究提出了一种新的任务，将焦点缩小到事件的经历者，将情感（如果有）分配给每个经历者，提出了表示每种情感分类的心理评价变量，从而使得情感分类更为准确。 |
| [^150] | [Entity-to-Text based Data Augmentation for various Named Entity Recognition Tasks.](http://arxiv.org/abs/2210.10343) | 本研究提出了一种新的基于实体与文本的数据增强技术（EnTDA），可为各种扁平、嵌套和不连续 NER 任务生成语义连贯和保留实体的文本，并引入多样性束搜索以增加文本生成过程中的多样性。 |
| [^151] | [Towards Summary Candidates Fusion.](http://arxiv.org/abs/2210.08779) | 本文提出了一种名为SummaFusion的新范式，通过融合多个总结候选项来产生一个新的抽象总结，以改善第一阶段候选项的限制，并在多个摘要数据集上取得良好的性能，尤其是在少样本设置下。 |
| [^152] | [Automatic Creation of Named Entity Recognition Datasets by Querying Phrase Representations.](http://arxiv.org/abs/2210.07586) | 本篇论文提出了一种名为HighGEN的新框架，通过使用短语嵌入搜索方法生成实体丰富的伪字典，在使用嵌入距离验证过程减少误报的基础上生成高覆盖率的NER数据集。 |
| [^153] | [You Can Have Your Data and Balance It Too: Towards Balanced and Efficient Multilingual Models.](http://arxiv.org/abs/2210.07135) | 使用基于教师-学生知识蒸馏的多语言训练技术，利用适用于每种语言优化的专业语言教师模型和平衡数据，可以在低资源语言的表现方面胜过标准训练方法，并在使用相同数量的数据的情况下提高高资源语言的性能，提高低资源语言在自然语言处理系统中的表示。 |
| [^154] | [Language Agnostic Multilingual Information Retrieval with Contrastive Learning.](http://arxiv.org/abs/2210.06633) | 该论文提出一种使用对比学习的技术，利用平行和非平行语料库来提高多语种信息检索的效果，仅使用英语IR训练数据和一些平行语料库即可在非英语数据上实现显著的检索性能改进。 |
| [^155] | [Can Language Models Be Specific? How?.](http://arxiv.org/abs/2210.05159) | 本论文提出了一种度量预训练语言模型具体性的方法，并设计了两种基于提示的方法，以改善模型具体性，结果表明，模型的具体性可以得到改善，而无需进行额外的训练。 |
| [^156] | [REV: Information-Theoretic Evaluation of Free-Text Rationales.](http://arxiv.org/abs/2210.04982) | 本论文提出了一种名为REV的度量，用于评估自由文本解释中新颖、与标签相关的信息的数量，通过信息论的角度进行研究。实验证明REV在评估解释-标签对方面的有效性，并且与人类直觉一致。 |
| [^157] | [A dynamic programming algorithm for span-based nested named-entity recognition in O(n^2).](http://arxiv.org/abs/2210.04738) | 本文提出了一种基于动态规划算法的基于跨度的嵌套式命名实体识别方法，时间复杂度为O(n^2)，其在英语标准基准测试三个标准中表现良好，具有实际应用价值。 |
| [^158] | [Downstream Datasets Make Surprisingly Good Pretraining Corpora.](http://arxiv.org/abs/2209.14389) | 本文研究了使用下游数据集进行自我预训练的效果，发现这种方法与使用大型语料库进行预训练的标准方法相媲美，并且在某些任务上更加优秀。同时，这些自我预训练模型还表现出了很好的泛化能力。 |
| [^159] | [Few-Shot Document-Level Event Argument Extraction.](http://arxiv.org/abs/2209.02203) | 本文介绍了一种在文档级别上捕捉事件论元的少样本情况下的新方法FewDocAE，并且通过N-Way-D-Doc抽样方法重构了语料库。通过将当前文档级神经模型调整到少样本情况下，为跨领域和领域内提供基线结果。 |
| [^160] | [A New Aligned Simple German Corpus.](http://arxiv.org/abs/2209.01106) | 本文介绍了一个新的对齐的简易德语语料库，用于辅助不同人群理解复杂的德语书面语言；该语料库通过自动句子对齐方法使多个文档对齐，且质量优于之前的工作。 |
| [^161] | [Environmental Claim Detection.](http://arxiv.org/abs/2209.00507) | 为了实现绿色经济，需要可靠、可比较和可验证的环境声明。该论文介绍了环境声明检测任务，并发布了一个专家标注的数据集和训练模型。通过这些模型，我们可以检测环境声明在季度电话会议中的使用情况并发现该使用情况自2015年以来有稳步增长的趋势。 |
| [^162] | [Multimedia Generative Script Learning for Task Planning.](http://arxiv.org/abs/2208.12306) | 该论文提出了多媒体生成式脚本学习任务，旨在通过跟踪文本和视觉模态中的历史状态来生成后续步骤，能对未见过的任务具有归纳能力并具有多样性。 |
| [^163] | [Hidden Schema Networks.](http://arxiv.org/abs/2207.03777) | 本文介绍了一种新颖的神经语言模型，通过归纳偏见强制执行明确的关系结构，从而将预训练语言模型的输出表示显式地组成。该模型可以从随机标记序列数据集中发现隐含的真实图，在自然语言数据集中推断出符号网络（模式），直接反映了语言的基础句法结构。 |
| [^164] | [B2T Connection: Serving Stability and Performance in Deep Transformers.](http://arxiv.org/abs/2206.00330) | 本研究提出了一种称为 B2T 连接的方法，连接了 Pre-LN 和 Post-LN 层的输出，为深度 Transformer 提供了高稳定性和有效的训练，实验结果表明，在多个基准数据集上取得了最先进结果。 |
| [^165] | [Understanding Factual Errors in Summarization: Errors, Summarizers, Datasets, Error Detectors.](http://arxiv.org/abs/2205.12854) | 本文聚合了来自九个现有数据集的事实错误注释，针对底层的摘要生成模型进行分类，并比较了最先进的事实度量标准的性能。结果表明，度量标准的性能因不同的摘要生成模型而有显著差异。 |
| [^166] | [TAGPRIME: A Unified Framework for Relational Structure Extraction.](http://arxiv.org/abs/2205.12585) | 本文提出了一种名为TAGPRIME的统一关系结构提取框架，通过将给定条件信息添加到输入文本中，使得输出的上下文表示更适合提取特定条件下的关系。在各种任务和数据集上的表现优于最新的关系提取模型。 |
| [^167] | [GENEVA: Benchmarking Generalizability for Event Argument Extraction with Hundreds of Event Types and Argument Roles.](http://arxiv.org/abs/2205.12505) | 本文提出了一个大而全的EAE本体论，105个事件和220个论元角色的包含在内，利用这个本体论创建了一种多样化的通用性基准测试数据集GENEVA，共包含四个测试套件，旨在评估模型处理有限数据的能力。 |
| [^168] | [Are We Really Making Much Progress? Bag-of-Words vs. Sequence vs. Graph vs. Hierarchy for Single- and Multi-Label Text Classification.](http://arxiv.org/abs/2204.03954) | 本文比较了用于文本分类的词袋、序列、图形和分层方法，发现基于图形的方法无法超越现代预训练语言模型并且甚至有时表现不如标准机器学习方法，质疑了过去几年中为开发新的图形方法投入的巨大努力以及它们为文本分类带来的承诺。 |
| [^169] | [SummaReranker: A Multi-Task Mixture-of-Experts Re-ranking Framework for Abstractive Summarization.](http://arxiv.org/abs/2203.06569) | SummaReranker是一种专家混合的二次排序框架，可用于抽象摘要。它能够直接在一组摘要候选上进行重新排序，从而优化基本模型的ROUGE分数，实现了新的SOTA。 |
| [^170] | [CrossSum: Beyond English-Centric Cross-Lingual Summarization for 1,500+ Language Pairs.](http://arxiv.org/abs/2112.08804) | 本文介绍了CrossSum - 一个1500多种语言对中的跨语言摘要数据集，以及一种多阶段数据采样算法和一种新的评估度量LaSE。该模型在摘要生成方面的表现优于基线模型，是目前已知最大的跨语言摘要数据集。 |
| [^171] | [Fact-driven Logical Reasoning for Machine Reading Comprehension.](http://arxiv.org/abs/2105.10334) | 本文提出一种基于事实的逻辑推理方法，采用分层方式涵盖常识和临时知识线索，通过构建超图实现句子级别和实体级别的交互，在逻辑推理基准测试和大规模阅读理解中表现出优越性。 |
| [^172] | [Multi-Task Attentive Residual Networks for Argument Mining.](http://arxiv.org/abs/2102.12227) | 本文提出了一种多任务注意力残差网络架构，通过利用集成方法、注意力机制和多任务学习，无需假设文档或论据结构，成功应用于多个论述挖掘任务中，成为了一种既通用又高性能的架构。 |

# 详细

[^1]: Prompt-和Trait关系感知的跨Prompt作文Trait评分

    Prompt- and Trait Relation-aware Cross-prompt Essay Trait Scoring. (arXiv:2305.16826v1 [cs.CL])

    [http://arxiv.org/abs/2305.16826](http://arxiv.org/abs/2305.16826)

    本研究提出了一种跨Prompt的作文Trait评分模型，通过作文提示关注和Traint相似性loss，有效解决了作文提示不同的问题，提高了自动化作文评分的准确性和可靠性。

    

    自动化作文评分（AES）的目的是对写作主题进行评分的文章，该主题定义了写作主题。大多数现有的AES系统假定对于训练中使用的相同提示评分文章，并分配仅整体分数。然而，这样的设置与实际教育情况冲突；特定提示的预分级文章缺乏，并且需要详细的子量规的Trait分数。因此，预测看不见的Prompt文章的各种Trait分数（称为跨Prompt作文Trait评分）是AES的一项挑战。在本文中，我们提出了一个强大的模型：Prompt-和Trait关系感知的跨Prompt作文Trait评分器。我们通过作文提示关注和利用由主题建模机制提取的主题连贯性特征对作文感知进行编码，而无需访问标记数据；因此，我们的模型甚至在跨Prompt设置中也考虑到作文的提示恪守。为了促进多Trait评分，我们设计了Trait相似性lo

    Automated essay scoring (AES) aims to score essays written for a given prompt, which defines the writing topic. Most existing AES systems assume to grade essays of the same prompt as used in training and assign only a holistic score. However, such settings conflict with real-education situations; pre-graded essays for a particular prompt are lacking, and detailed trait scores of sub-rubrics are required. Thus, predicting various trait scores of unseen-prompt essays (called cross-prompt essay trait scoring) is a remaining challenge of AES. In this paper, we propose a robust model: prompt- and trait relation-aware cross-prompt essay trait scorer. We encode prompt-aware essay representation by essay-prompt attention and utilizing the topic-coherence feature extracted by the topic-modeling mechanism without access to labeled data; therefore, our model considers the prompt adherence of an essay, even in a cross-prompt setting. To facilitate multi-trait scoring, we design trait-similarity lo
    
[^2]: 面向抽象摘要中的领域泛化的领域对齐前缀平均方法

    Domain Aligned Prefix Averaging for Domain Generalization in Abstractive Summarization. (arXiv:2305.16820v1 [cs.CL])

    [http://arxiv.org/abs/2305.16820](http://arxiv.org/abs/2305.16820)

    本文提出了一种轻量级、基于加权平均的领域对齐前缀平均方法（DAPA），用于抽象摘要中的领域泛化，实现了有效的源域扩展以提高性能。

    

    针对于抽象摘要中的领域泛化问题，本文提出了一种轻量级，基于加权平均的领域对齐前缀平均方法（DAPA）。通过给定多个源域，我们的方法首先为每个域训练一个前缀，然后利用这些前缀生成少量目标域文档的摘要，计算所需的权重来平均源前缀。在DAPA中，前缀调整允许轻量级的微调，加权平均允许有效地添加新的源域。在四个不同的摘要领域上进行评估，DAPA表现出与基准方法相当或更好的性能，证明了其前缀平均的有效性。

    Domain generalization is hitherto an underexplored area applied in abstractive summarization. Moreover, most existing works on domain generalization have sophisticated training algorithms. In this paper, we propose a lightweight, weight averaging based, Domain Aligned Prefix Averaging approach to domain generalization for abstractive summarization. Given a number of source domains, our method first trains a prefix for each one of them. These source prefixes generate summaries for a small number of target domain documents. The similarity of the generated summaries to their corresponding documents is used for calculating weights required to average source prefixes. In DAPA, prefix tuning allows for lightweight finetuning, and weight averaging allows for the computationally efficient addition of new source domains. When evaluated on four diverse summarization domains, DAPA shows comparable or better performance against the baselines, demonstrating the effectiveness of its prefix averaging
    
[^3]: 在轻微推动下，NLI模型可以高效、稳健地预测忠实度

    With a Little Push, NLI Models can Robustly and Efficiently Predict Faithfulness. (arXiv:2305.16819v1 [cs.CL])

    [http://arxiv.org/abs/2305.16819](http://arxiv.org/abs/2305.16819)

    本文证明，在任务自适应数据增强与稳健的推理过程相结合下，纯NLI模型可以胜过更复杂的度量方法。

    

    条件语言模型仍然生成不忠实的输出，这些输出与其输入不一致。这些不忠实的生成会危及到应用程序对于真实世界的信任，例如概述或人机互动，这促使需要自动忠实性度量标准的产生。为了实施这样的标准，NLI模型似乎很有吸引力，因为它们解决一个与众多先前研究和数据相关的任务。但最近的研究表明，在跨数据集可靠执行方面，NLI模型需要昂贵的附加机器，例如在输入和生成的句子的笛卡尔积上运行推理，或通过支持问答步骤来支持它们。在这份工作中，我们展示了通过将任务自适应数据增强与稳健的推理过程相结合，纯NLI模型可以胜过更复杂的度量方法。我们提出了以下措施：（1）增加NLI培训数据，以适应对话中忠实度预测的特殊性；（2）利用推理过程。

    Conditional language models still generate unfaithful output that is not supported by their input. These unfaithful generations jeopardize trust in real-world applications such as summarization or human-machine interaction, motivating a need for automatic faithfulness metrics. To implement such metrics, NLI models seem attractive, since they solve a strongly related task that comes with a wealth of prior research and data. But recent research suggests that NLI models require costly additional machinery to perform reliably across datasets, e.g., by running inference on a cartesian product of input and generated sentences, or supporting them with a question-generation/answering step.  In this work we show that pure NLI models _can_ outperform more complex metrics when combining task-adaptive data augmentation with robust inference procedures. We propose: (1) Augmenting NLI training data to adapt NL inferences to the specificities of faithfulness prediction in dialogue; (2) Making use of 
    
[^4]: 跨越边界的歌曲：可唱和可控的神经歌词翻译

    Songs Across Borders: Singable and Controllable Neural Lyric Translation. (arXiv:2305.16816v1 [cs.CL])

    [http://arxiv.org/abs/2305.16816](http://arxiv.org/abs/2305.16816)

    本文提出了一种可唱和可控的神经歌词翻译方法，通过将歌词翻译形式化为受约束的翻译问题，将翻译学文献中的理论指导和实际技术转化为驱动的NMT方法，实现了英汉歌词翻译系统，并在长度准确性、韵律准确性和单词边界召回率上得到优秀的成绩，相比朴素的微调能够显著提高翻译质量。

    

    最近几年，通用领域的神经机器翻译（NMT）方法得到了显著发展，但是其输出的自然度和音乐约束的不足使它们无法产生可唱的歌词翻译。本文通过将歌词翻译形式化为受约束的翻译问题，将翻译学文献中的理论指导和实际技术转化为驱动的NMT方法，探索更好的适应方法，并将其实例化为一种英汉歌词翻译系统来填补可唱歌词翻译品质差距。我们的模型在长度准确性、韵律准确性和单词边界召回率方面分别达到了99.85%、99.00%和95.52%。在主观评估中，与朴素的微调相比，我们的模型在整体质量上表现出了75%的相对增强。

    The development of general-domain neural machine translation (NMT) methods has advanced significantly in recent years, but the lack of naturalness and musical constraints in the outputs makes them unable to produce singable lyric translations. This paper bridges the singability quality gap by formalizing lyric translation into a constrained translation problem, converting theoretical guidance and practical techniques from translatology literature to prompt-driven NMT approaches, exploring better adaptation methods, and instantiating them to an English-Chinese lyric translation system. Our model achieves 99.85%, 99.00%, and 95.52% on length accuracy, rhyme accuracy, and word boundary recall. In our subjective evaluation, our model shows a 75% relative enhancement on overall quality, compared against naive fine-tuning (Code available at https://github.com/Sonata165/ControllableLyricTranslation).
    
[^5]: 基于自适应上下文建模的视觉故事生成的改进

    Improved Visual Story Generation with Adaptive Context Modeling. (arXiv:2305.16811v1 [cs.CV])

    [http://arxiv.org/abs/2305.16811](http://arxiv.org/abs/2305.16811)

    这篇论文提出了一种简单的方法，使用自适应上下文建模改进了视觉故事生成，以提高生成故事的全局一致性和生成语义一致的故事图像，并在PororoSV和FlintstonesSV数据集上实现了最佳结果。

    

    在像稳定扩散这样的强大的文本到图像生成模型上开发的扩散模型在视觉故事生成方面取得了显著的成功。然而，最佳表现的方法将历史生成的结果视为扁平化的记忆单元，忽略了并非所有先前的图像对当前阶段的角色和场景的生成都有同等的贡献。为了解决这个问题，我们提出了一种使用自适应上下文建模改进主要系统的简单方法，该方法不仅将其纳入编码器，而且还在采样阶段采用其作为额外的指导，以提高生成故事的全局一致性。我们评估了在PororoSV和FlintstonesSV数据集上的模型，并展示了我们的方法在故事可视化和延续场景方面都实现了最先进的FID分数。我们进行了详细的模型分析，并展示了我们的模型在生成语义一致的故事图像方面表现出色。

    Diffusion models developed on top of powerful text-to-image generation models like Stable Diffusion achieve remarkable success in visual story generation. However, the best-performing approach considers historically generated results as flattened memory cells, ignoring the fact that not all preceding images contribute equally to the generation of the characters and scenes at the current stage. To address this, we present a simple method that improves the leading system with adaptive context modeling, which is not only incorporated in the encoder but also adopted as additional guidance in the sampling stage to boost the global consistency of the generated story. We evaluate our model on PororoSV and FlintstonesSV datasets and show that our approach achieves state-of-the-art FID scores on both story visualization and continuation scenarios. We conduct detailed model analysis and show that our model excels at generating semantically consistent images for stories.
    
[^6]: GenQ：自动化问答生成器以帮助照顾者与孩子共读故事

    GenQ: Automated Question Generation to Support Caregivers While Reading Stories with Children. (arXiv:2305.16809v1 [cs.CL])

    [http://arxiv.org/abs/2305.16809](http://arxiv.org/abs/2305.16809)

    本研究设计了一个智能辅导系统（GenQ），可以根据照顾者和孩子之间的对话促进孩子的阅读理解能力，并通过考虑文化背景和语境变化以提高系统效果。

    

    当照顾者询问开放式问题以激发与孩子的对话时，可以促进孩子的阅读理解能力。虽然有利用技术工具来支持这个过程，即所谓的“智能辅导系统”的空间，但目前仍不清楚现有的生成类人语言问题的智能系统是否有益。此外，用于开发这些自动生成问题系统的培训数据通常没有考虑到人口统计学，但具有不同文化背景的人可能会提出不同的问题。作为为拉丁裔儿童设计智能阅读支持应用程序的广泛项目的一部分，我们从来自不同人口统计学的拉丁裔护理人员和非护理人员以及其他人口统计学背景的护理人员和非护理人员中群集大量问题。我们研究了这个数据集中个体、文化和环境因素中介的问题提问的变化。然后我们设计了一个系统来自动产生问题。

    When caregivers ask open--ended questions to motivate dialogue with children, it facilitates the child's reading comprehension skills.Although there is scope for use of technological tools, referred here as "intelligent tutoring systems", to scaffold this process, it is currently unclear whether existing intelligent systems that generate human--language like questions is beneficial. Additionally, training data used in the development of these automated question generation systems is typically sourced without attention to demographics, but people with different cultural backgrounds may ask different questions. As a part of a broader project to design an intelligent reading support app for Latinx children, we crowdsourced questions from Latinx caregivers and noncaregivers as well as caregivers and noncaregivers from other demographics. We examine variations in question--asking within this dataset mediated by individual, cultural, and contextual factors. We then design a system that autom
    
[^7]: GPT是否会产生更不准确的翻译?

    Do GPTs Produce Less Literal Translations?. (arXiv:2305.16806v1 [cs.CL])

    [http://arxiv.org/abs/2305.16806](http://arxiv.org/abs/2305.16806)

    本研究比较了GPT和NMT生成翻译的文字积极度差异，发现GPT翻译更不准确，但在MT质量评估指标上表现出相似或更好的分数。

    

    大型语言模型（LLMs），如GPT-3，已经成为通用语言模型，能够处理许多自然语言生成或理解任务。在机器翻译（MT）任务中，已有多项研究探索利用few-shot提示机制从LLMs中引出更好的翻译。然而，人们相对较少地关注这种翻译与标准神经机器翻译（NMT）模型生成翻译的质量差异。本研究从文字对齐和单调性等方面，比较了GPT和NMT生成翻译的文本文字积极度，发现GPT从英语（E-X）翻译的文本更不准确，但在MT质量评估指标上表现出相似或更好的分数。我们证明这一结果在人工评估中也得到了验证。同时，当翻译句子长度增加时，这种差别就尤为显著。

    Large Language Models (LLMs) such as GPT-3 have emerged as general-purpose language models capable of addressing many natural language generation or understanding tasks. On the task of Machine Translation (MT), multiple works have investigated few-shot prompting mechanisms to elicit better translations from LLMs. However, there has been relatively little investigation on how such translations differ qualitatively from the translations generated by standard Neural Machine Translation (NMT) models. In this work, we investigate these differences in terms of the literalness of translations produced by the two systems. Using literalness measures involving word alignment and monotonicity, we find that translations out of English (E-X) from GPTs tend to be less literal, while exhibiting similar or better scores on MT quality metrics. We demonstrate that this finding is borne out in human evaluations as well. We then show that these differences are especially pronounced when translating senten
    
[^8]: 基于曲率和扭矩的手语视频摘要技术

    Motion-Based Sign Language Video Summarization using Curvature and Torsion. (arXiv:2305.16801v1 [cs.CV])

    [http://arxiv.org/abs/2305.16801](http://arxiv.org/abs/2305.16801)

    该论文介绍了一种基于曲率和扭矩的手语视频摘要技术，能够选出最具信息量的关键帧。

    

    视频摘要技术在很多基于视频的应用中都非常有用。本文介绍了一种新的手语视频摘要技术，该技术利用从视频帧中提取的三维手部运动数据来模型化每一帧中的三维运动。基于此，本文提出了一种基于曲率和扭矩的新型信息函数，以便选择最具信息量的关键帧。

    An interesting problem in many video-based applications is the generation of short synopses by selecting the most informative frames, a procedure which is known as video summarization. For sign language videos the benefits of using the $t$-parameterized counterpart of the curvature of the 2-D signer's wrist trajectory to identify keyframes, have been recently reported in the literature. In this paper we extend these ideas by modeling the 3-D hand motion that is extracted from each frame of the video. To this end we propose a new informative function based on the $t$-parameterized curvature and torsion of the 3-D trajectory. The method to characterize video frames as keyframes depends on whether the motion occurs in 2-D or 3-D space. Specifically, in the case of 3-D motion we look for the maxima of the harmonic mean of the curvature and torsion of the target's trajectory; in the planar motion case we seek for the maxima of the trajectory's curvature. The proposed 3-D feature is experime
    
[^9]: 是否修改：学习检测可改进论点以支持辩论写作

    To Revise or Not to Revise: Learning to Detect Improvable Claims for Argumentative Writing Support. (arXiv:2305.16799v1 [cs.CL])

    [http://arxiv.org/abs/2305.16799](http://arxiv.org/abs/2305.16799)

    这篇论文探讨了检测辩论文本中需要改进的论点的挑战，通过学习协作编辑行为捕捉隐含的修订模式来开发指导作者改进论点的方法。

    

    优化辩论文本的措辞在高等教育和职业发展中至关重要。然而，评估文本中不同论点是否需要修改及如何修改是一项困难的任务，特别是对于初学者。在这项工作中，我们探讨了识别需要特定修改的辩论论点的主要挑战。通过从在线辩论中学习协作编辑行为，我们试图捕捉隐含的修订模式，以开发旨在指导作者如何进一步改进其论点的方法。我们系统地比较了常见词嵌入模型捕捉相同文本不同版本之间差异的能力，并分析了它们对各种类型的写作问题的影响。为了应对基于修订的语料库的嘈杂性，我们提出了一种基于修订距离的新的采样策略。与先前工作的方法相反，这种采样可以在不使用额外注释和评估的情况下完成。

    Optimizing the phrasing of argumentative text is crucial in higher education and professional development. However, assessing whether and how the different claims in a text should be revised is a hard task, especially for novice writers. In this work, we explore the main challenges to identifying argumentative claims in need of specific revisions. By learning from collaborative editing behaviors in online debates, we seek to capture implicit revision patterns in order to develop approaches aimed at guiding writers in how to further improve their arguments. We systematically compare the ability of common word embedding models to capture the differences between different versions of the same text, and we analyze their impact on various types of writing issues. To deal with the noisy nature of revision-based corpora, we propose a new sampling strategy based on revision distance. Opposed to approaches from prior work, such sampling can be done without employing additional annotations and j
    
[^10]: 面向任务的对话中基于模式的用户满意度建模

    Schema-Guided User Satisfaction Modeling for Task-Oriented Dialogues. (arXiv:2305.16798v1 [cs.CL])

    [http://arxiv.org/abs/2305.16798](http://arxiv.org/abs/2305.16798)

    本文提出了一种新的基于模式的用户满意度建模框架SG-USM，它特别模拟了系统程度的满足用户关于任务属性的偏好程度，以预测用户的满意度水平。

    

    用户满意度建模（USM）是任务导向对话系统评估的一种流行选择，其中用户满意度通常取决于系统是否实现了用户的任务目标。任务导向对话系统使用任务架构（task schema）来编码用户的任务目标。现有的USM研究忽略了使用任务架构显式建模用户的任务目标实现。本文提出了一种新的基于模式的用户满意度建模框架SG-USM。它特别模拟了系统程度的满足用户关于任务属性的偏好程度，以预测用户的满意度水平。SG-USM使用预训练的语言模型来编码对话上下文和任务属性，并采用履行表示层来学习对话中完成了多少任务属性，重要性预测器用于计算任务属性的重要性，并利用注意机制选择性地关注重要任务属性以预测用户满意度。我们在任务导向对话数据集上评估了SG-USM，并显示它优于现有的USM模型。

    User Satisfaction Modeling (USM) is one of the popular choices for task-oriented dialogue systems evaluation, where user satisfaction typically depends on whether the user's task goals were fulfilled by the system. Task-oriented dialogue systems use task schema, which is a set of task attributes, to encode the user's task goals. Existing studies on USM neglect explicitly modeling the user's task goals fulfillment using the task schema. In this paper, we propose SG-USM, a novel schema-guided user satisfaction modeling framework. It explicitly models the degree to which the user's preferences regarding the task attributes are fulfilled by the system for predicting the user's satisfaction level. SG-USM employs a pre-trained language model for encoding dialogue context and task attributes. Further, it employs a fulfillment representation layer for learning how many task attributes have been fulfilled in the dialogue, an importance predictor component for calculating the importance of task 
    
[^11]: 基于Transformer模型的社交媒体压力和抑郁识别模型的校准

    Calibration of Transformer-based Models for Identifying Stress and Depression in Social Media. (arXiv:2305.16797v1 [cs.CL])

    [http://arxiv.org/abs/2305.16797](http://arxiv.org/abs/2305.16797)

    本文提出了第一个使用校准后的Transformer模型来检测社交媒体上的压力和抑郁症状的研究。

    

    在当今快节奏的生活中，压力和抑郁症的发病率呈现上升趋势。社交媒体为早期发现心理健康状况提供了帮助。现有的方法主要介绍特征提取方法并训练浅层机器学习分类器。其他研究使用深度神经网络或Transformer模型。尽管Transformer模型取得了明显的改进，但它们通常无法捕捉丰富的实际知识。虽然已经提出了许多旨在增强预训练Transformer模型的研究，但没有先前的工作利用这些修改来通过社交媒体检测压力和抑郁症。此外，尽管机器学习模型在其预测中的置信度可靠性对于高风险应用至关重要，但尚未有先前的工作考虑模型的校准。为解决以上问题，本文提出了第一个通过模型校准来检测社交媒体上的压力和抑郁症状的研究。

    In today's fast-paced world, the rates of stress and depression present a surge. Social media provide assistance for the early detection of mental health conditions. Existing methods mainly introduce feature extraction approaches and train shallow machine learning classifiers. Other researches use deep neural networks or transformers. Despite the fact that transformer-based models achieve noticeable improvements, they cannot often capture rich factual knowledge. Although there have been proposed a number of studies aiming to enhance the pretrained transformer-based models with extra information or additional modalities, no prior work has exploited these modifications for detecting stress and depression through social media. In addition, although the reliability of a machine learning model's confidence in its predictions is critical for high-risk applications, there is no prior work taken into consideration the model calibration. To resolve the above issues, we present the first study i
    
[^12]: 结合话语结构分布的长文本自动摘要方法

    Incorporating Distributions of Discourse Structure for Long Document Abstractive Summarization. (arXiv:2305.16784v1 [cs.CL])

    [http://arxiv.org/abs/2305.16784](http://arxiv.org/abs/2305.16784)

    本文提出了一种名为'RSTformer'的摘要模型，该模型全面融合了话语关系类型和不确定性，并以修辞结构理论为基础，经过严格评估，表现明显优于现有的模型。

    

    对于文本摘要，话语结构在辨识文本核心内容方面起着关键作用。可惜的是，之前将修辞结构理论（RST）引入基于transformer的自动摘要模型的研究仅考虑了核心部分的注释，从而忽略了各种不同类型的话语关系。本文提出了一种名为'RSTformer'的新型摘要模型，该模型全面融合了话语关系类型和不确定性。我们的RST-attention机制是基于文档级修辞结构的Longformer框架的扩展。经过严格评估，本文提出的模型表现明显优于现有的模型，凸显出其在多个自动评估指标和人工评估上的卓越表现。

    For text summarization, the role of discourse structure is pivotal in discerning the core content of a text. Regrettably, prior studies on incorporating Rhetorical Structure Theory (RST) into transformer-based summarization models only consider the nuclearity annotation, thereby overlooking the variety of discourse relation types. This paper introduces the 'RSTformer', a novel summarization model that comprehensively incorporates both the types and uncertainty of rhetorical relations. Our RST-attention mechanism, rooted in document-level rhetorical structure, is an extension of the recently devised Longformer framework. Through rigorous evaluation, the model proposed herein exhibits significant superiority over state-of-the-art models, as evidenced by its notable performance on several automatic metrics and human evaluation.
    
[^13]: 多语言语言模型的跨语言转移因素的共同理解：一篇综述

    Towards a Common Understanding of Contributing Factors for Cross-Lingual Transfer in Multilingual Language Models: A Review. (arXiv:2305.16768v1 [cs.CL])

    [http://arxiv.org/abs/2305.16768](http://arxiv.org/abs/2305.16768)

    本文对多语言语言模型 (MLLMs)的跨语言转移能力的不同因素进行了调查和综述，将这些因素分成五类并提供了过去研究的经验证据。本文的工作旨在全面背景和统一MLLMs跨语言转移的现有研究流。

    

    近年来，预训练的多语言语言模型（MLLMs）表现出了在不同语言之间传递知识的强大能力。然而，鉴于这种能力的追求并未明确地融入大多数MLLM设计中，很难对其出现进行独特而直接的解释。在本综述论文中，我们调查了研究MLLM的跨语言转移能力的不同因素的文献，并详细概述和讨论了这些因素。为了增强这个综述的结构并便于与未来的研究整合，我们确定了五类这样的因素。除提供过去研究的经验证据概述外，我们还确定了在具有一致发现的研究中的共识，并解决了在矛盾的研究中的冲突。我们的工作将旨在解释MLLM跨语言转移能力的现有研究流进行了全面的背景和统一。

    In recent years, pre-trained Multilingual Language Models (MLLMs) have shown a strong ability to transfer knowledge across different languages. However, given that the aspiration for such an ability has not been explicitly incorporated in the design of the majority of MLLMs, it is challenging to obtain a unique and straightforward explanation for its emergence. In this review paper, we survey literature that investigates different factors contributing to the capacity of MLLMs to perform zero-shot cross-lingual transfer and subsequently outline and discuss these factors in detail. To enhance the structure of this review and to facilitate consolidation with future studies, we identify five categories of such factors. In addition to providing a summary of empirical evidence from past studies, we identify consensuses among studies with consistent findings and resolve conflicts among contradictory ones. Our work contextualizes and unifies existing research streams which aim at explaining th
    
[^14]: 背包语言模型

    Backpack Language Models. (arXiv:2305.16765v1 [cs.CL])

    [http://arxiv.org/abs/2305.16765](http://arxiv.org/abs/2305.16765)

    背包语言模型是一种结合了强大的建模性能和可解释性的神经架构。它学习每个单词的多个非上下文感知向量，并将单词表示为上下文依赖的非负线性组合。感知向量可以被解释为单词不同的方面，并可以通过干预这些可解释的钩子以可预测的方式改变模型的行为。该模型在词汇相似性评估中表现优越，甚至优于一个6B参数的Transformer语言模型的单词嵌入。

    

    我们提出了背包（Backpacks）：一种将强大的建模性能与可解释性和控制接口结合的新型神经架构。背包学习词汇表中每个单词的多个非上下文感知向量，并将序列中的单词表示为上下文依赖的非负线性组合。我们发现，在训练后，感知向量专门化了，每个感知向量编码了单词的不同方面。我们可以通过检查感知向量在输出空间上的（非上下文，线性）投影来解释一个感知向量，并干预这些可解释的钩子以可预测的方式改变模型的行为。我们在OpenWebText上训练了一个包含170M参数的背包语言模型，与124M参数的GPT-2小型Transformer的损失相匹配。在词汇相似性评估中，我们发现背包感知向量甚至优于一个6B参数的Transformer语言模型的单词嵌入。最后，我们提出了一些简单的算法来干预感知向量，以实现特定的行为。

    We present Backpacks: a new neural architecture that marries strong modeling performance with an interface for interpretability and control. Backpacks learn multiple non-contextual sense vectors for each word in a vocabulary, and represent a word in a sequence as a context-dependent, non-negative linear combination of sense vectors in this sequence. We find that, after training, sense vectors specialize, each encoding a different aspect of a word. We can interpret a sense vector by inspecting its (non-contextual, linear) projection onto the output space, and intervene on these interpretable hooks to change the model's behavior in predictable ways. We train a 170M-parameter Backpack language model on OpenWebText, matching the loss of a GPT-2 small (124Mparameter) Transformer. On lexical similarity evaluations, we find that Backpack sense vectors outperform even a 6B-parameter Transformer LM's word embeddings. Finally, we present simple algorithms that intervene on sense vectors to perfo
    
[^15]: 利用领域知识实现包容和偏见感知的人道主义响应入口分类

    Leveraging Domain Knowledge for Inclusive and Bias-aware Humanitarian Response Entry Classification. (arXiv:2305.16756v1 [cs.CL])

    [http://arxiv.org/abs/2305.16756](http://arxiv.org/abs/2305.16756)

    本研究提出了一种以人道主义本体为基础的新型语言模型HumBert，并提供了一种系统的方法来衡量和减少偏见，以实现对人道主义数据分析的有效和道德意识的支持。

    

    在人道主义危机期间，准确和快速的情况分析对于高效地提供人道主义援助至关重要，并且是人道主义原则和不留任何人落后原则的基础。语言处理系统可以极大地受益于这种数据分析，例如，按照人道主义本体对文本数据进行分类。然而，仅仅通过微调通用的大型语言模型 (LLM) 来实现，涉及一些实践和道德问题，特别是在数据稀疏和复杂子领域上的效果不佳以及社会偏见和不良关联的编码。在这项工作中，我们旨在为人道主义数据分析提供一种有效和道德意识的系统。我们通过 (1) 引入一个适合人道主义分析框架的新架构，(2) 创建和发布一个新的人道主义特定 LLM，称为 HumBert，并且 (3) 提出了一种系统的方式来衡量和减少偏见。

    Accurate and rapid situation analysis during humanitarian crises is critical to delivering humanitarian aid efficiently and is fundamental to humanitarian imperatives and the Leave No One Behind (LNOB) principle. This data analysis can highly benefit from language processing systems, e.g., by classifying the text data according to a humanitarian ontology. However, approaching this by simply fine-tuning a generic large language model (LLM) involves considerable practical and ethical issues, particularly the lack of effectiveness on data-sparse and complex subdomains, and the encoding of societal biases and unwanted associations. In this work, we aim to provide an effective and ethically-aware system for humanitarian data analysis. We approach this by (1) introducing a novel architecture adjusted to the humanitarian analysis framework, (2) creating and releasing a novel humanitarian-specific LLM called HumBert, and (3) proposing a systematic way to measure and mitigate biases. Our experi
    
[^16]: 大型语言模型能够生成显著的负面声明吗？

    Can large language models generate salient negative statements?. (arXiv:2305.16755v1 [cs.CL])

    [http://arxiv.org/abs/2305.16755](http://arxiv.org/abs/2305.16755)

    本研究探讨了大型语言模型生成真实实体的显著负面陈述的能力，在不同领域中进行了评估，结果发现大型语言模型在处理否定陈述中的事实概念上仍有困难。

    

    我们研究了大型语言模型（LLMs）生成关于现实世界实体的显著（有趣的）负面陈述的能力; 这是过去几年中涌现出的一个研究课题。我们使用零点和k次无约束探针来探测LLMs，并与传统的否定生成方法，即基于模式的文本提取和基于知识图的推理以及众包金标语句进行比较。我们评估了来自不同领域的主题生成列表的正确性和显着性。我们的评估表明，有指导的探针确实提高了生成的负面陈述的质量，与无指导的变体相比。然而，使用这两个提示，LLMs仍然难以处理负面事实的概念，常常生成许多含糊不清的陈述，或者带有负面关键词但具有积极意义的陈述。

    We examine the ability of large language models (LLMs) to generate salient (interesting) negative statements about real-world entities; an emerging research topic of the last few years. We probe the LLMs using zero- and k-shot unconstrained probes, and compare with traditional methods for negation generation, i.e., pattern-based textual extractions and knowledge-graph-based inferences, as well as crowdsourced gold statements. We measure the correctness and salience of the generated lists about subjects from different domains. Our evaluation shows that guided probes do in fact improve the quality of generated negatives, compared to the zero-shot variant. Nevertheless, using both prompts, LLMs still struggle with the notion of factuality of negatives, frequently generating many ambiguous statements, or statements with negative keywords but a positive meaning.
    
[^17]: 自动化国际协议中制度设计分析

    Automating the Analysis of Institutional Design in International Agreements. (arXiv:2305.16750v1 [cs.CL])

    [http://arxiv.org/abs/2305.16750](http://arxiv.org/abs/2305.16750)

    本文研究了从国际协议中自动化提取正式制度设计的知识的方法，并通过对于《无形文化遗产保护公约》的测试分析了正式制度设计中参与者的可见性和重要性之间的关系。

    

    本文探讨如何自动地从国际协议中提取正式制度设计、规范、规则和参与者等知识。重点是分析规范文化遗产关系关键方面的正式制度设计中参与者的可见性和重要性之间的关系。所开发的工具采用了多种技术，如收集法律文件、用制度语法注释这些文件并使用图分析方法来探索正式制度设计。该系统对2003年《无形文化遗产保护公约》进行了测试。

    This paper explores the automatic knowledge extraction of formal institutional design - norms, rules, and actors - from international agreements. The focus was to analyze the relationship between the visibility and centrality of actors in the formal institutional design in regulating critical aspects of cultural heritage relations. The developed tool utilizes techniques such as collecting legal documents, annotating them with Institutional Grammar, and using graph analysis to explore the formal institutional design. The system was tested against the 2003 UNESCO Convention for the Safeguarding of the Intangible Cultural Heritage.
    
[^18]: 无需引入新的延迟的参数高效微调

    Parameter-Efficient Fine-Tuning without Introducing New Latency. (arXiv:2305.16742v1 [cs.CL])

    [http://arxiv.org/abs/2305.16742](http://arxiv.org/abs/2305.16742)

    本文提出了一种参数高效微调的方法，以任务不可知的方式生成稀疏掩码，无需添加新参数，避免了额外的推断延迟，并超过了现有方法的效果。

    

    预训练语言模型的参数高效微调（PEFT）最近展示出明显的成就，有效地匹配了完全微调的性能，同时利用明显更少的可训练参数，因此解决了存储和通信限制。尽管如此，各种PEFT方法仍受其固有特性的限制。在稀疏微调的情况下，这只涉及修改现有参数的一小部分，微调参数的选择是任务和领域特定的，因此不适用于联合学习。另一方面，添加新参数的PEFT方法通常会引入额外的推断延迟。在本文中，我们展示了以任务不可知的方式生成稀疏掩码的可行性，其中所有下游任务共享相同的掩码。我们的方法仅依赖于预训练参数的幅度信息，超过了现有方法学的效果。

    Parameter-efficient fine-tuning (PEFT) of pre-trained language models has recently demonstrated remarkable achievements, effectively matching the performance of full fine-tuning while utilizing significantly fewer trainable parameters, and consequently addressing the storage and communication constraints. Nonetheless, various PEFT methods are limited by their inherent characteristics. In the case of sparse fine-tuning, which involves modifying only a small subset of the existing parameters, the selection of fine-tuned parameters is task- and domain-specific, making it unsuitable for federated learning. On the other hand, PEFT methods with adding new parameters typically introduce additional inference latency. In this paper, we demonstrate the feasibility of generating a sparse mask in a task-agnostic manner, wherein all downstream tasks share a common mask. Our approach, which relies solely on the magnitude information of pre-trained parameters, surpasses existing methodologies by a si
    
[^19]: 在动词省略结构中的并列解析

    Conjunct Resolution in the Face of Verbal Omissions. (arXiv:2305.16740v1 [cs.CL])

    [http://arxiv.org/abs/2305.16740](http://arxiv.org/abs/2305.16740)

    本文提出了一个直接在文本中操作的并列解析任务，并利用分割和重构范例来恢复并列结构中缺失的元素。基于实用的动词省略框架，我们整理了一份由真实语料库构成的数据集，用于评估并比较现有解析技术。

    

    动词省略是VP并列结构中复杂的句法现象。当动词及其（一些）论元在初始子句中得到明确说明后，在随后的子句中被省略时，就会出现这种现象。恢复这些省略元素对于准确解释句子是必要的，虽然人类很容易而且直观地填充缺失信息，但最先进的模型仍然难以完成这项任务。以往的工作仅限于小规模数据集、合成数据创建方法和依赖图级别的解析方法。在本文中，我们提出了一个直接在文本中操作的并列解析任务，并利用分割和重构范例来恢复并列结构中缺失的元素。为此，我们首先制定了一个实用的动词省略框架，描述了不同类型的省略，并开发了一种自动可扩展的收集方法。基于这种方法，我们整理了一份由真实语料库构成的数据集，用于评估并比较现有解析技术。

    Verbal omissions are complex syntactic phenomena in VP coordination structures. They occur when verbs and (some of) their arguments are omitted from subsequent clauses after being explicitly stated in an initial clause. Recovering these omitted elements is necessary for accurate interpretation of the sentence, and while humans easily and intuitively fill in the missing information, state-of-the-art models continue to struggle with this task. Previous work is limited to small-scale datasets, synthetic data creation methods, and to resolution methods in the dependency-graph level. In this work we propose a conjunct resolution task that operates directly on the text and makes use of a split-and-rephrase paradigm in order to recover the missing elements in the coordination structure. To this end, we first formulate a pragmatic framework of verbal omissions which describes the different types of omissions, and develop an automatic scalable collection method. Based on this method, we curate 
    
[^20]: AlignScore：使用统一的对齐函数评估事实一致性

    AlignScore: Evaluating Factual Consistency with a Unified Alignment Function. (arXiv:2305.16739v1 [cs.CL])

    [http://arxiv.org/abs/2305.16739](http://arxiv.org/abs/2305.16739)

    本文提出了AlignScore，一种新的综合度量标准，旨在评估各种事实不一致性情况。该方法基于两个文本片段之间的信息对齐，可以适用于不同任务的不同输入/输出。

    

    许多文本生成应用需要生成的文本与输入信息在事实上保持一致。然而，事实一致性的自动评估具有挑战性。先前的工作已经开发出了各种度量标准，通常依赖于特定的函数，例如自然语言推理（NLI）或问答（QA），这些函数在有限的数据上训练。这些度量标准因此难以评估不同的事实不一致性情况（例如矛盾、幻觉），这些情况发生在不同任务的不同输入/输出（例如句子、文档）中。在本文中，我们提出了AlignScore，这是一种适用于各种事实不一致性情况的新型综合度量标准。AlignScore是基于两个任意文本片段之间的信息对齐的一般函数。关键是，我们开发了一个统一的训练框架来集成大量数据源的对齐函数，从而得到了来自7个知名任务（NLI、QA、文章改写、工作场景文本等）的4.7M个训练示例。

    Many text generation applications require the generated text to be factually consistent with input information. Automatic evaluation of factual consistency is challenging. Previous work has developed various metrics that often depend on specific functions, such as natural language inference (NLI) or question answering (QA), trained on limited data. Those metrics thus can hardly assess diverse factual inconsistencies (e.g., contradictions, hallucinations) that occur in varying inputs/outputs (e.g., sentences, documents) from different tasks. In this paper, we propose AlignScore, a new holistic metric that applies to a variety of factual inconsistency scenarios as above. AlignScore is based on a general function of information alignment between two arbitrary text pieces. Crucially, we develop a unified training framework of the alignment function by integrating a large diversity of data sources, resulting in 4.7M training examples from 7 well-established tasks (NLI, QA, paraphrasing, fac
    
[^21]: AMPERE: 面向AMR的前缀生成事件论元抽取模型

    AMPERE: AMR-Aware Prefix for Generation-Based Event Argument Extraction Model. (arXiv:2305.16734v1 [cs.CL])

    [http://arxiv.org/abs/2305.16734](http://arxiv.org/abs/2305.16734)

    本论文提出了一种名为AMPERE的方法，面向AMR的前缀生成事件论元抽取模型，该模型成功引入了AMR的信息，提升了生成式模型的性能和泛化能力。

    

    事件论元抽取旨在识别某事件的论元及其特定的角色。生成式的事件论元抽取模型相比于分类式模型表现出更好的性能和泛化能力。但是，目前的生成式模型主要关注问题重新表述和提示设计，没有整合其他在分类式模型中已被证明有效的信息（如输入段落的抽象意义表示AMR）。由于生成式模型中通常使用自然语言形式，而AMR是一种结构化形式，因此将这样的信息整合到生成式模型中具有挑战性。本文研究了将AMR整合到生成式事件论元抽取模型中的策略。我们提出了AMPERE，为生成模型的每层生成AMR感知前缀。因此，该前缀为生成式的事件论元抽取模型引入了AMR信息。

    Event argument extraction (EAE) identifies event arguments and their specific roles for a given event. Recent advancement in generation-based EAE models has shown great performance and generalizability over classification-based models. However, existing generation-based EAE models mostly focus on problem re-formulation and prompt design, without incorporating additional information that has been shown to be effective for classification-based models, such as the abstract meaning representation (AMR) of the input passages. Incorporating such information into generation-based models is challenging due to the heterogeneous nature of the natural language form prevalently used in generation-based models and the structured form of AMRs. In this work, we study strategies to incorporate AMR into generation-based EAE models. We propose AMPERE, which generates AMR-aware prefixes for every layer of the generation model. Thus, the prefix introduces AMR information to the generation-based EAE model 
    
[^22]: 识别情感体验者作为情感分析的先决条件

    Emotion Experiencer Recognition as a Prerequisite for Experiencer-Specific Emotion Analysis. (arXiv:2305.16731v1 [cs.CL])

    [http://arxiv.org/abs/2305.16731](http://arxiv.org/abs/2305.16731)

    本文提出了一种用于检测情感体验者并为其分配情感的自动方法，并进行了相关的实验。该方法的实现具有挑战性，但展示了在文本中检测情感体验者的可行性。

    

    情感角色标注旨在提取文本中描述谁经历情感、为什么以及对谁的信息。这通常是一个具有挑战性的建模任务，如果要回答的主要问题是谁感受到了哪种情感，这可能会过于复杂。本文填补了这一空白，通过自动检测文本中的情感体验者并随后为其分配情感，展示了在文本中检测情感体验者是一项具有挑战性的任务，并呈现了相关的实验结果。

    Emotion role labeling aims at extracting who is described in text to experience an emotion, why, and towards whom. This is often a challenging modelling task which might be overly sophisticated if the main question to answer is who feels which emotion. Recently, Troiano et al. (2022) proposed a data set that focuses on assigning emotion labels and appraisal labels to individual entities in text and Wegge et al. (2022) presented the first modelling experiments. Their experiencer-specific emotion prediction model has, however, only been evaluated on gold-annotated experiencers, due to the unavailability of an automatic experiencer detection approach. We fill this gap with the first experiments to automatically detect emotion experiencers in text and, subsequently, assign them emotions. We show that experiencer detection in text is a challenging task, with a precision of .82 and a recall of .56 (F1 =.66). Consequently, the performance of the experiencer-specific emotion detection pipeline
    
[^23]: 未见过的语言对中的混合代码文本合成

    Code-Switched Text Synthesis in Unseen Language Pairs. (arXiv:2305.16724v1 [cs.CL])

    [http://arxiv.org/abs/2305.16724](http://arxiv.org/abs/2305.16724)

    本文介绍了GLOSS模型，旨在解决在缺乏训练数据的情况下合成混合代码文本的问题，并且可以推广到更广泛的语言对。该模型在四个未见过的语言对上的实验中优于其他基线模型和在单语文本上运行的生成模型。

    

    现有的针对混合代码文本合成的研究大多需要在目标语言对中的混合代码文本上进行训练，这限制了模型在缺乏混合代码数据的情况下的部署。在本文中，我们研究了在缺乏训练数据的情况下合成混合代码文本的问题。我们介绍了GLOSS，这是一个建立在预训练多语言机器翻译模型（PMMTM）之上，并带有额外的代码切换模块的模型。这个模块，无论是适配器还是额外的前缀，在训练过程中从混合代码数据中学习代码切换模式，而GLOSS的主要组成部分PMMTM被冻结。我们只调整代码切换模块的设计，防止模型过度拟合针对混合代码训练数据的约束。因此，GLOSS表现出了跨更广泛的语言对进行归纳和合成混合代码文本的能力。此外，我们还开发了一种基于目标语言单语文本的自训练算法，以提高模型性能。我们对四个未见过的语言对进行的实验证明，GLOSS优于其他从具有混合代码数据的语言对中调整的模型和在单语文本上运行的生成模型等多个基线模型。

    Existing efforts on text synthesis for code-switching mostly require training on code-switched texts in the target language pairs, limiting the deployment of the models to cases lacking code-switched data. In this work, we study the problem of synthesizing code-switched texts for language pairs absent from the training data. We introduce GLOSS, a model built on top of a pre-trained multilingual machine translation model (PMMTM) with an additional code-switching module. This module, either an adapter or extra prefixes, learns code-switching patterns from code-switched data during training, while the primary component of GLOSS, i.e., the PMMTM, is frozen. The design of only adjusting the code-switching module prevents our model from overfitting to the constrained training data for code-switching. Hence, GLOSS exhibits the ability to generalize and synthesize code-switched texts across a broader spectrum of language pairs. Additionally, we develop a self-training algorithm on target langu
    
[^24]: 历史欧洲的人与地方：引导注释管道和一个新的命名实体语料库在晚期中世纪文本中

    People and Places of Historical Europe: Bootstrapping Annotation Pipeline and a New Corpus of Named Entities in Late Medieval Texts. (arXiv:2305.16718v1 [cs.CL])

    [http://arxiv.org/abs/2305.16718](http://arxiv.org/abs/2305.16718)

    该论文提出了一个新的NER语料库，从未注释的历史文本中引导注释管道，并训练了一个NER模型来识别历史文献中的人名和地名，实现了较高的精度和召回率。

    

    虽然预先训练的命名实体识别（NER）模型对现代语料库非常准确，但由于OCR错误和语言差异，它们在历史文本上表现不佳。在这项工作中，我们开发了一个新的NER语料库，其中包含36万个句子，主要是使用捷克语、拉丁语和德语编写的晚期中世纪文书。我们展示了我们可以从已知的历史人物和地点列表以及未注释的历史文本中开始，并使用信息检索技术自动引导NER注释的语料库。利用我们的语料库，我们训练了一个NER模型，它在手动注释的测试数据集上实现了72.81-93.98％的实体级精度和58.14-81.77％的召回率。此外，我们展示了使用加权损失函数可以帮助应对标记分类任务中的类别不平衡。为了使其他人能够重现和建立我们的工作，我们公开发布了我们的语料库，模型和实验代码。

    Although pre-trained named entity recognition (NER) models are highly accurate on modern corpora, they underperform on historical texts due to differences in language OCR errors. In this work, we develop a new NER corpus of 3.6M sentences from late medieval charters written mainly in Czech, Latin, and German.  We show that we can start with a list of known historical figures and locations and an unannotated corpus of historical texts, and use information retrieval techniques to automatically bootstrap a NER-annotated corpus. Using our corpus, we train a NER model that achieves entity-level Precision of 72.81-93.98% with 58.14-81.77% Recall on a manually-annotated test dataset. Furthermore, we show that using a weighted loss function helps to combat class imbalance in token classification tasks. To make it easy for others to reproduce and build upon our work, we publicly release our corpus, models, and experimental code.
    
[^25]: PIP：语法控制的释义生成的解析指导前缀

    PIP: Parse-Instructed Prefix for Syntactically Controlled Paraphrase Generation. (arXiv:2305.16701v1 [cs.CL])

    [http://arxiv.org/abs/2305.16701](http://arxiv.org/abs/2305.16701)

    使用Parse-Instructed Prefix的语法控制释义生成的计算成本降低了10倍，并在两个benchmark上达到了最先进的性能表现。

    

    语法控制的释义生成需要语言模型根据特定的语法结构为句子生成释义。现有的fine-tuning方法需要更新模型的所有参数，成本高昂。在参数有效学习的最新研究的启发下，我们提出了Parse-Instructed Prefix (PIP),这是一种新颖的前缀调整方法，可在低数据设置中调整大型预训练语言模型，显着降低训练成本。 我们介绍了两种方法来指导模型的编码器前缀捕获语法相关知识：直接初始化（PIP-Direct）和间接优化（PIP-Indirect）。与传统的fine-tuning方法相比，PIP是一种低计算成本的替代方法，具有10倍更少的可学习参数。与现有的前缀调整方法相比，PIP在捕获语法控制信息方面表现出色，这得益于将语法解析树作为指导前缀。实验结果表明，PIP在两个语法控制的释义生成基准测试中实现了最先进的性能，同时只需要很少的训练数据和时间。

    Syntactically controlled paraphrase generation requires language models to generate paraphrases for sentences according to specific syntactic structures. Existing fine-tuning methods for this task are costly as all the parameters of the model need to be updated during the training process. Inspired by recent studies on parameter-efficient learning, we propose Parse-Instructed Prefix (PIP), a novel adaptation of prefix-tuning to tune large pre-trained language models on syntactically controlled paraphrase generation task in a low-data setting with significantly less training cost. We introduce two methods to instruct a model's encoder prefix to capture syntax-related knowledge: direct initiation (PIP-Direct) and indirect optimization (PIP-Indirect). In contrast to traditional fine-tuning methods for this task, PIP is a compute-efficient alternative with 10 times less learnable parameters. Compared to existing prefix-tuning methods, PIP excels at capturing syntax control information, ach
    
[^26]: DKAF：用于具有对话-KB不一致性的任务导向对话系统的KB仲裁

    DKAF: KB Arbitration for Learning Task-Oriented Dialog Systems with Dialog-KB Inconsistencies. (arXiv:2305.16697v1 [cs.CL])

    [http://arxiv.org/abs/2305.16697](http://arxiv.org/abs/2305.16697)

    本文提出了一个对话-KB仲裁框架（DKAF），可以预测每个训练对话的当代KB快照从而减少对话-KB不一致性。并且，在新建立的基准测试中，实验结果表明DKAF方法优于现有基线，并提高了TOD代理的鲁棒性。

    

    任务导向的对话系统通常会将其响应基于外部知识库（KB）。这些KB可能是动态的，可能经常更新。现有的学习TOD代理的方法假定在训练期间，可用于每个单独对话的KB快照是可用的。然而，在实际情况下，只有最新的KB快照可用于训练，因此，训练对话可能包含与最新KB冲突的事实。在训练数据中的这些对话-KB不一致可能会使TOD代理学习算法混淆。在这项工作中，我们定义了在训练数据中具有对话-KB不一致性的学习TOD代理的新问题。我们提出了一种对话-KB仲裁框架（DKAF），通过预测每个训练对话的当代KB快照来减少对话-KB不一致性。然后，这些预测的KB快照用于训练下游TOD代理。由于没有对话-KB不一致的现有数据集，我们还创建了一个新的基准来评估存在这种不一致性的TOD代理。新基准上的实验结果表明，我们提出的DKAF方法优于现有基线，并提高了TOD代理抵御对话-KB不一致性的鲁棒性。

    Task-oriented dialog (TOD) agents often ground their responses on external knowledge bases (KBs). These KBs can be dynamic and may be updated frequently. Existing approaches for learning TOD agents assume the KB snapshot contemporary to each individual dialog is available during training. However, in real-world scenarios, only the latest KB snapshot is available during training and as a result, the train dialogs may contain facts conflicting with the latest KB. These dialog-KB inconsistencies in the training data may potentially confuse the TOD agent learning algorithm.  In this work, we define the novel problem of learning a TOD agent with dialog-KB inconsistencies in the training data. We propose a Dialog-KB Arbitration Framework (DKAF) which reduces the dialog-KB inconsistencies by predicting the contemporary KB snapshot for each train dialog. These predicted KB snapshots are then used for training downstream TOD agents. As there are no existing datasets with dialog-KB inconsistenci
    
[^27]: 多视角标识增强生成式检索

    Multiview Identifiers Enhanced Generative Retrieval. (arXiv:2305.16675v1 [cs.CL])

    [http://arxiv.org/abs/2305.16675](http://arxiv.org/abs/2305.16675)

    该论文提出了一种新型的基于合成标识符的多视角标识符来增强生成式检索，从而提高了检索结果的准确性和多样性。

    

    与其简单地将查询与现有段落匹配，生成式检索生成段落的标识符字符串作为检索目标。然而，这种标识符必须足够独特以代表一个段落。当前的方法使用数字ID或文本片段（如标题或子字符串）作为标识符。然而，这些标识符不能很好地覆盖一个段落的内容。因此，我们提出了一种新类型的标识符，即基于段落内容生成的合成标识符，可以整合文本片段缺乏的情境信息。此外，我们同时考虑多视角标识符，包括合成标识符、标题和子字符串。这些标识符的视角相互补充，有助于从多个角度综合排名段落。我们在三个公共数据集上进行了一系列实验，结果表明我们提出的方法在生成式检索中表现最佳。

    Instead of simply matching a query to pre-existing passages, generative retrieval generates identifier strings of passages as the retrieval target. At a cost, the identifier must be distinctive enough to represent a passage. Current approaches use either a numeric ID or a text piece (such as a title or substrings) as the identifier. However, these identifiers cannot cover a passage's content well. As such, we are motivated to propose a new type of identifier, synthetic identifiers, that are generated based on the content of a passage and could integrate contextualized information that text pieces lack. Furthermore, we simultaneously consider multiview identifiers, including synthetic identifiers, titles, and substrings. These views of identifiers complement each other and facilitate the holistic ranking of passages from multiple perspectives. We conduct a series of experiments on three public datasets, and the results indicate that our proposed approach performs the best in generative 
    
[^28]: 多方面发音评估的分数平衡损失

    Score-balanced Loss for Multi-aspect Pronunciation Assessment. (arXiv:2305.16664v1 [cs.CL])

    [http://arxiv.org/abs/2305.16664](http://arxiv.org/abs/2305.16664)

    本文提出了一种分数平衡损失函数，该损失函数可以解决自动发音评估领域中极度不平衡的数据标签问题，该方法通过重新加权的方式，有效地对稀疏分数预测进行正面反馈。

    

    随着技术的迅速增长，自动发音评估已经向评估流畅度和重音等多个方面评价发音的系统过渡。然而，尽管每个方面内的分数标签高度不平衡，但现有的研究很少解决数据不平衡的问题。在本文中，我们提出了一种新的损失函数——分数平衡损失，以解决不均匀数据造成的问题，例如对多数分数的偏置。作为一种重新加权的方法，当预测分数属于少数类时，我们分配更高的成本，从而引导模型对稀疏分数预测获得正面反馈。具体而言，我们设计了两个加权因子，利用了有效样本数的概念和分数的排名。我们在 speechocean762 数据集上评估了我们的方法，该数据集在若干方面具有明显的不平衡分数。改进结果尤其在这种不平衡的方面表明了我们方法的有效性。

    With rapid technological growth, automatic pronunciation assessment has transitioned toward systems that evaluate pronunciation in various aspects, such as fluency and stress. However, despite the highly imbalanced score labels within each aspect, existing studies have rarely tackled the data imbalance problem. In this paper, we suggest a novel loss function, score-balanced loss, to address the problem caused by uneven data, such as bias toward the majority scores. As a re-weighting approach, we assign higher costs when the predicted score is of the minority class, thus, guiding the model to gain positive feedback for sparse score prediction. Specifically, we design two weighting factors by leveraging the concept of an effective number of samples and using the ranks of scores. We evaluate our method on the speechocean762 dataset, which has noticeably imbalanced scores for several aspects. Improved results particularly on such uneven aspects prove the effectiveness of our method.
    
[^29]: GDA: 用于关系抽取任务的生成式数据增强技术

    GDA: Generative Data Augmentation Techniques for Relation Extraction Tasks. (arXiv:2305.16663v1 [cs.CL])

    [http://arxiv.org/abs/2305.16663](http://arxiv.org/abs/2305.16663)

    GDA是一个专门用于关系文本增强的技术，通过采用两个互补模块，保持语义和语法结构的一致性，并使用实体提示扩展上下文。实验结果表明GDA超越了现有增强技术，实现了最先进的性能。

    

    在给定足够的训练标注时，关系抽取任务可以在句子中提取出两个实体之间的关系，表现出良好的性能。然而在实践中获得这种标注是费力的。现有的方法采用数据增强技术，在限制的标注范围之外生成伪标注句子。当采用基于规则的增强时，这些技术无法保持原始句子的语义一致性，并且在使用seq2seq模型表达关系时无法保持句子的语法结构， resulting in less diverse augmentations 。本文提出一个专门针对关系文本的增强技术，称为GDA，它使用两个互补模块来保持语义一致性和语法结构。我们采用生成式公式，并设计一个多任务解决方案以实现协同效应。此外，GDA采用实体提示作为生成模型的先验知识，将实体的上下文扩展到句子中。实验结果表明，GDA在两个公共数据集NYT10和SemEval2010 Task 8上实现了最先进的性能，并超越了现有的数据增强技术。

    Relation extraction (RE) tasks show promising performance in extracting relations from two entities mentioned in sentences, given sufficient annotations available during training. Such annotations would be labor-intensive to obtain in practice. Existing work adopts data augmentation techniques to generate pseudo-annotated sentences beyond limited annotations. These techniques neither preserve the semantic consistency of the original sentences when rule-based augmentations are adopted, nor preserve the syntax structure of sentences when expressing relations using seq2seq models, resulting in less diverse augmentations. In this work, we propose a dedicated augmentation technique for relational texts, named GDA, which uses two complementary modules to preserve both semantic consistency and syntax structures. We adopt a generative formulation and design a multi-tasking solution to achieve synergies. Furthermore, GDA adopts entity hints as the prior knowledge of the generative model to augm
    
[^30]: AdaPlanner:自适应规划与语言模型的反馈。 （arXiv：2305.16653v1 [cs.CL]）

    AdaPlanner: Adaptive Planning from Feedback with Language Models. (arXiv:2305.16653v1 [cs.CL])

    [http://arxiv.org/abs/2305.16653](http://arxiv.org/abs/2305.16653)

    LLM代理可以通过Adaplanner自适应改进自己的计划以应对环境反馈，为此提出计划内外的改进策略以及代码风格的LLM提示结构和技能发现机制。

    

    最近的大型语言模型（LLM）展示了在序列决策任务中作为自主代理的潜力。然而，大多数现有方法要么贪婪地采取行动而没有计划，要么依赖于不可适应环境反馈的静态计划。因此，随着问题复杂性和计划水平的增加，LLM代理的顺序决策性能会退化。我们提出了一种闭环方法AdaPlanner，它允许LLM代理根据环境反馈自适应地改进其自动生成的计划。在AdaPlanner中，LLM代理通过计划内和计划外的改进策略自适应地改进其计划。为了减轻幻觉，我们开发了一种代码风格的LLM提示结构，促进了跨各种任务，环境和代理能力的计划生成。此外，我们提出了一种技能发现机制，利用成功的计划作为少量示例，使计划更具普适性。

    Large language models (LLMs) have recently demonstrated the potential in acting as autonomous agents for sequential decision-making tasks. However, most existing methods either take actions greedily without planning or rely on static plans that are not adaptable to environmental feedback. Consequently, the sequential decision-making performance of LLM agents degenerates with problem complexity and plan horizons increase. We propose a closed-loop approach, AdaPlanner, which allows the LLM agent to refine its self-generated plan adaptively in response to environmental feedback. In AdaPlanner, the LLM agent adaptively refines its plan from feedback with both in-plan and out-of-plan refinement strategies. To mitigate hallucination, we develop a code-style LLM prompt structure that facilitates plan generation across a variety of tasks, environments, and agent capabilities. Furthermore, we propose a skill discovery mechanism that leverages successful plans as few-shot exemplars, enabling the
    
[^31]: TADA:英语任务不可知方言适配器

    TADA: Task-Agnostic Dialect Adapters for English. (arXiv:2305.16651v1 [cs.CL])

    [http://arxiv.org/abs/2305.16651](http://arxiv.org/abs/2305.16651)

    本论文提出了一种简单而有效的方法，即任务不可知方言适配器（TADA），通过使用适配器对齐非标准美式英语方言，并将它们与标准美式英语的任务特定适配器组合，从而实现了任务不可知的方言适应，提高了方言英语NLP的广泛可扩展性。

    

    大型语言模型，是自然语言处理（NLP）应用的主要出发点，但是对于标准美式英语以外的其他英语方言的使用者，其失败率较高。先前的工作使用特定任务数据或合成数据增强来解决这个问题，但这两种方法都需要针对每个方言和任务对进行干预，这使得鲁棒的方言英语NLP的广泛采用存在可扩展性问题。我们提出了一种简单而有效的方法，通过使用适配器对齐非标准美式英语方言，并将它们与标准美式英语的任务特定适配器组合，从而实现了任务不可知的方言适应。任务不可知方言适配器（TADA）在没有特定任务监督的情况下，提高了GLUE基准测试的4个方言变体的方言适应能力。

    Large Language Models, the dominant starting point for Natural Language Processing (NLP) applications, fail at a higher rate for speakers of English dialects other than Standard American English (SAE). Prior work addresses this using task-specific data or synthetic data augmentation, both of which require intervention for each dialect and task pair. This poses a scalability issue that prevents the broad adoption of robust dialectal English NLP. We introduce a simple yet effective method for task-agnostic dialect adaptation by aligning non-SAE dialects using adapters and composing them with task-specific adapters from SAE. Task-Agnostic Dialect Adapters (TADA) improve dialectal robustness on 4 dialectal variants of the GLUE benchmark without task-specific supervision.
    
[^32]: 戏剧对话梳理

    Dramatic Conversation Disentanglement. (arXiv:2305.16648v1 [cs.CL])

    [http://arxiv.org/abs/2305.16648](http://arxiv.org/abs/2305.16648)

    本文提出了一个用于研究电影和电视剧中语用模式的新数据集，并比较了几种梳理模型的性能，结果表明由女演员扮演的角色虽然少见，但它们更容易启动新的对话线索。

    

    本文提出了一个新的数据集，用于研究电影和电视剧中的对话梳理。与以往的研究重点放在 IRC 聊天室对话上的对话梳理不同，电影和电视剧提供了一个研究面对面多方互动中复杂的语用模式的空间。本文借鉴社会语言学、社会学和电影研究的理论研究，将话题和讨论次序的概念落实到戏剧文本的对话线索上，并使用该定义对包括 831 部电影的共计 10,033 段对话进行了数据集注释。我们比较了该戏剧数据集上几种梳理模型的性能，并将最佳性能模型应用于梳理了 808 部电影。与预期相反，我们发现过去 40 年的平均对话线索长度并没有显著减少，且由女演员扮演的角色虽然少见，但它们更容易启动新的对话线索。

    We present a new dataset for studying conversation disentanglement in movies and TV series. While previous work has focused on conversation disentanglement in IRC chatroom dialogues, movies and TV shows provide a space for studying complex pragmatic patterns of floor and topic change in face-to-face multi-party interactions. In this work, we draw on theoretical research in sociolinguistics, sociology, and film studies to operationalize a conversational thread (including the notion of a floor change) in dramatic texts, and use that definition to annotate a dataset of 10,033 dialogue turns (comprising 2,209 threads) from 831 movies. We compare the performance of several disentanglement models on this dramatic dataset, and apply the best-performing model to disentangle 808 movies. We see that, contrary to expectation, average thread lengths do not decrease significantly over the past 40 years, and characters portrayed by actors who are women, while underrepresented, initiate more new conv
    
[^33]: 语言模型可以通过少样本的绝对推理来提高事件预测

    Language Models Can Improve Event Prediction by Few-Shot Abductive Reasoning. (arXiv:2305.16646v1 [cs.CL])

    [http://arxiv.org/abs/2305.16646](http://arxiv.org/abs/2305.16646)

    本文提出了一个建模和预测框架，在少样本情况下使用语言模型的绝对推理能力来提高事件序列模型的预测精度，经过实验证实可以明显优于最先进的事件序列模型。

    

    大型语言模型在各种推理任务上表现出惊人的性能。本文研究它们是否可以推理现实世界中的事件，帮助提高事件序列模型的预测精度。我们设计了一个建模和预测框架，其中大型语言模型执行绝对推理以辅助事件序列模型：事件模型在给定过去的情况下提出未来事件的预测; 在几个专家注释示范的指导下，语言模型学会了为每个提议提供可能的原因; 一个搜索模块找到与原因匹配的先前事件; 一个评分函数学会检查检索到的事件是否实际上可以导致提议。通过在两个具有挑战性的现实世界数据集（亚马逊评论和GDELT）上进行广泛的实验，我们证明了我们的框架 - 由于语言模型的推理能力 - 可以在低数据情况下明显优于最先进的事件序列模型。

    Large language models have shown astonishing performance on a wide range of reasoning tasks. In this paper, we investigate whether they could reason about real-world events and help improve the prediction accuracy of event sequence models. We design a modeling and prediction framework where a large language model performs abductive reasoning to assist an event sequence model: the event model proposes predictions on future events given the past; instructed by a few expert-annotated demonstrations, the language model learns to suggest possible causes for each proposal; a search module finds out the previous events that match the causes; a scoring function learns to examine whether the retrieved events could actually cause the proposal. Through extensive experiments on two challenging real-world datasets (Amazon Review and GDELT), we demonstrate that our framework -- thanks to the reasoning ability of language models -- could significantly outperform the state-of-the-art event sequence mo
    
[^34]: 童话是否公平？分析儿童童话的时间叙事事件链中的性别偏见。

    Are Fairy Tales Fair? Analyzing Gender Bias in Temporal Narrative Event Chains of Children's Fairy Tales. (arXiv:2305.16641v1 [cs.CL])

    [http://arxiv.org/abs/2305.16641](http://arxiv.org/abs/2305.16641)

    本论文提出了一种计算机分析方法，通过事件叙述结构自动分析童话的社会偏见，为分析提供动词事件注释方案，并以性别为例进行了案例研究。

    

    社会偏见和刻板印象在我们的文化中通过故事存在，这在人文和社会科学文献中得到确认。我们的工作加入了这种跨学科的努力，并在分析故事中的社会偏见时考虑了事件叙述结构。我们提出了一个新颖的计算机分析方法，自动提取故事时间叙事下每个角色的基于动词的事件链和角色属性，如性别。

    Social biases and stereotypes are embedded in our culture in part through their presence in our stories, as evidenced by the rich history of humanities and social science literature analyzing such biases in children stories. Because these analyses are often conducted manually and at a small scale, such investigations can benefit from the use of more recent natural language processing methods that examine social bias in models and data corpora. Our work joins this interdisciplinary effort and makes a unique contribution by taking into account the event narrative structures when analyzing the social bias of stories. We propose a computational pipeline that automatically extracts a story's temporal narrative verb-based event chain for each of its characters as well as character attributes such as gender. We also present a verb-based event annotation scheme that can facilitate bias analysis by including categories such as those that align with traditional stereotypes. Through a case study 
    
[^35]: 对抗多任务学习用于端到端隐喻检测

    Adversarial Multi-task Learning for End-to-end Metaphor Detection. (arXiv:2305.16638v1 [cs.CL])

    [http://arxiv.org/abs/2305.16638](http://arxiv.org/abs/2305.16638)

    本文提出了一个对抗多任务学习框架，将基本意义鉴别的知识转移到隐喻检测中，缓解了数据稀缺问题，并在四个公共数据集上取得了竞争性的结果。

    

    隐喻检测（MD）受限于有限的训练数据。本文从一个称为隐喻识别程序的语言规则开始，然后提出了一个新颖的多任务学习框架，将基本意义鉴别（BSD）的知识转移到MD中。BSD建立在词义消歧（WSD）的基础上，后者拥有丰富的数据。我们利用对抗性训练将MD和BSD在相同的特征空间中的数据分布对齐，从而可以学习到任务不变表示。为了捕捉精细的对齐模式，我们利用了MD和BSD的多模态结构。我们的方法完全端到端，可以缓解MD中的数据稀缺问题。我们在四个公共数据集上报告了具有竞争力的结果。我们的代码和数据集是可用的。

    Metaphor detection (MD) suffers from limited training data. In this paper, we started with a linguistic rule called Metaphor Identification Procedure and then proposed a novel multi-task learning framework to transfer knowledge in basic sense discrimination (BSD) to MD. BSD is constructed from word sense disambiguation (WSD), which has copious amounts of data. We leverage adversarial training to align the data distributions of MD and BSD in the same feature space, so task-invariant representations can be learned. To capture fine-grained alignment patterns, we utilize the multi-mode structures of MD and BSD. Our method is totally end-to-end and can mitigate the data scarcity problem in MD. Competitive results are reported on four public datasets. Our code and datasets are available.
    
[^36]: DataFinder: 从自然语言描述中推荐科学数据集

    DataFinder: Scientific Dataset Recommendation from Natural Language Descriptions. (arXiv:2305.16636v1 [cs.IR])

    [http://arxiv.org/abs/2305.16636](http://arxiv.org/abs/2305.16636)

    DataFinder能够根据自然语言描述推荐相关数据集，解决科学家在现有数据集中寻找合适数据集的困难。

    

    现代机器学习依赖于数据集来开发和验证研究想法。鉴于公开可用数据的增长，找到合适的数据集变得越来越困难。任何研究问题对能够回答这个问题的数据集的要求都有明确和隐含的限制，例如数据集大小、模态和领域。我们引入了一项新任务，即在给定一个研究想法的简短自然语言描述的情况下推荐相关数据集，以帮助人们找到符合他们需求的相关数据集。数据集推荐存在独特的信息检索问题，数据集很难直接索引进行搜索，也没有现成的语料库用于这个任务。为了实现这个任务，我们构建了DataFinder数据集，其中包括一个自动构建的较大训练集（17500个查询）和一个较小的专家注释的评估集（392个查询）。利用这些数据，我们比较了各种信息检索模型。

    Modern machine learning relies on datasets to develop and validate research ideas. Given the growth of publicly available data, finding the right dataset to use is increasingly difficult. Any research question imposes explicit and implicit constraints on how well a given dataset will enable researchers to answer this question, such as dataset size, modality, and domain. We introduce a new task of recommending relevant datasets given a short natural language description of a research idea, to help people find relevant datasets for their needs. Dataset recommendation poses unique challenges as an information retrieval problem; datasets are hard to directly index for search and there are no corpora readily available for this task. To operationalize this task, we build the DataFinder Dataset which consists of a larger automatically-constructed training set (17.5K queries) and a smaller expert-annotated evaluation set (392 queries). Using this data, we compare various information retrieval 
    
[^37]: 零基础大语言模型在金融任务中的表现基准测试

    Zero is Not Hero Yet: Benchmarking Zero-Shot Performance of LLMs for Financial Tasks. (arXiv:2305.16633v1 [cs.CL])

    [http://arxiv.org/abs/2305.16633](http://arxiv.org/abs/2305.16633)

    研究比较了零基础LLM和RoBERTa在金融领域的性能表现，发现即使没有标记数据，ChatGPT的表现也很好，但微调后的模型通常表现更好，使用生成模型进行数据注释可能耗时

    

    最近，像ChatGPT这样的大型语言模型已经展现出在许多零基础自然语言处理任务上的惊人表现。在本文中，我们研究了零基础LLMs在金融领域中的有效性。我们将ChatGPT与一些开源生成型LLM以及在注释数据上进行RoBERTa微调的性能在零基础模式下进行了比较。我们解决了关于数据注释、性能差距以及在金融领域使用生成模型的可行性的三个相关研究问题。我们的研究结果表明，即使没有标记数据，ChatGPT的表现也很好，但经过微调的模型通常表现更好。我们的研究还强调了使用生成型模型进行注释可能是耗时的。我们的代码库在CC BY-NC 4.0许可下公开在GitHub上。

    Recently large language models (LLMs) like ChatGPT have shown impressive performance on many natural language processing tasks with zero-shot. In this paper, we investigate the effectiveness of zero-shot LLMs in the financial domain. We compare the performance of ChatGPT along with some open-source generative LLMs in zero-shot mode with RoBERTa fine-tuned on annotated data. We address three inter-related research questions on data annotation, performance gaps, and the feasibility of employing generative models in the finance domain. Our findings demonstrate that ChatGPT performs well even without labeled data but fine-tuned models generally outperform it. Our research also highlights how annotating with generative models can be time-intensive. Our codebase is publicly available on GitHub under CC BY-NC 4.0 license.
    
[^38]: 评估问答生成需要更多的参考文献

    Evaluation of Question Generation Needs More References. (arXiv:2305.16626v1 [cs.CL])

    [http://arxiv.org/abs/2305.16626](http://arxiv.org/abs/2305.16626)

    评估QG方法需要更多的参考文献来提高其有效性，单个参考不足以全面评估其潜力。使用多个参考文献的评估方法可以更好地与人类评估相关联。

    

    问答生成(QG)是一项任务，基于给定的上下文和目标答案生成一个有效和流畅的问题。根据不同的目的，即使给定相同的上下文，教师也可以提出关于不同概念的问题，甚至相同的概念也可以用不同的方式书写。然而，对于QG的评估通常依赖于单个基于参考的相似性度量，例如n-gram度量或学习度量，这不足以充分评估QG方法的潜力。为此，我们建议重新表述参考问题，以进行更强健的QG评估。使用大型语言模型，如GPT-3，我们创建了语义和句法多样的问题，然后采用流行的评估指标的简单聚合作为最终得分。通过我们的实验，我们发现使用多个（伪）参考文献对于QG评估更有效，同时与人类评估的相关性更高，而单个参考的评估则相对较低。

    Question generation (QG) is the task of generating a valid and fluent question based on a given context and the target answer. According to various purposes, even given the same context, instructors can ask questions about different concepts, and even the same concept can be written in different ways. However, the evaluation for QG usually depends on single reference-based similarity metrics, such as n-gram-based metric or learned metric, which is not sufficient to fully evaluate the potential of QG methods. To this end, we propose to paraphrase the reference question for a more robust QG evaluation. Using large language models such as GPT-3, we created semantically and syntactically diverse questions, then adopt the simple aggregation of the popular evaluation metrics as the final scores. Through our experiments, we found that using multiple (pseudo) references is more effective for QG evaluation while showing a higher correlation with human evaluations than evaluation with a single r
    
[^39]: 连接上下文表示中的领域差距，用于k最近邻神经机器翻译

    Bridging the Domain Gaps in Context Representations for k-Nearest Neighbor Neural Machine Translation. (arXiv:2305.16599v1 [cs.CL])

    [http://arxiv.org/abs/2305.16599](http://arxiv.org/abs/2305.16599)

    本文提出了一种新的方法，可以通过重建原始数据存储库来提高kNN-MT的向下数据检索，解决了上游和下游领域之间的显着差距问题。

    

    k最近邻机器翻译(kNN-MT)因其能够非参数地适应新的翻译领域而受到越来越多的关注。通过使用上游NMT模型遍历下游训练语料库，它配备了一个包含向量化键值对的数据存储库，在推理过程中检索这些信息来提高翻译质量。然而，上下游领域之间经常存在显着差距，这会损害检索准确性和最终翻译质量。为了解决这个问题，我们提出了一种新的方法，通过重建原始数据存储库来提高kNN-MT的数据检索。具体而言，我们设计了一个修订器来修订关键表示，使其更适合下游领域。修订器使用收集的语义相关键-查询对进行训练，并通过两个提出的损失进行优化：一个是键-查询语义距离，确保每个修订的键表示在语义上相似。

    $k$-Nearest neighbor machine translation ($k$NN-MT) has attracted increasing attention due to its ability to non-parametrically adapt to new translation domains. By using an upstream NMT model to traverse the downstream training corpus, it is equipped with a datastore containing vectorized key-value pairs, which are retrieved during inference to benefit translation. However, there often exists a significant gap between upstream and downstream domains, which hurts the retrieval accuracy and the final translation quality. To deal with this issue, we propose a novel approach to boost the datastore retrieval of $k$NN-MT by reconstructing the original datastore. Concretely, we design a reviser to revise the key representations, making them better fit for the downstream domain. The reviser is trained using the collected semantically-related key-queries pairs, and optimized by two proposed losses: one is the key-queries semantic distance ensuring each revised key representation is semanticall
    
[^40]: NormMark: 一个使用弱监督马尔可夫模型发现社会文化规范的方法

    NormMark: A Weakly Supervised Markov Model for Socio-cultural Norm Discovery. (arXiv:2305.16598v1 [cs.CL])

    [http://arxiv.org/abs/2305.16598](http://arxiv.org/abs/2305.16598)

    本文提出了一种使用马尔可夫模型发现社会文化规范的方法，该方法可以在对话的整个过程中捕获隐含特征并提高规范识别的效果。

    

    社会文化规范是一种被广泛接受的行为指导。将社会文化规范纳入对话模型中可以生成适合社会文化背景的话语。现有的规范识别方法往往只关注对话的表层特征，而没有考虑对话之间的交互。为了解决这个问题，我们提出了NormMark，一种概率生成的马尔可夫模型，以贯穿整个对话的隐含特征为特点。这些特征是由离散和连续的潜在变量在对话历史的条件下捕获的，提高了模型在规范识别方面的能力。该模型可使用变分技术对弱标注数据进行训练。在具有有限规范注释的数据集上，我们展示了我们的方法实现了更高的F1得分，超越了当前最先进的方法，包括GPT-3。

    Norms, which are culturally accepted guidelines for behaviours, can be integrated into conversational models to generate utterances that are appropriate for the socio-cultural context. Existing methods for norm recognition tend to focus only on surface-level features of dialogues and do not take into account the interactions within a conversation. To address this issue, we propose NormMark, a probabilistic generative Markov model to carry the latent features throughout a dialogue. These features are captured by discrete and continuous latent variables conditioned on the conversation history, and improve the model's ability in norm recognition. The model is trainable on weakly annotated data using the variational technique. On a dataset with limited norm annotations, we show that our approach achieves higher F1 score, outperforming current state-of-the-art methods, including GPT3.
    
[^41]: 基于神经架构搜索的参数高效微调大型预训练语言模型

    Neural Architecture Search for Parameter-Efficient Fine-tuning of Large Pre-trained Language Models. (arXiv:2305.16597v1 [cs.CL])

    [http://arxiv.org/abs/2305.16597](http://arxiv.org/abs/2305.16597)

    本文提出了一种基于神经架构搜索的参数高效微调大型预训练语言模型的方法，通过结构化和非结构化剪枝学习PET结构并在GLUE上进行实验验证，展示了该算法的有效性，探讨了PET架构设计选择对实际性能的影响。

    

    参数高效微调（PET）方法通过计算部分模型参数的小型压缩更新或添加和微调少量新的模型参数到预训练网络，将预训练语言模型（PLM）适应下游任务。手工设计的PET架构在实践中表现良好，但通过自动神经架构搜索（NAS），它们有改进的潜力。我们提出了一种通过结构化和非结构化剪枝学习PET结构的有效NAS方法。我们在GLUE上进行了实验，展示了我们算法的有效性，并讨论了PET架构设计选择如何影响实际性能。

    Parameter-efficient tuning (PET) methods fit pre-trained language models (PLMs) to downstream tasks by either computing a small compressed update for a subset of model parameters, or appending and fine-tuning a small number of new model parameters to the pre-trained network. Hand-designed PET architectures from the literature perform well in practice, but have the potential to be improved via automated neural architecture search (NAS). We propose an efficient NAS method for learning PET architectures via structured and unstructured pruning. We present experiments on GLUE demonstrating the effectiveness of our algorithm and discuss how PET architectural design choices affect performance in practice.
    
[^42]: ParaAMR: 基于AMR反向翻译的大规模语法多样化释义数据集

    ParaAMR: A Large-Scale Syntactically Diverse Paraphrase Dataset by AMR Back-Translation. (arXiv:2305.16585v1 [cs.CL])

    [http://arxiv.org/abs/2305.16585](http://arxiv.org/abs/2305.16585)

    ParaAMR是一个基于AMR反向翻译创建的大规模语法多样化释义数据集，相比现有的大规模释义数据集在语法上更具多样性，可用于提升自然语言处理任务的性能，包括学习句子嵌入向量、语法控制的释义生成和机器翻译的数据增强。

    

    释义生成是自然语言处理中一个长期存在的任务。监督式释义生成模型需要人工注释，费用高昂且难以扩展。与之相比，自动注释的释义对通常缺乏语法多样性——生成的释义句子在句法上与源句子非常相似。在本文中，我们提出ParaAMR，这是一个基于抽象意义表示反向翻译创建的大规模语法多样化释义数据集。我们的定量分析、定性例子和人类评估表明，ParaAMR的释义和现有的大规模释义数据集相比在语法上更具多样性，同时保留了良好的语义相似性。另外，我们还展示了ParaAMR在三个自然语言处理任务中的应用: 学习句子嵌入向量、语法控制的释义生成和机器翻译的数据增强。

    Paraphrase generation is a long-standing task in natural language processing (NLP). Supervised paraphrase generation models, which rely on human-annotated paraphrase pairs, are cost-inefficient and hard to scale up. On the other hand, automatically annotated paraphrase pairs (e.g., by machine back-translation), usually suffer from the lack of syntactic diversity -- the generated paraphrase sentences are very similar to the source sentences in terms of syntax. In this work, we present ParaAMR, a large-scale syntactically diverse paraphrase dataset created by abstract meaning representation back-translation. Our quantitative analysis, qualitative examples, and human evaluation demonstrate that the paraphrases of ParaAMR are syntactically more diverse compared to existing large-scale paraphrase datasets while preserving good semantic similarity. In addition, we show that ParaAMR can be used to improve on three NLP tasks: learning sentence embeddings, syntactically controlled paraphrase ge
    
[^43]: 大语言模型中的图思维推理：超越“思维链”的有力工具

    Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models. (arXiv:2305.16582v1 [cs.CL])

    [http://arxiv.org/abs/2305.16582](http://arxiv.org/abs/2305.16582)

    通过将人类思维过程建模成图形结构，我们提出了“思维图”（GoT）推理辅助大语言模型（LLMs）来完成更加真实的、复杂的思维任务。

    

    随着大语言模型（LLMs）在NLP任务中的广泛应用，研究人员发现“思维链”（CoT）能够通过生成中间步骤来帮助LLMs完成复杂的推理任务。然而，人类的思维过程常常是非线性的，而不只是简单的顺序思维链。因此，我们提出了“思维图”（GoT）推理，它不仅将人类思维过程建模成链式结构，而且还建模成图形结构。通过将思维单元表示为节点，它们之间的连接作为边缘，我们的方法捕捉了人类思维的非顺序性，实现了对思维过程的更加真实的建模。

    With the widespread use of large language models (LLMs) in NLP tasks, researchers have discovered the potential of Chain-of-thought (CoT) to assist LLMs in accomplishing complex reasoning tasks by generating intermediate steps. However, human thought processes are often non-linear, rather than simply sequential chains of thoughts. Therefore, we propose Graph-of-Thought (GoT) reasoning, which models human thought processes not only as a chain but also as a graph. By representing thought units as nodes and connections between them as edges, our approach captures the non-sequential nature of human thinking and allows for a more realistic modeling of thought processes. Similar to Multimodal-CoT, we modeled GoT reasoning as a two-stage framework, generating rationales first and then producing the final answer. Specifically, we employ an additional graph-of-thoughts encoder for GoT representation learning and fuse the GoT representation with the original input representation through a gated 
    
[^44]: 语态变化中噪声的调查

    An Investigation of Noise in Morphological Inflection. (arXiv:2305.16581v1 [cs.CL])

    [http://arxiv.org/abs/2305.16581](http://arxiv.org/abs/2305.16581)

    该研究调查了语态变化中噪声的不同类型，并探索了它们对非监督形态学范式完成和语态变化系统的影响。实验发现编码器解码器比复制偏差的模型更为稳健，CMLM预训练可提高transformer模型的稳定性。

    

    随着对语态细微变化系统的关注越来越多，而这些语言缺乏高质量的数据，训练中的噪声是一个严重但迄今为止很少被关注的问题。我们旨在通过调查真正无监督的形态范式完成管道中遇到的噪声类型并探索其对语态变化系统的影响来弥合这一差距：首先，我们提出了一个错误分类法和注释管道的活动训练数据。然后，我们比较了不同类型噪音对多种最先进的语态变化模型的影响。最后，我们提出了一种新的字符级掩码语言建模（CMLM）预训练目标，并探索了它对模型抗噪性的影响。我们的实验证明，各种体系结构受到不同类型的噪声的影响不同，但编码器-解码器比带有复制偏差的模型更为稳健。CMLM预训练有助于transformers，但对LSTMs的影响较低。

    With a growing focus on morphological inflection systems for languages where high-quality data is scarce, training data noise is a serious but so far largely ignored concern. We aim at closing this gap by investigating the types of noise encountered within a pipeline for truly unsupervised morphological paradigm completion and its impact on morphological inflection systems: First, we propose an error taxonomy and annotation pipeline for inflection training data. Then, we compare the effect of different types of noise on multiple state-of-the-art inflection models. Finally, we propose a novel character-level masked language modeling (CMLM) pretraining objective and explore its impact on the models' resistance to noise. Our experiments show that various architectures are impacted differently by separate types of noise, but encoder-decoders tend to be more robust to noise than models trained with a copy bias. CMLM pretraining helps transformers, but has lower impact on LSTMs.
    
[^45]: 人人可复现的NLP研究：初学者的需求调查

    NLP Reproducibility For All: Understanding Experiences of Beginners. (arXiv:2305.16579v1 [cs.CL])

    [http://arxiv.org/abs/2305.16579](http://arxiv.org/abs/2305.16579)

    通过对93名NLP初学者的调查，发现研究作者提供完整文档、更好的代码实践和更易于获取的数据文件是初学者成功复现最近NLP论文结果的关键，建议NLP研究人员注重这些方面，更好地支持初学者。

    

    随着自然语言处理（NLP）近年来异常火爆，越来越多的人急于进入该领域，但目前的研究复现努力是否足以让这些初学者应用最新的进展还不清楚。为了了解初学者的需求，我们在一个介绍性的NLP课程中开展了一项研究，让学生复现最近NLP论文的结果。令人惊讶的是，我们发现他们的编程技能和对研究论文的理解对完成练习的付出仅有限的影响，相比之下，研究作者的可访问性努力是成功的关键，包括完整的文档、更好的编码实践和更容易获取的数据文件。前进时，我们建议NLP研究人员密切关注这些开源工作的简单方面，并使用初学者的反馈见解提供可操作的想法以更好地支持他们。

    As natural language processing (NLP) has recently seen an unprecedented level of excitement, and more people are eager to enter the field, it is unclear whether current research reproducibility efforts are sufficient for this group of beginners to apply the latest developments. To understand their needs, we conducted a study with 93 students in an introductory NLP course, where students reproduced the results of recent NLP papers. Surprisingly, we find that their programming skill and comprehension of research papers have a limited impact on their effort spent completing the exercise. Instead, we find accessibility efforts by research authors to be the key to success, including complete documentation, better coding practice, and easier access to data files. Going forward, we recommend that NLP researchers pay close attention to these simple aspects of open-sourcing their work, and use insights from beginners' feedback to provide actionable ideas on how to better support them.
    
[^46]: 昵歇尔和南希：人口属性和标记长度对姓氏偏见的影响

    Nichelle and Nancy: The Influence of Demographic Attributes and Tokenization Length on First Name Biases. (arXiv:2305.16577v1 [cs.CL])

    [http://arxiv.org/abs/2305.16577](http://arxiv.org/abs/2305.16577)

    本文研究了人口属性和标记长度对社交常识推理模型的影响，发现名字的人口属性和名字标记化长度都是影响社交常识推理模型行为的系统性因素。

    

    先前的研究通过使用姓名替换实验表明，社交常识推理模型的倾向性会沿着种族、民族和性别的维度，系统性地表现出社会偏见（An等人，2023年）。然而，名字的人口属性与语料库频率和标记化长度强相关，这可能会独立于人口统计因素或除人口统计因素之外影响模型行为。在本文中，我们进行了一系列新的名字替换实验，以衡量这些因素对模型行为的影响，同时对其他因素进行控制。我们发现，一个名字的人口属性（种族、民族和性别）和名字标记化长度都是影响社交常识推理模型行为的系统性因素。

    Through the use of first name substitution experiments, prior research has demonstrated the tendency of social commonsense reasoning models to systematically exhibit social biases along the dimensions of race, ethnicity, and gender (An et al., 2023). Demographic attributes of first names, however, are strongly correlated with corpus frequency and tokenization length, which may influence model behavior independent of or in addition to demographic factors. In this paper, we conduct a new series of first name substitution experiments that measures the influence of these factors while controlling for the others. We find that demographic attributes of a name (race, ethnicity, and gender) and name tokenization length are both factors that systematically affect the behavior of social commonsense reasoning models.
    
[^47]: 反事实推理：测试语言模型对假设情景的理解

    Counterfactual reasoning: Testing language models' understanding of hypothetical scenarios. (arXiv:2305.16572v1 [cs.CL])

    [http://arxiv.org/abs/2305.16572](http://arxiv.org/abs/2305.16572)

    本文通过反事实条件测试了五个预先训练的语言模型的能力，发现这些模型通常能够在反事实情景中覆盖真实世界的知识，但这种效应通常由简单的词汇线索驱动。

    

    当前预先训练的语言模型在下游任务中取得了显著进展，但仍然难以区分统计相关性和更系统的基于对真实世界理解的逻辑推理的效果。我们通过利用反事实条件将这些因素分开，强制语言模型根据假设提议预测异常后果。我们引入了一系列来自心理语言学实验以及更大规模的受控数据集的测试，以探测五个预先训练的语言模型的反事实预测。我们发现，模型通常能够在反事实情景中覆盖真实世界的知识，并且在更强的基线世界知识案例中，这种效应更为强大--然而，我们还发现，对于大多数模型，这种效应似乎在很大程度上是由简单的词汇线索驱动的。当我们缓解世界知识和词汇线索的影响以测试语言的语言学自由程度时

    Current pre-trained language models have enabled remarkable improvements in downstream tasks, but it remains difficult to distinguish effects of statistical correlation from more systematic logical reasoning grounded on the understanding of real world. We tease these factors apart by leveraging counterfactual conditionals, which force language models to predict unusual consequences based on hypothetical propositions. We introduce a set of tests from psycholinguistic experiments, as well as larger-scale controlled datasets, to probe counterfactual predictions from five pre-trained language models. We find that models are consistently able to override real-world knowledge in counterfactual scenarios, and that this effect is more robust in case of stronger baseline world knowledge -- however, we also find that for most models this effect appears largely to be driven by simple lexical cues. When we mitigate effects of both world knowledge and lexical cues to test knowledge of linguistic nu
    
[^48]: 团队合作并不总是好的：类增量信息提取中分类器漂移的实证研究

    Teamwork Is Not Always Good: An Empirical Study of Classifier Drift in Class-incremental Information Extraction. (arXiv:2305.16559v1 [cs.CL])

    [http://arxiv.org/abs/2305.16559](http://arxiv.org/abs/2305.16559)

    本论文研究了类增量信息提取中分类器漂移如何导致遗忘的问题，并提出了四种解决方案来缓解分类器漂移。

    

    类增量学习旨在开发一种学习系统，该系统可以不断从数据流中学习新类，而不会忘记之前学习过的类。然而，当学习增量类时，分类器必须不断更新以纳入新类，并且决策边界的漂移可能导致严重的遗忘。然而，这一根本性挑战尚未得到广泛研究，特别是在不存储旧类别样本以进行重演的情况下。本文更详细地研究了分类器漂移如何导致遗忘，并据此设计了四种简单但（超级）有效的解决方案来缓解分类器漂移。

    Class-incremental learning (CIL) aims to develop a learning system that can continually learn new classes from a data stream without forgetting previously learned classes. When learning classes incrementally, the classifier must be constantly updated to incorporate new classes, and the drift in decision boundary may lead to severe forgetting. This fundamental challenge, however, has not yet been studied extensively, especially in the setting where no samples from old classes are stored for rehearsal. In this paper, we take a closer look at how the drift in the classifier leads to forgetting, and accordingly, design four simple yet (super-) effective solutions to alleviate the classifier drift: an Individual Classifiers with Frozen Feature Extractor (ICE) framework where we individually train a classifier for each learning session, and its three variants ICE-PL, ICE-O, and ICE-PL&O which further take the logits of previously learned classes from old sessions or a constant logit of an Ot
    
[^49]: 对话摘要中细粒度事实错误的注释和检测

    Annotating and Detecting Fine-grained Factual Errors for Dialogue Summarization. (arXiv:2305.16548v1 [cs.CL])

    [http://arxiv.org/abs/2305.16548](http://arxiv.org/abs/2305.16548)

    本论文提出第一个注释有细粒度事实错误的对话摘要数据集，探索了细粒度事实错误检测作为一个句子级多标签分类问题的挑战，并提出了一种无监督模型，取得了和 SOTA 模型相近的效果。

    

    针对格式良好的文档（如新闻文章）生成的摘要，已经提出了一系列数据集和模型。但是，对话摘要一直未被探索。本文介绍了第一个带有细粒度事实错误注释的数据集 DIASUMFACT。我们将细粒度事实错误检测定义为一个句子级多标签分类问题，并评估了两个最先进的模型在我们的数据集上的表现。两个模型都产生了次优结果，六个错误类别的宏平均 F1 分数约为 0.25。我们进一步提出了一种使用预训练编码器-解码器模型进行候选排名的无监督模型 ENDERANKER。我们的模型表现与 SOTA 模型不相上下，同时需要较少的资源。这些观察结果证实了从对话摘要中检测事实错误的挑战，这需要进一步的研究，而我们的数据集和实验结果为此提供了坚实的基础。

    A series of datasets and models have been proposed for summaries generated for well-formatted documents such as news articles. Dialogue summaries, however, have been under explored. In this paper, we present the first dataset with fine-grained factual error annotations named DIASUMFACT. We define fine-grained factual error detection as a sentence-level multi-label classification problem, and we evaluate two state-of-the-art (SOTA) models on our dataset. Both models yield sub-optimal results, with a macro-averaged F1 score of around 0.25 over 6 error classes. We further propose an unsupervised model ENDERANKER via candidate ranking using pretrained encoder-decoder models. Our model performs on par with the SOTA models while requiring fewer resources. These observations confirm the challenges in detecting factual errors from dialogue summaries, which call for further studies, for which our dataset and results offer a solid foundation.
    
[^50]: 面向零样本文本分类的标签无关预训练

    Label Agnostic Pre-training for Zero-shot Text Classification. (arXiv:2305.16521v1 [cs.CL])

    [http://arxiv.org/abs/2305.16521](http://arxiv.org/abs/2305.16521)

    本文旨在探究改进预训练语言模型的泛化能力，提高其在零样本情境下的文本分类表现。通过引入隐式和显式预训练策略，注入方面级别的理解，以建立任务层次的表示。

    

    传统的文本分类方法通常假设存在一组固定的预定义标签，用于将给定的文本分类。然而，在现实世界的应用中，存在着用于描述给定文本的无限标签空间。此外，根据文本的方面（情感、主题等）和领域（金融、法律等），标签的解释可能大不相同。这使得文本分类任务，特别是在零样本场景下，变得非常具有挑战性。在本文中，我们探讨了零样本文本分类的任务，旨在提高预训练语言模型（PLMs）对不同方面和领域中已知和未知数据的泛化能力。为了解决这个问题，我们引入了两种新的简单而有效的预训练策略，即隐式和显式预训练。这些方法在训练时注入了方面级别的理解，目的是让模型构建任务层次的表示。

    Conventional approaches to text classification typically assume the existence of a fixed set of predefined labels to which a given text can be classified. However, in real-world applications, there exists an infinite label space for describing a given text. In addition, depending on the aspect (sentiment, topic, etc.) and domain of the text (finance, legal, etc.), the interpretation of the label can vary greatly. This makes the task of text classification, particularly in the zero-shot scenario, extremely challenging. In this paper, we investigate the task of zero-shot text classification with the aim of improving the ability of pre-trained language models (PLMs) to generalize to both seen and unseen data across varying aspects and domains. To solve this we introduce two new simple yet effective pre-training strategies, Implicit and Explicit pre-training. These methods inject aspect-level understanding into the model at train time with the goal of conditioning the model to build task-l
    
[^51]: 相信随机鹦鹉的危险：自然对话问答中的忠诚度与信任

    The Dangers of trusting Stochastic Parrots: Faithfulness and Trust in Open-domain Conversational Question Answering. (arXiv:2305.16519v1 [cs.CL])

    [http://arxiv.org/abs/2305.16519](http://arxiv.org/abs/2305.16519)

    本文研究表明，具备某些高级语言对话行为（如重复用户所说的话）的任务型系统更受欢迎、更值得信任，然而那些一味模仿用户输入的系统却存在诸多不忠实响应的风险。

    

    大型语言模型往往能够生产出流畅而令人信服的输出结果，但它们经常会出现错误，即从知识库中提取的答案与客观事实不符。本文表明，那些展现出先进语言对话行为（如重复用户所说的话）的任务型系统，实际上更受欢迎、更值得信任，而其他现象（如代词和省略）则不被青睐。我们以开放域问答系统为测试基础，比较了数个开放式和封闭式图书模型的任务生成对话。研究结果突出表明，系统在模仿用户输入的同时提供不忠实的响应，这种表现看似可信，实则危险。

    Large language models are known to produce output which sounds fluent and convincing, but is also often wrong, e.g. "unfaithful" with respect to a rationale as retrieved from a knowledge base. In this paper, we show that task-based systems which exhibit certain advanced linguistic dialog behaviors, such as lexical alignment (repeating what the user said), are in fact preferred and trusted more, whereas other phenomena, such as pronouns and ellipsis are dis-preferred. We use open-domain question answering systems as our test-bed for task based dialog generation and compare several open- and closed-book models. Our results highlight the danger of systems that appear to be trustworthy by parroting user input while providing an unfaithful response.
    
[^52]: 开源大语言模型对工具操作能力的研究

    On the Tool Manipulation Capability of Open-source Large Language Models. (arXiv:2305.16504v1 [cs.CL])

    [http://arxiv.org/abs/2305.16504](http://arxiv.org/abs/2305.16504)

    本研究探讨了如何通过训练使用示例、上下文演示和生成样式规则来加强开源LLMs以达到与封闭型API的工具操作性能同等甚至更优的效果，并通过ToolBench测试得出了实验结果，同时本文还证明了改进的开源LLMs的鲁棒性。

    

    近期对使用大型语言模型( LLMs)进行软件工具操作的研究大多依赖于封闭模型API。由于向封闭LLMAPI服务公开信息存在安全和鲁棒性风险，这些模型的工业采用受到了实质性限制。本文提出了一个问题，那就是我们能否在实践中加强开源LLMs的功能，使其在工具操作方面与领先的封闭LLM APIs竞争。通过分析常见的工具操作失败，我们首先展示了开源LLMs可能需要训练使用示例、上下文演示和生成样式规则来解决失败。这些见解激发我们重新审视LLM文献中的经典方法，并证明我们可以将它们作为程序数据生成的模型对齐、系统提示和上下文演示检索器来适应开源LLMs以实现工具操作的增强。为了评估这些技术，我们创建了ToolBench，一个工具操作能力测试套件，包括现有API和我们改进的开源LLMs。在三个不同的编程任务上，我们发现改进的开源LLMs能够达到或超越现有API的性能，其中包括对已编写的程序进行轻微修改等实际操作。此外，我们通过反向工程测试和黑盒测试进一步证明了模型的鲁棒性。

    Recent studies on software tool manipulation with large language models (LLMs) mostly rely on closed model APIs. The industrial adoption of these models is substantially constrained due to the security and robustness risks in exposing information to closed LLM API services. In this paper, we ask can we enhance open-source LLMs to be competitive to leading closed LLM APIs in tool manipulation, with practical amount of human supervision. By analyzing common tool manipulation failures, we first demonstrate that open-source LLMs may require training with usage examples, in-context demonstration and generation style regulation to resolve failures. These insights motivate us to revisit classical methods in LLM literature, and demonstrate that we can adapt them as model alignment with programmatic data generation, system prompts and in-context demonstration retrievers to enhance open-source LLMs for tool manipulation. To evaluate these techniques, we create the ToolBench, a tool manipulation 
    
[^53]: 基于样例的可解释性法律引文预测

    Prototype-Based Interpretability for Legal Citation Prediction. (arXiv:2305.16490v1 [cs.CL])

    [http://arxiv.org/abs/2305.16490](http://arxiv.org/abs/2305.16490)

    本论文提出了一种基于样例的法律引文预测方法，结合先例和立法规定思维过程，并引入原型架构增加可解释性，该方法在实现强大性能的同时，考虑了高风险任务在实际社会影响中的重要考虑因素。

    

    深度学习在过去十年中取得了重大进展，并展示了解决具有广泛社会影响问题的潜力。在高风险决策领域，如法律，专家经常需要解释性以便在实际环境中使用自动化系统。在这项工作中，我们试图解决应用于重要问题的法律引文预测(LCP)的这些要求。我们设计任务，并类比律师的思维过程，即参考先例和立法规定。在初步实验结果后，我们通过法律专家的反馈，改进了目标引文预测。此外，我们引入原型架构来增加可解释性，同时遵循律师使用的决策参数，实现强大的性能。本研究建立在并利用了具有法律状况的语言处理模型的最新技术，同时考虑到了高风险任务在实际社会影响中的重要考虑因素。

    Deep learning has made significant progress in the past decade, and demonstrates potential to solve problems with extensive social impact. In high-stakes decision making areas such as law, experts often require interpretability for automatic systems to be utilized in practical settings. In this work, we attempt to address these requirements applied to the important problem of legal citation prediction (LCP). We design the task with parallels to the thought-process of lawyers, i.e., with reference to both precedents and legislative provisions. After initial experimental results, we refine the target citation predictions with the feedback of legal experts. Additionally, we introduce a prototype architecture to add interpretability, achieving strong performance while adhering to decision parameters used by lawyers. Our study builds on and leverages the state-of-the-art language processing models for law, while addressing vital considerations for high-stakes tasks with practical societal i
    
[^54]: 评估不同群体对影响力信息的反应

    Measuring the Effect of Influential Messages on Varying Personas. (arXiv:2305.16470v1 [cs.CL])

    [http://arxiv.org/abs/2305.16470](http://arxiv.org/abs/2305.16470)

    研究了评估不同群体对影响力信息的反应的任务和所创建的数据集，突出了新任务在建模中引入了个性化，预测了每个反应的情感极性和强度，并让评估和应用更加可靠。

    

    预测用户对新闻事件的反应能够实现智能代理或内容生成者估计不同社区的影响并修订未发布的信息，防止社会冲突和道德伤害。本文提出了一项新任务：用于新闻媒体的人设反应预测，以预测人设（描述个人或群体）对新闻信息的反应。与以往仅预测新闻的通用评论的工作相比，所提出的任务不仅在建模中引入了个性化，还预测了每个反应的情感极性和强度。这使得对人设的心理状态进行更准确和全面的推断成为可能。同时，生成的情感维度使得评估和应用更加可靠。我们创建了第一个基准数据集，其中包括来自Twitter的3,847个新闻标题的13,357个反应。

    Predicting how a user responds to news events enables important applications such as allowing intelligent agents or content producers to estimate the effect on different communities and revise unreleased messages to prevent unexpected bad outcomes such as social conflict and moral injury. We present a new task, Response Forecasting on Personas for News Media, to estimate the response a persona (characterizing an individual or a group) might have upon seeing a news message. Compared to the previous efforts which only predict generic comments to news, the proposed task not only introduces personalization in the modeling but also predicts the sentiment polarity and intensity of each response. This enables more accurate and comprehensive inference on the mental state of the persona. Meanwhile, the generated sentiment dimensions make the evaluation and application more reliable. We create the first benchmark dataset, which consists of 13,357 responses to 3,847 news headlines from Twitter. W
    
[^55]: 不需重新训练，只需重写：通过重写文本来对抗对抗性扰动攻击

    Don't Retrain, Just Rewrite: Countering Adversarial Perturbations by Rewriting Text. (arXiv:2305.16444v1 [cs.CL])

    [http://arxiv.org/abs/2305.16444](http://arxiv.org/abs/2305.16444)

    本文提出了ATINTER模型，该模型可以重写对抗性输入以使其对于下游文本分类器来说不具有对抗性，在多个数据集和攻击机制的实验中证明了其比现有防御方法更有效，且不会牺牲任务准确性

    

    语言模型能否转化输入以保护文本分类器免受对抗性攻击？本文提出了ATINTER模型，该模型截获并学习重写对抗性输入以使其对于下游文本分类器来说不具有对抗性。我们在四个数据集和五种攻击机制上的实验证明，ATINTER比现有的防御方法更有效，并且不会牺牲任务准确性。例如，使用SST-2数据集进行情感分类，我们的方法提高了比我们最好的现有防御方法更多的4%的对抗准确性，而任务准确性的下降更小(0.5%比2.5%)。此外，我们证明了ATINTER在不需要明确为这些设置重新训练的情况下横向推广到多个下游任务和分类器。具体而言，我们发现当ATINTER被训练以删除SST-2数据集情感分类任务的对抗性扰动时，它甚至可以传输。

    Can language models transform inputs to protect text classifiers against adversarial attacks? In this work, we present ATINTER, a model that intercepts and learns to rewrite adversarial inputs to make them non-adversarial for a downstream text classifier. Our experiments on four datasets and five attack mechanisms reveal that ATINTER is effective at providing better adversarial robustness than existing defense approaches, without compromising task accuracy. For example, on sentiment classification using the SST-2 dataset, our method improves the adversarial accuracy over the best existing defense approach by more than 4% with a smaller decrease in task accuracy (0.5% vs 2.5%). Moreover, we show that ATINTER generalizes across multiple downstream tasks and classifiers without having to explicitly retrain it for those settings. Specifically, we find that when ATINTER is trained to remove adversarial perturbations for the sentiment classification task on the SST-2 dataset, it even transfe
    
[^56]: 数学公式的神经机器翻译

    Neural Machine Translation for Mathematical Formulae. (arXiv:2305.16433v1 [cs.CL])

    [http://arxiv.org/abs/2305.16433](http://arxiv.org/abs/2305.16433)

    这篇论文解决了神经机器翻译数学公式时面临的词汇量较小、符号序列较长和需要高度精度的问题，并通过使用卷积序列到序列网络实现了较高的准确度。

    

    我们解决了在模糊的表达语言和明确的内容语言之间进行数学公式的神经机器翻译的问题。与自然语言的神经机器翻译相比，数学公式具有更小的词汇量和更长的符号序列，而翻译需要极高的精度来满足数学信息的需求。在这项工作中，我们完成了从LaTeX到Mathematica的翻译以及从LaTeX到语义LaTeX的翻译。尽管循环，递归和转换网络难以保留所有包含的信息，但我们发现卷积序列到序列网络分别可以达到95.1％和90.7％的精确匹配。

    We tackle the problem of neural machine translation of mathematical formulae between ambiguous presentation languages and unambiguous content languages. Compared to neural machine translation on natural language, mathematical formulae have a much smaller vocabulary and much longer sequences of symbols, while their translation requires extreme precision to satisfy mathematical information needs. In this work, we perform the tasks of translating from LaTeX to Mathematica as well as from LaTeX to semantic LaTeX. While recurrent, recursive, and transformer networks struggle with preserving all contained information, we find that convolutional sequence-to-sequence networks achieve 95.1% and 90.7% exact matches, respectively.
    
[^57]: 预训练语言模型中的“绝对”与“相对”副词研究

    Not wacky vs. definitely wacky: A study of scalar adverbs in pretrained language models. (arXiv:2305.16426v1 [cs.CL])

    [http://arxiv.org/abs/2305.16426](http://arxiv.org/abs/2305.16426)

    本文通过研究标量副词，探究了预训练语言模型中“绝对”与“相对”词的表现，在涉及逻辑推理的NLP应用中面临挑战。

    

    词义向量空间模型假设出现在相似语境中的词具有相似的含义。这些模型中，类似于主题关联但在逻辑力度上不同的词往往被视为语义上相似，这对涉及逻辑推理的NLP应用造成了普遍挑战。关于现代预训练语言模型（如BERT、RoBERTa和GPT-3）在逻辑任务上表现优异的报告存在混杂的情况。本文通过系统研究标量副词，这是一类具有强烈逻辑力度的词汇，推进了这一讨论。通过使用三项不同的任务（包括自然的社交媒体数据和构造的示例），我们调查了BERT、RoBERTa、GPT-2和GPT-3在这些常见词语方面是否展现出一般的、类人的知识。我们问：1）这些模型能否区分这三个语义类型中的差异？

    Vector space models of word meaning all share the assumption that words occurring in similar contexts have similar meanings. In such models, words that are similar in their topical associations but differ in their logical force tend to emerge as semantically close, creating well-known challenges for NLP applications that involve logical reasoning. Modern pretrained language models, such as BERT, RoBERTa and GPT-3 hold the promise of performing better on logical tasks than classic static word embeddings. However, reports are mixed about their success. In the current paper, we advance this discussion through a systematic study of scalar adverbs, an under-explored class of words with strong logical force. Using three different tasks, involving both naturalistic social media data and constructed examples, we investigate the extent to which BERT, RoBERTa, GPT-2 and GPT-3 exhibit general, human-like, knowledge of these common words. We ask: 1) Do the models distinguish amongst the three sema
    
[^58]: 因果推断方法研究特异性和情感对群体偏见的影响

    Counterfactual Probing for the influence of affect and specificity on Intergroup Bias. (arXiv:2305.16409v1 [cs.CL])

    [http://arxiv.org/abs/2305.16409](http://arxiv.org/abs/2305.16409)

    本文研究了特异性和情感两个语用特征在不同群体背景下是否会出现系统性变化，并将其与自然语言输出中的新群体偏见框架相联系。初步分析表明，推文的特异性和情感程度与监督的群体关系标签之间存在一定的相关性，而因果推断揭示了神经模型在分类时可靠地使用情感，但其对特异性的使用是不确定的。

    

    虽然研究自然语言处理中的偏见问题通常集中在负面或贬损语言的使用上，但Govindarajan等人（2023）提出了一个新的偏见框架，即以群体社会背景为基础，研究其对语言行为的影响。本文研究了两个语用特征（特异性和情感）在不同的群体上下文中是否会系统性地变化，从而将这个新的偏见框架与语言输出连接起来。初步的分析发现，推文的特异性和情感程度与监督的群体关系（IGR）标签之间存在适度的相关性。因果推断进一步揭示了，虽然被精调为IGR标签预测的神经模型可靠地使用情感进行分类，但模型使用特异性是不确定的。代码和数据可以在以下网址找到：https://github.com/venkatasg/intergroup-probing

    While existing work on studying bias in NLP focues on negative or pejorative language use, Govindarajan et al. (2023) offer a revised framing of bias in terms of intergroup social context, and its effects on language behavior. In this paper, we investigate if two pragmatic features (specificity and affect) systematically vary in different intergroup contexts -- thus connecting this new framing of bias to language output. Preliminary analysis finds modest correlations between specificity and affect of tweets with supervised intergroup relationship (IGR) labels. Counterfactual probing further reveals that while neural models finetuned for predicting IGR labels reliably use affect in classification, the model's usage of specificity is inconclusive. Code and data can be found at: https://github.com/venkatasg/intergroup-probing
    
[^59]: 双语社区非常规语言书写的脚本标准化问题

    Script Normalization for Unconventional Writing of Under-Resourced Languages in Bilingual Communities. (arXiv:2305.16407v1 [cs.CL])

    [http://arxiv.org/abs/2305.16407](http://arxiv.org/abs/2305.16407)

    本研究解决了在双语社区中非常规母语书写的脚本标准化问题，使用合成数据和transformer-based模型，并表明这种标准化也能提高下游任务的性能。

    

    社交媒体的广泛普及给语言代表性不充分的社区提供了以母语创作内容的卓越机会，然而，如果双语社区的语言使用者依赖其他书写该母语的文字或正字法来书写，那么就会涉及到一些脚本标准化的挑战。本文解决了使用合成数据和基于transformer的模型对主要使用波斯 - 阿拉伯文字书写的几种语言进行脚本标准化的问题，并进行了少量真实数据的评估。我们的实验结果表明，脚本标准化也有助于提高下游任务（如机器翻译和语言识别）的性能。

    The wide accessibility of social media has provided linguistically under-represented communities with an extraordinary opportunity to create content in their native languages. This, however, comes with certain challenges in script normalization, particularly where the speakers of a language in a bilingual community rely on another script or orthography to write their native language. This paper addresses the problem of script normalization for several such languages that are mainly written in a Perso-Arabic script. Using synthetic data with various levels of noise and a transformer-based model, we demonstrate that the problem can be effectively remediated. We conduct a small-scale evaluation of real data as well. Our experiments indicate that script normalization is also beneficial to improve the performance of downstream tasks such as machine translation and language identification.
    
[^60]: 基于情境感知注意力层及最优传输域自适应方法识别自发语音中的痴呆症

    Context-Aware Attention Layers coupled with Optimal Transport Domain Adaptation methods for recognizing dementia from spontaneous speech. (arXiv:2305.16406v1 [cs.CL])

    [http://arxiv.org/abs/2305.16406](http://arxiv.org/abs/2305.16406)

    本论文提出一种基于情境感知注意力层及最优传输域自适应方法的语音识别痴呆症的新方法。该方法捕捉了模态内部和模态间的交互，并实现了模型校准。

    

    阿尔茨海默病是一种复杂的神经认知病变，也是导致痴呆症最常见的原因。虽然已经有很多针对通过自发语音诊断痴呆症的研究，但仍然存在限制。现有的先进方法提出了多模态方法，分别训练语言和声学模型，并采用多数投票方法，以及将不同模态的表示在输入层进行级联或在训练过程中进行级联。与此同时，一些方法采用了自我注意力层，计算表示之间的依赖关系，但没有考虑到上下文信息。此外，以前的工作都没有考虑到模型的校准。为了解决这些限制，我们提出了一些新方法来检测AD患者，捕捉了模态内部和模态间的交互。首先，我们将音频文件转换为log-Mel光谱图，它们的delta和delta-delta，并在此基础上创建了一个多通道神经网络。

    Alzheimer's disease (AD) constitutes a complex neurocognitive disease and is the main cause of dementia. Although many studies have been proposed targeting at diagnosing dementia through spontaneous speech, there are still limitations. Existing state-of-the-art approaches, which propose multimodal methods, train separately language and acoustic models, employ majority-vote approaches, and concatenate the representations of the different modalities either at the input level, i.e., early fusion, or during training. Also, some of them employ self-attention layers, which calculate the dependencies between representations without considering the contextual information. In addition, no prior work has taken into consideration the model calibration. To address these limitations, we propose some new methods for detecting AD patients, which capture the intraand cross-modal interactions. First, we convert the audio files into log-Mel spectrograms, their delta, and delta-delta and create in this
    
[^61]: 扩散模型是否是视觉语言推理器？

    Are Diffusion Models Vision-And-Language Reasoners?. (arXiv:2305.16397v1 [cs.CV])

    [http://arxiv.org/abs/2305.16397](http://arxiv.org/abs/2305.16397)

    本文针对扩散-语言图像生成模型进行转换和评估，介绍了生成-鉴别评估基准(GDBench)基于7个视觉语言复杂任务，并发现转换后的模型在组合性任务方面的表现优于CLIP，通过微调可提高其组合性能。

    

    近期，使用去噪扩散过程的文本-图像生成模型已取得了巨大的定性成功。然而，与鉴别式视觉-语言模型不同，将基于扩散的生成模型置于自动细粒度定量评估高级现象（如组合性）的任务中是一项非常棘手的任务。为此，我们开展了两项创新。首先，我们使用一种称为DiffusionITM的新方法将基于扩散的模型（在我们的情况下，是稳定扩散）转换为任何图像文本匹配(ITM)任务。其次，我们引入了7个复杂的视觉语言任务、偏差评估和详细分析的生成-鉴别评估基准(GDBench)。我们发现，Stable Diffusion + DiffusionITM在许多任务上具有竞争力，并在组合性任务（如CLEVR和Winoground等）上优于CLIP。我们通过在MS-COCO上微调保持图像特征的转移设置进一步提高其组合性能。

    Text-conditioned image generation models have recently shown immense qualitative success using denoising diffusion processes. However, unlike discriminative vision-and-language models, it is a non-trivial task to subject these diffusion-based generative models to automatic fine-grained quantitative evaluation of high-level phenomena such as compositionality. Towards this goal, we perform two innovations. First, we transform diffusion-based models (in our case, Stable Diffusion) for any image-text matching (ITM) task using a novel method called DiffusionITM. Second, we introduce the Generative-Discriminative Evaluation Benchmark (GDBench) benchmark with 7 complex vision-and-language tasks, bias evaluation and detailed analysis. We find that Stable Diffusion + DiffusionITM is competitive on many tasks and outperforms CLIP on compositional tasks like like CLEVR and Winoground. We further boost its compositional performance with a transfer setup by fine-tuning on MS-COCO while retaining ge
    
[^62]: 扫描与拍照：理解1层Transformer中的训练动态和标记组成

    Scan and Snap: Understanding Training Dynamics and Token Composition in 1-layer Transformer. (arXiv:2305.16380v1 [cs.CL])

    [http://arxiv.org/abs/2305.16380](http://arxiv.org/abs/2305.16380)

    本文分析了1层Transformer在下一个标记预测任务中的SGD训练动态，证明了自我关注层充当了“区分性扫描算法”，从而逐步关注到相关标记并排除不相关的标记，总结相关信息在编码表示中。同时研究了标记频率、上下文和初始化自我关注层等对Transformer性能的影响。

    

    Transformer架构在多个研究领域表现出了惊人的性能，并成为许多神经网络模型的基础。然而，我们对其如何工作的理解仍然有限。特别是，通过简单的预测性损失，表示如何从梯度训练动态中出现仍然是一个谜。在本文中，针对具有一个自我关注层和一个解码器层的1层Transformer，我们以数学严谨的方式分析其在下一个标记预测任务中的SGD训练动态。我们打开了自我关注层组合输入标记的动态过程的黑盒子，并揭示了底层归纳偏差的本质。具体而言，在没有位置编码、长输入序列和解码器层学习速度快于自我关注层的假设下，我们证明了自我关注层充当了“区分性扫描算法”：从均匀注意力开始，它逐渐关注到相关标记，排除不相关的标记，直到所有相关信息被扫描并总结在编码表示中。我们的分析还显示了标记频率和上下文如何影响注意权重，以及自我关注层初始化如何影响收敛速度。

    Transformer architecture has shown impressive performance in multiple research domains and has become the backbone of many neural network models. However, there is limited understanding on how it works. In particular, with a simple predictive loss, how the representation emerges from the gradient \emph{training dynamics} remains a mystery. In this paper, for 1-layer transformer with one self-attention layer plus one decoder layer, we analyze its SGD training dynamics for the task of next token prediction in a mathematically rigorous manner. We open the black box of the dynamic process of how the self-attention layer combines input tokens, and reveal the nature of underlying inductive bias. More specifically, with the assumption (a) no positional encoding, (b) long input sequence, and (c) the decoder layer learns faster than the self-attention layer, we prove that self-attention acts as a \emph{discriminative scanning algorithm}: starting from uniform attention, it gradually attends mor
    
[^63]: 大语言模型角色扮演

    Role-Play with Large Language Models. (arXiv:2305.16367v1 [cs.CL])

    [http://arxiv.org/abs/2305.16367](http://arxiv.org/abs/2305.16367)

    本文将对话代理行为描述为角色扮演，以避免赋予其人类特征，在此基础上研究代理行为中的欺骗和自我意识。

    

    随着对话代理程序在表现上越来越接近人类，有必要开发有效的方式高层次描述其行为，而不会陷入赋予其人类特征的陷阱。本文提出了角色扮演的概念，将对话代理程序的行为视为角色扮演，使我们能够借鉴熟悉的民间心理学术语，而不是赋予它们实际上并不具备的人类特征。本文以(表面上的)欺骗和(表面上的)自我意识为例，探讨了对话代理程序行为的两种情况。

    As dialogue agents become increasingly human-like in their performance, it is imperative that we develop effective ways to describe their behaviour in high-level terms without falling into the trap of anthropomorphism. In this paper, we foreground the concept of role-play. Casting dialogue agent behaviour in terms of role-play allows us to draw on familiar folk psychological terms, without ascribing human characteristics to language models they in fact lack. Two important cases of dialogue agent behaviour are addressed this way, namely (apparent) deception and (apparent) self-awareness.
    
[^64]: 减少谜团：基于子目标的演示学习在形式定理证明中的应用

    Decomposing the Enigma: Subgoal-based Demonstration Learning for Formal Theorem Proving. (arXiv:2305.16366v1 [cs.CL])

    [http://arxiv.org/abs/2305.16366](http://arxiv.org/abs/2305.16366)

    本文提出了一个基于子目标的演示学习框架，通过将基于子目标的学习方法与扩散模型相结合，提高演示的可理解性，并提高LLMs在形式定理证明中的吞吐量。

    

    大型语言模型（LLMs）在形式定理证明领域提供了有趣的探索方向。然而，如何完全利用这些模型，特别是在演示格式和组织方面，仍然是一个未被充分探索的领域。为了增强LLMs的效能，作者提出了一个基于子目标的演示学习框架，包括两个主要元素：第一，从强化学习和机器人领域的子目标学习中汲取经验，为每个演示示例构建不同的子目标，并根据相关的子目标学习理论来优化这些子目标。第二，利用最近扩散模型的进展来预测最佳组织方式，同时解决演示组织领域中存在的两个复杂问题：子集选择和顺序确定。通过将基于子目标的学习方法与扩散模型相结合，作者提出的框架可以提高演示的可理解性，并提高LLMs在形式定理证明中的吞吐量。

    Large language models~(LLMs) present an intriguing avenue of exploration in the domain of formal theorem proving. Nonetheless, the full utilization of these models, particularly in terms of demonstration formatting and organization, remains an underexplored area. In an endeavor to enhance the efficacy of LLMs, we introduce a subgoal-based demonstration learning framework, consisting of two primary elements: Firstly, drawing upon the insights of subgoal learning from the domains of reinforcement learning and robotics, we propose the construction of distinct subgoals for each demonstration example and refine these subgoals in accordance with the pertinent theories of subgoal learning. Secondly, we build upon recent advances in diffusion models to predict the optimal organization, simultaneously addressing two intricate issues that persist within the domain of demonstration organization: subset selection and order determination. Through the integration of subgoal-based learning methodolog
    
[^65]: EDM3：事件检测作为多任务文本生成

    EDM3: Event Detection as Multi-task Text Generation. (arXiv:2305.16357v1 [cs.CL])

    [http://arxiv.org/abs/2305.16357](http://arxiv.org/abs/2305.16357)

    EDM3是一种新颖的事件检测方法，可以同时执行事件检测及其子任务，减少了误差传播。与先前基于数据集或特定领域的方法不同，EDM3利用现有语言模型的知识进行训练，在多个事件检测数据集上性能表现优异。

    

    事件检测指的是在文本中识别事件出现并包括两个子任务；事件识别和事件分类。我们提出了EDM3，一种新颖的事件检测方法，其构建了三个生成式任务：识别、分类和联合检测。我们展示EDM3能够帮助学习可转移的知识，使其能够同时执行事件检测及其子任务，减少了流水线方法中存在的误差传播。与先前基于数据集或特定领域的方法不同，EDM3利用了语言模型的现有知识，使其能够在任何分类模式上进行训练。我们在多个事件检测数据集上对EDM3进行了评估：RAMS、WikiEvents、MAVEN和MLEE，表明EDM3的平均单任务性能优于8.4％，平均无需指示性提示的多任务性能优于2.4％。我们在RAMS上获得了SOTA的结果（71.3％与65.1％的F-1），在其他数据集上也表现出了有竞争力的性能.

    Event detection refers to identifying event occurrences in a text and comprises of two subtasks; event identification and classification. We present EDM3, a novel approach for Event Detection that formulates three generative tasks: identification, classification, and combined detection. We show that EDM3 helps to learn transferable knowledge that can be leveraged to perform Event Detection and its subtasks concurrently, mitigating the error propagation inherent in pipelined approaches. Unlike previous dataset- or domain-specific approaches, EDM3 utilizes the existing knowledge of language models, allowing it to be trained over any classification schema. We evaluate EDM3 on multiple event detection datasets: RAMS, WikiEvents, MAVEN, and MLEE, showing that EDM3 outperforms 1) single-task performance by 8.4% on average and 2) multi-task performance without instructional prompts by 2.4% on average. We obtain SOTA results on RAMS (71.3% vs. 65.1% F-1) and competitive performance on other da
    
[^66]: PandaGPT: 一种能够执行图像、音频指令的语言模型

    PandaGPT: One Model To Instruction-Follow Them All. (arXiv:2305.16355v1 [cs.CL])

    [http://arxiv.org/abs/2305.16355](http://arxiv.org/abs/2305.16355)

    PandaGPT是一种能够同时接受多模态输入，并用于生成复杂任务输出的可学习语言模型。

    

    我们提出了一种名为PandaGPT的方法，通过对齐图像-文本对训练语言模型，将ImageBind的多模态编码器和Vicuna的大型语言模型结合起来，使其具有视觉和听觉指令跟踪能力。实验结果表明，除了可以生成详细的图像描述、写故事、还能够自然地组合多个数据的语义，以回答各种问题。

    We present PandaGPT, an approach to emPower large lANguage moDels with visual and Auditory instruction-following capabilities. Our pilot experiments show that PandaGPT can perform complex tasks such as detailed image description generation, writing stories inspired by videos, and answering questions about audios. More interestingly, PandaGPT can take multimodal inputs simultaneously and compose their semantics naturally. For example, PandaGPT can connect how objects look in an image/video and how they sound in an audio. To do so, PandaGPT combines the multimodal encoders from ImageBind and the large language models from Vicuna. Notably, only aligned image-text pairs are required for the training of PandaGPT. Thanks to the strong capability of ImageBind in embedding data from different modalities into the same space, PandaGPT displays emergent, i.e. zero-shot, cross-modal behaviors for data other than image and text (e.g., video, audio, depth, thermal, and IMU). We hope that PandaGPT se
    
[^67]: 自我背叛：利用单声道转立体声技术进行深度伪造音频的检测

    Betray Oneself: A Novel Audio DeepFake Detection Model via Mono-to-Stereo Conversion. (arXiv:2305.16353v1 [cs.SD])

    [http://arxiv.org/abs/2305.16353](http://arxiv.org/abs/2305.16353)

    本文提出了一种名为M2S-ADD的新型ADD模型，通过单声道转立体声技术发现伪造音频中的真实性线索，显著提高了检测性能。

    

    音频深度伪造检测(Audio Deepfake Detection, ADD)旨在检测由文本转语音(TTS)、语音转换(VC)、重放等生成的虚假音频，是一个新兴的研究领域。传统的研究方法将单声道信号作为输入，重点在于稳健的特征提取和有效的分类器设计。然而，音频信号中的双通道立体声信息也包含了深度伪造的重要线索，这在先前的工作中尚未得到研究。本文提出了一种新颖的ADD模型，称为M2S-ADD，旨在在单声道转立体声过程中发现音频真实性线索。我们首先使用预训练的立体声合成器将单声道投影到立体声信号上，然后采用双分支神经架构分别处理左右声道信号。这样，我们有效地揭示了伪造音频中的伪影，从而提高了ADD的性能。在ASVspoof2019数据库上的实验结果表明，M2S-ADD在所有输入单声道的基线模型中表现最佳。

    Audio Deepfake Detection (ADD) aims to detect the fake audio generated by text-to-speech (TTS), voice conversion (VC) and replay, etc., which is an emerging topic. Traditionally we take the mono signal as input and focus on robust feature extraction and effective classifier design. However, the dual-channel stereo information in the audio signal also includes important cues for deepfake, which has not been studied in the prior work. In this paper, we propose a novel ADD model, termed as M2S-ADD, that attempts to discover audio authenticity cues during the mono-to-stereo conversion process. We first projects the mono to a stereo signal using a pretrained stereo synthesizer, then employs a dual-branch neural architecture to process the left and right channel signals, respectively. In this way, we effectively reveal the artifacts in the fake audio, thus improve the ADD performance. The experiments on the ASVspoof2019 database show that M2S-ADD outperforms all baselines that input mono. We
    
[^68]: Lexinvariant语言模型

    Lexinvariant Language Models. (arXiv:2305.16349v1 [cs.CL])

    [http://arxiv.org/abs/2305.16349](http://arxiv.org/abs/2305.16349)

    本文讨论了一种新型的语言模型，称为Lexinvariant语言模型，该模型不需要任何固定标记嵌入，完全依赖上下文中标记的共现和重复。作者证明可以构建一个lexinvariant LM，以多项式方式与上下文长度成比例地收敛到真实语言模型，其常量因子在词汇表大小下为次线性。

    

    令牌嵌入是从离散词汇符号到连续向量的映射，是任何语言模型（LM）的核心。但是，词汇符号的含义也可以通过它们在长上下文中的结构角色来确定甚至重新定义。在本文中，我们问：是否可能存在一种没有任何固定标记嵌入的性能良好的语言模型？这样的语言模型将完全依赖于上下文中标记的共现和重复，而不是任何标记的\textit{a priori}标识。为了回答这个问题，我们研究了\textit{lexinvariant}语言模型，这些语言模型对词汇符号不变，因此在实践中不需要固定的令牌嵌入。首先，我们证明可以构建一个lexinvariant LM，以多项式方式与上下文长度成比例地收敛到真实语言模型，其常量因子在词汇表大小下为次线性。其次，要构建一个lexinvariant LM，我们只需使用随机高斯函数对标记进行编码。

    Token embeddings, a mapping from discrete lexical symbols to continuous vectors, are at the heart of any language model (LM). However, lexical symbol meanings can also be determined and even redefined by their structural role in a long context. In this paper, we ask: is it possible for a language model to be performant without \emph{any} fixed token embeddings? Such a language model would have to rely entirely on the co-occurence and repetition of tokens in the context rather than the \textit{a priori} identity of any token. To answer this, we study \textit{lexinvariant}language models that are invariant to lexical symbols and therefore do not need fixed token embeddings in practice. First, we prove that we can construct a lexinvariant LM to converge to the true language model at a uniform rate that is polynomial in terms of the context length, with a constant factor that is sublinear in the vocabulary size. Second, to build a lexinvariant LM, we simply encode tokens using random Gauss
    
[^69]: 利用LLMs从混合长文档中检索KPI的全面框架与数据集

    Leveraging LLMs for KPIs Retrieval from Hybrid Long-Document: A Comprehensive Framework and Dataset. (arXiv:2305.16344v1 [cs.CL])

    [http://arxiv.org/abs/2305.16344](http://arxiv.org/abs/2305.16344)

    本文提出了一个自动化财务信息提取的框架（AFIE），用于提取混合长文档中的关键业绩指标（KPI）。该框架利用LLMs增强了财务报告信息的理解和提取能力，并经过了广泛的实验验证，证明其在GPT-3.5和GPT-4上的有效性，相对于朴素方法，平均精度提高了53.94％和33.77％。

    

    大型语言模型（LLMs）在文本理解和表格推理任务中展现出了卓越的性能，但它们对包含文本和表格数据的混合文本的理解和分析能力仍未被充分发掘。本研究专注于利用LLMs的潜力，从混杂的长型财务报告中理解关键信息。我们提出了自动化财务信息提取（AFIE）框架，增强了LLMs理解和提取财务报告信息的能力。为了评估AFIE，我们开发了一个金融报告数值提取（FINE）数据集，并进行了广泛的实验分析。我们的框架在GPT-3.5和GPT-4上得到了有效验证，相对于朴素方法，平均精度提高了53.94％和33.77％。这些结果表明，AFIE框架为从复杂的混合文档中自动提取数值提供了准确性。

    Large Language Models (LLMs) demonstrate exceptional performance in textual understanding and tabular reasoning tasks. However, their ability to comprehend and analyze hybrid text, containing textual and tabular data, remains underexplored. In this research, we specialize in harnessing the potential of LLMs to comprehend critical information from financial reports, which are hybrid long-documents. We propose an Automated Financial Information Extraction (AFIE) framework that enhances LLMs' ability to comprehend and extract information from financial reports. To evaluate AFIE, we develop a Financial Reports Numerical Extraction (FINE) dataset and conduct an extensive experimental analysis. Our framework is effectively validated on GPT-3.5 and GPT-4, yielding average accuracy increases of 53.94% and 33.77%, respectively, compared to a naive method. These results suggest that the AFIE framework offers accuracy for automated numerical extraction from complex, hybrid documents.
    
[^70]: 基于Spark生态系统的分布式自动领域特定多词术语识别架构

    A Distributed Automatic Domain-Specific Multi-Word Term Recognition Architecture using Spark Ecosystem. (arXiv:2305.16343v1 [cs.CL])

    [http://arxiv.org/abs/2305.16343](http://arxiv.org/abs/2305.16343)

    本论文提出了一种基于Spark生态系统的分布式架构，可自动提取领域特定术语，经实验证明在术语提取准确性方面取得最先进的结果。

    

    自动术语识别用于提取属于给定领域的特定术语。为了准确，这些基于语料库和语言依赖的方法需要处理大量文本数据以提取候选术语，然后根据给定的度量标准进行评分。为了改进文本预处理和候选术语的提取和评分，我们提出了一种使用Spark生态系统自动提取领域特定术语的分布式架构。主要贡献如下：（1）提出了一种新颖的分布式自动领域特定多词术语识别架构，构建在Spark生态系统之上；（2）从准确性和可扩展性方面对我们的架构进行了深入分析；（3）设计了一个易于集成的Python实现，使其能够在计算语言学和自然语言处理等领域使用大数据处理。我们通过在多个数据集和领域上进行实验来经验性地证明了我们架构的可行性，在术语提取准确性方面取得了最先进的结果。

    Automatic Term Recognition is used to extract domain-specific terms that belong to a given domain. In order to be accurate, these corpus and language-dependent methods require large volumes of textual data that need to be processed to extract candidate terms that are afterward scored according to a given metric. To improve text preprocessing and candidate terms extraction and scoring, we propose a distributed Spark-based architecture to automatically extract domain-specific terms. The main contributions are as follows: (1) propose a novel distributed automatic domain-specific multi-word term recognition architecture built on top of the Spark ecosystem; (2) perform an in-depth analysis of our architecture in terms of accuracy and scalability; (3) design an easy-to-integrate Python implementation that enables the use of Big Data processing in fields such as Computational Linguistics and Natural Language Processing. We prove empirically the feasibility of our architecture by performing ex
    
[^71]: InterFormer: 混合局部和全局特征用于语音识别的交互式融合方法

    InterFormer: Interactive Local and Global Features Fusion for Automatic Speech Recognition. (arXiv:2305.16342v1 [cs.CL])

    [http://arxiv.org/abs/2305.16342](http://arxiv.org/abs/2305.16342)

    本文提出了InterFormer，用于交互式局部和全局特征融合，以学习更好的ASR表示。通过组合卷积块和变形器块，以及引入BFIM和SFM模块，实现了局部和全局特征的交互和融合，取得了在公共ASR数据集上优异的性能。

    

    对于自动语音识别（ASR）而言，局部和全局特征都是必不可少的。许多最近的方法已经证实，简单地合并局部和全局特征可以进一步提高ASR性能。然而，这些方法往往忽略了局部和全局特征之间的交互，并且它们的串行架构无法反映局部和全局特征之间的关系。为了解决这些问题，本文提出了InterFormer，用于交互式局部和全局特征融合，以学习更好的ASR表示。具体而言，我们将卷积块与变形器块以并行设计相结合。此外，我们提出了双向特征交互模块（BFIM）和选择性融合模块（SFM）来实现局部和全局特征的交互和融合。在公共ASR数据集上的大量实验表明了我们提出的InterFormer的有效性，并且相对于其他Transformer和Conformer模型具有更出色的性能。

    The local and global features are both essential for automatic speech recognition (ASR). Many recent methods have verified that simply combining local and global features can further promote ASR performance. However, these methods pay less attention to the interaction of local and global features, and their series architectures are rigid to reflect local and global relationships. To address these issues, this paper proposes InterFormer for interactive local and global features fusion to learn a better representation for ASR. Specifically, we combine the convolution block with the transformer block in a parallel design. Besides, we propose a bidirectional feature interaction module (BFIM) and a selective fusion module (SFM) to implement the interaction and fusion of local and global features, respectively. Extensive experiments on public ASR datasets demonstrate the effectiveness of our proposed InterFormer and its superior performance over the other Transformer and Conformer models.
    
[^72]: 分段循环Transformer:一种高效的序列到序列模型

    Segmented Recurrent Transformer: An Efficient Sequence-to-Sequence Model. (arXiv:2305.16340v1 [cs.CL])

    [http://arxiv.org/abs/2305.16340](http://arxiv.org/abs/2305.16340)

    本文提出了一种分段循环Transformer（SRformer）来减少计算/内存成本，并使用RAF层处理跨段的信息，从而提高序列处理能力。

    

    Transformer在许多领域中表现出卓越的性能，包括语言和视觉。然而，随着序列长度的增加，它们的计算成本呈二次增长，使得它们在资源受限的应用中使用成为不可能。为了解决这个问题，我们的方法是将整个序列划分成若干段。然后使用具有循环结构的神经元来聚合跨段的信息，从而实现具有较低计算/内存成本的序列处理能力模型。为了验证这个想法，我们首先研究了使用局部Attention机制对单个段的影响。然后我们提出了一种分段循环Transformer（SRformer），它将分段Attention和循环Attention相结合。它使用循环accumulate and fire（RAF）层在相邻段之间处理信息。通过更新key的产品来补偿减少Attention窗口长度产生的误差。

    Transformers have shown dominant performance across a range of domains including language and vision. However, their computational cost grows quadratically with the sequence length, making their usage prohibitive for resource-constrained applications. To counter this, our approach is to divide the whole sequence into segments. The information across segments can then be aggregated using neurons with recurrence leveraging their inherent memory. Such an approach leads to models with sequential processing capability at a lower computation/memory cost. To investigate this idea, first, we examine the effects of using local attention mechanism on the individual segments. Then we propose a segmented recurrent transformer (SRformer) that combines segmented attention with recurrent attention. It uses recurrent accumulate and fire (RAF) layers to process information between consecutive segments. The loss caused by reducing the attention window length is compensated by updating the product of key
    
[^73]: 当问题不是用英语提出时，不要完全信任GPT

    Don't Trust GPT When Your Question Is Not In English. (arXiv:2305.16339v1 [cs.CL])

    [http://arxiv.org/abs/2305.16339](http://arxiv.org/abs/2305.16339)

    在多语言环境下，GPT-3表现较差，特别是当问题不是用英语提出时。这与模型的训练数据和输入问题的语言差异有关。

    

    近年来，大型语言模型（LLMs）展示了出色的自然语言理解能力，并在多个自然语言处理（NLP）任务中表现出色。尽管大多数LLMs主要使用英语进行训练，但多项研究已经证明了它们在许多其他语言中的相对表现。然而，关于LLMs如何获得它们的多语言能力以及表现在不同语言中的差异仍然存在基本问题。这些问题对LLMs的研究非常关键，因为用户和研究人员通常来自多种语言背景，可能影响他们对LLMs结果的利用和解释。在本文中，我们提出了一种系统的方法，以定性评估多语言环境下LLMs的表现差异。我们调查了LLMs在跨语言泛化现象方面的表现，即不充足的多语言训练数据导致先进的多语言能力。为了实现这一目的，我们对一系列语言进行了GPT-3的实验，这些语言涵盖了从印欧语系到非印欧语系的各种语言，并提出了一种评估和验证结果的方法。我们的发现表明，即使模型在该语言上进行了微调，但如果输入问题不是英语，GPT-3在其他语言下的表现显著较差。此外，我们证明了模型的表现不佳与训练语言和输入问题的语言差异有关。我们的结果表明，在进行非英语自然语言处理任务时，需要谨慎使用LLMs。

    Large Language Models (LLMs) have demonstrated exceptional natural language understanding abilities and have excelled in a variety of natural language processing (NLP)tasks in recent years. Despite the fact that most LLMs are trained predominantly in English, multiple studies have demonstrated their comparative performance in many other languages. However, fundamental questions persist regarding how LLMs acquire their multi-lingual abilities and how performance varies across different languages. These inquiries are crucial for the study of LLMs since users and researchers often come from diverse language backgrounds, potentially influencing their utilization and interpretation of LLMs' results. In this work, we propose a systematic way of qualifying the performance disparities of LLMs under multilingual settings. We investigate the phenomenon of across-language generalizations in LLMs, wherein insufficient multi-lingual training data leads to advanced multi-lingual capabilities. To acc
    
[^74]: 深思熟虑：具有内部工作记忆的决策Transformer

    Think Before You Act: Decision Transformers with Internal Working Memory. (arXiv:2305.16338v1 [cs.LG])

    [http://arxiv.org/abs/2305.16338](http://arxiv.org/abs/2305.16338)

    该论文提出了具有内部工作记忆模块的决策Transformer方法，以解决使用大型语言模型的决策代理在处理新任务上性能低下的问题。所提出的方法改善了训练效率和泛化能力，并进一步增强了转化决策制定代理对新任务的适应性。

    

    基于大型语言模型（LLM）的决策制定代理已经展示了跨越多个任务的泛化能力。然而，它们的性能依赖于大规模的数据和计算。我们认为，这种低效性源于遗忘现象，即模型通过参数记忆其行为，在训练过程中。因此，新任务的训练可能会降低模型在先前任务上的性能。与LLM的隐式记忆机制不同，人脑利用分布式存储器存储记忆，以有效地管理和组织多种技能，减轻了遗忘现象。因此，我们建议使用内部工作记忆模块来存储、融合和检索不同下游任务的信息。评估结果表明，所提出的方法改善了Atari游戏和元世界物体操作任务的训练效率和泛化能力。此外，我们证明了记忆微调进一步增强了转化决策制定代理对新任务的适应性。

    Large language model (LLM)-based decision-making agents have shown the ability to generalize across multiple tasks. However, their performance relies on massive data and compute. We argue that this inefficiency stems from the forgetting phenomenon, in which a model memorizes its behaviors in parameters throughout training. As a result, training on a new task may deteriorate the model's performance on previous tasks. In contrast to LLMs' implicit memory mechanism, the human brain utilizes distributed memory storage, which helps manage and organize multiple skills efficiently, mitigating the forgetting phenomenon. Thus inspired, we propose an internal working memory module to store, blend, and retrieve information for different downstream tasks. Evaluation results show that the proposed method improves training efficiency and generalization in both Atari games and meta-world object manipulation tasks. Moreover, we demonstrate that memory fine-tuning further enhances the adaptability of t
    
[^75]: 处理BERT文本分类中的现实标签噪声

    Handling Realistic Label Noise in BERT Text Classification. (arXiv:2305.16337v1 [cs.CL])

    [http://arxiv.org/abs/2305.16337](http://arxiv.org/abs/2305.16337)

    本文研究了BERT在现实标签噪声存在下的分类性能，发现特征相关的标签噪声和来自注释者分歧的合成标签噪声会导致BERT的分类性能下降。提出不同类型的集成和噪声清理方法以提高鲁棒性。

    

    标签噪声是由于廉价的数据标注方法（如网络爬取或众包）导致的训练标签中的错误，这可能对监督分类器的性能有害。已经提出了几种方法来抵消有监督分类中随机标签噪声的影响，并且一些研究已经表明BERT已经对高比率的随机注入标签噪声具有鲁棒性。然而，真实的标签噪声并不是随机的，而是经常与输入特征或其他注释者特定因素相关。在本文中，我们评估了BERT在面对两种类型的现实标签噪声：特征相关的标签噪声和来自注释者分歧的合成标签噪声。我们表明这些类型噪声的存在显著降低了BERT分类性能。为了提高其鲁棒性，我们评估了不同类型的集成和噪声清理方法，并比较它们在不同数据集中对标签噪声的效果。

    Labels noise refers to errors in training labels caused by cheap data annotation methods, such as web scraping or crowd-sourcing, which can be detrimental to the performance of supervised classifiers. Several methods have been proposed to counteract the effect of random label noise in supervised classification, and some studies have shown that BERT is already robust against high rates of randomly injected label noise. However, real label noise is not random; rather, it is often correlated with input features or other annotator-specific factors. In this paper, we evaluate BERT in the presence of two types of realistic label noise: feature-dependent label noise, and synthetic label noise from annotator disagreements. We show that the presence of these types of noise significantly degrades BERT classification performance. To improve robustness, we evaluate different types of ensembles and noise-cleaning methods and compare their effectiveness against label noise across different datasets.
    
[^76]: 基于自适应最优输运的健壮短文本聚类中可靠伪标签的表示学习

    Robust Representation Learning with Reliable Pseudo-labels Generation via Self-Adaptive Optimal Transport for Short Text Clustering. (arXiv:2305.16335v1 [cs.CL])

    [http://arxiv.org/abs/2305.16335](http://arxiv.org/abs/2305.16335)

    本文提出了一种健壮短文本聚类（RSTC）模型，通过自适应最优输运的伪标签生成，以及基于类和实例的对比学习的健壮表示学习，帮助提高对不平衡和噪音数据的鲁棒性。

    

    短文本聚类因输入的不平衡和噪音数据而具有挑战性。现有方法无法很好地解决这个问题，因为它们容易在重度不平衡数据集上获得退化的解决方案，且易受到噪声干扰。为了解决这个问题，我们提出了一种健壮短文本聚类（RSTC）模型，以提高对不平衡和噪音数据的鲁棒性。RSTC包括两个模块，即伪标记生成模块和健壮表示学习模块。前者生成伪标记，为后者提供监督，有助于更健壮的表示和正确分离的聚类。为了提供对数据不平衡的鲁棒性，在伪标签生成模块中提出了自适应最优输运。为了提高对数据中噪声的鲁棒性，在健壮表示学习模块中进一步引入了基于类和实例的对比学习。

    Short text clustering is challenging since it takes imbalanced and noisy data as inputs. Existing approaches cannot solve this problem well, since (1) they are prone to obtain degenerate solutions especially on heavy imbalanced datasets, and (2) they are vulnerable to noises. To tackle the above issues, we propose a Robust Short Text Clustering (RSTC) model to improve robustness against imbalanced and noisy data. RSTC includes two modules, i.e., pseudo-label generation module and robust representation learning module. The former generates pseudo-labels to provide supervision for the later, which contributes to more robust representations and correctly separated clusters. To provide robustness against the imbalance in data, we propose self-adaptive optimal transport in the pseudo-label generation module. To improve robustness against the noise in data, we further introduce both class-wise and instance-wise contrastive learning in the robust representation learning module. Our empirical 
    
[^77]: OlaGPT：让大型语言模型具备类人的问题解决能力

    OlaGPT: Empowering LLMs With Human-like Problem-Solving Abilities. (arXiv:2305.16334v1 [cs.CL])

    [http://arxiv.org/abs/2305.16334](http://arxiv.org/abs/2305.16334)

    OlaGPT是一种新颖的智能框架，能够模拟人类在解决复杂推理问题时所采用的各种认知能力和与工具、知识和外部环境信息的交互，可以让大型语言模型具备类人的问题解决能力。

    

    目前大多数研究中，大型语言模型（LLMs）在特定提示的指导下通过生成思维链来执行推理任务。然而，它们在解决复杂推理问题上与人类的能力存在显著差距。目前，大多数方法都专注于思维链（COT）和工具使用，而忽视了采用和应用人类认知框架的重要性。人们通常在面对复杂的推理挑战时，会运用各种认知能力，并需要与工具、知识和外部环境信息的所有方面进行交互，才能完成复杂的任务。本文介绍了一种新颖的智能框架，称为OlaGPT。OlaGPT仔细研究了认知架构框架，并提出模拟人类认知的某些方面。该框架涉及近似不同的认知模块，包括关注力。

    In most current research, large language models (LLMs) are able to perform reasoning tasks by generating chains of thought through the guidance of specific prompts. However, there still exists a significant discrepancy between their capability in solving complex reasoning problems and that of humans. At present, most approaches focus on chains of thought (COT) and tool use, without considering the adoption and application of human cognitive frameworks. It is well-known that when confronting complex reasoning challenges, humans typically employ various cognitive abilities, and necessitate interaction with all aspects of tools, knowledge, and the external environment information to accomplish intricate tasks. This paper introduces a novel intelligent framework, referred to as OlaGPT. OlaGPT carefully studied a cognitive architecture framework, and propose to simulate certain aspects of human cognition. The framework involves approximating different cognitive modules, including attention,
    
[^78]: 基于语音合成的文本生成用于ASR数据增广

    Text Generation with Speech Synthesis for ASR Data Augmentation. (arXiv:2305.16333v1 [cs.CL])

    [http://arxiv.org/abs/2305.16333](http://arxiv.org/abs/2305.16333)

    本研究探索文本增广对ASR的影响，使用大规模预训练的神经网络来生成合成文本，并通过文本到语音系统转换为合成语音，实验发现，使用神经网络的文本增广方法能够有效提高ASR准确度，可以作为改进ASR系统的一种可行工具。

    

    为了减少对昂贵人工注释的依赖，数据增广一直是自动语音识别（ASR）领域的一个热门研究方向。先前的研究主要侧重于用于ASR数据增广的合成语音生成，而其与文本生成方法的结合却相对较少探索。在本文中，我们使用大规模预训练的神经网络探索文本增广对ASR的影响，并将其与传统文本增广方法进行了系统比较。生成的合成文本然后通过文本到语音（TTS）系统转换为合成语音，并添加到ASR训练数据中。我们在三个数据集上进行的实验发现，神经模型实现了9％-15％的相对WER改进，并优于传统方法。我们得出结论，特别是通过现代神经方法，文本增广是提高ASR系统准确性的一种可行工具。

    Aiming at reducing the reliance on expensive human annotations, data synthesis for Automatic Speech Recognition (ASR) has remained an active area of research. While prior work mainly focuses on synthetic speech generation for ASR data augmentation, its combination with text generation methods is considerably less explored. In this work, we explore text augmentation for ASR using large-scale pre-trained neural networks, and systematically compare those to traditional text augmentation methods. The generated synthetic texts are then converted to synthetic speech using a text-to-speech (TTS) system and added to the ASR training data. In experiments conducted on three datasets, we find that neural models achieve 9%-15% relative WER improvement and outperform traditional methods. We conclude that text augmentation, particularly through modern neural approaches, is a viable tool for improving the accuracy of ASR systems.
    
[^79]: 视觉上下文语言模型中的语义组合

    Semantic Composition in Visually Grounded Language Models. (arXiv:2305.16328v1 [cs.CL])

    [http://arxiv.org/abs/2305.16328](http://arxiv.org/abs/2305.16328)

    本论文研究了视觉上下文语言模型中的语义组合能力，提出了新的组合视觉问答基准，句法神经模块蒸馏等方法以提高组合能力，并探索了对图像字幕模型的因果追踪以定位重要神经表示。

    

    句子的意义和其理想表达方式是什么？人类语言表现力的很大一部分来自语义组合，即人类心智以层次化和关系性方式表示意义的能力。与此同时，大部分句子的意义存在于文本之外，需要基于感官、运动和体验模态进行充分的学习。尽管大型语言模型显示出相当的组合能力，但最近的研究表明，有视觉基础的语言模型在表示组合结构时严重失败。在本论文中，我们探讨了模型是否及如何组合视觉上下文语义以及如何提高其组合能力。具体而言，我们介绍了 1) WinogroundVQA，一个新的组合视觉问答基准，2) 句子嵌入模型中组合能力的句法神经模块蒸馏，3) 对于图像字幕模型的因果追踪，以定位重要的神经表示。

    What is sentence meaning and its ideal representation? Much of the expressive power of human language derives from semantic composition, the mind's ability to represent meaning hierarchically & relationally over constituents. At the same time, much sentential meaning is outside the text and requires grounding in sensory, motor, and experiential modalities to be adequately learned. Although large language models display considerable compositional ability, recent work shows that visually-grounded language models drastically fail to represent compositional structure. In this thesis, we explore whether & how models compose visually grounded semantics, and how we might improve their ability to do so.  Specifically, we introduce 1) WinogroundVQA, a new compositional visual question answering benchmark, 2) Syntactic Neural Module Distillation, a measure of compositional ability in sentence embedding models, 3) Causal Tracing for Image Captioning Models to locate neural representations vital f
    
[^80]: 生物医学自然语言处理中的大型语言模型: 基准、基线和建议

    Large language models in biomedical natural language processing: benchmarks, baselines, and recommendations. (arXiv:2305.16326v1 [cs.CL])

    [http://arxiv.org/abs/2305.16326](http://arxiv.org/abs/2305.16326)

    本文研究了GPT-3和GPT-4在生物医学自然语言处理中的表现，分析了它们可能产生的错误类型，并提供了使用这些模型的建议。

    

    生物医学文献呈指数级增长，手动筛选和提取知识变得困难。自动从生物医学文献中提取信息的生物医学自然语言处理（BioNLP）技术有助于减轻这种负担。近年来，如GPT-3和GPT-4等大型语言模型（LLMs）因其卓越的性能而受到重视。但是，它们在BioNLP任务中的有效性以及对方法开发和下游用户的影响仍未得到研究。本研究（1）在四个应用程序中在八个BioNLP数据集中建立了GPT-3和GPT-4在零-shot和一-shot设置下的基准表现，包括命名实体识别，关系提取，多标签文档分类和语义相似性和推理；（2）审查了LLMs产生的错误，并将错误分为三种类型：缺失，不一致和不需要的人工内容；（3）提出了使用LLMs的建议。

    Biomedical literature is growing rapidly, making it challenging to curate and extract knowledge manually. Biomedical natural language processing (BioNLP) techniques that can automatically extract information from biomedical literature help alleviate this burden. Recently, large Language Models (LLMs), such as GPT-3 and GPT-4, have gained significant attention for their impressive performance. However, their effectiveness in BioNLP tasks and impact on method development and downstream users remain understudied. This pilot study (1) establishes the baseline performance of GPT-3 and GPT-4 at both zero-shot and one-shot settings in eight BioNLP datasets across four applications: named entity recognition, relation extraction, multi-label document classification, and semantic similarity and reasoning, (2) examines the errors produced by the LLMs and categorized the errors into three types: missingness, inconsistencies, and unwanted artificial content, and (3) provides suggestions for using L
    
[^81]: 与机器对话：新兴对话系统的综合调查

    Talking with Machines: A Comprehensive Survey of Emergent Dialogue Systems. (arXiv:2305.16324v1 [cs.CL])

    [http://arxiv.org/abs/2305.16324](http://arxiv.org/abs/2305.16324)

    本文全面综述了对话系统的发展历史、基本运作、流行和新兴数据集、关键贡献、评估指标和挑战，展望了该领域的未来前景。

    

    从20世纪的最早实验到现在大规模语言模型和变压器技术的应用，对话系统研究一直在不断发展，在众多领域发挥着重要作用。本文提供了一份全面的这些系统综述，追溯它们的历史发展并检查它们的基本运作。我们分析了用于训练的流行和新兴数据集，并调查了对话系统研究中的关键贡献，包括传统系统和先进的机器学习方法。最后，我们考虑常规和基于变压器的评估指标，然后简要讨论了该领域的主要挑战和未来前景。

    From the earliest experiments in the 20th century to the utilization of large language models and transformers, dialogue systems research has continued to evolve, playing crucial roles in numerous fields. This paper offers a comprehensive review of these systems, tracing their historical development and examining their fundamental operations. We analyze popular and emerging datasets for training and survey key contributions in dialogue systems research, including traditional systems and advanced machine learning methods. Finally, we consider conventional and transformer-based evaluation metrics, followed by a short discussion of prevailing challenges and future prospects in the field.
    
[^82]: UNITE: 一个用于文本到SQL评估的统一基准

    UNITE: A Unified Benchmark for Text-to-SQL Evaluation. (arXiv:2305.16265v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.16265](http://arxiv.org/abs/2305.16265)

    提出了一个统一的基准UNITE用于文本到SQL评估，包含来自12个以上领域的自然语言问题、超过3.9K种模式的SQL查询和29K个数据库。研究表明，Codex在跨领域数据集上表现出色，特别设计的编码方法可以提高性能，可机读的数据库的质量对文本到SQL系统的性能至关重要。

    

    一个实用的文本到SQL系统应该可以很好地概括各种自然语言问题、未见过的数据库模式和新颖的SQL查询结构。为了全面评估文本到SQL系统，我们引入了一个统一的基准UNITE用于文本到SQL评估。该基准由公开可用的文本到SQL数据集组成，包含来自12个以上领域的自然语言问题、超过3.9K种模式的SQL查询和29K个数据库。与广泛使用的Spider基准相比，我们增加了约120K个额外的示例和三倍的SQL模式，例如比较和布尔问题。我们在新基准上对六种最先进的文本到SQL解析器进行了系统研究，并展示了：1）Codex在跨领域数据集上表现出色；2）特别设计的编码方法（例如约束束搜索）可以提高在领域内外的性能；3）可机读的数据库的质量对文本到SQL系统的性能至关重要。

    A practical text-to-SQL system should generalize well on a wide variety of natural language questions, unseen database schemas, and novel SQL query structures. To comprehensively evaluate text-to-SQL systems, we introduce a \textbf{UNI}fied benchmark for \textbf{T}ext-to-SQL \textbf{E}valuation (UNITE). It is composed of publicly available text-to-SQL datasets, containing natural language questions from more than 12 domains, SQL queries from more than 3.9K patterns, and 29K databases. Compared to the widely used Spider benchmark \cite{yu-etal-2018-spider}, we introduce $\sim$120K additional examples and a threefold increase in SQL patterns, such as comparative and boolean questions. We conduct a systematic study of six state-of-the-art (SOTA) text-to-SQL parsers on our new benchmark and show that: 1) Codex performs surprisingly well on out-of-domain datasets; 2) specially designed decoding methods (e.g. constrained beam search) can improve performance for both in-domain and out-of-doma
    
[^83]: 面向多样性的相干损失用于改进神经主题模型

    Diversity-Aware Coherence Loss for Improving Neural Topic Models. (arXiv:2305.16199v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.16199](http://arxiv.org/abs/2305.16199)

    本文提出了一种多样性感知的相干性损失，可以帮助神经主题模型在保持高多样性同时，更好地学习语料库级别的连贯性分数。

    

    神经主题建模的标准方法使用变分自编码器（VAE）框架，同时最小化估计后验和先验之间的KL散度，以及重建损失。由于神经主题模型是通过重新创建各个输入文档进行训练的，因此它们不会明确地捕获语料库级别的主题词之间的连贯性。在这项工作中，我们提出了一种新的多样性感知的相干性损失，鼓励模型学习语料库级别的连贯性分数，同时保持主题之间的高多样性。多个数据集上的实验结果表明，我们的方法可以显着提高神经主题模型的性能，而无需任何预训练或额外的参数。

    The standard approach for neural topic modeling uses a variational autoencoder (VAE) framework that jointly minimizes the KL divergence between the estimated posterior and prior, in addition to the reconstruction loss. Since neural topic models are trained by recreating individual input documents, they do not explicitly capture the coherence between topic words on the corpus level. In this work, we propose a novel diversity-aware coherence loss that encourages the model to learn corpus-level coherence scores while maintaining a high diversity between topics. Experimental results on multiple datasets show that our method significantly improves the performance of neural topic models without requiring any pretraining or additional parameters.
    
[^84]: 面向代码混合的印地语-英语数据的预训练BERT模型的比较研究

    Comparative Study of Pre-Trained BERT Models for Code-Mixed Hindi-English Data. (arXiv:2305.15722v1 [cs.CL])

    [http://arxiv.org/abs/2305.15722](http://arxiv.org/abs/2305.15722)

    本文比较了使用不同预训练Transformer模型的印地语-英语代码混合数据的性能表现，以提高情感分析、情绪识别和仇恨言论识别等自然语言处理任务的性能。

    

    “代码混合”是指在同一段文本中使用多种语言的现象。这种现象在社交媒体平台上广泛存在，并随着时间的推移越来越多地被采纳。检测语言中的外来元素并正确处理它们至关重要，因为许多人使用代码混合语言，其中任一语言都无法理解。本文重点研究低资源的印地语-英语代码混合语言，并提高不同代码混合自然语言处理任务（如情感分析、情绪识别和仇恨言论识别）的性能。我们对使用无监督方法预训练的不同基于Transformer的语言模型进行了比较分析。我们包括了代码混合模型（如HingBERT、HingRoBERTa、HingRoBERTa-Mixed、mBERT）和非代码混合模型（如AlBERT、BERT、RoBERTa），进行比较分析印地语-英语代码混合。

    The term "Code Mixed" refers to the use of more than one language in the same text. This phenomenon is predominantly observed on social media platforms, with an increasing amount of adaptation as time goes on. It is critical to detect foreign elements in a language and process them correctly, as a considerable number of individuals are using code-mixed languages that could not be comprehended by understanding one of those languages. In this work, we focus on low-resource Hindi-English code-mixed language and enhancing the performance of different code-mixed natural language processing tasks such as sentiment analysis, emotion recognition, and hate speech identification. We perform a comparative analysis of different Transformer-based language Models pre-trained using unsupervised approaches. We have included the code-mixed models like HingBERT, HingRoBERTa, HingRoBERTa-Mixed, mBERT, and non-code-mixed models like AlBERT, BERT, and RoBERTa for comparative analysis of code-mixed Hindi-En
    
[^85]: ConvGQR：面向会话搜索的生成式查询重构

    ConvGQR: Generative Query Reformulation for Conversational Search. (arXiv:2305.15645v1 [cs.IR])

    [http://arxiv.org/abs/2305.15645](http://arxiv.org/abs/2305.15645)

    本文提出了一种新的面向会话搜索的ConvGQR框架，通过结合预训练语言模型来重新构造查询，从而提供更好的搜索查询。

    

    在会话搜索中，用户当前搜索意图依赖于先前的对话历史。从整个对话上下文中确定一个良好的搜索查询是具有挑战性的。为避免查询编码器的昂贵重新训练，大部分现有方法尝试学习一个重写模型，通过模仿手动查询重写来去除当前查询的上下文。然而，手动重写的查询并不总是最好的搜索查询。训练重写模型会限制模型产生良好搜索查询的能力。本文提出一种新的框架ConvGQR，基于预训练语言模型（PLM），一个用于查询重写，另一个用于生成潜在答案，以重新构造会话查询。通过结合两者，ConvGQR可以提供更好的搜索查询。此外，为了将查询重构与检索性能联系起来，我们提出了一种基于特征选择的相似度分数模型，用于验证ConvGQR的有效性。

    In conversational search, the user's real search intent for the current turn is dependent on the previous conversation history. It is challenging to determine a good search query from the whole conversation context. To avoid the expensive re-training of the query encoder, most existing methods try to learn a rewriting model to de-contextualize the current query by mimicking the manual query rewriting. However, manually rewritten queries are not always the best search queries. Training a rewriting model on them would limit the model's ability to produce good search queries. Another useful hint is the potential answer to the question. In this paper, we propose ConvGQR, a new framework to reformulate conversational queries based on generative pre-trained language models (PLMs), one for query rewriting and another for generating potential answers. By combining both, ConvGQR can produce better search queries. In addition, to relate query reformulation to retrieval performance, we propose a 
    
[^86]: 一种严格零样例分层分类的简单有效框架

    A Simple and Effective Framework for Strict Zero-Shot Hierarchical Classification. (arXiv:2305.15282v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.15282](http://arxiv.org/abs/2305.15282)

    本研究提出了一种蕴含-矛盾预测方法，与大型语言模型结合，用于解决分层数据集中的零样例分类问题，成功实现了严格零样例分层分类。

    

    最近几年，大型语言模型（LLMs）在基准任务中表现出良好的性能，特别是在零样例或少样例情况下。然而，这些基准测试通常未能充分解决现实世界中所面临的挑战，如分层分类的挑战。为了解决这个挑战，我们将传统的分层数据集上的任务重新定义为更具指示性的长尾预测任务。我们观察到LLMs在这些情况下更容易失败。为了解决这些限制，我们提出在LLMs的基础上使用蕴含-矛盾预测方法，在严格零样例情况下获得强大的性能。重要的是，我们的方法不需要任何参数更新，这是一种资源密集型的过程，并且在多个数据集上获得了强大的性能。

    In recent years, large language models (LLMs) have achieved strong performance on benchmark tasks, especially in zero or few-shot settings. However, these benchmarks often do not adequately address the challenges posed in the real-world, such as that of hierarchical classification. In order to address this challenge, we propose refactoring conventional tasks on hierarchical datasets into a more indicative long-tail prediction task. We observe LLMs are more prone to failure in these cases. To address these limitations, we propose the use of entailment-contradiction prediction in conjunction with LLMs, which allows for strong performance in a strict zero-shot setting. Importantly, our method does not require any parameter updates, a resource-intensive process and achieves strong performance across multiple datasets.
    
[^87]: 评估OpenAI提供的Whisper ASR在Museum of the Person的生活史中进行标点符号预测和主题建模的效果

    Evaluating OpenAI's Whisper ASR for Punctuation Prediction and Topic Modeling of life histories of the Museum of the Person. (arXiv:2305.14580v1 [cs.CL])

    [http://arxiv.org/abs/2305.14580](http://arxiv.org/abs/2305.14580)

    本文首次对葡萄牙语中的Whisper ASR进行了标点符号预测方面的研究，并为标点符号预测在主题建模中的应用提供了有益的实验评估。

    

    自动语音识别（ASR）系统在人机交互应用中扮演着重要角色。然而，过去十年中提出的葡萄牙语ASR模型在正确识别自动转录中的标点符号方面存在局限性，这使得这些转录不能被其他系统、模型和甚至是人类使用。最近，OpenAI提出了Whisper ASR，这是一个通用的语音识别模型，有望处理这些限制。本研究是第一次针对葡萄牙语中Whisper的标点符号预测性能进行的研究。我们使用实验评估来考虑关于停顿点（逗号）和完整思想（感叹、疑问和句号）的理论方面，以及与基于转录的主题建模相关的实际方面，使用标点符号来提高性能的应用。

    Automatic speech recognition (ASR) systems play a key role in applications involving human-machine interactions. Despite their importance, ASR models for the Portuguese language proposed in the last decade have limitations in relation to the correct identification of punctuation marks in automatic transcriptions, which hinder the use of transcriptions by other systems, models, and even by humans. However, recently Whisper ASR was proposed by OpenAI, a general-purpose speech recognition model that has generated great expectations in dealing with such limitations. This chapter presents the first study on the performance of Whisper for punctuation prediction in the Portuguese language. We present an experimental evaluation considering both theoretical aspects involving pausing points (comma) and complete ideas (exclamation, question, and fullstop), as well as practical aspects involving transcript-based topic modeling - an application dependent on punctuation marks for promising performan
    
[^88]: SPEECH: 基于能量的事件中心超球的结构化预测

    SPEECH: Structured Prediction with Energy-Based Event-Centric Hyperspheres. (arXiv:2305.13617v1 [cs.CL])

    [http://arxiv.org/abs/2305.13617](http://arxiv.org/abs/2305.13617)

    这篇论文提出了一种称为SPEECH的模型，它使用能量建模来表示复杂的事件结构，并使用超球来表示事件类别。实验结果表明，SPEECH在事件检测和事件关系抽取任务中表现出卓越的性能。

    

    事件中心的结构化预测涉及预测事件的结构化输出。在大多数自然语言处理情况下，事件结构都具有复杂的依赖关系，因此有效地表示这些复杂的事件结构是具有挑战性的。为了解决这些问题，我们提出了基于能量的事件中心超球的结构化预测 (SPEECH)。 SPEECH 使用基于能量的建模来模拟事件结构组件之间的复杂依赖关系，并使用简单但有效的超球来表示事件类别。在两个统一标注的事件数据集的实验中，结果表明SPEECH在事件检测和事件关系抽取任务中占优势。

    Event-centric structured prediction involves predicting structured outputs of events. In most NLP cases, event structures are complex with manifold dependency, and it is challenging to effectively represent these complicated structured events. To address these issues, we propose Structured Prediction with Energy-based Event-Centric Hyperspheres (SPEECH). SPEECH models complex dependency among event structured components with energy-based modeling, and represents event classes with simple but effective hyperspheres. Experiments on two unified-annotated event datasets indicate that SPEECH is predominant in event detection and event-relation extraction tasks.
    
[^89]: 不对称学习率的分离式理性化: 一种灵活的Lipschitz限制

    Decoupled Rationalization with Asymmetric Learning Rates: A Flexible Lipshitz Restraint. (arXiv:2305.13599v1 [cs.LG])

    [http://arxiv.org/abs/2305.13599](http://arxiv.org/abs/2305.13599)

    本文提出了一种名为DR的灵活的方法，它通过不对称的学习率来解决由合作博弈引发的退化问题，该方法能够在两个基准测试中显著改善表现。

    

    通常情况下，自说明理性化模型通过合作博弈构建，其中生成器从输入文本中选择最易理解的部分作为原理，接着预测器基于所选择的原理进行预测。然而，这种合作博弈可能会引发退化问题，预测器过度拟合于由尚未训练好的生成器生成的信息不足的部分，反过来导致生成器收敛于趋向于选择无意义的部分的次优模型。本文从理论上将退化问题与预测器的Lipschitz连续性联系起来。随后，我们实验性地提出了一种名为DR的简单而有效的方法，可以自然、灵活地约束预测器的Lipschitz常数，并解决了退化问题。DR方法的主要思想是将生成器和预测器分离，为它们分配不对称的学习率。在两个广泛使用的基准测试中进行的一系列实验表明，我们的DR方法能够显著改善现有方法的表现。

    A self-explaining rationalization model is generally constructed by a cooperative game where a generator selects the most human-intelligible pieces from the input text as rationales, followed by a predictor that makes predictions based on the selected rationales. However, such a cooperative game may incur the degeneration problem where the predictor overfits to the uninformative pieces generated by a not yet well-trained generator and in turn, leads the generator to converge to a sub-optimal model that tends to select senseless pieces. In this paper, we theoretically bridge degeneration with the predictor's Lipschitz continuity. Then, we empirically propose a simple but effective method named DR, which can naturally and flexibly restrain the Lipschitz constant of the predictor, to address the problem of degeneration. The main idea of DR is to decouple the generator and predictor to allocate them with asymmetric learning rates. A series of experiments conducted on two widely used benchm
    
[^90]: 将挪威UD Treebank与实体和共指信息对齐

    Aligning the Norwegian UD Treebank with Entity and Coreference Information. (arXiv:2305.13527v1 [cs.CL])

    [http://arxiv.org/abs/2305.13527](http://arxiv.org/abs/2305.13527)

    本文将挪威两种书写形式语料库中的实体和共指标注数据合并到了通用依存语料库（UD treebanks）中，这是第一个加入实体和共指信息的挪威UD treebank，对未来语料库对齐和共指注释工作有帮助。

    

    本文介绍了一个基于挪威两种书写形式语料库──Bokm{å}l和Nynorsk的通用依存语料库（UD treebanks）中的实体和共指标注数据的合并集合。所合并的数据集包括Norwegian Named Entities（NorNE）和Norwegian Anaphora Resolution Corpus（NARC）两部分。虽然NorNE与旧版本的treebank对齐，但NARC则未能对齐，需要从原始注释到UD结构和CoNLL-U格式进行广泛的转换。我们在此演示了转换和对齐过程，并分析了发现的数据问题和错误，其中包括原始treebank中的数据分割重叠问题。这些程序和开发的系统可能有助于未来的语料库对齐和共指注释工作。合并的语料库包括第一个加入命名实体和共指信息的挪威UD treebank。

    This paper presents a merged collection of entity and coreference annotated data grounded in the Universal Dependencies (UD) treebanks for the two written forms of Norwegian: Bokm{\aa}l and Nynorsk. The aligned and converted corpora are the \textit{Norwegian Named Entities} (NorNE) and \textit{Norwegian Anaphora Resolution Corpus} (NARC). While NorNE is aligned with an older version of the treebank, NARC is misaligned and requires extensive transformation from the original annotations to the UD structure and CoNLL-U format. We here demonstrate the conversion and alignment processes, along with an analysis of discovered issues and errors in the data -- some of which include data split overlaps in the original treebank. These procedures and the developed system may prove helpful for future corpus alignment and coreference annotation endeavors. The merged corpora comprise the first Norwegian UD treebank enriched with named entities and coreference information.
    
[^91]: 使用大型语言模型进行基因集概括

    Gene Set Summarization using Large Language Models. (arXiv:2305.13338v1 [q-bio.GN])

    [http://arxiv.org/abs/2305.13338](http://arxiv.org/abs/2305.13338)

    该论文介绍了一种使用大型语言模型来对基因集进行函数概括的方法，名为SPINDOCTOR，可以提供比传统方法更好的性能和可解释性。

    

    分子生物学家经常解释从高通量实验和计算分析中获得的基因列表。这通常是通过统计富集分析来完成的，该分析测量与基因或其属性相关的生物功能术语的过度或欠表示程度，基于知识库（KB）（例如Gene Ontology（GO））中的编译断言。解释基因列表也可以被构建为一个文本概括任务，利用大型语言模型（LLMs）进行，可能直接利用科学文本并避免依赖KB。我们开发了SPINDOCTOR（稳定的提示插值的受控术语的自然语言描述的结构化报告模板），一种使用GPT模型执行基因集函数概括的方法，作为标准富集分析的补充。该方法可以使用不同的基因功能信息来源：（1）从鉴定的本体KB注释中获得的结构化文本，（2）从文本挖掘中推断的本体术语，以及（3）直接从非结构化文本中获得的术语。我们在一个1813个基因集的基准数据集上评估了SPINDOCTOR，并展示了使用GPT模型显著改善了现有方法的性能，同时也提高了可解释性，因为它能够生成人类可读的基因功能摘要。

    Molecular biologists frequently interpret gene lists derived from high-throughput experiments and computational analysis. This is typically done as a statistical enrichment analysis that measures the over- or under-representation of biological function terms associated with genes or their properties, based on curated assertions from a knowledge base (KB) such as the Gene Ontology (GO). Interpreting gene lists can also be framed as a textual summarization task, enabling the use of Large Language Models (LLMs), potentially utilizing scientific texts directly and avoiding reliance on a KB.  We developed SPINDOCTOR (Structured Prompt Interpolation of Natural Language Descriptions of Controlled Terms for Ontology Reporting), a method that uses GPT models to perform gene set function summarization as a complement to standard enrichment analysis. This method can use different sources of gene functional information: (1) structured text derived from curated ontological KB annotations, (2) ontol
    
[^92]: 探索不同架构和训练方法下基于能量的语言模型在语音识别中的应用

    Exploring Energy-based Language Models with Different Architectures and Training Methods for Speech Recognition. (arXiv:2305.12676v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12676](http://arxiv.org/abs/2305.12676)

    本文探索了不同的能量函数架构和不同的训练方法，以提高基于能量的语言模型在语音识别中计算句子得分的能力。

    

    基于能量的语言模型（ELM）通过参数化自然语句的非归一化分布与流行的自回归语言模型（ALM）有根本性区别。作为一种重要的应用，ELM已成功地用于语音识别中计算句子得分，但它们都使用不太现代的CNN或LSTM网络。随着Transformer网络和大型预训练模型（如BERT和GPT2）的最新进展，进一步提高ELMs的能力已经成为可能。在本文中，我们探索了不同的能量函数架构和不同的训练方法，以研究在以大型预训练模型作为骨干的语音识别中，ELMs的能力。

    Energy-based language models (ELMs) parameterize an unnormalized distribution for natural sentences and are radically different from popular autoregressive language models (ALMs). As an important application, ELMs have been successfully used as a means for calculating sentence scores in speech recognition, but they all use less-modern CNN or LSTM networks. The recent progress in Transformer networks and large pretrained models such as BERT and GPT2 opens new possibility to further advancing ELMs. In this paper, we explore different architectures of energy functions and different training methods to investigate the capabilities of ELMs in rescoring for speech recognition, all using large pretrained models as backbones.
    
[^93]: 多头状态空间模型在语音识别中的应用

    Multi-Head State Space Model for Speech Recognition. (arXiv:2305.12498v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2305.12498](http://arxiv.org/abs/2305.12498)

    本文提出了一种多头状态空间（MH-SSM）模型，它能够用于语音识别任务并在LibriSpeech数据集上表现出的新的性能，是变压器变换器的优秀替代方案。同时, MH-SSM层的引入也提高了变压器块的性能，达到了现有最新水平。

    

    最近，在一些小规模的序列和语言建模任务上，状态空间模型（SSM）已经表现出了很大的潜力，并且能够与许多基于注意力的方法相媲美甚至超越。在本文中，我们提出了一种多头状态空间（MH-SSM）架构，它配备了特殊的门控机制，其中并行头被教授如何在序列数据上学习本地和全局的时间动态。作为变压器编码器中多头注意力的直接替代方案，这个新模型在LibriSpeech语音识别语料库上显著优于变压器变换器。此外，我们在变压器块中增加了MH-SSM层，称为Stateformer，不使用外部语言模型，在LibriSpeech任务中达到了最新的性能，开发集和测试集的词错误率分别为1.76％ / 4.37％和1.91％ / 4.36％。

    State space models (SSMs) have recently shown promising results on small-scale sequence and language modelling tasks, rivalling and outperforming many attention-based approaches. In this paper, we propose a multi-head state space (MH-SSM) architecture equipped with special gating mechanisms, where parallel heads are taught to learn local and global temporal dynamics on sequence data. As a drop-in replacement for multi-head attention in transformer encoders, this new model significantly outperforms the transformer transducer on the LibriSpeech speech recognition corpus. Furthermore, we augment the transformer block with MH-SSMs layers, referred to as the Stateformer, achieving state-of-the-art performance on the LibriSpeech task, with word error rates of 1.76\%/4.37\% on the development and 1.91\%/4.36\% on the test sets without using an external language model.
    
[^94]: Glot500：扩展500种语言的多语料库和语言模型

    Glot500: Scaling Multilingual Corpora and Language Models to 500 Languages. (arXiv:2305.12182v1 [cs.CL])

    [http://arxiv.org/abs/2305.12182](http://arxiv.org/abs/2305.12182)

    Glot500是一个水平扩展的语言模型，覆盖了511种低资源语言。相比于XLM-R基线，Glot500展现出了更好的高资源和低资源语言表现。该模型质量的决定因素包括语料库大小、脚本、相关语言的“帮助”和模型的总容量。

    

    自然语言处理领域一直专注于使大型语言模型在大约100种语言中更加出色。我们通过不断的预训练，水平扩展大型语言模型。我们创建了Glot500-m，这是一个覆盖了511种语言的语言模型，其中几乎所有语言都是低资源语言。这项工作的重要部分是收集和清理Glot500-c，这是一个包括这511种语言的语料库，可以让我们对Glot500-m进行训练。我们在这些语言上评估了Glot500-m在五个不同的任务中的表现。我们观察到，与XLM-R基线相比，Glot500-m在高资源和低资源语言的表现都有了很大的提高。我们的分析表明，没有单一因素可以解释多语言大型语言模型表示的质量。相反，多个因素决定了质量，包括语料库大小、脚本、相关语言的“帮助”以及模型的总容量。我们的工作解决了自然语言处理研究的一个重要目标：我们不应该将自然语言处理局限于世界语言的一小部分，而是应该让它涵盖更广泛的语言范围。

    The NLP community has mainly focused on scaling Large Language Models (LLMs) vertically, i.e., making them better for about 100 languages. We instead scale LLMs horizontally: we create, through continued pretraining, Glot500-m, an LLM that covers 511 languages, almost all of them low-resource. An important part of this effort is to collect and clean Glot500-c, a corpus that covers these 511 languages and allows us to train Glot500-m. We evaluate Glot500-m on five diverse tasks across these languages. We observe large improvements for both high-resource and lowresource languages compared to an XLM-R baseline. Our analysis shows that no single factor explains the quality of multilingual LLM representations. Rather, a combination of factors determines quality including corpus size, script, "help" from related languages and the total capacity of the model. Our work addresses an important goal of NLP research: we should not limit NLP to a small fraction of the world's languages and instead 
    
[^95]: 基于上下文学习的命名实体识别

    Learning In-context Learning for Named Entity Recognition. (arXiv:2305.11038v1 [cs.CL])

    [http://arxiv.org/abs/2305.11038](http://arxiv.org/abs/2305.11038)

    本文提出了一种在 PLMs 中注入上下文 NER 能力的方法，只需少量示意实例即可动态识别新类型的实体，在几个基准数据集上达到了最先进的性能。

    

    现实世界中的命名实体识别受到实体类型的多样性、新实体类型的出现和高质量标注的缺乏等问题的影响。本文提出了一种基于上下文学习的命名实体识别方法，能够将上下文NER能力有效地注入到PLMs中，并且只使用少量示意实例就能动态识别新类型的实体。具体而言，我们将PLMs建模为一个元函数 $\mathcal{ \lambda_ {\text{instruction, demonstrations, text}}. M}$，并通过将新的指示和示例应用于PLMs来隐含地构建新的实体提取器，即 $\mathcal{ (\lambda . M) }$(instruction, demonstrations) $\to$ $\mathcal{F}$，其中 $\mathcal{F}$ 将成为一个新的实体提取器，即 $\mathcal{F}$: text $\to$ entities。为了将上述上下文NER能力注入PLMs，我们提出了一种元函数预训练算法，该算法通过比较（指示、示例）-identity和（掩盖后的指示、示例）-identity来预训练PLMs。实验结果表明，我们的方法在几个基准数据集上达到了最先进的性能，并且能够使用少量示意实例有效地识别新类型的实体。

    Named entity recognition in real-world applications suffers from the diversity of entity types, the emergence of new entity types, and the lack of high-quality annotations. To address the above problems, this paper proposes an in-context learning-based NER approach, which can effectively inject in-context NER ability into PLMs and recognize entities of novel types on-the-fly using only a few demonstrative instances. Specifically, we model PLMs as a meta-function $\mathcal{ \lambda_ {\text{instruction, demonstrations, text}}. M}$, and a new entity extractor can be implicitly constructed by applying new instruction and demonstrations to PLMs, i.e., $\mathcal{ (\lambda . M) }$(instruction, demonstrations) $\to$ $\mathcal{F}$ where $\mathcal{F}$ will be a new entity extractor, i.e., $\mathcal{F}$: text $\to$ entities. To inject the above in-context NER ability into PLMs, we propose a meta-function pre-training algorithm, which pre-trains PLMs by comparing the (instruction, demonstration)-i
    
[^96]: 不确定性引导的标签去噪在文档级远程关系抽取中的应用

    Uncertainty Guided Label Denoising for Document-level Distant Relation Extraction. (arXiv:2305.11029v1 [cs.CL])

    [http://arxiv.org/abs/2305.11029](http://arxiv.org/abs/2305.11029)

    本文提出了一种使用不确定性引导的标签去噪技术，可以有效准确地在文档级远程关系抽取中选择可信的伪标签，提高了性能表现，并在DocRED数据集上实现了新的最佳性能。

    

    文档级关系抽取旨在推断文档中实体之间的复杂语义关系。远程监督能够生成大量自动标注的数据，从而可以提高文档关系抽取的性能。然而，不可靠的伪标签会带来新的噪声，例如添加虚假的伪标签和失去正确的监督标签。因此，如何选择有效的伪标签来去噪远程监督数据仍然是文档级远程关系抽取中的一个挑战。为了解决这个问题，我们引入了不确定性估计技术来确定伪标签是否可信。在本文中，我们提出了一个带有不确定性引导标签去噪的文档级远程关系抽取框架，UGDRE。具体而言，我们提出了一种新的实例级不确定性估计方法，它测量了具有重叠关系的伪标签的可靠性。通过进一步考虑实例级和关系级的不确定性，我们设计了一个标签去噪组件，可以有效地选择可靠的伪标签进行文档关系抽取。在两个基准数据集上的实验结果表明，我们的方法显著优于现有方法，并在DocRED数据集上实现了新的最佳性能。

    Document-level relation extraction (DocRE) aims to infer complex semantic relations among entities in a document. Distant supervision (DS) is able to generate massive auto-labeled data, which can improve DocRE performance. Recent works leverage pseudo labels generated by the pre-denoising model to reduce noise in DS data. However, unreliable pseudo labels bring new noise, e.g., adding false pseudo labels and losing correct DS labels. Therefore, how to select effective pseudo labels to denoise DS data is still a challenge in document-level distant relation extraction. To tackle this issue, we introduce uncertainty estimation technology to determine whether pseudo labels can be trusted. In this work, we propose a Document-level distant Relation Extraction framework with Uncertainty Guided label denoising, UGDRE. Specifically, we propose a novel instance-level uncertainty estimation method, which measures the reliability of the pseudo labels with overlapping relations. By further consider
    
[^97]: MolXPT：使用文本包装分子进行生成性预训练

    MolXPT: Wrapping Molecules with Text for Generative Pre-training. (arXiv:2305.10688v1 [cs.CL])

    [http://arxiv.org/abs/2305.10688](http://arxiv.org/abs/2305.10688)

    MolXPT是一个文本包装的统一语言模型，使用SMILES作为输入，可以提高分子模型的性能表现，并且使得基于零shot的分子生成成为可能。

    

    生成式预训练变压器（GPT）已经在自然语言处理中取得了巨大成功，并且相关技术已经被应用到了分子建模中。考虑到文本是科学发现最重要的记录，本文提出了 MolXPT，一个在 SMILES 上预训练的统一语言模型，其中 SMILES 被文本包装。简单来说，我们检测每个序列中的分子名称，并将它们替换为相应的 SMILES。通过这种方式，SMILES 可以利用周围文本的信息，反之亦然。以上包装的序列，是由来自 PubMed 的文本序列和来自 PubChem 的 SMILES 序列组成的，它们都被输入到语言模型中进行预训练。实验结果表明，MolXPT 在 MoleculeNet 上的分子属性预测的强基准模型中表现更好，在文本-分子翻译中表现与最佳模型相当，而使用的参数不到其一半，并且能够通过文本提示零-shot生成分子。

    Generative pre-trained Transformer (GPT) has demonstrates its great success in natural language processing and related techniques have been adapted into molecular modeling. Considering that text is the most important record for scientific discovery, in this paper, we propose MolXPT, a unified language model of text and molecules pre-trained on SMILES (a sequence representation of molecules) wrapped by text. Briefly, we detect the molecule names in each sequence and replace them to the corresponding SMILES. In this way, the SMILES could leverage the information from surrounding text, and vice versa. The above wrapped sequences, text sequences from PubMed and SMILES sequences from PubChem are all fed into a language model for pre-training. Experimental results demonstrate that MolXPT outperforms strong baselines of molecular property prediction on MoleculeNet, performs comparably to the best model in text-molecule translation while using less than half of its parameters, and enables zero
    
[^98]: 阅读过程中对小说人物个性的理解

    Personality Understanding of Fictional Characters during Book Reading. (arXiv:2305.10156v1 [cs.CL])

    [http://arxiv.org/abs/2305.10156](http://arxiv.org/abs/2305.10156)

    本文提出了一个NLP领域内尚未研究的问题：情景和细致地理解小说人物个性，并提供了第一个标记数据集PersoNet来解决这个问题。

    

    理解小说人物个性是阅读故事的关键。随着读者与故事的互动，他们对一个人物的理解会根据新的事件和信息而演变；并且可以感知到多个精细的个性方面。这导致了一个自然的问题：情境和精细的个性理解。这个问题在NLP领域中没有得到研究，主要是由于缺乏模仿阅读过程的适当数据集。我们提供了第一个标记数据集PersoNet来解决这个问题。我们的新型注释策略涉及用在线阅读应用程序的用户笔记作为原始书籍的代理进行注释。实验和人体研究表明，我们的数据集构建既有效又准确；我们的任务在很大程度上依赖于长期的上下文以实现对机器和人类的准确预测。数据集可在https://github.com/Gorov/personet_acl23获得。

    Comprehending characters' personalities is a crucial aspect of story reading. As readers engage with a story, their understanding of a character evolves based on new events and information; and multiple fine-grained aspects of personalities can be perceived. This leads to a natural problem of situated and fine-grained personality understanding. The problem has not been studied in the NLP field, primarily due to the lack of appropriate datasets mimicking the process of book reading. We present the first labeled dataset PersoNet for this problem. Our novel annotation strategy involves annotating user notes from online reading apps as a proxy for the original books. Experiments and human studies indicate that our dataset construction is both efficient and accurate; and our task heavily relies on long-term context to achieve accurate predictions for both machines and humans. The dataset is available at https://github.com/Gorov/personet_acl23.
    
[^99]: sustain.AI: 一种分析可持续性报告的推荐系统

    sustain.AI: a Recommender System to analyze Sustainability Reports. (arXiv:2305.08711v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.08711](http://arxiv.org/abs/2305.08711)

    sustain.AI是一个智能的、上下文感知的推荐系统，可以帮助审计师、金融投资者以及广大公众高效地分析公司的可持续性报告，并通过与GRI标准匹配来提供更好的推荐精度。

    

    本文介绍了sustain.AI，这是一个智能的、上下文感知的推荐系统，可帮助审计师、金融投资者以及广大公众高效地分析公司的可持续性报告。该工具利用了端到端可训练的架构，将基于BERT的编码模块与多标签分类头相结合，将可持续性报告中的相关文本段落与全球报告倡议（GRI）标准中的相应法律法规匹配。我们在两个新颖的德国可持续性报告数据集上评估了我们的模型，并始终实现了与多个强基线模型相比更高的推荐性能。此外，sustain.AI已经公开在https://sustain.ki.nrw/上提供给所有人使用。

    We present $\text{sustain.AI}$, an intelligent, context-aware recommender system that assists auditors and financial investors as well as the general public to efficiently analyze companies' sustainability reports. The tool leverages an end-to-end trainable architecture that couples a BERT-based encoding module with a multi-label classification head to match relevant text passages from sustainability reports to their respective law regulations from the Global Reporting Initiative (GRI) standards. We evaluate our model on two novel German sustainability reporting data sets and consistently achieve a significantly higher recommendation performance compared to multiple strong baselines. Furthermore, $\text{sustain.AI}$ is publicly available for everyone at https://sustain.ki.nrw/.
    
[^100]: 超越相关分析的NLG评估指标：一种经验度量偏好检查表

    NLG Evaluation Metrics Beyond Correlation Analysis: An Empirical Metric Preference Checklist. (arXiv:2305.08566v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.08566](http://arxiv.org/abs/2305.08566)

    本研究提出了一种度量偏好检查表，以超越相关分析评估NLG自动指标，并分析了两种类型的指标及其在三个任务中的效果。

    

    本研究分析了NLG自动评估指标，基于是否将人类评估方面用作上下文或目标来计算指标，分为（i）任务不可知和（ii）与人类对齐的指标。我们提出了度量偏好检查表作为评估自动指标在三个NLG任务中的鉴别力的框架：文本摘要，对话响应生成和受控生成。

    In this study, we analyze NLG automatic metrics based on whether human evaluation aspect is used as context or objective to compute the metrics: (i) Task-agnostic and (ii) Human-aligned. Task-agnostic metrics, such as Perplexity, BLEU, BERTScore, are cost-effective and highly adaptable to diverse NLG tasks, yet they have a weak correlation with human. Human-aligned metrics (CTC, CtrlEval, UniEval) improves correlation level by incorporating desirable human-like qualities as training objective. However, their effectiveness at discerning system-level performance and quality of system outputs remains unclear.  We present metric preference checklist as a framework to assess the discriminative power of automatic metrics in three NLG tasks: Text Summarization, Dialogue Response Generation, and Controlled Generation. We show that multi-aspect human-aligned metric (UniEval) is not necessarily dominant over single-aspect human-aligned metrics (CTC, CtrlEval) and task-agnostic metrics (BLEU, BER
    
[^101]: 个性化感知的推荐系统中的LMMs模型

    PALR: Personalization Aware LLMs for Recommendation. (arXiv:2305.07622v1 [cs.IR])

    [http://arxiv.org/abs/2305.07622](http://arxiv.org/abs/2305.07622)

    本文提出了一个称为PALR的框架，将用户的历史行为与LLMs相结合，生成用户喜欢的物品的推荐。与现有的推荐方法相比，我们的PALR框架实现了最先进的性能。

    

    大型语言模型(LLMs)由于其出色的性能而受到越来越多的关注。本文提出了一种新的框架PALR，将用户的历史行为与LLMs相结合，以生成用户喜欢的物品的推荐。我们首先使用用户/物品互动作为候选检索的指导，然后采用基于LLMs的排序模型生成推荐物品。实验结果表明，与现有的推荐方法相比，我们提出的PALR框架实现了最先进的性能。

    Large language models (LLMs) have recently received significant attention for their exceptional capabilities. Despite extensive efforts in developing general-purpose LLMs that can be utilized in various natural language processing (NLP) tasks, there has been less research exploring their potential in recommender systems. In this paper, we propose a novel framework, named PALR, which aiming to combine user history behaviors (such as clicks, purchases, ratings, etc.) with LLMs to generate user preferred items. Specifically, we first use user/item interactions as guidance for candidate retrieval. Then we adopt a LLM-based ranking model to generate recommended items. Unlike existing approaches that typically adopt general-purpose LLMs for zero/few-shot recommendation testing or training on small-sized language models (with less than 1 billion parameters), which cannot fully elicit LLMs' reasoning abilities and leverage rich item side parametric knowledge, we fine-tune a 7 billion parameter
    
[^102]: BanglaBook: 一种用于情感分析的大规模孟加拉语书评数据集

    BanglaBook: A Large-scale Bangla Dataset for Sentiment Analysis from Book Reviews. (arXiv:2305.06595v1 [cs.CL])

    [http://arxiv.org/abs/2305.06595](http://arxiv.org/abs/2305.06595)

    BanglaBook 是一个大规模的孟加拉语书评数据集，其中包括 158,065 个样本，针对情感分析分为三个大类，通过使用预训练模型来取代手动构建特征的模型，取得显着的性能优势。

    

    消费者情感分析可以通过评论表达提供有关产品质量的丰富见解。尽管情感分析的研究在许多流行语言中得到了广泛探索，但由于缺乏相关数据和跨领域适应性，相对较少关注孟加拉语言。为了解决这个限制，我们提出了 BanglaBook，这是一个大规模的孟加拉语书评数据集，包括 158,065 个样本，分为三个大类：积极、消极和中性。我们对数据集进行了详细的统计分析，并使用一系列机器学习模型建立了基线，包括 SVM、LSTM 和 Bangla-BERT。我们的研究结果表明，与依赖手动构建特征的模型相比，预训练模型具有显着的性能优势，强调了在此领域需要额外的培训资源。此外，我们通过检查情感错误分类来进行深入的错误分析，并提供有关孟加拉情感分析性质的进一步见解。

    The analysis of consumer sentiment, as expressed through reviews, can provide a wealth of insight regarding the quality of a product. While the study of sentiment analysis has been widely explored in many popular languages, relatively less attention has been given to the Bangla language, mostly due to a lack of relevant data and cross-domain adaptability. To address this limitation, we present BanglaBook, a large-scale dataset of Bangla book reviews consisting of 158,065 samples classified into three broad categories: positive, negative, and neutral. We provide a detailed statistical analysis of the dataset and employ a range of machine learning models to establish baselines including SVM, LSTM, and Bangla-BERT. Our findings demonstrate a substantial performance advantage of pre-trained models over models that rely on manually crafted features, emphasizing the necessity for additional training resources in this domain. Additionally, we conduct an in-depth error analysis by examining se
    
[^103]: 多语言LLMs是更好的跨语言上下文学习者与对齐效果。

    Multilingual LLMs are Better Cross-lingual In-context Learners with Alignment. (arXiv:2305.05940v1 [cs.CL])

    [http://arxiv.org/abs/2305.05940](http://arxiv.org/abs/2305.05940)

    针对跨语言ICL中无法对准输入输出空间的问题，我们提出了一种新的提示构建策略X-InSTA，可以同时对源语言和目标语言的语境进行编码和对齐，从而提高跨语言ICL的效率。

    

    随着大语言模型能够在没有任何梯度更新的情况下推断出以少数标记样本为条件的测试标签，上下文学习(ICL)成为可能。启用ICL的大语言模型为在低资源环境下规避复发性注释成本提供了有希望的前进步伐。然而，过去只有少数几项研究探究了跨语言设置下的ICL，这在从高资源语言到低资源语言转移标签知识的需要下至关重要。为了弥合这一鸿沟，我们首次对跨语言文本分类的ICL进行了深入分析。我们发现，在跨语言ICL的情况下，普遍选择随机的输入-标签对来构建提示上下文的模式严重受限于输入和输出空间的缺乏对准。为了缓解这一问题，我们提出了一种新的提示构建策略——跨语言上下文源-目标对齐（X-InSTA）。通过注入共同训练的阈值元素，X-InSTA可以同时对源语言和目标语言的语境进行编码和对齐，从而提高跨语言ICL的效率。

    In-context learning (ICL) unfolds as large language models become capable of inferring test labels conditioned on a few labeled samples without any gradient update. ICL-enabled large language models provide a promising step forward toward bypassing recurrent annotation costs in a low-resource setting. Yet, only a handful of past studies have explored ICL in a cross-lingual setting, in which the need for transferring label-knowledge from a high-resource language to a low-resource one is immensely crucial. To bridge the gap, we provide the first in-depth analysis of ICL for cross-lingual text classification. We find that the prevalent mode of selecting random input-label pairs to construct the prompt-context is severely limited in the case of cross-lingual ICL, primarily due to the lack of alignment in the input as well as the output spaces. To mitigate this, we propose a novel prompt construction strategy -- Cross-lingual In-context Source-Target Alignment (X-InSTA). With an injected co
    
[^104]: 通过训练人工代码切换数据来提升零样本跨语言检索

    Boosting Zero-shot Cross-lingual Retrieval by Training on Artificially Code-Switched Data. (arXiv:2305.05295v1 [cs.CL])

    [http://arxiv.org/abs/2305.05295](http://arxiv.org/abs/2305.05295)

    研究者提出训练排名模型的方法来提高跨语言检索的效率，该模型使用了人工代码切换的数据，并且实验表明在跨语言检索和多语言检索中会带来显著改进，在不影响单语检索的基础上，特别是对于远程语言之间的检索。

    

    将以英语为代表的高资源语言的信息检索（IR）模型以零样本方式迁移到其他语言已成为被广泛采用的方法。在本研究中，我们表明当查询和文档以不同语言存在时，零样本排名器的有效性会降低。出于这个原因，我们建议使用人工代码切换数据来训练排名模型，而我们生成这些数据是通过利用双语词表。为此，我们尝试了从（1）跨语言词嵌入和（2）平行维基百科页面标题得出的词表。我们使用mMARCO数据集对涵盖单语IR（MoIR）、跨语言IR（CLIR）和多语言IR（MLIR）的36种语言对的重排模型进行了广泛评估。我们的结果表明，代码切换可以在保持MoIR性能稳定的同时，在CLIR中产生5.1 MRR@10的一致和显著增益，以及在MLIR中产生3.9 MRR@10的增益。令人鼓舞的是，远程语言之间的增益特别显著。

    Transferring information retrieval (IR) models from a high-resource language (typically English) to other languages in a zero-shot fashion has become a widely adopted approach. In this work, we show that the effectiveness of zero-shot rankers diminishes when queries and documents are present in different languages. Motivated by this, we propose to train ranking models on artificially code-switched data instead, which we generate by utilizing bilingual lexicons. To this end, we experiment with lexicons induced from (1) cross-lingual word embeddings and (2) parallel Wikipedia page titles. We use the mMARCO dataset to extensively evaluate reranking models on 36 language pairs spanning Monolingual IR (MoIR), Cross-lingual IR (CLIR), and Multilingual IR (MLIR). Our results show that code-switching can yield consistent and substantial gains of 5.1 MRR@10 in CLIR and 3.9 MRR@10 in MLIR, while maintaining stable performance in MoIR. Encouragingly, the gains are especially pronounced for distan
    
[^105]: 从大型语言模型中提取脚本知识以进行受限语言规划

    Distilling Script Knowledge from Large Language Models for Constrained Language Planning. (arXiv:2305.05252v1 [cs.CL])

    [http://arxiv.org/abs/2305.05252](http://arxiv.org/abs/2305.05252)

    本文首次定义了受限语言规划任务，提出了一种方法来提高大型语言模型在这个任务中的表现，并提取了一个新颖的受限语言规划数据集。实验证明该方法显著提高了其在约束忠实度方面的能力，并对赋予较小的语言模型受限语言规划能力非常有效。

    

    在日常生活中，人们经常通过遵循目标导向的脚本形式的逐步说明来规划自己的行动。以往的工作利用语言模型（LM）来为立体活动的抽象目标（例如，“制作蛋糕”）进行规划，但对于具有多方面约束的更具体目标（例如，“为糖尿病患者制作蛋糕”）鲜有研究。本文首次定义了受限语言规划任务。我们提出了一种过度生成并过滤的方法来改善大型语言模型（LLM）在这个任务中的表现，并利用它来提取一种新颖的受限语言规划数据集CoScript，其中包括55,000个脚本。实验证明，我们的方法显著提高了LLM在受限语言规划方面的能力，特别是在约束忠实度方面。此外，CoScript被证明对赋予较小的LM受限语言规划能力是非常有效的。

    In everyday life, humans often plan their actions by following step-by-step instructions in the form of goal-oriented scripts. Previous work has exploited language models (LMs) to plan for abstract goals of stereotypical activities (e.g., "make a cake"), but leaves more specific goals with multi-facet constraints understudied (e.g., "make a cake for diabetics"). In this paper, we define the task of constrained language planning for the first time. We propose an overgenerate-then-filter approach to improve large language models (LLMs) on this task, and use it to distill a novel constrained language planning dataset, CoScript, which consists of 55,000 scripts. Empirical results demonstrate that our method significantly improves the constrained language planning ability of LLMs, especially on constraint faithfulness. Furthermore, CoScript is demonstrated to be quite effective in endowing smaller LMs with constrained language planning ability.
    
[^106]: ANALOGICAL- 一种新的大语言模型文本类比评测基准

    ANALOGICAL - A New Benchmark for Analogy of Long Text for Large Language Models. (arXiv:2305.05050v1 [cs.CL])

    [http://arxiv.org/abs/2305.05050](http://arxiv.org/abs/2305.05050)

    本文介绍了一种名为“ANALOGICAL”的新型基准，用以内在评估LLMs在长文本类比中的能力，包括六个复杂级别的长文本类比分类，并使用13个数据集和三种距离度量方法来评估8个LLMs在语义向量空间中识别类比对的能力。

    

    在过去的十年中，以词级别的类比为形式的类比在衡量诸如word2vec之类的词嵌入方法的质量方面发挥了重要作用。然而，现代的大型语言模型(LLMs)主要根据GLUE和SuperGLUE等基准的外在量度进行评估，而在LLMs是否能够在长文本中绘制类比的方面，只有少数几项研究。本文介绍了一种名为“ANALOGICAL”的新型基准，以六个复杂级别的长文本类比分类对LLMs进行内在评估，分别为 (i)单词、(ii)单词vs句子、(iii)语法、(iv)否定、(v)蕴含和(vi)隐喻。利用13个数据集和三种不同的距离度量方法，我们评估了8个LLMs在语义向量空间中识别类比对的能力(例如，“我能说两种语言”应该更接近“我是双语的”，而“我喜欢巧克力”和“我不喜欢巧克力”应该是正交的)。

    Over the past decade, analogies, in the form of word-level analogies, have played a significant role as an intrinsic measure of evaluating the quality of word embedding methods such as word2vec. Modern large language models (LLMs), however, are primarily evaluated on extrinsic measures based on benchmarks such as GLUE and SuperGLUE, and there are only a few investigations on whether LLMs can draw analogies between long texts. In this paper, we present ANALOGICAL, a new benchmark to intrinsically evaluate LLMs across a taxonomy of analogies of long text with six levels of complexity -- (i) word, (ii) word vs. sentence, (iii) syntactic, (iv) negation, (v) entailment, and (vi) metaphor. Using thirteen datasets and three different distance measures, we evaluate the abilities of eight LLMs in identifying analogical pairs in the semantic vector space (e.g., "I can speak two languages" should be closer to "I am bilingual" while "I like chocolate" and "I do not like chocolate" should be orthog
    
[^107]: 解释性微调使模型对虚假提示更强韧

    Explanation-based Finetuning Makes Models More Robust to Spurious Cues. (arXiv:2305.04990v1 [cs.CL])

    [http://arxiv.org/abs/2305.04990](http://arxiv.org/abs/2305.04990)

    本文提出一种新型方法——解释性微调，通过让模型在给出答案的同时生成支持该答案的自由文本解释，来减轻LLMs依赖虚假关联，使得模型对虚假提示更加强韧，并具有广泛适用性。

    

    大型语言模型（LLMs）非常强大，有时会学习到标签和与任务无关的特征之间的相关性，导致在分布外数据上泛化能力差。我们提出解释性微调作为减轻LLMs依赖虚假关联的一种新的通用方法。与标准微调只在给定输入的情况下预测答案不同，我们微调模型以生成支持其答案的自由文本解释。为了评估我们的方法，我们在人工构建的训练集上微调模型，该训练集包含不同类型的虚假提示，并在没有这些提示的测试集上进行测试。与标准微调相比，我们的方法在四个分类任务的准确性下降方面使模型极其强韧：ComVE（+1.2），CREAK（+9.1），e-SNLI（+15.4）和SBIC（+6.5）。此外，我们的方法与模型生成的解释同样有效，这意味着我们的方法具有广泛的适用性。

    Large Language Models (LLMs) are so powerful that they sometimes learn correlations between labels and features that are irrelevant to the task, leading to poor generalization on out-of-distribution data. We propose explanation-based finetuning as a novel and general approach to mitigate LLMs' reliance on spurious correlations. Unlike standard finetuning where the model only predicts the answer given the input, we finetune the model to additionally generate a free-text explanation supporting its answer. To evaluate our method, we finetune the model on artificially constructed training sets containing different types of spurious cues, and test it on a test set without these cues. Compared to standard finetuning, our method makes models remarkably more robust against spurious cues in terms of accuracy drop across four classification tasks: ComVE (+1.2), CREAK (+9.1), e-SNLI (+15.4), and SBIC (+6.5). Moreover, our method works equally well with explanations generated by the model, implyin
    
[^108]: 计划和解决提示：通过大型语言模型改善零样本思考链推理

    Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models. (arXiv:2305.04091v1 [cs.CL])

    [http://arxiv.org/abs/2305.04091](http://arxiv.org/abs/2305.04091)

    本研究提出了一种计划和解决的提示方法来改善零样本思考链推理，该方法包括两个组成部分：制定计划将任务划分为子任务，并按计划执行子任务；将输入提示扩展到包括简单算术计算的示例。实验结果显示，该方法胜过了零样本-CoT。

    

    最近，大型语言模型（LLMs）在各种自然语言处理任务中表现出惊人的性能。为了解决多步骤推理任务，少样本的思维链（CoT）提示包括一些手工制作的逐步推理演示，使LLMs能够明确生成推理步骤并提高其推理任务准确性。为了消除手动劳动，零样本思维链将目标问题陈述与“让我们逐步思考”连接起来作为输入提示LLMs。尽管零样本-CoT取得了成功，但仍存在计算错误、缺失步骤错误和语义误解错误的问题。为了解决缺失步骤错误，我们提出了计划和解决（PS）提示。它包含两个组成部分：首先，制定计划将整个任务划分为较小的子任务，然后按照计划执行子任务。为了解决计算错误并提高生成推理步骤的质量，我们将输入提示扩展到包括简单算术计算的示例。我们的实验表明，PS提示在思维链推理任务的准确性方面胜过了零样本CoT。

    Large language models (LLMs) have recently been shown to deliver impressive performance in various NLP tasks. To tackle multi-step reasoning tasks, few-shot chain-of-thought (CoT) prompting includes a few manually crafted step-by-step reasoning demonstrations which enable LLMs to explicitly generate reasoning steps and improve their reasoning task accuracy. To eliminate the manual effort, Zero-shot-CoT concatenates the target problem statement with "Let's think step by step" as an input prompt to LLMs. Despite the success of Zero-shot-CoT, it still suffers from three pitfalls: calculation errors, missing-step errors, and semantic misunderstanding errors. To address the missing-step errors, we propose Plan-and-Solve (PS) Prompting. It consists of two components: first, devising a plan to divide the entire task into smaller subtasks, and then carrying out the subtasks according to the plan. To address the calculation errors and improve the quality of generated reasoning steps, we extend 
    
[^109]: 自我编辑：针对代码生成的故障感知式代码编辑器

    Self-Edit: Fault-Aware Code Editor for Code Generation. (arXiv:2305.04087v1 [cs.SE])

    [http://arxiv.org/abs/2305.04087](http://arxiv.org/abs/2305.04087)

    本文提出了一种故障感知式代码编辑器，通过执行生成的代码并将执行结果包含在在注释中来优化竞技编程任务的代码质量，通过与九个不同的LLMs进行比较，本方法可以在两个竞技编程数据集上显著提高代码的准确性。

    

    大型语言模型（LLMs）在竞技编程任务中生成代码的能力已经得到证明，但由于样本数量有限，LLMs仍然存在较低的准确性。受人类编程过程的启发，我们提出了一种生成和编辑的方法，利用LLMs生成的代码的执行结果来提高竞技编程任务的代码质量。我们在问题中提供的示例测试用例上执行生成的代码，并将执行结果包含在补充性注释中。利用这个注释作为指导，我们的故障感知式代码编辑器用于纠正生成的代码中的错误。我们在两个竞技编程数据集上进行了广泛的评估，涵盖了九个不同的LLMs。与直接从LLMs生成相比，我们的方法可以在APPS-dev上将pass@1的平均值提高89％，在APPS-test上提高31％，在HumanEval上提高48％，超过了九个流行的代码生成LLMs，参数大小范围为110M-t。

    Large language models (LLMs) have demonstrated an impressive ability to generate codes on competitive programming tasks. However, with limited sample numbers, LLMs still suffer from poor accuracy. Inspired by the process of human programming, we propose a generate-and-edit approach that utilizes execution results of the generated code from LLMs to improve the code quality on the competitive programming task. We execute the generated code on the example test case provided in the question and wrap execution results into a supplementary comment. Utilizing this comment as guidance, our fault-aware code editor is employed to correct errors in the generated code. We perform extensive evaluations across two competitive programming datasets with nine different LLMs. Compared to directly generating from LLMs, our approach can improve the average of pass@1 by 89\% on APPS-dev, 31\% on APPS-test, and 48\% on HumanEval over nine popular code generation LLMs with parameter sizes ranging from 110M t
    
[^110]: Chain-of-Skills: 一个可配置的用于开放领域问答的模型

    Chain-of-Skills: A Configurable Model for Open-domain Question Answering. (arXiv:2305.03130v1 [cs.CL])

    [http://arxiv.org/abs/2305.03130](http://arxiv.org/abs/2305.03130)

    本论文提出了一种模块化检索器可以在数据集间重复使用，支持针对目标领域的灵活技能配置，通过自我监督预训练和微调多个 ODQA 数据集，实现了最新颖的微调检索性能。

    

    在实际的知识密集任务中，如开放领域问答（ODQA），检索模型是不可或缺的组件。由于不同数据集的注释有着不同的检索技能，近期的工作侧重于定制方法，限制了模型的可转移性和可扩展性。在这项工作中，我们提出了一种模块化检索器，其中各个模块对应于可以在数据集之间重复使用的关键技能。我们的方法支持基于目标领域的灵活技能配置，以提高性能。为了减轻任务干扰，我们设计了一种受稀疏 Transformer 启发的新型模块化参数化方法。我们证明了我们的模型可以在维基百科上进行自我监督预训练，并在多个 ODQA 数据集上进行微调，具有多任务的特点。我们的方法在零样例评估中优于最近的自我监督检索器，并在 NQ、HotpotQA 和 OTT-QA 上获得了最先进的微调检索性能。

    The retrieval model is an indispensable component for real-world knowledge-intensive tasks, e.g., open-domain question answering (ODQA). As separate retrieval skills are annotated for different datasets, recent work focuses on customized methods, limiting the model transferability and scalability. In this work, we propose a modular retriever where individual modules correspond to key skills that can be reused across datasets. Our approach supports flexible skill configurations based on the target domain to boost performance. To mitigate task interference, we design a novel modularization parameterization inspired by sparse Transformer. We demonstrate that our model can benefit from self-supervised pretraining on Wikipedia and fine-tuning using multiple ODQA datasets, both in a multi-task fashion. Our approach outperforms recent self-supervised retrievers in zero-shot evaluations and achieves state-of-the-art fine-tuned retrieval performance on NQ, HotpotQA and OTT-QA.
    
[^111]: PeaCoK: 维持一致并引人入胜的叙述所需的角色常识知识

    PeaCoK: Persona Commonsense Knowledge for Consistent and Engaging Narratives. (arXiv:2305.02364v1 [cs.CL])

    [http://arxiv.org/abs/2305.02364](http://arxiv.org/abs/2305.02364)

    PeaCoK构建了一个大规模的角色常识知识图，包含约10万个经过人类验证的角色事实。该知识图展现了在以前的人类交互行为研究中确定的五个角色知识维度，并区分了常识和情感层面。

    

    维持一致且引人入胜的叙述需要对话或故事代理人理解说话者或听众的角色如何与叙述相关联。具体来说，这些代理人必须推断他们听众的角色，以产生符合他们兴趣的陈述。他们还必须学习在整个叙述中保持一致的说话者角色，以便他们的对等方感到参与其中并且是一段逼真的对话或故事。然而，角色是多样化和复杂的：它们包含大量丰富的相互关联的世界知识，这对于强大的一般叙述系统而言是具有挑战性的（例如，歌手擅长唱歌，并可能曾参加过音乐学院）。在这项工作中，我们构建了一个新的大规模角色常识知识图PeaCoK，其中包含约10万个经过人类验证的角色事实。我们的知识图表现了在以前的人类交互行为研究中确定的五个角色知识维度，并区分了常识和情感层面。

    Sustaining coherent and engaging narratives requires dialogue or storytelling agents to understand how the personas of speakers or listeners ground the narrative. Specifically, these agents must infer personas of their listeners to produce statements that cater to their interests. They must also learn to maintain consistent speaker personas for themselves throughout the narrative, so that their counterparts feel involved in a realistic conversation or story.  However, personas are diverse and complex: they entail large quantities of rich interconnected world knowledge that is challenging to robustly represent in general narrative systems (e.g., a singer is good at singing, and may have attended conservatoire). In this work, we construct a new large-scale persona commonsense knowledge graph, PeaCoK, containing ~100K human-validated persona facts. Our knowledge graph schematizes five dimensions of persona knowledge identified in previous studies of human interactive behaviours, and disti
    
[^112]: 系统研究基于伪目标训练的知识蒸馏用于自然语言生成

    A Systematic Study of Knowledge Distillation for Natural Language Generation with Pseudo-Target Training. (arXiv:2305.02031v1 [cs.CL])

    [http://arxiv.org/abs/2305.02031](http://arxiv.org/abs/2305.02031)

    本文研究如何压缩自然语言生成模型以适应实际应用需求，通过使用知识蒸馏和伪目标训练技术针对特定的自然语言生成任务和数据集进行优化，并取得了显著效果。

    

    现代自然语言生成模型需要大量的计算和存储资源。本文研究压缩这些模型的潜力，这对于服务数百万用户的实际应用至关重要。我们聚焦于知识蒸馏（KD）技术，其中小的学生模型学习模仿大的教师模型，使得可以从教师向学生传递知识。与之前的大部分工作不同，我们的目标是针对特定的自然语言生成任务和数据集优化模型。通常，在真实世界的应用中，除了有标记数据外，还有大量的未标记任务特定数据，这对于通过知识蒸馏获得高压缩率至关重要。在本文中，我们在现实的假设下，对各种自然语言生成任务进行了系统的任务特定知识蒸馏研究，并讨论了自然语言生成蒸馏的特殊特征，尤其是曝光偏差问题。接着，我们推导出一系列伪目标训练（PTT）技术，缓解了这个问题，并提高了学生模型的质量。通过广泛的实验评估，我们证明了我们提出的方法在不同的自然语言生成任务和数据集上的有效性。

    Modern Natural Language Generation (NLG) models come with massive computational and storage requirements. In this work, we study the potential of compressing them, which is crucial for real-world applications serving millions of users. We focus on Knowledge Distillation (KD) techniques, in which a small student model learns to imitate a large teacher model, allowing to transfer knowledge from the teacher to the student. In contrast to much of the previous work, our goal is to optimize the model for a specific NLG task and a specific dataset. Typically, in real-world applications, in addition to labeled data there is abundant unlabeled task-specific data, which is crucial for attaining high compression rates via KD. In this work, we conduct a systematic study of task-specific KD techniques for various NLG tasks under realistic assumptions. We discuss the special characteristics of NLG distillation and particularly the exposure bias problem. Following, we derive a family of Pseudo-Target
    
[^113]: FIREBALL：一份包含结构化游戏状态信息的Dungeons & Dragons实际游戏数据集

    FIREBALL: A Dataset of Dungeons and Dragons Actual-Play with Structured Game State Information. (arXiv:2305.01528v1 [cs.CL])

    [http://arxiv.org/abs/2305.01528](http://arxiv.org/abs/2305.01528)

    本研究介绍了一份包含真实游戏状态信息的Dungeons & Dragons实际游戏数据集FIREBALL，它可以改善自然语言生成的质量。此外，LLMs可以使用FIREBALL中的游戏状态信息来生成更高质量的游戏回合。

    

    Dungeons & Dragons（D＆D）是一款桌面角色扮演游戏，其玩家之间存在复杂的自然语言交互和隐藏的状态信息。最近的研究表明，拥有状态信息的大型语言模型（LLMs）生成的游戏回合比仅使用对话历史的LLMs更具高质量。然而，以往的研究使用的游戏状态信息是启发式创建的，并不是真正的黄金标准游戏状态。我们提出了FIREBALL，这是一个包含真实游戏状态信息的大型数据集，其中包含来自Discord的近25,000个真实D＆D游戏会话。我们记录了使用Avrae机器人的玩家的游戏会话，该机器人是为了帮助人们在线玩D＆D而开发的，并捕获了语言、游戏命令和基础游戏状态信息。我们证明，通过使用Avrae状态信息，FIREBALL可以提高自然语言生成（NLG），从而提高自动评估指标和人类的质量评判。此外，我们还展示了LLMs可以生成…

    Dungeons & Dragons (D&D) is a tabletop roleplaying game with complex natural language interactions between players and hidden state information. Recent work has shown that large language models (LLMs) that have access to state information can generate higher quality game turns than LLMs that use dialog history alone. However, previous work used game state information that was heuristically created and was not a true gold standard game state. We present FIREBALL, a large dataset containing nearly 25,000 unique sessions from real D\&D gameplay on Discord with true game state info. We recorded game play sessions of players who used the Avrae bot, which was developed to aid people in playing D&D online, capturing language, game commands and underlying game state information. We demonstrate that FIREBALL can improve natural language generation (NLG) by using Avrae state information, improving both automated metrics and human judgments of quality. Additionally, we show that LLMs can generate
    
[^114]: 一种改进领域特定机器阅读理解数据集的数据中心框架

    A Data-centric Framework for Improving Domain-specific Machine Reading Comprehension Datasets. (arXiv:2304.00483v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.00483](http://arxiv.org/abs/2304.00483)

    本文提出了一种数据中心框架，通过回译方法提高领域特定机器阅读理解数据集的质量，从而提高模型性能

    

    数据的质量低可能会导致高风险应用程序中的问题。数据中心方法强调提高数据集质量以增强模型性能。高质量的数据集对通用大语言模型（LLM）训练以及领域特定模型都是必需的，由于吸引大量领域专家参与创建数据集会很昂贵，因此领域特定训练数据的高质量对于模型性能是至关重要的。本文提出了一种增强原始数据集数据质量的框架，将该框架应用于四个生物医学数据集，通过使用回译来提高原始数据集的质量，在BioASQ数据集上对检索/读者模型进行微调时，我们的方法提高了最多33％/40％的性能。

    Low-quality data can cause downstream problems in high-stakes applications. Data-centric approach emphasizes on improving dataset quality to enhance model performance. High-quality datasets are needed for general-purpose Large Language Models (LLMs) training, as well as for domain-specific models, which are usually small in size as it is costly to engage a large number of domain experts for their creation. Thus, it is vital to ensure high-quality domain-specific training data. In this paper, we propose a framework for enhancing the data quality of original datasets. We applied the proposed framework to four biomedical datasets and showed relative improvement of up to 33%/40% for fine-tuning of retrieval/reader models on the BioASQ dataset when using back translation to enhance the original dataset quality.
    
[^115]: 自我反馈迭代精炼：一种无需监督学习或加强学习的LM改进框架

    Self-Refine: Iterative Refinement with Self-Feedback. (arXiv:2303.17651v1 [cs.CL])

    [http://arxiv.org/abs/2303.17651](http://arxiv.org/abs/2303.17651)

    自我反馈迭代精炼是一种无需监督学习或加强学习的LLMs初始输出优化方法，优于直接生成，被证实在7个不同任务中表现更好。

    

    鉴于语言模型(LLMs)不总是能在第一次良好地解决生成问题（如摘要、答案、解释等），我们引入自我反馈迭代精炼（SELF-REFINE）框架，通过迭代反馈和精炼相似地优化LLMs的初始输出。主要思想是：使用LLM生成输出，然后允许同一模型提供其自身输出的多方面反馈，最后利用反馈使相同模型精炼先前生成的输出。我们的迭代精炼框架与早期工作不同，无需监督训练数据或加强学习，并且可以与单个LLM一起使用。我们对七个不同的任务进行了实验，范围从评论重写到数学推理，表明我们的方法优于直接生成。在所有任务中，使用SELF-REFINE生成的输出被人类和自动化指标优先于使用GPT-3.5和GPT-4直接生成的输出，表现得更好。

    Like people, LLMs do not always generate the best text for a given generation problem on their first try (e.g., summaries, answers, explanations). Just as people then refine their text, we introduce SELF-REFINE, a framework for similarly improving initial outputs from LLMs through iterative feedback and refinement. The main idea is to generate an output using an LLM, then allow the same model to provide multi-aspect feedback for its own output; finally, the same model refines its previously generated output given its own feedback. Unlike earlier work, our iterative refinement framework does not require supervised training data or reinforcement learning, and works with a single LLM. We experiment with 7 diverse tasks, ranging from review rewriting to math reasoning, demonstrating that our approach outperforms direct generation. In all tasks, outputs generated with SELF-REFINE are preferred by humans and by automated metrics over those generated directly with GPT-3.5 and GPT-4, improving
    
[^116]: 基于后训练量化的大型语言模型综合研究

    A Comprehensive Study on Post-Training Quantization for Large Language Models. (arXiv:2303.08302v1 [cs.LG])

    [http://arxiv.org/abs/2303.08302](http://arxiv.org/abs/2303.08302)

    本文基于数万个零-shot实验对基于后训练量化的大型语言模型的不同量化组件进行了综合研究，结果发现细粒度量化和后训练量化方法很重要，用粗粒度量化的更高位数比用非常细粒度的更低位数更强大。我们给出了如何为不同大小的\llms利用量化的建议。

    

    后训练量化是一种减少大型语言模型内存消耗和/或计算成本的权衡方法。然而，关于不同量化方案、不同模型族、不同后训练量化方法、不同量化位精度等的影响的全面研究仍缺失。本文通过数万个零-shot实验对这些组件进行了广泛的研究。我们的研究结果表明：(1)细粒度量化和后训练量化方法(而不是朴素的最近舍入量化)是实现良好精度的必要条件；(2) 用粗粒度量化的更高位数（如5位）比用非常细粒度的更低位数（如4位）（其有效位数与5位相似）更强大。我们还提出了如何为不同大小的\llms利用量化的建议，并留下未来机会和系统工作的建议。

    Post-training quantization (\ptq) had been recently shown as a compromising method to reduce the memory consumption and/or compute cost for large language models. However, a comprehensive study about the effect of different quantization schemes, different model families, different \ptq methods, different quantization bit precision, etc, is still missing. In this work, we provide an extensive study on those components over tens of thousands of zero-shot experiments. Our results show that (1) Fine-grained quantization and \ptq methods (instead of naive round-to-nearest quantization) are necessary to achieve good accuracy and (2) Higher bits (e.g., 5 bits) with coarse-grained quantization is more powerful than lower bits (e.g., 4 bits) with very fine-grained quantization (whose effective bits is similar to 5-bits). We also present recommendations about how to utilize quantization for \llms with different sizes, and leave suggestions of future opportunities and system work that are not res
    
[^117]: 揭示未知：基于实体链接的知识库外提及发现

    Reveal the Unknown: Out-of-Knowledge-Base Mention Discovery with Entity Linking. (arXiv:2302.07189v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.07189](http://arxiv.org/abs/2302.07189)

    本文提出了基于BERT的实体链接方法BLINKout，通过与特殊NIL实体匹配来识别没有相应KB实体的实体提及，相较于现有方法具有优势。

    

    从文本中发现知识库（KB）外的实体提及，在KB维护中起着至关重要的作用，但并未被完全开发。当前的方法主要局限于简单的基于阈值的方法和基于特征的分类，并且用于评估的数据集相对较少。本文提出了BLINKout，一种新的基于BERT的实体链接（EL）方法，可以通过将提及与特殊的NIL实体进行匹配来识别没有相应KB实体的提及。为了更好地利用BERT，我们提出了包括NIL实体表示和分类在内的新技术，并增强了其同义词。我们还提出了KB修剪和版本控制策略，以自动从常见的KB EL数据集构建出KB外的数据集。在医学本体论、UMLS、SNOMED CT等五个不同领域中，对临床笔记、生物医学出版物和维基百科文章的结果表明，BLINKout在识别知识库外提及方面优于现有方法。

    Discovering entity mentions that are out of a Knowledge Base (KB) from texts plays a critical role in KB maintenance, but has not yet been fully explored. The current methods are mostly limited to the simple threshold-based approach and feature-based classification, and the datasets for evaluation are relatively rare. We propose BLINKout, a new BERT-based Entity Linking (EL) method which can identify mentions that do not have corresponding KB entities by matching them to a special NIL entity. To better utilize BERT, we propose new techniques including NIL entity representation and classification, with synonym enhancement. We also propose KB Pruning and Versioning strategies to automatically construct out-of-KB datasets from common in-KB EL datasets. Results on five datasets of clinical notes, biomedical publications, and Wikipedia articles in various domains show the advantages of BLINKout over existing methods to identify out-of-KB mentions for the medical ontologies, UMLS, SNOMED CT,
    
[^118]: 将语言模型与图像进行联系以处理多模态信息

    Grounding Language Models to Images for Multimodal Inputs and Outputs. (arXiv:2301.13823v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.13823](http://arxiv.org/abs/2301.13823)

    该论文提出一种有效的方法，将仅处理文本的语言模型与图像进行联系，使其能够处理任意交错的图像和文本数据，并生成与检索图像交错的自由形式文本。该方法在环境相关的图像检索和多模态对话等任务中表现十分优异，是利用预训练语言模型解决视觉场景下交互问题的有效解决方案。

    

    我们提出了一种有效的方法，将预训练的仅文本语言模型与视觉领域联系起来，使其能够处理任意交错的图像和文本数据，并生成与检索图像交错的文本。我们利用从大规模文本预训练中学到的语言模型的能力，例如上下文学习和自由形式文本生成。我们保持语言模型冻结，并微调输入和输出线性层以实现跨模态交互。这使得我们的模型能够处理任意交错的图像和文本输入，并生成与检索图像交错的自由形式文本。我们在环境相关的图像检索和多模态对话等任务中取得了强大的零-shot表现，并展示了引人入胜的交互能力。我们的方法适用于任何现成的语言模型，为在视觉场景下利用预训练语言模型提供了一个有效且通用的解决方案。

    We propose an efficient method to ground pretrained text-only language models to the visual domain, enabling them to process arbitrarily interleaved image-and-text data, and generate text interleaved with retrieved images. Our method leverages the abilities of language models learnt from large scale text-only pretraining, such as in-context learning and free-form text generation. We keep the language model frozen, and finetune input and output linear layers to enable cross-modality interactions. This allows our model to process arbitrarily interleaved image-and-text inputs, and generate free-form text interleaved with retrieved images. We achieve strong zero-shot performance on grounded tasks such as contextual image retrieval and multimodal dialogue, and showcase compelling interactive abilities. Our approach works with any off-the-shelf language model and paves the way towards an effective, general solution for leveraging pretrained language models in visually grounded settings.
    
[^119]: 具有包容性的机器翻译的性别中性化：从理论基础到开放挑战

    Gender Neutralization for an Inclusive Machine Translation: from Theoretical Foundations to Open Challenges. (arXiv:2301.10075v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.10075](http://arxiv.org/abs/2301.10075)

    研究了性别中性化翻译（GNT）作为一种性别包容性的方法，从英语到意大利语的翻译是一个突出的性别相关的语言翻译问题。研究回顾了一些相关的性别包容性语言指南，探讨了使用GNT的情景，并探讨了在MT中执行GNT的技术挑战和解决方案。

    

    语言技术中的性别包容性已成为一个重要的研究课题。本研究探讨性别中性化翻译（GNT）作为一种性别包容性和机器翻译（MT）模型所要实现的目标，这些模型被发现具有延续性别偏见和歧视的倾向。具体而言，我们关注英译意这对语言，它代表了突出的与性别有关的语言转移问题。为了定义GNT，我们回顾了一些相关的机构性别包容性语言指南，讨论了使用GNT的情景，并探讨了在MT中执行GNT的技术挑战，最后讨论了潜在的解决方案，以鼓励朝着更大的包容性发展。

    Gender inclusivity in language technologies has become a prominent research topic. In this study, we explore gender-neutral translation (GNT) as a form of gender inclusivity and a goal to be achieved by machine translation (MT) models, which have been found to perpetuate gender bias and discrimination. Specifically, we focus on translation from English into Italian, a language pair representative of salient gender-related linguistic transfer problems. To define GNT, we review a selection of relevant institutional guidelines for gender-inclusive language, discuss its scenarios of use, and examine the technical challenges of performing GNT in MT, concluding with a discussion of potential solutions to encourage advancements toward greater inclusivity in MT.
    
[^120]: MoralDial：通过道德讨论来训练和评估道德对话系统的框架

    MoralDial: A Framework to Train and Evaluate Moral Dialogue Systems via Moral Discussions. (arXiv:2212.10720v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10720](http://arxiv.org/abs/2212.10720)

    MoralDial提出了一个通过模拟特定用户和对话系统之间的道德讨论来训练和评估道德对话系统的框架，并通过判断对话响应与人类价值观之间的关系来评估道德的多个方面。

    

    最近，对话系统中的道德问题引起了研究人员的极大关注。与用户价值观一致的道德对话系统可以增强对话的参与度和用户连接。在本文中，我们提出了一个框架，MoralDial，用于训练和评估道德对话系统。在我们的框架中，我们首先探讨了道德的交流机制，并将表达的道德分为三个部分，这指明了构建道德对话系统的路线图。基于此，我们设计了一种简单而有效的方法：构建模拟特定用户和对话系统之间的道德讨论。构建的讨论包括在对话交换中表达、解释、修订和推断道德观点，这使得对话模型可以以自然的方式学习道德。此外，我们还提出了一种新颖的评估方法。我们通过判断对话响应与人类价值观之间的关系来评估道德的多个方面。

    Morality in dialogue systems has raised great attention in research recently. A moral dialogue system aligned with users' values could enhance conversation engagement and user connections. In this paper, we propose a framework, MoralDial to train and evaluate moral dialogue systems. In our framework, we first explore the communication mechanisms of morality and resolve expressed morality into three parts, which indicate the roadmap for building a moral dialogue system. Based on that, we design a simple yet effective method: constructing moral discussions between simulated specific users and the dialogue system. The constructed discussions consist of expressing, explaining, revising, and inferring moral views in dialogue exchanges, which makes conversational models learn morality well in a natural manner. Furthermore, we propose a novel evaluation method under the framework. We evaluate the multiple aspects of morality by judging the relation between dialogue responses and human values 
    
[^121]: 自我指导: 用自生成的指示对齐语言模型

    Self-Instruct: Aligning Language Models with Self-Generated Instructions. (arXiv:2212.10560v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10560](http://arxiv.org/abs/2212.10560)

    本论文提出了一种名为Self-Instruct的框架，通过自身生成指导信息来提高预训练语言模型的指令遵循能力。在超自然指令上，我们展示了与InstructGPT-001相同的性能表现，并在原始模型上获得了33%的改进。

    

    大型的"指令调整"语言模型(即，调整为响应指令)已经展示了惊人的能力，可以零-shot推广到新任务。然而，它们严重依赖于人工编写的指令数据，通常在数量、多样性和创造力方面受到限制，从而阻碍了调整模型的通用性。我们引入了Self-Instruct，这是一个用于改善预训练语言模型遵循指令能力的框架，通过自身的生成来引导它们。我们的工作流程从语言模型中生成指令、输入和输出样本，然后过滤掉无效或相似的样本，然后再将它们用于调整原始模型。将我们的方法应用于普通的GPT3，我们展示了在超自然指令上与InstructGPT-001的性能相媲美，并比原始模型获得了33%的绝对改进。

    Large "instruction-tuned" language models (i.e., finetuned to respond to instructions) have demonstrated a remarkable ability to generalize zero-shot to new tasks. Nevertheless, they depend heavily on human-written instruction data that is often limited in quantity, diversity, and creativity, therefore hindering the generality of the tuned model. We introduce Self-Instruct, a framework for improving the instruction-following capabilities of pretrained language models by bootstrapping off their own generations. Our pipeline generates instructions, input, and output samples from a language model, then filters invalid or similar ones before using them to finetune the original model. Applying our method to the vanilla GPT3, we demonstrate a 33% absolute improvement over the original model on Super-NaturalInstructions, on par with the performance of InstructGPT-001, which was trained with private user data and human annotations. For further evaluation, we curate a set of expert-written inst
    
[^122]: Socratic预训练：面向可控摘要的问题驱动预训练

    Socratic Pretraining: Question-Driven Pretraining for Controllable Summarization. (arXiv:2212.10449v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10449](http://arxiv.org/abs/2212.10449)

    本论文介绍了一种面向问题驱动的无监督预训练方法，名为Socratic预训练，用于提高摘要任务的可控性，并演示了该方法通过在多个控制策略上进行广泛实验得出的优于其他方法的结果。

    

    在标注数据稀缺的情况下，对于长篇文档的可控摘要，预训练模型很难适应任务并有效地响应用户查询。在本文中，我们介绍了Socratic预训练，一种面向问题驱动的无监督预训练方法，旨在提高摘要任务的可控性。通过训练模型生成和回答给定上下文中的相关问题，Socratic预训练使模型能够更有效地遵循用户提供的查询，并确定需要摘要的相关内容。我们通过在两个摘要域上进行广泛实验，即短篇故事和对话，并使用关键词、问题和事实QA对多个控制策略进行了演示。我们的预训练方法只依赖于无标注文档和问题生成系统，表现优于使用额外的监督数据的预精调方法。此外，我们的结果表明，Socratic预训练可以显著提高模型生成遵守用户指定约束条件的摘要的能力。

    In long document controllable summarization, where labeled data is scarce, pretrained models struggle to adapt to the task and effectively respond to user queries. In this paper, we introduce Socratic pretraining, a question-driven, unsupervised pretraining objective specifically designed to improve controllability in summarization tasks. By training a model to generate and answer relevant questions in a given context, Socratic pretraining enables the model to more effectively adhere to user-provided queries and identify relevant content to be summarized. We demonstrate the effectiveness of this approach through extensive experimentation on two summarization domains, short stories and dialogue, and multiple control strategies: keywords, questions, and factoid QA pairs. Our pretraining method relies only on unlabeled documents and a question generation system and outperforms pre-finetuning approaches that use additional supervised data. Furthermore, our results show that Socratic pretra
    
[^123]: 大型语言模型中的推理研究综述

    Towards Reasoning in Large Language Models: A Survey. (arXiv:2212.10403v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10403](http://arxiv.org/abs/2212.10403)

    本文综述了大型语言模型中的推理研究的现状和未来方向，包括提高和诱导推理能力的技术、评估推理能力的方法和基准，旨在提供一个详细和最新的综述，刺激有意义的讨论和未来的研究。

    

    推理是人类智能的基本方面，在问题解决、决策和批判性思维等活动中发挥着关键作用。近年来，大型语言模型（LLMs）在自然语言处理方面取得了显著的进展，观察到当这些模型足够大时，它们可能会展现出推理能力。然而，目前尚不清楚LLMs在推理方面的能力到底如何。本文全面阐述了LLMs中推理研究的当前状况，包括提高和诱导这些模型推理的技术、评估推理能力的方法和基准、以及以往研究的结果和意义，同时提出了未来方向的建议。我们的目的是提供一个详细和最新的综述，刺激有意义的讨论和未来的研究。

    Reasoning is a fundamental aspect of human intelligence that plays a crucial role in activities such as problem solving, decision making, and critical thinking. In recent years, large language models (LLMs) have made significant progress in natural language processing, and there is observation that these models may exhibit reasoning abilities when they are sufficiently large. However, it is not yet clear to what extent LLMs are capable of reasoning. This paper provides a comprehensive overview of the current state of knowledge on reasoning in LLMs, including techniques for improving and eliciting reasoning in these models, methods and benchmarks for evaluating reasoning abilities, findings and implications of previous research in this field, and suggestions on future directions. Our aim is to provide a detailed and up-to-date review of this topic and stimulate meaningful discussion and future work.
    
[^124]: 处理图像歧义：改善多模式机器翻译和对比评估

    Tackling Ambiguity with Images: Improved Multimodal Machine Translation and Contrastive Evaluation. (arXiv:2212.10140v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10140](http://arxiv.org/abs/2212.10140)

    本文提出了一种基于强文本机器翻译模型的多模式翻译方法，该方法利用图像解决机器翻译中的歧义问题，同时引入了CoMMuTE数据集以进行对比多语言多模式翻译评估，取得了与强文本模型相当的结果。

    

    机器翻译中的一个主要挑战是歧义，而图像等上下文信息可以在某些情况下解决此问题。然而，最近的多模式机器翻译研究表明，利用图像提高翻译效果具有挑战性，不仅受到跨模态表达有效性的困难限制，还受到特定评估和训练数据缺乏的限制。本文提出了一种新的基于强文本机器翻译模型的多模式翻译方法，该方法使用神经适配器和新颖的引导自注意力机制，并在视觉条件掩蔽和多模式翻译上进行联合训练。同时，我们还介绍了CoMMuTE，一组包含模糊句子及其可能的翻译方案和对应图像的对比多语言多模式翻译评估数据集。我们的方法在标准的英法、英德和英捷翻译基准测试中获得了与强文本模型相当的结果。

    One of the major challenges of machine translation (MT) is ambiguity, which can in some cases be resolved by accompanying context such as images. However, recent work in multimodal MT (MMT) has shown that obtaining improvements from images is challenging, limited not only by the difficulty of building effective cross-modal representations, but also by the lack of specific evaluation and training data. We present a new MMT approach based on a strong text-only MT model, which uses neural adapters, a novel guided self-attention mechanism and which is jointly trained on both visually-conditioned masking and MMT. We also introduce CoMMuTE, a Contrastive Multilingual Multimodal Translation Evaluation set of ambiguous sentences and their possible translations, accompanied by disambiguating images corresponding to each translation. Our approach obtains competitive results compared to strong text-only models on standard English-to-French, English-to-German and English-to-Czech benchmarks and ou
    
[^125]: DIONYSUS：用于低资源对话摘要的预训练模型

    DIONYSUS: A Pre-trained Model for Low-Resource Dialogue Summarization. (arXiv:2212.10018v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10018](http://arxiv.org/abs/2212.10018)

    提出了一种名为DIONYSUS的对话摘要模型，它是一个预先训练的编码器-解码器模型，可用于低资源的对话摘要，自监督的方法用于预训练。该模型的创新点在于利用不同的伪摘要，并基于对话中信息分布的分析来选择最佳的伪摘要，提高了在新领域中对话摘要的表现。

    

    对话摘要由于其广泛的应用受到了近期的极大关注。然而，现有的对话摘要方法存在局限性，因为它们没有考虑对话的固有结构，并且严重依赖于标记数据，这可能导致在新领域中效果欠佳。在这项工作中，我们提出了DIONYSUS（用于任何新领域中对话摘要的预训练编码器-解码器模型），其基于自监督方法，用于预训练模型。我们为每个对话示例创建了两个伪摘要：一个是通过微调摘要模型生成的，另一个是包含重要信息的对话转换集合。然后，我们基于不同类型的对话中的信息分布差异选择其中一个伪摘要。这个所选的伪摘要作为目标，用自监督的方法在大型对话语料库上预训练DIONYSUS。

    Dialogue summarization has recently garnered significant attention due to its wide range of applications. However, existing methods for summarizing dialogues have limitations because they do not take into account the inherent structure of dialogue and rely heavily on labeled data, which can lead to poor performance in new domains. In this work, we propose DIONYSUS (dynamic input optimization in pre-training for dialogue summarization), a pre-trained encoder-decoder model for summarizing dialogues in any new domain. To pre-train DIONYSUS, we create two pseudo summaries for each dialogue example: one is produced by a fine-tuned summarization model, and the other is a collection of dialogue turns that convey important information. We then choose one of these pseudo summaries based on the difference in information distribution across different types of dialogues. This selected pseudo summary serves as the objective for pre-training DIONYSUS using a self-supervised approach on a large dialo
    
[^126]: 通过提问澄清问题实现Python代码生成

    Python Code Generation by Asking Clarification Questions. (arXiv:2212.09885v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09885](http://arxiv.org/abs/2212.09885)

    本文提出了一个新的方法来解决自然语言描述中存在歧义的问题--通过提问澄清问题，本文提出的方法在预训练语言模型性能上取得了显著改善。

    

    从文本中生成代码需要理解用户的意图，并生成满足此意图的可执行代码片段。在这项任务中，当自然语言描述不够明确时，最近的预训练语言模型表现不佳。本文提出了一种新颖而更现实的任务设置，假设自然语言描述的不明确性可以通过提问澄清问题来解决。因此，我们收集并引入了一个名为 CodeClarQA 的新数据集，其中包含自然语言描述和代码的成对数据以及创建的合成澄清问题和答案。评估预训练语言模型在代码生成上的实证结果表明，在自然语言描述存在歧义时，通过澄清问题可以生成更准确的代码，这体现在所有评估指标的模型性能显著提高。除了翻译外，我们提出了一种新的代码生成方法，其中包括提问澄清问题以消除自然语言描述中的歧义。

    Code generation from text requires understanding the user's intent from a natural language description and generating an executable code snippet that satisfies this intent. While recent pretrained language models demonstrate remarkable performance for this task, these models fail when the given natural language description is under-specified. In this work, we introduce a novel and more realistic setup for this task. We hypothesize that the under-specification of a natural language description can be resolved by asking clarification questions. Therefore, we collect and introduce a new dataset named CodeClarQA containing pairs of natural language descriptions and code with created synthetic clarification questions and answers. The empirical results of our evaluation of pretrained language model performance on code generation show that clarifications result in more precisely generated code, as shown by the substantial improvement of model performance in all evaluation metrics. Alongside t
    
[^127]: 无监督摘要再排序

    Unsupervised Summarization Re-ranking. (arXiv:2212.09593v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09593](http://arxiv.org/abs/2212.09593)

    该论文提出了一种无监督的摘要再排序方法，可以将无监督模型的摘要表现提高，缩小其与有监督模型之间的性能差距。

    

    随着任务特定的预训练目标的兴起，像PEGASUS这样的抽象摘要模型在下游摘要任务中提供了令人满意的零样本性能。然而，这些无监督模型的性能仍然明显落后于它们的有监督对应物。本文提出了一种无监督的摘要再排序方法，旨在缩小无监督和有监督模型之间的性能差距。我们的方法在四个被广泛采用的摘要基准测试中，将PEGASUS的相对平均ROUGE提高了最多7.27％，ChatGPT提高了最多6.86％；并且在30种零样本转移设置（在一个数据集上微调，另一个数据集上评估）中，平均获得了7.51％的相对增益（从XSum到WikiHow最高可达23.73％）。

    With the rise of task-specific pre-training objectives, abstractive summarization models like PEGASUS offer appealing zero-shot performance on downstream summarization tasks. However, the performance of such unsupervised models still lags significantly behind their supervised counterparts. Similarly to the supervised setup, we notice a very high variance in quality among summary candidates from these models while only one candidate is kept as the summary output. In this paper, we propose to re-rank summary candidates in an unsupervised manner, aiming to close the performance gap between unsupervised and supervised models. Our approach improves the unsupervised PEGASUS by up to 7.27% and ChatGPT by up to 6.86% relative mean ROUGE across four widely-adopted summarization benchmarks ; and achieves relative gains of 7.51% (up to 23.73% from XSum to WikiHow) averaged over 30 zero-shot transfer setups (finetuning on a dataset, evaluating on another).
    
[^128]: 基于非监督联合建模的查询增强知识密集型对话

    Query Enhanced Knowledge-Intensive Conversation via Unsupervised Joint Modeling. (arXiv:2212.09588v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09588](http://arxiv.org/abs/2212.09588)

    本文提出了一个无监督的查询增强方法QKConv，用于知识密集型对话，并在三个数据集上进行了实验。实验结果表明，QKConv的表现比所有无监督方法都要好，并且与有监督方法具有竞争性的性能。

    

    本文提出了一种无监督查询增强方法——QKConv，用于知识密集型对话。QKConv包含三个模块：查询生成器、通用知识选择器和响应生成器。QKConv通过联合训练进行优化，通过探索多个候选查询并利用相应的选择的知识来生成响应。联合训练仅依赖于对话上下文和目标响应，免除了额外的查询注释或知识来源。为了评估所提出的QKConv的有效性，我们在三个代表性的知识密集型对话数据集上进行了实验：对话问答、任务导向对话和基于知识的对话。实验结果表明，在三个数据集上，QKConv的表现比所有无监督方法都要好，并且与有监督方法具有竞争性的性能。

    In this paper, we propose an unsupervised query enhanced approach for knowledge-intensive conversations, namely QKConv. There are three modules in QKConv: a query generator, an off-the-shelf knowledge selector, and a response generator. QKConv is optimized through joint training, which produces the response by exploring multiple candidate queries and leveraging corresponding selected knowledge. The joint training solely relies on the dialogue context and target response, getting exempt from extra query annotations or knowledge provenances. To evaluate the effectiveness of the proposed QKConv, we conduct experiments on three representative knowledge-intensive conversation datasets: conversational question-answering, task-oriented dialogue, and knowledge-grounded conversation. Experimental results reveal that QKConv performs better than all unsupervised methods across three datasets and achieves competitive performance compared to supervised methods.
    
[^129]: I2D2: 基于NeuroLogic和自我模仿的归纳知识蒸馏

    I2D2: Inductive Knowledge Distillation with NeuroLogic and Self-Imitation. (arXiv:2212.09246v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09246](http://arxiv.org/abs/2212.09246)

    本论文探究了通过常识蒸馏算法强化小型语言模型的能力，挑战大型模型的常识获取能力，提出了一种不依赖规模的学习算法方案。

    

    尽管预训练语言模型在规模方面不断强化，但仍缺乏坚实的常识功能。然而，规模似乎是制胜法宝；毕竟，最大的模型似乎已经获得了最多的常识功能。这篇论文探究了似乎不可能实现的匹配：如果小型语言模型（如GPT-2）通过新颖的常识蒸馏算法得到动力，它们是否能赢过比它们大数个数量级并且更优秀的模型（如GPT-3）？我们所提出的关键智力问题是，是否可能设计一种学习算法，它并不受到规模的好处，而却有竞争力的常识获取水平。在本文中，我们研究了常识知识的生成模型，重点关注生成通用语句的任务，即关于日常概念的常识事实陈述。

    Pre-trained language models, despite their rapid advancements powered by scale, still fall short of robust commonsense capabilities. And yet, scale appears to be the winning recipe; after all, the largest models seem to have acquired the largest amount of commonsense capabilities. Or is it?  In this paper, we investigate the possibility of a seemingly impossible match: can smaller language models with dismal commonsense capabilities (i.e., GPT-2), ever win over models that are orders of magnitude larger and better (i.e., GPT-3), if the smaller models are powered with novel commonsense distillation algorithms? The key intellectual question we ask here is whether it is possible, if at all, to design a learning algorithm that does not benefit from scale, yet leads to a competitive level of commonsense acquisition. In this work, we study the generative models of commonsense knowledge, focusing on the task of generating generics, statements of commonsense facts about everyday concepts, e.g.
    
[^130]: OASum：大规模开放领域基于特定方面的摘要

    OASum: Large-Scale Open Domain Aspect-based Summarization. (arXiv:2212.09233v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09233](http://arxiv.org/abs/2212.09233)

    本文提出了一种大规模开放领域基于特定方面的摘要生成方法，通过对维基百科进行众包知识的利用，构建了高质量的OASum数据集，并在七个下游数据集上进行训练。该方法可以进行多样化的方面基础的总结生成。

    

    近来方面或基于查询的总结引起了更多关注，因为它可以基于用户的兴趣生成不同的总结。然而，现有的方面或基于查询的总结数据集通常侧重于特定领域，包含的实例规模相对较小，或者仅包含少量方面类型。这些限制阻碍了在这个方向上的进一步探索。在这项工作中，我们利用维基百科.org上的众包知识，并自动生成一个高质量的、大规模的开放领域基于特定方面的摘要数据集，命名为OASum，其中包含了超过370万个实例，在200万个维基百科页面中涉及了约100万个不同的方面。我们在OASum上提供了基准结果，并展示了其进行多样化方面基础的总结生成的能力。为了克服特定领域数据稀缺问题，我们还通过对七个下游数据集进行零-shot、少-shot和微调进行训练。

    Aspect or query-based summarization has recently caught more attention, as it can generate differentiated summaries based on users' interests. However, the current dataset for aspect or query-based summarization either focuses on specific domains, contains relatively small-scale instances, or includes only a few aspect types. Such limitations hinder further explorations in this direction. In this work, we take advantage of crowd-sourcing knowledge on Wikipedia.org and automatically create a high-quality, large-scale open-domain aspect-based summarization dataset named OASum, which contains more than 3.7 million instances with around 1 million different aspects on 2 million Wikipedia pages. We provide benchmark results on OASum and demonstrate its ability for diverse aspect-based summarization generation. To overcome the data scarcity problem on specific domains, we also perform zero-shot, few-shot, and fine-tuning on seven downstream datasets. Specifically, zero/few-shot and fine-tunin
    
[^131]: 别忘了你的ABC：评估聊天导向对话系统的最新进展

    Don't Forget Your ABC's: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems. (arXiv:2212.09180v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09180](http://arxiv.org/abs/2212.09180)

    本文提出了一种可靠的维度化评估人机聊天的新方法，并评估了一组最先进的开放领域聊天机器人，为未来聊天导向对话系统的发展提供了基准。

    

    人机聊天交互领域近来取得了巨大进展，然而，适当的评估仍需要人类主观判断，因此评测指标易出现高方差问题。此外，当前评估方法和标准缺乏规范性，缺乏用于评估有效性的工作。因此，现有的评估结果可能无法完整反映开放领域聊天机器人的优点和缺陷。我们旨在实现对人机聊天的维度化评估，可可靠地测量聊天质量的几个不同方面。为此，我们提出了一种新颖的人类评估方法，量化了几种与质量相关的机器人聊天行为。我们的结果表明，我们的方法比替代的Likert-style或比较方法更适合评估维度化聊天。然后，我们使用我们验证的方法和现有方法来评估一组最先进的开放领域聊天机器人，并全面比较了它们在几个质量维度上的性能。我们的结果突显了现有开放领域聊天机器人技术的持续优势和限制，并为聊天导向对话系统的未来发展提供了基准。

    There has been great recent advancement in human-computer chat. However, proper evaluation currently requires human judgements that produce notoriously high-variance metrics due to their inherent subjectivity. Furthermore, there is little standardization in the methods and labels used for evaluation, with an overall lack of work to compare and assess the validity of various evaluation approaches. As a consequence, existing evaluation results likely leave an incomplete picture of the strengths and weaknesses of open-domain chatbots. We aim towards a dimensional evaluation of human-computer chat that can reliably measure several distinct aspects of chat quality. To this end, we present our novel human evaluation method that quantifies the rate of several quality-related chatbot behaviors. Our results demonstrate our method to be more suitable for dimensional chat evaluation than alternative likert-style or comparative methods. We then use our validated method and existing methods to eval
    
[^132]: 语言模型在处理量词时表现略有问题？使用少量类型的量词会导致语言模型的预测呈现反比例缩放的现象。

    Rarely a problem? Language models exhibit inverse scaling in their predictions following few-type quantifiers. (arXiv:2212.08700v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.08700](http://arxiv.org/abs/2212.08700)

    本文研究了语言模型处理“few-”类型量词的能力，结果显示所有模型对这种量词都表现不佳，且较大的模型表现更差。这种反比例缩放的现象表明大型模型越来愈反映在线人类处理，而不是离线处理。这可能挑战使用语言模型作为自然语言系统基础的做法。

    

    本研究探讨了语言模型如何处理量化问题。我们以“few-”类型的量词为重点，比如“few children like toys”，因为这种类型的句子组成部分通常会共现，而“few-”类型的量词较为罕见，这可能对语言模型构成特别挑战。我们对来自两项人类神经语言学实验的960个英语句子进行了试验，并将它们提供给22个不同大小的自回归变换器模型。不仅所有模型对“few-”类型的量词都表现不佳，而且总体上，模型越大，其表现越差。这种反比例缩放的现象与之前的研究结果一致，表明较大的模型越来越反映在线人类处理，而不是离线处理。我们认为，更大的模型的性能下降可能会挑战将语言模型作为自然语言系统基础的做法。

    How well do language models deal with quantification? In this study, we focus on 'few'-type quantifiers, as in 'few children like toys', which might pose a particular challenge for language models because the sentence components with out the quantifier are likely to co-occur, and 'few'-type quantifiers are rare. We present 960 English sentence stimuli from two human neurolinguistic experiments to 22 autoregressive transformer models of differing sizes. Not only do all the models perform poorly on 'few'-type quantifiers, but overall the larger the model, the worse its performance. This inverse scaling is consistent with previous work suggesting that larger models increasingly reflect online rather than offline human processing, and we argue that the decreasing performance of larger models may challenge uses of language models as the basis for natural language systems.
    
[^133]: UnitY: 用离散单元进行两遍直接语音翻译

    UnitY: Two-pass Direct Speech-to-speech Translation with Discrete Units. (arXiv:2212.08055v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.08055](http://arxiv.org/abs/2212.08055)

    UnitY是一种通过两遍翻译生成最佳结果的语音翻译方法，能够比单遍语音到单元翻译模型在ASR-BLEU值和解码速度上表现更好。

    

    直接语音到语音翻译具有优化的组件和简化的流程，比级联方法更具优势。我们提出了一种新颖的两遍直接语音到语音翻译架构UnitY，首先生成文本表示，其次预测离散的声学单元。通过第一遍解码器的子词预测、高级的两遍解码器架构设计和搜索策略以及更好的训练正则化来提高模型性能。为了利用大量未标记的文本数据，我们基于自监督去噪自编码任务对第一遍文本解码器进行预训练。在各种数据规模的基准数据集上进行实验验证，UnitY比单遍语音到单元翻译模型的ASR-BLEU提高了2.5-4.2个，并且解码速度提高了2.83倍。我们还展示了在第二遍预测频谱时，所提出的方法可以提高性能。

    Direct speech-to-speech translation (S2ST), in which all components can be optimized jointly, is advantageous over cascaded approaches to achieve fast inference with a simplified pipeline. We present a novel two-pass direct S2ST architecture, UnitY, which first generates textual representations and predicts discrete acoustic units subsequently. We enhance the model performance by subword prediction in the first-pass decoder, advanced two-pass decoder architecture design and search strategy, and better training regularization. To leverage large amounts of unlabeled text data, we pre-train the first-pass text decoder based on the self-supervised denoising auto-encoding task. Experimental evaluations on benchmark datasets at various data scales demonstrate that UnitY outperforms a single-pass speech-to-unit translation model by 2.5-4.2 ASR-BLEU with 2.83x decoding speed-up. We show that the proposed methods boost the performance even when predicting spectrogram in the second pass. However
    
[^134]: DAMP：面向任务型对话的双重对齐多语言解析器

    DAMP: Doubly Aligned Multilingual Parser for Task-Oriented Dialogue. (arXiv:2212.08054v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.08054](http://arxiv.org/abs/2212.08054)

    本文介绍了一种面向任务型对话的双重对齐多语言解析器，可以大幅提高多语言和代码切换语义解析系统的零-shot性能，提高mBERT转移性能。

    

    现代虚拟助手使用内部语义解析引擎将用户话语转化为可操作命令。然而，先前的研究表明，语义解析是一项困难的多语言转移任务，其转移效率比其他任务低。在全球市场（如印度和拉丁美洲），这是一个关键问题，因为双语用户频繁切换语言。在本研究中，我们使用两个阶段的多语言对齐，大大提高了多语言和代码切换语义解析系统的零-shot性能。首先，我们表明，对比对齐预训练可以提高英文性能和转移效率。然后，我们引入一种受限制的优化方法，用于无超参数的对抗性对齐。我们的双重对齐多语言解析器（DAMP）分别将Spanglish、Hinglish和多语言任务导向解析基准的mBERT转移性能提高了3倍、6倍和81倍。

    Modern virtual assistants use internal semantic parsing engines to convert user utterances to actionable commands. However, prior work has demonstrated that semantic parsing is a difficult multilingual transfer task with low transfer efficiency compared to other tasks. In global markets such as India and Latin America, this is a critical issue as switching between languages is prevalent for bilingual users. In this work we dramatically improve the zero-shot performance of a multilingual and codeswitched semantic parsing system using two stages of multilingual alignment. First, we show that constrastive alignment pretraining improves both English performance and transfer efficiency. We then introduce a constrained optimization approach for hyperparameter-free adversarial alignment during finetuning. Our Doubly Aligned Multilingual Parser (DAMP) improves mBERT transfer performance by 3x, 6x, and 81x on the Spanglish, Hinglish and Multilingual Task Oriented Parsing benchmarks respectively
    
[^135]: 多元价值：跨方言的英文NLP框架

    Multi-VALUE: A Framework for Cross-Dialectal English NLP. (arXiv:2212.08011v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.08011](http://arxiv.org/abs/2212.08011)

    该论文介绍了一个跨方言的英文NLP框架Multi-VALUE，该框架可以将标准美式英语映射为50种英语方言的合成形式，用于评估、实现英式方言临近性，并在非标准方言上进行压力测试。

    

    区域、社会和经济因素引起的方言差异对许多语言技术用户造成了性能差异。普惠和公平的语言技术必须是临近方言的，这意味着在方言转换时性能保持不变。由于它们的设计和测试都是基于标准美式英语（SAE），目前的系统往往不能达到这个理想状态。我们介绍了一个资源套件，用于评估和实现英式方言临近性，称之为Multi-VALUE，它是一个可控制的基于规则的翻译系统，覆盖了50种英语方言和189个独特的语言特征。Multi-VALUE将SAE映射到每种方言的合成形式。我们首先使用这个系统进行压力测试，测试问答、机器翻译和语义解析。压力测试揭示了在非标准方言上的领先模型的显着性能差距。其次，我们使用这个系统作为数据增强技术以改善性能。

    Dialect differences caused by regional, social, and economic factors cause performance discrepancies for many groups of language technology users. Inclusive and equitable language technology must critically be dialect invariant, meaning that performance remains constant over dialectal shifts. Current systems often fall short of this ideal since they are designed and tested on a single dialect: Standard American English (SAE). We introduce a suite of resources for evaluating and achieving English dialect invariance. The resource is called Multi-VALUE, a controllable rule-based translation system spanning 50 English dialects and 189 unique linguistic features. Multi-VALUE maps SAE to synthetic forms of each dialect. First, we use this system to stress tests question answering, machine translation, and semantic parsing. Stress tests reveal significant performance disparities for leading models on non-standard dialects. Second, we use this system as a data augmentation technique to improve
    
[^136]: 无需图像的视觉增强预训练语言模型用于自然语言处理任务

    Visually-augmented pretrained language models for NLP tasks without images. (arXiv:2212.07937v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.07937](http://arxiv.org/abs/2212.07937)

    该研究提出了一种无需检索或生成图像的视觉增强微调方法，可以普遍地应用于各种PLM或NLP任务，并在不同规模的BERT、RoBERTa、BART和T5上持续地提高性能。

    

    尽管预训练语言模型(PLMs)通过纯文本自监督训练表现出色，但他们缺乏视觉语义或常识。现有的解决方案常常依赖于明确的图像来进行视觉知识增强(需要耗费时间的检索或生成)，并且他们也会为整个输入文本进行增强，而不考虑是否实际上需要在特定的输入或任务中进行增强。为了解决这些问题，我们提出了一种新颖的视觉增强微调方法，可以普遍地应用于各种PLM或NLP任务，无需使用任何检索或生成的图像，称为VAWI。实验结果表明，我们的方法可以在不同规模的BERT、RoBERTa、BART和T5上持续地提高性能，并在十个任务上胜过几个竞争基线。我们的代码和数据公开可用于\url{https://github.com/RUCAIBox/VAWI}。

    Although pre-trained language models~(PLMs) have shown impressive performance by text-only self-supervised training, they are found lack of visual semantics or commonsense. Existing solutions often rely on explicit images for visual knowledge augmentation (requiring time-consuming retrieval or generation), and they also conduct the augmentation for the whole input text, without considering whether it is actually needed in specific inputs or tasks. To address these issues, we propose a novel \textbf{V}isually-\textbf{A}ugmented fine-tuning approach that can be generally applied to various PLMs or NLP tasks, \textbf{W}ithout using any retrieved or generated \textbf{I}mages, namely \textbf{VAWI}. Experimental results show that our approach can consistently improve the performance of BERT, RoBERTa, BART, and T5 at different scales, and outperform several competitive baselines on ten tasks. Our codes and data are publicly available at~\url{https://github.com/RUCAIBox/VAWI}.
    
[^137]: 预训练语言模型可以成为完全零-shot学习器

    Pre-trained Language Models Can be Fully Zero-Shot Learners. (arXiv:2212.06950v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.06950](http://arxiv.org/abs/2212.06950)

    本文提出了一种名为NPPrompt的方法，它可以使预训练语言模型成为完全零-shot学习器。相比于现有方法，NPPrompt不需要使用人工标注数据或者构建提示，只需使用预训练的语言模型。NPPrompt在文本分类、文本蕴含、相似文本检索和改写等任务上的表现大幅优于以前最好的完全零-shot方法。

    

    在没有标记或额外未标记数据的情况下，我们如何将预训练模型扩展到许多语言理解任务中？预训练语言模型（PLMs）已经对各种自然语言处理任务有效。然而，现有方法要么需要对下游标记数据集进行微调，要么需要手动构建适当的提示。在本文中，我们提出了用于完全零-shot语言理解的非参数提示PLM（NPPrompt）。与以前的方法不同，NPPrompt仅使用预训练的语言模型，不需要任何标记数据或额外的原始语料库进行进一步的微调，也不依赖于人类构建全面的提示标签词集。我们在不同的自然语言处理任务上评估了NPPrompt和以前的主要少量样本和零射方法：包括文本分类、文本蕴含、相似文本检索和改写。实验结果表明，我们的NPPrompt显示出大幅优于以前最好的完全零-shot方法的表现。

    How can we extend a pre-trained model to many language understanding tasks, without labeled or additional unlabeled data? Pre-trained language models (PLMs) have been effective for a wide range of NLP tasks. However, existing approaches either require fine-tuning on downstream labeled datasets or manually constructing proper prompts. In this paper, we propose nonparametric prompting PLM (NPPrompt) for fully zero-shot language understanding. Unlike previous methods, NPPrompt uses only pre-trained language models and does not require any labeled data or additional raw corpus for further fine-tuning, nor does it rely on humans to construct a comprehensive set of prompt label words. We evaluate NPPrompt against previous major few-shot and zero-shot learning methods on diverse NLP tasks: including text classification, text entailment, similar text retrieval, and paraphrasing. Experimental results demonstrate that our NPPrompt outperforms the previous best fully zero-shot method by big margi
    
[^138]: 非参数遮蔽语言建模

    Nonparametric Masked Language Modeling. (arXiv:2212.01349v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.01349](http://arxiv.org/abs/2212.01349)

    NPM是第一个使用非参数分布替换softmax的遮蔽语言模型，可以更好地处理稀有模式和预测罕见或几乎未见过的单词，并在16项任务上超过了更大的参数模型。

    

    现有的语言模型（LM）通过有限词汇表上的 softmax 来预测标记，这可能使得预测稀有标记或短语变得困难。我们介绍了 NPM，它是第一个使用对每个参考语料库中短语的非参数分布替换此 softmax 的非参数遮蔽语言模型。NPM 仅通过从文本语料库中检索标记来填写 [MASK]。我们展示了 NPM 可以通过对比性目标和批量近似全语料库检索有效地训练。对 16 项任务进行零样本评估，包括分类、事实探针和问题回答，证明 NPM 超过了显着更大的参数模型，无论使用或不使用检索生成方法，它在处理稀有模式（词义或事实）和预测罕见或几乎未见过的单词（如非拉丁文脚本）方面表现出更好的性能。我们在 github.com/facebookresearch/NPM 上发布了模型和代码。

    Existing language models (LMs) predict tokens with a softmax over a finite vocabulary, which can make it difficult to predict rare tokens or phrases. We introduce NPM, the first nonparametric masked language model that replaces this softmax with a nonparametric distribution over every phrase in a reference corpus. NPM fills in the [MASK] solely from retrieving a token from a text corpus. We show that NPM can be efficiently trained with a contrastive objective and an in-batch approximation to full corpus retrieval. Zero-shot evaluation on 16 tasks including classification, fact probing and question answering demonstrates that NPM outperforms significantly larger parametric models, either with or without a retrieve-and-generate approach. It is particularly better at dealing with rare patterns (word senses or facts) and predicting rare or nearly unseen words (e.g., non-Latin script). We release the model and code at github.com/facebookresearch/NPM.
    
[^139]: 基于Prompt学习与传播结构的零样本谣言检测

    Zero-Shot Rumor Detection with Propagation Structure via Prompt Learning. (arXiv:2212.01117v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.01117](http://arxiv.org/abs/2212.01117)

    本文提出了一种基于Prompt学习和传播结构的零样本谣言检测框架，其能够有效地检测不同领域和语言的谣言，并可适应非预料中断事件的影响。

    

    在社交媒体时代，谣言随着事件的发生而传播，严重影响了真相的传播。之前的研究表明，由于缺乏标注资源，很难检测出使用少数语言的谣言。而且，昨天没有涉及到的非预料中断事件加剧了数据资源的稀缺性。本文提出了一种基于Prompt学习的新型零样本框架，用于检测不同领域或用不同语言展现的谣言。具体地说，我们首先将社交媒体上传播的谣言表示为多样的传播线程，然后设计了一个分层Prompt编码机制，学习了无语言环境下的上下文表示，以用于促进对不同领域和语言下的谣言数据转换。此外，我们从传播线程中建模领域不变的结构特征，以整合有影响力的社区反应的结构位置表示，以进一步增强领域适应性。同时，我们引入新的虚拟响应机制，以加强模型的推断能力。

    The spread of rumors along with breaking events seriously hinders the truth in the era of social media. Previous studies reveal that due to the lack of annotated resources, rumors presented in minority languages are hard to be detected. Furthermore, the unforeseen breaking events not involved in yesterday's news exacerbate the scarcity of data resources. In this work, we propose a novel zero-shot framework based on prompt learning to detect rumors falling in different domains or presented in different languages. More specifically, we firstly represent rumor circulated on social media as diverse propagation threads, then design a hierarchical prompt encoding mechanism to learn language-agnostic contextual representations for both prompts and rumor data. To further enhance domain adaptation, we model the domain-invariant structural features from the propagation threads, to incorporate structural position representations of influential community response. In addition, a new virtual respon
    
[^140]: 用于生成语言的软对齐目标的鲁棒适应

    Soft Alignment Objectives for Robust Adaptation of Language Generation. (arXiv:2211.16550v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.16550](http://arxiv.org/abs/2211.16550)

    本研究提出了一种基于预测令牌与参考语义相似性的新型训练目标，可以在领域自适应中缓解灾难性遗忘，同时又可以保持调整质量，并且计算成本增加可忽略不计。

    

    领域自适应允许生成语言模型解决应用领域转移造成的特定缺陷。然而，通过在领域内数据上进行进一步训练来进行传统适应会迅速削弱模型推广到其他领域的能力，使得调整后模型的无限部署容易出现错误。本工作介绍了建立在预测令牌与参考语义相似性的新型训练目标。我们的结果表明，避免单个正确预测的常见假设，通过构建来自令牌语义相似性的训练目标可以缓解领域适应期间的灾难性遗忘，同时在保持调整质量方面具有可忽略的计算成本增加。在更广泛的背景下，基于连续的令牌相似度的目标引领了高效但显式令牌级目标和具有表现力的基于连续令牌表示的目标之间中间地带的探索。

    Domain adaptation allows generative language models to address specific flaws caused by the domain shift of their application. However, the traditional adaptation by further training on in-domain data rapidly weakens the model's ability to generalize to other domains, making the open-ended deployments of the adapted models prone to errors. This work introduces novel training objectives built upon a semantic similarity of the predicted tokens to the reference.  Our results show that (1) avoiding the common assumption of a single correct prediction by constructing the training target from tokens' semantic similarity can mitigate catastrophic forgetting during domain adaptation, while (2) preserving the quality of the adaptation, (3) with negligible additions to compute costs.  In the broader context, the objectives grounded in a continuous token similarity pioneer the exploration of the middle ground between the efficient but na\"{\i}ve exact-match token-level objectives and expressive b
    
[^141]: 对比新颖性增强学习: 利用大型语言模型预测离群值

    Contrastive Novelty-Augmented Learning: Anticipating Outliers with Large Language Models. (arXiv:2211.15718v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.15718](http://arxiv.org/abs/2211.15718)

    CoNAL方法可以帮助分类模型降低在新颖类别上的过度自信，提高检测和放弃这些类别示例的能力。

    

    在许多任务设置中，文本分类模型可能会遇到无法正确预测的新颖类别的示例。有选择地预测在低置信度示例上的模型提供了一种可能的解决方案，但现有模型对未见过的类别常常过于自信。为了纠正这种过度自信，我们引入了对比新颖性增强学习（CoNAL），这是一种两步方法，它生成代表新颖类别的OOD示例，然后训练以降低置信度。首先，通过提示大型语言模型两次，我们生成OOD示例：我们提示它枚举相关的新颖类别，然后生成每个新颖类别匹配任务格式的示例。其次，我们使用新颖的对比目标来训练分类器，该目标鼓励在生成的OOD示例上具有比训练示例更低的置信度。当使用CoNAL训练时，与先前的方法相比，分类器在检测和放弃新颖类别示例方面的能力得到了大幅提高，同时保持对已知类别的性能。

    In many task settings, text classification models are likely to encounter examples from novel classes on which they cannot predict correctly. Selective prediction, in which models abstain on low-confidence examples, provides a possible solution, but existing models are often overly confident on unseen classes. To remedy this overconfidence, we introduce Contrastive Novelty-Augmented Learning (CoNAL), a two-step method that generates OOD examples representative of novel classes, then trains to decrease confidence on them. First, we generate OOD examples by prompting a large language model twice: we prompt it to enumerate relevant novel classes, then generate examples from each novel class matching the task format. Second, we train a classifier with a novel contrastive objective that encourages lower confidence on generated OOD examples than training examples. When trained with CoNAL, classifiers improve in their ability to detect and abstain on novel class examples over prior methods by
    
[^142]: SongRewriter: 一种具有可控内容和韵律方案的中文歌曲改编系统

    SongRewriter: A Chinese Song Rewriting System with Controllable Content and Rhyme Scheme. (arXiv:2211.15037v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.15037](http://arxiv.org/abs/2211.15037)

    SongRewriter是一种中文歌曲改编系统，可以重新编写现有歌曲的歌词生成与旋律相配的歌词，可帮助没有旋律组成知识的用户，易于控制生成过程。

    

    尽管歌词生成在近年来取得了重大进展，但由于无法生成与相配的旋律进行演唱，因此具有限制性的实际应用。因此，我们提出了一种歌曲改编系统，可通过重新编写现有歌曲的歌词来生成与该旋律相容的歌词。具体而言，我们提出了SongRewriter，一种可控的中文歌词生成和编辑系统，可以帮助没有旋律组成知识的用户。该系统通过随机的多级屏蔽策略进行训练，从而生成适用于生成全新歌词或编辑少量片段的统一模型。为了改善生成过程的可控性，我们进一步加入了关键词提示来控制内容的词汇选择，并提出了新颖的解码约束和元音建模任务，以实现灵活的前后结构和内韵。

    Although lyrics generation has achieved significant progress in recent years, it has limited practical applications because the generated lyrics cannot be performed without composing compatible melodies. In this work, we bridge this practical gap by proposing a song rewriting system which rewrites the lyrics of an existing song such that the generated lyrics are compatible with the rhythm of the existing melody and thus singable. In particular, we propose SongRewriter,a controllable Chinese lyrics generation and editing system which assists users without prior knowledge of melody composition. The system is trained by a randomized multi-level masking strategy which produces a unified model for generating entirely new lyrics or editing a few fragments. To improve the controllabiliy of the generation process, we further incorporate a keyword prompt to control the lexical choices of the content and propose novel decoding constraints and a vowel modeling task to enable flexible end and inte
    
[^143]: 多视角压缩表示的鲁棒性低资源微调研究

    Towards Robust Low-Resource Fine-Tuning with Multi-View Compressed Representations. (arXiv:2211.08794v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.08794](http://arxiv.org/abs/2211.08794)

    本文提出了一种利用多视角压缩表示降低预训练语言模型微调过程中过拟合问题的方法，经过测试在低资源NLP任务中表现良好。

    

    由于参数的巨大数量，预训练语言模型（PLMs）的微调容易在低资源场景中出现过度拟合的问题。本文提出了一种新方法，该方法在PLM的隐藏表示上操作，以减少过拟合。在微调过程中，我们的方法在PLM的隐藏层之间插入随机自编码器，将来自前一层的激活转换为多视角压缩表示，然后将其馈送到上层。微调结束后，自编码器会被移除掉，因此我们的方法在推理过程中不会增加额外的参数或计算成本。我们的方法在一系列序列和标记级别的低资源NLP任务中展现了出色的性能提升。

    Due to the huge amount of parameters, fine-tuning of pretrained language models (PLMs) is prone to overfitting in the low resource scenarios. In this work, we present a novel method that operates on the hidden representations of a PLM to reduce overfitting. During fine-tuning, our method inserts random autoencoders between the hidden layers of a PLM, which transform activations from the previous layers into a multi-view compressed representation before feeding it into the upper layers. The autoencoders are plugged out after fine-tuning, so our method does not add extra parameters or increase computation cost during inference. Our method demonstrates promising performance improvement across a wide range of sequence- and token-level low-resource NLP tasks.
    
[^144]: 多层次多方面注意力的发音评估模型

    Hierarchical Pronunciation Assessment with Multi-Aspect Attention. (arXiv:2211.08102v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.08102](http://arxiv.org/abs/2211.08102)

    本论文提出了一种多层次多方面注意力的发音评估模型，能够更好地捕捉音素、单词和话语的语言层次结构，并在评估准确性、流畅度和完整性方面取得了最先进的结果。

    

    自动发音评估是计算机辅助发音训练系统的主要组成部分。为了提供深入的反馈，对各种粒度（如音素，单词和话语）和各种方面（如准确性，流畅度和完整性）进行发音评分至关重要。然而，现有的多方面多粒度方法同时预测所有粒度级别的所有方面；因此，它们难以捕捉音素，单词和话语的语言层次结构。该限制进一步导致忽略在同一语言单位内的亲密跨方面关系。在本文中，我们提出了一种多层次多方面注意力的发音评估模型（HiPAMA），该模型按层次表示粒度级别，以直接捕获其语言结构，并引入多方面注意力，以反映在同一级别上各方面之间的关联以创建更具内涵的表示。通过在中英文几个语料库上进行评估基准测试，我们表明我们的HiPAMA模型取得了最先进的结果。

    Automatic pronunciation assessment is a major component of a computer-assisted pronunciation training system. To provide in-depth feedback, scoring pronunciation at various levels of granularity such as phoneme, word, and utterance, with diverse aspects such as accuracy, fluency, and completeness, is essential. However, existing multi-aspect multi-granularity methods simultaneously predict all aspects at all granularity levels; therefore, they have difficulty in capturing the linguistic hierarchy of phoneme, word, and utterance. This limitation further leads to neglecting intimate cross-aspect relations at the same linguistic unit. In this paper, we propose a Hierarchical Pronunciation Assessment with Multi-aspect Attention (HiPAMA) model, which hierarchically represents the granularity levels to directly capture their linguistic structures and introduces multi-aspect attention that reflects associations across aspects at the same level to create more connotative representations. By ob
    
[^145]: GreenPLM：几乎不需要成本的跨语言预训练语言模型的跨语言转移

    GreenPLM: Cross-Lingual Transfer of Monolingual Pre-Trained Language Models at Almost No Cost. (arXiv:2211.06993v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.06993](http://arxiv.org/abs/2211.06993)

    GreenPLM是一个节能有效的框架，可利用双语词典实现几乎无成本的跨语言转移预训练语言模型，有效解决了跨语言访问预训练模型和减少大规模模型训练能源消耗的问题，并在18种语言的BERT模型中验证了其效果。

    

    大型预训练模型已经改变了自然语言处理的研究和应用，但高昂的训练成本和有限的数据资源阻碍了所有世界语言的使用者平等分享其中的好处。为了解决这些问题，减少大规模模型训练的能源消耗，本研究提出了一种有效的、节能的框架——GreenPLM。该框架利用双语词典直接“翻译”一个语言的预训练语言模型到另一种语言，几乎不需要额外的费用。我们验证了这种方法在18种语言的BERT模型中的有效性，并显示该框架与其他训练成本高的启发式算法相似甚至更优。此外，针对有限数据的轻量级持续预训练，这个框架在七种被测试的语言中有六种比原来的单语言模型表现更好，效率高达200倍。

    Large pre-trained models have revolutionized natural language processing (NLP) research and applications, but high training costs and limited data resources have prevented their benefits from being shared equally amongst speakers of all the world's languages. To address issues of cross-linguistic access to such models and reduce energy consumption for sustainability during large-scale model training, this study proposes an effective and energy-efficient framework called GreenPLM that uses bilingual lexicons to directly "translate" pre-trained language models of one language into another at almost no additional cost. We validate this approach in 18 languages' BERT models and show that this framework is comparable to, if not better than, other heuristics with high training costs. In addition, given lightweight continued pre-training on limited data where available, this framework outperforms the original monolingual language models in six out of seven tested languages with up to 200x les
    
[^146]: RQUGE：一种基于回答问题评估问题生成的无参考度量方法

    RQUGE: Reference-Free Metric for Evaluating Question Generation by Answering the Question. (arXiv:2211.01482v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.01482](http://arxiv.org/abs/2211.01482)

    RQUGE是一种新的度量标准方法，通过候选问题是否可以回答来评估问题生成质量, 比现有指标更加稳健，可以在不需要人工提供参考问题的情况下使用。

    

    现有的评估自动生成问题质量的指标（如BLEU、ROUGE、BERTScore和BLEURT）将参考和预测问题进行比较，当候选问题和参考问题之间存在相当的词汇重叠或语义相似性时，提供高分。该方法存在两个主要缺点：首先，我们需要昂贵的人工提供参考问题；其次，它惩罚那些可能与参考问题没有高词汇或语义相似性的有效问题。在本文中，我们提出一种新的度量标准RQUGE，基于给定上下文的候选问题的可回答性。该度量标准由一个问答模块和一个跨度评分器模块组成，使用现有文献中的预训练模型，因此可以在不进行进一步训练的情况下使用。我们证明RQUGE与人类判断具有更高的相关性，而不依赖于参考问题。此外，RQUGE显示更加稳健。

    Existing metrics for evaluating the quality of automatically generated questions such as BLEU, ROUGE, BERTScore, and BLEURT compare the reference and predicted questions, providing a high score when there is a considerable lexical overlap or semantic similarity between the candidate and the reference questions. This approach has two major shortcomings. First, we need expensive human-provided reference questions. Second, it penalises valid questions that may not have high lexical or semantic similarity to the reference questions. In this paper, we propose a new metric, RQUGE, based on the answerability of the candidate question given the context. The metric consists of a question-answering and a span scorer modules, using pre-trained models from existing literature, thus it can be used without any further training. We demonstrate that RQUGE has a higher correlation with human judgment without relying on the reference question. Additionally, RQUGE is shown to be more robust to several ad
    
[^147]: 防止神经语言模型的逐字记忆会产生虚假隐私保护感

    Preventing Verbatim Memorization in Language Models Gives a False Sense of Privacy. (arXiv:2210.17546v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.17546](http://arxiv.org/abs/2210.17546)

    防止神经语言模型逐字记忆无法真正保护隐私，本文设计的布隆过滤器虽然防止了所有逐字记忆，但仍然无法防止训练数据泄露，容易被合理修改的“样式转换”提示绕过。

    

    通过研究神经语言模型中数据记忆的现象，本研究帮助我们理解与隐私或版权相关的风险，并有助于评估对策。然而逐字记忆定义过于严格，未能捕捉更为微妙的记忆形式。本文基于布隆过滤器设计并实现了一种有效的防御方法，但该“完美”过滤器并不能防止训练数据泄露。

    Studying data memorization in neural language models helps us understand the risks (e.g., to privacy or copyright) associated with models regurgitating training data, and aids in the evaluation of potential countermeasures. Many prior works -- and some recently deployed defenses -- focus on "verbatim memorization", defined as a model generation that exactly matches a substring from the training set. We argue that verbatim memorization definitions are too restrictive and fail to capture more subtle forms of memorization. Specifically, we design and implement an efficient defense based on Bloom filters that perfectly prevents all verbatim memorization. And yet, we demonstrate that this "perfect" filter does not prevent the leakage of training data. Indeed, it is easily circumvented by plausible and minimally modified "style-transfer" prompts -- and in some cases even the non-modified original prompts -- to extract memorized information. For example, instructing the model to output ALL-CA
    
[^148]: JECC：从互动小说中推导出的常识推理任务

    JECC: Commonsense Reasoning Tasks Derived from Interactive Fictions. (arXiv:2210.15456v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.15456](http://arxiv.org/abs/2210.15456)

    本文提出了一个新的常识推理数据集JECC，基于人类互动小说游戏的演示步骤。与现有基准不同的是，该数据集评估的是功能性的常识知识规则。因此，为了在这些任务上表现良好，模型需要利用这种常识知识来推断行动的结果，而不是仅仅依赖于记忆事实。

    

    常识推理模拟了人类对我们物理世界的推断能力，是构建通用人工智能系统的基石。本文提出了一个新的常识推理数据集，基于人类互动小说游戏的步骤演示，因为人类玩家展示了丰富和多样的常识推理。该新数据集提供了各种推理类型的自然混合，并需要多跳推理。此外，IF游戏构建过程需要比以前的方法更少的人类干预。与现有的基准不同，我们的数据集侧重于评估功能性的常识知识规则，而不是事实知识。因此，为了在我们的任务上获得更高的性能，模型需要有效地利用这种功能性知识来推断行动的结果，而不是仅依靠记忆事实。实验表明，引入的数据集对于先前的机器阅读来说具有挑战性。

    Commonsense reasoning simulates the human ability to make presumptions about our physical world, and it is an essential cornerstone in building general AI systems. We propose a new commonsense reasoning dataset based on human's Interactive Fiction (IF) gameplay walkthroughs as human players demonstrate plentiful and diverse commonsense reasoning. The new dataset provides a natural mixture of various reasoning types and requires multi-hop reasoning. Moreover, the IF game-based construction procedure requires much less human interventions than previous ones. Different from existing benchmarks, our dataset focuses on the assessment of functional commonsense knowledge rules rather than factual knowledge. Hence, in order to achieve higher performance on our tasks, models need to effectively utilize such functional knowledge to infer the outcomes of actions, rather than relying solely on memorizing facts. Experiments show that the introduced dataset is challenging to previous machine reading
    
[^149]: 情感和评价的预测与个体经历有关

    Experiencer-Specific Emotion and Appraisal Prediction. (arXiv:2210.12078v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.12078](http://arxiv.org/abs/2210.12078)

    本研究提出了一种新的任务，将焦点缩小到事件的经历者，将情感（如果有）分配给每个经历者，提出了表示每种情感分类的心理评价变量，从而使得情感分类更为准确。

    

    自然语言处理中的情感分类是为文本（如句子或段落）分配情感。对于像“当他哭泣时，我感到内疚”这样的文本，关注句子级别忽略了每个参与者的立场：作者（“我”）和另一个实体（“他”）实际上可能具有不同的情感状态。不同实体的情感只在情感语义角色标注等任务中部分考虑。我们提出一个相关的任务，将焦点缩小到事件的经历者，将情感（如果有）分配给每个经历者。为此，我们将每种情感分类和评价变量都表示出来，作为解释人们为什么会产生特定情感的心理途径。在事件描述语料库上，我们对经历者感知的情感和评价模型优于经历者无关的基线，表明忽略事件参与者是在语言中传达情感的一种过度简化。

    Emotion classification in NLP assigns emotions to texts, such as sentences or paragraphs. With texts like "I felt guilty when he cried", focusing on the sentence level disregards the standpoint of each participant in the situation: the writer ("I") and the other entity ("he") could in fact have different affective states. The emotions of different entities have been considered only partially in emotion semantic role labeling, a task that relates semantic roles to emotion cue words. Proposing a related task, we narrow the focus on the experiencers of events, and assign an emotion (if any holds) to each of them. To this end, we represent each emotion both categorically and with appraisal variables, as a psychological access to explaining why a person develops a particular emotion. On an event description corpus, our experiencer-aware models of emotions and appraisals outperform the experiencer-agnostic baselines, showing that disregarding event participants is an oversimplification for t
    
[^150]: 基于实体与文本的数据增强对各种命名实体识别任务的应用

    Entity-to-Text based Data Augmentation for various Named Entity Recognition Tasks. (arXiv:2210.10343v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.10343](http://arxiv.org/abs/2210.10343)

    本研究提出了一种新的基于实体与文本的数据增强技术（EnTDA），可为各种扁平、嵌套和不连续 NER 任务生成语义连贯和保留实体的文本，并引入多样性束搜索以增加文本生成过程中的多样性。

    

    数据增强技术被用于缓解各种 NER（扁平、嵌套和不连续的 NER）任务中标注数据稀缺的问题。现有的增强技术要么修改原始文本中的单词从而破坏文本的语义连贯性，要么使用生成模型而忽略携带原始文本中的实体，这阻碍了增广技术在嵌套和不连续的 NER 任务上的使用。本研究提出了一种新的基于实体与文本的数据增强技术（EnTDA），对原始文本中的实体列表进行添加、删除、替换或交换，采用这些增广后的实体列表为各种 NER 任务生成语义连贯和保留实体的文本。此外，我们引入了一个多样性束搜索，以增加文本生成过程中的多样性。在三个任务（扁平、嵌套和不连续 NER 任务）和两个设置（完整数据以及数据稀缺情况下）的十三个 NER 数据集上进行实验。

    Data augmentation techniques have been used to alleviate the problem of scarce labeled data in various NER tasks (flat, nested, and discontinuous NER tasks). Existing augmentation techniques either manipulate the words in the original text that break the semantic coherence of the text, or exploit generative models that ignore preserving entities in the original text, which impedes the use of augmentation techniques on nested and discontinuous NER tasks. In this work, we propose a novel Entity-to-Text based data augmentation technique named EnTDA to add, delete, replace or swap entities in the entity list of the original texts, and adopt these augmented entity lists to generate semantically coherent and entity preserving texts for various NER tasks. Furthermore, we introduce a diversity beam search to increase the diversity during the text generation process. Experiments on thirteen NER datasets across three tasks (flat, nested, and discontinuous NER tasks) and two settings (full data a
    
[^151]: 向总结候选项融合迈进

    Towards Summary Candidates Fusion. (arXiv:2210.08779v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.08779](http://arxiv.org/abs/2210.08779)

    本文提出了一种名为SummaFusion的新范式，通过融合多个总结候选项来产生一个新的抽象总结，以改善第一阶段候选项的限制，并在多个摘要数据集上取得良好的性能，尤其是在少样本设置下。

    

    细调用于抽象总结的序列到序列深度神经模型可以在具有足够人为注释的数据集上取得良好的性能。然而，研究表明它们尚未达到其全部潜力，最佳束搜索输出与完美结果之间存在着很大差距。最近出现了重新排名方法，学习选择更好的摘要候选项。然而，这种方法受第一阶段候选项捕获的摘要质量方面的限制。为了绕过这种限制，我们提出了一种新范式，称为“SummaFusion”，它在第二阶段的抽象总结中融合了多个总结候选项，从而产生了一个新的抽象总结。我们的方法在几个摘要数据集上表现良好，提高了融合总结的ROUGE分数和质量特性。当需要融合的候选项较差时，特别是在少样本设置下，我们取得了新的最高水平。我们将在发表后公开我们的代码和检查点。

    Sequence-to-sequence deep neural models fine-tuned for abstractive summarization can achieve great performance on datasets with enough human annotations. Yet, it has been shown that they have not reached their full potential, with a wide gap between the top beam search output and the oracle beam. Recently, re-ranking methods have been proposed, to learn to select a better summary candidate. However, such methods are limited by the summary quality aspects captured by the first-stage candidates. To bypass this limitation, we propose a new paradigm in second-stage abstractive summarization called SummaFusion that fuses several summary candidates to produce a novel abstractive second-stage summary. Our method works well on several summarization datasets, improving both the ROUGE scores and qualitative properties of fused summaries. It is especially good when the candidates to fuse are worse, such as in the few-shot setup where we set a new state-of-the-art. We will make our code and checkp
    
[^152]: 使用短语表示查询自动生成命名实体识别数据集

    Automatic Creation of Named Entity Recognition Datasets by Querying Phrase Representations. (arXiv:2210.07586v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.07586](http://arxiv.org/abs/2210.07586)

    本篇论文提出了一种名为HighGEN的新框架，通过使用短语嵌入搜索方法生成实体丰富的伪字典，在使用嵌入距离验证过程减少误报的基础上生成高覆盖率的NER数据集。

    

    大多数弱监督的命名实体识别（NER）模型依赖于由专家提供的领域特定词典。然而，在许多没有字典的领域中，这种方法不可行。在最近的一项研究中，使用短语检索模型自动从维基百科中提取实体构建了伪字典，但这些字典的覆盖面往往有限，因为检索器很可能会检索到流行的实体而不是罕见的实体。在本研究中，我们提出了一个新的框架——HighGEN，它使用具有高覆盖率的伪字典生成NER数据集。具体来说，我们使用一种新的搜索方法——短语嵌入搜索来创建富实体字典，该方法鼓励检索器在一个密集的各种实体的空间中搜索。此外，我们使用一种基于实体提及和实体类型之间嵌入距离的新的验证过程，以减少高覆盖率伪标签中的误报噪声。

    Most weakly supervised named entity recognition (NER) models rely on domain-specific dictionaries provided by experts. This approach is infeasible in many domains where dictionaries do not exist. While a phrase retrieval model was used to construct pseudo-dictionaries with entities retrieved from Wikipedia automatically in a recent study, these dictionaries often have limited coverage because the retriever is likely to retrieve popular entities rather than rare ones. In this study, we present a novel framework, HighGEN, that generates NER datasets with high-coverage pseudo-dictionaries. Specifically, we create entity-rich dictionaries with a novel search method, called phrase embedding search, which encourages the retriever to search a space densely populated with various entities. In addition, we use a new verification process based on the embedding distance between candidate entity mentions and entity types to reduce the false-positive noise in weak labels generated by high-coverage 
    
[^153]: 你可以拥有你的数据并且平衡使用：走向平衡高效的多语言模型

    You Can Have Your Data and Balance It Too: Towards Balanced and Efficient Multilingual Models. (arXiv:2210.07135v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.07135](http://arxiv.org/abs/2210.07135)

    使用基于教师-学生知识蒸馏的多语言训练技术，利用适用于每种语言优化的专业语言教师模型和平衡数据，可以在低资源语言的表现方面胜过标准训练方法，并在使用相同数量的数据的情况下提高高资源语言的性能，提高低资源语言在自然语言处理系统中的表示。

    

    多语言模型被广泛用于跨语言的低资源转移，但是低资源语言在预训练数据中存在不充分的问题，这会影响性能。为了解决这个问题，我们提出了一种新的基于教师-学生知识蒸馏的多语言训练技术。在这种情况下，我们利用适用于每种语言优化的专业语言教师模型。我们使用这些教师和平衡（子采样）数据来蒸馏教师的知识到单一的多语言学生模型。我们的方法在低资源语言上优于标准的训练方法，并在使用相同数量的数据的情况下提高了高资源语言的性能。如果广泛应用，我们的方法可以提高低资源语言在自然语言处理系统中的表示。

    Multilingual models have been widely used for cross-lingual transfer to low-resource languages. However, the performance on these languages is hindered by their underrepresentation in the pretraining data. To alleviate this problem, we propose a novel multilingual training technique based on teacher-student knowledge distillation. In this setting, we utilize monolingual teacher models optimized for their language. We use those teachers along with balanced (sub-sampled) data to distill the teachers' knowledge into a single multilingual student. Our method outperforms standard training methods in low-resource languages and retrains performance on high-resource languages while using the same amount of data. If applied widely, our approach can increase the representation of low-resource languages in NLP systems.
    
[^154]: 无关语言的多语种信息检索与对比学习

    Language Agnostic Multilingual Information Retrieval with Contrastive Learning. (arXiv:2210.06633v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2210.06633](http://arxiv.org/abs/2210.06633)

    该论文提出一种使用对比学习的技术，利用平行和非平行语料库来提高多语种信息检索的效果，仅使用英语IR训练数据和一些平行语料库即可在非英语数据上实现显著的检索性能改进。

    

    多语种信息检索具有挑战性，因为在许多语言中获取经过注释的训练数据成本很高。我们提出了一种有效的方法，在只有英语IR训练数据和英语与其他语言之间的一些平行语料库可用时训练多语种IR系统。我们利用平行和非平行语料库来提高预训练多语种语言模型的跨语言传递能力，并设计了一个语义对比损失，以对齐在不同语言中具有相同语义的平行句子的表示，以及一种新的语言对比损失，利用平行句子对从非平行语料库中的句子表示中删除语言特定信息。在使用这些损失对英语IR数据进行训练并在非英语数据上进行零-shot评估时，我们的模型表现出明显的改进，同时需要较少的计算资源。我们还证明了该方法的实用价值。

    Multilingual information retrieval (IR) is challenging since annotated training data is costly to obtain in many languages. We present an effective method to train multilingual IR systems when only English IR training data and some parallel corpora between English and other languages are available. We leverage parallel and non-parallel corpora to improve the pretrained multilingual language models' cross-lingual transfer ability. We design a semantic contrastive loss to align representations of parallel sentences that share the same semantics in different languages, and a new language contrastive loss to leverage parallel sentence pairs to remove language-specific information in sentence representations from non-parallel corpora. When trained on English IR data with these losses and evaluated zero-shot on non-English data, our model demonstrates significant improvement to prior work on retrieval performance, while it requires much less computational effort. We also demonstrate the valu
    
[^155]: 语言模型能够具体化吗？如何实现？

    Can Language Models Be Specific? How?. (arXiv:2210.05159v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.05159](http://arxiv.org/abs/2210.05159)

    本论文提出了一种度量预训练语言模型具体性的方法，并设计了两种基于提示的方法，以改善模型具体性，结果表明，模型的具体性可以得到改善，而无需进行额外的训练。

    

    “他是一个人”、“巴黎位于地球上”。这些语句都是正确的，但没有具体性——因为缺乏明确的内容。在本文中，我们提出了一种度量预训练语言模型（PLMs）的具体性的方法。为了实现这一点，我们引入了一种新方法来建立具体性测试的基准，通过带有提示的掩码标记预测任务来实现。例如，给定“多伦多位于[MASK]中”，我们想测试PLMs是否能更好地填写更具体的答案，例如安大略省而不是加拿大。从我们的评估中，我们发现现有的PLMs只对更具体的答案略微更有偏好。我们确定了影响具体性的潜在因素，并设计了两种基于提示的方法以改善具体性。结果表明，通过所提出的方法，模型的具体性可以得到改善，而无需进行额外的训练。我们希望这项工作能带来语言模型具体性的认识，并鼓励相关研究。

    "He is a person", "Paris is located on the earth". Both statements are correct but meaningless - due to lack of specificity. In this paper, we propose to measure how specific the language of pre-trained language models (PLMs) is. To achieve this, we introduce a novel approach to build a benchmark for specificity testing by forming masked token prediction tasks with prompts. For instance, given "Toronto is located in [MASK].", we want to test whether a more specific answer will be better filled in by PLMs, e.g., Ontario instead of Canada. From our evaluations, we show that existing PLMs have only a slight preference for more specific answers. We identify underlying factors affecting the specificity and design two prompt-based methods to improve the specificity. Results show that the specificity of the models can be improved by the proposed methods without additional training. We hope this work can bring to awareness the notion of specificity of language models and encourage the research
    
[^156]: 用信息论评估自由文本解释的可行性

    REV: Information-Theoretic Evaluation of Free-Text Rationales. (arXiv:2210.04982v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.04982](http://arxiv.org/abs/2210.04982)

    本论文提出了一种名为REV的度量，用于评估自由文本解释中新颖、与标签相关的信息的数量，通过信息论的角度进行研究。实验证明REV在评估解释-标签对方面的有效性，并且与人类直觉一致。

    

    生成自由文本解释是迈向可解释 NLP 的一个有前途的步骤，然而评估这样的解释仍然是一个挑战。现有的度量主要集中在测量解释和给定标签之间的关联性上。我们认为，理想的度量应该集中于解释中提供的新信息，这些信息在输入或标签中都没有提供。我们从信息论的角度使用条件V-信息（Hewitt et al。，2021）研究了这个研究问题。更具体地说，我们提出了一个名为REV（利用条件V-信息评估解释）的度量，用于量化理性中除了输入或标签中已有信息之外的新标签相关信息的数量。在涉及推理任务的四个基准测试中进行的实验证明了REV在评估解释-标签对方面的有效性，与现有的度量相比。我们进一步证明REV与人类直觉一致，而一些现有的度量则不一致。

    Generating free-text rationales is a promising step towards explainable NLP, yet evaluating such rationales remains a challenge. Existing metrics have mostly focused on measuring the association between the rationale and a given label. We argue that an ideal metric should focus on the new information uniquely provided in the rationale that is otherwise not provided in the input or the label. We investigate this research problem from an information-theoretic perspective using conditional V-information (Hewitt et al., 2021). More concretely, we propose a metric called REV (Rationale Evaluation with conditional V-information), to quantify the amount of new, label-relevant information in a rationale beyond the information already available in the input or the label. Experiments across four benchmarks with reasoning tasks, including chain-of-thought, demonstrate the effectiveness of REV in evaluating rationale-label pairs, compared to existing metrics. We further demonstrate REV is consiste
    
[^157]: 一种O(n^2)时间复杂度的基于动态规划算法用于基于跨度的嵌套式命名实体识别

    A dynamic programming algorithm for span-based nested named-entity recognition in O(n^2). (arXiv:2210.04738v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.04738](http://arxiv.org/abs/2210.04738)

    本文提出了一种基于动态规划算法的基于跨度的嵌套式命名实体识别方法，时间复杂度为O(n^2)，其在英语标准基准测试三个标准中表现良好，具有实际应用价值。

    

    基于跨度的嵌套式命名实体识别(NER)使用修改版CYK算法的立方时间复杂度。我们通过在搜索空间上增加一种补充的结构约束，展示了嵌套式NER具有二次时间复杂度，与非嵌套式情况的渐近复杂度相同。所提出的算法覆盖了英语标准基准测试三个标准，且实验结果也可以与之相比。

    Span-based nested named-entity recognition (NER) has a cubic-time complexity using a variant of the CYK algorithm. We show that by adding a supplementary structural constraint on the search space, nested NER has a quadratic-time complexity, that is the same asymptotic complexity than the non-nested case. The proposed algorithm covers a large part of three standard English benchmarks and delivers comparable experimental results.
    
[^158]: 下游数据集意外地成为良好的预训练语料库

    Downstream Datasets Make Surprisingly Good Pretraining Corpora. (arXiv:2209.14389v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.14389](http://arxiv.org/abs/2209.14389)

    本文研究了使用下游数据集进行自我预训练的效果，发现这种方法与使用大型语料库进行预训练的标准方法相媲美，并且在某些任务上更加优秀。同时，这些自我预训练模型还表现出了很好的泛化能力。

    

    对于大多数自然语言处理任务，主要的做法是使用更小的下游数据集对大型预训练变压器模型（例如BERT）进行微调。尽管这种方法取得了成功，但目前尚不清楚这些收益在多大程度上归因于用于预训练的大规模语料库，而不是预训练目标本身。本文介绍了一项关于自我预训练（self-pretraining）的大规模研究，其中相同的（下游）训练数据用于预训练和微调。在针对ELECTRA和RoBERTa模型以及10个不同的下游分类数据集的实验中，我们观察到自我预训练与使用BookWiki语料库进行标准预训练相媲美（尽管使用的数据量仅为后者的$10$倍到$500$倍不等），并且在$7$个和$5$个数据集上分别优于后者。令人惊讶的是，这些针对特定任务的预训练模型在其他任务上表现良好，包括GLUE基准测试。除了分类任务，自我预训练模型还可以用于生成和抽取任务。

    For most natural language processing tasks, the dominant practice is to finetune large pretrained transformer models (e.g., BERT) using smaller downstream datasets. Despite the success of this approach, it remains unclear to what extent these gains are attributable to the massive background corpora employed for pretraining versus to the pretraining objectives themselves. This paper introduces a large-scale study of self-pretraining, where the same (downstream) training data is used for both pretraining and finetuning. In experiments addressing both ELECTRA and RoBERTa models and 10 distinct downstream classification datasets, we observe that self-pretraining rivals standard pretraining on the BookWiki corpus (despite using around $10\times$--$500\times$ less data), outperforming the latter on $7$ and $5$ datasets, respectively. Surprisingly, these task-specific pretrained models often perform well on other tasks, including the GLUE benchmark. Besides classification tasks, self-pretrain
    
[^159]: 少样本情况下的文档级事件论元提取

    Few-Shot Document-Level Event Argument Extraction. (arXiv:2209.02203v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.02203](http://arxiv.org/abs/2209.02203)

    本文介绍了一种在文档级别上捕捉事件论元的少样本情况下的新方法FewDocAE，并且通过N-Way-D-Doc抽样方法重构了语料库。通过将当前文档级神经模型调整到少样本情况下，为跨领域和领域内提供基线结果。

    

    事件论元提取(EAE)在句子级别上得到了很好的研究，但在文档级别上却很少。本文研究如何捕捉文档中跨越句子的事件论元。为了填补此空白，我们介绍了FewDocAE，一种基于现有文档级事件提取数据集的少样本情况下的文档级事件论元提取基准测试。我们首先定义了新问题，并通过新颖的N-Way-D-Doc抽样方法重构了语料库，而不是传统的N-Way-K-Shot策略。然后，我们将当前文档级神经模型调整到少样本情况下，为跨领域和领域内提供基线结果。由于论元提取取决于多个句子的上下文，并且学习过程仅限于很少的例子，我们发现这项新任务非常具有挑战性。

    Event argument extraction (EAE) has been well studied at the sentence level but under-explored at the document level. In this paper, we study to capture event arguments that actually spread across sentences in documents. Prior works usually assume full access to rich document supervision, ignoring the fact that the available argument annotation is usually limited. To fill this gap, we present FewDocAE, a Few-Shot Document-Level Event Argument Extraction benchmark, based on the existing document-level event extraction dataset. We first define the new problem and reconstruct the corpus by a novel N -Way-D-Doc sampling instead of the traditional N -Way-K-Shot strategy. Then we adjust the current document-level neural models into the few-shot setting to provide baseline results under in- and cross-domain settings. Since the argument extraction depends on the context from multiple sentences and the learning process is limited to very few examples, we find this novel task to be very challeng
    
[^160]: 一个新的对齐的简易德语语料库

    A New Aligned Simple German Corpus. (arXiv:2209.01106v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.01106](http://arxiv.org/abs/2209.01106)

    本文介绍了一个新的对齐的简易德语语料库，用于辅助不同人群理解复杂的德语书面语言；该语料库通过自动句子对齐方法使多个文档对齐，且质量优于之前的工作。

    

    "Leichte Sprache"是德语版的简易英语，旨在为不同人群提供复杂的书面语言，以便使这些内容易于理解。本文介绍了一个新的对齐句子的单语语料库，用于简易德语--德语。它包含多个文档对齐来源，我们使用自动句子对齐方法对其进行了对齐。我们基于手动标记的对齐文档的子集来评估我们的对齐质量。根据F1分数测量，我们的句子对齐质量超过了以前的工作。我们在CC BY-SA下发布数据集，在MIT许可下发布附带的代码。

    "Leichte Sprache", the German counterpart to Simple English, is a regulated language aiming to facilitate complex written language that would otherwise stay inaccessible to different groups of people. We present a new sentence-aligned monolingual corpus for Simple German -- German. It contains multiple document-aligned sources which we have aligned using automatic sentence-alignment methods. We evaluate our alignments based on a manually labelled subset of aligned documents. The quality of our sentence alignments, as measured by F1-score, surpasses previous work. We publish the dataset under CC BY-SA and the accompanying code under MIT license.
    
[^161]: 环境声明检测

    Environmental Claim Detection. (arXiv:2209.00507v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.00507](http://arxiv.org/abs/2209.00507)

    为了实现绿色经济，需要可靠、可比较和可验证的环境声明。该论文介绍了环境声明检测任务，并发布了一个专家标注的数据集和训练模型。通过这些模型，我们可以检测环境声明在季度电话会议中的使用情况并发现该使用情况自2015年以来有稳步增长的趋势。

    

    要实现绿色经济，公司所作出的环境声明必须是可靠、可比较和可验证的。为了大规模分析这些声明，需要自动化的方法来首先检测它们。然而，目前还不存在此类数据集或模型。因此，本文介绍了环境声明检测任务。为了配合该任务，我们发布了一个由专家标注的数据集和在该数据集上训练的模型。我们预览了此类模型的一个潜在应用：我们检测季度电话会议中所作出的环境声明，并发现自2015年巴黎协议以来环境声明的数量逐渐增加。

    To transition to a green economy, environmental claims made by companies must be reliable, comparable, and verifiable. To analyze such claims at scale, automated methods are needed to detect them in the first place. However, there exist no datasets or models for this. Thus, this paper introduces the task of environmental claim detection. To accompany the task, we release an expert-annotated dataset and models trained on this dataset. We preview one potential application of such models: We detect environmental claims made in quarterly earning calls and find that the number of environmental claims has steadily increased since the Paris Agreement in 2015.
    
[^162]: 多媒体生成式脚本学习用于任务规划

    Multimedia Generative Script Learning for Task Planning. (arXiv:2208.12306v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2208.12306](http://arxiv.org/abs/2208.12306)

    该论文提出了多媒体生成式脚本学习任务，旨在通过跟踪文本和视觉模态中的历史状态来生成后续步骤，能对未见过的任务具有归纳能力并具有多样性。

    

    目标导向的生成式脚本学习旨在基于目标生成后续步骤，这是帮助机器人执行日常生活中典型活动的重要任务。我们展示了如果历史状态不仅由给人的语言指示捕获，而且还通过相伴的图像提供了附加信息，那么此任务的表现可以改善。因此，我们提出了一个新任务，即多媒体生成式脚本学习，以通过跟踪文本和视觉模态中的历史状态来生成后续步骤，并提供了包含2,338个任务和31,496个步骤及其描述性图像的第一个基准。我们的目标是生成可视状态可跟踪的脚本，对于未见过的任务具有归纳能力，并且其步骤具有多样性。我们提出通过多媒体选择性编码器对视觉状态变化进行编码，利用检索增强解码器传递先前观察到的任务知识，并通过随机抽样和波束搜索解码生成多样的步骤。

    Goal-oriented generative script learning aims to generate subsequent steps based on a goal, which is an essential task to assist robots in performing stereotypical activities of daily life. We show that the performance of this task can be improved if historical states are not just captured by the linguistic instructions given to people, but are augmented with the additional information provided by accompanying images. Therefore, we propose a new task, Multimedia Generative Script Learning, to generate subsequent steps by tracking historical states in both text and vision modalities, as well as presenting the first benchmark containing 2,338 tasks and 31,496 steps with descriptive images. We aim to generate scripts that are visual-state trackable, inductive for unseen tasks, and diverse in their individual steps. We propose to encode visual state changes through a multimedia selective encoder, transferring knowledge from previously observed tasks using a retrieval-augmented decoder, and
    
[^163]: 隐藏结构网络

    Hidden Schema Networks. (arXiv:2207.03777v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2207.03777](http://arxiv.org/abs/2207.03777)

    本文介绍了一种新颖的神经语言模型，通过归纳偏见强制执行明确的关系结构，从而将预训练语言模型的输出表示显式地组成。该模型可以从随机标记序列数据集中发现隐含的真实图，在自然语言数据集中推断出符号网络（模式），直接反映了语言的基础句法结构。

    

    大型预训练语言模型可以推断出强大的表示形式，其中蕴含着丰富的语义和句法内容，尽管是隐含的。本文介绍了一种新颖的神经语言模型，通过归纳偏见强制执行明确的关系结构，从而将预训练语言模型的输出表示显式地组成。具体而言，该模型将句子编码为符号序列（组合表示），这些符号对应于全局潜在图上带偏置的随机游走器访问的节点，并推断其后验分布。我们首先展示了该模型能够从人工生成的随机标记序列数据集中发现隐含的真实图。接下来，我们利用预训练的BERT和GPT-2语言模型作为编码器和解码器，从自然语言数据集中推断出符号网络（模式）。我们的实验证明了：（i）推断出的符号可以解释为编码不同方面的含义，（ii）它们的复合性直接反映了语言的基础句法结构。

    Large, pretrained language models infer powerful representations that encode rich semantic and syntactic content, albeit implicitly. In this work we introduce a novel neural language model that enforces, via inductive biases, explicit relational structures which allow for compositionality onto the output representations of pretrained language models. Specifically, the model encodes sentences into sequences of symbols (composed representations), which correspond to the nodes visited by biased random walkers on a global latent graph, and infers the posterior distribution of the latter. We first demonstrate that the model is able to uncover ground-truth graphs from artificially generated datasets of random token sequences. Next, we leverage pretrained BERT and GPT-2 language models as encoder and decoder, respectively, to infer networks of symbols (schemata) from natural language datasets. Our experiments show that (i) the inferred symbols can be interpreted as encoding different aspects 
    
[^164]: B2T 连接：服务于深度 Transformer 的稳定性和性能

    B2T Connection: Serving Stability and Performance in Deep Transformers. (arXiv:2206.00330v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.00330](http://arxiv.org/abs/2206.00330)

    本研究提出了一种称为 B2T 连接的方法，连接了 Pre-LN 和 Post-LN 层的输出，为深度 Transformer 提供了高稳定性和有效的训练，实验结果表明，在多个基准数据集上取得了最先进结果。

    

    从层归一化（LN）的角度来看，Transformer 的架构可以分为两种类型：Post-LN 和 Pre-LN。最近的 Transformers 倾向于采用 Pre-LN，因为在 Post-LN 中，特别是在深度 Transformers 中（例如有十个或更多层的模型），训练经常不稳定，导致得到无用的模型。然而，与 Pre-LN 相比，在相对较浅的 Transformers（例如有六个或更少的层）中，Post-LN 一直取得了更好的性能。本研究首先从经验和理论上研究了这些不一致的观察结果，并发现了以下发现：1）Post-LN 中的 LN 是导致不稳定训练的梯度消失问题的主要原因，而 Pre-LN 可以避免这种问题；2）Post-LN 往往会在反向传播的高层保留更大的梯度范数，这可能导致有效的训练。利用这些新发现，我们提出了一种可以同时提供高稳定性和有效的 Transformer 训练的方法，称为 B2T Connection，它连接了 Pre-LN 和 Post-LN 层的输出。我们的实验结果表明，B2T Connection 可以显著提高深度 Transformers（有十个或更多层）的性能，实现了在多个基准数据集上的最先进结果。

    From the perspective of the layer normalization (LN) positions, the architectures of Transformers can be categorized into two types: Post-LN and Pre-LN. Recent Transformers tend to be Pre-LN because, in Post-LN with deep Transformers (e.g., those with ten or more layers), the training is often unstable, resulting in useless models. However, Post-LN has consistently achieved better performance than Pre-LN in relatively shallow Transformers (e.g., those with six or fewer layers). This study first investigates the reason for these discrepant observations empirically and theoretically and made the following discoveries: 1, the LN in Post-LN is the main source of the vanishing gradient problem that leads to unstable training, whereas Pre-LN prevents it, and 2, Post-LN tends to preserve larger gradient norms in higher layers during the back-propagation, which may lead to effective training. Exploiting the new findings, we propose a method that can provide both high stability and effective tr
    
[^165]: 理解总结中的事实错误：错误，摘要生成器，数据集和错误检测器

    Understanding Factual Errors in Summarization: Errors, Summarizers, Datasets, Error Detectors. (arXiv:2205.12854v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.12854](http://arxiv.org/abs/2205.12854)

    本文聚合了来自九个现有数据集的事实错误注释，针对底层的摘要生成模型进行分类，并比较了最先进的事实度量标准的性能。结果表明，度量标准的性能因不同的摘要生成模型而有显著差异。

    

    抽象摘要生成模型制造事实错误的倾向已经得到了广泛的研究，包括设计用于检测事实错误的度量标准和注释当前系统输出中的错误。然而，总结系统、度量标准和注释基准的不断发展使得事实评价成为一个移动的目标，并且在度量标准之间进行清晰的比较变得越来越困难。在本文中，我们聚合了来自九个现有数据集的事实错误注释，并根据底层的摘要生成模型进行分类。我们比较了最先进的事实度量标准的性能，包括最近的ChatGPT-based度量标准，在这个分层基准上展示了它们在不同类型的摘要生成模型上的性能差异。关键是，我们的分析显示，最近在事实检测空间的很大改进是针对旧的(前Transformer) 模型的总结，而不是更相关的模型。

    The propensity of abstractive summarization models to make factual errors has been studied extensively, including design of metrics to detect factual errors and annotation of errors in current systems' outputs. However, the ever-evolving nature of summarization systems, metrics, and annotated benchmarks makes factuality evaluation a moving target, and drawing clear comparisons among metrics has become increasingly difficult. In this work, we aggregate factuality error annotations from nine existing datasets and stratify them according to the underlying summarization model. We compare performance of state-of-the-art factuality metrics, including recent ChatGPT-based metrics, on this stratified benchmark and show that their performance varies significantly across different types of summarization models. Critically, our analysis shows that much of the recent improvement in the factuality detection space has been on summaries from older (pre-Transformer) models instead of more relevant rec
    
[^166]: TAGPRIME：一种用于关系结构提取的统一框架

    TAGPRIME: A Unified Framework for Relational Structure Extraction. (arXiv:2205.12585v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.12585](http://arxiv.org/abs/2205.12585)

    本文提出了一种名为TAGPRIME的统一关系结构提取框架，通过将给定条件信息添加到输入文本中，使得输出的上下文表示更适合提取特定条件下的关系。在各种任务和数据集上的表现优于最新的关系提取模型。

    

    自然语言处理中许多任务需要提取给定条件下的关系信息，例如事件参数提取、关系提取和面向任务的语义解析。最近的研究通常针对每个任务分别提出复杂的模型，较少关注这些任务的共性，并缺乏一个统一的框架来处理所有这些任务。本文提出了TAGPRIME，旨在从统一的角度来解决这些关系结构提取问题。TAGPRIME是一种序列标记模型，将给定条件（例如事件触发器）的信息添加到输入文本中。通过在预训练的语言模型中使用自注意机制，这些条件信息使得输出的上下文表示包含更多关于给定条件的信息，从而更适合提取特定条件下的关系。在广泛的实验和分析中表明，TAGPRIME在各种任务和数据集上的表现优于最新的关系提取模型。

    Many tasks in natural language processing require the extraction of relationship information for a given condition, such as event argument extraction, relation extraction, and task-oriented semantic parsing. Recent works usually propose sophisticated models for each task independently and pay less attention to the commonality of these tasks and to have a unified framework for all the tasks. In this work, we propose to take a unified view of all these tasks and introduce TAGPRIME to address relational structure extraction problems. TAGPRIME is a sequence tagging model that appends priming words about the information of the given condition (such as an event trigger) to the input text. With the self-attention mechanism in pre-trained language models, the priming words make the output contextualized representations contain more information about the given condition, and hence become more suitable for extracting specific relationships for the condition. Extensive experiments and analyses on
    
[^167]: GENEVA：“通用性基准测试”事件论元提取，涵盖数百种事件类型和论元角色

    GENEVA: Benchmarking Generalizability for Event Argument Extraction with Hundreds of Event Types and Argument Roles. (arXiv:2205.12505v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.12505](http://arxiv.org/abs/2205.12505)

    本文提出了一个大而全的EAE本体论，105个事件和220个论元角色的包含在内，利用这个本体论创建了一种多样化的通用性基准测试数据集GENEVA，共包含四个测试套件，旨在评估模型处理有限数据的能力。

    

    最近事件论元提取（EAE）的研究关注于提高模型的通用性以适应新的事件类型和领域。然而，标准的评估数据集如ACE和ERE只涵盖不到40种事件类型和25种面向实体的论元角色。数据集的有限多样性和覆盖范围影响了这些数据集对EAE模型通用性的充分评估。本文提出了一个大而全的EAE本体论，在FrameNet的基础上创建了包含115个事件和220个论元角色的本体论，其中许多角色不是实体。我们利用这个本体论进一步引入了GENEVA，一种多样化的通用性基准测试数据集，包括四个测试套件，旨在评估模型处理有限数据的能力。

    Recent works in Event Argument Extraction (EAE) have focused on improving model generalizability to cater to new events and domains. However, standard benchmarking datasets like ACE and ERE cover less than 40 event types and 25 entity-centric argument roles. Limited diversity and coverage hinder these datasets from adequately evaluating the generalizability of EAE models. In this paper, we first contribute by creating a large and diverse EAE ontology. This ontology is created by transforming FrameNet, a comprehensive semantic role labeling (SRL) dataset for EAE, by exploiting the similarity between these two tasks. Then, exhaustive human expert annotations are collected to build the ontology, concluding with 115 events and 220 argument roles, with a significant portion of roles not being entities. We utilize this ontology to further introduce GENEVA, a diverse generalizability benchmarking dataset comprising four test suites, aimed at evaluating models' ability to handle limited data a
    
[^168]: 我们真的取得了很大的进展吗？针对单标签和多标签文本分类的词袋、序列、图和层次结构的比较

    Are We Really Making Much Progress? Bag-of-Words vs. Sequence vs. Graph vs. Hierarchy for Single- and Multi-Label Text Classification. (arXiv:2204.03954v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2204.03954](http://arxiv.org/abs/2204.03954)

    本文比较了用于文本分类的词袋、序列、图形和分层方法，发现基于图形的方法无法超越现代预训练语言模型并且甚至有时表现不如标准机器学习方法，质疑了过去几年中为开发新的图形方法投入的巨大努力以及它们为文本分类带来的承诺。

    

    图神经网络的流行引发了单标签和多标签文本分类的图形方法的复苏。然而，这些基于图形的方法是否比标准机器学习方法和现代预训练语言模型更有益仍不清楚。本文比较了用于文本分类的丰富的词袋、基于序列、基于图形和分层方法。我们聚合了来自文献的结果，在5个单标签和7个多标签数据集上运行了我们自己的实验。我们的研究结果明确表明，在单标签和多标签分类任务中，基于图形的方法无法超越精调的语言模型，有时甚至表现不如词袋上的标准机器学习方法，这质疑了过去几年中为开发新的图形方法投入的巨大努力以及它们为文本分类带来的承诺。

    The popularity of graph neural networks has triggered a resurgence of graph-based methods for single-label and multi-label text classification. However, it is unclear whether these graph-based methods are beneficial compared to standard machine learning methods and modern pretrained language models. We compare a rich selection of bag-of-words, sequence-based, graph-based, and hierarchical methods for text classification. We aggregate results from the literature over 5 single-label and 7 multi-label datasets and run our own experiments. Our findings unambiguously demonstrate that for single-label and multi-label classification tasks, the graph-based methods fail to outperform fine-tuned language models and sometimes even perform worse than standard machine learning methods like multilayer perceptron (MLP) on a bag-of-words. This questions the enormous amount of effort put into the development of new graph-based methods in the last years and the promises they make for text classification
    
[^169]: SummaReranker：一种多任务专家混合二次排序框架，用于抽象摘要

    SummaReranker: A Multi-Task Mixture-of-Experts Re-ranking Framework for Abstractive Summarization. (arXiv:2203.06569v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.06569](http://arxiv.org/abs/2203.06569)

    SummaReranker是一种专家混合的二次排序框架，可用于抽象摘要。它能够直接在一组摘要候选上进行重新排序，从而优化基本模型的ROUGE分数，实现了新的SOTA。

    

    最近，序列到序列的神经网络在抽象摘要方面取得了巨大成功，尤其是通过在下游数据集上微调大型预训练语言模型。这些模型通常使用波束搜索进行解码以生成唯一的摘要。然而，搜索空间非常大，并且由于曝光偏差，这种解码不是最优的。在本文中，我们展示了可以直接训练第二阶段模型在一组摘要候选上执行重新排序。我们的专家混合框架SummaReranker学习选择更好的候选者，并持续提高基本模型的性能。以基本PEGASUS为例，我们在CNN-DailyMail（47.16 ROUGE-1）上提高了5.44％，在XSum（48.12 ROUGE-1）上提高了1.31％，在Reddit TIFU（29.83 ROUGE-1）上提高了9.34％，达到了新的最先进水平。我们的代码和检查点将在https://github.com/ntunlp/SummaReranker上提供。

    Sequence-to-sequence neural networks have recently achieved great success in abstractive summarization, especially through fine-tuning large pre-trained language models on the downstream dataset. These models are typically decoded with beam search to generate a unique summary. However, the search space is very large, and with the exposure bias, such decoding is not optimal. In this paper, we show that it is possible to directly train a second-stage model performing re-ranking on a set of summary candidates. Our mixture-of-experts SummaReranker learns to select a better candidate and consistently improves the performance of the base model. With a base PEGASUS, we push ROUGE scores by 5.44% on CNN-DailyMail (47.16 ROUGE-1), 1.31% on XSum (48.12 ROUGE-1) and 9.34% on Reddit TIFU (29.83 ROUGE-1), reaching a new state-of-the-art. Our code and checkpoints will be available at https://github.com/ntunlp/SummaReranker.
    
[^170]: CrossSum：超越英语中心的1500多种语言对的跨语言摘要。

    CrossSum: Beyond English-Centric Cross-Lingual Summarization for 1,500+ Language Pairs. (arXiv:2112.08804v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2112.08804](http://arxiv.org/abs/2112.08804)

    本文介绍了CrossSum - 一个1500多种语言对中的跨语言摘要数据集，以及一种多阶段数据采样算法和一种新的评估度量LaSE。该模型在摘要生成方面的表现优于基线模型，是目前已知最大的跨语言摘要数据集。

    

    我们介绍了CrossSum，这是一个包含1500多种语言对中168万篇文章-摘要样本的大规模跨语言摘要数据集。我们通过从多语言抽象概括数据集中进行跨语言检索对用不同语言编写的平行文章进行了对齐，并进行了受控人工评估以验证其质量。我们提出了一种多阶段数据采样算法，以有效训练能够摘要任何目标语言文章的跨语言摘要模型。我们还介绍了LaSE，这是一种基于嵌入的度量，用于自动评估模型生成的摘要。LaSE与ROUGE强相关，并且，与ROUGE不同，在目标语言没有参考文献的情况下也可以可靠地测量。ROUGE和LaSE的表现表明，我们的拟议模型始终优于基线模型。据我们所知，CrossSum是最大的跨语言摘要数据集，也是第一个。

    We present CrossSum, a large-scale cross-lingual summarization dataset comprising 1.68 million article-summary samples in 1,500+ language pairs. We create CrossSum by aligning parallel articles written in different languages via cross-lingual retrieval from a multilingual abstractive summarization dataset and perform a controlled human evaluation to validate its quality. We propose a multistage data sampling algorithm to effectively train a cross-lingual summarization model capable of summarizing an article in any target language. We also introduce LaSE, an embedding-based metric for automatically evaluating model-generated summaries. LaSE is strongly correlated with ROUGE and, unlike ROUGE, can be reliably measured even in the absence of references in the target language. Performance on ROUGE and LaSE indicate that our proposed model consistently outperforms baseline models. To the best of our knowledge, CrossSum is the largest cross-lingual summarization dataset and the first ever th
    
[^171]: 基于事实的逻辑推理与机器阅读理解

    Fact-driven Logical Reasoning for Machine Reading Comprehension. (arXiv:2105.10334v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2105.10334](http://arxiv.org/abs/2105.10334)

    本文提出一种基于事实的逻辑推理方法，采用分层方式涵盖常识和临时知识线索，通过构建超图实现句子级别和实体级别的交互，在逻辑推理基准测试和大规模阅读理解中表现出优越性。

    

    近年来，越来越多的人开始关注机器具备推理能力，这需要准确清晰地提供线索。在现有的研究中，线索通常被建模为实体感知知识。然而，这些实体感知线索主要集中于常识，对于需要了解临时事实或事件的任务，特别是在阅读理解的逻辑推理中，这些线索是不足够的。为了解决这一挑战，我们有动力以分层方式涵盖常识和临时知识线索。具体而言，我们提出了一种知识单元的通用形式，通过提取句子的骨干构成部分，如主语-谓语-宾语形成的“事实”。然后，在事实单元之上构建一个超图，允许句子级别（事实组之间的关系）和实体级别交互（事实中的概念或行动）的互动。在逻辑推理基准测试和大规模阅读理解中，实验结果证明了我们的方法的优越性。

    Recent years have witnessed an increasing interest in training machines with reasoning ability, which deeply relies on accurately and clearly presented clue forms. The clues are usually modeled as entity-aware knowledge in existing studies. However, those entity-aware clues are primarily focused on commonsense, making them insufficient for tasks that require knowledge of temporary facts or events, particularly in logical reasoning for reading comprehension. To address this challenge, we are motivated to cover both commonsense and temporary knowledge clues hierarchically. Specifically, we propose a general formalism of knowledge units by extracting backbone constituents of the sentence, such as the subject-verb-object formed ``facts''. We then construct a supergraph on top of the fact units, allowing for the benefit of sentence-level (relations among fact groups) and entity-level interactions (concepts or actions inside a fact). Experimental results on logical reasoning benchmarks and d
    
[^172]: 多任务注意力残差网络用于论述挖掘

    Multi-Task Attentive Residual Networks for Argument Mining. (arXiv:2102.12227v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2102.12227](http://arxiv.org/abs/2102.12227)

    本文提出了一种多任务注意力残差网络架构，通过利用集成方法、注意力机制和多任务学习，无需假设文档或论据结构，成功应用于多个论述挖掘任务中，成为了一种既通用又高性能的架构。

    

    本文探讨了多任务注意力残差网络在多个论述挖掘任务中的应用。我们提出了一种残差架构，利用了注意力、多任务学习，并使用集成方法，不对文档或论据结构做任何假设。我们在五个不同的用户生成评论、科学出版物和劝说性论文语料库上进行了广泛的实验评估。我们的结果表明，我们的方法是针对具有更高计算印记或特定于语料库设计的最先进架构的强有力的竞争对手，代表了通用性、性能精度和减少模型大小之间的有趣折衷。

    We explore the use of residual networks and neural attention for multiple argument mining tasks. We propose a residual architecture that exploits attention, multi-task learning, and makes use of ensemble, without any assumption on document or argument structure. We present an extensive experimental evaluation on five different corpora of user-generated comments, scientific publications, and persuasive essays. Our results show that our approach is a strong competitor against state-of-the-art architectures with a higher computational footprint or corpus-specific design, representing an interesting compromise between generality, performance accuracy and reduced model size.
    

