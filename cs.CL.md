# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Characterizing Political Bias in Automatic Summaries: A Case Study of Trump and Biden.](http://arxiv.org/abs/2305.02321) | 本文研究了自动生成新闻文章摘要中的政治偏见。研究发现，与特朗普相比，更多的美国政府集体机构（即政府）与拜登相关联。这些发现为未来的摘要偏见研究提供了一个框架。 |
| [^2] | [Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings.](http://arxiv.org/abs/2305.02317) | VCoT是一种使用思维链激励和视觉语言组合递归地弥合时序数据中逻辑差距的新颖方法，其使用视觉引导生成合成的多模态填充以添加一致且新颖的信息，并减少需要时序推理的逻辑差距。 |
| [^3] | [Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes.](http://arxiv.org/abs/2305.02301) | 本研究提出了Distilling Step-by-Step机制，通过提取LLM基础信息为小型模型提供额外的监督训练，从而使它们胜过更大的LLM模型，并需更少的训练数据。 |
| [^4] | [Evaluating the Efficacy of Length-Controllable Machine Translation.](http://arxiv.org/abs/2305.02300) | 本文评估了长度可控机器翻译的自动评估指标，发现BLEURT和COMET是最适合作为其评估指标的。 |
| [^5] | [M2-CTTS: End-to-End Multi-scale Multi-modal Conversational Text-to-Speech Synthesis.](http://arxiv.org/abs/2305.02269) | M2-CTTS是一个端到端的多尺度多模态的会话文本到语音合成系统，相比于其他系统，它采用了粗粒度和细粒度的建模来全面利用历史对话，同时还考虑了声学特征，能够有效提高会话式TTS性能。 |
| [^6] | [A Neural Divide-and-Conquer Reasoning Framework for Image Retrieval from Linguistically Complex Text.](http://arxiv.org/abs/2305.02265) | 提出了一种神经分治推理框架NDCR，通过将语言复杂文本视为由多个简单命题句组成的复合命题文本，将图像检索问题分为三个步骤：分治、征服和组合。该框架在解决语言复杂文本问题时具有较好的性能。 |
| [^7] | [End-to-end Training and Decoding for Pivot-based Cascaded Translation Model.](http://arxiv.org/abs/2305.02261) | 本文提出了一种端到端训练方法，并配置了改进的解码算法，即基于中转的级联翻译模型，使用加权中转语言嵌入输入模型，利用波束搜索缓解标记和概率分布之间的不一致性。实验证明，该方法提高了翻译的质量。 |
| [^8] | [The Benefits of Label-Description Training for Zero-Shot Text Classification.](http://arxiv.org/abs/2305.02239) | 本文提出了标注描述训练的方法，在零样本分类中可以显著提高准确率，并能更鲁棒地处理分类任务。 |
| [^9] | [AttenWalker: Unsupervised Long-Document Question Answering via Attention-based Graph Walking.](http://arxiv.org/abs/2305.02235) | AttenWalker是一种基于Attention的图遍历方法，用于实现无监督长文档问答。它由三个模块组成：span collector、span linker和answer aggregator。这些模块结合使用来选择有信息量的候选span，将这些span串联起来形成完整答案，并生成最终答案。在CoQA数据集上获得了良好的实验结果。 |
| [^10] | [Clinical Note Generation from Doctor-Patient Conversations using Large Language Models: Insights from MEDIQA-Chat.](http://arxiv.org/abs/2305.02220) | 本文介绍了使用大型语言模型从医生-患者对话中自动生成临床笔记的研究，采用少样本上下文学习法所生成笔记表现优秀，且可与人工编写的笔记媲美。 |
| [^11] | [Exploring Linguistic Properties of Monolingual BERTs with Typological Classification among Languages.](http://arxiv.org/abs/2305.02215) | 本文研究使用语言分类方法探究单语BERT的语言属性，核心发现为BERT正在复制传统的语言模型。 |
| [^12] | [Towards Being Parameter-Efficient: A Stratified Sparsely Activated Transformer with Dynamic Capacity.](http://arxiv.org/abs/2305.02176) | 本篇论文提出了一种新的分层稀疏激活Transformer模型，可以动态分配不同令牌的能力，解决了传统Mixture-of-experts模型参数低效的问题，实验表明该模型在多语言机器翻译任务中取得了较好效果。 |
| [^13] | [A Statistical Exploration of Text Partition Into Constituents: The Case of the Priestly Source in the Books of Genesis and Exodus.](http://arxiv.org/abs/2305.02170) | 为了验证文本分组的假设，我们提出了一个统计文本探索的流程，并在圣经的前两卷书中应用此流程，成功地识别并探索了司祭派别和非司祭派别之间的统计明显的文体差异。 |
| [^14] | [Explaining Language Models' Predictions with High-Impact Concepts.](http://arxiv.org/abs/2305.02160) | 本论文提供了一个完整的框架，将基于概念的可解释性方法推广到 NLP 领域。通过后期可解释性方法，从预训练模型的隐藏层激活中提取预测高级特征（概念），并优化具有高影响力的特征存在，使其能够准确地解释模型的行为。 |
| [^15] | [Zero-Shot Listwise Document Reranking with a Large Language Model.](http://arxiv.org/abs/2305.02156) | 本文提出了一种基于大型语言模型的列表式重新排序器，可以在没有特定任务训练数据的情况下实现强大的重新排序效果，并在实验中取得了令人满意的结果。 |
| [^16] | [Identifying the Correlation Between Language Distance and Cross-Lingual Transfer in a Multilingual Representation Space.](http://arxiv.org/abs/2305.02151) | 探索了语言特征对多语言表示空间中的跨语言传递性能的影响，初步提供了方法以增强对语言上相距较远的语言的传递能力。 |
| [^17] | [A Curriculum View of Robust Loss Functions.](http://arxiv.org/abs/2305.02139) | 本文提出了鲁棒损失函数的课程视角，以更直观的方式分析训练动态，指出欠拟合的原因是由于平均样本权重的降低而引起的，对噪声鲁棒性的优化则是通过对干净样本赋予更大的样本权重来实现的。进一步的研究表明，通过简单的课程修正可以提高鲁棒损失函数的性能，而训练进度对于鲁棒性也有着非常重要的影响。 |
| [^18] | [Pay More Attention to Relation Exploration for Knowledge Base Question Answering.](http://arxiv.org/abs/2305.02118) | 该研究提出了一个新框架RE-KBQA，利用知识库中的关系增强实体表示，并引入额外监督。在三个方面探索关系指导，包括区分相似实体、探索额外监督以及进行后处理的基于关系指导的重排算法。该方法在两个基准数据集上验证有效性。 |
| [^19] | [GPT-RE: In-context Learning for Relation Extraction using Large Language Models.](http://arxiv.org/abs/2305.02105) | 本文提出了GPT-RE，通过特定于任务的实体表示和使用金标签诱导的推理逻辑丰富演示，成功解决了大型语言模型在关系抽取方面的低相关性和倾向于错误分类的问题，成果在多个数据集上均超过现有基准，其中在三个数据集中的结果达到了最新研究成果。 |
| [^20] | [Background Knowledge Grounding for Readable, Relevant, and Factual Biomedical Lay Summaries.](http://arxiv.org/abs/2305.02104) | 使用背景知识源文件可以提高普及摘要的相关性和可读性，但不能提高其事实准确性。 |
| [^21] | [What makes a good pause? Investigating the turn-holding effects of fillers.](http://arxiv.org/abs/2305.02101) | 本文基于Voice Activity Projection模型，探究填充停顿对持续发言的影响，结果表明填充停顿确实具有持续发言的效果，但可能不像人们预期的那么强烈。 |
| [^22] | [Response-conditioned Turn-taking Prediction.](http://arxiv.org/abs/2305.02036) | 本文提出的响应条件模型结合了对话历史和下一个发言者想要表达的内容来预测一轮对话何时结束，并在Stanford对话数据集中表现出了最佳的预测和响应结果。 |
| [^23] | [A Systematic Study of Knowledge Distillation for Natural Language Generation with Pseudo-Target Training.](http://arxiv.org/abs/2305.02031) | 本文研究如何压缩自然语言生成模型以适应实际应用需求，通过使用知识蒸馏和伪目标训练技术针对特定的自然语言生成任务和数据集进行优化，并取得了显著效果。 |
| [^24] | [Natural language processing on customer note data.](http://arxiv.org/abs/2305.02029) | 本文将情感分析、主题建模和关键词提取应用于客户的B2B数据集，展示了能够自动提取出正确情感信息并分成不同的主题。 |
| [^25] | [Analysing the Impact of Audio Quality on the Use of Naturalistic Long-Form Recordings for Infant-Directed Speech Research.](http://arxiv.org/abs/2305.01965) | 分析音频质量对自然录音中婴儿语音研究的影响尚不清楚。本文探讨了音频质量对婴儿导向语音和成人导向语音分析的影响。 |
| [^26] | [NorQuAD: Norwegian Question Answering Dataset.](http://arxiv.org/abs/2305.01957) | NorQuAD是用于机器阅读理解的第一个挪威问答数据集，包含4,752对手工创建的问答对，并基于该数据集对多种语言模型进行了基准测试，并将其与人类表现进行了比较。 |
| [^27] | [SeqAug: Sequential Feature Resampling as a modality agnostic augmentation method.](http://arxiv.org/abs/2305.01954) | SeqAug是一种模态不可知的数据增强方法，可以成功应用于单模态或多模态，通过从基础特征分布中重新采样来增强序列，并且与循环和Transformer架构兼容，取得了与最先进方法相当的结果。 |
| [^28] | [TempoSum: Evaluating the Temporal Generalization of Abstractive Summarization.](http://arxiv.org/abs/2305.01951) | 本篇论文提出了 TempoSum 抽象摘要的时间泛化能力基准，通过广泛的人类评估证明了摘要模型中存储的参数化知识对未来数据上生成的摘要有显著影响。 |
| [^29] | [Doc2SoarGraph: Discrete Reasoning over Visually-Rich Table-Text Documents with Semantic-Oriented Hierarchical Graphs.](http://arxiv.org/abs/2305.01938) | 本文提出了 Doc2SoarGraph 框架，利用语义导向分层图结构中元素之间的差异和相关性，在富含视觉表格文本的TAT-DQA问题下实现了离散推理，表现出了最佳的实验结果。 |
| [^30] | [Can Large Language Models Be an Alternative to Human Evaluations?.](http://arxiv.org/abs/2305.01937) | 本文研究了大型语言模型是否能够替代人类评估。实验结果表明在两个NLP任务上，使用LLM评估和人类评估得到的结果是一致的。 |
| [^31] | [Generative Meta-Learning for Zero-Shot Relation Triplet Extraction.](http://arxiv.org/abs/2305.01920) | 该论文提出了一种生成式元学习框架，通过任务感知的生成式模型和三种针对典型元学习范畴的方法，提高了零样本关系三元组抽取任务的泛化能力并达到了最佳表现。 |
| [^32] | [Improving Contrastive Learning of Sentence Embeddings from AI Feedback.](http://arxiv.org/abs/2305.01918) | 本文提出了一种利用人工智能反馈改进句子嵌入对比学习方法的方式，可以提高对比学习样本对的质量，并结合人类反馈来提供更好的监督信号。 |
| [^33] | [Causal Interventions-based Few-Shot Named Entity Recognition.](http://arxiv.org/abs/2305.01914) | 本文提出了一种基于因果干预的小样本命名实体识别方法，该方法使用增量学习来介入原型以避免灾难性忘却问题，实现了在不同基准测试上新的最优结果。 |
| [^34] | [Few-shot Event Detection: An Empirical Study and a Unified View.](http://arxiv.org/abs/2305.01901) | 本文从两个实用的设置出发，分析比较了十种代表性的小样本事件检测方法，归纳总结出了原型方法的性能优越性，并在此基础上提出了一种简单且有效的方法。 |
| [^35] | [SCOTT: Self-Consistent Chain-of-Thought Distillation.](http://arxiv.org/abs/2305.01879) | 本研究提出了一种忠实的知识蒸馏方法，从比教师模型大数倍的模型中学习一个小的、自我一致的思路串模型。实验结果表明，该方法有助于证明决策并提高性能，特别是在较小的语言模型中。 |
| [^36] | [Causality-aware Concept Extraction based on Knowledge-guided Prompting.](http://arxiv.org/abs/2305.01876) | 该论文提出了一种基于因果感知的知识引导提示方法，将其作为干预器装备到基于预训练语言模型的句子提取器中，以缓解概念偏差。在代表性的多语言KG数据集上进行广泛实验，获得了最先进的结果。 |
| [^37] | [GPTutor: a ChatGPT-powered programming tool for code explanation.](http://arxiv.org/abs/2305.01863) | 本文介绍了一种名为GPTutor的ChatGPT动力编程工具，它是一个使用ChatGPT API的Visual Studio Code扩展，通过设计提示词，可以对所选代码进行精简、准确的解释。 |
| [^38] | [Post-Abstention: Towards Reliably Re-Attempting the Abstained Instances in QA.](http://arxiv.org/abs/2305.01812) | 本文研究再次尝试放弃实例的后期处理方法，以提高系统的覆盖范围而不显着牺牲准确性。 |
| [^39] | [KEPLET: Knowledge-Enhanced Pretrained Language Model with Topic Entity Awareness.](http://arxiv.org/abs/2305.01810) | 本文提出了一种知识增强预训练语言模型，即KEPLET，在预训练语料中加入主题实体感知，从而改善了实体交互和词语语义表示。 |
| [^40] | [Multimodal Procedural Planning via Dual Text-Image Prompting.](http://arxiv.org/abs/2305.01795) | 该论文提出了一个名为MPP的任务，用于使用文本和图像生成计划，帮助人类完成任务。为了解决跨模态的计划的可靠性问题，该论文提出了一种双模态提示方法TIP，它利用了大型语言模型和文本到图像生成模型的能力。 |
| [^41] | [Vision Meets Definitions: Unsupervised Visual Word Sense Disambiguation Incorporating Gloss Information.](http://arxiv.org/abs/2305.01788) | 本文提出了一种无监督的视觉词义消歧方法，通过引入外部词汇知识库的词义信息来解决原来图像-文本匹配模型中的多义词问题。采用贝叶斯推断来加入词义定义，并通过与上下文相关的 GPT-3 定义生成方法，成功解决了词典外问题。 |
| [^42] | [SLTUNET: A Simple Unified Model for Sign Language Translation.](http://arxiv.org/abs/2305.01778) | SLTUNET是一种简单的统一模型，为多个手语翻译任务提供支持。通过联合建模不同的任务，SLTUNET可以探索跨任务相关性以缩小模态差距，并借助外部数据进行优化，实现了竞争甚至领先的性能。 |
| [^43] | [Psychologically-Inspired Causal Prompts.](http://arxiv.org/abs/2305.01764) | 本文提出了三个因果提示语，涵盖了情感分类任务中人类的心理过程。这些提示语可以用来产生更准确和可解释的模型预测。 |
| [^44] | [Evaluation of Speaker Anonymization on Emotional Speech.](http://arxiv.org/abs/2305.01759) | 本文研究了VoicePrivacy 2020 Challenge中演讲者匿名化对情感语音的影响，并发现其未能有效地保护演讲者的隐私。 |
| [^45] | [Few-shot In-context Learning for Knowledge Base Question Answering.](http://arxiv.org/abs/2305.01750) | 该论文提出了KB-BINDER框架，通过少量的上下文演示实现了在多个知识库问答数据集上的背景学习，大大提高了KBQA问题的可解性。 |
| [^46] | [DiffuSum: Generation Enhanced Extractive Summarization with Diffusion.](http://arxiv.org/abs/2305.01735) | 本文提出了一种新的基于扩散模型的摘要提取方法DiffuSum，并且在多个数据集上实现了最先进的抽取结果。 |
| [^47] | [Stance Detection With Supervised, Zero-Shot, and Few-Shot Applications.](http://arxiv.org/abs/2305.01723) | 本文提出了三种不同的方法进行立场检测：有监督分类、零样本分类与NLI分类器和上下文学习。零样本和少样本语言分类器可以替代人工标签者，并演示了如何运用它们来执行立场检测。 |
| [^48] | [Learning Disentangled Semantic Spaces of Explanations via Invertible Neural Networks.](http://arxiv.org/abs/2305.01713) | 本文介绍了一种使用可逆神经网络将BERT-GPT2自动编码器的隐藏空间转换为更可分离的语义空间的方法，实验结果表明此方法可以改进模型的可解释性和可控性，并取得了比最先进模型更好的性能表现。 |
| [^49] | [Don't Stop Pretraining? Make Prompt-based Fine-tuning Powerful Learner.](http://arxiv.org/abs/2305.01711) | 本文研究了持续预训练对于微调性能的影响，发现传统的持续预训练不能保证一致的提高性能，甚至会对一些任务产生负面影响。针对这些问题，作者提出了基于提示的持续预训练，旨在通过无监督的预训练向LM展示任务相关文本和提示模板，从而提高基于提示的微调表现。 |
| [^50] | [Stars Are All You Need: A Distantly Supervised Pyramid Network for Document-Level End-to-End Sentiment Analysis.](http://arxiv.org/abs/2305.01710) | 本文提出了一种文档级端到端情感分析方法，通过星级评分标签，实现方面检测、情感分析和评分预测，具有良好的性能和可解释性。 |
| [^51] | [Distill or Annotate? Cost-Efficient Fine-Tuning of Compact Models.](http://arxiv.org/abs/2305.01645) | 本文研究了压缩模型的高效微调方法，实验结果表明，与手动标注更多的微调数据以直接训练压缩模型相比，从T5-XXL蒸馏到T5-Small几乎总是更具成本效益。 |
| [^52] | [How to Unleash the Power of Large Language Models for Few-shot Relation Extraction?.](http://arxiv.org/abs/2305.01555) | 本文通过使用GPT-3.5模型在少样本关系抽取中，实现在四个不同数据集上的新的最优性能，并提出了与任务相关的指导说明和约束模式下的数据生成方法。 |
| [^53] | [Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models.](http://arxiv.org/abs/2305.01219) | 本研究提出一种新颖有效的“ProAttack”方法来执行干净标签的后门攻击，使用的是提示本身作为触发器。该方法不需要外部触发器，并确保毒瘤数据的标注正确，提高了后门攻击的隐蔽性，相比于现有的后门攻击方法有显著提升。 |
| [^54] | [CryCeleb: A Speaker Verification Dataset Based on Infant Cry Sounds.](http://arxiv.org/abs/2305.00969) | CryCeleb是一个基于婴儿哭声的说话人认证数据集，包括超过6小时的手动分割哭声，可用于研究婴儿哭声分析。 |
| [^55] | [Search-in-the-Chain: Towards the Accurate, Credible and Traceable Content Generation for Complex Knowledge-intensive Tasks.](http://arxiv.org/abs/2304.14732) | 提出了一个名为SearChain的新型框架，以改进LLM生成的内容的准确性、可信度和可追溯性，从而提高复杂知识密集型任务的表现。SearChain通过深度集成LLM和信息检索（IR）实现，其思路是通过构造查询链，将多跳问题进行分解，最终指导LLM生成正确的答案。 |
| [^56] | [ImpressionGPT: An Iterative Optimizing Framework for Radiology Report Summarization with ChatGPT.](http://arxiv.org/abs/2304.08448) | ImpressionGPT是一个利用LLMs构建动态上下文的迭代优化框架，用于放射学报告摘要生成。相对于其他方法，ImpressionGPT在具有较好泛化性能的同时，成功提高了放射学报告摘要的生成能力。 |
| [^57] | [Multimodal Image-Text Matching Improves Retrieval-based Chest X-Ray Report Generation.](http://arxiv.org/abs/2303.17579) | 本研究提出了一种基于检索的放射性医学报告生成模块 X-REM，它使用图像文本匹配分数来衡量胸部 X 光图像和放射学报告之间的相似度，以进行报告检索，其在多个先前的放射学报告生成模块中表现优异，可有效提高放射学报告的自动生成精度。 |
| [^58] | [Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning.](http://arxiv.org/abs/2303.10475) | 传统的自然语言处理机器学习需要大规模的任务特定示例，但这不适用于任务可能过于复杂或成本过高以进行注释的场景。因此，社区对于自然语言处理中新的监督寻求范式--从任务指令学习--越来越感兴趣。 |
| [^59] | [Exploring Social Media for Early Detection of Depression in COVID-19 Patients.](http://arxiv.org/abs/2302.12044) | 本论文通过社交媒体分析探讨COVID-19感染和抑郁症之间的关系，并提出了一个深度神经网络用于早期预测抑郁症风险。 |
| [^60] | [Unsupervised Task Graph Generation from Instructional Video Transcripts.](http://arxiv.org/abs/2302.09173) | 本文提出了一种无监督的任务图生成方法，通过结合支持指导的语言模型的推理能力和聚类、排序组件，从执行真实世界活动的教学视频文本记录中生成任务图。实验结果表明该方法在ProceL和CrossTask数据集上比监督学习方法生成的任务图更加准确。 |
| [^61] | [Product Question Answering in E-Commerce: A Survey.](http://arxiv.org/abs/2302.08092) | 电商PQA的研究面临着问题多、数据难收集、答案不确定等特殊挑战。本文系统地综述了PQA研究的现状与未来方向。 |
| [^62] | [DocILE Benchmark for Document Information Localization and Extraction.](http://arxiv.org/abs/2302.05658) | 本文介绍了DocILE基准数据集，该数据集包含大量商务文件，可用于关键信息定位和提取以及行项目识别任务。该数据集具有55个类别的注释，超过以往发布的数据集，同时包括众多不同布局和未标记的文档，为该领域提供了有力的研究工具。 |
| [^63] | [APAM: Adaptive Pre-training and Adaptive Meta Learning in Language Model for Noisy Labels and Long-tailed Learning.](http://arxiv.org/abs/2302.03488) | 本文提出了APAM框架，通过整合自适应预训练和元学习的方法，成功解决了长尾和噪声标签带来的挑战，实验证明该方法的效果优于现有最新方法。 |
| [^64] | [Character-Aware Models Improve Visual Text Rendering.](http://arxiv.org/abs/2212.10562) | 本研究证实，以字体为基础的字符级文本编码模型可以显著提高图像生成的视觉文本排版质量，达到更高的拼写准确率和更好的效果。 |
| [^65] | [Self-Adaptive In-Context Learning: An Information Compression Perspective for In-Context Example Selection and Ordering.](http://arxiv.org/abs/2212.10375) | 这篇论文提出了自适应上下文学习的原则，通过引入自适应机制帮助每个样本找到正确的上下文示例排列，从而最大化表现。通过广泛的评估，在8个不同的NLP数据集上，自适应ICL方法相对于常规设置提高了40%的相对改进。 |
| [^66] | [SeqDiffuSeq: Text Diffusion Model with Encoder-Decoder Transformers for Sequence-to-Sequence Generation.](http://arxiv.org/abs/2212.10325) | 本文提出了一种名为SeqDiffuSeq的文本扩散模型，用于序列生成，采用了编码器-解码器Transformer架构和自适应噪声调度技术，旨在探索扩散模型在自然语言生成方面的性能表现。 |
| [^67] | [Don't Generate, Discriminate: A Proposal for Grounding Language Models to Real-World Environments.](http://arxiv.org/abs/2212.09736) | Pangu是一个泛用的框架，用于实现语言模型与现实环境的接轨，它利用语言模型的辨别能力而非生成能力，由一个符号代理和一个神经语言模型协同工作。这一方案已经在知识库问答问题中证明了它的有效性和灵活性。 |
| [^68] | [Human-in-the-loop Evaluation for Early Misinformation Detection: A Case Study of COVID-19 Treatments.](http://arxiv.org/abs/2212.09683) | 该论文提出了一种人机协同评估框架，用于检测新的虚假信息声明并识别支持它们的社交媒体消息。在COVID-19治疗的案例中，基于现代NLP方法开发基线系统，并展示了人类事实核查人员每小时可以识别出违反Twitter关于COVID-19虚假信息方针的124条推文。 |
| [^69] | [Cross-Lingual Retrieval Augmented Prompt for Low-Resource Languages.](http://arxiv.org/abs/2212.09651) | 本文提出了跨语言检索增强提示(PARC)管道，在零-shot低资源语言上通过从高资源语言中检索出的语义上类似的句子来改善性能，表现明显优于 fine-tuning 基线，同时与高低资源语言之间的相似性以及低资源预训练数据的数量存在显著正相关关系。 |
| [^70] | [Robustness of Learning from Task Instructions.](http://arxiv.org/abs/2212.03813) | 本文提出了一种鲁棒的方法来从任务说明中学习，以处理说明的变化并提高对新任务的泛化能力。 |
| [^71] | [Pivotal Role of Language Modeling in Recommender Systems: Enriching Task-specific and Task-agnostic Representation Learning.](http://arxiv.org/abs/2212.03760) | 本文研究发现，用户历史语言建模可以在不同推荐任务中取得优异结果，并且利用任务无关的用户历史还可以提供显著的性能优势。该方法具有广泛的现实世界迁移学习能力。 |
| [^72] | [Egocentric Audio-Visual Noise Suppression.](http://arxiv.org/abs/2211.03643) | 本文研究了对自我中心视频中的音频和视频进行噪声抑制的问题，并证明了自我中心视觉信息对于生成加性校正掩码最有帮助。 |
| [^73] | [Synthetic Text Generation with Differential Privacy: A Simple and Practical Recipe.](http://arxiv.org/abs/2210.14348) | 该论文介绍了一种简单而实用的方法，使用差分隐私对预训练的生成语言模型进行微调，能够生成具有强隐私保护的高质量合成文本，并且与非隐私版本相似。 |
| [^74] | [A Kernel-Based View of Language Model Fine-Tuning.](http://arxiv.org/abs/2210.05643) | 本文研究神经切线核 (NTK) 在描述预训练语言模型微调过程中的适用性。实验证明在14个NLP任务中使用掩码词预测问题作为下游任务，可以取得好的效果。 |
| [^75] | [How Far Are We from Real Synonym Substitution Attacks?.](http://arxiv.org/abs/2210.02844) | 本文探讨同义词替换攻击的现状，发现当前方法存在无解决的障碍，生成的敌对样本效果不佳，需要在未来改进。 |
| [^76] | [ContraCLM: Contrastive Learning For Causal Language Model.](http://arxiv.org/abs/2210.01185) | ContraCLM是一种对比学习框架，可增强因果语言模型的表示区分性并适用于超出语言生成的任务。在多个下游任务中，相对于其他模型，ContraCLM获得了显著的性能改进。 |
| [^77] | [Modular and On-demand Bias Mitigation with Attribute-Removal Subnetworks.](http://arxiv.org/abs/2205.15171) | 提出一种新颖的模块化偏差缓解方法，在推理时间按需集成到核心模型中的独立去偏置子网络，在性别、种族和年龄等受保护属性的分类任务中，该方法在缓解偏差方面是有效的，并且在精度和灵活性方面优于现有技术方法。 |
| [^78] | [The Diminishing Returns of Masked Language Models to Science.](http://arxiv.org/abs/2205.11342) | 本文从科学角度出发，评估了14个领域特定的基于Transformer的模型在12个下游科学任务中的表现，发现增加模型大小、训练数据或计算时间并不总是会导致显着提高，可能会有出乎意料的性能差异。 |
| [^79] | [Ontology-Driven and Weakly Supervised Rare Disease Identification from Clinical Notes.](http://arxiv.org/abs/2205.05656) | 本文提出了一种基于本体和弱监督的方法，可以利用来自BERT模型的最新预训练上下文表示来从临床记录中识别罕见病，无需领域专家的数据注释，实现了从文本到罕见病本体的自动匹配。 |
| [^80] | [Text Adversarial Purification as Defense against Adversarial Attacks.](http://arxiv.org/abs/2203.14207) | 该文章介绍了一种新型的针对文本对抗性攻击的对抗净化方法，通过注入噪声、掩盖输入文本并基于语言模型重构掩盖文本，成功地在不需要了解攻击形式的情况下对抗单词替换对抗攻击。 |
| [^81] | [Contrastive Learning of Sociopragmatic Meaning in Social Media.](http://arxiv.org/abs/2203.07648) | 提出了一种社交媒体中社会语用意义的对比学习框架，该框架能够学习可迁移的任务不可知表示学习，并在各种对比学习框架中表现最佳。 |
| [^82] | [Prompt-based Zero-shot Relation Extraction with Semantic Knowledge Augmentation.](http://arxiv.org/abs/2112.04539) | 本文提出了一种基于Prompt和语义知识增强的模型，用于在零样本情况下识别未见关系。采用了一个新的单词级别的类比推理方法，生成了具有未见关系的增强实例。设计了基于外部知识图谱的提示，增加了已见关系的语义知识信息。 |
| [^83] | [What do End-to-End Speech Models Learn about Speaker, Language and Channel Information? A Layer-wise and Neuron-level Analysis.](http://arxiv.org/abs/2107.00439) | 本研究通过对训练完成的语音模型进行层面和神经元水平的分析，探索了其中关于说话人、语言和信道属性的信息捕获情况。其研究结果有助于解释模型学习的关键特征及其在实现公正性决策方面的应用。 |
| [^84] | [Uni-Encoder: A Fast and Accurate Response Selection Paradigm for Generation-Based Dialogue Systems.](http://arxiv.org/abs/2106.01263) | 论文提出一种新的响应选择范例Uni-Encoder，解决了Cross-Encoder多次编码相同上下文计算成本高和Poly-Encoder性能下降的问题。该范例在一次前向传递中对所有候选与上下文进行编码。 |

# 详细

[^1]: 自动摘要中的政治偏见特征分析：以特朗普和拜登为例的案例研究

    Characterizing Political Bias in Automatic Summaries: A Case Study of Trump and Biden. (arXiv:2305.02321v1 [cs.CL])

    [http://arxiv.org/abs/2305.02321](http://arxiv.org/abs/2305.02321)

    本文研究了自动生成新闻文章摘要中的政治偏见。研究发现，与特朗普相比，更多的美国政府集体机构（即政府）与拜登相关联。这些发现为未来的摘要偏见研究提供了一个框架。

    

    越来越多的文献表明，强大的NLP系统可能对社会偏见进行编码；然而，自动摘要模型的政治偏见仍相对未知。在这项工作中，我们使用实体替换方法研究了新闻文章自动生成摘要中的政治家描绘。我们基于政治实体和词汇资源开发了一个计算框架，并使用它来评估抽取式和抽象式摘要模型中有关唐纳德·特朗普和乔·拜登的偏见。我们发现了一些一致的差异，例如在与特朗普相比，更多的美国政府集体机构（即政府）与拜登相关联。当实体在源文章中重点出现时，这些摘要差异最为明显。我们的系统化特征分析提供了一个未来研究摘要偏见的框架。

    Growing literature has shown that powerful NLP systems may encode social biases; however, the political bias of summarization models remains relatively unknown. In this work, we use an entity replacement method to investigate the portrayal of politicians in automatically generated summaries of news articles. We develop a computational framework based on political entities and lexical resources, and use it to assess biases about Donald Trump and Joe Biden in both extractive and abstractive summarization models. We find consistent differences, such as stronger associations of a collective US government (i.e., administration) with Biden than with Trump. These summary dissimilarities are most prominent when the entity is heavily featured in the source article. Our systematic characterization provides a framework for future studies of bias in summarization.
    
[^2]: 视觉思维链：多模态填充技术弥合逻辑差距

    Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings. (arXiv:2305.02317v1 [cs.CL])

    [http://arxiv.org/abs/2305.02317](http://arxiv.org/abs/2305.02317)

    VCoT是一种使用思维链激励和视觉语言组合递归地弥合时序数据中逻辑差距的新颖方法，其使用视觉引导生成合成的多模态填充以添加一致且新颖的信息，并减少需要时序推理的逻辑差距。

    

    大型自然语言模型的出现提高了模型的多步推理能力，能以人类方式分解问题。然而，该范例由于其单模态性质并且主要应用于问答任务而受到限制。我们认为将视觉增强内容纳入推理是必要的，尤其是针对复杂想象任务。因此，我们介绍了VCoT，一种新颖的方法，它利用思维链激励和视觉语言组合来递归地弥合时序数据中的逻辑差距。我们的方法使用视觉引导生成合成的多模态填充，以添加一致且新颖的信息，并减少下游任务中需要时序推理的逻辑差距，同时提供模型的多步推理的解释性。我们将VCoT应用于视觉叙事和WikiHow摘要数据集，并通过人工评估展示了其性能的提升。

    Recent advances in large language models elicit reasoning in a chain of thought that allows models to decompose problems in a human-like fashion. Though this paradigm improves multi-step reasoning ability in language models, it is limited by being unimodal and applied mainly to question-answering tasks. We claim that incorporating visual augmentation into reasoning is essential, especially for complex, imaginative tasks. Consequently, we introduce VCoT, a novel method that leverages chain of thought prompting with vision-language grounding to recursively bridge the logical gaps within sequential data. Our method uses visual guidance to generate synthetic multimodal infillings that add consistent and novel information to reduce the logical gaps for downstream tasks that can benefit from temporal reasoning, as well as provide interpretability into models' multi-step reasoning. We apply VCoT to the Visual Storytelling and WikiHow summarization datasets and demonstrate through human evalua
    
[^3]: Distilling Step-by-Step！使用更少的训练数据和更小的模型尺寸胜过更大的语言模型

    Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes. (arXiv:2305.02301v1 [cs.CL])

    [http://arxiv.org/abs/2305.02301](http://arxiv.org/abs/2305.02301)

    本研究提出了Distilling Step-by-Step机制，通过提取LLM基础信息为小型模型提供额外的监督训练，从而使它们胜过更大的LLM模型，并需更少的训练数据。

    

    部署大型语言模型（LLM）面临内存效率低和计算密集度高的问题，研究人员通过微调或精炼使用LLM生成的标签来训练较小的任务特定模型。但是，要想达到LLM相当的性能，这需要大量的训练数据。我们引入了Distilling Step-by-Step，这是一种新的机制， (a)训练较小的模型比LLM表现更好，(b)并通过利用微调或精炼所需的更少的训练数据来实现。我们的方法在多任务训练框架中提取LLM基础，并作为额外的监督来训练小型模型。在四个NLP基准测试中，我们提出了三个发现：第一，与微调和精炼相比，我们的机制使用较少的标记/未标记训练示例取得更好的性能。第二，与LLM相比，即使使用更小的模型，我们也实现了更好的性能。

    Deploying large language models (LLMs) is challenging because they are memory inefficient and compute-intensive for practical applications. In reaction, researchers train smaller task-specific models by either finetuning with human labels or distilling using LLM-generated labels. However, finetuning and distillation require large amounts of training data to achieve comparable performance to LLMs. We introduce Distilling step-by-step, a new mechanism that (a) trains smaller models that outperform LLMs, and (b) achieves so by leveraging less training data needed by finetuning or distillation. Our method extracts LLM rationales as additional supervision for small models within a multi-task training framework. We present three findings across 4 NLP benchmarks: First, compared to both finetuning and distillation, our mechanism achieves better performance with much fewer labeled/unlabeled training examples. Second, compared to LLMs, we achieve better performance using substantially smaller m
    
[^4]: 评估长度可控机器翻译的有效性

    Evaluating the Efficacy of Length-Controllable Machine Translation. (arXiv:2305.02300v1 [cs.CL])

    [http://arxiv.org/abs/2305.02300](http://arxiv.org/abs/2305.02300)

    本文评估了长度可控机器翻译的自动评估指标，发现BLEURT和COMET是最适合作为其评估指标的。

    

    长度可控机器翻译是一种约束翻译，旨在在控制翻译长度的同时尽可能保留原始含义。我们可以使用自动摘要或机器翻译评估指标进行长度可控机器翻译，但这并不一定适用和准确。这项工作是第一次系统评估长度可控机器翻译任务的自动评估指标。我们在两个翻译方向上进行了严格的人工评估，并评估了18个摘要或翻译评估指标。我们发现BLEURT和COMET与人工评估的相关性最高，最适合作为长度可控机器翻译的评估指标。

    Length-controllable machine translation is a type of constrained translation. It aims to contain the original meaning as much as possible while controlling the length of the translation. We can use automatic summarization or machine translation evaluation metrics for length-controllable machine translation, but this is not necessarily suitable and accurate. This work is the first attempt to evaluate the automatic metrics for length-controllable machine translation tasks systematically. We conduct a rigorous human evaluation on two translation directions and evaluate 18 summarization or translation evaluation metrics. We find that BLEURT and COMET have the highest correlation with human evaluation and are most suitable as evaluation metrics for length-controllable machine translation.
    
[^5]: M2-CTTS：端到端多尺度多模态会话文本到语音合成

    M2-CTTS: End-to-End Multi-scale Multi-modal Conversational Text-to-Speech Synthesis. (arXiv:2305.02269v1 [cs.SD])

    [http://arxiv.org/abs/2305.02269](http://arxiv.org/abs/2305.02269)

    M2-CTTS是一个端到端的多尺度多模态的会话文本到语音合成系统，相比于其他系统，它采用了粗粒度和细粒度的建模来全面利用历史对话，同时还考虑了声学特征，能够有效提高会话式TTS性能。

    

    会话式文本到语音合成（TTS）旨在根据历史对话合成具有适当语调的回复语音。然而，全面建模对话仍然是一个挑战，大多数会话式TTS系统只关注提取全局信息并省略本地语调特征，而后者包含关键词和强调等重要的细粒度信息。此外，仅考虑文本特征是不足的，声学特征也包含各种语调信息。因此，我们提出了M2-CTTS，这是一个端到端多尺度多模态的会话文本到语音合成系统，旨在全面利用历史对话并增强语调表达。更具体地，我们设计了一个文本上下文模块和一个声学上下文模块，二者都进行了粗粒度和细粒度的建模。实验结果表明，我们的模型结合细粒度上下文信息并额外考虑声学特征可以有效增强会话式TTS性能，并在各种评估指标上优于几种最先进的模型。

    Conversational text-to-speech (TTS) aims to synthesize speech with proper prosody of reply based on the historical conversation. However, it is still a challenge to comprehensively model the conversation, and a majority of conversational TTS systems only focus on extracting global information and omit local prosody features, which contain important fine-grained information like keywords and emphasis. Moreover, it is insufficient to only consider the textual features, and acoustic features also contain various prosody information. Hence, we propose M2-CTTS, an end-to-end multi-scale multi-modal conversational text-to-speech system, aiming to comprehensively utilize historical conversation and enhance prosodic expression. More specifically, we design a textual context module and an acoustic context module with both coarse-grained and fine-grained modeling. Experimental results demonstrate that our model mixed with fine-grained context information and additionally considering acoustic fea
    
[^6]: 一种面向语言复杂的图像检索的神经分治推理框架

    A Neural Divide-and-Conquer Reasoning Framework for Image Retrieval from Linguistically Complex Text. (arXiv:2305.02265v1 [cs.CL])

    [http://arxiv.org/abs/2305.02265](http://arxiv.org/abs/2305.02265)

    提出了一种神经分治推理框架NDCR，通过将语言复杂文本视为由多个简单命题句组成的复合命题文本，将图像检索问题分为三个步骤：分治、征服和组合。该框架在解决语言复杂文本问题时具有较好的性能。

    

    预训练视觉语言模型（VLMs）在图像检索方面取得了显着的性能。但是，当面对难以理解的语言复杂文本时，它们的性能会急剧下降。本文受到分治算法和双过程理论的启发，将语言复杂文本视为由多个简单命题句组成的复合命题文本，并提出了一个端到端的神经分治推理框架NDCR。它包括三个主要组件：1）分治：命题生成器将复合命题文本分为简单命题句，并生成它们的对应表示，2）征服：基于预训练视觉语言交互器实现分解命题句和图像之间的交互，3）组合：神经符号推理器采用神经逻辑推理方法将上述推理状态组合，获得最终解决方案。

    Pretrained Vision-Language Models (VLMs) have achieved remarkable performance in image retrieval from text. However, their performance drops drastically when confronted with linguistically complex texts that they struggle to comprehend. Inspired by the Divide-and-Conquer algorithm and dual-process theory, in this paper, we regard linguistically complex texts as compound proposition texts composed of multiple simple proposition sentences and propose an end-to-end Neural Divide-and-Conquer Reasoning framework, dubbed NDCR. It contains three main components: 1)Divide: a proposition generator divides the compound proposition text into simple proposition sentences and produces their corresponding representations, 2)Conquer: a pretrained VLMs-based visual-linguistic interactor achieves the interaction between decomposed proposition sentences and images, 3)Combine: a neural-symbolic reasoner combines the above reasoning states to obtain the final solution via a neural logic reasoning approach
    
[^7]: 基于中转的级联翻译模型的端到端训练与解码方法

    End-to-end Training and Decoding for Pivot-based Cascaded Translation Model. (arXiv:2305.02261v1 [cs.CL])

    [http://arxiv.org/abs/2305.02261](http://arxiv.org/abs/2305.02261)

    本文提出了一种端到端训练方法，并配置了改进的解码算法，即基于中转的级联翻译模型，使用加权中转语言嵌入输入模型，利用波束搜索缓解标记和概率分布之间的不一致性。实验证明，该方法提高了翻译的质量。

    

    利用中转语言可以显著提高低资源机器翻译效果。通常，源语言到中转语言模型和中转语言到目标语言模型分别训练，没有利用有限的（源语言，目标语言）并行数据。本文提出了一种用于级联翻译模型的端到端训练方法，并配置了改进的解码算法。中转语言到目标语言模型的输入根据源语言到中转语言模型的概率分布修改为加权中转语言嵌入，从而可以进行端到端训练。此外，当使用中转语言解码中的波束搜索时，我们缓解了标记和概率分布之间的不一致性。实验结果表明，我们的方法提高了翻译的质量。

    Utilizing pivot language effectively can significantly improve low-resource machine translation. Usually, the two translation models, source-pivot and pivot-target, are trained individually and do not utilize the limited (source, target) parallel data. This work proposes an end-to-end training method for the cascaded translation model and configures an improved decoding algorithm. The input of the pivot-target model is modified to weighted pivot embedding based on the probability distribution output by the source-pivot model. This allows the model to be trained end-to-end. In addition, we mitigate the inconsistency between tokens and probability distributions while using beam search in pivot decoding. Experiments demonstrate that our method enhances the quality of translation.
    
[^8]: 标注描述训练在零样本文本分类中的好处

    The Benefits of Label-Description Training for Zero-Shot Text Classification. (arXiv:2305.02239v1 [cs.CL])

    [http://arxiv.org/abs/2305.02239](http://arxiv.org/abs/2305.02239)

    本文提出了标注描述训练的方法，在零样本分类中可以显著提高准确率，并能更鲁棒地处理分类任务。

    

    大型语言模型通过允许从训练数据中转移语义知识，提高了零样本文本分类的性能，本文提出了一种简单的方法，进一步提高零样本准确性。我们策划了一个小的微调数据集，旨在描述任务标签。与通常有文本标注标签的微调数据不同，我们的数据只是用语言描述标签，例如使用一些相关术语、词典/百科全书条目和短模板。我们的方法在各种主题和情感数据集上的准确性比零样本高15-17％绝对值。它还更具有零样本分类所需选择的鲁棒性，例如提示模型进行分类的模式以及从标签映射到模型词汇表中的令牌。此外，由于我们的数据仅描述标签但不使用输入文本，因此在其上微调的模型可以将分类的重点更专注于标签而不是文本。

    Large language models have improved zero-shot text classification by allowing the transfer of semantic knowledge from the training data in order to classify among specific label sets in downstream tasks. We propose a simple way to further improve zero-shot accuracies with minimal effort. We curate small finetuning datasets intended to describe the labels for a task. Unlike typical finetuning data, which has texts annotated with labels, our data simply describes the labels in language, e.g., using a few related terms, dictionary/encyclopedia entries, and short templates. Across a range of topic and sentiment datasets, our method is more accurate than zero-shot by 15-17% absolute. It is also more robust to choices required for zero-shot classification, such as patterns for prompting the model to classify and mappings from labels to tokens in the model's vocabulary. Furthermore, since our data merely describes the labels but does not use input texts, finetuning on it yields a model that p
    
[^9]: AttenWalker: 使用基于Attention的图遍历实现无监督长文档问答

    AttenWalker: Unsupervised Long-Document Question Answering via Attention-based Graph Walking. (arXiv:2305.02235v1 [cs.CL])

    [http://arxiv.org/abs/2305.02235](http://arxiv.org/abs/2305.02235)

    AttenWalker是一种基于Attention的图遍历方法，用于实现无监督长文档问答。它由三个模块组成：span collector、span linker和answer aggregator。这些模块结合使用来选择有信息量的候选span，将这些span串联起来形成完整答案，并生成最终答案。在CoQA数据集上获得了良好的实验结果。

    

    标注长文档问答是耗时且昂贵的。为了缓解这个问题，可能可以通过无监督问答方法生成长文档问答对。然而，现有的UQA任务基于短文档，难以纳入长距离信息。为了解决这个问题，我们提出了一个新任务，名为无监督长文档问答（ULQA），旨在以无监督方式生成高质量的长文档QA实例。此外，我们提出了AttenWalker，一种新型的无监督方法，用于聚合和生成具有长距离依赖性的答案，以构建长文档QA对。在CoQA数据集上的实验结果表明了我们提出的无监督长文档QA方法的有效性。

    Annotating long-document question answering (long-document QA) pairs is time-consuming and expensive. To alleviate the problem, it might be possible to generate long-document QA pairs via unsupervised question answering (UQA) methods. However, existing UQA tasks are based on short documents, and can hardly incorporate long-range information. To tackle the problem, we propose a new task, named unsupervised long-document question answering (ULQA), aiming to generate high-quality long-document QA instances in an unsupervised manner. Besides, we propose AttenWalker, a novel unsupervised method to aggregate and generate answers with long-range dependency so as to construct long-document QA pairs. Specifically, AttenWalker is composed of three modules, i.e., span collector, span linker and answer aggregator. Firstly, the span collector takes advantage of constituent parsing and reconstruction loss to select informative candidate spans for constructing answers. Secondly, by going through the 
    
[^10]: 利用大型语言模型从医生-患者对话中生成临床笔记：来自MEDIQA-Chat的见解

    Clinical Note Generation from Doctor-Patient Conversations using Large Language Models: Insights from MEDIQA-Chat. (arXiv:2305.02220v1 [cs.CL])

    [http://arxiv.org/abs/2305.02220](http://arxiv.org/abs/2305.02220)

    本文介绍了使用大型语言模型从医生-患者对话中自动生成临床笔记的研究，采用少样本上下文学习法所生成笔记表现优秀，且可与人工编写的笔记媲美。

    

    本文描述了我们在MEDIQA-Chat 2023共享任务中提交的自动临床笔记生成方案。我们报告了两种方法的结果：第一种是在共享任务数据上微调预训练语言模型（PLM），第二种是使用大型语言模型（LLM）的少样本上下文学习（ICL）。两种方法都取得了高性能，如通过自动度量标准（例如ROUGE，BERTScore）测量，并分别在所有提交的方案中排名第二和第一。专家审核表明，通过基于ICL的方法使用GPT-4生成的笔记与人工编写的笔记一样受欢迎，这使得它成为从医生-患者对话中自动生成笔记的有前途的路径。

    This paper describes our submission to the MEDIQA-Chat 2023 shared task for automatic clinical note generation from doctor-patient conversations. We report results for two approaches: the first fine-tunes a pre-trained language model (PLM) on the shared task data, and the second uses few-shot in-context learning (ICL) with a large language model (LLM). Both achieve high performance as measured by automatic metrics (e.g. ROUGE, BERTScore) and ranked second and first, respectively, of all submissions to the shared task. Expert human scrutiny indicates that notes generated via the ICL-based approach with GPT-4 are preferred about as often as human-written notes, making it a promising path toward automated note generation from doctor-patient conversations.
    
[^11]: 用语言分类探究单语BERT的语言属性

    Exploring Linguistic Properties of Monolingual BERTs with Typological Classification among Languages. (arXiv:2305.02215v1 [cs.CL])

    [http://arxiv.org/abs/2305.02215](http://arxiv.org/abs/2305.02215)

    本文研究使用语言分类方法探究单语BERT的语言属性，核心发现为BERT正在复制传统的语言模型。

    

    Transformer模型的巨大成功使人们产生了一个问题：这些机器是在复制某些传统的语言模型，还是发现了根本性的新理论？在本文中，我们提出了一种新的研究观点，使用语言之间的类型相似性来对比不同语言的transformer模型，观察这些相似性是否出现在特定的层次。为了进行这项研究，我们提出了基于中心核对齐的权重矩阵相似度测量方法。我们发现，句法类型学相似性与中间层权重之间的相似性是一致的。这一发现确认了通过句法探针方法获得的BERT的结果，并因此重要地证明了BERT正在复制传统的语言模型。

    The overwhelming success of transformers is a real conundrum stimulating a compelling question: are these machines replicating some traditional linguistic models or discovering radically new theories? In this paper, we propose a novel standpoint to investigate this important question. Using typological similarities among languages, we aim to layer-wise compare transformers for different languages to observe whether these similarities emerge for particular layers. For this investigation, we propose to use Centered kernel alignment to measure similarity among weight matrices. We discovered that syntactic typological similarity is consistent with the similarity among weights in the middle layers. This finding confirms results obtained by syntactically probing BERT and, thus, gives an important confirmation that BERT is replicating traditional linguistic models.
    
[^12]: 向参数效率迈进：具有动态能力的分层稀疏激活Transformer

    Towards Being Parameter-Efficient: A Stratified Sparsely Activated Transformer with Dynamic Capacity. (arXiv:2305.02176v1 [cs.CL])

    [http://arxiv.org/abs/2305.02176](http://arxiv.org/abs/2305.02176)

    本篇论文提出了一种新的分层稀疏激活Transformer模型，可以动态分配不同令牌的能力，解决了传统Mixture-of-experts模型参数低效的问题，实验表明该模型在多语言机器翻译任务中取得了较好效果。

    

    采用稀疏激活的Mixture-of-experts（MoE）模型已经证明在保持低每个令牌计算要求的同时显着增加参数的有效性。然而，最近的研究表明，MoE模型本质上是参数低效的，因为随着专家数量增加，性能的提高会变小。我们假设这种参数低效是所有专家具有相同能力的结果，这可能无法充分满足不同令牌或任务的不同复杂度要求，例如在多语言环境下，基于其资源水平的语言可能需要不同的能力。因此，我们提出了具有分层结构并可以为不同令牌分配动态能力的Stratified Mixture of Experts（SMoE）模型。我们证明SMoE的有效性，该模型在两个多语言机器翻译基准测试中表现优于多个最先进的MoE模型。

    Mixture-of-experts (MoE) models that employ sparse activation have demonstrated effectiveness in significantly increasing the number of parameters while maintaining low computational requirements per token. However, recent studies have established that MoE models are inherently parameter-inefficient as the improvement in performance diminishes with an increasing number of experts. We hypothesize this parameter inefficiency is a result of all experts having equal capacity, which may not adequately meet the varying complexity requirements of different tokens or tasks, e.g., in a multilingual setting, languages based on their resource levels might require different capacities. In light of this, we propose Stratified Mixture of Experts(SMoE) models, which feature a stratified structure and can assign dynamic capacity to different tokens. We demonstrate the effectiveness of SMoE on two multilingual machine translation benchmarks, where it outperforms multiple state-of-the-art MoE models. On
    
[^13]: 一种文本分组的统计探索：《创世记》和《出埃及记》中司祭派别的情况

    A Statistical Exploration of Text Partition Into Constituents: The Case of the Priestly Source in the Books of Genesis and Exodus. (arXiv:2305.02170v1 [cs.CL])

    [http://arxiv.org/abs/2305.02170](http://arxiv.org/abs/2305.02170)

    为了验证文本分组的假设，我们提出了一个统计文本探索的流程，并在圣经的前两卷书中应用此流程，成功地识别并探索了司祭派别和非司祭派别之间的统计明显的文体差异。

    

    我们提出了一个统计文本探索的流程，提供了一种基于文体学的解释，并对文本的假设分组进行了统计验证。给定文本的参数化，我们的流程：（1）检测文学特征，以产生假设分组和无监督分组之间的最佳重叠，（2）执行假设检验分析，量化最佳重叠的统计显著性，同时保留更可能被分组的文本单位之间的隐式相关性，以及（3）提取和量化对分类最负责的特征的重要性，并估计它们的统计稳定性和聚类-wise丰度。我们将这个流程应用于圣经中的前两卷书，圣经学者们认为，其中一种文体成分特别突出，即司祭派别。我们确定并探索了司祭派别和非司祭派别之间的统计明显的文体差异。

    We present a pipeline for a statistical textual exploration, offering a stylometry-based explanation and statistical validation of a hypothesized partition of a text. Given a parameterization of the text, our pipeline: (1) detects literary features yielding the optimal overlap between the hypothesized and unsupervised partitions, (2) performs a hypothesis-testing analysis to quantify the statistical significance of the optimal overlap, while conserving implicit correlations between units of text that are more likely to be grouped, and (3) extracts and quantifies the importance of features most responsible for the classification, estimates their statistical stability and cluster-wise abundance.  We apply our pipeline to the first two books in the Bible, where one stylistic component stands out in the eyes of biblical scholars, namely, the Priestly component. We identify and explore statistically significant stylistic differences between the Priestly and non-Priestly components.
    
[^14]: 利用高影响概念解释语言模型的预测

    Explaining Language Models' Predictions with High-Impact Concepts. (arXiv:2305.02160v1 [cs.CL])

    [http://arxiv.org/abs/2305.02160](http://arxiv.org/abs/2305.02160)

    本论文提供了一个完整的框架，将基于概念的可解释性方法推广到 NLP 领域。通过后期可解释性方法，从预训练模型的隐藏层激活中提取预测高级特征（概念），并优化具有高影响力的特征存在，使其能够准确地解释模型的行为。

    

    大规模预训练语言模型的出现对推断模型的解释提出了前所未有的挑战。由于语言的组合性质，虚假相关继续削弱着 NLP 系统的可信度，导致模型的解释仅仅与输出预测相关，无法靠谱地解释模型的行为。为了促进公平和透明度，在 NLP 领域有着迫切需求可靠的解释，使用户能够一致地理解模型的行为。在这项工作中，我们提出了一个完整的框架，将基于概念的可解释性方法推广到 NLP 领域。具体而言，我们提出了一种用于从预训练模型的隐藏层激活中提取预测高级特征（概念）的后期可解释性方法。我们优化具有高影响力的特征存在，这些特征会导致输出预测发生显著变化。

    The emergence of large-scale pretrained language models has posed unprecedented challenges in deriving explanations of why the model has made some predictions. Stemmed from the compositional nature of languages, spurious correlations have further undermined the trustworthiness of NLP systems, leading to unreliable model explanations that are merely correlated with the output predictions. To encourage fairness and transparency, there exists an urgent demand for reliable explanations that allow users to consistently understand the model's behavior. In this work, we propose a complete framework for extending concept-based interpretability methods to NLP. Specifically, we propose a post-hoc interpretability method for extracting predictive high-level features (concepts) from the pretrained model's hidden layer activations. We optimize for features whose existence causes the output predictions to change substantially, \ie generates a high impact. Moreover, we devise several evaluation metri
    
[^15]: 基于大型语言模型的零样本列表式文档重新排序

    Zero-Shot Listwise Document Reranking with a Large Language Model. (arXiv:2305.02156v1 [cs.IR])

    [http://arxiv.org/abs/2305.02156](http://arxiv.org/abs/2305.02156)

    本文提出了一种基于大型语言模型的列表式重新排序器，可以在没有特定任务训练数据的情况下实现强大的重新排序效果，并在实验中取得了令人满意的结果。

    

    基于双编码器或交叉编码器结构的监督排序方法已经在多阶段文本排序任务中取得了成功，但是它们需要大量相关性判断作为训练数据。在本文中，我们提出了一种使用大型语言模型的列表式重新排序器(LRL)，它可以在不使用任何特定任务训练数据的情况下实现强大的重新排序效果。LRL与现有的点式排名方法不同，在点式排名方法中，文档是独立得分并按分数排名，而LRL直接生成给定候选文档的重新排序文档标识符列表。在三个TREC网络搜索数据集上的实验表明，LRL不仅可以在重新排序第一阶段检索结果时优于零样本点式方法，还可以作为点式方法的最终阶段重新排序器，以提高效率并提高前几名的结果。此外，我们将我们的方法应用于MIRACL的子集，这是最近的一个多语言检索数据集，获得了令人满意的结果。

    Supervised ranking methods based on bi-encoder or cross-encoder architectures have shown success in multi-stage text ranking tasks, but they require large amounts of relevance judgments as training data. In this work, we propose Listwise Reranker with a Large Language Model (LRL), which achieves strong reranking effectiveness without using any task-specific training data. Different from the existing pointwise ranking methods, where documents are scored independently and ranked according to the scores, LRL directly generates a reordered list of document identifiers given the candidate documents. Experiments on three TREC web search datasets demonstrate that LRL not only outperforms zero-shot pointwise methods when reranking first-stage retrieval results, but can also act as a final-stage reranker to improve the top-ranked results of a pointwise method for improved efficiency. Additionally, we apply our approach to subsets of MIRACL, a recent multilingual retrieval dataset, with results 
    
[^16]: 语言距离与多语言表示空间中的跨语言传递的相关性研究

    Identifying the Correlation Between Language Distance and Cross-Lingual Transfer in a Multilingual Representation Space. (arXiv:2305.02151v1 [cs.CL])

    [http://arxiv.org/abs/2305.02151](http://arxiv.org/abs/2305.02151)

    探索了语言特征对多语言表示空间中的跨语言传递性能的影响，初步提供了方法以增强对语言上相距较远的语言的传递能力。

    

    先前的研究已经探讨了不同语言特征对跨语言传递性能的影响。本研究探讨了这种效应如何映射到表示空间中。过去的研究集中在微调期间多语言语言模型的跨语言对齐上的影响，而本研究研究的是由MLLMs生成的相应语言表示空间的绝对演变。我们特别强调语言特征的作用，并调查其与表示空间和跨语言传递性能的影响之间的相互关系。此外，本文提供了初步证据，说明如何利用这些发现增强对语言上相距较远的语言的传递能力。

    Prior research has investigated the impact of various linguistic features on cross-lingual transfer performance. In this study, we investigate the manner in which this effect can be mapped onto the representation space. While past studies have focused on the impact on cross-lingual alignment in multilingual language models during fine-tuning, this study examines the absolute evolution of the respective language representation spaces produced by MLLMs. We place a specific emphasis on the role of linguistic characteristics and investigate their inter-correlation with the impact on representation spaces and cross-lingual transfer performance. Additionally, this paper provides preliminary evidence of how these findings can be leveraged to enhance transfer to linguistically distant languages.
    
[^17]: 鲁棒损失函数的课程视角

    A Curriculum View of Robust Loss Functions. (arXiv:2305.02139v1 [cs.LG])

    [http://arxiv.org/abs/2305.02139](http://arxiv.org/abs/2305.02139)

    本文提出了鲁棒损失函数的课程视角，以更直观的方式分析训练动态，指出欠拟合的原因是由于平均样本权重的降低而引起的，对噪声鲁棒性的优化则是通过对干净样本赋予更大的样本权重来实现的。进一步的研究表明，通过简单的课程修正可以提高鲁棒损失函数的性能，而训练进度对于鲁棒性也有着非常重要的影响。

    

    鲁棒损失函数旨在应对标签噪声的负面影响，其鲁棒性通常由与训练动态无关的理论界限支持。然而，这些界限可能无法表征实证性能，因为目前尚不清楚为什么鲁棒损失函数会欠拟合。我们表明，大多数损失函数可以重写成具有相同类-分数间隔和不同样本加权函数形式的形式。所得到的课程视角提供了对训练动态的直观分析，有助于将欠拟合归因于平均样本权重的降低和将噪声鲁棒性归因于对干净样本赋予较大的样本权重。我们表明，对课程视角进行简单的修正可以使欠拟合的鲁棒损失函数与最先进的方法竞争，而训练进度可以极大地影响噪声鲁棒性，即使采用鲁棒损失函数。代码可在\url{github}中找到。

    Robust loss functions are designed to combat the adverse impacts of label noise, whose robustness is typically supported by theoretical bounds agnostic to the training dynamics. However, these bounds may fail to characterize the empirical performance as it remains unclear why robust loss functions can underfit. We show that most loss functions can be rewritten into a form with the same class-score margin and different sample-weighting functions. The resulting curriculum view provides a straightforward analysis of the training dynamics, which helps attribute underfitting to diminished average sample weights and noise robustness to larger weights for clean samples. We show that simple fixes to the curriculums can make underfitting robust loss functions competitive with the state-of-the-art, and training schedules can substantially affect the noise robustness even with robust loss functions. Code is available at \url{github}.
    
[^18]: 关注关系探索，提升知识库问答技术

    Pay More Attention to Relation Exploration for Knowledge Base Question Answering. (arXiv:2305.02118v1 [cs.CL])

    [http://arxiv.org/abs/2305.02118](http://arxiv.org/abs/2305.02118)

    该研究提出了一个新框架RE-KBQA，利用知识库中的关系增强实体表示，并引入额外监督。在三个方面探索关系指导，包括区分相似实体、探索额外监督以及进行后处理的基于关系指导的重排算法。该方法在两个基准数据集上验证有效性。

    

    知识库问答（KBQA）是一项挑战性的任务，旨在从大规模知识库中检索正确答案。现有研究主要关注实体表示和最终答案推理，导致对此任务的限制性监督。此外，关系在最近的技术中并未被充分考虑，而关系实际上决定了推理路径的选择。在本研究中，我们提出了一个新框架RE-KBQA，利用知识库中的关系增强实体表示，并引入额外的监督。我们从三个方面探索关系指导，包括（1）通过使用变分图自编码器学习关系重要性来区分相似实体；（2）通过预测关系分布作为软标签，采用多任务方案探索额外监督；（3）设计基于关系指导的重排算法进行后处理。在两个基准数据集上的实验结果表明了该方法的有效性。

    Knowledge base question answering (KBQA) is a challenging task that aims to retrieve correct answers from large-scale knowledge bases. Existing attempts primarily focus on entity representation and final answer reasoning, which results in limited supervision for this task. Moreover, the relations, which empirically determine the reasoning path selection, are not fully considered in recent advancements. In this study, we propose a novel framework, RE-KBQA, that utilizes relations in the knowledge base to enhance entity representation and introduce additional supervision. We explore guidance from relations in three aspects, including (1) distinguishing similar entities by employing a variational graph auto-encoder to learn relation importance; (2) exploring extra supervision by predicting relation distributions as soft labels with a multi-task scheme; (3) designing a relation-guided re-ranking algorithm for post-processing. Experimental results on two benchmark datasets demonstrate the e
    
[^19]: GPT-RE: 利用大型语言模型进行上下文学习的关系抽取研究

    GPT-RE: In-context Learning for Relation Extraction using Large Language Models. (arXiv:2305.02105v1 [cs.CL])

    [http://arxiv.org/abs/2305.02105](http://arxiv.org/abs/2305.02105)

    本文提出了GPT-RE，通过特定于任务的实体表示和使用金标签诱导的推理逻辑丰富演示，成功解决了大型语言模型在关系抽取方面的低相关性和倾向于错误分类的问题，成果在多个数据集上均超过现有基准，其中在三个数据集中的结果达到了最新研究成果。

    

    尽管大型语言模型（例如GPT-3）有可能取得突破性成就，但它们在关系抽取方面仍远远落后于完全监督的基准（例如fine-tuned BERT）。  这是由于LLMs在RE方面存在两个主要缺点:(1)在上下文学习中，检索到的演示中实体和关系的相关性较低; (2)强烈倾向于错误地将NULL示例分类为其他预定义的标签。  本文提出了GPT-RE来弥合LLMs和完全监督的基准之间的差距。 GPT-RE通过（1）在演示检索中加入特定于任务的实体表示; （2）使用金标签诱导的推理逻辑丰富演示来成功解决上述问题。 我们在四个广泛使用的RE数据集上评估了GPT-RE，并观察到GPT-RE不仅改善了现有的GPT-3基准，而且改善了完全监督的基准。 具体而言，GPT-RE在四个数据集中的三个上都取得了最新的研究成果，证明了其在上下文学习关系抽取方面的有效性。

    In spite of the potential for ground-breaking achievements offered by large language models (LLMs) (e.g., GPT-3), they still lag significantly behind fully-supervised baselines (e.g., fine-tuned BERT) in relation extraction (RE). This is due to the two major shortcomings of LLMs in RE: (1) low relevance regarding entity and relation in retrieved demonstrations for in-context learning; and (2) the strong inclination to wrongly classify NULL examples into other pre-defined labels.  In this paper, we propose GPT-RE to bridge the gap between LLMs and fully-supervised baselines. GPT-RE successfully addresses the aforementioned issues by (1) incorporating task-specific entity representations in demonstration retrieval; and (2) enriching the demonstrations with gold label-induced reasoning logic. We evaluate GPT-RE on four widely-used RE datasets, and observe that GPT-RE achieves improvements over not only existing GPT-3 baselines, but also fully-supervised baselines. Specifically, GPT-RE ach
    
[^20]: 可读性、相关性和事实准确性的生物医学普及摘要的背景知识展开

    Background Knowledge Grounding for Readable, Relevant, and Factual Biomedical Lay Summaries. (arXiv:2305.02104v1 [cs.CL])

    [http://arxiv.org/abs/2305.02104](http://arxiv.org/abs/2305.02104)

    使用背景知识源文件可以提高普及摘要的相关性和可读性，但不能提高其事实准确性。

    

    向公众传播科学发现对于保持非专家了解紧急医疗治疗等发展是非常重要的。然而，从科学文档中生成可读的普及摘要是具有挑战性的，并且目前，这些摘要存在严重的事实错误。提高事实性的一种流行干预措施是使用其他外部知识来提供事实准确性。然而，目前尚不清楚如何检索、选择或整合这些背景知识，以及补充背景知识文档如何影响生成的摘要的可读性或相关性。我们开发了一种简单的方法来选择背景知识源，并将其与源文档集成。然后，我们使用BioLaySum汇总数据集来评估不同背景知识源对摘要质量的影响。我们发现，背景知识源文件可以提高普及摘要的相关性和可读性，但不能提高普及摘要的事实准确性。

    Communication of scientific findings to the public is important for keeping non-experts informed of developments such as life-saving medical treatments. However, generating readable lay summaries from scientific documents is challenging, and currently, these summaries suffer from critical factual errors. One popular intervention for improving factuality is using additional external knowledge to provide factual grounding. However, it is unclear how these grounding sources should be retrieved, selected, or integrated, and how supplementary grounding documents might affect the readability or relevance of the generated summaries. We develop a simple method for selecting grounding sources and integrating them with source documents. We then use the BioLaySum summarization dataset to evaluate the effects of different grounding sources on summary quality. We found that grounding source documents improves the relevance and readability of lay summaries but does not improve factuality of lay summ
    
[^21]: 什么样的停顿是好的呢?——探究语音停顿对持续发言效应的影响

    What makes a good pause? Investigating the turn-holding effects of fillers. (arXiv:2305.02101v1 [cs.CL])

    [http://arxiv.org/abs/2305.02101](http://arxiv.org/abs/2305.02101)

    本文基于Voice Activity Projection模型，探究填充停顿对持续发言的影响，结果表明填充停顿确实具有持续发言的效果，但可能不像人们预期的那么强烈。

    

    填充停顿（或占位符），例如“嗯”和“啊”，在口语中频繁出现，可以作为听众的持续发言提示，表明当前演讲者尚未完成。本文使用最近提出的Voice Activity Projection（VAP）模型，这是一个深度学习模型，用于预测对话的动态，分析填充停顿对预期持续发言概率的影响。结果表明，虽然填充停顿确实具有持续发言的效果，但可能不像人们预期的那么强烈，这可能是由于其他提示的冗余性。我们还发现，填充物的韵律特性和位置对持续发言的概率有重要影响。然而，与先前的研究所提出的不同，这方面“嗯”和“啊”没有区别。

    Filled pauses (or fillers), such as "uh" and "um", are frequent in spontaneous speech and can serve as a turn-holding cue for the listener, indicating that the current speaker is not done yet. In this paper, we use the recently proposed Voice Activity Projection (VAP) model, which is a deep learning model trained to predict the dynamics of conversation, to analyse the effects of filled pauses on the expected turn-hold probability. The results show that, while filled pauses do indeed have a turn-holding effect, it is perhaps not as strong as could be expected, probably due to the redundancy of other cues. We also find that the prosodic properties and position of the filler has a significant effect on the turn-hold probability. However, contrary to what has been suggested in previous work, there is no difference between "uh" and "um" in this regard.
    
[^22]: 响应条件的交替预测

    Response-conditioned Turn-taking Prediction. (arXiv:2305.02036v1 [cs.CL])

    [http://arxiv.org/abs/2305.02036](http://arxiv.org/abs/2305.02036)

    本文提出的响应条件模型结合了对话历史和下一个发言者想要表达的内容来预测一轮对话何时结束，并在Stanford对话数据集中表现出了最佳的预测和响应结果。

    

    先前解决对话系统中转换及响应生成的方法通常将其视为两个阶段的过程：首先通过对话历史来检测一轮对话是否已结束，然后系统生成一个合适的响应。然而，人类不仅仅因为很可能轮到自己了就发言，还要考虑自己想说的话是否适合当前位置。本文提出了一种模型（TurnGPT的扩展），它基于对话历史和下一个发言者要说的内容来预测一轮对话何时结束。我们发现，我们的模型在各种指标方面一直表现优异。在两种情景下，我们的模型的改进尤为显著，这两种情景下轮换预测仅由对话历史可能表现为模棱两可的：1）当前话语中包含陈述句和紧接着的疑问句；2）当前话语的结尾和所需响应在语义上匹配。将交替预测和响应排序视为一个阶段的过程，我们的模型在Stanford对话数据集中取得了最优秀的结果。

    Previous approaches to turn-taking and response generation in conversational systems have treated it as a two-stage process: First, the end of a turn is detected (based on conversation history), then the system generates an appropriate response. Humans, however, do not take the turn just because it is likely, but also consider whether what they want to say fits the position. In this paper, we present a model (an extension of TurnGPT) that conditions the end-of-turn prediction on both conversation history and what the next speaker wants to say. We found that our model consistently outperforms the baseline model in a variety of metrics. The improvement is most prominent in two scenarios where turn predictions can be ambiguous solely from the conversation history: 1) when the current utterance contains a statement followed by a question; 2) when the end of the current utterance semantically matches the response. Treating the turn-prediction and response-ranking as a one-stage process, our
    
[^23]: 系统研究基于伪目标训练的知识蒸馏用于自然语言生成

    A Systematic Study of Knowledge Distillation for Natural Language Generation with Pseudo-Target Training. (arXiv:2305.02031v1 [cs.CL])

    [http://arxiv.org/abs/2305.02031](http://arxiv.org/abs/2305.02031)

    本文研究如何压缩自然语言生成模型以适应实际应用需求，通过使用知识蒸馏和伪目标训练技术针对特定的自然语言生成任务和数据集进行优化，并取得了显著效果。

    

    现代自然语言生成模型需要大量的计算和存储资源。本文研究压缩这些模型的潜力，这对于服务数百万用户的实际应用至关重要。我们聚焦于知识蒸馏（KD）技术，其中小的学生模型学习模仿大的教师模型，使得可以从教师向学生传递知识。与之前的大部分工作不同，我们的目标是针对特定的自然语言生成任务和数据集优化模型。通常，在真实世界的应用中，除了有标记数据外，还有大量的未标记任务特定数据，这对于通过知识蒸馏获得高压缩率至关重要。在本文中，我们在现实的假设下，对各种自然语言生成任务进行了系统的任务特定知识蒸馏研究，并讨论了自然语言生成蒸馏的特殊特征，尤其是曝光偏差问题。接着，我们推导出一系列伪目标训练（PTT）技术，缓解了这个问题，并提高了学生模型的质量。通过广泛的实验评估，我们证明了我们提出的方法在不同的自然语言生成任务和数据集上的有效性。

    Modern Natural Language Generation (NLG) models come with massive computational and storage requirements. In this work, we study the potential of compressing them, which is crucial for real-world applications serving millions of users. We focus on Knowledge Distillation (KD) techniques, in which a small student model learns to imitate a large teacher model, allowing to transfer knowledge from the teacher to the student. In contrast to much of the previous work, our goal is to optimize the model for a specific NLG task and a specific dataset. Typically, in real-world applications, in addition to labeled data there is abundant unlabeled task-specific data, which is crucial for attaining high compression rates via KD. In this work, we conduct a systematic study of task-specific KD techniques for various NLG tasks under realistic assumptions. We discuss the special characteristics of NLG distillation and particularly the exposure bias problem. Following, we derive a family of Pseudo-Target
    
[^24]: 客户备注数据的自然语言处理

    Natural language processing on customer note data. (arXiv:2305.02029v1 [cs.CL])

    [http://arxiv.org/abs/2305.02029](http://arxiv.org/abs/2305.02029)

    本文将情感分析、主题建模和关键词提取应用于客户的B2B数据集，展示了能够自动提取出正确情感信息并分成不同的主题。

    

    自动分析客户数据对业务公司是一个有趣的领域。由于这些敏感信息的特殊性质，业务对业务数据很少被研究。应用自然语言处理可以加速分析大规模数据集的过程。本文将情感分析、主题建模和关键词提取应用于一份B2B数据集。我们展示了可以从备注中自动提取准确的情感信息，并将备注按照相关性分成不同的主题。我们发现在没有明确的主题分类的情况下，主题可能缺乏业务上的相关性。

    Automatic analysis of customer data for businesses is an area that is of interest to companies. Business to business data is studied rarely in academia due to the sensitive nature of such information. Applying natural language processing can speed up the analysis of prohibitively large sets of data. This paper addresses this subject and applies sentiment analysis, topic modelling and keyword extraction to a B2B data set. We show that accurate sentiment can be extracted from the notes automatically and the notes can be sorted by relevance into different topics. We see that without clear separation topics can lack relevance to a business context.
    
[^25]: 分析音频质量对自然长篇录音在婴儿语音研究中使用的影响

    Analysing the Impact of Audio Quality on the Use of Naturalistic Long-Form Recordings for Infant-Directed Speech Research. (arXiv:2305.01965v1 [cs.CL])

    [http://arxiv.org/abs/2305.01965](http://arxiv.org/abs/2305.01965)

    分析音频质量对自然录音中婴儿语音研究的影响尚不清楚。本文探讨了音频质量对婴儿导向语音和成人导向语音分析的影响。

    

    早期语言习得的建模旨在理解婴儿如何引导他们的语言技能。建模涵盖了用于训练模型的输入数据的属性，正在测试的认知假设及其算法实现，以及用于将模型与人类数据进行比较的评估方法。最近的进展使得计算模型使用更自然的训练数据成为可能。这也激发了开发更自然的模型行为测试的动机。实现这一目标的关键步骤是开发代表性的语音数据集，其中包括婴儿在其自然环境中听到的语音。然而，这种录音的一个主要缺点是它们通常是嘈杂的，目前尚不清楚声音质量如何影响基于这些数据进行的分析和建模实验。在本文中，我们探讨了婴儿导向语音（IDS）和成人导向语音（ADS）分析的这一方面。

    Modelling of early language acquisition aims to understand how infants bootstrap their language skills. The modelling encompasses properties of the input data used for training the models, the cognitive hypotheses and their algorithmic implementations being tested, and the evaluation methodologies to compare models to human data. Recent developments have enabled the use of more naturalistic training data for computational models. This also motivates development of more naturalistic tests of model behaviour. A crucial step towards such an aim is to develop representative speech datasets consisting of speech heard by infants in their natural environments. However, a major drawback of such recordings is that they are typically noisy, and it is currently unclear how the sound quality could affect analyses and modelling experiments conducted on such data. In this paper, we explore this aspect for the case of infant-directed speech (IDS) and adult-directed speech (ADS) analysis. First, we ma
    
[^26]: NorQuAD：挪威问答数据集

    NorQuAD: Norwegian Question Answering Dataset. (arXiv:2305.01957v1 [cs.CL])

    [http://arxiv.org/abs/2305.01957](http://arxiv.org/abs/2305.01957)

    NorQuAD是用于机器阅读理解的第一个挪威问答数据集，包含4,752对手工创建的问答对，并基于该数据集对多种语言模型进行了基准测试，并将其与人类表现进行了比较。

    

    本文介绍了NorQuAD：用于机器阅读理解的第一个挪威问答数据集。该数据集包含4,752对手工创建的问答对。我们详细介绍了数据收集过程，并提供了数据集的统计信息。我们还基于数据集对几种多语言和挪威单语言模型进行了基准测试，并将其与人类表现进行了比较。该数据集将被免费提供。

    In this paper we present NorQuAD: the first Norwegian question answering dataset for machine reading comprehension. The dataset consists of 4,752 manually created question-answer pairs. We here detail the data collection procedure and present statistics of the dataset. We also benchmark several multilingual and Norwegian monolingual language models on the dataset and compare them against human performance. The dataset will be made freely available.
    
[^27]: SeqAug: 序列特征重采样技术——一种模态不可知的数据增强方法

    SeqAug: Sequential Feature Resampling as a modality agnostic augmentation method. (arXiv:2305.01954v1 [cs.CL])

    [http://arxiv.org/abs/2305.01954](http://arxiv.org/abs/2305.01954)

    SeqAug是一种模态不可知的数据增强方法，可以成功应用于单模态或多模态，通过从基础特征分布中重新采样来增强序列，并且与循环和Transformer架构兼容，取得了与最先进方法相当的结果。

    

    数据增强是提高各种机器学习应用性能的常用技术。本文提出了SeqAug，一种针对从序列中提取的特征的模态不可知的增强方法。SeqAug的核心思想是通过从基础特征分布中重新采样来增强序列。重新采样通过随机选择特征维度并沿时间轴对它们进行置换来实现。在CMU-MOSEI上的实验验证了SeqAug的模态不可知性；它可以成功地应用于单模态或多模态。我们进一步验证了它与循环和Transformer架构的兼容性，并证明了它具有与最先进结果相当的性能。

    Data augmentation is a prevalent technique for improving performance in various machine learning applications. We propose SeqAug, a modality-agnostic augmentation method that is tailored towards sequences of extracted features. The core idea of SeqAug is to augment the sequence by resampling from the underlying feature distribution. Resampling is performed by randomly selecting feature dimensions and permuting them along the temporal axis. Experiments on CMU-MOSEI verify that SeqAug is modality agnostic; it can be successfully applied to a single modality or multiple modalities. We further verify its compatibility with both recurrent and transformer architectures, and also demonstrate comparable to state-of-the-art results.
    
[^28]: TempoSum：评估抽象摘要的时间泛化能力

    TempoSum: Evaluating the Temporal Generalization of Abstractive Summarization. (arXiv:2305.01951v1 [cs.CL])

    [http://arxiv.org/abs/2305.01951](http://arxiv.org/abs/2305.01951)

    本篇论文提出了 TempoSum 抽象摘要的时间泛化能力基准，通过广泛的人类评估证明了摘要模型中存储的参数化知识对未来数据上生成的摘要有显著影响。

    

    最近，预训练语言模型在现有的抽象摘要数据集中取得了有 promising 的结果。然而，现有的摘要基准与标准的预训练语料库和微调数据集在时间上重叠。因此，预训练语言模型的强大性能可能依赖于预训练和微调过程中所记忆的参数化知识。此外，预训练语言模型所记忆的知识可能很快就过时，这会影响到它们在未来数据上的泛化性能。为了了解抽象摘要模型的时间泛化能力，本文提出了 TempoSum，一个新的基准，其中包含了从 2010 年到 2022 年的数据样本。通过广泛的人类评估，我们证明了摘要模型中存储的参数化知识对未来数据上生成的摘要的准确性有显著影响。此外，现有的准确性提高方法不能可靠地提高摘要模型在未来数据上的准确性。

    Recent pre-trained language models (PLMs) achieve promising results in existing abstractive summarization datasets. However, existing summarization benchmarks overlap in time with the standard pre-training corpora and finetuning datasets. Hence, the strong performance of PLMs may rely on the parametric knowledge that is memorized during pre-training and fine-tuning. Moreover, the knowledge memorized by PLMs may quickly become outdated, which affects the generalization performance of PLMs on future data. In this work, we propose TempoSum, a novel benchmark that contains data samples from 2010 to 2022, to understand the temporal generalization ability of abstractive summarization models. Through extensive human evaluation, we show that parametric knowledge stored in summarization models significantly affects the faithfulness of the generated summaries on future data. Moreover, existing faithfulness enhancement methods cannot reliably improve the faithfulness of summarization models on fu
    
[^29]: Doc2SoarGraph：基于语义导向分层图的富含视觉表格文档的离散推理

    Doc2SoarGraph: Discrete Reasoning over Visually-Rich Table-Text Documents with Semantic-Oriented Hierarchical Graphs. (arXiv:2305.01938v1 [cs.CL])

    [http://arxiv.org/abs/2305.01938](http://arxiv.org/abs/2305.01938)

    本文提出了 Doc2SoarGraph 框架，利用语义导向分层图结构中元素之间的差异和相关性，在富含视觉表格文本的TAT-DQA问题下实现了离散推理，表现出了最佳的实验结果。

    

    近两年来，对于表格文本文档（例如财务报告）的离散推理越来越受到关注。现有的工作大多通过手动选择和转换文档页面到结构化的表格和段落来简化这一挑战，从而阻碍其实际应用。在这项工作中，我们探究了一种更为现实的问题设置，即以 TAT-DQA 的形式回答富含视觉表格文本的问题。具体而言，我们提出了一种新颖的 Doc2SoarGraph 框架，通过利用语义导向分层图结构中不同元素之间的差异和相关性，提高了其离散推理能力。我们对 TAT-DQA 数据集进行了广泛的实验，结果显示，我们的提出的框架在测试集上的精确匹配（EM）和 F1 得分方面分别比最佳基线模型分别提高了 17.73% 和 16.91%，实现了新的最先进技术水平。

    Discrete reasoning over table-text documents (e.g., financial reports) gains increasing attention in recent two years. Existing works mostly simplify this challenge by manually selecting and transforming document pages to structured tables and paragraphs, hindering their practical application. In this work, we explore a more realistic problem setting in the form of TAT-DQA, i.e. to answer the question over a visually-rich table-text document. Specifically, we propose a novel Doc2SoarGraph framework with enhanced discrete reasoning capability by harnessing the differences and correlations among different elements (e.g., quantities, dates) of the given question and document with Semantic-oriented hierarchical Graph structures. We conduct extensive experiments on TAT-DQA dataset, and the results show that our proposed framework outperforms the best baseline model by 17.73% and 16.91% in terms of Exact Match (EM) and F1 score respectively on the test set, achieving the new state-of-the-art
    
[^30]: 大型语言模型能否替代人类评估？

    Can Large Language Models Be an Alternative to Human Evaluations?. (arXiv:2305.01937v1 [cs.CL])

    [http://arxiv.org/abs/2305.01937](http://arxiv.org/abs/2305.01937)

    本文研究了大型语言模型是否能够替代人类评估。实验结果表明在两个NLP任务上，使用LLM评估和人类评估得到的结果是一致的。

    

    人类评估对于评估由机器学习模型生成或由人类编写的文本质量是必不可少和不可避免的。然而，人类评估非常难以重现，其质量也是非常不稳定的，这阻碍了不同自然语言处理（NLP）模型和算法之间的公平比较。最近，当只提供任务说明时，大型语言模型（LLMs）在未见过的任务上表现出了异常的性能。在本文中，我们探讨了LLMs的这种能力能否用作人类评估的替代品。我们向LLMs提供与进行人类评估相同的说明、待评估样本和问题，并要求LLMs对这些问题生成响应；我们将其称为LLM的评估。我们使用人类评估和LLM评估来评估两个NLP任务中的文本：开放式故事生成和对抗性攻击。我们表明LLM评估的结果是一致的。

    Human evaluation is indispensable and inevitable for assessing the quality of texts generated by machine learning models or written by humans. However, human evaluation is very difficult to reproduce and its quality is notoriously unstable, hindering fair comparisons among different natural language processing (NLP) models and algorithms. Recently, large language models (LLMs) have demonstrated exceptional performance on unseen tasks when only the task instructions are provided. In this paper, we explore if such an ability of the LLMs can be used as an alternative to human evaluation. We present the LLMs with the exact same instructions, samples to be evaluated, and questions used to conduct human evaluation, and then ask the LLMs to generate responses to those questions; we dub this LLM evaluation. We use human evaluation and LLM evaluation to evaluate the texts in two NLP tasks: open-ended story generation and adversarial attacks. We show that the result of LLM evaluation is consiste
    
[^31]: 零样本关系三元组抽取的生成式元学习

    Generative Meta-Learning for Zero-Shot Relation Triplet Extraction. (arXiv:2305.01920v1 [cs.CL])

    [http://arxiv.org/abs/2305.01920](http://arxiv.org/abs/2305.01920)

    该论文提出了一种生成式元学习框架，通过任务感知的生成式模型和三种针对典型元学习范畴的方法，提高了零样本关系三元组抽取任务的泛化能力并达到了最佳表现。

    

    零样本关系三元组抽取任务旨在从一个包含未见过关系类型的文本中提取关系三元组。比较有代表性的工作采用预训练的生成式模型为新关系生成合成样本。然而，当前的生成式模型在训练中缺乏对于模型泛化到不同任务的优化过程，因此具有有限的泛化能力。因此，我们提出了一种新颖的生成式元学习框架，利用元学习的“学习如何学习”的能力提高生成式模型的泛化能力。具体而言，我们首先设计了一个任务感知的生成式模型，它可以通过在多个任务上强制进行优化过程来学习一般性知识。基于此，我们提出了三种针对三类典型元学习范畴的生成式元学习方法。广泛的实验结果表明，我们的框架在零样本关系三元组抽取任务上实现了新的最佳表现。

    The zero-shot relation triplet extraction (ZeroRTE) task aims to extract relation triplets from a piece of text with unseen relation types. The seminal work adopts the pre-trained generative model to generate synthetic samples for new relations. However, current generative models lack the optimization process of model generalization on different tasks during training, and thus have limited generalization capability. For this reason, we propose a novel generative meta-learning framework which exploits the `learning-to-learn' ability of meta-learning to boost the generalization capability of generative models. Specifically, we first design a task-aware generative model which can learn the general knowledge by forcing the optimization process to be conducted across multiple tasks. Based on it, we then present three generative meta-learning approaches designated for three typical meta-learning categories. Extensive experimental results demonstrate that our framework achieves a new state-of
    
[^32]: 改进句子嵌入的对比学习方法，利用人工智能反馈

    Improving Contrastive Learning of Sentence Embeddings from AI Feedback. (arXiv:2305.01918v1 [cs.CL])

    [http://arxiv.org/abs/2305.01918](http://arxiv.org/abs/2305.01918)

    本文提出了一种利用人工智能反馈改进句子嵌入对比学习方法的方式，可以提高对比学习样本对的质量，并结合人类反馈来提供更好的监督信号。

    

    对比学习已成为自然语言处理中句子嵌入学习中的流行方法。然而，自然语言的离散性使得通过数据增强方法生成的正负样本对的质量难以保证。虽然有监督的对比学习可以通过人类反馈标签生成更准确的样本对，但仍缺乏细粒度的训练信号。本文提出了一种基于AI反馈来改进句子嵌入对比学习的方法（CLAIF），利用大型预训练语言模型 (LLMs) 的AI反馈构建带有细粒度样本相似度分数的样本对，以改进对比学习。此外，我们结合人工反馈和AI反馈为对比学习中的句子嵌入提供更好的监督信号。实验结果表明，我们的方法达到了最先进的水平。

    Contrastive learning has become a popular approach in natural language processing, particularly for the learning of sentence embeddings. However, the discrete nature of natural language makes it difficult to ensure the quality of positive and negative sample pairs generated through data augmentation methods. Although supervised contrastive learning can produce more accurate sample pairs with human feedback labels, it still lacks fine-grained training signals. In this paper, we propose to improve \textbf{C}ontrastive \textbf{L}earning of sentence embeddings from \textbf{AI} \textbf{F}eedback \textbf{(CLAIF)}. Our method utilizes AI feedback from large pre-trained language models (LLMs) to construct sample pairs with fine-grained sample similarity scores to improve contrastive learning. Besides, we combine human feedback and AI feedback to provide better supervision signals for supervised contrastive learning of sentence embeddings. Experimental results show that our method achieves stat
    
[^33]: 基于因果干预的小样本命名实体识别

    Causal Interventions-based Few-Shot Named Entity Recognition. (arXiv:2305.01914v1 [cs.CL])

    [http://arxiv.org/abs/2305.01914](http://arxiv.org/abs/2305.01914)

    本文提出了一种基于因果干预的小样本命名实体识别方法，该方法使用增量学习来介入原型以避免灾难性忘却问题，实现了在不同基准测试上新的最优结果。

    

    小样本命名实体识别系统旨在基于少量标记样本，识别新类别的实体。在小样本情况下，与大量样本任务相比，系统容易出现过度拟合的问题。小样本学习中的过度拟合主要是由少样本选择偏差导致的虚假相关性引起的。为了缓解小样本命名实体识别中虚假相关性的问题，本文提出了一种基于因果干预的小样本命名实体识别方法。该方法基于原型网络，在训练期间通过后门调整介入上下文和原型。特别是，介入一个样本场景的上下文非常困难，因此我们通过增量学习来介入原型，这也可以避免灾难性忘却的问题。我们在不同的基准测试上进行了实验，结果表明该方法实现了新的最优结果（对于所有任务，平均能够实现29％的绝对提高和12％的提高）。

    Few-shot named entity recognition (NER) systems aims at recognizing new classes of entities based on a few labeled samples. A significant challenge in the few-shot regime is prone to overfitting than the tasks with abundant samples. The heavy overfitting in few-shot learning is mainly led by spurious correlation caused by the few samples selection bias. To alleviate the problem of the spurious correlation in the few-shot NER, in this paper, we propose a causal intervention-based few-shot NER method. Based on the prototypical network, the method intervenes in the context and prototype via backdoor adjustment during training. In particular, intervening in the context of the one-shot scenario is very difficult, so we intervene in the prototype via incremental learning, which can also avoid catastrophic forgetting. Our experiments on different benchmarks show that our approach achieves new state-of-the-art results (achieving up to 29% absolute improvement and 12% on average for all tasks).
    
[^34]: 小样本事件检测：经验研究和统一视角

    Few-shot Event Detection: An Empirical Study and a Unified View. (arXiv:2305.01901v1 [cs.CL])

    [http://arxiv.org/abs/2305.01901](http://arxiv.org/abs/2305.01901)

    本文从两个实用的设置出发，分析比较了十种代表性的小样本事件检测方法，归纳总结出了原型方法的性能优越性，并在此基础上提出了一种简单且有效的方法。

    

    小样本事件检测 (ED) 已经被广泛研究，然而这也带来了明显的差异，例如各种动机、任务和实验设置，这些差异妨碍了模型的理解和未来进展。本文提出了一项彻底的经验研究、一个ED模型的统一视角和一个更好的统一基准线。为了公平评估，我们选择了两个实用的设置：低资源设置来评估泛化能力和类转移设置来评估可转移性。我们比较了三个数据集上的十种代表性方法，这些方法大致被分为基于提示和基于原型的模型进行详细分析。为了调查基于原型方法的优越性能，我们分解了设计并建立了一个统一框架。基于此，我们不仅提出了一种简单而有效的方法（例如在低资源设置下获得2.7％F1收益），而且为未来的研究提供了许多有价值的研究见解。

    Few-shot event detection (ED) has been widely studied, while this brings noticeable discrepancies, e.g., various motivations, tasks, and experimental settings, that hinder the understanding of models for future progress. This paper presents a thorough empirical study, a unified view of ED models, and a better unified baseline. For fair evaluation, we choose two practical settings: low-resource setting to assess generalization ability and class-transfer setting for transferability. We compare ten representative methods on three datasets, which are roughly grouped into prompt-based and prototype-based models for detailed analysis. To investigate the superior performance of prototype-based methods, we break down the design and build a unified framework. Based on that, we not only propose a simple yet effective method (e.g., 2.7% F1 gains under low-resource setting) but also offer many valuable research insights for future research.
    
[^35]: SCOTT: 自我一致性思路串提炼

    SCOTT: Self-Consistent Chain-of-Thought Distillation. (arXiv:2305.01879v1 [cs.CL])

    [http://arxiv.org/abs/2305.01879](http://arxiv.org/abs/2305.01879)

    本研究提出了一种忠实的知识蒸馏方法，从比教师模型大数倍的模型中学习一个小的、自我一致的思路串模型。实验结果表明，该方法有助于证明决策并提高性能，特别是在较小的语言模型中。

    

    超出一定规模的大型语言模型表现出通过一系列连续的思考过程获得自由文本理由的突出能力。虽然思路串可以显著提高性能，但仅在足够大的语言模型中才能观察到这种收益。更令人担忧的是，生成的理由很少保证与语言模型的预测保持一致或者忠实地证明决策。在这项工作中，我们提出了一种忠实的知识蒸馏方法，从比教师模型大数倍的模型中学习一个小的、自我一致的思路串模型。为了形成更好的监督，我们通过对比解码引导教师模型产生支持正确答案的理由，这鼓励教师模型生成的token只在考虑到答案时才更加可信。为了保证忠实的蒸馏，我们使用教师生成的理由来学习一个学生模型，该模型具有反事实推理目标，即根据具有自我一致性且忠实于教师预测的思路串理由预测决策。在自然语言推理和抽象摘要基准测试上，我们证明了学生模型中的自我一致性有助于证明决策并提高性能，特别是在较小的语言模型中。

    Large language models (LMs) beyond a certain scale, demonstrate the emergent capability of generating free-text rationales for their predictions via chain-of-thought (CoT) prompting. While CoT can yield dramatically improved performance, such gains are only observed for sufficiently large LMs. Even more concerning, there is little guarantee that the generated rationales are consistent with LM's predictions or faithfully justify the decisions. In this work, we propose a faithful knowledge distillation method to learn a small, self-consistent CoT model from a teacher model that is orders of magnitude larger. To form better supervision, we elicit rationales supporting the gold answers from a large LM (teacher) by contrastive decoding, which encourages the teacher to generate tokens that become more plausible only when the answer is considered. To ensure faithful distillation, we use the teacher-generated rationales to learn a student LM with a counterfactual reasoning objective, which pre
    
[^36]: 基于因果感知的知识引导句子提取

    Causality-aware Concept Extraction based on Knowledge-guided Prompting. (arXiv:2305.01876v1 [cs.CL])

    [http://arxiv.org/abs/2305.01876](http://arxiv.org/abs/2305.01876)

    该论文提出了一种基于因果感知的知识引导提示方法，将其作为干预器装备到基于预训练语言模型的句子提取器中，以缓解概念偏差。在代表性的多语言KG数据集上进行广泛实验，获得了最先进的结果。

    

    概念有助于自然语言理解，但现有的知识图谱（KG）中远未完善。最近，预训练语言模型（PLM）已被广泛用于基于文本的概念提取（CE）。然而，PLM往往从大量语料库的共现关联中进行预训练知识挖掘，而非Token之间的真实因果关系。因此，预训练知识混淆了PLM，导致提取基于虚假共现相关性的有偏概念，不可避免地导致低精度。本文通过结构因果模型（SCM）提出了一种知识引导提示方法，将其作为干预器装备到基于PLM的提取器中，以减轻概念偏差。提示采用现有KG中的给定实体主题来缓解实体和有偏概念之间的虚假共现相关性。我们在代表性的多语言KG数据集上进行了广泛的实验，证明了我们提出的提示显著改进了提取性能，并达到了最先进的结果。

    Concepts benefit natural language understanding but are far from complete in existing knowledge graphs (KGs). Recently, pre-trained language models (PLMs) have been widely used in text-based concept extraction (CE). However, PLMs tend to mine the co-occurrence associations from massive corpus as pre-trained knowledge rather than the real causal effect between tokens.As a result, the pre-trained knowledge confounds PLMs to extract biased concepts based on spurious co-occurrence correlations, inevitably resulting in low precision. In this paper, through the lens of a Structural Causal Model (SCM), we propose equipping the PLM-based extractor with a knowledge-guided prompt as an intervention to alleviate concept bias. The prompt adopts the topic of the given entity from the existing knowledge in KGs to mitigate the spurious co-occurrence correlations between entities and biased concepts. Our extensive experiments on representative multilingual KG datasets justify that our proposed prompt 
    
[^37]: GPTutor: 一种由ChatGPT驱动的编程工具，用于程序代码解释

    GPTutor: a ChatGPT-powered programming tool for code explanation. (arXiv:2305.01863v1 [cs.HC])

    [http://arxiv.org/abs/2305.01863](http://arxiv.org/abs/2305.01863)

    本文介绍了一种名为GPTutor的ChatGPT动力编程工具，它是一个使用ChatGPT API的Visual Studio Code扩展，通过设计提示词，可以对所选代码进行精简、准确的解释。

    

    学习新的编程技能需要个性化指导。随着ChatGPT API等高级自然语言生成模型的出现，现在有可能创建一个方便的、个性化的AI编程教育辅导系统。本文介绍了一种名为GPTutor的ChatGPT动力编程工具，它是一个使用ChatGPT API的Visual Studio Code扩展，用于提供编程代码解释。

    Learning new programming skills requires tailored guidance. With the emergence of advanced Natural Language Generation models like the ChatGPT API, there is now a possibility of creating a convenient and personalized tutoring system with AI for computer science education. This paper presents GPTutor, a ChatGPT-powered programming tool, which is a Visual Studio Code extension using the ChatGPT API to provide programming code explanations. By integrating Visual Studio Code API, GPTutor can comprehensively analyze the provided code by referencing the relevant source codes. As a result, GPTutor can use designed prompts to explain the selected code with a pop-up message. GPTutor is now published at the Visual Studio Code Extension Marketplace, and its source code is openly accessible on GitHub. Preliminary evaluation indicates that GPTutor delivers the most concise and accurate explanations compared to vanilla ChatGPT and GitHub Copilot. Moreover, the feedback from students and teachers ind
    
[^38]: 后放弃：关于在问答中可靠地重新尝试放弃实例的研究

    Post-Abstention: Towards Reliably Re-Attempting the Abstained Instances in QA. (arXiv:2305.01812v1 [cs.CL])

    [http://arxiv.org/abs/2305.01812](http://arxiv.org/abs/2305.01812)

    本文研究再次尝试放弃实例的后期处理方法，以提高系统的覆盖范围而不显着牺牲准确性。

    

    尽管自然语言处理取得了显著进展，但即使是最先进的模型也经常做出错误的预测。这些预测会影响系统的可靠性，并限制它们在实际应用中的广泛采用。选择性预测通过使模型能够在其预测可能不正确时放弃回答来部分地解决了上述问题。虽然选择性预测具有优势，但它留下了一个关键问题：“放弃后该怎么办”？为此，我们提出了一项关于“后放弃”的研究，该任务允许重新尝试放弃实例，以增加系统的“覆盖率”而不显着牺牲其“准确性”。我们首先提供了该任务的数学公式，然后探讨了几种解决方法。对11个问答数据集进行的全面实验表明，这些方法导致了相当大的风险改进——后放弃任务的性能指标。

    Despite remarkable progress made in natural language processing, even the state-of-the-art models often make incorrect predictions. Such predictions hamper the reliability of systems and limit their widespread adoption in real-world applications. 'Selective prediction' partly addresses the above concern by enabling models to abstain from answering when their predictions are likely to be incorrect. While selective prediction is advantageous, it leaves us with a pertinent question 'what to do after abstention'. To this end, we present an explorative study on 'Post-Abstention', a task that allows re-attempting the abstained instances with the aim of increasing 'coverage' of the system without significantly sacrificing its 'accuracy'. We first provide mathematical formulation of this task and then explore several methods to solve it. Comprehensive experiments on 11 QA datasets show that these methods lead to considerable risk improvements -- performance metric of the Post-Abstention task -
    
[^39]: KEPLET: 一种带有主题实体感知的知识增强预训练语言模型

    KEPLET: Knowledge-Enhanced Pretrained Language Model with Topic Entity Awareness. (arXiv:2305.01810v1 [cs.CL])

    [http://arxiv.org/abs/2305.01810](http://arxiv.org/abs/2305.01810)

    本文提出了一种知识增强预训练语言模型，即KEPLET，在预训练语料中加入主题实体感知，从而改善了实体交互和词语语义表示。

    

    近年来，预训练语言模型（PLM）通过在未结构化文本语料上进行预训练，然后在下游任务上进行微调以显示其优越性。在实体丰富的文本资源（如维基百科）中，知识增强的PLM（KEPLMs）在预训练过程中将标记与所提及的实体之间的交互结合起来，因此在实体中心任务（如实体链接和关系分类）上更有效。虽然传统KEPLM在某种程度上利用了维基百科的丰富结构，但它们仍然忽略了每个维基百科页面围绕一个主题实体的独特布局（由页面URL标识并在页面标题中显示）。本文证明，如果不加入主题实体，KEPLM将导致实体交互不足和偏差（关系）词语语义。因此，我们提出了KEPLET，一种新颖的带有主题实体感知的知识增强预训练语言模型。通过一种端到端的方式，KEPLET确定预训练语料中的主题实体，并改进了KEPLM的实体交互和词语语义表示。

    In recent years, Pre-trained Language Models (PLMs) have shown their superiority by pre-training on unstructured text corpus and then fine-tuning on downstream tasks. On entity-rich textual resources like Wikipedia, Knowledge-Enhanced PLMs (KEPLMs) incorporate the interactions between tokens and mentioned entities in pre-training, and are thus more effective on entity-centric tasks such as entity linking and relation classification. Although exploiting Wikipedia's rich structures to some extent, conventional KEPLMs still neglect a unique layout of the corpus where each Wikipedia page is around a topic entity (identified by the page URL and shown in the page title). In this paper, we demonstrate that KEPLMs without incorporating the topic entities will lead to insufficient entity interaction and biased (relation) word semantics. We thus propose KEPLET, a novel Knowledge-Enhanced Pre-trained LanguagE model with Topic entity awareness. In an end-to-end manner, KEPLET identifies where to a
    
[^40]: 通过双文本-图像提示的多模态过程规划

    Multimodal Procedural Planning via Dual Text-Image Prompting. (arXiv:2305.01795v1 [cs.CL])

    [http://arxiv.org/abs/2305.01795](http://arxiv.org/abs/2305.01795)

    该论文提出了一个名为MPP的任务，用于使用文本和图像生成计划，帮助人类完成任务。为了解决跨模态的计划的可靠性问题，该论文提出了一种双模态提示方法TIP，它利用了大型语言模型和文本到图像生成模型的能力。

    

    实体代理已经在遵循人类指令完成任务方面取得了杰出表现。然而，利用文本和图像提供指导以帮助人类完成任务的潜力仍未得到充分探索。为了揭示这种能力，我们提出了多模态过程规划（MPP）任务，其中模型给出了高级目标并生成配对的文本-图像步骤的计划，提供比单模态计划更丰富和信息丰富的指导。MPP的关键挑战是确保跨模态的计划在信息性，时间连贯性和准确性方面的可靠性。为了解决这个问题，我们提出了文本-图像提示（TIP），一种双模态提示方法，它同时利用大型语言模型（LLM）中的零-shot推理能力和基于扩散的模型中令人信服的文本到图像生成能力。TIP使用文本-图像桥和图像-文本桥改善了双模态交互，使LLMs引导文本和图像之间的转换。

    Embodied agents have achieved prominent performance in following human instructions to complete tasks. However, the potential of providing instructions informed by texts and images to assist humans in completing tasks remains underexplored. To uncover this capability, we present the multimodal procedural planning (MPP) task, in which models are given a high-level goal and generate plans of paired text-image steps, providing more complementary and informative guidance than unimodal plans. The key challenges of MPP are to ensure the informativeness, temporal coherence,and accuracy of plans across modalities. To tackle this, we propose Text-Image Prompting (TIP), a dual-modality prompting method that jointly leverages zero-shot reasoning ability in large language models (LLMs) and compelling text-to-image generation ability from diffusion-based models. TIP improves the interaction in the dual modalities using Text-to-Image Bridge and Image-to-Text Bridge, allowing LLMs to guide the textua
    
[^41]: 视觉与定义相遇：融合词义信息的无监督视觉词义消歧

    Vision Meets Definitions: Unsupervised Visual Word Sense Disambiguation Incorporating Gloss Information. (arXiv:2305.01788v1 [cs.CL])

    [http://arxiv.org/abs/2305.01788](http://arxiv.org/abs/2305.01788)

    本文提出了一种无监督的视觉词义消歧方法，通过引入外部词汇知识库的词义信息来解决原来图像-文本匹配模型中的多义词问题。采用贝叶斯推断来加入词义定义，并通过与上下文相关的 GPT-3 定义生成方法，成功解决了词典外问题。

    

    视觉词义消歧是一项任务，旨在找到最准确地描述给定上下文中目标词正确意义的图像。以往的图像-文本匹配模型往往受到词义多义性的影响。本文介绍了一种无监督的视觉词义消歧方法，该方法使用了外部词汇知识库的词汇信息，特别是词义定义。具体而言，我们建议在没有提供答案的词义信息时，采用贝叶斯推断来加入词义定义。此外，为了改进词典外问题，我们提出了一种与上下文相关的GPT-3定义生成方法。实验结果表明，我们的基于贝叶斯推断的方法明显提高了视觉词义消歧的性能。此外，我们的上下文相关定义生成方法在词典外例子上取得了显著的性能提升，表现优于现有的定义生成方法。

    Visual Word Sense Disambiguation (VWSD) is a task to find the image that most accurately depicts the correct sense of the target word for the given context. Previously, image-text matching models often suffered from recognizing polysemous words. This paper introduces an unsupervised VWSD approach that uses gloss information of an external lexical knowledge-base, especially the sense definitions. Specifically, we suggest employing Bayesian inference to incorporate the sense definitions when sense information of the answer is not provided. In addition, to ameliorate the out-of-dictionary (OOD) issue, we propose a context-aware definition generation with GPT-3. Experimental results show that the VWSD performance significantly increased with our Bayesian inference-based approach. In addition, our context-aware definition generation achieved prominent performance improvement in OOD examples exhibiting better performance than the existing definition generation method. We will publish source 
    
[^42]: SLTUNET：一种简单的统一模型进行手语翻译

    SLTUNET: A Simple Unified Model for Sign Language Translation. (arXiv:2305.01778v1 [cs.CL])

    [http://arxiv.org/abs/2305.01778](http://arxiv.org/abs/2305.01778)

    SLTUNET是一种简单的统一模型，为多个手语翻译任务提供支持。通过联合建模不同的任务，SLTUNET可以探索跨任务相关性以缩小模态差距，并借助外部数据进行优化，实现了竞争甚至领先的性能。

    

    尽管最近神经模型在手语翻译（SLT）方面取得了成功，但由于数据稀缺性和手语视频与文本之间的模态差距，翻译质量仍然落后于口语语言。为了解决这两个问题，我们研究了跨模态表示共享的策略，提出了SLTUNET，这是一个设计用于支持多个SLT相关任务的简单统一神经模型，例如手语到手语编码、手语编码到文本、手语到文本翻译。联合建模不同任务赋予SLTUNET探索有助于缩小模态差距的跨任务相关性的能力。此外，这使我们能够利用外部资源的知识，例如用于口语机器翻译（MT）的丰富平行数据。我们通过实验证明，SLTUNET在增加MT数据并配备一组优化技术的情况下，可以在PHOENIX-2014T和CSL-Daily上实现竞争甚至领先的性能。

    Despite recent successes with neural models for sign language translation (SLT), translation quality still lags behind spoken languages because of the data scarcity and modality gap between sign video and text. To address both problems, we investigate strategies for cross-modality representation sharing for SLT. We propose SLTUNET, a simple unified neural model designed to support multiple SLTrelated tasks jointly, such as sign-to-gloss, gloss-to-text and sign-to-text translation. Jointly modeling different tasks endows SLTUNET with the capability to explore the cross-task relatedness that could help narrow the modality gap. In addition, this allows us to leverage the knowledge from external resources, such as abundant parallel data used for spoken-language machine translation (MT). We show in experiments that SLTUNET achieves competitive and even state-of-the-art performance on PHOENIX-2014T and CSL-Daily when augmented with MT data and equipped with a set of optimization techniques. 
    
[^43]: 受心理学启发的因果提示语

    Psychologically-Inspired Causal Prompts. (arXiv:2305.01764v1 [cs.CL])

    [http://arxiv.org/abs/2305.01764](http://arxiv.org/abs/2305.01764)

    本文提出了三个因果提示语，涵盖了情感分类任务中人类的心理过程。这些提示语可以用来产生更准确和可解释的模型预测。

    

    NLP数据集不仅仅含有输入输出对，还包含输入和输出变量之间的因果关系。本文以情感分类为例，探讨评论（X）和情感（Y）之间的因果关系。心理学研究表明，语言可以影响情绪，当一个人首次进行评分并在评论中进行自我合理化时（情感引起评论，即Y->X），与首先描述自己的经历并权衡利弊以做出最后评分时（评论引起情感，即X->Y），会引发不同的心理过程。此外，如果评注者通过心智理论（ToM）推断用户的原始评分，则这也是完全不同的心理过程（评论引起评分，即X-ToM-> Y）。本文将这三种情感分类的人类心理过程的因果机制转化为三个提示语，并在情感分类任务中应用这些提示语，以产生更准确和可解释的模型预测。

    NLP datasets are richer than just input-output pairs; rather, they carry causal relations between the input and output variables. In this work, we take sentiment classification as an example and look into the causal relations between the review (X) and sentiment (Y). As psychology studies show that language can affect emotion, different psychological processes are evoked when a person first makes a rating and then self-rationalizes their feeling in a review (where the sentiment causes the review, i.e., Y -> X), versus first describes their experience, and weighs the pros and cons to give a final rating (where the review causes the sentiment, i.e., X -> Y ). Furthermore, it is also a completely different psychological process if an annotator infers the original rating of the user by theory of mind (ToM) (where the review causes the rating, i.e., X -ToM-> Y ). In this paper, we verbalize these three causal mechanisms of human psychological processes of sentiment classification into three
    
[^44]: 演讲者匿名化对情感语音的影响评估

    Evaluation of Speaker Anonymization on Emotional Speech. (arXiv:2305.01759v1 [eess.AS])

    [http://arxiv.org/abs/2305.01759](http://arxiv.org/abs/2305.01759)

    本文研究了VoicePrivacy 2020 Challenge中演讲者匿名化对情感语音的影响，并发现其未能有效地保护演讲者的隐私。

    

    语音数据携带着个人的信息，如演讲者的身份和情感状态。这些属性可能被用于恶意目的。随着虚拟助手的发展，出现了新一代的隐私威胁。当前的研究已经解决了保护语音隐私的话题，其中之一是VoicePrivacy倡议，旨在促进为语音技术开发隐私保护工具。VoicePrivacy 2020挑战赛（VPC）选定的任务是演讲者匿名化。目标是隐藏源演讲者的身份，同时保留语言信息。VPC的基准线使用了语音转换。本文研究了VPC基准线系统对语音话语中情感信息的影响。按照攻击者对匿名化系统的了解，执行了评估。我们的研究结果表明，VPC基准线系统未能有效地匿名化语音中的情感信息，这可能会对演讲者的隐私造成潜在威胁。

    Speech data carries a range of personal information, such as the speaker's identity and emotional state. These attributes can be used for malicious purposes. With the development of virtual assistants, a new generation of privacy threats has emerged. Current studies have addressed the topic of preserving speech privacy. One of them, the VoicePrivacy initiative aims to promote the development of privacy preservation tools for speech technology. The task selected for the VoicePrivacy 2020 Challenge (VPC) is about speaker anonymization. The goal is to hide the source speaker's identity while preserving the linguistic information. The baseline of the VPC makes use of a voice conversion. This paper studies the impact of the speaker anonymization baseline system of the VPC on emotional information present in speech utterances. Evaluation is performed following the VPC rules regarding the attackers' knowledge about the anonymization system. Our results show that the VPC baseline system does n
    
[^45]: 基于少样本背景学习的知识库问答

    Few-shot In-context Learning for Knowledge Base Question Answering. (arXiv:2305.01750v1 [cs.CL])

    [http://arxiv.org/abs/2305.01750](http://arxiv.org/abs/2305.01750)

    该论文提出了KB-BINDER框架，通过少量的上下文演示实现了在多个知识库问答数据集上的背景学习，大大提高了KBQA问题的可解性。

    

    知识库问答被认为是一个难以解决的问题，因为需要应对各种可能的自然语言问题。此外，不同知识库架构项之间的异构性通常需要针对不同的知识库问答（KBQA）数据集进行专门的训练。为了处理多种KBQA数据集上的问题，我们提出了KB-BINDER，该框架可以进行少量样本的背景学习，并将不同的KBQA数据集统一。首先，KB-BINDER利用像Codex这样的大型语言模型通过模仿少量演示来生成特定问题的逻辑形式作为草稿。其次，KB-BINDER基于知识库来绑定生成的草稿至可执行形式，通过BM25分数匹配。在四个公开的异构KBQA数据集上的实验结果表明，KB-BINDER可以在少量上下文演示的情况下取得强大的性能，在某些情况下超过了最先进的方法。

    Question answering over knowledge bases is considered a difficult problem due to the challenge of generalizing to a wide variety of possible natural language questions. Additionally, the heterogeneity of knowledge base schema items between different knowledge bases often necessitates specialized training for different knowledge base question-answering (KBQA) datasets. To handle questions over diverse KBQA datasets with a unified training-free framework, we propose KB-BINDER, which for the first time enables few-shot in-context learning over KBQA tasks. Firstly, KB-BINDER leverages large language models like Codex to generate logical forms as the draft for a specific question by imitating a few demonstrations. Secondly, KB-BINDER grounds on the knowledge base to bind the generated draft to an executable one with BM25 score matching. The experimental results on four public heterogeneous KBQA datasets show that KB-BINDER can achieve a strong performance with only a few in-context demonstr
    
[^46]: DiffuSum：基于扩散增强的摘要提取方法

    DiffuSum: Generation Enhanced Extractive Summarization with Diffusion. (arXiv:2305.01735v1 [cs.CL])

    [http://arxiv.org/abs/2305.01735](http://arxiv.org/abs/2305.01735)

    本文提出了一种新的基于扩散模型的摘要提取方法DiffuSum，并且在多个数据集上实现了最先进的抽取结果。

    

    抽取式摘要旨在通过直接从源文件中提取句子来形成摘要。本文提出了DiffuSum，一种基于扩散模型的新范式，通过直接生成所需的摘要句子表示，并基于句子表示匹配提取句子。此外，DiffuSum共同优化了对比句子编码器和匹配损失，用于句子表示对齐，以及用于表示多样性的多类对比损失。实验结果表明，DiffuSum在CNN/DailyMail数据集上实现了新的最先进的抽取结果，在ROUGE分数方面达到了 $44.83/22.56/40.56$。对两个具有不同摘要长度的数据集进行的实验也证明了DiffuSum的有效性。我们的框架的强大性能表明了适应当前情况的巨大潜力。

    Extractive summarization aims to form a summary by directly extracting sentences from the source document. Existing works mostly formulate it as a sequence labeling problem by making individual sentence label predictions. This paper proposes DiffuSum, a novel paradigm for extractive summarization, by directly generating the desired summary sentence representations with diffusion models and extracting sentences based on sentence representation matching. In addition, DiffuSum jointly optimizes a contrastive sentence encoder with a matching loss for sentence representation alignment and a multi-class contrastive loss for representation diversity. Experimental results show that DiffuSum achieves the new state-of-the-art extractive results on CNN/DailyMail with ROUGE scores of $44.83/22.56/40.56$. Experiments on the other two datasets with different summary lengths also demonstrate the effectiveness of DiffuSum. The strong performance of our framework shows the great potential of adapting g
    
[^47]: 利用有监督、零样本和少样本应用进行立场检测

    Stance Detection With Supervised, Zero-Shot, and Few-Shot Applications. (arXiv:2305.01723v1 [cs.CL])

    [http://arxiv.org/abs/2305.01723](http://arxiv.org/abs/2305.01723)

    本文提出了三种不同的方法进行立场检测：有监督分类、零样本分类与NLI分类器和上下文学习。零样本和少样本语言分类器可以替代人工标签者，并演示了如何运用它们来执行立场检测。

    

    立场检测是识别作者对一个主题的信仰的过程。研究人员通常依赖情感分析来完成这一任务。然而，最近的研究表明情感分析只与立场存在松散的相关性，如果有的话。本文通过精确定义立场检测任务、提供任务的普适框架，并针对执行立场检测的三种不同方法（有监督分类、零样本分类与NLI分类器、上下文学习）提出新的研究方法以推进文本分析方式。在此过程中，本文说明了如何使用零样本和少样本语言分类器替代人工标签者完成各种任务，并讨论了它们的应用和局限性与有监督分类器不同。最后，本文通过复制Block Jr等人 (2022)的方法，演示了零样本立场检测的应用。

    Stance detection is the identification of an author's beliefs about a subject from a document. Researchers widely rely on sentiment analysis to accomplish this. However, recent research has show that sentiment analysis is only loosely correlated with stance, if at all. This paper advances methods in text analysis by precisely defining the task of stance detection, providing a generalized framework for the task, and then presenting three distinct approaches for performing stance detection: supervised classification, zero-shot classification with NLI classifiers, and in-context learning. In doing so, I demonstrate how zero-shot and few-shot language classifiers can replace human labelers for a variety of tasks and discuss how their application and limitations differ from supervised classifiers. Finally, I demonstrate an application of zero-shot stance detection by replicating Block Jr et al. (2022).
    
[^48]: 通过可逆神经网络学习解释的非交互语义空间

    Learning Disentangled Semantic Spaces of Explanations via Invertible Neural Networks. (arXiv:2305.01713v1 [cs.CL])

    [http://arxiv.org/abs/2305.01713](http://arxiv.org/abs/2305.01713)

    本文介绍了一种使用可逆神经网络将BERT-GPT2自动编码器的隐藏空间转换为更可分离的语义空间的方法，实验结果表明此方法可以改进模型的可解释性和可控性，并取得了比最先进模型更好的性能表现。

    

    在细化连续空间的句子表征上进行解耦可以在定位明确发生的生成因素的同时，改进可解释性和语义控制，这为基于神经的语言模型赋予了一些符号模型的优势，同时保持其灵活性。 本文提出了一种方法，通过使用可逆神经网络（INN）将BERT-GPT2自动编码器的隐藏空间转换为更可分离的语义空间来解除编码的隐藏空间。实验结果表明，与最新的最先进模型相比，INN能够将分布式隐藏空间转换为更好的语义上解耦的潜在空间，从而产生更好的可解释性和可控性。

    Disentangling sentence representations over continuous spaces can be a critical process in improving interpretability and semantic control by localising explicit generative factors. Such process confers to neural-based language models some of the advantages that are characteristic of symbolic models, while keeping their flexibility. This work presents a methodology for disentangling the hidden space of a BERT-GPT2 autoencoder by transforming it into a more separable semantic space with the support of a flow-based invertible neural network (INN). Experimental results indicate that the INN can transform the distributed hidden space into a better semantically disentangled latent space, resulting in better interpretability and controllability, when compared to recent state-of-the-art models.
    
[^49]: 不停止预训练？让基于提示的微调更加强大

    Don't Stop Pretraining? Make Prompt-based Fine-tuning Powerful Learner. (arXiv:2305.01711v1 [cs.CL])

    [http://arxiv.org/abs/2305.01711](http://arxiv.org/abs/2305.01711)

    本文研究了持续预训练对于微调性能的影响，发现传统的持续预训练不能保证一致的提高性能，甚至会对一些任务产生负面影响。针对这些问题，作者提出了基于提示的持续预训练，旨在通过无监督的预训练向LM展示任务相关文本和提示模板，从而提高基于提示的微调表现。

    

    在大量无标注数据的训练下，语言模型（LM）极大地推动了自然语言处理（NLP）领域的发展。 在本研究中，我们重新审视NLP中广为接受的LM任务相关文本的持续预训练可以提高下游任务微调性能的理论。通过在半监督和全监督设置下对八个单句任务和八个句对任务的实验，我们发现传统的持续预训练不能保证一致的提高性能，甚至可能对句对任务或使用基于提示的微调方式时会产生负面影响。为了解决这些问题，我们提出了基于提示的持续预训练（PCP），将指导调整的思想与传统的持续预训练相结合。我们的方法旨在通过在微调目标之前通过无监督的预训练目标向LM展示任务相关文本和提示模板，从而提高基于提示的FT的表现。

    Language models (LMs) trained on vast quantities of unlabelled data have greatly advanced the field of natural language processing (NLP). In this study, we re-visit the widely accepted notion in NLP that continued pre-training LMs on task-related texts improves the performance of fine-tuning (FT) in downstream tasks. Through experiments on eight single-sentence tasks and eight sentence-pair tasks in both semi-supervised and fully-supervised settings, we find that conventional continued pre-training does not consistently provide benefits and can even be detrimental for sentence-pair tasks or when prompt-based FT is used. To tackle these issues, we propose Prompt-based Continued Pre-training (PCP), which combines the idea of instruction tuning with conventional continued pre-training. Our approach aims to improve the performance of prompt-based FT by presenting both task-related texts and prompt templates to LMs through unsupervised pre-training objectives before fine-tuning for the targ
    
[^50]: 星辰即你所需：用远程监督金字塔网络进行文档级端到端情感分析

    Stars Are All You Need: A Distantly Supervised Pyramid Network for Document-Level End-to-End Sentiment Analysis. (arXiv:2305.01710v1 [cs.CL])

    [http://arxiv.org/abs/2305.01710](http://arxiv.org/abs/2305.01710)

    本文提出了一种文档级端到端情感分析方法，通过星级评分标签，实现方面检测、情感分析和评分预测，具有良好的性能和可解释性。

    

    本文提出了文档级端到端情感分析方法，可以通过星级评分标签对在线评论中表达的方面和评论情感进行有效的统一分析。我们假设星级评分标签是评论中各方面评分的“粗粒度综合”。我们提出了一种远程监督的金字塔网络（DSPN），只用文档星级评分标签进行训练，即可有效地执行方面-类别检测、方面-类别情感分析和评分预测。通过以端到端的方式执行这三个相关的情感子任务，DSPN可以提取评论中提到的方面，确定相应的情感，并预测星级评分标签。我们在英文和汉语多方面评论数据集上评估了DSPN，发现仅使用星级评分标签进行监督，DSPN的性能与各种基准模型相当。我们还展示了DSPN在评论上的可解释性输出，以说明金字塔网络的结构。

    In this paper, we propose document-level end-to-end sentiment analysis to efficiently understand aspect and review sentiment expressed in online reviews in a unified manner. In particular, we assume that star rating labels are a "coarse-grained synthesis" of aspect ratings across in the review. We propose a Distantly Supervised Pyramid Network (DSPN) to efficiently perform Aspect-Category Detection, Aspect-Category Sentiment Analysis, and Rating Prediction using only document star rating labels for training. By performing these three related sentiment subtasks in an end-to-end manner, DSPN can extract aspects mentioned in the review, identify the corresponding sentiments, and predict the star rating labels. We evaluate DSPN on multi-aspect review datasets in English and Chinese and find that with only star rating labels for supervision, DSPN can perform comparably well to a variety of benchmark models. We also demonstrate the interpretability of DSPN's outputs on reviews to show the py
    
[^51]: 压缩模型的高效微调：蒸馏还是标注？

    Distill or Annotate? Cost-Efficient Fine-Tuning of Compact Models. (arXiv:2305.01645v1 [cs.CL])

    [http://arxiv.org/abs/2305.01645](http://arxiv.org/abs/2305.01645)

    本文研究了压缩模型的高效微调方法，实验结果表明，与手动标注更多的微调数据以直接训练压缩模型相比，从T5-XXL蒸馏到T5-Small几乎总是更具成本效益。

    

    大型模型的微调虽然效果显著，但使用这些模型进行推理成本高且会产生碳排放。知识蒸馏已被证明是减少推理成本的实用解决方案，但蒸馏过程本身需要大量计算资源。本文研究了如何最有效地使用固定预算构建压缩模型。在六个不同的自然语言处理任务上进行了大量实验后，我们发现从T5-XXL（11B）蒸馏到T5-Small（60M）几乎总是比手动标注更多的微调数据以直接训练一个压缩模型（T5-Small（60M））更具成本效益。我们进一步展示了最大化效用的最佳蒸馏量因任务而异。

    Fine-tuning large models is highly effective, however, inference using these models can be expensive and produces carbon emissions. Knowledge distillation has been shown to be a practical solution to reduce inference costs, but the distillation process itself requires significant computational resources. Rather than buying or renting GPUs to fine-tune, then distill a large model, an NLP practitioner who needs a compact model might also choose to simply allocate an available budget to hire annotators and manually label additional fine-tuning data. In this paper, we investigate how to most efficiently use a fixed budget to build a compact model. Through our extensive experiments on six diverse NLP tasks, we find that distilling from T5-XXL (11B) to T5-Small (60M) leads to almost always a cost-efficient option compared to annotating more data to directly train a compact model (T5-Small (60M)). We further demonstrate that the optimal amount of distillation that maximizes utility varies acr
    
[^52]: 如何发挥大语言模型在少样本关系抽取中的能力？

    How to Unleash the Power of Large Language Models for Few-shot Relation Extraction?. (arXiv:2305.01555v1 [cs.CL])

    [http://arxiv.org/abs/2305.01555](http://arxiv.org/abs/2305.01555)

    本文通过使用GPT-3.5模型在少样本关系抽取中，实现在四个不同数据集上的新的最优性能，并提出了与任务相关的指导说明和约束模式下的数据生成方法。

    

    语言模型的扩展已经彻底改变了广泛的自然语言处理任务，但是使用大型语言模型进行少样本关系抽取还没有得到全面探索。本文通过详细实验，研究了使用GPT-3.5进行少样本关系抽取的基本方法——上下文学习和数据生成。为了增强少样本性能，我们进一步提出了与任务相关的指导说明和约束模式下的数据生成。我们观察到，在上下文学习的情况下，可以实现与以前的提示学习方法相当的性能，而使用大型语言模型的数据生成可以推动以前的解决方案以在四个广泛研究的关系抽取数据集上获得新的最先进的少样本结果。我们希望我们的工作可以激发未来对大型语言模型在少样本关系抽取中的能力的研究。代码可以在 \url{https://github.com/zjunlp/DeepKE/tree/main/example/llm} 中找到。

    Scaling language models have revolutionized widespread NLP tasks, yet little comprehensively explored few-shot relation extraction with large language models. In this paper, we investigate principal methodologies, in-context learning and data generation, for few-shot relation extraction via GPT-3.5 through exhaustive experiments. To enhance few-shot performance, we further propose task-related instructions and schema-constrained data generation. We observe that in-context learning can achieve performance on par with previous prompt learning approaches, and data generation with the large language model can boost previous solutions to obtain new state-of-the-art few-shot results on four widely-studied relation extraction datasets. We hope our work can inspire future research for the capabilities of large language models in few-shot relation extraction. Code is available in \url{https://github.com/zjunlp/DeepKE/tree/main/example/llm.
    
[^53]: 触发词作为后门攻击的触发器：检查语言模型的脆弱性

    Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models. (arXiv:2305.01219v1 [cs.CL])

    [http://arxiv.org/abs/2305.01219](http://arxiv.org/abs/2305.01219)

    本研究提出一种新颖有效的“ProAttack”方法来执行干净标签的后门攻击，使用的是提示本身作为触发器。该方法不需要外部触发器，并确保毒瘤数据的标注正确，提高了后门攻击的隐蔽性，相比于现有的后门攻击方法有显著提升。

    

    基于提示的学习范例弥合了预训练和微调之间的差距，在几个NLP任务中取得了最先进的性能，尤其是在少样本情况下。尽管应用广泛，但基于提示的学习容易受到后门攻击。文本后门攻击旨在通过注入触发器并修改标签来在模型中引入有针对性的漏洞。然而，由于触发器的存在和毒瘤数据标注不正确等缺陷，这种攻击存在异常的自然语言表达。在本研究中，我们提出了一种新颖有效的“ProAttack”方法，基于提示来执行干净标签的后门攻击，使用的是提示本身作为触发器。我们的方法不需要外部触发器，并确保毒瘤数据的标注正确，提高了后门攻击的隐蔽性。通过在丰富的资源和少样本文本语料库上的广泛实验，我们证明了ProAttack方法在保持干净数据一致性的同时显著优于现有的后门攻击方式。

    The prompt-based learning paradigm, which bridges the gap between pre-training and fine-tuning, achieves state-of-the-art performance on several NLP tasks, particularly in few-shot settings. Despite being widely applied, prompt-based learning is vulnerable to backdoor attacks. Textual backdoor attacks are designed to introduce targeted vulnerabilities into models by poisoning a subset of training samples through trigger injection and label modification. However, they suffer from flaws such as abnormal natural language expressions resulting from the trigger and incorrect labeling of poisoned samples. In this study, we propose {\bf ProAttack}, a novel and efficient method for performing clean-label backdoor attacks based on the prompt, which uses the prompt itself as a trigger. Our method does not require external triggers and ensures correct labeling of poisoned samples, improving the stealthy nature of the backdoor attack. With extensive experiments on rich-resource and few-shot text c
    
[^54]: CryCeleb: 基于婴儿哭声的说话人认证数据集

    CryCeleb: A Speaker Verification Dataset Based on Infant Cry Sounds. (arXiv:2305.00969v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2305.00969](http://arxiv.org/abs/2305.00969)

    CryCeleb是一个基于婴儿哭声的说话人认证数据集，包括超过6小时的手动分割哭声，可用于研究婴儿哭声分析。

    

    本文描述了Ubenwa CryCeleb数据集——一个标记的婴儿哭声收集，以及附带的CryCeleb 2023任务——一个基于婴儿哭声的公共说话人验证挑战。我们释放出786名新生儿超过6小时的手动分割哭声，以鼓励婴儿哭声分析方面的研究。

    This paper describes the Ubenwa CryCeleb dataset - a labeled collection of infant cries, and the accompanying CryCeleb 2023 task - a public speaker verification challenge based on infant cry sounds. We release for academic usage more than 6 hours of manually segmented cry sounds from 786 newborns to encourage research in infant cry analysis.
    
[^55]: 基于SearChain的复杂知识密集型任务中精确、可信和可追溯内容生成的研究

    Search-in-the-Chain: Towards the Accurate, Credible and Traceable Content Generation for Complex Knowledge-intensive Tasks. (arXiv:2304.14732v1 [cs.CL])

    [http://arxiv.org/abs/2304.14732](http://arxiv.org/abs/2304.14732)

    提出了一个名为SearChain的新型框架，以改进LLM生成的内容的准确性、可信度和可追溯性，从而提高复杂知识密集型任务的表现。SearChain通过深度集成LLM和信息检索（IR）实现，其思路是通过构造查询链，将多跳问题进行分解，最终指导LLM生成正确的答案。

    

    随着ChatGPT等大型语言模型（LLM）的广泛应用，如何使LLM生成的内容准确可信在复杂知识密集型任务中变得非常重要。本文提出了一种名为Search-in-the-Chain（SearChain）的新型框架，以改进多跳问题回答等典型复杂知识密集型任务中LLM生成内容的准确性、可信度和可追溯性。SearChain是一个深度集成LLM和信息检索（IR）的框架。在SearChain中，LLM构建查询链，作为多跳问题的分解。链的每个节点都是由IR导向的查询-答案对，以及由LLM生成的该查询的答案。IR验证、完善和跟踪链中每个节点的信息，以指导LLM构建正确的查询链，并最终回答多跳问题。SearChain使LLM从一次性答案转变为多步答案，从而提高了生成内容的准确性和可信度。实验结果表明，SearChain在准确性和可靠性方面优于其他最先进的方法。

    With the wide application of Large Language Models (LLMs) such as ChatGPT, how to make the contents generated by LLM accurate and credible becomes very important, especially in complex knowledge-intensive tasks. In this paper, we propose a novel framework called Search-in-the-Chain (SearChain) to improve the accuracy, credibility and traceability of LLM-generated content for multi-hop question answering, which is a typical complex knowledge-intensive task. SearChain is a framework that deeply integrates LLM and information retrieval (IR). In SearChain, LLM constructs a chain-of-query, which is the decomposition of the multi-hop question. Each node of the chain is a query-answer pair consisting of an IR-oriented query and the answer generated by LLM for this query. IR verifies, completes, and traces the information of each node of the chain, so as to guide LLM to construct the correct chain-of-query, and finally answer the multi-hop question. SearChain makes LLM change from trying to gi
    
[^56]: 基于ChatGPT的放射学报告摘要生成的迭代优化框架：ImpressionGPT

    ImpressionGPT: An Iterative Optimizing Framework for Radiology Report Summarization with ChatGPT. (arXiv:2304.08448v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.08448](http://arxiv.org/abs/2304.08448)

    ImpressionGPT是一个利用LLMs构建动态上下文的迭代优化框架，用于放射学报告摘要生成。相对于其他方法，ImpressionGPT在具有较好泛化性能的同时，成功提高了放射学报告摘要的生成能力。

    

    放射学报告中的"Impression"部分是放射科医师和其他医生交流的重要基础，通常是基于"Findings"部分编写的。然而，对于放射科医师来说，编写大量的印象描述可能是费时费力且容易出错的。尽管最近的研究使用大规模医学文本数据进行预训练和微调预训练语言模型，实现了自动印象生成的有希望的结果。但这些模型通常需要大量的医学文本数据，并且具有较差的泛化性能。虽然像ChatGPT这样的大型语言模型表现出强大的泛化能力和性能，但它们在特定领域（如放射学）中的表现仍然未经调查，可能受到限制。为了解决这个问题，我们提出了ImpressionGPT，利用LLM的上下文学习能力，通过使用领域特定的个性化数据构建动态上下文，提高了放射学报告摘要的生成能力。

    The 'Impression' section of a radiology report is a critical basis for communication between radiologists and other physicians, and it is typically written by radiologists based on the 'Findings' section. However, writing numerous impressions can be laborious and error-prone for radiologists. Although recent studies have achieved promising results in automatic impression generation using large-scale medical text data for pre-training and fine-tuning pre-trained language models, such models often require substantial amounts of medical text data and have poor generalization performance. While large language models (LLMs) like ChatGPT have shown strong generalization capabilities and performance, their performance in specific domains, such as radiology, remains under-investigated and potentially limited. To address this limitation, we propose ImpressionGPT, which leverages the in-context learning capability of LLMs by constructing dynamic contexts using domain-specific, individualized dat
    
[^57]: 多模态图像文本匹配优化基于检索的胸部 X 射线报告生成

    Multimodal Image-Text Matching Improves Retrieval-based Chest X-Ray Report Generation. (arXiv:2303.17579v1 [cs.CL])

    [http://arxiv.org/abs/2303.17579](http://arxiv.org/abs/2303.17579)

    本研究提出了一种基于检索的放射性医学报告生成模块 X-REM，它使用图像文本匹配分数来衡量胸部 X 光图像和放射学报告之间的相似度，以进行报告检索，其在多个先前的放射学报告生成模块中表现优异，可有效提高放射学报告的自动生成精度。

    

    自动化生成临床准确的放射学报告可以改善患者护理。以前依赖图像字幕模型的报告生成方法由于缺乏相关领域知识而经常生成不连贯和不正确的文本，而基于检索的尝试经常检索到与输入图像不相关的报告。在这项工作中，我们提出了一种名为 Contrastive X-Ray REport Match（X-REM）的新型基于检索的放射性医学报告生成模块，该模块使用图像文本匹配分数来衡量胸部 X 光图像和放射学报告之间的相似度以进行报告检索。我们观察到，使用语言图像模型计算图像文本匹配分数可以有效地捕捉到在使用余弦相似性时经常丢失的图像和文本之间的细粒度交互。在自然语言和临床度量方面，X-REM在多个先前的放射学报告生成模块中表现优异。通过对生成的报告进行人类评估，表明 X-R...

    Automated generation of clinically accurate radiology reports can improve patient care. Previous report generation methods that rely on image captioning models often generate incoherent and incorrect text due to their lack of relevant domain knowledge, while retrieval-based attempts frequently retrieve reports that are irrelevant to the input image. In this work, we propose Contrastive X-Ray REport Match (X-REM), a novel retrieval-based radiology report generation module that uses an image-text matching score to measure the similarity of a chest X-ray image and radiology report for report retrieval. We observe that computing the image-text matching score with a language-image model can effectively capture the fine-grained interaction between image and text that is often lost when using cosine similarity. X-REM outperforms multiple prior radiology report generation modules in terms of both natural language and clinical metrics. Human evaluation of the generated reports suggests that X-R
    
[^58]: 仅仅提示足够了吗？不是的。指导学习的全面和更广阔视角（arXiv：2303.10475v1 [cs.CL]）

    Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning. (arXiv:2303.10475v1 [cs.CL])

    [http://arxiv.org/abs/2303.10475](http://arxiv.org/abs/2303.10475)

    传统的自然语言处理机器学习需要大规模的任务特定示例，但这不适用于任务可能过于复杂或成本过高以进行注释的场景。因此，社区对于自然语言处理中新的监督寻求范式--从任务指令学习--越来越感兴趣。

    

    任务语义可以通过一组输入输出示例或一条文本指令来表达。传统的自然语言处理（NLP）机器学习方法主要依赖于大规模的任务特定示例的可用性。这引起了两个问题：首先，收集任务特定标记示例不适用于任务可能过于复杂或成本过高以进行注释的场景，或者系统需要立即处理新任务。其次，这不是用户友好的，因为最终用户可能更愿意在使用系统之前提供任务描述而不是一组示例。因此，社区对于自然语言处理中新的监督寻求范式--从任务指令学习--越来越感兴趣。尽管取得了令人印象深刻的进展，但社区仍然面临着一些共同的问题。本次调查旨在总结指导学习的当前研究，特别是回答以下问题：

    Task semantics can be expressed by a set of input-to-output examples or a piece of textual instruction. Conventional machine learning approaches for natural language processing (NLP) mainly rely on the availability of large-scale sets of task-specific examples. Two issues arise: first, collecting task-specific labeled examples does not apply to scenarios where tasks may be too complicated or costly to annotate, or the system is required to handle a new task immediately; second, this is not user-friendly since end-users are probably more willing to provide task description rather than a set of examples before using the system. Therefore, the community is paying increasing interest in a new supervision-seeking paradigm for NLP: learning from task instructions. Despite its impressive progress, there are some common issues that the community struggles with. This survey paper tries to summarize the current research on instruction learning, particularly, by answering the following questions:
    
[^59]: 探究社交媒体在COVID-19患者早期检测抑郁症中的应用

    Exploring Social Media for Early Detection of Depression in COVID-19 Patients. (arXiv:2302.12044v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.12044](http://arxiv.org/abs/2302.12044)

    本论文通过社交媒体分析探讨COVID-19感染和抑郁症之间的关系，并提出了一个深度神经网络用于早期预测抑郁症风险。

    

    COVID-19大流行对全球健康造成了巨大的破坏。尽管三年过去了，世界仍在与这种病毒斗争。人们越来越关注COVID-19对感染者心理健康的影响，他们更容易患上抑郁症，这会对受影响的个体和世界产生长期后果。在COVID-19患者中早期检测和干预可以降低患抑郁症的风险。本文通过社交媒体分析探讨了COVID-19感染和抑郁症之间的关系。首先，我们管理了一个包含COVID-19患者社交媒体活动信息的数据集。其次，我们对这个数据集进行了广泛的分析，以研究COVID-19感染风险较高的患者的特点。第三，我们提出了一个深度神经网络，用于早期预测抑郁症风险。

    The COVID-19 pandemic has caused substantial damage to global health. Even though three years have passed, the world continues to struggle with the virus. Concerns are growing about the impact of COVID-19 on the mental health of infected individuals, who are more likely to experience depression, which can have long-lasting consequences for both the affected individuals and the world. Detection and intervention at an early stage can reduce the risk of depression in COVID-19 patients. In this paper, we investigated the relationship between COVID-19 infection and depression through social media analysis. Firstly, we managed a dataset of COVID-19 patients that contains information about their social media activity both before and after infection. Secondly,We conducted an extensive analysis of this dataset to investigate the characteristic of COVID-19 patients with a higher risk of depression. Thirdly, we proposed a deep neural network for early prediction of depression risk. This model con
    
[^60]: 从教学视频文本转录中无监督生成任务图

    Unsupervised Task Graph Generation from Instructional Video Transcripts. (arXiv:2302.09173v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.09173](http://arxiv.org/abs/2302.09173)

    本文提出了一种无监督的任务图生成方法，通过结合支持指导的语言模型的推理能力和聚类、排序组件，从执行真实世界活动的教学视频文本记录中生成任务图。实验结果表明该方法在ProceL和CrossTask数据集上比监督学习方法生成的任务图更加准确。

    

    本研究探讨了生成真实世界活动任务图的问题。与以往的方法不同，我们考虑提供执行真实世界活动（如制作咖啡）的教学视频文本记录，并旨在确定与任务相关的关键步骤及其依赖关系。我们提出了一种新颖的任务图生成方法，该方法结合了面向指导的语言模型的推理能力以及聚类和排序组件，在完全无监督的情况下生成准确的任务图。我们展示了该方法在ProceL和CrossTask数据集上生成的任务图比监督学习方法更加准确。

    This work explores the problem of generating task graphs of real-world activities. Different from prior formulations, we consider a setting where text transcripts of instructional videos performing a real-world activity (e.g., making coffee) are provided and the goal is to identify the key steps relevant to the task as well as the dependency relationship between these key steps. We propose a novel task graph generation approach that combines the reasoning capabilities of instruction-tuned language models along with clustering and ranking components to generate accurate task graphs in a completely unsupervised manner. We show that the proposed approach generates more accurate task graphs compared to a supervised learning approach on tasks from the ProceL and CrossTask datasets.
    
[^61]: 电商产品问答：一项综述调查

    Product Question Answering in E-Commerce: A Survey. (arXiv:2302.08092v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.08092](http://arxiv.org/abs/2302.08092)

    电商PQA的研究面临着问题多、数据难收集、答案不确定等特殊挑战。本文系统地综述了PQA研究的现状与未来方向。

    

    产品问答（PQA）致力于在电商平台上自动快速回复客户问题，近年来受到越来越多的关注。与典型的问答问题相比，PQA表现出了独特的挑战，例如电商平台上用户生成内容的主观性和可靠性。因此，各种问题设置和新方法已被提出来捕捉这些特殊特征。本文旨在系统地审查现有关于PQA的研究工作。具体而言，我们将PQA研究按提供的答案形式将其分类为四个问题设置。我们分析了每个设置的优缺点，并介绍了现有的数据集和评估协议。我们进一步总结了表征PQA与一般QA应用的最显著的挑战，并讨论了相应的解决方案。最后，我们通过提供几个未来方向来结束本文。

    Product question answering (PQA), aiming to automatically provide instant responses to customer's questions in E-Commerce platforms, has drawn increasing attention in recent years. Compared with typical QA problems, PQA exhibits unique challenges such as the subjectivity and reliability of user-generated contents in E-commerce platforms. Therefore, various problem settings and novel methods have been proposed to capture these special characteristics. In this paper, we aim to systematically review existing research efforts on PQA. Specifically, we categorize PQA studies into four problem settings in terms of the form of provided answers. We analyze the pros and cons, as well as present existing datasets and evaluation protocols for each setting. We further summarize the most significant challenges that characterize PQA from general QA applications and discuss their corresponding solutions. Finally, we conclude this paper by providing the prospect on several future directions.
    
[^62]: DocILE基准数据集用于文件信息定位和提取

    DocILE Benchmark for Document Information Localization and Extraction. (arXiv:2302.05658v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.05658](http://arxiv.org/abs/2302.05658)

    本文介绍了DocILE基准数据集，该数据集包含大量商务文件，可用于关键信息定位和提取以及行项目识别任务。该数据集具有55个类别的注释，超过以往发布的数据集，同时包括众多不同布局和未标记的文档，为该领域提供了有力的研究工具。

    

    本文介绍了DocILE基准数据集，用于关键信息定位和提取以及行项目识别任务的商务文件的最大数据集。 它包含6.7k个带注释的商务文件，100k个合成生成的文档以及近1M个未标记的文档，用于无监督的预训练。 该数据集具有特定于领域和任务的知识，具有以下关键特征：（i）在55个类别中注释，其粒度远远超过以前发布的关键信息提取数据集; （ii）行项目识别表示一项极具实用性的信息提取任务，在表格中必须将关键信息分配给项目; （iii）文档来自众多布局，测试集包括零-shot和少-shot案例以及训练集中常见的布局。基准数据集配有多个基线，包括RoBERTa、 LayoutLMv3和基于DETR的表格Transformer；

    This paper introduces the DocILE benchmark with the largest dataset of business documents for the tasks of Key Information Localization and Extraction and Line Item Recognition. It contains 6.7k annotated business documents, 100k synthetically generated documents, and nearly~1M unlabeled documents for unsupervised pre-training. The dataset has been built with knowledge of domainand task-specific aspects, resulting in the following key features: (i) annotations in 55 classes, which surpasses the granularity of previously published key information extraction datasets by a large margin; (ii) Line Item Recognition represents a highly practical information extraction task, where key information has to be assigned to items in a table; (iii) documents come from numerous layouts and the test set includes zero- and few-shot cases as well as layouts commonly seen in the training set. The benchmark comes with several baselines, including RoBERTa, LayoutLMv3 and DETR-based Table Transformer; app
    
[^63]: APAM：自适应预训练和自适应元学习在语言模型中用于处理噪声标签和长尾学习

    APAM: Adaptive Pre-training and Adaptive Meta Learning in Language Model for Noisy Labels and Long-tailed Learning. (arXiv:2302.03488v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.03488](http://arxiv.org/abs/2302.03488)

    本文提出了APAM框架，通过整合自适应预训练和元学习的方法，成功解决了长尾和噪声标签带来的挑战，实验证明该方法的效果优于现有最新方法。

    

    实际的自然语言处理 (NLP) 任务通常具有噪声标签和长尾分布的特点，这些问题会挑战复杂模型（如深度神经网络）的泛化和鲁棒性。常用的重抽样技术（如过采样或欠采样）容易导致过拟合。借助少量元数据学习数据权重正变得越来越流行。此外，最近的研究表明，自监督预训练对于弱表示数据的优点愈发明显。本文提出了一个通用的框架来处理长尾和噪声标签问题。该模型采用对比学习的方式适应问题域，并采用一种前馈神经网络的重新加权模块，该模块可以学习显式加权函数并根据元数据进行适应。我们在损失函数的项权重上进一步采用了交叉熵损失的多项式扩展和重点正则化的组合。此外，我们还将自适应元学习方法整合到预训练阶段中，以从弱表示类中学习更具可传递性的表示。实验表明，我们的方法在各种长尾和噪音标签分类任务中优于现有的最新方法。

    Practical natural language processing (NLP) tasks are commonly long-tailed with noisy labels. Those problems challenge the generalization and robustness of complex models such as Deep Neural Networks (DNNs). Some commonly used resampling techniques, such as oversampling or undersampling, could easily lead to overfitting. It is growing popular to learn the data weights leveraging a small amount of metadata. Besides, recent studies have shown the advantages of self-supervised pre-training, particularly to the under-represented data. In this work, we propose a general framework to handle the problem of both long-tail and noisy labels. The model is adapted to the domain of problems in a contrastive learning manner. The re-weighting module is a feed-forward network that learns explicit weighting functions and adapts weights according to metadata. The framework further adapts weights of terms in the loss function through a combination of the polynomial expansion of cross-entropy loss and foc
    
[^64]: 基于字符的模型提升了视觉文本渲染效果

    Character-Aware Models Improve Visual Text Rendering. (arXiv:2212.10562v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10562](http://arxiv.org/abs/2212.10562)

    本研究证实，以字体为基础的字符级文本编码模型可以显著提高图像生成的视觉文本排版质量，达到更高的拼写准确率和更好的效果。

    

    当前的图像生成模型在生成良好排版的视觉文本方面存在较大的问题。本文考察了其中一个关键因素：目前主流的文本到图像模型缺乏字符级别的输入特征，使得以字体为基础的视觉文本呈现更加困难。通过一系列的实验比较，我们发现基于字符的文本编码模型对于新颖的拼写任务（WikiSpell）提供了很大的帮助。将这些结果应用于视觉领域后，我们训练了一套图像生成模型，并展示了基于字符的变体在一系列新颖的文本渲染任务（即DrawText benchmark）上表现优于其无字符输入的对应模型。我们的模型在视觉拼写方面取得了远高于同领域对手的成果，在少量样本的情况下提高了超过30个百分点的准确率。

    Current image generation models struggle to reliably produce well-formed visual text. In this paper, we investigate a key contributing factor: popular text-to-image models lack character-level input features, making it much harder to predict a word's visual makeup as a series of glyphs. To quantify this effect, we conduct a series of experiments comparing character-aware vs. character-blind text encoders. In the text-only domain, we find that character-aware models provide large gains on a novel spelling task (WikiSpell). Applying our learnings to the visual domain, we train a suite of image generation models, and show that character-aware variants outperform their character-blind counterparts across a range of novel text rendering tasks (our DrawText benchmark). Our models set a much higher state-of-the-art on visual spelling, with 30+ point accuracy gains over competitors on rare words, despite training on far fewer examples.
    
[^65]: 自适应上下文学习：基于信息压缩视角的上下文示例选取和排序方法

    Self-Adaptive In-Context Learning: An Information Compression Perspective for In-Context Example Selection and Ordering. (arXiv:2212.10375v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10375](http://arxiv.org/abs/2212.10375)

    这篇论文提出了自适应上下文学习的原则，通过引入自适应机制帮助每个样本找到正确的上下文示例排列，从而最大化表现。通过广泛的评估，在8个不同的NLP数据集上，自适应ICL方法相对于常规设置提高了40%的相对改进。

    

    尽管在上下文学习 (ICL) 中具有惊人的少样本表现，但仍然普遍采用随机选取样本作为上下文的做法。本文提出了一种新的ICL原则：自适应上下文学习。引入自适应机制来帮助每个样本找到一个能够得到正确预测的上下文示例排列（即选取和排序），从而最大化表现。为了验证自适应ICL的有效性，我们提出了一个通用的选择-排序框架，并将其用新的选择和排序算法实例化。在八个不同的NLP数据集上进行了广泛的评估，我们的自适应ICL方法相对于常规设置提高了40%的相对改进。进一步分析揭示了自适应ICL的巨大潜力，即可能通过更先进的算法来缩小ICL和微调之间的差距。我们发布代码，以促进未来在该领域的研究：https://github.com/jxlr/SAICL_iclr22。

    Despite the surprising few-shot performance of in-context learning (ICL), it is still a common practice to randomly sample examples to serve as context. This paper advocates a new principle for ICL: self-adaptive in-context learning. The self-adaption mechanism is introduced to help each sample find an in-context example permutation (i.e., selection and ordering) that can derive the correct prediction, thus maximizing performance. To validate the effectiveness of self-adaptive ICL, we propose a general select-then-rank framework and instantiate it with new selection and ranking algorithms. Upon extensive evaluation on eight different NLP datasets, our self-adaptive ICL method achieves a 40% relative improvement over the common practice setting. Further analysis reveals the enormous potential of self-adaptive ICL that it might be able to close the gap between ICL and finetuning given more advanced algorithms. Our code is released to facilitate future research in this area: https://githu
    
[^66]: SeqDiffuSeq: 一种使用编码器-解码器Transformer的文本扩散模型用于序列生成

    SeqDiffuSeq: Text Diffusion Model with Encoder-Decoder Transformers for Sequence-to-Sequence Generation. (arXiv:2212.10325v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10325](http://arxiv.org/abs/2212.10325)

    本文提出了一种名为SeqDiffuSeq的文本扩散模型，用于序列生成，采用了编码器-解码器Transformer架构和自适应噪声调度技术，旨在探索扩散模型在自然语言生成方面的性能表现。

    

    扩散模型是一种新的生成建模范式，在图像、音频和视频生成方面取得了巨大成功。然而，考虑到文本的离散分类性质，将连续扩散模型扩展到自然语言并不是微不足道的，而且文本扩散模型研究较少。序列生成是自然语言处理中至关重要的话题之一。在本文中，我们将扩散模型应用于序列生成，探索扩散模型的优越生成性能能否转移到自然语言领域。我们提出SeqDiffuSeq，一种用于序列生成的文本扩散模型。SeqDiffuSeq使用编码器-解码器Transformer架构来建模去噪函数。为了提高生成质量，SeqDiffuSeq结合了自我调节技术和一个新提出的自适应噪声调度技术。自适应噪声调度具有均匀去噪的困难

    Diffusion model, a new generative modelling paradigm, has achieved great success in image, audio, and video generation. However, considering the discrete categorical nature of text, it is not trivial to extend continuous diffusion models to natural language, and text diffusion models are less studied. Sequence-to-sequence text generation is one of the essential natural language processing topics. In this work, we apply diffusion models to approach sequence-to-sequence text generation, and explore whether the superiority generation performance of diffusion model can transfer to natural language domain. We propose SeqDiffuSeq, a text diffusion model for sequence-to-sequence generation. SeqDiffuSeq uses an encoder-decoder Transformers architecture to model denoising function. In order to improve generation quality, SeqDiffuSeq combines the self-conditioning technique and a newly proposed adaptive noise schedule technique. The adaptive noise schedule has the difficulty of denoising evenly 
    
[^67]: 不生成，辨别：一种将语言模型与现实世界环境接轨的方案

    Don't Generate, Discriminate: A Proposal for Grounding Language Models to Real-World Environments. (arXiv:2212.09736v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09736](http://arxiv.org/abs/2212.09736)

    Pangu是一个泛用的框架，用于实现语言模型与现实环境的接轨，它利用语言模型的辨别能力而非生成能力，由一个符号代理和一个神经语言模型协同工作。这一方案已经在知识库问答问题中证明了它的有效性和灵活性。

    

    目前语言模型最缺失的就是现实世界环境的接轨性。已有的相关工作将语言模型用于直接生成计划，以便在环境中执行以达到预期的效果，这使得语言模型负担了确保语法正确性、忠实性和可控性的重担。本文提出了一个泛用的框架Pangu，用于实现语言模型与现实环境的接轨，该框架利用语言模型的辨别能力而非生成能力，由一个符号代理和一个神经语言模型协同工作：代理在环境中探索以逐步构建有效的计划，而语言模型评估备选计划的合理性以引导搜索过程。针对知识库问答（KBQA）这一具有挑战性的问题进行了案例研究，该问题具有庞大的环境，结果表明了Pangu的显著有效性和灵活性：BERT基语言模型已足够应对。

    A key missing capacity of current language models (LMs) is grounding to real-world environments. Most existing work for grounded language understanding uses LMs to directly generate plans that can be executed in the environment to achieve the desired effects. It thereby casts the burden of ensuring grammaticality, faithfulness, and controllability all on the LMs. We propose Pangu, a generic framework for grounded language understanding that capitalizes on the discriminative ability of LMs instead of their generative ability. Pangu consists of a symbolic agent and a neural LM working in a concerted fashion: The agent explores the environment to incrementally construct valid plans, and the LM evaluates the plausibility of the candidate plans to guide the search process. A case study on the challenging problem of knowledge base question answering (KBQA), which features a massive environment, demonstrates the remarkable effectiveness and flexibility of Pangu: A BERT-base LM is sufficient f
    
[^68]: 人机协同评估早期误传信息检测：COVID-19治疗案例研究。

    Human-in-the-loop Evaluation for Early Misinformation Detection: A Case Study of COVID-19 Treatments. (arXiv:2212.09683v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09683](http://arxiv.org/abs/2212.09683)

    该论文提出了一种人机协同评估框架，用于检测新的虚假信息声明并识别支持它们的社交媒体消息。在COVID-19治疗的案例中，基于现代NLP方法开发基线系统，并展示了人类事实核查人员每小时可以识别出违反Twitter关于COVID-19虚假信息方针的124条推文。

    

    我们提出了一个人机协同评估框架，用于事实核查新的虚假信息声明并识别支持它们的社交媒体消息。我们的方法提取值得核查的声明，这些声明被聚合并排名以便复审。然后使用立场分类器来识别支持新虚假信息申述的推文，进一步检查以确定它们是否违反相关政策。为了展示我们的方法的可行性，我们在COVID-19治疗领域基于现代NLP方法开发了一个基线系统用于人机协同事实核查。使用我们的基线系统，我们展示了人类事实核查人员每小时能够识别出违反Twitter关于COVID-19虚假信息方针的124条推文。我们将提供我们的代码、数据、基线模型和详细注释指南来支持人机协同系统的评估，这些系统可以直接从原始用户生成的内容中识别新的虚假信息。

    We present a human-in-the-loop evaluation framework for fact-checking novel misinformation claims and identifying social media messages that support them. Our approach extracts check-worthy claims, which are aggregated and ranked for review. Stance classifiers are then used to identify tweets supporting novel misinformation claims, which are further reviewed to determine whether they violate relevant policies. To demonstrate the feasibility of our approach, we develop a baseline system based on modern NLP methods for human-in-the-loop fact-checking in the domain of COVID-19 treatments. Using our baseline system, we show that human fact-checkers can identify 124 tweets per hour that violate Twitter's policies on COVID-19 misinformation. We will make our code, data, baseline models, and detailed annotation guidelines available to support the evaluation of human-in-the-loop systems that identify novel misinformation directly from raw user-generated content.
    
[^69]: 低资源语言的跨语言检索增强提示

    Cross-Lingual Retrieval Augmented Prompt for Low-Resource Languages. (arXiv:2212.09651v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09651](http://arxiv.org/abs/2212.09651)

    本文提出了跨语言检索增强提示(PARC)管道，在零-shot低资源语言上通过从高资源语言中检索出的语义上类似的句子来改善性能，表现明显优于 fine-tuning 基线，同时与高低资源语言之间的相似性以及低资源预训练数据的数量存在显著正相关关系。

    

    多语言预训练语言模型(MPLMs)在最近的经验跨语言转移研究中展现了其强大的多语言能力。在本文中，我们提出了跨语言检索增强的提示(PARC)管道，通过从高资源语言(HRL)中检索出的语义上类似的句子作为提示来改善零-shot低资源语言(LRLs)的性能。PARC通过多语言并行测试集在三个下游任务(二元情感分类、主题分类和自然语言推断)上提高了零-shot的性能，覆盖了10个LRLs，涵盖了6种语言家族，在未标记的设置中提高了(+5.1%)，在标记的设置中提高了(+16.3%)。PARC标记还超越了 fine-tuning 基线3.7%。我们发现，跨语言转移性能在一方面与高低资源语言之间的相似性以及低资源预训练数据的数量之间存在显著正相关关系。

    Multilingual Pretrained Language Models (MPLMs) have shown their strong multilinguality in recent empirical cross-lingual transfer studies. In this paper, we propose the Prompts Augmented by Retrieval Crosslingually (PARC) pipeline to improve the zero-shot performance on low-resource languages (LRLs) by augmenting the context with semantically similar sentences retrieved from a high-resource language (HRL) as prompts. PARC improves the zero-shot performance on three downstream tasks (binary sentiment classification, topic categorization and natural language inference) with multilingual parallel test sets across 10 LRLs covering 6 language families in both unlabeled settings (+5.1%) and labeled settings (+16.3%). PARC-labeled also outperforms the finetuning baseline by 3.7%. We find a significant positive correlation between cross-lingual transfer performance on one side, and the similarity between the high- and low-resource languages as well as the amount of low-resource pretraining da
    
[^70]: 从任务说明书中学习的鲁棒性

    Robustness of Learning from Task Instructions. (arXiv:2212.03813v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.03813](http://arxiv.org/abs/2212.03813)

    本文提出了一种鲁棒的方法来从任务说明中学习，以处理说明的变化并提高对新任务的泛化能力。

    

    传统的监督学习大多在个别任务上进行，并需要在大量的任务特定示例上训练。这种范式严重阻碍了任务概括的发展，因为准备任务特定示例集是昂贵的。为了构建一个可以快速轻松地推广到新任务的系统，最近采用了任务说明作为监督的新兴趋势。这些说明给模型定义了任务，并允许模型根据说明和输入输出适当的答案。然而，任务说明通常以不同形式表达，可以从两个线索中解释：首先，一些说明是短句，并且是预训练的语言模型（PLM）导向，例如提示，而其他说明是段落，并且是人为导向的，例如亚马逊的MTurk; 其次，不同的最终用户很可能用不同的文本表达方式解释相同的任务。需要一种鲁棒的学习方法来解决任务说明的可变性。在本文中，作者提出了一种鲁棒的方法来从任务说明中学习，可以处理说明的变化并改善对新任务的概括。

    Traditional supervised learning mostly works on individual tasks and requires training on a large set of task-specific examples. This paradigm seriously hinders the development of task generalization since preparing a task-specific example set is costly. To build a system that can quickly and easily generalize to new tasks, task instructions have been adopted as an emerging trend of supervision recently. These instructions give the model the definition of the task and allow the model to output the appropriate answer based on the instructions and inputs. However, task instructions are often expressed in different forms, which can be interpreted from two threads: first, some instructions are short sentences and are pretrained language model (PLM) oriented, such as prompts, while other instructions are paragraphs and are human-oriented, such as those in Amazon MTurk; second, different end-users very likely explain the same task with instructions of different textual expressions. A robust 
    
[^71]: 语言建模在推荐系统中的关键作用：丰富任务特定和任务无关的表示学习

    Pivotal Role of Language Modeling in Recommender Systems: Enriching Task-specific and Task-agnostic Representation Learning. (arXiv:2212.03760v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2212.03760](http://arxiv.org/abs/2212.03760)

    本文研究发现，用户历史语言建模可以在不同推荐任务中取得优异结果，并且利用任务无关的用户历史还可以提供显著的性能优势。该方法具有广泛的现实世界迁移学习能力。

    

    最近的研究提出了利用来自各种应用程序的用户行为数据的统一用户建模框架。其中许多受益于将用户行为序列作为纯文本使用，代表着任何领域或系统中的丰富信息而不失通用性。因此，一个问题产生了：用户历史语言建模能否帮助改善推荐系统？虽然语言建模的多功能性已在许多领域广泛研究，但其在推荐系统中的应用仍未深入探讨。我们展示了直接应用于任务特定用户历史的语言建模在不同的推荐任务上可以取得优异的结果。此外，利用任务无关的用户历史还可以提供显著的性能优势。我们进一步证明了我们的方法可以为广泛的现实世界推荐系统提供有前途的迁移学习能力，甚至在未知域和服务上也可以实现。

    Recent studies have proposed unified user modeling frameworks that leverage user behavior data from various applications. Many of them benefit from utilizing users' behavior sequences as plain texts, representing rich information in any domain or system without losing generality. Hence, a question arises: Can language modeling for user history corpus help improve recommender systems? While its versatile usability has been widely investigated in many domains, its applications to recommender systems still remain underexplored. We show that language modeling applied directly to task-specific user histories achieves excellent results on diverse recommendation tasks. Also, leveraging additional task-agnostic user histories delivers significant performance benefits. We further demonstrate that our approach can provide promising transfer learning capabilities for a broad spectrum of real-world recommender systems, even on unseen domains and services.
    
[^72]: 自我中心的音视频噪声抑制

    Egocentric Audio-Visual Noise Suppression. (arXiv:2211.03643v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2211.03643](http://arxiv.org/abs/2211.03643)

    本文研究了对自我中心视频中的音频和视频进行噪声抑制的问题，并证明了自我中心视觉信息对于生成加性校正掩码最有帮助。

    

    本文研究了自我中心视频（即未捕获到视频中的讲话者）的音视频噪声抑制。相比于以前依赖于唇部和面部视觉的音视频增强技术，本文中所使用的摄像头在画面中捕捉到的是潜在噪声源所看到的外部世界。首先，我们证明了自我中心视觉信息对于噪声抑制有帮助。我们比较了基于物体识别和动作分类的视觉特征提取器，并研究了将音频和视觉表示对齐的方法。然后，我们研究了不同的融合策略，以及在噪声抑制模型中整合视觉信息的位置。实验证明，视觉特征对于生成加性校正掩码最有帮助。最后，为了确保视觉特征在不同噪声条件下有辨识度，我们采用了噪声自适应的训练方式。

    This paper studies audio-visual noise suppression for egocentric videos -where the speaker is not captured in the video. Instead, potential noise sources are visible on screen with the camera emulating the off-screen speaker's view of the outside world. This setting is different from prior work in audio-visual speech enhancement that relies on lip and facial visuals. In this paper, we first demonstrate that egocentric visual information is helpful for noise suppression. We compare object recognition and action classification-based visual feature extractors and investigate methods to align audio and visual representations. Then, we examine different fusion strategies for the aligned features, and locations within the noise suppression model to incorporate visual information. Experiments demonstrate that visual features are most helpful when used to generate additive correction masks. Finally, in order to ensure that the visual features are discriminative with respect to different nois
    
[^73]: 差分隐私下的合成文本生成：一个简单而实用的方法

    Synthetic Text Generation with Differential Privacy: A Simple and Practical Recipe. (arXiv:2210.14348v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.14348](http://arxiv.org/abs/2210.14348)

    该论文介绍了一种简单而实用的方法，使用差分隐私对预训练的生成语言模型进行微调，能够生成具有强隐私保护的高质量合成文本，并且与非隐私版本相似。

    

    随着机器学习模型对敏感数据的记忆倾向引起越来越多的关注，隐私问题成为数据驱动产品的重要关注点。生成具有形式隐私保证的合成数据，如差分隐私（DP），为缓解这些隐私问题提供了一个有前途的方向。但是，以往的指向此方向的方法通常未能生成高质量的合成数据。在这项工作中，我们展示了差分隐私下文本领域的一个简单实用的方法：通过对经过预训练的生成语言模型进行微调并加入DP，使模型能够生成具有强隐私保护的有用的合成文本。通过对基准数据和私人客户数据的广泛实证分析，我们证明了我们的方法能够生成具有与非隐私版本相似的实用性的合成文本，同时提供强大的隐私保护，避免潜在的隐私泄露。

    Privacy concerns have attracted increasing attention in data-driven products due to the tendency of machine learning models to memorize sensitive training data. Generating synthetic versions of such data with a formal privacy guarantee, such as differential privacy (DP), provides a promising path to mitigating these privacy concerns, but previous approaches in this direction have typically failed to produce synthetic data of high quality. In this work, we show that a simple and practical recipe in the text domain is effective: simply fine-tuning a pretrained generative language model with DP enables the model to generate useful synthetic text with strong privacy protection. Through extensive empirical analyses on both benchmark and private customer data, we demonstrate that our method produces synthetic text that is competitive in terms of utility with its non-private counterpart, meanwhile providing strong protection against potential privacy leakages.
    
[^74]: 基于核函数的语言模型微调视角

    A Kernel-Based View of Language Model Fine-Tuning. (arXiv:2210.05643v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.05643](http://arxiv.org/abs/2210.05643)

    本文研究神经切线核 (NTK) 在描述预训练语言模型微调过程中的适用性。实验证明在14个NLP任务中使用掩码词预测问题作为下游任务，可以取得好的效果。

    

    在自然语言处理中，通过对预训练语言模型 (LMs) 进行微调，在低数据情况下解决 NLP 任务已经成为标准做法。但是，目前对于经验成功背后的理论机制了解很少，例如为什么在几十个训练点上微调一个有 $10^8$ 个或更多参数的模型不会导致过拟合。本文研究了神经切线核 (NTK) 在描述预训练语言模型的微调过程中的适用性。我们扩展了 NTK 形式化方法以应用于 Adam，并使用 Tensor Programs 描述了 NTK 适用于描述预训练语言模型微调更新的条件。我们在 14 个 NLP 任务上进行了广泛的实验验证了我们的理论，并表明通过提示将下游任务表述为掩码词预测问题可以取得良好的效果。

    It has become standard to solve NLP tasks by fine-tuning pre-trained language models (LMs), especially in low-data settings. There is minimal theoretical understanding of empirical success, e.g., why fine-tuning a model with $10^8$ or more parameters on a couple dozen training points does not result in overfitting. We investigate whether the Neural Tangent Kernel (NTK) - which originated as a model to study the gradient descent dynamics of infinitely wide networks with suitable random initialization - describes fine-tuning of pre-trained LMs. This study was inspired by the decent performance of NTK for computer vision tasks (Wei et al., 2022). We extend the NTK formalism to Adam and use Tensor Programs (Yang, 2020) to characterize conditions under which the NTK lens may describe fine-tuning updates to pre-trained language models. Extensive experiments on 14 NLP tasks validate our theory and show that formulating the downstream task as a masked word prediction problem through prompting 
    
[^75]: 离真正的同义词替换攻击还有多远？

    How Far Are We from Real Synonym Substitution Attacks?. (arXiv:2210.02844v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.02844](http://arxiv.org/abs/2210.02844)

    本文探讨同义词替换攻击的现状，发现当前方法存在无解决的障碍，生成的敌对样本效果不佳，需要在未来改进。

    

    本文探讨一个问题：我们距离真正的同义词替换攻击有多远？我们通过研究同义词替换攻击如何替换原始句子来探讨这个问题，并显示当前同义词替换攻击仍存在未解决的障碍使得生成的敌对样本是无效的。我们揭示了四种广泛使用的单词替换方法生成大量无效替换词，这些词是不合语法的或不符合原始句子的语义。接下来，我们展示了在检测无效敌对样本方面，SSA所使用的语义和语法约束是高度不足的。我们的工作是未来构建更好的SSA的重要基石。

    In this paper, we explore the following question: how far are we from real synonym substitution attacks (SSAs). We approach this question by examining how SSAs replace words in the original sentence and show that there are still unresolved obstacles that make current SSAs generate invalid adversarial samples. We reveal that four widely used word substitution methods generate a large fraction of invalid substitution words that are ungrammatical or do not preserve the original sentence's semantics. Next, we show that the semantic and grammatical constraints used in SSAs for detecting invalid word replacements are highly insufficient in detecting invalid adversarial samples. Our work is an important stepping stone to constructing better SSAs in the future.
    
[^76]: ContraCLM：因果语言模型的对比学习

    ContraCLM: Contrastive Learning For Causal Language Model. (arXiv:2210.01185v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.01185](http://arxiv.org/abs/2210.01185)

    ContraCLM是一种对比学习框架，可增强因果语言模型的表示区分性并适用于超出语言生成的任务。在多个下游任务中，相对于其他模型，ContraCLM获得了显著的性能改进。

    

    尽管因果语言模型取得了令人兴奋的进展，但其表示的表现力受到较差的区分能力的限制。为了解决这个问题，我们提出了一种新颖的对比学习框架 ContraCLM，它在标记级别和序列级别上进行对比学习。我们在各种下游任务上评估了 ContraCLM，并证明了它增强了表示的区分性，并弥合了仅编码器模型的差距，这使得因果语言模型更适合于超出语言生成的任务。具体而言，在语义文本相似性任务上，我们获得了44%的相对改进，在代码对代码搜索任务上获得了34%的改进。此外，通过提高表示的表现力，ContraCLM 还提高了源代码生成能力，在 HumanEval 基准测试中执行精度相对提高了9%。

    Despite exciting progress in causal language models, the expressiveness of the representations is largely limited due to poor discrimination ability. To remedy this issue, we present ContraCLM, a novel contrastive learning framework at both token-level and sequence-level. We assess ContraCLM on a variety of downstream tasks. We show that ContraCLM enhances discrimination of the representations and bridges the gap with the encoder-only models, which makes causal language models better suited for tasks beyond language generation. Specifically, we attain $44\%$ relative improvement on the Semantic Textual Similarity tasks and $34\%$ on Code-to-Code Search tasks. Furthermore, by improving the expressiveness of the representations, ContraCLM also boosts the source code generation capability with $9\%$ relative improvement on execution accuracy on the HumanEval benchmark.
    
[^77]: 带有属性删除子网络的模块化和按需偏差缓解方法

    Modular and On-demand Bias Mitigation with Attribute-Removal Subnetworks. (arXiv:2205.15171v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.15171](http://arxiv.org/abs/2205.15171)

    提出一种新颖的模块化偏差缓解方法，在推理时间按需集成到核心模型中的独立去偏置子网络，在性别、种族和年龄等受保护属性的分类任务中，该方法在缓解偏差方面是有效的，并且在精度和灵活性方面优于现有技术方法。

    

    社会偏见反映在大型预训练语言模型及其在下游任务中的微调版本中。常见的处理偏差的方法引入了额外的优化标准，并更新模型以达到新的去偏置状态。然而，在实践中，最终用户和从业人员可能更喜欢切换回原始模型，或仅对特定子集的保护属性应用去偏置。为了实现这一点，我们提出了一种新颖的模块化偏差缓解方法，包括独立高度稀疏的去偏置子网络，其中每个去偏置模块可以在推理时间按需集成到核心模型中。我们的方法借鉴了“diff”剪枝的概念，并提出了一种适合于各种表示分离优化的新型训练方式。我们在具有性别、种族和年龄等受保护属性的三个分类任务上进行了实验。结果表明，我们的模块化方法在缓解偏差方面是有效的，并且在精度和灵活性方面优于现有技术方法。

    Societal biases are reflected in large pre-trained language models and their fine-tuned versions on downstream tasks. Common in-processing bias mitigation approaches, such as adversarial training and mutual information removal, introduce additional optimization criteria, and update the model to reach a new debiased state. However, in practice, end-users and practitioners might prefer to switch back to the original model, or apply debiasing only on a specific subset of protected attributes. To enable this, we propose a novel modular bias mitigation approach, consisting of stand-alone highly sparse debiasing subnetworks, where each debiasing module can be integrated into the core model on-demand at inference time. Our approach draws from the concept of \emph{diff} pruning, and proposes a novel training regime adaptable to various representation disentanglement optimizations. We conduct experiments on three classification tasks with gender, race, and age as protected attributes. The resul
    
[^78]: 掩码语言模型在科学中的减弱收益

    The Diminishing Returns of Masked Language Models to Science. (arXiv:2205.11342v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.11342](http://arxiv.org/abs/2205.11342)

    本文从科学角度出发，评估了14个领域特定的基于Transformer的模型在12个下游科学任务中的表现，发现增加模型大小、训练数据或计算时间并不总是会导致显着提高，可能会有出乎意料的性能差异。

    

    基于Transformer的掩码语言模型，如BERT，在一般语料库上训练后在下游任务中表现出色。还已经证明这些模型的下游任务性能可以通过在更多数据上更长时间地预训练更大的模型来提高。在这项工作中，我们经验性地评估了这些结果在科学任务中的适用程度。我们使用了14个特定领域的基于Transformer的模型（包括ScholarBERT，一个新的 7.7 亿参数的科学聚焦掩码语言模型，预先训练了 高达 225B 个令牌），以评估训练数据、模型大小、预训练和微调时间对12个下游科学任务的影响。有趣的是，我们发现，在科学信息提取任务中，增加模型大小、训练数据或计算时间并不总是会导致显着的提高（即 >1% F1），如果有的话，可能会有出乎意料的性能差异，并提供了可能的解释。

    Transformer-based masked language models such as BERT, trained on general corpora, have shown impressive performance on downstream tasks. It has also been demonstrated that the downstream task performance of such models can be improved by pretraining larger models for longer on more data. In this work, we empirically evaluate the extent to which these results extend to tasks in science. We use 14 domain-specific transformer-based models (including ScholarBERT, a new 770M-parameter science-focused masked language model pretrained on up to 225B tokens) to evaluate the impact of training data, model size, pretraining and finetuning time on 12 downstream scientific tasks. Interestingly, we find that increasing model sizes, training data, or compute time does not always lead to significant improvements (i.e., >1% F1), if at all, in scientific information extraction tasks and offered possible explanations for the surprising performance differences.
    
[^79]: 基于本体和弱监督的临床记录中罕见病的识别

    Ontology-Driven and Weakly Supervised Rare Disease Identification from Clinical Notes. (arXiv:2205.05656v5 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.05656](http://arxiv.org/abs/2205.05656)

    本文提出了一种基于本体和弱监督的方法，可以利用来自BERT模型的最新预训练上下文表示来从临床记录中识别罕见病，无需领域专家的数据注释，实现了从文本到罕见病本体的自动匹配。

    

    计算文本表型是从临床记录中识别患有某些疾病和特征的实践。由于机器学习可用的案例很少，且需要领域专家的数据注释，因此罕见病难以被识别。我们提出了一种利用本体和弱监督的方法，使用来自Bi-directional Transformers（例如BERT）的最新预训练上下文表示。基于本体的框架包括两个步骤：（i）文本到UMLS，使用命名实体识别和链接工具SemEHR，在上下文中链接提及到Unified Medical Language System（UMLS）中的概念来提取表型，并使用自定义规则和上下文提及表示进行弱监督；（ii）UMLS到ORDO，将UMLS概念与Orphanet罕见病本体（ORDO）中的罕见病匹配。提出了弱监督方法来学习表型确认模型，以改进文本到UMLS的链接，而无需注释数据。

    Computational text phenotyping is the practice of identifying patients with certain disorders and traits from clinical notes. Rare diseases are challenging to be identified due to few cases available for machine learning and the need for data annotation from domain experts. We propose a method using ontologies and weak supervision, with recent pre-trained contextual representations from Bi-directional Transformers (e.g. BERT). The ontology-based framework includes two steps: (i) Text-to-UMLS, extracting phenotypes by contextually linking mentions to concepts in Unified Medical Language System (UMLS), with a Named Entity Recognition and Linking (NER+L) tool, SemEHR, and weak supervision with customised rules and contextual mention representation; (ii) UMLS-to-ORDO, matching UMLS concepts to rare diseases in Orphanet Rare Disease Ontology (ORDO). The weakly supervised approach is proposed to learn a phenotype confirmation model to improve Text-to-UMLS linking, without annotated data from
    
[^80]: 文本对抗净化作为对抗性攻击的防御

    Text Adversarial Purification as Defense against Adversarial Attacks. (arXiv:2203.14207v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.14207](http://arxiv.org/abs/2203.14207)

    该文章介绍了一种新型的针对文本对抗性攻击的对抗净化方法，通过注入噪声、掩盖输入文本并基于语言模型重构掩盖文本，成功地在不需要了解攻击形式的情况下对抗单词替换对抗攻击。

    

    对抗性净化是一种成功的防御机制，可以在不需要了解入侵攻击形式的情况下对抗对抗性攻击。通常，对抗性净化旨在消除对抗扰动，从而可以基于恢复的干净样本进行正确的预测。尽管对抗净化在计算机视觉领域中包括基于能量模型和扩散模型的生成模型方面取得了成功，但将净化作为针对文本对抗性攻击的防御策略却很少被探索。在这项工作中，我们介绍了一种针对文本对抗性攻击的新型对抗净化方法。借助语言模型的帮助，我们可以通过掩盖输入文本和基于掩盖的语言模型重构掩盖文本来注入噪声。通过这种方式，我们针对最常用的单词替换对抗攻击构建了针对文本模型的对抗净化过程。

    Adversarial purification is a successful defense mechanism against adversarial attacks without requiring knowledge of the form of the incoming attack. Generally, adversarial purification aims to remove the adversarial perturbations therefore can make correct predictions based on the recovered clean samples. Despite the success of adversarial purification in the computer vision field that incorporates generative models such as energy-based models and diffusion models, using purification as a defense strategy against textual adversarial attacks is rarely explored. In this work, we introduce a novel adversarial purification method that focuses on defending against textual adversarial attacks. With the help of language models, we can inject noise by masking input texts and reconstructing the masked texts based on the masked language models. In this way, we construct an adversarial purification process for textual models against the most widely used word-substitution adversarial attacks. We
    
[^81]: 社交媒体中社会语用意义的对比学习

    Contrastive Learning of Sociopragmatic Meaning in Social Media. (arXiv:2203.07648v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.07648](http://arxiv.org/abs/2203.07648)

    提出了一种社交媒体中社会语用意义的对比学习框架，该框架能够学习可迁移的任务不可知表示学习，并在各种对比学习框架中表现最佳。

    

    最近自然语言处理中的表示学习和对比学习等研究进展尚未广泛考虑社会语用意义这一类别（即不同语言社区内的交流意义）。为了弥补这一空白，我们提出了一种新的框架，用于学习可迁移至各种社会语用任务（如情感、仇恨言论、幽默、讽刺）的任务不可知表示学习。我们的框架在领域内和领域外数据以及一般和少样本情况下的各种对比学习框架中表现最佳。例如，与两个流行的预训练语言模型相比，我们的方法在每个数据集仅用20个训练样本微调时，平均F1值在16个数据集上提高了11.66个百分点。

    Recent progress in representation and contrastive learning in NLP has not widely considered the class of \textit{sociopragmatic meaning} (i.e., meaning in interaction within different language communities). To bridge this gap, we propose a novel framework for learning task-agnostic representations transferable to a wide range of sociopragmatic tasks (e.g., emotion, hate speech, humor, sarcasm). Our framework outperforms other contrastive learning frameworks for both in-domain and out-of-domain data, across both the general and few-shot settings. For example, compared to two popular pre-trained language models, our method obtains an improvement of $11.66$ average $F_1$ on $16$ datasets when fine-tuned on only $20$ training samples per dataset.
    
[^82]: 基于Prompt和语义知识增强的零样本关系抽取

    Prompt-based Zero-shot Relation Extraction with Semantic Knowledge Augmentation. (arXiv:2112.04539v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2112.04539](http://arxiv.org/abs/2112.04539)

    本文提出了一种基于Prompt和语义知识增强的模型，用于在零样本情况下识别未见关系。采用了一个新的单词级别的类比推理方法，生成了具有未见关系的增强实例。设计了基于外部知识图谱的提示，增加了已见关系的语义知识信息。

    

    在关系三元组抽取(RTE)任务中，识别没有训练实例的未见关系是一个具有挑战性的任务。已经尝试使用问答模型或关系描述来识别未见关系，但这些方法缺乏有关已见和未见关系之间联系的语义信息。本文提出了一种基于Prompt和语义知识增强的模型（ZS-SKA），用于在零样本情况下识别未见关系。我们提出了一种新的基于类比推理的单词级句子翻译规则，并使用该规则从具有已见关系的实例中生成具有未见关系的增强实例。我们设计了基于外部知识图谱的加权虚拟标签构建的提示信息，以整合从已见关系中学到的语义知识信息。我们构造了加权虚拟标签词，而不是在提示模板中使用实际的标签集。我们学习了RTE任务的表示形式，

    In relation triplet extraction (RTE), recognizing unseen (new) relations for which there are no training instances is a challenging task. Efforts have been made to recognize unseen relations based on question-answering models or relation descriptions. However, these approaches miss the semantic information about connections between seen and unseen relations. In this paper, We propose a prompt-based model with semantic knowledge augmentation (ZS-SKA) to recognize unseen relations under the zero-shot setting. We present a new word-level analogy-based sentence translation rule and generate augmented instances with unseen relations from instances with seen relations using that new rule. We design prompts with weighted virtual label construction based on an external knowledge graph to integrate semantic knowledge information learned from seen relations. Instead of using the actual label sets in the prompt template, we construct weighted virtual label words. We learn the representations of b
    
[^83]: 端到端语音模型学习了哪些关于说话人、语言和信道信息？一项层面和神经元水平的分析

    What do End-to-End Speech Models Learn about Speaker, Language and Channel Information? A Layer-wise and Neuron-level Analysis. (arXiv:2107.00439v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2107.00439](http://arxiv.org/abs/2107.00439)

    本研究通过对训练完成的语音模型进行层面和神经元水平的分析，探索了其中关于说话人、语言和信道属性的信息捕获情况。其研究结果有助于解释模型学习的关键特征及其在实现公正性决策方面的应用。

    

    深度神经网络天生难以解释和理解。与手工特征模型不同，我们难以理解这些模型学习了哪些概念以及它们如何相互作用。这种理解不仅对于调试目的至关重要，而且对于确保道德决策中的公正性也很重要。在本研究中，我们使用探测框架[1]对预训练语音模型进行事后功能解释性分析。具体而言，我们分析了针对不同任务（如说话人识别和方言识别）进行训练的语音模型的话语水平表示。我们进行了层面和神经元水平的分析，探索说话人、语言和信道属性。我们的研究旨在回答以下问题：i）表示中捕获了哪些信息？ii）它是如何表示和分布的？以及iii）我们能否确定拥有此信息的网络的最小子集？我们的结果揭示了一些新的发现，

    Deep neural networks are inherently opaque and challenging to interpret. Unlike hand-crafted feature-based models, we struggle to comprehend the concepts learned and how they interact within these models. This understanding is crucial not only for debugging purposes but also for ensuring fairness in ethical decision-making. In our study, we conduct a post-hoc functional interpretability analysis of pretrained speech models using the probing framework [1]. Specifically, we analyze utterance-level representations of speech models trained for various tasks such as speaker recognition and dialect identification. We conduct layer and neuron-wise analyses, probing for speaker, language, and channel properties. Our study aims to answer the following questions: i) what information is captured within the representations? ii) how is it represented and distributed? and iii) can we identify a minimal subset of the network that possesses this information?  Our results reveal several novel findings,
    
[^84]: Uni-Encoder: 一种用于生成型对话系统的快速准确响应选择范例

    Uni-Encoder: A Fast and Accurate Response Selection Paradigm for Generation-Based Dialogue Systems. (arXiv:2106.01263v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2106.01263](http://arxiv.org/abs/2106.01263)

    论文提出一种新的响应选择范例Uni-Encoder，解决了Cross-Encoder多次编码相同上下文计算成本高和Poly-Encoder性能下降的问题。该范例在一次前向传递中对所有候选与上下文进行编码。

    

    样本与排序是现代生成型对话系统的关键解码策略，通过从生成的少量候选答案中选择一个答案来实现多样化和高质量的响应。当前最先进的排序方法主要使用称为交叉编码器的编码范例，该编码器分别对每个上下文-候选对进行编码，并根据其适应度得分对候选进行排序。然而，交叉编码器为每个候选重复编码相同的冗长上下文，导致计算成本高。Poly-Encoder通过减少上下文和候选之间的交互来解决上述问题，但代价是性能下降。在这项工作中，我们开发了一种新的范例，称为Uni-Encoder，它像交叉编码器一样完全关注每个候选对，同时像Poly-编码器一样只编码一次上下文。Uni-Encoder在一次前向传递中对所有候选与上下文进行编码。我们针对所有候选使用相同的位置嵌入。

    Sample-and-rank is a key decoding strategy for modern generation-based dialogue systems. It helps achieve diverse and high-quality responses by selecting an answer from a small pool of generated candidates. The current state-of-the-art ranking methods mainly use an encoding paradigm called Cross-Encoder, which separately encodes each context-candidate pair and ranks the candidates according to their fitness scores. However, Cross-Encoder repeatedly encodes the same lengthy context for each candidate, resulting in high computational costs. Poly-Encoder addresses the above problems by reducing the interaction between context and candidates, but with a price of performance drop. In this work, we develop a new paradigm called Uni-Encoder, that keeps the full attention over each pair as in Cross-Encoder while only encoding the context once, as in Poly-Encoder. Uni-Encoder encodes all the candidates with the context in one forward pass. We use the same positional embedding for all candidates
    

