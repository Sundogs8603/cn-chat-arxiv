# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Language Models are Causal Knowledge Extractors for Zero-shot Video Question Answering.](http://arxiv.org/abs/2304.03754) | 本文提出了一种新颖的框架CaKE-LM，它利用语言模型中的因果常识知识来处理因果视频问答（CVidQA）任务，能够从语言模型中提取因果知识帮助生成问题-答案对，相较于现有方法在CVidQA任务上有着显著的性能优势。 |
| [^2] | [Gated Mechanism Enhanced Multi-Task Learning for Dialog Routing.](http://arxiv.org/abs/2304.03730) | 本论文研究了对话系统中的重要问题：如何利用门控机制增强多任务学习，以在各种对话数据之间发现数据-任务和任务-任务关系，提高对话路由效率，降低人力成本，增强用户体验。提出的门控机制增强的多任务模型具有层次化信息过滤的作用，其对现有系统不会产生影响。 |
| [^3] | [Interpretable Unified Language Checking.](http://arxiv.org/abs/2304.03728) | 本文提出了一种可解释的统一语言检查（UniLC）方法，旨在检查语言输入的事实和公正性。LLM可以在一个简单、少量样本的提示集上实现事实检查、陈规陋习检测和仇恨言论检测任务的高性能，这为实现可解释的统一语言检查提供了有前途的方法。 |
| [^4] | [On the Importance of Contrastive Loss in Multimodal Learning.](http://arxiv.org/abs/2304.03717) | 对比损失在多模态学习中是非常重要的，使模型能够有效地平衡所学表示，正对推动模型对齐表示，而负对则保持学习到的表示平衡。 |
| [^5] | [BenCoref: A Multi-Domain Dataset of Nominal Phrases and Pronominal Reference Annotations.](http://arxiv.org/abs/2304.03682) | 本论文介绍了一个包括四个不同领域Bengali文本的新数据集- BenCoref。该数据集可以帮助理解Bengali多个领域中共指消解现象的差异，并促进Bengali的资源开发。多个模型在该数据集上训练的性能也得到了报告。在跨语言测试中，从英语到Bengali的交叉语言性能较差，显示出需要语言特定的共指消解系统。 |
| [^6] | [Theoretical Conditions and Empirical Failure of Bracket Counting on Long Sequences with Linear Recurrent Networks.](http://arxiv.org/abs/2304.03639) | 本文研究了最简单的线性单元RNN在长序列计数问题上的极限，理论上使用的条件具有充分必要性；实验数据表明，通过标准的方法，该网络通常无法实现准确的计数行为。 |
| [^7] | [What does ChatGPT return about human values? Exploring value bias in ChatGPT using a descriptive value theory.](http://arxiv.org/abs/2304.03612) | 本研究通过使用心理学的价值理论测试了ChatGPT中的价值偏差，并没有发现明显的价值偏差。 |
| [^8] | [ArmanTTS single-speaker Persian dataset.](http://arxiv.org/abs/2304.03585) | 本文介绍了单发言人波斯语数据集ArmanTTS，并使用Tacotron2和HiFi GAN模型设计了一种将音素作为输入并生成相应语音输出的模型。 |
| [^9] | [GEMINI: Controlling the Sentence-level Writing Style for Abstractive Text Summarization.](http://arxiv.org/abs/2304.03548) | GEMINI模型将句子重写和融合技术集成，实现了抽象文本摘要中的句子级写作风格控制，该自适应方法在各种基准数据集上表现优异，特别是在数据集具有平衡的风格分布时。 |
| [^10] | [InfoCTM: A Mutual Information Maximization Perspective of Cross-Lingual Topic Modeling.](http://arxiv.org/abs/2304.03544) | 本文提出了一种基于互信息最大化的跨语言主题建模方法InfoCTM，通过主题对齐方法规范化主题生成并寻找更多链接的跨语言词汇，有效解决了重复主题和低覆盖字典的问题。 |
| [^11] | [From Retrieval to Generation: Efficient and Effective Entity Set Expansion.](http://arxiv.org/abs/2304.03531) | 本文提出了GenExpan，一种基于生成式预训练语言模型的实体集扩展框架，利用前缀树保证实体生成的有效性，采用自动生成的类名来引导模型生成同一类实体，从而提高了效率和可扩展性。 |
| [^12] | [SSS at SemEval-2023 Task 10: Explainable Detection of Online Sexism using Majority Voted Fine-Tuned Transformers.](http://arxiv.org/abs/2304.03518) | 本文描述了使用细调BERT模型和多数投票集成模型来检测和解释在线性别歧视的方法。翻转显着降低了女性在社交媒体平台上经历不成比例的性别歧视的风险。 |
| [^13] | [Hierarchical Catalogue Generation for Literature Review: A Benchmark.](http://arxiv.org/abs/2304.03512) | 研究提出了一个名为HiCatGLR任务，致力于为文献综述生成分层目录，它可以从多篇论文中提取和组织重要信息。为了解决现有研究中缺少清晰逻辑层次结构概述的问题，提供了一个具有挑战性的解决方案并创建了新的数据集。通过此项研究，可以更加准确地评估模型性能并验证数据集的高质量和评估指标的有效性。 |
| [^14] | [Linking Representations with Multimodal Contrastive Learning.](http://arxiv.org/abs/2304.03464) | 本文提出了一种名为CLIPPINGS的多模态框架，用于记录链接。该框架利用深度学习和对比学习的方法，通过端到端训练对称的视觉和语言编码器，在度量空间中学习相近或不同类别的表示方法，用于多个应用场景，如构建全面的补充专利注册表和识别不同社交媒体平台上的个人。 |
| [^15] | [Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4.](http://arxiv.org/abs/2304.03439) | 本文分析了多个逻辑推理数据集，评估了ChatGPT和GPT-4在逻辑推理任务上的表现，并构造了一个逻辑推理的分布之外的数据集来研究它们的鲁棒性。实验结果显示，ChatGPT在大多数逻辑推理基准测试中的表现远优于RoBERTa微调方法，而GPT-4的表现则更高。 |
| [^16] | [Cleansing Jewel: A Neural Spelling Correction Model Built On Google OCR-ed Tibetan Manuscripts.](http://arxiv.org/abs/2304.03427) | 本文提出了一种基于谷歌OCR扫描的藏文手稿的神经拼写纠错模型，可以自动纠正OCR输出中的噪声。 |
| [^17] | [Towards Corpus-Scale Discovery of Selection Biases in News Coverage: Comparing What Sources Say About Entities as a Start.](http://arxiv.org/abs/2304.03414) | 本文旨在探讨如何从大规模新闻语料库中直接发现媒体选择性偏见模式，并提出一种以不同来源报道的实体为起点的方法，通过比较计算选择性偏见。结果表明该方法可以用于发现容易受到偏见报道的话题。 |
| [^18] | [CAPOT: Creating Robust Dense Query Encoders using Post Training Contrastive Alignment.](http://arxiv.org/abs/2304.03401) | CAPOT使用后训练对比对齐的方法，提高模型对于噪声查询的健壮性，表现类似于数据增强但没有其开销。 |
| [^19] | [Using LSTM and GRU With a New Dataset for Named Entity Recognition in the Arabic Language.](http://arxiv.org/abs/2304.03399) | 本文提出了使用新的数据集和LSTM、GRU模型进行阿拉伯语命名实体识别的方法，结果良好，准确率达到80%。 |
| [^20] | [Deep Learning for Opinion Mining and Topic Classification of Course Reviews.](http://arxiv.org/abs/2304.03394) | 本文利用自然语言处理和深度学习技术，通过比较传统方法和现代机器学习方法，展示了如何处理大量课程评论，进行情感极性分析和主题分类。 |
| [^21] | [On the Evaluations of ChatGPT and Emotion-enhanced Prompting for Mental Health Analysis.](http://arxiv.org/abs/2304.03347) | 本文全面评估了ChatGPT在心理健康分析和情感推理方面的表现，以及不同提示策略和情感信息对其性能的影响。结果显示，ChatGPT在心理健康分析方面表现良好，加入情感增强提示对某些任务效果显著。 |
| [^22] | [ChatGPT-Crawler: Find out if ChatGPT really knows what it's talking about.](http://arxiv.org/abs/2304.03325) | 本文分析了从不同对话QA语料库中生成的ChatGPT的响应，并比较了其与正确答案的相似度。研究发现ChatGPT在某些情况下提供了错误的答案，提供了潜在用户和开发者的宝贵见解。 |
| [^23] | [Synthesis of Mathematical programs from Natural Language Specifications.](http://arxiv.org/abs/2304.03287) | 本论文关注于通过自然语言规范中的目标和约束合成数学程序，并通过评估CodeT5和使用GPT-3来生成需要的示例进行实验。 |
| [^24] | [Large language models effectively leverage document-level context for literary translation, but critical errors persist.](http://arxiv.org/abs/2304.03245) | 该研究通过人工评估发现，大型语言模型在进行文学段落翻译时会利用更多的文档级上下文，从而减少关键错误。然而，一些与上下文和意义相关的错误仍然存在。 |
| [^25] | [On the Pareto Front of Multilingual Neural Machine Translation.](http://arxiv.org/abs/2304.03216) | 本研究针对多语言神经机器翻译的数据不平衡问题，提出双重幂律方法用于预测独特的性能权衡前沿，并建立基于该方法的样本比例选择优化问题，取得更好的结果。 |
| [^26] | [ETPNav: Evolving Topological Planning for Vision-Language Navigation in Continuous Environments.](http://arxiv.org/abs/2304.03047) | ETPNav是一个能够在连续环境中进行视觉语言导航的新导航框架，它具有两个关键技能：能够抽象环境与生成长程导航计划以及在连续环境中避障控制的能力。ETPNav使用演化算法优化拓扑规划模块并在Matterport3D模拟器上实现了最先进的性能，达到了人类水平的VLN-CE任务性能。 |
| [^27] | [Unlocking the Potential of ChatGPT: A Comprehensive Exploration of its Applications, Advantages, Limitations, and Future Directions in Natural Language Processing.](http://arxiv.org/abs/2304.02017) | 本文全面探讨了ChatGPT在自然语言处理中的应用、优点和局限性，强调了使用这个强大工具时的道德考虑，为人工智能和NLP领域的讨论做出了贡献。 |
| [^28] | [GPTEval: NLG Evaluation using GPT-4 with Better Human Alignment.](http://arxiv.org/abs/2303.16634) | 本文介绍了GPTEval，一个利用链式思考和形式填充评价NLG生成的质量。实验表明，在文本摘要任务中，GPTEval结合GPT-4取得了0.514的斯皮尔曼相关系数，胜过其他方法。 |
| [^29] | [VideoXum: Cross-modal Visual and Textural Summarization of Videos.](http://arxiv.org/abs/2303.12060) | VideoXum是一个新的联合视频和文本摘要任务，它的目标是从长视频中生成对应的简化视频剪辑和文本摘要，利用了不同模态之间的关联和双重注意机制。该模型比现有的最先进方法在视频和文本摘要基准测试中表现更好。 |
| [^30] | [Clinical BERTScore: An Improved Measure of Automatic Speech Recognition Performance in Clinical Settings.](http://arxiv.org/abs/2303.05737) | 本文提出了一种临床BERTScore（CBERTScore）度量，它比其他度量更严厉地惩罚临床相关的错误，更接近于临床医生对医学句子的偏好。作者还收集了13个临床医生对149个现实医学句子的偏好基准，称为临床转录偏好基准（CTP），证明CBERTScore更接近于临床医生的偏好，并将基准发布给社区以进一步开发具有临床意识的ASR度量。 |
| [^31] | [Lon-ea at SemEval-2023 Task 11: A Comparison of Activation Functions for Soft and Hard Label Prediction.](http://arxiv.org/abs/2303.02468) | 本研究研究了在软硬标签预测中，不同激活函数对于深度神经网络模型输出的影响，并引入了一种新的正弦激活函数。 |
| [^32] | [Complex QA and language models hybrid architectures, Survey.](http://arxiv.org/abs/2302.09051) | 本文综述了语言模型架构和策略的最新进展，并重点关注混合技术在复杂问题回答中的应用，讨论了该领域的挑战和未来研究方向。 |
| [^33] | [Counteracts: Testing Stereotypical Representation in Pre-trained Language Models.](http://arxiv.org/abs/2301.04347) | 本文提出了一种使用反例测试预训练语言模型中内部刻板印象的方法，重点是性别偏见，结果表明模型在使用不相关的知识时表现出一定的鲁棒性，更倾向于使用浅层的语言线索来改变内部刻板印象。 |
| [^34] | [Multimodal and Explainable Internet Meme Classification.](http://arxiv.org/abs/2212.05612) | 本文提出了一种多模态和可解释的互联网迷因分类方法，旨在解决现有方法中忽略迷因语义和创建上下文导致公正内容管理困难的问题。作者采用示例和基于原型的推理并结合文本和视觉SOTA模型进行训练，成功在两个任务中检测了有害的迷因。 |
| [^35] | [Automated Identification of Eviction Status from Electronic Health Record Notes.](http://arxiv.org/abs/2212.02762) | 本研究开发了一种自然语言处理系统，可以自动从电子健康档案（EHR）记录中检测到逐出状态，并开发了一个新颖的模型KIRESH，已经显示出明显优于其他最先进的模型。 |
| [^36] | [PINTO: Faithful Language Reasoning Using Prompt-Generated Rationales.](http://arxiv.org/abs/2211.01562) | 本文提出了PINTO，基于提示生成的方式实现LM的忠实推理，并通过反事实正则化来学习。实验表明，PINTO显著优于使用外部原理的基线，同时提供了可理解的、忠实反映LM决策过程的理性。 |
| [^37] | [SC-Ques: A Sentence Completion Question Dataset for English as a Second Language Learners.](http://arxiv.org/abs/2206.12036) | 该论文介绍了一个针对英语学习者设计的大规模句子填空问题数据集\textsc{SC-Ques}，并且已经构建了一个综合基准来自动解决 SC 问题。 |
| [^38] | [Making first order linear logic a generating grammar.](http://arxiv.org/abs/2206.08955) | 本文研究了一阶线性逻辑与扩展张量类型演算的关系，提出了一种固有的演绎系统。 |
| [^39] | [Probing Pre-Trained Language Models for Cross-Cultural Differences in Values.](http://arxiv.org/abs/2203.13722) | 本文探究了预训练语言模型中跨文化的价值观差异，发现PTLMs捕捉到了文化之间的价值差异，但是这些价值差异只有微弱的相关性。跨文化应用中，将PTLMs与价值观对齐非常重要。 |
| [^40] | [Predicting Influenza A Viral Host Using PSSM and Word Embeddings.](http://arxiv.org/abs/2201.01140) | 该研究利用机器学习模型和特征提取方法，成功预测了甲型流感病毒的原始宿主，为早期和快速控制病毒传播提供了帮助。 |

# 详细

[^1]: 语言模型是零样本视频问答的因果知识提取器

    Language Models are Causal Knowledge Extractors for Zero-shot Video Question Answering. (arXiv:2304.03754v1 [cs.CL])

    [http://arxiv.org/abs/2304.03754](http://arxiv.org/abs/2304.03754)

    本文提出了一种新颖的框架CaKE-LM，它利用语言模型中的因果常识知识来处理因果视频问答（CVidQA）任务，能够从语言模型中提取因果知识帮助生成问题-答案对，相较于现有方法在CVidQA任务上有着显著的性能优势。

    

    因果视频问答（CVidQA）不仅查询相关或时间关系，还查询视频中的因果关系。现有的问题生成方法在阅读理解数据集上预先训练问题生成（QG）系统，输入为文本描述。但是，QG模型只学习提出相关问题（例如，“某人在做什么...”），导致转换到CVidQA的关联知识差，CVidQA重点关注“某人为什么这样做...”这样的因果问题。在观察到这一点后，我们提议利用因果知识生成问题-答案对，并提出了一种新颖的框架，即从语言模型中提取因果知识（CaKE-LM），利用语言模型中的因果常识知识来处理CVidQA。为了从LM中提取知识，CaKE-LM生成包含两个事件的因果问题（例如，“得分”触发“足球运动员踢球”），通过提示LM来提取因果常识知识作为这两个事件之间的关系，形成问题-答案对。在TVQA +数据集上的实验结果表明，我们的方法在CVidQA任务上明显优于现有方法。

    Causal Video Question Answering (CVidQA) queries not only association or temporal relations but also causal relations in a video. Existing question synthesis methods pre-trained question generation (QG) systems on reading comprehension datasets with text descriptions as inputs. However, QG models only learn to ask association questions (e.g., ``what is someone doing...'') and result in inferior performance due to the poor transfer of association knowledge to CVidQA, which focuses on causal questions like ``why is someone doing ...''. Observing this, we proposed to exploit causal knowledge to generate question-answer pairs, and proposed a novel framework, Causal Knowledge Extraction from Language Models (CaKE-LM), leveraging causal commonsense knowledge from language models to tackle CVidQA. To extract knowledge from LMs, CaKE-LM generates causal questions containing two events with one triggering another (e.g., ``score a goal'' triggers ``soccer player kicking ball'') by prompting LM w
    
[^2]: 多任务学习中的门控机制增强对话路由

    Gated Mechanism Enhanced Multi-Task Learning for Dialog Routing. (arXiv:2304.03730v1 [cs.CL])

    [http://arxiv.org/abs/2304.03730](http://arxiv.org/abs/2304.03730)

    本论文研究了对话系统中的重要问题：如何利用门控机制增强多任务学习，以在各种对话数据之间发现数据-任务和任务-任务关系，提高对话路由效率，降低人力成本，增强用户体验。提出的门控机制增强的多任务模型具有层次化信息过滤的作用，其对现有系统不会产生影响。

    

    目前，人-机器人协作对话系统（例如，在电子商务中的售前和售后）是无处不在的，而对话路由组件对于提高整体效率，降低人力成本和增强用户体验至关重要。尽管大多数现有方法可以满足这一要求，但它们只能对单一来源的对话数据进行建模，并且不能有效地捕获数据和子任务之间的关系的基础知识。在本文中，我们通过彻底挖掘各种类型的对话数据之间的数据-任务和任务-任务知识，来研究这个重要问题。为了实现上述目标，我们提出了一个门控机制增强的多任务模型（G3M），具体包括一种新型对话编码器和两个量身定制的门控机制模块。所提出的方法可以发挥层次化信息过滤的作用，并且不会对现有的对话系统产生影响。基于从现实世界应用程序收集的两个数据集，进行了广泛的实验结果研究。

    Currently, human-bot symbiosis dialog systems, e.g., pre- and after-sales in E-commerce, are ubiquitous, and the dialog routing component is essential to improve the overall efficiency, reduce human resource cost, and enhance user experience. Although most existing methods can fulfil this requirement, they can only model single-source dialog data and cannot effectively capture the underlying knowledge of relations among data and subtasks. In this paper, we investigate this important problem by thoroughly mining both the data-to-task and task-to-task knowledge among various kinds of dialog data. To achieve the above targets, we propose a Gated Mechanism enhanced Multi-task Model (G3M), specifically including a novel dialog encoder and two tailored gated mechanism modules. The proposed method can play the role of hierarchical information filtering and is non-invasive to existing dialog systems. Based on two datasets collected from real world applications, extensive experimental results d
    
[^3]: 可解释的统一语言检查

    Interpretable Unified Language Checking. (arXiv:2304.03728v1 [cs.CL])

    [http://arxiv.org/abs/2304.03728](http://arxiv.org/abs/2304.03728)

    本文提出了一种可解释的统一语言检查（UniLC）方法，旨在检查语言输入的事实和公正性。LLM可以在一个简单、少量样本的提示集上实现事实检查、陈规陋习检测和仇恨言论检测任务的高性能，这为实现可解释的统一语言检查提供了有前途的方法。

    

    尽管最近对大型语言模型（LLM）的不良行为提出了关注，包括非事实性、有偏见和充满仇恨的语言，但我们发现，基于自然和社会知识的潜在表示，LLM本质上是多任务语言检查器。我们提出了一种可解释的统一语言检查（UniLC）方法，旨在检查语言输入的事实和公正性。虽然公平性和事实检查任务以前是由不同的模型处理的，但我们发现LLM可以在一个简单、少量样本的提示集上实现事实检查、陈规陋习检测和仇恨言论检测任务的高性能。本文提出的“一半样本”多任务语言检查方法，使得GPT3.5-turbo模型在多项语言任务上优于完全监督的基准线。这种简单的方法和结果表明，基于强大的潜在知识表示，LLM可能是实现可解释的统一语言检查的有前途的方法。

    Despite recent concerns about undesirable behaviors generated by large language models (LLMs), including non-factual, biased, and hateful language, we find LLMs are inherent multi-task language checkers based on their latent representations of natural and social knowledge. We present an interpretable, unified, language checking (UniLC) method for both human and machine-generated language that aims to check if language input is factual and fair. While fairness and fact-checking tasks have been handled separately with dedicated models, we find that LLMs can achieve high performance on a combination of fact-checking, stereotype detection, and hate speech detection tasks with a simple, few-shot, unified set of prompts. With the ``1/2-shot'' multi-task language checking method proposed in this work, the GPT3.5-turbo model outperforms fully supervised baselines on several language tasks. The simple approach and results suggest that based on strong latent knowledge representations, an LLM can
    
[^4]: 关于对比损失在多模态学习中的重要性

    On the Importance of Contrastive Loss in Multimodal Learning. (arXiv:2304.03717v1 [cs.LG])

    [http://arxiv.org/abs/2304.03717](http://arxiv.org/abs/2304.03717)

    对比损失在多模态学习中是非常重要的，使模型能够有效地平衡所学表示，正对推动模型对齐表示，而负对则保持学习到的表示平衡。

    

    最近，对比学习方法（例如 CLIP（Radford 等人，2021））在多模态学习中取得了巨大的成功，其中模型尝试最小化同一数据点的不同视图（例如图像和其标题）的表示之间的距离，同时使不同数据点的表示彼此分离。然而，从理论的角度来看，当数据不是各向同性时，对比学习如何有效地学习来自不同视图的表示仍不清楚。在这项工作中，我们分析了一个简单的多模态对比学习模型的训练动态，并表明对比对是模型能够有效平衡所学表示的重要因素。尤其是，我们表明正对是能够推动模型在增加条件数的代价下对齐表示，而负对则降低条件数，保持学习到的表示平衡。

    Recently, contrastive learning approaches (e.g., CLIP (Radford et al., 2021)) have received huge success in multimodal learning, where the model tries to minimize the distance between the representations of different views (e.g., image and its caption) of the same data point while keeping the representations of different data points away from each other. However, from a theoretical perspective, it is unclear how contrastive learning can learn the representations from different views efficiently, especially when the data is not isotropic. In this work, we analyze the training dynamics of a simple multimodal contrastive learning model and show that contrastive pairs are important for the model to efficiently balance the learned representations. In particular, we show that the positive pairs will drive the model to align the representations at the cost of increasing the condition number, while the negative pairs will reduce the condition number, keeping the learned representations balance
    
[^5]: BenCoref:一种名词短语和代词指代注释的多领域数据集

    BenCoref: A Multi-Domain Dataset of Nominal Phrases and Pronominal Reference Annotations. (arXiv:2304.03682v1 [cs.CL])

    [http://arxiv.org/abs/2304.03682](http://arxiv.org/abs/2304.03682)

    本论文介绍了一个包括四个不同领域Bengali文本的新数据集- BenCoref。该数据集可以帮助理解Bengali多个领域中共指消解现象的差异，并促进Bengali的资源开发。多个模型在该数据集上训练的性能也得到了报告。在跨语言测试中，从英语到Bengali的交叉语言性能较差，显示出需要语言特定的共指消解系统。

    

    共指消解是自然语言处理中一个被广泛研究的问题。然而，由于缺乏相关数据集，Bengali 的共指消解研究主要未被探索。本文介绍了一个新的数据集BenCoref，包括来自四个不同领域的Bengali文本的共指注释。该数据集包含5200个提及注释，形成48,569个标记中的502个提及簇。我们描述了创建此数据集的过程，并报告了使用BenCoref训练的多个模型的性能。我们预计我们的工作将揭示Bengali多个领域中共指现象的差异，并鼓励开发其他Bengali资源。此外，我们发现在零样本设置下从英语到Bengali的交叉语言性能很差，这突显出需要语言特定的共指消解系统。

    Coreference Resolution is a well studied problem in NLP. While widely studied for English and other resource-rich languages, research on coreference resolution in Bengali largely remains unexplored due to the absence of relevant datasets. Bengali, being a low-resource language, exhibits greater morphological richness compared to English. In this article, we introduce a new dataset, BenCoref, comprising coreference annotations for Bengali texts gathered from four distinct domains. This relatively small dataset contains 5200 mention annotations forming 502 mention clusters within 48,569 tokens. We describe the process of creating this dataset and report performance of multiple models trained using BenCoref. We anticipate that our work sheds some light on the variations in coreference phenomena across multiple domains in Bengali and encourages the development of additional resources for Bengali. Furthermore, we found poor crosslingual performance at zero-shot setting from English, highlig
    
[^6]: 线性递归网络在长序列计数问题上的理论与实验困境

    Theoretical Conditions and Empirical Failure of Bracket Counting on Long Sequences with Linear Recurrent Networks. (arXiv:2304.03639v1 [cs.LG])

    [http://arxiv.org/abs/2304.03639](http://arxiv.org/abs/2304.03639)

    本文研究了最简单的线性单元RNN在长序列计数问题上的极限，理论上使用的条件具有充分必要性；实验数据表明，通过标准的方法，该网络通常无法实现准确的计数行为。

    

    先前的研究已经证明具有无限激活函数的RNN有计数的能力。然而，RNN的有效训练往往困难，通常无法学习准确的计数行为。本文通过研究最简单的线性单元RNN来解决这个问题。我们对线性RNN进行了理论分析，并确定了模型展现精确计数行为的条件。我们证明这些条件是必要且充分的。我们还使用涉及类似Dyck-1平衡符号的任务在两个不同的设置下进行了实证分析。我们发现线性RNN通常无法在标准方法训练下满足计数行为的必要且充分条件。我们研究了不同的训练序列长度和利用不同的目标类别对模型行为在训练期间和计数能力的影响。

    Previous work has established that RNNs with an unbounded activation function have the capacity to count exactly. However, it has also been shown that RNNs are challenging to train effectively and generally do not learn exact counting behaviour. In this paper, we focus on this problem by studying the simplest possible RNN, a linear single-cell network. We conduct a theoretical analysis of linear RNNs and identify conditions for the models to exhibit exact counting behaviour. We provide a formal proof that these conditions are necessary and sufficient. We also conduct an empirical analysis using tasks involving a Dyck-1-like Balanced Bracket language under two different settings. We observe that linear RNNs generally do not meet the necessary and sufficient conditions for counting behaviour when trained with the standard approach. We investigate how varying the length of training sequences and utilising different target classes impacts model behaviour during training and the ability of 
    
[^7]: ChatGPT对于人类价值观的反映是什么？使用描述性价值理论探索ChatGPT中的价值偏差

    What does ChatGPT return about human values? Exploring value bias in ChatGPT using a descriptive value theory. (arXiv:2304.03612v1 [cs.CL])

    [http://arxiv.org/abs/2304.03612](http://arxiv.org/abs/2304.03612)

    本研究通过使用心理学的价值理论测试了ChatGPT中的价值偏差，并没有发现明显的价值偏差。

    

    关于大型语言模型（LLMs）所生成的文本中存在的意识形态基础和潜在歧视问题引起了人们的关注。本研究使用心理学的价值理论来测试ChatGPT中可能存在的价值偏差。通过OpenAI API反复提示ChatGPT生成文本，并使用基于理论驱动的价值词典和词袋法对生成的语料库的价值内容进行分析。总体而言，我们没有发现明显的价值偏差。结果符合心理模型的理论预测，生成的文本表现出足够的构效效度，这表明价值内容被高度保留到了生成的输出中。我们观察到了某些社会取向价值的融合，这可能表明ChatGPT通过输出合理地反映了人类的价值观。

    There has been concern about ideological basis and possible discrimination in text generated by Large Language Models (LLMs). We test possible value biases in ChatGPT using a psychological value theory. We designed a simple experiment in which we used a number of different probes derived from the Schwartz basic value theory (items from the revised Portrait Value Questionnaire, the value type definitions, value names). We prompted ChatGPT via the OpenAI API repeatedly to generate text and then analyzed the generated corpus for value content with a theory-driven value dictionary using a bag of words approach. Overall, we found little evidence of explicit value bias. The results showed sufficient construct and discriminant validity for the generated text in line with the theoretical predictions of the psychological model, which suggests that the value content was carried through into the outputs with high fidelity. We saw some merging of socially oriented values, which may suggest that th
    
[^8]: ArmanTTS单发言人波斯语数据集

    ArmanTTS single-speaker Persian dataset. (arXiv:2304.03585v1 [cs.CL])

    [http://arxiv.org/abs/2304.03585](http://arxiv.org/abs/2304.03585)

    本文介绍了单发言人波斯语数据集ArmanTTS，并使用Tacotron2和HiFi GAN模型设计了一种将音素作为输入并生成相应语音输出的模型。

    

    TTS，即文本转语音，是使用深度学习方法进行适当建模可以完成的一种复杂过程。为了实现深度学习模型，需要一个合适的数据集。由于在波斯语领域中做了较少的工作，因此本文将介绍单一说话人数据集：ArmanTTS。我们将此数据集的特征与各种普遍数据集的特征进行了比较，以证明ArmanTTS符合教授波斯文本到语音转换模型所需的标准。我们还结合了Tacotron 2和HiFi GAN，设计了一个模型，可以将音素作为输入，输出对应的语音。从真实语音中获得了4.0的MOS值，用声码器预测获得了3.87的值，并用TTS模型生成的合成语音获得了2.98的值。

    TTS, or text-to-speech, is a complicated process that can be accomplished through appropriate modeling using deep learning methods. In order to implement deep learning models, a suitable dataset is required. Since there is a scarce amount of work done in this field for the Persian language, this paper will introduce the single speaker dataset: ArmanTTS. We compared the characteristics of this dataset with those of various prevalent datasets to prove that ArmanTTS meets the necessary standards for teaching a Persian text-to-speech conversion model. We also combined the Tacotron 2 and HiFi GAN to design a model that can receive phonemes as input, with the output being the corresponding speech. 4.0 value of MOS was obtained from real speech, 3.87 value was obtained by the vocoder prediction and 2.98 value was reached with the synthetic speech generated by the TTS model.
    
[^9]: GEMINI：针对抽象文本摘要控制句子级写作风格

    GEMINI: Controlling the Sentence-level Writing Style for Abstractive Text Summarization. (arXiv:2304.03548v1 [cs.CL])

    [http://arxiv.org/abs/2304.03548](http://arxiv.org/abs/2304.03548)

    GEMINI模型将句子重写和融合技术集成，实现了抽象文本摘要中的句子级写作风格控制，该自适应方法在各种基准数据集上表现优异，特别是在数据集具有平衡的风格分布时。

    

    人类专家使用不同技术编写摘要，包括重写文档中的句子或合并多个句子生成摘要句。这些技术是灵活的，因此很难通过任何单一方法模拟。为了解决这个问题，我们提出了一个自适应模型GEMINI，将重写器和融合器集成起来，以模拟句子重写和融合技术。GEMINI自适应地选择重写特定的文档句子或从头生成摘要句。实验证明，我们的自适应方法在各种基准数据集上优于纯抽象和重写基线，特别是当数据集具有平衡的风格分布时。有趣的是，实验结果表明，每个摘要句的人类写作风格在其上下文中是可以预测的。

    Human experts write summaries using different techniques, including rewriting a sentence in the document or fusing multiple sentences to generate a summary sentence. These techniques are flexible and thus difficult to be imitated by any single method. To address this issue, we propose an adaptive model, GEMINI, that integrates a rewriter and a fuser to mimic the sentence rewriting and fusion techniques, respectively. GEMINI adaptively chooses to rewrite a specific document sentence or generate a summary sentence from scratch. Experiments demonstrate that our adaptive approach outperforms the pure abstractive and rewriting baselines on various benchmark datasets, especially when the dataset has a balanced distribution of styles. Interestingly, empirical results show that the human writing style of each summary sentence is consistently predictable given its context.
    
[^10]: InfoCTM: 一种基于互信息最大化的跨语言主题建模方法

    InfoCTM: A Mutual Information Maximization Perspective of Cross-Lingual Topic Modeling. (arXiv:2304.03544v1 [cs.CL])

    [http://arxiv.org/abs/2304.03544](http://arxiv.org/abs/2304.03544)

    本文提出了一种基于互信息最大化的跨语言主题建模方法InfoCTM，通过主题对齐方法规范化主题生成并寻找更多链接的跨语言词汇，有效解决了重复主题和低覆盖字典的问题。

    

    跨语言主题模型在跨语言文本分析中使用广泛，可以揭示对齐的潜在主题。但是，大多数现有方法存在产生重复主题的问题以及由于低覆盖字典导致的性能下降。本文提出了一种基于互信息的跨语言主题建模方法InfoCTM。与先前工作中的直接对齐不同，我们提出了一种基于互信息的主题对齐方法。这可作为规范化，以正确对齐主题并防止词的退化主题表示，从而减轻了重复主题问题。为了解决低覆盖字典问题，我们进一步提出了一种跨语言词汇链接方法，该方法在给定字典的翻译以外，寻找更多链接的跨语言词汇进行主题对齐。在英语，中文和日语数据集上的广泛实验表明，我们的方法优于现有的基准线，产生更多多样化且信息丰富的主题，同时不损害跨语言对齐性能。

    Cross-lingual topic models have been prevalent for cross-lingual text analysis by revealing aligned latent topics. However, most existing methods suffer from producing repetitive topics that hinder further analysis and performance decline caused by low-coverage dictionaries. In this paper, we propose the Cross-lingual Topic Modeling with Mutual Information (InfoCTM). Instead of the direct alignment in previous work, we propose a topic alignment with mutual information method. This works as a regularization to properly align topics and prevent degenerate topic representations of words, which mitigates the repetitive topic issue. To address the low-coverage dictionary issue, we further propose a cross-lingual vocabulary linking method that finds more linked cross-lingual words for topic alignment beyond the translations of a given dictionary. Extensive experiments on English, Chinese, and Japanese datasets demonstrate that our method outperforms state-of-the-art baselines, producing more
    
[^11]: 从检索到生成：高效且有效的实体集扩展方法

    From Retrieval to Generation: Efficient and Effective Entity Set Expansion. (arXiv:2304.03531v1 [cs.CL])

    [http://arxiv.org/abs/2304.03531](http://arxiv.org/abs/2304.03531)

    本文提出了GenExpan，一种基于生成式预训练语言模型的实体集扩展框架，利用前缀树保证实体生成的有效性，采用自动生成的类名来引导模型生成同一类实体，从而提高了效率和可扩展性。

    

    实体集扩展（ESE）是一项至关重要的任务，旨在扩展由小的种子实体集描述的目标语义类的实体。大多数现有的ESE方法是基于检索的框架，需要提取实体的上下文特征，并计算种子实体和候选实体之间的相似性。为了实现这两个目的，它们必须迭代地遍历语料库和数据集中提供的实体词汇，导致效率和可扩展性较差。实验结果表明，基于检索的ESE方法消耗的时间与实体词汇和语料库的大小成线性增长。本文首先提出了一种生成式ESE框架，Generative Entity Set Expansion (GenExpan)，它利用生成式预训练语言模型来完成ESE任务。具体而言，采用前缀树来保证实体生成的有效性，并采用自动生成的类名来引导模型生成同一类实体。

    Entity Set Expansion (ESE) is a critical task aiming to expand entities of the target semantic class described by a small seed entity set. Most existing ESE methods are retrieval-based frameworks that need to extract the contextual features of entities and calculate the similarity between seed entities and candidate entities. To achieve the two purposes, they should iteratively traverse the corpus and the entity vocabulary provided in the datasets, resulting in poor efficiency and scalability. The experimental results indicate that the time consumed by the retrieval-based ESE methods increases linearly with entity vocabulary and corpus size. In this paper, we firstly propose a generative ESE framework, Generative Entity Set Expansion (GenExpan), which utilizes a generative pre-trained language model to accomplish ESE task. Specifically, a prefix tree is employed to guarantee the validity of entity generation, and automatically generated class names are adopted to guide the model to gen
    
[^12]: SSS在SemEval-2023任务10中的论文：使用投票细调变压器可解释的检测在线性别歧视。 (arXiv：2304.03518v1 [cs.CL])

    SSS at SemEval-2023 Task 10: Explainable Detection of Online Sexism using Majority Voted Fine-Tuned Transformers. (arXiv:2304.03518v1 [cs.CL])

    [http://arxiv.org/abs/2304.03518](http://arxiv.org/abs/2304.03518)

    本文描述了使用细调BERT模型和多数投票集成模型来检测和解释在线性别歧视的方法。翻转显着降低了女性在社交媒体平台上经历不成比例的性别歧视的风险。

    

    本文描述了我们在SemEval 2023任务10中提交的作品-可解释的在线性别歧视检测（EDOS），分为三个子任务。社交媒体平台的不断增长导致女性在社交媒体平台上面临不成比例的性别歧视。这使得检测和解释在线性别歧视内容变得比以往更加重要，以使社交媒体对女性更加安全和可访问。我们的方法包括实验和微调基于BERT的模型，并使用多数投票集合模型，该模型优于单个基线模型得分。我们的系统在任务A中实现了宏F1分数0.8392，在任务B中为0.6092，在任务C中为0.4319。

    This paper describes our submission to Task 10 at SemEval 2023-Explainable Detection of Online Sexism (EDOS), divided into three subtasks. The recent rise in social media platforms has seen an increase in disproportionate levels of sexism experienced by women on social media platforms. This has made detecting and explaining online sexist content more important than ever to make social media safer and more accessible for women. Our approach consists of experimenting and finetuning BERT-based models and using a Majority Voting ensemble model that outperforms individual baseline model scores. Our system achieves a macro F1 score of 0.8392 for Task A, 0.6092 for Task B, and 0.4319 for Task C.
    
[^13]: 文献综述的分层目录生成：一个基准测试

    Hierarchical Catalogue Generation for Literature Review: A Benchmark. (arXiv:2304.03512v1 [cs.CL])

    [http://arxiv.org/abs/2304.03512](http://arxiv.org/abs/2304.03512)

    研究提出了一个名为HiCatGLR任务，致力于为文献综述生成分层目录，它可以从多篇论文中提取和组织重要信息。为了解决现有研究中缺少清晰逻辑层次结构概述的问题，提供了一个具有挑战性的解决方案并创建了新的数据集。通过此项研究，可以更加准确地评估模型性能并验证数据集的高质量和评估指标的有效性。

    

    多文档科学摘要可以从大量的论文中提取和组织重要信息，最近引起了广泛关注。然而，现有的研究主要集中在产生缺乏清晰和逻辑层次结构的冗长概述上。为了缓解这个问题，我们提出了一个名为“Hierarchical Catalogue Generation for Literature Review (HiCatGLR)”的原子和具有挑战性的任务，其目标是根据各种参考文献为综述论文生成分层目录。我们精心构建了一个新的英文文献综述分层目录数据集(HiCaD)，其中包含13.8k篇文献综述目录和120k篇参考论文，并通过端到端和流水线方法进行了各种实验的基准测试。为了准确评估模型性能，我们设计了从语义和结构上与参考标准相似度的评估指标。此外，我们的广泛分析验证了我们数据集的高质量和我们评估指标的有效性。

    Multi-document scientific summarization can extract and organize important information from an abundant collection of papers, arousing widespread attention recently. However, existing efforts focus on producing lengthy overviews lacking a clear and logical hierarchy. To alleviate this problem, we present an atomic and challenging task named Hierarchical Catalogue Generation for Literature Review (HiCatGLR), which aims to generate a hierarchical catalogue for a review paper given various references. We carefully construct a novel English Hierarchical Catalogues of Literature Reviews Dataset (HiCaD) with 13.8k literature review catalogues and 120k reference papers, where we benchmark diverse experiments via the end-to-end and pipeline methods. To accurately assess the model performance, we design evaluation metrics for similarity to ground truth from semantics and structure. Besides, our extensive analyses verify the high quality of our dataset and the effectiveness of our evaluation met
    
[^14]: 用多模态对比学习连接表示

    Linking Representations with Multimodal Contrastive Learning. (arXiv:2304.03464v1 [cs.CV])

    [http://arxiv.org/abs/2304.03464](http://arxiv.org/abs/2304.03464)

    本文提出了一种名为CLIPPINGS的多模态框架，用于记录链接。该框架利用深度学习和对比学习的方法，通过端到端训练对称的视觉和语言编码器，在度量空间中学习相近或不同类别的表示方法，用于多个应用场景，如构建全面的补充专利注册表和识别不同社交媒体平台上的个人。

    

    许多应用需要将包含在各种文档数据集中的实例分组成类。最广泛使用的方法不使用深度学习，也不利用文档固有的多模态性质。值得注意的是，记录链接通常被概念化为字符串匹配问题。本研究开发了 CLIPPINGS，一种用于记录链接的多模态框架。CLIPPINGS 采用端到端训练对称的视觉和语言双编码器，通过对比语言-图像预训练进行对齐，学习一个度量空间，其中给定实例的汇总图像-文本表示靠近同一类中的表示，并远离不同类中的表示。在推理时，可以通过从离线示例嵌入索引中检索它们最近的邻居或聚类它们的表示来链接实例。本研究研究了两个具有挑战性的应用：通过将专利与其对应的监管文件链接来构建全面的补充专利注册表，以及在不同的社交媒体平台上识别个人。

    Many applications require grouping instances contained in diverse document datasets into classes. Most widely used methods do not employ deep learning and do not exploit the inherently multimodal nature of documents. Notably, record linkage is typically conceptualized as a string-matching problem. This study develops CLIPPINGS, (Contrastively Linking Pooled Pre-trained Embeddings), a multimodal framework for record linkage. CLIPPINGS employs end-to-end training of symmetric vision and language bi-encoders, aligned through contrastive language-image pre-training, to learn a metric space where the pooled image-text representation for a given instance is close to representations in the same class and distant from representations in different classes. At inference time, instances can be linked by retrieving their nearest neighbor from an offline exemplar embedding index or by clustering their representations. The study examines two challenging applications: constructing comprehensive suppl
    
[^15]: 评估ChatGPT和GPT-4的逻辑推理能力

    Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4. (arXiv:2304.03439v1 [cs.CL])

    [http://arxiv.org/abs/2304.03439](http://arxiv.org/abs/2304.03439)

    本文分析了多个逻辑推理数据集，评估了ChatGPT和GPT-4在逻辑推理任务上的表现，并构造了一个逻辑推理的分布之外的数据集来研究它们的鲁棒性。实验结果显示，ChatGPT在大多数逻辑推理基准测试中的表现远优于RoBERTa微调方法，而GPT-4的表现则更高。

    

    利用逻辑推理能力是一个全面的自然语言理解任务。随着先进的生成预训练转换器4（GPT-4）的发布，我们渴望了解GPT-4在各种逻辑推理任务上的表现。本文分析了多个逻辑推理数据集，包括LogiQA和ReClor等常用基准测试，以及像AR-LSAT这样的新发布的数据集。我们对需要逻辑推理的基准测试进行了多项选择阅读理解和自然语言推理任务测试。我们进一步构造了一个逻辑推理的分布之外的数据集，以研究ChatGPT和GPT-4的鲁棒性。我们还进行了ChatGPT和GPT-4之间的性能比较。实验结果表明，在大多数逻辑推理基准测试中，ChatGPT的表现远远优于RoBERTa微调方法。GPT-4在我们的手动测试中表现更高。在基准测试中，ChatGPT和GPT-4的表现相对较为均衡。

    Harnessing logical reasoning ability is a comprehensive natural language understanding endeavor. With the release of Generative Pretrained Transformer 4 (GPT-4), highlighted as "advanced" at reasoning tasks, we are eager to learn the GPT-4 performance on various logical reasoning tasks. This report analyses multiple logical reasoning datasets, with popular benchmarks like LogiQA and ReClor, and newly-released datasets like AR-LSAT. We test the multi-choice reading comprehension and natural language inference tasks with benchmarks requiring logical reasoning. We further construct a logical reasoning out-of-distribution dataset to investigate the robustness of ChatGPT and GPT-4. We also make a performance comparison between ChatGPT and GPT-4. Experiment results show that ChatGPT performs significantly better than the RoBERTa fine-tuning method on most logical reasoning benchmarks. GPT-4 shows even higher performance on our manual tests. Among benchmarks, ChatGPT and GPT-4 do relatively w
    
[^16]: 基于谷歌OCR扫描的藏文手稿的神经拼写纠错模型

    Cleansing Jewel: A Neural Spelling Correction Model Built On Google OCR-ed Tibetan Manuscripts. (arXiv:2304.03427v1 [cs.CL])

    [http://arxiv.org/abs/2304.03427](http://arxiv.org/abs/2304.03427)

    本文提出了一种基于谷歌OCR扫描的藏文手稿的神经拼写纠错模型，可以自动纠正OCR输出中的噪声。

    

    人文学者在研究历史、宗教和社会政治结构等方面经常依赖于古代手稿。虽然OCR技术可以将这些宝贵手稿数字化，但多数手稿因磨损而过时，OCR程序没办法识别翻页的虚淡或污渍。本文提出了一种基于谷歌OCR扫描的藏文手稿的神经拼写纠错模型，可以自动纠正OCR输出中的噪声。本文分为四个部分：数据集、模型架构、训练和分析。首先，我们对原始藏文电子文本语料库进行了特征工程，并将其转化为两组结构化数据框——一组匹配的玩具数据和一组匹配的真实数据。然后，我们在Transformer架构中实现了置信度得分机制来执行拼写校正任务。根据损失和字符错误率，我们的Transformer + 置信度得分机制比其他常用的拼写校正算法表现更好。

    Scholars in the humanities rely heavily on ancient manuscripts to study history, religion, and socio-political structures in the past. Many efforts have been devoted to digitizing these precious manuscripts using OCR technology, but most manuscripts were blemished over the centuries so that an Optical Character Recognition (OCR) program cannot be expected to capture faded graphs and stains on pages. This work presents a neural spelling correction model built on Google OCR-ed Tibetan Manuscripts to auto-correct OCR-ed noisy output. This paper is divided into four sections: dataset, model architecture, training and analysis. First, we feature-engineered our raw Tibetan etext corpus into two sets of structured data frames -- a set of paired toy data and a set of paired real data. Then, we implemented a Confidence Score mechanism into the Transformer architecture to perform spelling correction tasks. According to the Loss and Character Error Rate, our Transformer + Confidence score mechani
    
[^17]: 在新闻报道中探究选择性偏见的语料库规模发现：以比较不同来源对实体的报道为起点

    Towards Corpus-Scale Discovery of Selection Biases in News Coverage: Comparing What Sources Say About Entities as a Start. (arXiv:2304.03414v1 [cs.CL])

    [http://arxiv.org/abs/2304.03414](http://arxiv.org/abs/2304.03414)

    本文旨在探讨如何从大规模新闻语料库中直接发现媒体选择性偏见模式，并提出一种以不同来源报道的实体为起点的方法，通过比较计算选择性偏见。结果表明该方法可以用于发现容易受到偏见报道的话题。

    

    新闻报道涉及选择性过程，涵盖某一主题时不可避免地出现选择性偏见，即由于不同议题产生的报道选择不同所造成的讯息偏差。为了了解偏见的程度和影响，必须先发现以下两方面的内容：（1）新闻来源通常在哪些议题上对“值得报道”的信息定义存在分歧；（2）内容选择模式是否与新闻来源的某些属性（如意识形态倾向等）相关联。本文旨在探讨从海量新闻语料库直接发现媒体选择性偏见模式的可扩展NLP系统的挑战，并提出和研究一个概念框架，比较不同来源如何报道某些有争议的实体，并利用差异度量选择性偏见。我们的结果表明，这种方法可以有效地识别选择性偏见，并用于发现容易受到偏见报道的话题。

    News sources undergo the process of selecting newsworthy information when covering a certain topic. The process inevitably exhibits selection biases, i.e. news sources' typical patterns of choosing what information to include in news coverage, due to their agenda differences. To understand the magnitude and implications of selection biases, one must first discover (1) on what topics do sources typically have diverging definitions of "newsworthy" information, and (2) do the content selection patterns correlate with certain attributes of the news sources, e.g. ideological leaning, etc.  The goal of the paper is to investigate and discuss the challenges of building scalable NLP systems for discovering patterns of media selection biases directly from news content in massive-scale news corpora, without relying on labeled data. To facilitate research in this domain, we propose and study a conceptual framework, where we compare how sources typically mention certain controversial entities, and
    
[^18]: CAPOT: 使用后训练对比对齐创建强健的密集查询编码器

    CAPOT: Creating Robust Dense Query Encoders using Post Training Contrastive Alignment. (arXiv:2304.03401v1 [cs.IR])

    [http://arxiv.org/abs/2304.03401](http://arxiv.org/abs/2304.03401)

    CAPOT使用后训练对比对齐的方法，提高模型对于噪声查询的健壮性，表现类似于数据增强但没有其开销。

    

    上下文词表示的成功和神经信息检索的进步使得基于密集向量的检索成为段落和文档排名的标准方法。双编码器虽然有效和高效，但对查询分布和嘈杂查询变化很脆弱。数据增强可以使模型更加健壮，但会引入训练集生成的开销，并需要重新训练和索引重建。我们提出了 Contrastive Alignment POst Training (CAPOT)，一种高效的微调方法，通过冻结文档编码器，让查询编码器学习将嘈杂查询与其未更改的根对齐，以提高模型的健壮性。我们评估了 CAPOT 在 MSMARCO、自然问题和 Trivia QA 段落检索的嘈杂变体上，发现 CAPOT 具有与数据增强类似的影响，但没有它的开销。

    The success of contextual word representations and advances in neural information retrieval have made dense vector-based retrieval a standard approach for passage and document ranking. While effective and efficient, dual-encoders are brittle to variations in query distributions and noisy queries. Data augmentation can make models more robust but introduces overhead to training set generation and requires retraining and index regeneration. We present Contrastive Alignment POst Training (CAPOT), a highly efficient finetuning method that improves model robustness without requiring index regeneration, the training set optimization, or alteration. CAPOT enables robust retrieval by freezing the document encoder while the query encoder learns to align noisy queries with their unaltered root. We evaluate CAPOT noisy variants of MSMARCO, Natural Questions, and Trivia QA passage retrieval, finding CAPOT has a similar impact as data augmentation with none of its overhead.
    
[^19]: 使用新数据集的LSTM和GRU进行阿拉伯语命名实体识别

    Using LSTM and GRU With a New Dataset for Named Entity Recognition in the Arabic Language. (arXiv:2304.03399v1 [cs.CL])

    [http://arxiv.org/abs/2304.03399](http://arxiv.org/abs/2304.03399)

    本文提出了使用新的数据集和LSTM、GRU模型进行阿拉伯语命名实体识别的方法，结果良好，准确率达到80%。

    

    命名实体识别(NER)是一项自然语言处理任务(NLP)，旨在识别命名实体并对其进行分类，如人物、地点、组织等。在阿拉伯语中，可以找到相当数量的非结构化数据，需要使用不同的预处理工具处理，而不同于英语、俄语、德语等的语言。因此，在解决结构化数据缺乏的问题时，构建一个新的结构化数据集的重要性引人注目。本文使用BIOES格式标记单词，这使我们可以处理由多个句子组成的嵌套命名实体，并定义名称的开始和结束。该数据集包含三万六千多条记录。此外，本文提出使用长短时记忆(LSTM)单元和门控循环单元(GRU)构建阿拉伯语命名实体识别模型。该模型给出了近80%的良好结果，因为LSTM和GRU模型可以找到当前词和前面词之间的关系，这对于阿拉伯语的复杂语法结构非常重要。

    Named entity recognition (NER) is a natural language processing task (NLP), which aims to identify named entities and classify them like person, location, organization, etc. In the Arabic language, we can find a considerable size of unstructured data, and it needs to different preprocessing tool than languages like (English, Russian, German...). From this point, we can note the importance of building a new structured dataset to solve the lack of structured data. In this work, we use the BIOES format to tag the word, which allows us to handle the nested name entity that consists of more than one sentence and define the start and the end of the name. The dataset consists of more than thirty-six thousand records. In addition, this work proposes long short term memory (LSTM) units and Gated Recurrent Units (GRU) for building the named entity recognition model in the Arabic language. The models give an approximately good result (80%) because LSTM and GRU models can find the relationships be
    
[^20]: 深度学习应用于课程评论的观点挖掘和主题分类

    Deep Learning for Opinion Mining and Topic Classification of Course Reviews. (arXiv:2304.03394v1 [cs.CL])

    [http://arxiv.org/abs/2304.03394](http://arxiv.org/abs/2304.03394)

    本文利用自然语言处理和深度学习技术，通过比较传统方法和现代机器学习方法，展示了如何处理大量课程评论，进行情感极性分析和主题分类。

    

    对于教育工作者和管理者来说，学生对课程的反馈意见非常重要，无论课程的类型或机构如何。在机构级别或在线论坛上处理大量的开放反馈变得不可行。在本文中，我们收集和预处理了大量公开可用的课程评论。我们应用机器学习技术，目的是了解学生的情感和主题。具体而言，我们利用了当前的自然语言处理技术，如词嵌入和深度神经网络，并采用最先进的BERT（双向编码器表示来自变压器）、RoBERTa（经过优化的BERT方法）和XLNet（广义自回归预训练）技术。我们进行了广泛的实验，比较了这些技术与传统方法的差异。这项比较研究展示了如何应用现代机器学习方法进行情感极性分析和主题分类。

    Student opinions for a course are important to educators and administrators, regardless of the type of the course or the institution. Reading and manually analyzing open-ended feedback becomes infeasible for massive volumes of comments at institution level or online forums. In this paper, we collected and pre-processed a large number of course reviews publicly available online. We applied machine learning techniques with the goal to gain insight into student sentiments and topics. Specifically, we utilized current Natural Language Processing (NLP) techniques, such as word embeddings and deep neural networks, and state-of-the-art BERT (Bidirectional Encoder Representations from Transformers), RoBERTa (Robustly optimized BERT approach) and XLNet (Generalized Auto-regression Pre-training). We performed extensive experimentation to compare these techniques versus traditional approaches. This comparative study demonstrates how to apply modern machine learning approaches for sentiment polari
    
[^21]: 论ChatGPT和情感增强提示在心理健康分析中的评估

    On the Evaluations of ChatGPT and Emotion-enhanced Prompting for Mental Health Analysis. (arXiv:2304.03347v1 [cs.CL])

    [http://arxiv.org/abs/2304.03347](http://arxiv.org/abs/2304.03347)

    本文全面评估了ChatGPT在心理健康分析和情感推理方面的表现，以及不同提示策略和情感信息对其性能的影响。结果显示，ChatGPT在心理健康分析方面表现良好，加入情感增强提示对某些任务效果显著。

    

    自动化心理健康分析显示出提高心理健康护理效率和可访问性的巨大潜力，而最近的主流方法利用预训练的语言模型(PLMs)作为骨干，并融入情感信息。最新的大型语言模型(LLMs)，如ChatGPT，在各种自然语言处理任务上表现出惊人的能力。然而，现有的ChatGPT零-shot性能研究在不充分的评估、情感信息利用和方法可解释性方面存在局限性。本文全面评估了ChatGPT在11个数据集上的心理健康分析和情感推理能力，涵盖了5个任务，包括二进制和多类心理健康状况检测、心理健康状况的原因/因素检测、对话中的情绪识别和因果情感蕴含。我们在实证分析中探究了不同提示策略以及情感增强提示对ChatGPT性能的影响。结果表明，ChatGPT在心理健康分析中有着良好的表现，并且在某些任务中加入情感增强提示效果显著。

    Automated mental health analysis shows great potential for enhancing the efficiency and accessibility of mental health care, whereas the recent dominant methods utilized pre-trained language models (PLMs) as the backbone and incorporated emotional information. The latest large language models (LLMs), such as ChatGPT, exhibit dramatic capabilities on diverse natural language processing tasks. However, existing studies on ChatGPT's zero-shot performance for mental health analysis have limitations in inadequate evaluation, utilization of emotional information, and explainability of methods. In this work, we comprehensively evaluate the mental health analysis and emotional reasoning ability of ChatGPT on 11 datasets across 5 tasks, including binary and multi-class mental health condition detection, cause/factor detection of mental health conditions, emotion recognition in conversations, and causal emotion entailment. We empirically analyze the impact of different prompting strategies with 
    
[^22]: ChatGPT-Crawler：发现ChatGPT是否真的知道自己在说什么。（arXiv:2304.03325v1 [cs.CL]）

    ChatGPT-Crawler: Find out if ChatGPT really knows what it's talking about. (arXiv:2304.03325v1 [cs.CL])

    [http://arxiv.org/abs/2304.03325](http://arxiv.org/abs/2304.03325)

    本文分析了从不同对话QA语料库中生成的ChatGPT的响应，并比较了其与正确答案的相似度。研究发现ChatGPT在某些情况下提供了错误的答案，提供了潜在用户和开发者的宝贵见解。

    

    大型语言模型因其在各种任务上的出色表现而引起了人们的极大兴趣。其中，OpenAI开发的ChatGPT已经成为早期采用者中非常流行的模型，他们甚至将其视为客户服务、教育、医疗和金融等许多领域的破坏性技术。理解这些初期用户的观点非常重要，因为它可以为不同领域技术的潜在优势、劣势、成功或失败提供有价值的洞见。本研究考察了ChatGPT从不同对话QA语料库中生成的响应。研究使用BERT相似度分数将这些响应与正确答案进行比较，并获得自然语言推理（NLI）标签。还计算并比较了评估分数，以确定GPT-3＆GPT-4的整体性能。此外，该研究还确定了ChatGPT提供错误答案的情况，为相关领域提供了洞见。

    Large language models have gained considerable interest for their impressive performance on various tasks. Among these models, ChatGPT developed by OpenAI has become extremely popular among early adopters who even regard it as a disruptive technology in many fields like customer service, education, healthcare, and finance. It is essential to comprehend the opinions of these initial users as it can provide valuable insights into the potential strengths, weaknesses, and success or failure of the technology in different areas. This research examines the responses generated by ChatGPT from different Conversational QA corpora. The study employed BERT similarity scores to compare these responses with correct answers and obtain Natural Language Inference(NLI) labels. Evaluation scores were also computed and compared to determine the overall performance of GPT-3 \& GPT-4. Additionally, the study identified instances where ChatGPT provided incorrect answers to questions, providing insights into
    
[^23]: 自然语言规范中的数学程序合成

    Synthesis of Mathematical programs from Natural Language Specifications. (arXiv:2304.03287v1 [cs.AI])

    [http://arxiv.org/abs/2304.03287](http://arxiv.org/abs/2304.03287)

    本论文关注于通过自然语言规范中的目标和约束合成数学程序，并通过评估CodeT5和使用GPT-3来生成需要的示例进行实验。

    

    在各个商业领域中遇到的几个决策问题可以被建模为数学程序，即优化问题。进行这种建模的过程通常需要涉及到受过运筹学和高级算法培训的专家。令人惊讶的是，尽管程序和代码合成，AutoML，学习优化等方面的方法取得了重大进展，但几乎没有人关注自动化合成数学程序的任务。我们想象一种情景，在这种情况下，建模的规范，即目标和约束以自然语言的形式表达，并且必须从这样的自然语言规范中合成数学程序。在这项工作中，我们评估了使用带有数据增强和束后处理的CodeT5的功效。我们利用GPT-3进行背翻译以生成合成示例。此外，我们应用线性规划规则来评分。

    Several decision problems that are encountered in various business domains can be modeled as mathematical programs, i.e. optimization problems. The process of conducting such modeling often requires the involvement of experts trained in operations research and advanced algorithms. Surprisingly, despite the significant advances in the methods for program and code synthesis, AutoML, learning to optimize etc., there has been little or no attention paid to automating the task of synthesizing mathematical programs. We imagine a scenario where the specifications for modeling, i.e. the objective and constraints are expressed in an unstructured form in natural language (NL) and the mathematical program has to be synthesized from such an NL specification. In this work we evaluate the efficacy of employing CodeT5 with data augmentation and post-processing of beams. We utilize GPT-3 with back translation for generation of synthetic examples. Further we apply rules of linear programming to score b
    
[^24]: 大型语言模型在文学翻译中高效利用文档级上下文，但关键错误仍然存在

    Large language models effectively leverage document-level context for literary translation, but critical errors persist. (arXiv:2304.03245v1 [cs.CL])

    [http://arxiv.org/abs/2304.03245](http://arxiv.org/abs/2304.03245)

    该研究通过人工评估发现，大型语言模型在进行文学段落翻译时会利用更多的文档级上下文，从而减少关键错误。然而，一些与上下文和意义相关的错误仍然存在。

    

    大型语言模型（LLMs）在许多句子级别的翻译数据集上与现有技术水平相当。然而，它们在段落和文档翻译方面的能力尚未得到探究，因为这些环境下的评估代价高且困难。通过一项严谨的人工评估，我们展示了要求Gpt-3.5（text-davinci-003）LLM将整个文学段落（例如，从小说中）进行翻译的结果比标准的逐句翻译在18个语言对（例如，日语、波兰语和英语的翻译）上产生更高质量的翻译。我们的评估需要约350个小时的注释和分析工作，通过聘请熟练掌握源语言和目标语言的译者，并要求他们提供跨度级别的错误注释以及哪种系统的翻译更好的偏好判断。我们观察到，篇章级别的LLM翻译在文学段落的翻译中出现的关键错误更少，但仍存在一些与上下文和意义相关的错误。

    Large language models (LLMs) are competitive with the state of the art on a wide range of sentence-level translation datasets. However, their ability to translate paragraphs and documents remains unexplored because evaluation in these settings is costly and difficult. We show through a rigorous human evaluation that asking the Gpt-3.5 (text-davinci-003) LLM to translate an entire literary paragraph (e.g., from a novel) at once results in higher-quality translations than standard sentence-by-sentence translation across 18 linguistically-diverse language pairs (e.g., translating into and out of Japanese, Polish, and English). Our evaluation, which took approximately 350 hours of effort for annotation and analysis, is conducted by hiring translators fluent in both the source and target language and asking them to provide both span-level error annotations as well as preference judgments of which system's translations are better. We observe that discourse-level LLM translators commit fewer 
    
[^25]: 关于多语言神经机器翻译的Pareto前沿研究

    On the Pareto Front of Multilingual Neural Machine Translation. (arXiv:2304.03216v1 [cs.CL])

    [http://arxiv.org/abs/2304.03216](http://arxiv.org/abs/2304.03216)

    本研究针对多语言神经机器翻译的数据不平衡问题，提出双重幂律方法用于预测独特的性能权衡前沿，并建立基于该方法的样本比例选择优化问题，取得更好的结果。

    

    本研究探讨了在多语言神经机器翻译中，给定方向的泛化性能如何随其采样比例的变化而变化。通过训练200多个具有不同模型大小、方向和总任务数量的多语言模型，我们发现在训练语料库存在数据不平衡时，标量化导致了一个多任务权衡前沿，该前沿偏离了传统的Pareto前沿。基于我们的观察，我们提出了双重幂律来预测MNMT中独特的性能权衡前沿，该方法在各种语言、数据充足性和任务数量方面都很鲁棒。最后，我们将MNMT中的样本比例选择问题建模为基于双重幂律的优化问题，取得了更好的结果。

    In this work, we study how the generalization performance of a given direction changes with its sampling ratio in Multilingual Neural Machine Translation (MNMT). By training over 200 multilingual models with various model sizes, directions, and total numbers of tasks, we find that scalarization leads to a multitask trade-off front that deviates from the traditional Pareto front when there exists data imbalance in the training corpus. That is, the performance of certain translation directions does not improve with the increase of its weight in the multi-task optimization objective, which poses greater challenge to improve the overall performance of all directions. Based on our observations, we propose the Double Power Law to predict the unique performance trade-off front in MNMT, which is robust across various languages, data adequacy and number of tasks. Finally, we formulate sample ratio selection in MNMT as an optimization problem based on the Double Power Law, which achieves better 
    
[^26]: ETPNav: 在连续环境中演化拓扑规划的视觉语言导航

    ETPNav: Evolving Topological Planning for Vision-Language Navigation in Continuous Environments. (arXiv:2304.03047v1 [cs.CV])

    [http://arxiv.org/abs/2304.03047](http://arxiv.org/abs/2304.03047)

    ETPNav是一个能够在连续环境中进行视觉语言导航的新导航框架，它具有两个关键技能：能够抽象环境与生成长程导航计划以及在连续环境中避障控制的能力。ETPNav使用演化算法优化拓扑规划模块并在Matterport3D模拟器上实现了最先进的性能，达到了人类水平的VLN-CE任务性能。

    

    视觉语言导航需要智能体遵循指示在环境中导航，该任务在体验式人工智能领域中具有潜在应用，如自治导航、搜索与救援和人机交互。本文提出了一个更为实用但具有挑战性的情景 - 在连续环境中进行视觉语言导航（VLN-CE）。为了开发一个强大的VLN-CE代理，我们提出了一个新的导航框架ETPNav，它专注于两个关键技能：1）抽象环境和生成长程导航计划的能力；和2）在连续环境中避障控制的能力。ETPNav通过自组织沿着经过的路径预测的路标进行在线环境拓扑映射，而不需要先前的环境经验。它将导航过程分解为高层规划和低层控制。同时，ETPNav使用一种新颖的演化算法来优化拓扑规划模块，以实现有效的长期导航计划。所提出的方法在Matterport3D模拟器上实现了最先进的性能，并在任意起点和终点的VLN-CE任务中达到了人类水平的性能。

    Vision-language navigation is a task that requires an agent to follow instructions to navigate in environments. It becomes increasingly crucial in the field of embodied AI, with potential applications in autonomous navigation, search and rescue, and human-robot interaction. In this paper, we propose to address a more practical yet challenging counterpart setting - vision-language navigation in continuous environments (VLN-CE). To develop a robust VLN-CE agent, we propose a new navigation framework, ETPNav, which focuses on two critical skills: 1) the capability to abstract environments and generate long-range navigation plans, and 2) the ability of obstacle-avoiding control in continuous environments. ETPNav performs online topological mapping of environments by self-organizing predicted waypoints along a traversed path, without prior environmental experience. It privileges the agent to break down the navigation procedure into high-level planning and low-level control. Concurrently, ET
    
[^27]: 解锁ChatGPT的潜力：对其在自然语言处理中应用、优点、局限性和未来方向的全面探讨

    Unlocking the Potential of ChatGPT: A Comprehensive Exploration of its Applications, Advantages, Limitations, and Future Directions in Natural Language Processing. (arXiv:2304.02017v1 [cs.CL])

    [http://arxiv.org/abs/2304.02017](http://arxiv.org/abs/2304.02017)

    本文全面探讨了ChatGPT在自然语言处理中的应用、优点和局限性，强调了使用这个强大工具时的道德考虑，为人工智能和NLP领域的讨论做出了贡献。

    

    ChatGPT是人工智能领域中广泛应用的强大工具，已成功应用于聊天机器人、内容生成、语言翻译、个性化推荐和医疗诊断治疗。它的多功能性和准确性使其成为自然语言处理（NLP）的强大工具。但是，ChatGPT也存在局限性，例如其倾向于产生有偏见的响应以及存在潜在的有害语言模式。本文全面概述了ChatGPT及其应用、优点和局限性，并强调了在真实场景中使用这个强大工具时道德考虑的重要性。最后，本文通过提供提示工程技术的见解，为关于人工智能及其对视觉和NLP领域的影响的持续讨论做出了贡献。

    ChatGPT is a powerful tool in the field of artificial intelligence that has been widely used in various applications. ChatGPT has been applied successfully in chatbots, content generation, language translation, personalized recommendations, and medical diagnosis and treatment. Its versatility and accuracy make it a powerful tool for natural language processing (NLP). However, there are also limitations to ChatGPT, such as its tendency to produce biased responses and its potential to perpetuate harmful language patterns. This article provides a comprehensive overview of ChatGPT, its applications, advantages, and limitations. Additionally, the paper emphasizes the importance of ethical considerations when using this robust tool in real-world scenarios. Finally, This paper contributes to ongoing discussions surrounding artificial intelligence and its impact on vision and NLP domains by providing insights into prompt engineering techniques.
    
[^28]: GPTEval：使用GPT-4和更好的人类对齐来评估NLG

    GPTEval: NLG Evaluation using GPT-4 with Better Human Alignment. (arXiv:2303.16634v1 [cs.CL])

    [http://arxiv.org/abs/2303.16634](http://arxiv.org/abs/2303.16634)

    本文介绍了GPTEval，一个利用链式思考和形式填充评价NLG生成的质量。实验表明，在文本摘要任务中，GPTEval结合GPT-4取得了0.514的斯皮尔曼相关系数，胜过其他方法。

    

    自然语言生成（NLG）系统生成的文本质量很难进行自动测量。传统的基于参考的度量标准，如BLEU和ROUGE已被证明在需要创造性和多样性的任务中与人类判断的相关性相对较低。最近的研究建议使用大型语言模型（LLMs）作为无参考的NLG评估度量标准，这些模型适用于缺乏人类参考的新任务。然而，这些基于LLM的评估器仍然比中等规模的神经评估器的人类对应度低。在这项工作中，我们提出了GPTEval，一个使用链式思考（CoT）和形式填充范式来评估NLG输出质量的框架。我们针对两个生成任务，文本摘要和对话生成进行了实验。我们展示出，GPTEval结合GPT-4作为骨干模型，在摘要任务上实现了0.514的斯皮尔曼相关系数，胜过其他方法。

    The quality of texts generated by natural language generation (NLG) systems is hard to measure automatically. Conventional reference-based metrics, such as BLEU and ROUGE, have been shown to have relatively low correlation with human judgments, especially for tasks that require creativity and diversity. Recent studies suggest using large language models (LLMs) as reference-free metrics for NLG evaluation, which have the benefit of being applicable to new tasks that lack human references. However, these LLM-based evaluators still have lower human correspondence than medium-size neural evaluators. In this work, we present GPTEval, a framework of using large language models with chain-of-thoughts (CoT) and a form-filling paradigm, to assess the quality of NLG outputs. We experiment with two generation tasks, text summarization and dialogue generation. We show that GPTEval with GPT-4 as the backbone model achieves a Spearman correlation of 0.514 with human on summarization task, outperform
    
[^29]: VideoXum: 视频的跨模态视觉和文本摘要

    VideoXum: Cross-modal Visual and Textural Summarization of Videos. (arXiv:2303.12060v1 [cs.CV])

    [http://arxiv.org/abs/2303.12060](http://arxiv.org/abs/2303.12060)

    VideoXum是一个新的联合视频和文本摘要任务，它的目标是从长视频中生成对应的简化视频剪辑和文本摘要，利用了不同模态之间的关联和双重注意机制。该模型比现有的最先进方法在视频和文本摘要基准测试中表现更好。

    

    视频摘要旨在从源视频中提炼出最重要的信息，以生成简短的视频剪辑或文本叙述。我们提出了一种新的联合视频和文本摘要任务，并构建了一个大规模人工注释的数据集 -- VideoXum。我们的框架利用不同模态之间的关联，利用双重注意机制来对齐视觉和文本信息。实验结果表明，我们的方法在视频和文本摘要基准测试中优于现有的最先进方法。

    Video summarization aims to distill the most important information from a source video to produce either an abridged clip or a textual narrative. Traditionally, different methods have been proposed depending on whether the output is a video or text, thus ignoring the correlation between the two semantically related tasks of visual summarization and textual summarization. We propose a new joint video and text summarization task. The goal is to generate both a shortened video clip along with the corresponding textual summary from a long video, collectively referred to as a cross-modal summary. The generated shortened video clip and text narratives should be semantically well aligned. To this end, we first build a large-scale human-annotated dataset -- VideoXum (X refers to different modalities). The dataset is reannotated based on ActivityNet. After we filter out the videos that do not meet the length requirements, 14,001 long videos remain in our new dataset. Each video in our reannotat
    
[^30]: 临床BERTScore：临床环境下自动语音识别性能的改进度量

    Clinical BERTScore: An Improved Measure of Automatic Speech Recognition Performance in Clinical Settings. (arXiv:2303.05737v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2303.05737](http://arxiv.org/abs/2303.05737)

    本文提出了一种临床BERTScore（CBERTScore）度量，它比其他度量更严厉地惩罚临床相关的错误，更接近于临床医生对医学句子的偏好。作者还收集了13个临床医生对149个现实医学句子的偏好基准，称为临床转录偏好基准（CTP），证明CBERTScore更接近于临床医生的偏好，并将基准发布给社区以进一步开发具有临床意识的ASR度量。

    The paper proposes a Clinical BERTScore (CBERTScore) metric for ASR in medical contexts, which penalizes clinically-relevant mistakes more than other metrics and aligns more closely with clinician preferences. The authors also collect a benchmark of clinician preferences on medical sentences and release it for the community to further develop clinically-aware ASR metrics.

    医学环境中的自动语音识别（ASR）有潜力节省时间，降低成本，提高报告准确性并减少医生的疲劳。然而，由于避免医学相关的转录错误的重要性，医疗行业采用这种技术的速度较慢。在这项工作中，我们提出了临床BERTScore（CBERTScore），这是一种ASR度量，它比其他度量（WER、BLUE、METEOR等）更严厉地惩罚临床相关的错误。我们证明了这个度量更接近于临床医生对医学句子的偏好，有时差距很大。我们收集了13个临床医生对149个现实医学句子的偏好基准，称为临床转录偏好基准（CTP），证明CBERTScore更接近于临床医生的偏好，并将基准发布给社区以进一步开发具有临床意识的ASR度量。

    Automatic Speech Recognition (ASR) in medical contexts has the potential to save time, cut costs, increase report accuracy, and reduce physician burnout. However, the healthcare industry has been slower to adopt this technology, in part due to the importance of avoiding medically-relevant transcription mistakes. In this work, we present the Clinical BERTScore (CBERTScore), an ASR metric that penalizes clinically-relevant mistakes more than others. We demonstrate that this metric more closely aligns with clinician preferences on medical sentences as compared to other metrics (WER, BLUE, METEOR, etc), sometimes by wide margins. We collect a benchmark of 13 clinician preferences on 149 realistic medical sentences called the Clinician Transcript Preference benchmark (CTP), demonstrate that CBERTScore more closely matches what clinicians prefer, and release the benchmark for the community to further develop clinically-aware ASR metrics.
    
[^31]: SemEval-2023任务11的Lon-ea：软硬标签预测中激活函数的比较。

    Lon-ea at SemEval-2023 Task 11: A Comparison of Activation Functions for Soft and Hard Label Prediction. (arXiv:2303.02468v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.02468](http://arxiv.org/abs/2303.02468)

    本研究研究了在软硬标签预测中，不同激活函数对于深度神经网络模型输出的影响，并引入了一种新的正弦激活函数。

    

    我们研究在学习不同意任务的软硬标签预测中，深度神经网络模型输出层中不同激活函数的影响。在该任务中，目标是通过预测软标签来量化不同意量。为了预测软标签，我们使用基于BERT的预处理器和编码器，并改变输出层中使用的激活函数，同时保持其他参数不变。然后将软标签用于硬标签预测。考虑的激活函数包括sigmoid函数以及添加到模型中的阶跃函数和本文中首次介绍的正弦激活函数。

    We study the influence of different activation functions in the output layer of deep neural network models for soft and hard label prediction in the learning with disagreement task. In this task, the goal is to quantify the amount of disagreement via predicting soft labels. To predict the soft labels, we use BERT-based preprocessors and encoders and vary the activation function used in the output layer, while keeping other parameters constant. The soft labels are then used for the hard label prediction. The activation functions considered are sigmoid as well as a step-function that is added to the model post-training and a sinusoidal activation function, which is introduced for the first time in this paper.
    
[^32]: 复杂问答和语言模型混合架构综述

    Complex QA and language models hybrid architectures, Survey. (arXiv:2302.09051v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.09051](http://arxiv.org/abs/2302.09051)

    本文综述了语言模型架构和策略的最新进展，并重点关注混合技术在复杂问题回答中的应用，讨论了该领域的挑战和未来研究方向。

    

    本文回顾了语言模型架构和策略的最新进展，重点关注混合技术在复杂问题回答中的应用。大型语言模型能够在标准问题上利用公共数据，但在解决更具体的复杂问题时（如在不同文化中个人自由概念的变化如何？什么是为减少气候变化而实现的最佳发电方法组合？），需要特定的架构、知识、技能、方法、敏感数据保护、可解释性、人类审批和多功能反馈。最近的项目如ChatGPT和GALACTICA允许非专业人员了解LLM在复杂QA中的巨大潜力以及同等强大的局限性。在本文中，我们首先审查所需的技能和评估技术。然后，我们综述了现有的混合架构，将LLM与基于规则的方法、信息检索、知识图谱和其他AI/ML技术相结合。最后，我们指出这些CQA系统的挑战，并提出未来研究的可能方向。

    This paper reviews the state-of-the-art of language models architectures and strategies for "complex" question-answering (QA, CQA, CPS) with a focus on hybridization. Large Language Models (LLM) are good at leveraging public data on standard problems but once you want to tackle more specific complex questions or problems (e.g. How does the concept of personal freedom vary between different cultures ? What is the best mix of power generation methods to reduce climate change ?) you may need specific architecture, knowledge, skills, methods, sensitive data protection, explainability, human approval and versatile feedback... Recent projects like ChatGPT and GALACTICA have allowed non-specialists to grasp the great potential as well as the equally strong limitations of LLM in complex QA. In this paper, we start by reviewing required skills and evaluation techniques. We integrate findings from the robust community edited research papers BIG, BLOOM and HELM which open source, benchmark and an
    
[^33]: Counteracts：在预训练语言模型中测试刻板印象的对抗性。

    Counteracts: Testing Stereotypical Representation in Pre-trained Language Models. (arXiv:2301.04347v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.04347](http://arxiv.org/abs/2301.04347)

    本文提出了一种使用反例测试预训练语言模型中内部刻板印象的方法，重点是性别偏见，结果表明模型在使用不相关的知识时表现出一定的鲁棒性，更倾向于使用浅层的语言线索来改变内部刻板印象。

    

    语言模型在各种自然语言理解任务中表现出了强大的性能。与人类一样，语言模型也可能从训练数据中学习到自己的偏见。随着越来越多的下游任务将语言模型作为管道的一部分集成，有必要了解内部刻板印象和减轻负面影响的方法。在本文中，我们提出了一种简单的方法，使用反例来测试预训练语言模型中的内部刻板印象。我们主要关注性别偏见，但该方法可以扩展到其他类型的偏见。我们评估了9个不同的填空式提示的模型，包括知识和基础提示。结果表明，在使用不相关的知识时，预训练语言模型表现出一定的鲁棒性，并且更倾向于使用浅层的语言线索，如单词位置和句法结构来改变内部刻板印象。

    Language models have demonstrated strong performance on various natural language understanding tasks. Similar to humans, language models could also have their own bias that is learned from the training data. As more and more downstream tasks integrate language models as part of the pipeline, it is necessary to understand the internal stereotypical representation and the methods to mitigate the negative effects. In this paper, we proposed a simple method to test the internal stereotypical representation in pre-trained language models using counterexamples. We mainly focused on gender bias, but the method can be extended to other types of bias. We evaluated models on 9 different cloze-style prompts consisting of knowledge and base prompts. Our results indicate that pre-trained language models show a certain amount of robustness when using unrelated knowledge, and prefer shallow linguistic cues, such as word position and syntactic structure, to alter the internal stereotypical representat
    
[^34]: 多模态和可解释的互联网迷因分类

    Multimodal and Explainable Internet Meme Classification. (arXiv:2212.05612v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.05612](http://arxiv.org/abs/2212.05612)

    本文提出了一种多模态和可解释的互联网迷因分类方法，旨在解决现有方法中忽略迷因语义和创建上下文导致公正内容管理困难的问题。作者采用示例和基于原型的推理并结合文本和视觉SOTA模型进行训练，成功在两个任务中检测了有害的迷因。

    

    在当前的环境中，网络平台已经被有效地武器化，被用于各种地缘政治事件和社会问题中，互联网迷因使得大规模的公正内容管理更加困难。现有的迷因分类和跟踪工作主要采用黑盒方法，没有明确考虑迷因的语义或其创建的上下文。在本文中，我们追求一种模块化和可解释的互联网迷因理解架构。我们设计并实现了多模态分类方法，对训练案例进行示例和基于原型的推理，并利用文本和视觉SOTA模型来表示各个案例。 我们研究了我们的模块化和可解释模型在检测两个现有任务中有害迷因的相关性：仇恨言论检测和厌女症分类。我们比较了基于示例和基于原型的方法以及文本，视觉和多模态模型之间的性能差异在不同的任务上。

    In the current context where online platforms have been effectively weaponized in a variety of geo-political events and social issues, Internet memes make fair content moderation at scale even more difficult. Existing work on meme classification and tracking has focused on black-box methods that do not explicitly consider the semantics of the memes or the context of their creation. In this paper, we pursue a modular and explainable architecture for Internet meme understanding. We design and implement multimodal classification methods that perform example- and prototype-based reasoning over training cases, while leveraging both textual and visual SOTA models to represent the individual cases. We study the relevance of our modular and explainable models in detecting harmful memes on two existing tasks: Hate Speech Detection and Misogyny Classification. We compare the performance between example- and prototype-based methods, and between text, vision, and multimodal models, across differen
    
[^35]: 自动化从电子健康档案记录中识别逐出状态

    Automated Identification of Eviction Status from Electronic Health Record Notes. (arXiv:2212.02762v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.02762](http://arxiv.org/abs/2212.02762)

    本研究开发了一种自然语言处理系统，可以自动从电子健康档案（EHR）记录中检测到逐出状态，并开发了一个新颖的模型KIRESH，已经显示出明显优于其他最先进的模型。

    

    目标：逐出是健康的重要社会和行为决定因素。逐出与一系列负面事件相关，可能导致失业、住房不安全/无家可归、长期贫困和精神健康问题。在本研究中，我们开发了一种自然语言处理系统，可以自动从电子健康档案（EHR）记录中检测到逐出状态。

    Objective: Evictions are important social and behavioral determinants of health. Evictions are associated with a cascade of negative events that can lead to unemployment, housing insecurity/homelessness, long-term poverty, and mental health problems. In this study, we developed a natural language processing system to automatically detect eviction status from electronic health record (EHR) notes.  Materials and Methods: We first defined eviction status (eviction presence and eviction period) and then annotated eviction status in 5000 EHR notes from the Veterans Health Administration (VHA). We developed a novel model, KIRESH, that has shown to substantially outperform other state-of-the-art models such as fine-tuning pre-trained language models like BioBERT and BioClinicalBERT. Moreover, we designed a novel prompt to further improve the model performance by using the intrinsic connection between the two sub-tasks of eviction presence and period prediction. Finally, we used the Temperatur
    
[^36]: 使用提示生成的原理实现忠实的语言推理——PINTO

    PINTO: Faithful Language Reasoning Using Prompt-Generated Rationales. (arXiv:2211.01562v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.01562](http://arxiv.org/abs/2211.01562)

    本文提出了PINTO，基于提示生成的方式实现LM的忠实推理，并通过反事实正则化来学习。实验表明，PINTO显著优于使用外部原理的基线，同时提供了可理解的、忠实反映LM决策过程的理性。

    

    神经语言模型（LM）利用自己预训练参数中的潜在知识在各种基于语言的推理任务上取得了令人瞩目的成果。为了使这个推理过程更加明确，最近的研究利用训练或提示的方式检索LM的内部知识生成自由文本原理，可以用于引导相同LM或单独的推理LM进行任务预测。然而，理性化的LM需要昂贵的原理注释和（或）计算，并不能保证它们生成的原理会改善LM的任务表现或忠实地反映LM的决策。本文提出了PINTO，一种通过提示生成的学习来理性化的LM管道，并通过反事实正则化学习忠实地推理原理。首先，PINTO通过提示冻结的理性化LM生成自由文本的原理，为任务输入制定了合适的推理过程。其次，PINTO的推理LM使用生成的原理进行预测，同时被反事实正则化项指导，该项鼓励即使对原理进行微小的更改，预测也相同。我们在各种语言推理数据集上的实验表明，PINTO显著优于使用外部原理的基线，同时提供了可理解的、忠实反映LM决策过程的理性。

    Neural language models (LMs) have achieved impressive results on various language-based reasoning tasks by utilizing latent knowledge encoded in their own pretrained parameters. To make this reasoning process more explicit, recent works retrieve a rationalizing LM's internal knowledge by training or prompting it to generate free-text rationales, which can be used to guide task predictions made by either the same LM or a separate reasoning LM. However, rationalizing LMs require expensive rationale annotation and/or computation, without any assurance that their generated rationales improve LM task performance or faithfully reflect LM decision-making. In this paper, we propose PINTO, an LM pipeline that rationalizes via prompt-based learning, and learns to faithfully reason over rationales via counterfactual regularization. First, PINTO maps out a suitable reasoning process for the task input by prompting a frozen rationalizing LM to generate a free-text rationale. Second, PINTO's reasoni
    
[^37]: SC-Ques：为英语学习者设计的句子填空问题数据集

    SC-Ques: A Sentence Completion Question Dataset for English as a Second Language Learners. (arXiv:2206.12036v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2206.12036](http://arxiv.org/abs/2206.12036)

    该论文介绍了一个针对英语学习者设计的大规模句子填空问题数据集\textsc{SC-Ques}，并且已经构建了一个综合基准来自动解决 SC 问题。

    

    句子填空（SC）问题提供了一个带有一个或多个空白需要填写的句子，并提供三至五个可能的单词或短语作为选项。 SC问题广泛用于学习英语作为第二语言（ESL）的学生。本文介绍了一个大规模的SC数据集\textsc{SC-Ques}，由来自真实标准英语考试的289,148个ESL SC问题组成。此外，我们通过在提出的\textsc{SC-Ques}数据集上训练大规模预训练语言模型，构建了一个自动解决SC问题的综合基准。我们对基线模型的性能、限制和权衡进行了详细的分析。数据和代码可用于研究目的：\url{https://github.com/ai4ed/SC-Ques}。

    Sentence completion (SC) questions present a sentence with one or more blanks that need to be filled in, three to five possible words or phrases as options. SC questions are widely used for students learning English as a Second Language (ESL). In this paper, we present a large-scale SC dataset, \textsc{SC-Ques}, which is made up of 289,148 ESL SC questions from real-world standardized English examinations. Furthermore, we build a comprehensive benchmark of automatically solving the SC questions by training the large-scale pre-trained language models on the proposed \textsc{SC-Ques} dataset. We conduct detailed analysis of the baseline models performance, limitations and trade-offs. The data and our code are available for research purposes from: \url{https://github.com/ai4ed/SC-Ques}.
    
[^38]: 让一阶线性逻辑成为生成语法

    Making first order linear logic a generating grammar. (arXiv:2206.08955v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2206.08955](http://arxiv.org/abs/2206.08955)

    本文研究了一阶线性逻辑与扩展张量类型演算的关系，提出了一种固有的演绎系统。

    

    众所周知，不同的范畴语法在一阶乘法线性逻辑的一个片段中具有表面表示。 我们表明，该片段等价于最近引入的扩展张量类型演算。 这不仅为前者提供了一些替代的语法和直观的几何表示，而且还提供了一个固有的演绎系统，这是以前缺少的。

    It is known that different categorial grammars have surface representation in a fragment of first order multiplicative linear logic. We show that the fragment of interest is equivalent to the recently introduced {\it extended tensor type calculus}. This provides the former not only with some alternative syntax and intuitive geometric representation, but also with an intrinsic deductive system, which has been absent.
    
[^39]: “探究预训练语言模型中的跨文化价值差异”

    Probing Pre-Trained Language Models for Cross-Cultural Differences in Values. (arXiv:2203.13722v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.13722](http://arxiv.org/abs/2203.13722)

    本文探究了预训练语言模型中跨文化的价值观差异，发现PTLMs捕捉到了文化之间的价值差异，但是这些价值差异只有微弱的相关性。跨文化应用中，将PTLMs与价值观对齐非常重要。

    

    语言承载了人们所持有的社会、文化、政治价值观。先前的研究探索了预训练语言模型（PTLMs）中编码的社会和潜在有害的偏见。然而，在透彻研究这些模型中嵌入的不同文化价值观方面，还没有系统的研究。在本文中，我们引入了探针来研究不同文化中模型中嵌入的价值观，以及它们是否与现有的理论和跨文化价值调查相符。我们发现PTLMs捕捉到了文化之间的价值差异，但是这些价值与已有的价值调查只有微弱的相关性。我们讨论了在跨文化环境下使用不符合价值观的模型的影响，以及将PTLMs与价值观对齐的方法。

    Language embeds information about social, cultural, and political values people hold. Prior work has explored social and potentially harmful biases encoded in Pre-Trained Language models (PTLMs). However, there has been no systematic study investigating how values embedded in these models vary across cultures. In this paper, we introduce probes to study which values across cultures are embedded in these models, and whether they align with existing theories and cross-cultural value surveys. We find that PTLMs capture differences in values across cultures, but those only weakly align with established value surveys. We discuss implications of using mis-aligned models in cross-cultural settings, as well as ways of aligning PTLMs with value surveys.
    
[^40]: 利用PSSM和词嵌入预测甲型流感病毒宿主

    Predicting Influenza A Viral Host Using PSSM and Word Embeddings. (arXiv:2201.01140v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2201.01140](http://arxiv.org/abs/2201.01140)

    该研究利用机器学习模型和特征提取方法，成功预测了甲型流感病毒的原始宿主，为早期和快速控制病毒传播提供了帮助。

    

    流感病毒的快速突变威胁公共健康，可能引发致命的大流行病。然而，检测病毒的原始宿主在爆发期间或爆发后是困难的，因为流感病毒可以在不同的物种之间循环传播。因此，早期和快速检测病毒宿主将有助于减少病毒的进一步传播。我们使用基于位置特异性得分矩阵（PSSM）和学习自词嵌入和词编码的特征的各种机器学习模型来推断病毒的原始宿主。结果表明，基于PSSM的模型的性能达到了95%左右的MCC和96%左右的F1。使用词嵌入的模型得到的MCC约为96％，F1约为97％。

    The rapid mutation of the influenza virus threatens public health. Reassortment among viruses with different hosts can lead to a fatal pandemic. However, it is difficult to detect the original host of the virus during or after an outbreak as influenza viruses can circulate between different species. Therefore, early and rapid detection of the viral host would help reduce the further spread of the virus. We use various machine learning models with features derived from the position-specific scoring matrix (PSSM) and features learned from word embedding and word encoding to infer the origin host of viruses. The results show that the performance of the PSSM-based model reaches the MCC around 95%, and the F1 around 96%. The MCC obtained using the model with word embedding is around 96%, and the F1 is around 97%.
    

