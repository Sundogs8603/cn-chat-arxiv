# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Learning from Emotions, Demographic Information and Implicit User Feedback in Task-Oriented Document-Grounded Dialogues.](http://arxiv.org/abs/2401.09248) | 本论文介绍了FEDI，这是第一个用人口统计信息、用户情绪和隐含反馈对任务导向的文档对话进行注释的英文对话数据集，实验证明这些数据有潜力改善任务完成情况、生成响应的事实一致性和用户接受程度。 |
| [^2] | [Cross-lingual Offensive Language Detection: A Systematic Review of Datasets, Transfer Approaches and Challenges.](http://arxiv.org/abs/2401.09244) | 这篇论文对社交媒体中跨语言冒犯性语言检测的技术进行了系统综述，分析了67篇相关论文，并总结了跨语言转移学习的三种主要方法。同时，还探讨了该领域的挑战和未来的研究机会。 |
| [^3] | [UniVIE: A Unified Label Space Approach to Visual Information Extraction from Form-like Documents.](http://arxiv.org/abs/2401.09220) | UniVIE是一种将VIE问题重新定义为关系预测问题，并将不同任务的标签统一到一个单一的标签空间中的统一模型，该模型使用由粗到细的策略，能够有效处理表单式文档中的层次关系。 |
| [^4] | [QAnswer: Towards Question Answering Search over Websites.](http://arxiv.org/abs/2401.09175) | QAnswer是一种面向网站的问答搜索系统，结合了知识图谱和自由文本的QA技术。该系统展示了将QA技术用于网站搜索的潜力，并讨论了两种方法的优缺点。 |
| [^5] | [Fine-tuning Strategies for Domain Specific Question Answering under Low Annotation Budget Constraints.](http://arxiv.org/abs/2401.09168) | 该研究对低预算下Fine-tuning QA模型的策略进行了研究分析，发现基于预训练语言模型进行Fine-tuning，并结合目标数据集和SQuAD数据集能够在不增加额外标注的情况下取得更好的性能。 |
| [^6] | [Bridging Research and Readers: A Multi-Modal Automated Academic Papers Interpretation System.](http://arxiv.org/abs/2401.09150) | 我们介绍了一个多模态自动化学术论文解读系统(MMAPIS)，它通过利用大规模语言模型来提升功能性。我们的系统包括三个步骤的处理阶段，并针对现有模型面临的挑战提供了解决方案，包括多模态数据处理，长文本摘要和多样化用户界面。 |
| [^7] | [Asynchronous Local-SGD Training for Language Modeling.](http://arxiv.org/abs/2401.09135) | 本文通过异步Local-SGD训练语言模型，并进行了全面的实证研究。研究发现，尽管异步更新更频繁，但其收敛所需的迭代次数多于同步方法。作者还提出了一种利用延迟的Nesterov动量更新进行调整的新方法来解决异步更新的挑战。 |
| [^8] | [What makes for a 'good' social actor? Using respect as a lens to evaluate interactions with language agents.](http://arxiv.org/abs/2401.09082) | 本文研究以尊重为视角评估与语言代理的交互，提出了一种更加关注关系和情境因素的伦理方法，旨在帮助LLM技术表现得“好” |
| [^9] | [Code Simulation Challenges for Large Language Models.](http://arxiv.org/abs/2401.09074) | 大型语言模型在模拟计算机代码和算法执行方面遇到挑战，性能随着代码长度的增加而迅速下降。在处理短程序或标准过程时，它们能以低错误率按顺序执行指令，但对于复杂的程序，特别是包含关键路径和冗余指令的程序，模拟效果较差。我们提出了一种逐行模拟代码执行的方法来解决这个问题。 |
| [^10] | [LLMs for Relational Reasoning: How Far are We?.](http://arxiv.org/abs/2401.09042) | 本论文对多种最先进的LLM的推理能力进行了全面评估，发现它们在归纳逻辑编程基准测试上的表现欠佳，这挑战了它们在处理常识规划的顺序决策问题方面的能力。 |
| [^11] | [Textual Summarisation of Large Sets: Towards a General Approach.](http://arxiv.org/abs/2401.09041) | 本文介绍了一种基于规则的自然语言生成技术，用于总结学术论文中的参考文献集合，扩展了之前关于总结消费品集合的工作，并展示了模型在不同领域中的泛化能力。 |
| [^12] | [Explain Thyself Bully: Sentiment Aided Cyberbullying Detection with Explanation.](http://arxiv.org/abs/2401.09023) | 本文介绍了第一个可解释的多任务模型mExCB，用于从混合语言中自动检测网络霸凌，并引入了解释性网络霸凌检测的基准数据集BullyExplain。 |
| [^13] | [Augmenting Math Word Problems via Iterative Question Composing.](http://arxiv.org/abs/2401.09003) | 本研究通过引入MMIQC数据集和迭代组合问题(IQC)的新颖增强方法，成功提高了大型语言模型的数学推理能力，在竞赛级数学问题上取得了优于先前最佳结果的准确率。 |
| [^14] | [AttackEval: How to Evaluate the Effectiveness of Jailbreak Attacking on Large Language Models.](http://arxiv.org/abs/2401.09002) | 本研究提出一种新方法评估大型语言模型上越狱攻击效果，引入粗粒度和细粒度评估框架，提供了更全面和细致的评估角度，并开发了专门的真实数据集作为基准，为未来研究建立了基础资源。 |
| [^15] | [Efficient Adapter Finetuning for Tail Languages in Streaming Multilingual ASR.](http://arxiv.org/abs/2401.08992) | 本研究通过在流式多语言ASR中采用简单而有效的适配器微调方法，提供了对边缘语种的支持。适配器仅占每种语言的模型的0.4%。该方法在级联的Conformer转录器框架下，通过教师伪标签增强了模型性能。 |
| [^16] | [OCTO+: A Suite for Automatic Open-Vocabulary Object Placement in Mixed Reality.](http://arxiv.org/abs/2401.08973) | 本论文介绍了一种称为OCTO + 的套件，用于在混合现实中自动将虚拟物体放置在合适的位置。通过使用最新的开放词汇视觉语言模型，该方法在多个评估标准上取得了最先进的效果，超过其他方法。同时，还引入了一个用于自动评估增强现实中虚拟物体放置的基准。 |
| [^17] | [ReFT: Reasoning with Reinforced Fine-Tuning.](http://arxiv.org/abs/2401.08967) | ReFT是一种加强推理能力的强化微调方法，通过利用更多的推理路径进行微调，提高了大型语言模型在数学问题解决中的泛化能力。 |
| [^18] | [Partial Diacritization: A Context-Contrastive Inference Approach.](http://arxiv.org/abs/2401.08919) | 部分音标化是选择标记部分字符来提高阅读可读性和准确性的新方法。上下文对比的部分音标化（CCPD）集成了现有的阿拉伯音标化系统，并通过衡量部分音标化的新指标来判断需要标记哪些字符。 |
| [^19] | [NOTSOFAR-1 Challenge: New Datasets, Baseline, and Tasks for Distant Meeting Transcription.](http://arxiv.org/abs/2401.08887) | NOTSOFAR-1挑战旨在解决远距离会议转录中的远距离发言人划分和自动语音识别问题，在一个新发布的数据集上进行评估。 |
| [^20] | [Using i-vectors for subject-independent cross-session EEG transfer learning.](http://arxiv.org/abs/2401.08851) | 本文提出了使用基于i向量的神经网络分类器进行跨主体跨会话EEG迁移学习的方法，相对于等效的主体相关模型取得了18%的相对改进。此外，我们还展示了我们的主体无关模型在新主体上的竞争力和额外主体数据的增加对模型性能的改善，表明有效的认知负荷确定不需要主体相关的训练。 |
| [^21] | [Improving ASR Contextual Biasing with Guided Attention.](http://arxiv.org/abs/2401.08835) | 本文提出了一种引导注意力的辅助训练损失方法，可以改进自动语音识别中的上下文偏差问题，不引入额外参数，并且通过实验证明在偏差短语数量增加时仍然保持有效性。 |
| [^22] | [Revisiting Self-supervised Learning of Speech Representation from a Mutual Information Perspective.](http://arxiv.org/abs/2401.08833) | 本文从信息论的角度重新审视了自监督学习的语音表征方法，开发了使用互信息来度量表征质量的方法，并通过线性探测器评估了表征与目标信息之间的互信息，为模型设计和选择提供了新的见解。 |
| [^23] | [AiGen-FoodReview: A Multimodal Dataset of Machine-Generated Restaurant Reviews and Images on Social Media.](http://arxiv.org/abs/2401.08825) | 本论文创建了一个多模态的机器生成的社交媒体餐厅评论和图像数据集AiGen-FoodReview，并开发了相应的检测模型，可用于鉴别真实和虚假的评论。通过使用可读性和摄影理论的属性评分，证明了这些属性作为手工特征在可伸缩和可解释的检测模型中的有效性。 |
| [^24] | [HuixiangDou: Overcoming Group Chat Scenarios with LLM-based Technical Assistance.](http://arxiv.org/abs/2401.08772) | HuixiangDou是一种由大型语言模型驱动的技术助手，旨在通过对开源算法项目相关问题的深入回答来协助算法开发人员。该助手已被成功整合到群聊工具中，有效地回答用户的技术问题，并具备评分能力、上下文学习和长上下文等关键要求。 |
| [^25] | [MMToM-QA: Multimodal Theory of Mind Question Answering.](http://arxiv.org/abs/2401.08743) | MMToM-QA是一个多模态心智理论问答基准，用于评估机器对于人的心智理论的理解能力。我们提出了一种新的方法BIP-ALM用于实现多模态心智理论能力。 |
| [^26] | [Combining Confidence Elicitation and Sample-based Methods for Uncertainty Quantification in Misinformation Mitigation.](http://arxiv.org/abs/2401.08694) | 本研究提出了一种结合置信度引导和基于样本的方法的不确定性量化框架，用于解决误信息消除中的幻觉和过度自信的预测问题，并提出了混合框架以提供更好的不确定性估计。 |
| [^27] | [Automated Answer Validation using Text Similarity.](http://arxiv.org/abs/2401.08688) | 该论文研究了使用文本相似性进行自动答案验证的方法，并实现了一个通用解决方案。在科学问题回答中，信息检索方法在多项选择问题中优于神经方法。通过比较我们的监督模型与其他文本相似性解决方案，我们展示了该方法的有效性。 |
| [^28] | [Adapting Large Language Models for Education: Foundational Capabilities, Potentials, and Challenges.](http://arxiv.org/abs/2401.08664) | 本文回顾了针对教育能力的大型语言模型研究，包括数学、写作、编程、推理和基于知识的问答，旨在探索其在构建下一代智能教育系统中的潜力和挑战。 |
| [^29] | [Gemini Pro Defeated by GPT-4V: Evidence from Education.](http://arxiv.org/abs/2401.08660) | 本研究比较了Gemini Pro和GPT-4V在教育领域的分类性能，发现GPT-4V在评分准确度和Quadratic Weighted Kappa方面明显优于Gemini Pro，可能是因为GPT-4V能够处理图像中的细致文本并具有更好的整体图像分类性能。 |
| [^30] | [Salute the Classic: Revisiting Challenges of Machine Translation in the Age of Large Language Models.](http://arxiv.org/abs/2401.08350) | 本文重新审视了机器翻译领域的六个核心挑战，并提供了对于大规模语言模型在这些挑战中所取得进展的实证发现。研究发现，大规模语言模型能够有效减少对平行数据的依赖，提高翻译质量并扩展翻译文档的长度范围。然而，领域不匹配和罕见词预测仍然是需要解决的问题。 |
| [^31] | [See the Unseen: Better Context-Consistent Knowledge-Editing by Noises.](http://arxiv.org/abs/2401.07544) | 本文通过对不同上下文对大型语言模型的影响进行高斯噪声采样，实现了对知识编辑的上下文一致性进行更好的推广，提高了编辑的普适性。 |
| [^32] | [Fine-grained Hallucination Detection and Editing for Language Models.](http://arxiv.org/abs/2401.06855) | 这项研究提出了一个新任务，即自动细粒度幻觉检测，并介绍了一个综合分类方法。通过对两个语言模型的输出进行分析，发现大部分幻觉属于少有的类别。为了解决这个问题，研究者通过训练一个检索增强语言模型，使用合成数据来检测和纠正幻觉。 |
| [^33] | [LightHouse: A Survey of AGI Hallucination.](http://arxiv.org/abs/2401.06792) | 该论文综述了AGI（人工通用智能）的幻觉现象，总结了当前对AGI幻觉的研究进展，并提出了一些未来研究方向的建议。 |
| [^34] | [AboutMe: Using Self-Descriptions in Webpages to Document the Effects of English Pretraining Data Filters.](http://arxiv.org/abs/2401.06408) | 这项研究调查了十个质量和语言识别过滤器对不同社交维度变化的网页的影响。实验发现在数据筛选过程中存在隐含的偏好，一些质量分类器类似于主题过滤器，而语言识别可能会忽视某些地区的英语内容。我们的研究为促进更公正和全面的模型开发提供了洞察。 |
| [^35] | [AUTOACT: Automatic Agent Learning from Scratch via Self-Planning.](http://arxiv.org/abs/2401.05268) | AUTOACT是一个自动代理学习框架，通过自主规划合成轨迹，不依赖于大规模数据和闭源模型，能够实现更好或类似的性能。 |
| [^36] | [MLLM-Protector: Ensuring MLLM's Safety without Hurting Performance.](http://arxiv.org/abs/2401.02906) | MLLM-Protektor是一个即插即用的方法，用于保护多模态大型语言模型免受恶意攻击。通过解决图像与文本对齐的挑战，该方法提供了对MLLM的有效保护，防止其产生有害响应。 |
| [^37] | [Paralinguistics-Enhanced Large Language Modeling of Spoken Dialogue.](http://arxiv.org/abs/2312.15316) | 提出了一种增强声调语言的预训练变换器，利用文本和语音模态来更好地建模口语对话的语言内容和声调语言属性。 |
| [^38] | [Language Modeling on a SpiNNaker 2 Neuromorphic Chip.](http://arxiv.org/abs/2312.09084) | 该论文介绍了在SpiNNaker 2神经形态芯片上实现语言建模的首次尝试。通过利用基于事件的架构和大规模异步处理的硬件，该方法有望在减少能耗的同时保持竞争任务性能。 |
| [^39] | [TiMix: Text-aware Image Mixing for Effective Vision-Language Pre-training.](http://arxiv.org/abs/2312.08846) | TiMix是一种将文本感知的图像混合技术用于视觉语言预训练的方法，通过集成混合数据增强技术，并从互信息的角度进行理论分析，提高了数据效率并取得了可比较的性能。 |
| [^40] | [CLadder: A Benchmark to Assess Causal Reasoning Capabilities of Language Models.](http://arxiv.org/abs/2312.04350) | 该论文提出了一个新的NLP任务，评估语言模型在因果推理方面的能力。作者构建了一个大规模的数据集CLadder，并利用oracle因果推理引擎将符号问题转化为自然语言。研究结果表明多个LLMs在该数据集上的表现，并引入并评估了一种定制的链式推理机制。 |
| [^41] | [Dynamic Fault Characteristics Evaluation in Power Grid.](http://arxiv.org/abs/2311.16522) | 该论文提出了一种在电力系统中进行故障检测的新方法，通过图神经网络识别故障节点，并利用前后时间段内节点的状态来辅助当前故障检测。实验证明该方法准确可靠，并提供了对故障节点传播的定性分析。 |
| [^42] | [Dynamic Fault Analysis in Substations Based on Knowledge Graphs.](http://arxiv.org/abs/2311.13708) | 提出了一种基于知识图谱的变电站动态故障分析方法，利用非结构化文本提取相关信息，通过隐藏马尔科夫模型训练数据，利用Neo4j图数据库创建知识图谱，实现对变电站中隐藏危险的可视化分析。 |
| [^43] | [LQ-LoRA: Low-rank Plus Quantized Matrix Decomposition for Efficient Language Model Finetuning.](http://arxiv.org/abs/2311.12023) | LQ-LoRA是一种低秩加量化矩阵分解方法，用于内存高效的语言模型微调。它通过将每个预训练矩阵分解为高精度低秩部分和内存高效的量化部分，实现了动态配置量化参数以及对重构目标进行加权的优化，并在微调实验中表现出了优于QLoRA和GPTQ-LoRA的效果。 |
| [^44] | [Modelling prospective memory and resilient situated communications via Wizard of Oz.](http://arxiv.org/abs/2311.05268) | 通过奥兹魔术师模拟未来记忆和具有韧性的定位通信，在家庭环境中探索与社交辅助机器人的沟通记忆建模。 |
| [^45] | [DistilWhisper: Efficient Distillation of Multi-task Speech Models via Language-Specific Experts.](http://arxiv.org/abs/2311.01070) | 本文提出了DistilWhisper方法，通过使用语言特定专家进行轻量级模块化ASR微调和知识蒸馏，成功弥合了多任务语音模型在少数语言上的性能差距，同时保留了多任务和多语言能力的优势。 |
| [^46] | [DialogueLLM: Context and Emotion Knowledge-Tuned Large Language Models for Emotion Recognition in Conversations.](http://arxiv.org/abs/2310.11374) | DialogueLLM是一种通过使用多模态情感对话微调的上下文和情感知识调校的大型语言模型，用于情感识别任务。 |
| [^47] | [Towards Best Practices of Activation Patching in Language Models: Metrics and Methods.](http://arxiv.org/abs/2309.16042) | 本研究系统地考察了激活路径修复中的方法细节对语言模型解释性结果的影响，并提出了最佳实践建议。 |
| [^48] | [Watch Your Language: Large Language Models and Content Moderation.](http://arxiv.org/abs/2309.14517) | 本研究评估了大型语言模型在内容审查任务上的表现，发现它们在基于规则的社区审查和有害内容检测方面具有很好的效果，在有害内容检测方面超过了现有的分类器。然而，最近模型规模的增加对有害内容检测的改进效果很小。 |
| [^49] | [A Chat About Boring Problems: Studying GPT-based text normalization.](http://arxiv.org/abs/2309.13426) | 本文研究了基于GPT的文本规范化任务。通过结合自洽推理和基于语言知识的提示工程，我们发现基于LLM的文本规范化的错误率比顶级规范化系统低约40％。同时，通过对错误分析，我们发现传统的文本规范化任务设计存在关键限制。我们创建了一个新的框架以识别基于GPT的文本规范化的优势和局限性。这为未来的工作提供了机会。 |
| [^50] | [Semantic similarity prediction is better than other semantic similarity measures.](http://arxiv.org/abs/2309.12697) | 本文提出了一种使用经过微调的模型直接预测语义相似性的方法，并将其与其他方法进行比较，结果表明所得到的相似性更加符合我们对鲁棒的语义相似性度量的预期。 |
| [^51] | [Large Language Model as Autonomous Decision Maker.](http://arxiv.org/abs/2308.12519) | 本文提出了一种方法JuDec，为大型语言模型(LLMs)赋予了自我判断的能力，使其能够作为自主决策者实现自主判断和决策探索。实验结果显示JuDec在不同任务上表现优异，提高了通过率并降低了成本。 |
| [^52] | [Large Language Model Displays Emergent Ability to Interpret Novel Literary Metaphors.](http://arxiv.org/abs/2308.01497) | 最近的研究评估了GPT-4，一种大型语言模型，对来自塞尔维亚诗歌的新颖文学隐喻的解释能力。 |
| [^53] | [Sumformer: A Linear-Complexity Alternative to Self-Attention for Speech Recognition.](http://arxiv.org/abs/2307.07421) | Sumformer提出了一种线性时间代替自注意力的方法，用总结混合来处理语音识别任务，可以在保持准确性的同时降低训练和推理时间。 |
| [^54] | [GKD: Generalized Knowledge Distillation for Auto-regressive Sequence Models.](http://arxiv.org/abs/2306.13649) | 本文提出了广义知识蒸馏（GKD），通过从学生中采样输出序列来缓解分布不匹配，并在优化替代KL等离散度方面处理模型欠规范，达到了在摘要任务上最先进的性能。 |
| [^55] | [On the Hidden Mystery of OCR in Large Multimodal Models.](http://arxiv.org/abs/2305.07895) | 本研究全面评估了现有大型多模态模型在文本相关的视觉任务中的表现，结果显示这些模型虽然在语义理解方面表现优异，但对单个字符形状的感知有限，对图像的细粒度特征检测能力也不足，不能与传统领域特定方法相匹配，并仍需进一步探索它们在OCR中的表现。 |
| [^56] | [CryCeleb: A Speaker Verification Dataset Based on Infant Cry Sounds.](http://arxiv.org/abs/2305.00969) | CryCeleb是一个基于婴儿哭声的说话人认证数据集，包括超过6小时的手动分割哭声，可用于研究婴儿哭声分析。 |
| [^57] | [BiomedCLIP: a multimodal biomedical foundation model pretrained from fifteen million scientific image-text pairs.](http://arxiv.org/abs/2303.00915) | BiomedCLIP是一个从1500万科学图像-文本对中预训练的多模态生物医学基础模型，其基于大规模的PMC-15M数据集进行训练，该数据集比现有的生物医学多模态数据集大两个数量级，并成功应用于生物医学图像任务的检索、分类和视觉问题回答等方面。 |

# 详细

[^1]: 从情绪、人口统计信息和隐含用户反馈中学习任务导向的文档对话

    Learning from Emotions, Demographic Information and Implicit User Feedback in Task-Oriented Document-Grounded Dialogues. (arXiv:2401.09248v1 [cs.CL])

    [http://arxiv.org/abs/2401.09248](http://arxiv.org/abs/2401.09248)

    本论文介绍了FEDI，这是第一个用人口统计信息、用户情绪和隐含反馈对任务导向的文档对话进行注释的英文对话数据集，实验证明这些数据有潜力改善任务完成情况、生成响应的事实一致性和用户接受程度。

    

    任务导向和文档对话系统的成功取决于用户接受和享受使用它们。为了实现这一目标，人机交互领域的最新研究表明，考虑人口统计信息、用户情绪并从他们的话语中学习隐含反馈的组合尤为重要。然而，这些发现尚未转移到自然语言处理领域，这些数据主要是分别研究的。因此，目前没有足够注释的数据集可用。为了填补这一空白，我们引入了FEDI，这是第一个用人口统计信息、用户情绪和隐含反馈对任务导向的文档对话进行注释的英文对话数据集。我们使用FLAN-T5、GPT-2和LLaMA-2进行的实验证明，这些数据有潜力改善任务完成情况、生成响应的事实一致性和用户接受程度。

    The success of task-oriented and document-grounded dialogue systems depends on users accepting and enjoying using them. To achieve this, recently published work in the field of Human-Computer Interaction suggests that the combination of considering demographic information, user emotions and learning from the implicit feedback in their utterances, is particularly important. However, these findings have not yet been transferred to the field of Natural Language Processing, where these data are primarily studied separately. Accordingly, no sufficiently annotated dataset is available. To address this gap, we introduce FEDI, the first English dialogue dataset for task-oriented document-grounded dialogues annotated with demographic information, user emotions and implicit feedback. Our experiments with FLAN-T5, GPT-2 and LLaMA-2 show that these data have the potential to improve task completion and the factual consistency of the generated responses and user acceptance.
    
[^2]: 跨语言冒犯性语言检测：数据集、转移方法和挑战的系统综述

    Cross-lingual Offensive Language Detection: A Systematic Review of Datasets, Transfer Approaches and Challenges. (arXiv:2401.09244v1 [cs.CL])

    [http://arxiv.org/abs/2401.09244](http://arxiv.org/abs/2401.09244)

    这篇论文对社交媒体中跨语言冒犯性语言检测的技术进行了系统综述，分析了67篇相关论文，并总结了跨语言转移学习的三种主要方法。同时，还探讨了该领域的挑战和未来的研究机会。

    

    社交媒体上冒犯性语言的普及和迅速发展增加了检测的复杂性，尤其突显了在不同语言中识别此类内容的挑战。本综述系统性、全面地探讨了社交媒体中跨语言转移学习（CLTL）技术在冒犯性语言检测中的应用。我们的研究是该领域首个专注于跨语言情景的全面概述。我们分析了67篇相关论文，并对这些研究进行了各个维度的分类，包括使用的多语种数据集的特征、使用的跨语言资源以及实施的具体CLTL策略。此外，根据“何种转移”，我们还总结了三种主要的CLTL转移方法：实例、特征和参数转移。此外，我们还对该领域当前的挑战和未来的研究机会进行了探讨。

    The growing prevalence and rapid evolution of offensive language in social media amplify the complexities of detection, particularly highlighting the challenges in identifying such content across diverse languages. This survey presents a systematic and comprehensive exploration of Cross-Lingual Transfer Learning (CLTL) techniques in offensive language detection in social media. Our study stands as the first holistic overview to focus exclusively on the cross-lingual scenario in this domain. We analyse 67 relevant papers and categorise these studies across various dimensions, including the characteristics of multilingual datasets used, the cross-lingual resources employed, and the specific CLTL strategies implemented. According to "what to transfer", we also summarise three main CLTL transfer approaches: instance, feature, and parameter transfer. Additionally, we shed light on the current challenges and future research opportunities in this field. Furthermore, we have made our survey re
    
[^3]: UniVIE:一种从表单式文档中提取视觉信息的统一标签空间方法

    UniVIE: A Unified Label Space Approach to Visual Information Extraction from Form-like Documents. (arXiv:2401.09220v1 [cs.CL])

    [http://arxiv.org/abs/2401.09220](http://arxiv.org/abs/2401.09220)

    UniVIE是一种将VIE问题重新定义为关系预测问题，并将不同任务的标签统一到一个单一的标签空间中的统一模型，该模型使用由粗到细的策略，能够有效处理表单式文档中的层次关系。

    

    现有的从表单式文档中提取视觉信息(VIE)的方法通常将该过程分割为独立的子任务，例如关键信息提取、键值对提取和选择群提取。然而，这些方法常常忽视了表单文档的层次结构，包括层次键值对和层次选择群。为了解决这些限制，我们提出了一种新的视角，将VIE重新构建为一个关系预测问题，并将不同任务的标签统一到一个单一的标签空间中。这种统一的方法允许定义各种关系类型，并有效地处理表单式文档中的层次关系。根据这个观点，我们介绍了UniVIE，它是一个全面解决VIE问题的统一模型。UniVIE使用一个由粗到细的策略进行操作。它首先通过一个树提案网络生成树提案，然后将其细化为层次树。

    Existing methods for Visual Information Extraction (VIE) from form-like documents typically fragment the process into separate subtasks, such as key information extraction, key-value pair extraction, and choice group extraction. However, these approaches often overlook the hierarchical structure of form documents, including hierarchical key-value pairs and hierarchical choice groups. To address these limitations, we present a new perspective, reframing VIE as a relation prediction problem and unifying labels of different tasks into a single label space. This unified approach allows for the definition of various relation types and effectively tackles hierarchical relationships in form-like documents. In line with this perspective, we present UniVIE, a unified model that addresses the VIE problem comprehensively. UniVIE functions using a coarse-to-fine strategy. It initially generates tree proposals through a tree proposal network, which are subsequently refined into hierarchical trees b
    
[^4]: QAnswer: 面向网站的问答搜索

    QAnswer: Towards Question Answering Search over Websites. (arXiv:2401.09175v1 [cs.CL])

    [http://arxiv.org/abs/2401.09175](http://arxiv.org/abs/2401.09175)

    QAnswer是一种面向网站的问答搜索系统，结合了知识图谱和自由文本的QA技术。该系统展示了将QA技术用于网站搜索的潜力，并讨论了两种方法的优缺点。

    

    问答（QA）越来越被搜索引擎用于为用户提供结果，然而目前很少有网站使用QA技术进行搜索功能。为了展示QA技术在网站搜索中的潜力，我们演示了结合知识图谱QA和自由文本QA的网络搜索，这些通常分别进行。我们还讨论了两种方法在网站搜索中的不同优缺点。我们使用由维基媒体基金会托管的网站案例研究（即维基百科和维基数据）。与搜索引擎（如谷歌，必应等）不同，数据被完整索引，即我们不仅索引子集，而且它们的索引是专属的，即我们仅索引相应网站上可用的数据。

    Question Answering (QA) is increasingly used by search engines to provide results to their end-users, yet very few websites currently use QA technologies for their search functionality. To illustrate the potential of QA technologies for the website search practitioner, we demonstrate web searches that combine QA over knowledge graphs and QA over free text -- each being usually tackled separately. We also discuss the different benefits and drawbacks of both approaches for web site searches. We use the case studies made of websites hosted by the Wikimedia Foundation (namely Wikipedia and Wikidata). Differently from a search engine (e.g. Google, Bing, etc), the data are indexed integrally, i.e. we do not index only a subset, and they are indexed exclusively, i.e. we index only data available on the corresponding website.
    
[^5]: 低标注预算约束下域特定问答Fine-tuning策略

    Fine-tuning Strategies for Domain Specific Question Answering under Low Annotation Budget Constraints. (arXiv:2401.09168v1 [cs.CL])

    [http://arxiv.org/abs/2401.09168](http://arxiv.org/abs/2401.09168)

    该研究对低预算下Fine-tuning QA模型的策略进行了研究分析，发现基于预训练语言模型进行Fine-tuning，并结合目标数据集和SQuAD数据集能够在不增加额外标注的情况下取得更好的性能。

    

    预训练语言模型及其Fine-tuning的进展在大多数下游NLP任务中取得了显著改进。然而，我们的研究发现在低问答标注预算的情况下，这种策略对于Fine-tuning QA模型而言并不是最优的。通过对不同QA数据集上顺序Fine-tuning策略的性能进行详尽分析，我们得出结论，对于低预算设置下Fine-tuning QA模型的最佳策略是使用预训练语言模型（PLM），并将PLM与目标数据集和SQuAD数据集进行Fine-tuning。在没有额外标注的情况下，这种策略优于标准的baseline。

    The progress introduced by pre-trained language models and their fine-tuning has resulted in significant improvements in most downstream NLP tasks. The unsupervised training of a language model combined with further target task fine-tuning has become the standard QA fine-tuning procedure. In this work, we demonstrate that this strategy is sub-optimal for fine-tuning QA models, especially under a low QA annotation budget, which is a usual setting in practice due to the extractive QA labeling cost. We draw our conclusions by conducting an exhaustive analysis of the performance of the alternatives of the sequential fine-tuning strategy on different QA datasets. Based on the experiments performed, we observed that the best strategy to fine-tune the QA model in low-budget settings is taking a pre-trained language model (PLM) and then fine-tuning PLM with a dataset composed of the target dataset and SQuAD dataset. With zero extra annotation effort, the best strategy outperforms the standard 
    
[^6]: 架起研究与读者之间的桥梁：一个多模态自动化学术论文解读系统

    Bridging Research and Readers: A Multi-Modal Automated Academic Papers Interpretation System. (arXiv:2401.09150v1 [cs.CL])

    [http://arxiv.org/abs/2401.09150](http://arxiv.org/abs/2401.09150)

    我们介绍了一个多模态自动化学术论文解读系统(MMAPIS)，它通过利用大规模语言模型来提升功能性。我们的系统包括三个步骤的处理阶段，并针对现有模型面临的挑战提供了解决方案，包括多模态数据处理，长文本摘要和多样化用户界面。

    

    在当代信息时代，大规模语言模型的出现显著加快了科学文献的传播速度，科学文献的增长达到了前所未有的水平。研究人员迫切需要高效的工具来阅读和总结学术论文，发现重要的科学文献，并运用多种解释方法。为了满足这一迫切需求，自动化科学文献解读系统的作用变得至关重要。然而，现有的商业和开源模型都面临着一些困难：它们往往忽视多模态数据，难以总结过长的文本，并缺乏多样化的用户界面。为了解决这些问题，我们引入了一个开源的多模态自动化学术论文解读系统（MMAPIS），它具有三个步骤的处理阶段，并使用LLMs来增强其功能性。我们的系统首先利用混合模态预处理和对齐模块提取纯文本，

    In the contemporary information era, significantly accelerated by the advent of Large-scale Language Models, the proliferation of scientific literature is reaching unprecedented levels. Researchers urgently require efficient tools for reading and summarizing academic papers, uncovering significant scientific literature, and employing diverse interpretative methodologies. To address this burgeoning demand, the role of automated scientific literature interpretation systems has become paramount. However, prevailing models, both commercial and open-source, confront notable challenges: they often overlook multimodal data, grapple with summarizing over-length texts, and lack diverse user interfaces. In response, we introduce an open-source multi-modal automated academic paper interpretation system (MMAPIS) with three-step process stages, incorporating LLMs to augment its functionality. Our system first employs the hybrid modality preprocessing and alignment module to extract plain text, and 
    
[^7]: 异步Local-SGD训练语言建模

    Asynchronous Local-SGD Training for Language Modeling. (arXiv:2401.09135v1 [cs.LG])

    [http://arxiv.org/abs/2401.09135](http://arxiv.org/abs/2401.09135)

    本文通过异步Local-SGD训练语言模型，并进行了全面的实证研究。研究发现，尽管异步更新更频繁，但其收敛所需的迭代次数多于同步方法。作者还提出了一种利用延迟的Nesterov动量更新进行调整的新方法来解决异步更新的挑战。

    

    Local随机梯度下降(Local-SGD)，也称为联邦平均，是一种分布式优化方法，其中每个设备在通信中执行多个SGD更新。本文介绍了异步Local-SGD用于训练语言模型的经验证研究；即，每个工作节点在完成其SGD步骤后立即更新全局参数。我们通过考察工作节点硬件异构性、模型大小、工作节点数量和优化器等因素对学习性能的影响进行了全面调查。我们发现，尽管更频繁地更新（全局）模型参数，但异步Local-SGD比其同步对应物需要更多迭代才能收敛。我们确定了在工作节点梯度陈旧时全局参数的动量加速作为一个关键挑战。我们提出了一种利用延迟的Nesterov动量更新，根据工作节点的本地训练步骤进行调整的新方法。

    Local stochastic gradient descent (Local-SGD), also referred to as federated averaging, is an approach to distributed optimization where each device performs more than one SGD update per communication. This work presents an empirical study of {\it asynchronous} Local-SGD for training language models; that is, each worker updates the global parameters as soon as it has finished its SGD steps. We conduct a comprehensive investigation by examining how worker hardware heterogeneity, model size, number of workers, and optimizer could impact the learning performance. We find that with naive implementations, asynchronous Local-SGD takes more iterations to converge than its synchronous counterpart despite updating the (global) model parameters more frequently. We identify momentum acceleration on the global parameters when worker gradients are stale as a key challenge. We propose a novel method that utilizes a delayed Nesterov momentum update and adjusts the workers' local training steps based
    
[^8]: 什么是“好”的社交行为者？以尊重为视角评估与语言代理的交互

    What makes for a 'good' social actor? Using respect as a lens to evaluate interactions with language agents. (arXiv:2401.09082v1 [cs.CL])

    [http://arxiv.org/abs/2401.09082](http://arxiv.org/abs/2401.09082)

    本文研究以尊重为视角评估与语言代理的交互，提出了一种更加关注关系和情境因素的伦理方法，旨在帮助LLM技术表现得“好”

    

    随着基于大型语言模型（LLM）的对话代理越来越受欢迎，如何确保它们的行为道德和适当性已经引起了紧急关注。从“HHH”标准的角度来看，这主要体现在让输出更有帮助和诚实，并避免有害（有偏见、有毒或不准确）的陈述。虽然这种语义焦点对于将LLM代理视为纯粹的信息媒介是有用的，但它未能考虑到在不同社交情境中，同样的话语可能会显得更或者更少冒犯或不得体的实际因素。我们提出了一种更加关注关系和情境因素的伦理方法，探讨作为社交行为者的系统如何在交互中以尊重的方式对待个体。我们的工作预见了在情境交互层面上一系列尚未被探索的风险，并提供了实用建议，以帮助LLM技术表现得“好”

    With the growing popularity of dialogue agents based on large language models (LLMs), urgent attention has been drawn to finding ways to ensure their behaviour is ethical and appropriate. These are largely interpreted in terms of the 'HHH' criteria: making outputs more helpful and honest, and avoiding harmful (biased, toxic, or inaccurate) statements. Whilst this semantic focus is useful from the perspective of viewing LLM agents as mere mediums for information, it fails to account for pragmatic factors that can make the same utterance seem more or less offensive or tactless in different social situations. We propose an approach to ethics that is more centred on relational and situational factors, exploring what it means for a system, as a social actor, to treat an individual respectfully in a (series of) interaction(s). Our work anticipates a set of largely unexplored risks at the level of situated interaction, and offers practical suggestions to help LLM technologies behave as 'good'
    
[^9]: 大型语言模型中的代码模拟挑战

    Code Simulation Challenges for Large Language Models. (arXiv:2401.09074v1 [cs.LG])

    [http://arxiv.org/abs/2401.09074](http://arxiv.org/abs/2401.09074)

    大型语言模型在模拟计算机代码和算法执行方面遇到挑战，性能随着代码长度的增加而迅速下降。在处理短程序或标准过程时，它们能以低错误率按顺序执行指令，但对于复杂的程序，特别是包含关键路径和冗余指令的程序，模拟效果较差。我们提出了一种逐行模拟代码执行的方法来解决这个问题。

    

    我们调查了大型语言模型（LLMs）在模拟计算机代码和算法执行方面的能力。我们首先研究了直线程序，并展示了当前LLMs在处理这样简单的程序时表现出的性能较差——性能随着代码长度的增加而迅速下降。接着，我们研究了LLMs在模拟包含关键路径和冗余指令的程序方面的能力。我们还通过排序算法和嵌套循环超越了直线程序的模拟，并展示了程序的计算复杂性直接影响LLMs模拟其执行的能力。我们观察到LLMs只有在处理短程序或标准过程时才能以低错误率按顺序执行指令。LLMs的代码模拟与它们的模式识别和记忆能力存在矛盾：在记忆对任务有害的情况下，我们提出了一种新的提示方法，逐行模拟代码的执行。

    We investigate the extent to which Large Language Models (LLMs) can simulate the execution of computer code and algorithms. We begin by looking straight line programs, and show that current LLMs demonstrate poor performance even with such simple programs -- performance rapidly degrades with the length of code. We then investigate the ability of LLMs to simulate programs that contain critical paths and redundant instructions. We also go beyond straight line program simulation with sorting algorithms and nested loops, and we show the computational complexity of a routine directly affects the ability of an LLM to simulate its execution. We observe that LLMs execute instructions sequentially and with a low error margin only for short programs or standard procedures. LLMs' code simulation is in tension with their pattern recognition and memorisation capabilities: on tasks where memorisation is detrimental, we propose a novel prompting method to simulate code execution line by line. Empirica
    
[^10]: LLM对于关系推理的实现程度有多远？

    LLMs for Relational Reasoning: How Far are We?. (arXiv:2401.09042v1 [cs.AI])

    [http://arxiv.org/abs/2401.09042](http://arxiv.org/abs/2401.09042)

    本论文对多种最先进的LLM的推理能力进行了全面评估，发现它们在归纳逻辑编程基准测试上的表现欠佳，这挑战了它们在处理常识规划的顺序决策问题方面的能力。

    

    大型语言模型（LLM）通过在广泛的下游任务中取得了最先进的性能，从而革新了许多领域（例如自然语言处理、软件工程等）。为了实现强大且通用的人工智能，人们对LLM的推理能力产生了浓厚的兴趣。然而，先前研究采用的文本和数值推理基准测试相对浅显简单，仅仅通过在这些基准上取得积极结果难以得出LLM具有强大推理能力的结论。最近的研究努力通过在强化学习基准测试上评估LLM的性能，证明LLM在解决需要常识规划的顺序决策问题方面表现不佳。在本研究中，我们基于归纳逻辑编程（ILP）基准测试对几种最先进的LLM的推理能力进行了深入评估，这一基准测试被广泛认可为对推理能力的代表性评估。

    Large language models (LLMs) have revolutionized many areas (e.g. natural language processing, software engineering, etc.) by achieving state-of-the-art performance on extensive downstream tasks. Aiming to achieve robust and general artificial intelligence, there has been a surge of interest in investigating the reasoning ability of the LLMs. Whereas the textual and numerical reasoning benchmarks adopted by previous works are rather shallow and simple, it is hard to conclude that the LLMs possess strong reasoning ability by merely achieving positive results on these benchmarks. Recent efforts have demonstrated that the LLMs are poor at solving sequential decision-making problems that require common-sense planning by evaluating their performance on the reinforcement learning benchmarks. In this work, we conduct an in-depth assessment of several state-of-the-art LLMs' reasoning ability based on the inductive logic programming (ILP) benchmark, which is broadly recognized as a representati
    
[^11]: 大数据集的文本摘要：朝着一个通用方法的探索

    Textual Summarisation of Large Sets: Towards a General Approach. (arXiv:2401.09041v1 [cs.CL])

    [http://arxiv.org/abs/2401.09041](http://arxiv.org/abs/2401.09041)

    本文介绍了一种基于规则的自然语言生成技术，用于总结学术论文中的参考文献集合，扩展了之前关于总结消费品集合的工作，并展示了模型在不同领域中的泛化能力。

    

    我们正在开发一种生成对象集合摘要描述的技术。在本文中，我们提出并评估了一种基于规则的自然语言生成技术，用于总结学术论文中的参考文献集合。这扩展了我们之前关于总结消费品集合的工作，并展示了我们的模型如何在这两个非常不同的领域中进行泛化。

    We are developing techniques to generate summary descriptions of sets of objects. In this paper, we present and evaluate a rule-based NLG technique for summarising sets of bibliographical references in academic papers. This extends our previous work on summarising sets of consumer products and shows how our model generalises across these two very different domains.
    
[^12]: 解释你自己吧，霸凌者：使用情感辅助的带解释的网络霸凌检测

    Explain Thyself Bully: Sentiment Aided Cyberbullying Detection with Explanation. (arXiv:2401.09023v1 [cs.CL])

    [http://arxiv.org/abs/2401.09023](http://arxiv.org/abs/2401.09023)

    本文介绍了第一个可解释的多任务模型mExCB，用于从混合语言中自动检测网络霸凌，并引入了解释性网络霸凌检测的基准数据集BullyExplain。

    

    随着不同社交媒体网络和在线通讯应用的普及，网络霸凌已成为一个重大问题。尽管已经有很多关于单语言网络霸凌检测模型的研究，但在混合语言和可解释性方面的研究却很少。最近的《通用数据保护条例》等法律推动了以解释性模型为重点的研究，而不仅仅是性能。受此启发，我们开发了第一个可解释的多任务模型mExCB，用于从混合语言中自动检测网络霸凌，同时解决多个任务，包括网络霸凌检测、解释/理由识别、目标群体检测和情感分析。我们还引入了第一个用于解释性网络霸凌检测的基准数据集BullyExplain。BullyExplain数据集中的每个帖子都被注释了……

    Cyberbullying has become a big issue with the popularity of different social media networks and online communication apps. While plenty of research is going on to develop better models for cyberbullying detection in monolingual language, there is very little research on the code-mixed languages and explainability aspect of cyberbullying. Recent laws like "right to explanations" of General Data Protection Regulation, have spurred research in developing interpretable models rather than focusing on performance. Motivated by this we develop the first interpretable multi-task model called {\em mExCB} for automatic cyberbullying detection from code-mixed languages which can simultaneously solve several tasks, cyberbullying detection, explanation/rationale identification, target group detection and sentiment analysis. We have introduced {\em BullyExplain}, the first benchmark dataset for explainable cyberbullying detection in code-mixed language. Each post in {\em BullyExplain} dataset is ann
    
[^13]: 通过迭代组合问题来增强数学问题求解

    Augmenting Math Word Problems via Iterative Question Composing. (arXiv:2401.09003v1 [cs.CL])

    [http://arxiv.org/abs/2401.09003](http://arxiv.org/abs/2401.09003)

    本研究通过引入MMIQC数据集和迭代组合问题(IQC)的新颖增强方法，成功提高了大型语言模型的数学推理能力，在竞赛级数学问题上取得了优于先前最佳结果的准确率。

    

    尽管在改善大型语言模型(LLMs)的数学推理能力方面取得了一定进展，但在不使用外部工具的情况下解决竞赛级数学问题仍然对开源LLMs具有挑战性。在这项工作中，我们介绍了MMIQC数据集，这是一个混合处理的网络数据和合成问题-响应对的混合数据集，以提供基础模型更好的数学推理能力。通过在MMIQC上对Mistral-7B(arXiv:2310.06825)进行微调获得的模型Mistral-7B-MMIQC，在MATH(arXiv:2103.03874)上达到了36.0%的准确率，比之前(model size $\sim$7B)的最佳结果高出5.8%。我们的实验还表明，改进的一个重要部分归功于我们的新颖增强方法IQC(迭代组合问题)，其中我们迭代地要求LLM从给定的种子问题中组合新问题，并从另一个LLM中进行拒绝抽样。MMIQC现已在https://huggingface.co/datasets/Vivacem/MMIQC上发布。

    Despite recent progress in improving the mathematical reasoning ability of large language models(LLMs), solving competition-level math problems without the use of external tools remains challenging for open-source LLMs. In this work, we introduce the MMIQC dataset, a mixture of processed web data and synthetic question-response pairs, to equip base models with better mathematical reasoning skills. Mistral-7B-MMIQC, the model obtained by fine-tuning Mistral-7B(arXiv:2310.06825) on MMIQC, achieves 36.0\% accuracy on MATH(arXiv:2103.03874), 5.8\% higher than the previous (model size $\sim$7B) SOTA. Our experiments also show that a large part of the improvement attributes to our novel augmentation method IQC(Iterative Question Composing), where we iteratively ask an LLM to compose new questions from the given seed problems and do rejection sampling from another LLM. MMIQC has now been released on https://huggingface.co/datasets/Vivacem/MMIQC.
    
[^14]: 评估大型语言模型上越狱攻击效果的方法研究

    AttackEval: How to Evaluate the Effectiveness of Jailbreak Attacking on Large Language Models. (arXiv:2401.09002v1 [cs.CL])

    [http://arxiv.org/abs/2401.09002](http://arxiv.org/abs/2401.09002)

    本研究提出一种新方法评估大型语言模型上越狱攻击效果，引入粗粒度和细粒度评估框架，提供了更全面和细致的评估角度，并开发了专门的真实数据集作为基准，为未来研究建立了基础资源。

    

    在我们的研究中，我们开创性地提出了一种评估大型语言模型（LLMs）上越狱攻击效果的新方法，与传统的健壮性评估方法不同。我们的研究引入了两个不同的评估框架：粗粒度评估和细粒度评估。每个框架都使用从0到1的评分范围，提供了独特的视角，能够更全面和细致地评估攻击效果，并帮助攻击者更好地优化攻击提示。此外，我们还开发了一个专门用于越狱任务的全面的真实数据集。这个数据集不仅是我们当前研究的关键基准，也为未来研究建立了一个基础资源，可以在这个不断发展的领域中进行一致和比较的分析。通过与传统评估方法的精心比较，我们发现我们的评估方法与之相一致。

    In our research, we pioneer a novel approach to evaluate the effectiveness of jailbreak attacks on Large Language Models (LLMs), such as GPT-4 and LLaMa2, diverging from traditional robustness-focused binary evaluations. Our study introduces two distinct evaluation frameworks: a coarse-grained evaluation and a fine-grained evaluation. Each framework, using a scoring range from 0 to 1, offers a unique perspective, enabling a more comprehensive and nuanced evaluation of attack effectiveness and empowering attackers to refine their attack prompts with greater understanding. Furthermore, we have developed a comprehensive ground truth dataset specifically tailored for jailbreak tasks. This dataset not only serves as a crucial benchmark for our current study but also establishes a foundational resource for future research, enabling consistent and comparative analyses in this evolving field. Upon meticulous comparison with traditional evaluation methods, we discovered that our evaluation alig
    
[^15]: 流式多语言ASR中针对边缘语种的高效适配器微调

    Efficient Adapter Finetuning for Tail Languages in Streaming Multilingual ASR. (arXiv:2401.08992v1 [cs.CL])

    [http://arxiv.org/abs/2401.08992](http://arxiv.org/abs/2401.08992)

    本研究通过在流式多语言ASR中采用简单而有效的适配器微调方法，提供了对边缘语种的支持。适配器仅占每种语言的模型的0.4%。该方法在级联的Conformer转录器框架下，通过教师伪标签增强了模型性能。

    

    在流式多语言情景中，人们通常希望使用端到端ASR模型，因为这样更容易部署，并且可以从预训练的语音模型中受益，例如强大的基础模型。与此同时，不同语言的异质性和数据丰富度的不平衡可能导致性能下降，从而在训练过程中不同语言的性能出现异步峰值，尤其是对于边缘语种。有时，数据本身甚至可能因为加强的隐私保护而不可用。现有的方法往往倾向于显著增加模型大小或学习语言特定的解码器来单独适应每种语言。本研究中，我们探索了一种简单且有效的Language-Dependent Adapter (LDA)微调方法，该方法运用了级联的Conformer转录器框架，通过教师伪标签增强了对流式多语言ASR中的边缘语种的支持。适配器仅占每种语言的完整模型的0.4%。它被插入到冻结的基础模型中。

    The end-to-end ASR model is often desired in the streaming multilingual scenario since it is easier to deploy and can benefit from pre-trained speech models such as powerful foundation models. Meanwhile, the heterogeneous nature and imbalanced data abundance of different languages may cause performance degradation, leading to asynchronous peak performance for different languages during training, especially on tail ones. Sometimes even the data itself may become unavailable as a result of the enhanced privacy protection. Existing work tend to significantly increase the model size or learn language-specific decoders to accommodate each language separately. In this study, we explore simple yet effective Language-Dependent Adapter (LDA) finetuning under a cascaded Conformer transducer framework enhanced by teacher pseudo-labeling for tail languages in the streaming multilingual ASR. The adapter only accounts for 0.4% of the full model per language. It is plugged into the frozen foundation 
    
[^16]: OCTO + ：自动开放词汇物体放置在混合现实中的套件。

    OCTO+: A Suite for Automatic Open-Vocabulary Object Placement in Mixed Reality. (arXiv:2401.08973v1 [cs.CV])

    [http://arxiv.org/abs/2401.08973](http://arxiv.org/abs/2401.08973)

    本论文介绍了一种称为OCTO + 的套件，用于在混合现实中自动将虚拟物体放置在合适的位置。通过使用最新的开放词汇视觉语言模型，该方法在多个评估标准上取得了最先进的效果，超过其他方法。同时，还引入了一个用于自动评估增强现实中虚拟物体放置的基准。

    

    增强现实中的一个关键挑战是将虚拟内容放置在自然位置上。大多数现有的自动化技术只能使用封闭词汇、固定的物体集合来工作。在本文中，我们引入并评估了几种使用最新进展的开放词汇视觉语言模型进行自动物体放置的方法。通过多方面的评估，我们确定了一种新的最先进方法OCTO +。我们还引入了一个用于自动评估增强现实中虚拟物体放置的基准，减轻了需要昂贵用户研究的需求。通过这个基准，除了人类评估之外，我们发现OCTO + 有效地将物体放置在一个合理的区域内超过70％的时间，在各种指标上超越了其他方法。

    One key challenge in Augmented Reality is the placement of virtual content in natural locations. Most existing automated techniques can only work with a closed-vocabulary, fixed set of objects. In this paper, we introduce and evaluate several methods for automatic object placement using recent advances in open-vocabulary vision-language models. Through a multifaceted evaluation, we identify a new state-of-the-art method, OCTO+. We also introduce a benchmark for automatically evaluating the placement of virtual objects in augmented reality, alleviating the need for costly user studies. Through this, in addition to human evaluations, we find that OCTO+ places objects in a valid region over 70% of the time, outperforming other methods on a range of metrics.
    
[^17]: ReFT: 加强强化微调的推理能力

    ReFT: Reasoning with Reinforced Fine-Tuning. (arXiv:2401.08967v1 [cs.CL])

    [http://arxiv.org/abs/2401.08967](http://arxiv.org/abs/2401.08967)

    ReFT是一种加强推理能力的强化微调方法，通过利用更多的推理路径进行微调，提高了大型语言模型在数学问题解决中的泛化能力。

    

    增强大型语言模型（LLMs）的推理能力的一种方法是使用链式思考（CoT）注释进行监督微调（SFT）。然而，这种方法在泛化能力上并不十分强大，因为训练仅依赖于给定的CoT数据。例如，在数学问题解决中，训练数据中通常只有一个注释的推理路径用于每个问题。直观来说，让算法从给定的问题中学习多个注释的推理路径会更好。为了解决这个问题，我们提出了一种简单而有效的方法，称为加强强化微调（ReFT），以增强学习LLMs进行推理的泛化能力，以数学问题解决为例。ReFT首先使用SFT对模型进行热身，然后采用在线强化学习（具体来说，在本文中是使用PPO算法）进一步微调模型，其中根据问题自动采样了大量的推理路径。

    One way to enhance the reasoning capability of Large Language Models (LLMs) is to conduct Supervised Fine-Tuning (SFT) using Chain-of-Thought (CoT) annotations. This approach does not show sufficiently strong generalization ability, however, because the training only relies on the given CoT data. In math problem-solving, for example, there is usually only one annotated reasoning path for each question in the training data. Intuitively, it would be better for the algorithm to learn from multiple annotated reasoning paths given a question. To address this issue, we propose a simple yet effective approach called Reinforced Fine-Tuning (ReFT) to enhance the generalizability of learning LLMs for reasoning, with math problem-solving as an example. ReFT first warmups the model with SFT, and then employs on-line reinforcement learning, specifically the PPO algorithm in this paper, to further fine-tune the model, where an abundance of reasoning paths are automatically sampled given the question
    
[^18]: 部分音标化：一种上下文对比推理方法

    Partial Diacritization: A Context-Contrastive Inference Approach. (arXiv:2401.08919v1 [cs.CL])

    [http://arxiv.org/abs/2401.08919](http://arxiv.org/abs/2401.08919)

    部分音标化是选择标记部分字符来提高阅读可读性和准确性的新方法。上下文对比的部分音标化（CCPD）集成了现有的阿拉伯音标化系统，并通过衡量部分音标化的新指标来判断需要标记哪些字符。

    

    音标化在提高阿拉伯文本可读性和消除歧义方面起着关键作用。目前的努力主要集中在标记每个符合条件的字符（全音标化）。相比之下，部分音标化（PD）是选择标记子集以在必要时提供帮助。研究表明，过多的音标符号会妨碍熟练读者，降低阅读速度和准确性。我们进行了一项行为实验，并显示出部分标记的文本通常比完全标记的文本更容易阅读，有时甚至比纯文本更容易。在这种情况下，我们介绍了上下文对比的部分音标化（CCPD）-一种与现有阿拉伯音标化系统无缝集成的新方法。CCPD对每个单词进行两次处理，一次有上下文，一次没有，并且只对两次推理之间存在差异的字符进行音标化。此外，我们还引入了衡量部分音标化的新指标。

    Diacritization plays a pivotal role in improving readability and disambiguating the meaning of Arabic texts. Efforts have so far focused on marking every eligible character (Full Diacritization). Comparatively overlooked, Partial Diacritzation (PD) is the selection of a subset of characters to be marked to aid comprehension where needed. Research has indicated that excessive diacritic marks can hinder skilled readers--reducing reading speed and accuracy. We conduct a behavioral experiment and show that partially marked text is often easier to read than fully marked text, and sometimes easier than plain text. In this light, we introduce Context-Contrastive Partial Diacritization (CCPD)--a novel approach to PD which integrates seamlessly with existing Arabic diacritization systems. CCPD processes each word twice, once with context and once without, and diacritizes only the characters with disparities between the two inferences. Further, we introduce novel indicators for measuring partial
    
[^19]: NOTSOFAR-1挑战：远距离会议转录的新数据集，基准线和任务

    NOTSOFAR-1 Challenge: New Datasets, Baseline, and Tasks for Distant Meeting Transcription. (arXiv:2401.08887v1 [cs.SD])

    [http://arxiv.org/abs/2401.08887](http://arxiv.org/abs/2401.08887)

    NOTSOFAR-1挑战旨在解决远距离会议转录中的远距离发言人划分和自动语音识别问题，在一个新发布的数据集上进行评估。

    

    我们介绍了第一个自然办公室谈话者在远场音频记录环境中（“NOTSOFAR-1”）的挑战，包括数据集和基准系统。该挑战主要关注远场会议中的远距离发言人划分和自动语音识别（DASR），包括单声道和已知几何多通道的轨道，并且作为两个新数据集的发布平台：第一个数据集是一个基准测试数据集，包括315个会议，每个会议平均6分钟，捕捉到广泛的真实世界声学环境和对话动态。它是在30个会议室中录制的，每个会议室有4-8个与会者和共计35个不同的发言者。第二个数据集是一个1000小时的模拟训练数据集，具有增强的真实性以实现真实世界的泛化，包括15000个真实声学转移函数。任务集中在单设备DASR上，其中多通道设备始终共享相同已知的几何形状。这与实际会议室的常见设置是一致的。

    We introduce the first Natural Office Talkers in Settings of Far-field Audio Recordings (``NOTSOFAR-1'') Challenge alongside datasets and baseline system. The challenge focuses on distant speaker diarization and automatic speech recognition (DASR) in far-field meeting scenarios, with single-channel and known-geometry multi-channel tracks, and serves as a launch platform for two new datasets: First, a benchmarking dataset of 315 meetings, averaging 6 minutes each, capturing a broad spectrum of real-world acoustic conditions and conversational dynamics. It is recorded across 30 conference rooms, featuring 4-8 attendees and a total of 35 unique speakers. Second, a 1000-hour simulated training dataset, synthesized with enhanced authenticity for real-world generalization, incorporating 15,000 real acoustic transfer functions. The tasks focus on single-device DASR, where multi-channel devices always share the same known geometry. This is aligned with common setups in actual conference rooms,
    
[^20]: 使用i向量进行主体无关的跨会话EEG迁移学习

    Using i-vectors for subject-independent cross-session EEG transfer learning. (arXiv:2401.08851v1 [cs.LG])

    [http://arxiv.org/abs/2401.08851](http://arxiv.org/abs/2401.08851)

    本文提出了使用基于i向量的神经网络分类器进行跨主体跨会话EEG迁移学习的方法，相对于等效的主体相关模型取得了18%的相对改进。此外，我们还展示了我们的主体无关模型在新主体上的竞争力和额外主体数据的增加对模型性能的改善，表明有效的认知负荷确定不需要主体相关的训练。

    

    认知负荷分类是根据生理测量如脑电图（EEG）自动确定个体在执行任务时利用工作记忆资源的任务。本文采用了跨学科的方法，利用语音处理的工具和方法来解决这个问题。我们使用的语料库作为第一次被动脑机接口竞赛的一部分，在2021年公开发布。我们提出了使用基于i向量的神经网络分类器进行跨主体跨会话EEG迁移学习的方法，相较于等效的主体相关模型，取得了18%的相对改进。我们还报道了实验结果，显示我们的主体无关模型在新主体上具有竞争力，并且随着额外主体数据的增加而改善，表明有效的认知负荷确定不需要主体相关的训练。

    Cognitive load classification is the task of automatically determining an individual's utilization of working memory resources during performance of a task based on physiologic measures such as electroencephalography (EEG). In this paper, we follow a cross-disciplinary approach, where tools and methodologies from speech processing are used to tackle this problem. The corpus we use was released publicly in 2021 as part of the first passive brain-computer interface competition on cross-session workload estimation. We present our approach which used i-vector-based neural network classifiers to accomplish inter-subject cross-session EEG transfer learning, achieving 18% relative improvement over equivalent subject-dependent models. We also report experiments showing how our subject-independent models perform competitively on held-out subjects and improve with additional subject data, suggesting that subject-dependent training is not required for effective cognitive load determination.
    
[^21]: 使用引导注意力改进ASR的上下文偏差

    Improving ASR Contextual Biasing with Guided Attention. (arXiv:2401.08835v1 [cs.CL])

    [http://arxiv.org/abs/2401.08835](http://arxiv.org/abs/2401.08835)

    本文提出了一种引导注意力的辅助训练损失方法，可以改进自动语音识别中的上下文偏差问题，不引入额外参数，并且通过实验证明在偏差短语数量增加时仍然保持有效性。

    

    本文提出了一种引导注意力（GA）的辅助训练损失，可以提高自动语音识别（ASR）上下文偏差的效果和鲁棒性，而不引入额外的参数。在之前的文献中，一个常见的挑战是随着偏差短语数量的增加，上下文偏差带来的词错误率（WER）降低效果会减弱。为了解决这个挑战，我们除了使用转录损失外，还采用了GA损失作为额外的训练目标。所提出的GA损失旨在教会交叉注意力如何将偏差短语与文本标记或音频帧对齐。与具有类似动机的其他研究相比，所提出的损失直接作用于交叉注意力权重，更容易实现。通过基于带上下文适配器的Conformer Transducer的大量实验证明，所提出的方法不仅可以导致更低的WER，而且在偏差短语数量增加时仍然保持有效性。

    In this paper, we propose a Guided Attention (GA) auxiliary training loss, which improves the effectiveness and robustness of automatic speech recognition (ASR) contextual biasing without introducing additional parameters. A common challenge in previous literature is that the word error rate (WER) reduction brought by contextual biasing diminishes as the number of bias phrases increases. To address this challenge, we employ a GA loss as an additional training objective besides the Transducer loss. The proposed GA loss aims to teach the cross attention how to align bias phrases with text tokens or audio frames. Compared to studies with similar motivations, the proposed loss operates directly on the cross attention weights and is easier to implement. Through extensive experiments based on Conformer Transducer with Contextual Adapter, we demonstrate that the proposed method not only leads to a lower WER but also retains its effectiveness as the number of bias phrases increases. Specifical
    
[^22]: 从互信息角度重新审视自监督学习的语音表征

    Revisiting Self-supervised Learning of Speech Representation from a Mutual Information Perspective. (arXiv:2401.08833v1 [eess.AS])

    [http://arxiv.org/abs/2401.08833](http://arxiv.org/abs/2401.08833)

    本文从信息论的角度重新审视了自监督学习的语音表征方法，开发了使用互信息来度量表征质量的方法，并通过线性探测器评估了表征与目标信息之间的互信息，为模型设计和选择提供了新的见解。

    

    现有的自监督语音表征学习研究主要集中在开发新的训练方法并应用预训练模型于不同应用中。然而，这些模型的质量往往是通过不同下游任务的性能来衡量的。有关表征如何访问所需信息的研究较少。在本研究中，我们从信息论的角度对现有的自监督语音方法进行了更深入的研究。我们旨在使用互信息来开发度量标准，帮助解决模型设计和选择等实际问题。我们使用线性探测器估计目标信息与学习到的表征之间的互信息，展示了从语音表征中访问目标信息的另一种见解。此外，我们还探索了自监督方式评估表征的潜力，通过估计不同数据部分之间的互信息来实现。

    Existing studies on self-supervised speech representation learning have focused on developing new training methods and applying pre-trained models for different applications. However, the quality of these models is often measured by the performance of different downstream tasks. How well the representations access the information of interest is less studied. In this work, we take a closer look into existing self-supervised methods of speech from an information-theoretic perspective. We aim to develop metrics using mutual information to help practical problems such as model design and selection. We use linear probes to estimate the mutual information between the target information and learned representations, showing another insight into the accessibility to the target information from speech representations. Further, we explore the potential of evaluating representations in a self-supervised fashion, where we estimate the mutual information between different parts of the data without u
    
[^23]: AiGen-FoodReview:一种多模态的机器生成的社交媒体餐厅评论和图像数据集

    AiGen-FoodReview: A Multimodal Dataset of Machine-Generated Restaurant Reviews and Images on Social Media. (arXiv:2401.08825v1 [cs.LG])

    [http://arxiv.org/abs/2401.08825](http://arxiv.org/abs/2401.08825)

    本论文创建了一个多模态的机器生成的社交媒体餐厅评论和图像数据集AiGen-FoodReview，并开发了相应的检测模型，可用于鉴别真实和虚假的评论。通过使用可读性和摄影理论的属性评分，证明了这些属性作为手工特征在可伸缩和可解释的检测模型中的有效性。

    

    在线评论作为用户生成内容（UGC）显著影响消费者决策。然而，不仅人为制造的虚假内容，还有机器生成的内容都挑战了UGC的可靠性。借助于OpenAI的GPT-4-Turbo和DALL-E-2模型，我们创建了AiGen-FoodReview，这是一个包含20,144个餐厅评论-图像对的多模态数据集，分为真实和机器生成的部分。我们探索了单模态和多模态的检测模型，在FLAVA上实现了99.80%的多模态准确度。我们使用可读性和摄影理论的属性分别对评论和图像进行评分，证明了它们作为手工特征在可伸缩和可解释的检测模型中的实用性，其性能与对比相当。本文通过开源数据集和发布虚假评论检测器做出了贡献，推荐使用该数据集以增强可靠的UGC。

    Online reviews in the form of user-generated content (UGC) significantly impact consumer decision-making. However, the pervasive issue of not only human fake content but also machine-generated content challenges UGC's reliability. Recent advances in Large Language Models (LLMs) may pave the way to fabricate indistinguishable fake generated content at a much lower cost. Leveraging OpenAI's GPT-4-Turbo and DALL-E-2 models, we craft AiGen-FoodReview, a multi-modal dataset of 20,144 restaurant review-image pairs divided into authentic and machine-generated. We explore unimodal and multimodal detection models, achieving 99.80% multimodal accuracy with FLAVA. We use attributes from readability and photographic theories to score reviews and images, respectively, demonstrating their utility as hand-crafted features in scalable and interpretable detection models, with comparable performance. The paper contributes by open-sourcing the dataset and releasing fake review detectors, recommending its
    
[^24]: HuixiangDou：利用基于LLM的技术助手克服群聊场景

    HuixiangDou: Overcoming Group Chat Scenarios with LLM-based Technical Assistance. (arXiv:2401.08772v1 [cs.CL])

    [http://arxiv.org/abs/2401.08772](http://arxiv.org/abs/2401.08772)

    HuixiangDou是一种由大型语言模型驱动的技术助手，旨在通过对开源算法项目相关问题的深入回答来协助算法开发人员。该助手已被成功整合到群聊工具中，有效地回答用户的技术问题，并具备评分能力、上下文学习和长上下文等关键要求。

    

    在这项工作中，我们介绍了一种由大型语言模型（LLM）驱动的技术助手HuixiangDou。该系统旨在通过对与开源算法项目相关的问题提供深入的回答，如来自OpenMMLab的计算机视觉和深度学习项目，来协助算法开发人员。我们进一步探索了将该助手整合到即时消息工具（如微信和Lark）的群聊中。通过几次迭代改进和试验，我们开发出了一种先进的技术聊天助手，能够在不造成消息泛滥的情况下有效地回答用户的技术问题。本文的贡献包括: 1) 为群聊场景设计了一种算法流水线; 2) 验证了文本2向量在任务拒绝中的可靠性能; 3) 确定了技术助手产品中LLM的三个关键要求，即评分能力，上下文学习（ICL）和长上下文。我们已经完成了这些贡献

    In this work, we present HuixiangDou, a technical assistant powered by Large Language Models (LLM). This system is designed to assist algorithm developers by providing insightful responses to questions related to open-source algorithm projects, such as computer vision and deep learning projects from OpenMMLab. We further explore the integration of this assistant into the group chats of instant messaging (IM) tools such as WeChat and Lark. Through several iterative improvements and trials, we have developed a sophisticated technical chat assistant capable of effectively answering users' technical questions without causing message flooding. This paper's contributions include: 1) Designing an algorithm pipeline specifically for group chat scenarios; 2) Verifying the reliable performance of text2vec in task rejection; 3) Identifying three critical requirements for LLMs in technical-assistant-like products, namely scoring ability, In-Context Learning (ICL), and Long Context. We have made th
    
[^25]: MMToM-QA: 多模态心智理论问答

    MMToM-QA: Multimodal Theory of Mind Question Answering. (arXiv:2401.08743v1 [cs.AI])

    [http://arxiv.org/abs/2401.08743](http://arxiv.org/abs/2401.08743)

    MMToM-QA是一个多模态心智理论问答基准，用于评估机器对于人的心智理论的理解能力。我们提出了一种新的方法BIP-ALM用于实现多模态心智理论能力。

    

    理解人们的心智是开发具有人类水平社交智能的机器的一个重要组成部分。最近的机器学习模型，特别是大型语言模型，似乎展现出某些心智理解的方面。然而，现有的心智理论基准使用单模态数据集-或者视频或者文本。然而，人类的心智理论不仅仅是视频或文本理解。人们可以根据从任何可用数据中提取的概念表示（例如目标，信念，计划）灵活地推理另一个人的心智，这些数据可以包括视觉线索，语言叙事或两者兼有。为了解决这个问题，我们引入了一个多模态的心智理论问答（MMToM-QA）基准。MMToM-QA在多模态数据和关于一个人在家庭环境中的活动的不同种类的单模态数据上全面评估机器的心智理论。为了实现多模态心智理论能力，我们提出了一种新的方法，BIP-ALM（贝叶斯逆向规划）。

    Theory of Mind (ToM), the ability to understand people's minds, is an essential ingredient for developing machines with human-level social intelligence. Recent machine learning models, particularly large language models, seem to show some aspects of ToM understanding. However, existing ToM benchmarks use unimodal datasets - either video or text. Human ToM, on the other hand, is more than video or text understanding. People can flexibly reason about another person's mind based on conceptual representations (e.g., goals, beliefs, plans) extracted from any available data, which can include visual cues, linguistic narratives, or both. To address this, we introduce a multimodal Theory of Mind question answering (MMToM-QA) benchmark. MMToM-QA comprehensively evaluates machine ToM both on multimodal data and on different kinds of unimodal data about a person's activity in a household environment. To engineer multimodal ToM capacity, we propose a novel method, BIP-ALM (Bayesian Inverse Plannin
    
[^26]: 结合置信度引导和基于样本的方法用于消除误信息中的不确定性量化

    Combining Confidence Elicitation and Sample-based Methods for Uncertainty Quantification in Misinformation Mitigation. (arXiv:2401.08694v1 [cs.CL])

    [http://arxiv.org/abs/2401.08694](http://arxiv.org/abs/2401.08694)

    本研究提出了一种结合置信度引导和基于样本的方法的不确定性量化框架，用于解决误信息消除中的幻觉和过度自信的预测问题，并提出了混合框架以提供更好的不确定性估计。

    

    大型语言模型已经成为解决误信息消除的主要候选方案。然而，现有方法在幻觉和过度自信的预测方面存在问题。我们提出了一种不确定性量化框架，利用直接置信度引导和基于样本的一致性方法，为自然语言处理误信息消除解决方案提供更好的校准。首先，我们研究基于样本一致性方法的校准性，该方法利用样本规模和随机水平的一致性的不同特征。接下来，我们评估了鲁棒的数字化口头提示在单步和两步置信度引导过程中的性能和分布变化。我们还比较了相同提示在不同版本的GPT和不同数字尺度下的性能。最后，我们结合基于样本一致性和数字化方法，提出了一个混合框架，为GPT模型提供更好的不确定性估计。

    Large Language Models have emerged as prime candidates to tackle misinformation mitigation. However, existing approaches struggle with hallucinations and overconfident predictions. We propose an uncertainty quantification framework that leverages both direct confidence elicitation and sampled-based consistency methods to provide better calibration for NLP misinformation mitigation solutions. We first investigate the calibration of sample-based consistency methods that exploit distinct features of consistency across sample sizes and stochastic levels. Next, we evaluate the performance and distributional shift of a robust numeric verbalization prompt across single vs. two-step confidence elicitation procedure. We also compare the performance of the same prompt with different versions of GPT and different numerical scales. Finally, we combine the sample-based consistency and verbalized methods to propose a hybrid framework that yields a better uncertainty estimation for GPT models. Overal
    
[^27]: 使用文本相似性进行自动答案验证

    Automated Answer Validation using Text Similarity. (arXiv:2401.08688v1 [cs.CL])

    [http://arxiv.org/abs/2401.08688](http://arxiv.org/abs/2401.08688)

    该论文研究了使用文本相似性进行自动答案验证的方法，并实现了一个通用解决方案。在科学问题回答中，信息检索方法在多项选择问题中优于神经方法。通过比较我们的监督模型与其他文本相似性解决方案，我们展示了该方法的有效性。

    

    自动答案验证可以通过为学习者提供适当的反馈，使问题回答系统和在线学习解决方案更广泛可用来提高学习效果。在科学问题回答方面已经有一些研究表明，信息检索方法在这个问题的多项选择版本中优于神经方法。我们实现了孪生神经网络模型，并提供了一个通用解决方案来解决这个问题。我们将我们的监督模型与其他基于文本相似性的解决方案进行了比较。

    Automated answer validation can help improve learning outcomes by providing appropriate feedback to learners, and by making question answering systems and online learning solutions more widely available. There have been some works in science question answering which show that information retrieval methods outperform neural methods, especially in the multiple choice version of this problem. We implement Siamese neural network models and produce a generalised solution to this problem. We compare our supervised model with other text similarity based solutions.
    
[^28]: 将大型语言模型应用于教育：基本能力、潜力和挑战

    Adapting Large Language Models for Education: Foundational Capabilities, Potentials, and Challenges. (arXiv:2401.08664v1 [cs.AI])

    [http://arxiv.org/abs/2401.08664](http://arxiv.org/abs/2401.08664)

    本文回顾了针对教育能力的大型语言模型研究，包括数学、写作、编程、推理和基于知识的问答，旨在探索其在构建下一代智能教育系统中的潜力和挑战。

    

    在线教育平台利用互联网分发教育资源，旨在提供便捷的教育，但往往在与学生的实时交流方面存在不足。由于需要解决学生在学习过程中遇到的多样化障碍的挑战，它们经常难以提供个性化的教育资源。最近出现的大型语言模型（LLMs），如ChatGPT，提供了通过理解个体请求解决这一问题的可能性。虽然LLMs在各个领域都取得了成功，但基于LLM的教育系统的构建仍然面临着广泛的教育技能要求。本文回顾了与教育能力相关的近期出现的LLM研究，包括数学、写作、编程、推理和基于知识的问答，旨在探索它们在构建下一代智能教育系统方面的潜力。

    Online education platforms, leveraging the internet to distribute education resources, seek to provide convenient education but often fall short in real-time communication with students. They often struggle to offer personalized education resources due to the challenge of addressing the diverse obstacles students encounter throughout their learning journey. Recently, the emergence of large language models (LLMs), such as ChatGPT, offers the possibility for resolving this issue by comprehending individual requests. Although LLMs have been successful in various fields, creating an LLM-based education system is still challenging for the wide range of educational skills required. This paper reviews the recently emerged LLM researches related to educational capabilities, including mathematics, writing, programming, reasoning, and knowledge-based question answering, with the aim to explore their potential in constructing the next-generation intelligent education system. Based on the current 
    
[^29]: Gemini Pro被GPT-4V击败：来自教育领域的证据

    Gemini Pro Defeated by GPT-4V: Evidence from Education. (arXiv:2401.08660v1 [cs.AI])

    [http://arxiv.org/abs/2401.08660](http://arxiv.org/abs/2401.08660)

    本研究比较了Gemini Pro和GPT-4V在教育领域的分类性能，发现GPT-4V在评分准确度和Quadratic Weighted Kappa方面明显优于Gemini Pro，可能是因为GPT-4V能够处理图像中的细致文本并具有更好的整体图像分类性能。

    

    本研究在教育环境中比较了Gemini Pro和GPT-4V在分类性能上的表现。通过使用视觉问答（VQA）技术，本研究考察了两个模型在阅读基于文本的评分标准并自动评分科学教育中学生绘制的模型的能力。我们采用了定量和定性分析，并使用了从学生绘制的科学模型中得出的数据集以及NERIF（Notation-Enhanced Rubrics for Image Feedback）提问方法。研究结果显示，GPT-4V在评分准确度和Quadratic Weighted Kappa方面明显优于Gemini Pro。定性分析显示，这种差异可能源于模型在图像中处理细致文本和整体图像分类性能方面的能力。即使通过进一步缩小输入图像的NERIF方法来适应Gemini Pro，其性能仍不如GPT-4V。研究结果表明GPT-4V在处理复杂多样的学生绘制模型方面具有更强的能力。

    This study compared the classification performance of Gemini Pro and GPT-4V in educational settings. Employing visual question answering (VQA) techniques, the study examined both models' abilities to read text-based rubrics and then automatically score student-drawn models in science education. We employed both quantitative and qualitative analyses using a dataset derived from student-drawn scientific models and employing NERIF (Notation-Enhanced Rubrics for Image Feedback) prompting methods. The findings reveal that GPT-4V significantly outperforms Gemini Pro in terms of scoring accuracy and Quadratic Weighted Kappa. The qualitative analysis reveals that the differences may be due to the models' ability to process fine-grained texts in images and overall image classification performance. Even adapting the NERIF approach by further de-sizing the input images, Gemini Pro seems not able to perform as well as GPT-4V. The findings suggest GPT-4V's superior capability in handling complex mu
    
[^30]: 向经典致敬：在大规模语言模型时代重新思考机器翻译的挑战

    Salute the Classic: Revisiting Challenges of Machine Translation in the Age of Large Language Models. (arXiv:2401.08350v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.08350](http://arxiv.org/abs/2401.08350)

    本文重新审视了机器翻译领域的六个核心挑战，并提供了对于大规模语言模型在这些挑战中所取得进展的实证发现。研究发现，大规模语言模型能够有效减少对平行数据的依赖，提高翻译质量并扩展翻译文档的长度范围。然而，领域不匹配和罕见词预测仍然是需要解决的问题。

    

    神经机器翻译 (NMT) 的发展受到六个核心挑战的显著影响，这些挑战为这个领域的进展提供了基准。本研究重新审视了这些挑战，在先进大规模语言模型 (LLM) 的背景下，提供了对这些挑战持续相关性的深入见解。我们的实证研究表明，在预训练阶段，LLM能够有效减少对平行数据的依赖，特别是对于主要语言。此外，基于LLM的翻译系统显著提高了翻译约80个单词的长句子的质量，并且能够翻译长达512个单词的文档。然而，尽管取得了显著的改进，领域不匹配和罕见词预测仍然是挑战。在解决单词对齐和亚最优搜索的挑战方面，LLM仍存在改进的空间。

    The evolution of Neural Machine Translation (NMT) has been significantly influenced by six core challenges (Koehn and Knowles, 2017), which have acted as benchmarks for progress in this field. This study revisits these challenges, offering insights into their ongoing relevance in the context of advanced Large Language Models (LLMs): domain mismatch, amount of parallel data, rare word prediction, translation of long sentences, attention model as word alignment, and sub-optimal beam search. Our empirical findings indicate that LLMs effectively lessen the reliance on parallel data for major languages in the pretraining phase. Additionally, the LLM-based translation system significantly enhances the translation of long sentences that contain approximately 80 words and shows the capability to translate documents of up to 512 words. However, despite these significant improvements, the challenges of domain mismatch and prediction of rare words persist. While the challenges of word alignment a
    
[^31]: 看见未见：通过噪声实现更好的上下文一致性知识编辑

    See the Unseen: Better Context-Consistent Knowledge-Editing by Noises. (arXiv:2401.07544v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.07544](http://arxiv.org/abs/2401.07544)

    本文通过对不同上下文对大型语言模型的影响进行高斯噪声采样，实现了对知识编辑的上下文一致性进行更好的推广，提高了编辑的普适性。

    

    知识编辑更新大型语言模型（LLM）的知识，并为LLM的可解释性和应用做出贡献。然而，知识应用是上下文一致的：LLM可以在不同上下文中回忆相同的知识。现有的工作忽视了这一属性，并且编辑缺乏普适性。本文通过实验证明，不同上下文对于LLM在回忆相同知识时的影响符合高斯分布。我们随后对高斯噪声进行采样，模拟在更新LLM时不同上下文的影响。通过这样的方式，我们可以使LLM看到将应用编辑后知识的未见上下文，从而改善编辑的推广性。对三个LLM的实验结果证明了我们方法的有效性，并且将我们的方法与通过噪声微调LLM的其他方法区分开来。

    Knowledge-editing updates knowledge of large language models (LLMs) and contributes to the interpretability and application of LLMs. However, knowledge applying is context-consistent: LLMs can recall the same knowledge in different contexts. Existing works ignore this property and the editing lacks generalization. In this paper, we empirically find that the effects of different contexts upon LLMs in recalling the same knowledge follow a Gaussian-like distribution. We then sample Gaussian noises to simulate the effects of different contexts when updating LLMs. By such, we can make LLMs see the unseen contexts where the edited knowledge will be applied, therefore improving the editing generalization. Experimental results on three LLMs demonstrate the effectiveness of our methods and also distinguish our methods from the others of fine-tuning LLMs by noises.
    
[^32]: 语言模型的细粒度幻觉检测与编辑

    Fine-grained Hallucination Detection and Editing for Language Models. (arXiv:2401.06855v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.06855](http://arxiv.org/abs/2401.06855)

    这项研究提出了一个新任务，即自动细粒度幻觉检测，并介绍了一个综合分类方法。通过对两个语言模型的输出进行分析，发现大部分幻觉属于少有的类别。为了解决这个问题，研究者通过训练一个检索增强语言模型，使用合成数据来检测和纠正幻觉。

    

    大型语言模型往往会生成多样的事实不正确的陈述，被广泛称为幻觉。目前的方法主要集中在粗粒度的自动幻觉检测或编辑上，忽视了细微的错误级别。本文提出了一项新任务——自动细粒度幻觉检测，并提出了一个包含六个层次分明的幻觉类型的综合分类法。为了便于评估，我们引入了一个新的基准，其中包括对两个语言模型输出在各个领域上进行细粒度人工判断的数据。我们的分析发现，ChatGPT和Llama 2-Chat的输出中有60%和75%的幻觉，其中多数幻觉属于未被充分探索的类别。作为解决这一问题的初始步骤，我们训练了FAVA，一个经过精心设计合成数据生成来检测和纠正细粒度幻觉的检索增强语言模型。

    Large language models (LMs) are prone to generate diverse factually incorrect statements, which are widely called hallucinations. Current approaches predominantly focus on coarse-grained automatic hallucination detection or editing, overlooking nuanced error levels. In this paper, we propose a novel task -- automatic fine-grained hallucination detection -- and present a comprehensive taxonomy encompassing six hierarchically defined types of hallucination. To facilitate evaluation, we introduce a new benchmark that includes fine-grained human judgments on two LM outputs across various domains. Our analysis reveals that ChatGPT and Llama 2-Chat exhibit hallucinations in 60% and 75% of their outputs, respectively, and a majority of these hallucinations fall into categories that have been underexplored. As an initial step to address this, we train FAVA, a retrieval-augmented LM by carefully designing synthetic data generations to detect and correct fine-grained hallucinations. On our bench
    
[^33]: LightHouse: AGI幻觉综述

    LightHouse: A Survey of AGI Hallucination. (arXiv:2401.06792v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.06792](http://arxiv.org/abs/2401.06792)

    该论文综述了AGI（人工通用智能）的幻觉现象，总结了当前对AGI幻觉的研究进展，并提出了一些未来研究方向的建议。

    

    随着人工智能的发展，大规模模型变得越来越智能。然而，许多研究表明，这些大模型中的幻觉成为了阻碍AI研究发展的瓶颈。为了实现强人工智能，大量的研究工作正在投入到AGI（人工通用智能）幻觉研究中。以往的探索主要集中在研究LLM（大语言模型）中的幻觉，而对于多模态AGI，幻觉研究仍处于早期阶段。为了进一步推动幻觉现象领域的研究进展，我们提供了对AGI幻觉的总览，总结了当前对AGI幻觉的研究工作，并提出了一些未来研究方向的建议。

    With the development of artificial intelligence, large-scale models have become increasingly intelligent. However, numerous studies indicate that hallucinations within these large models are a bottleneck hindering the development of AI research. In the pursuit of achieving strong artificial intelligence, a significant volume of research effort is being invested in the AGI (Artificial General Intelligence) hallucination research. Previous explorations have been conducted in researching hallucinations within LLMs (Large Language Models). As for multimodal AGI, research on hallucinations is still in an early stage. To further the progress of research in the domain of hallucinatory phenomena, we present a bird's eye view of hallucinations in AGI, summarizing the current work on AGI hallucinations and proposing some directions for future research.
    
[^34]: 关于我：使用自我描述的网页来记录英语预训练数据过滤器的影响

    AboutMe: Using Self-Descriptions in Webpages to Document the Effects of English Pretraining Data Filters. (arXiv:2401.06408v1 [cs.CL])

    [http://arxiv.org/abs/2401.06408](http://arxiv.org/abs/2401.06408)

    这项研究调查了十个质量和语言识别过滤器对不同社交维度变化的网页的影响。实验发现在数据筛选过程中存在隐含的偏好，一些质量分类器类似于主题过滤器，而语言识别可能会忽视某些地区的英语内容。我们的研究为促进更公正和全面的模型开发提供了洞察。

    

    大型语言模型（LLM）的能力来源于它们的预训练数据，模型的开发始于数据的筛选。然而，在这个初步阶段决定保留哪些数据或移除哪些数据的决策常常没有被充分审查。在我们的工作中，我们将网页文本与其社交和地理背景联系起来。我们创建了一个新的数据集，包含1030万个网页创建者的自我描述，并提取了关于他们的个人信息以及他们来自哪里的信息：他们的兴趣领域、社交角色和地理归属。然后，我们进行了第一项研究，调查了十个“质量”和英语语言识别（langID）过滤器对这些社交维度变化的网页的影响。我们的实验揭示了数据筛选中一系列隐含的偏好：我们展示出一些质量分类器的作用类似于主题领域过滤器，而langID可能会忽视世界某些地区的英语内容。总体而言，我们希望我们的工作能够提供对数据筛选中隐含偏好的洞察，以促进更公正和全面的模型开发。

    Large language models' (LLMs) abilities are drawn from their pretraining data, and model development begins with data curation. However, decisions around what data is retained or removed during this initial stage is under-scrutinized. In our work, we ground web text, which is a popular pretraining data source, to its social and geographic contexts. We create a new dataset of 10.3 million self-descriptions of website creators, and extract information about who they are and where they are from: their topical interests, social roles, and geographic affiliations. Then, we conduct the first study investigating how ten "quality" and English language identification (langID) filters affect webpages that vary along these social dimensions. Our experiments illuminate a range of implicit preferences in data curation: we show that some quality classifiers act like topical domain filters, and langID can overlook English content from some regions of the world. Overall, we hope that our work will enc
    
[^35]: AUTOACT：通过自主规划实现的自动代理学习

    AUTOACT: Automatic Agent Learning from Scratch via Self-Planning. (arXiv:2401.05268v1 [cs.CL])

    [http://arxiv.org/abs/2401.05268](http://arxiv.org/abs/2401.05268)

    AUTOACT是一个自动代理学习框架，通过自主规划合成轨迹，不依赖于大规模数据和闭源模型，能够实现更好或类似的性能。

    

    语言代理在各种复杂任务上取得了相当的性能。尽管在这个领域进行了不断的探索，但现有的语言代理系统仍然面临昂贵、不可重复的数据依赖问题，并且面临将单一模型应用于多个功能的挑战。为此，我们介绍了AutoAct，这是一个自动代理学习框架，不依赖于大规模带注释的数据和来自闭源模型（如GPT-4）的合成轨迹。给定有限的数据和工具库，AutoAct首先自动合成规划轨迹，不需要人类或强闭源模型的任何辅助。然后，AutoAct利用分工策略，根据目标任务信息和合成轨迹自动区分，产生一个子代理组来完成任务。我们进行了多种LLMs的广泛实验，结果显示AutoAct在性能上优于或与其相当。

    Language agents have achieved considerable performance on various complex tasks. Despite the incessant exploration in this field, existing language agent systems still struggle with costly, non-reproducible data reliance and face the challenge of compelling a single model for multiple functions. To this end, we introduce AutoAct, an automatic agent learning framework that does not rely on large-scale annotated data and synthetic trajectories from closed-source models (e.g., GPT-4). Given limited data with a tool library, AutoAct first automatically synthesizes planning trajectories without any assistance from humans or strong closed-source models. Then, AutoAct leverages a division-of-labor strategy to automatically differentiate based on the target task information and synthesized trajectories, producing a sub-agent group to complete the task. We conduct comprehensive experiments with different LLMs, which demonstrates that AutoAct yields better or parallel performance compared to var
    
[^36]: MLLM-Protektor: 确保MLLM的安全性而不影响性能

    MLLM-Protector: Ensuring MLLM's Safety without Hurting Performance. (arXiv:2401.02906v1 [cs.CR])

    [http://arxiv.org/abs/2401.02906](http://arxiv.org/abs/2401.02906)

    MLLM-Protektor是一个即插即用的方法，用于保护多模态大型语言模型免受恶意攻击。通过解决图像与文本对齐的挑战，该方法提供了对MLLM的有效保护，防止其产生有害响应。

    

    多模态大型语言模型(MLLM)的部署带来了一个独特的脆弱性：对视觉输入的恶意攻击易受攻击。我们探讨了保护MLLM免受此类攻击的新挑战。我们发现，图像作为一种“外语”在对齐过程中没有被考虑到，这可能使MLLM更容易产生有害的响应。不幸的是，与文本中所考虑的离散标记不同，图像信号的连续性质在对齐过程中带来了重大挑战，从而使覆盖可能情景变得困难。这种脆弱性加剧了一个事实，即开源的MLLM主要在有限的图像-文本对上进行了微调，远远小于广泛的文本预训练语料库，这使得MLLM在明确对齐调整过程中更容易遗忘其原始能力。为了应对这些挑战，我们介绍了MLLM-Protektor，一个即插即用的

    The deployment of multimodal large language models (MLLMs) has brought forth a unique vulnerability: susceptibility to malicious attacks through visual inputs. We delve into the novel challenge of defending MLLMs against such attacks. We discovered that images act as a "foreign language" that is not considered during alignment, which can make MLLMs prone to producing harmful responses. Unfortunately, unlike the discrete tokens considered in text-based LLMs, the continuous nature of image signals presents significant alignment challenges, which poses difficulty to thoroughly cover the possible scenarios. This vulnerability is exacerbated by the fact that open-source MLLMs are predominantly fine-tuned on limited image-text pairs that is much less than the extensive text-based pretraining corpus, which makes the MLLMs more prone to catastrophic forgetting of their original abilities during explicit alignment tuning. To tackle these challenges, we introduce MLLM-Protector, a plug-and-play 
    
[^37]: 增强口语对话的声调语言建模

    Paralinguistics-Enhanced Large Language Modeling of Spoken Dialogue. (arXiv:2312.15316v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.15316](http://arxiv.org/abs/2312.15316)

    提出了一种增强声调语言的预训练变换器，利用文本和语音模态来更好地建模口语对话的语言内容和声调语言属性。

    

    大规模语言模型 (LLM) 在聊天、推理和问答等任务中展现出卓越的能力。然而，标准的 LLM 可能忽视了关键的声调语言信息，例如情感、情绪和语言风格，这些信息对于实现自然的、类似人类的口语对话至关重要，尤其是当这些信息通过声学线索传达时。因此，我们提出了增强声调语言的预训练变换器 (ParalinGPT)，它利用文本和语音模态来更好地建模口语对话的语言内容和声调语言属性。该模型将文本的对话上下文、语音嵌入和声调语言属性作为输入提示，放在一个串行多任务多模态框架中。具体而言，我们的框架按照当前声调语言属性预测、回应声调语言属性预测和回应文本生成的顺序进行序列化任务。

    Large Language Models (LLMs) have demonstrated superior abilities in tasks such as chatting, reasoning, and question-answering. However, standard LLMs may ignore crucial paralinguistic information, such as sentiment, emotion, and speaking style, which are essential for achieving natural, human-like spoken conversation, especially when such information is conveyed by acoustic cues. We therefore propose Paralinguistics-enhanced Generative Pretrained Transformer (ParalinGPT), an LLM that utilizes text and speech modalities to better model the linguistic content and paralinguistic attributes of spoken dialogue. The model takes the conversational context of text, speech embeddings, and paralinguistic attributes as input prompts within a serialized multitasking multimodal framework. Specifically, our framework serializes tasks in the order of current paralinguistic attribute prediction, response paralinguistic attribute prediction, and response text generation with autoregressive conditionin
    
[^38]: 在SpiNNaker 2神经形态芯片上进行语言建模

    Language Modeling on a SpiNNaker 2 Neuromorphic Chip. (arXiv:2312.09084v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2312.09084](http://arxiv.org/abs/2312.09084)

    该论文介绍了在SpiNNaker 2神经形态芯片上实现语言建模的首次尝试。通过利用基于事件的架构和大规模异步处理的硬件，该方法有望在减少能耗的同时保持竞争任务性能。

    

    随着大型语言模型的规模迅速增长，所需的计算能力也在增加。基于神经形态设备上的事件驱动网络提供了一种显著降低推理能耗的潜在方式。然而，迄今为止，大多数可以在神经形态硬件上运行的基于事件的网络，包括脉冲神经网络(SNN)，在语言建模方面的任务性能甚至不能与LSTM模型相媲美。因此，在神经形态设备上进行语言建模似乎是一个遥远的可能性。在这项工作中，我们首次在神经形态设备上实现了一个语言模型 - 具体来说是基于最近发布的名为EGRU的基于事件的架构的SpiNNaker 2芯片。SpiNNaker 2是一个设计用于大规模异步处理的众核神经形态芯片，而EGRU是为了在保持竞争任务性能的同时高效利用这种硬件而设计的。这个实现标志着在神经形态设备上进行语言建模的第一个

    As large language models continue to scale in size rapidly, so too does the computational power required to run them. Event-based networks on neuromorphic devices offer a potential way to reduce energy consumption for inference significantly. However, to date, most event-based networks that can run on neuromorphic hardware, including spiking neural networks (SNNs), have not achieved task performance even on par with LSTM models for language modeling. As a result, language modeling on neuromorphic devices has seemed a distant prospect. In this work, we demonstrate the first-ever implementation of a language model on a neuromorphic device - specifically the SpiNNaker 2 chip based on a recently published event-based architecture called the EGRU. SpiNNaker 2 is a many-core neuromorphic chip designed for large-scale asynchronous processing, while the EGRU is architected to leverage such hardware efficiently while maintaining competitive task performance. This implementation marks the firs
    
[^39]: TiMix: 文本感知图像混合用于有效的视觉语言预训练

    TiMix: Text-aware Image Mixing for Effective Vision-Language Pre-training. (arXiv:2312.08846v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.08846](http://arxiv.org/abs/2312.08846)

    TiMix是一种将文本感知的图像混合技术用于视觉语言预训练的方法，通过集成混合数据增强技术，并从互信息的角度进行理论分析，提高了数据效率并取得了可比较的性能。

    

    自监督的多模态对比学习（SMCL）通过对齐视觉和语言模态，显著推进了现代视觉语言预训练（VLP）模型的发展。然而，由于网络收集的文本-图像对中存在噪声，扩大SMCL的训练数据量在计算成本和数据效率方面面临着相当大的障碍。为了提高VLP的数据效率，我们提出了文本感知图像混合（TiMix），将基于混合的数据增强技术集成到SMCL中，显著提升了性能，而不会显著增加计算开销。我们从互信息（MI）的角度对TiMix进行了理论分析，表明跨模态对比学习的混合数据样本隐式地作为对比损失的正则化器。实验结果表明，即使使用较少的训练数据和较短的训练时间，TiMix在下游任务上表现出可比较的性能。

    Self-supervised Multi-modal Contrastive Learning (SMCL) remarkably advances modern Vision-Language Pre-training (VLP) models by aligning visual and linguistic modalities. Due to noises in web-harvested text-image pairs, however, scaling up training data volume in SMCL presents considerable obstacles in terms of computational cost and data inefficiency. To improve data efficiency in VLP, we propose Text-aware Image Mixing (TiMix), which integrates mix-based data augmentation techniques into SMCL, yielding significant performance improvements without significantly increasing computational overhead. We provide a theoretical analysis of TiMixfrom a mutual information (MI) perspective, showing that mixed data samples for cross-modal contrastive learning implicitly serve as a regularizer for the contrastive loss. The experimental results demonstrate that TiMix exhibits a comparable performance on downstream tasks, even with a reduced amount of training data and shorter training time, when be
    
[^40]: CLadder: 评估语言模型因果推理能力的基准测试

    CLadder: A Benchmark to Assess Causal Reasoning Capabilities of Language Models. (arXiv:2312.04350v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.04350](http://arxiv.org/abs/2312.04350)

    该论文提出了一个新的NLP任务，评估语言模型在因果推理方面的能力。作者构建了一个大规模的数据集CLadder，并利用oracle因果推理引擎将符号问题转化为自然语言。研究结果表明多个LLMs在该数据集上的表现，并引入并评估了一种定制的链式推理机制。

    

    进行因果推理的能力被广泛视为智能的核心特征。本文研究了大型语言模型(LLMs)能否连贯地推理因果关系。现有的自然语言处理(NLP)工作主要关注评估LLMs中的常识因果推理，未能评估模型是否能够按照一组明确定义的形式规则执行因果推断。为了解决这个问题，我们提出了一个新的NLP任务，自然语言中的因果推断，受到Judea Pearl等人提出的“因果推断引擎”的启发。我们构建了一个包含10K个样本的大型数据集CLadder，通过一种oracle因果推理引擎，基于一组因果图和查询(联合、干预和反事实)，得到符号问题和真实答案，并将其翻译为自然语言。我们对数据集上的多个LLMs进行评估，并引入和评估了一种定制的链式推理机制。

    The ability to perform causal reasoning is widely considered a core feature of intelligence. In this work, we investigate whether large language models (LLMs) can coherently reason about causality. Much of the existing work in natural language processing (NLP) focuses on evaluating commonsense causal reasoning in LLMs, thus failing to assess whether a model can perform causal inference in accordance with a set of well-defined formal rules. To address this, we propose a new NLP task, causal inference in natural language, inspired by the "causal inference engine" postulated by Judea Pearl et al. We compose a large dataset, CLadder, with 10K samples: based on a collection of causal graphs and queries (associational, interventional, and counterfactual), we obtain symbolic questions and ground-truth answers, through an oracle causal inference engine. These are then translated into natural language. We evaluate multiple LLMs on our dataset, and we introduce and evaluate a bespoke chain-of-th
    
[^41]: 电力系统中动态故障特性评估

    Dynamic Fault Characteristics Evaluation in Power Grid. (arXiv:2311.16522v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2311.16522](http://arxiv.org/abs/2311.16522)

    该论文提出了一种在电力系统中进行故障检测的新方法，通过图神经网络识别故障节点，并利用前后时间段内节点的状态来辅助当前故障检测。实验证明该方法准确可靠，并提供了对故障节点传播的定性分析。

    

    为了增强运维的智能度，提出了一种在电力系统中进行故障检测的新方法。该方法基于图神经网络，通过专门的特征提取方法和知识图谱来识别故障节点。通过引入时间数据，该方法利用前后时间段内节点的状态来辅助当前故障检测。为了验证节点特征的有效性，还进行了每个节点输出特征的相关性分析。实验证明，该方法可以在仿真场景中准确地定位故障节点，并具有显著的准确性。此外，基于图神经网络的特征建模可以定性地考察故障如何在节点间传播，为分析故障节点提供了有价值的见解。

    To enhance the intelligence degree in operation and maintenance, a novel method for fault detection in power grids is proposed. The proposed GNN-based approach first identifies fault nodes through a specialized feature extraction method coupled with a knowledge graph. By incorporating temporal data, the method leverages the status of nodes from preceding and subsequent time periods to help current fault detection. To validate the effectiveness of the node features, a correlation analysis of the output features from each node was conducted. The results from experiments show that this method can accurately locate fault nodes in simulation scenarios with a remarkable accuracy. Additionally, the graph neural network based feature modeling allows for a qualitative examination of how faults spread across nodes, which provides valuable insights for analyzing fault nodes.
    
[^42]: 基于知识图谱的变电站动态故障分析

    Dynamic Fault Analysis in Substations Based on Knowledge Graphs. (arXiv:2311.13708v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.13708](http://arxiv.org/abs/2311.13708)

    提出了一种基于知识图谱的变电站动态故障分析方法，利用非结构化文本提取相关信息，通过隐藏马尔科夫模型训练数据，利用Neo4j图数据库创建知识图谱，实现对变电站中隐藏危险的可视化分析。

    

    为了解决从非结构化文本中识别变电站隐藏危险的挑战，提出了一种新颖的动态分析方法。首先从非结构化文本中提取相关信息，然后利用基于Elastic-Search构建的灵活分布式搜索引擎处理数据。接下来，使用隐藏马尔科夫模型来训练引擎中的数据。维特比算法被整合进来解密隐藏状态序列，便于对与隐藏危险相关的实体进行分割和标注。最后，使用Neo4j图数据库动态创建知识图谱来可视化变电站中的隐藏危险。通过对文本记录中揭示的具体变电站的隐藏危险进行案例分析，证明了所提方法的有效性。

    To address the challenge of identifying hidden danger in substations from unstructured text, a novel dynamic analysis method is proposed. We first extract relevant information from the unstructured text, and then leverages a flexible distributed search engine built on Elastic-Search to handle the data. Following this, the hidden Markov model is employed to train the data within the engine. The Viterbi algorithm is integrated to decipher the hidden state sequences, facilitating the segmentation and labeling of entities related to hidden dangers. The final step involves using the Neo4j graph database to dynamically create a knowledge graph that visualizes hidden dangers in the substation. The effectiveness of the proposed method is demonstrated through a case analysis from a specific substation with hidden dangers revealed in the text records.
    
[^43]: LQ-LoRA: 低秩加量化矩阵分解用于有效的语言模型微调

    LQ-LoRA: Low-rank Plus Quantized Matrix Decomposition for Efficient Language Model Finetuning. (arXiv:2311.12023v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.12023](http://arxiv.org/abs/2311.12023)

    LQ-LoRA是一种低秩加量化矩阵分解方法，用于内存高效的语言模型微调。它通过将每个预训练矩阵分解为高精度低秩部分和内存高效的量化部分，实现了动态配置量化参数以及对重构目标进行加权的优化，并在微调实验中表现出了优于QLoRA和GPTQ-LoRA的效果。

    

    我们提出了一种简单的方法，用于对预训练语言模型进行内存高效的自适应。我们的方法使用迭代算法将每个预训练矩阵分解为高精度低秩部分和内存高效的量化部分。在微调过程中，量化部分保持固定，只有低秩部分被更新。我们提出了量化部分的整数线性规划表达，可以根据总体内存预算动态配置量化参数（例如比特宽度、块大小）给定每个矩阵。我们进一步探索了数据感知版本的算法，该算法使用Fisher信息矩阵的近似来加权矩阵分解过程中的重构目标。在RoBERTa和LLaMA-2（7B和70B）的微调实验中，我们的低秩加量化矩阵分解方法（LQ-LoRA）优于强基线方法QLoRA和GPTQ-LoRA，并实现了激进的量化。

    We propose a simple approach for memory-efficient adaptation of pretrained language models. Our approach uses an iterative algorithm to decompose each pretrained matrix into a high-precision low-rank component and a memory-efficient quantized component. During finetuning, the quantized component remains fixed and only the low-rank component is updated. We present an integer linear programming formulation of the quantization component which enables dynamic configuration of quantization parameters (e.g., bit-width, block size) for each matrix given an overall target memory budget. We further explore a data-aware version of the algorithm which uses an approximation of the Fisher information matrix to weight the reconstruction objective during matrix decomposition. Experiments on finetuning RoBERTa and LLaMA-2 (7B and 70B) demonstrate that our low-rank plus quantized matrix decomposition approach (LQ-LoRA) outperforms strong QLoRA and GPTQ-LoRA baselines and enables aggressive quantization
    
[^44]: 通过奥兹魔术师模拟未来记忆和具有韧性的定位通信

    Modelling prospective memory and resilient situated communications via Wizard of Oz. (arXiv:2311.05268v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.05268](http://arxiv.org/abs/2311.05268)

    通过奥兹魔术师模拟未来记忆和具有韧性的定位通信，在家庭环境中探索与社交辅助机器人的沟通记忆建模。

    

    这篇摘要提出了一个在家庭环境中涉及老年人和机器人的人机行动情景。该情景旨在探索对于与社交辅助机器人（SAR）进行沟通的记忆建模。该情景将能够收集关于语音技术故障和人机沟通中涉及共享记忆的数据，这些故障可能发生在诸如音乐欣赏活动等日常活动中。

    This abstract presents a scenario for human-robot action in a home setting involving an older adult and a robot. The scenario is designed to explore the envisioned modelling of memory for communication with a socially assistive robots (SAR). The scenario will enable the gathering of data on failures of speech technology and human-robot communication involving shared memory that may occur during daily activities such as a music-listening activity.
    
[^45]: DistilWhisper：通过语言特定专家高效压缩多任务语音模型

    DistilWhisper: Efficient Distillation of Multi-task Speech Models via Language-Specific Experts. (arXiv:2311.01070v1 [cs.CL])

    [http://arxiv.org/abs/2311.01070](http://arxiv.org/abs/2311.01070)

    本文提出了DistilWhisper方法，通过使用语言特定专家进行轻量级模块化ASR微调和知识蒸馏，成功弥合了多任务语音模型在少数语言上的性能差距，同时保留了多任务和多语言能力的优势。

    

    Whisper是一个多任务和多语言的语音模型，涵盖99种语言。它在其涵盖的部分语言中获得了令人称赞的自动语音识别（ASR）结果，但在一些数量可观的少数语言中，该模型仍然表现不佳，尤其在较小的模型版本中表现更为严重。在这项工作中，我们提出了DistilWhisper，一种能够在ASR方面弥合这些语言的性能差距，同时保留多任务和多语言能力优势的方法。我们的方法包括两个关键策略：使用语言特定专家对whisper-small进行轻量级模块化ASR微调，并从whisper-large-v2进行知识蒸馏。这种双重方法使我们能够在保持多任务和多语言预训练的鲁棒性的同时有效提升ASR性能。结果表明，我们的方法比标准微调或LoRA适配器更有效，在目标语言中提升了性能。

    Whisper is a multitask and multilingual speech model covering 99 languages. It yields commendable automatic speech recognition (ASR) results in a subset of its covered languages, but the model still under-performs on a non-negligible number of under-represented languages, a problem exacerbated in smaller model versions. In this work, we propose DistilWhisper, an approach able to bridge the performance gap in ASR for these languages while retaining the advantages of multitask and multilingual capabilities. Our approach involves two key strategies: lightweight modular ASR fine-tuning of whisper-small using language-specific experts, and knowledge distillation from whisper-large-v2. This dual approach allows us to effectively boost ASR performance while keeping the robustness inherited from the multitask and multilingual pre-training. Results demonstrate that our approach is more effective than standard fine-tuning or LoRA adapters, boosting performance in the targeted languages for both 
    
[^46]: DialogueLLM: 对情感识别中对话进行情境和情感知识调校的大型语言模型

    DialogueLLM: Context and Emotion Knowledge-Tuned Large Language Models for Emotion Recognition in Conversations. (arXiv:2310.11374v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.11374](http://arxiv.org/abs/2310.11374)

    DialogueLLM是一种通过使用多模态情感对话微调的上下文和情感知识调校的大型语言模型，用于情感识别任务。

    

    大型语言模型（LLMs）及其变种在众多自然语言处理（NLP）任务中显示出非凡的效果，这为NLP的发展带来了新的视野。尽管LLMs在自然语言生成（NLG）方面的表现出色，但缺乏对情感理解领域的明确关注。因此，使用LLMs进行情感识别可能导致精度不佳和不充分。另一个LLMs的限制是它们通常在没有利用多模态信息的情况下进行训练。为了克服这些限制，我们提出了DialogueLLM，一种经过细调的上下文和情感知识调校的LLM，通过使用13,638个多模态（文本和视频）情感对话的LLaMA模型进行微调获得。视觉信息被视为构建高质量指令的补充知识。我们对我们提出的模型在三个情感识别对话（ERC）基准数据集上进行了全面评估。

    Large language models (LLMs) and their variants have shown extraordinary efficacy across numerous downstream natural language processing (NLP) tasks, which has presented a new vision for the development of NLP. Despite their remarkable performance in natural language generating (NLG), LLMs lack a distinct focus on the emotion understanding domain. As a result, using LLMs for emotion recognition may lead to suboptimal and inadequate precision. Another limitation of LLMs is that they are typical trained without leveraging multi-modal information. To overcome these limitations, we propose DialogueLLM, a context and emotion knowledge tuned LLM that is obtained by fine-tuning LLaMA models with 13,638 multi-modal (i.e., texts and videos) emotional dialogues. The visual information is considered as the supplementary knowledge to construct high-quality instructions. We offer a comprehensive evaluation of our proposed model on three benchmarking emotion recognition in conversations (ERC) datase
    
[^47]: 《语言模型中激活路径修复的最佳实践：度量和方法》的论文翻译

    Towards Best Practices of Activation Patching in Language Models: Metrics and Methods. (arXiv:2309.16042v1 [cs.LG])

    [http://arxiv.org/abs/2309.16042](http://arxiv.org/abs/2309.16042)

    本研究系统地考察了激活路径修复中的方法细节对语言模型解释性结果的影响，并提出了最佳实践建议。

    

    机械解释性旨在理解机器学习模型的内部机制，其中定位-识别重要的模型组件是关键步骤。激活路径修复，也称为因果追踪或交换干预，是完成这一任务的标准技术，但文献中存在许多变体，对超参数或方法选择缺乏一致性。在这项工作中，我们系统地考察了激活路径修复中的方法细节对结果的影响，包括评估指标和损坏方法。在语言模型的定位和电路发现的几种设置中，我们发现不同的超参数可能导致不同的解释结果。通过经验观察支持，我们提出了为什么某些指标或方法可能更受欢迎的概念性论证。最后，我们提出了激活路径修复的最佳实践建议。

    Mechanistic interpretability seeks to understand the internal mechanisms of machine learning models, where localization -- identifying the important model components -- is a key step. Activation patching, also known as causal tracing or interchange intervention, is a standard technique for this task (Vig et al., 2020), but the literature contains many variants with little consensus on the choice of hyperparameters or methodology. In this work, we systematically examine the impact of methodological details in activation patching, including evaluation metrics and corruption methods. In several settings of localization and circuit discovery in language models, we find that varying these hyperparameters could lead to disparate interpretability results. Backed by empirical observations, we give conceptual arguments for why certain metrics or methods may be preferred. Finally, we provide recommendations for the best practices of activation patching going forwards.
    
[^48]: 注意言辞：大型语言模型和内容审查

    Watch Your Language: Large Language Models and Content Moderation. (arXiv:2309.14517v1 [cs.HC])

    [http://arxiv.org/abs/2309.14517](http://arxiv.org/abs/2309.14517)

    本研究评估了大型语言模型在内容审查任务上的表现，发现它们在基于规则的社区审查和有害内容检测方面具有很好的效果，在有害内容检测方面超过了现有的分类器。然而，最近模型规模的增加对有害内容检测的改进效果很小。

    

    由于其在各种自然语言任务上的能力，大型语言模型（LLMs）变得非常受欢迎。基于文本的内容审查是其中一个受到近期热情关注的LLM应用案例，然而，鲜有研究调查LLMs在内容审查设置中的表现。在这项工作中，我们评估了一套现代、商业化的LLMs（GPT-3、GPT-3.5、GPT-4）在两个常见的内容审查任务上的表现：基于规则的社区审查和有害内容检测。对于基于规则的社区审查，我们构建了95个LLM审查引擎，并使用95个Reddit子社区的规则进行指导，发现LLMs在许多社区的基于规则的审查中表现出色，实现了中位数准确率为64%和中位数精确度为83%。在有害内容检测方面，我们发现LLMs明显优于现有商业可用的有害性分类器。然而，我们还发现最近模型规模的增加对有害内容检测几乎没有带来明显的好处。

    Large language models (LLMs) have exploded in popularity due to their ability to perform a wide array of natural language tasks. Text-based content moderation is one LLM use case that has received recent enthusiasm, however, there is little research investigating how LLMs perform in content moderation settings. In this work, we evaluate a suite of modern, commercial LLMs (GPT-3, GPT-3.5, GPT-4) on two common content moderation tasks: rule-based community moderation and toxic content detection. For rule-based community moderation, we construct 95 LLM moderation-engines prompted with rules from 95 Reddit subcommunities and find that LLMs can be effective at rule-based moderation for many communities, achieving a median accuracy of 64% and a median precision of 83%. For toxicity detection, we find that LLMs significantly outperform existing commercially available toxicity classifiers. However, we also find that recent increases in model size add only marginal benefit to toxicity detection
    
[^49]: 闲谈令人无聊的问题：研究基于GPT的文本规范化

    A Chat About Boring Problems: Studying GPT-based text normalization. (arXiv:2309.13426v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.13426](http://arxiv.org/abs/2309.13426)

    本文研究了基于GPT的文本规范化任务。通过结合自洽推理和基于语言知识的提示工程，我们发现基于LLM的文本规范化的错误率比顶级规范化系统低约40％。同时，通过对错误分析，我们发现传统的文本规范化任务设计存在关键限制。我们创建了一个新的框架以识别基于GPT的文本规范化的优势和局限性。这为未来的工作提供了机会。

    

    文本规范化-将文本从书面形式转化为口语形式-通常被认为是语言模型面临的一个不完善的任务。在这项工作中，我们提出了与之相反的观点。我们通过实证研究了大型语言模型（LLM）在少样本情境下进行文本规范化的能力。通过结合自洽推理和基于语言知识的提示工程，我们发现基于LLM的文本规范化的错误率比顶级规范化系统低约40％。进一步的错误分析中，我们注意到传统的文本规范化任务设计的关键限制。我们创建了一个新的文本规范化错误分类，并将其应用于GPT-3.5-Turbo和GPT-4.0的结果中。通过这个新的框架，我们可以识别出基于GPT的文本规范化的优势和局限性，从而为未来的工作提供了机会。

    Text normalization - the conversion of text from written to spoken form - is traditionally assumed to be an ill-formed task for language models. In this work, we argue otherwise. We empirically show the capacity of Large-Language Models (LLM) for text normalization in few-shot scenarios. Combining self-consistency reasoning with linguistic-informed prompt engineering, we find LLM based text normalization to achieve error rates around 40\% lower than top normalization systems. Further, upon error analysis, we note key limitations in the conventional design of text normalization tasks. We create a new taxonomy of text normalization errors and apply it to results from GPT-3.5-Turbo and GPT-4.0. Through this new framework, we can identify strengths and weaknesses of GPT-based TN, opening opportunities for future work.
    
[^50]: 语义相似性预测优于其他语义相似性度量方法

    Semantic similarity prediction is better than other semantic similarity measures. (arXiv:2309.12697v1 [cs.CL])

    [http://arxiv.org/abs/2309.12697](http://arxiv.org/abs/2309.12697)

    本文提出了一种使用经过微调的模型直接预测语义相似性的方法，并将其与其他方法进行比较，结果表明所得到的相似性更加符合我们对鲁棒的语义相似性度量的预期。

    

    自然语言文本之间的语义相似性通常通过检查子序列的重叠（例如BLEU）或使用嵌入（例如BERTScore，S-BERT）来衡量。在本文中，我们认为当我们仅对衡量语义相似性感兴趣时，直接使用经过微调的模型来预测相似性比其他方法更好。我们使用从GLUE基准测试中微调的STS-B模型，定义了STSScore方法，并且显示出所得到的相似性与我们对鲁棒的语义相似性度量的预期更加一致。

    Semantic similarity between natural language texts is typically measured either by looking at the overlap between subsequences (e.g., BLEU) or by using embeddings (e.g., BERTScore, S-BERT). Within this paper, we argue that when we are only interested in measuring the semantic similarity, it is better to directly predict the similarity using a fine-tuned model for such a task. Using a fine-tuned model for the STS-B from the GLUE benchmark, we define the STSScore approach and show that the resulting similarity is better aligned with our expectations on a robust semantic similarity measure than other approaches.
    
[^51]: 大型语言模型作为自主决策者

    Large Language Model as Autonomous Decision Maker. (arXiv:2308.12519v1 [cs.CL])

    [http://arxiv.org/abs/2308.12519](http://arxiv.org/abs/2308.12519)

    本文提出了一种方法JuDec，为大型语言模型(LLMs)赋予了自我判断的能力，使其能够作为自主决策者实现自主判断和决策探索。实验结果显示JuDec在不同任务上表现优异，提高了通过率并降低了成本。

    

    虽然大型语言模型(LLMs)展示了令人印象深刻的语言理解和上下文学习能力，但它们在解决现实世界任务时仍严重依赖于专家知识的指导。为了发挥LLMs作为自主决策者的潜力，本文提出了一种称为JuDec的方法，赋予LLMs自我判断的能力，使其能够实现自主判断和决策探索。具体而言，在JuDec中，设计了基于Elo的自我判断机制，通过对两个解决方案进行配对比较，为决策步骤分配Elo分数，以判断它们的价值和效用，并相应地引导决策搜索过程朝向最优解。在ToolBench数据集上的实验结果表明，JuDec相对于基准模型具有优势，在不同任务上的通过率提高了10%以上。它提供了更高质量的解决方案并降低了成本(ChatGPT API调用)。

    While large language models (LLMs) exhibit impressive language understanding and in-context learning abilities, their decision-making ability still heavily relies on the guidance of task-specific expert knowledge when solving real-world tasks. To unleash the potential of LLMs as autonomous decision makers, this paper presents an approach JuDec to endow LLMs with the self-judgment ability, enabling LLMs to achieve autonomous judgment and exploration for decision making. Specifically, in JuDec, Elo-based Self-Judgment Mechanism is designed to assign Elo scores to decision steps to judge their values and utilities via pairwise comparisons between two solutions and then guide the decision-searching process toward the optimal solution accordingly. Experimental results on the ToolBench dataset demonstrate JuDec's superiority over baselines, achieving over 10% improvement in Pass Rate on diverse tasks. It offers higher-quality solutions and reduces costs (ChatGPT API calls), highlighting its 
    
[^52]: 大型语言模型展示出对新颖文学隐喻的解释能力

    Large Language Model Displays Emergent Ability to Interpret Novel Literary Metaphors. (arXiv:2308.01497v1 [cs.CL])

    [http://arxiv.org/abs/2308.01497](http://arxiv.org/abs/2308.01497)

    最近的研究评估了GPT-4，一种大型语言模型，对来自塞尔维亚诗歌的新颖文学隐喻的解释能力。

    

    最近在大型语言模型（LLMs）性能方面的进展引发了关于这种通用人工智能（AI）是否能够在足够的训练下展现出高水平人类能力的争论。尽管LLMs在涉及自然语言处理和推理的各种任务中表现出色，但对它们的能力是否延伸到更具创造力的人类能力存在严重分歧。其中一个核心问题是解释新颖隐喻的能力。由于用于训练LLMs的庞大且非策划的文本语料库，设计测试的一个严重障碍就是需要找到新颖但高质量的隐喻，这些隐喻不太可能出现在训练数据中。在这里，我们评估了GPT-4，一种最先进的大型语言模型，对来自塞尔维亚诗歌并翻译为英语的新颖文学隐喻的自然语言解释能力。

    Recent advances in the performance of large language models (LLMs) have sparked debate over whether, given sufficient training, high-level human abilities emerge in such generic forms of artificial intelligence (AI). Despite the exceptional performance of LLMs on a wide range of tasks involving natural language processing and reasoning, there has been sharp disagreement as to whether their abilities extend to more creative human abilities. A core example is the ability to interpret novel metaphors. Given the enormous and non-curated text corpora used to train LLMs, a serious obstacle to designing tests is the requirement of finding novel yet high-quality metaphors that are unlikely to have been included in the training data. Here we assessed the ability of GPT-4, a state-of-the-art large language model, to provide natural-language interpretations of novel literary metaphors drawn from Serbian poetry and translated into English. Despite exhibiting no signs of having been exposed to thes
    
[^53]: Sumformer: 一种用于语音识别的线性复杂度代替自注意力的方法

    Sumformer: A Linear-Complexity Alternative to Self-Attention for Speech Recognition. (arXiv:2307.07421v1 [cs.CL])

    [http://arxiv.org/abs/2307.07421](http://arxiv.org/abs/2307.07421)

    Sumformer提出了一种线性时间代替自注意力的方法，用总结混合来处理语音识别任务，可以在保持准确性的同时降低训练和推理时间。

    

    现代语音识别系统依赖于自注意力。然而，使用自注意力进行令牌混合的计算复杂度与语音语句的长度呈二次关系，导致推理、训练和内存占用速度变慢。虽然已经开发出了比自注意力更便宜的替代方法，但很难保证达到相同的准确性水平。实际上，经过训练的语音识别器的自注意力权重在时间上呈全局平均化的形式。因此，本文提出了一种用于语音识别的线性时间替代自注意力的方法。它用所有时间步长的向量的平均值来总结整个语句。然后将这个单一的总结与特定时间的信息结合起来。我们将这种方法称为“总结混合”。在最先进的ASR模型中引入总结混合，可以在降低训练和推理时间多达27%的同时，保持或超过先前的语音识别性能水平。

    Modern speech recognition systems rely on self-attention. Unfortunately, token mixing with self-attention takes quadratic time in the length of the speech utterance, slowing down inference as well as training and increasing memory consumption. Cheaper alternatives to self-attention for ASR have been developed, but fail to consistently reach the same level of accuracy. In practice, however, the self-attention weights of trained speech recognizers take the form of a global average over time. This paper, therefore, proposes a linear-time alternative to self-attention for speech recognition. It summarises a whole utterance with the mean over vectors for all time steps. This single summary is then combined with time-specific information. We call this method ``Summary Mixing''. Introducing Summary Mixing in state-of-the-art ASR models makes it feasible to preserve or exceed previous speech recognition performance while lowering the training and inference times by up to 27% and reducing the m
    
[^54]: GKD：自回归序列模型的广义知识蒸馏

    GKD: Generalized Knowledge Distillation for Auto-regressive Sequence Models. (arXiv:2306.13649v1 [cs.LG])

    [http://arxiv.org/abs/2306.13649](http://arxiv.org/abs/2306.13649)

    本文提出了广义知识蒸馏（GKD），通过从学生中采样输出序列来缓解分布不匹配，并在优化替代KL等离散度方面处理模型欠规范，达到了在摘要任务上最先进的性能。

    

    知识蒸馏通常用于压缩神经网络，以减少推理成本和内存占用。然而，当前针对自回归模型（如生成语言模型）的蒸馏方法存在两个关键问题：（1）训练期间输出序列和部署时由学生模型生成的序列之间分布不匹配，（2）模型欠规范，学生模型可能不够表达老师分布。为了解决这些问题，我们提出了广义知识蒸馏（GKD）。GKD通过在训练期间从学生中采样输出序列来缓解分布不匹配。此外，GKD通过优化替代KL等离散度来处理模型欠规范，这些离散度集中于生成可能符合老师分布的学生样本。我们证明，在摘要任务上，GKD优于常用的LLM蒸馏方法，在几个基准数据集上实现了最先进的性能。

    Knowledge distillation is commonly used for compressing neural networks to reduce their inference cost and memory footprint. However, current distillation methods for auto-regressive models, such as generative language models (LMs), suffer from two key issues: (1) distribution mismatch between output sequences during training and the sequences generated by the student during its deployment, and (2) model under-specification, where the student model may not be expressive enough to fit the teacher's distribution. To address these issues, we propose Generalized Knowledge Distillation (GKD). GKD mitigates distribution mismatch by sampling output sequences from the student during training. Furthermore, GKD handles model under-specification by optimizing alternative divergences, such as reverse KL, that focus on generating samples from the student that are likely under the teacher's distribution. We demonstrate that GKD outperforms commonly-used approaches for distilling LLMs on summarizatio
    
[^55]: 关于大型多模态模型中OCR的隐秘之谜

    On the Hidden Mystery of OCR in Large Multimodal Models. (arXiv:2305.07895v1 [cs.CV])

    [http://arxiv.org/abs/2305.07895](http://arxiv.org/abs/2305.07895)

    本研究全面评估了现有大型多模态模型在文本相关的视觉任务中的表现，结果显示这些模型虽然在语义理解方面表现优异，但对单个字符形状的感知有限，对图像的细粒度特征检测能力也不足，不能与传统领域特定方法相匹配，并仍需进一步探索它们在OCR中的表现。

    

    近来，大型模型在自然语言处理和多模态视觉语言学习中扮演着支配性的角色。关于它们在文本相关的视觉任务中有效性的探索仍不够。我们对现有公开可用的多模态模型进行了全面的研究，评估了它们在文本识别、基于文本的视觉问答和关键信息提取方面的表现。我们的研究结果揭示了这些模型的优劣势，它们主要依赖于语义理解来识别单词，并表现出较差的对单个字符形状的感知。它们对文本长度漠不关心，在检测图像的细粒度特征方面具有有限的能力。因此，这些结果表明，即使当前最强大的大型多模态模型也无法与传统文本任务的领域特定方法相匹配，并在更复杂的任务中面临更大的挑战。最重要的是，本研究展示的基线结果揭示了大型多模态模型中OCR的隐秘之谜，仍需要进一步探索。

    Large models have recently played a dominant role in natural language processing and multimodal vision-language learning. It remains less explored about their efficacy in text-related visual tasks. We conducted a comprehensive study of existing publicly available multimodal models, evaluating their performance in text recognition, text-based visual question answering, and key information extraction. Our findings reveal strengths and weaknesses in these models, which primarily rely on semantic understanding for word recognition and exhibit inferior perception of individual character shapes. They also display indifference towards text length and have limited capabilities in detecting fine-grained features in images. Consequently, these results demonstrate that even the current most powerful large multimodal models cannot match domain-specific methods in traditional text tasks and face greater challenges in more complex tasks. Most importantly, the baseline results showcased in this study
    
[^56]: CryCeleb: 基于婴儿哭声的说话人认证数据集

    CryCeleb: A Speaker Verification Dataset Based on Infant Cry Sounds. (arXiv:2305.00969v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2305.00969](http://arxiv.org/abs/2305.00969)

    CryCeleb是一个基于婴儿哭声的说话人认证数据集，包括超过6小时的手动分割哭声，可用于研究婴儿哭声分析。

    

    本文描述了Ubenwa CryCeleb数据集——一个标记的婴儿哭声收集，以及附带的CryCeleb 2023任务——一个基于婴儿哭声的公共说话人验证挑战。我们释放出786名新生儿超过6小时的手动分割哭声，以鼓励婴儿哭声分析方面的研究。

    This paper describes the Ubenwa CryCeleb dataset - a labeled collection of infant cries, and the accompanying CryCeleb 2023 task - a public speaker verification challenge based on infant cry sounds. We release for academic usage more than 6 hours of manually segmented cry sounds from 786 newborns to encourage research in infant cry analysis.
    
[^57]: BiomedCLIP：一种从一千五百万科学图像-文本对进行预训练的多模态生物医学基础模型

    BiomedCLIP: a multimodal biomedical foundation model pretrained from fifteen million scientific image-text pairs. (arXiv:2303.00915v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.00915](http://arxiv.org/abs/2303.00915)

    BiomedCLIP是一个从1500万科学图像-文本对中预训练的多模态生物医学基础模型，其基于大规模的PMC-15M数据集进行训练，该数据集比现有的生物医学多模态数据集大两个数量级，并成功应用于生物医学图像任务的检索、分类和视觉问题回答等方面。

    

    生物医学数据本质上是多模态的，包括物理测量和自然语言叙述。一个通用的生物医学人工智能模型需要同时处理不同的数据模态，包括文本和图像。因此，训练一个有效的通用生物医学模型需要高质量的多模态数据，例如平行的图像-文本对。在这里，我们提供了一个新颖的数据集PMC-15M，比现有的生物医学多模态数据集（如MIMIC-CXR）大两个数量级，并涵盖了各种各样的生物医学图像类型。PMC-15M包含了来自440万科学论文的1500万个生物医学图像-文本对。基于PMC-15M，我们训练了BiomedCLIP，一个多模态基础模型，并进行了领域特定的自适应，以适用于生物医学视觉-语言处理。我们在标准的生物医学图像任务，从检索到分类到视觉问题回答（VQA）方面进行了大量的实验和消融研究。

    Biomedical data is inherently multimodal, comprising physical measurements and natural language narratives. A generalist biomedical AI model needs to simultaneously process different modalities of data, including text and images. Therefore, training an effective generalist biomedical model requires high-quality multimodal data, such as parallel image-text pairs. Here, we present PMC-15M, a novel dataset that is two orders of magnitude larger than existing biomedical multimodal datasets such as MIMIC-CXR, and spans a diverse range of biomedical image types. PMC-15M contains 15 million biomedical image-text pairs collected from 4.4 million scientific articles. Based on PMC-15M, we have pretrained BiomedCLIP, a multimodal foundation model, with domain-specific adaptations tailored to biomedical vision-language processing. We conducted extensive experiments and ablation studies on standard biomedical imaging tasks from retrieval to classification to visual question-answering (VQA). BiomedC
    

