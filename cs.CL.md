# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Injecting knowledge into language generation: a case study in auto-charting after-visit care instructions from medical dialogue.](http://arxiv.org/abs/2306.03652) | 文章介绍了如何在自然语言生成中注入医学知识，提高事实正确性，并通过生成复诊护理指南的案例研究验证了该方法。 |
| [^2] | [A Quantum Probability Driven Framework for Joint Multi-Modal Sarcasm, Sentiment and Emotion Analysis.](http://arxiv.org/abs/2306.03650) | 本篇论文提出了一种使用量子概率驱动的框架，用于联合多模态讽刺、情感和情绪分析，解决了传统概率的兼容性假设和现有方法的不足问题。 |
| [^3] | [Convergence and Diversity in the Control Hierarchy.](http://arxiv.org/abs/2306.03628) | 本文研究了一种语言类的层次结构，提出了三个新的特征，并证明这些形式在更严格的等价概念下是等效的。 |
| [^4] | [CUE: An Uncertainty Interpretation Framework for Text Classifiers Built on Pre-Trained Language Models.](http://arxiv.org/abs/2306.03598) | 本文提出了一个框架CUE，它使用变分自编码器将预训练语言模型（PLMs）编码表示映射到潜在空间中，并通过扰动潜在空间生成不确定性预测，从而确定每个输入标记对总体预测不确定性的影响。同时，我们提出了一种不确定性感知微调算法，旨在利用标记级别的不确定性来提高文本分类器性能。 |
| [^5] | [Language acquisition: do children and language models follow similar learning stages?.](http://arxiv.org/abs/2306.03586) | 研究比较了深度语言模型和儿童的学习轨迹，发现它们都遵循将音韵作为起点逐步习得语法和语义的模式，而且都表现出对于某些语言结构有临界期的学习情况，但人类和机器学习还是存在重要差异。 |
| [^6] | [Take the Hint: Improving Arabic Diacritization with Partially-Diacritized Text.](http://arxiv.org/abs/2306.03557) | 本文提出了一个名为2SDiac的多源模型，可以在输入中使用可选音标来确定所有预测的输出，然后通过引入Guided Learning的训练策略，利用随机掩蔽和给定的输入音标提升标记的正确性。实验表明，该方法在非标记文本上表现良好，并实现了最先进的结果。 |
| [^7] | [SciLit: A Platform for Joint Scientific Literature Discovery, Summarization and Citation Generation.](http://arxiv.org/abs/2306.03535) | SciLit 是一个能够自动检索、摘要和引用相关论文的平台，它可以从数百万篇文献中高效地推荐论文，并提供具有上下文关联的引用句子。 |
| [^8] | ["A Little is Enough": Few-Shot Quality Estimation based Corpus Filtering improves Machine Translation.](http://arxiv.org/abs/2306.03507) | 本研究提出了一种基于质量评估的过滤方法，其从伪并行语料库中提取高质量平行数据，用于机器翻译模型训练，相较于传统方法，具有更好的性能。 |
| [^9] | [Applying Standards to Advance Upstream & Downstream Ethics in Large Language Models.](http://arxiv.org/abs/2306.03503) | 本文探讨如何为AI生成的内容制定安全保障，分析LLMs的内容生成机制，确定了四个关键领域，提出了新的分发和销售LLM生成内容的企业的标准。 |
| [^10] | [Towards Adaptable and Interactive Image Captioning with Data Augmentation and Episodic Memory.](http://arxiv.org/abs/2306.03500) | 本文提出一种基于交互式学习的图像描述生成方法，实现了通过数据增强与情节记忆来微调模型以适应新数据的目的，结果表明情节记忆是一种有效的方法。 |
| [^11] | [SciCap+: A Knowledge Augmented Dataset to Study the Challenges of Scientific Figure Captioning.](http://arxiv.org/abs/2306.03491) | SciCap+ 是一份知识增强的数据集，用于研究科学图例标题自动生成的任务，从提到图片的段落和OCR标记中提取跨模态嵌入的知识，经实验发现这些知识可以显著地提高自动标准图片的字幕生成效果。 |
| [^12] | [Putting Humans in the Image Captioning Loop.](http://arxiv.org/abs/2306.03476) | 本文介绍了一种新的图像字幕系统，该系统利用人类反馈进行训练，并且可以轻松适应用户特定数据。这种系统具有实时更新的功能，可以避免灾难性的遗忘。 |
| [^13] | [Joint Event Extraction via Structural Semantic Matching.](http://arxiv.org/abs/2306.03469) | 本文提出了一种基于语义特征的事件抽取方法，通过结构匹配实现事件类型的检测和论元角色的提取。实验结果表明，该方法在 ACE2005 数据集上表现出较高的性能。 |
| [^14] | [Natural Language Commanding via Program Synthesis.](http://arxiv.org/abs/2306.03460) | 通过使用大型语言模型和办公室领域特定语言，语义解释器实现了自然语言命令并执行Office应用程序中的用户意图。 |
| [^15] | [Phonetically-Grounded Language Generation: The Case of Tongue Twisters.](http://arxiv.org/abs/2306.03457) | 本文介绍了针对绕口令生成的基于音韵学的语言生成任务，提供了TwistList数据集和TwisterMisters基准系统，并验证了预训练模型在没有任务特定数据和显式音韵知识的情况下的良好性能。 |
| [^16] | [Automatic Assessment of Oral Reading Accuracy for Reading Diagnostics.](http://arxiv.org/abs/2306.03444) | 本研究使用ASR技术开发了一种自动评估荷兰语口头阅读准确性的系统，该系统可以与人类评估达到相当的一致性（MCC = 0.63），其语言模型中包括阅读错误可以提高评估性能。 |
| [^17] | [Alzheimer Disease Classification through ASR-based Transcriptions: Exploring the Impact of Punctuation and Pauses.](http://arxiv.org/abs/2306.03443) | 本研究使用ASR模型获取自动的阿尔茨海默病患者的语音转录，探索了加入标点符号和停顿信息对于分类的影响，结果表明停顿编码对于手动和ASR转录在所有探究的方法中有助于AD分类。 |
| [^18] | [Large Language Models of Code Fail at Completing Code with Potential Bugs.](http://arxiv.org/abs/2306.03438) | 本研究探讨了存在漏洞的代码补全问题，设计了两个数据集并发现这些漏洞显著降低了Code-LLMs的生成性能。 |
| [^19] | [On the Role of Attention in Prompt-tuning.](http://arxiv.org/abs/2306.03435) | 本论文研究了Prompt-tuning在注意力架构中的应用，通过探索上下文混合模型，表明softmax-prompt-attention在表达上优于其他模型，同时也证明了该方法可以高效的使用数据学习提示。 |
| [^20] | [Generate-then-Retrieve: Intent-Aware FAQ Retrieval in Product Search.](http://arxiv.org/abs/2306.03411) | 本研究提出了一种意图感知FAQ检索系统，它集成在商品搜索中，可以通过意图分类器和重构模型，提高了检索的精度和效率。 |
| [^21] | [$\textit{WHAT}$, $\textit{WHEN}$, and $\textit{HOW}$ to Ground: Designing User Persona-Aware Conversational Agents for Engaging Dialogue.](http://arxiv.org/abs/2306.03361) | 本文提出了一种针对商业环境的、能够平衡对话流畅性和趋向于理解对话系统的个性化开放领域对话系统方法，通过加权数据集混合、负角色信息增强方法，以及设计个性化对话数据集，解决了 $\textit{WHAT}$、$\textit{WHEN}$和$\textit{HOW}$ 等问题，同时提高了对话系统响应的可控性和解释性。 |
| [^22] | [BatchSampler: Sampling Mini-Batches for Contrastive Learning in Vision, Language, and Graphs.](http://arxiv.org/abs/2306.03355) | 本文提出了一个新的对比学习方法BatchSampler，通过从输入数据中采样难以区分的实例的小批量，并利用重启随机游走来形成小批量，以提高性能。 |
| [^23] | [Click: Controllable Text Generation with Sequence Likelihood Contrastive Learning.](http://arxiv.org/abs/2306.03350) | Click是一种无需修改模型架构的可控文本生成方法，它采用序列似然对比损失来根本减少不良属性的生成概率，同时采用一种新颖的样本构造策略来构建对比样本。在相关任务中，Click表现出了优异的性能，且样本构造策略相较于其他方法更加优秀。 |
| [^24] | [Inference-Time Intervention: Eliciting Truthful Answers from a Language Model.](http://arxiv.org/abs/2306.03341) | 本研究提出推理时间干预（ITI）技术，通过在推理过程中跨越有限数量的注意力头，显着提高大型语言模型的真实性。在TruthfulQA基准上，ITI使LLaMA模型的真实性从32.5%提高到65.1%。ITI是一种最小程度的干扰，计算廉价，且数据效率高。 |
| [^25] | [CoSiNES: Contrastive Siamese Network for Entity Standardization.](http://arxiv.org/abs/2306.03316) | CoSiNES 是一个通用的、适应性强的实体标准化方法，通过对比双子网络和预训练语言模型的结合，可以有效地捕捉实体的语法和语义特征。在技术领域的数据集上，相比于基线算法，CoSiNES 的精度更高、运行时间更短。 |
| [^26] | [Few Shot Rationale Generation using Self-Training with Dual Teachers.](http://arxiv.org/abs/2306.03315) | 本文提出了一种双教师学习框架，利用标记和未标记的数据，通过自我训练来改进少样本模型，实现同时生成任务标签和原理的效果；此外还提出了一种新的损失函数Masked Label Regularization，可以明确地强制解释明确地条件化。 |
| [^27] | [A Scalable and Adaptive System to Infer the Industry Sectors of Companies: Prompt + Model Tuning of Generative Language Models.](http://arxiv.org/abs/2306.03313) | 本文介绍了一个板块推断系统，可以帮助主题型私募股权基金的投资专业人士推断公司所在的行业板块。该系统建立在中型生成式语言模型上，通过Prompt+模型微调程序进行微调，并具有良好的可扩展性和适应性。 |
| [^28] | [Stack Over-Flowing with Results: The Case for Domain-Specific Pre-Training Over One-Size-Fits-All Models.](http://arxiv.org/abs/2306.03268) | 本文主张在大型预训练模型的潮流中，还应推广面向特定领域的预训练模型，并以 StackOverflow 为例展示了其优越性。 |
| [^29] | [shs-nlp at RadSum23: Domain-Adaptive Pre-training of Instruction-tuned LLMs for Radiology Report Impression Generation.](http://arxiv.org/abs/2306.03264) | 本文提出了一个基于领域自适应预训练的指导调整语言模型的系统，用于增强其医学知识和在特定医学任务上的性能，特别是在 IMPRESSIONS 生成任务中表现出色，比许多预训练和微调自适应方法表现更好，并且在 BioNLP 2023 研讨会的任务1B：放射学报告摘要中排名第1。 |
| [^30] | [Understanding the Effectiveness of Early Weight Averaging for Training Large Language Models.](http://arxiv.org/abs/2306.03241) | 本文研究了使用早期权重平均化方法来提高大型语言模型质量的有效性，证明该方法可以加速收敛且测试和零样本泛化效果显著，同时有效缓解了训练中的损失波动问题。 |
| [^31] | [NLU on Data Diets: Dynamic Data Subset Selection for NLP Classification Tasks.](http://arxiv.org/abs/2306.03208) | 本研究提出一种动态数据修剪的方法，通过定期对不重要的示例进行打分和抛弃，减少了微调大型语言模型的成本，并且在GLUE基准测试和四个联合NLU数据集上表现更好。 |
| [^32] | [A Static Evaluation of Code Completion by Large Language Models.](http://arxiv.org/abs/2306.03203) | 本文提出了一种基于抽象语法树的静态评价框架来评估大型语言模型的Python代码补全质量，相比于基于执行的评估方法更加高效，适用于实际代码。研究揭示了未定义名称是一个常见错误。 |
| [^33] | [Easy-to-Read in Germany: A Survey on its Current State and Available Resources.](http://arxiv.org/abs/2306.03189) | 本文综述了德语易读语言（LS）的最新自然语言处理（NLP）工具和资源，并探讨了德国LS和Einfache Sprache（ES）现状。 |
| [^34] | [Composition and Deformance: Measuring Imageability with a Text-to-Image Model.](http://arxiv.org/abs/2306.03168) | 本文使用文本到图像模型衡量了英文单个单词和相关文本的形象化能力，并通过变形检测模型检测组合变化引起的能力变化，结果显示所提出的计算措施能够更加一致地响应组合变化。 |
| [^35] | [Unsupervised Dense Retrieval with Relevance-Aware Contrastive Pre-Training.](http://arxiv.org/abs/2306.03166) | 本文提出了相关性感知对比学习方法，该方法可以自适应地加权不同对偶的对比损失，以改善无监督检索模型性能，进一步的探索表明它可以击败BM25，作为很好的少量样本学习器。 |
| [^36] | [Sampling and Ranking for Digital Ink Generation on a tight computational budget.](http://arxiv.org/abs/2306.03103) | 该论文研究了如何在资源受限的环境下，通过使用多种抽样和排序技术，最大化数字墨水生成模型的输出质量，这项研究在数字墨水领域中首次进行，其结果证明了这些技术能显着提高合成墨水的识别性。 |
| [^37] | [Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding.](http://arxiv.org/abs/2306.02858) | Video-LLaMA是一个多模态框架，利用已有的预训练模型，解决了视频中的视觉和听觉的理解问题，其中Video Q-former和Audio Q-former用于处理视频中的视觉与时间变化和音频信号的问题。 |
| [^38] | [A Technical Report for Polyglot-Ko: Open-Source Large-Scale Korean Language Models.](http://arxiv.org/abs/2306.02254) | Polyglot-Ko是一种韩语语言模型，提供了比mBERT和XGLM更好的性能，有助于改善非英语语言的表现。 |
| [^39] | [MultiLegalPile: A 689GB Multilingual Legal Corpus.](http://arxiv.org/abs/2306.02069) | MultiLegalPile是一个689GB的多语言法律语料库，包含来自17个司法管辖区的24种语言的不同法律数据源，允许在公平使用下针对预训练NLP模型。该语料库为多语言模型的预训练提供了新的最佳表现，并在LexGLUE上表现最佳。 |
| [^40] | [A Comprehensive Survey on Deep Learning for Relation Extraction: Recent Advances and New Frontiers.](http://arxiv.org/abs/2306.02051) | 本文综述了深度学习在关系抽取领域的应用进展，提出了新的分类法，讨论了面临的挑战和应对的技术，并展望了未来的发展方向。 |
| [^41] | [Learning Multi-step Reasoning from Arithmetic Task.](http://arxiv.org/abs/2306.01707) | 本文研究如何将相对较小的语言模型注入具有多步推理能力的合成算术任务（MsAT），从而提高LM在数学问题解决上的表现。 |
| [^42] | [Enhancing Programming eTextbooks with ChatGPT Generated Counterfactual-Thinking-Inspired Questions.](http://arxiv.org/abs/2306.00551) | 利用ChatGPT生成反事实思考启发问题，提高编程电子教材的导航性和互动性，激发学生的批判性思维。 |
| [^43] | [Make Your Pre-trained Model Reversible: From Parameter to Memory Efficient Fine-Tuning.](http://arxiv.org/abs/2306.00477) | 本研究尝试实现在预训练语言模型中运用可逆模型实现高效的微调，并发现在初始化微调时保留PLM的起点非常重要。 |
| [^44] | [CapText: Large Language Model-based Caption Generation From Image Context and Description.](http://arxiv.org/abs/2306.00301) | 研究提出了一种基于大型语言模型的图像字幕生成方法，从文本描述和上下文中生成字幕，而不直接处理图像。在CIDEr指标上，优于当前最先进的图像文本对齐模型。 |
| [^45] | [MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training.](http://arxiv.org/abs/2306.00107) | 提出了一个带有大规模自监督训练的音乐理解模型MERT，利用了教师模型并采用了一种优于传统的语音和音频方法的组合方式。 |
| [^46] | [Do GPTs Produce Less Literal Translations?.](http://arxiv.org/abs/2305.16806) | 本研究比较了GPT和NMT生成翻译的文字积极度差异，发现GPT翻译更不准确，但在MT质量评估指标上表现出相似或更好的分数。 |
| [^47] | [Self-supervised Predictive Coding Models Encode Speaker and Phonetic Information in Orthogonal Subspaces.](http://arxiv.org/abs/2305.12464) | 这篇论文提出了一种自监督预测编码模型，可以把说话者和语音信息编码在正交子空间，进而提出一种新的无需转录的说话者归一化方法，有效消除了说话者信息，并在音位辨别任务中优于之前的基线。 |
| [^48] | [Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models.](http://arxiv.org/abs/2305.10276) | 本文提出了自然语言规划（NLP）的基准，旨在研究LLMs在需要理解并在文本中相应进行操作的复杂规划任务中的表现。同时提出了一种新方法CoS，使用简化的符号空间表示法来表示复杂的环境。 |
| [^49] | [Explanation-based Finetuning Makes Models More Robust to Spurious Cues.](http://arxiv.org/abs/2305.04990) | 本文提出一种新型方法——解释性微调，通过让模型在给出答案的同时生成支持该答案的自由文本解释，来减轻LLMs依赖虚假关联，使得模型对虚假提示更加强韧，并具有广泛适用性。 |
| [^50] | [SI-LSTM: Speaker Hybrid Long-short Term Memory and Cross Modal Attention for Emotion Recognition in Conversation.](http://arxiv.org/abs/2305.03506) | SI-LSTM是一种用于对话情感识别的循环结构，可以追踪不同说话人的情感状态，从而增强对话情感学习。 |
| [^51] | [The Politics of Language Choice: How the Russian-Ukrainian War Influences Ukrainians' Language Use on Twitter.](http://arxiv.org/abs/2305.02770) | 本文研究了俄乌战争期间乌克兰人在 Twitter 上的语言使用，发现在战争爆发前已经出现从俄语向乌克兰语转变的趋势，而战争爆发后这种趋势加速了，并且许多使用俄语的用户在战争期间转变成使用乌克兰语。 |
| [^52] | [CCpdf: Building a High Quality Corpus for Visually Rich Documents from Web Crawl Data.](http://arxiv.org/abs/2304.14953) | 本文提出了一个流程，通过使用Common Crawl，从互联网上收集PDF文件，构建一个大规模、多样化、多语言的语料库。我们分享了一个CCpdf语料库，为研究人员提供了进行视觉丰富文档研究的机会。 |
| [^53] | [A logical word embedding for learning grammar.](http://arxiv.org/abs/2304.14590) | 这篇论文介绍了一种逻辑语法嵌入模型(LGE)，它可以从文本语料库中无监督进行推理，产生简明易懂的输出，能够透明地生成新句子，并且可以从仅有一百句话的语料中进行学习。 |
| [^54] | [NAIST-SIC-Aligned: Automatically-Aligned English-Japanese Simultaneous Interpretation Corpus.](http://arxiv.org/abs/2304.11766) | 本论文提出了NAIST-SIC-Aligned，这是一个自动对齐的英日平行同声传译数据集。该论文使用了一个两阶段的对齐方法，经过定量或定性验证的每个步骤，以确保语料库的质量。这是第一个开源的大规模平行SI数据集。 |
| [^55] | [Multi-aspect Repetition Suppression and Content Moderation of Large Language Models.](http://arxiv.org/abs/2304.10611) | 本文介绍了一种使用标记和序列级别的不可能性损失，以及在培训期间的重复惩罚、推理和后处理等多层面方法来抑制大型语言模型中的重复，并避免生成攻击性内容的能力。 |
| [^56] | [G2T: A simple but versatile framework for topic modeling based on pretrained language model and community detection.](http://arxiv.org/abs/2304.06653) | G2T是一种基于预训练语言模型和社区检测的主题建模框架，自动评估表明，G2T在多个数据集上均与当前最先进的方法相比表现更好。 |
| [^57] | [PDF-VQA: A New Dataset for Real-World VQA on PDF Documents.](http://arxiv.org/abs/2304.06447) | 该研究提出了一个新的文档VQA数据集PDF-VQA，以多个页面的完整文档作为研究对象，通过机器学习模型识别与处理文档元素、结构和内容等方面，为解决真实世界中的文档理解问题提供新的资源。 |
| [^58] | [oBERTa: Improving Sparse Transfer Learning via improved initialization, distillation, and pruning regimes.](http://arxiv.org/abs/2303.17612) | oBERTa是一组易于使用的语言模型，通过改进初始化、蒸馏、剪枝等技术，可以在不需要模型压缩方面的专业知识的情况下提高稀疏迁移学习的效率和准确性。 |
| [^59] | [Aligning Language Models with Preferences through f-divergence Minimization.](http://arxiv.org/abs/2302.08215) | 本文提出一种新的方法f-DPG，用于对齐语言模型和偏好，该方法适用于评估任何目标分布，统一了现有的各种框架和逼近方法。 |
| [^60] | [DP-BART for Privatized Text Rewriting under Local Differential Privacy.](http://arxiv.org/abs/2302.07636) | 本文提出了一个新的系统DP-BART，采用局部差分隐私的方法进行文本重写，优于现有的LDP系统，大大减少了需要DP保证的噪音量，实验表明在下游文本分类任务中有效。 |
| [^61] | [Large Language Models Can Be Easily Distracted by Irrelevant Context.](http://arxiv.org/abs/2302.00093) | 本文研究了大型语言模型对无关上下文的干扰性。他们使用一个带有无关信息的算术推理数据集GSM-IC来衡量这种可干扰性。研究发现当包含无关信息时，模型性能会急剧下降，但使用自我一致性进行解码并添加一个指令可以缓解这一缺陷。 |
| [^62] | [AutoPEFT: Automatic Configuration Search for Parameter-Efficient Fine-Tuning.](http://arxiv.org/abs/2301.12132) | AutoPEFT是一个自动化的PEFT（参数高效微调）配置搜索方法，它能够自动地找到最佳的PEFT模块和体系结构，以优化任务的性能和参数效率。在典型的NLP任务中，AutoPEFT表现出比手动设计更好的性能。 |
| [^63] | [How poor is the stimulus? Evaluating hierarchical generalization in neural networks trained on child-directed speech.](http://arxiv.org/abs/2301.11462) | 该研究探讨了在类似于儿童语言输入数据的语料库上训练的两种神经网络的层级概括能力。结果表明这些模型概括的能力与正确的层级规则不符，从结论可以看出，仅从语料库中进行类人概括需要比现有模型更强的偏见。 |
| [^64] | [A Watermark for Large Language Models.](http://arxiv.org/abs/2301.10226) | 本文提出了一种在大型语言模型中实现水印技术的方法，该技术可以在不降低文本质量的前提下嵌入信号，且可以使用高效的开源算法进行检测，并且该技术十分鲁棒和安全。 |
| [^65] | [NarrowBERT: Accelerating Masked Language Model Pretraining and Inference.](http://arxiv.org/abs/2301.04761) | NarrowBERT是一种改进的Transformer编码器，通过稀疏化模型并仅对掩码令牌进行操作，在掩码语言模型预训练中提高了$2\times$以上的吞吐量，并在推理时将吞吐量提高了多达$3.5\times$。NarrowBERT在几种自然语言处理任务中的性能与标准BERT相当。 |
| [^66] | [DISCO: Distilling Phrasal Counterfactuals with Large Language Models.](http://arxiv.org/abs/2212.10534) | 本文提出了一种名为DISCO的自动化方法，可利用大型语言模型生成高质量反事实数据，用于训练模型，以实现自然语言推理等任务的因果推理，相比于传统数据训练方法，效果更好且可扩展和高效。 |
| [^67] | [Benchmarking Spatial Relationships in Text-to-Image Generation.](http://arxiv.org/abs/2212.10015) | 本文研究了文本到图像生成中模型生成正确空间关系的能力，并提出了一个评估指标VISOR以衡量生成图像的准确性。实验发现当前T2I模型尽管可以生成高度逼真的图像，但其空间上准确的图像能力仍然不足，特别是在空间谓词和场景关系理解方面。 |
| [^68] | [DuNST: Dual Noisy Self Training for Semi-Supervised Controllable Text Generation.](http://arxiv.org/abs/2212.08724) | DuNST是一种双重噪声自训练方法，用于半监督可控文本生成。该方法通过扰动生成的伪文本，将伪文本标记和无标签的伪标签结合使用，并且可以缓解先前学习到的空间的限制性泛化边界。 |
| [^69] | [Revisiting the Gold Standard: Grounding Summarization Evaluation with Robust Human Evaluation.](http://arxiv.org/abs/2212.07981) | 该论文提出了一种新的摘要显要性协议，ACUs，解决了现有评估协议低一致性的问题。作者建立了一个超大规模评估数据集RoSE并进行了人类评估和自动评估，为摘要评估的相关研究提供了新的思路。 |
| [^70] | [Can In-context Learners Learn a Reasoning Concept from Demonstrations?.](http://arxiv.org/abs/2212.01692) | 本文介绍了一种概念性少样本学习方法，以帮助在场学习者学习新技能。通过选择与预测示例共享可能信息的演示，这个方法可以在模型记忆独立的情况下区分模型的在场学习能力。 |
| [^71] | [Topological Data Analysis for Speech Processing.](http://arxiv.org/abs/2211.17223) | 本论文将拓扑数据分析应用于语音分类问题和预训练语音模型的内省，并介绍了一系列基于Transformer注意力图和嵌入的拓扑和代数特征。在这些特征基础上构建的简单线性分类器胜过精调分类器头部，并实现了在许多数据集上的最新最优性能。拓扑特征能够揭示语音Transformer头的功能角色，这表明TDA是一种有前途的语音分析方法。 |
| [^72] | [SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models.](http://arxiv.org/abs/2211.10438) | SmoothQuant是一种训练无需的通用后训练量化（PTQ）解决方案，可以在保持精度的情况下实现大型语言模型的8位权重、8位激活（W8A8）量化。SmoothQuant通过数学等效转换将量化难度从激活移到权重，使得所有矩阵乘法的权重和激活的INT8量化成为可能，具有最高1.56倍加速和2倍内存减少的效果。 |
| [^73] | [A Universal Discriminator for Zero-Shot Generalization.](http://arxiv.org/abs/2211.08099) | 该论文提出了一种用于零样本泛化的通用鉴别器，通过在NLP任务中使用单一的鉴别器，可实现比生成方法更好的表现，取得了在T0基准测试中最先进的零样本结果，同时在各种NLP任务上实现了新的最先进结果。 |
| [^74] | [Self-Adaptive Named Entity Recognition by Retrieving Unstructured Knowledge.](http://arxiv.org/abs/2210.07523) | 本文提出了一种自适应命名实体识别方法，通过检索非结构化知识以修正预测，实验结果表明该方法在F1度量上优于强基线模型2.35个百分点。 |
| [^75] | [Zero-Shot Prompting for Implicit Intent Prediction and Recommendation with Commonsense Reasoning.](http://arxiv.org/abs/2210.05901) | 本文提出了一种多领域对话系统框架，基于常识推理能够实现隐式意图的预测和通过预训练语言模型进行零-shot提示以触发相应的任务导向机器人，提高了实用性和效率。 |
| [^76] | [A Kernel-Based View of Language Model Fine-Tuning.](http://arxiv.org/abs/2210.05643) | 本文研究神经切线核 (NTK) 在描述预训练语言模型微调过程中的适用性。实验证明在14个NLP任务中使用掩码词预测问题作为下游任务，可以取得好的效果。 |
| [^77] | [Controllable Dialogue Simulation with In-Context Learning.](http://arxiv.org/abs/2210.04185) | 本文提出了一种基于上下文学习的对话模拟方法，通过少量带注释的示例自动创建大量对话数据，比众包更加成本效益和节省时间，实验证明在低资源环境下使用模拟对话训练模型可以获得更好的性能。 |
| [^78] | [Guess the Instruction! Flipped Learning Makes Language Models Stronger Zero-Shot Learners.](http://arxiv.org/abs/2210.02969) | 本文提出了一种名为“翻转学习”的元训练替代方法，通过训练语言模型生成任务指令，可以在零样本任务中取得更好的表现，特别是在包含未见标签的挑战性任务中。Flipped在14个BIG-bench基准测试任务中平均比3-shot GPT-3高出8.4%和9.7%的分数。 |
| [^79] | [Less is More: Task-aware Layer-wise Distillation for Language Model Compression.](http://arxiv.org/abs/2210.01351) | 本文提出了一种新的面向任务的分层蒸馏方法（TED），通过设计任务感知的滤波器来对齐学生和教师的隐藏表示，选择有用的知识，减少知识差距，使学生模型更好地适应目标任务，实现了比最先进方法更少的参数下可比或更好的性能。 |
| [^80] | [Structured Knowledge Grounding for Question Answering.](http://arxiv.org/abs/2209.08284) | 本文提出了一种基于语言模型的知识基础问答方法，通过动态跳跃检索相关上下文，并使用深度融合机制，实现具有灵活性、覆盖面和结构推理，优于现有的知识基础构建方法，并达到与依赖于外部信息资源的最先进系统相竞争的性能。 |
| [^81] | [GigaST: A 10,000-hour Pseudo Speech Translation Corpus.](http://arxiv.org/abs/2204.03939) | GigaST是一份大规模的伪语音翻译(ST)语料库，使用该语料库所训练出的ST模型在MuST-C英语-德语基准测试集上取得了新的最先进结果。 |
| [^82] | [Detecting Harmful Content On Online Platforms: What Platforms Need Vs. Where Research Efforts Go.](http://arxiv.org/abs/2103.00153) | 在线平台上的有害内容种类和平台需求与自动检测有害内容的研究方向存在差异，需要更深入的研究和更好的平台管理，以减少社会危害和创建更完整的用户环境。 |

# 详细

[^1]: 将知识注入语言生成：医学对话中自动生成复诊护理指南的案例研究

    Injecting knowledge into language generation: a case study in auto-charting after-visit care instructions from medical dialogue. (arXiv:2306.03652v1 [cs.CL])

    [http://arxiv.org/abs/2306.03652](http://arxiv.org/abs/2306.03652)

    文章介绍了如何在自然语言生成中注入医学知识，提高事实正确性，并通过生成复诊护理指南的案例研究验证了该方法。

    

    在高风险领域如医疗保健中，事实正确性经常是自然语言生成实际应用的局限性。保持事实正确性的基本要求是处理罕见标记的能力。本文重点介绍了源序列和参考序列中出现的罕见标记，如果在生成过程中漏掉，则会降低输出文本的事实正确性。对于知识丰富的高风险领域，我们展示如何利用知识来识别出重要的出现在源和参考中的罕见标记，并提高它们的条件概率，从而提高生成结果的事实正确性。

    Factual correctness is often the limiting factor in practical applications of natural language generation in high-stakes domains such as healthcare. An essential requirement for maintaining factuality is the ability to deal with rare tokens. This paper focuses on rare tokens that appear in both the source and the reference sequences, and which, when missed during generation, decrease the factual correctness of the output text. For high-stake domains that are also knowledge-rich, we show how to use knowledge to (a) identify which rare tokens that appear in both source and reference are important and (b) uplift their conditional probability. We introduce the ``utilization rate'' that encodes knowledge and serves as a regularizer by maximizing the marginal probability of selected tokens. We present a study in a knowledge-rich domain of healthcare, where we tackle the problem of generating after-visit care instructions based on patient-doctor dialogues. We verify that, in our dataset, spec
    
[^2]: 量子概率驱动下的联合多模态讽刺、情感和情绪分析框架

    A Quantum Probability Driven Framework for Joint Multi-Modal Sarcasm, Sentiment and Emotion Analysis. (arXiv:2306.03650v1 [cs.CL])

    [http://arxiv.org/abs/2306.03650](http://arxiv.org/abs/2306.03650)

    本篇论文提出了一种使用量子概率驱动的框架，用于联合多模态讽刺、情感和情绪分析，解决了传统概率的兼容性假设和现有方法的不足问题。

    

    讽刺、情感和情绪是人类对外部事件产生的三种典型自发情感反应，它们与彼此耦合。这些事件可以用多种表达方式表达，例如多模态对话。联合分析人类的多模态讽刺、情感和情绪是一个重要而具有挑战性的主题，因为它是一个涉及跨模态交互和跨情感相关性的复杂认知过程。从概率论的角度来看，跨情感相关性意味着对讽刺、情感和情绪的判断是不兼容的。然而，这种现象由于经典概率理论的兼容性假设和现有方法的不足而无法被充分建模。考虑到量子概率在建模人类认知方面的最近成功，尤其是上下文不相容决策，我们提出了基于量子概率的框架来解决这个问题。

    Sarcasm, sentiment, and emotion are three typical kinds of spontaneous affective responses of humans to external events and they are tightly intertwined with each other. Such events may be expressed in multiple modalities (e.g., linguistic, visual and acoustic), e.g., multi-modal conversations. Joint analysis of humans' multi-modal sarcasm, sentiment, and emotion is an important yet challenging topic, as it is a complex cognitive process involving both cross-modality interaction and cross-affection correlation. From the probability theory perspective, cross-affection correlation also means that the judgments on sarcasm, sentiment, and emotion are incompatible. However, this exposed phenomenon cannot be sufficiently modelled by classical probability theory due to its assumption of compatibility. Neither do the existing approaches take it into consideration. In view of the recent success of quantum probability (QP) in modeling human cognition, particularly contextual incompatible decisio
    
[^3]: 控制层次结构中的收敛与多样性

    Convergence and Diversity in the Control Hierarchy. (arXiv:2306.03628v1 [cs.FL])

    [http://arxiv.org/abs/2306.03628](http://arxiv.org/abs/2306.03628)

    本文研究了一种语言类的层次结构，提出了三个新的特征，并证明这些形式在更严格的等价概念下是等效的。

    

    Weir定义了一种语言类的层次结构，其中第二个成员（$ \mathcal{L} _2 $）是由树相邻语法（TAG），线性索引语法（LIG），组合范畴语法和头语法生成的。该层次结构使用控制机制获得，并使用由另一个CFG控制的CFG的上下文无关文法（CFG）获得$ \mathcal{L} _2 $。我们将Weir关于可控CFG的定义调整为可控下推自动机（PDAs）的定义。这产生了三个新的$\mathcal{L} _2 $的特征，作为由控制PDAs的PDAs，控制CFGs的PDAs和CFGs的控制PDAs生成的语言类。我们证明了这些四个形式不仅是弱等效的，而且在我们称之为d-弱等效的更严格意义下是等效的。此外，使用更严格的等价概念d-强等价，我们明确了控制CFG的CFG就是TAG，控制PDA的PDA就是embedd。

    Weir has defined a hierarchy of language classes whose second member ($\mathcal{L}_2$) is generated by tree-adjoining grammars (TAG), linear indexed grammars (LIG), combinatory categorial grammars, and head grammars. The hierarchy is obtained using the mechanism of control, and $\mathcal{L}_2$ is obtained using a context-free grammar (CFG) whose derivations are controlled by another CFG. We adapt Weir's definition of a controllable CFG to give a definition of controllable pushdown automata (PDAs). This yields three new characterizations of $\mathcal{L}_2$ as the class of languages generated by PDAs controlling PDAs, PDAs controlling CFGs, and CFGs controlling PDAs. We show that these four formalisms are not only weakly equivalent but equivalent in a stricter sense that we call d-weak equivalence. Furthermore, using an even stricter notion of equivalence called d-strong equivalence, we make precise the intuition that a CFG controlling a CFG is a TAG, a PDA controlling a PDA is an embedd
    
[^4]: CUE: 基于预训练语言模型的文本分类器不确定性解释框架

    CUE: An Uncertainty Interpretation Framework for Text Classifiers Built on Pre-Trained Language Models. (arXiv:2306.03598v1 [cs.CL])

    [http://arxiv.org/abs/2306.03598](http://arxiv.org/abs/2306.03598)

    本文提出了一个框架CUE，它使用变分自编码器将预训练语言模型（PLMs）编码表示映射到潜在空间中，并通过扰动潜在空间生成不确定性预测，从而确定每个输入标记对总体预测不确定性的影响。同时，我们提出了一种不确定性感知微调算法，旨在利用标记级别的不确定性来提高文本分类器性能。

    

    基于预训练语言模型（PLMs）构建的文本分类器在情感分析、自然语言推理和问答等各种任务中取得了显著的进展。然而，这些分类器产生不确定预测时，对于它们在实际应用中的可靠性构成了挑战。为了理解PLMs的学习特点，已经进行了大量的工作，但是很少有研究探究影响PLM模型预测不确定性的因素。本文提出了一种新的框架——CUE，旨在解释PLM模型预测中的不确定性。具体来说，我们首先通过变分自编码器将PLM编码表示映射到一个潜在空间中。然后通过扰动潜在空间生成文本表示，从而导致预测不确定性的波动。通过比较扰动和原始表示之间的预测不确定性差异，可以确定每个输入标记对总体预测不确定性的影响。此外，我们提出了一种新的不确定性感知微调算法，在训练过程中利用已识别的标记级不确定性从而进一步改善文本分类性能。我们的实验结果表明，CUE可以有效地揭示不确定性，并为理解基于PLM的文本分类器的行为提供有价值的见解。此外，我们的不确定性感知微调算法在几个基准数据集上显著优于传统的微调方法。

    Text classifiers built on Pre-trained Language Models (PLMs) have achieved remarkable progress in various tasks including sentiment analysis, natural language inference, and question-answering. However, the occurrence of uncertain predictions by these classifiers poses a challenge to their reliability when deployed in practical applications. Much effort has been devoted to designing various probes in order to understand what PLMs capture. But few studies have delved into factors influencing PLM-based classifiers' predictive uncertainty. In this paper, we propose a novel framework, called CUE, which aims to interpret uncertainties inherent in the predictions of PLM-based models. In particular, we first map PLM-encoded representations to a latent space via a variational auto-encoder. We then generate text representations by perturbing the latent space which causes fluctuation in predictive uncertainty. By comparing the difference in predictive uncertainty between the perturbed and the or
    
[^5]: 语言习得：儿童和语言模型是否遵循相似的学习阶段？

    Language acquisition: do children and language models follow similar learning stages?. (arXiv:2306.03586v1 [cs.CL])

    [http://arxiv.org/abs/2306.03586](http://arxiv.org/abs/2306.03586)

    研究比较了深度语言模型和儿童的学习轨迹，发现它们都遵循将音韵作为起点逐步习得语法和语义的模式，而且都表现出对于某些语言结构有临界期的学习情况，但人类和机器学习还是存在重要差异。

    

    在语言习得过程中，儿童会按照典型的学习阶段顺序学习语言，首先学习发音分类，然后发展词汇，最终掌握越来越复杂的句法结构。然而，导致这种学习轨迹的计算原则仍然大部分未知。为了研究这一问题，我们比较了深度语言模型的学习轨迹和儿童的学习轨迹。具体而言，我们测试了GPT-2在训练过程中是否展现出与18个月至6岁儿童相似的语言习得阶段。通过从BLiMP、Zorro和BIG-Bench数据集中获取96个评估数据集，我们训练48个GPT-2模型，并在每个训练步骤中评估它们的句法和语义能力。然后将这些评估与54个儿童的语言产生过程行为进行比较。我们的分析揭示出了三个主要发现。首先，与儿童一样，语言模型倾向于首先习得音韵信息，然后逐渐学习使用正确的语法和语义生成单词和句子。其次，语言模型表现出对某些语言结构的学习有临界期，类似于儿童。最后，虽然总体上的学习轨迹相似，但也存在儿童和模型之间的重要差异，这可能指向了人类和机器学习之间的根本差异。

    During language acquisition, children follow a typical sequence of learning stages, whereby they first learn to categorize phonemes before they develop their lexicon and eventually master increasingly complex syntactic structures. However, the computational principles that lead to this learning trajectory remain largely unknown. To investigate this, we here compare the learning trajectories of deep language models to those of children. Specifically, we test whether, during its training, GPT-2 exhibits stages of language acquisition comparable to those observed in children aged between 18 months and 6 years. For this, we train 48 GPT-2 models from scratch and evaluate their syntactic and semantic abilities at each training step, using 96 probes curated from the BLiMP, Zorro and BIG-Bench benchmarks. We then compare these evaluations with the behavior of 54 children during language production. Our analyses reveal three main findings. First, similarly to children, the language models tend
    
[^6]: 利用部分标注的文本提升阿拉伯语音标注的准确性

    Take the Hint: Improving Arabic Diacritization with Partially-Diacritized Text. (arXiv:2306.03557v1 [cs.CL])

    [http://arxiv.org/abs/2306.03557](http://arxiv.org/abs/2306.03557)

    本文提出了一个名为2SDiac的多源模型，可以在输入中使用可选音标来确定所有预测的输出，然后通过引入Guided Learning的训练策略，利用随机掩蔽和给定的输入音标提升标记的正确性。实验表明，该方法在非标记文本上表现良好，并实现了最先进的结果。

    

    自动化的阿拉伯语音标注在很多应用场景中都非常有用，比如对于语言学习者来说，标注可以提供阅读支持，而对于语音合成这样的下游任务，标注准确性对于发音预测也非常重要。之前的研究大多数专注于处理没有音标的原始文本的模型，但是通过给人类提供选定的或部分标注的敏感词汇，可以使得生产系统的准确性更高。本文提出了一个名为2SDiac的多源模型，可以有效地支持输入中的可选音标以确定所有预测的输出。此外，本文还引入了一种称为Guided Learning的训练策略，可以利用给定的输入音标和不同等级的随机掩蔽来提升标注的正确性。我们展示了测试期间提供的标注能够影响更多的输出位置，实验结果还表明，我们的方法可以在非标记文本上表现出优异的效果，并且可以在减少60%的参数数目的情况下实现最先进的结果。

    Automatic Arabic diacritization is useful in many applications, ranging from reading support for language learners to accurate pronunciation predictor for downstream tasks like speech synthesis. While most of the previous works focused on models that operate on raw non-diacritized text, production systems can gain accuracy by first letting humans partly annotate ambiguous words. In this paper, we propose 2SDiac, a multi-source model that can effectively support optional diacritics in input to inform all predictions. We also introduce Guided Learning, a training scheme to leverage given diacritics in input with different levels of random masking. We show that the provided hints during test affect more output positions than those annotated. Moreover, experiments on two common benchmarks show that our approach i) greatly outperforms the baseline also when evaluated on non-diacritized text; and ii) achieves state-of-the-art results while reducing the parameter count by over 60%.
    
[^7]: SciLit: 一种联合科学文献发现、摘要和引文生成平台

    SciLit: A Platform for Joint Scientific Literature Discovery, Summarization and Citation Generation. (arXiv:2306.03535v1 [cs.CL])

    [http://arxiv.org/abs/2306.03535](http://arxiv.org/abs/2306.03535)

    SciLit 是一个能够自动检索、摘要和引用相关论文的平台，它可以从数百万篇文献中高效地推荐论文，并提供具有上下文关联的引用句子。

    

    科学写作涉及检索、总结和引用相关论文，这在大规模和快速发展的领域中可能是耗时的过程。通过将这些过程相互操作，自然语言处理 (NLP) 提供了创建端到端辅助写作工具的机会。我们提出了SciLit，这是一个流水线，可以自动推荐相关论文，提取亮点，并建议一个引用句子作为论文的引用，考虑到用户提供的上下文和关键词。SciLit可以高效地从数百万篇论文的大型数据库中推荐论文，使用两阶段的预取和重新排名文献搜索系统，灵活处理论文数据库的添加和删除。我们提供了一个方便的用户界面，显示推荐的论文作为摘要，并提供与提供的上下文对齐并提到所选关键词的摘要引文。

    Scientific writing involves retrieving, summarizing, and citing relevant papers, which can be time-consuming processes in large and rapidly evolving fields. By making these processes inter-operable, natural language processing (NLP) provides opportunities for creating end-to-end assistive writing tools. We propose SciLit, a pipeline that automatically recommends relevant papers, extracts highlights, and suggests a reference sentence as a citation of a paper, taking into consideration the user-provided context and keywords. SciLit efficiently recommends papers from large databases of hundreds of millions of papers using a two-stage pre-fetching and re-ranking literature search system that flexibly deals with addition and removal of a paper database. We provide a convenient user interface that displays the recommended papers as extractive summaries and that offers abstractively-generated citing sentences which are aligned with the provided context and which mention the chosen keyword(s).
    
[^8]: "一点就够了"：基于少量质量评估的语料过滤改进机器翻译

    "A Little is Enough": Few-Shot Quality Estimation based Corpus Filtering improves Machine Translation. (arXiv:2306.03507v1 [cs.CL])

    [http://arxiv.org/abs/2306.03507](http://arxiv.org/abs/2306.03507)

    本研究提出了一种基于质量评估的过滤方法，其从伪并行语料库中提取高质量平行数据，用于机器翻译模型训练，相较于传统方法，具有更好的性能。

    

    质量评估（QE）的任务是在没有参考翻译的情况下评估翻译的质量。QE的目标与语料库过滤的任务相一致，即为在伪并行语料库中的句对分配质量分数。我们提出了一种基于质量评估的过滤方法，以从伪并行语料库中提取高质量平行数据。据我们所知，这是一个将QE框架用于从伪并行语料库中提取高质量平行语料库的新颖适应方法。通过使用这个过滤后的语料库进行训练，相对于基准模型，我们观察到英马拉雅语、中文-英语和印地语-孟加拉语语种的机器翻译系统的性能提高了多达1.8个BLEU分数。基准模型是在整个伪并行语料库上进行训练的。我们的少样本QE模型从英马拉雅语QE模型中传递学习并在仅500个印地语-孟加拉语训练实例上进行微调，相对于传统的方法，显示出了对过滤后的语料库质量的改进。

    Quality Estimation (QE) is the task of evaluating the quality of a translation when reference translation is not available. The goal of QE aligns with the task of corpus filtering, where we assign the quality score to the sentence pairs present in the pseudo-parallel corpus. We propose a Quality Estimation based Filtering approach to extract high-quality parallel data from the pseudo-parallel corpus. To the best of our knowledge, this is a novel adaptation of the QE framework to extract quality parallel corpus from the pseudo-parallel corpus. By training with this filtered corpus, we observe an improvement in the Machine Translation (MT) system's performance by up to 1.8 BLEU points, for English-Marathi, Chinese-English, and Hindi-Bengali language pairs, over the baseline model. The baseline model is the one that is trained on the whole pseudo-parallel corpus. Our Few-shot QE model transfer learned from the English-Marathi QE model and fine-tuned on only 500 Hindi-Bengali training inst
    
[^9]: 应用标准促进大型语言模型上下游伦理

    Applying Standards to Advance Upstream & Downstream Ethics in Large Language Models. (arXiv:2306.03503v1 [cs.CY])

    [http://arxiv.org/abs/2306.03503](http://arxiv.org/abs/2306.03503)

    本文探讨如何为AI生成的内容制定安全保障，分析LLMs的内容生成机制，确定了四个关键领域，提出了新的分发和销售LLM生成内容的企业的标准。

    

    本文探讨AI所有者如何借鉴其他内容创作行业的行为准则和伦理标准，为AI生成的内容制定安全保障。它深入研究了大型语言模型（LLMs）的伦理意识现状。通过分析LLMs的内容生成机制，确定了四个关键领域（上下游和用户提示/回答），在这些领域可以有效地应用保障措施。随后，对这四个领域进行了比较分析，包括在成本、有效性和与行业惯例的一致性方面评估现有的伦理保障措施。本文的主要观点是，现有的与IT相关的伦理准则虽然适用于传统的IT工程领域，但不足以应对基于LLMs内容生成所带来的挑战。我们借鉴新闻业内已有的实践，为分发和销售LLM生成内容的企业提出了潜在的标准。

    This paper explores how AI-owners can develop safeguards for AI-generated content by drawing from established codes of conduct and ethical standards in other content-creation industries. It delves into the current state of ethical awareness on Large Language Models (LLMs). By dissecting the mechanism of content generation by LLMs, four key areas (upstream/downstream and at user prompt/answer), where safeguards could be effectively applied, are identified. A comparative analysis of these four areas follows and includes an evaluation of the existing ethical safeguards in terms of cost, effectiveness, and alignment with established industry practices. The paper's key argument is that existing IT-related ethical codes, while adequate for traditional IT engineering, are inadequate for the challenges posed by LLM-based content generation. Drawing from established practices within journalism, we propose potential standards for businesses involved in distributing and selling LLM-generated cont
    
[^10]: 基于数据增强与情节记忆的可适应交互式图像描述生成

    Towards Adaptable and Interactive Image Captioning with Data Augmentation and Episodic Memory. (arXiv:2306.03500v1 [cs.CL])

    [http://arxiv.org/abs/2306.03500](http://arxiv.org/abs/2306.03500)

    本文提出一种基于交互式学习的图像描述生成方法，实现了通过数据增强与情节记忆来微调模型以适应新数据的目的，结果表明情节记忆是一种有效的方法。

    

    交互式机器学习可以在数据有限的情况下起到很好的学习效果，因为人类反馈可以逐步地融入到训练过程中。本文提出了一种基于交互式学习的图像描述生成模型，能够利用用户输入的信息来逐步微调预训练的模型以适应新的数据分布。我们探讨了如何利用简单的数据增强方法在每个新的输入样例上获取更多的数据并实现了持续学习方法来防止重复更新导致的灾难性遗忘。我们将一个特定领域的图像描述数据集 VizWiz 分成不重叠的部分，以模拟逐步输入流，不断适应新数据的过程。结果表明，虽然数据增强会导致结果变差，但即使只有相对较少的数据可用，情节记忆也是一种有效的方法。

    Interactive machine learning (IML) is a beneficial learning paradigm in cases of limited data availability, as human feedback is incrementally integrated into the training process. In this paper, we present an IML pipeline for image captioning which allows us to incrementally adapt a pre-trained image captioning model to a new data distribution based on user input. In order to incorporate user input into the model, we explore the use of a combination of simple data augmentation methods to obtain larger data batches for each newly annotated data instance and implement continual learning methods to prevent catastrophic forgetting from repeated updates. For our experiments, we split a domain-specific image captioning dataset, namely VizWiz, into non-overlapping parts to simulate an incremental input flow for continually adapting the model to new data. We find that, while data augmentation worsens results, even when relatively small amounts of data are available, episodic memory is an effe
    
[^11]: SciCap+: 一份知识增强的数据集，用于研究科学图例标题的挑战。

    SciCap+: A Knowledge Augmented Dataset to Study the Challenges of Scientific Figure Captioning. (arXiv:2306.03491v1 [cs.CV])

    [http://arxiv.org/abs/2306.03491](http://arxiv.org/abs/2306.03491)

    SciCap+ 是一份知识增强的数据集，用于研究科学图例标题自动生成的任务，从提到图片的段落和OCR标记中提取跨模态嵌入的知识，经实验发现这些知识可以显著地提高自动标准图片的字幕生成效果。

    

    在学术文献中，图例为向读者传达科学研究结果提供了一种直接的方式。自动生成图例标题有助于将科学文档模型理解超越文本，帮助作者编写有助于传达科学研究结果的信息性标题。与之前的研究不同，我们将科学图例标题重新构建为一种知识增强的图像标题生成任务，模型需要使用跨模态嵌入的知识进行标题生成。为此，我们扩展了大规模的SciCap数据集，增加了提到图片的段落和OCR标记。然后，我们使用基于指针网络的多模态变换模型M4C-Captioner作为我们研究的基线，进行实验。我们的结果表明，提到图片的段落作为附加上下文知识，极大地增强了自动标准图片的字幕生成的效果。

    In scholarly documents, figures provide a straightforward way of communicating scientific findings to readers. Automating figure caption generation helps move model understandings of scientific documents beyond text and will help authors write informative captions that facilitate communicating scientific findings. Unlike previous studies, we reframe scientific figure captioning as a knowledge-augmented image captioning task that models need to utilize knowledge embedded across modalities for caption generation. To this end, we extended the large-scale SciCap dataset~\cite{hsu-etal-2021-scicap-generating} to SciCap+ which includes mention-paragraphs (paragraphs mentioning figures) and OCR tokens. Then, we conduct experiments with the M4C-Captioner (a multimodal transformer-based model with a pointer network) as a baseline for our study. Our results indicate that mention-paragraphs serves as additional context knowledge, which significantly boosts the automatic standard image caption eva
    
[^12]: 放置人类在图像字幕循环中

    Putting Humans in the Image Captioning Loop. (arXiv:2306.03476v1 [cs.CL])

    [http://arxiv.org/abs/2306.03476](http://arxiv.org/abs/2306.03476)

    本文介绍了一种新的图像字幕系统，该系统利用人类反馈进行训练，并且可以轻松适应用户特定数据。这种系统具有实时更新的功能，可以避免灾难性的遗忘。

    

    图像字幕 (IC) 模型在训练过程中可以从人类反馈中获益，特别是在数据有限的情况下。我们正在进行适应 IC 系统以集成人类反馈的工作，目标是使其易于适应用户特定数据。我们的方法建立在预先训练了 MS COCO 数据集上的基础 IC 模型上，该模型为看不见的图像生成字幕。然后，用户将能够提供对图片和生成/预测字幕的反馈，这将被增加以创建模型适应的其他训练实例。这些附加实例使用逐步更新集成到模型中，并使用稀疏内存回放组件以避免灾难性遗忘。我们希望这种方法不仅能导致改进的结果，而且还能产生可定制的 IC 模型。

    Image Captioning (IC) models can highly benefit from human feedback in the training process, especially in cases where data is limited. We present work-in-progress on adapting an IC system to integrate human feedback, with the goal to make it easily adaptable to user-specific data. Our approach builds on a base IC model pre-trained on the MS COCO dataset, which generates captions for unseen images. The user will then be able to offer feedback on the image and the generated/predicted caption, which will be augmented to create additional training instances for the adaptation of the model. The additional instances are integrated into the model using step-wise updates, and a sparse memory replay component is used to avoid catastrophic forgetting. We hope that this approach, while leading to improved results, will also result in customizable IC models.
    
[^13]: 基于结构化语义匹配的事件抽取

    Joint Event Extraction via Structural Semantic Matching. (arXiv:2306.03469v1 [cs.CL])

    [http://arxiv.org/abs/2306.03469](http://arxiv.org/abs/2306.03469)

    本文提出了一种基于语义特征的事件抽取方法，通过结构匹配实现事件类型的检测和论元角色的提取。实验结果表明，该方法在 ACE2005 数据集上表现出较高的性能。

    

    事件抽取是信息抽取中的一个重要任务，旨在从文本中检测事件提及，并找到相应的论元角色。本文通过编码事件类型的语义特征并与目标文本进行结构匹配，提出了语义类型嵌入和动态结构编码器模块。同时构建了联合结构化语义匹配模型，通过双向注意力层共同执行事件检测和论点提取任务。在ACE2005数据集上的实验结果表明，我们的模型实现了显著的性能提升。

    Event Extraction (EE) is one of the essential tasks in information extraction, which aims to detect event mentions from text and find the corresponding argument roles. The EE task can be abstracted as a process of matching the semantic definitions and argument structures of event types with the target text. This paper encodes the semantic features of event types and makes structural matching with target text. Specifically, Semantic Type Embedding (STE) and Dynamic Structure Encoder (DSE) modules are proposed. Also, the Joint Structural Semantic Matching (JSSM) model is built to jointly perform event detection and argument extraction tasks through a bidirectional attention layer. The experimental results on the ACE2005 dataset indicate that our model achieves a significant performance improvement
    
[^14]: 通过程序综合实现自然语言命令

    Natural Language Commanding via Program Synthesis. (arXiv:2306.03460v1 [cs.LG])

    [http://arxiv.org/abs/2306.03460](http://arxiv.org/abs/2306.03460)

    通过使用大型语言模型和办公室领域特定语言，语义解释器实现了自然语言命令并执行Office应用程序中的用户意图。

    

    我们提出了语义解释器，这是一种自然语言友好型的人工智能系统，用于生产力软件，如微软Office，利用大型语言模型（LLM）跨应用程序功能执行用户意图。虽然LLM在理解以自然语言表达的用户意图方面表现出色，但对于需要超过文本到文本转换的应用程序特定用户意图的实现不足。因此，我们引入了办公域特定语言（ODSL），这是一种简洁、高级别的语言，专门用于在Office应用程序中执行操作并与实体交互。语义解释器利用分析检索提示构造方法与LLM进行程序综合，将自然语言用户话语转换为可以被转换为应用程序API并执行的ODSL程序。我们主要关注Microsoft PowerPoint的研究探索。

    We present Semantic Interpreter, a natural language-friendly AI system for productivity software such as Microsoft Office that leverages large language models (LLMs) to execute user intent across application features. While LLMs are excellent at understanding user intent expressed as natural language, they are not sufficient for fulfilling application-specific user intent that requires more than text-to-text transformations. We therefore introduce the Office Domain Specific Language (ODSL), a concise, high-level language specialized for performing actions in and interacting with entities in Office applications. Semantic Interpreter leverages an Analysis-Retrieval prompt construction method with LLMs for program synthesis, translating natural language user utterances to ODSL programs that can be transpiled to application APIs and then executed. We focus our discussion primarily on a research exploration for Microsoft PowerPoint.
    
[^15]: 基于音韵学的语言生成：以绕口令为例

    Phonetically-Grounded Language Generation: The Case of Tongue Twisters. (arXiv:2306.03457v1 [cs.CL])

    [http://arxiv.org/abs/2306.03457](http://arxiv.org/abs/2306.03457)

    本文介绍了针对绕口令生成的基于音韵学的语言生成任务，提供了TwistList数据集和TwisterMisters基准系统，并验证了预训练模型在没有任务特定数据和显式音韵知识的情况下的良好性能。

    

    先前的音韵学语言生成主要集中在词歌和诗歌等领域。本文介绍了围绕绕口令生成展开的工作，绕口令需要在保持语义正确性的同时，最大化音频重叠并保持语法正确。我们提供了TwistList，一个包含超过2.1K人工编写的绕口令的大型注释数据集。此外，我们针对绕口令生成提出了一些基准系统(TwisterMisters)，包括需要和不需要在域内数据上进行训练的模型。我们使用自动和人工评估的结果来证明现有主流预训练模型在此任务中性能优良，即使在没有任务特定训练数据和显式音韵知识的情况下。我们发现，绕口令生成的任务是有挑战性的。

    Previous work in phonetically-grounded language generation has mainly focused on domains such as lyrics and poetry. In this paper, we present work on the generation of tongue twisters - a form of language that is required to be phonetically conditioned to maximise sound overlap, whilst maintaining semantic consistency with an input topic, and still being grammatically correct. We present \textbf{TwistList}, a large annotated dataset of tongue twisters, consisting of 2.1K+ human-authored examples. We additionally present several benchmark systems (referred to as TwisterMisters) for the proposed task of tongue twister generation, including models that both do and do not require training on in-domain data. We present the results of automatic and human evaluation to demonstrate the performance of existing mainstream pre-trained models in this task with limited (or no) task specific training and data, and no explicit phonetic knowledge. We find that the task of tongue twister generation is 
    
[^16]: 用于阅读诊断的口语阅读准确度自动评估

    Automatic Assessment of Oral Reading Accuracy for Reading Diagnostics. (arXiv:2306.03444v1 [cs.CL])

    [http://arxiv.org/abs/2306.03444](http://arxiv.org/abs/2306.03444)

    本研究使用ASR技术开发了一种自动评估荷兰语口头阅读准确性的系统，该系统可以与人类评估达到相当的一致性（MCC = 0.63），其语言模型中包括阅读错误可以提高评估性能。

    

    利用自动语音识别（ASR）自动评估阅读流畅度对早期检测阅读困难以及随后及时干预具有巨大潜力，特别是对于英语以外的语言更是如此。本研究使用Kaldi和Whisper评估了六种最先进的基于ASR的系统，以自动评估荷兰语口头阅读准确性。结果表明，我们最成功的系统与人类评估达到了相当的一致性（MCC = 0.63）。相同的系统在强制解码置信度得分和单词正确性之间获得了最高的相关性（r = 0.45）。该系统的语言模型（LM）由测试数据的手动正字法转录和阅读提示组成，这表明在LM中包括阅读错误可以提高评估性能。我们详细讨论了开发自动评估系统的意义，并确定了未来研究的可能途径。

    Automatic assessment of reading fluency using automatic speech recognition (ASR) holds great potential for early detection of reading difficulties and subsequent timely intervention. Precise assessment tools are required, especially for languages other than English. In this study, we evaluate six state-of-the-art ASR-based systems for automatically assessing Dutch oral reading accuracy using Kaldi and Whisper. Results show our most successful system reached substantial agreement with human evaluations (MCC = .63). The same system reached the highest correlation between forced decoding confidence scores and word correctness (r = .45). This system's language model (LM) consisted of manual orthographic transcriptions and reading prompts of the test data, which shows that including reading errors in the LM improves assessment performance. We discuss the implications for developing automatic assessment systems and identify possible avenues of future research.
    
[^17]: 基于ASR转录的阿尔茨海默病分类: 探索标点符号和停顿的影响

    Alzheimer Disease Classification through ASR-based Transcriptions: Exploring the Impact of Punctuation and Pauses. (arXiv:2306.03443v1 [cs.CL])

    [http://arxiv.org/abs/2306.03443](http://arxiv.org/abs/2306.03443)

    本研究使用ASR模型获取自动的阿尔茨海默病患者的语音转录，探索了加入标点符号和停顿信息对于分类的影响，结果表明停顿编码对于手动和ASR转录在所有探究的方法中有助于AD分类。

    

    阿尔茨海默病(AD)是世界上最常见的神经退行性疾病之一，常常伴随着交流困难。分析语音可以作为诊断工具来识别该病。最近的ADReSS挑战提供了一个用于AD分类的数据集，并突出了手动转录的实用性。在本研究中，我们使用了最新的自动语音识别（ASR）模型Whisper来获取转录，其中还包括自动标点符号。分类模型结合预训练的FastText字嵌入和循环神经网络在手动和ASR转录中分别实现了0.854和0.833的测试准确度得分。此外，我们探讨了在转录中包含停顿信息和标点符号的影响。我们发现，在一些情况下，标点符号只能产生轻微的改进，而停顿编码可以帮助手动和ASR转录在所有探究的方法中进行AD分类。

    Alzheimer's Disease (AD) is the world's leading neurodegenerative disease, which often results in communication difficulties. Analysing speech can serve as a diagnostic tool for identifying the condition. The recent ADReSS challenge provided a dataset for AD classification and highlighted the utility of manual transcriptions. In this study, we used the new state-of-the-art Automatic Speech Recognition (ASR) model Whisper to obtain the transcriptions, which also include automatic punctuation. The classification models achieved test accuracy scores of 0.854 and 0.833 combining the pretrained FastText word embeddings and recurrent neural networks on manual and ASR transcripts respectively. Additionally, we explored the influence of including pause information and punctuation in the transcriptions. We found that punctuation only yielded minor improvements in some cases, whereas pause encoding aided AD classification for both manual and ASR transcriptions across all approaches investigated.
    
[^18]: 代码大语言模型在填写可能存在漏洞的代码时存在失败问题

    Large Language Models of Code Fail at Completing Code with Potential Bugs. (arXiv:2306.03438v1 [cs.LG])

    [http://arxiv.org/abs/2306.03438](http://arxiv.org/abs/2306.03438)

    本研究探讨了存在漏洞的代码补全问题，设计了两个数据集并发现这些漏洞显著降低了Code-LLMs的生成性能。

    

    最近，代码大语言模型（Code-LLMs）在代码补全方面取得了巨大进展，这是编程辅助和代码智能的基本功能。然而，大多数现有的研究忽略了在生成过程中代码上下文中可能存在的漏洞问题，在软件开发中这是不可避免的。因此，我们引入并研究了存在漏洞的代码补全问题，受实时代码建议的现实场景启发，代码上下文中包含可能的漏洞-反模式，这些反模式可以成为完成程序中的漏洞。为了系统地研究任务，我们引入了两个数据集：一个是从语义改变操作中派生的合成漏洞数据集（buggy-HumanEval），另一个是从用户提交的编程问题中派生的现实漏洞数据集（buggy-FixEval）。我们发现，可能存在漏洞的情况显著降低了高性能Code-LLMs的生成性能。例如，CodeGen-2B-mono在测试数据集上的通过率

    Large language models of code (Code-LLMs) have recently brought tremendous advances to code completion, a fundamental feature of programming assistance and code intelligence. However, most existing works ignore the possible presence of bugs in the code context for generation, which are inevitable in software development. Therefore, we introduce and study the buggy-code completion problem, inspired by the realistic scenario of real-time code suggestion where the code context contains potential bugs -- anti-patterns that can become bugs in the completed program. To systematically study the task, we introduce two datasets: one with synthetic bugs derived from semantics-altering operator changes (buggy-HumanEval) and one with realistic bugs derived from user submissions to coding problems (buggy-FixEval). We find that the presence of potential bugs significantly degrades the generation performance of the high-performing Code-LLMs. For instance, the passing rates of CodeGen-2B-mono on test 
    
[^19]: 关注点对Prompt-tuning的作用

    On the Role of Attention in Prompt-tuning. (arXiv:2306.03435v1 [cs.LG])

    [http://arxiv.org/abs/2306.03435](http://arxiv.org/abs/2306.03435)

    本论文研究了Prompt-tuning在注意力架构中的应用，通过探索上下文混合模型，表明softmax-prompt-attention在表达上优于其他模型，同时也证明了该方法可以高效的使用数据学习提示。

    

    Prompt-tuning 是一种新兴的策略，通过从数据中学习 (软) 提示参数，使大型语言模型 (LLM) 适应下游任务。尽管其在 LLM 中取得了成功，但对于 Prompt-tuning 的能力及关注机制在提示中的作用，理论理解尚有限。在这项工作中，我们探索一个注意力架构的 Prompt-tuning，并研究上下文混合模型，其中每个输入表示属于上下文相关或无关集合。我们通过一个自包含的提示-注意力模型来隔离 Prompt-tuning 的作用。我们的贡献如下：(1) 我们表明在我们的上下文数据模型下，softmax-prompt-attention 在可证明地比softmax-self-attention 和线性提示注意力更具表达力。(2) 我们分析了渐变下降的初始轨迹，并展示可以通过近乎最优的样本复杂度学习提示和预测头，从而证明了提示可以证明地注意到稀疏的上下文相关信息。(3)

    Prompt-tuning is an emerging strategy to adapt large language models (LLM) to downstream tasks by learning a (soft-)prompt parameter from data. Despite its success in LLMs, there is limited theoretical understanding of the power of prompt-tuning and the role of the attention mechanism in prompting. In this work, we explore prompt-tuning for one-layer attention architectures and study contextual mixture-models where each input token belongs to a context-relevant or -irrelevant set. We isolate the role of prompt-tuning through a self-contained prompt-attention model. Our contributions are as follows: (1) We show that softmax-prompt-attention is provably more expressive than softmax-self-attention and linear-prompt-attention under our contextual data model. (2) We analyze the initial trajectory of gradient descent and show that it learns the prompt and prediction head with near-optimal sample complexity and demonstrate how prompt can provably attend to sparse context-relevant tokens. (3) 
    
[^20]: 商品搜索中的意图感知FAQ检索：生成-检索方法

    Generate-then-Retrieve: Intent-Aware FAQ Retrieval in Product Search. (arXiv:2306.03411v1 [cs.CL])

    [http://arxiv.org/abs/2306.03411](http://arxiv.org/abs/2306.03411)

    本研究提出了一种意图感知FAQ检索系统，它集成在商品搜索中，可以通过意图分类器和重构模型，提高了检索的精度和效率。

    

    与商品搜索引擎交互的客户越来越多地制定信息查询请求。常问问题（FAQ）检索旨在通过问题意图来检索用户查询的常见问题-答案对。将FAQ检索与商品搜索集成在一起，不仅可以使用户做出更明智的购买决策，还可以通过高效的售后支持增强用户保留率。在商品搜索中确定何时可以满足用户的信息需求的FAQ条目，而不会打扰其购物体验，是一个重要的挑战。我们提出了一个意图感知FAQ检索系统，其中包括（1）一个意图分类器，用于预测FAQ是否能够回答用户的问题；（2）一个重构模型，可以将查询重写为自然问题。离线评估表明，与基线系统相比，我们的方法在检索基准FAQ时将Hit @ 1提高了13％，同时将延迟降低了95％。这些改进结果说明了我们所提出的意图感知FAQ检索系统的有效性。

    Customers interacting with product search engines are increasingly formulating information-seeking queries. Frequently Asked Question (FAQ) retrieval aims to retrieve common question-answer pairs for a user query with question intent. Integrating FAQ retrieval in product search can not only empower users to make more informed purchase decisions, but also enhance user retention through efficient post-purchase support. Determining when an FAQ entry can satisfy a user's information need within product search, without disrupting their shopping experience, represents an important challenge. We propose an intent-aware FAQ retrieval system consisting of (1) an intent classifier that predicts when a user's information need can be answered by an FAQ; (2) a reformulation model that rewrites a query into a natural question. Offline evaluation demonstrates that our approach improves Hit@1 by 13% on retrieving ground-truth FAQs, while reducing latency by 95% compared to baseline systems. These impr
    
[^21]: 设计用户角色感知的对话代理进行有趣的对话：$\textit{WHAT}$, $\textit{WHEN}$, and $\textit{HOW}$ to Ground

    $\textit{WHAT}$, $\textit{WHEN}$, and $\textit{HOW}$ to Ground: Designing User Persona-Aware Conversational Agents for Engaging Dialogue. (arXiv:2306.03361v1 [cs.CL])

    [http://arxiv.org/abs/2306.03361](http://arxiv.org/abs/2306.03361)

    本文提出了一种针对商业环境的、能够平衡对话流畅性和趋向于理解对话系统的个性化开放领域对话系统方法，通过加权数据集混合、负角色信息增强方法，以及设计个性化对话数据集，解决了 $\textit{WHAT}$、$\textit{WHEN}$和$\textit{HOW}$ 等问题，同时提高了对话系统响应的可控性和解释性。

    

    本文提出了一种建立个性化开放领域对话系统以解决商业设置中涉及个性化对话响应与非正式响应交替的$\textit{WWH}$（$\textit{WHAT}$、$\textit{WHEN}$和$\textit{HOW}$）问题的方法。所提出的方法涉及加权数据集混合、负角色信息增强方法以及设计个性化对话数据集，以应对个性化、开放领域对话系统中$\textit{WWH}$的挑战。本文有效地平衡了对话流畅性和趋向于理解对话系统，同时还引入了响应类型标签来提高可控性和解释性。这些方法的组合导致了更加流畅的对话，证明了基于主观人类评估和客观评估的实验结果。

    This paper presents a method for building a personalized open-domain dialogue system to address the $\textit{WWH}$ ($\textit{WHAT}$, $\textit{WHEN}$, and $\textit{HOW}$) problem for natural response generation in a commercial setting, where personalized dialogue responses are heavily interleaved with casual response turns. The proposed approach involves weighted dataset blending, negative persona information augmentation methods, and the design of personalized conversation datasets to address the challenges of $\textit{WWH}$ in personalized, open-domain dialogue systems. Our work effectively balances dialogue fluency and tendency to ground, while also introducing a response-type label to improve the controllability and explainability of the grounded responses. The combination of these methods leads to more fluent conversations, as evidenced by subjective human evaluations as well as objective evaluations.
    
[^22]: BatchSampler：用于视觉、语言和图形的对比学习的小批量采样器

    BatchSampler: Sampling Mini-Batches for Contrastive Learning in Vision, Language, and Graphs. (arXiv:2306.03355v1 [cs.LG])

    [http://arxiv.org/abs/2306.03355](http://arxiv.org/abs/2306.03355)

    本文提出了一个新的对比学习方法BatchSampler，通过从输入数据中采样难以区分的实例的小批量，并利用重启随机游走来形成小批量，以提高性能。

    

    In-Batch对比学习是一种最先进的自我监督方法，它将语义相似的实例聚集在一起，同时将不相似的实例推到远离mini-batch之外。其成功的关键在于负样本共享策略，其中每个实例都作为mini-batch中其他实例的负样本。最近的研究旨在通过在当前mini-batch范围内采样难负样本来提高性能，但其质量仅受限于mini-batch本身。在这项工作中，我们提出通过从输入数据中采样mini-batch来改进对比学习。我们提出了BatchSampler来采样难以区分的（即彼此难以区分的困难和真实的负样本）实例的小批量。为了使每个小批量具有更少的假负样本，我们设计了随机选择实例的接近度图。为了形成小批量，我们利用接近度图上的重启随机游走来辅助采样。

    In-Batch contrastive learning is a state-of-the-art self-supervised method that brings semantically-similar instances close while pushing dissimilar instances apart within a mini-batch. Its key to success is the negative sharing strategy, in which every instance serves as a negative for the others within the mini-batch. Recent studies aim to improve performance by sampling hard negatives \textit{within the current mini-batch}, whose quality is bounded by the mini-batch itself. In this work, we propose to improve contrastive learning by sampling mini-batches from the input data. We present BatchSampler\footnote{The code is available at \url{https://github.com/THUDM/BatchSampler}} to sample mini-batches of hard-to-distinguish (i.e., hard and true negatives to each other) instances. To make each mini-batch have fewer false negatives, we design the proximity graph of randomly-selected instances. To form the mini-batch, we leverage random walk with restart on the proximity graph to help sam
    
[^23]: Click: 序列似然对比学习控制文本生成

    Click: Controllable Text Generation with Sequence Likelihood Contrastive Learning. (arXiv:2306.03350v1 [cs.CL])

    [http://arxiv.org/abs/2306.03350](http://arxiv.org/abs/2306.03350)

    Click是一种无需修改模型架构的可控文本生成方法，它采用序列似然对比损失来根本减少不良属性的生成概率，同时采用一种新颖的样本构造策略来构建对比样本。在相关任务中，Click表现出了优异的性能，且样本构造策略相较于其他方法更加优秀。

    

    控制语言模型避免生成带有不良属性的文本一直是个重要而具有挑战性的问题，比如有害的语言和不自然的重复。我们引入了 Click 来进行可控文本生成，无需修改模型架构，并且便于使用已经训练好的模型。它通过采用序列似然对比损失来根本减少负样本的生成概率（即具有不良属性的生成结果）。同时采用了一种新颖的似然排名策略来构建对比样本。在语言去毒、情感调整和减少重复的任务中，我们证明了 Click 優於强基线的可控文字生成，并展示了 Click 的样本构造策略的优越性。

    It has always been an important yet challenging problem to control language models to avoid generating texts with undesirable attributes, such as toxic language and unnatural repetition. We introduce Click for controllable text generation, which needs no modification to the model architecture and facilitates out-of-the-box use of trained models. It employs a contrastive loss on sequence likelihood, which fundamentally decreases the generation probability of negative samples (i.e., generations with undesirable attributes). It also adopts a novel likelihood ranking-based strategy to construct contrastive samples from model generations. On the tasks of language detoxification, sentiment steering, and repetition reduction, we show that Click outperforms strong baselines of controllable text generation and demonstrate the superiority of Click's sample construction strategy.
    
[^24]: 推理时间干预：从语言模型中引导出真实的答案

    Inference-Time Intervention: Eliciting Truthful Answers from a Language Model. (arXiv:2306.03341v1 [cs.LG])

    [http://arxiv.org/abs/2306.03341](http://arxiv.org/abs/2306.03341)

    本研究提出推理时间干预（ITI）技术，通过在推理过程中跨越有限数量的注意力头，显着提高大型语言模型的真实性。在TruthfulQA基准上，ITI使LLaMA模型的真实性从32.5%提高到65.1%。ITI是一种最小程度的干扰，计算廉价，且数据效率高。

    

    我们介绍了推理时间干预（ITI）技术，旨在增强大型语言模型（LLMs）的真实性。ITI通过在推理过程中沿着一组方向移动模型激活，跨越有限数量的注意力头。这种干预显着提高了LLaMA模型在TruthfulQA基准上的表现。在指令微调的LLaMA Alpaca上，ITI将其真实性从32.5％提高到65.1％。我们确定了真实性和可用性之间的权衡，并演示了如何通过调整干预强度来平衡它。ITI 取得了最低程度的干扰且计算廉价。此外，该技术在数据效率上表现优异：虽然像RLHF这样的方法需要广泛注释，但是ITI仅使用了几百个例子就能定位真实的方向。我们的研究结果表明，LLMs可能具有某种内部表示方法来表示某事是真实的可能性，即使它们在表面上产生了虚假的结果。

    We introduce Inference-Time Intervention (ITI), a technique designed to enhance the truthfulness of large language models (LLMs). ITI operates by shifting model activations during inference, following a set of directions across a limited number of attention heads. This intervention significantly improves the performance of LLaMA models on the TruthfulQA benchmark. On an instruction-finetuned LLaMA called Alpaca, ITI improves its truthfulness from 32.5% to 65.1%. We identify a tradeoff between truthfulness and helpfulness and demonstrate how to balance it by tuning the intervention strength. ITI is minimally invasive and computationally inexpensive. Moreover, the technique is data efficient: while approaches like RLHF require extensive annotations, ITI locates truthful directions using only few hundred examples. Our findings suggest that LLMs may have an internal representation of the likelihood of something being true, even as they produce falsehoods on the surface.
    
[^25]: CoSiNES: 基于对比双子网络的实体标准化方法

    CoSiNES: Contrastive Siamese Network for Entity Standardization. (arXiv:2306.03316v1 [cs.CL])

    [http://arxiv.org/abs/2306.03316](http://arxiv.org/abs/2306.03316)

    CoSiNES 是一个通用的、适应性强的实体标准化方法，通过对比双子网络和预训练语言模型的结合，可以有效地捕捉实体的语法和语义特征。在技术领域的数据集上，相比于基线算法，CoSiNES 的精度更高、运行时间更短。

    

    实体标准化将来自自由文本中的噪声提及映射到知识库中的标准实体。相对于其他实体相关任务，这项任务的唯一挑战是缺乏周围环境和提及形式的数种变化，特别是在跨领域泛化时标记数据不足。以前的研究大多集中于开发要么严重依赖上下文的模型，要么专门针对某个特定领域。相比之下，我们提出了 CoSiNES，这是一个具有对比双子网络的通用和适应性框架，可以有效地将预训练语言模型适应到新领域的实体的语法和语义特征中。我们在技术领域构建了一个新数据集，其中包含640个技术栈实体和6412个来自工业内容管理系统的提及。我们证明了 CoSiNES 比基线算法具有更高的精度和更快的运行时间。

    Entity standardization maps noisy mentions from free-form text to standard entities in a knowledge base. The unique challenge of this task relative to other entity-related tasks is the lack of surrounding context and numerous variations in the surface form of the mentions, especially when it comes to generalization across domains where labeled data is scarce. Previous research mostly focuses on developing models either heavily relying on context, or dedicated solely to a specific domain. In contrast, we propose CoSiNES, a generic and adaptable framework with Contrastive Siamese Network for Entity Standardization that effectively adapts a pretrained language model to capture the syntax and semantics of the entities in a new domain.  We construct a new dataset in the technology domain, which contains 640 technical stack entities and 6,412 mentions collected from industrial content management systems. We demonstrate that CoSiNES yields higher accuracy and faster runtime than baselines der
    
[^26]: 双教师自我训练的少样本原理生成研究

    Few Shot Rationale Generation using Self-Training with Dual Teachers. (arXiv:2306.03315v1 [cs.CL])

    [http://arxiv.org/abs/2306.03315](http://arxiv.org/abs/2306.03315)

    本文提出了一种双教师学习框架，利用标记和未标记的数据，通过自我训练来改进少样本模型，实现同时生成任务标签和原理的效果；此外还提出了一种新的损失函数Masked Label Regularization，可以明确地强制解释明确地条件化。

    

    自我解释模型同时为其预测的标签生成自由文本解释是构建可信赖的AI应用程序的重要工具。由于为注释标签生成解释是一个费力且成本昂贵的过程，因此近期的模型依赖于大型预训练语言模型（PLMs）作为其骨干，并且采用少样本学习。在这项工作中，我们探索了一种自我训练方法，利用标记和未标记的数据来进一步改进少样本模型，假设在大规模情况下都没有人工编写的原理或标注任务标签的情况下。我们引入了一种新的双教师学习框架，使用自我训练和精炼了两个专业的教师模型，用于任务预测和理性化，将它们的知识转化为能够共同生成任务标签和原理的多任务学生模型。此外，我们还制定了一种新的损失函数，掩码标签正则化（MLR），将解释明确地强制条件化。

    Self-rationalizing models that also generate a free-text explanation for their predicted labels are an important tool to build trustworthy AI applications. Since generating explanations for annotated labels is a laborious and costly pro cess, recent models rely on large pretrained language models (PLMs) as their backbone and few-shot learning. In this work we explore a self-training approach leveraging both labeled and unlabeled data to further improve few-shot models, under the assumption that neither human written rationales nor annotated task labels are available at scale. We introduce a novel dual-teacher learning framework, which learns two specialized teacher models for task prediction and rationalization using self-training and distills their knowledge into a multi-tasking student model that can jointly generate the task label and rationale. Furthermore, we formulate a new loss function, Masked Label Regularization (MLR) which promotes explanations to be strongly conditioned on 
    
[^27]: 一个可扩展和适应性强的系统用于推断公司的行业板块：基于生成式语言模型的Prompt+模型微调

    A Scalable and Adaptive System to Infer the Industry Sectors of Companies: Prompt + Model Tuning of Generative Language Models. (arXiv:2306.03313v1 [cs.CL])

    [http://arxiv.org/abs/2306.03313](http://arxiv.org/abs/2306.03313)

    本文介绍了一个板块推断系统，可以帮助主题型私募股权基金的投资专业人士推断公司所在的行业板块。该系统建立在中型生成式语言模型上，通过Prompt+模型微调程序进行微调，并具有良好的可扩展性和适应性。

    

    私募股权公司通过收购和管理公司来实现高收益，许多私募股权基金是主题型的，意味着投资专业人士要覆盖尽可能多的行业板块，并在这些板块中选择有前途的公司，因此推断公司的板块对主题型私募股权基金的成功至关重要。在本文中，我们标准化行业板块框架，并讨论了典型的挑战；然后介绍了我们的板块推断系统，解决了这些挑战。具体而言，我们的系统是建立在中型生成式语言模型上的，通过Prompt+模型微调程序进行微调。部署的模型展示了比常见基线更优秀的性能。该系统已经为许多私募股权专业人员服务超过一年，并显示出对数据量的良好可扩展性和对行业板块和/或注释的任何变化的适应性。

    The Private Equity (PE) firms operate investment funds by acquiring and managing companies to achieve a high return upon selling. Many PE funds are thematic, meaning investment professionals aim to identify trends by covering as many industry sectors as possible, and picking promising companies within these sectors. So, inferring sectors for companies is critical to the success of thematic PE funds. In this work, we standardize the sector framework and discuss the typical challenges; we then introduce our sector inference system addressing these challenges. Specifically, our system is built on a medium-sized generative language model, finetuned with a prompt + model tuning procedure. The deployed model demonstrates a superior performance than the common baselines. The system has been serving many PE professionals for over a year, showing great scalability to data volume and adaptability to any change in sector framework and/or annotation.
    
[^28]: 面向特定领域的预训练模型：相比一锅粥式模型，千万不要让领域的供给不足受到波及

    Stack Over-Flowing with Results: The Case for Domain-Specific Pre-Training Over One-Size-Fits-All Models. (arXiv:2306.03268v1 [cs.CL])

    [http://arxiv.org/abs/2306.03268](http://arxiv.org/abs/2306.03268)

    本文主张在大型预训练模型的潮流中，还应推广面向特定领域的预训练模型，并以 StackOverflow 为例展示了其优越性。

    

    大型预训练神经语言模型（如OpenAI的GPT系列）为NLP和软件工程带来了极大的进展。然而，我们认为这种追求大而全的潮流应该与针对特定目的、规模适中的预训练模型相结合。本文以StackOverflow为例，展示了我们的面向特定领域的预训练模型相对于通用模型在验证困惑度和迁移学习准确性方面表现更优。

    Large pre-trained neural language models have brought immense progress to both NLP and software engineering. Models in OpenAI's GPT series now dwarf Google's BERT and Meta's RoBERTa, which previously set new benchmarks on a wide range of NLP applications. These models are trained on massive corpora of heterogeneous data from web crawls, which enables them to learn general language patterns and semantic relationships. However, the largest models are both expensive to train and deploy and are often closed-source, so we lack access to their data and design decisions. We argue that this trend towards large, general-purpose models should be complemented with single-purpose, more modestly sized pre-trained models. In this work, we take StackOverflow (SO) as a domain example in which large volumes of rich aligned code and text data is available. We adopt standard practices for pre-training large language models, including using a very large context size (2,048 tokens), batch size (0.5M tokens
    
[^29]: RadSum23 上的 shs-nlp: 面向放射学报告的指导调整语言模型基于领域自适应预训练下的印象生成

    shs-nlp at RadSum23: Domain-Adaptive Pre-training of Instruction-tuned LLMs for Radiology Report Impression Generation. (arXiv:2306.03264v1 [cs.CL])

    [http://arxiv.org/abs/2306.03264](http://arxiv.org/abs/2306.03264)

    本文提出了一个基于领域自适应预训练的指导调整语言模型的系统，用于增强其医学知识和在特定医学任务上的性能，特别是在 IMPRESSIONS 生成任务中表现出色，比许多预训练和微调自适应方法表现更好，并且在 BioNLP 2023 研讨会的任务1B：放射学报告摘要中排名第1。

    

    ChatGPT 和 Bloomz 这样的指导调整生成语言模型在普适性方面表现出色，但在理解放射学报告方面存在局限性，特别是在从所发现的内容生成 IMPRESSIONS 部分的任务中。这些模型会生成冗长或不完整的 IMPRESSIONS，主要是由于训练期间对医学文本数据的曝光不足。我们提出了一个系统，利用大规模医学文本数据进行基于领域自适应预训练的指导调整语言模型的训练，以增强其医学知识和在特定医学任务上的性能。我们展示了在零-shot 设置下，这个系统在 IMPRESSIONS 生成任务上比许多预训练和微调自适应方法表现更好，并且在 BioNLP 2023 研讨会的任务1B：放射学报告摘要中排名第1。

    Instruction-tuned generative Large language models (LLMs) like ChatGPT and Bloomz possess excellent generalization abilities, but they face limitations in understanding radiology reports, particularly in the task of generating the IMPRESSIONS section from the FINDINGS section. They tend to generate either verbose or incomplete IMPRESSIONS, mainly due to insufficient exposure to medical text data during training. We present a system which leverages large-scale medical text data for domain-adaptive pre-training of instruction-tuned LLMs to enhance its medical knowledge and performance on specific medical tasks. We show that this system performs better in a zero-shot setting than a number of pretrain-and-finetune adaptation methods on the IMPRESSIONS generation task, and ranks 1st among participating systems in Task 1B: Radiology Report Summarization at the BioNLP 2023 workshop.
    
[^30]: 理解早期权重平均对训练大语言模型的有效性

    Understanding the Effectiveness of Early Weight Averaging for Training Large Language Models. (arXiv:2306.03241v1 [cs.LG])

    [http://arxiv.org/abs/2306.03241](http://arxiv.org/abs/2306.03241)

    本文研究了使用早期权重平均化方法来提高大型语言模型质量的有效性，证明该方法可以加速收敛且测试和零样本泛化效果显著，同时有效缓解了训练中的损失波动问题。

    

    训练大型语言模型代价高昂，最近的研究表明训练至收敛并不高效。在本文中，我们研究了一种简单的想法，即在训练过程中沿着轨迹进行检查点平均化，以在模型收敛之前提高其质量。这种方法在训练或推理期间不会产生额外的成本。具体而言，我们分析了具有10亿到120亿参数的Pythia LLM的训练轨迹，并证明特别是在训练的早期和中期阶段，这种想法可以加速收敛并提高测试和零样本泛化效果。损失波动是LLM训练中众所周知的问题；在我们的分析中，我们遇到了两种基础轨迹的这种情况，并且我们的平均化可以缓解这两种情况。例如，对于一个拥有69亿参数的LLM，我们的早期权重平均化配方可以节省高达4200小时的GPU时间，这对云计算成本来说是显著的节约。

    Training LLMs is expensive, and recent evidence indicates training all the way to convergence is inefficient. In this paper, we investigate the ability of a simple idea, checkpoint averaging along the trajectory of a training run to improve the quality of models before they have converged. This approach incurs no extra cost during training or inference. Specifically, we analyze the training trajectories of Pythia LLMs with 1 to 12 billion parameters and demonstrate that, particularly during the early to mid stages of training, this idea accelerates convergence and improves both test and zero-shot generalization. Loss spikes are a well recognized problem in LLM training; in our analysis we encountered two instances of this in the underlying trajectories, and both instances were mitigated by our averaging.  For a 6.9B parameter LLM, for example, our early weight averaging recipe can save upto 4200 hours of GPU time, which corresponds to significant savings in cloud compute costs.
    
[^31]: 数据饮食下的NLU：NLP分类任务中的动态数据子集选择。

    NLU on Data Diets: Dynamic Data Subset Selection for NLP Classification Tasks. (arXiv:2306.03208v1 [cs.CL])

    [http://arxiv.org/abs/2306.03208](http://arxiv.org/abs/2306.03208)

    本研究提出一种动态数据修剪的方法，通过定期对不重要的示例进行打分和抛弃，减少了微调大型语言模型的成本，并且在GLUE基准测试和四个联合NLU数据集上表现更好。

    

    微调大型语言模型会增加NLU应用的成本，并仍是开发周期的瓶颈。最近，计算机视觉领域的研究使用数据修剪来减少训练时间。采用静态方法进行修剪数据选择是基于微调之前为每个训练样例计算的得分，这涉及重要的计算开销。此外，该得分可能并不代表整个训练过程中样例的重要性。我们提出使用精细版本的动态数据修剪方法来解决这些问题，这是一个在微调过程中定期对不重要的示例进行打分和抛弃的课程。我们的方法利用了一个我们将其扩展到联合意图和槽分类任务的EL2N度量和对完整训练集进行的初始微调阶段。我们在GLUE基准测试和四个联合NLU数据集上的结果表明，与静态方法相比，我们的方法在时间-准确性权衡方面表现更好。我们的方法在训练50％时保持完全准确性。

    Finetuning large language models inflates the costs of NLU applications and remains the bottleneck of development cycles. Recent works in computer vision use data pruning to reduce training time. Pruned data selection with static methods is based on a score calculated for each training example prior to finetuning, which involves important computational overhead. Moreover, the score may not necessarily be representative of sample importance throughout the entire training duration. We propose to address these issues with a refined version of dynamic data pruning, a curriculum which periodically scores and discards unimportant examples during finetuning. Our method leverages an EL2N metric that we extend to the joint intent and slot classification task, and an initial finetuning phase on the full train set. Our results on the GLUE benchmark and four joint NLU datasets show a better time-accuracy trade-off compared to static methods. Our method preserves full accuracy while training on 50%
    
[^32]: 大型语言模型的代码补全的静态评价。

    A Static Evaluation of Code Completion by Large Language Models. (arXiv:2306.03203v1 [cs.CL])

    [http://arxiv.org/abs/2306.03203](http://arxiv.org/abs/2306.03203)

    本文提出了一种基于抽象语法树的静态评价框架来评估大型语言模型的Python代码补全质量，相比于基于执行的评估方法更加高效，适用于实际代码。研究揭示了未定义名称是一个常见错误。

    

    针对利用代码训练的大型语言模型提高软件开发人员生产力的研究，已经提出了数个基于执行的评估标准，用来评估模型生成的代码在简单编程问题上的功能正确性。然而，考虑到执行成本的问题，在复杂的实际项目上执行同样的评估是非常昂贵的。与此相反的是，可以静态地检测错误而无需运行程序的语法检查工具（如本文中使用的“linter”），尚未被广泛用于评估代码生成模型。本文提出了一种基于抽象语法树的静态评价框架，以量化Python代码补全中的静态错误。与基于执行的评估相比，我们的方法不仅更高效，而且适用于实际代码。在实验中，我们从开源代码库中收集代码上下文，使用公共模型生成了一百万个函数体。我们的静态分析揭示了未定义的名称（Undefined Name）这个常见错误。

    Large language models trained on code have shown great potential to increase productivity of software developers. Several execution-based benchmarks have been proposed to evaluate functional correctness of model-generated code on simple programming problems. Nevertheless, it is expensive to perform the same evaluation on complex real-world projects considering the execution cost. On the contrary, static analysis tools such as linters, which can detect errors without running the program, haven't been well explored for evaluating code generation models. In this work, we propose a static evaluation framework to quantify static errors in Python code completions, by leveraging Abstract Syntax Trees. Compared with execution-based evaluation, our method is not only more efficient, but also applicable to code in the wild. For experiments, we collect code context from open source repos to generate one million function bodies using public models. Our static analysis reveals that Undefined Name a
    
[^33]: 德国易读性：目前状况及可用资源的调查

    Easy-to-Read in Germany: A Survey on its Current State and Available Resources. (arXiv:2306.03189v1 [cs.CL])

    [http://arxiv.org/abs/2306.03189](http://arxiv.org/abs/2306.03189)

    本文综述了德语易读语言（LS）的最新自然语言处理（NLP）工具和资源，并探讨了德国LS和Einfache Sprache（ES）现状。

    

    易读性语言（E2R）是一种受控制的语言变体，通过使用清晰、直接和简单的语言，使任何书面文本更易理解。它主要面向认知或智力残疾等目标用户群体。而普通语言（PL）则旨在通过使用简单的语言来传达信息。德语拥有其易读语言版本Leichte Sprache（LS）和Einfache Sprache（ES）版本的PL。近年来，在LS领域进行了重要发展。本文提供了LS的自然语言处理（NLP）工具和资源的最新综述。此外，还旨在阐述德国LS和ES的状况。

    Easy-to-Read Language (E2R) is a controlled language variant that makes any written text more accessible through the use of clear, direct and simple language. It is mainly aimed at people with cognitive or intellectual disabilities, among other target users. Plain Language (PL), on the other hand, is a variant of a given language, which aims to promote the use of simple language to communicate information. German counts with Leichte Sprache (LS), its version of E2R, and Einfache Sprache (ES), its version of PL. In recent years, important developments have been conducted in the field of LS. This paper offers an updated overview of the existing Natural Language Processing (NLP) tools and resources for LS. Besides, it also aims to set out the situation with regard to LS and ES in Germany.
    
[^34]: 《组合与变形：使用文本到图像模型评估形象化能力》

    Composition and Deformance: Measuring Imageability with a Text-to-Image Model. (arXiv:2306.03168v1 [cs.CL])

    [http://arxiv.org/abs/2306.03168](http://arxiv.org/abs/2306.03168)

    本文使用文本到图像模型衡量了英文单个单词和相关文本的形象化能力，并通过变形检测模型检测组合变化引起的能力变化，结果显示所提出的计算措施能够更加一致地响应组合变化。

    

    尽管语言学学者和心理学家长期以来一直研究语言字符串在听者或读者中引发心理图像的倾向，但大多数计算研究仅将这种形象化的概念应用于孤立的单词。本文利用最近发展的文本到图像生成模型（如DALLE mini），提出了使用生成的图像来测量单个英语单词和相关文本的形象化能力的计算方法。我们从三个语料库中提取文本提示，包括人类生成的图像标题、新闻文章句子和诗歌行。我们对这些提示进行不同的变形，以检查模型检测到的由组合变化引起的形象化能力变化的能力。我们发现，所提出的形象化能力的计算措施与人类对单词的判断之间存在较高的相关性。我们还发现，所提出的措施更一致地响应组合变化而不是基线方法。最后，我们讨论了可能的应用和未来工作。

    Although psycholinguists and psychologists have long studied the tendency of linguistic strings to evoke mental images in hearers or readers, most computational studies have applied this concept of imageability only to isolated words. Using recent developments in text-to-image generation models, such as DALLE mini, we propose computational methods that use generated images to measure the imageability of both single English words and connected text. We sample text prompts for image generation from three corpora: human-generated image captions, news article sentences, and poem lines. We subject these prompts to different deformances to examine the model's ability to detect changes in imageability caused by compositional change. We find high correlation between the proposed computational measures of imageability and human judgments of individual words. We also find the proposed measures more consistently respond to changes in compositionality than baseline approaches. We discuss possible 
    
[^35]: 无监督稠密检索及相关性感知对比学习

    Unsupervised Dense Retrieval with Relevance-Aware Contrastive Pre-Training. (arXiv:2306.03166v1 [cs.IR])

    [http://arxiv.org/abs/2306.03166](http://arxiv.org/abs/2306.03166)

    本文提出了相关性感知对比学习方法，该方法可以自适应地加权不同对偶的对比损失，以改善无监督检索模型性能，进一步的探索表明它可以击败BM25，作为很好的少量样本学习器。

    

    稠密检索已经取得了令人瞩目的性能，但其对丰富的训练数据的要求限制了其应用场景。对比学习可以从无标签数据中构建伪正向示例，已经显示出解决这个问题的巨大潜力。然而，数据增广制作的伪正向示例可能不相关。因此，我们提出了相关性感知对比学习。它将中间训练的模型本身作为不完美的预测器来估计正对偶的相关性，并根据估计的相关性自适应地加权不同对偶的对比损失。我们的方法在BEIR和开放领域的QA检索基准上始终优于SOTA无监督检索模型Contriever。进一步的探索表明，我们的方法不仅可以在目标语料库上进一步预训练后击败BM25，而且还可以作为很好的少量样本学习器。我们的代码公开在https://github.com/Yibin-Lei/ReContriever。

    Dense retrievers have achieved impressive performance, but their demand for abundant training data limits their application scenarios. Contrastive pre-training, which constructs pseudo-positive examples from unlabeled data, has shown great potential to solve this problem. However, the pseudo-positive examples crafted by data augmentations can be irrelevant. To this end, we propose relevance-aware contrastive learning. It takes the intermediate-trained model itself as an imperfect oracle to estimate the relevance of positive pairs and adaptively weighs the contrastive loss of different pairs according to the estimated relevance. Our method consistently improves the SOTA unsupervised Contriever model on the BEIR and open-domain QA retrieval benchmarks. Further exploration shows that our method can not only beat BM25 after further pre-training on the target corpus but also serves as a good few-shot learner. Our code is publicly available at https://github.com/Yibin-Lei/ReContriever.
    
[^36]: 在计算资源有限的条件下进行数字笔迹生成的抽样和排序

    Sampling and Ranking for Digital Ink Generation on a tight computational budget. (arXiv:2306.03103v1 [cs.HC])

    [http://arxiv.org/abs/2306.03103](http://arxiv.org/abs/2306.03103)

    该论文研究了如何在资源受限的环境下，通过使用多种抽样和排序技术，最大化数字墨水生成模型的输出质量，这项研究在数字墨水领域中首次进行，其结果证明了这些技术能显着提高合成墨水的识别性。

    

    数字墨水（在线手写）生成有许多潜在的应用，例如书写自动完成功能、拼写纠正和美化等。因为写作是个人的，所以处理通常在设备上完成。因此，墨水生成模型需要在资源受限的环境下快速生成高质量的内容。在本研究中，我们研究了如何在推理时间预算内最大化训练的数字墨水生成模型的输出质量。我们使用和比较多种抽样和排序技术的效果，这是数字墨水领域第一次这样的消融研究。我们在多个数据集上验证我们的发现——英语和越南语书写以及数学公式——使用两种模型类型和两种常见的墨水数据表示。在所有组合中，我们报告了合成墨水的可识别性的显着提高，在某些情况下，字符数量减少了一半以上。

    Digital ink (online handwriting) generation has a number of potential applications for creating user-visible content, such as handwriting autocompletion, spelling correction, and beautification. Writing is personal and usually the processing is done on-device. Ink generative models thus need to produce high quality content quickly, in a resource constrained environment.  In this work, we study ways to maximize the quality of the output of a trained digital ink generative model, while staying within an inference time budget. We use and compare the effect of multiple sampling and ranking techniques, in the first ablation study of its kind in the digital ink domain.  We confirm our findings on multiple datasets - writing in English and Vietnamese, as well as mathematical formulas - using two model types and two common ink data representations. In all combinations, we report a meaningful improvement in the recognizability of the synthetic inks, in some cases more than halving the character
    
[^37]: Video-LLaMA：用于视频理解的指令调整的语音-视觉语言模型

    Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding. (arXiv:2306.02858v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.02858](http://arxiv.org/abs/2306.02858)

    Video-LLaMA是一个多模态框架，利用已有的预训练模型，解决了视频中的视觉和听觉的理解问题，其中Video Q-former和Audio Q-former用于处理视频中的视觉与时间变化和音频信号的问题。

    

    我们提出了一个多模态框架Video-LLaMA，赋予大型语言模型（LLMs）理解视频中的视觉和听觉内容的能力。Video-LLaMA从已经预训练好的视觉和音频编码器以及已经冻结的LLMs进行跨模态训练。相比于之前专注于静态图像理解的视觉-LLMs，如MiniGPT-4和LLaVA，Video-LLaMA主要解决两个视频理解方面的挑战：（1）捕捉视觉场景中的时间变化，（2）集成音频视觉信号。为了克服第一个挑战，我们提出了一个Video Q-former，将预训练的图像编码器组装到我们的视频编码器中，并引入一个视频到文本生成任务来学习视频-语言对应关系。为了解决第二个挑战，我们利用ImageBind，一个将多种模态对齐的通用嵌入模型，作为预训练的音频编码器，并在ImageBind之上引入一个Audio Q-former，学习合理的听觉查询嵌入。

    We present Video-LLaMA, a multi-modal framework that empowers Large Language Models (LLMs) with the capability of understanding both visual and auditory content in the video. Video-LLaMA bootstraps cross-modal training from the frozen pre-trained visual & audio encoders and the frozen LLMs. Unlike previous vision-LLMs that focus on static image comprehensions such as MiniGPT-4 and LLaVA, Video-LLaMA mainly tackles two challenges in video understanding: (1) capturing the temporal changes in visual scenes, (2) integrating audio-visual signals. To counter the first challenge, we propose a Video Q-former to assemble the pre-trained image encoder into our video encoder and introduce a video-to-text generation task to learn video-language correspondence. For the second challenge, we leverage ImageBind, a universal embedding model aligning multiple modalities as the pre-trained audio encoder, and introduce an Audio Q-former on top of ImageBind to learn reasonable auditory query embeddings for
    
[^38]: Polyglot-Ko: 开源大规模韩语语言模型的技术报告

    A Technical Report for Polyglot-Ko: Open-Source Large-Scale Korean Language Models. (arXiv:2306.02254v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.02254](http://arxiv.org/abs/2306.02254)

    Polyglot-Ko是一种韩语语言模型，提供了比mBERT和XGLM更好的性能，有助于改善非英语语言的表现。

    

    Polyglot是一个旨在增强多语言语言模型的非英语语言性能的开创性项目。本文介绍了Polyglot Korean模型，它是专注于韩语而不是多语言性质的。我们与TUNiB合作，收集了1.2TB的精心筛选的韩语数据，重点开发了韩语模型。 Polyglot-Ko模型包括多种预训练模型，具有不同的大小和特性以适应各种下游任务。这些模型在多个韩语NLP任务上表现比mBERT和XGLM更好，进一步支持具有专门针对某一语言的模型的需求和潜力。

    Polyglot is a pioneering project aimed at enhancing the non-English language performance of multilingual language models. Despite the availability of various multilingual models such as mBERT (Devlin et al., 2019), XGLM (Lin et al., 2022), and BLOOM (Scao et al., 2022), researchers and developers often resort to building monolingual models in their respective languages due to the dissatisfaction with the current multilingual models non-English language capabilities. Addressing this gap, we seek to develop advanced multilingual language models that offer improved performance in non-English languages. In this paper, we introduce the Polyglot Korean models, which represent a specific focus rather than being multilingual in nature. In collaboration with TUNiB, our team collected 1.2TB of Korean data meticulously curated for our research journey. We made a deliberate decision to prioritize the development of Korean models before venturing into multilingual models. This choice was motivated 
    
[^39]: MultiLegalPile：689GB的多语言法律语料库

    MultiLegalPile: A 689GB Multilingual Legal Corpus. (arXiv:2306.02069v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.02069](http://arxiv.org/abs/2306.02069)

    MultiLegalPile是一个689GB的多语言法律语料库，包含来自17个司法管辖区的24种语言的不同法律数据源，允许在公平使用下针对预训练NLP模型。该语料库为多语言模型的预训练提供了新的最佳表现，并在LexGLUE上表现最佳。

    

    大型高质量的数据集对于训练大型语言模型(LLMs)至关重要。然而，目前为止，专业领域（如法律）可用的数据集很少，而且经常仅限于英语。我们整理并发布了MultiLegalPile，这是一个包含来自17个司法管辖区的24种语言的689GB语料库。MultiLegalPile语料库包括各种许可证的不同法律数据源，允许在公平使用下针对预训练自然语言处理(NLP)模型，对于Eurlex Resources和Legal mC4子集拥有更宽松的许可证。我们进行了两个RoBERTa模型和一个多语言Longformer的预训练，并分别在每种特定语言子集上进行了24个单语模型的预训练，并在LEXTREME上对它们进行了评估。此外，我们在LexGLUE上对英语和多语言模型进行了评估。我们的多语言模型在LEXTREME上创造了新的最佳表现(SotA)，英语模型则在LexGLUE上表现最佳。我们将数据集、训练模型和代码全部释放在最开放的许可证下。

    Large, high-quality datasets are crucial for training Large Language Models (LLMs). However, so far, there are few datasets available for specialized critical domains such as law and the available ones are often only for the English language. We curate and release MultiLegalPile, a 689GB corpus in 24 languages from 17 jurisdictions. The MultiLegalPile corpus, which includes diverse legal data sources with varying licenses, allows for pretraining NLP models under fair use, with more permissive licenses for the Eurlex Resources and Legal mC4 subsets. We pretrain two RoBERTa models and one Longformer multilingually, and 24 monolingual models on each of the language-specific subsets and evaluate them on LEXTREME. Additionally, we evaluate the English and multilingual models on LexGLUE. Our multilingual models set a new SotA on LEXTREME and our English models on LexGLUE. We release the dataset, the trained models, and all of the code under the most open possible licenses.
    
[^40]: 深度学习在关系抽取领域的综述：最新进展与新方向

    A Comprehensive Survey on Deep Learning for Relation Extraction: Recent Advances and New Frontiers. (arXiv:2306.02051v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.02051](http://arxiv.org/abs/2306.02051)

    本文综述了深度学习在关系抽取领域的应用进展，提出了新的分类法，讨论了面临的挑战和应对的技术，并展望了未来的发展方向。

    

    关系抽取是指从非结构化文本中识别实体之间的关系。关系抽取是许多自然语言处理应用的基础，例如知识图谱补全、问答和信息检索。近年来，深度神经网络在关系抽取领域占据了主导地位，并取得了显着进展。随后，大规模预训练语言模型（PLMs）将关系抽取的最新技术推向了一个新的高度。本文综述了现有深度学习技术在关系抽取中的应用情况。首先，我们介绍了关系抽取资源，包括关系抽取数据集和评估指标。其次，我们提出了一个新的分类法，从文本表示、上下文编码和三元组预测三个方面对现有工作进行分类。第三，我们讨论了关系抽取面临的一些重要挑战，并总结了可能应对这些挑战的技术。最后，我们概述了一些具有潜在前景的未来方向和展望。

    Relation extraction (RE) involves identifying the relations between entities from unstructured texts. RE serves as the foundation for many natural language processing (NLP) applications, such as knowledge graph completion, question answering, and information retrieval. In recent years, deep neural networks have dominated the field of RE and made noticeable progress. Subsequently, the large pre-trained language models (PLMs) have taken the state-of-the-art of RE to a new level. This survey provides a comprehensive review of existing deep learning techniques for RE. First, we introduce RE resources, including RE datasets and evaluation metrics. Second, we propose a new taxonomy to categorize existing works from three perspectives (text representation, context encoding, and triplet prediction). Third, we discuss several important challenges faced by RE and summarize potential techniques to tackle these challenges. Finally, we outline some promising future directions and prospects in this 
    
[^41]: 从算术任务中学习多步推理

    Learning Multi-step Reasoning from Arithmetic Task. (arXiv:2306.01707v1 [cs.CL])

    [http://arxiv.org/abs/2306.01707](http://arxiv.org/abs/2306.01707)

    本文研究如何将相对较小的语言模型注入具有多步推理能力的合成算术任务（MsAT），从而提高LM在数学问题解决上的表现。

    

    数学推理被认为是语言模型（LM）必要的能力。最近的研究表明，大型LM在解决数学问题方面表现出色。成功归因于它们的连续思考（CoT）推理能力，即将复杂问题分解成逐步推理链的能力，但这种能力似乎只出现在具有丰富参数的模型中。本研究研究如何将相对较小的LM与多步推理能力相结合。我们建议通过对合成数据集MsAT（多步算术任务）进行持续的预训练来注入这种能力。我们在四个数学应用题数据集上的实验表明了所提出方法在增强LM数学推理能力方面的有效性。

    Mathematical reasoning is regarded as a necessary ability for Language Models (LMs). Recent works demonstrate large LMs' impressive performance in solving math problems. The success is attributed to their Chain-of-Thought (CoT) reasoning abilities, i.e., the ability to decompose complex questions into step-by-step reasoning chains, but such ability seems only to emerge from models with abundant parameters. This work investigates how to incorporate relatively small LMs with the capabilities of multi-step reasoning. We propose to inject such abilities by continually pre-training LMs on a synthetic dataset MsAT, which stands for Multi-step Arithmetic Task. Our experiments on four math word problem datasets show the effectiveness of the proposed method in enhancing LMs' math reasoning abilities.
    
[^42]: 使用ChatGPT生成的反事实思考启发问题提升编程电子教材

    Enhancing Programming eTextbooks with ChatGPT Generated Counterfactual-Thinking-Inspired Questions. (arXiv:2306.00551v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.00551](http://arxiv.org/abs/2306.00551)

    利用ChatGPT生成反事实思考启发问题，提高编程电子教材的导航性和互动性，激发学生的批判性思维。

    

    数字教材已经成为日常学习任务的重要组成部分。在本文中，我们考虑将数字教材用于编程课程。通常，学生们难以最大限度地利用编程教材，可能的原因是这些教材中用于说明概念的示例代码对学生的互动性不足，因此不足以激发学生进一步探索或理解这些编程示例。在我们的工作中，我们探讨了利用“反事实”问题增强智能教材导航性的想法，使学生对这些程序进行批判性思考并提高可能的程序理解。受以前有关教育领域的反事实思考诱导工作的启发，我们展示了使用GPT生成问题增强数字教科书的可能性。

    Digital textbooks have become an integral part of everyday learning tasks. In this work, we consider the use of digital textbooks for programming classes. Generally, students struggle with utilizing textbooks on programming to the maximum, with a possible reason being that the example programs provided as illustration of concepts in these textbooks don't offer sufficient interactivity for students, and thereby not sufficiently motivating to explore or understand these programming examples better. In our work, we explore the idea of enhancing the navigability of intelligent textbooks with the use of ``counterfactual'' questions, to make students think critically about these programs and enhance possible program comprehension. Inspired from previous works on nudging students on counter factual thinking, we present the possibility to enhance digital textbooks with questions generated using GPT.
    
[^43]: 使预训练模型具有可逆性：从参数到内存高效的微调

    Make Your Pre-trained Model Reversible: From Parameter to Memory Efficient Fine-Tuning. (arXiv:2306.00477v1 [cs.CL])

    [http://arxiv.org/abs/2306.00477](http://arxiv.org/abs/2306.00477)

    本研究尝试实现在预训练语言模型中运用可逆模型实现高效的微调，并发现在初始化微调时保留PLM的起点非常重要。

    

    预训练语言模型（PLM）的参数高效微调已经成为一种非常成功的方法，只需训练少量参数而不会降低性能，并随着PLM越来越大而成为事实上的学习范式。然而，现有的PEFT方法不具备内存效率，因为它们仍需要存储大部分中间激活值以便计算梯度，类似于微调。一个减少激活内存的有效方法是应用可逆模型，这样中间激活值就无需缓存，可以重新计算。然而，将PLM修改为它的可逆变体并进行PEFT并不是一件容易的事，因为可逆模型具有与当前发布的PLM不同的体系结构。本文首先调查现有PEFT方法成功的关键因素，认识到在初始化PEFT时保留PLM的起点是至关重要的。

    Parameter-efficient fine-tuning (PEFT) of pre-trained language models (PLMs) has emerged as a highly successful approach, with training only a small number of parameters without sacrificing performance and becoming the de-facto learning paradigm with the increasing size of PLMs. However, existing PEFT methods are not memory-efficient, because they still require caching most of the intermediate activations for the gradient calculation, akin to fine-tuning. One effective way to reduce the activation memory is to apply a reversible model, so the intermediate activations are not necessary to be cached and can be recomputed. Nevertheless, modifying a PLM to its reversible variant with PEFT is not straightforward, since the reversible model has a distinct architecture from the currently released PLMs. In this paper, we first investigate what is a key factor for the success of existing PEFT methods, and realize that it's essential to preserve the PLM's starting point when initializing a PEFT 
    
[^44]: CapText: 基于大型语言模型的图像内容和描述生成字幕

    CapText: Large Language Model-based Caption Generation From Image Context and Description. (arXiv:2306.00301v1 [cs.LG])

    [http://arxiv.org/abs/2306.00301](http://arxiv.org/abs/2306.00301)

    研究提出了一种基于大型语言模型的图像字幕生成方法，从文本描述和上下文中生成字幕，而不直接处理图像。在CIDEr指标上，优于当前最先进的图像文本对齐模型。

    

    尽管深度学习模型在图像到文本数据集上表现良好，但在实践中难以用于图像字幕生成，因为传统的图片字幕往往是与图像相关的，并且提供有关图像的补充信息，而模型往往生成描述图像视觉特征的“描述”。在字幕生成方面的研究已探索了使用模型在提供对应的描述或上下文信息的情况下生成字幕的方法。我们提出并评估了一种新的方法，该方法利用现有的大型语言模型从文本描述和上下文中生成字幕，而不直接处理图像。我们证明，在微调后，我们的方法在 CIDEr 指标上胜过了当前最先进的图像文本对齐模型，如 OSCAR-VinVL。

    While deep-learning models have been shown to perform well on image-to-text datasets, it is difficult to use them in practice for captioning images. This is because \textit{captions} traditionally tend to be context-dependent and offer complementary information about an image, while models tend to produce \textit{descriptions} that describe the visual features of the image. Prior research in caption generation has explored the use of models that generate captions when provided with the images alongside their respective descriptions or contexts. We propose and evaluate a new approach, which leverages existing large language models to generate captions from textual descriptions and context alone, without ever processing the image directly. We demonstrate that after fine-tuning, our approach outperforms current state-of-the-art image-text alignment models like OSCAR-VinVL on this task on the CIDEr metric.
    
[^45]: MERT:带有大规模自监督训练的声学音乐理解模型

    MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training. (arXiv:2306.00107v1 [cs.SD])

    [http://arxiv.org/abs/2306.00107](http://arxiv.org/abs/2306.00107)

    提出了一个带有大规模自监督训练的音乐理解模型MERT，利用了教师模型并采用了一种优于传统的语音和音频方法的组合方式。

    

    自监督学习（SSL）最近在视觉、文本和语音领域中已被证明是训练通用模型的一种很有前景的范例，对于跨越音乐领域的应用，尤其是对于调性和音高这样的特殊音乐知识的建模颇具挑战性。为了解决这一问题，我们提出了一个基于大规模自监督训练的声学音乐理解模型，即MERT。在我们的探索中，我们确定了更优秀的教师模型组合，这种组合方法在性能方面优于传统的语音和音频方法。

    Self-supervised learning (SSL) has recently emerged as a promising paradigm for training generalisable models on large-scale data in the fields of vision, text, and speech. Although SSL has been proven effective in speech and audio, its application to music audio has yet to be thoroughly explored. This is primarily due to the distinctive challenges associated with modelling musical knowledge, particularly its tonal and pitched characteristics of music. To address this research gap, we propose an acoustic Music undERstanding model with large-scale self-supervised Training (MERT), which incorporates teacher models to provide pseudo labels in the masked language modelling (MLM) style acoustic pre-training. In our exploration, we identified a superior combination of teacher models, which outperforms conventional speech and audio approaches in terms of performance. This combination includes an acoustic teacher based on Residual Vector Quantization - Variational AutoEncoder (RVQ-VAE) and a m
    
[^46]: GPT是否会产生更不准确的翻译?

    Do GPTs Produce Less Literal Translations?. (arXiv:2305.16806v1 [cs.CL])

    [http://arxiv.org/abs/2305.16806](http://arxiv.org/abs/2305.16806)

    本研究比较了GPT和NMT生成翻译的文字积极度差异，发现GPT翻译更不准确，但在MT质量评估指标上表现出相似或更好的分数。

    

    大型语言模型（LLMs），如GPT-3，已经成为通用语言模型，能够处理许多自然语言生成或理解任务。在机器翻译（MT）任务中，已有多项研究探索利用few-shot提示机制从LLMs中引出更好的翻译。然而，人们相对较少地关注这种翻译与标准神经机器翻译（NMT）模型生成翻译的质量差异。本研究从文字对齐和单调性等方面，比较了GPT和NMT生成翻译的文本文字积极度，发现GPT从英语（E-X）翻译的文本更不准确，但在MT质量评估指标上表现出相似或更好的分数。我们证明这一结果在人工评估中也得到了验证。同时，当翻译句子长度增加时，这种差别就尤为显著。

    Large Language Models (LLMs) such as GPT-3 have emerged as general-purpose language models capable of addressing many natural language generation or understanding tasks. On the task of Machine Translation (MT), multiple works have investigated few-shot prompting mechanisms to elicit better translations from LLMs. However, there has been relatively little investigation on how such translations differ qualitatively from the translations generated by standard Neural Machine Translation (NMT) models. In this work, we investigate these differences in terms of the literalness of translations produced by the two systems. Using literalness measures involving word alignment and monotonicity, we find that translations out of English (E-X) from GPTs tend to be less literal, while exhibiting similar or better scores on MT quality metrics. We demonstrate that this finding is borne out in human evaluations as well. We then show that these differences are especially pronounced when translating senten
    
[^47]: 自监督预测编码模型用正交子空间编码说话者和语音信息

    Self-supervised Predictive Coding Models Encode Speaker and Phonetic Information in Orthogonal Subspaces. (arXiv:2305.12464v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12464](http://arxiv.org/abs/2305.12464)

    这篇论文提出了一种自监督预测编码模型，可以把说话者和语音信息编码在正交子空间，进而提出一种新的无需转录的说话者归一化方法，有效消除了说话者信息，并在音位辨别任务中优于之前的基线。

    

    已知自监督语音表示编码了说话者和语音信息，但它们在高维空间中的分布情况仍未深入研究。我们假设它们被编码在正交子空间中，这种特性有助于简单的解缠。应用主成分分析到两个预测编码模型的表示中，我们确定了两个子空间，捕捉到的是说话者和语音变化，并确认它们几乎正交。基于这个特性，我们提出了一种新的说话者归一化方法，它折叠编码说话者信息的子空间，无需转录。探析实验表明，我们的方法有效消除了说话者信息，并在音位辨别任务中优于之前的基线。此外，该方法具有普适性，可用于消除未知说话者的信息。

    Self-supervised speech representations are known to encode both speaker and phonetic information, but how they are distributed in the high-dimensional space remains largely unexplored. We hypothesize that they are encoded in orthogonal subspaces, a property that lends itself to simple disentanglement. Applying principal component analysis to representations of two predictive coding models, we identify two subspaces that capture speaker and phonetic variances, and confirm that they are nearly orthogonal. Based on this property, we propose a new speaker normalization method which collapses the subspace that encodes speaker information, without requiring transcriptions. Probing experiments show that our method effectively eliminates speaker information and outperforms a previous baseline in phone discrimination tasks. Moreover, the approach generalizes and can be used to remove information of unseen speakers.
    
[^48]: 连锁符号提示激发了大型语言模型中的规划能力

    Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models. (arXiv:2305.10276v1 [cs.CL])

    [http://arxiv.org/abs/2305.10276](http://arxiv.org/abs/2305.10276)

    本文提出了自然语言规划（NLP）的基准，旨在研究LLMs在需要理解并在文本中相应进行操作的复杂规划任务中的表现。同时提出了一种新方法CoS，使用简化的符号空间表示法来表示复杂的环境。

    

    本文旨在研究LLMs在需要理解通过自然语言模拟的虚拟空间环境并在文本中相应进行操作的复杂规划任务中的表现。我们提出了一个名为自然语言规划（NLP）的基准，它由一组新颖的任务组成：Brick World、基于NLVR的操作和自然语言导航。我们发现当前流行的LLMs（如ChatGPT）仍然缺乏复杂规划的能力。这引出了一个问题——LLMs是否对自然语言中描述的环境有良好的理解，或者其他替代方法（如符号表示）是否更加简单，因此更容易被LLMs理解？为此，我们提出了一种名为CoS（Chain-of-Symbol Prompting）的新方法，在链式中间思考步骤中使用简化的符号空间表示法来表示复杂的环境。CoS易于使用，不需要对LLMs进行额外的培训。

    In this paper, we take the initiative to investigate the performance of LLMs on complex planning tasks that require LLMs to understand a virtual spatial environment simulated via natural language and act correspondingly in text. We propose a benchmark named Natural Language Planning (NLP) composed of a set of novel tasks: Brick World, NLVR-based Manipulations, and Natural Language Navigation. We found that current popular LLMs such as ChatGPT still lack abilities in complex planning. This arises a question -- do the LLMs have a good understanding of the environments described in natural language, or maybe other alternatives such as symbolic representations are neater and hence better to be understood by LLMs? To this end, we propose a novel method called CoS (Chain-of-Symbol Prompting) that represents the complex environments with condensed symbolic spatial representations during the chained intermediate thinking steps. CoS is easy to use and does not need additional training on LLMs. 
    
[^49]: 解释性微调使模型对虚假提示更强韧

    Explanation-based Finetuning Makes Models More Robust to Spurious Cues. (arXiv:2305.04990v1 [cs.CL])

    [http://arxiv.org/abs/2305.04990](http://arxiv.org/abs/2305.04990)

    本文提出一种新型方法——解释性微调，通过让模型在给出答案的同时生成支持该答案的自由文本解释，来减轻LLMs依赖虚假关联，使得模型对虚假提示更加强韧，并具有广泛适用性。

    

    大型语言模型（LLMs）非常强大，有时会学习到标签和与任务无关的特征之间的相关性，导致在分布外数据上泛化能力差。我们提出解释性微调作为减轻LLMs依赖虚假关联的一种新的通用方法。与标准微调只在给定输入的情况下预测答案不同，我们微调模型以生成支持其答案的自由文本解释。为了评估我们的方法，我们在人工构建的训练集上微调模型，该训练集包含不同类型的虚假提示，并在没有这些提示的测试集上进行测试。与标准微调相比，我们的方法在四个分类任务的准确性下降方面使模型极其强韧：ComVE（+1.2），CREAK（+9.1），e-SNLI（+15.4）和SBIC（+6.5）。此外，我们的方法与模型生成的解释同样有效，这意味着我们的方法具有广泛的适用性。

    Large Language Models (LLMs) are so powerful that they sometimes learn correlations between labels and features that are irrelevant to the task, leading to poor generalization on out-of-distribution data. We propose explanation-based finetuning as a novel and general approach to mitigate LLMs' reliance on spurious correlations. Unlike standard finetuning where the model only predicts the answer given the input, we finetune the model to additionally generate a free-text explanation supporting its answer. To evaluate our method, we finetune the model on artificially constructed training sets containing different types of spurious cues, and test it on a test set without these cues. Compared to standard finetuning, our method makes models remarkably more robust against spurious cues in terms of accuracy drop across four classification tasks: ComVE (+1.2), CREAK (+9.1), e-SNLI (+15.4), and SBIC (+6.5). Moreover, our method works equally well with explanations generated by the model, implyin
    
[^50]: SI-LSTM: 用于对话情感识别的说话人混合长短期记忆和跨模态注意力机制

    SI-LSTM: Speaker Hybrid Long-short Term Memory and Cross Modal Attention for Emotion Recognition in Conversation. (arXiv:2305.03506v1 [cs.CL])

    [http://arxiv.org/abs/2305.03506](http://arxiv.org/abs/2305.03506)

    SI-LSTM是一种用于对话情感识别的循环结构，可以追踪不同说话人的情感状态，从而增强对话情感学习。

    

    跨模态的对话情感识别对于智能医疗、对话人工智能和聊天历史观点挖掘等应用至关重要。本文提出了一种基于说话人信息增强长短期记忆（SI-LSTM）的循环结构，可以追踪不同说话人的情感状态，从而增强对话情感学习。

    Emotion Recognition in Conversation~(ERC) across modalities is of vital importance for a variety of applications, including intelligent healthcare, artificial intelligence for conversation, and opinion mining over chat history. The crux of ERC is to model both cross-modality and cross-time interactions throughout the conversation. Previous methods have made progress in learning the time series information of conversation while lacking the ability to trace down the different emotional states of each speaker in a conversation. In this paper, we propose a recurrent structure called Speaker Information Enhanced Long-Short Term Memory (SI-LSTM) for the ERC task, where the emotional states of the distinct speaker can be tracked in a sequential way to enhance the learning of the emotion in conversation. Further, to improve the learning of multimodal features in ERC, we utilize a cross-modal attention component to fuse the features between different modalities and model the interaction of the 
    
[^51]: 语言选择的政治：俄乌战争如何影响乌克兰人在 Twitter 上的语言使用。

    The Politics of Language Choice: How the Russian-Ukrainian War Influences Ukrainians' Language Use on Twitter. (arXiv:2305.02770v1 [cs.CY])

    [http://arxiv.org/abs/2305.02770](http://arxiv.org/abs/2305.02770)

    本文研究了俄乌战争期间乌克兰人在 Twitter 上的语言使用，发现在战争爆发前已经出现从俄语向乌克兰语转变的趋势，而战争爆发后这种趋势加速了，并且许多使用俄语的用户在战争期间转变成使用乌克兰语。

    

    语言使用天生是政治的，并经常用作文化身份的载体，同时也是国家建设的基础。本文研究了俄乌战争期间（2020年1月至2022年10月），基于超过62,000位用户发布的400万条地理标记推文中，乌克兰公民的语言选择和推文活动。使用统计模型，区分了Twitter上用户的流入流出所引起的样本效应和用户行为变化所引起的行为效应。我们观察到，在战争爆发之前已经有一个稳定的从俄语向乌克兰语的转变，而这一过程在战争爆发后迅速加速。我们将这些变化主要归因于用户行为的改变。值得注意的是，许多使用俄语的用户在战争期间会转变成使用乌克兰语。

    The use of language is innately political and often a vehicle of cultural identity as well as the basis for nation building. Here, we examine language choice and tweeting activity of Ukrainian citizens based on more than 4 million geo-tagged tweets from over 62,000 users before and during the Russian-Ukrainian War, from January 2020 to October 2022. Using statistical models, we disentangle sample effects, arising from the in- and outflux of users on Twitter, from behavioural effects, arising from behavioural changes of the users. We observe a steady shift from the Russian language towards the Ukrainian language already before the war, which drastically speeds up with its outbreak. We attribute these shifts in large part to users' behavioural changes. Notably, we find that many Russian-tweeting users perform a hard-switch to Ukrainian as a result of the war.
    
[^52]: CCpdf：从网络爬虫数据中构建高质量的视觉丰富文档语料库

    CCpdf: Building a High Quality Corpus for Visually Rich Documents from Web Crawl Data. (arXiv:2304.14953v1 [cs.CL])

    [http://arxiv.org/abs/2304.14953](http://arxiv.org/abs/2304.14953)

    本文提出了一个流程，通过使用Common Crawl，从互联网上收集PDF文件，构建一个大规模、多样化、多语言的语料库。我们分享了一个CCpdf语料库，为研究人员提供了进行视觉丰富文档研究的机会。

    

    最近几年，文档理解领域取得了很大进展。这些进展的一部分得益于使用预训练于大量文档的语言模型。然而，文档理解领域中使用的预训练语料库通常单一领域、单语言、或不公开。本文旨在提出一种有效的流程，通过使用Common Crawl，从互联网上收集PDF文件，构建一个大规模、多样化、多语言的语料库。我们对构建流程的所有步骤进行了广泛分析，并提出了一个在数据质量和处理时间之间平衡的解决方案。同时，我们还分享了一个CCpdf语料库，其中包括PDF文件的索引和下载脚本，可以用于语言模型预训练。本文所发布的数据集和工具为研究人员提供了进行视觉丰富文档研究的机会。

    In recent years, the field of document understanding has progressed a lot. A significant part of this progress has been possible thanks to the use of language models pretrained on large amounts of documents. However, pretraining corpora used in the domain of document understanding are single domain, monolingual, or nonpublic. Our goal in this paper is to propose an efficient pipeline for creating a big-scale, diverse, multilingual corpus of PDF files from all over the Internet using Common Crawl, as PDF files are the most canonical types of documents as considered in document understanding. We analysed extensively all of the steps of the pipeline and proposed a solution which is a trade-off between data quality and processing time. We also share a CCpdf corpus in a form or an index of PDF files along with a script for downloading them, which produces a collection useful for language model pretraining. The dataset and tools published with this paper offer researchers the opportunity to 
    
[^53]: 一种用于学习语法的逻辑词嵌入模型

    A logical word embedding for learning grammar. (arXiv:2304.14590v1 [cs.CL])

    [http://arxiv.org/abs/2304.14590](http://arxiv.org/abs/2304.14590)

    这篇论文介绍了一种逻辑语法嵌入模型(LGE)，它可以从文本语料库中无监督进行推理，产生简明易懂的输出，能够透明地生成新句子，并且可以从仅有一百句话的语料中进行学习。

    

    我们介绍了一种逻辑语法嵌入(LGE)模型，该模型受到了组合语法和类别语法的启发，可以从文本语料库中对词汇类别和句法规则进行无监督推理。 LGE产生了简明易懂的输出，能够透明地生成新句子，并且可以从仅有一百句话的语料中进行学习。

    We introduce the logical grammar emdebbing (LGE), a model inspired by pregroup grammars and categorial grammars to enable unsupervised inference of lexical categories and syntactic rules from a corpus of text. LGE produces comprehensible output summarizing its inferences, has a completely transparent process for producing novel sentences, and can learn from as few as a hundred sentences.
    
[^54]: NAIST-SIC-Aligned：自动对齐的英日同声传译语料库

    NAIST-SIC-Aligned: Automatically-Aligned English-Japanese Simultaneous Interpretation Corpus. (arXiv:2304.11766v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.11766](http://arxiv.org/abs/2304.11766)

    本论文提出了NAIST-SIC-Aligned，这是一个自动对齐的英日平行同声传译数据集。该论文使用了一个两阶段的对齐方法，经过定量或定性验证的每个步骤，以确保语料库的质量。这是第一个开源的大规模平行SI数据集。

    

    如何利用同声传译（SI）数据来影响同声机器翻译（SiMT）仍然是一个问题。由于缺乏大规模的训练语料库，研究受到了限制。本文介绍了NAIST-SIC-Aligned，这是一个自动对齐的英日平行同声传译数据集。通过一个非对齐语料库NAIST-SIC开始，我们提出了一个两阶段对齐方法，使语料库具有平行性，从而适合模型训练。第一阶段是粗略对齐，在此步骤中，我们在源语言和目标语言之间执行一个多对多的映射；第二阶段是细粒度对齐，在此步骤中，我们执行语句内部和语句间过滤来提高对齐对的质量。为确保语料库的质量，每个步骤都经过了定量或定性的验证。这是文献中第一个开源的大规模平行SI数据集。我们还手动精选了一个小型测试集用于评估目的。

    It remains a question that how simultaneous interpretation (SI) data affects simultaneous machine translation (SiMT). Research has been limited due to the lack of a large-scale training corpus. In this work, we aim to fill in the gap by introducing NAIST-SIC-Aligned, which is an automatically-aligned parallel English-Japanese SI dataset. Starting with a non-aligned corpus NAIST-SIC, we propose a two-stage alignment approach to make the corpus parallel and thus suitable for model training. The first stage is coarse alignment where we perform a many-to-many mapping between source and target sentences, and the second stage is fine-grained alignment where we perform intra- and inter-sentence filtering to improve the quality of aligned pairs. To ensure the quality of the corpus, each step has been validated either quantitatively or qualitatively. This is the first open-sourced large-scale parallel SI dataset in the literature. We also manually curated a small test set for evaluation purpose
    
[^55]: 大型语言模型的多方面重复抑制和内容调控

    Multi-aspect Repetition Suppression and Content Moderation of Large Language Models. (arXiv:2304.10611v1 [cs.CL])

    [http://arxiv.org/abs/2304.10611](http://arxiv.org/abs/2304.10611)

    本文介绍了一种使用标记和序列级别的不可能性损失，以及在培训期间的重复惩罚、推理和后处理等多层面方法来抑制大型语言模型中的重复，并避免生成攻击性内容的能力。

    

    自然语言生成在NLP领域是最具影响力的领域之一，近年来由大型语言模型(LLMs)带来的进步得到了人们的关注。作为编写助手应用程序的关键工具，它们通常容易复制或扩展输入中提供的具有攻击性的内容。在低资源数据环境中，它们也可能导致输出重复的问题。本文介绍了一种精确和非精确重复抑制的结合方法，使用标记和序列级别的不可能性损失，培训期间的重复惩罚、推理和后处理。我们进一步探讨了多级不可能性损失的范围，以赋予模型避免从一开始产生攻击性词汇和短语的能力。最后，通过全面的实验，在多个度量标准上证明了我们提出的方法的有效性。

    Natural language generation is one of the most impactful fields in NLP, and recent years have witnessed its evolution brought about by large language models (LLMs). As the key instrument for writing assistance applications, they are generally prone to replicating or extending offensive content provided in the input. In low-resource data regime, they can also lead to repetitive outputs (Holtzman et al., 2019) [1]. Usually, offensive content and repetitions are mitigated with post-hoc methods, including n-gram level blocklists, top-k and nucleus sampling. In this paper, we introduce a combination of exact and non-exact repetition suppression using token and sequence level unlikelihood loss, repetition penalty during training, inference, and post-processing respectively. We further explore multi-level unlikelihood loss to the extent that it endows the model with abilities to avoid generating offensive words and phrases from the beginning. Finally, with comprehensive experiments, we demons
    
[^56]: G2T: 基于预训练语言模型和社区检测的主题建模框架

    G2T: A simple but versatile framework for topic modeling based on pretrained language model and community detection. (arXiv:2304.06653v1 [cs.CL])

    [http://arxiv.org/abs/2304.06653](http://arxiv.org/abs/2304.06653)

    G2T是一种基于预训练语言模型和社区检测的主题建模框架，自动评估表明，G2T在多个数据集上均与当前最先进的方法相比表现更好。

    

    先前的研究表明，基于聚类的主题模型能够通过适当的词语筛选方法聚类高质量的句子嵌入，生成比生成式概率主题模型更好的主题。然而，这些方法存在选择合适参数的困难以及不完整的模型忽略单词与主题及主题与文本之间的定量关系的问题。为了解决这些问题，我们提出了一种简洁但有效的主题建模框架，即图主题（G2T）。

    It has been reported that clustering-based topic models, which cluster high-quality sentence embeddings with an appropriate word selection method, can generate better topics than generative probabilistic topic models. However, these approaches suffer from the inability to select appropriate parameters and incomplete models that overlook the quantitative relation between words with topics and topics with text. To solve these issues, we propose graph to topic (G2T), a simple but effective framework for topic modelling. The framework is composed of four modules. First, document representation is acquired using pretrained language models. Second, a semantic graph is constructed according to the similarity between document representations. Third, communities in document semantic graphs are identified, and the relationship between topics and documents is quantified accordingly. Fourth, the word--topic distribution is computed based on a variant of TFIDF. Automatic evaluation suggests that G2
    
[^57]: PDF-VQA: 一个新的用于PDF文件真实世界VQA的数据集

    PDF-VQA: A New Dataset for Real-World VQA on PDF Documents. (arXiv:2304.06447v1 [cs.CV])

    [http://arxiv.org/abs/2304.06447](http://arxiv.org/abs/2304.06447)

    该研究提出了一个新的文档VQA数据集PDF-VQA，以多个页面的完整文档作为研究对象，通过机器学习模型识别与处理文档元素、结构和内容等方面，为解决真实世界中的文档理解问题提供新的资源。

    

    基于文档的视觉问答（VQA）研究文档图像的文档理解问题。我们提出了一个新的基于文档的VQA数据集PDF-VQA，从文档元素识别、文档布局结构理解以及上下文理解和关键信息提取等各个方面全面探讨文档理解问题。我们的PDF-VQA数据集将文档理解的规模从单个文档页面扩展到询问多个页面的完整文档。我们还提出了一个新的基于图形的VQA模型，明确地集成了不同文档元素之间的空间和层次结构关系，以提高文档结构的理解能力。该性能与多个基线模型相比较，可以适用于不同的问题类型和任务。

    Document-based Visual Question Answering examines the document understanding of document images in conditions of natural language questions. We proposed a new document-based VQA dataset, PDF-VQA, to comprehensively examine the document understanding from various aspects, including document element recognition, document layout structural understanding as well as contextual understanding and key information extraction. Our PDF-VQA dataset extends the current scale of document understanding that limits on the single document page to the new scale that asks questions over the full document of multiple pages. We also propose a new graph-based VQA model that explicitly integrates the spatial and hierarchically structural relationships between different document elements to boost the document structural understanding. The performances are compared with several baselines over different question types and tasks\footnote{The full dataset will be released after paper acceptance.
    
[^58]: oBERTa: 通过改进初始化、蒸馏和剪枝来提高稀疏迁移学习

    oBERTa: Improving Sparse Transfer Learning via improved initialization, distillation, and pruning regimes. (arXiv:2303.17612v1 [cs.CL])

    [http://arxiv.org/abs/2303.17612](http://arxiv.org/abs/2303.17612)

    oBERTa是一组易于使用的语言模型，通过改进初始化、蒸馏、剪枝等技术，可以在不需要模型压缩方面的专业知识的情况下提高稀疏迁移学习的效率和准确性。

    

    本文介绍了oBERTa语言模型的范围，它是一组易于使用的语言模型，允许自然语言处理（NLP）从业者在不需要模型压缩方面的专业知识的情况下获得3.8到24.3倍的更快速的模型。oBERTa扩展了现有的剪枝、知识蒸馏和量化工作，并利用冻结的嵌入来改进知识蒸馏，并改进模型初始化，以在广泛的传递任务上提供更高的准确性。在生成oBERTa时，我们探索了高度优化的RoBERTa与BERT在预训练和微调期间剪枝方面的不同之处，并发现它在微调期间不太适合压缩。我们探索了oBERTa在七个具有代表性的NLP任务上的使用，并发现改进的压缩技术使得经过剪枝的oBERTa模型能够匹配BERTBASE的性能，并超过SQUAD V1.1问答数据的Prune OFA Large的性能。

    In this paper, we introduce the range of oBERTa language models, an easy-to-use set of language models, which allows Natural Language Processing (NLP) practitioners to obtain between 3.8 and 24.3 times faster models without expertise in model compression. Specifically, oBERTa extends existing work on pruning, knowledge distillation, and quantization and leverages frozen embeddings to improve knowledge distillation, and improved model initialization to deliver higher accuracy on a a broad range of transfer tasks. In generating oBERTa, we explore how the highly optimized RoBERTa differs from the BERT with respect to pruning during pre-training and fine-tuning and find it less amenable to compression during fine-tuning. We explore the use of oBERTa on a broad seven representative NLP tasks and find that the improved compression techniques allow a pruned oBERTa model to match the performance of BERTBASE and exceed the performance of Prune OFA Large on the SQUAD V1.1 Question Answering data
    
[^59]: 通过f-散度最小化对齐语言模型与偏好

    Aligning Language Models with Preferences through f-divergence Minimization. (arXiv:2302.08215v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.08215](http://arxiv.org/abs/2302.08215)

    本文提出一种新的方法f-DPG，用于对齐语言模型和偏好，该方法适用于评估任何目标分布，统一了现有的各种框架和逼近方法。

    

    对齐语言模型和偏好可以被看作是对目标分布进行逼近，以期达到某种所需行为。现有的方法在目标分布的函数形式和用于逼近目标分布的算法上存在差异。本文提出了一种新方法f-DPG，该方法允许使用任何可评估的f-散度逼近任何目标分布，从而统一了现有的各种框架和逼近方法。我们展示了各种散度目标的实际好处，并证明了没有普适的最佳选择。

    Aligning language models with preferences can be posed as approximating a target distribution representing some desired behavior. Existing approaches differ both in the functional form of the target distribution and the algorithm used to approximate it. For instance, Reinforcement Learning from Human Feedback (RLHF) corresponds to minimizing a reverse KL from an implicit target distribution arising from a KL penalty in the objective. On the other hand, Generative Distributional Control (GDC) has an explicit target distribution and minimizes a forward KL from it using the Distributional Policy Gradient (DPG) algorithm. In this paper, we propose a new approach, f-DPG, which allows the use of any f-divergence to approximate any target distribution that can be evaluated. f-DPG unifies both frameworks (RLHF, GDC) and the approximation methods (DPG, RL with KL penalties). We show the practical benefits of various choices of divergence objectives and demonstrate that there is no universally o
    
[^60]: 基于局部差分隐私的文本重写DP-BART翻译

    DP-BART for Privatized Text Rewriting under Local Differential Privacy. (arXiv:2302.07636v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2302.07636](http://arxiv.org/abs/2302.07636)

    本文提出了一个新的系统DP-BART，采用局部差分隐私的方法进行文本重写，优于现有的LDP系统，大大减少了需要DP保证的噪音量，实验表明在下游文本分类任务中有效。

    

    采用局部差分隐私（LDP）的私密文本重写是一种最近的方法，可以在正式保证对个人的隐私保护的同时，共享敏感的文本文档。然而，现有的系统存在许多问题，如形式上数学缺陷、不切实际的隐私保证、仅针对个别单词的私密化，以及缺乏透明度和可重复性等。本文提出了一个新系统“DP-BART”，在很大程度上优于现有的LDP系统。我们的方法使用了一种新的剪辑方法、迭代剪枝以及进一步培训内部表示，极大地减少了需要DP保证的噪音量。我们在五个大小不同的文本数据集上运行实验，在不同的隐私保证下重写这些数据集，并评估经过重写的文本的下游文本分类任务。最后，我们对私密文本重写方法及其限制进行了全面的讨论，包括严格性问题。

    Privatized text rewriting with local differential privacy (LDP) is a recent approach that enables sharing of sensitive textual documents while formally guaranteeing privacy protection to individuals. However, existing systems face several issues, such as formal mathematical flaws, unrealistic privacy guarantees, privatization of only individual words, as well as a lack of transparency and reproducibility. In this paper, we propose a new system 'DP-BART' that largely outperforms existing LDP systems. Our approach uses a novel clipping method, iterative pruning, and further training of internal representations which drastically reduces the amount of noise required for DP guarantees. We run experiments on five textual datasets of varying sizes, rewriting them at different privacy guarantees and evaluating the rewritten texts on downstream text classification tasks. Finally, we thoroughly discuss the privatized text rewriting approach and its limitations, including the problem of the stric
    
[^61]: 大型语言模型容易受到无关上下文的干扰

    Large Language Models Can Be Easily Distracted by Irrelevant Context. (arXiv:2302.00093v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.00093](http://arxiv.org/abs/2302.00093)

    本文研究了大型语言模型对无关上下文的干扰性。他们使用一个带有无关信息的算术推理数据集GSM-IC来衡量这种可干扰性。研究发现当包含无关信息时，模型性能会急剧下降，但使用自我一致性进行解码并添加一个指令可以缓解这一缺陷。

    

    大型语言模型已经在各种自然语言处理任务中取得了令人瞩目的表现。然而，迄今为止，它们主要在所有输入上下文信息都与解决任务相关的基准测试上进行了评估。在本文中，我们研究了大型语言模型的可干扰性，即不相关上下文如何影响模型的问题解决准确性。特别地，我们引入了一个带有无关信息的算术推理数据集GSM-IC。我们使用这个基准测试来衡量最尖端的提示技术在大型语言模型中可干扰性，发现当包含无关信息时，模型性能会急剧下降。我们还确定了几种缓解这种不足的方法，如使用自我一致性进行解码，并在提示中添加一条指令，告诉语言模型忽略无关信息。

    Large language models have achieved impressive performance on various natural language processing tasks. However, so far they have been evaluated primarily on benchmarks where all information in the input context is relevant for solving the task. In this work, we investigate the distractibility of large language models, i.e., how the model problem-solving accuracy can be influenced by irrelevant context. In particular, we introduce Grade-School Math with Irrelevant Context (GSM-IC), an arithmetic reasoning dataset with irrelevant information in the problem description. We use this benchmark to measure the distractibility of cutting-edge prompting techniques for large language models, and find that the model performance is dramatically decreased when irrelevant information is included. We also identify several approaches for mitigating this deficiency, such as decoding with self-consistency and adding to the prompt an instruction that tells the language model to ignore the irrelevant in
    
[^62]: AutoPEFT：用于参数高效微调的自动配置搜索

    AutoPEFT: Automatic Configuration Search for Parameter-Efficient Fine-Tuning. (arXiv:2301.12132v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.12132](http://arxiv.org/abs/2301.12132)

    AutoPEFT是一个自动化的PEFT（参数高效微调）配置搜索方法，它能够自动地找到最佳的PEFT模块和体系结构，以优化任务的性能和参数效率。在典型的NLP任务中，AutoPEFT表现出比手动设计更好的性能。

    

    大型预训练语言模型通过专门的微调用于下游NLP任务，但这样的过程可能很昂贵。最近，参数高效微调（PEFT）方法通过更新比完整模型微调（FFT）少得多的参数，实现了强大的任务性能。然而，在PEFT配置方面做出明智的设计选择是不容易的，例如它们的体系结构、可调参数的数量，甚至是PEFT模块插入的图层。因此，目前的手动设计配置很可能在性能效率权衡方面是次优的。受神经架构搜索的进展启发，我们提出了AutoPEFT来自动选择PEFT配置：首先设计具有多个代表性PEFT模块的表达配置搜索空间。然后使用多目标贝叶斯优化进行低成本的设置，从而发现优化任务性能和参数效率的Pareto优化配置。我们在几个典型的NLP任务，包括文本分类、问答和命名实体识别上评估了AutoPEFT，并展示了其优于手动设计基线的性能。

    Large pretrained language models are widely used in downstream NLP tasks via task-specific fine-tuning, but such procedures can be costly. Recently, Parameter-Efficient Fine-Tuning (PEFT) methods have achieved strong task performance while updating a much smaller number of parameters compared to full model fine-tuning (FFT). However, it is non-trivial to make informed design choices on the PEFT configurations, such as their architecture, the number of tunable parameters, and even the layers in which the PEFT modules are inserted. Consequently, it is highly likely that the current, manually designed configurations are suboptimal in terms of their performance-efficiency trade-off. Inspired by advances in neural architecture search, we propose AutoPEFT for automatic PEFT configuration selection: we first design an expressive configuration search space with multiple representative PEFT modules as building blocks. Using multi-objective Bayesian optimisation in a low-cost setup, we then disc
    
[^63]: 论语言输入贫乏程度对于神经网络层级概括能力的影响的评估

    How poor is the stimulus? Evaluating hierarchical generalization in neural networks trained on child-directed speech. (arXiv:2301.11462v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.11462](http://arxiv.org/abs/2301.11462)

    该研究探讨了在类似于儿童语言输入数据的语料库上训练的两种神经网络的层级概括能力。结果表明这些模型概括的能力与正确的层级规则不符，从结论可以看出，仅从语料库中进行类人概括需要比现有模型更强的偏见。

    

    儿童对于学习语法时通常会选择层次性规则，人们想知道这种偏好是由于学习层级结构的偏差还是其他一些情况。通过训练两种不带层级偏见的神经网络，我们探讨了这些可能性。结果表明，尽管两种模型表现良好，但它们概括的能力更符合错误线性规则而不是正确的层级规则。因此，我们得出结论，仅仅从语料库中进行类人概括需要比现有模型更强的偏见。

    When acquiring syntax, children consistently choose hierarchical rules over competing non-hierarchical possibilities. Is this preference due to a learning bias for hierarchical structure, or due to more general biases that interact with hierarchical cues in children's linguistic input? We explore these possibilities by training LSTMs and Transformers - two types of neural networks without a hierarchical bias - on data similar in quantity and content to children's linguistic input: text from the CHILDES corpus. We then evaluate what these models have learned about English yes/no questions, a phenomenon for which hierarchical structure is crucial. We find that, though they perform well at capturing the surface statistics of child-directed speech (as measured by perplexity), both model types generalize in a way more consistent with an incorrect linear rule than the correct hierarchical rule. These results suggest that human-like generalization from text alone requires stronger biases than
    
[^64]: 大型语言模型的水印技术

    A Watermark for Large Language Models. (arXiv:2301.10226v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.10226](http://arxiv.org/abs/2301.10226)

    本文提出了一种在大型语言模型中实现水印技术的方法，该技术可以在不降低文本质量的前提下嵌入信号，且可以使用高效的开源算法进行检测，并且该技术十分鲁棒和安全。

    

    通过在生成的文本中嵌入信号，即将水印技术应用于模型输出，可以减轻大型语言模型潜在的危害。我们提出了一种专有语言模型的水印技术框架。水印可以嵌入到文本中，对文本质量的影响可以忽略不计，并且可以使用高效的开源算法在不访问语言模型API或参数的情况下进行检测。水印技术通过在生成单词之前选择一组随机的“绿色”标记，然后在抽样过程中软性地推广使用这些标记。我们提出了一个可解释的P值统计检验方法，用于检测水印技术， 并推导了一个信息论框架来分析水印技术的敏感性。我们使用Open Pretrained Transformer（OPT）家族的一个数十亿参数模型来测试水印技术，并讨论了其鲁棒性和安全性。

    Potential harms of large language models can be mitigated by watermarking model output, i.e., embedding signals into generated text that are invisible to humans but algorithmically detectable from a short span of tokens. We propose a watermarking framework for proprietary language models. The watermark can be embedded with negligible impact on text quality, and can be detected using an efficient open-source algorithm without access to the language model API or parameters. The watermark works by selecting a randomized set of "green" tokens before a word is generated, and then softly promoting use of green tokens during sampling. We propose a statistical test for detecting the watermark with interpretable p-values, and derive an information-theoretic framework for analyzing the sensitivity of the watermark. We test the watermark using a multi-billion parameter model from the Open Pretrained Transformer (OPT) family, and discuss robustness and security.
    
[^65]: NarrowBERT: 加速掩码语言模型的预训练和推理

    NarrowBERT: Accelerating Masked Language Model Pretraining and Inference. (arXiv:2301.04761v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.04761](http://arxiv.org/abs/2301.04761)

    NarrowBERT是一种改进的Transformer编码器，通过稀疏化模型并仅对掩码令牌进行操作，在掩码语言模型预训练中提高了$2\times$以上的吞吐量，并在推理时将吞吐量提高了多达$3.5\times$。NarrowBERT在几种自然语言处理任务中的性能与标准BERT相当。

    

    大规模语言模型预训练是自监督学习在自然语言处理中非常成功的形式，但随着模型和预训练语料库的不断增大，执行预训练的成本变得越来越高。我们提出了NarrowBERT，一种改进的Transformer编码器，通过$2\times$以上的速度提高了掩码语言模型预训练的吞吐量。NarrowBERT稀疏化了Transformer模型，在预训练期间，自注意力查询和前馈层仅对每个句子的掩码令牌进行操作，而不是像通常的Transformer编码器那样对所有令牌进行操作。我们还展示了NarrowBERT在推理时将吞吐量提高了多达$3.5\times$，在像MNLI这样的句子编码任务上，性能几乎没有或没有明显降低。最后，我们考察了NarrowBERT在IMDB和Amazon评论分类以及CoNLL NER任务上的性能，并展示其与标准BERT的性能相当。

    Large-scale language model pretraining is a very successful form of self-supervised learning in natural language processing, but it is increasingly expensive to perform as the models and pretraining corpora have become larger over time. We propose NarrowBERT, a modified transformer encoder that increases the throughput for masked language model pretraining by more than $2\times$. NarrowBERT sparsifies the transformer model such that the self-attention queries and feedforward layers only operate on the masked tokens of each sentence during pretraining, rather than all of the tokens as with the usual transformer encoder. We also show that NarrowBERT increases the throughput at inference time by as much as $3.5\times$ with minimal (or no) performance degradation on sentence encoding tasks like MNLI. Finally, we examine the performance of NarrowBERT on the IMDB and Amazon reviews classification and CoNLL NER tasks and show that it is also comparable to standard BERT performance.
    
[^66]: DISCO: 利用大型语言模型提炼短语反事实数据

    DISCO: Distilling Phrasal Counterfactuals with Large Language Models. (arXiv:2212.10534v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10534](http://arxiv.org/abs/2212.10534)

    本文提出了一种名为DISCO的自动化方法，可利用大型语言模型生成高质量反事实数据，用于训练模型，以实现自然语言推理等任务的因果推理，相比于传统数据训练方法，效果更好且可扩展和高效。

    

    利用反事实增广数据训练的模型可以学习任务的因果结构表达，从而实现稳健的泛化。但对于大多数任务而言，高质量的反事实数据很少且难以大规模生成。当使用众包方法进行生成时，通常规模和多样性都有限。当使用有监督方法时，要将其扩展到新的反事实维度是计算上昂贵的。在这项工作中，我们提出了DISCO（DIStilled COunterfactual Data），一种新的方法，可在规模上自动生成高质量的反事实数据。DISCO工程师使用大型通用语言模型生成提示以生成短语扰动。然后，特定于任务的教师模型过滤这些生成，以提取高质量的反事实数据。虽然是面向任务的，我们应用我们的流程来处理自然语言推理（NLI）任务，并发现在像NLI压力测试这样的挑战性评估中，用DISCO生成的数据训练的相对较小的学生模型比使用传统（非反事实增强）的数据训练的大模型效果更好。我们的方法提供了一个可扩展和高效的解决方案，用于生成反事实数据，为各种自然语言任务的因果推理提供了可能。

    Models trained with counterfactually augmented data learn representations of the causal structure of tasks, enabling robust generalization. However, high-quality counterfactual data is scarce for most tasks and not easily generated at scale. When crowdsourced, such data is typically limited in scale and diversity; when generated using supervised methods, it is computationally expensive to extend to new counterfactual dimensions. In this work, we introduce DISCO (DIStilled COunterfactual Data), a new method for automatically generating high quality counterfactual data at scale. DISCO engineers prompts to generate phrasal perturbations with a large general language model. Then, a task-specific teacher model filters these generations to distill high-quality counterfactual data. While task-agnostic, we apply our pipeline to the task of natural language inference (NLI) and find that on challenging evaluations such as the NLI stress test, comparatively smaller student models trained with DIS
    
[^67]: 文本到图像生成中的空间关系基准测试

    Benchmarking Spatial Relationships in Text-to-Image Generation. (arXiv:2212.10015v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.10015](http://arxiv.org/abs/2212.10015)

    本文研究了文本到图像生成中模型生成正确空间关系的能力，并提出了一个评估指标VISOR以衡量生成图像的准确性。实验发现当前T2I模型尽管可以生成高度逼真的图像，但其空间上准确的图像能力仍然不足，特别是在空间谓词和场景关系理解方面。

    

    空间理解是计算机视觉的基本方面，对于人类级别的图像推理至关重要，因此是基础语言理解的重要组成部分。最近的文本到图像合成（T2I）模型在逼真性方面取得了前所未有的进展，但它们的可靠空间理解能力尚不清楚。我们调查了T2I模型生成正确空间关系的能力，并提出了VISOR评估指标，它捕捉了文本中描述的空间关系在图像中是否准确生成。为了基准现有模型，我们引入了一个包含描述两个对象及它们之间空间关系的句子数据集SR2D。我们构建了一个自动化评估流程来识别物体及其空间关系，并在大规模评估T2I模型时采用它。我们的实验发现了一个令人惊讶的发现，也就是尽管最新的T2I模型能够产生高度逼真的图像，但它们生成空间上准确的图像能力仍然不足。具体而言，我们发现现有模型在空间谓词（如'在前面'和'在后面'）方面存在困难，并且在场景的关系理解方面也有困难。

    Spatial understanding is a fundamental aspect of computer vision and integral for human-level reasoning about images, making it an important component for grounded language understanding. While recent text-to-image synthesis (T2I) models have shown unprecedented improvements in photorealism, it is unclear whether they have reliable spatial understanding capabilities. We investigate the ability of T2I models to generate correct spatial relationships among objects and present VISOR, an evaluation metric that captures how accurately the spatial relationship described in text is generated in the image. To benchmark existing models, we introduce a dataset, SR2D, that contains sentences describing two objects and the spatial relationship between them. We construct an automated evaluation pipeline to recognize objects and their spatial relationships, and employ it in a large-scale evaluation of T2I models. Our experiments reveal a surprising finding that, although state-of-the-art T2I models 
    
[^68]: DuNST：双重噪声自训练用于半监督可控文本生成

    DuNST: Dual Noisy Self Training for Semi-Supervised Controllable Text Generation. (arXiv:2212.08724v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.08724](http://arxiv.org/abs/2212.08724)

    DuNST是一种双重噪声自训练方法，用于半监督可控文本生成。该方法通过扰动生成的伪文本，将伪文本标记和无标签的伪标签结合使用，并且可以缓解先前学习到的空间的限制性泛化边界。

    

    对于语言理解，自训练（ST）通过增加预训练语言模型的微调次数来扩充标记数据不足的情况，有了较大发展。然而，在带属性控制的语言生成中，将ST纳入其中仍然具有挑战性。只能通过自动生成的伪文本进行增强的生成模型会过度强调先前学习到的空间，受到受限的泛化边界所困扰。我们重新思考ST，提出了一种新的方法DuNST来缓解这个问题。DuNST通过一个共享变分自编码器来联合生成文本和对应的分类标签，并使用两种灵活的噪声来扰乱生成的伪文本。这样，我们的模型可以构建并利用来自给定标签的伪文本以及来自可用无标签文本的伪标签，在ST过程中逐渐改进。理论上证明DuNST可以被视为向潜在真实文本的探索增强。

    Self-training (ST) has prospered again in language understanding by augmenting the fine-tuning of pre-trained language models when labeled data is insufficient. However, it remains challenging to incorporate ST into attribute-controllable language generation. Augmented by only self-generated pseudo text, generation models over-emphasize exploitation of the previously learned space, suffering from a constrained generalization boundary. We revisit ST and propose a novel method, DuNST to alleviate this problem. DuNST jointly models text generation and classification with a shared Variational AutoEncoder and corrupts the generated pseudo text by two kinds of flexible noise to disturb the space. In this way, our model could construct and utilize both pseudo text from given labels and pseudo labels from available unlabeled text, which are gradually refined during the ST process. We theoretically demonstrate that DuNST can be regarded as enhancing exploration towards the potential real text s
    
[^69]: 重访黄金标准：以健壮的人类评估为基础的摘要评估

    Revisiting the Gold Standard: Grounding Summarization Evaluation with Robust Human Evaluation. (arXiv:2212.07981v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.07981](http://arxiv.org/abs/2212.07981)

    该论文提出了一种新的摘要显要性协议，ACUs，解决了现有评估协议低一致性的问题。作者建立了一个超大规模评估数据集RoSE并进行了人类评估和自动评估，为摘要评估的相关研究提供了新的思路。

    

    人类评估是自动摘要系统和评估指标评估的基础。然而，现有的摘要人类评估研究要么存在很低的评分员一致性，要么规模不足，并且缺乏深入的人类评估分析。因此，我们从以下几个方面解决了现有摘要评估的缺点：（1）我们提出了一种修改过的摘要显要性协议，即原子内容单位（ACUs），它基于细粒度语义单元，允许获得较高的评分员一致性。（2）我们开发了一个大型的人类评估数据集RoSE，其中包括超过28个表现最佳的系统在三个数据集上的22,000个摘要级别注释。（3）我们对四种人类评估协议进行了比较研究，强调了评估设置中可能存在的混淆因素。（4）我们使用共现矩阵作为人类评估的代理，评估了50个自动指标及其变体。

    Human evaluation is the foundation upon which the evaluation of both summarization systems and automatic metrics rests. However, existing human evaluation studies for summarization either exhibit a low inter-annotator agreement or have insufficient scale, and an in-depth analysis of human evaluation is lacking. Therefore, we address the shortcomings of existing summarization evaluation along the following axes: (1) We propose a modified summarization salience protocol, Atomic Content Units (ACUs), which is based on fine-grained semantic units and allows for a high inter-annotator agreement. (2) We curate the Robust Summarization Evaluation (RoSE) benchmark, a large human evaluation dataset consisting of 22,000 summary-level annotations over 28 top-performing systems on three datasets. (3) We conduct a comparative study of four human evaluation protocols, underscoring potential confounding factors in evaluation setups. (4) We evaluate 50 automatic metrics and their variants using the co
    
[^70]: 在场学习者能否从演示中学习推理概念？

    Can In-context Learners Learn a Reasoning Concept from Demonstrations?. (arXiv:2212.01692v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.01692](http://arxiv.org/abs/2212.01692)

    本文介绍了一种概念性少样本学习方法，以帮助在场学习者学习新技能。通过选择与预测示例共享可能信息的演示，这个方法可以在模型记忆独立的情况下区分模型的在场学习能力。

    

    大型语言模型展示了从少量输入-输出演示中学习新任务的新能力。然而，最近的研究表明，在场学习者大部分依赖于他们的预训练知识，如标签的情感，而不是在输入中找到新的关联性。然而，常用的少样本评估设置使用随机选择的在场演示无法区分模型从演示中学习新技能的能力，因为大部分随机选择的演示并不呈现超越暴露于新任务分布的预测的关系。为了在模型记忆独立的情况下区分模型的在场学习能力，我们引入了一个概念性少样本学习方法，选择与预测示例共享可能信息的演示。我们从注释解释中提取了一组这样的概念，并测量了模型展示这些概念可以获得多少好处。

    Large language models show an emergent ability to learn a new task from a small number of input-output demonstrations. However, recent work shows that in-context learners largely rely on their pre-trained knowledge, such as the sentiment of the labels, instead of finding new associations in the input. However, the commonly-used few-shot evaluation settings using a random selection of in-context demonstrations can not disentangle models' ability to learn a new skill from demonstrations, as most of the randomly-selected demonstrations do not present relations informative for prediction beyond exposing the new task distribution.  To disentangle models' in-context learning ability independent of models' memory, we introduce a Conceptual few-shot learning method selecting the demonstrations sharing a possibly-informative concept with the predicted sample. We extract a set of such concepts from annotated explanations and measure how much can models benefit from presenting these concepts in f
    
[^71]: 基于拓扑数据分析的语音处理

    Topological Data Analysis for Speech Processing. (arXiv:2211.17223v3 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2211.17223](http://arxiv.org/abs/2211.17223)

    本论文将拓扑数据分析应用于语音分类问题和预训练语音模型的内省，并介绍了一系列基于Transformer注意力图和嵌入的拓扑和代数特征。在这些特征基础上构建的简单线性分类器胜过精调分类器头部，并实现了在许多数据集上的最新最优性能。拓扑特征能够揭示语音Transformer头的功能角色，这表明TDA是一种有前途的语音分析方法。

    

    我们将拓扑数据分析（TDA）应用于语音分类问题及预训练语音模型HuBERT的内省。为此，我们介绍了一些基于Transformer注意力图和嵌入的拓扑和代数特征。我们证明，在这些特征基础上构建的简单线性分类器胜过精调分类器头部。特别地，在四个常见数据集上，我们实现了约9%的准确率提高和5%的ERR提高。在CREMA-D数据集上，提出的特征集达到了准确率80.155的新的最优性能。我们还展示了拓扑特征能够揭示语音Transformer头的功能角色。例如，我们发现在没有任何下游精调的情况下，这些头可区分样本来源（自然/合成）或声音对。我们的结果表明，TDA是一种有前途的语音分析方法，尤其是对于需要结构预测的任务。此外，我们还提供了附录、对TDA和HuBERT模型的介绍以及使用其他数据集的实验。

    We apply topological data analysis (TDA) to speech classification problems and to the introspection of a pretrained speech model, HuBERT. To this end, we introduce a number of topological and algebraic features derived from Transformer attention maps and embeddings. We show that a simple linear classifier built on top of such features outperforms a fine-tuned classification head. In particular, we achieve an improvement of about $9\%$ accuracy and $5\%$ ERR on four common datasets; on CREMA-D, the proposed feature set reaches a new state of the art performance with accuracy $80.155$. We also show that topological features are able to reveal functional roles of speech Transformer heads; e.g., we find the heads capable to distinguish between pairs of sample sources (natural/synthetic) or voices without any downstream fine-tuning. Our results demonstrate that TDA is a promising new approach for speech analysis, especially for tasks that require structural prediction. Appendices, an introd
    
[^72]: SmoothQuant：用于大型语言模型的精确高效的后训练量化方法

    SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models. (arXiv:2211.10438v5 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.10438](http://arxiv.org/abs/2211.10438)

    SmoothQuant是一种训练无需的通用后训练量化（PTQ）解决方案，可以在保持精度的情况下实现大型语言模型的8位权重、8位激活（W8A8）量化。SmoothQuant通过数学等效转换将量化难度从激活移到权重，使得所有矩阵乘法的权重和激活的INT8量化成为可能，具有最高1.56倍加速和2倍内存减少的效果。

    

    大型语言模型（LLMs）表现出优异的性能，但需要大量计算和内存。量化可以减少内存并加速推理。然而，现有方法无法在保持精度和硬件效率的同时维持。我们提出了SmoothQuant，一种无需训练、保持精度和通用的后训练量化（PTQ）解决方案，以实现LLMs的8位权重、8位激活（W8A8）量化。基于权重易于量化而激活不易量化的事实，SmoothQuant通过数学等效转换将量化难度从激活移至权重，通过离线平滑激活的异常值来实现此目标。SmoothQuant使所有矩阵乘法的权重和激活的INT8量化成为可能，包括OPT、BLOOM、GLM、MT-NLG和LLaMA系列。我们演示了LLMs的最高1.56倍加速和2倍内存减少，并且几乎不会有精度损失。SmoothQuant可以为530B LLM提供服务。

    Large language models (LLMs) show excellent performance but are compute- and memory-intensive. Quantization can reduce memory and accelerate inference. However, existing methods cannot maintain accuracy and hardware efficiency at the same time. We propose SmoothQuant, a training-free, accuracy-preserving, and general-purpose post-training quantization (PTQ) solution to enable 8-bit weight, 8-bit activation (W8A8) quantization for LLMs. Based on the fact that weights are easy to quantize while activations are not, SmoothQuant smooths the activation outliers by offline migrating the quantization difficulty from activations to weights with a mathematically equivalent transformation. SmoothQuant enables an INT8 quantization of both weights and activations for all the matrix multiplications in LLMs, including OPT, BLOOM, GLM, MT-NLG, and LLaMA family. We demonstrate up to 1.56x speedup and 2x memory reduction for LLMs with negligible loss in accuracy. SmoothQuant enables serving 530B LLM wi
    
[^73]: 一种用于零样本泛化的通用鉴别器

    A Universal Discriminator for Zero-Shot Generalization. (arXiv:2211.08099v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.08099](http://arxiv.org/abs/2211.08099)

    该论文提出了一种用于零样本泛化的通用鉴别器，通过在NLP任务中使用单一的鉴别器，可实现比生成方法更好的表现，取得了在T0基准测试中最先进的零样本结果，同时在各种NLP任务上实现了新的最先进结果。

    

    生成建模一直是大规模预训练和零样本泛化的主要方法。本研究通过展示在大量NLP任务中，鉴别方法比生成方法表现更好，挑战这种惯例。我们训练一个单一的鉴别器来预测文本样本是否来自真实数据分布，类似于GAN。由于许多NLP任务可以表示为从几个选项中选择，因此我们使用这个鉴别器来预测输入和哪个选项与真实数据分布的概率最大。这种简单的公式在T0基准测试中实现了最先进的零样本结果，分别在不同规模上比T0高16.0％，7.8％和11.5％。在微调设置中，我们的方法还在各种NLP任务上取得了新的最先进结果，仅占之前方法的1/4参数。同时，我们的方法需要最小的噪声和架构工程。

    Generative modeling has been the dominant approach for large-scale pretraining and zero-shot generalization. In this work, we challenge this convention by showing that discriminative approaches perform substantially better than generative ones on a large number of NLP tasks. Technically, we train a single discriminator to predict whether a text sample comes from the true data distribution, similar to GANs. Since many NLP tasks can be formulated as selecting from a few options, we use this discriminator to predict the concatenation of input and which option has the highest probability of coming from the true data distribution. This simple formulation achieves state-of-the-art zero-shot results on the T0 benchmark, outperforming T0 by 16.0\%, 7.8\%, and 11.5\% respectively on different scales. In the finetuning setting, our approach also achieves new state-of-the-art results on a wide range of NLP tasks, with only 1/4 parameters of previous methods. Meanwhile, our approach requires minim
    
[^74]: 通过检索非结构化知识进行自适应命名实体识别

    Self-Adaptive Named Entity Recognition by Retrieving Unstructured Knowledge. (arXiv:2210.07523v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.07523](http://arxiv.org/abs/2210.07523)

    本文提出了一种自适应命名实体识别方法，通过检索非结构化知识以修正预测，实验结果表明该方法在F1度量上优于强基线模型2.35个百分点。

    

    命名实体识别（NER）可以用于从文本中提取特定领域的实体（例如音乐领域中的艺术家），但是创建大量的训练数据或结构化知识库来执行目标领域的准确NER是很昂贵的。为了检索未被很好地学习的实体的用法，我们提出了一种自适应NER方法，它从非结构化文本中检索外部知识。为了检索NER的有用知识，我们设计了一个有效的两阶段模型，使用不确定的实体作为查询来检索非结构化知识。我们的模型预测输入中的实体，然后找到那些预测不自信的实体。然后，它使用这些不确定的实体作为查询来检索知识，并将检索到的文本连接到原始输入以修正预测。在CrossNER数据集上的实验表明，我们的模型在F1度量上比强基线模型高2.35个百分点。

    Although named entity recognition (NER) helps us to extract domain-specific entities from text (e.g., artists in the music domain), it is costly to create a large amount of training data or a structured knowledge base to perform accurate NER in the target domain. Here, we propose self-adaptive NER, which retrieves external knowledge from unstructured text to learn the usages of entities that have not been learned well. To retrieve useful knowledge for NER, we design an effective two-stage model that retrieves unstructured knowledge using uncertain entities as queries. Our model predicts the entities in the input and then finds those of which the prediction is not confident. Then, it retrieves knowledge by using these uncertain entities as queries and concatenates the retrieved text to the original input to revise the prediction. Experiments on CrossNER datasets demonstrated that our model outperforms strong baselines by 2.35 points in F1 metric.
    
[^75]: 基于常识推理的隐式意图预测和建议的零-shot提示

    Zero-Shot Prompting for Implicit Intent Prediction and Recommendation with Commonsense Reasoning. (arXiv:2210.05901v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.05901](http://arxiv.org/abs/2210.05901)

    本文提出了一种多领域对话系统框架，基于常识推理能够实现隐式意图的预测和通过预训练语言模型进行零-shot提示以触发相应的任务导向机器人，提高了实用性和效率。

    

    目前的智能虚拟助手只能通过明确提到的任务或服务来执行相关领域或任务，需要通过长时间的会话和多个明确意图来执行。相比之下，人类助手能够基于常识知识推断出用户话语的（多个）隐式意图，从而减少复杂的交互并提高实用性。因此，本文提出了一个多领域对话系统的框架，可以根据用户话语自动推断隐式意图，然后使用大型预训练语言模型进行零-shot提示，从而触发适当的单个任务导向机器人。所提出的框架在零-shot方式下实现了隐式意图和相关机器人的建议的有效性。

    Intelligent virtual assistants are currently designed to perform tasks or services explicitly mentioned by users, so multiple related domains or tasks need to be performed one by one through a long conversation with many explicit intents. Instead, human assistants are capable of reasoning (multiple) implicit intents based on user utterances via commonsense knowledge, reducing complex interactions and improving practicality. Therefore, this paper proposes a framework of multi-domain dialogue systems, which can automatically infer implicit intents based on user utterances and then perform zero-shot prompting using a large pre-trained language model to trigger suitable single task-oriented bots. The proposed framework is demonstrated effective to realize implicit intents and recommend associated bots in a zero-shot manner.
    
[^76]: 基于核函数的语言模型微调视角

    A Kernel-Based View of Language Model Fine-Tuning. (arXiv:2210.05643v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.05643](http://arxiv.org/abs/2210.05643)

    本文研究神经切线核 (NTK) 在描述预训练语言模型微调过程中的适用性。实验证明在14个NLP任务中使用掩码词预测问题作为下游任务，可以取得好的效果。

    

    在自然语言处理中，通过对预训练语言模型 (LMs) 进行微调，在低数据情况下解决 NLP 任务已经成为标准做法。但是，目前对于经验成功背后的理论机制了解很少，例如为什么在几十个训练点上微调一个有 $10^8$ 个或更多参数的模型不会导致过拟合。本文研究了神经切线核 (NTK) 在描述预训练语言模型的微调过程中的适用性。我们扩展了 NTK 形式化方法以应用于 Adam，并使用 Tensor Programs 描述了 NTK 适用于描述预训练语言模型微调更新的条件。我们在 14 个 NLP 任务上进行了广泛的实验验证了我们的理论，并表明通过提示将下游任务表述为掩码词预测问题可以取得良好的效果。

    It has become standard to solve NLP tasks by fine-tuning pre-trained language models (LMs), especially in low-data settings. There is minimal theoretical understanding of empirical success, e.g., why fine-tuning a model with $10^8$ or more parameters on a couple dozen training points does not result in overfitting. We investigate whether the Neural Tangent Kernel (NTK) - which originated as a model to study the gradient descent dynamics of infinitely wide networks with suitable random initialization - describes fine-tuning of pre-trained LMs. This study was inspired by the decent performance of NTK for computer vision tasks (Wei et al., 2022). We extend the NTK formalism to Adam and use Tensor Programs (Yang, 2020) to characterize conditions under which the NTK lens may describe fine-tuning updates to pre-trained language models. Extensive experiments on 14 NLP tasks validate our theory and show that formulating the downstream task as a masked word prediction problem through prompting 
    
[^77]: 基于上下文学习的可控对话模拟

    Controllable Dialogue Simulation with In-Context Learning. (arXiv:2210.04185v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.04185](http://arxiv.org/abs/2210.04185)

    本文提出了一种基于上下文学习的对话模拟方法，通过少量带注释的示例自动创建大量对话数据，比众包更加成本效益和节省时间，实验证明在低资源环境下使用模拟对话训练模型可以获得更好的性能。

    

    建立对话系统需要大量的带注释对话语料库，而这些数据集通常通过众包创建，费时费力。本文提出了一种名为 Dialogic 的新型对话模拟方法，它基于大尺度语言模型上下文学习，以自动化的方式创建数据集。在少量带注释的对话示例的启发下，Dialogic 自动选择上下文中的示例，促使 GPT-3 控制生成新的对话和注释。我们的方法可以快速扩展少量的对话数据，几乎没有人类介入和参数更新，因此比众包更具成本效益和节省时间。基于 MultiWOZ 数据集上的实验结果表明，在具有挑战性的低资源环境下，使用模拟对话训练模型的性能甚至比使用相同数量人工生成的对话更好，仅使用 85 条对话。

    Building dialogue systems requires a large corpus of annotated dialogues. Such datasets are usually created via crowdsourcing, which is expensive and time-consuming. In this paper, we propose \textsc{Dialogic}, a novel dialogue simulation method based on large language model in-context learning to automate dataset creation. Seeded with a few annotated dialogues, \textsc{Dialogic} automatically selects in-context examples for demonstration and prompts GPT-3 to generate new dialogues and annotations in a controllable way. Our method can rapidly expand a small set of dialogue data with minimum or zero \textit{human involvement} and \textit{parameter update} and is thus much more cost-efficient and time-saving than crowdsourcing. Experimental results on the MultiWOZ dataset demonstrate that training a model on the simulated dialogues leads to even better performance than using the same amount of human-generated dialogues under the challenging low-resource settings, with as few as 85 dialog
    
[^78]: 猜测指令！翻转学习使语言模型成为更强的零样本学习者。

    Guess the Instruction! Flipped Learning Makes Language Models Stronger Zero-Shot Learners. (arXiv:2210.02969v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.02969](http://arxiv.org/abs/2210.02969)

    本文提出了一种名为“翻转学习”的元训练替代方法，通过训练语言模型生成任务指令，可以在零样本任务中取得更好的表现，特别是在包含未见标签的挑战性任务中。Flipped在14个BIG-bench基准测试任务中平均比3-shot GPT-3高出8.4%和9.7%的分数。

    

    元训练通过最大化给定任务指令和输入实例的目标标签似然来微调语言模型(LM)，从而提高了零样本任务的泛化性能。然而，元训练的LM仍然难以推广到包含在元训练期间未见过的新标签的具有挑战性的任务中。在本文中，我们提出了一种称为“翻转学习”的元训练替代方法，该方法训练LM在给定输入实例和标签的情况下生成任务指令。在推理过程中，使用翻转学习训练的LM(称为“Flipped”)选择最有可能生成任务指令的标签选项。在BIG-bench基准测试的14个任务中，大小为11B的Flipped在平均值方面优于零样本T0-11B甚至比16倍大的3-shot GPT-3(175B)高出8.4%和9.7%的分数。Flipped在具有未知标签的任务上尤其表现突出，在某些任务上比T0-11B高出20%。

    Meta-training, which fine-tunes the language model (LM) on various downstream tasks by maximizing the likelihood of the target label given the task instruction and input instance, has improved the zero-shot task generalization performance. However, meta-trained LMs still struggle to generalize to challenging tasks containing novel labels unseen during meta-training. In this paper, we propose Flipped Learning, an alternative method of meta-training which trains the LM to generate the task instruction given the input instance and label. During inference, the LM trained with Flipped Learning, referred to as Flipped, selects the label option that is most likely to generate the task instruction. On 14 tasks of the BIG-bench benchmark, the 11B-sized Flipped outperforms zero-shot T0-11B and even a 16 times larger 3-shot GPT-3 (175B) on average by 8.4% and 9.7% points, respectively. Flipped gives particularly large improvements on tasks with unseen labels, outperforming T0-11B by up to +20% av
    
[^79]: 少即是多：面向任务的分层蒸馏用于语言模型压缩

    Less is More: Task-aware Layer-wise Distillation for Language Model Compression. (arXiv:2210.01351v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.01351](http://arxiv.org/abs/2210.01351)

    本文提出了一种新的面向任务的分层蒸馏方法（TED），通过设计任务感知的滤波器来对齐学生和教师的隐藏表示，选择有用的知识，减少知识差距，使学生模型更好地适应目标任务，实现了比最先进方法更少的参数下可比或更好的性能。

    

    分层蒸馏是将大模型（即教师模型）压缩为小模型（即学生模型）的强大工具。学生通过在每个中间层模仿教师的隐藏表示来从教师中蒸馏知识。然而，分层蒸馏也存在一些挑战。由于学生的模型容量比教师小，它通常会出现欠拟合;此外，教师的隐藏表示包含了学生未必需要的冗余信息。为了解决这些问题，我们提出了一种新颖的面向任务的分层蒸馏（TED）方法。TED设计任务感知滤波器来对齐每一层的学生和教师的隐藏表示。这些滤波器从隐藏表示中选择对目标任务有用的知识。因此，TED减少了两个模型之间的知识差距，并帮助学生更好地适应目标任务。我们在多种语言模型任务中评估了TED，并表明它可以在比最先进的方法少得多的参数情况下实现可比或甚至更好的性能。

    Layer-wise distillation is a powerful tool to compress large models (i.e. teacher models) into small ones (i.e., student models). The student distills knowledge from the teacher by mimicking the hidden representations of the teacher at every intermediate layer. However, layer-wise distillation is difficult. Since the student has a smaller model capacity than the teacher, it is often under-fitted. Furthermore, the hidden representations of the teacher contain redundant information that the student does not necessarily need for the target task's learning. To address these challenges, we propose a novel Task-aware layEr-wise Distillation (TED). TED designs task-aware filters to align the hidden representations of the student and the teacher at each layer. The filters select the knowledge that is useful for the target task from the hidden representations. As such, TED reduces the knowledge gap between the two models and helps the student to fit better on the target task. We evaluate TED in
    
[^80]: 问答任务中的结构化知识基础构建

    Structured Knowledge Grounding for Question Answering. (arXiv:2209.08284v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.08284](http://arxiv.org/abs/2209.08284)

    本文提出了一种基于语言模型的知识基础问答方法，通过动态跳跃检索相关上下文，并使用深度融合机制，实现具有灵活性、覆盖面和结构推理，优于现有的知识基础构建方法，并达到与依赖于外部信息资源的最先进系统相竞争的性能。

    

    语言模型（LM）能否通过固有的关系推理能力在知识库中对问答任务进行知识基础构建？虽然之前只使用LM的模型在许多问答任务上取得了一定成功，但最近的一些方法包括知识图谱（KG），通过其更具逻辑驱动的隐含知识来补充LM。然而，有效地从结构化数据（如KG）中提取信息，使得LM保持面向未知问题的灵活性和广度，目前仍是个未解之谜，并且当前的模型依赖于图技术来提取知识。在本文中，我们提出仅利用LM来结合语言和知识，以实现具有灵活性、覆盖面和结构推理的知识基础问答。具体来说，我们设计了一种知识构建方法，通过动态跳跃来检索相关的上下文，这种方法表现出了比传统基于GNN技术更全面的表现力。并且我们设计了一种深度融合机制，进一步弥合了语言和知识模态之间信息交换的瓶颈。我们在几个基准数据集上的实验表明，我们的方法优于现有的知识基础构建方法，并展示出与依赖于外部信息资源的最先进系统相竞争的性能。

    Can language models (LM) ground question-answering (QA) tasks in the knowledge base via inherent relational reasoning ability? While previous models that use only LMs have seen some success on many QA tasks, more recent methods include knowledge graphs (KG) to complement LMs with their more logic-driven implicit knowledge. However, effectively extracting information from structured data, like KGs, empowers LMs to remain an open question, and current models rely on graph techniques to extract knowledge. In this paper, we propose to solely leverage the LMs to combine the language and knowledge for knowledge based question-answering with flexibility, breadth of coverage and structured reasoning. Specifically, we devise a knowledge construction method that retrieves the relevant context with a dynamic hop, which expresses more comprehensivenes than traditional GNN-based techniques. And we devise a deep fusion mechanism to further bridge the information exchanging bottleneck between the lan
    
[^81]: GigaST: 一份10,000小时的伪语音翻译语料库

    GigaST: A 10,000-hour Pseudo Speech Translation Corpus. (arXiv:2204.03939v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2204.03939](http://arxiv.org/abs/2204.03939)

    GigaST是一份大规模的伪语音翻译(ST)语料库，使用该语料库所训练出的ST模型在MuST-C英语-德语基准测试集上取得了新的最先进结果。

    

    本文介绍了GigaST，一份大规模的伪语音翻译(ST)语料库。我们通过将英语ASR语料库GigaSpeech中的文本翻译成德语和中文来创建该语料库。训练集由强大的机器翻译系统翻译，测试集由人类进行翻译。使用我们的语料库训练的ST模型在MuST-C英语-德语基准测试集上获得了新的最先进结果。我们提供了详细的翻译过程描述并验证了其质量。我们公开了翻译的文本数据，并希望促进语音翻译的研究。此外，我们还在NeurST上发布了训练脚本，以便轻松复制我们的系统。 GigaST数据集可在https://st-benchmark.github.io/resources/GigaST获得。

    This paper introduces GigaST, a large-scale pseudo speech translation (ST) corpus. We create the corpus by translating the text in GigaSpeech, an English ASR corpus, into German and Chinese. The training set is translated by a strong machine translation system and the test set is translated by human. ST models trained with an addition of our corpus obtain new state-of-the-art results on the MuST-C English-German benchmark test set. We provide a detailed description of the translation process and verify its quality. We make the translated text data public and hope to facilitate research in speech translation. Additionally, we also release the training scripts on NeurST to make it easy to replicate our systems. GigaST dataset is available at https://st-benchmark.github.io/resources/GigaST.
    
[^82]: 在在线平台上检测有害内容：平台需求与研究方向差异

    Detecting Harmful Content On Online Platforms: What Platforms Need Vs. Where Research Efforts Go. (arXiv:2103.00153v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2103.00153](http://arxiv.org/abs/2103.00153)

    在线平台上的有害内容种类和平台需求与自动检测有害内容的研究方向存在差异，需要更深入的研究和更好的平台管理，以减少社会危害和创建更完整的用户环境。

    

    在线平台上有害内容的泛滥是一个重要的社会问题，包括仇恨言论、攻击性语言、欺凌和骚扰、错误信息、垃圾邮件、暴力、露骨内容、性虐待、自残等多种形式。在线平台寻求限制这些内容以减少社会危害，遵守法律法规，并为用户创建更具包容性的环境。研究人员开发出了不同的方法来自动检测有害内容，通常集中在特定的子问题或狭窄的社区上，因为有害内容的定义通常取决于平台和上下文。我们认为，当前存在在线平台寻求遏制的有害内容类型，与自动检测此类内容的研究方向之间存在二元对立。因此，我们在此调查现有方法以及在线平台的内容管理政策，并针对性提出研究方向建议。

    The proliferation of harmful content on online platforms is a major societal problem, which comes in many different forms including hate speech, offensive language, bullying and harassment, misinformation, spam, violence, graphic content, sexual abuse, self harm, and many other. Online platforms seek to moderate such content to limit societal harm, to comply with legislation, and to create a more inclusive environment for their users. Researchers have developed different methods for automatically detecting harmful content, often focusing on specific sub-problems or on narrow communities, as what is considered harmful often depends on the platform and on the context. We argue that there is currently a dichotomy between what types of harmful content online platforms seek to curb, and what research efforts there are to automatically detect such content. We thus survey existing methods as well as content moderation policies by online platforms in this light and we suggest directions for fu
    

