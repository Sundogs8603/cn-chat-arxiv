# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [VideoChat: Chat-Centric Video Understanding.](http://arxiv.org/abs/2305.06355) | 本文提出了以聊天为核心的视频理解系统VideoChat，它通过可学习的神经接口将视频基础模型和大型语言模型集成在一起，擅长于时空推理、事件定位和因果关系推断。作者还提出了一个视频为中心的指令数据集，初步实验表明该系统在广泛的视频应用中具有潜力。 |
| [^2] | [K-UniMorph: Korean Universal Morphology and its Feature Schema.](http://arxiv.org/abs/2305.06335) | 本文介绍了一种韩语通用词形学数据集，保留韩语特色并采用Sylak-Glassman等人的词形特征模式，为韩语形态学范式领域做出了贡献。 |
| [^3] | [Automatic Evaluation of Attribution by Large Language Models.](http://arxiv.org/abs/2305.06311) | 本文探讨了大型语言模型对归属验证的自动评估。研究发现通过提示LLMs和微调较小的LLMs两种方法都有效地检测到了错误的归属陈述。 |
| [^4] | [Evaluating Embedding APIs for Information Retrieval.](http://arxiv.org/abs/2305.06300) | 本篇论文旨在通过对语义嵌入API在实际检索场景中的分析,为从业者和研究人员找到适当的服务。结果表明，在英语上使用API重新排名BM25的结果是一种预算友好的最优做法。 |
| [^5] | [Summarizing, Simplifying, and Synthesizing Medical Evidence Using GPT-3 (with Varying Success).](http://arxiv.org/abs/2305.06299) | 本文评估了GPT-3在生物医学领域中生成文章摘要的能力，发现它对单个文章的总结和简化效果较好，但在综合多篇文章中所报告的证据方面表现欠佳。 |
| [^6] | [CADGE: Context-Aware Dialogue Generation Enhanced with Graph-Structured Knowledge Aggregation.](http://arxiv.org/abs/2305.06294) | 本文提出了一种基于上下文感知的图注意力模型，可以将上下文增强的知识聚合过程与相关知识图的全局特征有效融合，将增强的图结构知识集成到基于上下文感知的对话生成模型中。实验证明，该模型在自动度量和人类评估方面均优于现有方法。 |
| [^7] | [Context-Aware Document Simplification.](http://arxiv.org/abs/2305.06274) | 本论文讨论了如何在文件简化过程中使用上下文信息，以提高输出质量。通过迭代更大的文本单元或扩展系统架构来关注文档的高级话语表示的方式，可以使简化模型直接访问局部的跨句子文档上下文，从而实现最新的文档简化成果。 |
| [^8] | [Learning Robust Self-attention Features for Speech Emotion Recognition with Label-adaptive Mixup.](http://arxiv.org/abs/2305.06273) | 本文提出了一种基于自注意力和标签自适应Mixup技术的方法，在语音情感识别中取得了优越的性能，能够有效地应对人类情感的不确定性。 |
| [^9] | [ComputeGPT: A computational chat model for numerical problems.](http://arxiv.org/abs/2305.06223) | ComputeGPT是一种计算型聊天模型，可以通过运行代码解决数值问题，结合本地浏览器的Python解释器和优化的提示，实现最先进的数值问题效率并为代码提供合适的前端和安全环境。 |
| [^10] | [Multi-Task End-to-End Training Improves Conversational Recommendation.](http://arxiv.org/abs/2305.06218) | 本文表明，采用多任务端到端Transformer模型可以提高对话式推荐的性能，可竞争于先前采用复杂多组件方法的模型，通过微调我们的模型和额外的多任务学习设置，实现了知识在领域间的转移。 |
| [^11] | [Privacy-Preserving Prompt Tuning for Large Language Model Services.](http://arxiv.org/abs/2305.06212) | RAPT是一个提供隐私保证的大语言模型服务的提示调整框架，采用本地差分隐私设置和新颖的隐私化标记重建任务，并在多种任务中取得有竞争力的性能和良好的隐私保护效果。 |
| [^12] | [Fine-tuning Language Models with Generative Adversarial Feedback.](http://arxiv.org/abs/2305.06176) | 本研究探讨了一种新的方法，使用生成对抗反馈的强化学习(RLGAF)对大型语言模型进行微调，以取代仅受人类反馈的强化学习(RLHF)，从而消除评估者的专业限制并提高性能。 |
| [^13] | [Analysis of Climate Campaigns on Social Media using Bayesian Model Averaging.](http://arxiv.org/abs/2305.06174) | 本文分析了工业、倡导组织和气候倡导组织在社交媒体上如何影响气候变化的叙事，并提出了一个最小化监督模型组合方法，用于识别Facebook上气候广告的立场。 |
| [^14] | [QICHWABASE: A Quechua Language and Knowledge Base for Quechua Communities.](http://arxiv.org/abs/2305.06173) | QICHWABASE为少数民族语言和知识构建Wikibase实例，支持凯楚亚社区和谐进程，能增强少数民族在网络上的存在感。 |
| [^15] | [ChatGPT as a Text Simplification Tool to Remove Bias.](http://arxiv.org/abs/2305.06166) | ChatGPT作为文本简化工具可以去除语言模型在训练过程中对某些特定群体的偏见，减少模型的歧视性。（注：ChatGPT是一种基于Transformer的自然语言处理模型） |
| [^16] | [Conversational Semantic Parsing using Dynamic Context Graphs.](http://arxiv.org/abs/2305.06164) | 本论文提出了一种新的方法，使用动态创建的子图表示话语及上下文的信息来进行会话语义解析，并利用图形神经网络编码，可表示大量看不见的节点，比静态方法更为优越。 |
| [^17] | [Algebra Error Classification with Large Language Models.](http://arxiv.org/abs/2305.06163) | 本研究提出了一种基于大语言模型的代数错误分类方法，相较于现有方法，具有更好的泛化能力和处理学生回答的能力。 |
| [^18] | [StarCoder: may the source be with you!.](http://arxiv.org/abs/2305.06161) | 本研究介绍了一个具有15.5B参数和8K上下文长度的大型语言模型——StarCoder，其可以进行快速大批量推理。经评估证明，在Python上表现优异，能够通过人工评估获得40\%的pass@1的得分，且在其他程序中也表现出令人满意的性能。 |
| [^19] | [A Review of Vision-Language Models and their Performance on the Hateful Memes Challenge.](http://arxiv.org/abs/2305.06159) | 本文综述了视觉-语言模型及其在社交媒体内容审核上的应用，研究发现早期融合模型比晚期融合模型更有效，其中表现最佳的早期融合模型是ClipBERT。 |
| [^20] | [Implications of Multi-Word Expressions on English to Bharti Braille Machine Translation.](http://arxiv.org/abs/2305.06157) | 本文通过给基线神经机器翻译模型添加语言知识及多词语翻译子模块，在英语到巴提盲文机器翻译中取得了显著的改进。 |
| [^21] | [The Vault: A Comprehensive Multilingual Dataset for Advancing Code Understanding and Generation.](http://arxiv.org/abs/2305.06156) | The Vault是一个提供了10种流行编程语言的40百万行代码-文本对的开源数据集，旨在增强面向代码的大型语言模型（LLM）的训练，有望在代码理解和生成任务上取得显著进展。 |
| [^22] | [Leveraging Synthetic Targets for Machine Translation.](http://arxiv.org/abs/2305.06155) | 本文提供了一种利用预训练模型生成合成目标从而提高机器翻译性能的方法，并发现其在不同测试基准下的表现优于使用真实数据训练，这一方法在有限资源的情况下尤其有用。 |
| [^23] | [Alleviating Over-smoothing for Unsupervised Sentence Representation.](http://arxiv.org/abs/2305.06154) | 本论文提出了自对抗学习（SSCL）方法，通过从PLMs较低层中采样负样本，缓解了无监督句子表示平滑问题，提升了句子表示的质量和性能。 |
| [^24] | [Structure-CLIP: Enhance Multi-modal Language Representations with Structure Knowledge.](http://arxiv.org/abs/2305.06152) | Structure-CLIP使用文本中的结构化知识，使用场景图强化多模态语言表示，从而在图像-文本匹配任务中展现了更好的性能。 |
| [^25] | [A semi-automatic method for document classification in the shipping industry.](http://arxiv.org/abs/2305.06148) | 运输行业使用OCR技术对文件进行分类以提高准确性和效率。该研究提出半自动化的方法，基于关键词频率构建一个稳健的文档分类系统，其在收集的85个违约案例和555个非违约案例上实现了93.31%的高分类准确度。 |
| [^26] | [CQSumDP: A ChatGPT-Annotated Resource for Query-Focused Abstractive Summarization Based on Debatepedia.](http://arxiv.org/abs/2305.06147) | 本文介绍了一种利用ChatGPT重新生成其查询以清理Debatepedia数据集噪声的方法，成功提高了查询相关性和摘要生成效果。 |
| [^27] | [PAI at SemEval-2023 Task 2: A Universal System for Named Entity Recognition with External Entity Information.](http://arxiv.org/abs/2305.06099) | PAI团队提出了一种利用维基百科等外部实体信息的通用命名实体识别系统，在SemEval-2023任务2中表现出色，共赢得了7个奖项。 |
| [^28] | [A Glimpse in ChatGPT Capabilities and its impact for AI research.](http://arxiv.org/abs/2305.06087) | ChatGPT展示了LLMs的强大能力，但这些模型的训练和运行需要巨大的计算资源和高昂的成本，预计会给AI研究带来重大影响。 |
| [^29] | [iLab at SemEval-2023 Task 11 Le-Wi-Di: Modelling Disagreement or Modelling Perspectives?.](http://arxiv.org/abs/2305.06074) | 本文讨论了建模注释者不一致性的两种方法：分布式软标记方法和建模个体注释者或其组的观点。本文通过将两种方法结合起来的方式来模拟注释者不一致性。尽管多任务方法之前表现良好，但我们发现其在包含不同注释者观点的数据集上表现不佳。研究结果表明，该方法可以更细致地理解注释者不一致性，为更准确的观点建模提供可能。 |
| [^30] | [ANALOGYKB: Unlocking Analogical Reasoning of Language Models with A Million-scale Knowledge Base.](http://arxiv.org/abs/2305.05994) | 本文提出了ANALOGYKB，一种使用百万规模知识库的类比推理方法，能够使语言模型在类比推理任务上取得比之前的最先进方法更好的结果。 |
| [^31] | [Generating medically-accurate summaries of patient-provider dialogue: A multi-stage approach using large language models.](http://arxiv.org/abs/2305.05982) | 本文需要解决医疗对话摘要的问题，通过将任务划分为几个小的对话任务依次构建，使用GPT-3大型语言模型，动态构建提示任务以及确定医学实体及其确认状态。 |
| [^32] | [Say What You Mean! Large Language Models Speak Too Positively about Negative Commonsense Knowledge.](http://arxiv.org/abs/2305.05976) | 本文研究了大型语言模型(LLMs)对负面常识知识的了解程度，发现LLMs在生成基于负面知识的有效句子方面存在困难，但在回答极性问题方面表现良好，这种信念冲突主要源于语言预训练时的统计快捷方式和否定报告偏见。 |
| [^33] | [Privacy-Preserving Recommender Systems with Synthetic Query Generation using Differentially Private Large Language Models.](http://arxiv.org/abs/2305.05973) | 提出使用差分隐私大语言模型合成查询的隐私保护推荐系统，可以安全有效地训练深度检索模型并提高检索质量。 |
| [^34] | [Investigating Forgetting in Pre-Trained Representations Through Continual Learning.](http://arxiv.org/abs/2305.05968) | 本文研究了在持续学习中的表示遗忘对预训练语言模型通用性的影响，并提出了两个减轻该遗忘的见解。 |
| [^35] | [Interpretable Multimodal Misinformation Detection with Logic Reasoning.](http://arxiv.org/abs/2305.05964) | 本文提出了一种新的基于逻辑的多模态虚假信息检测神经模型，通过集成可解释性逻辑子句表达目标任务的推理过程，并使用神经表征参数化符号逻辑元素，从而便于自动生成和评估有意义的逻辑子句。此外，引入了五个元预测器来捕获虚假信息的基本模式。实验结果表明，该模型不仅性能显著优于当前方法，而且提供了透明且可解释的逻辑推理过程。 |
| [^36] | [Multi-Path Transformer is Better: A Case Study on Neural Machine Translation.](http://arxiv.org/abs/2305.05948) | 本文研究了多路径结构对Transformer模型的影响，通过在每个子层中添加归一化、产生更多特征的廉价操作和可学习的加权机制来融合从不同路径提取的特征，实验发现相同参数下浅层多路径模型可以实现与深层模型相似甚至更好的性能。 |
| [^37] | [Multilingual LLMs are Better Cross-lingual In-context Learners with Alignment.](http://arxiv.org/abs/2305.05940) | 针对跨语言ICL中无法对准输入输出空间的问题，我们提出了一种新的提示构建策略X-InSTA，可以同时对源语言和目标语言的语境进行编码和对齐，从而提高跨语言ICL的效率。 |
| [^38] | [Multi-hop Commonsense Knowledge Injection Framework for Zero-Shot Commonsense Question Answering.](http://arxiv.org/abs/2305.05936) | 本文提出了一个多跳公共常识知识注入框架用于零样本常识问答，使用符合语言逻辑的多跳推理范式，提高了对多跳关系的识别能力，并在两个基准数据集上表现出了更好的效果。 |
| [^39] | [WikiSQE: A Large-Scale Dataset for Sentence Quality Estimation in Wikipedia.](http://arxiv.org/abs/2305.05928) | WikiSQE是第一个用于维基百科中句子质量估计的大规模数据集，其中包含约3.4M个句子和153个质量标签。在这个数据集上进行的实验表明，具有引文、语法/语义或命题问题的句子更难以检测。 |
| [^40] | [Decker: Double Check with Heterogeneous Knowledge for Commonsense Fact Verification.](http://arxiv.org/abs/2305.05921) | Decker是一种能够利用结构化和非结构化知识之间的潜在关系来桥接异构知识的常识事实验证模型，具有良好的验证效果和获取珍贵信息的能力。 |
| [^41] | [Address Matching Based On Hierarchical Information.](http://arxiv.org/abs/2305.05874) | 本文提出了一种基于层级信息的地址匹配方法，通过利用深度学习方法中的层级信息，提高了现有方法处理不规则地址的能力，并可以更加关注地址的特殊部分，实验结果表明性能提高了3.2个百分点。 |
| [^42] | [Are ChatGPT and GPT-4 General-Purpose Solvers for Financial Text Analytics? An Examination on Several Typical Tasks.](http://arxiv.org/abs/2305.05862) | 本研究探讨了ChatGPT和GPT-4在金融文本分析任务中的潜力，结果显示它们在数值推理上表现出色但在需要领域特定知识的任务上表现不佳。 |
| [^43] | [V\=arta: A Large-Scale Headline-Generation Dataset for Indic Languages.](http://arxiv.org/abs/2305.05858) | 本文介绍了一个用于印度语言头条生成的大规模多语言数据集 V\=arta，包含来自14种不同印度语言（和英语）的4180万条新闻文章，可用于预训练强语言模型，并可用于回答与印度语言处理和多语言研究相关的重要问题。 |
| [^44] | [Context-dependent communication under environmental constraints.](http://arxiv.org/abs/2305.05821) | 本文研究了在压缩词汇量的情况下，如何利用环境压力促进情境依赖性沟通的出现，并研究了在接收者无法处理歧义的情况下，发送者如何利用环境的制约因素实现沟通。 |
| [^45] | [Ranking & Reweighting Improves Group Distributional Robustness.](http://arxiv.org/abs/2305.05759) | 本文提出了一种利用折扣累积增益（DCG）排序并加权处理训练数据以提高模型对低代表性组的鲁棒性的方法，实验证明其优于先前方法。 |
| [^46] | [When and What to Ask Through World States and Text Instructions: IGLU NLP Challenge Solution.](http://arxiv.org/abs/2305.05754) | 论文解决了在协作建筑任务中如何解决模棱两可的情况，从而提出了何时寻求澄清以及应该询问什么澄清问题这两个关键问题的解答方法。 |
| [^47] | [Multilevel Sentence Embeddings for Personality Prediction.](http://arxiv.org/abs/2305.05748) | 本文提出了一种可将文本表示为多维空间的方法，可映射具有复杂的多层结构的句子，并应用于人格预测。 |
| [^48] | [CodeIE: Large Code Generation Models are Better Few-Shot Information Extractors.](http://arxiv.org/abs/2305.05711) | CodeIE提出了使用代码生成模型（Code-LLMs）代替自然语言生成模型（NL-LLMs）对命名实体识别和关系抽取这类信息提取任务进行少样本学习，取得优于几个强基准高达4.5%的绝对精度改进。 |
| [^49] | [$2 * n$ is better than $n^2$: Decomposing Event Coreference Resolution into Two Tractable Problems.](http://arxiv.org/abs/2305.05672) | 为了解决事件指称共指消解中的计算问题，我们将其分成两个部分：一种启发式过滤方法和基于均衡数据集的训练方法。该方法在两个数据集上获得了良好的结果。 |
| [^50] | [Representation Learning for Person or Entity-centric Knowledge Graphs: an application in Healthcare.](http://arxiv.org/abs/2305.05640) | 本研究提出了一种在医疗保健领域构建面向实体的知识图谱的端到端表示学习方法 HEER，通过将领域特定的约束和特征纳入到图嵌入算法中，有效地改善了下游预测任务。 |
| [^51] | [Large Language Models Need Holistically Thought in Medical Conversational QA.](http://arxiv.org/abs/2305.05410) | 本研究提出了一种Holistically Thought（HoT）方法，用于引导大型语言模型进行综合性思考，以在医疗对话问答中生成高质量的医学响应。 |
| [^52] | [Distilling Script Knowledge from Large Language Models for Constrained Language Planning.](http://arxiv.org/abs/2305.05252) | 本文首次定义了受限语言规划任务，提出了一种方法来提高大型语言模型在这个任务中的表现，并提取了一个新颖的受限语言规划数据集。实验证明该方法显著提高了其在约束忠实度方面的能力，并对赋予较小的语言模型受限语言规划能力非常有效。 |
| [^53] | [Multi-Teacher Knowledge Distillation For Text Image Machine Translation.](http://arxiv.org/abs/2305.05226) | 本文提出了一种多教师知识蒸馏方法，可以将知识有效地蒸馏到管道模型中并传递给端到端TIMT模型，从而提高性能。 |
| [^54] | [E2TIMT: Efficient and Effective Modal Adapter for Text Image Machine Translation.](http://arxiv.org/abs/2305.05166) | 本文提出了一种高效有效的文图机器翻译模态适配器，利用现有OCR和MT数据库和新型模态适配器将OCR编码器和MT解码器连接，使得端到端TIMT模型在翻译质量和效率方面优于现有的两阶段级联模型和其他最先进的一级端到端模型。 |
| [^55] | [Web Content Filtering through knowledge distillation of Large Language Models.](http://arxiv.org/abs/2305.05027) | 本文提出了一种基于大语言模型知识蒸馏的 URL 分类方法，可用于网络内容过滤，其学生模型在参数数量减少 175 倍的情况下，精度提升了 9%，超过了当前最先进方法。 |
| [^56] | [CAT: A Contextualized Conceptualization and Instantiation Framework for Commonsense Reasoning.](http://arxiv.org/abs/2305.04808) | CAT提出了一种情景化常识推理的概念化和实例化框架，通过该框架，可以在大规模场景下概念化常识知识库，并在两个基准测试数据集上达到最先进的性能。 |
| [^57] | [X-LLM: Bootstrapping Advanced Large Language Models by Treating Multi-Modalities as Foreign Languages.](http://arxiv.org/abs/2305.04160) | 本论文提出了一种名为X-LLM的方法，将多模态信息转换为外语并输入到大型语言模型中，从而赋予LLM多模态能力，对于LLM加入多模态信息的能力进行了探究和拓展。 |
| [^58] | [Curating corpora with classifiers: A case study of clean energy sentiment online.](http://arxiv.org/abs/2305.03092) | 本文介绍了利用分类器来快速选择最佳的相关文档语料库进行分析的方法，探索了过滤掉不相关的推文的方法，以进行在线清洁能源情感分析。 |
| [^59] | [Causality-aware Concept Extraction based on Knowledge-guided Prompting.](http://arxiv.org/abs/2305.01876) | 该论文提出了一种基于因果感知的知识引导提示方法，将其作为干预器装备到基于预训练语言模型的句子提取器中，以缓解概念偏差。在代表性的多语言KG数据集上进行广泛实验，获得了最先进的结果。 |
| [^60] | [Turning Flowchart into Dialog: Plan-based Data Augmentation for Low-Resource Flowchart-grounded Troubleshooting Dialogs.](http://arxiv.org/abs/2305.01323) | 本文提出了一个基于计划的数据增强方法，能够将简洁的流程图转化成对话，以生成足够的数据来训练以流程图为基础的故障排除对话系统，实验结果表明该方法有效地提高了系统性能。 |
| [^61] | [Nominal Topology for Data Languages.](http://arxiv.org/abs/2304.13337) | 该论文提出了一种新的拓扑视角，用于描述可以被轨道有限的名义单子群识别的数据语言，并探讨了 pro-轨道有限方程的表现能力。 |
| [^62] | [Better Language Models of Code through Self-Improvement.](http://arxiv.org/abs/2304.01228) | 本文提出了一个简单的数据增强框架来改善预训练语言模型为代码生成和代码摘要等任务微调的瓶颈问题，提高了模型性能。 |
| [^63] | [Rediscovery of CNN's Versatility for Text-based Encoding of Raw Electronic Health Records.](http://arxiv.org/abs/2303.08290) | 本文发现，CNN在健康记录文本编码方面的多功能性和隐含层次结构可以提高其性能，提出了一种基于CNN的编码器来处理不同类型的EHR特征，并在临床任务中展示了其有效性。 |
| [^64] | [Distinguishability Calibration to In-Context Learning.](http://arxiv.org/abs/2302.06198) | 本文提出了一种旋转和缩放的特征变换校准方法，可用于基于提示的学习进行文本分类，从而解决了在转换器中进行上下文学习时遇到的信息扩散问题。 |
| [^65] | [What's happening in your neighborhood? A Weakly Supervised Approach to Detect Local News.](http://arxiv.org/abs/2301.08146) | 该论文介绍了一种自动化的本地新闻检测和基于内容的本地新闻推荐方法，通过弱监督框架和自动化数据处理，与传统方法相比具有更高的准确性和覆盖率。 |
| [^66] | [SMAuC -- The Scientific Multi-Authorship Corpus.](http://arxiv.org/abs/2211.02477) | SMAuC是一个包含300万篇科学文本，且元数据丰富的语料库，涵盖各个学科的500万作者，并旨在推进科学文本中的作者身份分析领域。 |
| [^67] | [QuaLA-MiniLM: a Quantized Length Adaptive MiniLM.](http://arxiv.org/abs/2210.17114) | QuaLA-MiniLM 是一种量化长度自适应的 MiniLM 模型，通过应用低比特化技术和 LAT 方法，实现了在各种 NLP 任务上的最新成果，同时保持较小的模型尺寸和高效率。 |
| [^68] | [Extracting Cultural Commonsense Knowledge at Scale.](http://arxiv.org/abs/2210.07763) | 本篇论文提出了一种名为CANDLE的方法，用于从网络语料库中提取文化常识知识，其优于之前的工作。这些知识对于情境化人工智能和GPT-3语言模型都有好处。 |
| [^69] | [C2KD: Cross-Lingual Cross-Modal Knowledge Distillation for Multilingual Text-Video Retrieval.](http://arxiv.org/abs/2210.03625) | 本文提出了一种跨语言跨模态知识蒸馏方法，使用不同语言的输入文本训练一个学生模型，与使用英语输入文本的教师模型的跨模态预测相匹配，以提升多语言文本-视频检索。我们引入了一个新的多语言视频数据集，Multi-YouCook2，以及在多个数据集上验证了我们方法的性能提升。 |
| [^70] | [Modeling Paragraph-Level Vision-Language Semantic Alignment for Multi-Modal Summarization.](http://arxiv.org/abs/2208.11303) | 本文提出了ViL-Sum，用于建模段落级别的视觉-语言语义对齐和多模态摘要生成。实验结果表明，ViL-Sum在两个基准数据集上优于现有方法，表明该方法的有效性和优越性。 |
| [^71] | [QAMPARI: An Open-domain Question Answering Benchmark for Questions with Many Answers from Multiple Paragraphs.](http://arxiv.org/abs/2205.12665) | 本论文提出了一个针对多段落多答案问题的开放域问答基准测试QAMPARI，并训练了ODQA模型。研究结果表明QAMPARI在段落检索和答案生成方面具有挑战性，强调了需要发展能够处理此类问题的ODQA模型。 |
| [^72] | [Representation Projection Invariance Mitigates Representation Collapse.](http://arxiv.org/abs/2205.11603) | 本文提出了一种新的正则化方法 REPINA，旨在减少表示崩溃问题，结果在 13 个语言理解任务上表现出良好的效果。 |
| [^73] | [GAP-Gen: Guided Automatic Python Code Generation.](http://arxiv.org/abs/2201.08810) | 本文介绍了一种基于 Python 语法约束和语义约束的引导自动生成 Python 代码的方法 GAP-Gen，通过微调 T5 和 CodeT5 这两种语言模型，在自动生成 Python 代码任务上保持了高生成性能。 |
| [^74] | [An Efficient Transformer Decoder with Compressed Sub-layers.](http://arxiv.org/abs/2101.00542) | 该论文提出了一种使用压缩子层的高效Transformer解码器，通过减少子层并提高并行性能够达到1.42倍的速度提升，同时确保性能与基线相当。 |

# 详细

[^1]: 视频聊天：以聊天为核心的视频理解系统

    VideoChat: Chat-Centric Video Understanding. (arXiv:2305.06355v1 [cs.CV])

    [http://arxiv.org/abs/2305.06355](http://arxiv.org/abs/2305.06355)

    本文提出了以聊天为核心的视频理解系统VideoChat，它通过可学习的神经接口将视频基础模型和大型语言模型集成在一起，擅长于时空推理、事件定位和因果关系推断。作者还提出了一个视频为中心的指令数据集，初步实验表明该系统在广泛的视频应用中具有潜力。

    

    本文提出了视频聊天（VideoChat）——一个端到端的以聊天为核心的视频理解系统，它通过可学习的神经接口将视频基础模型和大型语言模型集成在一起，擅长于时空推理、事件定位和因果关系推断。为了教授该系统的使用，我们提出了一个视频为中心的指令数据集，包含成千上万个视频和详细的描述和对话，这个数据集强调时空推理和因果关系，为培训以聊天为核心的视频理解系统提供了宝贵的资产。初步的定性实验揭示了我们的系统在广泛的视频应用中的潜力，并为未来的研究设定了标准。我们的代码和数据可以在 https://github.com/OpenGVLab/Ask-Anything 上获取。

    In this study, we initiate an exploration into video understanding by introducing VideoChat, an end-to-end chat-centric video understanding system. It integrates video foundation models and large language models via a learnable neural interface, excelling in spatiotemporal reasoning, event localization, and causal relationship inference. To instructively tune this system, we propose a video-centric instruction dataset, composed of thousands of videos matched with detailed descriptions and conversations. This dataset emphasizes spatiotemporal reasoning and causal relationships, providing a valuable asset for training chat-centric video understanding systems. Preliminary qualitative experiments reveal our system's potential across a broad spectrum of video applications and set the standard for future research. Access our code and data at https://github.com/OpenGVLab/Ask-Anything
    
[^2]: K-UniMorph：韩语通用词形学及其特征模式

    K-UniMorph: Korean Universal Morphology and its Feature Schema. (arXiv:2305.06335v1 [cs.CL])

    [http://arxiv.org/abs/2305.06335](http://arxiv.org/abs/2305.06335)

    本文介绍了一种韩语通用词形学数据集，保留韩语特色并采用Sylak-Glassman等人的词形特征模式，为韩语形态学范式领域做出了贡献。

    

    本文介绍了一种韩语通用词形学数据集，之前，韩语在数百种多样的世界语言中的形态学范式领域中一直处于少数。因此，我们提出了这种保留韩语特色的通用词形学范式。我们的K-UniMorph数据集中，我们详细概述了每个语法标准的动词结尾，并阐明如何提取变形形式以及如何生成词形模式。此数据集采用Sylak-Glassman等人（2015）和Sylak-Glassman（2016）的词形特征模式，而我们从Sejong形态分析语料库中提取变形形式，这是韩语最大的注释语料库之一。在数据创建过程中，我们的方法还包括调查从Sejong语料库中的转换的正确性。此外，我们使用三种不同的模型进行了变形任务。

    We present in this work a new Universal Morphology dataset for Korean. Previously, the Korean language has been underrepresented in the field of morphological paradigms amongst hundreds of diverse world languages. Hence, we propose this Universal Morphological paradigms for the Korean language that preserve its distinct characteristics. For our K-UniMorph dataset, we outline each grammatical criterion in detail for the verbal endings, clarify how to extract inflected forms, and demonstrate how we generate the morphological schemata. This dataset adopts morphological feature schema from Sylak-Glassman et al. (2015) and Sylak-Glassman (2016) for the Korean language as we extract inflected verb forms from the Sejong morphologically analyzed corpus that is one of the largest annotated corpora for Korean. During the data creation, our methodology also includes investigating the correctness of the conversion from the Sejong corpus. Furthermore, we carry out the inflection task using three di
    
[^3]: 大型语言模型的自动归属验证

    Automatic Evaluation of Attribution by Large Language Models. (arXiv:2305.06311v1 [cs.CL])

    [http://arxiv.org/abs/2305.06311](http://arxiv.org/abs/2305.06311)

    本文探讨了大型语言模型对归属验证的自动评估。研究发现通过提示LLMs和微调较小的LLMs两种方法都有效地检测到了错误的归属陈述。

    

    大型语言模型的最新发展方向是通过引用外部参考来生成和支持它们的主张。然而，评估归属问题，即验证生成的陈述是否确实被引用参考全面支持，仍然是一个开放的问题。本文研究了大型语言模型对归属验证的自动评估。我们首先提供了归属的定义，然后探讨了两种自动评估方法：提示LLMs和微调较小的LLMs。微调数据从相关任务（例如，问答、事实检查、自然语言推理和摘要）中重新利用。为了便于评估，我们手动策划了一组测试例子，其中包括12个领域的来自新必应发生器的测试例子。我们在经过策划的测试集和来自外部语料库的模拟测试例子上的结果表明，所提出的方法能够有效地检测到错误的归属陈述。

    A recent focus of large language model (LLM) development, as exemplified by generative search engines, is to incorporate external references to generate and support their claims. However, evaluating the attribution, i.e., verifying whether the generated statement is indeed fully supported by the cited reference, remains an open problem. Although human evaluation is common practice, it is costly and time-consuming. In this paper, we investigate the automatic evaluation of attribution by LLMs. We begin by providing a definition of attribution and then explore two approaches for automatic evaluation: prompting LLMs and fine-tuning smaller LMs. The fine-tuning data is repurposed from related tasks, such as question answering, fact-checking, natural language inference, and summarization. To facilitate the evaluation, we manually curate a set of test examples covering 12 domains from a generative search engine, New Bing. Our results on the curated test set and simulated test examples from ex
    
[^4]: 评估信息检索的嵌入式API

    Evaluating Embedding APIs for Information Retrieval. (arXiv:2305.06300v1 [cs.IR])

    [http://arxiv.org/abs/2305.06300](http://arxiv.org/abs/2305.06300)

    本篇论文旨在通过对语义嵌入API在实际检索场景中的分析,为从业者和研究人员找到适当的服务。结果表明，在英语上使用API重新排名BM25的结果是一种预算友好的最优做法。

    

    语言模型不断增大使得其普及化成为了一项挑战，因此许多公司和初创企业通过API向社区提供大型语言模型的访问权限。其中一个适用于密集检索的特定API是语义嵌入式API，其可构建给定文本的向量表示。在拥有越来越多API的情况下，本文旨在分析在实际检索场景中语义嵌入式API以帮助从业者和研究人员根据他们的需求找到适当的服务。具体而言，我们希望调查现有API在领域泛化和多语言检索方面的能力。为此，我们在两个标准基准BEIR和MIRACL上评估了嵌入式API。我们发现，使用API重新排名BM25结果是一种预算友好的方法，并且在英语上最有效，与标准做法即作为第一阶段检索器不同。

    The ever-increasing size of language models curtails their widespread access to the community, thereby galvanizing many companies and startups into offering access to large language models through APIs. One particular API, suitable for dense retrieval, is the semantic embedding API that builds vector representations of a given text. With a growing number of APIs at our disposal, in this paper, our goal is to analyze semantic embedding APIs in realistic retrieval scenarios in order to assist practitioners and researchers in finding suitable services according to their needs. Specifically, we wish to investigate the capabilities of existing APIs on domain generalization and multilingual retrieval. For this purpose, we evaluate the embedding APIs on two standard benchmarks, BEIR, and MIRACL. We find that re-ranking BM25 results using the APIs is a budget-friendly approach and is most effective on English, in contrast to the standard practice, i.e., employing them as first-stage retrievers
    
[^5]: 使用GPT-3对医学证据进行总结、简化和综合（成果参差不齐）

    Summarizing, Simplifying, and Synthesizing Medical Evidence Using GPT-3 (with Varying Success). (arXiv:2305.06299v1 [cs.CL])

    [http://arxiv.org/abs/2305.06299](http://arxiv.org/abs/2305.06299)

    本文评估了GPT-3在生物医学领域中生成文章摘要的能力，发现它对单个文章的总结和简化效果较好，但在综合多篇文章中所报告的证据方面表现欠佳。

    

    大型语言模型，特别是GPT-3，能够在几乎没有监督的情况下生成一流的普通领域新闻文章摘要。但是，尚不清楚这样的模型是否在更专业和高风险的领域，如生物医学中同样具备这样的能力。本文中，我们请领域专家（具备医学培训的人）评估由GPT-3生成的生物医学文章摘要，并考虑单一和多文档摘要情况。前者中，GPT-3的任务是生成描述随机对照试验的文章的常规和简明语言摘要；后者中，我们评估GPT-3在整个文章集中综合报告的程度。我们设计了一个注释方案来评估模型输出，并重点评估生成摘要的事实准确性。我们发现，虽然GPT-3能够忠实地总结和简化单个生物医学文章，但它在综合多个文章所提供的证据方面表现不佳。

    Large language models, particularly GPT-3, are able to produce high quality summaries of general domain news articles in few- and zero-shot settings. However, it is unclear if such models are similarly capable in more specialized, high-stakes domains such as biomedicine. In this paper, we enlist domain experts (individuals with medical training) to evaluate summaries of biomedical articles generated by GPT-3, given zero supervision. We consider both single- and multi-document settings. In the former, GPT-3 is tasked with generating regular and plain-language summaries of articles describing randomized controlled trials; in the latter, we assess the degree to which GPT-3 is able to \emph{synthesize} evidence reported across a collection of articles. We design an annotation scheme for evaluating model outputs, with an emphasis on assessing the factual accuracy of generated summaries. We find that while GPT-3 is able to summarize and simplify single biomedical articles faithfully, it stru
    
[^6]: CADGE：基于图结构知识聚合的上下文感知对话生成

    CADGE: Context-Aware Dialogue Generation Enhanced with Graph-Structured Knowledge Aggregation. (arXiv:2305.06294v1 [cs.CL])

    [http://arxiv.org/abs/2305.06294](http://arxiv.org/abs/2305.06294)

    本文提出了一种基于上下文感知的图注意力模型，可以将上下文增强的知识聚合过程与相关知识图的全局特征有效融合，将增强的图结构知识集成到基于上下文感知的对话生成模型中。实验证明，该模型在自动度量和人类评估方面均优于现有方法。

    

    常识知识（commonsense knowledge）对于自然语言处理任务来说至关重要。现有的方法通常将图知识与传统的图神经网络（GNNs）相结合，导致文本和图知识编码过程在串行流水线中被分离。我们认为，这些分离的表示学习阶段可能对神经网络学习包含在两种输入知识类型中的整体上下文是次优的。在本文中，我们提出了一种新颖的基于上下文感知的图注意力模型（Context-aware GAT），它可以基于上下文增强的知识聚合过程有效地融合相关知识图的全局特征。具体地，我们的框架利用了一种新颖的表示学习方法来处理异构特征——将图知识与文本相结合。据我们所知，这是第一次尝试在连接子图上分层应用图知识聚合以及上下文信息，并将增强的图结构知识集成到基于上下文感知的对话生成模型中。我们在两个基准数据集上的实验证明，所提出的模型在自动度量和人类评估方面均优于现有方法。

    Commonsense knowledge is crucial to many natural language processing tasks. Existing works usually incorporate graph knowledge with conventional graph neural networks (GNNs), leading to the text and graph knowledge encoding processes being separated in a serial pipeline. We argue that these separate representation learning stages may be suboptimal for neural networks to learn the overall context contained in both types of input knowledge. In this paper, we propose a novel context-aware graph-attention model (Context-aware GAT), which can effectively incorporate global features of relevant knowledge graphs based on a context-enhanced knowledge aggregation process. Specifically, our framework leverages a novel representation learning approach to process heterogeneous features - combining flattened graph knowledge with text. To the best of our knowledge, this is the first attempt at hierarchically applying graph knowledge aggregation on a connected subgraph in addition to contextual infor
    
[^7]: 上下文感知的文件简化

    Context-Aware Document Simplification. (arXiv:2305.06274v1 [cs.CL])

    [http://arxiv.org/abs/2305.06274](http://arxiv.org/abs/2305.06274)

    本论文讨论了如何在文件简化过程中使用上下文信息，以提高输出质量。通过迭代更大的文本单元或扩展系统架构来关注文档的高级话语表示的方式，可以使简化模型直接访问局部的跨句子文档上下文，从而实现最新的文档简化成果。

    

    到目前为止，大多数文本简化工作都集中在句子级输入上。早期的文件简化尝试仅通过迭代文档中的句子来应用这些方法。然而，这无法连贯地保持话语结构，导致输出质量不佳。最近，控制简化的策略已被利用为了在生成文档级计划（句子级简化操作序列）之后，在下游使用该计划来引导句子级简化，从而实现了文档简化的最新成果。然而，这仍然具有局限性，因为简化模型没有直接访问局部的跨句子文档上下文，很可能会对表面实现产生负面影响。我们探索了多种使用文件上下文在简化过程中的系统，通过迭代更大的文本单元或通过扩展系统架构来关注文档的高级话语表示。

    To date, most work on text simplification has focused on sentence-level inputs. Early attempts at document simplification merely applied these approaches iteratively over the sentences of a document. However, this fails to coherently preserve the discourse structure, leading to suboptimal output quality. Recently, strategies from controllable simplification have been leveraged to achieve state-of-the-art results on document simplification by first generating a document-level plan (a sequence of sentence-level simplification operations) and using this plan to guide sentence-level simplification downstream. However, this is still limited in that the simplification model has no direct access to the local inter-sentence document context, likely having a negative impact on surface realisation. We explore various systems that use document context within the simplification process itself, either by iterating over larger text units or by extending the system architecture to attend over a high-
    
[^8]: 学习鲁棒性的自注意力特征和标签自适应Mixup在语音情感识别中的应用

    Learning Robust Self-attention Features for Speech Emotion Recognition with Label-adaptive Mixup. (arXiv:2305.06273v1 [cs.CL])

    [http://arxiv.org/abs/2305.06273](http://arxiv.org/abs/2305.06273)

    本文提出了一种基于自注意力和标签自适应Mixup技术的方法，在语音情感识别中取得了优越的性能，能够有效地应对人类情感的不确定性。

    

    语音情感识别(SER)在与机器进行自然语言交互的情境下，旨在识别人类的情感，由于人类情感的不确定性，这被认为是一个具有挑战性的问题。尽管近年来在SER的研究中取得了一些进展，但最先进的模型仍然难以达到令人满意的性能。我们提出了一种基于自注意力的方法，该方法结合了标签自适应Mixup和中心损失。通过将混合数据中的标签概率进行适应性调整并将中心损失适应于该混合训练策略，我们的方法在性能上优于最先进的方法。

    Speech Emotion Recognition (SER) is to recognize human emotions in a natural verbal interaction scenario with machines, which is considered as a challenging problem due to the ambiguous human emotions. Despite the recent progress in SER, state-of-the-art models struggle to achieve a satisfactory performance. We propose a self-attention based method with combined use of label-adaptive mixup and center loss. By adapting label probabilities in mixup and fitting center loss to the mixup training scheme, our proposed method achieves a superior performance to the state-of-the-art methods.
    
[^9]: ComputeGPT：适用于数值问题的计算型聊天模型

    ComputeGPT: A computational chat model for numerical problems. (arXiv:2305.06223v1 [cs.PL])

    [http://arxiv.org/abs/2305.06223](http://arxiv.org/abs/2305.06223)

    ComputeGPT是一种计算型聊天模型，可以通过运行代码解决数值问题，结合本地浏览器的Python解释器和优化的提示，实现最先进的数值问题效率并为代码提供合适的前端和安全环境。

    

    语言模型在解决数值问题上不够精确，其结构要求的是概率性的下一个单词。本文提出了ComputeGPT：一种通过按需运行代码来解决计算问题的聊天模型。ComputeGPT将每个问题转换为相关的代码，运行代码并将计算结果作为聊天的一部分返回。我们将这种方法与基于本地浏览器的Python解释器和优化的提示相结合，以实现最先进的数值问题效率，并为代码提供合适的前端和安全环境。

    Language models are not accurate in numerical problems. Their architecture does not allow for anything less than a probabilistic next word. This paper introduces ComputeGPT: an approach of creating a chat model able to answer computational problems through running on-demand code. ComputeGPT converts each question to relevant code, runs the code, and returns the computed answer as part of the chat. We combine this approach with a local browser-based Python interpretation and fine-tuned prompts in order to achieve state-of-the-art efficiency on numerical problems and provide a suitable front-end and safe environment for the code to be executed in.
    
[^10]: 多任务端到端训练改进了对话式推荐

    Multi-Task End-to-End Training Improves Conversational Recommendation. (arXiv:2305.06218v1 [cs.CL])

    [http://arxiv.org/abs/2305.06218](http://arxiv.org/abs/2305.06218)

    本文表明，采用多任务端到端Transformer模型可以提高对话式推荐的性能，可竞争于先前采用复杂多组件方法的模型，通过微调我们的模型和额外的多任务学习设置，实现了知识在领域间的转移。

    

    本文分析了一个多任务端到端Transformer模型在对话式推荐任务上的性能，该任务旨在基于用户在对话中明确表示的偏好提供推荐。虽然先前的研究在此领域采用了复杂的多组件方法，其中对话管理和实体推荐任务由单独的组件处理，但我们表明，基于T5文本-文本Transformer模型的统一Transformer模型在推荐相关项目和生成对话方面都可以竞争。我们在ReDIAL对话式电影推荐数据集上微调我们的模型，并在多任务学习设置中创建了衍生自MovieLens的额外训练任务（例如基于输入电影预测电影属性和相关电影）。使用一系列探针研究，我们证明了在额外任务中学习到的知识被转移到了对话式推荐领域中。

    In this paper, we analyze the performance of a multitask end-to-end transformer model on the task of conversational recommendations, which aim to provide recommendations based on a user's explicit preferences expressed in dialogue. While previous works in this area adopt complex multi-component approaches where the dialogue management and entity recommendation tasks are handled by separate components, we show that a unified transformer model, based on the T5 text-to-text transformer model, can perform competitively in both recommending relevant items and generating conversation dialogue. We fine-tune our model on the ReDIAL conversational movie recommendation dataset, and create additional training tasks derived from MovieLens (such as the prediction of movie attributes and related movies based on an input movie), in a multitask learning setting. Using a series of probe studies, we demonstrate that the learned knowledge in the additional tasks is transferred to the conversational setti
    
[^11]: 大语言模型服务的隐私保护提示调整

    Privacy-Preserving Prompt Tuning for Large Language Model Services. (arXiv:2305.06212v1 [cs.CL])

    [http://arxiv.org/abs/2305.06212](http://arxiv.org/abs/2305.06212)

    RAPT是一个提供隐私保证的大语言模型服务的提示调整框架，采用本地差分隐私设置和新颖的隐私化标记重建任务，并在多种任务中取得有竞争力的性能和良好的隐私保护效果。

    

    提示调整为用户在新兴的大语言模型服务场景下使用其私有数据自定义大语言模型(LLM)的有效方式。但是，私有数据的敏感性需要在LLM服务定制中保护隐私。基于提示调整，我们提出了一种名为隐私保护提示调整(RAPT)的框架，为LLM服务提供隐私保证。RAPT采用本地隐私设置，允许用户使用本地差分隐私对其数据进行本地化隐私处理。由于在直接训练隐私化数据的情况下，提示调整表现不佳，因此我们引入了一种新颖的隐私化标记重建任务，与下游任务一起进行培训，使LLM学习更好的任务相关表示。尽管我们的框架简单，但实验表明，RAPT在各种任务中均具有竞争力的性能，并提供抵御对手的隐私保证。

    Prompt tuning provides an efficient way for users to customize Large Language Models (LLMs) with their private data in the emerging LLM service scenario. However, the sensitive nature of private data brings the need for privacy preservation in LLM service customization. Based on prompt tuning, we propose Privacy-Preserving Prompt Tuning (RAPT), a framework that provides privacy guarantees for LLM services. \textsc{rapt} adopts a local privacy setting, allowing users to privatize their data locally with local differential privacy. As prompt tuning performs poorly when directly trained on privatized data, we introduce a novel privatized token reconstruction task that is trained jointly with the downstream task, allowing LLMs to learn better task-dependent representations. Despite the simplicity of our framework, experiments show that RAPT achieves competitive performance across tasks while providing privacy guarantees against adversaries.
    
[^12]: 通过生成对抗反馈对语言模型进行微调

    Fine-tuning Language Models with Generative Adversarial Feedback. (arXiv:2305.06176v1 [cs.CL])

    [http://arxiv.org/abs/2305.06176](http://arxiv.org/abs/2305.06176)

    本研究探讨了一种新的方法，使用生成对抗反馈的强化学习(RLGAF)对大型语言模型进行微调，以取代仅受人类反馈的强化学习(RLHF)，从而消除评估者的专业限制并提高性能。

    

    通过人类反馈的强化学习已经显著提高了大型语言模型(LLMs)的性能，使其输出与人类期望的价值观保持一致。然而，RLHF受到人类评估者的专业知识和生产力限制。在本研究中，我们研究了一种替代方法: 使用生成对抗反馈的强化学习(RLGAF)代替RLHF。我们的初步发现表明，RLGAF可以帮助对齐LLM的输出，同时不会受到RLHF固有的限制，为进一步自动化AI对齐的研究提供了有希望的途径。

    Reinforcement Learning with Human Feedback (RLHF) has been demonstrated to significantly enhance the performance of large language models (LLMs) by aligning their outputs with desired human values. However, RLHF is constrained by the expertise and productivity limitations of human evaluators. In this study, we investigate an alternative approach: Reinforcement Learning with Generative Adversarial Feedback (RLGAF) to RLHF. Our preliminary findings indicate that RLGAF can help align LLMs outputs while not suffering from the inherent restrictions of RLHF, suggesting promising avenues for further research on automating AI alignment.
    
[^13]: 使用贝叶斯模型平均分析社交媒体上的气候宣传活动

    Analysis of Climate Campaigns on Social Media using Bayesian Model Averaging. (arXiv:2305.06174v1 [cs.CL])

    [http://arxiv.org/abs/2305.06174](http://arxiv.org/abs/2305.06174)

    本文分析了工业、倡导组织和气候倡导组织在社交媒体上如何影响气候变化的叙事，并提出了一个最小化监督模型组合方法，用于识别Facebook上气候广告的立场。

    

    气候变化是我们时代的核心问题，我们正处于一个关键时刻。各种利益集团、社会运动组织和个人在社交媒体上开展针对这个问题的集体行动。此外，社交媒体上的问题倡导活动往往是针对当前社会关注的问题，特别是能源行业面临的问题。本文的目标是分析工业、倡导组织和气候倡导组织如何利用社交媒体影响气候变化的叙事。在这项工作中，我们提出了一个最小化监督模型组合方法，并结合消息主题来识别Facebook上气候广告的立场。最后，我们发布了我们的立场数据集、模型和与气候宣传活动相关的主题，供未来的舆情挖掘和自动检测气候变化立场的研究使用。

    Climate change is the defining issue of our time, and we are at a defining moment. Various interest groups, social movement organizations, and individuals engage in collective action on this issue on social media. In addition, issue advocacy campaigns on social media often arise in response to ongoing societal concerns, especially those faced by energy industries. Our goal in this paper is to analyze how those industries, their advocacy group, and climate advocacy group use social media to influence the narrative on climate change. In this work, we propose a minimally supervised model soup [56] approach combined with messaging themes to identify the stances of climate ads on Facebook. Finally, we release our stance dataset, model, and set of themes related to climate campaigns for future work on opinion mining and the automatic detection of climate change stances.
    
[^14]: QICHWABASE: 一个面向凯楚亚社区的凯楚亚语言和知识库

    QICHWABASE: A Quechua Language and Knowledge Base for Quechua Communities. (arXiv:2305.06173v1 [cs.CL])

    [http://arxiv.org/abs/2305.06173](http://arxiv.org/abs/2305.06173)

    QICHWABASE为少数民族语言和知识构建Wikibase实例，支持凯楚亚社区和谐进程，能增强少数民族在网络上的存在感。

    

    近十年来，网络越来越成为语言和知识表示的空间。然而，这只针对广泛流行的语言和社区，在少数民族社区和其资源方面却受到较少关注。本文提出了QICHWABASE以支持凯楚亚语言和知识及其社区的和谐进程。为此，我们采用了一些方法和工具，能够成为全球凯楚亚社区的助推器。我们得出的结论是，在构建QICHWABASE，即一个Wikibase实例时采用的方法和工具能够增强少数民族在网络上的存在感。

    Over the last decade, the Web has increasingly become a space of language and knowledge representation. However, it is only true for well-spread languages and well-established communities, while minority communities and their resources received less attention. In this paper, we propose QICHWABASE to support the harmonization process of the Quechua language and knowledge, and its community. For doing it, we adopt methods and tools that could become a game changer in favour of Quechua communities around the world. We conclude that the methodology and tools adopted on building QICHWABASE, which is a Wikibase instance, could enhance the presence of minorities on the Web.
    
[^15]: ChatGPT作为去除偏见的文本简化工具

    ChatGPT as a Text Simplification Tool to Remove Bias. (arXiv:2305.06166v1 [cs.CL])

    [http://arxiv.org/abs/2305.06166](http://arxiv.org/abs/2305.06166)

    ChatGPT作为文本简化工具可以去除语言模型在训练过程中对某些特定群体的偏见，减少模型的歧视性。（注：ChatGPT是一种基于Transformer的自然语言处理模型）

    

    在训练期间，语言模型可以捕捉到特定子群体的特定语言信号，如果模型学习了捕捉某个群体的语言，可能会导致歧视。如果模型开始将特定语言与某个特定群体联系起来，基于此语言做出的任何决策都将与其受保护特征有着强烈的相关性。我们探索了一种可能的偏见缓解技术，即文本简化。这个想法的驱动力是简化文本应该标准化语言，使其以一种方式说话，同时保持相同的含义。实验显示，针对敏感属性预测的分类器精度会因使用简化数据而下降高达17%。

    The presence of specific linguistic signals particular to a certain sub-group of people can be picked up by language models during training. This may lead to discrimination if the model has learnt to pick up on a certain group's language. If the model begins to associate specific language with a distinct group, any decisions made based upon this language would hold a strong correlation to a decision based on their protected characteristic. We explore a possible technique for bias mitigation in the form of simplification of text. The driving force of this idea is that simplifying text should standardise language to one way of speaking while keeping the same meaning. The experiment shows promising results as the classifier accuracy for predicting the sensitive attribute drops by up to 17% for the simplified data.
    
[^16]: 动态上下文图形实现对万物知识图谱的会话语义解析

    Conversational Semantic Parsing using Dynamic Context Graphs. (arXiv:2305.06164v1 [cs.CL])

    [http://arxiv.org/abs/2305.06164](http://arxiv.org/abs/2305.06164)

    本论文提出了一种新的方法，使用动态创建的子图表示话语及上下文的信息来进行会话语义解析，并利用图形神经网络编码，可表示大量看不见的节点，比静态方法更为优越。

    

    本文考虑了在拥有数百万个实体和数千种关系类型的通用知识图谱上进行会话语义解析的任务。我们致力于开发能够交互地将用户语言映射为可执行逻辑形式（例如SPARQL）的模型，同时考虑到对话历史的上下文。我们的关键想法是通过一个动态创建的子图来表示有关话语及其上下文的信息，即每个话语的节点数会发生变化。而且，我们利用子图的基本结构，而不是将其视为序列，使用图形神经网络进行编码，从而进一步允许我们表示大量（看不见的）节点。实验结果表明，动态建模上下文优于静态方法，可在各个方面（即简单和复杂问题）提高性能。我们的结果进一步证实，模型化上下文结构比仅考虑单个话语更好。

    In this paper we consider the task of conversational semantic parsing over general purpose knowledge graphs (KGs) with millions of entities, and thousands of relation-types. We are interested in developing models capable of interactively mapping user utterances into executable logical forms (e.g., SPARQL) in the context of the conversational history. Our key idea is to represent information about an utterance and its context via a subgraph which is created dynamically, i.e., the number of nodes varies per utterance. Moreover, rather than treating the subgraph as a sequence we exploit its underlying structure, and thus encode it using a graph neural network which further allows us to represent a large number of (unseen) nodes. Experimental results show that modeling context dynamically is superior to static approaches, delivering performance improvements across the board (i.e., for simple and complex questions). Our results further confirm that modeling the structure of context is bette
    
[^17]: 基于大语言模型的代数错误分类方法

    Algebra Error Classification with Large Language Models. (arXiv:2305.06163v1 [cs.CL])

    [http://arxiv.org/abs/2305.06163](http://arxiv.org/abs/2305.06163)

    本研究提出了一种基于大语言模型的代数错误分类方法，相较于现有方法，具有更好的泛化能力和处理学生回答的能力。

    

    在回答开放式数学问题时自动反馈具有显著的潜力来提高大规模学习成果。自动反馈系统的关键部分是错误分类组件，该组件识别学生的错误，并启用适当的预定义反馈。大多数现有的错误分类方法使用基于规则的方法，其泛化能力有限。现有的数据驱动方法避免了这些限制，但具体要求将学生答复中的数学表达式解析为语法树。这一要求本身就是一个限制，因为学生的答复并不总是符合语法的，无法转换为树形结构。在这项工作中，我们介绍一种使用预训练的大型语言模型进行错误分类的灵活方法。我们证明我们的方法可以在代数错误分类方面优于现有方法，并能够对更大的学生回答进行分类。此外，我们还展示了我们的方法可以推广到其他领域和语言，而无需额外的训练数据。

    Automated feedback as students answer open-ended math questions has significant potential in improving learning outcomes at large scale. A key part of automated feedback systems is an error classification component, which identifies student errors and enables appropriate, predefined feedback to be deployed. Most existing approaches to error classification use a rule-based method, which has limited capacity to generalize. Existing data-driven methods avoid these limitations but specifically require mathematical expressions in student responses to be parsed into syntax trees. This requirement is itself a limitation, since student responses are not always syntactically valid and cannot be converted into trees. In this work, we introduce a flexible method for error classification using pre-trained large language models. We demonstrate that our method can outperform existing methods in algebra error classification, and is able to classify a larger set of student responses. Additionally, we 
    
[^18]: StarCoder: 源代码与你同在！

    StarCoder: may the source be with you!. (arXiv:2305.06161v1 [cs.CL])

    [http://arxiv.org/abs/2305.06161](http://arxiv.org/abs/2305.06161)

    本研究介绍了一个具有15.5B参数和8K上下文长度的大型语言模型——StarCoder，其可以进行快速大批量推理。经评估证明，在Python上表现优异，能够通过人工评估获得40\%的pass@1的得分，且在其他程序中也表现出令人满意的性能。

    

    BigCode社区是一个开放的科学合作组织，致力于开发代表代码的大型语言模型（Code LLMs）的负责任发展。该文介绍了StarCoder和StarCoderBase，这是具有15.5B参数模型和8K上下文长度、填充能力以及多种查询注意力实现的快速大批量推理的模型。我们对StarCoderBase的1万亿个标记进行 fine-tuning，创建了StarCoder。我们进行了迄今为止最全面的Code LLMs评估，并表明StarCoderBase优于支持多种编程语言的每个开放Code LLM，并与OpenAI code-cushman-001模型相匹配或优于该模型。此外，StarCoder在Python上也表现出优异性能，能够通过人工评估获得40\%的pass@1的得分，并仍然保持其在其他程序中的性能。

    The BigCode community, an open-scientific collaboration working on the responsible development of Large Language Models for Code (Code LLMs), introduces StarCoder and StarCoderBase: 15.5B parameter models with 8K context length, infilling capabilities and fast large-batch inference enabled by multi-query attention. StarCoderBase is trained on 1 trillion tokens sourced from The Stack, a large collection of permissively licensed GitHub repositories with inspection tools and an opt-out process. We fine-tuned StarCoderBase on 35B Python tokens, resulting in the creation of StarCoder. We perform the most comprehensive evaluation of Code LLMs to date and show that StarCoderBase outperforms every open Code LLM that supports multiple programming languages and matches or outperforms the OpenAI code-cushman-001 model. Furthermore, StarCoder outperforms every model that is fine-tuned on Python, can be prompted to achieve 40\% pass@1 on HumanEval, and still retains its performance on other program
    
[^19]: 视觉-语言模型综述及在“恶意表情”挑战中的表现

    A Review of Vision-Language Models and their Performance on the Hateful Memes Challenge. (arXiv:2305.06159v1 [cs.CL])

    [http://arxiv.org/abs/2305.06159](http://arxiv.org/abs/2305.06159)

    本文综述了视觉-语言模型及其在社交媒体内容审核上的应用，研究发现早期融合模型比晚期融合模型更有效，其中表现最佳的早期融合模型是ClipBERT。

    

    社交媒体内容的审核目前仍然是一项高度手动的任务，然而每天发布的内容量太多，难以有效执行。随着许多多模态模型的出现，有潜力降低该任务的手动劳动量。本文旨在探讨不同的模型并确定在“恶意表情”挑战中最有效的模型。具体来说，我们探讨了早期融合和晚期融合模型在分类包含文本和图像的多模态表情中的差异。我们首先使用BERT和ResNet-152分别实现了文本和图像的单模态基线模型。然后将这些单模态模型的输出连接在一起创建了一个晚期融合模型。在早期融合模型方面，我们实现了ConcatBERT、VisualBERT、ViLT、CLIP和BridgeTower。结果发现，晚期融合模型的表现明显不如早期融合模型，而表现最佳的早期融合模型是ClipBERT。我们的研究结果表明，视觉-语言模型有潜力改善社交媒体上的恶意内容审核，但还需要更多的研究来进一步提高其性能。

    Moderation of social media content is currently a highly manual task, yet there is too much content posted daily to do so effectively. With the advent of a number of multimodal models, there is the potential to reduce the amount of manual labor for this task. In this work, we aim to explore different models and determine what is most effective for the Hateful Memes Challenge, a challenge by Meta designed to further machine learning research in content moderation. Specifically, we explore the differences between early fusion and late fusion models in classifying multimodal memes containing text and images. We first implement a baseline using unimodal models for text and images separately using BERT and ResNet-152, respectively. The outputs from these unimodal models were then concatenated together to create a late fusion model. In terms of early fusion models, we implement ConcatBERT, VisualBERT, ViLT, CLIP, and BridgeTower. It was found that late fusion performed significantly worse th
    
[^20]: 多词语对于英语到巴提盲文机器翻译的影响

    Implications of Multi-Word Expressions on English to Bharti Braille Machine Translation. (arXiv:2305.06157v1 [cs.CL])

    [http://arxiv.org/abs/2305.06157](http://arxiv.org/abs/2305.06157)

    本文通过给基线神经机器翻译模型添加语言知识及多词语翻译子模块，在英语到巴提盲文机器翻译中取得了显著的改进。

    

    本文研究了如何提高英语到巴提盲文机器翻译系统，通过在基线神经机器翻译模型中加入语言知识，对五种语言对进行实验，即将英语句子翻译成五种印度语言，并随后翻译成相应的巴提盲文。通过添加子模块翻译多词语，本研究显示了可行的方法，跨语言对 NMT 输出质量有所提高。最小的改进出现在英语-尼泊尔语对中，为 22.08%，最大的改进出现在英语-印地语对中，为 23.30%。

    In this paper, we have shown the improvement of English to Bharti Braille machine translation system. We have shown how we can improve a baseline NMT model by adding some linguistic knowledge to it. This was done for five language pairs where English sentences were translated into five Indian languages and then subsequently to corresponding Bharti Braille. This has been demonstrated by adding a sub-module for translating multi-word expressions. The approach shows promising results as across language pairs, we could see improvement in the quality of NMT outputs. The least improvement was observed in English-Nepali language pair with 22.08% and the most improvement was observed in the English-Hindi language pair with 23.30%.
    
[^21]: The Vault：一个全面的多语言数据集，为促进代码理解和生成而设计

    The Vault: A Comprehensive Multilingual Dataset for Advancing Code Understanding and Generation. (arXiv:2305.06156v1 [cs.CL])

    [http://arxiv.org/abs/2305.06156](http://arxiv.org/abs/2305.06156)

    The Vault是一个提供了10种流行编程语言的40百万行代码-文本对的开源数据集，旨在增强面向代码的大型语言模型（LLM）的训练，有望在代码理解和生成任务上取得显著进展。

    

    我们介绍了 The Vault，这是一个开源的大规模代码文本数据集，旨在增强面向代码的大型语言模型（LLM）的训练。现有的用于训练基于代码的LLM的开源数据集在大小、质量(由于噪声信号)和格式（仅包含代码函数和文本说明配对）方面经常面临挑战。The Vault通过提供10种流行编程语言的40百万行代码-文本对，彻底清除10种多样的问题，以及各种级别的代码-文本对，包括类、函数和代码行等级别，来克服这些限制。研究人员和从业人员可以利用The Vault来训练不同的面向代码的LLM，或者将提供的数据清洗方法和脚本合并到自己的数据集中来改进数据集。通过将The Vault作为面向代码的LLMs的训练数据集，我们预计在代码理解和生成任务上取得显著进展，促进人工智能研究和实践的发展。

    We present The Vault, an open-source, large-scale code-text dataset designed to enhance the training of code-focused large language models (LLMs). Existing open-source datasets for training code-based LLMs often face challenges in terms of size, quality (due to noisy signals), and format (only containing code function and text explanation pairings). The Vault overcomes these limitations by providing 40 million code-text pairs across 10 popular programming languages, thorough cleaning for 10+ prevalent issues, and various levels of code-text pairings, including class, function, and line levels. Researchers and practitioners can utilize The Vault for training diverse code-focused LLMs or incorporate the provided data cleaning methods and scripts to improve their datasets. By employing The Vault as the training dataset for code-centric LLMs, we anticipate significant advancements in code understanding and generation tasks, fostering progress in both artificial intelligence research and so
    
[^22]: 利用合成目标进行机器翻译

    Leveraging Synthetic Targets for Machine Translation. (arXiv:2305.06155v1 [cs.CL])

    [http://arxiv.org/abs/2305.06155](http://arxiv.org/abs/2305.06155)

    本文提供了一种利用预训练模型生成合成目标从而提高机器翻译性能的方法，并发现其在不同测试基准下的表现优于使用真实数据训练，这一方法在有限资源的情况下尤其有用。

    

    在本文中，我们提供了一种在有限资源情况下训练机器翻译模型的方法，该方法通过利用通过大型预训练模型生成的合成目标数据。我们表明，在双语、多语言和语音翻译设置的不同基准测试中，使用合成目标训练模型的性能优于使用实际的正确数据训练模型。这种性能差距随着可用资源的限制（数据集大小和模型参数数量）的增加而变得更大。我们还对性能提升是否与优化的便利性或预测的更确定性相关进行了初步分析，以及这种范例是否能够提高在不同测试领域的超出分布性能。

    In this work, we provide a recipe for training machine translation models in a limited resource setting by leveraging synthetic target data generated using a large pre-trained model. We show that consistently across different benchmarks in bilingual, multilingual, and speech translation setups, training models on synthetic targets outperforms training on the actual ground-truth data. This performance gap grows bigger with increasing limits on the amount of available resources in the form of the size of the dataset and the number of parameters in the model. We also provide preliminary analysis into whether this boost in performance is linked to ease of optimization or more deterministic nature of the predictions, and whether this paradigm leads to better out-of-distribution performance across different testing domains.
    
[^23]: 缓解无监督句子表示中的平滑问题

    Alleviating Over-smoothing for Unsupervised Sentence Representation. (arXiv:2305.06154v1 [cs.CL])

    [http://arxiv.org/abs/2305.06154](http://arxiv.org/abs/2305.06154)

    本论文提出了自对抗学习（SSCL）方法，通过从PLMs较低层中采样负样本，缓解了无监督句子表示平滑问题，提升了句子表示的质量和性能。

    

    当前，学习更好的无监督句子表示是许多自然语言处理社区的追求。许多基于预训练语言模型（PLMs）和对比学习的方法在此任务上取得了有希望的结果。实验表明，过度平滑的问题降低了这些强大PLMs的能力，导致子优句子表示。在本文中，我们提出了一种简单的方法，称为自对抗学习（SSCL），以缓解这个问题，该方法从PLMs中间层中采样负面样本，提高句子表示的质量。我们提出的方法非常简单，可以轻松地扩展到各种最先进的模型进行性能提升，可以看作是一种插件式的对比框架，用于学习无监督句子表示。广泛的结果证明，SSCL带来了不同强基线的卓越性能改进（例如BERT和SimCSE）。

    Currently, learning better unsupervised sentence representations is the pursuit of many natural language processing communities. Lots of approaches based on pre-trained language models (PLMs) and contrastive learning have achieved promising results on this task. Experimentally, we observe that the over-smoothing problem reduces the capacity of these powerful PLMs, leading to sub-optimal sentence representations. In this paper, we present a Simple method named Self-Contrastive Learning (SSCL) to alleviate this issue, which samples negatives from PLMs intermediate layers, improving the quality of the sentence representation. Our proposed method is quite simple and can be easily extended to various state-of-the-art models for performance boosting, which can be seen as a plug-and-play contrastive framework for learning unsupervised sentence representation. Extensive results prove that SSCL brings the superior performance improvements of different strong baselines (e.g., BERT and SimCSE) on
    
[^24]: Structure-CLIP: 结合结构知识优化多模态语言表示

    Structure-CLIP: Enhance Multi-modal Language Representations with Structure Knowledge. (arXiv:2305.06152v1 [cs.CL])

    [http://arxiv.org/abs/2305.06152](http://arxiv.org/abs/2305.06152)

    Structure-CLIP使用文本中的结构化知识，使用场景图强化多模态语言表示，从而在图像-文本匹配任务中展现了更好的性能。

    

    大规模的视觉-语言预训练在各种下游任务中展现出了很好的性能，并在多模态理解和生成任务中取得了显著的进展。然而，现有方法在需要对文本进行详细语义理解的图像-文本匹配任务上通常表现较差。尽管已经有一些研究在解决这个问题，但它们没有充分利用句子中存在的结构化知识来增强多模态语言表示，导致性能较差。本文提出了一个端到端的框架Structure-CLIP，该框架结合了从文本中提取的隐式详细语义，以增强精细的语义表示。具体而言，(1)我们使用场景图来更加关注文本中的详细语义学习，并充分探索细粒度语义之间的结构化知识，(2)我们结合场景图的知识强化框架来充分利用这些信息。

    Large-scale vision-language pre-training has shown promising advances on various downstream tasks and achieved significant performance in multi-modal understanding and generation tasks. However, existing methods often perform poorly on image-text matching tasks that require a detailed semantics understanding of the text. Although there have been some works on this problem, they do not sufficiently exploit the structural knowledge present in sentences to enhance multi-modal language representations, which leads to poor performance. In this paper, we present an end-to-end framework Structure-CLIP, which integrates latent detailed semantics from the text to enhance fine-grained semantic representations. Specifically, (1) we use scene graphs in order to pay more attention to the detailed semantic learning in the text and fully explore structured knowledge between fine-grained semantics, and (2) we utilize the knowledge-enhanced framework with the help of the scene graph to make full use of
    
[^25]: 一种运输行业文档分类的半自动化方法

    A semi-automatic method for document classification in the shipping industry. (arXiv:2305.06148v1 [cs.CL])

    [http://arxiv.org/abs/2305.06148](http://arxiv.org/abs/2305.06148)

    运输行业使用OCR技术对文件进行分类以提高准确性和效率。该研究提出半自动化的方法，基于关键词频率构建一个稳健的文档分类系统，其在收集的85个违约案例和555个非违约案例上实现了93.31%的高分类准确度。

    

    在运输行业中，文档分类对于确保必要的文件被正确识别并处理以通过海关清关流程起着至关重要的作用。OCR技术被用于自动化文档分类过程，其中包括识别商业发票、装箱清单、进出口报关单、提单、海运提单、证书、航空或铁路货运提单、到达通知书、原产地证明、进口商安全申报和信用证等重要文件。通过使用OCR技术，运输行业可以提高文档分类和海关清关流程的准确性和效率。本研究旨在基于关键词频率构建一个稳健的文档分类系统。研究通过分析IN-D公司提供的违约诉讼文档得出，该文档收集自新加坡政府司法网站。数据库中包含85个违约案例和555个非违约案例，提出的方法实现了93.31%的高分类准确度。

    In the shipping industry, document classification plays a crucial role in ensuring that the necessary documents are properly identified and processed for customs clearance. OCR technology is being used to automate the process of document classification, which involves identifying important documents such as Commercial Invoices, Packing Lists, Export/Import Customs Declarations, Bills of Lading, Sea Waybills, Certificates, Air or Rail Waybills, Arrival Notices, Certificate of Origin, Importer Security Filings, and Letters of Credit. By using OCR technology, the shipping industry can improve accuracy and efficiency in document classification and streamline the customs clearance process. The aim of this study is to build a robust document classification system based on keyword frequencies. The research is carried out by analyzing Contract-Breach law documents available with IN-D. The documents were collected by scraping the Singapore Government Judiciary website. The database developed ha
    
[^26]: 基于ChatGPT和Debatepedia的查询导向摘要资源CQSumDP

    CQSumDP: A ChatGPT-Annotated Resource for Query-Focused Abstractive Summarization Based on Debatepedia. (arXiv:2305.06147v1 [cs.CL])

    [http://arxiv.org/abs/2305.06147](http://arxiv.org/abs/2305.06147)

    本文介绍了一种利用ChatGPT重新生成其查询以清理Debatepedia数据集噪声的方法，成功提高了查询相关性和摘要生成效果。

    

    Debatepedia是一个公开可用的数据集，包含有关有争议的话题的论点和反驳论点，近年来已广泛用于单文档查询导向的浓缩摘要任务。然而，最近发现该数据集存在噪声，即使在该数据集中的大多数查询都与相应的文档无关。本文提出了一种方法来清理Debatepedia数据集，利用大型语言模型的生成能力使其适用于查询导向的浓缩摘要，具体而言，利用ChatGPT的语言生成能力重新生成其查询。我们使用几个基准摘要模型评估了ChatGPT注释版本的Debatepedia数据集的有效性，并证明了新注释的Debatepedia在查询相关性和摘要生成方面优于原始数据集。

    Debatepedia is a publicly available dataset consisting of arguments and counter-arguments on controversial topics that has been widely used for the single-document query-focused abstractive summarization task in recent years. However, it has been recently found that this dataset is limited by noise and even most queries in this dataset do not have any relevance to the respective document. In this paper, we present a methodology for cleaning the Debatepedia dataset by leveraging the generative power of large language models to make it suitable for query-focused abstractive summarization. More specifically, we harness the language generation capabilities of ChatGPT to regenerate its queries. We evaluate the effectiveness of the proposed ChatGPT annotated version of the Debatepedia dataset using several benchmark summarization models and demonstrate that the newly annotated version of Debatepedia outperforms the original dataset in terms of both query relevance as well as summary generati
    
[^27]: PAI在SemEval-2023任务2中：利用外部实体信息进行命名实体识别的通用系统

    PAI at SemEval-2023 Task 2: A Universal System for Named Entity Recognition with External Entity Information. (arXiv:2305.06099v1 [cs.CL])

    [http://arxiv.org/abs/2305.06099](http://arxiv.org/abs/2305.06099)

    PAI团队提出了一种利用维基百科等外部实体信息的通用命名实体识别系统，在SemEval-2023任务2中表现出色，共赢得了7个奖项。

    

    MultiCoNER II任务旨在在低文本情境和存在拼写错误和错别字等噪音场景下，检测多种语言的复杂、模糊和细粒度命名实体。该任务由于上下文信息的缺乏、实体的高粒度（高达33种类）以及噪音数据的干扰而具有重要的挑战性。为了应对这些问题，我们的团队PAI提出了一种通用的命名实体识别系统，该系统集成了外部实体信息以提高性能。具体而言，我们的系统从知识库（即维基百科）中检索给定文本的实体属性，然后将实体信息与输入句子连接起来，将其馈入基于Transformer的模型。最终，我们的系统在13个轨道中赢得了2个一等奖，4个二等奖和1个三等奖。该系统的代码公开可供使用，网址为\url{https://github.com/diqiuzhuanzhuan/semeval-2023}。

    The MultiCoNER II task aims to detect complex, ambiguous, and fine-grained named entities in low-context situations and noisy scenarios like the presence of spelling mistakes and typos for multiple languages. The task poses significant challenges due to the scarcity of contextual information, the high granularity of the entities(up to 33 classes), and the interference of noisy data. To address these issues, our team {\bf PAI} proposes a universal Named Entity Recognition (NER) system that integrates external entity information to improve performance. Specifically, our system retrieves entities with properties from the knowledge base (i.e. Wikipedia) for a given text, then concatenates entity information with the input sentence and feeds it into Transformer-based models. Finally, our system wins 2 first places, 4 second places, and 1 third place out of 13 tracks. The code is publicly available at \url{https://github.com/diqiuzhuanzhuan/semeval-2023}.
    
[^28]: ChatGPT能力展示及其对AI研究的影响

    A Glimpse in ChatGPT Capabilities and its impact for AI research. (arXiv:2305.06087v1 [cs.AI])

    [http://arxiv.org/abs/2305.06087](http://arxiv.org/abs/2305.06087)

    ChatGPT展示了LLMs的强大能力，但这些模型的训练和运行需要巨大的计算资源和高昂的成本，预计会给AI研究带来重大影响。

    

    大型语言模型（LLMs）最近在人工智能（AI）研究领域成为热门话题。像Google、亚马逊、Facebook、特斯拉和苹果（GAFA）这样的公司正在大力发展这些模型。这些模型会使用海量的数据进行训练，可用于各种任务，包括语言翻译、文章生成和问答系统。然而，训练和运行这些模型所需的计算资源非常巨大，而硬件和电力的成本可能限制了那些没有GAFA资金和资源的研究实验室。本文将研究LLMs对AI研究的影响，重点关注GPT3.5/ChatGPT3.4，并给出使用这些模型进行研究的一些示例。

    Large language models (LLMs) have recently become a popular topic in the field of Artificial Intelligence (AI) research, with companies such as Google, Amazon, Facebook, Amazon, Tesla, and Apple (GAFA) investing heavily in their development. These models are trained on massive amounts of data and can be used for a wide range of tasks, including language translation, text generation, and question answering. However, the computational resources required to train and run these models are substantial, and the cost of hardware and electricity can be prohibitive for research labs that do not have the funding and resources of the GAFA. In this paper, we will examine the impact of LLMs on AI research. The pace at which such models are generated as well as the range of domains covered is an indication of the trend which not only the public but also the scientific community is currently experiencing. We give some examples on how to use such models in research by focusing on GPT3.5/ChatGPT3.4 and
    
[^29]: SemEval-2023任务11中的iLab Le-Wi-Di：模拟不一致性还是模拟观点？

    iLab at SemEval-2023 Task 11 Le-Wi-Di: Modelling Disagreement or Modelling Perspectives?. (arXiv:2305.06074v1 [cs.CL])

    [http://arxiv.org/abs/2305.06074](http://arxiv.org/abs/2305.06074)

    本文讨论了建模注释者不一致性的两种方法：分布式软标记方法和建模个体注释者或其组的观点。本文通过将两种方法结合起来的方式来模拟注释者不一致性。尽管多任务方法之前表现良好，但我们发现其在包含不同注释者观点的数据集上表现不佳。研究结果表明，该方法可以更细致地理解注释者不一致性，为更准确的观点建模提供可能。

    

    对于建模注释者不一致性，有两种竞争的方法：分布式软标记方法（旨在捕捉不一致程度）或建模个体注释者或其组的观点。我们采用了一个先前在建模观点方面表现成功的多任务架构，对SEMEVAL任务11的性能进行评估。我们将两种方法结合起来，即预测个别注释者的观点作为预测注释者不一致性的过渡步骤。尽管此方法之前表现良好，但我们发现在包含不同注释者观点的数据集上，多任务方法的表现不佳，这表明这种方法在建模观点时可能并不总是适用的。此外，我们的结果表明，虽然强烈的观点主义方法可能不会根据分布式方法使用的评估指标取得最先进的性能，但我们的方法允许更细致的理解注释者不一致性，并可以导致更准确的观点建模。

    There are two competing approaches for modelling annotator disagreement: distributional soft-labelling approaches (which aim to capture the level of disagreement) or modelling perspectives of individual annotators or groups thereof. We adapt a multi-task architecture -- which has previously shown success in modelling perspectives -- to evaluate its performance on the SEMEVAL Task 11. We do so by combining both approaches, i.e. predicting individual annotator perspectives as an interim step towards predicting annotator disagreement. Despite its previous success, we found that a multi-task approach performed poorly on datasets which contained distinct annotator opinions, suggesting that this approach may not always be suitable when modelling perspectives. Furthermore, our results explain that while strongly perspectivist approaches might not achieve state-of-the-art performance according to evaluation metrics used by distributional approaches, our approach allows for a more nuanced under
    
[^30]: ANALOGYKB：使用百万规模知识库开启语言模型的类比推理能力。

    ANALOGYKB: Unlocking Analogical Reasoning of Language Models with A Million-scale Knowledge Base. (arXiv:2305.05994v1 [cs.CL])

    [http://arxiv.org/abs/2305.05994](http://arxiv.org/abs/2305.05994)

    本文提出了ANALOGYKB，一种使用百万规模知识库的类比推理方法，能够使语言模型在类比推理任务上取得比之前的最先进方法更好的结果。

    

    类比推理是人类的一项基本认知能力，然而，由于缺乏模型训练资源，目前的语言模型仍然难以在类比推理任务中达到人类的表现水平。本文提出了ANALOGYKB，这是一个百万规模的类比知识库，它由现有的知识图谱导出。ANALOGYKB从知识图谱中识别了两种类型的类比：1）相同关系的类比，可以直接从知识图谱中提取；2）类似关系的类比，则由大型语言模型（InstructGPT）启用的选择和过滤管道进行识别，再经过少量人工质量控制。在两个类比推理任务（类比识别和生成）的一系列数据集上的评估表明，ANALOGYKB成功地使语言模型取得了比之前的最先进方法更好的结果。

    Analogical reasoning is a fundamental cognitive ability of humans. However, current language models (LMs) still struggle to achieve human-like performance in analogical reasoning tasks due to a lack of resources for model training. In this work, we address this gap by proposing ANALOGYKB, a million-scale analogy knowledge base (KB) derived from existing knowledge graphs (KGs). ANALOGYKB identifies two types of analogies from the KGs: 1) analogies of the same relations, which can be directly extracted from the KGs, and 2) analogies of analogous relations, which are identified with a selection and filtering pipeline enabled by large LMs (InstructGPT), followed by minor human efforts for data quality control. Evaluations on a series of datasets of two analogical reasoning tasks (analogy recognition and generation) demonstrate that ANALOGYKB successfully enables LMs to achieve much better results than previous state-of-the-art methods.
    
[^31]: 使用大型语言模型的多阶段方法生成医学精确的患者-医生对话摘要

    Generating medically-accurate summaries of patient-provider dialogue: A multi-stage approach using large language models. (arXiv:2305.05982v1 [cs.CL])

    [http://arxiv.org/abs/2305.05982](http://arxiv.org/abs/2305.05982)

    本文需要解决医疗对话摘要的问题，通过将任务划分为几个小的对话任务依次构建，使用GPT-3大型语言模型，动态构建提示任务以及确定医学实体及其确认状态。

    

    医疗提供者对患者访问的摘要具有关键作用，包括临床决策、协调医疗团队和患者的参考资料。有效的摘要需要流畅，并准确捕捉对话中的所有医学相关信息，尽管患者语言的复杂性。即使在访问摘要中出现轻微的不准确 (例如，在发热时总结为“患者没有发烧”) 也会对患者的护理结果产生不利影响。本文将医学会话摘要问题划分为数个小型对话理解任务，其会依次构建。首先，我们确定对话中的医学实体及其确认状态，作为构建模块，通过在关联患者信息的情况下进行动态构建少量提示任务。使用GPT-3作为我们的支撑。

    A medical provider's summary of a patient visit serves several critical purposes, including clinical decision-making, facilitating hand-offs between providers, and as a reference for the patient. An effective summary is required to be coherent and accurately capture all the medically relevant information in the dialogue, despite the complexity of patient-generated language. Even minor inaccuracies in visit summaries (for example, summarizing "patient does not have a fever" when a fever is present) can be detrimental to the outcome of care for the patient.  This paper tackles the problem of medical conversation summarization by discretizing the task into several smaller dialogue-understanding tasks that are sequentially built upon. First, we identify medical entities and their affirmations within the conversation to serve as building blocks. We study dynamically constructing few-shot prompts for tasks by conditioning on relevant patient information and use GPT-3 as the backbone for our 
    
[^32]: 说到做到! 大型语言模型在负面常识知识方面存在太过乐观的表述

    Say What You Mean! Large Language Models Speak Too Positively about Negative Commonsense Knowledge. (arXiv:2305.05976v1 [cs.CL])

    [http://arxiv.org/abs/2305.05976](http://arxiv.org/abs/2305.05976)

    本文研究了大型语言模型(LLMs)对负面常识知识的了解程度，发现LLMs在生成基于负面知识的有效句子方面存在困难，但在回答极性问题方面表现良好，这种信念冲突主要源于语言预训练时的统计快捷方式和否定报告偏见。

    

    大型语言模型(LLMs)因能够存储和利用正面知识而被广泛研究。但是，负面知识，如“狮子不生活在海洋中”，也是世界上无处不在的，但很少在文本中明确提到。LLMs对负面常识知识了解多少？本文研究了LLMs对负面常识知识的了解能力。我们设计了一个有限制的关键词到句子生成任务(CG)和一个布尔型问答任务(QA)来探测LLMs。我们的实验揭示，LLMs经常无法生成基于负面常识知识的有效句子，但它们可以正确地回答极性的是或否问题。我们将这一现象称为LLMs的信念冲突。我们的进一步分析表明，语言建模预训练阶段的统计快捷方式和否定报告偏见引起了这种冲突。

    Large language models (LLMs) have been widely studied for their ability to store and utilize positive knowledge. However, negative knowledge, such as "lions don't live in the ocean", is also ubiquitous in the world but rarely mentioned explicitly in the text. What do LLMs know about negative knowledge? This work examines the ability of LLMs to negative commonsense knowledge. We design a constrained keywords-to-sentence generation task (CG) and a Boolean question-answering task (QA) to probe LLMs. Our experiments reveal that LLMs frequently fail to generate valid sentences grounded in negative commonsense knowledge, yet they can correctly answer polar yes-or-no questions. We term this phenomenon the belief conflict of LLMs. Our further analysis shows that statistical shortcuts and negation reporting bias from language modeling pre-training cause this conflict.
    
[^33]: 使用差分隐私大语言模型合成查询的隐私保护推荐系统.

    Privacy-Preserving Recommender Systems with Synthetic Query Generation using Differentially Private Large Language Models. (arXiv:2305.05973v1 [cs.CL])

    [http://arxiv.org/abs/2305.05973](http://arxiv.org/abs/2305.05973)

    提出使用差分隐私大语言模型合成查询的隐私保护推荐系统，可以安全有效地训练深度检索模型并提高检索质量。

    

    我们提出了一种新颖的方法，使用差分隐私大语言模型（LLMs）开发隐私保护的大规模推荐系统，克服了在训练这些复杂系统时的某些挑战和限制。我们的方法特别适用于基于LLM的推荐系统的新兴领域，但也可以轻松地用于处理自然语言输入表示的任何推荐系统。我们的方法涉及使用DP训练方法，对公开预训练的LLM在查询生成任务上进行微调。生成的模型可以生成私有合成查询，代表原始查询，可以在任何下游非私有推荐训练过程中自由共享，而不会产生任何额外的隐私成本。我们评估了我们的方法对安全训练有效的深度检索模型的能力，我们观察到它们的检索质量有显着的提高，而不会损害查询级别的隐私。

    We propose a novel approach for developing privacy-preserving large-scale recommender systems using differentially private (DP) large language models (LLMs) which overcomes certain challenges and limitations in DP training these complex systems. Our method is particularly well suited for the emerging area of LLM-based recommender systems, but can be readily employed for any recommender systems that process representations of natural language inputs. Our approach involves using DP training methods to fine-tune a publicly pre-trained LLM on a query generation task. The resulting model can generate private synthetic queries representative of the original queries which can be freely shared for any downstream non-private recommendation training procedures without incurring any additional privacy cost. We evaluate our method on its ability to securely train effective deep retrieval models, and we observe significant improvements in their retrieval quality without compromising query-level pri
    
[^34]: 通过持续学习研究预训练表示中的遗忘现象

    Investigating Forgetting in Pre-Trained Representations Through Continual Learning. (arXiv:2305.05968v1 [cs.CL])

    [http://arxiv.org/abs/2305.05968](http://arxiv.org/abs/2305.05968)

    本文研究了在持续学习中的表示遗忘对预训练语言模型通用性的影响，并提出了两个减轻该遗忘的见解。

    

    表示遗忘是指在不断的训练过程中，上下文表示的漂移。直观地说，表示遗忘会影响预训练语言模型中储存的通用知识，但具体影响仍不清楚。本文研究表示遗忘对预训练语言模型的通用性的影响，即处理未来下游任务的潜在能力。我们设计了三个度量标准，包括总体通用性破坏（GD）、句法知识遗忘（SynF）和语义知识遗忘（SemF），以衡量通用知识在持续学习中的演变。通过大量实验，我们发现多种预训练语言模型的通用性遭到破坏，而且语法和语义知识在持续学习中也会遗忘。基于我们的实验和分析，我们进一步得出两个减轻通用知识遗忘的见解：1）在通用和特定任务之间平衡， 2）在序列到序列模型中加入辅助任务。

    Representation forgetting refers to the drift of contextualized representations during continual training. Intuitively, the representation forgetting can influence the general knowledge stored in pre-trained language models (LMs), but the concrete effect is still unclear. In this paper, we study the effect of representation forgetting on the generality of pre-trained language models, i.e. the potential capability for tackling future downstream tasks. Specifically, we design three metrics, including overall generality destruction (GD), syntactic knowledge forgetting (SynF), and semantic knowledge forgetting (SemF), to measure the evolution of general knowledge in continual learning. With extensive experiments, we find that the generality is destructed in various pre-trained LMs, and syntactic and semantic knowledge is forgotten through continual learning. Based on our experiments and analysis, we further get two insights into alleviating general knowledge forgetting: 1) training on gene
    
[^35]: 多模态虚假信息解释性检测与逻辑推理

    Interpretable Multimodal Misinformation Detection with Logic Reasoning. (arXiv:2305.05964v1 [cs.MM])

    [http://arxiv.org/abs/2305.05964](http://arxiv.org/abs/2305.05964)

    本文提出了一种新的基于逻辑的多模态虚假信息检测神经模型，通过集成可解释性逻辑子句表达目标任务的推理过程，并使用神经表征参数化符号逻辑元素，从而便于自动生成和评估有意义的逻辑子句。此外，引入了五个元预测器来捕获虚假信息的基本模式。实验结果表明，该模型不仅性能显著优于当前方法，而且提供了透明且可解释的逻辑推理过程。

    

    在线社交平台上的多模态虚假信息由于多媒体内容的可信度和传播更容易而变得越来越重要。虽然现有的多模态检测方法已经达到了较高的性能，但缺乏解释性阻碍了这些系统的可靠性和实际部署。受到 NeuralSymbolic AI 的启发，该方法结合了神经网络的学习能力和符号学习的可解释性，我们提出了一种新的基于逻辑的多模态虚假信息检测神经模型，它集成了可解释性逻辑子句以表达目标任务的推理过程。为了使学习有效，我们使用神经表征来参数化符号逻辑元素，从而便于自动生成和评估有意义的逻辑子句。另外，为了使我们的框架可适用于各种虚假信息来源，我们在多模态融合网络中引入了五个元预测器来捕获虚假信息的基本模式。我们在实际的多模态虚假信息数据集上进行了大量实验，结果表明，我们的模型不仅显着优于现有方法，还为每个预测提供了透明且可解释的逻辑推理过程。

    Multimodal misinformation on online social platforms is becoming a critical concern due to increasing credibility and easier dissemination brought by multimedia content, compared to traditional text-only information. While existing multimodal detection approaches have achieved high performance, the lack of interpretability hinders these systems' reliability and practical deployment. Inspired by NeuralSymbolic AI which combines the learning ability of neural networks with the explainability of symbolic learning, we propose a novel logic-based neural model for multimodal misinformation detection which integrates interpretable logic clauses to express the reasoning process of the target task. To make learning effective, we parameterize symbolic logical elements using neural representations, which facilitate the automatic generation and evaluation of meaningful logic clauses. Additionally, to make our framework generalizable across diverse misinformation sources, we introduce five meta-pre
    
[^36]: 多路径Transformer更好：神经机器翻译的案例研究

    Multi-Path Transformer is Better: A Case Study on Neural Machine Translation. (arXiv:2305.05948v1 [cs.CL])

    [http://arxiv.org/abs/2305.05948](http://arxiv.org/abs/2305.05948)

    本文研究了多路径结构对Transformer模型的影响，通过在每个子层中添加归一化、产生更多特征的廉价操作和可学习的加权机制来融合从不同路径提取的特征，实验发现相同参数下浅层多路径模型可以实现与深层模型相似甚至更好的性能。

    

    多年来，机器学习模型的性能遵循参数尺寸为幂律分布的规律。为了考虑参数效率，最近的研究集中于增加模型深度而非宽度，以实现更好的性能。本文通过一个参数高效的多路径结构来研究模型宽度如何影响Transformer模型。为了更好地融合从不同路径提取的特征，我们在每个子层中添加了三个附加操作：每个路径末尾的归一化、产生更多特征的廉价操作以及可学习的加权机制，以灵活地融合所有特征。在12个WMT机器翻译任务上的大量实验表明，拥有相同数量参数的浅层多路径模型可以实现与深层模型相似甚至更好的性能，揭示了应更加关注多路径结构，并应在模型深度和宽度之间达成平衡，以训练更好的大规模机器学习模型。

    For years the model performance in machine learning obeyed a power-law relationship with the model size. For the consideration of parameter efficiency, recent studies focus on increasing model depth rather than width to achieve better performance. In this paper, we study how model width affects the Transformer model through a parameter-efficient multi-path structure. To better fuse features extracted from different paths, we add three additional operations to each sublayer: a normalization at the end of each path, a cheap operation to produce more features, and a learnable weighted mechanism to fuse all features flexibly. Extensive experiments on 12 WMT machine translation tasks show that, with the same number of parameters, the shallower multi-path model can achieve similar or even better performance than the deeper model. It reveals that we should pay more attention to the multi-path structure, and there should be a balance between the model depth and width to train a better large-sc
    
[^37]: 多语言LLMs是更好的跨语言上下文学习者与对齐效果。

    Multilingual LLMs are Better Cross-lingual In-context Learners with Alignment. (arXiv:2305.05940v1 [cs.CL])

    [http://arxiv.org/abs/2305.05940](http://arxiv.org/abs/2305.05940)

    针对跨语言ICL中无法对准输入输出空间的问题，我们提出了一种新的提示构建策略X-InSTA，可以同时对源语言和目标语言的语境进行编码和对齐，从而提高跨语言ICL的效率。

    

    随着大语言模型能够在没有任何梯度更新的情况下推断出以少数标记样本为条件的测试标签，上下文学习(ICL)成为可能。启用ICL的大语言模型为在低资源环境下规避复发性注释成本提供了有希望的前进步伐。然而，过去只有少数几项研究探究了跨语言设置下的ICL，这在从高资源语言到低资源语言转移标签知识的需要下至关重要。为了弥合这一鸿沟，我们首次对跨语言文本分类的ICL进行了深入分析。我们发现，在跨语言ICL的情况下，普遍选择随机的输入-标签对来构建提示上下文的模式严重受限于输入和输出空间的缺乏对准。为了缓解这一问题，我们提出了一种新的提示构建策略——跨语言上下文源-目标对齐（X-InSTA）。通过注入共同训练的阈值元素，X-InSTA可以同时对源语言和目标语言的语境进行编码和对齐，从而提高跨语言ICL的效率。

    In-context learning (ICL) unfolds as large language models become capable of inferring test labels conditioned on a few labeled samples without any gradient update. ICL-enabled large language models provide a promising step forward toward bypassing recurrent annotation costs in a low-resource setting. Yet, only a handful of past studies have explored ICL in a cross-lingual setting, in which the need for transferring label-knowledge from a high-resource language to a low-resource one is immensely crucial. To bridge the gap, we provide the first in-depth analysis of ICL for cross-lingual text classification. We find that the prevalent mode of selecting random input-label pairs to construct the prompt-context is severely limited in the case of cross-lingual ICL, primarily due to the lack of alignment in the input as well as the output spaces. To mitigate this, we propose a novel prompt construction strategy -- Cross-lingual In-context Source-Target Alignment (X-InSTA). With an injected co
    
[^38]: 多跳公共常识知识注入框架用于零样本常识问答

    Multi-hop Commonsense Knowledge Injection Framework for Zero-Shot Commonsense Question Answering. (arXiv:2305.05936v1 [cs.CL])

    [http://arxiv.org/abs/2305.05936](http://arxiv.org/abs/2305.05936)

    本文提出了一个多跳公共常识知识注入框架用于零样本常识问答，使用符合语言逻辑的多跳推理范式，提高了对多跳关系的识别能力，并在两个基准数据集上表现出了更好的效果。

    

    公共常识问答研究需要机器基于常识知识回答问题。然而，这种研究需要昂贵的劳动力成本来注释数据作为研究基础，依赖fine-tuning范式的模型只适用于特定任务，无法学习一般的常识推理能力。作为一种更强大的方法，零样本常识问答显示出良好的前景。当前的零样本框架试图将常识知识图中的三元组转化为QA形式的样本，作为预训练数据源，将常识知识融入模型中。然而，此方法忽略了KG中的多跳关系，这也是常识推理中的一个重要问题。在本文中，我们提出了一种新的多跳公共常识知识注入框架。具体来说，它探索符合语言逻辑的KG中的多跳推理范式，并进一步提出了两种基于所提出的框架的多跳QA生成模式。实验表明，所提出的框架在两个零样本常识QA基准数据集上的表现优于以前的最先进模型。

    Commonsense question answering (QA) research requires machines to answer questions based on commonsense knowledge. However, this research requires expensive labor costs to annotate data as the basis of research, and models that rely on fine-tuning paradigms only apply to specific tasks, rather than learn a general commonsense reasoning ability. As a more robust method, zero-shot commonsense question answering shows a good prospect. The current zero-shot framework tries to convert triples in commonsense knowledge graphs (KGs) into QA-form samples as the pre-trained data source to incorporate commonsense knowledge into the model. However, this method ignores the multi-hop relationship in the KG, which is also an important central problem in commonsense reasoning. In this paper, we propose a novel multi-hop commonsense knowledge injection framework. Specifically, it explores multi-hop reasoning paradigm in KGs that conform to linguistic logic, and we further propose two multi-hop QA gener
    
[^39]: WikiSQE：维基百科中句子质量估计的大规模数据集

    WikiSQE: A Large-Scale Dataset for Sentence Quality Estimation in Wikipedia. (arXiv:2305.05928v1 [cs.CL])

    [http://arxiv.org/abs/2305.05928](http://arxiv.org/abs/2305.05928)

    WikiSQE是第一个用于维基百科中句子质量估计的大规模数据集，其中包含约3.4M个句子和153个质量标签。在这个数据集上进行的实验表明，具有引文、语法/语义或命题问题的句子更难以检测。

    

    维基百科可以被任何人编辑，因此包含各种质量的句子。因此，维基百科包含一些质量较差的编辑，这些编辑通常会被其他编辑标记。虽然编辑的评论增强了维基百科的可信度，但很难检查所有编辑的文本。协助这个过程非常重要，但目前还没有一个大而全面的数据集来研究它。在这里，我们提出了 WikiSQE，这是第一个用于维基百科中句子质量估计的大规模数据集。每个句子都是从维基百科的整个修订历史中提取的，并且目标质量标签经过了仔细的调查和选择。WikiSQE具有约3.4 million个句子和153个质量标签。在使用竞争机器学习模型进行自动分类的实验中，发现具有引文，语法/语义或命题问题的句子更难以检测。此外，我们进行了自动作文评分实验，以评估生成摘要的有效性。

    Wikipedia can be edited by anyone and thus contains various quality sentences. Therefore, Wikipedia includes some poor-quality edits, which are often marked up by other editors. While editors' reviews enhance the credibility of Wikipedia, it is hard to check all edited text. Assisting in this process is very important, but a large and comprehensive dataset for studying it does not currently exist. Here, we propose WikiSQE, the first large-scale dataset for sentence quality estimation in Wikipedia. Each sentence is extracted from the entire revision history of Wikipedia, and the target quality labels were carefully investigated and selected. WikiSQE has about 3.4 M sentences with 153 quality labels. In the experiment with automatic classification using competitive machine learning models, sentences that had problems with citation, syntax/semantics, or propositions were found to be more difficult to detect. In addition, we conducted automated essay scoring experiments to evaluate the gen
    
[^40]: Decker: 双重检查与异构知识用于常识事实验证

    Decker: Double Check with Heterogeneous Knowledge for Commonsense Fact Verification. (arXiv:2305.05921v1 [cs.CL])

    [http://arxiv.org/abs/2305.05921](http://arxiv.org/abs/2305.05921)

    Decker是一种能够利用结构化和非结构化知识之间的潜在关系来桥接异构知识的常识事实验证模型，具有良好的验证效果和获取珍贵信息的能力。

    

    常识事实验证作为常识问答的一个具有挑战性的分支，旨在通过事实来验证一个给定的常识论断是否正确。回答常识问题需要从不同层次的知识中进行组合。然而，现有的研究主要依靠把握非结构化证据或从结构化知识库中找到潜在的推理路径，但没有同时利用异构知识的好处。鉴于此，我们提出了Decker，一种常识事实验证模型，能够通过发现结构化和非结构化知识之间的潜在关系来桥接异构知识。在两个常识事实验证基准数据集CSQA2.0和CREAK上的实验结果证明了我们Decker的有效性，进一步的分析验证了它在推理中获取更多珍贵信息的能力。

    Commonsense fact verification, as a challenging branch of commonsense question-answering (QA), aims to verify through facts whether a given commonsense claim is correct or not. Answering commonsense questions necessitates a combination of knowledge from various levels. However, existing studies primarily rest on grasping either unstructured evidence or potential reasoning paths from structured knowledge bases, yet failing to exploit the benefits of heterogeneous knowledge simultaneously. In light of this, we propose Decker, a commonsense fact verification model that is capable of bridging heterogeneous knowledge by uncovering latent relationships between structured and unstructured knowledge. Experimental results on two commonsense fact verification benchmark datasets, CSQA2.0 and CREAK demonstrate the effectiveness of our Decker and further analysis verifies its capability to seize more precious information through reasoning.
    
[^41]: 基于层级信息的地址匹配

    Address Matching Based On Hierarchical Information. (arXiv:2305.05874v1 [cs.CL])

    [http://arxiv.org/abs/2305.05874](http://arxiv.org/abs/2305.05874)

    本文提出了一种基于层级信息的地址匹配方法，通过利用深度学习方法中的层级信息，提高了现有方法处理不规则地址的能力，并可以更加关注地址的特殊部分，实验结果表明性能提高了3.2个百分点。

    

    有证据显示，地址匹配在许多领域中发挥着至关重要的作用，比如快递、在线购物等。地址具有分层结构，与非结构化文本形成对比，这可以为地址匹配提供有价值的信息。基于这种想法，本文提出了一种新的方法，利用深度学习方法中的层级信息，不仅提高了现有方法处理不规则地址的能力，还可以更密切地关注地址的特殊部分。实验结果表明，所提出的方法将现有方法的性能提高了3.2个百分点。

    There is evidence that address matching plays a crucial role in many areas such as express delivery, online shopping and so on. Address has a hierarchical structure, in contrast to unstructured texts, which can contribute valuable information for address matching. Based on this idea, this paper proposes a novel method to leverage the hierarchical information in deep learning method that not only improves the ability of existing methods to handle irregular address, but also can pay closer attention to the special part of address. Experimental findings demonstrate that the proposed method improves the current approach by 3.2% points.
    
[^42]: ChatGPT和GPT-4是否是金融文本分析的通用求解器？对几种典型任务进行检验。

    Are ChatGPT and GPT-4 General-Purpose Solvers for Financial Text Analytics? An Examination on Several Typical Tasks. (arXiv:2305.05862v1 [cs.CL])

    [http://arxiv.org/abs/2305.05862](http://arxiv.org/abs/2305.05862)

    本研究探讨了ChatGPT和GPT-4在金融文本分析任务中的潜力，结果显示它们在数值推理上表现出色但在需要领域特定知识的任务上表现不佳。

    

    最近的大型语言模型如ChatGPT和GPT-4引起了人们的广泛关注，因为它们能够生成高质量的对话回应。尽管ChatGPT和GPT-4在通用文本语料库上经过了广泛的测试，展示了它们令人印象深刻的能力，但还没有对金融语料库进行研究。本研究旨在通过在零样本或少样本情况下考察ChatGPT和GPT-4作为典型金融文本分析问题求解器的潜力来弥补这一差距。具体而言，我们评估了它们在五个不同的金融文本数据集上进行的四项代表性任务的能力。初步研究表明，ChatGPT和GPT-4在需要领域特定知识的金融命名实体识别（NER）和情感分析等任务上表现不佳，而在数值推理任务上表现出色。我们报告了当前版本ChatGPT和GPT-4的优点和局限性，并将它们与现有技术进行了比较。

    The most recent large language models such as ChatGPT and GPT-4 have garnered significant attention, as they are capable of generating high-quality responses to human input. Despite the extensive testing of ChatGPT and GPT-4 on generic text corpora, showcasing their impressive capabilities, a study focusing on financial corpora has not been conducted. In this study, we aim to bridge this gap by examining the potential of ChatGPT and GPT-4 as a solver for typical financial text analytic problems in the zero-shot or few-shot setting. Specifically, we assess their capabilities on four representative tasks over five distinct financial textual datasets. The preliminary study shows that ChatGPT and GPT-4 struggle on tasks such as financial named entity recognition (NER) and sentiment analysis, where domain-specific knowledge is required, while they excel in numerical reasoning tasks. We report both the strengths and limitations of the current versions of ChatGPT and GPT-4, comparing them to 
    
[^43]: V\=arta：一个用于印度语言头条生成的大规模数据集

    V\=arta: A Large-Scale Headline-Generation Dataset for Indic Languages. (arXiv:2305.05858v1 [cs.CL])

    [http://arxiv.org/abs/2305.05858](http://arxiv.org/abs/2305.05858)

    本文介绍了一个用于印度语言头条生成的大规模多语言数据集 V\=arta，包含来自14种不同印度语言（和英语）的4180万条新闻文章，可用于预训练强语言模型，并可用于回答与印度语言处理和多语言研究相关的重要问题。

    

    本文介绍了 V\=arta，这是一个用于印度语言头条生成的大规模多语言数据集。该数据集包含来自14种不同印度语言（和英语）的4180万条新闻文章，这些文章来自各种高质量来源。据我们所知，这是目前可用的印度语言精选文章最大的集合。我们使用收集到的数据进行一系列实验，以回答与印度语言处理和多语言研究相关的重要问题。我们表明即使对于最先进的抽象模型，该数据集也是有挑战性的，它们的表现也仅比抽取基线略优。由于其规模，我们还表明该数据集可用于预训练强语言模型，这些模型在自然语言理解和生成基准测试中均优于竞争基线。

    We present V\=arta, a large-scale multilingual dataset for headline generation in Indic languages. This dataset includes 41.8 million news articles in 14 different Indic languages (and English), which come from a variety of high-quality sources. To the best of our knowledge, this is the largest collection of curated articles for Indic languages currently available. We use the data collected in a series of experiments to answer important questions related to Indic NLP and multilinguality research in general. We show that the dataset is challenging even for state-of-the-art abstractive models and that they perform only slightly better than extractive baselines. Owing to its size, we also show that the dataset can be used to pretrain strong language models that outperform competitive baselines in both NLU and NLG benchmarks.
    
[^44]: 环境约束下的情境依赖性沟通

    Context-dependent communication under environmental constraints. (arXiv:2305.05821v1 [cs.AI])

    [http://arxiv.org/abs/2305.05821](http://arxiv.org/abs/2305.05821)

    本文研究了在压缩词汇量的情况下，如何利用环境压力促进情境依赖性沟通的出现，并研究了在接收者无法处理歧义的情况下，发送者如何利用环境的制约因素实现沟通。

    

    存在大量的证据表明，现实世界中的沟通不能简单地通过发送具有独立于情境意义的信号来实现。本文以经典的Lewis(1969)信号模型的变体为基础，探讨在情境化场景下产生情境依赖性沟通的条件。具体而言，我们证明了在最小化词汇量的压力下，这种沟通的出现是足够的。同时，我们研究了可能使符号含义得到情境区分的环境条件和认知能力。我们展示了在接受者的指代选择受到环境限制的情况下，发送者可以单方面地利用这些限制，而无需接收者具有澄清歧义的能力。与常见的假设一致，发送者对情境的意识似乎是需要的。我们认为，情境依赖性沟通是一种多层次的情境化现象，其受环境特性的影响至关重要。

    There is significant evidence that real-world communication cannot be reduced to sending signals with context-independent meaning. In this work, based on a variant of the classical Lewis (1969) signaling model, we explore the conditions for the emergence of context-dependent communication in a situated scenario. In particular, we demonstrate that pressure to minimise the vocabulary size is sufficient for such emergence. At the same time, we study the environmental conditions and cognitive capabilities that enable contextual disambiguation of symbol meanings. We show that environmental constraints on the receiver's referent choice can be unilaterally exploited by the sender, without disambiguation capabilities on the receiver's end. Consistent with common assumptions, the sender's awareness of the context appears to be required for contextual communication. We suggest that context-dependent communication is a situated multilayered phenomenon, crucially influenced by environment properti
    
[^45]: 排名和重新加权提高了组的分布鲁棒性

    Ranking & Reweighting Improves Group Distributional Robustness. (arXiv:2305.05759v1 [cs.LG])

    [http://arxiv.org/abs/2305.05759](http://arxiv.org/abs/2305.05759)

    本文提出了一种利用折扣累积增益（DCG）排序并加权处理训练数据以提高模型对低代表性组的鲁棒性的方法，实验证明其优于先前方法。

    

    最近的研究表明，通过经验风险最小化（ERM）进行标准训练可能会产生在平均精度上表现出色但在低代表性组上准确性较低的模型，这是由于表征中虚假特征的普遍存在所致。解决这个组鲁棒性问题的主要方法是在训练数据上最小化最坏的组误差（类似于极小值策略），希望它会在测试数据上有良好的泛化性能。然而，这种方法往往是次优的，尤其是当测试数据集中包含以前未见过的组时。本文受信息检索和Learning-to-Rank文献的启发，首先提出使用折扣累积增益（DCG）作为模型质量度量标准，以促进更好的超参数调整和模型选择。作为一种基于排序的度量标准，DCG加权多个性能较差的组（而不仅仅是考虑性能最差的组）。作为自然的下一步，我们基于这些结果提出了一种新的组重新加权方法，在训练期间鼓励模型集中于低代表性的组。在几个基准数据集上的实验证明，我们提出的方法优于先前的最先进方法，并显著提高了对组不平衡的鲁棒性。

    Recent work has shown that standard training via empirical risk minimization (ERM) can produce models that achieve high accuracy on average but low accuracy on underrepresented groups due to the prevalence of spurious features. A predominant approach to tackle this group robustness problem minimizes the worst group error (akin to a minimax strategy) on the training data, hoping it will generalize well on the testing data. However, this is often suboptimal, especially when the out-of-distribution (OOD) test data contains previously unseen groups. Inspired by ideas from the information retrieval and learning-to-rank literature, this paper first proposes to use Discounted Cumulative Gain (DCG) as a metric of model quality for facilitating better hyperparameter tuning and model selection. Being a ranking-based metric, DCG weights multiple poorly-performing groups (instead of considering just the group with the worst performance). As a natural next step, we build on our results to propose a
    
[^46]: 通过世界状态和文本指令提问的时间和问题：IGLU NLP挑战解决方案

    When and What to Ask Through World States and Text Instructions: IGLU NLP Challenge Solution. (arXiv:2305.05754v1 [cs.CL])

    [http://arxiv.org/abs/2305.05754](http://arxiv.org/abs/2305.05754)

    论文解决了在协作建筑任务中如何解决模棱两可的情况，从而提出了何时寻求澄清以及应该询问什么澄清问题这两个关键问题的解答方法。

    

    在协作任务中，有效的交流对于实现共同目标至关重要。其中一个任务是协作建筑，在这个任务中，建筑者必须相互通信，在诸如Minecraft之类的模拟环境中构建所需的结构。我们旨在开发一个智能建筑代理，根据用户对话建造结构。然而，在协作建筑中，建筑者可能会遇到难以解读的情况，因为信息和指令有限，导致模棱两可。在NeurIPS 2022竞赛的NLP任务中，我们回答了两个关键的研究问题，旨在填补这一空白：代理何时应该寻求澄清，应该询问什么澄清问题？我们通过两个子任务朝着这个目标迈进，一个是分类任务，一个是排序任务。对于分类任务，目标是根据当前的世界状态和对话历史确定代理是否应该寻求澄清。对于排序任务，目标是提供一份可能的澄清问题的排名列表。我们的方法结合了基于规则的启发式方法和机器学习模型，并在IGLU NLP挑战数据集上取得了竞争性的性能。

    In collaborative tasks, effective communication is crucial for achieving joint goals. One such task is collaborative building where builders must communicate with each other to construct desired structures in a simulated environment such as Minecraft. We aim to develop an intelligent builder agent to build structures based on user input through dialogue. However, in collaborative building, builders may encounter situations that are difficult to interpret based on the available information and instructions, leading to ambiguity. In the NeurIPS 2022 Competition NLP Task, we address two key research questions, with the goal of filling this gap: when should the agent ask for clarification, and what clarification questions should it ask? We move towards this target with two sub-tasks, a classification task and a ranking task. For the classification task, the goal is to determine whether the agent should ask for clarification based on the current world state and dialogue history. For the ran
    
[^47]: 多层句子嵌入用于人格预测

    Multilevel Sentence Embeddings for Personality Prediction. (arXiv:2305.05748v1 [cs.CL])

    [http://arxiv.org/abs/2305.05748](http://arxiv.org/abs/2305.05748)

    本文提出了一种可将文本表示为多维空间的方法，可映射具有复杂的多层结构的句子，并应用于人格预测。

    

    句子嵌入模型，如Sentence-BERT（SBERT），可将文本表示为多维空间。然而，当数据具有复杂的多层结构时，训练这些模型需要单独训练类别特定的模型，增加了时间和计算成本。我们提出了一种两步法，使我们能够根据句子的层次成员资格和极性来映射句子。首先，我们通过AdaCos loss函数教授上层句子空间，然后通过一种主要基于层内成对余弦相似度的新损失函数进行微调。我们将此方法应用于三个不同的数据集：从英语和日语Twitter数据中获取的两个弱监督的Big Five人格数据集和基准MNLI数据集。我们表明，我们的单一模型方法比多个类别特定分类模型表现更好。

    Representing text into a multidimensional space can be done with sentence embedding models such as Sentence-BERT (SBERT). However, training these models when the data has a complex multilevel structure requires individually trained class-specific models, which increases time and computing costs. We propose a two step approach which enables us to map sentences according to their hierarchical memberships and polarity. At first we teach the upper level sentence space through an AdaCos loss function and then finetune with a novel loss function mainly based on the cosine similarity of intra-level pairs. We apply this method to three different datasets: two weakly supervised Big Five personality dataset obtained from English and Japanese Twitter data and the benchmark MNLI dataset. We show that our single model approach performs better than multiple class-specific classification models.
    
[^48]: CodeIE: 大型代码生成模型优于少样本信息提取器

    CodeIE: Large Code Generation Models are Better Few-Shot Information Extractors. (arXiv:2305.05711v1 [cs.CL])

    [http://arxiv.org/abs/2305.05711](http://arxiv.org/abs/2305.05711)

    CodeIE提出了使用代码生成模型（Code-LLMs）代替自然语言生成模型（NL-LLMs）对命名实体识别和关系抽取这类信息提取任务进行少样本学习，取得优于几个强基准高达4.5%的绝对精度改进。

    

    在大规模语言模型（LLMs）的预训练方面，已经表现出在许多自然语言处理任务上具有惊人的少样本学习能力。通常的做法是将任务重构为文本到文本的格式，以便自然语言的生成式LLMs（如GPT-3）可以被提示解决它。然而，使用NL-LLMs进行信息提取（IE）任务是不易的，因为IE任务的输出通常是结构化的，因此很难转换成纯文本。我们提出使用代码形式而非自然语言来表达结构化的输出，并利用代码生成LLMs（如Codex）来执行IE任务，特别是命名实体识别和关系抽取。与NL-LLMs相比，我们表明通过设计代码风格的提示和将这些IE任务更改为代码生成任务，Code-LLMs可以与这些IE任务很好地对齐。在七个基准测试上的实验结果表明，我们的方法在少样本学习环境下一直优于几个强基准，并取得了高达4.5%的绝对精度改进。

    Large language models (LLMs) pre-trained on massive corpora have demonstrated impressive few-shot learning ability on many NLP tasks. A common practice is to recast the task into a text-to-text format such that generative LLMs of natural language (NL-LLMs) like GPT-3 can be prompted to solve it. However, it is nontrivial to perform information extraction (IE) tasks with NL-LLMs since the output of the IE task is usually structured and therefore is hard to be converted into plain text. In this paper, we propose to recast the structured output in the form of code instead of natural language and utilize generative LLMs of code (Code-LLMs) such as Codex to perform IE tasks, in particular, named entity recognition and relation extraction. In contrast to NL-LLMs, we show that Code-LLMs can be well-aligned with these IE tasks by designing code-style prompts and formulating these IE tasks as code generation tasks. Experiment results on seven benchmarks show that our method consistently outperf
    
[^49]: $2n$比$n^2$更好：将事件指称共指消解拆分成两个易于处理的问题

    $2 * n$ is better than $n^2$: Decomposing Event Coreference Resolution into Two Tractable Problems. (arXiv:2305.05672v1 [cs.CL])

    [http://arxiv.org/abs/2305.05672](http://arxiv.org/abs/2305.05672)

    为了解决事件指称共指消解中的计算问题，我们将其分成两个部分：一种启发式过滤方法和基于均衡数据集的训练方法。该方法在两个数据集上获得了良好的结果。

    

    事件指称共指消解(ECR)是将同一事件在文档中或跨文档中的指称进行链接的任务。大多数指称对不共指，但许多共指指称可以通过简单的技术进行识别，例如事件触发器或它们出现的句子的词形匹配。现有的共指消解系统训练方法从一个高度倾斜的分布中进行采样，这使得算法难以学习超出表面匹配的共指。此外，由于需要平方操作，这些方法是不可行的。为了解决这些挑战，我们将ECR问题分成两个部分：a) 一种启发式方法，有效地过滤出大量不共指的指称对，b) 在一组均衡的共指和非共指指称对上进行训练。通过采用这种方法，我们证明在两个流行的ECR数据集上获得了与最先进技术相当的结果，同时显着减少了计算需求。

    Event Coreference Resolution (ECR) is the task of linking mentions of the same event either within or across documents. Most mention pairs are not coreferent, yet many that are coreferent can be identified through simple techniques such as lemma matching of the event triggers or the sentences in which they appear. Existing methods for training coreference systems sample from a largely skewed distribution, making it difficult for the algorithm to learn coreference beyond surface matching. Additionally, these methods are intractable because of the quadratic operations needed. To address these challenges, we break the problem of ECR into two parts: a) a heuristic to efficiently filter out a large number of non-coreferent pairs, and b) a training approach on a balanced set of coreferent and non-coreferent mention pairs. By following this approach, we show that we get comparable results to the state of the art on two popular ECR datasets while significantly reducing compute requirements. We
    
[^50]: 面向个人或实体的知识图谱表示学习：在医疗保健领域应用的研究

    Representation Learning for Person or Entity-centric Knowledge Graphs: an application in Healthcare. (arXiv:2305.05640v1 [cs.AI])

    [http://arxiv.org/abs/2305.05640](http://arxiv.org/abs/2305.05640)

    本研究提出了一种在医疗保健领域构建面向实体的知识图谱的端到端表示学习方法 HEER，通过将领域特定的约束和特征纳入到图嵌入算法中，有效地改善了下游预测任务。

    

    知识图谱是一种按本体或模式组织信息的流行方式，已经在从搜索到推荐的各种场景中得到了应用。尽管在知识图谱方面有了一些进展，但知识表示仍然是跨行业的一个非常棘手的任务，特别是在生物医学和医疗保健领域，由于实体之间的复杂相互关系、异质性、缺乏标准化和数据稀疏性等因素，这一任务尤其具有挑战性。本文提出了一种面向医疗保健领域构建面向实体的知识图谱的端到端表示学习方法，重点是捕捉生物医学领域的独特特征。所提出的框架名为HEER（Healthcare Entity-Entity Representation learning），将领域特定的约束和特征纳入到图嵌入算法中。对多个基准数据集的结果表明，与最先进的方法相比，HEER在改善下游预测任务方面具有有效性。

    Knowledge graphs (KGs) are a popular way to organise information based on ontologies or schemas and have been used across a variety of scenarios from search to recommendation. Despite advances in KGs, representing knowledge remains a non-trivial task across industries and it is especially challenging in the biomedical and healthcare domains due to complex interdependent relations between entities, heterogeneity, lack of standardization, and sparseness of data. KGs are used to discover diagnoses or prioritize genes relevant to disease, but they often rely on schemas that are not centred around a node or entity of interest, such as a person. Entity-centric KGs are relatively unexplored but hold promise in representing important facets connected to a central node and unlocking downstream tasks beyond graph traversal and reasoning, such as generating graph embeddings and training graph neural networks for a wide range of predictive tasks. This paper presents an end-to-end representation le
    
[^51]: 大型语言模型在医疗对话问答中需要进行整体性思考

    Large Language Models Need Holistically Thought in Medical Conversational QA. (arXiv:2305.05410v1 [cs.CL])

    [http://arxiv.org/abs/2305.05410](http://arxiv.org/abs/2305.05410)

    本研究提出了一种Holistically Thought（HoT）方法，用于引导大型语言模型进行综合性思考，以在医疗对话问答中生成高质量的医学响应。

    

    医疗对话问答系统旨在提供一系列专业的医疗服务，以提高医疗护理效率。尽管大型语言模型在数学、逻辑和常识问答等各个领域的复杂推理任务中取得了成功，但随着医学领域的日益复杂和专业化，它们仍需要提高。这是因为医疗对话问答任务不仅需要强大的医学推理能力，还需要广泛深入的思维能力。本文针对这些需要从许多方面考虑和理解的医疗对话问答任务的挑战，提出了全面思考（HoT）方法，旨在引导大型语言模型进行扩散和聚焦思考，生成高质量的医学响应。所提出的HoT方法已通过自动化和手动评估，在包含英文和中文的三个不同的医疗对话问答数据集中进行了评估。

    The medical conversational question answering (CQA) system aims at providing a series of professional medical services to improve the efficiency of medical care. Despite the success of large language models (LLMs) in complex reasoning tasks in various fields, such as mathematics, logic, and commonsense QA, they still need to improve with the increased complexity and specialization of the medical field. This is because medical CQA tasks require not only strong medical reasoning, but also the ability to think broadly and deeply. In this paper, to address these challenges in medical CQA tasks that need to be considered and understood in many aspects, we propose the Holistically Thought (HoT) method, which is designed to guide the LLMs to perform the diffused and focused thinking for generating high-quality medical responses. The proposed HoT method has been evaluated through automated and manual assessments in three different medical CQA datasets containing the English and Chinese languag
    
[^52]: 从大型语言模型中提取脚本知识以进行受限语言规划

    Distilling Script Knowledge from Large Language Models for Constrained Language Planning. (arXiv:2305.05252v1 [cs.CL])

    [http://arxiv.org/abs/2305.05252](http://arxiv.org/abs/2305.05252)

    本文首次定义了受限语言规划任务，提出了一种方法来提高大型语言模型在这个任务中的表现，并提取了一个新颖的受限语言规划数据集。实验证明该方法显著提高了其在约束忠实度方面的能力，并对赋予较小的语言模型受限语言规划能力非常有效。

    

    在日常生活中，人们经常通过遵循目标导向的脚本形式的逐步说明来规划自己的行动。以往的工作利用语言模型（LM）来为立体活动的抽象目标（例如，“制作蛋糕”）进行规划，但对于具有多方面约束的更具体目标（例如，“为糖尿病患者制作蛋糕”）鲜有研究。本文首次定义了受限语言规划任务。我们提出了一种过度生成并过滤的方法来改善大型语言模型（LLM）在这个任务中的表现，并利用它来提取一种新颖的受限语言规划数据集CoScript，其中包括55,000个脚本。实验证明，我们的方法显著提高了LLM在受限语言规划方面的能力，特别是在约束忠实度方面。此外，CoScript被证明对赋予较小的LM受限语言规划能力是非常有效的。

    In everyday life, humans often plan their actions by following step-by-step instructions in the form of goal-oriented scripts. Previous work has exploited language models (LMs) to plan for abstract goals of stereotypical activities (e.g., "make a cake"), but leaves more specific goals with multi-facet constraints understudied (e.g., "make a cake for diabetics"). In this paper, we define the task of constrained language planning for the first time. We propose an overgenerate-then-filter approach to improve large language models (LLMs) on this task, and use it to distill a novel constrained language planning dataset, CoScript, which consists of 55,000 scripts. Empirical results demonstrate that our method significantly improves the constrained language planning ability of LLMs, especially on constraint faithfulness. Furthermore, CoScript is demonstrated to be quite effective in endowing smaller LMs with constrained language planning ability.
    
[^53]: 文本图像机器翻译多教师知识蒸馏

    Multi-Teacher Knowledge Distillation For Text Image Machine Translation. (arXiv:2305.05226v1 [cs.CL])

    [http://arxiv.org/abs/2305.05226](http://arxiv.org/abs/2305.05226)

    本文提出了一种多教师知识蒸馏方法，可以将知识有效地蒸馏到管道模型中并传递给端到端TIMT模型，从而提高性能。

    

    文本图像机器翻译（TIMT）已被广泛应用于各种实际应用程序中，它将图像中的源语言文本翻译成另一种目标语言句子。TIMT的现有方法主要分为两种类别：识别-然后-翻译流程模型和端到端模型。然而，如何从管道模型向端到端模型传递知识仍然是一个未解决的问题。在本文中，我们提出了一种新的多教师知识蒸馏（MTKD）方法，可以有效地将知识蒸馏到管道模型中并传递给端到端TIMT模型。具体而言，利用三个教师来提高端到端TIMT模型的性能。端到端TIMT模型中的图像编码器使用识别教师编码器的知识蒸馏指导进行优化，而顺序编码器和解码器则通过从翻译顺序和解码器教师模型传递知识来改善性能。

    Text image machine translation (TIMT) has been widely used in various real-world applications, which translates source language texts in images into another target language sentence. Existing methods on TIMT are mainly divided into two categories: the recognition-then-translation pipeline model and the end-to-end model. However, how to transfer knowledge from the pipeline model into the end-to-end model remains an unsolved problem. In this paper, we propose a novel Multi-Teacher Knowledge Distillation (MTKD) method to effectively distillate knowledge into the end-to-end TIMT model from the pipeline model. Specifically, three teachers are utilized to improve the performance of the end-to-end TIMT model. The image encoder in the end-to-end TIMT model is optimized with the knowledge distillation guidance from the recognition teacher encoder, while the sequential encoder and decoder are improved by transferring knowledge from the translation sequential and decoder teacher models. Furthermo
    
[^54]: E2TIMT: 高效有效的文图机器翻译模态适配器

    E2TIMT: Efficient and Effective Modal Adapter for Text Image Machine Translation. (arXiv:2305.05166v1 [cs.CL])

    [http://arxiv.org/abs/2305.05166](http://arxiv.org/abs/2305.05166)

    本文提出了一种高效有效的文图机器翻译模态适配器，利用现有OCR和MT数据库和新型模态适配器将OCR编码器和MT解码器连接，使得端到端TIMT模型在翻译质量和效率方面优于现有的两阶段级联模型和其他最先进的一级端到端模型。

    

    文本图像机器翻译旨在将嵌入图像中的文本从一种源语言翻译成另一种目标语言。现有方法，无论是两阶段级联还是一级端到端架构，都存在不同的问题。级联模型可以受益于大规模的光学字符识别（OCR）和 MT 数据集，但两阶段架构则是冗余的。端到端模型是高效的，但遭受训练数据不足的困扰。因此，在本文中，我们提出了一种端到端TIMT模型，充分利用现有OCR和MT数据集中的知识，追求有效和高效的框架。更具体地说，我们建立了一个新型模态适配器，有效地连接OCR编码器和MT解码器。同时使用端到端TIMT损失和跨模态对比损失来对齐OCR和MT任务的特征分布。大量实验表明，所提出的方法在翻译质量和效率方面优于现有的两阶段级联模型和其他最先进的一级端到端模型。

    Text image machine translation (TIMT) aims to translate texts embedded in images from one source language to another target language. Existing methods, both two-stage cascade and one-stage end-to-end architectures, suffer from different issues. The cascade models can benefit from the large-scale optical character recognition (OCR) and MT datasets but the two-stage architecture is redundant. The end-to-end models are efficient but suffer from training data deficiency. To this end, in our paper, we propose an end-to-end TIMT model fully making use of the knowledge from existing OCR and MT datasets to pursue both an effective and efficient framework. More specifically, we build a novel modal adapter effectively bridging the OCR encoder and MT decoder. End-to-end TIMT loss and cross-modal contrastive loss are utilized jointly to align the feature distribution of the OCR and MT tasks. Extensive experiments show that the proposed method outperforms the existing two-stage cascade models and o
    
[^55]: 基于大语言模型知识蒸馏的网络内容过滤方法

    Web Content Filtering through knowledge distillation of Large Language Models. (arXiv:2305.05027v1 [cs.LG])

    [http://arxiv.org/abs/2305.05027](http://arxiv.org/abs/2305.05027)

    本文提出了一种基于大语言模型知识蒸馏的 URL 分类方法，可用于网络内容过滤，其学生模型在参数数量减少 175 倍的情况下，精度提升了 9%，超过了当前最先进方法。

    

    本文提出了一种基于大语言模型的 URL 分类方法，旨在实现网络内容过滤的主要目标：保障组织免受法律和伦理风险，限制访问高风险或可疑网站，以及促进安全的专业工作环境。我们的方法利用大语言模型生成准确的分类，并利用已有的知识蒸馏技术创建更小、更专业的学生模型，以用于网络内容过滤。在将通过大型安全供应商收集的客户遥测数据的 30 个不同内容类别的网站进行分类的任务中，我们的学生模型通过蒸馏结果实现了 9% 的分类精度提升，超过了当前最先进方法。我们的学生模型在参数数量上与原始的大语言模型相比减少了 175 倍，从而达到了与老师模型相匹配的性能，可以用于大规模的在线扫描。

    We introduce a state-of-the-art approach for URL categorization that leverages the power of Large Language Models (LLMs) to address the primary objectives of web content filtering: safeguarding organizations from legal and ethical risks, limiting access to high-risk or suspicious websites, and fostering a secure and professional work environment. Our method utilizes LLMs to generate accurate classifications and then employs established knowledge distillation techniques to create smaller, more specialized student models tailored for web content filtering. Distillation results in a student model with a 9\% accuracy rate improvement in classifying websites, sourced from customer telemetry data collected by a large security vendor, into 30 distinct content categories based on their URLs, surpassing the current state-of-the-art approach. Our student model matches the performance of the teacher LLM with 175 times less parameters, allowing the model to be used for in-line scanning of large vo
    
[^56]: CAT: 一种情景化常识推理的概念化和实例化框架

    CAT: A Contextualized Conceptualization and Instantiation Framework for Commonsense Reasoning. (arXiv:2305.04808v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.04808](http://arxiv.org/abs/2305.04808)

    CAT提出了一种情景化常识推理的概念化和实例化框架，通过该框架，可以在大规模场景下概念化常识知识库，并在两个基准测试数据集上达到最先进的性能。

    

    常识推理旨在为机器赋予类似于人的情景推断能力，这极其具有挑战性。 对于一个几乎不了解“冥想”但熟悉“唱歌”的人，他仍然可以从现有的知识中通过将“唱歌”概念化为“一种放松的事件”，然后将该事件实例化为“冥想”，推断出“冥想使人放松”。 这个过程称为概念归纳和演绎，在缺乏标记数据和提高常识建模方法的情况下变得更加根本。为填补这样的研究空白，我们提出了CAT（情景化概念化和实例化），这是一个将事件概念化和实例化融合起来，以大规模概念化常识知识库的半监督学习框架。广泛的实验证明，我们的框架在两个概念推理基准数据集上实现了最先进的性能，证明了我们提出的方法的有效性。

    Commonsense reasoning, aiming at endowing machines with a human-like ability to make situational presumptions, is extremely challenging to generalize. For someone who barely knows about "meditation," while is knowledgeable about "singing," he can still infer that "meditation makes people relaxed" from the existing knowledge that "singing makes people relaxed" by first conceptualizing "singing" as a "relaxing event" and then instantiating that event to "meditation." This process, known as conceptual induction and deduction, is fundamental to commonsense reasoning while lacking both labeled data and methodologies to enhance commonsense modeling. To fill such a research gap, we propose CAT (Contextualized ConceptuAlization and InsTantiation), a semi-supervised learning framework that integrates event conceptualization and instantiation to conceptualize commonsense knowledge bases at scale. Extensive experiments show that our framework achieves state-of-the-art performances on two conceptu
    
[^57]: X-LLM: 通过将多模态视为外语引入大型语言模型来启动高级大型语言模型

    X-LLM: Bootstrapping Advanced Large Language Models by Treating Multi-Modalities as Foreign Languages. (arXiv:2305.04160v1 [cs.CL])

    [http://arxiv.org/abs/2305.04160](http://arxiv.org/abs/2305.04160)

    本论文提出了一种名为X-LLM的方法，将多模态信息转换为外语并输入到大型语言模型中，从而赋予LLM多模态能力，对于LLM加入多模态信息的能力进行了探究和拓展。

    

    大型语言模型（LLM）展示了卓越的语言能力。基于高级LLM的GPT-4表现出超常的多模态能力，超越了以往的视觉语言模型。我们将这归功于与以前的多模态模型相比使用了更先进的LLM。但不幸的是，GPT-4的模型架构和训练策略是未知的。为了赋予LLM多模态能力，我们提出了X-LLM，通过使用X2L接口将多模态（图像、语音、视频）转换为外语并将其输入到大型语言模型（ChatGLM）中。具体而言，X-LLM使用X2L接口将多个冻结的单模态编码器和冻结的LLM对齐，其中“X”表示多模态，例如图像、语音和视频，“L”表示语言。X-LLM的训练由三个阶段组成：（1）转换多模态信息：第一阶段分别训练每个X2L接口与其各自的单模态编码器对齐，将多模态信息转换为外语输入到ChatGLM中。...

    Large language models (LLMs) have demonstrated remarkable language abilities. GPT-4, based on advanced LLMs, exhibits extraordinary multimodal capabilities beyond previous visual language models. We attribute this to the use of more advanced LLMs compared with previous multimodal models. Unfortunately, the model architecture and training strategies of GPT-4 are unknown. To endow LLMs with multimodal capabilities, we propose X-LLM, which converts Multi-modalities (images, speech, videos) into foreign languages using X2L interfaces and inputs them into a large Language model (ChatGLM). Specifically, X-LLM aligns multiple frozen single-modal encoders and a frozen LLM using X2L interfaces, where ``X'' denotes multi-modalities such as image, speech, and videos, and ``L'' denotes languages. X-LLM's training consists of three stages: (1) Converting Multimodal Information: The first stage trains each X2L interface to align with its respective single-modal encoder separately to convert multimod
    
[^58]: 利用分类器来筛选语料库：以在线清洁能源情感分析为例

    Curating corpora with classifiers: A case study of clean energy sentiment online. (arXiv:2305.03092v1 [cs.CL])

    [http://arxiv.org/abs/2305.03092](http://arxiv.org/abs/2305.03092)

    本文介绍了利用分类器来快速选择最佳的相关文档语料库进行分析的方法，探索了过滤掉不相关的推文的方法，以进行在线清洁能源情感分析。

    

    精心策划的、大规模的社交媒体帖子语料库是补充传统调查的替代数据来源，可以提供广泛的公众意见。虽然调查在收集代表性样本和实现高准确率方面很有效，但运行成本很高，而且会滞后于公众意见数天或数周。这两个缺点可以通过实时、高容量的数据流和快速的分析管道克服。在组织这样的数据管道方面的一个核心挑战是设计一种有效的方法，快速选择最佳的相关文档语料库进行分析。仅仅通过关键词查询往往会包括不相关的文档，而这些文档很难用词袋自然语言处理方法消歧。在这里，我们使用预先训练的基于转换器的模型，通过在手动标注的推文上对其进行微调，探索了语料库策划的方法，以过滤掉不相关的推文。我们能够实现高达0.8以上的F1得分。

    Well curated, large-scale corpora of social media posts containing broad public opinion offer an alternative data source to complement traditional surveys. While surveys are effective at collecting representative samples and are capable of achieving high accuracy, they can be both expensive to run and lag public opinion by days or weeks. Both of these drawbacks could be overcome with a real-time, high volume data stream and fast analysis pipeline. A central challenge in orchestrating such a data pipeline is devising an effective method for rapidly selecting the best corpus of relevant documents for analysis. Querying with keywords alone often includes irrelevant documents that are not easily disambiguated with bag-of-words natural language processing methods. Here, we explore methods of corpus curation to filter irrelevant tweets using pre-trained transformer-based models, fine-tuned for our binary classification task on hand-labeled tweets. We are able to achieve F1 scores of up to 0.
    
[^59]: 基于因果感知的知识引导句子提取

    Causality-aware Concept Extraction based on Knowledge-guided Prompting. (arXiv:2305.01876v1 [cs.CL])

    [http://arxiv.org/abs/2305.01876](http://arxiv.org/abs/2305.01876)

    该论文提出了一种基于因果感知的知识引导提示方法，将其作为干预器装备到基于预训练语言模型的句子提取器中，以缓解概念偏差。在代表性的多语言KG数据集上进行广泛实验，获得了最先进的结果。

    

    概念有助于自然语言理解，但现有的知识图谱（KG）中远未完善。最近，预训练语言模型（PLM）已被广泛用于基于文本的概念提取（CE）。然而，PLM往往从大量语料库的共现关联中进行预训练知识挖掘，而非Token之间的真实因果关系。因此，预训练知识混淆了PLM，导致提取基于虚假共现相关性的有偏概念，不可避免地导致低精度。本文通过结构因果模型（SCM）提出了一种知识引导提示方法，将其作为干预器装备到基于PLM的提取器中，以减轻概念偏差。提示采用现有KG中的给定实体主题来缓解实体和有偏概念之间的虚假共现相关性。我们在代表性的多语言KG数据集上进行了广泛的实验，证明了我们提出的提示显著改进了提取性能，并达到了最先进的结果。

    Concepts benefit natural language understanding but are far from complete in existing knowledge graphs (KGs). Recently, pre-trained language models (PLMs) have been widely used in text-based concept extraction (CE). However, PLMs tend to mine the co-occurrence associations from massive corpus as pre-trained knowledge rather than the real causal effect between tokens.As a result, the pre-trained knowledge confounds PLMs to extract biased concepts based on spurious co-occurrence correlations, inevitably resulting in low precision. In this paper, through the lens of a Structural Causal Model (SCM), we propose equipping the PLM-based extractor with a knowledge-guided prompt as an intervention to alleviate concept bias. The prompt adopts the topic of the given entity from the existing knowledge in KGs to mitigate the spurious co-occurrence correlations between entities and biased concepts. Our extensive experiments on representative multilingual KG datasets justify that our proposed prompt 
    
[^60]: 将流程图转化为对话：基于计划的数据增强方法，用于低资源流程图相关故障排除对话

    Turning Flowchart into Dialog: Plan-based Data Augmentation for Low-Resource Flowchart-grounded Troubleshooting Dialogs. (arXiv:2305.01323v1 [cs.CL])

    [http://arxiv.org/abs/2305.01323](http://arxiv.org/abs/2305.01323)

    本文提出了一个基于计划的数据增强方法，能够将简洁的流程图转化成对话，以生成足够的数据来训练以流程图为基础的故障排除对话系统，实验结果表明该方法有效地提高了系统性能。

    

    近年来，以流程图为基础的故障排除对话系统（FTD系统）一直备受研究关注。然而，收集充分的自然基于流程图的对话数据成本较高，因此FTD系统受到数据稀缺的限制。为了缓解数据稀疏性问题，我们提出了基于计划的数据增强（PlanDA）方法，通过将简洁的流程图转化为对话，生成大量多样的合成对话数据。具体来说，它的生成模型采用具有全局和局部潜在规划变量的分层规划策略的变分基框架。在FloDial数据集上的实验表明，PlanDA生成的合成对话改善了下游任务的性能，包括流程图路径检索和响应生成，特别是在流程图以外的情况下。

    Flowchart-grounded troubleshooting dialogue (FTD) systems, which follow the instructions of a flowchart to diagnose users' problems in specific domains (eg., vehicle, laptop), have been gaining research interest in recent years. However, collecting sufficient dialogues that are naturally grounded on flowcharts is costly, thus FTD systems are impeded by scarce training data. To mitigate the data sparsity issue, we propose a plan-based data augmentation (PlanDA) approach that generates diverse synthetic dialog data at scale by transforming concise flowchart into dialogues. Specifically, its generative model employs a variational-base framework with a hierarchical planning strategy that includes global and local latent planning variables. Experiments on the FloDial dataset show that synthetic dialogue produced by PlanDA improves the performance of downstream tasks, including flowchart path retrieval and response generation, in particular on the Out-of-Flowchart settings. In addition, furt
    
[^61]: 数据语言的名义拓扑

    Nominal Topology for Data Languages. (arXiv:2304.13337v1 [cs.CL])

    [http://arxiv.org/abs/2304.13337](http://arxiv.org/abs/2304.13337)

    该论文提出了一种新的拓扑视角，用于描述可以被轨道有限的名义单子群识别的数据语言，并探讨了 pro-轨道有限方程的表现能力。

    

    我们提出了一种新的拓扑视角，用于描述可以被轨道有限的名义单子群识别的数据语言。为此，我们引入了 pro- 轨道有限的名义拓扑空间。在全局有界支持大小的前提下，它们与名义 Stone 空间重合，并且被证明与名义布尔代数的一个子范畴双重等价。可识别的数据语言被表征为 pro-轨道有限单词的拓扑闭开集。此外，我们通过建立 Reiterman 的伪变种定理的名义版本，探讨了 pro-轨道有限方程的表现能力。

    We propose a novel topological perspective on data languages recognizable by orbit-finite nominal monoids. For this purpose, we introduce pro-orbit-finite nominal topological spaces. Assuming globally bounded support sizes, they coincide with nominal Stone spaces and are shown to be dually equivalent to a subcategory of nominal boolean algebras. Recognizable data languages are characterized as topologically clopen sets of pro-orbit-finite words. In addition, we explore the expressive power of pro-orbit-finite equations by establishing a nominal version of Reiterman's pseudovariety theorem.
    
[^62]: 通过自我改进的方式实现更好的代码语言模型

    Better Language Models of Code through Self-Improvement. (arXiv:2304.01228v1 [cs.CL])

    [http://arxiv.org/abs/2304.01228](http://arxiv.org/abs/2304.01228)

    本文提出了一个简单的数据增强框架来改善预训练语言模型为代码生成和代码摘要等任务微调的瓶颈问题，提高了模型性能。

    

    近期，各种预训练的代码语言模型引起了人们的广泛关注。这些模型通过多模式目标在大规模数据集上进行预训练。但是，对其进行微调需要大量监督，并且受到提供的数据集规模的限制。我们提出了一个简单的数据增强框架以改善这个问题。这个框架利用了在预训练和微调阶段获得的知识来生成伪数据，并将其用作下一步的训练数据。我们将这个框架应用到最先进的语言模型中，如CodeT5、CodeBERT和UnixCoder。结果表明，我们的框架显著提高了PLMC在与代码相关的序列生成任务中的性能，如CodeXGLUE基准测试中的代码摘要和代码生成。

    Pre-trained language models for code (PLMCs) have gained attention in recent research. These models are pre-trained on large-scale datasets using multi-modal objectives. However, fine-tuning them requires extensive supervision and is limited by the size of the dataset provided. We aim to improve this issue by proposing a simple data augmentation framework. Our framework utilizes knowledge gained during the pre-training and fine-tuning stage to generate pseudo data, which is then used as training data for the next step. We incorporate this framework into the state-of-the-art language models, such as CodeT5, CodeBERT, and UnixCoder. The results show that our framework significantly improves PLMCs' performance in code-related sequence generation tasks, such as code summarization and code generation in the CodeXGLUE benchmark.
    
[^63]: 重新发现CNN在原始电子健康记录文本编码中的多功能性

    Rediscovery of CNN's Versatility for Text-based Encoding of Raw Electronic Health Records. (arXiv:2303.08290v1 [cs.LG])

    [http://arxiv.org/abs/2303.08290](http://arxiv.org/abs/2303.08290)

    本文发现，CNN在健康记录文本编码方面的多功能性和隐含层次结构可以提高其性能，提出了一种基于CNN的编码器来处理不同类型的EHR特征，并在临床任务中展示了其有效性。

    

    充分利用电子健康记录（EHR）中丰富的信息正逐渐成为医学领域的重要话题。最近的工作提出了一个有前途的框架，该框架可以在不考虑其格式和医学编码标准的情况下嵌入原始EHR数据的整个特征。然而，该框架仅侧重于对EHR进行最小的预处理，未考虑如何学习高效的EHR表示，包括计算和内存使用等方面。在本文中，我们寻找一种多功能的编码器，不仅将大量数据缩小到可管理的大小，还能很好地保留患者的核心信息，以执行各种临床任务。我们发现，具有分层结构的卷积神经网络（CNN）在各种任务（如重建，预测和生成）中经常优于最先进的模型，即使参数较少且训练时间较短。此外，利用EHR数据的固有层次结构可以提高CNN的性能。在这些发现的基础上，我们提出了一种基于CNN的编码器，可以处理不同类型的EHR特征，并证明了所提出的模型在几种临床任务中的有效性。

    Making the most use of abundant information in electronic health records (EHR) is rapidly becoming an important topic in the medical domain. Recent work presented a promising framework that embeds entire features in raw EHR data regardless of its form and medical code standards. The framework, however, only focuses on encoding EHR with minimal preprocessing and fails to consider how to learn efficient EHR representation in terms of computation and memory usage. In this paper, we search for a versatile encoder not only reducing the large data into a manageable size but also well preserving the core information of patients to perform diverse clinical tasks. We found that hierarchically structured Convolutional Neural Network (CNN) often outperforms the state-of-the-art model on diverse tasks such as reconstruction, prediction, and generation, even with fewer parameters and less training time. Moreover, it turns out that making use of the inherent hierarchy of EHR data can boost the perfo
    
[^64]: 区分度校准到上下文学习中的应用

    Distinguishability Calibration to In-Context Learning. (arXiv:2302.06198v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.06198](http://arxiv.org/abs/2302.06198)

    本文提出了一种旋转和缩放的特征变换校准方法，可用于基于提示的学习进行文本分类，从而解决了在转换器中进行上下文学习时遇到的信息扩散问题。

    

    近年来，随着对基于提示的学习方法的兴趣增加，模型能够在少量标注实例上进行训练，使它们适用于低资源环境。使用基于提示的学习进行文本分类时，目标是使用预训练语言模型 (PLM) 来预测预定义模板中的缺失标记，并将其映射到类别标签。然而，基于转换器架构构建的 PLM 倾向于生成相似的输出嵌入，很难区分不同的类别标签。当处理涉及许多细粒度类别标签的分类任务时，这个问题会进一步加剧。本文通过提出基于特征旋转和缩放的校准方法来缓解这个信息扩散问题，即当不同的令牌经过转换器中堆叠的多个自注意层时，它们共享大量相似的信息。

    Recent years have witnessed increasing interests in prompt-based learning in which models can be trained on only a few annotated instances, making them suitable in low-resource settings. When using prompt-based learning for text classification, the goal is to use a pre-trained language model (PLM) to predict a missing token in a pre-defined template given an input text, which can be mapped to a class label. However, PLMs built on the transformer architecture tend to generate similar output embeddings, making it difficult to discriminate between different class labels. The problem is further exacerbated when dealing with classification tasks involving many fine-grained class labels. In this work, we alleviate this information diffusion issue, i.e., different tokens share a large proportion of similar information after going through stacked multiple self-attention layers in a transformer, by proposing a calibration method built on feature transformations through rotation and scaling to m
    
[^65]: 你所在社区发生了什么？一种弱监督方法用于发现本地新闻。

    What's happening in your neighborhood? A Weakly Supervised Approach to Detect Local News. (arXiv:2301.08146v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2301.08146](http://arxiv.org/abs/2301.08146)

    该论文介绍了一种自动化的本地新闻检测和基于内容的本地新闻推荐方法，通过弱监督框架和自动化数据处理，与传统方法相比具有更高的准确性和覆盖率。

    

    本地新闻是影响特定地理区域（如城市、县和州）用户的新闻子集。检测本地新闻是准确地推荐本地新闻的关键步骤。基于最新的自然语言处理技术，我们开发了一种集成化的流程，实现了自动化本地新闻检测和基于内容的本地新闻推荐。本文着重介绍了管道的第一步骤：（1）结合领域知识和自动数据处理的弱监督框架，（2）可扩展到多语言设置。与斯坦福CoreNLP NER模型相比，我们的流程在经过真实世界和人工标记数据的评估时具有更高的精度和召回率。

    Local news articles are a subset of news that impact users in a geographical area, such as a city, county, or state. Detecting local news (Step 1) and subsequently deciding its geographical location as well as radius of impact (Step 2) are two important steps towards accurate local news recommendation. Naive rule-based methods, such as detecting city names from the news title, tend to give erroneous results due to lack of understanding of the news content. Empowered by the latest development in natural language processing, we develop an integrated pipeline that enables automatic local news detection and content-based local news recommendations. In this paper, we focus on Step 1 of the pipeline, which highlights: (1) a weakly supervised framework incorporated with domain knowledge and auto data processing, and (2) scalability to multi-lingual settings. Compared with Stanford CoreNLP NER model, our pipeline has higher precision and recall evaluated on a real-world and human-labeled datas
    
[^66]: SMAuC -- 科学多作者语料库

    SMAuC -- The Scientific Multi-Authorship Corpus. (arXiv:2211.02477v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.02477](http://arxiv.org/abs/2211.02477)

    SMAuC是一个包含300万篇科学文本，且元数据丰富的语料库，涵盖各个学科的500万作者，并旨在推进科学文本中的作者身份分析领域。

    

    快速增长的科学文献数量为研究分析单个或多个作者的文档方法提供了有趣的挑战。然而，大多数现有数据集缺乏科学文档或构建新实验和测试用例所必需的元数据。本文介绍了SMAuC，这是一个专为科学作者分析量身定制的全面的元数据丰富的语料库。SMAuC是最大的公开可访问的语料库，包括来自各个学科的超过500万作者的300多万篇科学文本，其中还包括明确的作者ID等广泛策划的元数据。SMAuC旨在显著推进科学文本中的作者身份分析领域。

    The rapidly growing volume of scientific publications offers an interesting challenge for research on methods for analyzing the authorship of documents with one or more authors. However, most existing datasets lack scientific documents or the necessary metadata for constructing new experiments and test cases. We introduce SMAuC, a comprehensive, metadata-rich corpus tailored to scientific authorship analysis. Comprising over 3 million publications across various disciplines from over 5 million authors, SMAuC is the largest openly accessible corpus for this purpose. It encompasses scientific texts from humanities and natural sciences, accompanied by extensive, curated metadata, including unambiguous author IDs. SMAuC aims to significantly advance the domain of authorship analysis in scientific texts.
    
[^67]: QuaLA-MiniLM: 一种量化长度自适应的 MiniLM

    QuaLA-MiniLM: a Quantized Length Adaptive MiniLM. (arXiv:2210.17114v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.17114](http://arxiv.org/abs/2210.17114)

    QuaLA-MiniLM 是一种量化长度自适应的 MiniLM 模型，通过应用低比特化技术和 LAT 方法，实现了在各种 NLP 任务上的最新成果，同时保持较小的模型尺寸和高效率。

    

    有限的计算资源经常阻止 Transformer 模型被应用于生产环境，并发挥其高精度优势。知识蒸馏方法通过将 BERT 自我蒸馏为较小的 Transformer 表示来提高计算效率，其层数更少，内部嵌入更小。然而，当我们减少层数时，这些模型的性能下降，尤其是在一些先进的 NLP 任务如跨度问答中。此外，对于每个不同的推理场景，都必须训练一个单独的模型以满足其不同的计算预算。Dynamic-TinyBERT 通过部分实现 Length Adaptive Transformer（LAT）技术到 TinyBERT 上解决了这两个限制，实现了与 BERT-base 相比 x3 的加速，同时最小化了精度损失。在本文中，我们扩展 Dynamic-TinyBERT 方法，生成了一个更加高效的模型。我们将 MiniLM 蒸馏和 LAT 方法联合使用，并通过应用低比特化技术进一步提高效率。我们提出的模型 QuaLA-MiniLM 在各种 NLP 任务上实现了最先进的结果，同时保持了小模型尺寸和高效率。

    Limited computational budgets often prevent transformers from being used in production and from having their high accuracy utilized. A knowledge distillation approach addresses the computational efficiency by self-distilling BERT into a smaller transformer representation having fewer layers and smaller internal embedding. However, the performance of these models drops as we reduce the number of layers, notably in advanced NLP tasks such as span question answering. In addition, a separate model must be trained for each inference scenario with its distinct computational budget. Dynamic-TinyBERT tackles both limitations by partially implementing the Length Adaptive Transformer (LAT) technique onto TinyBERT, achieving x3 speedup over BERT-base with minimal accuracy loss. In this work, we expand the Dynamic-TinyBERT approach to generate a much more highly efficient model. We use MiniLM distillation jointly with the LAT method, and we further enhance the efficiency by applying low-bit quanti
    
[^68]: 大规模提取文化常识知识

    Extracting Cultural Commonsense Knowledge at Scale. (arXiv:2210.07763v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.07763](http://arxiv.org/abs/2210.07763)

    本篇论文提出了一种名为CANDLE的方法，用于从网络语料库中提取文化常识知识，其优于之前的工作。这些知识对于情境化人工智能和GPT-3语言模型都有好处。

    

    结构化知识对于许多人工智能应用非常重要。常识知识对于强大的以人为中心的人工智能至关重要，但是当前列出的少数结构化常识项目缺乏有关社会文化背景下人类特征和行为的知识，这对于情境化人工智能至关重要。本文提出了CANDLE，一种用于大规模提取高质量文化常识知识（CCSK）的端到端方法。CANDLE从庞大的网络语料库中提取CCSK断言，并将其组织成一致的聚类，针对三个主题领域（地理，宗教，职业）和几个文化方面进行分类（食物，饮料，服装，传统，仪式，行为）。CANDLE包括分类过滤和趣味性评分的审慎技术。实验评估显示，CANDLE CCSK集合优于之前的工作，并且外部用例展示了CCSK对于GPT-3语言模型的好处。CANDLE的代码和数据是公开可用的。

    Structured knowledge is important for many AI applications. Commonsense knowledge, which is crucial for robust human-centric AI, is covered by a small number of structured knowledge projects. However, they lack knowledge about human traits and behaviors conditioned on socio-cultural contexts, which is crucial for situative AI. This paper presents CANDLE, an end-to-end methodology for extracting high-quality cultural commonsense knowledge (CCSK) at scale. CANDLE extracts CCSK assertions from a huge web corpus and organizes them into coherent clusters, for 3 domains of subjects (geography, religion, occupation) and several cultural facets (food, drinks, clothing, traditions, rituals, behaviors). CANDLE includes judicious techniques for classification-based filtering and scoring of interestingness. Experimental evaluations show the superiority of the CANDLE CCSK collection over prior works, and an extrinsic use case demonstrates the benefits of CCSK for the GPT-3 language model. Code and 
    
[^69]: C2KD: 跨语言跨模态知识蒸馏以提升多语言文本-视频检索

    C2KD: Cross-Lingual Cross-Modal Knowledge Distillation for Multilingual Text-Video Retrieval. (arXiv:2210.03625v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.03625](http://arxiv.org/abs/2210.03625)

    本文提出了一种跨语言跨模态知识蒸馏方法，使用不同语言的输入文本训练一个学生模型，与使用英语输入文本的教师模型的跨模态预测相匹配，以提升多语言文本-视频检索。我们引入了一个新的多语言视频数据集，Multi-YouCook2，以及在多个数据集上验证了我们方法的性能提升。

    

    近年来，多语言文本-视频检索方法有了显著提升，但其它语言的表现仍然落后于英语。本文提出了一种跨语言跨模态知识蒸馏方法，以提升多语言文本-视频检索。受到英语文本-视频检索胜过其它语言的事实启发，我们使用不同语言的输入文本训练一个学生模型，使其与使用英语输入文本的教师模型的跨模态预测相匹配。我们提出了一个基于交叉熵的目标函数，强制学生的文本-视频相似度分数分布与教师模型的相似度分数分布相似。我们引入了一个新的多语言视频数据集Multi-YouCook2，通过将YouCook2视频数据集中的英语字幕翻译为8种其他语言来创建。我们的方法提高了Multi-YouCook2以及多个其他数据集，比如Multi-MSRVTT和VATEX的多语言文本-视频检索性能。我们还对方法效果进行了分析。

    Multilingual text-video retrieval methods have improved significantly in recent years, but the performance for other languages lags behind English. We propose a Cross-Lingual Cross-Modal Knowledge Distillation method to improve multilingual text-video retrieval. Inspired by the fact that English text-video retrieval outperforms other languages, we train a student model using input text in different languages to match the cross-modal predictions from teacher models using input text in English. We propose a cross entropy based objective which forces the distribution over the student's text-video similarity scores to be similar to those of the teacher models. We introduce a new multilingual video dataset, Multi-YouCook2, by translating the English captions in the YouCook2 video dataset to 8 other languages. Our method improves multilingual text-video retrieval performance on Multi-YouCook2 and several other datasets such as Multi-MSRVTT and VATEX. We also conducted an analysis on the effe
    
[^70]: 建模段落级别的视觉-语言语义对齐用于多模态摘要生成

    Modeling Paragraph-Level Vision-Language Semantic Alignment for Multi-Modal Summarization. (arXiv:2208.11303v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2208.11303](http://arxiv.org/abs/2208.11303)

    本文提出了ViL-Sum，用于建模段落级别的视觉-语言语义对齐和多模态摘要生成。实验结果表明，ViL-Sum在两个基准数据集上优于现有方法，表明该方法的有效性和优越性。

    

    目前大多数多模态摘要方法采用级联方式：首先使用一个现成的目标检测器提取视觉特征, 然后将这些特征与语言表示相融合，使用编码器-解码器模型生成摘要。级联的方式无法捕捉图像和段落之间的语义对齐，这对于准确的摘要至关重要。本文提出了ViL-Sum，用于联合建模段落级别的视觉-语言语义对齐和多模态摘要生成。ViL-Sum的核心是一个联合多模态编码器，具有两个精心设计的任务：图像重排序和图像选择。联合多模态编码器捕捉了模态之间的交互作用，其中重排序任务引导模型学习段落级别的语义对齐，而选择任务引导模型在最终生成的摘要中选择与摘要相关的图像。实验结果表明，我们提出的ViL-Sum在两个基准数据集上显著优于现有的最先进方法，说明了我们的多模态摘要生成方法的有效性和优越性。

    Most current multi-modal summarization methods follow a cascaded manner, where an off-the-shelf object detector is first used to extract visual features, then these features are fused with language representations to generate the summary with an encoder-decoder model. The cascaded way cannot capture the semantic alignments between images and paragraphs, which are crucial to a precise summary. In this paper, we propose ViL-Sum to jointly model paragraph-level \textbf{Vi}sion-\textbf{L}anguage Semantic Alignment and Multi-Modal \textbf{Sum}marization. The core of ViL-Sum is a joint multi-modal encoder with two well-designed tasks, image reordering and image selection. The joint multi-modal encoder captures the interactions between modalities, where the reordering task guides the model to learn paragraph-level semantic alignment and the selection task guides the model to selected summary-related images in the final summary. Experimental results show that our proposed ViL-Sum significantly
    
[^71]: QAMPARI: 一个多段落多答案的开放域问答挑战

    QAMPARI: An Open-domain Question Answering Benchmark for Questions with Many Answers from Multiple Paragraphs. (arXiv:2205.12665v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.12665](http://arxiv.org/abs/2205.12665)

    本论文提出了一个针对多段落多答案问题的开放域问答基准测试QAMPARI，并训练了ODQA模型。研究结果表明QAMPARI在段落检索和答案生成方面具有挑战性，强调了需要发展能够处理此类问题的ODQA模型。

    

    现有的开放域问答（ODQA）基准测试通常专注于可以从单个段落中提取答案的问题。相比之下，许多自然问题，例如“布鲁克林篮网队选了哪些球员？”，都有一系列答案。回答此类问题需要在大型语料库中检索和阅读来自许多段落的内容。我们介绍了QAMPARI，一种ODQA基准测试，其中问题答案是分布在许多段落中的实体列表。我们通过（a）从维基百科的知识图谱和表中生成具有多个答案的问题，（b）自动将答案与维基百科段落中的支持证据配对，以及（c）手动改写问题并验证每个答案来创建QAMPARI。我们训练了来自检索和阅读族的ODQA模型，发现QAMPARI在段落检索和答案生成方面具有挑战性，最高达到32.8的F1分数。我们的研究结果强调了需要开发能够处理多段落多答案问题的ODQA模型。

    Existing benchmarks for open-domain question answering (ODQA) typically focus on questions whose answers can be extracted from a single paragraph. By contrast, many natural questions, such as "What players were drafted by the Brooklyn Nets?" have a list of answers. Answering such questions requires retrieving and reading from many passages, in a large corpus. We introduce QAMPARI, an ODQA benchmark, where question answers are lists of entities, spread across many paragraphs. We created QAMPARI by (a) generating questions with multiple answers from Wikipedia's knowledge graph and tables, (b) automatically pairing answers with supporting evidence in Wikipedia paragraphs, and (c) manually paraphrasing questions and validating each answer. We train ODQA models from the retrieve-and-read family and find that QAMPARI is challenging in terms of both passage retrieval and answer generation, reaching an F1 score of 32.8 at best. Our results highlight the need for developing ODQA models that han
    
[^72]: 表示投影不变性缓解表示崩溃问题

    Representation Projection Invariance Mitigates Representation Collapse. (arXiv:2205.11603v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.11603](http://arxiv.org/abs/2205.11603)

    本文提出了一种新的正则化方法 REPINA，旨在减少表示崩溃问题，结果在 13 个语言理解任务上表现出良好的效果。

    

    对预训练语言模型学习的上下文化表示进行微调在自然语言处理领域中仍然是一种流行的做法。然而，微调可能会导致表示降级（也被称为表示崩溃），这可能会导致不稳定性、次优性能和弱泛化。在本文中，我们提出了“表示投影不变性”（REPINA），这是一种新颖的正则化方法，通过抑制表示中的不良变化来维护表示的信息内容并减少表示崩溃问题。我们研究了所提出的正则化与5个可比较基线在13个语言理解任务（GLUE基准测试和其他六个数据集）中的实证行为。在评估内域性能时，REPINA 在大多数任务（13项中的10项）上始终优于其他基线。我们还证明了它在少样本设置中的有效性和对标签扰动的鲁棒性。作为副产品，我们扩展了已有的先前工作的范围，这些工作通过包括预测任务在内的自监督学习来降低表示崩溃率。

    Fine-tuning contextualized representations learned by pre-trained language models remains a prevalent practice in NLP. However, fine-tuning can lead to representation degradation (also known as representation collapse), which may result in instability, sub-optimal performance, and weak generalization.  In this paper, we propose Representation Projection Invariance (REPINA), a novel regularization method to maintain the information content of representation and reduce representation collapse during fine-tuning by discouraging undesirable changes in the representations. We study the empirical behavior of the proposed regularization in comparison to 5 comparable baselines across 13 language understanding tasks (GLUE benchmark and six additional datasets). When evaluating in-domain performance, REPINA consistently outperforms other baselines on most tasks (10 out of 13). We also demonstrate its effectiveness in few-shot settings and robustness to label perturbation. As a by-product, we ext
    
[^73]: GAP-Gen: 引导自动生成 Python 代码的方法

    GAP-Gen: Guided Automatic Python Code Generation. (arXiv:2201.08810v2 [cs.PL] UPDATED)

    [http://arxiv.org/abs/2201.08810](http://arxiv.org/abs/2201.08810)

    本文介绍了一种基于 Python 语法约束和语义约束的引导自动生成 Python 代码的方法 GAP-Gen，通过微调 T5 和 CodeT5 这两种语言模型，在自动生成 Python 代码任务上保持了高生成性能。

    

    自然语言描述自动生成代码在软件开发过程中非常有助于提高效率。本文提出了一种基于 Python 语法约束和语义约束的引导自动生成 Python 代码的方法 GAP-Gen。我们首先介绍了 Syntax-Flow，这是一种简化的抽象语法树（AST）形式的 Python 语法约束，并且在代码中保留了关键的语法信息，从而减小了抽象语法树的规模和复杂性。除了 Syntax-Flow，我们还介绍了 Variable-Flow，它能够在整个代码中一致地抽象变量和函数名。我们的工作重点不是在预训练上，而是在修改微调过程，从而减少计算需求，但在自动生成 Python 代码任务上保持高生成性能。 GAP-Gen 使用 T5 和 CodeT5 这两种基于 transformer 的语言模型，通过 CodeSearchNet 数据集进行微调。

    Automatic code generation from natural language descriptions can be highly beneficial during the process of software development. In this work, we propose GAP-Gen, a Guided Automatic Python Code Generation method based on Python syntactic constraints and semantic constraints. We first introduce Python syntactic constraints in the form of Syntax-Flow, which is a simplified version of Abstract Syntax Tree (AST) reducing the size and high complexity of Abstract Syntax Tree but maintaining crucial syntactic information of Python code. In addition to Syntax-Flow, we introduce Variable-Flow which abstracts variable and function names consistently through out the code. In our work, rather than pretraining, we focus on modifying the finetuning process which reduces computational requirements but retains high generation performance on automatic Python code generation task. GAP-Gen fine-tunes the transformer based language models T5 and CodeT5 using the Code-to-Docstring datasets CodeSearchNet, 
    
[^74]: 一种具有压缩子层的高效Transformer解码器

    An Efficient Transformer Decoder with Compressed Sub-layers. (arXiv:2101.00542v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2101.00542](http://arxiv.org/abs/2101.00542)

    该论文提出了一种使用压缩子层的高效Transformer解码器，通过减少子层并提高并行性能够达到1.42倍的速度提升，同时确保性能与基线相当。

    

    最近由于其高效而流行的大型基于注意力的编码器-解码器网络（Transformer）的解码器计算复杂度高，导致效率问题。通过查看解码器的数学公式，我们发现在某些条件下，可以通过压缩其子层（Transformer的基本构建块）简化架构并实现更高的并行性。因此，我们提出了压缩注意力网络，其解码器层仅包含一个子层而不是三个子层。在14个WMT机器翻译任务的广泛实验中表明，我们的模型比强基线快1.42倍，并且性能相当。而这个强基线已经比广泛使用的标准基线快2倍而且性能不降。

    The large attention-based encoder-decoder network (Transformer) has become prevailing recently due to its effectiveness. But the high computation complexity of its decoder raises the inefficiency issue. By examining the mathematic formulation of the decoder, we show that under some mild conditions, the architecture could be simplified by compressing its sub-layers, the basic building block of Transformer, and achieves a higher parallelism. We thereby propose Compressed Attention Network, whose decoder layer consists of only one sub-layer instead of three. Extensive experiments on 14 WMT machine translation tasks show that our model is 1.42x faster with performance on par with a strong baseline. This strong baseline is already 2x faster than the widely used standard baseline without loss in performance.
    

