# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [DUMA: a Dual-Mind Conversational Agent with Fast and Slow Thinking.](http://arxiv.org/abs/2310.18075) | DUMA是一种具有快速和慢速思考能力的双重思维对话代理框架，通过利用两个生成型大型语言模型，实现了根据情况在直观响应和深思熟虑的问题解决过程之间无缝切换的能力。 |
| [^2] | [Cultural and Linguistic Diversity Improves Visual Representations.](http://arxiv.org/abs/2310.14356) | 这项研究发现数据集和模型生成的图像描述在不同语言间存在显著的语义差异，多语言数据有更高的语义覆盖率，并且基于多语言训练的模型表现更好。 |
| [^3] | [Exploration with Principles for Diverse AI Supervision.](http://arxiv.org/abs/2310.08899) | 本论文提出了一种被称为探索性AI的新范式，旨在自主生成高质量的训练数据。通过利用大型语言模型评估生成内容的新颖性，使AI不再过度依赖人类监督。 |
| [^4] | [Revisiting Large Language Models as Zero-shot Relation Extractors.](http://arxiv.org/abs/2310.05028) | 本研究重新审视了大型语言模型(LLMs)作为零-shot关系抽取器的潜力，并提出了通过总结和提问(\textsc{SumAsk})提示方法来改进零-shot关系抽取。实验证明LLMs在这一任务上具有良好的表现。 |
| [^5] | [Fewer is More: Trojan Attacks on Parameter-Efficient Fine-Tuning.](http://arxiv.org/abs/2310.00648) | 本文研究了参数高效微调（PEFT）的安全性问题，发现PEFT易受特洛伊攻击。通过提出一种新的攻击方式PETA，并在各种下游任务和触发器设计中进行广泛测试，发现PETA能够在攻击成功率和未受影响的准确性方面取得有效结果。 |
| [^6] | [An evaluation of GPT models for phenotype concept recognition.](http://arxiv.org/abs/2309.17169) | 本研究评估了最新的GPT模型在临床深度表型学中的性能，并发现目前这些模型尚未达到最先进的性能水平。 |
| [^7] | [InstructERC: Reforming Emotion Recognition in Conversation with a Retrieval Multi-task LLMs Framework.](http://arxiv.org/abs/2309.11911) | InstructERC是一种使用大型语言模型(LLMs)的生成式框架，通过引入检索模板模块和额外的情感对齐任务，改革了对话中的情绪识别。 |
| [^8] | [Graph of Thoughts: Solving Elaborate Problems with Large Language Models.](http://arxiv.org/abs/2308.09687) | 想法图（GoT）是一种新的框架，它超越了现有的提示范式，通过将大型语言模型（LLM）的信息建模为任意图形，将LLM想法组合成具有协同效应的结果，提炼整个思维网络的本质，或者使用反馈环路增强思维。GoT在不同任务上展示出优势，并可以通过新的想法转换进行扩展，使LLM的推理更接近人类思维。 |
| [^9] | [Think-on-Graph: Deep and Responsible Reasoning of Large Language Model with Knowledge Graph.](http://arxiv.org/abs/2307.07697) | Think-on-Graph是一个利用知识图谱增强大型语言模型深度和负责任推理能力的新框架，在复杂的多跳推理问答任务上表现出色，解决了现有方法中存在的限制。 |
| [^10] | [A Comprehensive Overview of Large Language Models.](http://arxiv.org/abs/2307.06435) | 大语言模型的综合概述，分析了各种新的架构和训练策略，讨论了LLM的特点和功能，并总结了重要的研究发现和关键的架构和训练策略。 |
| [^11] | [GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio Pretraining for Speech Emotion Recognition.](http://arxiv.org/abs/2306.07848) | 本文提出了GEmo-CLAP模型用于语音情感识别，结合了性别属性信息，相比于其他先进方法，该模型在IEMOCAP上实现了更优越的识别性能。 |
| [^12] | [CrossGET: Cross-Guided Ensemble of Tokens for Accelerating Vision-Language Transformers.](http://arxiv.org/abs/2305.17455) | CrossGET是一种通用的加速框架，通过实时的跨模态导引，自适应地结合令牌，实现了视觉-语言转换器的大幅加速。 |
| [^13] | [clembench: Using Game Play to Evaluate Chat-Optimized Language Models as Conversational Agents.](http://arxiv.org/abs/2305.13455) | 本论文探讨了大型语言模型在接触具有挑战性的受限游戏式环境下，能否有意义地评估它们的能力。作为概念验证，研究了五种交互设置，表明当前的聊天优化LLMs在一定程度上能够遵循游戏玩法指令。这对于将LLMs开发为具有广泛适用性的对话代理人具有启示作用。 |
| [^14] | [Interpreting Transformer's Attention Dynamic Memory and Visualizing the Semantic Information Flow of GPT.](http://arxiv.org/abs/2305.13417) | 本文提出了一种将Transformer模型的权重和隐藏状态投影到其词汇表中解释模型的方法，并分析了注意力机制内部信息流的模式。文章还介绍了一个可视化工具，将GPT的前向传递可视化为交互式流图，简化了大量数据为易于阅读的图表，展示了其语义信息流。 |
| [^15] | [A Survey of Large Language Models.](http://arxiv.org/abs/2303.18223) | 本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。 |
| [^16] | [Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning.](http://arxiv.org/abs/2303.10475) | 传统的自然语言处理机器学习需要大规模的任务特定示例，但这不适用于任务可能过于复杂或成本过高以进行注释的场景。因此，社区对于自然语言处理中新的监督寻求范式--从任务指令学习--越来越感兴趣。 |
| [^17] | [tieval: An Evaluation Framework for Temporal Information Extraction Systems.](http://arxiv.org/abs/2301.04643) | 本文提出了tieval，一种用于时间信息抽取系统的评估框架，它提供了标准的接口和评估指标，以克服不同数据集注释体系的差异、解析不同语料库的格式和不同的评估指标等限制。本文通过分析几个TIE系统在不同数据集上的结果，证明了tieval的有效性。 |

# 详细

[^1]: DUMA：具有快速和慢速思考能力的双重思维对话代理

    DUMA: a Dual-Mind Conversational Agent with Fast and Slow Thinking. (arXiv:2310.18075v1 [cs.CL])

    [http://arxiv.org/abs/2310.18075](http://arxiv.org/abs/2310.18075)

    DUMA是一种具有快速和慢速思考能力的双重思维对话代理框架，通过利用两个生成型大型语言模型，实现了根据情况在直观响应和深思熟虑的问题解决过程之间无缝切换的能力。

    

    受到人类认知的双过程理论启发，我们介绍了DUMA，一种新颖的对话代理框架，通过利用两个用于快速和慢速思考的生成型大型语言模型（LLM），体现了双重思维机制。快速思考模型作为主要接口用于外部交互和初始响应生成，根据完整响应的复杂性评估是否需要调用慢速思考模型。一旦被调用，慢速思考模型接管对话，在细致规划、推理和工具利用方面进行工作，提供经过充分分析的响应。这种双重思维配置允许根据情况在直观响应和深思熟虑的问题解决过程之间无缝切换。我们构建了一个用于处理房地产行业在线咨询的对话代理。实验证明，我们的方法在效果和效率之间取得了平衡。

    Inspired by the dual-process theory of human cognition, we introduce DUMA, a novel conversational agent framework that embodies a dual-mind mechanism through the utilization of two generative Large Language Models (LLMs) dedicated to fast and slow thinking respectively. The fast thinking model serves as the primary interface for external interactions and initial response generation, evaluating the necessity for engaging the slow thinking model based on the complexity of the complete response. When invoked, the slow thinking model takes over the conversation, engaging in meticulous planning, reasoning, and tool utilization to provide a well-analyzed response. This dual-mind configuration allows for a seamless transition between intuitive responses and deliberate problem-solving processes based on the situation. We have constructed a conversational agent to handle online inquiries in the real estate industry. The experiment proves that our method balances effectiveness and efficiency, an
    
[^2]: 文化和语言多样性提高了视觉表示

    Cultural and Linguistic Diversity Improves Visual Representations. (arXiv:2310.14356v1 [cs.CV] CROSS LISTED)

    [http://arxiv.org/abs/2310.14356](http://arxiv.org/abs/2310.14356)

    这项研究发现数据集和模型生成的图像描述在不同语言间存在显著的语义差异，多语言数据有更高的语义覆盖率，并且基于多语言训练的模型表现更好。

    

    计算机视觉通常将感知视为客观的，并且这种假设在数据集收集和模型训练中得到反映。例如，不同语言的图像描述通常被假定为相同语义内容的翻译。然而，跨文化心理学和语言学的研究表明，个体的视觉感知因其文化背景和所说的语言而异。在本文中，我们展示了在数据集和模型生成的标题中，不同语言之间存在显著的语义内容差异。当数据是多语言而不是单语言时，标题的语义覆盖率平均更高，以场景图、嵌入和语言复杂性进行测量。例如，与一组单语标题相比，多语标题平均有21.8％更多的对象，24.5％更多的关系，以及27.1％更多的属性。此外，使用来自不同语言的内容训练的模型表现最好。

    Computer vision often treats perception as objective, and this assumption gets reflected in the way that datasets are collected and models are trained. For instance, image descriptions in different languages are typically assumed to be translations of the same semantic content. However, work in cross-cultural psychology and linguistics has shown that individuals differ in their visual perception depending on their cultural background and the language they speak. In this paper, we demonstrate significant differences in semantic content across languages in both dataset and model-produced captions. When data is multilingual as opposed to monolingual, captions have higher semantic coverage on average, as measured by scene graph, embedding, and linguistic complexity. For example, multilingual captions have on average 21.8% more objects, 24.5% more relations, and 27.1% more attributes than a set of monolingual captions. Moreover, models trained on content from different languages perform bes
    
[^3]: 探索多样化AI监督的原则

    Exploration with Principles for Diverse AI Supervision. (arXiv:2310.08899v1 [cs.CL])

    [http://arxiv.org/abs/2310.08899](http://arxiv.org/abs/2310.08899)

    本论文提出了一种被称为探索性AI的新范式，旨在自主生成高质量的训练数据。通过利用大型语言模型评估生成内容的新颖性，使AI不再过度依赖人类监督。

    

    使用下一个标记预测来训练大型transformer在AI领域取得了突破性进展。尽管这种生成型AI方法取得了令人印象深刻的结果，但它严重依赖于人类监督。即使是像ChatGPT这样的最先进的AI模型也依赖于通过人类演示的微调，需要大量的人类输入和领域专业知识。对人类监督的强烈依赖对于推动AI创新构成了重大障碍。为了解决这个限制，我们提出了一种新的范式，称为探索性AI（EAI），旨在自主生成高质量的训练数据。从无监督强化学习（RL）的预训练中获得灵感，EAI在自然语言空间内实现了探索。我们通过利用大型语言模型评估生成内容的新颖性来实现这一目标。我们的方法包括两个关键组成部分：一个生成按照探索原则生成新颖内容的执行者和一个评估生成内容的评论家。

    Training large transformers using next-token prediction has given rise to groundbreaking advancements in AI. While this generative AI approach has produced impressive results, it heavily leans on human supervision. Even state-of-the-art AI models like ChatGPT depend on fine-tuning through human demonstrations, demanding extensive human input and domain expertise. This strong reliance on human oversight poses a significant hurdle to the advancement of AI innovation. To address this limitation, we propose a novel paradigm termed Exploratory AI (EAI) aimed at autonomously generating high-quality training data. Drawing inspiration from unsupervised reinforcement learning (RL) pretraining, EAI achieves exploration within the natural language space. We accomplish this by harnessing large language models to assess the novelty of generated content. Our approach employs two key components: an actor that generates novel content following exploration principles and a critic that evaluates the gen
    
[^4]: 重新审视大型语言模型作为零-shot关系抽取器

    Revisiting Large Language Models as Zero-shot Relation Extractors. (arXiv:2310.05028v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2310.05028](http://arxiv.org/abs/2310.05028)

    本研究重新审视了大型语言模型(LLMs)作为零-shot关系抽取器的潜力，并提出了通过总结和提问(\textsc{SumAsk})提示方法来改进零-shot关系抽取。实验证明LLMs在这一任务上具有良好的表现。

    

    关系抽取(RE)即使在零-shot设定下，一直涉及一定程度的标记或未标记的数据。最近的研究表明，大型语言模型(LLMs)能够在给定自然语言提示的情况下，无需任何数据和参数调整，自动适应新任务，这为从文本中提取关系提供了可能性。本研究主要关注将LLMs，如ChatGPT，作为零-shot关系抽取器的研究。一方面，我们分析了现有RE提示的缺点，并尝试将最近的提示技术，如CoT，纳入其中以提高零-shot关系抽取。我们提出了总结和提问(\textsc{SumAsk})提示，这是一种简单的提示，通过递归使用LLMs将RE输入转换为有效的问答(QA)格式。另一方面，我们对各种基准和设置进行了全面的实验，以调查LLMs在零-shot关系抽取上的能力。具体而言，我们有以下的followi

    Relation extraction (RE) consistently involves a certain degree of labeled or unlabeled data even if under zero-shot setting. Recent studies have shown that large language models (LLMs) transfer well to new tasks out-of-the-box simply given a natural language prompt, which provides the possibility of extracting relations from text without any data and parameter tuning. This work focuses on the study of exploring LLMs, such as ChatGPT, as zero-shot relation extractors. On the one hand, we analyze the drawbacks of existing RE prompts and attempt to incorporate recent prompt techniques such as chain-of-thought (CoT) to improve zero-shot RE. We propose the summarize-and-ask (\textsc{SumAsk}) prompting, a simple prompt recursively using LLMs to transform RE inputs to the effective question answering (QA) format. On the other hand, we conduct comprehensive experiments on various benchmarks and settings to investigate the capabilities of LLMs on zero-shot RE. Specifically, we have the followi
    
[^5]: 更少就意味着更多: 对参数高效微调的特洛伊攻击

    Fewer is More: Trojan Attacks on Parameter-Efficient Fine-Tuning. (arXiv:2310.00648v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.00648](http://arxiv.org/abs/2310.00648)

    本文研究了参数高效微调（PEFT）的安全性问题，发现PEFT易受特洛伊攻击。通过提出一种新的攻击方式PETA，并在各种下游任务和触发器设计中进行广泛测试，发现PETA能够在攻击成功率和未受影响的准确性方面取得有效结果。

    

    参数高效微调（PEFT）可以将预训练语言模型（PLM）高效地适应到特定任务中。通过仅微调一小部分（额外的）参数，PEFT实现了与全面微调相当的性能。然而，尽管它被广泛使用，但PEFT的安全性影响仍然鲜为人知。在本文中，我们进行了一项初步研究，揭示了PEFT对特洛伊攻击的独特易受攻击性。具体而言，我们提出了PETA，一种通过双层优化考虑下游适应的新型攻击方式：上层目标将后门嵌入PLM中，而下层目标模拟PEFT以保留PLM的任务特定性能。通过对多种下游任务和触发器设计的广泛评估，我们证明了PETA在攻击成功率和未受影响的干净准确性方面的有效性，即使受害用户在使用纯净数据对带有后门的PLM进行PEFT后。

    Parameter-efficient fine-tuning (PEFT) enables efficient adaptation of pre-trained language models (PLMs) to specific tasks. By tuning only a minimal set of (extra) parameters, PEFT achieves performance comparable to full fine-tuning. However, despite its prevalent use, the security implications of PEFT remain largely unexplored. In this paper, we conduct a pilot study revealing that PEFT exhibits unique vulnerability to trojan attacks. Specifically, we present PETA, a novel attack that accounts for downstream adaptation through bilevel optimization: the upper-level objective embeds the backdoor into a PLM while the lower-level objective simulates PEFT to retain the PLM's task-specific performance. With extensive evaluation across a variety of downstream tasks and trigger designs, we demonstrate PETA's effectiveness in terms of both attack success rate and unaffected clean accuracy, even after the victim user performs PEFT over the backdoored PLM using untainted data. Moreover, we empi
    
[^6]: 评估GPT模型在表型概念识别中的应用

    An evaluation of GPT models for phenotype concept recognition. (arXiv:2309.17169v1 [cs.CL])

    [http://arxiv.org/abs/2309.17169](http://arxiv.org/abs/2309.17169)

    本研究评估了最新的GPT模型在临床深度表型学中的性能，并发现目前这些模型尚未达到最先进的性能水平。

    

    目标：临床深度表型学在罕见疾病患者的诊断以及构建协调护理计划中起到关键作用。该过程依赖于使用本体概念对患者档案进行建模和整理，通常使用人类表型本体进行。机器学习方法已被广泛采用来支持这项表型概念识别任务。随着大型语言模型在大多数自然语言处理任务中的显著应用，我们在本研究中评估了最新的生成式预训练变压器（GPT）模型在临床深度表型学中的性能。材料和方法：研究的实验设置包括七个不同特异性级别的提示、两个GPT模型（gpt-3.5和gpt-4.0）以及一个已建立的表型识别黄金标准。结果：我们的结果显示，目前这些模型尚未达到最先进的性能水平。最佳运行结果采用了少量样本学习，实现了最佳表现。

    Objective: Clinical deep phenotyping plays a critical role in both the diagnosis of patients with rare disorders as well as in building care coordination plans. The process relies on modelling and curating patient profiles using ontology concepts, usually from the Human Phenotype Ontology. Machine learning methods have been widely adopted to support this phenotype concept recognition task. With the significant shift in the use of large language models (LLMs) for most NLP tasks, herewithin, we examine the performance of the latest Generative Pre-trained Transformer (GPT) models underpinning ChatGPT in clinical deep phenotyping. Materials and Methods: The experimental setup of the study included seven prompts of various levels of specificity, two GPT models (gpt-3.5 and gpt-4.0) and an established gold standard for phenotype recognition. Results: Our results show that, currently, these models have not yet achieved state of the art performance. The best run, using few-shots learning, achi
    
[^7]: InstructERC：借助检索多任务LLMs框架改革对话中的情绪识别

    InstructERC: Reforming Emotion Recognition in Conversation with a Retrieval Multi-task LLMs Framework. (arXiv:2309.11911v1 [cs.CL])

    [http://arxiv.org/abs/2309.11911](http://arxiv.org/abs/2309.11911)

    InstructERC是一种使用大型语言模型(LLMs)的生成式框架，通过引入检索模板模块和额外的情感对齐任务，改革了对话中的情绪识别。

    

    对话情绪识别(ERC)的发展一直受到管道设计复杂性的阻碍，导致ERC模型往往对特定数据集和对话模式过拟合。在本研究中，我们提出了一种新方法，即InstructERC，将ERC任务从判别式框架转化为基于大型语言模型(LLMs)的生成式框架。InstructERC有两个重要贡献：首先，InstructERC引入了一个简单而有效的检索模板模块，通过将历史对话内容、标签语句和情感领域演示与高语义相似性进行拼接，帮助模型明确地集成多粒度对话监督信息。此外，我们引入了两个额外的情感对齐任务，即说话人识别和情感预测任务，以隐式地建模对话角色关系和未来对话情绪倾向。我们的基于LLM的方法

    The development of emotion recognition in dialogue (ERC) has been consistently hindered by the complexity of pipeline designs, leading to ERC models that often overfit to specific datasets and dialogue patterns. In this study, we propose a novel approach, namely  InstructERC, to reformulates the ERC task from a discriminative framework to a generative framework based on Large Language Models (LLMs) . InstructERC has two significant contributions: Firstly, InstructERC introduces a simple yet effective retrieval template module, which helps the model explicitly integrate multi-granularity dialogue supervision information by concatenating the historical dialog content, label statement, and emotional domain demonstrations with high semantic similarity. Furthermore, we introduce two additional emotion alignment tasks, namely speaker identification and emotion prediction tasks, to implicitly model the dialogue role relationships and future emotional tendencies in conversations. Our LLM-based
    
[^8]: 想法图：用大型语言模型解决复杂问题

    Graph of Thoughts: Solving Elaborate Problems with Large Language Models. (arXiv:2308.09687v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.09687](http://arxiv.org/abs/2308.09687)

    想法图（GoT）是一种新的框架，它超越了现有的提示范式，通过将大型语言模型（LLM）的信息建模为任意图形，将LLM想法组合成具有协同效应的结果，提炼整个思维网络的本质，或者使用反馈环路增强思维。GoT在不同任务上展示出优势，并可以通过新的想法转换进行扩展，使LLM的推理更接近人类思维。

    

    我们介绍了一种名为想法图（Graph of Thoughts，GoT）的框架，它在大型语言模型（LLM）的提示能力上超越了Chain-of-Thought或Tree of Thoughts（ToT）等范式。GoT的关键思想和主要优势在于能够将LLM生成的信息建模为任意图形，其中信息单元（"LLM想法"）是顶点，边表示这些顶点之间的依赖关系。这种方法使得将任意LLM想法组合成具有协同效应的结果、提炼整个思维网络的本质或者使用反馈环路增强思维成为可能。我们证明GoT在不同任务上比最先进的方法有优势，例如在排序任务上质量提高了62%，同时成本降低了超过31%。我们确保GoT能够通过新的想法转换进行扩展，从而可以用于开创新的提示方案。这项工作使得LLM的推理更接近人类思维。

    We introduce Graph of Thoughts (GoT): a framework that advances prompting capabilities in large language models (LLMs) beyond those offered by paradigms such as Chain-of-Thought or Tree of Thoughts (ToT). The key idea and primary advantage of GoT is the ability to model the information generated by an LLM as an arbitrary graph, where units of information ("LLM thoughts") are vertices, and edges correspond to dependencies between these vertices. This approach enables combining arbitrary LLM thoughts into synergistic outcomes, distilling the essence of whole networks of thoughts, or enhancing thoughts using feedback loops. We illustrate that GoT offers advantages over state of the art on different tasks, for example increasing the quality of sorting by 62% over ToT, while simultaneously reducing costs by >31%. We ensure that GoT is extensible with new thought transformations and thus can be used to spearhead new prompting schemes. This work brings the LLM reasoning closer to human thinki
    
[^9]: Think-on-Graph: 利用知识图谱进行大型语言模型的深度和负责任的推理

    Think-on-Graph: Deep and Responsible Reasoning of Large Language Model with Knowledge Graph. (arXiv:2307.07697v1 [cs.CL])

    [http://arxiv.org/abs/2307.07697](http://arxiv.org/abs/2307.07697)

    Think-on-Graph是一个利用知识图谱增强大型语言模型深度和负责任推理能力的新框架，在复杂的多跳推理问答任务上表现出色，解决了现有方法中存在的限制。

    

    大型语言模型（LLMs）在各种任务中取得了重大进展，但在需要知识追溯性、及时性和准确性至关重要的场景中，它们经常在复杂推理和表现方面遇到困难。为了解决这些限制，我们提出了Think-on-Graph（ToG），这是一个利用知识图谱增强LLMs深度和负责任推理能力的新框架。通过使用ToG，我们可以确定与给定问题相关的实体，并对外部知识数据库进行探索和推理，以检索相关三元组。这个迭代过程生成包含顺序连接的三元组的多个推理路径，直到收集到足够的信息来回答问题或达到最大深度为止。通过在复杂的多跳推理问答任务上的实验证明，ToG优于现有方法，有效地解决了LLMs的前述限制。

    Large language models (LLMs) have made significant strides in various tasks, yet they often struggle with complex reasoning and exhibit poor performance in scenarios where knowledge traceability, timeliness, and accuracy are crucial. To address these limitations, we present Think-on-Graph (ToG), a novel framework that leverages knowledge graphs to enhance LLMs' ability for deep and responsible reasoning. By employing ToG, we can identify entities relevant to a given question and conduct exploration and reasoning to retrieve related triples from an external knowledge database. This iterative procedure generates multiple reasoning pathways consisting of sequentially connected triplets until sufficient information is gathered to answer the question or the maximum depth is reached. Through experiments on complex multi-hop reasoning question-answering tasks, we demonstrate that ToG outperforms existing methods, effectively addressing the aforementioned limitations of LLMs without incurring 
    
[^10]: 大语言模型的综合概述

    A Comprehensive Overview of Large Language Models. (arXiv:2307.06435v1 [cs.CL])

    [http://arxiv.org/abs/2307.06435](http://arxiv.org/abs/2307.06435)

    大语言模型的综合概述，分析了各种新的架构和训练策略，讨论了LLM的特点和功能，并总结了重要的研究发现和关键的架构和训练策略。

    

    大语言模型（LLM）展示了出色的泛化能力，导致了众多模型的发展。这些模型提出了各种新的架构，通过改进的训练策略来调整现有的架构，增加上下文长度，使用高质量的训练数据，并增加训练时间以超越基线。分析新的发展对于识别增强训练稳定性和改进LLM泛化能力的变化至关重要。本综述论文全面分析了LLM的架构及其分类、训练策略、训练数据集和性能评估，并讨论未来的研究方向。此外，本文还讨论了LLM的基本构建块和概念，并提供了LLM的完整概述，包括其重要特点和功能。最后，本文总结了LLM研究的重要发现，并整合了关键的架构和训练策略。

    Large Language Models (LLMs) have shown excellent generalization capabilities that have led to the development of numerous models. These models propose various new architectures, tweaking existing architectures with refined training strategies, increasing context length, using high-quality training data, and increasing training time to outperform baselines. Analyzing new developments is crucial for identifying changes that enhance training stability and improve generalization in LLMs. This survey paper comprehensively analyses the LLMs architectures and their categorization, training strategies, training datasets, and performance evaluations and discusses future research directions. Moreover, the paper also discusses the basic building blocks and concepts behind LLMs, followed by a complete overview of LLMs, including their important features and functions. Finally, the paper summarizes significant findings from LLM research and consolidates essential architectural and training strateg
    
[^11]: GEmo-CLAP: 面向语音情感识别的性别属性增强对比语音-语言预训练模型

    GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio Pretraining for Speech Emotion Recognition. (arXiv:2306.07848v1 [cs.CL])

    [http://arxiv.org/abs/2306.07848](http://arxiv.org/abs/2306.07848)

    本文提出了GEmo-CLAP模型用于语音情感识别，结合了性别属性信息，相比于其他先进方法，该模型在IEMOCAP上实现了更优越的识别性能。

    

    对比语音-语言预训练（CLAP）最近在不同领域取得了惊人的成功。本文提出了一种名为GEmo-CLAP的高效性别属性增强CLAP模型，用于语音情感识别（SER）。具体而言，我们首先利用各种自监督学习的预训练模型构建了一种有效的情感CLAP模型（称为Emo-CLAP），用于SER。然后，考虑到在语音情感建模中性别属性的重要性，我们进一步提出了两种GEmo-CLAP方法，来整合语音信号的情感和性别信息，形成更合理的目标。在IEMOCAP语料库上进行的大量实验表明，我们提出的两种GEmo-CLAP方法始终优于基线Emo-CLAP模型（使用不同的预训练模型），同时与其他最先进的方法相比实现了更优越的识别性能。

    Contrastive Language-Audio Pretraining (CLAP) has recently exhibited impressive success in diverse fields. In this paper, we propose GEmo-CLAP, a kind of efficient gender-attribute-enhanced CLAP model for speech emotion recognition (SER). Specifically, we first build an effective emotion CLAP model termed Emo-CLAP for SER, utilizing various self-supervised learning based pre-trained models. Then, considering the importance of the gender attribute in speech emotion modeling, two GEmo-CLAP approaches are further proposed to integrate the emotion and gender information of speech signals, forming more reasonable objectives. Extensive experiments conducted on the IEMOCAP corpus demonstrate that our proposed two GEmo-CLAP approaches consistently outperform the baseline Emo-CLAP with different pre-trained models, while also achieving superior recognition performance compared with other state-of-the-art methods.
    
[^12]: CrossGET: 跨导引的令牌集合用于加速视觉-语言转换器

    CrossGET: Cross-Guided Ensemble of Tokens for Accelerating Vision-Language Transformers. (arXiv:2305.17455v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.17455](http://arxiv.org/abs/2305.17455)

    CrossGET是一种通用的加速框架，通过实时的跨模态导引，自适应地结合令牌，实现了视觉-语言转换器的大幅加速。

    

    最近，视觉-语言模型取得了巨大的进展，远远超出了我们的预期。然而，它们的计算成本随着快速发展也在大幅增长，特别是对于大型模型而言。在资源有限的情况下，模型加速变得极其关键。尽管对于单模态模型进行了广泛的研究，但对于多模态模型，特别是视觉-语言转换器的加速仍然相对不足。为了追求更高效和可访问的视觉-语言转换器，本文介绍了一种称为CrossGET的跨导引令牌集合的通用加速框架。该框架通过实时的跨模态导引，自适应地结合令牌，从而实现大幅加速而保持高性能。CrossGET的两个关键创新点是：1) 跨导引匹配和集合。CrossGET将跨导引的匹配和集合应用到视觉-语言转换器中，

    Recent vision-language models have achieved tremendous progress far beyond what we ever expected. However, their computational costs are also dramatically growing with rapid development, especially for the large models. It makes model acceleration exceedingly critical in a scenario of limited resources. Although extensively studied for unimodal models, the acceleration for multimodal models, especially the vision-language Transformers, is relatively under-explored. To pursue more efficient and accessible vision-language Transformers, this paper introduces \textbf{Cross}-\textbf{G}uided \textbf{E}nsemble of \textbf{T}okens (\textbf{\emph{CrossGET}}), a universal acceleration framework for vision-language Transformers. This framework adaptively combines tokens through real-time, cross-modal guidance, thereby achieving substantial acceleration while keeping high performance. \textit{CrossGET} has two key innovations: 1) \textit{Cross-Guided Matching and Ensemble}. \textit{CrossGET} incorp
    
[^13]: clembench：使用游戏来评估作为对话代理人的聊天优化语言模型

    clembench: Using Game Play to Evaluate Chat-Optimized Language Models as Conversational Agents. (arXiv:2305.13455v1 [cs.CL])

    [http://arxiv.org/abs/2305.13455](http://arxiv.org/abs/2305.13455)

    本论文探讨了大型语言模型在接触具有挑战性的受限游戏式环境下，能否有意义地评估它们的能力。作为概念验证，研究了五种交互设置，表明当前的聊天优化LLMs在一定程度上能够遵循游戏玩法指令。这对于将LLMs开发为具有广泛适用性的对话代理人具有启示作用。

    

    最近的工作提出了一种针对“站立语言理解代理”的系统评估方法——代理在丰富的语言和非语言环境中运行，通过在精心构造的互动环境中进行测试来评估它们。其他最近的工作则认为，如果适当设置，大型语言模型（LLMs）可以被理解为这样的代理（的模拟器）。本文探讨了这种联系：是否可以通过让LLMs接触具有挑战性的受限游戏式环境来有意义地评估它们的能力？作为概念验证，本文研究了五种交互设置，表明当前的聊天优化LLMs在一定程度上能够遵循游戏玩法指令。这种能力和游戏玩法的质量（通过满足不同游戏目标的情况来衡量）都遵循着发展循环，新型模型表现更好。即使是相对简单的“井字游戏”示例游戏的指标也提供了模型在这些条件下的基本性能指示。这对于将LLMs开发为具有广泛适用性的对话代理人具有启示作用。

    Recent work has proposed a methodology for the systematic evaluation of "Situated Language Understanding Agents"-agents that operate in rich linguistic and non-linguistic contexts-through testing them in carefully constructed interactive settings. Other recent work has argued that Large Language Models (LLMs), if suitably set up, can be understood as (simulators of) such agents. A connection suggests itself, which this paper explores: Can LLMs be evaluated meaningfully by exposing them to constrained game-like settings that are built to challenge specific capabilities? As a proof of concept, this paper investigates five interaction settings, showing that current chat-optimised LLMs are, to an extent, capable to follow game-play instructions. Both this capability and the quality of the game play, measured by how well the objectives of the different games are met, follows the development cycle, with newer models performing better. The metrics even for the comparatively simple example gam
    
[^14]: 解读Transformer的注意力动态内存，可视化GPT的语义信息流

    Interpreting Transformer's Attention Dynamic Memory and Visualizing the Semantic Information Flow of GPT. (arXiv:2305.13417v1 [cs.CL])

    [http://arxiv.org/abs/2305.13417](http://arxiv.org/abs/2305.13417)

    本文提出了一种将Transformer模型的权重和隐藏状态投影到其词汇表中解释模型的方法，并分析了注意力机制内部信息流的模式。文章还介绍了一个可视化工具，将GPT的前向传递可视化为交互式流图，简化了大量数据为易于阅读的图表，展示了其语义信息流。

    

    最近，解释性方面的进展表明我们可以将基于transformer模型的语言模型的权重和隐藏状态投影到其词汇表中，这种转换使它们变得更容易理解，并且使我们能够将语义分配到仅作为数字向量的内容上。在本文中，我们解释了LM注意力头和内存值，这些向量是模型在处理给定输入时动态地创建和检索的。通过通过这种投影分析它们所代表的标记，我们确定了注意力机制内部信息流的模式。基于这些发现，我们创建了一个工具来将生成预训练Transformer（GPT）的前向传递可视化为交互式流图，其中结点代表神经元或隐藏状态，边代表它们之间的相互作用。我们的可视化将海量数据简化为易于阅读的图表，反映了模型为什么输出其结果的原因。我们通过确定最重要的特征并可视化其语义信息流来演示我们建模的效用。

    Recent advances in interpretability suggest we can project weights and hidden states of transformer-based language models (LMs) to their vocabulary, a transformation that makes them human interpretable and enables us to assign semantics to what was seen only as numerical vectors. In this paper, we interpret LM attention heads and memory values, the vectors the models dynamically create and recall while processing a given input. By analyzing the tokens they represent through this projection, we identify patterns in the information flow inside the attention mechanism. Based on these discoveries, we create a tool to visualize a forward pass of Generative Pre-trained Transformers (GPTs) as an interactive flow graph, with nodes representing neurons or hidden states and edges representing the interactions between them. Our visualization simplifies huge amounts of data into easy-to-read plots that reflect why models output their results. We demonstrate the utility of our modeling by identifyi
    
[^15]: 大型语言模型综述

    A Survey of Large Language Models. (arXiv:2303.18223v1 [cs.CL])

    [http://arxiv.org/abs/2303.18223](http://arxiv.org/abs/2303.18223)

    本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。

    

    语言本质上是一个由语法规则控制的复杂精细的人类表达系统，对于开发理解和掌握语言的能力的AI算法来说是一项重大挑战。作为主要方法之一，语言建模在过去二十年里广泛研究用于语言理解和生成，从统计语言模型演化为神经语言模型。最近，通过在大规模语料库上预训练Transformer模型，提出了预训练语言模型（PLMs），在解决各种NLP任务方面显示出强大的能力。由于研究人员发现模型缩放可以导致性能改进，他们进一步通过增加模型规模来研究缩放效应，有趣的是，当参数规模超过一定水平时，这些扩大的语言模型不仅可以实现显着的性能提升，而且还显示出一些小规模语言模型所没有的特殊能力。

    Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale langu
    
[^16]: 仅仅提示足够了吗？不是的。指导学习的全面和更广阔视角（arXiv：2303.10475v1 [cs.CL]）

    Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning. (arXiv:2303.10475v1 [cs.CL])

    [http://arxiv.org/abs/2303.10475](http://arxiv.org/abs/2303.10475)

    传统的自然语言处理机器学习需要大规模的任务特定示例，但这不适用于任务可能过于复杂或成本过高以进行注释的场景。因此，社区对于自然语言处理中新的监督寻求范式--从任务指令学习--越来越感兴趣。

    

    任务语义可以通过一组输入输出示例或一条文本指令来表达。传统的自然语言处理（NLP）机器学习方法主要依赖于大规模的任务特定示例的可用性。这引起了两个问题：首先，收集任务特定标记示例不适用于任务可能过于复杂或成本过高以进行注释的场景，或者系统需要立即处理新任务。其次，这不是用户友好的，因为最终用户可能更愿意在使用系统之前提供任务描述而不是一组示例。因此，社区对于自然语言处理中新的监督寻求范式--从任务指令学习--越来越感兴趣。尽管取得了令人印象深刻的进展，但社区仍然面临着一些共同的问题。本次调查旨在总结指导学习的当前研究，特别是回答以下问题：

    Task semantics can be expressed by a set of input-to-output examples or a piece of textual instruction. Conventional machine learning approaches for natural language processing (NLP) mainly rely on the availability of large-scale sets of task-specific examples. Two issues arise: first, collecting task-specific labeled examples does not apply to scenarios where tasks may be too complicated or costly to annotate, or the system is required to handle a new task immediately; second, this is not user-friendly since end-users are probably more willing to provide task description rather than a set of examples before using the system. Therefore, the community is paying increasing interest in a new supervision-seeking paradigm for NLP: learning from task instructions. Despite its impressive progress, there are some common issues that the community struggles with. This survey paper tries to summarize the current research on instruction learning, particularly, by answering the following questions:
    
[^17]: tieval：一种用于时间信息抽取系统评估的评估框架

    tieval: An Evaluation Framework for Temporal Information Extraction Systems. (arXiv:2301.04643v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.04643](http://arxiv.org/abs/2301.04643)

    本文提出了tieval，一种用于时间信息抽取系统的评估框架，它提供了标准的接口和评估指标，以克服不同数据集注释体系的差异、解析不同语料库的格式和不同的评估指标等限制。本文通过分析几个TIE系统在不同数据集上的结果，证明了tieval的有效性。

    

    近二十年来，时间信息抽取(TIE)引起了广泛关注，推动了大量数据集的开发。然而，拥有大量语料库的好处与此同时也使得对TIE系统进行基准测试变得困难。不同数据集具有不同的注释体系，这使得比较不同语料库中的竞争对手变得困难。此外，每个语料库通常采用不同的格式进行传播，因此需要研究人员/从业人员在开发所有语料库的解析器时付出大量的工程努力。这种限制迫使研究人员选择有限的数据集来评估他们的系统，从而限制了系统的比较。另一个阻碍TIE系统可比性的障碍是评估指标的采用。本文提出了tieval，一种TIE系统的评估框架，为语料库访问、黄金标准表示和评估指标提供了标准接口。我们还展示了如何使用tieval评估TIE系统，并对TIE社区中使用的两个黄金标准的几个TIE系统的结果进行了广泛的分析。

    Temporal information extraction (TIE) has attracted a great deal of interest over the last two decades, leading to the development of a significant number of datasets. Despite its benefits, having access to a large volume of corpora makes it difficult when it comes to benchmark TIE systems. On the one hand, different datasets have different annotation schemes, thus hindering the comparison between competitors across different corpora. On the other hand, the fact that each corpus is commonly disseminated in a different format requires a considerable engineering effort for a researcher/practitioner to develop parsers for all of them. This constraint forces researchers to select a limited amount of datasets to evaluate their systems which consequently limits the comparability of the systems. Yet another obstacle that hinders the comparability of the TIE systems is the evaluation metric employed. While most research works adopt traditional metrics such as precision, recall, and $F_1$, a fe
    

