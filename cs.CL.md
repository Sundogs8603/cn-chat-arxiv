# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Backtracing: Retrieving the Cause of the Query](https://arxiv.org/abs/2403.03956) | 引入了回溯任务，通过检索文本段来确定引发用户查询的原因，涉及到不同领域，包括讲座、新闻和对话，评估了零次性能。 |
| [^2] | [The Heuristic Core: Understanding Subnetwork Generalization in Pretrained Language Models](https://arxiv.org/abs/2403.03942) | 在预训练语言模型中，发现所有子网络都共享一个注意力头集合，被称为启发式核心，这可能是造成子网络泛化差异的原因。 |
| [^3] | [Did Translation Models Get More Robust Without Anyone Even Noticing?](https://arxiv.org/abs/2403.03923) | 最近的研究表明，新的多语言机器翻译模型和大型语言模型在面对各种噪声输入时比先前的模型更加稳健，尽管它们的参数更多、训练过程更复杂，并且没有采用特定设计用于增强稳健性的技术。 |
| [^4] | [Enhancing Instructional Quality: Leveraging Computer-Assisted Textual Analysis to Generate In-Depth Insights from Educational Artifacts](https://arxiv.org/abs/2403.03920) | 通过计算机辅助文本分析，本文揭示了人工智能和机器学习方法在教学质量提升中的重要作用，为教育工作者提供了深入见解和可操作的反馈。 |
| [^5] | [A Measure for Transparent Comparison of Linguistic Diversity in Multilingual NLP Data Sets](https://arxiv.org/abs/2403.03909) | 本文提出了一种评估数据集语言多样性的方法，通过与参考语言样本进行对比，利用适合比较度量集合的Jaccard指数的版本来最大程度地促进长期内的多语言多样性。 |
| [^6] | [IRCoder: Intermediate Representations Make Language Models Robust Multilingual Code Generators](https://arxiv.org/abs/2403.03894) | 通过利用编译器中间表示来改进代码-LMs的多语言能力和促进跨语言转移。 |
| [^7] | [From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models](https://arxiv.org/abs/2403.03893) | 该研究拓展了语言模型中毒性缓解的范围，涵盖了多语言环境，通过翻译数据评估和增强缓解技术，比较了不同缓解方法，并探讨了模型大小和数据量对缓解效果的影响。 |
| [^8] | [FaaF: Facts as a Function for the evaluation of RAG systems](https://arxiv.org/abs/2403.03888) | FaaF是一种新的事实验证方法，利用语言模型的函数调用能力和面向RAG事实回忆评估的框架，显着提高了LM识别不支持事实的能力，并在效率和成本方面取得了明显的改进。 |
| [^9] | [SaulLM-7B: A pioneering Large Language Model for Law](https://arxiv.org/abs/2403.03883) | SaulLM-7B是首个专为法律文本设计的7B参数LLM，通过InnovativeFine-tuning方法，展现了领先的法律文件理解和处理能力。 |
| [^10] | [Impoverished Language Technology: The Lack of (Social) Class in NLP](https://arxiv.org/abs/2403.03874) | 该论文探讨了NLP领域中缺乏对社会阶级因素的研究，呼吁研究者在NLP技术中考虑和操作化阶级因素。 |
| [^11] | [Learning to Decode Collaboratively with Multiple Language Models](https://arxiv.org/abs/2403.03870) | 学习了一种协作解码方法，通过在标记级别交错生成来教授多个大型语言模型协作，无需直接监督，在特定任务中融合每个模型的专业知识，提高了联合系统的性能。 |
| [^12] | [On the Origins of Linear Representations in Large Language Models](https://arxiv.org/abs/2403.03867) | 本文研究了大型语言模型中线性表示的起源，通过引入简单的潜变量模型，并展示了梯度下降的隐性偏差与下一个标记预测目标共同促进了概念的线性表示。 |
| [^13] | [KIWI: A Dataset of Knowledge-Intensive Writing Instructions for Answering Research Questions](https://arxiv.org/abs/2403.03866) | 该论文介绍了一个名为KIWI的数据集，用于评估大型语言模型在提供科学写作帮助时的能力，发现这些模型在整合新信息到现有答案中存在困难。 |
| [^14] | [X-Shot: A Unified System to Handle Frequent, Few-shot and Zero-shot Learning Simultaneously in Classification](https://arxiv.org/abs/2403.03863) | X-Shot 提出了一个新的分类挑战，旨在在实际环境中同时处理频繁、少样本和零样本标签，系统需要能够适应任何标签出现频率。 |
| [^15] | [Designing Informative Metrics for Few-Shot Example Selection](https://arxiv.org/abs/2403.03861) | 提出了一种基于复杂度的提示选择方法，用于将示例与测试句子的句法-语义复杂度对齐，在少样本NER任务中取得了显著的性能提升。 |
| [^16] | [Emojinize : Enriching Any Text with Emoji Translations](https://arxiv.org/abs/2403.03857) | Emojinize 是一种方法，能够通过大型语言模型选择适当的表情符号翻译文本，提高猜测性，人类猜测可达55％。 |
| [^17] | [ShortGPT: Layers in Large Language Models are More Redundant Than You Expect](https://arxiv.org/abs/2403.03853) | 大语言模型中的层级存在较高相似性，有些层对网络功能几乎无影响。研究提出一种称为区块影响的度量，并通过层删除方法显著优于以往的模型修剪方法。 |
| [^18] | [A Modular Approach for Multimodal Summarization of TV Shows](https://arxiv.org/abs/2403.03823) | 提出了一种模块化方法用于多模态电视节目摘要，包括检测场景边界、重新排列场景、将视觉信息转换为文本、总结对话以及将场景摘要融合的过程，并引入了一个新的衡量摘要质量的评价指标PREFS。 |
| [^19] | [Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ](https://arxiv.org/abs/2403.03814) | 本研究通过引入MultiQ基准，调查了最先进的开放LLMs在其预期使用范围之外的基本多语能力，发现这些模型对于至少某些语言能够忠实和准确地进行回答。 |
| [^20] | [PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion](https://arxiv.org/abs/2403.03788) | 提出了PowerPoint任务完成鲁棒性基准（PPTC-R），旨在评估大型语言模型（LLMs）对用户PPT任务指令和软件版本的鲁棒性，发现GPT-4表现最佳。 |
| [^21] | [German also Hallucinates! Inconsistency Detection in News Summaries with the Absinth Dataset](https://arxiv.org/abs/2403.03750) | 本文提出了一个用于德语新闻摘要中幻觉检测的数据集absinth，探讨了LLMs在该任务中的应用。 |
| [^22] | [Probabilistic Topic Modelling with Transformer Representations](https://arxiv.org/abs/2403.03737) | 提出了Transformer-Representation神经主题模型（TNTM），结合了transformer嵌入空间中主题表示的优势和概率建模以及变分自动编码器（VAE）框架，实现了主题建模的强大和多功能性 |
| [^23] | [Rapidly Developing High-quality Instruction Data and Evaluation Benchmark for Large Language Models with Minimal Human Effort: A Case Study on Japanese](https://arxiv.org/abs/2403.03690) | 通过GPT-4自指导方法，快速开发高质量的日语指令数据和评估基准，无需大量人力投入，并为大型语言模型提供了有效的资源 |
| [^24] | [General2Specialized LLMs Translation for E-commerce](https://arxiv.org/abs/2403.03689) | 提出了一个名为G2ST的两步微调范式，通过自对比语义增强将通用NMT模型转换为专门用于电子商务的NMT模型，以提高翻译质量。 |
| [^25] | [Apollo: Lightweight Multilingual Medical LLMs towards Democratizing Medical AI to 6B People](https://arxiv.org/abs/2403.03640) | Apollo项目开发了多语言医学LLMs，创建了全球人口61亿的医学数据集，并发布了各种尺寸的最佳性能模型，其中Apollo-7B是最先进的多语言医学LLMs，可改善更大模型的多语言医学能力。 |
| [^26] | [GPTopic: Dynamic and Interactive Topic Representations](https://arxiv.org/abs/2403.03628) | 介绍了GPTopic，一种利用大型语言模型创建动态、交互式主题表示的软件包，通过直观的聊天界面使主题建模更易用和全面。 |
| [^27] | [Multimodal Large Language Models to Support Real-World Fact-Checking](https://arxiv.org/abs/2403.03627) | 多模态大型语言模型在支持现实世界事实核查中展现出优越性能，并能够解释恶意和误导性声明的不合理之处和潜在动机。 |
| [^28] | [Design of an Open-Source Architecture for Neural Machine Translation](https://arxiv.org/abs/2403.03582) | 该开源应用程序 adaptNMT 简化了神经机器翻译模型的开发和部署，提供了图形化训练进展展示、子词分割模型和一键式模型开发方法。 |
| [^29] | [Enhancing ASD detection accuracy: a combined approach of machine learning and deep learning models with natural language processing](https://arxiv.org/abs/2403.03581) | 该研究利用机器学习和深度学习模型结合自然语言处理技术，成功提高了ASD检测准确率，尤其在儿童中具有重要意义。 |
| [^30] | [gaHealth: An English-Irish Bilingual Corpus of Health Data](https://arxiv.org/abs/2403.03575) | 开发了一份用于低资源英语到爱尔兰语言对的特定健康领域数据集，实证证明使用领域数据对健康领域具有明显好处，并展示的最大BLEU分数提升为22.2点（40%）。 |
| [^31] | [Benchmarking Hallucination in Large Language Models based on Unanswerable Math Word Problem](https://arxiv.org/abs/2403.03558) | 本文提出了一种新方法，通过无法回答的数学单词问题评估大型语言模型中的幻觉能力，通过开发包含五个类别的5200个问题的UMWP数据集，结合文本相似度和数学表达式检测的评估方法，表明在-context学习和强化学习与人类反馈(RLHF)训练显著增强了模型避免幻觉的能力。 |
| [^32] | [Prompt Mining for Language-based Human Mobility Forecasting](https://arxiv.org/abs/2403.03544) | 使用信息熵进行提示挖掘，探索多样化的提示设计策略，提高基于语言的人类移动预测的准确性和效果 |
| [^33] | [RADIA -- Radio Advertisement Detection with Intelligent Analytics](https://arxiv.org/abs/2403.03538) | 本研究提出了一种新型自动广播广告检测技术RADIA，利用先进的语音识别和文本分类算法，能够在不需要先验知识的情况下检测广播中的即兴和新广告，为广播广告检测提供了全面的解决方案，并取得了较高的F1-macro得分。 |
| [^34] | [Non-verbal information in spontaneous speech - towards a new framework of analysis](https://arxiv.org/abs/2403.03522) | 这项研究提出了一个分析框架和技术验证概念，用于对言语中的非言语信号进行分类，并将其与含义关联起来，从而为探索表达实现多层韵律事件的大型数据提供了一种方法。 |
| [^35] | [BiVert: Bidirectional Vocabulary Evaluation using Relations for Machine Translation](https://arxiv.org/abs/2403.03521) | 提出了一种双向基于语义的评估方法，通过使用BabelNet词典计算源文本和反向翻译之间的语义距离，实现了在相同语言水平上的句子比较。 |
| [^36] | [Unsupervised Multilingual Dense Retrieval via Generative Pseudo Labeling](https://arxiv.org/abs/2403.03516) | 通过生成伪标签实现的无监督多语言稠密检索方法能够在多语言信息检索中取得优异性能，提高了多语言检索器的实用性 |
| [^37] | [CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models](https://arxiv.org/abs/2403.03514) | CLongEval是一个用于评估长上下文大语言模型的全面中文基准，具有足够的数据量、广泛的适用性和高质量，可以对多个开源和商业模型进行全面评估。 |
| [^38] | [Towards Detecting AI-Generated Text within Human-AI Collaborative Hybrid Texts](https://arxiv.org/abs/2403.03506) | 本研究探索了在人工智能协作混合文本中句子级人工智能生成文本检测的挑战，并提出了一种基于分割的两步骤流程来检测各段落的一致作者句子。 |
| [^39] | [A Knowledge Plug-and-Play Test Bed for Open-domain Dialogue Generation](https://arxiv.org/abs/2403.03496) | 本文提出了一个新的高质量基准测试，用于评估支持知识检索，在开放领域对话生成中引入新的知识源 |
| [^40] | [Magic Markup: Maintaining Document-External Markup with an LLM](https://arxiv.org/abs/2403.03481) | 使用LLM模型，我们提出了一种新方法，将元数据绑定到文本实体，扩展了文档注释的应用，实现了对修改后程序的自动重新标记，并提供了正式问题定义和基准套件。 |
| [^41] | [VLSP 2023 -- LTER: A Summary of the Challenge on Legal Textual Entailment Recognition](https://arxiv.org/abs/2403.03435) | 针对越南语言领域的法律文本蕴涵识别首次被引入，分析了参与者结果并讨论了法律领域中的关键语言因素挑战。 |
| [^42] | [Mixture-of-LoRAs: An Efficient Multitask Tuning for Large Language Models](https://arxiv.org/abs/2403.03432) | 提出了一种新颖且参数高效的混合LoRAs（MoA）架构，通过引入领域标签和显式路由策略，解决了大型语言模型多任务学习中的灾难性遗忘和任务干扰问题，从而提升了每个任务的性能。 |
| [^43] | [Negating Negatives: Alignment without Human Positive Samples via Distributional Dispreference Optimization](https://arxiv.org/abs/2403.03419) | 通过提出Distributional Dispreference Optimization (D$^2$O)方法，在不需要人类正样本的情况下实现了对齐，减少了有害信息的传播。 |
| [^44] | [Human vs. Machine: Language Models and Wargames](https://arxiv.org/abs/2403.03407) | 人工智能大型语言模型在战争游戏中与人类响应存在一致性，但也存在显著的差异，这表明在政策制定者交出自主权或听从基于AI的战略建议之前应谨慎对待。 |
| [^45] | [Japanese-English Sentence Translation Exercises Dataset for Automatic Grading](https://arxiv.org/abs/2403.03396) | 本文提出了用于自动评估句子翻译练习的任务，并创建了日英STE数据集，实验结果表明微调的BERT模型能够以约90%的F1值分类正确回答 |
| [^46] | [Learning to Maximize Mutual Information for Chain-of-Thought Distillation](https://arxiv.org/abs/2403.03348) | 通过最大化两个任务的表示特征的互信息，提出了一种解决思维链蒸馏中标签预测任务与知识集成不足问题的变分方法。 |
| [^47] | [Scope of Large Language Models for Mining Emerging Opinions in Online Health Discourse](https://arxiv.org/abs/2403.03336) | 本论文开发了一个由LLM驱动的框架，用于在在线健康社区中进行新兴观点挖掘，提出了一种新颖的Claim识别方法和观点挖掘驱动的评估框架，并发布了用于评估LLMs在在线健康社区中宣称识别和立场检测任务的新测试数据集。 |
| [^48] | [DIVERSE: Deciphering Internet Views on the U.S. Military Through Video Comment Stance Analysis, A Novel Benchmark Dataset for Stance Classification](https://arxiv.org/abs/2403.03334) | 本文提出了一个名为DIVERSE的数据集，其中包含超过173,000条YouTube视频评论，标注了这些评论对美国军事视频的立场，采用了一种通过人类引导、机器辅助的标注方法，使用了句子中的弱信号作为支持指标。 |
| [^49] | [Guardrail Baselines for Unlearning in LLMs](https://arxiv.org/abs/2403.03329) | 简单的基于guardrail的方法如提示和过滤可以实现与fine-tuning相媲美的unlearning结果，建议研究人员在评估更消耗计算资源的fine-tuning方法时考虑这些轻量级基线。 |
| [^50] | [Book2Dial: Generating Teacher-Student Interactions from Textbooks for Cost-Effective Development of Educational Chatbots](https://arxiv.org/abs/2403.03307) | 本文提出了一个基于教科书生成合成教师-学生互动的框架，用于开发教育聊天机器人，展示了使用合成对话训练教育聊天机器人的好处，并比较了几种方法，但最佳数据综合方法仍存在幻觉和重复信息问题。 |
| [^51] | [Best of Both Worlds: A Pliable and Generalizable Neuro-Symbolic Approach for Relation Classification](https://arxiv.org/abs/2403.03305) | 该论文介绍了一种将基于规则的方法与深度学习技术相结合的神经符号架构，通过神经组件提升规则泛化能力，实现了两种范式的优势，且在少样本关系分类数据集上取得了优于之前最先进模型的表现 |
| [^52] | [Mad Libs Are All You Need: Augmenting Cross-Domain Document-Level Event Argument Data](https://arxiv.org/abs/2403.03304) | Mad Libs 提供的数据增强方法 MLA 在跨领域文档级事件参数数据提取上取得了显著的性能提升，平均提高了 2.6 个 F1 分数。同时，在零和少样本事件角色方面相比无增强基线，提高了 3.9 和 5.2 个百分点。 |
| [^53] | [Benchmarking the Text-to-SQL Capability of Large Language Models: A Comprehensive Evaluation](https://arxiv.org/abs/2403.02951) | 大型语言模型在文本生成SQL任务中表现出色，但对于最佳提示模板和设计框架仍无共识，新数据集和评估任务有助于全面评估各种方法的表现，并提出了优化解决方案。 |
| [^54] | [OffLanDat: A Community Based Implicit Offensive Language Dataset Generated by Large Language Model Through Prompt Engineering](https://arxiv.org/abs/2403.02472) | 介绍了一个通过提示工程生成的大型语言模型创建的社区基础隐式攻击性语言数据集OffLanDat，为38个不同目标群体提供数据。 |
| [^55] | [NeuroVoz: a Castillian Spanish corpus of parkinsonian speech](https://arxiv.org/abs/2403.02371) | 这一研究提出了一个包含108位母语为卡斯蒂利亚语说话者的帕金森病患者语音语料库，涵盖了多种语音任务，通过手动和自动转录确保了数据的准确性和可靠性。 |
| [^56] | [Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Match Human Crowd Accuracy](https://arxiv.org/abs/2402.19379) | 该研究通过将十二个LLMs组成的LLM集成方法与925名人类预测者的群体预测进行比较，发现LLM群体优于简单的无信息基准，并在统计上等效于人类群体。 |
| [^57] | [Arithmetic Control of LLMs for Diverse User Preferences: Directional Preference Alignment with Multi-Objective Rewards](https://arxiv.org/abs/2402.18571) | 提出了方向偏好对齐（DPA）框架，通过多目标奖励模拟不同偏好配置，以实现用户相关的偏好控制。 |
| [^58] | [On the use of Silver Standard Data for Zero-shot Classification Tasks in Information Extraction](https://arxiv.org/abs/2402.18061) | 本研究提出了一个新框架Clean-LaVe，旨在利用银标准数据来增强零样本分类性能。 |
| [^59] | [GraphWiz: An Instruction-Following Language Model for Graph Problems](https://arxiv.org/abs/2402.16029) | GraphWiz是一个开源语言模型，通过引入指令调优数据集和直接偏好优化框架，能够高效解决各种图问题类型，平均准确率达到65%，超过了GPT-4的43.8%。 |
| [^60] | [Noise-BERT: A Unified Perturbation-Robust Framework with Noise Alignment Pre-training for Noisy Slot Filling Task](https://arxiv.org/abs/2402.14494) | 提出了Noise-BERT框架，包含噪声对齐预训练任务，通过对比学习损失和对抗攻击训练策略，以提高在嘈杂环境下的槽填充任务表现。 |
| [^61] | [$\texttt{Se}^2$: $\textit{Se}$quential Example $\textit{Se}$lection for In-Context Learning](https://arxiv.org/abs/2402.13874) | 本文提出了$\texttt{Se}^2$，一种顺序感知方法，利用大型语言模型的反馈帮助捕捉示例之间的相互关系和序列信息，显著丰富了上下文学习提示的相关性和相关性。 |
| [^62] | [GUARD: Role-playing to Generate Natural-language Jailbreakings to Test Guideline Adherence of Large Language Models](https://arxiv.org/abs/2402.03299) | 本论文提出了一个通过角色扮演的系统，可以生成自然语言越狱，用于测试大型语言模型的指南遵循情况。系统通过收集现有越狱并将其组织成知识图来生成新的越狱，证明了其高效性和有效性。 |
| [^63] | [English Prompts are Better for NLI-based Zero-Shot Emotion Classification than Target-Language Prompts](https://arxiv.org/abs/2402.03223) | 本研究填补了一个研究空白，探讨了在非英文文本中应该使用哪种语言来提示情绪标签。 |
| [^64] | [Integration of cognitive tasks into artificial general intelligence test for large models](https://arxiv.org/abs/2402.02547) | 建议将认知任务整合到大型模型的人工通用智能测试中，以建立一个综合框架，能够评估大型模型的多维智能。这个框架结合了认知科学和自然语言处理，包含了稳态智力、流态智力和社交智能等方面。 |
| [^65] | [LOCOST: State-Space Models for Long Document Abstractive Summarization](https://arxiv.org/abs/2401.17919) | LOCOST是一种基于状态空间模型的编码器-解码器架构，用于处理长文档的抽象摘要生成。与基于稀疏注意模式的最先进模型相比，LOCOST具有更低的计算复杂度，并且能够在训练和推断期间节省大量内存。在评估中，LOCOST在长文档摘要化任务上达到了93-96%的性能水平，并且能够处理超过600K个标记的输入文本。 |
| [^66] | [MedLM: Exploring Language Models for Medical Question Answering Systems](https://arxiv.org/abs/2401.11389) | 本研究比较了用于医疗问答的通用和医学特定的精炼语言模型的表现，以填补领域特定任务中这些模型性能的研究空白。 |
| [^67] | [SceneVerse: Scaling 3D Vision-Language Learning for Grounded Scene Understanding](https://arxiv.org/abs/2401.09340) | 本研究通过系统性地扩展室内环境中的3D视觉-语言学习，提出了首个百万规模的3D视觉-语言数据集SceneVerse，以解决3D视觉-语言对齐面临的几个重要挑战。 |
| [^68] | [Benchmarking and Defending Against Indirect Prompt Injection Attacks on Large Language Models](https://arxiv.org/abs/2312.14197) | 该研究引入了第一个间接提示注入攻击基准测试BIPIA，对大型语言模型在面对此类攻击时的风险进行评估，并分析了攻击成功的原因，从而开发了防御方法。 |
| [^69] | [Controlled Text Generation via Language Model Arithmetic](https://arxiv.org/abs/2311.14479) | 该论文提出了一种模型算术推断框架，可以在不重新训练模型或使用高度特定数据集的情况下构成和偏置大型语言模型，实现比直接提示和先前受控文本生成技术更精确的文本生成控制。 |
| [^70] | [AdaCCD: Adaptive Semantic Contrasts Discovery Based Cross Lingual Adaptation for Code Clone Detection](https://arxiv.org/abs/2311.07277) | AdaCCD是一种跨语言适应方法，通过自适应的对比学习框架和预训练编程语言模型提取语言无关的代码表示，实现了在没有目标语言注释的情况下检测新语言中的克隆代码。 |
| [^71] | [What's In My Big Data?](https://arxiv.org/abs/2310.20707) | 通过提出的平台和分析方法，我们揭示和比较了大型文本语料库的内容，发现了关于语料库内容的几个令人惊讶且以前未被记录的发现。 |
| [^72] | [LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay](https://arxiv.org/abs/2310.14985) | 本文提出了一个新颖的框架，旨在无缝适应Avalon游戏，通过多智能体系统实现了有效的沟通和互动，评估了智能体的性能和社会行为，展示了LLM智能体在游戏中具有潜力。 |
| [^73] | [Chat Vector: A Simple Approach to Equip LLMs with Instruction Following and Model Alignment in New Languages](https://arxiv.org/abs/2310.04799) | 提出了聊天向量的概念，通过简单的模型算术使预训练语言模型具备在新语言中遵循指令和实现模型对齐的能力 |
| [^74] | [Prompting and Fine-Tuning Open-Sourced Large Language Models for Stance Classification](https://arxiv.org/abs/2309.13734) | 本研究探讨了使用大型语言模型作为立场检测方法以减少手动注释的需求，发现它们与域内监督模型具有竞争力，但性能不一致。 |
| [^75] | [SelectLLM: Can LLMs Select Important Instructions to Annotate?.](http://arxiv.org/abs/2401.16553) | 这项工作提出了一种名为SelectLLM的新方法，利用LLMs选择高质量指令。通过提示LLMs估计每个无标签指令的有用性和影响力，并使用聚类算法将指令分为多个聚类。 |
| [^76] | [Q&A Prompts: Discovering Rich Visual Clues through Mining Question-Answer Prompts for VQA requiring Diverse World Knowledge.](http://arxiv.org/abs/2401.10712) | 本论文提出了一种叫做Q&A提示的方法，通过挖掘图像中的问题-回答对来发现丰富的视觉线索，以帮助AI模型更好地理解复杂视觉问题，提高跨模态推理能力。 |
| [^77] | [DevEval: Evaluating Code Generation in Practical Software Projects.](http://arxiv.org/abs/2401.06401) | 本文提出了一个名为DevEval的新基准测试，用于评估实际软件项目中的代码生成。与之前的基准测试相比，DevEval在真实的项目分布、充足的依赖和足够规模的项目背景等方面更贴合实际。通过对五个流行的大型语言模型进行评估，我们揭示了它们在代码生成中的实际能力。 |
| [^78] | [GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction.](http://arxiv.org/abs/2310.03668) | GoLLIE 是一个遵循注释指南的大型语言模型，通过微调以改进未见信息抽取任务的零样本结果。 |
| [^79] | [OATS: Opinion Aspect Target Sentiment Quadruple Extraction Dataset for Aspect-Based Sentiment Analysis.](http://arxiv.org/abs/2309.13297) | OATS数据集是一个全新的观点方面目标情感四元组抽取数据集，它解决了面向方面的情感分析中的领域限制和数据粒度挑战，并填补了餐馆和笔记本电脑等常见领域的数据不足和句子与评论级情感之间的协同作用问题。 |
| [^80] | [Towards Grounded Visual Spatial Reasoning in Multi-Modal Vision Language Models.](http://arxiv.org/abs/2308.09778) | 本文旨在研究多模态视觉语言模型在理解空间关系方面的能力，提出了细粒度组合的空间关系基础，并采用自底向上的方法评估空间关系推理任务的性能。 |
| [^81] | [Arithmetic with Language Models: from Memorization to Computation.](http://arxiv.org/abs/2308.01154) | 本研究探索了使用语言模型进行算术计算的能力，发现语言模型可以通过内部的值空间进行计算，并取得了成功的实验结果。 |
| [^82] | [Interpretable Stereotype Identification through Reasoning.](http://arxiv.org/abs/2308.00071) | 本研究通过使用推理方法，在零射击刻板印象识别中取得了重要的进展，并发现推理的性能增益远远超过模型规模扩展的增益。推理不仅提高了准确性，还提高了决策的可解释性。 |
| [^83] | [BERTTM: Leveraging Contextualized Word Embeddings from Pre-trained Language Models for Neural Topic Modeling.](http://arxiv.org/abs/2305.09329) | 本文提出了一种新颖的神经主题模型，利用来自预训练语言模型BERT的上下文化词嵌入，可以在不使用任何BoW信息的情况下推断出文档的主题分布，并直接从上下文化词嵌入中推断出文档中每个单词的主题分布。实验结果表明，该模型优于仅依赖BoW表示和其他神经主题模型的现有最先进方法。 |
| [^84] | [SIFT: Sparse Iso-FLOP Transformations for Maximizing Training Efficiency.](http://arxiv.org/abs/2303.11525) | 本研究提出了一种名为SIFT的方法，用于提高深度神经网络的训练效率、准确性和表示能力，通过稀疏等FLOP转换，缩短训练时间。 |
| [^85] | [Application of Quantum Density Matrix in Classical Question Answering and Classical Image Classification.](http://arxiv.org/abs/2203.11155) | 该论文将量子密度矩阵应用于经典问答和图像分类中，证明了其可以提高任务的效率，尤其在图像分类中取得了优秀的性能表现。 |

# 详细

[^1]: 回溯：检索查询原因

    Backtracing: Retrieving the Cause of the Query

    [https://arxiv.org/abs/2403.03956](https://arxiv.org/abs/2403.03956)

    引入了回溯任务，通过检索文本段来确定引发用户查询的原因，涉及到不同领域，包括讲座、新闻和对话，评估了零次性能。

    

    许多在线内容门户允许用户提出问题以补充他们的理解（例如，对讲座的理解）。虽然信息检索（IR）系统可以为这类用户查询提供答案，但它们并不直接帮助内容创建者（如希望改进内容的讲师）识别引发用户提出这些问题的段落。我们引入了回溯任务，系统检索出最有可能引发用户查询的文本段。我们对提高内容传递和沟通中重要的回溯任务进行了三个现实世界领域的形式化：（a）讲座领域中学生困惑的原因，（b）新闻文章领域中读者好奇心的原因，以及（c）对话领域中用户情绪的原因。我们评估了流行的信息检索方法和语言建模方法的零次性能，包括双编码器、重新排序和基于可能性的方法。

    arXiv:2403.03956v1 Announce Type: cross  Abstract: Many online content portals allow users to ask questions to supplement their understanding (e.g., of lectures). While information retrieval (IR) systems may provide answers for such user queries, they do not directly assist content creators -- such as lecturers who want to improve their content -- identify segments that _caused_ a user to ask those questions. We introduce the task of backtracing, in which systems retrieve the text segment that most likely caused a user query. We formalize three real-world domains for which backtracing is important in improving content delivery and communication: understanding the cause of (a) student confusion in the Lecture domain, (b) reader curiosity in the News Article domain, and (c) user emotion in the Conversation domain. We evaluate the zero-shot performance of popular information retrieval methods and language modeling methods, including bi-encoder, re-ranking and likelihood-based methods and 
    
[^2]: 《启发式核心：理解预训练语言模型中的子网络泛化》

    The Heuristic Core: Understanding Subnetwork Generalization in Pretrained Language Models

    [https://arxiv.org/abs/2403.03942](https://arxiv.org/abs/2403.03942)

    在预训练语言模型中，发现所有子网络都共享一个注意力头集合，被称为启发式核心，这可能是造成子网络泛化差异的原因。

    

    先前的研究发现，经过不同随机种子微调的预训练语言模型（LMs）可以实现类似的领域内性能，但在句法泛化测试中泛化不同。在这项工作中，我们展示出即使在单一模型内部，我们也可以找到执行类似领域内操作但泛化差异巨大的多个子网络。为了更好地理解这些现象，我们调查是否可以用“竞争性子网络”来理解它们：模型最初表示各种不同算法，对应于不同的子网络，当最终收敛到其中一个时泛化发生。这一解释已被用于解释简单算法任务中的泛化。我们发现，并非找到竞争性子网络，而是所有子网络 -- 无论它们是否泛化 -- 都共享一组注意力头，我们将其称为启发式核心。进一步分析表明，它可能是造成不同子网络泛化的原因。

    arXiv:2403.03942v1 Announce Type: new  Abstract: Prior work has found that pretrained language models (LMs) fine-tuned with different random seeds can achieve similar in-domain performance but generalize differently on tests of syntactic generalization. In this work, we show that, even within a single model, we can find multiple subnetworks that perform similarly in-domain, but generalize vastly differently. To better understand these phenomena, we investigate if they can be understood in terms of "competing subnetworks": the model initially represents a variety of distinct algorithms, corresponding to different subnetworks, and generalization occurs when it ultimately converges to one. This explanation has been used to account for generalization in simple algorithmic tasks. Instead of finding competing subnetworks, we find that all subnetworks -- whether they generalize or not -- share a set of attention heads, which we refer to as the heuristic core. Further analysis suggests that th
    
[^3]: 翻译模型是否在无人发觉的情况下变得更加稳健了？

    Did Translation Models Get More Robust Without Anyone Even Noticing?

    [https://arxiv.org/abs/2403.03923](https://arxiv.org/abs/2403.03923)

    最近的研究表明，新的多语言机器翻译模型和大型语言模型在面对各种噪声输入时比先前的模型更加稳健，尽管它们的参数更多、训练过程更复杂，并且没有采用特定设计用于增强稳健性的技术。

    

    神经机器翻译（MT）模型在各种场景中取得了强大的结果，但普遍认为它们对"嘈杂"输入（如拼写错误、缩写和其他格式问题）非常敏感。本文针对最近的多语言MT模型和应用于机器翻译的大型语言模型（LLMs），重新审视这一观点。有些令人惊讶的是，我们通过受控实验表明，这些模型对许多种噪声比先前的模型更加稳健，即使在干净数据上表现类似。这很引人注目，因为尽管LLMs拥有比过去模型更多的参数和更复杂的训练过程，我们考虑的开源模型中没有一个使用任何专门设计的鼓励稳健性的技术。接下来，我们展示类似的趋势也适用于社交媒体翻译实验——LLMs对社交媒体文本更加稳健。我们还包括了一项关于......

    arXiv:2403.03923v1 Announce Type: new  Abstract: Neural machine translation (MT) models achieve strong results across a variety of settings, but it is widely believed that they are highly sensitive to "noisy" inputs, such as spelling errors, abbreviations, and other formatting issues. In this paper, we revisit this insight in light of recent multilingual MT models and large language models (LLMs) applied to machine translation. Somewhat surprisingly, we show through controlled experiments that these models are far more robust to many kinds of noise than previous models, even when they perform similarly on clean data. This is notable because, even though LLMs have more parameters and more complex training processes than past models, none of the open ones we consider use any techniques specifically designed to encourage robustness. Next, we show that similar trends hold for social media translation experiments -- LLMs are more robust to social media text. We include an analysis of the ci
    
[^4]: 提升教学质量：利用计算机辅助文本分析从教育文献中生成深入见解

    Enhancing Instructional Quality: Leveraging Computer-Assisted Textual Analysis to Generate In-Depth Insights from Educational Artifacts

    [https://arxiv.org/abs/2403.03920](https://arxiv.org/abs/2403.03920)

    通过计算机辅助文本分析，本文揭示了人工智能和机器学习方法在教学质量提升中的重要作用，为教育工作者提供了深入见解和可操作的反馈。

    

    本文探讨了计算机辅助文本分析在通过教育文献提供深入见解以提升教学质量中的变革潜力。我们整合了理查德·埃尔莫尔的教学核心框架来研究人工智能（AI）和机器学习（ML）方法，尤其是自然语言处理（NLP），可以分析教育内容、教师话语和学生回应以促进教学改进。通过对教学核心框架内的综合评论和案例研究，我们确定了AI/ML整合提供显著优势的关键领域，包括教师辅导、学生支持和内容开发。我们揭示出的模式表明，AI/ML 不仅简化了行政任务，还为个性化学习开辟了新途径，为教育工作者提供可操作的反馈，并有助于更深入地理解教学。

    arXiv:2403.03920v1 Announce Type: new  Abstract: This paper explores the transformative potential of computer-assisted textual analysis in enhancing instructional quality through in-depth insights from educational artifacts. We integrate Richard Elmore's Instructional Core Framework to examine how artificial intelligence (AI) and machine learning (ML) methods, particularly natural language processing (NLP), can analyze educational content, teacher discourse, and student responses to foster instructional improvement. Through a comprehensive review and case studies within the Instructional Core Framework, we identify key areas where AI/ML integration offers significant advantages, including teacher coaching, student support, and content development. We unveil patterns that indicate AI/ML not only streamlines administrative tasks but also introduces novel pathways for personalized learning, providing actionable feedback for educators and contributing to a richer understanding of instructi
    
[^5]: 用于透明比较多语言自然语言处理数据集语言多样性的度量方法

    A Measure for Transparent Comparison of Linguistic Diversity in Multilingual NLP Data Sets

    [https://arxiv.org/abs/2403.03909](https://arxiv.org/abs/2403.03909)

    本文提出了一种评估数据集语言多样性的方法，通过与参考语言样本进行对比，利用适合比较度量集合的Jaccard指数的版本来最大程度地促进长期内的多语言多样性。

    

    类型学多样化的基准越来越多地被创建来追踪多语言自然语言处理中取得的进展。这些数据集的语言多样性通常被测量为样本中包含的语言或语言家族的数量，但这些度量并未考虑所包含语言的结构特性。在本文中，我们提出将数据集的语言多样性与参考语言样本进行评估，作为最大程度地促进长期内的语言多样性的一种方式。我们将语言表示为特征集，并应用适用于比较度量集合的Jaccard指数的版本。除了从类型学数据库中提取的特征之外，我们还提出一种自动的基于文本的度量方法，可以作为克服手动收集特征中已知的数据稀疏问题的手段。我们的多样性评分在语言特征方面是可解释的，并且可以识别语言类型

    arXiv:2403.03909v1 Announce Type: new  Abstract: Typologically diverse benchmarks are increasingly created to track the progress achieved in multilingual NLP. Linguistic diversity of these data sets is typically measured as the number of languages or language families included in the sample, but such measures do not consider structural properties of the included languages. In this paper, we propose assessing linguistic diversity of a data set against a reference language sample as a means of maximising linguistic diversity in the long run. We represent languages as sets of features and apply a version of the Jaccard index suitable for comparing sets of measures. In addition to the features extracted from typological data bases, we propose an automatic text-based measure, which can be used as a means of overcoming the well-known problem of data sparsity in manually collected features. Our diversity score is interpretable in terms of linguistic features and can identify the types of lang
    
[^6]: IRCoder: 中间表示使语言模型成为稳健的多语言代码生成器

    IRCoder: Intermediate Representations Make Language Models Robust Multilingual Code Generators

    [https://arxiv.org/abs/2403.03894](https://arxiv.org/abs/2403.03894)

    通过利用编译器中间表示来改进代码-LMs的多语言能力和促进跨语言转移。

    

    arXiv:2403.03894v1 公告类型: 新的 摘要: 代码理解和生成已迅速成为语言模型（LMs）最受欢迎的应用之一。然而，与自然语言LM的研究相比，对代码-LMs（即用于代码生成的LMs）的多语言方面的研究，如不同编程语言之间的跨语言转移，特定于语言的数据增强以及事后LM调整，以及利用原始文本内容之外的数据源，要稀少得多。特别是，大多数主流代码-LMs仅在源代码文件上进行了预训练。在这项工作中，我们研究了利用现成的编译器中间表示（跨编程语言共享）来改进代码-LMs的多语言能力并促进跨语言转移的前景。为此，我们首先编制了SLTrans，一个由近400万个自包含源代码文件组成的并行数据集。

    arXiv:2403.03894v1 Announce Type: new  Abstract: Code understanding and generation have fast become some of the most popular applications of language models (LMs). Nonetheless, research on multilingual aspects of Code-LMs (i.e., LMs for code generation) such as cross-lingual transfer between different programming languages, language-specific data augmentation, and post-hoc LM adaptation, alongside exploitation of data sources other than the original textual content, has been much sparser than for their natural language counterparts. In particular, most mainstream Code-LMs have been pre-trained on source code files alone. In this work, we investigate the prospect of leveraging readily available compiler intermediate representations - shared across programming languages - to improve the multilingual capabilities of Code-LMs and facilitate cross-lingual transfer.   To this end, we first compile SLTrans, a parallel dataset consisting of nearly 4M self-contained source code files coupled wi
    
[^7]: 从单一到多样：拓展语言模型中毒性缓解的范围

    From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models

    [https://arxiv.org/abs/2403.03893](https://arxiv.org/abs/2403.03893)

    该研究拓展了语言模型中毒性缓解的范围，涵盖了多语言环境，通过翻译数据评估和增强缓解技术，比较了不同缓解方法，并探讨了模型大小和数据量对缓解效果的影响。

    

    迄今为止，语言模型中的毒性缓解几乎完全集中在单语言环境中。随着语言模型拥抱多语言能力，我们的安全措施跟上步伐至关重要。我们意识到了这一研究空白，我们的方法将传统的毒性缓解范围扩展到应对多语言带来的复杂性。在缺乏跨语言的足够标注数据集的情况下，我们使用翻译数据来评估和增强我们的缓解技术。我们还在静态和持续毒性缓解场景下比较了微调缓解方法和检索增强技术。这使我们能够检验翻译质量和跨语言转移对毒性缓解的影响。我们还探讨了模型大小和数据数量如何影响这些缓解工作的成功。涵盖了九种语言，我们的研究代表了广泛的语言学领域。

    arXiv:2403.03893v1 Announce Type: cross  Abstract: To date, toxicity mitigation in language models has almost entirely been focused on single-language settings. As language models embrace multilingual capabilities, it's crucial our safety measures keep pace. Recognizing this research gap, our approach expands the scope of conventional toxicity mitigation to address the complexities presented by multiple languages. In the absence of sufficient annotated datasets across languages, we employ translated data to evaluate and enhance our mitigation techniques. We also compare finetuning mitigation approaches against retrieval-augmented techniques under both static and continual toxicity mitigation scenarios. This allows us to examine the effects of translation quality and the cross-lingual transfer on toxicity mitigation. We also explore how model size and data quantity affect the success of these mitigation efforts. Covering nine languages, our study represents a broad array of linguistic f
    
[^8]: FaaF：作为RAG系统评估的事实函数

    FaaF: Facts as a Function for the evaluation of RAG systems

    [https://arxiv.org/abs/2403.03888](https://arxiv.org/abs/2403.03888)

    FaaF是一种新的事实验证方法，利用语言模型的函数调用能力和面向RAG事实回忆评估的框架，显着提高了LM识别不支持事实的能力，并在效率和成本方面取得了明显的改进。

    

    从参考资料中准确提取事实对于评估检索增强生成（RAG）系统的性能至关重要，因为它直接探查了检索和生成的质量。然而，可靠高效地执行这种评估仍然是一个挑战。最近的工作侧重于通过提示语言模型（LM）评估器进行事实验证，然而我们证明，在信息不完整或不准确的情况下，这些方法是不可靠的。我们引入了FaaF（Facts as a Function），这是一种利用LM的函数调用能力和面向RAG事实回忆评估的框架的新方法。与基于提示的方法相比，FaaF显着提高了LM识别文本中不支持事实的能力，同时提高了效率，降低了成本几倍。

    arXiv:2403.03888v1 Announce Type: new  Abstract: Factual recall from a reference source is crucial for evaluating the performance of Retrieval Augmented Generation (RAG) systems, as it directly probes into the quality of both retrieval and generation. However, it still remains a challenge to perform this evaluation reliably and efficiently. Recent work has focused on fact verification via prompting language model (LM) evaluators, however we demonstrate that these methods are unreliable in the presence of incomplete or inaccurate information. We introduce Facts as a Function (FaaF), a new approach to fact verification that utilizes the function calling abilities of LMs and a framework for RAG factual recall evaluation. FaaF substantially improves the ability of LMs to identify unsupported facts in text with incomplete information whilst improving efficiency and lowering cost by several times, compared to prompt-based approaches.
    
[^9]: SaulLM-7B: 面向法律领域的开创性大型语言模型

    SaulLM-7B: A pioneering Large Language Model for Law

    [https://arxiv.org/abs/2403.03883](https://arxiv.org/abs/2403.03883)

    SaulLM-7B是首个专为法律文本设计的7B参数LLM，通过InnovativeFine-tuning方法，展现了领先的法律文件理解和处理能力。

    

    本文介绍了SaulLM-7B，一个专为法律领域量身定制的大型语言模型（LLM）。拥有70亿参数的SaulLM-7B是第一个专为法律文本理解和生成而设计的LLM。以Mistral 7B架构为基础，SaulLM-7B在超过300亿标记的英文法律语料库上进行训练。SaulLM-7B在理解和处理法律文件方面表现出最先进的能力。此外，我们提出了一种新颖的指导微调方法，利用法律数据集进一步增强SaulLM-7B在法律任务中的性能。SaulLM-7B采用CC-BY-SA-4.0许可发布。

    arXiv:2403.03883v1 Announce Type: new  Abstract: In this paper, we introduce SaulLM-7B, a large language model (LLM) tailored for the legal domain. With 7 billion parameters, SaulLM-7B is the first LLM designed explicitly for legal text comprehension and generation. Leveraging the Mistral 7B architecture as its foundation, SaulLM-7B is trained on an English legal corpus of over 30 billion tokens. SaulLM-7B exhibits state-of-the-art proficiency in understanding and processing legal documents. Additionally, we present a novel instructional fine-tuning method that leverages legal datasets to further enhance SaulLM-7B's performance in legal tasks. SaulLM-7B is released under the CC-BY-SA-4.0 License.
    
[^10]: 贫困的语言技术：NLP中缺乏（社会）阶级因素

    Impoverished Language Technology: The Lack of (Social) Class in NLP

    [https://arxiv.org/abs/2403.03874](https://arxiv.org/abs/2403.03874)

    该论文探讨了NLP领域中缺乏对社会阶级因素的研究，呼吁研究者在NLP技术中考虑和操作化阶级因素。

    

    自Labov（1964年）关于语言社会层级的基础性工作以来，语言学界致力于理解社会人口因素和语言生产和感知之间的关系。尽管大量证据表明社会人口因素与语言生产之间存在显著关系，但相对较少的因素在NLP技术的背景下得到研究。虽然年龄和性别得到了很好的覆盖，Labov最初关注的社会经济阶级却几乎不被涉及。我们调查了现有的自然语言处理（NLP）文献，并发现只有20篇论文提到了社会经济地位。然而，这些论文中的大部分并没有探讨超出收集注释者人口信息之外的阶级。鉴于这一研究空白，我们提供了一个可以被NLP研究人员操作的阶级定义，并主张包含该因素

    arXiv:2403.03874v1 Announce Type: cross  Abstract: Since Labov's (1964) foundational work on the social stratification of language, linguistics has dedicated concerted efforts towards understanding the relationships between socio-demographic factors and language production and perception. Despite the large body of evidence identifying significant relationships between socio-demographic factors and language production, relatively few of these factors have been investigated in the context of NLP technology. While age and gender are well covered, Labov's initial target, socio-economic class, is largely absent. We survey the existing Natural Language Processing (NLP) literature and find that only 20 papers even mention socio-economic status. However, the majority of those papers do not engage with class beyond collecting information of annotator-demographics. Given this research lacuna, we provide a definition of class that can be operationalised by NLP researchers, and argue for including
    
[^11]: 学习多个语言模型的协作解码方法

    Learning to Decode Collaboratively with Multiple Language Models

    [https://arxiv.org/abs/2403.03870](https://arxiv.org/abs/2403.03870)

    学习了一种协作解码方法，通过在标记级别交错生成来教授多个大型语言模型协作，无需直接监督，在特定任务中融合每个模型的专业知识，提高了联合系统的性能。

    

    我们提出了一种方法，通过在标记级别交错它们的生成来教授多个大型语言模型（LLM）协作。我们将下一个标记由哪个LLM生成的决策建模为潜变量。通过在我们的潜变量模型下优化训练集的边际似然，基础LLM自动学习何时生成自身以及何时调用其中一个“助手”语言模型来生成，而无需直接监督。在解码过程中进行标记级协作允许融合每个模型的专业知识，以符合特定任务的方式。我们的协作解码在跨领域设置中特别有用，其中通用基础LLM学会调用领域专家模型。在执行指令、领域特定问答和推理任务时，我们展示了联合系统的性能优于单独模型。通过对学习到的潜

    arXiv:2403.03870v1 Announce Type: new  Abstract: We propose a method to teach multiple large language models (LLM) to collaborate by interleaving their generations at the token level. We model the decision of which LLM generates the next token as a latent variable. By optimizing the marginal likelihood of a training set under our latent variable model, the base LLM automatically learns when to generate itself and when to call on one of the ``assistant'' language models to generate, all without direct supervision. Token-level collaboration during decoding allows for a fusion of each model's expertise in a manner tailored to the specific task at hand. Our collaborative decoding is especially useful in cross-domain settings where a generalist base LLM learns to invoke domain expert models. On instruction-following, domain-specific QA, and reasoning tasks, we show that the performance of the joint system exceeds that of the individual models. Through qualitative analysis of the learned lat
    
[^12]: 论大型语言模型中线性表示的起源

    On the Origins of Linear Representations in Large Language Models

    [https://arxiv.org/abs/2403.03867](https://arxiv.org/abs/2403.03867)

    本文研究了大型语言模型中线性表示的起源，通过引入简单的潜变量模型，并展示了梯度下降的隐性偏差与下一个标记预测目标共同促进了概念的线性表示。

    

    近期研究表明，大型语言模型的表示空间中编码了高层语义概念是"线性"的。本文研究了这种线性表示的起源。为此，我们引入了一个简单的潜变量模型来抽象和形式化下一个标记预测的概念动态。我们利用这种形式化展示了下一个标记预测目标（具有交叉熵的softmax）和梯度下降的隐性偏差共同促进了概念的线性表示。实验表明，当学习与潜变量模型匹配的数据时，线性表示会出现，从而确认这种简单结构已足以产生线性表示。我们还使用 LLaMA-2 大型语言模型验证了这一理论的部分预测，证明了简化模型提供了可推广的见解。

    arXiv:2403.03867v1 Announce Type: new  Abstract: Recent works have argued that high-level semantic concepts are encoded "linearly" in the representation space of large language models. In this work, we study the origins of such linear representations. To that end, we introduce a simple latent variable model to abstract and formalize the concept dynamics of the next token prediction. We use this formalism to show that the next token prediction objective (softmax with cross-entropy) and the implicit bias of gradient descent together promote the linear representation of concepts. Experiments show that linear representations emerge when learning from data matching the latent variable model, confirming that this simple structure already suffices to yield linear representations. We additionally confirm some predictions of the theory using the LLaMA-2 large language model, giving evidence that the simplified model yields generalizable insights.
    
[^13]: KIWI：用于回答研究问题的知识密集型写作指南数据集

    KIWI: A Dataset of Knowledge-Intensive Writing Instructions for Answering Research Questions

    [https://arxiv.org/abs/2403.03866](https://arxiv.org/abs/2403.03866)

    该论文介绍了一个名为KIWI的数据集，用于评估大型语言模型在提供科学写作帮助时的能力，发现这些模型在整合新信息到现有答案中存在困难。

    

    arXiv:2403.03866v1 公告类型：新的 摘要：大型语言模型（LLMs）已经被调整以遵循用户指令，并广泛部署为会话代理。在这项工作中，我们研究了一个越来越常见的指令跟随任务：提供写作帮助以撰写长篇答案。为了评估当前LLMs在这项任务上的能力，我们构建了一个在科学领域中包含知识密集型写作指南的数据集KIWI。给定一个研究问题，一个初始模型生成的答案和一组相关论文，一个专家注释者会迭代地发布指导模型修订和改进答案的指令。我们从与三个最先进的LLMs的234个交互会话中收集了1,260个交互轮次。每个轮次包括用户指令、模型回应和对模型回应的人工评估。通过对收集到的回应进行详细分析，我们发现所有模型都难以将新信息整合到现有答案中，

    arXiv:2403.03866v1 Announce Type: new  Abstract: Large language models (LLMs) adapted to follow user instructions are now widely deployed as conversational agents. In this work, we examine one increasingly common instruction-following task: providing writing assistance to compose a long-form answer. To evaluate the capabilities of current LLMs on this task, we construct KIWI, a dataset of knowledge-intensive writing instructions in the scientific domain. Given a research question, an initial model-generated answer and a set of relevant papers, an expert annotator iteratively issues instructions for the model to revise and improve its answer. We collect 1,260 interaction turns from 234 interaction sessions with three state-of-the-art LLMs. Each turn includes a user instruction, a model response, and a human evaluation of the model response. Through a detailed analysis of the collected responses, we find that all models struggle to incorporate new information into an existing answer, and
    
[^14]: X-Shot: 一个统一的系统，同时处理分类中的频繁、少样本和零样本学习

    X-Shot: A Unified System to Handle Frequent, Few-shot and Zero-shot Learning Simultaneously in Classification

    [https://arxiv.org/abs/2403.03863](https://arxiv.org/abs/2403.03863)

    X-Shot 提出了一个新的分类挑战，旨在在实际环境中同时处理频繁、少样本和零样本标签，系统需要能够适应任何标签出现频率。

    

    近年来，少样本和零样本学习引起了人们的极大关注，传统方法通常将频繁出现、少样本和零样本学习视为不同的挑战，仅为其中一种情况优化系统。然而，在真实世界的环境中，标签出现的频率差异很大。为了实现实际部署，关键在于系统能够适应任何标签出现。我们引入了一个新颖的分类挑战：X-shot，反映了一个实际环境，其中频繁出现、少样本和零样本标签在没有预定义限制的情况下共同出现。在这里，X可以从0到正无穷大。X-shot的关键在于开放领域泛化和设计一个足够灵活的系统来管理各种标签情景。

    arXiv:2403.03863v1 Announce Type: new  Abstract: In recent years, few-shot and zero-shot learning, which learn to predict labels with limited annotated instances, have garnered significant attention. Traditional approaches often treat frequent-shot (freq-shot; labels with abundant instances), few-shot, and zero-shot learning as distinct challenges, optimizing systems for just one of these scenarios. Yet, in real-world settings, label occurrences vary greatly. Some of them might appear thousands of times, while others might only appear sporadically or not at all. For practical deployment, it is crucial that a system can adapt to any label occurrence. We introduce a novel classification challenge: X-shot, reflecting a real-world context where freq-shot, few-shot, and zero-shot labels co-occur without predefined limits. Here, X can span from 0 to positive infinity. The crux of X-shot centers on open-domain generalization and devising a system versatile enough to manage various label scena
    
[^15]: 为少样本示例选择设计信息度量

    Designing Informative Metrics for Few-Shot Example Selection

    [https://arxiv.org/abs/2403.03861](https://arxiv.org/abs/2403.03861)

    提出了一种基于复杂度的提示选择方法，用于将示例与测试句子的句法-语义复杂度对齐，在少样本NER任务中取得了显著的性能提升。

    

    预训练语言模型（PLMs）在提供适当格式的示例时展现出了卓越的少样本学习能力。然而，选择“最佳”示例仍然是一个未解决的挑战。我们提出了一种基于复杂度的提示选择方法，适用于序列标注任务。该方法避免了训练一个专门用于选择示例的模型，而是使用特定的度量标准来对齐测试句子和示例的句法-语义复杂度。我们使用句子和单词级别的度量标准，将示例的复杂度与考虑中的（测试）句子进行匹配。我们的结果表明，我们的方法能够从PLMs中提取出更好的性能：在少样本NER上实现了最先进的性能，在CoNLL2003数据集上对GPT-4的F1分数实现了5%的绝对改善。我们还在像GPT-j-6B这样的较小模型中看到了高达28.85个点（F1/Acc.）的显著增益。

    arXiv:2403.03861v1 Announce Type: new  Abstract: Pretrained language models (PLMs) have shown remarkable few-shot learning capabilities when provided with properly formatted examples. However, selecting the "best" examples remains an open challenge. We propose a complexity-based prompt selection approach for sequence tagging tasks. This approach avoids the training of a dedicated model for selection of examples, and instead uses certain metrics to align the syntactico-semantic complexity of test sentences and examples. We use both sentence- and word-level metrics to match the complexity of examples to the (test) sentence being considered. Our results demonstrate that our approach extracts greater performance from PLMs: it achieves state-of-the-art performance on few-shot NER, achieving a 5% absolute improvement in F1 score on the CoNLL2003 dataset for GPT-4. We also see large gains of upto 28.85 points (F1/Acc.) in smaller models like GPT-j-6B.
    
[^16]: Emojinize：用表情符号丰富任何文本的翻译

    Emojinize : Enriching Any Text with Emoji Translations

    [https://arxiv.org/abs/2403.03857](https://arxiv.org/abs/2403.03857)

    Emojinize 是一种方法，能够通过大型语言模型选择适当的表情符号翻译文本，提高猜测性，人类猜测可达55％。

    

    Emoji已经成为书面交流中无处不在的存在，在网络上和更远的地方。它们可以强调或澄清情绪，为对话增添细节，或者简单地起装饰作用。然而，这种随意使用仅仅是表情符号表达能力的冰山一角。为了进一步释放这种力量，我们提出了Emojinize，一种将任意文本短语翻译成一个或多个表情符号序列的方法，而无需人类输入。通过利用大型语言模型的能力，Emojinize可以根据上下文（例如，板球-球棒vs蝙蝠）消除歧义地选择适当的表情符号，并通过组合多个表情符号（例如，“Emojinize”被翻译成输入-拉丁文字母-右箭头-笑脸）来组合表达复杂概念。在基于填空测试的用户研究中，我们表明Emojinize的表情符号翻译可以使掩盖的单词的猜测性增加55％，而人类选择的表情符号翻译只能增加29％。

    arXiv:2403.03857v1 Announce Type: new  Abstract: Emoji have become ubiquitous in written communication, on the Web and beyond. They can emphasize or clarify emotions, add details to conversations, or simply serve decorative purposes. This casual use, however, barely scratches the surface of the expressive power of emoji. To further unleash this power, we present Emojinize, a method for translating arbitrary text phrases into sequences of one or more emoji without requiring human input. By leveraging the power of large language models, Emojinize can choose appropriate emoji by disambiguating based on context (eg, cricket-bat vs bat) and can express complex concepts compositionally by combining multiple emoji (eq, ''Emojinize'' is translated to input-latin-letters right-arrow grinning-face). In a cloze test--based user study, we show that Emojinize's emoji translations increase the human guessability of masked words by 55%, whereas human-picked emoji translations do so by only 29%. These
    
[^17]: ShortGPT: 大语言模型中的层级比您想象的更冗余

    ShortGPT: Layers in Large Language Models are More Redundant Than You Expect

    [https://arxiv.org/abs/2403.03853](https://arxiv.org/abs/2403.03853)

    大语言模型中的层级存在较高相似性，有些层对网络功能几乎无影响。研究提出一种称为区块影响的度量，并通过层删除方法显著优于以往的模型修剪方法。

    

    随着大语言模型（LLMs）在性能上不断取得进展，其规模显著增加，当前的LLMs包含数十亿甚至数万亿个参数。然而，在这项研究中，我们发现许多LLMs的层之间存在高度相似性，并且一些层在网络功能中起到了可忽略的作用。基于这一观察，我们定义了一种称为区块影响（BI）的度量衡量LLMs中每个层的重要性。然后，我们提出了一种简单的修剪方法：层删除，即根据它们的BI得分直接删除LLMs中的冗余层。实验证明，我们的方法ShortGPT在模型修剪方面明显优于以往的最先进方法。此外，ShortGPT与量化等方法正交，可以进一步减少参数和计算。通过简单的层删除即可获得更好的结果的能力，与传统的精确修剪方法截然不同。

    arXiv:2403.03853v1 Announce Type: new  Abstract: As Large Language Models (LLMs) continue to advance in performance, their size has escalated significantly, with current LLMs containing billions or even trillions of parameters. However, in this study, we discovered that many layers of LLMs exhibit high similarity, and some layers play a negligible role in network functionality. Based on this observation, we define a metric called Block Influence (BI) to gauge the significance of each layer in LLMs. We then propose a straightforward pruning approach: layer removal, in which we directly delete the redundant layers in LLMs based on their BI scores. Experiments demonstrate that our method, which we call ShortGPT, significantly outperforms previous state-of-the-art (SOTA) methods in model pruning. Moreover, ShortGPT is orthogonal to quantization-like methods, enabling further reduction in parameters and computation. The ability to achieve better results through simple layer removal, as oppo
    
[^18]: 一种用于多模态电视节目摘要的模块化方法

    A Modular Approach for Multimodal Summarization of TV Shows

    [https://arxiv.org/abs/2403.03823](https://arxiv.org/abs/2403.03823)

    提出了一种模块化方法用于多模态电视节目摘要，包括检测场景边界、重新排列场景、将视觉信息转换为文本、总结对话以及将场景摘要融合的过程，并引入了一个新的衡量摘要质量的评价指标PREFS。

    

    在本文中，我们讨论了电视节目摘要的任务，涉及到人工智能研究中的关键领域：复杂推理、多模态和长篇叙事。我们提出了一种模块化方法，其中各个组件执行专门的子任务，我们认为与端到端方法相比，这种方法提供了更大的灵活性。我们的模块涉及检测场景边界，重新排列场景以尽量减少不同事件之间的切换次数，将视觉信息转换为文本，总结每个场景中的对话，并将场景摘要融合成整集的最终摘要。我们还提出了一个新的度量标准，PREFS（摘要事实的精确度和召回率评估），用于衡量生成摘要的精确度和召回率，我们将其分解为原子事实。在最近发布的SummScreen3D数据集Papalampidi和Lapata（2023）上进行测试，我们的方法产生了

    arXiv:2403.03823v1 Announce Type: new  Abstract: In this paper we address the task of summarizing television shows, which touches key areas in AI research: complex reasoning, multiple modalities, and long narratives. We present a modular approach where separate components perform specialized sub-tasks which we argue affords greater flexibility compared to end-to-end methods. Our modules involve detecting scene boundaries, reordering scenes so as to minimize the number of cuts between different events, converting visual information to text, summarizing the dialogue in each scene, and fusing the scene summaries into a final summary for the entire episode. We also present a new metric, PREFS (\textbf{P}recision and \textbf{R}ecall \textbf{E}valuation of Summary \textbf{F}act\textbf{s}), to measure both precision and recall of generated summaries, which we decompose into atomic facts. Tested on the recently released SummScreen3D dataset Papalampidi and Lapata (2023), our method produces hi
    
[^19]: 用MultiQ评估大型语言模型的基本多语能力

    Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ

    [https://arxiv.org/abs/2403.03814](https://arxiv.org/abs/2403.03814)

    本研究通过引入MultiQ基准，调查了最先进的开放LLMs在其预期使用范围之外的基本多语能力，发现这些模型对于至少某些语言能够忠实和准确地进行回答。

    

    大型语言模型（LLMs）需要为全球大多数非英语使用者提供服务。然而，大多数LLMs今天，特别是开放的LLMs，通常仅意为在英语（例如Llama2、Mistral）或少数几种高资源语言（例如Mixtral、Qwen）中使用。最近的研究表明，尽管存在使用上的限制，人们会用许多不同的语言提示LLMs。因此，在本文中，我们调查了最先进的开放LLMs在其预期使用范围之外的基本多语能力。为此，我们引入了MultiQ，一个新的用于基本开放式问答的银标准基准，涵盖137种语言的27.4k个测试问题。通过MultiQ，我们评估了语言忠实度，即模型是否以提示的语言回复，以及问题回答准确性。我们测试的所有LLMs对至少某些语言响应得忠实和/或准确。

    arXiv:2403.03814v1 Announce Type: cross  Abstract: Large language models (LLMs) need to serve everyone, including a global majority of non-English speakers. However, most LLMs today, and open LLMs in particular, are often intended for use in just English (e.g. Llama2, Mistral) or a small handful of high-resource languages (e.g. Mixtral, Qwen). Recent research shows that, despite limits in their intended use, people prompt LLMs in many different languages. Therefore, in this paper, we investigate the basic multilingual capabilities of state-of-the-art open LLMs beyond their intended use. For this purpose, we introduce MultiQ, a new silver standard benchmark for basic open-ended question answering with 27.4k test questions across a typologically diverse set of 137 languages. With MultiQ, we evaluate language fidelity, i.e.\ whether models respond in the prompted language, and question answering accuracy. All LLMs we test respond faithfully and/or accurately for at least some languages be
    
[^20]: PPTC-R基准：评估大型语言模型在PowerPoint任务完成中的鲁棒性

    PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion

    [https://arxiv.org/abs/2403.03788](https://arxiv.org/abs/2403.03788)

    提出了PowerPoint任务完成鲁棒性基准（PPTC-R），旨在评估大型语言模型（LLMs）对用户PPT任务指令和软件版本的鲁棒性，发现GPT-4表现最佳。

    

    随着对大型语言模型（LLMs）在完成用户指令方面的日益依赖，有必要全面了解它们在现实世界复杂任务完成中的鲁棒性。为了解决这一关键需求，我们提出了PowerPoint任务完成鲁棒性基准（PPTC-R），以衡量LLMs对用户PPT任务指令和软件版本的鲁棒性。具体而言，我们通过在句子、语义和多语言级别攻击用户指令来构建对抗性用户指令。为了评估语言模型对软件版本的鲁棒性，我们改变提供的API数量以模拟最新版本和早期版本设置。随后，我们使用包含这些鲁棒性设置的基准测试3个闭源和4个开源LLMs，旨在评估偏离如何影响LLMs的API调用以完成任务。我们发现GPT-4表现最佳。

    arXiv:2403.03788v1 Announce Type: new  Abstract: The growing dependence on Large Language Models (LLMs) for finishing user instructions necessitates a comprehensive understanding of their robustness to complex task completion in real-world situations. To address this critical need, we propose the PowerPoint Task Completion Robustness benchmark (PPTC-R) to measure LLMs' robustness to the user PPT task instruction and software version. Specifically, we construct adversarial user instructions by attacking user instructions at sentence, semantic, and multi-language levels. To assess the robustness of Language Models to software versions, we vary the number of provided APIs to simulate both the newest version and earlier version settings. Subsequently, we test 3 closed-source and 4 open-source LLMs using a benchmark that incorporates these robustness settings, aiming to evaluate how deviations impact LLMs' API calls for task completion. We find that GPT-4 exhibits the highest performance an
    
[^21]: 德语也产生幻觉！使用Absinth数据集检测新闻摘要中的不一致性

    German also Hallucinates! Inconsistency Detection in News Summaries with the Absinth Dataset

    [https://arxiv.org/abs/2403.03750](https://arxiv.org/abs/2403.03750)

    本文提出了一个用于德语新闻摘要中幻觉检测的数据集absinth，探讨了LLMs在该任务中的应用。

    

    大型语言模型（LLMs）的出现在自然语言处理任务中取得了显著进展，然而，这些大型模型仍然存在产生信息幻觉的问题，这在自动文本摘要中至关重要。先前的研究主要集中在英语上，并且最近的多语言方法缺乏德语数据。本文提出了absinth，一个用于德语新闻摘要中幻觉检测的手动注释数据集，并探讨了新型开源LLMs在这一任务上的能力，包括微调和上下文学习设置。我们开源并发布了这个数据集。

    arXiv:2403.03750v1 Announce Type: cross  Abstract: The advent of Large Language Models (LLMs) has led to remarkable progress on a wide range of natural language processing tasks. Despite the advances, these large-sized models still suffer from hallucinating information in their output, which poses a major issue in automatic text summarization, as we must guarantee that the generated summary is consistent with the content of the source document. Previous research addresses the challenging task of detecting hallucinations in the output (i.e. inconsistency detection) in order to evaluate the faithfulness of the generated summaries. However, these works primarily focus on English and recent multilingual approaches lack German data. This work presents absinth, a manually annotated dataset for hallucination detection in German news summarization and explores the capabilities of novel open-source LLMs on this task in both fine-tuning and in-context learning settings. We open-source and releas
    
[^22]: 使用Transformer表示的概率主题建模

    Probabilistic Topic Modelling with Transformer Representations

    [https://arxiv.org/abs/2403.03737](https://arxiv.org/abs/2403.03737)

    提出了Transformer-Representation神经主题模型（TNTM），结合了transformer嵌入空间中主题表示的优势和概率建模以及变分自动编码器（VAE）框架，实现了主题建模的强大和多功能性

    

    主题建模在过去的十年中大多由贝叶斯图模型主导。然而，随着Transformer在自然语言处理中的兴起，一些依赖于transformer嵌入空间中简单聚类方法的成功模型已经出现并巩固了主题作为嵌入向量聚类的概念。我们提出了Transformer-Representation神经主题模型（TNTM），结合了transformer嵌入空间中主题表示的优势和概率建模。因此，这种方法将基于transformer嵌入的强大多功能主题概念与完全概率建模统一起来，如Latent Dirichlet Allocation（LDA）等模型。我们利用变分自动编码器（VAE）框架改进推理速度和建模灵活性。实验结果显示我们提出的模型与各种模型达到了类似的结果。

    arXiv:2403.03737v1 Announce Type: cross  Abstract: Topic modelling was mostly dominated by Bayesian graphical models during the last decade. With the rise of transformers in Natural Language Processing, however, several successful models that rely on straightforward clustering approaches in transformer-based embedding spaces have emerged and consolidated the notion of topics as clusters of embedding vectors. We propose the Transformer-Representation Neural Topic Model (TNTM), which combines the benefits of topic representations in transformer-based embedding spaces and probabilistic modelling. Therefore, this approach unifies the powerful and versatile notion of topics based on transformer embeddings with fully probabilistic modelling, as in models such as Latent Dirichlet Allocation (LDA). We utilize the variational autoencoder (VAE) framework for improved inference speed and modelling flexibility. Experimental results show that our proposed model achieves results on par with various 
    
[^23]: 快速开发高质量的指令数据和评估基准，减少人力投入：以日语为例的案例研究

    Rapidly Developing High-quality Instruction Data and Evaluation Benchmark for Large Language Models with Minimal Human Effort: A Case Study on Japanese

    [https://arxiv.org/abs/2403.03690](https://arxiv.org/abs/2403.03690)

    通过GPT-4自指导方法，快速开发高质量的日语指令数据和评估基准，无需大量人力投入，并为大型语言模型提供了有效的资源

    

    为了为大型语言模型提供服务，创建指令数据和评估基准通常需要大量的人工标注。当为日语等非英语语言快速开发这些资源时，这个问题尤为突出。我们提出了一种基于GPT-4的高效自指导方法，而不是直接将现有的英语资源翻译成日语（例如Japanese-Alpaca）。我们首先将少量英语指令翻译成日语，并进行后期编辑以获得native-level质量。然后，GPT-4利用这些指令作为示范，自动生成日语指令数据。我们还利用GPT-4构建了一个包含80个问题跨8个类别的评估基准，使用GPT-4自动评估LLMs的响应质量，无需人工参考。实证结果表明，对我们的GPT-4自指导数据进行微调的模型显著

    arXiv:2403.03690v1 Announce Type: cross  Abstract: The creation of instruction data and evaluation benchmarks for serving Large language models often involves enormous human annotation. This issue becomes particularly pronounced when rapidly developing such resources for a non-English language like Japanese. Instead of following the popular practice of directly translating existing English resources into Japanese (e.g., Japanese-Alpaca), we propose an efficient self-instruct method based on GPT-4. We first translate a small amount of English instructions into Japanese and post-edit them to obtain native-level quality. GPT-4 then utilizes them as demonstrations to automatically generate Japanese instruction data. We also construct an evaluation benchmark containing 80 questions across 8 categories, using GPT-4 to automatically assess the response quality of LLMs without human references. The empirical results suggest that the models fine-tuned on our GPT-4 self-instruct data significant
    
[^24]: 通用到专业的电子商务LLMs翻译

    General2Specialized LLMs Translation for E-commerce

    [https://arxiv.org/abs/2403.03689](https://arxiv.org/abs/2403.03689)

    提出了一个名为G2ST的两步微调范式，通过自对比语义增强将通用NMT模型转换为专门用于电子商务的NMT模型，以提高翻译质量。

    

    现有的神经机器翻译（NMT）模型主要处理通用领域的翻译，忽略了具有特殊写作公式的领域，比如电子商务和法律文件。以电子商务为例，文本通常包含大量领域相关词汇，并且存在更多的语法问题，这导致当前NMT方法的性能较差。为解决这些问题，我们收集了两个与领域相关的资源，包括一组术语对（对齐的中英双语术语）和一个针对电子商务领域进行注释的平行语料库。此外，我们提出了一个两步微调范式（名为G2ST），其中包括自对比语义增强，以将一个通用NMT模型转换为专门用于电子商务的NMT模型。该范式适用于基于大型语言模型（LLMs）的NMT模型。对真实电子商务标题的广泛评估表明了卓越的翻译质量。

    arXiv:2403.03689v1 Announce Type: cross  Abstract: Existing Neural Machine Translation (NMT) models mainly handle translation in the general domain, while overlooking domains with special writing formulas, such as e-commerce and legal documents. Taking e-commerce as an example, the texts usually include amounts of domain-related words and have more grammar problems, which leads to inferior performances of current NMT methods. To address these problems, we collect two domain-related resources, including a set of term pairs (aligned Chinese-English bilingual terms) and a parallel corpus annotated for the e-commerce domain. Furthermore, we propose a two-step fine-tuning paradigm (named G2ST) with self-contrastive semantic enhancement to transfer one general NMT model to the specialized NMT model for e-commerce. The paradigm can be used for the NMT models based on Large language models (LLMs). Extensive evaluations on real e-commerce titles demonstrate the superior translation quality and 
    
[^25]: Apollo：轻量级多语言医学LLMs：让医学人工智能普惠60亿人

    Apollo: Lightweight Multilingual Medical LLMs towards Democratizing Medical AI to 6B People

    [https://arxiv.org/abs/2403.03640](https://arxiv.org/abs/2403.03640)

    Apollo项目开发了多语言医学LLMs，创建了全球人口61亿的医学数据集，并发布了各种尺寸的最佳性能模型，其中Apollo-7B是最先进的多语言医学LLMs，可改善更大模型的多语言医学能力。

    

    尽管全球医学知识的庞大存储库主要是以英语为主，但在传递量身定制医疗服务方面，本地语言对于在医疗资源有限的地区尤为重要。为了将医学人工智能的进展扩展到更广泛的人群，我们旨在开发涵盖全球61亿人口的六种最常用语言的医学LLMs。这一努力最终促成了ApolloCorpora多语言医学数据集和XMedBench基准的创建。在多语言医学基准测试中，发布的Apollo模型，在各种相对较小尺寸（即0.5B、1.8B、2B、6B和7B）上取得了与同等大小模型最佳性能。特别地，Apollo-7B是迄今为止达到70B的最先进的多语言医学LLMs。此外，这些轻量级模型可用于在不需要微调的情况下改进较大模型的多语言医学能力。

    arXiv:2403.03640v1 Announce Type: cross  Abstract: Despite the vast repository of global medical knowledge predominantly being in English, local languages are crucial for delivering tailored healthcare services, particularly in areas with limited medical resources. To extend the reach of medical AI advancements to a broader population, we aim to develop medical LLMs across the six most widely spoken languages, encompassing a global population of 6.1 billion. This effort culminates in the creation of the ApolloCorpora multilingual medical dataset and the XMedBench benchmark. In the multilingual medical benchmark, the released Apollo models, at various relatively-small sizes (i.e., 0.5B, 1.8B, 2B, 6B, and 7B), achieve the best performance among models of equivalent size. Especially, Apollo-7B is the state-of-the-art multilingual medical LLMs up to 70B. Additionally, these lite models could be used to improve the multi-lingual medical capabilities of larger models without fine-tuning in a
    
[^26]: 动态交互式主题表示

    GPTopic: Dynamic and Interactive Topic Representations

    [https://arxiv.org/abs/2403.03628](https://arxiv.org/abs/2403.03628)

    介绍了GPTopic，一种利用大型语言模型创建动态、交互式主题表示的软件包，通过直观的聊天界面使主题建模更易用和全面。

    

    主题建模似乎几乎等同于生成列出顶部单词以表示大型文本语料库中的主题。然而，从这样一列个别术语中推断主题可能需要大量的专业知识和经验，使得主题建模对于对特定顶词解释的细微差别和缺陷不熟悉的人群不够易用。仅限于顶词的主题表示可能进一步无法提供主题可能具有的各个方面、方面和细微差别的全面且易于访问的表征。为了解决这些挑战，我们介绍了GPTopic，一个利用大型语言模型（LLMs）创建动态，交互式主题表示的软件包。GPTopic提供直观的聊天界面，供用户交互地探索、分析和完善主题，使主题建模更易使用和全面。相应的代码可在此处找到：https://gith

    arXiv:2403.03628v1 Announce Type: new  Abstract: Topic modeling seems to be almost synonymous with generating lists of top words to represent topics within large text corpora. However, deducing a topic from such list of individual terms can require substantial expertise and experience, making topic modelling less accessible to people unfamiliar with the particularities and pitfalls of top-word interpretation. A topic representation limited to top-words might further fall short of offering a comprehensive and easily accessible characterization of the various aspects, facets and nuances a topic might have. To address these challenges, we introduce GPTopic, a software package that leverages Large Language Models (LLMs) to create dynamic, interactive topic representations. GPTopic provides an intuitive chat interface for users to explore, analyze, and refine topics interactively, making topic modeling more accessible and comprehensive. The corresponding code is available here: https://gith
    
[^27]: 多模态大型语言模型支持现实世界事实核查

    Multimodal Large Language Models to Support Real-World Fact-Checking

    [https://arxiv.org/abs/2403.03627](https://arxiv.org/abs/2403.03627)

    多模态大型语言模型在支持现实世界事实核查中展现出优越性能，并能够解释恶意和误导性声明的不合理之处和潜在动机。

    

    多模态大型语言模型（MLLMs）具有潜力支持人类处理大量信息。虽然MLLMs已经被用作事实核查工具，但就其在此方面的能力和局限性而言，尚未得到充分研究。我们旨在弥合这一差距。具体而言，我们提出了一个框架，系统评估当前多模态模型促进现实世界事实核查的能力。我们的方法论是无需证据的，仅利用这些模型的固有知识和推理能力。通过设计能够提取模型预测、解释和置信水平的提示，我们深入研究关于模型准确性、鲁棒性以及失败原因的研究问题。我们在实证上发现，(1) GPT-4V在识别恶意和误导性多模态声明方面表现出超凡性能，能够解释不合理的方面和潜在动机，以及(2)现有的o

    arXiv:2403.03627v1 Announce Type: cross  Abstract: Multimodal large language models (MLLMs) carry the potential to support humans in processing vast amounts of information. While MLLMs are already being used as a fact-checking tool, their abilities and limitations in this regard are understudied. Here is aim to bridge this gap. In particular, we propose a framework for systematically assessing the capacity of current multimodal models to facilitate real-world fact-checking. Our methodology is evidence-free, leveraging only these models' intrinsic knowledge and reasoning capabilities. By designing prompts that extract models' predictions, explanations, and confidence levels, we delve into research questions concerning model accuracy, robustness, and reasons for failure. We empirically find that (1) GPT-4V exhibits superior performance in identifying malicious and misleading multimodal claims, with the ability to explain the unreasonable aspects and underlying motives, and (2) existing o
    
[^28]: 为神经机器翻译设计的开源架构

    Design of an Open-Source Architecture for Neural Machine Translation

    [https://arxiv.org/abs/2403.03582](https://arxiv.org/abs/2403.03582)

    该开源应用程序 adaptNMT 简化了神经机器翻译模型的开发和部署，提供了图形化训练进展展示、子词分割模型和一键式模型开发方法。

    

    arXiv:2403.03582v1 公告类型: 跨领域 adaptNMT 是一个开源应用程序，提供了一种简化的方法来开发和部署循环神经网络和Transformer模型。该应用程序构建在广泛采用的OpenNMT生态系统之上，特别适用于该领域的新进入者，因为它简化了开发环境的设置以及训练、验证和测试数据集的创建。该应用程序提供了一个图形化功能，用于展示模型训练的进展，并采用SentencePiece来创建子词分割模型。此外，该应用程序提供了一个直观的用户界面，简化了超参数的定制。值得注意的是，该应用实现了一键式模型开发方法，通过adaptNMT开发的模型可以使用各种指标进行评估。为了鼓励环保研究，adaptNMT集成了一个环保报告，标志着能源消耗和二氧化碳排放量。

    arXiv:2403.03582v1 Announce Type: cross  Abstract: adaptNMT is an open-source application that offers a streamlined approach to the development and deployment of Recurrent Neural Networks and Transformer models. This application is built upon the widely-adopted OpenNMT ecosystem, and is particularly useful for new entrants to the field, as it simplifies the setup of the development environment and creation of train, validation, and test splits. The application offers a graphing feature that illustrates the progress of model training, and employs SentencePiece for creating subword segmentation models. Furthermore, the application provides an intuitive user interface that facilitates hyperparameter customization. Notably, a single-click model development approach has been implemented, and models developed by adaptNMT can be evaluated using a range of metrics. To encourage eco-friendly research, adaptNMT incorporates a green report that flags the power consumption and kgCO${_2}$ emissions
    
[^29]: 提高ASD检测准确性：机器学习和深度学习模型与自然语言处理的综合方法

    Enhancing ASD detection accuracy: a combined approach of machine learning and deep learning models with natural language processing

    [https://arxiv.org/abs/2403.03581](https://arxiv.org/abs/2403.03581)

    该研究利用机器学习和深度学习模型结合自然语言处理技术，成功提高了ASD检测准确率，尤其在儿童中具有重要意义。

    

    arXiv:2403.03581v1 公告类型：新摘要：目的：我们的研究探讨了利用人工智能（AI）来诊断自闭症谱系障碍（ASD）。它专注于利用机器学习（ML）和深度学习（DL）从社交媒体上的文本输入中检测ASD，解决传统ASD诊断中的挑战。方法：我们使用自然语言处理（NLP）、ML和DL模型（包括决策树、XGB、KNN、RNN、LSTM、Bi-LSTM、BERT和BERTweet）分析了404,627条tweets，根据ASD或非ASD作者对其进行分类。其中90,000条tweets用于模型训练和测试。结果：我们的AI模型表现出较高的准确性，成功率达到88％，可以识别出来自ASD患者的文本。结论：该研究展示了AI在改善ASD诊断方面的潜力，特别是在儿童中，突显了早期检测的重要性。

    arXiv:2403.03581v1 Announce Type: new  Abstract: Purpose: Our study explored the use of artificial intelligence (AI) to diagnose autism spectrum disorder (ASD). It focused on machine learning (ML) and deep learning (DL) to detect ASD from text inputs on social media, addressing challenges in traditional ASD diagnosis.   Methods: We used natural language processing (NLP), ML, and DL models (including decision trees, XGB, KNN, RNN, LSTM, Bi-LSTM, BERT, and BERTweet) to analyze 404,627 tweets, classifying them based on ASD or non-ASD authors. A subset of 90,000 tweets was used for model training and testing.   Results: Our AI models showed high accuracy, with an 88% success rate in identifying texts from individuals with ASD.   Conclusion: The study demonstrates AI's potential in improving ASD diagnosis, especially in children, highlighting the importance of early detection.
    
[^30]: gaHealth: 一份英语-爱尔兰爱尔兰双语健康数据语料库

    gaHealth: An English-Irish Bilingual Corpus of Health Data

    [https://arxiv.org/abs/2403.03575](https://arxiv.org/abs/2403.03575)

    开发了一份用于低资源英语到爱尔兰语言对的特定健康领域数据集，实证证明使用领域数据对健康领域具有明显好处，并展示的最大BLEU分数提升为22.2点（40%）。

    

    arXiv:2403.03575v1 公告类型：跨界  摘要：机器翻译是一种成熟的技术，适用于许多高资源语言对。然而，在低资源语言环境中，目前很少有可用于开发翻译模型的平行数据数据集。此外，针对低资源语言开发数据集的工作往往集中于简单地创建用于通用翻译的尽可能大的数据集。很容易忽视使用小型领域数据集的好处和发展。为了评估使用领域数据的优点，为低资源的英语到爱尔兰语言对特定领域的健康数据开发了一个数据集。我们的研究概述了开发语料库所使用的过程，并从经验上展示了使用健康领域的领域数据的好处。在翻译与健康相关数据的背景下，使用gaHealth语料库开发的模型在比较时显示出最大BLEU分数提升22.2点（40%）。

    arXiv:2403.03575v1 Announce Type: cross  Abstract: Machine Translation is a mature technology for many high-resource language pairs. However in the context of low-resource languages, there is a paucity of parallel data datasets available for developing translation models. Furthermore, the development of datasets for low-resource languages often focuses on simply creating the largest possible dataset for generic translation. The benefits and development of smaller in-domain datasets can easily be overlooked. To assess the merits of using in-domain data, a dataset for the specific domain of health was developed for the low-resource English to Irish language pair. Our study outlines the process used in developing the corpus and empirically demonstrates the benefits of using an in-domain dataset for the health domain. In the context of translating health-related data, models developed using the gaHealth corpus demonstrated a maximum BLEU score improvement of 22.2 points (40%) when compared
    
[^31]: 基于无法回答的数学单词问题对大型语言模型中幻觉能力的基准测试

    Benchmarking Hallucination in Large Language Models based on Unanswerable Math Word Problem

    [https://arxiv.org/abs/2403.03558](https://arxiv.org/abs/2403.03558)

    本文提出了一种新方法，通过无法回答的数学单词问题评估大型语言模型中的幻觉能力，通过开发包含五个类别的5200个问题的UMWP数据集，结合文本相似度和数学表达式检测的评估方法，表明在-context学习和强化学习与人类反馈(RLHF)训练显著增强了模型避免幻觉的能力。

    

    大型语言模型(大型语言模型)在各种自然语言处理(NLP)任务中非常有效。然而，在模糊语境中容易产生不可靠的推测，称为幻觉。本文提出了一种新方法，用于评估基于无法回答的数学单词问题(QA)的LLM幻觉。为了支持这种方法，我们创新地开发了一个名为无法回答的数学单词问题(UMWP)的数据集，包括五个类别的5200个问题。我们开发了一个评估方法，结合文本相似度和数学表达式检测，以确定LLM是否认为问题无法回答。对31个LLM进行了大量实验，包括GPT-3、InstructGPT、LLaMA和Claude，在-context学习和强化学习与人类反馈(RLHF)训练显著增强了模型避免幻觉的能力。

    arXiv:2403.03558v1 Announce Type: new  Abstract: Large language models (LLMs) are highly effective in various natural language processing (NLP) tasks. However, they are susceptible to producing unreliable conjectures in ambiguous contexts called hallucination. This paper presents a new method for evaluating LLM hallucination in Question Answering (QA) based on the unanswerable math word problem (MWP). To support this approach, we innovatively develop a dataset called Unanswerable Math Word Problem (UMWP) which comprises 5200 questions across five categories. We developed an evaluation methodology combining text similarity and mathematical expression detection to determine whether LLM considers the question unanswerable. The results of extensive experiments conducted on 31 LLMs, including GPT-3, InstructGPT, LLaMA, and Claude, demonstrate that in-context learning and reinforcement learning with human feedback (RLHF) training significantly enhance the model's ability to avoid hallucinati
    
[^32]: 基于语言的人类移动预测的提示挖掘

    Prompt Mining for Language-based Human Mobility Forecasting

    [https://arxiv.org/abs/2403.03544](https://arxiv.org/abs/2403.03544)

    使用信息熵进行提示挖掘，探索多样化的提示设计策略，提高基于语言的人类移动预测的准确性和效果

    

    随着大型语言模型的发展，基于语言的预测最近作为一种创新方法出现，用于预测人类移动模式。其核心思想是使用提示将以数字值给出的原始移动数据转化为自然语言句子，从而可以利用语言模型生成未来观察的描述。然而，先前的研究仅采用固定和手动设计的模板将数字值转化为句子。由于语言模型的预测性能严重依赖于提示，使用固定模板进行提示可能限制语言模型的预测能力。在本文中，我们提出了一种新颖的基于语言的移动预测提示挖掘框架，旨在探索多样化的提示设计策略。具体而言，该框架包括基于提示信息熵的提示生成阶段和

    arXiv:2403.03544v1 Announce Type: new  Abstract: With the advancement of large language models, language-based forecasting has recently emerged as an innovative approach for predicting human mobility patterns. The core idea is to use prompts to transform the raw mobility data given as numerical values into natural language sentences so that the language models can be leveraged to generate the description for future observations. However, previous studies have only employed fixed and manually designed templates to transform numerical values into sentences. Since the forecasting performance of language models heavily relies on prompts, using fixed templates for prompting may limit the forecasting capability of language models. In this paper, we propose a novel framework for prompt mining in language-based mobility forecasting, aiming to explore diverse prompt design strategies. Specifically, the framework includes a prompt generation stage based on the information entropy of prompts and 
    
[^33]: RADIA -- 具有智能分析的广播广告检测

    RADIA -- Radio Advertisement Detection with Intelligent Analytics

    [https://arxiv.org/abs/2403.03538](https://arxiv.org/abs/2403.03538)

    本研究提出了一种新型自动广播广告检测技术RADIA，利用先进的语音识别和文本分类算法，能够在不需要先验知识的情况下检测广播中的即兴和新广告，为广播广告检测提供了全面的解决方案，并取得了较高的F1-macro得分。

    

    广播广告仍然是现代营销策略中不可或缺的一部分，其吸引力和针对性传播的潜力不可否认。然而，广播播出时间的动态性和多个广播广告的日益增长趋势为监测广告播出的有效性提出了要求。本研究调查了一种结合先进语音识别和文本分类算法的新型自动广播广告检测技术。RADIA的方法通过消除对广播内容的先验知识的需求，超越了传统方法。这一贡献允许检测即兴和新引入的广告，为广播广告检测提供了全面的解决方案。实验结果表明，该模型在精心分割和标记的文本数据上训练，达到了F1-macro得分87.76，理论最大值为89.33。

    arXiv:2403.03538v1 Announce Type: cross  Abstract: Radio advertising remains an integral part of modern marketing strategies, with its appeal and potential for targeted reach undeniably effective. However, the dynamic nature of radio airtime and the rising trend of multiple radio spots necessitates an efficient system for monitoring advertisement broadcasts. This study investigates a novel automated radio advertisement detection technique incorporating advanced speech recognition and text classification algorithms. RadIA's approach surpasses traditional methods by eliminating the need for prior knowledge of the broadcast content. This contribution allows for detecting impromptu and newly introduced advertisements, providing a comprehensive solution for advertisement detection in radio broadcasting. Experimental results show that the resulting model, trained on carefully segmented and tagged text data, achieves an F1-macro score of 87.76 against a theoretical maximum of 89.33. This pape
    
[^34]: 自发性言语中的非言语信息 - 朝着新的分析框架

    Non-verbal information in spontaneous speech - towards a new framework of analysis

    [https://arxiv.org/abs/2403.03522](https://arxiv.org/abs/2403.03522)

    这项研究提出了一个分析框架和技术验证概念，用于对言语中的非言语信号进行分类，并将其与含义关联起来，从而为探索表达实现多层韵律事件的大型数据提供了一种方法。

    

    言语中的非言语信号是由韵律编码的，携带的信息范围从对话行为到态度和情感。尽管其重要性，掌握掌声结构的原则仍未得到充分理解。本文提出了一个分析框架和技术验证概念，用于对韵律信号进行分类，并将其与含义关联起来。该框架解释了多层韵律事件的表层表示。作为实施的第一步，我们提出了一个分类过程，可以解开三个级别的韵律现象。它依赖于微调预训练的语音识别模型，实现同时的多类别/多标签检测。它可以概括各种各样的自发数据，在与人类注释相当或优于的情况下执行。除了对韵律的标准化形式化外，解开韵律模式还可以指导

    arXiv:2403.03522v1 Announce Type: cross  Abstract: Non-verbal signals in speech are encoded by prosody and carry information that ranges from conversation action to attitude and emotion. Despite its importance, the principles that govern prosodic structure are not yet adequately understood. This paper offers an analytical schema and a technological proof-of-concept for the categorization of prosodic signals and their association with meaning. The schema interprets surface-representations of multi-layered prosodic events. As a first step towards implementation, we present a classification process that disentangles prosodic phenomena of three orders. It relies on fine-tuning a pre-trained speech recognition model, enabling the simultaneous multi-class/multi-label detection. It generalizes over a large variety of spontaneous data, performing on a par with, or superior to, human annotation. In addition to a standardized formalization of prosody, disentangling prosodic patterns can direct a
    
[^35]: BiVert：使用关系进行双向词汇评估用于机器翻译

    BiVert: Bidirectional Vocabulary Evaluation using Relations for Machine Translation

    [https://arxiv.org/abs/2403.03521](https://arxiv.org/abs/2403.03521)

    提出了一种双向基于语义的评估方法，通过使用BabelNet词典计算源文本和反向翻译之间的语义距离，实现了在相同语言水平上的句子比较。

    

    arXiv：2403.03521v1 公告类型：新  摘要：神经机器翻译（NMT）在过去几年取得了快速进展，为不同语言的改进和质量翻译提供了希望。对这一任务的评估对于确定翻译的质量至关重要。总体而言，传统方法在翻译的实际含义方面没有足够的强调。我们提出了一种双向基于语义的评估方法，旨在评估翻译与源文本之间的语义距离。该方法采用了综合的多语言百科全书词典BabelNet。通过计算源文本及其输出的反向翻译之间的语义距离，我们的方法引入了一种可量化的方法，从而使句子在相同的语言水平上进行比较。事实分析显示，我们的方法生成的平均评估分数与各种机器翻译系统的人类评估之间存在较强的相关性。

    arXiv:2403.03521v1 Announce Type: new  Abstract: Neural machine translation (NMT) has progressed rapidly in the past few years, promising improvements and quality translations for different languages. Evaluation of this task is crucial to determine the quality of the translation. Overall, insufficient emphasis is placed on the actual sense of the translation in traditional methods. We propose a bidirectional semantic-based evaluation method designed to assess the sense distance of the translation from the source text. This approach employs the comprehensive multilingual encyclopedic dictionary BabelNet. Through the calculation of the semantic distance between the source and its back translation of the output, our method introduces a quantifiable approach that empowers sentence comparison on the same linguistic level. Factual analysis shows a strong correlation between the average evaluation scores generated by our method and the human assessments across various machine translation syst
    
[^36]: 通过生成伪标签实现的无监督多语言稠密检索

    Unsupervised Multilingual Dense Retrieval via Generative Pseudo Labeling

    [https://arxiv.org/abs/2403.03516](https://arxiv.org/abs/2403.03516)

    通过生成伪标签实现的无监督多语言稠密检索方法能够在多语言信息检索中取得优异性能，提高了多语言检索器的实用性

    

    稠密检索方法在多语言信息检索中表现出色，但通常需要大量配对数据，这在多语言场景下更具挑战性。本文介绍了UMR，一种无需任何配对数据训练的无监督多语言稠密检索器。我们的方法利用多语言语言模型的序列似然估计能力来获取用于训练稠密检索器的伪标签。我们提出了一个两阶段框架，通过迭代改善多语言稠密检索器的性能。对两个基准数据集的实验结果表明，UMR的性能优于监督基线，展示了无需配对数据训练多语言检索器的潜力，从而提高了其实用性。我们的源代码、数据和模型已公开可用。

    arXiv:2403.03516v1 Announce Type: new  Abstract: Dense retrieval methods have demonstrated promising performance in multilingual information retrieval, where queries and documents can be in different languages. However, dense retrievers typically require a substantial amount of paired data, which poses even greater challenges in multilingual scenarios. This paper introduces UMR, an Unsupervised Multilingual dense Retriever trained without any paired data. Our approach leverages the sequence likelihood estimation capabilities of multilingual language models to acquire pseudo labels for training dense retrievers. We propose a two-stage framework which iteratively improves the performance of multilingual dense retrievers. Experimental results on two benchmark datasets show that UMR outperforms supervised baselines, showcasing the potential of training multilingual retrievers without paired data, thereby enhancing their practicality. Our source code, data, and models are publicly available
    
[^37]: CLongEval: 用于评估长上下文大语言模型的中文基准

    CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models

    [https://arxiv.org/abs/2403.03514](https://arxiv.org/abs/2403.03514)

    CLongEval是一个用于评估长上下文大语言模型的全面中文基准，具有足够的数据量、广泛的适用性和高质量，可以对多个开源和商业模型进行全面评估。

    

    arXiv:2403.03514v1 公告类型: 新的 摘要: 开发具有强大长上下文能力的大型语言模型(LLMs)一直是最近的研究重点，导致长上下文中文能力娴熟的LLMs的出现。然而，由于缺乏基准测试，这些模型的评估仍然不够完善。为填补这一空白，我们提出CLongEval，一个用于评估长上下文LLMs的全面中文基准。CLongEval具有三个关键特征：(1)足够的数据量，包括7个不同的任务和7,267个示例；(2)广泛的适用性，适用于上下文窗口大小从1K到100K的模型；(3)高质量，除了自动构建的标签外，还有超过2,000个手工注释的问答对。借助CLongEval，我们对6个开源长上下文LLMs和2个具有长上下文能力和中文熟练度的领先商业竞争对手进行了全面评估。

    arXiv:2403.03514v1 Announce Type: new  Abstract: Developing Large Language Models (LLMs) with robust long-context capabilities has been the recent research focus, resulting in the emergence of long-context LLMs proficient in Chinese. However, the evaluation of these models remains underdeveloped due to a lack of benchmarks. To address this gap, we present CLongEval, a comprehensive Chinese benchmark for evaluating long-context LLMs. CLongEval is characterized by three key features: (1) Sufficient data volume, comprising 7 distinct tasks and 7,267 examples; (2) Broad applicability, accommodating to models with context windows size from 1K to 100K; (3) High quality, with over 2,000 manually annotated question-answer pairs in addition to the automatically constructed labels. With CLongEval, we undertake a comprehensive assessment of 6 open-source long-context LLMs and 2 leading commercial counterparts that feature both long-context abilities and proficiency in Chinese. We also provide in-
    
[^38]: 人工智能生成文本与人工智能协作混合文本中的检测方法

    Towards Detecting AI-Generated Text within Human-AI Collaborative Hybrid Texts

    [https://arxiv.org/abs/2403.03506](https://arxiv.org/abs/2403.03506)

    本研究探索了在人工智能协作混合文本中句子级人工智能生成文本检测的挑战，并提出了一种基于分割的两步骤流程来检测各段落的一致作者句子。

    

    本研究探讨了在人工智能协作混合文本中句子级人工智能生成文本检测的挑战。现有的关于混合文本中AI生成文本检测的研究通常依赖于合成数据集，这些数据集通常涉及带有有限边界的混合文本。我们认为，检测混合文本中AI生成内容的研究应覆盖在真实环境中生成的不同类型混合文本，以更好地指导实际应用。因此，我们的研究利用了CoAuthor数据集，该数据集包括通过人类作者和智能写作系统之间的协作生成的多轮交互中产生的多样化、真实的混合文本。我们采用了两步分割为基础的流程：(i)检测给定混合文本中的各个段落，其中每个段落包含一致作者的句子，以及(ii)分类每个确定段落的作者。我们的实证

    arXiv:2403.03506v1 Announce Type: cross  Abstract: This study explores the challenge of sentence-level AI-generated text detection within human-AI collaborative hybrid texts. Existing studies of AI-generated text detection for hybrid texts often rely on synthetic datasets. These typically involve hybrid texts with a limited number of boundaries. We contend that studies of detecting AI-generated content within hybrid texts should cover different types of hybrid texts generated in realistic settings to better inform real-world applications. Therefore, our study utilizes the CoAuthor dataset, which includes diverse, realistic hybrid texts generated through the collaboration between human writers and an intelligent writing system in multi-turn interactions. We adopt a two-step, segmentation-based pipeline: (i) detect segments within a given hybrid text where each segment contains sentences of consistent authorship, and (ii) classify the authorship of each identified segment. Our empirical 
    
[^39]: 一个用于开放领域对话生成的知识即插即用测试平台

    A Knowledge Plug-and-Play Test Bed for Open-domain Dialogue Generation

    [https://arxiv.org/abs/2403.03496](https://arxiv.org/abs/2403.03496)

    本文提出了一个新的高质量基准测试，用于评估支持知识检索，在开放领域对话生成中引入新的知识源

    

    基于知识的开放领域对话生成旨在构建可以利用挖掘的支持知识与人类交谈的闲聊系统。先前已经展示了许多种类型和来源的知识作为支持知识是有用的。即使在大语言模型时代，基于从额外最新源检索的知识进行回应生成仍然是一种实际重要的方法。本文提出了一个高质量的基准测试

    arXiv:2403.03496v1 Announce Type: new  Abstract: Knowledge-based, open-domain dialogue generation aims to build chit-chat systems that talk to humans using mined support knowledge. Many types and sources of knowledge have previously been shown to be useful as support knowledge. Even in the era of large language models, response generation grounded in knowledge retrieved from additional up-to-date sources remains a practically important approach. While prior work using single-source knowledge has shown a clear positive correlation between the performances of knowledge selection and response generation, there are no existing multi-source datasets for evaluating support knowledge retrieval. Further, prior work has assumed that the knowledge sources available at test time are the same as during training. This unrealistic assumption unnecessarily handicaps models, as new knowledge sources can become available after a model is trained. In this paper, we present a high-quality benchmark named
    
[^40]: 魔法标记：使用LLM维护文档外部标记

    Magic Markup: Maintaining Document-External Markup with an LLM

    [https://arxiv.org/abs/2403.03481](https://arxiv.org/abs/2403.03481)

    使用LLM模型，我们提出了一种新方法，将元数据绑定到文本实体，扩展了文档注释的应用，实现了对修改后程序的自动重新标记，并提供了正式问题定义和基准套件。

    

    文本文档，包括程序，通常具有人类可读的语义结构。历史上，对这些语义的程序化访问需要显式的文档内标记。特别是在文本具有执行语义的系统中，这意味着这是一个难以正确支持的自愿功能。现今，语言模型提供了一种新方法：可以使用模型对语义的人类化理解将元数据绑定到变化的文本实体，而不需要文档结构的要求。该方法扩展了文档注释的应用，这是程序编写、调试、维护和展示中的基本操作。我们提出了一种系统，利用智能代理对修改后的程序重新进行标记，使得丰富的注释可以随着代码演进而自动跟随。我们还贡献了一个正式的问题定义，一个经验合成基准套件，以及我们的基准生成器。

    arXiv:2403.03481v1 Announce Type: new  Abstract: Text documents, including programs, typically have human-readable semantic structure. Historically, programmatic access to these semantics has required explicit in-document tagging. Especially in systems where the text has an execution semantics, this means it is an opt-in feature that is hard to support properly. Today, language models offer a new method: metadata can be bound to entities in changing text using a model's human-like understanding of semantics, with no requirements on the document structure. This method expands the applications of document annotation, a fundamental operation in program writing, debugging, maintenance, and presentation. We contribute a system that employs an intelligent agent to re-tag modified programs, enabling rich annotations to automatically follow code as it evolves. We also contribute a formal problem definition, an empirical synthetic benchmark suite, and our benchmark generator. Our system achieve
    
[^41]: VLSP 2023 -- LTER: 法律文本蕴涵识别挑战总结

    VLSP 2023 -- LTER: A Summary of the Challenge on Legal Textual Entailment Recognition

    [https://arxiv.org/abs/2403.03435](https://arxiv.org/abs/2403.03435)

    针对越南语言领域的法律文本蕴涵识别首次被引入，分析了参与者结果并讨论了法律领域中的关键语言因素挑战。

    

    在这个快速人工智能发展的新时代，特别是在语言处理领域，对于人工智能在法律领域的需求日益关键。在已经建立良好的英语、日语和汉语等其他语言研究的背景下，我们介绍了在越南语言和语音处理研讨会上针对越南语言领域的首个基础研究：法律文本蕴涵识别。通过分析参与者的结果，我们讨论了法律领域中某些语言方面的关键因素，这些因素构成了需要解决的挑战。

    arXiv:2403.03435v1 Announce Type: new  Abstract: In this new era of rapid AI development, especially in language processing, the demand for AI in the legal domain is increasingly critical. In the context where research in other languages such as English, Japanese, and Chinese has been well-established, we introduce the first fundamental research for the Vietnamese language in the legal domain: legal textual entailment recognition through the Vietnamese Language and Speech Processing workshop. In analyzing participants' results, we discuss certain linguistic aspects critical in the legal domain that pose challenges that need to be addressed.
    
[^42]: 混合LoRAs：大型语言模型的高效多任务调优

    Mixture-of-LoRAs: An Efficient Multitask Tuning for Large Language Models

    [https://arxiv.org/abs/2403.03432](https://arxiv.org/abs/2403.03432)

    提出了一种新颖且参数高效的混合LoRAs（MoA）架构，通过引入领域标签和显式路由策略，解决了大型语言模型多任务学习中的灾难性遗忘和任务干扰问题，从而提升了每个任务的性能。

    

    指导调优有潜力激发或增强大型语言模型（LLMs）的特定能力。然而，实现数据的正确平衡对于防止灾难性遗忘和任务之间的干扰至关重要。为了解决这些限制并增强训练灵活性，我们提出了适用于LLMs的新颖和参数高效的调优方法——混合LoRAs（MoA）架构。在本文中，我们通过使用相应的监督语料库数据单独训练多个特定领域的LoRA模块。这些LoRA模块可以与在专家设计原则中观察到的专家混合（MoE）相一致。随后，我们利用显式路由策略组合多个LoRAs，并引入领域标签以促进多任务学习，这有助于防止任务之间的干扰，并最终提升每个个别任务的性能。

    arXiv:2403.03432v1 Announce Type: cross  Abstract: Instruction Tuning has the potential to stimulate or enhance specific capabilities of large language models (LLMs). However, achieving the right balance of data is crucial to prevent catastrophic forgetting and interference between tasks. To address these limitations and enhance training flexibility, we propose the Mixture-of-LoRAs (MoA) architecture which is a novel and parameter-efficient tuning method designed for multi-task learning with LLMs. In this paper, we start by individually training multiple domain-specific LoRA modules using corresponding supervised corpus data. These LoRA modules can be aligned with the expert design principles observed in Mixture-of-Experts (MoE). Subsequently, we combine the multiple LoRAs using an explicit routing strategy and introduce domain labels to facilitate multi-task learning, which help prevent interference between tasks and ultimately enhances the performance of each individual task. Further
    
[^43]: 否定否定：通过分布式反喜好优化实现对齐而无需人类正样本

    Negating Negatives: Alignment without Human Positive Samples via Distributional Dispreference Optimization

    [https://arxiv.org/abs/2403.03419](https://arxiv.org/abs/2403.03419)

    通过提出Distributional Dispreference Optimization (D$^2$O)方法，在不需要人类正样本的情况下实现了对齐，减少了有害信息的传播。

    

    大型语言模型（LLM）改变了人工智能的角色，但也可能存在传播不道德内容的潜在风险。对齐技术被引入以引导LLM朝着人类偏好方向发展，并受到越来越多的关注。尽管在这个方向上取得了显著突破，但现有方法严重依赖于高质量的正负训练对，受到嘈杂标签和首选和非首选响应数据之间的边缘区别的困扰。鉴于最近LLM在生成有用响应方面的高水平，本文将研究重点转向一个新的方向：仅使用人工注释的负样本来实现对齐，保留有用性的同时降低有害性。为此，我们提出了分布式反喜好优化（D$^2$O），通过最大化生成的响应与非首选响应之间的差异，有效地排除有害信息。我们在理论上证明

    arXiv:2403.03419v1 Announce Type: cross  Abstract: Large language models (LLMs) have revolutionized the role of AI, yet also pose potential risks of propagating unethical content. Alignment technologies have been introduced to steer LLMs towards human preference, gaining increasing attention. Despite notable breakthroughs in this direction, existing methods heavily rely on high-quality positive-negative training pairs, suffering from noisy labels and the marginal distinction between preferred and dispreferred response data. Given recent LLMs' proficiency in generating helpful responses, this work pivots towards a new research focus: achieving alignment using solely human-annotated negative samples, preserving helpfulness while reducing harmfulness. For this purpose, we propose Distributional Dispreference Optimization (D$^2$O), which maximizes the discrepancy between the generated responses and the dispreferred ones to effectively eschew harmful information. We theoretically demonstrat
    
[^44]: 人类对抗机器：语言模型与战争游戏

    Human vs. Machine: Language Models and Wargames

    [https://arxiv.org/abs/2403.03407](https://arxiv.org/abs/2403.03407)

    人工智能大型语言模型在战争游戏中与人类响应存在一致性，但也存在显著的差异，这表明在政策制定者交出自主权或听从基于AI的战略建议之前应谨慎对待。

    

    战争游戏在军事战略的发展和国家对威胁或攻击的响应中有着悠久的历史。人工智能（AI）的出现承诺了更好的决策制定和增强的军事效果。然而，关于AI系统，尤其是大型语言模型（LLMs），与人类的行为有何不同仍存在争议。为此，我们进行了一项战争游戏实验，共有107位国家安全专家人类参与者参与，旨在研究在一个虚构的美中情景中的危机升级，并比较人类参与者与LLM模拟响应之间的差异。我们发现LLM和人类响应存在显著一致性，但在战争游戏中模拟和人类参与者之间也存在显著的定量和定性差异，这促使决策者在交出自主权或遵循基于AI的战略建议之前谨慎对待。

    arXiv:2403.03407v1 Announce Type: cross  Abstract: Wargames have a long history in the development of military strategy and the response of nations to threats or attacks. The advent of artificial intelligence (AI) promises better decision-making and increased military effectiveness. However, there is still debate about how AI systems, especially large language models (LLMs), behave as compared to humans. To this end, we use a wargame experiment with 107 national security expert human players designed to look at crisis escalation in a fictional US-China scenario and compare human players to LLM-simulated responses. We find considerable agreement in the LLM and human responses but also significant quantitative and qualitative differences between simulated and human players in the wargame, motivating caution to policymakers before handing over autonomy or following AI-based strategy recommendations.
    
[^45]: 用于自动评分的日英句子翻译练习数据集

    Japanese-English Sentence Translation Exercises Dataset for Automatic Grading

    [https://arxiv.org/abs/2403.03396](https://arxiv.org/abs/2403.03396)

    本文提出了用于自动评估句子翻译练习的任务，并创建了日英STE数据集，实验结果表明微调的BERT模型能够以约90%的F1值分类正确回答

    

    本文提出了自动评估句子翻译练习（STEs）的任务，这在第二语言学习的早期阶段被使用。我们将这项任务形式化为为每个由教育工作者预先指定的评分标准对学生回答进行评分的任务。我们创建了一个包含21个问题的日英STE数据集，以及共3,498个学生回答（平均167个）。回答数据来自学生和众包工作者。利用这个数据集，我们展示了包括微调的BERT和具有少量远程上下文学习的GPT模型在内的基线性能。实验结果表明，具有微调BERT的基线模型能够以约90%的F1值分类正确回答，但对于错误回答仅不到80%。此外，具有少量远程上下文学习的GPT模型显示出比微调的BERT更差的结果，表明我们新提出的任务

    arXiv:2403.03396v1 Announce Type: new  Abstract: This paper proposes the task of automatic assessment of Sentence Translation Exercises (STEs), that have been used in the early stage of L2 language learning. We formalize the task as grading student responses for each rubric criterion pre-specified by the educators. We then create a dataset for STE between Japanese and English including 21 questions, along with a total of 3, 498 student responses (167 on average). The answer responses were collected from students and crowd workers. Using this dataset, we demonstrate the performance of baselines including finetuned BERT and GPT models with few-shot in-context learning. Experimental results show that the baseline model with finetuned BERT was able to classify correct responses with approximately 90% in F1, but only less than 80% for incorrect responses. Furthermore, the GPT models with few-shot learning show poorer results than finetuned BERT, indicating that our newly proposed task prese
    
[^46]: 学习最大化互信息进行思维链提炼

    Learning to Maximize Mutual Information for Chain-of-Thought Distillation

    [https://arxiv.org/abs/2403.03348](https://arxiv.org/abs/2403.03348)

    通过最大化两个任务的表示特征的互信息，提出了一种解决思维链蒸馏中标签预测任务与知识集成不足问题的变分方法。

    

    知识蒸馏是将大型复杂模型的知识传递给较小模型的技术，是实现高效人工智能部署的关键一步。通过利用思维链 (CoT) 蒸馏的新方法——逐步蒸馏 (DSS)，已经展示出为较小模型赋予其较大同行的优越推理能力的潜力。在DSS中，蒸馏模型通过一个多任务学习框架同时获得生成理由和预测标签的能力。然而，DSS忽略了这两个训练任务之间的内在关系，导致CoT知识与标签预测任务的有效整合不足。为此，我们从信息瓶颈的角度研究了两个任务之间的相互关系，并将其表述为最大化两个任务的表示特征的互信息。我们提出了一种变分方法来解决这个问题。

    arXiv:2403.03348v1 Announce Type: cross  Abstract: Knowledge distillation, the technique of transferring knowledge from large, complex models to smaller ones, marks a pivotal step towards efficient AI deployment. Distilling Step-by-Step (DSS), a novel method utilizing chain-of-thought (CoT) distillation, has demonstrated promise by imbuing smaller models with the superior reasoning capabilities of their larger counterparts. In DSS, the distilled model acquires the ability to generate rationales and predict labels concurrently through a multi-task learning framework. However, DSS overlooks the intrinsic relationship between the two training tasks, leading to ineffective integration of CoT knowledge with the task of label prediction. To this end, we investigate the mutual relationship of the two tasks from Information Bottleneck perspective and formulate it as maximizing the mutual information of the representation features of the two tasks. We propose a variational approach to solve thi
    
[^47]: 大型语言模型在在线健康话语中挖掘新兴观点的范围

    Scope of Large Language Models for Mining Emerging Opinions in Online Health Discourse

    [https://arxiv.org/abs/2403.03336](https://arxiv.org/abs/2403.03336)

    本论文开发了一个由LLM驱动的框架，用于在在线健康社区中进行新兴观点挖掘，提出了一种新颖的Claim识别方法和观点挖掘驱动的评估框架，并发布了用于评估LLMs在在线健康社区中宣称识别和立场检测任务的新测试数据集。

    

    在这篇论文中，我们开发了一个由LLM驱动的框架，用于在在线健康社区中策划和评估新兴观点的挖掘。我们将新兴观点挖掘定义为来自Reddit的（标题，评论）配对间的两两立场检测问题，其中帖子标题包含未预定义话题的新兴健康相关声明。宣称可以由用户明确或隐含地表达。我们详细介绍了（i）宣称识别的方法--识别帖子标题是否包含宣称的任务；以及（ii）使用LLMs进行立场检测的观点挖掘驱动的评估框架。我们通过发布一个新颖的测试数据集Long COVID-Stance，或LC-stance，来促进我们的探索，该数据集可用于评估LLMs在在线健康社区中宣称识别和立场检测任务上的表现。长期COVID是一种新兴的COVID后疾病，治疗指南不确定且复杂，因此构成了一个复杂的问题。

    arXiv:2403.03336v1 Announce Type: new  Abstract: In this paper, we develop an LLM-powered framework for the curation and evaluation of emerging opinion mining in online health communities. We formulate emerging opinion mining as a pairwise stance detection problem between (title, comment) pairs sourced from Reddit, where post titles contain emerging health-related claims on a topic that is not predefined. The claims are either explicitly or implicitly expressed by the user. We detail (i) a method of claim identification -- the task of identifying if a post title contains a claim and (ii) an opinion mining-driven evaluation framework for stance detection using LLMs.   We facilitate our exploration by releasing a novel test dataset, Long COVID-Stance, or LC-stance, which can be used to evaluate LLMs on the tasks of claim identification and stance detection in online health communities. Long Covid is an emerging post-COVID disorder with uncertain and complex treatment guidelines, thus mak
    
[^48]: DIVERSE：通过视频评论态度分析解读互联网对美国军事的看法，一个用于立场分类的新颖基准数据集

    DIVERSE: Deciphering Internet Views on the U.S. Military Through Video Comment Stance Analysis, A Novel Benchmark Dataset for Stance Classification

    [https://arxiv.org/abs/2403.03334](https://arxiv.org/abs/2403.03334)

    本文提出了一个名为DIVERSE的数据集，其中包含超过173,000条YouTube视频评论，标注了这些评论对美国军事视频的立场，采用了一种通过人类引导、机器辅助的标注方法，使用了句子中的弱信号作为支持指标。

    

    社交媒体文本的立场检测是涉及识别在有争议主题上拥有相反观点的用户群组的下游任务的关键组成部分，如疫苗接种和争论中。具体来说，立场提供了对实体立场的指示。本文介绍了DIVERSE，这是一个包含对超过173,000个YouTube视频评论进行标注的数据集，标注了这些评论对于美国军事视频的立场。这些立场通过一种由人类引导、机器辅助的标注方法进行标注，该方法利用了句子中蕴含的语气弱信号作为支持指标，而非使用人类手动注释。这些弱信号包括仇恨言论和讽刺的存在，特定关键词的存在，文本的情感以及从两个大型语言模型中推断的立场。然后，在每个评论被注释之前，这些弱信号使用数据编程模型进行 consol

    arXiv:2403.03334v1 Announce Type: cross  Abstract: Stance detection of social media text is a key component of downstream tasks involving the identification of groups of users with opposing opinions on contested topics such as vaccination and within arguments. In particular, stance provides an indication of an opinion towards an entity. This paper introduces DIVERSE, a dataset of over 173,000 YouTube video comments annotated for their stance towards videos of the U.S. military. The stance is annotated through a human-guided, machine-assisted labeling methodology that makes use of weak signals of tone within the sentence as supporting indicators, as opposed to using manual annotations by humans. These weak signals consist of the presence of hate speech and sarcasm, the presence of specific keywords, the sentiment of the text, and the stance inference from two Large Language Models. The weak signals are then consolidated using a data programming model before each comment is annotated wit
    
[^49]: Guardrail Baselines for Unlearning in LLMs

    Guardrail Baselines for Unlearning in LLMs

    [https://arxiv.org/abs/2403.03329](https://arxiv.org/abs/2403.03329)

    简单的基于guardrail的方法如提示和过滤可以实现与fine-tuning相媲美的unlearning结果，建议研究人员在评估更消耗计算资源的fine-tuning方法时考虑这些轻量级基线。

    

    最近的研究表明fine-tuning是从大型语言模型中“unlearn”概念的一种有前途的方法。然而，fine-tuning可能很昂贵，因为它既需要生成一组示例，又需要运行多次迭代的fine-tuning来更新模型。在这项工作中，我们展示了简单的基于guardrail的方法，如提示和过滤，可以实现与fine-tuning相媲美的unlearning结果。我们建议研究人员在评估更消耗计算资源的fine-tuning方法的性能时，调查这些轻量级基线。虽然我们并不声称提示或过滤等方法是unlearning问题的通用解决方案，但我们的工作表明需要更好地区分guardrails与fine-tuning的强大之处的评估指标，并强调guardrails本身可能为unlearning具有优势的场景，例如生成示例用于fine-tuning或u

    arXiv:2403.03329v1 Announce Type: new  Abstract: Recent work has demonstrated that fine-tuning is a promising approach to `unlearn' concepts from large language models. However, fine-tuning can be expensive, as it requires both generating a set of examples and running iterations of fine-tuning to update the model. In this work, we show that simple guardrail-based approaches such as prompting and filtering can achieve unlearning results comparable to fine-tuning. We recommend that researchers investigate these lightweight baselines when evaluating the performance of more computationally intensive fine-tuning methods. While we do not claim that methods such as prompting or filtering are universal solutions to the problem of unlearning, our work suggests the need for evaluation metrics that can better separate the power of guardrails vs. fine-tuning, and highlights scenarios where guardrails themselves may be advantageous for unlearning, such as in generating examples for fine-tuning or u
    
[^50]: Book2Dial:从教科书中生成教师-学生互动，以实现教育聊天机器人的成本效益开发

    Book2Dial: Generating Teacher-Student Interactions from Textbooks for Cost-Effective Development of Educational Chatbots

    [https://arxiv.org/abs/2403.03307](https://arxiv.org/abs/2403.03307)

    本文提出了一个基于教科书生成合成教师-学生互动的框架，用于开发教育聊天机器人，展示了使用合成对话训练教育聊天机器人的好处，并比较了几种方法，但最佳数据综合方法仍存在幻觉和重复信息问题。

    

    教育聊天机器人是辅助学生学习的有前景的工具。然而，在教育领域，开发有效的聊天机器人一直是具有挑战性的，因为很少有高质量的数据可用。在本文中，我们提出了一个框架，用于生成基于一组教科书的合成教师-学生互动。我们的方法捕捉了学习互动的一个方面，即对材料产生兴趣的部分知识的学生与老师互动地向老师提出关于教科书中内容的问题。我们强调了这种对话应满足的各种质量标准，并比较了几种依赖于提示或对大型语言模型进行微调的方法。我们使用合成对话来训练教育聊天机器人，并展示了进一步在不同教育领域进行微调的好处。然而，人类评估表明，我们最佳的数据综合方法仍然存在幻觉，并且倾向于重复信息。

    arXiv:2403.03307v1 Announce Type: new  Abstract: Educational chatbots are a promising tool for assisting student learning. However, the development of effective chatbots in education has been challenging, as high-quality data is seldom available in this domain. In this paper, we propose a framework for generating synthetic teacher-student interactions grounded in a set of textbooks. Our approaches capture one aspect of learning interactions where curious students with partial knowledge interactively ask a teacher questions about the material in the textbook. We highlight various quality criteria that such dialogues should fulfill and compare several approaches relying on either prompting or fine-tuning large language models. We use synthetic dialogues to train educational chatbots and show benefits of further fine-tuning in different educational domains. However, human evaluation shows that our best data synthesis method still suffers from hallucinations and tends to reiterate informat
    
[^51]: 两全其美：一种灵活且通用的神经符号方法用于关系分类

    Best of Both Worlds: A Pliable and Generalizable Neuro-Symbolic Approach for Relation Classification

    [https://arxiv.org/abs/2403.03305](https://arxiv.org/abs/2403.03305)

    该论文介绍了一种将基于规则的方法与深度学习技术相结合的神经符号架构，通过神经组件提升规则泛化能力，实现了两种范式的优势，且在少样本关系分类数据集上取得了优于之前最先进模型的表现

    

    本文介绍了一种新颖的神经符号架构，用于关系分类（RC），将基于规则的方法与当代深度学习技术相结合。这种方法充分发挥了两种范式的优势：基于规则的系统的适应性和神经网络的泛化能力。我们的架构由两个组件组成：一个用于透明分类的声明性基于规则的模型，以及一个通过语义文本匹配增强规则泛化能力的神经组件。值得注意的是，我们的语义匹配器仅通过合成数据在无监督领域无关方式进行训练。此外，这些组件松散耦合，允许对规则进行修改而无需重新训练语义匹配器。在我们的评估中，我们专注于两个少样本关系分类数据集：Few-Shot TACRED 和 Few-Shot 版本的 NYT29。我们展示了我们提出的方法优于先前的最先进模型

    arXiv:2403.03305v1 Announce Type: cross  Abstract: This paper introduces a novel neuro-symbolic architecture for relation classification (RC) that combines rule-based methods with contemporary deep learning techniques. This approach capitalizes on the strengths of both paradigms: the adaptability of rule-based systems and the generalization power of neural networks. Our architecture consists of two components: a declarative rule-based model for transparent classification and a neural component to enhance rule generalizability through semantic text matching. Notably, our semantic matcher is trained in an unsupervised domain-agnostic way, solely with synthetic data. Further, these components are loosely coupled, allowing for rule modifications without retraining the semantic matcher. In our evaluation, we focused on two few-shot relation classification datasets: Few-Shot TACRED and a Few-Shot version of NYT29. We show that our proposed method outperforms previous state-of-the-art models 
    
[^52]: 所需只是 Mad Libs: 增强跨领域文档级事件参数数据

    Mad Libs Are All You Need: Augmenting Cross-Domain Document-Level Event Argument Data

    [https://arxiv.org/abs/2403.03304](https://arxiv.org/abs/2403.03304)

    Mad Libs 提供的数据增强方法 MLA 在跨领域文档级事件参数数据提取上取得了显著的性能提升，平均提高了 2.6 个 F1 分数。同时，在零和少样本事件角色方面相比无增强基线，提高了 3.9 和 5.2 个百分点。

    

    文档级事件参数提取（DocEAE）是一个极其困难的信息提取问题，尤其在低资源跨领域设置中存在着显著的局限性。为了解决这个问题，我们引入了 Mad Lib Aug（MLA），这是一个新颖的生成式 DocEAE 数据增强框架。我们的方法利用了 Mad Libs 的直觉，即作为一种热门游戏中使用的分类掩码文档可以被 LLMs 生成并解答，从而为 DocEAE 生成数据。使用 MLA，我们的整体 F1 分数平均改进了 2.6 个百分点。此外，与无增强基线相比，该方法在零和少样本事件角色方面在所有实验中平均提高了 3.9 和 5.2 个百分点。

    arXiv:2403.03304v1 Announce Type: new  Abstract: Document-Level Event Argument Extraction (DocEAE) is an extremely difficult information extraction problem -- with significant limitations in low-resource cross-domain settings. To address this problem, we introduce Mad Lib Aug (MLA), a novel generative DocEAE data augmentation framework. Our approach leverages the intuition that Mad Libs, which are categorically masked documents used as a part of a popular game, can be generated and solved by LLMs to produce data for DocEAE. Using MLA, we achieve a 2.6-point average improvement in overall F1 score. Moreover, this approach achieves a 3.9 and 5.2 point average increase in zero and few-shot event roles compared to augmentation-free baselines across all experiments.   To better facilitate analysis of cross-domain DocEAE, we additionally introduce a new metric, Role-Depth F1 (RDF1), which uses statistical depth to identify roles in the target domain which are semantic outliers with respect t
    
[^53]: 评估大型语言模型的文本生成SQL能力：全面评估

    Benchmarking the Text-to-SQL Capability of Large Language Models: A Comprehensive Evaluation

    [https://arxiv.org/abs/2403.02951](https://arxiv.org/abs/2403.02951)

    大型语言模型在文本生成SQL任务中表现出色，但对于最佳提示模板和设计框架仍无共识，新数据集和评估任务有助于全面评估各种方法的表现，并提出了优化解决方案。

    

    大型语言模型（LLMs）已经成为推动文本生成SQL任务的强大工具，明显优于传统方法。然而，作为一个新兴的研究领域，对于最佳提示模板和设计框架仍然没有达成共识。

    arXiv:2403.02951v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have emerged as a powerful tool in advancing the Text-to-SQL task, significantly outperforming traditional methods. Nevertheless, as a nascent research field, there is still no consensus on the optimal prompt templates and design frameworks. Additionally, existing benchmarks inadequately explore the performance of LLMs across the various sub-tasks of the Text-to-SQL process, which hinders the assessment of LLMs' cognitive capabilities and the optimization of LLM-based solutions.To address the aforementioned issues, we firstly construct a new dataset designed to mitigate the risk of overfitting in LLMs. Then we formulate five evaluation tasks to comprehensively assess the performance of diverse methods across various LLMs throughout the Text-to-SQL process.Our study highlights the performance disparities among LLMs and proposes optimal in-context learning solutions tailored to each task. These findings offer
    
[^54]: OffLanDat：通过提示工程生成的大型语言模型生成的社区基础隐式攻击性语言数据集

    OffLanDat: A Community Based Implicit Offensive Language Dataset Generated by Large Language Model Through Prompt Engineering

    [https://arxiv.org/abs/2403.02472](https://arxiv.org/abs/2403.02472)

    介绍了一个通过提示工程生成的大型语言模型创建的社区基础隐式攻击性语言数据集OffLanDat，为38个不同目标群体提供数据。

    

    社交媒体上攻击性语言的普遍存在对社会福祉产生了不良影响。因此，有必要高度重视解决这一问题。攻击性语言既存在明确形式，也存在隐式形式，后者更具挑战性。当前在该领域的研究遇到几个挑战。首先，现有数据集主要依赖于收集包含明确攻击性关键词的文本，这使得捕捉不包含这些关键词且隐含攻击性内容的任务具有挑战性。其次，通常的方法论倾向于仅关注文本分析，忽视社区信息可以提供的宝贵见解。在这篇研究论文中，我们介绍了一个新的数据集OffLanDat，这是由ChatGPT生成的基于社区的隐式攻击性语言数据集，其中包含38个不同目标群体的数据。

    arXiv:2403.02472v1 Announce Type: new  Abstract: The widespread presence of offensive languages on social media has resulted in adverse effects on societal well-being. As a result, it has become very important to address this issue with high priority. Offensive languages exist in both explicit and implicit forms, with the latter being more challenging to detect. Current research in this domain encounters several challenges. Firstly, the existing datasets primarily rely on the collection of texts containing explicit offensive keywords, making it challenging to capture implicitly offensive contents that are devoid of these keywords. Secondly, usual methodologies tend to focus solely on textual analysis, neglecting the valuable insights that community information can provide. In this research paper, we introduce a novel dataset OffLanDat, a community based implicit offensive language dataset generated by ChatGPT containing data for 38 different target groups. Despite limitations in genera
    
[^55]: NeuroVoz：帕金森病患者语音的卡斯蒂利亚语语料库

    NeuroVoz: a Castillian Spanish corpus of parkinsonian speech

    [https://arxiv.org/abs/2403.02371](https://arxiv.org/abs/2403.02371)

    这一研究提出了一个包含108位母语为卡斯蒂利亚语说话者的帕金森病患者语音语料库，涵盖了多种语音任务，通过手动和自动转录确保了数据的准确性和可靠性。

    

    通过语音分析进行帕金森病（PD）诊断的进展受到公开可用、多样化的语言数据集的显著缺乏的阻碍，限制了现有研究结果的可再现性和进一步探索。为了弥补这一空白，我们引入了一个全面的语料库，包括来自108位母语为卡斯蒂利亚语的说话者，包括55名健康对照组和53名被诊断患有PD的个体，所有这些个体都在药物治疗下，并且在药物优化状态下进行记录。 这一独特数据集涵盖了广泛的语音任务，包括持续发音五个西班牙元音、发音测试、16个听后重复的话语以及自由独白。该数据集通过专家手动转录听后重复任务强调准确性和可靠性，并利用Whisper进行自动独白转录，使其成为帕金森病患者语音的最完整的公开语料库。

    arXiv:2403.02371v1 Announce Type: cross  Abstract: The advancement of Parkinson's Disease (PD) diagnosis through speech analysis is hindered by a notable lack of publicly available, diverse language datasets, limiting the reproducibility and further exploration of existing research.   In response to this gap, we introduce a comprehensive corpus from 108 native Castilian Spanish speakers, comprising 55 healthy controls and 53 individuals diagnosed with PD, all of whom were under pharmacological treatment and recorded in their medication-optimized state. This unique dataset features a wide array of speech tasks, including sustained phonation of the five Spanish vowels, diadochokinetic tests, 16 listen-and-repeat utterances, and free monologues. The dataset emphasizes accuracy and reliability through specialist manual transcriptions of the listen-and-repeat tasks and utilizes Whisper for automated monologue transcriptions, making it the most complete public corpus of Parkinsonian speech, 
    
[^56]: 硅谷人群的智慧：LLM集成预测能力达到人群准确率水平

    Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Match Human Crowd Accuracy

    [https://arxiv.org/abs/2402.19379](https://arxiv.org/abs/2402.19379)

    该研究通过将十二个LLMs组成的LLM集成方法与925名人类预测者的群体预测进行比较，发现LLM群体优于简单的无信息基准，并在统计上等效于人类群体。

    

    实践中人类预测准确性依赖于“群体智慧”效应，即通过聚合一群个体预测者的预测可以显著提高对未来事件的预测。过去关于大型语言模型（LLMs）预测能力的研究表明，作为个体预测者的前沿LLMs表现不佳，与人类群体预测比赛的黄金标准相比。我们通过使用一个由十二个LLMs组成的LLM集成方法，扩展了研究。我们将31个二元问题的聚合LLM预测与一个来自三个月预测比赛的925名人类预测者的群体预测进行比较。我们的主要分析表明，LLM群体的表现优于简单的无信息基准，并在统计上等效于人类群体。我们还观察到一种顺从效应，平均模型预测明显高于50%，尽管几乎是平等的。

    arXiv:2402.19379v1 Announce Type: cross  Abstract: Human forecasting accuracy in practice relies on the 'wisdom of the crowd' effect, in which predictions about future events are significantly improved by aggregating across a crowd of individual forecasters. Past work on the forecasting ability of large language models (LLMs) suggests that frontier LLMs, as individual forecasters, underperform compared to the gold standard of a human crowd forecasting tournament aggregate. In Study 1, we expand this research by using an LLM ensemble approach consisting of a crowd of twelve LLMs. We compare the aggregated LLM predictions on 31 binary questions to that of a crowd of 925 human forecasters from a three-month forecasting tournament. Our main analysis shows that the LLM crowd outperforms a simple no-information benchmark and is statistically equivalent to the human crowd. We also observe an acquiescence effect, with mean model predictions being significantly above 50%, despite an almost even
    
[^57]: 用于满足多样用户偏好的算术控制LLMs：具有多目标奖励的方向偏好对齐

    Arithmetic Control of LLMs for Diverse User Preferences: Directional Preference Alignment with Multi-Objective Rewards

    [https://arxiv.org/abs/2402.18571](https://arxiv.org/abs/2402.18571)

    提出了方向偏好对齐（DPA）框架，通过多目标奖励模拟不同偏好配置，以实现用户相关的偏好控制。

    

    针对大型语言模型（LLMs）的精细控制仍然是一个重要挑战，阻碍了它们适应各种用户需求。本文提出了方向偏好对齐（DPA）框架，通过多目标奖励建模来表示多样化的偏好配置，将用户偏好建模为奖励空间中的方向（即单位向量）以实现用户相关的偏好控制。

    arXiv:2402.18571v1 Announce Type: cross  Abstract: Fine-grained control over large language models (LLMs) remains a significant challenge, hindering their adaptability to diverse user needs. While Reinforcement Learning from Human Feedback (RLHF) shows promise in aligning LLMs, its reliance on scalar rewards often limits its ability to capture diverse user preferences in real-world applications. To address this limitation, we introduce the Directional Preference Alignment (DPA) framework. Unlike the scalar-reward RLHF, DPA incorporates multi-objective reward modeling to represent diverse preference profiles. Additionally, DPA models user preferences as directions (i.e., unit vectors) in the reward space to achieve user-dependent preference control. Our method involves training a multi-objective reward model and then fine-tuning the LLM with a preference-conditioned variant of Rejection Sampling Finetuning (RSF), an RLHF method adopted by Llama 2. This method enjoys a better performance
    
[^58]: 关于在信息提取中利用银标准数据进行零样本分类任务的研究

    On the use of Silver Standard Data for Zero-shot Classification Tasks in Information Extraction

    [https://arxiv.org/abs/2402.18061](https://arxiv.org/abs/2402.18061)

    本研究提出了一个新框架Clean-LaVe，旨在利用银标准数据来增强零样本分类性能。

    

    在信息提取（IE）领域，监督分类方法的卓越性能严重依赖于大量的黄金标准数据。最近的零样本分类方法将任务转化为其他NLP任务（例如，文本蕴涵），并使用这些NLP任务的现成模型直接对测试数据进行推理，而无需使用大量的IE注释数据。这些方法的一个潜在有价值的副产品是大规模的银标准数据，即其他NLP任务的现成模型生成的伪标记数据。然而，对于这些数据的利用并没有进一步的研究。本文提出了一个新框架Clean-LaVe，旨在利用银标准数据来增强零样本分类性能。Clean-LaVe包括四个阶段：（1）获取银标准数据；（2）从银标准数据中识别相对干净的数据；（3）使用干净数据微调现成模型；

    arXiv:2402.18061v1 Announce Type: cross  Abstract: The superior performance of supervised classification methods in the information extraction (IE) area heavily relies on a large amount of gold standard data. Recent zero-shot classification methods converted the task to other NLP tasks (e.g., textual entailment) and used off-the-shelf models of these NLP tasks to directly perform inference on the test data without using a large amount of IE annotation data. A potentially valuable by-product of these methods is the large-scale silver standard data, i.e., pseudo-labeled data by the off-the-shelf models of other NLP tasks. However, there is no further investigation into the use of these data. In this paper, we propose a new framework, Clean-LaVe, which aims to utilize silver standard data to enhance the zero-shot performance. Clean-LaVe includes four phases: (1) Obtaining silver data; (2) Identifying relatively clean data from silver data; (3) Finetuning the off-the-shelf model using clea
    
[^59]: GraphWiz：用于图问题的指令跟随语言模型

    GraphWiz: An Instruction-Following Language Model for Graph Problems

    [https://arxiv.org/abs/2402.16029](https://arxiv.org/abs/2402.16029)

    GraphWiz是一个开源语言模型，通过引入指令调优数据集和直接偏好优化框架，能够高效解决各种图问题类型，平均准确率达到65%，超过了GPT-4的43.8%。

    

    大型语言模型（LLMs）在多个领域取得了令人印象深刻的成功，但它们在理解和解决复杂图问题方面的能力尚未得到充分探索。为弥合这一差距，我们引入了GraphInstruct，这是一个新颖而全面的指令调优数据集，旨在为语言模型提供处理各种图问题的能力，利用明确的推理路径。利用GraphInstruct，我们构建了GraphWiz，这是一个能够解决各种图问题类型并生成清晰推理过程的开源语言模型。为增强模型的能力和可靠性，我们将直接偏好优化（DPO）框架纳入图问题求解环境中。增强模型GraphWiz-DPO在九个具有不同复杂性水平的任务中取得了65%的平均准确率，超过了平均准确率为43.8%的GPT-4。此外，我们的研究深入探讨了...

    arXiv:2402.16029v1 Announce Type: new  Abstract: Large language models (LLMs) have achieved impressive success across several fields, but their proficiency in understanding and resolving complex graph problems is less explored. To bridge this gap, we introduce GraphInstruct, a novel and comprehensive instruction-tuning dataset designed to equip language models with the ability to tackle a broad spectrum of graph problems using explicit reasoning paths. Utilizing GraphInstruct, we build GraphWiz, an open-source language model capable of resolving various graph problem types while generating clear reasoning processes. To enhance the model's capability and reliability, we incorporate the Direct Preference Optimization (DPO) framework into the graph problem-solving context. The enhanced model, GraphWiz-DPO, achieves an average accuracy of 65% across nine tasks with different complexity levels, surpassing GPT-4 which has an average accuracy of 43.8%. Moreover, our research delves into the d
    
[^60]: Noise-BERT: 一种具有噪声对齐预训练的统一扰动鲁棒性框架，用于嘈杂的槽填充任务

    Noise-BERT: A Unified Perturbation-Robust Framework with Noise Alignment Pre-training for Noisy Slot Filling Task

    [https://arxiv.org/abs/2402.14494](https://arxiv.org/abs/2402.14494)

    提出了Noise-BERT框架，包含噪声对齐预训练任务，通过对比学习损失和对抗攻击训练策略，以提高在嘈杂环境下的槽填充任务表现。

    

    在现实对话系统中，用户输入信息经常遭受各种类型的输入扰动，这影响了槽填充任务。尽管基于规则的数据增强方法已经取得了令人满意的结果，但当面对未知噪声干扰时，它们无法展现出期望的泛化能力。在本研究中，我们通过提出Noise-BERT来解决槽填充中输入扰动带来的挑战，这是一个具有噪声对齐预训练的统一扰动鲁棒性框架。我们的框架包含两个Noise Alignment预训练任务：槽屏蔽预测和句子嘈杂度判别，旨在引导预训练语言模型捕捉准确的槽信息和噪声分布。在微调过程中，我们采用对比学习损失来增强实体和标签的语义表示。此外，我们引入了对抗攻击训练策略以提高语义表示的鲁棒性。

    arXiv:2402.14494v1 Announce Type: new  Abstract: In a realistic dialogue system, the input information from users is often subject to various types of input perturbations, which affects the slot-filling task. Although rule-based data augmentation methods have achieved satisfactory results, they fail to exhibit the desired generalization when faced with unknown noise disturbances. In this study, we address the challenges posed by input perturbations in slot filling by proposing Noise-BERT, a unified Perturbation-Robust Framework with Noise Alignment Pre-training. Our framework incorporates two Noise Alignment Pre-training tasks: Slot Masked Prediction and Sentence Noisiness Discrimination, aiming to guide the pre-trained language model in capturing accurate slot information and noise distribution. During fine-tuning, we employ a contrastive learning loss to enhance the semantic representation of entities and labels. Additionally, we introduce an adversarial attack training strategy to i
    
[^61]: $\texttt{Se}^2$: $\textit{Se}$quential Example $\textit{Se}$lection for In-Context Learning

    $\texttt{Se}^2$: $\textit{Se}$quential Example $\textit{Se}$lection for In-Context Learning

    [https://arxiv.org/abs/2402.13874](https://arxiv.org/abs/2402.13874)

    本文提出了$\texttt{Se}^2$，一种顺序感知方法，利用大型语言模型的反馈帮助捕捉示例之间的相互关系和序列信息，显著丰富了上下文学习提示的相关性和相关性。

    

    众所周知，大型语言模型（LLMs）在上下文学习（ICL）中具有出色的能力，但需要通过示例示范来激活。以往的研究广泛探讨了用于ICL的示例选择，主要遵循“先选择再组织”的范式，这些方法往往忽视示例之间的内在关系，存在训练和推理之间的不一致性。本文将问题表述为一个序贯选择问题，并引入$\texttt{Se}^2$，这是一种顺序感知方法，利用LLM对不同上下文的反馈，有助于捕捉示例之间的相互关系和序列信息，显著丰富ICL提示的上下文相关性和相关性。同时，我们利用束搜索来寻找和构建示例序列，增强了质量和多样性。我们在8个不同类别中的23个NLP任务上进行了大量实验

    arXiv:2402.13874v1 Announce Type: new  Abstract: The remarkable capability of large language models (LLMs) for in-context learning (ICL) needs to be activated by demonstration examples. Prior work has extensively explored the selection of examples for ICL, predominantly following the "select then organize" paradigm, such approaches often neglect the internal relationships between examples and exist an inconsistency between the training and inference. In this paper, we formulate the problem as a $\textit{se}$quential $\textit{se}$lection problem and introduce $\texttt{Se}^2$, a sequential-aware method that leverages the LLM's feedback on varying context, aiding in capturing inter-relationships and sequential information among examples, significantly enriching the contextuality and relevance of ICL prompts. Meanwhile, we utilize beam search to seek and construct example sequences, enhancing both quality and diversity. Extensive experiments across 23 NLP tasks from 8 distinct categories i
    
[^62]: GUARD: 通过角色扮演生成自然语言越狱来测试大型语言模型遵循指南的合规性

    GUARD: Role-playing to Generate Natural-language Jailbreakings to Test Guideline Adherence of Large Language Models

    [https://arxiv.org/abs/2402.03299](https://arxiv.org/abs/2402.03299)

    本论文提出了一个通过角色扮演的系统，可以生成自然语言越狱，用于测试大型语言模型的指南遵循情况。系统通过收集现有越狱并将其组织成知识图来生成新的越狱，证明了其高效性和有效性。

    

    发现绕过大型语言模型（LLM）的安全过滤和有害回应的"越狱"已经鼓励社区采取安全措施。其中一个主要的安全措施是在发布之前用越狱主动测试LLM。因此，这样的测试将需要一种能够大规模且高效地生成越狱的方法。本文在追随一种新颖而直观的策略下，以人类生成的方式来生成越狱。我们提出了一个角色扮演系统，将四种不同角色分配给用户LLM，以便协作生成新的越狱。此外，我们收集现有的越狱，并通过句子逐句进行聚类频率和语义模式的划分，将它们分成不同的独立特征。我们将这些特征组织成一个知识图，使其更易于访问和检索。我们的角色系统将利用这个知识图来生成新的越狱，证明了其有效性。

    The discovery of "jailbreaks" to bypass safety filters of Large Language Models (LLMs) and harmful responses have encouraged the community to implement safety measures. One major safety measure is to proactively test the LLMs with jailbreaks prior to the release. Therefore, such testing will require a method that can generate jailbreaks massively and efficiently. In this paper, we follow a novel yet intuitive strategy to generate jailbreaks in the style of the human generation. We propose a role-playing system that assigns four different roles to the user LLMs to collaborate on new jailbreaks. Furthermore, we collect existing jailbreaks and split them into different independent characteristics using clustering frequency and semantic patterns sentence by sentence. We organize these characteristics into a knowledge graph, making them more accessible and easier to retrieve. Our system of different roles will leverage this knowledge graph to generate new jailbreaks, which have proved effec
    
[^63]: 英文提示比目标语言提示更适用于基于NLI的零-shot情绪分类

    English Prompts are Better for NLI-based Zero-Shot Emotion Classification than Target-Language Prompts

    [https://arxiv.org/abs/2402.03223](https://arxiv.org/abs/2402.03223)

    本研究填补了一个研究空白，探讨了在非英文文本中应该使用哪种语言来提示情绪标签。

    

    文本情绪分类是一个具有挑战性和主观性的任务，由于需要进行认知推论过程来解释文字刺激。此外，情绪类别集合高度依赖于特定领域。例如，文学分析可能需要使用审美情感（例如，发现某物美丽），而社交媒体分析则可以从细粒度的集合中获取好处（例如，将愤怒与烦恼分开），与基本情绪类别相对应。这使得该任务成为了零-shot分类的一个有趣领域，在这种分类中，模型开发时不知道标签集合。不幸的是，大多数情绪分析资源都是英文的，因此，情绪分析的大部分研究都是用英文进行的，包括那些涉及使用提示语言模型的研究。这给我们留下一个研究空白，我们在本文中探讨：在非英文文本中，我们应该用哪种语言提示情绪标签？

    Emotion classification in text is a challenging and subjective task, due to the involved cognitive inference processes that are required to interpret a textual stimulus. In addition, the set of emotion categories is highly domain-specific. For instance, literature analysis might require the use of aesthetic emotions (e.g., finding something beautiful), and social media analysis could benefit from fine-grained sets (e.g., separating anger from annoyance) in contrast to basic emotion categories. This renders the task an interesting field for zero-shot classifications, in which the label set is not known at model development time. Unfortunately, most resources for emotion analysis are English, and therefore, most studies on emotion analysis have been performed in English, including those that involve prompting language models for text labels. This leaves us with a research gap that we address in this paper: In which language should we prompt for emotion labels on non-English texts? This i
    
[^64]: 将认知任务整合到大型模型的人工通用智能测试中

    Integration of cognitive tasks into artificial general intelligence test for large models

    [https://arxiv.org/abs/2402.02547](https://arxiv.org/abs/2402.02547)

    建议将认知任务整合到大型模型的人工通用智能测试中，以建立一个综合框架，能够评估大型模型的多维智能。这个框架结合了认知科学和自然语言处理，包含了稳态智力、流态智力和社交智能等方面。

    

    在大型模型的发展过程中，必须对中间模型进行性能评估以评估其能力，并对经过充分训练的模型进行安全性评估，以确保在实际应用之前的安全性。然而，当前的模型评估主要依赖于特定任务和数据集，缺乏对大型模型的多维智能评估的统一框架。在这个视角中，我们提倡建立一个人工通用智能测试的综合框架，旨在满足大型语言模型和多模态大型模型的测试需求，以提高其能力。该人工通用智能测试框架将认知科学和自然语言处理联系起来，包括智力的各个方面，包括稳态智力，即积累的知识和经验的反映; 流态智力，特点是解决问题和适应性推理; 社交智能，表示在多方面理解和适应的能力。

    During the evolution of large models, performance evaluation is necessarily performed on the intermediate models to assess their capabilities, and on the well-trained model to ensure safety before practical application. However, current model evaluations mainly rely on specific tasks and datasets, lacking a united framework for assessing the multidimensional intelligence of large models. In this perspective, we advocate for a comprehensive framework of artificial general intelligence (AGI) test, aimed at fulfilling the testing needs of large language models and multi-modal large models with enhanced capabilities. The AGI test framework bridges cognitive science and natural language processing to encompass the full spectrum of intelligence facets, including crystallized intelligence, a reflection of amassed knowledge and experience; fluid intelligence, characterized by problem-solving and adaptive reasoning; social intelligence, signifying comprehension and adaptation within multifacete
    
[^65]: LOCOST: 长文档抽象摘要化的状态空间模型

    LOCOST: State-Space Models for Long Document Abstractive Summarization

    [https://arxiv.org/abs/2401.17919](https://arxiv.org/abs/2401.17919)

    LOCOST是一种基于状态空间模型的编码器-解码器架构，用于处理长文档的抽象摘要生成。与基于稀疏注意模式的最先进模型相比，LOCOST具有更低的计算复杂度，并且能够在训练和推断期间节省大量内存。在评估中，LOCOST在长文档摘要化任务上达到了93-96%的性能水平，并且能够处理超过600K个标记的输入文本。

    

    状态空间模型是编码长序列和捕捉长期依赖的低复杂度替代方案，我们提出了LOCOST：一种基于状态空间模型的编码器-解码器架构，用于具有长上下文输入的条件文本生成。这种架构的计算复杂度为O（L log L），可以处理比基于稀疏注意模式的最先进模型更长的序列。我们在一系列长文档抽象摘要化任务上评估了我们的模型。该模型在性能水平上达到了与相同大小的最优稀疏变压器相当的93-96%，同时在训练期间节省了高达50%的内存，在推断期间节省了高达87%的内存。此外，LOCOST有效地处理超过600K个标记的输入文本，为完整书摘要化设定了新的最新结果，并为长输入处理开辟了新的视角。

    State-space models are a low-complexity alternative to transformers for encoding long sequences and capturing long-term dependencies. We propose LOCOST: an encoder-decoder architecture based on state-space models for conditional text generation with long context inputs. With a computational complexity of $O(L \log L)$, this architecture can handle significantly longer sequences than state-of-the-art models that are based on sparse attention patterns. We evaluate our model on a series of long document abstractive summarization tasks. The model reaches a performance level that is 93-96% comparable to the top-performing sparse transformers of the same size while saving up to 50% memory during training and up to 87% during inference. Additionally, LOCOST effectively handles input texts exceeding 600K tokens at inference time, setting new state-of-the-art results on full-book summarization and opening new perspectives for long input processing.
    
[^66]: MedLM: 探索用于医疗问答系统的语言模型

    MedLM: Exploring Language Models for Medical Question Answering Systems

    [https://arxiv.org/abs/2401.11389](https://arxiv.org/abs/2401.11389)

    本研究比较了用于医疗问答的通用和医学特定的精炼语言模型的表现，以填补领域特定任务中这些模型性能的研究空白。

    

    面对迅速扩大的在线医学文献，自动化系统用于聚合和总结信息对于医疗保健专业人员和患者变得日益关键。大型语言模型（LLM）以其先进的生成能力在各种自然语言处理任务中显示出潜力，它们在医疗领域的潜力，特别是在封闭式生成问答方面，是显著的。然而，这些模型在医学问答等领域特定任务中的性能仍然较少被探索。本研究旨在通过比较通用和专门用于医学的精炼语言模型在医疗问答中的表现来填补这一空白。我们旨在评估微调领域特定语言模型的效果，并比较不同类型语言模型的性能。本研究将探讨这些模型的可靠性、比较性能和在医疗问答背景下的有效性等关键问题。

    arXiv:2401.11389v2 Announce Type: replace-cross  Abstract: In the face of rapidly expanding online medical literature, automated systems for aggregating and summarizing information are becoming increasingly crucial for healthcare professionals and patients. Large Language Models (LLMs), with their advanced generative capabilities, have shown promise in various NLP tasks, and their potential in the healthcare domain, particularly for Closed-Book Generative QnA, is significant. However, the performance of these models in domain-specific tasks such as medical Q&A remains largely unexplored. This study aims to fill this gap by comparing the performance of general and medical-specific distilled LMs for medical Q&A. We aim to evaluate the effectiveness of fine-tuning domain-specific LMs and compare the performance of different families of Language Models. The study will address critical questions about these models' reliability, comparative performance, and effectiveness in the context of me
    
[^67]: SceneVerse：为基于场景的场景理解扩展3D视觉-语言学习

    SceneVerse: Scaling 3D Vision-Language Learning for Grounded Scene Understanding

    [https://arxiv.org/abs/2401.09340](https://arxiv.org/abs/2401.09340)

    本研究通过系统性地扩展室内环境中的3D视觉-语言学习，提出了首个百万规模的3D视觉-语言数据集SceneVerse，以解决3D视觉-语言对齐面临的几个重要挑战。

    

    3D视觉-语言对齐，即将语言与3D物理环境对齐，是发展具身体能力的智能体的基石。与2D领域最近的进展相比，将语言与3D场景对齐面临着几个重要挑战：（i）3D场景固有复杂性，由于多样的物体配置、丰富的属性和错综复杂的关系；（ii）支持基于场景学习的配对3D视觉-语言数据的稀缺性；以及（iii）缺乏从基于场景的3D数据中提炼知识的统一学习框架。在这项工作中，我们旨在通过系统地扩展室内环境中的3D视觉-语言学习，从而解决3D视觉-语言领域中的这三大挑战。我们介绍首个百万规模的3D视觉-语言数据集SceneVerse，包含约68K个3D室内场景，包括250万个视觉语言

    arXiv:2401.09340v2 Announce Type: replace-cross  Abstract: 3D vision-language grounding, which focuses on aligning language with the 3D physical environment, stands as a cornerstone in the development of embodied agents. In comparison to recent advancements in the 2D domain, grounding language in 3D scenes faces several significant challenges: (i) the inherent complexity of 3D scenes due to the diverse object configurations, their rich attributes, and intricate relationships; (ii) the scarcity of paired 3D vision-language data to support grounded learning; and (iii) the absence of a unified learning framework to distill knowledge from grounded 3D data. In this work, we aim to address these three major challenges in 3D vision-language by examining the potential of systematically upscaling 3D vision-language learning in indoor environments. We introduce the first million-scale 3D vision-language dataset, SceneVerse, encompassing about 68K 3D indoor scenes and comprising 2.5M vision-langu
    
[^68]: 在大型语言模型上进行间接提示注入攻击的基准测试和防御

    Benchmarking and Defending Against Indirect Prompt Injection Attacks on Large Language Models

    [https://arxiv.org/abs/2312.14197](https://arxiv.org/abs/2312.14197)

    该研究引入了第一个间接提示注入攻击基准测试BIPIA，对大型语言模型在面对此类攻击时的风险进行评估，并分析了攻击成功的原因，从而开发了防御方法。

    

    大型语言模型（LLMs）与外部内容的整合已经实现了LLMs的更新和广泛应用，比如微软Copilot。然而，这种整合也让LLMs面临了间接提示注入攻击的风险，攻击者可以在外部内容中嵌入恶意指令，从而ompromising LLM输出并导致响应偏离用户期望。为了研究这个重要但未被充分探讨的问题，我们引入了第一个间接提示注入攻击基准测试BIPIA，以评估这类攻击的风险。基于评估，我们的工作重点分析了该攻击成功的潜在原因，即LLMs无法区分指令和外部内容以及缺乏意识不执行外部内容内的指令。基于这一分析，我们开发了两种黑盒方法。

    arXiv:2312.14197v2 Announce Type: replace-cross  Abstract: The integration of large language models (LLMs) with external content has enabled more up-to-date and wide-ranging applications of LLMs, such as Microsoft Copilot. However, this integration has also exposed LLMs to the risk of indirect prompt injection attacks, where an attacker can embed malicious instructions within external content, compromising LLM output and causing responses to deviate from user expectations. To investigate this important but underexplored issue, we introduce the first benchmark for indirect prompt injection attacks, named BIPIA, to evaluate the risk of such attacks. Based on the evaluation, our work makes a key analysis of the underlying reason for the success of the attack, namely the inability of LLMs to distinguish between instructions and external content and the absence of LLMs' awareness to not execute instructions within external content. Building upon this analysis, we develop two black-box metho
    
[^69]: 通过语言模型算术实现控制文本生成

    Controlled Text Generation via Language Model Arithmetic

    [https://arxiv.org/abs/2311.14479](https://arxiv.org/abs/2311.14479)

    该论文提出了一种模型算术推断框架，可以在不重新训练模型或使用高度特定数据集的情况下构成和偏置大型语言模型，实现比直接提示和先前受控文本生成技术更精确的文本生成控制。

    

    随着大型语言模型（LLMs）的广泛部署，定制词汇、风格和字符变得越来越重要。在这项工作中，我们介绍了模型算术，这是一种新颖的推断框架，可以在不需要模型（重新）训练或高度特定数据集的情况下构成和偏置LLMs。此外，该框架允许比直接提示和先前的受控文本生成（CTG）技术更精确地控制生成的文本。使用模型算术，我们可以将先前的CTG技术表示为简单的公式，并自然地将其扩展到新的和更有效的公式。此外，我们展示了一种称为推测采样的高效LLM采样技术，可以扩展到我们的设置。这使得使用多个组合模型进行高效文本生成几乎没有超过单个模型的额外开销。我们的实证评估表明，模型算术允许对生成进行精细控制。

    arXiv:2311.14479v2 Announce Type: replace  Abstract: As Large Language Models (LLMs) are deployed more widely, customization with respect to vocabulary, style, and character becomes more important. In this work, we introduce model arithmetic, a novel inference framework for composing and biasing LLMs without the need for model (re)training or highly specific datasets. In addition, the framework allows for more precise control of generated text than direct prompting and prior controlled text generation (CTG) techniques. Using model arithmetic, we can express prior CTG techniques as simple formulas and naturally extend them to new and more effective formulations. Further, we show that speculative sampling, a technique for efficient LLM sampling, extends to our setting. This enables highly efficient text generation with multiple composed models with only marginal overhead over a single model. Our empirical evaluation demonstrates that model arithmetic allows fine-grained control of genera
    
[^70]: AdaCCD:基于自适应语义对比发现的跨语言适应方法用于代码克隆检测

    AdaCCD: Adaptive Semantic Contrasts Discovery Based Cross Lingual Adaptation for Code Clone Detection

    [https://arxiv.org/abs/2311.07277](https://arxiv.org/abs/2311.07277)

    AdaCCD是一种跨语言适应方法，通过自适应的对比学习框架和预训练编程语言模型提取语言无关的代码表示，实现了在没有目标语言注释的情况下检测新语言中的克隆代码。

    

    代码克隆检测旨在从大型代码库中检索功能相似的程序，一直受到越来越多的关注。现代软件通常涉及各种编程语言。然而，由于缺乏注释数据以及自身模型设计限制，当前的代码克隆检测方法通常仅限于几种流行的编程语言。为了解决这些问题，我们提出了AdaCCD，一种新颖的跨语言适应方法，可以在不使用目标语言注释的情况下检测新语言中的克隆代码。AdaCCD利用来自预训练的编程语言模型的语言无关代码表示，并提出了一种自适应精制对比学习框架，从资源丰富的语言向资源匮乏的语言传递知识。我们通过构建多语言代码克隆检测基准来评估AdaCCD的跨语言适应结果。

    arXiv:2311.07277v2 Announce Type: replace-cross  Abstract: Code Clone Detection, which aims to retrieve functionally similar programs from large code bases, has been attracting increasing attention. Modern software often involves a diverse range of programming languages. However, current code clone detection methods are generally limited to only a few popular programming languages due to insufficient annotated data as well as their own model design constraints. To address these issues, we present AdaCCD, a novel cross-lingual adaptation method that can detect cloned codes in a new language without annotations in that language. AdaCCD leverages language-agnostic code representations from pre-trained programming language models and propose an Adaptively Refined Contrastive Learning framework to transfer knowledge from resource-rich languages to resource-poor languages. We evaluate the cross-lingual adaptation results of AdaCCD by constructing a multilingual code clone detection benchmark
    
[^71]: 我的大数据中有什么？

    What's In My Big Data?

    [https://arxiv.org/abs/2310.20707](https://arxiv.org/abs/2310.20707)

    通过提出的平台和分析方法，我们揭示和比较了大型文本语料库的内容，发现了关于语料库内容的几个令人惊讶且以前未被记录的发现。

    

    大型文本语料库是语言模型的基础。然而，我们对这些语料库的内容，包括一般统计信息、质量、社会因素和评估数据（污染）的理解有限。在这项工作中，我们提出了“What's In My Big Data?”（WIMBD），这是一个平台和一组十六个分析方法，使我们能够揭示和比较大型文本语料库的内容。WIMBD基于两种基本能力——计数和搜索——在规模上进行，这使我们能够在标准计算节点上分析超过35TB的数据。我们将WIMBD应用于用于训练流行语言模型的十个不同语料库，包括C4、The Pile和RedPajama。我们的分析揭示了关于这些语料库的几个令人惊讶且以前未记录的发现，包括重复内容、合成内容、低质量内容、个人可识别信息、有毒语言和基准污染的高流行率。

    arXiv:2310.20707v2 Announce Type: replace  Abstract: Large text corpora are the backbone of language models. However, we have a limited understanding of the content of these corpora, including general statistics, quality, social factors, and inclusion of evaluation data (contamination). In this work, we propose What's In My Big Data? (WIMBD), a platform and a set of sixteen analyses that allow us to reveal and compare the contents of large text corpora. WIMBD builds on two basic capabilities -- count and search -- at scale, which allows us to analyze more than 35 terabytes on a standard compute node. We apply WIMBD to ten different corpora used to train popular language models, including C4, The Pile, and RedPajama. Our analysis uncovers several surprising and previously undocumented findings about these corpora, including the high prevalence of duplicate, synthetic, and low-quality content, personally identifiable information, toxic language, and benchmark contamination. For instance,
    
[^72]: 基于LLM的智能体社会行为研究：Avalon游戏中的协作与对抗

    LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay

    [https://arxiv.org/abs/2310.14985](https://arxiv.org/abs/2310.14985)

    本文提出了一个新颖的框架，旨在无缝适应Avalon游戏，通过多智能体系统实现了有效的沟通和互动，评估了智能体的性能和社会行为，展示了LLM智能体在游戏中具有潜力。

    

    本文旨在研究揭示基于LLM的智能体社会行为的开放性研究问题。为达到这一目标，我们采用了Avalon作为代表性的沟通游戏环境，并使用系统提示引导LLM智能体进行游戏。虽然先前的研究已经进行了关于LLM智能体的游戏玩法的初步研究，但是他们的社会行为仍缺乏研究。本文提出了一个新颖的框架，旨在无缝适应Avalon游戏。我们提出的框架的核心是一个多智能体系统，可以实现智能体之间的有效沟通和互动。我们根据两个角度的度量标准评估了我们框架的性能：赢得游戏和更分析LLM智能体的社会行为。我们的结果展示了我们的框架在生成自适应和智能智能体方面的有效性，并突显了LLM智能体在应对中的潜力。

    arXiv:2310.14985v2 Announce Type: replace  Abstract: This paper aims to investigate the open research problem of uncovering the social behaviors of LLM-based agents. To achieve this goal, we adopt Avalon, a representative communication game, as the environment and use system prompts to guide LLM agents to play the game. While previous studies have conducted preliminary investigations into gameplay with LLM agents, there lacks research on their social behaviors. In this paper, we present a novel framework designed to seamlessly adapt to Avalon gameplay. The core of our proposed framework is a multi-agent system that enables efficient communication and interaction among agents. We evaluate the performance of our framework based on metrics from two perspectives: winning the game and analyzing the social behaviors of LLM agents. Our results demonstrate the effectiveness of our framework in generating adaptive and intelligent agents and highlight the potential of LLM-based agents in address
    
[^73]: Chat Vector：一种简单的方法，在新语言中为LLMs提供指令遵循和模型对齐

    Chat Vector: A Simple Approach to Equip LLMs with Instruction Following and Model Alignment in New Languages

    [https://arxiv.org/abs/2310.04799](https://arxiv.org/abs/2310.04799)

    提出了聊天向量的概念，通过简单的模型算术使预训练语言模型具备在新语言中遵循指令和实现模型对齐的能力

    

    最近，开源大型语言模型（LLMs）的发展迅速。尽管如此，由于数据约束，大多数开源LLM的能力主要集中在英语上。为了解决这个问题，我们引入了聊天向量的概念，通过简单的模型算术为预训练的语言模型提供指令遵循和人类价值对齐。聊天向量是通过将预训练基础模型（例如LLaMA2）的权重减去其对应的聊天模型（例如LLaMA2-chat）的权重得出的。通过简单地将聊天向量添加到持续预训练模型的权重中，我们可以使模型在新语言中具有聊天能力，而无需进一步训练。我们的实证研究展示了聊天向量在三个不同方面的优越有效性：指令遵循、毒性缓解和多轮对话。此外，为了展示我们方法的适应性

    arXiv:2310.04799v2 Announce Type: replace  Abstract: Recently, the development of open-source large language models (LLMs) has advanced rapidly. Nevertheless, due to data constraints, the capabilities of most open-source LLMs are primarily focused on English. To address this issue, we introduce the concept of chat vector to equip pre-trained language models with instruction following and human value alignment via simple model arithmetic. The chat vector is derived by subtracting the weights of a pre-trained base model (e.g. LLaMA2) from those of its corresponding chat model (e.g. LLaMA2-chat). By simply adding the chat vector to a continual pre-trained model's weights, we can endow the model with chat capabilities in new languages without the need for further training. Our empirical studies demonstrate the superior efficacy of the chat vector from three different aspects: instruction following, toxicity mitigation, and multi-turn dialogue. Moreover, to showcase the adaptability of our 
    
[^74]: 使用大型开源语言模型进行立场分类的提示和微调

    Prompting and Fine-Tuning Open-Sourced Large Language Models for Stance Classification

    [https://arxiv.org/abs/2309.13734](https://arxiv.org/abs/2309.13734)

    本研究探讨了使用大型语言模型作为立场检测方法以减少手动注释的需求，发现它们与域内监督模型具有竞争力，但性能不一致。

    

    立场分类是一个长期以来研究重点领域，从社会科学到机器学习领域，这项任务涉及预测作者对感兴趣主题的观点。当前的立场检测方法主要依赖于手动注释句子，然后训练监督式机器学习模型。然而，这种手动注释过程需要大量的注释工作，因此限制了它在不同环境中泛化的潜力。在这项工作中，我们调查了大型语言模型（LLMs）作为一种可以减少甚至消除手动注释需求的立场检测方法。我们研究了10个开源模型和7种提示方案，发现LLMs在与域内监督模型具竞争力，但性能并不一定一致。我们还进行了LLMs的微调，但发现微调过程不必然

    arXiv:2309.13734v2 Announce Type: replace-cross  Abstract: Stance classification, the task of predicting the viewpoint of an author on a subject of interest, has long been a focal point of research in domains ranging from social science to machine learning. Current stance detection methods rely predominantly on manual annotation of sentences, followed by training a supervised machine learning model. However, this manual annotation process requires laborious annotation effort, and thus hampers its potential to generalize across different contexts. In this work, we investigate the use of Large Language Models (LLMs) as a stance detection methodology that can reduce or even eliminate the need for manual annotations. We investigate 10 open-source models and 7 prompting schemes, finding that LLMs are competitive with in-domain supervised models but are not necessarily consistent in their performance. We also fine-tuned the LLMs, but discovered that fine-tuning process does not necessarily l
    
[^75]: SelectLLM：LLMs能否选择重要的指令进行注释？

    SelectLLM: Can LLMs Select Important Instructions to Annotate?. (arXiv:2401.16553v1 [cs.CL])

    [http://arxiv.org/abs/2401.16553](http://arxiv.org/abs/2401.16553)

    这项工作提出了一种名为SelectLLM的新方法，利用LLMs选择高质量指令。通过提示LLMs估计每个无标签指令的有用性和影响力，并使用聚类算法将指令分为多个聚类。

    

    使用大量且多样化的指令数据集训练大型语言模型(LLMs)可以使模型理解和遵循人类指令。最近的研究表明，使用一小组高质量的指令可以超过使用大量更嘈杂的指令。由于指令是无标签的，且响应是自然文本，传统的主动学习方案无法直接应用于选择无标签指令。在这项工作中，我们提出了一种新的指令选择方法，称为SelectLLM，它利用LLMs选择高质量指令。我们的高级思想是利用LLMs通过提示来估计每个指令在没有相应标签（即响应）的情况下的有用性和影响力。SelectLLM包括两个步骤：使用聚类算法（例如CoreSet）将无标签指令划分为多个聚类，然后提示LLMs在其中选择高质量指令。

    Training large language models (LLMs) with a large and diverse instruction dataset aligns the models to comprehend and follow human instructions. Recent works have shown that using a small set of high-quality instructions can outperform using large yet more noisy ones. Because instructions are unlabeled and their responses are natural text, traditional active learning schemes with the model's confidence cannot be directly applied to the selection of unlabeled instructions. In this work, we propose a novel method for instruction selection, called SelectLLM, that leverages LLMs for the selection of high-quality instructions. Our high-level idea is to use LLMs to estimate the usefulness and impactfulness of each instruction without the corresponding labels (i.e., responses), via prompting. SelectLLM involves two steps: dividing the unlabelled instructions using a clustering algorithm (e.g., CoreSet) to multiple clusters, and then prompting LLMs to choose high-quality instructions within e
    
[^76]: Q&A提示：通过挖掘问题-回答提示来发现丰富的视觉线索，以满足对多样世界知识的视觉问答的需求

    Q&A Prompts: Discovering Rich Visual Clues through Mining Question-Answer Prompts for VQA requiring Diverse World Knowledge. (arXiv:2401.10712v1 [cs.CV])

    [http://arxiv.org/abs/2401.10712](http://arxiv.org/abs/2401.10712)

    本论文提出了一种叫做Q&A提示的方法，通过挖掘图像中的问题-回答对来发现丰富的视觉线索，以帮助AI模型更好地理解复杂视觉问题，提高跨模态推理能力。

    

    随着多模态大型语言模型的突破，回答需要高级推理能力和世界知识的复杂视觉问题比以往任何时候都更重要。然而，为AI模型配备强大的跨模态推理能力仍然具有挑战性，因为人类的认知方案尚未系统地被理解。在本文中，我们相信，如果我们能尽可能收集给定图像中的视觉线索，我们将能更准确地识别图像，更好地理解问题，更容易回忆相关知识，并最终推理出答案。我们通过在图像中挖掘问题-回答对来发现这些丰富的视觉线索，并将它们作为提示发送到多模态大型语言模型中。我们称之为Q&A提示的方法。具体而言，我们首先使用训练集中的图像-答案对和相应的问题作为输入和输出来训练一个视觉问题生成模型。

    With the breakthrough of multi-modal large language models, answering complex visual questions that demand advanced reasoning abilities and world knowledge has become a much more important testbed for developing AI models than ever. However, equipping AI models with robust cross-modality reasoning ability remains challenging since the cognition scheme of humans has not been understood systematically. In this paper, we believe that if we can collect visual clues in the given image as much as possible, we will recognize the image more accurately, understand the question better, recall relevant knowledge more easily, and finally reason out the answer. We discover these rich visual clues by mining question-answer pairs in images and sending them into multi-modal large language models as prompts. We call the proposed method Q&A Prompts. Specifically, we first use the image-answer pairs and the corresponding questions in the training set as inputs and outputs to train a visual question gener
    
[^77]: DevEval: 评估实际软件项目中的代码生成

    DevEval: Evaluating Code Generation in Practical Software Projects. (arXiv:2401.06401v1 [cs.SE])

    [http://arxiv.org/abs/2401.06401](http://arxiv.org/abs/2401.06401)

    本文提出了一个名为DevEval的新基准测试，用于评估实际软件项目中的代码生成。与之前的基准测试相比，DevEval在真实的项目分布、充足的依赖和足够规模的项目背景等方面更贴合实际。通过对五个流行的大型语言模型进行评估，我们揭示了它们在代码生成中的实际能力。

    

    如何评估大型语言模型（LLMs）在代码生成中的表现是一个开放的问题。许多基准测试已经提出，但是与实际软件项目不一致，例如虚构的程序分布，依赖不足和小规模项目背景。因此，LLMs在实际项目中的能力还不清楚。在本文中，我们提出了一个名为DevEval的新基准测试，与开发人员在实际项目中的经验相吻合。DevEval通过一个严格的流程收集到了来自119个实际项目的2690个样本，涵盖10个领域。与之前的基准测试相比，DevEval在多个维度上与实际项目相吻合，例如真实的程序分布，充足的依赖和足够规模的项目背景。我们在DevEval上评估了五个流行的LLMs（例如gpt-4，gpt-3.5-turbo，CodeLLaMa和StarCoder），并揭示了它们在代码生成中的实际能力。例如，gpt-3.5-turbo的最高Pass@1只有42。

    How to evaluate Large Language Models (LLMs) in code generation is an open question. Many benchmarks have been proposed but are inconsistent with practical software projects, e.g., unreal program distributions, insufficient dependencies, and small-scale project contexts. Thus, the capabilities of LLMs in practical projects are still unclear. In this paper, we propose a new benchmark named DevEval, aligned with Developers' experiences in practical projects. DevEval is collected through a rigorous pipeline, containing 2,690 samples from 119 practical projects and covering 10 domains. Compared to previous benchmarks, DevEval aligns to practical projects in multiple dimensions, e.g., real program distributions, sufficient dependencies, and enough-scale project contexts. We assess five popular LLMs on DevEval (e.g., gpt-4, gpt-3.5-turbo, CodeLLaMa, and StarCoder) and reveal their actual abilities in code generation. For instance, the highest Pass@1 of gpt-3.5-turbo only is 42 in our experim
    
[^78]: GoLLIE:注释指南提高了零样本信息抽取

    GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction. (arXiv:2310.03668v1 [cs.CL])

    [http://arxiv.org/abs/2310.03668](http://arxiv.org/abs/2310.03668)

    GoLLIE 是一个遵循注释指南的大型语言模型，通过微调以改进未见信息抽取任务的零样本结果。

    

    大型语言模型 (LLMs) 结合指导调优已经在泛化到未见任务方面取得了显著进展。然而，在信息抽取 (IE) 方面，它们的表现较差，落后于任务特定模型。通常，IE 任务的特点是复杂的注释指南，描述任务并给出示例给人类。先前利用这样的信息的尝试都失败了，即使使用最大的模型，它们也不能直接遵循指南。在本文中，我们提出了针对信息抽取的指南遵循大型语言模型 GoLLIE (Guideline-following Large Language Model for IE)，该模型通过微调以遵守注释指南，从而能够改进未见 IE 任务的零样本结果。全面的评估实证表明，GoLLIE 能够泛化并遵循未见指南，在零样本信息抽取方面优于先前的尝试。消融研究表明，详细的指南是取得良好结果的关键。

    Large Language Models (LLMs) combined with instruction tuning have made significant progress when generalizing to unseen tasks. However, they have been less successful in Information Extraction (IE), lagging behind task-specific models. Typically, IE tasks are characterized by complex annotation guidelines which describe the task and give examples to humans. Previous attempts to leverage such information have failed, even with the largest models, as they are not able to follow the guidelines out-of-the-box. In this paper we propose GoLLIE (Guideline-following Large Language Model for IE), a model able to improve zero-shot results on unseen IE tasks by virtue of being fine-tuned to comply with annotation guidelines. Comprehensive evaluation empirically demonstrates that GoLLIE is able to generalize to and follow unseen guidelines, outperforming previous attempts at zero-shot information extraction. The ablation study shows that detailed guidelines is key for good results.
    
[^79]: OATS: 观点方面目标情感四元组抽取数据集用于面向方面的情感分析

    OATS: Opinion Aspect Target Sentiment Quadruple Extraction Dataset for Aspect-Based Sentiment Analysis. (arXiv:2309.13297v1 [cs.CL])

    [http://arxiv.org/abs/2309.13297](http://arxiv.org/abs/2309.13297)

    OATS数据集是一个全新的观点方面目标情感四元组抽取数据集，它解决了面向方面的情感分析中的领域限制和数据粒度挑战，并填补了餐馆和笔记本电脑等常见领域的数据不足和句子与评论级情感之间的协同作用问题。

    

    面向方面的情感分析（ABSA）旨在理解文本内容中特定要素的情感。它旨在分析用户生成的评论，确定a) 被评论的目标实体，b) 它所属的高级方面，c) 用于表达观点的情感词，d) 对目标和方面表达的情感。尽管各种基准数据集推动了ABSA的进展，但它们往往带来领域限制和数据粒度挑战。为了解决这些问题，我们介绍了OATS数据集，该数据集涵盖了三个全新的领域，并包含20,000个句子级四元组和13,000个评论级元组。我们的目标是填补一些特定的观察到的差距：对熟悉领域（如餐馆和笔记本电脑）的反复关注，用于复杂四元组抽取任务的有限数据，以及偶尔忽视句子和评论级情感之间的协同作用。此外，为了阐明OATS的潜在能力，

    Aspect-based sentiment Analysis (ABSA) delves into understanding sentiments specific to distinct elements within textual content. It aims to analyze user-generated reviews to determine a) the target entity being reviewed, b) the high-level aspect to which it belongs, c) the sentiment words used to express the opinion, and d) the sentiment expressed toward the targets and the aspects. While various benchmark datasets have fostered advancements in ABSA, they often come with domain limitations and data granularity challenges. Addressing these, we introduce the OATS dataset, which encompasses three fresh domains and consists of 20,000 sentence-level quadruples and 13,000 review-level tuples. Our initiative seeks to bridge specific observed gaps: the recurrent focus on familiar domains like restaurants and laptops, limited data for intricate quadruple extraction tasks, and an occasional oversight of the synergy between sentence and review-level sentiments. Moreover, to elucidate OATS's pote
    
[^80]: 追求多模态视觉语言模型中的基于实际的视觉空间推理

    Towards Grounded Visual Spatial Reasoning in Multi-Modal Vision Language Models. (arXiv:2308.09778v1 [cs.CV])

    [http://arxiv.org/abs/2308.09778](http://arxiv.org/abs/2308.09778)

    本文旨在研究多模态视觉语言模型在理解空间关系方面的能力，提出了细粒度组合的空间关系基础，并采用自底向上的方法评估空间关系推理任务的性能。

    

    随着大规模视觉和语言模型（VLMs）的进展，评估它们在各种视觉推理任务（如计数、指涉表达和一般的视觉问题回答）上的表现变得越来越重要。本文的重点是研究这些模型理解空间关系的能力。先前，人们尝试使用图像-文本匹配（Liu, Emerson, and Collier 2022) 或视觉问题回答任务来处理此问题，但都表现出性能不佳并且与人类性能存在较大差距。为了更好地理解差距，我们提出了细粒度组合的空间关系基础，并提出了一种自底向上的方法来对空间从句进行排名并评估空间关系推理任务的性能。我们建议通过结合和地面化物体对应的名词短语和它们的位置的证据来计算空间从句的最终排名。我们在代表性的视觉语言模型上展示了这种方法。

    With the advances in large scale vision-and-language models (VLMs) it is of interest to assess their performance on various visual reasoning tasks such as counting, referring expressions and general visual question answering. The focus of this work is to study the ability of these models to understanding spatial relations. Previously, this has been tackled using image-text matching (Liu, Emerson, and Collier 2022) or visual question answering task, both showing poor performance and a large gap compared to human performance. To better understand the gap, we present fine-grained compositional grounding of spatial relationships and propose a bottom up approach for ranking spatial clauses and evaluating the performance of spatial relationship reasoning task. We propose to combine the evidence from grounding noun phrases corresponding to objects and their locations to compute the final rank of the spatial clause. We demonstrate the approach on representative vision-language models (Tan and 
    
[^81]: 使用语言模型进行算术运算：从记忆到计算

    Arithmetic with Language Models: from Memorization to Computation. (arXiv:2308.01154v1 [cs.AI])

    [http://arxiv.org/abs/2308.01154](http://arxiv.org/abs/2308.01154)

    本研究探索了使用语言模型进行算术计算的能力，发现语言模型可以通过内部的值空间进行计算，并取得了成功的实验结果。

    

    更好地理解最近的大型语言模型的出现性计算和问题解决能力对于进一步改进它们并拓宽其适用性至关重要。本研究探讨了一个训练用于预测下一个标记的语言模型如何在训练数据之外执行算术计算。二进制加法和乘法是一个很好的测试基础，因为它们需要一个非常小的词汇表，并且在输入/输出上展示了相关的不连续性，使得对新数据进行平滑的输入插值无效。我们成功地训练了一个轻量级的语言模型来学习这些任务，并进行了一系列实验证明其外推能力和内部信息处理。我们的研究结果支持这样一个假设，即语言模型作为一个编码-回归-解码机器，一旦将输入标记表示映射到合适的内部值空间，计算就在值空间中进行。

    A better understanding of the emergent computation and problem-solving capabilities of recent large language models is of paramount importance to further improve them and broaden their applicability. This work investigates how a language model, trained to predict the next token, can perform arithmetic computations generalizing beyond training data. Binary addition and multiplication constitute a good testbed for this purpose, since they require a very small vocabulary and exhibit relevant input/output discontinuities making smooth input interpolation ineffective for novel data. We successfully trained a light language model to learn these tasks and ran a number of experiments to investigate the extrapolation capabilities and internal information processing. Our findings support the hypotheses that the language model works as an Encoding-Regression-Decoding machine where the computation takes place in the value space once the input token representation is mapped to an appropriate intern
    
[^82]: 可解释的推理方法用于刻板印象识别

    Interpretable Stereotype Identification through Reasoning. (arXiv:2308.00071v1 [cs.CL])

    [http://arxiv.org/abs/2308.00071](http://arxiv.org/abs/2308.00071)

    本研究通过使用推理方法，在零射击刻板印象识别中取得了重要的进展，并发现推理的性能增益远远超过模型规模扩展的增益。推理不仅提高了准确性，还提高了决策的可解释性。

    

    鉴于语言模型训练使用了包含固有偏见的大量数据集，可能会不经意地持续系统性歧视，因此，审查和解决语言模型中的偏见变得至关重要，将公平性整合到它们的发展中，以确保这些模型具有公正和无偏的特性。在这项工作中，我们展示了基于Vicuna-13B-v1.3的零射击刻板印象识别中推理的重要性。尽管我们观察到从13B到33B的规模扩展会提高准确性，但我们表明推理的性能增益远远超过规模扩展的增益。我们的研究结果表明，推理可能是使LLMs在刻板印象等领域任务上超越规模定律的关键因素。此外，通过对选定的推理追踪进行定性分析，我们突出显示了推理不仅提高了准确性，还提高了决策的可解释性。

    Given that language models are trained on vast datasets that may contain inherent biases, there is a potential danger of inadvertently perpetuating systemic discrimination. Consequently, it becomes essential to examine and address biases in language models, integrating fairness into their development to ensure these models are equitable and free from bias. In this work, we demonstrate the importance of reasoning in zero-shot stereotype identification based on Vicuna-13B-v1.3. While we do observe improved accuracy by scaling from 13B to 33B, we show that the performance gain from reasoning significantly exceeds the gain from scaling up. Our findings suggest that reasoning could be a key factor that enables LLMs to trescend the scaling law on out-of-domain tasks such as stereotype identification. Additionally, through a qualitative analysis of select reasoning traces, we highlight how reasoning enhances not just accuracy but also the interpretability of the decision.
    
[^83]: BERTTM: 利用来自预训练语言模型的上下文化词向量进行神经主题建模

    BERTTM: Leveraging Contextualized Word Embeddings from Pre-trained Language Models for Neural Topic Modeling. (arXiv:2305.09329v1 [cs.CL])

    [http://arxiv.org/abs/2305.09329](http://arxiv.org/abs/2305.09329)

    本文提出了一种新颖的神经主题模型，利用来自预训练语言模型BERT的上下文化词嵌入，可以在不使用任何BoW信息的情况下推断出文档的主题分布，并直接从上下文化词嵌入中推断出文档中每个单词的主题分布。实验结果表明，该模型优于仅依赖BoW表示和其他神经主题模型的现有最先进方法。

    

    随着近年来神经主题模型的发展，主题建模在自然语言理解中扮演着日益重要的角色。然而，大多数现有的主题模型仍然依赖于词袋（BoW）信息，无论是作为训练输入还是训练目标。这限制了它们捕捉文档中的单词顺序信息的能力，并导致它们在处理新文档中的未观察到的单词时遇到困难。预训练语言模型中的上下文化词向量在词义消歧的能力上表现优越，并证明了它们在处理OOV单词时是有效的。在这项工作中，我们开发了一种新颖的神经主题模型，结合了预训练语言模型BERT的上下文化词嵌入。该模型可以在不使用任何BoW信息的情况下推断出文档的主题分布。此外，该模型可以直接从上下文化词嵌入中推断出文档中每个单词的主题分布。基准数据集的实验表明，我们的模型优于仅依赖BoW表示和其他神经主题模型的现有最先进方法。

    With the development of neural topic models in recent years, topic modelling is playing an increasingly important role in natural language understanding. However, most existing topic models still rely on bag-of-words (BoW) information, either as training input or training target. This limits their ability to capture word order information in documents and causes them to suffer from the out-of-vocabulary (OOV) issue, i.e. they cannot handle unobserved words in new documents. Contextualized word embeddings from pre-trained language models show superiority in the ability of word sense disambiguation and prove to be effective in dealing with OOV words. In this work, we developed a novel neural topic model combining contextualized word embeddings from the pre-trained language model BERT. The model can infer the topic distribution of a document without using any BoW information. In addition, the model can infer the topic distribution of each word in a document directly from the contextualize
    
[^84]: SIFT: 稀疏等FLOP转换以最大限度提高训练效率

    SIFT: Sparse Iso-FLOP Transformations for Maximizing Training Efficiency. (arXiv:2303.11525v1 [cs.LG])

    [http://arxiv.org/abs/2303.11525](http://arxiv.org/abs/2303.11525)

    本研究提出了一种名为SIFT的方法，用于提高深度神经网络的训练效率、准确性和表示能力，通过稀疏等FLOP转换，缩短训练时间。

    

    最近的研究探索了使用权重稀疏性来改善深度神经网络（DNN）的训练效率（与训练FLOPS相关的测试准确性）。 这些工作旨在减少训练FLOP，但使用稀疏权重进行训练通常会导致准确性损失或需要更长的训练周期，使得结果的训练效率不够清晰。 相比之下，我们专注于使用稀疏性提高准确性，同时使用与密集模型相同的FLOPS，并通过更高的准确性展示训练效率提高。 在本文中，我们介绍了SIFT，一组用作密集层的即插即用替代品来提高其表示能力和FLOP效率的稀疏等FLOP转换。 每个转换都由一个单一参数（稀疏级别）参数化，并提供更大的搜索空间以找到最佳的稀疏掩膜。

    Recent works have explored the use of weight sparsity to improve the training efficiency (test accuracy w.r.t training FLOPs) of deep neural networks (DNNs). These works aim to reduce training FLOPs but training with sparse weights often leads to accuracy loss or requires longer train schedules, making the resulting training efficiency less clear. In contrast, we focus on using sparsity to increase accuracy while using the same FLOPS as the dense model and show training efficiency gains through higher accuracy. In this work, we introduce SIFT, a family of Sparse Iso-FLOP Transformations which are used as drop-in replacements for dense layers to improve their representational capacity and FLOP efficiency. Each transformation is parameterized by a single parameter (sparsity level) and provides a larger search space to find optimal sparse masks. Without changing any training hyperparameters, replacing dense layers with SIFT leads to significant improvements across computer vision (CV) and
    
[^85]: 量子密度矩阵在经典问答和图像分类中的应用

    Application of Quantum Density Matrix in Classical Question Answering and Classical Image Classification. (arXiv:2203.11155v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.11155](http://arxiv.org/abs/2203.11155)

    该论文将量子密度矩阵应用于经典问答和图像分类中，证明了其可以提高任务的效率，尤其在图像分类中取得了优秀的性能表现。

    

    量子密度矩阵可表示整个量子系统的全部信息，将密度矩阵用于经典问答任务可以更加有效地实现问题回答。本论文设计了一种基于LSTM的新机制，以应对输入为矩阵的情况，并将该机制应用于卷积神经网络进行QA问题的求解，同时也证明了量子密度矩阵可以增强经典图像分类中的特征信息和特征之间的关系。实验结果表明，该新框架在CIFAR-10数据集上的性能优于传统的基于CNN的分类方法。

    Quantum density matrix represents all the information of the entire quantum system, and novel models of meaning employing density matrices naturally model linguistic phenomena such as hyponymy and linguistic ambiguity, among others in quantum question answering tasks. Naturally, we argue that applying the quantum density matrix into classical Question Answering (QA) tasks can show more effective performance. Specifically, we (i) design a new mechanism based on Long Short-Term Memory (LSTM) to accommodate the case when the inputs are matrixes; (ii) apply the new mechanism to QA problems with Convolutional Neural Network (CNN) and gain the LSTM-based QA model with the quantum density matrix. Experiments of our new model on TREC-QA and WIKI-QA data sets show encouraging results. Similarly, we argue that the quantum density matrix can also enhance the image feature information and the relationship between the features for the classical image classification. Thus, we (i) combine density mat
    

