# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Dynamic ASR Pathways: An Adaptive Masking Approach Towards Efficient Pruning of A Multilingual ASR Model.](http://arxiv.org/abs/2309.13018) | 本研究提出了一种自适应掩蔽方法，用于高效地压缩多语种ASR模型。该方法通过动态适应子网络结构，能够在减少性能损失的情况下得到稀疏的单语种模型或稀疏的多语种模型。实验证明，与现有的修剪方法相比，该方法在针对稀疏的单语种模型时表现更好，并且减少了对特定语言进行修剪的需求。 |
| [^2] | [ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs.](http://arxiv.org/abs/2309.13007) | ReConcile是一个通过多轮讨论和投票机制来增强LLM推理能力的多模型多代理框架。 |
| [^3] | [Audience-specific Explanations for Machine Translation.](http://arxiv.org/abs/2309.12998) | 该论文提出了一种针对机器翻译的针对特定观众的解释方法，通过从平行语料库中提取示例解释来解决翻译中的文化差异问题。实验结果表明，该方法能够有效提高句子中包含解释的比例。 |
| [^4] | [Nested Event Extraction upon Pivot Element Recogniton.](http://arxiv.org/abs/2309.12960) | 本文提出了一种名为PerNee的新模型，通过识别中心元素来提取嵌套事件。该模型解决了现有NEE方法无法处理中心元素双重身份的问题，并通过提示学习将事件类型和参数角色的信息纳入其中，以提高NEE性能。 |
| [^5] | [Self-Explanation Prompting Improves Dialogue Understanding in Large Language Models.](http://arxiv.org/abs/2309.12940) | 本研究提出了一种自解释提示策略，可显著提高大型语言模型在多轮对话中的理解能力，实验证实其在复杂对话任务中的有效性。 |
| [^6] | [TopRoBERTa: Topology-Aware Authorship Attribution of Deepfake Texts.](http://arxiv.org/abs/2309.12934) | 本论文提出了一种拓扑感知的深伪文本作者识别方法TopRoBERTa，通过捕捉深伪文本中的更多语言模式，改进了现有的作者识别解决方案。 |
| [^7] | [On Separate Normalization in Self-supervised Transformers.](http://arxiv.org/abs/2309.12931) | 在自监督变形器中，通过为标记和[CLS]符号分别使用归一化层，可以更好地捕捉它们各自的特点并提高下游任务的性能。 |
| [^8] | [ProtoEM: A Prototype-Enhanced Matching Framework for Event Relation Extraction.](http://arxiv.org/abs/2309.12892) | 本论文提出了一种原型加强匹配框架（ProtoEM）用于联合抽取多种类型的事件关系。该框架通过获取每种类型的事件关系的原型表示，并利用图神经网络匹配这些关系，从而全面理解它们的内在语义。 |
| [^9] | [Affect Recognition in Conversations Using Large Language Models.](http://arxiv.org/abs/2309.12881) | 本研究探讨了使用大型语言模型（LLMs）识别对话中人类情感的能力，并对开放领域闲聊对话和任务导向对话进行了评估。研究结果表明，LLMs具有零样本和少样本能力，并且通过上下文学习和任务特定微调可以提高模型性能。 |
| [^10] | [AnglE-Optimized Text Embeddings.](http://arxiv.org/abs/2309.12871) | 本文提出了一种名为AnglE的角度优化文本嵌入模型，通过在复杂空间中引入角度优化来缓解文本嵌入中余弦函数饱和区域造成的梯度消失问题。该模型在多个STS任务中实现了高质量的文本嵌入，并在有限标签数据的特定领域STS场景中展现出优秀的性能。 |
| [^11] | [Domain Adaptation for Arabic Machine Translation: The Case of Financial Texts.](http://arxiv.org/abs/2309.12863) | 这项研究旨在探索领域适应对阿拉伯机器翻译在金融领域的效果，并通过开发平行语料库进行了试验。结果显示，领域适应方法对于提高阿拉伯机器翻译的性能具有积极的影响。 |
| [^12] | [Synthetic Boost: Leveraging Synthetic Data for Enhanced Vision-Language Segmentation in Echocardiography.](http://arxiv.org/abs/2309.12829) | 本研究探讨了使用合成数据集来增强超声心动图分割的视觉-语言分割模型（VLSM），结果显示合成数据集可以提高分割模型的指标和训练速度。 |
| [^13] | [StyloMetrix: An Open-Source Multilingual Tool for Representing Stylometric Vectors.](http://arxiv.org/abs/2309.12810) | StyloMetrix是一个开源的多语言工具，可以提供覆盖语法、句法和词汇等各个方面的文体文本表示。它的归一化输出可用于机器学习模型的训练，并可作为深度学习算法嵌入层的有价值补充。实验证明，StyloMetrix向量在内容分类和嵌入层增强方面的应用具有潜力。 |
| [^14] | [ChatPRCS: A Personalized Support System for English Reading Comprehension based on ChatGPT.](http://arxiv.org/abs/2309.12808) | 本研究提出了一种基于ChatGPT的个性化英语阅读理解辅助系统ChatPRCS。通过利用大型语言模型的先进能力，该系统采用阅读理解能力预测、问题生成、自动评估等方法来增强阅读理解教学。使用学生的历史数据来预测阅读理解能力，并生成适当难度的问题。辅助系统提供了个体化的阅读理解训练支持。 |
| [^15] | [Furthest Reasoning with Plan Assessment: Stable Reasoning Path with Retrieval-Augmented Large Language Models.](http://arxiv.org/abs/2309.12767) | 本文提出了一种名为FuRePA的新的MHQA流水线，通过改进的fra算法解决了现有方法中信息检索器受到LLMs生成查询质量低和LLMs被IR提供的无关知识误导的问题。 |
| [^16] | [Reduce, Reuse, Recycle: Is Perturbed Data better than Other Language augmentation for Low Resource Self-Supervised Speech Models.](http://arxiv.org/abs/2309.12763) | 使用音频增强为低资源自我监督语音模型的预训练提出一种有效的方法，并且综合增强（噪声/音高）是最佳的增强策略，超过了重音和语言知识转移。 |
| [^17] | [In-context Interference in Chat-based Large Language Models.](http://arxiv.org/abs/2309.12727) | 本文研究了聊天式大型语言模型中的上下文干扰问题，发现模型在上下文中持续流动的信息之间可能会遭受干扰，导致遗忘之前学到的知识，降低性能。 |
| [^18] | [Semantic similarity prediction is better than other semantic similarity measures.](http://arxiv.org/abs/2309.12697) | 本文提出了一种使用经过微调的模型直接预测语义相似性的方法，并将其与其他方法进行比较，结果表明所得到的相似性更加符合我们对鲁棒的语义相似性度量的预期。 |
| [^19] | [AMPLIFY:Attention-based Mixup for Performance Improvement and Label Smoothing in Transformer.](http://arxiv.org/abs/2309.12689) | AMPLIFY提出了一种基于注意力机制的Mixup方法，用于减少原始样本中的噪音和异常值对于模型的影响，并在文本分类任务中表现出更好的性能。 |
| [^20] | [JCoLA: Japanese Corpus of Linguistic Acceptability.](http://arxiv.org/abs/2309.12676) | 本文介绍了JCoLA（日本语言可接受性语料库），该语料库包含10,020个句子，用于评估不同类型的日语语言模型的句法知识。 |
| [^21] | [HRoT: Hybrid prompt strategy and Retrieval of Thought for Table-Text Hybrid Question Answering.](http://arxiv.org/abs/2309.12669) | 本文介绍了一种新的混合提示策略和检索思路，用于解决表-文本混合问答任务。该方法通过上下文学习，使模型具备处理混合数据的检索思考能力，并在MultiHiertt数据集上的少样本设置下取得了优越性能。 |
| [^22] | [Decoding Affect in Dyadic Conversations: Leveraging Semantic Similarity through Sentence Embedding.](http://arxiv.org/abs/2309.12646) | 本研究通过利用句子嵌入和语义相似性，解码了双人对话中的情感，并发现在冲突对话中，妻子的情感与语义相似性呈正相关。 |
| [^23] | [Construction contract risk identification based on knowledge-augmented language model.](http://arxiv.org/abs/2309.12626) | 本文提出了一种基于增强语言模型的建筑合同风险识别方法，利用具备建筑合同知识的大型语言模型模拟人类专家的合同审查过程。该方法无需调整，能够识别建筑合同风险，并在真实环境中取得了良好性能。 |
| [^24] | [DRG-LLaMA : Tuning LLaMA Model to Predict Diagnosis-related Group for Hospitalized Patients.](http://arxiv.org/abs/2309.12625) | DRG-LLaMA是一个通过在临床笔记上细调的大型语言模型，用于改进住院患者的诊断相关分组预测。在多个评估指标上，DRG-LLaMA-7B相对于其他模型取得了显著的改进，并能够高准确度地预测基本DRG和并发症/合并症（CC）/重大并发症或合并症（MCC）的状态。 |
| [^25] | [Learning to Diversify Neural Text Generation via Degenerative Model.](http://arxiv.org/abs/2309.12619) | 我们通过训练两个模型，一个放大不良模式，一个增强多样性，来解决神经文本生成中多样性不足的问题。实验证明了我们方法的有效性。 |
| [^26] | [Unlocking Model Insights: A Dataset for Automated Model Card Generation.](http://arxiv.org/abs/2309.12616) | 该论文介绍了一个包含25个ML模型的数据集，用于自动生成模型卡片。实验发现目前存在的指令模型在研究论文的理解和生成准确文本方面存在显著差距。 |
| [^27] | [Creativity Support in the Age of Large Language Models: An Empirical Study Involving Emerging Writers.](http://arxiv.org/abs/2309.12570) | 本文通过实证研究探讨了大型语言模型（LLM）在协助专业作家方面的效用，并发现作家们更倾向于在翻译和审查阶段中寻求LLM的帮助。 |
| [^28] | [PlanFitting: Tailoring Personalized Exercise Plans with Large Language Models.](http://arxiv.org/abs/2309.12555) | PlanFitting是一个对话型人工智能，利用大型语言模型的生成能力帮助用户定制个性化的运动计划，并在用户研究中证明了它生成个性化、可操作和有据可依的运动计划的潜力。 |
| [^29] | [Automatic Answerability Evaluation for Question Generation.](http://arxiv.org/abs/2309.12546) | 这项工作提出了一种新颖的自动评估指标，用于评估问句生成任务中生成的问题是否可以由参考答案回答。实验证明该指标结果可靠，并与人工评价一致。并且这个指标可以补充传统的指标。 |
| [^30] | [Knowledge Graph Embedding: An Overview.](http://arxiv.org/abs/2309.12501) | 该论文综述了知识图谱嵌入的研究状态，介绍了两个主要分支：基于距离和基于语义匹配的方法。还讨论了CompoundE和CompoundE3D模型，并揭示了一个潜在的研究趋势。 |
| [^31] | [Exploring the Impact of Training Data Distribution and Subword Tokenization on Gender Bias in Machine Translation.](http://arxiv.org/abs/2309.12491) | 这项研究探索了训练数据分布和子词标记对机器翻译中性别偏见的影响。研究发现，模型训练语料库中性别形式的不平衡是导致性别偏见的主要因素，而子词拆分的影响较小。同时，研究还发现，通过分析子词拆分可以很好地估计训练数据中性别形式的不平衡。最后，通过仅微调标记嵌入层可以减少女性和男性之间性别预测准确性的差距。 |
| [^32] | [Studying and improving reasoning in humans and machines.](http://arxiv.org/abs/2309.12485) | 本研究通过对大型语言模型（LLM）和人类的推理能力进行比较研究，发现LLM在推理中存在类似于人类启发式推理的错误，但与人类推理有重要差异，最新的LLM版本几乎消除了模型的限制。此外，人类和机器对相同的提示方案的反应不同。这些结果对我们的认识论有重大影响。 |
| [^33] | [HANS, are you clever? Clever Hans Effect Analysis of Neural Systems.](http://arxiv.org/abs/2309.12481) | 这项研究调查了指导调整的大型语言模型（It-LLMs）对多项选择题（MCQ）的鲁棒性能力，在选择顺序变动时揭示了选择偏见和推理能力的问题。 |
| [^34] | [Multimodal Deep Learning for Scientific Imaging Interpretation.](http://arxiv.org/abs/2309.12460) | 本研究提出了一种多模态深度学习框架，通过模拟人类与扫描电子显微镜图像的交互，利用文本和视觉数据进行精细数据合成和评估。该模型（GlassLLaVA）能够准确解释、识别关键特征和检测以前未见的SEM图像中的缺陷，同时引入了适用于多种科学成像应用的灵活评估指标。 |
| [^35] | [LongDocFACTScore: Evaluating the Factuality of Long Document Abstractive Summarisation.](http://arxiv.org/abs/2309.12455) | LongDocFACTScore是一种评估长文档生成摘要实证性的评估框架，可以解决传统自动评估度量标准无法评估长文档摘要事实一致性的问题。 |
| [^36] | [Foundation Metrics: Quantifying Effectiveness of Healthcare Conversations powered by Generative AI.](http://arxiv.org/abs/2309.12444) | 这篇论文提出了基于生成AI的医疗对话模型的评估指标问题，并强调了现有指标对医学和健康概念的理解不足以及忽略了用户体验因素。 |
| [^37] | [Active Learning for Multilingual Fingerspelling Corpora.](http://arxiv.org/abs/2309.12443) | 本文应用主动学习来解决手语数据稀缺问题，并对预训练的效果进行了分析，发现预训练在多语种手指拼写语料库上有益处，可能是由于视觉上的相似性。 |
| [^38] | [Can LLMs Augment Low-Resource Reading Comprehension Datasets? Opportunities and Challenges.](http://arxiv.org/abs/2309.12426) | 本研究分析了使用大型语言模型(LLMs)对低资源阅读理解数据集进行增强的可能性。结果显示，GPT-4可以用作低资源读解任务中人工注释者的替代品。这项工作突出了LLMs作为合成数据增强器的机遇和挑战，并发布了增强版本的低资源数据集。 |
| [^39] | [Constraints First: A New MDD-based Model to Generate Sentences Under Constraints.](http://arxiv.org/abs/2309.12415) | 本文介绍了一种基于多值决策图的新模型，用于生成强约束文本。通过将生成句子问题形式化为离散组合优化问题，并利用多值决策图来处理约束，可以得到详尽解集。应用语言模型保留最佳句子，并在英语和法语上进行了详细讨论。该方法相比传统的视力筛查测试带来了重大突破，并且具有广泛的适用性。 |
| [^40] | [Examining the Influence of Varied Levels of Domain Knowledge Base Inclusion in GPT-based Intelligent Tutors.](http://arxiv.org/abs/2309.12367) | 本文研究了在基于GPT的智能辅导系统中将领域知识库与语言模型集成，以提高回答的可靠性。通过设计可扩展的知识库和评估实验，我们展示了该系统的有效性。学生和领域专家对于智能辅导系统的回答进行了验证和排名。 |
| [^41] | [ChatGPT Assisting Diagnosis of Neuro-ophthalmology Diseases Based on Case Reports.](http://arxiv.org/abs/2309.12361) | 本研究评估了大型语言模型ChatGPT在神经眼科疾病诊断中的辅助效果。实验结果显示，ChatGPT在13个病例中正确诊断了59%，而ChatGPT Plus和两名神经眼科医生的正确率分别达到了82%和86%。这表明ChatGPT可以作为神经眼科疾病诊断的有用工具。 |
| [^42] | [Efficient Social Choice via NLP and Sampling.](http://arxiv.org/abs/2309.12360) | 本文通过结合自然语言处理和抽样技术，提出了一种高效的注意力感知社会选择系统，该系统使用训练有素的NLP模型估计了提案通过的概率，并通过采样多数来决定提案。 |
| [^43] | [Cultural Alignment in Large Language Models: An Explanatory Analysis Based on Hofstede's Cultural Dimensions.](http://arxiv.org/abs/2309.12342) | 本研究提出了一种使用霍夫斯泰德文化维度框架来量化大型语言模型与不同文化之间的对齐程度的文化对齐测试（CAT）。通过在不同文化国家应用该方法，我们发现LLMs在解释性文化维度上存在差异，并能量化其与特定国家的文化对齐情况。 |
| [^44] | [Considerations for health care institutions training large language models on electronic health records.](http://arxiv.org/abs/2309.12339) | 本研究通过分析数据集大小、模型大小和使用电子病历数据进行大型语言模型（LLM）训练的成本，提供了一个思考医疗机构是否应该训练LLM以及如何在预算限制下选择合适LLM的框架。 |
| [^45] | [MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models.](http://arxiv.org/abs/2309.12284) | MetaMath是一种专门用于数学推理的微调语言模型，通过从多个角度重新编写问题来生成数学问题，并在两个基准测试中取得了优于其他开源语言模型的表现。 |
| [^46] | [AceGPT, Localizing Large Language Models in Arabic.](http://arxiv.org/abs/2309.12053) | 本研究旨在开发阿拉伯文的本地化大型语言模型(AceGPT)，通过预训练、监督微调和增强学习方法来培养具备文化意识和价值观一致的阿拉伯文模型，以满足阿拉伯语社区特定应用需求。评估结果表明，AceGPT在各项基准测试中都是最先进的阿拉伯文模型。 |
| [^47] | [LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset.](http://arxiv.org/abs/2309.11998) | LMSYS-Chat-1M是一个包含一百万个实际对话的大规模数据集，通过其多样性和用例展示了其在理解和推进LLM能力方面的价值。 |
| [^48] | [Rethinking the Evaluating Framework for Natural Language Understanding in AI Systems: Language Acquisition as a Core for Future Metrics.](http://arxiv.org/abs/2309.11981) | 这篇论文重新思考了人工智能系统中自然语言理解的评估框架，提出了以语言习得为核心的全面框架，旨在解决传统度量方法面临的问题，并借鉴了大型语言模型的进展。 |
| [^49] | [InstructERC: Reforming Emotion Recognition in Conversation with a Retrieval Multi-task LLMs Framework.](http://arxiv.org/abs/2309.11911) | InstructERC是一种使用大型语言模型(LLMs)的生成式框架，通过引入检索模板模块和额外的情感对齐任务，改革了对话中的情绪识别。 |
| [^50] | [Audio Contrastive based Fine-tuning.](http://arxiv.org/abs/2309.11895) | 本论文提出了一种基于音频对比的微调方法（AudioConFit），通过借助对比学习的可转移性，该方法在各种音频分类任务中表现出强大的泛化能力，并在不同设置下实现了最先进的结果。 |
| [^51] | [CFGPT: Chinese Financial Assistant with Large Language Model.](http://arxiv.org/abs/2309.10654) | CFGPT是一个具有大型语言模型的中国金融助手，包括CFData用于预训练和监督微调，以及CFLLM用于处理金融文本，CFAPP用于实际金融应用。这个框架在金融领域的各个方面展现出了巨大的潜力。 |
| [^52] | [Talk2Care: Facilitating Asynchronous Patient-Provider Communication with Large-Language-Model.](http://arxiv.org/abs/2309.09357) | 本研究利用大型语言模型（LLMs）来促进患者和医生之间的异步通信，通过访谈研究了解了他们对LLMs的需求，并构建了一个名为Talk2Care的LLM驱动的通信系统。 |
| [^53] | [ChatGPT v Bard v Bing v Claude 2 v Aria v human-expert. How good are AI chatbots at scientific writing? (ver. 23Q3).](http://arxiv.org/abs/2309.08636) | 本文综合分析了在人文学科和考古学领域中六个AI聊天机器人在学术写作方面的能力和局限性，发现它们在重新组合现有知识方面表现出色，但在产生原创科学内容方面存在问题。 |
| [^54] | [Contextual Biasing of Named-Entities with Large Language Models.](http://arxiv.org/abs/2309.00723) | 本文研究了使用大型语言模型进行上下文偏倚的方法，通过在第二次打分时提供额外的上下文信息，以提高自动语音识别性能。我们利用提示信息对大型语言模型进行boosting，并采用多任务训练以预测实体类别和下一个标记。此外，我们提出了动态提示方法来提高效率。 |
| [^55] | [Exploring Transfer Learning in Medical Image Segmentation using Vision-Language Models.](http://arxiv.org/abs/2308.07706) | 本论文提出使用视觉-语言模型进行医学图像分割的迁移学习，并评估了其在医学领域的可迁移性。通过捕捉语义信息和引入新的图像描述变化，实现了对多样化医学图像的分割。 |
| [^56] | [Right to be Forgotten in the Era of Large Language Models: Implications, Challenges, and Solutions.](http://arxiv.org/abs/2307.03941) | 本文探讨了在大型语言模型时代的被遗忘权（RTBF）面临的挑战，提供了实施技术解决方案的见解。 |
| [^57] | [Personality Traits in Large Language Models.](http://arxiv.org/abs/2307.00184) | 该研究介绍了一种综合方法，用于验证大型语言模型（LLMs）生成的文本中展示的人格特质。研究发现，部分LLMs在特定提示配置下模拟的人格可靠且有效，特别是对于更大和经过指导微调的模型。此外，LLMs的输出中的人格特质可以根据需要进行塑造。 |
| [^58] | [AVIS: Autonomous Visual Information Seeking with Large Language Models.](http://arxiv.org/abs/2306.08129) | 本文提出了一个基于大型语言模型的自主信息检索视觉问答框架AVIS，可以解决视觉问题所需的外部知识获取问题。 |
| [^59] | [Inference-Time Intervention: Eliciting Truthful Answers from a Language Model.](http://arxiv.org/abs/2306.03341) | 本研究提出推理时间干预（ITI）技术，通过在推理过程中跨越有限数量的注意力头，显着提高大型语言模型的真实性。在TruthfulQA基准上，ITI使LLaMA模型的真实性从32.5%提高到65.1%。ITI是一种最小程度的干扰，计算廉价，且数据效率高。 |
| [^60] | [GENTLE: A Genre-Diverse Multilayer Challenge Set for English NLP and Linguistic Evaluation.](http://arxiv.org/abs/2306.01966) | GENTLE是一个包含不同文体的英文NLP挑战数据集，对于各种NLP任务，包括句法依赖分析、实体识别、指代消解和篇章分析，最先进的NLP系统在某些文体上性能严重降低，这表明GENTLE在NLP系统评估中的实用性。 |
| [^61] | [FACE: Evaluating Natural Language Generation with Fourier Analysis of Cross-Entropy.](http://arxiv.org/abs/2305.10307) | FACE是一组可以有效识别人类和模型之间差距的度量标准。它基于傅里叶分析和交叉熵估计，可以反映模型大小、解码采样方法和人类评分。 |
| [^62] | [How to Index Item IDs for Recommendation Foundation Models.](http://arxiv.org/abs/2305.06569) | 本研究对推荐基础模型的项目索引问题进行了系统检查，提出了一种新的上下文感知索引方法，该方法在项目推荐准确性和文本生成质量方面具有优势。 |
| [^63] | [Don't Stop Pretraining? Make Prompt-based Fine-tuning Powerful Learner.](http://arxiv.org/abs/2305.01711) | 本文研究了持续预训练对于微调性能的影响，发现传统的持续预训练不能保证一致的提高性能，甚至会对一些任务产生负面影响。针对这些问题，作者提出了基于提示的持续预训练，旨在通过无监督的预训练向LM展示任务相关文本和提示模板，从而提高基于提示的微调表现。 |
| [^64] | [CryCeleb: A Speaker Verification Dataset Based on Infant Cry Sounds.](http://arxiv.org/abs/2305.00969) | CryCeleb是一个基于婴儿哭声的说话人认证数据集，包括超过6小时的手动分割哭声，可用于研究婴儿哭声分析。 |
| [^65] | [Search-in-the-Chain: Towards the Accurate, Credible and Traceable Content Generation for Complex Knowledge-intensive Tasks.](http://arxiv.org/abs/2304.14732) | 提出了一个名为SearChain的新型框架，以改进LLM生成的内容的准确性、可信度和可追溯性，从而提高复杂知识密集型任务的表现。SearChain通过深度集成LLM和信息检索（IR）实现，其思路是通过构造查询链，将多跳问题进行分解，最终指导LLM生成正确的答案。 |
| [^66] | [What Makes a Language Easy to Deep-Learn?.](http://arxiv.org/abs/2302.12239) | 本研究通过测试神经网络和人类在学习和推广不同结构程度的语言方面的能力，发现神经网络在系统化概括方面存在困难，这对于模拟人类语言学习和进化构成了一个问题。 |
| [^67] | [Conversation Style Transfer using Few-Shot Learning.](http://arxiv.org/abs/2302.08362) | 本论文提出了一种使用少样本学习的对话风格转移方法，通过观察目标风格中的少量示例对话，模型可以在考虑上下文的情况下进行风格转移，相比于句子级风格转移，该方法在恰当性和语义正确性上具有更好的表现。 |
| [^68] | [Lessons learned from the evaluation of Spanish Language Models.](http://arxiv.org/abs/2212.08390) | 该论文对西班牙语语言模型进行了全面比较，发现先前被忽视的大公司的多语言模型优于单语言模型，在西班牙语语言模型的评估领域产生了重大变化。需要进一步研究语料库大小、质量和预训练技术的影响。 |
| [^69] | [Development of Hybrid ASR Systems for Low Resource Medical Domain Conversational Telephone Speech.](http://arxiv.org/abs/2210.13397) | 本研究开发了针对低资源医疗领域会话电话语音的混合ASR系统，旨在改善患者护理并克服语言障碍。 |
| [^70] | [Smoothing Entailment Graphs with Language Models.](http://arxiv.org/abs/2208.00318) | 本文提出了一种使用语言模型平滑蕴含图的方法，通过构建传递链条和使用现成的语言模型找到丢失的前提谓词的近似，可以提高自然语言推理模型的召回率和平均精度，并保持模型的可解释性。 |
| [^71] | [Benchmarking Automated Clinical Language Simplification: Dataset, Algorithm, and Evaluation.](http://arxiv.org/abs/2012.02420) | 该论文构建了一个名为MedLane的新数据集，支持自动临床语言简化方法的开发和评估。提出了一种叫做DECLARE的新模型，与八种基准模型相比取得了最先进的性能，并提出了三个特定的评估指标。 |

# 详细

[^1]: 动态ASR路径：一种自适应掩蔽方法用于压缩多语种ASR模型的高效修剪

    Dynamic ASR Pathways: An Adaptive Masking Approach Towards Efficient Pruning of A Multilingual ASR Model. (arXiv:2309.13018v1 [eess.AS])

    [http://arxiv.org/abs/2309.13018](http://arxiv.org/abs/2309.13018)

    本研究提出了一种自适应掩蔽方法，用于高效地压缩多语种ASR模型。该方法通过动态适应子网络结构，能够在减少性能损失的情况下得到稀疏的单语种模型或稀疏的多语种模型。实验证明，与现有的修剪方法相比，该方法在针对稀疏的单语种模型时表现更好，并且减少了对特定语言进行修剪的需求。

    

    神经网络修剪是一种有效的方法，可以在性能损失最小的情况下压缩多语种自动语音识别（ASR）模型。然而，这需要对每种语言运行多轮修剪和重新训练。在这项工作中，我们提出了一种自适应掩蔽方法，以两种场景高效地修剪多语种ASR模型，分别得到了稀疏的单语种模型或稀疏的多语种模型（称为动态ASR路径）。我们的方法动态地适应子网络，避免对固定的子网络结构进行过早决策。我们证明了我们的方法在针对稀疏的单语种模型时优于现有的修剪方法。此外，我们还说明了动态ASR路径通过自不同的子网络初始化进行调整，共同发现和训练更好的单一多语种模型的子网络（路径），从而减少了对特定语言进行修剪的需求。

    Neural network pruning offers an effective method for compressing a multilingual automatic speech recognition (ASR) model with minimal performance loss. However, it entails several rounds of pruning and re-training needed to be run for each language. In this work, we propose the use of an adaptive masking approach in two scenarios for pruning a multilingual ASR model efficiently, each resulting in sparse monolingual models or a sparse multilingual model (named as Dynamic ASR Pathways). Our approach dynamically adapts the sub-network, avoiding premature decisions about a fixed sub-network structure. We show that our approach outperforms existing pruning methods when targeting sparse monolingual models. Further, we illustrate that Dynamic ASR Pathways jointly discovers and trains better sub-networks (pathways) of a single multilingual model by adapting from different sub-network initializations, thereby reducing the need for language-specific pruning.
    
[^2]: ReConcile：圆桌会议通过多元LLM的共识改进推理能力

    ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs. (arXiv:2309.13007v1 [cs.CL])

    [http://arxiv.org/abs/2309.13007](http://arxiv.org/abs/2309.13007)

    ReConcile是一个通过多轮讨论和投票机制来增强LLM推理能力的多模型多代理框架。

    

    大型语言模型（LLM）仍然在复杂的推理任务上遇到困难。受到心智社会理论（Minsky, 1988）的启发，我们提出了ReConcile，这是一个多模型多代理的框架，旨在通过多样的LLM代理人之间的圆桌会议来促进多样的思想和讨论，从而改进一致性。ReConcile通过进行多轮讨论、学习说服其他代理人改进答案以及采用置信度加权投票机制来增强LLM的推理能力。在每一轮中，ReConcile通过“讨论提示”来启动代理人间的讨论，其中包括上一轮每个代理人生成的答案和解释的分组、它们的不确定性以及用于说服其他代理人的答案修正人类解释的演示。这个讨论提示使每个代理人能够根据其他代理人的见解修订自己的回答。一旦达成一致并结束讨论，ReConcile执行一次全体投票以确定最终答案。

    Large Language Models (LLMs) still struggle with complex reasoning tasks. Motivated by the society of minds (Minsky, 1988), we propose ReConcile, a multi-model multi-agent framework designed as a round table conference among diverse LLM agents to foster diverse thoughts and discussion for improved consensus. ReConcile enhances the reasoning capabilities of LLMs by holding multiple rounds of discussion, learning to convince other agents to improve their answers, and employing a confidence-weighted voting mechanism. In each round, ReConcile initiates discussion between agents via a 'discussion prompt' that consists of (a) grouped answers and explanations generated by each agent in the previous round, (b) their uncertainties, and (c) demonstrations of answer-rectifying human explanations, used for convincing other agents. This discussion prompt enables each agent to revise their responses in light of insights from other agents. Once a consensus is reached and the discussion ends, ReConcil
    
[^3]: 机器翻译的针对特定观众的解释

    Audience-specific Explanations for Machine Translation. (arXiv:2309.12998v1 [cs.CL])

    [http://arxiv.org/abs/2309.12998](http://arxiv.org/abs/2309.12998)

    该论文提出了一种针对机器翻译的针对特定观众的解释方法，通过从平行语料库中提取示例解释来解决翻译中的文化差异问题。实验结果表明，该方法能够有效提高句子中包含解释的比例。

    

    在机器翻译中，一个常见问题是某些词的翻译即使翻译了也会因为不同的文化背景导致目标语言观众无法理解。解决这个问题的方法是为这些词添加解释。在第一步中，我们需要识别这些词或短语。在这项工作中，我们探索了从平行语料库中提取示例解释的技术。然而，包含需要解释的词的句子的稀缺性使得构建训练数据集极其困难。在这项工作中，我们提出了一种半自动技术，可以从大型平行语料库中提取这些解释。在英语->德语语言对上的实验表明，我们的方法能够提取出超过10%的句子包含解释，而原始句子中只有1.9%包含解释。此外，在英语->法语和英语->中文语言对上的实验也显示出类似的结果。

    In machine translation, a common problem is that the translation of certain words even if translated can cause incomprehension of the target language audience due to different cultural backgrounds. A solution to solve this problem is to add explanations for these words. In a first step, we therefore need to identify these words or phrases. In this work we explore techniques to extract example explanations from a parallel corpus. However, the sparsity of sentences containing words that need to be explained makes building the training dataset extremely difficult. In this work, we propose a semi-automatic technique to extract these explanations from a large parallel corpus. Experiments on English->German language pair show that our method is able to extract sentence so that more than 10% of the sentences contain explanation, while only 1.9% of the original sentences contain explanations. In addition, experiments on English->French and English->Chinese language pairs also show similar conc
    
[^4]: 基于中心元素识别的嵌套事件抽取

    Nested Event Extraction upon Pivot Element Recogniton. (arXiv:2309.12960v1 [cs.CL])

    [http://arxiv.org/abs/2309.12960](http://arxiv.org/abs/2309.12960)

    本文提出了一种名为PerNee的新模型，通过识别中心元素来提取嵌套事件。该模型解决了现有NEE方法无法处理中心元素双重身份的问题，并通过提示学习将事件类型和参数角色的信息纳入其中，以提高NEE性能。

    

    嵌套事件抽取（NEE）旨在提取包含其他事件作为其参数的复杂事件结构。嵌套事件涉及一种称为中心元素（PEs）的元素，它同时作为外部事件的参数和内部事件的触发器，并将它们连接成嵌套结构。PEs的这种特殊特性给现有的NEE方法带来了挑战，因为它们不能很好地处理PEs的双重身份。因此，本文提出了一种新模型，称为PerNee，主要基于识别PEs来提取嵌套事件。具体而言，PerNee首先识别内部和外部事件的触发器，然后通过分类触发器对之间关系类型来识别PEs。为了获得更好的触发器和参数表示以进一步提高NEE性能，PerNee通过提示学习将事件类型和参数角色的信息纳入其中。由于现有的NEE数据集（例如Gen）

    Nested Event Extraction (NEE) aims to extract complex event structures where an event contains other events as its arguments recursively. Nested events involve a kind of Pivot Elements (PEs) that simultaneously act as arguments of outer events and as triggers of inner events, and thus connect them into nested structures. This special characteristic of PEs brings challenges to existing NEE methods, as they cannot well cope with the dual identities of PEs. Therefore, this paper proposes a new model, called PerNee, which extracts nested events mainly based on recognizing PEs. Specifically, PerNee first recognizes the triggers of both inner and outer events and further recognizes the PEs via classifying the relation type between trigger pairs. In order to obtain better representations of triggers and arguments to further improve NEE performance, it incorporates the information of both event types and argument roles into PerNee through prompt learning. Since existing NEE datasets (e.g., Gen
    
[^5]: 自解释提示在大型语言模型中提高对话理解能力

    Self-Explanation Prompting Improves Dialogue Understanding in Large Language Models. (arXiv:2309.12940v1 [cs.CL])

    [http://arxiv.org/abs/2309.12940](http://arxiv.org/abs/2309.12940)

    本研究提出了一种自解释提示策略，可显著提高大型语言模型在多轮对话中的理解能力，实验证实其在复杂对话任务中的有效性。

    

    任务导向的对话系统通过多轮对话帮助用户执行各种活动，但是大型语言模型（LLMs）往往难以理解这些复杂的语境。在本研究中，我们提出了一种新的“自解释”提示策略，以增强LLMs在多轮对话中的理解能力。这种任务无关的方法要求模型在执行任务之前分析每个对话话语，从而改善各种对话中心任务的性能。来自六个基准数据集的实验证据证实，我们的方法始终优于其他零样本提示，并且与少样本提示的有效性相当或超过，展示了它在提高LLMs在复杂对话任务中的理解能力方面的潜力。

    Task-oriented dialogue (TOD) systems facilitate users in executing various activities via multi-turn dialogues, but Large Language Models (LLMs) often struggle to comprehend these intricate contexts. In this study, we propose a novel "Self-Explanation" prompting strategy to enhance the comprehension abilities of LLMs in multi-turn dialogues. This task-agnostic approach requires the model to analyze each dialogue utterance before task execution, thereby improving performance across various dialogue-centric tasks. Experimental results from six benchmark datasets confirm that our method consistently outperforms other zero-shot prompts and matches or exceeds the efficacy of few-shot prompts, demonstrating its potential as a powerful tool in enhancing LLMs' comprehension in complex dialogue tasks.
    
[^6]: TopRoBERTa：拓扑感知的深伪文本作者识别

    TopRoBERTa: Topology-Aware Authorship Attribution of Deepfake Texts. (arXiv:2309.12934v1 [cs.CL])

    [http://arxiv.org/abs/2309.12934](http://arxiv.org/abs/2309.12934)

    本论文提出了一种拓扑感知的深伪文本作者识别方法TopRoBERTa，通过捕捉深伪文本中的更多语言模式，改进了现有的作者识别解决方案。

    

    最近大规模语言模型（LLM）的进展使得生成开放性、高质量的文本成为可能，这些文本很难与人类写作的文本区分开来，我们将这种LLM生成的文本称为“深伪文本”。目前，huggingface模型存储库中有超过11K个文本生成模型。因此，恶意用户可以轻松使用这些开源的LLM生成大规模的有害文本和虚假信息。为了缓解这个问题，我们希望有一种计算方法能够确定给定的文本是否为深伪文本，即通过图灵测试（TT）来判断。具体而言，在这项工作中，我们调查了更一般版本的问题，即在多类别设置下的“作者识别（AA）”，即不仅确定给定的文本是否为深伪文本，而且还能够确定哪个LLM是作者。我们提出了TopRoBERTa，通过包含更多深伪文本中的语言模式来改进现有的AA解决方案。

    Recent advances in Large Language Models (LLMs) have enabled the generation of open-ended high-quality texts, that are non-trivial to distinguish from human-written texts. We refer to such LLM-generated texts as \emph{deepfake texts}. There are currently over 11K text generation models in the huggingface model repo. As such, users with malicious intent can easily use these open-sourced LLMs to generate harmful texts and misinformation at scale. To mitigate this problem, a computational method to determine if a given text is a deepfake text or not is desired--i.e., Turing Test (TT). In particular, in this work, we investigate the more general version of the problem, known as \emph{Authorship Attribution (AA)}, in a multi-class setting--i.e., not only determining if a given text is a deepfake text or not but also being able to pinpoint which LLM is the author. We propose \textbf{TopRoBERTa} to improve existing AA solutions by capturing more linguistic patterns in deepfake texts by includ
    
[^7]: 自监督变形器中的分别归一化

    On Separate Normalization in Self-supervised Transformers. (arXiv:2309.12931v1 [cs.CL])

    [http://arxiv.org/abs/2309.12931](http://arxiv.org/abs/2309.12931)

    在自监督变形器中，通过为标记和[CLS]符号分别使用归一化层，可以更好地捕捉它们各自的特点并提高下游任务的性能。

    

    自监督变形器的训练方法在各个领域展现了显著的性能。以往的基于变形器的模型（如遮蔽自编码器）通常会为[CLS]符号和标记使用单独的归一化层。我们在本文中提出了一种简单的修改，为标记和[CLS]符号分别使用归一化层，以更好地捕捉它们各自的特点并增强下游任务的性能。我们的方法旨在缓解将相同的归一化统计数据应用于两种标记类型可能带来的负面效果，这些统计数据可能无法与它们各自的角色最佳匹配。通过使用单独的归一化层，我们经验证明[CLS]嵌入能够更好地编码全局语境信息，并在其非各向同性空间中分布更均匀。当用这两个单独的归一化层替换常规的归一化层时，我们观察到平均性能提升了2.7%。

    Self-supervised training methods for transformers have demonstrated remarkable performance across various domains. Previous transformer-based models, such as masked autoencoders (MAE), typically utilize a single normalization layer for both the [CLS] symbol and the tokens. We propose in this paper a simple modification that employs separate normalization layers for the tokens and the [CLS] symbol to better capture their distinct characteristics and enhance downstream task performance. Our method aims to alleviate the potential negative effects of using the same normalization statistics for both token types, which may not be optimally aligned with their individual roles. We empirically show that by utilizing a separate normalization layer, the [CLS] embeddings can better encode the global contextual information and are distributed more uniformly in its anisotropic space. When replacing the conventional normalization layer with the two separate layers, we observe an average 2.7% performa
    
[^8]: ProtoEM：一种用于事件关系抽取的原型加强匹配框架

    ProtoEM: A Prototype-Enhanced Matching Framework for Event Relation Extraction. (arXiv:2309.12892v1 [cs.CL])

    [http://arxiv.org/abs/2309.12892](http://arxiv.org/abs/2309.12892)

    本论文提出了一种原型加强匹配框架（ProtoEM）用于联合抽取多种类型的事件关系。该框架通过获取每种类型的事件关系的原型表示，并利用图神经网络匹配这些关系，从而全面理解它们的内在语义。

    

    事件关系抽取（ERE）旨在从文本中提取多种类型的事件关系。然而，现有方法单独将事件关系分类为不同类别，无法充分捕捉这些关系的内在语义。为了全面理解它们的内在语义，本文针对每种类型的事件关系获取原型表示，并提出了一种原型加强匹配（ProtoEM）框架，用于联合抽取多种类型的事件关系。具体而言，ProtoEM以两步方式提取事件关系，即原型表示和原型匹配。在第一步中，为了捕捉不同事件关系的内涵，ProtoEM利用示例来表示与这些关系相对应的原型。随后，为了捕捉事件关系之间的相互依赖性，它为与这些关系相对应的原型构建了一个依赖图，并利用图神经网络进行匹配。

    Event Relation Extraction (ERE) aims to extract multiple kinds of relations among events in texts. However, existing methods singly categorize event relations as different classes, which are inadequately capturing the intrinsic semantics of these relations. To comprehensively understand their intrinsic semantics, in this paper, we obtain prototype representations for each type of event relation and propose a Prototype-Enhanced Matching (ProtoEM) framework for the joint extraction of multiple kinds of event relations. Specifically, ProtoEM extracts event relations in a two-step manner, i.e., prototype representing and prototype matching. In the first step, to capture the connotations of different event relations, ProtoEM utilizes examples to represent the prototypes corresponding to these relations. Subsequently, to capture the interdependence among event relations, it constructs a dependency graph for the prototypes corresponding to these relations and utilized a Graph Neural Network (
    
[^9]: 使用大型语言模型进行对话中的情感识别

    Affect Recognition in Conversations Using Large Language Models. (arXiv:2309.12881v1 [cs.CL])

    [http://arxiv.org/abs/2309.12881](http://arxiv.org/abs/2309.12881)

    本研究探讨了使用大型语言模型（LLMs）识别对话中人类情感的能力，并对开放领域闲聊对话和任务导向对话进行了评估。研究结果表明，LLMs具有零样本和少样本能力，并且通过上下文学习和任务特定微调可以提高模型性能。

    

    情感识别在人类交流中起着关键作用，涵盖情绪、心情和感受。在会话型人工智能领域，识别和回应人类情感线索的能力对于创建引人入胜且富有同理心的互动至关重要。本研究深入探讨了大型语言模型（LLMs）在对话中识别人类情感的能力，重点关注开放领域闲聊对话和任务导向对话。利用三个不同的数据集，包括IEMOCAP、EmoWOZ和DAIC-WOZ，涵盖了从日常对话到临床面试的不同类型对话，我们评估并比较了LLMs在情感识别方面的性能。我们的研究探讨了LLMs的零样本和少样本能力，通过上下文学习（ICL）以及任务特定微调来提高模型能力。此外，本研究还考虑了自动语音识别（ASR）的潜在影响。

    Affect recognition, encompassing emotions, moods, and feelings, plays a pivotal role in human communication. In the realm of conversational artificial intelligence (AI), the ability to discern and respond to human affective cues is a critical factor for creating engaging and empathetic interactions. This study delves into the capacity of large language models (LLMs) to recognise human affect in conversations, with a focus on both open-domain chit-chat dialogues and task-oriented dialogues. Leveraging three diverse datasets, namely IEMOCAP, EmoWOZ, and DAIC-WOZ, covering a spectrum of dialogues from casual conversations to clinical interviews, we evaluated and compared LLMs' performance in affect recognition. Our investigation explores the zero-shot and few-shot capabilities of LLMs through in-context learning (ICL) as well as their model capacities through task-specific fine-tuning. Additionally, this study takes into account the potential impact of automatic speech recognition (ASR) e
    
[^10]: 角度优化的文本嵌入

    AnglE-Optimized Text Embeddings. (arXiv:2309.12871v1 [cs.CL])

    [http://arxiv.org/abs/2309.12871](http://arxiv.org/abs/2309.12871)

    本文提出了一种名为AnglE的角度优化文本嵌入模型，通过在复杂空间中引入角度优化来缓解文本嵌入中余弦函数饱和区域造成的梯度消失问题。该模型在多个STS任务中实现了高质量的文本嵌入，并在有限标签数据的特定领域STS场景中展现出优秀的性能。

    

    高质量的文本嵌入对于提升语义文本相似度（STS）任务至关重要，而这些任务又是大型语言模型（LLM）应用中的关键组成部分。然而，现有的文本嵌入模型面临的一个普遍挑战是渐变消失问题，主要是由于它们在优化目标中依赖余弦函数，而余弦函数具有饱和区域。为了解决这个问题，本文提出了一种称为AnglE的新型角度优化文本嵌入模型。AnglE的核心思想是在一个复杂空间中引入角度优化。这种新颖的方法有效地缓解了余弦函数饱和区域产生的不利影响，从而可以阻碍梯度并阻碍优化过程。为了建立全面的STS评估，我们在现有的短文本STS数据集和从GitHub Issues中新收集的长文本STS数据集上进行了实验。此外，我们还研究了具有有限标签数据的特定领域STS场景，并探讨了AnglE的工作原理。

    High-quality text embedding is pivotal in improving semantic textual similarity (STS) tasks, which are crucial components in Large Language Model (LLM) applications. However, a common challenge existing text embedding models face is the problem of vanishing gradients, primarily due to their reliance on the cosine function in the optimization objective, which has saturation zones. To address this issue, this paper proposes a novel angle-optimized text embedding model called AnglE. The core idea of AnglE is to introduce angle optimization in a complex space. This novel approach effectively mitigates the adverse effects of the saturation zone in the cosine function, which can impede gradient and hinder optimization processes. To set up a comprehensive STS evaluation, we experimented on existing short-text STS datasets and a newly collected long-text STS dataset from GitHub Issues. Furthermore, we examine domain-specific STS scenarios with limited labeled data and explore how AnglE works w
    
[^11]: 针对阿拉伯金融文本的领域适应机器翻译

    Domain Adaptation for Arabic Machine Translation: The Case of Financial Texts. (arXiv:2309.12863v1 [cs.CL])

    [http://arxiv.org/abs/2309.12863](http://arxiv.org/abs/2309.12863)

    这项研究旨在探索领域适应对阿拉伯机器翻译在金融领域的效果，并通过开发平行语料库进行了试验。结果显示，领域适应方法对于提高阿拉伯机器翻译的性能具有积极的影响。

    

    神经机器翻译（NMT）在训练大规模语料库时展示出了令人印象深刻的性能。然而，通用的NMT系统在领域外的翻译中表现出了较差的性能。为了缓解这个问题，最近提出了几种领域适应方法，通常比通用的NMT系统有更好的翻译质量。尽管在NMT的英语和其他欧洲语言方面取得了一些持续的进展，但在阿拉伯语方面的领域适应在文献中受到了很少的关注。因此，本研究旨在探索阿拉伯机器翻译（AMT）领域特定适应的有效性，尤其是在尚未开发的领域中，如金融新闻文章。为此，我们精心开发了一个用于阿拉伯-英语（AR-EN）金融领域翻译的平行语料库，以评估不同领域适应方法的性能。我们还在我们的数据集上对几个预训练的NMT和大型语言模型进行了微调，包括ChatGPT-3.5 Turbo。结果表明，

    Neural machine translation (NMT) has shown impressive performance when trained on large-scale corpora. However, generic NMT systems have demonstrated poor performance on out-of-domain translation. To mitigate this issue, several domain adaptation methods have recently been proposed which often lead to better translation quality than genetic NMT systems. While there has been some continuous progress in NMT for English and other European languages, domain adaption in Arabic has received little attention in the literature. The current study, therefore, aims to explore the effectiveness of domain-specific adaptation for Arabic MT (AMT), in yet unexplored domain, financial news articles. To this end, we developed carefully a parallel corpus for Arabic-English (AR- EN) translation in the financial domain for benchmarking different domain adaptation methods. We then fine-tuned several pre-trained NMT and Large Language models including ChatGPT-3.5 Turbo on our dataset. The results showed that
    
[^12]: 合成提升：利用合成数据增强超声心动图中的视觉-语言分割

    Synthetic Boost: Leveraging Synthetic Data for Enhanced Vision-Language Segmentation in Echocardiography. (arXiv:2309.12829v1 [cs.CV])

    [http://arxiv.org/abs/2309.12829](http://arxiv.org/abs/2309.12829)

    本研究探讨了使用合成数据集来增强超声心动图分割的视觉-语言分割模型（VLSM），结果显示合成数据集可以提高分割模型的指标和训练速度。

    

    准确的分割对于基于超声心动图的心血管疾病评估至关重要。然而，超声图像的变异性和固有挑战阻碍了精确的分割。通过利用图像和文本模态的联合表示，视觉-语言分割模型（VLSM）可以融入丰富的上下文信息，可能有助于精确和可解释的分割。然而，超声心动图中缺乏现成的数据阻碍了VLSM的训练。本研究中，我们探讨了使用语义扩散模型（SDM）生成的合成数据集来增强超声心动图分割的VLSM。我们使用从超声心动图图像、分割掩模和元数据中自动提取的多个属性导出的七种不同的语言提示来评估两个流行的VLSM模型（CLIPSeg和CRIS）的结果。我们的结果显示，在预训练VLSM时，转换和收敛速度更快。

    Accurate segmentation is essential for echocardiography-based assessment of cardiovascular diseases (CVDs). However, the variability among sonographers and the inherent challenges of ultrasound images hinder precise segmentation. By leveraging the joint representation of image and text modalities, Vision-Language Segmentation Models (VLSMs) can incorporate rich contextual information, potentially aiding in accurate and explainable segmentation. However, the lack of readily available data in echocardiography hampers the training of VLSMs. In this study, we explore using synthetic datasets from Semantic Diffusion Models (SDMs) to enhance VLSMs for echocardiography segmentation. We evaluate results for two popular VLSMs (CLIPSeg and CRIS) using seven different kinds of language prompts derived from several attributes, automatically extracted from echocardiography images, segmentation masks, and their metadata. Our results show improved metrics and faster convergence when pretraining VLSMs
    
[^13]: StyloMetrix:一种用于表示文体向量的开源多语言工具。

    StyloMetrix: An Open-Source Multilingual Tool for Representing Stylometric Vectors. (arXiv:2309.12810v1 [cs.CL])

    [http://arxiv.org/abs/2309.12810](http://arxiv.org/abs/2309.12810)

    StyloMetrix是一个开源的多语言工具，可以提供覆盖语法、句法和词汇等各个方面的文体文本表示。它的归一化输出可用于机器学习模型的训练，并可作为深度学习算法嵌入层的有价值补充。实验证明，StyloMetrix向量在内容分类和嵌入层增强方面的应用具有潜力。

    

    本研究旨在提供一个关于开源多语言工具StyloMetrix的概述。它提供了覆盖语法、句法和词汇等各个方面的文体文本表示。StyloMetrix覆盖了四种语言：波兰语作为主要语言，英语、乌克兰语和俄语。每个特征的归一化输出可以成为机器学习模型的有益来源，并对任何深度学习算法的嵌入层起到有价值的补充。我们旨在提供对StyloMetrix向量应用的简明但详尽的概述，以及对开发的语言特征集的解释。实验结果表明，在简单算法（如随机森林分类器、投票分类器、逻辑回归等）的监督内容分类中，取得了有希望的结果。深度学习评估揭示了StyloMetrix向量在增强从Transformer架构中提取的嵌入层方面的有用性。

    This work aims to provide an overview on the open-source multilanguage tool called StyloMetrix. It offers stylometric text representations that cover various aspects of grammar, syntax and lexicon. StyloMetrix covers four languages: Polish as the primary language, English, Ukrainian and Russian. The normalized output of each feature can become a fruitful course for machine learning models and a valuable addition to the embeddings layer for any deep learning algorithm. We strive to provide a concise, but exhaustive overview on the application of the StyloMetrix vectors as well as explain the sets of the developed linguistic features. The experiments have shown promising results in supervised content classification with simple algorithms as Random Forest Classifier, Voting Classifier, Logistic Regression and others. The deep learning assessments have unveiled the usefulness of the StyloMetrix vectors at enhancing an embedding layer extracted from Transformer architectures. The StyloMetri
    
[^14]: ChatPRCS: 基于ChatGPT的个性化英语阅读理解辅助系统

    ChatPRCS: A Personalized Support System for English Reading Comprehension based on ChatGPT. (arXiv:2309.12808v1 [cs.CL])

    [http://arxiv.org/abs/2309.12808](http://arxiv.org/abs/2309.12808)

    本研究提出了一种基于ChatGPT的个性化英语阅读理解辅助系统ChatPRCS。通过利用大型语言模型的先进能力，该系统采用阅读理解能力预测、问题生成、自动评估等方法来增强阅读理解教学。使用学生的历史数据来预测阅读理解能力，并生成适当难度的问题。辅助系统提供了个体化的阅读理解训练支持。

    

    作为学习英语的常见方法，阅读理解主要包括阅读文章和回答相关问题。然而，设计有效练习的复杂性导致学生遇到标准化问题，使其难以与个体化学习者的阅读理解能力相匹配。本文利用大型语言模型（如ChatGPT）提供的先进能力，基于近发展区理论提出了一种新型个性化阅读理解辅助系统ChatPRCS。ChatPRCS采用阅读理解能力预测、问题生成、自动评估等方法，以增强阅读理解教学。首先，我们开发了一种新的算法，可以根据学习者的历史数据预测他们的阅读理解能力，为生成具有相应难度水平的问题奠定基础。其次，我们设计了一系列的阅读理解支持功能，如问题生成、自动评估等，来帮助学生进行个性化的阅读理解训练。

    As a common approach to learning English, reading comprehension primarily entails reading articles and answering related questions. However, the complexity of designing effective exercises results in students encountering standardized questions, making it challenging to align with individualized learners' reading comprehension ability. By leveraging the advanced capabilities offered by large language models, exemplified by ChatGPT, this paper presents a novel personalized support system for reading comprehension, referred to as ChatPRCS, based on the Zone of Proximal Development theory. ChatPRCS employs methods including reading comprehension proficiency prediction, question generation, and automatic evaluation, among others, to enhance reading comprehension instruction. First, we develop a new algorithm that can predict learners' reading comprehension abilities using their historical data as the foundation for generating questions at an appropriate level of difficulty. Second, a serie
    
[^15]: 与计划评估的最远推理：具有检索增强的大语言模型的稳定推理路径

    Furthest Reasoning with Plan Assessment: Stable Reasoning Path with Retrieval-Augmented Large Language Models. (arXiv:2309.12767v1 [cs.CL])

    [http://arxiv.org/abs/2309.12767](http://arxiv.org/abs/2309.12767)

    本文提出了一种名为FuRePA的新的MHQA流水线，通过改进的fra算法解决了现有方法中信息检索器受到LLMs生成查询质量低和LLMs被IR提供的无关知识误导的问题。

    

    大语言模型（LLMs）作为强大的推理和生成器，在各种自然语言任务（如问答）中展现出非凡的性能。在这些任务中，多跳问答（MHQA）是一个广泛讨论的类别，需要LLMs与外部知识的无缝集成。现有的方法采用LLMs生成推理路径和计划，并利用IR迭代检索相关知识，但这些方法存在固有缺陷。一方面，信息检索器（IR）受到LLMs生成查询质量低的影响。另一方面，LLMs很容易被IR提供的无关知识误导。这些不准确性由IR与LLMs之间的迭代交互累积，最终导致效果的灾难性衰减。为了克服以上障碍，本文提出了一种新的MHQA流水线，称为最远推理与计划评估（FuRePA），包括一个改进的fra

    Large Language Models (LLMs), acting as a powerful reasoner and generator, exhibit extraordinary performance across various natural language tasks, such as question answering (QA). Among these tasks, Multi-Hop Question Answering (MHQA) stands as a widely discussed category, necessitating seamless integration between LLMs and the retrieval of external knowledge. Existing methods employ LLM to generate reasoning paths and plans, and utilize IR to iteratively retrieve related knowledge, but these approaches have inherent flaws. On one hand, Information Retriever (IR) is hindered by the low quality of generated queries by LLM. On the other hand, LLM is easily misguided by the irrelevant knowledge by IR. These inaccuracies, accumulated by the iterative interaction between IR and LLM, lead to a disaster in effectiveness at the end. To overcome above barriers, in this paper, we propose a novel pipeline for MHQA called Furthest-Reasoning-with-Plan-Assessment (FuRePA), including an improved fra
    
[^16]: 减少、复用、回收：与其他语言增强相比，被扰动数据对低资源自我监督语音模型更好吗？

    Reduce, Reuse, Recycle: Is Perturbed Data better than Other Language augmentation for Low Resource Self-Supervised Speech Models. (arXiv:2309.12763v1 [eess.AS])

    [http://arxiv.org/abs/2309.12763](http://arxiv.org/abs/2309.12763)

    使用音频增强为低资源自我监督语音模型的预训练提出一种有效的方法，并且综合增强（噪声/音高）是最佳的增强策略，超过了重音和语言知识转移。

    

    自我监督表示学习（SSRL）已经改善了下游音素识别的性能，相对于受监督的模型。训练SSRL模型需要大量的预训练数据，这对于低资源语言是一个挑战。一种常用的方法是从其他语言中转移知识。相反，我们提出使用音频增强在低资源条件下预训练SSRL模型，并评估下游任务的音素识别。我们对增强技术进行了系统比较，包括音高变化、噪声添加、有重音的目标语音和其他语言的语音。我们发现综合增强（噪声/音高）是最好的增强策略，超过了重音和语言知识转移。我们比较了不同数量和类型的预训练数据的性能。我们考察了增强数据的缩放因子，以达到与预训练目标域语音模型相当的性能。我们的发现是...

    Self-supervised representation learning (SSRL) has improved the performance on downstream phoneme recognition versus supervised models. Training SSRL models requires a large amount of pre-training data and this poses a challenge for low resource languages. A common approach is transferring knowledge from other languages. Instead, we propose to use audio augmentation to pre-train SSRL models in a low resource condition and evaluate phoneme recognition as downstream task. We performed a systematic comparison of augmentation techniques, namely: pitch variation, noise addition, accented target-language speech and other language speech. We found combined augmentations (noise/pitch) was the best augmentation strategy outperforming accent and language knowledge transfer. We compared the performance with various quantities and types of pre-training data. We examined the scaling factor of augmented data to achieve equivalent performance to models pre-trained with target domain speech. Our findi
    
[^17]: 聊天式大型语言模型的上下文干扰问题

    In-context Interference in Chat-based Large Language Models. (arXiv:2309.12727v1 [cs.AI])

    [http://arxiv.org/abs/2309.12727](http://arxiv.org/abs/2309.12727)

    本文研究了聊天式大型语言模型中的上下文干扰问题，发现模型在上下文中持续流动的信息之间可能会遭受干扰，导致遗忘之前学到的知识，降低性能。

    

    大型语言模型（LLMs）由于其卓越的能力和广泛的世界知识而对社会产生了巨大影响。创建了各种应用和工具，使用户可以以黑盒场景与这些模型交互。然而，这种场景的限制之一是用户无法修改模型的内部知识，添加或修改内部知识的唯一方法是在当前交互过程中明确提及。这种学习过程称为上下文训练，指的是限定在用户当前会话或上下文中进行的训练。上下文学习具有重要的应用，但也存在很少研究的限制。在本文中，我们展示了一项研究，说明了模型可能会遭受在上下文中不断流动的信息之间的干扰，从而导致遗忘先前学到的知识，降低模型的性能。除了展示问题，我们还提出了解决方案来解决该问题。

    Large language models (LLMs) have had a huge impact on society due to their impressive capabilities and vast knowledge of the world. Various applications and tools have been created that allow users to interact with these models in a black-box scenario. However, one limitation of this scenario is that users cannot modify the internal knowledge of the model, and the only way to add or modify internal knowledge is by explicitly mentioning it to the model during the current interaction. This learning process is called in-context training, and it refers to training that is confined to the user's current session or context. In-context learning has significant applications, but also has limitations that are seldom studied. In this paper, we present a study that shows how the model can suffer from interference between information that continually flows in the context, causing it to forget previously learned knowledge, which can reduce the model's performance. Along with showing the problem, w
    
[^18]: 语义相似性预测优于其他语义相似性度量方法

    Semantic similarity prediction is better than other semantic similarity measures. (arXiv:2309.12697v1 [cs.CL])

    [http://arxiv.org/abs/2309.12697](http://arxiv.org/abs/2309.12697)

    本文提出了一种使用经过微调的模型直接预测语义相似性的方法，并将其与其他方法进行比较，结果表明所得到的相似性更加符合我们对鲁棒的语义相似性度量的预期。

    

    自然语言文本之间的语义相似性通常通过检查子序列的重叠（例如BLEU）或使用嵌入（例如BERTScore，S-BERT）来衡量。在本文中，我们认为当我们仅对衡量语义相似性感兴趣时，直接使用经过微调的模型来预测相似性比其他方法更好。我们使用从GLUE基准测试中微调的STS-B模型，定义了STSScore方法，并且显示出所得到的相似性与我们对鲁棒的语义相似性度量的预期更加一致。

    Semantic similarity between natural language texts is typically measured either by looking at the overlap between subsequences (e.g., BLEU) or by using embeddings (e.g., BERTScore, S-BERT). Within this paper, we argue that when we are only interested in measuring the semantic similarity, it is better to directly predict the similarity using a fine-tuned model for such a task. Using a fine-tuned model for the STS-B from the GLUE benchmark, we define the STSScore approach and show that the resulting similarity is better aligned with our expectations on a robust semantic similarity measure than other approaches.
    
[^19]: AMPLIFY: 基于注意力机制的Mixup方法，用于提高Transformer模型的性能和标签平滑

    AMPLIFY:Attention-based Mixup for Performance Improvement and Label Smoothing in Transformer. (arXiv:2309.12689v1 [cs.LG])

    [http://arxiv.org/abs/2309.12689](http://arxiv.org/abs/2309.12689)

    AMPLIFY提出了一种基于注意力机制的Mixup方法，用于减少原始样本中的噪音和异常值对于模型的影响，并在文本分类任务中表现出更好的性能。

    

    Mixup是一种有效的数据增强方法，通过对不同原始样本的线性组合生成新的增强样本。然而，如果原始样本中存在噪音或异常特征，Mixup可能将其传播到增强样本中，导致模型对这些异常值过于敏感。为了解决这个问题，本文提出了一种新的Mixup方法称为AMPLIFY。该方法利用Transformer自身的注意力机制减少原始样本中噪音和异常值对预测结果的影响，无需增加可训练参数，计算成本非常低，从而避免了常见Mixup方法（例如语句Mixup）中资源消耗过高的问题。实验结果表明，在更小的计算资源成本下，AMPLIFY在7个基准数据集的文本分类任务中优于其他Mixup方法，为进一步提高模型性能提供了新的思路和方法。

    Mixup is an effective data augmentation method that generates new augmented samples by aggregating linear combinations of different original samples. However, if there are noises or aberrant features in the original samples, Mixup may propagate them to the augmented samples, leading to over-sensitivity of the model to these outliers . To solve this problem, this paper proposes a new Mixup method called AMPLIFY. This method uses the Attention mechanism of Transformer itself to reduce the influence of noises and aberrant values in the original samples on the prediction results, without increasing additional trainable parameters, and the computational cost is very low, thereby avoiding the problem of high resource consumption in common Mixup methods such as Sentence Mixup . The experimental results show that, under a smaller computational resource cost, AMPLIFY outperforms other Mixup methods in text classification tasks on 7 benchmark datasets, providing new ideas and new ways to further
    
[^20]: JCoLA: 日本语言可接受性语料库

    JCoLA: Japanese Corpus of Linguistic Acceptability. (arXiv:2309.12676v1 [cs.CL])

    [http://arxiv.org/abs/2309.12676](http://arxiv.org/abs/2309.12676)

    本文介绍了JCoLA（日本语言可接受性语料库），该语料库包含10,020个句子，用于评估不同类型的日语语言模型的句法知识。

    

    神经语言模型在各种下游任务中表现出色。然而，目前对于这些模型内化句法知识的程度还有限，因此最近已经构建了各种数据集来促进语言模型在不同语言上的句法评估。在本文中，我们介绍了JCoLA（日本语言可接受性语料库），它包含10,020个通过二元可接受性判断注释的句子。具体来说，这些句子是从语言学教材、手册和期刊文章中手动提取的，并分为领域内数据（86％；从教材和手册中提取的相对简单的可接受性判断）和领域外数据（14％；从期刊文章中提取的理论上重要的可接受性判断），后者按照12种语言现象进行分类。然后，我们评估了9种不同类型的日语语言模型的句法知识。

    Neural language models have exhibited outstanding performance in a range of downstream tasks. However, there is limited understanding regarding the extent to which these models internalize syntactic knowledge, so that various datasets have recently been constructed to facilitate syntactic evaluation of language models across languages. In this paper, we introduce JCoLA (Japanese Corpus of Linguistic Acceptability), which consists of 10,020 sentences annotated with binary acceptability judgments. Specifically, those sentences are manually extracted from linguistics textbooks, handbooks and journal articles, and split into in-domain data (86 %; relatively simple acceptability judgments extracted from textbooks and handbooks) and out-of-domain data (14 %; theoretically significant acceptability judgments extracted from journal articles), the latter of which is categorized by 12 linguistic phenomena. We then evaluate the syntactic knowledge of 9 different types of Japanese language models 
    
[^21]: HRoT: 混合提示策略和检索思路用于表-文本混合问答

    HRoT: Hybrid prompt strategy and Retrieval of Thought for Table-Text Hybrid Question Answering. (arXiv:2309.12669v1 [cs.CL])

    [http://arxiv.org/abs/2309.12669](http://arxiv.org/abs/2309.12669)

    本文介绍了一种新的混合提示策略和检索思路，用于解决表-文本混合问答任务。该方法通过上下文学习，使模型具备处理混合数据的检索思考能力，并在MultiHiertt数据集上的少样本设置下取得了优越性能。

    

    在给定的表格和文本数据(TextTableQA)上回答数值问题是一个具有挑战性的任务。最近，大型语言模型在自然语言处理领域引起了重大关注。随着大型语言模型的出现，上下文学习和思路链提示成为了这个领域中特别流行的两个研究主题。在本文中，我们引入了一种称为混合提示策略和检索思路的新提示策略，用于文本和表格混合问答。通过上下文学习，我们促使模型在处理混合数据时能够具备检索思考的能力。我们的方法在少样本设置下，在MultiHiertt数据集上实现了优越的性能，超过了全部监督SOTA方法。

    Answering numerical questions over hybrid contents from the given tables and text(TextTableQA) is a challenging task. Recently, Large Language Models (LLMs) have gained significant attention in the NLP community. With the emergence of large language models, In-Context Learning and Chain-of-Thought prompting have become two particularly popular research topics in this field. In this paper, we introduce a new prompting strategy called Hybrid prompt strategy and Retrieval of Thought for TextTableQA. Through In-Context Learning, we prompt the model to develop the ability of retrieval thinking when dealing with hybrid data. Our method achieves superior performance compared to the fully-supervised SOTA on the MultiHiertt dataset in the few-shot setting.
    
[^22]: 在双人对话中解码情感：通过句子嵌入利用语义相似性

    Decoding Affect in Dyadic Conversations: Leveraging Semantic Similarity through Sentence Embedding. (arXiv:2309.12646v1 [cs.CL])

    [http://arxiv.org/abs/2309.12646](http://arxiv.org/abs/2309.12646)

    本研究通过利用句子嵌入和语义相似性，解码了双人对话中的情感，并发现在冲突对话中，妻子的情感与语义相似性呈正相关。

    

    自然语言处理的最新进展突显了句子嵌入在测量语义相似性方面的潜力。然而，其在分析现实中的双人互动并预测对话参与者情感方面的应用仍然很少。为了弥补这一空白，本研究利用50对夫妻之间关于冲突和愉快活动的口头对话。采用基于Transformer的模型all-MiniLM-L6-v2来获得每个发言者话语的嵌入。然后，通过嵌入相邻话语之间的余弦相似性的平均值对对话的整体相似性进行量化。结果显示，语义相似性与妻子在冲突对话中的情感呈正相关（但在愉快对话中不相关）。此外，无论对话类型如何，都未观察到这种相关性与丈夫的情感之间。两个验证检验进一步支持了t

    Recent advancements in Natural Language Processing (NLP) have highlighted the potential of sentence embeddings in measuring semantic similarity. Yet, its application in analyzing real-world dyadic interactions and predicting the affect of conversational participants remains largely uncharted. To bridge this gap, the present study utilizes verbal conversations within 50 married couples talking about conflicts and pleasant activities. Transformer-based model all-MiniLM-L6-v2 was employed to obtain the embeddings of the utterances from each speaker. The overall similarity of the conversation was then quantified by the average cosine similarity between the embeddings of adjacent utterances. Results showed that semantic similarity had a positive association with wives' affect during conflict (but not pleasant) conversations. Moreover, this association was not observed with husbands' affect regardless of conversation types. Two validation checks further provided support for the validity of t
    
[^23]: 基于增强语言模型的建筑合同风险识别

    Construction contract risk identification based on knowledge-augmented language model. (arXiv:2309.12626v1 [cs.AI])

    [http://arxiv.org/abs/2309.12626](http://arxiv.org/abs/2309.12626)

    本文提出了一种基于增强语言模型的建筑合同风险识别方法，利用具备建筑合同知识的大型语言模型模拟人类专家的合同审查过程。该方法无需调整，能够识别建筑合同风险，并在真实环境中取得了良好性能。

    

    在建筑项目中，合同审查是防止潜在损失的重要步骤。然而，当前用于审查建筑合同的方法缺乏效果和可靠性，导致耗时和容易出错。虽然大型语言模型（LLMs）在改革自然语言处理（NLP）任务方面显示出潜力，但它们在处理领域特定知识和解决专门问题方面存在困难。本文提出了一种新颖的方法，利用具备建筑合同知识的LLMs来模拟人类专家的合同审查过程。我们的无调整方法将建筑合同领域知识结合到语言模型中，以识别建筑合同风险。在构建领域知识库时使用自然语言有助于实际应用。我们在真实的建筑合同上对我们的方法进行了评估，并取得了良好的性能。此外，我们还研究了大型语言模型如何应用于建筑合同的识别过程。

    Contract review is an essential step in construction projects to prevent potential losses. However, the current methods for reviewing construction contracts lack effectiveness and reliability, leading to time-consuming and error-prone processes. While large language models (LLMs) have shown promise in revolutionizing natural language processing (NLP) tasks, they struggle with domain-specific knowledge and addressing specialized issues. This paper presents a novel approach that leverages LLMs with construction contract knowledge to emulate the process of contract review by human experts. Our tuning-free approach incorporates construction contract domain knowledge to enhance language models for identifying construction contract risks. The use of a natural language when building the domain knowledge base facilitates practical implementation. We evaluated our method on real construction contracts and achieved solid performance. Additionally, we investigated how large language models employ
    
[^24]: DRG-LLaMA: 调优LLaMA模型以预测住院患者的诊断相关分组

    DRG-LLaMA : Tuning LLaMA Model to Predict Diagnosis-related Group for Hospitalized Patients. (arXiv:2309.12625v1 [cs.AI])

    [http://arxiv.org/abs/2309.12625](http://arxiv.org/abs/2309.12625)

    DRG-LLaMA是一个通过在临床笔记上细调的大型语言模型，用于改进住院患者的诊断相关分组预测。在多个评估指标上，DRG-LLaMA-7B相对于其他模型取得了显著的改进，并能够高准确度地预测基本DRG和并发症/合并症（CC）/重大并发症或合并症（MCC）的状态。

    

    在美国住院付费系统中，诊断相关分组（DRG）起着关键作用，但目前的分组过程耗时。我们引入了DRG-LLaMA，一个在临床笔记上进行细调的大型语言模型（LLM），以改善DRG预测。使用Meta的LLaMA作为基础模型，我们通过在236,192个MIMIC-IV出院摘要上进行低秩适应（LoRA）优化。在输入令牌长度为512的情况下，DRG-LLaMA-7B实现的宏平均F1分数为0.327，顶级预测准确度为52.0％，宏平均AUC为0.986。令人印象深刻的是，DRG-LLaMA-7B在这个任务上超过了之前报道的领先模型，相对于ClinicalBERT的宏平均F1分数提高了40.3％，相对于CAML提高了35.7％。当应用DRG-LLaMA来预测基本DRG和并发症/合并症（CC）/重大并发症或合并症（MCC）时，基本DRG的顶级预测准确度达到了67.8％，而CC/MCC状态的预测准确度达到了67.5％。

    In the U.S. inpatient payment system, the Diagnosis-Related Group (DRG) plays a key role but its current assignment process is time-consuming. We introduce DRG-LLaMA, a large language model (LLM) fine-tuned on clinical notes for improved DRG prediction. Using Meta's LLaMA as the base model, we optimized it with Low-Rank Adaptation (LoRA) on 236,192 MIMIC-IV discharge summaries. With an input token length of 512, DRG-LLaMA-7B achieved a macro-averaged F1 score of 0.327, a top-1 prediction accuracy of 52.0% and a macro-averaged Area Under the Curve (AUC) of 0.986. Impressively, DRG-LLaMA-7B surpassed previously reported leading models on this task, demonstrating a relative improvement in macro-averaged F1 score of 40.3% compared to ClinicalBERT and 35.7% compared to CAML. When DRG-LLaMA is applied to predict base DRGs and complication or comorbidity (CC) / major complication or comorbidity (MCC), the top-1 prediction accuracy reached 67.8% for base DRGs and 67.5% for CC/MCC status. DRG-L
    
[^25]: 通过退化模型学习多样化神经文本生成

    Learning to Diversify Neural Text Generation via Degenerative Model. (arXiv:2309.12619v1 [cs.CL])

    [http://arxiv.org/abs/2309.12619](http://arxiv.org/abs/2309.12619)

    我们通过训练两个模型，一个放大不良模式，一个增强多样性，来解决神经文本生成中多样性不足的问题。实验证明了我们方法的有效性。

    

    神经语言模型在生成多样化且信息丰富的文本方面往往失败，限制了它们在实际问题中的适用性。虽然先前的方法通过识别和惩罚语言模型中的不良行为（例如重复、过度使用高频词汇）来解决这些问题，但我们提出了一种基于观察结果的替代方法：模型主要学习可能导致退化问题的示例中的属性。基于这一观察结果，我们提出了一种通过训练两个模型来预防退化问题的新方法。具体而言，我们首先训练一个旨在放大不良模式的模型。然后，通过专注于第一个模型未能学习到的模式来增强第二个模型的多样性。对语言建模和对话生成这两个任务的大量实验证明了我们方法的有效性。

    Neural language models often fail to generate diverse and informative texts, limiting their applicability in real-world problems. While previous approaches have proposed to address these issues by identifying and penalizing undesirable behaviors (e.g., repetition, overuse of frequent words) from language models, we propose an alternative approach based on an observation: models primarily learn attributes within examples that are likely to cause degeneration problems. Based on this observation, we propose a new approach to prevent degeneration problems by training two models. Specifically, we first train a model that is designed to amplify undesirable patterns. We then enhance the diversity of the second model by focusing on patterns that the first model fails to learn. Extensive experiments on two tasks, namely language modeling and dialogue generation, demonstrate the effectiveness of our approach.
    
[^26]: 解锁模型洞察力：用于自动生成模型卡片的数据集

    Unlocking Model Insights: A Dataset for Automated Model Card Generation. (arXiv:2309.12616v1 [cs.CL])

    [http://arxiv.org/abs/2309.12616](http://arxiv.org/abs/2309.12616)

    该论文介绍了一个包含25个ML模型的数据集，用于自动生成模型卡片。实验发现目前存在的指令模型在研究论文的理解和生成准确文本方面存在显著差距。

    

    语言模型（LMs）不再局限于机器学习界，针对指令的LMs引发了自主AI代理的兴起。随着LMs的可访问性增加，提高对其能力、预期用途和开发周期的理解变得至关重要。模型卡片是记录关于ML模型详细信息的常见实践。为了自动化模型卡片的生成，我们引入了一个包含25个ML模型的500个问答对的数据集，涵盖了模型的关键方面，如训练配置、数据集、偏见、架构细节和训练资源。我们雇佣注释者从原始论文中提取答案。此外，我们还通过回答问题来探索LMs在生成模型卡片方面的能力。我们对ChatGPT-3.5、LLaMa和Galactica的初步实验显示出这些LMs对研究论文的理解以及生成事实性文本响应方面存在显著差距。

    Language models (LMs) are no longer restricted to ML community, and instruction-tuned LMs have led to a rise in autonomous AI agents. As the accessibility of LMs grows, it is imperative that an understanding of their capabilities, intended usage, and development cycle also improves. Model cards are a popular practice for documenting detailed information about an ML model. To automate model card generation, we introduce a dataset of 500 question-answer pairs for 25 ML models that cover crucial aspects of the model, such as its training configurations, datasets, biases, architecture details, and training resources. We employ annotators to extract the answers from the original paper. Further, we explore the capabilities of LMs in generating model cards by answering questions. Our initial experiments with ChatGPT-3.5, LLaMa, and Galactica showcase a significant gap in the understanding of research papers by these aforementioned LMs as well as generating factual textual responses. We posit 
    
[^27]: 大型语言模型下的创造力支持: 一项涉及新兴作家的实证研究

    Creativity Support in the Age of Large Language Models: An Empirical Study Involving Emerging Writers. (arXiv:2309.12570v1 [cs.HC])

    [http://arxiv.org/abs/2309.12570](http://arxiv.org/abs/2309.12570)

    本文通过实证研究探讨了大型语言模型（LLM）在协助专业作家方面的效用，并发现作家们更倾向于在翻译和审查阶段中寻求LLM的帮助。

    

    大型语言模型（LLM）的发展使得其能够遵循指令并参与对话互动，引发了在各种支持工具中利用它们的兴趣增加。我们通过一项实证用户研究（n=30）探讨了现代LLM在协助专业作家方面的效用。我们的合作写作界面设计基于将写作视为一个目标导向的思维过程的认知过程模型，涵盖了非线性的认知活动：规划、翻译和审查。参与者被要求提交一份后完成调查，以提供关于LLM作为写作合作者潜力和问题的反馈。通过分析作家-LLM互动,我们发现作家在三种类型的认知活动中都寻求LLM的帮助，但他们发现LLM在翻译和审查方面更有帮助。通过分析互动和调查结果，我们的发现强调了未来研究的方向。

    The development of large language models (LLMs) capable of following instructions and engaging in conversational interactions sparked increased interest in their utilization across various support tools. We investigate the utility of modern LLMs in assisting professional writers via an empirical user study (n=30). The design of our collaborative writing interface is grounded in the cognitive process model of writing that views writing as a goal-oriented thinking process encompassing non-linear cognitive activities: planning, translating, and reviewing. Participants are asked to submit a post-completion survey to provide feedback on the potential and pitfalls of LLMs as writing collaborators. Upon analyzing the writer-LLM interactions, we find that while writers seek LLM's help across all three types of cognitive activities, they find LLMs more helpful in translation and reviewing. Our findings from analyzing both the interactions and the survey responses highlight future research direc
    
[^28]: PlanFitting：利用大型语言模型定制个性化的运动计划

    PlanFitting: Tailoring Personalized Exercise Plans with Large Language Models. (arXiv:2309.12555v1 [cs.HC])

    [http://arxiv.org/abs/2309.12555](http://arxiv.org/abs/2309.12555)

    PlanFitting是一个对话型人工智能，利用大型语言模型的生成能力帮助用户定制个性化的运动计划，并在用户研究中证明了它生成个性化、可操作和有据可依的运动计划的潜力。

    

    个性化的运动计划对于确保足够的体育活动至关重要，但由于人们的复杂日程和考虑因素以及计划的创建通常需要与专家的反复沟通，这一过程变得具有挑战性。我们提出了PlanFitting，它是一个对话型人工智能，可以辅助个性化的运动计划。通过利用大型语言模型的生成能力，PlanFitting使用户能够用自然语言描述各种约束和查询，从而便于创建和优化适合其特定情况的每周运动计划，并保持基本原则的扎根。通过一项用户研究，参与者（N=18）使用PlanFitting生成个性化的运动计划，而专家规划者（N=3）对这些计划进行评估，我们确定了PlanFitting在生成个性化、可操作和有据可依的运动计划方面的潜力。我们还讨论了AI助手在创建计划方面的未来设计机遇。

    A personally tailored exercise regimen is crucial to ensuring sufficient physical activities, yet challenging to create as people have complex schedules and considerations and the creation of plans often requires iterations with experts. We present PlanFitting, a conversational AI that assists in personalized exercise planning. Leveraging generative capabilities of large language models, PlanFitting enables users to describe various constraints and queries in natural language, thereby facilitating the creation and refinement of their weekly exercise plan to suit their specific circumstances while staying grounded in foundational principles. Through a user study where participants (N=18) generated a personalized exercise plan using PlanFitting and expert planners (N=3) evaluated these plans, we identified the potential of PlanFitting in generating personalized, actionable, and evidence-based exercise plans. We discuss future design opportunities for AI assistants in creating plans that 
    
[^29]: 问句生成的自动回答可行性评估

    Automatic Answerability Evaluation for Question Generation. (arXiv:2309.12546v1 [cs.CL])

    [http://arxiv.org/abs/2309.12546](http://arxiv.org/abs/2309.12546)

    这项工作提出了一种新颖的自动评估指标，用于评估问句生成任务中生成的问题是否可以由参考答案回答。实验证明该指标结果可靠，并与人工评价一致。并且这个指标可以补充传统的指标。

    

    传统的自动评估指标，如BLEU和ROUGE，是为自然语言生成（NLG）任务开发的，它们基于生成文本与参考文本之间的n-gram重叠度来衡量。这些简单的评估指标可能对于更复杂的任务，比如问句生成（QG），是不足够的，因为QG需要生成可以由参考答案回答的问题。因此，开发更复杂的自动评估指标仍然是QG研究中的一个紧迫问题。本文提出了一种基于提示的可回答性度量（PMAN），一种新颖的自动评估指标，用于评估问句生成任务中生成的问题是否可以由参考答案回答。大量实验证明，该评估结果可靠，并与人工评价一致。我们进一步应用我们的指标来评估QG模型的性能，结果显示我们的指标补充了传统的指标。我们基于ChatGPT的QG模型的实现取得了令人满意的成绩。

    Conventional automatic evaluation metrics, such as BLEU and ROUGE, developed for natural language generation (NLG) tasks, are based on measuring the n-gram overlap between the generated and reference text. These simple metrics may be insufficient for more complex tasks, such as question generation (QG), which requires generating questions that are answerable by the reference answers. Developing a more sophisticated automatic evaluation metric, thus, remains as an urgent problem in QG research. This work proposes a Prompting-based Metric on ANswerability (PMAN), a novel automatic evaluation metric to assess whether the generated questions are answerable by the reference answers for the QG tasks. Extensive experiments demonstrate that its evaluation results are reliable and align with human evaluations. We further apply our metric to evaluate the performance of QG models, which shows our metric complements conventional metrics. Our implementation of a ChatGPT-based QG model achieves stat
    
[^30]: 知识图谱嵌入：综述

    Knowledge Graph Embedding: An Overview. (arXiv:2309.12501v1 [cs.AI])

    [http://arxiv.org/abs/2309.12501](http://arxiv.org/abs/2309.12501)

    该论文综述了知识图谱嵌入的研究状态，介绍了两个主要分支：基于距离和基于语义匹配的方法。还讨论了CompoundE和CompoundE3D模型，并揭示了一个潜在的研究趋势。

    

    许多数学模型已被利用来设计嵌入，以表示知识图谱（KG）中的实体和关系，用于链接预测和许多下游任务。这些数学启发的模型不仅在大型KG中进行推理时高度可扩展，而且在建模不同关系模式方面具有很多可解释的优势，这些优势可以通过形式化证明和经验结果来验证。在本文中，我们对KG完成领域的当前研究状态进行了全面的概述。特别是，我们着重介绍了KG嵌入（KGE）设计的两个主要分支：1）基于距离的方法和2）基于语义匹配的方法。我们发现了最近提出的模型之间的联系，并提出了一个潜在的趋势，这可能有助于研究人员发明新颖且更有效的模型。接下来，我们深入探讨了从2D和3D仿射操作中汲取灵感的CompoundE和CompoundE3D。它们涵盖了包括dis在内的广泛技术谓词的范围。

    Many mathematical models have been leveraged to design embeddings for representing Knowledge Graph (KG) entities and relations for link prediction and many downstream tasks. These mathematically-inspired models are not only highly scalable for inference in large KGs, but also have many explainable advantages in modeling different relation patterns that can be validated through both formal proofs and empirical results. In this paper, we make a comprehensive overview of the current state of research in KG completion. In particular, we focus on two main branches of KG embedding (KGE) design: 1) distance-based methods and 2) semantic matching-based methods. We discover the connections between recently proposed models and present an underlying trend that might help researchers invent novel and more effective models. Next, we delve into CompoundE and CompoundE3D, which draw inspiration from 2D and 3D affine operations, respectively. They encompass a broad spectrum of techniques including dis
    
[^31]: 探索训练数据分布和子词标记对机器翻译中的性别偏见的影响

    Exploring the Impact of Training Data Distribution and Subword Tokenization on Gender Bias in Machine Translation. (arXiv:2309.12491v1 [cs.CL])

    [http://arxiv.org/abs/2309.12491](http://arxiv.org/abs/2309.12491)

    这项研究探索了训练数据分布和子词标记对机器翻译中性别偏见的影响。研究发现，模型训练语料库中性别形式的不平衡是导致性别偏见的主要因素，而子词拆分的影响较小。同时，研究还发现，通过分析子词拆分可以很好地估计训练数据中性别形式的不平衡。最后，通过仅微调标记嵌入层可以减少女性和男性之间性别预测准确性的差距。

    

    我们研究了标记化对机器翻译中性别偏见的影响，这是之前的研究中被大多数人忽视的一个方面。具体而言，我们关注的是训练数据中性别职业名称的频率、它们在子词标记器词汇表中的表示以及性别偏见之间的相互作用。我们观察到，女性和非刻板印象的性别职业名称的变形（例如，西班牙语中的"doctora"表示"女医生"）往往被拆分成多个子词标记。我们的结果表明，模型训练语料库中性别形式的不平衡是导致性别偏见的主要因素，其影响大于子词拆分。我们展示了分析子词拆分可以很好地估计训练数据中性别形式的不平衡，并且可以在语料库不公开的情况下使用。我们还证明，仅微调标记嵌入层可以减少女性和男性之间性别预测准确性的差距。

    We study the effect of tokenization on gender bias in machine translation, an aspect that has been largely overlooked in previous works. Specifically, we focus on the interactions between the frequency of gendered profession names in training data, their representation in the subword tokenizer's vocabulary, and gender bias. We observe that female and non-stereotypical gender inflections of profession names (e.g., Spanish "doctora" for "female doctor") tend to be split into multiple subword tokens. Our results indicate that the imbalance of gender forms in the model's training corpus is a major factor contributing to gender bias and has a greater impact than subword splitting. We show that analyzing subword splits provides good estimates of gender-form imbalance in the training data and can be used even when the corpus is not publicly available. We also demonstrate that fine-tuning just the token embedding layer can decrease the gap in gender prediction accuracy between female and male 
    
[^32]: 研究和改进人类和机器的推理能力

    Studying and improving reasoning in humans and machines. (arXiv:2309.12485v1 [cs.CL])

    [http://arxiv.org/abs/2309.12485](http://arxiv.org/abs/2309.12485)

    本研究通过对大型语言模型（LLM）和人类的推理能力进行比较研究，发现LLM在推理中存在类似于人类启发式推理的错误，但与人类推理有重要差异，最新的LLM版本几乎消除了模型的限制。此外，人类和机器对相同的提示方案的反应不同。这些结果对我们的认识论有重大影响。

    

    在本研究中，我们使用传统用于研究（有限）理性的认知心理学工具，研究和比较了大型语言模型（LLM）和人类的推理能力。为此，我们向人类参与者和一系列预训练的LLM呈现了新的经典认知实验的变体，并对它们的表现进行了交叉比较。我们的结果显示，大多数模型呈现出类似于常见的错误倾向于启发式人类推理的推理错误。尽管有这种表面上的相似性，人类和LLM之间的深入比较表明了人类样式推理的重要差异，随着最近LLM版本的推出，模型的限制几乎完全消失。此外，我们还展示出，虽然可能制定策略以获得更好的表现，但人类和机器对相同的提示方案的反应并不相同。我们通过讨论这一认识论的影响来总结。

    In the present study, we investigate and compare reasoning in large language models (LLM) and humans using a selection of cognitive psychology tools traditionally dedicated to the study of (bounded) rationality. To do so, we presented to human participants and an array of pretrained LLMs new variants of classical cognitive experiments, and cross-compared their performances. Our results showed that most of the included models presented reasoning errors akin to those frequently ascribed to error-prone, heuristic-based human reasoning. Notwithstanding this superficial similarity, an in-depth comparison between humans and LLMs indicated important differences with human-like reasoning, with models limitations disappearing almost entirely in more recent LLMs releases. Moreover, we show that while it is possible to devise strategies to induce better performance, humans and machines are not equally-responsive to the same prompting schemes. We conclude by discussing the epistemological implicat
    
[^33]: HANS，你聪明吗？神经系统的Clever Hans效应分析

    HANS, are you clever? Clever Hans Effect Analysis of Neural Systems. (arXiv:2309.12481v1 [cs.CL])

    [http://arxiv.org/abs/2309.12481](http://arxiv.org/abs/2309.12481)

    这项研究调查了指导调整的大型语言模型（It-LLMs）对多项选择题（MCQ）的鲁棒性能力，在选择顺序变动时揭示了选择偏见和推理能力的问题。

    

    指导调整的大型语言模型(It-LLMs)展示出了在认知状态、意图和反应方面推理的出色能力，可以让人们有效地引导和理解日常社交互动。事实上，已经提出了几个多项选择题(MCQ)基准来构建对模型能力的确切评估。然而，早期的研究表明It-LLMs中存在固有的“顺序偏见”，给适当的评估带来了挑战。本文通过使用四个MCQ基准对It-LLMs的抵抗能力进行了研究。通过引入对抗性示例，我们展示了显著的性能差距，特别是在选择顺序变动时，揭示了选择偏见并引发了对推理能力的讨论。通过第一位置和模型选择之间的相关性，我们假设在模型中存在结构启发式方法。

    Instruction-tuned Large Language Models (It-LLMs) have been exhibiting outstanding abilities to reason around cognitive states, intentions, and reactions of all people involved, letting humans guide and comprehend day-to-day social interactions effectively. In fact, several multiple-choice questions (MCQ) benchmarks have been proposed to construct solid assessments of the models' abilities. However, earlier works are demonstrating the presence of inherent "order bias" in It-LLMs, posing challenges to the appropriate evaluation. In this paper, we investigate It-LLMs' resilience abilities towards a series of probing tests using four MCQ benchmarks. Introducing adversarial examples, we show a significant performance gap, mainly when varying the order of the choices, which reveals a selection bias and brings into discussion reasoning abilities. Following a correlation between first positions and model choices due to positional bias, we hypothesized the presence of structural heuristics in 
    
[^34]: 多模态深度学习用于科学成像解释

    Multimodal Deep Learning for Scientific Imaging Interpretation. (arXiv:2309.12460v1 [cs.LG])

    [http://arxiv.org/abs/2309.12460](http://arxiv.org/abs/2309.12460)

    本研究提出了一种多模态深度学习框架，通过模拟人类与扫描电子显微镜图像的交互，利用文本和视觉数据进行精细数据合成和评估。该模型（GlassLLaVA）能够准确解释、识别关键特征和检测以前未见的SEM图像中的缺陷，同时引入了适用于多种科学成像应用的灵活评估指标。

    

    在科学成像领域，解释视觉数据常常需要人类专业知识和对主题材料的深入理解的复杂组合。本研究提出了一种新的方法，通过多模态深度学习框架来模拟并评估与扫描电子显微镜（SEM）图像的人类交互，特别是玻璃材料图像。我们的方法利用从同行评议的文章中收集的文本和视觉数据，进一步借助 GPT-4 的能力进行精细数据合成和评估。尽管存在诸多挑战，如细微的解释和专业数据集的有限可用性，但我们的模型（GlassLLaVA）在制定准确的解释、识别关键特征和检测以前未见的SEM图像中的缺陷方面表现出色。此外，我们引入了适用于多种科学成像应用的灵活评估指标，使得进行综合评估成为可能。

    In the domain of scientific imaging, interpreting visual data often demands an intricate combination of human expertise and deep comprehension of the subject materials. This study presents a novel methodology to linguistically emulate and subsequently evaluate human-like interactions with Scanning Electron Microscopy (SEM) images, specifically of glass materials. Leveraging a multimodal deep learning framework, our approach distills insights from both textual and visual data harvested from peer-reviewed articles, further augmented by the capabilities of GPT-4 for refined data synthesis and evaluation. Despite inherent challenges--such as nuanced interpretations and the limited availability of specialized datasets--our model (GlassLLaVA) excels in crafting accurate interpretations, identifying key features, and detecting defects in previously unseen SEM images. Moreover, we introduce versatile evaluation metrics, suitable for an array of scientific imaging applications, which allows for
    
[^35]: LongDocFACTScore: 评估长文档生成摘要的实证性。

    LongDocFACTScore: Evaluating the Factuality of Long Document Abstractive Summarisation. (arXiv:2309.12455v1 [cs.CL])

    [http://arxiv.org/abs/2309.12455](http://arxiv.org/abs/2309.12455)

    LongDocFACTScore是一种评估长文档生成摘要实证性的评估框架，可以解决传统自动评估度量标准无法评估长文档摘要事实一致性的问题。

    

    保持事实一致性是生成性文本摘要中的一个关键问题，然而，传统的用于评估文本摘要的自动度量标准（如ROUGE得分）无法评估事实一致性。最近，人们致力于开发使用预训练语言模型来测量事实一致性的改进度量标准，但这些度量标准有限制性的令牌限制，因此不适用于评估长文档生成摘要。此外，目前有限的研究评估了现有自动评估度量标准在应用于长文档数据集时是否适用。在这项工作中，我们评估了自动度量标准在评估长文档生成摘要的事实一致性方面的功效，并提出了一种新的评估框架LongDocFACTScore。该框架允许度量标准扩展到任意长度的文档。该框架在与人类事实一致性度量的相关性方面优于现有的最先进度量标准。

    Maintaining factual consistency is a critical issue in abstractive text summarisation, however, it cannot be assessed by traditional automatic metrics used for evaluating text summarisation, such as ROUGE scoring. Recent efforts have been devoted to developing improved metrics for measuring factual consistency using pre-trained language models, but these metrics have restrictive token limits, and are therefore not suitable for evaluating long document text summarisation. Moreover, there is limited research evaluating whether existing automatic evaluation metrics are fit for purpose when applied to long document data sets. In this work, we evaluate the efficacy of automatic metrics at assessing factual consistency in long document text summarisation and propose a new evaluation framework LongDocFACTScore. This framework allows metrics to be extended to any length document. This framework outperforms existing state-of-the-art metrics in its ability to correlate with human measures of fac
    
[^36]: 基于生成AI的医疗对话效果的量化度量

    Foundation Metrics: Quantifying Effectiveness of Healthcare Conversations powered by Generative AI. (arXiv:2309.12444v1 [cs.CL])

    [http://arxiv.org/abs/2309.12444](http://arxiv.org/abs/2309.12444)

    这篇论文提出了基于生成AI的医疗对话模型的评估指标问题，并强调了现有指标对医学和健康概念的理解不足以及忽略了用户体验因素。

    

    生成人工智能将通过将传统的患者护理转变为更个性化、高效和积极的过程，彻底改变医疗保健交付方式。聊天机器人作为互动对话模型，很可能推动医疗保健的以患者为中心的转型。通过提供诊断、个性化生活方式建议和心理健康支持等各种服务，目标是大幅度提高患者的健康结果，同时减轻医疗保健提供者的工作负担。医疗应用的生命关键性要求建立统一全面的对话模型评估指标。已有的针对各种通用大型语言模型(LLMs)提出的评估指标在理解医学和健康概念及其在促进患者福祉方面的重要性方面存在不足。此外，这些指标忽略了关键的用户体验因素。

    Generative Artificial Intelligence is set to revolutionize healthcare delivery by transforming traditional patient care into a more personalized, efficient, and proactive process. Chatbots, serving as interactive conversational models, will probably drive this patient-centered transformation in healthcare. Through the provision of various services, including diagnosis, personalized lifestyle recommendations, and mental health support, the objective is to substantially augment patient health outcomes, all the while mitigating the workload burden on healthcare providers. The life-critical nature of healthcare applications necessitates establishing a unified and comprehensive set of evaluation metrics for conversational models. Existing evaluation metrics proposed for various generic large language models (LLMs) demonstrate a lack of comprehension regarding medical and health concepts and their significance in promoting patients' well-being. Moreover, these metrics neglect pivotal user-ce
    
[^37]: 多语种手指拼写语料库的主动学习

    Active Learning for Multilingual Fingerspelling Corpora. (arXiv:2309.12443v1 [cs.CL])

    [http://arxiv.org/abs/2309.12443](http://arxiv.org/abs/2309.12443)

    本文应用主动学习来解决手语数据稀缺问题，并对预训练的效果进行了分析，发现预训练在多语种手指拼写语料库上有益处，可能是由于视觉上的相似性。

    

    我们应用主动学习来解决手语中的数据稀缺问题。具体而言，我们对预训练的效果进行了新颖的分析。由于许多手语是法国手语的语言后裔，它们共享手势配置，预训练有望利用这一点。我们在美国、中国、德国和爱尔兰的手指拼写语料库上测试了这一假设。我们确实观察到了预训练的好处，但这可能是由于视觉上的相似性而非语言上的相似性。

    We apply active learning to help with data scarcity problems in sign languages. In particular, we perform a novel analysis of the effect of pre-training. Since many sign languages are linguistic descendants of French sign language, they share hand configurations, which pre-training can hopefully exploit. We test this hypothesis on American, Chinese, German, and Irish fingerspelling corpora. We do observe a benefit from pre-training, but this may be due to visual rather than linguistic similarities
    
[^38]: LLMs能增强低资源阅读理解数据集吗？机遇和挑战。

    Can LLMs Augment Low-Resource Reading Comprehension Datasets? Opportunities and Challenges. (arXiv:2309.12426v1 [cs.CL])

    [http://arxiv.org/abs/2309.12426](http://arxiv.org/abs/2309.12426)

    本研究分析了使用大型语言模型(LLMs)对低资源阅读理解数据集进行增强的可能性。结果显示，GPT-4可以用作低资源读解任务中人工注释者的替代品。这项工作突出了LLMs作为合成数据增强器的机遇和挑战，并发布了增强版本的低资源数据集。

    

    大型语言模型(LLMs)在广泛的NLP任务上展现出了令人印象深刻的零-shot性能，能够进行推理和应用常识。一个相关的应用是将它们用于创建高质量的合成数据集以供后续任务使用。本文探讨了是否能够使用GPT-4来增强现有的抽取式阅读理解数据集。自动化的数据注释过程有潜力节省大量时间、金钱和精力，这些都是用于手动标注数据集的。本文通过比较微调后的性能以及注释的成本，评估了GPT-4作为低资源阅读理解任务的人工注释替代者的性能。这项工作是对LLMs作为QA系统合成数据增强器的首次分析，突出了独特的机遇和挑战。此外，我们还发布了低资源数据集的增强版本，这将使研究人员能够重新评估LLMs在阅读理解任务上的性能。

    Large Language Models (LLMs) have demonstrated impressive zero shot performance on a wide range of NLP tasks, demonstrating the ability to reason and apply commonsense. A relevant application is to use them for creating high quality synthetic datasets for downstream tasks. In this work, we probe whether GPT-4 can be used to augment existing extractive reading comprehension datasets. Automating data annotation processes has the potential to save large amounts of time, money and effort that goes into manually labelling datasets. In this paper, we evaluate the performance of GPT-4 as a replacement for human annotators for low resource reading comprehension tasks, by comparing performance after fine tuning, and the cost associated with annotation. This work serves to be the first analysis of LLMs as synthetic data augmenters for QA systems, highlighting the unique opportunities and challenges. Additionally, we release augmented versions of low resource datasets, that will allow the researc
    
[^39]: 约束优先：一种基于MDD的生成受约束句子的新模型

    Constraints First: A New MDD-based Model to Generate Sentences Under Constraints. (arXiv:2309.12415v1 [cs.AI])

    [http://arxiv.org/abs/2309.12415](http://arxiv.org/abs/2309.12415)

    本文介绍了一种基于多值决策图的新模型，用于生成强约束文本。通过将生成句子问题形式化为离散组合优化问题，并利用多值决策图来处理约束，可以得到详尽解集。应用语言模型保留最佳句子，并在英语和法语上进行了详细讨论。该方法相比传统的视力筛查测试带来了重大突破，并且具有广泛的适用性。

    

    本文介绍了一种生成强约束文本的新方法。我们考虑了用于视力筛查的标准化句子生成应用。为了解决这个问题，我们将其形式化为一个离散组合优化问题，并利用多值决策图(MDD)，这是一种处理约束的著名数据结构。在我们的环境中，MDD的一个关键优势是可以计算出不需要进行任何搜索的详尽解集。一旦获得了句子，我们应用了一个语言模型(GPT-2)来保留最佳的句子。我们详细介绍了英语和法语的情况，其中一些一致和变位规则被认为更复杂。最后，借助于GPT-2，我们得到了数百个真正的候选句子。与在著名的视力筛查测试(MNREAD)中通常可用的几十个句子相比，这在标准化句子生成领域带来了重大突破。此外，由于可以轻松调整该方法适应不同的语言和约束，因此具有广泛的适用性。

    This paper introduces a new approach to generating strongly constrained texts. We consider standardized sentence generation for the typical application of vision screening. To solve this problem, we formalize it as a discrete combinatorial optimization problem and utilize multivalued decision diagrams (MDD), a well-known data structure to deal with constraints. In our context, one key strength of MDD is to compute an exhaustive set of solutions without performing any search. Once the sentences are obtained, we apply a language model (GPT-2) to keep the best ones. We detail this for English and also for French where the agreement and conjugation rules are known to be more complex. Finally, with the help of GPT-2, we get hundreds of bona-fide candidate sentences. When compared with the few dozen sentences usually available in the well-known vision screening test (MNREAD), this brings a major breakthrough in the field of standardized sentence generation. Also, as it can be easily adapted 
    
[^40]: 在基于GPT的智能辅导系统中研究领域知识库不同程度的影响

    Examining the Influence of Varied Levels of Domain Knowledge Base Inclusion in GPT-based Intelligent Tutors. (arXiv:2309.12367v1 [cs.HC])

    [http://arxiv.org/abs/2309.12367](http://arxiv.org/abs/2309.12367)

    本文研究了在基于GPT的智能辅导系统中将领域知识库与语言模型集成，以提高回答的可靠性。通过设计可扩展的知识库和评估实验，我们展示了该系统的有效性。学生和领域专家对于智能辅导系统的回答进行了验证和排名。

    

    最近大型语言模型（LLM）的进展促进了具有复杂对话能力的聊天机器人的发展。然而，LLM对查询的回答经常不准确，这限制了在教育环境中的应用。本文研究了将知识库（KB）与LLM智能辅导系统集成以增加回答可靠性的效果。为了实现这一目标，我们设计了一个可扩展的知识库，教育监督员可以无缝集成课程，该课程会被智能辅导系统自动处理。然后，我们详细介绍了一个评估实验，学生参与者需要回答有关人工智能课程的问题。 GPT-4智能辅导系统具有不同层次的KB访问权限，并由人类领域专家评估这些回答。最后，学生对智能辅导系统的回答进行了与领域专家的交叉验证，并对它们的各种教学能力进行了排名。

    Recent advancements in large language models (LLMs) have facilitated the development of chatbots with sophisticated conversational capabilities. However, LLMs exhibit frequent inaccurate responses to queries, hindering applications in educational settings. In this paper, we investigate the effectiveness of integrating a knowledge base (KB) with LLM intelligent tutors to increase response reliability. To achieve this, we design a scaleable KB that affords educational supervisors seamless integration of lesson curricula, which is automatically processed by the intelligent tutoring system. We then detail an evaluation, where student participants were presented with questions about the artificial intelligence curriculum to respond to. GPT-4 intelligent tutors with varying hierarchies of KB access and human domain experts then assessed these responses. Lastly, students cross-examined the intelligent tutors' responses to the domain experts' and ranked their various pedagogical abilities. Res
    
[^41]: ChatGPT基于病例报告辅助神经眼科疾病的诊断

    ChatGPT Assisting Diagnosis of Neuro-ophthalmology Diseases Based on Case Reports. (arXiv:2309.12361v1 [cs.CY])

    [http://arxiv.org/abs/2309.12361](http://arxiv.org/abs/2309.12361)

    本研究评估了大型语言模型ChatGPT在神经眼科疾病诊断中的辅助效果。实验结果显示，ChatGPT在13个病例中正确诊断了59%，而ChatGPT Plus和两名神经眼科医生的正确率分别达到了82%和86%。这表明ChatGPT可以作为神经眼科疾病诊断的有用工具。

    

    目的：评估大型语言模型（LLM）如ChatGPT在基于详细病例描述辅助神经眼科疾病诊断方面的效果。方法：我们从一个公开可用的在线数据库中选择了22个不同的神经眼科疾病病例报告。这些病例包括神经眼科亚专科常见的慢性和急性疾病。我们把每个病例的文本作为新的提示插入到ChatGPT v3.5和ChatGPT Plus v4.0中，并询问最有可能的诊断。然后，我们将准确的信息提供给两名神经眼科医生，并记录他们的诊断结果，然后与ChatGPT的回答进行对比。结果：ChatGPT v3.5、ChatGPT Plus v4.0和两名神经眼科医生在22个病例中分别达到13个（59%）、18个（82%）、19个（86%）和19个（86%）的正确诊断。各种诊断来源之间的一致性如下：ChatGPT v3.5和ChatGPT Plus v4.0的一致性为13个...

    Objective: To evaluate the efficiency of large language models (LLMs) such as ChatGPT to assist in diagnosing neuro-ophthalmic diseases based on detailed case descriptions. Methods: We selected 22 different case reports of neuro-ophthalmic diseases from a publicly available online database. These cases included a wide range of chronic and acute diseases that are commonly seen by neuro-ophthalmic sub-specialists. We inserted the text from each case as a new prompt into both ChatGPT v3.5 and ChatGPT Plus v4.0 and asked for the most probable diagnosis. We then presented the exact information to two neuro-ophthalmologists and recorded their diagnoses followed by comparison to responses from both versions of ChatGPT. Results: ChatGPT v3.5, ChatGPT Plus v4.0, and the two neuro-ophthalmologists were correct in 13 (59%), 18 (82%), 19 (86%), and 19 (86%) out of 22 cases, respectively. The agreement between the various diagnostic sources were as follows: ChatGPT v3.5 and ChatGPT Plus v4.0, 13 (5
    
[^42]: 通过自然语言处理和抽样实现高效的社会选择

    Efficient Social Choice via NLP and Sampling. (arXiv:2309.12360v1 [cs.CY])

    [http://arxiv.org/abs/2309.12360](http://arxiv.org/abs/2309.12360)

    本文通过结合自然语言处理和抽样技术，提出了一种高效的注意力感知社会选择系统，该系统使用训练有素的NLP模型估计了提案通过的概率，并通过采样多数来决定提案。

    

    注意力感知社会选择解决了一些代理社区面临的基本冲突，即在决策过程中包括所有成员的渴望与社区成员可支配的有限时间和注意力之间的矛盾。本文研究了注意力感知社会选择的两种技术组合，即自然语言处理（NLP）和抽样。基本上，我们提出了一个系统，其中每个改变现状的治理提案首先发送到训练有素的NLP模型，该模型估计了如果所有社区成员直接对其进行投票，该提案通过的概率；然后，基于这种估计，选择一个确定大小的人群样本，并通过采样多数决定提案。我们根据上述方案开发了几种具体算法，并使用各种数据进行评估，包括多个分散自治组织（DAO）的数据。

    Attention-Aware Social Choice tackles the fundamental conflict faced by some agent communities between their desire to include all members in the decision making processes and the limited time and attention that are at the disposal of the community members. Here, we investigate a combination of two techniques for attention-aware social choice, namely Natural Language Processing (NLP) and Sampling. Essentially, we propose a system in which each governance proposal to change the status quo is first sent to a trained NLP model that estimates the probability that the proposal would pass if all community members directly vote on it; then, based on such an estimation, a population sample of a certain size is being selected and the proposal is decided upon by taking the sample majority. We develop several concrete algorithms following the scheme described above and evaluate them using various data, including such from several Decentralized Autonomous Organizations (DAOs).
    
[^43]: 大型语言模型中的文化对齐：基于霍夫斯泰德文化维度的解释性分析

    Cultural Alignment in Large Language Models: An Explanatory Analysis Based on Hofstede's Cultural Dimensions. (arXiv:2309.12342v1 [cs.CY])

    [http://arxiv.org/abs/2309.12342](http://arxiv.org/abs/2309.12342)

    本研究提出了一种使用霍夫斯泰德文化维度框架来量化大型语言模型与不同文化之间的对齐程度的文化对齐测试（CAT）。通过在不同文化国家应用该方法，我们发现LLMs在解释性文化维度上存在差异，并能量化其与特定国家的文化对齐情况。

    

    大型语言模型（LLMs）的部署引发了关于其文化对齐和对不同文化规范个体的潜在影响的担忧。现有研究主要关注政治和社会偏见以及公众意见，而未涉及文化价值观。为了解决这个局限性，我们提出了文化对齐测试（CAT），利用霍夫斯泰德的文化维度框架量化文化对齐，通过潜变量分析提供解释性的跨文化比较。我们将该方法应用于评估最先进的LLMs（如ChatGPT和Bard）在不同文化国家（美国、沙特阿拉伯、中国和斯洛伐克）中嵌入的文化价值观，使用不同的提示风格和超参数设置。我们的结果不仅量化了LLMs与特定国家的文化对齐程度，而且揭示了LLMs在解释性文化维度上的差异。尽管所有的LLMs都没有提供令人满意的结果

    The deployment of large language models (LLMs) raises concerns regarding their cultural misalignment and potential ramifications on individuals from various cultural norms. Existing work investigated political and social biases and public opinions rather than their cultural values. To address this limitation, the proposed Cultural Alignment Test (CAT) quantifies cultural alignment using Hofstede's cultural dimension framework, which offers an explanatory cross-cultural comparison through the latent variable analysis. We apply our approach to assess the cultural values embedded in state-of-the-art LLMs, such as: ChatGPT and Bard, across diverse cultures of countries: United States (US), Saudi Arabia, China, and Slovakia, using different prompting styles and hyperparameter settings. Our results not only quantify cultural alignment of LLMs with certain countries, but also reveal the difference between LLMs in explanatory cultural dimensions. While all LLMs did not provide satisfactory res
    
[^44]: 对医疗机构在电子病历上使用大型语言模型进行训练的考虑

    Considerations for health care institutions training large language models on electronic health records. (arXiv:2309.12339v1 [cs.CY])

    [http://arxiv.org/abs/2309.12339](http://arxiv.org/abs/2309.12339)

    本研究通过分析数据集大小、模型大小和使用电子病历数据进行大型语言模型（LLM）训练的成本，提供了一个思考医疗机构是否应该训练LLM以及如何在预算限制下选择合适LLM的框架。

    

    大型语言模型（LLM）（如ChatGPT）引起了跨学科科学家的兴趣；在医学领域中，对LLM在电子病历数据上进行训练的潜在应用也引发了关注。然而，如果医疗机构有意让LLM在自己的数据上进行训练，我们首先必须面对一些棘手的问题：他们应该从头开始训练LLM，还是从开源模型进行微调？对于预先确定预算的医疗机构来说，他们可以负担得起的最大LLM是什么？在本研究中，我们通过分析数据集大小、模型大小和使用电子病历数据进行LLM训练的成本来对这些问题进行了初步探讨。这个分析为从数据规模、计算规模和训练预算的角度思考这些问题提供了一个框架。

    Large language models (LLMs) like ChatGPT have excited scientists across fields; in medicine, one source of excitement is the potential applications of LLMs trained on electronic health record (EHR) data. But there are tough questions we must first answer if health care institutions are interested in having LLMs trained on their own data; should they train an LLM from scratch or fine-tune it from an open-source model? For healthcare institutions with a predefined budget, what are the biggest LLMs they can afford? In this study, we take steps towards answering these questions with an analysis on dataset sizes, model sizes, and costs for LLM training using EHR data. This analysis provides a framework for thinking about these questions in terms of data scale, compute scale, and training budgets.
    
[^45]: MetaMath：为大型语言模型创建自己的数学问题

    MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models. (arXiv:2309.12284v1 [cs.CL])

    [http://arxiv.org/abs/2309.12284](http://arxiv.org/abs/2309.12284)

    MetaMath是一种专门用于数学推理的微调语言模型，通过从多个角度重新编写问题来生成数学问题，并在两个基准测试中取得了优于其他开源语言模型的表现。

    

    大型语言模型（LLMs）推动了自然语言理解的极限，并展示了出色的问题解决能力。尽管取得了巨大的成功，但大多数现有的开源LLMs（例如LLaMA-2）在解决数学问题方面仍然远远不够令人满意，原因是复杂的推理过程。为了弥合这一鸿沟，我们提出了MetaMath，一种专门用于数学推理的微调语言模型。具体而言，我们通过在没有额外知识的情况下以多个角度重新写入问题来引导数学问题，从而产生了一个名为MetaMathQA的新数据集。然后我们在MetaMathQA上对LLaMA-2模型进行了微调。对于数学推理的两个流行基准测试（即GSM8K和MATH），实验结果表明MetaMath在性能上明显优于一套开源LLMs。我们的MetaMath-7B模型在GSM8K上达到了66.4％，在MATH上达到了19.4％，超过了相同规模的最先进模型。

    Large language models (LLMs) have pushed the limits of natural language understanding and exhibited excellent problem-solving ability. Despite the great success, most existing open-source LLMs (\eg, LLaMA-2) are still far away from satisfactory for solving mathematical problem due to the complex reasoning procedures. To bridge this gap, we propose \emph{MetaMath}, a fine-tuned language model that specializes in mathematical reasoning. Specifically, we start by bootstrapping mathematical questions by rewriting the question from multiple perspectives without extra knowledge, which results in a new dataset called {MetaMathQA}. Then we fine-tune the LLaMA-2 models on MetaMathQA. Experimental results on two popular benchmarks (\ie, GSM8K and MATH) for mathematical reasoning demonstrate that MetaMath outperforms a suite of open-source LLMs by a significant margin. Our MetaMath-7B model achieves $66.4\%$ on GSM8K and $19.4\%$ on MATH, exceeding the state-of-the-art models of the same size by 
    
[^46]: AceGPT：将大型语言模型本地化为阿拉伯文

    AceGPT, Localizing Large Language Models in Arabic. (arXiv:2309.12053v1 [cs.CL])

    [http://arxiv.org/abs/2309.12053](http://arxiv.org/abs/2309.12053)

    本研究旨在开发阿拉伯文的本地化大型语言模型(AceGPT)，通过预训练、监督微调和增强学习方法来培养具备文化意识和价值观一致的阿拉伯文模型，以满足阿拉伯语社区特定应用需求。评估结果表明，AceGPT在各项基准测试中都是最先进的阿拉伯文模型。

    

    本文探讨了开发适用于阿拉伯文的本地化大型语言模型(LLM)的迫切需求和方法论，阿拉伯文具有独特的文化特征，这些特征目前的主流模型如ChatGPT并未充分解决。在考虑文化敏感性和本地价值观时还存在关键问题。为此，本文提出了一个打包解决方案，包括进一步使用阿拉伯文本进行预训练、使用本地阿拉伯指令和阿拉伯语GPT-4回应进行监督微调(SFT)，以及使用对本地文化和价值观敏感的奖励模型进行增强学习与人工智能反馈(RLAIF)。目标是训练具备文化意识和与价值观一致的阿拉伯文LLM，以满足阿拉伯语社区多样化的特定应用需求。广泛的评估表明，所得到的名为AceGPT的阿拉伯文LLM在各种基准测试中均是最先进的。

    This paper explores the imperative need and methodology for developing a localized Large Language Model (LLM) tailored for Arabic, a language with unique cultural characteristics that are not adequately addressed by current mainstream models like ChatGPT. Key concerns additionally arise when considering cultural sensitivity and local values. To this end, the paper outlines a packaged solution, including further pre-training with Arabic texts, supervised fine-tuning (SFT) using native Arabic instructions and GPT-4 responses in Arabic, and reinforcement learning with AI feedback (RLAIF) using a reward model that is sensitive to local culture and values. The objective is to train culturally aware and value-aligned Arabic LLMs that can serve the diverse application-specific needs of Arabic-speaking communities.  Extensive evaluations demonstrated that the resulting LLM called `\textbf{AceGPT}' is the SOTA open Arabic LLM in various benchmarks, including instruction-following benchmark (i.e
    
[^47]: LMSYS-Chat-1M：一个大规模实际语言模型对话数据集

    LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset. (arXiv:2309.11998v1 [cs.CL])

    [http://arxiv.org/abs/2309.11998](http://arxiv.org/abs/2309.11998)

    LMSYS-Chat-1M是一个包含一百万个实际对话的大规模数据集，通过其多样性和用例展示了其在理解和推进LLM能力方面的价值。

    

    随着大规模语言模型（LLM）在各种应用中的广泛使用，研究人们如何在实际场景中与其交互变得越来越重要。在本文中，我们介绍了LMSYS-Chat-1M，这是一个包含一百万个与25个最先进的LLM进行的实际对话的大规模数据集。这个数据集是从我们的Vicuna演示和Chatbot Arena网站上的21万个独立IP地址中收集而来的。我们提供了数据集内容的概述，包括其策划过程、基本统计数据和主题分布，强调其多样性、独特性和规模。我们通过四个用例展示了它的多样性：开发与GPT-4表现相似的内容过滤模型、构建一个安全基准、训练与Vicuna表现相似的指令跟随模型、创建具有挑战性的基准问题。我们相信这个数据集将成为我们理解和推进LLM能力的宝贵资源。

    Studying how people interact with large language models (LLMs) in real-world scenarios is increasingly important due to their widespread use in various applications. In this paper, we introduce LMSYS-Chat-1M, a large-scale dataset containing one million real-world conversations with 25 state-of-the-art LLMs. This dataset is collected from 210K unique IP addresses in the wild on our Vicuna demo and Chatbot Arena website. We offer an overview of the dataset's content, including its curation process, basic statistics, and topic distribution, highlighting its diversity, originality, and scale. We demonstrate its versatility through four use cases: developing content moderation models that perform similarly to GPT-4, building a safety benchmark, training instruction-following models that perform similarly to Vicuna, and creating challenging benchmark questions. We believe that this dataset will serve as a valuable resource for understanding and advancing LLM capabilities. The dataset is pub
    
[^48]: 重新思考人工智能系统中自然语言理解的评估框架：以语言习得为未来度量的核心

    Rethinking the Evaluating Framework for Natural Language Understanding in AI Systems: Language Acquisition as a Core for Future Metrics. (arXiv:2309.11981v1 [cs.CL])

    [http://arxiv.org/abs/2309.11981](http://arxiv.org/abs/2309.11981)

    这篇论文重新思考了人工智能系统中自然语言理解的评估框架，提出了以语言习得为核心的全面框架，旨在解决传统度量方法面临的问题，并借鉴了大型语言模型的进展。

    

    在人工智能领域，大型语言模型在自然语言处理方面取得了前所未有的进展，这为重新审视传统的机器智能度量方法提供了机会。本文提出了一个新的评估框架，从传统的图灵测试转向以语言习得为核心的全面框架，并借鉴了最近在大型语言模型方面的进展。本文深受多个学科的卓越工作的影响，指出了保持跨学科桥梁开放的必要性，并勾勒了一个更加稳健和可持续的方法。

    In the burgeoning field of artificial intelligence (AI), the unprecedented progress of large language models (LLMs) in natural language processing (NLP) offers an opportunity to revisit the entire approach of traditional metrics of machine intelligence, both in form and content. As the realm of machine cognitive evaluation has already reached Imitation, the next step is an efficient Language Acquisition and Understanding. Our paper proposes a paradigm shift from the established Turing Test towards an all-embracing framework that hinges on language acquisition, taking inspiration from the recent advancements in LLMs. The present contribution is deeply tributary of the excellent work from various disciplines, point out the need to keep interdisciplinary bridges open, and delineates a more robust and sustainable approach.
    
[^49]: InstructERC：借助检索多任务LLMs框架改革对话中的情绪识别

    InstructERC: Reforming Emotion Recognition in Conversation with a Retrieval Multi-task LLMs Framework. (arXiv:2309.11911v1 [cs.CL])

    [http://arxiv.org/abs/2309.11911](http://arxiv.org/abs/2309.11911)

    InstructERC是一种使用大型语言模型(LLMs)的生成式框架，通过引入检索模板模块和额外的情感对齐任务，改革了对话中的情绪识别。

    

    对话情绪识别(ERC)的发展一直受到管道设计复杂性的阻碍，导致ERC模型往往对特定数据集和对话模式过拟合。在本研究中，我们提出了一种新方法，即InstructERC，将ERC任务从判别式框架转化为基于大型语言模型(LLMs)的生成式框架。InstructERC有两个重要贡献：首先，InstructERC引入了一个简单而有效的检索模板模块，通过将历史对话内容、标签语句和情感领域演示与高语义相似性进行拼接，帮助模型明确地集成多粒度对话监督信息。此外，我们引入了两个额外的情感对齐任务，即说话人识别和情感预测任务，以隐式地建模对话角色关系和未来对话情绪倾向。我们的基于LLM的方法

    The development of emotion recognition in dialogue (ERC) has been consistently hindered by the complexity of pipeline designs, leading to ERC models that often overfit to specific datasets and dialogue patterns. In this study, we propose a novel approach, namely  InstructERC, to reformulates the ERC task from a discriminative framework to a generative framework based on Large Language Models (LLMs) . InstructERC has two significant contributions: Firstly, InstructERC introduces a simple yet effective retrieval template module, which helps the model explicitly integrate multi-granularity dialogue supervision information by concatenating the historical dialog content, label statement, and emotional domain demonstrations with high semantic similarity. Furthermore, we introduce two additional emotion alignment tasks, namely speaker identification and emotion prediction tasks, to implicitly model the dialogue role relationships and future emotional tendencies in conversations. Our LLM-based
    
[^50]: 基于音频对比的微调方法

    Audio Contrastive based Fine-tuning. (arXiv:2309.11895v1 [cs.SD])

    [http://arxiv.org/abs/2309.11895](http://arxiv.org/abs/2309.11895)

    本论文提出了一种基于音频对比的微调方法（AudioConFit），通过借助对比学习的可转移性，该方法在各种音频分类任务中表现出强大的泛化能力，并在不同设置下实现了最先进的结果。

    

    音频分类在语音和声音处理任务中起着至关重要的作用，具有广泛的应用。在将模型拟合到训练数据（避免过拟合）并使其能够良好地泛化到新领域之间仍然存在着平衡的挑战。借助对比学习的可转移性，我们引入了基于音频对比的微调方法（AudioConFit），这种方法具有强大的泛化能力。对各种音频分类任务的实证实验表明了我们方法的有效性和鲁棒性，在不同设置下取得了最先进的结果。

    Audio classification plays a crucial role in speech and sound processing tasks with a wide range of applications. There still remains a challenge of striking the right balance between fitting the model to the training data (avoiding overfitting) and enabling it to generalise well to a new domain. Leveraging the transferability of contrastive learning, we introduce Audio Contrastive-based Fine-tuning (AudioConFit), an efficient approach characterised by robust generalisability. Empirical experiments on a variety of audio classification tasks demonstrate the effectiveness and robustness of our approach, which achieves state-of-the-art results in various settings.
    
[^51]: CFGPT: 具有大型语言模型的中国金融助手

    CFGPT: Chinese Financial Assistant with Large Language Model. (arXiv:2309.10654v1 [cs.CL])

    [http://arxiv.org/abs/2309.10654](http://arxiv.org/abs/2309.10654)

    CFGPT是一个具有大型语言模型的中国金融助手，包括CFData用于预训练和监督微调，以及CFLLM用于处理金融文本，CFAPP用于实际金融应用。这个框架在金融领域的各个方面展现出了巨大的潜力。

    

    大型语言模型（LLM）已经在金融领域的自然语言处理任务中展现出巨大的潜力。在这项工作中，我们提出了一个名为CFGPT的中国金融生成式预训练Transformer框架，该框架包括用于预训练和监督微调的数据集（CFData），用于熟练处理金融文本的金融LLM（CFLLM），以及用于实际金融应用的部署框架（CFAPP）。CFData包括一个预训练数据集和一个监督微调数据集，其中预训练数据集汇集了中国金融数据和分析，以及总共584M个文件和141B个标记的较小的通用文本子集，并且监督微调数据集针对六个不同的金融任务进行了定制，内容涵盖了金融分析和决策的各个方面，包括1.5M个指令对和总计1.5B个标记。CFLLM基于InternLM-7B进行了平衡模型能力的调整。

    Large language models (LLMs) have demonstrated great potential in natural language processing tasks within the financial domain. In this work, we present a Chinese Financial Generative Pre-trained Transformer framework, named CFGPT, which includes a dataset~(CFData) for pre-training and supervised fine-tuning, a financial LLM~(CFLLM) to adeptly manage financial texts, and a deployment framework~(CFAPP) designed to navigate real-world financial applications. The CFData comprising both a pre-training dataset and a supervised fine-tuning dataset, where the pre-training dataset collates Chinese financial data and analytics, alongside a smaller subset of general-purpose text with 584M documents and 141B tokens in total, and the supervised fine-tuning dataset is tailored for six distinct financial tasks, embodying various facets of financial analysis and decision-making with 1.5M instruction pairs and 1.5B tokens in total. The CFLLM, which is based on InternLM-7B to balance the model capabil
    
[^52]: Talk2Care: 利用大型语言模型促进异步患者-医生通信

    Talk2Care: Facilitating Asynchronous Patient-Provider Communication with Large-Language-Model. (arXiv:2309.09357v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.09357](http://arxiv.org/abs/2309.09357)

    本研究利用大型语言模型（LLMs）来促进患者和医生之间的异步通信，通过访谈研究了解了他们对LLMs的需求，并构建了一个名为Talk2Care的LLM驱动的通信系统。

    

    尽管有大量的远程医疗应用程序来帮助家庭中的老年人和医疗提供者，但基本的消息和电话仍然是最常见的通信方法，这些方法存在有限的可用性、信息丢失和流程效率低下的问题。促进患者-医生通信的一个有希望的解决方案是利用大型语言模型(LLMs)及其强大的自然对话和摘要能力。然而，对于LLMs在通信过程中的作用还存在有限的理解。我们首先进行了两项访谈研究，分别与老年人(N=10)和医疗提供者(N=9)进行了交流，以了解他们在患者-医生异步通信中对LLMs的需求和机会。基于这些见解，我们构建了一个LLM驱动的通信系统Talk2Care，并为两个群体设计了交互组件: (1) 对于老年人，我们利用语音助手的便利性和易于获取性，构建了一个LLM驱动的语音助手

    Despite the plethora of telehealth applications to assist home-based older adults and healthcare providers, basic messaging and phone calls are still the most common communication methods, which suffer from limited availability, information loss, and process inefficiencies. One promising solution to facilitate patient-provider communication is to leverage large language models (LLMs) with their powerful natural conversation and summarization capability. However, there is a limited understanding of LLMs' role during the communication. We first conducted two interview studies with both older adults (N=10) and healthcare providers (N=9) to understand their needs and opportunities for LLMs in patient-provider asynchronous communication. Based on the insights, we built an LLM-powered communication system, Talk2Care, and designed interactive components for both groups: (1) For older adults, we leveraged the convenience and accessibility of voice assistants (VAs) and built an LLM-powered VA i
    
[^53]: ChatGPT v Bard v Bing v Claude 2 v Aria v human-expert. AI聊天机器人在科学写作方面表现如何？（第23季第3季）。（arXiv:2309.08636v1 [cs.CL]）

    ChatGPT v Bard v Bing v Claude 2 v Aria v human-expert. How good are AI chatbots at scientific writing? (ver. 23Q3). (arXiv:2309.08636v1 [cs.CL])

    [http://arxiv.org/abs/2309.08636](http://arxiv.org/abs/2309.08636)

    本文综合分析了在人文学科和考古学领域中六个AI聊天机器人在学术写作方面的能力和局限性，发现它们在重新组合现有知识方面表现出色，但在产生原创科学内容方面存在问题。

    

    在历史上，熟练的写作被认为是人类进步的关键，创造性表达被视为人类成就的标志之一。然而，生成式AI的最新进展标志着这一叙事的一个转折点，包括在科学写作方面。本文全面分析了六个AI聊天机器人在人文学科和考古学方面学术写作中的能力和局限性。方法基于由人类专家对AI生成内容进行定量准确性和定性精确性标记。定量准确性评估了事实的正确性，而定性精确性评估了科学贡献。虽然AI聊天机器人，特别是ChatGPT-4，在重新组合现有知识方面表现出熟练性，但在生成原创科学内容方面失败了。顺便提一下，我们的结果还显示，随着ChatGPT-4，语言模型大小已经停滞不前。此外，本文强调了复杂且反复无常的生成过程。

    Historically, proficient writing was deemed essential for human advancement, with creative expression viewed as one of the hallmarks of human achievement. However, recent advances in generative AI have marked an inflection point in this narrative, including for scientific writing. This article provides a comprehensive analysis of the capabilities and limitations of six AI chatbots in scholarly writing in the humanities and archaeology. The methodology was based on tagging AI generated content for quantitative accuracy and qualitative precision by human experts. Quantitative accuracy assessed the factual correctness, while qualitative precision gauged the scientific contribution. While the AI chatbots, especially ChatGPT-4, demonstrated proficiency in recombining existing knowledge, they failed in generating original scientific content. As a side note, our results also suggest that with ChatGPT-4 the size of the LLMs has plateaued. Furthermore, the paper underscores the intricate and re
    
[^54]: 大型语言模型中的命名实体上下文偏倚研究

    Contextual Biasing of Named-Entities with Large Language Models. (arXiv:2309.00723v1 [cs.CL])

    [http://arxiv.org/abs/2309.00723](http://arxiv.org/abs/2309.00723)

    本文研究了使用大型语言模型进行上下文偏倚的方法，通过在第二次打分时提供额外的上下文信息，以提高自动语音识别性能。我们利用提示信息对大型语言模型进行boosting，并采用多任务训练以预测实体类别和下一个标记。此外，我们提出了动态提示方法来提高效率。

    

    本文研究了在大型语言模型(LLMs)中进行上下文偏倚，即在第二次打分时为LLM提供额外的上下文信息，以提高自动语音识别(ASR)性能。我们提出了在打分期间利用提示信息对LLM进行boosting，而无需进行微调，这些提示信息包括偏倚列表和少样本示例，用于在计算假设得分时作为附加信息。除了少样本提示学习外，我们还提出了LLM的多任务训练，以预测实体类别和下一个标记。为了提高上下文偏倚的效率并避免超过LLMs的最大序列长度，我们提出了动态提示，即使用类别标签预测选择最可能的类别，并仅使用这个类别中的实体作为下一个标记预测的上下文。对内部的呼叫、消息和口述数据集以及SLUE-Voxpopuli数据集进行了词错误率(WER)评估。

    This paper studies contextual biasing with Large Language Models (LLMs), where during second-pass rescoring additional contextual information is provided to a LLM to boost Automatic Speech Recognition (ASR) performance. We propose to leverage prompts for a LLM without fine tuning during rescoring which incorporate a biasing list and few-shot examples to serve as additional information when calculating the score for the hypothesis. In addition to few-shot prompt learning, we propose multi-task training of the LLM to predict both the entity class and the next token. To improve the efficiency for contextual biasing and to avoid exceeding LLMs' maximum sequence lengths, we propose dynamic prompting, where we select the most likely class using the class tag prediction, and only use entities in this class as contexts for next token prediction. Word Error Rate (WER) evaluation is performed on i) an internal calling, messaging, and dictation dataset, and ii) the SLUE-Voxpopuli dataset. Results
    
[^55]: 利用视觉-语言模型在医学图像分割中探索迁移学习

    Exploring Transfer Learning in Medical Image Segmentation using Vision-Language Models. (arXiv:2308.07706v1 [cs.CV])

    [http://arxiv.org/abs/2308.07706](http://arxiv.org/abs/2308.07706)

    本论文提出使用视觉-语言模型进行医学图像分割的迁移学习，并评估了其在医学领域的可迁移性。通过捕捉语义信息和引入新的图像描述变化，实现了对多样化医学图像的分割。

    

    医学图像分割在医学领域的各种临床应用中至关重要。尽管最先进的分割模型已被证明有效，但在这个任务中整合文本指导以增强视觉特征仍然是一个进展有限的领域。现有利用文本指导的分割模型主要在开放领域图像上训练，这引发了在医学领域直接应用的难题，需要手动介入或进行微调。为了解决这些挑战，我们提出使用多模态的视觉-语言模型从图像描述和图像中捕捉语义信息，使得能够对多样化的医学图像进行分割。该研究全面评估了现有的视觉-语言模型在多个数据集上的可迁移性，以评估其从开放领域向医学领域的迁移能力。此外，我们对数据集中以前未见图像的图像描述引入了变化，揭示了显著的变异。

    Medical Image Segmentation is crucial in various clinical applications within the medical domain. While state-of-the-art segmentation models have proven effective, integrating textual guidance to enhance visual features for this task remains an area with limited progress. Existing segmentation models that utilize textual guidance are primarily trained on open-domain images, raising concerns about their direct applicability in the medical domain without manual intervention or fine-tuning.  To address these challenges, we propose using multimodal vision-language models for capturing semantic information from image descriptions and images, enabling the segmentation of diverse medical images. This study comprehensively evaluates existing vision language models across multiple datasets to assess their transferability from the open domain to the medical field. Furthermore, we introduce variations of image descriptions for previously unseen images in the dataset, revealing notable variations 
    
[^56]: 在大型语言模型时代的被遗忘权：涵义、挑战和解决方案

    Right to be Forgotten in the Era of Large Language Models: Implications, Challenges, and Solutions. (arXiv:2307.03941v1 [cs.CY])

    [http://arxiv.org/abs/2307.03941](http://arxiv.org/abs/2307.03941)

    本文探讨了在大型语言模型时代的被遗忘权（RTBF）面临的挑战，提供了实施技术解决方案的见解。

    

    被遗忘权（RTBF）最初是由谷歌西班牙与埃克斯内塔索委员会(Mario Costeja Gonz\'alez)之间的官司结果而确立的，并且后来被作为欧洲联盟一般数据保护条例（GDPR）下的删除权。RTBF允许个人向组织请求删除个人数据，特别是对于搜索引擎，个人可以向组织发送请求，排除他们的信息在查询结果中出现。然而，随着大型语言模型（LLMs）的发展和其在聊天机器人中的应用，LLM启用的软件系统变得越来越受欢迎。但它们并没有被排除在RTBF之外。相比搜索引擎使用的索引方法，LLMs以一种完全不同的方式存储和处理信息，这为符合RTBF提出了新的挑战。在本文中，我们探讨了这些挑战，并提供了关于如何实施技术解决方案以符合RTBF的见解。

    The Right to be Forgotten (RTBF) was first established as the result of the ruling of Google Spain SL, Google Inc. v AEPD, Mario Costeja Gonz\'alez, and was later included as the Right to Erasure under the General Data Protection Regulation (GDPR) of European Union to allow individuals the right to request personal data be deleted by organizations. Specifically for search engines, individuals can send requests to organizations to exclude their information from the query results. With the recent development of Large Language Models (LLMs) and their use in chatbots, LLM-enabled software systems have become popular. But they are not excluded from the RTBF. Compared with the indexing approach used by search engines, LLMs store, and process information in a completely different way. This poses new challenges for compliance with the RTBF. In this paper, we explore these challenges and provide our insights on how to implement technical solutions for the RTBF, including the use of machine unle
    
[^57]: 大型语言模型中的人格特质

    Personality Traits in Large Language Models. (arXiv:2307.00184v1 [cs.CL])

    [http://arxiv.org/abs/2307.00184](http://arxiv.org/abs/2307.00184)

    该研究介绍了一种综合方法，用于验证大型语言模型（LLMs）生成的文本中展示的人格特质。研究发现，部分LLMs在特定提示配置下模拟的人格可靠且有效，特别是对于更大和经过指导微调的模型。此外，LLMs的输出中的人格特质可以根据需要进行塑造。

    

    大型语言模型（LLMs）的出现彻底改变了自然语言处理，使得能够生成连贯且上下文相关的文本。随着LLMs越来越多地用于驱动对话代理，这些模型通过训练大量人工生成的数据获得的人格特质引起了人们的关注。由于人格是决定交流效果的重要因素，我们提出了一种全面的方法来进行验证的心理测量测试，并对从广泛使用的LLMs生成的文本中展示的人格特质进行量化、分析和塑造。我们发现：1）某些LLMs的输出中模拟的人格（在特定的提示配置下）是可靠和有效的；2）LLM模拟的人格的可靠性和有效性的证据对于更大的和经过指导微调的模型更强；3）LLM输出中的人格可以根据需要的维度进行塑造，以模仿特定的人格特点。

    The advent of large language models (LLMs) has revolutionized natural language processing, enabling the generation of coherent and contextually relevant text. As LLMs increasingly power conversational agents, the synthesized personality embedded in these models by virtue of their training on large amounts of human-generated data draws attention. Since personality is an important factor determining the effectiveness of communication, we present a comprehensive method for administering validated psychometric tests and quantifying, analyzing, and shaping personality traits exhibited in text generated from widely-used LLMs. We find that: 1) personality simulated in the outputs of some LLMs (under specific prompting configurations) is reliable and valid; 2) evidence of reliability and validity of LLM-simulated personality is stronger for larger and instruction fine-tuned models; and 3) personality in LLM outputs can be shaped along desired dimensions to mimic specific personality profiles. 
    
[^58]: AVIS:利用大型语言模型的自主视觉信息检索

    AVIS: Autonomous Visual Information Seeking with Large Language Models. (arXiv:2306.08129v1 [cs.CV])

    [http://arxiv.org/abs/2306.08129](http://arxiv.org/abs/2306.08129)

    本文提出了一个基于大型语言模型的自主信息检索视觉问答框架AVIS，可以解决视觉问题所需的外部知识获取问题。

    

    本文提出了一种利用大型语言模型（LLM）实现自主信息检索的视觉问答框架AVIS。我们的方法利用LLM动态地制定利用外部工具的策略，并调查它们的输出，从而获取提供所提出问题所需的不可或缺的知识。回答需要外部知识的视觉问题，如“这幅图像所描绘的建筑物是为了纪念哪个事件？”，是一项复杂的任务。这个任务呈现出一个组合搜索空间，需要一系列行动，包括调用API、分析它们的响应并做出明智的决策。我们进行了一个用户研究，收集了人类面对这个任务时各种各样的决策实例。然后利用这些数据设计了一个由三个组件组成的系统：一个由LLM驱动的规划器，动态确定下一个要使用的工具；一个由LLM驱动的推理器，分析并提取关键信息。

    In this paper, we propose an autonomous information seeking visual question answering framework, AVIS. Our method leverages a Large Language Model (LLM) to dynamically strategize the utilization of external tools and to investigate their outputs, thereby acquiring the indispensable knowledge needed to provide answers to the posed questions. Responding to visual questions that necessitate external knowledge, such as "What event is commemorated by the building depicted in this image?", is a complex task. This task presents a combinatorial search space that demands a sequence of actions, including invoking APIs, analyzing their responses, and making informed decisions. We conduct a user study to collect a variety of instances of human decision-making when faced with this task. This data is then used to design a system comprised of three components: an LLM-powered planner that dynamically determines which tool to use next, an LLM-powered reasoner that analyzes and extracts key information 
    
[^59]: 推理时间干预：从语言模型中引导出真实的答案

    Inference-Time Intervention: Eliciting Truthful Answers from a Language Model. (arXiv:2306.03341v1 [cs.LG])

    [http://arxiv.org/abs/2306.03341](http://arxiv.org/abs/2306.03341)

    本研究提出推理时间干预（ITI）技术，通过在推理过程中跨越有限数量的注意力头，显着提高大型语言模型的真实性。在TruthfulQA基准上，ITI使LLaMA模型的真实性从32.5%提高到65.1%。ITI是一种最小程度的干扰，计算廉价，且数据效率高。

    

    我们介绍了推理时间干预（ITI）技术，旨在增强大型语言模型（LLMs）的真实性。ITI通过在推理过程中沿着一组方向移动模型激活，跨越有限数量的注意力头。这种干预显着提高了LLaMA模型在TruthfulQA基准上的表现。在指令微调的LLaMA Alpaca上，ITI将其真实性从32.5％提高到65.1％。我们确定了真实性和可用性之间的权衡，并演示了如何通过调整干预强度来平衡它。ITI 取得了最低程度的干扰且计算廉价。此外，该技术在数据效率上表现优异：虽然像RLHF这样的方法需要广泛注释，但是ITI仅使用了几百个例子就能定位真实的方向。我们的研究结果表明，LLMs可能具有某种内部表示方法来表示某事是真实的可能性，即使它们在表面上产生了虚假的结果。

    We introduce Inference-Time Intervention (ITI), a technique designed to enhance the truthfulness of large language models (LLMs). ITI operates by shifting model activations during inference, following a set of directions across a limited number of attention heads. This intervention significantly improves the performance of LLaMA models on the TruthfulQA benchmark. On an instruction-finetuned LLaMA called Alpaca, ITI improves its truthfulness from 32.5% to 65.1%. We identify a tradeoff between truthfulness and helpfulness and demonstrate how to balance it by tuning the intervention strength. ITI is minimally invasive and computationally inexpensive. Moreover, the technique is data efficient: while approaches like RLHF require extensive annotations, ITI locates truthful directions using only few hundred examples. Our findings suggest that LLMs may have an internal representation of the likelihood of something being true, even as they produce falsehoods on the surface.
    
[^60]: GENTLE: 一个包含不同文体的多层次英文NLP和语言评估挑战数据集

    GENTLE: A Genre-Diverse Multilayer Challenge Set for English NLP and Linguistic Evaluation. (arXiv:2306.01966v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.01966](http://arxiv.org/abs/2306.01966)

    GENTLE是一个包含不同文体的英文NLP挑战数据集，对于各种NLP任务，包括句法依赖分析、实体识别、指代消解和篇章分析，最先进的NLP系统在某些文体上性能严重降低，这表明GENTLE在NLP系统评估中的实用性。

    

    我们介绍了GENTLE，一个新的混合文体的英文挑战语料库，共有17K个单词，包括8种非常规的文本类型，用于跨领域评估：字典条目、电子竞技评论、法律文件、医学笔记、诗歌、数学证明、教学大纲和威胁信函。GENTLE手动注释了多种流行的NLP任务，包括句法依赖分析、实体识别、指代消解和篇章分析。我们在GENTLE上评价了最先进的NLP系统，并发现其在所有任务中对某些文体的性能出现严重降低，这表明GENTLE作为NLP系统评估数据集的实用性。

    We present GENTLE, a new mixed-genre English challenge corpus totaling 17K tokens and consisting of 8 unusual text types for out-of domain evaluation: dictionary entries, esports commentaries, legal documents, medical notes, poetry, mathematical proofs, syllabuses, and threat letters. GENTLE is manually annotated for a variety of popular NLP tasks, including syntactic dependency parsing, entity recognition, coreference resolution, and discourse parsing. We evaluate state-of-the-art NLP systems on GENTLE and find severe degradation for at least some genres in their performance on all tasks, which indicates GENTLE's utility as an evaluation dataset for NLP systems.
    
[^61]: FACE: 使用交叉熵的傅里叶分析评估自然语言生成

    FACE: Evaluating Natural Language Generation with Fourier Analysis of Cross-Entropy. (arXiv:2305.10307v1 [cs.CL])

    [http://arxiv.org/abs/2305.10307](http://arxiv.org/abs/2305.10307)

    FACE是一组可以有效识别人类和模型之间差距的度量标准。它基于傅里叶分析和交叉熵估计，可以反映模型大小、解码采样方法和人类评分。

    

    评估机器生成的语言与人类语言之间的距离是一个至关重要的问题。受到语言学心理学关于语言熵周期性实证发现的启示，我们提出了FACE——一组基于语言交叉熵的傅里叶分析的度量，用于衡量生成模型产生的语言与人类书写语言之间的相似度。通过一个开放式的生成任务和以前研究的实验数据，我们发现FACE可以有效地识别人类模型差距，在模型规模上有所缩放，反映了不同解码采样方法的结果，与其他评估指标和人类判断分数相关良好。FACE在计算上是高效的，并提供直观的解释。

    Measuring the distance between machine-produced and human language is acritical open problem. Inspired by empirical findings from psycholinguistics on theperiodicity of entropy in language, we propose FACE, a set of metrics based onFourier Analysis of the estimated Cross-Entropy of language, for measuring thesimilarity between model-generated and human-written languages. Based on anopen-ended generation task and the experimental data from previous studies, weind that FACE can effectively identify the human-model gap, scales with modelsize, reflects the outcomes of different sampling methods for decoding, correlateswell with other evaluation metrics and with human judgment scores. FACE iscomputationally efficient and provides intuitive interpretations.
    
[^62]: 如何为推荐基础模型索引项目ID

    How to Index Item IDs for Recommendation Foundation Models. (arXiv:2305.06569v1 [cs.IR])

    [http://arxiv.org/abs/2305.06569](http://arxiv.org/abs/2305.06569)

    本研究对推荐基础模型的项目索引问题进行了系统检查，提出了一种新的上下文感知索引方法，该方法在项目推荐准确性和文本生成质量方面具有优势。

    

    推荐基础模型将推荐任务转换为自然语言任务，利用大型语言模型（LLM）进行推荐。它通过直接生成建议的项目而不是计算传统推荐模型中每个候选项目的排名得分，简化了推荐管道，避免了多段过滤的问题。为了避免在决定要推荐哪些项目时生成过长的文本，为推荐基础模型创建LLM兼容的项目ID是必要的。本研究系统地研究了推荐基础模型的项目索引问题，以P5为代表的主干模型，并使用各种索引方法复制其结果。我们首先讨论了几种微不足道的项目索引方法（如独立索引、标题索引和随机索引）的问题，并表明它们不适用于推荐基础模型，然后提出了一种新的索引方法，称为上下文感知索引。我们表明，这种索引方法在项目推荐准确性和文本生成质量方面优于其他索引方法。

    Recommendation foundation model utilizes large language models (LLM) for recommendation by converting recommendation tasks into natural language tasks. It enables generative recommendation which directly generates the item(s) to recommend rather than calculating a ranking score for each and every candidate item in traditional recommendation models, simplifying the recommendation pipeline from multi-stage filtering to single-stage filtering. To avoid generating excessively long text when deciding which item(s) to recommend, creating LLM-compatible item IDs is essential for recommendation foundation models. In this study, we systematically examine the item indexing problem for recommendation foundation models, using P5 as the representative backbone model and replicating its results with various indexing methods. To emphasize the importance of item indexing, we first discuss the issues of several trivial item indexing methods, such as independent indexing, title indexing, and random inde
    
[^63]: 不停止预训练？让基于提示的微调更加强大

    Don't Stop Pretraining? Make Prompt-based Fine-tuning Powerful Learner. (arXiv:2305.01711v1 [cs.CL])

    [http://arxiv.org/abs/2305.01711](http://arxiv.org/abs/2305.01711)

    本文研究了持续预训练对于微调性能的影响，发现传统的持续预训练不能保证一致的提高性能，甚至会对一些任务产生负面影响。针对这些问题，作者提出了基于提示的持续预训练，旨在通过无监督的预训练向LM展示任务相关文本和提示模板，从而提高基于提示的微调表现。

    

    在大量无标注数据的训练下，语言模型（LM）极大地推动了自然语言处理（NLP）领域的发展。 在本研究中，我们重新审视NLP中广为接受的LM任务相关文本的持续预训练可以提高下游任务微调性能的理论。通过在半监督和全监督设置下对八个单句任务和八个句对任务的实验，我们发现传统的持续预训练不能保证一致的提高性能，甚至可能对句对任务或使用基于提示的微调方式时会产生负面影响。为了解决这些问题，我们提出了基于提示的持续预训练（PCP），将指导调整的思想与传统的持续预训练相结合。我们的方法旨在通过在微调目标之前通过无监督的预训练目标向LM展示任务相关文本和提示模板，从而提高基于提示的FT的表现。

    Language models (LMs) trained on vast quantities of unlabelled data have greatly advanced the field of natural language processing (NLP). In this study, we re-visit the widely accepted notion in NLP that continued pre-training LMs on task-related texts improves the performance of fine-tuning (FT) in downstream tasks. Through experiments on eight single-sentence tasks and eight sentence-pair tasks in both semi-supervised and fully-supervised settings, we find that conventional continued pre-training does not consistently provide benefits and can even be detrimental for sentence-pair tasks or when prompt-based FT is used. To tackle these issues, we propose Prompt-based Continued Pre-training (PCP), which combines the idea of instruction tuning with conventional continued pre-training. Our approach aims to improve the performance of prompt-based FT by presenting both task-related texts and prompt templates to LMs through unsupervised pre-training objectives before fine-tuning for the targ
    
[^64]: CryCeleb: 基于婴儿哭声的说话人认证数据集

    CryCeleb: A Speaker Verification Dataset Based on Infant Cry Sounds. (arXiv:2305.00969v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2305.00969](http://arxiv.org/abs/2305.00969)

    CryCeleb是一个基于婴儿哭声的说话人认证数据集，包括超过6小时的手动分割哭声，可用于研究婴儿哭声分析。

    

    本文描述了Ubenwa CryCeleb数据集——一个标记的婴儿哭声收集，以及附带的CryCeleb 2023任务——一个基于婴儿哭声的公共说话人验证挑战。我们释放出786名新生儿超过6小时的手动分割哭声，以鼓励婴儿哭声分析方面的研究。

    This paper describes the Ubenwa CryCeleb dataset - a labeled collection of infant cries, and the accompanying CryCeleb 2023 task - a public speaker verification challenge based on infant cry sounds. We release for academic usage more than 6 hours of manually segmented cry sounds from 786 newborns to encourage research in infant cry analysis.
    
[^65]: 基于SearChain的复杂知识密集型任务中精确、可信和可追溯内容生成的研究

    Search-in-the-Chain: Towards the Accurate, Credible and Traceable Content Generation for Complex Knowledge-intensive Tasks. (arXiv:2304.14732v1 [cs.CL])

    [http://arxiv.org/abs/2304.14732](http://arxiv.org/abs/2304.14732)

    提出了一个名为SearChain的新型框架，以改进LLM生成的内容的准确性、可信度和可追溯性，从而提高复杂知识密集型任务的表现。SearChain通过深度集成LLM和信息检索（IR）实现，其思路是通过构造查询链，将多跳问题进行分解，最终指导LLM生成正确的答案。

    

    随着ChatGPT等大型语言模型（LLM）的广泛应用，如何使LLM生成的内容准确可信在复杂知识密集型任务中变得非常重要。本文提出了一种名为Search-in-the-Chain（SearChain）的新型框架，以改进多跳问题回答等典型复杂知识密集型任务中LLM生成内容的准确性、可信度和可追溯性。SearChain是一个深度集成LLM和信息检索（IR）的框架。在SearChain中，LLM构建查询链，作为多跳问题的分解。链的每个节点都是由IR导向的查询-答案对，以及由LLM生成的该查询的答案。IR验证、完善和跟踪链中每个节点的信息，以指导LLM构建正确的查询链，并最终回答多跳问题。SearChain使LLM从一次性答案转变为多步答案，从而提高了生成内容的准确性和可信度。实验结果表明，SearChain在准确性和可靠性方面优于其他最先进的方法。

    With the wide application of Large Language Models (LLMs) such as ChatGPT, how to make the contents generated by LLM accurate and credible becomes very important, especially in complex knowledge-intensive tasks. In this paper, we propose a novel framework called Search-in-the-Chain (SearChain) to improve the accuracy, credibility and traceability of LLM-generated content for multi-hop question answering, which is a typical complex knowledge-intensive task. SearChain is a framework that deeply integrates LLM and information retrieval (IR). In SearChain, LLM constructs a chain-of-query, which is the decomposition of the multi-hop question. Each node of the chain is a query-answer pair consisting of an IR-oriented query and the answer generated by LLM for this query. IR verifies, completes, and traces the information of each node of the chain, so as to guide LLM to construct the correct chain-of-query, and finally answer the multi-hop question. SearChain makes LLM change from trying to gi
    
[^66]: 编程什么使一种语言易于深度学习？

    What Makes a Language Easy to Deep-Learn?. (arXiv:2302.12239v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.12239](http://arxiv.org/abs/2302.12239)

    本研究通过测试神经网络和人类在学习和推广不同结构程度的语言方面的能力，发现神经网络在系统化概括方面存在困难，这对于模拟人类语言学习和进化构成了一个问题。

    

    神经网络推动了自然语言处理的成功。语言的一个基本属性是其组成结构，使人类能够系统地产生新的意义形式。然而，与人类不同，神经网络在系统化概括方面一直存在困难，并且在新兴通信模拟中不一定受益于组成结构。这对于使用神经网络模拟人类语言学习和进化构成了一个问题，并且暗示了不同学习系统的偏见的关键差异。在这里，我们直接测试神经网络在学习和概括不同输入语言的能力，这些语言在其结构程度上有所不同。我们评估了一个预训练的语言模型GPT-3.5（类似于成年第二语言学习者）和从头开始训练的递归神经网络（类似于儿童第一语言学习者）的记忆和概括能力。我们的结果显示了令人震惊的

    Neural networks drive the success of natural language processing. A fundamental property of language is its compositional structure, allowing humans to produce forms for new meanings systematically. However, unlike humans, neural networks notoriously struggle with systematic generalization, and do not necessarily benefit from compositional structure in emergent communication simulations. This poses a problem for using neural networks to simulate human language learning and evolution, and suggests crucial differences in the biases of the different learning systems. Here, we directly test how neural networks compare to humans in learning and generalizing different input languages that vary in their degree of structure. We evaluate the memorization and generalization capabilities of a pre-trained language model GPT-3.5 (analagous to an adult second language learner) and recurrent neural networks trained from scratch (analaogous to a child first language learner). Our results show striking
    
[^67]: 使用少样本学习的对话风格转移

    Conversation Style Transfer using Few-Shot Learning. (arXiv:2302.08362v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.08362](http://arxiv.org/abs/2302.08362)

    本论文提出了一种使用少样本学习的对话风格转移方法，通过观察目标风格中的少量示例对话，模型可以在考虑上下文的情况下进行风格转移，相比于句子级风格转移，该方法在恰当性和语义正确性上具有更好的表现。

    

    传统的文本风格转移方法侧重于句子级的风格转移，而没有考虑上下文信息，并且风格是通过属性（例如，正式程度）来描述的。当将风格转移应用于任务导向对话等对话时，现有的方法受到这些限制的影响，因为上下文可以起到重要作用，而对话中的风格属性往往很难定义。在本文中，我们将对话风格转移引入为一个少样本学习问题，模型通过观察目标风格中的少量示例对话来进行风格转移。我们提出了一种新的上下文学习方法来解决这个任务，将不带风格的对话作为中转。人工评估结果显示，通过结合多轮对话上下文，该模型能够匹配目标风格，同时与语句/句子级风格转移相比，具有更好的恰当性和语义正确性。此外，我们还展示了对话风格转移技术的应用效果。

    Conventional text style transfer approaches focus on sentence-level style transfer without considering contextual information, and the style is described with attributes (e.g., formality). When applying style transfer in conversations such as task-oriented dialogues, existing approaches suffer from these limitations as context can play an important role and the style attributes are often difficult to define in conversations. In this paper, we introduce conversation style transfer as a few-shot learning problem, where the model learns to perform style transfer by observing only a few example dialogues in the target style. We propose a novel in-context learning approach to solve the task with style-free dialogues as a pivot. Human evaluation shows that by incorporating multi-turn context, the model is able to match the target style while having better appropriateness and semantic correctness compared to utterance/sentence-level style transfer. Additionally, we show that conversation styl
    
[^68]: 从西班牙语语言模型评估中得出的教训

    Lessons learned from the evaluation of Spanish Language Models. (arXiv:2212.08390v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.08390](http://arxiv.org/abs/2212.08390)

    该论文对西班牙语语言模型进行了全面比较，发现先前被忽视的大公司的多语言模型优于单语言模型，在西班牙语语言模型的评估领域产生了重大变化。需要进一步研究语料库大小、质量和预训练技术的影响。

    

    鉴于语言模型对自然语言处理领域的影响，已经训练并发布了一些仅有编码器的西班牙语掩码语言模型（即BERT）。这些模型要么是在使用非常大的私有语料库的大型项目中开发的，要么是通过利用免费可用数据的小规模学术工作开发的。本文对西班牙语语言模型进行了全面的比较，得出以下结果：（i）先前被忽视的大公司的多语言模型优于单语言模型，在西班牙语语言模型的评估领域产生了重大变化；（ii）单语言模型的结果并不明确，据说更小且更差的模型也具有竞争力。基于这些实证结果，我们主张需要更多的研究来理解其背后的因素。在这方面，语料库的大小、质量和预训练技术的影响需要进一步研究。

    Given the impact of language models on the field of Natural Language Processing, a number of Spanish encoder-only masked language models (aka BERTs) have been trained and released. These models were developed either within large projects using very large private corpora or by means of smaller scale academic efforts leveraging freely available data. In this paper we present a comprehensive head-to-head comparison of language models for Spanish with the following results: (i) Previously ignored multilingual models from large companies fare better than monolingual models, substantially changing the evaluation landscape of language models in Spanish; (ii) Results across the monolingual models are not conclusive, with supposedly smaller and inferior models performing competitively. Based on these empirical results, we argue for the need of more research to understand the factors underlying them. In this sense, the effect of corpus size, quality and pre-training techniques need to be further
    
[^69]: 低资源医疗领域会话电话语音的混合ASR系统的开发

    Development of Hybrid ASR Systems for Low Resource Medical Domain Conversational Telephone Speech. (arXiv:2210.13397v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.13397](http://arxiv.org/abs/2210.13397)

    本研究开发了针对低资源医疗领域会话电话语音的混合ASR系统，旨在改善患者护理并克服语言障碍。

    

    语言障碍在我们日益连接和全球化的世界中带来了巨大的挑战。尤其在医疗领域，如医院或急诊室，沟通困难和延误可能导致医疗失误和非最佳的患者护理。在HYKIST项目中，我们考虑患者和医生之间的交流，具体来说是德语医生和阿拉伯语或越南语患者之间的交流。目前，医生可以打电话给Triaphon服务以获得来自翻译员的帮助，以促进沟通。HYKIST的目标是为通常没有专业背景的双语翻译员提供自动语音翻译系统，以改进患者护理并解决语言障碍。在这项工作中，我们介绍了针对医疗领域会话电话语音翻译任务的ASR系统开发工作，涉及两种语言对的数据收集、各种声学模型架构和方言引起的困难。

    Language barriers present a great challenge in our increasingly connected and global world. Especially within the medical domain, e.g. hospital or emergency room, communication difficulties and delays may lead to malpractice and non-optimal patient care. In the HYKIST project, we consider patient-physician communication, more specifically between a German-speaking physician and an Arabic- or Vietnamese-speaking patient. Currently, a doctor can call the Triaphon service to get assistance from an interpreter in order to help facilitate communication. The HYKIST goal is to support the usually non-professional bilingual interpreter with an automatic speech translation system to improve patient care and help overcome language barriers. In this work, we present our ASR system development efforts for this conversational telephone speech translation task in the medical domain for two languages pairs, data collection, various acoustic model architectures and dialect-induced difficulties.
    
[^70]: 使用语言模型平滑蕴含图

    Smoothing Entailment Graphs with Language Models. (arXiv:2208.00318v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2208.00318](http://arxiv.org/abs/2208.00318)

    本文提出了一种使用语言模型平滑蕴含图的方法，通过构建传递链条和使用现成的语言模型找到丢失的前提谓词的近似，可以提高自然语言推理模型的召回率和平均精度，并保持模型的可解释性。

    

    自然语言谓词在语料库中的多样性和Zipf分布导致通过开放关系抽取构建的蕴含图（EGs）的稀疏性。EGs是计算高效和可解释的自然语言推理模型，但作为符号模型，如果测试时缺少新的前提或假设顶点，它们会失败。我们提出了一种克服这种符号模型稀疏性的理论和方法。首先，我们引入了一种通过构建传递链条来构建EGs的最优平滑理论。然后，我们使用一个现成的语言模型来找到丢失的前提谓词的近似，展示了一种高效、开放域和无监督的平滑方法。在两个困难的定向蕴含数据集上，这提高了25.1和16.3个百分点的召回率，并提高了平均精度并保持模型的可解释性。此外，在一个QA任务中，我们展示了EG平滑在回答支持较少的问题时的最实用性。

    The diversity and Zipfian frequency distribution of natural language predicates in corpora leads to sparsity in Entailment Graphs (EGs) built by Open Relation Extraction (ORE). EGs are computationally efficient and explainable models of natural language inference, but as symbolic models, they fail if a novel premise or hypothesis vertex is missing at test-time. We present theory and methodology for overcoming such sparsity in symbolic models. First, we introduce a theory of optimal smoothing of EGs by constructing transitive chains. We then demonstrate an efficient, open-domain, and unsupervised smoothing method using an off-the-shelf Language Model to find approximations of missing premise predicates. This improves recall by 25.1 and 16.3 percentage points on two difficult directional entailment datasets, while raising average precision and maintaining model explainability. Further, in a QA task we show that EG smoothing is most useful for answering questions with lesser supporting te
    
[^71]: 评估自动临床语言简化的基准：数据集、算法和评估

    Benchmarking Automated Clinical Language Simplification: Dataset, Algorithm, and Evaluation. (arXiv:2012.02420v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2012.02420](http://arxiv.org/abs/2012.02420)

    该论文构建了一个名为MedLane的新数据集，支持自动临床语言简化方法的开发和评估。提出了一种叫做DECLARE的新模型，与八种基准模型相比取得了最先进的性能，并提出了三个特定的评估指标。

    

    低健康素养的患者通常很难理解医学术语和专业医学语言的复杂结构。尽管有一些研究提出了自动将专业语言翻译成普通人可以理解的语言，但其中只有少数关注了临床领域中准确性和可读性的两个方面。因此，临床语言的简化仍然是一个具有挑战性的任务，但可惜的是，在之前的工作中尚未完全解决。为了评估这项任务，我们构建了一个名为MedLane的新数据集，以支持自动临床语言简化方法的开发和评估。此外，我们提出了一种名为DECLARE的新模型，遵循人工注释过程，与八种强基准模型相比取得了最先进的性能。为了公平评估性能，我们还提出了三个特定的评估指标。实验结果表明了MedLane数据集的实用性。

    Patients with low health literacy usually have difficulty understanding medical jargon and the complex structure of professional medical language. Although some studies are proposed to automatically translate expert language into layperson-understandable language, only a few of them focus on both accuracy and readability aspects simultaneously in the clinical domain. Thus, simplification of the clinical language is still a challenging task, but unfortunately, it is not yet fully addressed in previous work. To benchmark this task, we construct a new dataset named MedLane to support the development and evaluation of automated clinical language simplification approaches. Besides, we propose a new model called DECLARE that follows the human annotation procedure and achieves state-of-the-art performance compared with eight strong baselines. To fairly evaluate the performance, we also propose three specific evaluation metrics. Experimental results demonstrate the utility of the annotated Med
    

