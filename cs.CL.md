# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Defending Our Privacy With Backdoors.](http://arxiv.org/abs/2310.08320) | 本研究提出了一种基于后门攻击的防御方法，通过对模型进行策略性插入后门，对齐敏感短语与中性术语的嵌入，以删除训练数据中的私人信息。实证结果显示该方法的有效性。 |
| [^2] | [Not All Demonstration Examples are Equally Beneficial: Reweighting Demonstration Examples for In-Context Learning.](http://arxiv.org/abs/2310.08309) | 本文研究了如何给演示示例重新加权以优化上下文学习的效果。通过设计一个和最终学习性能具有强相关性的掩码自我预测分数，我们确定了近似最优的权重，并采用离散化和波束搜索等方法加快了权重搜索过程。 |
| [^3] | [MProto: Multi-Prototype Network with Denoised Optimal Transport for Distantly Supervised Named Entity Recognition.](http://arxiv.org/abs/2310.08298) | 本文提出了一种针对远程监督命名实体识别任务的多原型网络MProto。与以往方法不同的是，MProto使用多个原型来表示每个实体类型，以捕捉实体表示中的类内变化。为了减轻噪声，文中还提出了一种新的去噪最优传输算法。实验证明，MProto在远程监督命名实体识别中取得了优秀的性能。 |
| [^4] | [Expanding the Vocabulary of BERT for Knowledge Base Construction.](http://arxiv.org/abs/2310.08291) | 本论文介绍了一种扩展BERT词汇表的方法，以用于知识库构建任务。我们采用了特定任务的再预训练方法，通过添加新单词来扩展语言模型的词汇表，并保留了新添加单词的语义嵌入。 |
| [^5] | [Optimizing Odia Braille Literacy: The Influence of Speed on Error Reduction and Enhanced Comprehension.](http://arxiv.org/abs/2310.08280) | 本研究深入研究了视障学生的Odia盲文阅读理解情况，发现阅读速度与阅读错误之间存在明显的相关性。 |
| [^6] | [CP-KGC: Constrained-Prompt Knowledge Graph Completion with Large Language Models.](http://arxiv.org/abs/2310.08279) | CP-KGC方法利用大型语言模型，通过约束式提示来补全知识图谱，提高推断效果，展示了在低资源计算条件下的有效性，并在数据集上取得了优于之前方法的结果。 |
| [^7] | [Impact of Co-occurrence on Factual Knowledge of Large Language Models.](http://arxiv.org/abs/2310.08256) | 大型语言模型在回答问题时常常出现事实错误，这主要是因为过度依赖预训练语料库的共现统计。研究结果表明，大型语言模型容易受到共现偏见的影响，导致难以回忆起预训练数据集中很少共现的事实。建议使用去偏数据集进行微调来减轻偏见，但这对于微调期间未见过的稀有事实的回忆效果并不明显。 |
| [^8] | [Who Said That? Benchmarking Social Media AI Detection.](http://arxiv.org/abs/2310.08240) | 本文介绍了SAID，一个用于评估AI文本检测模型在真实社交媒体平台上的能力的新基准测试。研究发现，基于知乎数据集，注释员可以以96.5%的准确率区分AI生成文本和人类生成文本。 |
| [^9] | [Language Models are Universal Embedders.](http://arxiv.org/abs/2310.08232) | 该论文证明了多语言预训练的Transformer解码器在有限英文数据微调后能够通用地进行嵌入，实现了统一嵌入模型的目标。 |
| [^10] | [Fast Word Error Rate Estimation Using Self-Supervised Representations For Speech And Text.](http://arxiv.org/abs/2310.08225) | 本文介绍了一种使用自监督学习表示法（SSLR）的快速WER估计器（Fe-WER），在大数据场景下具有较高的计算效率和性能提升。 |
| [^11] | [SimCKP: Simple Contrastive Learning of Keyphrase Representations.](http://arxiv.org/abs/2310.08221) | SimCKP是一个简单的对比学习框架，通过学习上下文感知的短语级表示来提取关键词短语，并通过重新排序来调整生成的短语的分数。 |
| [^12] | [Visual Question Generation in Bengali.](http://arxiv.org/abs/2310.08187) | 本文提出了孟加拉语视觉问题生成任务，并开发了基于transformer的编码器-解码器架构，能够生成孟加拉语问题。通过引导型VQG模型，我们能够根据答案和问题类别生成问题。实验证明我们的模型在孟加拉语VQG任务上取得了最先进的性能。 |
| [^13] | [EIPE-text: Evaluation-Guided Iterative Plan Extraction for Long-Form Narrative Text Generation.](http://arxiv.org/abs/2310.08185) | 本文提出了EIPE-text方法用于长篇叙事文本生成，通过从语料库中提取计划并利用评估机制进行迭代改进，构建了更好的规划器。 |
| [^14] | [Exploring the Cognitive Knowledge Structure of Large Language Models: An Educational Diagnostic Assessment Approach.](http://arxiv.org/abs/2310.08172) | 本研究通过教育诊断评估方法，揭示了大型语言模型（LLMs）的知识结构，强调了研究LLMs的认知能力和不同认知模式的重要性。 |
| [^15] | [Simplicity Level Estimate (SLE): A Learned Reference-Less Metric for Sentence Simplification.](http://arxiv.org/abs/2310.08170) | 这个论文提出了一种基于学习的评估指标（SLE）用于句子简化，相比现有的指标，它更专注于简洁性，并在与人类判断的相关性方面表现出色。 |
| [^16] | [Multiclass Classification of Policy Documents with Large Language Models.](http://arxiv.org/abs/2310.08167) | 这项工作使用GPT 3.5和GPT 4等大型语言模型对政策文件进行多类别分类，提出了三种使用场景，并估计了整体准确率在58％至83％之间。结果表明，完全依赖语言模型仍存在不足之处。 |
| [^17] | [Ziya-VL: Bilingual Large Vision-Language Model via Multi-Task Instruction Tuning.](http://arxiv.org/abs/2310.08166) | 本论文介绍了Ziya-VL系列，这是一组双语大规模视觉语言模型，旨在将视觉语义融入语言模型以进行多模态对话。模型采用了查询变换器和优化方案，如指令调整和多阶段训练，以实现视觉语言对齐。 |
| [^18] | [Context Compression for Auto-regressive Transformers with Sentinel Tokens.](http://arxiv.org/abs/2310.08152) | 本论文提出了一种带有标记符号的自回归Transformer的上下文压缩方法，该方法通过将指定范围内的中间激活逐步压缩为紧凑形式，从而减少内存和计算成本。实验证明，在语言建模和文档生成方面，该方法相比稀疏注意力基线具有更好的流畅度、N-gram匹配和语义相似性。 |
| [^19] | [On the Relevance of Phoneme Duration Variability of Synthesized Training Data for Automatic Speech Recognition.](http://arxiv.org/abs/2310.08132) | 本研究探讨了自动生成的训练数据中音素持续时间变异性与自动语音识别的相关性，并提出了一种基于随机游走的算法来改善合成数据的质量，从而改进了半监督设置下的ASR系统。 |
| [^20] | [Fine-grained Conversational Decoding via Isotropic and Proximal Search.](http://arxiv.org/abs/2310.08130) | 本论文提出了一种细粒度的对话解码方法，通过各向同性和近端搜索（IPS）生成信息集中的语义回应，并在对话领域的评估中取得了优于现有方法的效果。 |
| [^21] | [Who Wrote it and Why? Prompting Large-Language Models for Authorship Verification.](http://arxiv.org/abs/2310.08123) | 本文提出了PromptAV，一种利用大语言模型（LLMs）进行作者验证的新技术，通过提供逐步的风格测量解释提示，解决了现有AV技术的限制，具有更好的性能和可解释性。 |
| [^22] | [Voice Conversion for Stuttered Speech, Instruments, Unseen Languages and Textually Described Voices.](http://arxiv.org/abs/2310.08104) | 这项研究调查了最新的声音转换模型在口吃、跨语言、乐器和文本描述声音等非标准任务上的表现。研究发现，在口吃和跨语言声音转换方面，kNN-VC方法保持了较高的性能，而乐器和文本到声音的转换则有更复杂的结果。 |
| [^23] | [QASiNa: Religious Domain Question Answering using Sirah Nabawiyah.](http://arxiv.org/abs/2310.08102) | 本文提出了一种使用《先知传记》的宗教领域问答系统(QASiNa)，旨在对大型语言模型在宗教领域的应用进行评估。 |
| [^24] | [Promptor: A Conversational and Autonomous Prompt Generation Agent for Intelligent Text Entry Techniques.](http://arxiv.org/abs/2310.08101) | 本论文介绍了Promptor，一个用于智能文本输入技术的对话式自主提示生成代理。利用大型语言模型的上下文学习能力，可以克服数据收集和模型微调的挑战。我们通过以GPT-3.5为例的实验证明，仅通过提示即可超过GPT-2支持的系统，并且可与经过精调的GPT-3.5模型相媲美。 |
| [^25] | [ClimateNLP: Analyzing Public Sentiment Towards Climate Change Using Natural Language Processing.](http://arxiv.org/abs/2310.08099) | 本研究利用自然语言处理分析社交媒体上关于气候变化的推文情感态度，通过使用ClimateBERT模型量化情感，从而获得有关公众对气候变化的观点和反馈。 |
| [^26] | [Low-Resource Clickbait Spoiling for Indonesian via Question Answering.](http://arxiv.org/abs/2310.08085) | 本论文介绍了一项以问答方式翻译印尼语低资源标题党处理的任务，贡献包括构建手动标注的印尼语标题党处理语料库，并评估了跨语言零射击问答模型的应用。实验结果表明，XLM-RoBERTa（大）模型在短语和段落标题党处理方面表现优异，而mDeBERTa（基础）模型在多部分标题党处理中表现最佳。 |
| [^27] | [To token or not to token: A Comparative Study of Text Representations for Cross-Lingual Transfer.](http://arxiv.org/abs/2310.08078) | 本文进行了针对跨语言转换的文本表示方案的比较研究，发现图像模型在相关且脚本相似的语言之间的转换中表现优秀，而基于分割的模型在偏向单词含义的任务中表现更好。 |
| [^28] | [Rethinking Negative Pairs in Code Search.](http://arxiv.org/abs/2310.08069) | 本文提出了一种简单而有效的Soft-InfoNCE损失函数，通过在InfoNCE中插入权重项来解决代码搜索中负样本的问题，包括大型代码库中的虚假负样本和未能区分负样本的潜在相关性。 |
| [^29] | [QLLM: Accurate and Efficient Low-Bitwidth Quantization for Large Language Models.](http://arxiv.org/abs/2310.08041) | QLLM是一种为大规模语言模型设计的准确高效的低位宽后训练量化方法，通过引入自适应通道重组技术，将离群值的大小重新分配给其他通道，从而减轻它们对量化范围的影响。 |
| [^30] | [Exploring Large Language Models for Multi-Modal Out-of-Distribution Detection.](http://arxiv.org/abs/2310.08027) | 本论文提出了一种利用大型语言模型以及图像上下文信息来增强多模态区分程度检测性能的方法。通过了解大型语言模型的生成特征和视觉对象，我们可以提高区分程度检测的准确度和可靠性。 |
| [^31] | [Harnessing Large Language Models' Empathetic Response Generation Capabilities for Online Mental Health Counselling Support.](http://arxiv.org/abs/2310.08017) | 本研究探讨了大型语言模型（LLMs）在模拟心理健康咨询对话中生成共情回应的能力。通过与传统回应生成对话系统和人工回应的比较，研究发现LLMs在这一领域具有潜力。 |
| [^32] | [Think, Act, and Ask: Open-World Interactive Personalized Robot Navigation.](http://arxiv.org/abs/2310.07968) | 这项研究引入了零射交互个性化对象导航（ZIPON），通过使用大型语言模型（LLM）和用户反馈，解决了在未知环境中导航到个性化目标对象的问题。 |
| [^33] | [Clustering of Spell Variations for Proper Nouns Transliterated from the other languages.](http://arxiv.org/abs/2310.07962) | 本研究提出了一种使用机器学习和数学相似性方程对来自不同语言的专有名词的拼写变体进行聚类的方法，以解决NLP中由于翻译和转写不一致而引起的拼写变化问题。 |
| [^34] | [A New Approach Towards Autoformalization.](http://arxiv.org/abs/2310.07957) | 该论文提出了一种新的方法来应对研究水平的数学自动形式化任务，通过将任务分解成更容易处理的子任务，包括未链接形式化、实体链接和类型调整。此外，还提出了一个用于未链接形式化的基准数据集 arXiv2Formal。 |
| [^35] | [D2 Pruning: Message Passing for Balancing Diversity and Difficulty in Data Pruning.](http://arxiv.org/abs/2310.07931) | D2修剪是一种平衡数据多样性和困难度的方法，在coreset选择中同时考虑数据多样性和重要性评分。 |
| [^36] | [Crosslingual Structural Priming and the Pre-Training Dynamics of Bilingual Language Models.](http://arxiv.org/abs/2310.07929) | 这项研究通过结构启示测试了多语言语言模型是否共享抽象的语法表示，并发现在接触第二种语言后的早期阶段即形成跨语言结构启示效应。这对数据污染、低资源转移以及多语言模型中抽象语法表示的产生具有重要意义。 |
| [^37] | [The Expresssive Power of Transformers with Chain of Thought.](http://arxiv.org/abs/2310.07923) | 本论文研究基于思维链的Transformer的表达能力，通过允许使用中间生成的方式提高了Transformer的推理能力，并发现线性数量的解码步骤在标准计算复杂度下增加了明显的新能力。 |
| [^38] | [Pit One Against Many: Leveraging Attention-head Embeddings for Parameter-efficient Multi-head Attention.](http://arxiv.org/abs/2310.07911) | 本论文提出一种利用注意力头嵌入来实现参数有效的多头注意力机制，该机制在多项下游任务中取得了与传统多头注意力机制相当的预测性能，同时显著减少内存占用。 |
| [^39] | [LangNav: Language as a Perceptual Representation for Navigation.](http://arxiv.org/abs/2310.07889) | 该论文探索了将语言作为导航的感知表示，并使用现成的视觉系统将每个时间步骤的视图转化为自然语言描述，通过微调预训练的语言模型选择最佳的行动来满足导航指令。有两种用例的实验对这种基于语言的导航方法进行了探索：使用大型语言模型生成合成轨迹以微调较小的语言模型，以及模拟到实际的转换。 |
| [^40] | [TabLib: A Dataset of 627M Tables with Context.](http://arxiv.org/abs/2310.07875) | TabLib是一个包含上亿表格和上百亿上下文的数据集，规模和多样性使其在表格模态下具有巨大的潜力。 |
| [^41] | [Assessing Evaluation Metrics for Neural Test Oracle Generation.](http://arxiv.org/abs/2310.07856) | 评估了神经测试Oracle生成的评估指标，在基于自然语言生成的度量和测试充分性度量之间发现了没有显著相关性。基于自然语言生成的度量高但测试充分性度量低的oracle往往具有复杂的特征。 |
| [^42] | [Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations.](http://arxiv.org/abs/2310.07849) | 本研究旨在探讨使用大型语言模型生成合成数据在文本分类模型训练中的潜力和限制。研究结果发现，主观性会负面影响模型在合成数据上的性能。这对于理解和利用合成数据的有效性具有重要的启示作用。 |
| [^43] | [Framework for Question-Answering in Sanskrit through Automated Construction of Knowledge Graphs.](http://arxiv.org/abs/2310.07848) | 本文针对梵语中问题的构建了一个自然语言问答系统，通过自动构建知识图谱来回答事实性问题，并在不同类型的关系上展示了系统的应用。分析了系统的缺点以便改进。 |
| [^44] | [Does Synthetic Data Make Large Language Models More Efficient?.](http://arxiv.org/abs/2310.07830) | 本文探讨了在NLP中合成数据生成的细微差别，重点关注基于模板的问题生成。通过评估其优势和固有限制，本研究揭示了合成数据对现代Transformer模型性能的影响，并强调了合成数据与真实世界数据之间所需的微妙平衡。 |
| [^45] | [Antarlekhaka: A Comprehensive Tool for Multi-task Natural Language Annotation.](http://arxiv.org/abs/2310.07826) | Antarlekhaka是一个全面的多任务自然语言标注工具，可用于手动标注与NLP相关的任务。它兼容Unicode，支持分布式注释，并提供用户友好的界面。其中包括两个其他工具没有处理的任务，即句子边界检测和决定规范词序，这对于诗歌形式的文本是重要的。 |
| [^46] | [Non-autoregressive Text Editing with Copy-aware Latent Alignments.](http://arxiv.org/abs/2310.07821) | 这篇论文提出了一种新的非自回归文本编辑方法，通过引入复制操作来管理文本重叠，解决了Seq2Edit方法在生成灵活性和跨语言推广方面的挑战。实验证明，该方法在GEC和句子融合任务上表现优异，并且在德语和俄语上具有良好的泛化性能。 |
| [^47] | [Faithfulness Measurable Masked Language Models.](http://arxiv.org/abs/2310.07819) | 本论文提出了一种可度量忠实性的掩码语言模型，通过使用一种新颖的微调方法，将屏蔽令牌作为设计使其成为分布内，以解决解释自然语言处理模型时常见的问题。 |
| [^48] | [Exploring the Relationship between Analogy Identification and Sentence Structure Encoding in Large Language Models.](http://arxiv.org/abs/2310.07818) | 这项研究探究了大型语言模型中识别句子类比的能力与其编码句法和语义结构能力之间的关系。 |
| [^49] | [Language Models As Semantic Indexers.](http://arxiv.org/abs/2310.07815) | 本文介绍了一种使用生成性语言模型学习语义ID的自监督框架LMINDEXER。 |
| [^50] | [A general mechanism of humor: reformulating the semantic overlap.](http://arxiv.org/abs/2310.07803) | 本文提出了一种普适性的认知幽默机制，建立在约束的概念上，通过重叠约束的观察来解释幽默的产生。 |
| [^51] | [Ontology Enrichment for Effective Fine-grained Entity Typing.](http://arxiv.org/abs/2310.07795) | 在本文中，我们提出了OnEFET方法，通过为本体结构的每个节点添加额外信息，包括实例信息和主题信息，来增强零样本细粒度实体类型定义。这种方法可以有效指导细粒度实体类型的识别任务。 |
| [^52] | [GenTKG: Generative Forecasting on Temporal Knowledge Graph.](http://arxiv.org/abs/2310.07793) | 研究提出了一种名为GenTKG的生成模型，用于在时间知识图谱上进行预测。该模型通过结合基于时间逻辑规则的检索策略和轻量级的参数效率指导，克服了复杂的时间图数据结构和庞大的数据量所带来的挑战。 |
| [^53] | [Well Begun is Half Done: Generator-agnostic Knowledge Pre-Selection for Knowledge-Grounded Dialogue.](http://arxiv.org/abs/2310.07659) | 本论文提出了一种生成器无关的知识选择方法GATE，将知识选择放置在生成之前，可以减少后续响应生成模型的负担，并为知识驱动对话系统提供更多信息量的响应。 |
| [^54] | [Rethinking the BERT-like Pretraining for DNA Sequences.](http://arxiv.org/abs/2310.07644) | 重新考虑了基于DNA序列的BERT-like预训练方法，通过使用K-mer重叠标记化，在下游任务的微调阶段和预训练过程中都取得了一致的性能改善。 |
| [^55] | [Typing to Listen at the Cocktail Party: Text-Guided Target Speaker Extraction.](http://arxiv.org/abs/2310.07284) | 研究人员提出了一种名为LLM-TSE的模型，该模型利用大型语言模型从用户键入的文本输入中提取语义线索，以增强目标说话人提取(TSE)模型的灵活性和可控性。 |
| [^56] | [An Analysis on Large Language Models in Healthcare: A Case Study of BioBERT.](http://arxiv.org/abs/2310.07282) | 本研究分析了在医疗保健领域应用大型语言模型（尤其是BioBERT）的可行性，并提出了针对医疗保健领域的微调方法。研究突出了BioBERT对于解决与生物医学文本挖掘相关任务的特定要求的适用性。 |
| [^57] | [Jaynes Machine: The universal microstructure of deep neural networks.](http://arxiv.org/abs/2310.06960) | Jaynes Machine提出了一种关于深度神经网络微结构的新理论，预测了所有高连接层具有分布为对数正态分布的通用连接强度微结构，并在理想条件下预测了${\mu}$和${\sigma}$在所有网络的所有层中是相同的。实证数据支持这些预测，并讨论了如何利用这些结果来减少训练大规模深度神经网络所需的资源。 |
| [^58] | [SpikeCLIP: A Contrastive Language-Image Pretrained Spiking Neural Network.](http://arxiv.org/abs/2310.06488) | 本论文引入了一种名为SpikeCLIP的新框架，通过对比语言-图像预训练实现了脉冲神经网络的多模态扩展，并在能源效率和性能方面取得了可比较的结果。 |
| [^59] | [Loose lips sink ships: Mitigating Length Bias in Reinforcement Learning from Human Feedback.](http://arxiv.org/abs/2310.05199) | 本文提出了一种创新的解决方案，通过应用“专家的乘积”（PoE）技术来减轻强化学习中的长度偏差问题。在这个框架中，主要的专家关注理解人类意图，而偏见专家则致力于识别和捕捉长度偏差。 |
| [^60] | [TEMPO: Prompt-based Generative Pre-trained Transformer for Time Series Forecasting.](http://arxiv.org/abs/2310.04948) | 本文提出了一个新的框架 TEMPO，通过利用时间序列任务的两个重要归纳偏差，即将复杂交互分解和引入基于选择的提示来有效学习时间序列表示。 |
| [^61] | [Effective Slogan Generation with Noise Perturbation.](http://arxiv.org/abs/2310.04472) | 本研究引入了基于噪声扰动的新方法，利用预训练的transformer T5模型生成独特且连贯的口号，同时将公司和品牌的描述纳入到生成过程中。结果表明，该方法在口号生成方面取得了良好的效果。 |
| [^62] | [MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use.](http://arxiv.org/abs/2310.03128) | 本文提出了一个名为MetaTool的基准，旨在评估大型语言模型（LLMs）是否具有工具使用意识并且能够正确选择工具。基准中包含一个名为ToolE的数据集，其中包含各种类型的用户查询，用于触发LLMs使用工具。 |
| [^63] | [Hierarchical Evaluation Framework: Best Practices for Human Evaluation.](http://arxiv.org/abs/2310.01917) | 这篇论文提出了一个分层评估框架，解决了自然语言处理中人工评估指标不统一的问题，并应用于机器阅读理解系统的评估，突出了输入与输出质量之间的关联。 |
| [^64] | [Ring Attention with Blockwise Transformers for Near-Infinite Context.](http://arxiv.org/abs/2310.01889) | 本论文提出了一种新颖的环形注意力方法，通过分块计算和通信重叠的方式处理长序列，解决了Transformer在处理长序列时的内存限制问题。实验证明该方法能够有效地消除单个设备对内存的约束，使得训练和推理的序列长度能够更长。 |
| [^65] | [GenAI Against Humanity: Nefarious Applications of Generative Artificial Intelligence and Large Language Models.](http://arxiv.org/abs/2310.00737) | 这篇论文探讨了生成式人工智能和大型语言模型的潜在滥用，呼吁认识到这些挑战的紧迫性。研究揭示了这些技术在深度伪造、合成身份恶意活动以及虚假信息和欺诈方面可能带来的社会影响。 |
| [^66] | [A Comprehensive Survey of Document-level Relation Extraction (2016-2022).](http://arxiv.org/abs/2309.16396) | 这篇综述论文介绍了文档级关系抽取（DocRE）的最新进展，与句子级关系抽取相比，DocRE提供了更广泛的上下文分析，涉及跨越多个句子或段落的关系抽取，可用于构建和自动填充知识库。 |
| [^67] | [DiLu: A Knowledge-Driven Approach to Autonomous Driving with Large Language Models.](http://arxiv.org/abs/2309.16292) | DiLu是基于大型语言模型的自动驾驶系统，采用知识驱动方法，通过推理和反思模块进行决策，积累经验并具有显著的泛化能力。 |
| [^68] | [PRiSM: Enhancing Low-Resource Document-Level Relation Extraction with Relation-Aware Score Calibration.](http://arxiv.org/abs/2309.13869) | PRiSM是一种增强低资源文档级关系抽取的方法，通过关系感知分数校准来提高模型性能，成功地降低了在低资源环境下训练模型时的校准误差。 |
| [^69] | [AceGPT, Localizing Large Language Models in Arabic.](http://arxiv.org/abs/2309.12053) | 本研究旨在开发阿拉伯文的本地化大型语言模型(AceGPT)，通过预训练、监督微调和增强学习方法来培养具备文化意识和价值观一致的阿拉伯文模型，以满足阿拉伯语社区特定应用需求。评估结果表明，AceGPT在各项基准测试中都是最先进的阿拉伯文模型。 |
| [^70] | [MBR and QE Finetuning: Training-time Distillation of the Best and Most Expensive Decoding Methods.](http://arxiv.org/abs/2309.10966) | 本文提出了MBR微调和QE微调方法，将训练时的质量提升蒸馏到基准模型中，从而在推断时使用高效的解码算法。实验证明，这些微调方法能显著提升模型性能，甚至超过基准模型。 |
| [^71] | [MINT: Evaluating LLMs in Multi-turn Interaction with Tools and Language Feedback.](http://arxiv.org/abs/2309.10691) | MINT是一个评估LLMs在多轮交互中解决任务能力的基准，通过使用工具和利用用户的自然语言反馈。它解决了当前评估协议忽略细致互动和低估自然语言反馈的问题，促进了研究基准评估和实际应用之间的一致性。 |
| [^72] | [DePT: Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning.](http://arxiv.org/abs/2309.05173) | DePT通过将软提示分解为较短的软提示和一对低秩矩阵，并用两个不同的学习率来优化，以解决提示调整对训练和推理时间以及内存使用的影响，从而实现更好的性能。 |
| [^73] | [PromptTTS 2: Describing and Generating Voices with Text Prompt.](http://arxiv.org/abs/2309.02285) | PromptTTS 2是一种使用文本提示来描述和生成声音的方法，通过变化网络提供声音的可变性信息，并利用大型语言模型（LLM）来生成高质量的文本提示。 |
| [^74] | [Bridging Emotion Role Labeling and Appraisal-based Emotion Analysis.](http://arxiv.org/abs/2309.02092) | 本文介绍了情绪角色标注和基于评估的情绪分析之间的桥梁。情绪角色标注在情绪分类的基础上添加了对提及实体的视角，提取了对应情绪原因的文本范围。情绪和事件具有两种关系：情绪本身就是一种事件，并且情绪是由事件引起的。这一概念对于情绪角色标注的研究具有重要意义。 |
| [^75] | [StoryBench: A Multifaceted Benchmark for Continuous Story Visualization.](http://arxiv.org/abs/2308.11606) | StoryBench是一个新的，具有挑战性的多任务基准，用于评估文本到视频模型。它包括动作执行，故事延续和故事生成三个难度逐渐增加的视频生成任务。我们提出了一些小而强大的文本到视频基线，并展示了它们的好处。 |
| [^76] | [Large Language Model as a User Simulator.](http://arxiv.org/abs/2308.11534) | 本文创新性地将从真实人机对话中提取的人类问题作为学习目标，并且训练了一个用户模拟器UserGPT，并使用生成的高质量合成对话数据集RealChat来训练助手模型ReaLM。实验证明，ReaLM在多个基准测试中超过了基准模型。 |
| [^77] | [Extracting detailed oncologic history and treatment plan from medical oncology notes with large language models.](http://arxiv.org/abs/2308.03853) | 本研究开发了一个详细的肿瘤学信息注释方案，使用大型语言模型从肿瘤学笔记中提取和推理复杂的修辞，并应用于乳腺癌进展笔记的语料库。 |
| [^78] | [CIDER: Context sensitive sentiment analysis for short-form text.](http://arxiv.org/abs/2307.07864) | CIDER是一种上下文感知的短文本情感分析方法，通过从整个语料库中推断出情感词的倾向来评分个别文本，相比通用方法在天气推文集合上表现更优。 |
| [^79] | [Distilling Large Vision-Language Model with Out-of-Distribution Generalizability.](http://arxiv.org/abs/2307.03135) | 本文研究了针对大型视觉语言模型的模型压缩方法，将教师模型的视觉表示压缩到学生模型中。研究重点在于超出分布可泛化的问题，并提出了两个原则来增强学生模型的性能。 |
| [^80] | [Questioning the Survey Responses of Large Language Models.](http://arxiv.org/abs/2306.07951) | 本文使用美国人口普查局建立的全美社区调查（ACS）评估了十几个不同大小的语言模型，发现小型模型具有显著的位置和标签偏差，而模型大小的增加能减轻这种偏差，但无法根据US群体或任何可识别的群体趋势进行调整。 |
| [^81] | [An Efficient Multilingual Language Model Compression through Vocabulary Trimming.](http://arxiv.org/abs/2305.15020) | 该论文提出了一种名为词汇修剪（VT）的方法，通过删除多语言语言模型中的不相关标记，将其压缩为目标语言模型。实验证明，词汇修剪可以在保持多语言模型性能的同时，降低了模型的大小。 |
| [^82] | [Learning to Generate Novel Scientific Directions with Contextualized Literature-based Discovery.](http://arxiv.org/abs/2305.14259) | 本文介绍了一种基于文献的发现方法，通过上下文化的学习生成新的科学方向，克服了标准方法在预测关联、忽略上下文等方面的局限性。模型使用了引文和知识图关系的网络，并使用大型语言模型进行评估，发现GPT4在生成创新思想方面表现出色。 |
| [^83] | [Evaluating Factual Consistency of Summaries with Large Language Models.](http://arxiv.org/abs/2305.14069) | 本研究通过直接提示大型语言模型（LLMs），探索评估摘要的事实一致性。实验证明，在各种设置中，提示LLMs能够在二分类准确性方面超过以前最佳的事实性系统，最高可提高12.2个绝对点。 |
| [^84] | [Satisfiability-Aided Language Models Using Declarative Prompting.](http://arxiv.org/abs/2305.09656) | 本文提出了一种利用自动定理证明器和声明性任务规范的可满足性辅助语言建模方法，可以提高大型语言模型的推理能力。 |
| [^85] | [Measuring Stereotypes using Entity-Centric Data.](http://arxiv.org/abs/2305.09548) | 本文提出并评估了三种新的以实体为中心的方法，展示了这些模型在预测人们如何将身份标签应用于自己和他人以及量化突出的社会维度（如性别）的刻板印象方面优于现有方法。 |
| [^86] | [Is ChatGPT a Good Causal Reasoner? A Comprehensive Evaluation.](http://arxiv.org/abs/2305.07375) | 本文对ChatGPT的因果推理能力进行了首次全面评估，实验证明ChatGPT是一个好的因果解释者，但不是一个好的因果推理者，存在严重的因果幻觉问题，对于明确的因果关系表现良好。 |
| [^87] | [Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in Large Language Models.](http://arxiv.org/abs/2304.11657) | 本文提出 Iter-CoT 方法，在大型语言模型中进行迭代增强的思维链提示，通过选择具有适度难度的具有挑战性但可回答的问题，并伴随推理链作为示例，提高了模型的泛化能力，同时使模型能够更准确地生成推理链。 |
| [^88] | [LLMMaps -- A Visual Metaphor for Stratified Evaluation of Large Language Models.](http://arxiv.org/abs/2304.00457) | LLMMaps是一种分层评估大型语言模型性能的可视化技术，能够揭示取得高准确度和产生幻觉的子领域，并指导模型的进一步发展。 |
| [^89] | [Analyzing And Editing Inner Mechanisms Of Backdoored Language Models.](http://arxiv.org/abs/2302.12461) | 本研究分析并编辑暗藏后门的语言模型的内部机制，发现早期层的MLP模块和初始嵌入投影是后门机制中最重要的部分。通过使用PCP消融技术替换变压器模块，我们成功删除、插入和修改后门机制，并显著改善了后门的输出效果。 |
| [^90] | [Can Pre-trained Vision and Language Models Answer Visual Information-Seeking Questions?.](http://arxiv.org/abs/2302.11713) | 本研究介绍了一个专门针对无法仅凭常识知识回答的信息寻求问题而设计的视觉问答数据集InfoSeek。使用InfoSeek数据集，我们发现目前最先进的预训练多模态模型在回答求知视觉问题方面面临挑战，但在该数据集上进行微调可以激发模型使用细粒度知识。 |
| [^91] | [Big Little Transformer Decoder.](http://arxiv.org/abs/2302.07863) | 提出了一种名为BiLD的框架，它由大小不同的两个模型协作生成文本。其中小型模型自回归地生成文本，而大型模型则在必要时以非自回归的方式对小型模型的预测进行微调，从而显著减少了推理延迟。 |
| [^92] | [On the Security Vulnerabilities of Text-to-SQL Models.](http://arxiv.org/abs/2211.15363) | 该论文揭示了Text-to-SQL模型存在的安全漏洞，并证明了这些漏洞能够被恶意利用产生攻击，通过对商业应用和开源语言模型的实验验证。该研究意在引起学术界对NLP算法相关的软件安全问题的关注和进一步研究。 |
| [^93] | [mGPT: Few-Shot Learners Go Multilingual.](http://arxiv.org/abs/2204.07580) | 本文介绍了两种自回归GPT样式模型，分别使用13亿和130亿个参数，在60种语言中训练，并展示了与Facebook最近发布的XGLM模型性能相当的结果。这为低资源语言的自然语言处理提供了更多可能性。 |

# 详细

[^1]: 使用后门技术保护我们的隐私

    Defending Our Privacy With Backdoors. (arXiv:2310.08320v1 [cs.LG])

    [http://arxiv.org/abs/2310.08320](http://arxiv.org/abs/2310.08320)

    本研究提出了一种基于后门攻击的防御方法，通过对模型进行策略性插入后门，对齐敏感短语与中性术语的嵌入，以删除训练数据中的私人信息。实证结果显示该方法的有效性。

    

    在使用未经筛选、常常包含敏感信息的网页数据训练大型人工智能模型的情况下，隐私问题成为了一个重要的关注点。其中一个问题是，攻击者可以利用隐私攻击的方法提取出训练数据的信息。然而，如何在不降低模型性能的情况下去除特定信息是一个不容易解决且具有挑战性的问题。我们提出了一个基于后门攻击的简单而有效的防御方法，用于从模型中删除私人信息，如个人姓名，特别是针对文本编码器的。具体而言，通过策略性地插入后门，我们将敏感短语的嵌入与中性术语的嵌入对齐，例如用"a person"代替人名。我们的实证结果通过对零样本分类器使用专门的隐私攻击测试表明了我们基于后门的防御方法的效果。我们的方法提供了一个新的"双重用途"的视角。

    The proliferation of large AI models trained on uncurated, often sensitive web-scraped data has raised significant privacy concerns. One of the concerns is that adversaries can extract information about the training data using privacy attacks. Unfortunately, the task of removing specific information from the models without sacrificing performance is not straightforward and has proven to be challenging. We propose a rather easy yet effective defense based on backdoor attacks to remove private information such as names of individuals from models, and focus in this work on text encoders. Specifically, through strategic insertion of backdoors, we align the embeddings of sensitive phrases with those of neutral terms-"a person" instead of the person's name. Our empirical results demonstrate the effectiveness of our backdoor-based defense on CLIP by assessing its performance using a specialized privacy attack for zero-shot classifiers. Our approach provides not only a new "dual-use" perspecti
    
[^2]: 并非所有的演示示例都有同样的益处：为上下文学习重新加权演示示例

    Not All Demonstration Examples are Equally Beneficial: Reweighting Demonstration Examples for In-Context Learning. (arXiv:2310.08309v1 [cs.CL])

    [http://arxiv.org/abs/2310.08309](http://arxiv.org/abs/2310.08309)

    本文研究了如何给演示示例重新加权以优化上下文学习的效果。通过设计一个和最终学习性能具有强相关性的掩码自我预测分数，我们确定了近似最优的权重，并采用离散化和波束搜索等方法加快了权重搜索过程。

    

    最近，随着模型规模的扩大，大型语言模型（LLMs）已经获得了上下文学习（ICL）的能力，仅通过在输入序列中添加几个演示示例就可以快速适应下游任务。然而，目前的ICL实践将所有演示示例视为相等，仍需要改进，因为示例的质量通常是不均匀的。在本文中，我们研究了如何确定近似最优的演示示例权重以及如何在ICL过程中应用它们。为了在没有额外验证数据的情况下评估权重的质量，我们设计了一个掩码自我预测（MSP）分数，该分数与最终的ICL性能呈强相关。为了加速权重搜索过程，我们对连续权重空间进行离散化，并采用波束搜索。通过获得近似最优权重，我们进一步提出了两种策略来将它们应用到不同模型位置的演示示例上。实验结果表明...

    Large Language Models (LLMs) have recently gained the In-Context Learning (ICL) ability with the models scaling up, allowing them to quickly adapt to downstream tasks with only a few demonstration examples prepended in the input sequence. Nonetheless, the current practice of ICL treats all demonstration examples equally, which still warrants improvement, as the quality of examples is usually uneven. In this paper, we investigate how to determine approximately optimal weights for demonstration examples and how to apply them during ICL. To assess the quality of weights in the absence of additional validation data, we design a masked self-prediction (MSP) score that exhibits a strong correlation with the final ICL performance. To expedite the weight-searching process, we discretize the continuous weight space and adopt beam search. With approximately optimal weights obtained, we further propose two strategies to apply them to demonstrations at different model positions. Experimental resul
    
[^3]: MProto：带去噪最优传输的多原型网络在远程监督命名实体识别中的应用

    MProto: Multi-Prototype Network with Denoised Optimal Transport for Distantly Supervised Named Entity Recognition. (arXiv:2310.08298v1 [cs.CL])

    [http://arxiv.org/abs/2310.08298](http://arxiv.org/abs/2310.08298)

    本文提出了一种针对远程监督命名实体识别任务的多原型网络MProto。与以往方法不同的是，MProto使用多个原型来表示每个实体类型，以捕捉实体表示中的类内变化。为了减轻噪声，文中还提出了一种新的去噪最优传输算法。实验证明，MProto在远程监督命名实体识别中取得了优秀的性能。

    

    远程监督命名实体识别（DS-NER）旨在通过知识库或词表以及无标签的语料库来定位实体提及并对其类型进行分类。然而，远程标注存在噪声，降低了NER模型的性能。在本文中，我们提出了一种针对DS-NER任务的鲁棒性原型网络MProto。与以往基于原型的NER方法不同，MProto用多个原型来表示每个实体类型，以表征实体表示中的类内变化。为了优化分类器，每个标记应分配一个合适的真实原型，我们将这样的标记-原型分配视为最优传输（OT）问题。此外，为了减轻不完全标记的噪声，我们提出了一种新颖的去噪最优传输（DOT）算法。具体而言，我们利用Other类标记的分配结果与所有原型之间的对应关系来区分未标记实体标记与真负例。实验证明，MProto在DS-NER任务上取得了优秀的性能，相对于现有方法具有更好的鲁棒性和准确性。

    Distantly supervised named entity recognition (DS-NER) aims to locate entity mentions and classify their types with only knowledge bases or gazetteers and unlabeled corpus. However, distant annotations are noisy and degrade the performance of NER models. In this paper, we propose a noise-robust prototype network named MProto for the DS-NER task. Different from previous prototype-based NER methods, MProto represents each entity type with multiple prototypes to characterize the intra-class variance among entity representations. To optimize the classifier, each token should be assigned an appropriate ground-truth prototype and we consider such token-prototype assignment as an optimal transport (OT) problem. Furthermore, to mitigate the noise from incomplete labeling, we propose a novel denoised optimal transport (DOT) algorithm. Specifically, we utilize the assignment result between Other class tokens and all prototypes to distinguish unlabeled entity tokens from true negatives. Experimen
    
[^4]: 扩展BERT词汇表以用于知识库构建

    Expanding the Vocabulary of BERT for Knowledge Base Construction. (arXiv:2310.08291v1 [cs.CL])

    [http://arxiv.org/abs/2310.08291](http://arxiv.org/abs/2310.08291)

    本论文介绍了一种扩展BERT词汇表的方法，以用于知识库构建任务。我们采用了特定任务的再预训练方法，通过添加新单词来扩展语言模型的词汇表，并保留了新添加单词的语义嵌入。

    

    知识库构建涉及获取结构化信息以创建一个包含事实和关系数据的知识库，以便于问答、信息检索和语义理解。国际语义网会议2023年的名为“来自预训练语言模型的知识库构建”挑战定义了专注于使用语言模型构建知识库的任务。我们关注挑战的第一轨道，其中参数受限于10亿，并且禁止在提示中包含实体描述。尽管遮蔽语言模型提供了足够的灵活性来扩展其词汇表，但它并非专门设计用于多令牌预测。为了解决这个问题，我们提出了适用于知识库构建的可扩展词汇BERT，它在扩展语言模型的词汇表的同时，保留了新添加单词的语义嵌入。我们采用了特定任务的再预训练方法，针对遮蔽语言模型进行重新训练。

    Knowledge base construction entails acquiring structured information to create a knowledge base of factual and relational data, facilitating question answering, information retrieval, and semantic understanding. The challenge called "Knowledge Base Construction from Pretrained Language Models" at International Semantic Web Conference 2023 defines tasks focused on constructing knowledge base using language model. Our focus was on Track 1 of the challenge, where the parameters are constrained to a maximum of 1 billion, and the inclusion of entity descriptions within the prompt is prohibited.  Although the masked language model offers sufficient flexibility to extend its vocabulary, it is not inherently designed for multi-token prediction. To address this, we present Vocabulary Expandable BERT for knowledge base construction, which expand the language model's vocabulary while preserving semantic embeddings for newly added words. We adopt task-specific re-pre-training on masked language mo
    
[^5]: 优化Odia盲文识字：速度对错误减少和提高理解力的影响

    Optimizing Odia Braille Literacy: The Influence of Speed on Error Reduction and Enhanced Comprehension. (arXiv:2310.08280v1 [cs.CL])

    [http://arxiv.org/abs/2310.08280](http://arxiv.org/abs/2310.08280)

    本研究深入研究了视障学生的Odia盲文阅读理解情况，发现阅读速度与阅读错误之间存在明显的相关性。

    

    本研究旨在对视障学生的Odia盲文阅读理解进行深入详细的分析。具体而言，研究探讨了他们的阅读速度和手指运动。研究还旨在调查他们可能遇到的理解困难和阅读错误。研究对象为来自9年级和10年级的六名年龄在14至16岁之间的学生。我们观察了参与者的手指运动，以了解阅读错误与手指运动的联系，并确定学生的阅读困难。我们还评估了参与者的Odia盲文阅读能力，包括他们的阅读速度（每分钟词数）、错误和理解力。Odia盲文读者的平均速度为17.64词/分钟。根据本研究，阅读速度与阅读错误之间存在明显的相关性。随着阅读速度的降低，阅读错误的数量往往会增加。此外，本研究还建立了阅读速度和理解力之间的联系。

    This study aims to conduct an extensive detailed analysis of the Odia Braille reading comprehension among students with visual disability. Specifically, the study explores their reading speed and hand or finger movements. The study also aims to investigate any comprehension difficulties and reading errors they may encounter. Six students from the 9th and 10th grades, aged between 14 and 16, participated in the study. We observed participants hand movements to understand how reading errors were connected to hand movement and identify the students reading difficulties. We also evaluated the participants Odia Braille reading skills, including their reading speed (in words per minute), errors, and comprehension. The average speed of Odia Braille reader is 17.64wpm. According to the study, there was a noticeable correlation between reading speed and reading errors. As reading speed decreased, the number of reading errors tended to increase. Moreover, the study established a link between red
    
[^6]: CP-KGC: 利用大型语言模型的约束式提示对知识图谱进行补全

    CP-KGC: Constrained-Prompt Knowledge Graph Completion with Large Language Models. (arXiv:2310.08279v1 [cs.CL])

    [http://arxiv.org/abs/2310.08279](http://arxiv.org/abs/2310.08279)

    CP-KGC方法利用大型语言模型，通过约束式提示来补全知识图谱，提高推断效果，展示了在低资源计算条件下的有效性，并在数据集上取得了优于之前方法的结果。

    

    知识图谱补全旨在利用现有知识推断和推测知识图谱中缺失的连接。SimKGC等基于文本的方法已经超过了图嵌入方法，展示了归纳式知识图谱补全的潜力。然而，基于文本的方法的效果取决于实体文本描述的质量。为了减轻LLM生成的文本中的幻觉，在本文中，我们引入了一种基于约束的提示方法，利用实体及其文本描述作为上下文约束来提高数据质量。我们的约束式提示知识图谱补全方法（CP-KGC）在低资源计算条件下表现出有效的推断能力，并超过了WN18RR和FB15K237数据集上的之前结果。这展示了LLMs在知识图谱补全任务中的整合，并为未来的研究提供了新的方向。

    Knowledge graph completion (KGC) aims to utilize existing knowledge to deduce and infer missing connections within knowledge graphs. Text-based approaches, like SimKGC, have outperformed graph embedding methods, showcasing the promise of inductive KGC. However, the efficacy of text-based methods hinges on the quality of entity textual descriptions. In this paper, we identify the key issue of whether large language models (LLMs) can generate effective text. To mitigate hallucination in LLM-generated text in this paper, we introduce a constraint-based prompt that utilizes the entity and its textual description as contextual constraints to enhance data quality. Our Constrained-Prompt Knowledge Graph Completion (CP-KGC) method demonstrates effective inference under low resource computing conditions and surpasses prior results on the WN18RR and FB15K237 datasets. This showcases the integration of LLMs in KGC tasks and provides new directions for future research.
    
[^7]: 大型语言模型中共现对事实知识的影响

    Impact of Co-occurrence on Factual Knowledge of Large Language Models. (arXiv:2310.08256v1 [cs.CL])

    [http://arxiv.org/abs/2310.08256](http://arxiv.org/abs/2310.08256)

    大型语言模型在回答问题时常常出现事实错误，这主要是因为过度依赖预训练语料库的共现统计。研究结果表明，大型语言模型容易受到共现偏见的影响，导致难以回忆起预训练数据集中很少共现的事实。建议使用去偏数据集进行微调来减轻偏见，但这对于微调期间未见过的稀有事实的回忆效果并不明显。

    

    尽管大型语言模型在各种应用中取得了成功，但它们经常在事实上做出错误的回答。本文假设过度依赖于预训练语料库的简单共现统计是导致事实错误的主要因素之一。我们的结果表明，大型语言模型容易受到共现偏见的影响，即更倾向于选择频繁共现的词而不是正确答案。因此，尽管在微调期间已经见过这些事实的主题和对象在预训练数据集中很少共现，大型语言模型仍然难以回忆起这些事实。我们展示了即使扩大模型规模或进行微调，共现偏见仍然存在。因此，我们建议在去偏数据集上进行微调，通过过滤掉主题-对象共现计数高的偏见样本来减轻偏见。尽管去偏微调允许大型语言模型记忆训练集中的稀有事实，但在微调期间未见过的稀有事实的回忆效果并不明显。

    Large language models (LLMs) often make factually incorrect responses despite their success in various applications. In this paper, we hypothesize that relying heavily on simple co-occurrence statistics of the pre-training corpora is one of the main factors that cause factual errors. Our results reveal that LLMs are vulnerable to the co-occurrence bias, defined as preferring frequently co-occurred words over the correct answer. Consequently, LLMs struggle to recall facts whose subject and object rarely co-occur in the pre-training dataset although they are seen during finetuning. We show that co-occurrence bias remains despite scaling up model sizes or finetuning. Therefore, we suggest finetuning on a debiased dataset to mitigate the bias by filtering out biased samples whose subject-object co-occurrence count is high. Although debiased finetuning allows LLMs to memorize rare facts in the training set, it is not effective in recalling rare facts unseen during finetuning. Further resear
    
[^8]: 谁说的？社交媒体AI检测的基准测试

    Who Said That? Benchmarking Social Media AI Detection. (arXiv:2310.08240v1 [cs.CL])

    [http://arxiv.org/abs/2310.08240](http://arxiv.org/abs/2310.08240)

    本文介绍了SAID，一个用于评估AI文本检测模型在真实社交媒体平台上的能力的新基准测试。研究发现，基于知乎数据集，注释员可以以96.5%的准确率区分AI生成文本和人类生成文本。

    

    AI生成的文本在各种在线平台上广泛存在，既带来了变革的前景，也带来了与虚假信息和操纵相关的重大风险。为了应对这些挑战，本文介绍了SAID（社交媒体AI检测），这是一个新颖的基准测试，用于评估真实社交媒体平台上AI文本检测模型的能力。它包含来自知乎和Quora等热门社交媒体平台的真实AI生成文本。与现有的基准测试不同，SAID处理反映真实AI用户在互联网上使用的复杂策略的内容，这些策略可能逃避检测或获得可见性，提供了一个更加真实和具有挑战性的评估环境。基于知乎数据集的一个显著发现是，注释员可以以96.5%的平均准确率区分AI生成文本和人类生成文本。这一发现需要重新评估人类识别AI生成文本的能力。

    AI-generated text has proliferated across various online platforms, offering both transformative prospects and posing significant risks related to misinformation and manipulation. Addressing these challenges, this paper introduces SAID (Social media AI Detection), a novel benchmark developed to assess AI-text detection models' capabilities in real social media platforms. It incorporates real AI-generate text from popular social media platforms like Zhihu and Quora. Unlike existing benchmarks, SAID deals with content that reflects the sophisticated strategies employed by real AI users on the Internet which may evade detection or gain visibility, providing a more realistic and challenging evaluation landscape. A notable finding of our study, based on the Zhihu dataset, reveals that annotators can distinguish between AI-generated and human-generated texts with an average accuracy rate of 96.5%. This finding necessitates a re-evaluation of human capability in recognizing AI-generated text 
    
[^9]: 语言模型是通用的嵌入器

    Language Models are Universal Embedders. (arXiv:2310.08232v1 [cs.CL])

    [http://arxiv.org/abs/2310.08232](http://arxiv.org/abs/2310.08232)

    该论文证明了多语言预训练的Transformer解码器在有限英文数据微调后能够通用地进行嵌入，实现了统一嵌入模型的目标。

    

    在大型语言模型（LLM）革命中，嵌入是各种系统的关键组成部分。例如，它被用于为LLMs检索知识或记忆，构建内容过滤器等。由于这些情况涉及从英语到其他自然或编程语言，从检索到分类等各种情况，因此建立一个统一的嵌入模型而不是为每个场景专门建立一个是可取的。在这项工作中，我们迈出了朝这个目标迈出了初始的一步，证明了多语言（自然语言和编程语言）预训练的Transformer解码器在有限的英文数据微调后能够通用地进行嵌入。我们提供了全面的实践，并进行了彻底的评估。在英文MTEB上，我们的模型在不使用大量训练数据的情况下在不同的嵌入任务上达到了竞争性的性能。在其他基准测试中，例如多语言分类和代码搜索，我们的模型（没有任何监督）表现出与或甚至超过大量监督基线的可比性。

    In the large language model (LLM) revolution, embedding is a key component of various systems. For example, it is used to retrieve knowledge or memories for LLMs, to build content moderation filters, etc. As such cases span from English to other natural or programming languages, from retrieval to classification and beyond, it is desirable to build a unified embedding model rather than dedicated ones for each scenario. In this work, we make an initial step towards this goal, demonstrating that multiple languages (both natural and programming) pre-trained transformer decoders can embed universally when finetuned on limited English data. We provide a comprehensive practice with thorough evaluations. On English MTEB, our models achieve competitive performance on different embedding tasks by minimal training data. On other benchmarks, such as multilingual classification and code search, our models (without any supervision) perform comparably to, or even surpass heavily supervised baselines 
    
[^10]: 使用自监督表示法对语音和文本进行快速字错率估计

    Fast Word Error Rate Estimation Using Self-Supervised Representations For Speech And Text. (arXiv:2310.08225v1 [eess.AS])

    [http://arxiv.org/abs/2310.08225](http://arxiv.org/abs/2310.08225)

    本文介绍了一种使用自监督学习表示法（SSLR）的快速WER估计器（Fe-WER），在大数据场景下具有较高的计算效率和性能提升。

    

    自动语音识别（ASR）的质量通常通过字错率（WER）来衡量。WER估计是一项任务，旨在预测ASR系统的WER，给定一个语音说话和一个转录。在大量数据上训练先进的ASR系统的同时，这个任务越来越受到关注。在这种情况下，WER估计在许多场景中变得必要，例如选择具有未知转录质量的训练数据，或在没有地面真实转录的情况下估计ASR系统的测试性能。面对大量数据，WER估计仪的运算效率在实际应用中变得至关重要。然而，以前的研究通常未将其视为优先考虑的问题。本文介绍了一种使用自监督学习表示法（SSLR）的快速WER估计器（Fe-WER）。该估计器基于通过平均池聚合的SSLR构建。结果表明，相对于e-WER3基线，Fe-WER的性能提高了19.69％。

    The quality of automatic speech recognition (ASR) is typically measured by word error rate (WER). WER estimation is a task aiming to predict the WER of an ASR system, given a speech utterance and a transcription. This task has gained increasing attention while advanced ASR systems are trained on large amounts of data. In this case, WER estimation becomes necessary in many scenarios, for example, selecting training data with unknown transcription quality or estimating the testing performance of an ASR system without ground truth transcriptions. Facing large amounts of data, the computation efficiency of a WER estimator becomes essential in practical applications. However, previous works usually did not consider it as a priority. In this paper, a Fast WER estimator (Fe-WER) using self-supervised learning representation (SSLR) is introduced. The estimator is built upon SSLR aggregated by average pooling. The results show that Fe-WER outperformed the e-WER3 baseline relatively by 19.69% an
    
[^11]: SimCKP: 简单对比学习关键词短语表示

    SimCKP: Simple Contrastive Learning of Keyphrase Representations. (arXiv:2310.08221v1 [cs.CL])

    [http://arxiv.org/abs/2310.08221](http://arxiv.org/abs/2310.08221)

    SimCKP是一个简单的对比学习框架，通过学习上下文感知的短语级表示来提取关键词短语，并通过重新排序来调整生成的短语的分数。

    

    关键词生成（KG）旨在生成一组总结性词语或短语，给定一个源文档，而关键词提取（KE）旨在从文本中识别它们。由于在KE中搜索空间较小，通常将其与KG相结合，预测可能存在或不存在于相应文档中的关键词短语。然而，目前的统一方法采用序列标注和基于最大化的生成，主要在令牌级别上操作，不能很好地观察和评分关键词短语作为一个整体。在这项工作中，我们提出了SimCKP，一个简单的对比学习框架，包括两个阶段：1）提取器-生成器，通过对比学习上下文感知的短语级表示来提取关键词短语，同时生成不出现在文档中的关键词短语；2）重新排序器，通过将它们的表示与相应文档对齐，同样调整每个生成的短语的分数。在多个基准上进行实验证明

    Keyphrase generation (KG) aims to generate a set of summarizing words or phrases given a source document, while keyphrase extraction (KE) aims to identify them from the text. Because the search space is much smaller in KE, it is often combined with KG to predict keyphrases that may or may not exist in the corresponding document. However, current unified approaches adopt sequence labeling and maximization-based generation that primarily operate at a token level, falling short in observing and scoring keyphrases as a whole. In this work, we propose SimCKP, a simple contrastive learning framework that consists of two stages: 1) An extractor-generator that extracts keyphrases by learning context-aware phrase-level representations in a contrastive manner while also generating keyphrases that do not appear in the document; 2) A reranker that adapts scores for each generated phrase by likewise aligning their representations with the corresponding document. Experimental results on multiple ben
    
[^12]: 孟加拉语中的视觉问题生成

    Visual Question Generation in Bengali. (arXiv:2310.08187v1 [cs.CL])

    [http://arxiv.org/abs/2310.08187](http://arxiv.org/abs/2310.08187)

    本文提出了孟加拉语视觉问题生成任务，并开发了基于transformer的编码器-解码器架构，能够生成孟加拉语问题。通过引导型VQG模型，我们能够根据答案和问题类别生成问题。实验证明我们的模型在孟加拉语VQG任务上取得了最先进的性能。

    

    视觉问题生成（VQG）的任务是生成与给定图像相关的类似于人类问题的文本。由于数据集的可用性，现有的工作往往只关注资源丰富的语言，如英语。本文提出了首个孟加拉语视觉问题生成任务，并开发了一种基于transformer的编码器-解码器架构，在给定图像时可以生成孟加拉语问题。我们提出了多个模型变体-（i）仅图像：从图像中生成问题的基线模型，没有额外的信息，（ii）图像-类别和图像-答案-类别：引导型VQG，在此模型中，我们通过答案和期望问题的类别对模型进行约束以生成问题。这些模型在翻译后的VQAv2.0数据集上进行了训练和评估。我们的定量和定性结果建立了孟加拉语VQG任务的首个最先进模型，并证明我们的模型能够生成高质量的问题。

    The task of Visual Question Generation (VQG) is to generate human-like questions relevant to the given image. As VQG is an emerging research field, existing works tend to focus only on resource-rich language such as English due to the availability of datasets. In this paper, we propose the first Bengali Visual Question Generation task and develop a novel transformer-based encoder-decoder architecture that generates questions in Bengali when given an image. We propose multiple variants of models - (i) image-only: baseline model of generating questions from images without additional information, (ii) image-category and image-answer-category: guided VQG where we condition the model to generate questions based on the answer and the category of expected question. These models are trained and evaluated on the translated VQAv2.0 dataset. Our quantitative and qualitative results establish the first state of the art models for VQG task in Bengali and demonstrate that our models are capable of g
    
[^13]: EIPE-text: 针对长篇叙事文本生成的评估引导迭代计划提取方法

    EIPE-text: Evaluation-Guided Iterative Plan Extraction for Long-Form Narrative Text Generation. (arXiv:2310.08185v1 [cs.CL])

    [http://arxiv.org/abs/2310.08185](http://arxiv.org/abs/2310.08185)

    本文提出了EIPE-text方法用于长篇叙事文本生成，通过从语料库中提取计划并利用评估机制进行迭代改进，构建了更好的规划器。

    

    计划与写作是长篇叙事文本生成中常用的层次化方法，首先创建一个计划来指导叙事写作。遵循这种方法，一些研究仅仅依靠对大型语言模型进行提示进行计划，这经常产生次优的结果。在本文中，我们提出了一种新的框架，称为评估引导迭代计划提取方法（EIPE-text）用于长篇叙事文本生成，该方法从叙事语料库中提取计划并利用提取的计划构建更好的规划器。EIPE-text有三个阶段：计划提取、学习和推理。在计划提取阶段，它迭代地从叙事语料库中提取和改进计划，并构建一个计划语料库。我们提出了一种基于问答（QA）的评估机制，自动评估计划并生成详细的计划改进指示，以引导迭代改进。在学习阶段，我们通过微调构建一个更好的规划器。

    Plan-and-Write is a common hierarchical approach in long-form narrative text generation, which first creates a plan to guide the narrative writing. Following this approach, several studies rely on simply prompting large language models for planning, which often yields suboptimal results. In this paper, we propose a new framework called Evaluation-guided Iterative Plan Extraction for long-form narrative text generation (EIPE-text), which extracts plans from the corpus of narratives and utilizes the extracted plans to construct a better planner. EIPE-text has three stages: plan extraction, learning, and inference. In the plan extraction stage, it iteratively extracts and improves plans from the narrative corpus and constructs a plan corpus. We propose a question answer (QA) based evaluation mechanism to automatically evaluate the plans and generate detailed plan refinement instructions to guide the iterative improvement. In the learning stage, we build a better planner by fine-tuning wit
    
[^14]: 探索大型语言模型的认知知识结构：一种教育诊断评估方法

    Exploring the Cognitive Knowledge Structure of Large Language Models: An Educational Diagnostic Assessment Approach. (arXiv:2310.08172v1 [cs.CL])

    [http://arxiv.org/abs/2310.08172](http://arxiv.org/abs/2310.08172)

    本研究通过教育诊断评估方法，揭示了大型语言模型（LLMs）的知识结构，强调了研究LLMs的认知能力和不同认知模式的重要性。

    

    大型语言模型（LLMs）不仅在各种任务中表现出了卓越的性能，还展示了智能的火花。最近的研究集中在评估它们在人类考试中的能力，并揭示了它们在不同领域的出色能力。然而，关于LLMs整体知识结构的认知研究仍然缺乏。本文基于教育诊断评估方法，在MoocRadar上进行评估，这是一个根据布鲁姆分类法进行细致注释的人类测试数据集。我们的目标是揭示LLMs的知识结构，并对它们的认知能力进行深入理解。本研究强调了调查LLMs的知识和理解其认知模式的重要性。通过照亮模型的知识，研究人员可以更加明确和有效地促进LLMs的开发和利用。

    Large Language Models (LLMs) have not only exhibited exceptional performance across various tasks, but also demonstrated sparks of intelligence. Recent studies have focused on assessing their capabilities on human exams and revealed their impressive competence in different domains. However, cognitive research on the overall knowledge structure of LLMs is still lacking. In this paper, based on educational diagnostic assessment method, we conduct an evaluation using MoocRadar, a meticulously annotated human test dataset based on Bloom Taxonomy. We aim to reveal the knowledge structures of LLMs and gain insights of their cognitive capabilities. This research emphasizes the significance of investigating LLMs' knowledge and understanding the disparate cognitive patterns of LLMs. By shedding light on models' knowledge, researchers can advance development and utilization of LLMs in a more informed and effective manner.
    
[^15]: 简明程度估计（SLE）：一种基于学习的无参考度量方法用于句子简化

    Simplicity Level Estimate (SLE): A Learned Reference-Less Metric for Sentence Simplification. (arXiv:2310.08170v1 [cs.CL])

    [http://arxiv.org/abs/2310.08170](http://arxiv.org/abs/2310.08170)

    这个论文提出了一种基于学习的评估指标（SLE）用于句子简化，相比现有的指标，它更专注于简洁性，并在与人类判断的相关性方面表现出色。

    

    句子简化的自动评估仍然是一个具有挑战性的问题。大多数流行的评估方法需要多个高质量的参考文献，而这在简化过程中是不容易得到的，这使得在未知领域中测试性能变得困难。此外，大多数现有的评估方法将简单性与流畅性或意义保持等相关属性混淆。我们提出了一种新的学习评估指标（SLE），专注于简洁性，在与人类判断的相关性方面优于几乎所有现有的指标。

    Automatic evaluation for sentence simplification remains a challenging problem. Most popular evaluation metrics require multiple high-quality references -- something not readily available for simplification -- which makes it difficult to test performance on unseen domains. Furthermore, most existing metrics conflate simplicity with correlated attributes such as fluency or meaning preservation. We propose a new learned evaluation metric (SLE) which focuses on simplicity, outperforming almost all existing metrics in terms of correlation with human judgements.
    
[^16]: 使用大规模语言模型进行政策文件的多类别分类

    Multiclass Classification of Policy Documents with Large Language Models. (arXiv:2310.08167v1 [cs.CL])

    [http://arxiv.org/abs/2310.08167](http://arxiv.org/abs/2310.08167)

    这项工作使用GPT 3.5和GPT 4等大型语言模型对政策文件进行多类别分类，提出了三种使用场景，并估计了整体准确率在58％至83％之间。结果表明，完全依赖语言模型仍存在不足之处。

    

    将政策文件按照政策议题进行分类一直以来是政治科学和传播学领域的长期努力。为了实现社会科学研究目的的文本分类自动化处理，已经取得了显著的成果，但仍有很大的进展空间。在本研究中，我们测试了一种替代策略的预测性能，该策略需要比完全手动编码少得多的人工参与。我们使用OpenAI的GPT 3.5和GPT 4模型，这些模型是经过预训练并针对指令进行调整的大型语言模型，将国会议案和国会听证会分类为Comparative Agendas Project的21个主要政策议题。我们提出了三种使用场景，并估计了根据所采用的场景和GPT模型的整体准确率在58％至83％之间的范围。这三种情景分别旨在实现对人工干预的最小、中度和重要程度。总的来说，我们的结果指向了完全依赖GPT模型的不足之处。

    Classifying policy documents into policy issue topics has been a long-time effort in political science and communication disciplines. Efforts to automate text classification processes for social science research purposes have so far achieved remarkable results, but there is still a large room for progress. In this work, we test the prediction performance of an alternative strategy, which requires human involvement much less than full manual coding. We use the GPT 3.5 and GPT 4 models of the OpenAI, which are pre-trained instruction-tuned Large Language Models (LLM), to classify congressional bills and congressional hearings into Comparative Agendas Project's 21 major policy issue topics. We propose three use-case scenarios and estimate overall accuracies ranging from %58-83 depending on scenario and GPT model employed. The three scenarios aims at minimal, moderate, and major human interference, respectively. Overall, our results point towards the insufficiency of complete reliance on G
    
[^17]: Ziya-VL: 双语大规模视觉语言模型通过多任务指令调整

    Ziya-VL: Bilingual Large Vision-Language Model via Multi-Task Instruction Tuning. (arXiv:2310.08166v1 [cs.CL])

    [http://arxiv.org/abs/2310.08166](http://arxiv.org/abs/2310.08166)

    本论文介绍了Ziya-VL系列，这是一组双语大规模视觉语言模型，旨在将视觉语义融入语言模型以进行多模态对话。模型采用了查询变换器和优化方案，如指令调整和多阶段训练，以实现视觉语言对齐。

    

    最近的进展扩大了大型语言模型（LLMs）在零射击图像到文本生成和理解方面的能力，通过整合多模输入。然而，这样的成功通常局限于英语场景，原因是缺乏大规模和高质量的非英语多模资源，使得在其他语言中建立竞争对手变得极其困难。在本文中，我们介绍了Ziya-VL系列，这是一组双语大规模视觉语言模型（LVLMs），旨在将视觉语义融入LLM以进行多模态对话。我们的模型由Ziya-VL-Base和Ziya-VL-Chat组成，采用BLIP-2中的查询变换器，并进一步探索指令调整、多阶段训练和低秩适应模块等优化方案的辅助作用，以实现视觉语言对齐。此外，我们刺激GPT-4在多模态场景中的理解能力，将我们收集的英文图像文本数据集翻译成...

    Recent advancements enlarge the capabilities of large language models (LLMs) in zero-shot image-to-text generation and understanding by integrating multi-modal inputs. However, such success is typically limited to English scenarios due to the lack of large-scale and high-quality non-English multi-modal resources, making it extremely difficult to establish competitive counterparts in other languages. In this paper, we introduce the Ziya-VL series, a set of bilingual large-scale vision-language models (LVLMs) designed to incorporate visual semantics into LLM for multi-modal dialogue. Composed of Ziya-VL-Base and Ziya-VL-Chat, our models adopt the Querying Transformer from BLIP-2, further exploring the assistance of optimization schemes such as instruction tuning, multi-stage training and low-rank adaptation module for visual-language alignment. In addition, we stimulate the understanding ability of GPT-4 in multi-modal scenarios, translating our gathered English image-text datasets into 
    
[^18]: 带有标记符号的自回归Transformer的上下文压缩

    Context Compression for Auto-regressive Transformers with Sentinel Tokens. (arXiv:2310.08152v1 [cs.CL])

    [http://arxiv.org/abs/2310.08152](http://arxiv.org/abs/2310.08152)

    本论文提出了一种带有标记符号的自回归Transformer的上下文压缩方法，该方法通过将指定范围内的中间激活逐步压缩为紧凑形式，从而减少内存和计算成本。实验证明，在语言建模和文档生成方面，该方法相比稀疏注意力基线具有更好的流畅度、N-gram匹配和语义相似性。

    

    注意力模块的二次复杂性使其在生成过程中逐渐成为基于Transformer的LLM的主要计算部分。此外，处理长输入时产生的过多的键值缓存也会在内存占用和推理延迟方面带来严重问题。在这项工作中，我们提出了一种即插即用的方法，能够将指定范围内的中间激活逐步压缩为紧凑形式，从而在处理后续上下文时减少内存和计算成本。在领域内语言建模和零样本开放文档生成的实验中，我们的方法在流畅度、N-gram匹配和语义相似性方面优于稀疏注意力基线。最后，我们全面评估了上下文压缩对系统改进的益处。代码可在https://github.com/DRSY/KV_Compression获得。

    The quadratic complexity of the attention module makes it gradually become the bulk of compute in Transformer-based LLMs during generation. Moreover, the excessive key-value cache that arises when dealing with long inputs also brings severe issues on memory footprint and inference latency. In this work, we propose a plug-and-play approach that is able to incrementally compress the intermediate activation of a specified span of tokens into compact ones, thereby reducing both memory and computational cost when processing subsequent context. Experiments on both in-domain language modeling and zero-shot open-ended document generation demonstrate the advantage of our approach over sparse attention baselines in terms of fluency, n-gram matching, and semantic similarity. At last, we comprehensively profile the benefit of context compression on improving the system throughout. Code is available at https://github.com/DRSY/KV_Compression.
    
[^19]: 对于自动生成的训练数据中音素持续时间变异性与自动语音识别相关性的研究

    On the Relevance of Phoneme Duration Variability of Synthesized Training Data for Automatic Speech Recognition. (arXiv:2310.08132v1 [cs.CL])

    [http://arxiv.org/abs/2310.08132](http://arxiv.org/abs/2310.08132)

    本研究探讨了自动生成的训练数据中音素持续时间变异性与自动语音识别的相关性，并提出了一种基于随机游走的算法来改善合成数据的质量，从而改进了半监督设置下的ASR系统。

    

    通过使用文本转语音(TTS)系统生成的合成数据可以改善低资源或领域不匹配任务中的自动语音识别(ASR)系统。已经证明，TTS生成的输出仍然不具备与真实数据相同的质量。在本研究中，我们关注合成数据的时间结构及其与ASR训练的关系。通过使用一种新的oracle设置，我们展示了非自回归(NAR) TTS中持续时间建模对合成数据质量的退化程度的影响。我们使用两种常见的对齐方法，即隐马尔可夫高斯混合模型(HMM-GMM)对齐器和神经连结时序分类(CTC)对齐器，来获取参考音素持续时间。通过一个基于随机游走的简单算法，我们将TTS系统的音素持续时间分布移动到真实持续时间附近，从而改进了半监督设置下使用合成数据的ASR系统。

    Synthetic data generated by text-to-speech (TTS) systems can be used to improve automatic speech recognition (ASR) systems in low-resource or domain mismatch tasks. It has been shown that TTS-generated outputs still do not have the same qualities as real data. In this work we focus on the temporal structure of synthetic data and its relation to ASR training. By using a novel oracle setup we show how much the degradation of synthetic data quality is influenced by duration modeling in non-autoregressive (NAR) TTS. To get reference phoneme durations we use two common alignment methods, a hidden Markov Gaussian-mixture model (HMM-GMM) aligner and a neural connectionist temporal classification (CTC) aligner. Using a simple algorithm based on random walks we shift phoneme duration distributions of the TTS system closer to real durations, resulting in an improvement of an ASR system using synthetic data in a semi-supervised setting.
    
[^20]: 通过各向同性和近端搜索实现细粒度对话解码

    Fine-grained Conversational Decoding via Isotropic and Proximal Search. (arXiv:2310.08130v1 [cs.CL])

    [http://arxiv.org/abs/2310.08130](http://arxiv.org/abs/2310.08130)

    本论文提出了一种细粒度的对话解码方法，通过各向同性和近端搜索（IPS）生成信息集中的语义回应，并在对话领域的评估中取得了优于现有方法的效果。

    

    通常采用通用的文本解码方法来进行对话回应生成。虽然采用了对话特定的编码方法可以提高生成的回应质量，但对话解码方法仍然未被充分探索。受到wu2023learning的启发，认为好的对话特征空间应遵循局部性和各向同性规则，我们提出了一种细粒度的对话解码方法，称为各向同性和近端搜索（IPS）。我们的方法旨在生成信息集中的语义回应，同时保持对上下文的信息量和区分度。实验证明，我们的方法在对话领域中的自动评估和人工评估指标上优于现有的解码策略。更深入的分析进一步证实了我们方法的有效性。

    General-purpose text decoding approaches are usually adopted for dialogue response generation. Although the quality of the generated responses can be improved with dialogue-specific encoding methods, conversational decoding methods are still under-explored. Inspired by \citet{wu2023learning} that a good dialogue feature space should follow the rules of locality and isotropy, we present a fine-grained conversational decoding method, termed \textit{isotropic and proximal search (IPS)}. Our method is designed to generate the semantic-concentrated response, while still maintaining informativeness and discrimination against the context. Experiments show that our approach outperforms existing decoding strategies in the dialogue field across both automatic and human evaluation metrics. More in-depth analyses further confirm the effectiveness of our approach.
    
[^21]: 谁写的和为什么写的？推动大语言模型进行作者验证。

    Who Wrote it and Why? Prompting Large-Language Models for Authorship Verification. (arXiv:2310.08123v1 [cs.CL])

    [http://arxiv.org/abs/2310.08123](http://arxiv.org/abs/2310.08123)

    本文提出了PromptAV，一种利用大语言模型（LLMs）进行作者验证的新技术，通过提供逐步的风格测量解释提示，解决了现有AV技术的限制，具有更好的性能和可解释性。

    

    作者验证（AV）是自然语言处理（NLP）和计算语言学中的一项基本任务，其应用领域包括法庭分析、抄袭检测和识别欺骗性内容。现有的AV技术，包括传统的风格测量和深度学习方法，在数据需求和解释能力方面存在局限性。为了解决这些限制，本文提出了PromptAV，一种利用大语言模型（LLMs）进行AV的新技术，通过提供逐步的风格测量解释提示。PromptAV优于最先进的基线方法，在有限的训练数据下运行效果显著，并通过直观的解释增强了可解释性，展示了其作为AV任务的有效和可解释解决方案的潜力。

    Authorship verification (AV) is a fundamental task in natural language processing (NLP) and computational linguistics, with applications in forensic analysis, plagiarism detection, and identification of deceptive content. Existing AV techniques, including traditional stylometric and deep learning approaches, face limitations in terms of data requirements and lack of explainability. To address these limitations, this paper proposes PromptAV, a novel technique that leverages Large-Language Models (LLMs) for AV by providing step-by-step stylometric explanation prompts. PromptAV outperforms state-of-the-art baselines, operates effectively with limited training data, and enhances interpretability through intuitive explanations, showcasing its potential as an effective and interpretable solution for the AV task.
    
[^22]: 针对口吃的语音、乐器、未知语言和以文本描述的声音的声音转换

    Voice Conversion for Stuttered Speech, Instruments, Unseen Languages and Textually Described Voices. (arXiv:2310.08104v1 [eess.AS])

    [http://arxiv.org/abs/2310.08104](http://arxiv.org/abs/2310.08104)

    这项研究调查了最新的声音转换模型在口吃、跨语言、乐器和文本描述声音等非标准任务上的表现。研究发现，在口吃和跨语言声音转换方面，kNN-VC方法保持了较高的性能，而乐器和文本到声音的转换则有更复杂的结果。

    

    声音转换旨在使用目标讲话者的录音将源语音转换为目标声音。较新的模型产生了越来越逼真的输出。但是，当模型接收非标准数据时，例如来自具有语言障碍的用户的语音，会发生什么情况呢？我们研究了最新的声音转换模型在非标准下游声音转换任务上的表现。我们使用了一种简单而健壮的方法，称为k最近邻声音转换（kNN-VC）。我们研究了四个非标准的应用：口吃的声音转换，跨语言的声音转换，乐器的声音转换和文本到声音的转换。后者涉及将声音转换为通过文本描述指定的目标声音，例如“一个年轻男子的尖声”。与已建立的基准相比，我们发现kNN-VC在口吃和跨语言声音转换方面保持了较高的性能。对于乐器和文本到声音的转换而言，结果更加复杂。

    Voice conversion aims to convert source speech into a target voice using recordings of the target speaker as a reference. Newer models are producing increasingly realistic output. But what happens when models are fed with non-standard data, such as speech from a user with a speech impairment? We investigate how a recent voice conversion model performs on non-standard downstream voice conversion tasks. We use a simple but robust approach called k-nearest neighbors voice conversion (kNN-VC). We look at four non-standard applications: stuttered voice conversion, cross-lingual voice conversion, musical instrument conversion, and text-to-voice conversion. The latter involves converting to a target voice specified through a text description, e.g. "a young man with a high-pitched voice". Compared to an established baseline, we find that kNN-VC retains high performance in stuttered and cross-lingual voice conversion. Results are more mixed for the musical instrument and text-to-voice conversio
    
[^23]: QASiNa: 使用《先知传记》的宗教领域问答系统

    QASiNa: Religious Domain Question Answering using Sirah Nabawiyah. (arXiv:2310.08102v1 [cs.CL])

    [http://arxiv.org/abs/2310.08102](http://arxiv.org/abs/2310.08102)

    本文提出了一种使用《先知传记》的宗教领域问答系统(QASiNa)，旨在对大型语言模型在宗教领域的应用进行评估。

    

    当前，问答（QA）任务受到重视，尤其是随着大型语言模型（LLM）如Chat GPT的发展。LLM可以应用于各个领域，但将其应用于伊斯兰领域时，与信息传递原则相矛盾。在伊斯兰教中，我们严格规定信息来源和谁可以对该来源进行解释或注释。LLM的回答生成方法与注释概念类似，LLM既不是伊斯兰专家，也不是人类，这在伊斯兰教中是不允许的。印度尼西亚是世界上信奉伊斯兰教人口最多的国家。在LLM的高影响下，我们需要对宗教领域的LLM进行评估。目前，只有少数宗教问答数据集可用，其中没有一个使用尤尼语的《先知传记》。在本文中，我们提出了基于《先知传记》的问答系统(QASiNa)。

    Nowadays, Question Answering (QA) tasks receive significant research focus, particularly with the development of Large Language Model (LLM) such as Chat GPT [1]. LLM can be applied to various domains, but it contradicts the principles of information transmission when applied to the Islamic domain. In Islam we strictly regulates the sources of information and who can give interpretations or tafseer for that sources [2]. The approach used by LLM to generate answers based on its own interpretation is similar to the concept of tafseer, LLM is neither an Islamic expert nor a human which is not permitted in Islam. Indonesia is the country with the largest Islamic believer population in the world [3]. With the high influence of LLM, we need to make evaluation of LLM in religious domain. Currently, there is only few religious QA dataset available and none of them using Sirah Nabawiyah especially in Indonesian Language. In this paper, we propose the Question Answering Sirah Nabawiyah (QASiNa) d
    
[^24]: Promptor:一种用于智能文本输入技术的对话式自主提示生成代理

    Promptor: A Conversational and Autonomous Prompt Generation Agent for Intelligent Text Entry Techniques. (arXiv:2310.08101v1 [cs.CL])

    [http://arxiv.org/abs/2310.08101](http://arxiv.org/abs/2310.08101)

    本论文介绍了Promptor，一个用于智能文本输入技术的对话式自主提示生成代理。利用大型语言模型的上下文学习能力，可以克服数据收集和模型微调的挑战。我们通过以GPT-3.5为例的实验证明，仅通过提示即可超过GPT-2支持的系统，并且可与经过精调的GPT-3.5模型相媲美。

    

    在我们日常数字交互中，文本输入是一项重要的任务。为了使文本输入更有效、高效和流畅，已经开发出了许多智能功能，包括句子预测和用户个性化。然而，随着基于深度学习的语言模型成为这些高级功能的常规，数据收集和模型微调的必要性也增加了。利用GPT-3.5等大型语言模型的上下文学习能力可以减轻这些挑战。这一独特的特性允许语言模型通过提示获得新的技能，消除了数据收集和微调的需要。因此，大型语言模型可以学习各种文本预测技术。我们最初展示了仅通过提示GPT-3.5即可超过GPT-2支持的系统，并且与经过精调的GPT-3.5模型相当，在后两种方法需要昂贵的数据集的情况下。

    Text entry is an essential task in our day-to-day digital interactions. Numerous intelligent features have been developed to streamline this process, making text entry more effective, efficient, and fluid. These improvements include sentence prediction and user personalization. However, as deep learning-based language models become the norm for these advanced features, the necessity for data collection and model fine-tuning increases. These challenges can be mitigated by harnessing the in-context learning capability of large language models such as GPT-3.5. This unique feature allows the language model to acquire new skills through prompts, eliminating the need for data collection and fine-tuning. Consequently, large language models can learn various text prediction techniques. We initially showed that, for a sentence prediction task, merely prompting GPT-3.5 surpassed a GPT-2 backed system and is comparable with a fine-tuned GPT-3.5 model, with the latter two methods requiring costly 
    
[^25]: ClimateNLP: 使用自然语言处理分析公众对气候变化的情感态度

    ClimateNLP: Analyzing Public Sentiment Towards Climate Change Using Natural Language Processing. (arXiv:2310.08099v1 [cs.CL])

    [http://arxiv.org/abs/2310.08099](http://arxiv.org/abs/2310.08099)

    本研究利用自然语言处理分析社交媒体上关于气候变化的推文情感态度，通过使用ClimateBERT模型量化情感，从而获得有关公众对气候变化的观点和反馈。

    

    气候变化对人类健康的影响带来了前所未有的挑战。除非采取基于确凿证据的积极措施，否则这些威胁很可能会升级，并继续威胁人类福祉。信息和通信技术的不断发展已经促进了社交媒体平台的广泛可用性和利用率。个人利用Twitter和Facebook等平台表达自己对各种主题的意见、想法和评论，包括紧迫的气候变化问题。社交媒体上与气候变化相关内容的激增需要进行全面分析以获得有意义的洞察。本论文利用自然语言处理技术分析气候变化话语，并量化与气候变化相关的推文的情感。我们使用ClimateBERT，这是一个专门针对气候变化领域进行了微调的预训练模型。目标是识别情感态度。

    Climate change's impact on human health poses unprecedented and diverse challenges. Unless proactive measures based on solid evidence are implemented, these threats will likely escalate and continue to endanger human well-being. The escalating advancements in information and communication technologies have facilitated the widespread availability and utilization of social media platforms. Individuals utilize platforms such as Twitter and Facebook to express their opinions, thoughts, and critiques on diverse subjects, encompassing the pressing issue of climate change. The proliferation of climate change-related content on social media necessitates comprehensive analysis to glean meaningful insights. This paper employs natural language processing (NLP) techniques to analyze climate change discourse and quantify the sentiment of climate change-related tweets. We use ClimateBERT, a pretrained model fine-tuned specifically for the climate change domain. The objective is to discern the sentim
    
[^26]: 以问答方式翻译印尼语的低资源标题党处理

    Low-Resource Clickbait Spoiling for Indonesian via Question Answering. (arXiv:2310.08085v1 [cs.CL])

    [http://arxiv.org/abs/2310.08085](http://arxiv.org/abs/2310.08085)

    本论文介绍了一项以问答方式翻译印尼语低资源标题党处理的任务，贡献包括构建手动标注的印尼语标题党处理语料库，并评估了跨语言零射击问答模型的应用。实验结果表明，XLM-RoBERTa（大）模型在短语和段落标题党处理方面表现优异，而mDeBERTa（基础）模型在多部分标题党处理中表现最佳。

    

    标题党处理旨在生成一个短文本，以满足标题党帖子引起的好奇心。由于这是一个新引入的任务，目前只有英文数据集可用。我们的贡献包括在印尼语中构建手动标注的标题党处理语料库，并评估使用跨语言零射击问答模型来处理印尼语等低资源语言的标题党处理。我们利用多语言语言模型的选择。实验结果表明，XLM-RoBERTa（大）模型在短语和段落标题党处理方面优于其他模型，而mDeBERTa（基础）模型在多部分标题党处理中优于其他模型。

    Clickbait spoiling aims to generate a short text to satisfy the curiosity induced by a clickbait post. As it is a newly introduced task, the dataset is only available in English so far. Our contributions include the construction of manually labeled clickbait spoiling corpus in Indonesian and an evaluation on using cross-lingual zero-shot question answering-based models to tackle clikcbait spoiling for low-resource language like Indonesian. We utilize selection of multilingual language models. The experimental results suggest that XLM-RoBERTa (large) model outperforms other models for phrase and passage spoilers, meanwhile, mDeBERTa (base) model outperforms other models for multipart spoilers.
    
[^27]: 是否进行词元化：用于跨语言转换的文本表示的比较研究

    To token or not to token: A Comparative Study of Text Representations for Cross-Lingual Transfer. (arXiv:2310.08078v1 [cs.CL])

    [http://arxiv.org/abs/2310.08078](http://arxiv.org/abs/2310.08078)

    本文进行了针对跨语言转换的文本表示方案的比较研究，发现图像模型在相关且脚本相似的语言之间的转换中表现优秀，而基于分割的模型在偏向单词含义的任务中表现更好。

    

    在资源匮乏的跨语言转换中，选择适当的词元化方案往往是一个瓶颈。为了理解文本表示选择的下游影响，我们对具有不同文本表示模态的语言模型进行了比较分析，包括2个基于分割的模型（BERT，mBERT），1个基于图像的模型（PIXEL），和1个字符级模型（CANINE）。首先，我们提出了一个评分语言商数（LQ）指标，能够提供零射击和少射击评估的加权表示。利用这个指标，我们在三个任务（词性标注，依存句法分析和命名实体识别）上进行了包含19个源语言和133个目标语言的实验。我们的分析表明，当语言之间关系密切且具有相似的视觉脚本时，基于图像的模型在跨语言转换中表现出色。然而，对于偏向于单词含义的任务（词性标注，命名实体识别），基于分割的模型证明是更好的选择。

    Choosing an appropriate tokenization scheme is often a bottleneck in low-resource cross-lingual transfer. To understand the downstream implications of text representation choices, we perform a comparative analysis on language models having diverse text representation modalities including 2 segmentation-based models (\texttt{BERT}, \texttt{mBERT}), 1 image-based model (\texttt{PIXEL}), and 1 character-level model (\texttt{CANINE}). First, we propose a scoring Language Quotient (LQ) metric capable of providing a weighted representation of both zero-shot and few-shot evaluation combined. Utilizing this metric, we perform experiments comprising 19 source languages and 133 target languages on three tasks (POS tagging, Dependency parsing, and NER). Our analysis reveals that image-based models excel in cross-lingual transfer when languages are closely related and share visually similar scripts. However, for tasks biased toward word meaning (POS, NER), segmentation-based models prove to be sup
    
[^28]: 重新思考代码搜索中的负样本对

    Rethinking Negative Pairs in Code Search. (arXiv:2310.08069v1 [cs.SE])

    [http://arxiv.org/abs/2310.08069](http://arxiv.org/abs/2310.08069)

    本文提出了一种简单而有效的Soft-InfoNCE损失函数，通过在InfoNCE中插入权重项来解决代码搜索中负样本的问题，包括大型代码库中的虚假负样本和未能区分负样本的潜在相关性。

    

    最近，对比学习成为细化代码搜索模型以提高软件开发效率和效果的关键组成部分。它将正样本代码片段聚集在一起，同时将与搜索查询不相关的负样本推开。在对比学习中，InfoNCE是最常用的损失函数，因为它具有更好的性能。然而，InfoNCE负样本存在以下问题可能会损害其表示学习的效果：1）由于重复，大型代码库中存在虚假负样本。2）未能明确区分负样本的潜在相关性。例如，对于快速排序算法查询，冒泡排序算法示例要比文件保存函数“更负面”。在本文中，我们通过提出一种简单而有效的Soft-InfoNCE损失来解决上述问题。在我们提出的损失函数中，我们采用了三种方法来估计权重...

    Recently, contrastive learning has become a key component in fine-tuning code search models for software development efficiency and effectiveness. It pulls together positive code snippets while pushing negative samples away given search queries. Among contrastive learning, InfoNCE is the most widely used loss function due to its better performance. However, the following problems in negative samples of InfoNCE may deteriorate its representation learning: 1) The existence of false negative samples in large code corpora due to duplications. 2). The failure to explicitly differentiate between the potential relevance of negative samples. As an example, a bubble sorting algorithm example is less ``negative'' than a file saving function for the quick sorting algorithm query. In this paper, we tackle the above problems by proposing a simple yet effective Soft-InfoNCE loss that inserts weight terms into InfoNCE. In our proposed loss function, we apply three methods to estimate the weights of n
    
[^29]: QLLM: 大规模语言模型的准确高效低位宽量化

    QLLM: Accurate and Efficient Low-Bitwidth Quantization for Large Language Models. (arXiv:2310.08041v1 [cs.CL])

    [http://arxiv.org/abs/2310.08041](http://arxiv.org/abs/2310.08041)

    QLLM是一种为大规模语言模型设计的准确高效的低位宽后训练量化方法，通过引入自适应通道重组技术，将离群值的大小重新分配给其他通道，从而减轻它们对量化范围的影响。

    

    大规模语言模型在自然语言处理领域表现出色，但由于其所需资源过大，限制了其广泛应用。虽然量化感知训练（Quantization-Aware Training，QAT）提供了一种解决方案，但它的训练成本过高，因此后训练量化（Post-Training Quantization，PTQ）成为大规模语言模型更实际的方法。在现有研究中，特定通道中的激活离群值被认为是导致后训练量化准确性下降的瓶颈。本文提出了QLLM，一种为大规模语言模型设计的准确高效的低位宽后训练量化方法。QLLM引入了一种自适应通道重组技术，将离群值的大小重新分配给其他通道，从而减轻它们对量化范围的影响。具体来说，通过通道拆分和通道组装，在保证低位宽的情况下将离群通道分解成多个子通道。

    Large Language Models (LLMs) excel in NLP, but their demands hinder their widespread deployment. While Quantization-Aware Training (QAT) offers a solution, its extensive training costs make Post-Training Quantization (PTQ) a more practical approach for LLMs. In existing studies, activation outliers in particular channels are identified as the bottleneck to PTQ accuracy. They propose to transform the magnitudes from activations to weights, which however offers limited alleviation or suffers from unstable gradients, resulting in a severe performance drop at low-bitwidth. In this paper, we propose QLLM, an accurate and efficient low-bitwidth PTQ method designed for LLMs. QLLM introduces an adaptive channel reassembly technique that reallocates the magnitude of outliers to other channels, thereby mitigating their impact on the quantization range. This is achieved by channel disassembly and channel assembly, which first breaks down the outlier channels into several sub-channels to ensure a 
    
[^30]: 探索用于多模态区分程度检测的大型语言模型

    Exploring Large Language Models for Multi-Modal Out-of-Distribution Detection. (arXiv:2310.08027v1 [cs.CL])

    [http://arxiv.org/abs/2310.08027](http://arxiv.org/abs/2310.08027)

    本论文提出了一种利用大型语言模型以及图像上下文信息来增强多模态区分程度检测性能的方法。通过了解大型语言模型的生成特征和视觉对象，我们可以提高区分程度检测的准确度和可靠性。

    

    区分程度检测是可靠和可信任的机器学习的关键。最近的多模态区分程度检测利用来自内分布类别名称的文本信息进行视觉区分程度检测，但目前忽视了内分布类别的丰富上下文信息。大型语言模型(LLM)对世界知识进行编码，并可以生成每个类别的描述性特征。不加区分地使用这些知识会对区分程度检测造成灾难性损害，这是我们分析所观察到的。本文提出利用世界知识增强区分程度检测性能的方法，通过从LLM中选择性生成来实现。具体而言，我们引入了一种基于一致性的不确定性校准方法，来估计每个生成的置信度得分。我们进一步从每个图像中提取视觉对象，充分利用上述的世界知识。广泛的实验表明，我们的方法在区分程度检测方面是一致的。

    Out-of-distribution (OOD) detection is essential for reliable and trustworthy machine learning. Recent multi-modal OOD detection leverages textual information from in-distribution (ID) class names for visual OOD detection, yet it currently neglects the rich contextual information of ID classes. Large language models (LLMs) encode a wealth of world knowledge and can be prompted to generate descriptive features for each class. Indiscriminately using such knowledge causes catastrophic damage to OOD detection due to LLMs' hallucinations, as is observed by our analysis. In this paper, we propose to apply world knowledge to enhance OOD detection performance through selective generation from LLMs. Specifically, we introduce a consistency-based uncertainty calibration method to estimate the confidence score of each generation. We further extract visual objects from each image to fully capitalize on the aforementioned world knowledge. Extensive experiments demonstrate that our method consistent
    
[^31]: 利用大型语言模型的共情回应生成能力用于在线心理健康咨询支持

    Harnessing Large Language Models' Empathetic Response Generation Capabilities for Online Mental Health Counselling Support. (arXiv:2310.08017v1 [cs.CL])

    [http://arxiv.org/abs/2310.08017](http://arxiv.org/abs/2310.08017)

    本研究探讨了大型语言模型（LLMs）在模拟心理健康咨询对话中生成共情回应的能力。通过与传统回应生成对话系统和人工回应的比较，研究发现LLMs在这一领域具有潜力。

    

    大型语言模型（LLMs）在各种信息获取和推理任务中表现出色。这些计算系统驱动着最先进的对话系统，如ChatGPT和Bard。它们在满足心理健康护理增长需求方面也具有巨大的潜力，尽管相对未被探索。因此，本研究旨在研究LLMs在模拟心理健康咨询环境中生成共情回应的能力。我们选择了五个LLMs：Generative Pre-training（GPT）的3.5版和4版、Vicuna FastChat-T5、Pathways Language Model（PaLM）的2版和Falcon-7B-Instruct。根据一个简单的指令提示，这些模型对来自EmpatheticDialogues（ED）数据集的话语进行回应。使用三个与共情相关的度量指标，我们将其回应与在ED数据集上进行微调的传统回应生成对话系统以及由人类生成的回应进行了比较。

    Large Language Models (LLMs) have demonstrated remarkable performance across various information-seeking and reasoning tasks. These computational systems drive state-of-the-art dialogue systems, such as ChatGPT and Bard. They also carry substantial promise in meeting the growing demands of mental health care, albeit relatively unexplored. As such, this study sought to examine LLMs' capability to generate empathetic responses in conversations that emulate those in a mental health counselling setting. We selected five LLMs: version 3.5 and version 4 of the Generative Pre-training (GPT), Vicuna FastChat-T5, Pathways Language Model (PaLM) version 2, and Falcon-7B-Instruct. Based on a simple instructional prompt, these models responded to utterances derived from the EmpatheticDialogues (ED) dataset. Using three empathy-related metrics, we compared their responses to those from traditional response generation dialogue systems, which were fine-tuned on the ED dataset, along with human-generat
    
[^32]: 思考、行动和问：开放世界互动个性化机器人导航

    Think, Act, and Ask: Open-World Interactive Personalized Robot Navigation. (arXiv:2310.07968v1 [cs.RO])

    [http://arxiv.org/abs/2310.07968](http://arxiv.org/abs/2310.07968)

    这项研究引入了零射交互个性化对象导航（ZIPON），通过使用大型语言模型（LLM）和用户反馈，解决了在未知环境中导航到个性化目标对象的问题。

    

    零射命令对象导航（ZSON）使代理能够在未知环境中导航到开放词汇对象。现有的ZSON工作主要集中在遵循个别指令以寻找通用对象类，忽略了自然语言交互的利用和识别用户特定对象的复杂性。为了解决这些局限性，我们引入了零射交互个性化对象导航（ZIPON），其中机器人需要在与用户对话的同时导航到个性化目标对象。为了解决ZIPON问题，我们提出了一种新的框架称为开放世界互动个性化导航（ORION），该框架使用大型语言模型（LLM）进行序列决策，以操作不同的感知、导航和通信模块。实验结果表明，能够利用用户反馈的互动代理的性能有了显著改进。然而，在任务完成和用户满意度之间取得良好的平衡仍然具有挑战性。

    Zero-Shot Object Navigation (ZSON) enables agents to navigate towards open-vocabulary objects in unknown environments. The existing works of ZSON mainly focus on following individual instructions to find generic object classes, neglecting the utilization of natural language interaction and the complexities of identifying user-specific objects. To address these limitations, we introduce Zero-shot Interactive Personalized Object Navigation (ZIPON), where robots need to navigate to personalized goal objects while engaging in conversations with users. To solve ZIPON, we propose a new framework termed Open-woRld Interactive persOnalized Navigation (ORION), which uses Large Language Models (LLMs) to make sequential decisions to manipulate different modules for perception, navigation and communication. Experimental results show that the performance of interactive agents that can leverage user feedback exhibits significant improvement. However, obtaining a good balance between task completion 
    
[^33]: 从其他语言转译的专有名词的拼写变体聚类

    Clustering of Spell Variations for Proper Nouns Transliterated from the other languages. (arXiv:2310.07962v1 [cs.CL])

    [http://arxiv.org/abs/2310.07962](http://arxiv.org/abs/2310.07962)

    本研究提出了一种使用机器学习和数学相似性方程对来自不同语言的专有名词的拼写变体进行聚类的方法，以解决NLP中由于翻译和转写不一致而引起的拼写变化问题。

    

    处理和操作文本数据时，非均匀性是一个突出的问题。由于方言和语言的变化，翻译的质量较低。这在使用NLP处理文本数据时会产生一个独特的问题，即不一致的翻译和转写引发的拼写变化。这个问题还可能因为将印度语中的专有名词转化为英文等效词的各种方式而导致人为错误。将来自印度语言的专有名词翻译成英文可能很复杂，因为一些专有名词也被用作普通名词，可能被直接理解。需要地址、名称和其他专有名词的NLP应用经常遇到这个问题。我们提出了一种使用机器学习技术和数学相似性方程对这些专有名词的拼写变体进行聚类的方法。我们旨在使用亲和传播来确定标记之间的相对相似度。

    One of the prominent problems with processing and operating on text data is the non uniformity of it. Due to the change in the dialects and languages, the caliber of translation is low. This creates a unique problem while using NLP in text data; which is the spell variation arising from the inconsistent translations and transliterations. This problem can also be further aggravated by the human error arising from the various ways to write a Proper Noun from an Indian language into its English equivalent. Translating proper nouns originating from Indian languages can be complicated as some proper nouns are also used as common nouns which might be taken literally. Applications of NLP that require addresses, names and other proper nouns face this problem frequently. We propose a method to cluster these spell variations for proper nouns using ML techniques and mathematical similarity equations. We aimed to use Affinity Propagation to determine relative similarity between the tokens. The res
    
[^34]: 一种新的自动形式化方法

    A New Approach Towards Autoformalization. (arXiv:2310.07957v1 [cs.CL])

    [http://arxiv.org/abs/2310.07957](http://arxiv.org/abs/2310.07957)

    该论文提出了一种新的方法来应对研究水平的数学自动形式化任务，通过将任务分解成更容易处理的子任务，包括未链接形式化、实体链接和类型调整。此外，还提出了一个用于未链接形式化的基准数据集 arXiv2Formal。

    

    验证数学证明是困难的，但可以通过计算机的辅助实现自动化。自动形式化是将自然语言数学自动转化为可以由程序验证的形式语言的任务。这是一项具有挑战性的任务，尤其对于研究论文中的高级数学来说。研究论文中的数学需要大量的背景和上下文。本文中，我们提出了一种应对研究水平数学自动形式化的方法，将任务分解为更易于处理的子任务：未链接形式化（包含未链接的定义和定理的形式化）、实体链接（链接到正确的定理和定义）以及调整类型以通过类型检查器。此外，我们还提出了arXiv2Formal，一个用于未链接形式化的基准数据集，其中包括从arXiv.org的论文中抽取的50个定理在Lean定理证明器中进行形式化。我们欢迎任何贡献。

    Verifying mathematical proofs is difficult, but can be automated with the assistance of a computer. Autoformalization is the task of automatically translating natural language mathematics into a formal language that can be verified by a program. This is a challenging task, and especially for higher-level mathematics found in research papers. Research paper mathematics requires large amounts of background and context. In this paper, we propose an avenue towards tackling autoformalization for research-level mathematics, by breaking the task into easier and more approachable subtasks: unlinked formalization (formalization with unlinked definitions and theorems), entity linking (linking to the proper theorems and definitions), and finally adjusting types so it passes the type checker. In addition, we present arXiv2Formal, a benchmark dataset for unlinked formalization consisting of 50 theorems formalized for the Lean theorem prover sampled from papers on arXiv.org. We welcome any contribut
    
[^35]: D2修剪：信息传递平衡数据修剪中的多样性和困难

    D2 Pruning: Message Passing for Balancing Diversity and Difficulty in Data Pruning. (arXiv:2310.07931v1 [cs.LG])

    [http://arxiv.org/abs/2310.07931](http://arxiv.org/abs/2310.07931)

    D2修剪是一种平衡数据多样性和困难度的方法，在coreset选择中同时考虑数据多样性和重要性评分。

    

    分析理论表明，在固定数据预算上训练的模型中，更高质量的数据可以导致更低的测试错误。此外，如果数据集可以剥离冗余项，则可以在较低的计算预算上训练模型而不降低性能。Coreset选择（或数据修剪）寻求选择训练数据的子集，以最大程度地提高在该子集上训练的模型的性能，也称为coreset。有两种主要方法：（1）基于几何的数据选取，以最大程度地提高coreset中的数据多样性，和（2）根据训练动态为样本分配困难度分数的函数。为数据多样性进行优化会导致偏向较容易样本的coreset，而难度排名选择会忽略深度学习模型训练所必需的容易样本。这表明数据多样性和重要性评分是两个互补因素，在coreset选择中需要同时考虑。

    Analytical theories suggest that higher-quality data can lead to lower test errors in models trained on a fixed data budget. Moreover, a model can be trained on a lower compute budget without compromising performance if a dataset can be stripped of its redundancies. Coreset selection (or data pruning) seeks to select a subset of the training data so as to maximize the performance of models trained on this subset, also referred to as coreset. There are two dominant approaches: (1) geometry-based data selection for maximizing data diversity in the coreset, and (2) functions that assign difficulty scores to samples based on training dynamics. Optimizing for data diversity leads to a coreset that is biased towards easier samples, whereas, selection by difficulty ranking omits easy samples that are necessary for the training of deep learning models. This demonstrates that data diversity and importance scores are two complementary factors that need to be jointly considered during coreset sel
    
[^36]: 跨语言结构启示与双语语言模型的预训练动态

    Crosslingual Structural Priming and the Pre-Training Dynamics of Bilingual Language Models. (arXiv:2310.07929v1 [cs.CL])

    [http://arxiv.org/abs/2310.07929](http://arxiv.org/abs/2310.07929)

    这项研究通过结构启示测试了多语言语言模型是否共享抽象的语法表示，并发现在接触第二种语言后的早期阶段即形成跨语言结构启示效应。这对数据污染、低资源转移以及多语言模型中抽象语法表示的产生具有重要意义。

    

    多语言语言模型是否在各种语言之间共享抽象的语法表示，并且如果共享的话，这种共享是何时发展的？我们使用结构启示来测试在模型输出上具有因果效应的抽象语法表示。我们将这种方法扩展到荷兰-英语双语环境，并在预训练期间评估荷兰-英语语言模型。我们发现在接触第二种语言后的早期阶段，跨语言结构启示效应出现，而仅需不到100万个该语言的标记数据。我们讨论了对数据污染、低资源转移以及多语言模型中抽象语法表示的产生的影响。

    Do multilingual language models share abstract grammatical representations across languages, and if so, when do these develop? Following Sinclair et al. (2022), we use structural priming to test for abstract grammatical representations with causal effects on model outputs. We extend the approach to a Dutch-English bilingual setting, and we evaluate a Dutch-English language model during pre-training. We find that crosslingual structural priming effects emerge early after exposure to the second language, with less than 1M tokens of data in that language. We discuss implications for data contamination, low-resource transfer, and how abstract grammatical representations emerge in multilingual models.
    
[^37]: 基于思维链的Transformer的表达能力

    The Expresssive Power of Transformers with Chain of Thought. (arXiv:2310.07923v1 [cs.LG])

    [http://arxiv.org/abs/2310.07923](http://arxiv.org/abs/2310.07923)

    本论文研究基于思维链的Transformer的表达能力，通过允许使用中间生成的方式提高了Transformer的推理能力，并发现线性数量的解码步骤在标准计算复杂度下增加了明显的新能力。

    

    最近的理论研究发现了一些出人意料地简单的推理问题，例如检查图中是否存在连接的两个节点，或模拟有限状态机，这些问题被证明无法由立即读取输入后回答的标准Transformer解决。然而，在实践中，通过允许Transformer使用“思维链”或“草稿纸”，即在回答之前生成并依赖一系列中间token，可以改善其推理能力。基于此，我们问：这种中间生成是否从根本上扩展了仅有解码器的Transformer的计算能力？我们表明答案是肯定的，但增加的程度关键取决于中间生成的数量。例如，我们发现相对于输入长度来说，具有对数级解码步骤的Transformer解码器仅略微推动了标准Transformer的极限，而线性数量的解码步骤则增加了明显的新能力（在标准计算复杂度下）。

    Recent theoretical work has identified surprisingly simple reasoning problems, such as checking if two nodes in a graph are connected or simulating finite-state machines, that are provably unsolvable by standard transformers that answer immediately after reading their input. However, in practice, transformers' reasoning can be improved by allowing them to use a "chain of thought" or "scratchpad", i.e., generate and condition on a sequence of intermediate tokens before answering. Motivated by this, we ask: Does such intermediate generation fundamentally extend the computational power of a decoder-only transformer? We show that the answer is yes, but the amount of increase depends crucially on the amount of intermediate generation. For instance, we find that transformer decoders with a logarithmic number of decoding steps (w.r.t. the input length) push the limits of standard transformers only slightly, while a linear number of decoding steps adds a clear new ability (under standard compl
    
[^38]: 一个对多个部分进行对比的方法：利用注意力头嵌入以实现参数有效的多头注意力机制

    Pit One Against Many: Leveraging Attention-head Embeddings for Parameter-efficient Multi-head Attention. (arXiv:2310.07911v1 [cs.CL])

    [http://arxiv.org/abs/2310.07911](http://arxiv.org/abs/2310.07911)

    本论文提出一种利用注意力头嵌入来实现参数有效的多头注意力机制，该机制在多项下游任务中取得了与传统多头注意力机制相当的预测性能，同时显著减少内存占用。

    

    在各种自然语言处理任务中，扩展预训练语言模型已经在性能上取得了巨大的提升，但这也带来了大量的内存需求。受Transformer中位置嵌入的启发，我们旨在简化和减少多头注意力机制的内存占用。我们提出了一种替代模块，只使用一个共享的投影矩阵和多个头部嵌入（MHE），即每个头部一个。我们经验证明，相比于其他注意力机制，我们的MHE注意力在内存使用效率上更高，同时在多项下游任务中实现了与传统的多头注意力机制相当的预测性能保持比。与单头注意力相比，MHE注意力仅需要额外的参数（$3nd$，其中$n$是注意力头的数量，$d$是头嵌入的大小）的微不足道的部分，而多头注意力则需要$(3n^2-3n)d^2-3nd$个额外参数。

    Scaling pre-trained language models has resulted in large performance gains in various natural language processing tasks but comes with a large cost in memory requirements. Inspired by the position embeddings in transformers, we aim to simplify and reduce the memory footprint of the multi-head attention (MHA) mechanism. We propose an alternative module that uses only a single shared projection matrix and multiple head embeddings (MHE), i.e. one per head. We empirically demonstrate that our MHE attention is substantially more memory efficient compared to alternative attention mechanisms while achieving high predictive performance retention ratio to vanilla MHA on several downstream tasks. MHE attention only requires a negligible fraction of additional parameters ($3nd$, where $n$ is the number of attention heads and $d$ the size of the head embeddings) compared to a single-head attention, while MHA requires $(3n^2-3n)d^2-3nd$ additional parameters.
    
[^39]: LangNav: 语言作为导航的感知表示

    LangNav: Language as a Perceptual Representation for Navigation. (arXiv:2310.07889v1 [cs.CV])

    [http://arxiv.org/abs/2310.07889](http://arxiv.org/abs/2310.07889)

    该论文探索了将语言作为导航的感知表示，并使用现成的视觉系统将每个时间步骤的视图转化为自然语言描述，通过微调预训练的语言模型选择最佳的行动来满足导航指令。有两种用例的实验对这种基于语言的导航方法进行了探索：使用大型语言模型生成合成轨迹以微调较小的语言模型，以及模拟到实际的转换。

    

    我们探索将语言作为视觉与语言导航的感知表示。我们的方法使用现成的视觉系统（用于图像字幕和物体检测）将每个时间步骤中代理人的自我中心全景视图转化为自然语言描述。然后，我们微调预训练的语言模型，根据当前视图和轨迹历史选择最佳的行动来满足导航指令。与标准设置相比，标准设置将预训练的语言模型适应于与预训练的视觉模型连续视觉特征直接配合使用。我们的方法使用（离散的）语言作为感知表示。我们在R2R视觉与语言导航基准测试中探索了两个用例：使用大型语言模型（GPT-4）生成合成轨迹，以便微调较小的语言模型；以及模拟到实际的转换。

    We explore the use of language as a perceptual representation for vision-and-language navigation. Our approach uses off-the-shelf vision systems (for image captioning and object detection) to convert an agent's egocentric panoramic view at each time step into natural language descriptions. We then finetune a pretrained language model to select an action, based on the current view and the trajectory history, that would best fulfill the navigation instructions. In contrast to the standard setup which adapts a pretrained language model to work directly with continuous visual features from pretrained vision models, our approach instead uses (discrete) language as the perceptual representation. We explore two use cases of our language-based navigation (LangNav) approach on the R2R vision-and-language navigation benchmark: generating synthetic trajectories from a prompted large language model (GPT-4) with which to finetune a smaller language model; and sim-to-real transfer where we transfer 
    
[^40]: TabLib：一个包含上亿表格和上百亿上下文的数据集

    TabLib: A Dataset of 627M Tables with Context. (arXiv:2310.07875v1 [cs.CL])

    [http://arxiv.org/abs/2310.07875](http://arxiv.org/abs/2310.07875)

    TabLib是一个包含上亿表格和上百亿上下文的数据集，规模和多样性使其在表格模态下具有巨大的潜力。

    

    巨大多样的数据集在提升现代AI系统在文本和图像模态下的性能方面起着关键作用。然而，对于表格数据，目前还没有与文本和图像可比拟的规模和多样性的数据集。因此，我们提出了"TabLib"，这是一个由6.27亿个表格和86.7亿个上下文令牌总共达到69 TiB的编译数据集。TabLib的数据来自多个文件格式，包括CSV、HTML、SQLite、PDF、Excel等，这些数据源自GitHub和Common Crawl。TabLib的规模和多样性在表格模态下具有巨大的潜力，如同原始的用于文本和图像的基础数据集，例如The Pile和LAION。

    It is well-established that large, diverse datasets play a pivotal role in the performance of modern AI systems for text and image modalities. However, there are no datasets for tabular data of comparable size and diversity to those available for text and images. Thus we present "TabLib'', a compilation of 627 million tables totaling 69 TiB, along with 867B tokens of context. TabLib was extracted from numerous file formats, including CSV, HTML, SQLite, PDF, Excel, and others, sourced from GitHub and Common Crawl. The size and diversity of TabLib offer considerable promise in the table modality, reminiscent of the original promise of foundational datasets for text and images, such as The Pile and LAION.
    
[^41]: 评估神经测试Oracle生成的评估指标

    Assessing Evaluation Metrics for Neural Test Oracle Generation. (arXiv:2310.07856v1 [cs.CL])

    [http://arxiv.org/abs/2310.07856](http://arxiv.org/abs/2310.07856)

    评估了神经测试Oracle生成的评估指标，在基于自然语言生成的度量和测试充分性度量之间发现了没有显著相关性。基于自然语言生成的度量高但测试充分性度量低的oracle往往具有复杂的特征。

    

    在这项工作中，我们重新审视了现有的Oracle生成研究和ChatGPT，并从经验上调查了它们在基于自然语言生成的度量和测试充分性度量方面的性能。具体而言，我们对五种基于自然语言生成的度量和两种测试充分性度量进行了四种最先进的测试Oracle生成模型的训练和运行，以进行分析。令人惊讶的是，我们发现基于自然语言的度量和测试充分性度量之间没有显著的相关性。例如，在研究中的所有NOG中，ChatGPT在project activemq-artemis上生成的oracle在所有基于自然语言的度量中具有最高的性能，然而，在测试充分性度量上，它有最多的项目表现出下降。我们进一步进行了定性分析，探索了我们观察结果背后的原因，我们发现基于自然语言的度量较高但测试充分性度量较低的oracle往往具有复杂的特征。

    In this work, we revisit existing oracle generation studies plus ChatGPT to empirically investigate the current standing of their performance in both NLG-based and test adequacy metrics. Specifically, we train and run four state-of-the-art test oracle generation models on five NLG-based and two test adequacy metrics for our analysis. We apply two different correlation analyses between these two different sets of metrics. Surprisingly, we found no significant correlation between the NLG-based metrics and test adequacy metrics. For instance, oracles generated from ChatGPT on the project activemq-artemis had the highest performance on all the NLG-based metrics among the studied NOGs, however, it had the most number of projects with a decrease in test adequacy metrics compared to all the studied NOGs. We further conduct a qualitative analysis to explore the reasons behind our observations, we found that oracles with high NLG-based metrics but low test adequacy metrics tend to have complex 
    
[^42]: 使用大型语言模型生成合成数据用于文本分类：潜力和限制

    Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations. (arXiv:2310.07849v1 [cs.CL])

    [http://arxiv.org/abs/2310.07849](http://arxiv.org/abs/2310.07849)

    本研究旨在探讨使用大型语言模型生成合成数据在文本分类模型训练中的潜力和限制。研究结果发现，主观性会负面影响模型在合成数据上的性能。这对于理解和利用合成数据的有效性具有重要的启示作用。

    

    收集和整理高质量的训练数据对于开发具有卓越性能的文本分类模型至关重要，但往往伴随着巨大的成本和时间投入。研究人员最近开始探索使用大型语言模型（LLMs）生成合成数据集作为一种替代方法。然而，LLM生成的合成数据在支持模型训练方面的有效性在不同的分类任务中是不一致的。为了更好地了解调节LLM生成的合成数据有效性的因素，本研究探讨了在分类的主观性如何影响在合成数据上训练的模型的性能。我们的研究结果表明，主观性在任务层面和实例层面上都与在合成数据上训练的模型的性能呈负相关。最后，我们讨论了我们的工作对于利用LLM来生成合成数据在潜力和限制方面的影响。

    The collection and curation of high-quality training data is crucial for developing text classification models with superior performance, but it is often associated with significant costs and time investment. Researchers have recently explored using large language models (LLMs) to generate synthetic datasets as an alternative approach. However, the effectiveness of the LLM-generated synthetic data in supporting model training is inconsistent across different classification tasks. To better understand factors that moderate the effectiveness of the LLM-generated synthetic data, in this study, we look into how the performance of models trained on these synthetic data may vary with the subjectivity of classification. Our results indicate that subjectivity, at both the task level and instance level, is negatively associated with the performance of the model trained on synthetic data. We conclude by discussing the implications of our work on the potential and limitations of leveraging LLM fo
    
[^43]: 通过自动构建知识图谱的方式, 解答梵语中问题的框架

    Framework for Question-Answering in Sanskrit through Automated Construction of Knowledge Graphs. (arXiv:2310.07848v1 [cs.CL])

    [http://arxiv.org/abs/2310.07848](http://arxiv.org/abs/2310.07848)

    本文针对梵语中问题的构建了一个自然语言问答系统，通过自动构建知识图谱来回答事实性问题，并在不同类型的关系上展示了系统的应用。分析了系统的缺点以便改进。

    

    梵语是世界上最大和最多样化的文学之一，然而提取其中的知识是一项具有挑战性的任务，原因包括语言的复杂性和标准自然语言处理工具的匮乏。本文针对从梵语文本中构建特定类型关系的知识图谱问题。我们在梵语中构建一个自然语言问答系统，该系统使用知识图谱来回答事实性问题。我们设计了一个整体系统的框架，并在马哈巴拉塔和罗摩衍那中的人际关系上实现了两个独立的系统实例，并在阿育吠陀中的技术文本——《生理/病理秘密》中的同义关系上实现了一个实例。我们展示了系统可以正确回答大约50%的事实性问题。更重要的是，我们详细分析了系统的缺点以便改进。

    Sanskrit (sa\d{m}sk\d{r}ta) enjoys one of the largest and most varied literature in the whole world. Extracting the knowledge from it, however, is a challenging task due to multiple reasons including complexity of the language and paucity of standard natural language processing tools. In this paper, we target the problem of building knowledge graphs for particular types of relationships from sa\d{m}sk\d{r}ta texts. We build a natural language question-answering system in sa\d{m}sk\d{r}ta that uses the knowledge graph to answer factoid questions. We design a framework for the overall system and implement two separate instances of the system on human relationships from mah\=abh\=arata and r\=am\=aya\d{n}a, and one instance on synonymous relationships from bh\=avaprak\=a\'sa nigha\d{n}\d{t}u, a technical text from \=ayurveda. We show that about 50% of the factoid questions can be answered correctly by the system. More importantly, we analyse the shortcomings of the system in detail for ea
    
[^44]: 合成数据是否能使大型语言模型更高效？

    Does Synthetic Data Make Large Language Models More Efficient?. (arXiv:2310.07830v1 [cs.CL])

    [http://arxiv.org/abs/2310.07830](http://arxiv.org/abs/2310.07830)

    本文探讨了在NLP中合成数据生成的细微差别，重点关注基于模板的问题生成。通过评估其优势和固有限制，本研究揭示了合成数据对现代Transformer模型性能的影响，并强调了合成数据与真实世界数据之间所需的微妙平衡。

    

    随着深度学习方法的出现，自然语言处理(NLP)经历了深刻的变革。研究人员持续面临的一个挑战是驱动这些模型的高质量标注数据集的稀缺。本文探讨了在NLP中合成数据生成的细微差别，重点关注基于模板的问题生成。通过评估其优势，包括数据扩充潜力和结构多样性的引入，我们将这些优点与固有限制进行了对比，如过拟合风险和预定义模板所带来的限制。通过经验评估，我们展示了基于模板的合成数据对现代Transformer模型性能的影响。我们通过强调合成数据和真实世界数据之间所需的微妙平衡及将合成数据整合到模型训练流程中的未来轨迹来总结。这些发现旨在指导NLP从业者。

    Natural Language Processing (NLP) has undergone transformative changes with the advent of deep learning methodologies. One challenge persistently confronting researchers is the scarcity of high-quality, annotated datasets that drive these models. This paper explores the nuances of synthetic data generation in NLP, with a focal point on template-based question generation. By assessing its advantages, including data augmentation potential and the introduction of structured variety, we juxtapose these benefits against inherent limitations, such as the risk of overfitting and the constraints posed by pre-defined templates. Drawing from empirical evaluations, we demonstrate the impact of template-based synthetic data on the performance of modern transformer models. We conclude by emphasizing the delicate balance required between synthetic and real-world data, and the future trajectories of integrating synthetic data in model training pipelines. The findings aim to guide NLP practitioners in
    
[^45]: Antarlekhaka：一个全面的多任务自然语言标注工具

    Antarlekhaka: A Comprehensive Tool for Multi-task Natural Language Annotation. (arXiv:2310.07826v1 [cs.CL])

    [http://arxiv.org/abs/2310.07826](http://arxiv.org/abs/2310.07826)

    Antarlekhaka是一个全面的多任务自然语言标注工具，可用于手动标注与NLP相关的任务。它兼容Unicode，支持分布式注释，并提供用户友好的界面。其中包括两个其他工具没有处理的任务，即句子边界检测和决定规范词序，这对于诗歌形式的文本是重要的。

    

    自然语言处理（NLP）技术在低资源语言中的推进面临的主要障碍之一是缺乏用于训练和测试机器学习模型的标注数据集。在本文中，我们介绍了Antarlekhaka，一个用于手动标注与NLP相关的一整套任务的工具。该工具兼容Unicode，与语言无关，可在Web上部署，并支持多个同时注释者的分布式注释。该系统提供了用户友好的界面，支持8个类别的标注任务。这些任务类别又能够支持更多的NLP任务的标注。其中包括两个其他工具没有处理的语言任务，即句子边界检测和决定规范词序，这些对于诗歌形式的文本是重要的任务。我们提出了基于小文本单元的顺序标注的想法，其中注释者在处理一个文本单元之前会执行多个与之相关的任务。

    One of the primary obstacles in the advancement of Natural Language Processing (NLP) technologies for low-resource languages is the lack of annotated datasets for training and testing machine learning models. In this paper, we present Antarlekhaka, a tool for manual annotation of a comprehensive set of tasks relevant to NLP. The tool is Unicode-compatible, language-agnostic, Web-deployable and supports distributed annotation by multiple simultaneous annotators. The system sports user-friendly interfaces for 8 categories of annotation tasks. These, in turn, enable the annotation of a considerably larger set of NLP tasks. The task categories include two linguistic tasks not handled by any other tool, namely, sentence boundary detection and deciding canonical word order, which are important tasks for text that is in the form of poetry. We propose the idea of sequential annotation based on small text units, where an annotator performs several tasks related to a single text unit before proc
    
[^46]: 非自回归文本编辑方法与具有复制感知潜在对齐.

    Non-autoregressive Text Editing with Copy-aware Latent Alignments. (arXiv:2310.07821v1 [cs.CL])

    [http://arxiv.org/abs/2310.07821](http://arxiv.org/abs/2310.07821)

    这篇论文提出了一种新的非自回归文本编辑方法，通过引入复制操作来管理文本重叠，解决了Seq2Edit方法在生成灵活性和跨语言推广方面的挑战。实验证明，该方法在GEC和句子融合任务上表现优异，并且在德语和俄语上具有良好的泛化性能。

    

    近期的研究在文本编辑领域中将Seq2Seq转变为Seq2Edit，旨在解决前者中的慢自回归推理问题。尽管有着有希望的结果，Seq2Edit方法仍然面临着一些挑战，如生成的灵活性和推广到其他语言的困难。在本研究中，我们提出了一种新颖的非自回归文本编辑方法，通过建模具有复制操作的编辑过程的潜在CTC对齐来规避以上问题，从而可以更高效地处理文本重叠的编辑。我们在 GEC 和句子融合任务上进行了大量实验，表明我们的方法明显优于现有的Seq2Edit模型，并实现了与Seq2Seq相当或甚至更好的结果，同时有超过4倍的加速度。此外，我们还展示了它在德语和俄语上具有很好的泛化性能。

    Recent work has witnessed a paradigm shift from Seq2Seq to Seq2Edit in the field of text editing, with the aim of addressing the slow autoregressive inference problem posed by the former. Despite promising results, Seq2Edit approaches still face several challenges such as inflexibility in generation and difficulty in generalizing to other languages. In this work, we propose a novel non-autoregressive text editing method to circumvent the above issues, by modeling the edit process with latent CTC alignments. We make a crucial extension to CTC by introducing the copy operation into the edit space, thus enabling more efficient management of textual overlap in editing. We conduct extensive experiments on GEC and sentence fusion tasks, showing that our proposed method significantly outperforms existing Seq2Edit models and achieves similar or even better results than Seq2Seq with over $4\times$ speedup. Moreover, it demonstrates good generalizability on German and Russian. In-depth analyses 
    
[^47]: 可度量忠实性的掩码语言模型

    Faithfulness Measurable Masked Language Models. (arXiv:2310.07819v1 [cs.CL])

    [http://arxiv.org/abs/2310.07819](http://arxiv.org/abs/2310.07819)

    本论文提出了一种可度量忠实性的掩码语言模型，通过使用一种新颖的微调方法，将屏蔽令牌作为设计使其成为分布内，以解决解释自然语言处理模型时常见的问题。

    

    解释自然语言处理模型的常见方法是使用重要性度量来表达哪些令牌对于预测很重要。然而，尽管这些解释具有说服力，但往往是错误的。因此，测量它们的忠实性至关重要。其中一种度量标准是如果令牌确实很重要，那么屏蔽它们应该导致模型性能变差。然而，令牌屏蔽会引入区域外问题，而现有的解决方案在计算上很昂贵并且使用代理模型。此外，其他指标的适用范围非常有限。在这项工作中，我们提出了一种固有的忠实性可度量模型来应对这些挑战。通过使用一种新颖的微调方法来实现这一目标，该方法将屏蔽令牌作为设计使其成为分布内。这与现有方法不同，现有方法完全与模型无关，但在实践中不适用。我们通过将其应用于各种任务和数据集来证明我们方法的普适性。

    A common approach to explain NLP models, is to use importance measures that express which tokens are important for a prediction. Unfortunately, such explanations are often wrong despite being persuasive. Therefore, it is essential to measure their faithfulness. One such metric is if tokens are truly important, then masking them should result in worse model performance. However, token masking introduces out-of-distribution issues and existing solutions are computationally expensive and employ proxy-models. Furthermore, other metrics are very limited in scope. In this work, we propose an inherently faithfulness measurable model that addresses these challenges. This is achieved by using a novel fine-tuning method that incorporates masking, such that masking tokens become in-distribution by design. This differs from existing approaches, which are completely model-agnostic but are inapplicable in practice. We demonstrate the generality of our approach by applying it to various tasks and val
    
[^48]: 探索大型语言模型中类比识别与句子结构编码之间的关系

    Exploring the Relationship between Analogy Identification and Sentence Structure Encoding in Large Language Models. (arXiv:2310.07818v1 [cs.CL])

    [http://arxiv.org/abs/2310.07818](http://arxiv.org/abs/2310.07818)

    这项研究探究了大型语言模型中识别句子类比的能力与其编码句法和语义结构能力之间的关系。

    

    识别类比在人类认知和语言能力中起着重要作用。在过去的十年里，对于“A对B就像C对D”这种形式的词语类比进行了广泛的研究。然而，对于涉及更长文本的类比，如句子和句子集合，传达类比意义的问题引起了越来越多的兴趣。当前的自然语言处理研究社区评估大型语言模型（LLMs）识别此类类比的能力，但这些能力背后的原因需要进一步探究。此外，LLMs在其嵌入中编码语言的句法和语义结构的能力，近年来得到了显著关注。在这项工作中，我们研究了多个LLMs识别句子类比的能力与其编码句法和语义结构的能力之间的关系。通过分析，我们发现LLMs的类比识别能力与其编码能力有关。

    Identifying analogies plays a pivotal role in human cognition and language proficiency. In the last decade, there has been extensive research on word analogies in the form of ``A is to B as C is to D.'' However, there is a growing interest in analogies that involve longer text, such as sentences and collections of sentences, which convey analogous meanings. While the current NLP research community evaluates the ability of Large Language Models (LLMs) to identify such analogies, the underlying reasons behind these abilities warrant deeper investigation. Furthermore, the capability of LLMs to encode both syntactic and semantic structures of language within their embeddings has garnered significant attention with the surge in their utilization. In this work, we examine the relationship between the abilities of multiple LLMs to identify sentence analogies, and their capacity to encode syntactic and semantic structures. Through our analysis, we find that analogy identification ability of LL
    
[^49]: 语言模型作为语义索引器

    Language Models As Semantic Indexers. (arXiv:2310.07815v1 [cs.IR])

    [http://arxiv.org/abs/2310.07815](http://arxiv.org/abs/2310.07815)

    本文介绍了一种使用生成性语言模型学习语义ID的自监督框架LMINDEXER。

    

    语义标识符（ID）是信息检索中的一个重要概念，旨在保留对象（如文档和项）内部的语义。先前的研究通常采用两阶段流程来学习语义ID，首先使用现成的文本编码器获取嵌入，并根据嵌入来推导ID。然而，每个步骤都会引入潜在的信息损失，并且文本编码器生成的潜在空间内的嵌入分布通常与语义索引所需的预期分布存在固有的不匹配。然而，设计一个既能学习文档的语义表示又能同时学习其分层结构的方法并不容易，因为语义ID是离散和顺序结构的，并且语义监督是不充分的。在本文中，我们引入了LMINDEXER，它是一个自监督框架，用于使用生成性语言模型学习语义ID。

    Semantic identifier (ID) is an important concept in information retrieval that aims to preserve the semantics of objects such as documents and items inside their IDs. Previous studies typically adopt a two-stage pipeline to learn semantic IDs by first procuring embeddings using off-the-shelf text encoders and then deriving IDs based on the embeddings. However, each step introduces potential information loss and there is usually an inherent mismatch between the distribution of embeddings within the latent space produced by text encoders and the anticipated distribution required for semantic indexing. Nevertheless, it is non-trivial to design a method that can learn the document's semantic representations and its hierarchical structure simultaneously, given that semantic IDs are discrete and sequentially structured, and the semantic supervision is deficient. In this paper, we introduce LMINDEXER, a self-supervised framework to learn semantic IDs with a generative language model. We tackl
    
[^50]: 幽默的一般机制：重新定义语义重叠

    A general mechanism of humor: reformulating the semantic overlap. (arXiv:2310.07803v1 [cs.CL])

    [http://arxiv.org/abs/2310.07803](http://arxiv.org/abs/2310.07803)

    本文提出了一种普适性的认知幽默机制，建立在约束的概念上，通过重叠约束的观察来解释幽默的产生。

    

    本文提出一种普适性的认知幽默机制，不仅限于语言交流。它借鉴了Raskin关于情节重叠的概念，并符合不一致性-解决理论框架，但是建立在约束的概念上，即数据集之间的抽象对应关系。根据这种观点，情节重叠是一种更抽象描述的现象，即约束重叠。文中引入了被忽视的论证概念，用于描述两个重叠的约束——明显的和隐蔽的。它们的输入和输出并不直接编码在话语中，而是由话语暗示，它们的重叠导致在交流的话语层面上产生另一种重叠，这种不一致性显露了出来。我们的假设是，唤起这种约束是听众解释话语的推理过程的认知效应。我们基于Hofstadter关于暗示的理论假设这一假设。

    This article proposes a cognitive mechanism of humour of general applicability, not restricted to verbal communication. It is indebted to Raskin's concept of script overlap, and conforms to the incongruity-resolution theoretical framework, but it is built on the notion of constraint, an abstract correspondence between sets of data. Under this view, script overlap is an outcome of a more abstractly described phenomenon, constraint overlap. The important concept of the overlooked argument is introduced to characterise the two overlapping constraints -- overt and covert. Their inputs and outputs are not directly encoded in utterances, but implicated by them, and their overlap results in another overlap at the level of the communicated utterances, that the incongruity reveals. Our hypothesis assumes as a given that the evocation of such constraints is a cognitive effect of the inferential process by which a hearer interprets utterances. We base this assumption on Hofstadter's theory of ana
    
[^51]: 为有效的细粒度实体类型定义进行本体增强

    Ontology Enrichment for Effective Fine-grained Entity Typing. (arXiv:2310.07795v1 [cs.CL])

    [http://arxiv.org/abs/2310.07795](http://arxiv.org/abs/2310.07795)

    在本文中，我们提出了OnEFET方法，通过为本体结构的每个节点添加额外信息，包括实例信息和主题信息，来增强零样本细粒度实体类型定义。这种方法可以有效指导细粒度实体类型的识别任务。

    

    细粒度实体类型定义（FET）是根据上下文信息识别实体提及中特定实体类型的任务。传统的FET方法需要大量的人工标注，耗时且昂贵。最近的研究提出了弱监督或零样本方法。我们研究了只提供本体的零样本FET设置。然而，大多数现有的本体结构缺乏丰富的支持信息，甚至含有模糊的关系，导致它们在指导FET方面效果不佳。最近发展的语言模型，在各种几样本和零样本的自然语言处理任务中取得了很好的结果，但由于缺乏与任务相关的本体的互动，可能在零样本FET方面面临挑战。在这项研究中，我们提出了OnEFET，我们通过两种类型的额外信息对本体结构中的每个节点进行增强：实例信息用于训练样本增强，主题信息用于将类型与上下文关联起来。

    Fine-grained entity typing (FET) is the task of identifying specific entity types at a fine-grained level for entity mentions based on their contextual information. Conventional methods for FET require extensive human annotation, which is time-consuming and costly. Recent studies have been developing weakly supervised or zero-shot approaches. We study the setting of zero-shot FET where only an ontology is provided. However, most existing ontology structures lack rich supporting information and even contain ambiguous relations, making them ineffective in guiding FET. Recently developed language models, though promising in various few-shot and zero-shot NLP tasks, may face challenges in zero-shot FET due to their lack of interaction with task-specific ontology. In this study, we propose OnEFET, where we (1) enrich each node in the ontology structure with two types of extra information: instance information for training sample augmentation and topic information to relate types to contexts
    
[^52]: GenTKG: 基于生成模型的时间知识图谱预测

    GenTKG: Generative Forecasting on Temporal Knowledge Graph. (arXiv:2310.07793v1 [cs.CL])

    [http://arxiv.org/abs/2310.07793](http://arxiv.org/abs/2310.07793)

    研究提出了一种名为GenTKG的生成模型，用于在时间知识图谱上进行预测。该模型通过结合基于时间逻辑规则的检索策略和轻量级的参数效率指导，克服了复杂的时间图数据结构和庞大的数据量所带来的挑战。

    

    大规模语言模型(LLM)的快速发展引发了对时间知识图谱(tKG)领域的兴趣，其中传统的基于嵌入和规则的模型占主导地位。目前仍然存在一个问题，即预训练的LLM是否能够理解结构化的时间关系数据，并取代它们成为时间关系预测的基础模型。因此，我们将时间知识预测引入生成模式。然而，在复杂的时间图数据结构和LLM可以处理的序列自然表达之间存在巨大的鸿沟，在tKG的庞大数据量和微调LLM的巨大计算成本之间也存在挑战。为了解决这些挑战，我们提出了一种新颖的检索增强生成框架，称为GenTKG，它在tKG上执行生成式预测，结合了基于时间逻辑规则的检索策略和轻量级的参数效率指导。通过大量实验证明了GenTKG的有效性。

    The rapid advancements in large language models (LLMs) have ignited interest in the temporal knowledge graph (tKG) domain, where conventional carefully designed embedding-based and rule-based models dominate. The question remains open of whether pre-trained LLMs can understand structured temporal relational data and replace them as the foundation model for temporal relational forecasting. Therefore, we bring temporal knowledge forecasting into the generative setting. However, challenges occur in the huge chasms between complex temporal graph data structure and sequential natural expressions LLMs can handle, and between the enormous data sizes of tKGs and heavy computation costs of finetuning LLMs. To address these challenges, we propose a novel retrieval augmented generation framework that performs generative forecasting on tKGs named GenTKG, which combines a temporal logical rule-based retrieval strategy and lightweight parameter-efficient instruction tuning. Extensive experiments hav
    
[^53]: 优先选择知识：面向知识驱动对话的生成器无关的知识预选方法

    Well Begun is Half Done: Generator-agnostic Knowledge Pre-Selection for Knowledge-Grounded Dialogue. (arXiv:2310.07659v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.07659](http://arxiv.org/abs/2310.07659)

    本论文提出了一种生成器无关的知识选择方法GATE，将知识选择放置在生成之前，可以减少后续响应生成模型的负担，并为知识驱动对话系统提供更多信息量的响应。

    

    在知识驱动的对话系统中，准确的知识选择至关重要。针对这个问题，我们提供了一个新的视角来组织现有的文献，即将知识选择与生成器耦合，并放置在生成之前和之后。我们专注于第三个未深入研究的研究类别，它不仅可以提前准确选择知识，还可以减少后续响应生成模型的学习、调整和解释负担，特别是LLMs。我们提出了一种生成器无关的知识选择方法GATE，通过在不同的知识结构和可变的知识要求中选择与上下文相关的知识来为后续响应生成模型准备知识。实验结果证明了GATE的优越性，并表明在生成之前进行知识选择是一种轻量级但有效的方式，可以促使LLMs（如ChatGPT）生成更有信息量的响应。

    Accurate knowledge selection is critical in knowledge-grounded dialogue systems. Towards a closer look at it, we offer a novel perspective to organize existing literature, i.e., knowledge selection coupled with, after, and before generation. We focus on the third under-explored category of study, which can not only select knowledge accurately in advance, but has the advantage to reduce the learning, adjustment, and interpretation burden of subsequent response generation models, especially LLMs. We propose GATE, a generator-agnostic knowledge selection method, to prepare knowledge for subsequent response generation models by selecting context-related knowledge among different knowledge structures and variable knowledge requirements. Experimental results demonstrate the superiority of GATE, and indicate that knowledge selection before generation is a lightweight yet effective way to facilitate LLMs (e.g., ChatGPT) to generate more informative responses.
    
[^54]: 重新考虑基于DNA序列的BERT-like预训练

    Rethinking the BERT-like Pretraining for DNA Sequences. (arXiv:2310.07644v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2310.07644](http://arxiv.org/abs/2310.07644)

    重新考虑了基于DNA序列的BERT-like预训练方法，通过使用K-mer重叠标记化，在下游任务的微调阶段和预训练过程中都取得了一致的性能改善。

    

    随着在自然语言处理领域中大规模预训练的成功，将其应用于生命科学领域的趋势日益增长。特别是基于DNA序列的预训练方法因其捕捉基因的通用信息的潜力而受到关注。然而，现有的DNA序列预训练方法主要依赖于从自然语言处理领域直接引入的BERT预训练方法，缺乏全面的理解和专门定制的方法。为了填补这一研究空白，我们首先进行了一系列的探索性实验，并获得了几个有启发性的观察结果：1）在下游任务的微调阶段，使用K-mer重叠标记化而不是K-mer非重叠标记化时，重叠和非重叠的预训练权重均表现出一致的性能改善。2）在预训练过程中，使用K-mer重叠标记化会迅速产生清晰的K-mer嵌入，并将损失降低到非常低的水平。

    With the success of large-scale pretraining in NLP, there is an increasing trend of applying it to the domain of life sciences. In particular, pretraining methods based on DNA sequences have garnered growing attention due to their potential to capture generic information about genes. However, existing pretraining methods for DNA sequences largely rely on direct adoptions of BERT pretraining from NLP, lacking a comprehensive understanding and a specifically tailored approach. To address this research gap, we first conducted a series of exploratory experiments and gained several insightful observations: 1) In the fine-tuning phase of downstream tasks, when using K-mer overlapping tokenization instead of K-mer non-overlapping tokenization, both overlapping and non-overlapping pretraining weights show consistent performance improvement.2) During the pre-training process, using K-mer overlapping tokenization quickly produces clear K-mer embeddings and reduces the loss to a very low level, w
    
[^55]: 打字倾听鸡尾酒会：文本引导的目标说话人提取

    Typing to Listen at the Cocktail Party: Text-Guided Target Speaker Extraction. (arXiv:2310.07284v1 [eess.AS])

    [http://arxiv.org/abs/2310.07284](http://arxiv.org/abs/2310.07284)

    研究人员提出了一种名为LLM-TSE的模型，该模型利用大型语言模型从用户键入的文本输入中提取语义线索，以增强目标说话人提取(TSE)模型的灵活性和可控性。

    

    人类拥有一种在复杂的声学环境中有选择性地专注于感兴趣的声音源的非凡能力，通常称为鸡尾酒会场景。为了在机器中复制这种引人注目的听觉注意能力，研究人员开发了目标说话人提取(TSE)模型。这些模型利用目标说话人的预先注册线索来提取感兴趣的声源。然而，在真实世界的情景中，这些模型的有效性受到了预先注册线索的可能变化甚至缺失的限制。为了解决这个限制，本研究调查了将自然语言整合到现有TSE模型中以增强其灵活性和可控性的方法。具体而言，我们提出了一个名为LLM-TSE的模型，其中使用大型语言模型(LLM)从用户的键入文本输入中提取有用的语义线索，这些线索可以补充预先注册的线索或独立工作以控制TSE过程。

    Humans possess an extraordinary ability to selectively focus on the sound source of interest amidst complex acoustic environments, commonly referred to as cocktail party scenarios. In an attempt to replicate this remarkable auditory attention capability in machines, target speaker extraction (TSE) models have been developed. These models leverage the pre-registered cues of the target speaker to extract the sound source of interest. However, the effectiveness of these models is hindered in real-world scenarios due to the potential variation or even absence of pre-registered cues. To address this limitation, this study investigates the integration of natural language to enhance the flexibility and controllability of existing TSE models. Specifically, we propose a model named LLM-TSE, wherein a large language model (LLM) to extract useful semantic cues from the user's typed text input, which can complement the pre-registered cues or work independently to control the TSE process. Our exper
    
[^56]: 在医疗保健领域中对大型语言模型的分析：BioBERT 案例研究

    An Analysis on Large Language Models in Healthcare: A Case Study of BioBERT. (arXiv:2310.07282v1 [cs.AI])

    [http://arxiv.org/abs/2310.07282](http://arxiv.org/abs/2310.07282)

    本研究分析了在医疗保健领域应用大型语言模型（尤其是BioBERT）的可行性，并提出了针对医疗保健领域的微调方法。研究突出了BioBERT对于解决与生物医学文本挖掘相关任务的特定要求的适用性。

    

    本文对在医疗保健领域应用大型语言模型（尤其是BioBERT）进行了全面调查研究。它首先彻底检查了先前在医疗保健领域中应用自然语言处理（NLP）方法的情况，揭示了这些方法面临的局限和挑战。随后，本研究探讨了将BioBERT整合到医疗保健应用中的路径，突出其适用于解决与生物医学文本挖掘相关任务的特定要求。该分析概述了用于针对医疗保健领域独特需求微调BioBERT的系统方法论。这个方法包括从各种医疗保健来源收集数据，为识别医疗实体和对其进行分类等任务进行数据注释，并应用专门针对处理生物医学文本中复杂性的预处理技术。

    This paper conducts a comprehensive investigation into applying large language models, particularly on BioBERT, in healthcare. It begins with thoroughly examining previous natural language processing (NLP) approaches in healthcare, shedding light on the limitations and challenges these methods face. Following that, this research explores the path that led to the incorporation of BioBERT into healthcare applications, highlighting its suitability for addressing the specific requirements of tasks related to biomedical text mining. The analysis outlines a systematic methodology for fine-tuning BioBERT to meet the unique needs of the healthcare domain. This approach includes various components, including the gathering of data from a wide range of healthcare sources, data annotation for tasks like identifying medical entities and categorizing them, and the application of specialized preprocessing techniques tailored to handle the complexities found in biomedical texts. Additionally, the pape
    
[^57]: Jaynes Machine: 深度神经网络的通用微结构

    Jaynes Machine: The universal microstructure of deep neural networks. (arXiv:2310.06960v1 [cond-mat.stat-mech] CROSS LISTED)

    [http://arxiv.org/abs/2310.06960](http://arxiv.org/abs/2310.06960)

    Jaynes Machine提出了一种关于深度神经网络微结构的新理论，预测了所有高连接层具有分布为对数正态分布的通用连接强度微结构，并在理想条件下预测了${\mu}$和${\sigma}$在所有网络的所有层中是相同的。实证数据支持这些预测，并讨论了如何利用这些结果来减少训练大规模深度神经网络所需的资源。

    

    我们提出了关于深度神经网络微结构的新理论。使用名为统计远动力学的理论框架，它是统计热力学和潜在博弈理论的概念综合，我们预测深度神经网络所有高连接层具有分布为对数正态分布的通用连接强度微结构（$LN({\mu}, {\sigma})$)。此外，在理想条件下，理论预测对于所有网络的所有层，${\mu}$和${\sigma}$是相同的。这是由所有连接竞争并对整体损失函数最小化做出相同有效效用的套利均衡的结果。这些令人惊讶的预测得到了来自六个大规模深度神经网络的实证数据的支持。我们还讨论了如何利用这些结果来减少训练大规模深度神经网络所需的数据量，时间和计算资源。

    We present a novel theory of the microstructure of deep neural networks. Using a theoretical framework called statistical teleodynamics, which is a conceptual synthesis of statistical thermodynamics and potential game theory, we predict that all highly connected layers of deep neural networks have a universal microstructure of connection strengths that is distributed lognormally ($LN({\mu}, {\sigma})$). Furthermore, under ideal conditions, the theory predicts that ${\mu}$ and ${\sigma}$ are the same for all layers in all networks. This is shown to be the result of an arbitrage equilibrium where all connections compete and contribute the same effective utility towards the minimization of the overall loss function. These surprising predictions are shown to be supported by empirical data from six large-scale deep neural networks in real life. We also discuss how these results can be exploited to reduce the amount of data, time, and computational resources needed to train large deep neural
    
[^58]: SpikeCLIP：一种对比语言-图像预训练脉冲神经网络

    SpikeCLIP: A Contrastive Language-Image Pretrained Spiking Neural Network. (arXiv:2310.06488v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2310.06488](http://arxiv.org/abs/2310.06488)

    本论文引入了一种名为SpikeCLIP的新框架，通过对比语言-图像预训练实现了脉冲神经网络的多模态扩展，并在能源效率和性能方面取得了可比较的结果。

    

    脉冲神经网络（SNNs）已经证明其在视觉和语言领域中能够实现与深度神经网络（DNNs）相当的性能，同时具有能效提高和符合生物合理性的优势。然而，将这种单模态的SNNs扩展到多模态的情景仍然是一个未开发的领域。受到对比语言-图像预训练（CLIP）概念的启发，我们引入了一个名为SpikeCLIP的新框架，通过“对齐预训练+双损失微调”的两步骤配方，来解决脉冲计算背景下两种模态之间的差距。广泛的实验证明，在常用的用于多模态模型评估的各种数据集上，SNNs取得了与其DNNs对应物相当的结果，同时显著降低了能源消耗。此外，SpikeCLIP在图像分类方面保持了稳定的性能。

    Spiking neural networks (SNNs) have demonstrated the capability to achieve comparable performance to deep neural networks (DNNs) in both visual and linguistic domains while offering the advantages of improved energy efficiency and adherence to biological plausibility. However, the extension of such single-modality SNNs into the realm of multimodal scenarios remains an unexplored territory. Drawing inspiration from the concept of contrastive language-image pre-training (CLIP), we introduce a novel framework, named SpikeCLIP, to address the gap between two modalities within the context of spike-based computing through a two-step recipe involving ``Alignment Pre-training + Dual-Loss Fine-tuning". Extensive experiments demonstrate that SNNs achieve comparable results to their DNN counterparts while significantly reducing energy consumption across a variety of datasets commonly used for multimodal model evaluation. Furthermore, SpikeCLIP maintains robust performance in image classification 
    
[^59]: 宽松的嘴唇会使船沉没：减轻强化学习中的长度偏差问题

    Loose lips sink ships: Mitigating Length Bias in Reinforcement Learning from Human Feedback. (arXiv:2310.05199v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.05199](http://arxiv.org/abs/2310.05199)

    本文提出了一种创新的解决方案，通过应用“专家的乘积”（PoE）技术来减轻强化学习中的长度偏差问题。在这个框架中，主要的专家关注理解人类意图，而偏见专家则致力于识别和捕捉长度偏差。

    

    人类反馈强化学习是重要的桥梁，将大型语言模型与人类和社会价值观对齐。这种对齐需要大量的人类反馈语料库来学习奖励模型，然后用于微调语言模型。然而，我们发现奖励模型常常会找到绕过预期目标的捷径，错误地假设人类更喜欢较长的回答。长度偏差的出现常常会导致模型倾向于较长的输出，但并不意味着这些输出中有更多有用的信息。在本文中，我们提出了一种创新的解决方案，应用了“专家的乘积”（PoE）技术来将奖励建模与序列长度的影响分离。在我们的框架中，主要的专家关注理解人类意图，而偏见专家则致力于识别和捕捉长度偏差。为了进一步增强偏见的学习，我们引入了扰动进入偏差部分。

    Reinforcement learning from human feedback serves as a crucial bridge, aligning large language models with human and societal values. This alignment requires a vast corpus of human feedback to learn a reward model, which is subsequently used to finetune language models. However, we have identified that the reward model often finds shortcuts to bypass its intended objectives, misleadingly assuming that humans prefer longer responses. The emergence of length bias often induces the model to favor longer outputs, yet it doesn't equate to an increase in helpful information within these outputs. In this paper, we propose an innovative solution, applying the Product-of-Experts (PoE) technique to separate reward modeling from the influence of sequence length. In our framework, the main expert concentrates on understanding human intents, while the biased expert targets the identification and capture of length bias. To further enhance the learning of bias, we introduce perturbations into the bia
    
[^60]: TEMPO: 基于提示的生成式预训练变换器模型用于时间序列预测

    TEMPO: Prompt-based Generative Pre-trained Transformer for Time Series Forecasting. (arXiv:2310.04948v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.04948](http://arxiv.org/abs/2310.04948)

    本文提出了一个新的框架 TEMPO，通过利用时间序列任务的两个重要归纳偏差，即将复杂交互分解和引入基于选择的提示来有效学习时间序列表示。

    

    在过去的十年中，深度学习在时间序列建模方面取得了显著进展。尽管在取得最先进的结果的同时，最好的架构在不同应用和领域之间差异很大。与此同时，在自然语言处理方面，生成式预训练变换器(GPT)通过训练一个通用模型在各种文本数据集上展现出了令人印象深刻的性能。有趣的是，探索是否GPT类型的架构可以对时间序列产生有效的影响，捕捉其内在动态属性并显著提高准确性。在本文中，我们提出了一个新颖的框架TEMPO，可以有效地学习时间序列表示。我们专注于利用时间序列任务的两种重要归纳偏差来预训练模型：(i) 对趋势、季节和残差成分复杂交互的分解；和(ii) 提出基于选择的提示以便于非分布自适应。

    The past decade has witnessed significant advances in time series modeling with deep learning. While achieving state-of-the-art results, the best-performing architectures vary highly across applications and domains. Meanwhile, for natural language processing, the Generative Pre-trained Transformer (GPT) has demonstrated impressive performance via training one general-purpose model across various textual datasets. It is intriguing to explore whether GPT-type architectures can be effective for time series, capturing the intrinsic dynamic attributes and leading to significant accuracy improvements. In this paper, we propose a novel framework, TEMPO, that can effectively learn time series representations. We focus on utilizing two essential inductive biases of the time series task for pre-trained models: (i) decomposition of the complex interaction between trend, seasonal and residual components; and (ii) introducing the selection-based prompts to facilitate distribution adaptation in non-
    
[^61]: 噪声扰动下的有效口号生成

    Effective Slogan Generation with Noise Perturbation. (arXiv:2310.04472v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.04472](http://arxiv.org/abs/2310.04472)

    本研究引入了基于噪声扰动的新方法，利用预训练的transformer T5模型生成独特且连贯的口号，同时将公司和品牌的描述纳入到生成过程中。结果表明，该方法在口号生成方面取得了良好的效果。

    

    口号在建立公司品牌形象中起着至关重要的作用。口号被期望以令人难忘和讨人喜欢的方式反映公司的愿景和品牌的价值主张。自动化生成具有这些特点的口号是具有挑战性的。以往的研究发展和测试了具有句法控制和摘要模型的口号生成，但这些模型无法生成独特的口号。我们引入了一种新颖的方法，利用预训练的transformer T5模型和新提出的1:N匹配对数据集的噪声扰动。该方法在生成独特且连贯的口号方面起到了促进作用。此外，该方法将公司和品牌的描述纳入到口号生成中。我们根据ROUGE1、ROUGEL和余弦相似性指标评估生成的口号，并通过人为主体评估它们的独特性、连贯性和流畅性。结果显示o

    Slogans play a crucial role in building the brand's identity of the firm. A slogan is expected to reflect firm's vision and brand's value propositions in memorable and likeable ways. Automating the generation of slogans with such characteristics is challenging. Previous studies developted and tested slogan generation with syntactic control and summarization models which are not capable of generating distinctive slogans. We introduce a a novel apporach that leverages pre-trained transformer T5 model with noise perturbation on newly proposed 1:N matching pair dataset. This approach serves as a contributing fator in generting distinctive and coherent slogans. Turthermore, the proposed approach incorporates descriptions about the firm and brand into the generation of slogans. We evaluate generated slogans based on ROUGE1, ROUGEL and Cosine Similarity metrics and also assess them with human subjects in terms of slogan's distinctiveness, coherence, and fluency. The results demonstrate that o
    
[^62]: MetaTool基准：决定是否使用工具和选择使用哪个工具。

    MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use. (arXiv:2310.03128v1 [cs.SE])

    [http://arxiv.org/abs/2310.03128](http://arxiv.org/abs/2310.03128)

    本文提出了一个名为MetaTool的基准，旨在评估大型语言模型（LLMs）是否具有工具使用意识并且能够正确选择工具。基准中包含一个名为ToolE的数据集，其中包含各种类型的用户查询，用于触发LLMs使用工具。

    

    大型语言模型（LLMs）由于其出色的自然语言处理（NLP）能力而受到了广泛关注。最近，许多研究关注LLMs的工具利用能力。它们主要研究了LLMs如何有效地与给定的特定工具合作。然而，在LLMs充当智能体的场景中，例如AutoGPT和MetaGPT应用中，LLMs被期望参与涉及是否使用工具以及从可用工具集中选择最合适的工具来满足用户请求的复杂决策过程。因此，在本文中，我们介绍了MetaTool，这是一个用于评估LLMs是否具有工具使用意识并且能够正确选择工具的基准。具体而言，我们在该基准中创建了一个名为ToolE的数据集。该数据集包含以触发LLMs使用工具的提示形式出现的各种类型的用户查询，包括单一工具和多种工具。

    Large language models (LLMs) have garnered significant attention due to their impressive natural language processing (NLP) capabilities. Recently, many studies have focused on the tool utilization ability of LLMs. They primarily investigated how LLMs effectively collaborate with given specific tools. However, in scenarios where LLMs serve as intelligent agents, as seen in applications like AutoGPT and MetaGPT, LLMs are expected to engage in intricate decision-making processes that involve deciding whether to employ a tool and selecting the most suitable tool(s) from a collection of available tools to fulfill user requests. Therefore, in this paper, we introduce MetaTool, a benchmark designed to evaluate whether LLMs have tool usage awareness and can correctly choose tools. Specifically, we create a dataset called ToolE within the benchmark. This dataset contains various types of user queries in the form of prompts that trigger LLMs to use tools, including both single-tool and multi-too
    
[^63]: 分层评估框架：人工评估的最佳实践

    Hierarchical Evaluation Framework: Best Practices for Human Evaluation. (arXiv:2310.01917v1 [cs.CL])

    [http://arxiv.org/abs/2310.01917](http://arxiv.org/abs/2310.01917)

    这篇论文提出了一个分层评估框架，解决了自然语言处理中人工评估指标不统一的问题，并应用于机器阅读理解系统的评估，突出了输入与输出质量之间的关联。

    

    人工评估在自然语言处理（NLP）中起着至关重要的作用，它评估了开发系统的质量和相关性，从而促进了系统的改进。然而，在NLP中缺乏广泛接受的人工评估指标，阻碍了不同系统之间的公平比较和建立普遍的评估标准。通过对现有文献中的人工评估指标进行广泛分析，我们发现了NLP评估方法中的几个缺口。这些缺口成为我们开发自己的分层评估框架的动力。所提出的框架具有显著优势，特别是在提供更全面的NLP系统性能表示方面。我们将此框架应用于评估开发的机器阅读理解系统，该系统在人工智能与人类的共生模型中被使用。结果突出了输入与输出质量之间的关联，强调了评估系统性能的必要性。

    Human evaluation plays a crucial role in Natural Language Processing (NLP) as it assesses the quality and relevance of developed systems, thereby facilitating their enhancement. However, the absence of widely accepted human evaluation metrics in NLP hampers fair comparisons among different systems and the establishment of universal assessment standards. Through an extensive analysis of existing literature on human evaluation metrics, we identified several gaps in NLP evaluation methodologies. These gaps served as motivation for developing our own hierarchical evaluation framework. The proposed framework offers notable advantages, particularly in providing a more comprehensive representation of the NLP system's performance. We applied this framework to evaluate the developed Machine Reading Comprehension system, which was utilized within a human-AI symbiosis model. The results highlighted the associations between the quality of inputs and outputs, underscoring the necessity to evaluate 
    
[^64]: 使用分块Transformer的环形注意力解决近无限上下文问题

    Ring Attention with Blockwise Transformers for Near-Infinite Context. (arXiv:2310.01889v1 [cs.CL])

    [http://arxiv.org/abs/2310.01889](http://arxiv.org/abs/2310.01889)

    本论文提出了一种新颖的环形注意力方法，通过分块计算和通信重叠的方式处理长序列，解决了Transformer在处理长序列时的内存限制问题。实验证明该方法能够有效地消除单个设备对内存的约束，使得训练和推理的序列长度能够更长。

    

    Transformer已经成为许多最先进的人工智能模型的首选架构，在广泛的人工智能应用中展示出了非凡的性能。然而，Transformer对内存的需求限制了它处理长序列的能力，因此对于涉及扩展序列或长期依赖的任务而言存在挑战。我们提出了一种独特的方法，即环形注意力(Ring Attention)，它利用自注意力的分块计算将长序列分布到多个设备上，同时将关键-值块的通信与分块注意力的计算重叠。通过处理更长的输入序列同时保持内存效率，环形注意力使得训练和推理的序列比之前的内存高效Transformer能够多出设备数量倍，有效地消除了单个设备对内存的约束。在语言模型任务上进行的大量实验证明了这种方法的有效性。

    Transformers have emerged as the architecture of choice for many state-of-the-art AI models, showcasing exceptional performance across a wide range of AI applications. However, the memory demands imposed by Transformers limit their ability to handle long sequences, thereby creating challenges for tasks involving extended sequences or long-term dependencies. We present a distinct approach, Ring Attention, which leverages blockwise computation of self-attention to distribute long sequences across multiple devices while concurrently overlapping the communication of key-value blocks with the computation of blockwise attention. By processing longer input sequences while maintaining memory efficiency, Ring Attention enables training and inference of sequences that are device count times longer than those of prior memory-efficient Transformers, effectively eliminating the memory constraints imposed by individual devices. Extensive experiments on language modeling tasks demonstrate the effecti
    
[^65]: 《GenAI对抗人性：生成式人工智能和大型语言模型的邪恶应用》

    GenAI Against Humanity: Nefarious Applications of Generative Artificial Intelligence and Large Language Models. (arXiv:2310.00737v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2310.00737](http://arxiv.org/abs/2310.00737)

    这篇论文探讨了生成式人工智能和大型语言模型的潜在滥用，呼吁认识到这些挑战的紧迫性。研究揭示了这些技术在深度伪造、合成身份恶意活动以及虚假信息和欺诈方面可能带来的社会影响。

    

    生成式人工智能（GenAI）和大型语言模型（LLM）是技术的奇迹，以其在自然语言处理和多模式内容生成方面的卓越能力而受到赞扬，它们承诺带来一个变革的未来。但就像所有强大的工具一样，它们也有其阴影存在。想象一下生活在一个深度伪造与现实无法区分、合成身份组织恶意活动、以及有着无与伦比精确度的有针对性的虚假信息或欺诈手法的世界。欢迎来到GenAI应用的黑暗面。本文不仅是探索GenAI和LLMs潜在滥用的旅程，也是呼吁认识到面临的挑战的紧迫性。在我们航行于虚假信息活动、恶意内容生成与精密恶意软件构建的海洋中，我们将揭示这场我们正在见证的GenAI革命中的社会影响。

    Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs) are marvels of technology; celebrated for their prowess in natural language processing and multimodal content generation, they promise a transformative future. But as with all powerful tools, they come with their shadows. Picture living in a world where deepfakes are indistinguishable from reality, where synthetic identities orchestrate malicious campaigns, and where targeted misinformation or scams are crafted with unparalleled precision. Welcome to the darker side of GenAI applications. This article is not just a journey through the meanders of potential misuse of GenAI and LLMs, but also a call to recognize the urgency of the challenges ahead. As we navigate the seas of misinformation campaigns, malicious content generation, and the eerie creation of sophisticated malware, we'll uncover the societal implications that ripple through the GenAI revolution we are witnessing. From AI-powered botnets on social med
    
[^66]: 对文档级关系抽取的综合调查（2016-2022）

    A Comprehensive Survey of Document-level Relation Extraction (2016-2022). (arXiv:2309.16396v1 [cs.CL])

    [http://arxiv.org/abs/2309.16396](http://arxiv.org/abs/2309.16396)

    这篇综述论文介绍了文档级关系抽取（DocRE）的最新进展，与句子级关系抽取相比，DocRE提供了更广泛的上下文分析，涉及跨越多个句子或段落的关系抽取，可用于构建和自动填充知识库。

    

    文档级关系抽取（DocRE）是自然语言处理（NLP）中一个活跃研究领域，涉及识别和抽取实体之间的关系，超越句子边界。与传统的句子级关系抽取相比，DocRE提供了更广泛的上下文分析，更具挑战性，因为它涉及识别可能跨越多个句子或段落的关系。这个任务在构建和自动填充知识库方面越来越受关注，以从非结构化的大规模文档（例如科学论文、法律合同或新闻文章）中自动获取关系，以便更好地理解实体之间的关系。本文旨在全面介绍这一领域的最新进展，突出其与句子级关系抽取的不同应用。

    Document-level relation extraction (DocRE) is an active area of research in natural language processing (NLP) concerned with identifying and extracting relationships between entities beyond sentence boundaries. Compared to the more traditional sentence-level relation extraction, DocRE provides a broader context for analysis and is more challenging because it involves identifying relationships that may span multiple sentences or paragraphs. This task has gained increased interest as a viable solution to build and populate knowledge bases automatically from unstructured large-scale documents (e.g., scientific papers, legal contracts, or news articles), in order to have a better understanding of relationships between entities. This paper aims to provide a comprehensive overview of recent advances in this field, highlighting its different applications in comparison to sentence-level relation extraction.
    
[^67]: DiLu: 基于大型语言模型的自动驾驶的知识驱动方法

    DiLu: A Knowledge-Driven Approach to Autonomous Driving with Large Language Models. (arXiv:2309.16292v1 [cs.RO])

    [http://arxiv.org/abs/2309.16292](http://arxiv.org/abs/2309.16292)

    DiLu是基于大型语言模型的自动驾驶系统，采用知识驱动方法，通过推理和反思模块进行决策，积累经验并具有显著的泛化能力。

    

    自动驾驶领域最近的进展依赖于数据驱动方法，虽然被广泛采用，但面临数据集偏见、过拟合和不可解释性等挑战。受人类驾驶知识驱动的启发，我们探索如何将类似的能力注入自动驾驶系统，并提出了一个集成互动环境、驾驶员代理和记忆组件的范例来解决这个问题。通过利用具有新兴能力的大型语言模型，我们提出了DiLu框架，它结合了推理模块和反思模块，使系统能够依据常识知识进行决策，并持续演化。大量实验证明DiLu能够积累经验，并且在泛化能力上比基于强化学习的方法具有显著优势。此外，DiLu能够直接从真实世界数据集中获得经验。

    Recent advancements in autonomous driving have relied on data-driven approaches, which are widely adopted but face challenges including dataset bias, overfitting, and uninterpretability. Drawing inspiration from the knowledge-driven nature of human driving, we explore the question of how to instill similar capabilities into autonomous driving systems and summarize a paradigm that integrates an interactive environment, a driver agent, as well as a memory component to address this question. Leveraging large language models with emergent abilities, we propose the DiLu framework, which combines a Reasoning and a Reflection module to enable the system to perform decision-making based on common-sense knowledge and evolve continuously. Extensive experiments prove DiLu's capability to accumulate experience and demonstrate a significant advantage in generalization ability over reinforcement learning-based methods. Moreover, DiLu is able to directly acquire experiences from real-world datasets w
    
[^68]: PRiSM: 使用关系感知分数校准增强低资源文档级关系抽取

    PRiSM: Enhancing Low-Resource Document-Level Relation Extraction with Relation-Aware Score Calibration. (arXiv:2309.13869v1 [cs.CL] CROSS LISTED)

    [http://arxiv.org/abs/2309.13869](http://arxiv.org/abs/2309.13869)

    PRiSM是一种增强低资源文档级关系抽取的方法，通过关系感知分数校准来提高模型性能，成功地降低了在低资源环境下训练模型时的校准误差。

    

    文档级关系抽取（DocRE）旨在提取文档中所有实体对的关系。在DocRE中的一个关键挑战是注释这类数据的成本，需要大量的人力投入。因此，我们调查了低资源环境中的DocRE情况，并发现现有的在少量数据上训练的模型过高估计了NA（"no relation"）标签，导致性能受限。在这项工作中，我们从校准的角度来解决这个问题，提出了PRiSM，它可以根据关系语义信息来适应logits。我们在三个DocRE数据集上评估了我们的方法，并证明了将现有模型与PRiSM集成可以提高性能，F1分数提高了26.38%，而当用约3%的数据进行训练时，校准误差下降了36倍。代码可以在https://github.com/brightjade/PRiSM公开获取。

    Document-level relation extraction (DocRE) aims to extract relations of all entity pairs in a document. A key challenge in DocRE is the cost of annotating such data which requires intensive human effort. Thus, we investigate the case of DocRE in a low-resource setting, and we find that existing models trained on low data overestimate the NA ("no relation") label, causing limited performance. In this work, we approach the problem from a calibration perspective and propose PRiSM, which learns to adapt logits based on relation semantic information. We evaluate our method on three DocRE datasets and demonstrate that integrating existing models with PRiSM improves performance by as much as 26.38 F1 score, while the calibration error drops as much as 36 times when trained with about 3% of data. The code is publicly available at https://github.com/brightjade/PRiSM.
    
[^69]: AceGPT：将大型语言模型本地化为阿拉伯文

    AceGPT, Localizing Large Language Models in Arabic. (arXiv:2309.12053v1 [cs.CL])

    [http://arxiv.org/abs/2309.12053](http://arxiv.org/abs/2309.12053)

    本研究旨在开发阿拉伯文的本地化大型语言模型(AceGPT)，通过预训练、监督微调和增强学习方法来培养具备文化意识和价值观一致的阿拉伯文模型，以满足阿拉伯语社区特定应用需求。评估结果表明，AceGPT在各项基准测试中都是最先进的阿拉伯文模型。

    

    本文探讨了开发适用于阿拉伯文的本地化大型语言模型(LLM)的迫切需求和方法论，阿拉伯文具有独特的文化特征，这些特征目前的主流模型如ChatGPT并未充分解决。在考虑文化敏感性和本地价值观时还存在关键问题。为此，本文提出了一个打包解决方案，包括进一步使用阿拉伯文本进行预训练、使用本地阿拉伯指令和阿拉伯语GPT-4回应进行监督微调(SFT)，以及使用对本地文化和价值观敏感的奖励模型进行增强学习与人工智能反馈(RLAIF)。目标是训练具备文化意识和与价值观一致的阿拉伯文LLM，以满足阿拉伯语社区多样化的特定应用需求。广泛的评估表明，所得到的名为AceGPT的阿拉伯文LLM在各种基准测试中均是最先进的。

    This paper explores the imperative need and methodology for developing a localized Large Language Model (LLM) tailored for Arabic, a language with unique cultural characteristics that are not adequately addressed by current mainstream models like ChatGPT. Key concerns additionally arise when considering cultural sensitivity and local values. To this end, the paper outlines a packaged solution, including further pre-training with Arabic texts, supervised fine-tuning (SFT) using native Arabic instructions and GPT-4 responses in Arabic, and reinforcement learning with AI feedback (RLAIF) using a reward model that is sensitive to local culture and values. The objective is to train culturally aware and value-aligned Arabic LLMs that can serve the diverse application-specific needs of Arabic-speaking communities.  Extensive evaluations demonstrated that the resulting LLM called `\textbf{AceGPT}' is the SOTA open Arabic LLM in various benchmarks, including instruction-following benchmark (i.e
    
[^70]: MBR和QE微调：对最佳和最昂贵的解码方法进行训练时蒸馏

    MBR and QE Finetuning: Training-time Distillation of the Best and Most Expensive Decoding Methods. (arXiv:2309.10966v1 [cs.CL])

    [http://arxiv.org/abs/2309.10966](http://arxiv.org/abs/2309.10966)

    本文提出了MBR微调和QE微调方法，将训练时的质量提升蒸馏到基准模型中，从而在推断时使用高效的解码算法。实验证明，这些微调方法能显著提升模型性能，甚至超过基准模型。

    

    最近在自然语言生成（NLG）任务的解码方法研究中表明，传统的波束搜索和贪婪解码算法并不是最优的，因为模型概率不总是与人类偏好一致。为了解决模型困惑度与质量不匹配的问题，提出了一些更强的解码方法，包括质量估计（QE）重排序和最小贝叶斯风险（MBR）解码。尽管这些解码方法实现了最先进的性能，但计算成本过高。在这项工作中，我们提出了MBR微调和QE微调，这些微调方法在训练时蒸馏了这些解码方法的质量提升，在推断时使用高效的解码算法。通过使用神经机器翻译（NMT）这一典型的NLG任务，我们表明即使进行自训练，这些微调方法的性能仍明显优于基准模型。此外，当使用外部LLM作为教师模型时，这些微调方法也表现出了卓越的性能。

    Recent research in decoding methods for Natural Language Generation (NLG) tasks has shown that the traditional beam search and greedy decoding algorithms are not optimal, because model probabilities do not always align with human preferences. Stronger decoding methods, including Quality Estimation (QE) reranking and Minimum Bayes' Risk (MBR) decoding, have since been proposed to mitigate the model-perplexity-vs-quality mismatch. While these decoding methods achieve state-of-the-art performance, they are prohibitively expensive to compute. In this work, we propose MBR finetuning and QE finetuning which distill the quality gains from these decoding methods at training time, while using an efficient decoding algorithm at inference time. Using the canonical NLG task of Neural Machine Translation (NMT), we show that even with self-training, these finetuning methods significantly outperform the base model. Moreover, when using an external LLM as a teacher model, these finetuning methods outp
    
[^71]: MINT: 评估在与工具和语言反馈进行多轮交互中的LLMs的能力

    MINT: Evaluating LLMs in Multi-turn Interaction with Tools and Language Feedback. (arXiv:2309.10691v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.10691](http://arxiv.org/abs/2309.10691)

    MINT是一个评估LLMs在多轮交互中解决任务能力的基准，通过使用工具和利用用户的自然语言反馈。它解决了当前评估协议忽略细致互动和低估自然语言反馈的问题，促进了研究基准评估和实际应用之间的一致性。

    

    为了解决复杂任务，大语言模型（LLMs）通常需要与用户进行多轮交互，有时候辅以外部工具的帮助。然而，当前的评估协议常常强调用单轮交流的基准性能，忽略了用户、LLMs和外部工具之间的细致互动，并低估了用户的自然语言反馈的重要性。这些疏忽导致了研究基准评估结果与实际应用情况之间的差异。我们引入了MINT，这是一个通过使用工具和利用用户的自然语言反馈来评估LLMs解决多轮交互任务能力的基准。为了保证可重复性，我们提供了一个评估框架，在这个框架中，LLMs可以通过执行Python代码来访问工具，并接收由GPT-4模拟的用户的自然语言反馈。我们重新利用了一系列多样的已建立评估数据集，重点关注推理、编码和决策方面。

    To solve complex tasks, large language models (LLMs) often require multiple rounds of interactions with the user, sometimes assisted by external tools. However, current evaluation protocols often emphasize benchmark performance with single-turn exchanges, neglecting the nuanced interactions among the user, LLMs, and external tools, while also underestimating the importance of natural language feedback from users. These oversights contribute to discrepancies between research benchmark evaluations and real-world use cases. We introduce MINT, a benchmark that evaluates LLMs' ability to solve tasks with multi-turn interactions by (1) using tools and (2) leveraging natural language feedback. To ensure reproducibility, we provide an evaluation framework where LLMs can access tools by executing Python code and receive users' natural language feedback simulated by GPT-4. We repurpose a diverse set of established evaluation datasets focusing on reasoning, coding, and decision-making and careful
    
[^72]: DePT:分解提示调整以实现参数高效微调

    DePT: Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning. (arXiv:2309.05173v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.05173](http://arxiv.org/abs/2309.05173)

    DePT通过将软提示分解为较短的软提示和一对低秩矩阵，并用两个不同的学习率来优化，以解决提示调整对训练和推理时间以及内存使用的影响，从而实现更好的性能。

    

    提示调整（PT）是一种将可训练的少量软提示向量附加到语言模型（LM）输入中的参数高效微调（PEFT）方法，已在各种任务和模型中显示出了有希望的结果。 与其他PEFT方法相比，PT的竞争性能可以在可训练参数更少的情况下保持，并且随着模型规模的扩大，其参数并不会显著增加。 但是，PT引入了额外的软提示标记，导致输入序列变长，这对于Transformer的二次复杂度而言，在训练和推理时间以及内存使用方面会产生显著影响。 这对于面临大量每日查询的大型语言模型（LLMs）尤其令人担忧。

    Prompt tuning (PT), where a small amount of trainable soft (continuous) prompt vectors is affixed to the input of language models (LM), has shown promising results across various tasks and models for parameter-efficient fine-tuning (PEFT). PT stands out from other PEFT approaches because it maintains competitive performance with fewer trainable parameters and does not drastically scale up its parameters as the model size expands. However, PT introduces additional soft prompt tokens, leading to longer input sequences, which significantly impacts training and inference time and memory usage due to the Transformer's quadratic complexity. Particularly concerning for Large Language Models (LLMs) that face heavy daily querying. To address this issue, we propose Decomposed Prompt Tuning (DePT), which decomposes the soft prompt into a shorter soft prompt and a pair of low-rank matrices that are then optimised with two different learning rates. This allows DePT to achieve better performance whi
    
[^73]: PromptTTS 2: 使用文本提示描述和生成声音

    PromptTTS 2: Describing and Generating Voices with Text Prompt. (arXiv:2309.02285v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2309.02285](http://arxiv.org/abs/2309.02285)

    PromptTTS 2是一种使用文本提示来描述和生成声音的方法，通过变化网络提供声音的可变性信息，并利用大型语言模型（LLM）来生成高质量的文本提示。

    

    语音传达的信息比文字更丰富，因为相同的词可以以不同的声音表达不同的信息。与依赖语音提示（参考语音）来实现声音可变性的传统文本转语音（TTS）方法相比，使用文本提示（描述）更加用户友好，因为语音提示可能难以找到或根本不存在。基于文本提示的TTS方法面临两个主要挑战：1）一对多问题，即文本提示无法描述声音可变性的所有细节；2）文本提示数据集的有限可用性，需要供应商和大量数据标注成本来编写语音的文本提示。在这项工作中，我们介绍了PromptTTS 2来解决这些挑战，该系统使用变化网络提供文本提示无法捕捉的声音可变性信息，并使用大型语言模型（LLM）来生成高质量的文本提示。

    Speech conveys more information than text, as the same word can be uttered in various voices to convey diverse information. Compared to traditional text-to-speech (TTS) methods relying on speech prompts (reference speech) for voice variability, using text prompts (descriptions) is more user-friendly since speech prompts can be hard to find or may not exist at all. TTS approaches based on the text prompt face two main challenges: 1) the one-to-many problem, where not all details about voice variability can be described in the text prompt, and 2) the limited availability of text prompt datasets, where vendors and large cost of data labeling are required to write text prompts for speech. In this work, we introduce PromptTTS 2 to address these challenges with a variation network to provide variability information of voice not captured by text prompts, and a prompt generation pipeline to utilize the large language models (LLM) to compose high quality text prompts. Specifically, the variatio
    
[^74]: 架桥情绪角色标注和基于评估的情绪分析

    Bridging Emotion Role Labeling and Appraisal-based Emotion Analysis. (arXiv:2309.02092v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.02092](http://arxiv.org/abs/2309.02092)

    本文介绍了情绪角色标注和基于评估的情绪分析之间的桥梁。情绪角色标注在情绪分类的基础上添加了对提及实体的视角，提取了对应情绪原因的文本范围。情绪和事件具有两种关系：情绪本身就是一种事件，并且情绪是由事件引起的。这一概念对于情绪角色标注的研究具有重要意义。

    

    文本中的情绪分析涵盖了各种自然语言处理任务，其共同目标是让计算机理解情绪。其中最流行的是情绪分类，其中将一个或多个情绪分配给预定义的文本单位。而情绪角色标注则添加了提及实体的视角，并提取与情绪原因相对应的文本范围。相关的情绪理论达成一个重要观点：情绪是由某些内部或外部事件引起并包含了多个子组成部分，包括主观感受和认知评估。因此，我们认为情绪和事件有两种关系。 （1）情绪本身就是事件；这个视角是情绪角色标注中的基础。 （2）情绪是由事件引起的；这个视角则需要研究如何将心理评估纳入其中。

    The term emotion analysis in text subsumes various natural language processing tasks which have in common the goal to enable computers to understand emotions. Most popular is emotion classification in which one or multiple emotions are assigned to a predefined textual unit. While such setting is appropriate to identify the reader's or author's emotion, emotion role labeling adds the perspective of mentioned entities and extracts text spans that correspond to the emotion cause. The underlying emotion theories agree on one important point; that an emotion is caused by some internal or external event and comprises several subcomponents, including the subjective feeling and a cognitive evaluation. We therefore argue that emotions and events are related in two ways. (1) Emotions are events; and this perspective is the fundament in NLP for emotion role labeling. (2) Emotions are caused by events; a perspective that is made explicit with research how to incorporate psychological appraisal the
    
[^75]: StoryBench: 一个多方面的连续故事可视化基准

    StoryBench: A Multifaceted Benchmark for Continuous Story Visualization. (arXiv:2308.11606v1 [cs.CV])

    [http://arxiv.org/abs/2308.11606](http://arxiv.org/abs/2308.11606)

    StoryBench是一个新的，具有挑战性的多任务基准，用于评估文本到视频模型。它包括动作执行，故事延续和故事生成三个难度逐渐增加的视频生成任务。我们提出了一些小而强大的文本到视频基线，并展示了它们的好处。

    

    从文本提示生成视频故事是一项复杂的任务。除了具有高质量的视觉效果外，视频还需要在整个帧中保持与文本提示序列的一致。创建视频生成的基准需要在时间上对数据进行注释，这与视频数据集中经常使用的单个标题形成对比。为了填补这一空白，我们收集了三个现有数据集上的全面的人类注释，并推出了StoryBench：一个新的，具有挑战性的多任务基准，可可靠地评估即将发布的文本到视频模型。我们的基准包括三个难度逐渐增加的视频生成任务：动作执行，在从一个条件视频开始生成下一个动作；故事延续，在从一个条件视频开始执行一系列动作；故事生成，仅从文本提示中生成一个视频。我们评估了一些小而强大的文本到视频基线，并展示了它们的好处。

    Generating video stories from text prompts is a complex task. In addition to having high visual quality, videos need to realistically adhere to a sequence of text prompts whilst being consistent throughout the frames. Creating a benchmark for video generation requires data annotated over time, which contrasts with the single caption used often in video datasets. To fill this gap, we collect comprehensive human annotations on three existing datasets, and introduce StoryBench: a new, challenging multi-task benchmark to reliably evaluate forthcoming text-to-video models. Our benchmark includes three video generation tasks of increasing difficulty: action execution, where the next action must be generated starting from a conditioning video; story continuation, where a sequence of actions must be executed starting from a conditioning video; and story generation, where a video must be generated from only text prompts. We evaluate small yet strong text-to-video baselines, and show the benefit
    
[^76]: 作为用户模拟器的大型语言模型

    Large Language Model as a User Simulator. (arXiv:2308.11534v1 [cs.CL])

    [http://arxiv.org/abs/2308.11534](http://arxiv.org/abs/2308.11534)

    本文创新性地将从真实人机对话中提取的人类问题作为学习目标，并且训练了一个用户模拟器UserGPT，并使用生成的高质量合成对话数据集RealChat来训练助手模型ReaLM。实验证明，ReaLM在多个基准测试中超过了基准模型。

    

    闭源ChatGPT的卓越性能引发了对其民主化的努力，借助真实用户和ChatGPT对话的努力取得了显著进展，Vicuna是一个很好的例子。然而，目前的Baize和UltraChat等努力主要依靠ChatGPT根据指令模拟人类行为，而不是真实的人类学习，导致范围有限，多样性减弱，缺乏真正的多轮对话动态。为了解决上述问题，我们创新性地把从真实人机对话中提取的人类问题作为学习目标，并训练一个用户模拟器UserGPT来生成高质量的以人为中心的合成对话数据集RealChat。随后，该数据集训练我们的助手模型ReaLM。实验证明，ReaLM在Vicuna-Bench和MT-Bench中均超过了基准模型。

    The unparalleled performance of closed-sourced ChatGPT has sparked efforts towards its democratization, with notable strides made by leveraging real user and ChatGPT conversations, as evidenced by Vicuna. However, while current endeavors like Baize and UltraChat aim to auto-generate conversational data due to challenges in gathering human participation, they primarily rely on ChatGPT to simulate human behaviors based on directives rather than genuine human learning. This results in a limited scope, diminished diversity, and an absence of genuine multi-round conversational dynamics. To address the above issues, we innovatively target human questions extracted from genuine human-machine conversations as a learning goal and train a user simulator, UserGPT, to produce a high-quality human-centric synthetic conversation dataset, RealChat. Subsequently, this dataset trains our assistant model, ReaLM. Experimentally, ReaLM outpaces baseline models in both Vicuna-Bench and MT-Bench by pairwise
    
[^77]: 使用大型语言模型从医学肿瘤学笔记中提取详细的肿瘤病史和治疗计划

    Extracting detailed oncologic history and treatment plan from medical oncology notes with large language models. (arXiv:2308.03853v1 [cs.CL])

    [http://arxiv.org/abs/2308.03853](http://arxiv.org/abs/2308.03853)

    本研究开发了一个详细的肿瘤学信息注释方案，使用大型语言模型从肿瘤学笔记中提取和推理复杂的修辞，并应用于乳腺癌进展笔记的语料库。

    

    医学护理和肿瘤学观察研究都需要全面了解患者的疾病进展和治疗历史，这些信息通常在临床记录中详细记录。尽管它们在肿瘤学中的重要作用，但目前没有针对这些记录中记录的多样信息进行完整封装的肿瘤学信息表示和注释方案。虽然大型语言模型（LLM）最近在各种医学自然语言处理任务中表现出色，但由于目前缺乏全面注释的肿瘤学数据集，对LLM在提取和推理肿瘤学笔记中的复杂修辞的广泛评估仍然不足。我们开发了一个详细的方案，用于注释肿瘤学文本信息，包括患者特征、肿瘤特征、测试、治疗和时间性。我们利用加利福尼亚大学旧金山分校的10个去标识化乳腺癌进展笔记语料库，应用了这个方案。

    Both medical care and observational studies in oncology require a thorough understanding of a patient's disease progression and treatment history, often elaborately documented in clinical notes. Despite their vital role, no current oncology information representation and annotation schema fully encapsulates the diversity of information recorded within these notes. Although large language models (LLMs) have recently exhibited impressive performance on various medical natural language processing tasks, due to the current lack of comprehensively annotated oncology datasets, an extensive evaluation of LLMs in extracting and reasoning with the complex rhetoric in oncology notes remains understudied. We developed a detailed schema for annotating textual oncology information, encompassing patient characteristics, tumor characteristics, tests, treatments, and temporality. Using a corpus of 10 de-identified breast cancer progress notes at University of California, San Francisco, we applied this
    
[^78]: CIDER: 上下文感知的短文本情感分析

    CIDER: Context sensitive sentiment analysis for short-form text. (arXiv:2307.07864v1 [cs.CL])

    [http://arxiv.org/abs/2307.07864](http://arxiv.org/abs/2307.07864)

    CIDER是一种上下文感知的短文本情感分析方法，通过从整个语料库中推断出情感词的倾向来评分个别文本，相比通用方法在天气推文集合上表现更优。

    

    研究人员通常对大量关于特定主题、主题或事件的短文本进行情感分析，如推文、Reddit帖子或报纸头条。通常使用通用情感分析方法，这些方法在平均意义上表现良好，但会忽略不同上下文中发生的意义变化，例如，“active”一词在“active lifestyle”和“active volcano”中具有非常不同的意图和倾向。本研究提出了一种新的方法，即CIDER（上下文感知词典和情感推理器），它进行上下文感知的情感分析，其中从整个语料库中推断出情感词的倾向，然后再用于评分个别文本。在本文中，我们详细介绍了CIDER算法，并证明它在大量关于天气的推文集合上优于最先进的通用情感分析方法。我们已将CIDER的实现以python代码的形式提供。

    Researchers commonly perform sentiment analysis on large collections of short texts like tweets, Reddit posts or newspaper headlines that are all focused on a specific topic, theme or event. Usually, general purpose sentiment analysis methods are used which perform well on average but miss the variation in meaning that happens across different contexts, for example, the word "active" has a very different intention and valence in the phrase "active lifestyle" versus "active volcano". This work presents a new approach, CIDER (Context Informed Dictionary and sEntiment Reasoner), which performs context sensitive sentiment analysis, where the valence of sentiment laden terms is inferred from the whole corpus before being used to score the individual texts. In this paper we detail the CIDER algorithm and demonstrate that it outperforms state-of-the-art generalist sentiment analysis on a large collection of tweets about the weather. We have made our implementation of CIDER available as a pyth
    
[^79]: 用于超出分布可泛化性的大型视觉语言模型压缩

    Distilling Large Vision-Language Model with Out-of-Distribution Generalizability. (arXiv:2307.03135v1 [cs.CV])

    [http://arxiv.org/abs/2307.03135](http://arxiv.org/abs/2307.03135)

    本文研究了针对大型视觉语言模型的模型压缩方法，将教师模型的视觉表示压缩到学生模型中。研究重点在于超出分布可泛化的问题，并提出了两个原则来增强学生模型的性能。

    

    大型视觉语言模型取得了出色的性能，但其规模和计算要求使它们在资源受限设备和时间敏感任务上的部署变得不切实际。模型压缩是创建更小、更快的模型以保持较大模型性能的有希望的方法。本文研究了将大型视觉语言模型中的视觉表示压缩到轻量级学生模型中的过程，使用小型或中型数据集。值得注意的是，本研究关注的是超出分布（OOD）可泛化的开放词汇问题，这在以往的模型压缩研究中被忽视了。我们从视觉和语言的角度提出了两个原则来增强学生模型的OOD可泛化性：（1）更好地模仿教师的视觉表示空间，并在视觉语言对齐方面谨慎地促进更好的一致性；（2）通过丰富学生模型的自举学习和数据扩充来提高OOD可泛化性。

    Large vision-language models have achieved outstanding performance, but their size and computational requirements make their deployment on resource-constrained devices and time-sensitive tasks impractical. Model distillation, the process of creating smaller, faster models that maintain the performance of larger models, is a promising direction towards the solution. This paper investigates the distillation of visual representations in large teacher vision-language models into lightweight student models using a smallor mid-scale dataset. Notably, this study focuses on open-vocabulary out-of-distribution (OOD) generalization, a challenging problem that has been overlooked in previous model distillation literature. We propose two principles from vision and language modality perspectives to enhance student's OOD generalization: (1) by better imitating teacher's visual representation space, and carefully promoting better coherence in vision-language alignment with the teacher; (2) by enric
    
[^80]: 对大型语言模型调查响应的质疑

    Questioning the Survey Responses of Large Language Models. (arXiv:2306.07951v1 [cs.CL])

    [http://arxiv.org/abs/2306.07951](http://arxiv.org/abs/2306.07951)

    本文使用美国人口普查局建立的全美社区调查（ACS）评估了十几个不同大小的语言模型，发现小型模型具有显著的位置和标签偏差，而模型大小的增加能减轻这种偏差，但无法根据US群体或任何可识别的群体趋势进行调整。

    

    随着大型语言模型的能力增强，研究人员开始以各种科学动机对这些模型进行调查。本文旨在通过美国人口普查局已经建立的全美社区调查（ACS），就模型的调查响应结果探究所能了解的内容。我们对十几个不同大小的模型进行了评估，这些模型的参数范围从几亿到一万亿不等，使用ACS的问题进行了数十万次的测试，系统地得出了两个主要模式。首先，小型模型存在明显的位置和标签偏差，例如偏向于采用标记为“A”的调查响应。随着模型尺寸的增加，A-偏差虽然有所减少，但也进展缓慢。其次，即使通过随机答案顺序来调整这种标记偏差，模型仍然不会趋向于美国人口统计数据或任何可识别的人口排序。相反，各种模型趋向于均匀随机化。

    As large language models increase in capability, researchers have started to conduct surveys of all kinds on these models with varying scientific motivations. In this work, we examine what we can learn from a model's survey responses on the basis of the well-established American Community Survey (ACS) by the U.S. Census Bureau. Evaluating more than a dozen different models, varying in size from a few hundred million to ten billion parameters, hundreds of thousands of times each on questions from the ACS, we systematically establish two dominant patterns. First, smaller models have a significant position and labeling bias, for example, towards survey responses labeled with the letter "A". This A-bias diminishes, albeit slowly, as model size increases. Second, when adjusting for this labeling bias through randomized answer ordering, models still do not trend toward US population statistics or those of any cognizable population. Rather, models across the board trend toward uniformly rando
    
[^81]: 通过词汇修剪实现高效的多语言语言模型压缩

    An Efficient Multilingual Language Model Compression through Vocabulary Trimming. (arXiv:2305.15020v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.15020](http://arxiv.org/abs/2305.15020)

    该论文提出了一种名为词汇修剪（VT）的方法，通过删除多语言语言模型中的不相关标记，将其压缩为目标语言模型。实验证明，词汇修剪可以在保持多语言模型性能的同时，降低了模型的大小。

    

    多语言语言模型（LM）已经成为自然语言处理中非英语语言的强大工具。然而，由于涵盖不同语言标记的词汇嵌入矩阵较大，多语言LM的模型参数仍然很大。相反，单一语言模型可以使用特定于语言的词汇在目标语言中训练，但这需要大量预算和可靠语料库才能从头开始实现高质量的语言模型。在本文中，我们提出了词汇修剪（VT）的方法，通过从词汇中删除不相关的标记，将多语言LM的词汇减少到目标语言。理论上，VT可以压缩任何现有的多语言LM，以在多语言LM涵盖的任何语言中构建单一语言模型。在我们的实验中，我们展示了VT可以保留多语言LM的原始性能，同时尺寸更小（通常只需原始词汇大小的约50％）。

    Multilingual language model (LM) have become a powerful tool in NLP especially for non-English languages. Nevertheless, model parameters of multilingual LMs remain large due to the larger embedding matrix of the vocabulary covering tokens in different languages. On the contrary, monolingual LMs can be trained in a target language with the language-specific vocabulary only, but this requires a large budget and availability of reliable corpora to achieve a high-quality LM from scratch. In this paper, we propose vocabulary-trimming (VT), a method to reduce a multilingual LM vocabulary to a target language by deleting irrelevant tokens from its vocabulary. In theory, VT can compress any existing multilingual LM to build monolingual LMs in any language covered by the multilingual LM. In our experiments, we show that VT can retain the original performance of the multilingual LM, while being smaller in size (in general around 50% of the original vocabulary size is enough) than the original mu
    
[^82]: 使用基于文献的语境化学习生成新的科学方向

    Learning to Generate Novel Scientific Directions with Contextualized Literature-based Discovery. (arXiv:2305.14259v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.14259](http://arxiv.org/abs/2305.14259)

    本文介绍了一种基于文献的发现方法，通过上下文化的学习生成新的科学方向，克服了标准方法在预测关联、忽略上下文等方面的局限性。模型使用了引文和知识图关系的网络，并使用大型语言模型进行评估，发现GPT4在生成创新思想方面表现出色。

    

    基于文献的发现（LBD）旨在通过挖掘论文并生成假设来发现新的科学知识。标准的LBD仅限于预测离散概念之间的两两关系（例如，药物和疾病的关联）。LBD还忽略了关键的上下文，例如实验设置（例如，药物评估的特定患者群体）和人类科学家考虑的背景知识和动机（例如，找到没有特定副作用的药物候选）。我们通过一种新颖的上下文化LBD（C-LBD）表述来解决这些局限性：以自然语言生成科学假设，同时将它们联系到控制假设搜索空间的上下文中。我们提出了一个建模框架，使用获得的引文和知识图关系的异构网络中的“灵感”，并创建了一个从论文中派生的新数据集。我们使用强大的大型语言模型（LLM）进行评估，发现GPT4倾向于生成具有创新性的思想。

    Literature-Based Discovery (LBD) aims to discover new scientific knowledge by mining papers and generating hypotheses. Standard LBD is limited to predicting pairwise relations between discrete concepts (e.g., drug-disease links). LBD also ignores critical contexts like experimental settings (e.g., a specific patient population where a drug is evaluated) and background knowledge and motivations that human scientists consider (e.g., to find a drug candidate without specific side effects). We address these limitations with a novel formulation of contextualized-LBD (C-LBD): generating scientific hypotheses in natural language, while grounding them in a context that controls the hypothesis search space. We present a modeling framework using retrieval of ``inspirations'' from a heterogeneous network of citations and knowledge graph relations, and create a new dataset derived from papers. Our evaluations with powerful large language models (LLMs) reveal that GPT4 tends to generate ideas with 
    
[^83]: 用大型语言模型评估摘要的事实一致性

    Evaluating Factual Consistency of Summaries with Large Language Models. (arXiv:2305.14069v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.14069](http://arxiv.org/abs/2305.14069)

    本研究通过直接提示大型语言模型（LLMs），探索评估摘要的事实一致性。实验证明，在各种设置中，提示LLMs能够在二分类准确性方面超过以前最佳的事实性系统，最高可提高12.2个绝对点。

    

    在摘要研究中，检测事实错误一直是一个重要而具有挑战性的课题。受到大型语言模型（LLMs）新兴的能力的启发，我们探索通过直接提示LLMs来评估摘要的事实一致性。我们进行了一项全面的实证研究，评估LLMs作为事实一致性评估器的能力，其中包括(1)分析不同的LLMs，如GPT模型系列和Flan-T5;(2)研究各种提示方法，包括vanilla提示、思维链提示和逐句提示方法来处理长篇摘要;(3)评估多个摘要系统生成的多样化摘要，范围从预变压器方法到SOTA预训练模型。我们的实验表明，在所有设置中，提示LLMs能够优于先前最佳的事实性系统，对于不一致性的二分类准确性，提高了最多12.2个绝对点。

    Detecting factual errors in summaries has been an important and challenging subject in summarization research. Inspired by the emergent ability of large language models (LLMs), we explore evaluating factual consistency of summaries by directly prompting LLMs. We present a comprehensive empirical study to assess the ability of LLMs as factual consistency evaluators, which consists of (1) analyzing different LLMs such as the GPT model series and Flan-T5; (2) investigating a variety of prompting methods including vanilla prompting, chain-of-thought prompting, and a sentence-by-sentence prompting method to tackle long summaries; and (3) evaluating on diverse summaries generated by multiple summarization systems, ranging from pre-transformer methods to SOTA pretrained models. Our experiments demonstrate that prompting LLMs is able to outperform the previous best factuality systems in all settings, by up to 12.2 absolute points in terms of the binary classification accuracy on inconsistency 
    
[^84]: 声明提示下的可满足性辅助语言模型

    Satisfiability-Aided Language Models Using Declarative Prompting. (arXiv:2305.09656v1 [cs.CL])

    [http://arxiv.org/abs/2305.09656](http://arxiv.org/abs/2305.09656)

    本文提出了一种利用自动定理证明器和声明性任务规范的可满足性辅助语言建模方法，可以提高大型语言模型的推理能力。

    

    本文提出了一种新的可满足性辅助语言建模方法，用于提高大型语言模型的推理能力。我们使用一个大型语言模型生成一个声明性任务规范，并利用一个现成的自动定理证明器得出最终答案。该方法具有两个关键优点：第一，声明性规范比推理步骤更接近问题描述，因此大型语言模型可以更准确地解析它；第二，通过将实际推理任务委托给自动定理证明器，我们的方法可以保证正确性。

    Prior work has combined chain-of-thought prompting in large language models (LLMs) with programmatic representations to perform effective and transparent reasoning. While such an approach works very well for tasks that only require forward reasoning (e.g., straightforward arithmetic), it is less effective for constraint solving tasks that require more sophisticated planning and search. In this paper, we propose a new satisfiability-aided language modeling approach for improving the reasoning capabilities of LLMs. We use an LLM to generate a declarative task specification rather than an imperative program and leverage an off-the-shelf automated theorem prover to derive the final answer. This approach has two key advantages. The declarative specification is closer to the problem description than the reasoning steps are, so the LLM can parse it more accurately. Furthermore, by offloading the actual reasoning task to an automated theorem prover, our approach can guarantee the correctness o
    
[^85]: 使用以实体为中心的数据来衡量刻板印象

    Measuring Stereotypes using Entity-Centric Data. (arXiv:2305.09548v1 [cs.CL])

    [http://arxiv.org/abs/2305.09548](http://arxiv.org/abs/2305.09548)

    本文提出并评估了三种新的以实体为中心的方法，展示了这些模型在预测人们如何将身份标签应用于自己和他人以及量化突出的社会维度（如性别）的刻板印象方面优于现有方法。

    

    刻板印象影响我们如何展示自己和他人，从而影响我们的行为。因此，衡量刻板印象非常重要。最近的研究使用分布语义模型（DSM）（如BERT）中嵌入的投影来进行这些测量。然而，DSMs捕捉到的认知联想不一定与刻板印象的人际性质相关。在这里，我们提出并评估了三种新的以实体为中心的方法，从Twitter和Wikipedia传记中学习刻板印象。通过利用多个短语应用于同一个人的事实来训练模型，扩大了学习联想的人本身中心性。我们证明了这些模型在预测人们如何将身份标签应用于自己和他人以及量化突出的社会维度（如性别）的刻板印象方面优于现有方法。通过一个案例研究，我们还展示了这些模型对未来计算社会科学问题的实用性。

    Stereotypes inform how we present ourselves and others, and in turn how we behave. They are thus important to measure. Recent work has used projections of embeddings from Distributional Semantic Models (DSMs), such as BERT, to perform these measurements. However, DSMs capture cognitive associations that are not necessarily relevant to the interpersonal nature of stereotyping. Here, we propose and evaluate three novel, entity-centric methods for learning stereotypes from Twitter and Wikipedia biographies. Models are trained by leveraging the fact that multiple phrases are applied to the same person, magnifying the person-centric nature of the learned associations. We show that these models outperform existing approaches to stereotype measurement with respect to 1) predicting which identities people apply to themselves and others, and 2) quantifying stereotypes on salient social dimensions (e.g. gender). Via a case study, we also show the utility of these models for future questions in c
    
[^86]: ChatGPT是一个好的因果推断器吗？全面评估

    Is ChatGPT a Good Causal Reasoner? A Comprehensive Evaluation. (arXiv:2305.07375v1 [cs.CL])

    [http://arxiv.org/abs/2305.07375](http://arxiv.org/abs/2305.07375)

    本文对ChatGPT的因果推理能力进行了首次全面评估，实验证明ChatGPT是一个好的因果解释者，但不是一个好的因果推理者，存在严重的因果幻觉问题，对于明确的因果关系表现良好。

    

    因果推理能力对于众多NLP应用至关重要。尽管ChatGPT在各种NLP任务中表现出令人印象深刻的新兴能力，但ChatGPT在因果推理方面的表现如何仍不清楚。本文对ChatGPT的因果推理能力进行了首次全面评估。实验证明，ChatGPT不是一个好的因果推理者，但是是一个好的因果解释者。此外，ChatGPT在因果推理方面存在严重的幻觉，可能是由于自然语言中因果关系和非因果关系的报告偏见，以及ChatGPT的升级过程，如RLHF。在上下文学习（ICL）和思维链（COT）技术方面，可能会进一步加剧这种因果幻觉。此外，ChatGPT的因果推理能力对于在提示中表达因果概念的词语非常敏感，并且封闭提示比开放提示表现更好。对于句子中的事件，ChatGPT擅长捕捉明确的因果关系。

    Causal reasoning ability is crucial for numerous NLP applications. Despite the impressive emerging ability of ChatGPT in various NLP tasks, it is unclear how well ChatGPT performs in causal reasoning. In this paper, we conduct the first comprehensive evaluation of the ChatGPT's causal reasoning capabilities. Experiments show that ChatGPT is not a good causal reasoner, but a good causal interpreter. Besides, ChatGPT has a serious hallucination on causal reasoning, possibly due to the reporting biases between causal and non-causal relationships in natural language, as well as ChatGPT's upgrading processes, such as RLHF. The In-Context Learning (ICL) and Chain-of-Though (COT) techniques can further exacerbate such causal hallucination. Additionally, the causal reasoning ability of ChatGPT is sensitive to the words used to express the causal concept in prompts, and close-ended prompts perform better than open-ended prompts. For events in sentences, ChatGPT excels at capturing explicit caus
    
[^87]: 在大型语言模型中加强迭代增强的思维链提示

    Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in Large Language Models. (arXiv:2304.11657v1 [cs.CL])

    [http://arxiv.org/abs/2304.11657](http://arxiv.org/abs/2304.11657)

    本文提出 Iter-CoT 方法，在大型语言模型中进行迭代增强的思维链提示，通过选择具有适度难度的具有挑战性但可回答的问题，并伴随推理链作为示例，提高了模型的泛化能力，同时使模型能够更准确地生成推理链。

    

    通过逐步引导思维链 (CoT) 作为示范，大型语言模型 (LLMs) 可以在各种推理任务上实现高度有效的性能。然而，LLMs 生成的演示推理链容易出现错误，这可能会导致推理过程中的错误。此外，不恰当的示例 (过于简单或复杂) 可以影响在不同难度级别下的整体性能。我们引入了Iter-CoT (迭代引导思维链提示) 的迭代引导方法，用于选择实例并生成推理链。通过利用迭代增强，我们的方法使LLMs 自主更正错误，从而产生更精确、全面的推理链。同时，我们的方法选择具有适度难度的具有挑战性但可回答的问题，并伴随推理链作为示例，从而增强LLMs 的泛化能力。

    Large language models (LLMs) can achieve highly effective performance on various reasoning tasks by incorporating step-by-step chain-of-thought (CoT) prompting as demonstrations. However, the reasoning chains of demonstrations generated by LLMs are prone to errors, which can subsequently lead to incorrect reasoning during inference. Furthermore, inappropriate exemplars (overly simplistic or complex), can affect overall performance among varying levels of difficulty. We introduce Iter-CoT (Iterative bootstrapping in Chain-of-Thoughts Prompting), an iterative bootstrapping approach for selecting exemplars and generating reasoning chains. By utilizing iterative bootstrapping, our approach enables LLMs to autonomously rectify errors, resulting in more precise and comprehensive reasoning chains. Simultaneously, our approach selects challenging yet answerable questions accompanied by reasoning chains as exemplars with a moderate level of difficulty, which enhances the LLMs' generalizability 
    
[^88]: LLMMaps——大型语言模型分层评价的可视化隐喻

    LLMMaps -- A Visual Metaphor for Stratified Evaluation of Large Language Models. (arXiv:2304.00457v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.00457](http://arxiv.org/abs/2304.00457)

    LLMMaps是一种分层评估大型语言模型性能的可视化技术，能够揭示取得高准确度和产生幻觉的子领域，并指导模型的进一步发展。

    

    大型语言模型(LLMs)在自然语言处理中取得了革命性的进展，并在各种任务中展示了惊人的能力。然而，它们容易产生幻觉，即模型在响应中暴露出不正确或错误的信息，这使得必须采用勤奋的评估方法。虽然LLM在特定知识领域中的表现通常是基于问答(Q&A)数据集进行评估，但这些评估通常仅报告整个领域的单个准确度数字，这一程序在透明度和模型改进方面存在问题。分层评估可以揭示可能更容易发生幻觉的子领域，从而有助于更好地评估LLMs的风险并指导它们的进一步发展。为支持这样的分层评估，我们提出了LLMMaps作为一种新的可视化技术，使用户能够根据Q&A数据集评估LLMs的性能。LLMMaps提供了对LLMs在不同子领域中的知识分布的详细洞察，允许用户放大领域的特定部分并探索模型性能上的差异。我们的实验证明，LLMMaps有助于识别出更容易出现LLM幻觉的子领域，并可以指导模型的发展，以改善这些领域的准确性。

    Large Language Models (LLMs) have revolutionized natural language processing and demonstrated impressive capabilities in various tasks. Unfortunately, they are prone to hallucinations, where the model exposes incorrect or false information in its responses, which renders diligent evaluation approaches mandatory. While LLM performance in specific knowledge fields is often evaluated based on question and answer (Q&A) datasets, such evaluations usually report only a single accuracy number for the entire field, a procedure which is problematic with respect to transparency and model improvement. A stratified evaluation could instead reveal subfields, where hallucinations are more likely to occur and thus help to better assess LLMs' risks and guide their further development. To support such stratified evaluations, we propose LLMMaps as a novel visualization technique that enables users to evaluate LLMs' performance with respect to Q&A datasets. LLMMaps provide detailed insights into LLMs' kn
    
[^89]: 分析和编辑暗藏后门的语言模型的内部机制

    Analyzing And Editing Inner Mechanisms Of Backdoored Language Models. (arXiv:2302.12461v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.12461](http://arxiv.org/abs/2302.12461)

    本研究分析并编辑暗藏后门的语言模型的内部机制，发现早期层的MLP模块和初始嵌入投影是后门机制中最重要的部分。通过使用PCP消融技术替换变压器模块，我们成功删除、插入和修改后门机制，并显著改善了后门的输出效果。

    

    数据集中的毒化是对大型语言模型的潜在安全威胁，可能导致暗藏后门的模型。关于暗藏后门语言模型的内部机制以及它们如何处理触发输入（例如，切换至有毒语言）的描述尚未找到。本文研究基于Transformer的暗藏后门语言模型的内部表示，并确定早期层的MLP模块与初始嵌入投影结合是后门机制中最重要的部分。我们利用这些知识来删除、插入和修改后门机制，并用工程化替代物降低MLP模块输出的重要性。为此，我们引入了基于主要成分的低秩矩阵的PCP消融技术，用其替换变压器模块。我们在暗藏后门的玩具模型、暗藏后门的大型模型和非暗藏后门的开源模型上展示了我们的结果。我们表明我们可以改善后门的输出效果。

    Poisoning of data sets is a potential security threat to large language models that can lead to backdoored models. A description of the internal mechanisms of backdoored language models and how they process trigger inputs, e.g., when switching to toxic language, has yet to be found. In this work, we study the internal representations of transformer-based backdoored language models and determine early-layer MLP modules as most important for the backdoor mechanism in combination with the initial embedding projection. We use this knowledge to remove, insert, and modify backdoor mechanisms with engineered replacements that reduce the MLP module outputs to essentials for the backdoor mechanism. To this end, we introduce PCP ablation, where we replace transformer modules with low-rank matrices based on the principal components of their activations. We demonstrate our results on backdoored toy, backdoored large, and non-backdoored open-source models. We show that we can improve the backdoor r
    
[^90]: Pre-trained Vision and Language Models能否回答求知视觉问题？

    Can Pre-trained Vision and Language Models Answer Visual Information-Seeking Questions?. (arXiv:2302.11713v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.11713](http://arxiv.org/abs/2302.11713)

    本研究介绍了一个专门针对无法仅凭常识知识回答的信息寻求问题而设计的视觉问答数据集InfoSeek。使用InfoSeek数据集，我们发现目前最先进的预训练多模态模型在回答求知视觉问题方面面临挑战，但在该数据集上进行微调可以激发模型使用细粒度知识。

    

    Pre-trained vision and language models在涉及图像和文本的任务中展示了领先的能力，包括视觉问答。然而，这些模型是否具备回答不仅仅查询视觉内容，而且还具有知识密集和信息寻求性质的问题的能力仍然不清楚。在本研究中，我们介绍了InfoSeek，一个专门针对无法仅凭常识知识回答的信息寻求问题而设计的视觉问答数据集。使用InfoSeek，我们分析了各种预训练的视觉问答模型，并深入了解它们的特点。我们的发现揭示了目前最先进的预训练多模态模型（如PaLI-X，BLIP2等）在回答求知视觉问题方面面临挑战，但在InfoSeek数据集上进行微调能够激发模型使用他们在预训练过程中学到的细粒度知识。此外，我们还展示了准确的视觉实体的重要性。

    Pre-trained vision and language models have demonstrated state-of-the-art capabilities over existing tasks involving images and texts, including visual question answering. However, it remains unclear whether these models possess the capability to answer questions that are not only querying visual content but knowledge-intensive and information-seeking. In this study, we introduce InfoSeek, a visual question answering dataset tailored for information-seeking questions that cannot be answered with only common sense knowledge. Using InfoSeek, we analyze various pre-trained visual question answering models and gain insights into their characteristics. Our findings reveal that state-of-the-art pre-trained multi-modal models (e.g., PaLI-X, BLIP2, etc.) face challenges in answering visual information-seeking questions, but fine-tuning on the InfoSeek dataset elicits models to use fine-grained knowledge that was learned during their pre-training. Furthermore, we show that accurate visual entit
    
[^91]: 大小不同的Transformer解码器

    Big Little Transformer Decoder. (arXiv:2302.07863v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.07863](http://arxiv.org/abs/2302.07863)

    提出了一种名为BiLD的框架，它由大小不同的两个模型协作生成文本。其中小型模型自回归地生成文本，而大型模型则在必要时以非自回归的方式对小型模型的预测进行微调，从而显著减少了推理延迟。

    

    基于Transformer架构的大型语言模型的出现，使得自然语言处理领域取得了巨大的进展。然而，这些模型存在长时间的推理延迟，限制了它们的使用并且使得它们在各种实时应用中过于昂贵。在自回归生成任务中，由于模型需要迭代地运行才能逐个生成标记，因此推理延迟更加严重。为了解决这个问题，我们提出了Big Little Decoder（BiLD）框架，它可以提高各种文本生成应用的推理效率和延迟。BiLD框架包含两个不同大小的模型，它们协作地生成文本。小型模型自回归地运行以低延迟生成文本，大型模型只在需要时以非自回归的方式调整小型模型不准确的预测。为了提高训练的稳定性和改善模型性能，我们引入了一种渐进蒸馏机制，使小型模型逐渐地从大型模型中学习。实验结果证明，所提出的BiLD框架显著降低了推理延迟，同时在保持与大型自回归模型相当甚至更好的生成质量的情况下。

    The recent emergence of Large Language Models based on the Transformer architecture has enabled dramatic advancements in the field of Natural Language Processing. However, these models have long inference latency, which limits their deployment, and which makes them prohibitively expensive for various real-time applications. The inference latency is further exacerbated by autoregressive generative tasks, as models need to run iteratively to generate tokens sequentially without leveraging token-level parallelization. To address this, we propose Big Little Decoder (BiLD), a framework that can improve inference efficiency and latency for a wide range of text generation applications. The BiLD framework contains two models with different sizes that collaboratively generate text. The small model runs autoregressively to generate text with a low inference cost, and the large model is only invoked occasionally to refine the small model's inaccurate predictions in a non-autoregressive manner. To
    
[^92]: 关于Text-to-SQL模型的安全漏洞

    On the Security Vulnerabilities of Text-to-SQL Models. (arXiv:2211.15363v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.15363](http://arxiv.org/abs/2211.15363)

    该论文揭示了Text-to-SQL模型存在的安全漏洞，并证明了这些漏洞能够被恶意利用产生攻击，通过对商业应用和开源语言模型的实验验证。该研究意在引起学术界对NLP算法相关的软件安全问题的关注和进一步研究。

    

    尽管已经证明自然语言处理（NLP）算法容易受到恶意攻击，但这些弱点是否可能导致软件安全威胁尚未深入研究。为了弥补这一差距，我们对常用于创建自然语言数据库接口的Text-to-SQL系统进行了漏洞测试。我们展示了六个商业应用中的Text-to-SQL模块可以被操纵以产生恶意代码，潜在地导致数据泄漏和拒绝服务攻击。这是第一个证明NLP模型可以被利用为攻击向量的示例。此外，使用四个开源语言模型的实验验证了对Text-to-SQL系统进行直接后门攻击可以达到100％的成功率，而不影响其性能。本研究旨在引起学术界对与NLP算法相关的潜在软件安全问题的关注，并鼓励进一步探索。

    Although it has been demonstrated that Natural Language Processing (NLP) algorithms are vulnerable to deliberate attacks, the question of whether such weaknesses can lead to software security threats is under-explored. To bridge this gap, we conducted vulnerability tests on Text-to-SQL systems that are commonly used to create natural language interfaces to databases. We showed that the Text-to-SQL modules within six commercial applications can be manipulated to produce malicious code, potentially leading to data breaches and Denial of Service attacks. This is the first demonstration that NLP models can be exploited as attack vectors in the wild. In addition, experiments using four open-source language models verified that straightforward backdoor attacks on Text-to-SQL systems achieve a 100% success rate without affecting their performance. The aim of this work is to draw the community's attention to potential software security issues associated with NLP algorithms and encourage explor
    
[^93]: mGPT: 少样本学习者走向多语言（arXiv:2204.07580v2 [cs.CL] 更新）

    mGPT: Few-Shot Learners Go Multilingual. (arXiv:2204.07580v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2204.07580](http://arxiv.org/abs/2204.07580)

    本文介绍了两种自回归GPT样式模型，分别使用13亿和130亿个参数，在60种语言中训练，并展示了与Facebook最近发布的XGLM模型性能相当的结果。这为低资源语言的自然语言处理提供了更多可能性。

    

    最近的研究报告称，自回归语言模型可以通过零样本和少样本学习范式成功解决许多自然语言处理任务，这为使用预训练语言模型开辟了新的可能性。本文介绍了两种自回归GPT样式模型，其参数分别为13亿和130亿，使用维基百科和巨大干净爬取的语料库训练了25个语系中的60种语言。我们使用GPT-2源代码和稀疏注意机制复现了GPT-3架构；Deepspeed和Megatron框架使我们能够有效地并行化训练和推断步骤。所得到的模型在性能上与Facebook最近发布的XGLM模型相当，在覆盖更多语言的同时增强了独联体国家和俄罗斯小国家等低资源语言的自然语言处理可能性。我们详细说明了架构设计的动机，详细描述了数据准备流程，并训练了五个小版本的模型。

    Recent studies report that autoregressive language models can successfully solve many NLP tasks via zero- and few-shot learning paradigms, which opens up new possibilities for using the pre-trained language models. This paper introduces two autoregressive GPT-like models with 1.3 billion and 13 billion parameters trained on 60 languages from 25 language families using Wikipedia and Colossal Clean Crawled Corpus. We reproduce the GPT-3 architecture using GPT-2 sources and the sparse attention mechanism; Deepspeed and Megatron frameworks allow us to parallelize the training and inference steps effectively. The resulting models show performance on par with the recently released XGLM models by Facebook, covering more languages and enhancing NLP possibilities for low resource languages of CIS countries and Russian small nations. We detail the motivation for the choices of the architecture design, thoroughly describe the data preparation pipeline, and train five small versions of the model t
    

