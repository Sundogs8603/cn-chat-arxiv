# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Bangla Grammatical Error Detection Using T5 Transformer Model.](http://arxiv.org/abs/2303.10612) | 本文使用T5 Transformer模型成功地在孟加拉语中检测语法错误，并对模型检测到的错误进行了详细分析，同时探讨了将翻译模型适应语法检测任务的挑战。 |
| [^2] | [CTRAN: CNN-Transformer-based Network for Natural Language Understanding.](http://arxiv.org/abs/2303.10606) | CTRAN是一种新颖的基于CNN-Transformer的编码器-解码器架构，用于自然语言理解的意图检测和插槽填充。该网络利用了BERT和多层卷积和Transformer编码器，采用自注意力和对齐的Transformer解码器。该网络在ATIS和SNIPS数据集上的插槽填充任务中超越了当前的最新结果。 |
| [^3] | [Toward Artificial Empathy for Human-Centered Design: A Framework.](http://arxiv.org/abs/2303.10583) | 本文提出了一个框架，旨在从人工智能研究中引入人工共情的思想进入人本设计，以帮助设计师更好地理解用户的需求。 |
| [^4] | [Extracting Incidents, Effects, and Requested Advice from MeToo Posts.](http://arxiv.org/abs/2303.10573) | 本论文提出了一种基于自然语言的模型，能够从MeToo帖文中准确地识别和提取出描述性骚扰事件、对幸存者的影响和请求的建议的句子。 |
| [^5] | [How People Respond to the COVID-19 Pandemic on Twitter: A Comparative Analysis of Emotional Expressions from US and India.](http://arxiv.org/abs/2303.10560) | 本研究分析了从2020年2月至2021年4月，超过5400万条美国和印度的推文中与COVID-19相关的情绪表达，发现两个国家的情绪表达有显著差异，同时在2020年中期情绪表达的趋势出现了反转。 |
| [^6] | [Two Kinds of Recall.](http://arxiv.org/abs/2303.10527) | 该论文提出了基于模式的方法和基于神经网络的方法在两种不同记忆方式（多样性和详尽性）方面不同的表现，并认为优秀方法应同时追求这两种方式。 |
| [^7] | [Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning.](http://arxiv.org/abs/2303.10512) | AdaLoRA是一种自适应预算分配方法，用于参数效率微调。将增量更新的预算根据权重矩阵的重要性分数进行自适应分配，通过奇异值分解的形式，实现了微调表现的优化。 |
| [^8] | [A Deep Learning System for Domain-specific speech Recognition.](http://arxiv.org/abs/2303.10510) | 本文提出了一个使用半监督学习注释领域特定数据，基于预训练的声学模型进行微调的ASR系统，并在领域特定上取得了优于商业ASR系统的性能。 |
| [^9] | [Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning.](http://arxiv.org/abs/2303.10475) | 传统的自然语言处理机器学习需要大规模的任务特定示例，但这不适用于任务可能过于复杂或成本过高以进行注释的场景。因此，社区对于自然语言处理中新的监督寻求范式--从任务指令学习--越来越感兴趣。 |
| [^10] | [SPDF: Sparse Pre-training and Dense Fine-tuning for Large Language Models.](http://arxiv.org/abs/2303.10464) | 本文提出了SPDF算法来实现大规模语言模型的高效训练。通过非结构化权重稀疏性来进行预训练，可以降低计算成本，而密集微调则可以保证高性能的表现。 |
| [^11] | [GazeReader: Detecting Unknown Word Using Webcam for English as a Second Language (ESL) Learners.](http://arxiv.org/abs/2303.10443) | GazeReader是一种利用网络摄像头来检测未知单词的方法，可辅助英语作为第二语言学习者的阅读体验，准确率和F1分数分别为98.09%和75.73%。 |
| [^12] | [Stop Words for Processing Software Engineering Documents: Do they Matter?.](http://arxiv.org/abs/2303.10439) | 本文研究了停用词在软件工程文档中的实用性。经实验证明，使用领域特定的停用词可以显著提高研究工具的性能，并且19个评估措施中有17个评估措施受益于停用词的消除。 |
| [^13] | [NoisyHate: Benchmarking Content Moderation Machine Learning Models with Human-Written Perturbations Online.](http://arxiv.org/abs/2303.10430) | 本文提出了一个包含人类编写的在线扰动的测试集，用于毒性言论检测模型的评估。 |
| [^14] | [A Comprehensive Capability Analysis of GPT-3 and GPT-3.5 Series Models.](http://arxiv.org/abs/2303.10420) | 本论文分析了GPT-3和GPT-3.5系列模型在自然语言理解任务中的发展趋势，并发现最新的模型在大多数任务中的表现优于前一代，特别是在零样本情况下。 |
| [^15] | [A Graph-Guided Reasoning Approach for Open-ended Commonsense Question Answering.](http://arxiv.org/abs/2303.10395) | 提出了一种基于图表推理的开放式常识问题回答方法，该方法能够处理常识问题的隐式多跳推理并构建与问题相关的开放式知识图，有望在没有预定义答案选项的真实情境应用中发挥作用。 |
| [^16] | [Powerful and Extensible WFST Framework for RNN-Transducer Losses.](http://arxiv.org/abs/2303.10384) | 本文提出了一个基于WFST框架的的RNN-Transducer Losses强大且可扩展的实现，“Compose-Transducer”和“Grid-Transducer”，并引入了新的W-Transducer Loss来展示组件的易扩展性。在实验中，W-Transducer（W-RNNT）表现出比标准RNN-T更好的性能。 |
| [^17] | [An Empirical Study of Pre-trained Language Models in Simple Knowledge Graph Question Answering.](http://arxiv.org/abs/2303.10368) | 该论文旨在比较和分析不同预训练语言模型在简易知识图谱问答中的表现，研究发现RoBERTa和ELECTRA模型在KGQA中表现最佳。 |
| [^18] | [Exploring Partial Knowledge Base Inference in Biomedical Entity Linking.](http://arxiv.org/abs/2303.10330) | 本文探索了生物医学实体链接中的部分知识库推理问题，发现由于精度下降导致EL性能出现灾难性下降，而且EL范例无法处理无法链接的提及，提出了两种赎回方法来解决NIL问题。 |
| [^19] | [Revisiting Automatic Question Summarization Evaluation in the Biomedical Domain.](http://arxiv.org/abs/2303.10328) | 本研究重新审视了生物医学领域中自动问题摘要的评估方法，通过人工评估发现当前自动评估指标和摘要系统存在不同值得关注的特征，并发布了一个数据集以促进未来的研究。 |
| [^20] | [On the rise of fear speech in online social media.](http://arxiv.org/abs/2303.10311) | 本研究通过抓取Gab.com上40万个恐惧言论和70多万个仇恨言论，揭示了恐惧言论在社交媒体中的普遍性和效果。发布大量恐惧言论的用户比发布大量仇恨言论的用户更容易获得追随者和在社交网络中占据核心地位，他们还能更有效地接触到良性用户。 |
| [^21] | [Conversational Tree Search: A New Hybrid Dialog Task.](http://arxiv.org/abs/2303.10227) | 本文介绍了一项新的任务——会话树搜索(CTS)，它可以架起FAQ和对话之间的桥梁，领域专家可以定义对话树，然后将其转换为一个有效的对话策略，只学习提出导航用户达到目标所需的问题。 |
| [^22] | [Translating Radiology Reports into Plain Language using ChatGPT and GPT-4 with Prompt Learning: Promising Results, Limitations, and Potential.](http://arxiv.org/abs/2303.09038) | 本文研究探讨利用ChatGPT将放射学报告翻译成通俗易懂的语言，平均得分为5分制的4.1分，信息缺失率和信息错误率均较低，ChatGPT提供的建议大都与放射学报告相关。 |
| [^23] | [The Science of Detecting LLM-Generated Texts.](http://arxiv.org/abs/2303.07205) | 本文综述了现有大型语言模型生成文本检测技术并提出了关键考虑因素，如开发全面评估指标和开源 LLM 所构成的威胁。 |
| [^24] | [Interactive Text Generation.](http://arxiv.org/abs/2303.00908) | 本研究提出了一种新的交互式文本生成任务，使用用户模拟器进行交互式训练生成模型，避免了真实用户参与的成本，并通过提供编辑指导模型朝着给定目标前进，从而提高了生成质量。 |
| [^25] | [Uzbek text's correspondence with the educational potential of pupils: a case study of the School corpus.](http://arxiv.org/abs/2303.00465) | 本文研究了使用学校语料库自动确定推荐给学生的教材与学生的教育材料之间的对应关系，为教育系统选择适当的内容提供了参考。 |
| [^26] | [AugGPT: Leveraging ChatGPT for Text Data Augmentation.](http://arxiv.org/abs/2302.13007) | AugGPT提出了一种基于ChatGPT的文本数据增强方法，该方法能够更忠实地保留正确标记的生成数据并提供足够的多样性，从而有效地缓解了自然语言处理任务中的限制样本量的问题。 |
| [^27] | [Learning from Noisy Crowd Labels with Logics.](http://arxiv.org/abs/2302.06337) | 这篇论文介绍了一种利用逻辑引导的从嘈杂的众包标签中学习的框架，能够改进文本分类和命名实体识别等任务中，学习从嘈杂数据中提取有效信息的方法，这种框架能够融合逻辑知识，提高现有技术水平。 |
| [^28] | [FGSI: Distant Supervision for Relation Extraction method based on Fine-Grained Semantic Information.](http://arxiv.org/abs/2302.02078) | 本研究提出了一种基于远程监督的关系抽取方法，该方法通过利用句子中的细粒度语义信息来减少干扰信息，提高了实体关系提取的准确性。 |
| [^29] | [Is ChatGPT A Good Translator? Yes With GPT-4 As The Engine.](http://arxiv.org/abs/2301.08745) | 本论文评估了ChatGPT的机器翻译能力，发现它在高资源欧洲语言上表现良好，但在低资源或远程语言上表现滞后；采用枢轴提示可以显著提高远程语言翻译的性能；在生物医学摘要或Reddit评论方面，ChatGPT的表现不如商业系统。 |
| [^30] | [An Error-Guided Correction Model for Chinese Spelling Error Correction.](http://arxiv.org/abs/2301.06323) | 本文提出了一个基于误差引导的模型用于改进汉语拼写纠错，它采用了零-shot误差检测、新的损失函数和高度并行的解码等方法，在实验中表现优于先进方法。 |
| [^31] | [MN-DS: A Multilabeled News Dataset for News Articles Hierarchical Classification.](http://arxiv.org/abs/2212.12061) | 本文介绍了一个包含10,917篇新闻文章的多标签数据集，可用于训练机器学习模型自动按主题对新闻文章进行分类，对新闻结构、分类和预测未来事件的研究人员非常有帮助。 |
| [^32] | [LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models.](http://arxiv.org/abs/2212.04088) | 本研究提出了一种新颖的方法LLM-Planner，利用大型语言模型为实体代理进行少样本规划，以实体代理目前所在的环境为基础，增强LLMs生成和更新计划，实验表明其在多任务和快速学习新任务的通用代理的开发中具有很好的表现。 |
| [^33] | [VieCap4H-VLSP 2021: ObjectAoA-Enhancing performance of Object Relation Transformer with Attention on Attention for Vietnamese image captioning.](http://arxiv.org/abs/2211.05405) | 本文提出了一种使用Attention on Attention机制来提高基于Transformer方法的图像理解能力的方法，实验结果显示其在VieCap4H数据集上表现显著优于其原始结构。 |
| [^34] | [Privately Fine-Tuning Large Language Models with Differential Privacy.](http://arxiv.org/abs/2210.15042) | 该论文介绍了如何使用差分隐私保护方法在微调大规模语言模型时防止个人信息泄露。 |
| [^35] | [PACIFIC: Towards Proactive Conversational Question Answering over Tabular and Textual Data in Finance.](http://arxiv.org/abs/2210.08817) | PACIFIC是一个金融领域的主动对话问答系统，特点是数字推理和混合语境，提出了PCQA任务，提供了新方法UniPCQA来适应这个任务。在PACIFIC数据集上进行了全面评估。 |
| [^36] | [MTEB: Massive Text Embedding Benchmark.](http://arxiv.org/abs/2210.07316) | 本文提出了一个大规模文本嵌入基准测试(MTEB)，该基准测试涵盖了8个嵌入任务、58个数据集和112种语言，以解决文本嵌入在不同任务中表现差异的问题。通过33个模型的测试，作者发现该领域尚未收敛于一种通用的文本嵌入方法， |
| [^37] | [Construction and Applications of Billion-Scale Pre-Trained Multimodal Business Knowledge Graph.](http://arxiv.org/abs/2209.15214) | 本文介绍了一个基于阿里巴巴集团的空前规模的 OpenBG 商业知识图谱，包含超过 88 百万实体和 26 亿三元组。它具有精细的分类和多模态事实，有助于推动商业智能化的发展。 |
| [^38] | [EcoFormer: Energy-Saving Attention with Linear Complexity.](http://arxiv.org/abs/2209.09004) | EcoFormer是一种通过核哈希技术进行高维softmax注意力二值化的新方法，实现了具有线性时间复杂度的高效注意力模块，从而显著降低了计算和能量开销，同时在多个任务上取得了高性能。 |
| [^39] | [GraphCFC: A Directed Graph based Cross-modal Feature Complementation Approach for Multimodal Conversational Emotion Recognition.](http://arxiv.org/abs/2207.12261) | 本文提出了一种基于有向图的跨模态特征补充方法，可以提取多模态上下文信息和交互信息，缓解了多模态融合中的异构性差距问题。 |
| [^40] | [The Maximum Linear Arrangement Problem for trees under projectivity and planarity.](http://arxiv.org/abs/2206.06924) | 该论文提出了一种解决在平面性和投影性定义下树的最大线性排列问题的算法，证明了最大投影和平面排列的多个性质，发现毛毛虫树最优，推广了之前的极值结果。 |
| [^41] | [Toward a realistic model of speech processing in the brain with self-supervised learning.](http://arxiv.org/abs/2206.01685) | 本研究针对语音处理问题，使用自监督学习的方法得到的特征与大脑神经元对于语音刺激的反应能够形成类似的层级，且解释了大脑活动的变化。该算法能够最少依赖先验语言和理解知识资源，并且需要的数据量远小于其它模型。 |
| [^42] | [NELA-GT-2022: A Large Multi-Labelled News Dataset for The Study of Misinformation in News Articles.](http://arxiv.org/abs/2203.05659) | NELA-GT-2022是一份包含361个来源的1,778,361篇文章的多标签新闻数据集，可用于研究新闻报道中的误导信息。 |
| [^43] | [Contextual Semantic Embeddings for Ontology Subsumption Prediction.](http://arxiv.org/abs/2202.09791) | 本文提出了一种名为BERTSubs的新型子类预测方法，用于OWL本体类，它可以预测包括来自同一本体或另一个本体的命名类以及来自同一本体的存在限制等多种子类。 |
| [^44] | [Active Learning for Event Extraction with Memory-based Loss Prediction Model.](http://arxiv.org/abs/2112.03073) | 本论文提出了一种基于深度学习的主动学习方法，采用基于批次的样本选择策略和记忆损失预测模型以降低事件注释成本，实验结果表明此方法优于现有主动学习方法且性能最优。 |
| [^45] | [What Makes Sentences Semantically Related: A Textual Relatedness Dataset and Empirical Study.](http://arxiv.org/abs/2110.04845) | 本论文介绍了一个手动注释的语义文本相关性数据集STR-2022，对于自动句子表示方法和各种下游自然语言处理任务的评估具有实用性。除此之外，我们探究了影响句子语义相关性的因素。 |

# 详细

[^1]: 使用T5 Transformer模型的孟加拉语语法错误检测

    Bangla Grammatical Error Detection Using T5 Transformer Model. (arXiv:2303.10612v1 [cs.CL])

    [http://arxiv.org/abs/2303.10612](http://arxiv.org/abs/2303.10612)

    本文使用T5 Transformer模型成功地在孟加拉语中检测语法错误，并对模型检测到的错误进行了详细分析，同时探讨了将翻译模型适应语法检测任务的挑战。

    

    本文提出了一种使用基于文本的转换变压器（T5）语言模型检测孟加拉语语法错误的方法，使用精细调整过的BanglaT5的小变种，在一个包含9385个句子的语料库上进行训练，其中错误被专用分界符括起来。T5模型主要设计用于翻译，而不是特别为这个任务设计的，因此需要进行广泛的后处理来使其适应错误检测任务。我们的实验表明，T5模型在检测孟加拉语语法错误时可以实现较低的Levenshtein距离，但是必须进行后处理才能达到最佳性能。在对精细调整的模型输出进行后处理后，最终测试集的平均Levenshtein距离为1.0394。本文还对模型检测到的错误进行了详细分析，并讨论了将翻译模型适应语法检测任务的挑战。我们的方法可以扩展到其他语言，这在成功检测孟加拉语语法错误时得到了证明。

    This paper presents a method for detecting grammatical errors in Bangla using a Text-to-Text Transfer Transformer (T5) Language Model, using the small variant of BanglaT5, fine-tuned on a corpus of 9385 sentences where errors were bracketed by the dedicated demarcation symbol. The T5 model was primarily designed for translation and is not specifically designed for this task, so extensive post-processing was necessary to adapt it to the task of error detection. Our experiments show that the T5 model can achieve low Levenshtein Distance in detecting grammatical errors in Bangla, but post-processing is essential to achieve optimal performance. The final average Levenshtein Distance after post-processing the output of the fine-tuned model was 1.0394 on a test set of 5000 sentences. This paper also presents a detailed analysis of the errors detected by the model and discusses the challenges of adapting a translation model for grammar. Our approach can be extended to other languages, demonst
    
[^2]: CTRAN：基于CNN-Transformer的自然语言理解网络

    CTRAN: CNN-Transformer-based Network for Natural Language Understanding. (arXiv:2303.10606v1 [cs.CL])

    [http://arxiv.org/abs/2303.10606](http://arxiv.org/abs/2303.10606)

    CTRAN是一种新颖的基于CNN-Transformer的编码器-解码器架构，用于自然语言理解的意图检测和插槽填充。该网络利用了BERT和多层卷积和Transformer编码器，采用自注意力和对齐的Transformer解码器。该网络在ATIS和SNIPS数据集上的插槽填充任务中超越了当前的最新结果。

    

    意图检测和插槽填充是自然语言理解中的两个主要任务。在本研究中，我们提出了CTRAN，一种新的基于CNN-Transformer的编码器-解码器架构，用于意图检测和插槽填充。在编码器中，我们使用BERT，接着几个卷积层，并使用窗口特征序列重新排列输出。我们在窗口特征序列后使用堆叠的Transformer编码器。对于意图检测解码器，我们利用自注意力后跟一个线性层。在插槽填充解码器中，我们介绍了对齐的Transformer解码器，它利用了零对角线掩码，将输出标签与输入标记对齐。我们将我们的网络应用于ATIS和SNIPS，并在两个数据集的插槽填充中超越了当前的最新结果。此外，我们将语言模型作为词嵌入并将其应用于网络中，结果表明这种策略比将语言模型作为编码器更好。

    Intent-detection and slot-filling are the two main tasks in natural language understanding. In this study, we propose CTRAN, a novel encoder-decoder CNN-Transformer-based architecture for intent-detection and slot-filling. In the encoder, we use BERT, followed by several convolutional layers, and rearrange the output using window feature sequence. We use stacked Transformer encoders after the window feature sequence. For the intent-detection decoder, we utilize self-attention followed by a linear layer. In the slot-filling decoder, we introduce the aligned Transformer decoder, which utilizes a zero diagonal mask, aligning output tags with input tokens. We apply our network on ATIS and SNIPS, and surpass the current state-of-the-art in slot-filling on both datasets. Furthermore, we incorporate the language model as word embeddings, and show that this strategy yields a better result when compared to the language model as an encoder.
    
[^3]: 人本设计中的人工共情：一个框架

    Toward Artificial Empathy for Human-Centered Design: A Framework. (arXiv:2303.10583v1 [cs.HC])

    [http://arxiv.org/abs/2303.10583](http://arxiv.org/abs/2303.10583)

    本文提出了一个框架，旨在从人工智能研究中引入人工共情的思想进入人本设计，以帮助设计师更好地理解用户的需求。

    

    设计过程的早期阶段，设计师通过发现未满足的需求和开发创新的概念作为潜在的解决方案来探索机会。从人本设计的角度来看，设计师必须与人发展共情，才能真正理解他们的需求。然而，发展共情是一个复杂而主观的过程，非常依赖于设计师的共情能力。因此，共情的发展是直觉性的，潜在需求的发现往往是偶然的。本文旨在提供人工智能研究的见解，以指出以共情为核心的人本设计人工智能驱动的发展方向。具体而言，我们进行了跨学科研究，包括数据驱动的用户研究、共情理解的发展和人工共情等研究领域。基于这个基础，我们讨论了人工共情在人本设计中可以发挥的作用，并提出了一个在设计过程中开发人工共情的框架。

    In the early stages of the design process, designers explore opportunities by discovering unmet needs and developing innovative concepts as potential solutions. From a human-centered design perspective, designers must develop empathy with people to truly understand their needs. However, developing empathy is a complex and subjective process that relies heavily on the designer's empathetic capability. Therefore, the development of empathetic understanding is intuitive, and the discovery of underlying needs is often serendipitous. This paper aims to provide insights from artificial intelligence research to indicate the future direction of AI-driven human-centered design, taking into account the essential role of empathy. Specifically, we conduct an interdisciplinary investigation of research areas such as data-driven user studies, empathetic understanding development, and artificial empathy. Based on this foundation, we discuss the role that artificial empathy can play in human-centered 
    
[^4]: 从 MeToo 帖文中提取事件、影响和请求的建议

    Extracting Incidents, Effects, and Requested Advice from MeToo Posts. (arXiv:2303.10573v1 [cs.CL])

    [http://arxiv.org/abs/2303.10573](http://arxiv.org/abs/2303.10573)

    本论文提出了一种基于自然语言的模型，能够从MeToo帖文中准确地识别和提取出描述性骚扰事件、对幸存者的影响和请求的建议的句子。

    

    受到性骚扰的幸存者经常在社交媒体上分享自己的经历，展示他们的感受和情绪，并寻求建议。我们发现，在 Reddit 上，幸存者经常分享描述以下三个内容的长帖文：（i）性骚扰事件、（ii）其对幸存者的影响，包括他们的感受和情绪，以及（iii）正在寻求的建议。我们称这样的帖文为 MeToo 帖文，尽管它们可能没有被标记，并且可能出现在各种子论坛中。我们提出了一个基于自然语言的模型来从长帖文中识别描述上述三种类别的句子，以便帮助人员理解幸存者的需求。在数据集的十折交叉验证中，我们的模型实现了 0.82 的宏 F1 评分。

    Survivors of sexual harassment frequently share their experiences on social media, revealing their feelings and emotions and seeking advice. We observed that on Reddit, survivors regularly share long posts that describe a combination of (i) a sexual harassment incident, (ii) its effect on the survivor, including their feelings and emotions, and (iii) the advice being sought. We term such posts MeToo posts, even though they may not be so tagged and may appear in diverse subreddits. A prospective helper (such as a counselor or even a casual reader) must understand a survivor's needs from such posts. But long posts can be time-consuming to read and respond to.  Accordingly, we address the problem of extracting key information from a long MeToo post. We develop a natural language-based model to identify sentences from a post that describe any of the above three categories.  On ten-fold cross-validation of a dataset, our model achieves a macro F1 score of 0.82.  In addition, we contribute M
    
[^5]: 人们如何在 Twitter 上回应 COVID-19 疫情：美国和印度的情绪表达的比较分析

    How People Respond to the COVID-19 Pandemic on Twitter: A Comparative Analysis of Emotional Expressions from US and India. (arXiv:2303.10560v1 [cs.CL])

    [http://arxiv.org/abs/2303.10560](http://arxiv.org/abs/2303.10560)

    本研究分析了从2020年2月至2021年4月，超过5400万条美国和印度的推文中与COVID-19相关的情绪表达，发现两个国家的情绪表达有显著差异，同时在2020年中期情绪表达的趋势出现了反转。

    

    COVID-19 疫情已夺去了全球数百万人的生命，引发了高度的情绪。本研究分析了美国和印度与 COVID-19 相关的各种情绪表达，涵盖了从2020年2月至2021年4月的15个月中的超过5400万条推文。采用预训练的情绪分析和主题建模算法，研究了四种不同类型的情绪（恐惧、愤怒、快乐和悲伤）及其与时间和地点相关的变化。结果显示，在恐惧情绪降低、愤怒和快乐情绪波动的情况下，2020年的趋势发生了反转，直到2021年前四个月的新情况再次导致这种趋势的出现。讨论了检测到的差异。

    The COVID-19 pandemic has claimed millions of lives worldwide and elicited heightened emotions. This study examines the expression of various emotions pertaining to COVID-19 in the United States and India as manifested in over 54 million tweets, covering the fifteen-month period from February 2020 through April 2021, a period which includes the beginnings of the huge and disastrous increase in COVID-19 cases that started to ravage India in March 2021. Employing pre-trained emotion analysis and topic modeling algorithms, four distinct types of emotions (fear, anger, happiness, and sadness) and their time- and location-associated variations were examined. Results revealed significant country differences and temporal changes in the relative proportions of fear, anger, and happiness, with fear declining and anger and happiness fluctuating in 2020 until new situations over the first four months of 2021 reversed the trends. Detected differences are discussed briefly in terms of the latent to
    
[^6]: 两种记忆方式

    Two Kinds of Recall. (arXiv:2303.10527v1 [cs.CL])

    [http://arxiv.org/abs/2303.10527](http://arxiv.org/abs/2303.10527)

    该论文提出了基于模式的方法和基于神经网络的方法在两种不同记忆方式（多样性和详尽性）方面不同的表现，并认为优秀方法应同时追求这两种方式。

    

    人们普遍认为，基于模式的模型擅长准确性，而基于学习的模型则更擅长召回率。但这确实是这样吗？作者认为，有两种记忆方式：d-recall，代表多样性，和e-recall，代表详尽性。作者通过实验证明，虽然神经网络方法确实在d-recall方面显著优于模式方法，但有时候模式方法仍然在e-recall方面明显优于神经网络方法。理想的方法应该同时追求这两种方式，并且这种理想应该反映在我们的评估中。

    It is an established assumption that pattern-based models are good at precision, while learning based models are better at recall. But is that really the case? I argue that there are two kinds of recall: d-recall, reflecting diversity, and e-recall, reflecting exhaustiveness. I demonstrate through experiments that while neural methods are indeed significantly better at d-recall, it is sometimes the case that pattern-based methods are still substantially better at e-recall. Ideal methods should aim for both kinds, and this ideal should in turn be reflected in our evaluations.
    
[^7]: 参数效率微调的自适应预算分配

    Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning. (arXiv:2303.10512v1 [cs.CL])

    [http://arxiv.org/abs/2303.10512](http://arxiv.org/abs/2303.10512)

    AdaLoRA是一种自适应预算分配方法，用于参数效率微调。将增量更新的预算根据权重矩阵的重要性分数进行自适应分配，通过奇异值分解的形式，实现了微调表现的优化。

    

    在自然语言处理中，对预训练的大型语言模型进行微调已经成为了一种重要的范式。然而，通常的做法是微调预训练模型中的所有参数，当存在大量下游任务时，这种方法变得不切实际。因此，许多微调方法被提出来以以参数有效的方式学习预训练加权的增量更新，例如低秩增量。这些方法通常将增量更新的预算均匀分配到所有预训练的权重矩阵上，忽略了不同权重参数的不同重要性。结果，微调的表现是次优的。为弥补这一差距，我们提出了AdaLoRA，根据它们的重要性分数自适应分配权重矩阵的参数预算。特别地，AdaLoRA将增量更新的参数化为奇异值分解的形式。这种新颖的方法使我们可以有效地剪枝奇异值。

    Fine-tuning large pre-trained language models on downstream tasks has become an important paradigm in NLP. However, common practice fine-tunes all of the parameters in a pre-trained model, which becomes prohibitive when a large number of downstream tasks are present. Therefore, many fine-tuning methods are proposed to learn incremental updates of pre-trained weights in a parameter efficient way, e.g., low-rank increments. These methods often evenly distribute the budget of incremental updates across all pre-trained weight matrices, and overlook the varying importance of different weight parameters. As a consequence, the fine-tuning performance is suboptimal. To bridge this gap, we propose AdaLoRA, which adaptively allocates the parameter budget among weight matrices according to their importance score. In particular, AdaLoRA parameterizes the incremental updates in the form of singular value decomposition. Such a novel approach allows us to effectively prune the singular values of unim
    
[^8]: 面向领域特定语音识别的深度学习系统

    A Deep Learning System for Domain-specific speech Recognition. (arXiv:2303.10510v1 [cs.CL])

    [http://arxiv.org/abs/2303.10510](http://arxiv.org/abs/2303.10510)

    本文提出了一个使用半监督学习注释领域特定数据，基于预训练的声学模型进行微调的ASR系统，并在领域特定上取得了优于商业ASR系统的性能。

    

    随着人机语音接口越来越便捷，许多最先进的自动语音识别（ASR）系统被提出。然而，商业ASR系统通常在领域特定语音，特别是在低资源情况下的表现较差。作者使用预训练的DeepSpeech2和Wav2Vec2声学模型，开发了受益特定的ASR系统。使用半监督学习注释领域特定数据，只需少量人工干预即可。最佳性能来自一种经过微调的Wav2Vec2-Large-LV60声学模型，带有外部KenLM，在受益特定语音上超越了Google和AWS ASR系统。还研究了将容易出错的ASR转录作为口语理解（SLU）的一部分的可行性。受益特定自然语言理解（NLU）任务的结果表明，领域特定微调的ASR系统可以超越商业ASR系统并提高NLU任务的准确性。

    As human-machine voice interfaces provide easy access to increasingly intelligent machines, many state-of-the-art automatic speech recognition (ASR) systems are proposed. However, commercial ASR systems usually have poor performance on domain-specific speech especially under low-resource settings. The author works with pre-trained DeepSpeech2 and Wav2Vec2 acoustic models to develop benefit-specific ASR systems. The domain-specific data are collected using proposed semi-supervised learning annotation with little human intervention. The best performance comes from a fine-tuned Wav2Vec2-Large-LV60 acoustic model with an external KenLM, which surpasses the Google and AWS ASR systems on benefit-specific speech. The viability of using error prone ASR transcriptions as part of spoken language understanding (SLU) is also investigated. Results of a benefit-specific natural language understanding (NLU) task show that the domain-specific fine-tuned ASR system can outperform the commercial ASR sys
    
[^9]: 仅仅提示足够了吗？不是的。指导学习的全面和更广阔视角（arXiv：2303.10475v1 [cs.CL]）

    Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning. (arXiv:2303.10475v1 [cs.CL])

    [http://arxiv.org/abs/2303.10475](http://arxiv.org/abs/2303.10475)

    传统的自然语言处理机器学习需要大规模的任务特定示例，但这不适用于任务可能过于复杂或成本过高以进行注释的场景。因此，社区对于自然语言处理中新的监督寻求范式--从任务指令学习--越来越感兴趣。

    

    任务语义可以通过一组输入输出示例或一条文本指令来表达。传统的自然语言处理（NLP）机器学习方法主要依赖于大规模的任务特定示例的可用性。这引起了两个问题：首先，收集任务特定标记示例不适用于任务可能过于复杂或成本过高以进行注释的场景，或者系统需要立即处理新任务。其次，这不是用户友好的，因为最终用户可能更愿意在使用系统之前提供任务描述而不是一组示例。因此，社区对于自然语言处理中新的监督寻求范式--从任务指令学习--越来越感兴趣。尽管取得了令人印象深刻的进展，但社区仍然面临着一些共同的问题。本次调查旨在总结指导学习的当前研究，特别是回答以下问题：

    Task semantics can be expressed by a set of input-to-output examples or a piece of textual instruction. Conventional machine learning approaches for natural language processing (NLP) mainly rely on the availability of large-scale sets of task-specific examples. Two issues arise: first, collecting task-specific labeled examples does not apply to scenarios where tasks may be too complicated or costly to annotate, or the system is required to handle a new task immediately; second, this is not user-friendly since end-users are probably more willing to provide task description rather than a set of examples before using the system. Therefore, the community is paying increasing interest in a new supervision-seeking paradigm for NLP: learning from task instructions. Despite its impressive progress, there are some common issues that the community struggles with. This survey paper tries to summarize the current research on instruction learning, particularly, by answering the following questions:
    
[^10]: SPDF：大规模语言模型的稀疏预训练和密集微调

    SPDF: Sparse Pre-training and Dense Fine-tuning for Large Language Models. (arXiv:2303.10464v1 [cs.LG])

    [http://arxiv.org/abs/2303.10464](http://arxiv.org/abs/2303.10464)

    本文提出了SPDF算法来实现大规模语言模型的高效训练。通过非结构化权重稀疏性来进行预训练，可以降低计算成本，而密集微调则可以保证高性能的表现。

    

    预训练和微调范式为自然语言处理（NLP）的多项突破做出了贡献。语言模型首先在大型数据集上进行跨域知识的预训练（例如，Pile、MassiveText等），然后在特定任务的数据上进行微调（例如，自然语言生成、文本摘要等）。虽然扩大模型和数据集大小有助于提高LLM性能，但这也带来了极为禁止性的计算成本。预训练LLMs通常需要比微调演习更多的FLOPs，两个阶段之间的模型容量通常保持不变。为了实现相对于训练FLOPs的训练效率，我们建议在两个阶段之间解耦模型容量，并引入稀疏预训练和密集微调（SPDF）。在这项工作中，我们展示了使用非结构化权重稀疏性来仅训练子集权重的好处。

    The pre-training and fine-tuning paradigm has contributed to a number of breakthroughs in Natural Language Processing (NLP). Instead of directly training on a downstream task, language models are first pre-trained on large datasets with cross-domain knowledge (e.g., Pile, MassiveText, etc.) and then fine-tuned on task-specific data (e.g., natural language generation, text summarization, etc.). Scaling the model and dataset size has helped improve the performance of LLMs, but unfortunately, this also leads to highly prohibitive computational costs. Pre-training LLMs often require orders of magnitude more FLOPs than fine-tuning and the model capacity often remains the same between the two phases. To achieve training efficiency w.r.t training FLOPs, we propose to decouple the model capacity between the two phases and introduce Sparse Pre-training and Dense Fine-tuning (SPDF). In this work, we show the benefits of using unstructured weight sparsity to train only a subset of weights during 
    
[^11]: GazeReader：利用网络摄像头检测英语作为第二语言学习者的未知单词

    GazeReader: Detecting Unknown Word Using Webcam for English as a Second Language (ESL) Learners. (arXiv:2303.10443v1 [cs.HC])

    [http://arxiv.org/abs/2303.10443](http://arxiv.org/abs/2303.10443)

    GazeReader是一种利用网络摄像头来检测未知单词的方法，可辅助英语作为第二语言学习者的阅读体验，准确率和F1分数分别为98.09%和75.73%。

    

    自动检测未知单词的技术可以为辅助英语作为第二语言学习者的新应用提供可能性，从而提高他们的阅读体验。然而，大多数现代未知单词检测方法需要具有高精度的专用眼动仪，这些设备对于终端用户来说不易获取。在这项工作中，我们提出了GazeReader，一种只使用网络摄像头的未知单词检测方法。GazeReader跟踪学习者的凝视，然后应用一个基于Transformer的机器学习模型来编码文本信息以定位未知单词。我们还应用了知识增强技术，包括词频、词性和命名实体识别，以提高性能。用户研究表明，我们的方法的准确率和F1分数分别为98.09%和75.73%。最后，我们探讨了ESL阅读的设计范围并讨论了研究结果。

    Automatic unknown word detection techniques can enable new applications for assisting English as a Second Language (ESL) learners, thus improving their reading experiences. However, most modern unknown word detection methods require dedicated eye-tracking devices with high precision that are not easily accessible to end-users. In this work, we propose GazeReader, an unknown word detection method only using a webcam. GazeReader tracks the learner's gaze and then applies a transformer-based machine learning model that encodes the text information to locate the unknown word. We applied knowledge enhancement including term frequency, part of speech, and named entity recognition to improve the performance. The user study indicates that the accuracy and F1-score of our method were 98.09% and 75.73%, respectively. Lastly, we explored the design scope for ESL reading and discussed the findings.
    
[^12]: 处理软件工程文档的停用词：它们重要吗？

    Stop Words for Processing Software Engineering Documents: Do they Matter?. (arXiv:2303.10439v1 [cs.SE])

    [http://arxiv.org/abs/2303.10439](http://arxiv.org/abs/2303.10439)

    本文研究了停用词在软件工程文档中的实用性。经实验证明，使用领域特定的停用词可以显著提高研究工具的性能，并且19个评估措施中有17个评估措施受益于停用词的消除。

    

    停用词通常被认为是不具有预测性的，因此在自然语言处理任务中通常会被去除。然而，不确定性词汇的定义是模糊的，因此大多数算法使用基于通用知识的停用词列表来去除停用词。学者们一直在就停用词的使用价值进行讨论，特别是在特定领域的设置中。在这项工作中，我们调查了停用词去除在软件工程背景下的实用性。为此，我们复制并实验了三个软件工程研究工具，并构建了一个软件工程领域相关文本的语料库，包括来自 Stack Overflow 的10,000个问题，并使用传统的信息论方法识别了200个领域特定的停用词。我们的结果表明，使用领域特定的停用词与使用通用停用列表相比，显着提高了研究工具的性能，并且19个评估措施中有17个评估措施受益于停用词的消除。我们的工作证明了在处理软件工程文档中去除领域特定的停用词的重要性。

    Stop words, which are considered non-predictive, are often eliminated in natural language processing tasks. However, the definition of uninformative vocabulary is vague, so most algorithms use general knowledge-based stop lists to remove stop words. There is an ongoing debate among academics about the usefulness of stop word elimination, especially in domain-specific settings. In this work, we investigate the usefulness of stop word removal in a software engineering context. To do this, we replicate and experiment with three software engineering research tools from related work. Additionally, we construct a corpus of software engineering domain-related text from 10,000 Stack Overflow questions and identify 200 domain-specific stop words using traditional information-theoretic methods. Our results show that the use of domain-specific stop words significantly improved the performance of research tools compared to the use of a general stop list and that 17 out of 19 evaluation measures sh
    
[^13]: NoisyHate：在人类编写的在线扰动下对内容审核机器学习模型进行基准测试

    NoisyHate: Benchmarking Content Moderation Machine Learning Models with Human-Written Perturbations Online. (arXiv:2303.10430v1 [cs.LG])

    [http://arxiv.org/abs/2303.10430](http://arxiv.org/abs/2303.10430)

    本文提出了一个包含人类编写的在线扰动的测试集，用于毒性言论检测模型的评估。

    

    在社交媒体上，具有有害内容的在线文本是一种威胁，可能会引起网络骚扰。尽管许多平台采取了措施，例如基于机器学习的仇恨言论检测系统来减少其影响，但那些有害内容发布者仍然可以通过修改有害词汇的拼写来逃避系统。这些修改后的单词也称为人类编写的文本扰动。许多研究开发了一定的技术来生成对抗样本，以帮助机器学习模型获得识别这些扰动的能力。然而，机器生成的扰动与人类编写的扰动之间仍存在差距。在本文中，我们介绍了一个包含人类编写的在线扰动的基准测试集，用于毒性言论检测模型。我们还招募了一组工人来评估此测试集的质量并删除低质量的样本。同时，为了检查我们的扰动是否可以归一化为其干净版本，我们还创建了一个相关的测试集。

    Online texts with toxic content are a threat in social media that might cause cyber harassment. Although many platforms applied measures, such as machine learning-based hate-speech detection systems, to diminish their effect, those toxic content publishers can still evade the system by modifying the spelling of toxic words. Those modified words are also known as human-written text perturbations. Many research works developed certain techniques to generate adversarial samples to help the machine learning models obtain the ability to recognize those perturbations. However, there is still a gap between those machine-generated perturbations and human-written perturbations. In this paper, we introduce a benchmark test set containing human-written perturbations online for toxic speech detection models. We also recruited a group of workers to evaluate the quality of this test set and dropped low-quality samples. Meanwhile, to check if our perturbation can be normalized to its clean version, w
    
[^14]: GPT-3和GPT-3.5系列模型的全面能力分析

    A Comprehensive Capability Analysis of GPT-3 and GPT-3.5 Series Models. (arXiv:2303.10420v1 [cs.CL])

    [http://arxiv.org/abs/2303.10420](http://arxiv.org/abs/2303.10420)

    本论文分析了GPT-3和GPT-3.5系列模型在自然语言理解任务中的发展趋势，并发现最新的模型在大多数任务中的表现优于前一代，特别是在零样本情况下。

    

    GPT系列模型，如GPT-3、CodeX、InstructGPT、ChatGPT等，由于其出色的自然语言处理能力而受到广泛关注。然而，尽管已有大量研究探讨了GPT系列模型与精调模型在能力上的差异，但对于GPT系列模型的能力随时间演化的研究却受到了限制。为了全面分析GPT系列模型的能力，我们选择了六个代表性模型，包括两个GPT-3系列模型（即davinci和text-davinci-001）和四个GPT-3.5系列模型（即code-davinci-002、text-davinci-002、text-davinci-003和gpt-3.5-turbo）。我们使用21个数据集在九个自然语言理解（NLU）任务上评估它们的表现。特别地，我们比较了每个任务中不同模型在零样本和少样本场景下的性能和鲁棒性。我们广泛的实验表明，GPT系列模型的整体能力继续随时间演化，最新的模型在大多数任务中的表现优于前一代，特别是在零样本情况下。

    GPT series models, such as GPT-3, CodeX, InstructGPT, ChatGPT, and so on, have gained considerable attention due to their exceptional natural language processing capabilities. However, despite the abundance of research on the difference in capabilities between GPT series models and fine-tuned models, there has been limited attention given to the evolution of GPT series models' capabilities over time. To conduct a comprehensive analysis of the capabilities of GPT series models, we select six representative models, comprising two GPT-3 series models (i.e., davinci and text-davinci-001) and four GPT-3.5 series models (i.e., code-davinci-002, text-davinci-002, text-davinci-003, and gpt-3.5-turbo). We evaluate their performance on nine natural language understanding (NLU) tasks using 21 datasets. In particular, we compare the performance and robustness of different models for each task under zero-shot and few-shot scenarios. Our extensive experiments reveal that the overall ability of GPT s
    
[^15]: 一种基于图表推理的开放式常识问题回答方法

    A Graph-Guided Reasoning Approach for Open-ended Commonsense Question Answering. (arXiv:2303.10395v1 [cs.CL])

    [http://arxiv.org/abs/2303.10395](http://arxiv.org/abs/2303.10395)

    提出了一种基于图表推理的开放式常识问题回答方法，该方法能够处理常识问题的隐式多跳推理并构建与问题相关的开放式知识图，有望在没有预定义答案选项的真实情境应用中发挥作用。

    

    最近，针对多项选择的常识问题回答的端到端训练模型取得了良好的结果。然而，在现实场景中，无法直接应用此类问答系统，因为没有提供答案候选人。因此，最近发布了一个新的基准挑战集（OpenCSR）用于开放式常识推理，其中包含自然科学问题而没有预定义的选项。在OpenCSR挑战集中，许多问题需要隐含的多跳推理并且决策空间很大，反映了这项任务的困难性质。现有的OpenCSR工作仅着眼于改进检索过程，从文本知识库中提取相关事实句子，而将重要且非平凡的推理任务超出范围。在本工作中，我们扩展范围，包括一个基于检索支撑事实构建问题相关开放知识图的推理器，并采用顺序

    Recently, end-to-end trained models for multiple-choice commonsense question answering (QA) have delivered promising results. However, such question-answering systems cannot be directly applied in real-world scenarios where answer candidates are not provided. Hence, a new benchmark challenge set for open-ended commonsense reasoning (OpenCSR) has been recently released, which contains natural science questions without any predefined choices. On the OpenCSR challenge set, many questions require implicit multi-hop reasoning and have a large decision space, reflecting the difficult nature of this task. Existing work on OpenCSR sorely focuses on improving the retrieval process, which extracts relevant factual sentences from a textual knowledge base, leaving the important and non-trivial reasoning task outside the scope. In this work, we extend the scope to include a reasoner that constructs a question-dependent open knowledge graph based on retrieved supporting facts and employs a sequentia
    
[^16]: 基于WFST框架的RNN-Transducer Losses强大且可扩展的实现

    Powerful and Extensible WFST Framework for RNN-Transducer Losses. (arXiv:2303.10384v1 [eess.AS])

    [http://arxiv.org/abs/2303.10384](http://arxiv.org/abs/2303.10384)

    本文提出了一个基于WFST框架的的RNN-Transducer Losses强大且可扩展的实现，“Compose-Transducer”和“Grid-Transducer”，并引入了新的W-Transducer Loss来展示组件的易扩展性。在实验中，W-Transducer（W-RNNT）表现出比标准RNN-T更好的性能。

    

    本文提出了一个基于加权有限状态转移器（WFST）的框架，以简化对RNN-Transducer（RNN-T） Losses的修改开发。现有的RNN-T实现使用与CUDA相关的代码，难以扩展和调试。WFST易于构建和扩展，并允许通过可视化进行调试。我们介绍了两个基于WFST的RNN-T实现：（1）“Compose-Transducer”，它基于声学和文本架构的WFST图组合，计算效率高和易于修改；（2）“Grid-Transducer”，直接构建晶格用于进一步计算，最紧凑和计算效率最高。我们通过引入新的W-Transducer Loss，即Connectionist Temporal Classification with Wild Cards的适应性，展示了组件的易扩展性。在缺少转录开头部分的弱监督数据设置中，W-Transducer（W-RNNT）始终优于标准RNN-T。

    This paper presents a framework based on Weighted Finite-State Transducers (WFST) to simplify the development of modifications for RNN-Transducer (RNN-T) loss. Existing implementations of RNN-T use CUDA-related code, which is hard to extend and debug. WFSTs are easy to construct and extend, and allow debugging through visualization. We introduce two WFST-powered RNN-T implementations: (1) "Compose-Transducer", based on a composition of the WFST graphs from acoustic and textual schema -- computationally competitive and easy to modify; (2) "Grid-Transducer", which constructs the lattice directly for further computations -- most compact, and computationally efficient. We illustrate the ease of extensibility through introduction of a new W-Transducer loss -- the adaptation of the Connectionist Temporal Classification with Wild Cards. W-Transducer (W-RNNT) consistently outperforms the standard RNN-T in a weakly-supervised data setup with missing parts of transcriptions at the beginning and 
    
[^17]: 简易知识图谱问答中预训练语言模型的实证研究

    An Empirical Study of Pre-trained Language Models in Simple Knowledge Graph Question Answering. (arXiv:2303.10368v1 [cs.CL])

    [http://arxiv.org/abs/2303.10368](http://arxiv.org/abs/2303.10368)

    该论文旨在比较和分析不同预训练语言模型在简易知识图谱问答中的表现，研究发现RoBERTa和ELECTRA模型在KGQA中表现最佳。

    

    大规模预训练语言模型（PLMs）如BERT最近取得了巨大成功，成为自然语言处理（NLP）中的里程碑。现在，NLP界普遍认为采用PLMs作为下游任务的骨干是一种共识。在最近的知识图谱问答（KGQA）研究中，BERT或其变体已成为其KGQA模型中必不可少的。然而，目前仍缺乏对KGQA中不同PLMs性能的全面研究和比较。为了解决这个问题，我们总结了两种基于PLMs的基本KGQA框架，比较了九种PLMs在准确性和效率方面的表现，并提出了基于流行的SimpleQuestions基准测试的三个更大规模的KGs基准测试，以研究PLMs的可扩展性。我们仔细分析了所有基于PLMs的KGQA基础框架在这些基准测试以及其他两个流行数据集WebQuestionSP和FreebaseQA上的结果，并发现RoBERTa和ELECTRA模型在KGQA中表现最佳。

    Large-scale pre-trained language models (PLMs) such as BERT have recently achieved great success and become a milestone in natural language processing (NLP). It is now the consensus of the NLP community to adopt PLMs as the backbone for downstream tasks. In recent works on knowledge graph question answering (KGQA), BERT or its variants have become necessary in their KGQA models. However, there is still a lack of comprehensive research and comparison of the performance of different PLMs in KGQA. To this end, we summarize two basic KGQA frameworks based on PLMs without additional neural network modules to compare the performance of nine PLMs in terms of accuracy and efficiency. In addition, we present three benchmarks for larger-scale KGs based on the popular SimpleQuestions benchmark to investigate the scalability of PLMs. We carefully analyze the results of all PLMs-based KGQA basic frameworks on these benchmarks and two other popular datasets, WebQuestionSP and FreebaseQA, and find th
    
[^18]: 探索生物医学实体链接中的部分知识库推理

    Exploring Partial Knowledge Base Inference in Biomedical Entity Linking. (arXiv:2303.10330v1 [cs.CL])

    [http://arxiv.org/abs/2303.10330](http://arxiv.org/abs/2303.10330)

    本文探索了生物医学实体链接中的部分知识库推理问题，发现由于精度下降导致EL性能出现灾难性下降，而且EL范例无法处理无法链接的提及，提出了两种赎回方法来解决NIL问题。

    

    生物医学实体链接（EL）包括命名实体识别（NER）和命名实体消歧（NED）。EL模型在由预定义的知识库标记的语料库上进行训练。然而，常见的情况是只有知识库的子集中的实体对利益相关者有价值。我们称这种情况为部分知识库推理：使用一个知识库对EL模型进行训练，并在没有进一步训练的情况下对其部分进行推理。在这项工作中，我们给出了这种实际上非常有价值但明显不够研究的情况的详细定义和评估方法，并评估了三个代表性的EL范例的方法。我们构建了部分知识库推理基准，并发现由于大量精度下降导致EL性能出现灾难性下降。我们的发现揭示了这些EL范例无法正确处理无法链接的提及（NIL），因此它们对部分知识库推理不具有鲁棒性。我们还提出了两种简单有效的赎回方法来解决NIL问题。

    Biomedical entity linking (EL) consists of named entity recognition (NER) and named entity disambiguation (NED). EL models are trained on corpora labeled by a predefined KB. However, it is a common scenario that only entities within a subset of the KB are precious to stakeholders. We name this scenario partial knowledge base inference: training an EL model with one KB and inferring on the part of it without further training. In this work, we give a detailed definition and evaluation procedures for this practically valuable but significantly understudied scenario and evaluate methods from three representative EL paradigms. We construct partial KB inference benchmarks and witness a catastrophic degradation in EL performance due to dramatically precision drop. Our findings reveal these EL paradigms can not correctly handle unlinkable mentions (NIL), so they are not robust to partial KB inference. We also propose two simple-and-effective redemption methods to combat the NIL issue with litt
    
[^19]: 重新审视生物医学领域自动问题摘要的评估

    Revisiting Automatic Question Summarization Evaluation in the Biomedical Domain. (arXiv:2303.10328v1 [cs.CL])

    [http://arxiv.org/abs/2303.10328](http://arxiv.org/abs/2303.10328)

    本研究重新审视了生物医学领域中自动问题摘要的评估方法，通过人工评估发现当前自动评估指标和摘要系统存在不同值得关注的特征，并发布了一个数据集以促进未来的研究。

    

    自动化评估指标通过提供快速且公正的摘要质量评估，促进了摘要方法的快速发展。然而，这些指标大多是为一般领域，特别是新闻和会议记录，或其他语言生成任务开发的。这些指标被应用于评估在不同领域中的摘要系统，例如生物医学问题摘要。为了更好地了解常用的评估指标是否能够评估生物医学领域中的自动化摘要，我们进行了人工评估，并从生物医学问题摘要任务的四个不同方面评估了摘要质量。根据人类评判，我们发现当前自动评估指标和摘要系统存在不同值得关注的特征。我们还发布了我们的人工注释数据集，以促进生物医学领域摘要评估指标的研究。

    Automatic evaluation metrics have been facilitating the rapid development of automatic summarization methods by providing instant and fair assessments of the quality of summaries. Most metrics have been developed for the general domain, especially news and meeting notes, or other language-generation tasks. However, these metrics are applied to evaluate summarization systems in different domains, such as biomedical question summarization. To better understand whether commonly used evaluation metrics are capable of evaluating automatic summarization in the biomedical domain, we conduct human evaluations of summarization quality from four different aspects of a biomedical question summarization task. Based on human judgments, we identify different noteworthy features for current automatic metrics and summarization systems as well. We also release a dataset of our human annotations to aid the research of summarization evaluation metrics in the biomedical domain.
    
[^20]: 在线社交媒体中恐惧言论的兴起

    On the rise of fear speech in online social media. (arXiv:2303.10311v1 [cs.SI])

    [http://arxiv.org/abs/2303.10311](http://arxiv.org/abs/2303.10311)

    本研究通过抓取Gab.com上40万个恐惧言论和70多万个仇恨言论，揭示了恐惧言论在社交媒体中的普遍性和效果。发布大量恐惧言论的用户比发布大量仇恨言论的用户更容易获得追随者和在社交网络中占据核心地位，他们还能更有效地接触到良性用户。

    

    最近，社交媒体平台进行了大量的审查，以防止在线仇恨言论的传播，这些言论通常充满有毒的词汇，是针对个人或社区的。由于这种严格的审查，越来越多的新颖而微妙的技术正在被部署。其中最引人注目的是恐惧言论。正如其名称所示，恐惧言论试图在目标社区中引起恐惧。虽然它是微妙的，但它可能非常有效，经常将社区推向身体冲突。因此，了解社交媒体中它们的普遍性是至关重要的。本文介绍了一项大规模研究，旨在了解从Gab.com收集的40万个恐惧言论和70多万个仇恨言论的普及率。值得注意的是，发布大量恐惧言论的用户比发布大量仇恨言论的用户获取更多的追随者，并在社交网络中占据更为核心的位置。与仇恨言论用户相比，他们还能更有效地接触到良性用户。我们的分析显示，用户对恐惧言论的接受程度在这一现象中发挥了重要作用。最后，我们讨论了研究结果的含义，并提出了可能检测和预防社交媒体中恐惧言论的方式。

    Recently, social media platforms are heavily moderated to prevent the spread of online hate speech, which is usually fertile in toxic words and is directed toward an individual or a community. Owing to such heavy moderation, newer and more subtle techniques are being deployed. One of the most striking among these is fear speech. Fear speech, as the name suggests, attempts to incite fear about a target community. Although subtle, it might be highly effective, often pushing communities toward a physical conflict. Therefore, understanding their prevalence in social media is of paramount importance. This article presents a large-scale study to understand the prevalence of 400K fear speech and over 700K hate speech posts collected from Gab.com. Remarkably, users posting a large number of fear speech accrue more followers and occupy more central positions in social networks than users posting a large number of hate speech. They can also reach out to benign users more effectively than hate sp
    
[^21]: 会话树搜索：一项新的混合对话任务

    Conversational Tree Search: A New Hybrid Dialog Task. (arXiv:2303.10227v1 [cs.CL])

    [http://arxiv.org/abs/2303.10227](http://arxiv.org/abs/2303.10227)

    本文介绍了一项新的任务——会话树搜索(CTS)，它可以架起FAQ和对话之间的桥梁，领域专家可以定义对话树，然后将其转换为一个有效的对话策略，只学习提出导航用户达到目标所需的问题。

    

    对话接口提供了一种灵活和方便的方式，让用户获取原本可能难以或不方便获得的信息。然而，现有的界面大体上可以分为两种类型：FAQ，用户必须提出明确的问题以检索一般的答案；或者对话，用户必须遵循预定义的路径但可能会接收到个性化的答案。本文介绍了一种新的任务——会话树搜索(CTS)，它架起了信息检索风格FAQ和面向任务对话之间的桥梁，允许领域专家定义对话树，然后将其转换为一个有效的对话策略，只学习提出导航用户达到目标所需的问题。我们收集了旅行报销领域的数据集，并展示了这项任务的基线（baseline）以及一项新颖的深度增强学习架构。结果显示，新的架构综合了FAQ和对话的优点，取得了良好的效果。

    Conversational interfaces provide a flexible and easy way for users to seek information that may otherwise be difficult or inconvenient to obtain. However, existing interfaces generally fall into one of two categories: FAQs, where users must have a concrete question in order to retrieve a general answer, or dialogs, where users must follow a predefined path but may receive a personalized answer. In this paper, we introduce Conversational Tree Search (CTS) as a new task that bridges the gap between FAQ-style information retrieval and task-oriented dialog, allowing domain-experts to define dialog trees which can then be converted to an efficient dialog policy that learns only to ask the questions necessary to navigate a user to their goal. We collect a dataset for the travel reimbursement domain and demonstrate a baseline as well as a novel deep Reinforcement Learning architecture for this task. Our results show that the new architecture combines the positive aspects of both the FAQ and 
    
[^22]: 利用ChatGPT和Prompt Learning将放射学报告翻译成通俗易懂的语言：结果、限制和潜力。

    Translating Radiology Reports into Plain Language using ChatGPT and GPT-4 with Prompt Learning: Promising Results, Limitations, and Potential. (arXiv:2303.09038v1 [cs.CL])

    [http://arxiv.org/abs/2303.09038](http://arxiv.org/abs/2303.09038)

    本文研究探讨利用ChatGPT将放射学报告翻译成通俗易懂的语言，平均得分为5分制的4.1分，信息缺失率和信息错误率均较低，ChatGPT提供的建议大都与放射学报告相关。

    

    ChatGPT作为一种大型语言模型，以其类似人类表达和推理能力而备受关注。本研究探讨使用ChatGPT将放射学报告翻译成通俗易懂的语言的可行性，以便患者和医疗服务提供者得到更好的医疗教育。研究采集了62份低剂量胸部CT肺癌筛查扫描和76份脑MRI转移性筛查扫描的放射学报告。根据放射科医师的评价，ChatGPT可以成功将放射学报告翻译成通俗易懂的语言，平均得分为5分制的4.1分，信息缺失0.07处，信息错误0.11处。就ChatGPT提供的建议而言，它们是一般性的相关建议，例如保持与医生的随访和密切监测任何症状，对于共138个病例中的约37％，ChatGPT提供了与放射学报告有关的建议。

    The large language model called ChatGPT has drawn extensively attention because of its human-like expression and reasoning abilities. In this study, we investigate the feasibility of using ChatGPT in experiments on using ChatGPT to translate radiology reports into plain language for patients and healthcare providers so that they are educated for improved healthcare. Radiology reports from 62 low-dose chest CT lung cancer screening scans and 76 brain MRI metastases screening scans were collected in the first half of February for this study. According to the evaluation by radiologists, ChatGPT can successfully translate radiology reports into plain language with an average score of 4.1 in the five-point system with 0.07 places of information missing and 0.11 places of misinformation. In terms of the suggestions provided by ChatGPT, they are general relevant such as keeping following-up with doctors and closely monitoring any symptoms, and for about 37% of 138 cases in total ChatGPT offer
    
[^23]: 检测大型语言模型生成文字的科学

    The Science of Detecting LLM-Generated Texts. (arXiv:2303.07205v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.07205](http://arxiv.org/abs/2303.07205)

    本文综述了现有大型语言模型生成文本检测技术并提出了关键考虑因素，如开发全面评估指标和开源 LLM 所构成的威胁。

    

    大型语言模型 (LLMs) 的出现导致了高度复杂且几乎难以区分出是否为人类创作的 LLM 生成文字。但是，这也引发了对此类文字潜在误用的担忧，例如传播错误信息和在教育系统中造成混乱。尽管已提出许多检测方法，但关于其成就和挑战的全面理解仍然缺乏。本文旨在概述现有的 LLM 生成文本检测技术，并增强对语言生成模型的控制和监管。此外，我们强调未来研究的重要考虑因素，包括开发全面评估指标和开源 LLM 所构成的威胁，以推动 LLM 生成文本检测领域的进展。

    The emergence of large language models (LLMs) has resulted in the production of LLM-generated texts that is highly sophisticated and almost indistinguishable from texts written by humans. However, this has also sparked concerns about the potential misuse of such texts, such as spreading misinformation and causing disruptions in the education system. Although many detection approaches have been proposed, a comprehensive understanding of the achievements and challenges is still lacking. This survey aims to provide an overview of existing LLM-generated text detection techniques and enhance the control and regulation of language generation models. Furthermore, we emphasize crucial considerations for future research, including the development of comprehensive evaluation metrics and the threat posed by open-source LLMs, to drive progress in the area of LLM-generated text detection.
    
[^24]: 交互式文本生成

    Interactive Text Generation. (arXiv:2303.00908v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.00908](http://arxiv.org/abs/2303.00908)

    本研究提出了一种新的交互式文本生成任务，使用用户模拟器进行交互式训练生成模型，避免了真实用户参与的成本，并通过提供编辑指导模型朝着给定目标前进，从而提高了生成质量。

    

    用户每天都要与文本、图片、代码或其他编辑器互动。然而，机器学习模型很少在反映用户与编辑器之间互动的设置中进行训练。这是可以理解的，因为使用真实用户进行AI模型的训练不仅速度慢且成本高，而且这些模型所学习的内容可能特定于用户界面设计选择。不幸的是，这意味着大多数文本、代码和图像生成的研究都集中在非交互设置上，即模型被期望在没有考虑任何来自愿意帮助的用户输入的情况下完成所有任务。我们引入了一项新的交互式文本生成任务，允许使用用户模拟器进行交互式训练生成模型，无需涉及真实用户的成本，模拟器通过提供编辑指导模型朝着给定的目标文本前进。我们使用模仿学习训练我们的交互式模型，并与具有竞争力的非交互式生成模型进行了实验比较。

    Users interact with text, image, code, or other editors on a daily basis. However, machine learning models are rarely trained in the settings that reflect the interactivity between users and their editor. This is understandable as training AI models with real users is not only slow and costly, but what these models learn may be specific to user interface design choices. Unfortunately, this means most of the research on text, code, and image generation has focused on non-interactive settings, whereby the model is expected to get everything right without accounting for any input from a user who may be willing to help.  We introduce a new Interactive Text Generation task that allows training generation models interactively without the costs of involving real users, by using user simulators that provide edits that guide the model towards a given target text. We train our interactive models using Imitation Learning, and our experiments against competitive non-interactive generation models s
    
[^25]: 乌兹别克文本与学生教育潜力的对应关系：学校语料库案例研究

    Uzbek text's correspondence with the educational potential of pupils: a case study of the School corpus. (arXiv:2303.00465v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.00465](http://arxiv.org/abs/2303.00465)

    本文研究了使用学校语料库自动确定推荐给学生的教材与学生的教育材料之间的对应关系，为教育系统选择适当的内容提供了参考。

    

    教育系统面临的主要挑战之一是选择适合学生年龄和思维潜力的内容。本文研究了小学一年级到四年级的实验，旨在通过使用学校语料库自动确定推荐给学生的教材与学生的教育材料之间的对应关系。该语料库包括乌兹别克斯坦幼儿园和学校教育部确认的25本学校教科书的数据集。在这种情况下，计算文本的TF-IDF分数并将其转换为向量表示，然后使用余弦相似性算法比较所给的教育材料与学校语料库相应班级的内容。根据计算结果，确定所给教育材料是否适合学生的教育潜力。

    One of the major challenges of an educational system is choosing appropriate content considering pupils' age and intellectual potential. In this article the experiment of primary school grades (from 1st to 4th grades) is considered for automatically determining the correspondence of an educational materials recommended for pupils by using the School corpus where it includes the dataset of 25 school textbooks confirmed by the Ministry of preschool and school education of the Republic of Uzbekistan. In this case, TF-IDF scores of the texts are determined, they are converted into a vector representation, and the given educational materials are compared with the corresponding class of the School corpus using the cosine similarity algorithm. Based on the results of the calculation, it is determined whether the given educational material is appropriate or not appropriate for the pupils' educational potential.
    
[^26]: AugGPT：利用ChatGPT进行文本数据增强

    AugGPT: Leveraging ChatGPT for Text Data Augmentation. (arXiv:2302.13007v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.13007](http://arxiv.org/abs/2302.13007)

    AugGPT提出了一种基于ChatGPT的文本数据增强方法，该方法能够更忠实地保留正确标记的生成数据并提供足够的多样性，从而有效地缓解了自然语言处理任务中的限制样本量的问题。

    

    文本数据增强是受限制的样本量在许多自然语言处理（NLP）任务中克服挑战的有效策略。对于少样本学习场景，其中目标域的数据通常更加稀缺且质量更低，这一挑战特别突出。为了更好地捕捉数据不变性并增加样本量，缓解这种挑战的一种自然且广泛使用的策略是执行数据增强。然而，当前的文本数据增强方法要么无法保证生成数据的正确标记（缺乏忠实度），要么无法保证生成的数据具有足够的多样性（缺乏紧凑性），或者两者都有。在大语言模型的最近成功，尤其是在开发ChatGPT方面展示了改进的语言理解能力的基础上，本文提出了一种基于ChatGPT（名为AugGPT）的文本数据增强方法。

    Text data augmentation is an effective strategy for overcoming the challenge of limited sample sizes in many natural language processing (NLP) tasks. This challenge is especially prominent in the few-shot learning scenario, where the data in the target domain is generally much scarcer and of lowered quality. A natural and widely-used strategy to mitigate such challenges is to perform data augmentation to better capture the data invariance and increase the sample size. However, current text data augmentation methods either can't ensure the correct labeling of the generated data (lacking faithfulness) or can't ensure sufficient diversity in the generated data (lacking compactness), or both. Inspired by the recent success of large language models, especially the development of ChatGPT, which demonstrated improved language comprehension abilities, in this work, we propose a text data augmentation approach based on ChatGPT (named AugGPT). AugGPT rephrases each sentence in the training sampl
    
[^27]: 利用逻辑学习从嘈杂的众包标签中学习

    Learning from Noisy Crowd Labels with Logics. (arXiv:2302.06337v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.06337](http://arxiv.org/abs/2302.06337)

    这篇论文介绍了一种利用逻辑引导的从嘈杂的众包标签中学习的框架，能够改进文本分类和命名实体识别等任务中，学习从嘈杂数据中提取有效信息的方法，这种框架能够融合逻辑知识，提高现有技术水平。

    

    本文探讨了将符号逻辑知识集成到深度神经网络中，从嘈杂的众包标签中学习的方法。我们引入了一种逻辑引导的从嘈杂的众包标签中学习的框架（Logic-LNCL），这是一种类似EM的迭代逻辑知识蒸馏框架，能够从嘈杂的标记数据和感兴趣的逻辑规则中进行学习。与传统的EM方法不同，我们的框架包含一种“伪E步骤”，从逻辑规则中蒸馏出一种新类型的学习目标，然后在“伪M步骤”中使用该目标来训练分类器。在文本情感分类和命名实体识别的两个真实世界数据集上进行的广泛评估表明，所提出的框架改进了最先进技术并为从嘈杂的众包标签中学习提供了一种新的解决方案。

    This paper explores the integration of symbolic logic knowledge into deep neural networks for learning from noisy crowd labels. We introduce Logic-guided Learning from Noisy Crowd Labels (Logic-LNCL), an EM-alike iterative logic knowledge distillation framework that learns from both noisy labeled data and logic rules of interest. Unlike traditional EM methods, our framework contains a ``pseudo-E-step'' that distills from the logic rules a new type of learning target, which is then used in the ``pseudo-M-step'' for training the classifier. Extensive evaluations on two real-world datasets for text sentiment classification and named entity recognition demonstrate that the proposed framework improves the state-of-the-art and provides a new solution to learning from noisy crowd labels.
    
[^28]: 基于细粒度语义信息的关系抽取FGSI：一种基于远程监督的方法

    FGSI: Distant Supervision for Relation Extraction method based on Fine-Grained Semantic Information. (arXiv:2302.02078v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.02078](http://arxiv.org/abs/2302.02078)

    本研究提出了一种基于远程监督的关系抽取方法，该方法通过利用句子中的细粒度语义信息来减少干扰信息，提高了实体关系提取的准确性。

    

    关系抽取的主要目的是提取句子中标记实体对之间的语义关系，它在句子的语义理解和知识图谱构建中发挥着重要作用。本文提出，在句子内部的关键语义信息对实体关系的提取起着重要作用。我们基于这个假设，按照实体在句子内部的位置将句子分为三段，并通过句内注意机制找到句子内部的细粒度语义特征，以减少无关噪声信息的干扰。所提出的关系抽取模型可以充分利用可用的正面语义信息。实验结果表明该方法在两个基准数据集上的表现优于几种最先进的基线方法。

    The main purpose of relation extraction is to extract the semantic relationships between tagged pairs of entities in a sentence, which plays an important role in the semantic understanding of sentences and the construction of knowledge graphs. In this paper, we propose that the key semantic information within a sentence plays a key role in the relationship extraction of entities. We propose the hypothesis that the key semantic information inside the sentence plays a key role in entity relationship extraction. And based on this hypothesis, we split the sentence into three segments according to the location of the entity from the inside of the sentence, and find the fine-grained semantic features inside the sentence through the intra-sentence attention mechanism to reduce the interference of irrelevant noise information. The proposed relational extraction model can make full use of the available positive semantic information. The experimental results show that the proposed relation extra
    
[^29]: ChatGPT作为翻译引擎，依赖于GPT-4，是一种好的翻译器吗？

    Is ChatGPT A Good Translator? Yes With GPT-4 As The Engine. (arXiv:2301.08745v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.08745](http://arxiv.org/abs/2301.08745)

    本论文评估了ChatGPT的机器翻译能力，发现它在高资源欧洲语言上表现良好，但在低资源或远程语言上表现滞后；采用枢轴提示可以显著提高远程语言翻译的性能；在生物医学摘要或Reddit评论方面，ChatGPT的表现不如商业系统。

    

    本报告对ChatGPT进行了机器翻译的初步评估，包括翻译提示、多语言翻译和翻译的鲁棒性。我们采用ChatGPT建议的提示来触发其翻译能力，发现候选提示通常运行良好，表现出轻微的性能差异。通过在多个基准测试集上进行评估，发现在高资源的欧洲语言上，ChatGPT的表现与商业翻译产品（例如Google翻译）相当，但在低资源或远程语言上表现显著滞后。对于远程语言，我们探索了一种有趣的策略，称为$\mathbf{枢轴提示}$，即让ChatGPT先将源语言句子翻译成高资源的轴语言，再翻译目标语言，这显著提高了翻译性能。至于翻译的鲁棒性，在生物医学摘要或Reddit评论方面，ChatGPT的表现不如商业系统。

    This report provides a preliminary evaluation of ChatGPT for machine translation, including translation prompt, multilingual translation, and translation robustness. We adopt the prompts advised by ChatGPT to trigger its translation ability and find that the candidate prompts generally work well and show minor performance differences. By evaluating on a number of benchmark test sets, we find that ChatGPT performs competitively with commercial translation products (e.g., Google Translate) on high-resource European languages but lags behind significantly on low-resource or distant languages. For distant languages, we explore an interesting strategy named $\mathbf{pivot~prompting}$ that asks ChatGPT to translate the source sentence into a high-resource pivot language before into the target language, which improves the translation performance significantly. As for the translation robustness, ChatGPT does not perform as well as the commercial systems on biomedical abstracts or Reddit commen
    
[^30]: 一个基于误差引导的模型用于汉语拼写纠错

    An Error-Guided Correction Model for Chinese Spelling Error Correction. (arXiv:2301.06323v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.06323](http://arxiv.org/abs/2301.06323)

    本文提出了一个基于误差引导的模型用于改进汉语拼写纠错，它采用了零-shot误差检测、新的损失函数和高度并行的解码等方法，在实验中表现优于先进方法。

    

    虽然现有的神经网络方法在汉语拼写纠错方面取得了巨大成功，但仍有进一步提高的空间。在本文中，我们提出了一个误差引导的纠错模型（EGCM）来改进汉语拼写纠错。通过借鉴BERT的强大能力，我们提出了一种新的零-shot误差检测方法来进行初步检测，这样可以指导我们的模型在编码时更多地关注可能错误的标记，并在生成时避免修改正确的标记。此外，我们还引入了新的损失函数来集成误差混淆集，这使得我们的模型能够轻松区分易混淆的标记。此外，我们的模型支持高度并行的解码，以满足实际应用的要求。我们在广泛使用的基准测试中进行了实验。我们的模型优于先进方法。

    Although existing neural network approaches have achieved great success on Chinese spelling correction, there is still room to improve. The model is required to avoid over-correction and to distinguish a correct token from its phonological and visually similar ones. In this paper, we propose an error-guided correction model (EGCM) to improve Chinese spelling correction. By borrowing the powerful ability of BERT, we propose a novel zero-shot error detection method to do a preliminary detection, which guides our model to attend more on the probably wrong tokens in encoding and to avoid modifying the correct tokens in generating. Furthermore, we introduce a new loss function to integrate the error confusion set, which enables our model to distinguish easily misused tokens. Moreover, our model supports highly parallel decoding to meet real application requirements. Experiments are conducted on widely used benchmarks. Our model achieves superior performance against state-of-the-art approach
    
[^31]: MN-DS：新闻文章层次分类的多标签数据集

    MN-DS: A Multilabeled News Dataset for News Articles Hierarchical Classification. (arXiv:2212.12061v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.12061](http://arxiv.org/abs/2212.12061)

    本文介绍了一个包含10,917篇新闻文章的多标签数据集，可用于训练机器学习模型自动按主题对新闻文章进行分类，对新闻结构、分类和预测未来事件的研究人员非常有帮助。

    

    本文介绍了一个数据集，其中包含10,917篇新闻文章，涵盖了从2019年1月1日到2019年12月31日的层次新闻分类。我们根据17个一级类别和109个二级类别的层次分类手动标记了这些文章。该数据集可用于训练机器学习模型，以自动按主题分类新闻文章。该数据集对于从事新闻结构、分类和根据发布的新闻预测未来事件的研究人员非常有帮助。

    This article presents a dataset of 10,917 news articles with hierarchical news categories collected between January 1st 2019, and December 31st 2019. We manually labelled the articles based on a hierarchical taxonomy with 17 first-level and 109 second-level categories. This dataset can be used to train machine learning models for automatically classifying news articles by topic. This dataset can be helpful for researchers working on news structuring, classification, and predicting future events based on released news.
    
[^32]: LLM-Planner: 利用大型语言模型进行少样本实体代理规划

    LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models. (arXiv:2212.04088v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.04088](http://arxiv.org/abs/2212.04088)

    本研究提出了一种新颖的方法LLM-Planner，利用大型语言模型为实体代理进行少样本规划，以实体代理目前所在的环境为基础，增强LLMs生成和更新计划，实验表明其在多任务和快速学习新任务的通用代理的开发中具有很好的表现。

    

    本研究关注利用大型语言模型（LLMs）作为规划器，让实体代理可以按照自然语言指令完成在视觉感知环境中的复杂任务。现有方法的高数据成本和低样本效率阻碍了多任务和快速学习新任务的通用代理的开发。本文提出了一种新颖的方法LLM-Planner，利用大型语言模型为实体代理进行少样本规划。我们进一步提出了一种简单但有效的方法，以实体代理目前所在的环境为基础，增强LLMs生成和更新计划。在ALFRED数据集上的实验表明，我们的方法可以取得非常有竞争力的少样本性能：尽管使用的配对训练数据不到0.5％，LLM-Planner的表现与使用完整训练数据训练的最新基线相当。现有方法几乎无法完成任何任务。

    This study focuses on using large language models (LLMs) as a planner for embodied agents that can follow natural language instructions to complete complex tasks in a visually-perceived environment. The high data cost and poor sample efficiency of existing methods hinders the development of versatile agents that are capable of many tasks and can learn new tasks quickly. In this work, we propose a novel method, LLM-Planner, that harnesses the power of large language models to do few-shot planning for embodied agents. We further propose a simple but effective way to enhance LLMs with physical grounding to generate and update plans that are grounded in the current environment. Experiments on the ALFRED dataset show that our method can achieve very competitive few-shot performance: Despite using less than 0.5% of paired training data, LLM-Planner achieves competitive performance with recent baselines that are trained using the full training data. Existing methods can barely complete any ta
    
[^33]: VieCap4H-VLSP 2021：使用Attention on Attention增强物体关系Transformer的性能，提高越南图像字幕生成能力.

    VieCap4H-VLSP 2021: ObjectAoA-Enhancing performance of Object Relation Transformer with Attention on Attention for Vietnamese image captioning. (arXiv:2211.05405v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.05405](http://arxiv.org/abs/2211.05405)

    本文提出了一种使用Attention on Attention机制来提高基于Transformer方法的图像理解能力的方法，实验结果显示其在VieCap4H数据集上表现显著优于其原始结构。

    

    图像字幕生成是一项需要理解视觉信息并使用自然语言描述图像的挑战性任务。本文提出了一种扩展物体关系Transformer结构的Attention on Attention机制，从而提高了基于Transformer方法的图像理解能力。在VieCap4H数据集上的实验表明，我们提出的方法在VLSP举办的图像字幕生成任务的公共测试和私人测试中都显著优于其原始结构。

    Image captioning is currently a challenging task that requires the ability to both understand visual information and use human language to describe this visual information in the image. In this paper, we propose an efficient way to improve the image understanding ability of transformer-based method by extending Object Relation Transformer architecture with Attention on Attention mechanism. Experiments on the VieCap4H dataset show that our proposed method significantly outperforms its original structure on both the public test and private test of the Image Captioning shared task held by VLSP.
    
[^34]: 差分隐私保护下的大规模语言模型私有微调

    Privately Fine-Tuning Large Language Models with Differential Privacy. (arXiv:2210.15042v3 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2210.15042](http://arxiv.org/abs/2210.15042)

    该论文介绍了如何使用差分隐私保护方法在微调大规模语言模型时防止个人信息泄露。

    

    预训练的大规模语言模型（LLM）是现代人工智能的重要组成部分，已经在复杂的人工智能任务中实现了突破性表现。然而，已经证明，攻击者可以从这些LLM中提取/重建出确切的训练样本，这可能会导致泄露个人识别信息。差分隐私（DP）提供了一个严谨的框架，允许在训练或微调LLM过程中添加噪声，使提取训练数据变得不可行。

    Pre-trained Large Language Models (LLMs) are an integral part of modern AI that have led to breakthrough performances in complex AI tasks. Major AI companies with expensive infrastructures are able to develop and train these large models with billions and millions of parameters from scratch. Third parties, researchers, and practitioners are increasingly adopting these pre-trained models and fine-tuning them on their private data to accomplish their downstream AI tasks. However, it has been shown that an adversary can extract/reconstruct the exact training samples from these LLMs, which can lead to revealing personally identifiable information. The issue has raised deep concerns about the privacy of LLMs. Differential privacy (DP) provides a rigorous framework that allows adding noise in the process of training or fine-tuning LLMs such that extracting the training data becomes infeasible (i.e., with a cryptographically small success probability). While the theoretical privacy guarantees
    
[^35]: PACIFIC：面向金融领域表格和文本数据的主动对话问答系统

    PACIFIC: Towards Proactive Conversational Question Answering over Tabular and Textual Data in Finance. (arXiv:2210.08817v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.08817](http://arxiv.org/abs/2210.08817)

    PACIFIC是一个金融领域的主动对话问答系统，特点是数字推理和混合语境，提出了PCQA任务，提供了新方法UniPCQA来适应这个任务。在PACIFIC数据集上进行了全面评估。

    

    为了促进金融领域混合语境下的对话问答，我们提出了一个名为PACIFIC的新数据集。与现有的对话问答数据集相比，PACIFIC具有三个关键特征：主动性、数字推理和表格和文本的混合语境。我们定义了一个新的任务，即研究主动对话问答系统(PCQA)，它结合了澄清问题生成和对话问答功能。此外，我们提出了一种新方法UniPCQA，将PCQA中输入和输出内容的混合格式适应于Seq2Seq问题，包括将数字推理过程重新定义为代码生成。UniPCQA在PCQA的所有子任务中进行多任务学习，并结合简单的集成策略，通过交叉验证top-k样本中的Seq2Seq输出来减轻多任务学习中的误差传播问题。我们通过广泛的基线测试对PACIFIC数据集进行基准测试，并对每个子任务进行全面评估。

    To facilitate conversational question answering (CQA) over hybrid contexts in finance, we present a new dataset, named PACIFIC. Compared with existing CQA datasets, PACIFIC exhibits three key features: (i) proactivity, (ii) numerical reasoning, and (iii) hybrid context of tables and text. A new task is defined accordingly to study Proactive Conversational Question Answering (PCQA), which combines clarification question generation and CQA. In addition, we propose a novel method, namely UniPCQA, to adapt a hybrid format of input and output content in PCQA into the Seq2Seq problem, including the reformulation of the numerical reasoning process as code generation. UniPCQA performs multi-task learning over all sub-tasks in PCQA and incorporates a simple ensemble strategy to alleviate the error propagation issue in the multi-task learning by cross-validating top-$k$ sampled Seq2Seq outputs. We benchmark the PACIFIC dataset with extensive baselines and provide comprehensive evaluations on eac
    
[^36]: MTEB: 大规模文本嵌入基准测试

    MTEB: Massive Text Embedding Benchmark. (arXiv:2210.07316v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.07316](http://arxiv.org/abs/2210.07316)

    本文提出了一个大规模文本嵌入基准测试(MTEB)，该基准测试涵盖了8个嵌入任务、58个数据集和112种语言，以解决文本嵌入在不同任务中表现差异的问题。通过33个模型的测试，作者发现该领域尚未收敛于一种通用的文本嵌入方法，

    

    文本嵌入通常在覆盖其他任务的可能应用时，仅在单个任务的少量数据集上进行评估。目前还不清楚在语义文本相似度（STS）上最先进的嵌入方法是否同样适用于其他任务，比如聚类或重新排序。这使得评估该领域的进展变得困难，因为各种模型不断被提出却没有得到适当的评估。为了解决这个问题，我们引入了大规模文本嵌入基准测试（MTEB）。MTEB涵盖8个嵌入任务，涵盖58个数据集和112个语言。通过在MTEB上对33个模型进行基准测试，我们建立了迄今为止最全面的文本嵌入基准。我们发现，没有任何一种特定的文本嵌入方法在所有任务中都占据优势。这表明该领域尚未收敛于一种通用的文本嵌入方法，并将其扩展足够大以在所有嵌入任务中提供最先进的结果。MTEB附带开源代码和数据，以使社区能够基准测试新的嵌入模型并跟踪该领域的进展。

    Text embeddings are commonly evaluated on a small set of datasets from a single task not covering their possible applications to other tasks. It is unclear whether state-of-the-art embeddings on semantic textual similarity (STS) can be equally well applied to other tasks like clustering or reranking. This makes progress in the field difficult to track, as various models are constantly being proposed without proper evaluation. To solve this problem, we introduce the Massive Text Embedding Benchmark (MTEB). MTEB spans 8 embedding tasks covering a total of 58 datasets and 112 languages. Through the benchmarking of 33 models on MTEB, we establish the most comprehensive benchmark of text embeddings to date. We find that no particular text embedding method dominates across all tasks. This suggests that the field has yet to converge on a universal text embedding method and scale it up sufficiently to provide state-of-the-art results on all embedding tasks. MTEB comes with open-source code and
    
[^37]: 十亿级预训练多模态商业知识图谱的构建与应用

    Construction and Applications of Billion-Scale Pre-Trained Multimodal Business Knowledge Graph. (arXiv:2209.15214v6 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2209.15214](http://arxiv.org/abs/2209.15214)

    本文介绍了一个基于阿里巴巴集团的空前规模的 OpenBG 商业知识图谱，包含超过 88 百万实体和 26 亿三元组。它具有精细的分类和多模态事实，有助于推动商业智能化的发展。

    

    商业知识图谱是当前许多企业的重要组成部分，为许多产品提供事实知识和结构化数据，使它们变得更加智能化。尽管它们有着许多潜在的好处，但构建商业知识图谱需要解决结构不足和多模态的限制等问题。本文深入探讨了在非微不足道的实际应用系统中构建知识图谱所面临的挑战。我们介绍了一个基于阿里巴巴集团的 OpenBG 商业知识图谱的构建过程。具体来说，我们定义了一个核心本体，涵盖各种抽象产品和消费需求，并在部署的应用中提供精细的分类和多模态事实。OpenBG 是一个空前规模的商业知识图谱：包含超过 88 百万实体、覆盖超过 1 百万个核心类/概念和 2,681 种关系的 26 亿三元组。我们公开了所有的资源和基准数据集，以促进知识图谱的发展和研究。

    Business Knowledge Graphs (KGs) are important to many enterprises today, providing factual knowledge and structured data that steer many products and make them more intelligent. Despite their promising benefits, building business KG necessitates solving prohibitive issues of deficient structure and multiple modalities. In this paper, we advance the understanding of the practical challenges related to building KG in non-trivial real-world systems. We introduce the process of building an open business knowledge graph (OpenBG) derived from a well-known enterprise, Alibaba Group. Specifically, we define a core ontology to cover various abstract products and consumption demands, with fine-grained taxonomy and multimodal facts in deployed applications. OpenBG is an open business KG of unprecedented scale: 2.6 billion triples with more than 88 million entities covering over 1 million core classes/concepts and 2,681 types of relations. We release all the open resources (OpenBG benchmarks) deri
    
[^38]: EcoFormer：具有线性复杂度的节能注意力机制

    EcoFormer: Energy-Saving Attention with Linear Complexity. (arXiv:2209.09004v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2209.09004](http://arxiv.org/abs/2209.09004)

    EcoFormer是一种通过核哈希技术进行高维softmax注意力二值化的新方法，实现了具有线性时间复杂度的高效注意力模块，从而显著降低了计算和能量开销，同时在多个任务上取得了高性能。

    

    Transformer是一种用于建模序列数据的革命性框架，在广泛的任务中已经取得了显著的性能，但其高计算量和能源成本限制了其实际应用。为了提高Transformer的效率，压缩模型是一个受欢迎的选择，其中最常用的方法是通过二值化来将浮点值限制为二进制值，以便于进行位运算从而节省计算和能源开销。然而，现有的二值化方法只注重最大化统计上的输入分布信息而忽略了注意力机制中核心的相似度建模问题。为此，我们提出了一个新的二值化方法，通过核哈希技术对高维softmax注意力机制进行定制化处理，将原始查询和键嵌入到哈明空间的低维二进制编码中。核哈希函数是以自监督方式从注意力图中提取基本关系的相似度所学习的。在这些二进制编码的基础上，我们开发了一种具有线性时间复杂度的高效注意力模块，从而显著降低了计算和能量开销，相比于基本模型实现了较高的性能和可比性。我们进行了大量实验来验证其在图像分类、语言模型预训练和机器翻译等多个任务上的性能。

    Transformer is a transformative framework that models sequential data and has achieved remarkable performance on a wide range of tasks, but with high computational and energy cost. To improve its efficiency, a popular choice is to compress the models via binarization which constrains the floating-point values into binary ones to save resource consumption owing to cheap bitwise operations significantly. However, existing binarization methods only aim at minimizing the information loss for the input distribution statistically, while ignoring the pairwise similarity modeling at the core of the attention. To this end, we propose a new binarization paradigm customized to high-dimensional softmax attention via kernelized hashing, called EcoFormer, to map the original queries and keys into low-dimensional binary codes in Hamming space. The kernelized hash functions are learned to match the ground-truth similarity relations extracted from the attention map in a self-supervised way. Based on th
    
[^39]: 基于有向图的跨模态特征补充方法用于多模态对话情感识别

    GraphCFC: A Directed Graph based Cross-modal Feature Complementation Approach for Multimodal Conversational Emotion Recognition. (arXiv:2207.12261v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2207.12261](http://arxiv.org/abs/2207.12261)

    本文提出了一种基于有向图的跨模态特征补充方法，可以提取多模态上下文信息和交互信息，缓解了多模态融合中的异构性差距问题。

    

    对话情感识别在人机交互系统中起着重要作用，因为它可以提供有共情心理的服务。多模态对话情感识别可以缓解单模态方法的缺点。最近，由于关系建模方面的卓越性能，图神经网络已被广泛用于各种领域。在多模态对话情感识别中，图神经网络能够提取远距离的上下文信息和跨模态的交互信息。不幸的是，由于现有方法（如MMGCN）直接融合多个模态，可能会产生冗余信息，且可能丢失多样化的信息。在本文中，我们提出了一种基于有向图的跨模态特征补充（GraphCFC）模块，可以有效地模拟上下文和互动信息。GraphCFC通过利用多个子空间提取器和成对跨模态补充（PairCC）策略，缓解了多模态融合中的异构性差距问题。

    Emotion Recognition in Conversation (ERC) plays a significant part in Human-Computer Interaction (HCI) systems since it can provide empathetic services. Multimodal ERC can mitigate the drawbacks of uni-modal approaches. Recently, Graph Neural Networks (GNNs) have been widely used in a variety of fields due to their superior performance in relation modeling. In multimodal ERC, GNNs are capable of extracting both long-distance contextual information and inter-modal interactive information. Unfortunately, since existing methods such as MMGCN directly fuse multiple modalities, redundant information may be generated and diverse information may be lost. In this work, we present a directed Graph based Cross-modal Feature Complementation (GraphCFC) module that can efficiently model contextual and interactive information. GraphCFC alleviates the problem of heterogeneity gap in multimodal fusion by utilizing multiple subspace extractors and Pair-wise Cross-modal Complementary (PairCC) strategy. 
    
[^40]: 基于平面性与投影性定义下树的最大线性排列问题（arXiv:2206.06924v3[cs.DS] 更新版）

    The Maximum Linear Arrangement Problem for trees under projectivity and planarity. (arXiv:2206.06924v3 [cs.DS] UPDATED)

    [http://arxiv.org/abs/2206.06924](http://arxiv.org/abs/2206.06924)

    该论文提出了一种解决在平面性和投影性定义下树的最大线性排列问题的算法，证明了最大投影和平面排列的多个性质，发现毛毛虫树最优，推广了之前的极值结果。

    

    最大线性排列问题(MaxLA)是指找到从图G的n个顶点到不同连续整数的映射$ \pi $，使得$ D(G)=\sum_{uv\in E(G)}|\pi(u)-\pi(v)| $最大化。在这种情况下，顶点被认为在一条水平线上，并且边是作为半圆弧画在线上方的。存在一些限制排列的MaxLA变体。在平面变体中，禁止边交叉。在针对根树的投影变体中，排列是平面的，而根不能被任何边覆盖。在这里，我们提出了用于解决树的平面和投影MaxLA的O(n)-时间和O(n）-空间算法。我们还证明了最大投影和平面排列的多个性质，并且表明毛毛虫树在固定大小的所有树中最大化平面MaxLA，因此推广了先前关于树的极值结果。

    The Maximum Linear Arrangement problem (MaxLA) consists of finding a mapping $\pi$ from the $n$ vertices of a graph $G$ to distinct consecutive integers that maximizes $D(G)=\sum_{uv\in E(G)}|\pi(u) - \pi(v)|$. In this setting, vertices are considered to lie on a horizontal line and edges are drawn as semicircles above the line. There exist variants of MaxLA in which the arrangements are constrained. In the planar variant, edge crossings are forbidden. In the projective variant for rooted trees, arrangements are planar and the root cannot be covered by any edge. Here we present $O(n)$-time and $O(n)$-space algorithms that solve planar and projective MaxLA for trees. We also prove several properties of maximum projective and planar arrangements, and show that caterpillar trees maximize planar MaxLA over all trees of a fixed size thereby generalizing a previous extremal result on trees.
    
[^41]: 利用自监督学习研究大脑中的语音处理机制

    Toward a realistic model of speech processing in the brain with self-supervised learning. (arXiv:2206.01685v2 [q-bio.NC] UPDATED)

    [http://arxiv.org/abs/2206.01685](http://arxiv.org/abs/2206.01685)

    本研究针对语音处理问题，使用自监督学习的方法得到的特征与大脑神经元对于语音刺激的反应能够形成类似的层级，且解释了大脑活动的变化。该算法能够最少依赖先验语言和理解知识资源，并且需要的数据量远小于其它模型。

    

    最近研究发现一些深度神经网络对于输入的刺激反应能够与人脑神经元的活动十分相似。但这些算法存在数据量巨大、监督标签难以获取、只能接受文本输入以及需要高昂的存储资源等问题。这些限制表明需要寻找在这些限制下能够解释行为和大脑反应的算法。本研究专注于语音处理问题，假设基于原始波形的自监督算法成为一个有前景的候选方案。作者通过比较最近的自监督架构Wav2Vec 2.0和412名英语、法语和汉语听取约1小时音频书籍时的功能磁共振成像（fMRI）数据，展示了四个主要成果：首先，作者发现Wav2Vec 2.0和大脑神经元会将语音音频信息编码到类似时间变化的层级中。其次，作者证明这种对于音频层级的编码不是由于影响常规声音的表面因素导致。第三，作者还表明，与文本表示法或传统语音特征相比，通过无监督学习获得的特征可以更加准确地解释大脑活动的变化。最后，研究还展示了在最少的语言背景和理解知识资源下，可以通过自监督学习解释有意义的大脑活动。

    Several deep neural networks have recently been shown to generate activations similar to those of the brain in response to the same input. These algorithms, however, remain largely implausible: they require (1) extraordinarily large amounts of data, (2) unobtainable supervised labels, (3) textual rather than raw sensory input, and / or (4) implausibly large memory (e.g. thousands of contextual words). These elements highlight the need to identify algorithms that, under these limitations, would suffice to account for both behavioral and brain responses. Focusing on the issue of speech processing, we here hypothesize that self-supervised algorithms trained on the raw waveform constitute a promising candidate. Specifically, we compare a recent self-supervised architecture, Wav2Vec 2.0, to the brain activity of 412 English, French, and Mandarin individuals recorded with functional Magnetic Resonance Imaging (fMRI), while they listened to ~1h of audio books. Our results are four-fold. First
    
[^42]: NELA-GT-2022：一份用于研究新闻报道中误导信息的大型多标签新闻数据集

    NELA-GT-2022: A Large Multi-Labelled News Dataset for The Study of Misinformation in News Articles. (arXiv:2203.05659v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.05659](http://arxiv.org/abs/2203.05659)

    NELA-GT-2022是一份包含361个来源的1,778,361篇文章的多标签新闻数据集，可用于研究新闻报道中的误导信息。

    

    本文介绍了NELA-GT数据集的第五版，即NELA-GT-2022。该数据集包含361个来源的1,778,361篇文章，时间跨度为2022年1月1日至12月31日。与过去版本一样，NELA-GT-2022还包括来自Media Bias / Fact Check的出口级真实性标签以及嵌入收集的新闻文章中的推文。NELA-GT-2022数据集的获取链接为： https://doi.org/10.7910/DVN/AMCV2H

    In this paper, we present the fifth installment of the NELA-GT datasets, NELA-GT-2022. The dataset contains 1,778,361 articles from 361 outlets between January 1st, 2022 and December 31st, 2022. Just as in past releases of the dataset, NELA-GT-2022 includes outlet-level veracity labels from Media Bias/Fact Check and tweets embedded in collected news articles. The NELA-GT-2022 dataset can be found at: https://doi.org/10.7910/DVN/AMCV2H
    
[^43]: 用于本体子类预测的上下文语义嵌入

    Contextual Semantic Embeddings for Ontology Subsumption Prediction. (arXiv:2202.09791v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2202.09791](http://arxiv.org/abs/2202.09791)

    本文提出了一种名为BERTSubs的新型子类预测方法，用于OWL本体类，它可以预测包括来自同一本体或另一个本体的命名类以及来自同一本体的存在限制等多种子类。

    

    自动化本体构建和维护是知识工程和人工智能中重要但具有挑战性的任务。机器学习技术（如上下文语义嵌入）进行预测是一个有前途的方向，但是相关研究尤其是针对Web本体语言（OWL）中的表达型本体仍处在初步阶段。本文提出了一种名为BERTSubs的新型子类预测方法，用于OWL本体类。它利用预训练的语言模型BERT计算类的上下文嵌入，其中提出了自定义模板来结合类的上下文（例如邻近类）和逻辑存在限制。BERTSubs可以预测多种子类，包括来自同一本体或另一个本体的命名类以及来自同一本体的存在限制。在三种不同的子类任务上对五个真实世界本体进行了广泛评估，表明了BERTSubs的有效性。

    Automating ontology construction and curation is an important but challenging task in knowledge engineering and artificial intelligence. Prediction by machine learning techniques such as contextual semantic embedding is a promising direction, but the relevant research is still preliminary especially for expressive ontologies in Web Ontology Language (OWL). In this paper, we present a new subsumption prediction method named BERTSubs for classes of OWL ontology. It exploits the pre-trained language model BERT to compute contextual embeddings of a class, where customized templates are proposed to incorporate the class context (e.g., neighbouring classes) and the logical existential restriction. BERTSubs is able to predict multiple kinds of subsumers including named classes from the same ontology or another ontology, and existential restrictions from the same ontology. Extensive evaluation on five real-world ontologies for three different subsumption tasks has shown the effectiveness of th
    
[^44]: 基于记忆损失预测模型的事件抽取主动学习方法

    Active Learning for Event Extraction with Memory-based Loss Prediction Model. (arXiv:2112.03073v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2112.03073](http://arxiv.org/abs/2112.03073)

    本论文提出了一种基于深度学习的主动学习方法，采用基于批次的样本选择策略和记忆损失预测模型以降低事件注释成本，实验结果表明此方法优于现有主动学习方法且性能最优。

    

    事件抽取在许多工业应用场景中扮演着重要角色，高质量的事件抽取方法需要大量手动注释数据以训练监督学习模型。然而，获取注释数据的成本非常高，特别是对于领域事件注释，需要相应领域的专家参与。因此，我们引入主动学习技术来降低事件注释的成本。但是现有的主动学习方法存在两个主要问题，使它们无法很好地用于事件抽取。首先，现有的基于样本池选择的策略在计算成本和样本有效性方面存在局限性。其次，现有的样本重要性评估缺乏对本地样本信息的利用。在本文中，我们提出了一种新颖的基于深度学习的主动学习方法。我们提出了基于批次的选择策略和一个记忆损失预测模型（MBLP），以有效地选择未标记的样本。在选择过程中，MBLP被用来预测标记数据的可能损失，并指导选择具有最高信息增益的样本。在两个基准数据集上的实验表明，我们提出的方法优于现有的主动学习方法，并以显著降低注释成本的方式实现了最先进的性能。

    Event extraction (EE) plays an important role in many industrial application scenarios, and high-quality EE methods require a large amount of manual annotation data to train supervised learning models. However, the cost of obtaining annotation data is very high, especially for annotation of domain events, which requires the participation of experts from corresponding domain. So we introduce active learning (AL) technology to reduce the cost of event annotation. But the existing AL methods have two main problems, which make them not well used for event extraction. Firstly, the existing pool-based selection strategies have limitations in terms of computational cost and sample validity. Secondly, the existing evaluation of sample importance lacks the use of local sample information. In this paper, we present a novel deep AL method for EE. We propose a batch-based selection strategy and a Memory-Based Loss Prediction model (MBLP) to select unlabeled samples efficiently. During the selectio
    
[^45]: 句子的语义相关性取决于哪些因素：一个文本相关性数据集和实证研究

    What Makes Sentences Semantically Related: A Textual Relatedness Dataset and Empirical Study. (arXiv:2110.04845v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2110.04845](http://arxiv.org/abs/2110.04845)

    本论文介绍了一个手动注释的语义文本相关性数据集STR-2022，对于自动句子表示方法和各种下游自然语言处理任务的评估具有实用性。除此之外，我们探究了影响句子语义相关性的因素。

    

    对于理解语义，语言单元之间的语义相关性一直被认为是基础性的。自动确定相关性在问答和摘要等许多应用中有很多应用。然而，先前的自然语言处理研究主要集中在语义相似性上，因为缺乏相关性数据集。本文介绍了一个语义文本相关性数据集STR-2022，其中包含了5500个英文句子对，使用比较式注释框架进行了手动注释，得到了细粒度的得分。我们发现，关于句子对相关性的人类直觉是非常可靠的，重复注释相关系数为0.84。我们使用该数据集探究了哪些因素影响句子的语义相关性，并展示了STR-2022对于评估自动句子表示方法以及各种下游自然语言处理任务的效用。我们提供了数据集、数据说明和注释请求。

    The degree of semantic relatedness of two units of language has long been considered fundamental to understanding meaning. Additionally, automatically determining relatedness has many applications such as question answering and summarization. However, prior NLP work has largely focused on semantic similarity, a subset of relatedness, because of a lack of relatedness datasets. In this paper, we introduce a dataset for Semantic Textual Relatedness, STR-2022, that has 5,500 English sentence pairs manually annotated using a comparative annotation framework, resulting in fine-grained scores. We show that human intuition regarding relatedness of sentence pairs is highly reliable, with a repeat annotation correlation of 0.84. We use the dataset to explore questions on what makes sentences semantically related. We also show the utility of STR-2022 for evaluating automatic methods of sentence representation and for various downstream NLP tasks.  Our dataset, data statement, and annotation quest
    

