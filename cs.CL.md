# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Learning to Generate Equitable Text in Dialogue from Biased Training Data.](http://arxiv.org/abs/2307.04303) | 该论文研究了从偏见的训练数据中学习生成对话中公平文本的问题，提供了公平文本生成的正式定义，并证明了学习公平可以归结为改善人类样式的算法。 |
| [^2] | [HistRED: A Historical Document-Level Relation Extraction Dataset.](http://arxiv.org/abs/2307.04285) | HistRED是一个历史文档级别的关系抽取数据集，提供双语标注，支持不同长度的子文本，并且我们的双语模型在该数据集上表现出色。 |
| [^3] | [Automated Essay Scoring in Argumentative Writing: DeBERTeachingAssistant.](http://arxiv.org/abs/2307.04276) | 本研究提出了一种基于Transformer的架构，用于自动评分论证性写作文章的说服力质量，并计划进一步研究其模型的可解释性，以提供可操作的反馈给学生。 |
| [^4] | [Assessing the efficacy of large language models in generating accurate teacher responses.](http://arxiv.org/abs/2307.04274) | 本研究评估了大型语言模型在生成准确的教师回答中的能力。实验结果表明，在教师-学生聊天室语料库子集上，GPT-4的效果优于其他模型。研究还指出样本抽样和代表性等数据集特征可能影响生成模型的效果。 |
| [^5] | [ChatGPT in the Age of Generative AI and Large Language Models: A Concise Survey.](http://arxiv.org/abs/2307.04251) | ChatGPT是由OpenAI创建的一种大型语言模型（LLM），它在自然语言处理（NLP）领域引起了革命性的变革。它是第一个实现公众大规模与生成式人工智能（GAI）互动的关键技术，也引发了类似技术的研究兴趣和应用探索。 |
| [^6] | [SAS Video-QA: Self-Adaptive Sampling for Efficient Video Question-Answering.](http://arxiv.org/abs/2307.04192) | SAS视频问答通过自适应采样策略解决了视频问答中的问题，提高了效率和准确性 |
| [^7] | [Can Generative Large Language Models Perform ASR Error Correction?.](http://arxiv.org/abs/2307.04172) | 本文研究了大型生成语言模型在ASR错误修正中的应用，以ChatGPT为例，探讨了其在零-shot或1-shot设置下的能力。实验结果表明，使用ChatGPT模型进行错误修正可以显著提高ASR系统的性能。 |
| [^8] | [Dream Content Discovery from Reddit with an Unsupervised Mixed-Method Approach.](http://arxiv.org/abs/2307.04167) | 本论文介绍了一种无监督混合方法，通过自然语言处理从Reddit的r/Dreams子版块中发现梦境内容。通过测试数据，得到了包含217个主题的最广泛的梦境主题集合。与传统方法相比，该方法不受规模限制，并能发现不同梦境类型的独特模式。 |
| [^9] | [Towards cross-language prosody transfer for dialog.](http://arxiv.org/abs/2307.04123) | 本研究探索了实现跨语言语调转换以用于对话的方法。通过收集双语讲话者用另一种语言重新演绎对话的话语，并量化了跨语言韵律差异，评估了基准模型的实用性。研究结果可为未来的跨语言韵律研究和语音翻译系统设计提供参考。 |
| [^10] | [FILM: How can Few-Shot Image Classification Benefit from Pre-Trained Language Models?.](http://arxiv.org/abs/2307.04114) | 本文提出了一种使用预训练语言模型的新型少样本学习框架，通过对比学习，使用文本嵌入和度量模块来提高图像分类性能和可迁移性。 |
| [^11] | [Optimal Transport Posterior Alignment for Cross-lingual Semantic Parsing.](http://arxiv.org/abs/2307.04096) | 该论文提出了一种新的跨语义解析方法，利用最优输运来显式地最小化概率潜变量之间的跨语义差异。通过这种直接引导，可以使用较少的样例和训练来改善自然语言解析效果，并且在少样本跨语言制度下取得了最先进的结果。同时，该方法在没有并行输入翻译的情况下也能提高性能，并且更好地捕捉跨语言结构以改善语义表示。 |
| [^12] | [DebateKG: Automatic Policy Debate Case Creation with Semantic Knowledge Graphs.](http://arxiv.org/abs/2307.04090) | 本论文提出了一种利用语义知识图自动创建政策辩论案例的方法，通过在争论的语义知识图上进行限制最短路径遍历，有效构建高质量的辩论案例。研究结果表明，在美国竞赛辩论中，利用这种方法显著改进了已有数据集DebateSum，并贡献了新的例子和有用的元数据。通过使用txtai语义搜索和知识图工具链，创建和贡献了9个语义知识图，同时提出了一种独特的评估方法来确定哪个知识图更适合政策辩论案例生成。 |
| [^13] | [Bidirectional Attention as a Mixture of Continuous Word Experts.](http://arxiv.org/abs/2307.04057) | 双向注意力模型具有混合专家权重，类似于连续词袋模型（CBOW）的统计模型，它在大型语言模型中起到了重要作用。 |
| [^14] | [How is Fatherhood Framed Online in Singapore?.](http://arxiv.org/abs/2307.04053) | 这项研究探索了在新加坡的在线环境中如何解读父亲身份，发现父亲并没有被视为家庭单位的核心。 |
| [^15] | [Revisiting Cross-Lingual Summarization: A Corpus-based Study and A New Benchmark with Improved Annotation.](http://arxiv.org/abs/2307.04018) | 本研究重新审视了跨语言摘要，并提出了一个新的具有改进注释的基准。通过考虑源输入上下文，该基准更可靠。此外，作者还提出了一种两步方法，在ConvSumX上表现出较强的性能。 |
| [^16] | [Toward Interactive Dictation.](http://arxiv.org/abs/2307.04008) | 本文研究了允许用户在口述过程中用自然语言进行编辑命令的可行性，提出了一个新任务和数据集TERTiUS，并通过使用大型预训练语言模型进行实验。实验结果表明，模型的准确性和延迟之间存在权衡。 |
| [^17] | [A Stitch in Time Saves Nine: Detecting and Mitigating Hallucinations of LLMs by Validating Low-Confidence Generation.](http://arxiv.org/abs/2307.03987) | 本文提出了一种通过验证低置信度生成来检测和减轻LLMs的幻觉的方法。通过对模型生成的候选项进行验证，并缓解幻觉，改进了模型的可靠性。 |
| [^18] | [Evaluating the Capability of Large-scale Language Models on Chinese Grammatical Error Correction Task.](http://arxiv.org/abs/2307.03972) | 本研究评估了大规模语言模型在中文语法错误修正任务上的表现，并发现存在过度修正的问题。此外，我们还发现在评估不同数据分布时，大型语言模型的性能有显著变化。 |
| [^19] | [Is ChatGPT a Good Personality Recognizer? A Preliminary Study.](http://arxiv.org/abs/2307.03952) | 这篇论文进行了初步评估，探索了ChatGPT在文本中识别人格的能力，特别是通过面向层级的提示策略。论文比较了ChatGPT和传统神经网络、RoBERTa在两个实际数据集上的表现。 |
| [^20] | [Right to be Forgotten in the Era of Large Language Models: Implications, Challenges, and Solutions.](http://arxiv.org/abs/2307.03941) | 本文探讨了在大型语言模型时代的被遗忘权（RTBF）面临的挑战，提供了实施技术解决方案的见解。 |
| [^21] | [On decoder-only architecture for speech-to-text and large language model integration.](http://arxiv.org/abs/2307.03917) | 该论文介绍了一种新颖的方法Speech-LLaMA，将声学信息有效地融入基于文本的大型语言模型中。通过使用连接主义时序分类和简单的音频编码器，将压缩的声学特征映射到大型语言模型的连续语义空间中，实现了语音到文本任务中的实质性提升。 |
| [^22] | [ScriptWorld: Text Based Environment For Learning Procedural Knowledge.](http://arxiv.org/abs/2307.03906) | ScriptWorld是一个基于文本的环境，用于教授智能体关于真实世界日常任务和常识知识。它是第一个采用脚本数据集设计的互动式基于文本的游戏框架，在10个日常活动中提供了游戏环境，并通过对环境的详细分析，展示了引入脚本式真实世界任务可以有效提供常识知识并提高强化学习智能体的学习性能。 |
| [^23] | [Answering Ambiguous Questions via Iterative Prompting.](http://arxiv.org/abs/2307.03897) | 本文提出了一种通过迭代提示的方法来回答模糊问题。该方法集成了一个答案模型和一个提示模型，并通过逐步追踪阅读过程并触发答案模型来生成独特且相关的答案。通过开发任务特定的预训练方法，该方法在实验证明了其性能的提升。 |
| [^24] | [Embedding Mental Health Discourse for Community Recommendation.](http://arxiv.org/abs/2307.03892) | 本论文研究了使用话语嵌入技术开发社区推荐系统，重点关注心理健康支持群体。通过整合不同社区的话语信息，采用基于内容和协同过滤技术，提升了推荐系统的性能，并提供了可解释性。 |
| [^25] | [Large Language Models for Supply Chain Optimization.](http://arxiv.org/abs/2307.03875) | 这项研究研究了利用大型语言模型（LLMs）来帮助解释和解读供应链优化结果的方法。他们设计了一个框架，可以接受普通文本查询作为输入，并输出关于底层优化结果的洞察。通过定量回答假设情况，该框架在不放弃最先进的组合优化技术的情况下帮助企业运营者更好地理解和信任优化结果。 |
| [^26] | [MDACE: MIMIC Documents Annotated with Code Evidence.](http://arxiv.org/abs/2307.03859) | 这篇论文介绍了一个用于在长篇医疗文档上进行证据/理由提取的新数据集，该数据集能够为计算机辅助编码系统提供准确可靠的支持证据，对于改进医疗编码具有重要意义。 |
| [^27] | [RADAR: Robust AI-Text Detection via Adversarial Learning.](http://arxiv.org/abs/2307.03838) | 本论文提出了一种名为RADAR的新框架，通过对抗性学习实现了鲁棒的AI文本检测，以解决当前AI文本检测器对于大语言模型的改写不具备鲁棒性的问题。 |
| [^28] | [Linguistic representations for fewer-shot relation extraction across domains.](http://arxiv.org/abs/2307.03823) | 这项研究探索了在跨领域少样本迁移学习中，将语言表示作为额外的上下文信息对关系抽取任务性能的影响。他们通过交替使用句法和语义图来扩充Transformer架构，并发现语言表示可以增强泛化能力，而且语义表示在多个领域的关系抽取上更有帮助。 |
| [^29] | [For Women, Life, Freedom: A Participatory AI-Based Social Web Analysis of a Watershed Moment in Iran's Gender Struggles.](http://arxiv.org/abs/2307.03764) | 本文通过对波斯语Twitter话语的计算分析，估算了马莎·阿米尼去世后伊朗社会对性别平等立场的转变。研究采用参与式人工智能方法，涉及伊朗女性在标注过程中的积极角色。结果发现，马莎·阿米尼的死亡引发了波斯语话语的极化，积极推文数量略多于负面推文数量。此外，研究还观察到政府和抗议者在Twitter上的存在差异。 |
| [^30] | [Brain in a Vat: On Missing Pieces Towards Artificial General Intelligence in Large Language Models.](http://arxiv.org/abs/2307.03762) | 该论文综合评估了大型语言模型的能力并指出了其评估方法存在的问题；同时，提出了人工通用智能应该具备的能力，并讨论了人工通用智能的缺失之处，即知与行的统一。 |
| [^31] | [Testing the Predictions of Surprisal Theory in 11 Languages.](http://arxiv.org/abs/2307.03667) | 本研究填补了现有文献中的空白，通过研究11种不同语言之间的surprisal与阅读时间之间的关系，测试了Surprisal理论的三个预测，并发现了其他语言特征对阅读时间的影响。 |
| [^32] | [BLEURT Has Universal Translations: An Analysis of Automatic Metrics by Minimum Risk Training.](http://arxiv.org/abs/2307.03131) | 本研究通过最小风险训练系统性地分析和比较了各种自动度量，并发现了BLEURT和BARTScore等度量中存在的通用对抗翻译现象。研究结果表明，这些鲁棒性缺陷主要由训练数据集中的分布偏差和度量范式的倾向引起。通过引入标记级约束，可以提高度量的鲁棒性。 |
| [^33] | [Generalizing Backpropagation for Gradient-Based Interpretability.](http://arxiv.org/abs/2307.03056) | 本论文在深度神经网络的特征解释中，泛化了反向传播算法，以便更好地理解梯度图的可解释统计数据，如最高加权路径和熵。作者通过在合成数据集上的评估和应用于BERT的实验中验证了该方法的有效性。 |
| [^34] | [ValiTex -- a uniform validation framework for computational text-based measures of social science constructs.](http://arxiv.org/abs/2307.02863) | ValiTex是一个统一的验证框架，旨在帮助学者们基于文本数据来度量社会科学构建。它借鉴了心理测量学的传统，通过概念模型和动态检查表提供了验证的结构和步骤。 |
| [^35] | [Multilingual Language Models are not Multicultural: A Case Study in Emotion.](http://arxiv.org/abs/2307.01370) | 研究发现，多语言语言模型未能成功学习到文化适宜情绪的微妙差别，并提出了纠正这一问题的可能研究方向。 |
| [^36] | [vONTSS: vMF based semi-supervised neural topic modeling with optimal transport.](http://arxiv.org/abs/2307.01226) | vONTSS是一种基于vMF和最优传输的半监督神经主题建模方法，它在分类准确率和多样性方面优于其他方法，并且支持无监督主题建模。实验证明，vONTSS比最近的NTM更快。 |
| [^37] | [GenRec: Large Language Model for Generative Recommendation.](http://arxiv.org/abs/2307.00457) | 本文介绍了一种基于大型语言模型的创新推荐系统方法GenRec，通过直接生成目标推荐项而不是计算排名分数，利用LLM的表达能力和理解能力来生成相关推荐。 |
| [^38] | [Biomedical Language Models are Robust to Sub-optimal Tokenization.](http://arxiv.org/abs/2306.17649) | 生物医学语言模型对生物医学术语的标记分割方式具有鲁棒性，这对于改进下游生物医学自然语言处理任务的性能非常重要。 |
| [^39] | [Unsupervised Text Embedding Space Generation Using Generative Adversarial Networks for Text Synthesis.](http://arxiv.org/abs/2306.17181) | 本论文提出了一种使用生成对抗网络（GAN）生成连续文本嵌入空间的方法（TESGAN），以解决传统GAN在自然语言生成中的限制。这种方法通过引入连续的文本嵌入空间取代离散的标记，使得生成器在通过反向传播更新梯度时更加有效。 |
| [^40] | [Testing of Detection Tools for AI-Generated Text.](http://arxiv.org/abs/2306.15666) | 本文研究了人工智能生成文本的检测工具的功能，并对其进行了评估。研究发现，现有的检测工具既不准确也不可靠。 |
| [^41] | [Sparse Modular Activation for Efficient Sequence Modeling.](http://arxiv.org/abs/2306.11197) | 本论文引入了稀疏模块激活 (SMA) 机制，用于高效的序列建模。这种机制可以动态地稀疏激活序列元素的子模块，减少计算和内存消耗。 |
| [^42] | [Can ChatGPT pass the Vietnamese National High School Graduation Examination?.](http://arxiv.org/abs/2306.09170) | ChatGPT使用在越南高中毕业考试中表现出一定的水平，展示了AI动力聊天机器人在教育领域的潜力。 |
| [^43] | [GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio Pretraining for Speech Emotion Recognition.](http://arxiv.org/abs/2306.07848) | 本文提出了GEmo-CLAP模型用于语音情感识别，结合了性别属性信息，相比于其他先进方法，该模型在IEMOCAP上实现了更优越的识别性能。 |
| [^44] | [A Cross-Linguistic Pressure for Uniform Information Density in Word Order.](http://arxiv.org/abs/2306.03734) | 本论文研究了单词顺序中的信息密度统一压力，通过对10种不同类型的语言进行计算模型测试，发现在SVO语言中，真实词序具有更大的统一性。 |
| [^45] | [DiffusEmp: A Diffusion Model-Based Framework with Multi-Grained Control for Empathetic Response Generation.](http://arxiv.org/abs/2306.01657) | 本文提出了一种名为DiffusEmp的框架，该框架基于条件扩散语言模型，并使用多级控制信号来生成更加细致和个性化的共情回应。 |
| [^46] | [Supervised Adversarial Contrastive Learning for Emotion Recognition in Conversations.](http://arxiv.org/abs/2306.01505) | 本文提出了一种监督式对抗性对比学习（SACL）框架，用于学习类别分布结构表示，通过联合类别分布对比学习目标，有效利用标签级特性一致性并保留细粒度的类内特性，实现了在对话情感识别中最先进的结果。 |
| [^47] | [Task-Agnostic Structured Pruning of Speech Representation Models.](http://arxiv.org/abs/2306.01385) | 本文提出了一种精细的注意力头剪枝方法和Straight-Through Estimator，用于加速模型剪枝，以解决自监督的预训练模型的大内存和强计算需求问题。在实验中表明，该模型可以在任务中取得很好的性能且参数减少且推理速度提高。 |
| [^48] | [Quantization-Aware and Tensor-Compressed Training of Transformers for Natural Language Understanding.](http://arxiv.org/abs/2306.01076) | 本研究提出了一种量化感知张量压缩训练方法，用于减少基于Transformer的模型的模型大小，算术运算和最终运行时延。该方法经过逐层蒸馏后在文本蕴含和情感分析任务中表现出良好性能。 |
| [^49] | [Beyond One-Model-Fits-All: A Survey of Domain Specialization for Large Language Models.](http://arxiv.org/abs/2305.18703) | 本文综述了大型语言模型的领域专门化，包括动机、挑战、方法论和评估指标。此外，还提供了一个特定领域任务和数据集的分类法，对现有的领域自适应和定制技术进行了详细比较，并广泛讨论了这一领域中的未解决问题和未来的发展方向。 |
| [^50] | [Conformal Prediction with Large Language Models for Multi-Choice Question Answering.](http://arxiv.org/abs/2305.18404) | 本研究探讨了如何利用符合性预测技术，在多项选择题回答任务中为语言模型提供不确定性量化。我们发现符合性预测的不确定性估计与预测准确性密切相关。 |
| [^51] | [Syntax and Semantics Meet in the "Middle": Probing the Syntax-Semantics Interface of LMs Through Agentivity.](http://arxiv.org/abs/2305.18185) | 本论文通过以代理性为案例研究，探究了大规模语言模型在语法和语义交互方面的能力，并利用特定数据集测试了不同模型的表现，结果表明GPT-3 text-davinci-003在这些实验中表现优秀，比其他测试的模型更好。 |
| [^52] | [Improving Textless Spoken Language Understanding with Discrete Units as Intermediate Target.](http://arxiv.org/abs/2305.18096) | 本研究提出使用离散单元作为中间指导，以提高无文本语音理解技术的性能。在五个基准数据集上，我们的方法超过了基准方法，并发现单元指导有助于小样本学习和提升模型能力。 |
| [^53] | [When Giant Language Brains Just Aren't Enough! Domain Pizzazz with Knowledge Sparkle Dust.](http://arxiv.org/abs/2305.07230) | 本文将保险问答作为案例研究，提出了一种新模型，通过从保险政策手册中提取领域特定知识来增强LLMs的性能，实现领域适应，从而显著提高推理准确性。 |
| [^54] | [How to Index Item IDs for Recommendation Foundation Models.](http://arxiv.org/abs/2305.06569) | 本研究对推荐基础模型的项目索引问题进行了系统检查，提出了一种新的上下文感知索引方法，该方法在项目推荐准确性和文本生成质量方面具有优势。 |
| [^55] | [Inductive Relation Prediction from Relational Paths and Context with Hierarchical Transformers.](http://arxiv.org/abs/2304.00215) | 本文提出了一种基于分层Transformer的方法，即REPORT，能够同时聚合关系路径和上下文，捕捉实体之间的联系和内在特性。它完全依赖于关系语义，并能自然地推广到完全归纳的设置中。在基准数据集上实现了最先进的性能。 |
| [^56] | [On the Creativity of Large Language Models.](http://arxiv.org/abs/2304.00008) | 这篇论文探讨了大型语言模型的创造性问题，分析了与之相关的机器创造性的难点和易点，并重点分析了这些技术在创意产业中的社会影响。 |
| [^57] | [Student's t-Distribution: On Measuring the Inter-Rater Reliability When the Observations are Scarce.](http://arxiv.org/abs/2303.04526) | 这篇论文介绍了在数据稀缺时如何使用学生t-分布方法评估评价者间可靠性，并通过定量分析展示了引入更多观察可以大大提高评估置信度。 |
| [^58] | [Building High-accuracy Multilingual ASR with Gated Language Experts and Curriculum Training.](http://arxiv.org/abs/2303.00786) | 本文提出了一种使用门控语言专家和课程训练来增强多语言ASR的方法，无需用户提供LID输入。在双语任务中，与基线模型相比，平均词错误率分别降低了12.5％和7.3％，并且与使用oracle LID训练的上限模型相当。 |
| [^59] | [Talk the Walk: Synthetic Data Generation for Conversational Music Recommendation.](http://arxiv.org/abs/2301.11489) | TalkTheWalk 是一种新技术，通过利用精心策划的项目收藏中的领域专业知识来合成逼真高质量的会话数据，解决了构建会话式推荐系统所需的训练数据收集的困难。 |
| [^60] | [CausalDialogue: Modeling Utterance-level Causality in Conversations.](http://arxiv.org/abs/2212.10515) | 本研究通过建立CausalDialogue数据集并提出了ExMATE方法来模拟对话中话语级的因果关系，并表明传统的损失函数难以整合有向无环图结构。研究结果为训练神经对话模型提供了一种增强因果关系影响力的方法。 |
| [^61] | [LENS: A Learnable Evaluation Metric for Text Simplification.](http://arxiv.org/abs/2212.09739) | 本文提出了一种用于文本简化的可学习评估度量标准LENS，通过引入SimpeEval语料库作为人类评估数据集，与现有度量标准相比，LENS对人类判断相关性更好，为评估文本简化的未来进展铺平了道路。 |
| [^62] | [Simplicity Bias in Transformers and their Ability to Learn Sparse Boolean Functions.](http://arxiv.org/abs/2211.12316) | Transformers相对于循环模型更偏向于学习具有低敏感度的函数，尤其在稀疏布尔函数上，Transformers能够实现近乎完美的泛化，而LSTMs则表现出过拟合和较低的泛化精度。 |
| [^63] | [Nano: Nested Human-in-the-Loop Reward Learning for Few-shot Language Model Control.](http://arxiv.org/abs/2211.05750) | 本研究提出了一个少样本人机交互训练算法Nano，用于按任意分布（定量和未定量）生成文本。与先前的工作相比，Nano在单一主题/属性以及定量分布控制方面表现出最先进的结果。 |
| [^64] | [Mars: Modeling Context & State Representations with Contrastive Learning for End-to-End Task-Oriented Dialog.](http://arxiv.org/abs/2210.08917) | 本文提出了Mars，一种使用对比学习建模上下文和状态表示的端到端任务导向对话系统。研究结果表明，与语义状态表示不同的对话上下文表示对于多轮任务导向对话更为有益，且Mars在常用评测数据集上取得了最先进的性能。 |
| [^65] | [Multimedia Generative Script Learning for Task Planning.](http://arxiv.org/abs/2208.12306) | 该论文提出了多媒体生成式脚本学习任务，旨在通过跟踪文本和视觉模态中的历史状态来生成后续步骤，能对未见过的任务具有归纳能力并具有多样性。 |
| [^66] | [Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies.](http://arxiv.org/abs/2208.10264) | 该论文介绍了一种新型测试方法，称为图灵实验（TE），用于评估语言模型的人类行为模拟能力。论文通过模拟经济学、心理语言学和社会心理学实验，成功复制了已有研究，并揭示了一种“超准确度扭曲”的现象。 |
| [^67] | [Multilingual Coreference Resolution in Multiparty Dialogue.](http://arxiv.org/abs/2208.01307) | 该论文提出了一个基于电视剧本的大规模数据集Multilingual Multiparty Coref（MMC），用于解决多语言多方对话中的共指解析问题。通过重复使用黄金标注，在其他语言上创建了银共指解析数据，并发现MMC在多方共指解析的覆盖范围上比之前的数据集更广泛。在银标注数据上，无论是用于数据增强还是从头开始训练，都取得了成功，有效地模拟了零射跨语言的情况。 |
| [^68] | [KenSwQuAD -- A Question Answering Dataset for Swahili Low Resource Language.](http://arxiv.org/abs/2205.02364) | 该研究开发了KenSwQuAD - 一份适用于斯瓦希里语低资源语言的问答数据集，以满足低资源语言中机器理解自然语言的需求。这个数据集是通过从斯瓦希里语低资源语言的原始故事文本中进行注释得到的，包含7,526个QA对。 |
| [^69] | [Forecasting financial markets with semantic network analysis in the COVID-19 crisis.](http://arxiv.org/abs/2009.04975) | 本文通过使用语义网络分析来预测金融市场，基于新的文本数据指标，评估经济相关关键词的重要性，并应用于意大利股票和债券市场。研究结果显示，该指标能够很好地捕捉到金融时间序列的不同阶段，并且对于债券市场数据和股票市场波动性都存在明显的可预测性。 |

# 详细

[^1]: 从偏见训练数据中学习生成对话中公平的文本

    Learning to Generate Equitable Text in Dialogue from Biased Training Data. (arXiv:2307.04303v1 [cs.CL])

    [http://arxiv.org/abs/2307.04303](http://arxiv.org/abs/2307.04303)

    该论文研究了从偏见的训练数据中学习生成对话中公平文本的问题，提供了公平文本生成的正式定义，并证明了学习公平可以归结为改善人类样式的算法。

    

    对话系统在决策过程和生成回复中注重公平原则对于用户的参与、满意度和任务完成至关重要。缺乏公平和包容原则可能阻碍共同基础的形成，从而对系统的整体性能产生负面影响。然而，关于对话中公平文本生成的综合研究还不全面。因此，在这项工作中，我们使用计算学习的理论来研究这个问题。我们提供了文本生成中公平的正式定义，并进一步证明了学习人类样式和学习公平之间的正式关联：改进公平的算法最终归结为改善人类样式的算法（在扩充数据上）。基于这个理解，我们还制定了合理的条件，使得文本生成算法能够学习生成公平的文本。

    The ingrained principles of fairness in a dialogue system's decision-making process and generated responses are crucial for user engagement, satisfaction, and task achievement. Absence of equitable and inclusive principles can hinder the formation of common ground, which in turn negatively impacts the overall performance of the system. For example, misusing pronouns in a user interaction may cause ambiguity about the intended subject. Yet, there is no comprehensive study of equitable text generation in dialogue. Aptly, in this work, we use theories of computational learning to study this problem. We provide formal definitions of equity in text generation, and further, prove formal connections between learning human-likeness and learning equity: algorithms for improving equity ultimately reduce to algorithms for improving human-likeness (on augmented data). With this insight, we also formulate reasonable conditions under which text generation algorithms can learn to generate equitable t
    
[^2]: HistRED：一个历史文档级别的关系抽取数据集

    HistRED: A Historical Document-Level Relation Extraction Dataset. (arXiv:2307.04285v1 [cs.CL])

    [http://arxiv.org/abs/2307.04285](http://arxiv.org/abs/2307.04285)

    HistRED是一个历史文档级别的关系抽取数据集，提供双语标注，支持不同长度的子文本，并且我们的双语模型在该数据集上表现出色。

    

    尽管关系抽取（RE）任务在各个领域有广泛的应用，但在历史背景下的研究还很少。为了推动历史RE研究，我们从《延行錄》构建了HistRED。《延行錄》是最初用汉字写成的记录，后来被翻译成韩文。HistRED提供了双语标注，可以对韩文和汉字文本进行RE。此外，HistRED支持不同长度的自包含子文本，从句子级别到文档级别，为研究人员提供了多样的上下文设置来评估其RE模型的鲁棒性。为了展示我们数据集的有用性，我们提出了一个双语RE模型，利用韩文和汉字上下文来预测实体之间的关系。我们的模型在HistRED上表现优于单语基线模型，显示出其优势。

    Despite the extensive applications of relation extraction (RE) tasks in various domains, little has been explored in the historical context, which contains promising data across hundreds and thousands of years. To promote the historical RE research, we present HistRED constructed from Yeonhaengnok. Yeonhaengnok is a collection of records originally written in Hanja, the classical Chinese writing, which has later been translated into Korean. HistRED provides bilingual annotations such that RE can be performed on Korean and Hanja texts. In addition, HistRED supports various self-contained subtexts with different lengths, from a sentence level to a document level, supporting diverse context settings for researchers to evaluate the robustness of their RE models. To demonstrate the usefulness of our dataset, we propose a bilingual RE model that leverages both Korean and Hanja contexts to predict relations between entities. Our model outperforms monolingual baselines on HistRED, showing that
    
[^3]: 自动化的论证性写作文章评分：DeBERT教学助手

    Automated Essay Scoring in Argumentative Writing: DeBERTeachingAssistant. (arXiv:2307.04276v1 [cs.CL])

    [http://arxiv.org/abs/2307.04276](http://arxiv.org/abs/2307.04276)

    本研究提出了一种基于Transformer的架构，用于自动评分论证性写作文章的说服力质量，并计划进一步研究其模型的可解释性，以提供可操作的反馈给学生。

    

    自动化的文章评分已经成为一个研究和产业问题超过50年。由于其明确的教育价值以及对教育者提供有价值的节省时间工具的研究领域，它吸引了自然语言处理社区的大量关注。然而，这些工具通常只关注于检测良好的语法、拼写错误和组织质量，但往往在评估中未能将说服力特征纳入考虑。提供可操作的反馈以改进学生论证的力量的责任完全落在教师肩上。在这项工作中，我们提出了一种基于Transformer的架构，能够以超过人类准确度对论证性写作的话语要素进行注释其说服力质量，并扩展了对我们模型可解释性的未来研究。

    Automated Essay scoring has been explored as a research and industry problem for over 50 years. It has drawn a lot of attention from the NLP community because of its clear educational value as a research area that can engender the creation of valuable time-saving tools for educators around the world. Yet, these tools are generally focused on detecting good grammar, spelling mistakes, and organization quality but tend to fail at incorporating persuasiveness features in their final assessment. The responsibility to give actionable feedback to the student to improve the strength of their arguments is left solely on the teacher's shoulders. In this work, we present a transformer-based architecture capable of achieving above-human accuracy in annotating argumentative writing discourse elements for their persuasiveness quality and we expand on planned future work investigating the explainability of our model so that actionable feedback can be offered to the student and thus potentially enabl
    
[^4]: 评估大型语言模型在生成准确的教师回答中的有效性

    Assessing the efficacy of large language models in generating accurate teacher responses. (arXiv:2307.04274v1 [cs.CL])

    [http://arxiv.org/abs/2307.04274](http://arxiv.org/abs/2307.04274)

    本研究评估了大型语言模型在生成准确的教师回答中的能力。实验结果表明，在教师-学生聊天室语料库子集上，GPT-4的效果优于其他模型。研究还指出样本抽样和代表性等数据集特征可能影响生成模型的效果。

    

    (Tack等人，2023年)在第18届创新使用NLP构建教育应用研讨会上组织了共享任务，即教育对话中教师语言的生成。本研究按照共享任务的结构，试图评估大型语言模型在向学生提供信息性和有益洞察力方面的生成能力，从而模拟知识渊博的教师的角色。为此，我们对几种基准生成模型进行了广泛的评估，包括GPT-4（少样本、上下文学习）、微调的GPT-2和微调的DialoGPT。此外，为了优化教学质量，我们使用强化学习对Flan-T5模型进行了微调。在教师-学生聊天室语料库子集上的实验结果表明，使用BERTScore和DialogRPT度量，GPT-4比其他微调模型更为有效。我们假设样本抽样和代表性等多个数据集特征可能影响生成模型的效果。

    (Tack et al., 2023) organized the shared task hosted by the 18th Workshop on Innovative Use of NLP for Building Educational Applications on generation of teacher language in educational dialogues. Following the structure of the shared task, in this study, we attempt to assess the generative abilities of large language models in providing informative and helpful insights to students, thereby simulating the role of a knowledgeable teacher. To this end, we present an extensive evaluation of several benchmarking generative models, including GPT-4 (few-shot, in-context learning), fine-tuned GPT-2, and fine-tuned DialoGPT. Additionally, to optimize for pedagogical quality, we fine-tuned the Flan-T5 model using reinforcement learning. Our experimental findings on the Teacher-Student Chatroom Corpus subset indicate the efficacy of GPT-4 over other fine-tuned models, measured using BERTScore and DialogRPT.  We hypothesize that several dataset characteristics, including sampling, representativen
    
[^5]: ChatGPT在生成式AI和大语言模型时代的应用：一份简洁的调查报告

    ChatGPT in the Age of Generative AI and Large Language Models: A Concise Survey. (arXiv:2307.04251v1 [cs.CL])

    [http://arxiv.org/abs/2307.04251](http://arxiv.org/abs/2307.04251)

    ChatGPT是由OpenAI创建的一种大型语言模型（LLM），它在自然语言处理（NLP）领域引起了革命性的变革。它是第一个实现公众大规模与生成式人工智能（GAI）互动的关键技术，也引发了类似技术的研究兴趣和应用探索。

    

    ChatGPT是由OpenAI创建的一种大型语言模型（LLM），经过精心训练并使用了大量数据。它在自然语言处理（NLP）领域引起了革命性的变革，并推动了LLM能力的边界。ChatGPT在大规模范围内实现了普遍公众与生成式人工智能（GAI）的互动，起到了关键作用。它还引发了开发类似技术和研究其应用和影响的兴趣。本文的主要目标是对ChatGPT及其演化的当前研究方向进行简明调查。我们同时考虑了ChatGPT的玻璃盒和黑盒视角，包括技术的组成部分和基本要素，以及其应用、影响和影响。玻璃盒方法着重于理解技术的内部运作，而黑盒方法将其视为一个复杂系统，因此研究其输入，

    ChatGPT is a large language model (LLM) created by OpenAI that has been carefully trained on a large amount of data. It has revolutionized the field of natural language processing (NLP) and has pushed the boundaries of LLM capabilities. ChatGPT has played a pivotal role in enabling widespread public interaction with generative artificial intelligence (GAI) on a large scale. It has also sparked research interest in developing similar technologies and investigating their applications and implications. In this paper, our primary goal is to provide a concise survey on the current lines of research on ChatGPT and its evolution. We considered both the glass box and black box views of ChatGPT, encompassing the components and foundational elements of the technology, as well as its applications, impacts, and implications. The glass box approach focuses on understanding the inner workings of the technology, and the black box approach embraces it as a complex system, and thus examines its inputs,
    
[^6]: SAS视频问答：自适应采样用于高效视频问答

    SAS Video-QA: Self-Adaptive Sampling for Efficient Video Question-Answering. (arXiv:2307.04192v1 [cs.CV])

    [http://arxiv.org/abs/2307.04192](http://arxiv.org/abs/2307.04192)

    SAS视频问答通过自适应采样策略解决了视频问答中的问题，提高了效率和准确性

    

    视频问答是视频理解领域的一项基础任务。尽管当前的视觉-语言模型(VLMs)配备了视频变换器(Video Transformers)，实现了时间建模并取得了优秀的结果，但代价是巨大的计算能力，因此在实时应用场景中过于昂贵。一种经济的解决方法是只对视频的一小部分帧进行采样，来代表视频的主要内容，并在这些采样帧上调整图像-文本模型。最近的视频理解模型通常随机采样一组帧或片段，而不考虑它们的内部关联性和与问题的相关性。我们认为这种无目标的采样可能会遗漏可以推导出正确答案的关键帧，在采样稀疏程度增加时，情况会变得更糟，而随着视频长度的增加，采样稀疏程度也会增加。为了解决这个问题，我们提出了两种帧采样策略，分别是

    Video question--answering is a fundamental task in the field of video understanding. Although current vision--language models (VLMs) equipped with Video Transformers have enabled temporal modeling and yielded superior results, they are at the cost of huge computational power and thus too expensive to deploy in real-time application scenarios. An economical workaround only samples a small portion of frames to represent the main content of that video and tune an image--text model on these sampled frames. Recent video understanding models usually randomly sample a set of frames or clips, regardless of internal correlations between their visual contents, nor their relevance to the problem. We argue that such kinds of aimless sampling may omit the key frames from which the correct answer can be deduced, and the situation gets worse when the sampling sparsity increases, which always happens as the video lengths increase. To mitigate this issue, we propose two frame sampling strategies, namel
    
[^7]: 大型生成语言模型能够执行ASR错误修正吗？

    Can Generative Large Language Models Perform ASR Error Correction?. (arXiv:2307.04172v1 [cs.CL])

    [http://arxiv.org/abs/2307.04172](http://arxiv.org/abs/2307.04172)

    本文研究了大型生成语言模型在ASR错误修正中的应用，以ChatGPT为例，探讨了其在零-shot或1-shot设置下的能力。实验结果表明，使用ChatGPT模型进行错误修正可以显著提高ASR系统的性能。

    

    ASR错误修正在语音识别系统的后处理中继续扮演重要角色。传统上，这些模型使用底层ASR系统的解码结果和参考文本进行有监督训练。这种方法在计算上非常耗费资源，而且需要在切换底层ASR模型时重新训练模型。近年来，大型语言模型的发展使得它们能够以零-shot的方式执行自然语言处理任务。本文以ChatGPT为例，研究其在零-shot或1-shot设置下进行ASR错误修正的能力。我们使用ASR N-best列表作为模型的输入，并提出了无约束错误修正和N-best约束错误修正的方法。在Conformer-Transducer模型和预训练的Whisper模型上的实验结果表明，使用强大的ChatGPT模型进行错误修正可以大大提高ASR系统的性能。

    ASR error correction continues to serve as an important part of post-processing for speech recognition systems. Traditionally, these models are trained with supervised training using the decoding results of the underlying ASR system and the reference text. This approach is computationally intensive and the model needs to be re-trained when switching the underlying ASR model. Recent years have seen the development of large language models and their ability to perform natural language processing tasks in a zero-shot manner. In this paper, we take ChatGPT as an example to examine its ability to perform ASR error correction in the zero-shot or 1-shot settings. We use the ASR N-best list as model input and propose unconstrained error correction and N-best constrained error correction methods. Results on a Conformer-Transducer model and the pre-trained Whisper model show that we can largely improve the ASR system performance with error correction using the powerful ChatGPT model.
    
[^8]: 通过无监督混合方法从Reddit发现梦内容

    Dream Content Discovery from Reddit with an Unsupervised Mixed-Method Approach. (arXiv:2307.04167v1 [cs.CY])

    [http://arxiv.org/abs/2307.04167](http://arxiv.org/abs/2307.04167)

    本论文介绍了一种无监督混合方法，通过自然语言处理从Reddit的r/Dreams子版块中发现梦境内容。通过测试数据，得到了包含217个主题的最广泛的梦境主题集合。与传统方法相比，该方法不受规模限制，并能发现不同梦境类型的独特模式。

    

    梦是人类体验的一个基本但不完全理解的部分，可以揭示我们的思维模式。传统的梦境分析方法虽然受欢迎且有130多种独特的评分系统，但存在局限性。传统方法主要基于回顾性调查或实验室研究，难以大规模应用或展示不同梦境主题之间的重要性和联系。为了克服这些问题，我们开发了一种新的数据驱动混合方法，通过自然语言处理来识别自由形式的梦境报告中的主题。我们在Reddit的r/Dreams子版块上对44,213份梦境报告进行了测试，发现了217个主题，分为22个更大的主题：到目前为止最全面的梦境主题收集。我们通过与广泛使用的Hall和van de Castle评分方法进行对比验证了我们的主题。与传统评分方法不同，我们的方法可以发现不同类型梦境（如噩梦或反复出现的梦境）中的独特模式。

    Dreaming is a fundamental but not fully understood part of human experience that can shed light on our thought patterns. Traditional dream analysis practices, while popular and aided by over 130 unique scales and rating systems, have limitations. Mostly based on retrospective surveys or lab studies, they struggle to be applied on a large scale or to show the importance and connections between different dream themes. To overcome these issues, we developed a new, data-driven mixed-method approach for identifying topics in free-form dream reports through natural language processing. We tested this method on 44,213 dream reports from Reddit's r/Dreams subreddit, where we found 217 topics, grouped into 22 larger themes: the most extensive collection of dream topics to date. We validated our topics by comparing it to the widely-used Hall and van de Castle scale. Going beyond traditional scales, our method can find unique patterns in different dream types (like nightmares or recurring dreams)
    
[^9]: 实现跨语言语调转换以用于对话

    Towards cross-language prosody transfer for dialog. (arXiv:2307.04123v1 [cs.CL])

    [http://arxiv.org/abs/2307.04123](http://arxiv.org/abs/2307.04123)

    本研究探索了实现跨语言语调转换以用于对话的方法。通过收集双语讲话者用另一种语言重新演绎对话的话语，并量化了跨语言韵律差异，评估了基准模型的实用性。研究结果可为未来的跨语言韵律研究和语音翻译系统设计提供参考。

    

    当前的语音翻译系统在对话目的下的应用支持不足。特别是由于语调转换不当，讲话者意图和立场的细微差别可能会丢失。我们探讨了如何克服这个问题。首先，我们开发了一种数据收集协议，使双语讲话者用另一种语言重新演绎早前对话的话语，并利用此方法收集了一个包含1871个配对话语的英语-西班牙语语料库。其次，我们开发了一个简单的基于欧氏距离的韵律相似度度量，涵盖了广泛的韵律特征。然后，我们利用这些数据研究了跨语言韵律差异，量化了三个简单基准模型的实用性，并确定了需要更强大建模的现象。我们的发现将有助于未来的跨语言韵律研究和设计能够有效进行韵律转换的语音翻译系统的发展。

    Speech-to-speech translation systems today do not adequately support use for dialog purposes. In particular, nuances of speaker intent and stance can be lost due to improper prosody transfer. We present an exploration of what needs to be done to overcome this. First, we developed a data collection protocol in which bilingual speakers re-enact utterances from an earlier conversation in their other language, and used this to collect an English-Spanish corpus, so far comprising 1871 matched utterance pairs. Second, we developed a simple prosodic dissimilarity metric based on Euclidean distance over a broad set of prosodic features. We then used these to investigate cross-language prosodic differences, measure the likely utility of three simple baseline models, and identify phenomena which will require more powerful modeling. Our findings should inform future research on cross-language prosody and the design of speech-to-speech translation systems capable of effective prosody transfer.
    
[^10]: 《FILM:如何让少样本图像分类从预训练语言模型中受益?》

    FILM: How can Few-Shot Image Classification Benefit from Pre-Trained Language Models?. (arXiv:2307.04114v1 [cs.LG])

    [http://arxiv.org/abs/2307.04114](http://arxiv.org/abs/2307.04114)

    本文提出了一种使用预训练语言模型的新型少样本学习框架，通过对比学习，使用文本嵌入和度量模块来提高图像分类性能和可迁移性。

    

    少样本学习旨在训练能够利用少量样本推广到新类别的模型。最近，一系列工作提出利用可访问的类别名称语义信息来增强少样本学习。然而，这些工作主要集中在改进标准少样本学习框架中的视觉原型和特征提取器等现有模块，限制了语义信息的充分利用。本文提出了一种基于对比学习的预训练语言模型的新型少样本学习框架。为了解决视觉特征和文本嵌入之间的对齐挑战，我们精心设计了框架的文本分支，并引入了度量模块来推广余弦相似度。为了更好的可迁移性，我们让度量模块适应不同的少样本任务，并采用MAML进行双层优化训练模型。

    Few-shot learning aims to train models that can be generalized to novel classes with only a few samples. Recently, a line of works are proposed to enhance few-shot learning with accessible semantic information from class names. However, these works focus on improving existing modules such as visual prototypes and feature extractors of the standard few-shot learning framework. This limits the full potential use of semantic information. In this paper, we propose a novel few-shot learning framework that uses pre-trained language models based on contrastive learning. To address the challenge of alignment between visual features and textual embeddings obtained from text-based pre-trained language model, we carefully design the textual branch of our framework and introduce a metric module to generalize the cosine similarity. For better transferability, we let the metric module adapt to different few-shot tasks and adopt MAML to train the model via bi-level optimization. Moreover, we conduct 
    
[^11]: 跨语义解析的最优输运后验对齐

    Optimal Transport Posterior Alignment for Cross-lingual Semantic Parsing. (arXiv:2307.04096v1 [cs.CL])

    [http://arxiv.org/abs/2307.04096](http://arxiv.org/abs/2307.04096)

    该论文提出了一种新的跨语义解析方法，利用最优输运来显式地最小化概率潜变量之间的跨语义差异。通过这种直接引导，可以使用较少的样例和训练来改善自然语言解析效果，并且在少样本跨语言制度下取得了最先进的结果。同时，该方法在没有并行输入翻译的情况下也能提高性能，并且更好地捕捉跨语言结构以改善语义表示。

    

    跨语义解析通过从高资源语言（例如英语）转移解析能力到训练数据稀缺的低资源语言。以往的研究主要考虑了银标准数据增强或零样本方法，然而利用少样本黄金数据的方法相对未被探索。我们提出了一种新的方法，通过显式地最小化概率潜变量之间的跨语义差异来进行跨语义解析。我们展示了这种直接引导如何在使用较少的样例和较少的训练下改善自然语言解析。我们在两个数据集（MTOP和MultiATIS++SQL）上评估了我们的方法，在少样本跨语言制度下取得了最先进的结果。消融研究进一步揭示了我们的方法即使在没有并行输入翻译的情况下也能提高性能。此外，我们还证明了我们的模型更好地捕捉跨语言结构在潜空间中以改善语义表示。

    Cross-lingual semantic parsing transfers parsing capability from a high-resource language (e.g., English) to low-resource languages with scarce training data. Previous work has primarily considered silver-standard data augmentation or zero-shot methods, however, exploiting few-shot gold data is comparatively unexplored. We propose a new approach to cross-lingual semantic parsing by explicitly minimizing cross-lingual divergence between probabilistic latent variables using Optimal Transport. We demonstrate how this direct guidance improves parsing from natural languages using fewer examples and less training. We evaluate our method on two datasets, MTOP and MultiATIS++SQL, establishing state-of-the-art results under a few-shot cross-lingual regime. Ablation studies further reveal that our method improves performance even without parallel input translations. In addition, we show that our model better captures cross-lingual structure in the latent space to improve semantic representation 
    
[^12]: DebateKG: 用语义知识图自动创建政策辩论案例

    DebateKG: Automatic Policy Debate Case Creation with Semantic Knowledge Graphs. (arXiv:2307.04090v1 [cs.CL])

    [http://arxiv.org/abs/2307.04090](http://arxiv.org/abs/2307.04090)

    本论文提出了一种利用语义知识图自动创建政策辩论案例的方法，通过在争论的语义知识图上进行限制最短路径遍历，有效构建高质量的辩论案例。研究结果表明，在美国竞赛辩论中，利用这种方法显著改进了已有数据集DebateSum，并贡献了新的例子和有用的元数据。通过使用txtai语义搜索和知识图工具链，创建和贡献了9个语义知识图，同时提出了一种独特的评估方法来确定哪个知识图更适合政策辩论案例生成。

    

    近期相关工作表明，自然语言处理系统在解决竞赛辩论中的问题方面具有应用性。竞赛辩论中最重要的任务之一是辩手创建高质量的辩论案例。我们展示了使用限制最短路径遍历在争论的语义知识图上构建有效的辩论案例的方法。我们在一个名为DebateSum的大规模数据集上研究了这种潜力，该数据集针对的是一种名为政策辩论的美国竞赛辩论类型。我们通过向数据集中引入53180个新的例子，并为每个例子提供进一步有用的元数据，显著改进了DebateSum。我们利用txtai语义搜索和知识图工具链基于这个数据集产生并贡献了9个语义知识图。我们创建了一种独特的评估方法，以确定在政策辩论案例生成的背景下哪个知识图更好。

    Recent work within the Argument Mining community has shown the applicability of Natural Language Processing systems for solving problems found within competitive debate. One of the most important tasks within competitive debate is for debaters to create high quality debate cases. We show that effective debate cases can be constructed using constrained shortest path traversals on Argumentative Semantic Knowledge Graphs. We study this potential in the context of a type of American Competitive Debate, called Policy Debate, which already has a large scale dataset targeting it called DebateSum. We significantly improve upon DebateSum by introducing 53180 new examples, as well as further useful metadata for every example, to the dataset. We leverage the txtai semantic search and knowledge graph toolchain to produce and contribute 9 semantic knowledge graphs built on this dataset. We create a unique method for evaluating which knowledge graphs are better in the context of producing policy deb
    
[^13]: 双向注意力作为连续词专家的混合物

    Bidirectional Attention as a Mixture of Continuous Word Experts. (arXiv:2307.04057v1 [cs.CL])

    [http://arxiv.org/abs/2307.04057](http://arxiv.org/abs/2307.04057)

    双向注意力模型具有混合专家权重，类似于连续词袋模型（CBOW）的统计模型，它在大型语言模型中起到了重要作用。

    

    双向注意力由位置编码和屏蔽语言模型（MLM）目标组成的自注意力构成，已成为现代大型语言模型（LLMs）的关键组件。尽管它在实践中取得了成功，但很少有研究探讨它的统计基础：双向注意力隐含地拟合了什么统计模型？它与非注意机制的先驱有何不同？本文探讨了这些问题。关键观察是，重新参数化后，拟合单层单头双向注意力等于拟合具有混合专家权重的连续词袋（CBOW）模型。此外，具有多个头和多个层的双向注意力等价于堆叠的MoEs和MoEs的混合。这个统计观点揭示了MoE在双向注意力中的独特用途，这与其在处理异构性方面的实际有效性相一致。

    Bidirectional attention $\unicode{x2013}$ composed of self-attention with positional encodings and the masked language model (MLM) objective $\unicode{x2013}$ has emerged as a key component of modern large language models (LLMs). Despite its empirical success, few studies have examined its statistical underpinnings: What statistical model is bidirectional attention implicitly fitting? What sets it apart from its non-attention predecessors? We explore these questions in this paper. The key observation is that fitting a single-layer single-head bidirectional attention, upon reparameterization, is equivalent to fitting a continuous bag of words (CBOW) model with mixture-of-experts (MoE) weights. Further, bidirectional attention with multiple heads and multiple layers is equivalent to stacked MoEs and a mixture of MoEs, respectively. This statistical viewpoint reveals the distinct use of MoE in bidirectional attention, which aligns with its practical effectiveness in handling heterogeneous
    
[^14]: 新加坡的在线环境中如何解读父亲身份？

    How is Fatherhood Framed Online in Singapore?. (arXiv:2307.04053v1 [cs.CL])

    [http://arxiv.org/abs/2307.04053](http://arxiv.org/abs/2307.04053)

    这项研究探索了在新加坡的在线环境中如何解读父亲身份，发现父亲并没有被视为家庭单位的核心。

    

    新加坡关于父亲身份的讨论激增，表明有必要探索父亲身份的框架，以促进新加坡的父亲政策制定。全面和有效的父亲政策可以减少对成为父母的负面评价和恐惧，对改善国家的出生率至关重要。我们分析了15,705篇文章和56,221个帖子，研究了在新加坡的各种在线平台（新闻媒体、育儿论坛、Twitter）上关于父亲身份的框架。我们使用自然语言处理技术来理解这些差异。尽管在新加坡的在线环境中有多种对父亲身份的解读，但似乎父亲并没有被视为新加坡家庭单位的核心。我们工作的一个优势是应用了不同的技术相互验证。

    The proliferation of discussion about fatherhood in Singapore attests to its significance, indicating the need for an exploration of how fatherhood is framed, aiding policy-making around fatherhood in Singapore. Sound and holistic policy around fatherhood in Singapore may reduce stigma and apprehension around being a parent, critical to improving the nations flagging birth rate. We analyzed 15,705 articles and 56,221 posts to study how fatherhood is framed in Singapore across a range of online platforms (news outlets, parenting forums, Twitter). We used NLP techniques to understand these differences. While fatherhood was framed in a range of ways on the Singaporean online environment, it did not seem that fathers were framed as central to the Singaporean family unit. A strength of our work is how the different techniques we have applied validate each other.
    
[^15]: 重新审视跨语言摘要：一个基于语料库的研究和一个新的具有改进注释的基准

    Revisiting Cross-Lingual Summarization: A Corpus-based Study and A New Benchmark with Improved Annotation. (arXiv:2307.04018v1 [cs.CL])

    [http://arxiv.org/abs/2307.04018](http://arxiv.org/abs/2307.04018)

    本研究重新审视了跨语言摘要，并提出了一个新的具有改进注释的基准。通过考虑源输入上下文，该基准更可靠。此外，作者还提出了一种两步方法，在ConvSumX上表现出较强的性能。

    

    大多数现有的跨语言摘要（CLS）工作通过简单直接地将预先注释的摘要从一种语言翻译为另一种语言来构建CLS语料库，这可能包含摘要和翻译过程中的错误。为了解决这个问题，我们提出了ConvSumX，一个跨语言对话摘要基准，通过一个新的注释架构，明确考虑了源输入上下文。ConvSumX包括两个子任务，涵盖了不同的现实场景，每个子任务涵盖了三个语言方向。我们对ConvSumX和3个广泛使用的手工注释的CLS语料库进行了深入分析，实证发现ConvSumX对输入文本更可靠。此外，基于相同的直觉，我们提出了一种两步方法，将对话和摘要作为输入来模拟人类注释过程。实验结果表明，两步方法在ConvSumX上在自动评估和人工评估下均超越了强基线。分析表明，

    Most existing cross-lingual summarization (CLS) work constructs CLS corpora by simply and directly translating pre-annotated summaries from one language to another, which can contain errors from both summarization and translation processes. To address this issue, we propose ConvSumX, a cross-lingual conversation summarization benchmark, through a new annotation schema that explicitly considers source input context. ConvSumX consists of 2 sub-tasks under different real-world scenarios, with each covering 3 language directions. We conduct thorough analysis on ConvSumX and 3 widely-used manually annotated CLS corpora and empirically find that ConvSumX is more faithful towards input text. Additionally, based on the same intuition, we propose a 2-Step method, which takes both conversation and summary as input to simulate human annotation process. Experimental results show that 2-Step method surpasses strong baselines on ConvSumX under both automatic and human evaluation. Analysis shows that
    
[^16]: 迈向交互式口述

    Toward Interactive Dictation. (arXiv:2307.04008v1 [cs.CL])

    [http://arxiv.org/abs/2307.04008](http://arxiv.org/abs/2307.04008)

    本文研究了允许用户在口述过程中用自然语言进行编辑命令的可行性，提出了一个新任务和数据集TERTiUS，并通过使用大型预训练语言模型进行实验。实验结果表明，模型的准确性和延迟之间存在权衡。

    

    语音口述是一个日益重要的文本输入方式。现有的允许口述和语音编辑的系统将它们的命令语言限制在由触发词调用的平面模板上。在这项工作中，我们研究了允许用户中断口述并使用开放式自然语言进行口述命令的可行性。我们引入了一个新任务和数据集TERTiUS，用于对这种系统进行实验。为了实时支持这种灵活性，系统必须将连续的语音片段逐步分段并分类为口述或命令，并解释命令片段。我们尝试使用大型预训练语言模型来预测编辑后的文本，或者预测一个小的文本编辑程序。实验显示模型的准确性和延迟之间存在天然的权衡：较小的模型以1.3秒的延迟达到30％的最终准确率，而较大的模型以7秒的延迟达到55％的最终准确率。

    Voice dictation is an increasingly important text input modality. Existing systems that allow both dictation and editing-by-voice restrict their command language to flat templates invoked by trigger words. In this work, we study the feasibility of allowing users to interrupt their dictation with spoken editing commands in open-ended natural language. We introduce a new task and dataset, TERTiUS, to experiment with such systems. To support this flexibility in real-time, a system must incrementally segment and classify spans of speech as either dictation or command, and interpret the spans that are commands. We experiment with using large pre-trained language models to predict the edited text, or alternatively, to predict a small text-editing program. Experiments show a natural trade-off between model accuracy and latency: a smaller model achieves 30% end-state accuracy with 1.3 seconds of latency, while a larger model achieves 55% end-state accuracy with 7 seconds of latency.
    
[^17]: 孤掌难鸣：通过验证低置信度生成检测和减轻LLMs的幻觉

    A Stitch in Time Saves Nine: Detecting and Mitigating Hallucinations of LLMs by Validating Low-Confidence Generation. (arXiv:2307.03987v1 [cs.CL])

    [http://arxiv.org/abs/2307.03987](http://arxiv.org/abs/2307.03987)

    本文提出了一种通过验证低置信度生成来检测和减轻LLMs的幻觉的方法。通过对模型生成的候选项进行验证，并缓解幻觉，改进了模型的可靠性。

    

    最近开发的大型语言模型在生成流畅连贯的文本方面取得了显著的成功。然而，这些模型常常会发生“幻觉”，严重影响其可靠性。在这项工作中，我们解决了这个关键问题，并提出了一种主动检测和减轻生成过程中幻觉的方法。具体而言，我们首先利用模型的逻辑输出值识别可能的幻觉候选项，通过验证过程检查其正确性，减轻检测到的幻觉，然后继续生成过程。通过与“文章生成任务”的广泛实验，我们首先展示了我们的检测和减轻技术的个体有效性。具体而言，检测技术的召回率达到了88％，缓解技术成功缓解了57.6％被正确检测到的幻觉。重要的是，我们的减轻技术不会引入新的幻觉。

    Recently developed large language models have achieved remarkable success in generating fluent and coherent text. However, these models often tend to 'hallucinate' which critically hampers their reliability. In this work, we address this crucial problem and propose an approach that actively detects and mitigates hallucinations during the generation process. Specifically, we first identify the candidates of potential hallucination leveraging the model's logit output values, check their correctness through a validation procedure, mitigate the detected hallucinations, and then continue with the generation process. Through extensive experiments with the 'article generation task', we first demonstrate the individual efficacy of our detection and mitigation techniques. Specifically, the detection technique achieves a recall of 88% and the mitigation technique successfully mitigates 57.6% of the correctly detected hallucinations. Importantly, our mitigation technique does not introduce new ha
    
[^18]: 评估大规模语言模型在中文语法错误修正任务上的能力

    Evaluating the Capability of Large-scale Language Models on Chinese Grammatical Error Correction Task. (arXiv:2307.03972v1 [cs.CL])

    [http://arxiv.org/abs/2307.03972](http://arxiv.org/abs/2307.03972)

    本研究评估了大规模语言模型在中文语法错误修正任务上的表现，并发现存在过度修正的问题。此外，我们还发现在评估不同数据分布时，大型语言模型的性能有显著变化。

    

    大规模语言模型（LLMs）在各种自然语言处理（NLP）任务中表现出了令人瞩目的能力，并在最近受到了广泛关注。然而，一些研究表明，大型语言模型在英文语法错误修正任务中未能达到超越最先进模型的良好结果。本报告旨在探究大型语言模型在中文语法错误修正任务中的表现，并为未来的工作提供指导。我们在4个中文语法错误修正数据集上使用了3个不同模型规模的LLMs进行实验。我们的实验结果表明，LLMs在自动评估指标上的表现不及之前的最佳模型，因为存在过度修正的问题。此外，我们还发现LLMs在评估不同数据分布时的性能存在显著变化。我们的发现表明，需要进一步研究LLMs在中文语法错误修正任务上的应用。

    Large-scale language models (LLMs) has shown remarkable capability in various of Natural Language Processing (NLP) tasks and attracted lots of attention recently. However, some studies indicated that large language models fail to achieve promising result beyond the state-of-the-art models in English grammatical error correction (GEC) tasks. In this report, we aim to explore the how large language models perform on Chinese grammatical error correction tasks and provide guidance for future work. We conduct experiments with 3 different LLMs of different model scale on 4 Chinese GEC dataset. Our experimental results indicate that the performances of LLMs on automatic evaluation metrics falls short of the previous sota models because of the problem of over-correction. Furthermore, we also discover notable variations in the performance of LLMs when evaluated on different data distributions. Our findings demonstrates that further investigation is required for the application of LLMs on Chines
    
[^19]: ChatGPT是一个好的人格识别器吗？初步研究。

    Is ChatGPT a Good Personality Recognizer? A Preliminary Study. (arXiv:2307.03952v1 [cs.CL])

    [http://arxiv.org/abs/2307.03952](http://arxiv.org/abs/2307.03952)

    这篇论文进行了初步评估，探索了ChatGPT在文本中识别人格的能力，特别是通过面向层级的提示策略。论文比较了ChatGPT和传统神经网络、RoBERTa在两个实际数据集上的表现。

    

    近年来，人格被视为一种有价值的个人因素，被纳入了许多任务，如情感分析和产品推荐。这导致了对基于文本的人格识别任务的广泛关注，该任务旨在根据给定的文本识别个体的人格。考虑到ChatGPT近期在各种自然语言处理任务中展现出的显著能力，我们对ChatGPT在基于文本的人格识别任务上的表现进行了初步评估，以生成有效的人格数据。具体而言，我们采用了各种提示策略，探索ChatGPT从给定的文本中识别人格的能力，尤其是我们设计的面向层级的提示策略，用于指导ChatGPT在指定层次分析给定的文本。我们将ChatGPT在两个代表性的实际数据集上与传统的神经网络、微调的RoBERTa以及相应的最新任务的性能进行了比较。

    In recent years, personality has been regarded as a valuable personal factor being incorporated into numerous tasks such as sentiment analysis and product recommendation. This has led to widespread attention to text-based personality recognition task, which aims to identify an individual's personality based on given text. Considering that ChatGPT has recently exhibited remarkable abilities on various natural language processing tasks, we provide a preliminary evaluation of ChatGPT on text-based personality recognition task for generating effective personality data. Concretely, we employ a variety of prompting strategies to explore ChatGPT's ability in recognizing personality from given text, especially the level-oriented prompting strategy we designed for guiding ChatGPT in analyzing given text at a specified level. We compare the performance of ChatGPT on two representative real-world datasets with traditional neural network, fine-tuned RoBERTa, and corresponding state-of-the-art task
    
[^20]: 在大型语言模型时代的被遗忘权：涵义、挑战和解决方案

    Right to be Forgotten in the Era of Large Language Models: Implications, Challenges, and Solutions. (arXiv:2307.03941v1 [cs.CY])

    [http://arxiv.org/abs/2307.03941](http://arxiv.org/abs/2307.03941)

    本文探讨了在大型语言模型时代的被遗忘权（RTBF）面临的挑战，提供了实施技术解决方案的见解。

    

    被遗忘权（RTBF）最初是由谷歌西班牙与埃克斯内塔索委员会(Mario Costeja Gonz\'alez)之间的官司结果而确立的，并且后来被作为欧洲联盟一般数据保护条例（GDPR）下的删除权。RTBF允许个人向组织请求删除个人数据，特别是对于搜索引擎，个人可以向组织发送请求，排除他们的信息在查询结果中出现。然而，随着大型语言模型（LLMs）的发展和其在聊天机器人中的应用，LLM启用的软件系统变得越来越受欢迎。但它们并没有被排除在RTBF之外。相比搜索引擎使用的索引方法，LLMs以一种完全不同的方式存储和处理信息，这为符合RTBF提出了新的挑战。在本文中，我们探讨了这些挑战，并提供了关于如何实施技术解决方案以符合RTBF的见解。

    The Right to be Forgotten (RTBF) was first established as the result of the ruling of Google Spain SL, Google Inc. v AEPD, Mario Costeja Gonz\'alez, and was later included as the Right to Erasure under the General Data Protection Regulation (GDPR) of European Union to allow individuals the right to request personal data be deleted by organizations. Specifically for search engines, individuals can send requests to organizations to exclude their information from the query results. With the recent development of Large Language Models (LLMs) and their use in chatbots, LLM-enabled software systems have become popular. But they are not excluded from the RTBF. Compared with the indexing approach used by search engines, LLMs store, and process information in a completely different way. This poses new challenges for compliance with the RTBF. In this paper, we explore these challenges and provide our insights on how to implement technical solutions for the RTBF, including the use of machine unle
    
[^21]: 关于仅解码器架构在语音到文本和大型语言模型集成中的应用

    On decoder-only architecture for speech-to-text and large language model integration. (arXiv:2307.03917v1 [eess.AS])

    [http://arxiv.org/abs/2307.03917](http://arxiv.org/abs/2307.03917)

    该论文介绍了一种新颖的方法Speech-LLaMA，将声学信息有效地融入基于文本的大型语言模型中。通过使用连接主义时序分类和简单的音频编码器，将压缩的声学特征映射到大型语言模型的连续语义空间中，实现了语音到文本任务中的实质性提升。

    

    大型语言模型在自然语言处理领域取得了显著的成功，能够使用自然语言实现更好的人机交互。然而，如何将语音信号无缝地集成到大型语言模型中尚未得到很好的探索。同时，关于语音处理任务的“仅解码器”架构也没有得到很好的研究。在这项研究中，我们介绍了Speech-LLaMA，一种新颖的方法，有效地将声学信息融入基于文本的大型语言模型中。我们的方法利用了连接主义时序分类和简单的音频编码器，将压缩的声学特征映射到大型语言模型的连续语义空间中。此外，我们进一步探索了仅解码器架构在语音到文本任务中的应用，通过仅使用语音-文本配对数据训练一个较小规模、随机初始化的Speech-LLaMA模型。我们在多语言语音到文本翻译任务上进行了实验，证明与强基准相比有明显的改进。

    Large language models (LLMs) have achieved remarkable success in the field of natural language processing, enabling better human-computer interaction using natural language. However, the seamless integration of speech signals into LLMs has not been explored well. The "decoder-only" architecture has also not been well studied for speech processing tasks. In this research, we introduce Speech-LLaMA, a novel approach that effectively incorporates acoustic information into text-based large language models. Our method leverages Connectionist Temporal Classification and a simple audio encoder to map the compressed acoustic features to the continuous semantic space of the LLM. In addition, we further probe the decoder-only architecture for speech-to-text tasks by training a smaller scale randomly initialized speech-LLaMA model from speech-text paired data alone. We conduct experiments on multilingual speech-to-text translation tasks and demonstrate a significant improvement over strong baseli
    
[^22]: ScriptWorld: 用于学习过程性知识的基于文本的环境

    ScriptWorld: Text Based Environment For Learning Procedural Knowledge. (arXiv:2307.03906v1 [cs.CL])

    [http://arxiv.org/abs/2307.03906](http://arxiv.org/abs/2307.03906)

    ScriptWorld是一个基于文本的环境，用于教授智能体关于真实世界日常任务和常识知识。它是第一个采用脚本数据集设计的互动式基于文本的游戏框架，在10个日常活动中提供了游戏环境，并通过对环境的详细分析，展示了引入脚本式真实世界任务可以有效提供常识知识并提高强化学习智能体的学习性能。

    

    文本游戏为基于强化学习的智能体开发自然语言理解和常识知识提供了一个框架。现有的文本环境通常依赖于虚构的情景和角色来创建游戏框架，与真实世界场景相差甚远。本文介绍了ScriptWorld：一个基于文本的环境，用于教授智能体关于真实世界日常任务和常识知识。据我们所知，这是第一个采用脚本数据集设计的互动式基于文本的游戏框架，提供了10个日常活动的游戏环境，并对所提出的环境进行了详细分析。我们开发了基于强化学习的基准模型/智能体来玩ScriptWorld中的游戏。为了理解语言模型在这种环境中的作用，我们利用从预训练语言模型中获得的特征来辅助强化学习智能体。我们的实验表明，在ScriptWorld中引入脚本式的真实世界任务可以有效提供常识知识和提高强化学习智能体的学习性能。

    Text-based games provide a framework for developing natural language understanding and commonsense knowledge about the world in reinforcement learning based agents. Existing text-based environments often rely on fictional situations and characters to create a gaming framework and are far from real-world scenarios. In this paper, we introduce ScriptWorld: a text-based environment for teaching agents about real-world daily chores and hence imparting commonsense knowledge. To the best of our knowledge, it is the first interactive text-based gaming framework that consists of daily real-world human activities designed using scripts dataset. We provide gaming environments for 10 daily activities and perform a detailed analysis of the proposed environment. We develop RL-based baseline models/agents to play the games in Scriptworld. To understand the role of language models in such environments, we leverage features obtained from pre-trained language models in the RL agents. Our experiments sh
    
[^23]: 通过迭代提示回答模糊问题

    Answering Ambiguous Questions via Iterative Prompting. (arXiv:2307.03897v1 [cs.CL])

    [http://arxiv.org/abs/2307.03897](http://arxiv.org/abs/2307.03897)

    本文提出了一种通过迭代提示的方法来回答模糊问题。该方法集成了一个答案模型和一个提示模型，并通过逐步追踪阅读过程并触发答案模型来生成独特且相关的答案。通过开发任务特定的预训练方法，该方法在实验证明了其性能的提升。

    

    在开放领域的问答中，由于问题的模糊性，可能存在多个合理的答案。为了对一个模糊的问题提供可行的答案，一种方法是直接预测所有有效的答案，但这可能难以平衡相关性和多样性。另一种方法是收集候选答案并对它们进行汇总，但这种方法在计算上代价高，并且可能忽略答案之间的依赖关系。在这篇论文中，我们提出了AmbigPrompt来解决现有方法中回答模糊问题的缺陷。具体而言，我们以迭代的方式将一个答案模型与一个提示模型集成在一起。提示模型逐步追踪阅读过程，并逐渐触发答案模型来生成独特且相关的答案。此外，我们为答案模型和提示模型开发了一种任务特定的预训练方法，大大提高了我们框架的性能。在两个数据集上进行了实证研究。

    In open-domain question answering, due to the ambiguity of questions, multiple plausible answers may exist. To provide feasible answers to an ambiguous question, one approach is to directly predict all valid answers, but this can struggle with balancing relevance and diversity. An alternative is to gather candidate answers and aggregate them, but this method can be computationally costly and may neglect dependencies among answers. In this paper, we present AmbigPrompt to address the imperfections of existing approaches to answering ambiguous questions. Specifically, we integrate an answering model with a prompting model in an iterative manner. The prompting model adaptively tracks the reading process and progressively triggers the answering model to compose distinct and relevant answers. Additionally, we develop a task-specific post-pretraining approach for both the answering model and the prompting model, which greatly improves the performance of our framework. Empirical studies on tw
    
[^24]: 将心理健康话语嵌入社区推荐系统

    Embedding Mental Health Discourse for Community Recommendation. (arXiv:2307.03892v1 [cs.IR])

    [http://arxiv.org/abs/2307.03892](http://arxiv.org/abs/2307.03892)

    本论文研究了使用话语嵌入技术开发社区推荐系统，重点关注心理健康支持群体。通过整合不同社区的话语信息，采用基于内容和协同过滤技术，提升了推荐系统的性能，并提供了可解释性。

    

    我们的论文研究了使用话语嵌入技术来开发一个社区推荐系统，重点关注社交媒体上的心理健康支持群体。社交媒体平台为用户提供了与满足其特定兴趣的社区匿名连接的方式。然而，由于在线社区数量庞大，用户可能难以找到相关群组来解决他们的心理健康问题。为了解决这个挑战，我们使用嵌入技术探索来自不同subreddit社区的话语信息的整合，以开发一个有效的推荐系统。我们的方法使用基于内容和协同过滤的技术来提升推荐系统的性能。我们的研究结果表明，所提出的方法优于单独使用每种技术，并提供了推荐过程的可解释性。

    Our paper investigates the use of discourse embedding techniques to develop a community recommendation system that focuses on mental health support groups on social media. Social media platforms provide a means for users to anonymously connect with communities that cater to their specific interests. However, with the vast number of online communities available, users may face difficulties in identifying relevant groups to address their mental health concerns. To address this challenge, we explore the integration of discourse information from various subreddit communities using embedding techniques to develop an effective recommendation system. Our approach involves the use of content-based and collaborative filtering techniques to enhance the performance of the recommendation system. Our findings indicate that the proposed approach outperforms the use of each technique separately and provides interpretability in the recommendation process.
    
[^25]: 大型语言模型用于供应链优化

    Large Language Models for Supply Chain Optimization. (arXiv:2307.03875v1 [cs.AI])

    [http://arxiv.org/abs/2307.03875](http://arxiv.org/abs/2307.03875)

    这项研究研究了利用大型语言模型（LLMs）来帮助解释和解读供应链优化结果的方法。他们设计了一个框架，可以接受普通文本查询作为输入，并输出关于底层优化结果的洞察。通过定量回答假设情况，该框架在不放弃最先进的组合优化技术的情况下帮助企业运营者更好地理解和信任优化结果。

    

    传统上，供应链操作涉及各种复杂的决策问题。在过去几十年中，供应链受益于计算技术的进步，从手动处理过渡到自动化和成本效益优化。然而，企业运营者仍然需要花费大量精力来解释和解读优化结果给相关人士。受大型语言模型(LLMs)最近的进展的启发，我们研究了这种颠覆性技术如何帮助弥合供应链自动化和人类理解与信任之间的差距。我们设计了一个名为\name{}的框架，它接受普通文本查询作为输入，并输出关于底层优化结果的洞察。我们的框架并没有放弃最先进的组合优化技术，而是利用它来定量地回答假设情况（例如，如果我们使用供应商B而不是供应商A，成本会如何变化）。

    Supply chain operations traditionally involve a variety of complex decision making problems. Over the last few decades, supply chains greatly benefited from advances in computation, which allowed the transition from manual processing to automation and cost-effective optimization. Nonetheless, business operators still need to spend substantial efforts in \emph{explaining} and interpreting the optimization outcomes to stakeholders. Motivated by the recent advances in Large Language Models (LLMs), we study how this disruptive technology can help bridge the gap between supply chain automation and human comprehension and trust thereof. We design \name{} -- a framework that accepts as input queries in plain text, and outputs insights about the underlying optimization outcomes. Our framework does not forgo the state-of-the-art combinatorial optimization technology, but rather leverages it to quantitatively answer what-if scenarios (e.g., how would the cost change if we used supplier B instead
    
[^26]: MDACE: MIMIC文档的带代码证据注释

    MDACE: MIMIC Documents Annotated with Code Evidence. (arXiv:2307.03859v1 [cs.CL])

    [http://arxiv.org/abs/2307.03859](http://arxiv.org/abs/2307.03859)

    这篇论文介绍了一个用于在长篇医疗文档上进行证据/理由提取的新数据集，该数据集能够为计算机辅助编码系统提供准确可靠的支持证据，对于改进医疗编码具有重要意义。

    

    我们介绍了一个用于在长篇医疗文档上进行证据/理由提取的数据集，该数据集是在极端多标签分类任务上进行的。其中一个任务是计算机辅助编码（CAC），近年来由于机器学习技术的进步，CAC取得了显著的改进。然而，仅仅预测患者就诊的一组最终代码是不够的，因为CAC系统需要提供支持的文本证据来证明计费代码的合理性。能够为每个代码产生准确可靠的支持证据的模型将有巨大的好处。然而，创建人工注释的代码证据语料库非常困难，因为它需要专业知识。在本文中，我们介绍了MDACE，这是第一个公开可用的代码证据数据集，它是基于MIMIC-III临床记录的一个子集构建的。该数据集由专业医疗编码人员进行了注释，包含302份住院病历的3,934个证据片段和52份费用病历的5,563个证据片段。

    We introduce a dataset for evidence/rationale extraction on an extreme multi-label classification task over long medical documents. One such task is Computer-Assisted Coding (CAC) which has improved significantly in recent years, thanks to advances in machine learning technologies. Yet simply predicting a set of final codes for a patient encounter is insufficient as CAC systems are required to provide supporting textual evidence to justify the billing codes. A model able to produce accurate and reliable supporting evidence for each code would be a tremendous benefit. However, a human annotated code evidence corpus is extremely difficult to create because it requires specialized knowledge. In this paper, we introduce MDACE, the first publicly available code evidence dataset, which is built on a subset of the MIMIC-III clinical records. The dataset -- annotated by professional medical coders -- consists of 302 Inpatient charts with 3,934 evidence spans and 52 Profee charts with 5,563 evi
    
[^27]: RADAR: 通过对抗性学习实现鲁棒的AI文本检测

    RADAR: Robust AI-Text Detection via Adversarial Learning. (arXiv:2307.03838v1 [cs.CL])

    [http://arxiv.org/abs/2307.03838](http://arxiv.org/abs/2307.03838)

    本论文提出了一种名为RADAR的新框架，通过对抗性学习实现了鲁棒的AI文本检测，以解决当前AI文本检测器对于大语言模型的改写不具备鲁棒性的问题。

    

    最近大语言模型（LLMs）的进展以及ChatGPT类应用的普及已经模糊了人类和机器之间高质量文本生成的界限。然而，除了对我们的技术和社会预期的革命性变化外，区分LLM生成的文本（AI文本）和人类生成的文本的困难也带来了新的滥用和公平性挑战，例如虚假内容生成，抄袭以及对无辜作者的错误指控。尽管现有的研究表明当前的AI文本检测器对基于LLM的改写不具有鲁棒性，但本文旨在通过提出一种名为RADAR的新框架来弥合这一差距，该框架通过对抗性学习共同训练了一个鲁棒的AI文本检测器。RADAR基于一个改写器和一个检测器的对抗性训练。改写器的目标是生成逼真的内容以规避AI文本检测。RADAR使用来自检测器的反馈来更新改写器，反之亦然。

    Recent advances in large language models (LLMs) and the intensifying popularity of ChatGPT-like applications have blurred the boundary of high-quality text generation between humans and machines. However, in addition to the anticipated revolutionary changes to our technology and society, the difficulty of distinguishing LLM-generated texts (AI-text) from human-generated texts poses new challenges of misuse and fairness, such as fake content generation, plagiarism, and false accusation of innocent writers. While existing works show that current AI-text detectors are not robust to LLM-based paraphrasing, this paper aims to bridge this gap by proposing a new framework called RADAR, which jointly trains a Robust AI-text Detector via Adversarial leaRning. RADAR is based on adversarial training of a paraphraser and a detector. The paraphraser's goal is to generate realistic contents to evade AI-text detection. RADAR uses the feedback from the detector to update the paraphraser, and vice vers
    
[^28]: 跨领域少样本关系抽取的语言表示方法

    Linguistic representations for fewer-shot relation extraction across domains. (arXiv:2307.03823v1 [cs.CL])

    [http://arxiv.org/abs/2307.03823](http://arxiv.org/abs/2307.03823)

    这项研究探索了在跨领域少样本迁移学习中，将语言表示作为额外的上下文信息对关系抽取任务性能的影响。他们通过交替使用句法和语义图来扩充Transformer架构，并发现语言表示可以增强泛化能力，而且语义表示在多个领域的关系抽取上更有帮助。

    

    最近的研究已经证明将语言表示作为额外的上下文和支持信息加入到多个NLP任务的领域内性能中可以产生积极影响。我们通过在几次迁移学习环境中探索语言表示对跨领域性能的影响，对这些研究进行了扩展。一个重要的问题是，语言表示是否通过提供作为跨领域中心的特征来增强泛化能力。我们关注在两个领域（烹饪和材料科学）中的三个程序性文本数据集上的关系抽取任务。我们的方法通过交替地使用通过免费提供的现成工具构建的句法和语义图来扩充流行的基于Transformer的架构。我们考察了它们在增强泛化能力方面的实用性，并调查了早期发现，例如语义表示比句法表示更有帮助，是否适用于多个领域的关系抽取。我们发现

    Recent work has demonstrated the positive impact of incorporating linguistic representations as additional context and scaffolding on the in-domain performance of several NLP tasks. We extend this work by exploring the impact of linguistic representations on cross-domain performance in a few-shot transfer setting. An important question is whether linguistic representations enhance generalizability by providing features that function as cross-domain pivots. We focus on the task of relation extraction on three datasets of procedural text in two domains, cooking and materials science. Our approach augments a popular transformer-based architecture by alternately incorporating syntactic and semantic graphs constructed by freely available off-the-shelf tools. We examine their utility for enhancing generalization, and investigate whether earlier findings, e.g. that semantic representations can be more helpful than syntactic ones, extend to relation extraction in multiple domains. We find that
    
[^29]: 对于女性而言，生活和自由：基于参与式人工智能的社交网络分析论文研究伊朗性别斗争中的分水岭时刻

    For Women, Life, Freedom: A Participatory AI-Based Social Web Analysis of a Watershed Moment in Iran's Gender Struggles. (arXiv:2307.03764v1 [cs.CY])

    [http://arxiv.org/abs/2307.03764](http://arxiv.org/abs/2307.03764)

    本文通过对波斯语Twitter话语的计算分析，估算了马莎·阿米尼去世后伊朗社会对性别平等立场的转变。研究采用参与式人工智能方法，涉及伊朗女性在标注过程中的积极角色。结果发现，马莎·阿米尼的死亡引发了波斯语话语的极化，积极推文数量略多于负面推文数量。此外，研究还观察到政府和抗议者在Twitter上的存在差异。

    

    本文通过对波斯语Twitter话语的计算分析，旨在估算马莎·阿米尼在警方拘留期间去世后对性别平等立场的转变。我们提出了一个集成主动学习流程来训练一个立场分类器。我们的创新在于伊朗女性以主动的角色参与在构建这个人工智能系统中的标注。我们的标注者不仅提供标签，还提供有价值的关键词以进行更有意义的语料库创建，并提供简短的示例文档以进行引导式抽样。我们的分析结果表明，马莎·阿米尼的死亡引发了极化的波斯语话语，对性别平等的负面和积极推文数量都增加了。积极推文的增加略大于负面推文的增加。我们还观察到，就账号创建时间而言，与政府对齐的Twitter账号和支持抗议的Twitter账号之间存在差异。

    In this paper, we present a computational analysis of the Persian language Twitter discourse with the aim to estimate the shift in stance toward gender equality following the death of Mahsa Amini in police custody. We present an ensemble active learning pipeline to train a stance classifier. Our novelty lies in the involvement of Iranian women in an active role as annotators in building this AI system. Our annotators not only provide labels, but they also suggest valuable keywords for more meaningful corpus creation as well as provide short example documents for a guided sampling step. Our analyses indicate that Mahsa Amini's death triggered polarized Persian language discourse where both fractions of negative and positive tweets toward gender equality increased. The increase in positive tweets was slightly greater than the increase in negative tweets. We also observe that with respect to account creation time, between the state-aligned Twitter accounts and pro-protest Twitter accounts
    
[^30]: 贮存在计算机中的大型语言模型对于人工通用智能的缺失之处

    Brain in a Vat: On Missing Pieces Towards Artificial General Intelligence in Large Language Models. (arXiv:2307.03762v1 [cs.CL])

    [http://arxiv.org/abs/2307.03762](http://arxiv.org/abs/2307.03762)

    该论文综合评估了大型语言模型的能力并指出了其评估方法存在的问题；同时，提出了人工通用智能应该具备的能力，并讨论了人工通用智能的缺失之处，即知与行的统一。

    

    在这篇观点论文中，我们首先综合评估了使用标准化测试和以能力为导向的基准测试对大型语言模型（LLMs）的现有评估。我们指出了当前评估方法存在的几个问题，这些方法往往夸大了LLMs的能力。然后，我们阐述了人工通用智能应该具备的能力，超越了LLMs的能力范围。我们提出了智能代理的四个特征：1）他们可以执行无限的任务；2）他们可以在特定环境中生成新的任务；3）他们基于支撑任务生成的价值体系进行操作；4）他们拥有反映现实的世界模型，这影响着他们与世界的互动。在此观点的基础上，我们强调了人工通用智能的缺失之处，即知与行的统一。我们认为，与现实世界中的物体积极互动可以为形成概念性表示提供更可靠的信号。

    In this perspective paper, we first comprehensively review existing evaluations of Large Language Models (LLMs) using both standardized tests and ability-oriented benchmarks. We pinpoint several problems with current evaluation methods that tend to overstate the capabilities of LLMs. We then articulate what artificial general intelligence should encompass beyond the capabilities of LLMs. We propose four characteristics of generally intelligent agents: 1) they can perform unlimited tasks; 2) they can generate new tasks within a context; 3) they operate based on a value system that underpins task generation; and 4) they have a world model reflecting reality, which shapes their interaction with the world. Building on this viewpoint, we highlight the missing pieces in artificial general intelligence, that is, the unity of knowing and acting. We argue that active engagement with objects in the real world delivers more robust signals for forming conceptual representations. Additionally, know
    
[^31]: 在11种语言中测试Surprisal理论的预测

    Testing the Predictions of Surprisal Theory in 11 Languages. (arXiv:2307.03667v1 [cs.CL])

    [http://arxiv.org/abs/2307.03667](http://arxiv.org/abs/2307.03667)

    本研究填补了现有文献中的空白，通过研究11种不同语言之间的surprisal与阅读时间之间的关系，测试了Surprisal理论的三个预测，并发现了其他语言特征对阅读时间的影响。

    

    心理语言学的一个基本结果是，可预测性较低的词语需要更长时间来处理。Surprisal理论（Hale, 2001; Levy, 2008）是对这一发现的一个理论解释，它将一个词的可预测性量化为其surprisal，即在给定上下文的情况下，其负对数概率。虽然有大量的证据支持Surprisal理论的预测，但大多数研究都集中在一个非常有限的数据范围内，即以英语为母语的人阅读英语文本。事实上，目前还没有全面的多语言分析。我们通过研究在五个语言家族中分布的十一种不同语言中surprisal与阅读时间之间的关系来填补当前文献中的这一空白。通过从单语和多语语料库训练的语言模型中推导估计值，我们测试了与surprisal理论相关的三个预测：(i) surprisal是否能够预测阅读时间；(ii) 预期surprisal，即上下文熵，是否影响阅读时间；(iii) 与surprisal相关的其他语言特征是否可以解释阅读时间。

    A fundamental result in psycholinguistics is that less predictable words take a longer time to process. One theoretical explanation for this finding is Surprisal Theory (Hale, 2001; Levy, 2008), which quantifies a word's predictability as its surprisal, i.e. its negative log-probability given a context. While evidence supporting the predictions of Surprisal Theory have been replicated widely, most have focused on a very narrow slice of data: native English speakers reading English texts. Indeed, no comprehensive multilingual analysis exists. We address this gap in the current literature by investigating the relationship between surprisal and reading times in eleven different languages, distributed across five language families. Deriving estimates from language models trained on monolingual and multilingual corpora, we test three predictions associated with surprisal theory: (i) whether surprisal is predictive of reading times; (ii) whether expected surprisal, i.e. contextual entropy, i
    
[^32]: BLEURT具有通用翻译能力：基于最小风险训练的自动度量分析

    BLEURT Has Universal Translations: An Analysis of Automatic Metrics by Minimum Risk Training. (arXiv:2307.03131v1 [cs.CL])

    [http://arxiv.org/abs/2307.03131](http://arxiv.org/abs/2307.03131)

    本研究通过最小风险训练系统性地分析和比较了各种自动度量，并发现了BLEURT和BARTScore等度量中存在的通用对抗翻译现象。研究结果表明，这些鲁棒性缺陷主要由训练数据集中的分布偏差和度量范式的倾向引起。通过引入标记级约束，可以提高度量的鲁棒性。

    

    自动度量在机器翻译中起着关键作用。尽管n-gram度量广泛应用，但最近出现了基于预训练模型的度量的发展潮流，重点在于测量句子语义。然而，这些神经度量虽然与人工评估相关性更高，但常常被认为是带有潜在偏见且难以检测的黑盒子。本研究从训练机器翻译系统的指导角度，系统分析和比较了多种主流和前沿的自动度量。通过最小风险训练（MRT），我们发现某些度量存在鲁棒性缺陷，例如BLEURT和BARTScore中存在通用对抗翻译现象。深入分析表明，这些鲁棒性缺陷主要有两个原因：训练数据集中的分布偏差和度量范式的倾向。通过引入标记级约束，我们增强了度量的鲁棒性。

    Automatic metrics play a crucial role in machine translation. Despite the widespread use of n-gram-based metrics, there has been a recent surge in the development of pre-trained model-based metrics that focus on measuring sentence semantics. However, these neural metrics, while achieving higher correlations with human evaluations, are often considered to be black boxes with potential biases that are difficult to detect. In this study, we systematically analyze and compare various mainstream and cutting-edge automatic metrics from the perspective of their guidance for training machine translation systems. Through Minimum Risk Training (MRT), we find that certain metrics exhibit robustness defects, such as the presence of universal adversarial translations in BLEURT and BARTScore. In-depth analysis suggests two main causes of these robustness deficits: distribution biases in the training datasets, and the tendency of the metric paradigm. By incorporating token-level constraints, we enhan
    
[^33]: 泛化反向传播用于基于梯度的可解释性

    Generalizing Backpropagation for Gradient-Based Interpretability. (arXiv:2307.03056v1 [cs.LG])

    [http://arxiv.org/abs/2307.03056](http://arxiv.org/abs/2307.03056)

    本论文在深度神经网络的特征解释中，泛化了反向传播算法，以便更好地理解梯度图的可解释统计数据，如最高加权路径和熵。作者通过在合成数据集上的评估和应用于BERT的实验中验证了该方法的有效性。

    

    许多用于解释深度神经网络的流行特征归因方法依赖于计算模型输出对输入的梯度。虽然这些方法可以指示哪些输入特征可能对模型的预测很重要，但它们对模型本身的内部工作了解甚少。在本文中，我们观察到模型的梯度计算是使用半环的更一般形式的特例。这种观察使我们能够将反向传播算法泛化，以高效地计算关于神经网络梯度图的其他可解释统计数据，例如最高加权路径和熵。我们实现了这个泛化算法，在合成数据集上进行评估以更好地理解它计算的统计数据，并将其应用于研究BERT在主谓数一致性任务（SVA）上的行为。使用这种方法，我们验证了模型组件上通过的梯度流量反映了其重要性。

    Many popular feature-attribution methods for interpreting deep neural networks rely on computing the gradients of a model's output with respect to its inputs. While these methods can indicate which input features may be important for the model's prediction, they reveal little about the inner workings of the model itself. In this paper, we observe that the gradient computation of a model is a special case of a more general formulation using semirings. This observation allows us to generalize the backpropagation algorithm to efficiently compute other interpretable statistics about the gradient graph of a neural network, such as the highest-weighted path and entropy. We implement this generalized algorithm, evaluate it on synthetic datasets to better understand the statistics it computes, and apply it to study BERT's behavior on the subject-verb number agreement task (SVA). With this method, we (a) validate that the amount of gradient flow through a component of a model reflects its impor
    
[^34]: ValiTex -- 一种用于计算文本的社会科学构建度量的统一验证框架

    ValiTex -- a uniform validation framework for computational text-based measures of social science constructs. (arXiv:2307.02863v1 [cs.CL])

    [http://arxiv.org/abs/2307.02863](http://arxiv.org/abs/2307.02863)

    ValiTex是一个统一的验证框架，旨在帮助学者们基于文本数据来度量社会科学构建。它借鉴了心理测量学的传统，通过概念模型和动态检查表提供了验证的结构和步骤。

    

    关于如何验证计算文本的社会科学构建度量的指导是分散的。虽然学者们普遍认识到验证他们的文本度量的重要性，但他们通常缺乏共同的术语和统一的框架来进行验证。本文介绍了一个名为ValiTex的新验证框架，旨在帮助学者们基于文本数据来度量社会科学构建。该框架借鉴了心理测量学中长期存在的传统，同时扩展了框架以适用于计算文本分析的目的。ValiTex包括两个组成部分，一个是概念模型，一个是动态检查表。概念模型提供了一个通用的结构，可以指导验证的不同阶段，动态检查表定义了具体的验证步骤，并提供了哪些步骤可能被认为是推荐的（即提供相关和必要的验证证据）或可选的（即对提供额外信息有用的）。

    Guidance on how to validate computational text-based measures of social science constructs is fragmented. Whereas scholars are generally acknowledging the importance of validating their text-based measures, they often lack common terminology and a unified framework to do so. This paper introduces a new validation framework called ValiTex, designed to assist scholars to measure social science constructs based on textual data. The framework draws on a long-established tradition within psychometrics while extending the framework for the purpose of computational text analysis. ValiTex consists of two components, a conceptual model, and a dynamic checklist. Whereas the conceptual model provides a general structure along distinct phases on how to approach validation, the dynamic checklist defines specific validation steps and provides guidance on which steps might be considered recommendable (i.e., providing relevant and necessary validation evidence) or optional (i.e., useful for providing 
    
[^35]: 多语言语言模型并非多元文化的: 以情绪为案例研究

    Multilingual Language Models are not Multicultural: A Case Study in Emotion. (arXiv:2307.01370v1 [cs.CL])

    [http://arxiv.org/abs/2307.01370](http://arxiv.org/abs/2307.01370)

    研究发现，多语言语言模型未能成功学习到文化适宜情绪的微妙差别，并提出了纠正这一问题的可能研究方向。

    

    情绪在世界各地的经历和表达方式不同。为了在需要情感敏感性的多语言任务中使用大型语言模型(LMs)，LMs必须反映情绪上的文化差异。在本研究中，我们调查了2023年广泛使用的多语言LMs是否反映了跨文化和跨语言情感表达的差异。我们发现从LMs(如XLM-RoBERTa)获得的嵌入是以英语为中心的，生成型LMs(如ChatGPT)在回应其他语言的提示时也体现了西方规范。我们的结果表明，多语言LMs并没有成功地学习文化上适当的情绪细微差别，并强调了可能的研究方向以纠正这一点。

    Emotions are experienced and expressed differently across the world. In order to use Large Language Models (LMs) for multilingual tasks that require emotional sensitivity, LMs must reflect this cultural variation in emotion. In this study, we investigate whether the widely-used multilingual LMs in 2023 reflect differences in emotional expressions across cultures and languages. We find that embeddings obtained from LMs (e.g., XLM-RoBERTa) are Anglocentric, and generative LMs (e.g., ChatGPT) reflect Western norms, even when responding to prompts in other languages. Our results show that multilingual LMs do not successfully learn the culturally appropriate nuances of emotion and we highlight possible research directions towards correcting this.
    
[^36]: vONTSS：基于vMF和最优传输的半监督神经主题建模

    vONTSS: vMF based semi-supervised neural topic modeling with optimal transport. (arXiv:2307.01226v1 [cs.LG])

    [http://arxiv.org/abs/2307.01226](http://arxiv.org/abs/2307.01226)

    vONTSS是一种基于vMF和最优传输的半监督神经主题建模方法，它在分类准确率和多样性方面优于其他方法，并且支持无监督主题建模。实验证明，vONTSS比最近的NTM更快。

    

    最近，受变分自编码器启发的神经主题模型（NTM）引起了很多研究兴趣，然而，由于整合人类知识的挑战，这些方法在实际应用中受到了限制。本研究提出了一种半监督神经主题建模方法vONTSS，该方法利用基于von Mises-Fisher（vMF）的变分自编码器和最优传输。在半监督设置中，当提供每个主题的少量关键词时，vONTSS生成潜在主题并优化主题-关键词质量和主题分类。实验证明，vONTSS在分类准确率和多样性方面优于现有的半监督主题建模方法。vONTSS还支持无监督主题建模。定量和定性实验证明，vONTSS在无监督设置下在多个方面优于最近的NTM：vONTSS在基准数据集上发现高度聚类和连贯的主题。它也比现有-手法快得多。

    Recently, Neural Topic Models (NTM), inspired by variational autoencoders, have attracted a lot of research interest; however, these methods have limited applications in the real world due to the challenge of incorporating human knowledge. This work presents a semi-supervised neural topic modeling method, vONTSS, which uses von Mises-Fisher (vMF) based variational autoencoders and optimal transport. When a few keywords per topic are provided, vONTSS in the semi-supervised setting generates potential topics and optimizes topic-keyword quality and topic classification. Experiments show that vONTSS outperforms existing semi-supervised topic modeling methods in classification accuracy and diversity. vONTSS also supports unsupervised topic modeling. Quantitative and qualitative experiments show that vONTSS in the unsupervised setting outperforms recent NTMs on multiple aspects: vONTSS discovers highly clustered and coherent topics on benchmark datasets. It is also much faster than the state
    
[^37]: GenRec:大型语言模型在生成式推荐中的应用

    GenRec: Large Language Model for Generative Recommendation. (arXiv:2307.00457v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2307.00457](http://arxiv.org/abs/2307.00457)

    本文介绍了一种基于大型语言模型的创新推荐系统方法GenRec，通过直接生成目标推荐项而不是计算排名分数，利用LLM的表达能力和理解能力来生成相关推荐。

    

    近年来，大型语言模型(Large Language Model，LLM)已经成为各种自然语言处理任务的强大工具。然而，在生成式推荐范式下，它们在推荐系统中的潜力相对未被探索。本文提出了一种创新的基于文本数据的推荐系统方法，利用大型语言模型(LLM)来进行推荐。我们介绍了一种新颖的大型语言模型推荐系统(GenRec)，该系统利用LLM的表达能力直接生成目标推荐项，而不是像传统的判别式推荐系统一样逐个计算每个候选项的排名分数。GenRec利用LLM的理解能力来解释上下文、学习用户偏好并生成相关推荐。我们提出的方法利用大型语言模型中编码的丰富知识来完成推荐任务。我们首先制定了专门的提示，以增强LLM理解推荐任务的能力。

    In recent years, large language models (LLM) have emerged as powerful tools for diverse natural language processing tasks. However, their potential for recommender systems under the generative recommendation paradigm remains relatively unexplored. This paper presents an innovative approach to recommendation systems using large language models (LLMs) based on text data. In this paper, we present a novel LLM for generative recommendation (GenRec) that utilized the expressive power of LLM to directly generate the target item to recommend, rather than calculating ranking score for each candidate item one by one as in traditional discriminative recommendation. GenRec uses LLM's understanding ability to interpret context, learn user preferences, and generate relevant recommendation. Our proposed approach leverages the vast knowledge encoded in large language models to accomplish recommendation tasks. We first we formulate specialized prompts to enhance the ability of LLM to comprehend recomm
    
[^38]: 生物医学语言模型对不理想的标记分割方式具有鲁棒性

    Biomedical Language Models are Robust to Sub-optimal Tokenization. (arXiv:2306.17649v1 [cs.CL])

    [http://arxiv.org/abs/2306.17649](http://arxiv.org/abs/2306.17649)

    生物医学语言模型对生物医学术语的标记分割方式具有鲁棒性，这对于改进下游生物医学自然语言处理任务的性能非常重要。

    

    与一般的英语相反，生物医学术语中的许多概念是由生物医学专业人员设计的，目的是要精确且简明。通常通过将有意义的生物医学词素连接起来创建新的语义单位来实现这一目标。然而，大多数现代生物医学语言模型 (LMs) 是使用从大规模生物医学语料库统计中导出的标准领域特定标记器进行预训练的，而没有明确利用生物医学语言的粘附性特点。在这项工作中，我们首先发现标准通用领域和生物医学标记器在将生物医学术语分割成有意义的组成部分方面能力有限。因此，我们假设使用一种更准确分割生物医学术语的标记器将使生物医学语言模型在下游生物医学自然语言处理任务中提高性能，特别是涉及生物医学术语的任务，如命名实体识别 (NER) 和实体链接。

    As opposed to general English, many concepts in biomedical terminology have been designed in recent history by biomedical professionals with the goal of being precise and concise. This is often achieved by concatenating meaningful biomedical morphemes to create new semantic units. Nevertheless, most modern biomedical language models (LMs) are pre-trained using standard domain-specific tokenizers derived from large scale biomedical corpus statistics without explicitly leveraging the agglutinating nature of biomedical language. In this work, we first find that standard open-domain and biomedical tokenizers are largely unable to segment biomedical terms into meaningful components. Therefore, we hypothesize that using a tokenizer which segments biomedical terminology more accurately would enable biomedical LMs to improve their performance on downstream biomedical NLP tasks, especially ones which involve biomedical terms directly such as named entity recognition (NER) and entity linking. Su
    
[^39]: 使用生成对抗网络生成无监督文本嵌入空间用于文本合成

    Unsupervised Text Embedding Space Generation Using Generative Adversarial Networks for Text Synthesis. (arXiv:2306.17181v1 [cs.CL])

    [http://arxiv.org/abs/2306.17181](http://arxiv.org/abs/2306.17181)

    本论文提出了一种使用生成对抗网络（GAN）生成连续文本嵌入空间的方法（TESGAN），以解决传统GAN在自然语言生成中的限制。这种方法通过引入连续的文本嵌入空间取代离散的标记，使得生成器在通过反向传播更新梯度时更加有效。

    

    生成对抗网络（GAN）是一种用于数据合成的模型，通过生成器和判别器的竞争来创建逼真的数据。尽管GAN在图像合成方面得到了广泛研究，但在自然语言生成方面存在固有的限制。因为自然语言由离散的标记组成，生成器在通过反向传播更新梯度时遇到困难；因此，大多数文本-GAN研究使用奖励系统以随机标记为基础生成句子。因此，先前研究中的生成器在对抗训练之前以自回归方式进行预训练，导致合成的句子重复训练数据。在本文中，我们使用类似原始GAN的框架来合成句子。更具体地说，我们提出了文本嵌入空间生成对抗网络（TESGAN），它生成连续的文本嵌入空间来解决梯度反向传播的问题。

    Generative Adversarial Networks (GAN) is a model for data synthesis, which creates plausible data through the competition of generator and discriminator. Although GAN application to image synthesis is extensively studied, it has inherent limitations to natural language generation. Because natural language is composed of discrete tokens, a generator has difficulty updating its gradient through backpropagation; therefore, most text-GAN studies generate sentences starting with a random token based on a reward system. Thus, the generators of previous studies are pre-trained in an autoregressive way before adversarial training, causing data memorization that synthesized sentences reproduce the training data. In this paper, we synthesize sentences using a framework similar to the original GAN. More specifically, we propose Text Embedding Space Generative Adversarial Networks (TESGAN) which generate continuous text embedding spaces instead of discrete tokens to solve the gradient backpropagat
    
[^40]: AI-生成文本检测工具的测试

    Testing of Detection Tools for AI-Generated Text. (arXiv:2306.15666v1 [cs.CL])

    [http://arxiv.org/abs/2306.15666](http://arxiv.org/abs/2306.15666)

    本文研究了人工智能生成文本的检测工具的功能，并对其进行了评估。研究发现，现有的检测工具既不准确也不可靠。

    

    最近，生成式预训练变形器大语言模型的发展强调了在学术环境中不公平使用人工智能生成内容的潜在风险，并加强了寻找检测此类内容解决方案的努力。本文研究了人工智能生成文本的检测工具的一般功能，并根据准确性和错误类型分析对其进行评估。具体而言，该研究旨在回答以下研究问题：现有的检测工具是否能可靠地区分人类编写的文本和ChatGPT生成的文本，以及机器翻译和内容混淆技术是否影响对AI生成文本的检测。研究涵盖了12种公开可用的工具和两个广泛应用于学术环境中的商业系统（Turnitin和PlagiarismCheck）。研究人员得出结论，现有的检测工具既不准确也不可靠，并且存在主要的可辨识错误。

    Recent advances in generative pre-trained transformer large language models have emphasised the potential risks of unfair use of artificial intelligence (AI) generated content in an academic environment and intensified efforts in searching for solutions to detect such content. The paper examines the general functionality of detection tools for artificial intelligence generated text and evaluates them based on accuracy and error type analysis. Specifically, the study seeks to answer research questions about whether existing detection tools can reliably differentiate between human-written text and ChatGPT-generated text, and whether machine translation and content obfuscation techniques affect the detection of AIgenerated text. The research covers 12 publicly available tools and two commercial systems (Turnitin and PlagiarismCheck) that are widely used in the academic setting. The researchers conclude that the available detection tools are neither accurate nor reliable and have a main bi
    
[^41]: 稀疏模块激活用于高效的序列建模

    Sparse Modular Activation for Efficient Sequence Modeling. (arXiv:2306.11197v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.11197](http://arxiv.org/abs/2306.11197)

    本论文引入了稀疏模块激活 (SMA) 机制，用于高效的序列建模。这种机制可以动态地稀疏激活序列元素的子模块，减少计算和内存消耗。

    

    线性状态空间模型 (SSM) 在各种序列建模任务中表现出了很强的性能，因为它们有效地编码了循环结构。然而，在更综合的任务中，如语言建模和机器翻译中，基于自注意力的模型仍然优于SSM。同时使用SSM和自注意力的混合模型通常显示出有希望的性能，但当前方法将注意力模块静态且均匀地应用于输入序列中的所有元素，导致了质量和效率之间的次优权衡。在这项工作中，我们引入了稀疏模块激活 (SMA)，这是一种通用机制，使神经网络能够以可微分的方式稀疏地动态激活序列元素的子模块。通过允许每个元素跳过非激活的子模块，SMA可以在序列建模的训练和推理阶段降低计算和内存消耗。作为SMA的一个特定实例，我们设计了一种新颖的神经网络模型。

    Linear State Space Models (SSMs) have demonstrated strong performance in a variety of sequence modeling tasks due to their efficient encoding of the recurrent structure. However, in more comprehensive tasks like language modeling and machine translation, self-attention-based models still outperform SSMs. Hybrid models employing both SSM and self-attention generally show promising performance, but current approaches apply attention modules statically and uniformly to all elements in the input sequences, leading to sub-optimal quality-efficiency trade-offs. In this work, we introduce Sparse Modular Activation (SMA), a general mechanism enabling neural networks to sparsely and dynamically activate sub-modules for sequence elements in a differentiable manner. Through allowing each element to skip non-activated sub-modules, SMA reduces computation and memory consumption at both training and inference stages of sequence modeling. As a specific instantiation of SMA, we design a novel neural a
    
[^42]: ChatGPT 能通过越南高中毕业考试吗？

    Can ChatGPT pass the Vietnamese National High School Graduation Examination?. (arXiv:2306.09170v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.09170](http://arxiv.org/abs/2306.09170)

    ChatGPT使用在越南高中毕业考试中表现出一定的水平，展示了AI动力聊天机器人在教育领域的潜力。

    

    本研究文章强调了 AI 动力聊天机器人在教育中的潜力，并介绍了使用 ChatGPT，一种大型语言模型，完成越南高中毕业考试（VNHSGE）的结果。研究数据集包括文学测试案例中的 30 篇文章和设计给其他科目的 1,700 道多项选择题。结果显示 ChatGPT 能够通过考试，并得到了平均 6-7 分的成绩，展示了这项技术革命教育领域的潜力。 ChatGPT 表现的分析显示其在包括数学、英语、物理、化学、生物、历史、地理、公民教育和文学在内的一系列学科中都很熟练，这表明其支持学习者具有潜力。但需要进一步研究 ChatGPT 在更复杂的考试问题上的表现以及其支持不同背景学习者的潜力。随着技术的不断发展，AI 动力聊天机器人在教育领域的潜在应用是广泛而有前景的。

    This research article highlights the potential of AI-powered chatbots in education and presents the results of using ChatGPT, a large language model, to complete the Vietnamese National High School Graduation Examination (VNHSGE). The study dataset included 30 essays in the literature test case and 1,700 multiple-choice questions designed for other subjects. The results showed that ChatGPT was able to pass the examination with an average score of 6-7, demonstrating the technology's potential to revolutionize the educational landscape. The analysis of ChatGPT performance revealed its proficiency in a range of subjects, including mathematics, English, physics, chemistry, biology, history, geography, civic education, and literature, which suggests its potential to provide effective support for learners. However, further research is needed to assess ChatGPT performance on more complex exam questions and its potential to support learners in different contexts. As technology continues to evo
    
[^43]: GEmo-CLAP: 面向语音情感识别的性别属性增强对比语音-语言预训练模型

    GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio Pretraining for Speech Emotion Recognition. (arXiv:2306.07848v1 [cs.CL])

    [http://arxiv.org/abs/2306.07848](http://arxiv.org/abs/2306.07848)

    本文提出了GEmo-CLAP模型用于语音情感识别，结合了性别属性信息，相比于其他先进方法，该模型在IEMOCAP上实现了更优越的识别性能。

    

    对比语音-语言预训练（CLAP）最近在不同领域取得了惊人的成功。本文提出了一种名为GEmo-CLAP的高效性别属性增强CLAP模型，用于语音情感识别（SER）。具体而言，我们首先利用各种自监督学习的预训练模型构建了一种有效的情感CLAP模型（称为Emo-CLAP），用于SER。然后，考虑到在语音情感建模中性别属性的重要性，我们进一步提出了两种GEmo-CLAP方法，来整合语音信号的情感和性别信息，形成更合理的目标。在IEMOCAP语料库上进行的大量实验表明，我们提出的两种GEmo-CLAP方法始终优于基线Emo-CLAP模型（使用不同的预训练模型），同时与其他最先进的方法相比实现了更优越的识别性能。

    Contrastive Language-Audio Pretraining (CLAP) has recently exhibited impressive success in diverse fields. In this paper, we propose GEmo-CLAP, a kind of efficient gender-attribute-enhanced CLAP model for speech emotion recognition (SER). Specifically, we first build an effective emotion CLAP model termed Emo-CLAP for SER, utilizing various self-supervised learning based pre-trained models. Then, considering the importance of the gender attribute in speech emotion modeling, two GEmo-CLAP approaches are further proposed to integrate the emotion and gender information of speech signals, forming more reasonable objectives. Extensive experiments conducted on the IEMOCAP corpus demonstrate that our proposed two GEmo-CLAP approaches consistently outperform the baseline Emo-CLAP with different pre-trained models, while also achieving superior recognition performance compared with other state-of-the-art methods.
    
[^44]: 单词顺序中的跨语言信息密度统一压力

    A Cross-Linguistic Pressure for Uniform Information Density in Word Order. (arXiv:2306.03734v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.03734](http://arxiv.org/abs/2306.03734)

    本论文研究了单词顺序中的信息密度统一压力，通过对10种不同类型的语言进行计算模型测试，发现在SVO语言中，真实词序具有更大的统一性。

    

    尽管自然语言在基本词序和词序灵活性方面差异很大，但它们的词序仍然遵循共享的跨语言统计模式，这通常归因于功能压力。在识别这些压力的努力中，以前的研究比较了真实和反事实的词序。然而，在这些调查中，有一个功能压力被忽视了，即统一信息密度假设，该假设认为信息应该在话语中均匀分布。在这里，我们询问是否跨语言地存在信息密度统一的压力可能会影响词序模式。为此，我们使用计算模型测试真实顺序是否比反事实顺序导致更大的信息统一性。在我们对10种类型多样的语言进行的实证研究中，我们发现：（i）在SVO语言中，真实的词序一致比反向的词序具有更大的统一性，（ii）只有语言上不合理的反事实顺序...

    While natural languages differ widely in both canonical word order and word order flexibility, their word orders still follow shared cross-linguistic statistical patterns, often attributed to functional pressures. In the effort to identify these pressures, prior work has compared real and counterfactual word orders. Yet one functional pressure has been overlooked in such investigations: the uniform information density (UID) hypothesis, which holds that information should be spread evenly throughout an utterance. Here, we ask whether a pressure for UID may have influenced word order patterns cross-linguistically. To this end, we use computational models to test whether real orders lead to greater information uniformity than counterfactual orders. In our empirical study of 10 typologically diverse languages, we find that: (i) among SVO languages, real word orders consistently have greater uniformity than reverse word orders, and (ii) only linguistically implausible counterfactual orders 
    
[^45]: DiffusEmp:一种基于扩散模型的多级控制共情回应生成框架

    DiffusEmp: A Diffusion Model-Based Framework with Multi-Grained Control for Empathetic Response Generation. (arXiv:2306.01657v1 [cs.CL])

    [http://arxiv.org/abs/2306.01657](http://arxiv.org/abs/2306.01657)

    本文提出了一种名为DiffusEmp的框架，该框架基于条件扩散语言模型，并使用多级控制信号来生成更加细致和个性化的共情回应。

    

    共情是开放式交流中至关重要的因素，它自然地展示了一个人对他人的关心和理解。虽然已经提出了几种生成共情响应的方法，但现有的作品往往导致单调的共情，即指通用和安全的表达方式。本文提出使用显式控制来引导共情表达，并设计了一个DiffusEmp框架，基于条件扩散语言模型，统一了对话上下文和属性导向控制信号的利用。具体而言，引入通信机制、意图和语义框架作为多层次信号，可从粗糙到细致地控制共情实现。然后我们设计了一个特定的屏蔽策略，以反映多层次信号与响应令牌之间的关系，并将其整合到扩散模型中以影响生成过程。实验结果在基准数据集EmpatheticDialogue上表明，我们的框架优于其他共情回应生成方法。

    Empathy is a crucial factor in open-domain conversations, which naturally shows one's caring and understanding to others. Though several methods have been proposed to generate empathetic responses, existing works often lead to monotonous empathy that refers to generic and safe expressions. In this paper, we propose to use explicit control to guide the empathy expression and design a framework DiffusEmp based on conditional diffusion language model to unify the utilization of dialogue context and attribute-oriented control signals. Specifically, communication mechanism, intent, and semantic frame are imported as multi-grained signals that control the empathy realization from coarse to fine levels. We then design a specific masking strategy to reflect the relationship between multi-grained signals and response tokens, and integrate it into the diffusion model to influence the generative process. Experimental results on a benchmark dataset EmpatheticDialogue show that our framework outper
    
[^46]: 在对话情感识别中使用监督式对抗性对比学习

    Supervised Adversarial Contrastive Learning for Emotion Recognition in Conversations. (arXiv:2306.01505v1 [cs.CL])

    [http://arxiv.org/abs/2306.01505](http://arxiv.org/abs/2306.01505)

    本文提出了一种监督式对抗性对比学习（SACL）框架，用于学习类别分布结构表示，通过联合类别分布对比学习目标，有效利用标签级特性一致性并保留细粒度的类内特性，实现了在对话情感识别中最先进的结果。

    

    情感识别在对话中是提取泛化和稳健表示的一个重要挑战。为了解决这个问题，本文提出了一种监督式对抗性对比学习（SACL）框架，用于学习类别分布结构表示。该框架应用于对比感知对抗性训练以生成最坏情况的样本，并在原始和对抗样本上使用联合类别分布对比学习目标。它可以有效地利用标签级特性一致性并保留细粒度的类内特性。为了避免对上下文相关数据产生负面影响，我们设计了一个上下文对抗性训练策略，从上下文中学习更多不同的特征，并增强模型对上下文的容错性。在该框架下，我们开发了一个基于序列的方法SACL-LSTM，用于学习针对ERC的标签一致和上下文稳健的情感特征。在三个数据集上的实验证明，SACL-LSTM在对话情感识别方面实现了最先进的结果，优于现有的方法。

    Extracting generalized and robust representations is a major challenge in emotion recognition in conversations (ERC). To address this, we propose a supervised adversarial contrastive learning (SACL) framework for learning class-spread structured representations. The framework applies contrast-aware adversarial training to generate worst-case samples and uses a joint class-spread contrastive learning objective on both original and adversarial samples. It can effectively utilize label-level feature consistency and retain fine-grained intra-class features. To avoid the negative impact of adversarial perturbations on context-dependent data, we design a contextual adversarial training strategy to learn more diverse features from context and enhance the model's context robustness. We develop a sequence-based method SACL-LSTM under this framework, to learn label-consistent and context-robust emotional features for ERC. Experiments on three datasets demonstrate that SACL-LSTM achieves state-of
    
[^47]: 面向任务无关的语音表示模型结构剪枝

    Task-Agnostic Structured Pruning of Speech Representation Models. (arXiv:2306.01385v1 [eess.AS])

    [http://arxiv.org/abs/2306.01385](http://arxiv.org/abs/2306.01385)

    本文提出了一种精细的注意力头剪枝方法和Straight-Through Estimator，用于加速模型剪枝，以解决自监督的预训练模型的大内存和强计算需求问题。在实验中表明，该模型可以在任务中取得很好的性能且参数减少且推理速度提高。

    

    自监督的预训练模型如Wav2vec2、Hubert和WavLM已被证明能显著提高许多语音任务的性能。然而，它们庞大的内存和强大的计算需求阻碍了它们的工业应用。结构化剪枝是一种硬件友好的模型压缩技术，但通常会导致更大的精度损失。本文提出了一种精细的注意力头剪枝方法来弥补性能下降。此外，我们还在L0规则化中引入了Straight-Through Estimator来进一步加速剪枝模型。在SUPERB基准上的实验证明，我们的模型可以在多个任务上达到与密集模型相当的性能，并且平均优于Wav2vec 2.0基准模型，同时参数减少72％，推理速度提高2倍。

    Self-supervised pre-trained models such as Wav2vec2, Hubert, and WavLM have been shown to significantly improve many speech tasks. However, their large memory and strong computational requirements hinder their industrial applicability. Structured pruning is a hardware-friendly model compression technique but usually results in a larger loss of accuracy. In this paper, we propose a fine-grained attention head pruning method to compensate for the performance degradation. In addition, we also introduce the straight through estimator into the L0 regularization to further accelerate the pruned model. Experiments on the SUPERB benchmark show that our model can achieve comparable performance to the dense model in multiple tasks and outperforms the Wav2vec 2.0 base model on average, with 72% fewer parameters and 2 times faster inference speed.
    
[^48]: 量化感知和张量压缩训练：用于自然语言理解的Transformer

    Quantization-Aware and Tensor-Compressed Training of Transformers for Natural Language Understanding. (arXiv:2306.01076v1 [cs.CL])

    [http://arxiv.org/abs/2306.01076](http://arxiv.org/abs/2306.01076)

    本研究提出了一种量化感知张量压缩训练方法，用于减少基于Transformer的模型的模型大小，算术运算和最终运行时延。该方法经过逐层蒸馏后在文本蕴含和情感分析任务中表现出良好性能。

    

    细调的Transformer模型在许多自然语言任务中表现出优越性能。然而，庞大的模型大小阻止了在资源受限设备上部署高性能Transformer模型。本文提出了一种量化感知张量压缩训练方法，以减少基于Transformer的模型的模型大小，算术运算和最终运行时延。我们将Transformer的嵌入和线性层压缩为小型低秩张量核，从而显著减少模型参数。采用可学习比例因子的量化感知训练来进一步获得张量压缩模型的低精度表示。该方法可用于端到端训练和蒸馏训练。为了提高收敛性，采用逐层蒸馏方法从预训练Transformer中提取出一个经过量化和张量压缩的学生模型。本研究在两个自然语言任务，即文本蕴含和情感分析中展示了其性能。

    Fine-tuned transformer models have shown superior performances in many natural language tasks. However, the large model size prohibits deploying high-performance transformer models on resource-constrained devices. This paper proposes a quantization-aware tensor-compressed training approach to reduce the model size, arithmetic operations, and ultimately runtime latency of transformer-based models. We compress the embedding and linear layers of transformers into small low-rank tensor cores, which significantly reduces model parameters. A quantization-aware training with learnable scale factors is used to further obtain low-precision representations of the tensor-compressed models. The developed approach can be used for both end-to-end training and distillation-based training. To improve the convergence, a layer-by-layer distillation is applied to distill a quantized and tensor-compressed student model from a pre-trained transformer. The performance is demonstrated in two natural language
    
[^49]: 超越一个模型适用于所有领域：大型语言模型的领域专门化综述

    Beyond One-Model-Fits-All: A Survey of Domain Specialization for Large Language Models. (arXiv:2305.18703v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.18703](http://arxiv.org/abs/2305.18703)

    本文综述了大型语言模型的领域专门化，包括动机、挑战、方法论和评估指标。此外，还提供了一个特定领域任务和数据集的分类法，对现有的领域自适应和定制技术进行了详细比较，并广泛讨论了这一领域中的未解决问题和未来的发展方向。

    

    大型语言模型（LLM）已经大大推动了自然语言处理（NLP）领域的发展，为广泛应用提供了高度实用、任务无关的基础。LLMs 作为通用任务求解器的巨大潜力，促使人们将其用于特定领域，如医疗保健、金融和教育，并将其用作助手甚至替代特定领域的专家和工具。但是，将LLMs直接应用于特定领域中的复杂问题会遇到许多困难，包括领域数据的异质性、领域知识的复杂性、领域目标的独特性以及约束的多样性。为了填补这种差距，最近几年进行了急剧增加的研究和实践致力于大型语言模型的领域专门化，然而这方面的研究尚未被系统地总结。在这篇综述中，我们对LLMs的领域专门化进行了全面概述，包括动机、挑战、方法论和评估指标。此外，我们提供了一个特定领域任务和数据集的分类法，对现有的领域自适应和定制技术进行了详细比较，并广泛讨论了这一领域中的未解决问题和未来的发展方向。

    Large language models (LLMs) have significantly advanced the field of natural language processing (NLP), providing a highly useful, task-agnostic foundation for a wide range of applications. The great promise of LLMs as general task solvers motivated people to extend their functionality largely beyond just a ``chatbot'', and use it as an assistant or even replacement for domain experts and tools in specific domains such as healthcare, finance, and education. However, directly applying LLMs to solve sophisticated problems in specific domains meets many hurdles, caused by the heterogeneity of domain data, the sophistication of domain knowledge, the uniqueness of domain objectives, and the diversity of the constraints (e.g., various social norms, cultural conformity, religious beliefs, and ethical standards in the domain applications). To fill such a gap, explosively-increase research, and practices have been conducted in very recent years on the domain specialization of LLMs, which, howe
    
[^50]: 基于大语言模型的多项选择题答案确认预测研究

    Conformal Prediction with Large Language Models for Multi-Choice Question Answering. (arXiv:2305.18404v1 [cs.CL])

    [http://arxiv.org/abs/2305.18404](http://arxiv.org/abs/2305.18404)

    本研究探讨了如何利用符合性预测技术，在多项选择题回答任务中为语言模型提供不确定性量化。我们发现符合性预测的不确定性估计与预测准确性密切相关。

    

    随着大型语言模型的广泛开发，对它们进行健壮的不确定性量化技术将成为它们在高风险场景下安全部署的关键。本研究探讨了如何利用符合性预测技术，在多项选择题回答任务中为语言模型提供不确定性量化。我们发现符合性预测的不确定性估计与预测准确性密切相关。这种观察对于下游应用，如选择性分类和过滤低质量预测，可能会有用。我们还研究了符合性预测对于超出主题的问题的交换性假设，这可能是许多实际应用的更为现实的场景。本研究为在需要可靠保证错误率的安全关键情况下更加值得信赖和可靠地使用大型语言模型做出了贡献。

    As large language models continue to be widely developed, robust uncertainty quantification techniques will become crucial for their safe deployment in high-stakes scenarios. In this work, we explore how conformal prediction can be used to provide uncertainty quantification in language models for the specific task of multiple-choice question-answering. We find that the uncertainty estimates from conformal prediction are tightly correlated with prediction accuracy. This observation can be useful for downstream applications such as selective classification and filtering out low-quality predictions. We also investigate the exchangeability assumption required by conformal prediction to out-of-subject questions, which may be a more realistic scenario for many practical applications. Our work contributes towards more trustworthy and reliable usage of large language models in safety-critical situations, where robust guarantees of error rate are required.
    
[^51]: 语法和语义在“中间”相遇：通过代理性探究语法-语义界面的语言模型能力

    Syntax and Semantics Meet in the "Middle": Probing the Syntax-Semantics Interface of LMs Through Agentivity. (arXiv:2305.18185v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.18185](http://arxiv.org/abs/2305.18185)

    本论文通过以代理性为案例研究，探究了大规模语言模型在语法和语义交互方面的能力，并利用特定数据集测试了不同模型的表现，结果表明GPT-3 text-davinci-003在这些实验中表现优秀，比其他测试的模型更好。

    

    大规模语言模型的最新进展促使研究人员在各种语言任务上检验它们的能力，但在研究模型如何处理跨单词和更大句法形式的意义交互方面几乎没有研究。我们以代理性作为语义概念，作为探究这种交互的案例研究。我们利用部分可选的英语及物动词的独特语言属性创建了一个新的评估数据集。该数据集被用来针对不同大小的三种模型类别进行测试，以查看它们是否对词汇级别的代理性敏感，以及它们是否能在特定的句法上下文中适当地应用这些词级先验知识。总体而言，GPT-3 text-davinci-003在所有实验中表现非常出色，远远超过其他测试的模型。实际上，与人类判断相比，结果甚至更好地相关。

    Recent advances in large language models have prompted researchers to examine their abilities across a variety of linguistic tasks, but little has been done to investigate how models handle the interactions in meaning across words and larger syntactic forms -- i.e. phenomena at the intersection of syntax and semantics. We present the semantic notion of agentivity as a case study for probing such interactions. We created a novel evaluation dataset by utilitizing the unique linguistic properties of a subset of optionally transitive English verbs. This dataset was used to prompt varying sizes of three model classes to see if they are sensitive to agentivity at the lexical level, and if they can appropriately employ these word-level priors given a specific syntactic context. Overall, GPT-3 text-davinci-003 performs extremely well across all experiments, outperforming all other models tested by far. In fact, the results are even better correlated with human judgements than both syntactic an
    
[^52]: 用离散单元作为中间目标提高无文本语音理解技术的能力

    Improving Textless Spoken Language Understanding with Discrete Units as Intermediate Target. (arXiv:2305.18096v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.18096](http://arxiv.org/abs/2305.18096)

    本研究提出使用离散单元作为中间指导，以提高无文本语音理解技术的性能。在五个基准数据集上，我们的方法超过了基准方法，并发现单元指导有助于小样本学习和提升模型能力。

    

    语音理解（SLU）是一项旨在从口语中提取语义信息的任务。先前的研究通过使用配对的语音转文本数据，如预训练的自动语音识别（ASR）模型或配对文本作为中间目标，在端到端SLU上取得了进展。然而，获取配对的文本转录对于无书面语言来说是昂贵且不实际的。另一方面，无文本SLU从语音中提取语义信息而不使用配对的文本。然而，无文本SLU缺乏中间目标和训练指导常常导致表现不佳。在本研究中，受到自监督语音模型中内容分解离散单元的启发，我们提出使用离散单元作为中间指导，以提高无文本SLU的性能。我们的方法在五个SLU基准数据集上超过了基准方法。此外，我们发现单元指导有助于小样本学习，并增强了模型的能力。

    Spoken Language Understanding (SLU) is a task that aims to extract semantic information from spoken utterances. Previous research has made progress in end-to-end SLU by using paired speech-text data, such as pre-trained Automatic Speech Recognition (ASR) models or paired text as intermediate targets. However, acquiring paired transcripts is expensive and impractical for unwritten languages. On the other hand, Textless SLU extracts semantic information from speech without utilizing paired transcripts. However, the absence of intermediate targets and training guidance for textless SLU often results in suboptimal performance. In this work, inspired by the content-disentangled discrete units from self-supervised speech models, we proposed to use discrete units as intermediate guidance to improve textless SLU performance. Our method surpasses the baseline method on five SLU benchmark corpora. Additionally, we find that unit guidance facilitates few-shot learning and enhances the model's abi
    
[^53]: 当超级语言模型不足以满足业务需求：领域特定知识提升自然语言处理性能

    When Giant Language Brains Just Aren't Enough! Domain Pizzazz with Knowledge Sparkle Dust. (arXiv:2305.07230v1 [cs.CL])

    [http://arxiv.org/abs/2305.07230](http://arxiv.org/abs/2305.07230)

    本文将保险问答作为案例研究，提出了一种新模型，通过从保险政策手册中提取领域特定知识来增强LLMs的性能，实现领域适应，从而显著提高推理准确性。

    

    大型语言模型（LLMs）已经显著地推动了自然语言处理领域的进展，GPT模型处于领先地位。虽然它们在许多任务上的表现令人惊叹，但将LLMs用于真实世界的业务场景仍然面临挑战，并需要进一步研究。本文提出了一种经验分析，旨在弥合将LLMs适应于实际使用情况的差距。为此，我们选择保险问答（QA）任务作为案例研究，因为它具有推理的挑战。基于该任务，我们设计了一种新模型，依赖于从保险政策手册中提取的领域特定知识，使LLMs能够理解保险的新概念进行领域适应。实际QA对的初步结果表明，从政策手册中提取的知识显著提高了GPT-3.5的推理能力，准确性提高了50.4％。分析还表明，现有的公开评估标准可能不足以评估LLMs在实际场景中的性能。

    Large language models (LLMs) have significantly advanced the field of natural language processing, with GPT models at the forefront. While their remarkable performance spans a range of tasks, adapting LLMs for real-world business scenarios still poses challenges warranting further investigation. This paper presents an empirical analysis aimed at bridging the gap in adapting LLMs to practical use cases. To do that, we select the question answering (QA) task of insurance as a case study due to its challenge of reasoning. Based on the task we design a new model relied on LLMs which are empowered by domain-specific knowledge extracted from insurance policy rulebooks. The domain-specific knowledge helps LLMs to understand new concepts of insurance for domain adaptation. Preliminary results on real QA pairs show that knowledge enhancement from policy rulebooks significantly improves the reasoning ability of GPT-3.5 of 50.4% in terms of accuracy. The analysis also indicates that existing publ
    
[^54]: 如何为推荐基础模型索引项目ID

    How to Index Item IDs for Recommendation Foundation Models. (arXiv:2305.06569v1 [cs.IR])

    [http://arxiv.org/abs/2305.06569](http://arxiv.org/abs/2305.06569)

    本研究对推荐基础模型的项目索引问题进行了系统检查，提出了一种新的上下文感知索引方法，该方法在项目推荐准确性和文本生成质量方面具有优势。

    

    推荐基础模型将推荐任务转换为自然语言任务，利用大型语言模型（LLM）进行推荐。它通过直接生成建议的项目而不是计算传统推荐模型中每个候选项目的排名得分，简化了推荐管道，避免了多段过滤的问题。为了避免在决定要推荐哪些项目时生成过长的文本，为推荐基础模型创建LLM兼容的项目ID是必要的。本研究系统地研究了推荐基础模型的项目索引问题，以P5为代表的主干模型，并使用各种索引方法复制其结果。我们首先讨论了几种微不足道的项目索引方法（如独立索引、标题索引和随机索引）的问题，并表明它们不适用于推荐基础模型，然后提出了一种新的索引方法，称为上下文感知索引。我们表明，这种索引方法在项目推荐准确性和文本生成质量方面优于其他索引方法。

    Recommendation foundation model utilizes large language models (LLM) for recommendation by converting recommendation tasks into natural language tasks. It enables generative recommendation which directly generates the item(s) to recommend rather than calculating a ranking score for each and every candidate item in traditional recommendation models, simplifying the recommendation pipeline from multi-stage filtering to single-stage filtering. To avoid generating excessively long text when deciding which item(s) to recommend, creating LLM-compatible item IDs is essential for recommendation foundation models. In this study, we systematically examine the item indexing problem for recommendation foundation models, using P5 as the representative backbone model and replicating its results with various indexing methods. To emphasize the importance of item indexing, we first discuss the issues of several trivial item indexing methods, such as independent indexing, title indexing, and random inde
    
[^55]: 基于分层Transformer的关系路径和上下文归纳关系预测方法

    Inductive Relation Prediction from Relational Paths and Context with Hierarchical Transformers. (arXiv:2304.00215v1 [cs.CL])

    [http://arxiv.org/abs/2304.00215](http://arxiv.org/abs/2304.00215)

    本文提出了一种基于分层Transformer的方法，即REPORT，能够同时聚合关系路径和上下文，捕捉实体之间的联系和内在特性。它完全依赖于关系语义，并能自然地推广到完全归纳的设置中。在基准数据集上实现了最先进的性能。

    

    在知识图谱中进行关系预测是一个重要的研究课题。现有的嵌入式方法主要依赖于转导设置，缺乏归纳能力，无法推广到新的实体上进行推理。本文提出了一种新方法，通过使用统一的分层Transformer框架，即REPORT，同时聚合关系路径和上下文，捕捉实体之间的联系和内在特性，这种方法完全依赖于关系语义，并能自然地推广到完全归纳的设置中。在实验中，REPORT表现优于所有基线方法，甚至在两个完全归纳的数据集的八个版本子集上也是如此。此外，REPORT能够将推理推广到训练和推理中没有公共实体的新实体上，并在基准数据集上实现了最先进的性能。

    Relation prediction on knowledge graphs (KGs) is a key research topic. Dominant embedding-based methods mainly focus on the transductive setting and lack the inductive ability to generalize to new entities for inference. Existing methods for inductive reasoning mostly mine the connections between entities, i.e., relational paths, without considering the nature of head and tail entities contained in the relational context. This paper proposes a novel method that captures both connections between entities and the intrinsic nature of entities, by simultaneously aggregating RElational Paths and cOntext with a unified hieRarchical Transformer framework, namely REPORT. REPORT relies solely on relation semantics and can naturally generalize to the fully-inductive setting, where KGs for training and inference have no common entities. In the experiments, REPORT performs consistently better than all baselines on almost all the eight version subsets of two fully-inductive datasets. Moreover. REPO
    
[^56]: 关于大型语言模型的创造性研究

    On the Creativity of Large Language Models. (arXiv:2304.00008v1 [cs.AI])

    [http://arxiv.org/abs/2304.00008](http://arxiv.org/abs/2304.00008)

    这篇论文探讨了大型语言模型的创造性问题，分析了与之相关的机器创造性的难点和易点，并重点分析了这些技术在创意产业中的社会影响。

    

    大型语言模型(LLMs)正在颠覆人工智能的多个领域。其中最显著的应用之一是创作，例如诗歌或故事：生成的输出通常具有惊人的质量。但是，一个自然的问题是：LLMs真的可以被认为是创造性的吗？在本文中，我们首先通过创造性理论的角度分析了LLMs的发展，探讨了关键的未解决问题和挑战。然后，我们在与LLMs相关的机器创造性方面确定了一组“易”和“难”问题，并对其进行了讨论。最后，我们分析了这些技术在创意产业中的社会影响。

    Large Language Models (LLMs) are revolutionizing several areas of Artificial Intelligence. One of the most remarkable applications is creative writing, e.g., poetry or storytelling: the generated outputs are often of astonishing quality. However, a natural question arise: can LLMs really be considered creative? In this article we firstly analyze the development of LLMs under the lens of creativity theories, investigating the key open questions and challenges. Then, we identify a set of "easy" and "hard" problems in machine creativity, discussing them in relation to LLMs. Finally, we analyze the societal impact of these technologies with a particular focus on the creative industries.
    
[^57]: 学生t-分布：在观察稀缺时测量评价者间可靠性

    Student's t-Distribution: On Measuring the Inter-Rater Reliability When the Observations are Scarce. (arXiv:2303.04526v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.04526](http://arxiv.org/abs/2303.04526)

    这篇论文介绍了在数据稀缺时如何使用学生t-分布方法评估评价者间可靠性，并通过定量分析展示了引入更多观察可以大大提高评估置信度。

    

    在自然语言处理中，我们总是依赖于人类判断作为黄金质量评估方法。然而，对于某些评估任务（如翻译质量评估）的评价者间可靠性（IRR）水平如何更好评估一直存在争议，特别是当数据样本（观察）非常稀缺时。本研究首先介绍了当只有一个数据（评估）点可用时如何估计测量值的置信区间。然后，我们通过具体例子介绍了两个人生成的观察评分，引入了"学生t-分布"方法，并解释了如何使用它仅使用这两个数据点来测量IRR得分，以及质量评估的置信区间（CI）。我们定量分析了通过引入更多观察即使只有一个额外观察如何大大提高评估置信度。我们鼓励研究者们进行进一步研究和应用。

    In natural language processing (NLP) we always rely on human judgement as the golden quality evaluation method. However, there has been an ongoing debate on how to better evaluate inter-rater reliability (IRR) levels for certain evaluation tasks, such as translation quality evaluation (TQE), especially when the data samples (observations) are very scarce. In this work, we first introduce the study on how to estimate the confidence interval for the measurement value when only one data (evaluation) point is available. Then, this leads to our example with two human-generated observational scores, for which, we introduce ``Student's \textit{t}-Distribution'' method and explain how to use it to measure the IRR score using only these two data points, as well as the confidence intervals (CIs) of the quality evaluation. We give quantitative analysis on how the evaluation confidence can be greatly improved by introducing more observations, even if only one extra observation. We encourage resear
    
[^58]: 使用门控语言专家和课程训练构建高准确度的多语言ASR

    Building High-accuracy Multilingual ASR with Gated Language Experts and Curriculum Training. (arXiv:2303.00786v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.00786](http://arxiv.org/abs/2303.00786)

    本文提出了一种使用门控语言专家和课程训练来增强多语言ASR的方法，无需用户提供LID输入。在双语任务中，与基线模型相比，平均词错误率分别降低了12.5％和7.3％，并且与使用oracle LID训练的上限模型相当。

    

    我们提出使用门控语言专家和课程训练来增强多语言变压器传导模型，在推断过程中无需用户提供语言识别（LID）输入。我们的方法采用门控机制和LID损失，使变压器专家学习语言特定信息。通过将门控变压器专家与共享变压器层相结合，我们构建了多语言变压器块，并利用线性专家有效地规范化联合网络。课程训练方案利用LID引导门控专家改进各自的语言性能。在涉及英语和西班牙语的双语任务上的实验证明了显著的改进，与基线的双语和单语模型相比，平均相对词错误率分别降低了12.5％和7.3％。值得注意的是，我们的方法的性能与使用oracle LID训练和推断的上限模型相当。

    We propose gated language experts and curriculum training to enhance multilingual transformer transducer models without requiring language identification (LID) input from users during inference. Our method incorporates a gating mechanism and LID loss, enabling transformer experts to learn language-specific information. By combining gated transformer experts with shared transformer layers, we construct multilingual transformer blocks and utilize linear experts to effectively regularize the joint network. The curriculum training scheme leverages LID to guide the gated experts in improving their respective language performance. Experimental results on a bilingual task involving English and Spanish demonstrate significant improvements, with average relative word error reductions of 12.5% and 7.3% compared to the baseline bilingual and monolingual models, respectively. Notably, our method achieves performance comparable to the upper-bound model trained and inferred with oracle LID. Extendin
    
[^59]: Talk the Walk: 针对会话式音乐推荐的合成数据生成

    Talk the Walk: Synthetic Data Generation for Conversational Music Recommendation. (arXiv:2301.11489v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2301.11489](http://arxiv.org/abs/2301.11489)

    TalkTheWalk 是一种新技术，通过利用精心策划的项目收藏中的领域专业知识来合成逼真高质量的会话数据，解决了构建会话式推荐系统所需的训练数据收集的困难。

    

    推荐系统广泛存在，但用户往往很难在推荐质量较差时进行控制和调整。这促使了会话式推荐系统(CRSs)的发展，通过自然语言反馈提供对推荐的控制。然而，构建会话式推荐系统需要包含用户话语和涵盖多样化偏好范围的项目的会话训练数据。使用传统方法如众包，这样的数据收集起来非常困难。我们在项目集推荐的背景下解决了这个问题，注意到这个任务受到越来越多关注，动机在于音乐、新闻和食谱推荐等使用案例。我们提出了一种新技术TalkTheWalk，通过利用广泛可获得的精心策划的项目收藏中的领域专业知识来合成逼真高质量的会话数据，并展示了如何将其转化为相应的项目集策划。

    Recommendation systems are ubiquitous yet often difficult for users to control and adjust when recommendation quality is poor. This has motivated the development of conversational recommendation systems (CRSs), with control over recommendations provided through natural language feedback. However, building conversational recommendation systems requires conversational training data involving user utterances paired with items that cover a diverse range of preferences. Such data has proved challenging to collect scalably using conventional methods like crowdsourcing. We address it in the context of item-set recommendation, noting the increasing attention to this task motivated by use cases like music, news and recipe recommendation. We present a new technique, TalkTheWalk, that synthesizes realistic high-quality conversational data by leveraging domain expertise encoded in widely available curated item collections, showing how these can be transformed into corresponding item set curation c
    
[^60]: CausalDialogue: 对话中话语级因果关系的建模

    CausalDialogue: Modeling Utterance-level Causality in Conversations. (arXiv:2212.10515v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10515](http://arxiv.org/abs/2212.10515)

    本研究通过建立CausalDialogue数据集并提出了ExMATE方法来模拟对话中话语级的因果关系，并表明传统的损失函数难以整合有向无环图结构。研究结果为训练神经对话模型提供了一种增强因果关系影响力的方法。

    

    尽管它们被广泛采用，但神经对话模型尚未展现出与人类自然交流的能力。在这项研究中，我们将用户话语视为因果关系，将生成的回应视为效果，并认识到对因果关系的改变应产生不同的效果。为了进一步探索这个概念，我们通过众包编制了一个名为CausalDialogue的新数据集，并对其进行了扩展。该数据集包含了一个有向无环图(DAG)结构中的多个因果对。我们的分析发现，传统的损失函数难以有效地整合DAG结构，因此我们提出了一种增强话语级因果关系在训练神经对话模型中影响力的方法，称为指数最大平均治疗效应(ExMATE)。为了评估在对话生成中考虑因果关系的需求，我们利用不同的模型、推理和训练方法在CausalDialogue数据集上构建了一个全面的基准测试。

    Despite their widespread adoption, neural conversation models have yet to exhibit natural chat capabilities with humans. In this research, we examine user utterances as causes and generated responses as effects, recognizing that changes in a cause should produce a different effect. To further explore this concept, we have compiled and expanded upon a new dataset called CausalDialogue through crowd-sourcing. This dataset includes multiple cause-effect pairs within a directed acyclic graph (DAG) structure. Our analysis reveals that traditional loss functions struggle to effectively incorporate the DAG structure, leading us to propose a causality-enhanced method called Exponential Maximum Average Treatment Effect (ExMATE) to enhance the impact of causality at the utterance level in training neural conversation models. To evaluate the needs of considering causality in dialogue generation, we built a comprehensive benchmark on CausalDialogue dataset using different models, inference, and tr
    
[^61]: LENS：一种可学习的文本简化评估指标

    LENS: A Learnable Evaluation Metric for Text Simplification. (arXiv:2212.09739v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09739](http://arxiv.org/abs/2212.09739)

    本文提出了一种用于文本简化的可学习评估度量标准LENS，通过引入SimpeEval语料库作为人类评估数据集，与现有度量标准相比，LENS对人类判断相关性更好，为评估文本简化的未来进展铺平了道路。

    

    最近，使用现代语言模型训练可学习度量标准已成为自动评估机器翻译的一种有前途的方法。然而，现有的用于文本简化的人类评估数据集只有一些基于单一或过时模型的有限注释，使它们不能适用于这种方法。为解决这些问题，我们引入了SimpEval语料库，其中包括：SimpEval_past，包括对24个过去系统2.4K简化的12K人类评分，以及SimpEval_2022，一个具有挑战性的简化基准，包含了对360个简化，包括GPT-3.5生成文本的1K人类评分。在SimpEval上进行训练，我们提出了一种用于文本简化的可学习评估度量标准LENS。广泛的实证结果表明，LENS与人类判断相关性更好，为评估文本简化的未来进展铺平了道路。我们还引入了Rank和Rate，一种人类评估框架，用于对简化进行排名和评分。

    Training learnable metrics using modern language models has recently emerged as a promising method for the automatic evaluation of machine translation. However, existing human evaluation datasets for text simplification have limited annotations that are based on unitary or outdated models, making them unsuitable for this approach. To address these issues, we introduce the SimpEval corpus that contains: SimpEval_past, comprising 12K human ratings on 2.4K simplifications of 24 past systems, and SimpEval_2022, a challenging simplification benchmark consisting of over 1K human ratings of 360 simplifications including GPT-3.5 generated text. Training on SimpEval, we present LENS, a Learnable Evaluation Metric for Text Simplification. Extensive empirical results show that LENS correlates much better with human judgment than existing metrics, paving the way for future progress in the evaluation of text simplification. We also introduce Rank and Rate, a human evaluation framework that rates si
    
[^62]: Transformers中的简洁偏见及其学习稀疏布尔函数的能力

    Simplicity Bias in Transformers and their Ability to Learn Sparse Boolean Functions. (arXiv:2211.12316v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.12316](http://arxiv.org/abs/2211.12316)

    Transformers相对于循环模型更偏向于学习具有低敏感度的函数，尤其在稀疏布尔函数上，Transformers能够实现近乎完美的泛化，而LSTMs则表现出过拟合和较低的泛化精度。

    

    尽管Transformers在自然语言处理任务上取得了广泛的成功，但最近的研究发现，与循环模型相比，它们在建模几种形式语言时遇到困难。这引发了一个问题，为什么Transformers在实践中表现良好，它们是否具有任何能使它们比循环模型更好地泛化的属性。在这项工作中，我们对布尔函数进行了广泛的实证研究，以证明以下内容：(i) 随机Transformers相对更偏向于具有低敏感度的函数。(ii) 当训练布尔函数时，Transformers和LSTMs都优先学习具有低敏感度的函数，最终Transformers收敛到具有更低敏感度的函数。(iii) 在具有低敏感度的稀疏布尔函数上，我们发现Transformers在存在噪音标签的情况下能够近乎完美地泛化，而LSTMs过拟合并且泛化精度较低。总体而言，我们的结果提供了强有力的可量化证据。

    Despite the widespread success of Transformers on NLP tasks, recent works have found that they struggle to model several formal languages when compared to recurrent models. This raises the question of why Transformers perform well in practice and whether they have any properties that enable them to generalize better than recurrent models. In this work, we conduct an extensive empirical study on Boolean functions to demonstrate the following: (i) Random Transformers are relatively more biased towards functions of low sensitivity. (ii) When trained on Boolean functions, both Transformers and LSTMs prioritize learning functions of low sensitivity, with Transformers ultimately converging to functions of lower sensitivity. (iii) On sparse Boolean functions which have low sensitivity, we find that Transformers generalize near perfectly even in the presence of noisy labels whereas LSTMs overfit and achieve poor generalization accuracy. Overall, our results provide strong quantifiable evidence
    
[^63]: Nano: 嵌套的人机交互奖励学习用于少样本语言模型控制

    Nano: Nested Human-in-the-Loop Reward Learning for Few-shot Language Model Control. (arXiv:2211.05750v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.05750](http://arxiv.org/abs/2211.05750)

    本研究提出了一个少样本人机交互训练算法Nano，用于按任意分布（定量和未定量）生成文本。与先前的工作相比，Nano在单一主题/属性以及定量分布控制方面表现出最先进的结果。

    

    预训练语言模型在语言生成方面展示了非凡的能力。然而，真实世界的任务经常需要控制生成文本的分布，以减轻偏见、促进公平性和实现个性化。现有的文本分布控制技术只适用于定量分布，这要求预先定义的类别、分布比例或符合所需分布的现有语料库。然而，许多重要的分布，如个人偏好，是未定量化的。在这项工作中，我们通过提出Nano，一个少样本人机交互训练算法，不断从人类反馈中学习，来解决按任意分布（定量和未定量）生成文本的问题。与先前的工作相比，Nano在单一主题/属性以及定量分布控制方面取得了最先进的结果。我们还展示Nano能够学习未定量化的分布。

    Pretrained language models have demonstrated extraordinary capabilities in language generation. However, real-world tasks often require controlling the distribution of generated text in order to mitigate bias, promote fairness, and achieve personalization. Existing techniques for controlling the distribution of generated text only work with quantified distributions, which require pre-defined categories, proportions of the distribution, or an existing corpus following the desired distributions. However, many important distributions, such as personal preferences, are unquantified. In this work, we tackle the problem of generating text following arbitrary distributions (quantified and unquantified) by proposing Nano, a few-shot human-in-the-loop training algorithm that continuously learns from human feedback. Nano achieves state-of-the-art results on single topic/attribute as well as quantified distribution control compared to previous works. We also show that Nano is able to learn unquan
    
[^64]: Mars: 使用对比学习建模上下文和状态表示的端到端任务导向对话系统

    Mars: Modeling Context & State Representations with Contrastive Learning for End-to-End Task-Oriented Dialog. (arXiv:2210.08917v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.08917](http://arxiv.org/abs/2210.08917)

    本文提出了Mars，一种使用对比学习建模上下文和状态表示的端到端任务导向对话系统。研究结果表明，与语义状态表示不同的对话上下文表示对于多轮任务导向对话更为有益，且Mars在常用评测数据集上取得了最先进的性能。

    

    传统的端到端任务导向对话系统将对话上下文转换为信念状态和动作状态，然后生成系统响应。系统响应的性能显著受到信念状态和动作状态质量的影响。本文首先探索了对话上下文表示对提高信念状态和动作状态质量的益处，从而进一步增强生成的响应质量。为了解决这个问题，我们提出了Mars，一种端到端任务导向对话系统，利用两种对比学习策略来建模对话上下文和信念/动作状态表示之间的关系。实证结果表明，与语义状态表示更不同的对话上下文表示对多轮任务导向对话更有益。此外，我们提出的Mars在MultiWOZ 2.0、CamRest676和CrossWOZ上达到了最先进的性能。

    Traditional end-to-end task-oriented dialog systems first convert dialog context into belief state and action state before generating the system response. The system response performance is significantly affected by the quality of the belief state and action state. We first explore what dialog context representation is beneficial to improving the quality of the belief state and action state, which further enhances the generated response quality. To tackle our exploration, we propose Mars, an end-to-end task-oriented dialog system with two contrastive learning strategies to model the relationship between dialog context and belief/action state representations. Empirical results show dialog context representations, which are more different from semantic state representations, are more conducive to multi-turn task-oriented dialog. Moreover, our proposed Mars achieves state-of-the-art performance on the MultiWOZ 2.0, CamRest676, and CrossWOZ.
    
[^65]: 多媒体生成式脚本学习用于任务规划

    Multimedia Generative Script Learning for Task Planning. (arXiv:2208.12306v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2208.12306](http://arxiv.org/abs/2208.12306)

    该论文提出了多媒体生成式脚本学习任务，旨在通过跟踪文本和视觉模态中的历史状态来生成后续步骤，能对未见过的任务具有归纳能力并具有多样性。

    

    目标导向的生成式脚本学习旨在基于目标生成后续步骤，这是帮助机器人执行日常生活中典型活动的重要任务。我们展示了如果历史状态不仅由给人的语言指示捕获，而且还通过相伴的图像提供了附加信息，那么此任务的表现可以改善。因此，我们提出了一个新任务，即多媒体生成式脚本学习，以通过跟踪文本和视觉模态中的历史状态来生成后续步骤，并提供了包含2,338个任务和31,496个步骤及其描述性图像的第一个基准。我们的目标是生成可视状态可跟踪的脚本，对于未见过的任务具有归纳能力，并且其步骤具有多样性。我们提出通过多媒体选择性编码器对视觉状态变化进行编码，利用检索增强解码器传递先前观察到的任务知识，并通过随机抽样和波束搜索解码生成多样的步骤。

    Goal-oriented generative script learning aims to generate subsequent steps based on a goal, which is an essential task to assist robots in performing stereotypical activities of daily life. We show that the performance of this task can be improved if historical states are not just captured by the linguistic instructions given to people, but are augmented with the additional information provided by accompanying images. Therefore, we propose a new task, Multimedia Generative Script Learning, to generate subsequent steps by tracking historical states in both text and vision modalities, as well as presenting the first benchmark containing 2,338 tasks and 31,496 steps with descriptive images. We aim to generate scripts that are visual-state trackable, inductive for unseen tasks, and diverse in their individual steps. We propose to encode visual state changes through a multimedia selective encoder, transferring knowledge from previously observed tasks using a retrieval-augmented decoder, and
    
[^66]: 使用大型语言模型模拟多个人并复制人类实验研究

    Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies. (arXiv:2208.10264v5 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2208.10264](http://arxiv.org/abs/2208.10264)

    该论文介绍了一种新型测试方法，称为图灵实验（TE），用于评估语言模型的人类行为模拟能力。论文通过模拟经济学、心理语言学和社会心理学实验，成功复制了已有研究，并揭示了一种“超准确度扭曲”的现象。

    

    我们引入了一种称为图灵实验（TE）的新型测试，用于评估给定的语言模型（如GPT模型）在多大程度上可以模拟人类行为的不同方面。TE还可以揭示语言模型在模拟特定人类行为方面的一致性扭曲。与图灵测试不同，图灵实验需要模拟代表性参与人类受试者研究的样本。我们进行TEs，试图复制之前研究中确立的发现。我们设计了一种模拟TEs的方法，并举例说明其用于比较不同语言模型能够多大程度上复制经典经济学、心理语言学和社会心理学实验的能力：最终游戏、园路句子、米尔格拉姆电击实验和众人的智慧。在前三个TEs中，使用最新模型成功复制了现有的研究结果，而最后一个TE揭示了存在于最新模型中的“超准确度扭曲”。

    We introduce a new type of test, called a Turing Experiment (TE), for evaluating to what extent a given language model, such as GPT models, can simulate different aspects of human behavior. A TE can also reveal consistent distortions in a language model's simulation of a specific human behavior. Unlike the Turing Test, which involves simulating a single arbitrary individual, a TE requires simulating a representative sample of participants in human subject research. We carry out TEs that attempt to replicate well-established findings from prior studies. We design a methodology for simulating TEs and illustrate its use to compare how well different language models are able to reproduce classic economic, psycholinguistic, and social psychology experiments: Ultimatum Game, Garden Path Sentences, Milgram Shock Experiment, and Wisdom of Crowds. In the first three TEs, the existing findings were replicated using recent models, while the last TE reveals a "hyper-accuracy distortion" present in
    
[^67]: 多语言多方对话中的共指解析

    Multilingual Coreference Resolution in Multiparty Dialogue. (arXiv:2208.01307v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2208.01307](http://arxiv.org/abs/2208.01307)

    该论文提出了一个基于电视剧本的大规模数据集Multilingual Multiparty Coref（MMC），用于解决多语言多方对话中的共指解析问题。通过重复使用黄金标注，在其他语言上创建了银共指解析数据，并发现MMC在多方共指解析的覆盖范围上比之前的数据集更广泛。在银标注数据上，无论是用于数据增强还是从头开始训练，都取得了成功，有效地模拟了零射跨语言的情况。

    

    现有的多方对话实体共指解析数据集尚不完善，并且还存在许多挑战尚待解决。我们基于电视剧本创造了一个大规模的数据集，名为Multilingual Multiparty Coref（MMC），用于这个任务。由于多种语言中存在质量较高的字幕，我们提出重复使用标注来创建其他语言（中文和波斯语）上的银共指解析数据，通过标注传递来实现。在黄金标注（英文）数据上，现有模型在MMC上表现相对较差，这表明MMC在多方共指解析的覆盖范围上比之前的数据集更广泛。在银标注数据上，我们发现无论是用于数据增强还是从头开始训练，都取得了成功，这有效地模拟了零射跨语言的情况。

    Existing multiparty dialogue datasets for entity coreference resolution are nascent, and many challenges are still unaddressed. We create a large-scale dataset, Multilingual Multiparty Coref (MMC), for this task based on TV transcripts. Due to the availability of gold-quality subtitles in multiple languages, we propose reusing the annotations to create silver coreference resolution data in other languages (Chinese and Farsi) via annotation projection. On the gold (English) data, off-the-shelf models perform relatively poorly on MMC, suggesting that MMC has broader coverage of multiparty coreference than prior datasets. On the silver data, we find success both using it for data augmentation and training from scratch, which effectively simulates the zero-shot cross-lingual setting.
    
[^68]: KenSwQuAD - 一份适用于斯瓦希里语低资源语言的问答数据集

    KenSwQuAD -- A Question Answering Dataset for Swahili Low Resource Language. (arXiv:2205.02364v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.02364](http://arxiv.org/abs/2205.02364)

    该研究开发了KenSwQuAD - 一份适用于斯瓦希里语低资源语言的问答数据集，以满足低资源语言中机器理解自然语言的需求。这个数据集是通过从斯瓦希里语低资源语言的原始故事文本中进行注释得到的，包含7,526个QA对。

    

    本研究的动机是为低资源语言开发问答数据集的需求，从而开发了斯瓦希里语问答数据集KenSwQuAD。该数据集是从斯瓦希里语低资源语言的原始故事文本中进行注释的，该语言主要在东非和世界其他地方使用。问答（QA）数据集对于机器理解自然语言的任务（如互联网搜索和对话系统）非常重要。机器学习系统需要训练数据，如本研究开发的黄金标准问答集。本项目聘请了注解员从Kencorpus项目收集的斯瓦希里语文本中制定QA对。该项目对总共2,585个文本进行了1,445个文本的注释，每个注释至少有5个QA对，最终形成了一个包含7,526个QA对的数据集。对12.5%的注释文本进行的质量保证确认了QA对的准确性。

    The need for Question Answering datasets in low resource languages is the motivation of this research, leading to the development of Kencorpus Swahili Question Answering Dataset, KenSwQuAD. This dataset is annotated from raw story texts of Swahili low resource language, which is a predominantly spoken in Eastern African and in other parts of the world. Question Answering (QA) datasets are important for machine comprehension of natural language for tasks such as internet search and dialog systems. Machine learning systems need training data such as the gold standard Question Answering set developed in this research. The research engaged annotators to formulate QA pairs from Swahili texts collected by the Kencorpus project, a Kenyan languages corpus. The project annotated 1,445 texts from the total 2,585 texts with at least 5 QA pairs each, resulting into a final dataset of 7,526 QA pairs. A quality assurance set of 12.5% of the annotated texts confirmed that the QA pairs were all correc
    
[^69]: 在COVID-19危机中使用语义网络分析预测金融市场

    Forecasting financial markets with semantic network analysis in the COVID-19 crisis. (arXiv:2009.04975v4 [q-fin.GN] UPDATED)

    [http://arxiv.org/abs/2009.04975](http://arxiv.org/abs/2009.04975)

    本文通过使用语义网络分析来预测金融市场，基于新的文本数据指标，评估经济相关关键词的重要性，并应用于意大利股票和债券市场。研究结果显示，该指标能够很好地捕捉到金融时间序列的不同阶段，并且对于债券市场数据和股票市场波动性都存在明显的可预测性。

    

    本文使用一种新的文本数据指标来预测股票市场数据。该指标应用于大量新闻中，评估文本中出现的一个或多个与经济相关的关键词的重要性。该指标根据关键词的使用频率和语义网络位置评估其重要性。我们将其应用于意大利新闻，并构建指数来预测意大利股票和债券市场的回报率和波动性，包括COVID-19危机期间的数据。研究结果表明，该指标很好地捕捉到金融时间序列的不同阶段。此外，研究结果显示，债券市场数据，无论是回报率还是波动性，在短期和长期到期日以及股票市场波动性方面都存在明显的可预测性。

    This paper uses a new textual data index for predicting stock market data. The index is applied to a large set of news to evaluate the importance of one or more general economic-related keywords appearing in the text. The index assesses the importance of the economic-related keywords, based on their frequency of use and semantic network position. We apply it to the Italian press and construct indices to predict Italian stock and bond market returns and volatilities in a recent sample period, including the COVID-19 crisis. The evidence shows that the index captures the different phases of financial time series well. Moreover, results indicate strong evidence of predictability for bond market data, both returns and volatilities, short and long maturities, and stock market volatility.
    

