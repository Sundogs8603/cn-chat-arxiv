# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models.](http://arxiv.org/abs/2401.01335) | 本文提出了一种名为自我对弱语言模型进行细调（SPIN）的方法，通过模型自我对弈生成训练数据，并从中优化模型策略，从而将弱语言模型转化为强语言模型，无需额外的人类标注数据。 |
| [^2] | [TREC iKAT 2023: The Interactive Knowledge Assistance Track Overview.](http://arxiv.org/abs/2401.01330) | TREC iKAT 2023是一个交互式的知识辅助任务，旨在开发适应用户交互和上下文的会话搜索代理。该任务还强调决策搜索任务，用户通过筛选数据和信息来进行决策和执行动作。 |
| [^3] | [An Autoregressive Text-to-Graph Framework for Joint Entity and Relation Extraction.](http://arxiv.org/abs/2401.01326) | 这篇论文提出了一种新颖的方法，通过将联合实体和关系抽取问题作为条件序列生成问题来解决。该方法使用了基于跨度的图生成方式，并通过指向机制将生成的输出与原始文本对齐。评估结果证明了该方法的有效性，并获得了竞争性的结果。 |
| [^4] | [LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning.](http://arxiv.org/abs/2401.01325) | 本研究提出了一种名为Self-Extend的方法，通过自身扩展现有LLMs的上下文窗口，无需调整，充分利用LLMs处理长上下文的固有能力。 |
| [^5] | [A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models.](http://arxiv.org/abs/2401.01313) | 大型语言模型在生成文本时容易出现幻觉，这是安全部署这些模型的最大障碍。解决幻觉问题对于在实际环境中广泛使用这些模型至关重要。 |
| [^6] | [Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models.](http://arxiv.org/abs/2401.01301) | 大型语言模型存在法律幻觉，不一致法律事实，幻觉普遍存在高达69%至88%的情况，无法纠正用户错误法律假设。 |
| [^7] | [A Comprehensive Study of Knowledge Editing for Large Language Models.](http://arxiv.org/abs/2401.01286) | 本研究全面研究了大型语言模型的知识编辑，旨在有效修改模型的行为，同时保持整体性能。 |
| [^8] | [Quality and Quantity of Machine Translation References for Automated Metrics.](http://arxiv.org/abs/2401.01283) | 本研究发现，机器翻译评估的较高质量参考文献对于评估指标与人类评价之间的相关性更好。每个段落平均使用7个参考文献有助于提升所有评估指标。不同质量的供应商参考文献可以混合使用来提高评估指标的准确性。这些发现可用于在特定预算下创建参考文献的共享任务的评估者。 |
| [^9] | [CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent Evaluation.](http://arxiv.org/abs/2401.01275) | CharacterEval是一个用于角色扮演对话代理评估的中文基准测试集，包含1,785个多轮对话和23,020个示例，涵盖77个角色。实验结果表明CharacterEval在评估RPCA方面是有效的。 |
| [^10] | [Fairness Certification for Natural Language Processing and Large Language Models.](http://arxiv.org/abs/2401.01262) | 这项研究旨在为自然语言处理领域开发公平性认证方法。通过综述大量文献和专家访谈，我们提出了六个公平性标准，为操作化和测试过程提供了基础。 |
| [^11] | [VideoDrafter: Content-Consistent Multi-Scene Video Generation with LLM.](http://arxiv.org/abs/2401.01256) | VideoDrafter是一个利用LLM实现内容一致的多场景视频生成的框架，能够根据输入提示生成逻辑连贯的多场景脚本，并生成高质量的视频。 |
| [^12] | [Zero-Shot Position Debiasing for Large Language Models.](http://arxiv.org/abs/2401.01218) | 本文提出了一种零样本位置去偏方法（ZOE）来降低大语言模型（LLMs）的位置偏差问题，该方法利用预训练的LLMs的无监督响应进行去偏。实验证实ZOE在多个数据集和任务中均表现出优异的性能。 |
| [^13] | [Uncertainty Resolution in Misinformation Detection.](http://arxiv.org/abs/2401.01197) | 该研究介绍了一种解决误解信息中不确定性的新方法，通过提出一个分类框架和生成有效的用户查询来解决缺失上下文的问题，提高了误解信息检测的性能。 |
| [^14] | [Unifying Structured Data as Graph for Data-to-Text Pre-Training.](http://arxiv.org/abs/2401.01183) | 本论文提出了一种将不同类型的结构化数据统一为图形格式，并将数据到文本生成任务转化为图形到文本生成的方法。为了更好地利用输入图形的结构信息，作者设计了一个结构增强的Transformer，并使用位置矩阵编码了相连节点的相对位置信息。 |
| [^15] | [Unveiling Comparative Sentiments in Vietnamese Product Reviews: A Sequential Classification Framework.](http://arxiv.org/abs/2401.01108) | 该论文提出了一种串联分类框架，用于揭示越南产品评论中的比较情感。该方法包括解决三个顺序子任务，即识别比较句、提取比较元素和分类比较类型。研究结果在越南语言和语音处理挑战赛中取得了第五名的成绩。 |
| [^16] | [Quokka: An Open-source Large Language Model ChatBot for Material Science.](http://arxiv.org/abs/2401.01089) | 本文介绍了Quokka——一个用于材料科学的开源大型语言模型聊天机器人，通过对超过一百万篇领域特定的论文进行预训练，并在材料科学领域的查询中提供即时的上下文意识响应。 |
| [^17] | [Vietnamese Poem Generation & The Prospect Of Cross-Language Poem-To-Poem Translation.](http://arxiv.org/abs/2401.01078) | 本文通过使用大型语言模型，成功提出了一种生成越南诗歌的方法，并探索了将诗歌翻译成不同语言的可能性，同时保持对生成内容的完全控制。 |
| [^18] | [DialCLIP: Empowering CLIP as Multi-Modal Dialog Retriever.](http://arxiv.org/abs/2401.01076) | DialCLIP是一种参数高效的多模态对话检索方法，通过在预训练的视觉语言模型CLIP中引入多模态上下文提示生成器和领域提示来提升对话检索的能力。 |
| [^19] | [Discovering Significant Topics from Legal Decisions with Selective Inference.](http://arxiv.org/abs/2401.01068) | 本研究提出了一个自动化流程，通过主题模型和统计分析方法从法律裁决文本中发现重要主题。该方法可以识别与结果相关的案例主题，并通过主题-词分布和案例-主题权重来提供更多信息。研究结果表明该方法具有很好的准确性和实用性。 |
| [^20] | [LLaMA Beyond English: An Empirical Study on Language Capability Transfer.](http://arxiv.org/abs/2401.01055) | 本文提出了LLaMA超越英语：语言能力转移的实证研究。通过对LLaMA进行广泛的实证调查，分析了词汇扩展、进一步预训练和指导调整等关键因素对非英语语言上的能力转移的影响，并通过四个标准化测试基准评估了模型的知识水平和响应质量。 |
| [^21] | [Cheetah: Natural Language Generation for 517 African Languages.](http://arxiv.org/abs/2401.01053) | Cheetah是一个面向517种非洲语言的大规模多语种自然语言生成模型，通过综合评估和人工评估，证明了其在生成连贯和上下文恰当的文本方面的卓越性能，并提供了促进语言多样性的解决方案。 |
| [^22] | [Auffusion: Leveraging the Power of Diffusion and Large Language Models for Text-to-Audio Generation.](http://arxiv.org/abs/2401.01044) | 这篇论文介绍了一种名为Auffusion的文本到音频生成系统，它利用扩散和大型语言模型，通过跨模态对齐的能力，提高了生成质量和文本-音频对齐。该系统在有限的数据和计算资源下胜过了之前的方法，并关注了编码器选择对跨模态对齐的重要性。 |
| [^23] | [DocLLM: A layout-aware generative language model for multimodal document understanding.](http://arxiv.org/abs/2401.00908) | 本文提出了一种名为DocLLM的面向布局感知的多模态文档理解生成语言模型，通过结合文本语义和空间布局，避免了使用昂贵的图像编码器，提供了一种有效理解企业文档的方法。 |
| [^24] | [LaFFi: Leveraging Hybrid Natural Language Feedback for Fine-tuning Language Models.](http://arxiv.org/abs/2401.00907) | LaFFi是一种用于微调语言模型的替代方法，通过要求模型预测标注者将会给出的反馈，显著提高了在问答任务中的准确性，为应用自然语言反馈提供了一个有前途的方向。 |
| [^25] | [Structured Packing in LLM Training Improves Long Context Utilization.](http://arxiv.org/abs/2312.17296) | 本论文研究了长上下文大型语言模型（LLM）中上下文利用不足的问题，并通过将相关文档纳入训练示例中来改进模型的困惑度。通过引入Structured Packing for Long Context (SPLiCe)方法，使用检索方法将最互相关文档汇集到单个训练上下文中，进一步提高了模型的性能。 |
| [^26] | [A Stochastic Analysis of the Linguistic Provenance of English Place Names.](http://arxiv.org/abs/2312.12850) | 本文通过随机分析英国地名与其他国家地名的相似性，确定解释地名所使用的可能语言。 |
| [^27] | [StyleSinger: Style Transfer for Out-of-Domain Singing Voice Synthesis.](http://arxiv.org/abs/2312.10741) | StyleSinger是针对领域外演唱声音合成的风格转移模型，通过残差风格适配器（RSA）捕捉多样的风格特征实现高质量的合成演唱声音。 |
| [^28] | [On the Learnability of Watermarks for Language Models.](http://arxiv.org/abs/2312.04469) | 该论文研究了语言模型水印的可学习性，提出了水印蒸馏方法，通过训练学生模型使其模仿使用解码水印的教师模型的行为。结果表明，语言模型具有直接学习生成水印的能力，这对于水印的实际应用具有重要影响。 |
| [^29] | [A Study on the Calibration of In-context Learning.](http://arxiv.org/abs/2312.04021) | 本研究关注上下文学习（ICL），通过定制提示来调整静态语言模型（LMs），研究了在各种自然语言理解和推理任务中性能和校准之间的平衡。研究发现随着ICL示例数量的增加，模型的校准会先增加而后得到改善，而校准误差主要出现在低样本场景下。此外，微调和CoT提示等方法可能导致校准误差和不可靠的自然语言解释，提示需要针对可靠性场景开发新的方法。 |
| [^30] | [Real-Time Online Stock Forecasting Utilizing Integrated Quantitative and Qualitative Analysis.](http://arxiv.org/abs/2311.15218) | 本研究提供了一个综合定量和定性分析的实时在线股票预测方法，通过提供一个包含了来自各种来源的数据集，将数字股票数据和定性文本数据结合起来进行分析。数据集包含了多个公司和道琼斯工业平均指数的数据，为训练提供了有效的数据基础。 |
| [^31] | [Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents.](http://arxiv.org/abs/2310.19923) | Jina Embeddings 2是一个能够处理长篇文档的文本嵌入模型，突破了传统512个标记限制，提供了高达8192个标记的容量。 |
| [^32] | [Large Search Model: Redefining Search Stack in the Era of LLMs.](http://arxiv.org/abs/2310.14587) | 本文介绍了一个称为大型搜索模型的框架，通过将所有搜索任务统一为一个大型语言模型(LLM)，重新定义了传统的搜索堆栈。这个框架利用了LLM的强大语言理解和推理能力，有潜力提高搜索结果的质量，同时简化现有的繁琐的搜索堆栈。 |
| [^33] | [Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis.](http://arxiv.org/abs/2310.10477) | 该论文介绍了一种基于错误分析的对齐策略，通过暴露大型语言模型的错误输出并进行评估，以理解内部原因。通过这种方法，有毒回应可以转化为模型对齐的指导调谐语料，从而提高模型的安全性并训练其进行自我批评。 |
| [^34] | [Reward-Augmented Decoding: Efficient Controlled Text Generation With a Unidirectional Reward Model.](http://arxiv.org/abs/2310.09520) | 该论文介绍了一种名为Reward-Augmented Decoding (RAD)的文本生成方法，使用小型的单向奖励模型来鼓励语言模型生成具有特定属性的文本。RAD在生成非有害和情感受控文本方面表现最佳，并且在非常大的语言模型上也很有效。 |
| [^35] | [The Cambridge Law Corpus: A Corpus for Legal AI Research.](http://arxiv.org/abs/2309.12269) | 剑桥法律语料库是一个用于法律人工智能研究的语料库，包含来自英国的超过250,000个法庭案例。在该语料库的基础上，我们提供了案例结果的专家注解，并使用多个模型进行了案例结果提取的训练和评估，为研究提供了基准。 |
| [^36] | [Evidence of Human-Like Visual-Linguistic Integration in Multimodal Large Language Models During Predictive Language Processing.](http://arxiv.org/abs/2308.06035) | 这篇论文研究了多模态大语言模型（mLLMs）在预测语言处理过程中与人类的视觉-语言集成能力是否一致的问题，并通过实验验证了mLLMs的多模态输入方法可以减少认知负荷，提高感知和理解能力。 |
| [^37] | [RS5M: A Large Scale Vision-Language Dataset for Remote Sensing Vision-Language Foundation Model.](http://arxiv.org/abs/2306.11300) | 本文提出了一个新的框架RS5M，该框架包括领域基础模型（DFM），用于实现通用基础模型（GFM）和领域特定下游任务之间的转换。另外，还介绍了一个遥感领域的大规模图像-文本配对数据集RS5M，该数据集是通过过滤公开可用的图像-文本配对数据集并使用预训练的视觉-语言基础模型为标签数据集生成标题。 |
| [^38] | [Language Models are Bounded Pragmatic Speakers.](http://arxiv.org/abs/2305.17760) | 本文提出了一个概率认知模型，称为有限实用说话者，用于表征不同变体的语言模型的操作方式。经过人类反馈的强化学习微调的大型语言模型具有概念上类似于 快与慢思考模型的思维模型，而这种思维模型被归因于人类。此研究凸显了采用认知概率建模方法对语言模型的理解、评估和推进的价值。 |
| [^39] | [ArtGPT-4: Artistic Vision-Language Understanding with Adapter-enhanced MiniGPT-4.](http://arxiv.org/abs/2305.07490) | ArtGPT-4是一种基于适配器增强的MiniGPT-4模型，专注于解决图像理解方面的问题，能够在短时间内训练出具备良好视觉语言理解能力的多模态模型。 |
| [^40] | [In-depth analysis of music structure as a self-organized network.](http://arxiv.org/abs/2303.13631) | 本文介绍了一种利用Essential Element Network (EEN)算法将音频编码成文本并进行相关性计算和优化应用于聚类系数的频率和排名的方法，得到了音乐的深层结构信息，为厘清音乐结构提供了新方法。 |

# 详细

[^1]: 自我对弱语言模型进行细调可以将其转化为强语言模型

    Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models. (arXiv:2401.01335v1 [cs.LG])

    [http://arxiv.org/abs/2401.01335](http://arxiv.org/abs/2401.01335)

    本文提出了一种名为自我对弱语言模型进行细调（SPIN）的方法，通过模型自我对弈生成训练数据，并从中优化模型策略，从而将弱语言模型转化为强语言模型，无需额外的人类标注数据。

    

    通过监督细调（SFT）利用人类标注数据的力量对于推进大型语言模型（LLMs）至关重要。本文探讨了在不需要获取额外人类标注数据的情况下，将弱语言模型发展成为强语言模型的可能性。我们提出了一种名为自我对弱语言模型进行细调（SPIN）的新的细调方法，该方法从一个经过监督细调的模型开始。SPIN的核心是自我对弱语言模型的机制，其中弱语言模型通过与自身的实例对弈来提升自己的能力。具体而言，弱语言模型通过生成自己的训练数据来优化自身策略，通过区分自我生成的回应与来自人类标注数据的回应来改进。我们的方法逐步将弱语言模型提升为强大的模型，充分发掘人类标注示范数据在SFT中的潜力。在理论上，我们证明了该方法的训练目标函数的全局最优解是可以达到的。

    Harnessing the power of human-annotated data through Supervised Fine-Tuning (SFT) is pivotal for advancing Large Language Models (LLMs). In this paper, we delve into the prospect of growing a strong LLM out of a weak one without the need for acquiring additional human-annotated data. We propose a new fine-tuning method called Self-Play fIne-tuNing (SPIN), which starts from a supervised fine-tuned model. At the heart of SPIN lies a self-play mechanism, where the LLM refines its capability by playing against instances of itself. More specifically, the LLM generates its own training data from its previous iterations, refining its policy by discerning these self-generated responses from those obtained from human-annotated data. Our method progressively elevates the LLM from a nascent model to a formidable one, unlocking the full potential of human-annotated demonstration data for SFT. Theoretically, we prove that the global optimum to the training objective function of our method is achiev
    
[^2]: TREC iKAT 2023: 交互式知识辅助任务概述

    TREC iKAT 2023: The Interactive Knowledge Assistance Track Overview. (arXiv:2401.01330v1 [cs.IR])

    [http://arxiv.org/abs/2401.01330](http://arxiv.org/abs/2401.01330)

    TREC iKAT 2023是一个交互式的知识辅助任务，旨在开发适应用户交互和上下文的会话搜索代理。该任务还强调决策搜索任务，用户通过筛选数据和信息来进行决策和执行动作。

    

    会话式信息查询是一个关键的研究领域，之前的工作也有很大的贡献。TREC交互式知识辅助任务（iKAT）建立在TREC会话辅助任务（CAsT）的基础上。然而，iKAT着重于创建和研究可以根据用户之前的交互和当前情境自适应响应的会话搜索代理。挑战在于使会话搜索代理能够将个性化的上下文信息融入到相应中，以高效地引导用户获取相关信息。iKAT还着重于决策搜索任务，即用户通过数据和信息筛选来衡量各种选择，以达到结论或执行动作。这些任务在日常信息搜索决策中普遍存在，无论是旅游、健康还是购物等，通常涉及一组高级信息操作符，其中查询或问题可能会

    Conversational Information Seeking stands as a pivotal research area with significant contributions from previous works. The TREC Interactive Knowledge Assistance Track (iKAT) builds on the foundational work of the TREC Conversational Assistance Track (CAsT). However, iKAT distinctively emphasizes the creation and research of conversational search agents that adapt responses based on user's prior interactions and present context. The challenge lies in enabling Conversational Search Agents (CSA) to incorporate this personalized context to efficiency and effectively guide users through the relevant information to them. iKAT also emphasizes decisional search tasks, where users sift through data and information to weigh up options in order to reach a conclusion or perform an action. These tasks, prevalent in everyday information-seeking decisions -- be it related to travel, health, or shopping -- often revolve around a subset of high-level information operators where queries or questions a
    
[^3]: 一种用于联合实体和关系抽取的自回归文本到图框架

    An Autoregressive Text-to-Graph Framework for Joint Entity and Relation Extraction. (arXiv:2401.01326v1 [cs.CL])

    [http://arxiv.org/abs/2401.01326](http://arxiv.org/abs/2401.01326)

    这篇论文提出了一种新颖的方法，通过将联合实体和关系抽取问题作为条件序列生成问题来解决。该方法使用了基于跨度的图生成方式，并通过指向机制将生成的输出与原始文本对齐。评估结果证明了该方法的有效性，并获得了竞争性的结果。

    

    本文提出了一种新颖的方法，将非结构化文本中的联合实体和关系抽取问题作为条件序列生成问题来解决。与传统的生成式信息抽取模型不同，我们的方法是基于跨度的，它生成一个线性化的图，其中节点表示文本跨度，边表示关系三元组。我们的方法采用了一个具有指向机制的转换器编码器-解码器架构，使用一个动态词汇表来表示跨度和关系类型。我们的模型能够通过跨度表示捕捉实体和关系的结构特征和边界，同时通过指向机制将生成的输出与原始文本进行对齐。在基准数据集上的评估验证了我们方法的有效性，展示了竞争性的结果。代码可在https://github.com/urchade/ATG找到。

    In this paper, we propose a novel method for joint entity and relation extraction from unstructured text by framing it as a conditional sequence generation problem. In contrast to conventional generative information extraction models that are left-to-right token-level generators, our approach is \textit{span-based}. It generates a linearized graph where nodes represent text spans and edges represent relation triplets. Our method employs a transformer encoder-decoder architecture with pointing mechanism on a dynamic vocabulary of spans and relation types. Our model can capture the structural characteristics and boundaries of entities and relations through span representations while simultaneously grounding the generated output in the original text thanks to the pointing mechanism. Evaluation on benchmark datasets validates the effectiveness of our approach, demonstrating competitive results. Code is available at https://github.com/urchade/ATG.
    
[^4]: 自扩展LLM:无需调整的LLM上下文窗口。

    LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning. (arXiv:2401.01325v1 [cs.CL])

    [http://arxiv.org/abs/2401.01325](http://arxiv.org/abs/2401.01325)

    本研究提出了一种名为Self-Extend的方法，通过自身扩展现有LLMs的上下文窗口，无需调整，充分利用LLMs处理长上下文的固有能力。

    

    本研究揭示了LLM在处理长上下文时的固有能力，而无需进行精调。在训练过程中，训练序列的有限长度可能限制了大型语言模型（LLMs）在推理过程中对长输入序列的应用。在本研究中，我们认为现有的LLMs本身具有处理长上下文的固有能力。基于这一观点，我们建议通过自身扩展LLMs的上下文窗口，以充分利用其固有能力。我们提出了Self-Extend方法来激发LLMs的长上下文处理潜力。基本思想是构建双层注意信息：群组级和邻居级。这两个级别通过原始模型的自注意力计算，这意味着所提方法不需要任何训练。只需修改四行代码，所提方法就可以轻松扩展现有LLMs的上下文窗口，而无需进行任何精调。我们进行了全面的实验证明，结果表明所提方法可以+摘要减掉文章最后一句話

    This work elicits LLMs' inherent ability to handle long contexts without fine-tuning. The limited length of the training sequence during training may limit the application of Large Language Models (LLMs) on long input sequences for inference. In this work, we argue that existing LLMs themselves have inherent capabilities for handling long contexts. Based on this argument, we suggest extending LLMs' context window by themselves to fully utilize the inherent ability.We propose Self-Extend to stimulate LLMs' long context handling potential. The basic idea is to construct bi-level attention information: the group level and the neighbor level. The two levels are computed by the original model's self-attention, which means the proposed does not require any training. With only four lines of code modification, the proposed method can effortlessly extend existing LLMs' context window without any fine-tuning. We conduct comprehensive experiments and the results show that the proposed method can 
    
[^5]: 大型语言模型中幻觉缓解技术的综述

    A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models. (arXiv:2401.01313v1 [cs.CL])

    [http://arxiv.org/abs/2401.01313](http://arxiv.org/abs/2401.01313)

    大型语言模型在生成文本时容易出现幻觉，这是安全部署这些模型的最大障碍。解决幻觉问题对于在实际环境中广泛使用这些模型至关重要。

    

    随着大型语言模型（LLMs）在生成人类化文本方面的能力不断提高，一个关键挑战是它们倾向于产生虚构的内容，看似真实但没有依据。幻觉问题可以说是安全地将这些强大的LLMs部署到影响人们生活的现实生产系统中最大的障碍。在实际环境中广泛采用LLMs的过程严重依赖于解决和减轻幻觉。与传统的专注于有限任务的人工智能系统不同，LLMs在训练过程中可以接触到大量的在线文本数据。这使它们能够展示出令人印象深刻的语言流利性，但也意味着它们能够从训练数据的偏见中推断信息，错误解释含糊不清的提示，或者修改信息以表面上与输入一致。当我们依赖语言生成能力来完成敏感应用时，这变得非常令人担忧。

    As Large Language Models (LLMs) continue to advance in their ability to write human-like text, a key challenge remains around their tendency to hallucinate generating content that appears factual but is ungrounded. This issue of hallucination is arguably the biggest hindrance to safely deploying these powerful LLMs into real-world production systems that impact people's lives. The journey toward widespread adoption of LLMs in practical settings heavily relies on addressing and mitigating hallucinations. Unlike traditional AI systems focused on limited tasks, LLMs have been exposed to vast amounts of online text data during training. While this allows them to display impressive language fluency, it also means they are capable of extrapolating information from the biases in training data, misinterpreting ambiguous prompts, or modifying the information to align superficially with the input. This becomes hugely alarming when we rely on language generation capabilities for sensitive applica
    
[^6]: 大型法律虚构：揭示大型语言模型中的法律幻觉

    Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models. (arXiv:2401.01301v1 [cs.CL])

    [http://arxiv.org/abs/2401.01301](http://arxiv.org/abs/2401.01301)

    大型语言模型存在法律幻觉，不一致法律事实，幻觉普遍存在高达69%至88%的情况，无法纠正用户错误法律假设。

    

    大型语言模型（LLMs）有可能改变法律实践，但其潜力受到法律幻觉的威胁，即这些模型产生与法律事实不一致的回答。我们使用一套原创的法律查询来调查这些幻觉的程度，将LLMs的回答与结构化的法律元数据进行对比，并检查其一致性。我们的工作有四个关键贡献：（1）我们建立了法律幻觉的分类体系，为今后在这一领域进行的研究提供了概念框架。（2）我们发现，法律幻觉的普遍性令人担忧，在对随机联邦法院案例进行具体、可验证的问题时，ChatGPT 3.5产生的幻觉发生率为69％，而Llama 2为88％。（3）我们展示了LLMs在逆向问题设置中往往无法纠正用户的错误法律假设。（4）我们提供了证据表明LLMs并不总能预测或并不总知道...

    Large language models (LLMs) have the potential to transform the practice of law, but this potential is threatened by the presence of legal hallucinations -- responses from these models that are not consistent with legal facts. We investigate the extent of these hallucinations using an original suite of legal queries, comparing LLMs' responses to structured legal metadata and examining their consistency. Our work makes four key contributions: (1) We develop a typology of legal hallucinations, providing a conceptual framework for future research in this area. (2) We find that legal hallucinations are alarmingly prevalent, occurring between 69% of the time with ChatGPT 3.5 and 88% with Llama 2, when these models are asked specific, verifiable questions about random federal court cases. (3) We illustrate that LLMs often fail to correct a user's incorrect legal assumptions in a contra-factual question setup. (4) We provide evidence that LLMs cannot always predict, or do not always know, wh
    
[^7]: 大型语言模型的知识编辑全面研究

    A Comprehensive Study of Knowledge Editing for Large Language Models. (arXiv:2401.01286v1 [cs.CL])

    [http://arxiv.org/abs/2401.01286](http://arxiv.org/abs/2401.01286)

    本研究全面研究了大型语言模型的知识编辑，旨在有效修改模型的行为，同时保持整体性能。

    

    大型语言模型(LLM)在理解和生成与人类交流紧密相似的文本方面展现出了非凡的能力。然而，其主要限制在于训练过程中的显著计算需求，这是由于其广泛的参数化造成的。这一挑战在于世界的动态性，需要频繁更新LLM以修正过时的信息或集成新知识，从而确保其持续的相关性。许多应用需要在训练后进行持续的模型调整，以解决缺陷或不良行为。近年来，对于LLM的知识编辑技术的兴趣越来越高，在特定领域内有效地修改LLM的行为，同时保持整体性能在各种输入中的表现。本文首先定义了知识编辑的目标和挑战，然后综述了现有的知识编辑方法和技术，并讨论了其应用和未来发展的方向。

    Large Language Models (LLMs) have shown extraordinary capabilities in understanding and generating text that closely mirrors human communication. However, a primary limitation lies in the significant computational demands during training, arising from their extensive parameterization. This challenge is further intensified by the dynamic nature of the world, necessitating frequent updates to LLMs to correct outdated information or integrate new knowledge, thereby ensuring their continued relevance. Note that many applications demand continual model adjustments post-training to address deficiencies or undesirable behaviors. There is an increasing interest in efficient, lightweight methods for on-the-fly model modifications. To this end, recent years have seen a burgeoning in the techniques of knowledge editing for LLMs, which aim to efficiently modify LLMs' behaviors within specific domains while preserving overall performance across various inputs. In this paper, we first define the kno
    
[^8]: 机器翻译自动评估的参考文献质量和数量

    Quality and Quantity of Machine Translation References for Automated Metrics. (arXiv:2401.01283v1 [cs.CL])

    [http://arxiv.org/abs/2401.01283](http://arxiv.org/abs/2401.01283)

    本研究发现，机器翻译评估的较高质量参考文献对于评估指标与人类评价之间的相关性更好。每个段落平均使用7个参考文献有助于提升所有评估指标。不同质量的供应商参考文献可以混合使用来提高评估指标的准确性。这些发现可用于在特定预算下创建参考文献的共享任务的评估者。

    

    自动机器翻译评估指标通常使用人工翻译来确定系统翻译的质量。领域内的共识认为人工参考文献应具有很高的质量。然而，目前没有成本效益分析可以指导计划收集机器翻译评估参考文献的从业者。我们发现，较高质量的参考文献能够在段落级别上与人类评价的相关性更好。每个段落平均使用7个参考文献有助于所有评估指标的提升。有趣的是，来自不同质量的供应商的参考文献可以混合使用，并提高评估指标的准确性。然而，较高质量的参考文献制作成本更高，我们将其视为一个优化问题：在特定预算下，应该收集哪些参考文献以最大化评估指标的准确性。这些发现可用于在特定预算下创建参考文献的共享任务的评估者。

    Automatic machine translation metrics often use human translations to determine the quality system translations. Common wisdom in the field dictates that the human references should be of very high quality. However, there are no cost-benefit analyses that could be used to guide practitioners who plan to collect references for machine translation evaluation. We find that higher-quality references lead to better metric correlations with humans at the segment-level. Having up to 7 references per segment and taking their average helps all metrics. Interestingly, the references from vendors of different qualities can be mixed together and improve metric success. Higher quality references, however, cost more to create and we frame this as an optimization problem: given a specific budget, what references should be collected to maximize metric success. These findings can be used by evaluators of shared tasks when references need to be created under a certain budget.
    
[^9]: CharacterEval: 一种用于角色扮演对话代理评估的中文基准

    CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent Evaluation. (arXiv:2401.01275v1 [cs.CL])

    [http://arxiv.org/abs/2401.01275](http://arxiv.org/abs/2401.01275)

    CharacterEval是一个用于角色扮演对话代理评估的中文基准测试集，包含1,785个多轮对话和23,020个示例，涵盖77个角色。实验结果表明CharacterEval在评估RPCA方面是有效的。

    

    最近，大型语言模型（LLM）的出现彻底改变了生成代理的方式。其中，角色扮演对话代理（RPCA）由于其触发用户情感的能力而引起了广泛关注。然而，缺乏一个全面的基准测试集阻碍了该领域的进展。为了填补这一空白，我们推出了CharacterEval，这是一个用于全面评估RPCA的中文基准测试集，并配有一个定制的高质量数据集。该数据集包括1,785个多轮角色扮演对话，涵盖了23,020个示例，涉及了77个来源于中国小说和剧本的角色。它经过精心构建，首先通过GPT-4进行初始对话提取，然后进行严格的人工质量控制，并通过百度百科获取了深入的角色资料。CharacterEval采用多方面的评估方法，包括四个维度上的十三个有针对性的指标。在CharacterEval上进行的全面实验证明了它的有效性。

    Recently, the advent of large language models (LLMs) has revolutionized generative agents. Among them, Role-Playing Conversational Agents (RPCAs) attract considerable attention due to their ability to emotionally engage users. However, the absence of a comprehensive benchmark impedes progress in this field. To bridge this gap, we introduce CharacterEval, a Chinese benchmark for comprehensive RPCA assessment, complemented by a tailored high-quality dataset. The dataset comprises 1,785 multi-turn role-playing dialogues, encompassing 23,020 examples and featuring 77 characters derived from Chinese novels and scripts. It was carefully constructed, beginning with initial dialogue extraction via GPT-4, followed by rigorous human-led quality control, and enhanced with in-depth character profiles sourced from Baidu Baike. CharacterEval employs a multifaceted evaluation approach, encompassing thirteen targeted metrics on four dimensions. Comprehensive experiments on CharacterEval demonstrate th
    
[^10]: 自然语言处理和大型语言模型公平性认证

    Fairness Certification for Natural Language Processing and Large Language Models. (arXiv:2401.01262v1 [cs.CL])

    [http://arxiv.org/abs/2401.01262](http://arxiv.org/abs/2401.01262)

    这项研究旨在为自然语言处理领域开发公平性认证方法。通过综述大量文献和专家访谈，我们提出了六个公平性标准，为操作化和测试过程提供了基础。

    

    自然语言处理（NLP）在我们的日常生活中扮演着重要角色，特别是由于大型语言模型（LLM）的巨大进展。然而，NLP在招聘等公平关键应用场景中存在许多问题，例如作为专家系统或基于LLM的教育导师。由于NLP基于人类语言，可能会导致潜在的有害偏见渗入NLP系统，产生不公平的结果，歧视少数群体或引发法律问题。因此，开展NLP方法的公平性认证非常重要。我们采用定性研究方法，对算法公平性的大量文献进行了综述，并与该领域的多位专家进行了半结构化的专家访谈。我们系统地提出了NLP的六个公平性标准，并进一步细化为18个子类别。我们的标准为实施和测试过程提供了基础。

    Natural Language Processing (NLP) plays an important role in our daily lives, particularly due to the enormous progress of Large Language Models (LLM). However, NLP has many fairness-critical use cases, e.g., as an expert system in recruitment or as an LLM-based tutor in education. Since NLP is based on human language, potentially harmful biases can diffuse into NLP systems and produce unfair results, discriminate against minorities or generate legal issues. Hence, it is important to develop a fairness certification for NLP approaches. We follow a qualitative research approach towards a fairness certification for NLP. In particular, we have reviewed a large body of literature on algorithmic fairness, and we have conducted semi-structured expert interviews with a wide range of experts from that area. We have systematically devised six fairness criteria for NLP, which can be further refined into 18 sub-categories. Our criteria offer a foundation for operationalizing and testing processes
    
[^11]: VideoDrafter: 利用LLM实现内容一致的多场景视频生成

    VideoDrafter: Content-Consistent Multi-Scene Video Generation with LLM. (arXiv:2401.01256v1 [cs.CV])

    [http://arxiv.org/abs/2401.01256](http://arxiv.org/abs/2401.01256)

    VideoDrafter是一个利用LLM实现内容一致的多场景视频生成的框架，能够根据输入提示生成逻辑连贯的多场景脚本，并生成高质量的视频。

    

    最近扩展模型的创新和突破显著扩大了根据给定提示生成高质量视频的可能性。现有的大多数作品仅处理在单个背景中发生单个视频事件的单场景情况。然而，扩展到生成多场景视频并且在保持各个场景之间的逻辑一致同时保持视觉外观一致性方面并不简单。在本文中，我们提出了一种新颖的框架，即VideoDrafter，用于内容一致的多场景视频生成。技术上，VideoDrafter利用大型语言模型（LLM）将输入提示转化为综合的多场景脚本，该脚本从LLM学到的逻辑知识中受益。每个场景的脚本包括描述事件、前景/背景实体以及摄像机运动的提示。VideoDrafter识别脚本中的共同实体，并询问LLM来选择生成逻辑连贯的视频场景。

    The recent innovations and breakthroughs in diffusion models have significantly expanded the possibilities of generating high-quality videos for the given prompts. Most existing works tackle the single-scene scenario with only one video event occurring in a single background. Extending to generate multi-scene videos nevertheless is not trivial and necessitates to nicely manage the logic in between while preserving the consistent visual appearance of key content across video scenes. In this paper, we propose a novel framework, namely VideoDrafter, for content-consistent multi-scene video generation. Technically, VideoDrafter leverages Large Language Models (LLM) to convert the input prompt into comprehensive multi-scene script that benefits from the logical knowledge learnt by LLM. The script for each scene includes a prompt describing the event, the foreground/background entities, as well as camera movement. VideoDrafter identifies the common entities throughout the script and asks LLM
    
[^12]: 大语言模型的零样本位置去偏方法

    Zero-Shot Position Debiasing for Large Language Models. (arXiv:2401.01218v1 [cs.CL])

    [http://arxiv.org/abs/2401.01218](http://arxiv.org/abs/2401.01218)

    本文提出了一种零样本位置去偏方法（ZOE）来降低大语言模型（LLMs）的位置偏差问题，该方法利用预训练的LLMs的无监督响应进行去偏。实验证实ZOE在多个数据集和任务中均表现出优异的性能。

    

    微调已被证明是改善大语言模型（LLMs）领域性能的有效方法。然而，LLMs可能适应数据集偏见和预测的捷径，导致生成性能差。实验结果显示，LLMs容易表现出位置偏差，即利用位于开头或末尾或输入中特定位置线索的信息。现有的减轻位置偏差的工作需要外部偏差知识或带注释的非偏倚样本，在实际中不太实用。在这项工作中，我们提出了一种零样本位置去偏（ZOE）框架对LLMs进行位置去偏。ZOE利用预训练的LLMs的无监督响应进行去偏，因此不需要任何外部知识或数据集。为了提高无监督响应的质量，我们提出了一种主从对齐（MSA）模块来修剪这些响应。对八个数据集和五个任务的实验表明，ZOE始终优于其他方法。

    Fine-tuning has been demonstrated to be an effective method to improve the domain performance of large language models (LLMs). However, LLMs might fit the dataset bias and shortcuts for prediction, leading to poor generation performance. Experimental result shows that LLMs are prone to exhibit position bias, i.e., leveraging information positioned at the beginning or end, or specific positional cues within the input. Existing works on mitigating position bias require external bias knowledge or annotated non-biased samples, which is unpractical in reality. In this work, we propose a zero-shot position debiasing (ZOE) framework to mitigate position bias for LLMs. ZOE leverages unsupervised responses from pre-trained LLMs for debiasing, thus without any external knowledge or datasets. To improve the quality of unsupervised responses, we propose a master-slave alignment (MSA) module to prune these responses. Experiments on eight datasets and five tasks show that ZOE consistently outperform
    
[^13]: 误解信息检测中的不确定性解决方法

    Uncertainty Resolution in Misinformation Detection. (arXiv:2401.01197v1 [cs.CL])

    [http://arxiv.org/abs/2401.01197](http://arxiv.org/abs/2401.01197)

    该研究介绍了一种解决误解信息中不确定性的新方法，通过提出一个分类框架和生成有效的用户查询来解决缺失上下文的问题，提高了误解信息检测的性能。

    

    误解信息存在各种风险，如破坏公众信任和扭曲事实言论。大型语言模型（LLMs）如GPT-4已被证明在减轻误解信息方面很有效，特别是在处理提供足够上下文的陈述时。然而，它们很难准确评估模糊或缺乏上下文的陈述。本文介绍了一种解决此类陈述中不确定性的新方法。我们提出了一个框架来对缺失信息进行分类，并为LIAR-New数据集提供类别标签，该数据集适用于具有缺失信息的跨域内容。然后，我们利用这个框架来生成缺失上下文的有效用户查询。与基线相比，我们的方法提高了用户可回答问题的比例38个百分点，并且分类性能提高了超过10个百分点的宏F1。因此，这种方法可能为未来的误解信息缓解提供有价值的组成部分。

    Misinformation poses a variety of risks, such as undermining public trust and distorting factual discourse. Large Language Models (LLMs) like GPT-4 have been shown effective in mitigating misinformation, particularly in handling statements where enough context is provided. However, they struggle to assess ambiguous or context-deficient statements accurately. This work introduces a new method to resolve uncertainty in such statements. We propose a framework to categorize missing information and publish category labels for the LIAR-New dataset, which is adaptable to cross-domain content with missing information. We then leverage this framework to generate effective user queries for missing context. Compared to baselines, our method improves the rate at which generated questions are answerable by the user by 38 percentage points and classification performance by over 10 percentage points macro F1. Thus, this approach may provide a valuable component for future misinformation mitigation pi
    
[^14]: 将结构化数据统一为图形以进行数据到文本预训练

    Unifying Structured Data as Graph for Data-to-Text Pre-Training. (arXiv:2401.01183v1 [cs.CL])

    [http://arxiv.org/abs/2401.01183](http://arxiv.org/abs/2401.01183)

    本论文提出了一种将不同类型的结构化数据统一为图形格式，并将数据到文本生成任务转化为图形到文本生成的方法。为了更好地利用输入图形的结构信息，作者设计了一个结构增强的Transformer，并使用位置矩阵编码了相连节点的相对位置信息。

    

    数据到文本（D2T）生成旨在将结构化数据转化为自然语言文本。数据到文本预训练已被证明在增强D2T生成并产生令人印象深刻的性能方面是有效的。然而，先前的预训练方法要么将结构化数据过度简化为一个序列，而不考虑输入的结构，要么设计用于特定数据结构（例如表格或知识图）的训练目标。在本文中，我们将不同类型的结构化数据（即，表格、键值数据、知识图）统一为图形格式，并将不同的数据到文本生成任务转化为图形到文本生成。为了有效利用输入图形的结构信息，我们提出了一种用于D2T生成的结构增强预训练方法，通过设计一种结构增强的Transformer。具体而言，我们为Transformer设计了一个位置矩阵，用于编码输入图形中相连节点的相对位置信息。此外，我们提出了一种基于图形结构的句法标签分类方法，用于有效结合句法信息和structure-enhanced特征。

    Data-to-text (D2T) generation aims to transform structured data into natural language text. Data-to-text pre-training has proved to be powerful in enhancing D2T generation and yields impressive performances. However, previous pre-training methods either oversimplified structured data into a sequence without considering input structures or designed training objectives tailored for a specific data structure (e.g., table or knowledge graph). In this paper, we unify different types of structured data (i.e., table, key-value data, knowledge graph) into the graph format and cast different data-to-text generation tasks as graph-to-text generation. To effectively exploit the structural information of the input graph, we propose a structure-enhanced pre-training method for D2T generation by designing a structure-enhanced Transformer. Concretely, we devise a position matrix for the Transformer, encoding relative positional information of connected nodes in the input graph. In addition, we propos
    
[^15]: 揭示越南产品评论中的比较情感：一种顺序分类框架

    Unveiling Comparative Sentiments in Vietnamese Product Reviews: A Sequential Classification Framework. (arXiv:2401.01108v1 [cs.CL])

    [http://arxiv.org/abs/2401.01108](http://arxiv.org/abs/2401.01108)

    该论文提出了一种串联分类框架，用于揭示越南产品评论中的比较情感。该方法包括解决三个顺序子任务，即识别比较句、提取比较元素和分类比较类型。研究结果在越南语言和语音处理挑战赛中取得了第五名的成绩。

    

    比较意见挖掘是情感分析的一个专门领域，旨在识别和提取表达比较情感的内容。为了解决这个任务，我们提出了一种方法，包括解决三个顺序子任务：（一）识别比较句，即判断句子是否具有比较意义，（二）提取比较元素，即比较主体、对象、方面、谓词是什么，（三）分类比较类型，从而更深入地理解越南产品评论中用户的情感。我们的方法在越南语言和语音处理（VLSP）2023挑战赛的比较意见挖掘（ComOM）任务中排名第五。

    Comparative opinion mining is a specialized field of sentiment analysis that aims to identify and extract sentiments expressed comparatively. To address this task, we propose an approach that consists of solving three sequential sub-tasks: (i) identifying comparative sentence, i.e., if a sentence has a comparative meaning, (ii) extracting comparative elements, i.e., what are comparison subjects, objects, aspects, predicates, and (iii) classifying comparison types which contribute to a deeper comprehension of user sentiments in Vietnamese product reviews. Our method is ranked fifth at the Vietnamese Language and Speech Processing (VLSP) 2023 challenge on Comparative Opinion Mining (ComOM) from Vietnamese Product Reviews.
    
[^16]: Quokka: 一个用于材料科学的开源大型语言模型聊天机器人

    Quokka: An Open-source Large Language Model ChatBot for Material Science. (arXiv:2401.01089v1 [cs.CL])

    [http://arxiv.org/abs/2401.01089](http://arxiv.org/abs/2401.01089)

    本文介绍了Quokka——一个用于材料科学的开源大型语言模型聊天机器人，通过对超过一百万篇领域特定的论文进行预训练，并在材料科学领域的查询中提供即时的上下文意识响应。

    

    本文介绍了一个用于材料科学的专用聊天机器人的开发，利用了Llama-2语言模型，并在S2ORC数据集中的材料科学领域的广泛研究文章上进行持续的预训练。方法包括首先在超过一百万篇领域特定的论文上进行预训练，然后进行指令调整过程来改善聊天机器人的能力。该聊天机器人旨在通过提供即时的、具有上下文意识的材料科学领域的查询响应，来帮助研究人员、教师和学生。我们将四个经过训练的检查点（7B、13B，带或不带聊天功能）免费提供给研究界，网址为https://github.com/Xianjun-Yang/Quokka。

    This paper presents the development of a specialized chatbot for materials science, leveraging the Llama-2 language model, and continuing pre-training on the expansive research articles in the materials science domain from the S2ORC dataset. The methodology involves an initial pretraining phase on over one million domain-specific papers, followed by an instruction-tuning process to refine the chatbot's capabilities. The chatbot is designed to assist researchers, educators, and students by providing instant, context-aware responses to queries in the field of materials science. We make the four trained checkpoints (7B, 13B, with or without chat ability) freely available to the research community at https://github.com/Xianjun-Yang/Quokka.
    
[^17]: 越南诗歌生成与跨语言诗歌翻译的前景

    Vietnamese Poem Generation & The Prospect Of Cross-Language Poem-To-Poem Translation. (arXiv:2401.01078v1 [cs.CL])

    [http://arxiv.org/abs/2401.01078](http://arxiv.org/abs/2401.01078)

    本文通过使用大型语言模型，成功提出了一种生成越南诗歌的方法，并探索了将诗歌翻译成不同语言的可能性，同时保持对生成内容的完全控制。

    

    诗歌生成一直是自然语言处理领域的一项挑战任务，因为它要求模型理解语言、情感和风格的细微差别。在本文中，我们提出使用大型语言模型从自然语言提示中生成越南诗歌，从而实现直观的过程和增强的内容控制。我们最有效的模型，GPT-3 Babbage变种，在越南诗歌的“六八词”类型中实现了0.8的自定义评分。此外，我们还探索了将诗歌改写成正常文本提示的想法，并在“六八词”类型中获得了相对较高的0.718分数。这个实验展示了以翻译后的诗歌作为输入进行跨语言诗歌翻译的潜力，并同时保持对生成内容的完全控制。

    Poetry generation has been a challenging task in the field of Natural Language Processing, as it requires the model to understand the nuances of language, sentiment, and style. In this paper, we propose using Large Language Models to generate Vietnamese poems from natural language prompts, thereby facilitating an intuitive process with enhanced content control. Our most efficacious model, the GPT-3 Babbage variant, achieves a custom evaluation score of 0.8, specifically tailored to the "luc bat" genre of Vietnamese poetry. Furthermore, we also explore the idea of paraphrasing poems into normal text prompts and yield a relatively high score of 0.718 in the "luc bat" genre. This experiment presents the potential for cross-Language poem-to-poem translation with translated poems as the inputs while concurrently maintaining complete control over the generated content.
    
[^18]: DialCLIP: 将CLIP扩展为多模态对话检索器

    DialCLIP: Empowering CLIP as Multi-Modal Dialog Retriever. (arXiv:2401.01076v1 [cs.CL])

    [http://arxiv.org/abs/2401.01076](http://arxiv.org/abs/2401.01076)

    DialCLIP是一种参数高效的多模态对话检索方法，通过在预训练的视觉语言模型CLIP中引入多模态上下文提示生成器和领域提示来提升对话检索的能力。

    

    最近，在预训练的视觉语言模型方面取得了重大进展，极大地提升了多模态对话系统的能力。这些模型通过在下游任务上进行微调，已经取得了显著的改进。然而，现有的预训练模型主要集中在有效地捕捉视觉和语言模态之间的对齐，往往忽视了对话环境的复杂性。本文提出了一种名为DialCLIP的参数高效的提示微调方法，用于多模态对话检索。具体而言，我们的方法引入了一个多模态上下文提示生成器，用于学习上下文特征，并在预训练视觉语言模型CLIP中将其提炼为提示。此外，我们引入了领域提示，以减轻下游对话数据引起的差异。为了方便各种类型的检索，我们还设计了多个专家，从CLIP的输出学习到多模态表示空间的映射，每个专家都有自己的模型。

    Recently, substantial advancements in pre-trained vision-language models have greatly enhanced the capabilities of multi-modal dialog systems. These models have demonstrated significant improvements by fine-tuning on downstream tasks. However, the existing pre-trained models primarily focus on effectively capturing the alignment between vision and language modalities, often ignoring the intricate nature of dialog context. In this paper, we propose a parameter-efficient prompt-tuning method named DialCLIP for multi-modal dialog retrieval. Specifically, our approach introduces a multi-modal context prompt generator to learn context features which are subsequently distilled into prompts within the pre-trained vision-language model CLIP. Besides, we introduce domain prompt to mitigate the disc repancy from the downstream dialog data. To facilitate various types of retrieval, we also design multiple experts to learn mappings from CLIP outputs to multi-modal representation space, with each e
    
[^19]: 从法律裁决中发现重要主题的选择推理方法

    Discovering Significant Topics from Legal Decisions with Selective Inference. (arXiv:2401.01068v1 [cs.CL])

    [http://arxiv.org/abs/2401.01068](http://arxiv.org/abs/2401.01068)

    本研究提出了一个自动化流程，通过主题模型和统计分析方法从法律裁决文本中发现重要主题。该方法可以识别与结果相关的案例主题，并通过主题-词分布和案例-主题权重来提供更多信息。研究结果表明该方法具有很好的准确性和实用性。

    

    我们提出并评估了一个自动化流程，通过将主题模型合成的特征通过受惩罚的回归和后选择显著性检验来发现法律裁决文本中的重要主题。该方法识别出与结果显著相关的案例主题，可以手动解释以获取有关重要主题的见解的主题-词分布，以及可以用于标识每个主题的代表性案例的案例-主题权重。我们在一个新的域名争议数据集和一个欧洲人权法院违规案例的经典数据集上展示了该方法。基于潜在语义分析和语言模型嵌入的主题模型进行了评估。我们证明了通过流程推导的主题在两个领域中与法律教条一致，并且可以在其他相关法律分析任务中有用。

    We propose and evaluate an automated pipeline for discovering significant topics from legal decision texts by passing features synthesized with topic models through penalised regressions and post-selection significance tests. The method identifies case topics significantly correlated with outcomes, topic-word distributions which can be manually-interpreted to gain insights about significant topics, and case-topic weights which can be used to identify representative cases for each topic. We demonstrate the method on a new dataset of domain name disputes and a canonical dataset of European Court of Human Rights violation cases. Topic models based on latent semantic analysis as well as language model embeddings are evaluated. We show that topics derived by the pipeline are consistent with legal doctrines in both areas and can be useful in other related legal analysis tasks.
    
[^20]: LLaMA超越英语：语言能力转移的实证研究

    LLaMA Beyond English: An Empirical Study on Language Capability Transfer. (arXiv:2401.01055v1 [cs.CL])

    [http://arxiv.org/abs/2401.01055](http://arxiv.org/abs/2401.01055)

    本文提出了LLaMA超越英语：语言能力转移的实证研究。通过对LLaMA进行广泛的实证调查，分析了词汇扩展、进一步预训练和指导调整等关键因素对非英语语言上的能力转移的影响，并通过四个标准化测试基准评估了模型的知识水平和响应质量。

    

    最近，在大型语言模型（LLM）方面取得了重大进展，如ChatGPT，在各种复杂任务中展现出卓越的熟练度。然而，许多主流的LLM（如LLaMA）是基于以英语为主导的语料库进行预训练的，这限制了它们在其他非英语语言中的性能。本文主要研究如何有效地将语言生成和遵循指示的能力转移到非英语语言上。为了回答这个问题，我们基于LLaMA进行了广泛的实证调查，总计耗费了1440个GPU小时。我们分析了诸如词汇扩展、进一步预训练和指导调整等关键因素对转移的影响。为了准确评估模型的知识水平，我们采用了四个广泛使用的标准化测试基准：C-Eval、MMLU、AGI-Eval和GAOKAO-Bench。此外，我们还对模型的响应质量进行了全面评估，考虑了诸如...

    In recent times, substantial advancements have been witnessed in large language models (LLMs), exemplified by ChatGPT, showcasing remarkable proficiency across a range of complex tasks. However, many mainstream LLMs (e.g. LLaMA) are pretrained on English-dominant corpus, which limits their performance in other non-English languages. In this paper, we focus on how to effectively transfer the capabilities of language generation and following instructions to a non-English language. To answer this question, we conduct an extensive empirical investigation based on LLaMA, accumulating over 1440 GPU hours. We analyze the impact of key factors such as vocabulary extension, further pretraining, and instruction tuning on transfer. To accurately assess the model's level of knowledge, we employ four widely used standardized testing benchmarks: C-Eval, MMLU, AGI-Eval, and GAOKAO-Bench. Furthermore, a comprehensive evaluation of the model's response quality is conducted, considering aspects such as 
    
[^21]: Cheetah: 517种非洲语言的自然语言生成

    Cheetah: Natural Language Generation for 517 African Languages. (arXiv:2401.01053v1 [cs.CL])

    [http://arxiv.org/abs/2401.01053](http://arxiv.org/abs/2401.01053)

    Cheetah是一个面向517种非洲语言的大规模多语种自然语言生成模型，通过综合评估和人工评估，证明了其在生成连贯和上下文恰当的文本方面的卓越性能，并提供了促进语言多样性的解决方案。

    

    对于自然语言处理 (NLP) 任务来说，非洲语言资源稀缺是一个独特的挑战，包括自然语言生成 (NLG)。在本文中，我们开发了Cheetah，一个面向非洲语言的大规模多语种NLG语言模型。Cheetah支持517种非洲语言和语言变体，解决了NLG资源匮乏问题，并为促进语言多样性提供了解决方案。我们通过七个生成下游任务的综合评估证明了Cheetah的有效性。在七个任务中的五个任务中，Cheetah的表现显著优于其他模型，展示了其在广泛范围的非洲语言中生成连贯和上下文恰当的文本的卓越性能。我们还进行了详细的人工评估，以深入了解Cheetah的语言能力。Cheetah的引入对语言多样性具有深远的益处。通过利用预训练模型并将其适应特定的非洲语言，我们能够提供更多的语言生成选择和资源。

    Low-resource African languages pose unique challenges for natural language processing (NLP) tasks, including natural language generation (NLG). In this paper, we develop Cheetah, a massively multilingual NLG language model for African languages. Cheetah supports 517 African languages and language varieties, allowing us to address the scarcity of NLG resources and provide a solution to foster linguistic diversity. We demonstrate the effectiveness of Cheetah through comprehensive evaluations across seven generation downstream tasks. In five of the seven tasks, Cheetah significantly outperforms other models, showcasing its remarkable performance for generating coherent and contextually appropriate text in a wide range of African languages. We additionally conduct a detailed human evaluation to delve deeper into the linguistic capabilities of Cheetah. The introduction of Cheetah has far-reaching benefits for linguistic diversity. By leveraging pretrained models and adapting them to specifi
    
[^22]: Auffusion: 利用扩散和大型语言模型提升文本到音频生成的能力

    Auffusion: Leveraging the Power of Diffusion and Large Language Models for Text-to-Audio Generation. (arXiv:2401.01044v1 [cs.SD])

    [http://arxiv.org/abs/2401.01044](http://arxiv.org/abs/2401.01044)

    这篇论文介绍了一种名为Auffusion的文本到音频生成系统，它利用扩散和大型语言模型，通过跨模态对齐的能力，提高了生成质量和文本-音频对齐。该系统在有限的数据和计算资源下胜过了之前的方法，并关注了编码器选择对跨模态对齐的重要性。

    

    最近扩散模型和大型语言模型（LLM）的进展显著推动了AIGC领域的发展。文本到音频（TTA）作为一种新兴的AIGC应用，旨在从自然语言提示生成音频，引起了越来越多的关注。然而，现有的TTA研究往往在生成质量和文本-音频对齐方面存在困难，特别是对于复杂的文本输入。受到最先进的文本到图像（T2I）扩散模型的启发，我们介绍了Auffusion，一种将T2I模型框架适应TTA任务的系统，通过有效利用其固有的生成优势和精确的跨模态对齐能力。我们的客观和主观评估表明，Auffusion在使用有限的数据和计算资源时超越了之前的TTA方法。此外，之前的T2I研究认识到编码器选择对跨模态对齐的重要影响，例如细节和物体绑定，而类似的评估则缺乏。

    Recent advancements in diffusion models and large language models (LLMs) have significantly propelled the field of AIGC. Text-to-Audio (TTA), a burgeoning AIGC application designed to generate audio from natural language prompts, is attracting increasing attention. However, existing TTA studies often struggle with generation quality and text-audio alignment, especially for complex textual inputs. Drawing inspiration from state-of-the-art Text-to-Image (T2I) diffusion models, we introduce Auffusion, a TTA system adapting T2I model frameworks to TTA task, by effectively leveraging their inherent generative strengths and precise cross-modal alignment. Our objective and subjective evaluations demonstrate that Auffusion surpasses previous TTA approaches using limited data and computational resource. Furthermore, previous studies in T2I recognizes the significant impact of encoder choice on cross-modal alignment, like fine-grained details and object bindings, while similar evaluation is lack
    
[^23]: DocLLM: 一种面向布局感知的多模态文档理解生成语言模型

    DocLLM: A layout-aware generative language model for multimodal document understanding. (arXiv:2401.00908v1 [cs.CL])

    [http://arxiv.org/abs/2401.00908](http://arxiv.org/abs/2401.00908)

    本文提出了一种名为DocLLM的面向布局感知的多模态文档理解生成语言模型，通过结合文本语义和空间布局，避免了使用昂贵的图像编码器，提供了一种有效理解企业文档的方法。

    

    企业文档，如表单、发票、收据、报告、合同等记录，通常在文本和空间模态的交汇处具有丰富的语义。它们复杂的布局所提供的视觉线索在有效理解这些文档中起着至关重要的作用。在本文中，我们提出了DocLLM，一个针对视觉文档推理的轻量级扩展传统大型语言模型（LLMs），它考虑了文本语义和空间布局。我们的模型与现有的多模态LLMs不同，避免了昂贵的图像编码器，并且专注于利用边界框信息来融入空间布局结构。具体而言，我们通过将经典Transformer中的注意机制分解为一组解耦矩阵，来捕捉文本和空间模态之间的交叉对齐。此外，我们设计了一种预训练目标，用于学习填充文本片段。这种方法使我们能够处理不规则的布局情况。

    Enterprise documents such as forms, invoices, receipts, reports, contracts, and other similar records, often carry rich semantics at the intersection of textual and spatial modalities. The visual cues offered by their complex layouts play a crucial role in comprehending these documents effectively. In this paper, we present DocLLM, a lightweight extension to traditional large language models (LLMs) for reasoning over visual documents, taking into account both textual semantics and spatial layout. Our model differs from existing multimodal LLMs by avoiding expensive image encoders and focuses exclusively on bounding box information to incorporate the spatial layout structure. Specifically, the cross-alignment between text and spatial modalities is captured by decomposing the attention mechanism in classical transformers to a set of disentangled matrices. Furthermore, we devise a pre-training objective that learns to infill text segments. This approach allows us to address irregular layo
    
[^24]: LaFFi: 利用混合自然语言反馈来优化语言模型的微调

    LaFFi: Leveraging Hybrid Natural Language Feedback for Fine-tuning Language Models. (arXiv:2401.00907v1 [cs.LG])

    [http://arxiv.org/abs/2401.00907](http://arxiv.org/abs/2401.00907)

    LaFFi是一种用于微调语言模型的替代方法，通过要求模型预测标注者将会给出的反馈，显著提高了在问答任务中的准确性，为应用自然语言反馈提供了一个有前途的方向。

    

    大型语言模型（LLM）的微调可以将训练好的模型适应特定的下游任务，并显著提高任务特定性能。监督微调（SFT）是一种常见的方法，其中LLM被训练成产生期望的答案。然而，使用SFT训练的LLM在推理任务（如问答）中有时会出现简单错误和幻觉。在没有外部反馈的情况下，SFT很难学习到问题和期望答案之间的良好映射，特别是在数据集较小的情况下。本文介绍了一种名为自然语言反馈微调LLM（LaFFi）的替代方法。LaFFi要求LLM直接预测标注者将会给出的反馈。我们发现，这样的反思要求可以显著提高在领域内问答任务中的准确性，为在SFT LLM领域中应用自然语言反馈提供了一个有前途的方向。额外的消融研究表明这种方法的一部分可以被替代。

    Fine-tuning Large Language Models (LLMs) adapts a trained model to specific downstream tasks, significantly improving task-specific performance. Supervised Fine-Tuning (SFT) is a common approach, where an LLM is trained to produce desired answers. However, LLMs trained with SFT sometimes make simple mistakes and result in hallucinations on reasoning tasks such as question-answering. Without external feedback, it is difficult for SFT to learn a good mapping between the question and the desired answer, especially with a small dataset. This paper introduces an alternative to SFT called Natural Language Feedback for Finetuning LLMs (LaFFi). LaFFi has LLMs directly predict the feedback they will receive from an annotator. We find that requiring such reflection can significantly improve the accuracy in in-domain question-answering tasks, providing a promising direction for the application of natural language feedback in the realm of SFT LLMs. Additional ablation studies show that the portion
    
[^25]: LLM训练中的结构化填充改进了长上下文利用

    Structured Packing in LLM Training Improves Long Context Utilization. (arXiv:2312.17296v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.17296](http://arxiv.org/abs/2312.17296)

    本论文研究了长上下文大型语言模型（LLM）中上下文利用不足的问题，并通过将相关文档纳入训练示例中来改进模型的困惑度。通过引入Structured Packing for Long Context (SPLiCe)方法，使用检索方法将最互相关文档汇集到单个训练上下文中，进一步提高了模型的性能。

    

    长上下文大型语言模型（LCLM）的最新进展引起了广泛关注，特别是在查询科学研究论文等应用中。然而，它们的潜力往往受到上下文利用不足的限制。我们确定典型训练数据中缺乏长程语义依赖是主要障碍。为了解决这个问题，我们深入研究了频繁将相关文档纳入训练输入的好处。利用代码数据的固有目录结构作为训练示例的来源，我们证明了即使对于与编码无关的任务，囊括相关文档能够改进模型的困惑度。基于这些发现，并且更具广泛的关注，我们引入了一种名为Structured Packing for Long Context (SPLiCe)的创新方法。 SPLiCe是一种使用检索方法将最互相关文档汇集到单个训练上下文中的方法。我们的结果表明，\method{}提高了模型的性能，并可用于t

    Recent advances in long-context Large Language Models (LCLMs) have generated significant interest, especially in applications such as querying scientific research papers. However, their potential is often limited by inadequate context utilization. We identify the absence of long-range semantic dependencies in typical training data as a primary hindrance. To address this, we delve into the benefits of frequently incorporating related documents into training inputs. Using the inherent directory structure of code data as a source of training examples, we demonstrate improvements in perplexity, even for tasks unrelated to coding. Building on these findings, but with a broader focus, we introduce Structured Packing for Long Context (SPLiCe). SPLiCe is an innovative method for creating training examples by using a retrieval method to collate the most mutually relevant documents into a single training context. Our results indicate that \method{} enhances model performance and can be used to t
    
[^26]: 英语地名的语言渊源的随机分析

    A Stochastic Analysis of the Linguistic Provenance of English Place Names. (arXiv:2312.12850v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.12850](http://arxiv.org/abs/2312.12850)

    本文通过随机分析英国地名与其他国家地名的相似性，确定解释地名所使用的可能语言。

    

    在英语地名分析中，通常是通过地名的词根与地貌特征、专有名词和/或影响英语地名的语言中的居住地词汇相似来确定其含义。问题在于有时难以确定用于解释词根的基础语言。本文的目的是随机确定18799个英国地名与爱尔兰、苏格兰、威尔士、丹麦、挪威、瑞典、法国、德国、荷兰和古罗马的84687个地名之间的相似性。根据英国地名与其他国家地名的相似性程度，对每个英国地名进行排名，从而确定解释地名所使用的可能语言。通过提供的排名可以得出一些观察结果。特别地，发现`Harlington'是英国样本中最具典型英国地名，而`Anna'是...

    In English place name analysis, meanings are often derived from the resemblance of roots in place names to topographical features, proper names and/or habitation terms in one of the languages that have had an influence on English place names. The problem here is that it is sometimes difficult to determine the base language to use to interpret the roots. The purpose of this paper is to stochastically determine the resemblance between 18799 English place names and 84687 place names from Ireland, Scotland, Wales, Denmark, Norway, Sweden, France, Germany, the Netherlands and Ancient Rome. Each English place name is ranked according to the extent to which it resembles place names from the other countries, and this provides a basis for determining the likely language to use to interpret the place name. A number of observations can be made using the ranking provided. In particular, it is found that `Harlington' is the most archetypically English place name in the English sample, and `Anna' is
    
[^27]: StyleSinger: 针对领域外演唱声音合成的风格转移

    StyleSinger: Style Transfer for Out-of-Domain Singing Voice Synthesis. (arXiv:2312.10741v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2312.10741](http://arxiv.org/abs/2312.10741)

    StyleSinger是针对领域外演唱声音合成的风格转移模型，通过残差风格适配器（RSA）捕捉多样的风格特征实现高质量的合成演唱声音。

    

    针对领域外演唱声音合成（SVS）的风格转移专注于生成高质量的演唱声音，该声音具有从参考演唱声音样本中衍生的未见风格（如音色、情感、发音和发音技巧）。然而，模拟演唱声音风格的精细差异是一项艰巨的任务，因为演唱声音具有非常高的表现力。此外，现有的SVS方法在领域外场景中合成的演唱声音质量下降，因为它们基于训练阶段可辨别出目标声音属性的假设。为了克服这些挑战，我们提出了StyleSinger，这是第一个用于领域外参考演唱声音样本的零样式转移的演唱声音合成模型。StyleSinger采用了两种关键方法以提高效果：1）残差风格适配器（RSA），它使用残差量化模块来捕捉多样的风格特征。

    Style transfer for out-of-domain (OOD) singing voice synthesis (SVS) focuses on generating high-quality singing voices with unseen styles (such as timbre, emotion, pronunciation, and articulation skills) derived from reference singing voice samples. However, the endeavor to model the intricate nuances of singing voice styles is an arduous task, as singing voices possess a remarkable degree of expressiveness. Moreover, existing SVS methods encounter a decline in the quality of synthesized singing voices in OOD scenarios, as they rest upon the assumption that the target vocal attributes are discernible during the training phase. To overcome these challenges, we propose StyleSinger, the first singing voice synthesis model for zero-shot style transfer of out-of-domain reference singing voice samples. StyleSinger incorporates two critical approaches for enhanced effectiveness: 1) the Residual Style Adaptor (RSA) which employs a residual quantization module to capture diverse style character
    
[^28]: 论语言模型的水印可学习性研究

    On the Learnability of Watermarks for Language Models. (arXiv:2312.04469v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.04469](http://arxiv.org/abs/2312.04469)

    该论文研究了语言模型水印的可学习性，提出了水印蒸馏方法，通过训练学生模型使其模仿使用解码水印的教师模型的行为。结果表明，语言模型具有直接学习生成水印的能力，这对于水印的实际应用具有重要影响。

    

    语言模型输出的水印可以实现对模型生成文本的统计检测，广泛应用于语言模型的负责任部署中。现有的水印策略通过改变现有语言模型的解码器来操作，而语言模型直接学习生成水印的能力将对水印在实际应用中产生重要影响。首先，学习得到的水印可以用于构建能自然生成带水印文本的开放模型，使开放模型也能从水印中受益。其次，如果水印用于确定生成文本的来源，攻击者可以通过伪造水印并生成有害的带水印文本来损害受害模型的声誉。为了研究水印的可学习性，我们提出了水印蒸馏方法，该方法通过训练学生模型使其行为类似于使用基于解码的水印的教师模型。我们在三个实验数据集上测试了我们的方法。

    Watermarking of language model outputs enables statistical detection of model-generated text, which has many applications in the responsible deployment of language models. Existing watermarking strategies operate by altering the decoder of an existing language model, and the ability for a language model to directly learn to generate the watermark would have significant implications for the real-world deployment of watermarks. First, learned watermarks could be used to build open models that naturally generate watermarked text, allowing for open models to benefit from watermarking. Second, if watermarking is used to determine the provenance of generated text, an adversary can hurt the reputation of a victim model by spoofing its watermark and generating damaging watermarked text. To investigate the learnability of watermarks, we propose watermark distillation, which trains a student model to behave like a teacher model that uses decoding-based watermarking. We test our approach on three
    
[^29]: 关于上下文学习的校准研究

    A Study on the Calibration of In-context Learning. (arXiv:2312.04021v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.04021](http://arxiv.org/abs/2312.04021)

    本研究关注上下文学习（ICL），通过定制提示来调整静态语言模型（LMs），研究了在各种自然语言理解和推理任务中性能和校准之间的平衡。研究发现随着ICL示例数量的增加，模型的校准会先增加而后得到改善，而校准误差主要出现在低样本场景下。此外，微调和CoT提示等方法可能导致校准误差和不可靠的自然语言解释，提示需要针对可靠性场景开发新的方法。

    

    准确的不确定性量化对于语言模型（LMs）的安全部署至关重要，以前的研究已经证明了现代LMs校准性的改进。我们的研究重点是上下文学习（ICL），一种通过定制提示来调整静态LMs的常见方法，并研究在广泛的自然语言理解和推理任务中性能和校准之间的平衡。通过全面的实验，我们观察到，随着ICL示例数量的增加，模型最初会出现增加的校准误差，然后才能实现更好的校准，而校准误差往往在低样本场景下出现。此外，我们发现以提高可用性为目标的方法，如微调和CoT提示，可能导致校准误差和不可靠的自然语言解释，这表明在期望模型可靠性的场景中可能需要新的方法。

    Accurate uncertainty quantification is crucial for the safe deployment of language models (LMs), and prior research has demonstrated improvements in the calibration of modern LMs. Our study focuses on in-context learning (ICL), a prevalent method for adapting static LMs through tailored prompts, and examines the balance between performance and calibration across a broad spectrum of natural language understanding and reasoning tasks. Through comprehensive experiments, we observe that, with an increasing number of ICL examples, models initially exhibit increased miscalibration before achieving better calibration and miscalibration tends to arise in low-shot settings. Moreover, we find that methods aimed at improving usability, such as fine-tuning and chain-of-thought (CoT) prompting, can lead to miscalibration and unreliable natural language explanations, suggesting that new methods may be required for scenarios where models are expected to be reliable.
    
[^30]: 实时在线股票预测利用综合定量和定性分析

    Real-Time Online Stock Forecasting Utilizing Integrated Quantitative and Qualitative Analysis. (arXiv:2311.15218v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.15218](http://arxiv.org/abs/2311.15218)

    本研究提供了一个综合定量和定性分析的实时在线股票预测方法，通过提供一个包含了来自各种来源的数据集，将数字股票数据和定性文本数据结合起来进行分析。数据集包含了多个公司和道琼斯工业平均指数的数据，为训练提供了有效的数据基础。

    

    机器学习在金融领域的应用已经变得非常常见，尤其在股票市场预测中更是如此。股票市场高度波动，全球每分钟都会产生大量数据。从这些数据中提取有效的智能信息十分重要。然而，将数字股票数据与定性文本数据结合起来可能是一项具有挑战性的任务。在这项工作中，我们通过提供一个史无前例的公开可用数据集，从新闻档案、电视新闻字幕、广播文本、推文、每日财经报纸等处收集到了包括技术和基本数据以及情感数据。用于情感提取的文本数据总共超过140万条。该数据集包含从2018年1月到2022年12月为期一年的八家代表不同产业部门的公司的每日数据，以及道琼斯工业平均指数（DJIA）整体的数据。综合的基本数据和技术数据可直接用于训练。

    The application of Machine learning to finance has become a familiar approach, even more so in stock market forecasting. The stock market is highly volatile, and huge amounts of data are generated every minute globally. The extraction of effective intelligence from this data is of critical importance. However, a collaboration of numerical stock data with qualitative text data can be a challenging task. In this work, we accomplish this by providing an unprecedented, publicly available dataset with technical and fundamental data and sentiment that we gathered from news archives, TV news captions, radio transcripts, tweets, daily financial newspapers, etc. The text data entries used for sentiment extraction total more than 1.4 Million. The dataset consists of daily entries from January 2018 to December 2022 for eight companies representing diverse industrial sectors and the Dow Jones Industrial Average (DJIA) as a whole. Holistic Fundamental and Technical data is provided training ready f
    
[^31]: Jina Embeddings 2: 面向长篇文档的8192-Token通用文本嵌入模型

    Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents. (arXiv:2310.19923v1 [cs.CL])

    [http://arxiv.org/abs/2310.19923](http://arxiv.org/abs/2310.19923)

    Jina Embeddings 2是一个能够处理长篇文档的文本嵌入模型，突破了传统512个标记限制，提供了高达8192个标记的容量。

    

    文本嵌入模型已经成为将句子转化为固定大小特征向量的强大工具，这些向量包含了语义信息。尽管这些模型对于信息检索、语义聚类和文本重排序等任务至关重要，但大多数现有的开源模型，尤其是基于BERT等架构构建的模型，难以表示长篇文档，并且常常会进行截断。为了缓解这个挑战，一种常见的方法是将文档分割成更小的段落进行嵌入。然而，这种策略会导致更大的向量集合，进而增加内存消耗，并且在向量搜索时会出现计算密集和延迟升高的问题。为了解决这些挑战，我们介绍了Jina Embeddings 2，这是一个开源的文本嵌入模型，可以容纳高达8192个标记。该模型旨在突破传统的512个标记限制，能够灵活处理长篇文档。

    Text embedding models have emerged as powerful tools for transforming sentences into fixed-sized feature vectors that encapsulate semantic information. While these models are essential for tasks like information retrieval, semantic clustering, and text re-ranking, most existing open-source models, especially those built on architectures like BERT, struggle to represent lengthy documents and often resort to truncation. One common approach to mitigate this challenge involves splitting documents into smaller paragraphs for embedding. However, this strategy results in a much larger set of vectors, consequently leading to increased memory consumption and computationally intensive vector searches with elevated latency.  To address these challenges, we introduce Jina Embeddings 2, an open-source text embedding model capable of accommodating up to 8192 tokens. This model is designed to transcend the conventional 512-token limit and adeptly process long documents. Jina Embeddings 2 not only ach
    
[^32]: 大型搜索模型：重新定义LLM时代的搜索堆栈

    Large Search Model: Redefining Search Stack in the Era of LLMs. (arXiv:2310.14587v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2310.14587](http://arxiv.org/abs/2310.14587)

    本文介绍了一个称为大型搜索模型的框架，通过将所有搜索任务统一为一个大型语言模型(LLM)，重新定义了传统的搜索堆栈。这个框架利用了LLM的强大语言理解和推理能力，有潜力提高搜索结果的质量，同时简化现有的繁琐的搜索堆栈。

    

    现代搜索引擎是由不同组件构建的堆栈，包括查询理解、检索、多阶段排名和问答等。这些组件通常是独立优化和部署的。本文介绍了一个新的概念性框架，称为大型搜索模型，通过将所有任务统一为一个大型语言模型(LLM)来重新定义传统的搜索堆栈。所有任务都被表述为自回归文本生成问题，通过使用自然语言提示可以定制任务。这个提出的框架利用了LLM的强大语言理解和推理能力，有潜力提高搜索结果的质量，同时简化现有的繁琐的搜索堆栈。为了验证这个框架的可行性，我们展示了一系列概念验证实验，并讨论了实现这种方法所面临的潜在挑战。

    Modern search engines are built on a stack of different components, including query understanding, retrieval, multi-stage ranking, and question answering, among others. These components are often optimized and deployed independently. In this paper, we introduce a novel conceptual framework called large search model, which redefines the conventional search stack by unifying search tasks with one large language model (LLM). All tasks are formulated as autoregressive text generation problems, allowing for the customization of tasks through the use of natural language prompts. This proposed framework capitalizes on the strong language understanding and reasoning capabilities of LLMs, offering the potential to enhance search result quality while simultaneously simplifying the existing cumbersome search stack. To substantiate the feasibility of this framework, we present a series of proof-of-concept experiments and discuss the potential challenges associated with implementing this approach w
    
[^33]: 从挫折中获得智慧：通过错误分析对齐大型语言模型

    Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis. (arXiv:2310.10477v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.10477](http://arxiv.org/abs/2310.10477)

    该论文介绍了一种基于错误分析的对齐策略，通过暴露大型语言模型的错误输出并进行评估，以理解内部原因。通过这种方法，有毒回应可以转化为模型对齐的指导调谐语料，从而提高模型的安全性并训练其进行自我批评。

    

    大型语言模型（LLMs）的快速发展既带来了机遇，也带来了挑战，特别是在意外生成有害和有毒回应方面。传统的对齐方法致力于引导LLMs朝着期望的性能发展并保护它们免受恶意内容的侵害，而本研究提出了一种基于错误分析的全新对齐策略，通过有意暴露LLMs的缺陷输出并进行深入评估，以完全理解内部原因，通过自然语言分析。因此，有毒回应可以转化为模型对齐的指导调谐语料，LLMs不仅可以避免生成有缺陷的回应，还可以训练其进行自我批评，发挥其辨别有毒内容的内在能力。实验结果表明，所提出的方法在安全指令遵循方面优于传统的对齐技术，同时还保持了卓越的效率。

    The rapid advancement of large language models (LLMs) presents both opportunities and challenges, particularly concerning unintentional generation of harmful and toxic responses. While the traditional alignment methods strive to steer LLMs towards desired performance and shield them from malicious content, this study proposes a novel alignment strategy rooted in mistake analysis by exposing LLMs to flawed outputs purposefully and then conducting a thorough assessment to fully comprehend internal reasons via natural language analysis. Thus, toxic responses can be transformed into instruction tuning corpus for model alignment, and LLMs can not only be deterred from generating flawed responses but also trained to self-criticize, leveraging its innate ability to discriminate toxic content. Experimental results demonstrate that the proposed method outperforms conventional alignment techniques for safety instruction following, while maintaining superior efficiency.
    
[^34]: Reward-Augmented Decoding: 使用单向奖励模型实现高效的受控文本生成

    Reward-Augmented Decoding: Efficient Controlled Text Generation With a Unidirectional Reward Model. (arXiv:2310.09520v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.09520](http://arxiv.org/abs/2310.09520)

    该论文介绍了一种名为Reward-Augmented Decoding (RAD)的文本生成方法，使用小型的单向奖励模型来鼓励语言模型生成具有特定属性的文本。RAD在生成非有害和情感受控文本方面表现最佳，并且在非常大的语言模型上也很有效。

    

    尽管大型语言模型已经在许多应用中证明了其有效性，但它们通常生成的文本存在问题或者缺乏所需的属性。本文提出了一种名为Reward-Augmented Decoding (RAD)的文本生成方法，它利用一个小型的单向奖励模型来鼓励语言模型生成具有特定属性的文本。具体而言，RAD利用奖励模型对生成的文本进行评分，并通过重新调整采样概率来更倾向于高奖励的标记。通过使用单向奖励模型，RAD能够缓存先前生成步骤的激活值，降低计算开销。通过在生成非有害和情感受控文本方面的实验，我们证明RAD在仅改变生成过程的方法中表现最佳，并且与涉及重新训练语言模型的最先进方法相当。我们进一步验证了RAD在非常大的语言模型上的有效性。

    While large language models have proven effective in a huge range of downstream applications, they often generate text that is problematic or lacks a desired attribute. In this paper, we introduce Reward-Augmented Decoding (RAD), a text generation procedure that uses a small unidirectional reward model to encourage a language model to generate text that has certain properties. Specifically, RAD uses the reward model to score generations as they are produced and rescales sampling probabilities to favor high-reward tokens. By using a unidirectional reward model, RAD can cache activations from prior generation steps to decrease computational overhead. Through experiments on generating non-toxic and sentiment-controlled text, we demonstrate that RAD performs best among methods that change only the generation procedure and matches the performance of state-of-the-art methods that involve re-training the language model. We further validate that RAD is effective on very large language models w
    
[^35]: 剑桥法律语料库：用于法律人工智能研究的语料库

    The Cambridge Law Corpus: A Corpus for Legal AI Research. (arXiv:2309.12269v1 [cs.CL])

    [http://arxiv.org/abs/2309.12269](http://arxiv.org/abs/2309.12269)

    剑桥法律语料库是一个用于法律人工智能研究的语料库，包含来自英国的超过250,000个法庭案例。在该语料库的基础上，我们提供了案例结果的专家注解，并使用多个模型进行了案例结果提取的训练和评估，为研究提供了基准。

    

    我们介绍了剑桥法律语料库（CLC），这是一个用于法律人工智能研究的语料库。它包含了来自英国的超过250,000个法庭案例。大部分案例来自21世纪，但该语料库包括了16世纪以来的案例。本文介绍了该语料库的首次发布，包括原始文本和元数据。在语料库的基础上，我们提供了638个案例的法律专家对案例结果的注解。我们使用我们的标注数据，训练和评估了GPT-3、GPT-4和RoBERTa模型进行案例结果提取，以提供基准。我们还进行了广泛的法律和伦理讨论，以解决这些材料可能具有敏感性的问题。因此，该语料库只会在一定限制下用于研究目的。

    We introduce the Cambridge Law Corpus (CLC), a corpus for legal AI research. It consists of over 250 000 court cases from the UK. Most cases are from the 21st century, but the corpus includes cases as old as the 16th century. This paper presents the first release of the corpus, containing the raw text and meta-data. Together with the corpus, we provide annotations on case outcomes for 638 cases, done by legal experts. Using our annotated data, we have trained and evaluated case outcome extraction with GPT-3, GPT-4 and RoBERTa models to provide benchmarks. We include an extensive legal and ethical discussion to address the potentially sensitive nature of this material. As a consequence, the corpus will only be released for research purposes under certain restrictions.
    
[^36]: 多模态大语言模型在预测语言处理期间表现出人类视觉-语言集成的证据

    Evidence of Human-Like Visual-Linguistic Integration in Multimodal Large Language Models During Predictive Language Processing. (arXiv:2308.06035v1 [cs.AI])

    [http://arxiv.org/abs/2308.06035](http://arxiv.org/abs/2308.06035)

    这篇论文研究了多模态大语言模型（mLLMs）在预测语言处理过程中与人类的视觉-语言集成能力是否一致的问题，并通过实验验证了mLLMs的多模态输入方法可以减少认知负荷，提高感知和理解能力。

    

    大语言模型（LLMs）的先进语言处理能力引发了关于它们是否能够复制人类认知过程的争议。LLMs和人类在语言处理方面的一个区别在于，语言输入通常建立在多个知觉模态上，而大多数LLMs仅处理基于文本的信息。多模态基础使人类能够整合视觉背景与语言信息，从而对即将出现的单词的空间施加限制，减少认知负荷，提高感知和理解能力。最近的多模态LLMs（mLLMs）结合了视觉和语言嵌入空间，并使用变压器类型的注意机制进行下一个单词的预测。在多大程度上，基于多模态输入的预测语言处理在mLLMs和人类中吻合？为了回答这个问题，200名被试观看了短的视听剪辑，并估计了即将出现的动词或名词的可预测性。

    The advanced language processing abilities of large language models (LLMs) have stimulated debate over their capacity to replicate human-like cognitive processes. One differentiating factor between language processing in LLMs and humans is that language input is often grounded in more than one perceptual modality, whereas most LLMs process solely text-based information. Multimodal grounding allows humans to integrate - e.g. visual context with linguistic information and thereby place constraints on the space of upcoming words, reducing cognitive load and improving perception and comprehension. Recent multimodal LLMs (mLLMs) combine visual and linguistic embedding spaces with a transformer type attention mechanism for next-word prediction. To what extent does predictive language processing based on multimodal input align in mLLMs and humans? To answer this question, 200 human participants watched short audio-visual clips and estimated the predictability of an upcoming verb or noun. The 
    
[^37]: RS5M：用于遥感视觉-语言基础模型的大规模视觉-语言数据集

    RS5M: A Large Scale Vision-Language Dataset for Remote Sensing Vision-Language Foundation Model. (arXiv:2306.11300v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.11300](http://arxiv.org/abs/2306.11300)

    本文提出了一个新的框架RS5M，该框架包括领域基础模型（DFM），用于实现通用基础模型（GFM）和领域特定下游任务之间的转换。另外，还介绍了一个遥感领域的大规模图像-文本配对数据集RS5M，该数据集是通过过滤公开可用的图像-文本配对数据集并使用预训练的视觉-语言基础模型为标签数据集生成标题。

    

    利用大量图像-文本配对数据进行预训练的视觉-语言基础模型展示了前所未有的图像-文本关联能力，在各种下游任务中取得了显著的成果。关键挑战是如何利用已有的大规模预训练的视觉-语言基础模型，在域相关的下游任务中进行领域特定的迁移。本文提出了一个新的框架，包括领域基础模型（DFM），弥合了通用基础模型（GFM）和领域特定下游任务之间的差距。此外，我们还介绍了一个遥感领域（RS）的图像-文本配对数据集RS5M，其中包含了500万张带有英文描述的RS图像。该数据集是通过过滤公开可用的图像-文本配对数据集，并使用预训练的视觉-语言基础模型为仅带标签的RS数据集生成标题。这是第一个大规模的RS图像-文本配对数据集。

    Pre-trained Vision-Language Foundation Models utilizing extensive image-text paired data have demonstrated unprecedented image-text association capabilities, achieving remarkable results across various downstream tasks. A critical challenge is how to make use of existing large-scale pre-trained VLMs, which are trained on common objects, to perform the domain-specific transfer for accomplishing domain-related downstream tasks. In this paper, we propose a new framework that includes the Domain Foundation Model (DFM), bridging the gap between the General Foundation Model (GFM) and domain-specific downstream tasks. Moreover, we present an image-text paired dataset in the field of remote sensing (RS), RS5M, which has 5 million RS images with English descriptions. The dataset is obtained from filtering publicly available image-text paired datasets and captioning label-only RS datasets with pre-trained VLM. These constitute the first large-scale RS image-text paired dataset. Additionally, we 
    
[^38]: 语言模型是有限实用说话者

    Language Models are Bounded Pragmatic Speakers. (arXiv:2305.17760v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.17760](http://arxiv.org/abs/2305.17760)

    本文提出了一个概率认知模型，称为有限实用说话者，用于表征不同变体的语言模型的操作方式。经过人类反馈的强化学习微调的大型语言模型具有概念上类似于 快与慢思考模型的思维模型，而这种思维模型被归因于人类。此研究凸显了采用认知概率建模方法对语言模型的理解、评估和推进的价值。

    

    本文提出了一个概率认知模型，称为有限实用说话者，用于表征不同变体的语言模型的操作方式。特别地，我们展示了经过人类反馈的强化学习微调的大型语言模型（Ouyang等人，2022）具有概念上类似于 快与慢思考模型（Kahneman，2011）的思维模型，而这种思维模型被心理学家们归因于人类。我们讨论了从人类反馈中的强化学习作为快与慢思考模型的局限性，并提出了扩展这个框架的途径。本研究实质上凸显了采用认知概率建模方法来获得对语言模型的理解、评估和推进方面的深刻见解的价值。

    How do language models "think"? This paper formulates a probabilistic cognitive model called the bounded pragmatic speaker, which can characterize the operation of different variations of language models. Specifically, we demonstrate that large language models fine-tuned with reinforcement learning from human feedback (Ouyang et al., 2022) embody a model of thought that conceptually resembles a fast-and-slow model (Kahneman, 2011), which psychologists have attributed to humans. We discuss the limitations of reinforcement learning from human feedback as a fast-and-slow model of thought and propose avenues for expanding this framework. In essence, our research highlights the value of adopting a cognitive probabilistic modeling approach to gain insights into the comprehension, evaluation, and advancement of language models.
    
[^39]: ArtGPT-4: 基于适配器增强的MiniGPT-4模型的艺术视觉语言理解

    ArtGPT-4: Artistic Vision-Language Understanding with Adapter-enhanced MiniGPT-4. (arXiv:2305.07490v1 [cs.CL])

    [http://arxiv.org/abs/2305.07490](http://arxiv.org/abs/2305.07490)

    ArtGPT-4是一种基于适配器增强的MiniGPT-4模型，专注于解决图像理解方面的问题，能够在短时间内训练出具备良好视觉语言理解能力的多模态模型。

    

    近年来，大型语言模型在自然语言处理领域取得了显著进展，比如ChatGPT和GPT-4等模型在多种语言任务上取得了惊人的能力。但是，对这样的大规模模型进行训练是具有挑战性的，而找到与模型规模匹配的数据集通常也很困难。微调和使用新方法训练参数较少的模型已经成为克服这些挑战的有效方法。MiniGPT-4模型便是其中之一，该模型通过运用新颖的预训练模型和革新性的培训策略实现了与GPT-4相当的视觉语言理解能力。但是，该模型在图像理解方面仍然面临一些挑战，特别是在艺术图片方面。ArtGPT-4是一种新型的多模态模型，旨在应对这些局限。ArtGPT-4使用Tesla A100设备对图像-文本对进行训练，仅用了约200GB的数据，在2小时内就能展示出图像。

    In recent years, large language models (LLMs) have made significant progress in natural language processing (NLP), with models like ChatGPT and GPT-4 achieving impressive capabilities in various linguistic tasks. However, training models on such a large scale is challenging, and finding datasets that match the model's scale is often difficult. Fine-tuning and training models with fewer parameters using novel methods have emerged as promising approaches to overcome these challenges. One such model is MiniGPT-4, which achieves comparable vision-language understanding to GPT-4 by leveraging novel pre-training models and innovative training strategies. However, the model still faces some challenges in image understanding, particularly in artistic pictures. A novel multimodal model called ArtGPT-4 has been proposed to address these limitations. ArtGPT-4 was trained on image-text pairs using a Tesla A100 device in just 2 hours, using only about 200 GB of data. The model can depict images wit
    
[^40]: 音乐结构的自组织网络分析

    In-depth analysis of music structure as a self-organized network. (arXiv:2303.13631v1 [cs.SD])

    [http://arxiv.org/abs/2303.13631](http://arxiv.org/abs/2303.13631)

    本文介绍了一种利用Essential Element Network (EEN)算法将音频编码成文本并进行相关性计算和优化应用于聚类系数的频率和排名的方法，得到了音乐的深层结构信息，为厘清音乐结构提供了新方法。

    

    自然语言中的词汇不仅传递信息，还随着文明和人类迁移而演变。音乐也是如此。为了理解音乐背后的复杂结构，我们引入了一个叫做Essential Element Network (EEN)的算法将音频编码成文本。该网络通过计算音调、时间和音量之间的相关性得到，通过优化EEN算法以生成Zipf定律应用于聚类系数的频率和排名，我们可以将语义关系视为词汇并生成它们的映射。我们将这些编码后的词汇映射到音调-时间空间中，有助于我们系统地组织音乐深层结构中的句法。相比于其他深度学习方法的黑盒子特性，我们的算法提供了对音乐背后复杂网络的精确描述。因此，这些过程积累的经验和属性不仅为此类应用提供了新的方法，同时也为许多其他相关领域的研究提供了探索的路径。

    Words in a natural language not only transmit information but also evolve with the development of civilization and human migration. The same is true for music. To understand the complex structure behind the music, we introduced an algorithm called the Essential Element Network (EEN) to encode the audio into text. The network is obtained by calculating the correlations between scales, time, and volume. Optimizing EEN to generate Zipfs law for the frequency and rank of the clustering coefficient enables us to generate and regard the semantic relationships as words. We map these encoded words into the scale-temporal space, which helps us organize systematically the syntax in the deep structure of music. Our algorithm provides precise descriptions of the complex network behind the music, as opposed to the black-box nature of other deep learning approaches. As a result, the experience and properties accumulated through these processes can offer not only a new approach to the applications of
    

