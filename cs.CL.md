# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Enhanced Chart Understanding in Vision and Language Task via Cross-modal Pre-training on Plot Table Pairs.](http://arxiv.org/abs/2305.18641) | 该论文介绍了一个名为ChartT5的V+L模型，它通过对绘图表对进行跨模态预训练，学习如何解释来自图表图像的表格信息，并在图表问答任务中表现出8%以上的性能提升。 |
| [^2] | [Short Answer Grading Using One-shot Prompting and Text Similarity Scoring Model.](http://arxiv.org/abs/2305.18638) | 本文提出了一种自动化的短回答评分（ASAG）模型，使用基于大型语言模型的一次提示和文本相似度评分模型，可以提供分析得分和最终整体得分，并使用小规模手动注释的数据集进行领域适应，取得了显著的改进。 |
| [^3] | [W-procer: Weighted Prototypical Contrastive Learning for Medical Few-Shot Named Entity Recognition.](http://arxiv.org/abs/2305.18624) | W-procer是一种基于加权原型对比学习的医学少样本命名实体识别方法，在构建基于原型的对比损失和加权网络方面具有创新性，优于现有的最先进方法。 |
| [^4] | [Alfred: A System for Prompted Weak Supervision.](http://arxiv.org/abs/2305.18623) | Alfred是一个系统，通过提示创建机器学习训练数据，而不是由专家编写的程序式弱监督(PWS)系统，用户可以通过自然语言提示为语言和视觉-语言模型编写主题专业知识。Alfred为这种新兴范式的关键步骤提供简单的Python接口，具有大规模数据标注的高吞吐量后端。 |
| [^5] | [CONA: A novel CONtext-Aware instruction paradigm for communication using large language model.](http://arxiv.org/abs/2305.18620) | CONA是一种基于上下文的指令范式，利用大型语言模型，自动优化演示内容并提供上下文感知型答案，具有较高的上下文感知性和易理解性。 |
| [^6] | [Likelihood-Based Diffusion Language Models.](http://arxiv.org/abs/2305.18619) | 本论文介绍了基于似然的扩散语言模型，并通过算法改进、缩放定律和增加计算，成功构建和发布了一个超过小但广为人知的自回归模型的扩散模型，优于GPT-2 124M。 |
| [^7] | [Chatbots put to the test in math and logic problems: A preliminary comparison and assessment of ChatGPT-3.5, ChatGPT-4, and Google Bard.](http://arxiv.org/abs/2305.18618) | 本文比较了三种基于大型语言模型的聊天机器人(ChatGPT-3.5、ChatGPT-4和Google Bard)在解决数学和逻辑问题上的正确性，研究发现这些机器人可以在某些情况下给出正确答案，但在更复杂的问题中需要改进。 |
| [^8] | [From `Snippet-lects' to Doculects and Dialects: Leveraging Neural Representations of Speech for Placing Audio Signals in a Language Landscape.](http://arxiv.org/abs/2305.18602) | 本文利用XSLR-53神经表示来估计音频文件之间的接近程度，最终旨在提取相关的语言属性。在11种方言的数据中，可为一种很少资源或完全未知的语言获得总体语音/语音学接近度估计。 |
| [^9] | [Improving Generalization for Multimodal Fake News Detection.](http://arxiv.org/abs/2305.18599) | 本研究提出了三种模型，采用和微调最先进的多模态Transformer进行多模态假新闻检测，并提出了训练数据增强来提高模型泛化能力。 |
| [^10] | [A Method for Studying Semantic Construal in Grammatical Constructions with Interpretable Contextual Embedding Spaces.](http://arxiv.org/abs/2305.18598) | 本文介绍了一种使用大型语言模型研究语法结构中的语义表达的方法，首先将上下文单词嵌入投射到三个可解释的语义空间中，然后使用这些空间自动派生出在语法结构中的词汇项目的语义表述，我们发现主语位置中的单词被解释为比同样的宾语位置中的单词更具代理性，并且AANN结构中的名词被解释为比传统转换中的名词更具测量属性。 |
| [^11] | [Exploiting Explainability to Design Adversarial Attacks and Evaluate Attack Resilience in Hate-Speech Detection Models.](http://arxiv.org/abs/2305.18585) | 本文结合可解释性和对抗攻击两个关键方面，研究了仇恨言论检测模型的鲁棒性，并提出了针对性的对抗攻击，对该领域的未来研究具有重要的意义。 |
| [^12] | [TreeMAN: Tree-enhanced Multimodal Attention Network for ICD Coding.](http://arxiv.org/abs/2305.18576) | 提出了TreeMAN模型，该模型通过使用基于树的特征增强文本表示，将表格特征和文本特征融合为多模态表示以更准确地预测ICD代码。 |
| [^13] | [Fairness of ChatGPT.](http://arxiv.org/abs/2305.18569) | 本文提供了一个使用ChatGPT作为研究案例的LLM有效性和公平性的系统评估，旨在评估ChatGPT在高风险领域的表现，以提供更深入的了解LLM的公平表现，并为偏见缓解和负责任的人工智能系统的发展做出贡献。 |
| [^14] | [PaLI-X: On Scaling up a Multilingual Vision and Language Model.](http://arxiv.org/abs/2305.18565) | 论文介绍了一个多语言视觉与语言模型PaLI-X，通过扩展模型组件和训练任务范围，实现了在复杂任务上的新性能水平，包括图像字幕问答、对象检测、视频问答和视频字幕等，同时在视觉语言基准测试中取得了最新的研究成果。 |
| [^15] | [Forgotten Knowledge: Examining the Citational Amnesia in NLP.](http://arxiv.org/abs/2305.18554) | 本文系统地和实证地考察了自然语言处理(NLP)领域内的引文模式，证明了大约62%的引用论文属于出版前五年，只有约17%的论文超过十年。目前，NLP论文的引用年龄趋于历史最低水平，这个趋势与此前相反。 |
| [^16] | [SlimFit: Memory-Efficient Fine-Tuning of Transformer-based Models Using Training Dynamics.](http://arxiv.org/abs/2305.18513) | SlimFit是一个新工具，通过动态分析模型的训练动态并在微调过程中冻结不影响性能的层，将基于Transformer模型的内存占用降低了5倍，而不影响性能。 |
| [^17] | [Code Prompting: a Neural Symbolic Method for Complex Reasoning in Large Language Models.](http://arxiv.org/abs/2305.18507) | 本文介绍了一种神经符号提示方法——代码提示，该方法可以触发代码作为中间步骤。与自然语言相比，代码提示有着几个独特优势，能够提高符号推理和算术推理的性能，并且通常优于思路链提示。 |
| [^18] | [From Adversarial Arms Race to Model-centric Evaluation: Motivating a Unified Automatic Robustness Evaluation Framework.](http://arxiv.org/abs/2305.18503) | 本文旨在建立一个统一的自动鲁棒性评估框架，向以模型为中心的评估转型，利用对抗攻击的优势。研究者们根据模型能力确定鲁棒性评估维度，并针对每个维度指定合理的算法来生成对抗样本。 |
| [^19] | [VAST: A Vision-Audio-Subtitle-Text Omni-Modality Foundation Model and Dataset.](http://arxiv.org/abs/2305.18500) | 本文提出了一种全模态视频文本基础模型VAST及其数据集VAST-27M。该模型可以感知和处理视频中的视觉、音频和字幕模态，通过自动集成多模态字幕和资源，提供更好的支持文本关联的多种任务。 |
| [^20] | [ANPL: Compiling Natural Programs with Interactive Decomposition.](http://arxiv.org/abs/2305.18498) | ANPL是一个编程系统，可以让用户直接操作草图，使用自然语言描述注释模块或孔，并生成一个有机的Python程序，它优于基线。 |
| [^21] | [A Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark Datasets.](http://arxiv.org/abs/2305.18486) | 本文对基准数据集上 ChatGPT 的性能进行了全面的评估，包括问答、文本摘要、代码生成、常识推理、数学问题求解、机器翻译、偏见检测和伦理考虑等任务。研究旨在验证 ChatGPT 的优势和弱点，并为使用语言模型的未来研究提供见解。 |
| [^22] | [Test-Time Training on Nearest Neighbors for Large Language Models.](http://arxiv.org/abs/2305.18466) | 该论文提出了一种基于最近邻的测试时间训练方法，通过检索和微调少量邻居的文本数据，该方法在大语言模型上显著提高了性能。 |
| [^23] | [Membership Inference Attacks against Language Models via Neighbourhood Comparison.](http://arxiv.org/abs/2305.18462) | 本文提出两种新的基于邻域比较的攻击策略，利用语言数据的内在结构来提高成员推断攻击的性能，并在几个公开数据集上证明这些攻击的有效性。 |
| [^24] | [Taming AI Bots: Controllability of Neural States in Large Language Models.](http://arxiv.org/abs/2305.18449) | 本文提出了一个问题，是否可以通过适当选择提示，控制AI bot到达任何状态，而研究表明训练良好的Bot能几乎确定地到达任何意义子集，具有可控性。 |
| [^25] | [Semantic Segmentation with Bidirectional Language Models Improves Long-form ASR.](http://arxiv.org/abs/2305.18419) | 本研究提出一种采用双向语言模型进行语义分割的方法，可以有效提高长篇音频识别的准确性和速度。 |
| [^26] | [Understanding Breast Cancer Survival: Using Causality and Language Models on Multi-omics Data.](http://arxiv.org/abs/2305.18410) | 本文旨在探究多组学数据在因果推断、基因组学和乳腺癌中的应用，利用大规模语言模型辅助解决因果推断方法的评估问题，突出了如何利用因果关系分析基因组扰动对乳腺癌患者生存的影响。 |
| [^27] | [Conformal Prediction with Large Language Models for Multi-Choice Question Answering.](http://arxiv.org/abs/2305.18404) | 本研究探讨了如何利用符合性预测技术，在多项选择题回答任务中为语言模型提供不确定性量化。我们发现符合性预测的不确定性估计与预测准确性密切相关。 |
| [^28] | [LLMs Can Understand Encrypted Prompt: Towards Privacy-Computing Friendly Transformers.](http://arxiv.org/abs/2305.18396) | 本文中，研究人员通过使用隐私计算友好的近似方法替换transformer架构中计算和通信密集的运算符，实现了大幅降低私有推断成本的效果，并在保持准确性的前提下实现了计算加速和通信开销降低。 |
| [^29] | [Knowledge-Augmented Reasoning Distillation for Small Language Models in Knowledge-Intensive Tasks.](http://arxiv.org/abs/2305.18395) | 本论文提出了一种KARD方法，可以通过向小型语言模型中加入从外部知识库检索到的增强知识来解决知识密集型推理任务中小型语言模型记忆能力有限的问题。 |
| [^30] | [MemeGraphs: Linking Memes to Knowledge Graphs.](http://arxiv.org/abs/2305.18391) | 该论文提出了一种使用场景图和知识图谱结构化表达网络文化表情包的方法，并将其用于分类。结果显示该方法相比使用学习表达式的模型有所改善。 |
| [^31] | [Emergent Modularity in Pre-trained Transformers.](http://arxiv.org/abs/2305.18390) | 本论文研究了预训练Transformers中的自发模块化现象，发现神经元可以进行功能专业化，并通过聚类建立起模块化结构，此结构可被有效扰动。 |
| [^32] | [KAFA: Rethinking Image Ad Understanding with Knowledge-Augmented Feature Adaptation of Vision-Language Models.](http://arxiv.org/abs/2305.18373) | 本文是第一篇通过预训练的VLMs实证研究图像广告理解的文章。我们提出了一种基于知识增强特征自适应的策略，有效地融合了图像广告的多模态信息，并通过真实世界实体的知识进一步增强了模型。研究对广告行业具有广泛的相关性。 |
| [^33] | [What indeed can GPT models do in chemistry? A comprehensive benchmark on eight tasks.](http://arxiv.org/abs/2305.18365) | 本文建立了包括 8 个实际化学任务的综合基准测试，有力地证明了 LLM 在实际化学中的能力。 |
| [^34] | [DeepSI: Interactive Deep Learning for Semantic Interaction.](http://arxiv.org/abs/2305.18357) | 本文提出了一种基于语义交互的交互式深度学习方法，可以高效地学习用户和任务特定的数据表示，改善视觉分析应用中的语义交互，并通过比较验证了该方法的优势。 |
| [^35] | [LLMs and the Abstraction and Reasoning Corpus: Successes, Failures, and the Importance of Object-based Representations.](http://arxiv.org/abs/2305.18354) | 本文通过分析GPT模型在抽象推理语料库上的表现，发现GPT在抽象推理任务中存在需要核心概念“核心知识”的限制。通过使用基于对象的表示方法和新的1D-ARC基准，GPT在抽象推理任务中取得了较好的表现。 |
| [^36] | [Towards Open-World Product Attribute Mining: A Lightly-Supervised Approach.](http://arxiv.org/abs/2305.18350) | 该研究提出了一种用于电子商务产品属性挖掘的新任务设置，可以利用高质量的种子属性集合轻度监督并自动发现新的属性类型。通过自我监督启发式和无监督潜在属性，该方法能够以额外的隐含语义信号作为辅助监督，将现有类型的属性扩展最多12倍，并成功发掘了39％的新属性值。 |
| [^37] | [Neural Task Synthesis for Visual Programming.](http://arxiv.org/abs/2305.18342) | 该论文提出了一种基于神经符号技术的可视化编程任务合成方法NeurTaskSyn。该方法能够针对规范中给出的解决方案代码所需要的编程概念和对可视化任务的限制，自动生成编程任务。 |
| [^38] | [Mapping ChatGPT in Mainstream Media: Early Quantitative Insights through Sentiment Analysis and Word Frequency Analysis.](http://arxiv.org/abs/2305.18340) | 本文量化分析了主流媒体对ChatGPT和人工智能的报道趋势和情感态度，发现人们普遍对其持积极态度。然而，主题的词频分析显示，大型科技问题和行为者得到了高度关注，而就业、多样性、伦理、版权、性别和女性等主题则表现不足或完全缺失。本文呼吁在人工智能领域需要更加多元和细致的媒体发言。 |
| [^39] | [A Survey on ChatGPT: AI-Generated Contents, Challenges, and Solutions.](http://arxiv.org/abs/2305.18339) | 本论文探讨了AI生成内容的工作原理、安全与隐私威胁、现状和未来挑战，并提供了针对这些问题的最新解决方案。 |
| [^40] | [#REVAL: a semantic evaluation framework for hashtag recommendation.](http://arxiv.org/abs/2305.18330) | #REVAL是一种新颖的语义评估框架，用于解决传统评估方法无法考虑推荐和实际hashtag之间语义相关性问题。实验证明#REVAL在捕捉语义相关性方面是有效的。 |
| [^41] | [Regex-augmented Domain Transfer Topic Classification based on a Pre-trained Language Model: An application in Financial Domain.](http://arxiv.org/abs/2305.18324) | 本文介绍了将正则表达式模式作为领域知识特征与领域特定文本一起用于微调预训练语言模型的方法，通过在金融领域中实验，证明这种方法可以改善下游文本分类任务的表现。 |
| [^42] | [ReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models.](http://arxiv.org/abs/2305.18323) | ReWOO是一种将推理过程与外部观察分离的模块化范式，从而可以减少标记消耗并提高性能。 |
| [^43] | [REFinD: Relation Extraction Financial Dataset.](http://arxiv.org/abs/2305.18322) | REFinD是第一个完全基于金融文档生成的关系注释的大规模数据集，并对其进行了评估，显示出在金融领域进行关系抽取的特定挑战。 |
| [^44] | [Cognitive network science reveals bias in GPT-3, ChatGPT, and GPT-4 mirroring math anxiety in high-school students.](http://arxiv.org/abs/2305.18320) | 本研究通过行为forma mentis网络(BFMNs)的方法研究了先进的语言模型(GPT-3，Chat-GPT和GPT-4)对数学和STEM领域的偏见，并发现它们都倾向于将数学和STEM领域视为困难、紧张和引起焦虑。 |
| [^45] | [Automated Feedback Generation for a Chemistry Database and Abstracting Exercise.](http://arxiv.org/abs/2305.18319) | 本研究利用BERT模型，对化学数据库中摘要练习的答案结构进行反馈，该模型在学生提交的句子中将其归为三类，即背景、技术和观察，提供了一种方法对学生作业进行自动化反馈。 |
| [^46] | [CDJUR-BR -- A Golden Collection of Legal Document from Brazilian Justice with Fine-Grained Named Entities.](http://arxiv.org/abs/2305.18315) | CDJUR-BR是一份稳健的黄金收藏，包含巴西司法文件中的精细命名实体，该收藏涵盖各种法律程序文件，并有助于解决目前命名实体识别（NER）无法轻而易举地识别法律实践文本中实体的问题。 |
| [^47] | [Semantic-aware Digital Twin for Metaverse: A Comprehensive Review.](http://arxiv.org/abs/2305.18304) | 本文综述了数字孪生体在元宇宙中的部署，并介绍了通过语义通信实现数字孪生体与元宇宙结合的框架，以及其在智能工业应用中的基本原理和性能优化的实现。 |
| [^48] | [Do Large Language Models Know What They Don't Know?.](http://arxiv.org/abs/2305.18153) | 本文研究大型语言模型（LLM）的自我认知能力，基于无法回答或不可知问题对它们进行评估，发现LLM在认识自身限制方面存在显著差异。 |
| [^49] | [KoSBi: A Dataset for Mitigating Social Bias Risks Towards Safer Large Language Model Application.](http://arxiv.org/abs/2305.17701) | KoSBi是一个新的社会偏见数据集，通过基于过滤的中介处理，可以将生成内容中的社会偏差平均降低16.47%p，适用于韩国语言文化背景的大型语言模型应用程序。 |
| [^50] | [Learning from Children: Improving Image-Caption Pretraining via Curriculum.](http://arxiv.org/abs/2305.17540) | 本研究借鉴孩子语言学习的方法，提出了一种课程学习框架，通过逐渐增加新概念的对齐来改进图像字幕预训练，提高其在各种下游视觉任务中的表现。 |
| [^51] | [A Match Made in Heaven: A Multi-task Framework for Hyperbole and Metaphor Detection.](http://arxiv.org/abs/2305.17480) | 本研究提出了一个多任务深度学习框架，同时检测夸张和隐喻。使用隐喻标签注释了两个夸张数据集，使用夸张标签注释了两个隐喻数据集，实验证明该框架检测夸张的性能比先前方法进步了12%。此外，多任务学习方法比单任务学习方法提高了多达17%。 |
| [^52] | [Improving accuracy of GPT-3/4 results on biomedical data using a retrieval-augmented language model.](http://arxiv.org/abs/2305.17116) | 本研究使用Retrieval Augmentation（RetA）方法，对比了OpenAI的GPT-3、GPT-4、Bing的Prometheus以及定制的RetA模型在回答19个弥漫大B细胞淋巴瘤（DLBCL）疾病相关问题方面的表现，结果显示RetA模型在准确性和相关性方面表现最佳。 |
| [^53] | [Evaluating Open-Domain Dialogues in Latent Space with Next Sentence Prediction and Mutual Information.](http://arxiv.org/abs/2305.16967) | 本文提出了一种新的基于学习的自动评估度量方法（CMN），能够通过将条件变分自编码器（CVAEs）与下一句预测（NSP）目标相结合，并利用互信息（MI）在潜空间中建模文本的语义相似度，来鲁棒地评估开放域对话，并在实验中取得了优异的结果。 |
| [^54] | [Few-shot Fine-tuning vs. In-context Learning: A Fair Comparison and Evaluation.](http://arxiv.org/abs/2305.16938) | 本文比较了少样本微调和上下文学习在控制模型大小、样本数量和参数数量的情况下对挑战性数据集的泛化能力，结果表明少样本微调在某些复杂的推理和组合性任务中比上下文学习效果更好。 |
| [^55] | [GenQ: Automated Question Generation to Support Caregivers While Reading Stories with Children.](http://arxiv.org/abs/2305.16809) | 本研究设计了一个智能辅导系统（GenQ），可以根据照顾者和孩子之间的对话促进孩子的阅读理解能力，并通过考虑文化背景和语境变化以提高系统效果。 |
| [^56] | [Do GPTs Produce Less Literal Translations?.](http://arxiv.org/abs/2305.16806) | 本研究比较了GPT和NMT生成翻译的文字积极度差异，发现GPT翻译更不准确，但在MT质量评估指标上表现出相似或更好的分数。 |
| [^57] | [Leveraging Domain Knowledge for Inclusive and Bias-aware Humanitarian Response Entry Classification.](http://arxiv.org/abs/2305.16756) | 本研究提出了一种以人道主义本体为基础的新型语言模型HumBert，并提供了一种系统的方法来衡量和减少偏见，以实现对人道主义数据分析的有效和道德意识的支持。 |
| [^58] | [Scaling Data-Constrained Language Models.](http://arxiv.org/abs/2305.16264) | 研究人员研究了在数据受限制的情况下缩放语言模型，并提出了一个计算最优性的缩放定律，考虑到重复令牌和过量参数的价值递减。 |
| [^59] | [Visually grounded few-shot word acquisition with fewer shots.](http://arxiv.org/abs/2305.15937) | 该论文提出了一种基于视觉的语音模型，可以从仅有少量的词-图像示例对中习得新的词汇及其视觉表示，并且与现有方法相比，该模型在使用更少的样本时取得了更好的性能。 |
| [^60] | [From Characters to Words: Hierarchical Pre-trained Language Model for Open-vocabulary Language Understanding.](http://arxiv.org/abs/2305.14571) | 本文提出了一种新颖的开放词汇语言模型，它采用了分层两级方法和浅层Transformer体系结构从字符中学习单词，能够提高模型的容忍度和适应性。 |
| [^61] | [BA-SOT: Boundary-Aware Serialized Output Training for Multi-Talker ASR.](http://arxiv.org/abs/2305.13716) | BA-SOT是一种面向多说话人ASR的训练方法，通过边界感知和连接时间分类策略，显著提高了模型的准确性和精度。 |
| [^62] | [EntRED: Benchmarking Relation Extraction with Fewer Shortcuts.](http://arxiv.org/abs/2305.13551) | 本研究提出了一个名称更为多样、没有捷径、具有挑战性的关系提取基准测试EntRed，并解决了标准基准测试数据集存在的实体注释错误、实体名称多样性较低、从实体名称到基本事实关系的捷径等问题。 |
| [^63] | [Debiased Automatic Speech Recognition for Dysarthric Speech via Sample Reweighting with Sample Affinity Test.](http://arxiv.org/abs/2305.13108) | 本文提出了一种样本重新加权与样本关联测试（Re-SAT）的新方法，用于缓解失语症患者的偏差问题，在不影响健康患者语音的ASR性能的情况下，有效提高了ASR的性能表现。 |
| [^64] | [Iterative Forward Tuning Boosts In-context Learning in Language Models.](http://arxiv.org/abs/2305.13016) | 本文提出了一种两阶段框架来提高LLMs中ICL的性能，它将ICL过程分为“深思熟虑”和推理阶段。在“深思熟虑”阶段中，通过多次迭代优化示范，并操纵Transformer中的自我注意模块中的Key-Value矩阵来生成元梯度，从而期望在测试时提高LLM的推理能力。 |
| [^65] | [Empower Large Language Model to Perform Better on Industrial Domain-Specific Question Answering.](http://arxiv.org/abs/2305.11541) | 本文提供了一个行业云特定QA数据集 MSQA，该数据集可用于评估旨在提高大规模语言模型特定领域能力的方法。本文还提出了一种新的模型交互范式，可以使大规模语言模型在其不擅长的特定任务上取得更好的性能。 |
| [^66] | [Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark.](http://arxiv.org/abs/2305.10036) | 提出了一种名为 EmbMarker 的嵌入式水印方法，用于保护大型语言模型在 EaaS 中的版权。该方法可以在嵌入式上植入后门，并有效地传输和恢复。实验证明，EmbMarker 可以在维护各种 NLP 任务的性能的同时成功保护 EaaS 对 LLM 的版权。 |
| [^67] | ["I'm fully who I am": Towards Centering Transgender and Non-Binary Voices to Measure Biases in Open Language Generation.](http://arxiv.org/abs/2305.09941) | 本论文研究了如何以TGNB人群的声音为中心，评估开放式语言生成中的偏见。通过理解TGNB个体的经历，提出了以TGNB人群为中心的OLG系统评估框架，并且包括一个为TGNB人群设计的调查工具和分析方法。 |
| [^68] | [Analysis of Visual Question Answering Algorithms with attention model.](http://arxiv.org/abs/2305.09782) | 本文批评性地检查和审查了使用共同注意力方法的VQA算法的方法，重点关注文本语义生成、对象识别和答案分类技术。 |
| [^69] | [Document Understanding Dataset and Evaluation (DUDE).](http://arxiv.org/abs/2305.08455) | DUDE推出了一个新的数据集和评估方法，旨在创造一个更实际的基准测试并推动当前方法的边界，以更准确地模拟真实世界的情况 |
| [^70] | [ArtGPT-4: Artistic Vision-Language Understanding with Adapter-enhanced MiniGPT-4.](http://arxiv.org/abs/2305.07490) | ArtGPT-4是一种基于适配器增强的MiniGPT-4模型，专注于解决图像理解方面的问题，能够在短时间内训练出具备良好视觉语言理解能力的多模态模型。 |
| [^71] | [Prompt Learning to Mitigate Catastrophic Forgetting in Cross-lingual Transfer for Open-domain Dialogue Generation.](http://arxiv.org/abs/2305.07393) | 本文提出了一种提示学习方法，以解决开放域非英语语言对话系统中少量数据下的跨语言迁移学习和多任务学习中的灾难性遗忘问题，并在六种语言上的实验中证明了其有效性。 |
| [^72] | [Consistent Text Categorization using Data Augmentation in e-Commerce.](http://arxiv.org/abs/2305.05402) | 本文提出了一种在电子商务中使用数据增强实现一致的文本分类的新框架，该框架旨在改进产品分类模型的一致性，同时保持其生产水平的性能。 |
| [^73] | [A transformer-based method for zero and few-shot biomedical named entity recognition.](http://arxiv.org/abs/2305.04928) | 本文提出了一种基于Transformer的生物医学领域零样本和少样本NER方法。此方法利用预训练学习给定和潜在类别之间的语义关系，将多类标记分类任务转换为二元标记分类，能够在不同数量的样本情况下达到良好的识别效果。 |
| [^74] | [A Dual Semantic-Aware Recurrent Global-Adaptive Network For Vision-and-Language Navigation.](http://arxiv.org/abs/2305.03602) | 本文提出了一种双重语义感知的全局适应循环网络，通过引入指导语言模块和外观语义视觉模块，以及全局自适应聚合模块，提高了在视觉语言导航中的语义学习。 |
| [^75] | [Can LLM Already Serve as A Database Interface? A BIg Bench for Large-Scale Database Grounded Text-to-SQLs.](http://arxiv.org/abs/2305.03111) | 本文提出了一个大型的基准测试Bird，可以用于大规模数据库文本到SQL的任务，突出了数据库值理解和SQL效率等领域的挑战。 |
| [^76] | [Towards Weakly-Supervised Hate Speech Classification Across Datasets.](http://arxiv.org/abs/2305.02637) | 该论文提出使用极度弱的监督方法，只依赖于类别名称而不是注释数据中的类别示例，解决当前仇恨言论识别的研究存在的数据创建策略不系统和不同注释方案问题，并展示了有效性。 |
| [^77] | [How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model.](http://arxiv.org/abs/2305.00586) | 本研究运用机械式可解释性技术探究了GPT-2 Small的数学能力，并确定了它的计算图中的一个小电路用于计算大于符号，该电路的多层感知器提高了结束年份大于开始年份的概率，并且该电路具有广泛的适用性。 |
| [^78] | [Still no evidence for an effect of the proportion of non-native speakers on language complexity -- A response to Kauhanen, Einhaus & Walkden (2023).](http://arxiv.org/abs/2305.00217) | 本研究为对Kauhanen、Einhaus和Walkden（2023）的回应，仍然没有证据表明大量的L2用户影响语言复杂性。 |
| [^79] | [Efficient Sequence Transduction by Jointly Predicting Tokens and Durations.](http://arxiv.org/abs/2304.06795) | 本文提出了一种新型的序列转导架构TDT，它可以联合预测标记和持续时间，从而实现比传统Transducers更高的准确性和显着更快的推理速度。 |
| [^80] | [BenCoref: A Multi-Domain Dataset of Nominal Phrases and Pronominal Reference Annotations.](http://arxiv.org/abs/2304.03682) | 本论文介绍了一个包括四个不同领域Bengali文本的新数据集- BenCoref。该数据集可以帮助理解Bengali多个领域中共指消解现象的差异，并促进Bengali的资源开发。多个模型在该数据集上训练的性能也得到了报告。在跨语言测试中，从英语到Bengali的交叉语言性能较差，显示出需要语言特定的共指消解系统。 |
| [^81] | [ContraSim -- A Similarity Measure Based on Contrastive Learning.](http://arxiv.org/abs/2303.16992) | 本文提出了一种新的相似度度量方法: ContraSim，该方法利用对比学习学习参数化的度量方法。实验表明，ContraSim在多种基准测试中均获得了比之前相似度量方法更高的准确性。 |
| [^82] | [An Analysis of GPT-3's Performance in Grammatical Error Correction.](http://arxiv.org/abs/2303.14342) | 本文分析了GPT-3模型在语法纠错任务上的表现，通过实验测试了几种不同的提示方式，揭示了人类评分者与基于参考的自动度量之间的差异。 |
| [^83] | [CB2: Collaborative Natural Language Interaction Research Platform.](http://arxiv.org/abs/2303.08127) | CB2是一个用于研究基于任务的合作自然语言交互的平台，在3D游戏环境中提供了后端服务器和各种工具和流程。它在可扩展的研究中展示了学习的指令跟随模型。 |
| [^84] | [Unsupervised Layer-wise Score Aggregation for Textual OOD Detection.](http://arxiv.org/abs/2302.09852) | 提出了一种无监督的逐层聚合异常得分的方法，用于更好地进行文本OOD检测。其能发掘不同层输出的优势，达到更鲁棒的性能，并扩展经典基准测试以反映更现实的设置。 |
| [^85] | [Pre-training for Speech Translation: CTC Meets Optimal Transport.](http://arxiv.org/abs/2301.11716) | 本文提出了一种基于CTC和最优传输的语音翻译预训练方法，可以有效减小语音和文本模态之间的差距，提高最终的ST准确性。 |
| [^86] | [Parameter-Efficient Low-Resource Dialogue State Tracking by Prompt Tuning.](http://arxiv.org/abs/2301.10915) | 这篇论文提出了一种通过使用软提示令牌嵌入来学习任务属性的方法，以实现参数高效的低资源对话状态跟踪，同时在不微调语言模型参数的情况下，取得了比之前方法更好的性能表现。 |
| [^87] | [Continual Contrastive Finetuning Improves Low-Resource Relation Extraction.](http://arxiv.org/abs/2212.10823) | 本文提出了一种使用连续对比微调的方法来改进低资源关系提取，通过使用一致的对比学习目标预训练和微调RE模型，以及多中心对比损失来允许一个关系形成多个聚类。实验结果表明该方法可以显着提高低资源情况和领域中的关系提取性能。 |
| [^88] | [4D ASR: Joint modeling of CTC, Attention, Transducer, and Mask-Predict decoders.](http://arxiv.org/abs/2212.10818) | 本文介绍了一种CTC、Attention、RNN-T和Mask-Predict四个解码器的联合建模(4D)，它可以高效地建模不同类型的ASR任务，包括低资源语音、代码转换语音和不同场景下的语音，并且性能优于单一模型和两个混合模型。 |
| [^89] | [ORCA: A Challenging Benchmark for Arabic Language Understanding.](http://arxiv.org/abs/2212.10758) | ORCA 是一个公开可用的阿拉伯语言理解评估基准，利用各种阿拉伯语言和一系列有挑战性的阿拉伯语言理解任务构建。当前使用 ORCA 对 18 个多语言和阿拉伯语言模型进行比较。 |
| [^90] | [Semantically-informed Hierarchical Event Modeling.](http://arxiv.org/abs/2212.10547) | 本文提出了一种双层次、半监督的事件建模框架，通过注入在事件类型层面定义的结构化本体知识来指导隐变量的压缩，相比之前的最先进方法在不同的数据集和评估指标上均提升了多达8.5%的性能。 |
| [^91] | [When Not to Trust Language Models: Investigating Effectiveness and Limitations of Parametric and Non-Parametric Memories.](http://arxiv.org/abs/2212.10511) | 本文通过对10个模型和4种增强方法的实验，发现语言模型在记忆不太流行的实际知识方面存在困难，而检索增强的语言模型表现较好，提出了一种检索增强语言模型的简单有效方法。 |
| [^92] | [One Embedder, Any Task: Instruction-Finetuned Text Embeddings.](http://arxiv.org/abs/2212.09741) | 使用任务说明微调的单一文本嵌入器INSTRUCTOR，在多个领域和任务的基准测试中实现了最先进的性能，并且功能强大，适应性强。 |
| [^93] | [LENS: A Learnable Evaluation Metric for Text Simplification.](http://arxiv.org/abs/2212.09739) | 本文提出了一种用于文本简化的可学习评估度量标准LENS，通过引入SimpeEval语料库作为人类评估数据集，与现有度量标准相比，LENS对人类判断相关性更好，为评估文本简化的未来进展铺平了道路。 |
| [^94] | [Multi-VALUE: A Framework for Cross-Dialectal English NLP.](http://arxiv.org/abs/2212.08011) | 该论文介绍了一个跨方言的英文NLP框架Multi-VALUE，该框架可以将标准美式英语映射为50种英语方言的合成形式，用于评估、实现英式方言临近性，并在非标准方言上进行压力测试。 |
| [^95] | [Prompting Is Programming: A Query Language for Large Language Models.](http://arxiv.org/abs/2212.06094) | LMP将语言模型提示从纯文本提示扩展为文本提示和脚本的直观组合，实现了一种新的语言模型编程方式。 |
| [^96] | [GPT-3-driven pedagogical agents for training children's curious question-asking skills.](http://arxiv.org/abs/2211.14228) | 该研究探索了使用自然语言处理技术自动生成儿童好奇心问题提问培训的教育内容，该方法显示出了很高的相关性和教育价值。 |
| [^97] | [World Knowledge in Multiple Choice Reading Comprehension.](http://arxiv.org/abs/2211.07040) | 本文研究了在多项选择阅读理解中利用世界知识的可能性，并提出了基于信息理论的度量方法，这些方法能够评估系统利用世界知识的水平，帮助测试设计人员确保使用世界知识的问题是可接受的，同时可以测试问题的质量并发现设计中可能存在的问题。 |
| [^98] | [Using contradictions improves question answering systems.](http://arxiv.org/abs/2211.05598) | 本论文研究了在自然语言推理中使用矛盾技术进行问答，发现结合矛盾、支持和问答模型置信分数的系统表现最佳。 |
| [^99] | [LAMASSU: A Streaming Language-Agnostic Multilingual Speech Recognition and Translation Model Using Neural Transducers.](http://arxiv.org/abs/2211.02809) | LAMASSU 是一个使用神经变换器的流式跨语言通用语音识别和翻译模型，能显著降低模型大小并达到与单语 ASR 和双语翻译模型相当的性能。 |
| [^100] | [Saliency Map Verbalization: Comparing Feature Importance Representations from Model-free and Instruction-based Methods.](http://arxiv.org/abs/2210.07222) | 本研究探索了将显著图转换为自然语言的任务，提出了两种新方法与传统方法的比较，并指导了GPT-3.5生成显著图言语化，得到最高人类评分的结果。 |
| [^101] | [Extractive is not Faithful: An Investigation of Broad Unfaithfulness Problems in Extractive Summarization.](http://arxiv.org/abs/2209.03549) | 本论文调查抽取式总结中存在的五种广泛的不忠实问题，并发现30%的抽取式摘要存在至少一种问题。为了自动检测这些问题，提出了新的度量标准 ExtEval。 |
| [^102] | [Diversity Enhanced Table-to-Text Generation via Type Control.](http://arxiv.org/abs/2205.10938) | 该论文提出了一种利用语句逻辑类型增加多样性的表格生成自然语言模型，可促进控制生成语句类型的能力同时提高结果质量和多样性。 |
| [^103] | [Multi-armed bandits for resource efficient, online optimization of language model pre-training: the use case of dynamic masking.](http://arxiv.org/abs/2203.13151) | 本文提出了一种多臂老虎机框架，用于顺序选择TLM预训练超参数，旨在以资源高效的方式优化语言模型性能。并设计了基于高斯过程的Thompson抽样（GP-TS）算法，加速Pre-training过程并降低MLM损失。 |
| [^104] | [C2-CRS: Coarse-to-Fine Contrastive Learning for Conversational Recommender System.](http://arxiv.org/abs/2201.02732) | 本文提出了一种新的粗到细对比学习框架，用于对话式推荐系统中多类型外部数据的数据语义融合，在此基础上提高了数据的处理效率。 |
| [^105] | [Detecting Inspiring Content on Social Media.](http://arxiv.org/abs/2109.02734) | 本研究尝试通过机器学习方法自动检测社交媒体上具有启发性的内容，首次将启发性引入NLP领域研究。 |

# 详细

[^1]: 通过绘图表对的跨模态预训练来增强视觉语言任务中的图表理解

    Enhanced Chart Understanding in Vision and Language Task via Cross-modal Pre-training on Plot Table Pairs. (arXiv:2305.18641v1 [cs.CL])

    [http://arxiv.org/abs/2305.18641](http://arxiv.org/abs/2305.18641)

    该论文介绍了一个名为ChartT5的V+L模型，它通过对绘图表对进行跨模态预训练，学习如何解释来自图表图像的表格信息，并在图表问答任务中表现出8%以上的性能提升。

    

    在视觉语言领域，建立可以理解图表并传达其中隐藏的信息的跨模态智能是一个有吸引力的挑战。揭示图表数据的关键是自动图表理解的关键。我们介绍了ChartT5，这是一个V + L模型，通过对绘图表对进行跨模态预训练来学习如何解释来自图表图像的表格信息。具体而言，我们提出了两种新颖的预训练目标：遮罩标题预测（MHP）和遮罩值预测（MVP），以使模型具备不同的技能来解释表格信息。我们对图表问答和图表摘要进行了广泛的实验，以验证所提出的预训练策略的有效性。特别是在ChartQA基准测试中，我们的ChartT5的性能比最先进的非预训练方法提高了8%以上。

    Building cross-model intelligence that can understand charts and communicate the salient information hidden behind them is an appealing challenge in the vision and language(V+L) community. The capability to uncover the underlined table data of chart figures is a critical key to automatic chart understanding. We introduce ChartT5, a V+L model that learns how to interpret table information from chart images via cross-modal pre-training on plot table pairs. Specifically, we propose two novel pre-training objectives: Masked Header Prediction (MHP) and Masked Value Prediction (MVP) to facilitate the model with different skills to interpret the table information. We have conducted extensive experiments on chart question answering and chart summarization to verify the effectiveness of the proposed pre-training strategies. In particular, on the ChartQA benchmark, our ChartT5 outperforms the state-of-the-art non-pretraining methods by over 8% performance gains.
    
[^2]: 采用一次提示和文本相似度评分模型进行短回答评分

    Short Answer Grading Using One-shot Prompting and Text Similarity Scoring Model. (arXiv:2305.18638v1 [cs.CL])

    [http://arxiv.org/abs/2305.18638](http://arxiv.org/abs/2305.18638)

    本文提出了一种自动化的短回答评分（ASAG）模型，使用基于大型语言模型的一次提示和文本相似度评分模型，可以提供分析得分和最终整体得分，并使用小规模手动注释的数据集进行领域适应，取得了显著的改进。

    

    在这项研究中，我们开发了一种自动化的短回答评分（ASAG）模型，提供了分析得分和最终整体得分。为了增加自动化得分的可解释性，短回答项通常包含多个子问题，并且提供每个子问题相关的文本范围和分析得分可以增加其解释性。此外，它们可以用来为学生提供可执行的反馈。尽管具有这些优势，但由于难以构建手动注释数据集，大多数研究只关注预测整体得分。为解决这个问题，我们使用基于大型语言模型的一次提示和文本相似度评分模型，使用小规模手动注释的数据集进行领域适应。我们模型的准确度和二次加权kappa系数分别为0.67和0.71，这在公开可用的ASAG数据集的子集上取得了显着的改进。

    In this study, we developed an automated short answer grading (ASAG) model that provided both analytic scores and final holistic scores. Short answer items typically consist of multiple sub-questions, and providing an analytic score and the text span relevant to each sub-question can increase the interpretability of the automated scores. Furthermore, they can be used to generate actionable feedback for students. Despite these advantages, most studies have focused on predicting only holistic scores due to the difficulty in constructing dataset with manual annotations. To address this difficulty, we used large language model (LLM)-based one-shot prompting and a text similarity scoring model with domain adaptation using small manually annotated dataset. The accuracy and quadratic weighted kappa of our model were 0.67 and 0.71 on a subset of the publicly available ASAG dataset. The model achieved a substantial improvement over the majority baseline.
    
[^3]: W-procer: 基于加权原型对比学习的医学少样本命名实体识别

    W-procer: Weighted Prototypical Contrastive Learning for Medical Few-Shot Named Entity Recognition. (arXiv:2305.18624v1 [cs.CL])

    [http://arxiv.org/abs/2305.18624](http://arxiv.org/abs/2305.18624)

    W-procer是一种基于加权原型对比学习的医学少样本命名实体识别方法，在构建基于原型的对比损失和加权网络方面具有创新性，优于现有的最先进方法。

    

    对比学习已成为少样本命名实体识别（NER）的一种受欢迎的解决方案。传统配置力求减少具有相同标签的标记之间的距离，并增加具有不同标签的标记之间的距离。然而，在医学领域中存在大量被注释为“O”（即“OUTSIDE”）的实体，并且它们不希望被推离到当前对比学习方法标记为“O”以外的其他实体，这种设定效果不佳，可能会得出含有噪声原型标签的语义表示，尽管存在许多“O”标签实体与有标签实体相关。为解决这个挑战，我们提出了一种名为医学少样本命名实体识别中基于加权原型的对比学习方法（W-PROCER）。我们的方法主要围绕构建基于原型的对比损失和加权网络展开。这些组件在协助在医学领域中的迁移学习方面发挥了至关重要的作用。在实验中，我们将W-PROCER应用于一个公共的医学数据集，并展示了其相对于现有的最先进方法的优异表现。

    Contrastive learning has become a popular solution for few-shot Name Entity Recognization (NER). The conventional configuration strives to reduce the distance between tokens with the same labels and increase the distance between tokens with different labels. The effect of this setup may, however, in the medical domain, there are a lot of entities annotated as OUTSIDE (O), and they are undesirably pushed apart to other entities that are not labeled as OUTSIDE (O) by the current contrastive learning method end up with a noisy prototype for the semantic representation of the label, though there are many OUTSIDE (O) labeled entities are relevant to the labeled entities. To address this challenge, we propose a novel method named Weighted Prototypical Contrastive Learning for Medical Few Shot Named Entity Recognization (W-PROCER). Our approach primarily revolves around constructing the prototype-based contractive loss and weighting network. These components play a crucial role in assisting t
    
[^4]: Alfred: 一种通过提示进行弱监督的系统

    Alfred: A System for Prompted Weak Supervision. (arXiv:2305.18623v1 [cs.LG])

    [http://arxiv.org/abs/2305.18623](http://arxiv.org/abs/2305.18623)

    Alfred是一个系统，通过提示创建机器学习训练数据，而不是由专家编写的程序式弱监督(PWS)系统，用户可以通过自然语言提示为语言和视觉-语言模型编写主题专业知识。Alfred为这种新兴范式的关键步骤提供简单的Python接口，具有大规模数据标注的高吞吐量后端。

    

    Alfred是第一个使用提示创建机器学习训练数据的程序式弱监督(PWS)系统。与典型的PWS系统不同，其中弱监督源由专家编写的程序，Alfred允许用户通过自然语言提示为语言和视觉-语言模型编写主题专业知识。Alfred为这种新兴范式的关键步骤提供简单的Python接口，具有大规模数据标注的高吞吐量后端。用户可以快速创建、评估和完善基于提示的弱监督来源；将结果映射到弱标签；并使用标签模型解决不同意见。Alfred支持被自管理的计算集群提供的模型服务，实现无缝的本地开发体验。它使用优化的批处理机制自动优化提示的执行。我们发现，与简单方法相比，这种优化可以将查询吞吐量提高2.9倍。我们提供了两个示例。

    Alfred is the first system for programmatic weak supervision (PWS) that creates training data for machine learning by prompting. In contrast to typical PWS systems where weak supervision sources are programs coded by experts, Alfred enables users to encode their subject matter expertise via natural language prompts for language and vision-language models. Alfred provides a simple Python interface for the key steps of this emerging paradigm, with a high-throughput backend for large-scale data labeling. Users can quickly create, evaluate, and refine their prompt-based weak supervision sources; map the results to weak labels; and resolve their disagreements with a label model. Alfred enables a seamless local development experience backed by models served from self-managed computing clusters. It automatically optimizes the execution of prompts with optimized batching mechanisms. We find that this optimization improves query throughput by 2.9x versus a naive approach. We present two example
    
[^5]: CONA: 一种新颖的基于上下文的指令范式，用于使用大型语言模型的通信

    CONA: A novel CONtext-Aware instruction paradigm for communication using large language model. (arXiv:2305.18620v1 [cs.CL])

    [http://arxiv.org/abs/2305.18620](http://arxiv.org/abs/2305.18620)

    CONA是一种基于上下文的指令范式，利用大型语言模型，自动优化演示内容并提供上下文感知型答案，具有较高的上下文感知性和易理解性。

    

    我们介绍了CONA，这是一种新颖的基于上下文的指令范式，利用生成预训练转换器（GPT）模型有效进行知识传播。CONA是一个灵活的框架，旨在利用大型语言模型（LLMs）的能力，并结合DIKW（数据、信息、知识、智慧）层级自动指导和优化演示内容，预测潜在的听众问题，并适应听众群体的知识水平提供上下文感知型答案。CONA范式的独特之处在于其独立咨询机制和根植于DIKW层级的递归反馈循环的组合。这种协同作用显著提高了上下文感知内容，确保听众可以轻松理解和获取。这种范式是探索LLM时代的知识传播和沟通的新方法的早期先驱，为日常知识共享场景提供有效支持。

    We introduce CONA, a novel context-aware instruction paradigm for effective knowledge dissemination using generative pre-trained transformer (GPT) models. CONA is a flexible framework designed to leverage the capabilities of Large Language Models (LLMs) and incorporate DIKW (Data, Information, Knowledge, Wisdom) hierarchy to automatically instruct and optimise presentation content, anticipate potential audience inquiries, and provide context-aware answers that adaptive to the knowledge level of the audience group. The unique aspect of the CONA paradigm lies in its combination of an independent advisory mechanism and a recursive feedback loop rooted on the DIKW hierarchy. This synergy significantly enhances context-aware contents, ensuring they are accessible and easily comprehended by the audience. This paradigm is an early pioneer to explore new methods for knowledge dissemination and communication in the LLM era, offering effective support for everyday knowledge sharing scenarios. We
    
[^6]: 基于似然的扩散语言模型

    Likelihood-Based Diffusion Language Models. (arXiv:2305.18619v1 [cs.CL])

    [http://arxiv.org/abs/2305.18619](http://arxiv.org/abs/2305.18619)

    本论文介绍了基于似然的扩散语言模型，并通过算法改进、缩放定律和增加计算，成功构建和发布了一个超过小但广为人知的自回归模型的扩散模型，优于GPT-2 124M。

    

    尽管人们对基于扩散的语言模型越来越感兴趣，但现有的工作尚未表明这些模型可以在标准语言建模基准上获得非微不足道的似然度。在这项工作中，我们首先采取了措施来缩小自回归和扩散语言模型之间的似然差异，目标是构建和发布一个超过小但广为人知的自回归模型的扩散模型。我们通过算法改进、缩放定律和增加计算来实现这个目标。在算法前沿，我们引入了几种最大似然训练扩散语言模型的方法论改进。然后，我们研究了我们的扩散模型缩放定律，并发现计算优化的训练方案与自回归模型差别很大。使用我们的方法和缩放分析，我们训练并发布了Plaid 1B，一个大型扩散语言模型，它在基准数据集上的似然度和生成文本质量上优于GPT-2 124M。

    Despite a growing interest in diffusion-based language models, existing work has not shown that these models can attain nontrivial likelihoods on standard language modeling benchmarks. In this work, we take the first steps towards closing the likelihood gap between autoregressive and diffusion-based language models, with the goal of building and releasing a diffusion model which outperforms a small but widely-known autoregressive model. We pursue this goal through algorithmic improvements, scaling laws, and increased compute. On the algorithmic front, we introduce several methodological improvements for the maximum-likelihood training of diffusion language models. We then study scaling laws for our diffusion models and find compute-optimal training regimes which differ substantially from autoregressive models. Using our methods and scaling analysis, we train and release Plaid 1B, a large diffusion language model which outperforms GPT-2 124M in likelihood on benchmark datasets and gener
    
[^7]: 数学与逻辑问题中的聊天机器人: ChatGPT-3.5、ChatGPT-4和Google Bard的初步比较和评估

    Chatbots put to the test in math and logic problems: A preliminary comparison and assessment of ChatGPT-3.5, ChatGPT-4, and Google Bard. (arXiv:2305.18618v1 [cs.CL])

    [http://arxiv.org/abs/2305.18618](http://arxiv.org/abs/2305.18618)

    本文比较了三种基于大型语言模型的聊天机器人(ChatGPT-3.5、ChatGPT-4和Google Bard)在解决数学和逻辑问题上的正确性，研究发现这些机器人可以在某些情况下给出正确答案，但在更复杂的问题中需要改进。

    

    本文介绍了三个基于大型语言模型的聊天机器人(ChatGPT-3.5、ChatGPT-4和Google Bard)在解决数学和逻辑问题时的正确性对比。我们使用30个清晰、无二义性、仅使用纯文本且具有独特定义的正确答案的问题，分为两组并分别向每个聊天机器人提出三遍。通过记录并讨论问题的答案，我们总结了它们的优点和缺点。研究表明，对于简单的算术和代数表达式...

    A comparison between three chatbots which are based on large language models, namely ChatGPT-3.5, ChatGPT-4 and Google Bard is presented, focusing on their ability to give correct answers to mathematics and logic problems. In particular, we check their ability to Understand the problem at hand; Apply appropriate algorithms or methods for its solution; and Generate a coherent response and a correct answer. We use 30 questions that are clear, without any ambiguities, fully described with plain text only, and have a unique, well defined correct answer. The questions are divided into two sets of 15 each. The questions of Set A are 15 "Original" problems that cannot be found online, while Set B contains 15 "Published" problems that one can find online, usually with their solution. Each question is posed three times to each chatbot. The answers are recorded and discussed, highlighting their strengths and weaknesses. It has been found that for straightforward arithmetic, algebraic expressions
    
[^8]: 从“音频片段方言”到“语料库和方言”: 利用语音的神经表示在语言背景中定位音频信号

    From `Snippet-lects' to Doculects and Dialects: Leveraging Neural Representations of Speech for Placing Audio Signals in a Language Landscape. (arXiv:2305.18602v1 [cs.CL])

    [http://arxiv.org/abs/2305.18602](http://arxiv.org/abs/2305.18602)

    本文利用XSLR-53神经表示来估计音频文件之间的接近程度，最终旨在提取相关的语言属性。在11种方言的数据中，可为一种很少资源或完全未知的语言获得总体语音/语音学接近度估计。

    

    XSLR-53是一种多语言语音模型，可以从音频中建立一个向量表示，允许进行各种计算处理。本文使用这种神经表示来估计音频文件之间的接近程度，最终旨在提取相关的语言属性。我们使用最大汇集法从“音频片段方言”(一个5秒音频片段中的语音)聚合神经表示到“语料库”(给定资源中的语音)，然后到方言和语言。我们使用来自5种较少研究的语言中11种方言的语料库数据。对这11个语料库之间的相似度测量揭示了已知是同一语言方言之间最大的接近度。这些发现表明: (i) 方言/语言可以在表征音频文件的各个参数之间出现， (ii) 可以为一种很少资源或完全未知的语言获得总体语音/语音学接近度估计。这些发现有助于利用语音的神经表示在语言背景中定位音频信号。

    XLSR-53 a multilingual model of speech, builds a vector representation from audio, which allows for a range of computational treatments. The experiments reported here use this neural representation to estimate the degree of closeness between audio files, ultimately aiming to extract relevant linguistic properties. We use max-pooling to aggregate the neural representations from a "snippet-lect" (the speech in a 5-second audio snippet) to a "doculect" (the speech in a given resource), then to dialects and languages. We use data from corpora of 11 dialects belonging to 5 less-studied languages. Similarity measurements between the 11 corpora bring out greatest closeness between those that are known to be dialects of the same language. The findings suggest that (i) dialect/language can emerge among the various parameters characterizing audio files and (ii) estimates of overall phonetic/phonological closeness can be obtained for a little-resourced or fully unknown language. The findings help
    
[^9]: 提高多模态假新闻检测的泛化能力

    Improving Generalization for Multimodal Fake News Detection. (arXiv:2305.18599v1 [cs.CL])

    [http://arxiv.org/abs/2305.18599](http://arxiv.org/abs/2305.18599)

    本研究提出了三种模型，采用和微调最先进的多模态Transformer进行多模态假新闻检测，并提出了训练数据增强来提高模型泛化能力。

    

    现在，虚假信息的不断传播及其惊人的影响已经促使行业和学术界开发出假新闻检测方法。然而，最先进的方法通常使用规模较小或特定主题的有限数据集进行训练。因此，这些模型缺乏泛化能力，不能应用于现实世界的数据。本文提出了三种采用并微调最先进的多模态Transformer进行多模态假新闻检测的模型。我们通过操作输入数据进行深入分析，旨在探索这些模型在社交媒体上的实际使用情况下的性能。我们跨多个模型进行的研究表明，这些系统在受到操作数据的情况下会出现显着的性能下降。为了减少偏差并提高模型的泛化能力，我们建议进行训练数据增强，以在社交媒体上进行更有意义的假新闻检测实验。

    The increasing proliferation of misinformation and its alarming impact have motivated both industry and academia to develop approaches for fake news detection. However, state-of-the-art approaches are usually trained on datasets of smaller size or with a limited set of specific topics. As a consequence, these models lack generalization capabilities and are not applicable to real-world data. In this paper, we propose three models that adopt and fine-tune state-of-the-art multimodal transformers for multimodal fake news detection. We conduct an in-depth analysis by manipulating the input data aimed to explore models performance in realistic use cases on social media. Our study across multiple models demonstrates that these systems suffer significant performance drops against manipulated data. To reduce the bias and improve model generalization, we suggest training data augmentation to conduct more meaningful experiments for fake news detection on social media. The proposed data augmentat
    
[^10]: 一种使用可解释的上下文嵌入空间研究语法结构中的语义表达的方法

    A Method for Studying Semantic Construal in Grammatical Constructions with Interpretable Contextual Embedding Spaces. (arXiv:2305.18598v1 [cs.CL])

    [http://arxiv.org/abs/2305.18598](http://arxiv.org/abs/2305.18598)

    本文介绍了一种使用大型语言模型研究语法结构中的语义表达的方法，首先将上下文单词嵌入投射到三个可解释的语义空间中，然后使用这些空间自动派生出在语法结构中的词汇项目的语义表述，我们发现主语位置中的单词被解释为比同样的宾语位置中的单词更具代理性，并且AANN结构中的名词被解释为比传统转换中的名词更具测量属性。

    

    我们使用大型语言模型研究语法结构中的语义表达。首先，我们将上下文单词嵌入投射到三个可解释的语义空间中，每个空间由不同的心理语言学特征规范集定义。我们验证了这些可解释的空间，然后使用它们自动派生出两个语法结构中词汇项目的语义表述：在同一句子中作为主语或宾语位置的名词，以及AANN结构（例如，“美丽的三天”）。我们展示了主语位置中的单词被解释为比同样的宾语位置中的单词更具代理性，并且AANN结构中的名词被解释为比传统转换中的名词更具测量属性。我们的方法可以在模板级别上探测句法结构的分布式意义，抽象到特定词汇之外。

    We study semantic construal in grammatical constructions using large language models. First, we project contextual word embeddings into three interpretable semantic spaces, each defined by a different set of psycholinguistic feature norms. We validate these interpretable spaces and then use them to automatically derive semantic characterizations of lexical items in two grammatical constructions: nouns in subject or object position within the same sentence, and the AANN construction (e.g., `a beautiful three days'). We show that a word in subject position is interpreted as more agentive than the very same word in object position, and that the nouns in the AANN construction are interpreted as more measurement-like than when in the canonical alternation. Our method can probe the distributional meaning of syntactic constructions at a templatic level, abstracted away from specific lexemes.
    
[^11]: 利用可解释性设计对抗攻击和评估仇恨言论检测模型的鲁棒性

    Exploiting Explainability to Design Adversarial Attacks and Evaluate Attack Resilience in Hate-Speech Detection Models. (arXiv:2305.18585v1 [cs.CL])

    [http://arxiv.org/abs/2305.18585](http://arxiv.org/abs/2305.18585)

    本文结合可解释性和对抗攻击两个关键方面，研究了仇恨言论检测模型的鲁棒性，并提出了针对性的对抗攻击，对该领域的未来研究具有重要的意义。

    

    社交媒体的出现带来了许多伦理问题，其中仇恨言论是最重要的问题之一。研究人员正在尝试通过利用仇恨言论检测和使用语言模型来自动审查内容并促进文明讨论来解决这个问题。不幸的是，最近的研究表明，仇恨言论检测系统可能会被对抗攻击所误导，引起其鲁棒性的关注。尽管以前的研究已单独讨论了在对抗攻击下模型的鲁棒性和可解释性，但没有全面研究他们的交集。我们的工作的创新在于结合这两个关键方面，利用可解释性识别潜在的漏洞，从而设计有针对性的对抗攻击。我们对各种仇恨言论检测模型表现出的对抗鲁棒性进行了全面和比较分析。

    The advent of social media has given rise to numerous ethical challenges, with hate speech among the most significant concerns. Researchers are attempting to tackle this problem by leveraging hate-speech detection and employing language models to automatically moderate content and promote civil discourse. Unfortunately, recent studies have revealed that hate-speech detection systems can be misled by adversarial attacks, raising concerns about their resilience. While previous research has separately addressed the robustness of these models under adversarial attacks and their interpretability, there has been no comprehensive study exploring their intersection. The novelty of our work lies in combining these two critical aspects, leveraging interpretability to identify potential vulnerabilities and enabling the design of targeted adversarial attacks. We present a comprehensive and comparative analysis of adversarial robustness exhibited by various hate-speech detection models. Our study e
    
[^12]: TreeMAN：基于树增强的多模态注意力网络用于ICD编码

    TreeMAN: Tree-enhanced Multimodal Attention Network for ICD Coding. (arXiv:2305.18576v1 [cs.CL])

    [http://arxiv.org/abs/2305.18576](http://arxiv.org/abs/2305.18576)

    提出了TreeMAN模型，该模型通过使用基于树的特征增强文本表示，将表格特征和文本特征融合为多模态表示以更准确地预测ICD代码。

    

    ICD编码旨在为出院后的电子健康记录分配疾病代码，这对账单和临床统计非常重要。为了提高手动编码的效率和准确性，许多方法已被提出来自动从临床记录中预测ICD代码。然而，大多数之前的工作忽略了包含在EHR中的结构化医疗数据中的重要信息，这些信息很难从嘈杂的临床记录中捕获。在本文中，我们提出了一种Tree-enhanced Multimodal Attention Network(TreeMAN)，通过使用注意力机制，将表格特征和文本特征融合为多模态表示，并借助基于树的特征增强文本表示。基于树的特征是根据从结构化多模态医疗数据中学习的决策树构建的，它们捕捉关于ICD编码的重要信息。我们可以将先前文本模型中的相同多标签分类器应用于多模态表示。

    ICD coding is designed to assign the disease codes to electronic health records (EHRs) upon discharge, which is crucial for billing and clinical statistics. In an attempt to improve the effectiveness and efficiency of manual coding, many methods have been proposed to automatically predict ICD codes from clinical notes. However, most previous works ignore the decisive information contained in structured medical data in EHRs, which is hard to be captured from the noisy clinical notes. In this paper, we propose a Tree-enhanced Multimodal Attention Network (TreeMAN) to fuse tabular features and textual features into multimodal representations by enhancing the text representations with tree-based features via the attention mechanism. Tree-based features are constructed according to decision trees learned from structured multimodal medical data, which capture the decisive information about ICD coding. We can apply the same multi-label classifier from previous text models to the multimodal re
    
[^13]: ChatGPT的公平性评估

    Fairness of ChatGPT. (arXiv:2305.18569v1 [cs.LG])

    [http://arxiv.org/abs/2305.18569](http://arxiv.org/abs/2305.18569)

    本文提供了一个使用ChatGPT作为研究案例的LLM有效性和公平性的系统评估，旨在评估ChatGPT在高风险领域的表现，以提供更深入的了解LLM的公平表现，并为偏见缓解和负责任的人工智能系统的发展做出贡献。

    

    理解和解决LLM中不公平的问题对于负责任的AI部署至关重要。然而，在将LLM应用于高风险领域时，尤其是关于公平评估方面，数量分析和深入研究的可用性有限。本文旨在提供一个使用ChatGPT作为研究案例的LLM有效性和公平性的系统评估，我们专注于评估ChatGPT在包括教育、犯罪学、金融和医疗保健等高风险领域的表现。为了进行全面的评估，我们考虑了群体公平性和个人公平性，并观察了在一系列有偏或无偏提示下ChatGPT输出的差异。该研究对于更深入的了解LLM的公平表现，便于偏见缓解，促进负责任的人工智能系统的发展具有意义。

    Understanding and addressing unfairness in LLMs are crucial for responsible AI deployment. However, there is a limited availability of quantitative analyses and in-depth studies regarding fairness evaluations in LLMs, especially when applying LLMs to high-stakes fields. This work aims to fill this gap by providing a systematic evaluation of the effectiveness and fairness of LLMs using ChatGPT as a study case. We focus on assessing ChatGPT's performance in high-takes fields including education, criminology, finance and healthcare. To make thorough evaluation, we consider both group fairness and individual fairness and we also observe the disparities in ChatGPT's outputs under a set of biased or unbiased prompts. This work contributes to a deeper understanding of LLMs' fairness performance, facilitates bias mitigation and fosters the development of responsible artificial intelligence systems.
    
[^14]: PaLI-X：关于扩展一种多语言视觉与语言模型的研究

    PaLI-X: On Scaling up a Multilingual Vision and Language Model. (arXiv:2305.18565v1 [cs.CV])

    [http://arxiv.org/abs/2305.18565](http://arxiv.org/abs/2305.18565)

    论文介绍了一个多语言视觉与语言模型PaLI-X，通过扩展模型组件和训练任务范围，实现了在复杂任务上的新性能水平，包括图像字幕问答、对象检测、视频问答和视频字幕等，同时在视觉语言基准测试中取得了最新的研究成果。

    

    我们介绍了扩展PaLI-X，一种多语言视觉与语言模型的训练配方和结果，包括组件的大小和训练任务范围的广度。我们的模型在多个基于图像的字幕和问答任务、基于图像的文档理解和少量（上下文内）学习以及对象检测、视频问答和视频字幕等各种复杂任务上实现了新的性能水平。PaLI-X 在大多数视觉语言基准测试中取得了最新的研究成果（考虑了25个以上的测试）。最后，我们观察到了一些新兴的能力，如复杂计数和多语言对象检测，这些任务并没有明确列在训练范围之内。

    We present the training recipe and results of scaling up PaLI-X, a multilingual vision and language model, both in terms of size of the components and the breadth of its training task mixture. Our model achieves new levels of performance on a wide-range of varied and complex tasks, including multiple image-based captioning and question-answering tasks, image-based document understanding and few-shot (in-context) learning, as well as object detection, video question answering, and video captioning. PaLI-X advances the state-of-the-art on most vision-and-language benchmarks considered (25+ of them). Finally, we observe emerging capabilities, such as complex counting and multilingual object detection, tasks that are not explicitly in the training mix.
    
[^15]: 遗忘的知识：审视自然语言处理中的引文健忘现象

    Forgotten Knowledge: Examining the Citational Amnesia in NLP. (arXiv:2305.18554v1 [cs.CL])

    [http://arxiv.org/abs/2305.18554](http://arxiv.org/abs/2305.18554)

    本文系统地和实证地考察了自然语言处理(NLP)领域内的引文模式，证明了大约62%的引用论文属于出版前五年，只有约17%的论文超过十年。目前，NLP论文的引用年龄趋于历史最低水平，这个趋势与此前相反。

    

    引用论文是现代科学写作讨论和建立先前工作的主要方法。全面地引用一组多样化(时间和研究领域)的论文是衡量社区阅读广泛程度的指标。然而，鲜有研究探讨引文的广泛时间模式。本研究系统地和实证地考察了自然语言处理领域内的引文重要性，探讨了我们引用论文时往回追溯多少年的问题，引用时间的变化趋势，以及有哪些因素与这种引文注意力/健忘状态相关。我们分析了约71.5K篇论文，选择了自然语言处理作为我们感兴趣的领域，并证明并量化了引用中的几个关键趋势。特别地，我们发现，大约62%的引用论文属于在出版前五年的论文，而只有约17%的论文超过十年。此外，我们发现引用论文的年龄中位数和年龄多样性从1990年到2014年持续增加，但自那时起，这个趋势已经逆转，目前自然语言处理论文的引文年龄还创历史最低点。

    Citing papers is the primary method through which modern scientific writing discusses and builds on past work. Collectively, citing a diverse set of papers (in time and area of study) is an indicator of how widely the community is reading. Yet, there is little work looking at broad temporal patterns of citation. This work systematically and empirically examines: How far back in time do we tend to go to cite papers? How has that changed over time, and what factors correlate with this citational attention/amnesia? We chose NLP as our domain of interest and analyzed approximately 71.5K papers to show and quantify several key trends in citation. Notably, around 62% of cited papers are from the immediate five years prior to publication, whereas only about 17% are more than ten years old. Furthermore, we show that the median age and age diversity of cited papers were steadily increasing from 1990 to 2014, but since then, the trend has reversed, and current NLP papers have an all-time low tem
    
[^16]: SlimFit：使用训练动态实现基于Transformer模型的内存高效微调

    SlimFit: Memory-Efficient Fine-Tuning of Transformer-based Models Using Training Dynamics. (arXiv:2305.18513v1 [cs.CL])

    [http://arxiv.org/abs/2305.18513](http://arxiv.org/abs/2305.18513)

    SlimFit是一个新工具，通过动态分析模型的训练动态并在微调过程中冻结不影响性能的层，将基于Transformer模型的内存占用降低了5倍，而不影响性能。

    

    基于Transformer的模型（如BERT和ViT）在不同的自然语言处理（NLP）和计算机视觉（CV）任务中取得了最先进的结果。然而，在微调过程中，这些模型的内存占用极高，使它们难以在内存资源受限的GPU上部署。为了应对这个问题，我们引入了一个称为SlimFit的新工具，通过动态分析训练过程中的训练动态并在微调过程中冻结贡献较少的层来减少这些模型的内存要求。运行时层间调度算法选择要冻结的层。SlimFit对特定层采用量化和剪枝，以平衡动态激活的负载，并最小化不能丢弃的静态激活的内存占用，其中静态激活指无论冻结与否都不能丢弃的激活。这使得SlimFit可以冻结多达95％的层，并将变压器模型的整体设备GPU内存使用率降低高达5倍，而不影响性能。

    Transformer-based models, such as BERT and ViT, have achieved state-of-the-art results across different natural language processing (NLP) and computer vision (CV) tasks. However, these models are extremely memory intensive during their fine-tuning process, making them difficult to deploy on GPUs with limited memory resources. To address this issue, we introduce a new tool called SlimFit that reduces the memory requirements of these models by dynamically analyzing their training dynamics and freezing less-contributory layers during fine-tuning. The layers to freeze are chosen using a runtime inter-layer scheduling algorithm. SlimFit adopts quantization and pruning for particular layers to balance the load of dynamic activations and to minimize the memory footprint of static activations, where static activations refer to those that cannot be discarded regardless of freezing. This allows SlimFit to freeze up to 95% of layers and reduce the overall on-device GPU memory usage of transformer
    
[^17]: 代码提示：用于大语言模型中复杂推理的神经符号方法

    Code Prompting: a Neural Symbolic Method for Complex Reasoning in Large Language Models. (arXiv:2305.18507v1 [cs.CL])

    [http://arxiv.org/abs/2305.18507](http://arxiv.org/abs/2305.18507)

    本文介绍了一种神经符号提示方法——代码提示，该方法可以触发代码作为中间步骤。与自然语言相比，代码提示有着几个独特优势，能够提高符号推理和算术推理的性能，并且通常优于思路链提示。

    

    大语言模型已经通过各种提示方法扩大了规模，以解锁广泛的复杂推理任务。然而，当前的提示方法生成自然语言中间步骤以帮助推理，这可能导致不完善的任务缩减和混淆。为了缓解这样的限制，我们探索了代码提示，一种神经符号提示方法，具有零-shot和少-shot版本，可以触发代码作为中间步骤。我们在涉及符号推理和算术推理的7个广泛使用的基准测试中进行了实验。代码提示通常优于思路链提示。为了进一步了解代码提示的性能和限制，我们进行了广泛的消融研究和错误分析，并确定了使用符号提示相对于自然语言的几个独特优势。我们还考虑了代码提示和思路链提示的集合，以结合两者的优势。最后，我们展示了...

    Large language models (LLMs) have scaled up to unlock a wide range of complex reasoning tasks with the aid of various prompting methods. However, current prompting methods generate natural language intermediate steps to help reasoning, which can cause imperfect task reduction and confusion. To mitigate such limitations, we explore code prompting, a neural symbolic prompting method with both zero-shot and few-shot versions which triggers code as intermediate steps. We conduct experiments on 7 widely-used benchmarks involving symbolic reasoning and arithmetic reasoning. Code prompting generally outperforms chain-of-thought (CoT) prompting. To further understand the performance and limitations of code prompting, we perform extensive ablation studies and error analyses, and identify several exclusive advantages of using symbolic promptings compared to natural language. We also consider the ensemble of code prompting and CoT prompting to combine the strengths of both. Finally, we show throu
    
[^18]: 从对抗性竞争到以模型为中心的评价：推动一个统一的自动鲁棒性评估框架

    From Adversarial Arms Race to Model-centric Evaluation: Motivating a Unified Automatic Robustness Evaluation Framework. (arXiv:2305.18503v1 [cs.CL])

    [http://arxiv.org/abs/2305.18503](http://arxiv.org/abs/2305.18503)

    本文旨在建立一个统一的自动鲁棒性评估框架，向以模型为中心的评估转型，利用对抗攻击的优势。研究者们根据模型能力确定鲁棒性评估维度，并针对每个维度指定合理的算法来生成对抗样本。

    

    文本对抗攻击可以通过向输入添加语义保留但具有误导性的扰动来发现模型的弱点。自然语言处理（NLP）中长期的对抗性攻击和防御竞争是算法中心的，为自动鲁棒性评估提供了有价值的技术。但是，现有的鲁棒性评估实践可能存在评估不全面、评估协议不实用以及对抗样本失效等问题。本文旨在建立一个统一的自动鲁棒性评估框架，向以模型为中心的评估转型，进一步利用对抗攻击的优势。为了解决上述挑战，我们首先基于模型能力确定鲁棒性评估维度，并针对每个维度指定合理的算法来生成对抗样本。然后，我们建立了评估协议，包括评估设置和指标，以满足实际需求。最后，我们利用该框架在多个数据集上进行实验，并探讨了其在不同场景下的适用性和局限性。

    Textual adversarial attacks can discover models' weaknesses by adding semantic-preserved but misleading perturbations to the inputs. The long-lasting adversarial attack-and-defense arms race in Natural Language Processing (NLP) is algorithm-centric, providing valuable techniques for automatic robustness evaluation. However, the existing practice of robustness evaluation may exhibit issues of incomprehensive evaluation, impractical evaluation protocol, and invalid adversarial samples. In this paper, we aim to set up a unified automatic robustness evaluation framework, shifting towards model-centric evaluation to further exploit the advantages of adversarial attacks. To address the above challenges, we first determine robustness evaluation dimensions based on model capabilities and specify the reasonable algorithm to generate adversarial samples for each dimension. Then we establish the evaluation protocol, including evaluation settings and metrics, under realistic demands. Finally, we u
    
[^19]: VAST：一种视听字幕文本全模态基础模型与数据集

    VAST: A Vision-Audio-Subtitle-Text Omni-Modality Foundation Model and Dataset. (arXiv:2305.18500v1 [cs.CV])

    [http://arxiv.org/abs/2305.18500](http://arxiv.org/abs/2305.18500)

    本文提出了一种全模态视频文本基础模型VAST及其数据集VAST-27M。该模型可以感知和处理视频中的视觉、音频和字幕模态，通过自动集成多模态字幕和资源，提供更好的支持文本关联的多种任务。

    

    当代视频文本基础模型已经完全探索了视觉和文本，而其他模态，如视频中的音频和字幕，却没有得到足够的关注。本文旨在通过探索自动生成的大规模全模态视频字幕数据集VAST-27M，建立多模态视频轨迹之间的连接，包括视觉、音频和字幕，并与文本进行关联。具体而言，我们首先收集了2700万个开放领域视频片段，并分别训练视觉和音频字幕生成器以生成视觉和音频字幕。然后，我们使用一个现有的大语言模型（LLM）将生成的字幕、字幕和指导提示集成到全模态字幕中。基于提出的VAST-27M数据集，我们训练了一种全模态视频文本基础模型VAST，它可以感知和处理视频中的视觉、音频和字幕模态，并更好地支持各种任务，包括视觉和文本之间的关联。

    Vision and text have been fully explored in contemporary video-text foundational models, while other modalities such as audio and subtitles in videos have not received sufficient attention. In this paper, we resort to establish connections between multi-modality video tracks, including Vision, Audio, and Subtitle, and Text by exploring an automatically generated large-scale omni-modality video caption dataset called VAST-27M. Specifically, we first collect 27 million open-domain video clips and separately train a vision and an audio captioner to generate vision and audio captions. Then, we employ an off-the-shelf Large Language Model (LLM) to integrate the generated captions, together with subtitles and instructional prompts into omni-modality captions. Based on the proposed VAST-27M dataset, we train an omni-modality video-text foundational model named VAST, which can perceive and process vision, audio, and subtitle modalities from video, and better support various tasks including vis
    
[^20]: ANPL：使用交互式分解编译自然程序

    ANPL: Compiling Natural Programs with Interactive Decomposition. (arXiv:2305.18498v1 [cs.PL])

    [http://arxiv.org/abs/2305.18498](http://arxiv.org/abs/2305.18498)

    ANPL是一个编程系统，可以让用户直接操作草图，使用自然语言描述注释模块或孔，并生成一个有机的Python程序，它优于基线。

    

    大型语言模型的出现在通过自然交互增强编程方面显示出了潜力。然而，虽然大型语言模型擅长将常见的使用模式编译为编程语言，例如Python，但如何编辑和调试由大型语言模型生成的程序仍然是一个挑战。我们介绍了ANPL，一种编程系统，允许用户分解特定于用户的任务。在ANPL程序中，用户可以直接操作草图，该草图指定生成的程序的数据流。用户使用自然语言描述注释模块或孔，将生成功能的昂贵任务卸载到大型语言模型中。给定一个ANPL程序，ANPL编译器会生成一个有机的Python程序，实现孔中的功能，并遵守草图中指定的数据流。我们将ANPL部署在抽象和推理语料库（ARC）上，它是一组对于最先进的AI系统而言具有挑战性的独特任务，结果表明它优于基线。

    The advents of Large Language Models (LLMs) have shown promise in augmenting programming using natural interactions. However, while LLMs are proficient in compiling common usage patterns into a programming language, e.g., Python, it remains a challenge how to edit and debug an LLM-generated program. We introduce ANPL, a programming system that allows users to decompose user-specific tasks. In an ANPL program, a user can directly manipulate sketch, which specifies the data flow of the generated program. The user annotates the modules, or hole with natural language descriptions offloading the expensive task of generating functionalities to the LLM. Given an ANPL program, the ANPL compiler generates a cohesive Python program that implements the functionalities in hole, while respecting the dataflows specified in sketch. We deploy ANPL on the Abstraction and Reasoning Corpus (ARC), a set of unique tasks that are challenging for state-of-the-art AI systems, showing it outperforms baseline p
    
[^21]: 基准数据集上 ChatGPT 的系统研究和全面评估

    A Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark Datasets. (arXiv:2305.18486v1 [cs.CL])

    [http://arxiv.org/abs/2305.18486](http://arxiv.org/abs/2305.18486)

    本文对基准数据集上 ChatGPT 的性能进行了全面的评估，包括问答、文本摘要、代码生成、常识推理、数学问题求解、机器翻译、偏见检测和伦理考虑等任务。研究旨在验证 ChatGPT 的优势和弱点，并为使用语言模型的未来研究提供见解。

    

    最近，如 ChatGPT 这样的大型语言模型（LLM）的开发引起了很多关注。然而，由于难以将该模型生成的产出与基本事实进行比较，因此其在基准学术数据集上的评估仍未充分探索。本文旨在对 ChatGPT 在包括问答、文本摘要、代码生成、常识推理、数学问题求解、机器翻译、偏见检测和伦理考虑等任务中的表现进行彻底评估。具体而言，我们在 140 个任务中评估了 ChatGPT，并分析了其在这些数据集中生成的 255K 次响应，这使我们的工作成为了在 NLP 基准测试中对 ChatGPT 进行的最大评估。简而言之，我们的研究旨在验证 ChatGPT 在各种任务中的优势和弱点，并为使用 LLM 的未来研究提供见解。我们还报告了一种新的迸发能力，即遵循多个查询指令。

    The development of large language models (LLMs) such as ChatGPT has brought a lot of attention recently. However, their evaluation in the benchmark academic datasets remains under-explored due to the difficulty of evaluating the generative outputs produced by this model against the ground truth. In this paper, we aim to present a thorough evaluation of ChatGPT's performance on diverse academic datasets, covering tasks like question-answering, text summarization, code generation, commonsense reasoning, mathematical problem-solving, machine translation, bias detection, and ethical considerations. Specifically, we evaluate ChatGPT across 140 tasks and analyze 255K responses it generates in these datasets. This makes our work the largest evaluation of ChatGPT in NLP benchmarks. In short, our study aims to validate the strengths and weaknesses of ChatGPT in various tasks and provide insights for future research using LLMs. We also report a new emergent ability to follow multi-query instruct
    
[^22]: 基于最近邻的大语言模型的测试时间训练

    Test-Time Training on Nearest Neighbors for Large Language Models. (arXiv:2305.18466v1 [cs.CL])

    [http://arxiv.org/abs/2305.18466](http://arxiv.org/abs/2305.18466)

    该论文提出了一种基于最近邻的测试时间训练方法，通过检索和微调少量邻居的文本数据，该方法在大语言模型上显著提高了性能。

    

    最近的许多工作都旨在在测试时从数据库中检索相关信息以增强语言模型。我们通过直接在测试时使用其标准训练设置对检索到的数据对模型进行微调，避免了提示工程的需要。为此，我们建立了一个基于“Pile”数据集的文本嵌入的大规模分布式最近邻索引。给定一个语言模型的查询，我们的系统检索查询的邻居，并在对应于这些邻居的文本数据上微调模型。令人惊讶的是，检索和训练仅20个邻居，每个邻居仅进行一次梯度迭代，就显著提高了在“Pile”基准测试中超过二十个语言建模任务的性能。例如，测试时间训练显著缩小了小型GPT2模型和GPTNeo模型之间的性能差距，后者是专门对“Pile”进行收敛训练的，体积却是前者的十倍以上。然而，其方法的成功还取决于充分的索引质量和大小。

    Many recent efforts aim to augment language models with relevant information retrieved from a database at test time. We avoid the need for prompt engineering by directly fine-tuning the model on data retrieved at test time using its standard training setup. For this purpose, we build a large-scale distributed nearest neighbor index based on text embeddings of the Pile dataset. Given a query to a language model, our system retrieves the neighbors of the query and fine-tunes the model on the text data corresponding to those neighbors. Surprisingly, retrieving and training on as few as 20 neighbors, each for only one gradient iteration, drastically improves performance across more than twenty language modeling tasks in the Pile benchmark. For example, test-time training significantly narrows the performance gap between a small GPT2 model and a GPTNeo model, more than ten times larger, that was specifically trained to convergence on the Pile. Sufficient index quality and size, however, are
    
[^23]: 基于邻域比较的语言模型成员推断攻击

    Membership Inference Attacks against Language Models via Neighbourhood Comparison. (arXiv:2305.18462v1 [cs.CL])

    [http://arxiv.org/abs/2305.18462](http://arxiv.org/abs/2305.18462)

    本文提出两种新的基于邻域比较的攻击策略，利用语言数据的内在结构来提高成员推断攻击的性能，并在几个公开数据集上证明这些攻击的有效性。

    

    成员推断攻击(MIAs)旨在预测一个数据样本是否存在于机器学习模型的训练数据中，广泛用于评估语言模型的隐私风险。现有的大多数攻击依赖于这样一个观察结果，即模型倾向于将更高的概率分配给训练样本而非非训练点。然而，对模型分数的简单阈值设定往往导致高误报率，因为它没有考虑样本的内在复杂性。最近的研究表明，基于参考模型的攻击可以将模型分数与在类似数据上训练的参考模型获得的分数进行比较，可以显著提高MIAs的性能。然而，为了训练参考模型，这种攻击的做法是假定敌方知道与原始训练数据密切相似的样本，这是一个强假设。因此，我们在更现实的情况下，假定攻击者只能访问有限的邻域样本，研究了这些攻击的性能。我们提出了两种新的攻击策略，利用语言数据的内在结构，可以用于评估在更现实的成员推断场景下的语言模型的隐私风险。我们的实验表明，我们的攻击在几个公开可用的数据集上是有效的，其中包括文本分类、自然语言推理和对话生成，并突显了语言模型在实际应用中的潜在隐私风险。

    Membership Inference attacks (MIAs) aim to predict whether a data sample was present in the training data of a machine learning model or not, and are widely used for assessing the privacy risks of language models. Most existing attacks rely on the observation that models tend to assign higher probabilities to their training samples than non-training points. However, simple thresholding of the model score in isolation tends to lead to high false-positive rates as it does not account for the intrinsic complexity of a sample. Recent work has demonstrated that reference-based attacks which compare model scores to those obtained from a reference model trained on similar data can substantially improve the performance of MIAs. However, in order to train reference models, attacks of this kind make the strong and arguably unrealistic assumption that an adversary has access to samples closely resembling the original training data. Therefore, we investigate their performance in more realistic sce
    
[^24]: 驯服AI Bot：大型语言模型中神经状态的可控性

    Taming AI Bots: Controllability of Neural States in Large Language Models. (arXiv:2305.18449v1 [cs.AI])

    [http://arxiv.org/abs/2305.18449](http://arxiv.org/abs/2305.18449)

    本文提出了一个问题，是否可以通过适当选择提示，控制AI bot到达任何状态，而研究表明训练良好的Bot能几乎确定地到达任何意义子集，具有可控性。

    

    我们解决了一个问题，即是否可以通过适当选择提示，将AI bot 控制到任何状态。为此，我们首先介绍了一个正式的“意义”定义，便于分析。然后，我们通过一些条件，表征了大型语言模型（LLM）所显然训练的“有意义的数据”和“训练良好的LLM”。虽然训练良好的LLM构建了一个欧几里得意义嵌入空间，但是意义本身并不形成一个向量（线性）子空间，而是一个商空间。我们然后表征了某个输入提示的状态所能到达的意义子集，并展示了训练良好的Bot能够到达任何意义，尽管概率很小。我们接着引入了更强的可控性概念，即“几乎确定可达性”，并展示了限制到意义空间时，AI bot是可控的。我们在引入功能特征的情况下这样做了。

    We tackle the question of whether an agent can, by suitable choice of prompts, control an AI bot to any state. To that end, we first introduce a formal definition of ``meaning'' that is amenable to analysis. Then, we characterize ``meaningful data'' on which large language models (LLMs) are ostensibly trained, and ``well-trained LLMs'' through conditions that are largely met by today's LLMs. While a well-trained LLM constructs an embedding space of meanings that is Euclidean, meanings themselves do not form a vector (linear) subspace, but rather a quotient space within. We then characterize the subset of meanings that can be reached by the state of the LLMs for some input prompt, and show that a well-trained bot can reach any meaning albeit with small probability. We then introduce a stronger notion of controllability as {\em almost certain reachability}, and show that, when restricted to the space of meanings, an AI bot is controllable. We do so after introducing a functional characte
    
[^25]: 采用双向语言模型进行语义分割，提高长篇音频识别的准确性

    Semantic Segmentation with Bidirectional Language Models Improves Long-form ASR. (arXiv:2305.18419v1 [cs.CL])

    [http://arxiv.org/abs/2305.18419](http://arxiv.org/abs/2305.18419)

    本研究提出一种采用双向语言模型进行语义分割的方法，可以有效提高长篇音频识别的准确性和速度。

    

    我们提出了一种通过分离发音中的语义完整句子实现长篇音频分割的方法，这可以防止ASR解码器处理远距离上下文的无效信息，同时避免它错过当前句子中的相关信息。在书面文本中，语义完整的句子通常由标点符号分隔；但不幸的是，实际口语中的发音很少包含标点符号。因此，我们通过提炼从书面标点文本中训练的双向语言模型（LM）中的标点符号知识来解决这个问题。我们将从LM教师提炼的分割器与以其他方法使用基于声学停顿的教师提炼的分割器进行了比较，并在流媒体ASR管道上进行了测试。我们的分割器在YouTube字幕任务中实现了3.2%的相对WER增益以及60ms中位段末端延迟的减少。

    We propose a method of segmenting long-form speech by separating semantically complete sentences within the utterance. This prevents the ASR decoder from needlessly processing faraway context while also preventing it from missing relevant context within the current sentence. Semantically complete sentence boundaries are typically demarcated by punctuation in written text; but unfortunately, spoken real-world utterances rarely contain punctuation. We address this limitation by distilling punctuation knowledge from a bidirectional teacher language model (LM) trained on written, punctuated text. We compare our segmenter, which is distilled from the LM teacher, against a segmenter distilled from a acoustic-pause-based teacher used in other works, on a streaming ASR pipeline. The pipeline with our segmenter achieves a 3.2% relative WER gain along with a 60 ms median end-of-segment latency reduction on a YouTube captioning task.
    
[^26]: 理解乳腺癌生存：在多组学数据上利用因果关系和语言模型

    Understanding Breast Cancer Survival: Using Causality and Language Models on Multi-omics Data. (arXiv:2305.18410v1 [cs.LG])

    [http://arxiv.org/abs/2305.18410](http://arxiv.org/abs/2305.18410)

    本文旨在探究多组学数据在因果推断、基因组学和乳腺癌中的应用，利用大规模语言模型辅助解决因果推断方法的评估问题，突出了如何利用因果关系分析基因组扰动对乳腺癌患者生存的影响。

    

    随着医疗保健领域对更易用和可解释的机器学习模型的需求增加，发展和利用因果推断算法以通过分析观测数据发现因果关系变得越来越重要。可解释的方法有助于临床医生和生物学家预测疾病预后并建议适当的治疗方法。然而，在因果推断、基因组学和乳腺癌交叉领域上极少进行研究，我们旨在填补这一空白。此外，真实数据上对因果推断方法的评估普遍极为困难，因为地面真实的因果关系通常是未知的。因此，在本文中，我们还提议使用大规模语言模型来解决评估问题。具体来说，我们利用合适的因果推断算法来研究基因组中各种扰动如何影响乳腺癌患者的生存。我们使用了三种主要的因果推断方法。

    The need for more usable and explainable machine learning models in healthcare increases the importance of developing and utilizing causal discovery algorithms, which aim to discover causal relations by analyzing observational data. Explainable approaches aid clinicians and biologists in predicting the prognosis of diseases and suggesting proper treatments. However, very little research has been conducted at the crossroads between causal discovery, genomics, and breast cancer, and we aim to bridge this gap. Moreover, evaluation of causal discovery methods on real data is in general notoriously difficult because ground-truth causal relations are usually unknown, and accordingly, in this paper, we also propose to address the evaluation problem with large language models. In particular, we exploit suitable causal discovery algorithms to investigate how various perturbations in the genome can affect the survival of patients diagnosed with breast cancer. We used three main causal discovery 
    
[^27]: 基于大语言模型的多项选择题答案确认预测研究

    Conformal Prediction with Large Language Models for Multi-Choice Question Answering. (arXiv:2305.18404v1 [cs.CL])

    [http://arxiv.org/abs/2305.18404](http://arxiv.org/abs/2305.18404)

    本研究探讨了如何利用符合性预测技术，在多项选择题回答任务中为语言模型提供不确定性量化。我们发现符合性预测的不确定性估计与预测准确性密切相关。

    

    随着大型语言模型的广泛开发，对它们进行健壮的不确定性量化技术将成为它们在高风险场景下安全部署的关键。本研究探讨了如何利用符合性预测技术，在多项选择题回答任务中为语言模型提供不确定性量化。我们发现符合性预测的不确定性估计与预测准确性密切相关。这种观察对于下游应用，如选择性分类和过滤低质量预测，可能会有用。我们还研究了符合性预测对于超出主题的问题的交换性假设，这可能是许多实际应用的更为现实的场景。本研究为在需要可靠保证错误率的安全关键情况下更加值得信赖和可靠地使用大型语言模型做出了贡献。

    As large language models continue to be widely developed, robust uncertainty quantification techniques will become crucial for their safe deployment in high-stakes scenarios. In this work, we explore how conformal prediction can be used to provide uncertainty quantification in language models for the specific task of multiple-choice question-answering. We find that the uncertainty estimates from conformal prediction are tightly correlated with prediction accuracy. This observation can be useful for downstream applications such as selective classification and filtering out low-quality predictions. We also investigate the exchangeability assumption required by conformal prediction to out-of-subject questions, which may be a more realistic scenario for many practical applications. Our work contributes towards more trustworthy and reliable usage of large language models in safety-critical situations, where robust guarantees of error rate are required.
    
[^28]: LLM可以理解加密提示：面向隐私计算友好的Transformers

    LLMs Can Understand Encrypted Prompt: Towards Privacy-Computing Friendly Transformers. (arXiv:2305.18396v1 [cs.LG])

    [http://arxiv.org/abs/2305.18396](http://arxiv.org/abs/2305.18396)

    本文中，研究人员通过使用隐私计算友好的近似方法替换transformer架构中计算和通信密集的运算符，实现了大幅降低私有推断成本的效果，并在保持准确性的前提下实现了计算加速和通信开销降低。

    

    先前的研究尝试在服务器客户端环境中为基于transformer的大型语言模型 (LLMs) 构建私有推断框架，其中服务器持有模型参数，客户端输入私有数据进行推断。然而，当私有输入通过原始LLMs进行前向传播时，这些框架会产生显着的开销。在本文中，我们展示了通过用隐私计算友好的近似替换transformer架构中计算和通信密集的运算符可以大大降低私有推断成本，对模型性能的影响微乎其微。与最新的Iron（NeurIPS 2022）相比，我们的隐私计算友好的模型推断管道在计算上实现了$5 \times$的加速，在通信开销上实现了80\%的降低，同时几乎保持了相同的准确性。

    Prior works have attempted to build private inference frameworks for transformer-based large language models (LLMs) in a server-client setting, where the server holds the model parameters and the client inputs the private data for inference. However, these frameworks impose significant overhead when the private inputs are forward propagated through the original LLMs. In this paper, we show that substituting the computation- and communication-heavy operators in the transformer architecture with privacy-computing friendly approximations can greatly reduce the private inference costs with minor impact on model performance. Compared to the state-of-the-art Iron (NeurIPS 2022), our privacy-computing friendly model inference pipeline achieves a $5\times$ acceleration in computation and an 80\% reduction in communication overhead, while retaining nearly identical accuracy.
    
[^29]: 知识增强的推理蒸馏：面向知识密集型任务的小型语言模型

    Knowledge-Augmented Reasoning Distillation for Small Language Models in Knowledge-Intensive Tasks. (arXiv:2305.18395v1 [cs.CL])

    [http://arxiv.org/abs/2305.18395](http://arxiv.org/abs/2305.18395)

    本论文提出了一种KARD方法，可以通过向小型语言模型中加入从外部知识库检索到的增强知识来解决知识密集型推理任务中小型语言模型记忆能力有限的问题。

    

    大型语言模型在需要复合知识理解的知识密集型推理任务中表现出了良好的性能。但是，由于计算要求高且涉及数据隐私，将此类模型部署到现实世界的应用中可能会具有挑战性。以往的研究专注于通过微调具有标记数据或蒸馏大型语言模型来构建任务特定的小型语言模型，但是由于小型语言模型在记忆所需知识方面的能力有限，这些方法不适用于知识密集型推理任务。在理论分析的基础上，我们提出了一种名为知识增强的推理蒸馏 (KARD) 的新方法，该方法微调小型语言模型以生成从外部知识库检索到的增强知识的依据。此外，我们还提出了一个神经重排器，用于获得与依据生成相关的文档。我们实证表明，KARD在三项知识密集型任务上显着优于以前的方法，并且在模型尺寸相同的情况下可以达到与LLMs可比较的结果。

    Large Language Models (LLMs) have shown promising performance in knowledge-intensive reasoning tasks that require a compound understanding of knowledge. However, deployment of the LLMs in real-world applications can be challenging due to their high computational requirements and concerns on data privacy. Previous studies have focused on building task-specific small language models (LMs) by fine-tuning them with labeled data or distilling LLMs. However, these approaches are ill-suited for knowledge-intensive reasoning tasks due to the limited capacity of small LMs in memorizing the knowledge required. Motivated by our theoretical analysis on memorization, we propose Knowledge-Augmented Reasoning Distillation (KARD), a novel method that fine-tunes small LMs to generate rationales with augmented knowledge retrieved from an external knowledge base. Moreover, we further propose a neural reranker to obtain documents relevant to rationale generation. We empirically show that KARD significantl
    
[^30]: MemeGraphs: 将网络文化表情包与知识图谱相连

    MemeGraphs: Linking Memes to Knowledge Graphs. (arXiv:2305.18391v1 [cs.LG])

    [http://arxiv.org/abs/2305.18391](http://arxiv.org/abs/2305.18391)

    该论文提出了一种使用场景图和知识图谱结构化表达网络文化表情包的方法，并将其用于分类。结果显示该方法相比使用学习表达式的模型有所改善。

    

    网络文化表情包是一种在社交媒体和互联网上流行的传播趋势和观点的形式，结合了图像和文本的模式。它们可以表达幽默和讽刺，但也可能含有冒犯性的内容。自动分析和分类网络文化表情包具有挑战性，因为其解释依赖于对视觉元素、语言和背景知识的理解。因此，重要的是有意义地表示这些来源以及它们之间的交互，以便将表情包作为整体分类。在这项工作中，我们提出使用场景图作为表示图像中物体及其视觉关系的结构化表达方式，并将知识图谱作为网络文化表情包分类的结构化表示，使用基于Transformer的架构。我们将我们的方法与ImgBERT进行比较，后者使用仅学习（而不是结构化）的表达式进行多模式建模，我们观察到始终有所改善。我们还提供了一个具有人工图注释的数据集，供比较。

    Memes are a popular form of communicating trends and ideas in social media and on the internet in general, combining the modalities of images and text. They can express humor and sarcasm but can also have offensive content. Analyzing and classifying memes automatically is challenging since their interpretation relies on the understanding of visual elements, language, and background knowledge. Thus, it is important to meaningfully represent these sources and the interaction between them in order to classify a meme as a whole. In this work, we propose to use scene graphs, that express images in terms of objects and their visual relations, and knowledge graphs as structured representations for meme classification with a Transformer-based architecture. We compare our approach with ImgBERT, a multimodal model that uses only learned (instead of structured) representations of the meme, and observe consistent improvements. We further provide a dataset with human graph annotations that we compa
    
[^31]: 预训练Transformers中的自发模块化

    Emergent Modularity in Pre-trained Transformers. (arXiv:2305.18390v1 [cs.CL])

    [http://arxiv.org/abs/2305.18390](http://arxiv.org/abs/2305.18390)

    本论文研究了预训练Transformers中的自发模块化现象，发现神经元可以进行功能专业化，并通过聚类建立起模块化结构，此结构可被有效扰动。

    

    本论文研究了预训练Transformers中的模块化特征，这是人脑中常见的特点，被认为对于普遍智能至关重要。本文主要考虑了模块化的两个主要特征：（1）神经元的功能专业化：我们评估了每个神经元是否主要专业化于某一功能，结果表明是的。（2）基于功能聚类的神经元分组：我们探究了将神经元按功能分组的结构寻找方法，每个模块均为其相应功能工作。鉴于可能存在的大量结构，我们将重点放在了分层专家模型身上，并将神经元划分为专家，通常为不同的输入激活不同的专家。实验结果表明存在功能专家，聚集了某一功能的神经元。此外，扰动功能专家的激活显著影响了相应的f键

    This work examines the presence of modularity in pre-trained Transformers, a feature commonly found in human brains and thought to be vital for general intelligence. In analogy to human brains, we consider two main characteristics of modularity: (1) functional specialization of neurons: we evaluate whether each neuron is mainly specialized in a certain function, and find that the answer is yes. (2) function-based neuron grouping: we explore finding a structure that groups neurons into modules by function, and each module works for its corresponding function. Given the enormous amount of possible structures, we focus on Mixture-of-Experts as a promising candidate, which partitions neurons into experts and usually activates different experts for different inputs. Experimental results show that there are functional experts, where clustered are the neurons specialized in a certain function. Moreover, perturbing the activations of functional experts significantly affects the corresponding f
    
[^32]: KAFA：基于知识增强特征自适应的视觉语言模型重新思考图像广告理解

    KAFA: Rethinking Image Ad Understanding with Knowledge-Augmented Feature Adaptation of Vision-Language Models. (arXiv:2305.18373v1 [cs.CV])

    [http://arxiv.org/abs/2305.18373](http://arxiv.org/abs/2305.18373)

    本文是第一篇通过预训练的VLMs实证研究图像广告理解的文章。我们提出了一种基于知识增强特征自适应的策略，有效地融合了图像广告的多模态信息，并通过真实世界实体的知识进一步增强了模型。研究对广告行业具有广泛的相关性。

    

    图像广告理解是一个非常关键的任务，具有广泛的实际应用。尽管有各种挑战，包括涉及非典型场景，真实世界实体，并对场景文本进行推理等，但如何解释图像广告相对少有研究，特别是在基于卓越的泛化性和适应性的基础视觉语言模型（VLMs）时代。在本文中，我们通过预训练的VLMs的视角，进行了第一次实证研究图像广告理解。我们评估并揭示了将这些VLMs适应于图像广告理解的实际挑战。我们提出了一种简单的特征自适应策略，以有效地融合图像广告的多模态信息，并通过真实世界实体的知识进一步增强它。我们希望我们的研究引起更多人对广告行业广泛相关的图像广告理解的关注。

    Image ad understanding is a crucial task with wide real-world applications. Although highly challenging with the involvement of diverse atypical scenes, real-world entities, and reasoning over scene-texts, how to interpret image ads is relatively under-explored, especially in the era of foundational vision-language models (VLMs) featuring impressive generalizability and adaptability. In this paper, we perform the first empirical study of image ad understanding through the lens of pre-trained VLMs. We benchmark and reveal practical challenges in adapting these VLMs to image ad understanding. We propose a simple feature adaptation strategy to effectively fuse multimodal information for image ads and further empower it with knowledge of real-world entities. We hope our study draws more attention to image ad understanding which is broadly relevant to the advertising industry.
    
[^33]: GPT 模型在化学领域到底有怎样的应用？八个任务的综合基准测试。

    What indeed can GPT models do in chemistry? A comprehensive benchmark on eight tasks. (arXiv:2305.18365v1 [cs.CL])

    [http://arxiv.org/abs/2305.18365](http://arxiv.org/abs/2305.18365)

    本文建立了包括 8 个实际化学任务的综合基准测试，有力地证明了 LLM 在实际化学中的能力。

    

    具有强大自然语言处理能力的大型语言模型已被广泛应用于科学、金融和软件工程等领域。但是，LLM 是否有能力推动化学领域的进展仍不清楚。本文建立了包含 8 个实际化学任务的综合基准测试，包括名称预测、属性预测、产量预测、反应预测、反合成（从产物预测反应物）、基于文本的分子设计、分子字幕和试剂选择。我们使用广泛认可的数据集，包括 BBBP、Tox21、PubChem、USPTO 和 ChEBI，有力地证明了 LLM 在实际化学中的能力。在精心选择的示例中，对三种 GPT 模型（GPT-4、GPT-3.5 和 DaVinci-003）在零样本和少样本有上下文学习的设置中进行了评估。

    Large Language Models (LLMs) with strong abilities in natural language processing tasks have emerged and have been rapidly applied in various kinds of areas such as science, finance and software engineering. However, the capability of LLMs to advance the field of chemistry remains unclear. In this paper,we establish a comprehensive benchmark containing 8 practical chemistry tasks, including 1) name prediction, 2) property prediction, 3) yield prediction, 4) reaction prediction, 5) retrosynthesis (prediction of reactants from products), 6)text-based molecule design, 7) molecule captioning, and 8) reagent selection. Our analysis draws on widely recognized datasets including BBBP, Tox21, PubChem, USPTO, and ChEBI, facilitating a broad exploration of the capacities of LLMs within the context of practical chemistry. Three GPT models (GPT-4, GPT-3.5,and Davinci-003) are evaluated for each chemistry task in zero-shot and few-shot in-context learning settings with carefully selected demonstrat
    
[^34]: 基于语义交互的交互式深度学习方法

    DeepSI: Interactive Deep Learning for Semantic Interaction. (arXiv:2305.18357v1 [cs.LG])

    [http://arxiv.org/abs/2305.18357](http://arxiv.org/abs/2305.18357)

    本文提出了一种基于语义交互的交互式深度学习方法，可以高效地学习用户和任务特定的数据表示，改善视觉分析应用中的语义交互，并通过比较验证了该方法的优势。

    

    本文提出了一种新颖的交互式深度学习方法，旨在改善视觉分析应用中的语义交互。语义交互推断分析人员在感知过程中的精确意图取决于底层数据表示的质量。我们提出了$\text{DeepSI}_{\text{finetune}}$框架，将深度学习集成到人在交互式感知管道中，具有两个重要属性。首先，深度学习从原始数据中提取有意义的表示，提高了语义交互推断的质量。其次，利用语义交互来微调深度学习表示，进一步提高了语义交互推断的质量。人机交互和深度学习之间的反馈循环使得可以高效地学习用户和任务特定的表示。为了评估将深度学习嵌入到语义交互循环中的优势，我们比较了$\text{DeepSI}_{\te

    In this paper, we design novel interactive deep learning methods to improve semantic interactions in visual analytics applications. The ability of semantic interaction to infer analysts' precise intents during sensemaking is dependent on the quality of the underlying data representation. We propose the $\text{DeepSI}_{\text{finetune}}$ framework that integrates deep learning into the human-in-the-loop interactive sensemaking pipeline, with two important properties. First, deep learning extracts meaningful representations from raw data, which improves semantic interaction inference. Second, semantic interactions are exploited to fine-tune the deep learning representations, which then further improves semantic interaction inference. This feedback loop between human interaction and deep learning enables efficient learning of userand task-specific representations. To evaluate the advantage of embedding the deep learning within the semantic interaction loop, we compare $\text{DeepSI}_{\te
    
[^35]: LLM和抽象推理语料库：成功、失败与基于对象表示的重要性

    LLMs and the Abstraction and Reasoning Corpus: Successes, Failures, and the Importance of Object-based Representations. (arXiv:2305.18354v1 [cs.CL])

    [http://arxiv.org/abs/2305.18354](http://arxiv.org/abs/2305.18354)

    本文通过分析GPT模型在抽象推理语料库上的表现，发现GPT在抽象推理任务中存在需要核心概念“核心知识”的限制。通过使用基于对象的表示方法和新的1D-ARC基准，GPT在抽象推理任务中取得了较好的表现。

    

    一个大型语言模型（LLM）能否解决简单的抽象推理问题？我们通过系统地分析GPT在抽象推理语料库（ARC）上的表现来探索这个广泛的问题，这是一个代表性的基准，从有限的例子中要求我们有些关于概念（如对象、目标状态、计数和基本几何）的“核心知识”以解决问题。当使用文本编码对二维输入输出网格的ARC任务进行编码时，GPT-4仅解决了50个最简单的任务中的13个。我们的失败分析显示，GPT-4识别对象并推理它们的能力受到表示任务中对象的文本的顺序性的显著影响。为了验证这个假设，我们设计了一个新的基准，1D-ARC，它由更有利于基于GPT的推理的一维（类似数组）任务组成，在这些任务上，GPT的表现确实比在（2D）ARC上更好。为了减轻这个问题，我们提出了一种新的基于对象的编码方案，它保留了对象之间的基本空间关系并实现了更好的推理。使用这种编码，GPT-4在ARC上的成功率大大提高，达到了45/50。我们的工作强调了使用基于对象的表示方法进行抽象推理任务的重要性，并揭示了LLM基于推理系统的局限性和机遇。

    Can a Large Language Model (LLM) solve simple abstract reasoning problems? We explore this broad question through a systematic analysis of GPT on the Abstraction and Reasoning Corpus (ARC), a representative benchmark of abstract reasoning ability from limited examples in which solutions require some "core knowledge" of concepts such as objects, goal states, counting, and basic geometry. GPT-4 solves only 13/50 of the most straightforward ARC tasks when using textual encodings for their two-dimensional input-output grids. Our failure analysis reveals that GPT-4's capacity to identify objects and reason about them is significantly influenced by the sequential nature of the text that represents an object within a text encoding of a task. To test this hypothesis, we design a new benchmark, the 1D-ARC, which consists of one-dimensional (array-like) tasks that are more conducive to GPT-based reasoning, and where it indeed performs better than on the (2D) ARC. To alleviate this issue, we prop
    
[^36]: 实现开放世界产品属性挖掘：基于轻度监督方法的研究

    Towards Open-World Product Attribute Mining: A Lightly-Supervised Approach. (arXiv:2305.18350v1 [cs.LG])

    [http://arxiv.org/abs/2305.18350](http://arxiv.org/abs/2305.18350)

    该研究提出了一种用于电子商务产品属性挖掘的新任务设置，可以利用高质量的种子属性集合轻度监督并自动发现新的属性类型。通过自我监督启发式和无监督潜在属性，该方法能够以额外的隐含语义信号作为辅助监督，将现有类型的属性扩展最多12倍，并成功发掘了39％的新属性值。

    

    我们提出了一种新的电子商务产品属性挖掘任务设置，用于提取开放世界属性，同时减少人工干预。我们的监督来自于现有资源中引导的高质量种子属性集合，旨在扩展现有种子类型的属性词汇，并通过自动方式发现任何新的属性类型。我们创建了一个新数据集以支持我们的设置，并提出了特定于受限监督的Amacer方法。尤其是，由于那些未见过的新属性没有直接监督，我们的新颖公式利用了自我监督启发式和无监督潜在属性，利用产品上下文获得额外的隐含语义信号作为辅助监督。实验表明，我们的方法在F1值上超过了各种基线方法12个百分点，使现有类型的属性大大扩展了最多12倍，并且发现新属性值的能力达到了39％。

    We present a new task setting for attribute mining on e-commerce products, serving as a practical solution to extract open-world attributes without extensive human intervention. Our supervision comes from a high-quality seed attribute set bootstrapped from existing resources, and we aim to expand the attribute vocabulary of existing seed types, and also to discover any new attribute types automatically. A new dataset is created to support our setting, and our approach Amacer is proposed specifically to tackle the limited supervision. Especially, given that no direct supervision is available for those unseen new attributes, our novel formulation exploits self-supervised heuristic and unsupervised latent attributes, which attains implicit semantic signals as additional supervision by leveraging product context. Experiments suggest that our approach surpasses various baselines by 12 F1, expanding attributes of existing types significantly by up to 12 times, and discovering values from 39%
    
[^37]: 可视化编程中神经任务合成

    Neural Task Synthesis for Visual Programming. (arXiv:2305.18342v1 [cs.LG])

    [http://arxiv.org/abs/2305.18342](http://arxiv.org/abs/2305.18342)

    该论文提出了一种基于神经符号技术的可视化编程任务合成方法NeurTaskSyn。该方法能够针对规范中给出的解决方案代码所需要的编程概念和对可视化任务的限制，自动生成编程任务。

    

    通过合成新的内容，生成式神经模型在增强编程教育方面具有巨大的潜力。我们旨在设计神经模型，能够根据可视化编程环境下给定的规范自动生成编程任务。尽管近年来像 GPT-4 这样的大型生成模型获得了成功，但我们的初步结果显示，这些模型在合成可视化编程任务方面效果不佳，并且在逻辑和空间推理方面存在困难。我们提出了一种新颖的神经符号技术 NeurTaskSyn，该技术能够针对规范中给出的解决方案代码所需要的编程概念和对可视化任务的限制，合成编程任务。NeurTaskSyn 由两个部分构成：第一个部分通过模仿学习程序进行训练，生成可能的解决方案代码，第二个部分通过强化学习程序进行训练，指导底层符号执行引擎生成可视化任务。

    Generative neural models hold great promise in enhancing programming education by synthesizing new content for students. We seek to design neural models that can automatically generate programming tasks for a given specification in the context of visual programming domains. Despite the recent successes of large generative models like GPT-4, our initial results show that these models are ineffective in synthesizing visual programming tasks and struggle with logical and spatial reasoning. We propose a novel neuro-symbolic technique, NeurTaskSyn, that can synthesize programming tasks for a specification given in the form of desired programming concepts exercised by its solution code and constraints on the visual task. NeurTaskSyn has two components: the first component is trained via imitation learning procedure to generate possible solution codes, and the second component is trained via reinforcement learning procedure to guide an underlying symbolic execution engine that generates visua
    
[^38]: 在主流媒体上绘制ChatGPT的地图：情感分析和词频分析的早期量化视角。

    Mapping ChatGPT in Mainstream Media: Early Quantitative Insights through Sentiment Analysis and Word Frequency Analysis. (arXiv:2305.18340v1 [cs.CY])

    [http://arxiv.org/abs/2305.18340](http://arxiv.org/abs/2305.18340)

    本文量化分析了主流媒体对ChatGPT和人工智能的报道趋势和情感态度，发现人们普遍对其持积极态度。然而，主题的词频分析显示，大型科技问题和行为者得到了高度关注，而就业、多样性、伦理、版权、性别和女性等主题则表现不足或完全缺失。本文呼吁在人工智能领域需要更加多元和细致的媒体发言。

    

    ChatGPT是一个由人工智能驱动的聊天机器人，其用户获取和普及性的指数增长，伴随着广泛的主流媒体报道。本文通过对与ChatGPT和人工智能主题相关的10,902条主流新闻标题语料进行文本挖掘和NLP方法的定量数据分析，呈现出早期趋势和情感的发现。情感分析的结果显示，ChatGPT和人工智能在主流媒体中的好感度高于反感度。关于词频结果，65%以上的高频词集中在大型科技问题和行为者上，而就业、多样性、伦理、版权、性别和女性等主题则表现不足或完全缺失，仅占总语料的6%。本文是对主流媒体报道ChatGPT和人工智能的权力结构进行的批判性分析，并强调在人工智能领域需要更加多元和细致的媒体发言。

    The exponential growth in user acquisition and popularity of ChatGPT, an artificial intelligence(AI) powered chatbot, was accompanied by widespread mainstream media coverage. This article presents a quantitative data analysis of the early trends and sentiments revealed by conducting text mining and NLP methods onto a corpus of 10,902 mainstream news headlines related to the subject of ChatGPT and artificial intelligence, from the launch of ChatGPT in November 2022 to March 2023. The findings revealed in sentiment analysis, ChatGPT and artificial intelligence, were perceived more positively than negatively in the mainstream media. In regards to word frequency results, over sixty-five percent of the top frequency words were focused on Big Tech issues and actors while topics such as jobs, diversity, ethics, copyright, gender and women were poorly represented or completely absent and only accounted for six percent of the total corpus. This article is a critical analysis into the power stru
    
[^39]: ChatGPT：AI生成内容的挑战与解决方案综述

    A Survey on ChatGPT: AI-Generated Contents, Challenges, and Solutions. (arXiv:2305.18339v1 [cs.CY])

    [http://arxiv.org/abs/2305.18339](http://arxiv.org/abs/2305.18339)

    本论文探讨了AI生成内容的工作原理、安全与隐私威胁、现状和未来挑战，并提供了针对这些问题的最新解决方案。

    

    随着大型人工智能模型比如ChatGPT的普及使用，AI生成内容（AIGC）日益受到关注，正在引领内容创作和知识表示方式实现范式转变。AIGC利用生成式大型AI算法来辅助或替代人类，根据用户提供的提示以更快的速度和更低的成本创建大规模、高质量和类人的内容。尽管在AIGC方面取得了显著进展，但安全、隐私、伦理和法律挑战仍需解决。本文深入调查了AIGC范式的工作原理、安全和隐私威胁、最新解决方案和未来挑战。具体而言，我们首先探讨了AIGC的技术实现、总体架构，并讨论了其工作模式和关键特征。然后，我们调查了针对AIGC的安全和隐私威胁分类法，并强调了GPT和AIGC技术的伦理和社会影响。接下来，我们全面回顾了现有的解决方案，以解决已确定的挑战，并讨论了AIGC领域未来的研究方向。最后，我们总结了我们的发现，并提出了一些未来发展AIGC的潜在研究方向。

    With the widespread use of large artificial intelligence (AI) models such as ChatGPT, AI-generated content (AIGC) has garnered increasing attention and is leading a paradigm shift in content creation and knowledge representation. AIGC uses generative large AI algorithms to assist or replace humans in creating massive, high-quality, and human-like content at a faster pace and lower cost, based on user-provided prompts. Despite the recent significant progress in AIGC, security, privacy, ethical, and legal challenges still need to be addressed. This paper presents an in-depth survey of working principles, security and privacy threats, state-of-the-art solutions, and future challenges of the AIGC paradigm. Specifically, we first explore the enabling technologies, general architecture of AIGC, and discuss its working modes and key characteristics. Then, we investigate the taxonomy of security and privacy threats to AIGC and highlight the ethical and societal implications of GPT and AIGC tec
    
[^40]: #REVAL：一种用于hashtag推荐的语义评估框架

    #REVAL: a semantic evaluation framework for hashtag recommendation. (arXiv:2305.18330v1 [cs.IR])

    [http://arxiv.org/abs/2305.18330](http://arxiv.org/abs/2305.18330)

    #REVAL是一种新颖的语义评估框架，用于解决传统评估方法无法考虑推荐和实际hashtag之间语义相关性问题。实验证明#REVAL在捕捉语义相关性方面是有效的。

    

    在许多在线社交网络系统中，自动评估hashtag推荐模型是一项基本任务。传统的评估方法是首先比较算法推荐的hashtag与实际的hashtag的精确对应关系，然后使用精确匹配的数量计算命中率、命中比率、精确度、召回率或F1分数。然而，这种评估方式忽略了推荐和实际hashtag之间的语义相关性。为了解决这个问题，我们提出了一种新颖的语义评估框架#REval，它包括一个称为BERTag的内部模块，可自动学习hashtag嵌入。我们使用提出的#REval-hit-ratio度量标准，研究了#REval框架在不同的词嵌入方法和推荐中的同义词和hashtag数量下的性能。在两个基准数据集上的实验表明，我们提出的框架在捕捉推荐和实际hashtag之间的语义相关性方面是有效的。

    Automatic evaluation of hashtag recommendation models is a fundamental task in many online social network systems. In the traditional evaluation method, the recommended hashtags from an algorithm are firstly compared with the ground truth hashtags for exact correspondences. The number of exact matches is then used to calculate the hit rate, hit ratio, precision, recall, or F1-score. This way of evaluating hashtag similarities is inadequate as it ignores the semantic correlation between the recommended and ground truth hashtags. To tackle this problem, we propose a novel semantic evaluation framework for hashtag recommendation, called #REval. This framework includes an internal module referred to as BERTag, which automatically learns the hashtag embeddings. We investigate on how the #REval framework performs under different word embedding methods and different numbers of synonyms and hashtags in the recommendation using our proposed #REval-hit-ratio measure. Our experiments of the propo
    
[^41]: 基于预训练语言模型的正则表达式增强的领域迁移主题分类：金融领域中的应用

    Regex-augmented Domain Transfer Topic Classification based on a Pre-trained Language Model: An application in Financial Domain. (arXiv:2305.18324v1 [cs.CL])

    [http://arxiv.org/abs/2305.18324](http://arxiv.org/abs/2305.18324)

    本文介绍了将正则表达式模式作为领域知识特征与领域特定文本一起用于微调预训练语言模型的方法，通过在金融领域中实验，证明这种方法可以改善下游文本分类任务的表现。

    

    使用大型预训练语言模型进行下游任务的常见方法是使用额外的层进行微调。但当下游领域是一个专业领域而大型语言模型已经在通用语料库上进行了预训练时，这种方法可能效果不佳。本文讨论了在微调过程中使用正则表达式模式作为领域知识的特征，以及领域特定文本。我们在实际生产数据上的实验表明，与仅在领域特定文本上进行微调相比，这种微调方法改善了下游文本分类任务的表现。我们还展示了使用注意力网络进行微调比简单的线性层获得更好的结果。

    A common way to use large pre-trained language models for downstream tasks is to fine tune them using additional layers. This may not work well if downstream domain is a specialized domain whereas the large language model has been pre-trained on a generic corpus. In this paper, we discuss the use of regular expression patterns employed as features for domain knowledge during the process of fine tuning, in addition to domain specific text. Our experiments on real scenario production data show that this method of fine tuning improves the downstream text classification tasks as compared to fine tuning only on domain specific text. We also show that the use of attention network for fine tuning improves results compared to simple linear layers.
    
[^42]: ReWOO：将推理与观察分离，实现高效增强语言模型

    ReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models. (arXiv:2305.18323v1 [cs.CL])

    [http://arxiv.org/abs/2305.18323](http://arxiv.org/abs/2305.18323)

    ReWOO是一种将推理过程与外部观察分离的模块化范式，从而可以减少标记消耗并提高性能。

    

    增强语言模型（ALMs）将大型语言模型（LLMs）的推理能力与允许知识检索和行动执行的工具相结合。现有的ALM系统以交错方式触发LLM思考过程，同时从这些工具中提取观察。本研究首次提出了一种模块化范式ReWOO（Without Observation Reasoning），将推理过程与外部观察分离，从而显著减少标记消耗。在六个公共NLP基准测试和一个策划数据集中进行全面评估，结果显示采用我们提出的方法可以显著提高性能。

    Augmented Language Models (ALMs) blend the reasoning capabilities of Large Language Models (LLMs) with tools that allow for knowledge retrieval and action execution. Existing ALM systems trigger LLM thought processes while pulling observations from these tools in an interleaved fashion. Specifically, an LLM reasons to call an external tool, gets halted to fetch the tool's response, and then decides the next action based on all preceding response tokens. Such a paradigm, though straightforward and easy to implement, often leads to huge computation complexity from redundant prompts and repeated execution. This study addresses such challenges for the first time, proposing a modular paradigm ReWOO (Reasoning WithOut Observation) that detaches the reasoning process from external observations, thus significantly reducing token consumption. Comprehensive evaluations across six public NLP benchmarks and a curated dataset reveal consistent performance enhancements with our proposed methodology.
    
[^43]: REFinD: 金融领域关系抽取数据集

    REFinD: Relation Extraction Financial Dataset. (arXiv:2305.18322v1 [cs.CL])

    [http://arxiv.org/abs/2305.18322](http://arxiv.org/abs/2305.18322)

    REFinD是第一个完全基于金融文档生成的关系注释的大规模数据集，并对其进行了评估，显示出在金融领域进行关系抽取的特定挑战。

    

    创建了许多用于关系抽取（RE）的数据集，以帮助下游任务，如信息检索、语义搜索、问答和文本蕴含。然而，这些数据集未能捕捉到金融领域的特定挑战，因为大多数数据集使用维基百科、基于网络的文本和新闻文章等一般知识来源编制，阻碍了在金融世界中的实际进展和采用。为了解决这个限制，我们提出了REFinD，该数据集是第一个完全基于金融文档生成的关系注释的大规模数据集，涵盖8种类型的实体对之间的22个关系和约29K个实例。我们还提供了与各种最先进模型的经验评估，作为RE任务的基准，并强调了我们的数据集所面临的挑战。我们观察到，各种最先进的深度学习模型在数字推理、关系和方向模糊等方面都存在困难。

    A number of datasets for Relation Extraction (RE) have been created to aide downstream tasks such as information retrieval, semantic search, question answering and textual entailment. However, these datasets fail to capture financial-domain specific challenges since most of these datasets are compiled using general knowledge sources such as Wikipedia, web-based text and news articles, hindering real-life progress and adoption within the financial world. To address this limitation, we propose REFinD, the first large-scale annotated dataset of relations, with $\sim$29K instances and 22 relations amongst 8 types of entity pairs, generated entirely over financial documents. We also provide an empirical evaluation with various state-of-the-art models as benchmarks for the RE task and highlight the challenges posed by our dataset. We observed that various state-of-the-art deep learning models struggle with numeric inference, relational and directional ambiguity.
    
[^44]: 认知网络科学揭示GPT-3、ChatGPT和GPT-4中的偏见：反映高中学生数学焦虑

    Cognitive network science reveals bias in GPT-3, ChatGPT, and GPT-4 mirroring math anxiety in high-school students. (arXiv:2305.18320v1 [cs.CY])

    [http://arxiv.org/abs/2305.18320](http://arxiv.org/abs/2305.18320)

    本研究通过行为forma mentis网络(BFMNs)的方法研究了先进的语言模型(GPT-3，Chat-GPT和GPT-4)对数学和STEM领域的偏见，并发现它们都倾向于将数学和STEM领域视为困难、紧张和引起焦虑。

    

    大型语言模型正在逐渐融入我们的生活。因此，了解它们输出中的偏见是很重要的，以避免持续流传有害的刻板印象。这种挑战需要开发新的基准和方法来量化情感和语义偏差，同时铭记LLMs是反映社会中普遍存在的观点和倾向的心理社会镜子。其中一种有害的负面影响是青少年全球普遍存在的数学和STEM领域的焦虑现象。在本文中，我们运用网络科学和认知心理学的方法，使用行为forma mentis网络(BFMNs)，研究了先进的LLMs，即GPT-3、Chat-GPT和GPT-4，提供的数学和STEM领域的知识，以及这些LLMs如何将数学和STEM领域与其他概念联系起来。我们使用与数学和STEM相关的提示探测神经语言模型的吞吐量获取的数据，发现GPT-3、Chat-GPT和GPT-4都倾向于将数学和STEM领域视为困难、紧张和引起焦虑，反映了高中学生数学焦虑现象。我们的结果强调了考虑LLMs中存在的偏见的重要性，并突显了利用网络科学和认知心理学开发量化这些偏见的新工具的潜力。

    Large language models are becoming increasingly integrated into our lives. Hence, it is important to understand the biases present in their outputs in order to avoid perpetuating harmful stereotypes, which originate in our own flawed ways of thinking. This challenge requires developing new benchmarks and methods for quantifying affective and semantic bias, keeping in mind that LLMs act as psycho-social mirrors that reflect the views and tendencies that are prevalent in society. One such tendency that has harmful negative effects is the global phenomenon of anxiety toward math and STEM subjects. Here, we investigate perceptions of math and STEM fields provided by cutting-edge language models, namely GPT-3, Chat-GPT, and GPT-4, by applying an approach from network science and cognitive psychology. Specifically, we use behavioral forma mentis networks (BFMNs) to understand how these LLMs frame math and STEM disciplines in relation to other concepts. We use data obtained by probing the thr
    
[^45]: 化学数据库和摘要练习的自动生成反馈

    Automated Feedback Generation for a Chemistry Database and Abstracting Exercise. (arXiv:2305.18319v1 [cs.CL])

    [http://arxiv.org/abs/2305.18319](http://arxiv.org/abs/2305.18319)

    本研究利用BERT模型，对化学数据库中摘要练习的答案结构进行反馈，该模型在学生提交的句子中将其归为三类，即背景、技术和观察，提供了一种方法对学生作业进行自动化反馈。

    

    及时的反馈对于教学和学习来说非常重要。本文描述了如何利用现成的神经网络变换器（机器学习）模型（BERT）来对摘要练习的答案结构进行反馈。在这项任务中，要求学生们从出版数据库中找到一篇文章并对其内容进行总结。数据集包括207个提交品，总共摘要了21篇来自主要文献的文章。该模型使用一个现有的数据集（约15,000个样本）进行了预训练，然后在80%的已提交数据集上进行了微调，这一步骤被认为是重要的。学生提交的句子被归为三类——背景、技术和观察——这使得可以将每个提交品的结构进行比较。通过比较学生的摘要结构以及来自PubMed数据库的大量摘要，可以发现...

    Timely feedback is an important part of teaching and learning. Here we describe how a readily available neural network transformer (machine-learning) model (BERT) can be used to give feedback on the structure of the response to an abstracting exercise where students are asked to summarise the contents of a published article after finding it from a publication database. The dataset contained 207 submissions from two consecutive years of the course, summarising a total of 21 different papers from the primary literature. The model was pre-trained using an available dataset (approx. 15,000 samples) and then fine-tuned on 80% of the submitted dataset. This fine tuning was seen to be important. The sentences in the student submissions are characterised into three classes - background, technique and observation - which allows a comparison of how each submission is structured. Comparing the structure of the students' abstract a large collection of those from the PubMed database shows that stud
    
[^46]: CDJUR-BR -- 带有精细命名实体的巴西司法文件黄金收藏

    CDJUR-BR -- A Golden Collection of Legal Document from Brazilian Justice with Fine-Grained Named Entities. (arXiv:2305.18315v1 [cs.CL])

    [http://arxiv.org/abs/2305.18315](http://arxiv.org/abs/2305.18315)

    CDJUR-BR是一份稳健的黄金收藏，包含巴西司法文件中的精细命名实体，该收藏涵盖各种法律程序文件，并有助于解决目前命名实体识别（NER）无法轻而易举地识别法律实践文本中实体的问题。

    

    对于大多数法律人工智能（Legal AI）应用程序而言，命名实体识别（NER）是一项基本任务。然而，法律实践中产生的文本涉及到的实体并非当前可用的NER轻而易举地识别。缺乏法规、判例、证据、惩罚、法律程序中人们的角色（法官、律师、受害者、被告、证人）、位置类型（犯罪地点、被告地址）等的分类。因此，仍需要一个用法律领域的精细实体进行注释的稳健的黄金收藏，涵盖法律程序的各种文件，例如请愿书、调查、投诉、决定和判决。在本文中，我们描述了巴西司法黄金收藏（CDJUR-BR）的开发，该收藏包含一组由法律文献专家注释的精细命名实体。创建CDJUR-BR遵循了自己的

    A basic task for most Legal Artificial Intelligence (Legal AI) applications is Named Entity Recognition (NER). However, texts produced in the context of legal practice make references to entities that are not trivially recognized by the currently available NERs. There is a lack of categorization of legislation, jurisprudence, evidence, penalties, the roles of people in a legal process (judge, lawyer, victim, defendant, witness), types of locations (crime location, defendant's address), etc. In this sense, there is still a need for a robust golden collection, annotated with fine-grained entities of the legal domain, and which covers various documents of a legal process, such as petitions, inquiries, complaints, decisions and sentences. In this article, we describe the development of the Golden Collection of the Brazilian Judiciary (CDJUR-BR) contemplating a set of fine-grained named entities that have been annotated by experts in legal documents. The creation of CDJUR-BR followed its ow
    
[^47]: 语义感知数字孪生体在元宇宙中的综述

    Semantic-aware Digital Twin for Metaverse: A Comprehensive Review. (arXiv:2305.18304v1 [cs.CY])

    [http://arxiv.org/abs/2305.18304](http://arxiv.org/abs/2305.18304)

    本文综述了数字孪生体在元宇宙中的部署，并介绍了通过语义通信实现数字孪生体与元宇宙结合的框架，以及其在智能工业应用中的基本原理和性能优化的实现。

    

    为了在元宇宙中实现数字孪生体的部署，提出了具有语义感知能力的范式，以实现准确的、面向任务的信息提取和内在的智能化。然而，这种框架需要将元宇宙环境中的所有设备直接连接到语义模型中，以实现信息的忠实解释。相反，本文介绍了数字孪生体框架，考虑了智能工业应用，通过与元宇宙使能技术结合使用，实现了语义通信。本文介绍了语义通信、元宇宙和数字孪生体的基础知识，并在工业车间管理应用用例中展示了该框架的基本原理，以通过语义通信改善其性能。介绍了这些技术与基本架构的集成以及对未来工业应用的影响。

    To facilitate the deployment of digital twins in Metaverse, the paradigm with semantic awareness has been proposed as a means for enabling accurate and task-oriented information extraction with inherent intelligence. However, this framework requires all devices in the Metaverse environment to be directly linked with the semantic model to enable faithful interpretation of messages. In contrast, this article introduces the digital twin framework, considering a smart industrial application, which enables semantic communication in conjugation with the Metaverse enabling technologies. The fundamentals of this framework are demonstrated on an industrial shopfloor management use case with a digital twin so as to improve its performance through semantic communication. An overview of semantic communication, Metaverse, and digital twins is presented. Integration of these technologies with the basic architecture as well as the impact on future industrial applications is presented. In a nutshell, 
    
[^48]: 大型语言模型是否知道自己所不知道的内容？

    Do Large Language Models Know What They Don't Know?. (arXiv:2305.18153v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.18153](http://arxiv.org/abs/2305.18153)

    本文研究大型语言模型（LLM）的自我认知能力，基于无法回答或不可知问题对它们进行评估，发现LLM在认识自身限制方面存在显著差异。

    

    大型语言模型（LLM）具有丰富的知识，使它们能够在各种自然语言处理（NLP）任务中表现出色。当前的研究集中在增强它们在现有知识范畴内的性能。尽管它们拥有庞大的知识储备，但LLM仍然受到它们能够容纳和理解的信息总量限制。因此，理解它们在未知领域的限制，即所谓的自我认知能力，至关重要。本研究旨在评估LLM的自我认知能力，通过评估它们识别无法回答或不可知问题的能力。我们引入一种自动化方法来检测这些模型响应中的不确定性，提供它们自我认知的一种新度量。我们进一步引入一个独特的数据集SelfAware，包括来自五个不同类别的无法回答问题及其可回答对应问题。我们进行了广泛的分析，涉及20个LLM（包括GPT-3、InstructGPT和LLaMA），发现它们在识别无法回答问题并认识到自身限制方面存在显著差异。

    Large language models (LLMs) have a wealth of knowledge that allows them to excel in various Natural Language Processing (NLP) tasks. Current research focuses on enhancing their performance within their existing knowledge. Despite their vast knowledge, LLMs are still limited by the amount of information they can accommodate and comprehend. Therefore, the ability to understand their own limitations on the unknows, referred to as self-knowledge, is of paramount importance. This study aims to evaluate LLMs' self-knowledge by assessing their ability to identify unanswerable or unknowable questions. We introduce an automated methodology to detect uncertainty in the responses of these models, providing a novel measure of their self-knowledge. We further introduce a unique dataset, SelfAware, consisting of unanswerable questions from five diverse categories and their answerable counterparts. Our extensive analysis, involving 20 LLMs including GPT-3, InstructGPT, and LLaMA, discovering an intr
    
[^49]: KoSBi: 一份用于减轻社会偏见的数据集，以确保更安全的大型语言模型应用 (arXiv: 2305.17701v2 [cs.CL] UPDATED)

    KoSBi: A Dataset for Mitigating Social Bias Risks Towards Safer Large Language Model Application. (arXiv:2305.17701v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.17701](http://arxiv.org/abs/2305.17701)

    KoSBi是一个新的社会偏见数据集，通过基于过滤的中介处理，可以将生成内容中的社会偏差平均降低16.47%p，适用于韩国语言文化背景的大型语言模型应用程序。

    

    大型语言模型 (LLM) 不仅能够学习自然文本生成能力，而且还能通过真实世界的数据学习对不同人口群体的社会偏见，这在部署基于 LLM 的应用程序时构成了关键风险。由于语言和文化的差异显著影响偏见和目标人口群体，因此，现有的研究和资源在韩国并不适用。为了解决这一限制，我们提出了一份新的社会偏见数据集 KoSBi，该数据集包含 72 个人口群体在 15 个类别中的 34k 类语境和句子。我们发现通过基于过滤的中介处理，可以将生成内容中的社会偏差平均降低 16.47%p，对 HyperCLOVA（30B 和 82B）和 GPT-3 均适用。

    Large language models (LLMs) learn not only natural text generation abilities but also social biases against different demographic groups from real-world data. This poses a critical risk when deploying LLM-based applications. Existing research and resources are not readily applicable in South Korea due to the differences in language and culture, both of which significantly affect the biases and targeted demographic groups. This limitation requires localized social bias datasets to ensure the safe and effective deployment of LLMs. To this end, we present KO SB I, a new social bias dataset of 34k pairs of contexts and sentences in Korean covering 72 demographic groups in 15 categories. We find that through filtering-based moderation, social biases in generated content can be reduced by 16.47%p on average for HyperCLOVA (30B and 82B), and GPT-3.
    
[^50]: 从孩子身上学习：通过课程学习改进图像字幕预训练

    Learning from Children: Improving Image-Caption Pretraining via Curriculum. (arXiv:2305.17540v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.17540](http://arxiv.org/abs/2305.17540)

    本研究借鉴孩子语言学习的方法，提出了一种课程学习框架，通过逐渐增加新概念的对齐来改进图像字幕预训练，提高其在各种下游视觉任务中的表现。

    

    图像字幕预训练已经被广泛用于零样本图像分类和物体检测等下游视觉任务，但仍然是一个难题，需要将字幕中的多个概念与图片中的多个对象对齐。为了解决这个问题，研究者们从最优秀的学习者——孩子们身上汲取灵感，提出了一种课程学习框架，最开始使用易于对齐一组概念的图像字幕配对进行学习，然后逐渐增加难度，每个新阶段都逐渐增加一个概念，利用每个学习阶段获取的知识在后续阶段中帮助对齐一个新的概念-对象对。我们展示了这种学习策略在各种基准测试中对原始的图像字幕训练的改进效果。

    Image-caption pretraining has been quite successfully used for downstream vision tasks like zero-shot image classification and object detection. However, image-caption pretraining is still a hard problem -- it requires multiple concepts (nouns) from captions to be aligned to several objects in images. To tackle this problem, we go to the roots -- the best learner, children. We take inspiration from cognitive science studies dealing with children's language learning to propose a curriculum learning framework. The learning begins with easy-to-align image caption pairs containing one concept per caption. The difficulty is progressively increased with each new phase by adding one more concept per caption. Correspondingly, the knowledge acquired in each learning phase is utilized in subsequent phases to effectively constrain the learning problem to aligning one new concept-object pair in each phase. We show that this learning strategy improves over vanilla image-caption training in various 
    
[^51]: 一桩天作之合：用于夸张和隐喻检测的多任务框架。

    A Match Made in Heaven: A Multi-task Framework for Hyperbole and Metaphor Detection. (arXiv:2305.17480v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.17480](http://arxiv.org/abs/2305.17480)

    本研究提出了一个多任务深度学习框架，同时检测夸张和隐喻。使用隐喻标签注释了两个夸张数据集，使用夸张标签注释了两个隐喻数据集，实验证明该框架检测夸张的性能比先前方法进步了12%。此外，多任务学习方法比单任务学习方法提高了多达17%。

    

    夸张和隐喻在日常交流中很常见（例如，“我陷入了麻烦之中”：麻烦怎么可能有深度？），因此它们的检测尤为重要，特别是在对话 AI 设置中。现有的自动检测夸张和隐喻的方法独立地研究了这些语言现象，但它们之间的关系从未被计算化探索过。在本文中，我们提出了一个多任务深度学习框架，同时检测夸张和隐喻。我们假设隐喻有助于夸张检测，反之亦然。为验证这一假设，我们使用隐喻标签注释了两个夸张数据集-HYPO 和 HYPO-L-。同时，我们使用夸张标签注释了两个隐喻数据集-TroFi 和 LCC。使用这些数据集的实验证明，我们的方法比先前的夸张检测方法进步了 12%。此外，我们的多任务学习方法相对于单任务学习方法提高了多达 17%。

    Hyperbole and metaphor are common in day-to-day communication (e.g., "I am in deep trouble": how does trouble have depth?), which makes their detection important, especially in a conversational AI setting. Existing approaches to automatically detect metaphor and hyperbole have studied these language phenomena independently, but their relationship has hardly, if ever, been explored computationally. In this paper, we propose a multi-task deep learning framework to detect hyperbole and metaphor simultaneously. We hypothesize that metaphors help in hyperbole detection, and vice-versa. To test this hypothesis, we annotate two hyperbole datasets- HYPO and HYPO-L- with metaphor labels. Simultaneously, we annotate two metaphor datasets- TroFi and LCC- with hyperbole labels. Experiments using these datasets give an improvement of the state of the art of hyperbole detection by 12%. Additionally, our multi-task learning (MTL) approach shows an improvement of up to 17% over single-task learning (S
    
[^52]: 使用检索增强语言模型提高GPT-3/4在生物医学数据上的准确性

    Improving accuracy of GPT-3/4 results on biomedical data using a retrieval-augmented language model. (arXiv:2305.17116v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.17116](http://arxiv.org/abs/2305.17116)

    本研究使用Retrieval Augmentation（RetA）方法，对比了OpenAI的GPT-3、GPT-4、Bing的Prometheus以及定制的RetA模型在回答19个弥漫大B细胞淋巴瘤（DLBCL）疾病相关问题方面的表现，结果显示RetA模型在准确性和相关性方面表现最佳。

    

    大型语言模型（LLM）在自然语言处理（NLP）方面取得了重大进展。广泛的语料库捕获了多样的模式，但也可能引入无关的信息，而专注的语料库通过减少误导性信息来提高可靠性。针对特定领域中的Retrieval Augmentation（RetA）方法是使用专注语料库训练LLM的替代方法。本文针对弥漫大B细胞淋巴瘤（DLBCL）疾病提出了19个问题并比较了OpenAI的GPT-3、GPT-4、Bing的Prometheus以及定制的RetA模型在回答这些问题方面的表现。 8名独立的评审根据准确性、相关性和可读性（评分1-3）对回答进行评估。结果显示RetA模型在准确性（19项中12项获得3分，总计47分）和相关性（19项中13项，50分）方面表现最佳，其次是GPT-4（19项中8项，43分；11项中49分）。GPT-4获得了最高的可读性评分（19项中17项，55分），其次是GPT-3（19项中15项，53分）和RetA模型（19项中11项，47分）。Prometheus在准确性方面表现不佳。

    Large language models (LLMs) have made significant advancements in natural language processing (NLP). Broad corpora capture diverse patterns but can introduce irrelevance, while focused corpora enhance reliability by reducing misleading information. Training LLMs on focused corpora poses computational challenges. An alternative approach is to use a retrieval-augmentation (RetA) method tested in a specific domain.  To evaluate LLM performance, OpenAI's GPT-3, GPT-4, Bing's Prometheus, and a custom RetA model were compared using 19 questions on diffuse large B-cell lymphoma (DLBCL) disease. Eight independent reviewers assessed responses based on accuracy, relevance, and readability (rated 1-3).  The RetA model performed best in accuracy (12/19 3-point scores, total=47) and relevance (13/19, 50), followed by GPT-4 (8/19, 43; 11/19, 49). GPT-4 received the highest readability scores (17/19, 55), followed by GPT-3 (15/19, 53) and the RetA model (11/19, 47). Prometheus underperformed in accu
    
[^53]: 用下一句预测和互信息在潜空间中评估开放域对话

    Evaluating Open-Domain Dialogues in Latent Space with Next Sentence Prediction and Mutual Information. (arXiv:2305.16967v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.16967](http://arxiv.org/abs/2305.16967)

    本文提出了一种新的基于学习的自动评估度量方法（CMN），能够通过将条件变分自编码器（CVAEs）与下一句预测（NSP）目标相结合，并利用互信息（MI）在潜空间中建模文本的语义相似度，来鲁棒地评估开放域对话，并在实验中取得了优异的结果。

    

    开放域对话中的一对多问题使得自动评估方法面临重大挑战，本文提出了一种新的基于学习的自动评估度量方法（CMN），通过将条件变分自编码器（CVAEs）与下一句预测（NSP）目标相结合，并利用互信息（MI）在潜空间中建模文本的语义相似度，实现了对开放域对话的鲁棒评估。在两个开放域对话数据集上的实验结果表明，与广泛的基线方法相比，我们的方法具有明显的优越性，特别是在处理语义上远离黄金参考回答的响应时更为有效。

    The long-standing one-to-many issue of the open-domain dialogues poses significant challenges for automatic evaluation methods, i.e., there may be multiple suitable responses which differ in semantics for a given conversational context. To tackle this challenge, we propose a novel learning-based automatic evaluation metric (CMN), which can robustly evaluate open-domain dialogues by augmenting Conditional Variational Autoencoders (CVAEs) with a Next Sentence Prediction (NSP) objective and employing Mutual Information (MI) to model the semantic similarity of text in the latent space. Experimental results on two open-domain dialogue datasets demonstrate the superiority of our method compared with a wide range of baselines, especially in handling responses which are distant to the golden reference responses in semantics.
    
[^54]: 少样本微调 vs 上下文学习：公平比较和评估

    Few-shot Fine-tuning vs. In-context Learning: A Fair Comparison and Evaluation. (arXiv:2305.16938v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.16938](http://arxiv.org/abs/2305.16938)

    本文比较了少样本微调和上下文学习在控制模型大小、样本数量和参数数量的情况下对挑战性数据集的泛化能力，结果表明少样本微调在某些复杂的推理和组合性任务中比上下文学习效果更好。

    

    少样本微调和上下文学习是预训练语言模型任务适应的两种替代策略。近期，上下文学习因其简单性和改善的跨域泛化能力而备受欢迎，因为大量证据表明微调模型会受到虚假相关性的影响。不幸的是，之前对这两种方法的比较使用的是不同大小的模型，这引发了一个问题：微调模型的跨域泛化能力是否是微调本身的固有属性，还是实验设置的局限性？本文利用模型大小、样本数量和参数数量等方面来进行公平的少样本微调和上下文学习的泛化比较，涉及的模型规模从125M到30B不等。研究结果表明，微调模型实际上能够很好地跨域泛化，发现这两种方法都是有效的，但在某些需要更复杂的推理和组合性的任务中，少样本微调的效果优于上下文学习。

    Few-shot fine-tuning and in-context learning are two alternative strategies for task adaptation of pre-trained language models. Recently, in-context learning has gained popularity over fine-tuning due to its simplicity and improved out-of-domain generalization, and because extensive evidence shows that fine-tuned models pick up on spurious correlations. Unfortunately, previous comparisons of the two approaches were done using models of different sizes. This raises the question of whether the observed weaker out-of-domain generalization of fine-tuned models is an inherent property of fine-tuning or a limitation of the experimental setup. In this paper, we compare the generalization of few-shot fine-tuning and in-context learning to challenge datasets, while controlling for the models used, the number of examples, and the number of parameters, ranging from 125M to 30B. Our results show that fine-tuned language models can in fact generalize well out-of-domain. We find that both approaches
    
[^55]: GenQ：自动化问答生成器以帮助照顾者与孩子共读故事

    GenQ: Automated Question Generation to Support Caregivers While Reading Stories with Children. (arXiv:2305.16809v1 [cs.CL])

    [http://arxiv.org/abs/2305.16809](http://arxiv.org/abs/2305.16809)

    本研究设计了一个智能辅导系统（GenQ），可以根据照顾者和孩子之间的对话促进孩子的阅读理解能力，并通过考虑文化背景和语境变化以提高系统效果。

    

    当照顾者询问开放式问题以激发与孩子的对话时，可以促进孩子的阅读理解能力。虽然有利用技术工具来支持这个过程，即所谓的“智能辅导系统”的空间，但目前仍不清楚现有的生成类人语言问题的智能系统是否有益。此外，用于开发这些自动生成问题系统的培训数据通常没有考虑到人口统计学，但具有不同文化背景的人可能会提出不同的问题。作为为拉丁裔儿童设计智能阅读支持应用程序的广泛项目的一部分，我们从来自不同人口统计学的拉丁裔护理人员和非护理人员以及其他人口统计学背景的护理人员和非护理人员中群集大量问题。我们研究了这个数据集中个体、文化和环境因素中介的问题提问的变化。然后我们设计了一个系统来自动产生问题。

    When caregivers ask open--ended questions to motivate dialogue with children, it facilitates the child's reading comprehension skills.Although there is scope for use of technological tools, referred here as "intelligent tutoring systems", to scaffold this process, it is currently unclear whether existing intelligent systems that generate human--language like questions is beneficial. Additionally, training data used in the development of these automated question generation systems is typically sourced without attention to demographics, but people with different cultural backgrounds may ask different questions. As a part of a broader project to design an intelligent reading support app for Latinx children, we crowdsourced questions from Latinx caregivers and noncaregivers as well as caregivers and noncaregivers from other demographics. We examine variations in question--asking within this dataset mediated by individual, cultural, and contextual factors. We then design a system that autom
    
[^56]: GPT是否会产生更不准确的翻译?

    Do GPTs Produce Less Literal Translations?. (arXiv:2305.16806v1 [cs.CL])

    [http://arxiv.org/abs/2305.16806](http://arxiv.org/abs/2305.16806)

    本研究比较了GPT和NMT生成翻译的文字积极度差异，发现GPT翻译更不准确，但在MT质量评估指标上表现出相似或更好的分数。

    

    大型语言模型（LLMs），如GPT-3，已经成为通用语言模型，能够处理许多自然语言生成或理解任务。在机器翻译（MT）任务中，已有多项研究探索利用few-shot提示机制从LLMs中引出更好的翻译。然而，人们相对较少地关注这种翻译与标准神经机器翻译（NMT）模型生成翻译的质量差异。本研究从文字对齐和单调性等方面，比较了GPT和NMT生成翻译的文本文字积极度，发现GPT从英语（E-X）翻译的文本更不准确，但在MT质量评估指标上表现出相似或更好的分数。我们证明这一结果在人工评估中也得到了验证。同时，当翻译句子长度增加时，这种差别就尤为显著。

    Large Language Models (LLMs) such as GPT-3 have emerged as general-purpose language models capable of addressing many natural language generation or understanding tasks. On the task of Machine Translation (MT), multiple works have investigated few-shot prompting mechanisms to elicit better translations from LLMs. However, there has been relatively little investigation on how such translations differ qualitatively from the translations generated by standard Neural Machine Translation (NMT) models. In this work, we investigate these differences in terms of the literalness of translations produced by the two systems. Using literalness measures involving word alignment and monotonicity, we find that translations out of English (E-X) from GPTs tend to be less literal, while exhibiting similar or better scores on MT quality metrics. We demonstrate that this finding is borne out in human evaluations as well. We then show that these differences are especially pronounced when translating senten
    
[^57]: 利用领域知识实现包容和偏见感知的人道主义响应入口分类

    Leveraging Domain Knowledge for Inclusive and Bias-aware Humanitarian Response Entry Classification. (arXiv:2305.16756v1 [cs.CL])

    [http://arxiv.org/abs/2305.16756](http://arxiv.org/abs/2305.16756)

    本研究提出了一种以人道主义本体为基础的新型语言模型HumBert，并提供了一种系统的方法来衡量和减少偏见，以实现对人道主义数据分析的有效和道德意识的支持。

    

    在人道主义危机期间，准确和快速的情况分析对于高效地提供人道主义援助至关重要，并且是人道主义原则和不留任何人落后原则的基础。语言处理系统可以极大地受益于这种数据分析，例如，按照人道主义本体对文本数据进行分类。然而，仅仅通过微调通用的大型语言模型 (LLM) 来实现，涉及一些实践和道德问题，特别是在数据稀疏和复杂子领域上的效果不佳以及社会偏见和不良关联的编码。在这项工作中，我们旨在为人道主义数据分析提供一种有效和道德意识的系统。我们通过 (1) 引入一个适合人道主义分析框架的新架构，(2) 创建和发布一个新的人道主义特定 LLM，称为 HumBert，并且 (3) 提出了一种系统的方式来衡量和减少偏见。

    Accurate and rapid situation analysis during humanitarian crises is critical to delivering humanitarian aid efficiently and is fundamental to humanitarian imperatives and the Leave No One Behind (LNOB) principle. This data analysis can highly benefit from language processing systems, e.g., by classifying the text data according to a humanitarian ontology. However, approaching this by simply fine-tuning a generic large language model (LLM) involves considerable practical and ethical issues, particularly the lack of effectiveness on data-sparse and complex subdomains, and the encoding of societal biases and unwanted associations. In this work, we aim to provide an effective and ethically-aware system for humanitarian data analysis. We approach this by (1) introducing a novel architecture adjusted to the humanitarian analysis framework, (2) creating and releasing a novel humanitarian-specific LLM called HumBert, and (3) proposing a systematic way to measure and mitigate biases. Our experi
    
[^58]: 缩放数据受限的语言模型

    Scaling Data-Constrained Language Models. (arXiv:2305.16264v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.16264](http://arxiv.org/abs/2305.16264)

    研究人员研究了在数据受限制的情况下缩放语言模型，并提出了一个计算最优性的缩放定律，考虑到重复令牌和过量参数的价值递减。

    

    现在扩展语言模型的趋势涉及增加参数计数和训练数据集大小。推断这个趋势表明，训练数据集大小可能很快就会受到互联网上可用文本数据的限制。出于此限制的动机，我们研究在数据受限制的情况下缩放语言模型。具体而言，我们运行了大量的实验，变化数据重复程度和计算预算，范围达到了9000亿个训练令牌和9亿参数模型。我们发现，在有限的数据的情况下，使用高达4次重复数据的训练与使用唯一数据相比对损失的贡献微不足道。然而，使用更多的重复数据，添加计算的价值最终会衰减为零。我们提出并经验证了一个计算最优性的缩放定律，考虑到重复令牌和过量参数的价值递减。最后，我们尝试了缓解数据稀缺的方法。

    The current trend of scaling language models involves increasing both parameter count and training dataset size. Extrapolating this trend suggests that training dataset size may soon be limited by the amount of text data available on the internet. Motivated by this limit, we investigate scaling language models in data-constrained regimes. Specifically, we run a large set of experiments varying the extent of data repetition and compute budget, ranging up to 900 billion training tokens and 9 billion parameter models. We find that with constrained data for a fixed compute budget, training with up to 4 epochs of repeated data yields negligible changes to loss compared to having unique data. However, with more repetition, the value of adding compute eventually decays to zero. We propose and empirically validate a scaling law for compute optimality that accounts for the decreasing value of repeated tokens and excess parameters. Finally, we experiment with approaches mitigating data scarcity,
    
[^59]: 用更少的数据进行视觉上有依据的少样本词汇习得

    Visually grounded few-shot word acquisition with fewer shots. (arXiv:2305.15937v1 [cs.CL])

    [http://arxiv.org/abs/2305.15937](http://arxiv.org/abs/2305.15937)

    该论文提出了一种基于视觉的语音模型，可以从仅有少量的词-图像示例对中习得新的词汇及其视觉表示，并且与现有方法相比，该模型在使用更少的样本时取得了更好的性能。

    

    我们提出了一种基于视觉的语音模型，它可以从仅有少量的词-图像示例对中习得新的词汇及其视觉表示。给定一组测试图像和一个口头查询，我们要求模型指出哪个图像展示了查询词。先前的工作要么使用数字词-图像对的人造环境来简化该问题，要么使用每个类别大量的示例。我们提出了一种方法，可以在自然的词-图像对上进行，但只需更少的数据，即更少的样本。我们的方法包括使用给定的词-图像示例对从大量未标记的语音和图像中挖掘新的无监督词-图像训练对。另外，我们使用了一种单词到图像的注意力机制来确定词-图像的相似度。通过这种新模型，我们实现了比任何现有方法都更好的性能，而且只需更少的数据量。

    We propose a visually grounded speech model that acquires new words and their visual depictions from just a few word-image example pairs. Given a set of test images and a spoken query, we ask the model which image depicts the query word. Previous work has simplified this problem by either using an artificial setting with digit word-image pairs or by using a large number of examples per class. We propose an approach that can work on natural word-image pairs but with less examples, i.e. fewer shots. Our approach involves using the given word-image example pairs to mine new unsupervised word-image training pairs from large collections of unlabelled speech and images. Additionally, we use a word-to-image attention mechanism to determine word-image similarity. With this new model, we achieve better performance with fewer shots than any existing approach.
    
[^60]: 从字符到词：用于开放词汇语言理解的分层预训练语言模型

    From Characters to Words: Hierarchical Pre-trained Language Model for Open-vocabulary Language Understanding. (arXiv:2305.14571v1 [cs.CL])

    [http://arxiv.org/abs/2305.14571](http://arxiv.org/abs/2305.14571)

    本文提出了一种新颖的开放词汇语言模型，它采用了分层两级方法和浅层Transformer体系结构从字符中学习单词，能够提高模型的容忍度和适应性。

    

    当前自然语言理解的最新模型需要对原始文本进行预处理，将其转换为离散标记。这个过程称为分词，依赖于预先构建的单词或子词。但这种固定词汇表限制了模型对拼写错误的容忍度和适应新领域的能力。本文提出了一种新颖的开放词汇语言模型，采用了分层的两级方法：一个在词级别，另一个在序列级别。具体来说，我们设计了一个内部单词模块，使用浅层Transformer体系结构从其字符中学习单词表示，并另一个深层Transformer模块，将每个单词表示置于整个单词序列中。因此，我们的模型直接在具有显式单词边界意识的字符序列上运行，但没有偏见的子单词或单词级词汇表。各种下游任务的实验表明我们的模型比其他模型有更好的性能。

    Current state-of-the-art models for natural language understanding require a preprocessing step to convert raw text into discrete tokens. This process known as tokenization relies on a pre-built vocabulary of words or sub-word morphemes. This fixed vocabulary limits the model's robustness to spelling errors and its capacity to adapt to new domains. In this work, we introduce a novel open-vocabulary language model that adopts a hierarchical two-level approach: one at the word level and another at the sequence level. Concretely, we design an intra-word module that uses a shallow Transformer architecture to learn word representations from their characters, and a deep inter-word Transformer module that contextualizes each word representation by attending to the entire word sequence. Our model thus directly operates on character sequences with explicit awareness of word boundaries, but without biased sub-word or word-level vocabulary. Experiments on various downstream tasks show that our me
    
[^61]: BA-SOT: 面向多说话人ASR的边界感知序列化输出训练

    BA-SOT: Boundary-Aware Serialized Output Training for Multi-Talker ASR. (arXiv:2305.13716v1 [cs.SD])

    [http://arxiv.org/abs/2305.13716](http://arxiv.org/abs/2305.13716)

    BA-SOT是一种面向多说话人ASR的训练方法，通过边界感知和连接时间分类策略，显著提高了模型的准确性和精度。

    

    最近提出的序列化输出训练（SOT）通过生成由特殊标记分隔的说话者转录简化了多说话者自动语音识别（ASR）。但是，频繁的说话者更改可能会使说话者更改预测变得困难。为了解决这个问题，我们提出了边界感知序列化输出训练（BA-SOT），它通过说话者更改检测任务和边界约束损失将边界知识明确地纳入解码器中。我们还引入了一个两阶段连接时间分类（CTC）策略，它将基于标记的SOT CTC结合起来，以恢复时间上下文信息。除了典型的字符错误率（CER），我们引入了基于话语的字符错误率（UD-CER），以进一步衡量说话者更改预测的精度。与原始的SOT相比，BA-SOT将CER / UD-CER降低了5.1％/ 14.0％，并利用预训练的ASR模型进行BA-SOT模型初始化进一步将CER / UD-CER降低了8.4％/ 19.9％。

    The recently proposed serialized output training (SOT) simplifies multi-talker automatic speech recognition (ASR) by generating speaker transcriptions separated by a special token. However, frequent speaker changes can make speaker change prediction difficult. To address this, we propose boundary-aware serialized output training (BA-SOT), which explicitly incorporates boundary knowledge into the decoder via a speaker change detection task and boundary constraint loss. We also introduce a two-stage connectionist temporal classification (CTC) strategy that incorporates token-level SOT CTC to restore temporal context information. Besides typical character error rate (CER), we introduce utterance-dependent character error rate (UD-CER) to further measure the precision of speaker change prediction. Compared to original SOT, BA-SOT reduces CER/UD-CER by 5.1%/14.0%, and leveraging a pre-trained ASR model for BA-SOT model initialization further reduces CER/UD-CER by 8.4%/19.9%.
    
[^62]: EntRED: 用更少的捷径进行关系抽取基准测试

    EntRED: Benchmarking Relation Extraction with Fewer Shortcuts. (arXiv:2305.13551v1 [cs.CL])

    [http://arxiv.org/abs/2305.13551](http://arxiv.org/abs/2305.13551)

    本研究提出了一个名称更为多样、没有捷径、具有挑战性的关系提取基准测试EntRed，并解决了标准基准测试数据集存在的实体注释错误、实体名称多样性较低、从实体名称到基本事实关系的捷径等问题。

    

    实体名称在关系抽取中起着有效的作用，并常常影响模型性能。因此，基准测试中测试集中的实体名称显著影响了关系提取模型的评估。本研究发现，标准的关系抽取基准测试数据集存在大量错误的实体注释，实体名称多样性较低，并且容易出现从实体名称到基本事实关系的捷径。这些问题使得标准基准测试与现实世界场景相距甚远。因此，在本研究中，我们提出了EntRED，这是一个具有较少捷径和更高实体多样性的具有挑战性的关系提取基准测试。为构建EntRED，我们提出了一种基于因果推理（CI）的端到端实体替换管道：ERIC。ERIC对实体进行类型约束替换，以减少从实体偏差到基本事实关系的捷径。ERIC在两个方面应用CI：1）针对需要实体替换的实例，2）确定候选实体。

    Entity names play an effective role in relation extraction (RE) and often influence model performance. As a result, the entity names in the benchmarks' test sets significantly influence the evaluation of RE models. In this work, we find that the standard RE benchmarks' datasets have a large portion of incorrect entity annotations, low entity name diversity, and are prone to have shortcuts from entity names to ground-truth relations. These issues make the standard benchmarks far from reflecting the real-world scenarios. Hence, in this work, we present EntRED, a challenging RE benchmark with reduced shortcuts and higher diversity of entities. To build EntRED, we propose an end-to-end entity replacement pipeline based on causal inference (CI): ERIC. ERIC performs type-constrained replacements on entities to reduce the shortcuts from entity bias to ground-truth relations. ERIC applies CI in two aspects: 1) targeting the instances that need entity replacements, and 2) determining the candid
    
[^63]: 通过样本重新加权与样本关联测试进行失语症语音的无偏自动语音识别

    Debiased Automatic Speech Recognition for Dysarthric Speech via Sample Reweighting with Sample Affinity Test. (arXiv:2305.13108v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2305.13108](http://arxiv.org/abs/2305.13108)

    本文提出了一种样本重新加权与样本关联测试（Re-SAT）的新方法，用于缓解失语症患者的偏差问题，在不影响健康患者语音的ASR性能的情况下，有效提高了ASR的性能表现。

    

    基于深度学习的自动语音识别系统主要是通过经验风险最小化（ERM）进行训练的。由于ERM利用数据样本的平均表现而不考虑一个群体，例如健康或失语症患者，因此ASR系统无法识别跨群体的性能差异，导致ASR系统存在偏差且其群体性能差异严重。本研究旨在提高语音识别系统的群体稳健性，针对失语症患者进行改进。为了实现我们的目标，我们提出了一种新方法，即样本重新加权与样本关联测试（Re-SAT）。 Re-SAT系统地衡量所给数据样本的去偏帮助性，并通过去偏帮助性加权来缓解偏差。实验结果表明， Re-SAT有助于改善失语症语音的ASR性能，而不会影响健康语音的ASR性能。

    Automatic speech recognition systems based on deep learning are mainly trained under empirical risk minimization (ERM). Since ERM utilizes the averaged performance on the data samples regardless of a group such as healthy or dysarthric speakers, ASR systems are unaware of the performance disparities across the groups. This results in biased ASR systems whose performance differences among groups are severe. In this study, we aim to improve the ASR system in terms of group robustness for dysarthric speakers. To achieve our goal, we present a novel approach, sample reweighting with sample affinity test (Re-SAT). Re-SAT systematically measures the debiasing helpfulness of the given data sample and then mitigates the bias by debiasing helpfulness-based sample reweighting. Experimental results demonstrate that Re-SAT contributes to improved ASR performance on dysarthric speech without performance degradation on healthy speech.
    
[^64]: 《迭代前向调整提升语言模型中上下文学习》

    Iterative Forward Tuning Boosts In-context Learning in Language Models. (arXiv:2305.13016v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.13016](http://arxiv.org/abs/2305.13016)

    本文提出了一种两阶段框架来提高LLMs中ICL的性能，它将ICL过程分为“深思熟虑”和推理阶段。在“深思熟虑”阶段中，通过多次迭代优化示范，并操纵Transformer中的自我注意模块中的Key-Value矩阵来生成元梯度，从而期望在测试时提高LLM的推理能力。

    

    大型语言模型具有紧密联系的上下文学习能力，但能够解决普通问题的上下文学习模型无法通过一次处理示范样例来解决更复杂的任务。本文提出了一种有效和高效的两阶段框架，通过开发Transformer注意力和基于梯度下降的优化之间的双重形式来提高LLMs中ICL的性能。具体而言，我们将ICL过程分为“深思熟虑”和推理阶段。在“深思熟虑”阶段中，通过多次迭代优化示范，并操纵Transformer中的自我注意模块中的Key-Value矩阵来生成元梯度，从而期望在测试时提高LLM的推理能力。推理阶段仅处理测试查询，而不需要再次考虑示范。

    Large language models (LLMs) have exhibited an emergent in-context learning (ICL) ability. However, the ICL models that can solve ordinary cases are hardly extended to solve more complex tasks by processing the demonstration examples once. This single-turn ICL is incoordinate with the decision making process of humans by learning from analogy. In this paper, we propose an effective and efficient two-stage framework to boost ICL in LLMs by exploiting a dual form between Transformer attention and gradient descent-based optimization. Concretely, we divide the ICL process into "Deep-Thinking" and inference stages. The "Deep-Thinking" stage performs iterative forward optimization of demonstrations, which is expected to boost the reasoning abilities of LLMs at test time by "thinking" demonstrations multiple times. It produces accumulated meta-gradients by manipulating the Key-Value matrices in the self-attention modules of the Transformer. Then, the inference stage only takes the test query 
    
[^65]: 提升大规模语言模型在工业领域特定问答中的表现

    Empower Large Language Model to Perform Better on Industrial Domain-Specific Question Answering. (arXiv:2305.11541v1 [cs.CL])

    [http://arxiv.org/abs/2305.11541](http://arxiv.org/abs/2305.11541)

    本文提供了一个行业云特定QA数据集 MSQA，该数据集可用于评估旨在提高大规模语言模型特定领域能力的方法。本文还提出了一种新的模型交互范式，可以使大规模语言模型在其不擅长的特定任务上取得更好的性能。

    

    大规模语言模型（LLM）在开放领域任务中获得了广泛应用和卓越的成果，但其在真实的工业特定场景中的表现通常很平庸，因为它缺乏特定领域的知识。这个问题引起了广泛关注，但相关基准测试很少。本文提供了一个名为MSQA的基准问答（QA）数据集，该数据集涉及Microsoft产品和客户遇到的IT技术问题。这个数据集包含了行业云的特定QA知识，这对于一般的LLM来说是不可用的，因此非常适合评估旨在提高LLM特定领域能力的方法。此外，我们提出了一种新的模型交互范式，可以使LLM在其不擅长的特定任务上取得更好的性能。广泛的实验表明，遵循我们的模型融合框架的方法比使用检索方法的常用LLM表现更好。

    Large Language Model (LLM) has gained popularity and achieved remarkable results in open-domain tasks, but its performance in real industrial domain-specific scenarios is average since there is no specific knowledge in it. This issue has attracted widespread attention, but there are few relevant benchmarks available. In this paper, we provide a benchmark Question Answering (QA) dataset named MSQA, which is about Microsoft products and IT technical problems encountered by customers. This dataset contains industry cloud-specific QA knowledge, which is not available for general LLM, so it is well suited for evaluating methods aimed at improving domain-specific capabilities of LLM. In addition, we propose a new model interaction paradigm that can empower LLM to achieve better performance on domain-specific tasks where it is not proficient. Extensive experiments demonstrate that the approach following our model fusion framework outperforms the commonly used LLM with retrieval methods.
    
[^66]: 你在抄我的模型吗？基于后门水印的保护大语言模型在 EaaS 中的版权

    Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark. (arXiv:2305.10036v1 [cs.CL])

    [http://arxiv.org/abs/2305.10036](http://arxiv.org/abs/2305.10036)

    提出了一种名为 EmbMarker 的嵌入式水印方法，用于保护大型语言模型在 EaaS 中的版权。该方法可以在嵌入式上植入后门，并有效地传输和恢复。实验证明，EmbMarker 可以在维护各种 NLP 任务的性能的同时成功保护 EaaS 对 LLM 的版权。

    

    大型语言模型已经展示了在文本理解和生成方面的强大能力。公司已经开始基于这些大型语言模型提供嵌入式服务 (EaaS)，可以为客户的各种自然语言处理 (NLP) 任务带来益处。然而，先前的研究表明，EaaS 易受到模型提取攻击的攻击，这可能会对 LLM 的所有者造成巨大损失，因为训练这些模型非常昂贵。为了保护 EaaS 的 LLM 的版权，我们提出了一个名为 EmbMarker 的嵌入式水印方法，该方法在嵌入式上植入后门。我们的方法从通用文本语料库中选择一组中等频率的单词，形成触发集，然后选择一个目标嵌入作为水印，并将其插入包含触发词的文本的嵌入中作为后门。插入的重量与包含在文本中的触发词数量成比例。这使得水印后门可以有效地传输和恢复，而不影响 LLM 在各种 NLP 任务中的性能。实验证明，EmbMarker 可以在维护各种 NLP 任务的性能的同时成功保护 EaaS 对 LLM 的版权。

    Large language models (LLMs) have demonstrated powerful capabilities in both text understanding and generation. Companies have begun to offer Embedding as a Service (EaaS) based on these LLMs, which can benefit various natural language processing (NLP) tasks for customers. However, previous studies have shown that EaaS is vulnerable to model extraction attacks, which can cause significant losses for the owners of LLMs, as training these models is extremely expensive. To protect the copyright of LLMs for EaaS, we propose an Embedding Watermark method called EmbMarker that implants backdoors on embeddings. Our method selects a group of moderate-frequency words from a general text corpus to form a trigger set, then selects a target embedding as the watermark, and inserts it into the embeddings of texts containing trigger words as the backdoor. The weight of insertion is proportional to the number of trigger words included in the text. This allows the watermark backdoor to be effectively t
    
[^67]: “我全然成为我自己”：以TGNB人群为中心，评估开放式语言生成中的偏见

    "I'm fully who I am": Towards Centering Transgender and Non-Binary Voices to Measure Biases in Open Language Generation. (arXiv:2305.09941v1 [cs.CL])

    [http://arxiv.org/abs/2305.09941](http://arxiv.org/abs/2305.09941)

    本论文研究了如何以TGNB人群的声音为中心，评估开放式语言生成中的偏见。通过理解TGNB个体的经历，提出了以TGNB人群为中心的OLG系统评估框架，并且包括一个为TGNB人群设计的调查工具和分析方法。

    

    跨性别和非二元（TGNB）人群在日常生活中经历了不成比例的歧视和排斥。随着语言生成技术的日益普及和应用，进一步边缘化这一人群的可能性也在增加。虽然大量的NLP公平文献着重于阐明和解决性别偏见，但评估TGNB身份所带来的性别伤害需要理解这些身份如何独特地与社会性别规范互动以及与性别二元中心的视角相区分。这样的测量框架本质上需要以TGNB声音为中心，帮助指导包容性别的自然语言处理应该为谁服务。为实现这一目标，我们以TGNB社区和现有的跨学科文献为基础，评估了TGNB个体经历边缘化所形成的社会现实是如何影响和存在于开放式语言生成（OLG）中。首先理解TGNB个体的经历，我们提出了一个评估OLG系统的框架，旨在以TGNB人群为中心，度量与该人群相关的偏见。我们的框架包括特别为TGNB人群设计的调查工具，以及交叉分析结果的交叉方法。我们相信，这项工作将有助于实现更公平、更包容的自然语言处理社区，并潜在地解决NLP研究中广泛的交叉身份问题。

    Transgender and non-binary (TGNB) individuals disproportionately experience discrimination and exclusion from daily life. Given the recent popularity and adoption of language generation technologies, the potential to further marginalize this population only grows. Although a multitude of NLP fairness literature focuses on illuminating and addressing gender biases, assessing gender harms for TGNB identities requires understanding how such identities uniquely interact with societal gender norms and how they differ from gender binary-centric perspectives. Such measurement frameworks inherently require centering TGNB voices to help guide the alignment between gender-inclusive NLP and whom they are intended to serve. Towards this goal, we ground our work in the TGNB community and existing interdisciplinary literature to assess how the social reality surrounding experienced marginalization by TGNB persons contributes to and persists within Open Language Generation (OLG). By first understandi
    
[^68]: 带有注意力模型的视觉问答算法分析

    Analysis of Visual Question Answering Algorithms with attention model. (arXiv:2305.09782v1 [cs.CV])

    [http://arxiv.org/abs/2305.09782](http://arxiv.org/abs/2305.09782)

    本文批评性地检查和审查了使用共同注意力方法的VQA算法的方法，重点关注文本语义生成、对象识别和答案分类技术。

    

    视觉问答（VQA）使用图像处理算法处理图像，使用自然语言处理方法理解并回答问题。 VQA 对视觉受损者有帮助，可用于安全监控系统和从网络中学习的在线聊天机器人。 它使用自然语言处理方法学习问题的语义并提取文本特征。 计算机视觉技术用于以一种能够识别所问问题涉及的物体的方式生成图像表示。 注意力模型试图模仿人类根据语境关注图像不同区域的行为。 本文批评性地检查和审查了使用共同注意力方法的 VQA 算法的方法，例如生成文本语义，识别对象和答案分类技术。

    Visual question answering (VQA) usesimage processing algorithms to process the image and natural language processing methods to understand and answer the question. VQA is helpful to a visually impaired person, can be used for the security surveillance system and online chatbots that learn from the web. It uses NLP methods to learn the semantic of the question and to derive the textual features. Computer vision techniques are used for generating image representation in such a way that they can identify the objects about which question is asked. The Attention model tries to mimic the human behavior of giving attention to a different region of an image according to our understanding of its context. This paper critically examines and reviews methods of VQA algorithm such as generation of semantics of text, identification of objects and answer classification techniques that use the co-attention approach.
    
[^69]: 文档理解数据集和评估（DUDE）

    Document Understanding Dataset and Evaluation (DUDE). (arXiv:2305.08455v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.08455](http://arxiv.org/abs/2305.08455)

    DUDE推出了一个新的数据集和评估方法，旨在创造一个更实际的基准测试并推动当前方法的边界，以更准确地模拟真实世界的情况

    

    我们呼吁文档AI社区重新评估当前的方法论，拥抱创建更实际取向的基准测试的挑战。文档理解数据集和评估（DUDE）旨在纠正在理解视觉丰富文档（VRD）方面的研究进展停滞不前的情况。我们提供了一个新的数据集，其中包括与多行业、多领域和多页VRD相关的问题类型、答案和文档布局的创新，具有各种来源和日期。此外，我们通过创建多任务和多领域的评估设置来推动当前方法的边界，这些设置更准确地模拟了真实世界的情况，在这些情况下需要在低资源环境下进行强大的泛化和适应。DUDE旨在成为一个更实际、更长期的基准测试标准，并希望它会引领未来的扩展和贡献，以应对真实世界的挑战。最后，我们的工作说明了以下重要性。

    We call on the Document AI (DocAI) community to reevaluate current methodologies and embrace the challenge of creating more practically-oriented benchmarks. Document Understanding Dataset and Evaluation (DUDE) seeks to remediate the halted research progress in understanding visually-rich documents (VRDs). We present a new dataset with novelties related to types of questions, answers, and document layouts based on multi-industry, multi-domain, and multi-page VRDs of various origins, and dates. Moreover, we are pushing the boundaries of current methods by creating multi-task and multi-domain evaluation setups that more accurately simulate real-world situations where powerful generalization and adaptation under low-resource settings are desired. DUDE aims to set a new standard as a more practical, long-standing benchmark for the community, and we hope that it will lead to future extensions and contributions that address real-world challenges. Finally, our work illustrates the importance o
    
[^70]: ArtGPT-4: 基于适配器增强的MiniGPT-4模型的艺术视觉语言理解

    ArtGPT-4: Artistic Vision-Language Understanding with Adapter-enhanced MiniGPT-4. (arXiv:2305.07490v1 [cs.CL])

    [http://arxiv.org/abs/2305.07490](http://arxiv.org/abs/2305.07490)

    ArtGPT-4是一种基于适配器增强的MiniGPT-4模型，专注于解决图像理解方面的问题，能够在短时间内训练出具备良好视觉语言理解能力的多模态模型。

    

    近年来，大型语言模型在自然语言处理领域取得了显著进展，比如ChatGPT和GPT-4等模型在多种语言任务上取得了惊人的能力。但是，对这样的大规模模型进行训练是具有挑战性的，而找到与模型规模匹配的数据集通常也很困难。微调和使用新方法训练参数较少的模型已经成为克服这些挑战的有效方法。MiniGPT-4模型便是其中之一，该模型通过运用新颖的预训练模型和革新性的培训策略实现了与GPT-4相当的视觉语言理解能力。但是，该模型在图像理解方面仍然面临一些挑战，特别是在艺术图片方面。ArtGPT-4是一种新型的多模态模型，旨在应对这些局限。ArtGPT-4使用Tesla A100设备对图像-文本对进行训练，仅用了约200GB的数据，在2小时内就能展示出图像。

    In recent years, large language models (LLMs) have made significant progress in natural language processing (NLP), with models like ChatGPT and GPT-4 achieving impressive capabilities in various linguistic tasks. However, training models on such a large scale is challenging, and finding datasets that match the model's scale is often difficult. Fine-tuning and training models with fewer parameters using novel methods have emerged as promising approaches to overcome these challenges. One such model is MiniGPT-4, which achieves comparable vision-language understanding to GPT-4 by leveraging novel pre-training models and innovative training strategies. However, the model still faces some challenges in image understanding, particularly in artistic pictures. A novel multimodal model called ArtGPT-4 has been proposed to address these limitations. ArtGPT-4 was trained on image-text pairs using a Tesla A100 device in just 2 hours, using only about 200 GB of data. The model can depict images wit
    
[^71]: 针对开放域对话生成的跨语言迁移中降低灾难性遗忘的提示学习

    Prompt Learning to Mitigate Catastrophic Forgetting in Cross-lingual Transfer for Open-domain Dialogue Generation. (arXiv:2305.07393v1 [cs.CL])

    [http://arxiv.org/abs/2305.07393](http://arxiv.org/abs/2305.07393)

    本文提出了一种提示学习方法，以解决开放域非英语语言对话系统中少量数据下的跨语言迁移学习和多任务学习中的灾难性遗忘问题，并在六种语言上的实验中证明了其有效性。

    

    长期以来，非英语语言的对话系统一直未得到充分探索。本文第一次在非英语语言有限数据的开放域对话生成中研究了少样本跨语言迁移学习（FS-XLT）和多任务学习（MTL）。在初步实验中，我们发现在FS-XLT和MTL中所有的6种语言中都存在灾难性遗忘。为了减轻这一问题，我们提出了一种简单而有效的提示学习方法，通过固定提示语言模型调参和我们手工制作的提示语来弥合预训练和微调之间的差距，从而保持多语言预训练语言模型（mPLM）在FS-XLT和MTL中的多语言性。在所有6种语言上的自动和人工评估结果都证明了我们方法的有效性。我们的代码可在 https://github.com/JeremyLeiLiu/XLinguDial 上获取。

    Dialogue systems for non-English languages have long been under-explored. In this paper, we take the first step to investigate few-shot cross-lingual transfer learning (FS-XLT) and multitask learning (MTL) in the context of open-domain dialogue generation for non-English languages with limited data. We observed catastrophic forgetting in both FS-XLT and MTL for all 6 languages in our preliminary experiments. To mitigate the issue, we propose a simple yet effective prompt learning approach that can preserve the multilinguality of multilingual pre-trained language model (mPLM) in FS-XLT and MTL by bridging the gap between pre-training and fine-tuning with Fixed-prompt LM Tuning and our hand-crafted prompts. Experimental results on all 6 languages in terms of both automatic and human evaluations demonstrate the effectiveness of our approach. Our code is available at https://github.com/JeremyLeiLiu/XLinguDial.
    
[^72]: 在电子商务中使用数据增强实现一致的文本分类

    Consistent Text Categorization using Data Augmentation in e-Commerce. (arXiv:2305.05402v1 [cs.LG])

    [http://arxiv.org/abs/2305.05402](http://arxiv.org/abs/2305.05402)

    本文提出了一种在电子商务中使用数据增强实现一致的文本分类的新框架，该框架旨在改进产品分类模型的一致性，同时保持其生产水平的性能。

    

    大规模电子商务数据分类是一项关键的、广泛应用于工业领域的任务。本文旨在改进一家主要网络公司已经在使用的产品分类模型，该模型用于多种应用。在该模型核心中，产品分类模型是一个文本分类模型，接受产品标题作为输入，并从数千个可用候选项中输出最合适的类别。经过进一步观察，我们发现了类似物品标签上的不一致性。例如，标题中关于颜色或尺寸的小变化，会对模型产生较大影响。这种现象可能会对下游的推荐或搜索应用造成负面影响，导致用户体验下降。为了解决这个问题，我们提出了一个新的框架，实现一致的文本分类。我们的目标是提高模型的一致性，并保持其生产水平的性能。

    The categorization of massive e-Commerce data is a crucial, well-studied task, which is prevalent in industrial settings. In this work, we aim to improve an existing product categorization model that is already in use by a major web company, serving multiple applications. At its core, the product categorization model is a text classification model that takes a product title as an input and outputs the most suitable category out of thousands of available candidates. Upon a closer inspection, we found inconsistencies in the labeling of similar items. For example, minor modifications of the product title pertaining to colors or measurements majorly impacted the model's output. This phenomenon can negatively affect downstream recommendation or search applications, leading to a sub-optimal user experience.  To address this issue, we propose a new framework for consistent text categorization. Our goal is to improve the model's consistency while maintaining its production-level performance. W
    
[^73]: 基于Transformer的零样本和少样本生物医学命名实体识别方法

    A transformer-based method for zero and few-shot biomedical named entity recognition. (arXiv:2305.04928v1 [cs.CL])

    [http://arxiv.org/abs/2305.04928](http://arxiv.org/abs/2305.04928)

    本文提出了一种基于Transformer的生物医学领域零样本和少样本NER方法。此方法利用预训练学习给定和潜在类别之间的语义关系，将多类标记分类任务转换为二元标记分类，能够在不同数量的样本情况下达到良好的识别效果。

    

    在生物医学领域中，有监督的命名实体识别（NER）依赖于具有给定命名实体的大量注释文本，其创建可能耗时且昂贵。此外，提取新实体通常需要进行额外的注释任务和重新训练模型。为解决这些挑战，本文提出了一种基于Transformer的生物医学领域零样本和少样本NER方法。该方法基于将多类标记分类任务转换为二元标记分类（标记包含搜索的实体或不包含搜索的实体），并在更多的数据集和生物医学实体上进行预训练，从而可学习到给定和潜在类别之间的语义关系。在9种不同的生物医学实体上，我们在零样本NER、一次样本NER、10次样本NER和100次样本NER上实现了平均F1得分分别为35.44％、50.10％、69.94％和79.51％。

    Supervised named entity recognition (NER) in the biomedical domain is dependent on large sets of annotated texts with the given named entities, whose creation can be time-consuming and expensive. Furthermore, the extraction of new entities often requires conducting additional annotation tasks and retraining the model. To address these challenges, this paper proposes a transformer-based method for zero- and few-shot NER in the biomedical domain. The method is based on transforming the task of multi-class token classification into binary token classification (token contains the searched entity or does not contain the searched entity) and pre-training on a larger amount of datasets and biomedical entities, from where the method can learn semantic relations between the given and potential classes. We have achieved average F1 scores of 35.44% for zero-shot NER, 50.10% for one-shot NER, 69.94% for 10-shot NER, and 79.51% for 100-shot NER on 9 diverse evaluated biomedical entities with PubMed
    
[^74]: 一种双重语义感知的全局适应循环网络用于视觉语言导航

    A Dual Semantic-Aware Recurrent Global-Adaptive Network For Vision-and-Language Navigation. (arXiv:2305.03602v1 [cs.CV])

    [http://arxiv.org/abs/2305.03602](http://arxiv.org/abs/2305.03602)

    本文提出了一种双重语义感知的全局适应循环网络，通过引入指导语言模块和外观语义视觉模块，以及全局自适应聚合模块，提高了在视觉语言导航中的语义学习。

    

    视觉语言导航是一项现实但具有挑战性的任务，需要代理使用语言和视觉线索定位目标区域。本文提出了一种双重语义感知的全局适应循环网络 (DSRG) 来解决该问题。首先，DSRG 提出了一个指导语言模块 (IGL) 和一个外观语义视觉模块 (ASV) 分别提高视觉和语言语义学习。对于内存机制，还引入了全局自适应聚合模块 (GAA)。

    Vision-and-Language Navigation (VLN) is a realistic but challenging task that requires an agent to locate the target region using verbal and visual cues. While significant advancements have been achieved recently, there are still two broad limitations: (1) The explicit information mining for significant guiding semantics concealed in both vision and language is still under-explored; (2) The previously structured map method provides the average historical appearance of visited nodes, while it ignores distinctive contributions of various images and potent information retention in the reasoning process. This work proposes a dual semantic-aware recurrent global-adaptive network (DSRG) to address the above problems. First, DSRG proposes an instruction-guidance linguistic module (IGL) and an appearance-semantics visual module (ASV) for boosting vision and language semantic learning respectively. For the memory mechanism, a global adaptive aggregation module (GAA) is devised for explicit pano
    
[^75]: LLM能否作为数据库接口？大型数据库基础文本到SQL的基准测试。

    Can LLM Already Serve as A Database Interface? A BIg Bench for Large-Scale Database Grounded Text-to-SQLs. (arXiv:2305.03111v1 [cs.CL])

    [http://arxiv.org/abs/2305.03111](http://arxiv.org/abs/2305.03111)

    本文提出了一个大型的基准测试Bird，可以用于大规模数据库文本到SQL的任务，突出了数据库值理解和SQL效率等领域的挑战。

    

    近年来，文本到SQL解析受到越来越多的关注，旨在将自然语言指令转换为可执行的SQL命令。本文提出了一个大型基准测试Bird，它包含旨在大规模数据库基础的12,751对文本到SQL数据和95个数据库，总大小为33.4GB，涵盖37个专业领域。与现有基准测试相比，Bird强调数据库值的理解，突出了脏数据库内容、NL问题和数据库内容之间的外部知识以及SQL效率等新挑战。解决这些问题，文本到SQL模型必须具备数据库值理解和语义解析的能力。

    Text-to-SQL parsing, which aims at converting natural language instructions into executable SQLs, has gained increasing attention in recent years. In particular, Codex and ChatGPT have shown impressive results in this task. However, most of the prevalent benchmarks, i.e., Spider, and WikiSQL, focus on database schema with few rows of database contents leaving the gap between academic study and real-world applications. To mitigate this gap, we present Bird, a big benchmark for large-scale database grounded in text-to-SQL tasks, containing 12,751 pairs of text-to-SQL data and 95 databases with a total size of 33.4 GB, spanning 37 professional domains. Our emphasis on database values highlights the new challenges of dirty database contents, external knowledge between NL questions and database contents, and SQL efficiency, particularly in the context of massive databases. To solve these problems, text-to-SQL models must feature database value comprehension in addition to semantic parsing. 
    
[^76]: 面向跨数据集的弱监督仇恨言论分类

    Towards Weakly-Supervised Hate Speech Classification Across Datasets. (arXiv:2305.02637v1 [cs.CL])

    [http://arxiv.org/abs/2305.02637](http://arxiv.org/abs/2305.02637)

    该论文提出使用极度弱的监督方法，只依赖于类别名称而不是注释数据中的类别示例，解决当前仇恨言论识别的研究存在的数据创建策略不系统和不同注释方案问题，并展示了有效性。

    

    如多位学者指出的那样，当前针对仇恨言论（HS）识别的研究特点是不系统的数据创建策略和不同的注释方案。因此，监督学习模型往往对它们未被训练的数据集进行泛化性能差，并且不同HS分类法标记的数据集所训练的模型的性能无法比较。为了解决这个问题，我们提出了一种极度弱的监督方法，只依赖于类别名称而不是注释数据中的类别示例。我们展示了一种最先进的弱监督文本分类模型在各种数据集内和跨数据集的情况下的有效性。此外，我们对HS分类模型通用性较差的原因进行了深入的定量和定性分析。

    As pointed out by several scholars, current research on hate speech (HS) recognition is characterized by unsystematic data creation strategies and diverging annotation schemata. Subsequently, supervised-learning models tend to generalize poorly to datasets they were not trained on, and the performance of the models trained on datasets labeled using different HS taxonomies cannot be compared. To ease this problem, we propose applying extremely weak supervision that only relies on the class name rather than on class samples from the annotated data. We demonstrate the effectiveness of a state-of-the-art weakly-supervised text classification model in various in-dataset and cross-dataset settings. Furthermore, we conduct an in-depth quantitative and qualitative analysis of the source of poor generalizability of HS classification models.
    
[^77]: GPT-2是如何计算大于符号的？解释预训练语言模型中的数学能力

    How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model. (arXiv:2305.00586v1 [cs.CL])

    [http://arxiv.org/abs/2305.00586](http://arxiv.org/abs/2305.00586)

    本研究运用机械式可解释性技术探究了GPT-2 Small的数学能力，并确定了它的计算图中的一个小电路用于计算大于符号，该电路的多层感知器提高了结束年份大于开始年份的概率，并且该电路具有广泛的适用性。

    

    预训练语言模型在未被明确训练的任务上表现出惊人的能力，但它们如何实现这些功能却不为人所知。本文通过机械式可解释性技术探究预训练语言模型通常具有的基本数学能力。具体来说，我们以GPT-2 Small为例，研究其能否通过输入"战争持续时间是从1732年到17年"，预测出有效的两位数字的截止年份 (大于32年)。我们首先确定了一个电路，即GPT-2 Small计算图的一个小子集，用于计算这个任务的输出，然后我们解释了每个电路组件的作用，显示出GPT-2 Small的最终多层感知器提高了结束年份大于开始年份的概率。最后，我们证明了我们的电路适用于其他任务，在其他大于场景中发挥作用。

    Pre-trained language models can be surprisingly adept at tasks they were not explicitly trained on, but how they implement these capabilities is poorly understood. In this paper, we investigate the basic mathematical abilities often acquired by pre-trained language models. Concretely, we use mechanistic interpretability techniques to explain the (limited) mathematical abilities of GPT-2 small. As a case study, we examine its ability to take in sentences such as "The war lasted from the year 1732 to the year 17", and predict valid two-digit end years (years > 32). We first identify a circuit, a small subset of GPT-2 small's computational graph that computes this task's output. Then, we explain the role of each circuit component, showing that GPT-2 small's final multi-layer perceptrons boost the probability of end years greater than the start year. Finally, we show that our circuit generalizes to other tasks, playing a role in other greater-than scenarios.
    
[^78]: 对Kauhanen、Einhaus和Walkden（2023年）的回应：仍然没有证据证明非母语用户比例对语言复杂度有影响（arXiv:2305.00217v1 [cs.CL]）

    Still no evidence for an effect of the proportion of non-native speakers on language complexity -- A response to Kauhanen, Einhaus & Walkden (2023). (arXiv:2305.00217v1 [cs.CL])

    [http://arxiv.org/abs/2305.00217](http://arxiv.org/abs/2305.00217)

    本研究为对Kauhanen、Einhaus和Walkden（2023）的回应，仍然没有证据表明大量的L2用户影响语言复杂性。

    

    近期在《语言进化杂志》发表的一篇论文中，Kauhanen、Einhaus和Walkden（https://doi.org/10.1093/jole/lzad005，KEW）挑战了我在一篇论文中（Koplenig，Royal Society Open Science，6，181274（2019），https://doi.org/10.1098/rsos.181274）所呈现的结果。在该论文中，我试图通过一系列的统计分析来表明大量L2（第二语言）用户似乎不会影响语言的（语法或统计）复杂性。为此，我专注于Ethnologue评估语言地位的方式：如果一种语言除了被L1（第一语言）使用者之外，还应该有大量的L2使用者，那么该语言就被描述为传播性的。KEW批评了将传播性作为语言是否拥有大量L2使用者（二元）指标的使用，以及在直接估计L2比例的情况下，将L2用户比例归为非传播性语言的想法。

    In a recent paper published in the Journal of Language Evolution, Kauhanen, Einhaus & Walkden (https://doi.org/10.1093/jole/lzad005, KEW) challenge the results presented in one of my papers (Koplenig, Royal Society Open Science, 6, 181274 (2019), https://doi.org/10.1098/rsos.181274), in which I tried to show through a series of statistical analyses that large numbers of L2 (second language) speakers do not seem to affect the (grammatical or statistical) complexity of a language. To this end, I focus on the way in which the Ethnologue assesses language status: a language is characterised as vehicular if, in addition to being used by L1 (first language) speakers, it should also have a significant number of L2 users. KEW criticise both the use of vehicularity as a (binary) indicator of whether a language has a significant number of L2 users and the idea of imputing a zero proportion of L2 speakers to non-vehicular languages whenever a direct estimate of that proportion is unavailable. Whi
    
[^79]: Token-and-Duration Transducer架构：联合预测标记与时长的高效序列转导

    Efficient Sequence Transduction by Jointly Predicting Tokens and Durations. (arXiv:2304.06795v1 [eess.AS])

    [http://arxiv.org/abs/2304.06795](http://arxiv.org/abs/2304.06795)

    本文提出了一种新型的序列转导架构TDT，它可以联合预测标记和持续时间，从而实现比传统Transducers更高的准确性和显着更快的推理速度。

    

    本文提出了一种用于序列到序列任务的新型Token-and-Duration Transducer(TDT)架构。TDT通过联合预测标记和持续时间，即发射的标记覆盖的输入帧的数量，来扩展传统的RNN-Transducer架构。它使用具有两个独立标准化输出的联合网络来生成标记和持续时间的分布。在推理期间，TDT模型可以通过预测的持续时间输出跳过输入帧，使其比逐帧处理编码器输出的传统Transducers显着更快。在不同的序列转导任务上，TDT模型均实现了更高的准确性和显着更快的推理速度。语音识别的TDT模型比RNN-Transducers获得更好的准确性，并且推理速度高达2.82倍。语音翻译的TDT模型与MUST-C测试相比提高了1个BLEU分数。

    This paper introduces a novel Token-and-Duration Transducer (TDT) architecture for sequence-to-sequence tasks. TDT extends conventional RNN-Transducer architectures by jointly predicting both a token and its duration, i.e. the number of input frames covered by the emitted token. This is achieved by using a joint network with two outputs which are independently normalized to generate distributions over tokens and durations. During inference, TDT models can skip input frames guided by the predicted duration output, which makes them significantly faster than conventional Transducers which process the encoder output frame by frame. TDT models achieve both better accuracy and significantly faster inference than conventional Transducers on different sequence transduction tasks. TDT models for Speech Recognition achieve better accuracy and up to 2.82X faster inference than RNN-Transducers. TDT models for Speech Translation achieve an absolute gain of over 1 BLEU on the MUST-C test compared wi
    
[^80]: BenCoref:一种名词短语和代词指代注释的多领域数据集

    BenCoref: A Multi-Domain Dataset of Nominal Phrases and Pronominal Reference Annotations. (arXiv:2304.03682v1 [cs.CL])

    [http://arxiv.org/abs/2304.03682](http://arxiv.org/abs/2304.03682)

    本论文介绍了一个包括四个不同领域Bengali文本的新数据集- BenCoref。该数据集可以帮助理解Bengali多个领域中共指消解现象的差异，并促进Bengali的资源开发。多个模型在该数据集上训练的性能也得到了报告。在跨语言测试中，从英语到Bengali的交叉语言性能较差，显示出需要语言特定的共指消解系统。

    

    共指消解是自然语言处理中一个被广泛研究的问题。然而，由于缺乏相关数据集，Bengali 的共指消解研究主要未被探索。本文介绍了一个新的数据集BenCoref，包括来自四个不同领域的Bengali文本的共指注释。该数据集包含5200个提及注释，形成48,569个标记中的502个提及簇。我们描述了创建此数据集的过程，并报告了使用BenCoref训练的多个模型的性能。我们预计我们的工作将揭示Bengali多个领域中共指现象的差异，并鼓励开发其他Bengali资源。此外，我们发现在零样本设置下从英语到Bengali的交叉语言性能很差，这突显出需要语言特定的共指消解系统。

    Coreference Resolution is a well studied problem in NLP. While widely studied for English and other resource-rich languages, research on coreference resolution in Bengali largely remains unexplored due to the absence of relevant datasets. Bengali, being a low-resource language, exhibits greater morphological richness compared to English. In this article, we introduce a new dataset, BenCoref, comprising coreference annotations for Bengali texts gathered from four distinct domains. This relatively small dataset contains 5200 mention annotations forming 502 mention clusters within 48,569 tokens. We describe the process of creating this dataset and report performance of multiple models trained using BenCoref. We anticipate that our work sheds some light on the variations in coreference phenomena across multiple domains in Bengali and encourages the development of additional resources for Bengali. Furthermore, we found poor crosslingual performance at zero-shot setting from English, highlig
    
[^81]: ContraSim -- 基于对比学习的相似度度量方法

    ContraSim -- A Similarity Measure Based on Contrastive Learning. (arXiv:2303.16992v1 [cs.CL])

    [http://arxiv.org/abs/2303.16992](http://arxiv.org/abs/2303.16992)

    本文提出了一种新的相似度度量方法: ContraSim，该方法利用对比学习学习参数化的度量方法。实验表明，ContraSim在多种基准测试中均获得了比之前相似度量方法更高的准确性。

    

    最近有研究通过基于相似性的分析比较神经网络表示，揭示了不同方面（如架构、训练数据等）如何影响模型的内部表示。相似度量的质量通常通过其在预期匹配的表示中分配高分数的成功来评估。然而，现有的相似度量在标准基准测试中表现平庸。本文提出一种新的相似度度量方法，称为ContraSim，基于对比学习，与常见的闭式相似性度量不同，ContraSim使用相似和不相似的示例来学习参数化的度量方法。我们在标准的图层预测基准测试和我们介绍的两个新基准测试中使用语言和视觉模型进行广泛的实验评估：多语言基准测试和图像字幕基准测试。在所有情况下，ContraSim的准确性都比之前的相似度量方法高得多。

    Recent work has compared neural network representations via similarity-based analyses, shedding light on how different aspects (architecture, training data, etc.) affect models' internal representations. The quality of a similarity measure is typically evaluated by its success in assigning a high score to representations that are expected to be matched. However, existing similarity measures perform mediocrely on standard benchmarks. In this work, we develop a new similarity measure, dubbed ContraSim, based on contrastive learning. In contrast to common closed-form similarity measures, ContraSim learns a parameterized measure by using both similar and dissimilar examples. We perform an extensive experimental evaluation of our method, with both language and vision models, on the standard layer prediction benchmark and two new benchmarks that we introduce: the multilingual benchmark and the image-caption benchmark. In all cases, ContraSim achieves much higher accuracy than previous simila
    
[^82]: GPT-3在语法纠错上性能的分析

    An Analysis of GPT-3's Performance in Grammatical Error Correction. (arXiv:2303.14342v1 [cs.CL])

    [http://arxiv.org/abs/2303.14342](http://arxiv.org/abs/2303.14342)

    本文分析了GPT-3模型在语法纠错任务上的表现，通过实验测试了几种不同的提示方式，揭示了人类评分者与基于参考的自动度量之间的差异。

    

    GPT-3模型具有很高的自然语言处理能力，在各种任务上表现出色。然而，目前对它们在语法纠错(GEC)任务上的表现缺乏详细的分析。因此，我们对GPT-3模型（text-davinci-003版本）进行了实验，测试了几种不同的提示方式，包括零样本学习和少样本学习。我们分析了使用不同提示格式遇到的有趣或有问题的输出。我们使用自动评估和人类评价相结合的方法，报告了我们最佳提示在BEA-2019和JFLEG数据集上的表现，揭示了人类评分者与基于参考的自动度量之间的有趣差异。

    GPT-3 models are very powerful, achieving high performance on a variety of natural language processing tasks. However, there is a relative lack of detailed published analysis on how well they perform on the task of grammatical error correction (GEC). To address this, we perform experiments testing the capabilities of a GPT-3 model (text-davinci-003) against major GEC benchmarks, comparing the performance of several different prompts, including a comparison of zero-shot and few-shot settings. We analyze intriguing or problematic outputs encountered with different prompt formats. We report the performance of our best prompt on the BEA-2019 and JFLEG datasets using a combination of automatic metrics and human evaluations, revealing interesting differences between the preferences of human raters and the reference-based automatic metrics.
    
[^83]: CB2：合作自然语言交互研究平台

    CB2: Collaborative Natural Language Interaction Research Platform. (arXiv:2303.08127v1 [cs.LG])

    [http://arxiv.org/abs/2303.08127](http://arxiv.org/abs/2303.08127)

    CB2是一个用于研究基于任务的合作自然语言交互的平台，在3D游戏环境中提供了后端服务器和各种工具和流程。它在可扩展的研究中展示了学习的指令跟随模型。

    

    CB2 是一个多智能体平台，用于研究基于任务的情境下的合作自然语言交互。它包括一个 3D 游戏环境、一个后端服务器，可为人类智能体提供训练模型，以及各种工具和流程，以实现可扩展性的研究。我们在 https://cb2.ai 上展示了一个具有学习指令跟随模型的系统演示。

    CB2 is a multi-agent platform to study collaborative natural language interaction in a grounded task-oriented scenario. It includes a 3D game environment, a backend server designed to serve trained models to human agents, and various tools and processes to enable scalable studies. We deploy CB2 at https://cb2.ai as a system demonstration with a learned instruction following model.
    
[^84]: 无监督的逐层文本OOD检测得分聚合

    Unsupervised Layer-wise Score Aggregation for Textual OOD Detection. (arXiv:2302.09852v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.09852](http://arxiv.org/abs/2302.09852)

    提出了一种无监督的逐层聚合异常得分的方法，用于更好地进行文本OOD检测。其能发掘不同层输出的优势，达到更鲁棒的性能，并扩展经典基准测试以反映更现实的设置。

    

    随着越来越多基于AI的系统增加，OOD检测是一个迅速发展的领域，由于新的鲁棒性和安全性要求。现有的OOD文本检测器通常依赖于在编码器的最后一层输出上计算的异常得分（例如马氏距离）。在这项工作中，我们观察到OOD检测性能因任务和层输出而异。更重要的是，我们表明通常的选择（最后一层）很少是OOD检测的最佳选择，如果选择最佳层，则可以获得更好的结果。为了利用这个观察结果，我们提出了一种数据驱动的无监督方法来结合逐层的异常得分。此外，我们通过包括更多类别的分类任务（高达77）扩展了经典文本OOD基准测试，从而反映更现实的设置。在这个增强的基准测试上，我们展示了所提出的后聚合方法实现了鲁棒的OOD检测性能。

    Out-of-distribution (OOD) detection is a rapidly growing field due to new robustness and security requirements driven by an increased number of AI-based systems. Existing OOD textual detectors often rely on an anomaly score (e.g., Mahalanobis distance) computed on the embedding output of the last layer of the encoder. In this work, we observe that OOD detection performance varies greatly depending on the task and layer output. More importantly, we show that the usual choice (the last layer) is rarely the best one for OOD detection and that far better results could be achieved if the best layer were picked. To leverage this observation, we propose a data-driven, unsupervised method to combine layer-wise anomaly scores. In addition, we extend classical textual OOD benchmarks by including classification tasks with a greater number of classes (up to 77), which reflects more realistic settings. On this augmented benchmark, we show that the proposed post-aggregation methods achieve robust an
    
[^85]: 基于CTC和最优传输的语音翻译预训练方法

    Pre-training for Speech Translation: CTC Meets Optimal Transport. (arXiv:2301.11716v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.11716](http://arxiv.org/abs/2301.11716)

    本文提出了一种基于CTC和最优传输的语音翻译预训练方法，可以有效减小语音和文本模态之间的差距，提高最终的ST准确性。

    

    语音到文本翻译(ST)中的模态差距是一个重要挑战，该文提出了一种预训练方法来减轻这个问题，无需改变ST模型的架构。首先，本文表明连接时序分类(CTC)损失可以通过设计来减小模态差距。通过与更常见的交叉熵损失的定量比较，我们证明了使用CTC进行预训练可以始终实现更好的最终ST准确性。其次，我们提出了一种结合CTC和最优传输的新型预训练方法以进一步减小这种差距。我们的实验证明了使用CTC和最优传输进行预训练相对于仅使用CTC进行预训练和没有进行预训练的基线模型均能够提供持续改进。

    The gap between speech and text modalities is a major challenge in speech-to-text translation (ST). Different methods have been proposed to reduce this gap, but most of them require architectural changes in ST training. In this work, we propose to mitigate this issue at the pre-training stage, requiring no change in the ST model. First, we show that the connectionist temporal classification (CTC) loss can reduce the modality gap by design. We provide a quantitative comparison with the more common cross-entropy loss, showing that pre-training with CTC consistently achieves better final ST accuracy. Nevertheless, CTC is only a partial solution and thus, in our second contribution, we propose a novel pre-training method combining CTC and optimal transport to further reduce this gap. Our method pre-trains a Siamese-like model composed of two encoders, one for acoustic inputs and the other for textual inputs, such that they produce representations that are close to each other in the Wassers
    
[^86]: 通过提示调整实现参数高效的低资源对话状态跟踪

    Parameter-Efficient Low-Resource Dialogue State Tracking by Prompt Tuning. (arXiv:2301.10915v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.10915](http://arxiv.org/abs/2301.10915)

    这篇论文提出了一种通过使用软提示令牌嵌入来学习任务属性的方法，以实现参数高效的低资源对话状态跟踪，同时在不微调语言模型参数的情况下，取得了比之前方法更好的性能表现。

    

    对话状态跟踪是对话管理中的一个重要步骤，需要跟踪用户的信念状态。现有的方法需要大量数据和计算资源对所有语言模型参数进行微调来应对对话状态跟踪任务。在实际部署中，需要为不同的领域和任务使用几十个微调了的语言模型，所需的成本呈指数级增长。为了降低参数大小并更好地利用跨任务共享的信息，我们提出使用软提示令牌嵌入来学习任务属性。在不微调语言模型参数的情况下，我们的方法将参数数量大幅减少到少于之前方法的0.5％，同时实现了更好的低资源对话状态跟踪性能。

    Dialogue state tracking (DST) is an important step in dialogue management to keep track of users' beliefs. Existing works fine-tune all language model (LM) parameters to tackle the DST task, which requires significant data and computing resources for training and hosting. The cost grows exponentially in the real-world deployment where dozens of fine-tuned LM are used for different domains and tasks. To reduce parameter size and better utilize cross-task shared information, we propose to use soft prompt token embeddings to learn task properties. Without tuning LM parameters, our method drastically reduces the number of parameters needed to less than 0.5% of prior works while achieves better low-resource DST performance.
    
[^87]: 连续对比微调改进低资源关系提取

    Continual Contrastive Finetuning Improves Low-Resource Relation Extraction. (arXiv:2212.10823v1 [cs.CL] CROSS LISTED)

    [http://arxiv.org/abs/2212.10823](http://arxiv.org/abs/2212.10823)

    本文提出了一种使用连续对比微调的方法来改进低资源关系提取，通过使用一致的对比学习目标预训练和微调RE模型，以及多中心对比损失来允许一个关系形成多个聚类。实验结果表明该方法可以显着提高低资源情况和领域中的关系提取性能。

    

    关系提取（RE）依赖结构化注释语料库进行模型训练，尤其在低资源情况和领域中，该任务具有挑战性。近期研究通过自监督学习来解决低资源的RE，其中解决方案包括通过RE目标预训练关系嵌入，并通过分类为基础的目标对有标签数据进行微调。然而，这种方法的一个关键挑战是目标之间的差距，它阻止RE模型充分利用预训练表示中的知识。本文旨在弥合差距，并提出使用一致的对比学习目标预训练和微调RE模型。由于在这种表示学习范式中，一个关系可能在表示空间中轻松形成多个聚类，因此我们进一步提出了多中心对比损失，允许一个关系形成多个聚类以更好地对齐预训练。在两个文档中的实验表明，所提出的方法可以在低资源情况和领域中显着提高关系提取性能。

    Relation extraction (RE), which has relied on structurally annotated corpora for model training, has been particularly challenging in low-resource scenarios and domains. Recent literature has tackled low-resource RE by self-supervised learning, where the solution involves pretraining the relation embedding by RE-based objective and finetuning on labeled data by classification-based objective. However, a critical challenge to this approach is the gap in objectives, which prevents the RE model from fully utilizing the knowledge in pretrained representations. In this paper, we aim at bridging the gap and propose to pretrain and finetune the RE model using consistent objectives of contrastive learning. Since in this kind of representation learning paradigm, one relation may easily form multiple clusters in the representation space, we further propose a multi-center contrastive loss that allows one relation to form multiple clusters to better align with pretraining. Experiments on two docum
    
[^88]: 4D ASR：CTC、Attention、RNN-T和Mask-Predict解码器的联合建模。

    4D ASR: Joint modeling of CTC, Attention, Transducer, and Mask-Predict decoders. (arXiv:2212.10818v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2212.10818](http://arxiv.org/abs/2212.10818)

    本文介绍了一种CTC、Attention、RNN-T和Mask-Predict四个解码器的联合建模(4D)，它可以高效地建模不同类型的ASR任务，包括低资源语音、代码转换语音和不同场景下的语音，并且性能优于单一模型和两个混合模型。

    

    无论是CTC、RNN-T、注意力机制还是非自回归的Mask-Predict模型，端到端(E2E)自动语音识别(ASR)的网络架构都可归为几类。由于每个架构都有其优势和劣势，因此典型的用例是根据应用需求切换这些独立模型，导致维护所有模型的开销增加。已经提出了几种方法来集成这些互补模型中的两种以减轻开销问题；然而，如果我们集成更多模型，我们将进一步从这些互补模型中受益，并通过单一系统实现更广泛的应用。本文提出了CTC、Attention、RNN-T和Mask-Predict四个解码器的联合建模(4D)，具有以下三个优点：1) 四个解码器联合训练，因此根据应用程序可以轻松切换；2) 提出的4D模型优于单一模型和两个混合模型；3) 该模型可以高效地建模不同类型的ASR任务，包括低资源语音、代码转换语音和不同场景下的语音。

    The network architecture of end-to-end (E2E) automatic speech recognition (ASR) can be classified into several models, including connectionist temporal classification (CTC), recurrent neural network transducer (RNN-T), attention mechanism, and non-autoregressive mask-predict models. Since each of these network architectures has pros and cons, a typical use case is to switch these separate models depending on the application requirement, resulting in the increased overhead of maintaining all models. Several methods for integrating two of these complementary models to mitigate the overhead issue have been proposed; however, if we integrate more models, we will further benefit from these complementary models and realize broader applications with a single system. This paper proposes four-decoder joint modeling (4D) of CTC, attention, RNN-T, and mask-predict, which has the following three advantages: 1) The four decoders are jointly trained so that they can be easily switched depending on t
    
[^89]: ORCA: 一项挑战性的阿拉伯语言理解基准评估

    ORCA: A Challenging Benchmark for Arabic Language Understanding. (arXiv:2212.10758v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10758](http://arxiv.org/abs/2212.10758)

    ORCA 是一个公开可用的阿拉伯语言理解评估基准，利用各种阿拉伯语言和一系列有挑战性的阿拉伯语言理解任务构建。当前使用 ORCA 对 18 个多语言和阿拉伯语言模型进行比较。

    

    由于其在所有 NLP 中的关键作用，已提出了多个基准来评估预训练语言模型。尽管有这些努力，目前尚不存在专门用于评估阿拉伯语的多样化公共基准。这使得同时评估阿拉伯语和多语言语言模型的进展变得具有挑战性。这个挑战还因阿拉伯语不是单一语言而是一系列语言和方言而变得更加困难。在这项工作中，我们介绍了 ORCA，一项公开可用的阿拉伯语言理解评估基准。ORCA 被精心构建，以覆盖多种阿拉伯语言和一系列有挑战性的阿拉伯语言理解任务，利用七个 NLU 任务集群中的 60 种不同数据集。为了衡量当前阿拉伯语 NLU 的进展，我们使用 ORCA 在 18 个多语言和阿拉伯语言模型之间进行了全面对比。我们还提供了一个公共排行榜。

    Due to their crucial role in all NLP, several benchmarks have been proposed to evaluate pretrained language models. In spite of these efforts, no public benchmark of diverse nature currently exists for evaluation of Arabic. This makes it challenging to measure progress for both Arabic and multilingual language models. This challenge is compounded by the fact that any benchmark targeting Arabic needs to take into account the fact that Arabic is not a single language but rather a collection of languages and varieties. In this work, we introduce ORCA, a publicly available benchmark for Arabic language understanding evaluation. ORCA is carefully constructed to cover diverse Arabic varieties and a wide range of challenging Arabic understanding tasks exploiting 60 different datasets across seven NLU task clusters. To measure current progress in Arabic NLU, we use ORCA to offer a comprehensive comparison between 18 multilingual and Arabic language models. We also provide a public leaderboard 
    
[^90]: 语义信息指导的分层事件建模

    Semantically-informed Hierarchical Event Modeling. (arXiv:2212.10547v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10547](http://arxiv.org/abs/2212.10547)

    本文提出了一种双层次、半监督的事件建模框架，通过注入在事件类型层面定义的结构化本体知识来指导隐变量的压缩，相比之前的最先进方法在不同的数据集和评估指标上均提升了多达8.5%的性能。

    

    先前的研究表明，将语义本体知识与顺序隐变量模型相结合可以改善事件建模方法的表达能力。在本文中，我们提出了一种新颖的双层次、半监督事件建模框架，提供结构层次并考虑本体层次。我们的方法包括多层结构隐变量，每个连续层都压缩和抽象先前的层。我们通过注入在事件类型层面定义的结构化本体知识来指导这种压缩：重要的是，我们的模型允许部分注入语义知识，并且不依赖于在任何特定层次的语义本体观察实例。在两个不同的数据集和四个不同的评估指标上，我们展示了我们的方法能够比之前的最先进的方法提高多达8.5%的性能， demonstrating:

    Prior work has shown that coupling sequential latent variable models with semantic ontological knowledge can improve the representational capabilities of event modeling approaches. In this work, we present a novel, doubly hierarchical, semi-supervised event modeling framework that provides structural hierarchy while also accounting for ontological hierarchy. Our approach consists of multiple layers of structured latent variables, where each successive layer compresses and abstracts the previous layers. We guide this compression through the injection of structured ontological knowledge that is defined at the type level of events: importantly, our model allows for partial injection of semantic knowledge and it does not depend on observing instances at any particular level of the semantic ontology. Across two different datasets and four different evaluation metrics, we demonstrate that our approach is able to out-perform the previous state-of-the-art approaches by up to 8.5%, demonstratin
    
[^91]: 何时不信任语言模型：探索参数和非参数记忆的有效性和限制。

    When Not to Trust Language Models: Investigating Effectiveness and Limitations of Parametric and Non-Parametric Memories. (arXiv:2212.10511v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10511](http://arxiv.org/abs/2212.10511)

    本文通过对10个模型和4种增强方法的实验，发现语言模型在记忆不太流行的实际知识方面存在困难，而检索增强的语言模型表现较好，提出了一种检索增强语言模型的简单有效方法。

    

    尽管大型语言模型在各种任务上表现出色，但仍然难以处理需要丰富世界知识的任务，这暗示了仅依靠其参数来编码丰富的世界知识的局限性。本文旨在通过对10个模型和4种增强方法在PopQA上进行大规模知识探测实验，以了解语言模型在记忆事实知识方面的优点和局限性。我们发现，语言模型难以记忆不太流行的实际知识，并且在长尾中，扩展规模无法明显改善记忆实际知识。然后，我们展示了检索增强的语言模型在很大程度上胜过级别大得多的语言模型，而未经协助的语言模型在涉及高流行实体的问题上仍然具有竞争力。基于这些发现，我们设计了一种简单而有效的强大和高效的检索增强语言模型方法，该方法仅在需要时检索非参数记忆。

    Despite their impressive performance on diverse tasks, large language models (LMs) still struggle with tasks requiring rich world knowledge, implying the limitations of relying solely on their parameters to encode a wealth of world knowledge. This paper aims to understand LMs' strengths and limitations in memorizing factual knowledge, by conducting large-scale knowledge probing experiments of 10 models and 4 augmentation methods on PopQA, our new open-domain QA dataset with 14k questions. We find that LMs struggle with less popular factual knowledge, and that scaling fails to appreciably improve memorization of factual knowledge in the long tail. We then show that retrieval-augmented LMs largely outperform orders of magnitude larger LMs, while unassisted LMs remain competitive in questions about high-popularity entities. Based on those findings, we devise a simple, yet effective, method for powerful and efficient retrieval-augmented LMs, which retrieves non-parametric memories only whe
    
[^92]: 一种嵌入器，多种任务: 基于任务说明微调的文本嵌入方法

    One Embedder, Any Task: Instruction-Finetuned Text Embeddings. (arXiv:2212.09741v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09741](http://arxiv.org/abs/2212.09741)

    使用任务说明微调的单一文本嵌入器INSTRUCTOR，在多个领域和任务的基准测试中实现了最先进的性能，并且功能强大，适应性强。

    

    我们引入了一种名为INSTRUCTOR的新方法，用于根据任务说明计算文本嵌入：每个文本输入都与解释用例（例如，任务和领域描述）一起嵌入。与之前更专业化的编码器不同，INSTRUCTOR是一个单一嵌入器，可以生成适用于不同下游任务和领域的文本嵌入，无需进一步训练。我们首先为330个不同的任务注释了任务说明，并使用对比损失在此多任务混合中训练INSTRUCTOR。我们在70个嵌入评估任务上评估了INSTRUCTOR（其中有66个在训练期间未见过），涵盖分类、信息检索、语义文本相似性和文本生成等方面的任务。INSTRUCTOR虽然拥有比之前最佳模型少一个数量级的参数，但在70个不同数据集上平均改进了3.4％，实现了最先进的性能。我们的分析显示，INSTRUCTOR适应不同任务和领域的能力是由于它有效地使用任务说明，它们作为编码器的软提示。我们还在三个下游任务上证明了INSTRUCTOR的实用性：领域适应、小样本学习和跨语言转移，在所有情况下都优于先前的最佳性能。

    We introduce INSTRUCTOR, a new method for computing text embeddings given task instructions: every text input is embedded together with instructions explaining the use case (e.g., task and domain descriptions). Unlike encoders from prior work that are more specialized, INSTRUCTOR is a single embedder that can generate text embeddings tailored to different downstream tasks and domains, without any further training. We first annotate instructions for 330 diverse tasks and train INSTRUCTOR on this multitask mixture with a contrastive loss. We evaluate INSTRUCTOR on 70 embedding evaluation tasks (66 of which are unseen during training), ranging from classification and information retrieval to semantic textual similarity and text generation evaluation. INSTRUCTOR, while having an order of magnitude fewer parameters than the previous best model, achieves state-of-the-art performance, with an average improvement of 3.4% compared to the previous best results on the 70 diverse datasets. Our ana
    
[^93]: LENS：一种可学习的文本简化评估指标

    LENS: A Learnable Evaluation Metric for Text Simplification. (arXiv:2212.09739v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09739](http://arxiv.org/abs/2212.09739)

    本文提出了一种用于文本简化的可学习评估度量标准LENS，通过引入SimpeEval语料库作为人类评估数据集，与现有度量标准相比，LENS对人类判断相关性更好，为评估文本简化的未来进展铺平了道路。

    

    最近，使用现代语言模型训练可学习度量标准已成为自动评估机器翻译的一种有前途的方法。然而，现有的用于文本简化的人类评估数据集只有一些基于单一或过时模型的有限注释，使它们不能适用于这种方法。为解决这些问题，我们引入了SimpEval语料库，其中包括：SimpEval_past，包括对24个过去系统2.4K简化的12K人类评分，以及SimpEval_2022，一个具有挑战性的简化基准，包含了对360个简化，包括GPT-3.5生成文本的1K人类评分。在SimpEval上进行训练，我们提出了一种用于文本简化的可学习评估度量标准LENS。广泛的实证结果表明，LENS与人类判断相关性更好，为评估文本简化的未来进展铺平了道路。我们还引入了Rank和Rate，一种人类评估框架，用于对简化进行排名和评分。

    Training learnable metrics using modern language models has recently emerged as a promising method for the automatic evaluation of machine translation. However, existing human evaluation datasets for text simplification have limited annotations that are based on unitary or outdated models, making them unsuitable for this approach. To address these issues, we introduce the SimpEval corpus that contains: SimpEval_past, comprising 12K human ratings on 2.4K simplifications of 24 past systems, and SimpEval_2022, a challenging simplification benchmark consisting of over 1K human ratings of 360 simplifications including GPT-3.5 generated text. Training on SimpEval, we present LENS, a Learnable Evaluation Metric for Text Simplification. Extensive empirical results show that LENS correlates much better with human judgment than existing metrics, paving the way for future progress in the evaluation of text simplification. We also introduce Rank and Rate, a human evaluation framework that rates si
    
[^94]: 多元价值：跨方言的英文NLP框架

    Multi-VALUE: A Framework for Cross-Dialectal English NLP. (arXiv:2212.08011v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.08011](http://arxiv.org/abs/2212.08011)

    该论文介绍了一个跨方言的英文NLP框架Multi-VALUE，该框架可以将标准美式英语映射为50种英语方言的合成形式，用于评估、实现英式方言临近性，并在非标准方言上进行压力测试。

    

    区域、社会和经济因素引起的方言差异对许多语言技术用户造成了性能差异。普惠和公平的语言技术必须是临近方言的，这意味着在方言转换时性能保持不变。由于它们的设计和测试都是基于标准美式英语（SAE），目前的系统往往不能达到这个理想状态。我们介绍了一个资源套件，用于评估和实现英式方言临近性，称之为Multi-VALUE，它是一个可控制的基于规则的翻译系统，覆盖了50种英语方言和189个独特的语言特征。Multi-VALUE将SAE映射到每种方言的合成形式。我们首先使用这个系统进行压力测试，测试问答、机器翻译和语义解析。压力测试揭示了在非标准方言上的领先模型的显着性能差距。其次，我们使用这个系统作为数据增强技术以改善性能。

    Dialect differences caused by regional, social, and economic factors cause performance discrepancies for many groups of language technology users. Inclusive and equitable language technology must critically be dialect invariant, meaning that performance remains constant over dialectal shifts. Current systems often fall short of this ideal since they are designed and tested on a single dialect: Standard American English (SAE). We introduce a suite of resources for evaluating and achieving English dialect invariance. The resource is called Multi-VALUE, a controllable rule-based translation system spanning 50 English dialects and 189 unique linguistic features. Multi-VALUE maps SAE to synthetic forms of each dialect. First, we use this system to stress tests question answering, machine translation, and semantic parsing. Stress tests reveal significant performance disparities for leading models on non-standard dialects. Second, we use this system as a data augmentation technique to improve
    
[^95]: Prompting就是编程: 一种大语言模型的查询语言

    Prompting Is Programming: A Query Language for Large Language Models. (arXiv:2212.06094v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.06094](http://arxiv.org/abs/2212.06094)

    LMP将语言模型提示从纯文本提示扩展为文本提示和脚本的直观组合，实现了一种新的语言模型编程方式。

    

    大型语言模型在问答和代码生成等各种任务上展现出了优异的表现。从高层次上讲，给定输入，语言模型可以用统计上的可能性自动完成序列。基于此，用户通过语言指令或示例来提示这些模型，以执行各种下游任务。高级提示方法甚至可以暗示模型、用户和计算器等外部工具之间的交互。然而，为了获得最先进的性能或将语言模型适应特定任务，必须实现复杂的任务-和模型特定的程序，这仍然可能需要特定的交互。基于此，我们提出了语言模型编程（LMP）的新概念。LMP将语言模型提示从纯文本提示扩展为文本提示和脚本的直观组合。此外，LMP允许指定语言模型的约束条件。

    Large language models have demonstrated outstanding performance on a wide range of tasks such as question answering and code generation. On a high level, given an input, a language model can be used to automatically complete the sequence in a statistically-likely way. Based on this, users prompt these models with language instructions or examples, to implement a variety of downstream tasks. Advanced prompting methods can even imply interaction between the language model, a user, and external tools such as calculators. However, to obtain state-of-the-art performance or adapt language models for specific tasks, complex task- and model-specific programs have to be implemented, which may still require ad-hoc interaction.  Based on this, we present the novel idea of Language Model Programming (LMP). LMP generalizes language model prompting from pure text prompts to an intuitive combination of text prompting and scripting. Additionally, LMP allows constraints to be specified over the languag
    
[^96]: GPT-3 驱动的教育智能体训练儿童好奇心问题提问技巧

    GPT-3-driven pedagogical agents for training children's curious question-asking skills. (arXiv:2211.14228v5 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.14228](http://arxiv.org/abs/2211.14228)

    该研究探索了使用自然语言处理技术自动生成儿童好奇心问题提问培训的教育内容，该方法显示出了很高的相关性和教育价值。

    

    为了训练儿童提问好奇心驱动的问题的能力，之前的研究探索了设计特定的练习，依靠提供语义和语言提示来帮助形成这样的问题。但尽管表现出了教学效率，但该方法仍然受限于手动生成提示，这可能是一个非常昂贵的过程。在这种情况下，我们提议利用自然语言处理领域（NLP）的先进技术，并调查使用大型语言模型（LLM）自动化好奇心问题提问（QA）培训的教育内容的有效性。我们研究使用“基于提示”的方法来生成教育内容，该方法包括使用自然文本向LLM解释任务。我们使用人类专家注释和手动生成内容进行评估。结果确实表明了这种内容的相关性和有用性。我们还在小学进行了现场研究（75个孩子）

    In order to train children's ability to ask curiosity-driven questions, previous research has explored designing specific exercises relying on providing semantic and linguistic cues to help formulate such questions. But despite showing pedagogical efficiency, this method is still limited as it relies on generating the said cues by hand, which can be a very costly process. In this context, we propose to leverage advances in the natural language processing field (NLP) and investigate the efficiency of using a large language model (LLM) for automating the production of the pedagogical content of a curious question-asking (QA) training. We study generating the said content using the "prompt-based" method that consists of explaining the task to the LLM in natural text. We evaluate the output using human experts annotations and comparisons with hand-generated content. Results suggested indeed the relevance and usefulness of this content. We also conduct a field study in primary school (75 ch
    
[^97]: 多项选择阅读理解中的世界知识

    World Knowledge in Multiple Choice Reading Comprehension. (arXiv:2211.07040v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.07040](http://arxiv.org/abs/2211.07040)

    本文研究了在多项选择阅读理解中利用世界知识的可能性，并提出了基于信息理论的度量方法，这些方法能够评估系统利用世界知识的水平，帮助测试设计人员确保使用世界知识的问题是可接受的，同时可以测试问题的质量并发现设计中可能存在的问题。

    

    最近的研究表明，在没有上下文语境的情况下，多项选择阅读理解（MCRC）系统能够比随机回答问题要好得多。这些系统使用他们积累的“世界知识”来直接回答问题，而不使用来自段落的信息。本文探讨了利用这个观察结果作为测试设计工具的可能性，以确保在特定的一组问题中使用“世界知识”是可接受的。我们提出了基于信息理论的度量方法，可以评估系统利用"世界知识"的水平。我们描述了两个度量标准：期望选项数，它测量了无需使用上下文信息，系统是否可以利用世界知识来确定一个问题的答案；词汇互信息，它测量了对于给定的问题来说上下文的重要性。我们证明了那些期望选项数较低的问题，即可以利用世界知识来回答的问题，可以被准确地鉴定。我们的结果进一步表明，我们所提出的度量方法可以用于测试问题的质量并确定测试设计中可能存在的问题。

    Recently it has been shown that without any access to the contextual passage, multiple choice reading comprehension (MCRC) systems are able to answer questions significantly better than random on average. These systems use their accumulated "world knowledge" to directly answer questions, rather than using information from the passage. This paper examines the possibility of exploiting this observation as a tool for test designers to ensure that the use of "world knowledge" is acceptable for a particular set of questions. We propose information-theory based metrics that enable the level of "world knowledge" exploited by systems to be assessed. Two metrics are described: the expected number of options, which measures whether a passage-free system can identify the answer a question using world knowledge; and the contextual mutual information, which measures the importance of context for a given question. We demonstrate that questions with low expected number of options, and hence answerabl
    
[^98]: 使用矛盾能够改善问答系统

    Using contradictions improves question answering systems. (arXiv:2211.05598v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.05598](http://arxiv.org/abs/2211.05598)

    本论文研究了在自然语言推理中使用矛盾技术进行问答，发现结合矛盾、支持和问答模型置信分数的系统表现最佳。

    

    本论文研究在自然语言推理中使用矛盾技术进行问答。通常，自然语言推理系统通过确定一个潜在答案是否被一些背景语境所支持来帮助回答问题。但是，确定一个答案是否与上下文矛盾是否有用呢？我们在多项选择和抽取式问答两个场景中进行测试，并发现在某些数据集上，结合矛盾技术的系统可比仅有支持技术的系统表现更好。然而，结合矛盾、支持和问答模型置信分数的系统表现最佳。这对于在医学和科学等领域部署问答系统时具有重要意义，因为涉及到安全问题。

    This work examines the use of contradiction in natural language inference (NLI) for question answering (QA). Typically, NLI systems help answer questions by determining if a potential answer is \emph{entailed} (supported) by some background context. But is it useful to also determine if an answer contradicts the context? We test this in two settings, multiple choice and extractive QA, and find that systems that incorporate contradiction can do slightly better than entailment-only systems on certain datasets. However, the best performances come from using contradiction, entailment, and QA model confidence scores together. This has implications for the deployment of QA systems in domains such as medicine and science where safety is an issue.
    
[^99]: LAMASSU: 使用神经变换器的流式跨语言通用语音识别与翻译模型

    LAMASSU: A Streaming Language-Agnostic Multilingual Speech Recognition and Translation Model Using Neural Transducers. (arXiv:2211.02809v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.02809](http://arxiv.org/abs/2211.02809)

    LAMASSU 是一个使用神经变换器的流式跨语言通用语音识别和翻译模型，能显著降低模型大小并达到与单语 ASR 和双语翻译模型相当的性能。

    

    自动语音识别（ASR）和语音翻译（ST）可以同时使用神经变换器作为模型结构，因此可以使用单个变换器模型执行两个任务。在实际应用中，这种联合 ASR 和 ST 模型可能需要流式处理并且不需要源语言识别（即跨语言）。在本文中，我们提出了 LAMASSU，这是一个使用神经变换器的流式跨语言通用语音识别和翻译模型。基于变换器模型结构，我们提出了四种方法：用于多语言输出的统一联合和预测网络、聚类式多语言编码器、编码器的目标语言识别、以及连结时序分类正则化。实验结果表明，LAMASSU 不仅显著降低了模型大小，而且达到了单语 ASR 和双语翻译模型的性能水平。

    Automatic speech recognition (ASR) and speech translation (ST) can both use neural transducers as the model structure. It is thus possible to use a single transducer model to perform both tasks. In real-world applications, such joint ASR and ST models may need to be streaming and do not require source language identification (i.e. language-agnostic). In this paper, we propose LAMASSU, a streaming language-agnostic multilingual speech recognition and translation model using neural transducers. Based on the transducer model structure, we propose four methods, a unified joint and prediction network for multilingual output, a clustered multilingual encoder, target language identification for encoder, and connectionist temporal classification regularization. Experimental results show that LAMASSU not only drastically reduces the model size but also reaches the performances of monolingual ASR and bilingual ST models.
    
[^100]: 显著图翻译：模型无关和基于指令方法的特征重要性表示比较。

    Saliency Map Verbalization: Comparing Feature Importance Representations from Model-free and Instruction-based Methods. (arXiv:2210.07222v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.07222](http://arxiv.org/abs/2210.07222)

    本研究探索了将显著图转换为自然语言的任务，提出了两种新方法与传统方法的比较，并指导了GPT-3.5生成显著图言语化，得到最高人类评分的结果。

    

    显著图可以通过识别重要的输入特征来解释神经模型的预测。但是，它们很难被非专业人士解释，特别是对于具有许多特征的实例。为了使它们更易于理解，我们规范化了将显著图转换为自然语言的任务，并比较了两种关键挑战的方法：什么和如何表达。在自动和人工评估设置中，利用文本分类任务的标记级属性，我们比较了两种新方法（基于搜索和基于指令的表达）与传统的特征重要性表示（热图可视化和抽取理性），评估可模拟性、忠诚度、帮助性和易理解性。通过指导 GPT-3.5 生成显著图言语化，可以得到合理的解释，包括关联、抽象概括和常识推理，从而取得了迄今最高的人类评分。

    Saliency maps can explain a neural model's predictions by identifying important input features. They are difficult to interpret for laypeople, especially for instances with many features. In order to make them more accessible, we formalize the underexplored task of translating saliency maps into natural language and compare methods that address two key challenges of this approach -- what and how to verbalize. In both automatic and human evaluation setups, using token-level attributions from text classification tasks, we compare two novel methods (search-based and instruction-based verbalizations) against conventional feature importance representations (heatmap visualizations and extractive rationales), measuring simulatability, faithfulness, helpfulness and ease of understanding. Instructing GPT-3.5 to generate saliency map verbalizations yields plausible explanations which include associations, abstractive summarization and commonsense reasoning, achieving by far the highest human rat
    
[^101]: 抽取式总结的不忠实性：广泛的不忠实问题调查

    Extractive is not Faithful: An Investigation of Broad Unfaithfulness Problems in Extractive Summarization. (arXiv:2209.03549v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.03549](http://arxiv.org/abs/2209.03549)

    本论文调查抽取式总结中存在的五种广泛的不忠实问题，并发现30%的抽取式摘要存在至少一种问题。为了自动检测这些问题，提出了新的度量标准 ExtEval。

    

    在抽象式总结的背景下，不忠实总结的问题已经被广泛讨论。虽然相较于抽象式总结，抽取式总结更少倾向于普遍的不忠实问题，但这是否意味着抽取式总结等同于忠实呢？结果证明并非如此。在这项工作中，我们定义了一种五种广泛的不忠实问题（包括和超出非蕴含）的分类，这些问题可能出现在抽取式总结中，包括不正确的共指、不完整的共指、不正确的话语、不完整的话语，以及其他具有误导性的信息。我们要求人类对由16个不同的抽取式系统产生的1600篇英文摘要进行标注，我们发现30%的摘要中至少存在五个问题中的一个。为了自动检测这些问题，我们发现5种现有的总结忠实度评估度量与人类评判的相关性差。为了解决这个问题，我们提出了一个新的度量标准 ExtEval。

    The problems of unfaithful summaries have been widely discussed under the context of abstractive summarization. Though extractive summarization is less prone to the common unfaithfulness issues of abstractive summaries, does that mean extractive is equal to faithful? Turns out that the answer is no. In this work, we define a typology with five types of broad unfaithfulness problems (including and beyond not-entailment) that can appear in extractive summaries, including incorrect coreference, incomplete coreference, incorrect discourse, incomplete discourse, as well as other misleading information. We ask humans to label these problems out of 1600 English summaries produced by 16 diverse extractive systems. We find that 30% of the summaries have at least one of the five issues. To automatically detect these problems, we find that 5 existing faithfulness evaluation metrics for summarization have poor correlations with human judgment. To remedy this, we propose a new metric, ExtEval, that
    
[^102]: 类型控制增强的表格生成自然语言模型

    Diversity Enhanced Table-to-Text Generation via Type Control. (arXiv:2205.10938v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.10938](http://arxiv.org/abs/2205.10938)

    该论文提出了一种利用语句逻辑类型增加多样性的表格生成自然语言模型，可促进控制生成语句类型的能力同时提高结果质量和多样性。

    

    从表格数据中生成自然语言语句是一个具有一个输入和多个有效输出的过程（即逻辑 NLG）。这表明需要一种方法来产生多样化的有效输出，呈现出输入数据的不同角度。我们提出了一种简单但有效的多样性增强方案，利用语句的逻辑类型作为内在特征，使用一种类型受控的表格生成自然语言模型。我们通过对两个公开可用的逻辑 NLG 数据集进行广泛的自动化和人工评估，证明了我们提出的方法既促进了有效控制生成语句类型的能力，又在质量和事实多样性权衡方面产生了优于最强基线的结果。

    Generating natural language statements to convey logical inferences from tabular data (i.e., Logical NLG) is a process with one input and a variety of valid outputs. This characteristic underscores the need for a method to produce a diverse set of valid outputs, presenting different perspectives of the input data. We propose a simple yet effective diversity-enhancing scheme that builds upon an inherent property of the statements, their logic-types, by using a type-controlled table-to-text generation model. We demonstrate, through extensive automatic and human evaluations over the two publicly available Logical NLG datasets, that our proposed method both facilitates the ability to effectively control the generated statement type, and produces results superior to the strongest baselines in terms of quality and factuality-diversity trade-off.
    
[^103]: 多臂老虎机用于语言模型预训练的资源高效、在线优化：动态遮盖的使用案例

    Multi-armed bandits for resource efficient, online optimization of language model pre-training: the use case of dynamic masking. (arXiv:2203.13151v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.13151](http://arxiv.org/abs/2203.13151)

    本文提出了一种多臂老虎机框架，用于顺序选择TLM预训练超参数，旨在以资源高效的方式优化语言模型性能。并设计了基于高斯过程的Thompson抽样（GP-TS）算法，加速Pre-training过程并降低MLM损失。

    

    我们设计并评估了一种贝叶斯优化框架，以资源高效的方式预训练基于Transformer的语言模型（TLM）。 TLM预训练需要高计算资源，并引入许多未解决的设计选择，例如选择其预训练超参数。 我们提出了一个多臂老虎机框架，用于顺序选择TLM预训练超参数，旨在以资源高效的方式优化语言模型性能。 我们设计了一个Thompson抽样算法，用于其顺序最小化的带有掩码语言模型（MLM）预训练目标的代理高斯过程奖励模型。 提出的基于高斯过程的Thompson抽样（GP-TS）不是使用固定掩码概率进行MLM预训练，而是通过顺序选择改善性能的掩码超参数来加速预训练。 我们通过实验证明了GP-TS如何高效进行语言模型的预训练，即在少量迭代中实现更低的MLM损失。

    We design and evaluate a Bayesian optimization framework for resource efficient pre-training of Transformer-based language models (TLMs). TLM pre-training requires high computational resources and introduces many unresolved design choices, such as selecting its pre-training hyperparameters. We propose a multi-armed bandit framework for the sequential selection of TLM pre-training hyperparameters, aimed at optimizing language model performance, in a resource efficient manner. We design a Thompson sampling algorithm, with a surrogate Gaussian process reward model of the Masked Language Model (MLM) pre-training objective, for its sequential minimization. Instead of MLM pre-training with fixed masking probabilities, the proposed Gaussian process-based Thompson sampling (GP-TS) accelerates pre-training by sequentially selecting masking hyperparameters that improve performance. We empirically demonstrate how GP-TS pre-trains language models efficiently, i.e., it achieves lower MLM loss in fe
    
[^104]: C2-CRS：面向对话推荐系统的粗到细对比学习

    C2-CRS: Coarse-to-Fine Contrastive Learning for Conversational Recommender System. (arXiv:2201.02732v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2201.02732](http://arxiv.org/abs/2201.02732)

    本文提出了一种新的粗到细对比学习框架，用于对话式推荐系统中多类型外部数据的数据语义融合，在此基础上提高了数据的处理效率。

    

    对话式推荐系统旨在通过自然语言交互向用户推荐适合的物品。为了开发有效的对话式推荐系统，一个主要的技术问题是如何从非常有限的对话上下文中准确地推断用户偏好。为了解决这个问题，一种有前途的解决方案是结合外部数据来丰富上下文信息。然而，以往的研究主要集中在为一些特定类型的外部数据设计融合模型，这不适用于模型和利用多类型的外部数据。为了有效利用多类型的外部数据，我们提出了一种新的粗到细对比学习框架来改善对话式推荐系统的数据语义融合。在我们的方法中，我们首先从不同的数据信号中提取和表示多种粒度的语义单元，然后以粗到细的方式对齐相关的多种语义单元。为了实现这个框架，我们设计了粗粒度和细粒度的过程来对用户建模。

    Conversational recommender systems (CRS) aim to recommend suitable items to users through natural language conversations. For developing effective CRSs, a major technical issue is how to accurately infer user preference from very limited conversation context. To address issue, a promising solution is to incorporate external data for enriching the context information. However, prior studies mainly focus on designing fusion models tailored for some specific type of external data, which is not general to model and utilize multi-type external data.  To effectively leverage multi-type external data, we propose a novel coarse-to-fine contrastive learning framework to improve data semantic fusion for CRS. In our approach, we first extract and represent multi-grained semantic units from different data signals, and then align the associated multi-type semantic units in a coarse-to-fine way. To implement this framework, we design both coarse-grained and fine-grained procedures for modeling user 
    
[^105]: 在社交媒体上检测启发性内容。

    Detecting Inspiring Content on Social Media. (arXiv:2109.02734v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2109.02734](http://arxiv.org/abs/2109.02734)

    本研究尝试通过机器学习方法自动检测社交媒体上具有启发性的内容，首次将启发性引入NLP领域研究。

    

    启发将一个人带到看到新的可能性，并转化他们感知自己潜力的方式。然而，在心理学领域，启发性几乎没有得到研究，这也是NLP社区没有研究过的内容。据我们所知，本文是第一篇使用机器学习方法研究启发性的工作。我们旨在自动检测社交媒体数据中的启发性内容。为此，我们分析社交媒体节目，以找出哪些内容可以启发人并确定哪些主题具有启发性。我们发布了一个数据集，其中包含5800条启发性和5800条非启发性的英语公共帖子独特的ID，这些帖子来自于Reddit公共帖子的转存，以协助使用语言启发来自动检测社交媒体的英语帖子。

    Inspiration moves a person to see new possibilities and transforms the way they perceive their own potential. Inspiration has received little attention in psychology, and has not been researched before in the NLP community. To the best of our knowledge, this work is the first to study inspiration through machine learning methods. We aim to automatically detect inspiring content from social media data. To this end, we analyze social media posts to tease out what makes a post inspiring and what topics are inspiring. We release a dataset of 5,800 inspiring and 5,800 non-inspiring English-language public post unique ids collected from a dump of Reddit public posts made available by a third party and use linguistic heuristics to automatically detect which social media English-language posts are inspiring.
    

