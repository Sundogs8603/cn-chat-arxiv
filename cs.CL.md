# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [MMICL: Empowering Vision-language Model with Multi-Modal In-Context Learning.](http://arxiv.org/abs/2309.07915) | MMICL提出了一种用于视觉-语言模型的架构和训练数据设计，以解决VLM在理解复杂多模态提示方面的困难。 |
| [^2] | [Ambiguity-Aware In-Context Learning with Large Language Models.](http://arxiv.org/abs/2309.07900) | 在上下文学习中，选择与测试输入语义相似的演示有助于提高下游性能，但是考虑到语言模型关于任务的现有知识能够更好地指导演示选择。 |
| [^3] | [Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language Models that Follow Instructions.](http://arxiv.org/abs/2309.07875) | 在训练大型语言模型遵循指令时，仅强调帮助性而不考虑安全性会导致模型产生有害内容。本研究发现，在训练LLaMA模型时添加少量安全示例可以显著提高其安全性，而不影响其能力和帮助性。然而，过度安全调优会使模型拒绝回应表面上类似于不安全提示的合理提示。 |
| [^4] | [Agents: An Open-source Framework for Autonomous Language Agents.](http://arxiv.org/abs/2309.07870) | Agents是一个开源框架，支持构建自主语言代理的各种功能，并提供用户友好的接口和对研究人员的扩展性。 |
| [^5] | [The Rise and Potential of Large Language Model Based Agents: A Survey.](http://arxiv.org/abs/2309.07864) | 基于大型语言模型的代理的崛起和潜力：一项调查。大型语言模型被认为是构建通用人工智能代理的潜在催化剂，许多研究已经取得重要进展。 |
| [^6] | [CiwaGAN: Articulatory information exchange.](http://arxiv.org/abs/2309.07861) | 本文介绍了CiwaGAN模型，该模型结合了无监督声韵学建模和无监督听觉模态信息交流，是对人类口语习得最现实的近似。 |
| [^7] | [ExpertQA: Expert-Curated Questions and Attributed Answers.](http://arxiv.org/abs/2309.07852) | 本论文介绍了ExpertQA，它是一个专家策划的问题和带有属性的答案系统。该系统通过分析语言模型在领域特定情景中提供的事实准确性和归因等方面来确保提供准确的信息。研究还收集了领域专家的问题并要求他们评估生成的答案。这项工作的目的是确保语言模型在高风险领域中不会传播错误信息，从而避免不良的社会后果。 |
| [^8] | [CATfOOD: Counterfactual Augmented Training for Improving Out-of-Domain Performance and Calibration.](http://arxiv.org/abs/2309.07822) | 本研究通过在小型语言模型训练数据中增加自动生成的反事实实例，提高了摘要问答模型在领域外的性能和模型校准能力，并发现性能改进与反事实实例的多样性相关。 |
| [^9] | [Text Classification of Cancer Clinical Trial Eligibility Criteria.](http://arxiv.org/abs/2309.07812) | 本文研究了癌症临床试验中常见的排除标准，通过应用文本分类方法和预训练的BERT模型，证明了自动分类排除标准的可行性，并展示了专门为临床试验设计的预训练语言模型的价值。 |
| [^10] | [Pop Quiz! Do Pre-trained Code Models Possess Knowledge of Correct API Names?.](http://arxiv.org/abs/2309.07804) | 我们研究了预训练代码模型在理解API名称方面的困难，并提出使用知识探测的方法来解释模型。我们发现当前的代码模型在理解API的完全限定名方面遇到了困难。 |
| [^11] | [The Dynamical Principles of Storytelling.](http://arxiv.org/abs/2309.07797) | 这项研究揭示了讲故事的开头部分通常会遵循动作原则，并且这种顺序可能与西方传统讲故事的有关。 |
| [^12] | [Improving Multimodal Classification of Social Media Posts by Leveraging Image-Text Auxiliary tasks.](http://arxiv.org/abs/2309.07794) | 本研究通过引入图像-文本辅助任务，有效地提高了社交媒体帖子的多模态分类，通过两个辅助损失函数对图像-文本表示进行调整，捕捉底层依赖关系和语义对应关系，实现了一致的改进。 |
| [^13] | [Usability Evaluation of Spoken Humanoid Embodied Conversational Agents in Mobile Serious Games.](http://arxiv.org/abs/2309.07773) | 本文通过实证调查评估了移动严肃游戏应用中口语化人形机器人对可用性的影响，结果表明用户更喜欢与高人类相似度的机器人进行交互。 |
| [^14] | [Echotune: A Modular Extractor Leveraging the Variable-Length Nature of Speech in ASR Tasks.](http://arxiv.org/abs/2309.07765) | Echotune是一个模块化特征提取器，利用语音的可变长度特性，通过引入Echo-MSA模块，实现了从帧到话语的各种颗粒度的语音特征提取，解决了固定长度注意力的局限性。 |
| [^15] | [PROGrasp: Pragmatic Human-Robot Communication for Object Grasping.](http://arxiv.org/abs/2309.07759) | PROGrasp是一个实现物体抓取的人机交流系统，通过使用面向意图的多模态对话和答案解释模块，机器人能够根据用户的意图来识别和抓取目标物体。 |
| [^16] | [Generative AI Text Classification using Ensemble LLM Approaches.](http://arxiv.org/abs/2309.07755) | 本文提出了一个利用集成的LLM方法进行生成式AI文本分类的方法，通过使用多个预训练LLM生成概率作为特征来准确检测AI生成的语言，并确定生成文本的特定语言模型的归属。 |
| [^17] | [Explaining Speech Classification Models via Word-Level Audio Segments and Paralinguistic Features.](http://arxiv.org/abs/2309.07733) | 该论文提出了一种解释语音分类模型的新方法，通过在单词级别上解释音频段落和语音特征。该方法通过对输入进行扰动，生成易于理解的解释，并回答了如果修改了音频信号会对模型预测产生怎样影响的问题。通过验证，发现这些解释与模型内部工作相符，且对人类而言是可信的。 |
| [^18] | [PerPLM: Personalized Fine-tuning of Pretrained Language Models via Writer-specific Intermediate Learning and Prompts.](http://arxiv.org/abs/2309.07727) | PerPLM通过个性化中间学习和提示实现个性化的预训练语言模型微调，并在只有目标作者纯文本的情况下将其扩展到多用户，提高了文本理解任务的准确性。 |
| [^19] | [L1-aware Multilingual Mispronunciation Detection Framework.](http://arxiv.org/abs/2309.07719) | 本文介绍了一种L1感知的多语言发音错误检测框架，该框架通过注意力机制对齐输入音频和参考音素序列，并将预训练的辅助模型提取的L1-L2语音嵌入与主要网络进行融合。该框架在英文、阿拉伯语和普通话上的统一多语言音素识别任务中取得了良好的效果。 |
| [^20] | [CoLLD: Contrastive Layer-to-layer Distillation for Compressing Multilingual Pre-trained Speech Encoders.](http://arxiv.org/abs/2309.07707) | CoLLD是一种用于压缩预训练语音编码器的对比层与层蒸馏方法，通过学生模型复制大教师模型的行为来提高性能，并在多语种任务中取得了优异表现。 |
| [^21] | [Tree of Uncertain Thoughts Reasoning for Large Language Models.](http://arxiv.org/abs/2309.07694) | 本研究提出了一种针对大型语言模型的推理框架——不确定思维树（TouT），它通过利用蒙特卡洛丢弃来量化中间步骤上的本地不确定性，提高了模型生成响应的精确性。 |
| [^22] | [Detecting ChatGPT: A Survey of the State of Detecting ChatGPT-Generated Text.](http://arxiv.org/abs/2309.07689) | 这篇调查论文概述了当前用于区分ChatGPT生成文本和人工文本的方法和数据集，并总结了研究发现。 |
| [^23] | [Assessing the nature of large language models: A caution against anthropocentrism.](http://arxiv.org/abs/2309.07683) | 通过评估GPT3.5，我们发现它具有有趣的个性问卷回答能力，但不太可能发展出意识，并显示出较大的认知和个性变异。 |
| [^24] | [A Conversation is Worth A Thousand Recommendations: A Survey of Holistic Conversational Recommender Systems.](http://arxiv.org/abs/2309.07682) | 该论文综述了综合对话式推荐系统的方法，传统方法无法应用于真实世界场景，该论文提出了一种新的方法，即使用真实对话数据进行训练。 |
| [^25] | [Aligning Speakers: Evaluating and Visualizing Text-based Diarization Using Efficient Multiple Sequence Alignment (Extended Version).](http://arxiv.org/abs/2309.07677) | 本文提出了一种新的基于文本的说话人分离评估方法，并引入了多序列对齐算法。提出的度量标准克服了传统方法在文本中缺乏上下文信息的问题，并能够进行更全面的分析。该研究为对话系统的发展提供了可视化和评估工具。 |
| [^26] | [Automatic Data Visualization Generation from Chinese Natural Language Questions.](http://arxiv.org/abs/2309.07650) | 本论文提出了一个中文文本到可视化数据集，并通过使用多语言BERT作为编码器以及融入n-gram信息来解决中文文本到可视化的问题。 |
| [^27] | [Incorporating Class-based Language Model for Named Entity Recognition in Factorized Neural Transducer.](http://arxiv.org/abs/2309.07648) | 这项研究在分解神经传输器中加入了基于类别的语言模型，提升了命名实体识别的能力。 |
| [^28] | [Dynamic MOdularized Reasoning for Compositional Structured Explanation Generation.](http://arxiv.org/abs/2309.07624) | 本文提出了一种动态模块化推理模型MORSE，用于改善神经模型的组合推理能力，通过采用模块化的自注意力机制，实现了对输入的动态选择和路由，提高了神经模型的组合泛化能力。 |
| [^29] | [Zero-shot Audio Topic Reranking using Large Language Models.](http://arxiv.org/abs/2309.07606) | 本论文研究了使用大型语言模型的零-shot重新排序方法，以改善基于主题的视频检索性能，无需任何特定任务的训练数据。 |
| [^30] | [Detecting Misinformation with LLM-Predicted Credibility Signals and Weak Supervision.](http://arxiv.org/abs/2309.07601) | 本文研究了使用大型语言模型和弱监督的方式来检测虚假信息，证明了这种方法在两个数据集上的效果优于当前最先进的分类器。 |
| [^31] | [C-Pack: Packaged Resources To Advance General Chinese Embedding.](http://arxiv.org/abs/2309.07597) | C-Pack是一套推进普通汉语嵌入领域的资源，包括全面汉语文本嵌入基准、大规模文本嵌入数据集和涵盖多个尺寸的嵌入模型系列。该资源集在C-MTEB基准上实现了最高+10%的表现，并通过整合和优化一套训练方法进一步提升了效果。此外，C-Pack还发布了英语文本嵌入数据和模型，实现了最先进的性能。该资源集可公开获取。 |
| [^32] | [Revisiting Supertagging for HPSG.](http://arxiv.org/abs/2309.07590) | 重新审视基于HPSG的Supertagging，在高质量注释的树库和多样化的测试数据集上，通过使用SVM和神经网络方法，取得了较高准确率。相关数据集已整理为标记分类形式，可为现代HPSG解析器提供帮助。 |
| [^33] | [Adaptive Prompt Learning with Distilled Connective Knowledge for Implicit Discourse Relation Recognition.](http://arxiv.org/abs/2309.07561) | 本文提出了一种连续版本的提示学习方法AdaptPrompt，在隐含篇章关系识别中应用连贯知识蒸馏，通过连续提示和知识传递改进性能，减少手动设计工作。 |
| [^34] | [DBLPLink: An Entity Linker for the DBLP Scholarly Knowledge Graph.](http://arxiv.org/abs/2309.07545) | DBLPLink是一个用于DBLP学术知识图的实体链接器，它使用文本到文本的预训练语言模型和实体嵌入来进行实体标签生成和排序。 |
| [^35] | [Direct Text to Speech Translation System using Acoustic Units.](http://arxiv.org/abs/2309.07478) | 本文提出了一种使用离散声学单元的直接文本到语音翻译系统，通过结合语音编码器和聚类算法提取声学单元，并使用编码器-解码器架构预测和生成语音。实验证明，该系统在多数评估的语言对上表现出竞争性能，并且使用更多语言预训练模型进行初始化会带来显著的改进。 |
| [^36] | [Are Large Language Model-based Evaluators the Solution to Scaling Up Multilingual Evaluation?.](http://arxiv.org/abs/2309.07462) | 大型语言模型（LLMs）作为评估器可以解决当前多语言评估的限制和挑战，能够对各种语言中的自然语言处理任务进行有效评估。 |
| [^37] | [SIB-200: A Simple, Inclusive, and Big Evaluation Dataset for Topic Classification in 200+ Languages and Dialects.](http://arxiv.org/abs/2309.07445) | 本研究提出了SIB-200数据集，在200多种语言和方言中提供了一个大规模、全面的主题分类评估数据集。该数据集填补了自然语言理解领域中对评估数据集的缺乏，通过全监督、跨语言迁移和大型语言模型提示的评估，发现性能仍存在差距。 |
| [^38] | [Clinical Text Summarization: Adapting Large Language Models Can Outperform Human Experts.](http://arxiv.org/abs/2309.07430) | 本研究通过对八个大型语言模型在临床摘要任务上的领域适应方法实验进行了全面的定量评估，发现最佳适应的模型的摘要在完整性和正确性方面优于人类摘要。 |
| [^39] | [Semantic Parsing in Limited Resource Conditions.](http://arxiv.org/abs/2309.07429) | 本论文探讨了在有限资源条件下的语义解析的挑战，并提出了解决方案，包括使用自动数据筛选、知识迁移、主动学习和持续学习。具体方法包括合成训练样本、利用源领域知识改进目标领域解析，以及利用有限的人工翻译预算和机器翻译服务来调整解析器。 |
| [^40] | [ChatGPT MT: Competitive for High- (but not Low-) Resource Languages.](http://arxiv.org/abs/2309.07423) | ChatGPT在高资源语言中具有竞争力的机器翻译能力，但在低资源语言方面表现不佳。资源水平是决定其翻译能力的最重要特征。 |
| [^41] | [PromptASR for contextualized ASR with controllable style.](http://arxiv.org/abs/2309.07414) | PromptASR是一个框架，将提示集成到端到端自动语音识别系统中，实现了具有可控风格的语境化语音转录。在实验中，使用前一话语的真实文本作为内容提示时，相对于基线ASR系统，该系统在阅读图书数据集和内部数据集上分别获得了21.9％和6.8％的词错误率降低。此外，该系统可以采用单词级偏置列表作为提示来提高对罕见单词的识别准确性。同时，该系统还可以使用额外的样式提示来引导ASR系统输出不同风格的转录。 |
| [^42] | [CPPF: A contextual and post-processing-free model for automatic speech recognition.](http://arxiv.org/abs/2309.07413) | CPPF是一种上下文和后处理无关的自动语音识别模型，它整合了多个与语音识别相关的ASR文本处理任务，提供了一种优化流程、避免级联错误传播且识别性能几乎没有损失的解决方案。 |
| [^43] | [Advancing Regular Language Reasoning in Linear Recurrent Neural Networks.](http://arxiv.org/abs/2309.07412) | 通过分析现有的线性循环神经网络（LRNN），我们提出了一种新的LRNN模型，该模型配备了一个块对角且输入相关的转移矩阵，并且是唯一一个能够在正则语言任务上进行长度外推的LRNN。 |
| [^44] | [DebCSE: Rethinking Unsupervised Contrastive Sentence Embedding Learning in the Debiasing Perspective.](http://arxiv.org/abs/2309.07396) | 本文重新思考了无监督对比句子嵌入学习，并从去偏见的角度提出了DebCSE方法。通过消除各种偏差，包括词频偏差、句子长度偏差和假负样本偏差，DebCSE旨在学习高质量的句子嵌入。 |
| [^45] | [VDialogUE: A Unified Evaluation Benchmark for Visually-grounded Dialogue.](http://arxiv.org/abs/2309.07387) | VDialogUE是一个用于视觉导向对话的统一评估基准，定义了五个核心多模态对话任务，并涵盖了六个数据集。此外，还引入了一种新的评估指标VDscore，并提供了一个名为VISIT的基线模型来促进通用多模态对话系统的发展。 |
| [^46] | [An Interactive Framework for Profiling News Media Sources.](http://arxiv.org/abs/2309.07384) | 本文提出了一个交互式框架用于对新闻媒体来源进行特征分析，通过结合图形分析模型、预训练语言模型和人类洞察力，可以快速检测虚假和有偏见的新闻媒体。 |
| [^47] | [Less is More for Long Document Summary Evaluation by LLMs.](http://arxiv.org/abs/2309.07382) | 该论文引入了一种新颖的方法，通过先提取关键句子再进行评估，有效解决了大型语言模型在长文档摘要评估中遇到的计算成本高和忽视重要信息的问题。研究发现，这种方法不仅显著降低了评估成本，而且与人工评估有更高的相关性。此外，论文还提供了关于最佳文档长度和句子提取方法的实用建议，为基于大型语言模型的文本生成评估的发展做出了贡献。 |
| [^48] | [Hybrid Attention-based Encoder-decoder Model for Efficient Language Model Adaptation.](http://arxiv.org/abs/2309.07369) | 半混合注意力编码器-解码器模型通过分离声学模型和语言模型，以实现对传统文本语言模型适应技术的利用。在使用域外文本数据进行语言模型适应时，相对于传统模型，该模型可获得21\%的词错误率改进。 |
| [^49] | [Learning from Auxiliary Sources in Argumentative Revision Classification.](http://arxiv.org/abs/2309.07334) | 该论文主要研究了在辩论写作中分类理想的推理修改的模型，并提出了多任务学习和迁移学习两种方法来利用辅助修订数据的来源。研究结果表明，这两种方法可以显著改善分类器的性能，并且迁移学习可以更好地表示数据之间的关系。 |
| [^50] | [Traveling Words: A Geometric Interpretation of Transformers.](http://arxiv.org/abs/2309.07315) | 本文提出了一种几何视角来解释变压器的内部机制，主要贡献在于阐明了层归一化如何限制潜在特征并在超球面上塑造注意力机制，通过探测预训练的GPT-2模型验证了该视角的有效性，并提供了对变压器的直观理解。 |
| [^51] | [Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and Simplicity Bias in MLMs.](http://arxiv.org/abs/2309.07311) | 本文通过对掩码语言模型中的语法习得进行案例研究，发现在训练的一个短暂窗口内，模型突然获得了语法注意结构(SAS)，并伴随着损失的陡峭下降。SAS对随后习得语言能力起到了重要的促进作用。 |
| [^52] | [In-Contextual Bias Suppression for Large Language Models.](http://arxiv.org/abs/2309.07251) | 基于文本前导语和职业描述句生成的反事实命题模板可以有效抑制大型语言模型中的性别偏见，而不需要访问模型参数，并且不会对下游任务性能产生明显的负面影响。 |
| [^53] | [Exploring Large Language Models for Ontology Alignment.](http://arxiv.org/abs/2309.07172) | 本文研究了大型语言模型在本体对齐中的应用，并发现它们有潜力在谨慎的框架和提示设计下超越现有的本体对齐系统。 |
| [^54] | [Stochastic LLMs do not Understand Language: Towards Symbolic, Explainable and Ontologically Based LLMs.](http://arxiv.org/abs/2309.05918) | 随机LLMs无法理解语言的原因是它们无法提供可以依赖的事实信息，它们存储的语言知识埋藏在无意义的微特征中，并在某些语言上下文中无法进行正确推理。本文建议在符号化方法中应用有效的自下而上策略 |
| [^55] | [Zero-shot Learning with Minimum Instruction to Extract Social Determinants and Family History from Clinical Notes using GPT Model.](http://arxiv.org/abs/2309.05475) | 本研究通过将最小信息提供给GPT模型，研究了零-shot学习在从临床记录中提取社会决定因素和家族史信息方面的应用，采用了两组评估指标来评估性能。 |
| [^56] | [USA: Universal Sentiment Analysis Model & Construction of Japanese Sentiment Text Classification and Part of Speech Dataset.](http://arxiv.org/abs/2309.03787) | 本论文提出了一种通过利用单词和整个文本之间的互相增强效应来提高情感分析性能的通用情感分析模型，并构建了新的情感文本分类和词性数据集。该模型在实验中表现出超越gpt-3.5-t的性能。 |
| [^57] | [Knowledge Graph Embeddings for Multi-Lingual Structured Representations of Radiology Reports.](http://arxiv.org/abs/2309.00917) | 本论文提出一种新颖的轻量级基于图的嵌入方法，用于对放射学报告进行多语言结构化表现。通过连接医学术语和多语言知识库，这种嵌入方法揭示了临床术语之间的关系，提供了对临床医生更易理解、临床更准确的表征。 |
| [^58] | [Qwen-VL: A Frontier Large Vision-Language Model with Versatile Abilities.](http://arxiv.org/abs/2308.12966) | Qwen-VL是一种具有多功能能力的前沿大规模视觉-语言模型，它在图像字幕生成、问题回答、视觉定位和灵活交互等任务中表现出卓越性能，优于现有的大规模视觉-语言模型。它在推动多模态人工智能方面做出了重要贡献。 |
| [^59] | [Halo: Estimation and Reduction of Hallucinations in Open-Source Weak Large Language Models.](http://arxiv.org/abs/2308.11764) | 本文介绍了一种用于评估和减少开源弱大语言模型中幻觉问题的框架，并探索了知识注入和师生方法等技术来减轻低参数模型中的幻觉问题，实验结果表明，在挑战性领域中，这些模型的幻觉问题得到了减少。 |
| [^60] | [YORC: Yoruba Reading Comprehension dataset.](http://arxiv.org/abs/2308.09768) | 本文介绍了一个新的多项选择约鲁巴语阅读理解数据集YORC，通过跨语言转移和大型语言模型的使用，提供了该数据集的基准结果和更高层次的结果。 |
| [^61] | [Identical and Fraternal Twins: Fine-Grained Semantic Contrastive Learning of Sentence Representations.](http://arxiv.org/abs/2307.10932) | 本文提出了一种名为同卵和异卵对比学习（IFTCL）框架，通过同时适应不同的正样本对生成方式，在无监督学习句子表示中解决了对比学习中存在的语义扭曲和语义间隔问题。 |
| [^62] | [TIM: Teaching Large Language Models to Translate with Comparison.](http://arxiv.org/abs/2307.04408) | 我们提出了一个使用对比教授大型语言模型进行翻译的新框架，通过向模型呈现正确和错误翻译的示例并使用偏好损失来指导模型学习，我们证明该方法优于现有方法，在精调LLMs用于翻译任务方面提供了新的视角。 |
| [^63] | [Personality Traits in Large Language Models.](http://arxiv.org/abs/2307.00184) | 该研究介绍了一种综合方法，用于验证大型语言模型（LLMs）生成的文本中展示的人格特质。研究发现，部分LLMs在特定提示配置下模拟的人格可靠且有效，特别是对于更大和经过指导微调的模型。此外，LLMs的输出中的人格特质可以根据需要进行塑造。 |
| [^64] | [Generative User-Experience Research for Developing Domain-specific Natural Language Processing Applications.](http://arxiv.org/abs/2306.16143) | 本论文提出了一种在开发领域特定自然语言处理应用中整合生成式用户体验研究的方法。该方法将领域用户纳入原型开发的不同阶段，以更好地了解用户需求和评估用户价值的变化。 |
| [^65] | [Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning.](http://arxiv.org/abs/2306.14565) | 本论文通过引入第一个大型多样化的视觉指令调整数据集，提出了一种解决大规模多模态模型中幻觉问题的方法。通过设计包含正负指令的数据集和提出的评估方法，能够更准确地衡量模型产生的幻觉。 |
| [^66] | [Overview of Robust and Multilingual Automatic Evaluation Metrics for Open-Domain Dialogue Systems at DSTC 11 Track 4.](http://arxiv.org/abs/2306.12794) | 本文综述了DSTC 11 Track 4中针对开放域对话系统进行鲁棒性和多语言自动评估的挑战，介绍了提供给参与者的数据集和基线，并总结了表现最佳的系统及其方法。 |
| [^67] | [COVER: A Heuristic Greedy Adversarial Attack on Prompt-based Learning in Language Models.](http://arxiv.org/abs/2306.05659) | 本文提出了一种启发式贪心对抗攻击，针对基于提示的模板在PLMs中可能存在的漏洞，通过字符级和单词级的破坏方法进行攻击，取得了较高的攻击成功率。 |
| [^68] | [Learning A Foundation Language Model for Geoscience Knowledge Understanding and Utilization.](http://arxiv.org/abs/2306.05064) | 本文首次提出了一个地球科学领域的大型语言模型K2，并开发了各种资源以进一步促进其在地球科学领域中的研究和应用，包括第一个地球科学教学调音数据集GeoSignal和第一个地球科学基准测试GeoBenchmark。我们使用了完整的方法将预先训练的通用领域LLM LLaMA-7B 模型适应到地球科学领域。 |
| [^69] | [Probing in Context: Toward Building Robust Classifiers via Probing Large Language Models.](http://arxiv.org/abs/2305.14171) | 本文提出了一种在上下文中的探测方法，用于构建鲁棒的分类器。通过探测上下文化的表示来预测标签，这种方法对指令变化更加鲁棒，并且在多样化的分类任务上表现出竞争力或更好的性能。 |
| [^70] | [PaLM 2 Technical Report.](http://arxiv.org/abs/2305.10403) | PaLM 2 是一种计算效率更高的最先进的语言模型，提供了更好的多语言和推理能力，并且通过使用多种目标进行训练，获得了在不同模型大小的下游任务上显着的改进质量。此外，PaLM 2 还展示了强大的推理能力和稳定的性能表现，使得模型能够更广泛地部署，并且可以控制毒性推理时间，而不会对其他能力产生影响。 |
| [^71] | [A Latent Space Theory for Emergent Abilities in Large Language Models.](http://arxiv.org/abs/2304.09960) | 本文探讨了大规模语言模型中的贝叶斯推断和稀疏联合分布，证明了LLMs能够完成语言理解、上下文学习、思路启发以及有效指令微调的新兴能力。 |
| [^72] | [MER 2023: Multi-label Learning, Modality Robustness, and Semi-Supervised Learning.](http://arxiv.org/abs/2304.08981) | 多模态情感识别挑战赛（MER 2023）提出了三个子挑战：MER-MULTI、MER-NOISE和MER-SEMI，为全球研究人员构建创新技术提供了激励，并测试了各种多模态特征，提供了有竞争力的基线，以促进鲁棒而有效的算法的发展和应用。 |
| [^73] | [Reasoning with Language Model Prompting: A Survey.](http://arxiv.org/abs/2212.09597) | 本文提供了使用语言模型提示进行推理的前沿研究综合调查。讨论了新兴推理能力出现的潜在原因，并提供系统资源帮助初学者。 |
| [^74] | [LambdaKG: A Library for Pre-trained Language Model-Based Knowledge Graph Embeddings.](http://arxiv.org/abs/2210.00305) | LambdaKG是一个基于预训练语言模型的知识图谱嵌入库，提供了多个预训练语言模型和支持多种任务，如知识图谱补全、问答、推荐和知识探索。 |
| [^75] | [Modern Baselines for SPARQL Semantic Parsing.](http://arxiv.org/abs/2204.12793) | 本文探讨了从自然语言问题生成SPARQL查询的任务，使用预训练语言模型作为新的基准模型，并在DBpedia和Wikidata知识图谱上进行了实验。我们展示了T5模型在LC-QuAD 1.0和LC-QuAD 2.0数据集上表现出最先进的性能，并且能够解析需要将一部分输入复制到输出查询中的问题，这为知识图谱语义解析带来了新的可能性。 |

# 详细

[^1]: MMICL：多模态上下文学习增强视觉-语言模型

    MMICL: Empowering Vision-language Model with Multi-Modal In-Context Learning. (arXiv:2309.07915v1 [cs.CL])

    [http://arxiv.org/abs/2309.07915](http://arxiv.org/abs/2309.07915)

    MMICL提出了一种用于视觉-语言模型的架构和训练数据设计，以解决VLM在理解复杂多模态提示方面的困难。

    

    从深度学习的复苏开始，借助大型语言模型（LLM）的视觉-语言模型（VLM）变得非常流行。然而，尽管LLM可以利用丰富的背景知识和任务信息进行上下文学习，大多数VLM在理解复杂的多模态提示（包含多个图像）方面仍然面临困难。这个问题可以追溯到VLM的架构设计或预训练数据。具体来说，当前的VLM主要强调利用带有单个图像的多模态数据，而不是带有交错多个图像和文本的多模态提示。尽管一些新提出的VLM可以处理带有多个图像的用户提示，但预训练数据没有提供比从Web抓取时交错图像和文本更复杂的多模态提示。我们提出了MMICL，从模型和数据的角度来解决这个问题。我们引入了一个精心设计的架构，能够无缝地集成视觉和语言信息，并提供更丰富的多模态训练数据。

    Starting from the resurgence of deep learning, vision-language models (VLMs) benefiting from large language models (LLMs) have never been so popular. However, while LLMs can utilize extensive background knowledge and task information with in-context learning, most VLMs still struggle with understanding complex multi-modal prompts with multiple images. The issue can traced back to the architectural design of VLMs or pre-training data. Specifically, the current VLMs primarily emphasize utilizing multi-modal data with a single image some, rather than multi-modal prompts with interleaved multiple images and text. Even though some newly proposed VLMs could handle user prompts with multiple images, pre-training data does not provide more sophisticated multi-modal prompts than interleaved image and text crawled from the web. We propose MMICL to address the issue by considering both the model and data perspectives. We introduce a well-designed architecture capable of seamlessly integrating vis
    
[^2]: 具有大型语言模型的上下文学习中的歧义感知

    Ambiguity-Aware In-Context Learning with Large Language Models. (arXiv:2309.07900v1 [cs.CL])

    [http://arxiv.org/abs/2309.07900](http://arxiv.org/abs/2309.07900)

    在上下文学习中，选择与测试输入语义相似的演示有助于提高下游性能，但是考虑到语言模型关于任务的现有知识能够更好地指导演示选择。

    

    在上下文学习（In-context learning, ICL）中，仅向LLMs展示少量任务特定演示已经导致了下游增益，无需进行任务特定的微调。然而，LLMs对于提示选择非常敏感，因此一个关键的研究问题是如何为ICL选择好的演示。一种有效的策略是利用ICL演示和测试输入之间的语义相似性，并使用文本检索器，然而这种方法并不考虑LLM关于该任务的现有知识，因此并不最优。根据之前的工作（Min等，2022），我们已经知道与演示配对的标签会对模型预测造成偏见。这引导我们提出了一个假设：考虑到LLM关于任务的现有知识，特别是与输出标签空间相关的知识，是否有助于更好的演示选择策略。通过在三个文本分类任务上进行广泛的实验，我们发现不仅选择语义相似的ICL演示是有益的，同时也要考虑LLM关于任务的现有知识以获得更好的演示选择策略。

    In-context learning (ICL) i.e. showing LLMs only a few task-specific demonstrations has led to downstream gains with no task-specific fine-tuning required. However, LLMs are sensitive to the choice of prompts, and therefore a crucial research question is how to select good demonstrations for ICL. One effective strategy is leveraging semantic similarity between the ICL demonstrations and test inputs by using a text retriever, which however is sub-optimal as that does not consider the LLM's existing knowledge about that task. From prior work (Min et al., 2022), we already know that labels paired with the demonstrations bias the model predictions. This leads us to our hypothesis whether considering LLM's existing knowledge about the task, especially with respect to the output label space can help in a better demonstration selection strategy. Through extensive experimentation on three text classification tasks, we find that it is beneficial to not only choose semantically similar ICL demon
    
[^3]: 安全调优的LLaMAs：从提高大型语言模型遵循指令的安全性中学到的经验

    Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language Models that Follow Instructions. (arXiv:2309.07875v1 [cs.CL])

    [http://arxiv.org/abs/2309.07875](http://arxiv.org/abs/2309.07875)

    在训练大型语言模型遵循指令时，仅强调帮助性而不考虑安全性会导致模型产生有害内容。本研究发现，在训练LLaMA模型时添加少量安全示例可以显著提高其安全性，而不影响其能力和帮助性。然而，过度安全调优会使模型拒绝回应表面上类似于不安全提示的合理提示。

    

    训练大型语言模型遵循指令可以使它们在各种任务上表现得更好，通常更具有帮助性。然而，一个完全有用的模型会遵循甚至最恶意的指令，并轻易生成有害内容。本文关注的是那些只强调帮助性而不考虑安全性的模型的安全性问题。我们展示了一些流行的指令调优模型非常不安全。此外，我们还展示了在fine-tuning类似LLaMA的模型时，只需将3%的安全示例（几百个演示）添加到训练集中，就能显著提高其安全性。我们的安全调优并不会显著降低模型的能力或帮助性，这是通过标准基准测试来衡量的。但是，我们发现一种过度安全的行为，即过度的安全调优会使得模型拒绝对表面上类似于不安全提示的合理提示做出回应。我们的研究揭示了训练LLM模型遵循指令时的权衡关系。

    Training large language models to follow instructions makes them perform better on a wide range of tasks, generally becoming more helpful. However, a perfectly helpful model will follow even the most malicious instructions and readily generate harmful content. In this paper, we raise concerns over the safety of models that only emphasize helpfulness, not safety, in their instruction-tuning. We show that several popular instruction-tuned models are highly unsafe. Moreover, we show that adding just 3% safety examples (a few hundred demonstrations) in the training set when fine-tuning a model like LLaMA can substantially improve their safety. Our safety-tuning does not make models significantly less capable or helpful as measured by standard benchmarks. However, we do find a behavior of exaggerated safety, where too much safety-tuning makes models refuse to respond to reasonable prompts that superficially resemble unsafe ones. Our study sheds light on trade-offs in training LLMs to follow
    
[^4]: 自主语言代理的开源框架：Agents

    Agents: An Open-source Framework for Autonomous Language Agents. (arXiv:2309.07870v1 [cs.CL])

    [http://arxiv.org/abs/2309.07870](http://arxiv.org/abs/2309.07870)

    Agents是一个开源框架，支持构建自主语言代理的各种功能，并提供用户友好的接口和对研究人员的扩展性。

    

    最近大型语言模型（LLMs）的高级进展使研究人员和开发人员能够构建自主语言代理，这些代理能够通过自然语言接口自动解决各种任务并与环境、人类和其他代理交互。我们将语言代理视为人工通用智能的有前途的方向，并发布Agents，一个开源库，旨在向更广泛的非专业人士开放这些进展。Agents经过精心设计，支持重要功能，包括规划、记忆、工具使用、多代理通信和细粒度的符号控制。Agents用户友好，使非专业人士能够在不需要编写太多代码的情况下构建、定制、测试、调优和部署最先进的自主语言代理。该库也对研究人员友好，其模块化设计使其易于扩展。

    Recent advances on large language models (LLMs) enable researchers and developers to build autonomous language agents that can automatically solve various tasks and interact with environments, humans, and other agents using natural language interfaces. We consider language agents as a promising direction towards artificial general intelligence and release Agents, an open-source library with the goal of opening up these advances to a wider non-specialist audience. Agents is carefully engineered to support important features including planning, memory, tool usage, multi-agent communication, and fine-grained symbolic control. Agents is user-friendly as it enables non-specialists to build, customize, test, tune, and deploy state-of-the-art autonomous language agents without much coding. The library is also research-friendly as its modularized design makes it easily extensible for researchers. Agents is available at https://github.com/aiwaves-cn/agents.
    
[^5]: 基于大型语言模型的代理的崛起和潜力：一项调查

    The Rise and Potential of Large Language Model Based Agents: A Survey. (arXiv:2309.07864v1 [cs.AI])

    [http://arxiv.org/abs/2309.07864](http://arxiv.org/abs/2309.07864)

    基于大型语言模型的代理的崛起和潜力：一项调查。大型语言模型被认为是构建通用人工智能代理的潜在催化剂，许多研究已经取得重要进展。

    

    长期以来，人类一直追求人工智能（AI）达到或超越人类水平的目标，而被认为是实现这一目标的有望方式的AI代理。AI代理是能感知环境、做出决策和采取行动的人工实体。自20世纪中叶以来，人们为开发智能AI代理进行了许多努力。然而，这些努力主要集中在算法或训练策略的进步上，以增强特定能力或在特定任务上的性能。实际上，社区所缺乏的是一个足够通用和强大的模型，作为设计能适应各种场景的AI代理的起点。由于展示出的多功能和显著能力，大型语言模型（LLMs）被视为人工通用智能（AGI）的潜在催化剂，为构建通用AI代理提供了希望。许多研究工作利用LLMs作为构建AI代理的基础，并且已经取得重要的进展。

    For a long time, humanity has pursued artificial intelligence (AI) equivalent to or surpassing the human level, with AI agents considered a promising vehicle for this pursuit. AI agents are artificial entities that sense their environment, make decisions, and take actions. Many efforts have been made to develop intelligent AI agents since the mid-20th century. However, these efforts have mainly focused on advancement in algorithms or training strategies to enhance specific capabilities or performance on particular tasks. Actually, what the community lacks is a sufficiently general and powerful model to serve as a starting point for designing AI agents that can adapt to diverse scenarios. Due to the versatile and remarkable capabilities they demonstrate, large language models (LLMs) are regarded as potential sparks for Artificial General Intelligence (AGI), offering hope for building general AI agents. Many research efforts have leveraged LLMs as the foundation to build AI agents and ha
    
[^6]: CiwaGAN: 声韵学信息交流

    CiwaGAN: Articulatory information exchange. (arXiv:2309.07861v1 [cs.SD])

    [http://arxiv.org/abs/2309.07861](http://arxiv.org/abs/2309.07861)

    本文介绍了CiwaGAN模型，该模型结合了无监督声韵学建模和无监督听觉模态信息交流，是对人类口语习得最现实的近似。

    

    人类通过控制发音器官将信息编码成声音，并通过听觉装置解码声音的信息。本文介绍了CiwaGAN，这是一个结合了无监督声韵学建模和无监督听觉模态信息交流的人类口语习得模型。尽管之前的研究分别包括了无监督声韵学建模和信息交流，但我们的模型是第一个将这两个组成部分结合在一起的。本文还提出了一个改进的声韵学模型，具有更可解释的内部表示。提出的CiwaGAN模型是使用深度学习对人类口语习得进行最现实的近似。因此，它对于认知上可行的人类言语行为模拟是有用的。

    Humans encode information into sounds by controlling articulators and decode information from sounds using the auditory apparatus. This paper introduces CiwaGAN, a model of human spoken language acquisition that combines unsupervised articulatory modeling with an unsupervised model of information exchange through the auditory modality. While prior research includes unsupervised articulatory modeling and information exchange separately, our model is the first to combine the two components. The paper also proposes an improved articulatory model with more interpretable internal representations. The proposed CiwaGAN model is the most realistic approximation of human spoken language acquisition using deep learning. As such, it is useful for cognitively plausible simulations of the human speech act.
    
[^7]: ExpertQA: 专家策划的问题和带有属性的答案

    ExpertQA: Expert-Curated Questions and Attributed Answers. (arXiv:2309.07852v1 [cs.CL])

    [http://arxiv.org/abs/2309.07852](http://arxiv.org/abs/2309.07852)

    本论文介绍了ExpertQA，它是一个专家策划的问题和带有属性的答案系统。该系统通过分析语言模型在领域特定情景中提供的事实准确性和归因等方面来确保提供准确的信息。研究还收集了领域专家的问题并要求他们评估生成的答案。这项工作的目的是确保语言模型在高风险领域中不会传播错误信息，从而避免不良的社会后果。

    

    随着语言模型被越来越复杂和多样化的用户所采用，确保它们提供基于可验证来源的事实准确信息的重要性在各个领域的研究和职业中都是至关重要的。这特别适用于医学和法律等高风险领域，因为传播错误信息的风险较高，可能导致不良的社会后果。先前的研究关注于事实性和归因方面，并未专注于分析语言模型在特定领域情景中的这些特征。在这项工作中，我们通过将领域专家纳入其中，提出了一个评估研究，分析来自几个系统的响应中提供的事实准确性和归因的各个方面。具体而言，我们先从32个学科领域的484名参与者中收集由专家策划的问题，然后要求这些专家评估对他们自己问题的产生的响应。我们还要求专家修改产生的答案。

    As language models are adapted by a more sophisticated and diverse set of users, the importance of guaranteeing that they provide factually correct information supported by verifiable sources is critical across fields of study & professions. This is especially the case for high-stakes fields, such as medicine and law, where the risk of propagating false information is high and can lead to undesirable societal consequences. Previous work studying factuality and attribution has not focused on analyzing these characteristics of language model outputs in domain-specific scenarios. In this work, we present an evaluation study analyzing various axes of factuality and attribution provided in responses from a few systems, by bringing domain experts in the loop. Specifically, we first collect expert-curated questions from 484 participants across 32 fields of study, and then ask the same experts to evaluate generated responses to their own questions. We also ask experts to revise answers produce
    
[^8]: CATfOOD：反事实增强训练以提高领域外性能和校准能力

    CATfOOD: Counterfactual Augmented Training for Improving Out-of-Domain Performance and Calibration. (arXiv:2309.07822v1 [cs.CL])

    [http://arxiv.org/abs/2309.07822](http://arxiv.org/abs/2309.07822)

    本研究通过在小型语言模型训练数据中增加自动生成的反事实实例，提高了摘要问答模型在领域外的性能和模型校准能力，并发现性能改进与反事实实例的多样性相关。

    

    在最近的几年中，大型语言模型（LLM）在规模方面展示了显著的能力，特别是在给定提示的条件下生成文本。在我们的研究中，我们探讨了使用LLM来增强小型语言模型（SLM）的训练数据的方法，通过自动生成的反事实（CF）实例（即最小程度的改变输入），以提高SLM在摘要问答（QA）设置下的领域外（OOD）性能。我们证明，在各种LLM生成器中，这种数据增强始终能够提高OOD性能，并改进了基于置信度和基于理性增强的校准模型的模型校准能力。此外，这些性能提升与CF实例在外观形式和语义内容方面的多样性呈正相关。最后，我们证明了校准更容易的CF增强模型在分配重要性时的熵也较低，这表明理性增强的校准器更偏好简洁的解释。

    In recent years, large language models (LLMs) have shown remarkable capabilities at scale, particularly at generating text conditioned on a prompt. In our work, we investigate the use of LLMs to augment training data of small language models~(SLMs) with automatically generated counterfactual~(CF) instances -- i.e. minimally altered inputs -- in order to improve out-of-domain~(OOD) performance of SLMs in the extractive question answering~(QA) setup. We show that, across various LLM generators, such data augmentation consistently enhances OOD performance and improves model calibration for both confidence-based and rationale-augmented calibrator models. Furthermore, these performance improvements correlate with higher diversity of CF instances in terms of their surface form and semantic content. Finally, we show that CF augmented models which are easier to calibrate also exhibit much lower entropy when assigning importance, indicating that rationale-augmented calibrators prefer concise ex
    
[^9]: 癌症临床试验资格标准的文本分类

    Text Classification of Cancer Clinical Trial Eligibility Criteria. (arXiv:2309.07812v1 [cs.CL])

    [http://arxiv.org/abs/2309.07812](http://arxiv.org/abs/2309.07812)

    本文研究了癌症临床试验中常见的排除标准，通过应用文本分类方法和预训练的BERT模型，证明了自动分类排除标准的可行性，并展示了专门为临床试验设计的预训练语言模型的价值。

    

    由于试验资格标准以自然语言形式陈述，因此自动确定患者是否符合试验资格是一项复杂的任务。解决该问题的一个潜在方法是使用文本分类方法对常见类型的资格标准进行处理。本研究关注癌症试验中的七个常见排除标准：先前恶性肿瘤、人类免疫缺陷病毒、乙肝病毒、丙肝病毒、精神疾病、药物/物质滥用和自身免疫疾病。我们的数据集包含764个带有这些排除标准注释的三期癌症试验。我们尝试了常见的transformer模型以及一个新的预训练的临床试验BERT模型。我们的结果表明，自动分类常见的排除标准是可行的。此外，我们展示了一种专门针对临床试验的预训练语言模型的价值，该模型在所有标准中表现出最高的平均性能。

    Automatic identification of clinical trials for which a patient is eligible is complicated by the fact that trial eligibility is stated in natural language. A potential solution to this problem is to employ text classification methods for common types of eligibility criteria. In this study, we focus on seven common exclusion criteria in cancer trials: prior malignancy, human immunodeficiency virus, hepatitis B, hepatitis C, psychiatric illness, drug/substance abuse, and autoimmune illness. Our dataset consists of 764 phase III cancer trials with these exclusions annotated at the trial level. We experiment with common transformer models as well as a new pre-trained clinical trial BERT model. Our results demonstrate the feasibility of automatically classifying common exclusion criteria. Additionally, we demonstrate the value of a pre-trained language model specifically for clinical trials, which yields the highest average performance across all criteria.
    
[^10]: 弹出测验！预训练代码模型是否具有正确API名称的知识？

    Pop Quiz! Do Pre-trained Code Models Possess Knowledge of Correct API Names?. (arXiv:2309.07804v1 [cs.SE])

    [http://arxiv.org/abs/2309.07804](http://arxiv.org/abs/2309.07804)

    我们研究了预训练代码模型在理解API名称方面的困难，并提出使用知识探测的方法来解释模型。我们发现当前的代码模型在理解API的完全限定名方面遇到了困难。

    

    最近在预训练代码模型（如CodeBERT和Codex）方面取得了重大突破，展现了其在各种下游任务中的卓越性能。这些代码模型对于实现期望的程序功能的API的正确性和明确性非常关键，要求它们在结构和语义上学习各种API的完全限定名。最近的研究表明，即使是最先进的预训练代码模型在代码生成过程中也很难正确建议API。然而，关于API使用性能差的原因几乎没有进行研究。为了解决这个挑战，我们提出使用知识探测作为解释代码模型的手段，通过填空式测试来衡量模型中存储的知识。我们全面地研究了代码模型理解API完全限定名的能力，从API调用和API导入两个不同的角度来进行。具体而言，我们发现当前的代码模型在理解API方面存在困难。

    Recent breakthroughs in pre-trained code models, such as CodeBERT and Codex, have shown their superior performance in various downstream tasks. The correctness and unambiguity of API usage among these code models are crucial for achieving desirable program functionalities, requiring them to learn various API fully qualified names structurally and semantically. Recent studies reveal that even state-of-the-art pre-trained code models struggle with suggesting the correct APIs during code generation. However, the reasons for such poor API usage performance are barely investigated. To address this challenge, we propose using knowledge probing as a means of interpreting code models, which uses cloze-style tests to measure the knowledge stored in models. Our comprehensive study examines a code model's capability of understanding API fully qualified names from two different perspectives: API call and API import. Specifically, we reveal that current code models struggle with understanding API n
    
[^11]: 讲故事的动态原则

    The Dynamical Principles of Storytelling. (arXiv:2309.07797v1 [cs.CL])

    [http://arxiv.org/abs/2309.07797](http://arxiv.org/abs/2309.07797)

    这项研究揭示了讲故事的开头部分通常会遵循动作原则，并且这种顺序可能与西方传统讲故事的有关。

    

    在考虑了1800个短篇小说的开头部分之后，我们发现平均故事的前十几个段落遵循了arXiv:2309.06600中定义的动作原则。当段落的顺序被打乱时，平均值不再具备这一特性。研究结果表明，在开始一个故事时，我们在语义空间中有一个优先方向，可能与亚里士多德在《诗学》中所暗示的西方传统讲故事有关。

    When considering the opening part of 1800 short stories, we find that the first dozen paragraphs of the average narrative follow an action principle as defined in arXiv:2309.06600. When the order of the paragraphs is shuffled, the average no longer exhibits this property. The findings show that there is a preferential direction we take in semantic space when starting a story, possibly related to a common Western storytelling tradition as implied by Aristotle in Poetics.
    
[^12]: 通过利用图像-文本辅助任务提高社交媒体帖子的多模态分类

    Improving Multimodal Classification of Social Media Posts by Leveraging Image-Text Auxiliary tasks. (arXiv:2309.07794v1 [cs.CL])

    [http://arxiv.org/abs/2309.07794](http://arxiv.org/abs/2309.07794)

    本研究通过引入图像-文本辅助任务，有效地提高了社交媒体帖子的多模态分类，通过两个辅助损失函数对图像-文本表示进行调整，捕捉底层依赖关系和语义对应关系，实现了一致的改进。

    

    有效地利用社交媒体帖子中的多模态信息对情感分析、讽刺检测和仇恨言论分类等多个下游任务至关重要。然而，由于匹配的图像-文本对中存在隐藏或互补信息的独特跨模态语义，将文本和图像信息结合起来是具有挑战性的。在本研究中，我们旨在通过在微调任何预训练的多模态模型时联合使用两个辅助损失函数来直接建模这一问题。图像-文本对比（ITC）将一篇帖子的图像-文本表示更加靠近，并将其与其他帖子分离开来，捕捉底层依赖关系。图像-文本匹配（ITM）通过惩罚不相关的对来促进理解图像和文本之间的语义对应关系。我们将这些目标与五个多模态模型相结合，证明了在四个热门社交媒体数据集上的一致改进。

    Effectively leveraging multimodal information from social media posts is essential to various downstream tasks such as sentiment analysis, sarcasm detection and hate speech classification. However, combining text and image information is challenging because of the idiosyncratic cross-modal semantics with hidden or complementary information present in matching image-text pairs. In this work, we aim to directly model this by proposing the use of two auxiliary losses jointly with the main task when fine-tuning any pre-trained multimodal model. Image-Text Contrastive (ITC) brings image-text representations of a post closer together and separates them from different posts, capturing underlying dependencies. Image-Text Matching (ITM) facilitates the understanding of semantic correspondence between images and text by penalizing unrelated pairs. We combine these objectives with five multimodal models, demonstrating consistent improvements across four popular social media datasets. Furthermore,
    
[^13]: 移动严肃游戏中口语化人形机器人对可用性的评估

    Usability Evaluation of Spoken Humanoid Embodied Conversational Agents in Mobile Serious Games. (arXiv:2309.07773v1 [cs.HC])

    [http://arxiv.org/abs/2309.07773](http://arxiv.org/abs/2309.07773)

    本文通过实证调查评估了移动严肃游戏应用中口语化人形机器人对可用性的影响，结果表明用户更喜欢与高人类相似度的机器人进行交互。

    

    本文对移动严肃游戏应用中口语化人形机器人（HECA）对可用性的影响进行了实证调查。研究旨在评估多个机器人和人类交互幻觉对交互质量的影响。实验研究了两种机器人呈现方式：高人类相似度的机器人（HECA）和低人类相似度的机器人（文本）。实验的目的是评估高人类相似度机器人是否能够引发人类幻觉并影响可用性。高人类相似度机器人是根据ECA设计模型进行设计的，该模型是一种ECA开发的指导方针。实验结果显示，90位参与者更喜欢与HECA进行交互。两个版本之间的差异在统计学上具有显著性，效应大小较大（d=1.01），许多参与者通过解释选择来证明他们的选择。

    This paper presents an empirical investigation of the extent to which spoken Humanoid Embodied Conversational Agents (HECAs) can foster usability in mobile serious game (MSG) applications. The aim of the research is to assess the impact of multiple agents and illusion of humanness on the quality of the interaction. The experiment investigates two styles of agent presentation: an agent of high human-likeness (HECA) and an agent of low human-likeness (text). The purpose of the experiment is to assess whether and how agents of high humanlikeness can evoke the illusion of humanness and affect usability. Agents of high human-likeness were designed by following the ECA design model that is a proposed guide for ECA development. The results of the experiment with 90 participants show that users prefer to interact with the HECAs. The difference between the two versions is statistically significant with a large effect size (d=1.01), with many of the participants justifying their choice by saying
    
[^14]: Echotune: 利用语音的可变长度特性的模块化特征提取器在ASR任务中的应用

    Echotune: A Modular Extractor Leveraging the Variable-Length Nature of Speech in ASR Tasks. (arXiv:2309.07765v1 [cs.SD])

    [http://arxiv.org/abs/2309.07765](http://arxiv.org/abs/2309.07765)

    Echotune是一个模块化特征提取器，利用语音的可变长度特性，通过引入Echo-MSA模块，实现了从帧到话语的各种颗粒度的语音特征提取，解决了固定长度注意力的局限性。

    

    Transformer架构已被证明在自动语音识别（ASR）任务中非常有效，成为该领域众多研究的基础组件。历史上，许多方法依赖于固定长度的注意力窗口，这对于持续时间和复杂性不同的语音样本来说是有问题的，导致数据过度平滑化和忽视了长期连通性的重要性。为了解决这个限制，我们引入了Echo-MSA，一个具有可变长度注意力机制的灵活模块，可以适应不同复杂性和持续时间的语音样本。该模块提供了从帧和音素到单词和话语的各种颗粒度的语音特征提取的灵活性。提出的设计捕捉到了语音的可变长度特征，并解决了固定长度注意力的局限性。我们的评估利用了一个平行的注意力架构，并结合了一个动态门控机制。

    The Transformer architecture has proven to be highly effective for Automatic Speech Recognition (ASR) tasks, becoming a foundational component for a plethora of research in the domain. Historically, many approaches have leaned on fixed-length attention windows, which becomes problematic for varied speech samples in duration and complexity, leading to data over-smoothing and neglect of essential long-term connectivity. Addressing this limitation, we introduce Echo-MSA, a nimble module equipped with a variable-length attention mechanism that accommodates a range of speech sample complexities and durations. This module offers the flexibility to extract speech features across various granularities, spanning from frames and phonemes to words and discourse. The proposed design captures the variable length feature of speech and addresses the limitations of fixed-length attention. Our evaluation leverages a parallel attention architecture complemented by a dynamic gating mechanism that amalgam
    
[^15]: PROGrasp:实现物体抓取的人机交流

    PROGrasp: Pragmatic Human-Robot Communication for Object Grasping. (arXiv:2309.07759v1 [cs.CL])

    [http://arxiv.org/abs/2309.07759](http://arxiv.org/abs/2309.07759)

    PROGrasp是一个实现物体抓取的人机交流系统，通过使用面向意图的多模态对话和答案解释模块，机器人能够根据用户的意图来识别和抓取目标物体。

    

    交互式物体抓取(IOG)是通过人机自然语言交流识别和抓取目标物体的任务。当前IOG系统假定人类用户最初指定目标对象的类别(例如，瓶子)。受到语用学的启发，人类往往通过依赖上下文来传达意图以实现目标。我们引入了一项新的IOG任务，即实用IOG，并提出相应的数据集，即面向意图的多模态对话(IM-Dial)。在我们提出的任务场景中，首先给出一个面向意图的话语(例如，“我渴了”)。然后，机器人应通过与人类用户互动来识别目标对象。基于任务设置，我们提出了一个新的机器人系统，可以解释用户的意图并捡起目标对象，即实用物体抓取(PROGrasp)。PROGrasp通过结合视觉定位、问题提问、物体抓取以及最重要的，答案解释模块执行实用IOG。

    Interactive Object Grasping (IOG) is the task of identifying and grasping the desired object via human-robot natural language interaction. Current IOG systems assume that a human user initially specifies the target object's category (e.g., bottle). Inspired by pragmatics, where humans often convey their intentions by relying on context to achieve goals, we introduce a new IOG task, Pragmatic-IOG, and the corresponding dataset, Intention-oriented Multi-modal Dialogue (IM-Dial). In our proposed task scenario, an intention-oriented utterance (e.g., "I am thirsty") is initially given to the robot. The robot should then identify the target object by interacting with a human user. Based on the task setup, we propose a new robotic system that can interpret the user's intention and pick up the target object, Pragmatic Object Grasping (PROGrasp). PROGrasp performs Pragmatic-IOG by incorporating modules for visual grounding, question asking, object grasping, and most importantly, answer interpre
    
[^16]: 利用集成的LLM方法进行生成式AI文本分类

    Generative AI Text Classification using Ensemble LLM Approaches. (arXiv:2309.07755v1 [cs.CL])

    [http://arxiv.org/abs/2309.07755](http://arxiv.org/abs/2309.07755)

    本文提出了一个利用集成的LLM方法进行生成式AI文本分类的方法，通过使用多个预训练LLM生成概率作为特征来准确检测AI生成的语言，并确定生成文本的特定语言模型的归属。

    

    大型语言模型（LLM）在人工智能和自然语言处理任务中表现出色，如内容创作、报告生成等。然而，对这些模型的不受限制的恶意应用可能导致不良后果，如虚假新闻生成、抄袭等。因此，在负责任地使用LLM时准确检测AI生成的语言非常重要。在本研究中，我们探讨了以下问题：1）某个文本是由AI生成还是人类编写的；2）特定语言模型在生成文本中的归属。我们考虑了英文和西班牙文的文本。本研究中使用的数据集是Automated Text Identification (AuTexTification)共享任务的一部分。针对上述每个研究目标，我们提出了一个基于集成神经模型的方法，该方法从不同的预训练LLM生成概率，这些概率被用作传统机器学习方法的特征。

    Large Language Models (LLMs) have shown impressive performance across a variety of Artificial Intelligence (AI) and natural language processing tasks, such as content creation, report generation, etc. However, unregulated malign application of these models can create undesirable consequences such as generation of fake news, plagiarism, etc. As a result, accurate detection of AI-generated language can be crucial in responsible usage of LLMs. In this work, we explore 1) whether a certain body of text is AI generated or written by human, and 2) attribution of a specific language model in generating a body of text. Texts in both English and Spanish are considered. The datasets used in this study are provided as part of the Automated Text Identification (AuTexTification) shared task. For each of the research objectives stated above, we propose an ensemble neural model that generates probabilities from different pre-trained LLMs which are used as features to a Traditional Machine Learning (T
    
[^17]: 通过单词级音频片段和语音特征解释语音分类模型

    Explaining Speech Classification Models via Word-Level Audio Segments and Paralinguistic Features. (arXiv:2309.07733v1 [cs.CL])

    [http://arxiv.org/abs/2309.07733](http://arxiv.org/abs/2309.07733)

    该论文提出了一种解释语音分类模型的新方法，通过在单词级别上解释音频段落和语音特征。该方法通过对输入进行扰动，生成易于理解的解释，并回答了如果修改了音频信号会对模型预测产生怎样影响的问题。通过验证，发现这些解释与模型内部工作相符，且对人类而言是可信的。

    

    最近可解释的人工智能（XAI）的进展为我们对视觉、语言和表格数据模型的运行方式提供了新的见解。然而，很少有方法用于理解语音模型。现有工作专注于一些口语理解任务，并且对大多数用户来说，解释难以解释。我们提出了一种解释语音分类模型的新方法。我们通过在两个信息级别上对输入进行扰动来生成易于解释的解释。1) 单词级解释显示每个与单词相关的音频片段如何影响结果。2) 语音特征（例如韵律和背景噪音）回答了反事实问题：“如果我们以这种方式编辑音频信号，模型的预测会是什么？”我们通过解释两个最先进的英语和意大利语口语理解模型的两个口语分类任务来验证我们的方法。我们的发现表明这些解释符合模型的内部工作并且对人类而言是可信的。

    Recent advances in eXplainable AI (XAI) have provided new insights into how models for vision, language, and tabular data operate. However, few approaches exist for understanding speech models. Existing work focuses on a few spoken language understanding (SLU) tasks, and explanations are difficult to interpret for most users. We introduce a new approach to explain speech classification models. We generate easy-to-interpret explanations via input perturbation on two information levels. 1) Word-level explanations reveal how each word-related audio segment impacts the outcome. 2) Paralinguistic features (e.g., prosody and background noise) answer the counterfactual: ``What would the model prediction be if we edited the audio signal in this way?'' We validate our approach by explaining two state-of-the-art SLU models on two speech classification tasks in English and Italian. Our findings demonstrate that the explanations are faithful to the model's inner workings and plausible to humans. O
    
[^18]: PerPLM: 通过个性化的中间学习和提示对预训练语言模型进行个性化微调

    PerPLM: Personalized Fine-tuning of Pretrained Language Models via Writer-specific Intermediate Learning and Prompts. (arXiv:2309.07727v1 [cs.CL])

    [http://arxiv.org/abs/2309.07727](http://arxiv.org/abs/2309.07727)

    PerPLM通过个性化中间学习和提示实现个性化的预训练语言模型微调，并在只有目标作者纯文本的情况下将其扩展到多用户，提高了文本理解任务的准确性。

    

    单词和短语的含义不仅取决于它们所在的上下文，还取决于使用者。预训练语言模型（PLMs）是捕捉上下文的强大工具，但通常是为了在不同的使用者之间普遍使用而进行预训练和微调的。本研究旨在通过个性化微调PLMs来提高文本理解任务的准确性。我们关注一个只有目标作者的纯文本可用于个性化的一般设置。为了避免对不同用户进行微调和存储多个PLM的成本，我们详细探讨了使用特定作者提示来个性化统一PLM的可能性。由于这些提示的设计和评估是一个尚未发展完善的领域，我们介绍并比较了在我们的环境中可能的不同类型的提示。为了最大限度地发挥基于提示的个性化微调的潜力，我们提出了一种基于掩码的个性化中间学习。

    The meanings of words and phrases depend not only on where they are used (contexts) but also on who use them (writers). Pretrained language models (PLMs) are powerful tools for capturing context, but they are typically pretrained and fine-tuned for universal use across different writers. This study aims to improve the accuracy of text understanding tasks by personalizing the fine-tuning of PLMs for specific writers. We focus on a general setting where only the plain text from target writers are available for personalization. To avoid the cost of fine-tuning and storing multiple copies of PLMs for different users, we exhaustively explore using writer-specific prompts to personalize a unified PLM. Since the design and evaluation of these prompts is an underdeveloped area, we introduce and compare different types of prompts that are possible in our setting. To maximize the potential of prompt-based personalized fine-tuning, we propose a personalized intermediate learning based on masked l
    
[^19]: L1感知多语言发音错误检测框架

    L1-aware Multilingual Mispronunciation Detection Framework. (arXiv:2309.07719v1 [cs.CL])

    [http://arxiv.org/abs/2309.07719](http://arxiv.org/abs/2309.07719)

    本文介绍了一种L1感知的多语言发音错误检测框架，该框架通过注意力机制对齐输入音频和参考音素序列，并将预训练的辅助模型提取的L1-L2语音嵌入与主要网络进行融合。该框架在英文、阿拉伯语和普通话上的统一多语言音素识别任务中取得了良好的效果。

    

    说话者的母语(L1)和非母语(L2)之间的语音差异是发音错误的主要因素。本文介绍了一种新颖的多语言MDD架构——L1-MultiMDD框架，该框架通过L1感知的语音表示进行增强。首先，通过注意力机制将输入音频与参考音素序列进行对齐。然后，从在多任务设置中预先训练的辅助模型中提取L1-L2语音嵌入，并将其与主要网络进行融合。最后，通过连接时序分类(CTC)损失优化L1-MultiMDD框架，用于目标语言英文、阿拉伯语和普通话的统一多语言音素识别任务。实验证明了所提出的L1-MultiMDD框架在已见数据集L2-ARTIC、LATIC和AraVoiceL2上的有效性。

    The phonological discrepancies between a speaker's native (L1) and the non-native language (L2) serves as a major factor for mispronunciation. This paper introduces a novel multilingual MDD architecture, L1-MultiMDD, enriched with L1-aware speech representation. An end-to-end speech encoder is trained on the input signal and its corresponding reference phoneme sequence. First, an attention mechanism is deployed to align the input audio with the reference phoneme sequence. Afterwards, the L1-L2-speech embedding are extracted from an auxiliary model, pretrained in a multi-task setup identifying L1 and L2 language, and are infused with the primary network. Finally, the L1-MultiMDD is then optimized for a unified multilingual phoneme recognition task using connectionist temporal classification (CTC) loss for the target languages: English, Arabic, and Mandarin. Our experiments demonstrate the effectiveness of the proposed L1-MultiMDD framework on both seen -- L2-ARTIC, LATIC, and AraVoiceL2
    
[^20]: CoLLD: 对多语种预训练语音编码器的对比层与层蒸馏进行压缩

    CoLLD: Contrastive Layer-to-layer Distillation for Compressing Multilingual Pre-trained Speech Encoders. (arXiv:2309.07707v1 [cs.CL])

    [http://arxiv.org/abs/2309.07707](http://arxiv.org/abs/2309.07707)

    CoLLD是一种用于压缩预训练语音编码器的对比层与层蒸馏方法，通过学生模型复制大教师模型的行为来提高性能，并在多语种任务中取得了优异表现。

    

    大规模自监督预训练语音编码器在语音识别和翻译任务中表现优于传统方法。由于开发这些大模型的成本较高，为新任务构建新编码器并将其部署到设备应用中是不可行的。先前的研究提出了模型压缩方法来解决这个问题，但这些方法仅针对较小模型和不太实际的任务。因此，我们提出了对比层与层蒸馏（CoLLD），一种新颖的知识蒸馏方法，通过利用掩蔽预测和对比学习，训练学生模型复制大教师模型的行为来压缩预训练语音编码器。CoLLD在多语种语音到文本翻译和识别基准上胜过先前的方法，弥合了小模型和大模型之间的差距。

    Large-scale self-supervised pre-trained speech encoders outperform conventional approaches in speech recognition and translation tasks. Due to the high cost of developing these large models, building new encoders for new tasks and deploying them to on-device applications are infeasible. Prior studies propose model compression methods to address this issue, but those works focus on smaller models and less realistic tasks. Thus, we propose Contrastive Layer-to-layer Distillation (CoLLD), a novel knowledge distillation method to compress pre-trained speech encoders by leveraging masked prediction and contrastive learning to train student models to copy the behavior of a large teacher model. CoLLD outperforms prior methods and closes the gap between small and large models on multilingual speech-to-text translation and recognition benchmarks.
    
[^21]: 不确定思维树：大型语言模型的推理方法

    Tree of Uncertain Thoughts Reasoning for Large Language Models. (arXiv:2309.07694v1 [cs.CL])

    [http://arxiv.org/abs/2309.07694](http://arxiv.org/abs/2309.07694)

    本研究提出了一种针对大型语言模型的推理框架——不确定思维树（TouT），它通过利用蒙特卡洛丢弃来量化中间步骤上的本地不确定性，提高了模型生成响应的精确性。

    

    尽管最近引入的不确定思维树（Tree of Thoughts, ToT）在允许大型语言模型（LLMs）通过预见和回溯进行全局决策方面取得了进展，但它忽视了中间决策点或“思维”中的固有局部不确定性。这些固有的局部不确定性，由于LLMs潜在的多样性响应能力，成为推理过程中的重要问题。为了解决这一关键差距，我们引入了不确定思维树（Tree of Uncertain Thoughts, TouT）-一种针对LLMs设计的推理框架。我们的TouT有效地利用了蒙特卡洛丢弃(Monte Carlo Dropout)来量化与LLMs在这些中间步骤上的不同本地响应相关的不确定性得分。通过将这种本地不确定性量化与全局搜索算法结合起来，TouT提高了模型生成响应的精确性。我们通过在两个苛刻的规划任务上进行严格实验证明了我们的方法：24点游戏和迷你填字游戏。

    While the recently introduced Tree of Thoughts (ToT) has heralded advancements in allowing Large Language Models (LLMs) to reason through foresight and backtracking for global decision-making, it has overlooked the inherent local uncertainties in intermediate decision points or "thoughts". These local uncertainties, intrinsic to LLMs given their potential for diverse responses, remain a significant concern in the reasoning process. Addressing this pivotal gap, we introduce the Tree of Uncertain Thoughts (TouT) - a reasoning framework tailored for LLMs. Our TouT effectively leverages Monte Carlo Dropout to quantify uncertainty scores associated with LLMs' diverse local responses at these intermediate steps. By marrying this local uncertainty quantification with global search algorithms, TouT enhances the model's precision in response generation. We substantiate our approach with rigorous experiments on two demanding planning tasks: Game of 24 and Mini Crosswords. The empirical evidence 
    
[^22]: 检测ChatGPT：对检测ChatGPT生成文本状态的调查

    Detecting ChatGPT: A Survey of the State of Detecting ChatGPT-Generated Text. (arXiv:2309.07689v1 [cs.CL])

    [http://arxiv.org/abs/2309.07689](http://arxiv.org/abs/2309.07689)

    这篇调查论文概述了当前用于区分ChatGPT生成文本和人工文本的方法和数据集，并总结了研究发现。

    

    随着ChatGPT（OpenAI, 2022）等生成语言模型能力和广泛使用的不断进步，它们生成流利的类人文本带来了各种好处，但区分人类生成文本和大型语言模型（LLM）生成文本的任务也因此成为一个关键问题。这些模型可能通过生成看似由人类生成的人工文本而进行欺骗。在法律、教育和科学等领域，确保文本的真实性尤为重要，因此这个问题尤为显著。本调查概述了当前用于区分人工文本和ChatGPT生成文本的方法，我们介绍了构建用于检测ChatGPT生成文本的不同数据集，使用的各种方法，进行了哪些关于人类与ChatGPT生成文本特征的定性分析，并总结了我们的研究结果。

    While recent advancements in the capabilities and widespread accessibility of generative language models, such as ChatGPT (OpenAI, 2022), have brought about various benefits by generating fluent human-like text, the task of distinguishing between human- and large language model (LLM) generated text has emerged as a crucial problem. These models can potentially deceive by generating artificial text that appears to be human-generated. This issue is particularly significant in domains such as law, education, and science, where ensuring the integrity of text is of the utmost importance. This survey provides an overview of the current approaches employed to differentiate between texts generated by humans and ChatGPT. We present an account of the different datasets constructed for detecting ChatGPT-generated text, the various methods utilized, what qualitative analyses into the characteristics of human versus ChatGPT-generated text have been performed, and finally, summarize our findings int
    
[^23]: 评估大规模语言模型的性质：对人类中心主义的警告

    Assessing the nature of large language models: A caution against anthropocentrism. (arXiv:2309.07683v1 [cs.AI])

    [http://arxiv.org/abs/2309.07683](http://arxiv.org/abs/2309.07683)

    通过评估GPT3.5，我们发现它具有有趣的个性问卷回答能力，但不太可能发展出意识，并显示出较大的认知和个性变异。

    

    生成式人工智能模型通过OpenAI的聊天机器人ChatGPT的发布引起了公众的关注和猜测。目前存在两种意见阵营：一方对这些模型为人类任务带来的基本变革的可能性感到兴奋，另一方对这些模型的强大能力感到高度关切。为了应对这些关切，我们使用了标准、规范化和经过验证的认知和个性测量工具来评估GPT3.5。在这个初步项目中，我们开发了一套测试，可以估计这些模型的能力边界，它们在短时间内的稳定性以及与人类的比较。我们的结果表明，GPT 3.5很可能没有产生意识，尽管它对个性问卷的回答能力令人感兴趣。它在重复观察过程中显示出认知和个性测量方面的大量变异，这与具有人类般个性的模型是不符合预期的。

    Generative AI models garnered a large amount of public attention and speculation with the release of OpenAIs chatbot, ChatGPT. At least two opinion camps exist: one excited about possibilities these models offer for fundamental changes to human tasks, and another highly concerned about power these models seem to have. To address these concerns, we assessed GPT3.5 using standard, normed, and validated cognitive and personality measures. For this seedling project, we developed a battery of tests that allowed us to estimate the boundaries of some of these models capabilities, how stable those capabilities are over a short period of time, and how they compare to humans.  Our results indicate that GPT 3.5 is unlikely to have developed sentience, although its ability to respond to personality inventories is interesting. It did display large variability in both cognitive and personality measures over repeated observations, which is not expected if it had a human-like personality. Variability 
    
[^24]: 一次对话胜过千万的推荐：综述综合对话推荐系统

    A Conversation is Worth A Thousand Recommendations: A Survey of Holistic Conversational Recommender Systems. (arXiv:2309.07682v1 [cs.CL])

    [http://arxiv.org/abs/2309.07682](http://arxiv.org/abs/2309.07682)

    该论文综述了综合对话式推荐系统的方法，传统方法无法应用于真实世界场景，该论文提出了一种新的方法，即使用真实对话数据进行训练。

    

    对话式推荐系统通过交互过程生成推荐。然而，并非所有对话式推荐系统方法都使用人类对话作为交互数据源；先前的大部分对话式推荐系统工作通过交换实体级信息来模拟交互。因此，先前的对话式推荐系统工作无法适用于真实世界场景中的对话，其中对话会出现意外转变，或者对话和意图理解并非完美。为了解决这一挑战，研究界已经开始研究综合对话式推荐系统，这些系统使用从真实场景中收集到的对话数据进行训练。尽管这些综合方法已经出现，但其尚未充分探索。我们通过结构化方式总结文献，对综合对话式推荐系统方法进行全面调查。调查将综合对话式推荐系统方法分为三个组成部分：1）骨干语言模型，可选使用2）外部知识和/或3）外部指导。

    Conversational recommender systems (CRS) generate recommendations through an interactive process. However, not all CRS approaches use human conversations as their source of interaction data; the majority of prior CRS work simulates interactions by exchanging entity-level information. As a result, claims of prior CRS work do not generalise to real-world settings where conversations take unexpected turns, or where conversational and intent understanding is not perfect. To tackle this challenge, the research community has started to examine holistic CRS, which are trained using conversational data collected from real-world scenarios. Despite their emergence, such holistic approaches are under-explored.  We present a comprehensive survey of holistic CRS methods by summarizing the literature in a structured manner. Our survey recognises holistic CRS approaches as having three components: 1) a backbone language model, the optional use of 2) external knowledge, and/or 3) external guidance. We
    
[^25]: 对利用高效的多序列对齐评估和可视化基于文本的说话人分离进行了研究（扩展版）

    Aligning Speakers: Evaluating and Visualizing Text-based Diarization Using Efficient Multiple Sequence Alignment (Extended Version). (arXiv:2309.07677v1 [cs.CL])

    [http://arxiv.org/abs/2309.07677](http://arxiv.org/abs/2309.07677)

    本文提出了一种新的基于文本的说话人分离评估方法，并引入了多序列对齐算法。提出的度量标准克服了传统方法在文本中缺乏上下文信息的问题，并能够进行更全面的分析。该研究为对话系统的发展提供了可视化和评估工具。

    

    本文提出了一种新颖的基于文本的说话人分离（SD）评估方法，解决了传统度量方法在文本中不考虑任何上下文信息的局限性。提出了两个新的度量标准，即基于文本的说话人分离错误率和分离F1，通过对齐参考文本和假设转录中的标记来进行话语和单词级别的评估。与现有方法相比，我们的度量标准包含更多类型的错误，可以在SD中进行更全面的分析。为了对齐标记，引入了支持参考序列的多序列对齐算法，同时使用动态规划处理对假设的高维对齐。我们的工作分为两个工具，align4d提供了我们的对齐算法的API，TranscribeView用于可视化和评估SD错误，可以极大地促进高质量数据的生成，推动对话系统的进展。

    This paper presents a novel evaluation approach to text-based speaker diarization (SD), tackling the limitations of traditional metrics that do not account for any contextual information in text. Two new metrics are proposed, Text-based Diarization Error Rate and Diarization F1, which perform utteranceand word-level evaluations by aligning tokens in reference and hypothesis transcripts. Our metrics encompass more types of errors compared to existing ones, allowing us to make a more comprehensive analysis in SD. To align tokens, a multiple sequence alignment algorithm is introduced that supports multiple sequences in the reference while handling high-dimensional alignment to the hypothesis using dynamic programming. Our work is packaged into two tools, align4d providing an API for our alignment algorithm and TranscribeView for visualizing and evaluating SD errors, which can greatly aid in the creation of high-quality data, fostering the advancement of dialogue systems.
    
[^26]: 从中文自然语言问题中自动生成数据可视化

    Automatic Data Visualization Generation from Chinese Natural Language Questions. (arXiv:2309.07650v1 [cs.CL])

    [http://arxiv.org/abs/2309.07650](http://arxiv.org/abs/2309.07650)

    本论文提出了一个中文文本到可视化数据集，并通过使用多语言BERT作为编码器以及融入n-gram信息来解决中文文本到可视化的问题。

    

    数据可视化已经成为从大规模数据集中获取洞见的有效工具。由于操作数据可视化编程语言的困难性，从自然语言中自动生成数据可视化（文本到可视化）变得越来越受欢迎。尽管在英文文本到可视化上有大量的研究工作，但是关于从中文问题生成数据可视化的研究还没有进行。鉴于此，本论文提出了一个中文文本到可视化数据集，并展示了我们对这个问题的首次尝试。我们的模型将多语言BERT作为编码器，增强了跨语言能力，并将n-gram信息融入到我们的词表示学习中。实验证明，我们的数据集具有挑战性，值得进一步研究。

    Data visualization has emerged as an effective tool for getting insights from massive datasets. Due to the hardness of manipulating the programming languages of data visualization, automatic data visualization generation from natural languages (Text-to-Vis) is becoming increasingly popular. Despite the plethora of research effort on the English Text-to-Vis, studies have yet to be conducted on data visualization generation from questions in Chinese. Motivated by this, we propose a Chinese Text-to-Vis dataset in the paper and demonstrate our first attempt to tackle this problem. Our model integrates multilingual BERT as the encoder, boosts the cross-lingual ability, and infuses the $n$-gram information into our word representation learning. Our experimental results show that our dataset is challenging and deserves further research.
    
[^27]: 在分解神经传输器中引入基于类别的语言模型来进行命名实体识别

    Incorporating Class-based Language Model for Named Entity Recognition in Factorized Neural Transducer. (arXiv:2309.07648v1 [eess.AS])

    [http://arxiv.org/abs/2309.07648](http://arxiv.org/abs/2309.07648)

    这项研究在分解神经传输器中加入了基于类别的语言模型，提升了命名实体识别的能力。

    

    尽管最近几年端到端（E2E）模型在语音识别方面取得了巨大的进展，但命名实体识别仍然具有挑战性但又对语义理解至关重要。为了增强E2E模型中识别命名实体的能力，先前的研究主要集中在各种基于规则或基于注意力的上下文偏置算法上。然而，它们的性能可能对偏置权重敏感，或者由于对命名实体列表的过度关注而降低，并且存在误触发的风险。受传统混合系统中基于类别的语言模型（LM）在命名实体识别中的成功启发，以及在分解神经传输器（FNT）中声学和语言信息的有效解耦，我们提出了一种新颖的E2E模型来将基于类别的LMs纳入FNT中，称为C-FNT。在C-FNT中，命名实体的语言模型得分可以与其类别关联，而不是与其表面形式关联。

    In spite of the excellent strides made by end-to-end (E2E) models in speech recognition in recent years, named entity recognition is still challenging but critical for semantic understanding. In order to enhance the ability to recognize named entities in E2E models, previous studies mainly focus on various rule-based or attention-based contextual biasing algorithms. However, their performance might be sensitive to the biasing weight or degraded by excessive attention to the named entity list, along with a risk of false triggering. Inspired by the success of the class-based language model (LM) in named entity recognition in conventional hybrid systems and the effective decoupling of acoustic and linguistic information in the factorized neural Transducer (FNT), we propose a novel E2E model to incorporate class-based LMs into FNT, which is referred as C-FNT. In C-FNT, the language model score of named entities can be associated with the name class instead of its surface form. The experime
    
[^28]: 动态模块化推理用于组合结构化解释生成

    Dynamic MOdularized Reasoning for Compositional Structured Explanation Generation. (arXiv:2309.07624v1 [cs.CL])

    [http://arxiv.org/abs/2309.07624](http://arxiv.org/abs/2309.07624)

    本文提出了一种动态模块化推理模型MORSE，用于改善神经模型的组合推理能力，通过采用模块化的自注意力机制，实现了对输入的动态选择和路由，提高了神经模型的组合泛化能力。

    

    尽管神经模型在解决推理任务方面取得了成功，但其组合泛化能力仍不清楚。本文提出了一种新的结构化解释生成任务设置，以促进组合推理研究。以往的研究发现，符号方法通过使用预定义的推理规则进行反复推理实现了优秀的组合性。但这些方法依赖于脆弱的符号传递，并且局限于定义明确的任务。因此，我们提出了一种动态模块化推理模型MORSE，以提高神经模型的组合推理能力。MORSE将推理过程分解为多个模块的组合，其中每个模块代表一个功能单元。具体而言，我们采用模块化的自注意力机制来动态选择和路由输入到专门的头部，使其专门针对特定函数。我们在两个基准数据集上进行了实验，测试了推理树的长度和形状的提高。

    Despite the success of neural models in solving reasoning tasks, their compositional generalization capabilities remain unclear. In this work, we propose a new setting of the structured explanation generation task to facilitate compositional reasoning research. Previous works found that symbolic methods achieve superior compositionality by using pre-defined inference rules for iterative reasoning. But these approaches rely on brittle symbolic transfers and are restricted to well-defined tasks. Hence, we propose a dynamic modularized reasoning model, MORSE, to improve the compositional generalization of neural models. MORSE factorizes the inference process into a combination of modules, where each module represents a functional unit. Specifically, we adopt modularized self-attention to dynamically select and route inputs to dedicated heads, which specializes them to specific functions. We conduct experiments for increasing lengths and shapes of reasoning trees on two benchmarks to test 
    
[^29]: 使用大型语言模型进行零-shot音频主题重排序

    Zero-shot Audio Topic Reranking using Large Language Models. (arXiv:2309.07606v1 [cs.CL])

    [http://arxiv.org/abs/2309.07606](http://arxiv.org/abs/2309.07606)

    本论文研究了使用大型语言模型的零-shot重新排序方法，以改善基于主题的视频检索性能，无需任何特定任务的训练数据。

    

    多模态视频搜索项目通过使用视频片段作为查询项，而不是传统的文本查询，来研究信息检索。这使得搜索模态更加丰富，例如图像、说话者、内容、主题和情感。这个过程的关键要素是对大型存档的高速、灵活的搜索支持，MVSE通过用嵌入表示视频属性来实现这一点。这项工作旨在通过检查重新排序方法来减少来自快速存档搜索的性能损失。具体而言，研究使用大型语言模型的零-shot 重新排序方法，因为这些方法适用于任何视频存档音频内容。在公开可用的视频存档BBC Rewind语料库上评估了基于主题的检索性能。结果表明，在不需要任何任务特定的训练数据的情况下，重新排序可以实现改进的检索排名。

    The Multimodal Video Search by Examples (MVSE) project investigates using video clips as the query term for information retrieval, rather than the more traditional text query. This enables far richer search modalities such as images, speaker, content, topic, and emotion. A key element for this process is highly rapid, flexible, search to support large archives, which in MVSE is facilitated by representing video attributes by embeddings. This work aims to mitigate any performance loss from this rapid archive search by examining reranking approaches. In particular, zero-shot reranking methods using large language models are investigated as these are applicable to any video archive audio content. Performance is evaluated for topic-based retrieval on a publicly available video archive, the BBC Rewind corpus. Results demonstrate that reranking can achieve improved retrieval ranking without the need for any task-specific training data.
    
[^30]: 使用LLM预测的可信度信号和弱监督检测虚假信息

    Detecting Misinformation with LLM-Predicted Credibility Signals and Weak Supervision. (arXiv:2309.07601v1 [cs.CL])

    [http://arxiv.org/abs/2309.07601](http://arxiv.org/abs/2309.07601)

    本文研究了使用大型语言模型和弱监督的方式来检测虚假信息，证明了这种方法在两个数据集上的效果优于当前最先进的分类器。

    

    可信度信号代表了记者和事实核查员通常用来评估在线内容真实性的一系列启发式方法。然而，自动化可信度信号提取的任务非常具有挑战性，因为它需要训练高准确率的特定信号提取器，而目前没有足够大的数据集对所有可信度信号进行注释。本文研究了是否可以有效地用一组18个可信度信号来提示大型语言模型（LLMs），以产生每个信号的弱标签。然后，我们使用弱监督的方式对这些潜在的噪声标签进行聚合，以预测内容的真实性。我们证明了我们的方法，即结合了零-shot LLM可信度信号标注和弱监督的方法，在两个虚假信息数据集上优于最先进的分类器，而没有使用任何训练标签。

    Credibility signals represent a wide range of heuristics that are typically used by journalists and fact-checkers to assess the veracity of online content. Automating the task of credibility signal extraction, however, is very challenging as it requires high-accuracy signal-specific extractors to be trained, while there are currently no sufficiently large datasets annotated with all credibility signals. This paper investigates whether large language models (LLMs) can be prompted effectively with a set of 18 credibility signals to produce weak labels for each signal. We then aggregate these potentially noisy labels using weak supervision in order to predict content veracity. We demonstrate that our approach, which combines zero-shot LLM credibility signal labeling and weak supervision, outperforms state-of-the-art classifiers on two misinformation datasets without using any ground-truth labels for training. We also analyse the contribution of the individual credibility signals towards p
    
[^31]: C-Pack: 推进普通汉语嵌入的打包资源

    C-Pack: Packaged Resources To Advance General Chinese Embedding. (arXiv:2309.07597v1 [cs.CL])

    [http://arxiv.org/abs/2309.07597](http://arxiv.org/abs/2309.07597)

    C-Pack是一套推进普通汉语嵌入领域的资源，包括全面汉语文本嵌入基准、大规模文本嵌入数据集和涵盖多个尺寸的嵌入模型系列。该资源集在C-MTEB基准上实现了最高+10%的表现，并通过整合和优化一套训练方法进一步提升了效果。此外，C-Pack还发布了英语文本嵌入数据和模型，实现了最先进的性能。该资源集可公开获取。

    

    我们介绍了C-Pack，这是一套显著推进普通汉语嵌入领域的资源。C-Pack包括三个关键资源。1）C-MTEB是一个涵盖6个任务和35个数据集的全面汉语文本嵌入基准。2）C-MTP是一个从标记和未标记的汉语语料库中策划的大规模文本嵌入数据集，用于训练嵌入模型。3）C-TEM是一个涵盖多个尺寸的嵌入模型系列。我们的模型在C-MTEB上的表现优于之前的所有汉语文本嵌入达到了发布时的最高+10%。我们还整合和优化了C-TEM的整套训练方法。除了我们关于普通汉语嵌入的资源外，我们还发布了我们的英语文本嵌入数据和模型。这些英语模型在MTEB基准上实现了最先进的性能；与此同时，我们发布的英语数据比汉语数据大2倍。所有这些资源都可以在https://github.com/FlagOpen/FlagEmbedding上公开获取。

    We introduce C-Pack, a package of resources that significantly advance the field of general Chinese embeddings. C-Pack includes three critical resources. 1) C-MTEB is a comprehensive benchmark for Chinese text embeddings covering 6 tasks and 35 datasets. 2) C-MTP is a massive text embedding dataset curated from labeled and unlabeled Chinese corpora for training embedding models. 3) C-TEM is a family of embedding models covering multiple sizes. Our models outperform all prior Chinese text embeddings on C-MTEB by up to +10% upon the time of the release. We also integrate and optimize the entire suite of training methods for C-TEM. Along with our resources on general Chinese embedding, we release our data and models for English text embeddings. The English models achieve state-of-the-art performance on MTEB benchmark; meanwhile, our released English data is 2 times larger than the Chinese data. All these resources are made publicly available at https://github.com/FlagOpen/FlagEmbedding.
    
[^32]: 重新审视基于HPSG的Supertagging

    Revisiting Supertagging for HPSG. (arXiv:2309.07590v1 [cs.CL])

    [http://arxiv.org/abs/2309.07590](http://arxiv.org/abs/2309.07590)

    重新审视基于HPSG的Supertagging，在高质量注释的树库和多样化的测试数据集上，通过使用SVM和神经网络方法，取得了较高准确率。相关数据集已整理为标记分类形式，可为现代HPSG解析器提供帮助。

    

    我们提出了基于HPSG树库训练的新型supertagger。这些树库基于一个成熟的语言学理论，具有高质量的注释，并且包含了丰富多样和具有挑战性的测试数据集，超出了通常的WSJ第23节和维基百科数据。之前的HPSG supertagging主要依赖于基于MaxEnt的模型。我们使用SVM和基于神经CRF和BERT的方法，并展示出SVM和神经supertagger相对于基准模型取得了显著更高的准确率。我们微调的BERT-based tagger在来自WSJ23的1000个句子上达到了97.26%的准确率，并在完全不同领域的"The Cathedral and the Bazaar"上达到了93.88%的准确率。因此，我们得出结论，将这些新的supertagger集成到现代HPSG解析器中是有意义的，并且我们也希望我们在这里使用的多样且难的数据集在该领域中获得更多的关注。我们贡献了重新格式化为标记分类的完整数据集。

    We present new supertaggers trained on HPSG-based treebanks. These treebanks feature high-quality annotation based on a well-developed linguistic theory and include diverse and challenging test datasets, beyond the usual WSJ section 23 and Wikipedia data. HPSG supertagging has previously relied on MaxEnt-based models. We use SVM and neural CRF- and BERT-based methods and show that both SVM and neural supertaggers achieve considerably higher accuracy compared to the baseline. Our fine-tuned BERT-based tagger achieves 97.26% accuracy on 1000 sentences from WSJ23 and 93.88% on the completely out-of-domain The Cathedral and the Bazaar (cb)). We conclude that it therefore makes sense to integrate these new supertaggers into modern HPSG parsers, and we also hope that the diverse and difficult datasets we used here will gain more popularity in the field. We contribute the complete dataset reformatted for token classification.
    
[^33]: 自适应提示学习与蒸馏连贯知识在隐含篇章关系识别中的应用

    Adaptive Prompt Learning with Distilled Connective Knowledge for Implicit Discourse Relation Recognition. (arXiv:2309.07561v1 [cs.CL])

    [http://arxiv.org/abs/2309.07561](http://arxiv.org/abs/2309.07561)

    本文提出了一种连续版本的提示学习方法AdaptPrompt，在隐含篇章关系识别中应用连贯知识蒸馏，通过连续提示和知识传递改进性能，减少手动设计工作。

    

    隐含篇章关系识别(IDRR)旨在识别两个文本片段之间的篇章关系，而无需显式的连接词。最近，提示学习被应用于IDRR任务，并取得了比基于神经网络的方法更好的性能。然而，现有的提示学习方法需要手动设计模板和答案，这对于实际应用来说是一个巨大的障碍。本文提出了一种连续版本的提示学习方法，结合连贯知识蒸馏，称为AdaptPrompt，通过连续的提示减少手动设计工作，并通过知识传递进一步改进性能。具体而言，我们设计和训练了一些虚拟标记来形成连续的模板，并通过在嵌入空间中进行梯度搜索自动选择最合适的模板。我们还设计了一个答案关系映射规则来生成一些虚拟答案作为答案空间。

    Implicit discourse relation recognition (IDRR) aims at recognizing the discourse relation between two text segments without an explicit connective. Recently, the prompt learning has just been applied to the IDRR task with great performance improvements over various neural network-based approaches. However, the discrete nature of the state-art-of-art prompting approach requires manual design of templates and answers, a big hurdle for its practical applications. In this paper, we propose a continuous version of prompt learning together with connective knowledge distillation, called AdaptPrompt, to reduce manual design efforts via continuous prompting while further improving performance via knowledge transfer. In particular, we design and train a few virtual tokens to form continuous templates and automatically select the most suitable one by gradient search in the embedding space. We also design an answer-relation mapping rule to generate a few virtual answers as the answer space. Furthe
    
[^34]: DBLPLink: 一个用于DBLP学术知识图的实体链接器

    DBLPLink: An Entity Linker for the DBLP Scholarly Knowledge Graph. (arXiv:2309.07545v1 [cs.CL])

    [http://arxiv.org/abs/2309.07545](http://arxiv.org/abs/2309.07545)

    DBLPLink是一个用于DBLP学术知识图的实体链接器，它使用文本到文本的预训练语言模型和实体嵌入来进行实体标签生成和排序。

    

    在这项工作中，我们介绍了一个名为DBLPLink的网络应用程序，它在DBLP学术知识图上执行实体链接。DBLPLink使用文本到文本的预训练语言模型（如T5）从输入的文本问题中生成实体标签跨度。基于这些标签，从数据库中获取实体候选项，并使用实体嵌入（如TransE、DistMult和ComplEx）对它们进行排序。结果以用户可以比较和对比T5-small、T5-base和不同的知识图嵌入之间的结果。演示可以在https://ltdemos.informatik.uni-hamburg.de/dblplink/访问。

    In this work, we present a web application named DBLPLink, which performs entity linking over the DBLP scholarly knowledge graph. DBLPLink uses text-to-text pre-trained language models, such as T5, to produce entity label spans from an input text question. Entity candidates are fetched from a database based on the labels, and an entity re-ranker sorts them based on entity embeddings, such as TransE, DistMult and ComplEx. The results are displayed so that users may compare and contrast the results between T5-small, T5-base and the different KG embeddings used. The demo can be accessed at https://ltdemos.informatik.uni-hamburg.de/dblplink/.
    
[^35]: 使用声学单元的直接文本到语音翻译系统

    Direct Text to Speech Translation System using Acoustic Units. (arXiv:2309.07478v1 [cs.CL])

    [http://arxiv.org/abs/2309.07478](http://arxiv.org/abs/2309.07478)

    本文提出了一种使用离散声学单元的直接文本到语音翻译系统，通过结合语音编码器和聚类算法提取声学单元，并使用编码器-解码器架构预测和生成语音。实验证明，该系统在多数评估的语言对上表现出竞争性能，并且使用更多语言预训练模型进行初始化会带来显著的改进。

    

    本文提出了一种使用离散声学单元的直接文本到语音翻译系统。该框架使用不同源语言的文本作为输入，在不需要该语言的文本转录的情况下生成目标语言的语音。受到以前直接语音到语音翻译系统中声学单元的成功启发，我们使用相同的流水线通过结合语音编码器和聚类算法提取声学单元。一旦获得单元，就会训练一个编码器-解码器架构来预测它们。然后，一个声码器从单元生成语音。我们的直接文本到语音翻译方法在使用两个不同的文本mBART模型作为初始化的新CVSS语料库上进行了测试。所提出的系统在大多数评估的语言对上表现出竞争性能。此外，结果表明，当使用更多语言预训练模型来初始化我们提出的架构时，有显着的改进。

    This paper proposes a direct text to speech translation system using discrete acoustic units. This framework employs text in different source languages as input to generate speech in the target language without the need for text transcriptions in this language. Motivated by the success of acoustic units in previous works for direct speech to speech translation systems, we use the same pipeline to extract the acoustic units using a speech encoder combined with a clustering algorithm. Once units are obtained, an encoder-decoder architecture is trained to predict them. Then a vocoder generates speech from units. Our approach for direct text to speech translation was tested on the new CVSS corpus with two different text mBART models employed as initialisation. The systems presented report competitive performance for most of the language pairs evaluated. Besides, results show a remarkable improvement when initialising our proposed architecture with a model pre-trained with more languages.
    
[^36]: 基于大型语言模型的评估器是否是扩展多语言评估的解决方案？

    Are Large Language Model-based Evaluators the Solution to Scaling Up Multilingual Evaluation?. (arXiv:2309.07462v1 [cs.CL])

    [http://arxiv.org/abs/2309.07462](http://arxiv.org/abs/2309.07462)

    大型语言模型（LLMs）作为评估器可以解决当前多语言评估的限制和挑战，能够对各种语言中的自然语言处理任务进行有效评估。

    

    大型语言模型（LLMs）在自然语言处理（NLP）任务中展现出了令人印象深刻的性能，如问答、摘要和分类。将LLMs用作评估器，可以对其他模型（通常为LLMs）的输出进行排序或评分，因为当前评估技术存在许多限制，包括缺乏适当的基准、指标、成本和人工标注者的访问性。虽然LLMs能够处理大约100种语言，但大多数语言在各种任务、指标和基准上缺乏系统的评估。这就迫切需要扩展多语言评估，以确保对LLM在各种语言中的性能有准确的理解。基于LLM的评估器似乎是这个问题的完美解决方案，因为它们不需要人工标注者、人工创建的参考和基准，并且理论上可以用来评估任何被覆盖的语言。

    Large Language Models (LLMs) have demonstrated impressive performance on Natural Language Processing (NLP) tasks, such as Question Answering, Summarization, and Classification. The use of LLMs as evaluators, that can rank or score the output of other models (usually LLMs) has become increasingly popular, due to the limitations of current evaluation techniques including the lack of appropriate benchmarks, metrics, cost, and access to human annotators. While LLMs are capable of handling approximately 100 languages, the majority of languages beyond the top 20 lack systematic evaluation across various tasks, metrics, and benchmarks. This creates an urgent need to scale up multilingual evaluation to ensure a precise understanding of LLM performance across diverse languages. LLM-based evaluators seem like the perfect solution to this problem, as they do not require human annotators, human-created references, or benchmarks and can theoretically be used to evaluate any language covered by the 
    
[^37]: SIB-200: 包括200多种语言和方言的简单、全面和大型主题分类评估数据集

    SIB-200: A Simple, Inclusive, and Big Evaluation Dataset for Topic Classification in 200+ Languages and Dialects. (arXiv:2309.07445v1 [cs.CL])

    [http://arxiv.org/abs/2309.07445](http://arxiv.org/abs/2309.07445)

    本研究提出了SIB-200数据集，在200多种语言和方言中提供了一个大规模、全面的主题分类评估数据集。该数据集填补了自然语言理解领域中对评估数据集的缺乏，通过全监督、跨语言迁移和大型语言模型提示的评估，发现性能仍存在差距。

    

    尽管在多语言自然语言处理方面取得了进展，但评估通常仅限于一小部分带有可用数据集的语言，排除了许多资源匮乏的语言。本文创建了SIB-200，这是一个用于主题分类的大规模开放源代码基准数据集，涵盖了200多种语言和方言，以弥补自然语言理解（NLU）缺乏评估数据集的问题。对于SIB-200中涵盖的许多语言来说，这是首个公开可用的NLU评估数据集。该数据集基于Flores-200机器翻译语料库，并对该语料库涵盖的其他203种语言进行了句子级注释。尽管该任务简单，但我们在全监督设置、跨语言迁移设置和大型语言模型提示设置下的评估结果表明，性能仍存在较大差距。

    Despite the progress we have recorded in the last few years in multilingual natural language processing, evaluation is typically limited to a small set of languages with available datasets which excludes a large number of low-resource languages. In this paper, we created SIB-200 -- a large-scale open-sourced benchmark dataset for topic classification in 200 languages and dialects to address the lack of evaluation dataset for Natural Language Understanding (NLU). For many of the languages covered in SIB-200, this is the first publicly available evaluation dataset for NLU. The dataset is based on Flores-200 machine translation corpus. We annotated the English portion of the dataset and extended the sentence-level annotation to the remaining 203 languages covered in the corpus. Despite the simplicity of this task, our evaluation in full-supervised setting, cross-lingual transfer setting and prompting of large language model setting show that there is still a large gap between the performa
    
[^38]: 临床文本摘要: 大型语言模型的应用优于人类专家

    Clinical Text Summarization: Adapting Large Language Models Can Outperform Human Experts. (arXiv:2309.07430v1 [cs.CL])

    [http://arxiv.org/abs/2309.07430](http://arxiv.org/abs/2309.07430)

    本研究通过对八个大型语言模型在临床摘要任务上的领域适应方法实验进行了全面的定量评估，发现最佳适应的模型的摘要在完整性和正确性方面优于人类摘要。

    

    在临床工作中，浏览大量的文本数据并总结关键信息对临床医生的时间分配造成了很大的负担。尽管大型语言模型（LLMs）在自然语言处理（NLP）任务中展现了巨大的潜力，但它们在各种临床摘要任务中的效果尚未得到严格的检验。在本研究中，我们对八个LLMs进行了领域适应方法的实验，涵盖了六个数据集和四个不同的摘要任务：放射学报告、患者问题、病历记录和医患对话。我们进行了全面的定量评估，发现模型和适应方法之间存在权衡，并且在某些情况下，LLMs的最新进展可能不会带来改进的结果。此外，通过与六名医生进行的临床阅读者研究，我们发现最佳适应的LLM的摘要在完整性和正确性方面优于人类摘要。我们的进一步定性分析揭示了LLMs和人类在面对的共同挑战。

    Sifting through vast textual data and summarizing key information imposes a substantial burden on how clinicians allocate their time. Although large language models (LLMs) have shown immense promise in natural language processing (NLP) tasks, their efficacy across diverse clinical summarization tasks has not yet been rigorously examined. In this work, we employ domain adaptation methods on eight LLMs, spanning six datasets and four distinct summarization tasks: radiology reports, patient questions, progress notes, and doctor-patient dialogue. Our thorough quantitative assessment reveals trade-offs between models and adaptation methods in addition to instances where recent advances in LLMs may not lead to improved results. Further, in a clinical reader study with six physicians, we depict that summaries from the best adapted LLM are preferable to human summaries in terms of completeness and correctness. Our ensuing qualitative analysis delineates mutual challenges faced by both LLMs and
    
[^39]: 在有限资源条件下的语义解析

    Semantic Parsing in Limited Resource Conditions. (arXiv:2309.07429v1 [cs.CL])

    [http://arxiv.org/abs/2309.07429](http://arxiv.org/abs/2309.07429)

    本论文探讨了在有限资源条件下的语义解析的挑战，并提出了解决方案，包括使用自动数据筛选、知识迁移、主动学习和持续学习。具体方法包括合成训练样本、利用源领域知识改进目标领域解析，以及利用有限的人工翻译预算和机器翻译服务来调整解析器。

    

    本论文探讨了在有限的数据和计算资源条件下的语义解析的挑战，并提供了使用自动数据筛选、知识迁移、主动学习和持续学习等技术的解决方案。对于没有平行训练数据的任务，本论文提出了从结构化数据库模式生成合成训练样本的方法。当源领域有大量数据但目标领域只有有限的平行数据时，利用源领域的知识来改进目标领域的解析。对于目标语言中有限数据的多语言情况，本论文引入了一种使用有限的人工翻译预算来调整解析器的方法。通过主动学习选择源语言样本进行手动翻译，最大化目标语言解析器的性能。此外，本论文还提出了一种替代方法，利用机器翻译服务，并辅以人工翻译的方法。

    This thesis explores challenges in semantic parsing, specifically focusing on scenarios with limited data and computational resources. It offers solutions using techniques like automatic data curation, knowledge transfer, active learning, and continual learning.  For tasks with no parallel training data, the thesis proposes generating synthetic training examples from structured database schemas. When there is abundant data in a source domain but limited parallel data in a target domain, knowledge from the source is leveraged to improve parsing in the target domain.  For multilingual situations with limited data in the target languages, the thesis introduces a method to adapt parsers using a limited human translation budget. Active learning is applied to select source-language samples for manual translation, maximizing parser performance in the target language. In addition, an alternative method is also proposed to utilize machine translation services, supplemented by human-translated d
    
[^40]: ChatGPT MT: 高资源语言中具有竞争力（但不是低资源语言）的机器翻译

    ChatGPT MT: Competitive for High- (but not Low-) Resource Languages. (arXiv:2309.07423v1 [cs.CL])

    [http://arxiv.org/abs/2309.07423](http://arxiv.org/abs/2309.07423)

    ChatGPT在高资源语言中具有竞争力的机器翻译能力，但在低资源语言方面表现不佳。资源水平是决定其翻译能力的最重要特征。

    

    大型语言模型（LLMs）隐式地学习执行各种语言任务，包括机器翻译（MT）。先前的研究探索了LLMs在MT方面的能力。然而，存在许多语言，其最近的LLM MT性能尚未评估。在没有发表的实验证据的情况下，世界上多样化语言的使用者难以知道如何以及是否可以使用LLMs进行该语言的翻译。我们提供了首个实验证据，涵盖了204种语言，以及使用FLORES-200基准进行的MT成本分析。趋势表明GPT模型在某些高资源语言（HRLs）的性能接近或超过传统MT模型，但在低资源语言（LRLs）方面一直表现不佳，我们所研究的语言中有84.1%的语言在传统MT下效果更好。我们的分析表明，语言的资源水平是确定ChatGPT相对能力的最重要特征。

    Large language models (LLMs) implicitly learn to perform a range of language tasks, including machine translation (MT). Previous studies explore aspects of LLMs' MT capabilities. However, there exist a wide variety of languages for which recent LLM MT performance has never before been evaluated. Without published experimental evidence on the matter, it is difficult for speakers of the world's diverse languages to know how and whether they can use LLMs for their languages. We present the first experimental evidence for an expansive set of 204 languages, along with MT cost analysis, using the FLORES-200 benchmark. Trends reveal that GPT models approach or exceed traditional MT model performance for some high-resource languages (HRLs) but consistently lag for low-resource languages (LRLs), under-performing traditional MT for 84.1% of languages we covered. Our analysis reveals that a language's resource level is the most important feature in determining ChatGPT's relative ability to transl
    
[^41]: 具有可控风格的语境化自动语音识别中的PromptASR

    PromptASR for contextualized ASR with controllable style. (arXiv:2309.07414v1 [eess.AS])

    [http://arxiv.org/abs/2309.07414](http://arxiv.org/abs/2309.07414)

    PromptASR是一个框架，将提示集成到端到端自动语音识别系统中，实现了具有可控风格的语境化语音转录。在实验中，使用前一话语的真实文本作为内容提示时，相对于基线ASR系统，该系统在阅读图书数据集和内部数据集上分别获得了21.9％和6.8％的词错误率降低。此外，该系统可以采用单词级偏置列表作为提示来提高对罕见单词的识别准确性。同时，该系统还可以使用额外的样式提示来引导ASR系统输出不同风格的转录。

    

    对于大型语言模型来说，提示非常重要，因为它们提供了主题或逻辑关系等上下文信息。受此启发，我们提出了PromptASR，这是一个将提示集成到端到端自动语音识别（E2E ASR）系统中，以实现具有可控风格的语境化语音转录的框架。具体地，专用文本编码器对文本提示进行编码，并通过跨两种模态的特征交互将编码注入到语音编码器中。当使用前面话语的真实文本作为内容提示时，与基线ASR系统相比，所提出的系统在阅读图书数据集和内部数据集上分别实现了21.9％和6.8％的相对词错误率降低。系统还可以采用单词级偏置列表作为提示，以提高对罕见单词的识别准确性。还可以给文本编码器提供额外的样式提示，并引导ASR系统输出不同风格的转录。代码可供使用。

    Prompts are crucial to large language models as they provide context information such as topic or logical relationships. Inspired by this, we propose PromptASR, a framework that integrates prompts in end-to-end automatic speech recognition (E2E ASR) systems to achieve contextualized ASR with controllable style of transcriptions. Specifically, a dedicated text encoder encodes the text prompts and the encodings are injected into the speech encoder by cross-attending the features from two modalities. When using the ground truth text from preceding utterances as content prompt, the proposed system achieves 21.9% and 6.8% relative word error rate reductions on a book reading dataset and an in-house dataset compared to a baseline ASR system. The system can also take word-level biasing lists as prompt to improve recognition accuracy on rare words. An additional style prompt can be given to the text encoder and guide the ASR system to output different styles of transcriptions. The code is avai
    
[^42]: CPPF: 一种上下文和后处理无关的自动语音识别模型

    CPPF: A contextual and post-processing-free model for automatic speech recognition. (arXiv:2309.07413v1 [cs.CL])

    [http://arxiv.org/abs/2309.07413](http://arxiv.org/abs/2309.07413)

    CPPF是一种上下文和后处理无关的自动语音识别模型，它整合了多个与语音识别相关的ASR文本处理任务，提供了一种优化流程、避免级联错误传播且识别性能几乎没有损失的解决方案。

    

    近年来，ASR系统变得越来越广泛应用。然而，它们的文本输出通常需要经过后处理任务才能实际利用。为了解决这个问题，我们从LLMs和Whisper的多方面能力中获得启发，专注于将与语音识别相关的多个ASR文本处理任务整合到ASR模型中。这种整合不仅缩短了多阶段的流程，还防止了级联错误的传播，从而直接生成后处理过的文本。本研究重点关注与ASR相关的处理任务，包括上下文ASR和多个ASR后处理任务。为了实现这一目标，我们引入了CPPF模型，它提供了一种多功能和高效的ASR处理替代方案。CPPF无缝地整合了这些任务，而且识别性能几乎没有明显的损失。

    ASR systems have become increasingly widespread in recent years. However, their textual outputs often require post-processing tasks before they can be practically utilized. To address this issue, we draw inspiration from the multifaceted capabilities of LLMs and Whisper, and focus on integrating multiple ASR text processing tasks related to speech recognition into the ASR model. This integration not only shortens the multi-stage pipeline, but also prevents the propagation of cascading errors, resulting in direct generation of post-processed text. In this study, we focus on ASR-related processing tasks, including Contextual ASR and multiple ASR post processing tasks. To achieve this objective, we introduce the CPPF model, which offers a versatile and highly effective alternative to ASR processing. CPPF seamlessly integrates these tasks without any significant loss in recognition performance.
    
[^43]: 在线性循环神经网络中推进正则语言推理

    Advancing Regular Language Reasoning in Linear Recurrent Neural Networks. (arXiv:2309.07412v1 [cs.CL])

    [http://arxiv.org/abs/2309.07412](http://arxiv.org/abs/2309.07412)

    通过分析现有的线性循环神经网络（LRNN），我们提出了一种新的LRNN模型，该模型配备了一个块对角且输入相关的转移矩阵，并且是唯一一个能够在正则语言任务上进行长度外推的LRNN。

    

    在最近的研究中，线性循环神经网络（LRNN）在自然语言建模和长程建模中取得了与Transformer相当的性能，同时提供了快速的并行训练和恒定的推理成本。在对LRNN重新产生兴趣的同时，我们研究它们是否能够学习训练序列中的隐藏规则，例如正则语言的语法结构。我们对一些已有的LRNN进行理论分析，发现它们在正则语言上存在限制。在这个分析的基础上，我们提出了一种新的LRNN，配备了一个块对角和输入相关的转移矩阵。实验表明，所提出的模型是唯一一个能够在正则语言任务（如求和、偶数对、模运算等）上进行长度外推的LRNN。

    In recent studies, linear recurrent neural networks (LRNNs) have achieved Transformer-level performance in natural language modeling and long-range modeling while offering rapid parallel training and constant inference costs. With the resurged interest in LRNNs, we study whether they can learn the hidden rules in training sequences, such as the grammatical structures of regular language. We theoretically analyze some existing LRNNs and discover their limitations on regular language. Motivated by the analysis, we propose a new LRNN equipped with a block-diagonal and input-dependent transition matrix. Experiments suggest that the proposed model is the only LRNN that can perform length extrapolation on regular language tasks such as Sum, Even Pair, and Modular Arithmetic.
    
[^44]: DebCSE: 以去偏见的角度重新思考无监督对比句子嵌入学习

    DebCSE: Rethinking Unsupervised Contrastive Sentence Embedding Learning in the Debiasing Perspective. (arXiv:2309.07396v1 [cs.CL])

    [http://arxiv.org/abs/2309.07396](http://arxiv.org/abs/2309.07396)

    本文重新思考了无监督对比句子嵌入学习，并从去偏见的角度提出了DebCSE方法。通过消除各种偏差，包括词频偏差、句子长度偏差和假负样本偏差，DebCSE旨在学习高质量的句子嵌入。

    

    先前的研究指出，词频偏差会导致Bert模型学习到无法区分的句子嵌入。一些对比学习方案，如SimCSE和ConSERT，已成功用于改善无监督句子嵌入的质量，减少偏差。然而，这些方法仍会引入新的偏差，如句子长度偏差和假负样本偏差，这些偏差阻碍了模型学习更精细的语义。本文从去偏见的角度重新审视对比句子嵌入学习的挑战，并认为有效消除各种偏差对于学习高质量句子嵌入至关重要。我们认为，所有这些偏差都是由于对比学习中构建训练数据的简单规则引入的，对比学习句子嵌入的关键是在无监督机器学习中模拟训练数据的分布。

    Several prior studies have suggested that word frequency biases can cause the Bert model to learn indistinguishable sentence embeddings. Contrastive learning schemes such as SimCSE and ConSERT have already been adopted successfully in unsupervised sentence embedding to improve the quality of embeddings by reducing this bias. However, these methods still introduce new biases such as sentence length bias and false negative sample bias, that hinders model's ability to learn more fine-grained semantics. In this paper, we reexamine the challenges of contrastive sentence embedding learning from a debiasing perspective and argue that effectively eliminating the influence of various biases is crucial for learning high-quality sentence embeddings. We think all those biases are introduced by simple rules for constructing training data in contrastive learning and the key for contrastive learning sentence embedding is to mimic the distribution of training data in supervised machine learning in uns
    
[^45]: VDialogUE: 一个用于视觉导向对话的统一评估基准

    VDialogUE: A Unified Evaluation Benchmark for Visually-grounded Dialogue. (arXiv:2309.07387v1 [cs.CL])

    [http://arxiv.org/abs/2309.07387](http://arxiv.org/abs/2309.07387)

    VDialogUE是一个用于视觉导向对话的统一评估基准，定义了五个核心多模态对话任务，并涵盖了六个数据集。此外，还引入了一种新的评估指标VDscore，并提供了一个名为VISIT的基线模型来促进通用多模态对话系统的发展。

    

    视觉导向对话系统将多种沟通模式（如文本和视觉输入）集成在一起，成为一个越来越受关注的领域。然而，缺乏标准化的评估框架对于评估该领域的发展构成了挑战。为此，我们提出了VDialogUE，一个用于视觉导向对话的统一评估基准。它定义了五个核心多模态对话任务，并涵盖了六个数据集。此外，为了全面评估模型在所有任务上的性能，我们开发了一种新的评估指标VDscore，该指标基于层次分析过程（Analytic Hierarchy Process，AHP）方法。此外，我们还提供了一个简单而高效的基线模型VISIT（VISually-grounded dIalog Transformer），以促进通用多模态对话系统的进展。它逐步构建它的多模态能力

    Visually-grounded dialog systems, which integrate multiple modes of communication such as text and visual inputs, have become an increasingly popular area of investigation. However, the absence of a standardized evaluation framework poses a challenge in assessing the development of this field. To this end, we propose \textbf{VDialogUE}, a \textbf{V}isually-grounded \textbf{Dialog}ue benchmark for \textbf{U}nified \textbf{E}valuation. It defines five core multi-modal dialogue tasks and covers six datasets. Furthermore, in order to provide a comprehensive assessment of the model's performance across all tasks, we developed a novel evaluation metric called VDscore, which is based on the Analytic Hierarchy Process~(AHP) method. Additionally, we present a straightforward yet efficient baseline model, named \textbf{VISIT}~(\textbf{VIS}ually-grounded d\textbf{I}alog \textbf{T}ransformer), to promote the advancement of general multi-modal dialogue systems. It progressively builds its multi-mod
    
[^46]: 一个交互式框架用于对新闻媒体来源进行特征分析

    An Interactive Framework for Profiling News Media Sources. (arXiv:2309.07384v1 [cs.CL])

    [http://arxiv.org/abs/2309.07384](http://arxiv.org/abs/2309.07384)

    本文提出了一个交互式框架用于对新闻媒体来源进行特征分析，通过结合图形分析模型、预训练语言模型和人类洞察力，可以快速检测虚假和有偏见的新闻媒体。

    

    社交媒体的兴起导致了大量虚假和有偏见的新闻传播，即以影响信仰为目的的内容发布。虽然检测和对传播这些新闻的来源进行特征分析对于维护一个健康的社会很重要，但对于自动化系统来说是具有挑战性的。本文提出了一个交互式框架用于新闻媒体的特征分析，将基于图的新闻媒体特征分析模型、预训练大型语言模型和人类洞察力相结合，以表征社交媒体上的社会环境。实验结果显示，通过仅需五次人类交互，我们的框架可以快速检测出虚假和有偏见的新闻媒体，甚至在最具挑战性的新闻事件出现时，其中的测试数据是未知的。

    The recent rise of social media has led to the spread of large amounts of fake and biased news, content published with the intent to sway beliefs. While detecting and profiling the sources that spread this news is important to maintain a healthy society, it is challenging for automated systems.  In this paper, we propose an interactive framework for news media profiling. It combines the strengths of graph based news media profiling models, Pre-trained Large Language Models, and human insight to characterize the social context on social media. Experimental results show that with as little as 5 human interactions, our framework can rapidly detect fake and biased news media, even in the most challenging settings of emerging news events, where test data is unseen.
    
[^47]: 长文本摘要评估中“少即是多”的理论

    Less is More for Long Document Summary Evaluation by LLMs. (arXiv:2309.07382v1 [cs.CL])

    [http://arxiv.org/abs/2309.07382](http://arxiv.org/abs/2309.07382)

    该论文引入了一种新颖的方法，通过先提取关键句子再进行评估，有效解决了大型语言模型在长文档摘要评估中遇到的计算成本高和忽视重要信息的问题。研究发现，这种方法不仅显著降低了评估成本，而且与人工评估有更高的相关性。此外，论文还提供了关于最佳文档长度和句子提取方法的实用建议，为基于大型语言模型的文本生成评估的发展做出了贡献。

    

    大型语言模型(LLMs)在摘要评估任务中表现出了令人期待的性能，但它们面临诸如高计算成本和长文档中重要信息被忽视的“迷失在中间”问题。为解决这些问题，本文引入了一种新颖的方法，即“先提取再评估”，该方法涉及从长文本源文件中提取关键句子，然后通过提问LLMs来评估摘要。结果表明，所提出的方法不仅显著降低了评估成本，而且与人工评估之间存在更高的相关性。此外，我们提供了关于最佳文档长度和句子提取方法的实用建议，为基于LLMs的文本生成评估的开发提供了成本效益更高且更准确的方法。

    Large Language Models (LLMs) have shown promising performance in summary evaluation tasks, yet they face challenges such as high computational costs and the Lost-in-the-Middle problem where important information in the middle of long documents is often overlooked. To address these issues, this paper introduces a novel approach, Extract-then-Evaluate, which involves extracting key sentences from a long source document and then evaluating the summary by prompting LLMs. The results reveal that the proposed method not only significantly reduces evaluation costs but also exhibits a higher correlation with human evaluations. Furthermore, we provide practical recommendations for optimal document length and sentence extraction methods, contributing to the development of cost-effective yet more accurate methods for LLM-based text generation evaluation.
    
[^48]: 半混合注意力编码器-解码器模型用于高效语言模型适应

    Hybrid Attention-based Encoder-decoder Model for Efficient Language Model Adaptation. (arXiv:2309.07369v1 [eess.AS])

    [http://arxiv.org/abs/2309.07369](http://arxiv.org/abs/2309.07369)

    半混合注意力编码器-解码器模型通过分离声学模型和语言模型，以实现对传统文本语言模型适应技术的利用。在使用域外文本数据进行语言模型适应时，相对于传统模型，该模型可获得21\%的词错误率改进。

    

    基于注意力的编码器-解码器语音识别模型近年来取得了广泛的成功。然而，在端到端方式中联合优化声学模型和语言模型对于文本适应性提出了挑战。特别是，有效、快速和廉价地适应文本已成为在工业中部署注意力编码器-解码器系统的主要关注点。为了解决这个问题，我们提出了一种新颖的模型，即半混合注意力编码器-解码器语音识别模型，保留了传统混合自动语音识别系统的模块化特性。我们的半混合注意力编码器-解码器模型将声学模型和语言模型分离，使得可以使用传统的基于文本的语言模型适应技术。我们证明了在使用域外文本数据进行语言模型适应时，所提出的半混合注意力编码器-解码器模型相对于传统的基于注意力的模型在词错误率上实现了21\%的改进，并且在常规测试集上的词错误率只有轻微的降低。

    Attention-based encoder-decoder (AED) speech recognition model has been widely successful in recent years. However, the joint optimization of acoustic model and language model in end-to-end manner has created challenges for text adaptation. In particular, effectively, quickly and inexpensively adapting text has become a primary concern for deploying AED systems in industry. To address this issue, we propose a novel model, the hybrid attention-based encoder-decoder (HAED) speech recognition model that preserves the modularity of conventional hybrid automatic speech recognition systems. Our HAED model separates the acoustic and language models, allowing for the use of conventional text-based language model adaptation techniques. We demonstrate that the proposed HAED model yields 21\% Word Error Rate (WER) improvements in relative when out-of-domain text data is used for language model adaptation, and with only a minor degradation in WER on a general test set compared with conventional AE
    
[^49]: 从辅助来源中学习在辩论修订分类中的应用

    Learning from Auxiliary Sources in Argumentative Revision Classification. (arXiv:2309.07334v1 [cs.CL])

    [http://arxiv.org/abs/2309.07334](http://arxiv.org/abs/2309.07334)

    该论文主要研究了在辩论写作中分类理想的推理修改的模型，并提出了多任务学习和迁移学习两种方法来利用辅助修订数据的来源。研究结果表明，这两种方法可以显著改善分类器的性能，并且迁移学习可以更好地表示数据之间的关系。

    

    我们开发了模型来分类辩论写作中希望改进的推理修订。我们探索了两种方法 - 多任务学习和迁移学习 - 利用类似任务的修订数据的辅助来源。内在和外在评估结果表明，这两种方法确实可以提高分类器性能，超过基线。尽管多任务学习显示同时在不同的数据来源上进行训练可能会提高性能，迁移学习更好地表示数据之间的关系。

    We develop models to classify desirable reasoning revisions in argumentative writing. We explore two approaches -- multi-task learning and transfer learning -- to take advantage of auxiliary sources of revision data for similar tasks. Results of intrinsic and extrinsic evaluations show that both approaches can indeed improve classifier performance over baselines. While multi-task learning shows that training on different sources of data at the same time may improve performance, transfer-learning better represents the relationship between the data.
    
[^50]: 旅行词：一种变压器的几何解释。

    Traveling Words: A Geometric Interpretation of Transformers. (arXiv:2309.07315v1 [cs.CL])

    [http://arxiv.org/abs/2309.07315](http://arxiv.org/abs/2309.07315)

    本文提出了一种几何视角来解释变压器的内部机制，主要贡献在于阐明了层归一化如何限制潜在特征并在超球面上塑造注意力机制，通过探测预训练的GPT-2模型验证了该视角的有效性，并提供了对变压器的直观理解。

    

    变压器在自然语言处理领域取得了显著的进展，但理解其内部机制仍然是一个挑战。本文介绍了一种新颖的几何视角，阐明了变压器操作的内部机制。我们的主要贡献是说明了层归一化如何将潜在特征限制在一个超球面上，从而使注意力能够在该表面上塑造单词的语义表示。这种几何视点无缝地连接了迭代改进和上下文嵌入等已知属性。我们通过探测一个预训练的124M参数的GPT-2模型验证了我们的见解。我们的发现揭示了早期层中清晰的查询-键注意力模式，并在更深的层次上建立在先前关于注意头的专门性的观察基础上。利用这些几何见解，我们提出了对变压器的直观理解，将其描绘为塑造轨迹的过程。

    Transformers have significantly advanced the field of natural language processing, but comprehending their internal mechanisms remains a challenge. In this paper, we introduce a novel geometric perspective that elucidates the inner mechanisms of transformer operations. Our primary contribution is illustrating how layer normalization confines the latent features to a hyper-sphere, subsequently enabling attention to mold the semantic representation of words on this surface. This geometric viewpoint seamlessly connects established properties such as iterative refinement and contextual embeddings. We validate our insights by probing a pre-trained 124M parameter GPT-2 model. Our findings reveal clear query-key attention patterns in early layers and build upon prior observations regarding the subject-specific nature of attention heads at deeper layers. Harnessing these geometric insights, we present an intuitive understanding of transformers, depicting them as processes that model the trajec
    
[^51]: 损失突然下降：语法习得、相变和MLM中的简化偏差

    Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and Simplicity Bias in MLMs. (arXiv:2309.07311v1 [cs.CL])

    [http://arxiv.org/abs/2309.07311](http://arxiv.org/abs/2309.07311)

    本文通过对掩码语言模型中的语法习得进行案例研究，发现在训练的一个短暂窗口内，模型突然获得了语法注意结构(SAS)，并伴随着损失的陡峭下降。SAS对随后习得语言能力起到了重要的促进作用。

    

    自然语言处理(NLP)中的大多数可解释性研究侧重于理解完全训练模型的行为和特征。然而，通过观察训练过程的轨迹，可能才能获得对模型行为的某些洞察。在本文中，我们通过对掩码语言模型(MLMs)中的语法习得进行案例研究，展示了如何通过分析训练过程中可解释性的演化来加深我们对新兴行为的理解。具体而言，我们研究了语法注意结构(SAS)，这是MLMs中自然形成的一个特性，其中特定的Transformer头倾向于关注特定的句法关系。我们发现在训练的一个短暂窗口内，模型突然获得了SAS，并发现这个窗口与损失的陡峭下降同时发生。此外，SAS促使了随后对语言能力的习得。然后，我们通过引入一个正则化项来操纵训练过程中的SAS，来研究SAS的因果作用，并进行了实验证明。

    Most interpretability research in NLP focuses on understanding the behavior and features of a fully trained model. However, certain insights into model behavior may only be accessible by observing the trajectory of the training process. In this paper, we present a case study of syntax acquisition in masked language models (MLMs). Our findings demonstrate how analyzing the evolution of interpretable artifacts throughout training deepens our understanding of emergent behavior. In particular, we study Syntactic Attention Structure (SAS), a naturally emerging property of MLMs wherein specific Transformer heads tend to focus on specific syntactic relations. We identify a brief window in training when models abruptly acquire SAS and find that this window is concurrent with a steep drop in loss. Moreover, SAS precipitates the subsequent acquisition of linguistic capabilities. We then examine the causal role of SAS by introducing a regularizer to manipulate SAS during training, and demonstrate
    
[^52]: 大型语言模型中的背景偏见抑制

    In-Contextual Bias Suppression for Large Language Models. (arXiv:2309.07251v1 [cs.CL])

    [http://arxiv.org/abs/2309.07251](http://arxiv.org/abs/2309.07251)

    基于文本前导语和职业描述句生成的反事实命题模板可以有效抑制大型语言模型中的性别偏见，而不需要访问模型参数，并且不会对下游任务性能产生明显的负面影响。

    

    尽管大型语言模型在各种自然语言处理任务中表现出色，但已有研究报告称其存在令人担忧的性别偏见。先前的工作提出了需要人工标注示例、数据增强和LLM的微调的去偏方法，这些方法计算成本高昂。此外，某些情况下可能无法获得进行去偏所需的内部参数，如商用LLM（如GPT-4）的情况。为了解决这一挑战，我们提出了一种新的去偏替代方法，称为偏见抑制，它不需要访问模型参数。我们展示了基于手动设计的反事实命题模板生成的文本前导语可以准确地抑制LLM中的性别偏见。此外，我们发现职业的描述句可以进一步抑制性别偏见。有趣的是，我们发现偏见抑制对下游任务性能几乎没有不利影响，同时有效缓解了性别偏见。

    Despite their impressive performance in a wide range of NLP tasks, Large Language Models (LLMs) have been reported to encode worrying-levels of gender bias. Prior work has proposed debiasing methods that require human labelled examples, data augmentation and fine-tuning of the LLMs, which are computationally costly. Moreover, one might not even have access to the internal parameters for performing debiasing such as in the case of commercially available LLMs such as GPT-4. To address this challenge we propose bias suppression, a novel alternative to debiasing that does not require access to model parameters. We show that text-based preambles, generated from manually designed templates covering counterfactual statements, can accurately suppress gender biases in LLMs. Moreover, we find that descriptive sentences for occupations can further suppress gender biases. Interestingly, we find that bias suppression has a minimal adverse effect on downstream task performance, while effectively mit
    
[^53]: 探索大型语言模型在本体对齐中的应用

    Exploring Large Language Models for Ontology Alignment. (arXiv:2309.07172v1 [cs.AI])

    [http://arxiv.org/abs/2309.07172](http://arxiv.org/abs/2309.07172)

    本文研究了大型语言模型在本体对齐中的应用，并发现它们有潜力在谨慎的框架和提示设计下超越现有的本体对齐系统。

    

    本文研究了最近的生成式大型语言模型（LLMs）（如GPT系列和Flan-T5）在本体对齐中的适用性，用于识别本体之间的概念等价映射。为了测试Flan-T5-XXL和GPT-3.5-turbo的零样本性能，我们利用了OAEI Bio-ML track的两个等价匹配数据集中具有挑战性的子集，并考虑到概念标签和结构上下文。初步结果表明，LLMs有可能在谨慎的框架和提示设计的情况下，胜过现有的本体对齐系统如BERTMap。

    This work investigates the applicability of recent generative Large Language Models (LLMs), such as the GPT series and Flan-T5, to ontology alignment for identifying concept equivalence mappings across ontologies. To test the zero-shot performance of Flan-T5-XXL and GPT-3.5-turbo, we leverage challenging subsets from two equivalence matching datasets of the OAEI Bio-ML track, taking into account concept labels and structural contexts. Preliminary findings suggest that LLMs have the potential to outperform existing ontology alignment systems like BERTMap, given careful framework and prompt design.
    
[^54]: 随机LLMs无法理解语言：走向符号化、可解释性和本体论基于的LLMs

    Stochastic LLMs do not Understand Language: Towards Symbolic, Explainable and Ontologically Based LLMs. (arXiv:2309.05918v1 [cs.CL])

    [http://arxiv.org/abs/2309.05918](http://arxiv.org/abs/2309.05918)

    随机LLMs无法理解语言的原因是它们无法提供可以依赖的事实信息，它们存储的语言知识埋藏在无意义的微特征中，并在某些语言上下文中无法进行正确推理。本文建议在符号化方法中应用有效的自下而上策略

    

    在我们看来，围绕数据驱动的大型语言模型（LLMs）相对成功的狂热是有些误导的，原因如下：（i）LLMs不能依赖于事实信息，因为对于LLMs来说，摄入的所有文本（事实或非事实）都是平等的；（ii）由于它们的亚符号性质，这些模型对语言的任何“知识”都将永远埋藏在数十亿个微特征（权重）中，其中没有一个本身是有意义的；以及（iii）LLMs在几种语言上下文中常常无法进行正确推理（如名词复合词、共谓词、量词范围模糊和意向性上下文）。我们相信，数据驱动的大型语言模型（LLMs）的相对成功不是符号与亚符号之辩的反映，而是在规模上应用自下而上的逆向工程语言的成功策略的反映。在本文中，我们建议将有效的自下而上策略应用于符号化方法中

    In our opinion the exuberance surrounding the relative success of data-driven large language models (LLMs) is slightly misguided and for several reasons (i) LLMs cannot be relied upon for factual information since for LLMs all ingested text (factual or non-factual) was created equal; (ii) due to their subsymbolic na-ture, whatever 'knowledge' these models acquire about language will always be buried in billions of microfeatures (weights), none of which is meaningful on its own; and (iii) LLMs will often fail to make the correct inferences in several linguistic contexts (e.g., nominal compounds, copredication, quantifier scope ambi-guities, intensional contexts. Since we believe the relative success of data-driven large language models (LLMs) is not a reflection on the symbolic vs. subsymbol-ic debate but a reflection on applying the successful strategy of a bottom-up reverse engineering of language at scale, we suggest in this paper applying the effective bottom-up strategy in a symbol
    
[^55]: 使用GPT模型从临床记录中提取社会决定因素和家族史的最小指导的零-shot学习

    Zero-shot Learning with Minimum Instruction to Extract Social Determinants and Family History from Clinical Notes using GPT Model. (arXiv:2309.05475v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.05475](http://arxiv.org/abs/2309.05475)

    本研究通过将最小信息提供给GPT模型，研究了零-shot学习在从临床记录中提取社会决定因素和家族史信息方面的应用，采用了两组评估指标来评估性能。

    

    越来越多的研究关注从电子健康记录中的非结构化文本中研究人口统计学数据、社会决定因素和家族史，以了解如何利用这些信息与结构化数据相结合来改善医疗结果。在GPT模型发布后，许多研究应用GPT模型从临床记录中提取这些信息。与现有工作不同，我们的研究聚焦于通过对GPT模型提供最小信息来研究零-shot学习在提取这些信息方面的应用。我们利用匿名化的真实临床记录注释的人口统计学数据、各种社会决定因素和家族史信息。考虑到GPT模型可能提供与原始数据中的文本不同的文本，我们探索了两组评估指标，包括传统的命名实体识别评估指标和语义相似度评估指标，以完全了解性能情况。

    Demographics, Social determinants of health, and family history documented in the unstructured text within the electronic health records are increasingly being studied to understand how this information can be utilized with the structured data to improve healthcare outcomes. After the GPT models were released, many studies have applied GPT models to extract this information from the narrative clinical notes. Different from the existing work, our research focuses on investigating the zero-shot learning on extracting this information together by providing minimum information to the GPT model. We utilize de-identified real-world clinical notes annotated for demographics, various social determinants, and family history information. Given that the GPT model might provide text different from the text in the original data, we explore two sets of evaluation metrics, including the traditional NER evaluation metrics and semantic similarity evaluation metrics, to completely understand the perform
    
[^56]: 美国：通用情感分析模型和构建日语情感文本分类和词性数据集

    USA: Universal Sentiment Analysis Model & Construction of Japanese Sentiment Text Classification and Part of Speech Dataset. (arXiv:2309.03787v1 [cs.CL])

    [http://arxiv.org/abs/2309.03787](http://arxiv.org/abs/2309.03787)

    本论文提出了一种通过利用单词和整个文本之间的互相增强效应来提高情感分析性能的通用情感分析模型，并构建了新的情感文本分类和词性数据集。该模型在实验中表现出超越gpt-3.5-t的性能。

    

    情感分析是自然语言处理领域的一个关键任务，它包括文本级情感极性分类和词级情感极性确定。这种分析挑战模型在全面理解文本的同时，提取细微的信息。随着大语言模型（LLM）的兴起，情感分析的新途径得以开展。本文提出通过利用单词和整个文本之间的互相增强效应（MRE）来提高性能。它深入探讨了单词极性对整个段落的情感的影响。为了支持我们的研究，我们标注了四个新颖的情感文本分类和词性（SCPOS）数据集，基于现有的情感分类数据集进行构建。此外，我们还开发了一个拥有70亿参数规模的通用情感分析（USA）模型。实验证实，我们的模型的性能超过了gpt-3.5-t。

    Sentiment analysis is a pivotal task in the domain of natural language processing. It encompasses both text-level sentiment polarity classification and word-level Part of Speech(POS) sentiment polarity determination. Such analysis challenges models to understand text holistically while also extracting nuanced information. With the rise of Large Language Models(LLMs), new avenues for sentiment analysis have opened. This paper proposes enhancing performance by leveraging the Mutual Reinforcement Effect(MRE) between individual words and the overall text. It delves into how word polarity influences the overarching sentiment of a passage. To support our research, we annotated four novel Sentiment Text Classification and Part of Speech(SCPOS) datasets, building upon existing sentiment classification datasets. Furthermore, we developed a Universal Sentiment Analysis(USA) model, with a 7-billion parameter size. Experimental results revealed that our model surpassed the performance of gpt-3.5-t
    
[^57]: 知识图谱嵌入用于多语言结构化表现的放射学报告

    Knowledge Graph Embeddings for Multi-Lingual Structured Representations of Radiology Reports. (arXiv:2309.00917v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.00917](http://arxiv.org/abs/2309.00917)

    本论文提出一种新颖的轻量级基于图的嵌入方法，用于对放射学报告进行多语言结构化表现。通过连接医学术语和多语言知识库，这种嵌入方法揭示了临床术语之间的关系，提供了对临床医生更易理解、临床更准确的表征。

    

    过去几年中，我们分析临床文本的方式发生了重大变化。语言模型（如BERT）的引入导致了针对（生物）医学领域的调整，如PubMedBERT和ClinicalBERT。这些模型依赖于大量存档的医学文档数据库。虽然在准确度方面表现良好，但解释能力的缺乏和跨语言转移的限制限制了它们在临床设置中的使用。我们引入了一种新颖的轻量级基于图的嵌入方法，专门针对放射学报告。它考虑了报告的结构和组成，同时通过多语言SNOMED临床术语知识库连接报告中的医学术语。生成的图嵌入揭示出临床术语之间的潜在关系，实现了对临床医生更易理解、临床更准确的表征，而不依赖于大规模的预训练数据集。我们展示了这种嵌入的使用。

    The way we analyse clinical texts has undergone major changes over the last years. The introduction of language models such as BERT led to adaptations for the (bio)medical domain like PubMedBERT and ClinicalBERT. These models rely on large databases of archived medical documents. While performing well in terms of accuracy, both the lack of interpretability and limitations to transfer across languages limit their use in clinical setting. We introduce a novel light-weight graph-based embedding method specifically catering radiology reports. It takes into account the structure and composition of the report, while also connecting medical terms in the report through the multi-lingual SNOMED Clinical Terms knowledge base. The resulting graph embedding uncovers the underlying relationships among clinical terms, achieving a representation that is better understandable for clinicians and clinically more accurate, without reliance on large pre-training datasets. We show the use of this embedding
    
[^58]: Qwen-VL: 一种具有多功能能力的前沿大规模视觉-语言模型

    Qwen-VL: A Frontier Large Vision-Language Model with Versatile Abilities. (arXiv:2308.12966v1 [cs.CV])

    [http://arxiv.org/abs/2308.12966](http://arxiv.org/abs/2308.12966)

    Qwen-VL是一种具有多功能能力的前沿大规模视觉-语言模型，它在图像字幕生成、问题回答、视觉定位和灵活交互等任务中表现出卓越性能，优于现有的大规模视觉-语言模型。它在推动多模态人工智能方面做出了重要贡献。

    

    我们引入了一系列名为Qwen-VL的大规模视觉-语言模型，旨在感知和理解文本和图像。包括Qwen-VL和Qwen-VL-Chat，这些模型在图像字幕生成、问题回答、视觉定位和灵活交互等任务中表现出卓越的性能。评估范围涵盖了零样本字幕生成、视觉或文档视觉问题回答和 grounding 等各种任务。我们证明了Qwen-VL比现有的大规模视觉-语言模型（LVLMs）表现更优异。我们展示了它们的架构、训练方法、能力和性能，并突出了它们在推动多模态人工智能方面的贡献。代码、演示和模型可以在https://github.com/QwenLM/Qwen-VL找到。

    We introduce the Qwen-VL series, a set of large-scale vision-language models designed to perceive and understand both text and images. Comprising Qwen-VL and Qwen-VL-Chat, these models exhibit remarkable performance in tasks like image captioning, question answering, visual localization, and flexible interaction. The evaluation covers a wide range of tasks including zero-shot captioning, visual or document visual question answering, and grounding. We demonstrate the Qwen-VL outperforms existing Large Vision Language Models (LVLMs). We present their architecture, training, capabilities, and performance, highlighting their contributions to advancing multimodal artificial intelligence. Code, demo and models are available at https://github.com/QwenLM/Qwen-VL.
    
[^59]: Halo：评估和降低开源弱大语言模型中的幻觉

    Halo: Estimation and Reduction of Hallucinations in Open-Source Weak Large Language Models. (arXiv:2308.11764v1 [cs.CL])

    [http://arxiv.org/abs/2308.11764](http://arxiv.org/abs/2308.11764)

    本文介绍了一种用于评估和减少开源弱大语言模型中幻觉问题的框架，并探索了知识注入和师生方法等技术来减轻低参数模型中的幻觉问题，实验结果表明，在挑战性领域中，这些模型的幻觉问题得到了减少。

    

    大型语言模型(LLMs)已经彻底改变了自然语言处理(NLP)领域。虽然对于研究和实际应用来说方便，但是与其更大规模的对应模型相比，开源的参数较少的LLMs经常出现严重幻觉问题。本文着重于测量和减少BLOOM 7B中的幻觉问题，该模型是公开提供给研究和商业应用的弱开源LLMs的代表。我们引入了HaloCheck，一种轻量级的无需知识的黑盒子框架，用于量化LLMs中幻觉问题的严重程度。此外，我们探索了知识注入和师生方法等技术，以减轻低参数LLMs中的幻觉问题。我们的实验证明了在这些LLMs的挑战性领域中幻觉问题的减少。

    Large Language Models (LLMs) have revolutionized Natural Language Processing (NLP). Although convenient for research and practical applications, open-source LLMs with fewer parameters often suffer from severe hallucinations compared to their larger counterparts. This paper focuses on measuring and reducing hallucinations in BLOOM 7B, a representative of such weaker open-source LLMs that are publicly available for research and commercial applications. We introduce HaloCheck, a lightweight BlackBox knowledge-free framework designed to quantify the severity of hallucinations in LLMs. Additionally, we explore techniques like knowledge injection and teacher-student approaches to alleviate hallucinations in low-parameter LLMs. Our experiments effectively demonstrate the reduction of hallucinations in challenging domains for these LLMs.
    
[^60]: YORC：约鲁巴语阅读理解数据集

    YORC: Yoruba Reading Comprehension dataset. (arXiv:2308.09768v1 [cs.CL])

    [http://arxiv.org/abs/2308.09768](http://arxiv.org/abs/2308.09768)

    本文介绍了一个新的多项选择约鲁巴语阅读理解数据集YORC，通过跨语言转移和大型语言模型的使用，提供了该数据集的基准结果和更高层次的结果。

    

    本文介绍了YORC：一个基于约鲁巴语高中阅读理解考试的新的多项选择约鲁巴语阅读理解数据集。我们使用已训练的仅编码器模型，通过跨语言转移来提供基准结果，同时还使用大型语言模型（LLMs）如GPT-4提供了结果。

    In this paper, we create YORC: a new multi-choice Yoruba Reading Comprehension dataset that is based on Yoruba high-school reading comprehension examination. We provide baseline results by performing cross-lingual transfer using existing English RACE dataset based on a pre-trained encoder-only model. Additionally, we provide results by prompting large language models (LLMs) like GPT-4.
    
[^61]: 同卵和异卵双胞胎：句子表示的细粒度语义对比学习

    Identical and Fraternal Twins: Fine-Grained Semantic Contrastive Learning of Sentence Representations. (arXiv:2307.10932v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.10932](http://arxiv.org/abs/2307.10932)

    本文提出了一种名为同卵和异卵对比学习（IFTCL）框架，通过同时适应不同的正样本对生成方式，在无监督学习句子表示中解决了对比学习中存在的语义扭曲和语义间隔问题。

    

    利用对比学习显著提高了无监督学习句子表示的效果。该方法通过将正样本与锚定样本聚类来创建所需的嵌入空间。然而，仅仅依靠对比目标可能会导致次优结果，因为它无法区分正样本对之间的微小语义变化。具体而言，常见的数据增强技术经常引入语义扭曲，导致正样本对之间存在语义间隔。虽然InfoNCE损失函数忽略了语义间隔，并在训练期间优先考虑正样本对之间的相似性最大化，从而导致训练模型的语义理解能力不敏感。本文介绍了一种新颖的同卵和异卵对比学习（称为IFTCL）框架，能够同时适应不同的正样本对生成方式。

    The enhancement of unsupervised learning of sentence representations has been significantly achieved by the utility of contrastive learning. This approach clusters the augmented positive instance with the anchor instance to create a desired embedding space. However, relying solely on the contrastive objective can result in sub-optimal outcomes due to its inability to differentiate subtle semantic variations between positive pairs. Specifically, common data augmentation techniques frequently introduce semantic distortion, leading to a semantic margin between the positive pair. While the InfoNCE loss function overlooks the semantic margin and prioritizes similarity maximization between positive pairs during training, leading to the insensitive semantic comprehension ability of the trained model. In this paper, we introduce a novel Identical and Fraternal Twins of Contrastive Learning (named IFTCL) framework, capable of simultaneously adapting to various positive pairs generated by differ
    
[^62]: TIM: 使用对比教授大型语言模型进行翻译

    TIM: Teaching Large Language Models to Translate with Comparison. (arXiv:2307.04408v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.04408](http://arxiv.org/abs/2307.04408)

    我们提出了一个使用对比教授大型语言模型进行翻译的新框架，通过向模型呈现正确和错误翻译的示例并使用偏好损失来指导模型学习，我们证明该方法优于现有方法，在精调LLMs用于翻译任务方面提供了新的视角。

    

    开源的大型语言模型（LLMs）在通过指令调整方面展示了出色的效果。然而，这些模型在需要更专业知识的任务（如翻译）中有时会遇到困难。这种不足的可能原因之一是指令调整旨在生成流畅、连贯的文本，而不受任何任务特定要求的限制。此外，调整较小的LLM并使用较低质量的训练数据可能更具挑战性。为了解决这个问题，我们提出了一个使用例子进行对比教授LLMs学习翻译的新框架。我们的方法涉及向模型呈现正确和错误翻译的示例，并使用偏好损失来指导模型的学习。我们在WMT2022测试集上评估了我们的方法，并证明其优于现有方法。我们的发现为精调LLMs用于翻译任务提供了新的视角。

    Open-sourced large language models (LLMs) have demonstrated remarkable efficacy in various tasks with instruction tuning. However, these models can sometimes struggle with tasks that require more specialized knowledge such as translation. One possible reason for such deficiency is that instruction tuning aims to generate fluent and coherent text that continues from a given instruction without being constrained by any task-specific requirements. Moreover, it can be more challenging for tuning smaller LLMs with lower-quality training data. To address this issue, we propose a novel framework using examples in comparison to teach LLMs to learn translation. Our approach involves presenting the model with examples of correct and incorrect translations and using a preference loss to guide the model's learning. We evaluate our method on WMT2022 test sets and show that it outperforms existing methods. Our findings offer a new perspective on fine-tuning LLMs for translation tasks and provide a p
    
[^63]: 大型语言模型中的人格特质

    Personality Traits in Large Language Models. (arXiv:2307.00184v1 [cs.CL])

    [http://arxiv.org/abs/2307.00184](http://arxiv.org/abs/2307.00184)

    该研究介绍了一种综合方法，用于验证大型语言模型（LLMs）生成的文本中展示的人格特质。研究发现，部分LLMs在特定提示配置下模拟的人格可靠且有效，特别是对于更大和经过指导微调的模型。此外，LLMs的输出中的人格特质可以根据需要进行塑造。

    

    大型语言模型（LLMs）的出现彻底改变了自然语言处理，使得能够生成连贯且上下文相关的文本。随着LLMs越来越多地用于驱动对话代理，这些模型通过训练大量人工生成的数据获得的人格特质引起了人们的关注。由于人格是决定交流效果的重要因素，我们提出了一种全面的方法来进行验证的心理测量测试，并对从广泛使用的LLMs生成的文本中展示的人格特质进行量化、分析和塑造。我们发现：1）某些LLMs的输出中模拟的人格（在特定的提示配置下）是可靠和有效的；2）LLM模拟的人格的可靠性和有效性的证据对于更大的和经过指导微调的模型更强；3）LLM输出中的人格可以根据需要的维度进行塑造，以模仿特定的人格特点。

    The advent of large language models (LLMs) has revolutionized natural language processing, enabling the generation of coherent and contextually relevant text. As LLMs increasingly power conversational agents, the synthesized personality embedded in these models by virtue of their training on large amounts of human-generated data draws attention. Since personality is an important factor determining the effectiveness of communication, we present a comprehensive method for administering validated psychometric tests and quantifying, analyzing, and shaping personality traits exhibited in text generated from widely-used LLMs. We find that: 1) personality simulated in the outputs of some LLMs (under specific prompting configurations) is reliable and valid; 2) evidence of reliability and validity of LLM-simulated personality is stronger for larger and instruction fine-tuned models; and 3) personality in LLM outputs can be shaped along desired dimensions to mimic specific personality profiles. 
    
[^64]: 为开发领域特定自然语言处理应用而进行的生成式用户体验研究

    Generative User-Experience Research for Developing Domain-specific Natural Language Processing Applications. (arXiv:2306.16143v1 [cs.CL])

    [http://arxiv.org/abs/2306.16143](http://arxiv.org/abs/2306.16143)

    本论文提出了一种在开发领域特定自然语言处理应用中整合生成式用户体验研究的方法。该方法将领域用户纳入原型开发的不同阶段，以更好地了解用户需求和评估用户价值的变化。

    

    用户体验（UX）是人机交互（HCI）研究的一部分，专注于提高系统用户的直观性、透明度、简洁性和信任度。大多数针对机器学习（ML）或自然语言处理（NLP）的UX研究都采用数据驱动的方法，即没有关注用户需求，并仅仅将领域用户用于可用性评估。此外，更典型的UX方法是先针对用户的可用性进行定制，而不是首先了解用户需求。本文提出了一种将生成式UX研究整合到开发领域NLP应用中的方法。生成式UX研究将领域用户纳入原型开发的初始阶段，即构思和概念评估阶段，以及最后一阶段评估用户价值的变化。案例研究中，我们报道了一个针对过程工业中日常操作的领域特定语义搜索的完整原型开发过程。

    User experience (UX) is a part of human-computer interaction (HCI) research and focuses on increasing intuitiveness, transparency, simplicity, and trust for system users. Most of the UX research for machine learning (ML) or natural language processing (NLP) focuses on a data-driven methodology, i.e., it fails to focus on users' requirements, and engages domain users mainly for usability evaluation. Moreover, more typical UX methods tailor the systems towards user usability, unlike learning about the user needs first. The paper proposes a methodology for integrating generative UX research into developing domain NLP applications. Generative UX research employs domain users at the initial stages of prototype development, i.e., ideation and concept evaluation, and the last stage for evaluating the change in user value. In the case study, we report the full-cycle prototype development of a domain-specific semantic search for daily operations in the process industry. Our case study shows tha
    
[^65]: 通过强化指令调整来减轻大规模多模态模型中的幻觉问题

    Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning. (arXiv:2306.14565v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.14565](http://arxiv.org/abs/2306.14565)

    本论文通过引入第一个大型多样化的视觉指令调整数据集，提出了一种解决大规模多模态模型中幻觉问题的方法。通过设计包含正负指令的数据集和提出的评估方法，能够更准确地衡量模型产生的幻觉。

    

    尽管多模态任务取得了可喜的进展，但当前的大规模多模态模型（LMM）很容易在描述图像和人类指令时产生不一致的幻觉。本文通过引入第一个大型多样化的视觉指令调整数据集LRV-Instruction来解决这个问题。我们的数据集包含由GPT4生成的12万个视觉指令，涵盖了16个开放式指令和答案的视觉与语言任务。与现有研究主要关注正指令样本不同，我们设计了LRV-Instruction以包含更多针对更强的视觉指令调整的正负指令。我们的负指令在两个语义层次上设计：（i）不存在元素操作和（ii）存在元素操作。为了更有效地衡量LMM所产生的幻觉，我们提出了一种新的方法，即GPT4辅助的视觉指令评估（GAVIE）。

    Despite the promising progress in multi-modal tasks, current large multi-modal models (LMM) are prone to hallucinating inconsistent descriptions with respect to the associated image and human instructions. This paper addresses this issue by introducing the first large and diverse visual instruction tuning dataset, named Large-scale Robust Visual (LRV)-Instruction. Our dataset consists of 120k visual instructions generated by GPT4, covering 16 vision-and-language tasks with open-ended instructions and answers. Unlike existing studies that primarily focus on positive instruction samples, we design LRV-Instruction to include both positive and negative instructions for more robust visual instruction tuning. Our negative instructions are designed at two semantic levels: (i) Nonexistent Element Manipulation and (ii) Existent Element Manipulation. To efficiently measure the hallucination generated by LMMs, we propose GPT4-Assisted Visual Instruction Evaluation (GAVIE), a novel approach to eva
    
[^66]: DSTC 11 Track 4中用于开放域对话系统的鲁棒性和多语言自动评估度量的综述

    Overview of Robust and Multilingual Automatic Evaluation Metrics for Open-Domain Dialogue Systems at DSTC 11 Track 4. (arXiv:2306.12794v1 [cs.CL])

    [http://arxiv.org/abs/2306.12794](http://arxiv.org/abs/2306.12794)

    本文综述了DSTC 11 Track 4中针对开放域对话系统进行鲁棒性和多语言自动评估的挑战，介绍了提供给参与者的数据集和基线，并总结了表现最佳的系统及其方法。

    

    神经网络的出现和快速发展已经彻底改变了对话系统的研究，并随之引发了关于其自动评估的各种挑战。开放域对话系统的自动评估作为一个开放性挑战已经引起了许多研究人员的关注。尽管一直在努力提高自动评估度量与人类评估的相关性，但很少有尝试评估它们在多个领域和维度上的鲁棒性，而且它们的重点主要集中于英语语言上。所有这些挑战促进了开发可靠的自动评估度量，在各种领域、维度和语言中都能够使用。DSTC11中的这个轨道是促进鲁棒和多语言自动评估度量的持续努力的一部分。本文介绍了提供给参与者的数据集和基线，并讨论了该轨道的提交和结果细节。本文还总结了表现最佳的系统及其方法。

    The advent and fast development of neural networks have revolutionized the research on dialogue systems and subsequently have triggered various challenges regarding their automatic evaluation. Automatic evaluation of open-domain dialogue systems as an open challenge has been the center of the attention of many researchers. Despite the consistent efforts to improve automatic metrics' correlations with human evaluation, there have been very few attempts to assess their robustness over multiple domains and dimensions. Also, their focus is mainly on the English language. All of these challenges prompt the development of automatic evaluation metrics that are reliable in various domains, dimensions, and languages. This track in the 11th Dialogue System Technology Challenge (DSTC11) is part of the ongoing effort to promote robust and multilingual automatic evaluation metrics. This article describes the datasets and baselines provided to participants and discusses the submission and result det
    
[^67]: COVER：一种启发式贪心对抗攻击预训练语言模型中的基于提示学习

    COVER: A Heuristic Greedy Adversarial Attack on Prompt-based Learning in Language Models. (arXiv:2306.05659v1 [cs.CL])

    [http://arxiv.org/abs/2306.05659](http://arxiv.org/abs/2306.05659)

    本文提出了一种启发式贪心对抗攻击，针对基于提示的模板在PLMs中可能存在的漏洞，通过字符级和单词级的破坏方法进行攻击，取得了较高的攻击成功率。

    

    基于提示的学习已被证明是预训练语言模型（PLMs）中一种有效的方式，特别是在像少量样本场景这样的低资源情况下。然而，PLMs的可信度至关重要，并且在基于模板的提示中已经显示出了潜在的漏洞，可能会误导语言模型的预测，引起严重的安全问题。本文通过在黑盒场景中提出基于提示的对抗攻击手段，揭示了PLMs的一些漏洞。首先，我们设计了字符级别和单词级别的启发式方法来破坏手动模板。然后，我们基于上述启发式破坏方法提出了一种贪心算法进行攻击。最后，我们使用BERT系列模型的三个变种和八个数据集的分类任务评估了我们的方法。广泛的实验结果证明了我们的方法在攻击成功率方面的有效性。

    Prompt-based learning has been proved to be an effective way in pre-trained language models (PLMs), especially in low-resource scenarios like few-shot settings. However, the trustworthiness of PLMs is of paramount significance and potential vulnerabilities have been shown in prompt-based templates that could mislead the predictions of language models, causing serious security concerns. In this paper, we will shed light on some vulnerabilities of PLMs, by proposing a prompt-based adversarial attack on manual templates in black box scenarios. First of all, we design character-level and word-level heuristic approaches to break manual templates separately. Then we present a greedy algorithm for the attack based on the above heuristic destructive approaches. Finally, we evaluate our approach with the classification tasks on three variants of BERT series models and eight datasets. And comprehensive experimental results justify the effectiveness of our approach in terms of attack success rate
    
[^68]: 学习地球科学知识理解和利用的基础语言模型

    Learning A Foundation Language Model for Geoscience Knowledge Understanding and Utilization. (arXiv:2306.05064v1 [cs.CL])

    [http://arxiv.org/abs/2306.05064](http://arxiv.org/abs/2306.05064)

    本文首次提出了一个地球科学领域的大型语言模型K2，并开发了各种资源以进一步促进其在地球科学领域中的研究和应用，包括第一个地球科学教学调音数据集GeoSignal和第一个地球科学基准测试GeoBenchmark。我们使用了完整的方法将预先训练的通用领域LLM LLaMA-7B 模型适应到地球科学领域。

    

    大型语言模型(LLM)在自然语言处理的常规领域取得了巨大成功。本文将LLM引入地球科学领域，旨在推进该领域的研究和应用。为此，我们首次提出了地球科学领域的LLM，命名为K2，并开发了一系列资源，以进一步促进LLM在地球科学研究中的应用。例如，我们为LLM提供了第一个地球科学教学调音数据集GeoSignal，旨在将LLM相应与地球科学相关的用户查询对齐。此外，我们还建立了第一个地质科学基准测试GeoBenchmark，以在地球科学环境中评估LLM。在这项工作中，我们尝试使用完整的方法将预先训练的通用领域LLM适应到地球科学领域。具体而言，我们在超过100万篇地球科学文献上进一步训练了LLaMA-7B模型，并利用GeoSignal的监督数据对模型进行微调。此外，我们还分享了一个可以在不同领域中迁移LLM的协议。

    Large language models (LLMs)have achieved great success in general domains of natural language processing. In this paper, we bring LLMs to the realm of geoscience, with the objective of advancing research and applications in this field. To this end, we present the first-ever LLM in geoscience, K2, alongside a suite of resources developed to further promote LLM research within geoscience. For instance, we have curated the first geoscience instruction tuning dataset, GeoSignal, which aims to align LLM responses to geoscience-related user queries. Additionally, we have established the first geoscience benchmark, GeoBenchmark, to evaluate LLMs in the context of geoscience. In this work, we experiment with a complete recipe to adapt a pretrained general-domain LLM to the geoscience domain. Specifically, we further train the LLaMA-7B model on over 1 million pieces of geoscience literature and utilize GeoSignal's supervised data to fine-tune the model. Moreover, we share a protocol that can e
    
[^69]: 在上下文中的探测：通过对大型语言模型的探测构建鲁棒的分类器

    Probing in Context: Toward Building Robust Classifiers via Probing Large Language Models. (arXiv:2305.14171v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.14171](http://arxiv.org/abs/2305.14171)

    本文提出了一种在上下文中的探测方法，用于构建鲁棒的分类器。通过探测上下文化的表示来预测标签，这种方法对指令变化更加鲁棒，并且在多样化的分类任务上表现出竞争力或更好的性能。

    

    大型语言模型能够在上下文中学习新任务，在提供指令和少量注释示例的情况下。然而，上下文学习的有效性取决于提供的上下文，并且下游任务的性能可能会有很大变化，取决于指令。重要的是，这种对上下文的依赖可能以不可预测的方式表现，例如，一个看似更有信息量的指令可能导致性能更差。在本文中，我们提出了一种替代方法，称之为上下文中的探测。类似于上下文学习，我们用指令对输入的表示进行上下文化，但是我们不是解码输出预测，而是探测上下文化的表示来预测标签。通过一系列在多样化的分类任务上的实验，我们展示了上下文中的探测对指令变化更加鲁棒。我们进一步展示了探测的性能与其他方法相竞争或更胜一筹。

    Large language models are able to learn new tasks in context, where they are provided with instructions and a few annotated examples. However, the effectiveness of in-context learning is dependent on the provided context, and the performance on a downstream task can vary considerably, depending on the instruction. Importantly, such dependency on the context can surface in unpredictable ways, e.g., a seemingly more informative instruction might lead to a worse performance. In this paper, we propose an alternative approach, which we term in-context probing. Similar to in-context learning, we contextualize the representation of the input with an instruction, but instead of decoding the output prediction, we probe the contextualized representation to predict the label. Through a series of experiments on a diverse set of classification tasks, we show that in-context probing is significantly more robust to changes in instructions. We further show that probing performs competitive or superior
    
[^70]: PaLM 2 技术报告

    PaLM 2 Technical Report. (arXiv:2305.10403v1 [cs.CL])

    [http://arxiv.org/abs/2305.10403](http://arxiv.org/abs/2305.10403)

    PaLM 2 是一种计算效率更高的最先进的语言模型，提供了更好的多语言和推理能力，并且通过使用多种目标进行训练，获得了在不同模型大小的下游任务上显着的改进质量。此外，PaLM 2 还展示了强大的推理能力和稳定的性能表现，使得模型能够更广泛地部署，并且可以控制毒性推理时间，而不会对其他能力产生影响。

    

    我们介绍了 PaLM 2，这是一种新的最先进的语言模型，比其前身 PaLM 在多语言和推理能力方面更加出色，并且计算效率更高。PaLM 2 是一种基于 Transformer 的模型，使用多种目标进行训练。通过对英语和多语言语言以及推理任务的广泛评估，我们展示了 PaLM 2 在不同模型大小的下游任务上具有显着的改进质量，同时展现了比 PaLM 更快和更有效的推理能力。这种改进的效率使得模型能够更广泛地部署，同时也使得模型能够更快地响应，以获得更自然的交互节奏。PaLM 2 展示了强大的推理能力，在 BIG-Bench 和其他推理任务上相对于 PaLM 有巨大的改进。PaLM 2 在一套负责人的 AI 评估中表现出稳定的性能，并且在没有附加运行开销或对其他能力产生影响的情况下，能够对毒性进行推理时间的控制。

    We introduce PaLM 2, a new state-of-the-art language model that has better multilingual and reasoning capabilities and is more compute-efficient than its predecessor PaLM. PaLM 2 is a Transformer-based model trained using a mixture of objectives. Through extensive evaluations on English and multilingual language, and reasoning tasks, we demonstrate that PaLM 2 has significantly improved quality on downstream tasks across different model sizes, while simultaneously exhibiting faster and more efficient inference compared to PaLM. This improved efficiency enables broader deployment while also allowing the model to respond faster, for a more natural pace of interaction. PaLM 2 demonstrates robust reasoning capabilities exemplified by large improvements over PaLM on BIG-Bench and other reasoning tasks. PaLM 2 exhibits stable performance on a suite of responsible AI evaluations, and enables inference-time control over toxicity without additional overhead or impact on other capabilities. Over
    
[^71]: 大规模语言模型中潜在空间理论对应新兴能力

    A Latent Space Theory for Emergent Abilities in Large Language Models. (arXiv:2304.09960v1 [cs.CL])

    [http://arxiv.org/abs/2304.09960](http://arxiv.org/abs/2304.09960)

    本文探讨了大规模语言模型中的贝叶斯推断和稀疏联合分布，证明了LLMs能够完成语言理解、上下文学习、思路启发以及有效指令微调的新兴能力。

    

    语言并不是随机生成，而是为了传递信息。语言与其底层含义之间存在强烈的关联，在其相关性方面有着严重偏差的稀疏联合分布。此外，由于稀疏性，这些高峰值恰好与语言的边缘分布匹配。随着大数据和大模型上训练的LLMs的出现，我们现在可以精确评估语言的边缘分布，这提供了一种方便的探索联合分布稀疏结构实现有效推理的方式。在本文中，我们将语言分类为明确与{\epsilon}-模糊，并提出定量结果，以表明LLMs的新兴能力（例如语言理解、上下文学习、思路启发以及有效指令微调）都可以归因于对稀疏联合分布进行贝叶斯推断。

    Languages are not created randomly but rather to communicate information. There is a strong association between languages and their underlying meanings, resulting in a sparse joint distribution that is heavily peaked according to their correlations. Moreover, these peak values happen to match with the marginal distribution of languages due to the sparsity. With the advent of LLMs trained on big data and large models, we can now precisely assess the marginal distribution of languages, providing a convenient means of exploring the sparse structures in the joint distribution for effective inferences. In this paper, we categorize languages as either unambiguous or {\epsilon}-ambiguous and present quantitative results to demonstrate that the emergent abilities of LLMs, such as language understanding, in-context learning, chain-of-thought prompting, and effective instruction fine-tuning, can all be attributed to Bayesian inference on the sparse joint distribution of languages.
    
[^72]: MER 2023: 多标签学习，模态鲁棒性和半监督学习

    MER 2023: Multi-label Learning, Modality Robustness, and Semi-Supervised Learning. (arXiv:2304.08981v1 [cs.CL])

    [http://arxiv.org/abs/2304.08981](http://arxiv.org/abs/2304.08981)

    多模态情感识别挑战赛（MER 2023）提出了三个子挑战：MER-MULTI、MER-NOISE和MER-SEMI，为全球研究人员构建创新技术提供了激励，并测试了各种多模态特征，提供了有竞争力的基线，以促进鲁棒而有效的算法的发展和应用。

    

    在过去的几十年中，深度学习的发展使得多模态情感识别取得了显着进展。然而，现有技术难以满足实际应用的需求。为了提高鲁棒性，我们发起了多模态情感识别挑战赛（MER 2023），以激励全球研究人员构建创新技术，进一步加速和促进研究。针对今年的挑战赛，我们提出了三个不同的子挑战：（1）MER-MULTI，参赛者需要识别离散和维度情感；（2）MER-NOISE，在测试视频中添加噪声，以评估模态鲁棒性；（3）MER-SEMI，提供大量未标记的样本，用于半监督学习。在本文中，我们测试了各种多模态特征，并为每个子挑战提供了有竞争力的基线。我们的系统在MER-MULTI上获得了77.57％的F1分数和0.82的均方误差（MSE），在MER-NOISE上获得了69.82％的F1分数和0.75的MSE，在MER-SEMI上获得了69.39％的F1分数和0.80的MSE。我们希望这个挑战赛能够激发更多的研究人员探索多模态情感识别，并促进鲁棒而有效的算法用于实际应用。

    Over the past few decades, multimodal emotion recognition has made remarkable progress with the development of deep learning. However, existing technologies are difficult to meet the demand for practical applications. To improve the robustness, we launch a Multimodal Emotion Recognition Challenge (MER 2023) to motivate global researchers to build innovative technologies that can further accelerate and foster research. For this year's challenge, we present three distinct sub-challenges: (1) MER-MULTI, in which participants recognize both discrete and dimensional emotions; (2) MER-NOISE, in which noise is added to test videos for modality robustness evaluation; (3) MER-SEMI, which provides large amounts of unlabeled samples for semi-supervised learning. In this paper, we test a variety of multimodal features and provide a competitive baseline for each sub-challenge. Our system achieves 77.57% on the F1 score and 0.82 on the mean squared error (MSE) for MER-MULTI, 69.82% on the F1 score a
    
[^73]: 使用语言模型提示进行推理：一项调查

    Reasoning with Language Model Prompting: A Survey. (arXiv:2212.09597v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09597](http://arxiv.org/abs/2212.09597)

    本文提供了使用语言模型提示进行推理的前沿研究综合调查。讨论了新兴推理能力出现的潜在原因，并提供系统资源帮助初学者。

    

    推理作为复杂问题解决的重要能力，可以为医疗诊断、谈判等各种实际应用提供后端支持。本文对使用语言模型提示进行推理的前沿研究进行了综合调查。我们介绍了研究成果的比较和总结，并提供了系统资源以帮助初学者。我们还讨论了新兴推理能力出现的潜在原因，并突出了未来的研究方向。资源可在 https://github.com/zjunlp/Prompt4ReasoningPapers 上获取（定期更新）。

    Reasoning, as an essential ability for complex problem-solving, can provide back-end support for various real-world applications, such as medical diagnosis, negotiation, etc. This paper provides a comprehensive survey of cutting-edge research on reasoning with language model prompting. We introduce research works with comparisons and summaries and provide systematic resources to help beginners. We also discuss the potential reasons for emerging such reasoning abilities and highlight future research directions. Resources are available at https://github.com/zjunlp/Prompt4ReasoningPapers (updated periodically).
    
[^74]: LambdaKG:基于预训练语言模型的知识图谱嵌入库

    LambdaKG: A Library for Pre-trained Language Model-Based Knowledge Graph Embeddings. (arXiv:2210.00305v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.00305](http://arxiv.org/abs/2210.00305)

    LambdaKG是一个基于预训练语言模型的知识图谱嵌入库，提供了多个预训练语言模型和支持多种任务，如知识图谱补全、问答、推荐和知识探索。

    

    知识图谱（KG）通常具有异构的图结构和文本丰富的实体/关系信息。基于文本的KG嵌入可以通过使用预训练语言模型对描述进行编码来表示实体，但目前尚无专门为PLM与KG设计的开源库。本文介绍了LambdaKG，一个带有多个预训练语言模型（如BERT，BART，T5，GPT-3）并支持各种任务（如知识图谱补全，问答，推荐和知识探索）的KGE库。LambdaKG在https://github.com/zjunlp/PromptKG/tree/main/lambdaKG上公开开源，并提供了演示视频和长期维护。

    Knowledge Graphs (KGs) often have two characteristics: heterogeneous graph structure and text-rich entity/relation information. Text-based KG embeddings can represent entities by encoding descriptions with pre-trained language models, but no open-sourced library is specifically designed for KGs with PLMs at present. In this paper, we present LambdaKG, a library for KGE that equips with many pre-trained language models (e.g., BERT, BART, T5, GPT-3), and supports various tasks (e.g., knowledge graph completion, question answering, recommendation, and knowledge probing). LambdaKG is publicly open-sourced at https://github.com/zjunlp/PromptKG/tree/main/lambdaKG, with a demo video at this http URL and long-term maintenance.
    
[^75]: SPARQL语义解析的现代基准模型

    Modern Baselines for SPARQL Semantic Parsing. (arXiv:2204.12793v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2204.12793](http://arxiv.org/abs/2204.12793)

    本文探讨了从自然语言问题生成SPARQL查询的任务，使用预训练语言模型作为新的基准模型，并在DBpedia和Wikidata知识图谱上进行了实验。我们展示了T5模型在LC-QuAD 1.0和LC-QuAD 2.0数据集上表现出最先进的性能，并且能够解析需要将一部分输入复制到输出查询中的问题，这为知识图谱语义解析带来了新的可能性。

    

    本文关注于从自然语言问题生成SPARQL查询的任务，这些查询可以在知识图谱上执行。我们假设已经提供了黄金实体和关系，剩下的任务是将它们与SPARQL词汇和输入标记一起按正确的顺序排列，以生成正确的SPARQL查询。到目前为止，预训练语言模型（PLMs）在这个任务上尚未深入研究，因此我们尝试了使用BART、T5和PGNs（指针生成网络）与BERT嵌入来寻找这个任务在PLM时代的新基准，在DBpedia和Wikidata知识图谱上进行了实验。我们展示了T5需要特殊的输入标记化，但在LC-QuAD 1.0和LC-QuAD 2.0数据集上表现出最先进的性能，并超过了以前工作中的任务特定模型。此外，这些方法使得对问题进行语义解析成为可能，其中输入的一部分需要复制到输出查询中，从而实现了知识图谱语义解析的新范式。

    In this work, we focus on the task of generating SPARQL queries from natural language questions, which can then be executed on Knowledge Graphs (KGs). We assume that gold entity and relations have been provided, and the remaining task is to arrange them in the right order along with SPARQL vocabulary, and input tokens to produce the correct SPARQL query. Pre-trained Language Models (PLMs) have not been explored in depth on this task so far, so we experiment with BART, T5 and PGNs (Pointer Generator Networks) with BERT embeddings, looking for new baselines in the PLM era for this task, on DBpedia and Wikidata KGs. We show that T5 requires special input tokenisation, but produces state of the art performance on LC-QuAD 1.0 and LC-QuAD 2.0 datasets, and outperforms task-specific models from previous works. Moreover, the methods enable semantic parsing for questions where a part of the input needs to be copied to the output query, thus enabling a new paradigm in KG semantic parsing.
    

