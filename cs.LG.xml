<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20122;&#32447;&#24615;&#26102;&#38388;&#30340;&#35889;&#32858;&#31867;&#39044;&#27979;&#22120;&#65292;&#29992;&#20110;&#22788;&#29702;&#20855;&#26377;&#24378;&#32858;&#31867;&#29305;&#24615;&#30340;&#22270;&#12290;&#35813;&#39044;&#27979;&#22120;&#33021;&#22815;&#22312;&#20122;&#32447;&#24615;&#26102;&#38388;&#20869;&#36827;&#34892;&#39044;&#22788;&#29702;&#21644;&#26597;&#35810;&#32858;&#31867;&#25104;&#21592;&#65292;&#24182;&#19988;&#19982;&#30495;&#23454;&#32858;&#31867;&#25509;&#36817;&#30340;k-&#20998;&#21306;&#20445;&#25345;&#19968;&#33268;&#12290;&#27492;&#22806;&#65292;&#35813;&#39044;&#27979;&#22120;&#23545;&#20110;&#23569;&#37327;&#30340;&#38543;&#26426;&#36793;&#21024;&#38500;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.17878</link><description>&lt;p&gt;
&#19968;&#31181;&#20855;&#26377;&#25913;&#36827;&#39044;&#22788;&#29702;&#26102;&#38388;&#30340;&#20122;&#32447;&#24615;&#26102;&#38388;&#35889;&#32858;&#31867;&#39044;&#27979;&#22120;
&lt;/p&gt;
&lt;p&gt;
A Sublinear-Time Spectral Clustering Oracle with Improved Preprocessing Time. (arXiv:2310.17878v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17878
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20122;&#32447;&#24615;&#26102;&#38388;&#30340;&#35889;&#32858;&#31867;&#39044;&#27979;&#22120;&#65292;&#29992;&#20110;&#22788;&#29702;&#20855;&#26377;&#24378;&#32858;&#31867;&#29305;&#24615;&#30340;&#22270;&#12290;&#35813;&#39044;&#27979;&#22120;&#33021;&#22815;&#22312;&#20122;&#32447;&#24615;&#26102;&#38388;&#20869;&#36827;&#34892;&#39044;&#22788;&#29702;&#21644;&#26597;&#35810;&#32858;&#31867;&#25104;&#21592;&#65292;&#24182;&#19988;&#19982;&#30495;&#23454;&#32858;&#31867;&#25509;&#36817;&#30340;k-&#20998;&#21306;&#20445;&#25345;&#19968;&#33268;&#12290;&#27492;&#22806;&#65292;&#35813;&#39044;&#27979;&#22120;&#23545;&#20110;&#23569;&#37327;&#30340;&#38543;&#26426;&#36793;&#21024;&#38500;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35299;&#20915;&#20102;&#35774;&#35745;&#19968;&#31181;&#36866;&#29992;&#20110;&#20855;&#26377;&#24378;&#32858;&#31867;&#29305;&#24615;&#30340;&#22270;&#30340;&#20122;&#32447;&#24615;&#26102;&#38388;&#35889;&#32858;&#31867;&#39044;&#27979;&#22120;&#30340;&#38382;&#39064;&#12290;&#36825;&#26679;&#30340;&#22270;&#21253;&#21547;k&#20010;&#28508;&#22312;&#32858;&#31867;&#65292;&#27599;&#20010;&#32858;&#31867;&#30340;&#20869;&#23548;&#32435;&#36739;&#22823;&#65288;&#33267;&#23569;&#20026;&#966;&#65289;&#65292;&#22806;&#23548;&#32435;&#36739;&#23567;&#65288;&#26368;&#22810;&#20026;&#949;&#65289;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#23545;&#22270;&#36827;&#34892;&#39044;&#22788;&#29702;&#65292;&#20197;&#20351;&#24471;&#32858;&#31867;&#25104;&#21592;&#26597;&#35810;&#33021;&#22815;&#22312;&#20122;&#32447;&#24615;&#26102;&#38388;&#20869;&#36827;&#34892;&#65292;&#24182;&#19988;&#25152;&#24471;&#21040;&#30340;&#20998;&#21306;&#24212;&#19982;&#25509;&#36817;&#30495;&#23454;&#32858;&#31867;&#30340;k-&#20998;&#21306;&#19968;&#33268;&#12290;&#20043;&#21069;&#30340;&#39044;&#27979;&#22120;&#35201;&#20040;&#20381;&#36182;&#20110;&#20869;&#22806;&#23548;&#32435;&#20043;&#38388;&#26377;&#19968;&#20010;poly(k)log n&#30340;&#24046;&#36317;&#65292;&#35201;&#20040;&#38656;&#35201;&#25351;&#25968;&#32423;&#65288;&#22312;k/&#949;&#19978;&#65289;&#30340;&#39044;&#22788;&#29702;&#26102;&#38388;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#25918;&#23485;&#20102;&#36825;&#20123;&#20551;&#35774;&#65292;&#23613;&#31649;&#20250;&#30053;&#24494;&#22686;&#21152;&#38169;&#35823;&#20998;&#31867;&#29575;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#32858;&#31867;&#39044;&#27979;&#22120;&#23545;&#20110;&#23569;&#37327;&#30340;&#38543;&#26426;&#36793;&#21024;&#38500;&#26159;&#40065;&#26834;&#30340;&#12290;&#20026;&#20102;&#39564;&#35777;&#25105;&#20204;&#30340;&#29702;&#35770;&#30028;&#38480;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
We address the problem of designing a sublinear-time spectral clustering oracle for graphs that exhibit strong clusterability. Such graphs contain $k$ latent clusters, each characterized by a large inner conductance (at least $\varphi$) and a small outer conductance (at most $\varepsilon$). Our aim is to preprocess the graph to enable clustering membership queries, with the key requirement that both preprocessing and query answering should be performed in sublinear time, and the resulting partition should be consistent with a $k$-partition that is close to the ground-truth clustering. Previous oracles have relied on either a $\textrm{poly}(k)\log n$ gap between inner and outer conductances or exponential (in $k/\varepsilon$) preprocessing time. Our algorithm relaxes these assumptions, albeit at the cost of a slightly higher misclassification ratio. We also show that our clustering oracle is robust against a few random edge deletions. To validate our theoretical bounds, we conducted exp
&lt;/p&gt;</description></item><item><title>&#32452;&#21512;&#33021;&#21147;&#20197;&#20056;&#27861;&#26041;&#24335;&#20986;&#29616;&#65306;&#30740;&#31350;&#20102;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#22312;&#21512;&#25104;&#20219;&#21153;&#20013;&#30340;&#32452;&#21512;&#27867;&#21270;&#33021;&#21147;&#65292;&#32467;&#26524;&#26174;&#31034;&#36825;&#31181;&#33021;&#21147;&#21463;&#21040;&#24213;&#23618;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#30340;&#32467;&#26500;&#24433;&#21709;&#65292;&#19988;&#27169;&#22411;&#22312;&#23398;&#20064;&#21040;&#26356;&#39640;&#32423;&#30340;&#32452;&#21512;&#26102;&#23384;&#22312;&#22256;&#38590;&#12290;</title><link>http://arxiv.org/abs/2310.09336</link><description>&lt;p&gt;
&#32452;&#21512;&#33021;&#21147;&#20197;&#20056;&#27861;&#26041;&#24335;&#20986;&#29616;&#65306;&#22312;&#21512;&#25104;&#20219;&#21153;&#20013;&#25506;&#32034;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Compositional Abilities Emerge Multiplicatively: Exploring Diffusion Models on a Synthetic Task. (arXiv:2310.09336v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09336
&lt;/p&gt;
&lt;p&gt;
&#32452;&#21512;&#33021;&#21147;&#20197;&#20056;&#27861;&#26041;&#24335;&#20986;&#29616;&#65306;&#30740;&#31350;&#20102;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#22312;&#21512;&#25104;&#20219;&#21153;&#20013;&#30340;&#32452;&#21512;&#27867;&#21270;&#33021;&#21147;&#65292;&#32467;&#26524;&#26174;&#31034;&#36825;&#31181;&#33021;&#21147;&#21463;&#21040;&#24213;&#23618;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#30340;&#32467;&#26500;&#24433;&#21709;&#65292;&#19988;&#27169;&#22411;&#22312;&#23398;&#20064;&#21040;&#26356;&#39640;&#32423;&#30340;&#32452;&#21512;&#26102;&#23384;&#22312;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#29983;&#25104;&#27169;&#22411;&#23637;&#31034;&#20986;&#20102;&#20135;&#29983;&#26497;&#20026;&#36924;&#30495;&#25968;&#25454;&#30340;&#21069;&#25152;&#26410;&#26377;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#32771;&#34385;&#21040;&#29616;&#23454;&#19990;&#30028;&#30340;&#33258;&#28982;&#32452;&#21512;&#24615;&#65292;&#36825;&#20123;&#27169;&#22411;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#21487;&#38752;&#20351;&#29992;&#38656;&#35201;&#23637;&#31034;&#20986;&#33021;&#22815;&#32452;&#21512;&#26032;&#30340;&#27010;&#24565;&#38598;&#21512;&#20197;&#29983;&#25104;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#26410;&#35265;&#30340;&#36755;&#20986;&#30340;&#33021;&#21147;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#26368;&#36817;&#30340;&#25193;&#25955;&#27169;&#22411;&#30830;&#23454;&#34920;&#29616;&#20986;&#20102;&#26377;&#36259;&#30340;&#32452;&#21512;&#27867;&#21270;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#20063;&#20250;&#20986;&#29616;&#26080;&#27861;&#39044;&#27979;&#30340;&#22833;&#36133;&#12290;&#21463;&#27492;&#21551;&#21457;&#65292;&#25105;&#20204;&#22312;&#21512;&#25104;&#29615;&#22659;&#20013;&#36827;&#34892;&#20102;&#26377;&#25511;&#21046;&#24615;&#30340;&#30740;&#31350;&#65292;&#20197;&#20102;&#35299;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#30340;&#32452;&#21512;&#27867;&#21270;&#33021;&#21147;&#65292;&#25105;&#20204;&#21464;&#21270;&#20102;&#35757;&#32451;&#25968;&#25454;&#30340;&#19981;&#21516;&#23646;&#24615;&#24182;&#27979;&#37327;&#20102;&#27169;&#22411;&#29983;&#25104;&#36234;&#30028;&#26679;&#26412;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;&#65306;&#65288;i&#65289;&#20174;&#19968;&#20010;&#27010;&#24565;&#29983;&#25104;&#26679;&#26412;&#30340;&#33021;&#21147;&#21644;&#23558;&#23427;&#20204;&#32452;&#21512;&#36215;&#26469;&#30340;&#33021;&#21147;&#30340;&#20986;&#29616;&#39034;&#24207;&#21463;&#21040;&#20102;&#24213;&#23618;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#30340;&#32467;&#26500;&#30340;&#24433;&#21709;&#65307;&#65288;ii&#65289;&#22312;&#32452;&#21512;&#20219;&#21153;&#19978;&#30340;&#34920;&#29616;&#34920;&#26126;&#27169;&#22411;&#22312;&#23398;&#20064;&#21040;&#26356;&#39640;&#32423;&#30340;&#32452;&#21512;&#26102;&#23384;&#22312;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern generative models exhibit unprecedented capabilities to generate extremely realistic data. However, given the inherent compositionality of the real world, reliable use of these models in practical applications requires that they exhibit the capability to compose a novel set of concepts to generate outputs not seen in the training data set. Prior work demonstrates that recent diffusion models do exhibit intriguing compositional generalization abilities, but also fail unpredictably. Motivated by this, we perform a controlled study for understanding compositional generalization in conditional diffusion models in a synthetic setting, varying different attributes of the training data and measuring the model's ability to generate samples out-of-distribution. Our results show: (i) the order in which the ability to generate samples from a concept and compose them emerges is governed by the structure of the underlying data-generating process; (ii) performance on compositional tasks exhib
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27604;&#36739;&#20102;&#29616;&#20195;&#22270;&#20687;&#21644;&#35270;&#39057;&#36136;&#37327;&#35780;&#20272;&#24230;&#37327;&#26041;&#27861;&#23545;&#25239;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#21457;&#29616;&#37096;&#20998;&#24230;&#37327;&#26041;&#27861;&#23545;&#23545;&#25239;&#25915;&#20987;&#34920;&#29616;&#20986;&#36739;&#39640;&#30340;&#25269;&#25239;&#21147;&#65292;&#20026;&#22522;&#20934;&#27979;&#35797;&#25552;&#20379;&#20102;&#26356;&#23433;&#20840;&#30340;&#36873;&#25321;&#12290;</title><link>http://arxiv.org/abs/2310.06958</link><description>&lt;p&gt;
&#27604;&#36739;&#29616;&#20195;&#26080;&#21442;&#32771;&#22270;&#20687;&#21644;&#35270;&#39057;&#36136;&#37327;&#35780;&#20272;&#24230;&#37327;&#26041;&#27861;&#23545;&#23545;&#25239;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Comparing the robustness of modern no-reference image- and video-quality metrics to adversarial attacks. (arXiv:2310.06958v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06958
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27604;&#36739;&#20102;&#29616;&#20195;&#22270;&#20687;&#21644;&#35270;&#39057;&#36136;&#37327;&#35780;&#20272;&#24230;&#37327;&#26041;&#27861;&#23545;&#25239;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#21457;&#29616;&#37096;&#20998;&#24230;&#37327;&#26041;&#27861;&#23545;&#23545;&#25239;&#25915;&#20987;&#34920;&#29616;&#20986;&#36739;&#39640;&#30340;&#25269;&#25239;&#21147;&#65292;&#20026;&#22522;&#20934;&#27979;&#35797;&#25552;&#20379;&#20102;&#26356;&#23433;&#20840;&#30340;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#20170;&#65292;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#22270;&#20687;&#21644;&#35270;&#39057;&#36136;&#37327;&#35780;&#20272;&#24230;&#37327;&#26041;&#27861;&#30456;&#27604;&#20256;&#32479;&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#20063;&#21464;&#24471;&#26356;&#23481;&#26131;&#21463;&#21040;&#23545;&#25239;&#24615;&#25915;&#20987;&#65292;&#36825;&#20123;&#25915;&#20987;&#21487;&#20197;&#25552;&#39640;&#24230;&#37327;&#20998;&#25968;&#20294;&#19981;&#25913;&#21892;&#35270;&#35273;&#36136;&#37327;&#12290;&#29616;&#26377;&#30340;&#36136;&#37327;&#24230;&#37327;&#22522;&#20934;&#23558;&#20854;&#24615;&#33021;&#19982;&#20027;&#35266;&#36136;&#37327;&#30456;&#20851;&#24615;&#21644;&#35745;&#31639;&#26102;&#38388;&#36827;&#34892;&#27604;&#36739;&#12290;&#28982;&#32780;&#65292;&#22270;&#20687;&#36136;&#37327;&#24230;&#37327;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#20063;&#26159;&#19968;&#20010;&#20540;&#24471;&#30740;&#31350;&#30340;&#39046;&#22495;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;&#29616;&#20195;&#24230;&#37327;&#26041;&#27861;&#23545;&#19981;&#21516;&#23545;&#25239;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#35745;&#31639;&#26426;&#35270;&#35273;&#20219;&#21153;&#20013;&#30340;&#23545;&#25239;&#25915;&#20987;&#65292;&#24182;&#27604;&#36739;&#20102;&#36825;&#20123;&#25915;&#20987;&#23545;15&#20010;&#26080;&#21442;&#32771;&#22270;&#20687;/&#35270;&#39057;&#36136;&#37327;&#24230;&#37327;&#26041;&#27861;&#30340;&#25928;&#26524;&#12290;&#19968;&#20123;&#24230;&#37327;&#26041;&#27861;&#23545;&#23545;&#25239;&#25915;&#20987;&#34920;&#29616;&#20986;&#20102;&#36739;&#39640;&#30340;&#25269;&#25239;&#21147;&#65292;&#20351;&#23427;&#20204;&#22312;&#22522;&#20934;&#27979;&#35797;&#20013;&#30340;&#20351;&#29992;&#27604;&#23481;&#26131;&#21463;&#25915;&#20987;&#30340;&#26041;&#27861;&#26356;&#23433;&#20840;&#12290;&#35813;&#22522;&#20934;&#27979;&#35797;&#25509;&#21463;&#30740;&#31350;&#20154;&#21592;&#25552;&#20132;&#26032;&#30340;&#24230;&#37327;&#26041;&#27861;&#65292;&#20197;&#20351;&#20182;&#20204;&#30340;&#26041;&#27861;&#23545;&#25915;&#20987;&#26356;&#21152;&#40065;&#26834;&#65292;&#25110;&#32773;&#20026;&#20182;&#20204;&#23547;&#25214;&#31526;&#21512;&#38656;&#27714;&#30340;&#40065;&#26834;&#24230;&#37327;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nowadays neural-network-based image- and video-quality metrics show better performance compared to traditional methods. However, they also became more vulnerable to adversarial attacks that increase metrics' scores without improving visual quality. The existing benchmarks of quality metrics compare their performance in terms of correlation with subjective quality and calculation time. However, the adversarial robustness of image-quality metrics is also an area worth researching. In this paper, we analyse modern metrics' robustness to different adversarial attacks. We adopted adversarial attacks from computer vision tasks and compared attacks' efficiency against 15 no-reference image/video-quality metrics. Some metrics showed high resistance to adversarial attacks which makes their usage in benchmarks safer than vulnerable metrics. The benchmark accepts new metrics submissions for researchers who want to make their metrics more robust to attacks or to find such metrics for their needs. 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;OILCA&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#21487;&#35782;&#21035;&#30340;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#29983;&#25104;"&#23545;&#25239;&#24615;"&#26679;&#26412;&#65292;&#20197;&#35299;&#20915;&#31163;&#32447;&#27169;&#20223;&#23398;&#20064;&#20013;&#25968;&#25454;&#31232;&#32570;&#12289;&#29615;&#22659;&#21464;&#21270;&#31561;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.04706</link><description>&lt;p&gt;
&#31163;&#32447;&#27169;&#20223;&#23398;&#20064;&#19982;&#21464;&#20998;&#36870;&#21521;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Offline Imitation Learning with Variational Counterfactual Reasoning. (arXiv:2310.04706v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04706
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;OILCA&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#21487;&#35782;&#21035;&#30340;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#29983;&#25104;"&#23545;&#25239;&#24615;"&#26679;&#26412;&#65292;&#20197;&#35299;&#20915;&#31163;&#32447;&#27169;&#20223;&#23398;&#20064;&#20013;&#25968;&#25454;&#31232;&#32570;&#12289;&#29615;&#22659;&#21464;&#21270;&#31561;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31163;&#32447;&#27169;&#20223;&#23398;&#20064;&#20013;&#65292;&#26234;&#33021;&#20307;&#26088;&#22312;&#23398;&#20064;&#19968;&#31181;&#26368;&#20248;&#30340;&#19987;&#23478;&#34892;&#20026;&#31574;&#30053;&#65292;&#32780;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#22312;&#32447;&#29615;&#22659;&#20132;&#20114;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#30495;&#23454;&#22330;&#26223;&#20013;&#65292;&#20363;&#22914;&#26426;&#22120;&#20154;&#25805;&#20316;&#20013;&#65292;&#31163;&#32447;&#25968;&#25454;&#38598;&#26159;&#20174;&#27809;&#26377;&#22870;&#21169;&#30340;&#27425;&#20248;&#34892;&#20026;&#20013;&#25910;&#38598;&#26469;&#30340;&#12290;&#30001;&#20110;&#19987;&#23478;&#25968;&#25454;&#31232;&#32570;&#65292;&#26234;&#33021;&#20307;&#36890;&#24120;&#21482;&#33021;&#31616;&#21333;&#22320;&#35760;&#20303;&#36139;&#20047;&#30340;&#36712;&#36857;&#65292;&#24182;&#19988;&#23481;&#26131;&#21463;&#21040;&#29615;&#22659;&#21464;&#21270;&#30340;&#24433;&#21709;&#65292;&#32570;&#20047;&#23545;&#26032;&#29615;&#22659;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#20026;&#20102;&#26377;&#25928;&#22320;&#28040;&#38500;&#20250;&#23545;&#26234;&#33021;&#20307;&#36896;&#25104;&#20559;&#24046;&#24182;&#38459;&#30861;&#27867;&#21270;&#30340;&#20266;&#29305;&#24449;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;OILCA&#30340;&#26694;&#26550;&#65292;&#21363;&#31163;&#32447;&#27169;&#20223;&#23398;&#20064;&#19982;&#23545;&#25239;&#25968;&#25454;&#22686;&#24378;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#21033;&#29992;&#21487;&#35782;&#21035;&#30340;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#29983;&#25104;"&#23545;&#25239;&#24615;"&#26679;&#26412;&#12290;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#20998;&#26512;&#20102;&#23545;&#25239;&#24615;&#35782;&#21035;&#21644;&#27867;&#21270;&#30340;&#25913;&#21892;&#12290;
&lt;/p&gt;
&lt;p&gt;
In offline Imitation Learning (IL), an agent aims to learn an optimal expert behavior policy without additional online environment interactions. However, in many real-world scenarios, such as robotics manipulation, the offline dataset is collected from suboptimal behaviors without rewards. Due to the scarce expert data, the agents usually suffer from simply memorizing poor trajectories and are vulnerable to the variations in the environments, lacking the capability of generalizing to new environments. To effectively remove spurious features that would otherwise bias the agent and hinder generalization, we propose a framework named \underline{O}ffline \underline{I}mitation \underline{L}earning with \underline{C}ounterfactual data \underline{A}ugmentation (OILCA). In particular, we leverage the identifiable variational autoencoder to generate \textit{counterfactual} samples. We theoretically analyze the counterfactual identification and the improvement of generalization. Moreover, we con
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22686;&#24378;&#40065;&#26834;&#24615;&#30340;&#25552;&#21319;&#24314;&#27169;&#26694;&#26550;RUAD&#65292;&#24182;&#36890;&#36807;&#29305;&#24449;&#36873;&#25321;&#21644;&#23545;&#25239;&#29305;&#24449;&#25233;&#21046;&#20004;&#20010;&#23450;&#21046;&#27169;&#22359;&#26356;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#25552;&#21319;&#27169;&#22411;&#30340;&#29305;&#24449;&#25935;&#24863;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.04693</link><description>&lt;p&gt;
&#22686;&#24378;&#40065;&#26834;&#24615;&#30340;&#24102;&#23545;&#25239;&#29305;&#24449;&#25233;&#21046;&#30340;&#25552;&#21319;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Robustness-enhanced Uplift Modeling with Adversarial Feature Desensitization. (arXiv:2310.04693v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04693
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22686;&#24378;&#40065;&#26834;&#24615;&#30340;&#25552;&#21319;&#24314;&#27169;&#26694;&#26550;RUAD&#65292;&#24182;&#36890;&#36807;&#29305;&#24449;&#36873;&#25321;&#21644;&#23545;&#25239;&#29305;&#24449;&#25233;&#21046;&#20004;&#20010;&#23450;&#21046;&#27169;&#22359;&#26356;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#25552;&#21319;&#27169;&#22411;&#30340;&#29305;&#24449;&#25935;&#24863;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#21319;&#24314;&#27169;&#22312;&#22312;&#32447;&#33829;&#38144;&#20013;&#23637;&#31034;&#20102;&#38750;&#24120;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#24037;&#20316;&#22312;&#19968;&#20123;&#23454;&#38469;&#24212;&#29992;&#20013;&#23481;&#26131;&#21463;&#21040;&#40065;&#26834;&#24615;&#25361;&#25112;&#30340;&#24433;&#21709;&#12290;&#26412;&#25991;&#39318;&#20808;&#23545;&#19978;&#36848;&#29616;&#35937;&#32473;&#20986;&#20102;&#19968;&#20010;&#21487;&#33021;&#30340;&#35299;&#37322;&#12290;&#25105;&#20204;&#20351;&#29992;&#19981;&#21516;&#30340;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#39564;&#35777;&#20102;&#22312;&#32447;&#33829;&#38144;&#20013;&#23384;&#22312;&#29305;&#24449;&#25935;&#24863;&#24615;&#38382;&#39064;&#65292;&#19968;&#20123;&#20851;&#38190;&#29305;&#24449;&#30340;&#25200;&#21160;&#20250;&#20005;&#37325;&#24433;&#21709;&#25552;&#21319;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#29978;&#33267;&#23548;&#33268;&#30456;&#21453;&#30340;&#36235;&#21183;&#12290;&#20026;&#20102;&#35299;&#20915;&#19978;&#36848;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36890;&#36807;&#23545;&#25239;&#29305;&#24449;&#25233;&#21046;&#22686;&#24378;&#40065;&#26834;&#24615;&#30340;&#25552;&#21319;&#24314;&#27169;&#26694;&#26550;&#65288;RUAD&#65289;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#30340;RUAD&#36890;&#36807;&#20004;&#20010;&#23450;&#21046;&#27169;&#22359;&#26356;&#26377;&#25928;&#22320;&#20943;&#36731;&#25552;&#21319;&#27169;&#22411;&#30340;&#29305;&#24449;&#25935;&#24863;&#24615;&#65292;&#21253;&#25324;&#19968;&#20010;&#20855;&#26377;&#32852;&#21512;&#22810;&#26631;&#31614;&#24314;&#27169;&#30340;&#29305;&#24449;&#36873;&#25321;&#27169;&#22359;&#65292;&#20197;&#20174;&#36755;&#20837;&#29305;&#24449;&#20013;&#35782;&#21035;&#19968;&#20010;&#20851;&#38190;&#23376;&#38598;&#65292;&#20197;&#21450;&#19968;&#20010;&#37319;&#29992;&#23545;&#25239;&#35757;&#32451;&#21644;&#36719;&#25554;&#20540;&#25805;&#20316;&#30340;&#23545;&#25239;&#29305;&#24449;&#25233;&#21046;&#27169;&#22359;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uplift modeling has shown very promising results in online marketing. However, most existing works are prone to the robustness challenge in some practical applications. In this paper, we first present a possible explanation for the above phenomenon. We verify that there is a feature sensitivity problem in online marketing using different real-world datasets, where the perturbation of some key features will seriously affect the performance of the uplift model and even cause the opposite trend. To solve the above problem, we propose a novel robustness-enhanced uplift modeling framework with adversarial feature desensitization (RUAD). Specifically, our RUAD can more effectively alleviate the feature sensitivity of the uplift model through two customized modules, including a feature selection module with joint multi-label modeling to identify a key subset from the input features and an adversarial feature desensitization module using adversarial training and soft interpolation operations t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22270;&#31070;&#32463;&#25552;&#31034;&#65288;GNP&#65289;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#24110;&#21161;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20174;&#30693;&#35782;&#22270;&#20013;&#23398;&#20064;&#26377;&#30410;&#30340;&#30693;&#35782;&#65292;&#20197;&#24357;&#34917;&#23427;&#20204;&#22312;&#20934;&#30830;&#25429;&#25417;&#21644;&#36820;&#22238;&#22522;&#20110;&#30693;&#35782;&#30340;&#20449;&#24687;&#26041;&#38754;&#30340;&#22266;&#26377;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2309.15427</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22270;&#31070;&#32463;&#25552;&#31034;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Prompting with Large Language Models. (arXiv:2309.15427v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15427
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22270;&#31070;&#32463;&#25552;&#31034;&#65288;GNP&#65289;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#24110;&#21161;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20174;&#30693;&#35782;&#22270;&#20013;&#23398;&#20064;&#26377;&#30410;&#30340;&#30693;&#35782;&#65292;&#20197;&#24357;&#34917;&#23427;&#20204;&#22312;&#20934;&#30830;&#25429;&#25417;&#21644;&#36820;&#22238;&#22522;&#20110;&#30693;&#35782;&#30340;&#20449;&#24687;&#26041;&#38754;&#30340;&#22266;&#26377;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21508;&#31181;&#35821;&#35328;&#24314;&#27169;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#20102;&#21331;&#36234;&#30340;&#27867;&#21270;&#33021;&#21147;&#21644;&#20986;&#33394;&#30340;&#24615;&#33021;&#65292;&#20294;&#23427;&#20204;&#22312;&#20934;&#30830;&#25429;&#25417;&#21644;&#36820;&#22238;&#22522;&#20110;&#30693;&#35782;&#30340;&#20449;&#24687;&#26041;&#38754;&#20173;&#23384;&#22312;&#22266;&#26377;&#38480;&#21046;&#12290;&#29616;&#26377;&#30340;&#30740;&#31350;&#24050;&#32463;&#25506;&#32034;&#20102;&#21033;&#29992;&#30693;&#35782;&#22270;&#26469;&#36890;&#36807;&#32852;&#21512;&#35757;&#32451;&#21644;&#23450;&#21046;&#27169;&#22411;&#26550;&#26500;&#22686;&#24378;&#35821;&#35328;&#24314;&#27169;&#65292;&#20294;&#26159;&#23558;&#27492;&#24212;&#29992;&#20110;LLMs&#23384;&#22312;&#21442;&#25968;&#25968;&#37327;&#24222;&#22823;&#21644;&#35745;&#31639;&#25104;&#26412;&#39640;&#30340;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#22914;&#20309;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;LLMs&#24182;&#36991;&#20813;&#20174;&#22836;&#24320;&#22987;&#35757;&#32451;&#33258;&#23450;&#20041;&#27169;&#22411;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#30340;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22270;&#31070;&#32463;&#25552;&#31034;&#65288;GNP&#65289;&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#21363;&#25554;&#21363;&#29992;&#26041;&#27861;&#65292;&#21487;&#20197;&#24110;&#21161;&#39044;&#35757;&#32451;&#30340;LLMs&#20174;&#30693;&#35782;&#22270;&#20013;&#23398;&#20064;&#26377;&#30410;&#30340;&#30693;&#35782;&#12290;GNP&#21253;&#25324;&#21508;&#31181;&#35774;&#35745;&#65292;&#21253;&#25324;&#26631;&#20934;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#32534;&#30721;&#22120;&#12289;&#36328;&#27169;&#24577;&#27719;&#32858;&#27169;&#22359;&#12289;&#22495;&#25237;&#24433;&#22120;&#21644;&#33258;&#30417;&#30563;&#38142;&#25509;&#39044;&#27979;&#30446;&#26631;&#12290;&#22312;&#22810;&#20010;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;GNP&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have shown remarkable generalization capability with exceptional performance in various language modeling tasks. However, they still exhibit inherent limitations in precisely capturing and returning grounded knowledge. While existing work has explored utilizing knowledge graphs to enhance language modeling via joint training and customized model architectures, applying this to LLMs is problematic owing to their large number of parameters and high computational cost. In addition, how to leverage the pre-trained LLMs and avoid training a customized model from scratch remains an open question. In this work, we propose Graph Neural Prompting (GNP), a novel plug-and-play method to assist pre-trained LLMs in learning beneficial knowledge from KGs. GNP encompasses various designs, including a standard graph neural network encoder, a cross-modality pooling module, a domain projector, and a self-supervised link prediction objective. Extensive experiments on multiple
&lt;/p&gt;</description></item><item><title>&#26368;&#22823;&#25193;&#25955;&#24378;&#21270;&#23398;&#20064;&#26159;&#19968;&#31181;&#20811;&#26381;&#24378;&#21270;&#23398;&#20064;&#20013;&#25968;&#25454;&#30456;&#20851;&#24615;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35299;&#32806;&#20195;&#29702;&#30340;&#32463;&#39564;&#23454;&#29616;&#25345;&#32493;&#23398;&#20064;&#65292;&#24182;&#22312;&#21508;&#31181;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>http://arxiv.org/abs/2309.15293</link><description>&lt;p&gt;
&#26368;&#22823;&#25193;&#25955;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Maximum Diffusion Reinforcement Learning. (arXiv:2309.15293v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15293
&lt;/p&gt;
&lt;p&gt;
&#26368;&#22823;&#25193;&#25955;&#24378;&#21270;&#23398;&#20064;&#26159;&#19968;&#31181;&#20811;&#26381;&#24378;&#21270;&#23398;&#20064;&#20013;&#25968;&#25454;&#30456;&#20851;&#24615;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35299;&#32806;&#20195;&#29702;&#30340;&#32463;&#39564;&#23454;&#29616;&#25345;&#32493;&#23398;&#20064;&#65292;&#24182;&#22312;&#21508;&#31181;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25152;&#26377;&#26426;&#22120;&#23398;&#20064;&#37117;&#24314;&#31435;&#22312;&#25968;&#25454;&#29420;&#31435;&#19988;&#21516;&#20998;&#24067;&#30340;&#20551;&#35774;&#19978;&#12290;&#28982;&#32780;&#65292;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#24403;&#25968;&#25454;&#26159;&#20381;&#27425;&#20174;&#20195;&#29702;&#32463;&#39564;&#20013;&#25910;&#38598;&#32780;&#26469;&#26102;&#65292;&#36825;&#19968;&#20551;&#35774;&#36890;&#24120;&#19981;&#25104;&#31435;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#26368;&#22823;&#25193;&#25955;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#32479;&#35745;&#21147;&#23398;&#20013;&#30340;&#36941;&#21382;&#36807;&#31243;&#26469;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#35299;&#32806;&#20195;&#29702;&#30340;&#32463;&#39564;&#65292;&#21487;&#35777;&#26126;&#22320;&#20351;&#20195;&#29702;&#22312;&#21333;&#27425;&#37096;&#32626;&#20013;&#33021;&#22815;&#25345;&#32493;&#23398;&#20064;&#65292;&#32780;&#19981;&#21463;&#21021;&#22987;&#21270;&#26041;&#24335;&#30340;&#24433;&#21709;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#25512;&#24191;&#20102;&#20247;&#25152;&#21608;&#30693;&#30340;&#26368;&#22823;&#29109;&#25216;&#26415;&#65292;&#24182;&#19988;&#36890;&#36807;&#22312;&#27969;&#34892;&#30340;&#22522;&#20934;&#27979;&#35797;&#20013;&#31283;&#23450;&#36229;&#36807;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#27700;&#24179;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25104;&#26524;&#26497;&#22823;&#22320;&#20419;&#36827;&#20102;&#29289;&#29702;&#23398;&#12289;&#23398;&#20064;&#21644;&#25511;&#21046;&#30340;&#20132;&#21449;&#39046;&#22495;&#65292;&#20026;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#65288;&#22914;&#34892;&#36208;&#26426;&#22120;&#20154;&#21644;&#33258;&#21160;&#39550;&#39542;&#27773;&#36710;&#65289;&#30340;&#36879;&#26126;&#21487;&#38752;&#20915;&#31574;&#25552;&#20379;&#20102;&#19968;&#26465;&#36947;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
The assumption that data are independent and identically distributed underpins all machine learning. When data are collected sequentially from agent experiences this assumption does not generally hold, as in reinforcement learning. Here, we derive a method that overcomes these limitations by exploiting the statistical mechanics of ergodic processes, which we term maximum diffusion reinforcement learning. By decorrelating agent experiences, our approach provably enables agents to learn continually in single-shot deployments regardless of how they are initialized. Moreover, we prove our approach generalizes well-known maximum entropy techniques, and show that it robustly exceeds state-of-the-art performance across popular benchmarks. Our results at the nexus of physics, learning, and control pave the way towards more transparent and reliable decision-making in reinforcement learning agents, such as locomoting robots and self-driving cars.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#24555;&#36895;Slate&#31574;&#30053;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#31867;&#65292;&#21487;&#20197;&#22312;&#22823;&#35268;&#27169;&#20915;&#31574;&#31995;&#32479;&#20013;&#26377;&#25928;&#22320;&#20248;&#21270;&#20219;&#24847;&#22870;&#21169;&#20989;&#25968;&#65292;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#30334;&#19975;&#32423;&#21035;&#21160;&#20316;&#31354;&#38388;&#38382;&#39064;&#19978;&#20855;&#26377;&#24456;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.01566</link><description>&lt;p&gt;
&#24555;&#36895;Slate&#31574;&#30053;&#20248;&#21270;&#65306;&#36229;&#36234;Plackett-Luce
&lt;/p&gt;
&lt;p&gt;
Fast Slate Policy Optimization: Going Beyond Plackett-Luce. (arXiv:2308.01566v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01566
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#24555;&#36895;Slate&#31574;&#30053;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#31867;&#65292;&#21487;&#20197;&#22312;&#22823;&#35268;&#27169;&#20915;&#31574;&#31995;&#32479;&#20013;&#26377;&#25928;&#22320;&#20248;&#21270;&#20219;&#24847;&#22870;&#21169;&#20989;&#25968;&#65292;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#30334;&#19975;&#32423;&#21035;&#21160;&#20316;&#31354;&#38388;&#38382;&#39064;&#19978;&#20855;&#26377;&#24456;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#20013;&#19968;&#20010;&#36234;&#26469;&#36234;&#37325;&#35201;&#30340;&#26500;&#24314;&#27169;&#22359;&#26159;&#36820;&#22238;Slate&#65292;&#21363;&#32473;&#23450;&#19968;&#20010;&#26597;&#35810;&#36820;&#22238;&#26377;&#24207;&#30340;&#39033;&#30446;&#21015;&#34920;&#12290;&#35813;&#25216;&#26415;&#30340;&#24212;&#29992;&#21253;&#25324;&#25628;&#32034;&#12289;&#20449;&#24687;&#26816;&#32034;&#21644;&#25512;&#33616;&#31995;&#32479;&#12290;&#24403;&#34892;&#21160;&#31354;&#38388;&#24456;&#22823;&#26102;&#65292;&#20915;&#31574;&#31995;&#32479;&#20250;&#38480;&#21046;&#22312;&#29305;&#23450;&#32467;&#26500;&#20013;&#20197;&#24555;&#36895;&#23436;&#25104;&#22312;&#32447;&#26597;&#35810;&#12290;&#26412;&#25991;&#35299;&#20915;&#20102;&#36825;&#20123;&#22823;&#35268;&#27169;&#20915;&#31574;&#31995;&#32479;&#22312;&#32473;&#23450;&#20219;&#24847;&#22870;&#21169;&#20989;&#25968;&#19979;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#23398;&#20064;&#38382;&#39064;&#36716;&#21270;&#20026;&#31574;&#30053;&#20248;&#21270;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#31867;&#65292;&#23427;&#28304;&#20110;&#20915;&#31574;&#20989;&#25968;&#30340;&#19968;&#31181;&#26032;&#39062;&#25918;&#26494;&#12290;&#36825;&#23548;&#33268;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#39640;&#25928;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#20197;&#25193;&#23637;&#21040;&#22823;&#35268;&#27169;&#30340;&#21160;&#20316;&#31354;&#38388;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#24120;&#29992;&#30340;Plackett-Luce&#31574;&#30053;&#31867;&#36827;&#34892;&#27604;&#36739;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21160;&#20316;&#31354;&#38388;&#22823;&#23567;&#36798;&#21040;&#30334;&#19975;&#32423;&#21035;&#30340;&#38382;&#39064;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
An increasingly important building block of large scale machine learning systems is based on returning slates; an ordered lists of items given a query. Applications of this technology include: search, information retrieval and recommender systems. When the action space is large, decision systems are restricted to a particular structure to complete online queries quickly. This paper addresses the optimization of these large scale decision systems given an arbitrary reward function. We cast this learning problem in a policy optimization framework and propose a new class of policies, born from a novel relaxation of decision functions. This results in a simple, yet efficient learning algorithm that scales to massive action spaces. We compare our method to the commonly adopted Plackett-Luce policy class and demonstrate the effectiveness of our approach on problems with action space sizes in the order of millions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;VillanDiffusion&#65292;&#19968;&#20010;&#38024;&#23545;&#25193;&#25955;&#27169;&#22411;&#30340;&#32479;&#19968;&#21518;&#38376;&#25915;&#20987;&#26694;&#26550;&#65292;&#28085;&#30422;&#20027;&#27969;&#30340;&#26080;&#26465;&#20214;&#21644;&#26377;&#26465;&#20214;DM&#65292;&#20415;&#20110;&#23545;&#19981;&#21516;DM&#37197;&#32622;&#36827;&#34892;&#21518;&#38376;&#20998;&#26512;&#65292;&#24182;&#20026;&#22522;&#20110;&#23383;&#24149;&#30340;DM&#21518;&#38376;&#25915;&#20987;&#25552;&#20379;&#20102;&#26032;&#30340;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2306.06874</link><description>&lt;p&gt;
VillanDiffusion: &#19968;&#31181;&#38024;&#23545;&#25193;&#25955;&#27169;&#22411;&#30340;&#32479;&#19968;&#21518;&#38376;&#25915;&#20987;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
VillanDiffusion: A Unified Backdoor Attack Framework for Diffusion Models. (arXiv:2306.06874v2 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06874
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;VillanDiffusion&#65292;&#19968;&#20010;&#38024;&#23545;&#25193;&#25955;&#27169;&#22411;&#30340;&#32479;&#19968;&#21518;&#38376;&#25915;&#20987;&#26694;&#26550;&#65292;&#28085;&#30422;&#20027;&#27969;&#30340;&#26080;&#26465;&#20214;&#21644;&#26377;&#26465;&#20214;DM&#65292;&#20415;&#20110;&#23545;&#19981;&#21516;DM&#37197;&#32622;&#36827;&#34892;&#21518;&#38376;&#20998;&#26512;&#65292;&#24182;&#20026;&#22522;&#20110;&#23383;&#24149;&#30340;DM&#21518;&#38376;&#25915;&#20987;&#25552;&#20379;&#20102;&#26032;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#65288;DM&#65289;&#26159;&#26368;&#20808;&#36827;&#30340;&#29983;&#25104;&#27169;&#22411;&#20043;&#19968;&#65292;&#23427;&#36890;&#36807;&#36845;&#20195;&#28155;&#21152;&#22122;&#22768;&#21644;&#21435;&#22122;&#23398;&#20064;&#21487;&#36870;&#30340;&#25439;&#22351;&#36807;&#31243;&#12290;&#23427;&#20204;&#26159;&#35768;&#22810;&#29983;&#25104;&#20154;&#24037;&#26234;&#33021;&#24212;&#29992;&#30340;&#20027;&#24178;&#65292;&#20363;&#22914;&#25991;&#26412;&#21040;&#22270;&#20687;&#26377;&#26465;&#20214;&#29983;&#25104;&#12290;&#20294;&#26159;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#22522;&#26412;&#26080;&#26465;&#20214;DM&#65288;&#20363;&#22914;DDPM&#21644;DDIM&#65289;&#26131;&#21463;&#21518;&#38376;&#27880;&#20837;&#25915;&#20987;&#65292;&#36825;&#26159;&#19968;&#31181;&#30001;&#20110;&#24694;&#24847;&#23884;&#20837;&#27169;&#22411;&#36755;&#20837;&#30340;&#27169;&#24335;&#32780;&#35302;&#21457;&#30340;&#36755;&#20986;&#25805;&#32437;&#25915;&#20987;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#21518;&#38376;&#25915;&#20987;&#26694;&#26550;&#65288;VillanDiffusion&#65289;&#65292;&#20197;&#25193;&#23637;&#24403;&#21069;&#30340;DM&#21518;&#38376;&#20998;&#26512;&#33539;&#22260;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#28085;&#30422;&#20102;&#20027;&#27969;&#30340;&#26080;&#26465;&#20214;&#21644;&#26377;&#26465;&#20214;DM&#65288;&#22522;&#20110;&#21435;&#22122;&#21644;&#22522;&#20110;&#35780;&#20998;&#65289;&#65292;&#20197;&#21450;&#21508;&#31181;&#26080;&#38656;&#35757;&#32451;&#30340;&#37319;&#26679;&#22120;&#36827;&#34892;&#25972;&#20307;&#35780;&#20272;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#32479;&#19968;&#26694;&#26550;&#20415;&#20110;&#23545;&#19981;&#21516;DM&#37197;&#32622;&#36827;&#34892;&#21518;&#38376;&#20998;&#26512;&#65292;&#24182;&#20026;&#22522;&#20110;&#23383;&#24149;&#30340;DM&#21518;&#38376;&#25915;&#20987;&#25552;&#20379;&#26032;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion Models (DMs) are state-of-the-art generative models that learn a reversible corruption process from iterative noise addition and denoising. They are the backbone of many generative AI applications, such as text-to-image conditional generation. However, recent studies have shown that basic unconditional DMs (e.g., DDPM and DDIM) are vulnerable to backdoor injection, a type of output manipulation attack triggered by a maliciously embedded pattern at model input. This paper presents a unified backdoor attack framework (VillanDiffusion) to expand the current scope of backdoor analysis for DMs. Our framework covers mainstream unconditional and conditional DMs (denoising-based and score-based) and various training-free samplers for holistic evaluations. Experiments show that our unified framework facilitates the backdoor analysis of different DM configurations and provides new insights into caption-based backdoor attacks on DMs.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#21487;&#24494;&#20998;&#30340;&#24555;&#36895;&#36924;&#36817;&#26041;&#27861;&#65292;&#35757;&#32451;&#20102;&#19968;&#20010;&#32534;&#30721;&#22120;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#39640;&#20142;LHC&#25968;&#25454;&#30340;&#21387;&#32553;&#65292;&#21516;&#26102;&#20445;&#30041;&#20102;&#25968;&#25454;&#20869;&#19982;&#31890;&#23376;&#25506;&#27979;&#22120;&#20013;&#30340;&#33021;&#37327;&#27785;&#31215;&#20998;&#24067;&#30456;&#20851;&#30340;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2306.04712</link><description>&lt;p&gt;
&#21487;&#24494;&#30340;&#22320;&#29699;&#31227;&#21160;&#36317;&#31163;&#22312;&#39640;&#20142;LHC&#25968;&#25454;&#21387;&#32553;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Differentiable Earth Mover's Distance for Data Compression at the High-Luminosity LHC. (arXiv:2306.04712v1 [hep-ex])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04712
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#21487;&#24494;&#20998;&#30340;&#24555;&#36895;&#36924;&#36817;&#26041;&#27861;&#65292;&#35757;&#32451;&#20102;&#19968;&#20010;&#32534;&#30721;&#22120;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#39640;&#20142;LHC&#25968;&#25454;&#30340;&#21387;&#32553;&#65292;&#21516;&#26102;&#20445;&#30041;&#20102;&#25968;&#25454;&#20869;&#19982;&#31890;&#23376;&#25506;&#27979;&#22120;&#20013;&#30340;&#33021;&#37327;&#27785;&#31215;&#20998;&#24067;&#30456;&#20851;&#30340;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22320;&#29699;&#31227;&#21160;&#36317;&#31163;(EMD)&#26159;&#22270;&#20687;&#35782;&#21035;&#21644;&#20998;&#31867;&#30340;&#26377;&#29992;&#25351;&#26631;&#65292;&#20294;&#20854;&#36890;&#24120;&#23454;&#29616;&#19981;&#21487;&#24494;&#20998;&#25110;&#36807;&#20110;&#32531;&#24930;&#65292;&#26080;&#27861;&#29992;&#20316;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#20854;&#20182;&#31639;&#27861;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;&#26412;&#25991;&#35757;&#32451;&#20102;&#19968;&#20010;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;(CNN)&#65292;&#23398;&#20064;&#20102;&#21487;&#24494;&#20998;&#30340;&#12289;&#24555;&#36895;&#30340;EMD&#30340;&#36924;&#36817;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#23427;&#21487;&#20197;&#29992;&#20316;&#35745;&#31639;&#23494;&#38598;&#30340;EMD&#23454;&#29616;&#30340;&#26367;&#20195;&#21697;&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#21487;&#24494;&#20998;&#30340;&#36924;&#36817;&#26041;&#27861;&#24212;&#29992;&#20110;&#29992;&#20110;&#25968;&#25454;&#21387;&#32553;&#30340;&#31867;&#33258;&#32534;&#30721;&#31070;&#32463;&#32593;&#32476;(encoder NN)&#30340;&#35757;&#32451;&#65292;&#36825;&#20123;&#25968;&#25454;&#26469;&#33258;&#27431;&#27954;&#26680;&#23376;&#30740;&#31350;&#32452;&#32455;&#30340;&#39640;&#20142;LHC&#12290;&#32534;&#30721;&#22120;NN&#30340;&#30446;&#26631;&#26159;&#22312;&#20445;&#30041;&#19982;&#31890;&#23376;&#25506;&#27979;&#22120;&#20013;&#30340;&#33021;&#37327;&#27785;&#31215;&#20998;&#24067;&#30456;&#20851;&#30340;&#20449;&#24687;&#30340;&#21516;&#26102;&#21387;&#32553;&#25968;&#25454;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#20351;&#29992;&#21487;&#24494;&#30340;EMD CNN&#35757;&#32451;&#30340;&#32534;&#30721;&#22120;NN&#30340;&#24615;&#33021;&#36229;&#36234;&#22522;&#20110;&#24179;&#22343;&#24179;&#26041;&#35823;&#24046;&#30340;&#25439;&#22833;&#20989;&#25968;&#30340;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Earth mover's distance (EMD) is a useful metric for image recognition and classification, but its usual implementations are not differentiable or too slow to be used as a loss function for training other algorithms via gradient descent. In this paper, we train a convolutional neural network (CNN) to learn a differentiable, fast approximation of the EMD and demonstrate that it can be used as a substitute for computing-intensive EMD implementations. We apply this differentiable approximation in the training of an autoencoder-inspired neural network (encoder NN) for data compression at the high-luminosity LHC at CERN. The goal of this encoder NN is to compress the data while preserving the information related to the distribution of energy deposits in particle detectors. We demonstrate that the performance of our encoder NN trained using the differentiable EMD CNN surpasses that of training with loss functions based on mean squared error.
&lt;/p&gt;</description></item><item><title>M3ICRO&#26159;&#19968;&#31181;&#22522;&#20110;&#23450;&#21046;MOMMI&#22120;&#20214;&#30340;&#26426;&#22120;&#23398;&#20064;&#20809;&#23376;&#24352;&#37327;&#26680;&#24515;&#65292;&#20855;&#26377;&#36229;&#39640;&#33021;&#25928;&#12289;&#32039;&#20945;&#22411;&#35774;&#35745;&#21644;ML for optics&#20248;&#21270;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#21152;&#36895;&#22270;&#20687;&#35782;&#21035;&#12289;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#31561;&#22810;&#31181;ML&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2305.19505</link><description>&lt;p&gt;
&#22522;&#20110;&#21487;&#32534;&#31243;&#22810;&#25805;&#20316;&#22810;&#27169;&#24178;&#28041;&#30340;&#26426;&#22120;&#23398;&#20064;&#20809;&#23376;&#24352;&#37327;&#26680;&#24515;&#8212;&#8212;M3ICRO
&lt;/p&gt;
&lt;p&gt;
M3ICRO: Machine Learning-Enabled Compact Photonic Tensor Core based on PRogrammable Multi-Operand Multimode Interference. (arXiv:2305.19505v1 [cs.ET])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19505
&lt;/p&gt;
&lt;p&gt;
M3ICRO&#26159;&#19968;&#31181;&#22522;&#20110;&#23450;&#21046;MOMMI&#22120;&#20214;&#30340;&#26426;&#22120;&#23398;&#20064;&#20809;&#23376;&#24352;&#37327;&#26680;&#24515;&#65292;&#20855;&#26377;&#36229;&#39640;&#33021;&#25928;&#12289;&#32039;&#20945;&#22411;&#35774;&#35745;&#21644;ML for optics&#20248;&#21270;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#21152;&#36895;&#22270;&#20687;&#35782;&#21035;&#12289;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#31561;&#22810;&#31181;ML&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20809;&#23376;&#35745;&#31639;&#23545;&#20110;&#26426;&#22120;&#23398;&#20064;&#21152;&#36895;&#20855;&#26377;&#37325;&#35201;&#20316;&#29992;&#65292;&#20854;&#20855;&#26377;&#36229;&#24555;&#36895;&#24230;&#12289;&#22823;&#35268;&#27169;&#24182;&#34892;&#21644;&#39640;&#33021;&#25928;&#31561;&#20248;&#21183;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#22522;&#20110;&#26631;&#20934;&#20809;&#23398;&#20803;&#20214;&#30340;&#20809;&#23376;&#24352;&#37327;&#26680;&#24515;&#65288;PTC&#65289;&#35774;&#35745;&#30001;&#20110;&#20854;&#36739;&#22823;&#30340;&#31354;&#38388;&#21344;&#29992;&#38754;&#31215;&#32780;&#38480;&#21046;&#20102;&#20854;&#21487;&#25193;&#23637;&#24615;&#21644;&#35745;&#31639;&#23494;&#24230;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#27454;&#21033;&#29992;&#23450;&#21046;&#21487;&#32534;&#31243;&#22810;&#25805;&#20316;&#22810;&#27169;&#24178;&#28041;&#65288;MOMMI&#65289;&#22120;&#20214;&#30340;&#36229;&#32039;&#20945;&#22411;PTC&#65292;&#21517;&#20026;M3ICRO&#12290;&#21487;&#32534;&#31243;&#30340;MOMMI&#21033;&#29992;&#20809;&#30340;&#22266;&#26377;&#20256;&#25773;&#21407;&#29702;&#65292;&#25552;&#20379;&#21333;&#35774;&#22791;&#21487;&#32534;&#31243;&#30697;&#38453;&#21333;&#20803;&#65292;&#36229;&#36234;&#20102;&#20256;&#32479;&#35745;&#31639;&#33539;&#24335;&#20013;&#27599;&#20010;&#35774;&#22791;&#19968;&#20010;&#20056;&#31215;&#32047;&#21152;&#65288;MAC&#65289;&#25805;&#20316;&#30340;&#38480;&#21046;&#12290;&#20026;&#20102;&#35299;&#20915;&#24120;&#35268;&#20248;&#21270;&#25216;&#26415;&#23545;&#23450;&#21046;&#22120;&#20214;&#30340;&#20248;&#21270;&#22256;&#38590;&#65292;&#36890;&#24120;&#38656;&#35201;&#32791;&#36153;&#22823;&#37327;&#26102;&#38388;&#36827;&#34892;&#27169;&#25311;&#65292;&#25105;&#20204;&#20351;&#29992;ML for optics&#26469;&#39044;&#27979;&#22120;&#20214;&#34892;&#20026;&#24182;&#23454;&#29616;&#21487;&#24494;&#20998;&#30340;&#20248;&#21270;&#27969;&#31243;&#12290;&#25105;&#20204;&#20840;&#38754;&#30740;&#31350;&#20102;M3ICRO&#30340;&#21487;&#37325;&#26500;&#24615;&#21644;&#30697;&#38453;&#34920;&#29616;&#21147;&#65292;&#23637;&#31034;&#20102;&#23427;&#30456;&#23545;&#20110;&#29616;&#26377;&#35774;&#35745;&#30340;&#33021;&#25928;&#25552;&#21319;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#21152;&#36895;&#22270;&#20687;&#35782;&#21035;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#31561;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Photonic computing shows promise for transformative advancements in machine learning (ML) acceleration, offering ultra-fast speed, massive parallelism, and high energy efficiency. However, current photonic tensor core (PTC) designs based on standard optical components hinder scalability and compute density due to their large spatial footprint. To address this, we propose an ultra-compact PTC using customized programmable multi-operand multimode interference (MOMMI) devices, named M3ICRO. The programmable MOMMI leverages the intrinsic light propagation principle, providing a single-device programmable matrix unit beyond the conventional computing paradigm of one multiply-accumulate (MAC) operation per device. To overcome the optimization difficulty of customized devices that often requires time-consuming simulation, we apply ML for optics to predict the device behavior and enable a differentiable optimization flow. We thoroughly investigate the reconfigurability and matrix expressivity 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Fitted Likelihood Estimation (FLE)&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#20998;&#24067;&#24335;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#30340;&#38382;&#39064;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#23398;&#20064;&#21040;&#23494;&#20999;&#25509;&#36817;&#30495;&#23454;&#20998;&#24067;&#30340;&#31574;&#30053;&#22238;&#25253;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2302.09456</link><description>&lt;p&gt;
&#20855;&#26377;&#39044;&#27979;&#35823;&#24046;&#20445;&#35777;&#30340;&#20998;&#24067;&#24335;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Distributional Offline Policy Evaluation with Predictive Error Guarantees. (arXiv:2302.09456v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09456
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Fitted Likelihood Estimation (FLE)&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#20998;&#24067;&#24335;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#30340;&#38382;&#39064;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#23398;&#20064;&#21040;&#23494;&#20999;&#25509;&#36817;&#30495;&#23454;&#20998;&#24067;&#30340;&#31574;&#30053;&#22238;&#25253;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20351;&#29992;&#38750;&#31574;&#30053;&#29983;&#25104;&#30340;&#31163;&#32447;&#25968;&#25454;&#38598;&#26469;&#20272;&#31639;&#31574;&#30053;&#22238;&#25253;&#20998;&#24067;&#30340;&#38382;&#39064;&#65292;&#21363;&#20998;&#24067;&#24335;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#65288;OPE&#65289;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Fitted Likelihood Estimation&#65288;FLE&#65289;&#30340;&#31639;&#27861;&#65292;&#23427;&#25191;&#34892;&#20102;&#19968;&#31995;&#21015;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65292;&#20855;&#26377;&#23558;&#20219;&#20309;&#26368;&#20808;&#36827;&#30340;&#27010;&#29575;&#29983;&#25104;&#27169;&#22411;&#38598;&#25104;&#30340;&#28789;&#27963;&#24615;&#65292;&#21482;&#35201;&#23427;&#21487;&#20197;&#36890;&#36807;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#36827;&#34892;&#35757;&#32451;&#12290;FLE&#33021;&#22815;&#29992;&#20110;&#26377;&#38480;&#25110;&#26080;&#38480;&#26102;&#38388;&#25240;&#25187;&#35774;&#32622;&#65292;&#20854;&#20013;&#22870;&#21169;&#21487;&#20197;&#26159;&#22810;&#32500;&#21521;&#37327;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#34920;&#26126;&#65292;&#26080;&#35770;&#26159;&#22312;&#26377;&#38480;&#26102;&#38388;&#25240;&#25187;&#35774;&#32622;&#36824;&#26159;&#26080;&#38480;&#26102;&#38388;&#25240;&#25187;&#35774;&#32622;&#19979;&#65292;FLE&#37117;&#21487;&#20197;&#23398;&#20064;&#21040;&#23494;&#20999;&#25509;&#36817;&#30495;&#23454;&#20998;&#24067;&#30340;&#20998;&#24067;&#65292;&#20998;&#21035;&#22312;&#24635;&#21464;&#24046;&#36317;&#31163;&#21644;Wasserstein&#36317;&#31163;&#19979;&#12290;&#22312;&#35757;&#32451;MLE&#36807;&#31243;&#25104;&#21151;&#26102;&#65292;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#36866;&#29992;&#20110;&#31163;&#32447;&#25968;&#25454;&#35206;&#30422;&#27979;&#35797;&#31574;&#30053;&#30165;&#36857;&#30340;&#26465;&#20214;&#12290;&#22312;&#23454;&#39564;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;FLE&#22312;&#21508;&#31181;&#29615;&#22659;&#20013;&#37117;&#33021;&#21462;&#24471;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of estimating the distribution of the return of a policy using an offline dataset that is not generated from the policy, i.e., distributional offline policy evaluation (OPE). We propose an algorithm called Fitted Likelihood Estimation (FLE), which conducts a sequence of Maximum Likelihood Estimation (MLE) and has the flexibility of integrating any state-of-the-art probabilistic generative models as long as it can be trained via MLE. FLE can be used for both finite-horizon and infinite-horizon discounted settings where rewards can be multi-dimensional vectors. Our theoretical results show that for both finite-horizon and infinite-horizon discounted settings, FLE can learn distributions that are close to the ground truth under total variation distance and Wasserstein distance, respectively. Our theoretical results hold under the conditions that the offline data covers the test policy's traces and that the supervised learning MLE procedures succeed. Experimentally, we
&lt;/p&gt;</description></item></channel></rss>