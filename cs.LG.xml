<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#35780;&#35770;&#23478;-&#28436;&#21592;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#38271;&#26399;&#24179;&#22343;&#22870;&#21169;&#35774;&#32622;&#20013;&#30340;&#20989;&#25968;&#36924;&#36817;&#38382;&#39064;&#65292;&#24182;&#36827;&#34892;&#20102;&#26377;&#38480;&#26102;&#38388;&#20998;&#26512;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#33021;&#22815;&#22312;&#35780;&#35770;&#23478;&#30340;&#22343;&#26041;&#35823;&#24046;&#19978;&#30028;&#20026;$\epsilon$&#30340;&#24773;&#20917;&#19979;&#65292;&#33719;&#24471;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\mathcal{\tilde{O}}(\epsilon^{-2.08})$&#65292;&#20248;&#20110;&#28436;&#21592;-&#35780;&#35770;&#23478;&#31639;&#27861;&#30340;&#32467;&#26524;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01371</link><description>&lt;p&gt;
Critic-Actor&#31639;&#27861;&#22312;&#24179;&#22343;&#22870;&#21169;MDPs&#20013;&#30340;&#20989;&#25968;&#36924;&#36817;&#38382;&#39064;&#65306;&#26377;&#38480;&#26102;&#38388;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Critic-Actor for Average Reward MDPs with Function Approximation: A Finite-Time Analysis
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01371
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#35780;&#35770;&#23478;-&#28436;&#21592;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#38271;&#26399;&#24179;&#22343;&#22870;&#21169;&#35774;&#32622;&#20013;&#30340;&#20989;&#25968;&#36924;&#36817;&#38382;&#39064;&#65292;&#24182;&#36827;&#34892;&#20102;&#26377;&#38480;&#26102;&#38388;&#20998;&#26512;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#33021;&#22815;&#22312;&#35780;&#35770;&#23478;&#30340;&#22343;&#26041;&#35823;&#24046;&#19978;&#30028;&#20026;$\epsilon$&#30340;&#24773;&#20917;&#19979;&#65292;&#33719;&#24471;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\mathcal{\tilde{O}}(\epsilon^{-2.08})$&#65292;&#20248;&#20110;&#28436;&#21592;-&#35780;&#35770;&#23478;&#31639;&#27861;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#20851;&#20110;&#20004;&#20010;&#26102;&#38388;&#23610;&#24230;&#28436;&#21592;-&#35780;&#35770;&#23478;&#31639;&#27861;&#30340;&#28176;&#36817;&#21644;&#38750;&#28176;&#36817;&#25910;&#25947;&#20998;&#26512;&#30340;&#30740;&#31350;&#24037;&#20316;&#38750;&#24120;&#27963;&#36291;&#65292;&#20854;&#20013;&#28436;&#21592;&#30340;&#26356;&#26032;&#36895;&#24230;&#27604;&#35780;&#35770;&#23478;&#24930;&#12290;&#22312;&#26368;&#36817;&#30340;&#19968;&#39033;&#24037;&#20316;&#20013;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#35780;&#35770;&#23478;-&#28436;&#21592;&#31639;&#27861;&#65292;&#29992;&#20110;&#26080;&#38480;&#26102;&#22495;&#25240;&#25187;&#25104;&#26412;&#35774;&#32622;&#20013;&#30340;&#26597;&#25214;&#34920;&#24773;&#20917;&#65292;&#20854;&#20013;&#28436;&#21592;&#21644;&#35780;&#35770;&#23478;&#30340;&#26102;&#38388;&#23610;&#24230;&#30456;&#21453;&#65292;&#24182;&#32473;&#20986;&#20102;&#28176;&#36817;&#25910;&#25947;&#20998;&#26512;&#12290;&#22312;&#25105;&#20204;&#30340;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#25552;&#20986;&#20102;&#19968;&#20010;&#20855;&#26377;&#20989;&#25968;&#36924;&#36817;&#30340;&#35780;&#35770;&#23478;-&#28436;&#21592;&#31639;&#27861;&#65292;&#24182;&#22312;&#38271;&#26399;&#24179;&#22343;&#22870;&#21169;&#35774;&#32622;&#20013;&#36827;&#34892;&#20102;&#39318;&#27425;&#26377;&#38480;&#26102;&#38388;&#65288;&#38750;&#28176;&#36817;&#65289;&#20998;&#26512;&#12290;&#25105;&#20204;&#24471;&#21040;&#20102;&#26368;&#20248;&#30340;&#23398;&#20064;&#36895;&#29575;&#65292;&#24182;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#20174;&#35780;&#35770;&#23478;&#30340;&#22343;&#26041;&#35823;&#24046;&#19978;&#30028;&#20026;$\epsilon$&#65292;&#20854;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\mathcal{\tilde{O}}(\epsilon^{-2.08})$&#65292;&#27492;&#32467;&#26524;&#27604;&#28436;&#21592;-&#35780;&#35770;&#23478;&#31639;&#27861;&#33719;&#24471;&#30340;&#32467;&#26524;&#35201;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, there has been a lot of research work activity focused on carrying out asymptotic and non-asymptotic convergence analyses for two-timescale actor critic algorithms where the actor updates are performed on a timescale that is slower than that of the critic. In a recent work, the critic-actor algorithm has been presented for the infinite horizon discounted cost setting in the look-up table case where the timescales of the actor and the critic are reversed and asymptotic convergence analysis has been presented. In our work, we present the first critic-actor algorithm with function approximation and in the long-run average reward setting and present the first finite-time (non-asymptotic) analysis of such a scheme. We obtain optimal learning rates and prove that our algorithm achieves a sample complexity of $\mathcal{\tilde{O}}(\epsilon^{-2.08})$ for the mean squared error of the critic to be upper bounded by $\epsilon$ which is better than the one obtained for actor-critic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#26465;&#20214;&#21270;&#27491;&#21017;&#21270;&#27969;&#21644;&#20027;&#21160;&#23398;&#20064;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#31895;&#31890;&#21270;&#20998;&#23376;&#34920;&#31034;&#20013;&#30340;&#29627;&#23572;&#20857;&#26364;&#20998;&#24067;&#37319;&#26679;&#38382;&#39064;&#65292;&#30456;&#27604;&#20256;&#32479;&#30340;&#20998;&#23376;&#21160;&#21147;&#23398;&#27169;&#25311;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#33719;&#24471;&#26356;&#39640;&#25928;&#30340;&#21152;&#36895;&#25928;&#26524;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01195</link><description>&lt;p&gt;
&#26465;&#20214;&#21270;&#27491;&#21017;&#21270;&#27969;&#29992;&#20110;&#31895;&#31890;&#21270;&#20998;&#23376;&#34920;&#31034;&#30340;&#20027;&#21160;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Conditional Normalizing Flows for Active Learning of Coarse-Grained Molecular Representations
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01195
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#26465;&#20214;&#21270;&#27491;&#21017;&#21270;&#27969;&#21644;&#20027;&#21160;&#23398;&#20064;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#31895;&#31890;&#21270;&#20998;&#23376;&#34920;&#31034;&#20013;&#30340;&#29627;&#23572;&#20857;&#26364;&#20998;&#24067;&#37319;&#26679;&#38382;&#39064;&#65292;&#30456;&#27604;&#20256;&#32479;&#30340;&#20998;&#23376;&#21160;&#21147;&#23398;&#27169;&#25311;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#33719;&#24471;&#26356;&#39640;&#25928;&#30340;&#21152;&#36895;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#25928;&#37319;&#26679;&#20998;&#23376;&#31995;&#32479;&#30340;&#29627;&#23572;&#20857;&#26364;&#20998;&#24067;&#26159;&#19968;&#20010;&#38271;&#26399;&#23384;&#22312;&#30340;&#25361;&#25112;&#12290;&#26368;&#36817;&#65292;&#19982;&#29983;&#25104;&#38271;&#26102;&#38388;&#20998;&#23376;&#21160;&#21147;&#23398;&#27169;&#25311;&#19981;&#21516;&#65292;&#29983;&#25104;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22914;&#27491;&#21017;&#21270;&#27969;&#34987;&#29992;&#20110;&#30452;&#25509;&#23398;&#20064;&#29627;&#23572;&#20857;&#26364;&#20998;&#24067;&#65292;&#32780;&#19981;&#38656;&#35201;&#26679;&#26412;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#23481;&#26131;&#20986;&#29616;&#27169;&#24335;&#23849;&#28291;&#65292;&#22240;&#27492;&#24120;&#24120;&#26080;&#27861;&#25506;&#32034;&#20840;&#37096;&#30340;&#26500;&#22411;&#31354;&#38388;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23558;&#38382;&#39064;&#20998;&#20026;&#20004;&#20010;&#23618;&#27425;&#65292;&#32454;&#31890;&#24230;&#21644;&#31895;&#31890;&#24230;&#33258;&#30001;&#24230;&#12290;&#22312;&#31895;&#31890;&#21270;&#31354;&#38388;&#19978;&#26465;&#20214;&#21270;&#27491;&#21017;&#21270;&#27969;&#21487;&#20197;&#20135;&#29983;&#20004;&#20010;&#23618;&#27425;&#20043;&#38388;&#30340;&#27010;&#29575;&#36830;&#25509;&#12290;&#20026;&#20102;&#25506;&#32034;&#26500;&#22411;&#31354;&#38388;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#31895;&#31890;&#21270;&#27169;&#25311;&#19982;&#20027;&#21160;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#24517;&#35201;&#26102;&#26356;&#26032;&#27969;&#24182;&#36827;&#34892;&#20840;&#21407;&#23376;&#21183;&#33021;&#35780;&#20272;&#12290;&#20197;&#19993;&#27688;&#37240;&#20108;&#32957;&#20026;&#20363;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30456;&#23545;&#20110;&#20998;&#23376;&#21160;&#21147;&#23398;&#27169;&#25311;&#30340;&#21152;&#36895;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Efficient sampling of the Boltzmann distribution of molecular systems is a long-standing challenge. Recently, instead of generating long molecular dynamics simulations, generative machine learning methods such as normalizing flows have been used to learn the Boltzmann distribution directly, without samples. However, this approach is susceptible to mode collapse and thus often does not explore the full configurational space. In this work, we address this challenge by separating the problem into two levels, the fine-grained and coarse-grained degrees of freedom. A normalizing flow conditioned on the coarse-grained space yields a probabilistic connection between the two levels. To explore the configurational space, we employ coarse-grained simulations with active learning which allows us to update the flow and make all-atom potential energy evaluations only when necessary. Using alanine dipeptide as an example, we show that our methods obtain a speedup to molecular dynamics simulations of
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#28145;&#20837;&#30740;&#31350;Transformer-based&#35821;&#35328;&#27169;&#22411;&#22312;&#20107;&#23454;&#22238;&#24518;&#20219;&#21153;&#20013;&#30340;&#26426;&#21046;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#38646;/&#23569;&#27425;&#26679;&#26412;&#24773;&#20917;&#19979;&#30340;&#29305;&#23450;&#20219;&#21153;&#22836;&#12289;MLP&#23618;&#21644;&#27531;&#24046;&#27969;&#30340;&#21151;&#33021;&#65292;&#20197;&#21450;&#25239;&#36807;&#24230;&#33258;&#20449;&#26426;&#21046;&#12290;</title><link>https://arxiv.org/abs/2403.19521</link><description>&lt;p&gt;
&#35299;&#37322;&#22522;&#20110;Transformer&#27169;&#22411;&#30340;&#35821;&#35328;&#27169;&#22411;&#22312;&#20107;&#23454;&#22238;&#24518;&#20013;&#30340;&#20851;&#38190;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Interpreting Key Mechanisms of Factual Recall in Transformer-Based Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19521
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#28145;&#20837;&#30740;&#31350;Transformer-based&#35821;&#35328;&#27169;&#22411;&#22312;&#20107;&#23454;&#22238;&#24518;&#20219;&#21153;&#20013;&#30340;&#26426;&#21046;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#38646;/&#23569;&#27425;&#26679;&#26412;&#24773;&#20917;&#19979;&#30340;&#29305;&#23450;&#20219;&#21153;&#22836;&#12289;MLP&#23618;&#21644;&#27531;&#24046;&#27969;&#30340;&#21151;&#33021;&#65292;&#20197;&#21450;&#25239;&#36807;&#24230;&#33258;&#20449;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#28145;&#20837;&#25506;&#35752;&#20102;Transformer-based&#35821;&#35328;&#27169;&#22411;&#22312;&#20107;&#23454;&#22238;&#24518;&#20219;&#21153;&#20013;&#25152;&#37319;&#29992;&#30340;&#26426;&#21046;&#12290;&#22312;&#38646;&#27425;&#26679;&#26412;&#24773;&#20917;&#19979;&#65292;&#32473;&#23450;&#31867;&#20284;&#8220;&#27861;&#22269;&#30340;&#39318;&#37117;&#26159;&#8221;&#30340;&#25552;&#31034;&#65292;&#29305;&#23450;&#20219;&#21153;&#30340;&#27880;&#24847;&#21147;&#22836;&#20250;&#20174;&#19978;&#19979;&#25991;&#20013;&#25552;&#21462;&#20027;&#39064;&#23454;&#20307;&#65292;&#22914;&#8220;&#27861;&#22269;&#8221;&#65292;&#24182;&#23558;&#20854;&#20256;&#36882;&#32473;&#21518;&#32493;&#30340;MLP&#20197;&#22238;&#24518;&#25152;&#38656;&#30340;&#31572;&#26696;&#65292;&#22914;&#8220;&#24052;&#40654;&#8221;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#26512;&#26041;&#27861;&#65292;&#26088;&#22312;&#23558;MLP&#30340;&#36755;&#20986;&#20998;&#35299;&#20026;&#20154;&#31867;&#21487;&#29702;&#35299;&#30340;&#32452;&#20214;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#65292;&#25105;&#20204;&#37327;&#21270;&#20102;&#36319;&#38543;&#36825;&#20123;&#29305;&#23450;&#20219;&#21153;&#22836;&#30340;MLP&#23618;&#30340;&#21151;&#33021;&#12290;&#22312;&#27531;&#24046;&#27969;&#20013;&#65292;&#23427;&#20250;&#25830;&#38500;&#25110;&#25918;&#22823;&#26469;&#33258;&#21508;&#20010;&#22836;&#30340;&#20449;&#24687;&#12290;&#27492;&#22806;&#65292;&#23427;&#20250;&#29983;&#25104;&#19968;&#20010;&#32452;&#20214;&#65292;&#23558;&#27531;&#24046;&#27969;&#37325;&#26032;&#23450;&#21521;&#21040;&#39044;&#26399;&#31572;&#26696;&#30340;&#26041;&#21521;&#12290;&#36825;&#20123;&#38646;&#27425;&#26426;&#21046;&#20063;&#36866;&#29992;&#20110;&#23569;&#27425;&#26679;&#26412;&#24773;&#20917;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#19968;&#31181;&#24191;&#27867;&#23384;&#22312;&#30340;&#25239;&#36807;&#24230;&#33258;&#20449;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19521v1 Announce Type: cross  Abstract: In this paper, we deeply explore the mechanisms employed by Transformer-based language models in factual recall tasks. In zero-shot scenarios, given a prompt like "The capital of France is," task-specific attention heads extract the topic entity, such as "France," from the context and pass it to subsequent MLPs to recall the required answer such as "Paris." We introduce a novel analysis method aimed at decomposing the outputs of the MLP into components understandable by humans. Through this method, we quantify the function of the MLP layer following these task-specific heads. In the residual stream, it either erases or amplifies the information originating from individual heads. Moreover, it generates a component that redirects the residual stream towards the direction of its expected answer. These zero-shot mechanisms are also employed in few-shot scenarios. Additionally, we observed a widely existent anti-overconfidence mechanism in 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;MoE&#27169;&#22411;\tool&#65292;&#36890;&#36807;&#21033;&#29992;&#23567;&#22411;&#19987;&#23478;&#21644;&#22522;&#20110;&#38408;&#20540;&#30340;&#36335;&#30001;&#22120;&#65292;&#20351;&#26631;&#35760;&#33021;&#22815;&#36873;&#25321;&#24615;&#22320;&#20165;&#28041;&#21450;&#21040;&#24517;&#35201;&#30340;&#21442;&#25968;&#65292;&#20174;&#32780;&#22312;&#20943;&#23569;MoE&#23618;&#35745;&#31639;&#36127;&#36733;50%&#20197;&#19978;&#30340;&#21516;&#26102;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.18926</link><description>&lt;p&gt;
&#29992;&#26356;&#31232;&#30095;&#30340;&#36873;&#25321;&#25552;&#39640;&#31232;&#30095;&#27169;&#22411;&#30340;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;
Enhancing Efficiency in Sparse Models with Sparser Selection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18926
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;MoE&#27169;&#22411;\tool&#65292;&#36890;&#36807;&#21033;&#29992;&#23567;&#22411;&#19987;&#23478;&#21644;&#22522;&#20110;&#38408;&#20540;&#30340;&#36335;&#30001;&#22120;&#65292;&#20351;&#26631;&#35760;&#33021;&#22815;&#36873;&#25321;&#24615;&#22320;&#20165;&#28041;&#21450;&#21040;&#24517;&#35201;&#30340;&#21442;&#25968;&#65292;&#20174;&#32780;&#22312;&#20943;&#23569;MoE&#23618;&#35745;&#31639;&#36127;&#36733;50%&#20197;&#19978;&#30340;&#21516;&#26102;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#27169;&#22411;&#65292;&#21253;&#25324;&#31232;&#30095;&#30340;&#19987;&#23478;&#28151;&#21512;&#65288;MoE&#65289;&#27169;&#22411;&#65292;&#24050;&#32463;&#25104;&#20026;&#32553;&#25918;Transformer&#27169;&#22411;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#36890;&#24120;&#23384;&#22312;&#35745;&#31639;&#25928;&#29575;&#20302;&#30340;&#38382;&#39064;&#65292;&#22240;&#20026;&#22823;&#37327;&#21442;&#25968;&#36890;&#36807;&#23558;&#20540;&#20056;&#20197;&#38646;&#25110;&#20302;&#28608;&#27963;&#20540;&#26080;&#35859;&#21442;&#19982;&#35745;&#31639;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;\tool &#30340;&#26032;&#39062;MoE&#27169;&#22411;&#65292;&#26088;&#22312;&#25552;&#21319;&#31232;&#30095;MoE&#27169;&#22411;&#30340;&#21151;&#25928;&#21644;&#25928;&#29575;&#12290; \tool &#21033;&#29992;&#23567;&#22411;&#19987;&#23478;&#21644;&#22522;&#20110;&#38408;&#20540;&#30340;&#36335;&#30001;&#22120;&#65292;&#20351;&#26631;&#35760;&#33021;&#22815;&#36873;&#25321;&#24615;&#22320;&#20165;&#28041;&#21450;&#21040;&#24517;&#35201;&#30340;&#21442;&#25968;&#12290;&#25105;&#20204;&#22312;&#35821;&#35328;&#24314;&#27169;&#21644;&#26426;&#22120;&#32763;&#35793;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;\tool &#21487;&#20197;&#22312;&#19981;&#29306;&#29298;&#24615;&#33021;&#30340;&#24773;&#20917;&#19979;&#65292;&#23558;MoE&#23618;&#30340;&#35745;&#31639;&#36127;&#36733;&#20943;&#23569;50\%&#20197;&#19978;&#65292;&#21516;&#26102;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;\tool &#30340;&#36890;&#29992;&#24615;&#65292;&#36890;&#36807;&#23558;&#20854;&#24212;&#29992;&#20110;&#23494;&#38598;&#27169;&#22411;&#65292;&#22312;&#25512;&#26029;&#26399;&#38388;&#23454;&#29616;&#31232;&#30095;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18926v1 Announce Type: cross  Abstract: Sparse models, including sparse Mixture-of-Experts (MoE) models, have emerged as an effective approach for scaling Transformer models. However, they often suffer from computational inefficiency since a significant number of parameters are unnecessarily involved in computations via multiplying values by zero or low activation values. To address this issue, we present \tool, a novel MoE designed to enhance both the efficacy and efficiency of sparse MoE models. \tool leverages small experts and a threshold-based router to enable tokens to selectively engage only essential parameters. Our extensive experiments on language modeling and machine translation tasks demonstrate that \tool can enhance model performance while decreasing the computation load at MoE layers by over 50\% without sacrificing performance. Furthermore, we present the versatility of \tool by applying it to dense models, enabling sparse computation during inference. We pro
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20272;&#35745;&#36890;&#36947;&#25968;&#25454;&#22686;&#24378;&#25216;&#26415;&#23545;&#36965;&#24863;&#22270;&#20687;&#29289;&#29702;&#20449;&#24687;&#19968;&#33268;&#24615;&#24433;&#21709;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#36825;&#19968;&#39046;&#22495;&#20013;&#23384;&#22312;&#30340;&#20105;&#35758;&#12290;</title><link>https://arxiv.org/abs/2403.14547</link><description>&lt;p&gt;
&#20272;&#35745;&#36890;&#36947;&#25968;&#25454;&#22686;&#24378;&#23545;&#36965;&#24863;&#22270;&#20687;&#29289;&#29702;&#20449;&#24687;&#19968;&#33268;&#24615;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Estimating Physical Information Consistency of Channel Data Augmentation for Remote Sensing Images
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14547
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20272;&#35745;&#36890;&#36947;&#25968;&#25454;&#22686;&#24378;&#25216;&#26415;&#23545;&#36965;&#24863;&#22270;&#20687;&#29289;&#29702;&#20449;&#24687;&#19968;&#33268;&#24615;&#24433;&#21709;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#36825;&#19968;&#39046;&#22495;&#20013;&#23384;&#22312;&#30340;&#20105;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#22686;&#24378;&#22312;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#20013;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#65292;&#29305;&#21035;&#26159;&#36890;&#36947;&#21464;&#25442;&#34987;&#25972;&#21512;&#21040;&#36965;&#24863;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#30340;&#25968;&#25454;&#22686;&#24378;&#27969;&#31243;&#20013;&#12290;&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#36890;&#36947;&#22686;&#24378;&#25216;&#26415;&#26159;&#21542;&#20250;&#24433;&#21709;&#36965;&#24863;&#22270;&#20687;&#30340;&#29289;&#29702;&#20449;&#24687;&#65292;&#20197;&#35299;&#20915;&#20154;&#20204;&#23545;&#20854;&#22312;&#36965;&#24863;&#22270;&#20687;&#19978;&#30340;&#36866;&#29992;&#24615;&#23384;&#22312;&#20105;&#35758;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14547v1 Announce Type: cross  Abstract: The application of data augmentation for deep learning (DL) methods plays an important role in achieving state-of-the-art results in supervised, semi-supervised, and self-supervised image classification. In particular, channel transformations (e.g., solarize, grayscale, brightness adjustments) are integrated into data augmentation pipelines for remote sensing (RS) image classification tasks. However, contradicting beliefs exist about their proper applications to RS images. A common point of critique is that the application of channel augmentation techniques may lead to physically inconsistent spectral data (i.e., pixel signatures). To shed light on the open debate, we propose an approach to estimate whether a channel augmentation technique affects the physical information of RS images. To this end, the proposed approach estimates a score that measures the alignment of a pixel signature within a time series that can be naturally subject
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20998;&#23618;&#31070;&#32463;&#31526;&#21495;&#33539;&#24335;&#30340;&#21160;&#20316;&#36136;&#37327;&#35780;&#20272;&#26041;&#27861;&#65292;&#22312;&#36339;&#27700;&#20013;&#21462;&#24471;&#20102;&#39046;&#20808;&#30340;&#34920;&#29616;&#65292;&#36890;&#36807;&#20174;&#35270;&#39057;&#25968;&#25454;&#20013;&#25552;&#21462;&#21487;&#35299;&#37322;&#31526;&#21495;&#24182;&#24212;&#29992;&#35268;&#21017;&#36827;&#34892;&#36136;&#37327;&#35780;&#20272;&#65292;&#20248;&#20110;&#31471;&#21040;&#31471;&#31070;&#32463;&#27169;&#22411;&#65292;&#21516;&#26102;&#23454;&#29616;&#20102;&#21160;&#20316;&#35782;&#21035;&#21644;&#26102;&#38388;&#20998;&#21106;&#65292;&#24182;&#29983;&#25104;&#35814;&#32454;&#25253;&#21578;&#12290;</title><link>https://arxiv.org/abs/2403.13798</link><description>&lt;p&gt;
&#20998;&#23618;&#31070;&#32463;&#31526;&#21495;&#26041;&#27861;&#29992;&#20110;&#21160;&#20316;&#36136;&#37327;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Hierarchical NeuroSymbolic Approach for Action Quality Assessment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13798
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20998;&#23618;&#31070;&#32463;&#31526;&#21495;&#33539;&#24335;&#30340;&#21160;&#20316;&#36136;&#37327;&#35780;&#20272;&#26041;&#27861;&#65292;&#22312;&#36339;&#27700;&#20013;&#21462;&#24471;&#20102;&#39046;&#20808;&#30340;&#34920;&#29616;&#65292;&#36890;&#36807;&#20174;&#35270;&#39057;&#25968;&#25454;&#20013;&#25552;&#21462;&#21487;&#35299;&#37322;&#31526;&#21495;&#24182;&#24212;&#29992;&#35268;&#21017;&#36827;&#34892;&#36136;&#37327;&#35780;&#20272;&#65292;&#20248;&#20110;&#31471;&#21040;&#31471;&#31070;&#32463;&#27169;&#22411;&#65292;&#21516;&#26102;&#23454;&#29616;&#20102;&#21160;&#20316;&#35782;&#21035;&#21644;&#26102;&#38388;&#20998;&#21106;&#65292;&#24182;&#29983;&#25104;&#35814;&#32454;&#25253;&#21578;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21160;&#20316;&#36136;&#37327;&#35780;&#20272;&#65288;AQA&#65289;&#24212;&#29992;&#35745;&#31639;&#26426;&#35270;&#35273;&#23450;&#37327;&#35780;&#20272;&#20154;&#31867;&#21160;&#20316;&#30340;&#34920;&#29616;&#25110;&#25191;&#34892;&#12290;&#24403;&#21069;&#30340;AQA&#26041;&#27861;&#26159;&#31471;&#21040;&#31471;&#30340;&#31070;&#32463;&#27169;&#22411;&#65292;&#32570;&#20047;&#36879;&#26126;&#24230;&#24182;&#19988;&#26131;&#21463;&#20559;&#35265;&#65292;&#22240;&#20026;&#23427;&#20204;&#26159;&#22522;&#20110;&#20027;&#35266;&#20154;&#31867;&#21028;&#26029;&#20316;&#20026;&#22320;&#38754;&#30495;&#30456;&#36827;&#34892;&#35757;&#32451;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;AQA&#30340;&#31070;&#32463;&#31526;&#21495;&#33539;&#24335;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#20174;&#35270;&#39057;&#25968;&#25454;&#20013;&#25277;&#35937;&#20986;&#21487;&#35299;&#37322;&#30340;&#31526;&#21495;&#65292;&#24182;&#36890;&#36807;&#23558;&#35268;&#21017;&#24212;&#29992;&#20110;&#36825;&#20123;&#31526;&#21495;&#36827;&#34892;&#36136;&#37327;&#35780;&#20272;&#12290;&#25105;&#20204;&#20197;&#36339;&#27700;&#20026;&#26696;&#20363;&#30740;&#31350;&#12290;&#25105;&#20204;&#21457;&#29616;&#39046;&#22495;&#19987;&#23478;&#26356;&#21916;&#27426;&#25105;&#20204;&#30340;&#31995;&#32479;&#65292;&#24182;&#21457;&#29616;&#20854;&#27604;&#32431;&#31070;&#32463;&#26041;&#27861;&#26356;&#20855;&#20449;&#24687;&#37327;&#12290;&#25105;&#20204;&#30340;&#31995;&#32479;&#36824;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#21160;&#20316;&#35782;&#21035;&#21644;&#26102;&#38388;&#20998;&#21106;&#65292;&#24182;&#33258;&#21160;&#29983;&#25104;&#20102;&#19968;&#20221;&#35814;&#32454;&#25253;&#21578;&#65292;&#23558;&#36339;&#27700;&#20998;&#35299;&#20026;&#20854;&#20803;&#32032;&#65292;&#24182;&#25552;&#20379;&#24102;&#26377;&#35270;&#35273;&#35777;&#25454;&#30340;&#23458;&#35266;&#35780;&#20998;&#12290;&#32463;&#19968;&#32452;&#39046;&#22495;&#19987;&#23478;&#39564;&#35777;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13798v1 Announce Type: cross  Abstract: Action quality assessment (AQA) applies computer vision to quantitatively assess the performance or execution of a human action. Current AQA approaches are end-to-end neural models, which lack transparency and tend to be biased because they are trained on subjective human judgements as ground-truth. To address these issues, we introduce a neuro-symbolic paradigm for AQA, which uses neural networks to abstract interpretable symbols from video data and makes quality assessments by applying rules to those symbols. We take diving as the case study. We found that domain experts prefer our system and find it more informative than purely neural approaches to AQA in diving. Our system also achieves state-of-the-art action recognition and temporal segmentation, and automatically generates a detailed report that breaks the dive down into its elements and provides objective scoring with visual evidence. As verified by a group of domain experts, t
&lt;/p&gt;</description></item><item><title>UPS&#36890;&#36807;&#36328;&#27169;&#24577;&#36866;&#24212;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#65292;&#23558;&#19981;&#21516;PDE&#32479;&#19968;&#21040;&#19968;&#33268;&#30340;&#34920;&#31034;&#31354;&#38388;&#65292;&#24182;&#22312;&#23569;&#26679;&#26412;&#19979;&#36798;&#21040;&#20102;&#24378;&#26377;&#21147;&#30340;&#23454;&#39564;&#32467;&#26524;&#65292;&#20248;&#20110;&#29616;&#26377;&#22522;&#32447;&#65292;&#23454;&#29616;&#20102;1D&#21644;2D&#25968;&#25454;&#38598;&#19978;&#30340;&#26368;&#20808;&#36827;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.07187</link><description>&lt;p&gt;
UPS: &#36890;&#36807;&#36328;&#27169;&#24577;&#36866;&#24212;&#23454;&#29616;&#20559;&#24494;&#20998;&#26041;&#31243;&#27714;&#35299;&#30340;&#22522;&#30784;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
UPS: Towards Foundation Models for PDE Solving via Cross-Modal Adaptation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07187
&lt;/p&gt;
&lt;p&gt;
UPS&#36890;&#36807;&#36328;&#27169;&#24577;&#36866;&#24212;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#65292;&#23558;&#19981;&#21516;PDE&#32479;&#19968;&#21040;&#19968;&#33268;&#30340;&#34920;&#31034;&#31354;&#38388;&#65292;&#24182;&#22312;&#23569;&#26679;&#26412;&#19979;&#36798;&#21040;&#20102;&#24378;&#26377;&#21147;&#30340;&#23454;&#39564;&#32467;&#26524;&#65292;&#20248;&#20110;&#29616;&#26377;&#22522;&#32447;&#65292;&#23454;&#29616;&#20102;1D&#21644;2D&#25968;&#25454;&#38598;&#19978;&#30340;&#26368;&#20808;&#36827;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;UPS&#65288;&#32479;&#19968;PDE&#27714;&#35299;&#22120;&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#25968;&#25454;&#39640;&#25928;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#19981;&#21516;&#22495;&#12289;&#32500;&#24230;&#21644;&#20998;&#36776;&#29575;&#19978;&#23450;&#20041;&#30340;&#21508;&#31181;&#26102;&#31354;PDE&#12290;UPS&#23558;&#19981;&#21516;&#30340;PDE&#32479;&#19968;&#21040;&#19968;&#33268;&#30340;&#34920;&#31034;&#31354;&#38388;&#20013;&#65292;&#24182;&#20351;&#29992;&#23558;LLMs&#19982;&#29305;&#23450;&#22495;&#31070;&#32463;&#31639;&#23376;&#30456;&#32467;&#21512;&#30340;&#32479;&#19968;&#32593;&#32476;&#26550;&#26500;&#22788;&#29702;&#21508;&#31181;PDE&#25968;&#25454;&#38598;&#21512;&#12290;&#25105;&#20204;&#36890;&#36807;&#20004;&#38454;&#27573;&#30340;&#36328;&#27169;&#24577;&#36866;&#24212;&#36807;&#31243;&#35757;&#32451;&#32593;&#32476;&#65292;&#21033;&#29992;&#27169;&#24577;&#23545;&#40784;&#21644;&#22810;&#20219;&#21153;&#23398;&#20064;&#30340;&#24605;&#24819;&#12290;&#36890;&#36807;&#20174;&#39044;&#35757;&#32451;&#30340;LLMs&#36827;&#34892;&#35843;&#25972;&#24182;&#21033;&#29992;&#25991;&#26412;&#24418;&#24335;&#30340;&#20803;&#20449;&#24687;&#65292;&#25105;&#20204;&#33021;&#22815;&#20351;&#29992;&#27604;&#20197;&#21069;&#30340;&#26041;&#27861;&#23569;&#24471;&#22810;&#30340;&#35757;&#32451;&#26679;&#26412;&#65292;&#24182;&#33719;&#24471;&#24378;&#26377;&#21147;&#30340;&#23454;&#35777;&#32467;&#26524;&#12290;UPS&#22312;PDEBench&#30340;&#24191;&#27867;1D&#21644;2D&#25968;&#25454;&#38598;&#19978;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#22522;&#32447;&#65292;&#23545;&#32771;&#34385;&#30340;10&#20010;&#20219;&#21153;&#20013;&#30340;8&#20010;&#20219;&#21153;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#23427;&#33021;&#22815;&#23569;&#26679;&#26412;&#24555;&#36895;&#36716;&#31227;&#33267;&#19981;&#21516;&#30340;PDE&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07187v1 Announce Type: new  Abstract: We introduce UPS (Unified PDE Solver), an effective and data-efficient approach to solve diverse spatiotemporal PDEs defined over various domains, dimensions, and resolutions. UPS unifies different PDEs into a consistent representation space and processes diverse collections of PDE data using a unified network architecture that combines LLMs with domain-specific neural operators. We train the network via a two-stage cross-modal adaptation process, leveraging ideas of modality alignment and multi-task learning. By adapting from pretrained LLMs and exploiting text-form meta information, we are able to use considerably fewer training samples than previous methods while obtaining strong empirical results. UPS outperforms existing baselines, often by a large margin, on a wide range of 1D and 2D datasets in PDEBench, achieving state-of-the-art results on 8 of 10 tasks considered. Meanwhile, it is capable of few-shot transfer to different PDE f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22522;&#20110;Flow Matching&#21457;&#23637;&#20102;&#26465;&#20214;&#29983;&#25104;&#29702;&#35770;&#65292;&#36890;&#36807;&#20351;&#29992;&#24191;&#20041;&#36830;&#32493;&#24615;&#26041;&#31243;&#30340;&#25968;&#23398;&#26694;&#26550;&#32780;&#38750;&#27969;&#21305;&#37197;&#20013;&#30340;&#36830;&#32493;&#24615;&#26041;&#31243;&#65292;&#23454;&#29616;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27969;&#22522;&#26465;&#20214;&#20998;&#24067;&#29983;&#25104;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.18839</link><description>&lt;p&gt;
&#25193;&#23637;&#27969;&#21305;&#37197;&#65306;&#20855;&#26377;&#24191;&#20041;&#36830;&#32493;&#24615;&#26041;&#31243;&#30340;&#26465;&#20214;&#29983;&#25104;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Extended Flow Matching: a Method of Conditional Generation with Generalized Continuity Equation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18839
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22522;&#20110;Flow Matching&#21457;&#23637;&#20102;&#26465;&#20214;&#29983;&#25104;&#29702;&#35770;&#65292;&#36890;&#36807;&#20351;&#29992;&#24191;&#20041;&#36830;&#32493;&#24615;&#26041;&#31243;&#30340;&#25968;&#23398;&#26694;&#26550;&#32780;&#38750;&#27969;&#21305;&#37197;&#20013;&#30340;&#36830;&#32493;&#24615;&#26041;&#31243;&#65292;&#23454;&#29616;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27969;&#22522;&#26465;&#20214;&#20998;&#24067;&#29983;&#25104;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26465;&#20214;&#29983;&#25104;&#20219;&#21153;&#26159;&#29983;&#25104;&#27169;&#22411;&#20013;&#26368;&#37325;&#35201;&#30340;&#24212;&#29992;&#20043;&#19968;&#65292;&#36804;&#20170;&#20026;&#27490;&#24050;&#32463;&#24320;&#21457;&#20102;&#35768;&#22810;&#22522;&#20110;&#33879;&#21517;&#25193;&#25955;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#20197;&#22522;&#20110;&#24341;&#23548;&#30340;&#26080;&#20998;&#31867;&#22120;&#26041;&#27861;&#20026;&#39318;&#12290;&#28982;&#32780;&#65292;&#22522;&#20110;&#24341;&#23548;&#30340;&#26041;&#27861;&#30340;&#29702;&#35770;&#19981;&#20165;&#35201;&#27714;&#29992;&#25143;&#24494;&#35843;&#8220;&#24341;&#23548;&#24378;&#24230;&#8221;&#65292;&#32780;&#19988;&#20854;&#30446;&#26631;&#21521;&#37327;&#22330;&#19981;&#19968;&#23450;&#23545;&#24212;&#20110;&#35757;&#32451;&#20013;&#20351;&#29992;&#30340;&#26465;&#20214;&#20998;&#24067;&#12290;&#26412;&#25991;&#22522;&#20110;&#27969;&#21305;&#37197;&#21457;&#23637;&#20102;&#26465;&#20214;&#29983;&#25104;&#29702;&#35770;&#65292;&#27969;&#21305;&#37197;&#26159;&#25193;&#25955;&#26041;&#27861;&#30340;&#24403;&#21069;&#24378;&#22823;&#31454;&#20105;&#32773;&#20043;&#19968;&#12290;&#21463;&#23558;&#27010;&#29575;&#36335;&#24452;&#35299;&#37322;&#20026;&#36335;&#24452;&#31354;&#38388;&#19978;&#30340;&#20998;&#24067;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#27969;&#22522;&#26465;&#20214;&#20998;&#24067;&#29983;&#25104;&#29702;&#35770;&#65292;&#36890;&#36807;&#20351;&#29992;&#24191;&#20041;&#36830;&#32493;&#24615;&#26041;&#31243;&#30340;&#25968;&#23398;&#26694;&#26550;&#32780;&#19981;&#26159;&#27969;&#21305;&#37197;&#20013;&#30340;&#36830;&#32493;&#24615;&#26041;&#31243;&#12290;&#36825;&#19968;&#29702;&#35770;&#33258;&#28982;&#22320;&#25512;&#23548;&#20986;&#19968;&#31181;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18839v1 Announce Type: new  Abstract: The task of conditional generation is one of the most important applications of generative models, and numerous methods have been developed to date based on the celebrated diffusion models, with the guidance-based classifier-free method taking the lead. However, the theory of the guidance-based method not only requires the user to fine-tune the "guidance strength," but its target vector field does not necessarily correspond to the conditional distribution used in training. In this paper, we develop the theory of conditional generation based on Flow Matching, a current strong contender of diffusion methods. Motivated by the interpretation of a probability path as a distribution on path space, we establish a novel theory of flow-based generation of conditional distribution by employing the mathematical framework of generalized continuity equation instead of the continuity equation in flow matching. This theory naturally derives a method th
&lt;/p&gt;</description></item><item><title>&#20848;&#33457;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#30456;&#20851;&#21367;&#31215;&#26426;&#21046;&#65292;&#36890;&#36807;&#21160;&#24577;&#35843;&#25972;&#21367;&#31215;&#26680;&#65292;&#23454;&#29616;&#20102;&#39640;&#34920;&#36798;&#33021;&#21147;&#21644;&#35745;&#31639;&#25928;&#29575;&#30340;&#24179;&#34913;&#12290;</title><link>https://arxiv.org/abs/2402.18508</link><description>&lt;p&gt;
&#20848;&#33457;&#65306;&#28789;&#27963;&#19988;&#25968;&#25454;&#30456;&#20851;&#30340;&#21367;&#31215;&#29992;&#20110;&#24207;&#21015;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Orchid: Flexible and Data-Dependent Convolution for Sequence Modeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18508
&lt;/p&gt;
&lt;p&gt;
&#20848;&#33457;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#30456;&#20851;&#21367;&#31215;&#26426;&#21046;&#65292;&#36890;&#36807;&#21160;&#24577;&#35843;&#25972;&#21367;&#31215;&#26680;&#65292;&#23454;&#29616;&#20102;&#39640;&#34920;&#36798;&#33021;&#21147;&#21644;&#35745;&#31639;&#25928;&#29575;&#30340;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28145;&#24230;&#23398;&#20064;&#19981;&#26029;&#21457;&#23637;&#30340;&#26684;&#23616;&#20013;&#65292;&#24179;&#34913;&#34920;&#36798;&#33021;&#21147;&#19982;&#35745;&#31639;&#25928;&#29575;&#30340;&#27169;&#22411;&#24050;&#32463;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#20848;&#33457;&#65288;Orchid&#65289;&#30340;&#26032;&#22411;&#26550;&#26500;&#65292;&#36890;&#36807;&#21253;&#21547;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#30456;&#20851;&#21367;&#31215;&#26426;&#21046;&#26469;&#37325;&#26032;&#26500;&#24819;&#24207;&#21015;&#24314;&#27169;&#12290;&#20848;&#33457;&#26088;&#22312;&#35299;&#20915;&#20256;&#32479;&#27880;&#24847;&#21147;&#26426;&#21046;&#22266;&#26377;&#30340;&#38480;&#21046;&#65292;&#29305;&#21035;&#26159;&#23427;&#20204;&#30340;&#20108;&#27425;&#22797;&#26434;&#24615;&#65292;&#21516;&#26102;&#19981;&#24433;&#21709;&#25429;&#25417;&#36828;&#31243;&#20381;&#36182;&#24615;&#21644;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#33021;&#21147;&#12290;&#20848;&#33457;&#30340;&#26680;&#24515;&#26159;&#25968;&#25454;&#30456;&#20851;&#21367;&#31215;&#23618;&#65292;&#23427;&#21033;&#29992;&#19987;&#38376;&#30340;&#26465;&#20214;&#21270;&#31070;&#32463;&#32593;&#32476;&#26681;&#25454;&#36755;&#20837;&#25968;&#25454;&#21160;&#24577;&#35843;&#25972;&#20854;&#21367;&#31215;&#26680;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#20004;&#20010;&#31616;&#21333;&#30340;&#26465;&#20214;&#21270;&#32593;&#32476;&#65292;&#20197;&#22312;&#33258;&#36866;&#24212;&#21367;&#31215;&#25805;&#20316;&#20013;&#32500;&#25345;&#24179;&#31227;&#31561;&#21464;&#24615;&#12290;&#25968;&#25454;&#30456;&#20851;&#21367;&#31215;&#26680;&#30340;&#21160;&#24577;&#29305;&#24615;&#65292;&#21152;&#19978;&#38376;&#25511;&#25805;&#20316;&#65292;&#36171;&#20104;&#20102;&#20848;&#33457;&#39640;&#34920;&#36798;&#33021;&#21147;&#65292;&#21516;&#26102;&#32500;&#25345;&#20102;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18508v1 Announce Type: new  Abstract: In the rapidly evolving landscape of deep learning, the quest for models that balance expressivity with computational efficiency has never been more critical. This paper introduces Orchid, a novel architecture that reimagines sequence modeling by incorporating a new data-dependent convolution mechanism. Orchid is designed to address the inherent limitations of traditional attention mechanisms, particularly their quadratic complexity, without compromising the ability to capture long-range dependencies and in-context learning. At the core of Orchid lies the data-dependent convolution layer, which dynamically adjusts its kernel conditioned on input data using a dedicated conditioning neural network. We design two simple conditioning networks that maintain shift equivariance in the adaptive convolution operation. The dynamic nature of data-dependent convolution kernel, coupled with gating operations, grants Orchid high expressivity while mai
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102; DecisionNCE &#26694;&#26550;&#65292;&#36890;&#36807;&#38544;&#24335;&#20559;&#22909;&#23398;&#20064;&#23454;&#20307;&#22810;&#27169;&#24577;&#34920;&#31034;&#65292;&#23454;&#29616;&#20102;&#25552;&#21462;&#20219;&#21153;&#36827;&#23637;&#20449;&#24687;&#21644;&#19982;&#35821;&#35328;&#25351;&#20196;&#23545;&#40784;&#30340;&#26377;&#25928;&#26041;&#27861;</title><link>https://arxiv.org/abs/2402.18137</link><description>&lt;p&gt;
DecisionNCE: &#36890;&#36807;&#38544;&#24335;&#20559;&#22909;&#23398;&#20064;&#23454;&#20307;&#22810;&#27169;&#24577;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
DecisionNCE: Embodied Multimodal Representations via Implicit Preference Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18137
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102; DecisionNCE &#26694;&#26550;&#65292;&#36890;&#36807;&#38544;&#24335;&#20559;&#22909;&#23398;&#20064;&#23454;&#20307;&#22810;&#27169;&#24577;&#34920;&#31034;&#65292;&#23454;&#29616;&#20102;&#25552;&#21462;&#20219;&#21153;&#36827;&#23637;&#20449;&#24687;&#21644;&#19982;&#35821;&#35328;&#25351;&#20196;&#23545;&#40784;&#30340;&#26377;&#25928;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#39044;&#35757;&#32451;&#24050;&#34987;&#35777;&#26126;&#26159;&#33258;&#20027;&#26426;&#22120;&#20154;&#20013;&#34920;&#31034;&#23398;&#20064;&#30340;&#19977;&#22823;&#30446;&#26631;&#65306;1&#65289;&#25552;&#21462;&#23616;&#37096;&#21644;&#20840;&#23616;&#20219;&#21153;&#36827;&#23637;&#20449;&#24687;&#65307;2&#65289;&#24378;&#21270;&#35270;&#35273;&#34920;&#31034;&#30340;&#26102;&#38388;&#19968;&#33268;&#24615;&#65307;3&#65289;&#25429;&#33719;&#36712;&#36857;&#32423;&#35821;&#35328;&#22522;&#30784;&#30340;&#26377;&#25928;&#31574;&#30053;&#12290;&#22823;&#37096;&#20998;&#24050;&#26377;&#26041;&#27861;&#36890;&#36807;&#19981;&#21516;&#30340;&#30446;&#26631;&#26469;&#22788;&#29702;&#36825;&#20123;&#38382;&#39064;&#65292;&#24448;&#24448;&#23548;&#33268;&#27425;&#20248;&#35299;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#32479;&#19968;&#30446;&#26631;&#65292;&#21487;&#20197;&#21516;&#26102;&#20174;&#22270;&#20687;&#24207;&#21015;&#20013;&#25552;&#21462;&#26377;&#24847;&#20041;&#30340;&#20219;&#21153;&#36827;&#23637;&#20449;&#24687;&#65292;&#24182;&#23558;&#23427;&#20204;&#19982;&#35821;&#35328;&#25351;&#20196;&#26080;&#32541;&#23545;&#40784;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#36890;&#36807;&#38544;&#24335;&#20559;&#22909;&#65292;&#22312;&#35270;&#35273;&#36712;&#36857;&#19982;&#20854;&#23545;&#24212;&#30340;&#35821;&#35328;&#25351;&#20196;&#30456;&#27604;&#19981;&#21305;&#37197;&#23545;&#26356;&#22909;&#22320;&#23545;&#40784;&#26102;&#65292;&#27969;&#34892;&#30340; Bradley-Terry &#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#36866;&#24403;&#30340;&#22870;&#21169;&#37325;&#26032;&#21442;&#25968;&#21270;&#32780;&#21464;&#20026;&#34920;&#31034;&#23398;&#20064;&#12290;&#32467;&#26524;&#20135;&#29983;&#30340; DecisionNCE &#26694;&#26550;&#65292;&#31867;&#20284;&#20110; InfoNC
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18137v1 Announce Type: cross  Abstract: Multimodal pretraining has emerged as an effective strategy for the trinity of goals of representation learning in autonomous robots: 1) extracting both local and global task progression information; 2) enforcing temporal consistency of visual representation; 3) capturing trajectory-level language grounding. Most existing methods approach these via separate objectives, which often reach sub-optimal solutions. In this paper, we propose a universal unified objective that can simultaneously extract meaningful task progression information from image sequences and seamlessly align them with language instructions. We discover that via implicit preferences, where a visual trajectory inherently aligns better with its corresponding language instruction than mismatched pairs, the popular Bradley-Terry model can transform into representation learning through proper reward reparameterizations. The resulted framework, DecisionNCE, mirrors an InfoNC
&lt;/p&gt;</description></item><item><title>Conformer&#26159;&#19968;&#31181;&#29992;&#20110;&#22825;&#27668;&#39044;&#27979;&#30340;&#26102;&#31354;&#36830;&#32493;&#35270;&#35273;Transformer&#65292;&#36890;&#36807;&#22312;&#22810;&#22836;&#27880;&#24847;&#21147;&#26426;&#21046;&#20013;&#23454;&#29616;&#36830;&#32493;&#24615;&#26469;&#23398;&#20064;&#26102;&#38388;&#19978;&#30340;&#36830;&#32493;&#22825;&#27668;&#28436;&#21464;&#12290;</title><link>https://arxiv.org/abs/2402.17966</link><description>&lt;p&gt;
Conformer&#65306;&#23558;&#36830;&#32493;&#27880;&#24847;&#21147;&#23884;&#20837;&#35270;&#35273;Transformer&#29992;&#20110;&#22825;&#27668;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Conformer: Embedding Continuous Attention in Vision Transformer for Weather Forecasting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17966
&lt;/p&gt;
&lt;p&gt;
Conformer&#26159;&#19968;&#31181;&#29992;&#20110;&#22825;&#27668;&#39044;&#27979;&#30340;&#26102;&#31354;&#36830;&#32493;&#35270;&#35273;Transformer&#65292;&#36890;&#36807;&#22312;&#22810;&#22836;&#27880;&#24847;&#21147;&#26426;&#21046;&#20013;&#23454;&#29616;&#36830;&#32493;&#24615;&#26469;&#23398;&#20064;&#26102;&#38388;&#19978;&#30340;&#36830;&#32493;&#22825;&#27668;&#28436;&#21464;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25805;&#20316;&#24615;&#22825;&#27668;&#39044;&#25253;&#31995;&#32479;&#20381;&#36182;&#20110;&#35745;&#31639;&#26114;&#36149;&#30340;&#22522;&#20110;&#29289;&#29702;&#30340;&#27169;&#22411;&#12290;&#23613;&#31649;&#22522;&#20110;Transformer&#30340;&#27169;&#22411;&#22312;&#22825;&#27668;&#39044;&#27979;&#20013;&#26174;&#31034;&#20986;&#20102;&#26174;&#33879;&#28508;&#21147;&#65292;&#20294;Transformers&#26159;&#31163;&#25955;&#27169;&#22411;&#65292;&#38480;&#21046;&#20102;&#20854;&#23398;&#20064;&#21160;&#24577;&#22825;&#27668;&#31995;&#32479;&#36830;&#32493;&#26102;&#31354;&#29305;&#24449;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#36890;&#36807;Conformer&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;&#22825;&#27668;&#39044;&#27979;&#30340;&#26102;&#31354;&#36830;&#32493;&#35270;&#35273;Transformer&#12290;Conformer&#26088;&#22312;&#36890;&#36807;&#22312;&#22810;&#22836;&#27880;&#24847;&#21147;&#26426;&#21046;&#20013;&#23454;&#29616;&#36830;&#32493;&#24615;&#26469;&#23398;&#20064;&#26102;&#38388;&#19978;&#30340;&#36830;&#32493;&#22825;&#27668;&#28436;&#21464;&#12290;&#27880;&#24847;&#21147;&#26426;&#21046;&#34987;&#32534;&#30721;&#20026;Transformer&#26550;&#26500;&#20013;&#30340;&#21487;&#24494;&#20998;&#20989;&#25968;&#65292;&#20197;&#24314;&#27169;&#22797;&#26434;&#30340;&#22825;&#27668;&#21160;&#24577;&#12290;&#25105;&#20204;&#23558;Conformer&#19982;&#26368;&#20808;&#36827;&#30340;&#25968;&#20540;&#22825;&#27668;&#39044;&#25253;&#65288;NWP&#65289;&#27169;&#22411;&#21644;&#20960;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#22825;&#27668;&#39044;&#27979;&#27169;&#22411;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;Conformer&#22312;&#25152;&#26377;&#21069;&#23548;&#26102;&#38388;&#19978;&#20248;&#20110;&#19968;&#20123;&#29616;&#26377;&#30340;&#25968;&#25454;&#39537;&#21160;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17966v1 Announce Type: new  Abstract: Operational weather forecasting system relies on computationally expensive physics-based models. Although Transformers-based models have shown remarkable potential in weather forecasting, Transformers are discrete models which limit their ability to learn the continuous spatio-temporal features of the dynamical weather system. We address this issue with Conformer, a spatio-temporal Continuous Vision Transformer for weather forecasting. Conformer is designed to learn the continuous weather evolution over time by implementing continuity in the multi-head attention mechanism. The attention mechanism is encoded as a differentiable function in the transformer architecture to model the complex weather dynamics. We evaluate Conformer against a state-of-the-art Numerical Weather Prediction (NWP) model and several deep learning based weather forecasting models. Conformer outperforms some of the existing data-driven models at all lead times while 
&lt;/p&gt;</description></item><item><title>DS-Agent&#26159;&#19968;&#20010;&#33258;&#21160;&#26694;&#26550;&#65292;&#32467;&#21512;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#21644;&#26696;&#20363;&#25512;&#29702;&#65292;&#33021;&#22815;&#22312;&#25968;&#25454;&#31185;&#23398;&#20219;&#21153;&#20013;&#28789;&#27963;&#21033;&#29992;&#19987;&#23478;&#30693;&#35782;&#24182;&#36890;&#36807;&#21453;&#39304;&#26426;&#21046;&#25345;&#32493;&#25913;&#21892;&#24615;&#33021;</title><link>https://arxiv.org/abs/2402.17453</link><description>&lt;p&gt;
DS-Agent&#65306;&#36890;&#36807;&#36171;&#20104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26696;&#20363;&#25512;&#29702;&#33021;&#21147;&#23454;&#29616;&#33258;&#21160;&#21270;&#25968;&#25454;&#31185;&#23398;
&lt;/p&gt;
&lt;p&gt;
DS-Agent: Automated Data Science by Empowering Large Language Models with Case-Based Reasoning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17453
&lt;/p&gt;
&lt;p&gt;
DS-Agent&#26159;&#19968;&#20010;&#33258;&#21160;&#26694;&#26550;&#65292;&#32467;&#21512;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#21644;&#26696;&#20363;&#25512;&#29702;&#65292;&#33021;&#22815;&#22312;&#25968;&#25454;&#31185;&#23398;&#20219;&#21153;&#20013;&#28789;&#27963;&#21033;&#29992;&#19987;&#23478;&#30693;&#35782;&#24182;&#36890;&#36807;&#21453;&#39304;&#26426;&#21046;&#25345;&#32493;&#25913;&#21892;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20195;&#29702;&#30340;&#28508;&#21147;&#65292;&#20197;&#33258;&#21160;&#21270;&#25968;&#25454;&#31185;&#23398;&#20219;&#21153;&#65292;&#30446;&#26631;&#26159;&#29702;&#35299;&#20219;&#21153;&#35201;&#27714;&#65292;&#28982;&#21518;&#26500;&#24314;&#21644;&#35757;&#32451;&#26368;&#21512;&#36866;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;&#23613;&#31649;&#29616;&#26377;&#30340;LLM&#20195;&#29702;&#21462;&#24471;&#20102;&#24191;&#27867;&#25104;&#21151;&#65292;&#20294;&#22312;&#36825;&#31181;&#24773;&#26223;&#19979;&#29983;&#25104;&#19981;&#21512;&#29702;&#30340;&#23454;&#39564;&#35745;&#21010;&#21463;&#21040;&#38459;&#30861;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;DS-Agent&#65292;&#36825;&#26159;&#19968;&#20010;&#21033;&#29992;LLM&#20195;&#29702;&#21644;&#26696;&#20363;&#25512;&#29702;&#65288;CBR&#65289;&#30340;&#26032;&#39062;&#33258;&#21160;&#21270;&#26694;&#26550;&#12290;&#22312;&#24320;&#21457;&#38454;&#27573;&#65292;DS-Agent&#36981;&#24490;CBR&#26694;&#26550;&#26469;&#26500;&#24314;&#33258;&#21160;&#36845;&#20195;&#27969;&#27700;&#32447;&#65292;&#21487;&#20197;&#28789;&#27963;&#21033;&#29992;&#26469;&#33258;Kaggle&#30340;&#19987;&#19994;&#30693;&#35782;&#65292;&#24182;&#36890;&#36807;&#21453;&#39304;&#26426;&#21046;&#20419;&#36827;&#19968;&#33268;&#30340;&#24615;&#33021;&#25913;&#36827;&#12290;&#27492;&#22806;&#65292;DS-Agent&#23454;&#29616;&#20102;&#19968;&#20010;&#20302;&#36164;&#28304;&#37096;&#32626;&#38454;&#27573;&#65292;&#37319;&#29992;&#31616;&#21270;&#30340;CBR&#33539;&#20363;&#26469;&#36866;&#24212;&#24320;&#21457;&#38454;&#27573;&#25104;&#21151;&#35299;&#20915;&#26041;&#26696;&#65292;&#20197;&#36827;&#34892;&#30452;&#25509;&#20195;&#30721;&#29983;&#25104;&#65292;&#26174;&#33879;&#20943;&#23569;&#20102;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17453v1 Announce Type: new  Abstract: In this work, we investigate the potential of large language models (LLMs) based agents to automate data science tasks, with the goal of comprehending task requirements, then building and training the best-fit machine learning models. Despite their widespread success, existing LLM agents are hindered by generating unreasonable experiment plans within this scenario. To this end, we present DS-Agent, a novel automatic framework that harnesses LLM agent and case-based reasoning (CBR). In the development stage, DS-Agent follows the CBR framework to structure an automatic iteration pipeline, which can flexibly capitalize on the expert knowledge from Kaggle, and facilitate consistent performance improvement through the feedback mechanism. Moreover, DS-Agent implements a low-resource deployment stage with a simplified CBR paradigm to adapt past successful solutions from the development stage for direct code generation, significantly reducing th
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#36890;&#30693;&#20803;&#23398;&#20064;&#36825;&#19968;&#26032;&#33539;&#24335;&#65292;&#26088;&#22312;&#36890;&#36807;&#20154;&#31867;&#21644;&#26426;&#22120;&#20043;&#38388;&#30340;&#36328;&#20219;&#21153;&#30693;&#35782;&#20849;&#20139;&#65292;&#25552;&#39640;&#25968;&#25454;&#25928;&#29575;&#21644;&#25269;&#24481;&#35266;&#27979;&#22122;&#22768;&#12290;</title><link>https://arxiv.org/abs/2402.16105</link><description>&lt;p&gt;
&#36890;&#30693;&#20803;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Informed Meta-Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16105
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#36890;&#30693;&#20803;&#23398;&#20064;&#36825;&#19968;&#26032;&#33539;&#24335;&#65292;&#26088;&#22312;&#36890;&#36807;&#20154;&#31867;&#21644;&#26426;&#22120;&#20043;&#38388;&#30340;&#36328;&#20219;&#21153;&#30693;&#35782;&#20849;&#20139;&#65292;&#25552;&#39640;&#25968;&#25454;&#25928;&#29575;&#21644;&#25269;&#24481;&#35266;&#27979;&#22122;&#22768;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30495;&#23454;&#24212;&#29992;&#20013;&#30427;&#34892;&#30340;&#22024;&#26434;&#21644;&#20302;&#25968;&#25454;&#24773;&#20917;&#19979;&#65292;&#26426;&#22120;&#23398;&#20064;&#20013;&#19968;&#20010;&#31361;&#20986;&#30340;&#25361;&#25112;&#22312;&#20110;&#26377;&#25928;&#22320;&#34701;&#21512;&#20419;&#36827;&#25968;&#25454;&#25928;&#29575;&#21644;&#31283;&#20581;&#24615;&#30340;&#24402;&#32435;&#20559;&#24046;&#12290;&#20803;&#23398;&#20064;&#21644;&#36890;&#30693;&#26426;&#22120;&#23398;&#20064;&#26159;&#20004;&#31181;&#23558;&#20808;&#39564;&#30693;&#35782;&#32435;&#20837;&#26426;&#22120;&#23398;&#20064;&#27969;&#31243;&#30340;&#26041;&#27861;&#12290;&#21069;&#32773;&#20381;&#36182;&#20110;&#19968;&#31181;&#32431;&#25968;&#25454;&#39537;&#21160;&#30340;&#20808;&#39564;&#26469;&#28304;&#65292;&#32780;&#21518;&#32773;&#21463;&#19987;&#23478;&#30693;&#35782;&#30340;&#24418;&#24335;&#21270;&#34920;&#31034;&#24341;&#23548;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28151;&#21512;&#33539;&#24335;&#65292;&#36890;&#30693;&#20803;&#23398;&#20064;&#65292;&#26088;&#22312;&#23454;&#29616;&#20154;&#31867;&#21644;&#26426;&#22120;&#20043;&#38388;&#36328;&#20219;&#21153;&#30693;&#35782;&#20849;&#20139;&#30340;&#20114;&#34917;&#24615;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#36890;&#30693;&#20803;&#23398;&#20064;&#30340;&#22522;&#26412;&#32452;&#25104;&#37096;&#20998;&#65292;&#24182;&#25552;&#20986;&#20102;&#36825;&#19968;&#26694;&#26550;&#30340;&#20855;&#20307;&#23454;&#20363;--&#36890;&#30693;&#31070;&#32463;&#36807;&#31243;&#12290;&#36890;&#36807;&#19968;&#31995;&#21015;&#35828;&#26126;&#24615;&#21644;&#26356;&#22823;&#35268;&#27169;&#30340;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#30693;&#20803;&#23398;&#20064;&#22312;&#25552;&#39640;&#25968;&#25454;&#25928;&#29575;&#21644;&#25269;&#24481;&#35266;&#27979;&#22122;&#22768;&#26041;&#38754;&#30340;&#28508;&#22312;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16105v1 Announce Type: new  Abstract: In noisy and low-data regimes prevalent in real-world applications, an outstanding challenge of machine learning lies in effectively incorporating inductive biases that promote data efficiency and robustness. Meta-learning and informed ML stand out as two approaches for incorporating prior knowledge into the ML pipeline. While the former relies on a purely data-driven source of priors, the latter is guided by a formal representation of expert knowledge. This paper introduces a novel hybrid paradigm, informed meta-learning, seeking complementarity in cross-task knowledge sharing of humans and machines. We establish the foundational components of informed meta-learning and present a concrete instantiation of this framework--the Informed Neural Process. Through a series of illustrative and larger-scale experiments, we demonstrate the potential benefits of informed meta-learning in improving data efficiency and robustness to observational no
&lt;/p&gt;</description></item><item><title>EasyRL4Rec&#26159;&#19968;&#20010;&#38754;&#21521;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#29992;&#25143;&#21451;&#22909;&#21644;&#39640;&#25928;&#24211;&#65292;&#25552;&#20379;&#20102;&#22810;&#26679;&#21270;&#30340;RL&#29615;&#22659;&#12289;&#20840;&#38754;&#30340;&#26680;&#24515;&#27169;&#22359;&#12289;&#19968;&#33268;&#30340;&#35780;&#20272;&#26631;&#20934;&#21644;&#23450;&#21046;&#35299;&#20915;&#26041;&#26696;&#65292;&#26088;&#22312;&#24110;&#21161;&#31616;&#21270;&#27169;&#22411;&#24320;&#21457;&#24182;&#25913;&#21892;&#38271;&#26399;&#29992;&#25143;&#21442;&#19982;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.15164</link><description>&lt;p&gt;
EasyRL4Rec&#65306;&#38754;&#21521;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#29992;&#25143;&#21451;&#22909;&#20195;&#30721;&#24211;
&lt;/p&gt;
&lt;p&gt;
EasyRL4Rec: A User-Friendly Code Library for Reinforcement Learning Based Recommender Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15164
&lt;/p&gt;
&lt;p&gt;
EasyRL4Rec&#26159;&#19968;&#20010;&#38754;&#21521;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#29992;&#25143;&#21451;&#22909;&#21644;&#39640;&#25928;&#24211;&#65292;&#25552;&#20379;&#20102;&#22810;&#26679;&#21270;&#30340;RL&#29615;&#22659;&#12289;&#20840;&#38754;&#30340;&#26680;&#24515;&#27169;&#22359;&#12289;&#19968;&#33268;&#30340;&#35780;&#20272;&#26631;&#20934;&#21644;&#23450;&#21046;&#35299;&#20915;&#26041;&#26696;&#65292;&#26088;&#22312;&#24110;&#21161;&#31616;&#21270;&#27169;&#22411;&#24320;&#21457;&#24182;&#25913;&#21892;&#38271;&#26399;&#29992;&#25143;&#21442;&#19982;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;-&#22522;&#30784;&#30340;&#25512;&#33616;&#31995;&#32479;&#65288;RSs&#65289;&#36234;&#26469;&#36234;&#34987;&#35748;&#21487;&#20854;&#25552;&#39640;&#38271;&#26399;&#29992;&#25143;&#21442;&#19982;&#24230;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#36825;&#20010;&#39046;&#22495;&#38754;&#20020;&#25361;&#25112;&#65292;&#22914;&#32570;&#20047;&#26131;&#29992;&#30340;&#26694;&#26550;&#12289;&#35780;&#20272;&#26631;&#20934;&#19981;&#19968;&#33268;&#20197;&#21450;&#22797;&#21046;&#20197;&#21069;&#30340;&#24037;&#20316;&#30340;&#22797;&#26434;&#24615;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38556;&#30861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;EasyRL4Rec&#65292;&#19968;&#20010;&#19987;&#20026;&#22522;&#20110;RL&#30340;RSs&#37327;&#36523;&#23450;&#21046;&#30340;&#29992;&#25143;&#21451;&#22909;&#21644;&#39640;&#25928;&#30340;&#24211;&#12290;EasyRL4Rec&#20855;&#26377;&#22522;&#20110;&#20116;&#20010;&#24191;&#27867;&#20351;&#29992;&#30340;&#20844;&#20849;&#25968;&#25454;&#38598;&#26500;&#24314;&#30340;&#36731;&#37327;&#32423;&#12289;&#22810;&#26679;&#21270;&#30340;RL&#29615;&#22659;&#65292;&#24182;&#37197;&#22791;&#20102;&#20840;&#38754;&#30340;&#26680;&#24515;&#27169;&#22359;&#65292;&#25552;&#20379;&#20016;&#23500;&#30340;&#36873;&#39033;&#26469;&#31616;&#21270;&#27169;&#22411;&#30340;&#24320;&#21457;&#12290;&#23427;&#24314;&#31435;&#20102;&#19968;&#33268;&#30340;&#35780;&#20272;&#26631;&#20934;&#65292;&#37325;&#28857;&#20851;&#27880;&#38271;&#26399;&#24433;&#21709;&#65292;&#24182;&#24341;&#20837;&#20102;&#38024;&#23545;&#25512;&#33616;&#31995;&#32479;&#23450;&#21046;&#30340;&#29366;&#24577;&#24314;&#27169;&#21644;&#34892;&#20026;&#34920;&#31034;&#30340;&#23450;&#21046;&#35299;&#20915;&#26041;&#26696;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20998;&#20139;&#20102;&#36890;&#36807;&#19982;&#24403;&#21069;&#26041;&#27861;&#36827;&#34892;&#30340;&#22823;&#37327;&#23454;&#39564;&#33719;&#24471;&#30340;&#23453;&#36149;&#35265;&#35299;&#12290;EasyRL4Rec&#26088;&#22312;&#20419;&#36827;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15164v1 Announce Type: cross  Abstract: Reinforcement Learning (RL)-Based Recommender Systems (RSs) are increasingly recognized for their ability to improve long-term user engagement. Yet, the field grapples with challenges such as the absence of accessible frameworks, inconsistent evaluation standards, and the complexity of replicating prior work. Addressing these obstacles, we present EasyRL4Rec, a user-friendly and efficient library tailored for RL-based RSs. EasyRL4Rec features lightweight, diverse RL environments built on five widely-used public datasets, and is equipped with comprehensive core modules that offer rich options to ease the development of models. It establishes consistent evaluation criteria with a focus on long-term impacts and introduces customized solutions for state modeling and action representation tailored to recommender systems. Additionally, we share valuable insights gained from extensive experiments with current methods. EasyRL4Rec aims to facil
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25552;&#20379;&#35777;&#25454;&#34920;&#26126;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#31070;&#32463;&#22349;&#22604;&#20027;&#35201;&#26159;&#36890;&#36807;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#36827;&#34892;&#28145;&#24230;&#29305;&#24449;&#23398;&#20064;&#30340;&#65292;&#26435;&#37325;&#30340;&#22855;&#24322;&#32467;&#26500;&#19982;AGOP&#39640;&#24230;&#30456;&#20851;&#65292;&#23548;&#33268;&#31867;&#20869;&#21464;&#24322;&#22349;&#22604;&#12290;</title><link>https://arxiv.org/abs/2402.13728</link><description>&lt;p&gt;
&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#20316;&#20026;&#28145;&#24230;&#31070;&#32463;&#22349;&#22604;&#26426;&#21046;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Average gradient outer product as a mechanism for deep neural collapse
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13728
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25552;&#20379;&#35777;&#25454;&#34920;&#26126;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#31070;&#32463;&#22349;&#22604;&#20027;&#35201;&#26159;&#36890;&#36807;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#36827;&#34892;&#28145;&#24230;&#29305;&#24449;&#23398;&#20064;&#30340;&#65292;&#26435;&#37325;&#30340;&#22855;&#24322;&#32467;&#26500;&#19982;AGOP&#39640;&#24230;&#30456;&#20851;&#65292;&#23548;&#33268;&#31867;&#20869;&#21464;&#24322;&#22349;&#22604;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Deep Neural Collapse (DNC)&#25351;&#30340;&#26159;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#26368;&#21518;&#20960;&#23618;&#25968;&#25454;&#34920;&#31034;&#30340;&#24778;&#20154;&#21018;&#24615;&#32467;&#26500;&#12290;&#23613;&#31649;&#36825;&#31181;&#29616;&#35937;&#22312;&#21508;&#31181;&#24773;&#22659;&#20013;&#37117;&#24471;&#21040;&#20102;&#27979;&#37327;&#65292;&#20294;&#20854;&#20986;&#29616;&#21482;&#26377;&#37096;&#20998;&#34987;&#29702;&#35299;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#20805;&#20998;&#35777;&#25454;&#65292;&#34920;&#26126;DNC&#20027;&#35201;&#26159;&#36890;&#36807;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;(AGOP)&#36827;&#34892;&#28145;&#24230;&#29305;&#24449;&#23398;&#20064;&#32780;&#21457;&#29983;&#30340;&#12290;&#30456;&#27604;&#20110;&#35299;&#37322;&#31070;&#32463;&#22349;&#22604;&#30340;&#29305;&#24449;&#19981;&#21487;&#30693;&#26041;&#27861;&#65292;&#22914;&#26080;&#32422;&#26463;&#29305;&#24449;&#27169;&#22411;&#65292;&#36825;&#19968;&#36827;&#23637;&#26356;&#36827;&#19968;&#27493;&#12290;&#25105;&#20204;&#32487;&#32493;&#25552;&#20379;&#35777;&#25454;&#34920;&#26126;&#65292;&#26435;&#37325;&#30340;&#21491;&#22855;&#24322;&#21521;&#37327;&#21644;&#22855;&#24322;&#20540;&#26159;DNN&#20013;&#31867;&#20869;&#21464;&#24322;&#22349;&#22604;&#30340;&#20027;&#35201;&#22240;&#32032;&#12290;&#27491;&#22914;&#26368;&#36817;&#30340;&#30740;&#31350;&#25152;&#31034;&#65292;&#36825;&#31181;&#22855;&#24322;&#32467;&#26500;&#19982;AGOP&#30340;&#39640;&#24230;&#30456;&#20851;&#12290;&#28982;&#21518;&#25105;&#20204;&#22312;&#23454;&#39564;&#21644;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;AGOP&#22312;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#20013;&#24341;&#21457;&#31070;&#32463;&#22349;&#22604;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13728v1 Announce Type: new  Abstract: Deep Neural Collapse (DNC) refers to the surprisingly rigid structure of the data representations in the final layers of Deep Neural Networks (DNNs). Though the phenomenon has been measured in a wide variety of settings, its emergence is only partially understood. In this work, we provide substantial evidence that DNC formation occurs primarily through deep feature learning with the average gradient outer product (AGOP). This takes a step further compared to efforts that explain neural collapse via feature-agnostic approaches, such as the unconstrained features model. We proceed by providing evidence that the right singular vectors and values of the weights are responsible for the majority of within-class variability collapse in DNNs. As shown in recent work, this singular structure is highly correlated with that of the AGOP. We then establish experimentally and theoretically that AGOP induces neural collapse in a randomly initialized ne
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#21033;&#29992;&#21464;&#21387;&#22120;&#27169;&#22411;&#35299;&#20915;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#38382;&#39064;&#65292;&#39318;&#27425;&#37319;&#29992;&#21464;&#21387;&#22120;&#39044;&#27979;&#20108;&#36827;&#21046;&#21464;&#37327;&#65292;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#35299;&#20915;&#26102;&#38388;&#19978;&#36229;&#36234;&#20102;&#20256;&#32479;CPLEX&#21644;LSTM&#12290;</title><link>https://arxiv.org/abs/2402.13380</link><description>&lt;p&gt;
&#36808;&#21521;&#21464;&#21387;&#22120;&#65306;&#29992;&#21464;&#21387;&#22120;&#24443;&#24213;&#25913;&#21464;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#30340;&#35299;&#20915;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Toward TransfORmers: Revolutionizing the Solution of Mixed Integer Programs with Transformers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13380
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#21033;&#29992;&#21464;&#21387;&#22120;&#27169;&#22411;&#35299;&#20915;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#38382;&#39064;&#65292;&#39318;&#27425;&#37319;&#29992;&#21464;&#21387;&#22120;&#39044;&#27979;&#20108;&#36827;&#21046;&#21464;&#37327;&#65292;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#35299;&#20915;&#26102;&#38388;&#19978;&#36229;&#36234;&#20102;&#20256;&#32479;CPLEX&#21644;LSTM&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#21033;&#29992;&#21464;&#21387;&#22120;&#27169;&#22411;&#26469;&#35299;&#20915;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#30340;&#25361;&#25112;&#65292;&#29305;&#21035;&#26159;&#19987;&#27880;&#20110;&#23481;&#37327;&#38480;&#21046;&#25209;&#37327;&#29983;&#20135;&#38382;&#39064;&#65288;CLSP&#65289;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#39318;&#20010;&#21033;&#29992;&#21464;&#21387;&#22120;&#26469;&#39044;&#27979;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#38382;&#39064;&#20013;&#30340;&#20108;&#36827;&#21046;&#21464;&#37327;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#21464;&#21387;&#22120;&#22788;&#29702;&#39034;&#24207;&#25968;&#25454;&#30340;&#33021;&#21147;&#65292;&#38750;&#24120;&#36866;&#21512;&#39044;&#27979;&#27599;&#20010;CLSP&#21608;&#26399;&#20013;&#34920;&#31034;&#29983;&#20135;&#35774;&#32622;&#20915;&#31574;&#30340;&#20108;&#36827;&#21046;&#21464;&#37327;&#12290;&#36825;&#20010;&#38382;&#39064;&#26412;&#36136;&#19978;&#26159;&#21160;&#24577;&#30340;&#65292;&#25105;&#20204;&#38656;&#35201;&#22312;&#32422;&#26463;&#26465;&#20214;&#19979;&#22788;&#29702;&#39034;&#24207;&#20915;&#31574;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#21464;&#21387;&#22120;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;CLSP&#35299;&#20915;&#26041;&#26696;&#12290;&#25152;&#25552;&#20986;&#30340;&#21518;&#22788;&#29702;&#21464;&#21387;&#22120;&#31639;&#27861;&#22312;&#35299;&#20915;&#26102;&#38388;&#19978;&#36229;&#36234;&#20102;&#26368;&#20808;&#36827;&#30340;&#27714;&#35299;&#22120;CPLEX&#21644;&#38271;&#30701;&#26399;&#35760;&#24518;&#65288;LSTM&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13380v1 Announce Type: new  Abstract: In this study, we introduce an innovative deep learning framework that employs a transformer model to address the challenges of mixed-integer programs, specifically focusing on the Capacitated Lot Sizing Problem (CLSP). Our approach, to our knowledge, is the first to utilize transformers to predict the binary variables of a mixed-integer programming (MIP) problem. Specifically, our approach harnesses the encoder decoder transformer's ability to process sequential data, making it well-suited for predicting binary variables indicating production setup decisions in each period of the CLSP. This problem is inherently dynamic, and we need to handle sequential decision making under constraints. We present an efficient algorithm in which CLSP solutions are learned through a transformer neural network. The proposed post-processed transformer algorithm surpasses the state-of-the-art solver, CPLEX and Long Short-Term Memory (LSTM) in solution time
&lt;/p&gt;</description></item><item><title>PARCv2&#36890;&#36807;&#24341;&#20837;&#24494;&#20998;&#31639;&#23376;&#25193;&#23637;&#20102;PARC&#27169;&#22411;&#65292;&#29992;&#20110;&#27169;&#25311;&#19981;&#31283;&#23450;&#12289;&#30636;&#24577;&#21644;&#20256;&#36755;&#20027;&#23548;&#31995;&#32479;&#30340;&#26102;&#31354;&#21160;&#21147;&#23398;&#12290;</title><link>https://arxiv.org/abs/2402.12503</link><description>&lt;p&gt;
PARCv2&#65306;&#29289;&#29702;&#24863;&#30693;&#24490;&#29615;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#26102;&#31354;&#21160;&#21147;&#23398;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
PARCv2: Physics-aware Recurrent Convolutional Neural Networks for Spatiotemporal Dynamics Modeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12503
&lt;/p&gt;
&lt;p&gt;
PARCv2&#36890;&#36807;&#24341;&#20837;&#24494;&#20998;&#31639;&#23376;&#25193;&#23637;&#20102;PARC&#27169;&#22411;&#65292;&#29992;&#20110;&#27169;&#25311;&#19981;&#31283;&#23450;&#12289;&#30636;&#24577;&#21644;&#20256;&#36755;&#20027;&#23548;&#31995;&#32479;&#30340;&#26102;&#31354;&#21160;&#21147;&#23398;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12503v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#26032;&#25688;&#35201;&#65306;&#23545;&#19981;&#31283;&#23450;&#30340;&#12289;&#24555;&#36895;&#30636;&#24577;&#21644;&#20248;&#21183;&#20256;&#36755;&#20027;&#23548;&#30340;&#29289;&#29702;&#38382;&#39064;&#36827;&#34892;&#24314;&#27169;&#26159;&#29289;&#29702;&#24863;&#30693;&#28145;&#24230;&#23398;&#20064;&#65288;PADL&#65289;&#38754;&#20020;&#30340;&#36843;&#20999;&#25361;&#25112;&#12290;&#22797;&#26434;&#31995;&#32479;&#30340;&#29289;&#29702;&#30001;&#22823;&#22411;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDEs&#65289;&#31995;&#32479;&#21644;&#24102;&#26377;&#38750;&#32447;&#24615;&#32467;&#26500;&#30340;&#36741;&#21161;&#26412;&#26500;&#27169;&#22411;&#25152;&#25511;&#21046;&#65292;&#21516;&#26102;&#36824;&#21253;&#25324;&#34920;&#29616;&#20986;&#24613;&#21095;&#26799;&#24230;&#21644;&#24555;&#36895;&#21464;&#24418;&#26448;&#26009;&#30028;&#38754;&#30340;&#28436;&#21270;&#29366;&#24577;&#22330;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#22810;&#21151;&#33021;&#19988;&#36890;&#29992;&#30340;&#24402;&#32435;&#20559;&#35265;&#26041;&#27861;&#65292;&#29992;&#20110;&#27169;&#25311;&#36890;&#29992;&#30340;&#38750;&#32447;&#24615;&#22330;&#28436;&#21464;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32858;&#28966;&#20110;&#26368;&#36817;&#30340;&#29289;&#29702;&#24863;&#30693;&#24490;&#29615;&#21367;&#31215;&#65288;PARC&#65289;&#65292;&#23427;&#32467;&#21512;&#20102;&#19968;&#31181;&#21306;&#20998;-&#31215;&#20998;&#22120;&#32467;&#26500;&#65292;&#24402;&#32435;&#22320;&#27169;&#25311;&#20102;&#36890;&#29992;&#29289;&#29702;&#31995;&#32479;&#30340;&#26102;&#31354;&#21160;&#21147;&#23398;&#12290;&#25105;&#20204;&#25193;&#23637;&#20102;PARC&#30340;&#21151;&#33021;&#65292;&#20197;&#27169;&#25311;&#19981;&#31283;&#23450;&#12289;&#30636;&#24577;&#21644;&#20256;&#36755;&#20027;&#23548;&#31995;&#32479;&#12290;&#36825;&#20010;&#25193;&#23637;&#27169;&#22411;&#34987;&#31216;&#20026;PARCv2&#65292;&#37197;&#22791;&#20102;&#24494;&#20998;&#31639;&#23376;&#26469;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12503v1 Announce Type: new  Abstract: Modeling unsteady, fast transient, and advection-dominated physics problems is a pressing challenge for physics-aware deep learning (PADL). The physics of complex systems is governed by large systems of partial differential equations (PDEs) and ancillary constitutive models with nonlinear structures, as well as evolving state fields exhibiting sharp gradients and rapidly deforming material interfaces. Here, we investigate an inductive bias approach that is versatile and generalizable to model generic nonlinear field evolution problems. Our study focuses on the recent physics-aware recurrent convolutions (PARC), which incorporates a differentiator-integrator architecture that inductively models the spatiotemporal dynamics of generic physical systems. We extend the capabilities of PARC to simulate unsteady, transient, and advection-dominant systems. The extended model, referred to as PARCv2, is equipped with differential operators to model
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;Rewards-in-Context&#65288;RiC&#65289;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#22810;&#20010;&#22870;&#21169;&#26465;&#20214;&#25511;&#21046;&#22522;&#30784;&#27169;&#22411;&#30340;&#21709;&#24212;&#65292;&#24182;&#24212;&#29992;&#26377;&#30417;&#30563;&#30340;&#24494;&#35843;&#36827;&#34892;&#23545;&#40784;&#12290;&#23427;&#20855;&#26377;&#31616;&#21333;&#24615;&#21644;&#36866;&#24212;&#24615;&#65292;&#24182;&#25903;&#25345;&#22312;&#25512;&#29702;&#26102;&#21160;&#24577;&#35843;&#25972;&#29992;&#25143;&#20559;&#22909;&#12290;</title><link>https://arxiv.org/abs/2402.10207</link><description>&lt;p&gt;
&#22522;&#20110;&#19978;&#19979;&#25991;&#30340;&#22870;&#21169;&#65306;&#22522;&#20110;&#21160;&#24577;&#20559;&#22909;&#35843;&#25972;&#30340;&#22810;&#30446;&#26631;&#22522;&#30784;&#27169;&#22411;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Rewards-in-Context: Multi-objective Alignment of Foundation Models with Dynamic Preference Adjustment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10207
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;Rewards-in-Context&#65288;RiC&#65289;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#22810;&#20010;&#22870;&#21169;&#26465;&#20214;&#25511;&#21046;&#22522;&#30784;&#27169;&#22411;&#30340;&#21709;&#24212;&#65292;&#24182;&#24212;&#29992;&#26377;&#30417;&#30563;&#30340;&#24494;&#35843;&#36827;&#34892;&#23545;&#40784;&#12290;&#23427;&#20855;&#26377;&#31616;&#21333;&#24615;&#21644;&#36866;&#24212;&#24615;&#65292;&#24182;&#25903;&#25345;&#22312;&#25512;&#29702;&#26102;&#21160;&#24577;&#35843;&#25972;&#29992;&#25143;&#20559;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#22522;&#20110;&#20154;&#31867;&#20559;&#22909;&#30340;&#22522;&#30784;&#27169;&#22411;&#22810;&#30446;&#26631;&#23545;&#40784;&#38382;&#39064;&#65292;&#36825;&#26159;&#23454;&#29616;&#26377;&#30410;&#21644;&#26080;&#23475;&#30340;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#30340;&#20851;&#38190;&#27493;&#39588;&#12290;&#28982;&#32780;&#65292;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#23545;&#22823;&#22411;&#22522;&#30784;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#36890;&#24120;&#26159;&#26114;&#36149;&#19988;&#19981;&#31283;&#23450;&#30340;&#65292;&#24182;&#19988;&#20154;&#31867;&#20559;&#22909;&#30340;&#22810;&#32500;&#24230;&#12289;&#24322;&#36136;&#24615;&#21644;&#20914;&#31361;&#24615;&#36827;&#19968;&#27493;&#22797;&#26434;&#21270;&#20102;&#23545;&#40784;&#36807;&#31243;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;Rewards-in-Context&#65288;RiC&#65289;&#26041;&#27861;&#65292;&#23427;&#20351;&#24471;&#22522;&#30784;&#27169;&#22411;&#30340;&#21709;&#24212;&#21462;&#20915;&#20110;&#20854;&#25552;&#31034;&#19978;&#19979;&#25991;&#20013;&#30340;&#22810;&#20010;&#22870;&#21169;&#65292;&#24182;&#24212;&#29992;&#26377;&#30417;&#30563;&#30340;&#24494;&#35843;&#26469;&#36827;&#34892;&#23545;&#40784;&#12290;RiC&#30340;&#26174;&#33879;&#29305;&#28857;&#26159;&#31616;&#21333;&#24615;&#21644;&#36866;&#24212;&#24615;&#65292;&#22240;&#20026;&#23427;&#21482;&#38656;&#35201;&#23545;&#21333;&#20010;&#22522;&#30784;&#27169;&#22411;&#36827;&#34892;&#26377;&#30417;&#30563;&#30340;&#24494;&#35843;&#65292;&#24182;&#25903;&#25345;&#22312;&#25512;&#29702;&#26102;&#21160;&#24577;&#35843;&#25972;&#29992;&#25143;&#20559;&#22909;&#12290;&#21463;&#21040;&#25277;&#35937;&#30340;&#20984;&#20248;&#21270;&#38382;&#39064;&#30340;&#35299;&#26512;&#35299;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21160;&#24577;&#25512;&#29702;&#26102;&#35843;&#25972;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10207v1 Announce Type: cross  Abstract: We consider the problem of multi-objective alignment of foundation models with human preferences, which is a critical step towards helpful and harmless AI systems. However, it is generally costly and unstable to fine-tune large foundation models using reinforcement learning (RL), and the multi-dimensionality, heterogeneity, and conflicting nature of human preferences further complicate the alignment process. In this paper, we introduce Rewards-in-Context (RiC), which conditions the response of a foundation model on multiple rewards in its prompt context and applies supervised fine-tuning for alignment. The salient features of RiC are simplicity and adaptivity, as it only requires supervised fine-tuning of a single foundation model and supports dynamic adjustment for user preferences during inference time. Inspired by the analytical solution of an abstracted convex optimization problem, our dynamic inference-time adjustment method appro
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;GES&#65288;&#24191;&#20041;&#25351;&#25968;&#21943;&#27922;&#65289;&#65292;&#19968;&#31181;&#21033;&#29992;&#24191;&#20041;&#25351;&#25968;&#20989;&#25968;&#26469;&#24314;&#27169;3D&#22330;&#26223;&#30340;&#26032;&#34920;&#31034;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;3D&#37325;&#24314;&#21644;&#29983;&#25104;&#30340;&#25928;&#29575;&#12290;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;&#39640;&#26031;&#21943;&#27922;&#26041;&#27861;&#65292;GES&#25152;&#38656;&#30340;&#31890;&#23376;&#25968;&#37327;&#26356;&#23569;&#65292;&#33021;&#26356;&#20934;&#30830;&#22320;&#34920;&#31034;&#20855;&#26377;&#38160;&#21033;&#36793;&#32536;&#30340;&#20449;&#21495;&#12290;</title><link>https://arxiv.org/abs/2402.10128</link><description>&lt;p&gt;
GES&#65306;&#29992;&#20110;&#39640;&#25928;&#36752;&#23556;&#22330;&#28210;&#26579;&#30340;&#24191;&#20041;&#25351;&#25968;&#21943;&#27922;
&lt;/p&gt;
&lt;p&gt;
GES: Generalized Exponential Splatting for Efficient Radiance Field Rendering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10128
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;GES&#65288;&#24191;&#20041;&#25351;&#25968;&#21943;&#27922;&#65289;&#65292;&#19968;&#31181;&#21033;&#29992;&#24191;&#20041;&#25351;&#25968;&#20989;&#25968;&#26469;&#24314;&#27169;3D&#22330;&#26223;&#30340;&#26032;&#34920;&#31034;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;3D&#37325;&#24314;&#21644;&#29983;&#25104;&#30340;&#25928;&#29575;&#12290;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;&#39640;&#26031;&#21943;&#27922;&#26041;&#27861;&#65292;GES&#25152;&#38656;&#30340;&#31890;&#23376;&#25968;&#37327;&#26356;&#23569;&#65292;&#33021;&#26356;&#20934;&#30830;&#22320;&#34920;&#31034;&#20855;&#26377;&#38160;&#21033;&#36793;&#32536;&#30340;&#20449;&#21495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10128v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#36328;&#39046;&#22495; &#25688;&#35201;&#65306;3D&#39640;&#26031;&#21943;&#27922;&#25216;&#26415;&#30340;&#36827;&#23637;&#26174;&#33879;&#21152;&#24555;&#20102;3D&#37325;&#24314;&#21644;&#29983;&#25104;&#30340;&#36895;&#24230;&#12290;&#28982;&#32780;&#65292;&#36825;&#21487;&#33021;&#38656;&#35201;&#22823;&#37327;&#39640;&#26031;&#20989;&#25968;&#65292;&#23548;&#33268;&#21344;&#29992;&#22823;&#37327;&#20869;&#23384;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;GES&#65288;&#24191;&#20041;&#25351;&#25968;&#21943;&#27922;&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#30340;&#34920;&#31034;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#24191;&#20041;&#25351;&#25968;&#20989;&#25968;&#65288;GEF&#65289;&#26469;&#24314;&#27169;3D&#22330;&#26223;&#65292;&#21482;&#38656;&#35201;&#24456;&#23569;&#30340;&#31890;&#23376;&#26469;&#34920;&#31034;&#19968;&#20010;&#22330;&#26223;&#65292;&#22240;&#27492;&#22312;&#25928;&#29575;&#19978;&#26126;&#26174;&#20248;&#20110;&#22522;&#20110;&#39640;&#26031;&#30340;&#21943;&#27922;&#26041;&#27861;&#65292;&#24182;&#19988;&#20855;&#26377;&#39640;&#26031;-based utilities&#30340;&#21363;&#25554;&#21363;&#29992;&#26367;&#25442;&#33021;&#21147;&#12290;GES&#22312;&#29702;&#35770;&#19978;&#21644;&#23454;&#35777;&#19978;&#37117;&#24471;&#21040;&#20102;&#39564;&#35777;&#65292;&#22312;&#21407;&#21017;&#19978;&#30340;1D&#35774;&#32622;&#21644;&#36924;&#30495;&#30340;3D&#22330;&#26223;&#20013;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;GEF&#27604;&#39640;&#26031;&#20989;&#25968;&#26356;&#20934;&#30830;&#22320;&#34920;&#31034;&#20855;&#26377;&#38160;&#21033;&#36793;&#32536;&#30340;&#20449;&#21495;&#65292;&#36825;&#22312;&#39640;&#26031;&#20989;&#25968;&#20013;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#22240;&#20026;&#23427;&#20204;&#20855;&#26377;&#20302;&#36890;&#29305;&#24615;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#20998;&#26512;&#34920;&#26126;&#65292;GEF&#22312;&#25311;&#21512;&#33258;&#28982;&#21457;&#29983;&#30340;&#20449;&#21495;&#65288;&#20363;&#22914;&#27491;&#26041;&#24418;&#12289;&#19977;&#35282;&#24418;&#65289;&#26041;&#38754;&#20248;&#20110;&#39640;&#26031;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10128v1 Announce Type: cross  Abstract: Advancements in 3D Gaussian Splatting have significantly accelerated 3D reconstruction and generation. However, it may require a large number of Gaussians, which creates a substantial memory footprint. This paper introduces GES (Generalized Exponential Splatting), a novel representation that employs Generalized Exponential Function (GEF) to model 3D scenes, requiring far fewer particles to represent a scene and thus significantly outperforming Gaussian Splatting methods in efficiency with a plug-and-play replacement ability for Gaussian-based utilities. GES is validated theoretically and empirically in both principled 1D setup and realistic 3D scenes.   It is shown to represent signals with sharp edges more accurately, which are typically challenging for Gaussians due to their inherent low-pass characteristics. Our empirical analysis demonstrates that GEF outperforms Gaussians in fitting natural-occurring signals (e.g. squares, triangl
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#31070;&#32463;&#32593;&#32476;&#21644;Transformer&#22312;&#25968;&#23398;&#25512;&#29702;&#21644;&#27169;&#36816;&#31639;&#20013;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#21644;&#21333;&#23618;Transformer&#22312;&#35299;&#20915;&#22797;&#26434;&#20195;&#25968;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#29305;&#24449;&#12290;&#38416;&#26126;&#20102;&#36793;&#32536;&#26368;&#22823;&#21270;&#21407;&#21017;&#23545;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.09469</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20613;&#31435;&#21494;&#30005;&#36335;&#65306;&#35299;&#38145;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#22312;&#25968;&#23398;&#25512;&#29702;&#21644;&#27169;&#36816;&#31639;&#20013;&#30340;&#28508;&#21147;
&lt;/p&gt;
&lt;p&gt;
Fourier Circuits in Neural Networks: Unlocking the Potential of Large Language Models in Mathematical Reasoning and Modular Arithmetic
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09469
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#31070;&#32463;&#32593;&#32476;&#21644;Transformer&#22312;&#25968;&#23398;&#25512;&#29702;&#21644;&#27169;&#36816;&#31639;&#20013;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#21644;&#21333;&#23618;Transformer&#22312;&#35299;&#20915;&#22797;&#26434;&#20195;&#25968;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#29305;&#24449;&#12290;&#38416;&#26126;&#20102;&#36793;&#32536;&#26368;&#22823;&#21270;&#21407;&#21017;&#23545;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#19981;&#26029;&#21457;&#23637;&#30340;&#32972;&#26223;&#19979;&#65292;&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#21644;Transformer&#25152;&#21033;&#29992;&#30340;&#20869;&#37096;&#34920;&#31034;&#26159;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#12290;&#26412;&#30740;&#31350;&#22312;&#36817;&#26399;&#30340;&#30740;&#31350;&#22522;&#30784;&#19978;&#65292;&#23545;&#32593;&#32476;&#37319;&#29992;&#29305;&#23450;&#35745;&#31639;&#31574;&#30053;&#32972;&#21518;&#30340;&#21407;&#22240;&#36827;&#34892;&#20102;&#25506;&#32034;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32858;&#28966;&#20110;&#28041;&#21450;k&#20010;&#36755;&#20837;&#30340;&#22797;&#26434;&#20195;&#25968;&#23398;&#20064;&#20219;&#21153;&#65292;&#21363;&#27169;&#36816;&#31639;&#30340;&#21152;&#27861;&#12290;&#25105;&#20204;&#23545;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#21644;&#21333;&#23618;Transformer&#22312;&#35299;&#20915;&#36825;&#19968;&#20219;&#21153;&#20013;&#23398;&#21040;&#30340;&#29305;&#24449;&#36827;&#34892;&#20102;&#28145;&#20837;&#30340;&#20998;&#26512;&#12290;&#25105;&#20204;&#29702;&#35770;&#26694;&#26550;&#30340;&#19968;&#20010;&#20851;&#38190;&#26159;&#38416;&#26126;&#36793;&#32536;&#26368;&#22823;&#21270;&#21407;&#21017;&#23545;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#37319;&#29992;&#30340;&#29305;&#24449;&#30340;&#24433;&#21709;&#12290;&#20854;&#20013;&#65292;p&#34920;&#31034;&#27169;&#25968;&#65292;Dp&#34920;&#31034;k&#20010;&#36755;&#20837;&#30340;&#27169;&#36816;&#31639;&#25968;&#25454;&#38598;&#65292;m&#34920;&#31034;&#32593;&#32476;&#36755;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09469v1 Announce Type: new  Abstract: In the evolving landscape of machine learning, a pivotal challenge lies in deciphering the internal representations harnessed by neural networks and Transformers. Building on recent progress toward comprehending how networks execute distinct target functions, our study embarks on an exploration of the underlying reasons behind networks adopting specific computational strategies. We direct our focus to the complex algebraic learning task of modular addition involving $k$ inputs. Our research presents a thorough analytical characterization of the features learned by stylized one-hidden layer neural networks and one-layer Transformers in addressing this task.   A cornerstone of our theoretical framework is the elucidation of how the principle of margin maximization shapes the features adopted by one-hidden layer neural networks. Let $p$ denote the modulus, $D_p$ denote the dataset of modular arithmetic with $k$ inputs and $m$ denote the net
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#20998;&#31163;&#36716;&#25442;&#32467;&#26500;&#21644;&#22870;&#21169;&#65292;&#24341;&#20837;&#20102;&#20998;&#24067;&#24335;&#21518;&#32487;&#24230;&#37327;&#26469;&#25551;&#36848;&#34892;&#20026;&#30340;&#20998;&#24067;&#24335;&#21518;&#26524;&#12290;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#38646;&#26679;&#26412;&#39118;&#38505;&#25935;&#24863;&#31574;&#30053;&#35780;&#20272;&#26041;&#38754;&#12290;</title><link>https://arxiv.org/abs/2402.08530</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#21518;&#32493;&#34920;&#31034;&#30340;&#20998;&#24067;&#24335;&#31867;&#27604;
&lt;/p&gt;
&lt;p&gt;
A Distributional Analogue to the Successor Representation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08530
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#20998;&#31163;&#36716;&#25442;&#32467;&#26500;&#21644;&#22870;&#21169;&#65292;&#24341;&#20837;&#20102;&#20998;&#24067;&#24335;&#21518;&#32487;&#24230;&#37327;&#26469;&#25551;&#36848;&#34892;&#20026;&#30340;&#20998;&#24067;&#24335;&#21518;&#26524;&#12290;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#38646;&#26679;&#26412;&#39118;&#38505;&#25935;&#24863;&#31574;&#30053;&#35780;&#20272;&#26041;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#23427;&#23558;&#36716;&#25442;&#32467;&#26500;&#21644;&#22870;&#21169;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#36827;&#34892;&#20102;&#26126;&#30830;&#30340;&#20998;&#31163;&#12290;&#19982;&#21518;&#32493;&#34920;&#31034;&#65288;SR&#65289;&#25551;&#36848;&#25353;&#29031;&#32473;&#23450;&#31574;&#30053;&#34892;&#20026;&#30340;&#26399;&#26395;&#21518;&#26524;&#31867;&#20284;&#65292;&#25105;&#20204;&#30340;&#20998;&#24067;&#24335;&#21518;&#32487;&#24230;&#37327;&#65288;SM&#65289;&#25551;&#36848;&#20102;&#36825;&#31181;&#34892;&#20026;&#30340;&#20998;&#24067;&#24335;&#32467;&#26524;&#12290;&#25105;&#20204;&#23558;&#20998;&#24067;&#24335;SM&#26500;&#24314;&#20026;&#19968;&#20010;&#20998;&#24067;&#30340;&#20998;&#24067;&#65292;&#24182;&#25552;&#20379;&#20102;&#19982;&#20998;&#24067;&#24335;&#21644;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#30456;&#20851;&#30340;&#29702;&#35770;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#20998;&#24067;&#24335;SM&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#20004;&#20010;&#23618;&#27425;&#30340;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#26469;&#23454;&#29616;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#20851;&#38190;&#26159;&#19968;&#20123;&#29420;&#31435;&#26377;&#20215;&#20540;&#30340;&#23398;&#20064;&#29366;&#24577;&#29983;&#25104;&#27169;&#22411;&#30340;&#31639;&#27861;&#25216;&#26415;&#12290;&#20316;&#20026;&#20998;&#24067;&#24335;SM&#26377;&#29992;&#24615;&#30340;&#20363;&#35777;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23427;&#20351;&#24471;&#38646;&#26679;&#26412;&#39118;&#38505;&#25935;&#24863;&#31574;&#30053;&#35780;&#20272;&#25104;&#20026;&#21487;&#33021;&#65292;&#36825;&#22312;&#20197;&#21069;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper contributes a new approach for distributional reinforcement learning which elucidates a clean separation of transition structure and reward in the learning process. Analogous to how the successor representation (SR) describes the expected consequences of behaving according to a given policy, our distributional successor measure (SM) describes the distributional consequences of this behaviour. We formulate the distributional SM as a distribution over distributions and provide theory connecting it with distributional and model-based reinforcement learning. Moreover, we propose an algorithm that learns the distributional SM from data by minimizing a two-level maximum mean discrepancy. Key to our method are a number of algorithmic techniques that are independently valuable for learning generative models of state. As an illustration of the usefulness of the distributional SM, we show that it enables zero-shot risk-sensitive policy evaluation in a way that was not previously possi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#33945;&#29305;&#21345;&#27931;&#26641;&#25628;&#32034;&#24341;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#39564;&#35777;&#31243;&#24207;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#39564;&#35777;&#22120;&#30340;&#21453;&#39304;&#21644;LLM&#20808;&#39564;&#30693;&#35782;&#25552;&#39640;&#20102;&#21512;&#25104;&#33021;&#21147;&#65292;&#23454;&#39564;&#35777;&#26126;&#36825;&#31181;&#26041;&#27861;&#22312;&#19968;&#32452;&#39564;&#35777;&#32534;&#31243;&#38382;&#39064;&#19978;&#30340;&#24615;&#33021;&#20248;&#20110;&#22522;&#26412;&#27169;&#22411;&#21644;&#20855;&#26377;&#25554;&#20214;&#30340;ChatGPT4&#12290;</title><link>https://arxiv.org/abs/2402.08147</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#33945;&#29305;&#21345;&#27931;&#26641;&#25628;&#32034;&#36827;&#34892;&#39564;&#35777;&#30340;&#22810;&#27493;&#21512;&#25104;
&lt;/p&gt;
&lt;p&gt;
Verified Multi-Step Synthesis using Large Language Models and Monte Carlo Tree Search
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08147
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#33945;&#29305;&#21345;&#27931;&#26641;&#25628;&#32034;&#24341;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#39564;&#35777;&#31243;&#24207;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#39564;&#35777;&#22120;&#30340;&#21453;&#39304;&#21644;LLM&#20808;&#39564;&#30693;&#35782;&#25552;&#39640;&#20102;&#21512;&#25104;&#33021;&#21147;&#65292;&#23454;&#39564;&#35777;&#26126;&#36825;&#31181;&#26041;&#27861;&#22312;&#19968;&#32452;&#39564;&#35777;&#32534;&#31243;&#38382;&#39064;&#19978;&#30340;&#24615;&#33021;&#20248;&#20110;&#22522;&#26412;&#27169;&#22411;&#21644;&#20855;&#26377;&#25554;&#20214;&#30340;ChatGPT4&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#33945;&#29305;&#21345;&#27931;&#26641;&#25628;&#32034;&#65288;MCTS&#65289;&#24341;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#29983;&#25104;&#22312;Dafny&#12289;Lean&#21644;Coq&#20013;&#39564;&#35777;&#30340;&#31243;&#24207;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#34987;&#31216;&#20026;VMCTS&#65292;&#36890;&#36807;&#22312;&#27599;&#20010;&#27493;&#39588;&#26816;&#26597;&#37096;&#20998;&#31243;&#24207;&#26469;&#21033;&#29992;&#25628;&#32034;&#31639;&#27861;&#20013;&#30340;&#39564;&#35777;&#22120;&#12290;&#32467;&#21512;LLM&#20808;&#39564;&#30693;&#35782;&#65292;&#39564;&#35777;&#22120;&#30340;&#21453;&#39304;&#25552;&#39640;&#20102;&#24320;&#28304;&#27169;&#22411;&#30340;&#21512;&#25104;&#33021;&#21147;&#12290;&#22312;&#19968;&#32452;&#20116;&#20010;&#32463;&#36807;&#39564;&#35777;&#30340;&#32534;&#31243;&#38382;&#39064;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#22235;&#20010;&#38382;&#39064;&#20013;&#65292;&#21363;&#20351;&#37325;&#26032;&#23545;&#35299;&#20915;&#26041;&#26696;&#36827;&#34892;&#19968;&#23567;&#26102;&#30340;&#37325;&#26032;&#37319;&#26679;&#65292;&#22522;&#26412;&#27169;&#22411;&#26080;&#27861;&#35299;&#20915;&#38382;&#39064;&#65292;&#32780;VMCTS&#21487;&#20197;&#22312;6&#20998;&#38047;&#20869;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;&#22312;&#36825;&#20123;&#38382;&#39064;&#19978;&#65292;&#22522;&#26412;&#27169;&#22411;&#21152;&#19978;VMCTS&#29978;&#33267;&#19982;&#20855;&#26377;&#25554;&#20214;&#21644;&#22810;&#27425;&#37325;&#35797;&#30340;ChatGPT4&#31454;&#20105;&#21147;&#30456;&#24403;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#21644;&#22522;&#20934;&#27979;&#35797;&#32467;&#26524;&#21487;&#22312;https://github.com/namin/llm-verified-with-monte-carlo-tree-search&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present an approach using Monte Carlo Tree Search (MCTS) to guide Large Language Models (LLMs) to generate verified programs in Dafny, Lean and Coq. Our method, which we call VMCTS, leverages the verifier inside the search algorithm by checking partial programs at each step. In combination with the LLM prior, the verifier feedback raises the synthesis capabilities of open source models. On a set of five verified programming problems, we find that in four problems where the base model cannot solve the question even when re-sampling solutions for one hour, VMCTS can solve the problems within 6 minutes. The base model with VMCTS is even competitive with ChatGPT4 augmented with plugins and multiple re-tries on these problems. Our code and benchmarks are available at https://github.com/namin/llm-verified-with-monte-carlo-tree-search .
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24809;&#32602;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;Bilevel&#24378;&#21270;&#23398;&#20064;&#21644;RLHF&#38382;&#39064;&#65292;&#36825;&#26159;&#39318;&#20010;&#26377;&#21407;&#21017;&#30340;&#31639;&#27861;&#26694;&#26550;&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.06886</link><description>&lt;p&gt;
Bilevel&#24378;&#21270;&#23398;&#20064;&#21644;RLHF&#30340;&#26377;&#21407;&#21017;&#30340;&#22522;&#20110;&#24809;&#32602;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Principled Penalty-based Methods for Bilevel Reinforcement Learning and RLHF
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06886
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24809;&#32602;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;Bilevel&#24378;&#21270;&#23398;&#20064;&#21644;RLHF&#38382;&#39064;&#65292;&#36825;&#26159;&#39318;&#20010;&#26377;&#21407;&#21017;&#30340;&#31639;&#27861;&#26694;&#26550;&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;Bilevel&#20248;&#21270;&#24050;&#34987;&#24212;&#29992;&#20110;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#24212;&#29992;&#20165;&#38480;&#20110;&#30417;&#30563;&#23398;&#20064;&#35774;&#32622;&#65292;&#20854;&#20013;&#32771;&#34385;&#20102;&#20855;&#26377;&#33391;&#24615;&#32467;&#26500;&#30340;&#38745;&#24577;&#30446;&#26631;&#20989;&#25968;&#12290;&#20294;&#26159;&#65292;&#28608;&#21169;&#35774;&#35745;&#12289;&#21453;&#21521;&#24378;&#21270;&#23398;&#20064;(RL)&#21644;&#26469;&#33258;&#20154;&#31867;&#21453;&#39304;&#30340;RLHF&#31561;Bilevel&#38382;&#39064;&#36890;&#24120;&#34987;&#24314;&#27169;&#20026;&#36229;&#36234;&#31616;&#21333;&#38745;&#24577;&#30446;&#26631;&#32467;&#26500;&#30340;&#21160;&#24577;&#30446;&#26631;&#20989;&#25968;&#65292;&#36825;&#32473;&#20351;&#29992;&#29616;&#26377;Bilevel&#35299;&#20915;&#26041;&#26696;&#24102;&#26469;&#20102;&#37325;&#22823;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#26032;&#30340;Bilevel&#38382;&#39064;&#31867;&#21035;&#65292;&#25105;&#20204;&#36890;&#36807;&#24809;&#32602;&#24418;&#24335;&#24341;&#20837;&#20102;&#35299;&#20915;Bilevel RL&#38382;&#39064;&#30340;&#31532;&#19968;&#20010;&#21407;&#21017;&#24615;&#31639;&#27861;&#26694;&#26550;&#12290;&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#30740;&#31350;&#38382;&#39064;&#30340;&#26223;&#35266;&#21450;&#20854;&#22522;&#20110;&#24809;&#32602;&#30340;&#65288;&#31574;&#30053;&#65289;&#26799;&#24230;&#31639;&#27861;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;Stackelberg&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#12289;&#26469;&#33258;&#20154;&#31867;&#21453;&#39304;&#30340;RL&#21644;&#28608;&#21169;&#35774;&#35745;&#20013;&#36827;&#34892;&#27169;&#25311;&#26469;&#35777;&#26126;&#25105;&#20204;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bilevel optimization has been recently applied to many machine learning tasks. However, their applications have been restricted to the supervised learning setting, where static objective functions with benign structures are considered. But bilevel problems such as incentive design, inverse reinforcement learning (RL), and RL from human feedback (RLHF) are often modeled as dynamic objective functions that go beyond the simple static objective structures, which pose significant challenges of using existing bilevel solutions. To tackle this new class of bilevel problems, we introduce the first principled algorithmic framework for solving bilevel RL problems through the lens of penalty formulation. We provide theoretical studies of the problem landscape and its penalty-based (policy) gradient algorithms. We demonstrate the effectiveness of our algorithms via simulations in the Stackelberg Markov game, RL from human feedback and incentive design.
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#30417;&#30563;&#23398;&#20064;&#26694;&#26550;&#65288;S3L&#65289;&#65292;&#29992;&#20110;&#23398;&#20064;&#25972;&#20010;&#20999;&#29255;&#30340;&#34920;&#31034;&#12290;&#23427;&#32467;&#21512;&#20102;&#21464;&#21387;&#22120;&#27169;&#22411;&#30340;&#35270;&#35273;&#21644;&#35821;&#35328;&#24314;&#27169;&#31574;&#30053;&#65292;&#36890;&#36807;&#29983;&#25104;&#37197;&#23545;&#35270;&#22270;&#36827;&#34892;&#33258;&#30417;&#30563;&#23398;&#20064;&#65292;&#20197;&#23454;&#29616;&#39640;&#36136;&#37327;&#30340;WSI&#35270;&#35273;&#29305;&#24449;&#23398;&#20064;&#12290;</title><link>https://arxiv.org/abs/2402.06188</link><description>&lt;p&gt;
&#19968;&#20010;&#33258;&#30417;&#30563;&#23398;&#20064;&#26694;&#26550;&#29992;&#20110;&#23398;&#20064;&#25972;&#20010;&#20999;&#29255;&#30340;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
A self-supervised framework for learning whole slide representations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06188
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#30417;&#30563;&#23398;&#20064;&#26694;&#26550;&#65288;S3L&#65289;&#65292;&#29992;&#20110;&#23398;&#20064;&#25972;&#20010;&#20999;&#29255;&#30340;&#34920;&#31034;&#12290;&#23427;&#32467;&#21512;&#20102;&#21464;&#21387;&#22120;&#27169;&#22411;&#30340;&#35270;&#35273;&#21644;&#35821;&#35328;&#24314;&#27169;&#31574;&#30053;&#65292;&#36890;&#36807;&#29983;&#25104;&#37197;&#23545;&#35270;&#22270;&#36827;&#34892;&#33258;&#30417;&#30563;&#23398;&#20064;&#65292;&#20197;&#23454;&#29616;&#39640;&#36136;&#37327;&#30340;WSI&#35270;&#35273;&#29305;&#24449;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25972;&#20010;&#20999;&#29255;&#25104;&#20687;&#23545;&#20110;&#29983;&#29289;&#21307;&#23398;&#26174;&#24494;&#38236;&#21644;&#35745;&#31639;&#30149;&#29702;&#23398;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20854;&#21315;&#20806;&#20687;&#32032;&#30340;&#22823;&#23567;&#12289;&#22810;&#26679;&#30340;&#32452;&#32455;&#30149;&#29702;&#23398;&#29305;&#24449;&#12289;&#31354;&#38388;&#24322;&#36136;&#24615;&#20197;&#21450;&#26377;&#38480;&#30340;/&#19981;&#23384;&#22312;&#30340;&#25968;&#25454;&#27880;&#37322;&#65292;&#25972;&#20010;&#20999;&#29255;&#22270;&#20687; (WSIs) &#26500;&#25104;&#20102;&#19968;&#20010;&#22797;&#26434;&#30340;&#35745;&#31639;&#26426;&#35270;&#35273;&#25361;&#25112;&#12290;&#36825;&#20123;&#25361;&#25112;&#31361;&#26174;&#20102;&#20165;&#20381;&#38752;&#30417;&#30563;&#35757;&#32451;&#21487;&#33021;&#23548;&#33268;&#27425;&#20248;&#30340;&#25972;&#20010;&#20999;&#29255;&#34920;&#31034;&#12290;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#21487;&#20197;&#20026;&#19979;&#28216;&#35786;&#26029;&#20219;&#21153;&#65288;&#22914;&#30284;&#30151;&#35786;&#26029;&#25110;&#20998;&#23376;&#36951;&#20256;&#39044;&#27979;&#65289;&#23454;&#29616;&#39640;&#36136;&#37327;&#30340;WSI&#35270;&#35273;&#29305;&#24449;&#23398;&#20064;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#33258;&#30417;&#30563;&#25972;&#20010;&#20999;&#29255;&#23398;&#20064;&#65288;S3L&#65289;&#26694;&#26550;&#65292;&#29992;&#20110;&#21315;&#20806;&#20687;&#32032;&#35268;&#27169;&#30340;WSI&#33258;&#30417;&#30563;&#12290;S3L&#23558;&#26469;&#33258;&#22522;&#20110;&#21464;&#21387;&#22120;&#30340;&#35270;&#35273;&#21644;&#35821;&#35328;&#24314;&#27169;&#30340;&#25968;&#25454;&#36716;&#25442;&#31574;&#30053;&#32467;&#21512;&#21040;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#20013;&#65292;&#20197;&#29983;&#25104;&#29992;&#20110;&#33258;&#30417;&#30563;&#30340;&#37197;&#23545;&#35270;&#22270;&#12290;S3L&#21033;&#29992;&#20869;&#22312;&#30340;&#21306;&#22495;&#24322;&#36136;&#24615;&#12289;&#32452;&#32455;&#23398;&#29305;&#24449;&#30340;&#21487;&#21464;&#24615;&#21644;&#20449;&#24687;&#20887;&#20313;&#24615;
&lt;/p&gt;
&lt;p&gt;
Whole slide imaging is fundamental to biomedical microscopy and computational pathology. However, whole slide images (WSIs) present a complex computer vision challenge due to their gigapixel size, diverse histopathologic features, spatial heterogeneity, and limited/absent data annotations. These challenges highlight that supervised training alone can result in suboptimal whole slide representations. Self-supervised representation learning can achieve high-quality WSI visual feature learning for downstream diagnostic tasks, such as cancer diagnosis or molecular genetic prediction. Here, we present a general self-supervised whole slide learning (S3L) framework for gigapixel-scale self-supervision of WSIs. S3L combines data transformation strategies from transformer-based vision and language modeling into a single unified framework to generate paired views for self-supervision. S3L leverages the inherent regional heterogeneity, histologic feature variability, and information redundancy wi
&lt;/p&gt;</description></item><item><title>Premier-TACO&#26159;&#19968;&#31181;&#22810;&#20219;&#21153;&#29305;&#24449;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#39044;&#35757;&#32451;&#36890;&#29992;&#29305;&#24449;&#34920;&#31034;&#65292;&#24182;&#24341;&#20837;&#36127;&#20363;&#25277;&#26679;&#31574;&#30053;&#26469;&#25552;&#39640;&#26102;&#24207;&#34892;&#21160;&#23545;&#27604;&#23398;&#20064;&#30340;&#35745;&#31639;&#25928;&#29575;&#65292;&#20174;&#32780;&#26174;&#33879;&#22686;&#24378;&#20102;&#23545;&#26032;&#39062;&#21160;&#20316;&#30340;&#23569;&#26679;&#26412;&#27169;&#20223;&#23398;&#20064;&#30340;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.06187</link><description>&lt;p&gt;
Premier-TACO: &#36890;&#36807;&#26102;&#38388;&#39537;&#21160;&#30340;&#23545;&#27604;&#25439;&#22833;&#36827;&#34892;&#22810;&#20219;&#21153;&#34920;&#31034;&#39044;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Premier-TACO: Pretraining Multitask Representation via Temporal Action-Driven Contrastive Loss
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06187
&lt;/p&gt;
&lt;p&gt;
Premier-TACO&#26159;&#19968;&#31181;&#22810;&#20219;&#21153;&#29305;&#24449;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#39044;&#35757;&#32451;&#36890;&#29992;&#29305;&#24449;&#34920;&#31034;&#65292;&#24182;&#24341;&#20837;&#36127;&#20363;&#25277;&#26679;&#31574;&#30053;&#26469;&#25552;&#39640;&#26102;&#24207;&#34892;&#21160;&#23545;&#27604;&#23398;&#20064;&#30340;&#35745;&#31639;&#25928;&#29575;&#65292;&#20174;&#32780;&#26174;&#33879;&#22686;&#24378;&#20102;&#23545;&#26032;&#39062;&#21160;&#20316;&#30340;&#23569;&#26679;&#26412;&#27169;&#20223;&#23398;&#20064;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;Premier-TACO&#65292;&#36825;&#26159;&#19968;&#31181;&#22810;&#20219;&#21153;&#29305;&#24449;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#26088;&#22312;&#25552;&#39640;&#39034;&#24207;&#20915;&#31574;&#20219;&#21153;&#20013;&#23569;&#26679;&#26412;&#31574;&#30053;&#23398;&#20064;&#30340;&#25928;&#29575;&#12290;Premier-TACO&#21033;&#29992;&#19968;&#37096;&#20998;&#22810;&#20219;&#21153;&#31163;&#32447;&#25968;&#25454;&#38598;&#36827;&#34892;&#39044;&#35757;&#32451;&#36890;&#29992;&#29305;&#24449;&#34920;&#31034;&#65292;&#35813;&#29305;&#24449;&#34920;&#31034;&#25429;&#25417;&#20102;&#20851;&#38190;&#30340;&#29615;&#22659;&#21160;&#21147;&#23398;&#65292;&#24182;&#20351;&#29992;&#26368;&#23569;&#30340;&#19987;&#23478;&#28436;&#31034;&#36827;&#34892;&#24494;&#35843;&#12290;&#23427;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#26032;&#30340;&#36127;&#20363;&#25277;&#26679;&#31574;&#30053;&#25512;&#21160;&#20102;&#26102;&#24207;&#34892;&#21160;&#23545;&#27604;&#23398;&#20064;&#65288;TACO&#65289;&#30446;&#26631;&#30340;&#21457;&#23637;&#65292;TACO&#22312;&#35270;&#35273;&#25511;&#21046;&#20219;&#21153;&#20013;&#20855;&#26377;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;&#36825;&#31181;&#31574;&#30053;&#22312;&#26174;&#33879;&#25552;&#39640;TACO&#30340;&#35745;&#31639;&#25928;&#29575;&#26041;&#38754;&#38750;&#24120;&#37325;&#35201;&#65292;&#20351;&#22823;&#35268;&#27169;&#22810;&#20219;&#21153;&#31163;&#32447;&#39044;&#35757;&#32451;&#25104;&#20026;&#21487;&#33021;&#12290;&#25105;&#20204;&#22312;&#21253;&#25324;Deepmind Control Suite&#12289;MetaWorld&#21644;LIBERO&#22312;&#20869;&#30340;&#21508;&#31181;&#36830;&#32493;&#25511;&#21046;&#22522;&#20934;&#27979;&#35797;&#20013;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#23454;&#35777;&#35780;&#20272;&#65292;&#35777;&#26126;&#20102;Premier-TACO&#22312;&#39044;&#35757;&#32451;&#35270;&#35273;&#34920;&#31034;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#65292;&#26174;&#33879;&#22686;&#24378;&#20102;&#23545;&#26032;&#39062;&#21160;&#20316;&#30340;&#23569;&#26679;&#26412;&#27169;&#20223;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present Premier-TACO, a multitask feature representation learning approach designed to improve few-shot policy learning efficiency in sequential decision-making tasks. Premier-TACO leverages a subset of multitask offline datasets for pretraining a general feature representation, which captures critical environmental dynamics and is fine-tuned using minimal expert demonstrations. It advances the temporal action contrastive learning (TACO) objective, known for state-of-the-art results in visual control tasks, by incorporating a novel negative example sampling strategy. This strategy is crucial in significantly boosting TACO's computational efficiency, making large-scale multitask offline pretraining feasible. Our extensive empirical evaluation in a diverse set of continuous control benchmarks including Deepmind Control Suite, MetaWorld, and LIBERO demonstrate Premier-TACO's effectiveness in pretraining visual representations, significantly enhancing few-shot imitation learning of nove
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#25193;&#25955;&#27169;&#22411;&#21644;&#36125;&#21494;&#26031;&#26041;&#27861;&#36827;&#34892;&#40065;&#26834;&#21518;&#38376;&#25915;&#20987;&#30340;&#26041;&#27861;&#65292;&#20855;&#20307;&#24212;&#29992;&#20110;&#38899;&#39057;Transformer&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#20102;&#25915;&#20987;&#30340;&#21487;&#34892;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.05967</link><description>&lt;p&gt;
&#26368;&#21518;&#20043;&#33310;&#65306;&#36890;&#36807;&#25193;&#25955;&#27169;&#22411;&#21644;&#36125;&#21494;&#26031;&#26041;&#27861;&#36827;&#34892;&#40065;&#26834;&#21518;&#38376;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
The last Dance : Robust backdoor attack via diffusion models and bayesian approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05967
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#25193;&#25955;&#27169;&#22411;&#21644;&#36125;&#21494;&#26031;&#26041;&#27861;&#36827;&#34892;&#40065;&#26834;&#21518;&#38376;&#25915;&#20987;&#30340;&#26041;&#27861;&#65292;&#20855;&#20307;&#24212;&#29992;&#20110;&#38899;&#39057;Transformer&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#20102;&#25915;&#20987;&#30340;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#26159;&#26368;&#20808;&#36827;&#30340;&#28145;&#24230;&#23398;&#20064;&#29983;&#25104;&#27169;&#22411;&#65292;&#20854;&#36890;&#36807;&#36880;&#27493;&#28155;&#21152;&#22122;&#38899;&#21644;&#21435;&#22122;&#30340;&#26041;&#24335;&#23398;&#20064;&#27491;&#21521;&#21644;&#21453;&#21521;&#25193;&#25955;&#36807;&#31243;&#30340;&#21407;&#29702;&#36827;&#34892;&#35757;&#32451;&#12290;&#26412;&#25991;&#26088;&#22312;&#27450;&#39575;&#22522;&#20110;&#38899;&#39057;&#30340;DNN&#27169;&#22411;&#65292;&#20363;&#22914;Hugging Face&#26694;&#26550;&#20013;&#30340;&#38899;&#39057;&#27169;&#22411;&#65292;&#29305;&#21035;&#26159;&#22522;&#20110;Transformer&#30340;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#65292;&#36825;&#20123;&#27169;&#22411;&#26159;&#24378;&#22823;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#33410;&#30465;&#26102;&#38388;&#65292;&#25552;&#20379;&#26356;&#39640;&#25928;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;Hugging Face&#25512;&#23548;&#20986;&#30340;&#38899;&#39057;Transformer&#19978;&#23454;&#29616;&#21518;&#38376;&#25915;&#20987;&#65288;&#31216;&#20026;`BacKBayDiffMod`&#65289;&#30340;&#21487;&#34892;&#24615;&#12290;&#26412;&#25991;&#20013;&#24320;&#21457;&#30340;&#21518;&#38376;&#25915;&#20987;&#22522;&#20110;&#27602;&#21270;&#27169;&#22411;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#28041;&#21450;&#21518;&#38376;&#25193;&#25955;&#37319;&#26679;&#21644;&#36125;&#21494;&#26031;&#26041;&#27861;&#20998;&#24067;&#30340;&#24341;&#20837;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models are state-of-the-art deep learning generative models that are trained on the principle of learning forward and backward diffusion processes via the progressive addition of noise and denoising. In this paper, we seek to trick audio-based DNN models, such as those in the Hugging Face framework, for example, those that focus on audio, in particular transformer-based artificial intelligence models, which are powerful machine learning models that save time and deliver faster, more efficient results. We demonstrate the feasibility of backdoor attacks (called `BacKBayDiffMod`) on audio transformers derived from Hugging Face, a popular framework in the world of artificial intelligence (AI) research. The backdoor attack developed in this paper is based on poisoning the model's training data by incorporating backdoor diffusion sampling and a Bayesian approach to the distribution of poisoned data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#38543;&#26426;&#36817;&#20284;&#26799;&#24230;&#26368;&#23567;&#21270;&#25237;&#24433;&#32676;&#20307;&#39118;&#38505;&#30340;&#26032;&#22411;&#38750;&#21442;&#25968;&#20202;&#22120;&#21464;&#37327;&#22238;&#24402;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#35777;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#31454;&#20105;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#36824;&#22788;&#29702;&#20102;&#20108;&#20803;&#32467;&#26524;&#30340;&#24773;&#20917;&#65292;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.05639</link><description>&lt;p&gt;
&#38750;&#21442;&#25968;&#20202;&#22120;&#21464;&#37327;&#22238;&#24402;&#36890;&#36807;&#38543;&#26426;&#36817;&#20284;&#26799;&#24230;
&lt;/p&gt;
&lt;p&gt;
Nonparametric Instrumental Variable Regression through Stochastic Approximate Gradients
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05639
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#38543;&#26426;&#36817;&#20284;&#26799;&#24230;&#26368;&#23567;&#21270;&#25237;&#24433;&#32676;&#20307;&#39118;&#38505;&#30340;&#26032;&#22411;&#38750;&#21442;&#25968;&#20202;&#22120;&#21464;&#37327;&#22238;&#24402;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#35777;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#31454;&#20105;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#36824;&#22788;&#29702;&#20102;&#20108;&#20803;&#32467;&#26524;&#30340;&#24773;&#20917;&#65292;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;SAGD-IV&#65292;&#36825;&#26159;&#19968;&#31181;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#36817;&#20284;&#26799;&#24230;&#26469;&#26368;&#23567;&#21270;&#25237;&#24433;&#32676;&#20307;&#39118;&#38505;&#30340;&#26032;&#22411;&#38750;&#21442;&#25968;&#20202;&#22120;&#21464;&#37327;&#65288;NPIV&#65289;&#22238;&#24402;&#26694;&#26550;&#12290;&#20202;&#22120;&#21464;&#37327;&#65288;IV&#65289;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#35745;&#37327;&#32463;&#27982;&#23398;&#20013;&#65292;&#20197;&#35299;&#20915;&#22312;&#23384;&#22312;&#19981;&#21487;&#35266;&#27979;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#30340;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#19988;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#33268;&#21147;&#20110;&#25913;&#36827;&#29616;&#26377;&#26041;&#27861;&#24182;&#22312;NPIV&#35774;&#32622;&#19979;&#35774;&#35745;&#26032;&#26041;&#27861;&#65292;&#35813;&#35774;&#32622;&#34987;&#35748;&#20026;&#26159;&#19968;&#20010;&#19981;&#36866;&#23450;&#30340;&#32447;&#24615;&#36870;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#25105;&#20204;&#31639;&#27861;&#30340;&#29702;&#35770;&#25903;&#25345;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#23454;&#39564;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#20854;&#31454;&#20105;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#22788;&#29702;&#20102;&#20108;&#20803;&#32467;&#26524;&#30340;&#24773;&#20917;&#65292;&#24182;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#65292;&#32780;&#35813;&#24773;&#20917;&#22312;&#31038;&#21306;&#20013;&#27809;&#26377;&#24471;&#21040;&#19982;&#20854;&#36830;&#32493;&#23545;&#24212;&#29289;&#30340;&#21516;&#26679;&#20851;&#27880;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes SAGD-IV, a novel framework for conducting nonparametric instrumental variable (NPIV) regression by employing stochastic approximate gradients to minimize the projected populational risk. Instrumental Variables (IVs) are widely used in econometrics to address estimation problems in the presence of unobservable confounders, and the Machine Learning community has devoted significant effort to improving existing methods and devising new ones in the NPIV setting, which is known to be an ill-posed linear inverse problem. We provide theoretical support for our algorithm and further exemplify its competitive performance through empirical experiments. Furthermore, we address, with promising results, the case of binary outcomes, which has not received as much attention from the community as its continuous counterpart.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;QGFN&#65292;&#36890;&#36807;&#23558;GFN&#31574;&#30053;&#19982;&#21160;&#20316;&#20540;&#20272;&#35745;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#29983;&#25104;&#26356;&#22810;&#39640;&#22870;&#21169;&#30340;&#26679;&#26412;&#32780;&#19981;&#29306;&#29298;&#22810;&#26679;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.05234</link><description>&lt;p&gt;
QGFN:&#20855;&#26377;&#21160;&#20316;&#20540;&#30340;&#21487;&#25511;&#36138;&#23146;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
QGFN: Controllable Greediness with Action Values
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05234
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;QGFN&#65292;&#36890;&#36807;&#23558;GFN&#31574;&#30053;&#19982;&#21160;&#20316;&#20540;&#20272;&#35745;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#29983;&#25104;&#26356;&#22810;&#39640;&#22870;&#21169;&#30340;&#26679;&#26412;&#32780;&#19981;&#29306;&#29298;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27969;&#32593;&#32476;&#65288;GFlowNets;GFNs&#65289;&#26159;&#19968;&#31181;&#29992;&#20110;&#32452;&#21512;&#23545;&#35937;&#30340;&#22522;&#20110;&#22870;&#21169;/&#33021;&#37327;&#30340;&#29983;&#25104;&#26041;&#27861;&#65292;&#33021;&#22815;&#29983;&#25104;&#22810;&#26679;&#21270;&#21644;&#39640;&#25928;&#30340;&#26679;&#26412;&#12290;&#28982;&#32780;&#65292;&#20559;&#21521;&#20110;&#29983;&#25104;&#39640;&#25928;&#26679;&#26412;&#30340;GFNs&#24182;&#19981;&#23481;&#26131;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;GFNs&#21644;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#25552;&#20986;&#23558;GFN&#31574;&#30053;&#19982;&#21160;&#20316;&#20540;&#20272;&#35745;$Q$&#30456;&#32467;&#21512;&#65292;&#20174;&#32780;&#21019;&#24314;&#21487;&#20197;&#36890;&#36807;&#28151;&#21512;&#21442;&#25968;&#25511;&#21046;&#30340;&#36138;&#23146;&#37319;&#26679;&#31574;&#30053;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20960;&#20010;QGFN&#30340;&#21464;&#20307;&#33021;&#22815;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#25913;&#21892;&#29983;&#25104;&#39640;&#22870;&#21169;&#26679;&#26412;&#30340;&#25968;&#37327;&#65292;&#21516;&#26102;&#19981;&#29306;&#29298;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative Flow Networks (GFlowNets; GFNs) are a family of reward/energy-based generative methods for combinatorial objects, capable of generating diverse and high-utility samples. However, biasing GFNs towards producing high-utility samples is non-trivial. In this work, we leverage connections between GFNs and reinforcement learning (RL) and propose to combine the GFN policy with an action-value estimate, $Q$, to create greedier sampling policies which can be controlled by a mixing parameter. We show that several variants of the proposed method, QGFN, are able to improve on the number of high-reward samples generated in a variety of tasks without sacrificing diversity.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;VAR&#27169;&#22411;&#65292;&#21033;&#29992;&#20998;&#23618;&#22270;&#20808;&#39564;&#25512;&#26029;&#20108;&#20803;&#26684;&#20848;&#26480;&#22240;&#26524;&#22270;&#30340;&#21518;&#39564;&#27010;&#29575;&#12290;&#30456;&#27604;&#31454;&#20105;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12289;&#36229;&#21442;&#25968;&#25968;&#37327;&#21644;&#31232;&#30095;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#19978;&#37117;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>https://arxiv.org/abs/2402.03614</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#20998;&#35299;&#26684;&#20848;&#26480;&#22240;&#26524;&#22270;&#29992;&#20110;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Bayesian Factorised Granger-Causal Graphs For Multivariate Time-series Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03614
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;VAR&#27169;&#22411;&#65292;&#21033;&#29992;&#20998;&#23618;&#22270;&#20808;&#39564;&#25512;&#26029;&#20108;&#20803;&#26684;&#20848;&#26480;&#22240;&#26524;&#22270;&#30340;&#21518;&#39564;&#27010;&#29575;&#12290;&#30456;&#27604;&#31454;&#20105;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12289;&#36229;&#21442;&#25968;&#25968;&#37327;&#21644;&#31232;&#30095;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#19978;&#37117;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#33258;&#21160;&#21457;&#29616;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#26684;&#20848;&#26480;&#22240;&#26524;&#20851;&#31995;&#30340;&#38382;&#39064;&#12290;&#30690;&#37327;&#33258;&#22238;&#24402;(VAR)&#27169;&#22411;&#24050;&#32463;&#22312;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#19978;&#32463;&#36807;&#20102;&#26102;&#38388;&#30340;&#32771;&#39564;&#65292;&#21253;&#25324;&#36125;&#21494;&#26031;&#21464;&#31181;&#21644;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#26032;&#21457;&#23637;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;VAR&#26684;&#20848;&#26480;&#22240;&#26524;&#26041;&#27861;&#20351;&#29992;&#31232;&#30095;&#24615;&#35825;&#23548;&#24809;&#32602;/&#20808;&#39564;&#25110;&#20107;&#21518;&#38408;&#20540;&#26469;&#35299;&#37322;&#23427;&#20204;&#30340;&#31995;&#25968;&#20316;&#20026;&#26684;&#20848;&#26480;&#22240;&#26524;&#22270;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#36125;&#21494;&#26031;VAR&#27169;&#22411;&#65292;&#20854;&#20013;&#21253;&#21547;&#20102;&#19968;&#20010;&#20998;&#23618;&#22270;&#20808;&#39564;&#26469;&#34920;&#31034;&#20108;&#20803;&#26684;&#20848;&#26480;&#22240;&#26524;&#22270;&#65292;&#19982;VAR&#31995;&#25968;&#20998;&#24320;&#32771;&#34385;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#31639;&#27861;&#26469;&#25512;&#26029;&#20108;&#20803;&#26684;&#20848;&#26480;&#22240;&#26524;&#22270;&#30340;&#21518;&#39564;&#27010;&#29575;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#36739;&#23569;&#30340;&#36229;&#21442;&#25968;&#65292;&#24182;&#22312;&#31232;&#30095;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#19978;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of automatically discovering Granger causal relations from observational multivariate time-series data. Vector autoregressive (VAR) models have been time-tested for this problem, including Bayesian variants and more recent developments using deep neural networks. Most existing VAR methods for Granger causality use sparsity-inducing penalties/priors or post-hoc thresholds to interpret their coefficients as Granger causal graphs. Instead, we propose a new Bayesian VAR model with a hierarchical graph prior over binary Granger causal graphs, separately from the VAR coefficients. We develop an efficient algorithm to infer the posterior over binary Granger causal graphs. Our method provides better uncertainty quantification, has less hyperparameters, and achieves better performance than competing approaches, especially on sparse multivariate time-series data.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#31354;&#38388;&#29615;&#22659;&#20013;&#39564;&#35777;&#39044;&#27979;&#26041;&#27861;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22788;&#29702;&#19981;&#21305;&#37197;&#24773;&#20917;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.03527</link><description>&lt;p&gt;
&#22312;&#31354;&#38388;&#29615;&#22659;&#20013;&#19968;&#33268;&#39564;&#35777;&#39044;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Consistent Validation for Predictive Methods in Spatial Settings
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03527
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#31354;&#38388;&#29615;&#22659;&#20013;&#39564;&#35777;&#39044;&#27979;&#26041;&#27861;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22788;&#29702;&#19981;&#21305;&#37197;&#24773;&#20917;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31354;&#38388;&#39044;&#27979;&#20219;&#21153;&#23545;&#20110;&#22825;&#27668;&#39044;&#25253;&#12289;&#31354;&#27668;&#27745;&#26579;&#30740;&#31350;&#21644;&#20854;&#20182;&#31185;&#23398;&#24037;&#20316;&#33267;&#20851;&#37325;&#35201;&#12290;&#30830;&#23450;&#25105;&#20204;&#23545;&#32479;&#35745;&#25110;&#29289;&#29702;&#26041;&#27861;&#25152;&#20316;&#39044;&#27979;&#30340;&#21487;&#20449;&#24230;&#26159;&#31185;&#23398;&#32467;&#35770;&#30340;&#37325;&#35201;&#38382;&#39064;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#20256;&#32479;&#30340;&#39564;&#35777;&#26041;&#27861;&#26080;&#27861;&#22788;&#29702;&#39564;&#35777;&#20301;&#32622;&#21644;&#25105;&#20204;&#24076;&#26395;&#36827;&#34892;&#39044;&#27979;&#30340;&#65288;&#27979;&#35797;&#65289;&#20301;&#32622;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#12290;&#36825;&#31181;&#19981;&#21305;&#37197;&#36890;&#24120;&#19981;&#26159;&#21327;&#21464;&#37327;&#20559;&#31227;&#30340;&#19968;&#20010;&#23454;&#20363;&#65288;&#24120;&#24120;&#34987;&#24418;&#24335;&#21270;&#65289;&#65292;&#22240;&#20026;&#39564;&#35777;&#21644;&#27979;&#35797;&#20301;&#32622;&#26159;&#22266;&#23450;&#30340;&#65288;&#20363;&#22914;&#65292;&#22312;&#32593;&#26684;&#19978;&#25110;&#36873;&#23450;&#30340;&#28857;&#19978;&#65289;&#65292;&#32780;&#19981;&#26159;&#20174;&#20004;&#20010;&#20998;&#24067;&#20013;&#29420;&#31435;&#21516;&#20998;&#24067;&#22320;&#37319;&#26679;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24418;&#24335;&#21270;&#20102;&#23545;&#39564;&#35777;&#26041;&#27861;&#30340;&#26816;&#26597;&#65306;&#38543;&#30528;&#39564;&#35777;&#25968;&#25454;&#30340;&#23494;&#24230;&#36234;&#26469;&#36234;&#22823;&#65292;&#23427;&#20204;&#33021;&#22815;&#21464;&#24471;&#20219;&#24847;&#31934;&#30830;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20256;&#32479;&#26041;&#27861;&#21644;&#21327;&#21464;&#37327;&#20559;&#31227;&#26041;&#27861;&#21487;&#33021;&#19981;&#28385;&#36275;&#36825;&#20010;&#26816;&#26597;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#23427;&#20511;&#37492;&#20102;&#21327;&#21464;&#37327;&#20559;&#31227;&#25991;&#29486;&#20013;&#30340;&#29616;&#26377;&#24605;&#24819;&#65292;&#20294;&#23545;&#39564;&#35777;&#25968;&#25454;&#36827;&#34892;&#20102;&#35843;&#25972;&#12290;
&lt;/p&gt;
&lt;p&gt;
Spatial prediction tasks are key to weather forecasting, studying air pollution, and other scientific endeavors. Determining how much to trust predictions made by statistical or physical methods is essential for the credibility of scientific conclusions. Unfortunately, classical approaches for validation fail to handle mismatch between locations available for validation and (test) locations where we want to make predictions. This mismatch is often not an instance of covariate shift (as commonly formalized) because the validation and test locations are fixed (e.g., on a grid or at select points) rather than i.i.d. from two distributions. In the present work, we formalize a check on validation methods: that they become arbitrarily accurate as validation data becomes arbitrarily dense. We show that classical and covariate-shift methods can fail this check. We instead propose a method that builds from existing ideas in the covariate-shift literature, but adapts them to the validation data 
&lt;/p&gt;</description></item><item><title>&#21516;&#24615;&#36136;&#30340;&#23884;&#20837;&#31354;&#38388;&#23545;&#32858;&#31867;&#21644;&#32447;&#24615;&#20998;&#31867;&#30446;&#26631;&#20855;&#26377;&#36127;&#38754;&#24433;&#21709;&#65292;&#36825;&#19968;&#20107;&#23454;&#24471;&#21040;&#20102;&#26412;&#25991;&#30340;&#23454;&#35777;&#25903;&#25345;&#65292;&#24182;&#23545;&#25991;&#29486;&#20013;&#30340;&#20808;&#21069;&#32467;&#26524;&#26377;&#25152;&#21551;&#31034;&#12290;</title><link>https://arxiv.org/abs/2402.03191</link><description>&lt;p&gt;
&#21516;&#24615;&#36136;&#65292;&#32858;&#31867;&#21644;&#20998;&#31867;&#22120;
&lt;/p&gt;
&lt;p&gt;
Isotropy, Clusters, and Classifiers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03191
&lt;/p&gt;
&lt;p&gt;
&#21516;&#24615;&#36136;&#30340;&#23884;&#20837;&#31354;&#38388;&#23545;&#32858;&#31867;&#21644;&#32447;&#24615;&#20998;&#31867;&#30446;&#26631;&#20855;&#26377;&#36127;&#38754;&#24433;&#21709;&#65292;&#36825;&#19968;&#20107;&#23454;&#24471;&#21040;&#20102;&#26412;&#25991;&#30340;&#23454;&#35777;&#25903;&#25345;&#65292;&#24182;&#23545;&#25991;&#29486;&#20013;&#30340;&#20808;&#21069;&#32467;&#26524;&#26377;&#25152;&#21551;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#20851;&#20110;&#23884;&#20837;&#31354;&#38388;&#26159;&#21542;&#22343;&#21248;&#21033;&#29992;&#25152;&#26377;&#32500;&#24230;&#65288;&#21363;&#26159;&#21542;&#20855;&#26377;&#21516;&#24615;&#36136;&#65289;&#30340;&#38382;&#39064;&#24341;&#36215;&#20102;&#35752;&#35770;&#12290;&#26377;&#35777;&#25454;&#25903;&#25345;&#21644;&#21453;&#23545;&#22312;&#23884;&#20837;&#31354;&#38388;&#20013;&#23454;&#26045;&#21516;&#24615;&#36136;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24378;&#35843;&#21516;&#24615;&#36136;&#23545;&#23884;&#20837;&#31354;&#38388;&#30340;&#35201;&#27714;&#19982;&#32858;&#31867;&#30340;&#23384;&#22312;&#19981;&#20860;&#23481;&#65292;&#36825;&#20063;&#23545;&#32447;&#24615;&#20998;&#31867;&#30446;&#26631;&#20135;&#29983;&#20102;&#36127;&#38754;&#24433;&#21709;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20010;&#20107;&#23454;&#65292;&#24182;&#29992;&#23427;&#26469;&#38416;&#26126;&#25991;&#29486;&#20013;&#30340;&#20808;&#21069;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Whether embedding spaces use all their dimensions equally, i.e., whether they are isotropic, has been a recent subject of discussion. Evidence has been accrued both for and against enforcing isotropy in embedding spaces. In the present paper, we stress that isotropy imposes requirements on the embedding space that are not compatible with the presence of clusters -- which also negatively impacts linear classification objectives. We demonstrate this fact empirically and use it to shed light on previous results from the literature.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#23545;&#20598;&#25289;&#26684;&#26391;&#26085;&#23398;&#20064;&#65288;DLL&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#38181;&#23545;&#20598;&#29702;&#35770;&#21644;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#34920;&#31034;&#33021;&#21147;&#65292;&#22312;&#21442;&#25968;&#21270;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#38181;&#20248;&#21270;&#38382;&#39064;&#19978;&#25552;&#20379;&#20102;&#26377;&#25928;&#30340;&#25289;&#26684;&#26391;&#26085;&#23545;&#20598;&#30028;&#38480;&#65292;&#35777;&#26126;&#20102;&#20854;&#24615;&#33021;&#22312;&#20248;&#21270;&#38382;&#39064;&#19978;&#25509;&#36817;&#26368;&#20248;&#35299;&#30340;0.5%&#12290;</title><link>https://arxiv.org/abs/2402.03086</link><description>&lt;p&gt;
&#23545;&#20598;&#25289;&#26684;&#26391;&#26085;&#23398;&#20064;&#29992;&#20110;&#38181;&#20248;&#21270;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Dual Lagrangian Learning for Conic Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03086
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#23545;&#20598;&#25289;&#26684;&#26391;&#26085;&#23398;&#20064;&#65288;DLL&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#38181;&#23545;&#20598;&#29702;&#35770;&#21644;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#34920;&#31034;&#33021;&#21147;&#65292;&#22312;&#21442;&#25968;&#21270;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#38181;&#20248;&#21270;&#38382;&#39064;&#19978;&#25552;&#20379;&#20102;&#26377;&#25928;&#30340;&#25289;&#26684;&#26391;&#26085;&#23545;&#20598;&#30028;&#38480;&#65292;&#35777;&#26126;&#20102;&#20854;&#24615;&#33021;&#22312;&#20248;&#21270;&#38382;&#39064;&#19978;&#25509;&#36817;&#26368;&#20248;&#35299;&#30340;0.5%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#23545;&#20598;&#25289;&#26684;&#26391;&#26085;&#23398;&#20064;&#65288;DLL&#65289;&#65292;&#19968;&#31181;&#32467;&#21512;&#38181;&#23545;&#20598;&#29702;&#35770;&#21644;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#34920;&#31034;&#33021;&#21147;&#30340;&#21407;&#29702;&#24615;&#23398;&#20064;&#26041;&#27861;&#12290;DLL&#21033;&#29992;&#38181;&#23545;&#20598;&#25552;&#20379;&#23545;&#20598;&#21487;&#34892;&#35299;&#65292;&#24182;&#22240;&#27492;&#23545;&#21442;&#25968;&#21270;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#38181;&#20248;&#21270;&#38382;&#39064;&#25552;&#20379;&#26377;&#25928;&#30340;&#25289;&#26684;&#26391;&#26085;&#23545;&#20598;&#30028;&#38480;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#21487;&#24494;&#20998;&#38181;&#25237;&#24433;&#23618;&#65292;&#19968;&#20010;&#31995;&#32479;&#30340;&#23545;&#20598;&#23436;&#25104;&#36807;&#31243;&#20197;&#21450;&#19968;&#20010;&#33258;&#30417;&#30563;&#23398;&#20064;&#26694;&#26550;&#12290;DLL&#30340;&#26377;&#25928;&#24615;&#22312;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#21442;&#25968;&#21270;&#20248;&#21270;&#38382;&#39064;&#19978;&#24471;&#21040;&#20102;&#35777;&#26126;&#65292;DLL&#21487;&#20197;&#22312;&#20248;&#21270;&#24615;&#33021;&#30340;0.5%&#20043;&#20869;&#25552;&#20379;&#26377;&#25928;&#30340;&#23545;&#20598;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents Dual Lagrangian Learning (DLL), a principled learning methodology that combines conic duality theory with the represen- tation power of ML models. DLL leverages conic duality to provide dual-feasible solutions, and therefore valid Lagrangian dual bounds, for para- metric linear and nonlinear conic optimization problems. The paper introduces differentiable conic projection layers, a systematic dual com- pletion procedure, and a self-supervised learning framework. The effectiveness of DLL is demon- strated on linear and nonlinear parametric opti- mization problems for which DLL provides valid dual bounds within 0.5% of optimality.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#35299;&#30721;&#26102;&#38388;&#23545;&#40784;&#65288;DeRa&#65289;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#37325;&#26032;&#35757;&#32451;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#25506;&#32034;&#21644;&#35780;&#20272;&#19981;&#21516;&#30340;&#35268;&#21017;&#21270;&#24378;&#24230;&#65292;&#20174;&#32780;&#23545;&#40784;&#35821;&#35328;&#27169;&#22411;&#21644;&#20154;&#31867;&#20559;&#22909;&#12290;</title><link>https://arxiv.org/abs/2402.02992</link><description>&lt;p&gt;
&#35770;&#25991;&#26631;&#39064;&#65306;&#35299;&#30721;&#26102;&#38388;&#23545;&#40784;&#30340;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Decoding-time Realignment of Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02992
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#35299;&#30721;&#26102;&#38388;&#23545;&#40784;&#65288;DeRa&#65289;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#37325;&#26032;&#35757;&#32451;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#25506;&#32034;&#21644;&#35780;&#20272;&#19981;&#21516;&#30340;&#35268;&#21017;&#21270;&#24378;&#24230;&#65292;&#20174;&#32780;&#23545;&#40784;&#35821;&#35328;&#27169;&#22411;&#21644;&#20154;&#31867;&#20559;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#35821;&#35328;&#27169;&#22411;&#19982;&#20154;&#31867;&#20559;&#22909;&#23545;&#40784;&#23545;&#20110;&#20943;&#23569;&#27169;&#22411;&#20013;&#30340;&#38169;&#35823;&#21644;&#20559;&#24046;&#38750;&#24120;&#37325;&#35201;&#12290;&#23545;&#40784;&#25216;&#26415;&#65292;&#22914;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#36827;&#34892;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RLHF&#65289;&#65292;&#36890;&#24120;&#34987;&#35270;&#20026;&#22312;&#20154;&#31867;&#20559;&#22909;&#22870;&#21169;&#21644;&#40723;&#21169;&#20445;&#25345;&#19982;&#26410;&#23545;&#40784;&#27169;&#22411;&#25509;&#36817;&#30340;&#25509;&#36817;&#24615;&#35268;&#21017;&#39033;&#20043;&#38388;&#36827;&#34892;&#20248;&#21270;&#30340;&#26435;&#34913;&#12290;&#36873;&#25321;&#36866;&#24403;&#30340;&#35268;&#21017;&#21270;&#27700;&#24179;&#33267;&#20851;&#37325;&#35201;&#65306;&#35268;&#21017;&#21270;&#19981;&#36275;&#21487;&#33021;&#23548;&#33268;&#30001;&#20110;&#22870;&#21169;&#27450;&#39575;&#32780;&#38477;&#20302;&#27169;&#22411;&#33021;&#21147;&#65292;&#32780;&#36807;&#24230;&#35268;&#21017;&#21270;&#21017;&#38459;&#30861;&#23545;&#40784;&#12290;&#20256;&#32479;&#26041;&#27861;&#25214;&#21040;&#26368;&#20339;&#35268;&#21017;&#21270;&#27700;&#24179;&#38656;&#35201;&#20351;&#29992;&#19981;&#21516;&#35268;&#21017;&#21270;&#24378;&#24230;&#37325;&#26032;&#35757;&#32451;&#22810;&#20010;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#36825;&#20010;&#36807;&#31243;&#32791;&#36153;&#36164;&#28304;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#22823;&#22411;&#27169;&#22411;&#26469;&#35828;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#35299;&#30721;&#26102;&#38388;&#23545;&#40784;&#65288;DeRa&#65289;&#65292;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#65292;&#22312;&#26080;&#38656;&#37325;&#26032;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#25506;&#32034;&#21644;&#35780;&#20272;&#19981;&#21516;&#30340;&#35268;&#21017;&#21270;&#24378;&#24230;&#12290;DeRa&#21487;&#20197;&#23545;&#23545;&#40784;&#27169;&#22411;&#30340;&#31243;&#24230;&#36827;&#34892;&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Aligning language models with human preferences is crucial for reducing errors and biases in these models. Alignment techniques, such as reinforcement learning from human feedback (RLHF), are typically cast as optimizing a tradeoff between human preference rewards and a proximity regularization term that encourages staying close to the unaligned model. Selecting an appropriate level of regularization is critical: insufficient regularization can lead to reduced model capabilities due to reward hacking, whereas excessive regularization hinders alignment. Traditional methods for finding the optimal regularization level require retraining multiple models with varying regularization strengths. This process, however, is resource-intensive, especially for large models. To address this challenge, we propose decoding-time realignment (DeRa), a simple method to explore and evaluate different regularization strengths in aligned models without retraining. DeRa enables control over the degree of al
&lt;/p&gt;</description></item><item><title>MetaOptimize&#26159;&#19968;&#20010;&#26694;&#26550;&#65292;&#36890;&#36807;&#21160;&#24577;&#35843;&#25972;&#23398;&#20064;&#29575;&#26469;&#20248;&#21270;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#20013;&#30340;&#20803;&#21442;&#25968;&#65292;&#20197;&#25552;&#39640;&#35757;&#32451;&#25928;&#29575;&#21644;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.02342</link><description>&lt;p&gt;
MetaOptimize&#65306;&#19968;&#20010;&#20248;&#21270;&#27493;&#38271;&#21644;&#20854;&#20182;&#20803;&#21442;&#25968;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
MetaOptimize: A Framework for Optimizing Step Sizes and Other Meta-parameters
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02342
&lt;/p&gt;
&lt;p&gt;
MetaOptimize&#26159;&#19968;&#20010;&#26694;&#26550;&#65292;&#36890;&#36807;&#21160;&#24577;&#35843;&#25972;&#23398;&#20064;&#29575;&#26469;&#20248;&#21270;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#20013;&#30340;&#20803;&#21442;&#25968;&#65292;&#20197;&#25552;&#39640;&#35757;&#32451;&#25928;&#29575;&#21644;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#20013;&#20248;&#21270;&#20803;&#21442;&#25968;&#65288;&#21363;&#36229;&#21442;&#25968;&#65289;&#30340;&#25361;&#25112;&#65292;&#36825;&#26159;&#24433;&#21709;&#35757;&#32451;&#25928;&#29575;&#21644;&#27169;&#22411;&#24615;&#33021;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;MetaOptimize&#26694;&#26550;&#65292;&#25670;&#33073;&#20102;&#35745;&#31639;&#26114;&#36149;&#30340;&#20256;&#32479;&#20803;&#21442;&#25968;&#25628;&#32034;&#26041;&#27861;&#65292;&#36890;&#36807;&#21160;&#24577;&#35843;&#25972;&#20803;&#21442;&#25968;&#65292;&#29305;&#21035;&#26159;&#27493;&#38271;&#65288;&#20063;&#31216;&#20026;&#23398;&#20064;&#29575;&#65289;&#65292;&#26469;&#35757;&#32451;&#27169;&#22411;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;MetaOptimize&#21487;&#20197;&#36866;&#29992;&#20110;&#20219;&#20309;&#19968;&#38454;&#20248;&#21270;&#31639;&#27861;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#23454;&#26102;&#35843;&#25972;&#27493;&#38271;&#65292;&#36890;&#36807;&#26410;&#26469;&#25439;&#22833;&#30340;&#25240;&#29616;&#24635;&#21644;&#26469;&#26368;&#23567;&#21270;&#19968;&#31181;&#29305;&#23450;&#24418;&#24335;&#30340;&#36951;&#25022;&#12290;&#25105;&#20204;&#36824;&#20171;&#32461;&#20102;MetaOptimize&#30340;&#20302;&#22797;&#26434;&#24230;&#21464;&#20307;&#65292;&#32467;&#21512;&#20854;&#36866;&#24212;&#22810;&#20010;&#20248;&#21270;&#31639;&#27861;&#30340;&#33021;&#21147;&#65292;&#23637;&#31034;&#20102;&#22312;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#19982;&#25163;&#24037;&#35774;&#35745;&#30340;&#23398;&#20064;&#29575;&#35745;&#21010;&#30456;&#23218;&#32654;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper addresses the challenge of optimizing meta-parameters (i.e., hyperparameters) in machine learning algorithms, a critical factor influencing training efficiency and model performance. Moving away from the computationally expensive traditional meta-parameter search methods, we introduce MetaOptimize framework that dynamically adjusts meta-parameters, particularly step sizes (also known as learning rates), during training. More specifically, MetaOptimize can wrap around any first-order optimization algorithm, tuning step sizes on the fly to minimize a specific form of regret that accounts for long-term effect of step sizes on training, through a discounted sum of future losses. We also introduce low complexity variants of MetaOptimize that, in conjunction with its adaptability to multiple optimization algorithms, demonstrate performance competitive to those of best hand-crafted learning rate schedules across various machine learning applications.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#31995;&#32479;&#22320;&#25506;&#35752;&#20102;Transformer&#22312;&#38271;&#24207;&#21015;&#24314;&#27169;&#20013;&#30340;&#36817;&#20284;&#24615;&#36136;&#65292;&#24182;&#30740;&#31350;&#20102;&#20854;&#20851;&#38190;&#32452;&#20214;&#23545;&#34920;&#36798;&#33021;&#21147;&#30340;&#24433;&#21709;&#26426;&#21046;&#12290;&#36825;&#20123;&#21457;&#29616;&#25581;&#31034;&#20102;&#20851;&#38190;&#21442;&#25968;&#23545;Transformer&#30340;&#20316;&#29992;&#65292;&#24182;&#20026;&#26367;&#20195;&#26550;&#26500;&#25552;&#20379;&#20102;&#33258;&#28982;&#24314;&#35758;&#12290;</title><link>https://arxiv.org/abs/2402.00522</link><description>&lt;p&gt;
&#29702;&#35299;Transformer&#22312;&#24207;&#21015;&#24314;&#27169;&#20013;&#30340;&#34920;&#36798;&#33021;&#21147;&#21644;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Understanding the Expressive Power and Mechanisms of Transformer for Sequence Modeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00522
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#31995;&#32479;&#22320;&#25506;&#35752;&#20102;Transformer&#22312;&#38271;&#24207;&#21015;&#24314;&#27169;&#20013;&#30340;&#36817;&#20284;&#24615;&#36136;&#65292;&#24182;&#30740;&#31350;&#20102;&#20854;&#20851;&#38190;&#32452;&#20214;&#23545;&#34920;&#36798;&#33021;&#21147;&#30340;&#24433;&#21709;&#26426;&#21046;&#12290;&#36825;&#20123;&#21457;&#29616;&#25581;&#31034;&#20102;&#20851;&#38190;&#21442;&#25968;&#23545;Transformer&#30340;&#20316;&#29992;&#65292;&#24182;&#20026;&#26367;&#20195;&#26550;&#26500;&#25552;&#20379;&#20102;&#33258;&#28982;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23545;Transformer&#22312;&#38271;&#12289;&#31232;&#30095;&#21644;&#22797;&#26434;&#35760;&#24518;&#30340;&#24207;&#21015;&#24314;&#27169;&#20013;&#30340;&#36817;&#20284;&#24615;&#36136;&#36827;&#34892;&#20102;&#31995;&#32479;&#30740;&#31350;&#12290;&#25105;&#20204;&#35843;&#26597;&#20102;Transformer&#30340;&#19981;&#21516;&#32452;&#20214;&#65288;&#22914;&#28857;&#31215;&#33258;&#27880;&#24847;&#21147;&#12289;&#20301;&#32622;&#32534;&#30721;&#21644;&#21069;&#39304;&#23618;&#65289;&#26159;&#22914;&#20309;&#24433;&#21709;&#20854;&#34920;&#36798;&#33021;&#21147;&#30340;&#26426;&#21046;&#65292;&#24182;&#36890;&#36807;&#24314;&#31435;&#26126;&#30830;&#30340;&#36817;&#20284;&#29575;&#26469;&#30740;&#31350;&#23427;&#20204;&#30340;&#32508;&#21512;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;Transformer&#20013;&#20851;&#38190;&#21442;&#25968;&#65288;&#22914;&#23618;&#25968;&#21644;&#27880;&#24847;&#21147;&#22836;&#25968;&#65289;&#30340;&#20316;&#29992;&#65292;&#24182;&#19988;&#36825;&#20123;&#27934;&#23519;&#36824;&#20026;&#26367;&#20195;&#26550;&#26500;&#25552;&#20379;&#20102;&#33258;&#28982;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
We conduct a systematic study of the approximation properties of Transformer for sequence modeling with long, sparse and complicated memory. We investigate the mechanisms through which different components of Transformer, such as the dot-product self-attention, positional encoding and feed-forward layer, affect its expressive power, and we study their combined effects through establishing explicit approximation rates. Our study reveals the roles of critical parameters in the Transformer, such as the number of layers and the number of attention heads, and these insights also provide natural suggestions for alternative architectures.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#40065;&#26834;&#30340;&#36807;&#25311;&#21512;&#28508;&#21464;&#37327;&#26041;&#27861;&#26469;&#25913;&#36827;&#31070;&#32463;&#22270;&#20687;&#21387;&#32553;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;SGA+&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#24615;&#33021;&#24182;&#20943;&#23569;&#23545;&#36229;&#21442;&#25968;&#36873;&#25321;&#30340;&#25935;&#24863;&#24615;&#12290;</title><link>https://arxiv.org/abs/2401.17789</link><description>&lt;p&gt;
&#24377;&#24615;&#31070;&#32463;&#22270;&#20687;&#21387;&#32553;&#20013;&#30340;&#40065;&#26834;&#36807;&#25311;&#21512;&#28508;&#21464;&#37327;
&lt;/p&gt;
&lt;p&gt;
Robustly overfitting latents for flexible neural image compression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17789
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#40065;&#26834;&#30340;&#36807;&#25311;&#21512;&#28508;&#21464;&#37327;&#26041;&#27861;&#26469;&#25913;&#36827;&#31070;&#32463;&#22270;&#20687;&#21387;&#32553;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;SGA+&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#24615;&#33021;&#24182;&#20943;&#23569;&#23545;&#36229;&#21442;&#25968;&#36873;&#25321;&#30340;&#25935;&#24863;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#22270;&#20687;&#21387;&#32553;&#21462;&#24471;&#20102;&#24456;&#22823;&#30340;&#36827;&#23637;&#12290;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#22522;&#20110;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65292;&#32988;&#36807;&#20102;&#20256;&#32479;&#27169;&#22411;&#12290;&#31070;&#32463;&#21387;&#32553;&#27169;&#22411;&#23398;&#20250;&#23558;&#22270;&#20687;&#32534;&#30721;&#20026;&#37327;&#21270;&#30340;&#28508;&#21464;&#37327;&#34920;&#31034;&#65292;&#28982;&#21518;&#23558;&#20854;&#39640;&#25928;&#22320;&#21457;&#36865;&#32473;&#35299;&#30721;&#22120;&#65292;&#35299;&#30721;&#22120;&#20877;&#23558;&#37327;&#21270;&#30340;&#28508;&#21464;&#37327;&#35299;&#30721;&#20026;&#37325;&#24314;&#22270;&#20687;&#12290;&#34429;&#28982;&#36825;&#20123;&#27169;&#22411;&#22312;&#23454;&#36341;&#20013;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#30001;&#20110;&#20248;&#21270;&#19981;&#23436;&#32654;&#20197;&#21450;&#32534;&#30721;&#22120;&#21644;&#35299;&#30721;&#22120;&#23481;&#37327;&#30340;&#38480;&#21046;&#65292;&#23427;&#20204;&#23548;&#33268;&#20102;&#27425;&#20248;&#32467;&#26524;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22914;&#20309;&#21033;&#29992;&#38543;&#26426;Gumbel&#36864;&#28779;&#65288;SGA&#65289;&#26469;&#25913;&#36827;&#39044;&#35757;&#32451;&#30340;&#31070;&#32463;&#22270;&#20687;&#21387;&#32553;&#27169;&#22411;&#30340;&#28508;&#21464;&#37327;&#12290;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;SGA+&#25193;&#23637;&#20102;&#36825;&#20010;&#24819;&#27861;&#65292;SGA+&#21253;&#21547;&#20102;&#19977;&#31181;&#19981;&#21516;&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#26041;&#27861;&#37117;&#24314;&#31435;&#22312;SGA&#30340;&#22522;&#30784;&#19978;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23545;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#35814;&#32454;&#20998;&#26512;&#65292;&#23637;&#31034;&#20102;&#23427;&#20204;&#22914;&#20309;&#25913;&#36827;&#24615;&#33021;&#65292;&#24182;&#19988;&#35777;&#26126;&#23427;&#20204;&#23545;&#36229;&#21442;&#25968;&#36873;&#25321;&#19981;&#25935;&#24863;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#27599;&#20010;&#26041;&#27861;&#25193;&#23637;&#21040;&#19977;&#20010;&#32780;&#19981;&#26159;&#20004;&#20010;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural image compression has made a great deal of progress. State-of-the-art models are based on variational autoencoders and are outperforming classical models. Neural compression models learn to encode an image into a quantized latent representation that can be efficiently sent to the decoder, which decodes the quantized latent into a reconstructed image. While these models have proven successful in practice, they lead to sub-optimal results due to imperfect optimization and limitations in the encoder and decoder capacity. Recent work shows how to use stochastic Gumbel annealing (SGA) to refine the latents of pre-trained neural image compression models. We extend this idea by introducing SGA+, which contains three different methods that build upon SGA. Further, we give a detailed analysis of our proposed methods, show how they improve performance, and show that they are less sensitive to hyperparameter choices. Besides, we show how each method can be extended to three- instead of two
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#35843;&#26597;&#26465;&#20214;&#30456;&#20851;&#24615;&#21644;&#33258;&#30456;&#20851;&#24615;&#65292;&#25581;&#31034;&#20102;&#36755;&#20837;&#25968;&#25454;&#20013;&#30340;&#20887;&#20313;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;HDformer&#65292;&#36825;&#26159;&#19968;&#31181;&#36731;&#37327;&#32423;&#30340;Transformer&#21464;&#31181;&#65292;&#21033;&#29992;&#33976;&#39311;&#25216;&#26415;&#21644;&#24555;&#36895;&#32593;&#32476;&#36830;&#25509;&#23618;&#26469;&#38477;&#20302;&#27169;&#22411;&#22797;&#26434;&#24615;&#12290;</title><link>https://arxiv.org/abs/2401.11929</link><description>&lt;p&gt;
&#8220;&#36234;&#22823;&#36234;&#22909;&#65311;&#8221;&#37325;&#26032;&#24605;&#32771;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#26377;&#25928;&#27169;&#22411;&#35268;&#27169;
&lt;/p&gt;
&lt;p&gt;
The Bigger the Better? Rethinking the Effective Model Scale in Long-term Time Series Forecasting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.11929
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#35843;&#26597;&#26465;&#20214;&#30456;&#20851;&#24615;&#21644;&#33258;&#30456;&#20851;&#24615;&#65292;&#25581;&#31034;&#20102;&#36755;&#20837;&#25968;&#25454;&#20013;&#30340;&#20887;&#20313;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;HDformer&#65292;&#36825;&#26159;&#19968;&#31181;&#36731;&#37327;&#32423;&#30340;Transformer&#21464;&#31181;&#65292;&#21033;&#29992;&#33976;&#39311;&#25216;&#26415;&#21644;&#24555;&#36895;&#32593;&#32476;&#36830;&#25509;&#23618;&#26469;&#38477;&#20302;&#27169;&#22411;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#65288;LTSF&#65289;&#26159;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#21069;&#27839;&#65292;&#20854;&#29305;&#28857;&#26159;&#20851;&#27880;&#20110;&#22823;&#37327;&#36755;&#20837;&#24207;&#21015;&#65292;&#19982;&#20256;&#32479;&#26041;&#27861;&#20013;&#30340;&#26377;&#38480;&#38271;&#24230;&#30456;&#27604;&#26377;&#25152;&#19981;&#21516;&#12290;&#23613;&#31649;&#26356;&#38271;&#30340;&#24207;&#21015;&#26412;&#36136;&#19978;&#20256;&#36798;&#20102;&#26356;&#20016;&#23500;&#30340;&#20449;&#24687;&#65292;&#21487;&#33021;&#25552;&#39640;&#20102;&#39044;&#27979;&#30340;&#31934;&#24230;&#65292;&#20294;&#30446;&#21069;&#30340;&#25216;&#26415;&#24448;&#24448;&#36890;&#36807;&#25552;&#39640;&#27169;&#22411;&#22797;&#26434;&#24615;&#26469;&#24212;&#23545;&#12290;&#36825;&#20123;&#22797;&#26434;&#30340;&#27169;&#22411;&#21487;&#20197;&#33192;&#32960;&#20026;&#25968;&#30334;&#19975;&#20010;&#21442;&#25968;&#65292;&#21253;&#25324;&#20301;&#32622;&#32534;&#30721;&#12289;&#21069;&#39304;&#32593;&#32476;&#21644;&#33258;&#27880;&#24847;&#26426;&#21046;&#31561;&#21442;&#25968;&#23494;&#38598;&#22411;&#20803;&#32032;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#22797;&#26434;&#24615;&#23548;&#33268;&#20102;&#31105;&#27490;&#24615;&#30340;&#27169;&#22411;&#35268;&#27169;&#65292;&#29305;&#21035;&#26159;&#32771;&#34385;&#21040;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#35821;&#20041;&#31616;&#21333;&#24615;&#12290;&#20986;&#20110;&#36861;&#27714;&#31616;&#27905;&#24615;&#30340;&#21160;&#26426;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#21033;&#29992;&#26465;&#20214;&#30456;&#20851;&#24615;&#21644;&#33258;&#30456;&#20851;&#24615;&#20316;&#20026;&#35843;&#26597;&#24037;&#20855;&#65292;&#25581;&#31034;&#20102;&#36755;&#20837;&#25968;&#25454;&#20013;&#30340;&#26174;&#33879;&#20887;&#20313;&#12290;&#20511;&#21161;&#36825;&#20123;&#35265;&#35299;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;HDformer&#65292;&#36825;&#26159;&#19968;&#31181;&#36731;&#37327;&#32423;&#30340;Transformer&#21464;&#20307;&#65292;&#32463;&#36807;&#22686;&#24378;&#65292;&#20351;&#29992;&#33976;&#39311;&#25216;&#26415;&#21644;&#24555;&#36895;&#32593;&#32476;&#36830;&#25509;&#23618;&#26469;&#38477;&#20302;&#27169;&#22411;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Long-term time series forecasting (LTSF) represents a critical frontier in time series analysis, distinguished by its focus on extensive input sequences, in contrast to the constrained lengths typical of traditional approaches. While longer sequences inherently convey richer information, potentially enhancing predictive precision, prevailing techniques often respond by escalating model complexity. These intricate models can inflate into millions of parameters, incorporating parameter-intensive elements like positional encodings, feed-forward networks and self-attention mechanisms. This complexity, however, leads to prohibitive model scale, particularly given the time series data's semantic simplicity. Motivated by the pursuit of parsimony, our research employs conditional correlation and auto-correlation as investigative tools, revealing significant redundancies within the input data. Leveraging these insights, we introduce the HDformer, a lightweight Transformer variant enhanced with 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#25913;&#36827;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#65292;&#21033;&#29992;&#20923;&#32467;&#30340;&#22522;&#30784;&#27169;&#22411;&#20316;&#20026;&#31070;&#32463;&#32593;&#32476;&#39592;&#24178;&#65292;&#22312;&#21322;&#30417;&#30563;&#23398;&#20064;&#21644;&#36229;&#20986;&#20998;&#24067;&#26816;&#27979;&#26041;&#38754;&#21462;&#24471;&#20102;&#20248;&#36234;&#30340;&#34920;&#29616;&#65292;&#24182;&#24341;&#20837;&#20102;&#26032;&#30340;&#39044;&#35757;&#32451;&#25216;&#26415;&#12289;&#25439;&#22833;&#20989;&#25968;&#21644;&#21407;&#22411;&#36873;&#25321;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2311.17093</link><description>&lt;p&gt;
&#29992;&#21407;&#22411;&#21322;&#30417;&#30563;&#23398;&#20064;&#21644;&#22522;&#30784;&#27169;&#22411;&#23454;&#29616;&#39640;&#25928;&#30340;&#36229;&#20986;&#20998;&#24067;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Efficient Out-of-Distribution Detection with Prototypical Semi-Supervised Learning and Foundation Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.17093
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#25913;&#36827;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#65292;&#21033;&#29992;&#20923;&#32467;&#30340;&#22522;&#30784;&#27169;&#22411;&#20316;&#20026;&#31070;&#32463;&#32593;&#32476;&#39592;&#24178;&#65292;&#22312;&#21322;&#30417;&#30563;&#23398;&#20064;&#21644;&#36229;&#20986;&#20998;&#24067;&#26816;&#27979;&#26041;&#38754;&#21462;&#24471;&#20102;&#20248;&#36234;&#30340;&#34920;&#29616;&#65292;&#24182;&#24341;&#20837;&#20102;&#26032;&#30340;&#39044;&#35757;&#32451;&#25216;&#26415;&#12289;&#25439;&#22833;&#20989;&#25968;&#21644;&#21407;&#22411;&#36873;&#25321;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;PAWS-VMK&#65292;&#19968;&#31181;&#25913;&#36827;&#30340;&#21407;&#22411;&#21322;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#65292;&#19987;&#38376;&#35774;&#35745;&#29992;&#20110;&#21033;&#29992;&#20923;&#32467;&#30340;&#22522;&#30784;&#27169;&#22411;&#20316;&#20026;&#31070;&#32463;&#32593;&#32476;&#39592;&#24178;&#65292;&#35813;&#26041;&#27861;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#39046;&#22495;&#20013;&#20248;&#20110;&#20197;&#24448;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#21644;&#36229;&#20986;&#20998;&#24067;&#65288;OOD&#65289;&#26816;&#27979;&#32467;&#26524;&#65292;&#25913;&#36827;&#20102;Predicting View-Assignments With Support Samples&#65288;PAWS&#65289;&#21322;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;(1) &#21442;&#25968;&#21270;von-Mises Fisher&#38543;&#26426;&#37051;&#22495;&#23884;&#20837;&#65288;vMF-SNE&#65289;&#26469;&#39044;&#35757;&#32451;&#25237;&#24433;&#22836;&#65292;&#20351;&#29992;&#22522;&#30784;&#27169;&#22411;&#30340;&#39640;&#36136;&#37327;&#23884;&#20837;;(2) &#21463;MixMatch&#21551;&#21457;&#30340;&#25439;&#22833;&#65292;&#36890;&#36807;&#23545;&#22810;&#35270;&#22270;&#30340;&#39044;&#27979;&#36827;&#34892;&#24179;&#22343;&#65292;&#25552;&#20379;&#27604;PAWS&#20013;&#20351;&#29992;&#30340;&#19968;&#33268;&#24615;&#25439;&#22833;&#26356;&#21487;&#38752;&#30340;&#30417;&#30563;&#20449;&#21495;;&#21644;(3) &#31616;&#21333;k-Means&#21407;&#22411;&#36873;&#25321;&#65288;SKMPS&#65289;&#65292;&#19968;&#31181;&#27604;&#20854;&#20182;&#26080;&#30417;&#30563;&#26631;&#31614;&#36873;&#25321;&#26041;&#27861;&#25552;&#20379;&#26356;&#20248;&#36234;&#24615;&#33021;&#30340;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.17093v2 Announce Type: replace-cross  Abstract: This paper describes PAWS-VMK, an improved approach to prototypical semi-supervised learning in the field of computer vision, specifically designed to utilize a frozen foundation model as the neural network backbone. This method outperforms previous results in semi-supervised learning and out-of-distribution (OOD) detection, improving upon the Predicting View-Assignments With Support Samples (PAWS) semi-supervised learning method. We introduce (1) parametric von-Mises Fisher Stochastic Neighbour Embedding (vMF-SNE) to pretrain the projection head using the high-quality embeddings of the foundation model; (2) a MixMatch inspired loss, where predictions across multiple views are averaged to provide a more reliable supervision signal compared to the consistency loss used in PAWS and (3) simple $k$-Means prototype selection (SKMPS), a technique that provides superior performance to other unsupervised label selection approaches in t
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24212;&#29992;&#26399;&#26395;&#25928;&#29992;&#20551;&#35774;&#65292;&#26412;&#25991;&#25581;&#31034;&#20102;&#39118;&#38505;&#20013;&#24615;&#21644;&#39118;&#38505;&#24863;&#30693;RL&#30446;&#26631;&#23454;&#38469;&#19978;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#25351;&#25968;&#25928;&#29992;&#20989;&#25968;&#30340;&#26399;&#26395;&#25928;&#29992;&#26368;&#22823;&#21270;&#26469;&#35299;&#37322;&#65292;&#25552;&#20986;&#20102;&#21452;&#28436;&#21592;-&#35780;&#35770;&#23478;&#65288;DAC&#65289;&#31639;&#27861;&#65292;&#20026;&#39118;&#38505;&#24863;&#30693;&#30340;RL&#31639;&#27861;&#36129;&#29486;&#20102;&#26694;&#26550;&#12290;</title><link>https://arxiv.org/abs/2310.19527</link><description>&lt;p&gt;
&#20851;&#20110;&#39118;&#38505;&#24863;&#30693;&#20195;&#29702;&#29702;&#35770;&#65306;&#26725;&#25509;&#28436;&#21592;-&#35780;&#35770;&#23478;&#21644;&#32463;&#27982;&#23398;
&lt;/p&gt;
&lt;p&gt;
On the Theory of Risk-Aware Agents: Bridging Actor-Critic and Economics
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2310.19527
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24212;&#29992;&#26399;&#26395;&#25928;&#29992;&#20551;&#35774;&#65292;&#26412;&#25991;&#25581;&#31034;&#20102;&#39118;&#38505;&#20013;&#24615;&#21644;&#39118;&#38505;&#24863;&#30693;RL&#30446;&#26631;&#23454;&#38469;&#19978;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#25351;&#25968;&#25928;&#29992;&#20989;&#25968;&#30340;&#26399;&#26395;&#25928;&#29992;&#26368;&#22823;&#21270;&#26469;&#35299;&#37322;&#65292;&#25552;&#20986;&#20102;&#21452;&#28436;&#21592;-&#35780;&#35770;&#23478;&#65288;DAC&#65289;&#31639;&#27861;&#65292;&#20026;&#39118;&#38505;&#24863;&#30693;&#30340;RL&#31639;&#27861;&#36129;&#29486;&#20102;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2310.19527v2 &#20844;&#21578;&#31867;&#22411;&#65306;&#26367;&#25442; &#25688;&#35201;&#65306;&#39118;&#38505;&#24863;&#30693;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#31639;&#27861;&#22914;SAC&#21644;TD3&#22312;&#21508;&#31181;&#36830;&#32493;&#21160;&#20316;&#20219;&#21153;&#20013;&#30340;&#23454;&#35777;&#34920;&#29616;&#20248;&#20110;&#20854;&#39118;&#38505;&#20013;&#24615;&#23545;&#24212;&#29289;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31639;&#27861;&#37319;&#29992;&#30340;&#24754;&#35266;&#30446;&#26631;&#30340;&#29702;&#35770;&#22522;&#30784;&#23578;&#26410;&#24314;&#31435;&#65292;&#36825;&#24341;&#21457;&#20102;&#20851;&#20110;&#23427;&#20204;&#23454;&#26045;&#30340;&#20855;&#20307;&#25919;&#31574;&#31867;&#21035;&#30340;&#38382;&#39064;&#12290; &#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24212;&#29992;&#20102;&#26399;&#26395;&#25928;&#29992;&#20551;&#35774;&#65292;&#36825;&#26159;&#32463;&#27982;&#23398;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#27010;&#24565;&#65292;&#20197;&#38416;&#26126;&#39118;&#38505;&#20013;&#24615;&#21644;&#39118;&#38505;&#24863;&#30693;RL&#30446;&#26631;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#25351;&#25968;&#25928;&#29992;&#20989;&#25968;&#30340;&#26399;&#26395;&#25928;&#29992;&#26368;&#22823;&#21270;&#26469;&#35299;&#37322;&#12290; &#36825;&#31181;&#26041;&#27861;&#25581;&#31034;&#20102;&#39118;&#38505;&#24863;&#30693;&#25919;&#31574;&#26377;&#25928;&#22320;&#26368;&#22823;&#21270;&#20102;&#20215;&#20540;&#30830;&#23450;&#24615;&#31561;&#20215;&#29289;&#65292;&#20351;&#20854;&#19982;&#20256;&#32479;&#20915;&#31574;&#29702;&#35770;&#21407;&#21017;&#20445;&#25345;&#19968;&#33268;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21452;&#28436;&#21592;-&#35780;&#35770;&#23478;&#65288;Dual Actor-Critic&#65292;DAC&#65289;&#12290; DAC&#26159;&#19968;&#31181;&#39118;&#38505;&#24863;&#30693;&#30340;&#26080;&#27169;&#22411;&#31639;&#27861;&#65292;&#20855;&#26377;&#20004;&#20010;&#19981;&#21516;&#30340;&#28436;&#21592;&#32593;&#32476;&#65306;&#19968;&#20010;&#29992;&#20110;&#26102;&#24207;&#24046;&#20998;&#30340;&#24754;&#35266;&#28436;&#21592;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2310.19527v2 Announce Type: replace  Abstract: Risk-aware Reinforcement Learning (RL) algorithms like SAC and TD3 were shown empirically to outperform their risk-neutral counterparts in a variety of continuous-action tasks. However, the theoretical basis for the pessimistic objectives these algorithms employ remains unestablished, raising questions about the specific class of policies they are implementing. In this work, we apply the expected utility hypothesis, a fundamental concept in economics, to illustrate that both risk-neutral and risk-aware RL goals can be interpreted through expected utility maximization using an exponential utility function. This approach reveals that risk-aware policies effectively maximize value certainty equivalent, aligning them with conventional decision theory principles. Furthermore, we propose Dual Actor-Critic (DAC). DAC is a risk-aware, model-free algorithm that features two distinct actor networks: a pessimistic actor for temporal-difference 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;Wasserstein&#27010;&#29575;&#31354;&#38388;&#19978;&#30340;Riemannian SGD&#21644;SVRG&#27969;&#30340;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#26469;&#20016;&#23500;Wasserstein&#31354;&#38388;&#20013;&#30340;&#36830;&#32493;&#20248;&#21270;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.13530</link><description>&lt;p&gt;
&#22312;Wasserstein&#27010;&#29575;&#31354;&#38388;&#19978;&#29702;&#35299;Riemannian SGD&#21644;SVRG&#27969;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Towards Understanding the Riemannian SGD and SVRG Flows on Wasserstein Probabilistic Space. (arXiv:2401.13530v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13530
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;Wasserstein&#27010;&#29575;&#31354;&#38388;&#19978;&#30340;Riemannian SGD&#21644;SVRG&#27969;&#30340;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#26469;&#20016;&#23500;Wasserstein&#31354;&#38388;&#20013;&#30340;&#36830;&#32493;&#20248;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#23545;&#20110;Riemannian&#27969;&#24418;&#19978;&#30340;&#20248;&#21270;&#30740;&#31350;&#20026;&#20248;&#21270;&#39046;&#22495;&#25552;&#20379;&#20102;&#26032;&#30340;&#35265;&#35299;&#12290;&#22312;&#36825;&#26041;&#38754;&#65292;&#27010;&#29575;&#27979;&#24230;&#24230;&#37327;&#31354;&#38388;&#20316;&#20026;&#27969;&#24418;&#65292;&#37197;&#22791;&#31532;&#20108;&#38454;Wasserstein&#36317;&#31163;&#65292;&#23588;&#20854;&#24341;&#20154;&#20851;&#27880;&#65292;&#22240;&#20026;&#22312;&#20854;&#19978;&#30340;&#20248;&#21270;&#21487;&#20197;&#19982;&#23454;&#38469;&#30340;&#37319;&#26679;&#36807;&#31243;&#30456;&#20851;&#32852;&#12290;&#19968;&#33324;&#26469;&#35828;&#65292;Wasserstein&#31354;&#38388;&#19978;&#30340;&#26368;&#20248;&#21270;&#26041;&#27861;&#26159;Riemannian&#26799;&#24230;&#27969;&#65288;&#21363;&#65292;&#22312;&#26368;&#23567;&#21270;KL&#25955;&#24230;&#26102;&#30340;Langevin&#21160;&#21147;&#23398;&#65289;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#36890;&#36807;&#23558;&#26799;&#24230;&#27969;&#24310;&#23637;&#21040;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#27969;&#21644;&#38543;&#26426;&#26041;&#24046;&#20943;&#23569;&#26799;&#24230;&#65288;SVRG&#65289;&#27969;&#65292;&#20016;&#23500;Wasserstein&#31354;&#38388;&#20013;&#30340;&#36830;&#32493;&#20248;&#21270;&#26041;&#27861;&#12290;Euclidean&#31354;&#38388;&#19978;&#30340;&#36825;&#20004;&#31181;&#27969;&#26159;&#26631;&#20934;&#30340;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#65292;&#32780;&#23427;&#20204;&#22312;Riemannian&#31354;&#38388;&#20013;&#30340;&#23545;&#24212;&#26041;&#27861;&#23578;&#26410;&#34987;&#25506;&#32034;&#12290;&#36890;&#36807;&#21033;&#29992;Wasserstein&#31354;&#38388;&#20013;&#30340;&#32467;&#26500;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#26469;&#36817;&#20284;&#31163;&#25955;&#21160;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, optimization on the Riemannian manifold has provided new insights to the optimization community. In this regard, the manifold taken as the probability measure metric space equipped with the second-order Wasserstein distance is of particular interest, since optimization on it can be linked to practical sampling processes. In general, the oracle (continuous) optimization method on Wasserstein space is Riemannian gradient flow (i.e., Langevin dynamics when minimizing KL divergence). In this paper, we aim to enrich the continuous optimization methods in the Wasserstein space by extending the gradient flow into the stochastic gradient descent (SGD) flow and stochastic variance reduction gradient (SVRG) flow. The two flows on Euclidean space are standard stochastic optimization methods, while their Riemannian counterparts are not explored yet. By leveraging the structures in Wasserstein space, we construct a stochastic differential equation (SDE) to approximate the discrete dynamic
&lt;/p&gt;</description></item><item><title>&#36793;&#32536;&#21464;&#25442;&#22120;&#26159;&#19968;&#20010;&#20840;&#23616;&#27880;&#24847;&#21147;&#27169;&#22411;&#65292;&#23427;&#20855;&#26377;&#33267;&#23569;3-WL&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#33021;&#22815;&#22312;&#39044;&#27979;&#24615;&#33021;&#19978;&#36229;&#36807;&#20854;&#20182;&#26550;&#26500;&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;&#20301;&#32622;&#25110;&#32467;&#26500;&#32534;&#30721;&#12290;</title><link>http://arxiv.org/abs/2401.10119</link><description>&lt;p&gt;
&#36208;&#21521;&#22522;&#20110;&#21407;&#21017;&#30340;&#22270;&#24418;&#21464;&#25442;&#22120;
&lt;/p&gt;
&lt;p&gt;
Towards Principled Graph Transformers. (arXiv:2401.10119v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10119
&lt;/p&gt;
&lt;p&gt;
&#36793;&#32536;&#21464;&#25442;&#22120;&#26159;&#19968;&#20010;&#20840;&#23616;&#27880;&#24847;&#21147;&#27169;&#22411;&#65292;&#23427;&#20855;&#26377;&#33267;&#23569;3-WL&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#33021;&#22815;&#22312;&#39044;&#27979;&#24615;&#33021;&#19978;&#36229;&#36807;&#20854;&#20182;&#26550;&#26500;&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;&#20301;&#32622;&#25110;&#32467;&#26500;&#32534;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;k&#32500;Weisfeiler-Leman&#65288;k-WL&#65289;&#23618;&#27425;&#32467;&#26500;&#30340;&#22270;&#24418;&#23398;&#20064;&#26550;&#26500;&#25552;&#20379;&#20102;&#29702;&#35770;&#19978;&#24456;&#22909;&#29702;&#35299;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#36825;&#26679;&#30340;&#26550;&#26500;&#22312;&#30495;&#23454;&#20219;&#21153;&#20013;&#24448;&#24448;&#26080;&#27861;&#25552;&#20379;&#21487;&#38752;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#23454;&#38469;&#24433;&#21709;&#21147;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#22522;&#20110;&#20840;&#23616;&#27880;&#24847;&#21147;&#30340;&#27169;&#22411;&#22914;&#22270;&#24418;&#21464;&#25442;&#22120;&#22312;&#23454;&#36341;&#20013;&#34920;&#29616;&#20986;&#20102;&#24378;&#22823;&#30340;&#24615;&#33021;&#65292;&#20294;&#26159;&#23558;&#23427;&#20204;&#30340;&#34920;&#36798;&#33021;&#21147;&#19982;k-WL&#23618;&#27425;&#32467;&#26500;&#36827;&#34892;&#27604;&#36739;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#23588;&#20854;&#26159;&#22240;&#20026;&#36825;&#20123;&#26550;&#26500;&#20381;&#36182;&#20110;&#20301;&#32622;&#25110;&#32467;&#26500;&#32534;&#30721;&#26469;&#23454;&#29616;&#20854;&#34920;&#36798;&#33021;&#21147;&#21644;&#39044;&#27979;&#24615;&#33021;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26368;&#36817;&#25552;&#20986;&#30340;&#36793;&#32536;&#21464;&#25442;&#22120;&#65292;&#36825;&#26159;&#19968;&#20010;&#22312;&#33410;&#28857;&#23545;&#32780;&#19981;&#26159;&#33410;&#28857;&#19978;&#36827;&#34892;&#25805;&#20316;&#30340;&#20840;&#23616;&#27880;&#24847;&#21147;&#27169;&#22411;&#65292;&#20855;&#26377;&#33267;&#23569;3-WL&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;&#32463;&#39564;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36793;&#32536;&#21464;&#25442;&#22120;&#22312;&#39044;&#27979;&#24615;&#33021;&#19978;&#36229;&#36807;&#20102;&#20854;&#20182;&#29702;&#35770;&#23545;&#40784;&#30340;&#26550;&#26500;&#65292;&#21516;&#26102;&#19981;&#20381;&#36182;&#20110;&#20301;&#32622;&#25110;&#32467;&#26500;&#32534;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph learning architectures based on the k-dimensional Weisfeiler-Leman (k-WL) hierarchy offer a theoretically well-understood expressive power. However, such architectures often fail to deliver solid predictive performance on real-world tasks, limiting their practical impact. In contrast, global attention-based models such as graph transformers demonstrate strong performance in practice, but comparing their expressive power with the k-WL hierarchy remains challenging, particularly since these architectures rely on positional or structural encodings for their expressivity and predictive performance. To address this, we show that the recently proposed Edge Transformer, a global attention model operating on node pairs instead of nodes, has at least 3-WL expressive power. Empirically, we demonstrate that the Edge Transformer surpasses other theoretically aligned architectures regarding predictive performance while not relying on positional or structural encodings.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;DiffClone&#65292;&#19968;&#31181;&#36890;&#36807;&#25193;&#25955;&#39537;&#21160;&#30340;&#31574;&#30053;&#23398;&#20064;&#22686;&#24378;&#34892;&#20026;&#20811;&#38534;&#20195;&#29702;&#30340;&#31163;&#32447;&#31639;&#27861;&#12290;&#22312;&#30495;&#23454;&#30340;&#22312;&#32447;&#29289;&#29702;&#26426;&#22120;&#20154;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#37319;&#29992;MOCO&#24494;&#35843;&#30340;ResNet50&#30340;&#25928;&#26524;&#26368;&#22909;&#12290;</title><link>http://arxiv.org/abs/2401.09243</link><description>&lt;p&gt;
DiffClone: &#20351;&#29992;&#25193;&#25955;&#39537;&#21160;&#30340;&#31574;&#30053;&#23398;&#20064;&#22686;&#24378;&#26426;&#22120;&#20154;&#34892;&#20026;&#20811;&#38534;
&lt;/p&gt;
&lt;p&gt;
DiffClone: Enhanced Behaviour Cloning in Robotics with Diffusion-Driven Policy Learning. (arXiv:2401.09243v1 [cs.RO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09243
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;DiffClone&#65292;&#19968;&#31181;&#36890;&#36807;&#25193;&#25955;&#39537;&#21160;&#30340;&#31574;&#30053;&#23398;&#20064;&#22686;&#24378;&#34892;&#20026;&#20811;&#38534;&#20195;&#29702;&#30340;&#31163;&#32447;&#31639;&#27861;&#12290;&#22312;&#30495;&#23454;&#30340;&#22312;&#32447;&#29289;&#29702;&#26426;&#22120;&#20154;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#37319;&#29992;MOCO&#24494;&#35843;&#30340;ResNet50&#30340;&#25928;&#26524;&#26368;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#20154;&#23398;&#20064;&#20219;&#21153;&#22312;&#35745;&#31639;&#19978;&#38750;&#24120;&#23494;&#38598;&#19988;&#30828;&#20214;&#29305;&#23450;&#12290;&#22240;&#27492;&#65292;&#36890;&#36807;&#20351;&#29992;&#22810;&#26679;&#21270;&#30340;&#31163;&#32447;&#28436;&#31034;&#25968;&#25454;&#38598;&#26469;&#35757;&#32451;&#26426;&#22120;&#20154;&#25805;&#20316;&#20195;&#29702;&#65292;&#26469;&#24212;&#23545;&#36825;&#20123;&#25361;&#25112;&#30340;&#26041;&#24335;&#38750;&#24120;&#21560;&#24341;&#20154;&#12290;Train-Offline-Test-Online&#65288;TOTO&#65289;&#22522;&#20934;&#25552;&#20379;&#20102;&#19968;&#20010;&#32463;&#36807;&#31934;&#24515;&#31574;&#21010;&#30340;&#24320;&#28304;&#31163;&#32447;&#35757;&#32451;&#25968;&#25454;&#38598;&#65292;&#20027;&#35201;&#30001;&#19987;&#23478;&#25968;&#25454;&#32452;&#25104;&#65292;&#24182;&#25552;&#20379;&#20102;&#24120;&#35265;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#21644;&#34892;&#20026;&#20811;&#38534;&#20195;&#29702;&#30340;&#22522;&#20934;&#20998;&#25968;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;DiffClone&#65292;&#19968;&#31181;&#22686;&#24378;&#34892;&#20026;&#20811;&#38534;&#20195;&#29702;&#30340;&#31163;&#32447;&#31639;&#27861;&#65292;&#37319;&#29992;&#22522;&#20110;&#25193;&#25955;&#30340;&#31574;&#30053;&#23398;&#20064;&#65292;&#24182;&#22312;&#27979;&#35797;&#26102;&#22312;&#30495;&#23454;&#30340;&#22312;&#32447;&#29289;&#29702;&#26426;&#22120;&#20154;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#21516;&#26102;&#65292;&#36825;&#20063;&#26159;&#25105;&#20204;&#22312;NeurIPS 2023&#20030;&#21150;&#30340;Train-Offline-Test-Online&#65288;TOTO&#65289;&#22522;&#20934;&#25361;&#25112;&#36187;&#20013;&#30340;&#23448;&#26041;&#25552;&#20132;&#12290;&#25105;&#20204;&#23581;&#35797;&#20102;&#39044;&#35757;&#32451;&#30340;&#35270;&#35273;&#34920;&#31034;&#21644;&#20195;&#29702;&#31574;&#30053;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;MOCO&#24494;&#35843;&#30340;ResNet50&#30456;&#27604;&#20854;&#20182;&#24494;&#35843;&#26041;&#27861;&#34920;&#29616;&#26368;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Robot learning tasks are extremely compute-intensive and hardware-specific. Thus the avenues of tackling these challenges, using a diverse dataset of offline demonstrations that can be used to train robot manipulation agents, is very appealing. The Train-Offline-Test-Online (TOTO) Benchmark provides a well-curated open-source dataset for offline training comprised mostly of expert data and also benchmark scores of the common offline-RL and behaviour cloning agents. In this paper, we introduce DiffClone, an offline algorithm of enhanced behaviour cloning agent with diffusion-based policy learning, and measured the efficacy of our method on real online physical robots at test time. This is also our official submission to the Train-Offline-Test-Online (TOTO) Benchmark Challenge organized at NeurIPS 2023. We experimented with both pre-trained visual representation and agent policies. In our experiments, we find that MOCO finetuned ResNet50 performs the best in comparison to other finetuned
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#35266;&#23519;&#21040;&#30340;&#32676;&#20869;&#29305;&#24449;&#32858;&#38598;&#21644;&#32676;&#22806;&#29305;&#24449;&#31163;&#25955;&#30340;&#24615;&#36136;&#65292;&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29305;&#24449;&#21644;&#26435;&#37325;&#21521;&#37327;&#25509;&#36817;&#31243;&#24230;&#30340;&#31070;&#32463;&#22349;&#22604;&#65288;NC-OOD&#65289;&#26816;&#27979;&#22120;&#26469;&#25552;&#39640;OAD&#26816;&#27979;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#24182;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2311.01479</link><description>&lt;p&gt;
&#36890;&#36807;&#31070;&#32463;&#22349;&#22604;&#30340;&#35270;&#35282;&#26816;&#27979;&#21040;&#32676;&#22806;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Detecting Out-of-Distribution Through the Lens of Neural Collapse. (arXiv:2311.01479v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01479
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#35266;&#23519;&#21040;&#30340;&#32676;&#20869;&#29305;&#24449;&#32858;&#38598;&#21644;&#32676;&#22806;&#29305;&#24449;&#31163;&#25955;&#30340;&#24615;&#36136;&#65292;&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29305;&#24449;&#21644;&#26435;&#37325;&#21521;&#37327;&#25509;&#36817;&#31243;&#24230;&#30340;&#31070;&#32463;&#22349;&#22604;&#65288;NC-OOD&#65289;&#26816;&#27979;&#22120;&#26469;&#25552;&#39640;OAD&#26816;&#27979;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#24182;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32676;&#22806;&#65288;OOD&#65289;&#26816;&#27979;&#23545;&#20110;&#23433;&#20840;&#37096;&#32626;&#20154;&#24037;&#26234;&#33021;&#33267;&#20851;&#37325;&#35201;&#12290;&#29305;&#21035;&#26159;&#65292;OOD&#26816;&#27979;&#22120;&#24212;&#35813;&#22312;&#21508;&#31181;&#22330;&#26223;&#20013;&#26377;&#25928;&#22320;&#27867;&#21270;&#12290;&#20026;&#20102;&#25913;&#36827;&#29616;&#26377;OOD&#26816;&#27979;&#22120;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#39640;&#24230;&#28789;&#27963;&#30340;OOD&#26816;&#27979;&#22120;&#65292;&#31216;&#20026;&#31070;&#32463;&#22349;&#22604;&#65288;NC-OOD&#65289;&#26816;&#27979;&#22120;&#12290;&#25105;&#20204;&#25193;&#23637;&#20102;&#26222;&#36941;&#35266;&#23519;&#21040;&#30340;&#32676;&#20869;&#65288;ID&#65289;&#29305;&#24449;&#20542;&#21521;&#20110;&#24418;&#25104;&#31751;&#65292;&#32780;&#32676;&#22806;&#29305;&#24449;&#21017;&#36828;&#31163;&#30340;&#35266;&#23519;&#12290;&#29305;&#21035;&#26159;&#22522;&#20110;&#26368;&#36817;&#30340;&#35266;&#23519;&#32467;&#26524;&#65292;&#31070;&#32463;&#22349;&#22604;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;ID&#29305;&#24449;&#20542;&#21521;&#20110;&#22312;&#25509;&#36817;&#26435;&#37325;&#21521;&#37327;&#30340;&#20301;&#32622;&#32858;&#38598;&#12290;&#26681;&#25454;&#25105;&#20204;&#30340;&#25193;&#23637;&#35266;&#23519;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29305;&#24449;&#19982;&#26435;&#37325;&#21521;&#37327;&#30340;&#25509;&#36817;&#31243;&#24230;&#26469;&#26816;&#27979;OOD&#30340;&#26041;&#27861;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#25490;&#38500;OOD&#26679;&#26412;&#65292;&#25105;&#20204;&#21033;&#29992;&#20102;OOD&#29305;&#24449;&#20542;&#21521;&#20110;&#27604;ID&#29305;&#24449;&#26356;&#25509;&#36817;&#21407;&#28857;&#30340;&#35266;&#23519;&#32467;&#26524;&#12290;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#22686;&#24378;&#20102;&#29616;&#26377;&#24037;&#20316;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#24182;&#19988;&#22312;OOD&#26816;&#27979;&#26041;&#38754;&#22987;&#32456;&#33021;&#22815;&#36798;&#21040;&#26368;&#20808;&#36827;&#30340;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
Out-of-distribution (OOD) detection is essential for the safe deployment of AI. Particularly, OOD detectors should generalize effectively across diverse scenarios. To improve upon the generalizability of existing OOD detectors, we introduce a highly versatile OOD detector, called Neural Collapse inspired OOD detector (NC-OOD). We extend the prevalent observation that in-distribution (ID) features tend to form clusters, whereas OOD features are far away. Particularly, based on the recent observation, Neural Collapse, we further demonstrate that ID features tend to cluster in proximity to weight vectors. From our extended observation, we propose to detect OOD based on feature proximity to weight vectors. To further rule out OOD samples, we leverage the observation that OOD features tend to reside closer to the origin than ID features. Extensive experiments show that our approach enhances the generalizability of existing work and can consistently achieve state-of-the-art OOD detection per
&lt;/p&gt;</description></item><item><title>&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#27604;&#20363;&#32858;&#31867;&#38382;&#39064;&#65292;&#23558;&#20854;&#19982;&#35745;&#31639;&#31038;&#20250;&#36873;&#25321;&#20013;&#30340;&#22810;&#36194;&#23478;&#25237;&#31080;&#39046;&#22495;&#30456;&#20851;&#32852;&#12290;&#25105;&#20204;&#21457;&#29616;&#28385;&#36275;Brill&#21644;Peters&#30340;&#27604;&#20363;&#27010;&#24565;&#30340;&#20219;&#20309;&#32858;&#31867;&#37117;&#33021;&#21516;&#26102;&#33719;&#24471;Chen&#31561;&#20154;&#30340;&#27604;&#20363;&#20844;&#24179;&#24615;&#12289;&#20010;&#20307;&#20844;&#24179;&#24615;&#21644;&#26680;&#24515;&#30340;&#26368;&#20339;&#36817;&#20284;&#12290;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#26356;&#24378;&#30340;&#27604;&#20363;&#20195;&#34920;&#24615;&#27010;&#24565;&#65292;&#24182;&#23637;&#31034;&#20102;&#36825;&#20123;&#26356;&#24378;&#27010;&#24565;&#23545;&#24212;&#30340;&#36817;&#20284;&#12290;</title><link>http://arxiv.org/abs/2310.18162</link><description>&lt;p&gt;
&#38598;&#32676;&#20013;&#30340;&#27604;&#20363;&#20844;&#24179;&#24615;: &#31038;&#20250;&#36873;&#25321;&#35270;&#35282;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Proportional Fairness in Clustering: A Social Choice Perspective. (arXiv:2310.18162v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18162
&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#27604;&#20363;&#32858;&#31867;&#38382;&#39064;&#65292;&#23558;&#20854;&#19982;&#35745;&#31639;&#31038;&#20250;&#36873;&#25321;&#20013;&#30340;&#22810;&#36194;&#23478;&#25237;&#31080;&#39046;&#22495;&#30456;&#20851;&#32852;&#12290;&#25105;&#20204;&#21457;&#29616;&#28385;&#36275;Brill&#21644;Peters&#30340;&#27604;&#20363;&#27010;&#24565;&#30340;&#20219;&#20309;&#32858;&#31867;&#37117;&#33021;&#21516;&#26102;&#33719;&#24471;Chen&#31561;&#20154;&#30340;&#27604;&#20363;&#20844;&#24179;&#24615;&#12289;&#20010;&#20307;&#20844;&#24179;&#24615;&#21644;&#26680;&#24515;&#30340;&#26368;&#20339;&#36817;&#20284;&#12290;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#26356;&#24378;&#30340;&#27604;&#20363;&#20195;&#34920;&#24615;&#27010;&#24565;&#65292;&#24182;&#23637;&#31034;&#20102;&#36825;&#20123;&#26356;&#24378;&#27010;&#24565;&#23545;&#24212;&#30340;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;Chen&#31561;&#20154;&#30340;&#27604;&#20363;&#32858;&#31867;&#38382;&#39064;&#65292;&#24182;&#23558;&#20854;&#19982;&#35745;&#31639;&#31038;&#20250;&#36873;&#25321;&#20013;&#30340;&#22810;&#36194;&#23478;&#25237;&#31080;&#39046;&#22495;&#30456;&#20851;&#32852;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#28385;&#36275;Brill&#21644;Peters&#30340;&#24369;&#27604;&#20363;&#27010;&#24565;&#30340;&#20219;&#20309;&#32858;&#31867;&#21516;&#26102;&#33719;&#24471;&#20102;Chen&#31561;&#20154;&#30340;&#27604;&#20363;&#20844;&#24179;&#24615;&#30340;&#26368;&#20339;&#36817;&#20284;&#65292;&#20063;&#33719;&#24471;&#20102;&#20010;&#20307;&#20844;&#24179;&#24615;&#21644;&#8220;&#26680;&#24515;&#8221;&#30340;&#26368;&#20339;&#36817;&#20284;&#12290;&#20107;&#23454;&#19978;&#65292;&#25105;&#20204;&#34920;&#26126;&#20219;&#20309;&#23545;&#27604;&#20363;&#20844;&#24179;&#24615;&#30340;&#36817;&#20284;&#20063;&#26159;&#23545;&#20010;&#20307;&#20844;&#24179;&#24615;&#30340;&#36817;&#20284;&#65292;&#21453;&#20043;&#20134;&#28982;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#26356;&#24378;&#30340;&#27604;&#20363;&#20195;&#34920;&#24615;&#27010;&#24565;&#65292;&#20854;&#20013;&#20559;&#24046;&#19981;&#20165;&#21457;&#29983;&#22312;&#21333;&#20010;&#20505;&#36873;&#20013;&#24515;&#65292;&#32780;&#26159;&#22810;&#20010;&#20505;&#36873;&#20013;&#24515;&#65292;&#24182;&#23637;&#31034;&#20102;Brill&#21644;Peters&#30340;&#26356;&#24378;&#27604;&#20363;&#27010;&#24565;&#26263;&#31034;&#20102;&#36825;&#20123;&#26356;&#24378;&#20445;&#35777;&#30340;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the proportional clustering problem of Chen et al. [ICML'19] and relate it to the area of multiwinner voting in computational social choice. We show that any clustering satisfying a weak proportionality notion of Brill and Peters [EC'23] simultaneously obtains the best known approximations to the proportional fairness notion of Chen et al. [ICML'19], but also to individual fairness [Jung et al., FORC'20] and the "core" [Li et al. ICML'21]. In fact, we show that any approximation to proportional fairness is also an approximation to individual fairness and vice versa. Finally, we also study stronger notions of proportional representation, in which deviations do not only happen to single, but multiple candidate centers, and show that stronger proportionality notions of Brill and Peters [EC'23] imply approximations to these stronger guarantees.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#21518;&#39564;&#37319;&#26679;&#23398;&#20064;&#31639;&#27861;&#22312;&#24207;&#21015;&#21270;POMDPs&#20013;&#30340;&#36951;&#25022;&#24615;&#33021;&#65292;&#24182;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#25552;&#20379;&#20102;&#25913;&#36827;&#30340;&#22810;&#39033;&#24335;&#36125;&#21494;&#26031;&#36951;&#25022;&#30028;&#12290;</title><link>http://arxiv.org/abs/2310.10107</link><description>&lt;p&gt;
&#21518;&#39564;&#37319;&#26679;&#23398;&#20064;&#31639;&#27861;&#22312;&#24207;&#21015;&#21270;POMDPs&#20013;&#30340;&#36951;&#25022;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Regret Analysis of the Posterior Sampling-based Learning Algorithm for Episodic POMDPs. (arXiv:2310.10107v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10107
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#21518;&#39564;&#37319;&#26679;&#23398;&#20064;&#31639;&#27861;&#22312;&#24207;&#21015;&#21270;POMDPs&#20013;&#30340;&#36951;&#25022;&#24615;&#33021;&#65292;&#24182;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#25552;&#20379;&#20102;&#25913;&#36827;&#30340;&#22810;&#39033;&#24335;&#36125;&#21494;&#26031;&#36951;&#25022;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30456;&#27604;&#20110;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#65292;&#37096;&#20998;&#21487;&#35266;&#23519;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;POMDPs&#65289;&#30340;&#23398;&#20064;&#30001;&#20110;&#35266;&#23519;&#25968;&#25454;&#38590;&#20197;&#35299;&#35835;&#32780;&#21464;&#24471;&#26356;&#21152;&#22256;&#38590;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#20855;&#26377;&#26410;&#30693;&#36716;&#31227;&#21644;&#35266;&#27979;&#27169;&#22411;&#30340;POMDPs&#20013;&#30340;&#24207;&#21015;&#21270;&#23398;&#20064;&#38382;&#39064;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#22522;&#20110;&#21518;&#39564;&#37319;&#26679;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65288;PSRL&#65289;&#22312;POMDPs&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#35777;&#26126;&#20854;&#36125;&#21494;&#26031;&#36951;&#25022;&#38543;&#30528;&#24207;&#21015;&#30340;&#25968;&#37327;&#30340;&#24179;&#26041;&#26681;&#32780;&#32553;&#23567;&#12290;&#19968;&#33324;&#26469;&#35828;&#65292;&#36951;&#25022;&#38543;&#30528;&#26102;&#38388;&#38271;&#24230;$H$&#21576;&#25351;&#25968;&#32423;&#22686;&#38271;&#65292;&#24182;&#36890;&#36807;&#25552;&#20379;&#19968;&#20010;&#19979;&#30028;&#35777;&#26126;&#20102;&#36825;&#19968;&#28857;&#12290;&#28982;&#32780;&#65292;&#22312;POMDP&#26159;&#27424;&#23436;&#22791;&#19988;&#24369;&#21487;&#35782;&#21035;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#22810;&#39033;&#24335;&#36125;&#21494;&#26031;&#36951;&#25022;&#30028;&#65292;&#30456;&#27604;&#20110;arXiv:2204.08967&#30340;&#26368;&#26032;&#32467;&#26524;&#65292;&#25913;&#36827;&#20102;&#36951;&#25022;&#30028;&#32422;$\Omega(H^2\sqrt{SA})$&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;
Compared to Markov Decision Processes (MDPs), learning in Partially Observable Markov Decision Processes (POMDPs) can be significantly harder due to the difficulty of interpreting observations. In this paper, we consider episodic learning problems in POMDPs with unknown transition and observation models. We consider the Posterior Sampling-based Reinforcement Learning (PSRL) algorithm for POMDPs and show that its Bayesian regret scales as the square root of the number of episodes. In general, the regret scales exponentially with the horizon length $H$, and we show that this is inevitable by providing a lower bound. However, under the condition that the POMDP is undercomplete and weakly revealing, we establish a polynomial Bayesian regret bound that improves the regret bound by a factor of $\Omega(H^2\sqrt{SA})$ over the recent result by arXiv:2204.08967.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#30899;&#36861;&#36394;&#27169;&#22411;&#65292;&#29992;&#20110;&#23454;&#26102;&#30417;&#27979;&#32852;&#37030;&#23398;&#20064;&#31995;&#32479;&#30340;&#33021;&#28304;&#28040;&#32791;&#21644;&#30899;&#36275;&#36857;&#24433;&#21709;&#12290;&#36890;&#36807;&#23545;&#19981;&#21516;&#30340;&#35745;&#31639;&#21644;&#36890;&#20449;&#39640;&#25928;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#23450;&#37327;&#35780;&#20272;&#65292;&#20026;&#20943;&#23569;&#33021;&#28304;&#28040;&#32791;&#21644;&#30899;&#25490;&#25918;&#25552;&#20379;&#20102;&#21442;&#32771;&#12290;</title><link>http://arxiv.org/abs/2310.08087</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#32852;&#37030;&#23398;&#20064;&#30340;&#30899;&#36861;&#36394;&#27169;&#22411;&#65306;&#37327;&#21270;&#21644;&#31232;&#30095;&#21270;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
A Carbon Tracking Model for Federated Learning: Impact of Quantization and Sparsification. (arXiv:2310.08087v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08087
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#30899;&#36861;&#36394;&#27169;&#22411;&#65292;&#29992;&#20110;&#23454;&#26102;&#30417;&#27979;&#32852;&#37030;&#23398;&#20064;&#31995;&#32479;&#30340;&#33021;&#28304;&#28040;&#32791;&#21644;&#30899;&#36275;&#36857;&#24433;&#21709;&#12290;&#36890;&#36807;&#23545;&#19981;&#21516;&#30340;&#35745;&#31639;&#21644;&#36890;&#20449;&#39640;&#25928;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#23450;&#37327;&#35780;&#20272;&#65292;&#20026;&#20943;&#23569;&#33021;&#28304;&#28040;&#32791;&#21644;&#30899;&#25490;&#25918;&#25552;&#20379;&#20102;&#21442;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#37319;&#29992;&#39640;&#25928;&#30340;&#36890;&#20449;&#25216;&#26415;&#23558;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20998;&#24067;&#22312;&#36793;&#32536;&#35774;&#22791;&#19978;&#65292;&#19982;&#38598;&#20013;&#24335;&#35299;&#20915;&#26041;&#26696;&#30456;&#27604;&#65292;&#22312;&#25968;&#25454;&#23384;&#20648;&#21644;&#35745;&#31639;&#22797;&#26434;&#24615;&#26041;&#38754;&#20943;&#23569;&#20102;&#24320;&#38144;&#12290;&#32852;&#37030;&#23398;&#20064;&#20026;&#35299;&#20915;&#20174;&#29983;&#20135;&#32773;&#65288;&#20256;&#24863;&#22120;&#12289;&#26426;&#22120;&#65289;&#21040;&#33021;&#32791;&#39640;&#30340;&#25968;&#25454;&#20013;&#24515;&#22823;&#37327;&#20256;&#36755;&#25968;&#25454;&#24341;&#36215;&#30340;&#36164;&#28304;&#38656;&#27714;&#32780;&#24341;&#21457;&#30340;&#29615;&#22659;&#38382;&#39064;&#25552;&#20379;&#20102;&#26367;&#20195;&#35299;&#20915;&#26041;&#26696;&#65292;&#21516;&#26102;&#20351;&#24471;&#26032;&#30340;&#29289;&#32852;&#32593;&#20154;&#24037;&#26234;&#33021;&#65288;AIoT&#65289;&#24212;&#29992;&#25104;&#20026;&#21487;&#33021;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#23454;&#26102;&#30417;&#27979;&#32852;&#37030;&#23398;&#20064;&#31995;&#32479;&#33021;&#28304;&#28040;&#32791;&#21644;&#30899;&#36275;&#36857;&#24433;&#21709;&#30340;&#26694;&#26550;&#12290;&#35813;&#30899;&#36861;&#36394;&#24037;&#20855;&#23545;&#20849;&#35782;&#65288;&#23436;&#20840;&#20998;&#25955;&#65289;&#21644;&#20256;&#32479;&#32852;&#37030;&#23398;&#20064;&#31574;&#30053;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#25105;&#20204;&#39318;&#27425;&#20174;&#33021;&#32791;&#21644;&#31561;&#25928;&#30899;&#25490;&#25918;&#30340;&#35282;&#24230;&#23450;&#37327;&#35780;&#20272;&#20102;&#19981;&#21516;&#30340;&#35745;&#31639;&#21644;&#36890;&#20449;&#39640;&#25928;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated Learning (FL) methods adopt efficient communication technologies to distribute machine learning tasks across edge devices, reducing the overhead in terms of data storage and computational complexity compared to centralized solutions. Rather than moving large data volumes from producers (sensors, machines) to energy-hungry data centers, raising environmental concerns due to resource demands, FL provides an alternative solution to mitigate the energy demands of several learning tasks while enabling new Artificial Intelligence of Things (AIoT) applications. This paper proposes a framework for real-time monitoring of the energy and carbon footprint impacts of FL systems. The carbon tracking tool is evaluated for consensus (fully decentralized) and classical FL policies. For the first time, we present a quantitative evaluation of different computationally and communication efficient FL methods from the perspectives of energy consumption and carbon equivalent emissions, suggesting 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#39640;&#32500;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#25351;&#25968;&#26426;&#21046;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#65292;&#24182;&#25552;&#20986;&#20102;Metropolis-Hastings&#31639;&#27861;&#26469;&#20811;&#26381;&#25351;&#25968;&#25628;&#32034;&#31354;&#38388;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#19968;&#23450;&#36793;&#30028;&#26465;&#20214;&#19979;&#33021;&#22815;&#23454;&#29616;&#24378;&#27169;&#22411;&#24674;&#22797;&#24615;&#36136;&#65292;&#24182;&#20855;&#26377;&#22810;&#39033;&#24335;&#28151;&#21512;&#26102;&#38388;&#21644;&#36817;&#20284;&#24046;&#20998;&#38544;&#31169;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/2310.07852</link><description>&lt;p&gt;
&#20851;&#20110;&#36890;&#36807;&#25351;&#25968;&#26426;&#21046;&#36827;&#34892;&#39640;&#32500;&#31169;&#26377;&#27169;&#22411;&#36873;&#25321;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Computational Complexity of Private High-dimensional Model Selection via the Exponential Mechanism. (arXiv:2310.07852v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07852
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#39640;&#32500;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#25351;&#25968;&#26426;&#21046;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#65292;&#24182;&#25552;&#20986;&#20102;Metropolis-Hastings&#31639;&#27861;&#26469;&#20811;&#26381;&#25351;&#25968;&#25628;&#32034;&#31354;&#38388;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#19968;&#23450;&#36793;&#30028;&#26465;&#20214;&#19979;&#33021;&#22815;&#23454;&#29616;&#24378;&#27169;&#22411;&#24674;&#22797;&#24615;&#36136;&#65292;&#24182;&#20855;&#26377;&#22810;&#39033;&#24335;&#28151;&#21512;&#26102;&#38388;&#21644;&#36817;&#20284;&#24046;&#20998;&#38544;&#31169;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24046;&#20998;&#38544;&#31169;&#26694;&#26550;&#19979;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#39640;&#32500;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#24046;&#20998;&#38544;&#31169;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#30340;&#38382;&#39064;&#65292;&#24182;&#30740;&#31350;&#20102;&#20854;&#25928;&#29992;&#20445;&#35777;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#24191;&#20026;&#20154;&#30693;&#30340;&#25351;&#25968;&#26426;&#21046;&#26469;&#36873;&#25321;&#26368;&#20339;&#27169;&#22411;&#65292;&#24182;&#22312;&#19968;&#23450;&#36793;&#30028;&#26465;&#20214;&#19979;&#65292;&#24314;&#31435;&#20102;&#20854;&#24378;&#27169;&#22411;&#24674;&#22797;&#24615;&#36136;&#12290;&#28982;&#32780;&#65292;&#25351;&#25968;&#26426;&#21046;&#30340;&#25351;&#25968;&#25628;&#32034;&#31354;&#38388;&#23548;&#33268;&#20102;&#20005;&#37325;&#30340;&#35745;&#31639;&#29942;&#39048;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Metropolis-Hastings&#31639;&#27861;&#26469;&#36827;&#34892;&#37319;&#26679;&#27493;&#39588;&#65292;&#24182;&#22312;&#38382;&#39064;&#21442;&#25968;$n$&#12289;$p$&#21644;$s$&#20013;&#24314;&#31435;&#20102;&#20854;&#21040;&#31283;&#24577;&#20998;&#24067;&#30340;&#22810;&#39033;&#24335;&#28151;&#21512;&#26102;&#38388;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21033;&#29992;&#20854;&#28151;&#21512;&#24615;&#36136;&#24314;&#31435;&#20102;Metropolis-Hastings&#38543;&#26426;&#34892;&#36208;&#30340;&#26368;&#32456;&#20272;&#35745;&#30340;&#36817;&#20284;&#24046;&#20998;&#38544;&#31169;&#24615;&#36136;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#19968;&#20123;&#35828;&#26126;&#24615;&#27169;&#25311;&#65292;&#21360;&#35777;&#20102;&#25105;&#20204;&#20027;&#35201;&#32467;&#26524;&#30340;&#29702;&#35770;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of model selection in a high-dimensional sparse linear regression model under the differential privacy framework. In particular, we consider the problem of differentially private best subset selection and study its utility guarantee. We adopt the well-known exponential mechanism for selecting the best model, and under a certain margin condition, we establish its strong model recovery property. However, the exponential search space of the exponential mechanism poses a serious computational bottleneck. To overcome this challenge, we propose a Metropolis-Hastings algorithm for the sampling step and establish its polynomial mixing time to its stationary distribution in the problem parameters $n,p$, and $s$. Furthermore, we also establish approximate differential privacy for the final estimates of the Metropolis-Hastings random walk using its mixing property. Finally, we also perform some illustrative simulations that echo the theoretical findings of our main results
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20934;&#33945;&#29305;&#21345;&#32599;&#26426;&#21046;&#65292;&#31216;&#20026;&#25490;&#26021;&#38543;&#26426;&#28216;&#36208;&#65292;&#36890;&#36807;&#25913;&#36827;&#22270;&#30340;&#37319;&#26679;&#65292;&#25552;&#39640;&#20102;&#32479;&#35745;&#20272;&#35745;&#22120;&#30340;&#38598;&#20013;&#24230;&#12290;&#35813;&#26426;&#21046;&#22312;&#20272;&#35745;&#22270;&#20869;&#26680;&#12289;PageRank&#21521;&#37327;&#21644;&#22270;&#24418;&#27987;&#24230;&#31561;&#26041;&#38754;&#23637;&#31034;&#20102;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.04859</link><description>&lt;p&gt;
&#36890;&#29992;&#22270;&#38543;&#26426;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Universal Graph Random Features. (arXiv:2310.04859v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04859
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20934;&#33945;&#29305;&#21345;&#32599;&#26426;&#21046;&#65292;&#31216;&#20026;&#25490;&#26021;&#38543;&#26426;&#28216;&#36208;&#65292;&#36890;&#36807;&#25913;&#36827;&#22270;&#30340;&#37319;&#26679;&#65292;&#25552;&#39640;&#20102;&#32479;&#35745;&#20272;&#35745;&#22120;&#30340;&#38598;&#20013;&#24230;&#12290;&#35813;&#26426;&#21046;&#22312;&#20272;&#35745;&#22270;&#20869;&#26680;&#12289;PageRank&#21521;&#37327;&#21644;&#22270;&#24418;&#27987;&#24230;&#31561;&#26041;&#38754;&#23637;&#31034;&#20102;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20934;&#33945;&#29305;&#21345;&#32599;&#26426;&#21046;&#65292;&#31216;&#20026;&#25490;&#26021;&#38543;&#26426;&#28216;&#36208;&#65292;&#20197;&#25913;&#36827;&#22522;&#20110;&#22270;&#30340;&#37319;&#26679;&#12290;&#36890;&#36807;&#22312;&#30456;&#20114;&#20316;&#29992;&#38598;&#21512;&#30340;&#36712;&#36857;&#20043;&#38388;&#24341;&#20837;&#30456;&#20851;&#24615;&#65292;&#20351;&#23427;&#20204;&#30340;&#36793;&#38469;&#36716;&#31227;&#27010;&#29575;&#20445;&#25345;&#19981;&#21464;&#65292;&#25105;&#20204;&#33021;&#22815;&#26356;&#39640;&#25928;&#22320;&#25506;&#32034;&#22270;&#24418;&#65292;&#25552;&#39640;&#32479;&#35745;&#20272;&#35745;&#22120;&#30340;&#38598;&#20013;&#24230;&#65292;&#21516;&#26102;&#20445;&#25345;&#23427;&#20204;&#30340;&#26080;&#20559;&#24615;&#12290;&#35813;&#26426;&#21046;&#21487;&#20197;&#36731;&#26494;&#22320;&#23454;&#29616;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#20272;&#35745;&#22270;&#20869;&#26680;&#12289;PageRank&#21521;&#37327;&#21644;&#22270;&#24418;&#27987;&#24230;&#31561;&#21508;&#31181;&#24773;&#20917;&#19979;&#65292;&#25490;&#26021;&#38543;&#26426;&#28216;&#36208;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#35814;&#32454;&#30340;&#23454;&#39564;&#35780;&#20272;&#21644;&#40065;&#26834;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#25490;&#26021;&#38543;&#26426;&#28216;&#36208;&#26159;&#31532;&#19968;&#20010;&#22312;&#22270;&#19978;&#30456;&#20851;&#27493;&#34892;&#32773;&#26041;&#21521;&#36827;&#34892;&#20005;&#26684;&#30740;&#31350;&#30340;&#20934;&#33945;&#29305;&#21345;&#32599;&#26041;&#26696;&#65292;&#20026;&#36825;&#20010;&#20196;&#20154;&#20852;&#22859;&#30340;&#26032;&#20852;&#39046;&#22495;&#24102;&#26469;&#20102;&#26032;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a novel quasi-Monte Carlo mechanism to improve graph-based sampling, coined repelling random walks. By inducing correlations between the trajectories of an interacting ensemble such that their marginal transition probabilities are unmodified, we are able to explore the graph more efficiently, improving the concentration of statistical estimators whilst leaving them unbiased. The mechanism has a trivial drop-in implementation. We showcase the effectiveness of repelling random walks in a range of settings including estimation of graph kernels, the PageRank vector and graphlet concentrations. We provide detailed experimental evaluation and robust theoretical guarantees. To our knowledge, repelling random walks constitute the first rigorously studied quasi-Monte Carlo scheme correlating the directions of walkers on a graph, inviting new research in this exciting nascent domain.
&lt;/p&gt;</description></item><item><title>&#25269;&#21046;&#38543;&#26426;&#28216;&#36208;&#26159;&#19968;&#31181;&#26032;&#30340;&#20934;&#33945;&#29305;&#21345;&#32599;&#26426;&#21046;&#65292;&#36890;&#36807;&#22312;&#22270;&#19978;&#30340;&#34892;&#36208;&#32773;&#20043;&#38388;&#24341;&#20837;&#30456;&#20851;&#24615;&#65292;&#33021;&#22815;&#26356;&#39640;&#25928;&#22320;&#25506;&#32034;&#22270;&#24182;&#25552;&#39640;&#32479;&#35745;&#20272;&#35745;&#30340;&#38598;&#20013;&#24230;&#65292;&#21516;&#26102;&#20445;&#25345;&#20854;&#26080;&#20559;&#24615;&#12290;&#27492;&#26426;&#21046;&#22312;&#20272;&#35745;&#22270;&#26680;&#12289;PageRank&#21521;&#37327;&#21644;&#22270;&#20803;&#27987;&#24230;&#31561;&#22810;&#20010;&#39046;&#22495;&#37117;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#35814;&#32454;&#30340;&#23454;&#39564;&#35780;&#20272;&#21644;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2310.04854</link><description>&lt;p&gt;
&#25269;&#21046;&#38543;&#26426;&#28216;&#36208;
&lt;/p&gt;
&lt;p&gt;
Repelling Random Walks. (arXiv:2310.04854v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04854
&lt;/p&gt;
&lt;p&gt;
&#25269;&#21046;&#38543;&#26426;&#28216;&#36208;&#26159;&#19968;&#31181;&#26032;&#30340;&#20934;&#33945;&#29305;&#21345;&#32599;&#26426;&#21046;&#65292;&#36890;&#36807;&#22312;&#22270;&#19978;&#30340;&#34892;&#36208;&#32773;&#20043;&#38388;&#24341;&#20837;&#30456;&#20851;&#24615;&#65292;&#33021;&#22815;&#26356;&#39640;&#25928;&#22320;&#25506;&#32034;&#22270;&#24182;&#25552;&#39640;&#32479;&#35745;&#20272;&#35745;&#30340;&#38598;&#20013;&#24230;&#65292;&#21516;&#26102;&#20445;&#25345;&#20854;&#26080;&#20559;&#24615;&#12290;&#27492;&#26426;&#21046;&#22312;&#20272;&#35745;&#22270;&#26680;&#12289;PageRank&#21521;&#37327;&#21644;&#22270;&#20803;&#27987;&#24230;&#31561;&#22810;&#20010;&#39046;&#22495;&#37117;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#35814;&#32454;&#30340;&#23454;&#39564;&#35780;&#20272;&#21644;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20934;&#33945;&#29305;&#21345;&#32599;&#26426;&#21046;&#26469;&#25913;&#36827;&#22522;&#20110;&#22270;&#30340;&#25277;&#26679;&#65292;&#31216;&#20026;&#25269;&#21046;&#38543;&#26426;&#28216;&#36208;&#12290;&#36890;&#36807;&#22312;&#19968;&#20010;&#30456;&#20114;&#20316;&#29992;&#30340;&#38598;&#21512;&#20013;&#30340;&#36712;&#36857;&#20043;&#38388;&#24341;&#20837;&#30456;&#20851;&#24615;&#65292;&#20351;&#23427;&#20204;&#30340;&#36793;&#38469;&#36716;&#31227;&#27010;&#29575;&#20445;&#25345;&#19981;&#21464;&#65292;&#25105;&#20204;&#33021;&#22815;&#26356;&#26377;&#25928;&#22320;&#25506;&#32034;&#22270;&#65292;&#25552;&#39640;&#32479;&#35745;&#20272;&#35745;&#22120;&#30340;&#38598;&#20013;&#24230;&#65292;&#21516;&#26102;&#20445;&#25345;&#20854;&#26080;&#20559;&#24615;&#12290;&#36825;&#20010;&#26426;&#21046;&#26377;&#19968;&#20010;&#31616;&#21333;&#30340;&#25554;&#20837;&#23454;&#29616;&#26041;&#24335;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25269;&#21046;&#38543;&#26426;&#28216;&#36208;&#22312;&#19968;&#31995;&#21015;&#35774;&#32622;&#20013;&#30340;&#26377;&#25928;&#24615;&#65292;&#21253;&#25324;&#22270;&#26680;&#30340;&#20272;&#35745;&#12289;PageRank&#21521;&#37327;&#21644;&#22270;&#20803;&#27987;&#24230;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#35814;&#32454;&#30340;&#23454;&#39564;&#35780;&#20272;&#21644;&#31283;&#20581;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#25269;&#21046;&#38543;&#26426;&#28216;&#36208;&#26159;&#39318;&#20010;&#22312;&#22270;&#19978;&#30456;&#20851;&#34892;&#36208;&#26041;&#21521;&#30340;&#20934;&#33945;&#29305;&#21345;&#32599;&#26041;&#26696;&#36827;&#34892;&#20102;&#20005;&#35880;&#30740;&#31350;&#65292;&#20026;&#36825;&#20010;&#20196;&#20154;&#20852;&#22859;&#30340;&#26032;&#20852;&#39046;&#22495;&#24320;&#23637;&#26032;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#22865;&#26426;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a novel quasi-Monte Carlo mechanism to improve graph-based sampling, coined repelling random walks. By inducing correlations between the trajectories of an interacting ensemble such that their marginal transition probabilities are unmodified, we are able to explore the graph more efficiently, improving the concentration of statistical estimators whilst leaving them unbiased. The mechanism has a trivial drop-in implementation. We showcase the effectiveness of repelling random walks in a range of settings including estimation of graph kernels, the PageRank vector and graphlet concentrations. We provide detailed experimental evaluation and robust theoretical guarantees. To our knowledge, repelling random walks constitute the first rigorously studied quasi-Monte Carlo scheme correlating the directions of walkers on a graph, inviting new research in this exciting nascent domain.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22270;&#24418;&#23545;&#27604;&#23398;&#20064;&#20013;&#22686;&#24378;&#26041;&#27861;&#21644;&#19979;&#28216;&#24615;&#33021;&#30340;&#20851;&#31995;&#65292;&#24182;&#21457;&#29616;&#22270;&#24418;&#23545;&#27604;&#23398;&#20064;&#20027;&#35201;&#36890;&#36807;&#20998;&#31163;&#19981;&#21516;&#31867;&#21035;&#30340;&#33410;&#28857;&#26469;&#20026;&#19979;&#28216;&#20219;&#21153;&#20570;&#20986;&#36129;&#29486;&#12290;</title><link>http://arxiv.org/abs/2310.03977</link><description>&lt;p&gt;
&#23436;&#32654;&#23545;&#40784;&#21487;&#33021;&#23545;&#22270;&#24418;&#23545;&#27604;&#23398;&#20064;&#20135;&#29983;&#36127;&#38754;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Perfect Alignment May be Poisonous to Graph Contrastive Learning. (arXiv:2310.03977v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03977
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22270;&#24418;&#23545;&#27604;&#23398;&#20064;&#20013;&#22686;&#24378;&#26041;&#27861;&#21644;&#19979;&#28216;&#24615;&#33021;&#30340;&#20851;&#31995;&#65292;&#24182;&#21457;&#29616;&#22270;&#24418;&#23545;&#27604;&#23398;&#20064;&#20027;&#35201;&#36890;&#36807;&#20998;&#31163;&#19981;&#21516;&#31867;&#21035;&#30340;&#33410;&#28857;&#26469;&#20026;&#19979;&#28216;&#20219;&#21153;&#20570;&#20986;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#24418;&#23545;&#27604;&#23398;&#20064;&#26088;&#22312;&#36890;&#36807;&#23545;&#40784;&#27491;&#26679;&#26412;&#21644;&#20998;&#31163;&#36127;&#26679;&#26412;&#26469;&#23398;&#20064;&#33410;&#28857;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;&#22312;&#22522;&#20110;&#22270;&#24418;&#30340;&#23398;&#20064;&#20013;&#65292;&#23545;&#20110;&#29305;&#23450;&#22686;&#24378;&#26041;&#27861;&#32972;&#21518;&#30340;&#20869;&#22312;&#35268;&#24459;&#30340;&#30740;&#31350;&#26377;&#38480;&#12290;&#20160;&#20040;&#26679;&#30340;&#22686;&#24378;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#19979;&#28216;&#24615;&#33021;&#65311;&#23545;&#27604;&#23398;&#20064;&#22914;&#20309;&#23454;&#38469;&#24433;&#21709;&#19979;&#28216;&#20219;&#21153;&#65311;&#20026;&#20160;&#20040;&#22686;&#24378;&#30340;&#24133;&#24230;&#24456;&#37325;&#35201;&#65311;&#26412;&#25991;&#35797;&#22270;&#36890;&#36807;&#24314;&#31435;&#22686;&#24378;&#26041;&#27861;&#21644;&#19979;&#28216;&#24615;&#33021;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#20197;&#21450;&#23545;&#23545;&#27604;&#23398;&#20064;&#30340;&#27867;&#21270;&#24615;&#36827;&#34892;&#30740;&#31350;&#26469;&#22238;&#31572;&#36825;&#20123;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#34920;&#26126;&#65292;&#22270;&#24418;&#23545;&#27604;&#23398;&#20064;&#20027;&#35201;&#36890;&#36807;&#20998;&#31163;&#19981;&#21516;&#31867;&#21035;&#32780;&#19981;&#26159;&#32858;&#38598;&#21516;&#19968;&#31867;&#21035;&#30340;&#33410;&#28857;&#26469;&#20026;&#19979;&#28216;&#20219;&#21153;&#20570;&#20986;&#36129;&#29486;&#12290;&#22240;&#27492;&#65292;&#26080;&#27861;&#35299;&#37322;&#23545;&#27604;&#23398;&#20064;&#30340;&#25104;&#21151;&#65292;&#21363;&#20840;&#37096;&#26679;&#26412;&#23436;&#32654;&#23545;&#40784;&#21644;&#22686;&#24378;&#37325;&#21472;&#12290;&#20026;&#20102;&#29702;&#35299;&#22686;&#24378;&#22914;&#20309;&#36741;&#21161;&#23545;&#27604;&#23398;&#20064;&#36807;&#31243;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#36827;&#19968;&#27493;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Contrastive Learning (GCL) aims to learn node representations by aligning positive pairs and separating negative ones. However, limited research has been conducted on the inner law behind specific augmentations used in graph-based learning. What kind of augmentation will help downstream performance, how does contrastive learning actually influence downstream tasks, and why the magnitude of augmentation matters? This paper seeks to address these questions by establishing a connection between augmentation and downstream performance, as well as by investigating the generalization of contrastive learning. Our findings reveal that GCL contributes to downstream tasks mainly by separating different classes rather than gathering nodes of the same class. So perfect alignment and augmentation overlap which draw all intra-class samples the same can not explain the success of contrastive learning. Then in order to comprehend how augmentation aids the contrastive learning process, we conduct 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#28151;&#21512;&#24322;&#26500;&#24615;&#22914;&#20309;&#24433;&#21709;&#32852;&#37030;&#20248;&#21270;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26368;&#22823;&#21270;&#26799;&#24230;&#22810;&#26679;&#24615;&#26469;&#20943;&#36731;&#28151;&#21512;&#24322;&#26500;&#24615;&#36127;&#38754;&#24433;&#21709;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.02702</link><description>&lt;p&gt;
&#36890;&#36807;&#26368;&#22823;&#21270;&#26799;&#24230;&#22810;&#26679;&#24615;&#26469;&#35299;&#20915;&#32852;&#37030;&#20248;&#21270;&#20013;&#30340;&#28151;&#21512;&#24322;&#26500;&#24615;
&lt;/p&gt;
&lt;p&gt;
Tackling Hybrid Heterogeneity on Federated Optimization via Gradient Diversity Maximization. (arXiv:2310.02702v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02702
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#28151;&#21512;&#24322;&#26500;&#24615;&#22914;&#20309;&#24433;&#21709;&#32852;&#37030;&#20248;&#21270;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26368;&#22823;&#21270;&#26799;&#24230;&#22810;&#26679;&#24615;&#26469;&#20943;&#36731;&#28151;&#21512;&#24322;&#26500;&#24615;&#36127;&#38754;&#24433;&#21709;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#26159;&#19968;&#31181;&#20998;&#24067;&#24335;&#26426;&#22120;&#23398;&#20064;&#33539;&#24335;&#65292;&#20854;&#20013;&#25968;&#25454;&#26679;&#26412;&#34987;&#20998;&#25955;&#21644;&#20998;&#24067;&#22312;&#22810;&#20010;&#23458;&#25143;&#31471;&#20043;&#38388;&#12290;&#36825;&#20123;&#26679;&#26412;&#21487;&#33021;&#34920;&#29616;&#20986;&#32479;&#35745;&#24322;&#36136;&#24615;&#65292;&#21363;&#25968;&#25454;&#20998;&#24067;&#22312;&#23458;&#25143;&#31471;&#20043;&#38388;&#19981;&#26159;&#29420;&#31435;&#21644;&#30456;&#21516;&#30340;&#12290;&#27492;&#22806;&#65292;&#31995;&#32479;&#24322;&#36136;&#24615;&#65292;&#21363;&#23458;&#25143;&#31471;&#35745;&#31639;&#33021;&#21147;&#30340;&#21464;&#21270;&#65292;&#20250;&#32473;&#32852;&#37030;&#23398;&#20064;&#24102;&#26469;&#20559;&#24046;&#12290;&#32479;&#35745;&#21644;&#31995;&#32479;&#24322;&#36136;&#24615;&#30340;&#32508;&#21512;&#25928;&#24212;&#21487;&#20197;&#26174;&#33879;&#38477;&#20302;&#32852;&#37030;&#20248;&#21270;&#30340;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#28151;&#21512;&#24322;&#26500;&#24615;&#30340;&#24433;&#21709;&#24182;&#27809;&#26377;&#24471;&#21040;&#20005;&#35880;&#30340;&#35752;&#35770;&#12290;&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#26381;&#21153;&#22120;&#31471;&#20248;&#21270;&#65292;&#25506;&#35752;&#20102;&#28151;&#21512;&#24322;&#26500;&#24615;&#22914;&#20309;&#24433;&#21709;&#32852;&#37030;&#20248;&#21270;&#12290;&#29702;&#35770;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#26381;&#21153;&#22120;&#26356;&#26032;&#26041;&#21521;&#19978;&#33258;&#36866;&#24212;&#22320;&#26368;&#22823;&#21270;&#26799;&#24230;&#22810;&#26679;&#24615;&#21487;&#20197;&#24110;&#21161;&#20943;&#36731;&#28151;&#21512;&#24322;&#26500;&#24615;&#30340;&#28508;&#22312;&#36127;&#38754;&#24433;&#21709;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#26381;&#21153;&#22120;&#31471;&#26799;&#24230;&#30340;&#20248;&#21270;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated learning refers to a distributed machine learning paradigm in which data samples are decentralized and distributed among multiple clients. These samples may exhibit statistical heterogeneity, which refers to data distributions are not independent and identical across clients. Additionally, system heterogeneity, or variations in the computational power of the clients, introduces biases into federated learning. The combined effects of statistical and system heterogeneity can significantly reduce the efficiency of federated optimization. However, the impact of hybrid heterogeneity is not rigorously discussed. This paper explores how hybrid heterogeneity affects federated optimization by investigating server-side optimization. The theoretical results indicate that adaptively maximizing gradient diversity in server update direction can help mitigate the potential negative consequences of hybrid heterogeneity. To this end, we introduce a novel server-side gradient-based optimizer \
&lt;/p&gt;</description></item><item><title>HyperMask&#26159;&#19968;&#31181;&#29992;&#20110;&#25345;&#32493;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#23427;&#20351;&#29992;&#22522;&#20110;&#36229;&#32593;&#32476;&#30340;&#25513;&#30721;&#26469;&#35757;&#32451;&#19968;&#20010;&#21333;&#19968;&#32593;&#32476;&#65292;&#20197;&#20811;&#26381;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#22312;&#22810;&#20219;&#21153;&#19978;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.00113</link><description>&lt;p&gt;
HyperMask: &#33258;&#36866;&#24212;&#30340;&#22522;&#20110;&#36229;&#32593;&#32476;&#30340;&#25513;&#30721;&#29992;&#20110;&#25345;&#32493;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
HyperMask: Adaptive Hypernetwork-based Masks for Continual Learning. (arXiv:2310.00113v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00113
&lt;/p&gt;
&lt;p&gt;
HyperMask&#26159;&#19968;&#31181;&#29992;&#20110;&#25345;&#32493;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#23427;&#20351;&#29992;&#22522;&#20110;&#36229;&#32593;&#32476;&#30340;&#25513;&#30721;&#26469;&#35757;&#32451;&#19968;&#20010;&#21333;&#19968;&#32593;&#32476;&#65292;&#20197;&#20811;&#26381;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#22312;&#22810;&#20219;&#21153;&#19978;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#22312;&#22810;&#20010;&#20219;&#21153;&#19978;&#39034;&#24207;&#35757;&#32451;&#26102;&#65292;&#24448;&#24448;&#20250;&#20986;&#29616;&#28798;&#38590;&#24615;&#36951;&#24536;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38382;&#39064;&#65292;&#24050;&#32463;&#23384;&#22312;&#35768;&#22810;&#25345;&#32493;&#23398;&#20064;&#31574;&#30053;&#65292;&#20854;&#20013;&#26368;&#26377;&#25928;&#30340;&#20043;&#19968;&#26159;&#22522;&#20110;&#36229;&#32593;&#32476;&#30340;&#26041;&#27861;&#12290;&#36229;&#32593;&#32476;&#26681;&#25454;&#20219;&#21153;&#30340;&#29305;&#24449;&#29983;&#25104;&#30446;&#26631;&#27169;&#22411;&#30340;&#26435;&#37325;&#12290;&#28982;&#32780;&#65292;&#35813;&#27169;&#22411;&#30340;&#20027;&#35201;&#38480;&#21046;&#26159;&#36229;&#32593;&#32476;&#23545;&#20110;&#27599;&#20010;&#20219;&#21153;&#21487;&#20197;&#20135;&#29983;&#23436;&#20840;&#19981;&#21516;&#30340;&#32593;&#32476;&#32467;&#26500;&#65292;&#22240;&#27492;&#27599;&#20010;&#20219;&#21153;&#37117;&#26159;&#21333;&#29420;&#35299;&#20915;&#30340;&#12290;&#27169;&#22411;&#22312;&#23398;&#20064;&#21518;&#32493;&#20219;&#21153;&#26102;&#19981;&#20351;&#29992;&#20043;&#21069;&#20219;&#21153;&#25152;&#20851;&#32852;&#30340;&#32593;&#32476;&#20449;&#24687;&#65292;&#24182;&#23454;&#38469;&#19978;&#20135;&#29983;&#20102;&#26032;&#30340;&#32593;&#32476;&#26550;&#26500;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#24425;&#31080;&#31080;&#35777;&#20551;&#35774;&#65292;&#35813;&#20551;&#35774;&#35748;&#20026;&#23384;&#22312;&#31232;&#30095;&#30340;&#23376;&#32593;&#32476;&#65288;&#21363;&#20013;&#22870;&#31080;&#65289;&#65292;&#21487;&#20197;&#20445;&#25345;&#23436;&#25972;&#32593;&#32476;&#30340;&#24615;&#33021;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;HyperMask&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20026;&#25152;&#26377;&#20219;&#21153;&#35757;&#32451;&#19968;&#20010;&#21333;&#19968;&#32593;&#32476;&#12290;&#36229;&#32593;&#32476;&#20135;&#29983;&#21322;&#20108;&#36827;&#21046;&#25513;&#30721;&#65292;&#20197;&#33719;&#21462;&#30446;&#26631;&#23376;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
Artificial neural networks suffer from catastrophic forgetting when they are sequentially trained on multiple tasks. To overcome this problem, there exist many continual learning strategies. One of the most effective is the hypernetwork-based approach. The hypernetwork generates the weights of a target model based on the task's identity. The model's main limitation is that hypernetwork can produce completely different nests for each task. Consequently, each task is solved separately. The model does not use information from the network dedicated to previous tasks and practically produces new architectures when it learns the subsequent tasks. To solve such a problem, we use the lottery ticket hypothesis, which postulates the existence of sparse subnetworks, named winning tickets, that preserve the performance of a full network.  In the paper, we propose a method called HyperMask, which trains a single network for all tasks. Hypernetwork produces semi-binary masks to obtain target subnetw
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#35270;&#35273;&#35266;&#23519;&#20013;&#36827;&#34892;&#27169;&#20223;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28508;&#22312;&#23545;&#25239;&#35266;&#23519;&#27169;&#20223;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#31163;&#31574;&#30053;&#23545;&#25239;&#23398;&#20064;&#25216;&#26415;&#21644;&#20174;&#35266;&#23519;&#24207;&#21015;&#20013;&#23398;&#20064;&#30340;&#20195;&#29702;&#29366;&#24577;&#30340;&#28508;&#22312;&#34920;&#31034;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#31181;&#31639;&#27861;&#33021;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#30456;&#21305;&#37197;&#12290;</title><link>http://arxiv.org/abs/2309.17371</link><description>&lt;p&gt;
&#21033;&#29992;&#28508;&#22312;&#20449;&#24687;&#20174;&#35270;&#35273;&#35266;&#23519;&#20013;&#36827;&#34892;&#23545;&#25239;&#24615;&#27169;&#20223;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Adversarial Imitation Learning from Visual Observations using Latent Information. (arXiv:2309.17371v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.17371
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#35270;&#35273;&#35266;&#23519;&#20013;&#36827;&#34892;&#27169;&#20223;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28508;&#22312;&#23545;&#25239;&#35266;&#23519;&#27169;&#20223;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#31163;&#31574;&#30053;&#23545;&#25239;&#23398;&#20064;&#25216;&#26415;&#21644;&#20174;&#35266;&#23519;&#24207;&#21015;&#20013;&#23398;&#20064;&#30340;&#20195;&#29702;&#29366;&#24577;&#30340;&#28508;&#22312;&#34920;&#31034;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#31181;&#31639;&#27861;&#33021;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#30456;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#19987;&#27880;&#20110;&#20174;&#35270;&#35273;&#35266;&#23519;&#20013;&#36827;&#34892;&#27169;&#20223;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#23398;&#20064;&#20195;&#29702;&#21482;&#33021;&#35775;&#38382;&#19987;&#23478;&#30340;&#35270;&#39057;&#20316;&#20026;&#20854;&#21807;&#19968;&#30340;&#23398;&#20064;&#28304;&#12290;&#36825;&#20010;&#26694;&#26550;&#30340;&#25361;&#25112;&#21253;&#25324;&#32570;&#20047;&#19987;&#23478;&#30340;&#21160;&#20316;&#21644;&#29615;&#22659;&#30340;&#23616;&#37096;&#21487;&#35266;&#27979;&#24615;&#65292;&#22240;&#20026;&#22320;&#38754;&#30495;&#23454;&#29366;&#24577;&#21482;&#33021;&#20174;&#20687;&#32032;&#20013;&#25512;&#26029;&#20986;&#26469;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#39318;&#20808;&#23545;&#37096;&#20998;&#21487;&#35266;&#27979;&#29615;&#22659;&#20013;&#30340;&#27169;&#20223;&#23398;&#20064;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#12290;&#25105;&#20204;&#22312;&#19987;&#23478;&#21644;&#20195;&#29702;&#28508;&#22312;&#29366;&#24577;&#36716;&#25442;&#20998;&#24067;&#20043;&#38388;&#30340;&#24046;&#24322;&#24230;&#19978;&#24314;&#31435;&#20102;&#23398;&#20064;&#20195;&#29702;&#23376;&#20248;&#24230;&#30340;&#19978;&#30028;&#12290;&#21463;&#21040;&#36825;&#20010;&#20998;&#26512;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;&#28508;&#22312;&#23545;&#25239;&#35266;&#23519;&#27169;&#20223;&#30340;&#31639;&#27861;&#65292;&#23427;&#23558;&#31163;&#31574;&#30053;&#23545;&#25239;&#23398;&#20064;&#25216;&#26415;&#19982;&#20174;&#35266;&#23519;&#24207;&#21015;&#20013;&#23398;&#20064;&#30340;&#20195;&#29702;&#29366;&#24577;&#30340;&#28508;&#22312;&#34920;&#31034;&#30456;&#32467;&#21512;&#12290;&#22312;&#39640;&#32500;&#36830;&#32493;&#26426;&#22120;&#20154;&#20219;&#21153;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#30456;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;
We focus on the problem of imitation learning from visual observations, where the learning agent has access to videos of experts as its sole learning source. The challenges of this framework include the absence of expert actions and the partial observability of the environment, as the ground-truth states can only be inferred from pixels. To tackle this problem, we first conduct a theoretical analysis of imitation learning in partially observable environments. We establish upper bounds on the suboptimality of the learning agent with respect to the divergence between the expert and the agent latent state-transition distributions. Motivated by this analysis, we introduce an algorithm called Latent Adversarial Imitation from Observations, which combines off-policy adversarial imitation techniques with a learned latent representation of the agent's state from sequences of observations. In experiments on high-dimensional continuous robotic tasks, we show that our algorithm matches state-of-t
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25581;&#31034;&#22312;&#26080;&#20559;&#23398;&#20064;&#25490;&#21517;&#20013;&#65292;&#24403;&#28857;&#20987;&#25968;&#25454;&#19981;&#33021;&#23436;&#20840;&#25311;&#21512;&#26102;&#65292;&#26080;&#27861;&#24674;&#22797;&#30495;&#23454;&#30456;&#20851;&#24615;&#65292;&#23548;&#33268;&#25490;&#21517;&#24615;&#33021;&#26174;&#33879;&#38477;&#20302;&#65292;&#25552;&#20986;&#20102;&#21487;&#35782;&#21035;&#24615;&#22270;&#27169;&#22411;&#20316;&#20026;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2309.15560</link><description>&lt;p&gt;
&#35782;&#21035;&#24615;&#24456;&#37325;&#35201;&#65306;&#25581;&#31034;&#26080;&#20559;&#23398;&#20064;&#25490;&#21517;&#20013;&#38544;&#34255;&#30340;&#21487;&#24674;&#22797;&#26465;&#20214;
&lt;/p&gt;
&lt;p&gt;
Identifiability Matters: Revealing the Hidden Recoverable Condition in Unbiased Learning to Rank. (arXiv:2309.15560v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15560
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25581;&#31034;&#22312;&#26080;&#20559;&#23398;&#20064;&#25490;&#21517;&#20013;&#65292;&#24403;&#28857;&#20987;&#25968;&#25454;&#19981;&#33021;&#23436;&#20840;&#25311;&#21512;&#26102;&#65292;&#26080;&#27861;&#24674;&#22797;&#30495;&#23454;&#30456;&#20851;&#24615;&#65292;&#23548;&#33268;&#25490;&#21517;&#24615;&#33021;&#26174;&#33879;&#38477;&#20302;&#65292;&#25552;&#20986;&#20102;&#21487;&#35782;&#21035;&#24615;&#22270;&#27169;&#22411;&#20316;&#20026;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#20559;&#23398;&#20064;&#25490;&#21517;(Unbiased Learning to Rank, ULTR)&#22312;&#20174;&#26377;&#20559;&#28857;&#20987;&#26085;&#24535;&#35757;&#32451;&#26080;&#20559;&#25490;&#21517;&#27169;&#22411;&#30340;&#29616;&#20195;&#31995;&#32479;&#20013;&#34987;&#24191;&#27867;&#24212;&#29992;&#12290;&#20851;&#38190;&#22312;&#20110;&#26126;&#30830;&#22320;&#24314;&#27169;&#29992;&#25143;&#34892;&#20026;&#30340;&#29983;&#25104;&#36807;&#31243;&#65292;&#24182;&#22522;&#20110;&#26816;&#39564;&#20551;&#35774;&#23545;&#28857;&#20987;&#25968;&#25454;&#36827;&#34892;&#25311;&#21512;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#32463;&#39564;&#24615;&#22320;&#21457;&#29616;&#21482;&#35201;&#28857;&#20987;&#23436;&#20840;&#25311;&#21512;&#65292;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#21487;&#20197;&#24674;&#22797;&#20986;&#30495;&#23454;&#28508;&#22312;&#30456;&#20851;&#24615;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35777;&#26126;&#24182;&#38750;&#24635;&#26159;&#33021;&#22815;&#23454;&#29616;&#36825;&#19968;&#28857;&#65292;&#20174;&#32780;&#23548;&#33268;&#25490;&#21517;&#24615;&#33021;&#26174;&#33879;&#38477;&#20302;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#22238;&#31572;&#30495;&#23454;&#30456;&#20851;&#24615;&#26159;&#21542;&#33021;&#22815;&#20174;&#28857;&#20987;&#25968;&#25454;&#24674;&#22797;&#20986;&#26469;&#30340;&#38382;&#39064;&#65292;&#36825;&#26159;ULTR&#39046;&#22495;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#23558;&#19968;&#20010;&#25490;&#21517;&#27169;&#22411;&#23450;&#20041;&#20026;&#21487;&#35782;&#21035;&#30340;&#65292;&#22914;&#26524;&#23427;&#21487;&#20197;&#24674;&#22797;&#20986;&#30495;&#23454;&#30456;&#20851;&#24615;&#65292;&#26368;&#22810;&#21482;&#26377;&#19968;&#20010;&#32553;&#25918;&#21464;&#25442;&#65292;&#36825;&#23545;&#20110;&#25104;&#23545;&#25490;&#21517;&#30446;&#26631;&#26469;&#35828;&#24050;&#36275;&#22815;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#19968;&#20010;&#31561;&#20215;&#30340;&#21487;&#35782;&#21035;&#26465;&#20214;&#65292;&#21487;&#20197;&#26032;&#39062;&#22320;&#34920;&#36798;&#20026;&#19968;&#20010;&#22270;&#36830;&#36890;&#24615;&#27979;&#35797;&#38382;&#39064;&#65306;&#24403;&#19988;&#20165;&#24403;&#19968;&#20010;&#22270;&#65288;&#21363;&#21487;&#35782;&#21035;&#24615;&#22270;&#65289;&#36830;&#36890;&#26102;&#65292;&#35813;&#25490;&#21517;&#27169;&#22411;&#26159;&#21487;&#35782;&#21035;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
The application of Unbiased Learning to Rank (ULTR) is widespread in modern systems for training unbiased ranking models from biased click logs. The key is to explicitly model a generation process for user behavior and fit click data based on examination hypothesis. Previous research found empirically that the true latent relevance can be recovered in most cases as long as the clicks are perfectly fitted. However, we demonstrate that this is not always achievable, resulting in a significant reduction in ranking performance. In this work, we aim to answer if or when the true relevance can be recovered from click data, which is a foundation issue for ULTR field. We first define a ranking model as identifiable if it can recover the true relevance up to a scaling transformation, which is enough for pairwise ranking objective. Then we explore an equivalent condition for identifiability that can be novely expressed as a graph connectivity test problem: if and only if a graph (namely identifi
&lt;/p&gt;</description></item><item><title>&#22270;&#23545;&#27604;&#23398;&#20064;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#35757;&#32451;&#23384;&#22312;&#19981;&#24179;&#34913;&#30340;&#38382;&#39064;&#65292;&#20026;&#27492;&#25105;&#20204;&#25552;&#20986;&#20102;&#8220;&#33410;&#28857;&#32039;&#20945;&#24615;&#8221;&#24230;&#37327;&#26469;&#25351;&#23548;&#35757;&#32451;&#12290;</title><link>http://arxiv.org/abs/2309.13944</link><description>&lt;p&gt;
&#22270;&#23545;&#27604;&#23398;&#20064;&#30340;&#21487;&#35777;&#26126;&#35757;&#32451;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Provable Training for Graph Contrastive Learning. (arXiv:2309.13944v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13944
&lt;/p&gt;
&lt;p&gt;
&#22270;&#23545;&#27604;&#23398;&#20064;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#35757;&#32451;&#23384;&#22312;&#19981;&#24179;&#34913;&#30340;&#38382;&#39064;&#65292;&#20026;&#27492;&#25105;&#20204;&#25552;&#20986;&#20102;&#8220;&#33410;&#28857;&#32039;&#20945;&#24615;&#8221;&#24230;&#37327;&#26469;&#25351;&#23548;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#23545;&#27604;&#23398;&#20064;&#65288;GCL&#65289;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#20174;&#22686;&#24378;&#22270;&#20013;&#23398;&#20064;&#33410;&#28857;&#23884;&#20837;&#32780;&#26080;&#38656;&#26631;&#31614;&#30340;&#27969;&#34892;&#35757;&#32451;&#26041;&#27861;&#12290;&#23613;&#31649;&#26368;&#22823;&#21270;&#27491;&#33410;&#28857;&#23545;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#24182;&#26368;&#23567;&#21270;&#36127;&#33410;&#28857;&#23545;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#30340;&#20851;&#38190;&#21407;&#21017;&#24050;&#32463;&#24471;&#21040;&#30830;&#35748;&#65292;&#20294;&#20173;&#23384;&#22312;&#19968;&#20123;&#22522;&#26412;&#38382;&#39064;&#12290;&#32771;&#34385;&#21040;&#22797;&#26434;&#30340;&#22270;&#32467;&#26500;&#65292;&#26159;&#21542;&#26377;&#19968;&#20123;&#33410;&#28857;&#22987;&#32456;&#25353;&#29031;&#36825;&#19968;&#21407;&#21017;&#36827;&#34892;&#33391;&#22909;&#35757;&#32451;&#65292;&#21363;&#20351;&#22312;&#19981;&#21516;&#30340;&#22270;&#22686;&#24378;&#26041;&#27861;&#19979;&#20063;&#26159;&#22914;&#27492;&#65311;&#36824;&#26159;&#26377;&#19968;&#20123;&#33410;&#28857;&#26356;&#26377;&#21487;&#33021;&#22312;&#22270;&#22686;&#24378;&#20013;&#26410;&#32463;&#35757;&#32451;&#65292;&#24182;&#36829;&#21453;&#36825;&#19968;&#21407;&#21017;&#65311;&#22914;&#20309;&#21306;&#20998;&#36825;&#20123;&#33410;&#28857;&#24182;&#36827;&#19968;&#27493;&#25351;&#23548;GCL&#30340;&#35757;&#32451;&#65311;&#20026;&#20102;&#22238;&#31572;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#23454;&#39564;&#35777;&#25454;&#65292;&#34920;&#26126;GCL&#30340;&#35757;&#32451;&#22312;&#25152;&#26377;&#33410;&#28857;&#19978;&#30830;&#23454;&#23384;&#22312;&#19981;&#24179;&#34913;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#24230;&#37327;&#8220;&#33410;&#28857;&#32039;&#20945;&#24615;&#8221;&#65292;&#23427;&#26159;&#33410;&#28857;&#36981;&#24490;GCL&#21407;&#21017;&#19982;&#22686;&#24378;&#33539;&#22260;&#30456;&#20851;&#30340;&#19979;&#30028;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23548;&#20986;&#20102;
&lt;/p&gt;
&lt;p&gt;
Graph Contrastive Learning (GCL) has emerged as a popular training approach for learning node embeddings from augmented graphs without labels. Despite the key principle that maximizing the similarity between positive node pairs while minimizing it between negative node pairs is well established, some fundamental problems are still unclear. Considering the complex graph structure, are some nodes consistently well-trained and following this principle even with different graph augmentations? Or are there some nodes more likely to be untrained across graph augmentations and violate the principle? How to distinguish these nodes and further guide the training of GCL? To answer these questions, we first present experimental evidence showing that the training of GCL is indeed imbalanced across all nodes. To address this problem, we propose the metric "node compactness", which is the lower bound of how a node follows the GCL principle related to the range of augmentations. We further derive the
&lt;/p&gt;</description></item><item><title>Des-q&#26159;&#19968;&#31181;&#37327;&#23376;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#22238;&#24402;&#21644;&#20108;&#20998;&#31867;&#20219;&#21153;&#20013;&#26500;&#24314;&#21644;&#37325;&#26032;&#35757;&#32451;&#20915;&#31574;&#26641;&#12290;&#23427;&#26174;&#33879;&#20943;&#23569;&#20102;&#26641;&#37325;&#26032;&#35757;&#32451;&#25152;&#38656;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#65292;&#24182;&#19988;&#33021;&#22815;&#22788;&#29702;&#26032;&#26679;&#26412;&#30340;&#21152;&#36733;&#26102;&#38388;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807; k &#20998;&#27573;&#32447;&#24615;&#26641;&#20998;&#35010;&#26469;&#26500;&#24314;&#20915;&#31574;&#26641;&#65292;&#23558;&#25968;&#25454;&#21010;&#20998;&#20026;&#19981;&#21516;&#30340;&#23376;&#31354;&#38388;&#12290;</title><link>http://arxiv.org/abs/2309.09976</link><description>&lt;p&gt;
Des-q: &#19968;&#31181;&#29992;&#20110;&#22238;&#24402;&#21644;&#20108;&#20998;&#31867;&#30340;&#26500;&#24314;&#21644;&#39640;&#25928;&#37325;&#26032;&#35757;&#32451;&#20915;&#31574;&#26641;&#30340;&#37327;&#23376;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Des-q: a quantum algorithm to construct and efficiently retrain decision trees for regression and binary classification. (arXiv:2309.09976v2 [quant-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09976
&lt;/p&gt;
&lt;p&gt;
Des-q&#26159;&#19968;&#31181;&#37327;&#23376;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#22238;&#24402;&#21644;&#20108;&#20998;&#31867;&#20219;&#21153;&#20013;&#26500;&#24314;&#21644;&#37325;&#26032;&#35757;&#32451;&#20915;&#31574;&#26641;&#12290;&#23427;&#26174;&#33879;&#20943;&#23569;&#20102;&#26641;&#37325;&#26032;&#35757;&#32451;&#25152;&#38656;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#65292;&#24182;&#19988;&#33021;&#22815;&#22788;&#29702;&#26032;&#26679;&#26412;&#30340;&#21152;&#36733;&#26102;&#38388;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807; k &#20998;&#27573;&#32447;&#24615;&#26641;&#20998;&#35010;&#26469;&#26500;&#24314;&#20915;&#31574;&#26641;&#65292;&#23558;&#25968;&#25454;&#21010;&#20998;&#20026;&#19981;&#21516;&#30340;&#23376;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20915;&#31574;&#26641;&#30001;&#20110;&#20854;&#31616;&#21333;&#26500;&#36896;&#21644;&#21487;&#35299;&#37322;&#24615;&#32780;&#24191;&#27867;&#24212;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#25968;&#25454;&#35268;&#27169;&#30340;&#22686;&#38271;&#65292;&#20256;&#32479;&#30340;&#20915;&#31574;&#26641;&#26500;&#24314;&#21644;&#37325;&#26032;&#35757;&#32451;&#26041;&#27861;&#21464;&#24471;&#36234;&#26469;&#36234;&#24930;&#65292;&#19982;&#35757;&#32451;&#26679;&#26412;&#25968;&#37327;&#21576;&#22810;&#39033;&#24335;&#35268;&#27169;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#37327;&#23376;&#31639;&#27861;Des-q&#65292;&#29992;&#20110;&#22312;&#22238;&#24402;&#21644;&#20108;&#20998;&#31867;&#20219;&#21153;&#20013;&#26500;&#24314;&#21644;&#37325;&#26032;&#35757;&#32451;&#20915;&#31574;&#26641;&#12290;&#20551;&#35774;&#25968;&#25454;&#27969;&#20135;&#29983;&#36739;&#23567;&#30340;&#26032;&#35757;&#32451;&#26679;&#26412;&#22686;&#37327;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;Des-q&#31639;&#27861;&#26174;&#33879;&#20943;&#23569;&#20102;&#26641;&#37325;&#26032;&#35757;&#32451;&#25152;&#38656;&#30340;&#26102;&#38388;&#65292;&#21363;&#20351;&#32771;&#34385;&#23558;&#26032;&#26679;&#26412;&#21152;&#36733;&#21040;&#37327;&#23376;&#21487;&#35775;&#38382;&#20869;&#23384;&#25152;&#38656;&#30340;&#26102;&#38388;&#65292;&#20854;&#26102;&#38388;&#22797;&#26434;&#24230;&#20063;&#36798;&#21040;&#20102;&#22810;&#23545;&#25968;&#32423;&#21035;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28041;&#21450;&#26500;&#24314;&#19968;&#20010;&#20915;&#31574;&#26641;&#31639;&#27861;&#65292;&#22312;&#27599;&#20010;&#20869;&#37096;&#33410;&#28857;&#25191;&#34892;k&#20998;&#27573;&#32447;&#24615;&#26641;&#20998;&#35010;&#12290;&#36825;&#20123;&#20998;&#35010;&#21516;&#26102;&#29983;&#25104;&#22810;&#20010;&#36229;&#24179;&#38754;&#65292;&#23558;&#25968;&#25454;&#21010;&#20998;&#20026;&#19981;&#21516;&#30340;&#23376;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
Decision trees are widely used in machine learning due to their simplicity in construction and interpretability. However, as data sizes grow, traditional methods for constructing and retraining decision trees become increasingly slow, scaling polynomially with the number of training examples. In this work, we introduce a novel quantum algorithm, named Des-q, for constructing and retraining decision trees in regression and binary classification tasks. Assuming the data stream produces small increments of new training examples, we demonstrate that our Des-q algorithm significantly reduces the time required for tree retraining, achieving a poly-logarithmic time complexity in the number of training examples, even accounting for the time needed to load the new examples into quantum-accessible memory. Our approach involves building a decision tree algorithm to perform k-piecewise linear tree splits at each internal node. These splits simultaneously generate multiple hyperplanes, dividing the
&lt;/p&gt;</description></item><item><title>&#21363;&#20351;&#22312;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#20013;&#20063;&#23384;&#22312;&#20851;&#38190;&#23398;&#20064;&#26399;&#65292;&#36825;&#20123;&#20851;&#38190;&#23398;&#20064;&#26399;&#21462;&#20915;&#20110;&#27169;&#22411;&#30340;&#28145;&#24230;&#21644;&#25968;&#25454;&#20998;&#24067;&#30340;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2308.12221</link><description>&lt;p&gt;
&#21363;&#20351;&#22312;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#20013;&#20063;&#23384;&#22312;&#20851;&#38190;&#23398;&#20064;&#26399;
&lt;/p&gt;
&lt;p&gt;
Critical Learning Periods Emerge Even in Deep Linear Networks. (arXiv:2308.12221v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12221
&lt;/p&gt;
&lt;p&gt;
&#21363;&#20351;&#22312;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#20013;&#20063;&#23384;&#22312;&#20851;&#38190;&#23398;&#20064;&#26399;&#65292;&#36825;&#20123;&#20851;&#38190;&#23398;&#20064;&#26399;&#21462;&#20915;&#20110;&#27169;&#22411;&#30340;&#28145;&#24230;&#21644;&#25968;&#25454;&#20998;&#24067;&#30340;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20851;&#38190;&#23398;&#20064;&#26399;&#26159;&#25351;&#22312;&#21457;&#32946;&#26089;&#26399;&#65292;&#26242;&#26102;&#30340;&#24863;&#30693;&#32570;&#38519;&#20250;&#23545;&#34892;&#20026;&#21644;&#23398;&#20064;&#34920;&#31034;&#20135;&#29983;&#27704;&#20037;&#24433;&#21709;&#30340;&#26102;&#38388;&#27573;&#12290;&#23613;&#31649;&#29983;&#29289;&#32593;&#32476;&#21644;&#20154;&#24037;&#32593;&#32476;&#20043;&#38388;&#23384;&#22312;&#26681;&#26412;&#24615;&#30340;&#24046;&#24322;&#65292;&#20294;&#20851;&#38190;&#23398;&#20064;&#26399;&#22312;&#20004;&#20010;&#31995;&#32479;&#20013;&#37117;&#26377;&#32463;&#39564;&#35266;&#23519;&#21040;&#12290;&#36825;&#34920;&#26126;&#20851;&#38190;&#23398;&#20064;&#26399;&#21487;&#33021;&#26159;&#23398;&#20064;&#30340;&#22522;&#26412;&#35201;&#32032;&#65292;&#32780;&#19981;&#26159;&#29983;&#29289;&#23398;&#19978;&#30340;&#20598;&#28982;&#29616;&#35937;&#12290;&#28982;&#32780;&#65292;&#20026;&#20160;&#20040;&#20851;&#38190;&#23398;&#20064;&#26399;&#20250;&#22312;&#28145;&#24230;&#32593;&#32476;&#20013;&#20986;&#29616;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#35299;&#20043;&#35868;&#65292;&#23588;&#20854;&#26159;&#19981;&#28165;&#26970;&#22312;&#20004;&#20010;&#31995;&#32479;&#20013;&#35266;&#23519;&#21040;&#30340;&#20851;&#38190;&#23398;&#20064;&#26399;&#26159;&#21542;&#20381;&#36182;&#20110;&#29305;&#23450;&#30340;&#26550;&#26500;&#25110;&#20248;&#21270;&#32454;&#33410;&#12290;&#20026;&#20102;&#30830;&#23450;&#20851;&#38190;&#30340;&#22522;&#26412;&#22240;&#32032;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#27169;&#22411;&#65292;&#24182;&#23637;&#31034;&#20102;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#36825;&#26679;&#30340;&#32593;&#32476;&#20063;&#26174;&#31034;&#20986;&#29983;&#29289;&#23398;&#21644;&#20154;&#24037;&#32593;&#32476;&#20013;&#35266;&#23519;&#21040;&#30340;&#35768;&#22810;&#34892;&#20026;&#65292;&#21516;&#26102;&#36824;&#21487;&#20197;&#36827;&#34892;&#20998;&#26512;&#22788;&#29702;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20851;&#38190;&#23398;&#20064;&#26399;&#21462;&#20915;&#20110;&#27169;&#22411;&#30340;&#28145;&#24230;&#21644;&#25968;&#25454;&#20998;&#24067;&#30340;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Critical learning periods are periods early in development where temporary sensory deficits can have a permanent effect on behavior and learned representations. Despite the radical differences between biological and artificial networks, critical learning periods have been empirically observed in both systems. This suggests that critical periods may be fundamental to learning and not an accident of biology. Yet, why exactly critical periods emerge in deep networks is still an open question, and in particular it is unclear whether the critical periods observed in both systems depend on particular architectural or optimization details. To isolate the key underlying factors, we focus on deep linear network models, and show that, surprisingly, such networks also display much of the behavior seen in biology and artificial networks, while being amenable to analytical treatment. We show that critical periods depend on the depth of the model and structure of the data distribution. We also show 
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#37327;&#23376;&#36924;&#36817;&#26041;&#26696;&#65292;&#29992;&#20110;&#35299;&#20915;&#32463;&#20856;&#30340;k-Means&#32858;&#31867;&#38382;&#39064;&#65292;&#35813;&#26041;&#26696;&#30340;&#36816;&#34892;&#26102;&#38388;&#19982;&#25968;&#25454;&#28857;&#30340;&#25968;&#37327;&#20855;&#26377;&#22810;&#23545;&#25968;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#19988;&#33021;&#22815;&#22312;&#39640;&#27010;&#29575;&#19979;&#36755;&#20986;&#19968;&#20010;&#36817;&#20284;&#26368;&#20248;&#35299;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#20855;&#26377;&#22810;&#23545;&#25968;&#36816;&#34892;&#26102;&#38388;&#30340;&#37327;&#23376;&#31639;&#27861;&#65292;&#24182;&#19988;&#33021;&#22815;&#25552;&#20379;&#19968;&#20010;&#21487;&#35777;&#26126;&#30340;&#36924;&#36817;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2308.08167</link><description>&lt;p&gt;
&#19968;&#20010;&#29992;&#20110;k-Means&#30340;&#37327;&#23376;&#36924;&#36817;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
A Quantum Approximation Scheme for k-Means. (arXiv:2308.08167v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08167
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#37327;&#23376;&#36924;&#36817;&#26041;&#26696;&#65292;&#29992;&#20110;&#35299;&#20915;&#32463;&#20856;&#30340;k-Means&#32858;&#31867;&#38382;&#39064;&#65292;&#35813;&#26041;&#26696;&#30340;&#36816;&#34892;&#26102;&#38388;&#19982;&#25968;&#25454;&#28857;&#30340;&#25968;&#37327;&#20855;&#26377;&#22810;&#23545;&#25968;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#19988;&#33021;&#22815;&#22312;&#39640;&#27010;&#29575;&#19979;&#36755;&#20986;&#19968;&#20010;&#36817;&#20284;&#26368;&#20248;&#35299;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#20855;&#26377;&#22810;&#23545;&#25968;&#36816;&#34892;&#26102;&#38388;&#30340;&#37327;&#23376;&#31639;&#27861;&#65292;&#24182;&#19988;&#33021;&#22815;&#25552;&#20379;&#19968;&#20010;&#21487;&#35777;&#26126;&#30340;&#36924;&#36817;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;QRAM&#27169;&#22411;&#20013;&#25552;&#20379;&#20102;&#19968;&#20010;&#37327;&#23376;&#36924;&#36817;&#26041;&#26696;&#65288;&#21363;&#23545;&#20110;&#20219;&#24847;&#949; &gt; 0, &#37117;&#26159; (1 + &#949;)-&#36924;&#36817;&#65289;&#65292;&#29992;&#20110;&#32463;&#20856;&#30340;k-Means&#32858;&#31867;&#38382;&#39064;&#65292;&#20854;&#36816;&#34892;&#26102;&#38388;&#20165;&#19982;&#25968;&#25454;&#28857;&#30340;&#25968;&#37327;&#20855;&#26377;&#22810;&#23545;&#25968;&#20381;&#36182;&#20851;&#31995;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#32473;&#23450;&#19968;&#20010;&#22312;QRAM&#25968;&#25454;&#32467;&#26500;&#20013;&#23384;&#20648;&#30340;&#20855;&#26377;N&#20010;&#28857;&#30340;&#25968;&#25454;&#38598;V&#65292;&#36825;&#20010;&#37327;&#23376;&#31639;&#27861;&#30340;&#36816;&#34892;&#26102;&#38388;&#20026;O&#771;(2^(O&#771;(k/&#949;))&#951;^2d)&#65292;&#24182;&#19988;&#20197;&#39640;&#27010;&#29575;&#36755;&#20986;&#19968;&#20010;&#21253;&#21547;k&#20010;&#20013;&#24515;&#30340;&#38598;&#21512;C&#65292;&#28385;&#36275;cost(V, C) &#8804; (1+&#949;) &#183; cost(V, C_OPT)&#12290;&#36825;&#37324;C_OPT&#34920;&#31034;&#26368;&#20248;&#30340;k&#20010;&#20013;&#24515;&#65292;cost(.)&#34920;&#31034;&#26631;&#20934;&#30340;k-Means&#20195;&#20215;&#20989;&#25968;&#65288;&#21363;&#28857;&#21040;&#26368;&#36817;&#20013;&#24515;&#30340;&#24179;&#26041;&#36317;&#31163;&#20043;&#21644;&#65289;&#65292;&#32780;&#951;&#26159;&#32437;&#27178;&#27604;&#65288;&#21363;&#26368;&#36828;&#36317;&#31163;&#19982;&#26368;&#36817;&#36317;&#31163;&#30340;&#27604;&#20540;&#65289;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#20855;&#26377;&#22810;&#23545;&#25968;&#36816;&#34892;&#26102;&#38388;&#30340;&#37327;&#23376;&#31639;&#27861;&#65292;&#24182;&#19988;&#33021;&#22815;&#25552;&#20379;&#19968;&#20010;&#21487;&#35777;&#26126;&#30340;(1+&#949;)&#36924;&#36817;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We give a quantum approximation scheme (i.e., $(1 + \varepsilon)$-approximation for every $\varepsilon &gt; 0$) for the classical $k$-means clustering problem in the QRAM model with a running time that has only polylogarithmic dependence on the number of data points. More specifically, given a dataset $V$ with $N$ points in $\mathbb{R}^d$ stored in QRAM data structure, our quantum algorithm runs in time $\tilde{O} \left( 2^{\tilde{O}(\frac{k}{\varepsilon})} \eta^2 d\right)$ and with high probability outputs a set $C$ of $k$ centers such that $cost(V, C) \leq (1+\varepsilon) \cdot cost(V, C_{OPT})$. Here $C_{OPT}$ denotes the optimal $k$-centers, $cost(.)$ denotes the standard $k$-means cost function (i.e., the sum of the squared distance of points to the closest center), and $\eta$ is the aspect ratio (i.e., the ratio of maximum distance to minimum distance). This is the first quantum algorithm with a polylogarithmic running time that gives a provable approximation guarantee of $(1+\varep
&lt;/p&gt;</description></item><item><title>&#23376;&#27169;&#22359;&#24378;&#21270;&#23398;&#20064;(SubRL)&#26159;&#19968;&#31181;&#29992;&#20110;&#20248;&#21270;&#38750;&#21487;&#21152;&#22870;&#21169;&#30340;&#33539;&#24335;&#65292;&#36890;&#36807;&#23376;&#27169;&#22359;&#38598;&#21512;&#20989;&#25968;&#26469;&#24314;&#27169;&#36882;&#20943;&#22238;&#25253;&#12290;&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;SubRL&#30340;&#31616;&#21333;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;SubPO&#65292;&#21487;&#20197;&#29992;&#20110;&#22788;&#29702;&#36825;&#31181;&#31867;&#22411;&#30340;&#22870;&#21169;&#12290;</title><link>http://arxiv.org/abs/2307.13372</link><description>&lt;p&gt;
&#23376;&#27169;&#22359;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Submodular Reinforcement Learning. (arXiv:2307.13372v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13372
&lt;/p&gt;
&lt;p&gt;
&#23376;&#27169;&#22359;&#24378;&#21270;&#23398;&#20064;(SubRL)&#26159;&#19968;&#31181;&#29992;&#20110;&#20248;&#21270;&#38750;&#21487;&#21152;&#22870;&#21169;&#30340;&#33539;&#24335;&#65292;&#36890;&#36807;&#23376;&#27169;&#22359;&#38598;&#21512;&#20989;&#25968;&#26469;&#24314;&#27169;&#36882;&#20943;&#22238;&#25253;&#12290;&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;SubRL&#30340;&#31616;&#21333;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;SubPO&#65292;&#21487;&#20197;&#29992;&#20110;&#22788;&#29702;&#36825;&#31181;&#31867;&#22411;&#30340;&#22870;&#21169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#29366;&#24577;&#30340;&#22870;&#21169;&#36890;&#24120;&#34987;&#35748;&#20026;&#26159;&#21487;&#21152;&#30340;&#65292;&#24182;&#19988;&#26681;&#25454;&#39532;&#23572;&#21487;&#22827;&#20551;&#35774;&#65292;&#23427;&#20204;&#19982;&#20043;&#21069;&#35775;&#38382;&#30340;&#29366;&#24577;$\textit{&#29420;&#31435;}$&#12290;&#22312;&#35768;&#22810;&#37325;&#35201;&#24212;&#29992;&#20013;&#65292;&#22914;&#35206;&#30422;&#25511;&#21046;&#12289;&#23454;&#39564;&#35774;&#35745;&#21644;&#20449;&#24687;&#36335;&#24452;&#35268;&#21010;&#65292;&#22870;&#21169;&#33258;&#28982;&#20855;&#26377;&#36882;&#20943;&#22238;&#25253;&#65292;&#21363;&#20854;&#20215;&#20540;&#38543;&#20043;&#21069;&#35775;&#38382;&#36807;&#30340;&#30456;&#20284;&#29366;&#24577;&#30340;&#22686;&#21152;&#32780;&#20943;&#23567;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;$\textit{&#23376;&#27169;&#22359;&#24378;&#21270;&#23398;&#20064;}$ (SubRL) &#65292;&#36825;&#19968;&#33539;&#24335;&#26088;&#22312;&#36890;&#36807;&#23376;&#27169;&#22359;&#38598;&#21512;&#20989;&#25968;&#26469;&#24314;&#27169;&#36882;&#20943;&#22238;&#25253;&#65292;&#20174;&#32780;&#20248;&#21270;&#26356;&#19968;&#33324;&#30340;&#38750;&#21487;&#21152;&#22870;&#21169;&#65288;&#21382;&#21490;&#30456;&#20851;&#65289;&#12290;&#28982;&#32780;&#65292;&#19981;&#24184;&#30340;&#26159;&#65292;&#21363;&#20351;&#22312;&#34920;&#26684;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24471;&#21040;&#30340;&#20248;&#21270;&#38382;&#39064;&#24456;&#38590;&#36817;&#20284;&#35299;&#20915;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#21463;&#32463;&#20856;&#23376;&#27169;&#22359;&#20248;&#21270;&#20013;&#36138;&#23146;&#31639;&#27861;&#30340;&#25104;&#21151;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;SubPO&#65292;&#19968;&#31181;&#29992;&#20110;SubRL&#30340;&#31616;&#21333;&#22522;&#20110;&#31574;&#30053;&#26799;&#24230;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#36138;&#23146;&#22320;&#26368;&#22823;&#21270;&#36793;&#38469;&#26469;&#22788;&#29702;&#38750;&#21487;&#21152;&#22870;&#21169;&#12290;
&lt;/p&gt;
&lt;p&gt;
In reinforcement learning (RL), rewards of states are typically considered additive, and following the Markov assumption, they are $\textit{independent}$ of states visited previously. In many important applications, such as coverage control, experiment design and informative path planning, rewards naturally have diminishing returns, i.e., their value decreases in light of similar states visited previously. To tackle this, we propose $\textit{submodular RL}$ (SubRL), a paradigm which seeks to optimize more general, non-additive (and history-dependent) rewards modelled via submodular set functions which capture diminishing returns. Unfortunately, in general, even in tabular settings, we show that the resulting optimization problem is hard to approximate. On the other hand, motivated by the success of greedy algorithms in classical submodular optimization, we propose SubPO, a simple policy gradient-based algorithm for SubRL that handles non-additive rewards by greedily maximizing marginal
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#26399;&#21464;&#20998;&#25512;&#26029;&#20316;&#20026;&#36817;&#20284;&#21518;&#39564;&#25512;&#26029;&#30340;&#19968;&#31181;&#36890;&#29992;&#26367;&#20195;&#26041;&#27861;&#65292;&#25506;&#35752;&#20102;&#20309;&#26102;&#33021;&#22815;&#36798;&#21040;&#19982;&#20256;&#32479;&#30340;&#22240;&#23376;&#21270;&#21464;&#20998;&#25512;&#26029;&#30456;&#21516;&#30340;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2307.11018</link><description>&lt;p&gt;
&#20998;&#26399;&#21464;&#20998;&#25512;&#26029;&#65306;&#20309;&#26102;&#20197;&#21450;&#20026;&#20160;&#20040;&#20351;&#29992;&#65311;
&lt;/p&gt;
&lt;p&gt;
Amortized Variational Inference: When and Why?. (arXiv:2307.11018v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11018
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#26399;&#21464;&#20998;&#25512;&#26029;&#20316;&#20026;&#36817;&#20284;&#21518;&#39564;&#25512;&#26029;&#30340;&#19968;&#31181;&#36890;&#29992;&#26367;&#20195;&#26041;&#27861;&#65292;&#25506;&#35752;&#20102;&#20309;&#26102;&#33021;&#22815;&#36798;&#21040;&#19982;&#20256;&#32479;&#30340;&#22240;&#23376;&#21270;&#21464;&#20998;&#25512;&#26029;&#30456;&#21516;&#30340;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#26399;&#21464;&#20998;&#25512;&#26029;&#65288;A-VI&#65289;&#26159;&#19968;&#31181;&#36817;&#20284;&#22788;&#29702;&#27010;&#29575;&#27169;&#22411;&#20013;&#30340;&#38590;&#20197;&#35745;&#31639;&#30340;&#21518;&#39564;&#20998;&#24067;&#30340;&#26041;&#27861;&#12290;A-VI&#30340;&#23450;&#20041;&#29305;&#28857;&#26159;&#23398;&#20064;&#19968;&#20010;&#20840;&#23616;&#25512;&#26029;&#20989;&#25968;&#65292;&#23558;&#27599;&#20010;&#35266;&#23519;&#26144;&#23556;&#21040;&#20854;&#23616;&#37096;&#28508;&#21464;&#37327;&#30340;&#36817;&#20284;&#21518;&#39564;&#20998;&#24067;&#12290;&#36825;&#19982;&#26356;&#20256;&#32479;&#30340;&#20998;&#35299;&#65288;&#25110;&#22343;&#22330;&#65289;&#21464;&#20998;&#25512;&#26029;&#65288;F-VI&#65289;&#24418;&#25104;&#23545;&#27604;&#65292;&#21518;&#32773;&#30452;&#25509;&#23398;&#20064;&#27599;&#20010;&#28508;&#21464;&#37327;&#30340;&#36817;&#20284;&#20998;&#24067;&#30340;&#21442;&#25968;&#12290;&#22312;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#20013;&#65292;A-VI&#29992;&#20316;&#21152;&#36895;&#23616;&#37096;&#28508;&#21464;&#37327;&#25512;&#26029;&#30340;&#35745;&#31639;&#25216;&#24039;&#12290;&#26412;&#25991;&#30740;&#31350;A-VI&#20316;&#20026;&#36817;&#20284;&#21518;&#39564;&#25512;&#26029;&#30340;&#19968;&#31181;&#36890;&#29992;&#26367;&#20195;&#26041;&#27861;&#12290;&#30001;&#20110;&#20998;&#26399;&#23478;&#26063;&#26159;&#20998;&#35299;&#23478;&#26063;&#30340;&#23376;&#38598;&#65292;A-VI&#26080;&#27861;&#20135;&#29983;&#27604;F-VI&#26368;&#20248;&#35299;&#26356;&#20302;&#30340;Kullback-Leibler&#25955;&#24230;&#30340;&#36817;&#20284;&#20540;&#12290;&#22240;&#27492;&#65292;&#19968;&#20010;&#26680;&#24515;&#30340;&#29702;&#35770;&#38382;&#39064;&#26159;&#21051;&#30011;A-VI&#20309;&#26102;&#20173;&#28982;&#36798;&#21040;F-VI&#30340;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Amortized variational inference (A-VI) is a method for approximating the intractable posterior distributions that arise in probabilistic models. The defining feature of A-VI is that it learns a global inference function that maps each observation to its local latent variable's approximate posterior. This stands in contrast to the more classical factorized (or mean-field) variational inference (F-VI), which directly learns the parameters of the approximating distribution for each latent variable. In deep generative models, A-VI is used as a computational trick to speed up inference for local latent variables. In this paper, we study A-VI as a general alternative to F-VI for approximate posterior inference. A-VI cannot produce an approximation with a lower Kullback-Leibler divergence than F-VI's optimal solution, because the amortized family is a subset of the factorized family. Thus a central theoretical problem is to characterize when A-VI still attains F-VI's optimal solution. We deri
&lt;/p&gt;</description></item><item><title>&#38750;&#32447;&#24615;&#20803;&#23398;&#20064;&#21487;&#20197;&#20445;&#35777;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2307.10870</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#20803;&#23398;&#20064;&#21487;&#20197;&#20445;&#35777;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;
&lt;/p&gt;
&lt;p&gt;
Nonlinear Meta-Learning Can Guarantee Faster Rates. (arXiv:2307.10870v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10870
&lt;/p&gt;
&lt;p&gt;
&#38750;&#32447;&#24615;&#20803;&#23398;&#20064;&#21487;&#20197;&#20445;&#35777;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#35768;&#22810;&#20851;&#20110;&#20803;&#23398;&#20064;&#30340;&#29702;&#35770;&#30740;&#31350;&#26088;&#22312;&#21033;&#29992;&#30456;&#20851;&#20219;&#21153;&#20013;&#30340;&#30456;&#20284;&#34920;&#31034;&#32467;&#26500;&#26469;&#31616;&#21270;&#30446;&#26631;&#20219;&#21153;&#65292;&#24182;&#23454;&#29616;&#25910;&#25947;&#36895;&#29575;&#30340;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#34920;&#31034;&#24448;&#24448;&#26159;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#65292;&#24341;&#20837;&#20102;&#27599;&#20010;&#20219;&#21153;&#20013;&#19981;&#21487;&#31616;&#21333;&#24179;&#22343;&#30340;&#38750;&#24179;&#20961;&#20559;&#24046;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#38750;&#32447;&#24615;&#34920;&#31034;&#25512;&#23548;&#20986;&#20803;&#23398;&#20064;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many recent theoretical works on \emph{meta-learning} aim to achieve guarantees in leveraging similar representational structures from related tasks towards simplifying a target task. Importantly, the main aim in theory works on the subject is to understand the extent to which convergence rates -- in learning a common representation -- \emph{may scale with the number $N$ of tasks} (as well as the number of samples per task). First steps in this setting demonstrate this property when both the shared representation amongst tasks, and task-specific regression functions, are linear. This linear setting readily reveals the benefits of aggregating tasks, e.g., via averaging arguments. In practice, however, the representation is often highly nonlinear, introducing nontrivial biases in each task that cannot easily be averaged out as in the linear case. In the present work, we derive theoretical guarantees for meta-learning with nonlinear representations. In particular, assuming the shared nonl
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;TACO&#26041;&#27861;&#65292;&#19968;&#31181;&#22522;&#20110;&#26102;&#38388;&#28508;&#22312;&#21160;&#20316;&#39537;&#21160;&#23545;&#27604;&#25439;&#22833;&#30340;&#35270;&#35273;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#33021;&#22815;&#21516;&#26102;&#23398;&#20064;&#29366;&#24577;&#34920;&#31034;&#21644;&#21160;&#20316;&#34920;&#31034;&#65292;&#25552;&#39640;&#20195;&#29702;&#23398;&#20064;&#30340;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.13229</link><description>&lt;p&gt;
TACO&#65306;&#22522;&#20110;&#26102;&#38388;&#28508;&#22312;&#21160;&#20316;&#39537;&#21160;&#23545;&#27604;&#25439;&#22833;&#30340;&#35270;&#35273;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
TACO: Temporal Latent Action-Driven Contrastive Loss for Visual Reinforcement Learning. (arXiv:2306.13229v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13229
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;TACO&#26041;&#27861;&#65292;&#19968;&#31181;&#22522;&#20110;&#26102;&#38388;&#28508;&#22312;&#21160;&#20316;&#39537;&#21160;&#23545;&#27604;&#25439;&#22833;&#30340;&#35270;&#35273;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#33021;&#22815;&#21516;&#26102;&#23398;&#20064;&#29366;&#24577;&#34920;&#31034;&#21644;&#21160;&#20316;&#34920;&#31034;&#65292;&#25552;&#39640;&#20195;&#29702;&#23398;&#20064;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22312;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20174;&#21407;&#22987;&#20687;&#32032;&#25968;&#25454;&#20013;&#21462;&#24471;&#20102;&#26368;&#36817;&#30340;&#36827;&#23637;&#65292;&#20294;&#26679;&#26412;&#25928;&#29575;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#38556;&#30861;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#35797;&#22270;&#36890;&#36807;&#21019;&#24314;&#33258;&#30417;&#30563;&#36741;&#21161;&#20219;&#21153;&#26469;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#26088;&#22312;&#20026;&#26410;&#26469;&#29366;&#24577;&#39044;&#27979;&#20016;&#23500;&#20195;&#29702;&#23398;&#20064;&#30340;&#34920;&#31034;&#19982;&#25511;&#21046;&#30456;&#20851;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#30446;&#26631;&#36890;&#24120;&#19981;&#36275;&#20197;&#23398;&#20064;&#33021;&#22815;&#34920;&#31034;&#26368;&#20248;&#31574;&#30053;&#25110;&#20540;&#20989;&#25968;&#30340;&#34920;&#31034;&#65292;&#24182;&#19988;&#23427;&#20204;&#36890;&#24120;&#32771;&#34385;&#20855;&#26377;&#23567;&#30340;&#25277;&#35937;&#31163;&#25955;&#21160;&#20316;&#31354;&#38388;&#30340;&#20219;&#21153;&#65292;&#22240;&#27492;&#24573;&#35270;&#20102;&#22312;&#36830;&#32493;&#25511;&#21046;&#20013;&#21160;&#20316;&#34920;&#31034;&#23398;&#20064;&#30340;&#37325;&#35201;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;TACO&#65306;&#19968;&#31181;&#31616;&#21333;&#32780;&#24378;&#22823;&#30340;&#26102;&#38388;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#65292;&#21033;&#29992;&#23427;&#65292;&#20195;&#29702;&#21487;&#20197;&#21516;&#26102;&#33719;&#24471;&#28508;&#22312;&#29366;&#24577;&#21644;&#21160;&#20316;&#34920;&#31034;&#12290;TACO&#36890;&#36807;&#20248;&#21270;&#37325;&#26032;&#33719;&#24471;&#35266;&#23519;&#19982;&#26368;&#36817;&#30340;&#22810;&#20010;&#20808;&#21069;&#35266;&#23519;&#30340;&#30456;&#20284;&#24615;&#65292;&#21516;&#26102;&#23398;&#20064;&#29366;&#24577;&#19982;&#21160;&#20316;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite recent progress in reinforcement learning (RL) from raw pixel data, sample inefficiency continues to present a substantial obstacle. Prior works have attempted to address this challenge by creating self-supervised auxiliary tasks, aiming to enrich the agent's learned representations with control-relevant information for future state prediction. However, these objectives are often insufficient to learn representations that can represent the optimal policy or value function, and they often consider tasks with small, abstract discrete action spaces and thus overlook the importance of action representation learning in continuous control. In this paper, we introduce TACO: Temporal Action-driven Contrastive Learning, a simple yet powerful temporal contrastive learning approach that facilitates the concurrent acquisition of latent state and action representations for agents. TACO simultaneously learns a state and an action representation by optimizing the mutual information between re
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#27491;&#21017;&#21270;&#40065;&#26834;MDP&#38382;&#39064;&#21644;&#39118;&#38505;&#25935;&#24863;MDP&#38382;&#39064;&#30340;&#30456;&#20851;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#26377;&#25928;&#30340;&#23398;&#20064;&#31639;&#27861;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2306.11626</link><description>&lt;p&gt;
&#27491;&#21017;&#21270;&#40065;&#26834;&#30340;MDPs&#21644;&#39118;&#38505;&#25935;&#24863;&#30340;MDPs&#65306;&#31561;&#20215;&#24615;&#12289;&#31574;&#30053;&#26799;&#24230;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
Regularized Robust MDPs and Risk-Sensitive MDPs: Equivalence, Policy Gradient, and Sample Complexity. (arXiv:2306.11626v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11626
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#27491;&#21017;&#21270;&#40065;&#26834;MDP&#38382;&#39064;&#21644;&#39118;&#38505;&#25935;&#24863;MDP&#38382;&#39064;&#30340;&#30456;&#20851;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#26377;&#25928;&#30340;&#23398;&#20064;&#31639;&#27861;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20851;&#27880;&#20110;&#27491;&#21017;&#21270;&#40065;&#26834;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#38382;&#39064;&#30340;&#24378;&#21270;&#23398;&#20064;&#65292;&#23427;&#26159;&#40065;&#26834;MDP&#26694;&#26550;&#30340;&#19968;&#20010;&#25193;&#23637;&#12290;&#25105;&#20204;&#39318;&#20808;&#20171;&#32461;&#20102;&#39118;&#38505;&#25935;&#24863;MDP&#65292;&#24182;&#24314;&#31435;&#20102;&#39118;&#38505;&#25935;&#24863;MDP&#21644;&#27491;&#21017;&#21270;&#40065;&#26834;MDP&#20043;&#38388;&#30340;&#31561;&#20215;&#24615;&#12290;&#36825;&#31181;&#31561;&#20215;&#24615;&#20026;&#35299;&#20915;&#27491;&#21017;&#21270;RMDP&#25552;&#20379;&#20102;&#21478;&#19968;&#31181;&#35270;&#35282;&#65292;&#24182;&#19988;&#20351;&#24471;&#35774;&#35745;&#39640;&#25928;&#30340;&#23398;&#20064;&#31639;&#27861;&#25104;&#20026;&#21487;&#33021;&#12290;&#22312;&#36825;&#31181;&#31561;&#20215;&#24615;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25512;&#23548;&#20102;&#27491;&#21017;&#21270;&#40065;&#26834;MDP&#38382;&#39064;&#30340;&#31574;&#30053;&#26799;&#24230;&#23450;&#29702;&#65292;&#24182;&#22312;&#20855;&#26377;&#30452;&#25509;&#21442;&#25968;&#21270;&#30340;&#34920;&#26684;&#35774;&#32622;&#19979;&#35777;&#26126;&#20102;&#31934;&#30830;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26679;&#26412;&#30340;&#31163;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#21363;&#40065;&#26834;&#30340;FZI&#36845;&#20195;&#65292;&#29992;&#20110;&#20855;&#26377;KL&#25955;&#24230;&#27491;&#21017;&#21270;&#39033;&#30340;&#29305;&#23450;&#27491;&#21017;&#21270;&#40065;&#26834;MDP&#38382;&#39064;&#65292;&#24182;&#20998;&#26512;&#20102;&#31639;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20063;&#24471;&#21040;&#20102;&#25968;&#20540;&#27169;&#25311;&#30340;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper focuses on reinforcement learning for the regularized robust Markov decision process (MDP) problem, an extension of the robust MDP framework. We first introduce the risk-sensitive MDP and establish the equivalence between risk-sensitive MDP and regularized robust MDP. This equivalence offers an alternative perspective for addressing the regularized RMDP and enables the design of efficient learning algorithms. Given this equivalence, we further derive the policy gradient theorem for the regularized robust MDP problem and prove the global convergence of the exact policy gradient method under the tabular setting with direct parameterization. We also propose a sample-based offline learning algorithm, namely the robust fitted-Z iteration (RFZI), for a specific regularized robust MDP problem with a KL-divergence regularization term and analyze the sample complexity of the algorithm. Our results are also supported by numerical simulations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;GromovMatcher&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#26368;&#20248;&#36755;&#36816;&#33258;&#21160;&#21512;&#24182;LC-MS&#25968;&#25454;&#38598;&#65292;&#21487;&#25552;&#39640;&#25968;&#25454;&#23545;&#40784;&#30340;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#65292;&#26377;&#25928;&#35299;&#20915;&#20195;&#35874;&#32452;&#23398;&#25968;&#25454;&#21512;&#24182;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2306.03218</link><description>&lt;p&gt;
&#29992;&#20110;&#26080;&#30446;&#26631;&#20195;&#35874;&#32452;&#23398;&#25968;&#25454;&#33258;&#21160;&#23545;&#40784;&#30340;&#26368;&#20248;&#36755;&#36816;
&lt;/p&gt;
&lt;p&gt;
Optimal transport for automatic alignment of untargeted metabolomic data. (arXiv:2306.03218v1 [q-bio.QM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03218
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;GromovMatcher&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#26368;&#20248;&#36755;&#36816;&#33258;&#21160;&#21512;&#24182;LC-MS&#25968;&#25454;&#38598;&#65292;&#21487;&#25552;&#39640;&#25968;&#25454;&#23545;&#40784;&#30340;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#65292;&#26377;&#25928;&#35299;&#20915;&#20195;&#35874;&#32452;&#23398;&#25968;&#25454;&#21512;&#24182;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28082;&#30456;&#33394;&#35889;-&#36136;&#35889;&#65288;LC-MS&#65289;&#36890;&#36807;&#27979;&#37327;&#29983;&#29289;&#26631;&#26412;&#20013;&#30340;&#22823;&#37327;&#20195;&#35874;&#29289;&#25512;&#21160;&#33647;&#29289;&#30740;&#21457;&#65292;&#30142;&#30149;&#35786;&#26029;&#21644;&#39118;&#38505;&#39044;&#27979;&#30340;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;LC-MS&#30340;&#20302;&#36890;&#37327;&#23545;&#20110;&#29983;&#29289;&#26631;&#35760;&#29289;&#21457;&#29616;&#65292;&#27880;&#37322;&#21644;&#23454;&#39564;&#27604;&#36739;&#26500;&#25104;&#20102;&#20027;&#35201;&#25361;&#25112;&#65292;&#38656;&#35201;&#21512;&#24182;&#22810;&#20010;&#25968;&#25454;&#38598;&#12290;&#24403;&#21069;&#30340;&#25968;&#25454;&#27744;&#21270;&#26041;&#27861;&#30001;&#20110;&#23545;&#25968;&#25454;&#21464;&#21270;&#21644;&#36229;&#21442;&#25968;&#20381;&#36182;&#24615;&#30340;&#33030;&#24369;&#24615;&#32780;&#36935;&#21040;&#23454;&#38469;&#38480;&#21046;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;GromovMatcher&#65292;&#19968;&#31181;&#28789;&#27963;&#19988;&#29992;&#25143;&#21451;&#22909;&#30340;&#31639;&#27861;&#65292;&#20351;&#29992;&#26368;&#20248;&#36755;&#36816;&#33258;&#21160;&#32467;&#21512;LC-MS&#25968;&#25454;&#38598;&#12290;&#36890;&#36807;&#21033;&#29992;&#29305;&#24449;&#24378;&#24230;&#30456;&#20851;&#32467;&#26500;&#65292;GromovMatcher&#25552;&#20379;&#20102;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#39640;&#30340;&#23545;&#40784;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;&#35813;&#31639;&#27861;&#21487;&#25193;&#23637;&#21040;&#38656;&#35201;&#26368;&#23567;&#36229;&#21442;&#25968;&#35843;&#25972;&#30340;&#25968;&#21315;&#20010;&#29305;&#24449;&#12290;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#32925;&#30284;&#21644;&#33008;&#33146;&#30284;&#30340;&#23454;&#39564;&#24739;&#32773;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Untargeted metabolomic profiling through liquid chromatography-mass spectrometry (LC-MS) measures a vast array of metabolites within biospecimens, advancing drug development, disease diagnosis, and risk prediction. However, the low throughput of LC-MS poses a major challenge for biomarker discovery, annotation, and experimental comparison, necessitating the merging of multiple datasets. Current data pooling methods encounter practical limitations due to their vulnerability to data variations and hyperparameter dependence. Here we introduce GromovMatcher, a flexible and user-friendly algorithm that automatically combines LC-MS datasets using optimal transport. By capitalizing on feature intensity correlation structures, GromovMatcher delivers superior alignment accuracy and robustness compared to existing approaches. This algorithm scales to thousands of features requiring minimal hyperparameter tuning. Applying our method to experimental patient studies of liver and pancreatic cancer, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;$p$-NormSoftmax&#30340;&#20107;&#21518;&#32622;&#20449;&#24230;&#20272;&#35745;&#22120;&#26469;&#25552;&#39640;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#36873;&#25321;&#20998;&#31867;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.15508</link><description>&lt;p&gt;
&#36890;&#36807;&#20107;&#21518;&#23545;&#25968;&#24402;&#19968;&#21270;&#21644;&#28201;&#24230;&#32553;&#25918;&#25913;&#21892;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#36873;&#25321;&#20998;&#31867;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
Improving selective classification performance of deep neural networks through post-hoc logit normalization and temperature scaling. (arXiv:2305.15508v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15508
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;$p$-NormSoftmax&#30340;&#20107;&#21518;&#32622;&#20449;&#24230;&#20272;&#35745;&#22120;&#26469;&#25552;&#39640;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#36873;&#25321;&#20998;&#31867;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#36873;&#25321;&#20998;&#31867;&#38382;&#39064;&#65292;&#20854;&#20013;&#27169;&#22411;&#21487;&#20197;&#36991;&#20813;&#28508;&#22312;&#38169;&#35823;&#36890;&#36807;&#25918;&#24323;&#20302;&#32622;&#20449;&#24230;&#30340;&#39044;&#27979;&#12290;&#25105;&#20204;&#38024;&#23545;&#30340;&#26159;&#20248;&#21270;&#22266;&#23450;&#20998;&#31867;&#22120;&#30340;&#32622;&#20449;&#24230;&#20272;&#35745;&#22120;&#65292;&#26088;&#22312;&#22686;&#24378;&#20854;&#35823;&#20998;&#31867;&#26816;&#27979;&#24615;&#33021;&#65292;&#21363;&#36890;&#36807;&#23558;&#26356;&#39640;&#30340;&#32622;&#20449;&#24230;&#20540;&#20998;&#37197;&#32473;&#27491;&#30830;&#30340;&#39044;&#27979;&#26469;&#21306;&#20998;&#27491;&#30830;&#21644;&#19981;&#27491;&#30830;&#30340;&#39044;&#27979;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#26377;&#25928;&#30340;&#20107;&#21518;&#32622;&#20449;&#24230;&#20272;&#35745;&#22120;$p$-NormSoftmax&#65292;&#36890;&#36807;&#23545;&#25968;&#36827;&#34892;$p$-&#33539;&#25968;&#24402;&#19968;&#21270;&#21644;&#28201;&#24230;&#32553;&#25918;&#24471;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper addresses the problem of selective classification for deep neural networks, where a model is allowed to abstain from low-confidence predictions to avoid potential errors. Specifically, we tackle the problem of optimizing the confidence estimator of a fixed classifier, aiming to enhance its misclassification detection performance, i.e., its ability to discriminate between correct and incorrect predictions by assigning higher confidence values to the correct ones. Previous work has found that different classifiers exhibit varying levels of misclassification detection performance, particularly when using the maximum softmax probability (MSP) as a measure of confidence. However, we argue that these findings are mainly due to a sub-optimal confidence estimator being used for each model. To overcome this issue, we propose a simple and efficient post-hoc confidence estimator, named $p$-NormSoftmax, which consists of transforming the logits through $p$-norm normalization and tempera
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20195;&#20215;&#24863;&#30693;&#30340;&#27169;&#22411;&#36873;&#25321;BO&#26041;&#27861;SADCBO&#65292;&#36890;&#36807;&#23545;&#21518;&#39564;&#20195;&#29702;&#27169;&#22411;&#30340;&#25935;&#24863;&#24615;&#20998;&#26512;&#26469;&#23398;&#20064;&#20851;&#20110;&#29615;&#22659;&#30340;&#30456;&#20851;&#24773;&#22659;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#24179;&#22343;&#27169;&#22411;&#39044;&#27979;&#26469;&#26368;&#23567;&#21270;&#20248;&#21270;&#20195;&#20215;&#65292;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.14120</link><description>&lt;p&gt;
&#22522;&#20110;&#20195;&#20215;&#24863;&#30693;&#30340;&#24773;&#22659;&#21464;&#37327;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Cost-aware learning of relevant contextual variables within Bayesian optimization. (arXiv:2305.14120v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14120
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20195;&#20215;&#24863;&#30693;&#30340;&#27169;&#22411;&#36873;&#25321;BO&#26041;&#27861;SADCBO&#65292;&#36890;&#36807;&#23545;&#21518;&#39564;&#20195;&#29702;&#27169;&#22411;&#30340;&#25935;&#24863;&#24615;&#20998;&#26512;&#26469;&#23398;&#20064;&#20851;&#20110;&#29615;&#22659;&#30340;&#30456;&#20851;&#24773;&#22659;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#24179;&#22343;&#27169;&#22411;&#39044;&#27979;&#26469;&#26368;&#23567;&#21270;&#20248;&#21270;&#20195;&#20215;&#65292;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24773;&#22659;&#36125;&#21494;&#26031;&#20248;&#21270;(CBO)&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#26694;&#26550;&#65292;&#21487;&#38024;&#23545;&#35774;&#35745;&#21464;&#37327;&#20248;&#21270;&#40657;&#30418;&#26114;&#36149;&#30340;&#35780;&#20272;&#20989;&#25968;&#65292;&#24182;&#21516;&#26102;&#26377;&#25928;&#22320;&#25972;&#21512;&#20851;&#20110;&#29615;&#22659;&#30340;&#30456;&#20851;&#24773;&#22659;&#20449;&#24687;&#65292;&#22914;&#23454;&#39564;&#26465;&#20214;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#23454;&#38469;&#22330;&#26223;&#20013;&#65292;&#24773;&#22659;&#21464;&#37327;&#30340;&#30456;&#20851;&#24615;&#19981;&#19968;&#23450;&#26159;&#39044;&#20808;&#24050;&#30693;&#30340;&#12290;&#27492;&#22806;&#65292;&#26377;&#26102;&#36824;&#21487;&#20197;&#26368;&#20248;&#21270;&#24773;&#22659;&#21464;&#37327;&#26412;&#36523;&#65292;&#36825;&#26159;&#24403;&#21069;CBO&#31639;&#27861;&#26410;&#32771;&#34385;&#30340;&#35774;&#32622;&#12290;&#20248;&#21270;&#24773;&#22659;&#21464;&#37327;&#21487;&#33021;&#26159;&#26114;&#36149;&#30340;&#65292;&#36825;&#24341;&#20986;&#20102;&#30830;&#23450;&#19968;&#20010;&#26368;&#23567;&#30456;&#20851;&#23376;&#38598;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#38382;&#39064;&#20316;&#20026;&#19968;&#20010;&#20195;&#20215;&#24863;&#30693;&#30340;&#27169;&#22411;&#36873;&#25321;BO&#20219;&#21153;&#26469;&#26500;&#26550;&#65292;&#37319;&#29992;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21363;&#22522;&#20110;&#25935;&#24863;&#24615;&#20998;&#26512;&#30340;&#24773;&#22659;BO (SADCBO) &#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#29305;&#23450;&#36755;&#20837;&#28857;&#21518;&#39564;&#20195;&#29702;&#27169;&#22411;&#30340;&#25935;&#24863;&#24615;&#20998;&#26512;&#26469;&#23398;&#20064;&#24773;&#22659;&#21464;&#37327;&#30340;&#30456;&#20851;&#24615;&#65292;&#21516;&#26102;&#36890;&#36807;&#24179;&#22343;&#27169;&#22411;&#39044;&#27979;&#26469;&#26368;&#23567;&#21270;&#20248;&#21270;&#30340;&#20195;&#20215;&#12290;SADCBO&#22312;&#22810;&#20010;&#21512;&#25104;&#21644;&#30495;&#23454;&#22522;&#20934;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#65292;&#26174;&#31034;&#20986;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Contextual Bayesian Optimization (CBO) is a powerful framework for optimizing black-box, expensive-to-evaluate functions with respect to design variables, while simultaneously efficiently integrating relevant contextual information regarding the environment, such as experimental conditions. However, in many practical scenarios, the relevance of contextual variables is not necessarily known beforehand. Moreover, the contextual variables can sometimes be optimized themselves, a setting that current CBO algorithms do not take into account. Optimizing contextual variables may be costly, which raises the question of determining a minimal relevant subset. In this paper, we frame this problem as a cost-aware model selection BO task and address it using a novel method, Sensitivity-Analysis-Driven Contextual BO (SADCBO). We learn the relevance of context variables by sensitivity analysis of the posterior surrogate model at specific input points, whilst minimizing the cost of optimization by lev
&lt;/p&gt;</description></item><item><title>Reprompting&#26159;&#19968;&#31181;&#26080;&#38656;&#20154;&#31867;&#24178;&#39044;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#36845;&#20195;&#37319;&#26679;&#26032;&#37197;&#26041;&#35299;&#20915;&#22810;&#27493;&#25512;&#29702;&#20219;&#21153;&#65292;&#27604;&#20154;&#31867;&#32534;&#20889;&#30340;&#24605;&#32500;&#38142;&#25552;&#31034;&#34920;&#29616;&#26356;&#22909;&#65292;&#36824;&#21487;&#20197;&#25552;&#39640;&#36739;&#24369;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.09993</link><description>&lt;p&gt;
Reprompting: &#36890;&#36807;&#21513;&#24067;&#26031;&#37319;&#26679;&#33258;&#21160;&#25512;&#26029;&#24605;&#32500;&#38142;&#30340;&#25552;&#31034;
&lt;/p&gt;
&lt;p&gt;
Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling. (arXiv:2305.09993v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09993
&lt;/p&gt;
&lt;p&gt;
Reprompting&#26159;&#19968;&#31181;&#26080;&#38656;&#20154;&#31867;&#24178;&#39044;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#36845;&#20195;&#37319;&#26679;&#26032;&#37197;&#26041;&#35299;&#20915;&#22810;&#27493;&#25512;&#29702;&#20219;&#21153;&#65292;&#27604;&#20154;&#31867;&#32534;&#20889;&#30340;&#24605;&#32500;&#38142;&#25552;&#31034;&#34920;&#29616;&#26356;&#22909;&#65292;&#36824;&#21487;&#20197;&#25552;&#39640;&#36739;&#24369;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;Reprompting&#65292;&#36825;&#26159;&#19968;&#31181;&#36845;&#20195;&#37319;&#26679;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#27809;&#26377;&#20154;&#31867;&#24178;&#39044;&#30340;&#24773;&#20917;&#19979;&#25628;&#32034;&#32473;&#23450;&#20219;&#21153;&#30340;&#24605;&#32500;&#38142;&#37197;&#26041;&#12290;&#36890;&#36807;&#21513;&#24067;&#26031;&#37319;&#26679;&#65292;&#25105;&#20204;&#25512;&#26029;&#36866;&#29992;&#20110;&#19968;&#32452;&#35757;&#32451;&#26679;&#20363;&#30340;&#24605;&#32500;&#38142;&#37197;&#26041;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#29992;&#20808;&#21069;&#37319;&#26679;&#30340;&#35299;&#20316;&#20026;&#29238;&#25552;&#31034;&#65292;&#36845;&#20195;&#22320;&#37319;&#26679;&#26032;&#30340;&#37197;&#26041;&#26469;&#35299;&#20915;&#20854;&#20182;&#35757;&#32451;&#38382;&#39064;&#12290;&#22312;&#38656;&#35201;&#22810;&#27493;&#25512;&#29702;&#30340;&#20116;&#20010;Big-Bench Hard&#20219;&#21153;&#20013;&#65292;Reprompting&#30340;&#34920;&#29616;&#22987;&#32456;&#20248;&#20110;&#38646;&#26679;&#26412;&#12289;&#23569;&#26679;&#26412;&#21644;&#20154;&#31867;&#32534;&#20889;&#30340;&#24605;&#32500;&#38142;&#22522;&#32447;&#12290;Reprompting&#36824;&#21487;&#20197;&#20419;&#36827;&#30693;&#35782;&#20174;&#19968;&#20010;&#26356;&#24378;&#30340;&#27169;&#22411;&#21040;&#19968;&#20010;&#36739;&#24369;&#30340;&#27169;&#22411;&#30340;&#36716;&#31227;&#65292;&#20174;&#32780;&#22823;&#22823;&#25552;&#39640;&#20102;&#36739;&#24369;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;Reprompting&#30456;&#23545;&#20110;&#20351;&#29992;&#20154;&#31867;&#32534;&#20889;&#30340;&#24605;&#32500;&#38142;&#25552;&#31034;&#30340;&#20808;&#21069;&#26368;&#20808;&#36827;&#26041;&#27861;&#65292;&#24102;&#26469;&#20102;&#39640;&#36798;+17&#20010;&#24615;&#33021;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce Reprompting, an iterative sampling algorithm that searches for the Chain-of-Thought (CoT) recipes for a given task without human intervention. Through Gibbs sampling, we infer CoT recipes that work consistently well for a set of training samples. Our method iteratively samples new recipes using previously sampled solutions as parent prompts to solve other training problems. On five Big-Bench Hard tasks that require multi-step reasoning, Reprompting achieves consistently better performance than the zero-shot, few-shot, and human-written CoT baselines. Reprompting can also facilitate transfer of knowledge from a stronger model to a weaker model leading to substantially improved performance of the weaker model. Overall, Reprompting brings up to +17 point improvements over the previous state-of-the-art method that uses human-written CoT prompts.
&lt;/p&gt;</description></item><item><title>&#31070;&#32463;&#32593;&#32476;&#30340;&#31232;&#30095;&#24615;&#33021;&#25552;&#39640;&#38544;&#31169;&#24615;&#24182;&#20445;&#25345;&#24615;&#33021;&#34920;&#29616;</title><link>http://arxiv.org/abs/2304.07234</link><description>&lt;p&gt;
&#31232;&#30095;&#24615;&#21487;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#30340;&#38544;&#31169;&#24615;
&lt;/p&gt;
&lt;p&gt;
Sparsity in neural networks can increase their privacy. (arXiv:2304.07234v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07234
&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#30340;&#31232;&#30095;&#24615;&#33021;&#25552;&#39640;&#38544;&#31169;&#24615;&#24182;&#20445;&#25345;&#24615;&#33021;&#34920;&#29616;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31232;&#30095;&#24615;&#22914;&#20309;&#20351;&#31070;&#32463;&#32593;&#32476;&#23545;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#26356;&#21152;&#40065;&#26834;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#31232;&#30095;&#24615;&#33021;&#22815;&#25552;&#39640;&#32593;&#32476;&#30340;&#38544;&#31169;&#24615;&#65292;&#21516;&#26102;&#20445;&#25345;&#30456;&#24212;&#20219;&#21153;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;&#36825;&#39033;&#23454;&#35777;&#30740;&#31350;&#23436;&#21892;&#20102;&#24182;&#25193;&#23637;&#20102;&#29616;&#26377;&#25991;&#29486;&#30340;&#20869;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article measures how sparsity can make neural networks more robust to membership inference attacks. The obtained empirical results show that sparsity improves the privacy of the network, while preserving comparable performances on the task at hand. This empirical study completes and extends existing literature.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19968;&#38454;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#38543;&#26426;&#31639;&#23376;&#21644;/&#25110;&#38543;&#26426;&#32422;&#26463;&#30340;&#24102;&#20989;&#25968;&#32422;&#26463;&#30340;&#21464;&#20998;&#19981;&#31561;&#24335;&#38382;&#39064;&#65292;&#24403;FCVI&#38382;&#39064;&#26159;&#30830;&#23450;&#24615;&#38750;&#20809;&#28369;&#30340;&#25110;&#38543;&#26426;&#30340;&#26102;&#65292;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#26368;&#20248;&#31639;&#23376;&#25110;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.04778</link><description>&lt;p&gt;
&#24102;&#20989;&#25968;&#32422;&#26463;&#30340;&#38543;&#26426;&#21464;&#20998;&#19981;&#31561;&#24335;&#38382;&#39064;&#30340;&#19968;&#38454;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
First-order methods for Stochastic Variational Inequality problems with Function Constraints. (arXiv:2304.04778v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04778
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19968;&#38454;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#38543;&#26426;&#31639;&#23376;&#21644;/&#25110;&#38543;&#26426;&#32422;&#26463;&#30340;&#24102;&#20989;&#25968;&#32422;&#26463;&#30340;&#21464;&#20998;&#19981;&#31561;&#24335;&#38382;&#39064;&#65292;&#24403;FCVI&#38382;&#39064;&#26159;&#30830;&#23450;&#24615;&#38750;&#20809;&#28369;&#30340;&#25110;&#38543;&#26426;&#30340;&#26102;&#65292;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#26368;&#20248;&#31639;&#23376;&#25110;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#21333;&#35843;&#21464;&#20998;&#19981;&#31561;&#24335;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#38382;&#39064;&#12290;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#21464;&#20998;&#19981;&#31561;&#24335;&#38382;&#39064;&#20276;&#38543;&#30528;&#21487;&#33021;&#26159;&#25968;&#25454;&#39537;&#21160;&#30340;&#20989;&#25968;&#32422;&#26463;&#65292;&#36825;&#20351;&#24471;&#25237;&#24433;&#31639;&#23376;&#30340;&#35745;&#31639;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#38024;&#23545;&#21508;&#31181;&#24773;&#20917;&#19979;&#30340;&#24102;&#20989;&#25968;&#32422;&#26463;&#30340;&#21464;&#20998;&#19981;&#31561;&#24335;&#38382;&#39064;&#65292;&#21253;&#25324;&#20855;&#26377;&#38543;&#26426;&#31639;&#23376;&#21644;/&#25110;&#38543;&#26426;&#32422;&#26463;&#30340;&#20809;&#28369;&#25110;&#38750;&#20809;&#28369;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#19968;&#38454;&#26041;&#27861;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;{\texttt{OpConEx}}&#26041;&#27861;&#21450;&#20854;&#38543;&#26426;&#21464;&#20307;&#65292;&#23427;&#20204;&#37319;&#29992;&#31639;&#23376;&#21644;&#38480;&#21046;&#35780;&#20272;&#30340;&#22806;&#25512;&#26469;&#26356;&#26032;&#21464;&#37327;&#21644;Lagrangian&#20056;&#25968;&#12290;&#24403;FCVI&#38382;&#39064;&#26159;&#30830;&#23450;&#24615;&#38750;&#20809;&#28369;&#30340;&#25110;&#38543;&#26426;&#30340;&#65288;&#21253;&#25324;&#20809;&#28369;&#25110;&#38750;&#20809;&#28369;&#30340;&#38543;&#26426;&#32422;&#26463;&#65289;&#26102;&#65292;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#26368;&#20248;&#31639;&#23376;&#25110;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#26159;&#31616;&#21333;&#30340;&#21333;&#24490;&#29615;&#31243;&#24207;&#65292;&#19981;&#38656;&#35201;&#30693;&#36947;&#25289;&#26684;&#26391;&#26085;&#20056;&#25968;&#23601;&#21487;&#20197;&#36798;&#21040;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The monotone Variational Inequality (VI) is an important problem in machine learning. In numerous instances, the VI problems are accompanied by function constraints which can possibly be data-driven, making the projection operator challenging to compute. In this paper, we present novel first-order methods for function constrained VI (FCVI) problem under various settings, including smooth or nonsmooth problems with a stochastic operator and/or stochastic constraints. First, we introduce the~{\texttt{OpConEx}} method and its stochastic variants, which employ extrapolation of the operator and constraint evaluations to update the variables and the Lagrangian multipliers. These methods achieve optimal operator or sample complexities when the FCVI problem is either (i) deterministic nonsmooth, or (ii) stochastic, including smooth or nonsmooth stochastic constraints. Notably, our algorithms are simple single-loop procedures and do not require the knowledge of Lagrange multipliers to attain th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#23618;&#36125;&#21494;&#26031;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#22810;&#20010;&#27979;&#37327;&#21521;&#37327;&#20013;&#25512;&#26029;&#32852;&#21512;&#31232;&#30095;&#30340;&#21442;&#25968;&#21521;&#37327;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#20849;&#21516;&#30340;&#20285;&#39532;&#20998;&#24067;&#36229;&#21442;&#25968;&#26469;&#24378;&#21046;&#32852;&#21512;&#31232;&#30095;&#24615;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2303.16954</link><description>&lt;p&gt;
&#21033;&#29992;&#32852;&#21512;&#31232;&#30095;&#24615;&#30340;&#20998;&#23618;&#36125;&#21494;&#26031;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Leveraging joint sparsity in hierarchical Bayesian learning. (arXiv:2303.16954v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16954
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#23618;&#36125;&#21494;&#26031;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#22810;&#20010;&#27979;&#37327;&#21521;&#37327;&#20013;&#25512;&#26029;&#32852;&#21512;&#31232;&#30095;&#30340;&#21442;&#25968;&#21521;&#37327;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#20849;&#21516;&#30340;&#20285;&#39532;&#20998;&#24067;&#36229;&#21442;&#25968;&#26469;&#24378;&#21046;&#32852;&#21512;&#31232;&#30095;&#24615;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#23618;&#36125;&#21494;&#26031;&#23398;&#20064;&#26041;&#27861;&#65292;&#20174;&#22810;&#20010;&#27979;&#37327;&#21521;&#37327;&#20013;&#25512;&#26029;&#32852;&#21512;&#31232;&#30095;&#30340;&#21442;&#25968;&#21521;&#37327;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#20026;&#27599;&#20010;&#21442;&#25968;&#21521;&#37327;&#20351;&#29992;&#21333;&#29420;&#30340;&#26465;&#20214;&#39640;&#26031;&#20808;&#39564;&#65292;&#24182;&#20351;&#29992;&#20849;&#21516;&#30340;&#20285;&#39532;&#20998;&#24067;&#36229;&#21442;&#25968;&#26469;&#24378;&#21046;&#32852;&#21512;&#31232;&#30095;&#24615;&#12290;&#24471;&#21040;&#30340;&#32852;&#21512;&#31232;&#30095;&#24615;&#20808;&#39564;&#19982;&#29616;&#26377;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#24418;&#25104;&#20102;&#19968;&#31995;&#21015;&#26032;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#25968;&#20540;&#23454;&#39564;&#65292;&#21253;&#25324;&#22810;&#32447;&#22280;&#30913;&#20849;&#25391;&#25104;&#20687;&#24212;&#29992;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26032;&#26041;&#27861;&#22987;&#32456;&#20248;&#20110;&#24120;&#29992;&#30340;&#20998;&#23618;&#36125;&#21494;&#26031;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a hierarchical Bayesian learning approach to infer jointly sparse parameter vectors from multiple measurement vectors. Our model uses separate conditionally Gaussian priors for each parameter vector and common gamma-distributed hyper-parameters to enforce joint sparsity. The resulting joint-sparsity-promoting priors are combined with existing Bayesian inference methods to generate a new family of algorithms. Our numerical experiments, which include a multi-coil magnetic resonance imaging application, demonstrate that our new approach consistently outperforms commonly used hierarchical Bayesian methods.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23567;&#27874;&#25955;&#23556;&#21464;&#25442;&#21644;1D-CNN&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#32467;&#21512;&#30340;&#24515;&#26434;&#38899;&#33258;&#21160;&#26816;&#27979;&#26041;&#27861;&#65292;&#21487;&#23454;&#29616;97.98%&#30340;&#39640;&#20934;&#30830;&#29575;&#12290;</title><link>http://arxiv.org/abs/2303.11423</link><description>&lt;p&gt;
&#21033;&#29992;&#23567;&#27874;&#25955;&#23556;&#21464;&#25442;&#21644;1D-CNN&#36827;&#34892;&#21548;&#35786;&#22120;&#24515;&#26434;&#38899;&#21644;&#24322;&#24120;PCG&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Heart Murmur and Abnormal PCG Detection via Wavelet Scattering Transform &amp; a 1D-CNN. (arXiv:2303.11423v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11423
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23567;&#27874;&#25955;&#23556;&#21464;&#25442;&#21644;1D-CNN&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#32467;&#21512;&#30340;&#24515;&#26434;&#38899;&#33258;&#21160;&#26816;&#27979;&#26041;&#27861;&#65292;&#21487;&#23454;&#29616;97.98%&#30340;&#39640;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#39033;&#30740;&#31350;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#23545;&#21548;&#35786;&#22120;&#24515;&#26434;&#38899;&#30340;&#33258;&#21160;&#21644;&#20934;&#30830;&#26816;&#27979;&#65292;&#24182;&#20351;&#29992;&#20004;&#20010;&#20844;&#20849;PCG&#25968;&#25454;&#38598;&#65288;CirCor Digiscope 2022&#21644;PCG 2016&#25968;&#25454;&#38598;&#65289;&#36827;&#34892;&#35757;&#32451;&#21644;&#27979;&#35797;&#19977;&#20010;&#33258;&#23450;&#20041;&#31070;&#32463;&#32593;&#32476;&#65306;&#19968;&#32500;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#65292;&#38271;&#30701;&#26399;&#35760;&#24518;&#65288;LSTM&#65289;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#65288;RNN&#65289;&#21644;&#21367;&#31215;RNN&#65288;C-RNN&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work leverages deep learning (DL) techniques in order to do automatic and accurate heart murmur detection from phonocardiogram (PCG) recordings. Two public PCG datasets (CirCor Digiscope 2022 dataset and PCG 2016 dataset) from Physionet online database are utilized to train and test three custom neural networks (NN): a 1D convolutional neural network (CNN), a long short-term memory (LSTM) recurrent neural network (RNN), and a convolutional RNN (C-RNN). Under our proposed method, we first do pre-processing on both datasets in order to prepare the data for the NNs. Key pre-processing steps include the following: denoising, segmentation, re-labeling of noise-only segments, data normalization, and time-frequency analysis of the PCG segments using wavelet scattering transform. To evaluate the performance of the three NNs we have implemented, we conduct four experiments, first three using PCG 2022 dataset, and fourth using PCG 2016 dataset. It turns out that our custom 1D-CNN outperform
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#36890;&#36807;&#27169;&#22411;&#36873;&#25321;&#21644;&#20132;&#21449;&#39564;&#35777;&#39118;&#38505;&#20272;&#35745;&#26469;&#23398;&#20064;&#30340;&#19968;&#33324;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#26080;&#20998;&#24067;&#20559;&#24046;&#30028;&#65292;&#27604;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#26041;&#27861;&#26356;&#32039;&#23494;&#65292;&#22312;&#19968;&#20123;&#24773;&#20917;&#19979;&#34920;&#29616;&#26356;&#20248;&#12290;</title><link>http://arxiv.org/abs/2303.08777</link><description>&lt;p&gt;
&#27169;&#22411;&#36873;&#25321;&#37197;&#21512;&#20132;&#21449;&#39564;&#35777;&#39118;&#38505;&#20272;&#35745;&#30340;&#26080;&#20998;&#24067;&#20559;&#24046;&#30028;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Distribution-free Deviation Bounds of Learning via Model Selection with Cross-validation Risk Estimation. (arXiv:2303.08777v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08777
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#36890;&#36807;&#27169;&#22411;&#36873;&#25321;&#21644;&#20132;&#21449;&#39564;&#35777;&#39118;&#38505;&#20272;&#35745;&#26469;&#23398;&#20064;&#30340;&#19968;&#33324;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#26080;&#20998;&#24067;&#20559;&#24046;&#30028;&#65292;&#27604;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#26041;&#27861;&#26356;&#32039;&#23494;&#65292;&#22312;&#19968;&#20123;&#24773;&#20917;&#19979;&#34920;&#29616;&#26356;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20132;&#21449;&#39564;&#35777;&#26041;&#27861;&#30340;&#39118;&#38505;&#20272;&#35745;&#21644;&#27169;&#22411;&#36873;&#25321;&#22312;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#24471;&#21040;&#20102;&#24191;&#27867;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#23398;&#20064;&#36890;&#36807;&#27169;&#22411;&#36873;&#25321;&#19982;&#20132;&#21449;&#39564;&#35777;&#39118;&#38505;&#20272;&#35745;&#30340;&#29702;&#35770;&#24615;&#36136;&#30340;&#29702;&#35299;&#22312;&#20854;&#24191;&#27867;&#20351;&#29992;&#38754;&#21069;&#30456;&#24403;&#32570;&#20047;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#26412;&#25991;&#23558;&#23398;&#20064;&#36890;&#36807;&#27169;&#22411;&#36873;&#25321;&#19982;&#20132;&#21449;&#39564;&#35777;&#39118;&#38505;&#20272;&#35745;&#20316;&#20026;&#19968;&#31181;&#32463;&#20856;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#19968;&#33324;&#31995;&#32479;&#23398;&#20064;&#26694;&#26550;&#65292;&#24182;&#24314;&#31435;&#20102;&#22522;&#20110;VC&#32500;&#30340;&#26080;&#20998;&#24067;&#20559;&#24046;&#36793;&#30028;&#65292;&#32473;&#20986;&#20102;&#32467;&#26524;&#30340;&#35814;&#32454;&#35777;&#26126;&#65292;&#24182;&#32771;&#34385;&#20102;&#26377;&#30028;&#21644;&#26080;&#30028;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;&#25105;&#20204;&#36824;&#25512;&#23548;&#20986;&#22312;&#25972;&#20010;&#20551;&#35774;&#31354;&#38388;&#20013;&#65292;&#23398;&#20064;&#36890;&#36807;&#27169;&#22411;&#36873;&#25321;&#30340;&#20559;&#24046;&#30028;&#27604;&#36890;&#36807;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#23398;&#20064;&#30340;&#20559;&#24046;&#30028;&#26356;&#32039;&#23494;&#30340;&#26465;&#20214;&#65292;&#25903;&#25345;&#22312;&#19968;&#20123;&#24773;&#20917;&#19979;&#32463;&#39564;&#19978;&#35266;&#23519;&#21040;&#30340;&#27169;&#22411;&#36873;&#25321;&#26694;&#26550;&#30340;&#26356;&#22909;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cross-validation techniques for risk estimation and model selection are widely used in statistics and machine learning. However, the understanding of the theoretical properties of learning via model selection with cross-validation risk estimation is quite low in face of its widespread use. In this context, this paper presents learning via model selection with cross-validation risk estimation as a general systematic learning framework within classical statistical learning theory and establishes distribution-free deviation bounds in terms of VC dimension, giving detailed proofs of the results and considering both bounded and unbounded loss functions. We also deduce conditions under which the deviation bounds of learning via model selection are tighter than that of learning via empirical risk minimization in the whole hypotheses space, supporting the better performance of model selection frameworks observed empirically in some instances.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31070;&#32463;&#26041;&#27861;&#26469;&#35745;&#31639;&#37096;&#20998;&#26368;&#20248;&#36755;&#36816;&#26144;&#23556;&#65292;&#24182;&#22312;&#21512;&#25104;&#20363;&#23376;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;</title><link>http://arxiv.org/abs/2303.07988</link><description>&lt;p&gt;
&#37096;&#20998;&#31070;&#32463;&#26368;&#20248;&#36755;&#36816;
&lt;/p&gt;
&lt;p&gt;
Partial Neural Optimal Transport. (arXiv:2303.07988v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.07988
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31070;&#32463;&#26041;&#27861;&#26469;&#35745;&#31639;&#37096;&#20998;&#26368;&#20248;&#36755;&#36816;&#26144;&#23556;&#65292;&#24182;&#22312;&#21512;&#25104;&#20363;&#23376;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31070;&#32463;&#26041;&#27861;&#26469;&#35745;&#31639;&#37096;&#20998;&#26368;&#20248;&#36755;&#36816;&#65288;OT&#65289;&#26144;&#23556;&#65292;&#21363;&#25351;&#23450;&#36136;&#37327;&#30340;&#24230;&#37327;&#37096;&#20998;&#20043;&#38388;&#30340;OT&#26144;&#23556;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#20363;&#23376;&#19978;&#27979;&#35797;&#20102;&#25105;&#20204;&#30340;&#37096;&#20998;&#31070;&#32463;&#26368;&#20248;&#36755;&#36816;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel neural method to compute partial optimal transport (OT) maps, i.e., OT maps between parts of measures of the specified masses. We test our partial neural optimal transport algorithm on synthetic examples.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;Thompson-CHM&#30340;&#28176;&#36817;&#26368;&#20248;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20984;&#21253;&#25104;&#21592;&#38382;&#39064;&#65292;&#19988;&#23558;&#31639;&#27861;&#25193;&#23637;&#21040;&#20102;&#19968;&#32500;&#21644;&#22810;&#32500;&#29615;&#22659;&#20013;&#12290;&#35813;&#31639;&#27861;&#22522;&#20110;&#27169;&#22359;&#21270;&#35774;&#35745;&#65292;&#21253;&#25324;&#20572;&#27490;&#35268;&#21017;&#21644;&#37319;&#26679;&#35268;&#21017;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#29702;&#35770;&#32467;&#26524;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.02033</link><description>&lt;p&gt;
&#19968;&#20010;&#28176;&#36817;&#26368;&#20248;&#30340;&#20984;&#21253;&#25104;&#21592;&#38382;&#39064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Asymptotically Optimal Algorithm for the Convex Hull Membership Problem. (arXiv:2302.02033v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.02033
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;Thompson-CHM&#30340;&#28176;&#36817;&#26368;&#20248;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20984;&#21253;&#25104;&#21592;&#38382;&#39064;&#65292;&#19988;&#23558;&#31639;&#27861;&#25193;&#23637;&#21040;&#20102;&#19968;&#32500;&#21644;&#22810;&#32500;&#29615;&#22659;&#20013;&#12290;&#35813;&#31639;&#27861;&#22522;&#20110;&#27169;&#22359;&#21270;&#35774;&#35745;&#65292;&#21253;&#25324;&#20572;&#27490;&#35268;&#21017;&#21644;&#37319;&#26679;&#35268;&#21017;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#29702;&#35770;&#32467;&#26524;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#20984;&#21253;&#25104;&#21592;&#38382;&#39064;&#30340;&#32431;&#25506;&#32034;&#35774;&#32622;&#19982;&#20984;&#21253;&#22343;&#20540;&#30340;&#26377;&#38480;&#20998;&#24067;&#38598;&#21512;&#20013;&#26377;&#25928;&#20934;&#30830;&#22320;&#30830;&#23450;&#32473;&#23450;&#28857;&#26159;&#21542;&#22312;&#20984;&#21253;&#20013;&#30456;&#20851;&#12290;&#25105;&#20204;&#22312;&#19968;&#32500;&#29615;&#22659;&#20013;&#23436;&#20840;&#21051;&#30011;&#20102;&#20984;&#21253;&#25104;&#21592;&#38382;&#39064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#28176;&#36817;&#26368;&#20248;&#31639;&#27861;&#65292;&#21517;&#20026;Thompson-CHM&#65292;&#20854;&#27169;&#22359;&#21270;&#35774;&#35745;&#21253;&#25324;&#20572;&#27490;&#35268;&#21017;&#21644;&#37319;&#26679;&#35268;&#21017;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#31639;&#27861;&#25193;&#23637;&#21040;&#20102;&#19968;&#20123;&#22312;&#22810;&#33218;&#36172;&#21338;&#26426;&#25991;&#29486;&#20013;&#24191;&#20041;&#30340;&#37325;&#35201;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;Thompson-CHM&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#30340;&#25193;&#23637;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#25968;&#20540;&#23454;&#39564;&#65292;&#20197;&#23637;&#31034;&#31639;&#27861;&#30340;&#32463;&#39564;&#34892;&#20026;&#19982;&#25105;&#20204;&#22312;&#23454;&#38469;&#26102;&#38388;&#33539;&#22260;&#20869;&#30340;&#29702;&#35770;&#32467;&#26524;&#30456;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work studies the pure-exploration setting for the convex hull membership (CHM) problem where one aims to efficiently and accurately determine if a given point lies in the convex hull of means of a finite set of distributions. We give a complete characterization of the sample complexity of the CHM problem in the one-dimensional setting. We present the first asymptotically optimal algorithm called Thompson-CHM, whose modular design consists of a stopping rule and a sampling rule. In addition, we extend the algorithm to settings that generalize several important problems in the multi-armed bandit literature. Furthermore, we discuss the extension of Thompson-CHM to higher dimensions. Finally, we provide numerical experiments to demonstrate the empirical behavior of the algorithm matches our theoretical results for realistic time horizons.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#20989;&#25968;&#36924;&#36817;&#31639;&#27861;&#30340;&#24102;&#24179;&#22343;&#26631;&#20934;&#32422;&#26463; MDP &#30340;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2302.00808</link><description>&lt;p&gt;
&#24179;&#22343;&#38480;&#21046;&#31574;&#30053;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Average-Constrained Policy Optimization. (arXiv:2302.00808v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00808
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#20989;&#25968;&#36924;&#36817;&#31639;&#27861;&#30340;&#24102;&#24179;&#22343;&#26631;&#20934;&#32422;&#26463; MDP &#30340;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26377;&#38480;&#21046;&#26465;&#20214;&#30340;&#24378;&#21270;&#23398;&#20064;&#23545;&#20110;&#21508;&#31181;&#24212;&#29992;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#36890;&#24120;&#65292;&#24179;&#22343;&#26631;&#20934;&#27604;&#25240;&#25187;&#26631;&#20934;&#26356;&#21512;&#36866;&#12290;&#28982;&#32780;&#65292;&#38024;&#23545;&#24179;&#22343;&#38480;&#21046; CMDP &#30340;&#24378;&#21270;&#23398;&#20064;&#20173;&#28982;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;&#38024;&#23545;&#25240;&#25187;&#38480;&#21046; RL &#38382;&#39064;&#35774;&#35745;&#30340;&#31639;&#27861;&#36890;&#24120;&#22312;&#24179;&#22343; CMDP &#29615;&#22659;&#19979;&#34920;&#29616;&#19981;&#20339;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#20989;&#25968;&#36924;&#36817;&#31639;&#27861;&#30340;&#24102;&#24179;&#22343;&#26631;&#20934;&#32422;&#26463; MDP &#30340;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#12290;&#24179;&#22343;&#38480;&#21046;&#31574;&#30053;&#20248;&#21270;&#65288;ACPO&#65289;&#31639;&#27861;&#30340;&#28789;&#24863;&#26469;&#33258;&#22522;&#20110;&#20449;&#20219;&#21306;&#22495;&#26041;&#27861;&#30340;&#33879;&#21517; PPO &#31867;&#31639;&#27861;&#12290;&#25105;&#20204;&#21457;&#23637;&#20102;&#22522;&#26412;&#30340;&#24179;&#22343; MDP &#25935;&#24863;&#24615;&#29702;&#35770;&#65292;&#28982;&#21518;&#22312;&#31639;&#27861;&#35774;&#35745;&#20013;&#20351;&#29992;&#30456;&#24212;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20854;&#24615;&#33021;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#36890;&#36807;&#22312;&#21508;&#31181;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340; MuJoCo &#29615;&#22659;&#20013;&#36827;&#34892;&#22823;&#37327;&#23454;&#39564;&#24037;&#20316;&#65292;&#23637;&#31034;&#20102;&#35813;&#31639;&#27861;&#19982;&#20854;&#20182;&#24120;&#35268;&#31639;&#27861;&#30456;&#27604;&#30340;&#21331;&#36234;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning (RL) with constraints is becoming an increasingly important problem for various applications. Often, the average criterion is more suitable than the discounted criterion. Yet, RL for average criterion-constrained MDPs remains a challenging problem. Algorithms designed for discounted constrained RL problems often do not perform well for the average CMDP setting. In this paper, we introduce a new policy optimization with function approximation algorithm for constrained MDPs with the average criterion. The Average-Constrained Policy Optimization (ACPO) algorithm is inspired by the famed PPO-type algorithms based on trust region methods. We develop basic sensitivity theory for average MDPs, and then use the corresponding bounds in the design of the algorithm. We provide theoretical guarantees on its performance, and through extensive experimental work in various challenging MuJoCo environments, show the superior performance of the algorithm when compared to other sta
&lt;/p&gt;</description></item><item><title>&#25152;&#25552;&#20986;&#30340;RFold&#26041;&#27861;&#37319;&#29992;&#35299;&#32806;&#20248;&#21270;&#36807;&#31243;&#21644;&#27880;&#24847;&#21147;&#26426;&#21046;&#36827;&#34892;&#31616;&#21333;&#21448;&#26377;&#25928;&#30340;RNA&#20108;&#32423;&#32467;&#26500;&#39044;&#27979;&#65292;&#20855;&#26377;&#36739;&#39640;&#30340;&#20934;&#30830;&#24615;&#21644;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2212.14041</link><description>&lt;p&gt;
RFold&#65306;&#22522;&#20110;&#35299;&#32806;&#20248;&#21270;&#26041;&#27861;&#30340;RNA&#20108;&#32423;&#32467;&#26500;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
RFold: RNA Secondary Structure Prediction with Decoupled Optimization. (arXiv:2212.14041v2 [q-bio.BM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.14041
&lt;/p&gt;
&lt;p&gt;
&#25152;&#25552;&#20986;&#30340;RFold&#26041;&#27861;&#37319;&#29992;&#35299;&#32806;&#20248;&#21270;&#36807;&#31243;&#21644;&#27880;&#24847;&#21147;&#26426;&#21046;&#36827;&#34892;&#31616;&#21333;&#21448;&#26377;&#25928;&#30340;RNA&#20108;&#32423;&#32467;&#26500;&#39044;&#27979;&#65292;&#20855;&#26377;&#36739;&#39640;&#30340;&#20934;&#30830;&#24615;&#21644;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#31958;&#26680;&#37240;&#65288;RNA&#65289;&#30340;&#20108;&#32423;&#32467;&#26500;&#27604;&#19977;&#32423;&#32467;&#26500;&#26356;&#31283;&#23450;&#21644;&#26356;&#26131;&#20110;&#22312;&#32454;&#32990;&#20013;&#35775;&#38382;&#65292;&#22240;&#27492;&#23545;&#20110;&#21151;&#33021;&#39044;&#27979;&#33267;&#20851;&#37325;&#35201;&#12290;&#23613;&#31649;&#28145;&#24230;&#23398;&#20064;&#22312;&#36825;&#20010;&#39046;&#22495;&#20013;&#26174;&#31034;&#20986;&#20102;&#24456;&#22909;&#30340;&#32467;&#26524;&#65292;&#20294;&#24403;&#21069;&#30340;&#26041;&#27861;&#23384;&#22312;&#27867;&#21270;&#24615;&#24046;&#21644;&#22797;&#26434;&#24615;&#39640;&#30340;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;RNA&#20108;&#32423;&#32467;&#26500;&#39044;&#27979;&#26041;&#27861;RFold&#12290;RFold&#24341;&#20837;&#20102;&#19968;&#31181;&#35299;&#32806;&#20248;&#21270;&#30340;&#36807;&#31243;&#65292;&#23558;&#20256;&#32479;&#30340;&#32422;&#26463;&#28385;&#36275;&#38382;&#39064;&#20998;&#35299;&#20026;&#36880;&#34892;&#21644;&#36880;&#21015;&#20248;&#21270;&#65292;&#31616;&#21270;&#20102;&#27714;&#35299;&#36807;&#31243;&#65292;&#21516;&#26102;&#20445;&#35777;&#20102;&#36755;&#20986;&#30340;&#26377;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;RFold&#37319;&#29992;&#27880;&#24847;&#21147;&#22320;&#22270;&#20316;&#20026;&#20449;&#24687;&#34920;&#31034;&#65292;&#32780;&#19981;&#26159;&#35774;&#35745;&#25163;&#24037;&#29305;&#24449;&#12290;&#24191;&#27867;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;RFold&#20855;&#26377;&#31454;&#20105;&#24615;&#33021;&#65292;&#24182;&#19988;&#27604;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#20855;&#26377;&#32422;8&#20493;&#30340;&#25512;&#29702;&#25928;&#29575;&#12290;&#20195;&#30721;&#21644;Colab&#28436;&#31034;&#21487;&#22312;\href{this http URL}{this http UR}&#19978;&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
The secondary structure of ribonucleic acid (RNA) is more stable and accessible in the cell than its tertiary structure, making it essential for functional prediction. Although deep learning has shown promising results in this field, current methods suffer from poor generalization and high complexity. In this work, we present RFold, a simple yet effective RNA secondary structure prediction in an end-to-end manner. RFold introduces a decoupled optimization process that decomposes the vanilla constraint satisfaction problem into row-wise and column-wise optimization, simplifying the solving process while guaranteeing the validity of the output. Moreover, RFold adopts attention maps as informative representations instead of designing hand-crafted features. Extensive experiments demonstrate that RFold achieves competitive performance and about eight times faster inference efficiency than the state-of-the-art method. The code and Colab demo are available in \href{this http URL}{this http UR
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20027;&#21160;&#39038;&#38382;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26694;&#26550;&#65292;Ask-AC&#65292;&#23427;&#26367;&#25442;&#20102;&#20256;&#32479;&#30340;&#34987;&#21160;&#30417;&#30563;&#20449;&#21495;&#26426;&#21046;&#65292;&#23454;&#29616;&#20102;&#23450;&#21046;&#21270;&#21644;&#39640;&#25928;&#30340;&#20449;&#24687;&#20132;&#25442;&#65292;&#20854;&#20013;&#30340;&#20004;&#20010;&#20114;&#34917;&#32452;&#20214;&#20801;&#35768;&#20195;&#29702;&#20027;&#21160;&#23547;&#27714;&#39038;&#38382;&#24178;&#39044;&#21644;&#35782;&#21035;&#28431;&#25481;&#30340;&#19981;&#31283;&#23450;&#29366;&#24577;&#12290;</title><link>http://arxiv.org/abs/2207.01955</link><description>&lt;p&gt;
Ask-AC: &#19968;&#31181;&#24490;&#29615;&#20013;&#30340;&#20027;&#21160;&#39038;&#38382;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Ask-AC: An Initiative Advisor-in-the-Loop Actor-Critic Framework. (arXiv:2207.01955v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.01955
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20027;&#21160;&#39038;&#38382;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26694;&#26550;&#65292;Ask-AC&#65292;&#23427;&#26367;&#25442;&#20102;&#20256;&#32479;&#30340;&#34987;&#21160;&#30417;&#30563;&#20449;&#21495;&#26426;&#21046;&#65292;&#23454;&#29616;&#20102;&#23450;&#21046;&#21270;&#21644;&#39640;&#25928;&#30340;&#20449;&#24687;&#20132;&#25442;&#65292;&#20854;&#20013;&#30340;&#20004;&#20010;&#20114;&#34917;&#32452;&#20214;&#20801;&#35768;&#20195;&#29702;&#20027;&#21160;&#23547;&#27714;&#39038;&#38382;&#24178;&#39044;&#21644;&#35782;&#21035;&#28431;&#25481;&#30340;&#19981;&#31283;&#23450;&#29366;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#20132;&#20114;&#24335;&#24378;&#21270;&#23398;&#20064;&#26041;&#26696;&#21462;&#24471;&#20102;&#24456;&#22810;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#65292;&#20294;&#30446;&#21069;&#30340;&#26041;&#26696;&#20173;&#28982;&#20381;&#36182;&#20110;&#26469;&#33258;&#39038;&#38382;&#19987;&#23478;&#30340;&#34987;&#21160;&#30417;&#30563;&#20449;&#21495;&#65292;&#24418;&#24335;&#21253;&#25324;&#25345;&#32493;&#30417;&#25511;&#25110;&#39044;&#23450;&#20041;&#35268;&#21017;&#65292;&#36825;&#19981;&#21487;&#36991;&#20813;&#22320;&#23548;&#33268;&#20102;&#19968;&#31181;&#40635;&#28902;&#32780;&#26114;&#36149;&#30340;&#23398;&#20064;&#36807;&#31243;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#20027;&#21160;&#39038;&#38382;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26694;&#26550;&#65292;&#31216;&#20026;Ask-AC&#65292;&#23427;&#29992;&#19968;&#20010;&#21452;&#21521;&#30340;&#23398;&#20064;&#32773;&#20027;&#21160;&#26426;&#21046;&#26367;&#25442;&#20102;&#21333;&#21521;&#30340;&#39038;&#38382;&#25351;&#23548;&#26426;&#21046;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23398;&#20064;&#32773;&#21644;&#39038;&#38382;&#20043;&#38388;&#30340;&#23450;&#21046;&#21270;&#21644;&#26377;&#25928;&#30340;&#20449;&#24687;&#20132;&#25442;&#12290;Ask-AC &#30340;&#26680;&#24515;&#26159;&#20004;&#20010;&#20114;&#34917;&#30340;&#32452;&#20214;&#65292;&#20998;&#21035;&#26159;&#21160;&#20316;&#35831;&#27714;&#32773;&#21644;&#33258;&#36866;&#24212;&#29366;&#24577;&#36873;&#25321;&#22120;&#65292;&#21487;&#20197;&#26041;&#20415;&#22320;&#32435;&#20837;&#21508;&#31181;&#31163;&#25955;&#30340;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26550;&#26500;&#20013;&#12290;&#21069;&#32773;&#20801;&#35768;&#20195;&#29702;&#20027;&#21160;&#23547;&#27714;&#19981;&#30830;&#23450;&#29366;&#24577;&#19979;&#30340;&#39038;&#38382;&#24178;&#39044;&#65292;&#21518;&#32773;&#21017;&#21487;&#20197;&#35782;&#21035;&#28431;&#25481;&#30340;&#19981;&#31283;&#23450;&#29366;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the promising results achieved, state-of-the-art interactive reinforcement learning schemes rely on passively receiving supervision signals from advisor experts, in the form of either continuous monitoring or pre-defined rules, which inevitably result in a cumbersome and expensive learning process. In this paper, we introduce a novel initiative advisor-in-the-loop actor-critic framework, termed as Ask-AC, that replaces the unilateral advisor-guidance mechanism with a bidirectional learner-initiative one, and thereby enables a customized and efficacious message exchange between learner and advisor. At the heart of Ask-AC are two complementary components, namely action requester and adaptive state selector, that can be readily incorporated into various discrete actor-critic architectures. The former component allows the agent to initiatively seek advisor intervention in the presence of uncertain states, while the latter identifies the unstable states potentially missed by the for
&lt;/p&gt;</description></item></channel></rss>