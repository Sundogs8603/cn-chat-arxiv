<rss version="2.0"><channel><title>Chat Arxiv stat</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26368;&#22823;&#21270;&#19968;&#31995;&#21015;&#24402;&#19968;&#21270;&#30697;&#26469;&#20351;&#29992;&#23376;&#39640;&#26031;&#20869;&#22312;&#30697;&#33539;&#23454;&#29616;&#32039;&#20945;&#30340;&#38750;&#28176;&#36827;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#23548;&#33268;&#26356;&#32039;&#30340;Hoeffding&#23376;&#39640;&#26031;&#27987;&#24230;&#19981;&#31561;&#24335;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#23376;&#39640;&#26031;&#22270;&#26816;&#26597;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#22823;&#23567;&#30340;&#23376;&#39640;&#26031;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2303.07287</link><description>&lt;p&gt;
&#36890;&#36807;&#23376;&#39640;&#26031;&#20869;&#22312;&#30697;&#33539;&#23454;&#29616;&#32039;&#20945;&#30340;&#38750;&#28176;&#36827;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Tight Non-asymptotic Inference via Sub-Gaussian Intrinsic Moment Norm. (arXiv:2303.07287v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.07287
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26368;&#22823;&#21270;&#19968;&#31995;&#21015;&#24402;&#19968;&#21270;&#30697;&#26469;&#20351;&#29992;&#23376;&#39640;&#26031;&#20869;&#22312;&#30697;&#33539;&#23454;&#29616;&#32039;&#20945;&#30340;&#38750;&#28176;&#36827;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#23548;&#33268;&#26356;&#32039;&#30340;Hoeffding&#23376;&#39640;&#26031;&#27987;&#24230;&#19981;&#31561;&#24335;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#23376;&#39640;&#26031;&#22270;&#26816;&#26597;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#22823;&#23567;&#30340;&#23376;&#39640;&#26031;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a method of achieving tight non-asymptotic inference by using sub-Gaussian intrinsic moment norm through maximizing a series of normalized moments, which can lead to tighter Hoeffding's sub-Gaussian concentration inequalities and can be checked with sub-Gaussian plot for sub-Gaussian data with a finite sample size.
&lt;/p&gt;
&lt;p&gt;
&#22312;&#38750;&#28176;&#36827;&#32479;&#35745;&#25512;&#26029;&#20013;&#65292;&#23376;&#39640;&#26031;&#20998;&#24067;&#30340;&#26041;&#24046;&#31867;&#22411;&#21442;&#25968;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#22522;&#20110;&#32463;&#39564;&#30697;&#29983;&#25104;&#20989;&#25968;&#65288;MGF&#65289;&#30340;&#30452;&#25509;&#20272;&#35745;&#36825;&#20123;&#21442;&#25968;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24314;&#35758;&#36890;&#36807;&#26368;&#22823;&#21270;&#19968;&#31995;&#21015;&#24402;&#19968;&#21270;&#30697;&#26469;&#20351;&#29992;&#23376;&#39640;&#26031;&#20869;&#22312;&#30697;&#33539;[Buldygin&#21644;Kozachenko&#65288;2000&#65289;&#65292;&#23450;&#29702;1.3]&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25512;&#33616;&#30340;&#33539;&#25968;&#19981;&#20165;&#21487;&#20197;&#24674;&#22797;&#30456;&#24212;MGF&#30340;&#25351;&#25968;&#30697;&#30028;&#38480;&#65292;&#32780;&#19988;&#36824;&#21487;&#20197;&#23548;&#33268;&#26356;&#32039;&#30340;Hoeffding&#23376;&#39640;&#26031;&#27987;&#24230;&#19981;&#31561;&#24335;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#30452;&#35266;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23376;&#39640;&#26031;&#22270;&#26816;&#26597;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#22823;&#23567;&#30340;&#23376;&#39640;&#26031;&#25968;&#25454;&#12290;&#21487;&#20197;&#36890;&#36807;&#31616;&#21333;&#30340;&#25554;&#20837;&#26041;&#27861;&#40065;&#26834;&#22320;&#20272;&#35745;&#20869;&#22312;&#30697;&#33539;&#25968;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#24212;&#29992;&#20110;&#38750;&#28176;&#36827;&#20998;&#26512;&#65292;&#21253;&#25324;&#22810;&#33218;&#36172;&#21338;&#26426;&#12290;
&lt;/p&gt;
&lt;p&gt;
In non-asymptotic statistical inferences, variance-type parameters of sub-Gaussian distributions play a crucial role. However, direct estimation of these parameters based on the empirical moment generating function (MGF) is infeasible. To this end, we recommend using a sub-Gaussian intrinsic moment norm [Buldygin and Kozachenko (2000), Theorem 1.3] through maximizing a series of normalized moments. Importantly, the recommended norm can not only recover the exponential moment bounds for the corresponding MGFs, but also lead to tighter Hoeffding's sub-Gaussian concentration inequalities. In practice, {\color{black} we propose an intuitive way of checking sub-Gaussian data with a finite sample size by the sub-Gaussian plot}. Intrinsic moment norm can be robustly estimated via a simple plug-in approach. Our theoretical results are applied to non-asymptotic analysis, including the multi-armed bandit.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#32479;&#19968;&#24754;&#35266;&#39118;&#38505;&#30340;&#32508;&#21512;$\alpha$-&#39118;&#38505;&#29256;&#26412;&#21644;&#22522;&#20110;&#39118;&#38505;&#33719;&#24471;&#26368;&#20248;&#32452;&#21512;&#30340;&#35745;&#31639;&#31639;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#20272;&#35745;&#38889;&#22269;&#32929;&#31080;&#30340;&#24754;&#35266;&#26368;&#20248;&#32452;&#21512;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2303.07158</link><description>&lt;p&gt;
&#32479;&#19968;&#24754;&#35266;&#39118;&#38505;&#21644;&#26368;&#20248;&#32452;&#21512;
&lt;/p&gt;
&lt;p&gt;
Uniform Pessimistic Risk and Optimal Portfolio. (arXiv:2303.07158v1 [q-fin.PM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.07158
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#32479;&#19968;&#24754;&#35266;&#39118;&#38505;&#30340;&#32508;&#21512;$\alpha$-&#39118;&#38505;&#29256;&#26412;&#21644;&#22522;&#20110;&#39118;&#38505;&#33719;&#24471;&#26368;&#20248;&#32452;&#21512;&#30340;&#35745;&#31639;&#31639;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#20272;&#35745;&#38889;&#22269;&#32929;&#31080;&#30340;&#24754;&#35266;&#26368;&#20248;&#32452;&#21512;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a version of integrated $\alpha$-risk called the uniform pessimistic risk and a computational algorithm to obtain an optimal portfolio based on the risk. The proposed method can be used to estimate the pessimistic optimal portfolio models for Korean stocks.
&lt;/p&gt;
&lt;p&gt;
&#36164;&#20135;&#37197;&#32622;&#30340;&#26368;&#20248;&#24615;&#24050;&#32463;&#22312;&#39118;&#38505;&#24230;&#37327;&#30340;&#29702;&#35770;&#20998;&#26512;&#20013;&#24471;&#21040;&#24191;&#27867;&#35752;&#35770;&#12290;&#24754;&#35266;&#20027;&#20041;&#26159;&#19968;&#31181;&#36229;&#36234;&#20256;&#32479;&#26368;&#20248;&#32452;&#21512;&#27169;&#22411;&#30340;&#26368;&#26377;&#21560;&#24341;&#21147;&#30340;&#26041;&#27861;&#20043;&#19968;&#65292;$\alpha$-&#39118;&#38505;&#22312;&#25512;&#23548;&#20986;&#24191;&#27867;&#30340;&#24754;&#35266;&#26368;&#20248;&#32452;&#21512;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#30001;&#24754;&#35266;&#39118;&#38505;&#35780;&#20272;&#30340;&#26368;&#20248;&#32452;&#21512;&#30340;&#20272;&#35745;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#32570;&#20047;&#21487;&#29992;&#30340;&#20272;&#35745;&#27169;&#22411;&#21644;&#35745;&#31639;&#31639;&#27861;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#32479;&#19968;&#24754;&#35266;&#39118;&#38505;&#30340;&#32508;&#21512;$\alpha$-&#39118;&#38505;&#29256;&#26412;&#21644;&#22522;&#20110;&#39118;&#38505;&#33719;&#24471;&#26368;&#20248;&#32452;&#21512;&#30340;&#35745;&#31639;&#31639;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20174;&#22810;&#20010;&#20998;&#20301;&#25968;&#22238;&#24402;&#12289;&#36866;&#24403;&#30340;&#35780;&#20998;&#35268;&#21017;&#21644;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#19977;&#20010;&#19981;&#21516;&#30340;&#26041;&#27861;&#26469;&#30740;&#31350;&#25152;&#25552;&#20986;&#30340;&#39118;&#38505;&#30340;&#29702;&#35770;&#24615;&#36136;&#12290;&#21516;&#26102;&#65292;&#32479;&#19968;&#24754;&#35266;&#39118;&#38505;&#34987;&#24212;&#29992;&#20110;&#20272;&#35745;&#38889;&#22269;&#32929;&#31080;&#30340;&#24754;&#35266;&#26368;&#20248;&#32452;&#21512;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
The optimality of allocating assets has been widely discussed with the theoretical analysis of risk measures. Pessimism is one of the most attractive approaches beyond the conventional optimal portfolio model, and the $\alpha$-risk plays a crucial role in deriving a broad class of pessimistic optimal portfolios. However, estimating an optimal portfolio assessed by a pessimistic risk is still challenging due to the absence of an available estimation model and a computational algorithm. In this study, we propose a version of integrated $\alpha$-risk called the uniform pessimistic risk and the computational algorithm to obtain an optimal portfolio based on the risk. Further, we investigate the theoretical properties of the proposed risk in view of three different approaches: multiple quantile regression, the proper scoring rule, and distributionally robust optimization. Also, the uniform pessimistic risk is applied to estimate the pessimistic optimal portfolio models for the Korean stock 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20840;&#29699;&#20215;&#20540;&#38142;&#20013;&#20135;&#19994;&#21644;&#22269;&#23478;&#30340;&#19978;&#28216;&#21644;&#19979;&#28216;&#65292;&#21457;&#29616;&#21516;&#19968;&#20135;&#19994;&#37096;&#38376;&#30340;&#19978;&#28216;&#21644;&#19979;&#28216;&#20043;&#38388;&#23384;&#22312;&#27491;&#30456;&#20851;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.06603</link><description>&lt;p&gt;
&#38543;&#26426;&#20840;&#29699;&#20215;&#20540;&#38142;&#20013;&#19978;&#28216;&#21644;&#19979;&#28216;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;
&lt;/p&gt;
&lt;p&gt;
Correlation between upstreamness and downstreamness in random global value chains. (arXiv:2303.06603v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06603
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20840;&#29699;&#20215;&#20540;&#38142;&#20013;&#20135;&#19994;&#21644;&#22269;&#23478;&#30340;&#19978;&#28216;&#21644;&#19979;&#28216;&#65292;&#21457;&#29616;&#21516;&#19968;&#20135;&#19994;&#37096;&#38376;&#30340;&#19978;&#28216;&#21644;&#19979;&#28216;&#20043;&#38388;&#23384;&#22312;&#27491;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the upstreamness and downstreamness of industries and countries in global value chains, and finds a positive correlation between upstreamness and downstreamness of the same industrial sector.
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#20840;&#29699;&#20215;&#20540;&#38142;&#20013;&#20135;&#19994;&#21644;&#22269;&#23478;&#30340;&#19978;&#28216;&#21644;&#19979;&#28216;&#12290;&#19978;&#28216;&#21644;&#19979;&#28216;&#20998;&#21035;&#34913;&#37327;&#20135;&#19994;&#37096;&#38376;&#19982;&#26368;&#32456;&#28040;&#36153;&#21644;&#21021;&#32423;&#36755;&#20837;&#20043;&#38388;&#30340;&#24179;&#22343;&#36317;&#31163;&#65292;&#24182;&#22522;&#20110;&#26368;&#24120;&#29992;&#30340;&#20840;&#29699;&#25237;&#20837;&#20135;&#20986;&#34920;&#25968;&#25454;&#24211;&#65288;&#20363;&#22914;&#19990;&#30028;&#25237;&#20837;&#20135;&#20986;&#25968;&#25454;&#24211;&#65288;WIOD&#65289;&#65289;&#36827;&#34892;&#35745;&#31639;&#12290;&#26368;&#36817;&#65292;Antr\`as&#21644;Chor&#22312;1995-2011&#24180;&#30340;&#25968;&#25454;&#20013;&#25253;&#21578;&#20102;&#19968;&#20010;&#20196;&#20154;&#22256;&#24785;&#21644;&#21453;&#30452;&#35273;&#30340;&#21457;&#29616;&#65292;&#21363;&#65288;&#22312;&#22269;&#23478;&#23618;&#38754;&#19978;&#65289;&#19978;&#28216;&#20284;&#20046;&#19982;&#19979;&#28216;&#21576;&#27491;&#30456;&#20851;&#65292;&#30456;&#20851;&#26012;&#29575;&#25509;&#36817;+1&#12290;&#36825;&#31181;&#25928;&#24212;&#38543;&#26102;&#38388;&#21644;&#36328;&#22269;&#23478;&#31283;&#23450;&#23384;&#22312;&#65292;&#24182;&#24050;&#24471;&#21040;&#21518;&#32493;&#20998;&#26512;&#30340;&#30830;&#35748;&#21644;&#39564;&#35777;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#38543;&#26426;&#25237;&#20837;&#20135;&#20986;&#34920;&#27169;&#22411;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#26368;&#23567;&#21644;&#29616;&#23454;&#30340;&#32467;&#26500;&#20551;&#35774;&#19979;&#65292;&#21516;&#19968;&#20135;&#19994;&#37096;&#38376;&#30340;&#19978;&#28216;&#21644;&#19979;&#28216;&#20043;&#38388;&#23384;&#22312;&#27491;&#30456;&#20851;&#24615;&#65292;&#20855;&#26377;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is concerned with upstreamness and downstreamness of industries and countries in global value chains. Upstreamness and downstreamness measure respectively the average distance of an industrial sector from final consumption and from primary inputs, and they are computed from based on the most used global Input-Output tables databases, e.g., the World Input-Output Database (WIOD). Recently, Antr\`as and Chor reported a puzzling and counter-intuitive finding in data from the period 1995-2011, namely that (at country level) upstreamness appears to be positively correlated with downstreamness, with a correlation slope close to $+1$. This effect is stable over time and across countries, and it has been confirmed and validated by later analyses. We analyze a simple model of random Input/Output tables, and we show that, under minimal and realistic structural assumptions, there is a positive correlation between upstreamness and downstreamness of the same industrial sector, with corre
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25968;&#25454;&#30456;&#20851;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#20840;&#19987;&#23478;&#21453;&#39304;&#21644;Bandit&#21453;&#39304;&#35774;&#32622;&#20013;&#20855;&#26377;&#25968;&#25454;&#30456;&#20851;&#30340;&#36951;&#25022;&#20445;&#35777;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#38382;&#39064;&#22330;&#26223;&#12290;</title><link>http://arxiv.org/abs/2303.06526</link><description>&lt;p&gt;
&#25968;&#25454;&#30456;&#20851;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Data Dependent Regret Guarantees Against General Comparators for Full or Bandit Feedback. (arXiv:2303.06526v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06526
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25968;&#25454;&#30456;&#20851;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#20840;&#19987;&#23478;&#21453;&#39304;&#21644;Bandit&#21453;&#39304;&#35774;&#32622;&#20013;&#20855;&#26377;&#25968;&#25454;&#30456;&#20851;&#30340;&#36951;&#25022;&#20445;&#35777;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#38382;&#39064;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a data-dependent online learning algorithm framework that has data-dependent regret guarantees in both full expert feedback and bandit feedback settings, applicable for a wide variety of problem scenarios.
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#23545;&#25239;&#24615;&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#21019;&#24314;&#20102;&#19968;&#20010;&#23436;&#20840;&#22312;&#32447;&#30340;&#31639;&#27861;&#26694;&#26550;&#65292;&#20855;&#26377;&#22312;&#20840;&#19987;&#23478;&#21453;&#39304;&#21644;Bandit&#21453;&#39304;&#35774;&#32622;&#20013;&#20855;&#26377;&#25968;&#25454;&#30456;&#20851;&#30340;&#36951;&#25022;&#20445;&#35777;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#23545;&#19968;&#33324;&#27604;&#36739;&#22120;&#30340;&#39044;&#26399;&#24615;&#33021;&#65292;&#20351;&#20854;&#36866;&#29992;&#20110;&#21508;&#31181;&#38382;&#39064;&#22330;&#26223;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20174;&#36890;&#29992;&#39044;&#27979;&#35282;&#24230;&#24037;&#20316;&#65292;&#20351;&#29992;&#30340;&#24615;&#33021;&#24230;&#37327;&#26159;&#23545;&#20219;&#24847;&#27604;&#36739;&#22120;&#24207;&#21015;&#30340;&#39044;&#26399;&#36951;&#25022;&#65292;&#21363;&#25105;&#20204;&#30340;&#25439;&#22833;&#19982;&#31454;&#20105;&#25439;&#22833;&#24207;&#21015;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#31454;&#20105;&#31867;&#21487;&#20197;&#35774;&#35745;&#20026;&#21253;&#25324;&#22266;&#23450;&#33218;&#36873;&#25321;&#12289;&#20999;&#25442;Bandit&#12289;&#19978;&#19979;&#25991;Bandit&#12289;&#21608;&#26399;Bandit&#25110;&#20219;&#20309;&#20854;&#20182;&#24863;&#20852;&#36259;&#30340;&#31454;&#20105;&#12290;&#31454;&#20105;&#31867;&#20013;&#30340;&#24207;&#21015;&#36890;&#24120;&#30001;&#20855;&#20307;&#24212;&#29992;&#31243;&#24207;&#30830;&#23450;&#65292;&#24182;&#24212;&#30456;&#24212;&#22320;&#35774;&#35745;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#26082;&#19981;&#20351;&#29992;&#20063;&#19981;&#38656;&#35201;&#20219;&#20309;&#26377;&#20851;&#25439;&#22833;&#24207;&#21015;&#30340;&#21021;&#27493;&#20449;&#24687;&#65292;&#23436;&#20840;&#22312;&#32447;&#12290;&#20854;
&lt;/p&gt;
&lt;p&gt;
We study the adversarial online learning problem and create a completely online algorithmic framework that has data dependent regret guarantees in both full expert feedback and bandit feedback settings. We study the expected performance of our algorithm against general comparators, which makes it applicable for a wide variety of problem scenarios. Our algorithm works from a universal prediction perspective and the performance measure used is the expected regret against arbitrary comparator sequences, which is the difference between our losses and a competing loss sequence. The competition class can be designed to include fixed arm selections, switching bandits, contextual bandits, periodic bandits or any other competition of interest. The sequences in the competition class are generally determined by the specific application at hand and should be designed accordingly. Our algorithm neither uses nor needs any preliminary information about the loss sequences and is completely online. Its
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#24191;&#20041;&#31070;&#32463;&#22349;&#22604;&#20551;&#35774;&#65292;&#26377;&#25928;&#22320;&#21253;&#21547;&#20102;&#21407;&#22987;&#31070;&#32463;&#22349;&#22604;&#65292;&#24182;&#23558;&#20854;&#20998;&#35299;&#20026;&#20004;&#20010;&#30446;&#26631;&#65306;&#26368;&#23567;&#21270;&#31867;&#20869;&#21464;&#24322;&#24615;&#21644;&#26368;&#22823;&#21270;&#31867;&#38388;&#21487;&#20998;&#24615;&#12290;&#20351;&#29992;&#36229;&#29699;&#32479;&#19968;&#24615;&#20316;&#20026;&#37327;&#21270;&#36825;&#20004;&#20010;&#30446;&#26631;&#30340;&#32479;&#19968;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30446;&#26631;&#8212;&#8212;&#36229;&#29699;&#32479;&#19968;&#24615;&#24046;&#65288;HUG&#65289;&#65292;&#23427;&#30001;&#31867;&#38388;&#21644;&#31867;&#20869;&#36229;&#29699;&#32479;&#19968;&#24615;&#20043;&#38388;&#30340;&#24046;&#24322;&#23450;&#20041;&#12290;</title><link>http://arxiv.org/abs/2303.06484</link><description>&lt;p&gt;
&#36890;&#36807;&#36229;&#29699;&#32479;&#19968;&#24615;&#24046;&#22635;&#34917;&#31070;&#32463;&#22349;&#22604;&#30340;&#27867;&#21270;&#21644;&#35299;&#32806;
&lt;/p&gt;
&lt;p&gt;
Generalizing and Decoupling Neural Collapse via Hyperspherical Uniformity Gap. (arXiv:2303.06484v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06484
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#24191;&#20041;&#31070;&#32463;&#22349;&#22604;&#20551;&#35774;&#65292;&#26377;&#25928;&#22320;&#21253;&#21547;&#20102;&#21407;&#22987;&#31070;&#32463;&#22349;&#22604;&#65292;&#24182;&#23558;&#20854;&#20998;&#35299;&#20026;&#20004;&#20010;&#30446;&#26631;&#65306;&#26368;&#23567;&#21270;&#31867;&#20869;&#21464;&#24322;&#24615;&#21644;&#26368;&#22823;&#21270;&#31867;&#38388;&#21487;&#20998;&#24615;&#12290;&#20351;&#29992;&#36229;&#29699;&#32479;&#19968;&#24615;&#20316;&#20026;&#37327;&#21270;&#36825;&#20004;&#20010;&#30446;&#26631;&#30340;&#32479;&#19968;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30446;&#26631;&#8212;&#8212;&#36229;&#29699;&#32479;&#19968;&#24615;&#24046;&#65288;HUG&#65289;&#65292;&#23427;&#30001;&#31867;&#38388;&#21644;&#31867;&#20869;&#36229;&#29699;&#32479;&#19968;&#24615;&#20043;&#38388;&#30340;&#24046;&#24322;&#23450;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a generalized neural collapse hypothesis that effectively subsumes the original neural collapse and decomposes it into two objectives: minimizing intra-class variability and maximizing inter-class separability. The authors use hyperspherical uniformity as a unified framework to quantify these objectives and propose a general objective, hyperspherical uniformity gap (HUG), which is defined by the difference between inter-class and intra-class hyperspherical uniformity.
&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#22349;&#22604;&#29616;&#35937;&#25551;&#36848;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#24213;&#23618;&#20960;&#20309;&#23545;&#31216;&#24615;&#65292;&#20854;&#20013;&#28145;&#24230;&#23398;&#20064;&#30340;&#29305;&#24449;&#21644;&#20998;&#31867;&#22120;&#37117;&#25910;&#25947;&#20110;&#19968;&#20010;&#31561;&#35282;&#32039;&#26694;&#26550;&#12290;&#24050;&#32463;&#35777;&#26126;&#65292;&#20132;&#21449;&#29109;&#25439;&#22833;&#21644;&#22343;&#26041;&#35823;&#24046;&#37117;&#21487;&#20197;&#23548;&#33268;&#31070;&#32463;&#22349;&#22604;&#12290;&#25105;&#20204;&#28040;&#38500;&#20102;&#31070;&#32463;&#22349;&#22604;&#23545;&#29305;&#24449;&#32500;&#24230;&#21644;&#31867;&#21035;&#25968;&#37327;&#30340;&#20851;&#38190;&#20551;&#35774;&#65292;&#28982;&#21518;&#25552;&#20986;&#20102;&#19968;&#20010;&#24191;&#20041;&#31070;&#32463;&#22349;&#22604;&#20551;&#35774;&#65292;&#26377;&#25928;&#22320;&#21253;&#21547;&#20102;&#21407;&#22987;&#31070;&#32463;&#22349;&#22604;&#12290;&#21463;&#31070;&#32463;&#22349;&#22604;&#25551;&#36848;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#30446;&#26631;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#23558;&#24191;&#20041;&#31070;&#32463;&#22349;&#22604;&#20998;&#35299;&#20026;&#20004;&#20010;&#30446;&#26631;&#65306;&#26368;&#23567;&#21270;&#31867;&#20869;&#21464;&#24322;&#24615;&#21644;&#26368;&#22823;&#21270;&#31867;&#38388;&#21487;&#20998;&#24615;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#36229;&#29699;&#32479;&#19968;&#24615;&#65288;&#23427;&#25551;&#36848;&#20102;&#21333;&#20301;&#36229;&#29699;&#19978;&#22343;&#21248;&#24615;&#30340;&#31243;&#24230;&#65289;&#20316;&#20026;&#37327;&#21270;&#36825;&#20004;&#20010;&#30446;&#26631;&#30340;&#32479;&#19968;&#26694;&#26550;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30446;&#26631;&#8212;&#8212;&#36229;&#29699;&#32479;&#19968;&#24615;&#24046;&#65288;HUG&#65289;&#65292;&#23427;&#30001;&#31867;&#38388;&#21644;&#31867;&#20869;&#36229;&#29699;&#32479;&#19968;&#24615;&#20043;&#38388;&#30340;&#24046;&#24322;&#23450;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
The neural collapse (NC) phenomenon describes an underlying geometric symmetry for deep neural networks, where both deeply learned features and classifiers converge to a simplex equiangular tight frame. It has been shown that both cross-entropy loss and mean square error can provably lead to NC. We remove NC's key assumption on the feature dimension and the number of classes, and then present a generalized neural collapse (GNC) hypothesis that effectively subsumes the original NC. Inspired by how NC characterizes the training target of neural networks, we decouple GNC into two objectives: minimal intra-class variability and maximal inter-class separability. We then use hyperspherical uniformity (which characterizes the degree of uniformity on the unit hypersphere) as a unified framework to quantify these two objectives. Finally, we propose a general objective -- hyperspherical uniformity gap (HUG), which is defined by the difference between inter-class and intra-class hyperspherical un
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#21487;&#38752;&#21644;&#21487;&#25193;&#23637;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#65288;iMIIC&#65289;&#65292;&#24182;&#22312;&#26469;&#33258;&#32654;&#22269;&#30417;&#27979;&#12289;&#27969;&#34892;&#30149;&#23398;&#21644;&#32456;&#26411;&#32467;&#26524;&#35745;&#21010;&#30340;396,179&#21517;&#20083;&#33146;&#30284;&#24739;&#32773;&#30340;&#21307;&#30103;&#20445;&#20581;&#25968;&#25454;&#19978;&#23637;&#31034;&#20102;&#20854;&#29420;&#29305;&#33021;&#21147;&#12290;&#36229;&#36807;90&#65285;&#30340;&#39044;&#27979;&#22240;&#26524;&#25928;&#24212;&#26159;&#27491;&#30830;&#30340;&#65292;&#32780;&#20854;&#20313;&#30340;&#24847;&#22806;&#30452;&#25509;&#21644;&#38388;&#25509;&#22240;&#26524;&#25928;&#24212;&#21487;&#20197;&#35299;&#37322;&#20026;&#35786;&#26029;&#31243;&#24207;&#12289;&#27835;&#30103;&#26102;&#38388;&#12289;&#24739;&#32773;&#20559;&#22909;&#25110;&#31038;&#20250;&#32463;&#27982;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/2303.06423</link><description>&lt;p&gt;
&#20174;&#22823;&#22411;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#21487;&#35299;&#37322;&#30340;&#22240;&#26524;&#32593;&#32476;&#65292;&#20197;&#20083;&#33146;&#30284;&#24739;&#32773;&#30340;40&#19975;&#20221;&#21307;&#30103;&#35760;&#24405;&#20026;&#20363;
&lt;/p&gt;
&lt;p&gt;
Learning interpretable causal networks from very large datasets, application to 400,000 medical records of breast cancer patients. (arXiv:2303.06423v1 [q-bio.QM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06423
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#21487;&#38752;&#21644;&#21487;&#25193;&#23637;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#65288;iMIIC&#65289;&#65292;&#24182;&#22312;&#26469;&#33258;&#32654;&#22269;&#30417;&#27979;&#12289;&#27969;&#34892;&#30149;&#23398;&#21644;&#32456;&#26411;&#32467;&#26524;&#35745;&#21010;&#30340;396,179&#21517;&#20083;&#33146;&#30284;&#24739;&#32773;&#30340;&#21307;&#30103;&#20445;&#20581;&#25968;&#25454;&#19978;&#23637;&#31034;&#20102;&#20854;&#29420;&#29305;&#33021;&#21147;&#12290;&#36229;&#36807;90&#65285;&#30340;&#39044;&#27979;&#22240;&#26524;&#25928;&#24212;&#26159;&#27491;&#30830;&#30340;&#65292;&#32780;&#20854;&#20313;&#30340;&#24847;&#22806;&#30452;&#25509;&#21644;&#38388;&#25509;&#22240;&#26524;&#25928;&#24212;&#21487;&#20197;&#35299;&#37322;&#20026;&#35786;&#26029;&#31243;&#24207;&#12289;&#27835;&#30103;&#26102;&#38388;&#12289;&#24739;&#32773;&#20559;&#22909;&#25110;&#31038;&#20250;&#32463;&#27982;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a more reliable and scalable causal discovery method (iMIIC) and showcases its unique capabilities on healthcare data from 396,179 breast cancer patients from the US Surveillance, Epidemiology, and End Results program. Over 90% of predicted causal effects appear correct, while the remaining unexpected direct and indirect causal effects can be interpreted in terms of diagnostic procedures, therapeutic timing, patient preference or socio-economic disparity.
&lt;/p&gt;
&lt;p&gt;
&#21457;&#29616;&#22240;&#26524;&#25928;&#24212;&#26159;&#31185;&#23398;&#30740;&#31350;&#30340;&#26680;&#24515;&#65292;&#20294;&#24403;&#21482;&#26377;&#35266;&#23519;&#25968;&#25454;&#21487;&#29992;&#26102;&#65292;&#36825;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#22240;&#26524;&#32593;&#32476;&#38590;&#20197;&#23398;&#20064;&#21644;&#35299;&#37322;&#65292;&#24182;&#19988;&#20165;&#38480;&#20110;&#30456;&#23545;&#36739;&#23567;&#30340;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#25253;&#21578;&#20102;&#19968;&#31181;&#26356;&#21487;&#38752;&#21644;&#21487;&#25193;&#23637;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#65288;iMIIC&#65289;&#65292;&#22522;&#20110;&#19968;&#33324;&#30340;&#20114;&#20449;&#24687;&#26368;&#22823;&#21407;&#21017;&#65292;&#23427;&#26497;&#22823;&#22320;&#25552;&#39640;&#20102;&#25512;&#26029;&#30340;&#22240;&#26524;&#20851;&#31995;&#30340;&#31934;&#24230;&#65292;&#21516;&#26102;&#21306;&#20998;&#20102;&#30495;&#27491;&#30340;&#21407;&#22240;&#21644;&#20551;&#23450;&#30340;&#21644;&#28508;&#22312;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;iMIIC&#22312;&#26469;&#33258;&#32654;&#22269;&#30417;&#27979;&#12289;&#27969;&#34892;&#30149;&#23398;&#21644;&#32456;&#26411;&#32467;&#26524;&#35745;&#21010;&#30340;396,179&#21517;&#20083;&#33146;&#30284;&#24739;&#32773;&#30340;&#21512;&#25104;&#21644;&#29616;&#23454;&#21307;&#30103;&#20445;&#20581;&#25968;&#25454;&#19978;&#30340;&#29420;&#29305;&#33021;&#21147;&#12290;&#36229;&#36807;90&#65285;&#30340;&#39044;&#27979;&#22240;&#26524;&#25928;&#24212;&#26159;&#27491;&#30830;&#30340;&#65292;&#32780;&#20854;&#20313;&#30340;&#24847;&#22806;&#30452;&#25509;&#21644;&#38388;&#25509;&#22240;&#26524;&#25928;&#24212;&#21487;&#20197;&#35299;&#37322;&#20026;&#35786;&#26029;&#31243;&#24207;&#12289;&#27835;&#30103;&#26102;&#38388;&#12289;&#24739;&#32773;&#20559;&#22909;&#25110;&#31038;&#20250;&#32463;&#27982;&#24046;&#36317;&#12290;iMIIC&#30340;&#29420;&#29305;&#33021;&#21147;&#24320;&#36767;&#20102;&#21457;&#29616;&#21487;&#38752;&#21644;&#21487;&#35299;&#37322;&#30340;&#22240;&#26524;&#32593;&#32476;&#30340;&#26032;&#36884;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;
Discovering causal effects is at the core of scientific investigation but remains challenging when only observational data is available. In practice, causal networks are difficult to learn and interpret, and limited to relatively small datasets. We report a more reliable and scalable causal discovery method (iMIIC), based on a general mutual information supremum principle, which greatly improves the precision of inferred causal relations while distinguishing genuine causes from putative and latent causal effects. We showcase iMIIC on synthetic and real-life healthcare data from 396,179 breast cancer patients from the US Surveillance, Epidemiology, and End Results program. More than 90\% of predicted causal effects appear correct, while the remaining unexpected direct and indirect causal effects can be interpreted in terms of diagnostic procedures, therapeutic timing, patient preference or socio-economic disparity. iMIIC's unique capabilities open up new avenues to discover reliable and
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#36951;&#25022;&#31639;&#27861;&#65292;&#29992;&#20110;&#20844;&#24179;&#36164;&#28304;&#20998;&#37197;&#38382;&#39064;&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#23454;&#29616;$c_\alpha$-&#36817;&#20284;&#27425;&#32447;&#24615;&#36951;&#25022;&#65292;&#20854;&#20013;&#36817;&#20284;&#22240;&#23376;$c_\alpha=(1-\alpha)^{-(1-\alpha)}\leq 1.445$&#65292;&#23545;&#20110;$0\leq \alpha &lt; 1$&#12290;</title><link>http://arxiv.org/abs/2303.06396</link><description>&lt;p&gt;
&#26080;&#36951;&#25022;&#31639;&#27861;&#29992;&#20110;&#20844;&#24179;&#36164;&#28304;&#20998;&#37197;
&lt;/p&gt;
&lt;p&gt;
No-regret Algorithms for Fair Resource Allocation. (arXiv:2303.06396v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06396
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#36951;&#25022;&#31639;&#27861;&#65292;&#29992;&#20110;&#20844;&#24179;&#36164;&#28304;&#20998;&#37197;&#38382;&#39064;&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#23454;&#29616;$c_\alpha$-&#36817;&#20284;&#27425;&#32447;&#24615;&#36951;&#25022;&#65292;&#20854;&#20013;&#36817;&#20284;&#22240;&#23376;$c_\alpha=(1-\alpha)^{-(1-\alpha)}\leq 1.445$&#65292;&#23545;&#20110;$0\leq \alpha &lt; 1$&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a no-regret algorithm for fair resource allocation, which achieves $c_\alpha$-approximate sublinear regret with the approximation factor $c_\alpha=(1-\alpha)^{-(1-\alpha)}\leq 1.445,$ for $0\leq \alpha &lt; 1$.
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#20010;&#20844;&#24179;&#36164;&#28304;&#20998;&#37197;&#38382;&#39064;&#65292;&#35813;&#38382;&#39064;&#22312;&#26080;&#36951;&#25022;&#35774;&#32622;&#19979;&#38024;&#23545;&#26080;&#38480;&#21046;&#30340;&#23545;&#25163;&#12290;&#30446;&#26631;&#26159;&#20197;&#22312;&#32447;&#26041;&#24335;&#20844;&#24179;&#22320;&#20998;&#37197;&#22810;&#20010;&#20195;&#29702;&#30340;&#36164;&#28304;&#65292;&#20351;&#24471;&#26368;&#20248;&#38745;&#24577;&#39044;&#30693;&#20998;&#37197;&#21644;&#22312;&#32447;&#31574;&#30053;&#30340;&#20195;&#29702;&#30340;&#32858;&#21512;&#945;-&#20844;&#24179;&#25928;&#29992;&#20043;&#24046;&#38543;&#26102;&#38388;&#22686;&#38271;&#30340;&#36895;&#24230;&#20026;&#27425;&#32447;&#24615;&#12290;&#30001;&#20110;&#945;-&#20844;&#24179;&#24615;&#20989;&#25968;&#30340;&#38750;&#21152;&#24615;&#29305;&#24615;&#65292;&#35813;&#38382;&#39064;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#35813;&#38382;&#39064;&#19981;&#23384;&#22312;&#20855;&#26377;&#27425;&#32447;&#24615;&#26631;&#20934;&#36951;&#25022;&#30340;&#22312;&#32447;&#31574;&#30053;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#22312;&#32447;&#36164;&#28304;&#20998;&#37197;&#31574;&#30053;&#65292;&#31216;&#20026;&#22312;&#32447;&#27604;&#20363;&#20844;&#24179;&#65288;OPF&#65289;&#65292;&#35813;&#31574;&#30053;&#23454;&#29616;&#20102;$c_\alpha$-&#36817;&#20284;&#27425;&#32447;&#24615;&#36951;&#25022;&#65292;&#20854;&#20013;&#36817;&#20284;&#22240;&#23376;$c_\alpha=(1-\alpha)^{-(1-\alpha)}\leq 1.445$&#65292;&#23545;&#20110;$0\leq \alpha &lt; 1$&#12290;&#35813;&#38382;&#39064;&#30340;$c_\alpha$-&#36951;&#25022;&#19978;&#30028;&#23637;&#29616;&#20986;&#20102;&#19968;&#20010;&#20196;&#20154;&#24778;&#35766;&#30340;&#30456;&#21464;&#29616;&#35937;&#12290;&#36951;&#25022;&#19978;&#30028;&#20174;&#19968;&#20010;&#24130;&#20989;&#25968;&#21464;&#20026;&#19968;&#20010;&#23545;&#25968;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a fair resource allocation problem in the no-regret setting against an unrestricted adversary. The objective is to allocate resources equitably among several agents in an online fashion so that the difference of the aggregate $\alpha$-fair utilities of the agents between an optimal static clairvoyant allocation and that of the online policy grows sub-linearly with time. The problem is challenging due to the non-additive nature of the $\alpha$-fairness function. Previously, it was shown that no online policy can exist for this problem with a sublinear standard regret. In this paper, we propose an efficient online resource allocation policy, called Online Proportional Fair (OPF), that achieves $c_\alpha$-approximate sublinear regret with the approximation factor $c_\alpha=(1-\alpha)^{-(1-\alpha)}\leq 1.445,$ for $0\leq \alpha &lt; 1$. The upper bound to the $c_\alpha$-regret for this problem exhibits a surprising phase transition phenomenon. The regret bound changes from a power
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;Transformer&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#21457;&#29616;&#20302;&#27880;&#24847;&#21147;&#29109;&#20276;&#38543;&#30528;&#39640;&#35757;&#32451;&#19981;&#31283;&#23450;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;$\sigma$Reparam&#65292;&#25104;&#21151;&#22320;&#38450;&#27490;&#20102;&#27880;&#24847;&#21147;&#23618;&#20013;&#30340;&#29109;&#23849;&#28291;&#65292;&#20419;&#36827;&#20102;&#26356;&#31283;&#23450;&#30340;&#35757;&#32451;&#12290;</title><link>http://arxiv.org/abs/2303.06296</link><description>&lt;p&gt;
&#38450;&#27490;&#27880;&#24847;&#21147;&#29109;&#23849;&#28291;&#30340;Transformer&#35757;&#32451;&#31283;&#23450;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Stabilizing Transformer Training by Preventing Attention Entropy Collapse. (arXiv:2303.06296v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06296
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Transformer&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#21457;&#29616;&#20302;&#27880;&#24847;&#21147;&#29109;&#20276;&#38543;&#30528;&#39640;&#35757;&#32451;&#19981;&#31283;&#23450;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;$\sigma$Reparam&#65292;&#25104;&#21151;&#22320;&#38450;&#27490;&#20102;&#27880;&#24847;&#21147;&#23618;&#20013;&#30340;&#29109;&#23849;&#28291;&#65292;&#20419;&#36827;&#20102;&#26356;&#31283;&#23450;&#30340;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates the training dynamics of Transformers and proposes a simple and efficient solution, $\sigma$Reparam, to prevent entropy collapse in the attention layers, promoting more stable training.
&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#31283;&#23450;&#24615;&#23545;&#20110;Transformer&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#27880;&#24847;&#21147;&#23618;&#30340;&#28436;&#21464;&#26469;&#25506;&#31350;Transformer&#30340;&#35757;&#32451;&#21160;&#24577;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36319;&#36394;&#27599;&#20010;&#27880;&#24847;&#21147;&#22836;&#30340;&#27880;&#24847;&#21147;&#29109;&#65292;&#36825;&#26159;&#27169;&#22411;&#38160;&#24230;&#30340;&#20195;&#29702;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#19981;&#21516;&#30340;&#26550;&#26500;&#21644;&#20219;&#21153;&#20013;&#23384;&#22312;&#19968;&#31181;&#24120;&#35265;&#27169;&#24335;&#65292;&#21363;&#20302;&#27880;&#24847;&#21147;&#29109;&#20276;&#38543;&#30528;&#39640;&#35757;&#32451;&#19981;&#31283;&#23450;&#24615;&#65292;&#36825;&#21487;&#33021;&#37319;&#21462;&#25391;&#33633;&#25439;&#22833;&#25110;&#21457;&#25955;&#30340;&#24418;&#24335;&#12290;&#25105;&#20204;&#23558;&#30149;&#24577;&#20302;&#27880;&#24847;&#21147;&#29109;&#65292;&#23545;&#24212;&#39640;&#24230;&#38598;&#20013;&#30340;&#27880;&#24847;&#21147;&#20998;&#25968;&#65292;&#31216;&#20026;$\textit{&#29109;&#23849;&#28291;}$&#12290;&#20316;&#20026;&#19968;&#31181;&#35299;&#20915;&#26041;&#26696;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;$\sigma$Reparam&#65292;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20854;&#20013;&#25105;&#20204;&#20351;&#29992;&#35889;&#24402;&#19968;&#21270;&#21644;&#39069;&#22806;&#30340;&#23398;&#20064;&#26631;&#37327;&#37325;&#26032;&#21442;&#25968;&#21270;&#25152;&#26377;&#32447;&#24615;&#23618;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#37325;&#26032;&#21442;&#25968;&#21270;&#25104;&#21151;&#22320;&#38450;&#27490;&#20102;&#27880;&#24847;&#21147;&#23618;&#20013;&#30340;&#29109;&#23849;&#28291;&#65292;&#20419;&#36827;&#20102;&#26356;&#31283;&#23450;&#30340;&#35757;&#32451;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;
&lt;/p&gt;
&lt;p&gt;
Training stability is of great importance to Transformers. In this work, we investigate the training dynamics of Transformers by examining the evolution of the attention layers. In particular, we track the attention entropy for each attention head during the course of training, which is a proxy for model sharpness. We identify a common pattern across different architectures and tasks, where low attention entropy is accompanied by high training instability, which can take the form of oscillating loss or divergence. We denote the pathologically low attention entropy, corresponding to highly concentrated attention scores, as $\textit{entropy collapse}$. As a remedy, we propose $\sigma$Reparam, a simple and efficient solution where we reparametrize all linear layers with spectral normalization and an additional learned scalar. We demonstrate that the proposed reparameterization successfully prevents entropy collapse in the attention layers, promoting more stable training. Additionally, we 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#20998;&#21306;&#20195;&#25968;&#35745;&#31639;&#32622;&#25442;&#31561;&#21464;&#23618;&#36755;&#20986;&#21644;&#26799;&#24230;&#30340;&#26032;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#36755;&#20837;&#22823;&#23567;&#30340;&#32447;&#24615;&#21644;&#20108;&#27425;&#26102;&#38388;&#20869;&#35745;&#31639;&#65292;&#26377;&#25928;&#24615;&#24471;&#21040;&#20102;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2303.06208</link><description>&lt;p&gt;
&#21033;&#29992;&#20998;&#21306;&#20195;&#25968;&#24555;&#36895;&#35745;&#31639;&#32622;&#25442;&#31561;&#21464;&#23618;
&lt;/p&gt;
&lt;p&gt;
Fast computation of permutation equivariant layers with the partition algebra. (arXiv:2303.06208v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06208
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#20998;&#21306;&#20195;&#25968;&#35745;&#31639;&#32622;&#25442;&#31561;&#21464;&#23618;&#36755;&#20986;&#21644;&#26799;&#24230;&#30340;&#26032;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#36755;&#20837;&#22823;&#23567;&#30340;&#32447;&#24615;&#21644;&#20108;&#27425;&#26102;&#38388;&#20869;&#35745;&#31639;&#65292;&#26377;&#25928;&#24615;&#24471;&#21040;&#20102;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a new algorithm for computing the output and gradient of permutation equivariant linear layers using the partition algebra, which can be computed in time linear and quadratic in the input size, respectively. The effectiveness of the approach is demonstrated on several benchmark datasets.
&lt;/p&gt;
&lt;p&gt;
&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#23618;&#65292;&#26080;&#35770;&#26159;&#31561;&#21464;&#36824;&#26159;&#19981;&#21464;&#20110;&#20854;&#36755;&#20837;&#30340;&#25490;&#21015;&#65292;&#37117;&#26159;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#30340;&#26680;&#24515;&#26500;&#24314;&#22359;&#12290;&#20363;&#22914;DeepSets&#30340;&#23618;&#65292;&#20197;&#21450;&#20986;&#29616;&#22312;transformers&#21644;&#19968;&#20123;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#27880;&#24847;&#21147;&#22359;&#20013;&#30340;&#32447;&#24615;&#23618;&#12290;&#32622;&#25442;&#31561;&#21464;&#32447;&#24615;&#23618;&#30340;&#31354;&#38388;&#21487;&#20197;&#34987;&#35782;&#21035;&#20026;&#26576;&#20010;&#23545;&#31216;&#32676;&#34920;&#31034;&#30340;&#19981;&#21464;&#23376;&#31354;&#38388;&#65292;&#24182;&#19988;&#26368;&#36817;&#30340;&#24037;&#20316;&#36890;&#36807;&#23637;&#31034;&#19968;&#32452;&#22522;&#30784;&#65292;&#20854;&#21521;&#37327;&#26159;&#26631;&#20934;&#22522;&#30784;&#20803;&#32032;&#22312;&#23545;&#31216;&#32676;&#20316;&#29992;&#19979;&#36712;&#36947;&#30340;&#24635;&#21644;&#65292;&#26469;&#21442;&#25968;&#21270;&#36825;&#20010;&#31354;&#38388;&#12290;&#21442;&#25968;&#21270;&#25171;&#24320;&#20102;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#32622;&#25442;&#31561;&#21464;&#32447;&#24615;&#23618;&#26435;&#37325;&#30340;&#21487;&#33021;&#24615;&#12290;&#32622;&#25442;&#31561;&#21464;&#32447;&#24615;&#23618;&#30340;&#31354;&#38388;&#26159;&#20998;&#21306;&#20195;&#25968;&#30340;&#19968;&#33324;&#21270;&#65292;&#36825;&#26159;&#19968;&#31181;&#22312;&#32479;&#35745;&#29289;&#29702;&#23398;&#20013;&#39318;&#27425;&#21457;&#29616;&#30340;&#23545;&#35937;&#65292;&#19982;&#23545;&#31216;&#32676;&#30340;&#34920;&#31034;&#35770;&#26377;&#30528;&#28145;&#21051;&#30340;&#32852;&#31995;&#65292;&#32780;&#19978;&#36848;&#22522;&#30784;&#19982;&#20998;&#21306;&#20195;&#25968;&#30340;&#22522;&#30784;&#23494;&#20999;&#30456;&#20851;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#36825;&#31181;&#32852;&#31995;&#65292;&#22312;&#36755;&#20837;&#22823;&#23567;&#30340;&#32447;&#24615;&#26102;&#38388;&#20869;&#35745;&#31639;&#32622;&#25442;&#31561;&#21464;&#32447;&#24615;&#23618;&#30340;&#36755;&#20986;&#65292;&#24182;&#22312;&#36755;&#20837;&#22823;&#23567;&#30340;&#20108;&#27425;&#26102;&#38388;&#20869;&#35745;&#31639;&#25439;&#22833;&#30456;&#23545;&#20110;&#26435;&#37325;&#30340;&#26799;&#24230;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#19968;&#31181;&#35745;&#31639;&#20998;&#21306;&#20195;&#25968;&#22312;&#21521;&#37327;&#19978;&#20316;&#29992;&#30340;&#26032;&#31639;&#27861;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#8220;&#20998;&#21306;&#21367;&#31215;&#8221;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20998;&#21306;&#21367;&#31215;&#21487;&#20197;&#22312;&#36755;&#20837;&#21521;&#37327;&#22823;&#23567;&#30340;&#32447;&#24615;&#26102;&#38388;&#20869;&#35745;&#31639;&#65292;&#24182;&#19988;&#21487;&#20197;&#29992;&#20110;&#22312;&#36755;&#20837;&#22823;&#23567;&#30340;&#32447;&#24615;&#21644;&#20108;&#27425;&#26102;&#38388;&#20869;&#35745;&#31639;&#32622;&#25442;&#31561;&#21464;&#32447;&#24615;&#23618;&#30340;&#36755;&#20986;&#21644;&#26799;&#24230;&#65292;&#20998;&#21035;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#20998;&#21306;&#21367;&#31215;&#26469;&#35745;&#31639;&#26576;&#20123;&#38750;&#32447;&#24615;&#32622;&#25442;&#31561;&#21464;&#23618;&#30340;&#36755;&#20986;&#21644;&#26799;&#24230;&#65292;&#24182;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Linear neural network layers that are either equivariant or invariant to permutations of their inputs form core building blocks of modern deep learning architectures. Examples include the layers of DeepSets, as well as linear layers occurring in attention blocks of transformers and some graph neural networks. The space of permutation equivariant linear layers can be identified as the invariant subspace of a certain symmetric group representation, and recent work parameterized this space by exhibiting a basis whose vectors are sums over orbits of standard basis elements with respect to the symmetric group action. A parameterization opens up the possibility of learning the weights of permutation equivariant linear layers via gradient descent. The space of permutation equivariant linear layers is a generalization of the partition algebra, an object first discovered in statistical physics with deep connections to the representation theory of the symmetric group, and the basis described abo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;&#32553;&#20943;&#24322;&#26041;&#24046;PCA&#65292;&#23427;&#22312;&#20811;&#26381;&#30149;&#24577;&#38382;&#39064;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#21644;&#26080;&#26465;&#20214;&#25968;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2303.06198</link><description>&lt;p&gt;
&#20811;&#26381;&#24322;&#26041;&#24046;PCA&#20013;&#30149;&#24577;&#38382;&#39064;&#30340;&#32553;&#20943;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Deflated HeteroPCA: Overcoming the curse of ill-conditioning in heteroskedastic PCA. (arXiv:2303.06198v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06198
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;&#32553;&#20943;&#24322;&#26041;&#24046;PCA&#65292;&#23427;&#22312;&#20811;&#26381;&#30149;&#24577;&#38382;&#39064;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#21644;&#26080;&#26465;&#20214;&#25968;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a novel algorithm, called Deflated-HeteroPCA, that overcomes the curse of ill-conditioning in heteroskedastic PCA while achieving near-optimal and condition-number-free theoretical guarantees.
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#20110;&#20174;&#21463;&#27745;&#26579;&#30340;&#25968;&#25454;&#20013;&#20272;&#35745;&#20302;&#31209;&#30697;&#38453;X*&#30340;&#21015;&#23376;&#31354;&#38388;&#12290;&#24403;&#23384;&#22312;&#24322;&#26041;&#24046;&#22122;&#22768;&#21644;&#19981;&#24179;&#34913;&#30340;&#32500;&#24230;&#65288;&#21363;n2 &gt;&gt; n1&#65289;&#26102;&#65292;&#22914;&#20309;&#22312;&#23481;&#32435;&#26368;&#24191;&#27867;&#30340;&#20449;&#22122;&#27604;&#33539;&#22260;&#30340;&#21516;&#26102;&#33719;&#24471;&#26368;&#20339;&#30340;&#32479;&#35745;&#31934;&#24230;&#21464;&#24471;&#29305;&#21035;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#34429;&#28982;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;HeteroPCA&#25104;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#24378;&#26377;&#21147;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#23427;&#36973;&#21463;&#20102;&#8220;&#30149;&#24577;&#38382;&#39064;&#30340;&#35781;&#21650;&#8221;&#65292;&#21363;&#38543;&#30528;X*&#30340;&#26465;&#20214;&#25968;&#22686;&#38271;&#65292;&#20854;&#24615;&#33021;&#20250;&#19979;&#38477;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#20851;&#38190;&#38382;&#39064;&#32780;&#19981;&#24433;&#21709;&#20801;&#35768;&#30340;&#20449;&#22122;&#27604;&#33539;&#22260;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;&#32553;&#20943;&#24322;&#26041;&#24046;PCA&#65292;&#23427;&#22312;$\ell_2$&#21644;$\ell_{2,\infty}$&#32479;&#35745;&#31934;&#24230;&#26041;&#38754;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#21644;&#26080;&#26465;&#20214;&#25968;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#23558;&#35889;&#20998;&#25104;&#20004;&#37096;&#20998;
&lt;/p&gt;
&lt;p&gt;
This paper is concerned with estimating the column subspace of a low-rank matrix $\boldsymbol{X}^\star \in \mathbb{R}^{n_1\times n_2}$ from contaminated data. How to obtain optimal statistical accuracy while accommodating the widest range of signal-to-noise ratios (SNRs) becomes particularly challenging in the presence of heteroskedastic noise and unbalanced dimensionality (i.e., $n_2\gg n_1$). While the state-of-the-art algorithm $\textsf{HeteroPCA}$ emerges as a powerful solution for solving this problem, it suffers from "the curse of ill-conditioning," namely, its performance degrades as the condition number of $\boldsymbol{X}^\star$ grows. In order to overcome this critical issue without compromising the range of allowable SNRs, we propose a novel algorithm, called $\textsf{Deflated-HeteroPCA}$, that achieves near-optimal and condition-number-free theoretical guarantees in terms of both $\ell_2$ and $\ell_{2,\infty}$ statistical accuracy. The proposed algorithm divides the spectrum
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;DP-Fast MH&#31639;&#27861;&#65292;&#29992;&#20110;&#22823;&#35268;&#27169;&#36125;&#21494;&#26031;&#25512;&#26029;&#65292;&#20855;&#26377;&#31934;&#30830;&#12289;&#24555;&#36895;&#21644;&#38544;&#31169;&#20445;&#25252;&#30340;&#29305;&#28857;&#12290;</title><link>http://arxiv.org/abs/2303.06171</link><description>&lt;p&gt;
DP-Fast MH: &#22823;&#35268;&#27169;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#31169;&#26377;&#12289;&#24555;&#36895;&#12289;&#20934;&#30830;&#30340;Metropolis-Hastings&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
DP-Fast MH: Private, Fast, and Accurate Metropolis-Hastings for Large-Scale Bayesian Inference. (arXiv:2303.06171v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06171
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;DP-Fast MH&#31639;&#27861;&#65292;&#29992;&#20110;&#22823;&#35268;&#27169;&#36125;&#21494;&#26031;&#25512;&#26029;&#65292;&#20855;&#26377;&#31934;&#30830;&#12289;&#24555;&#36895;&#21644;&#38544;&#31169;&#20445;&#25252;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a new DP-Fast MH algorithm for large-scale Bayesian inference, which is accurate, fast, and privacy-preserving.
&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#25512;&#26029;&#25552;&#20379;&#20102;&#19968;&#20010;&#20174;&#22797;&#26434;&#25968;&#25454;&#20013;&#23398;&#20064;&#21644;&#22312;&#19981;&#30830;&#23450;&#24615;&#19979;&#25512;&#29702;&#30340;&#21407;&#21017;&#24615;&#26694;&#26550;&#12290;&#23427;&#24050;&#32463;&#24191;&#27867;&#24212;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#22914;&#21307;&#23398;&#35786;&#26029;&#12289;&#33647;&#29289;&#35774;&#35745;&#21644;&#25919;&#31574;&#21046;&#23450;&#12290;&#22312;&#36825;&#20123;&#24120;&#35265;&#24212;&#29992;&#20013;&#65292;&#25968;&#25454;&#21487;&#33021;&#38750;&#24120;&#25935;&#24863;&#12290;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#25552;&#20379;&#20102;&#20855;&#26377;&#24378;&#22823;&#26368;&#22351;&#24773;&#20917;&#38544;&#31169;&#20445;&#35777;&#30340;&#25968;&#25454;&#20998;&#26512;&#24037;&#20855;&#65292;&#24182;&#24050;&#21457;&#23637;&#25104;&#20026;&#38544;&#31169;&#20445;&#25252;&#25968;&#25454;&#20998;&#26512;&#30340;&#20027;&#35201;&#26041;&#27861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;Metropolis-Hastings&#65288;MH&#65289;&#31639;&#27861;&#65292;&#36825;&#26159;&#26368;&#22522;&#26412;&#30340;MCMC&#26041;&#27861;&#20043;&#19968;&#65292;&#29992;&#20110;&#24046;&#20998;&#38544;&#31169;&#19979;&#30340;&#22823;&#35268;&#27169;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;&#34429;&#28982;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#31169;&#26377;MCMC&#31639;&#27861;&#20026;&#20102;&#33719;&#24471;&#38544;&#31169;&#32780;&#29306;&#29298;&#20102;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#65292;&#20294;&#25105;&#20204;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#31934;&#30830;&#19988;&#24555;&#36895;&#30340;DP MH&#31639;&#27861;&#65292;&#22823;&#22810;&#25968;&#36845;&#20195;&#20013;&#20165;&#20351;&#29992;&#19968;&#20010;&#23567;&#25209;&#37327;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25581;&#31034;&#20102;&#38544;&#31169;&#12289;&#21487;&#25193;&#23637;&#24615;&#65288;&#21363;&#25209;&#37327;&#22823;&#23567;&#65289;&#21644;&#25928;&#29575;&#65288;&#21363;&#25910;&#25947;&#36895;&#24230;&#65289;&#20043;&#38388;&#30340;&#19977;&#37325;&#26435;&#34913;&#65292;&#20174;&#29702;&#35770;&#19978;&#35828;&#26126;&#20102;&#36825;&#19968;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian inference provides a principled framework for learning from complex data and reasoning under uncertainty. It has been widely applied in machine learning tasks such as medical diagnosis, drug design, and policymaking. In these common applications, the data can be highly sensitive. Differential privacy (DP) offers data analysis tools with powerful worst-case privacy guarantees and has been developed as the leading approach in privacy-preserving data analysis. In this paper, we study Metropolis-Hastings (MH), one of the most fundamental MCMC methods, for large-scale Bayesian inference under differential privacy. While most existing private MCMC algorithms sacrifice accuracy and efficiency to obtain privacy, we provide the first exact and fast DP MH algorithm, using only a minibatch of data in most iterations. We further reveal, for the first time, a three-way trade-off among privacy, scalability (i.e. the batch size), and efficiency (i.e. the convergence rate), theoretically char
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#38480;&#21046;&#26410;&#27979;&#37327;&#28151;&#26434;&#19979;&#30340;&#21463;&#30410;&#21644;&#20260;&#23475;&#27010;&#29575;&#65292;&#19968;&#31181;&#26159;&#36890;&#36807;&#25935;&#24863;&#24615;&#21442;&#25968;&#35745;&#31639;&#27010;&#29575;&#30340;&#19978;&#38480;&#25110;&#19979;&#38480;&#65292;&#21478;&#19968;&#31181;&#26159;&#21033;&#29992;&#20195;&#29702;&#21464;&#37327;&#24471;&#21040;&#26356;&#32039;&#30340;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2303.05396</link><description>&lt;p&gt;
&#36890;&#36807;&#25935;&#24863;&#24615;&#21442;&#25968;&#21644;&#20195;&#29702;&#21464;&#37327;&#38480;&#21046;&#21463;&#30410;&#21644;&#20260;&#23475;&#30340;&#27010;&#29575;
&lt;/p&gt;
&lt;p&gt;
Bounding the Probabilities of Benefit and Harm Through Sensitivity Parameters and Proxies. (arXiv:2303.05396v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.05396
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#38480;&#21046;&#26410;&#27979;&#37327;&#28151;&#26434;&#19979;&#30340;&#21463;&#30410;&#21644;&#20260;&#23475;&#27010;&#29575;&#65292;&#19968;&#31181;&#26159;&#36890;&#36807;&#25935;&#24863;&#24615;&#21442;&#25968;&#35745;&#31639;&#27010;&#29575;&#30340;&#19978;&#38480;&#25110;&#19979;&#38480;&#65292;&#21478;&#19968;&#31181;&#26159;&#21033;&#29992;&#20195;&#29702;&#21464;&#37327;&#24471;&#21040;&#26356;&#32039;&#30340;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents two methods for bounding the probabilities of benefit and harm under unmeasured confounding, one is to compute the upper or lower bound of the probability through sensitivity parameters, and the other is to derive tighter bounds using a measured nondifferential proxy of the unmeasured confounder.
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#38480;&#21046;&#26410;&#27979;&#37327;&#28151;&#26434;&#19979;&#30340;&#21463;&#30410;&#21644;&#20260;&#23475;&#27010;&#29575;&#12290;&#31532;&#19968;&#31181;&#26041;&#27861;&#35745;&#31639;&#20219;&#19968;&#27010;&#29575;&#30340;&#65288;&#19978;&#38480;&#25110;&#19979;&#38480;&#65289;&#65292;&#20316;&#20026;&#35266;&#23519;&#25968;&#25454;&#20998;&#24067;&#21644;&#20004;&#20010;&#30452;&#35266;&#25935;&#24863;&#24615;&#21442;&#25968;&#30340;&#20989;&#25968;&#65292;&#28982;&#21518;&#21487;&#20197;&#23558;&#20854;&#21576;&#29616;&#32473;&#20998;&#26512;&#24072;&#20316;&#20026;2-D&#22270;&#20197;&#21327;&#21161;&#20854;&#20915;&#31574;&#12290;&#31532;&#20108;&#31181;&#26041;&#27861;&#20551;&#35774;&#23384;&#22312;&#26410;&#27979;&#37327;&#28151;&#26434;&#22240;&#32032;&#30340;&#27979;&#37327;&#38750;&#24046;&#24322;&#20195;&#29702;&#21464;&#37327;&#65288;&#21363;&#30452;&#25509;&#25928;&#24212;&#65289;&#12290;&#20351;&#29992;&#27492;&#20195;&#29702;&#21464;&#37327;&#65292;&#21487;&#20197;&#20174;&#20165;&#35266;&#23519;&#21040;&#30340;&#25968;&#25454;&#20998;&#24067;&#20013;&#23548;&#20986;&#27604;&#29616;&#26377;&#30028;&#38480;&#26356;&#32039;&#30340;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present two methods for bounding the probabilities of benefit and harm under unmeasured confounding. The first method computes the (upper or lower) bound of either probability as a function of the observed data distribution and two intuitive sensitivity parameters which, then, can be presented to the analyst as a 2-D plot to assist her in decision making. The second method assumes the existence of a measured nondifferential proxy (i.e., direct effect) of the unmeasured confounder. Using this proxy, tighter bounds than the existing ones can be derived from just the observed data distribution.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Fisher&#20449;&#24687;&#30340;&#35777;&#25454;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#25968;&#25454;&#19981;&#30830;&#23450;&#24615;&#26679;&#26412;&#20294;&#27880;&#37322;&#20026;one-hot&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#35777;&#25454;&#23398;&#20064;&#36807;&#31243;&#34987;&#36807;&#24230;&#24809;&#32602;&#24182;&#21463;&#21040;&#38459;&#30861;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2303.02045</link><description>&lt;p&gt;
&#22522;&#20110;Fisher&#20449;&#24687;&#30340;&#35777;&#25454;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#29992;&#20110;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Uncertainty Estimation by Fisher Information-based Evidential Deep Learning. (arXiv:2303.02045v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.02045
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Fisher&#20449;&#24687;&#30340;&#35777;&#25454;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#25968;&#25454;&#19981;&#30830;&#23450;&#24615;&#26679;&#26412;&#20294;&#27880;&#37322;&#20026;one-hot&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#35777;&#25454;&#23398;&#20064;&#36807;&#31243;&#34987;&#36807;&#24230;&#24809;&#32602;&#24182;&#21463;&#21040;&#38459;&#30861;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a Fisher Information-based Evidential Deep Learning method to address the problem of over-penalization and hindrance in evidence learning for high data uncertainty samples annotated with one-hot labels.
&lt;/p&gt;
&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#26159;&#20351;&#28145;&#24230;&#23398;&#20064;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#21487;&#38752;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;&#26368;&#36817;&#25552;&#20986;&#30340;&#35777;&#25454;&#31070;&#32463;&#32593;&#32476;&#36890;&#36807;&#23558;&#32593;&#32476;&#36755;&#20986;&#35270;&#20026;&#35777;&#25454;&#26469;&#21442;&#25968;&#21270;&#29380;&#21033;&#20811;&#38647;&#20998;&#24067;&#65292;&#26126;&#30830;&#32771;&#34385;&#19981;&#21516;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#22312;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#26041;&#38754;&#21462;&#24471;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#39640;&#25968;&#25454;&#19981;&#30830;&#23450;&#24615;&#26679;&#26412;&#20294;&#27880;&#37322;&#20026;one-hot&#26631;&#31614;&#30340;&#24773;&#20917;&#65292;&#36825;&#20123;&#38169;&#35823;&#26631;&#35760;&#30340;&#31867;&#21035;&#30340;&#35777;&#25454;&#23398;&#20064;&#36807;&#31243;&#20250;&#34987;&#36807;&#24230;&#24809;&#32602;&#24182;&#21463;&#21040;&#38459;&#30861;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#22522;&#20110;Fisher&#20449;&#24687;&#30340;&#35777;&#25454;&#28145;&#24230;&#23398;&#20064;&#65288;$\mathcal{I}$-EDL&#65289;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#24341;&#20837;Fisher&#20449;&#24687;&#30697;&#38453;&#65288;FIM&#65289;&#26469;&#34913;&#37327;&#27599;&#20010;&#26679;&#26412;&#25152;&#25658;&#24102;&#30340;&#35777;&#25454;&#30340;&#20449;&#24687;&#37327;&#65292;&#26681;&#25454;&#36825;&#20010;&#20449;&#24687;&#37327;&#65292;&#25105;&#20204;&#21487;&#20197;&#21160;&#24577;&#22320;&#37325;&#26032;&#21152;&#26435;&#30446;&#26631;&#25439;&#22833;&#39033;&#65292;&#20351;&#32593;&#32476;&#26356;&#21152;&#19987;&#27880;&#20110;&#19981;&#30830;&#23450;&#31867;&#21035;&#30340;&#34920;&#31034;&#23398;&#20064;&#12290;&#25105;&#20204;&#30340;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#36890;&#36807;&#20248;&#21270;&#36827;&#19968;&#27493;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainty estimation is a key factor that makes deep learning reliable in practical applications. Recently proposed evidential neural networks explicitly account for different uncertainties by treating the network's outputs as evidence to parameterize the Dirichlet distribution, and achieve impressive performance in uncertainty estimation. However, for high data uncertainty samples but annotated with the one-hot label, the evidence-learning process for those mislabeled classes is over-penalized and remains hindered. To address this problem, we propose a novel method, Fisher Information-based Evidential Deep Learning ($\mathcal{I}$-EDL). In particular, we introduce Fisher Information Matrix (FIM) to measure the informativeness of evidence carried by each sample, according to which we can dynamically reweight the objective loss terms to make the network more focused on the representation learning of uncertain classes. The generalization ability of our network is further improved by opt
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22312;&#21487;&#27979;&#35797;&#23398;&#20064;&#27169;&#22411;&#20013;&#23398;&#20064;&#21322;&#31354;&#38388;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#36816;&#34892;&#65292;&#24182;&#36755;&#20986;&#19968;&#20010;&#22312;&#20219;&#20309;&#24378;&#23545;&#25968;&#20985;&#30446;&#26631;&#20998;&#24067;&#19979;&#20855;&#26377;&#65288;&#20449;&#24687;&#29702;&#35770;&#19978;&#26368;&#20248;&#30340;&#65289;&#35823;&#24046;&#30340;&#20551;&#35774;&#12290;</title><link>http://arxiv.org/abs/2302.14853</link><description>&lt;p&gt;
&#21322;&#31354;&#38388;&#30340;&#39640;&#25928;&#27979;&#35797;&#23398;&#20064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Efficient Tester-Learner for Halfspaces. (arXiv:2302.14853v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.14853
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22312;&#21487;&#27979;&#35797;&#23398;&#20064;&#27169;&#22411;&#20013;&#23398;&#20064;&#21322;&#31354;&#38388;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#36816;&#34892;&#65292;&#24182;&#36755;&#20986;&#19968;&#20010;&#22312;&#20219;&#20309;&#24378;&#23545;&#25968;&#20985;&#30446;&#26631;&#20998;&#24067;&#19979;&#20855;&#26377;&#65288;&#20449;&#24687;&#29702;&#35770;&#19978;&#26368;&#20248;&#30340;&#65289;&#35823;&#24046;&#30340;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose the first efficient algorithm for learning halfspaces in the testable learning model, which runs in polynomial time and outputs a hypothesis with (information-theoretically optimal) error for any strongly log-concave target distribution.
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22312;Rubinfeld&#21644;Vasilyan&#65288;2023&#65289;&#26368;&#36817;&#23450;&#20041;&#30340;&#21487;&#27979;&#35797;&#23398;&#20064;&#27169;&#22411;&#20013;&#23398;&#20064;&#21322;&#31354;&#38388;&#30340;&#39640;&#25928;&#31639;&#27861;&#12290;&#22312;&#36825;&#20010;&#27169;&#22411;&#20013;&#65292;&#24403;&#35757;&#32451;&#38598;&#36890;&#36807;&#30456;&#20851;&#27979;&#35797;&#26102;&#65292;&#23398;&#20064;&#32773;&#35777;&#26126;&#20854;&#36755;&#20986;&#20551;&#35774;&#30340;&#20934;&#30830;&#24615;&#25509;&#36817;&#26368;&#20248;&#65292;&#24182;&#19988;&#20174;&#26576;&#20123;&#30446;&#26631;&#20998;&#24067;&#65288;&#20363;&#22914;&#39640;&#26031;&#20998;&#24067;&#65289;&#20013;&#25277;&#21462;&#30340;&#35757;&#32451;&#38598;&#24517;&#39035;&#36890;&#36807;&#27979;&#35797;&#12290;&#36825;&#20010;&#27169;&#22411;&#27604;&#20998;&#24067;&#29305;&#23450;&#30340;&#19981;&#21487;&#30693;&#25110;Massart&#22122;&#22768;&#27169;&#22411;&#26356;&#20855;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#22914;&#26524;&#20998;&#24067;&#20551;&#35774;&#19981;&#25104;&#31435;&#65292;&#23398;&#20064;&#32773;&#21487;&#20197;&#20219;&#24847;&#22833;&#36133;&#12290;&#25105;&#20204;&#32771;&#34385;&#30446;&#26631;&#20998;&#24067;&#20026;&#39640;&#26031;&#20998;&#24067;&#65288;&#25110;&#26356;&#19968;&#33324;&#30340;&#20219;&#20309;&#24378;&#23545;&#25968;&#20985;&#20998;&#24067;&#65289;&#30340;$d$&#32500;&#24773;&#20917;&#65292;&#22122;&#22768;&#27169;&#22411;&#20026;Massart&#25110;&#23545;&#25239;&#24615;&#65288;&#19981;&#21487;&#30693;&#65289;&#12290;&#23545;&#20110;Massart&#22122;&#22768;&#65292;&#25105;&#20204;&#30340;&#27979;&#35797;&#23398;&#20064;&#31639;&#27861;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#36816;&#34892;&#65292;&#24182;&#36755;&#20986;&#19968;&#20010;&#22312;&#20219;&#20309;&#24378;&#23545;&#25968;&#20985;&#30446;&#26631;&#20998;&#24067;&#19979;&#20855;&#26377;&#65288;&#20449;&#24687;&#29702;&#35770;&#19978;&#26368;&#20248;&#30340;&#65289;&#35823;&#24046;$\mathsf{opt}+\epsilon$&#30340;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
We give the first efficient algorithm for learning halfspaces in the testable learning model recently defined by Rubinfeld and Vasilyan (2023). In this model, a learner certifies that the accuracy of its output hypothesis is near optimal whenever the training set passes an associated test, and training sets drawn from some target distribution -- e.g., the Gaussian -- must pass the test. This model is more challenging than distribution-specific agnostic or Massart noise models where the learner is allowed to fail arbitrarily if the distributional assumption does not hold.  We consider the setting where the target distribution is Gaussian (or more generally any strongly log-concave distribution) in $d$ dimensions and the noise model is either Massart or adversarial (agnostic). For Massart noise, our tester-learner runs in polynomial time and outputs a hypothesis with (information-theoretically optimal) error $\mathsf{opt} + \epsilon$ for any strongly log-concave target distribution. For 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#24809;&#32602;&#30340;&#21452;&#23618;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#19979;&#23618;&#38750;&#24378;&#20984;&#32422;&#26463;&#21452;&#23618;&#38382;&#39064;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#31639;&#27861;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2302.05185</link><description>&lt;p&gt;
&#22522;&#20110;&#24809;&#32602;&#30340;&#21452;&#23618;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Penalty-based Bilevel Gradient Descent Method. (arXiv:2302.05185v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05185
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#24809;&#32602;&#30340;&#21452;&#23618;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#19979;&#23618;&#38750;&#24378;&#20984;&#32422;&#26463;&#21452;&#23618;&#38382;&#39064;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#31639;&#27861;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a penalty-based bilevel gradient descent algorithm to solve the constrained bilevel problem without lower-level strong convexity, and experiments show its efficiency.
&lt;/p&gt;
&lt;p&gt;
&#21452;&#23618;&#20248;&#21270;&#22312;&#36229;&#21442;&#25968;&#20248;&#21270;&#12289;&#20803;&#23398;&#20064;&#21644;&#24378;&#21270;&#23398;&#20064;&#31561;&#39046;&#22495;&#26377;&#24191;&#27867;&#24212;&#29992;&#65292;&#20294;&#26159;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#38590;&#20197;&#35299;&#20915;&#12290;&#26368;&#36817;&#30340;&#21487;&#25193;&#23637;&#21452;&#23618;&#31639;&#27861;&#20027;&#35201;&#38598;&#20013;&#22312;&#19979;&#23618;&#30446;&#26631;&#20989;&#25968;&#26159;&#24378;&#20984;&#25110;&#26080;&#32422;&#26463;&#30340;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#19978;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#24809;&#32602;&#26041;&#27861;&#26469;&#35299;&#20915;&#21452;&#23618;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#65292;&#24809;&#32602;&#37325;&#26500;&#21487;&#20197;&#24674;&#22797;&#21407;&#22987;&#21452;&#23618;&#38382;&#39064;&#30340;&#35299;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#24809;&#32602;&#30340;&#21452;&#23618;&#26799;&#24230;&#19979;&#38477;&#65288;PBGD&#65289;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#22312;&#19979;&#23618;&#38750;&#24378;&#20984;&#32422;&#26463;&#21452;&#23618;&#38382;&#39064;&#19978;&#30340;&#26377;&#38480;&#26102;&#38388;&#25910;&#25947;&#24615;&#12290;&#23454;&#39564;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;PBGD&#31639;&#27861;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bilevel optimization enjoys a wide range of applications in hyper-parameter optimization, meta-learning and reinforcement learning. However, bilevel optimization problems are difficult to solve. Recent progress on scalable bilevel algorithms mainly focuses on bilevel optimization problems where the lower-level objective is either strongly convex or unconstrained. In this work, we tackle the bilevel problem through the lens of the penalty method. We show that under certain conditions, the penalty reformulation recovers the solutions of the original bilevel problem. Further, we propose the penalty-based bilevel gradient descent (PBGD) algorithm and establish its finite-time convergence for the constrained bilevel problem without lower-level strong convexity. Experiments showcase the efficiency of the proposed PBGD algorithm.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;LASSO&#30340;&#24191;&#20041;&#19981;&#21464;&#21305;&#37197;&#24615;&#36136;&#65292;&#36890;&#36807;&#21046;&#23450;&#20855;&#26377;&#20869;&#22312;&#31232;&#30095;&#24615;&#30340;&#39640;&#32500;&#38382;&#39064;&#65292;&#23558;&#19981;&#21464;&#21305;&#37197;&#24615;&#36136;&#25512;&#24191;&#21040;&#20165;&#30446;&#26631;&#34987;&#24178;&#39044;&#30340;&#37325;&#35201;&#24773;&#20917;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#21152;&#31283;&#20581;&#21644;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#31639;&#27861;&#65292;&#25913;&#36827;&#20102;&#29616;&#26377;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2301.05975</link><description>&lt;p&gt;
&#22522;&#20110;LASSO&#30340;&#24191;&#20041;&#19981;&#21464;&#21305;&#37197;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;
Generalized Invariant Matching Property via LASSO. (arXiv:2301.05975v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.05975
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;LASSO&#30340;&#24191;&#20041;&#19981;&#21464;&#21305;&#37197;&#24615;&#36136;&#65292;&#36890;&#36807;&#21046;&#23450;&#20855;&#26377;&#20869;&#22312;&#31232;&#30095;&#24615;&#30340;&#39640;&#32500;&#38382;&#39064;&#65292;&#23558;&#19981;&#21464;&#21305;&#37197;&#24615;&#36136;&#25512;&#24191;&#21040;&#20165;&#30446;&#26631;&#34987;&#24178;&#39044;&#30340;&#37325;&#35201;&#24773;&#20917;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#21152;&#31283;&#20581;&#21644;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#31639;&#27861;&#65292;&#25913;&#36827;&#20102;&#29616;&#26377;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a generalized invariant matching property via LASSO, which formulates a high-dimensional problem with intrinsic sparsity and extends the invariant matching property to the important setting when only the target is intervened. The paper also presents a more robust and computation-efficient algorithm by leveraging a variant of Lasso, improving upon the existing algorithms.
&lt;/p&gt;
&lt;p&gt;
&#22312;&#20998;&#24067;&#21464;&#21270;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#23398;&#20064;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#19968;&#31181;&#22522;&#26412;&#30340;&#26041;&#27861;&#26159;&#36890;&#36807;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#21033;&#29992;&#19981;&#21464;&#24615;&#21407;&#21017;&#12290;&#28982;&#32780;&#65292;&#24403;&#21709;&#24212;&#34987;&#24178;&#39044;&#26102;&#65292;&#19981;&#21464;&#24615;&#21407;&#21017;&#34987;&#36829;&#21453;&#65292;&#20351;&#24471;&#36825;&#31181;&#24773;&#20917;&#21464;&#24471;&#22256;&#38590;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#24320;&#21457;&#20102;&#19981;&#21464;&#21305;&#37197;&#24615;&#36136;&#26469;&#30740;&#31350;&#36825;&#31181;&#24773;&#20917;&#65292;&#24182;&#26174;&#31034;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#36890;&#36807;&#21046;&#23450;&#20855;&#26377;&#20869;&#22312;&#31232;&#30095;&#24615;&#30340;&#39640;&#32500;&#38382;&#39064;&#65292;&#25105;&#20204;&#23558;&#19981;&#21464;&#21305;&#37197;&#24615;&#36136;&#25512;&#24191;&#21040;&#20165;&#30446;&#26631;&#34987;&#24178;&#39044;&#30340;&#37325;&#35201;&#24773;&#20917;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#21152;&#31283;&#20581;&#21644;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#31639;&#27861;&#65292;&#21033;&#29992;Lasso&#30340;&#21464;&#20307;&#65292;&#25913;&#36827;&#20102;&#29616;&#26377;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning under distribution shifts is a challenging task. One principled approach is to exploit the invariance principle via the structural causal models. However, the invariance principle is violated when the response is intervened, making it a difficult setting. In a recent work, the invariant matching property has been developed to shed light on this scenario and shows promising performance. In this work, by formulating a high-dimensional problem with intrinsic sparsity, we generalize the invariant matching property for an important setting when only the target is intervened. We propose a more robust and computation-efficient algorithm by leveraging a variant of Lasso, improving upon the existing algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#21160;&#21147;&#31995;&#32479;&#29702;&#35770;&#20013;&#30340;&#20960;&#20010;&#24037;&#20855;&#26469;&#35299;&#20915;&#38750;&#20984;&#37319;&#26679;&#20013;&#30340;&#37325;&#35201;&#25361;&#25112;&#12290;&#23545;&#20110;&#19968;&#22823;&#31867;&#26368;&#20808;&#36827;&#30340;&#37319;&#26679;&#26041;&#26696;&#65292;&#23427;&#20204;&#22312;Wasserstein&#36317;&#31163;&#19979;&#30340;&#26368;&#21518;&#36845;&#20195;&#25910;&#25947;&#21487;&#20197;&#24402;&#32467;&#20026;&#23545;&#23427;&#20204;&#30340;&#36830;&#32493;&#26102;&#38388;&#23545;&#24212;&#29289;&#30340;&#30740;&#31350;&#65292;&#36825;&#26159;&#26356;&#22909;&#29702;&#35299;&#30340;&#12290;</title><link>http://arxiv.org/abs/2210.13867</link><description>&lt;p&gt;
Langevin-Based Non-Convex Sampling&#30340;&#21160;&#21147;&#23398;&#31995;&#32479;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
A Dynamical System View of Langevin-Based Non-Convex Sampling. (arXiv:2210.13867v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.13867
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#21160;&#21147;&#31995;&#32479;&#29702;&#35770;&#20013;&#30340;&#20960;&#20010;&#24037;&#20855;&#26469;&#35299;&#20915;&#38750;&#20984;&#37319;&#26679;&#20013;&#30340;&#37325;&#35201;&#25361;&#25112;&#12290;&#23545;&#20110;&#19968;&#22823;&#31867;&#26368;&#20808;&#36827;&#30340;&#37319;&#26679;&#26041;&#26696;&#65292;&#23427;&#20204;&#22312;Wasserstein&#36317;&#31163;&#19979;&#30340;&#26368;&#21518;&#36845;&#20195;&#25910;&#25947;&#21487;&#20197;&#24402;&#32467;&#20026;&#23545;&#23427;&#20204;&#30340;&#36830;&#32493;&#26102;&#38388;&#23545;&#24212;&#29289;&#30340;&#30740;&#31350;&#65292;&#36825;&#26159;&#26356;&#22909;&#29702;&#35299;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a new framework that uses tools from the theory of dynamical systems to address important challenges in non-convex sampling. For a large class of state-of-the-art sampling schemes, their last-iterate convergence in Wasserstein distances can be reduced to the study of their continuous-time counterparts, which is much better understood.
&lt;/p&gt;
&lt;p&gt;
&#38750;&#20984;&#37319;&#26679;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#65292;&#23545;&#20110;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#38750;&#20984;&#20248;&#21270;&#20197;&#21450;&#36817;&#20284;&#27010;&#29575;&#25512;&#26029;&#37117;&#33267;&#20851;&#37325;&#35201;&#12290;&#23613;&#31649;&#20854;&#37325;&#35201;&#24615;&#65292;&#29702;&#35770;&#19978;&#20173;&#23384;&#22312;&#35768;&#22810;&#37325;&#35201;&#25361;&#25112;&#65306;&#29616;&#26377;&#30340;&#20445;&#35777;&#36890;&#24120;&#20165;&#36866;&#29992;&#20110;&#24179;&#22343;&#36845;&#20195;&#32780;&#19981;&#26159;&#26356;&#29702;&#24819;&#30340;&#26368;&#21518;&#36845;&#20195;&#65292;&#32570;&#20047;&#25429;&#25417;&#21464;&#37327;&#23610;&#24230;&#65288;&#22914;Wasserstein&#36317;&#31163;&#65289;&#30340;&#25910;&#25947;&#24230;&#37327;&#65292;&#20027;&#35201;&#36866;&#29992;&#20110;&#38543;&#26426;&#26799;&#24230;Langevin&#21160;&#21147;&#23398;&#31561;&#22522;&#26412;&#26041;&#26696;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#21160;&#21147;&#31995;&#32479;&#29702;&#35770;&#20013;&#30340;&#20960;&#20010;&#24037;&#20855;&#26469;&#35299;&#20915;&#19978;&#36848;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#32467;&#26524;&#26159;&#65292;&#23545;&#20110;&#19968;&#22823;&#31867;&#26368;&#20808;&#36827;&#30340;&#37319;&#26679;&#26041;&#26696;&#65292;&#23427;&#20204;&#22312;Wasserstein&#36317;&#31163;&#19979;&#30340;&#26368;&#21518;&#36845;&#20195;&#25910;&#25947;&#21487;&#20197;&#24402;&#32467;&#20026;&#23545;&#23427;&#20204;&#30340;&#36830;&#32493;&#26102;&#38388;&#23545;&#24212;&#29289;&#30340;&#30740;&#31350;&#65292;&#36825;&#26159;&#26356;&#22909;&#29702;&#35299;&#30340;&#12290;&#32467;&#21512;MCMC&#37319;&#26679;&#30340;&#26631;&#20934;&#20551;&#35774;&#65292;&#25105;&#20204;&#30340;&#29702;&#35770;&#31435;&#21363;&#20135;&#29983;&#20102;
&lt;/p&gt;
&lt;p&gt;
Non-convex sampling is a key challenge in machine learning, central to non-convex optimization in deep learning as well as to approximate probabilistic inference. Despite its significance, theoretically there remain many important challenges: Existing guarantees (1) typically only hold for the averaged iterates rather than the more desirable last iterates, (2) lack convergence metrics that capture the scales of the variables such as Wasserstein distances, and (3) mainly apply to elementary schemes such as stochastic gradient Langevin dynamics. In this paper, we develop a new framework that lifts the above issues by harnessing several tools from the theory of dynamical systems. Our key result is that, for a large class of state-of-the-art sampling schemes, their last-iterate convergence in Wasserstein distances can be reduced to the study of their continuous-time counterparts, which is much better understood. Coupled with standard assumptions of MCMC sampling, our theory immediately yie
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#24369;&#30417;&#30563;&#20449;&#24687;&#30340;&#26631;&#31614;&#20256;&#25773;&#31639;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#26410;&#26631;&#35760;&#25968;&#25454;&#19978;&#30340;&#27010;&#29575;&#20551;&#35774;&#26631;&#31614;&#65292;&#32467;&#21512;&#23616;&#37096;&#20960;&#20309;&#29305;&#24615;&#21644;&#20808;&#39564;&#20449;&#24687;&#30340;&#36136;&#37327;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#35823;&#24046;&#30028;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#21512;&#24182;&#22810;&#20010;&#22122;&#22768;&#20449;&#24687;&#28304;&#12290;&#22312;&#22810;&#20010;&#22522;&#20934;&#24369;&#30417;&#30563;&#20998;&#31867;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#26041;&#27861;&#30340;&#33021;&#21147;&#65292;&#26174;&#31034;&#20986;&#23545;&#29616;&#26377;&#21322;&#30417;&#30563;&#21644;&#24369;&#30417;&#30563;&#26041;&#27861;&#30340;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2210.03594</link><description>&lt;p&gt;
&#24369;&#30417;&#30563;&#19979;&#30340;&#26631;&#31614;&#20256;&#25773;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Label Propagation with Weak Supervision. (arXiv:2210.03594v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.03594
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#24369;&#30417;&#30563;&#20449;&#24687;&#30340;&#26631;&#31614;&#20256;&#25773;&#31639;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#26410;&#26631;&#35760;&#25968;&#25454;&#19978;&#30340;&#27010;&#29575;&#20551;&#35774;&#26631;&#31614;&#65292;&#32467;&#21512;&#23616;&#37096;&#20960;&#20309;&#29305;&#24615;&#21644;&#20808;&#39564;&#20449;&#24687;&#30340;&#36136;&#37327;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#35823;&#24046;&#30028;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#21512;&#24182;&#22810;&#20010;&#22122;&#22768;&#20449;&#24687;&#28304;&#12290;&#22312;&#22810;&#20010;&#22522;&#20934;&#24369;&#30417;&#30563;&#20998;&#31867;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#26041;&#27861;&#30340;&#33021;&#21147;&#65292;&#26174;&#31034;&#20986;&#23545;&#29616;&#26377;&#21322;&#30417;&#30563;&#21644;&#24369;&#30417;&#30563;&#26041;&#27861;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a label propagation algorithm that utilizes weak supervision information, specifically probabilistic hypothesized labels on the unlabeled data, and provides an error bound that exploits both the local geometric properties of the underlying graph and the quality of the prior information. The approach is demonstrated on multiple benchmark weakly supervised classification tasks, showing improvements upon existing semi-supervised and weakly supervised methods.
&lt;/p&gt;
&lt;p&gt;
&#21322;&#30417;&#30563;&#23398;&#20064;&#21644;&#24369;&#30417;&#30563;&#23398;&#20064;&#26159;&#24403;&#21069;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#26088;&#22312;&#20943;&#23569;&#26631;&#35760;&#25968;&#25454;&#38656;&#27714;&#30340;&#37325;&#35201;&#33539;&#24335;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#23545;&#32463;&#20856;&#26631;&#31614;&#20256;&#25773;&#31639;&#27861;&#65288;LPA&#65289;&#65288;Zhu&#65286;Ghahramani&#65292;2002&#65289;&#30340;&#20998;&#26512;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#20102;&#26377;&#29992;&#30340;&#20808;&#39564;&#20449;&#24687;&#65292;&#29305;&#21035;&#26159;&#26410;&#26631;&#35760;&#25968;&#25454;&#19978;&#30340;&#27010;&#29575;&#20551;&#35774;&#26631;&#31614;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#35823;&#24046;&#30028;&#65292;&#21033;&#29992;&#20102;&#24213;&#23618;&#22270;&#24418;&#30340;&#23616;&#37096;&#20960;&#20309;&#29305;&#24615;&#21644;&#20808;&#39564;&#20449;&#24687;&#30340;&#36136;&#37327;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#21512;&#24182;&#22810;&#20010;&#22122;&#22768;&#20449;&#24687;&#28304;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#24369;&#30417;&#30563;&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;&#25105;&#20204;&#30340;&#20449;&#24687;&#26469;&#28304;&#26159;&#24369;&#26631;&#35760;&#32773;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#22522;&#20934;&#24369;&#30417;&#30563;&#20998;&#31867;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#33021;&#21147;&#65292;&#26174;&#31034;&#20986;&#23545;&#29616;&#26377;&#21322;&#30417;&#30563;&#21644;&#24369;&#30417;&#30563;&#26041;&#27861;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Semi-supervised learning and weakly supervised learning are important paradigms that aim to reduce the growing demand for labeled data in current machine learning applications. In this paper, we introduce a novel analysis of the classical label propagation algorithm (LPA) (Zhu &amp; Ghahramani, 2002) that moreover takes advantage of useful prior information, specifically probabilistic hypothesized labels on the unlabeled data. We provide an error bound that exploits both the local geometric properties of the underlying graph and the quality of the prior information. We also propose a framework to incorporate multiple sources of noisy information. In particular, we consider the setting of weak supervision, where our sources of information are weak labelers. We demonstrate the ability of our approach on multiple benchmark weakly supervised classification tasks, showing improvements upon existing semi-supervised and weakly supervised methods.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20887;&#20313;&#37325;&#21442;&#25968;&#21270;&#21644;&#31616;&#21333;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26469;&#26368;&#23567;&#21270;&#24102;&#26377;$L_1$&#24809;&#32602;&#30340;&#36890;&#29992;&#21487;&#24494;&#25439;&#22833;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;\textit{spred}&#65292;&#26159;$L_1$&#30340;&#31934;&#30830;&#27714;&#35299;&#22120;&#65292;&#21487;&#29992;&#20110;&#35757;&#32451;&#31232;&#30095;&#31070;&#32463;&#32593;&#32476;&#20197;&#25191;&#34892;&#22522;&#22240;&#36873;&#25321;&#20219;&#21153;&#21644;&#31070;&#32463;&#32593;&#32476;&#21387;&#32553;&#20219;&#21153;&#65292;&#24357;&#21512;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#31232;&#30095;&#24615;&#21644;&#20256;&#32479;&#32479;&#35745;&#23398;&#20064;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/2210.01212</link><description>&lt;p&gt;
&#36890;&#36807;&#20887;&#20313;&#24615;&#23454;&#29616;&#31232;&#30095;&#24615;&#65306;&#29992;SGD&#27714;&#35299;$L_1$
&lt;/p&gt;
&lt;p&gt;
Sparsity by Redundancy: Solving $L_1$ with SGD. (arXiv:2210.01212v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.01212
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20887;&#20313;&#37325;&#21442;&#25968;&#21270;&#21644;&#31616;&#21333;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26469;&#26368;&#23567;&#21270;&#24102;&#26377;$L_1$&#24809;&#32602;&#30340;&#36890;&#29992;&#21487;&#24494;&#25439;&#22833;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;\textit{spred}&#65292;&#26159;$L_1$&#30340;&#31934;&#30830;&#27714;&#35299;&#22120;&#65292;&#21487;&#29992;&#20110;&#35757;&#32451;&#31232;&#30095;&#31070;&#32463;&#32593;&#32476;&#20197;&#25191;&#34892;&#22522;&#22240;&#36873;&#25321;&#20219;&#21153;&#21644;&#31070;&#32463;&#32593;&#32476;&#21387;&#32553;&#20219;&#21153;&#65292;&#24357;&#21512;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#31232;&#30095;&#24615;&#21644;&#20256;&#32479;&#32479;&#35745;&#23398;&#20064;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a method called "spred" to minimize a generic differentiable loss function with $L_1$ penalty using redundant reparametrization and straightforward stochastic gradient descent. It is an exact solver of $L_1$ and can be used to train sparse neural networks for gene selection tasks and neural network compression tasks, bridging the gap between sparsity in deep learning and conventional statistical learning.
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20887;&#20313;&#37325;&#21442;&#25968;&#21270;&#21644;&#31616;&#21333;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26469;&#26368;&#23567;&#21270;&#24102;&#26377;$L_1$&#24809;&#32602;&#30340;&#36890;&#29992;&#21487;&#24494;&#25439;&#22833;&#20989;&#25968;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#25552;&#35758;&#26159;$L_1$&#24809;&#32602;&#31561;&#20215;&#20110;&#24102;&#26377;&#26435;&#37325;&#34928;&#20943;&#30340;&#21487;&#24494;&#37325;&#21442;&#25968;&#21270;&#30340;&#30452;&#25509;&#25512;&#24191;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#21363;\textit{spred}&#65292;&#26159;$L_1$&#30340;&#31934;&#30830;&#27714;&#35299;&#22120;&#65292;&#24182;&#19988;&#23545;&#20110;&#36890;&#29992;&#30340;&#38750;&#20984;&#20989;&#25968;&#65292;&#37325;&#21442;&#25968;&#21270;&#25216;&#24039;&#26159;&#23436;&#20840;&#8220;&#33391;&#24615;&#8221;&#30340;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#65292;&#21253;&#25324;(1)&#35757;&#32451;&#31232;&#30095;&#31070;&#32463;&#32593;&#32476;&#20197;&#25191;&#34892;&#22522;&#22240;&#36873;&#25321;&#20219;&#21153;&#65292;&#20854;&#20013;&#28041;&#21450;&#22312;&#38750;&#24120;&#39640;&#32500;&#31354;&#38388;&#20013;&#25214;&#21040;&#30456;&#20851;&#29305;&#24449;&#65292;&#20197;&#21450;(2)&#31070;&#32463;&#32593;&#32476;&#21387;&#32553;&#20219;&#21153;&#65292;&#20808;&#21069;&#23581;&#35797;&#24212;&#29992;$L_1$&#24809;&#32602;&#30340;&#26041;&#27861;&#22343;&#26410;&#25104;&#21151;&#12290;&#20174;&#27010;&#24565;&#19978;&#35762;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#24357;&#21512;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#31232;&#30095;&#24615;&#21644;&#20256;&#32479;&#32479;&#35745;&#23398;&#20064;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose to minimize a generic differentiable loss function with $L_1$ penalty with a redundant reparametrization and straightforward stochastic gradient descent. Our proposal is the direct generalization of a series of previous ideas that the $L_1$ penalty may be equivalent to a differentiable reparametrization with weight decay. We prove that the proposed method, \textit{spred}, is an exact solver of $L_1$ and that the reparametrization trick is completely ``benign" for a generic nonconvex function. Practically, we demonstrate the usefulness of the method in (1) training sparse neural networks to perform gene selection tasks, which involves finding relevant features in a very high dimensional space, and (2) neural network compression task, to which previous attempts at applying the $L_1$-penalty have been unsuccessful. Conceptually, our result bridges the gap between the sparsity in deep learning and conventional statistical learning.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19981;&#38656;&#35201;&#35745;&#31639;&#37197;&#20998;&#20989;&#25968;&#30340;&#28508;&#21147;&#20272;&#35745;&#26041;&#27861;&#65292;&#22522;&#20110;&#26368;&#22823;&#21518;&#39564;&#20272;&#35745;&#65288;MAP&#65289;&#20272;&#35745;&#22120;&#65292;&#23558;&#38382;&#39064;&#37325;&#26032;&#34920;&#36848;&#20026;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#23567;&#20316;&#29992;&#37327;&#31867;&#22411;&#30340;&#21183;&#20989;&#25968;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#24555;&#36895;&#23558;&#20248;&#21270;&#38382;&#39064;&#35299;&#20915;&#20026;&#21069;&#39304;&#21452;&#26354;&#31070;&#32463;&#32593;&#32476;&#12290;</title><link>http://arxiv.org/abs/2208.09433</link><description>&lt;p&gt;
&#19981;&#38656;&#35201;&#35745;&#31639;&#37197;&#20998;&#20989;&#25968;&#30340;&#28508;&#21147;&#20272;&#35745;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Estimating a potential without the agony of the partition function. (arXiv:2208.09433v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.09433
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19981;&#38656;&#35201;&#35745;&#31639;&#37197;&#20998;&#20989;&#25968;&#30340;&#28508;&#21147;&#20272;&#35745;&#26041;&#27861;&#65292;&#22522;&#20110;&#26368;&#22823;&#21518;&#39564;&#20272;&#35745;&#65288;MAP&#65289;&#20272;&#35745;&#22120;&#65292;&#23558;&#38382;&#39064;&#37325;&#26032;&#34920;&#36848;&#20026;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#23567;&#20316;&#29992;&#37327;&#31867;&#22411;&#30340;&#21183;&#20989;&#25968;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#24555;&#36895;&#23558;&#20248;&#21270;&#38382;&#39064;&#35299;&#20915;&#20026;&#21069;&#39304;&#21452;&#26354;&#31070;&#32463;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a potential estimation method that does not require the computation of the partition function, based on Maximum A-Posteriori (MAP) estimators, reformulating the problem as an optimization problem, and proposing a least-action type potential that allows for quick solution as a feed-forward hyperbolic neural network.
&lt;/p&gt;
&lt;p&gt;
&#22312;&#35745;&#31639;&#32479;&#35745;&#21644;&#32479;&#35745;&#23398;&#20064;&#20013;&#65292;&#32473;&#23450;&#26679;&#26412;&#20272;&#35745;Gibbs&#23494;&#24230;&#20989;&#25968;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#38382;&#39064;&#12290;&#34429;&#28982;&#26368;&#22823;&#20284;&#28982;&#26041;&#27861;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;&#23427;&#38656;&#35201;&#35745;&#31639;&#37197;&#20998;&#20989;&#25968;&#65288;&#21363;&#23494;&#24230;&#30340;&#24402;&#19968;&#21270;&#65289;&#12290;&#23545;&#20110;&#31616;&#21333;&#30340;&#20302;&#32500;&#38382;&#39064;&#65292;&#21487;&#20197;&#36731;&#26494;&#35745;&#31639;&#35813;&#20989;&#25968;&#65292;&#20294;&#23545;&#20110;&#19968;&#33324;&#23494;&#24230;&#21644;&#39640;&#32500;&#38382;&#39064;&#65292;&#20854;&#35745;&#31639;&#26159;&#22256;&#38590;&#29978;&#33267;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#22823;&#21518;&#39564;&#20272;&#35745;&#65288;MAP&#65289;&#20272;&#35745;&#22120;&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#25105;&#20204;&#23558;&#20854;&#21629;&#21517;&#20026;&#26368;&#22823;&#24674;&#22797;MAP&#65288;MR-MAP&#65289;&#65292;&#20197;&#23548;&#20986;&#19981;&#38656;&#35201;&#35745;&#31639;&#37197;&#20998;&#20989;&#25968;&#30340;&#20272;&#35745;&#22120;&#65292;&#24182;&#23558;&#38382;&#39064;&#37325;&#26032;&#34920;&#36848;&#20026;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#23567;&#20316;&#29992;&#37327;&#31867;&#22411;&#30340;&#21183;&#20989;&#25968;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#24555;&#36895;&#23558;&#20248;&#21270;&#38382;&#39064;&#35299;&#20915;&#20026;&#21069;&#39304;&#21452;&#26354;&#31070;&#32463;&#32593;&#32476;&#12290;&#25105;&#20204;&#22312;&#19968;&#20123;&#26631;&#20934;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating a Gibbs density function given a sample is an important problem in computational statistics and statistical learning. Although the well established maximum likelihood method is commonly used, it requires the computation of the partition function (i.e., the normalization of the density).  This function can be easily calculated for simple low-dimensional problems but its computation is difficult or even intractable for general densities and high-dimensional problems. In this paper we propose an alternative approach based on Maximum A-Posteriori (MAP) estimators, we name Maximum Recovery MAP (MR-MAP), to derive estimators that do not require the computation of the partition function, and reformulate the problem as an optimization problem. We further propose a least-action type potential that allows us to quickly solve the optimization problem as a feed-forward hyperbolic neural network. We demonstrate the effectiveness of our methods on some standard data sets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#29992;&#20110;&#25512;&#26029;&#23884;&#20837;&#31163;&#25955;&#31354;&#38388;&#30340;&#25968;&#25454;&#38598;&#30340;&#20869;&#22312;&#32500;&#24230;&#65288;ID&#65289;&#65292;&#24182;&#22312;&#29289;&#31181;&#25351;&#32441;&#30340;&#20195;&#35874;&#32452;&#23398;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#20854;&#20934;&#30830;&#24615;&#65292;&#21457;&#29616;&#19968;&#20010;&#20196;&#20154;&#24778;&#35766;&#30340;&#23567;ID&#65292;&#32422;&#20026;2&#30340;&#25968;&#37327;&#32423;&#12290;</title><link>http://arxiv.org/abs/2207.09688</link><description>&lt;p&gt;
&#31163;&#25955;&#24230;&#37327;&#30340;&#20869;&#22312;&#32500;&#24230;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Intrinsic dimension estimation for discrete metrics. (arXiv:2207.09688v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.09688
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#29992;&#20110;&#25512;&#26029;&#23884;&#20837;&#31163;&#25955;&#31354;&#38388;&#30340;&#25968;&#25454;&#38598;&#30340;&#20869;&#22312;&#32500;&#24230;&#65288;ID&#65289;&#65292;&#24182;&#22312;&#29289;&#31181;&#25351;&#32441;&#30340;&#20195;&#35874;&#32452;&#23398;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#20854;&#20934;&#30830;&#24615;&#65292;&#21457;&#29616;&#19968;&#20010;&#20196;&#20154;&#24778;&#35766;&#30340;&#23567;ID&#65292;&#32422;&#20026;2&#30340;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces an algorithm to estimate the intrinsic dimension (ID) of datasets embedded in discrete spaces, and demonstrates its accuracy on a metagenomic dataset for species fingerprinting, finding a surprisingly small ID of order 2, suggesting that evolutive pressure acts on a low-dimensional manifold despite the high-dimensionality of sequences' space.
&lt;/p&gt;
&lt;p&gt;
&#20855;&#26377;&#31163;&#25955;&#29305;&#24449;&#30340;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#26159;&#26080;&#22788;&#19981;&#22312;&#30340;&#65306;&#20174;&#20998;&#31867;&#35843;&#26597;&#21040;&#20020;&#24202;&#38382;&#21367;&#65292;&#20174;&#26080;&#26435;&#32593;&#32476;&#21040;DNA&#24207;&#21015;&#12290;&#28982;&#32780;&#65292;&#26368;&#24120;&#35265;&#30340;&#26080;&#30417;&#30563;&#38477;&#32500;&#26041;&#27861;&#26159;&#20026;&#36830;&#32493;&#31354;&#38388;&#35774;&#35745;&#30340;&#65292;&#23427;&#20204;&#22312;&#31163;&#25955;&#31354;&#38388;&#20013;&#30340;&#20351;&#29992;&#21487;&#33021;&#20250;&#23548;&#33268;&#38169;&#35823;&#21644;&#20559;&#24046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#29992;&#20110;&#25512;&#26029;&#23884;&#20837;&#31163;&#25955;&#31354;&#38388;&#30340;&#25968;&#25454;&#38598;&#30340;&#20869;&#22312;&#32500;&#24230;&#65288;ID&#65289;&#12290;&#25105;&#20204;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#20854;&#20934;&#30830;&#24615;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#20998;&#26512;&#29992;&#20110;&#29289;&#31181;&#25351;&#32441;&#30340;&#20195;&#35874;&#32452;&#23398;&#25968;&#25454;&#38598;&#65292;&#21457;&#29616;&#19968;&#20010;&#20196;&#20154;&#24778;&#35766;&#30340;&#23567;ID&#65292;&#32422;&#20026;2&#30340;&#25968;&#37327;&#32423;&#12290;&#36825;&#34920;&#26126;&#65292;&#23613;&#31649;&#24207;&#21015;&#31354;&#38388;&#30340;&#39640;&#32500;&#24230;&#65292;&#36827;&#21270;&#21387;&#21147;&#20173;&#28982;&#20316;&#29992;&#20110;&#20302;&#32500;&#27969;&#24418;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
Real world-datasets characterized by discrete features are ubiquitous: from categorical surveys to clinical questionnaires, from unweighted networks to DNA sequences. Nevertheless, the most common unsupervised dimensional reduction methods are designed for continuous spaces, and their use for discrete spaces can lead to errors and biases. In this letter we introduce an algorithm to infer the intrinsic dimension (ID) of datasets embedded in discrete spaces. We demonstrate its accuracy on benchmark datasets, and we apply it to analyze a metagenomic dataset for species fingerprinting, finding a surprisingly small ID, of order 2. This suggests that evolutive pressure acts on a low-dimensional manifold despite the high-dimensionality of sequences' space.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#31616;&#21333;&#32780;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#21033;&#29992;MLE&#20844;&#24335;&#24182;&#20174;&#22810;&#20010;&#39057;&#29575;&#30340;&#20449;&#24687;&#20013;&#21463;&#30410;&#65292;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#30456;&#23545;&#30456;&#20301;&#30340;&#38543;&#26426;&#22359;&#27169;&#22411;&#19978;&#30340;&#32852;&#21512;&#31038;&#21306;&#26816;&#27979;&#21644;&#30456;&#20301;&#21516;&#27493;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2206.12276</link><description>&lt;p&gt;
&#22810;&#39057;&#32852;&#21512;&#31038;&#21306;&#26816;&#27979;&#21644;&#30456;&#20301;&#21516;&#27493;
&lt;/p&gt;
&lt;p&gt;
Multi-Frequency Joint Community Detection and Phase Synchronization. (arXiv:2206.12276v2 [cs.SI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.12276
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#31616;&#21333;&#32780;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#21033;&#29992;MLE&#20844;&#24335;&#24182;&#20174;&#22810;&#20010;&#39057;&#29575;&#30340;&#20449;&#24687;&#20013;&#21463;&#30410;&#65292;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#30456;&#23545;&#30456;&#20301;&#30340;&#38543;&#26426;&#22359;&#27169;&#22411;&#19978;&#30340;&#32852;&#21512;&#31038;&#21306;&#26816;&#27979;&#21644;&#30456;&#20301;&#21516;&#27493;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes two simple and efficient algorithms that leverage the MLE formulation and benefit from the information across multiple frequencies to solve the joint community detection and phase synchronization problem on the stochastic block model with relative phase.
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#30456;&#23545;&#30456;&#20301;&#30340;&#38543;&#26426;&#22359;&#27169;&#22411;&#19978;&#30340;&#32852;&#21512;&#31038;&#21306;&#26816;&#27979;&#21644;&#30456;&#20301;&#21516;&#27493;&#38382;&#39064;&#65292;&#20854;&#20013;&#27599;&#20010;&#33410;&#28857;&#37117;&#19982;&#19968;&#20010;&#26410;&#30693;&#30340;&#30456;&#20301;&#35282;&#30456;&#20851;&#32852;&#12290;&#36825;&#20010;&#38382;&#39064;&#20855;&#26377;&#22810;&#31181;&#23454;&#38469;&#24212;&#29992;&#65292;&#26088;&#22312;&#21516;&#26102;&#24674;&#22797;&#31751;&#32467;&#26500;&#21644;&#30456;&#20851;&#30340;&#30456;&#20301;&#35282;&#12290;&#25105;&#20204;&#36890;&#36807;&#20180;&#32454;&#30740;&#31350;&#20854;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65288;MLE&#65289;&#20844;&#24335;&#65292;&#23637;&#31034;&#20102;&#36825;&#20010;&#38382;&#39064;&#21576;&#29616;&#20986;&#8220;&#22810;&#39057;&#8221;&#32467;&#26500;&#65292;&#32780;&#29616;&#26377;&#26041;&#27861;&#24182;&#38750;&#28304;&#20110;&#36825;&#20010;&#35282;&#24230;&#12290;&#20026;&#27492;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#31616;&#21333;&#32780;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#21033;&#29992;MLE&#20844;&#24335;&#24182;&#20174;&#22810;&#20010;&#39057;&#29575;&#30340;&#20449;&#24687;&#20013;&#21463;&#30410;&#12290;&#21069;&#32773;&#26159;&#22522;&#20110;&#26032;&#39062;&#30340;&#22810;&#39057;&#21015;&#20027;&#20803;QR&#20998;&#35299;&#30340;&#35889;&#26041;&#27861;&#12290;&#24212;&#29992;&#20110;&#35266;&#27979;&#30697;&#38453;&#30340;&#21069;&#20960;&#20010;&#29305;&#24449;&#21521;&#37327;&#30340;&#20998;&#35299;&#25552;&#20379;&#20102;&#26377;&#20851;&#31751;&#32467;&#26500;&#21644;&#30456;&#20851;&#30456;&#20301;&#35282;&#30340;&#20851;&#38190;&#20449;&#24687;&#12290;&#31532;&#20108;&#31181;&#26041;&#27861;&#26159;&#36845;&#20195;&#30340;&#22810;&#39057;&#29575;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the joint community detection and phase synchronization problem on the stochastic block model with relative phase, where each node is associated with an unknown phase angle. This problem, with a variety of real-world applications, aims to recover the cluster structure and associated phase angles simultaneously. We show this problem exhibits a ``multi-frequency'' structure by closely examining its maximum likelihood estimation (MLE) formulation, whereas existing methods are not originated from this perspective. To this end, two simple yet efficient algorithms that leverage the MLE formulation and benefit from the information across multiple frequencies are proposed. The former is a spectral method based on the novel multi-frequency column-pivoted QR factorization. The factorization applied to the top eigenvectors of the observation matrix provides key information about the cluster structure and associated phase angles. The second approach is an iterative multi-frequen
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#34920;&#26126;&#65292;&#22522;&#20110;&#23545;&#31216;&#20915;&#31574;&#26641;&#30340;&#26799;&#24230;&#25552;&#21319;&#21487;&#20197;&#31561;&#20215;&#22320;&#37325;&#26500;&#20026;&#19968;&#31181;&#26680;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#25910;&#25947;&#20110;&#26576;&#20010;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#30340;&#35299;&#65292;&#20174;&#32780;&#20351;&#25105;&#20204;&#33021;&#22815;&#36731;&#26494;&#22320;&#23558;&#26799;&#24230;&#25552;&#21319;&#36716;&#25442;&#20026;&#20174;&#21518;&#39564;&#20013;&#25552;&#20379;&#26356;&#22909;&#30340;&#30693;&#35782;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#37319;&#26679;&#22120;&#65292;&#36890;&#36807;&#21518;&#39564;&#26041;&#24046;&#30340;&#33945;&#29305;&#21345;&#32599;&#20272;&#35745;&#65292;&#20174;&#32780;&#20801;&#35768;&#26356;&#22909;&#30340;&#30693;&#35782;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#23548;&#33268;&#25913;&#36827;&#30340;&#22495;&#22806;&#26816;&#27979;&#12290;</title><link>http://arxiv.org/abs/2206.05608</link><description>&lt;p&gt;
&#26799;&#24230;&#25552;&#21319;&#25191;&#34892;&#39640;&#26031;&#36807;&#31243;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Gradient Boosting Performs Gaussian Process Inference. (arXiv:2206.05608v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.05608
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#34920;&#26126;&#65292;&#22522;&#20110;&#23545;&#31216;&#20915;&#31574;&#26641;&#30340;&#26799;&#24230;&#25552;&#21319;&#21487;&#20197;&#31561;&#20215;&#22320;&#37325;&#26500;&#20026;&#19968;&#31181;&#26680;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#25910;&#25947;&#20110;&#26576;&#20010;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#30340;&#35299;&#65292;&#20174;&#32780;&#20351;&#25105;&#20204;&#33021;&#22815;&#36731;&#26494;&#22320;&#23558;&#26799;&#24230;&#25552;&#21319;&#36716;&#25442;&#20026;&#20174;&#21518;&#39564;&#20013;&#25552;&#20379;&#26356;&#22909;&#30340;&#30693;&#35782;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#37319;&#26679;&#22120;&#65292;&#36890;&#36807;&#21518;&#39564;&#26041;&#24046;&#30340;&#33945;&#29305;&#21345;&#32599;&#20272;&#35745;&#65292;&#20174;&#32780;&#20801;&#35768;&#26356;&#22909;&#30340;&#30693;&#35782;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#23548;&#33268;&#25913;&#36827;&#30340;&#22495;&#22806;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper shows that gradient boosting based on symmetric decision trees can be equivalently reformulated as a kernel method that converges to the solution of a certain Kernel Ridge Regression problem, which allows us to easily transform gradient boosting into a sampler from the posterior to provide better knowledge uncertainty estimates through Monte-Carlo estimation of the posterior variance, leading to improved out-of-domain detection.
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#34920;&#26126;&#65292;&#22522;&#20110;&#23545;&#31216;&#20915;&#31574;&#26641;&#30340;&#26799;&#24230;&#25552;&#21319;&#21487;&#20197;&#31561;&#20215;&#22320;&#37325;&#26500;&#20026;&#19968;&#31181;&#26680;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#25910;&#25947;&#20110;&#26576;&#20010;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#30340;&#35299;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#25910;&#25947;&#20110;&#39640;&#26031;&#36807;&#31243;&#21518;&#39564;&#22343;&#20540;&#30340;&#25910;&#25947;&#24615;&#65292;&#20174;&#32780;&#20351;&#25105;&#20204;&#33021;&#22815;&#36731;&#26494;&#22320;&#23558;&#26799;&#24230;&#25552;&#21319;&#36716;&#25442;&#20026;&#20174;&#21518;&#39564;&#20013;&#25552;&#20379;&#26356;&#22909;&#30340;&#30693;&#35782;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#37319;&#26679;&#22120;&#65292;&#36890;&#36807;&#21518;&#39564;&#26041;&#24046;&#30340;&#33945;&#29305;&#21345;&#32599;&#20272;&#35745;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#37319;&#26679;&#22120;&#20801;&#35768;&#26356;&#22909;&#30340;&#30693;&#35782;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#20174;&#32780;&#23548;&#33268;&#25913;&#36827;&#30340;&#22495;&#22806;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper shows that gradient boosting based on symmetric decision trees can be equivalently reformulated as a kernel method that converges to the solution of a certain Kernel Ridge Regression problem. Thus, we obtain the convergence to a Gaussian Process' posterior mean, which, in turn, allows us to easily transform gradient boosting into a sampler from the posterior to provide better knowledge uncertainty estimates through Monte-Carlo estimation of the posterior variance. We show that the proposed sampler allows for better knowledge uncertainty estimates leading to improved out-of-domain detection.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#23545;&#25239;&#38543;&#26426;&#26862;&#26519;&#36827;&#34892;&#23494;&#24230;&#20272;&#35745;&#21644;&#25968;&#25454;&#21512;&#25104;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#20379;&#24179;&#28369;&#30340;&#65288;&#38750;&#65289;&#26465;&#20214;&#23494;&#24230;&#65292;&#24182;&#20801;&#35768;&#23436;&#20840;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#65292;&#21516;&#26102;&#22312;&#21508;&#31181;&#34920;&#26684;&#25968;&#25454;&#22522;&#20934;&#27979;&#35797;&#20013;&#23454;&#29616;&#20102;&#19982;&#26368;&#20808;&#36827;&#30340;&#27010;&#29575;&#30005;&#36335;&#21644;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30456;&#24403;&#25110;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#24179;&#22343;&#25191;&#34892;&#36895;&#24230;&#24555;&#20102;&#20004;&#20010;&#25968;&#37327;&#32423;&#12290;</title><link>http://arxiv.org/abs/2205.09435</link><description>&lt;p&gt;
&#23545;&#25239;&#38543;&#26426;&#26862;&#26519;&#29992;&#20110;&#23494;&#24230;&#20272;&#35745;&#21644;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Adversarial random forests for density estimation and generative modeling. (arXiv:2205.09435v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.09435
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#23545;&#25239;&#38543;&#26426;&#26862;&#26519;&#36827;&#34892;&#23494;&#24230;&#20272;&#35745;&#21644;&#25968;&#25454;&#21512;&#25104;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#20379;&#24179;&#28369;&#30340;&#65288;&#38750;&#65289;&#26465;&#20214;&#23494;&#24230;&#65292;&#24182;&#20801;&#35768;&#23436;&#20840;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#65292;&#21516;&#26102;&#22312;&#21508;&#31181;&#34920;&#26684;&#25968;&#25454;&#22522;&#20934;&#27979;&#35797;&#20013;&#23454;&#29616;&#20102;&#19982;&#26368;&#20808;&#36827;&#30340;&#27010;&#29575;&#30005;&#36335;&#21644;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30456;&#24403;&#25110;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#24179;&#22343;&#25191;&#34892;&#36895;&#24230;&#24555;&#20102;&#20004;&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a method for density estimation and data synthesis using adversarial random forests, which provides smooth (un)conditional densities and allows for fully synthetic data generation. The method achieves comparable or superior performance to state-of-the-art probabilistic circuits and deep learning models on various tabular data benchmarks while executing about two orders of magnitude faster on average.
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26032;&#22411;&#26080;&#30417;&#30563;&#38543;&#26426;&#26862;&#26519;&#36827;&#34892;&#23494;&#24230;&#20272;&#35745;&#21644;&#25968;&#25454;&#21512;&#25104;&#30340;&#26041;&#27861;&#12290;&#21463;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#19968;&#31181;&#36882;&#24402;&#36807;&#31243;&#65292;&#20854;&#20013;&#26641;&#36890;&#36807;&#20132;&#26367;&#30340;&#29983;&#25104;&#21644;&#21028;&#21035;&#36718;&#27425;&#36880;&#28176;&#23398;&#20064;&#25968;&#25454;&#30340;&#32467;&#26500;&#29305;&#24615;&#12290;&#35813;&#26041;&#27861;&#22312;&#26368;&#23567;&#20551;&#35774;&#19979;&#21487;&#20197;&#34987;&#35777;&#26126;&#26159;&#19968;&#33268;&#30340;&#12290;&#19982;&#32463;&#20856;&#30340;&#22522;&#20110;&#26641;&#30340;&#26367;&#20195;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#20379;&#24179;&#28369;&#30340;&#65288;&#38750;&#65289;&#26465;&#20214;&#23494;&#24230;&#65292;&#24182;&#20801;&#35768;&#23436;&#20840;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#34920;&#26684;&#25968;&#25454;&#22522;&#20934;&#27979;&#35797;&#20013;&#23454;&#29616;&#20102;&#19982;&#26368;&#20808;&#36827;&#30340;&#27010;&#29575;&#30005;&#36335;&#21644;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30456;&#24403;&#25110;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#24179;&#22343;&#25191;&#34892;&#36895;&#24230;&#24555;&#20102;&#20004;&#20010;&#25968;&#37327;&#32423;&#12290;&#38468;&#24102;&#30340;R&#21253;arf&#21487;&#22312;CRAN&#19978;&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose methods for density estimation and data synthesis using a novel form of unsupervised random forests. Inspired by generative adversarial networks, we implement a recursive procedure in which trees gradually learn structural properties of the data through alternating rounds of generation and discrimination. The method is provably consistent under minimal assumptions. Unlike classic tree-based alternatives, our approach provides smooth (un)conditional densities and allows for fully synthetic data generation. We achieve comparable or superior performance to state-of-the-art probabilistic circuits and deep learning models on various tabular data benchmarks while executing about two orders of magnitude faster on average. An accompanying $\texttt{R}$ package, $\texttt{arf}$, is available on $\texttt{CRAN}$.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;Vine copula&#32467;&#26500;&#30340;&#30697;&#38453;&#21644;&#22270;&#24418;&#34920;&#31034;&#65292;&#35777;&#26126;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#31561;&#20215;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#26500;&#24314;&#30697;&#38453;&#12290;&#36825;&#20123;&#31639;&#27861;&#30340;&#36816;&#34892;&#26102;&#38388;&#20063;&#34987;&#35745;&#31639;&#20102;&#12290;</title><link>http://arxiv.org/abs/2205.04783</link><description>&lt;p&gt;
Vine copula&#32467;&#26500;&#30340;&#30697;&#38453;&#21644;&#22270;&#24418;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Matrix and graph representations of vine copula structures. (arXiv:2205.04783v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.04783
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Vine copula&#32467;&#26500;&#30340;&#30697;&#38453;&#21644;&#22270;&#24418;&#34920;&#31034;&#65292;&#35777;&#26126;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#31561;&#20215;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#26500;&#24314;&#30697;&#38453;&#12290;&#36825;&#20123;&#31639;&#27861;&#30340;&#36816;&#34892;&#26102;&#38388;&#20063;&#34987;&#35745;&#31639;&#20102;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Vine copula&#21487;&#20197;&#26377;&#25928;&#22320;&#24314;&#27169;&#22810;&#20803;&#27010;&#29575;&#20998;&#24067;&#12290;&#26412;&#25991;&#37325;&#28857;&#30740;&#31350;&#23427;&#20204;&#30340;&#32467;&#26500;&#65292;&#22240;&#20026;&#22312;&#25991;&#29486;&#20013;&#65292;vine copula&#30340;&#34920;&#31034;&#32463;&#24120;&#26159;&#27169;&#31946;&#30340;&#12290;&#22270;&#24418;&#34920;&#31034;&#21253;&#25324;&#21407;&#22987;&#30340;&#12289;cherry&#21644;chordal&#22270;&#24418;&#24207;&#21015;&#32467;&#26500;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#31561;&#20215;&#24615;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#19968;&#20010;&#26032;&#30340;&#32467;&#26524;&#65292;&#21363;&#24403;&#32473;&#20986;vine&#32467;&#26500;&#30340;&#23436;&#32654;&#28040;&#38500;&#25490;&#24207;&#26102;&#65292;&#23427;&#24635;&#26159;&#21487;&#20197;&#29992;&#30697;&#38453;&#21807;&#19968;&#34920;&#31034;&#12290;O. M. N\'apoles&#24050;&#32463;&#23637;&#31034;&#20102;&#19968;&#31181;&#22312;&#30697;&#38453;&#20013;&#34920;&#31034;vine&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#23545;&#36825;&#31181;&#20808;&#21069;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#31639;&#27861;&#21270;&#65292;&#21516;&#26102;&#36824;&#23637;&#31034;&#20102;&#19968;&#31181;&#36890;&#36807;cherry&#26641;&#24207;&#21015;&#26500;&#24314;&#36825;&#31181;&#30697;&#38453;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#36824;&#35745;&#31639;&#20102;&#36825;&#20123;&#31639;&#27861;&#30340;&#36816;&#34892;&#26102;&#38388;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20004;&#31181;&#30697;&#38453;&#26500;&#24314;&#31639;&#27861;&#22312;&#20351;&#29992;&#30456;&#21516;&#30340;&#23436;&#32654;&#28040;&#38500;&#25490;&#24207;&#26102;&#26159;&#31561;&#20215;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Vine copulas can efficiently model multivariate probability distributions. This paper focuses on a more thorough understanding of their structures, since in the literature, vine copula representations are often ambiguous. The graph representations include the original, cherry and chordal graph sequence structures, which we show equivalence between. Importantly we also show a new result, namely that when a perfect elimination ordering of a vine structure is given, then it can always be uniquely represented with a matrix. O. M. N\'apoles has shown a way to represent vines in a matrix, and we algorithmify this previous approach, while also showing a new method for constructing such a matrix, through cherry tree sequences. We also calculate the runtime of these algorithms. Lastly, we prove that these two matrix-building algorithms are equivalent if the same perfect elimination ordering is being used.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#27979;&#25277;&#26679;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#38750;&#24179;&#31283;&#36172;&#21338;&#26426;&#23398;&#20064;&#38382;&#39064;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#38477;&#20302;&#33719;&#21462;&#20449;&#24687;&#30340;&#20248;&#20808;&#32423;&#65292;&#35299;&#20915;&#20102;Thompson&#25277;&#26679;&#22312;&#38750;&#24179;&#31283;&#29615;&#22659;&#19979;&#34920;&#29616;&#19981;&#20339;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#25152;&#26377;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#20248;&#20110;Thompson&#25277;&#26679;&#12290;</title><link>http://arxiv.org/abs/2205.01970</link><description>&lt;p&gt;
&#38750;&#24179;&#31283;&#36172;&#21338;&#26426;&#23398;&#20064;&#30340;&#39044;&#27979;&#25277;&#26679;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Non-Stationary Bandit Learning via Predictive Sampling. (arXiv:2205.01970v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.01970
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#27979;&#25277;&#26679;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#38750;&#24179;&#31283;&#36172;&#21338;&#26426;&#23398;&#20064;&#38382;&#39064;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#38477;&#20302;&#33719;&#21462;&#20449;&#24687;&#30340;&#20248;&#20808;&#32423;&#65292;&#35299;&#20915;&#20102;Thompson&#25277;&#26679;&#22312;&#38750;&#24179;&#31283;&#29615;&#22659;&#19979;&#34920;&#29616;&#19981;&#20339;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#25152;&#26377;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#20248;&#20110;Thompson&#25277;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a predictive sampling algorithm to solve the non-stationary bandit learning problem. By deprioritizing the acquisition of information that quickly loses usefulness, the algorithm outperforms Thompson sampling in all non-stationary environments examined.
&lt;/p&gt;
&lt;p&gt;
Thompson&#25277;&#26679;&#24050;&#32463;&#22312;&#24191;&#27867;&#30340;&#24179;&#31283;&#36172;&#21338;&#26426;&#29615;&#22659;&#20013;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;&#28982;&#32780;&#65292;&#27491;&#22914;&#25105;&#20204;&#22312;&#26412;&#25991;&#20013;&#25152;&#23637;&#31034;&#30340;&#65292;&#24403;&#24212;&#29992;&#20110;&#38750;&#24179;&#31283;&#29615;&#22659;&#26102;&#65292;&#23427;&#30340;&#34920;&#29616;&#21487;&#33021;&#24456;&#24046;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#36825;&#26679;&#30340;&#22833;&#36133;&#26159;&#30001;&#20110;&#22312;&#25506;&#32034;&#26102;&#65292;&#31639;&#27861;&#27809;&#26377;&#26681;&#25454;&#30001;&#20110;&#38750;&#24179;&#31283;&#24615;&#23548;&#33268;&#20449;&#24687;&#24555;&#36895;&#22833;&#21435;&#26377;&#29992;&#24615;&#30340;&#36895;&#24230;&#21306;&#20998;&#34892;&#21160;&#12290;&#22522;&#20110;&#36825;&#19968;&#27934;&#35265;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#39044;&#27979;&#25277;&#26679;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#38477;&#20302;&#20102;&#33719;&#21462;&#20449;&#24687;&#30340;&#20248;&#20808;&#32423;&#65292;&#36825;&#20123;&#20449;&#24687;&#30001;&#20110;&#24555;&#36895;&#22833;&#21435;&#26377;&#29992;&#24615;&#32780;&#19981;&#20877;&#37325;&#35201;&#12290;&#36890;&#36807;&#36125;&#21494;&#26031;&#36951;&#25022;&#30028;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#39044;&#27979;&#25277;&#26679;&#24615;&#33021;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#39044;&#27979;&#25277;&#26679;&#30340;&#29256;&#26412;&#65292;&#20854;&#35745;&#31639;&#21487;&#25193;&#23637;&#21040;&#23454;&#38469;&#24863;&#20852;&#36259;&#30340;&#22797;&#26434;&#36172;&#21338;&#26426;&#29615;&#22659;&#12290;&#36890;&#36807;&#25968;&#20540;&#27169;&#25311;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#39044;&#27979;&#25277;&#26679;&#22312;&#25152;&#26377;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#37117;&#20248;&#20110;Thompson&#25277;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;
Thompson sampling has proven effective across a wide range of stationary bandit environments. However, as we demonstrate in this paper, it can perform poorly when applied to non-stationary environments. We show that such failures are attributed to the fact that, when exploring, the algorithm does not differentiate actions based on how quickly the information acquired loses its usefulness due to non-stationarity. Building upon this insight, we propose predictive sampling, an algorithm that deprioritizes acquiring information that quickly loses usefulness. Theoretical guarantee on the performance of predictive sampling is established through a Bayesian regret bound. We provide versions of predictive sampling for which computations tractably scale to complex bandit environments of practical interest. Through numerical simulations, we demonstrate that predictive sampling outperforms Thompson sampling in all non-stationary environments examined.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20271;&#24681;&#26031;&#22374;&#22810;&#39033;&#24335;&#24402;&#19968;&#21270;&#27969;&#30340;&#28789;&#27963;&#26465;&#20214;&#23494;&#24230;&#39044;&#27979;&#26041;&#27861;&#65292;&#29992;&#20110;&#30701;&#26399;&#20302;&#21387;&#36127;&#33655;&#39044;&#27979;&#65292;&#30456;&#27604;&#20256;&#32479;&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#65292;&#21487;&#29992;&#20110;&#35268;&#21010;&#21644;&#36816;&#33829;&#20302;&#30899;&#33021;&#28304;&#31995;&#32479;&#12290;</title><link>http://arxiv.org/abs/2204.13939</link><description>&lt;p&gt;
&#20302;&#21387;&#36127;&#33655;&#20271;&#24681;&#26031;&#22374;&#22810;&#39033;&#24335;&#24402;&#19968;&#21270;&#27969;&#30340;&#30701;&#26399;&#23494;&#24230;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Short-Term Density Forecasting of Low-Voltage Load using Bernstein-Polynomial Normalizing Flows. (arXiv:2204.13939v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.13939
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20271;&#24681;&#26031;&#22374;&#22810;&#39033;&#24335;&#24402;&#19968;&#21270;&#27969;&#30340;&#28789;&#27963;&#26465;&#20214;&#23494;&#24230;&#39044;&#27979;&#26041;&#27861;&#65292;&#29992;&#20110;&#30701;&#26399;&#20302;&#21387;&#36127;&#33655;&#39044;&#27979;&#65292;&#30456;&#27604;&#20256;&#32479;&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#65292;&#21487;&#29992;&#20110;&#35268;&#21010;&#21644;&#36816;&#33829;&#20302;&#30899;&#33021;&#28304;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a flexible conditional density forecasting method based on Bernstein polynomial normalizing flows for short-term low-voltage load forecasting, which outperforms traditional methods and can be used for planning and operating low-carbon energy systems.
&lt;/p&gt;
&lt;p&gt;
&#23454;&#29616;&#20840;&#38754;&#21487;&#20877;&#29983;&#33021;&#28304;&#30005;&#32593;&#30340;&#36716;&#22411;&#38656;&#35201;&#26356;&#22909;&#22320;&#39044;&#27979;&#20302;&#21387;&#27700;&#24179;&#30340;&#38656;&#27714;&#65292;&#20197;&#25552;&#39640;&#25928;&#29575;&#24182;&#30830;&#20445;&#21487;&#38752;&#30340;&#25511;&#21046;&#12290;&#28982;&#32780;&#65292;&#39640;&#27874;&#21160;&#24615;&#21644;&#19981;&#26029;&#22686;&#21152;&#30340;&#30005;&#27668;&#21270;&#23548;&#33268;&#24040;&#22823;&#30340;&#39044;&#27979;&#21464;&#24322;&#24615;&#65292;&#36825;&#22312;&#20256;&#32479;&#30340;&#28857;&#20272;&#35745;&#20013;&#27809;&#26377;&#21453;&#26144;&#20986;&#26469;&#12290;&#27010;&#29575;&#36127;&#36733;&#39044;&#27979;&#32771;&#34385;&#26410;&#26469;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#22240;&#27492;&#20801;&#35768;&#26356;&#26126;&#26234;&#30340;&#20915;&#31574;&#65292;&#29992;&#20110;&#35268;&#21010;&#21644;&#36816;&#33829;&#20302;&#30899;&#33021;&#28304;&#31995;&#32479;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20271;&#24681;&#26031;&#22374;&#22810;&#39033;&#24335;&#24402;&#19968;&#21270;&#27969;&#30340;&#28789;&#27963;&#26465;&#20214;&#23494;&#24230;&#39044;&#27979;&#26041;&#27861;&#65292;&#20854;&#20013;&#31070;&#32463;&#32593;&#32476;&#25511;&#21046;&#27969;&#30340;&#21442;&#25968;&#12290;&#22312;&#19968;&#39033;&#21253;&#25324;363&#20010;&#26234;&#33021;&#30005;&#34920;&#23458;&#25143;&#30340;&#23454;&#35777;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#30340;&#23494;&#24230;&#39044;&#27979;&#19982;&#39640;&#26031;&#21644;&#39640;&#26031;&#28151;&#21512;&#23494;&#24230;&#30456;&#27604;&#34920;&#29616;&#20986;&#20248;&#21183;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#20004;&#31181;&#19981;&#21516;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#23427;&#20204;&#22312;24&#23567;&#26102;&#21069;&#30340;&#36127;&#36733;&#39044;&#27979;&#20013;&#20248;&#20110;&#22522;&#20110;&#38024;&#29699;&#25439;&#22833;&#30340;&#38750;&#21442;&#25968;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The transition to a fully renewable energy grid requires better forecasting of demand at the low-voltage level to increase efficiency and ensure reliable control. However, high fluctuations and increasing electrification cause huge forecast variability, not reflected in traditional point estimates. Probabilistic load forecasts take future uncertainties into account and thus allow more informed decision-making for the planning and operation of low-carbon energy systems. We propose an approach for flexible conditional density forecasting of short-term load based on Bernstein polynomial normalizing flows, where a neural network controls the parameters of the flow. In an empirical study with 363 smart meter customers, our density predictions compare favorably against Gaussian and Gaussian mixture densities. Also, they outperform a non-parametric approach based on the pinball loss for 24h-ahead load forecasting for two different neural network architectures.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20004;&#27493;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#31216;&#20026;&#28145;&#24230;&#29305;&#24449;&#31579;&#36873;&#65288;DeepFS&#65289;&#65292;&#21487;&#20197;&#20811;&#26381;&#39640;&#32500;&#12289;&#20302;&#26679;&#26412;&#25968;&#25454;&#19978;&#30340;&#22256;&#38590;&#21644;&#25361;&#25112;&#65292;&#24182;&#23545;&#36229;&#39640;&#32500;&#12289;&#20302;&#26679;&#26412;&#25968;&#25454;&#36827;&#34892;&#39640;&#31934;&#24230;&#30340;&#29305;&#24449;&#31579;&#36873;&#12290;</title><link>http://arxiv.org/abs/2204.01682</link><description>&lt;p&gt;
&#28145;&#24230;&#29305;&#24449;&#31579;&#36873;&#65306;&#36890;&#36807;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#36229;&#39640;&#32500;&#25968;&#25454;&#30340;&#29305;&#24449;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Deep Feature Screening: Feature Selection for Ultra High-Dimensional Data via Deep Neural Networks. (arXiv:2204.01682v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.01682
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20004;&#27493;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#31216;&#20026;&#28145;&#24230;&#29305;&#24449;&#31579;&#36873;&#65288;DeepFS&#65289;&#65292;&#21487;&#20197;&#20811;&#26381;&#39640;&#32500;&#12289;&#20302;&#26679;&#26412;&#25968;&#25454;&#19978;&#30340;&#22256;&#38590;&#21644;&#25361;&#25112;&#65292;&#24182;&#23545;&#36229;&#39640;&#32500;&#12289;&#20302;&#26679;&#26412;&#25968;&#25454;&#36827;&#34892;&#39640;&#31934;&#24230;&#30340;&#29305;&#24449;&#31579;&#36873;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a novel two-step nonparametric approach called Deep Feature Screening (DeepFS) that can overcome the challenges of high-dimensional, low-sample-size data and identify significant features with high precision for ultra high-dimensional, low-sample-size data.
&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#32479;&#35745;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#22312;&#39640;&#32500;&#12289;&#20302;&#26679;&#26412;&#25968;&#25454;&#19978;&#30340;&#24212;&#29992;&#32463;&#24120;&#36935;&#21040;&#22256;&#38590;&#21644;&#25361;&#25112;&#65292;&#22914;&#36807;&#25311;&#21512;&#12289;&#32500;&#25968;&#28798;&#38590;&#12289;&#35745;&#31639;&#19981;&#21487;&#34892;&#21644;&#24378;&#27169;&#22411;&#20551;&#35774;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20004;&#27493;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#31216;&#20026;&#28145;&#24230;&#29305;&#24449;&#31579;&#36873;&#65288;DeepFS&#65289;&#65292;&#21487;&#20197;&#20811;&#26381;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#23545;&#36229;&#39640;&#32500;&#12289;&#20302;&#26679;&#26412;&#25968;&#25454;&#36827;&#34892;&#39640;&#31934;&#24230;&#30340;&#29305;&#24449;&#31579;&#36873;&#12290;&#35813;&#26041;&#27861;&#39318;&#20808;&#25552;&#21462;&#36755;&#20837;&#25968;&#25454;&#30340;&#20302;&#32500;&#34920;&#31034;&#65292;&#28982;&#21518;&#24212;&#29992;&#22522;&#20110;Deb&#21644;Sen&#65288;2021&#65289;&#26368;&#36817;&#24320;&#21457;&#30340;&#22810;&#20803;&#31209;&#36317;&#30456;&#20851;&#24615;&#30340;&#29305;&#24449;&#31579;&#36873;&#12290;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#29305;&#24449;&#31579;&#36873;&#30340;&#20248;&#28857;&#65292;&#38500;&#20102;&#22788;&#29702;&#20855;&#26377;&#23569;&#37327;&#26679;&#26412;&#30340;&#36229;&#39640;&#32500;&#25968;&#25454;&#30340;&#33021;&#21147;&#22806;&#65292;&#36824;&#20855;&#26377;&#20197;&#19979;&#21560;&#24341;&#20154;&#30340;&#29305;&#28857;&#65306;&#65288;1&#65289;&#23427;&#26159;&#27169;&#22411;&#33258;&#30001;&#21644;&#20998;&#24067;&#33258;&#30001;&#30340;&#65307;&#65288;2&#65289;&#23427;&#21487;&#20197;
&lt;/p&gt;
&lt;p&gt;
The applications of traditional statistical feature selection methods to high-dimension, low sample-size data often struggle and encounter challenging problems, such as overfitting, curse of dimensionality, computational infeasibility, and strong model assumption. In this paper, we propose a novel two-step nonparametric approach called Deep Feature Screening (DeepFS) that can overcome these problems and identify significant features with high precision for ultra high-dimensional, low-sample-size data. This approach first extracts a low-dimensional representation of input data and then applies feature screening based on multivariate rank distance correlation recently developed by Deb and Sen (2021). This approach combines the strengths of both deep neural networks and feature screening, and thereby has the following appealing features in addition to its ability of handling ultra high-dimensional data with small number of samples: (1) it is model free and distribution free; (2) it can be
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#34701;&#21512;&#31243;&#24207;&#24369;&#30417;&#30563;&#21644;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#40784;&#31163;&#25955;&#28508;&#22312;&#21464;&#37327;&#21644;&#24369;&#30417;&#30563;&#27966;&#29983;&#30340;&#26631;&#31614;&#20272;&#35745;&#65292;&#25913;&#21892;&#20102;&#26410;&#35266;&#23519;&#21040;&#30340;&#26631;&#31614;&#30340;&#20272;&#35745;&#65292;&#23454;&#29616;&#20102;&#25968;&#25454;&#22686;&#24378;&#12290;</title><link>http://arxiv.org/abs/2203.12023</link><description>&lt;p&gt;
&#29983;&#25104;&#24314;&#27169;&#26377;&#21161;&#20110;&#24369;&#30417;&#30563;&#65288;&#21453;&#20043;&#20134;&#28982;&#65289;
&lt;/p&gt;
&lt;p&gt;
Generative Modeling Helps Weak Supervision (and Vice Versa). (arXiv:2203.12023v6 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.12023
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#34701;&#21512;&#31243;&#24207;&#24369;&#30417;&#30563;&#21644;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#40784;&#31163;&#25955;&#28508;&#22312;&#21464;&#37327;&#21644;&#24369;&#30417;&#30563;&#27966;&#29983;&#30340;&#26631;&#31614;&#20272;&#35745;&#65292;&#25913;&#21892;&#20102;&#26410;&#35266;&#23519;&#21040;&#30340;&#26631;&#31614;&#30340;&#20272;&#35745;&#65292;&#23454;&#29616;&#20102;&#25968;&#25454;&#22686;&#24378;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a model that fuses programmatic weak supervision and generative adversarial networks, improving the estimate of unobserved labels by aligning discrete latent variables and weak supervision derived label estimate, and enabling data augmentation through weak supervision.
&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#26377;&#21069;&#36884;&#30340;&#30417;&#30563;&#24335;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#22312;&#33719;&#21462;&#36275;&#22815;&#25968;&#37327;&#21644;&#36136;&#37327;&#30340;&#26631;&#35760;&#25968;&#25454;&#26041;&#38754;&#38754;&#20020;&#22256;&#38590;&#65292;&#20174;&#32780;&#36896;&#25104;&#26114;&#36149;&#30340;&#29942;&#39048;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#65292;&#30740;&#31350;&#20102;&#19981;&#20381;&#36182;&#20110;&#22522;&#26412;&#30495;&#23454;&#26631;&#31614;&#30340;&#25216;&#26415;&#65292;&#21253;&#25324;&#24369;&#30417;&#30563;&#21644;&#29983;&#25104;&#24314;&#27169;&#12290;&#34429;&#28982;&#36825;&#20123;&#25216;&#26415;&#20284;&#20046;&#21487;&#20197;&#20849;&#21516;&#20351;&#29992;&#65292;&#30456;&#20114;&#25913;&#36827;&#65292;&#20294;&#22914;&#20309;&#22312;&#23427;&#20204;&#20043;&#38388;&#24314;&#31435;&#25509;&#21475;&#23578;&#19981;&#20026;&#20154;&#25152;&#30693;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#34701;&#21512;&#31243;&#24207;&#24369;&#30417;&#30563;&#21644;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30340;&#27169;&#22411;&#65292;&#24182;&#25552;&#20379;&#20102;&#29702;&#35770;&#19978;&#30340;&#29702;&#30001;&#26469;&#25903;&#25345;&#36825;&#31181;&#34701;&#21512;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#25429;&#25417;&#25968;&#25454;&#20013;&#30340;&#31163;&#25955;&#28508;&#22312;&#21464;&#37327;&#20197;&#21450;&#24369;&#30417;&#30563;&#27966;&#29983;&#30340;&#26631;&#31614;&#20272;&#35745;&#12290;&#20004;&#32773;&#30340;&#23545;&#40784;&#20801;&#35768;&#26356;&#22909;&#22320;&#24314;&#27169;&#24369;&#30417;&#30563;&#26469;&#28304;&#30340;&#26679;&#26412;&#30456;&#20851;&#20934;&#30830;&#24615;&#65292;&#20174;&#32780;&#25913;&#21892;&#26410;&#35266;&#23519;&#21040;&#30340;&#26631;&#31614;&#30340;&#20272;&#35745;&#12290;&#36825;&#26159;&#31532;&#19968;&#31181;&#36890;&#36807;&#24369;&#30417;&#30563;&#23454;&#29616;&#25968;&#25454;&#22686;&#24378;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many promising applications of supervised machine learning face hurdles in the acquisition of labeled data in sufficient quantity and quality, creating an expensive bottleneck. To overcome such limitations, techniques that do not depend on ground truth labels have been studied, including weak supervision and generative modeling. While these techniques would seem to be usable in concert, improving one another, how to build an interface between them is not well-understood. In this work, we propose a model fusing programmatic weak supervision and generative adversarial networks and provide theoretical justification motivating this fusion. The proposed approach captures discrete latent variables in the data alongside the weak supervision derived label estimate. Alignment of the two allows for better modeling of sample-dependent accuracies of the weak supervision sources, improving the estimate of unobserved labels. It is the first approach to enable data augmentation through weakly supervi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#26088;&#22312;&#25506;&#35752;&#30315;&#30187;&#26679;&#27963;&#21160;&#23545;&#21361;&#37325;&#30149;&#24739;&#32773;&#20986;&#38498;&#32467;&#23616;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#22238;&#39038;&#24615;&#27178;&#26029;&#38754;&#30740;&#31350;&#21457;&#29616;&#65292;&#22914;&#26524;&#27599;&#20010;&#20154;&#37117;&#32463;&#21382;&#20102;&#26576;&#31181;EA&#36127;&#33655;&#24182;&#19988;&#26410;&#25509;&#21463;&#27835;&#30103;&#65292;&#20986;&#38498;mRS&#20250;&#21457;&#29983;&#21464;&#21270;&#12290;</title><link>http://arxiv.org/abs/2203.04920</link><description>&lt;p&gt;
&#30315;&#30187;&#26679;&#27963;&#21160;&#23545;&#21361;&#37325;&#30149;&#24739;&#32773;&#20986;&#38498;&#32467;&#23616;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Effects of Epileptiform Activity on Discharge Outcome in Critically Ill Patients. (arXiv:2203.04920v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.04920
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#25506;&#35752;&#30315;&#30187;&#26679;&#27963;&#21160;&#23545;&#21361;&#37325;&#30149;&#24739;&#32773;&#20986;&#38498;&#32467;&#23616;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#22238;&#39038;&#24615;&#27178;&#26029;&#38754;&#30740;&#31350;&#21457;&#29616;&#65292;&#22914;&#26524;&#27599;&#20010;&#20154;&#37117;&#32463;&#21382;&#20102;&#26576;&#31181;EA&#36127;&#33655;&#24182;&#19988;&#26410;&#25509;&#21463;&#27835;&#30103;&#65292;&#20986;&#38498;mRS&#20250;&#21457;&#29983;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study aims to explore the effects of epileptiform activity on discharge outcomes in critically ill patients. Through a retrospective cross-sectional study, it was found that the discharge mRS would change if everyone had experienced a certain EA burden and were untreated.
&lt;/p&gt;
&lt;p&gt;
&#30315;&#30187;&#26679;&#27963;&#21160;&#65288;EA&#65289;&#19982;&#26356;&#24046;&#30340;&#32467;&#23616;&#30456;&#20851;&#65292;&#21253;&#25324;&#22686;&#21152;&#27531;&#30142;&#21644;&#27515;&#20129;&#30340;&#39118;&#38505;&#12290;&#28982;&#32780;&#65292;EA&#23545;&#31070;&#32463;&#31995;&#32479;&#32467;&#23616;&#30340;&#24433;&#21709;&#21463;&#21040;&#25239;&#30315;&#30187;&#33647;&#29289;&#65288;ASM&#65289;&#27835;&#30103;&#21644;EA&#36127;&#33655;&#20043;&#38388;&#30340;&#21453;&#39304;&#30340;&#24178;&#25200;&#12290;&#30001;&#20110;EA-ASM&#21453;&#39304;&#30340;&#39034;&#24207;&#24615;&#20197;&#21450;&#20262;&#29702;&#21407;&#22240;&#65292;&#38543;&#26426;&#20020;&#24202;&#35797;&#39564;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#28982;&#32780;&#65292;&#19968;&#20123;&#26426;&#21046;&#30693;&#35782;&#26159;&#21487;&#29992;&#30340;&#65292;&#20363;&#22914;&#33647;&#29289;&#30340;&#21560;&#25910;&#26041;&#24335;&#12290;&#36825;&#20123;&#30693;&#35782;&#19982;&#35266;&#23519;&#25968;&#25454;&#32467;&#21512;&#36215;&#26469;&#65292;&#21487;&#20197;&#20351;&#29992;&#22240;&#26524;&#25512;&#26029;&#25552;&#20379;&#26356;&#20934;&#30830;&#30340;&#25928;&#24212;&#20272;&#35745;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#22238;&#39038;&#24615;&#27178;&#26029;&#38754;&#30740;&#31350;&#65292;&#20849;&#26377;995&#21517;&#24739;&#32773;&#65292;&#20197;&#20986;&#38498;&#26102;&#30340;&#20462;&#27491;Rankin&#37327;&#34920;&#65288;mRS&#65289;&#20026;&#32467;&#26524;&#65292;&#20197;&#22312;&#31532;&#19968;&#27425;&#33041;&#30005;&#22270;&#30340;&#21069;24&#23567;&#26102;&#20869;&#27599;&#20010;&#20845;&#23567;&#26102;&#31383;&#21475;&#20013;EA&#36127;&#33655;&#30340;&#24179;&#22343;&#25110;&#26368;&#22823;&#27604;&#20363;&#20026;&#26292;&#38706;&#12290;&#25105;&#20204;&#20272;&#35745;&#20102;&#22914;&#26524;&#25968;&#25454;&#38598;&#20013;&#30340;&#27599;&#20010;&#20154;&#37117;&#32463;&#21382;&#20102;&#26576;&#31181;EA&#36127;&#33655;&#24182;&#19988;&#26410;&#25509;&#21463;&#27835;&#30103;&#65292;&#20986;&#38498;mRS&#30340;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Epileptiform activity (EA) is associated with worse outcomes including increased risk of disability and death. However, the effect of EA on the neurologic outcome is confounded by the feedback between treatment with anti-seizure medications (ASM) and EA burden. A randomized clinical trial is challenging due to the sequential nature of EA-ASM feedback, as well as ethical reasons. However, some mechanistic knowledge is available, e.g., how drugs are absorbed. This knowledge together with observational data could provide a more accurate effect estimate using causal inference. We performed a retrospective cross-sectional study with 995 patients with the modified Rankin Scale (mRS) at discharge as the outcome and the EA burden defined as the mean or maximum proportion of time spent with EA in six-hour windows in the first 24 hours of electroencephalography as the exposure. We estimated the change in discharge mRS if everyone in the dataset had experienced a certain EA burden and were untrea
&lt;/p&gt;</description></item><item><title>PGMax&#26159;&#19968;&#20010;&#29992;&#20110;&#31163;&#25955;&#27010;&#29575;&#22270;&#27169;&#22411;&#30340;&#22240;&#23376;&#22270;&#24037;&#20855;&#65292;&#21487;&#20197;&#22312;JAX&#20013;&#33258;&#21160;&#36816;&#34892;&#39640;&#25928;&#19988;&#21487;&#25193;&#23637;&#30340;&#24490;&#29615;&#32622;&#20449;&#20256;&#25773;&#65292;&#19982;&#29616;&#26377;&#26367;&#20195;&#26041;&#26696;&#30456;&#27604;&#65292;PGMax&#33719;&#24471;&#20102;&#26356;&#39640;&#36136;&#37327;&#30340;&#25512;&#29702;&#32467;&#26524;&#65292;&#25512;&#29702;&#26102;&#38388;&#21152;&#36895;&#39640;&#36798;&#19977;&#20010;&#25968;&#37327;&#32423;&#12290;</title><link>http://arxiv.org/abs/2202.04110</link><description>&lt;p&gt;
PGMax: &#29992;&#20110;&#31163;&#25955;&#27010;&#29575;&#22270;&#27169;&#22411;&#21644;JAX&#20013;&#30340;&#24490;&#29615;&#32622;&#20449;&#20256;&#25773;&#30340;&#22240;&#23376;&#22270;
&lt;/p&gt;
&lt;p&gt;
PGMax: Factor Graphs for Discrete Probabilistic Graphical Models and Loopy Belief Propagation in JAX. (arXiv:2202.04110v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.04110
&lt;/p&gt;
&lt;p&gt;
PGMax&#26159;&#19968;&#20010;&#29992;&#20110;&#31163;&#25955;&#27010;&#29575;&#22270;&#27169;&#22411;&#30340;&#22240;&#23376;&#22270;&#24037;&#20855;&#65292;&#21487;&#20197;&#22312;JAX&#20013;&#33258;&#21160;&#36816;&#34892;&#39640;&#25928;&#19988;&#21487;&#25193;&#23637;&#30340;&#24490;&#29615;&#32622;&#20449;&#20256;&#25773;&#65292;&#19982;&#29616;&#26377;&#26367;&#20195;&#26041;&#26696;&#30456;&#27604;&#65292;PGMax&#33719;&#24471;&#20102;&#26356;&#39640;&#36136;&#37327;&#30340;&#25512;&#29702;&#32467;&#26524;&#65292;&#25512;&#29702;&#26102;&#38388;&#21152;&#36895;&#39640;&#36798;&#19977;&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;
PGMax is a factor graph tool for discrete probabilistic graphical models that automatically runs efficient and scalable loopy belief propagation in JAX. Compared with existing alternatives, PGMax obtains higher-quality inference results with up to three orders-of-magnitude inference time speedups.
&lt;/p&gt;
&lt;p&gt;
PGMax&#26159;&#19968;&#20010;&#24320;&#28304;&#30340;Python&#21253;&#65292;&#29992;&#20110;&#36731;&#26494;&#25351;&#23450;&#31163;&#25955;&#27010;&#29575;&#22270;&#27169;&#22411;&#65288;PGMs&#65289;&#20316;&#20026;&#22240;&#23376;&#22270;&#65292;&#24182;&#22312;JAX&#20013;&#33258;&#21160;&#36816;&#34892;&#39640;&#25928;&#19988;&#21487;&#25193;&#23637;&#30340;&#24490;&#29615;&#32622;&#20449;&#20256;&#25773;&#65288;LBP&#65289;&#12290;PGMax&#25903;&#25345;&#20855;&#26377;&#21487;&#22788;&#29702;&#22240;&#23376;&#30340;&#19968;&#33324;&#22240;&#23376;&#22270;&#65292;&#24182;&#21033;&#29992;&#29616;&#20195;&#21152;&#36895;&#22120;&#65288;&#22914;GPU&#65289;&#36827;&#34892;&#25512;&#29702;&#12290;&#19982;&#29616;&#26377;&#26367;&#20195;&#26041;&#26696;&#30456;&#27604;&#65292;PGMax&#33719;&#24471;&#20102;&#26356;&#39640;&#36136;&#37327;&#30340;&#25512;&#29702;&#32467;&#26524;&#65292;&#25512;&#29702;&#26102;&#38388;&#21152;&#36895;&#39640;&#36798;&#19977;&#20010;&#25968;&#37327;&#32423;&#12290;PGMax&#36824;&#19982;&#24555;&#36895;&#22686;&#38271;&#30340;JAX&#29983;&#24577;&#31995;&#32479;&#26080;&#32541;&#20132;&#20114;&#65292;&#24320;&#21551;&#20102;&#26032;&#30340;&#30740;&#31350;&#21487;&#33021;&#24615;&#12290;&#25105;&#20204;&#30340;&#28304;&#20195;&#30721;&#12289;&#31034;&#20363;&#21644;&#25991;&#26723;&#21487;&#22312;https://github.com/deepmind/PGMax&#19978;&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
PGMax is an open-source Python package for (a) easily specifying discrete Probabilistic Graphical Models (PGMs) as factor graphs; and (b) automatically running efficient and scalable loopy belief propagation (LBP) in JAX. PGMax supports general factor graphs with tractable factors, and leverages modern accelerators like GPUs for inference. Compared with existing alternatives, PGMax obtains higher-quality inference results with up to three orders-of-magnitude inference time speedups. PGMax additionally interacts seamlessly with the rapidly growing JAX ecosystem, opening up new research possibilities. Our source code, examples and documentation are available at https://github.com/deepmind/PGMax.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30452;&#25509;&#30340;&#36125;&#21494;&#26031;&#35823;&#24046;&#20272;&#35745;&#22120;&#65292;&#21487;&#20197;&#29992;&#20110;&#35780;&#20272;&#20855;&#26377;&#26368;&#20808;&#36827;&#24615;&#33021;&#30340;&#20998;&#31867;&#22120;&#30340;&#26631;&#20934;&#65292;&#24182;&#21487;&#29992;&#20110;&#26816;&#27979;&#27979;&#35797;&#38598;&#36807;&#25311;&#21512;&#12290;&#19982;&#20854;&#20182;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#26080;&#27169;&#22411;&#30340;&#65292;&#29978;&#33267;&#26159;&#26080;&#23454;&#20363;&#30340;&#12290;&#27492;&#22806;&#65292;&#23427;&#27809;&#26377;&#36229;&#21442;&#25968;&#65292;&#24182;&#19988;&#22312;&#23454;&#35777;&#19978;&#27604;&#20960;&#20010;&#22522;&#32447;&#32473;&#20986;&#20102;&#26356;&#20934;&#30830;&#30340;&#36125;&#21494;&#26031;&#35823;&#24046;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2202.00395</link><description>&lt;p&gt;
&#25105;&#30340;&#28145;&#24230;&#32593;&#32476;&#30340;&#34920;&#29616;&#26159;&#21542;&#36807;&#20110;&#20248;&#31168;&#65311;&#19968;&#31181;&#30452;&#25509;&#20272;&#35745;&#20108;&#20803;&#20998;&#31867;&#20013;&#36125;&#21494;&#26031;&#35823;&#24046;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Is the Performance of My Deep Network Too Good to Be True? A Direct Approach to Estimating the Bayes Error in Binary Classification. (arXiv:2202.00395v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.00395
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30452;&#25509;&#30340;&#36125;&#21494;&#26031;&#35823;&#24046;&#20272;&#35745;&#22120;&#65292;&#21487;&#20197;&#29992;&#20110;&#35780;&#20272;&#20855;&#26377;&#26368;&#20808;&#36827;&#24615;&#33021;&#30340;&#20998;&#31867;&#22120;&#30340;&#26631;&#20934;&#65292;&#24182;&#21487;&#29992;&#20110;&#26816;&#27979;&#27979;&#35797;&#38598;&#36807;&#25311;&#21512;&#12290;&#19982;&#20854;&#20182;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#26080;&#27169;&#22411;&#30340;&#65292;&#29978;&#33267;&#26159;&#26080;&#23454;&#20363;&#30340;&#12290;&#27492;&#22806;&#65292;&#23427;&#27809;&#26377;&#36229;&#21442;&#25968;&#65292;&#24182;&#19988;&#22312;&#23454;&#35777;&#19978;&#27604;&#20960;&#20010;&#22522;&#32447;&#32473;&#20986;&#20102;&#26356;&#20934;&#30830;&#30340;&#36125;&#21494;&#26031;&#35823;&#24046;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a simple and direct Bayes error estimator, which can be used as a criterion to evaluate classifiers with state-of-the-art performance and can be used to detect test set overfitting. Our method is model-free and even instance-free, and gives a more accurate estimate of the Bayes error than several baselines empirically.
&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#39044;&#27979;&#24615;&#33021;&#23384;&#22312;&#26681;&#26412;&#38480;&#21046;&#65292;&#36825;&#26159;&#30001;&#20110;&#39044;&#27979;&#30446;&#26631;&#30340;&#19981;&#21487;&#36991;&#20813;&#30340;&#19981;&#30830;&#23450;&#24615;&#25152;&#33268;&#12290;&#22312;&#20998;&#31867;&#38382;&#39064;&#20013;&#65292;&#36825;&#21487;&#20197;&#36890;&#36807;&#36125;&#21494;&#26031;&#35823;&#24046;&#26469;&#25551;&#36848;&#65292;&#23427;&#26159;&#20219;&#20309;&#20998;&#31867;&#22120;&#21487;&#20197;&#36798;&#21040;&#30340;&#26368;&#20339;&#35823;&#24046;&#12290;&#36125;&#21494;&#26031;&#35823;&#24046;&#21487;&#20197;&#29992;&#20316;&#35780;&#20272;&#20855;&#26377;&#26368;&#20808;&#36827;&#24615;&#33021;&#30340;&#20998;&#31867;&#22120;&#30340;&#26631;&#20934;&#65292;&#24182;&#21487;&#29992;&#20110;&#26816;&#27979;&#27979;&#35797;&#38598;&#36807;&#25311;&#21512;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30452;&#25509;&#30340;&#36125;&#21494;&#26031;&#35823;&#24046;&#20272;&#35745;&#22120;&#65292;&#20854;&#20013;&#25105;&#20204;&#21482;&#38656;&#21462;&#26174;&#31034;&#31867;&#21035;&#20998;&#37197;&#19981;&#30830;&#23450;&#24615;&#30340;&#26631;&#31614;&#30340;&#24179;&#22343;&#20540;&#12290;&#25105;&#20204;&#30340;&#28789;&#27963;&#26041;&#27861;&#20351;&#25105;&#20204;&#33021;&#22815;&#21363;&#20351;&#23545;&#20110;&#24369;&#30417;&#30563;&#25968;&#25454;&#20063;&#36827;&#34892;&#36125;&#21494;&#26031;&#35823;&#24046;&#20272;&#35745;&#12290;&#19982;&#20854;&#20182;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#26080;&#27169;&#22411;&#30340;&#65292;&#29978;&#33267;&#26159;&#26080;&#23454;&#20363;&#30340;&#12290;&#27492;&#22806;&#65292;&#23427;&#27809;&#26377;&#36229;&#21442;&#25968;&#65292;&#24182;&#19988;&#22312;&#23454;&#35777;&#19978;&#27604;&#20960;&#20010;&#22522;&#32447;&#32473;&#20986;&#20102;&#26356;&#20934;&#30830;&#30340;&#36125;&#21494;&#26031;&#35823;&#24046;&#20272;&#35745;&#12290;&#20351;&#29992;&#25105;&#20204;&#30340;&#26041;&#27861;&#36827;&#34892;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#26368;&#36817;&#25552;&#20986;&#30340;&#28145;&#24230;&#32593;&#32476;&#65288;&#22914;Vision Transformer m&#65289;&#30340;&#34920;&#29616;&#21487;&#33021;&#36807;&#20110;&#20248;&#31168;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is a fundamental limitation in the prediction performance that a machine learning model can achieve due to the inevitable uncertainty of the prediction target. In classification problems, this can be characterized by the Bayes error, which is the best achievable error with any classifier. The Bayes error can be used as a criterion to evaluate classifiers with state-of-the-art performance and can be used to detect test set overfitting. We propose a simple and direct Bayes error estimator, where we just take the mean of the labels that show \emph{uncertainty} of the class assignments. Our flexible approach enables us to perform Bayes error estimation even for weakly supervised data. In contrast to others, our method is model-free and even instance-free. Moreover, it has no hyperparameters and gives a more accurate estimate of the Bayes error than several baselines empirically. Experiments using our method suggest that recently proposed deep networks such as the Vision Transformer m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#21442;&#25968;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#21644;&#25512;&#26029;&#20855;&#26377;&#20132;&#20114;&#22266;&#23450;&#25928;&#24212;&#30340;&#38754;&#26495;&#25968;&#25454;&#27169;&#22411;&#20013;&#30340;&#22238;&#24402;&#21442;&#25968;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#31616;&#21333;&#30340;&#20559;&#26368;&#23567;&#20108;&#20056;&#24418;&#24335;&#65292;&#19981;&#38656;&#35201;&#36845;&#20195;&#36807;&#31243;&#21644;&#20808;&#21069;&#30340;&#22240;&#23376;&#20272;&#35745;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#27178;&#25130;&#38754;&#33258;&#21161;&#27861;&#23454;&#29616;&#32479;&#19968;&#26377;&#25928;&#30340;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2201.11482</link><description>&lt;p&gt;
&#20132;&#20114;&#22266;&#23450;&#25928;&#24212;&#38754;&#26495;&#25968;&#25454;&#27169;&#22411;&#30340;&#21322;&#21442;&#25968;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A semiparametric approach for interactive fixed effects panel data models. (arXiv:2201.11482v2 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.11482
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#21442;&#25968;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#21644;&#25512;&#26029;&#20855;&#26377;&#20132;&#20114;&#22266;&#23450;&#25928;&#24212;&#30340;&#38754;&#26495;&#25968;&#25454;&#27169;&#22411;&#20013;&#30340;&#22238;&#24402;&#21442;&#25968;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#31616;&#21333;&#30340;&#20559;&#26368;&#23567;&#20108;&#20056;&#24418;&#24335;&#65292;&#19981;&#38656;&#35201;&#36845;&#20195;&#36807;&#31243;&#21644;&#20808;&#21069;&#30340;&#22240;&#23376;&#20272;&#35745;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#27178;&#25130;&#38754;&#33258;&#21161;&#27861;&#23454;&#29616;&#32479;&#19968;&#26377;&#25928;&#30340;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a semiparametric approach for estimating and inferring regression parameters in a panel data model with interactive fixed effects, which has a simple partial least squares form and does not require iterative procedures or previous factor estimation. Uniformly valid inference can be achieved by using the cross-sectional bootstrap.
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#21644;&#25512;&#26029;&#20855;&#26377;&#20132;&#20114;&#22266;&#23450;&#25928;&#24212;&#30340;&#38754;&#26495;&#25968;&#25454;&#27169;&#22411;&#20013;&#30340;&#22238;&#24402;&#21442;&#25968;&#12290;&#23427;&#22522;&#20110;&#36825;&#26679;&#19968;&#20010;&#20551;&#35774;&#65292;&#21363;&#22240;&#23376;&#36733;&#33655;&#21487;&#20197;&#34920;&#31034;&#20026;&#21327;&#21464;&#37327;&#30340;&#26102;&#38388;&#24179;&#22343;&#20540;&#30340;&#26410;&#30693;&#24179;&#28369;&#20989;&#25968;&#21152;&#19978;&#19968;&#20010;&#29305;&#24322;&#24615;&#35823;&#24046;&#39033;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#20855;&#26377;&#31616;&#21333;&#30340;&#20559;&#26368;&#23567;&#20108;&#20056;&#24418;&#24335;&#65292;&#26082;&#19981;&#38656;&#35201;&#36845;&#20195;&#36807;&#31243;&#65292;&#20063;&#19981;&#38656;&#35201;&#20808;&#21069;&#30340;&#22240;&#23376;&#20272;&#35745;&#12290;&#25105;&#20204;&#36890;&#36807;&#21457;&#29616;&#26497;&#38480;&#20998;&#24067;&#20855;&#26377;&#19981;&#36830;&#32493;&#24615;&#26469;&#25512;&#23548;&#20854;&#28176;&#36817;&#24615;&#36136;&#65292;&#36825;&#21462;&#20915;&#20110;&#25105;&#20204;&#22522;&#30784;&#20989;&#25968;&#30340;&#35299;&#37322;&#33021;&#21147;&#65292;&#20854;&#30001;&#22240;&#23376;&#36733;&#33655;&#35823;&#24046;&#30340;&#26041;&#24046;&#34920;&#31034;&#12290;&#22240;&#27492;&#65292;&#22522;&#20110;&#28176;&#36817;&#21327;&#26041;&#24046;&#20272;&#35745;&#30340;&#36890;&#24120;&#30340;&#8220;&#25554;&#20837;&#8221;&#26041;&#27861;&#20165;&#22312;&#28857;&#19978;&#26377;&#25928;&#65292;&#24182;&#19988;&#21487;&#33021;&#20135;&#29983;&#36807;&#24230;&#25110;&#19981;&#36275;&#30340;&#35206;&#30422;&#27010;&#29575;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#27178;&#25130;&#38754;&#33258;&#21161;&#27861;&#23454;&#29616;&#32479;&#19968;&#26377;&#25928;&#30340;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a new approach for the estimation and inference of the regression parameters in a panel data model with interactive fixed effects. It relies on the assumption that the factor loadings can be expressed as an unknown smooth function of the time average of covariates plus an idiosyncratic error term. Compared to existing approaches, our estimator has a simple partial least squares form and does neither require iterative procedures nor the previous estimation of factors.  We derive its asymptotic properties by finding out that the limiting distribution has a discontinuity, depending on the explanatory power of our basis functions which is expressed by the variance of the error of the factor loadings. As a result, the usual ``plug-in" methods based on estimates of the asymptotic covariance are only valid pointwise and may produce either over- or under-coverage probabilities. We show that uniformly valid inference can be achieved by using the cross-sectional bootstrap. A 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23558;&#26333;&#20809;&#26144;&#23556;&#30340;&#20004;&#20010;&#20316;&#29992;&#20998;&#24320;&#65292;&#20174;&#32780;&#22312;&#26333;&#20809;&#34987;&#38169;&#35823;&#25351;&#23450;&#26102;&#31934;&#30830;&#20272;&#35745;&#26333;&#20809;&#25928;&#24212;&#65292;&#36991;&#20813;&#20102;&#24120;&#24120;&#26159;&#21487;&#30097;&#30340;&#20551;&#35774;&#12290;</title><link>http://arxiv.org/abs/2103.06471</link><description>&lt;p&gt;
&#35823;&#24046;&#26333;&#20809;&#26144;&#23556;&#19979;&#30340;&#22240;&#26524;&#25512;&#26029;&#65306;&#21306;&#20998;&#23450;&#20041;&#21644;&#20551;&#35774;
&lt;/p&gt;
&lt;p&gt;
Causal inference with misspecified exposure mappings: separating definitions and assumptions. (arXiv:2103.06471v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2103.06471
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23558;&#26333;&#20809;&#26144;&#23556;&#30340;&#20004;&#20010;&#20316;&#29992;&#20998;&#24320;&#65292;&#20174;&#32780;&#22312;&#26333;&#20809;&#34987;&#38169;&#35823;&#25351;&#23450;&#26102;&#31934;&#30830;&#20272;&#35745;&#26333;&#20809;&#25928;&#24212;&#65292;&#36991;&#20813;&#20102;&#24120;&#24120;&#26159;&#21487;&#30097;&#30340;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a new method to separate the two roles of exposure mappings, which allows for precise estimation of exposure effects even when the exposures are misspecified, avoiding often questionable assumptions.
&lt;/p&gt;
&lt;p&gt;
&#24403;&#23454;&#39564;&#21333;&#20301;&#30456;&#20114;&#20316;&#29992;&#26102;&#65292;&#26333;&#20809;&#26144;&#23556;&#26377;&#21161;&#20110;&#30740;&#31350;&#22797;&#26434;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#30446;&#21069;&#30340;&#26041;&#27861;&#35201;&#27714;&#23454;&#39564;&#32773;&#22312;&#23450;&#20041;&#24863;&#20852;&#36259;&#30340;&#25928;&#24212;&#21644;&#23545;&#24178;&#25200;&#32467;&#26500;&#26045;&#21152;&#20551;&#35774;&#26102;&#20351;&#29992;&#30456;&#21516;&#30340;&#26333;&#20809;&#26144;&#23556;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#36825;&#20004;&#20010;&#35282;&#33394;&#24456;&#23569;&#37325;&#21512;&#65292;&#23454;&#39564;&#32773;&#34987;&#36843;&#20570;&#20986;&#24120;&#24120;&#26159;&#21487;&#30097;&#30340;&#20551;&#35774;&#65292;&#21363;&#20182;&#20204;&#30340;&#26333;&#20809;&#26144;&#23556;&#26159;&#27491;&#30830;&#30340;&#12290;&#26412;&#25991;&#35748;&#20026;&#65292;&#26333;&#20809;&#26144;&#23556;&#30446;&#21069;&#25152;&#36215;&#30340;&#20004;&#20010;&#20316;&#29992;&#21487;&#20197;&#65292;&#32780;&#19988;&#36890;&#24120;&#24212;&#35813;&#20998;&#24320;&#65292;&#36825;&#26679;&#26333;&#20809;&#23601;&#21487;&#20197;&#29992;&#26469;&#23450;&#20041;&#25928;&#24212;&#65292;&#32780;&#19981;&#24517;&#20551;&#35774;&#23427;&#20204;&#25429;&#25417;&#20102;&#23454;&#39564;&#20013;&#30340;&#23436;&#25972;&#22240;&#26524;&#32467;&#26500;&#12290;&#26412;&#25991;&#36890;&#36807;&#25552;&#20379;&#26333;&#20809;&#25928;&#24212;&#21487;&#20197;&#22312;&#26333;&#20809;&#34987;&#38169;&#35823;&#25351;&#23450;&#26102;&#31934;&#30830;&#20272;&#35745;&#30340;&#26465;&#20214;&#65292;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#22312;&#23454;&#36341;&#20013;&#26159;&#21487;&#34892;&#30340;&#12290;&#19968;&#20123;&#37325;&#35201;&#30340;&#38382;&#39064;&#20173;&#28982;&#27809;&#26377;&#35299;&#20915;&#12290;
&lt;/p&gt;
&lt;p&gt;
Exposure mappings facilitate investigations of complex causal effects when units interact in experiments. Current methods require experimenters to use the same exposure mappings both to define the effect of interest and to impose assumptions on the interference structure. However, the two roles rarely coincide in practice, and experimenters are forced to make the often questionable assumption that their exposures are correctly specified. This paper argues that the two roles exposure mappings currently serve can, and typically should, be separated, so that exposures are used to define effects without necessarily assuming that they are capturing the complete causal structure in the experiment. The paper shows that this approach is practically viable by providing conditions under which exposure effects can be precisely estimated when the exposures are misspecified. Some important questions remain open.
&lt;/p&gt;</description></item><item><title>NOMU&#26159;&#19968;&#31181;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#21487;&#20197;&#22312;&#26080;&#22122;&#22768;&#35774;&#32622;&#19979;&#65292;&#36890;&#36807;&#35774;&#35745;&#19968;&#20010;&#30001;&#20004;&#20010;&#36830;&#25509;&#30340;&#23376;NN&#32452;&#25104;&#30340;&#32593;&#32476;&#26550;&#26500;&#65292;&#24182;&#20351;&#29992;&#31934;&#24515;&#35774;&#35745;&#30340;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#35757;&#32451;&#65292;&#26469;&#25429;&#25417;NN&#30340;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#12290;&#35813;&#27169;&#22411;&#28385;&#36275;&#20116;&#20010;&#20851;&#20110;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;&#37325;&#35201;&#24895;&#26395;&#12290;</title><link>http://arxiv.org/abs/2102.13640</link><description>&lt;p&gt;
NOMU: &#22522;&#20110;&#31070;&#32463;&#20248;&#21270;&#30340;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
NOMU: Neural Optimization-based Model Uncertainty. (arXiv:2102.13640v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.13640
&lt;/p&gt;
&lt;p&gt;
NOMU&#26159;&#19968;&#31181;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#21487;&#20197;&#22312;&#26080;&#22122;&#22768;&#35774;&#32622;&#19979;&#65292;&#36890;&#36807;&#35774;&#35745;&#19968;&#20010;&#30001;&#20004;&#20010;&#36830;&#25509;&#30340;&#23376;NN&#32452;&#25104;&#30340;&#32593;&#32476;&#26550;&#26500;&#65292;&#24182;&#20351;&#29992;&#31934;&#24515;&#35774;&#35745;&#30340;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#35757;&#32451;&#65292;&#26469;&#25429;&#25417;NN&#30340;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#12290;&#35813;&#27169;&#22411;&#28385;&#36275;&#20116;&#20010;&#20851;&#20110;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;&#37325;&#35201;&#24895;&#26395;&#12290;
&lt;/p&gt;
&lt;p&gt;
NOMU is a new neural network model that captures model uncertainty for neural networks (NNs) in regression by designing a network architecture consisting of two connected sub-NNs, one for model prediction and one for model uncertainty, and training it using a carefully-designed loss function. The model satisfies five important desiderata regarding model uncertainty.
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#22238;&#24402;&#20013;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;&#20272;&#35745;&#26041;&#27861;&#12290;&#20026;&#20102;&#38548;&#31163;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;&#24433;&#21709;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#31232;&#32570;&#35757;&#32451;&#25968;&#25454;&#30340;&#26080;&#22122;&#22768;&#35774;&#32622;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20116;&#20010;&#20851;&#20110;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;&#37325;&#35201;&#24895;&#26395;&#65292;&#20219;&#20309;&#26041;&#27861;&#37117;&#24212;&#35813;&#28385;&#36275;&#36825;&#20123;&#24895;&#26395;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#65292;&#21363;&#20351;&#26159;&#36125;&#21494;&#26031;&#29702;&#35770;&#25152;&#35201;&#27714;&#30340;&#19968;&#20123;&#24895;&#26395;&#65292;&#24050;&#32463;&#24314;&#31435;&#30340;&#22522;&#20934;&#27979;&#35797;&#20063;&#32463;&#24120;&#26080;&#27861;&#21487;&#38752;&#22320;&#25429;&#25417;&#21040;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#25429;&#25417;NN&#30340;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#65292;&#31216;&#20026;&#31070;&#32463;&#20248;&#21270;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#65288;NOMU&#65289;&#12290; NOMU&#30340;&#20027;&#35201;&#24605;&#24819;&#26159;&#35774;&#35745;&#19968;&#20010;&#30001;&#20004;&#20010;&#36830;&#25509;&#30340;&#23376;NN&#32452;&#25104;&#30340;&#32593;&#32476;&#26550;&#26500;&#65292;&#19968;&#20010;&#29992;&#20110;&#27169;&#22411;&#39044;&#27979;&#65292;&#19968;&#20010;&#29992;&#20110;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#20351;&#29992;&#31934;&#24515;&#35774;&#35745;&#30340;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#35757;&#32451;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#35774;&#35745;&#24378;&#21046;NOMU&#28385;&#36275;&#25105;&#20204;&#30340;&#20116;&#20010;&#24895;&#26395;&#12290;&#30001;&#20110;&#20854;&#27169;&#22359;&#21270;&#26550;&#26500;&#65292;&#22914;&#26524;&#32473;&#23450;&#35775;&#38382;&#26435;&#38480;&#65292;NOMU&#21487;&#20197;&#20026;&#20219;&#20309;&#32473;&#23450;&#30340;&#65288;&#20808;&#21069;&#35757;&#32451;&#30340;&#65289;NN&#25552;&#20379;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study methods for estimating model uncertainty for neural networks (NNs) in regression. To isolate the effect of model uncertainty, we focus on a noiseless setting with scarce training data. We introduce five important desiderata regarding model uncertainty that any method should satisfy. However, we find that established benchmarks often fail to reliably capture some of these desiderata, even those that are required by Bayesian theory. To address this, we introduce a new approach for capturing model uncertainty for NNs, which we call Neural Optimization-based Model Uncertainty (NOMU). The main idea of NOMU is to design a network architecture consisting of two connected sub-NNs, one for model prediction and one for model uncertainty, and to train it using a carefully-designed loss function. Importantly, our design enforces that NOMU satisfies our five desiderata. Due to its modular architecture, NOMU can provide model uncertainty for any given (previously trained) NN if given access
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#19981;&#30830;&#23450;&#24615;&#23545;&#19981;&#21516;&#20154;&#32676;&#30340;&#24433;&#21709;&#26159;&#19981;&#24179;&#31561;&#30340;&#65292;&#34429;&#28982;&#23427;&#20250;&#22312;&#25152;&#26377;&#20154;&#21475;&#32676;&#20307;&#20013;&#20135;&#29983;&#35823;&#24046;&#65292;&#20294;&#35823;&#24046;&#30340;&#31867;&#22411;&#20250;&#26377;&#31995;&#32479;&#24615;&#30340;&#21464;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#24179;&#26435;&#20449;&#24687;&#30340;&#31574;&#30053;&#65292;&#21487;&#20197;&#28040;&#38500;&#36825;&#31181;&#24046;&#24322;&#24182;&#25193;&#22823;&#26426;&#20250;&#30340;&#33719;&#21462;&#65292;&#36825;&#21487;&#20197;&#20316;&#20026;&#24179;&#26435;&#34892;&#21160;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2102.10019</link><description>&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#30340;&#19981;&#24179;&#31561;&#24433;&#21709;&#65306;&#24179;&#26435;&#34892;&#21160;&#19982;&#24179;&#26435;&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;
The Disparate Impact of Uncertainty: Affirmative Action vs. Affirmative Information. (arXiv:2102.10019v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.10019
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#19981;&#30830;&#23450;&#24615;&#23545;&#19981;&#21516;&#20154;&#32676;&#30340;&#24433;&#21709;&#26159;&#19981;&#24179;&#31561;&#30340;&#65292;&#34429;&#28982;&#23427;&#20250;&#22312;&#25152;&#26377;&#20154;&#21475;&#32676;&#20307;&#20013;&#20135;&#29983;&#35823;&#24046;&#65292;&#20294;&#35823;&#24046;&#30340;&#31867;&#22411;&#20250;&#26377;&#31995;&#32479;&#24615;&#30340;&#21464;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#24179;&#26435;&#20449;&#24687;&#30340;&#31574;&#30053;&#65292;&#21487;&#20197;&#28040;&#38500;&#36825;&#31181;&#24046;&#24322;&#24182;&#25193;&#22823;&#26426;&#20250;&#30340;&#33719;&#21462;&#65292;&#36825;&#21487;&#20197;&#20316;&#20026;&#24179;&#26435;&#34892;&#21160;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proves that uncertainty has a disparate impact on different demographic groups, with varying types of errors. The proposed strategy, called Affirmative Information, can eliminate this disparity and broaden access to opportunity, serving as an alternative to Affirmative Action.
&lt;/p&gt;
&lt;p&gt;
&#20687;&#36151;&#27454;&#25209;&#20934;&#12289;&#21307;&#30103;&#24178;&#39044;&#21644;&#22823;&#23398;&#24405;&#21462;&#36825;&#26679;&#30340;&#20851;&#38190;&#20915;&#31574;&#26159;&#22312;&#23384;&#22312;&#19981;&#30830;&#23450;&#24615;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#39044;&#27979;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19981;&#30830;&#23450;&#24615;&#20855;&#26377;&#19981;&#24179;&#31561;&#30340;&#24433;&#21709;&#12290;&#34429;&#28982;&#23427;&#20250;&#22312;&#25152;&#26377;&#20154;&#21475;&#32676;&#20307;&#20013;&#20135;&#29983;&#35823;&#24046;&#65292;&#20294;&#35823;&#24046;&#30340;&#31867;&#22411;&#20250;&#26377;&#31995;&#32479;&#24615;&#30340;&#21464;&#21270;&#65306;&#24179;&#22343;&#32467;&#26524;&#36739;&#39640;&#30340;&#32676;&#20307;&#36890;&#24120;&#34987;&#20998;&#37197;&#26356;&#39640;&#30340;&#20551;&#38451;&#24615;&#29575;&#65292;&#32780;&#24179;&#22343;&#32467;&#26524;&#36739;&#20302;&#30340;&#32676;&#20307;&#21017;&#34987;&#20998;&#37197;&#26356;&#39640;&#30340;&#20551;&#38452;&#24615;&#29575;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#39069;&#22806;&#30340;&#25968;&#25454;&#33719;&#21462;&#21487;&#20197;&#28040;&#38500;&#36825;&#31181;&#24046;&#24322;&#24182;&#25193;&#22823;&#26426;&#20250;&#30340;&#33719;&#21462;&#12290;&#25105;&#20204;&#31216;&#20043;&#20026;&#24179;&#26435;&#20449;&#24687;&#30340;&#31574;&#30053;&#21487;&#20197;&#20316;&#20026;&#24179;&#26435;&#34892;&#21160;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Critical decisions like loan approvals, medical interventions, and college admissions are guided by predictions made in the presence of uncertainty. In this paper, we prove that uncertainty has a disparate impact. While it imparts errors across all demographic groups, the types of errors vary systematically: Groups with higher average outcomes are typically assigned higher false positive rates, while those with lower average outcomes are assigned higher false negative rates. We show that additional data acquisition can eliminate the disparity and broaden access to opportunity. The strategy, which we call Affirmative Information, could stand as an alternative to Affirmative Action.
&lt;/p&gt;</description></item><item><title>LOCUS&#26159;&#19968;&#31181;&#26032;&#30340;&#22823;&#33041;&#32593;&#32476;&#36830;&#25509;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#65292;&#20351;&#29992;&#20302;&#31209;&#32467;&#26500;&#21644;&#22343;&#21248;&#31232;&#30095;&#24615;&#65292;&#33021;&#22815;&#26356;&#26377;&#25928;&#21644;&#20934;&#30830;&#22320;&#20998;&#31163;&#36830;&#25509;&#30697;&#38453;&#28304;&#65292;&#26377;&#26395;&#25104;&#20026;&#29702;&#35299;&#22823;&#33041;&#32452;&#32455;&#30340;&#20851;&#38190;&#12290;</title><link>http://arxiv.org/abs/2008.08915</link><description>&lt;p&gt;
LOCUS&#65306;&#19968;&#31181;&#20351;&#29992;&#20302;&#31209;&#32467;&#26500;&#21644;&#22343;&#21248;&#31232;&#30095;&#24615;&#30340;&#22823;&#33041;&#32593;&#32476;&#36830;&#25509;&#30697;&#38453;&#20998;&#35299;&#26032;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
LOCUS: A Novel Decomposition Method for Brain Network Connectivity Matrices using Low-rank Structure with Uniform Sparsity. (arXiv:2008.08915v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2008.08915
&lt;/p&gt;
&lt;p&gt;
LOCUS&#26159;&#19968;&#31181;&#26032;&#30340;&#22823;&#33041;&#32593;&#32476;&#36830;&#25509;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#65292;&#20351;&#29992;&#20302;&#31209;&#32467;&#26500;&#21644;&#22343;&#21248;&#31232;&#30095;&#24615;&#65292;&#33021;&#22815;&#26356;&#26377;&#25928;&#21644;&#20934;&#30830;&#22320;&#20998;&#31163;&#36830;&#25509;&#30697;&#38453;&#28304;&#65292;&#26377;&#26395;&#25104;&#20026;&#29702;&#35299;&#22823;&#33041;&#32452;&#32455;&#30340;&#20851;&#38190;&#12290;
&lt;/p&gt;
&lt;p&gt;
LOCUS is a novel method for decomposing brain network connectivity matrices using low-rank structure and uniform sparsity, which achieves more efficient and accurate source separation and has the potential to serve as a key for understanding brain organizations.
&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#23548;&#21521;&#30740;&#31350;&#22312;&#35768;&#22810;&#31185;&#23398;&#39046;&#22495;&#20013;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#22312;&#31070;&#32463;&#31185;&#23398;&#30740;&#31350;&#20013;&#65292;&#22522;&#20110;&#25104;&#20687;&#30340;&#32593;&#32476;&#36830;&#25509;&#24230;&#37327;&#24050;&#25104;&#20026;&#29702;&#35299;&#22823;&#33041;&#32452;&#32455;&#30340;&#20851;&#38190;&#65292;&#21487;&#33021;&#20316;&#20026;&#20010;&#20307;&#31070;&#32463;&#25351;&#32441;&#12290;&#20998;&#26512;&#36830;&#25509;&#30697;&#38453;&#23384;&#22312;&#20027;&#35201;&#25361;&#25112;&#65292;&#21253;&#25324;&#22823;&#33041;&#32593;&#32476;&#30340;&#39640;&#32500;&#24230;&#65292;&#35266;&#23519;&#21040;&#30340;&#36830;&#25509;&#19979;&#38754;&#30340;&#26410;&#30693;&#28508;&#22312;&#28304;&#20197;&#21450;&#23548;&#33268;&#34394;&#20551;&#21457;&#29616;&#30340;&#22823;&#37327;&#33041;&#36830;&#25509;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30450;&#28304;&#20998;&#31163;&#26041;&#27861;&#65292;&#21363;&#20855;&#26377;&#20302;&#31209;&#32467;&#26500;&#21644;&#22343;&#21248;&#31232;&#30095;&#24615;&#65288;LOCUS&#65289;&#30340;&#23436;&#20840;&#25968;&#25454;&#39537;&#21160;&#20998;&#35299;&#26041;&#27861;&#65292;&#29992;&#20110;&#32593;&#32476;&#24230;&#37327;&#12290;&#19982;&#23558;&#36830;&#25509;&#30697;&#38453;&#21521;&#37327;&#21270;&#24182;&#24573;&#30053;&#22823;&#33041;&#32593;&#32476;&#25299;&#25169;&#30340;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;LOCUS&#20351;&#29992;&#20302;&#31209;&#32467;&#26500;&#23454;&#29616;&#20102;&#26356;&#26377;&#25928;&#21644;&#20934;&#30830;&#30340;&#36830;&#25509;&#30697;&#38453;&#28304;&#20998;&#31163;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#35282;&#24230;&#30340;&#22343;&#21248;&#31232;&#30095;&#27491;&#21017;&#21270;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#36830;&#25509;&#30697;&#38453;&#20998;&#35299;&#20013;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Network-oriented research has been increasingly popular in many scientific areas. In neuroscience research, imaging-based network connectivity measures have become the key for understanding brain organizations, potentially serving as individual neural fingerprints. There are major challenges in analyzing connectivity matrices including the high dimensionality of brain networks, unknown latent sources underlying the observed connectivity, and the large number of brain connections leading to spurious findings. In this paper, we propose a novel blind source separation method with low-rank structure and uniform sparsity (LOCUS) as a fully data-driven decomposition method for network measures. Compared with the existing method that vectorizes connectivity matrices ignoring brain network topology, LOCUS achieves more efficient and accurate source separation for connectivity matrices using low-rank structure. We propose a novel angle-based uniform sparsity regularization that demonstrates bet
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27969;&#30340;&#24490;&#29615;&#28151;&#21512;&#23494;&#24230;&#32593;&#32476;&#65292;&#36890;&#36807;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#19978;&#23450;&#20041;&#19968;&#20010;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65292;&#23558;&#24490;&#29615;&#28151;&#21512;&#23494;&#24230;&#32593;&#32476;&#25512;&#24191;&#21040;&#38750;&#32447;&#24615;&#21464;&#25442;&#30340;&#30446;&#26631;&#24207;&#21015;&#19978;&#65292;&#35813;&#27169;&#22411;&#22312;&#22270;&#20687;&#24207;&#21015;&#30340;&#25311;&#21512;&#24230;&#19978;&#34920;&#29616;&#26174;&#33879;&#65292;&#20855;&#26377;&#26174;&#33879;&#30340;&#24314;&#27169;&#33021;&#21147;&#65292;&#22312;&#23545;&#25968;&#20284;&#28982;&#24230;&#37327;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2008.02144</link><description>&lt;p&gt;
FRMDN: &#22522;&#20110;&#27969;&#30340;&#24490;&#29615;&#28151;&#21512;&#23494;&#24230;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
FRMDN: Flow-based Recurrent Mixture Density Network. (arXiv:2008.02144v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2008.02144
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27969;&#30340;&#24490;&#29615;&#28151;&#21512;&#23494;&#24230;&#32593;&#32476;&#65292;&#36890;&#36807;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#19978;&#23450;&#20041;&#19968;&#20010;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65292;&#23558;&#24490;&#29615;&#28151;&#21512;&#23494;&#24230;&#32593;&#32476;&#25512;&#24191;&#21040;&#38750;&#32447;&#24615;&#21464;&#25442;&#30340;&#30446;&#26631;&#24207;&#21015;&#19978;&#65292;&#35813;&#27169;&#22411;&#22312;&#22270;&#20687;&#24207;&#21015;&#30340;&#25311;&#21512;&#24230;&#19978;&#34920;&#29616;&#26174;&#33879;&#65292;&#20855;&#26377;&#26174;&#33879;&#30340;&#24314;&#27169;&#33021;&#21147;&#65292;&#22312;&#23545;&#25968;&#20284;&#28982;&#24230;&#37327;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a flow-based recurrent mixture density network (FRMDN) that generalizes recurrent mixture density networks by defining a Gaussian mixture model on a non-linearly transformed target sequence in each time-step. The model significantly improves the fit to image sequences and outperforms other state-of-the-art methods in terms of the log-likelihood.
&lt;/p&gt;
&lt;p&gt;
&#24490;&#29615;&#28151;&#21512;&#23494;&#24230;&#32593;&#32476;&#26159;&#19968;&#31867;&#37325;&#35201;&#30340;&#27010;&#29575;&#27169;&#22411;&#65292;&#24191;&#27867;&#24212;&#29992;&#20110;&#24207;&#21015;&#24314;&#27169;&#21644;&#24207;&#21015;&#21040;&#24207;&#21015;&#26144;&#23556;&#24212;&#29992;&#20013;&#12290;&#22312;&#36825;&#31867;&#27169;&#22411;&#20013;&#65292;&#30446;&#26631;&#24207;&#21015;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#30340;&#23494;&#24230;&#30001;&#20855;&#26377;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#30340;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#24314;&#27169;&#12290;&#26412;&#25991;&#36890;&#36807;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#19978;&#23450;&#20041;&#19968;&#20010;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65292;&#23558;&#24490;&#29615;&#28151;&#21512;&#23494;&#24230;&#32593;&#32476;&#25512;&#24191;&#21040;&#38750;&#32447;&#24615;&#21464;&#25442;&#30340;&#30446;&#26631;&#24207;&#21015;&#19978;&#12290;&#38750;&#32447;&#24615;&#21464;&#25442;&#31354;&#38388;&#26159;&#36890;&#36807;&#24402;&#19968;&#21270;&#27969;&#21019;&#24314;&#30340;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#35813;&#27169;&#22411;&#26174;&#33879;&#25552;&#39640;&#20102;&#22270;&#20687;&#24207;&#21015;&#30340;&#25311;&#21512;&#24230;&#65292;&#29992;&#23545;&#25968;&#20284;&#28982;&#24230;&#37327;&#12290;&#25105;&#20204;&#36824;&#23558;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#24212;&#29992;&#20110;&#19968;&#20123;&#35821;&#38899;&#21644;&#22270;&#20687;&#25968;&#25454;&#65292;&#24182;&#35266;&#23519;&#21040;&#35813;&#27169;&#22411;&#20855;&#26377;&#26174;&#33879;&#30340;&#24314;&#27169;&#33021;&#21147;&#65292;&#22312;&#23545;&#25968;&#20284;&#28982;&#24230;&#37327;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The class of recurrent mixture density networks is an important class of probabilistic models used extensively in sequence modeling and sequence-to-sequence mapping applications. In this class of models, the density of a target sequence in each time-step is modeled by a Gaussian mixture model with the parameters given by a recurrent neural network. In this paper, we generalize recurrent mixture density networks by defining a Gaussian mixture model on a non-linearly transformed target sequence in each time-step. The non-linearly transformed space is created by normalizing flow. We observed that this model significantly improves the fit to image sequences measured by the log-likelihood. We also applied the proposed model on some speech and image data, and observed that the model has significant modeling power outperforming other state-of-the-art methods in terms of the log-likelihood.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24322;&#24120;&#26816;&#27979;&#31639;&#27861;&#65292;&#31216;&#20026;&#24322;&#24120;&#24863;&#30693;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#20462;&#25913;&#25104;&#26412;&#20989;&#25968;&#26469;&#23398;&#20064;&#27491;&#24120;&#20107;&#20214;&#65292;&#24182;&#20102;&#35299;&#24322;&#24120;&#20107;&#20214;&#12290;&#35813;&#26041;&#27861;&#22312;&#19981;&#21516;&#30340;&#31890;&#23376;&#29289;&#29702;&#24773;&#20917;&#21644;&#26631;&#20934;&#35745;&#31639;&#26426;&#35270;&#35273;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#35782;&#21035;&#20197;&#21069;&#26410;&#35265;&#36807;&#30340;&#24322;&#24120;&#65292;&#24182;&#22312;&#20102;&#35299;&#36275;&#22815;&#22810;&#30340;&#24322;&#24120;&#26102;&#21464;&#24471;&#26356;&#21152;&#31283;&#20581;&#12290;</title><link>http://arxiv.org/abs/2007.14462</link><description>&lt;p&gt;
&#24322;&#24120;&#24863;&#30693;
&lt;/p&gt;
&lt;p&gt;
Anomaly Awareness. (arXiv:2007.14462v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2007.14462
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24322;&#24120;&#26816;&#27979;&#31639;&#27861;&#65292;&#31216;&#20026;&#24322;&#24120;&#24863;&#30693;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#20462;&#25913;&#25104;&#26412;&#20989;&#25968;&#26469;&#23398;&#20064;&#27491;&#24120;&#20107;&#20214;&#65292;&#24182;&#20102;&#35299;&#24322;&#24120;&#20107;&#20214;&#12290;&#35813;&#26041;&#27861;&#22312;&#19981;&#21516;&#30340;&#31890;&#23376;&#29289;&#29702;&#24773;&#20917;&#21644;&#26631;&#20934;&#35745;&#31639;&#26426;&#35270;&#35273;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#35782;&#21035;&#20197;&#21069;&#26410;&#35265;&#36807;&#30340;&#24322;&#24120;&#65292;&#24182;&#22312;&#20102;&#35299;&#36275;&#22815;&#22810;&#30340;&#24322;&#24120;&#26102;&#21464;&#24471;&#26356;&#21152;&#31283;&#20581;&#12290;
&lt;/p&gt;
&lt;p&gt;
The paper proposes a new anomaly detection algorithm called Anomaly Awareness, which learns about normal events while being made aware of the anomalies through a modification of the cost function. The method is effective in identifying anomalies not seen before and becomes more robust as it is made aware of a varied-enough set of anomalies. It is applied in different Particle Physics situations and in standard Computer Vision tasks.
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24322;&#24120;&#26816;&#27979;&#31639;&#27861;&#65292;&#31216;&#20026;&#24322;&#24120;&#24863;&#30693;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#20462;&#25913;&#25104;&#26412;&#20989;&#25968;&#26469;&#23398;&#20064;&#27491;&#24120;&#20107;&#20214;&#65292;&#24182;&#20102;&#35299;&#24322;&#24120;&#20107;&#20214;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22312;&#19981;&#21516;&#30340;&#31890;&#23376;&#29289;&#29702;&#24773;&#20917;&#21644;&#26631;&#20934;&#35745;&#31639;&#26426;&#35270;&#35273;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#12290;&#20363;&#22914;&#65292;&#25105;&#20204;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#30001;&#26631;&#20934;&#27169;&#22411;&#39030;&#22840;&#20811;&#21644;QCD&#20107;&#20214;&#29983;&#25104;&#30340;Fat Jet&#25299;&#25169;&#30340;&#22270;&#20687;&#65292;&#24182;&#38024;&#23545;&#19968;&#31995;&#21015;&#26032;&#29289;&#29702;&#22330;&#26223;&#36827;&#34892;&#27979;&#35797;&#65292;&#21253;&#25324;&#20855;&#26377;EFT&#25928;&#24212;&#30340;&#24076;&#26684;&#26031;&#20135;&#29983;&#21644;&#34928;&#21464;&#25104;&#20004;&#20010;&#12289;&#19977;&#20010;&#25110;&#22235;&#20010;&#23376;&#21943;&#27880;&#30340;&#20849;&#25391;&#12290;&#25105;&#20204;&#21457;&#29616;&#35813;&#31639;&#27861;&#33021;&#22815;&#26377;&#25928;&#22320;&#35782;&#21035;&#20197;&#21069;&#26410;&#35265;&#36807;&#30340;&#24322;&#24120;&#65292;&#24182;&#22312;&#25105;&#20204;&#35753;&#23427;&#20102;&#35299;&#36275;&#22815;&#22810;&#30340;&#24322;&#24120;&#26102;&#21464;&#24471;&#26356;&#21152;&#31283;&#20581;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a new algorithm for anomaly detection called Anomaly Awareness. The algorithm learns about normal events while being made aware of the anomalies through a modification of the cost function. We show how this method works in different Particle Physics situations and in standard Computer Vision tasks. For example, we apply the method to images from a Fat Jet topology generated by Standard Model Top and QCD events, and test it against an array of new physics scenarios, including Higgs production with EFT effects and resonances decaying into two, three or four subjets. We find that the algorithm is effective identifying anomalies not seen before, and becomes robust as we make it aware of a varied-enough set of anomalies.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;FPGA&#30340;&#36731;&#37327;&#32423;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#21033;&#29992;OS-ELM&#31639;&#27861;&#36827;&#34892;&#35757;&#32451;&#65292;&#36991;&#20813;&#20102;DQN&#38656;&#35201;&#22823;&#37327;&#32531;&#20914;&#21306;&#21644;&#25209;&#22788;&#29702;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;L2&#27491;&#21017;&#21270;&#21644;&#35889;&#24402;&#19968;&#21270;&#30340;&#32452;&#21512;&#20351;&#24471;&#24378;&#21270;&#23398;&#20064;&#26356;&#21152;&#31283;&#23450;&#12290;</title><link>http://arxiv.org/abs/2005.04646</link><description>&lt;p&gt;
&#22522;&#20110;FPGA&#30340;&#22312;&#32447;&#39034;&#24207;&#23398;&#20064;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
An FPGA-Based On-Device Reinforcement Learning Approach using Online Sequential Learning. (arXiv:2005.04646v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2005.04646
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;FPGA&#30340;&#36731;&#37327;&#32423;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#21033;&#29992;OS-ELM&#31639;&#27861;&#36827;&#34892;&#35757;&#32451;&#65292;&#36991;&#20813;&#20102;DQN&#38656;&#35201;&#22823;&#37327;&#32531;&#20914;&#21306;&#21644;&#25209;&#22788;&#29702;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;L2&#27491;&#21017;&#21270;&#21644;&#35889;&#24402;&#19968;&#21270;&#30340;&#32452;&#21512;&#20351;&#24471;&#24378;&#21270;&#23398;&#20064;&#26356;&#21152;&#31283;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a lightweight on-device reinforcement learning approach for low-cost FPGA devices, which uses OS-ELM algorithm for training and avoids the problem of requiring large buffers and batch processing in DQN. The combination of L2 regularization and spectral normalization is used to make the reinforcement learning more stable.
&lt;/p&gt;
&lt;p&gt;
DQN&#26159;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#24378;&#21270;&#23398;&#20064;&#30340;Q&#23398;&#20064;&#26041;&#27861;&#12290;DQN&#38656;&#35201;&#22823;&#37327;&#30340;&#32531;&#20914;&#21306;&#21644;&#25209;&#22788;&#29702;&#36827;&#34892;&#32463;&#39564;&#37325;&#25918;&#65292;&#24182;&#20381;&#36182;&#20110;&#22522;&#20110;&#21453;&#21521;&#20256;&#25773;&#30340;&#36845;&#20195;&#20248;&#21270;&#65292;&#20351;&#23427;&#20204;&#38590;&#20197;&#22312;&#36164;&#28304;&#26377;&#38480;&#30340;&#36793;&#32536;&#35774;&#22791;&#19978;&#23454;&#29616;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36731;&#37327;&#32423;&#30340;&#22522;&#20110;&#35774;&#22791;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#20302;&#25104;&#26412;&#30340;FPGA&#35774;&#22791;&#12290;&#23427;&#21033;&#29992;&#20102;&#26368;&#36817;&#25552;&#20986;&#30340;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#35774;&#22791;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#19981;&#20381;&#36182;&#20110;&#21453;&#21521;&#20256;&#25773;&#26041;&#27861;&#65292;&#32780;&#26159;&#20351;&#29992;&#22522;&#20110;OS-ELM&#65288;&#22312;&#32447;&#39034;&#24207;&#26497;&#38480;&#23398;&#20064;&#26426;&#65289;&#30340;&#35757;&#32451;&#31639;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;L2&#27491;&#21017;&#21270;&#21644;&#35889;&#24402;&#19968;&#21270;&#30340;&#32452;&#21512;&#65292;&#29992;&#20110;&#35774;&#22791;&#19978;&#30340;&#24378;&#21270;&#23398;&#20064;&#65292;&#20197;&#20415;&#23558;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20986;&#20540;&#36866;&#21512;&#20110;&#26576;&#20010;&#33539;&#22260;&#65292;&#24182;&#20351;&#24378;&#21270;&#23398;&#20064;&#21464;&#24471;&#31283;&#23450;&#12290;&#25152;&#25552;&#20986;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#26159;&#20026;PYNQ-Z1&#26495;&#35774;&#35745;&#30340;&#65292;&#20316;&#20026;&#20302;&#25104;&#26412;&#30340;FPGA&#24179;&#21488;&#12290;
&lt;/p&gt;
&lt;p&gt;
DQN (Deep Q-Network) is a method to perform Q-learning for reinforcement learning using deep neural networks. DQNs require a large buffer and batch processing for an experience replay and rely on a backpropagation based iterative optimization, making them difficult to be implemented on resource-limited edge devices. In this paper, we propose a lightweight on-device reinforcement learning approach for low-cost FPGA devices. It exploits a recently proposed neural-network based on-device learning approach that does not rely on the backpropagation method but uses OS-ELM (Online Sequential Extreme Learning Machine) based training algorithm. In addition, we propose a combination of L2 regularization and spectral normalization for the on-device reinforcement learning so that output values of the neural network can be fit into a certain range and the reinforcement learning becomes stable. The proposed reinforcement learning approach is designed for PYNQ-Z1 board as a low-cost FPGA platform. Th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#21644;&#32479;&#19968;&#30340;&#25554;&#20540;&#26041;&#27861;&#65292;&#23427;&#21516;&#26102;&#20801;&#35768;&#25105;&#20204;&#22312;&#20219;&#24847;&#23494;&#24230;&#30340;&#24773;&#20917;&#19979;&#25628;&#32034;&#27979;&#22320;&#32447;&#21644;&#25554;&#20540;&#26354;&#32447;&#12290;&#26368;&#22823;&#21270;&#26354;&#32447;&#30340;&#36136;&#37327;&#24230;&#37327;&#21487;&#20197;&#31561;&#20215;&#22320;&#29702;&#35299;&#20026;&#22312;&#31354;&#38388;&#19978;&#26576;&#31181;&#37325;&#26032;&#23450;&#20041;&#30340;&#40654;&#26364;&#24230;&#37327;&#19979;&#25628;&#32034;&#27979;&#22320;&#32447;&#12290;</title><link>http://arxiv.org/abs/1904.03445</link><description>&lt;p&gt;
&#22522;&#20110;&#29305;&#24449;&#30340;&#29983;&#25104;&#27169;&#22411;&#28508;&#31354;&#38388;&#25554;&#20540;&#21644;&#27979;&#22320;&#32447;
&lt;/p&gt;
&lt;p&gt;
Feature-Based Interpolation and Geodesics in the Latent Spaces of Generative Models. (arXiv:1904.03445v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1904.03445
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#21644;&#32479;&#19968;&#30340;&#25554;&#20540;&#26041;&#27861;&#65292;&#23427;&#21516;&#26102;&#20801;&#35768;&#25105;&#20204;&#22312;&#20219;&#24847;&#23494;&#24230;&#30340;&#24773;&#20917;&#19979;&#25628;&#32034;&#27979;&#22320;&#32447;&#21644;&#25554;&#20540;&#26354;&#32447;&#12290;&#26368;&#22823;&#21270;&#26354;&#32447;&#30340;&#36136;&#37327;&#24230;&#37327;&#21487;&#20197;&#31561;&#20215;&#22320;&#29702;&#35299;&#20026;&#22312;&#31354;&#38388;&#19978;&#26576;&#31181;&#37325;&#26032;&#23450;&#20041;&#30340;&#40654;&#26364;&#24230;&#37327;&#19979;&#25628;&#32034;&#27979;&#22320;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a general and unified approach to interpolation, which simultaneously allows us to search for geodesics and interpolating curves in latent space in the case of arbitrary density. Maximizing the quality measure of the curve can be equivalently understood as a search of geodesic for a certain redefinition of the Riemannian metric on the space.
&lt;/p&gt;
&lt;p&gt;
&#25554;&#20540;&#38382;&#39064;&#21516;&#26102;&#28041;&#21450;&#21040;&#27979;&#22320;&#32447;&#21644;&#29983;&#25104;&#27169;&#22411;&#30340;&#30740;&#31350;&#12290;&#22312;&#27979;&#22320;&#32447;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23547;&#25214;&#38271;&#24230;&#26368;&#30701;&#30340;&#26354;&#32447;&#65292;&#32780;&#22312;&#29983;&#25104;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#36890;&#24120;&#22312;&#28508;&#31354;&#38388;&#20013;&#24212;&#29992;&#32447;&#24615;&#25554;&#20540;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#25554;&#20540;&#38544;&#21547;&#22320;&#20351;&#29992;&#20102;&#39640;&#26031;&#20998;&#24067;&#26159;&#21333;&#23792;&#30340;&#20107;&#23454;&#12290;&#22240;&#27492;&#65292;&#22312;&#28508;&#22312;&#23494;&#24230;&#20026;&#38750;&#39640;&#26031;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#25554;&#20540;&#30340;&#38382;&#39064;&#26159;&#19968;&#20010;&#24320;&#25918;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#21644;&#32479;&#19968;&#30340;&#25554;&#20540;&#26041;&#27861;&#65292;&#23427;&#21516;&#26102;&#20801;&#35768;&#25105;&#20204;&#22312;&#20219;&#24847;&#23494;&#24230;&#30340;&#24773;&#20917;&#19979;&#25628;&#32034;&#27979;&#22320;&#32447;&#21644;&#25554;&#20540;&#26354;&#32447;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20855;&#26377;&#24378;&#22823;&#30340;&#29702;&#35770;&#32972;&#26223;&#65292;&#22522;&#20110;&#24341;&#20837;&#30340;&#25554;&#20540;&#26354;&#32447;&#36136;&#37327;&#24230;&#37327;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26368;&#22823;&#21270;&#26354;&#32447;&#30340;&#36136;&#37327;&#24230;&#37327;&#21487;&#20197;&#31561;&#20215;&#22320;&#29702;&#35299;&#20026;&#22312;&#31354;&#38388;&#19978;&#26576;&#31181;&#37325;&#26032;&#23450;&#20041;&#30340;&#40654;&#26364;&#24230;&#37327;&#19979;&#25628;&#32034;&#27979;&#22320;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;
Interpolating between points is a problem connected simultaneously with finding geodesics and study of generative models. In the case of geodesics, we search for the curves with the shortest length, while in the case of generative models we typically apply linear interpolation in the latent space. However, this interpolation uses implicitly the fact that Gaussian is unimodal. Thus the problem of interpolating in the case when the latent density is non-Gaussian is an open problem.  In this paper, we present a general and unified approach to interpolation, which simultaneously allows us to search for geodesics and interpolating curves in latent space in the case of arbitrary density. Our results have a strong theoretical background based on the introduced quality measure of an interpolating curve. In particular, we show that maximising the quality measure of the curve can be equivalently understood as a search of geodesic for a certain redefinition of the Riemannian metric on the space. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#32447;&#24615;&#22238;&#24402;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#22810;&#20010;&#32479;&#35745;&#30456;&#20851;&#26041;&#21521;&#19978;&#36827;&#34892;&#26799;&#24230;&#30340;&#22238;&#24402;&#26469;&#25552;&#39640;SGD&#30340;&#25910;&#25947;&#24615;&#65292;&#35299;&#20915;&#20102;&#26631;&#20934;&#26041;&#27861;&#21482;&#32771;&#34385;&#21333;&#20010;&#26041;&#21521;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#36991;&#20813;&#20102;&#20108;&#38454;&#26041;&#27861;&#30340;&#25104;&#26412;&#21644;&#25968;&#20540;&#19981;&#31283;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/1901.11457</link><description>&lt;p&gt;
&#22312;&#22810;&#20010;&#32479;&#35745;&#30456;&#20851;&#26041;&#21521;&#19978;&#36827;&#34892;&#26799;&#24230;&#30340;&#22312;&#32447;&#32447;&#24615;&#22238;&#24402;&#20197;&#25552;&#39640;SGD&#30340;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Improving SGD convergence by online linear regression of gradients in multiple statistically relevant directions. (arXiv:1901.11457v11 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1901.11457
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#32447;&#24615;&#22238;&#24402;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#22810;&#20010;&#32479;&#35745;&#30456;&#20851;&#26041;&#21521;&#19978;&#36827;&#34892;&#26799;&#24230;&#30340;&#22238;&#24402;&#26469;&#25552;&#39640;SGD&#30340;&#25910;&#25947;&#24615;&#65292;&#35299;&#20915;&#20102;&#26631;&#20934;&#26041;&#27861;&#21482;&#32771;&#34385;&#21333;&#20010;&#26041;&#21521;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#36991;&#20813;&#20102;&#20108;&#38454;&#26041;&#27861;&#30340;&#25104;&#26412;&#21644;&#25968;&#20540;&#19981;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes an online linear regression method that improves the convergence of SGD by regressing gradients in multiple statistically relevant directions, addressing the issue of standard methods only considering a single direction and avoiding the cost and numerical instability of second order methods.
&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36890;&#24120;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#36827;&#34892;&#35757;&#32451;&#65292;&#35813;&#26041;&#27861;&#20165;&#20351;&#29992;&#26799;&#24230;&#30340;&#38750;&#24120;&#31895;&#30053;&#30340;&#36817;&#20284;&#20540;&#26469;&#26368;&#23567;&#21270;&#30446;&#26631;&#20989;&#25968;&#12290;&#26631;&#20934;&#26041;&#27861;&#65288;&#22914;&#21160;&#37327;&#25110;ADAM&#65289;&#20165;&#32771;&#34385;&#21333;&#20010;&#26041;&#21521;&#65292;&#24182;&#19988;&#19981;&#23581;&#35797;&#27169;&#25311;&#21040;&#26497;&#20540;&#30340;&#36317;&#31163;&#65292;&#24573;&#30053;&#20102;&#20174;&#35745;&#31639;&#30340;&#26799;&#24230;&#24207;&#21015;&#20013;&#33719;&#24471;&#30340;&#26377;&#20215;&#20540;&#20449;&#24687;&#65292;&#24448;&#24448;&#20572;&#28382;&#22312;&#26576;&#20123;&#27425;&#20248;&#24179;&#21488;&#19978;&#12290;&#20108;&#38454;&#26041;&#27861;&#21487;&#20197;&#21033;&#29992;&#36825;&#20123;&#38169;&#36807;&#30340;&#26426;&#20250;&#65292;&#20294;&#38500;&#20102;&#36973;&#21463;&#38750;&#24120;&#22823;&#30340;&#25104;&#26412;&#21644;&#25968;&#20540;&#19981;&#31283;&#23450;&#24615;&#22806;&#65292;&#20854;&#20013;&#35768;&#22810;&#26041;&#27861;&#30001;&#20110;&#24573;&#30053;&#26354;&#29575;&#30340;&#31526;&#21495;&#65288;&#20316;&#20026;Hessian&#30340;&#29305;&#24449;&#20540;&#65289;&#32780;&#21560;&#24341;&#21040;&#20687;&#38797;&#28857;&#36825;&#26679;&#30340;&#27425;&#20248;&#28857;&#12290;&#26080;&#38797;&#29275;&#39039;&#27861;&#26159;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#19968;&#20010;&#32597;&#35265;&#20363;&#23376;&#65292;&#23427;&#23558;&#38797;&#28857;&#21560;&#24341;&#21147;&#36716;&#21464;&#20026;&#25490;&#26021;&#21147;&#65292;&#24182;&#34987;&#35777;&#26126;&#22312;&#36825;&#31181;&#26041;&#24335;&#19979;&#25552;&#20379;&#20102;&#26368;&#32456;&#20540;&#30340;&#37325;&#35201;&#25913;&#36827;&#12290;&#28982;&#32780;&#65292;&#23427;&#22312;&#27169;&#25311;&#20108;&#38454;&#34892;&#20026;&#26102;&#24573;&#30053;&#20102;&#22122;&#22768;&#65292;&#19987;&#27880;&#20110;Krylov&#23376;&#31354;&#38388;&#20197;&#36827;&#34892;&#25968;&#20540;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks are usually trained with stochastic gradient descent (SGD), which minimizes objective function using very rough approximations of gradient, only averaging to the real gradient. Standard approaches like momentum or ADAM only consider a single direction, and do not try to model distance from extremum - neglecting valuable information from calculated sequence of gradients, often stagnating in some suboptimal plateau. Second order methods could exploit these missed opportunities, however, beside suffering from very large cost and numerical instabilities, many of them attract to suboptimal points like saddles due to negligence of signs of curvatures (as eigenvalues of Hessian).  Saddle-free Newton method is a rare example of addressing this issue changes saddle attraction into repulsion, and was shown to provide essential improvement for final value this way. However, it neglects noise while modelling second order behavior, focuses on Krylov subspace for numerical rea
&lt;/p&gt;</description></item></channel></rss>