# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Are consumers ready to pay extra for crowd-shipping e-groceries and why? A hybrid choice analysis for developing economies.](http://arxiv.org/abs/2303.07044) | 本文研究了消费者是否愿意为基于众包配送的电子杂货配送支付额外费用，结果表明如果众包配送提供更灵活和以消费者为导向的服务，电子购物者有意愿支付额外费用。 |
| [^2] | [Data Dependent Regret Guarantees Against General Comparators for Full or Bandit Feedback.](http://arxiv.org/abs/2303.06526) | 该论文提出了一个数据相关的在线学习算法框架，可以在全专家反馈和Bandit反馈设置中具有数据相关的遗憾保证，适用于各种问题场景。 |
| [^3] | [Lossless Point Cloud Geometry and Attribute Compression Using a Learned Conditional Probability Model.](http://arxiv.org/abs/2303.06519) | 本文提出了一种使用稀疏张量深度神经网络学习点云几何和颜色概率分布的高效无损点云压缩方法，具有更高的压缩比和更快的压缩速度。 |
| [^4] | [Deep probabilistic model for lossless scalable point cloud attribute compression.](http://arxiv.org/abs/2303.06517) | 本文提出了一种利用深度概率模型进行无损可扩展点云属性压缩的方法，通过多尺度架构提供准确的上下文，从而最小化编码比特率，同时允许从无损压缩的比特流中轻松提取较低质量的版本。该方法在实验中表现优于最近提出的方法，并与最新的G-PCC版本14相当，且编码时间更快。 |
| [^5] | [Transcription free filler word detection with Neural semi-CRFs.](http://arxiv.org/abs/2303.06475) | 本文提出了一种无需转录的填充词检测系统，使用结构化状态空间序列模型和神经半马尔可夫条件随机场，能够在PodcastFillers数据集上实现6.4％（分段级别）和3.1％（事件级别）的绝对F1改进。 |
| [^6] | [On Neural Architectures for Deep Learning-based Source Separation of Co-Channel OFDM Signals.](http://arxiv.org/abs/2303.06438) | 本文研究了涉及OFDM信号的单通道源分离问题，通过原型问题评估了使用面向音频的神经网络架构在分离共信道OFDM波形方面的有效性，并提出了关键的领域知识修改网络参数化的解决方案。 |
| [^7] | [Brain Diffuser: An End-to-End Brain Image to Brain Network Pipeline.](http://arxiv.org/abs/2303.06410) | 本文提出了一种基于扩散的端到端脑网络生成模型Brain Diffuser，直接从DTI中形成结构性脑网络。对于阿尔茨海默病的情况，所提出的模型在ADNI数据库上的表现优于现有工具包的结果。 |
| [^8] | [Learning to Precode for Integrated Sensing and Communications Systems.](http://arxiv.org/abs/2303.06381) | 本文提出了一种无监督学习神经模型，用于设计集成感知和通信（ISAC）系统的传输预编码器，以最大化最坏情况下的目标照明功率，同时确保所有用户的最小信干噪比（SINR）。通过数值模拟，证明了该方法在存在信道估计误差的情况下优于传统的基于优化的方法，同时产生较小的计算复杂度，并且在不同的信道条件下具有良好的泛化能力。 |
| [^9] | [Assessing gender fairness in EEG-based machine learning detection of Parkinson's disease: A multi-center study.](http://arxiv.org/abs/2303.06376) | 本研究在多中心环境中对基于EEG的机器学习算法进行了性别子组群的检测能力分析，发现男性和女性的PD检测能力存在显着差异。 |
| [^10] | [Privacy-Preserving Cooperative Visible Light Positioning for Nonstationary Environment: A Federated Learning Perspective.](http://arxiv.org/abs/2303.06361) | 本文提出了一种基于联邦学习的合作可见光定位方案，通过共同训练适应环境变化的全局模型，提高了在非静态环境下的定位精度和泛化能力。 |
| [^11] | [Intelligent diagnostic scheme for lung cancer screening with Raman spectra data by tensor network machine learning.](http://arxiv.org/abs/2303.06340) | 本文提出了一种基于张量网络机器学习的方案，通过筛查呼出气中挥发性有机化合物（VOC）的Raman光谱数据，可可靠地预测肺癌患者及其阶段。 |
| [^12] | [MLP-SRGAN: A Single-Dimension Super Resolution GAN using MLP-Mixer.](http://arxiv.org/abs/2303.06298) | MLP-SRGAN是一种单维超分辨率GAN，使用MLP-Mixer和卷积层进行上采样，可用于FLAIR MRI图像的超分辨率重建，提出了新的图像质量度量方法。 |
| [^13] | [MCROOD: Multi-Class Radar Out-Of-Distribution Detection.](http://arxiv.org/abs/2303.06232) | 本文提出了一种基于重建的多类OOD检测器，该检测器在雷达距离多普勒图像（RDIs）上运行。检测器旨在将除坐、站或走的人以外的任何移动物体分类为OOD。作者还提供了一种简单而有效的预处理技术，以检测呼吸等微小的人体运动。在实验中，该方法表现优于最先进的OOD检测方法。 |
| [^14] | [Digital Twin-Assisted Knowledge Distillation Framework for Heterogeneous Federated Learning.](http://arxiv.org/abs/2303.06155) | 本文提出了一种数字孪生辅助的知识蒸馏框架，用于解决联邦学习系统中的异构性问题，用户可以选择自己的神经网络模型并从大型教师模型中蒸馏知识，同时利用数字孪生在服务器上训练大型教师模型，最终通过混合整数规划和Q-learning算法实现模型选择和资源分配。 |
| [^15] | [Clinical BERTScore: An Improved Measure of Automatic Speech Recognition Performance in Clinical Settings.](http://arxiv.org/abs/2303.05737) | 本文提出了一种临床BERTScore（CBERTScore）度量，它比其他度量更严厉地惩罚临床相关的错误，更接近于临床医生对医学句子的偏好。作者还收集了13个临床医生对149个现实医学句子的偏好基准，称为临床转录偏好基准（CTP），证明CBERTScore更接近于临床医生的偏好，并将基准发布给社区以进一步开发具有临床意识的ASR度量。 |
| [^16] | [Real-time scheduling of renewable power systems through planning-based reinforcement learning.](http://arxiv.org/abs/2303.05205) | 本文提出了一种基于规划强化学习算法和真实电力网环境的系统解决方案，可以实现发电机的规划和更细的时间分辨率调整，从而增加了电网的能力。 |
| [^17] | [Leveraging Pre-trained AudioLDM for Text to Sound Generation: A Benchmark Study.](http://arxiv.org/abs/2303.03857) | 本文研究了使用预训练的AudioLDM作为声音生成的骨干的优势，证明了在数据稀缺情况下使用预训练模型进行文本到声音生成的优势，并在几个常用数据集上使用相同的评估协议评估了各种文本到声音生成系统，为未来的研究提供了基础。 |
| [^18] | [PreFallKD: Pre-Impact Fall Detection via CNN-ViT Knowledge Distillation.](http://arxiv.org/abs/2303.03634) | 本文提出了一种基于CNN-ViT知识蒸馏的预防跌倒系统PreFallKD，通过将预训练的教师模型的检测知识转移到轻量级卷积神经网络的学生模型上，实现了检测性能和计算复杂性的平衡。 |
| [^19] | [Heterogeneous Graph Learning for Acoustic Event Classification.](http://arxiv.org/abs/2303.02665) | 本文提出了一种新模型，异构图跨模态网络（HGCN），它学习跨模态边缘，可以适应各种空间和时间尺度，有效地连接了跨模态的相关节点，在声音事件分类中表现出最先进的性能。 |
| [^20] | [Fine-grained Emotional Control of Text-To-Speech: Learning To Rank Inter- And Intra-Class Emotion Intensities.](http://arxiv.org/abs/2303.01508) | 本文提出了一种细粒度可控情感TTS，考虑了内部和外部类距离，并能够合成具有可识别强度差异的语音。 |
| [^21] | [Rethinking Semi-Supervised Medical Image Segmentation: A Variance-Reduction Perspective.](http://arxiv.org/abs/2302.01735) | 本文提出了ARCO，一种半监督对比学习（CL）框架，其中包括医学图像分割中的分层组采样理论。通过方差缩减估计的概念来构建ARCO，并表明某些方差缩减技术在医学图像分割中特别有益。 |
| [^22] | [LDMIC: Learning-based Distributed Multi-view Image Coding.](http://arxiv.org/abs/2301.09799) | LDMIC是一种基于学习的分布式多视图图像编码框架，通过独立编码器和联合上下文传输模块实现了全局视图间的相关性捕捉，对几何关系不敏感。 |
| [^23] | [Perceptual-Neural-Physical Sound Matching.](http://arxiv.org/abs/2301.02886) | 本文提出了一种新的声音匹配算法，称为感知-神经-物理损失（PNP），它是频谱损失的最优二次近似，能够更好地适应不同参数的感知重要性，同时具有快速收敛的特点。 |
| [^24] | [A attention way in Explainable methods for infant brain.](http://arxiv.org/abs/2301.00815) | 本文提出了一种可解释的几何深度网络，通过端到端学习解释因素以增强区分性表示提取，以反向保证细粒度的可解释性，适用于神经影像和神经科学研究中的高维数据。 |
| [^25] | [One-shot domain adaptation in video-based assessment of surgical skills.](http://arxiv.org/abs/2301.00812) | 本文提出了一种元学习模型A-VBANet，可以通过一次性学习提供领域不可知的手术技能分类，成功地适应了模拟任务和腹腔镜胆囊切除术，为基于视频的手术技能评估提供了领域不可知程序。 |
| [^26] | [UniDA3D: Unified Domain Adaptive 3D Semantic Segmentation Pipeline.](http://arxiv.org/abs/2212.10390) | 本文提出了UniDA3D，一种统一的域自适应三维语义分割管道，通过设计统一的源和目标主动采样策略，可以解决三维分割领域中的多个自适应任务，并探索了实现多模态采样策略的可能性。 |
| [^27] | [A large-scale and PCR-referenced vocal audio dataset for COVID-19.](http://arxiv.org/abs/2212.07738) | 英国COVID-19 Vocal Audio Dataset是迄今为止最大的SARS-CoV-2 PCR参考音频记录集合，旨在为训练和评估使用声音数据分类SARS-CoV-2感染状态或相关呼吸症状的机器学习模型而设计。 |
| [^28] | [Client Selection for Federated Bayesian Learning.](http://arxiv.org/abs/2212.05492) | 本文提出了两种基于核化Stein差异（KSD）和希尔伯特内积（HIP）的DSVGD选择方案，以提高联邦贝叶斯学习中的模型收敛和通信效率。 |
| [^29] | [Neural Transducer Training: Reduced Memory Consumption with Sample-wise Computation.](http://arxiv.org/abs/2211.16270) | 本文提出了一种内存高效的神经转录器训练方法，采用逐个样本计算转录器损失和梯度，显著减少了内存使用量，并在与默认批量计算相比时表现出竞争速度。 |
| [^30] | [Deep Neural Mel-Subband Beamformer for In-car Speech Separation.](http://arxiv.org/abs/2211.12590) | 本文提出了一种基于DL的Mel-Subband时空波束成形器，用于在车载环境中进行语音分离，通过基于Mel尺度的子带选择策略，实现对低频的细粒度处理和对高频的粗粒度处理，降低了计算成本和推理时间。 |
| [^31] | [LA-VocE: Low-SNR Audio-visual Speech Enhancement using Neural Vocoders.](http://arxiv.org/abs/2211.10999) | LA-VocE是一种新的音频视觉语音增强方法，使用神经声码器将从嘈杂的音频视觉语音预测的mel频谱图转换为波形音频，适用于多种语言和不同水平的背景噪声和语音干扰。 |
| [^32] | [Differentiable Uncalibrated Imaging.](http://arxiv.org/abs/2211.10525) | 本文提出了一种可微的成像框架，以解决测量坐标的不确定性，通过隐式神经网络和可微分样条插值器实现。该方法应用于2D和3D计算机断层扫描，产生了改进的重建结果。 |
| [^33] | [Efficient brain age prediction from 3D MRI volumes using 2D projections.](http://arxiv.org/abs/2211.05762) | 本文提出了一种使用2D投影从3D MRI体积中高效预测脑龄的方法，相比于使用3D CNN，该方法在计算速度上有两个数量级的提升，对于没有3D CNN昂贵GPU硬件的研究人员非常有用。 |
| [^34] | [Accidental Learners: Spoken Language Identification in Multilingual Self-Supervised Models.](http://arxiv.org/abs/2211.05103) | 本文通过在多语言预训练范式中尝试Conformer架构，扩展了先前的自监督语言识别方法。预训练的语音模型在较低层中最优地编码了语言区分信息，从这些层获得的嵌入能够显著地稳健地分类未见过的语言和不同的声学环境。在对预训练的Conformer模型在VoxLingua107数据集上进行微调后，我们实现了与当前最先进的语言识别系统类似的结果，且使用的参数量仅为其它模型的五分之一。 |
| [^35] | [Efficient ECG-based Atrial Fibrillation Detection via Parameterised Hypercomplex Neural Networks.](http://arxiv.org/abs/2211.02678) | 本文提出了一种基于参数化超复数神经网络的轻量级卷积神经网络方法，用于心房颤动检测。该方法在可穿戴设备上训练小规模CNN，克服了有限的计算资源。在两个公开可用的ECG数据集上，该方法表现出与实值CNN相当的性能，但使用了显着较少的模型参数。 |
| [^36] | [Graph Neural Networks on SPD Manifolds for Motor Imagery Classification: A Perspective from the Time-Frequency Analysis.](http://arxiv.org/abs/2211.02641) | 本文介绍了一种基于SPD流形的图神经网络用于运动想象分类，利用EEG的二阶统计量，相比传统方法具有更好的性能。 |
| [^37] | [Cutting Through the Noise: An Empirical Comparison of Psychoacoustic and Envelope-based Features for Machinery Fault Detection.](http://arxiv.org/abs/2211.01704) | 本文提出了一个自动化和噪声鲁棒的听觉检查系统，用于检测机械部件的健康状况。我们提供了一个基准来比较不同类型的包络特征与心理声学特征。我们是第一个应用时变心理声学特征进行故障检测的人。 |
| [^38] | [WiserVR: Semantic Communication Enabled Wireless Virtual Reality Delivery.](http://arxiv.org/abs/2211.01241) | WiserVR提出了一种新的框架，利用语义通信和深度学习技术，实现了高效的无线虚拟现实传输，其中包括语义位置图和联合语义通道编码方法。 |
| [^39] | [Learning Audio Features with Metadata and Contrastive Learning.](http://arxiv.org/abs/2210.16192) | 本研究使用监督对比学习结合可用元数据解决多个前置任务，学习数据的良好表示。在呼吸音分类数据集上，仅使用元数据学习表示可以获得与仅使用类标签的交叉熵相似的性能。在使用多个监督对比学习将类标签与元数据相结合时，获得了最先进的得分。 |
| [^40] | [Articulation GAN: Unsupervised modeling of articulatory learning.](http://arxiv.org/abs/2210.15173) | 本文提出了一种新的无监督生成模型，通过完全无监督的方式学习生成关节表示（电磁关节成像或EMA），更接近于人类语音产生的方式，从而更好地模拟人类语音产生的过程。 |
| [^41] | [Play It Back: Iterative Attention for Audio Recognition.](http://arxiv.org/abs/2210.11328) | 该论文提出了一种基于注意力的架构，通过选择性重复跨越音频序列的最具区分性的声音来进行关注，最终实现了在三个音频分类基准测试中始终实现最先进的性能。 |
| [^42] | [PSVRF: Learning to restore Pitch-Shifted Voice without reference.](http://arxiv.org/abs/2210.02731) | 本文提出了一种无参考方法PSVRF，用于高质量还原变调语音，可以增强ASV系统对音高缩放攻击的鲁棒性，性能甚至超过了最先进的基于参考的方法。 |
| [^43] | [On the Stability Analysis of Open Federated Learning Systems.](http://arxiv.org/abs/2209.12307) | 本文研究了开放式联邦学习系统的稳定性问题，提出了一种新的性能度量，即开放式FL系统的稳定性，并在假设本地客户端函数是强凸和平滑的情况下，理论上量化了两种FL算法的稳定半径。 |
| [^44] | [U-Sleep's resilience to AASM guidelines.](http://arxiv.org/abs/2209.11173) | 本研究表明，基于深度学习的U-Sleep睡眠评分算法可以弹性地使用非推荐或非传统的导联，而不需要严格遵守AASM指南。 |
| [^45] | [Learning ASR pathways: A sparse multilingual ASR model.](http://arxiv.org/abs/2209.05735) | 本文提出了一种稀疏的多语言ASR模型，通过激活语言特定的子网络来显式地学习每种语言的参数，同时通过联合多语言训练实现对低资源语言的知识转移，相比于密集模型和语言不可知的剪枝模型，在低资源语言上提供更好的性能。 |
| [^46] | [Uconv-Conformer: High Reduction of Input Sequence Length for End-to-End Speech Recognition.](http://arxiv.org/abs/2208.07657) | 本文提出了一种新型Uconv-Conformer架构，可以将输入序列长度缩短16倍，加速中间层的工作，同时通过使用上采样块解决了收敛问题，表现出更好的WER和更快的训练和推理速度。 |
| [^47] | [DailyTalk: Spoken Dialogue Dataset for Conversational Text-to-Speech.](http://arxiv.org/abs/2207.01063) | 本文介绍了一个高质量的对话语音数据集DailyTalk，专门为对话TTS设计。DailyTalk可以用作通用的TTS数据集，而且基线可以表示DailyTalk的上下文信息。 |
| [^48] | [Bootstrapping Semi-supervised Medical Image Segmentation with Anatomical-aware Contrastive Distillation.](http://arxiv.org/abs/2206.02307) | 本文提出了一种基于解剖感知对比蒸馏的半监督医学图像分割引导启动方法，通过软标记负样本和捕获更多语义上相似的特征来解决医学图像数据不平衡的问题。 |
| [^49] | [DynLight: Realize dynamic phase duration with multi-level traffic signal control.](http://arxiv.org/abs/2204.03471) | 本文已被撤回，原因是语言和理论描述不够令人满意，作者已经进行了修订和更新。 |
| [^50] | [Alternate Intermediate Conditioning with Syllable-level and Character-level Targets for Japanese ASR.](http://arxiv.org/abs/2204.00175) | 该论文提出了一种基于音节和字符目标的交替中间条件方法，利用字符级和音节级中间预测作为条件特征来处理日语ASR中的多对一和一对多的映射问题，并在实验中取得了优异的表现。 |
| [^51] | [Learning Torque Control for Quadrupedal Locomotion.](http://arxiv.org/abs/2203.05194) | 本文提出了一种基于扭矩的强化学习框架，直接预测关节扭矩，避免使用PD控制器，通过广泛的实验验证，四足动物能够穿越各种地形并抵抗外部干扰，同时保持运动。 |
| [^52] | [FLSys: Toward an Open Ecosystem for Federated Learning Mobile Apps.](http://arxiv.org/abs/2111.09445) | 本文介绍了FLSys，一个移动-云联邦学习（FL）系统，可以成为FL模型和应用程序开放生态系统的关键组成部分。FLSys旨在在智能手机上使用移动感测数据。它平衡了模型性能和资源消耗，容忍通信故障，并实现了可扩展性。FLSys提供了先进的隐私保护机制和一个通用的API，供第三方应用程序开发人员访问FL模型。 |
| [^53] | [Data-Driven Reachability Analysis from Noisy Data.](http://arxiv.org/abs/2105.07229) | 本文提出了一种从嘈杂的数据中计算可达集的算法，适用于不同类型的系统，包括线性、多项式和非线性系统。算法基于矩阵zonotope，可以提供较少保守的可达集，并且可以将关于未知系统模型的先前知识纳入计算。算法具有理论保证，并在多个数值示例和实际实验中得到了验证。 |

# 详细

[^1]: 消费者是否愿意为众包配送的电子杂货支付额外费用？为发展中国家提供混合选择分析

    Are consumers ready to pay extra for crowd-shipping e-groceries and why? A hybrid choice analysis for developing economies. (arXiv:2303.07044v1 [econ.GN])

    [http://arxiv.org/abs/2303.07044](http://arxiv.org/abs/2303.07044)

    本文研究了消费者是否愿意为基于众包配送的电子杂货配送支付额外费用，结果表明如果众包配送提供更灵活和以消费者为导向的服务，电子购物者有意愿支付额外费用。

    This paper studies whether consumers are willing to pay extra for crowd-shipping e-groceries deliveries, and the results indicate that e-shoppers are willing to pay extra if crowd-shipping provides more flexible and consumer-oriented service.

    本文介绍了关于消费者愿意为基于众包配送的电子杂货配送支付额外费用的行为研究结果。该方法在乌克兰进行了测试，即一个众包配送服务正在发展的发展中国家。为了考虑到消费者的行为复杂性，选择模型被增加了一个潜在变量。研究结果表明，如果众包配送提供更灵活和以消费者为导向的服务，电子购物者有意愿为众包配送配送支付额外费用。众包配送的预期环境影响并不被电子购物者认为很重要，这可以通过对所考虑的案例研究中环境和以汽车为导向的流动性的低关注度来解释。

    This paper presents the behavioral study's results on willingness-to-pay the extra money by the customers for e-groceries deliveries based on crowd-shipping. The proposed methodology was tested for Ukraine, i.e., a developing country where the crowd-shipping services are under development conditions. To account for the behavior complexity of the consumers who have not faced the crowd-shipping services in the past, the choice model was enhanced with a latent variable. The findings indicate the revealed readiness of the e-shoppers to pay extra money for crowd-shipping delivery if it provides more flexible and consumer-oriented service. The expected environmental impact of the crowd-shipping delivery was not considered as important by the e-shoppers, which is explained by low concerns about the environment and car-oriented mobility in the considered case study.
    
[^2]: 数据相关的在线学习算法框架

    Data Dependent Regret Guarantees Against General Comparators for Full or Bandit Feedback. (arXiv:2303.06526v1 [cs.LG])

    [http://arxiv.org/abs/2303.06526](http://arxiv.org/abs/2303.06526)

    该论文提出了一个数据相关的在线学习算法框架，可以在全专家反馈和Bandit反馈设置中具有数据相关的遗憾保证，适用于各种问题场景。

    This paper proposes a data-dependent online learning algorithm framework that has data-dependent regret guarantees in both full expert feedback and bandit feedback settings, applicable for a wide variety of problem scenarios.

    我们研究了对抗性在线学习问题，并创建了一个完全在线的算法框架，具有在全专家反馈和Bandit反馈设置中具有数据相关的遗憾保证。我们研究了我们的算法对一般比较器的预期性能，使其适用于各种问题场景。我们的算法从通用预测角度工作，使用的性能度量是对任意比较器序列的预期遗憾，即我们的损失与竞争损失序列之间的差异。竞争类可以设计为包括固定臂选择、切换Bandit、上下文Bandit、周期Bandit或任何其他感兴趣的竞争。竞争类中的序列通常由具体应用程序确定，并应相应地设计。我们的算法既不使用也不需要任何有关损失序列的初步信息，完全在线。其

    We study the adversarial online learning problem and create a completely online algorithmic framework that has data dependent regret guarantees in both full expert feedback and bandit feedback settings. We study the expected performance of our algorithm against general comparators, which makes it applicable for a wide variety of problem scenarios. Our algorithm works from a universal prediction perspective and the performance measure used is the expected regret against arbitrary comparator sequences, which is the difference between our losses and a competing loss sequence. The competition class can be designed to include fixed arm selections, switching bandits, contextual bandits, periodic bandits or any other competition of interest. The sequences in the competition class are generally determined by the specific application at hand and should be designed accordingly. Our algorithm neither uses nor needs any preliminary information about the loss sequences and is completely online. Its
    
[^3]: 使用学习的条件概率模型进行无损点云几何和属性压缩

    Lossless Point Cloud Geometry and Attribute Compression Using a Learned Conditional Probability Model. (arXiv:2303.06519v1 [eess.IV])

    [http://arxiv.org/abs/2303.06519](http://arxiv.org/abs/2303.06519)

    本文提出了一种使用稀疏张量深度神经网络学习点云几何和颜色概率分布的高效无损点云压缩方法，具有更高的压缩比和更快的压缩速度。

    This paper proposes an efficient lossless point cloud compression method that uses sparse tensor-based deep neural networks to learn point cloud geometry and color probability distributions, achieving higher compression ratio and faster compression speed compared to the state-of-the-art method from Moving Pict.

    近年来，我们在生活的许多方面都见证了点云数据的存在，从沉浸式媒体、自动驾驶到医疗保健，但代价是巨大的数据量。本文提出了一种高效的无损点云压缩方法，使用稀疏张量深度神经网络学习点云几何和颜色概率分布。我们的方法使用统一的稀疏表示将点云表示为具有不同位深度的占用特征和三个属性特征。这使我们能够使用稀疏张量神经网络有效地利用点云内的特征和点内依赖关系，从而为算术编码器构建准确的自回归上下文模型。据我们所知，这是第一个基于学习的无损点云几何和属性压缩方法。与Moving Pict的最新无损点云压缩方法相比，我们的方法在保持无损压缩的同时，具有更高的压缩比和更快的压缩速度。

    In recent years, we have witnessed the presence of point cloud data in many aspects of our life, from immersive media, autonomous driving to healthcare, although at the cost of a tremendous amount of data. In this paper, we present an efficient lossless point cloud compression method that uses sparse tensor-based deep neural networks to learn point cloud geometry and color probability distributions. Our method represents a point cloud with both occupancy feature and three attribute features at different bit depths in a unified sparse representation. This allows us to efficiently exploit feature-wise and point-wise dependencies within point clouds using a sparse tensor-based neural network and thus build an accurate auto-regressive context model for an arithmetic coder. To the best of our knowledge, this is the first learning-based lossless point cloud geometry and attribute compression approach. Compared with the-state-of-the-art lossless point cloud compression method from Moving Pict
    
[^4]: 深度概率模型用于无损可扩展点云属性压缩

    Deep probabilistic model for lossless scalable point cloud attribute compression. (arXiv:2303.06517v1 [eess.IV])

    [http://arxiv.org/abs/2303.06517](http://arxiv.org/abs/2303.06517)

    本文提出了一种利用深度概率模型进行无损可扩展点云属性压缩的方法，通过多尺度架构提供准确的上下文，从而最小化编码比特率，同时允许从无损压缩的比特流中轻松提取较低质量的版本。该方法在实验中表现优于最近提出的方法，并与最新的G-PCC版本14相当，且编码时间更快。

    This paper proposes a deep probabilistic model for lossless scalable point cloud attribute compression, which utilizes a multiscale architecture to provide accurate context for attribute probability modeling and allows for easily extracting lower quality versions from the losslessly compressed bitstream. The method outperforms recently proposed methods and is on par with the latest G-PCC version 14, with substantially faster coding time.

    近年来，已经提出了几种利用先进的深度学习技术的点云几何压缩方法，但是关于属性压缩，特别是无损压缩的工作还很有限。在这项工作中，我们构建了一种端到端的多尺度点云属性编码方法（MNeT），该方法逐步将属性投影到多尺度潜在空间上。多尺度架构为属性概率建模提供了准确的上下文，从而通过单个网络预测最小化编码比特率。此外，我们的方法允许可扩展编码，可以从无损压缩的比特流中轻松提取较低质量的版本。我们在来自MVUB和MPEG的一组点云上验证了我们的方法，并表明我们的方法优于最近提出的方法，并与最新的G-PCC版本14相当。此外，我们的编码时间比G-PCC快得多。

    In recent years, several point cloud geometry compression methods that utilize advanced deep learning techniques have been proposed, but there are limited works on attribute compression, especially lossless compression. In this work, we build an end-to-end multiscale point cloud attribute coding method (MNeT) that progressively projects the attributes onto multiscale latent spaces. The multiscale architecture provides an accurate context for the attribute probability modeling and thus minimizes the coding bitrate with a single network prediction. Besides, our method allows scalable coding that lower quality versions can be easily extracted from the losslessly compressed bitstream. We validate our method on a set of point clouds from MVUB and MPEG and show that our method outperforms recently proposed methods and on par with the latest G-PCC version 14. Besides, our coding time is substantially faster than G-PCC.
    
[^5]: 基于神经半条件随机场的无需转录的填充词检测

    Transcription free filler word detection with Neural semi-CRFs. (arXiv:2303.06475v1 [eess.AS])

    [http://arxiv.org/abs/2303.06475](http://arxiv.org/abs/2303.06475)

    本文提出了一种无需转录的填充词检测系统，使用结构化状态空间序列模型和神经半马尔可夫条件随机场，能够在PodcastFillers数据集上实现6.4％（分段级别）和3.1％（事件级别）的绝对F1改进。

    This paper proposes a transcription-free filler word detection system that uses structured state space sequence model and neural semi-Markov conditional random fields, achieving an absolute F1 improvement of 6.4% (segment level) and 3.1% (event level) on the PodcastFillers dataset.

    非语言填充词，如“嗯”或“啊”，在自发语言中普遍存在，用于表达犹豫或不确定性。以前检测某些非语言填充词的工作高度依赖于来自成熟商业自动语音识别（ASR）系统的转录。然而，某些ASR系统在许多方面（例如预算、目标语言和计算能力）并不普遍可用。在这项工作中，我们研究了不依赖于ASR系统的填充词检测系统。我们展示了通过使用结构化状态空间序列模型（S4）和神经半马尔可夫条件随机场（semi-CRFs），我们在PodcastFillers数据集上实现了6.4％（分段级别）和3.1％（事件级别）的绝对F1改进。我们还对检测结果进行了定性分析，以分析我们提出的系统的局限性。

    Non-linguistic filler words, such as "uh" or "um", are prevalent in spontaneous speech and serve as indicators for expressing hesitation or uncertainty. Previous works for detecting certain non-linguistic filler words are highly dependent on transcriptions from a well-established commercial automatic speech recognition (ASR) system. However, certain ASR systems are not universally accessible from many aspects, e.g., budget, target languages, and computational power. In this work, we investigate filler word detection system that does not depend on ASR systems. We show that, by using the structured state space sequence model (S4) and neural semi-Markov conditional random fields (semi-CRFs), we achieve an absolute F1 improvement of 6.4% (segment level) and 3.1% (event level) on the PodcastFillers dataset. We also conduct a qualitative analysis on the detected results to analyze the limitations of our proposed system.
    
[^6]: 关于深度学习源分离中的神经网络架构：共信道OFDM信号的分离

    On Neural Architectures for Deep Learning-based Source Separation of Co-Channel OFDM Signals. (arXiv:2303.06438v1 [eess.SP])

    [http://arxiv.org/abs/2303.06438](http://arxiv.org/abs/2303.06438)

    本文研究了涉及OFDM信号的单通道源分离问题，通过原型问题评估了使用面向音频的神经网络架构在分离共信道OFDM波形方面的有效性，并提出了关键的领域知识修改网络参数化的解决方案。

    This paper studies the single-channel source separation problem involving OFDM signals and evaluates the efficacy of using audio-oriented neural architectures in separating co-channel OFDM waveforms. Critical domain-informed modifications to the network parameterization are proposed based on insights from OFDM structures.

    本文研究了涉及正交频分复用（OFDM）信号的单通道源分离问题，这种信号在许多现代数字通信系统中普遍存在。在单声道源分离方面已经进行了相关的努力，其中采用了最先进的神经网络架构来训练端到端的音频信号分离器（作为一维时间序列）。通过基于OFDM源模型的原型问题，我们评估并质疑了使用面向音频的神经网络架构在基于通信波形相关特征分离信号方面的有效性。也许令人惊讶的是，我们证明在某些配置中，即使在理论上可以实现完美分离的情况下，这些面向音频的神经网络架构在分离共信道OFDM波形方面表现不佳。然而，我们提出了关键的领域知识修改网络参数化，基于OFDM结构的洞察，可以共同解决这个问题。

    We study the single-channel source separation problem involving orthogonal frequency-division multiplexing (OFDM) signals, which are ubiquitous in many modern-day digital communication systems. Related efforts have been pursued in monaural source separation, where state-of-the-art neural architectures have been adopted to train an end-to-end separator for audio signals (as 1-dimensional time series). In this work, through a prototype problem based on the OFDM source model, we assess -- and question -- the efficacy of using audio-oriented neural architectures in separating signals based on features pertinent to communication waveforms. Perhaps surprisingly, we demonstrate that in some configurations, where perfect separation is theoretically attainable, these audio-oriented neural architectures perform poorly in separating co-channel OFDM waveforms. Yet, we propose critical domain-informed modifications to the network parameterization, based on insights from OFDM structures, that can co
    
[^7]: Brain Diffuser：一种端到端的脑图像到脑网络管道

    Brain Diffuser: An End-to-End Brain Image to Brain Network Pipeline. (arXiv:2303.06410v1 [cs.AI])

    [http://arxiv.org/abs/2303.06410](http://arxiv.org/abs/2303.06410)

    本文提出了一种基于扩散的端到端脑网络生成模型Brain Diffuser，直接从DTI中形成结构性脑网络。对于阿尔茨海默病的情况，所提出的模型在ADNI数据库上的表现优于现有工具包的结果。

    This paper proposes a diffusion based end-to-end brain network generative model Brain Diffuser that directly shapes the structural brain networks from DTI. For the case of Alzheimer's disease, the proposed model performs better than the results from existing toolkits on the Alzheimer's Disease Neuroimaging Initiative (ADNI) database.

    脑网络分析对于诊断和干预阿尔茨海默病（AD）至关重要。然而，以往的研究主要依赖于特定的耗时和主观的工具包。只有少数工具可以从脑扩散张量图像（DTI）中获取结构性脑网络。在本文中，我们提出了一种基于扩散的端到端脑网络生成模型Brain Diffuser，直接从DTI中形成结构性脑网络。与现有工具包相比，Brain Diffuser通过分析受试者之间结构性脑网络的差异，利用更多的结构连接特征和与疾病相关的信息。对于阿尔茨海默病的情况，所提出的模型在阿尔茨海默病神经影像学倡议（ADNI）数据库上的表现优于现有工具包的结果。

    Brain network analysis is essential for diagnosing and intervention for Alzheimer's disease (AD). However, previous research relied primarily on specific time-consuming and subjective toolkits. Only few tools can obtain the structural brain networks from brain diffusion tensor images (DTI). In this paper, we propose a diffusion based end-to-end brain network generative model Brain Diffuser that directly shapes the structural brain networks from DTI. Compared to existing toolkits, Brain Diffuser exploits more structural connectivity features and disease-related information by analyzing disparities in structural brain networks across subjects. For the case of Alzheimer's disease, the proposed model performs better than the results from existing toolkits on the Alzheimer's Disease Neuroimaging Initiative (ADNI) database.
    
[^8]: 学习预编码用于集成感知和通信系统

    Learning to Precode for Integrated Sensing and Communications Systems. (arXiv:2303.06381v1 [eess.SP])

    [http://arxiv.org/abs/2303.06381](http://arxiv.org/abs/2303.06381)

    本文提出了一种无监督学习神经模型，用于设计集成感知和通信（ISAC）系统的传输预编码器，以最大化最坏情况下的目标照明功率，同时确保所有用户的最小信干噪比（SINR）。通过数值模拟，证明了该方法在存在信道估计误差的情况下优于传统的基于优化的方法，同时产生较小的计算复杂度，并且在不同的信道条件下具有良好的泛化能力。

    This paper proposes an unsupervised learning neural model to design transmit precoders for integrated sensing and communication (ISAC) systems to maximize the worst-case target illumination power while ensuring a minimum signal-to-interference-plus-noise ratio (SINR) for all the users. The proposed method outperforms traditional optimization-based methods in presence of channel estimation errors while incurring lesser computational complexity and generalizing well across different channel conditions that were not shown during training.

    本文提出了一种无监督学习神经模型，用于设计集成感知和通信（ISAC）系统的传输预编码器，以最大化最坏情况下的目标照明功率，同时确保所有用户的最小信干噪比（SINR）。从上行导频和回波中学习传输预编码器的问题可以看作是一个参数化函数估计问题，我们提出使用神经网络模型来学习这个函数。为了学习神经网络参数，我们开发了一种基于一阶最优性条件的损失函数，以纳入SINR和功率约束。通过数值模拟，我们证明了所提出的方法在存在信道估计误差的情况下优于传统的基于优化的方法，同时产生较小的计算复杂度，并且在不同的信道条件下具有良好的泛化能力，这些条件在训练期间没有显示出来。

    In this paper, we present an unsupervised learning neural model to design transmit precoders for integrated sensing and communication (ISAC) systems to maximize the worst-case target illumination power while ensuring a minimum signal-to-interference-plus-noise ratio (SINR) for all the users. The problem of learning transmit precoders from uplink pilots and echoes can be viewed as a parameterized function estimation problem and we propose to learn this function using a neural network model. To learn the neural network parameters, we develop a novel loss function based on the first-order optimality conditions to incorporate the SINR and power constraints. Through numerical simulations, we demonstrate that the proposed method outperforms traditional optimization-based methods in presence of channel estimation errors while incurring lesser computational complexity and generalizing well across different channel conditions that were not shown during training.
    
[^9]: 评估基于EEG的机器学习在帕金森病检测中的性别公平性：一项多中心研究

    Assessing gender fairness in EEG-based machine learning detection of Parkinson's disease: A multi-center study. (arXiv:2303.06376v1 [eess.SP])

    [http://arxiv.org/abs/2303.06376](http://arxiv.org/abs/2303.06376)

    本研究在多中心环境中对基于EEG的机器学习算法进行了性别子组群的检测能力分析，发现男性和女性的PD检测能力存在显着差异。

    This study analyzed the detection ability of gender sub-groups in a multi-center setting of a previously developed machine learning algorithm based on EEG, finding significant differences in Parkinson's disease detection ability between males and females.

    随着基于机器学习（ML）和静息态脑电图（rs-EEG）的自动工具在帕金森病（PD）检测中的数量不断增长，通过公平性和偏差分析评估可能加剧健康差异的问题变得更加重要。受保护的属性，如性别，在PD诊断开发中发挥重要作用。然而，来自不同性别的子组群体的分析很少在ML模型的开发或PD检测的性能评估中考虑。在这项工作中，我们对基于静息态脑电图功率谱密度（PSD）特征的先前开发的ML算法在多中心环境中的性别子组群的检测能力进行了系统分析。我们发现在测试时间（80.5％对63.7％的准确性）男性和女性的PD检测能力存在显着差异，并且一组顶部和前额脑电图通道和频率存在显着更高的活动。

    As the number of automatic tools based on machine learning (ML) and resting-state electroencephalography (rs-EEG) for Parkinson's disease (PD) detection keeps growing, the assessment of possible exacerbation of health disparities by means of fairness and bias analysis becomes more relevant. Protected attributes, such as gender, play an important role in PD diagnosis development. However, analysis of sub-group populations stemming from different genders is seldom taken into consideration in ML models' development or the performance assessment for PD detection. In this work, we perform a systematic analysis of the detection ability for gender sub-groups in a multi-center setting of a previously developed ML algorithm based on power spectral density (PSD) features of rs-EEG. We find significant differences in the PD detection ability for males and females at testing time (80.5% vs. 63.7% accuracy) and significantly higher activity for a set of parietal and frontal EEG channels and frequen
    
[^10]: 面向非静态环境的隐私保护合作可见光定位：联邦学习视角

    Privacy-Preserving Cooperative Visible Light Positioning for Nonstationary Environment: A Federated Learning Perspective. (arXiv:2303.06361v1 [eess.SP])

    [http://arxiv.org/abs/2303.06361](http://arxiv.org/abs/2303.06361)

    本文提出了一种基于联邦学习的合作可见光定位方案，通过共同训练适应环境变化的全局模型，提高了在非静态环境下的定位精度和泛化能力。

    This paper proposes a cooperative visible light positioning scheme based on federated learning, which improves the positioning accuracy and generalization capability in nonstationary environments by jointly training a global model adaptive to environmental changes without sharing private data of users.

    可见光定位（VLP）作为一种有前途的室内定位技术，已经引起了足够的关注。然而，在非静态环境下，由于高度时变的信道，VLP的性能受到限制。为了提高非静态环境下的定位精度和泛化能力，本文提出了一种基于联邦学习（FL）的合作VLP方案。利用FL框架，用户可以共同训练适应环境变化的全局模型，而不共享用户的私有数据。此外，提出了一种合作可见光定位网络（CVPosNet），以加速收敛速度和提高定位精度。仿真结果表明，所提出的方案在非静态环境下优于基准方案。

    Visible light positioning (VLP) has drawn plenty of attention as a promising indoor positioning technique. However, in nonstationary environments, the performance of VLP is limited because of the highly time-varying channels. To improve the positioning accuracy and generalization capability in nonstationary environments, a cooperative VLP scheme based on federated learning (FL) is proposed in this paper. Exploiting the FL framework, a global model adaptive to environmental changes can be jointly trained by users without sharing private data of users. Moreover, a Cooperative Visible-light Positioning Network (CVPosNet) is proposed to accelerate the convergence rate and improve the positioning accuracy. Simulation results show that the proposed scheme outperforms the benchmark schemes, especially in nonstationary environments.
    
[^11]: 基于张量网络机器学习的Raman光谱数据肺癌智能诊断方案

    Intelligent diagnostic scheme for lung cancer screening with Raman spectra data by tensor network machine learning. (arXiv:2303.06340v1 [q-bio.QM])

    [http://arxiv.org/abs/2303.06340](http://arxiv.org/abs/2303.06340)

    本文提出了一种基于张量网络机器学习的方案，通过筛查呼出气中挥发性有机化合物（VOC）的Raman光谱数据，可可靠地预测肺癌患者及其阶段。

    This paper proposes a tensor-network machine learning method to reliably predict lung cancer patients and their stages via screening Raman spectra data of Volatile organic compounds (VOCs) in exhaled breath.

    人工智能（AI）已经在生物医学科学中带来了巨大的影响，从学术研究到临床应用，例如生物标志物的检测和诊断、治疗优化以及药物发现中新的治疗靶点的识别。然而，当代AI技术，特别是深度机器学习（ML），严重受到非可解释性的影响，这可能会不可控地导致错误的预测。对于ML的可解释性尤其重要，因为消费者必须从坚实的基础或令人信服的解释中获得必要的安全感和信任感。在这项工作中，我们提出了一种基于张量网络（TN）-ML方法的方案，通过筛查呼出气中挥发性有机化合物（VOC）的Raman光谱数据，可可靠地预测肺癌患者及其阶段，这些数据通常适用于生物标志物，并被认为是非侵入性肺癌筛查的理想方式。TN-ML的预测基于

    Artificial intelligence (AI) has brought tremendous impacts on biomedical sciences from academic researches to clinical applications, such as in biomarkers' detection and diagnosis, optimization of treatment, and identification of new therapeutic targets in drug discovery. However, the contemporary AI technologies, particularly deep machine learning (ML), severely suffer from non-interpretability, which might uncontrollably lead to incorrect predictions. Interpretability is particularly crucial to ML for clinical diagnosis as the consumers must gain necessary sense of security and trust from firm grounds or convincing interpretations. In this work, we propose a tensor-network (TN)-ML method to reliably predict lung cancer patients and their stages via screening Raman spectra data of Volatile organic compounds (VOCs) in exhaled breath, which are generally suitable as biomarkers and are considered to be an ideal way for non-invasive lung cancer screening. The prediction of TN-ML is based
    
[^12]: MLP-SRGAN: 使用MLP-Mixer的单维超分辨率GAN

    MLP-SRGAN: A Single-Dimension Super Resolution GAN using MLP-Mixer. (arXiv:2303.06298v1 [cs.CV])

    [http://arxiv.org/abs/2303.06298](http://arxiv.org/abs/2303.06298)

    MLP-SRGAN是一种单维超分辨率GAN，使用MLP-Mixer和卷积层进行上采样，可用于FLAIR MRI图像的超分辨率重建，提出了新的图像质量度量方法。

    MLP-SRGAN is a single-dimension Super Resolution GAN that utilizes MLP-Mixers and convolutional layers for upsampling, and can be used for super-resolution reconstruction of FLAIR MRI images. New image quality metrics were proposed.

    我们提出了一种新的架构，称为MLP-SRGAN，它是一种单维超分辨率生成对抗网络（SRGAN），利用多层感知器混合器（MLP-Mixer）以及卷积层在切片方向上进行上采样。 MLP-SRGAN使用MSSEG2挑战数据集中的高分辨率（HR）FLAIR MRI进行训练和验证。该方法应用于三个低空间分辨率的多中心FLAIR数据集（CAIN，ADNI，CCNA）的图像，以检查在保留（未见）临床数据上的性能。将上采样结果与几种最先进的SR网络进行比较。对于具有高分辨率（HR）基本事实的图像，使用峰值信噪比（PSNR）和结构相似性指数（SSIM）来衡量上采样性能。提出了几种新的结构，无参考图像质量度量，以在缺乏基础事实的情况下量化锐度（边缘强度），噪声（熵）和模糊度（低频信息）。

    We propose a novel architecture called MLP-SRGAN, which is a single-dimension Super Resolution Generative Adversarial Network (SRGAN) that utilizes Multi-Layer Perceptron Mixers (MLP-Mixers) along with convolutional layers to upsample in the slice direction. MLP-SRGAN is trained and validated using high resolution (HR) FLAIR MRI from the MSSEG2 challenge dataset. The method was applied to three multicentre FLAIR datasets (CAIN, ADNI, CCNA) of images with low spatial resolution in the slice dimension to examine performance on held-out (unseen) clinical data. Upsampled results are compared to several state-of-the-art SR networks. For images with high resolution (HR) ground truths, peak-signal-to-noise-ratio (PSNR) and structural similarity index (SSIM) are used to measure upsampling performance. Several new structural, no-reference image quality metrics were proposed to quantify sharpness (edge strength), noise (entropy), and blurriness (low frequency information) in the absence of groun
    
[^13]: MCROOD: 多类雷达超出分布检测

    MCROOD: Multi-Class Radar Out-Of-Distribution Detection. (arXiv:2303.06232v1 [cs.CV])

    [http://arxiv.org/abs/2303.06232](http://arxiv.org/abs/2303.06232)

    本文提出了一种基于重建的多类OOD检测器，该检测器在雷达距离多普勒图像（RDIs）上运行。检测器旨在将除坐、站或走的人以外的任何移动物体分类为OOD。作者还提供了一种简单而有效的预处理技术，以检测呼吸等微小的人体运动。在实验中，该方法表现优于最先进的OOD检测方法。

    This paper proposes a reconstruction-based multi-class OOD detector that operates on radar range doppler images (RDIs). The detector aims to classify any moving object other than a person sitting, standing, or walking as OOD. The authors also provide a simple yet effective pre-processing technique to detect minor human body movements like breathing. The method outperforms state-of-the-art OOD detection methods in experiments.

    最近，由于其在安全部署现代深度学习（DL）架构中的关键作用，超出分布（OOD）检测受到特别关注。本文提出了一种基于重建的多类OOD检测器，该检测器在雷达距离多普勒图像（RDIs）上运行。检测器旨在将除坐、站或走的人以外的任何移动物体分类为OOD。我们还提供了一种简单而有效的预处理技术，以检测呼吸等微小的人体运动。这个简单的想法被称为呼吸检测器（RESPD），可以减轻OOD检测的负担，特别是对于人坐和人站的类别。在我们收集的60GHz短距离FMCW雷达数据集上，我们分别为坐、站和走三个类别实现了97.45％、92.13％和96.58％的AUROC。我们进行了大量实验，并表明我们的方法优于最先进的OOD检测方法。此外，我们的流程比第二好的方法快24倍，并且是v

    Out-of-distribution (OOD) detection has recently received special attention due to its critical role in safely deploying modern deep learning (DL) architectures. This work proposes a reconstruction-based multi-class OOD detector that operates on radar range doppler images (RDIs). The detector aims to classify any moving object other than a person sitting, standing, or walking as OOD. We also provide a simple yet effective pre-processing technique to detect minor human body movements like breathing. The simple idea is called respiration detector (RESPD) and eases the OOD detection, especially for human sitting and standing classes. On our dataset collected by 60GHz short-range FMCW Radar, we achieve AUROCs of 97.45%, 92.13%, and 96.58% for sitting, standing, and walking classes, respectively. We perform extensive experiments and show that our method outperforms state-of-the-art (SOTA) OOD detection methods. Also, our pipeline performs 24 times faster than the second-best method and is v
    
[^14]: 数字孪生辅助异构联邦学习的知识蒸馏框架

    Digital Twin-Assisted Knowledge Distillation Framework for Heterogeneous Federated Learning. (arXiv:2303.06155v1 [cs.LG])

    [http://arxiv.org/abs/2303.06155](http://arxiv.org/abs/2303.06155)

    本文提出了一种数字孪生辅助的知识蒸馏框架，用于解决联邦学习系统中的异构性问题，用户可以选择自己的神经网络模型并从大型教师模型中蒸馏知识，同时利用数字孪生在服务器上训练大型教师模型，最终通过混合整数规划和Q-learning算法实现模型选择和资源分配。

    This paper proposes a digital twin-assisted knowledge distillation framework for heterogeneous federated learning, where users can select their own neural network models and distill knowledge from a big teacher model, and the teacher model can be trained on a digital twin located in the server. The joint problem of model selection and training offloading and resource allocation for users is formulated as a mixed integer programming problem and solved using Q-learning and optimization algorithms.

    本文提出了一种知识蒸馏驱动的联邦学习框架，以应对联邦学习系统中的异构性，其中每个用户可以根据需要选择其神经网络模型，并使用自己的私有数据集从大型教师模型中蒸馏知识。为了克服在资源有限的用户设备上训练大型教师模型的挑战，利用数字孪生的方式，教师模型可以在具有足够计算资源的服务器上的数字孪生中进行训练。然后，在模型蒸馏期间，每个用户可以在物理实体或数字代理处更新其模型的参数。为用户选择模型和训练卸载和资源分配制定了混合整数规划（MIP）问题。为了解决这个问题，联合使用Q-learning和优化，其中Q-learning为用户选择模型并确定是在本地还是在服务器上进行训练，而优化则用于资源分配。

    In this paper, to deal with the heterogeneity in federated learning (FL) systems, a knowledge distillation (KD) driven training framework for FL is proposed, where each user can select its neural network model on demand and distill knowledge from a big teacher model using its own private dataset. To overcome the challenge of train the big teacher model in resource limited user devices, the digital twin (DT) is exploit in the way that the teacher model can be trained at DT located in the server with enough computing resources. Then, during model distillation, each user can update the parameters of its model at either the physical entity or the digital agent. The joint problem of model selection and training offloading and resource allocation for users is formulated as a mixed integer programming (MIP) problem. To solve the problem, Q-learning and optimization are jointly used, where Q-learning selects models for users and determines whether to train locally or on the server, and optimiz
    
[^15]: 临床BERTScore：临床环境下自动语音识别性能的改进度量

    Clinical BERTScore: An Improved Measure of Automatic Speech Recognition Performance in Clinical Settings. (arXiv:2303.05737v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2303.05737](http://arxiv.org/abs/2303.05737)

    本文提出了一种临床BERTScore（CBERTScore）度量，它比其他度量更严厉地惩罚临床相关的错误，更接近于临床医生对医学句子的偏好。作者还收集了13个临床医生对149个现实医学句子的偏好基准，称为临床转录偏好基准（CTP），证明CBERTScore更接近于临床医生的偏好，并将基准发布给社区以进一步开发具有临床意识的ASR度量。

    The paper proposes a Clinical BERTScore (CBERTScore) metric for ASR in medical contexts, which penalizes clinically-relevant mistakes more than other metrics and aligns more closely with clinician preferences. The authors also collect a benchmark of clinician preferences on medical sentences and release it for the community to further develop clinically-aware ASR metrics.

    医学环境中的自动语音识别（ASR）有潜力节省时间，降低成本，提高报告准确性并减少医生的疲劳。然而，由于避免医学相关的转录错误的重要性，医疗行业采用这种技术的速度较慢。在这项工作中，我们提出了临床BERTScore（CBERTScore），这是一种ASR度量，它比其他度量（WER、BLUE、METEOR等）更严厉地惩罚临床相关的错误。我们证明了这个度量更接近于临床医生对医学句子的偏好，有时差距很大。我们收集了13个临床医生对149个现实医学句子的偏好基准，称为临床转录偏好基准（CTP），证明CBERTScore更接近于临床医生的偏好，并将基准发布给社区以进一步开发具有临床意识的ASR度量。

    Automatic Speech Recognition (ASR) in medical contexts has the potential to save time, cut costs, increase report accuracy, and reduce physician burnout. However, the healthcare industry has been slower to adopt this technology, in part due to the importance of avoiding medically-relevant transcription mistakes. In this work, we present the Clinical BERTScore (CBERTScore), an ASR metric that penalizes clinically-relevant mistakes more than others. We demonstrate that this metric more closely aligns with clinician preferences on medical sentences as compared to other metrics (WER, BLUE, METEOR, etc), sometimes by wide margins. We collect a benchmark of 13 clinician preferences on 149 realistic medical sentences called the Clinician Transcript Preference benchmark (CTP), demonstrate that CBERTScore more closely matches what clinicians prefer, and release the benchmark for the community to further develop clinically-aware ASR metrics.
    
[^16]: 基于规划强化学习的可再生能源电力系统实时调度

    Real-time scheduling of renewable power systems through planning-based reinforcement learning. (arXiv:2303.05205v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.05205](http://arxiv.org/abs/2303.05205)

    本文提出了一种基于规划强化学习算法和真实电力网环境的系统解决方案，可以实现发电机的规划和更细的时间分辨率调整，从而增加了电网的能力。

    This paper proposes a systematic solution based on the state-of-the-art reinforcement learning algorithm and the real power grid environment, which enables planning and finer time resolution adjustments of power generators, including unit commitment and economic dispatch, thus increasing the grid's ability.

    不断增长的可再生能源来源对传统电力调度提出了重大挑战。运营商难以获得准确的可再生能源发电日前预测，因此需要未来调度系统根据超短期预测进行实时调度决策。受计算速度限制，传统的基于优化的方法无法解决这个问题。最近强化学习（RL）的发展已经展示了解决这个挑战的潜力。然而，现有的RL方法在约束复杂性、算法性能和环境保真度方面不足。我们是第一个提出基于最先进的强化学习算法和真实电力网环境的系统解决方案。所提出的方法使发电机的规划和更细的时间分辨率调整成为可能，包括机组组合和经济调度，从而增加了电网的能力。

    The growing renewable energy sources have posed significant challenges to traditional power scheduling. It is difficult for operators to obtain accurate day-ahead forecasts of renewable generation, thereby requiring the future scheduling system to make real-time scheduling decisions aligning with ultra-short-term forecasts. Restricted by the computation speed, traditional optimization-based methods can not solve this problem. Recent developments in reinforcement learning (RL) have demonstrated the potential to solve this challenge. However, the existing RL methods are inadequate in terms of constraint complexity, algorithm performance, and environment fidelity. We are the first to propose a systematic solution based on the state-of-the-art reinforcement learning algorithm and the real power grid environment. The proposed approach enables planning and finer time resolution adjustments of power generators, including unit commitment and economic dispatch, thus increasing the grid's abilit
    
[^17]: 利用预训练的AudioLDM进行文本到声音生成：基准研究

    Leveraging Pre-trained AudioLDM for Text to Sound Generation: A Benchmark Study. (arXiv:2303.03857v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2303.03857](http://arxiv.org/abs/2303.03857)

    本文研究了使用预训练的AudioLDM作为声音生成的骨干的优势，证明了在数据稀缺情况下使用预训练模型进行文本到声音生成的优势，并在几个常用数据集上使用相同的评估协议评估了各种文本到声音生成系统，为未来的研究提供了基础。

    This paper investigates the advantages of using pre-trained AudioLDM as the backbone for sound generation, demonstrates the benefits of using pre-trained models for text-to-sound generation in data-scarcity scenarios, and evaluates various text-to-sound generation systems on several frequently used datasets under the same evaluation protocols to provide a basis for future research.

    深度神经网络最近在文本提示下实现了声音生成的突破。尽管它们的表现很有前途，但当前的文本到声音生成模型在小规模数据集（例如过度拟合）上面临问题，从而显著限制了它们的性能。在本文中，我们研究了使用预训练的AudioLDM作为声音生成的骨干的优势。我们的研究证明了在数据稀缺情况下使用预训练模型进行文本到声音生成的优势。此外，实验表明，不同的训练策略（例如训练条件）可能会影响AudioLDM在不同规模的数据集上的性能。为了促进未来的研究，我们还在几个常用数据集上使用相同的评估协议评估了各种文本到声音生成系统，这些协议允许在共同基础上公平比较和基准测试这些方法。

    Deep neural networks have recently achieved breakthroughs in sound generation with text prompts. Despite their promising performance, current text-to-sound generation models face issues on small-scale datasets (e.g., overfitting), significantly limiting their performance. In this paper, we investigate the use of pre-trained AudioLDM, the state-of-the-art model for text-to-audio generation, as the backbone for sound generation. Our study demonstrates the advantages of using pre-trained models for text-to-sound generation, especially in data-scarcity scenarios. In addition, experiments show that different training strategies (e.g., training conditions) may affect the performance of AudioLDM on datasets of different scales. To facilitate future studies, we also evaluate various text-to-sound generation systems on several frequently used datasets under the same evaluation protocols, which allow fair comparisons and benchmarking of these methods on the common ground.
    
[^18]: PreFallKD: 基于CNN-ViT知识蒸馏的预防跌倒系统

    PreFallKD: Pre-Impact Fall Detection via CNN-ViT Knowledge Distillation. (arXiv:2303.03634v2 [eess.SP] UPDATED)

    [http://arxiv.org/abs/2303.03634](http://arxiv.org/abs/2303.03634)

    本文提出了一种基于CNN-ViT知识蒸馏的预防跌倒系统PreFallKD，通过将预训练的教师模型的检测知识转移到轻量级卷积神经网络的学生模型上，实现了检测性能和计算复杂性的平衡。

    This paper proposes a pre-impact fall detection system called PreFallKD, which uses CNN-ViT knowledge distillation to transfer detection knowledge from a pre-trained teacher model to a lightweight convolutional neural network student model. The system achieves a balance between detection performance and computational complexity.

    跌倒事故是老龄化社会中的重要问题。近年来，许多研究人员使用深度学习开发了预防跌倒系统，以支持基于可穿戴设备的跌倒保护系统，以预防严重的伤害。然而，大多数工作只使用简单的神经网络模型，而不是考虑到资源受限的移动设备和严格的延迟要求的复杂模型的可用性。在这项工作中，我们提出了一种新颖的基于CNN-ViT知识蒸馏的预防跌倒系统，即PreFallKD，以在检测性能和计算复杂性之间取得平衡。所提出的PreFallKD将检测知识从预训练的教师模型（视觉变换器）转移到学生模型（轻量级卷积神经网络）。此外，我们应用数据增强技术来解决数据不平衡的问题。我们在KFall公共数据集上进行实验，并将PreFallKD与其他最先进的模型进行比较。

    Fall accidents are critical issues in an aging and aged society. Recently, many researchers developed pre-impact fall detection systems using deep learning to support wearable-based fall protection systems for preventing severe injuries. However, most works only employed simple neural network models instead of complex models considering the usability in resource-constrained mobile devices and strict latency requirements. In this work, we propose a novel pre-impact fall detection via CNN-ViT knowledge distillation, namely PreFallKD, to strike a balance between detection performance and computational complexity. The proposed PreFallKD transfers the detection knowledge from the pre-trained teacher model (vision transformer) to the student model (lightweight convolutional neural networks). Additionally, we apply data augmentation techniques to tackle issues of data imbalance. We conduct the experiment on the KFall public dataset and compare PreFallKD with other state-of-the-art models. The
    
[^19]: 异构图学习在声音事件分类中的应用

    Heterogeneous Graph Learning for Acoustic Event Classification. (arXiv:2303.02665v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2303.02665](http://arxiv.org/abs/2303.02665)

    本文提出了一种新模型，异构图跨模态网络（HGCN），它学习跨模态边缘，可以适应各种空间和时间尺度，有效地连接了跨模态的相关节点，在声音事件分类中表现出最先进的性能。

    This paper proposes a new model, Heterogeneous Graph Crossmodal Network (HGCN), which learns crossmodal edges and can adapt to various spatial and temporal scales, effectively connecting relevant nodes across modalities. It achieves state-of-the-art performance in acoustic event classification.

    异构图提供了一种紧凑、高效、可扩展的方式来建模涉及多个不同模态的数据。这使得使用异构图来建模音频视觉数据成为一种有吸引力的选择。然而，图结构在音频视觉数据中并不自然。音频视觉数据的图是手动构建的，这既困难又次优。在这项工作中，我们通过（i）提出一种参数化图构建策略来解决这个问题，以及（ii）学习跨模态边缘。为此，我们开发了一种新模型，异构图跨模态网络（HGCN），它学习跨模态边缘。我们提出的模型可以适应各种空间和时间尺度，因为它是参数化构建的，而可学习的跨模态边缘有效地连接了跨模态的相关节点。在一个大型基准数据集（AudioSet）上的实验表明，我们的模型是最先进的（0.53平均精度），优于transfo。

    Heterogeneous graphs provide a compact, efficient, and scalable way to model data involving multiple disparate modalities. This makes modeling audiovisual data using heterogeneous graphs an attractive option. However, graph structure does not appear naturally in audiovisual data. Graphs for audiovisual data are constructed manually which is both difficult and sub-optimal. In this work, we address this problem by (i) proposing a parametric graph construction strategy for the intra-modal edges, and (ii) learning the crossmodal edges. To this end, we develop a new model, heterogeneous graph crossmodal network (HGCN) that learns the crossmodal edges. Our proposed model can adapt to various spatial and temporal scales owing to its parametric construction, while the learnable crossmodal edges effectively connect the relevant nodes across modalities. Experiments on a large benchmark dataset (AudioSet) show that our model is state-of-the-art (0.53 mean average precision), outperforming transfo
    
[^20]: 文本转语音的细粒度情感控制：学习排名内部和外部类情感强度

    Fine-grained Emotional Control of Text-To-Speech: Learning To Rank Inter- And Intra-Class Emotion Intensities. (arXiv:2303.01508v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2303.01508](http://arxiv.org/abs/2303.01508)

    本文提出了一种细粒度可控情感TTS，考虑了内部和外部类距离，并能够合成具有可识别强度差异的语音。

    This paper proposes a fine-grained controllable emotional TTS, that considers both interand intra-class distances and be able to synthesize speech with recognizable intensity difference.

    最先进的文本转语音（TTS）模型能够产生高质量的语音。然而，生成的语音通常在情感表达上是中性的，而很多时候人们希望对单词或音素进行细粒度的情感控制。虽然仍然具有挑战性，但最近已经提出了第一批TTS模型，能够通过手动分配情感强度来控制语音。不幸的是，由于忽略了内部类距离，强度差异经常无法识别。在本文中，我们提出了一种细粒度可控情感TTS，考虑了内部和外部类距离，并能够合成具有可识别强度差异的语音。我们的主观和客观实验表明，我们的模型在可控性、情感表达和自然度方面超过了两个最先进的可控TTS模型。

    State-of-the-art Text-To-Speech (TTS) models are capable of producing high-quality speech. The generated speech, however, is usually neutral in emotional expression, whereas very often one would want fine-grained emotional control of words or phonemes. Although still challenging, the first TTS models have been recently proposed that are able to control voice by manually assigning emotion intensity. Unfortunately, due to the neglect of intra-class distance, the intensity differences are often unrecognizable. In this paper, we propose a fine-grained controllable emotional TTS, that considers both interand intra-class distances and be able to synthesize speech with recognizable intensity difference. Our subjective and objective experiments demonstrate that our model exceeds two state-of-the-art controllable TTS models for controllability, emotion expressiveness and naturalness.
    
[^21]: 重新思考半监督医学图像分割：方差缩减的视角

    Rethinking Semi-Supervised Medical Image Segmentation: A Variance-Reduction Perspective. (arXiv:2302.01735v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.01735](http://arxiv.org/abs/2302.01735)

    本文提出了ARCO，一种半监督对比学习（CL）框架，其中包括医学图像分割中的分层组采样理论。通过方差缩减估计的概念来构建ARCO，并表明某些方差缩减技术在医学图像分割中特别有益。

    This paper proposes ARCO, a semi-supervised contrastive learning (CL) framework with stratified group sampling theory in medical image segmentation. The concept of variance-reduced estimation is used to build ARCO, and certain variance-reduction techniques are shown to be particularly beneficial in medical image segmentation.

    对于医学图像分割，对比学习是提高视觉表示质量的主要方法，通过对比语义相似和不相似的样本对来实现。这是通过观察到，在没有访问地面真实标签的情况下，如果采样具有真正不同解剖特征的负样本，则可以显着提高性能。然而，在现实中，这些样本可能来自相似的解剖特征，模型可能难以区分少数尾类样本，使得尾类更容易被错误分类，这通常导致模型崩溃。在本文中，我们提出了ARCO，一种半监督对比学习（CL）框架，其中包括医学图像分割中的分层组采样理论。特别是，我们首先提出通过方差缩减估计的概念来构建ARCO，并表明某些方差缩减技术在医学图像分割中特别有益。

    For medical image segmentation, contrastive learning is the dominant practice to improve the quality of visual representations by contrasting semantically similar and dissimilar pairs of samples. This is enabled by the observation that without accessing ground truth label, negative examples with truly dissimilar anatomical features, if sampled, can significantly improve the performance. In reality, however, these samples may come from similar anatomical features and the models may struggle to distinguish the minority tail-class samples, making the tail classes more prone to misclassification, both of which typically lead to model collapse. In this paper, we propose ARCO, a semi-supervised contrastive learning (CL) framework with stratified group sampling theory in medical image segmentation. In particular, we first propose building ARCO through the concept of variance-reduced estimation, and show that certain variance-reduction techniques are particularly beneficial in medical image se
    
[^22]: LDMIC：基于学习的分布式多视图图像编码

    LDMIC: Learning-based Distributed Multi-view Image Coding. (arXiv:2301.09799v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2301.09799](http://arxiv.org/abs/2301.09799)

    LDMIC是一种基于学习的分布式多视图图像编码框架，通过独立编码器和联合上下文传输模块实现了全局视图间的相关性捕捉，对几何关系不敏感。

    LDMIC is a learning-based distributed multi-view image coding framework that captures global inter-view correlations through independent encoders and a joint context transfer module based on the cross-attention mechanism, which is insensitive to geometric relations.

    多视图图像压缩在3D相关应用中起着至关重要的作用。现有方法采用预测编码架构，需要联合编码压缩相应的视差和残差信息。这要求相机之间进行协作，并强制执行不同视图之间的极线几何约束，这使得在具有随机重叠视野的分布式相机系统中部署这些方法具有挑战性。同时，分布式源编码理论表明，可以通过独立编码和联合解码实现相关源的高效数据压缩，这激发了我们设计基于学习的分布式多视图图像编码（LDMIC）框架的动机。通过独立编码器，LDMIC引入了一个简单而有效的基于交叉注意机制的联合上下文传输模块，以有效捕捉全局视图间的相关性，对几何关系不敏感。

    Multi-view image compression plays a critical role in 3D-related applications. Existing methods adopt a predictive coding architecture, which requires joint encoding to compress the corresponding disparity as well as residual information. This demands collaboration among cameras and enforces the epipolar geometric constraint between different views, which makes it challenging to deploy these methods in distributed camera systems with randomly overlapping fields of view. Meanwhile, distributed source coding theory indicates that efficient data compression of correlated sources can be achieved by independent encoding and joint decoding, which motivates us to design a learning-based distributed multi-view image coding (LDMIC) framework. With independent encoders, LDMIC introduces a simple yet effective joint context transfer module based on the cross-attention mechanism at the decoder to effectively capture the global inter-view correlations, which is insensitive to the geometric relation
    
[^23]: 感知-神经-物理声音匹配

    Perceptual-Neural-Physical Sound Matching. (arXiv:2301.02886v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2301.02886](http://arxiv.org/abs/2301.02886)

    本文提出了一种新的声音匹配算法，称为感知-神经-物理损失（PNP），它是频谱损失的最优二次近似，能够更好地适应不同参数的感知重要性，同时具有快速收敛的特点。

    This paper proposes a new sound matching algorithm called Perceptual-Neural-Physical loss (PNP), which is the optimal quadratic approximation of spectral loss and can better accommodate the differing perceptual significance of each parameter while having fast convergence.

    声音匹配算法旨在通过参数化音频合成来近似目标波形。深度神经网络在匹配持续谐波音调方面取得了有希望的结果。然而，当目标是非平稳和非谐波的时候，例如打击乐器，任务就更具挑战性。我们将这个问题归因于损失函数的不足。一方面，参数域中的均方误差，称为“P-loss”，简单快速，但未能适应每个参数的不同感知重要性。另一方面，频谱时间域中的均方误差，称为“频谱损失”，在感知上是有动机的，并在可微分数字信号处理（DDSP）中发挥作用。然而，频谱损失是音高间隔的不良预测因素，其梯度可能计算成本高，因此收敛速度较慢。在这个困境中，我们提出了感知-神经-物理损失（PNP）。PNP是频谱损失的最优二次近似，同时具有快速收敛的特点。

    Sound matching algorithms seek to approximate a target waveform by parametric audio synthesis. Deep neural networks have achieved promising results in matching sustained harmonic tones. However, the task is more challenging when targets are nonstationary and inharmonic, e.g., percussion. We attribute this problem to the inadequacy of loss function. On one hand, mean square error in the parametric domain, known as "P-loss", is simple and fast but fails to accommodate the differing perceptual significance of each parameter. On the other hand, mean square error in the spectrotemporal domain, known as "spectral loss", is perceptually motivated and serves in differentiable digital signal processing (DDSP). Yet, spectral loss is a poor predictor of pitch intervals and its gradient may be computationally expensive; hence a slow convergence. Against this conundrum, we present Perceptual-Neural-Physical loss (PNP). PNP is the optimal quadratic approximation of spectral loss while being as fast 
    
[^24]: 一种用于婴儿脑可解释方法的注意力机制

    A attention way in Explainable methods for infant brain. (arXiv:2301.00815v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.00815](http://arxiv.org/abs/2301.00815)

    本文提出了一种可解释的几何深度网络，通过端到端学习解释因素以增强区分性表示提取，以反向保证细粒度的可解释性，适用于神经影像和神经科学研究中的高维数据。

    This paper proposes an explainable geometric deep network that enhances discriminative representation extraction by end-to-end learning of explanation factors, which is a more intuitive strategy to inversely assure fine-grained explainability, suitable for high-dimensional data in neuroimaging and neuroscience studies containing noisy, redundant, and task-irrelevant information.

    在跨学科应用中部署可靠的深度学习技术需要学习模型输出准确且（更重要的是）可解释的预测。现有方法通常以事后方式解释网络输出，隐含地假设忠实的解释来自准确的预测/分类。我们提出相反的观点，即解释提升（甚至决定）分类。也就是说，端到端学习解释因素以增强区分性表示提取可能是一种更直观的策略，以反向保证细粒度的可解释性，例如在那些包含噪声，冗余和任务无关信息的高维数据的神经影像和神经科学研究中。在本文中，我们提出了一种可解释的几何深度网络。

    Deploying reliable deep learning techniques in interdisciplinary applications needs learned models to output accurate and ({even more importantly}) explainable predictions. Existing approaches typically explicate network outputs in a post-hoc fashion, under an implicit assumption that faithful explanations come from accurate predictions/classifications. We have an opposite claim that explanations boost (or even determine) classification. That is, end-to-end learning of explanation factors to augment discriminative representation extraction could be a more intuitive strategy to inversely assure fine-grained explainability, e.g., in those neuroimaging and neuroscience studies with high-dimensional data containing noisy, redundant, and task-irrelevant information. In this paper, we propose such an explainable geometric deep network dubbed.
    
[^25]: 一次性领域自适应在基于视频的手术技能评估中的应用

    One-shot domain adaptation in video-based assessment of surgical skills. (arXiv:2301.00812v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.00812](http://arxiv.org/abs/2301.00812)

    本文提出了一种元学习模型A-VBANet，可以通过一次性学习提供领域不可知的手术技能分类，成功地适应了模拟任务和腹腔镜胆囊切除术，为基于视频的手术技能评估提供了领域不可知程序。

    This paper proposes a meta-learning model, A-VBANet, that can deliver domain-agnostic surgical skill classification via one-shot learning. The model successfully adapts to simulated tasks and laparoscopic cholecystectomy, providing a domain-agnostic procedure for video-based assessment of surgical skills.

    深度学习已经实现了手术技能的自动和客观评估。然而，深度学习模型需要大量数据，并且受限于其训练领域。这阻止了它们过渡到数据有限的新任务。因此，领域自适应对于在现实生活中实现深度学习至关重要。在这里，我们提出了一种元学习模型A-VBANet，它可以通过一次性学习提供领域不可知的手术技能分类。我们在五个腹腔镜和机器人手术模拟器上开发了A-VBANet。此外，我们在腹腔镜胆囊切除术的手术室视频上进行了测试。我们的模型成功地适应了模拟任务，准确率高达99.5%（一次性）和99.9%（少量样本），在腹腔镜胆囊切除术中的准确率为89.7%。我们首次提供了基于视频的手术技能评估的领域不可知程序。这种方法的一个重要影响是它允许使用来自手术模拟器的数据来评估手术表现。

    Deep Learning (DL) has achieved automatic and objective assessment of surgical skills. However, DL models are data-hungry and restricted to their training domain. This prevents them from transitioning to new tasks where data is limited. Hence, domain adaptation is crucial to implement DL in real life. Here, we propose a meta-learning model, A-VBANet, that can deliver domain-agnostic surgical skill classification via one-shot learning. We develop the A-VBANet on five laparoscopic and robotic surgical simulators. Additionally, we test it on operating room (OR) videos of laparoscopic cholecystectomy. Our model successfully adapts with accuracies up to 99.5% in one-shot and 99.9% in few-shot settings for simulated tasks and 89.7% for laparoscopic cholecystectomy. For the first time, we provide a domain-agnostic procedure for video-based assessment of surgical skills. A significant implication of this approach is that it allows the use of data from surgical simulators to assess performance 
    
[^26]: UniDA3D: 统一的域自适应三维语义分割管道

    UniDA3D: Unified Domain Adaptive 3D Semantic Segmentation Pipeline. (arXiv:2212.10390v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.10390](http://arxiv.org/abs/2212.10390)

    本文提出了UniDA3D，一种统一的域自适应三维语义分割管道，通过设计统一的源和目标主动采样策略，可以解决三维分割领域中的多个自适应任务，并探索了实现多模态采样策略的可能性。

    This paper proposes UniDA3D, a unified domain adaptive 3D semantic segmentation pipeline, which can tackle several adaptation tasks in 3D segmentation field by designing a unified source-and-target active sampling strategy, and investigates the possibility of achieving a multi-modal sampling strategy.

    目前的三维语义分割模型是在现成的公共基准上训练的，但当这些训练良好的模型部署到新领域时，它们将不可避免地面临识别精度下降的挑战。本文介绍了一种统一的域自适应三维语义分割管道（UniDA3D），以增强弱泛化能力，并弥合域之间的点分布差距。与之前只关注单一自适应任务的研究不同，UniDA3D可以通过设计统一的源和目标主动采样策略来解决三维分割领域中的多个自适应任务，该策略从源域和目标域中选择最具信息量的子集以实现有效的模型自适应。此外，受到多模态二维-三维数据集的崛起的影响，UniDA3D探索了实现多模态采样策略的可能性，通过开发跨模态特征交互模块，可以提取代表性对。

    State-of-the-art 3D semantic segmentation models are trained on off-the-shelf public benchmarks, but they will inevitably face the challenge of recognition accuracy drop when these well-trained models are deployed to a new domain. In this paper, we introduce a Unified Domain Adaptive 3D semantic segmentation pipeline (UniDA3D) to enhance the weak generalization ability, and bridge the point distribution gap between domains. Different from previous studies that only focus on a single adaptation task, UniDA3D can tackle several adaptation tasks in 3D segmentation field, by designing a unified source-and-target active sampling strategy, which selects a maximally-informative subset from both source and target domains for effective model adaptation. Besides, benefiting from the rise of multi-modal 2D-3D datasets, UniDA3D investigates the possibility of achieving a multi-modal sampling strategy, by developing a cross-modality feature interaction module that can extract a representative pair 
    
[^27]: 一份大规模的、基于PCR的COVID-19声音数据集

    A large-scale and PCR-referenced vocal audio dataset for COVID-19. (arXiv:2212.07738v3 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2212.07738](http://arxiv.org/abs/2212.07738)

    英国COVID-19 Vocal Audio Dataset是迄今为止最大的SARS-CoV-2 PCR参考音频记录集合，旨在为训练和评估使用声音数据分类SARS-CoV-2感染状态或相关呼吸症状的机器学习模型而设计。

    The UK COVID-19 Vocal Audio Dataset is the largest collection of SARS-CoV-2 PCR-referenced audio recordings to date, designed for the training and evaluation of machine learning models that classify SARS-CoV-2 infection status or associated respiratory symptoms using vocal audio.

    英国COVID-19 Vocal Audio Dataset旨在为训练和评估使用声音数据分类SARS-CoV-2感染状态或相关呼吸症状的机器学习模型而设计。英国卫生安全局通过国家测试和追踪计划和REACT-1调查在2021年3月至2022年3月期间招募了自愿参与者，收集了自愿咳嗽、呼气和语音的音频记录，并将其与SARS-CoV-2检测结果相关联。该数据集是迄今为止最大的SARS-CoV-2 PCR参考音频记录集合。

    The UK COVID-19 Vocal Audio Dataset is designed for the training and evaluation of machine learning models that classify SARS-CoV-2 infection status or associated respiratory symptoms using vocal audio. The UK Health Security Agency recruited voluntary participants through the national Test and Trace programme and the REACT-1 survey in England from March 2021 to March 2022, during dominant transmission of the Alpha and Delta SARS-CoV-2 variants and some Omicron variant sublineages. Audio recordings of volitional coughs, exhalations, and speech were collected in the 'Speak up to help beat coronavirus' digital survey alongside demographic, self-reported symptom and respiratory condition data, and linked to SARS-CoV-2 test results. The UK COVID-19 Vocal Audio Dataset represents the largest collection of SARS-CoV-2 PCR-referenced audio recordings to date. PCR results were linked to 70,794 of 72,999 participants and 24,155 of 25,776 positive cases. Respiratory symptoms were reported by 45.6
    
[^28]: 联邦贝叶斯学习中的客户端选择

    Client Selection for Federated Bayesian Learning. (arXiv:2212.05492v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.05492](http://arxiv.org/abs/2212.05492)

    本文提出了两种基于核化Stein差异（KSD）和希尔伯特内积（HIP）的DSVGD选择方案，以提高联邦贝叶斯学习中的模型收敛和通信效率。

    This paper proposes two selection schemes for Distributed Stein Variational Gradient Descent (DSVGD) based on Kernelized Stein Discrepancy (KSD) and Hilbert Inner Product (HIP) to improve the model convergence and communication efficiency in federated Bayesian learning.

    分布式Stein变分梯度下降（DSVGD）是一种非参数分布式学习框架，用于联邦贝叶斯学习，多个客户端通过与服务器通信一定数量的非随机和交互粒子来共同训练机器学习模型。由于通信资源有限，选择具有最具信息性的本地学习更新的客户端可以提高模型收敛和通信效率。本文提出了两种基于核化Stein差异（KSD）和希尔伯特内积（HIP）的DSVGD选择方案。我们推导了两种方案每次迭代全局自由能下降的上界，然后将其最小化以加速模型收敛。我们使用各种学习任务和数据集评估和比较了我们的方案与传统方案在模型准确性、收敛速度和稳定性方面的表现。

    Distributed Stein Variational Gradient Descent (DSVGD) is a non-parametric distributed learning framework for federated Bayesian learning, where multiple clients jointly train a machine learning model by communicating a number of non-random and interacting particles with the server. Since communication resources are limited, selecting the clients with most informative local learning updates can improve the model convergence and communication efficiency. In this paper, we propose two selection schemes for DSVGD based on Kernelized Stein Discrepancy (KSD) and Hilbert Inner Product (HIP). We derive the upper bound on the decrease of the global free energy per iteration for both schemes, which is then minimized to speed up the model convergence. We evaluate and compare our schemes with conventional schemes in terms of model accuracy, convergence speed, and stability using various learning tasks and datasets.
    
[^29]: 神经转录器训练：采用逐样本计算减少内存消耗

    Neural Transducer Training: Reduced Memory Consumption with Sample-wise Computation. (arXiv:2211.16270v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.16270](http://arxiv.org/abs/2211.16270)

    本文提出了一种内存高效的神经转录器训练方法，采用逐个样本计算转录器损失和梯度，显著减少了内存使用量，并在与默认批量计算相比时表现出竞争速度。

    This paper proposes a memory-efficient training method for neural transducer, which computes the transducer loss and gradients sample by sample, significantly reducing memory usage and performing at competitive speed compared to the default batched computation.

    神经转录器是一种用于自动语音识别（ASR）的端到端模型。虽然该模型非常适合流式ASR，但训练过程仍然具有挑战性。在训练过程中，内存需求可能会迅速超过最先进的GPU的容量，限制批量大小和序列长度。在这项工作中，我们分析了典型转录器训练设置的时间和空间复杂度。我们提出了一种内存高效的训练方法，逐个样本计算转录器损失和梯度。我们提出了优化方法，以增加逐样本方法的效率和并行性。在一组彻底的基准测试中，我们展示了我们的逐样本方法显著减少了内存使用量，并在与默认批量计算相比时表现出竞争速度。作为亮点，我们成功地使用仅6 GB的内存计算了批量大小为1024，音频长度为40秒的转录器损失和梯度。

    The neural transducer is an end-to-end model for automatic speech recognition (ASR). While the model is well-suited for streaming ASR, the training process remains challenging. During training, the memory requirements may quickly exceed the capacity of state-of-the-art GPUs, limiting batch size and sequence lengths. In this work, we analyze the time and space complexity of a typical transducer training setup. We propose a memory-efficient training method that computes the transducer loss and gradients sample by sample. We present optimizations to increase the efficiency and parallelism of the sample-wise method. In a set of thorough benchmarks, we show that our sample-wise method significantly reduces memory usage, and performs at competitive speed when compared to the default batched computation. As a highlight, we manage to compute the transducer loss and gradients for a batch size of 1024, and audio length of 40 seconds, using only 6 GB of memory.
    
[^30]: 深度神经Mel-Subband波束成形器用于车载语音分离

    Deep Neural Mel-Subband Beamformer for In-car Speech Separation. (arXiv:2211.12590v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2211.12590](http://arxiv.org/abs/2211.12590)

    本文提出了一种基于DL的Mel-Subband时空波束成形器，用于在车载环境中进行语音分离，通过基于Mel尺度的子带选择策略，实现对低频的细粒度处理和对高频的粗粒度处理，降低了计算成本和推理时间。

    This paper proposes a DL-based Mel-Subband spatio-temporal beamformer for speech separation in a car environment, which reduces computational costs and inference time by using a Mel-scale based subband selection strategy for fine-grained processing of lower frequencies and coarse-grained processing of higher frequencies.

    当前的深度学习（DL）基于波束成形技术已被证明在语音分离中有效，但它们通常被设计为独立处理窄带（NB）频率，这导致更高的计算成本和推理时间，使它们不适合实际应用。在本文中，我们提出了基于DL的Mel-Subband时空波束成形器，以在车载环境中进行语音分离，从而降低计算成本和推理时间。与传统的子带（SB）方法相反，我们的框架使用基于Mel尺度的子带选择策略，确保对大多数语音共振结构存在的低频进行细粒度处理，对高频进行粗粒度处理。以递归方式，从估计的子带语音和噪声协方差矩阵中确定每个扬声器位置/区域的鲁棒帧级波束成形权重。此外，所提出的框架还估计并抑制任何回声。

    While current deep learning (DL)-based beamforming techniques have been proved effective in speech separation, they are often designed to process narrow-band (NB) frequencies independently which results in higher computational costs and inference times, making them unsuitable for real-world use. In this paper, we propose DL-based mel-subband spatio-temporal beamformer to perform speech separation in a car environment with reduced computation cost and inference time. As opposed to conventional subband (SB) approaches, our framework uses a mel-scale based subband selection strategy which ensures a fine-grained processing for lower frequencies where most speech formant structure is present, and coarse-grained processing for higher frequencies. In a recursive way, robust frame-level beamforming weights are determined for each speaker location/zone in a car from the estimated subband speech and noise covariance matrices. Furthermore, proposed framework also estimates and suppresses any echo
    
[^31]: LA-VocE: 使用神经声码器的低信噪比音频视觉语音增强

    LA-VocE: Low-SNR Audio-visual Speech Enhancement using Neural Vocoders. (arXiv:2211.10999v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2211.10999](http://arxiv.org/abs/2211.10999)

    LA-VocE是一种新的音频视觉语音增强方法，使用神经声码器将从嘈杂的音频视觉语音预测的mel频谱图转换为波形音频，适用于多种语言和不同水平的背景噪声和语音干扰。

    LA-VocE is a new audio-visual speech enhancement method that uses a neural vocoder to convert mel-spectrograms predicted from noisy audio-visual speech via a transformer-based architecture into waveform audio, and is applicable to multiple languages and different levels of background noise and speech interference.

    音频视觉语音增强旨在通过利用音频本身以及目标说话者的唇部运动从嘈杂的环境中提取干净的语音。这种方法已经被证明比仅使用音频的语音增强方法更有效，特别是对于消除干扰语音。尽管语音合成方面取得了最近的进展，但大多数音频视觉方法仍然使用频谱映射/掩蔽来重现干净的音频，通常会在现有的语音增强架构中添加视觉骨干。在这项工作中，我们提出了LA-VocE，一种新的两阶段方法，通过基于Transformer的架构从嘈杂的音频视觉语音预测mel频谱图，然后使用神经声码器（HiFi-GAN）将它们转换为波形音频。我们在数千个说话者和11种以上不同的语言上训练和评估我们的框架，并研究我们的模型适应不同水平的背景噪声和语音干扰的能力。我们的实验表明

    Audio-visual speech enhancement aims to extract clean speech from a noisy environment by leveraging not only the audio itself but also the target speaker's lip movements. This approach has been shown to yield improvements over audio-only speech enhancement, particularly for the removal of interfering speech. Despite recent advances in speech synthesis, most audio-visual approaches continue to use spectral mapping/masking to reproduce the clean audio, often resulting in visual backbones added to existing speech enhancement architectures. In this work, we propose LA-VocE, a new two-stage approach that predicts mel-spectrograms from noisy audio-visual speech via a transformer-based architecture, and then converts them into waveform audio using a neural vocoder (HiFi-GAN). We train and evaluate our framework on thousands of speakers and 11+ different languages, and study our model's ability to adapt to different levels of background noise and speech interference. Our experiments show that 
    
[^32]: 可微非标定成像

    Differentiable Uncalibrated Imaging. (arXiv:2211.10525v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2211.10525](http://arxiv.org/abs/2211.10525)

    本文提出了一种可微的成像框架，以解决测量坐标的不确定性，通过隐式神经网络和可微分样条插值器实现。该方法应用于2D和3D计算机断层扫描，产生了改进的重建结果。

    This paper proposes a differentiable imaging framework to address uncertainty in measurement coordinates, using implicit neural networks and differentiable spline interpolators. The method is applied to 2D and 3D computed tomography and produces improved reconstructions.

    我们提出了一种可微成像框架，以解决测量坐标（如传感器位置和投影角度）的不确定性。我们将问题公式化为在未知节点处的测量插值，通过正向算子进行监督。为了解决这个问题，我们应用了隐式神经网络，也称为神经场，它们在输入坐标方面自然可微分。我们还开发了可微分样条插值器，其性能与神经网络一样好，需要更少的优化时间，并且具有良好的性质。可微性是关键，因为它允许我们共同拟合测量表示，优化不确定的测量坐标，并执行图像重建，从而确保一致的标定。我们将我们的方法应用于2D和3D计算机断层扫描，并展示了与不考虑缺乏标定的基线相比，它产生了改进的重建结果。所提出的框架的灵活性

    We propose a differentiable imaging framework to address uncertainty in measurement coordinates such as sensor locations and projection angles. We formulate the problem as measurement interpolation at unknown nodes supervised through the forward operator. To solve it we apply implicit neural networks, also known as neural fields, which are naturally differentiable with respect to the input coordinates. We also develop differentiable spline interpolators which perform as well as neural networks, require less time to optimize and have well-understood properties. Differentiability is key as it allows us to jointly fit a measurement representation, optimize over the uncertain measurement coordinates, and perform image reconstruction which in turn ensures consistent calibration. We apply our approach to 2D and 3D computed tomography and show that it produces improved reconstructions compared to baselines that do not account for the lack of calibration. The flexibility of the proposed framew
    
[^33]: 使用2D投影从3D MRI体积中高效预测脑龄

    Efficient brain age prediction from 3D MRI volumes using 2D projections. (arXiv:2211.05762v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2211.05762](http://arxiv.org/abs/2211.05762)

    本文提出了一种使用2D投影从3D MRI体积中高效预测脑龄的方法，相比于使用3D CNN，该方法在计算速度上有两个数量级的提升，对于没有3D CNN昂贵GPU硬件的研究人员非常有用。

    This paper proposes an efficient method for predicting brain age from 3D MRI volumes using 2D projections, which is two orders of magnitude faster than using 3D CNNs and is important for researchers without access to expensive GPU hardware.

    在高分辨率医学体积上使用3D CNN非常计算密集，特别是对于像英国生物库这样的大型数据集，该库旨在扫描10万个受试者。在这里，我们证明了使用2D CNN在3D体积的几个2D投影（代表轴向，矢状面和冠状面切片的平均值和标准差）上进行预测脑龄时，可以获得合理的测试准确性。使用我们的方法，使用单个GPU进行的一次训练时，20324个受试者需要20-50秒，比小型3D CNN快两个数量级。这些结果对于没有3D CNN昂贵GPU硬件的研究人员非常重要。

    Using 3D CNNs on high resolution medical volumes is very computationally demanding, especially for large datasets like the UK Biobank which aims to scan 100,000 subjects. Here we demonstrate that using 2D CNNs on a few 2D projections (representing mean and standard deviation across axial, sagittal and coronal slices) of the 3D volumes leads to reasonable test accuracy when predicting the age from brain volumes. Using our approach, one training epoch with 20,324 subjects takes 20 - 50 seconds using a single GPU, which two orders of magnitude faster compared to a small 3D CNN. These results are important for researchers who do not have access to expensive GPU hardware for 3D CNNs.
    
[^34]: 意外学习者：自监督多语言模型中的口语语言识别

    Accidental Learners: Spoken Language Identification in Multilingual Self-Supervised Models. (arXiv:2211.05103v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2211.05103](http://arxiv.org/abs/2211.05103)

    本文通过在多语言预训练范式中尝试Conformer架构，扩展了先前的自监督语言识别方法。预训练的语音模型在较低层中最优地编码了语言区分信息，从这些层获得的嵌入能够显著地稳健地分类未见过的语言和不同的声学环境。在对预训练的Conformer模型在VoxLingua107数据集上进行微调后，我们实现了与当前最先进的语言识别系统类似的结果，且使用的参数量仅为其它模型的五分之一。

    This paper extends previous self-supervised approaches for language identification by experimenting with Conformer based architecture in a multilingual pre-training paradigm. The pre-trained speech models optimally encode language discriminatory information in lower layers, and the embeddings obtained from these layers are significantly robust to classify unseen languages and different acoustic environments without additional training. After fine-tuning a pre-trained Conformer model on the VoxLingua107 dataset, the authors achieve results similar to current state-of-the-art systems for language identification, with 5x less parameters. The model is open-sourced through the NVIDIA NeMo toolkit.

    本文通过在多语言预训练范式中尝试Conformer架构，扩展了先前的自监督语言识别方法。我们发现，预训练的语音模型在较低层中最优地编码了语言区分信息。此外，我们证明了从这些层获得的嵌入在没有额外训练的情况下，能够显著地稳健地分类未见过的语言和不同的声学环境。在对预训练的Conformer模型在VoxLingua107数据集上进行微调后，我们实现了与当前最先进的语言识别系统类似的结果。此外，我们的模型使用的参数量仅为其它模型的五分之一。我们通过NVIDIA NeMo工具包开源了该模型。

    In this paper, we extend previous self-supervised approaches for language identification by experimenting with Conformer based architecture in a multilingual pre-training paradigm. We find that pre-trained speech models optimally encode language discriminatory information in lower layers. Further, we demonstrate that the embeddings obtained from these layers are significantly robust to classify unseen languages and different acoustic environments without additional training. After fine-tuning a pre-trained Conformer model on the VoxLingua107 dataset, we achieve results similar to current state-of-the-art systems for language identification. More, our model accomplishes this with 5x less parameters. We open-source the model through the NVIDIA NeMo toolkit.
    
[^35]: 基于参数化超复数神经网络的心房颤动检测的高效ECG方法

    Efficient ECG-based Atrial Fibrillation Detection via Parameterised Hypercomplex Neural Networks. (arXiv:2211.02678v2 [eess.SP] UPDATED)

    [http://arxiv.org/abs/2211.02678](http://arxiv.org/abs/2211.02678)

    本文提出了一种基于参数化超复数神经网络的轻量级卷积神经网络方法，用于心房颤动检测。该方法在可穿戴设备上训练小规模CNN，克服了有限的计算资源。在两个公开可用的ECG数据集上，该方法表现出与实值CNN相当的性能，但使用了显着较少的模型参数。

    This paper proposes a lightweight convolutional neural network method based on parameterized hypercomplex neural networks for atrial fibrillation detection. The method trains small-scale CNNs on wearable devices, overcoming limited computing resources. The approach shows comparable performance to real-valued CNNs on two publicly available ECG datasets using significantly fewer model parameters.

    心房颤动（AF）是最常见的心律失常，与中风等严重疾病的高风险相关。嵌入自动和及时的AF评估的可穿戴设备使用心电图（ECG）已被证明在预防危及生命的情况方面具有前景。虽然深度神经网络在模型性能方面表现出优越性，但它们在可穿戴设备上的使用受到模型性能和复杂性之间的权衡的限制。在这项工作中，我们提出使用带有参数化超复数（PH）层的轻量级卷积神经网络（CNN）来基于ECG进行AF检测。所提出的方法训练小规模CNN，从而克服了可穿戴设备上的有限计算资源。我们使用显着较少的模型参数在两个公开可用的ECG数据集上展示了与相应的实值CNN相当的性能。PH模型比其他超复数神经网络更灵活，可以在...

    Atrial fibrillation (AF) is the most common cardiac arrhythmia and associated with a high risk for serious conditions like stroke. The use of wearable devices embedded with automatic and timely AF assessment from electrocardiograms (ECGs) has shown to be promising in preventing life-threatening situations. Although deep neural networks have demonstrated superiority in model performance, their use on wearable devices is limited by the trade-off between model performance and complexity. In this work, we propose to use lightweight convolutional neural networks (CNNs) with parameterised hypercomplex (PH) layers for AF detection based on ECGs. The proposed approach trains small-scale CNNs, thus overcoming the limited computing resources on wearable devices. We show comparable performance to corresponding real-valued CNNs on two publicly available ECG datasets using significantly fewer model parameters. PH models are more flexible than other hypercomplex neural networks and can operate on an
    
[^36]: 基于SPD流形的图神经网络用于运动想象分类：来自时频分析的视角

    Graph Neural Networks on SPD Manifolds for Motor Imagery Classification: A Perspective from the Time-Frequency Analysis. (arXiv:2211.02641v2 [eess.SP] UPDATED)

    [http://arxiv.org/abs/2211.02641](http://arxiv.org/abs/2211.02641)

    本文介绍了一种基于SPD流形的图神经网络用于运动想象分类，利用EEG的二阶统计量，相比传统方法具有更好的性能。

    This paper introduces a graph neural network based on SPD manifolds for motor imagery classification, which utilizes second-order statistics of EEG signals and outperforms traditional methods.

    运动想象（MI）的分类是脑电图（EEG）基础脑机接口（BCI）领域中备受追捧的研究课题，具有巨大的商业价值。过去二十年，MI-EEG分类器的趋势发生了根本性的转变，其性能逐渐提高。 Tensor-CSPNet的出现是BCI研究中第一个几何深度学习（GDL）框架的必要性，其归因于信号的非欧几里德性质的特征化。从根本上讲，Tensor-CSPNet是一种基于深度学习的分类器，利用EEG的二阶统计量。与利用EEG信号的一阶统计量的传统方法相比，利用这些二阶统计量代表了经典的处理方法。这些统计量提供了足够的区分信息，使它们适用于MI-EEG分类。在本研究中，我们介绍了另一种GDL分类器，

    The classification of motor imagery (MI) is a highly sought-after research topic in the field of Electroencephalography (EEG)-based brain-computer interfaces (BCIs), with immense commercial value. Over the past two decades, there has been a fundamental shift in the trend of MI-EEG classifiers, resulting in a gradual increase in their performance. The emergence of Tensor-CSPNet, the first geometric deep learning (GDL) framework in BCI research, is attributed to the imperative of characterizing the non-Euclidean nature of signals. Fundamentally, Tensor-CSPNet is a deep learning-based classifier that capitalizes on the second-order statistics of EEGs. In contrast to the conventional approach of utilizing first-order statistics for EEG signals, the utilization of these second-order statistics represents the classical treatment. These statistics provide adequate discriminative information, rendering them suitable for MI-EEG classification. In this study, we introduce another GDL classifier,
    
[^37]: 去除噪音：心理声学和基于包络的特征在机械故障检测中的实证比较

    Cutting Through the Noise: An Empirical Comparison of Psychoacoustic and Envelope-based Features for Machinery Fault Detection. (arXiv:2211.01704v2 [eess.SP] UPDATED)

    [http://arxiv.org/abs/2211.01704](http://arxiv.org/abs/2211.01704)

    本文提出了一个自动化和噪声鲁棒的听觉检查系统，用于检测机械部件的健康状况。我们提供了一个基准来比较不同类型的包络特征与心理声学特征。我们是第一个应用时变心理声学特征进行故障检测的人。

    This paper presents an automated and noise-robust auditory inspection system for detecting the health condition of mechanical parts. A benchmark is provided to compare different types of envelope features with psychoacoustic features. The authors are the first to apply time-varying psychoacoustic features for fault detection.

    基于声学的故障检测具有监测机械部件健康状况的高潜力。然而，工业环境的背景噪音可能会对故障检测的性能产生负面影响。目前对于提高故障检测对工业环境噪声的鲁棒性的关注有限。因此，我们提出了Lenze生产背景噪声（LPBN）真实世界数据集和用于齿轮电机末端检查的自动化和噪声鲁棒的听觉检查（ARAI）系统。采用声学阵列从具有轻微故障、重大故障或健康的电机中获取数据。提供了一个基准来比较基于专家对齿轮箱的知识的不同类型的包络特征与心理声学特征。据我们所知，我们是第一个应用时变心理声学特征进行故障检测的人。我们训练了一种最先进的单类分类器，使用来自健康电机的样本进行训练。

    Acoustic-based fault detection has a high potential to monitor the health condition of mechanical parts. However, the background noise of an industrial environment may negatively influence the performance of fault detection. Limited attention has been paid to improving the robustness of fault detection against industrial environmental noise. Therefore, we present the Lenze production background-noise (LPBN) real-world dataset and an automated and noise-robust auditory inspection (ARAI) system for the end-of-line inspection of geared motors. An acoustic array is used to acquire data from motors with a minor fault, major fault, or which are healthy. A benchmark is provided to compare the psychoacoustic features with different types of envelope features based on expert knowledge of the gearbox. To the best of our knowledge, we are the first to apply time-varying psychoacoustic features for fault detection. We train a state-of-the-art one-class-classifier, on samples from healthy motors an
    
[^38]: WiserVR：语义通信支持的无线虚拟现实传输

    WiserVR: Semantic Communication Enabled Wireless Virtual Reality Delivery. (arXiv:2211.01241v4 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2211.01241](http://arxiv.org/abs/2211.01241)

    WiserVR提出了一种新的框架，利用语义通信和深度学习技术，实现了高效的无线虚拟现实传输，其中包括语义位置图和联合语义通道编码方法。

    WiserVR proposes a novel framework that utilizes semantic communication and deep learning techniques to achieve efficient wireless virtual reality delivery, including semantic location graph and joint-semantic-channel-coding method with knowledge sharing.

    无线虚拟现实被认为是下一代通信网络中的杀手级应用之一。然而，在有限的带宽资源下，巨大的数据量以及对延迟和可靠性的严格要求使得无线VR传输变得越来越具有挑战性。这些瓶颈促使本文探索使用语义通信的潜力，这是一种新的范式，可以显著缓解资源压力，以实现高效的VR传输。为此，我们提出了一种新的框架，即WiserVR（WIreless SEmantic deliveRy for VR），用于向VR用户传递连续的360度视频帧。具体而言，我们设计了基于深度学习的多个模块，用于WiserVR中的收发器，以实现高性能的特征提取和语义恢复。其中，我们专门开发了语义位置图的概念，并利用知识共享的联合语义通道编码方法。

    Virtual reality (VR) over wireless is expected to be one of the killer applications in next-generation communication networks. Nevertheless, the huge data volume along with stringent requirements on latency and reliability under limited bandwidth resources makes untethered wireless VR delivery increasingly challenging. Such bottlenecks, therefore, motivate this work to seek the potential of using semantic communication, a new paradigm that promises to significantly ease the resource pressure, for efficient VR delivery. To this end, we propose a novel framework, namely WIreless SEmantic deliveRy for VR (WiserVR), for delivering consecutive 360{\deg} video frames to VR users. Specifically, deep learning-based multiple modules are well-devised for the transceiver in WiserVR to realize high-performance feature extraction and semantic recovery. Among them, we dedicatedly develop a concept of semantic location graph and leverage the joint-semantic-channel-coding method with knowledge sharing
    
[^39]: 利用元数据和对比学习学习音频特征

    Learning Audio Features with Metadata and Contrastive Learning. (arXiv:2210.16192v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2210.16192](http://arxiv.org/abs/2210.16192)

    本研究使用监督对比学习结合可用元数据解决多个前置任务，学习数据的良好表示。在呼吸音分类数据集上，仅使用元数据学习表示可以获得与仅使用类标签的交叉熵相似的性能。在使用多个监督对比学习将类标签与元数据相结合时，获得了最先进的得分。

    This study uses supervised contrastive learning combined with available metadata to solve multiple pretext tasks that learn a good representation of data. Learning representations using only metadata obtains similar performance as using cross entropy with class labels only. State-of-the-art score is obtained when combining class labels with metadata using multiple supervised contrastive learning.

    基于注释的监督学习方法一直是分类问题的最先进技术，但是在低数据情况下，它们的泛化能力可能受到限制。本研究使用监督对比学习结合可用元数据解决多个前置任务，学习数据的良好表示。我们将我们的方法应用于ICBHI，这是一个适合这种情况的呼吸音分类数据集。我们表明，仅使用元数据学习表示，而不使用类标签，可以获得与仅使用这些标签的交叉熵相似的性能。此外，我们使用多个监督对比学习将类标签与元数据相结合时，获得了最先进的得分。这项工作表明，在监督对比设置中使用多个元数据源的潜力，特别是在类不平衡和少量数据的情况下。我们的代码已发布。

    Methods based on supervised learning using annotations in an end-to-end fashion have been the state-of-the-art for classification problems. However, they may be limited in their generalization capability, especially in the low data regime. In this study, we address this issue using supervised contrastive learning combined with available metadata to solve multiple pretext tasks that learn a good representation of data. We apply our approach on ICBHI, a respiratory sound classification dataset suited for this setting. We show that learning representations using only metadata, without class labels, obtains similar performance as using cross entropy with those labels only. In addition, we obtain state-of-the-art score when combining class labels with metadata using multiple supervised contrastive learning. This work suggests the potential of using multiple metadata sources in supervised contrastive settings, in particular in settings with class imbalance and few data. Our code is released 
    
[^40]: Articulation GAN: 无监督建模关节学习

    Articulation GAN: Unsupervised modeling of articulatory learning. (arXiv:2210.15173v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2210.15173](http://arxiv.org/abs/2210.15173)

    本文提出了一种新的无监督生成模型，通过完全无监督的方式学习生成关节表示（电磁关节成像或EMA），更接近于人类语音产生的方式，从而更好地模拟人类语音产生的过程。

    This paper proposes a new unsupervised generative model that learns to generate articulatory representations (electromagnetic articulography or EMA) in a fully unsupervised manner, which more closely mimics human speech production and better simulates the process of human speech production.

    生成式深度神经网络广泛用于语音合成，但大多数现有模型直接生成波形或频谱输出。然而，人类通过控制关节来产生语音，这通过声音传播的物理特性导致语音声音的产生。我们引入了关节生成器到生成对抗网络范例中，这是一种新的无监督生成模型，用于语音产生/合成。关节生成器通过完全无监督的方式学习生成关节表示（电磁关节成像或EMA），更接近于人类语音产生的方式。然后，一个单独的预训练物理模型（ema2wav）将生成的EMA表示转换为语音波形，这些波形被发送到鉴别器进行评估。关节分析表明，网络学习控制关节的方式类似于人类在语音产生过程中的方式。输出的声学分析表明...

    Generative deep neural networks are widely used for speech synthesis, but most existing models directly generate waveforms or spectral outputs. Humans, however, produce speech by controlling articulators, which results in the production of speech sounds through physical properties of sound propagation. We introduce the Articulatory Generator to the Generative Adversarial Network paradigm, a new unsupervised generative model of speech production/synthesis. The Articulatory Generator more closely mimics human speech production by learning to generate articulatory representations (electromagnetic articulography or EMA) in a fully unsupervised manner. A separate pre-trained physical model (ema2wav) then transforms the generated EMA representations to speech waveforms, which get sent to the Discriminator for evaluation. Articulatory analysis suggests that the network learns to control articulators in a similar manner to humans during speech production. Acoustic analysis of the outputs sugge
    
[^41]: 回放：迭代注意力用于音频识别

    Play It Back: Iterative Attention for Audio Recognition. (arXiv:2210.11328v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2210.11328](http://arxiv.org/abs/2210.11328)

    该论文提出了一种基于注意力的架构，通过选择性重复跨越音频序列的最具区分性的声音来进行关注，最终实现了在三个音频分类基准测试中始终实现最先进的性能。

    The paper proposes an end-to-end attention-based architecture that attends over the most discriminative sounds across the audio sequence through selective repetition, achieving consistently state-of-the-art performance across three audio-classification benchmarks.

    听觉认知的一个关键功能是随着时间的推移将特征声音与其相应的语义关联起来。人类试图区分细粒度音频类别时，通常会重播相同的区分性声音以增加其预测置信度。我们提出了一种端到端的基于注意力的架构，通过选择性重复跨越音频序列的最具区分性的声音来进行关注。我们的模型最初使用完整的音频序列，并通过插槽注意力迭代地细化重播的时间段。在每次播放时，所选段使用较小的跳跃长度重播，这代表了这些段内更高分辨率的特征。我们展示了我们的方法可以在三个音频分类基准测试中始终实现最先进的性能：AudioSet、VGG-Sound和EPIC-KITCHENS-100。

    A key function of auditory cognition is the association of characteristic sounds with their corresponding semantics over time. Humans attempting to discriminate between fine-grained audio categories, often replay the same discriminative sounds to increase their prediction confidence. We propose an end-to-end attention-based architecture that through selective repetition attends over the most discriminative sounds across the audio sequence. Our model initially uses the full audio sequence and iteratively refines the temporal segments replayed based on slot attention. At each playback, the selected segments are replayed using a smaller hop length which represents higher resolution features within these segments. We show that our method can consistently achieve state-of-the-art performance across three audio-classification benchmarks: AudioSet, VGG-Sound, and EPIC-KITCHENS-100.
    
[^42]: PSVRF: 无参考学习还原变调语音

    PSVRF: Learning to restore Pitch-Shifted Voice without reference. (arXiv:2210.02731v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2210.02731](http://arxiv.org/abs/2210.02731)

    本文提出了一种无参考方法PSVRF，用于高质量还原变调语音，可以增强ASV系统对音高缩放攻击的鲁棒性，性能甚至超过了最先进的基于参考的方法。

    This paper proposes a no-reference approach called PSVRF for high-quality restoration of pitch-shifted voice, which enhances the robustness of ASV systems to pitch-scaling attacks and even outperforms the state-of-the-art reference-based approach.

    音高缩放算法对自动说话人验证（ASV）系统的安全性有重要影响。虽然已经提出了许多反欺骗算法来识别变调语音并将其恢复到原始版本，但它们要么性能较差，要么需要原始语音作为参考，限制了应用前景。本文提出了一种无参考方法PSVRF，用于高质量还原变调语音。在AISHELL-1和AISHELL-3上的实验表明，PSVRF可以恢复被各种音高缩放技术伪装的语音，显然增强了ASV系统对音高缩放攻击的鲁棒性。此外，PSVRF的性能甚至超过了最先进的基于参考的方法。

    Pitch scaling algorithms have a significant impact on the security of Automatic Speaker Verification (ASV) systems. Although numerous anti-spoofing algorithms have been proposed to identify the pitch-shifted voice and even restore it to the original version, they either have poor performance or require the original voice as a reference, limiting the prospects of applications. In this paper, we propose a no-reference approach termed PSVRF$^1$ for high-quality restoration of pitch-shifted voice. Experiments on AISHELL-1 and AISHELL-3 demonstrate that PSVRF can restore the voice disguised by various pitch-scaling techniques, which obviously enhances the robustness of ASV systems to pitch-scaling attacks. Furthermore, the performance of PSVRF even surpasses that of the state-of-the-art reference-based approach.
    
[^43]: 开放式联邦学习系统的稳定性分析

    On the Stability Analysis of Open Federated Learning Systems. (arXiv:2209.12307v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.12307](http://arxiv.org/abs/2209.12307)

    本文研究了开放式联邦学习系统的稳定性问题，提出了一种新的性能度量，即开放式FL系统的稳定性，并在假设本地客户端函数是强凸和平滑的情况下，理论上量化了两种FL算法的稳定半径。

    This paper studies the stability issue of open federated learning systems, proposes a new performance metric, namely the stability of open FL systems, and theoretically quantifies the stability radius of two FL algorithms under the assumption that local clients' functions are strongly convex and smooth.

    我们考虑开放式联邦学习系统，其中客户端可能在联邦学习过程中加入和/或离开系统。由于存在客户端数量的变化，无法保证在开放系统中收敛到固定模型。因此，我们采用一种新的性能度量，称为开放式FL系统的稳定性，它量化了在开放系统中学习模型的大小。在假设本地客户端函数是强凸和平滑的情况下，我们理论上量化了两种FL算法（即本地SGD和本地Adam）的稳定半径。我们观察到，这个半径依赖于几个关键参数，包括函数条件数以及随机梯度的方差。我们的理论结果在合成和真实世界基准数据集上通过数值模拟进一步验证。

    We consider the open federated learning (FL) systems, where clients may join and/or leave the system during the FL process. Given the variability of the number of present clients, convergence to a fixed model cannot be guaranteed in open systems. Instead, we resort to a new performance metric that we term the stability of open FL systems, which quantifies the magnitude of the learned model in open systems. Under the assumption that local clients' functions are strongly convex and smooth, we theoretically quantify the radius of stability for two FL algorithms, namely local SGD and local Adam. We observe that this radius relies on several key parameters, including the function condition number as well as the variance of the stochastic gradient. Our theoretical results are further verified by numerical simulations on both synthetic and real-world benchmark data-sets.
    
[^44]: U-Sleep对AASM指南的弹性

    U-Sleep's resilience to AASM guidelines. (arXiv:2209.11173v3 [eess.SP] UPDATED)

    [http://arxiv.org/abs/2209.11173](http://arxiv.org/abs/2209.11173)

    本研究表明，基于深度学习的U-Sleep睡眠评分算法可以弹性地使用非推荐或非传统的导联，而不需要严格遵守AASM指南。

    This study shows that the deep learning-based U-Sleep sleep scoring algorithm can flexibly use non-recommended or non-traditional derivations without strictly adhering to AASM guidelines.

    AASM指南是几十年努力的结果，旨在标准化睡眠评分程序，最终目标是共享全球通用的方法。该指南涵盖了从技术/数字规范（例如，推荐的EEG导联）到根据年龄详细的睡眠评分规则的几个方面。自动睡眠评分系统始终将标准作为基本指南。在这种情况下，深度学习表现出比传统机器学习更好的性能。我们的研究表明，基于深度学习的睡眠评分算法可能不需要充分利用临床知识或严格遵守AASM指南。具体而言，我们证明了U-Sleep，一种最先进的睡眠评分算法，即使使用临床非推荐或非传统的导联，也可以足够强大地解决评分任务，而且不需要利用有关受试者年龄的信息。

    AASM guidelines are the result of decades of efforts aiming at standardizing sleep scoring procedure, with the final goal of sharing a worldwide common methodology. The guidelines cover several aspects from the technical/digital specifications,e.g., recommended EEG derivations, to detailed sleep scoring rules accordingly to age. Automated sleep scoring systems have always largely exploited the standards as fundamental guidelines. In this context, deep learning has demonstrated better performance compared to classical machine learning. Our present work shows that a deep learning based sleep scoring algorithm may not need to fully exploit the clinical knowledge or to strictly adhere to the AASM guidelines. Specifically, we demonstrate that U-Sleep, a state-of-the-art sleep scoring algorithm, can be strong enough to solve the scoring task even using clinically non-recommended or non-conventional derivations, and with no need to exploit information about the chronological age of the subjec
    
[^45]: 学习ASR路径：一种稀疏的多语言ASR模型

    Learning ASR pathways: A sparse multilingual ASR model. (arXiv:2209.05735v3 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2209.05735](http://arxiv.org/abs/2209.05735)

    本文提出了一种稀疏的多语言ASR模型，通过激活语言特定的子网络来显式地学习每种语言的参数，同时通过联合多语言训练实现对低资源语言的知识转移，相比于密集模型和语言不可知的剪枝模型，在低资源语言上提供更好的性能。

    This paper proposes a sparse multilingual ASR model, which explicitly learns the parameters for each language by activating language-specific sub-networks, and enables knowledge transfer for lower-resource languages via joint multilingual training. The proposed ASR pathways outperform both dense models and a language-agnostically pruned model, and provide better performance on low-resource languages compared to the monolingual sparse models.

    神经网络剪枝有效地压缩了自动语音识别（ASR）模型。然而，在多语言ASR中，语言不可知的剪枝可能会导致某些语言的性能严重下降，因为语言不可知的剪枝掩码可能不适合所有语言并且丢弃重要的语言特定参数。在这项工作中，我们提出了ASR路径，一种稀疏的多语言ASR模型，它激活语言特定的子网络（“路径”），以便为每种语言显式地学习参数。通过重叠的子网络，共享参数还可以通过联合多语言训练实现对低资源语言的知识转移。我们提出了一种新算法来学习ASR路径，并使用流式RNN-T模型在4种语言上评估了所提出的方法。我们提出的ASR路径模型优于密集模型和语言不可知的剪枝模型，并且与单语稀疏模型相比，在低资源语言上提供更好的性能。

    Neural network pruning compresses automatic speech recognition (ASR) models effectively. However, in multilingual ASR, language-agnostic pruning may lead to severe performance drops on some languages because language-agnostic pruning masks may not fit all languages and discard important language-specific parameters. In this work, we present ASR pathways, a sparse multilingual ASR model that activates language-specific sub-networks ("pathways"), such that the parameters for each language are learned explicitly. With the overlapping sub-networks, the shared parameters can also enable knowledge transfer for lower-resource languages via joint multilingual training. We propose a novel algorithm to learn ASR pathways, and evaluate the proposed method on 4 languages with a streaming RNN-T model. Our proposed ASR pathways outperform both dense models and a language-agnostically pruned model, and provide better performance on low-resource languages compared to the monolingual sparse models.
    
[^46]: Uconv-Conformer: 针对端到端语音识别的输入序列长度大幅缩减的新型架构

    Uconv-Conformer: High Reduction of Input Sequence Length for End-to-End Speech Recognition. (arXiv:2208.07657v3 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2208.07657](http://arxiv.org/abs/2208.07657)

    本文提出了一种新型Uconv-Conformer架构，可以将输入序列长度缩短16倍，加速中间层的工作，同时通过使用上采样块解决了收敛问题，表现出更好的WER和更快的训练和推理速度。

    The paper proposes a new Uconv-Conformer architecture that reduces the input sequence length by 16 times, speeds up the work of intermediate layers, and solves the convergence issue by using upsampling blocks. The Uconv-Conformer architecture shows better WER and faster training and inference speed.

    优化现代ASR架构是最高优先级的任务之一，因为它可以节省模型训练和推理的许多计算资源。本文提出了一种基于标准Conformer模型的新型Uconv-Conformer架构。它通过16倍的一致性缩短输入序列长度，从而加速了中间层的工作。为了解决与时间维度大幅缩减相关的收敛问题，我们使用了像U-Net架构中的上采样块来确保正确的CTC损失计算和稳定网络训练。Uconv-Conformer架构不仅在训练和推理速度方面更快，而且与基线Conformer相比，表现出更好的WER。我们最好的Uconv-Conformer模型在CPU和GPU上分别显示出47.8％和23.5％的推理加速。相对WER的减少分别为7.3％和9.2％。

    Optimization of modern ASR architectures is among the highest priority tasks since it saves many computational resources for model training and inference. The work proposes a new Uconv-Conformer architecture based on the standard Conformer model. It consistently reduces the input sequence length by 16 times, which results in speeding up the work of the intermediate layers. To solve the convergence issue connected with such a significant reduction of the time dimension, we use upsampling blocks like in the U-Net architecture to ensure the correct CTC loss calculation and stabilize network training. The Uconv-Conformer architecture appears to be not only faster in terms of training and inference speed but also shows better WER compared to the baseline Conformer. Our best Uconv-Conformer model shows 47.8% and 23.5% inference acceleration on the CPU and GPU, respectively. Relative WER reduction is 7.3% and 9.2% on LibriSpeech test_clean and test_other respectively.
    
[^47]: DailyTalk：面向对话文本转语音的口语对话数据集

    DailyTalk: Spoken Dialogue Dataset for Conversational Text-to-Speech. (arXiv:2207.01063v3 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2207.01063](http://arxiv.org/abs/2207.01063)

    本文介绍了一个高质量的对话语音数据集DailyTalk，专门为对话TTS设计。DailyTalk可以用作通用的TTS数据集，而且基线可以表示DailyTalk的上下文信息。

    This paper introduces a high-quality conversational speech dataset DailyTalk designed for conversational TTS. DailyTalk can be used as a general TTS dataset, and the baseline can represent contextual information from DailyTalk.

    目前大多数的文本转语音（TTS）数据集都是由单个话语组成，缺乏对话方面的内容。本文介绍了DailyTalk，这是一个高质量的对话语音数据集，专门为对话TTS设计。我们从开放领域对话数据集DailyDialog中抽样、修改和录制了2,541个对话，并继承了其注释属性。在我们的数据集上，我们扩展了之前的工作作为我们的基线，其中一个非自回归TTS在对话中的历史信息的条件下进行。通过基线实验和我们的新颖度量标准，我们展示了DailyTalk可以用作通用的TTS数据集，而且我们的基线可以表示DailyTalk的上下文信息。DailyTalk数据集和基线代码可供学术用途免费使用，采用CC-BY-SA 4.0许可证。

    The majority of current Text-to-Speech (TTS) datasets, which are collections of individual utterances, contain few conversational aspects. In this paper, we introduce DailyTalk, a high-quality conversational speech dataset designed for conversational TTS. We sampled, modified, and recorded 2,541 dialogues from the open-domain dialogue dataset DailyDialog inheriting its annotated attributes. On top of our dataset, we extend prior work as our baseline, where a non-autoregressive TTS is conditioned on historical information in a dialogue. From the baseline experiment with both general and our novel metrics, we show that DailyTalk can be used as a general TTS dataset, and more than that, our baseline can represent contextual information from DailyTalk. The DailyTalk dataset and baseline code are freely available for academic use with CC-BY-SA 4.0 license.
    
[^48]: 基于解剖感知对比蒸馏的半监督医学图像分割引导启动

    Bootstrapping Semi-supervised Medical Image Segmentation with Anatomical-aware Contrastive Distillation. (arXiv:2206.02307v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.02307](http://arxiv.org/abs/2206.02307)

    本文提出了一种基于解剖感知对比蒸馏的半监督医学图像分割引导启动方法，通过软标记负样本和捕获更多语义上相似的特征来解决医学图像数据不平衡的问题。

    This paper proposes a semi-supervised medical image segmentation bootstrapping method based on anatomical-aware contrastive distillation, which solves the problem of imbalanced medical image data by softly labeling negative samples and capturing more semantically similar features.

    对比学习已经在医学图像分割的注释稀缺问题上显示出了巨大的潜力。现有的方法通常假设标记和未标记的医学图像具有平衡的类分布。然而，现实中的医学图像数据通常是不平衡的（即多类标签不平衡），这自然地产生模糊的轮廓并通常错误地标记罕见的对象。此外，所有负样本是否同样负面仍不清楚。在这项工作中，我们提出了ACTION，一种解剖感知对比蒸馏框架，用于半监督医学图像分割。具体而言，我们首先通过软标记负样本而不是正负对之间的二元监督来开发迭代对比蒸馏算法。与正样本相比，我们还从随机选择的负样本集中捕获更多语义上相似的特征，以强制执行采样数据的多样性。其次，我们提出了一种基于解剖感知的启动方法，以更好地利用有限的标记数据。

    Contrastive learning has shown great promise over annotation scarcity problems in the context of medical image segmentation. Existing approaches typically assume a balanced class distribution for both labeled and unlabeled medical images. However, medical image data in reality is commonly imbalanced (i.e., multi-class label imbalance), which naturally yields blurry contours and usually incorrectly labels rare objects. Moreover, it remains unclear whether all negative samples are equally negative. In this work, we present ACTION, an Anatomical-aware ConTrastive dIstillatiON framework, for semi-supervised medical image segmentation. Specifically, we first develop an iterative contrastive distillation algorithm by softly labeling the negatives rather than binary supervision between positive and negative pairs. We also capture more semantically similar features from the randomly chosen negative set compared to the positives to enforce the diversity of the sampled data. Second, we raise a m
    
[^49]: DynLight: 多级交通信号控制实现动态相位时长

    DynLight: Realize dynamic phase duration with multi-level traffic signal control. (arXiv:2204.03471v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2204.03471](http://arxiv.org/abs/2204.03471)

    本文已被撤回，原因是语言和理论描述不够令人满意，作者已经进行了修订和更新。

    The article has been withdrawn due to unsatisfactory language and theoretical description, and the authors have revised and updated it.

    我们因以下原因撤回本文：1.本文的语言和理论描述不够令人满意；2.我们在其他作者的帮助下丰富和修订了本文；3.我们必须更新作者贡献信息。

    We would like to withdraw this article for the following reasons: 1 this article is not satisfactory for limited language and theoretical description; 2 we have enriched and revised this article with the help of other authors; 3 we must update the author contribution information.
    
[^50]: 日语ASR中基于音节和字符目标的交替中间条件

    Alternate Intermediate Conditioning with Syllable-level and Character-level Targets for Japanese ASR. (arXiv:2204.00175v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2204.00175](http://arxiv.org/abs/2204.00175)

    该论文提出了一种基于音节和字符目标的交替中间条件方法，利用字符级和音节级中间预测作为条件特征来处理日语ASR中的多对一和一对多的映射问题，并在实验中取得了优异的表现。

    This paper proposes an alternate intermediate conditioning method with syllable-level and character-level targets to deal with the many-to-one and one-to-many mapping problems in Japanese ASR, and achieves better performance than conventional multi-task and Self-conditioned CTC methods in experiments.

    端到端的自动语音识别直接将输入语音映射到字符。然而，当多个不同的发音应该映射到一个字符或一个发音被多个不同的字符共享时，映射可能会出现问题。由于日语汉字的存在，日语ASR最容易遭受这种多对一和一对多的映射问题。为了缓解这些问题，我们引入了字符和音节之间的显式交互，使用自我条件连接主义时间分类（CTC），其中上层“自我条件”于下层的中间预测。所提出的方法利用字符级和音节级中间预测作为条件特征来处理字符和音节之间的相互依赖关系。在自发日语语料库上的实验结果表明，所提出的方法优于传统的多任务和自我条件CTC方法。

    End-to-end automatic speech recognition directly maps input speech to characters. However, the mapping can be problematic when several different pronunciations should be mapped into one character or when one pronunciation is shared among many different characters. Japanese ASR suffers the most from such many-to-one and one-to-many mapping problems due to Japanese kanji characters. To alleviate the problems, we introduce explicit interaction between characters and syllables using Self-conditioned connectionist temporal classification (CTC), in which the upper layers are ``self-conditioned'' on the intermediate predictions from the lower layers. The proposed method utilizes character-level and syllable-level intermediate predictions as conditioning features to deal with mutual dependency between characters and syllables. Experimental results on Corpus of Spontaneous Japanese show that the proposed method outperformed the conventional multi-task and Self-conditioned CTC methods.
    
[^51]: 学习四足动物运动的扭矩控制

    Learning Torque Control for Quadrupedal Locomotion. (arXiv:2203.05194v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2203.05194](http://arxiv.org/abs/2203.05194)

    本文提出了一种基于扭矩的强化学习框架，直接预测关节扭矩，避免使用PD控制器，通过广泛的实验验证，四足动物能够穿越各种地形并抵抗外部干扰，同时保持运动。

    This paper proposes a torque-based reinforcement learning framework that directly predicts joint torques, avoiding the use of a PD controller. The framework is validated through extensive experiments, where a quadruped is capable of traversing various terrain and resisting external disturbances while maintaining locomotion.

    强化学习已成为开发四足机器人控制器的一种有前途的方法。传统上，用于运动的RL设计遵循基于位置的范例，其中RL策略以低频率输出目标关节位置，然后由高频比例-导数（PD）控制器跟踪以产生关节扭矩。相比之下，对于四足动物运动的基于模型的控制，已经从基于位置的控制范例转向基于扭矩的控制。鉴于基于模型的控制的最新进展，我们通过引入基于扭矩的RL框架，探索了一种替代基于位置的RL范例的方法，其中RL策略直接在高频率下预测关节扭矩，从而避免使用PD控制器。所提出的学习扭矩控制框架通过广泛的实验进行了验证，在这些实验中，四足动物能够穿越各种地形并抵抗外部干扰，同时保持运动。

    Reinforcement learning (RL) has become a promising approach to developing controllers for quadrupedal robots. Conventionally, an RL design for locomotion follows a position-based paradigm, wherein an RL policy outputs target joint positions at a low frequency that are then tracked by a high-frequency proportional-derivative (PD) controller to produce joint torques. In contrast, for the model-based control of quadrupedal locomotion, there has been a paradigm shift from position-based control to torque-based control. In light of the recent advances in model-based control, we explore an alternative to the position-based RL paradigm, by introducing a torque-based RL framework, where an RL policy directly predicts joint torques at a high frequency, thus circumventing the use of a PD controller. The proposed learning torque control framework is validated with extensive experiments, in which a quadruped is capable of traversing various terrain and resisting external disturbances while followi
    
[^52]: FLSys：面向联邦学习移动应用的开放生态系统

    FLSys: Toward an Open Ecosystem for Federated Learning Mobile Apps. (arXiv:2111.09445v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2111.09445](http://arxiv.org/abs/2111.09445)

    本文介绍了FLSys，一个移动-云联邦学习（FL）系统，可以成为FL模型和应用程序开放生态系统的关键组成部分。FLSys旨在在智能手机上使用移动感测数据。它平衡了模型性能和资源消耗，容忍通信故障，并实现了可扩展性。FLSys提供了先进的隐私保护机制和一个通用的API，供第三方应用程序开发人员访问FL模型。

    This article introduces FLSys, a mobile-cloud federated learning (FL) system that can be a key component for an open ecosystem of FL models and apps. FLSys is designed to work on smart phones with mobile sensing data. It balances model performance with resource consumption, tolerates communication failures, and achieves scalability. FLSys provides advanced privacy preserving mechanisms and a common API for third-party app developers to access FL models.

    本文介绍了FLSys的设计、实现和评估，这是一个移动-云联邦学习（FL）系统，可以成为FL模型和应用程序开放生态系统的关键组成部分。FLSys旨在在智能手机上使用移动感测数据。它平衡了模型性能和资源消耗，容忍通信故障，并实现了可扩展性。在FLSys中，不同的DL模型和不同的FL聚合方法可以同时被不同的应用程序训练和访问。此外，FLSys提供了先进的隐私保护机制和一个通用的API，供第三方应用程序开发人员访问FL模型。FLSys采用模块化设计，实现在Android和AWS云中。我们与人类活动识别（HAR）模型共同设计了FLSys。在4个月的时间里，从100多名大学生中收集了HAR感测数据。我们实现了HAR-Wild，这是一个针对移动设备量身定制的CNN模型，具有数据增强机制以减轻p

    This article presents the design, implementation, and evaluation of FLSys, a mobile-cloud federated learning (FL) system, which can be a key component for an open ecosystem of FL models and apps. FLSys is designed to work on smart phones with mobile sensing data. It balances model performance with resource consumption, tolerates communication failures, and achieves scalability. In FLSys, different DL models with different FL aggregation methods can be trained and accessed concurrently by different apps. Furthermore, FLSys provides advanced privacy preserving mechanisms and a common API for third-party app developers to access FL models. FLSys adopts a modular design and is implemented in Android and AWS cloud. We co-designed FLSys with a human activity recognition (HAR) model. HAR sensing data was collected in the wild from 100+ college students during a 4-month period. We implemented HAR-Wild, a CNN model tailored to mobile devices, with a data augmentation mechanism to mitigate the p
    
[^53]: 从嘈杂的数据中进行数据驱动的可达性分析

    Data-Driven Reachability Analysis from Noisy Data. (arXiv:2105.07229v3 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2105.07229](http://arxiv.org/abs/2105.07229)

    本文提出了一种从嘈杂的数据中计算可达集的算法，适用于不同类型的系统，包括线性、多项式和非线性系统。算法基于矩阵zonotope，可以提供较少保守的可达集，并且可以将关于未知系统模型的先前知识纳入计算。算法具有理论保证，并在多个数值示例和实际实验中得到了验证。

    This paper proposes an algorithm for computing reachable sets directly from noisy data without a given system model, which is applicable to different types of systems including linear, polynomial, and nonlinear systems. The algorithm is based on matrix zonotopes and can provide less conservative reachable sets while incorporating prior knowledge about the unknown system model. Theoretical guarantees are given and the applicability of the algorithm is demonstrated through numerical examples and real experiments.

    我们考虑在没有给定系统模型的情况下直接从嘈杂的数据中计算可达集的问题。我们提出了几种适用于生成数据的不同类型系统的可达性算法。首先，我们提出了一种基于矩阵zonotope的算法，用于计算线性系统的过估计可达集。引入了约束矩阵zonotope以提供较少保守的可达集，但代价是增加计算开销，并用于将关于未知系统模型的先前知识纳入计算。然后，我们将这种方法扩展到多项式系统，并在Lipschitz连续性的假设下扩展到非线性系统。这些算法的理论保证是它们给出一个包含真实可达集的适当过估计可达集。多个数值示例和实际实验显示了引入算法的适用性，并进行了算法之间的比较。

    We consider the problem of computing reachable sets directly from noisy data without a given system model. Several reachability algorithms are presented for different types of systems generating the data. First, an algorithm for computing over-approximated reachable sets based on matrix zonotopes is proposed for linear systems. Constrained matrix zonotopes are introduced to provide less conservative reachable sets at the cost of increased computational expenses and utilized to incorporate prior knowledge about the unknown system model. Then we extend the approach to polynomial systems and, under the assumption of Lipschitz continuity, to nonlinear systems. Theoretical guarantees are given for these algorithms in that they give a proper over-approximate reachable set containing the true reachable set. Multiple numerical examples and real experiments show the applicability of the introduced algorithms, and comparisons are made between algorithms.
    

