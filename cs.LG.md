# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Learning Intersections of Halfspaces with Distribution Shift: Improved Algorithms and SQ Lower Bounds](https://arxiv.org/abs/2404.02364) | 研究学习与分布偏移的交集问题，在基于高斯训练分布的情况下，证明了一系列新的上界，包括一种TDS学习$k$个齐次半空间交集达到精度$\epsilon$的$2^{(k/\epsilon)^{O(1)}} \mathsf{poly}(d)$时间算法（在先前的工作中）。 |
| [^2] | [Ship in Sight: Diffusion Models for Ship-Image Super Resolution](https://arxiv.org/abs/2403.18370) | 该研究探索了船只图像超分辨率问题，提出了一种基于扩散模型的架构，利用文本条件在训练期间，并在类别感知的情况下，以最佳方式保存船只的关键细节。 |
| [^3] | [Adversarial Attacks and Defenses in Automated Control Systems: A Comprehensive Benchmark](https://arxiv.org/abs/2403.13502) | 该研究通过评估在自动控制系统中部署的深度学习模型对抗性攻击的脆弱性和不同防御策略的有效性，提出了结合多种防御方法的新颖保护方法，并为确保工业中的稳健故障诊断提供了见解。 |
| [^4] | [AdaptSFL: Adaptive Split Federated Learning in Resource-constrained Edge Networks](https://arxiv.org/abs/2403.13101) | 提出了AdaptSFL自适应分割联邦学习框架，以加速资源受限边缘系统中的学习性能。 |
| [^5] | [An Aligning and Training Framework for Multimodal Recommendations](https://arxiv.org/abs/2403.12384) | 提出了一种名为AlignRec的对齐和训练框架，用于解决多模态推荐中的不对齐问题，通过将推荐目标分解为三个对齐部分，实现内容内部对齐、内容与分类ID之间的对齐以及用户和项目之间的对齐。 |
| [^6] | [Skipformer: A Skip-and-Recover Strategy for Efficient Speech Recognition](https://arxiv.org/abs/2403.08258) | Skipformer提出了一种“跳过和恢复”的Conformer架构，可以动态、不均匀地压缩序列输入长度，大大减少了计算预算和内存消耗，并获得更好的识别准确性。 |
| [^7] | [Optimizing Polynomial Graph Filters: A Novel Adaptive Krylov Subspace Approach](https://arxiv.org/abs/2403.07954) | 本文通过统一多项式图滤波器和相同次数的最优滤波器到同阶克里洛夫子空间，提供了等效的表达能力；设计了一种新的自适应克里洛夫子空间方法，以优化具有可控性的多项式基准。 |
| [^8] | [Efficient Data Collection for Robotic Manipulation via Compositional Generalization](https://arxiv.org/abs/2403.05110) | 通过研究机器人策略的复合能力，可以避免收集处理复合情况所需的数据。 |
| [^9] | [What makes an image realistic?](https://arxiv.org/abs/2403.04493) | 论文讨论了如何设计能够可靠区分真实数据和不真实数据的函数，提出了通用评论者的概念作为一个新的解决方案。 |
| [^10] | [Scalable Continuous-time Diffusion Framework for Network Inference and Influence Estimation](https://arxiv.org/abs/2403.02867) | 将扩散过程视为连续时间动力系统，建立了可扩展且有效的框架以近似从级联中推断出基础网络结构，解决了网络推断和影响估计中存在的可扩展性问题 |
| [^11] | [NiNformer: A Network in Network Transformer with Token Mixing Generated Gating Function](https://arxiv.org/abs/2403.02411) | 提出了一种新的计算块，称为NiNformer，具有令牌混合生成门控功能，以解决注意机制在深度学习中的计算成本高昂和数据集要求大的缺点。 |
| [^12] | [A Two-Stage Algorithm for Cost-Efficient Multi-instance Counterfactual Explanations](https://arxiv.org/abs/2403.01221) | 本文提出了一种两阶段算法，用于找到实例组以及成本有效的多实例反事实解释，填补了先前工作中未解决的空白。 |
| [^13] | [Inexact Unlearning Needs More Careful Evaluations to Avoid a False Sense of Privacy](https://arxiv.org/abs/2403.01218) | 论文讨论了针对反学习环境的成员推断攻击的调整，并提出了现有U-MIA的分类，对每个示例实例化了专用攻击者。 |
| [^14] | [Confidence-Aware Multi-Field Model Calibration](https://arxiv.org/abs/2402.17655) | 本研究提出了一种基于置信度的多字段校准方法，通过根据样本统计推导的置信水平自适应调整校准强度，以解决校准过程中存在的偏差放大和在线干扰问题。 |
| [^15] | [m2mKD: Module-to-Module Knowledge Distillation for Modular Transformers](https://arxiv.org/abs/2402.16918) | 提出了用于在模块之间传递知识的通用模块到模块知识蒸馏（m2mKD）方法，解决了模块化Transformer训练中的优化困难和参数数量庞大等挑战。 |
| [^16] | [Stable Neural Stochastic Differential Equations in Analyzing Irregular Time Series Data](https://arxiv.org/abs/2402.14989) | 神经常微分方程（Neural ODEs）的扩展——神经随机微分方程（Neural SDEs）在处理不规则时间序列数据中的稳定性和性能方面提出了重要指导，需要谨慎设计漂移和扩散函数以保持稳定性。 |
| [^17] | [2D Matryoshka Sentence Embeddings](https://arxiv.org/abs/2402.14776) | Matryoshka表示学习(MRL)以更细粒度地编码信息，以适应临时任务，同时实现了更小的嵌入大小，从而加快了下游任务的速度。 |
| [^18] | [Verifying message-passing neural networks via topology-based bounds tightening](https://arxiv.org/abs/2402.13937) | 通过基于拓扑的界限紧缩，我们提出了一种强大的证书生成方法，用于验证消息传递神经网络，支持添加和删除边、全局和局部预算的设置，以及拓扑扰动和特征修改，展示了其在优化约束动态调整方面的有效性。 |
| [^19] | [HyperMoE: Towards Better Mixture of Experts via Transferring Among Experts](https://arxiv.org/abs/2402.12656) | HyperMoE通过Hypernetworks框架整合知识传递的概念，解决了在专家选择过程中专家知识稀疏性和可用性之间的矛盾。 |
| [^20] | [DDIPrompt: Drug-Drug Interaction Event Prediction based on Graph Prompt Learning](https://arxiv.org/abs/2402.11472) | 基于图提示学习的DDIPrompt框架旨在解决药物相互作用事件预测中的高度不平衡事件分布和罕见事件标记数据稀缺性问题。 |
| [^21] | [Criterion collapse and loss distribution control](https://arxiv.org/abs/2402.09802) | 该论文研究了"准则崩溃"的概念，即优化一个度量指标意味着另一个度量指标的最优性。研究结果发现，对于损失的伯努利分布，CVaR和DRO的结果远超出现有研究，同时发现了一些特定条件下，单调准则如倾斜ERM无法避免崩溃，而非单调的替代方案可以。 |
| [^22] | [Feature Attribution with Necessity and Sufficiency via Dual-stage Perturbation Test for Causal Explanation](https://arxiv.org/abs/2402.08845) | 这篇论文提出了一种使用双阶段扰动测试来进行特征归因的方法，通过计算扰动一个特征对预测变化的必要性和充分性作用的概率来衡量特征重要性。该方法能够增强特征归因方法在区分不同特征贡献方面的能力。 |
| [^23] | [Concept-1K: A Novel Benchmark for Instance Incremental Learning](https://arxiv.org/abs/2402.08526) | 我们提出了一种名为Concept-1K的具有挑战性的实例增量学习（IIL）场景和数据集，揭示了十亿参数的PLM仍然遭受灾难性遗忘，影响因素包括模型规模、预训练和缓冲区大小。现有的IL方法和LoRA技术无法满足性能需求。我们的研究为探索和缓解PLM中的遗忘问题提供了新的场景。 |
| [^24] | [The Effect of Data Poisoning on Counterfactual Explanations](https://arxiv.org/abs/2402.08290) | 本研究研究了反事实解释在数据污染方面的脆弱性，发现最先进的反事实生成方法和工具包容易受到数据污染的影响。 |
| [^25] | [Towards Faithful and Robust LLM Specialists for Evidence-Based Question-Answering](https://arxiv.org/abs/2402.08277) | 这项工作探索了如何鲁棒地微调大型语言模型以提高答案的来源质量和答案归因能力，引入了数据生成流水线和四个测试集来评估模型的性能，并展示了在合成数据上微调可以改善内部和外部分布的性能。 |
| [^26] | [Text-centric Alignment for Multi-Modality Learning](https://arxiv.org/abs/2402.08086) | 本研究提出了一种名为文本中心对齐的多模态学习方法（TAMML），利用大型语言模型和基础模型，通过将文本作为统一的语义空间，解决了多模态学习中的模态不匹配问题，并在处理未见过的、多样化的、不可预测的模态组合时取得了显著的改进。 |
| [^27] | [Boundary Exploration for Bayesian Optimization With Unknown Physical Constraints](https://arxiv.org/abs/2402.07692) | 本文提出了一种新的贝叶斯优化方法BE-CBO，通过有效地探索可行和不可行设计之间的边界，来解决在实际应用中优化未知约束的未知函数的问题。 |
| [^28] | [Probabilistic Forecasting of Irregular Time Series via Conditional Flows](https://arxiv.org/abs/2402.06293) | 该论文提出了一种使用条件流进行不规则时间序列的概率预测的新模型ProFITi。该模型通过学习条件下未来值的联合分布，对具有缺失值的不规则时间序列进行预测，而不假设底层分布的固定形状。通过引入可逆三角形注意力层和可逆非线性激活函数，该模型取得了良好的实验结果。 |
| [^29] | [Safety Filters for Black-Box Dynamical Systems by Learning Discriminating Hyperplanes](https://arxiv.org/abs/2402.05279) | 本文提出一种基于学习的方法，通过定义判别超平面来实现黑盒动态系统的安全过滤器。我们的方法不仅可以消除对特定证明函数的依赖，还简化了安全过滤器的设计。 |
| [^30] | [AONeuS: A Neural Rendering Framework for Acoustic-Optical Sensor Fusion](https://arxiv.org/abs/2402.03309) | AONeuS是一种基于物理的多模态声光神经表面重建框架，通过融合高分辨率RGB测量和低分辨率深度成像声纳测量，能够在受限基线下实现准确的高分辨率三维表面重建。 |
| [^31] | [Comparative Analysis of LLaMA and ChatGPT Embeddings for Molecule Embedding](https://arxiv.org/abs/2402.00024) | LLaMA和ChatGPT比较分析了它们在SMILES字符串嵌入中的性能，在分子性质预测和药物-药物相互作用预测中，LLaMA相对于ChatGPT表现更好并且与现有方法相当。 |
| [^32] | [Prompt-Driven LLM Safeguarding via Directed Representation Optimization](https://arxiv.org/abs/2401.18018) | 通过研究模型表示的影响，我们发现安全提示并没有明显增强恶意和无害查询之间的区分，并提出了一种名为DRO的方法，用于自动优化安全提示。 |
| [^33] | [Agile But Safe: Learning Collision-Free High-Speed Legged Locomotion](https://arxiv.org/abs/2401.17583) | 本文介绍了一种名为敏捷但安全（ABS）的学习控制框架，能够实现四足机器人的敏捷且无碰撞行走。该框架通过一个学习得到的控制论到达-避免值网络来实现策略切换，并通过协作运行的敏捷策略和恢复策略，使机器人能够高速且安全地导航。 |
| [^34] | [A Generative Model for Accelerated Inverse Modelling Using a Novel Embedding for Continuous Variables](https://arxiv.org/abs/2311.11343) | 提出了一种用于加速反向建模的生成模型，利用了新型的连续变量嵌入策略，消除了归一化的需要，保留信息并创造了一个多功能的嵌入空间。 |
| [^35] | [Residual Quantization with Implicit Neural Codebooks.](http://arxiv.org/abs/2401.14732) | 本文提出了QINCo，一种神经网络残余量化变体，通过预测每个矢量的专门码书，提高了准确性，并在多个数据集和码书大小上优于现有方法。 |
| [^36] | [Precision Mars Entry Navigation with Atmospheric Density Adaptation via Neural Networks.](http://arxiv.org/abs/2401.14411) | 这项工作介绍了一种利用神经网络进行火星进入导航的新方法，使用神经网络估计大气密度，并根据估计的不确定性进行实时参数调整，以提高导航滤波器的性能。 |
| [^37] | [Transfer learning-assisted inverse modeling in nanophotonics based on mixture density networks.](http://arxiv.org/abs/2401.12254) | 本文提出了一种基于迁移学习增强的混合密度网络模型的纳米光子结构逆向建模方法，可以高效地预测多个可能的解决方案。 |
| [^38] | [Hacking Predictors Means Hacking Cars: Using Sensitivity Analysis to Identify Trajectory Prediction Vulnerabilities for Autonomous Driving Security.](http://arxiv.org/abs/2401.10313) | 本文通过对两个轨迹预测模型进行敏感性分析，发现尽管图像地图对于这两个模型的预测输出可能只有轻微的贡献，但使用快速梯度符号法制作的不可检测的图像地图扰动可以导致预测误差大幅增加，从而破坏自动驾驶系统的轨迹预测性能。 |
| [^39] | [Deep Ensemble Shape Calibration: Multi-Field Post-hoc Calibration in Online Advertising.](http://arxiv.org/abs/2401.09507) | 这篇论文介绍了一种用于解决电子商务广告中多场后处理校准问题的方法。该方法通过训练校准器，并在在线推断过程中应用这些校准器来实现形状校准和数值校准。 |
| [^40] | [Learning Explainable and Better Performing Representations of POMDP Strategies.](http://arxiv.org/abs/2401.07656) | 本研究提出了一种学习部分可观测的马尔可夫决策过程（POMDP）策略自动机表示的方法。与传统的表格表示相比，该方法得到的自动机更小更易理解，且在学习过程中可改善策略性能。与其他方法相比，本方法在可扩展性上具有显著优势。 |
| [^41] | [Multilingual Instruction Tuning With Just a Pinch of Multilinguality.](http://arxiv.org/abs/2401.01854) | 本研究研究了多语言指令调优中的多语言性对跨语言指令遵循的影响。研究发现，即使在单语调优过程中，许多语言也可以将一些指令遵循能力转移到其他语言上。此外，只有40个多语言示例能够显著提高多语言指令遵循。总体来说，多语言混合调优的模型在多种语言上的表现相比单语调优的模型要好或者不相上下，尽管使用的这些语言的训练示例数量只有10倍少。 |
| [^42] | [Quantum circuit synthesis with diffusion models.](http://arxiv.org/abs/2311.02041) | 该论文提出了一种利用扩散模型进行量子电路合成的方法，通过使用生成式机器学习模型，可以在基于门的量子电路中产生所需的量子操作，而且能够绕过经典模拟量子动力学的指数级开销。实验证明该模型在纠缠生成和酉编译等任务中表现优秀，并支持扩展功能以适应不同的量子设备约束条件。 |
| [^43] | [MIR2: Towards Provably Robust Multi-Agent Reinforcement Learning by Mutual Information Regularization.](http://arxiv.org/abs/2310.09833) | MIR2提出了一种针对鲁棒多智能体强化学习的方法，通过在常规情况下训练策略并最小化互信息作为鲁棒正则化，实现了在不准备每种可能的最坏情况的情况下提升鲁棒性的目标。 |
| [^44] | [TimeGPT-1.](http://arxiv.org/abs/2310.03589) | TimeGPT是第一个面向时间序列的基础模型，能够生成准确的预测。它在性能、效率和简洁性方面优于现有的统计学、机器学习和深度学习方法。我们的研究提供了有力的证据，表明借鉴其他人工智能领域的见解可以有效应用于时间序列分析。大规模时间序列模型有望民主化访问精确的预测并减少不确定性。 |
| [^45] | [FedLPA: Personalized One-shot Federated Learning with Layer-Wise Posterior Aggregation.](http://arxiv.org/abs/2310.00339) | 本文提出了一种名为FedLPA的新颖方法，采用分层后验聚合的方式实现个性化单次联邦学习。FedLPA能够高效地将本地模型聚合到全局模型，解决了单次聚合在非相同训练数据分布下的性能问题。 |
| [^46] | [EnCodecMAE: Leveraging neural codecs for universal audio representation learning.](http://arxiv.org/abs/2309.07391) | 本文提出了一种称为EnCodecMAE的方法，利用神经编解码器EnCodec生成离散目标，用于基于遮蔽自动编码器（MAE）学习通用音频模型。通过在涵盖语音、音乐和环境声音的多个音频任务上的评估，发现EnCodecMAE达到了与领先的音频表示模型相当甚至更好的性能。 |
| [^47] | [Fitness Approximation through Machine Learning.](http://arxiv.org/abs/2309.03318) | 我们提出了一种使用机器学习模型在遗传算法中进行适应度近似的方法。实验结果表明，这种方法显著提高了进化运行时间，并且适应度得分要么与完全运行的遗传算法相同，要么稍微低一点。 |
| [^48] | [Data-Driven Projection for Reducing Dimensionality of Linear Programs: Generalization Bound and Learning Methods.](http://arxiv.org/abs/2309.00203) | 本文研究了一种简单的数据驱动方法，通过学习投影矩阵来降低高维线性规划问题的维数，实现更快的求解速度。基于“数据驱动算法设计”，提出了泛化保证的数据量与性能指标的伪维度的上界和下界。 |
| [^49] | [BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual Pragmatic Knowledge.](http://arxiv.org/abs/2308.16458) | BioCoder是一个用于评估预训练模型在生成生物信息学代码方面的基准，涵盖了函数代码生成中的包依赖关系、类声明和全局变量，并通过模糊测试框架进行评估。 |
| [^50] | [High-Resolution Cranial Defect Reconstruction by Iterative, Low-Resolution, Point Cloud Completion Transformers.](http://arxiv.org/abs/2308.03813) | 该论文提出了一种新的方法来增加个性化颅骨重建的可用性，通过点云完成任务实现高分辨率颅缺损重建，并在训练和推理过程中快速且资源高效。 |
| [^51] | [Incorporating Recklessness to Collaborative Filtering based Recommender Systems.](http://arxiv.org/abs/2308.02058) | 本文提出了一种将鲁莽行为引入基于矩阵分解的推荐系统学习过程的方法，通过控制风险水平来提高预测的数量和质量。 |
| [^52] | [Budgeting Counterfactual for Offline RL.](http://arxiv.org/abs/2307.06328) | 离线强化学习中，通过动态规划的方法限制超出分布动作的数量。 |
| [^53] | [Offline Reinforcement Learning with Imbalanced Datasets.](http://arxiv.org/abs/2307.02752) | 本文提出了一种在不平衡数据集中的新型离线强化学习方法，通过将CQL与回溯过程相结合来提取策略，从而有效地解决了不平衡数据集带来的挑战。 |
| [^54] | [Empirical Sample Complexity of Neural Network Mixed State Reconstruction.](http://arxiv.org/abs/2307.01840) | 该论文通过数值研究混合态重构技术的性能，展示了在不同混合度下不同神经量子态编码的效率，并提出了设计更高效编码的需求。 |
| [^55] | [Unsupervised Episode Generation for Graph Meta-learning.](http://arxiv.org/abs/2306.15217) | 本文研究了无监督的剧集生成方法，通过元学习解决没有标签的少样本节点分类问题。它们充分利用所有节点信息，并且通过泛化能力提高性能。 |
| [^56] | [Multi-omics Prediction from High-content Cellular Imaging with Deep Learning.](http://arxiv.org/abs/2306.09391) | 本研究使用深度学习方法，从高内容细胞成像中直接预测细胞群体的多组学。实验结果表明，该方法能够在多种刺激条件下实现显著成果，为细胞组学领域提供了新的方法。 |
| [^57] | [Simplifying Full Waveform Inversion via Domain-Independent Self-Supervised Learning.](http://arxiv.org/abs/2305.13314) | 本文提出了基于领域无关自监督学习的SimFWI算法，其两个步骤分别是分别通过多个数据集上的遮盖图像建模学习编码器和解码器，然后为每个数据集学习一个线性映射。该算法可用于预测地震数据中的地下速度图，可极大地简化全波形反演任务，并连接多个FWI数据集。 |
| [^58] | [Enriching Disentanglement: Definitions to Metrics.](http://arxiv.org/abs/2305.11512) | 本文探究了解缠结表示学习的度量标准，并提出了基于丰富范畴论的系统方法，将方程定义转化为可比较的度量标准，我们推导出应用于测量解缠结属性的度量标准，并在合成数据上证明其有效性。 |
| [^59] | [Time Series Classification for Detecting Parkinson's Disease from Wrist Motions.](http://arxiv.org/abs/2304.11265) | 该研究使用InceptionTime和ROCKET方法进行时间序列分类，以监测帕金森病患者的手腕运动。研究发现，所有方法都适用于估计震颤严重程度和肌肉强直的存在，但在检测运动障碍方面存在困难。具有岭分类器的InceptionTime方法展示了最先进的分类性能，显示时间序列分类在基于可穿戴设备的PD症状监测中具有潜力。 |
| [^60] | [Data as voters: instance selection using approval-based multi-winner voting.](http://arxiv.org/abs/2304.09995) | 该论文提出了一种基于赞成票的多获胜者投票的实例选择方法，通过代表性投票规则选择获胜者，并将其作为减少训练集的数据实例。 |
| [^61] | [Hierarchical Training of Deep Neural Networks Using Early Exiting.](http://arxiv.org/abs/2303.02384) | 本文提出了一种使用早期退出的分层训练方法，将深度神经网络分为边缘和云工作者，以减少通信成本、训练运行时间和隐私问题。 |
| [^62] | [t-SMILES: A Scalable Fragment-based Molecular Representation Framework for De Novo Molecule Generation.](http://arxiv.org/abs/2301.01829) | 本研究提出了一种可扩展的基于碎片的分子表示框架 t-SMILES，通过引入 t-SMILES 可以显著改善分子的表示效果，并在多种任务中表现出色，优于其他经典模型。 |

# 详细

[^1]: 学习与分布偏移的半空间交集：改进算法和SQ下界

    Learning Intersections of Halfspaces with Distribution Shift: Improved Algorithms and SQ Lower Bounds

    [https://arxiv.org/abs/2404.02364](https://arxiv.org/abs/2404.02364)

    研究学习与分布偏移的交集问题，在基于高斯训练分布的情况下，证明了一系列新的上界，包括一种TDS学习$k$个齐次半空间交集达到精度$\epsilon$的$2^{(k/\epsilon)^{O(1)}} \mathsf{poly}(d)$时间算法（在先前的工作中）。

    

    Klivans、Stavropoulos和Vasilyan最近的工作引发了对具有分布偏移的可测试学习（TDS学习）的研究，其中学习者从训练分布$\mathcal{D}$获得标记样本，从测试分布$\mathcal{D}'$获得未标记样本，目标是在训练样本通过相应的测试时输出在$\mathcal{D}'$上具有低误差的分类器。他们的模型不同于先前的所有工作，因为$\mathcal{D}'$上没有假设。相反，当训练和测试分布的边际相等时，测试必须接受（以高概率）。

    arXiv:2404.02364v1 Announce Type: cross  Abstract: Recent work of Klivans, Stavropoulos, and Vasilyan initiated the study of testable learning with distribution shift (TDS learning), where a learner is given labeled samples from training distribution $\mathcal{D}$, unlabeled samples from test distribution $\mathcal{D}'$, and the goal is to output a classifier with low error on $\mathcal{D}'$ whenever the training samples pass a corresponding test. Their model deviates from all prior work in that no assumptions are made on $\mathcal{D}'$. Instead, the test must accept (with high probability) when the marginals of the training and test distributions are equal.   Here we focus on the fundamental case of intersections of halfspaces with respect to Gaussian training distributions and prove a variety of new upper bounds including a $2^{(k/\epsilon)^{O(1)}} \mathsf{poly}(d)$-time algorithm for TDS learning intersections of $k$ homogeneous halfspaces to accuracy $\epsilon$ (prior work achieved
    
[^2]: 视野中的船只：船只图像超分辨率的扩散模型

    Ship in Sight: Diffusion Models for Ship-Image Super Resolution

    [https://arxiv.org/abs/2403.18370](https://arxiv.org/abs/2403.18370)

    该研究探索了船只图像超分辨率问题，提出了一种基于扩散模型的架构，利用文本条件在训练期间，并在类别感知的情况下，以最佳方式保存船只的关键细节。

    

    近年来，图像生成领域取得了显著进展，主要受到不断增长的对各种图像生成子任务（如修补、去噪和超分辨率）高质量结果的需求驱动。我们的方法深入探讨了船只图像超分辨率问题，这对沿海和港口监视至关重要。我们研究了文本到图像扩散模型的应用机会，利用这些基础模型已经学到的先验知识。具体来说，我们提出了一种基于扩散模型的架构，利用文本条件在训练期间，并在类别感知的情况下，以最佳方式保存船只的关键细节在超分辨率生成过程中。

    arXiv:2403.18370v1 Announce Type: cross  Abstract: In recent years, remarkable advancements have been achieved in the field of image generation, primarily driven by the escalating demand for high-quality outcomes across various image generation subtasks, such as inpainting, denoising, and super resolution. A major effort is devoted to exploring the application of super-resolution techniques to enhance the quality of low-resolution images. In this context, our method explores in depth the problem of ship image super resolution, which is crucial for coastal and port surveillance. We investigate the opportunity given by the growing interest in text-to-image diffusion models, taking advantage of the prior knowledge that such foundation models have already learned. In particular, we present a diffusion-model-based architecture that leverages text conditioning during training while being class-aware, to best preserve the crucial details of the ships during the generation of the super-resolut
    
[^3]: 在自动控制系统中的对抗性攻击与防御：一项综合基准研究

    Adversarial Attacks and Defenses in Automated Control Systems: A Comprehensive Benchmark

    [https://arxiv.org/abs/2403.13502](https://arxiv.org/abs/2403.13502)

    该研究通过评估在自动控制系统中部署的深度学习模型对抗性攻击的脆弱性和不同防御策略的有效性，提出了结合多种防御方法的新颖保护方法，并为确保工业中的稳健故障诊断提供了见解。

    

    将机器学习整合到自动控制系统（ACS）中增强了工业过程管理的决策能力。其中一项限制工业普遍采用这些技术的是神经网络对对抗性攻击的脆弱性。本研究探讨了使用Tennessee Eastman过程数据集在ACS中部署深度学习模型进行故障诊断时的威胁。通过评估三种不同架构的神经网络，我们对其进行了六种对抗性攻击，并探讨了五种不同的防御方法。我们的结果突出了模型对对抗性样本的强大脆弱性以及防御策略的不同有效性。我们还提出了一种新颖的保护方法，将多种防御方法结合起来，并展示了其有效性。这项研究对确保工业中机器学习的安全性提供了一些见解，确保了工业中稳健的故障诊断。

    arXiv:2403.13502v1 Announce Type: new  Abstract: Integrating machine learning into Automated Control Systems (ACS) enhances decision-making in industrial process management. One of the limitations to the widespread adoption of these technologies in industry is the vulnerability of neural networks to adversarial attacks. This study explores the threats in deploying deep learning models for fault diagnosis in ACS using the Tennessee Eastman Process dataset. By evaluating three neural networks with different architectures, we subject them to six types of adversarial attacks and explore five different defense methods. Our results highlight the strong vulnerability of models to adversarial samples and the varying effectiveness of defense strategies. We also propose a novel protection approach by combining multiple defense methods and demonstrate it's efficacy. This research contributes several insights into securing machine learning within ACS, ensuring robust fault diagnosis in industrial 
    
[^4]: AdaptSFL：资源受限边缘网络中的自适应分割联邦学习

    AdaptSFL: Adaptive Split Federated Learning in Resource-constrained Edge Networks

    [https://arxiv.org/abs/2403.13101](https://arxiv.org/abs/2403.13101)

    提出了AdaptSFL自适应分割联邦学习框架，以加速资源受限边缘系统中的学习性能。

    

    深度神经网络的日益复杂使得将其民主化到资源有限的边缘设备面临重要障碍。为了解决这一挑战，通过模型分区将主要训练工作负荷转移到服务器上，并在边缘设备之间实现并行训练的分割联邦学习（SFL）已经成为一种有前途的解决方案。然而，尽管系统优化极大地影响了资源受限系统下SFL的性能，但这个问题仍然很大程度上没有被探索。本文提供了SFL的收敛分析，量化了模型分割（MS）和客户端模型聚合（MA）对学习性能的影响，作为理论基础。然后，我们提出了AdaptSFL，一种新颖的资源自适应SFL框架，以加速资源受限边缘计算系统下的SFL。具体来说，AdaptSFL自适应地控制客户端MA和MS，以平衡通信

    arXiv:2403.13101v1 Announce Type: new  Abstract: The increasing complexity of deep neural networks poses significant barriers to democratizing them to resource-limited edge devices. To address this challenge, split federated learning (SFL) has emerged as a promising solution by of floading the primary training workload to a server via model partitioning while enabling parallel training among edge devices. However, although system optimization substantially influences the performance of SFL under resource-constrained systems, the problem remains largely uncharted. In this paper, we provide a convergence analysis of SFL which quantifies the impact of model splitting (MS) and client-side model aggregation (MA) on the learning performance, serving as a theoretical foundation. Then, we propose AdaptSFL, a novel resource-adaptive SFL framework, to expedite SFL under resource-constrained edge computing systems. Specifically, AdaptSFL adaptively controls client-side MA and MS to balance commun
    
[^5]: 一种用于多模态推荐的对齐和训练框架

    An Aligning and Training Framework for Multimodal Recommendations

    [https://arxiv.org/abs/2403.12384](https://arxiv.org/abs/2403.12384)

    提出了一种名为AlignRec的对齐和训练框架，用于解决多模态推荐中的不对齐问题，通过将推荐目标分解为三个对齐部分，实现内容内部对齐、内容与分类ID之间的对齐以及用户和项目之间的对齐。

    

    随着多媒体应用的发展，多模态推荐正在发挥着重要作用，因为它们可以利用超越用户交互的丰富上下文。现有方法主要将多模态信息视为辅助，用于帮助学习ID特征；然而，多模态内容特征和ID特征之间存在语义差距，直接将多模态信息作为辅助使用会导致用户和项目表示的不对齐。本文首先系统地研究了多模态推荐中的不对齐问题，并提出了一种名为AlignRec的解决方案。在AlignRec中，推荐目标被分解为三个对齐部分，即内容内部对齐，内容与分类ID之间的对齐以及用户和项目之间的对齐。每个对齐部分都由特定的目标函数来表征，并整合到我们的多模态推荐中。

    arXiv:2403.12384v1 Announce Type: cross  Abstract: With the development of multimedia applications, multimodal recommendations are playing an essential role, as they can leverage rich contexts beyond user interactions. Existing methods mainly regard multimodal information as an auxiliary, using them to help learn ID features; however, there exist semantic gaps among multimodal content features and ID features, for which directly using multimodal information as an auxiliary would lead to misalignment in representations of users and items. In this paper, we first systematically investigate the misalignment issue in multimodal recommendations, and propose a solution named AlignRec. In AlignRec, the recommendation objective is decomposed into three alignments, namely alignment within contents, alignment between content and categorical ID, and alignment between users and items. Each alignment is characterized by a specific objective function and is integrated into our multimodal recommendat
    
[^6]: Skipformer：一种用于高效语音识别的跳过和恢复策略

    Skipformer: A Skip-and-Recover Strategy for Efficient Speech Recognition

    [https://arxiv.org/abs/2403.08258](https://arxiv.org/abs/2403.08258)

    Skipformer提出了一种“跳过和恢复”的Conformer架构，可以动态、不均匀地压缩序列输入长度，大大减少了计算预算和内存消耗，并获得更好的识别准确性。

    

    基于Conformer的注意力模型已成为自动语音识别任务的事实标杆模型。通常引入一个空白符号来对齐CTC或RNN-T模型的输入和输出序列。不幸的是，由于注意力机制，长输入长度会对计算预算和内存消耗造成二次负荷。在这项工作中，我们提出了一种名为Skipformer的“跳过和恢复”Conformer架构，以动态和不均匀地压缩序列输入长度。Skipformer使用中间CTC输出作为标准将帧分为三组：关键、跳过和忽略。关键组馈送到下一个Conformer块，其输出与跳过组通过原始时间顺序联接作为最终编码器输出。实验表明，我们的模型在Aishell-1上将输入序列长度减少了31倍，在Librispeech语料库上减少了22倍。同时，该模型可实现更好的识别准确性。

    arXiv:2403.08258v1 Announce Type: new  Abstract: Conformer-based attention models have become the de facto backbone model for Automatic Speech Recognition tasks. A blank symbol is usually introduced to align the input and output sequences for CTC or RNN-T models. Unfortunately, the long input length overloads computational budget and memory consumption quadratically by attention mechanism. In this work, we propose a "Skip-and-Recover" Conformer architecture, named Skipformer, to squeeze sequence input length dynamically and inhomogeneously. Skipformer uses an intermediate CTC output as criteria to split frames into three groups: crucial, skipping and ignoring. The crucial group feeds into next conformer blocks and its output joint with skipping group by original temporal order as the final encoder output. Experiments show that our model reduces the input sequence length by 31 times on Aishell-1 and 22 times on Librispeech corpus. Meanwhile, the model can achieve better recognition accu
    
[^7]: 优化多项式图滤波器：一种新的自适应克里洛夫子空间方法

    Optimizing Polynomial Graph Filters: A Novel Adaptive Krylov Subspace Approach

    [https://arxiv.org/abs/2403.07954](https://arxiv.org/abs/2403.07954)

    本文通过统一多项式图滤波器和相同次数的最优滤波器到同阶克里洛夫子空间，提供了等效的表达能力；设计了一种新的自适应克里洛夫子空间方法，以优化具有可控性的多项式基准。

    

    图神经网络（GNN），也称为谱图滤波器，在网络图中有着广泛的应用。为了绕过特征分解，提出了使用各种多项式基准进行滤波器训练的多项式图滤波器，以近似图滤波器。然而，目前没有研究从统一的角度探讨多样化的多项式图滤波器进行优化。本文首先将多项式图滤波器以及相同次数的最优滤波器统一成同阶克里洛夫子空间，从而在理论上提供相同的表达能力。接下来，我们从统一的克里洛夫子空间角度研究多项式的渐近收敛属性，揭示了它们在具有不同异质程度的图中的有限适应性。受到这些事实的启发，我们设计了一种新颖的自适应克里洛夫子空间方法，以优化多项式基准，并可证明具有可控性。

    arXiv:2403.07954v1 Announce Type: new  Abstract: Graph Neural Networks (GNNs), known as spectral graph filters, find a wide range of applications in web networks. To bypass eigendecomposition, polynomial graph filters are proposed to approximate graph filters by leveraging various polynomial bases for filter training. However, no existing studies have explored the diverse polynomial graph filters from a unified perspective for optimization.   In this paper, we first unify polynomial graph filters, as well as the optimal filters of identical degrees into the Krylov subspace of the same order, thus providing equivalent expressive power theoretically. Next, we investigate the asymptotic convergence property of polynomials from the unified Krylov subspace perspective, revealing their limited adaptability in graphs with varying heterophily degrees. Inspired by those facts, we design a novel adaptive Krylov subspace approach to optimize polynomial bases with provable controllability over the
    
[^8]: 机器人操纵的高效数据收集通过组合概括

    Efficient Data Collection for Robotic Manipulation via Compositional Generalization

    [https://arxiv.org/abs/2403.05110](https://arxiv.org/abs/2403.05110)

    通过研究机器人策略的复合能力，可以避免收集处理复合情况所需的数据。

    

    数据收集在机器人操纵中变得越来越重要，然而如何有效地收集数据以促进广泛泛化仍然缺乏很多理解。最近关于大规模机器人数据收集的研究通常在数据收集过程中变化了许多环境因素，如物体类型和桌面纹理。虽然这些研究试图涵盖各种各样的场景，但它们并没有明确考虑到基于数据训练的策略可能具有的复合能力。如果机器人策略能够从它们的训练数据中组合不同的环境变量（例如物体类型、桌面高度）以在遇到看不见的因素组合时成功，那么我们就可以利用这一点来避免为复合处理的情况收集数据。为了研究这种可能性，我们在仿真环境和实际机器人上进行了彻底的实证研究。

    arXiv:2403.05110v1 Announce Type: cross  Abstract: Data collection has become an increasingly important problem in robotic manipulation, yet there still lacks much understanding of how to effectively collect data to facilitate broad generalization. Recent works on large-scale robotic data collection typically vary a wide range of environmental factors during data collection, such as object types and table textures. While these works attempt to cover a diverse variety of scenarios, they do not explicitly account for the possible compositional abilities of policies trained on the data. If robot policies are able to compose different environmental factors of variation (e.g., object types, table heights) from their training data to succeed when encountering unseen factor combinations, then we can exploit this to avoid collecting data for situations that composition would address. To investigate this possibility, we conduct thorough empirical studies both in simulation and on a real robot t
    
[^9]: 使图像真实的因素是什么？

    What makes an image realistic?

    [https://arxiv.org/abs/2403.04493](https://arxiv.org/abs/2403.04493)

    论文讨论了如何设计能够可靠区分真实数据和不真实数据的函数，提出了通用评论者的概念作为一个新的解决方案。

    

    在过去的十年里，我们在生成看起来真实的数据方面取得了巨大进展，无论是图像、文本、音频还是视频。在这里，我们讨论了与之密切相关的问题，即量化现实主义，即设计能够可靠地区分真实数据和不真实数据的函数。从算法信息理论的观点出发，我们讨论了为什么这个问题很具挑战性，为什么一个好的生成模型单独不能解决它，以及一个好的解决方案应该是什么样的。特别是，我们引入了通用评论者的概念，不像对抗性评论者那样需要对抗性训练。尽管通用评论者并不立即实用，但它们既可以作为引导实际实现的北极星，也可以作为一个工具。

    arXiv:2403.04493v1 Announce Type: new  Abstract: The last decade has seen tremendous progress in our ability to generate realistic-looking data, be it images, text, audio, or video. Here, we discuss the closely related problem of quantifying realism, that is, designing functions that can reliably tell realistic data from unrealistic data. This problem turns out to be significantly harder to solve and remains poorly understood, despite its prevalence in machine learning and recent breakthroughs in generative AI. Drawing on insights from algorithmic information theory, we discuss why this problem is challenging, why a good generative model alone is insufficient to solve it, and what a good solution would look like. In particular, we introduce the notion of a universal critic, which unlike adversarial critics does not require adversarial training. While universal critics are not immediately practical, they can serve both as a North Star for guiding practical implementations and as a tool 
    
[^10]: 可扩展的连续时间扩散框架用于网络推断和影响估计

    Scalable Continuous-time Diffusion Framework for Network Inference and Influence Estimation

    [https://arxiv.org/abs/2403.02867](https://arxiv.org/abs/2403.02867)

    将扩散过程视为连续时间动力系统，建立了可扩展且有效的框架以近似从级联中推断出基础网络结构，解决了网络推断和影响估计中存在的可扩展性问题

    

    最近几年，连续时间信息传播的研究已成为许多应用领域的重要研究领域。当只能访问传播跟踪（级联）时，基于级联的网络推断和影响估计是两个必须探讨的重要问题。然而，现有方法在推断和处理超过几千个节点的网络时表现出有限的能力，存在可扩展性问题。本文将扩散过程视为连续时间动力系统，基于此建立了一个连续时间扩散模型。随后，我们将该模型实例化为一个可扩展且有效的框架（FIM），以近似从可用级联中推断出基础网络结构的扩散传播。此外，我们对FIM在网络推断中的近似误差进行了分析。为了实现影响估计的所需可扩展性，我们设计了...

    arXiv:2403.02867v1 Announce Type: cross  Abstract: The study of continuous-time information diffusion has been an important area of research for many applications in recent years. When only the diffusion traces (cascades) are accessible, cascade-based network inference and influence estimation are two essential problems to explore. Alas, existing methods exhibit limited capability to infer and process networks with more than a few thousand nodes, suffering from scalability issues. In this paper, we view the diffusion process as a continuous-time dynamical system, based on which we establish a continuous-time diffusion model. Subsequently, we instantiate the model to a scalable and effective framework (FIM) to approximate the diffusion propagation from available cascades, thereby inferring the underlying network structure. Furthermore, we undertake an analysis of the approximation error of FIM for network inference. To achieve the desired scalability for influence estimation, we devise 
    
[^11]: NiNformer: 一种具有令牌混合生成门控功能的网络中网络变压器

    NiNformer: A Network in Network Transformer with Token Mixing Generated Gating Function

    [https://arxiv.org/abs/2403.02411](https://arxiv.org/abs/2403.02411)

    提出了一种新的计算块，称为NiNformer，具有令牌混合生成门控功能，以解决注意机制在深度学习中的计算成本高昂和数据集要求大的缺点。

    

    注意机制是Transformer架构的主要组件，自引入以来，在深度学习领域取得了显著进展，跨越了许多领域和多个任务。该机制在计算机视觉中被应用为Vision Transformer ViT，并且其用途已扩展到视觉领域的许多任务，如分类、分割、目标检测和图像生成。尽管该机制非常具有表现力和能力，但其缺点是计算成本高昂，需要大规模数据集来有效优化。为了解决这些缺点，文献中提出了许多设计来减轻计算负担和缓解数据大小要求。在视觉领域的一些尝试的例子包括MLP-Mixer、Conv-Mixer、Perciver-IO等。本文介绍了一种新的计算块，作为一种

    arXiv:2403.02411v1 Announce Type: cross  Abstract: The Attention mechanism is the main component of the Transformer architecture, and since its introduction, it has led to significant advancements in Deep Learning that span many domains and multiple tasks. The Attention Mechanism was utilized in Computer Vision as the Vision Transformer ViT, and its usage has expanded into many tasks in the vision domain, such as classification, segmentation, object detection, and image generation. While this mechanism is very expressive and capable, it comes with the drawback of being computationally expensive and requiring datasets of considerable size for effective optimization. To address these shortcomings, many designs have been proposed in the literature to reduce the computational burden and alleviate the data size requirements. Examples of such attempts in the vision domain are the MLP-Mixer, the Conv-Mixer, the Perciver-IO, and many more. This paper introduces a new computational block as an 
    
[^12]: 一种用于成本效率多实例反事实解释的两阶段算法

    A Two-Stage Algorithm for Cost-Efficient Multi-instance Counterfactual Explanations

    [https://arxiv.org/abs/2403.01221](https://arxiv.org/abs/2403.01221)

    本文提出了一种两阶段算法，用于找到实例组以及成本有效的多实例反事实解释，填补了先前工作中未解决的空白。

    

    反事实解释是分析黑盒系统预测结果的最流行方法之一，因为它可以推荐成本有效且可操作的输入更改，将不良系统输出转变为期望输出。大多数现有的反事实方法解释单个实例，但一些真实的用例（如客户满意度）需要识别能同时满足多个实例（例如客户）的单一反事实。在这项工作中，我们提出了一种灵活的两阶段算法，用于找到实例组以及成本有效的多实例反事实解释。这是因为在大多数先前的工作中，找到这样的实例组并未得到充分解决的。

    arXiv:2403.01221v1 Announce Type: cross  Abstract: Counterfactual explanations constitute among the most popular methods for analyzing the predictions of black-box systems since they can recommend cost-efficient and actionable changes to the input to turn an undesired system's output into a desired output. While most of the existing counterfactual methods explain a single instance, several real-world use cases, such as customer satisfaction, require the identification of a single counterfactual that can satisfy multiple instances (e.g. customers) simultaneously. In this work, we propose a flexible two-stage algorithm for finding groups of instances along with cost-efficient multi-instance counterfactual explanations. This is motivated by the fact that in most previous works the aspect of finding such groups is not addressed.
    
[^13]: 粗糙反学习需要更加谨慎的评估以避免虚假隐私感知

    Inexact Unlearning Needs More Careful Evaluations to Avoid a False Sense of Privacy

    [https://arxiv.org/abs/2403.01218](https://arxiv.org/abs/2403.01218)

    论文讨论了针对反学习环境的成员推断攻击的调整，并提出了现有U-MIA的分类，对每个示例实例化了专用攻击者。

    

    模型训练的高成本使得开发反学习技术变得越来越有吸引力。这些技术旨在删除训练样本的影响，而无需从头重新训练模型。从直觉上讲，一旦模型完成反学习，与该模型交互的对手就不应再能够判断反学习的样本是否包含在模型的训练集中。在隐私领域，这被称为成员推断。在这项工作中，我们讨论了成员推断攻击（MIAs）对反学习设置的调整（导致它们的“U-MIA”对应）。我们提出了现有U-MIA的分类，将其分为“人口U-MIA”，其中同一攻击者适用于所有示例，和“每个示例U-MIA”，其中为每个示例实例化了专用攻击者。我们展示了后一类别，在这种情况下，攻击者为每个实例定制其成员预测。

    arXiv:2403.01218v1 Announce Type: new  Abstract: The high cost of model training makes it increasingly desirable to develop techniques for unlearning. These techniques seek to remove the influence of a training example without having to retrain the model from scratch. Intuitively, once a model has unlearned, an adversary that interacts with the model should no longer be able to tell whether the unlearned example was included in the model's training set or not. In the privacy literature, this is known as membership inference. In this work, we discuss adaptations of Membership Inference Attacks (MIAs) to the setting of unlearning (leading to their ``U-MIA'' counterparts). We propose a categorization of existing U-MIAs into ``population U-MIAs'', where the same attacker is instantiated for all examples, and ``per-example U-MIAs'', where a dedicated attacker is instantiated for each example. We show that the latter category, wherein the attacker tailors its membership prediction to each ex
    
[^14]: 基于置信度的多字段模型校准

    Confidence-Aware Multi-Field Model Calibration

    [https://arxiv.org/abs/2402.17655](https://arxiv.org/abs/2402.17655)

    本研究提出了一种基于置信度的多字段校准方法，通过根据样本统计推导的置信水平自适应调整校准强度，以解决校准过程中存在的偏差放大和在线干扰问题。

    

    预测用户反馈概率（如点击和转换）对于广告排名和竞价至关重要。然而，由于数据分布的转移和固有模型偏差，预测概率与真实可能性之间经常存在不希望的不一致。校准旨在通过后处理模型预测来解决此问题，而基于字段的校准可以调整不同特征字段值上的模型输出，以满足细粒度的广告需求。不幸的是，对应于某些字段值的观察样本可能太有限，无法进行有信心的校准，这可能导致偏差放大和在线干扰。在本文中，我们提出了一种基于置信度的多字段校准方法，根据样本统计推导的置信水平自适应调整校准强度。它还利用多个特征字段进行联合模型校准。

    arXiv:2402.17655v1 Announce Type: new  Abstract: Accurately predicting the probabilities of user feedback, such as clicks and conversions, is critical for ad ranking and bidding. However, there often exist unwanted mismatches between predicted probabilities and true likelihoods due to the shift of data distributions and intrinsic model biases. Calibration aims to address this issue by post-processing model predictions, and field-aware calibration can adjust model output on different feature field values to satisfy fine-grained advertising demands. Unfortunately, the observed samples corresponding to certain field values can be too limited to make confident calibrations, which may yield bias amplification and online disturbance. In this paper, we propose a confidence-aware multi-field calibration method, which adaptively adjusts the calibration intensity based on the confidence levels derived from sample statistics. It also utilizes multiple feature fields for joint model calibration wi
    
[^15]: m2mKD：模块间知识蒸馏用于模块化Transformer

    m2mKD: Module-to-Module Knowledge Distillation for Modular Transformers

    [https://arxiv.org/abs/2402.16918](https://arxiv.org/abs/2402.16918)

    提出了用于在模块之间传递知识的通用模块到模块知识蒸馏（m2mKD）方法，解决了模块化Transformer训练中的优化困难和参数数量庞大等挑战。

    

    模块化神经结构因其强大的泛化能力和对新领域的高效适应能力而越来越受到关注。然而，训练模块化模型，特别是在早期阶段，由于固有的稀疏连接导致的优化困难，存在挑战。利用来自整体模型的知识，如知识蒸馏等技术，可能有助于训练模块化模型，并使它们能够整合来自在多个来源上预训练的模型的知识。然而，传统的知识蒸馏方法并不针对模块化模型设计，直接应用时可能失败，这是由于独特的架构和大量涉及的参数。受到这些挑战的启发，我们提出了一种用于在模块之间传递知识的通用模块到模块知识蒸馏（m2mKD）方法。

    arXiv:2402.16918v1 Announce Type: new  Abstract: Modular neural architectures are gaining increasing attention due to their powerful capability for generalization and sample-efficient adaptation to new domains. However, training modular models, particularly in the early stages, poses challenges due to the optimization difficulties arising from their intrinsic sparse connectivity. Leveraging the knowledge from monolithic models, using techniques such as knowledge distillation, is likely to facilitate the training of modular models and enable them to integrate knowledge from multiple models pretrained on diverse sources. Nevertheless, conventional knowledge distillation approaches are not tailored to modular models and can fail when directly applied due to the unique architectures and the enormous number of parameters involved. Motivated by these challenges, we propose a general module-to-module knowledge distillation (m2mKD) method for transferring knowledge between modules. Our approac
    
[^16]: 分析不规则时间序列数据中的稳定神经随机微分方程

    Stable Neural Stochastic Differential Equations in Analyzing Irregular Time Series Data

    [https://arxiv.org/abs/2402.14989](https://arxiv.org/abs/2402.14989)

    神经常微分方程（Neural ODEs）的扩展——神经随机微分方程（Neural SDEs）在处理不规则时间序列数据中的稳定性和性能方面提出了重要指导，需要谨慎设计漂移和扩散函数以保持稳定性。

    

    实际时间序列数据中的不规则采样间隔和缺失值对于假设一致间隔和完整数据的传统方法构成挑战。神经常微分方程（Neural ODEs）提供了一种替代方法，利用神经网络与常微分方程求解器结合，通过参数化向量场学习连续潜在表示。神经随机微分方程（Neural SDEs）通过引入扩散项扩展了神经常微分方程，然而在处理不规则间隔和缺失值时，这种添加并不是微不足道的。因此，仔细设计漂移和扩散函数对于保持稳定性和增强性能至关重要，而粗心的选择可能导致出现没有强解、随机破坏或不稳定的Euler离散化等不利的性质，显著影响神经随机微分方程的性能。

    arXiv:2402.14989v1 Announce Type: cross  Abstract: Irregular sampling intervals and missing values in real-world time series data present challenges for conventional methods that assume consistent intervals and complete data. Neural Ordinary Differential Equations (Neural ODEs) offer an alternative approach, utilizing neural networks combined with ODE solvers to learn continuous latent representations through parameterized vector fields. Neural Stochastic Differential Equations (Neural SDEs) extend Neural ODEs by incorporating a diffusion term, although this addition is not trivial, particularly when addressing irregular intervals and missing values. Consequently, careful design of drift and diffusion functions is crucial for maintaining stability and enhancing performance, while incautious choices can result in adverse properties such as the absence of strong solutions, stochastic destabilization, or unstable Euler discretizations, significantly affecting Neural SDEs' performance. In 
    
[^17]: 2D Matryoshka句子嵌入

    2D Matryoshka Sentence Embeddings

    [https://arxiv.org/abs/2402.14776](https://arxiv.org/abs/2402.14776)

    Matryoshka表示学习(MRL)以更细粒度地编码信息，以适应临时任务，同时实现了更小的嵌入大小，从而加快了下游任务的速度。

    

    arXiv:2402.14776v1 公告类型：新  摘要：常见方法依赖于从语言模型中获得的固定长度的嵌入向量作为句子嵌入，用于语义文本相似性（STS）等下游任务。由于在各种应用程序中存在未知的计算约束和预算，这些方法在灵活性上受到限制。Matryoshka表示学习(MRL)(Kusupati等人，2022)以更细粒度地编码信息，即使用较低的嵌入维度，以自适应地适应临时任务。可以通过较小的嵌入大小达到类似的准确性，从而加快下游任务。尽管其改进了效率，MRL仍要在获得嵌入之前遍历所有Transformer层，这仍然是时间和内存消耗的主要因素。这引发了是否固定数量的Transformer层会影响表示质量以及使用中间层进行句子表示是否可行的考虑。

    arXiv:2402.14776v1 Announce Type: new  Abstract: Common approaches rely on fixed-length embedding vectors from language models as sentence embeddings for downstream tasks such as semantic textual similarity (STS). Such methods are limited in their flexibility due to unknown computational constraints and budgets across various applications. Matryoshka Representation Learning (MRL) (Kusupati et al., 2022) encodes information at finer granularities, i.e., with lower embedding dimensions, to adaptively accommodate ad hoc tasks. Similar accuracy can be achieved with a smaller embedding size, leading to speedups in downstream tasks. Despite its improved efficiency, MRL still requires traversing all Transformer layers before obtaining the embedding, which remains the dominant factor in time and memory consumption. This prompts consideration of whether the fixed number of Transformer layers affects representation quality and whether using intermediate layers for sentence representation is feas
    
[^18]: 通过基于拓扑的界限紧缩验证消息传递神经网络

    Verifying message-passing neural networks via topology-based bounds tightening

    [https://arxiv.org/abs/2402.13937](https://arxiv.org/abs/2402.13937)

    通过基于拓扑的界限紧缩，我们提出了一种强大的证书生成方法，用于验证消息传递神经网络，支持添加和删除边、全局和局部预算的设置，以及拓扑扰动和特征修改，展示了其在优化约束动态调整方面的有效性。

    

    由于图神经网络（GNNs）经常容易遭受攻击，我们需要知道何时可以信任它们。我们发展了一种计算有效的方法，通过使用修正线性单元（ReLU）激活函数为消息传递神经网络（MPNNs）提供强大的证书。我们的工作建立在混合整数优化之上，编码了多种子问题，例如允许添加和删除边，全局和局部预算，以及拓扑扰动和特征修改。我们的关键技术，基于拓扑的界限紧缩，利用图结构来收紧界限。我们还尝试使用积极的界限紧缩来动态改变优化约束，即通过收紧变量界限。为了证明这些策略的效果，我们扩展了开源的分支定界求解器SCIP。我们在节点和图分类上进行了测试。

    arXiv:2402.13937v1 Announce Type: cross  Abstract: Since graph neural networks (GNNs) are often vulnerable to attack, we need to know when we can trust them. We develop a computationally effective approach towards providing robust certificates for message-passing neural networks (MPNNs) using a Rectified Linear Unit (ReLU) activation function. Because our work builds on mixed-integer optimization, it encodes a wide variety of subproblems, for example it admits (i) both adding and removing edges, (ii) both global and local budgets, and (iii) both topological perturbations and feature modifications. Our key technology, topology-based bounds tightening, uses graph structure to tighten bounds. We also experiment with aggressive bounds tightening to dynamically change the optimization constraints by tightening variable bounds. To demonstrate the effectiveness of these strategies, we implement an extension to the open-source branch-and-cut solver SCIP. We test on both node and graph classifi
    
[^19]: HyperMoE: 通过专家之间的知识传递实现更好的专家混合

    HyperMoE: Towards Better Mixture of Experts via Transferring Among Experts

    [https://arxiv.org/abs/2402.12656](https://arxiv.org/abs/2402.12656)

    HyperMoE通过Hypernetworks框架整合知识传递的概念，解决了在专家选择过程中专家知识稀疏性和可用性之间的矛盾。

    

    混合专家(MoE)在语言模型中被证明有效地增强了模型的能力，通过动态地将每个输入标记路由到特定的专家子集进行处理。尽管取得了成功，但大多数现有方法在专家知识的稀疏性和可用性之间面临挑战：通过增加对专家知识的使用来增强性能，往往会导致在专家选择过程中稀疏度减少。为了缓解这一矛盾，我们提出了HyperMoE，这是一个建立在Hypernetworks之上的新颖MoE框架。该框架将MoE的计算过程与多任务学习中的知识传递概念进行了集成。基于未选择专家信息生成的特定模块作为补充信息，允许未被选中的专家的知识在保持选择稀疏性的同时被使用。

    arXiv:2402.12656v1 Announce Type: cross  Abstract: The Mixture of Experts (MoE) for language models has been proven effective in augmenting the capacity of models by dynamically routing each input token to a specific subset of experts for processing. Despite the success, most existing methods face a challenge for balance between sparsity and the availability of expert knowledge: enhancing performance through increased use of expert knowledge often results in diminishing sparsity during expert selection. To mitigate this contradiction, we propose HyperMoE, a novel MoE framework built upon Hypernetworks. This framework integrates the computational processes of MoE with the concept of knowledge transferring in multi-task learning. Specific modules generated based on the information of unselected experts serve as supplementary information, which allows the knowledge of experts not selected to be used while maintaining selection sparsity. Our comprehensive empirical evaluations across multi
    
[^20]: 基于图提示学习的药物相互作用事件预测：DDIPrompt

    DDIPrompt: Drug-Drug Interaction Event Prediction based on Graph Prompt Learning

    [https://arxiv.org/abs/2402.11472](https://arxiv.org/abs/2402.11472)

    基于图提示学习的DDIPrompt框架旨在解决药物相互作用事件预测中的高度不平衡事件分布和罕见事件标记数据稀缺性问题。

    

    最近，由于其在建模药物分子内部和之间原子和功能团之间复杂关联方面的熟练表现，图神经网络在预测药物相互作用事件（DDI）方面变得日益普遍。然而，它们仍然受到两个重大挑战的制约：（1）高度不平衡事件分布的问题，在医学数据集中这是一个常见但关键的问题，某些相互作用被广泛地低估。这种不平衡对实现准确可靠的DDI预测构成了重大障碍。（2）罕见事件标记数据的稀缺性，在医学领域是一个普遍问题，由于数据有限，往往忽视或研究不足的罕见但潜在关键的相互作用。为此，我们提出了DDIPrompt，这是一种受最近图提示学进展启发的创新良方。我们的框架旨在解决这些问题。

    arXiv:2402.11472v1 Announce Type: cross  Abstract: Recently, Graph Neural Networks have become increasingly prevalent in predicting adverse drug-drug interactions (DDI) due to their proficiency in modeling the intricate associations between atoms and functional groups within and across drug molecules. However, they are still hindered by two significant challenges: (1) the issue of highly imbalanced event distribution, which is a common but critical problem in medical datasets where certain interactions are vastly underrepresented. This imbalance poses a substantial barrier to achieving accurate and reliable DDI predictions. (2) the scarcity of labeled data for rare events, which is a pervasive issue in the medical field where rare yet potentially critical interactions are often overlooked or under-studied due to limited available data. In response, we offer DDIPrompt, an innovative panacea inspired by the recent advancements in graph prompting. Our framework aims to address these issue
    
[^21]: 准则崩溃和损失分布控制

    Criterion collapse and loss distribution control

    [https://arxiv.org/abs/2402.09802](https://arxiv.org/abs/2402.09802)

    该论文研究了"准则崩溃"的概念，即优化一个度量指标意味着另一个度量指标的最优性。研究结果发现，对于损失的伯努利分布，CVaR和DRO的结果远超出现有研究，同时发现了一些特定条件下，单调准则如倾斜ERM无法避免崩溃，而非单调的替代方案可以。

    

    在这项工作中，我们考虑了"准则崩溃"的概念，即优化一个度量指标意味着另一个度量指标的最优性，特别关注各种学习准则下崩溃成误差概率最小化器的条件，从DRO和OCE风险（CVaR、倾斜ERM）到文献中探索的最新上升-下降算法的非单调准则（洪水、SoftAD）。我们展示了在伯努利分布损失的背景下，CVaR和DRO的现有结果远远超越了崩溃的范围，然后扩大了我们的范围，包括代理损失，展示了像倾斜ERM这样的单调准则无法避免崩溃的条件，而非单调的替代方案可以。

    arXiv:2402.09802v1 Announce Type: cross  Abstract: In this work, we consider the notion of "criterion collapse," in which optimization of one metric implies optimality in another, with a particular focus on conditions for collapse into error probability minimizers under a wide variety of learning criteria, ranging from DRO and OCE risks (CVaR, tilted ERM) to non-monotonic criteria underlying recent ascent-descent algorithms explored in the literature (Flooding, SoftAD). We show how collapse in the context of losses with a Bernoulli distribution goes far beyond existing results for CVaR and DRO, then expand our scope to include surrogate losses, showing conditions where monotonic criteria such as tilted ERM cannot avoid collapse, whereas non-monotonic alternatives can.
    
[^22]: 使用双阶段扰动测试通过必要性和充分性进行特征归因，以进行因果解释

    Feature Attribution with Necessity and Sufficiency via Dual-stage Perturbation Test for Causal Explanation

    [https://arxiv.org/abs/2402.08845](https://arxiv.org/abs/2402.08845)

    这篇论文提出了一种使用双阶段扰动测试来进行特征归因的方法，通过计算扰动一个特征对预测变化的必要性和充分性作用的概率来衡量特征重要性。该方法能够增强特征归因方法在区分不同特征贡献方面的能力。

    

    我们研究了机器学习中的可解释性问题。为了解决这个问题，特征归因方法（FAMs）通过扰动测试来测量每个特征的贡献，其中在不同扰动下的预测差异进行比较。然而，在特征的预测变化相同的情况下，这种扰动测试可能无法准确区分不同特征的贡献。为了增强FAMs在这种具有挑战性的情况下区分不同特征贡献的能力，我们提出利用扰动一个特征对预测变化起到必要性和充分性作用的概率（PNS）作为特征重要性的度量。我们的方法，利用必要性和充分性进行特征归因（FANS），通过涉及两个阶段（事实性和干预性）的扰动测试计算PNS。在实践中，为了生成反事实样本，我们使用了一个重新...

    arXiv:2402.08845v1 Announce Type: new Abstract: We investigate the problem of explainability in machine learning.To address this problem, Feature Attribution Methods (FAMs) measure the contribution of each feature through a perturbation test, where the difference in prediction is compared under different perturbations.However, such perturbation tests may not accurately distinguish the contributions of different features, when their change in prediction is the same after perturbation.In order to enhance the ability of FAMs to distinguish different features' contributions in this challenging setting, we propose to utilize the probability (PNS) that perturbing a feature is a necessary and sufficient cause for the prediction to change as a measure of feature importance.Our approach, Feature Attribution with Necessity and Sufficiency (FANS), computes the PNS via a perturbation test involving two stages (factual and interventional).In practice, to generate counterfactual samples, we use a re
    
[^23]: Concept-1K：一种用于实例增量学习的新型基准

    Concept-1K: A Novel Benchmark for Instance Incremental Learning

    [https://arxiv.org/abs/2402.08526](https://arxiv.org/abs/2402.08526)

    我们提出了一种名为Concept-1K的具有挑战性的实例增量学习（IIL）场景和数据集，揭示了十亿参数的PLM仍然遭受灾难性遗忘，影响因素包括模型规模、预训练和缓冲区大小。现有的IL方法和LoRA技术无法满足性能需求。我们的研究为探索和缓解PLM中的遗忘问题提供了新的场景。

    

    增量学习（IL）对于实现神经网络中的人类级智能至关重要。然而，现有的IL场景和数据集无法评估PLM中的遗忘，使人误以为PLM不会遭受灾难性遗忘。为此，我们提出了一种具有挑战性的IL场景，称为实例增量学习（IIL），以及一个支持数量级更大的IL步骤的新数据集Concept-1K。基于对Concept-1K的实验，我们揭示了十亿参数的PLM仍然遭受着灾难性遗忘，并且遗忘受模型规模、预训练和缓冲区大小的影响。此外，现有的IL方法和一种流行的微调技术LoRA都未能达到令人满意的性能。我们的研究为未来研究提供了一个新的场景，探索PLM的灾难性遗忘，并鼓励设计更强大的技术以减轻PLM中的遗忘问题。

    Incremental learning (IL) is essential to realize the human-level intelligence in the neural network. However, existing IL scenarios and datasets are unqualified for assessing forgetting in PLMs, giving an illusion that PLMs do not suffer from catastrophic forgetting. To this end, we propose a challenging IL scenario called instance-incremental learning (IIL) and a novel dataset called Concept-1K, which supports an order of magnitude larger IL steps. Based on the experiments on Concept-1K, we reveal that billion-parameter PLMs still suffer from catastrophic forgetting, and the forgetting is affected by both model scale, pretraining, and buffer size. Furthermore, existing IL methods and a popular finetuning technique, LoRA, fail to achieve satisfactory performance. Our study provides a novel scenario for future studies to explore the catastrophic forgetting of PLMs and encourage more powerful techniques to be designed for alleviating the forgetting in PLMs. The data, code and scripts ar
    
[^24]: 数据污染对反事实解释的影响

    The Effect of Data Poisoning on Counterfactual Explanations

    [https://arxiv.org/abs/2402.08290](https://arxiv.org/abs/2402.08290)

    本研究研究了反事实解释在数据污染方面的脆弱性，发现最先进的反事实生成方法和工具包容易受到数据污染的影响。

    

    反事实解释是分析黑盒系统预测的一种流行方法，它们提供了根据不同情况建议改变输入以获得不同（更有利）系统输出的计算补救机会。然而，最近的研究突显了它们对不同类型操纵的脆弱性。本研究研究了反事实解释对数据污染的脆弱性。我们在增加三个不同层次的补救成本方面，形式化地研究了反事实解释在单个实例、某个子组或所有实例上的数据污染。我们证明了最先进的反事实生成方法和工具包对此类数据污染是脆弱的。

    Counterfactual explanations provide a popular method for analyzing the predictions of black-box systems, and they can offer the opportunity for computational recourse by suggesting actionable changes on how to change the input to obtain a different (i.e. more favorable) system output. However, recent work highlighted their vulnerability to different types of manipulations. This work studies the vulnerability of counterfactual explanations to data poisoning. We formalize data poisoning in the context of counterfactual explanations for increasing the cost of recourse on three different levels: locally for a single instance, or a sub-group of instances, or globally for all instances. We demonstrate that state-of-the-art counterfactual generation methods \& toolboxes are vulnerable to such data poisoning.
    
[^25]: 朝着忠实和强大的基于证据的问答专家的方向前进

    Towards Faithful and Robust LLM Specialists for Evidence-Based Question-Answering

    [https://arxiv.org/abs/2402.08277](https://arxiv.org/abs/2402.08277)

    这项工作探索了如何鲁棒地微调大型语言模型以提高答案的来源质量和答案归因能力，引入了数据生成流水线和四个测试集来评估模型的性能，并展示了在合成数据上微调可以改善内部和外部分布的性能。

    

    对大型语言模型（LLM）更忠实和可追踪的答案的进步对于各种研究和实践活动至关重要。其中一种达到这个目标的方法是基于可靠的来源提供答案。然而，这种基于证据的问答在使用LLM时已经证明在引用正确的来源（来源质量）和准确地表示来源中的信息（答案归因能力）方面工作不足。在这项工作中，我们系统地研究了如何鲁棒地微调LLM，以提高来源质量和答案归因能力。具体而言，我们引入了一个数据生成流水线，其中包括自动数据质量过滤器，可以大规模合成多样化的高质量训练和测试数据。我们还引入了四个测试集，以对微调后的专家模型的鲁棒性进行基准测试。广泛的评估结果表明，在合成数据上进行微调可以提高在内部和外部分布的性能。%基于证据的问答案例。此外，我们展示了用于评估的四个测试集，以评估微调后的专家模型的鲁棒性。

    Advances towards more faithful and traceable answers of Large Language Models (LLMs) are crucial for various research and practical endeavors. One avenue in reaching this goal is basing the answers on reliable sources. However, this Evidence-Based QA has proven to work insufficiently with LLMs in terms of citing the correct sources (source quality) and truthfully representing the information within sources (answer attributability). In this work, we systematically investigate how to robustly fine-tune LLMs for better source quality and answer attributability. Specifically, we introduce a data generation pipeline with automated data quality filters, which can synthesize diversified high-quality training and testing data at scale. We further introduce four test sets to benchmark the robustness of fine-tuned specialist models. Extensive evaluation shows that fine-tuning on synthetic data improves performance on both in- and out-of-distribution. %Evidence-Based QA cases. Furthermore, we sho
    
[^26]: 多模态学习中的文本中心对齐

    Text-centric Alignment for Multi-Modality Learning

    [https://arxiv.org/abs/2402.08086](https://arxiv.org/abs/2402.08086)

    本研究提出了一种名为文本中心对齐的多模态学习方法（TAMML），利用大型语言模型和基础模型，通过将文本作为统一的语义空间，解决了多模态学习中的模态不匹配问题，并在处理未见过的、多样化的、不可预测的模态组合时取得了显著的改进。

    

    本研究论文解决了多模态学习中的模态不匹配问题，即推理阶段可用的模态与训练阶段不同。我们提出了一种名为文本中心对齐的多模态学习（TAMML）方法，该方法利用大型语言模型（LLMs）进行上下文学习，并借助基础模型增强多模态系统在这些条件下的泛化能力。通过利用文本作为统一的语义空间的独特特性，TAMML在处理未见过的、多样化的、不可预测的模态组合方面展示出显著的改进。TAMML不仅能够适应不同的模态，还能保持稳健的性能，展示了基础模型在克服传统的固定模态框架中的表示嵌入限制方面的潜力。这项研究为领域提供了一种灵活有效的解决方案，适用于现实世界的应用，其中模态的可用性可能会变化。

    This research paper addresses the challenge of modality mismatch in multimodal learning, where the modalities available during inference differ from those available at training. We propose the Text-centric Alignment for Multi-Modality Learning (TAMML) approach, an innovative method that utilizes Large Language Models (LLMs) with in-context learning and foundation models to enhance the generalizability of multimodal systems under these conditions. By leveraging the unique properties of text as a unified semantic space, TAMML demonstrates significant improvements in handling unseen, diverse, and unpredictable modality combinations. TAMML not only adapts to varying modalities but also maintains robust performance, showcasing the potential of foundation models in overcoming the limitations of traditional fixed-modality frameworks in embedding representations. This study contributes to the field by offering a flexible, effective solution for real-world applications where modality availabili
    
[^27]: Bayesian优化中的边界探索与未知物理约束

    Boundary Exploration for Bayesian Optimization With Unknown Physical Constraints

    [https://arxiv.org/abs/2402.07692](https://arxiv.org/abs/2402.07692)

    本文提出了一种新的贝叶斯优化方法BE-CBO，通过有效地探索可行和不可行设计之间的边界，来解决在实际应用中优化未知约束的未知函数的问题。

    

    贝叶斯优化已成功应用于优化评估次数严重限制的黑盒函数。然而，在许多实际应用中，由于一些物理或系统限制，很难或者不可能事先知道哪些设计是可行的。这些问题导致了更加困难的问题，即优化未知约束的未知函数。在本文中，我们观察到在这种情况下，最优解通常位于设计空间的可行和不可行区域之间的边界上，这使得问题比具有内部最优解的情况更加困难。受到这一观察的启发，我们提出了一种新的贝叶斯优化方法BE-CBO，可以有效地探索可行和不可行设计之间的边界。为了确定边界，我们使用一组神经网络来学习约束，这些神经网络在捕捉复杂边界方面优于标准高斯过程。

    Bayesian optimization has been successfully applied to optimize black-box functions where the number of evaluations is severely limited. However, in many real-world applications, it is hard or impossible to know in advance which designs are feasible due to some physical or system limitations. These issues lead to an even more challenging problem of optimizing an unknown function with unknown constraints. In this paper, we observe that in such scenarios optimal solution typically lies on the boundary between feasible and infeasible regions of the design space, making it considerably more difficult than that with interior optima. Inspired by this observation, we propose BE-CBO, a new Bayesian optimization method that efficiently explores the boundary between feasible and infeasible designs. To identify the boundary, we learn the constraints with an ensemble of neural networks that outperform the standard Gaussian Processes for capturing complex boundaries. Our method demonstrates superio
    
[^28]: 通过条件流进行不规则时间序列的概率预测

    Probabilistic Forecasting of Irregular Time Series via Conditional Flows

    [https://arxiv.org/abs/2402.06293](https://arxiv.org/abs/2402.06293)

    该论文提出了一种使用条件流进行不规则时间序列的概率预测的新模型ProFITi。该模型通过学习条件下未来值的联合分布，对具有缺失值的不规则时间序列进行预测，而不假设底层分布的固定形状。通过引入可逆三角形注意力层和可逆非线性激活函数，该模型取得了良好的实验结果。

    

    不规则采样的多变量时间序列具有缺失值的概率预测是许多领域的重要问题，包括医疗保健、天文学和气候学。目前该任务的最先进方法仅估计单个通道和单个时间点上观测值的边际分布，假设了一个固定形状的参数分布。在这项工作中，我们提出了一种新的模型ProFITi，用于使用条件归一化流对具有缺失值的不规则采样时间序列进行概率预测。该模型学习了在过去观测和查询的通道和时间上条件下时间序列未来值的联合分布，而不假设底层分布的固定形状。作为模型组件，我们引入了一种新颖的可逆三角形注意力层和一个可逆的非线性激活函数，能够在整个实数线上进行转换。我们在四个数据集上进行了大量实验，并证明了该模型的提议。

    Probabilistic forecasting of irregularly sampled multivariate time series with missing values is an important problem in many fields, including health care, astronomy, and climate. State-of-the-art methods for the task estimate only marginal distributions of observations in single channels and at single timepoints, assuming a fixed-shape parametric distribution. In this work, we propose a novel model, ProFITi, for probabilistic forecasting of irregularly sampled time series with missing values using conditional normalizing flows. The model learns joint distributions over the future values of the time series conditioned on past observations and queried channels and times, without assuming any fixed shape of the underlying distribution. As model components, we introduce a novel invertible triangular attention layer and an invertible non-linear activation function on and onto the whole real line. We conduct extensive experiments on four datasets and demonstrate that the proposed model pro
    
[^29]: 通过学习判别超平面实现黑盒动态系统的安全过滤器

    Safety Filters for Black-Box Dynamical Systems by Learning Discriminating Hyperplanes

    [https://arxiv.org/abs/2402.05279](https://arxiv.org/abs/2402.05279)

    本文提出一种基于学习的方法，通过定义判别超平面来实现黑盒动态系统的安全过滤器。我们的方法不仅可以消除对特定证明函数的依赖，还简化了安全过滤器的设计。

    

    基于学习的方法正在成为黑盒动态系统的安全过滤器的有效途径。现有方法依赖证明函数（如控制界面函数（CBFs）和哈密顿-雅可比（HJ）可达性值函数）。我们工作的主要动机是认识到最终将安全约束作为每个状态的控制输入约束来强制执行才是最重要的。通过专注于这个约束，我们可以消除对任何特定证明函数设计的依赖性。为了实现这一点，我们定义了一个判别超平面，用于在每个状态上形成控制输入的半空间约束，作为安全的充分条件。这个概念不仅广泛适用传统的安全方法，而且通过消除对特定证明函数的依赖，简化了安全过滤器的设计。我们提出了两种学习判别超平面的策略：（a）监督学习方法，使用预先验证的证明函数信息来训练模型；（b）加速回归的方法，通过迭代生成判别超平面。

    Learning-based approaches are emerging as an effective approach for safety filters for black-box dynamical systems. Existing methods have relied on certificate functions like Control Barrier Functions (CBFs) and Hamilton-Jacobi (HJ) reachability value functions. The primary motivation for our work is the recognition that ultimately, enforcing the safety constraint as a control input constraint at each state is what matters. By focusing on this constraint, we can eliminate dependence on any specific certificate function-based design. To achieve this, we define a discriminating hyperplane that shapes the half-space constraint on control input at each state, serving as a sufficient condition for safety. This concept not only generalizes over traditional safety methods but also simplifies safety filter design by eliminating dependence on specific certificate functions. We present two strategies to learn the discriminating hyperplane: (a) a supervised learning approach, using pre-verified c
    
[^30]: AONeuS: 一种用于声光传感器融合的神经渲染框架

    AONeuS: A Neural Rendering Framework for Acoustic-Optical Sensor Fusion

    [https://arxiv.org/abs/2402.03309](https://arxiv.org/abs/2402.03309)

    AONeuS是一种基于物理的多模态声光神经表面重建框架，通过融合高分辨率RGB测量和低分辨率深度成像声纳测量，能够在受限基线下实现准确的高分辨率三维表面重建。

    

    水下感知和三维表面重建是具有广泛应用的挑战性问题，涉及建筑、安全、海洋考古和环境监测等领域。恶劣的操作条件、脆弱的环境和有限的导航控制通常导致水下航行器限制其运动范围和测量基线。在三维场景重建的背景下，我们知道较小的基线会增加重建难度。本文开发了一种基于物理的多模态声光神经表面重建框架（AONeuS），能够有效地将高分辨率RGB测量与低分辨率深度成像声纳测量进行融合。通过融合这些互补的模态，我们的框架可以从在受限基线上捕获的测量中重建出准确的高分辨率三维表面。通过大量的模拟和实验室实验，我们证明了...

    Underwater perception and 3D surface reconstruction are challenging problems with broad applications in construction, security, marine archaeology, and environmental monitoring. Treacherous operating conditions, fragile surroundings, and limited navigation control often dictate that submersibles restrict their range of motion and, thus, the baseline over which they can capture measurements. In the context of 3D scene reconstruction, it is well-known that smaller baselines make reconstruction more challenging. Our work develops a physics-based multimodal acoustic-optical neural surface reconstruction framework (AONeuS) capable of effectively integrating high-resolution RGB measurements with low-resolution depth-resolved imaging sonar measurements. By fusing these complementary modalities, our framework can reconstruct accurate high-resolution 3D surfaces from measurements captured over heavily-restricted baselines. Through extensive simulations and in-lab experiments, we demonstrate tha
    
[^31]: LLaMA和ChatGPT嵌入在分子嵌入中的比较分析

    Comparative Analysis of LLaMA and ChatGPT Embeddings for Molecule Embedding

    [https://arxiv.org/abs/2402.00024](https://arxiv.org/abs/2402.00024)

    LLaMA和ChatGPT比较分析了它们在SMILES字符串嵌入中的性能，在分子性质预测和药物-药物相互作用预测中，LLaMA相对于ChatGPT表现更好并且与现有方法相当。

    

    目的：ChatGPT和LLaMA等大型语言模型在化学信息学领域越来越受到重视，特别是在解释Simplified Molecular Input Line Entry System (SMILES)方面。这些语言模型可以将SMILES字符串解码为向量表示，为理解化学图提供了一种新的方法。方法：我们研究了ChatGPT和LLaMA在嵌入SMILES字符串方面的性能。我们的评估集中在两个关键应用领域：分子性质（MP）预测和药物-药物相互作用（DDI）预测，这在药物开发和医疗保健中至关重要。结果：我们发现，使用LLaMA生成的SMILES嵌入在MP和DDI预测任务中表现优于ChatGPT。值得注意的是，基于LLaMA的SMILES嵌入在这两个预测任务中显示了与现有方法相当的结果。结论：在化学信息学中应用LLMs，特别是在利用SMILES进行嵌入方面，是可行的。

    Purpose: Large Language Models (LLMs) like ChatGPT and LLaMA are increasingly recognized for their potential in the field of cheminformatics, particularly in interpreting Simplified Molecular Input Line Entry System (SMILES), a standard method for representing chemical structures. These LLMs can decode SMILES strings into vector representations, providing a novel approach to understanding chemical graphs.   Methods: We investigate the performance of ChatGPT and LLaMA in embedding SMILES strings. Our evaluation focuses on two key applications: molecular property (MP) prediction and drug-drug interaction (DDI) prediction, both essential in drug development and healthcare.   Results: We find that SMILES embeddings generated using LLaMA outperform those from ChatGPT in both MP and DDI prediction tasks. Notably, LLaMA-based SMILES embeddings show results comparable to existing methods in both prediction tasks.   Conclusion: The application of LLMs in cheminformatics, particularly in utilizi
    
[^32]: 通过定向表示优化实现的安全提示驱动的大型语言模型(LLM)保护

    Prompt-Driven LLM Safeguarding via Directed Representation Optimization

    [https://arxiv.org/abs/2401.18018](https://arxiv.org/abs/2401.18018)

    通过研究模型表示的影响，我们发现安全提示并没有明显增强恶意和无害查询之间的区分，并提出了一种名为DRO的方法，用于自动优化安全提示。

    

    在大型语言模型(LLM)中，使用安全提示在模型输入之前是一种常见的保护实践，以使其不遵从包含恶意意图的查询。然而，安全提示的工作机制尚未完全理解，这妨碍了自动优化其以改善LLM安全性的潜力。针对这个问题，我们从模型表示的角度调查了安全提示的影响。我们发现在模型的表示空间中，有害和无害的查询可以在很大程度上区分开来，但安全提示并没有明显增强这一区分。相反，不同安全提示导致查询的表示朝着相似的方向移动，使得模型即使在查询无害时也更容易拒绝提供协助。受到这些发现的启发，我们提出了一种名为DRO（定向表示优化）的方法，用于自动安全提示优化。DRO将安全提示视为要优化的表示方向。

    Prepending model inputs with safety prompts is a common practice of safeguarding large language models (LLMs) from complying with queries that contain harmful intents. However, the working mechanisms of safety prompts have not yet been fully understood, which hinders the potential for automatically optimizing them for improved LLM safety. Motivated by this problem, we investigate the impact of safety prompts from the perspective of model representations. We find that in models' representation space, harmful and harmless queries can be largely distinguished, but this is not noticeably enhanced by safety prompts. Instead, the queries' representations are moved by different safety prompts in similar directions, where models become more prone to refusal (i.e., refusing to provide assistance) even when the queries are harmless. Inspired by these findings, we propose a method called DRO (Directed Representation Optimization) for automatic safety prompt optimization. DRO treats safety prompts
    
[^33]: 敏捷但安全：学习无碰撞高速四足机器人行走

    Agile But Safe: Learning Collision-Free High-Speed Legged Locomotion

    [https://arxiv.org/abs/2401.17583](https://arxiv.org/abs/2401.17583)

    本文介绍了一种名为敏捷但安全（ABS）的学习控制框架，能够实现四足机器人的敏捷且无碰撞行走。该框架通过一个学习得到的控制论到达-避免值网络来实现策略切换，并通过协作运行的敏捷策略和恢复策略，使机器人能够高速且安全地导航。

    

    在杂乱环境中行走的四足机器人必须既敏捷以提高任务执行效率，又要确保安全，避免与障碍物或人碰撞。现有的研究要么开发保守的控制器（速度小于1.0 m/s）以确保安全，要么专注于敏捷性而未考虑潜在致命的碰撞。本文介绍了敏捷但安全（ABS）的学习控制框架，为四足机器人实现了敏捷且无碰撞的行走。ABS包括一个敏捷策略来在障碍物中执行灵活的动作技能，并且有一个恢复策略来避免失败，共同实现高速且无碰撞的导航。ABS中的策略切换由一个学习得到的控制论到达-避免值网络控制，该网络也指导恢复策略作为目标函数，从而在闭环中保护机器人。训练过程涉及敏捷策略、到达-避免值网络、恢复策略和外感知表征的学习。

    Legged robots navigating cluttered environments must be jointly agile for efficient task execution and safe to avoid collisions with obstacles or humans. Existing studies either develop conservative controllers (< 1.0 m/s) to ensure safety, or focus on agility without considering potentially fatal collisions. This paper introduces Agile But Safe (ABS), a learning-based control framework that enables agile and collision-free locomotion for quadrupedal robots. ABS involves an agile policy to execute agile motor skills amidst obstacles and a recovery policy to prevent failures, collaboratively achieving high-speed and collision-free navigation. The policy switch in ABS is governed by a learned control-theoretic reach-avoid value network, which also guides the recovery policy as an objective function, thereby safeguarding the robot in a closed loop. The training process involves the learning of the agile policy, the reach-avoid value network, the recovery policy, and an exteroception repre
    
[^34]: 一种用于加速反向建模的生成模型，使用了一种连续变量的新型嵌入

    A Generative Model for Accelerated Inverse Modelling Using a Novel Embedding for Continuous Variables

    [https://arxiv.org/abs/2311.11343](https://arxiv.org/abs/2311.11343)

    提出了一种用于加速反向建模的生成模型，利用了新型的连续变量嵌入策略，消除了归一化的需要，保留信息并创造了一个多功能的嵌入空间。

    

    在材料科学中，快速原型制作具有所需性能的材料的挑战通常涉及大量的实验，以找到合适的微结构。此外，对于给定性能寻找微结构通常是一个不适定问题，可能存在多个解决方案。使用生成式机器学习模型可以是一个可行的解决方案，同时减少计算成本。然而，这也带来了新的挑战，例如，需要将连续属性变量作为模型的条件输入。我们研究了现有方法的缺点，并将其与一种基于浮点数的二进制表示的生成模型的新型嵌入策略进行了比较。这种方法消除了归一化的需要，保留了信息，并为生成模型的条件提供了一个多功能的嵌入空间。

    arXiv:2311.11343v2 Announce Type: replace  Abstract: In materials science, the challenge of rapid prototyping materials with desired properties often involves extensive experimentation to find suitable microstructures. Additionally, finding microstructures for given properties is typically an ill-posed problem where multiple solutions may exist. Using generative machine learning models can be a viable solution which also reduces the computational cost. This comes with new challenges because, e.g., a continuous property variable as conditioning input to the model is required. We investigate the shortcomings of an existing method and compare this to a novel embedding strategy for generative models that is based on the binary representation of floating point numbers. This eliminates the need for normalization, preserves information, and creates a versatile embedding space for conditioning the generative model. This technique can be applied to condition a network on any number, to provide 
    
[^35]: 隐式神经码书的残余量化方法

    Residual Quantization with Implicit Neural Codebooks. (arXiv:2401.14732v1 [cs.LG])

    [http://arxiv.org/abs/2401.14732](http://arxiv.org/abs/2401.14732)

    本文提出了QINCo，一种神经网络残余量化变体，通过预测每个矢量的专门码书，提高了准确性，并在多个数据集和码书大小上优于现有方法。

    

    矢量量化是数据压缩和矢量搜索的基本操作。为了获得高准确性，多码书方法通过使用多个码书中的码字来表示每个矢量来增加速率。残余量化（RQ）是一种方法，通过迭代量化上一步的误差来提高准确性。然而，误差分布依赖于先前选择的码字，在传统RQ中未对此进行考虑，因为它在每个量化步骤中使用通用码书。在本文中，我们提出了QINCo，一种神经网络残余量化变体，它使用神经网络来预测每个矢量的专门码书，条件是先前步骤的向量近似。实验证明，在多个数据集和码书大小上，QINCo的性能优于现有方法很多。例如，QINCo使用12字节的码字在BigANN上比使用16字节的其他方法实现更好的最近邻搜索准确性。

    Vector quantization is a fundamental operation for data compression and vector search. To obtain high accuracy, multi-codebook methods increase the rate by representing each vector using codewords across multiple codebooks. Residual quantization (RQ) is one such method, which increases accuracy by iteratively quantizing the error of the previous step. The error distribution is dependent on previously selected codewords. This dependency is, however, not accounted for in conventional RQ as it uses a generic codebook per quantization step. In this paper, we propose QINCo, a neural RQ variant which predicts specialized codebooks per vector using a neural network that is conditioned on the approximation of the vector from previous steps. Experiments show that QINCo outperforms state-of-the-art methods by a large margin on several datasets and code sizes. For example, QINCo achieves better nearest-neighbor search accuracy using 12 bytes codes than other methods using 16 bytes on the BigANN a
    
[^36]: 利用神经网络进行大气密度自适应的火星精准进入导航

    Precision Mars Entry Navigation with Atmospheric Density Adaptation via Neural Networks. (arXiv:2401.14411v1 [cs.LG])

    [http://arxiv.org/abs/2401.14411](http://arxiv.org/abs/2401.14411)

    这项工作介绍了一种利用神经网络进行火星进入导航的新方法，使用神经网络估计大气密度，并根据估计的不确定性进行实时参数调整，以提高导航滤波器的性能。

    

    真实的火星大气密度与机载密度模型之间的差异会严重影响航天器进入导航滤波器的性能。本文介绍了一种新的火星进入在线滤波方法，使用神经网络估计大气密度，并利用一种考虑分析来考虑估计的不确定性。网络以指数大气密度模型进行训练，并实时动态调整它的参数，以适应真实密度与估计密度之间的任何不匹配。网络的调整被形式化为最大似然问题，利用滤波器的测量创新来识别最佳网络参数。神经网络的应用使得可以在最大似然方法的背景下使用在机器学习领域高效的随机优化器。与之前的方法进行了性能比较。

    Discrepancies between the true Martian atmospheric density and the onboard density model can significantly impair the performance of spacecraft entry navigation filters. This work introduces a new approach to online filtering for Martian entry by using a neural network to estimate atmospheric density and employing a consider analysis to account for the uncertainty in the estimate. The network is trained on an exponential atmospheric density model, and its parameters are dynamically adapted in real time to account for any mismatches between the true and estimated densities. The adaptation of the network is formulated as a maximum likelihood problem, leveraging the measurement innovations of the filter to identify optimal network parameters. The incorporation of a neural network enables the use of stochastic optimizers known for their efficiency in the machine learning domain within the context of the maximum likelihood approach. Performance comparisons against previous approaches are co
    
[^37]: 基于混合密度网络的纳米光子学逆向建模中的迁移学习辅助

    Transfer learning-assisted inverse modeling in nanophotonics based on mixture density networks. (arXiv:2401.12254v1 [cs.LG])

    [http://arxiv.org/abs/2401.12254](http://arxiv.org/abs/2401.12254)

    本文提出了一种基于迁移学习增强的混合密度网络模型的纳米光子结构逆向建模方法，可以高效地预测多个可能的解决方案。

    

    纳米光子结构的模拟依赖于电磁求解器，在理解其行为方面起着关键作用。然而，这些求解器通常具有显著的计算成本，使得它们在优化等设计任务中的应用变得不切实际。为了解决这个挑战，已经探索了机器学习技术，用于精确和高效地建模和设计光子器件。深度神经网络在这个领域特别受到关注。它们可以用于创建前向模型和逆向模型。逆向建模方法避免了将前向模型与优化器耦合的需求，并直接执行最佳设计参数值的预测。

    The simulation of nanophotonic structures relies on electromagnetic solvers, which play a crucial role in understanding their behavior. However, these solvers often come with a significant computational cost, making their application in design tasks, such as optimization, impractical. To address this challenge, machine learning techniques have been explored for accurate and efficient modeling and design of photonic devices. Deep neural networks, in particular, have gained considerable attention in this field. They can be used to create both forward and inverse models. An inverse modeling approach avoids the need for coupling a forward model with an optimizer and directly performs the prediction of the optimal design parameters values.  In this paper, we propose an inverse modeling method for nanophotonic structures, based on a mixture density network model enhanced by transfer learning. Mixture density networks can predict multiple possible solutions at a time including their respectiv
    
[^38]: 黑客攻击预测器意味着黑客攻击汽车：利用敏感性分析识别自动驾驶安全中的轨迹预测漏洞

    Hacking Predictors Means Hacking Cars: Using Sensitivity Analysis to Identify Trajectory Prediction Vulnerabilities for Autonomous Driving Security. (arXiv:2401.10313v1 [cs.CR])

    [http://arxiv.org/abs/2401.10313](http://arxiv.org/abs/2401.10313)

    本文通过对两个轨迹预测模型进行敏感性分析，发现尽管图像地图对于这两个模型的预测输出可能只有轻微的贡献，但使用快速梯度符号法制作的不可检测的图像地图扰动可以导致预测误差大幅增加，从而破坏自动驾驶系统的轨迹预测性能。

    

    对基于学习的轨迹预测器的对抗攻击已经得到了证明，但是关于除了状态历史以外的轨迹预测器输入的扰动效果以及这些攻击对下游规划和控制的影响仍然存在一些问题。在本文中，我们对两个轨迹预测模型Trajectron++和AgentFormer进行了敏感性分析。我们观察到，在所有的输入中，Trajectron++的几乎所有扰动敏感性仅限于最近的状态历史时间点，而AgentFormer的扰动敏感性则分布在随时间变化的状态历史中。我们还演示了尽管对状态历史的扰动具有主导的敏感性，但使用快速梯度符号法制作的不可检测的图像地图扰动可以导致这两个模型中的预测误差大幅增加。尽管图像地图对于这两个模型的预测输出可能只有轻微的贡献，但这个结果揭示了一个问题：攻击者可以通过扰动图像地图来破坏自动驾驶系统的轨迹预测性能。

    Adversarial attacks on learning-based trajectory predictors have already been demonstrated. However, there are still open questions about the effects of perturbations on trajectory predictor inputs other than state histories, and how these attacks impact downstream planning and control. In this paper, we conduct a sensitivity analysis on two trajectory prediction models, Trajectron++ and AgentFormer. We observe that between all inputs, almost all of the perturbation sensitivities for Trajectron++ lie only within the most recent state history time point, while perturbation sensitivities for AgentFormer are spread across state histories over time. We additionally demonstrate that, despite dominant sensitivity on state history perturbations, an undetectable image map perturbation made with the Fast Gradient Sign Method can induce large prediction error increases in both models. Even though image maps may contribute slightly to the prediction output of both models, this result reveals that
    
[^39]: 深度集成形状校准：在线广告中的多场后处理校准

    Deep Ensemble Shape Calibration: Multi-Field Post-hoc Calibration in Online Advertising. (arXiv:2401.09507v1 [cs.LG])

    [http://arxiv.org/abs/2401.09507](http://arxiv.org/abs/2401.09507)

    这篇论文介绍了一种用于解决电子商务广告中多场后处理校准问题的方法。该方法通过训练校准器，并在在线推断过程中应用这些校准器来实现形状校准和数值校准。

    

    在电子商务广告场景中，估计CTR和CVR的真实概率（称为校准估计）是至关重要的，直接影响买方、卖方和平台的利益。先前的研究已经提出了许多解决校准问题的方法。这些方法通常涉及使用验证集训练校准器，并随后在在线推断过程中应用这些校准器来修正原始估计值。然而，电子商务广告场景的挑战在于多场校准。多场校准可以分为两个不同的子问题：数值校准和形状校准。数值校准被定义为每个关注领域下每个数值的不过度或不低估。形状校准被定义为在关注领域条件下特定范围内每个pCTR子集的不过度或不低估。为了实现形状校准和数值校准，我们提出了一种深度集成形状校准的方法。

    In the e-commerce advertising scenario, estimating the true probabilities (known as a calibrated estimate) on CTR and CVR is critical and can directly affect the benefits of the buyer, seller and platform. Previous research has introduced numerous solutions for addressing the calibration problem. These methods typically involve the training of calibrators using a validation set and subsequently applying these calibrators to correct the original estimated values during online inference. However, what sets e-commerce advertising scenarios is the challenge of multi-field calibration. Multi-field calibration can be subdivided into two distinct sub-problems: value calibration and shape calibration. Value calibration is defined as no over- or under-estimation for each value under concerned fields. Shape calibration is defined as no over- or under-estimation for each subset of the pCTR within the specified range under condition of concerned fields. In order to achieve shape calibration and va
    
[^40]: 学习可解释且性能更好的POMDP策略表示

    Learning Explainable and Better Performing Representations of POMDP Strategies. (arXiv:2401.07656v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2401.07656](http://arxiv.org/abs/2401.07656)

    本研究提出了一种学习部分可观测的马尔可夫决策过程（POMDP）策略自动机表示的方法。与传统的表格表示相比，该方法得到的自动机更小更易理解，且在学习过程中可改善策略性能。与其他方法相比，本方法在可扩展性上具有显著优势。

    

    部分可观测的马尔可夫决策过程（POMDP）的策略通常需要记忆。一种表示这种记忆的方法是使用自动机。我们提出了一种使用改进的L*算法学习策略的自动机表示的方法。与策略的表格表示相比，得到的自动机体积显著更小，因此更易于理解。此外，在学习过程中，我们的启发式方法甚至可以改善策略的性能。与直接从POMDP合成自动机以解决问题的方法相比，我们的方法具有不可比拟的可扩展性。

    Strategies for partially observable Markov decision processes (POMDP) typically require memory. One way to represent this memory is via automata. We present a method to learn an automaton representation of a strategy using a modification of the L*-algorithm. Compared to the tabular representation of a strategy, the resulting automaton is dramatically smaller and thus also more explainable. Moreover, in the learning process, our heuristics may even improve the strategy's performance. In contrast to approaches that synthesize an automaton directly from the POMDP thereby solving it, our approach is incomparably more scalable.
    
[^41]: 多语言指令调优中的多语言性

    Multilingual Instruction Tuning With Just a Pinch of Multilinguality. (arXiv:2401.01854v1 [cs.CL])

    [http://arxiv.org/abs/2401.01854](http://arxiv.org/abs/2401.01854)

    本研究研究了多语言指令调优中的多语言性对跨语言指令遵循的影响。研究发现，即使在单语调优过程中，许多语言也可以将一些指令遵循能力转移到其他语言上。此外，只有40个多语言示例能够显著提高多语言指令遵循。总体来说，多语言混合调优的模型在多种语言上的表现相比单语调优的模型要好或者不相上下，尽管使用的这些语言的训练示例数量只有10倍少。

    

    随着大型语言模型（LLMs）的全球采纳，它们在多语言指令遵循能力变得越来越重要。一种有前途的方法是跨语言转移，通过在另一种语言上微调，模型可以在某种语言上获得特定的功能。本文研究了多语言LLM在指令调优过程中的多语言性对跨语言指令遵循的影响。首先我们发现，即使在单语调优过程中，许多语言也可以将一些指令遵循能力转移到其他语言上。此外，我们发现在英语调优集合中，只有40个多语言示例能够显著提高多语言指令遵循，在调优过程中不论是已见语言还是未见语言。总的来说，我们观察到在多语言混合调优的模型在多种语言上的表现相比单语调优的模型要好或者不相上下，尽管使用的这些语言的训练示例数量只有10倍少。

    As instruction-tuned large language models (LLMs) gain global adoption, their ability to follow instructions in multiple languages becomes increasingly crucial. One promising approach is cross-lingual transfer, where a model acquires specific functionality on some language by finetuning on another language. In this work, we investigate how multilinguality during instruction tuning of a multilingual LLM affects instruction-following across languages. We first show that many languages transfer some instruction-following capabilities to other languages from even monolingual tuning. Furthermore, we find that only 40 multilingual examples in an English tuning set substantially improve multilingual instruction-following, both in seen and unseen languages during tuning. In general, we observe that models tuned on multilingual mixtures exhibit comparable or superior performance in several languages compared to monolingually tuned models, despite training on 10x fewer examples in those language
    
[^42]: 用扩散模型进行量子电路合成

    Quantum circuit synthesis with diffusion models. (arXiv:2311.02041v1 [quant-ph])

    [http://arxiv.org/abs/2311.02041](http://arxiv.org/abs/2311.02041)

    该论文提出了一种利用扩散模型进行量子电路合成的方法，通过使用生成式机器学习模型，可以在基于门的量子电路中产生所需的量子操作，而且能够绕过经典模拟量子动力学的指数级开销。实验证明该模型在纠缠生成和酉编译等任务中表现优秀，并支持扩展功能以适应不同的量子设备约束条件。

    

    量子计算最近成为一项具有变革性的技术。然而，它所承诺的优势依赖于将量子操作有效地转化为可行的物理实现。在此工作中，我们使用生成式机器学习模型，具体而言是去噪扩散模型（DMs），以促进这种转化。通过文本条件，我们引导模型在基于门的量子电路中产生所需的量子操作。值得注意的是，DMs允许在训练过程中避免经典模拟量子动力学中固有的指数级开销，这是先前机器学习技术中一直存在的瓶颈。我们在两个任务上展示了该模型的能力：纠缠生成和酉编译。该模型在生成新电路方面表现出色，并支持典型的DM扩展，例如掩码和编辑，以使电路生成符合目标量子设备的约束条件。由于其灵活性和泛化能力，我们的方法可以应用于各种量子任务。

    Quantum computing has recently emerged as a transformative technology. Yet, its promised advantages rely on efficiently translating quantum operations into viable physical realizations. In this work, we use generative machine learning models, specifically denoising diffusion models (DMs), to facilitate this transformation. Leveraging text-conditioning, we steer the model to produce desired quantum operations within gate-based quantum circuits. Notably, DMs allow to sidestep during training the exponential overhead inherent in the classical simulation of quantum dynamics -- a consistent bottleneck in preceding ML techniques. We demonstrate the model's capabilities across two tasks: entanglement generation and unitary compilation. The model excels at generating new circuits and supports typical DM extensions such as masking and editing to, for instance, align the circuit generation to the constraints of the targeted quantum device. Given their flexibility and generalization abilities, we
    
[^43]: MIR2:面向通过互信息正则化进行可证明鲁棒多智能体强化学习

    MIR2: Towards Provably Robust Multi-Agent Reinforcement Learning by Mutual Information Regularization. (arXiv:2310.09833v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.09833](http://arxiv.org/abs/2310.09833)

    MIR2提出了一种针对鲁棒多智能体强化学习的方法，通过在常规情况下训练策略并最小化互信息作为鲁棒正则化，实现了在不准备每种可能的最坏情况的情况下提升鲁棒性的目标。

    

    鲁棒多智能体强化学习(MARL)对于未知盟友的不确定或最坏情况行动需要具备弹性。现有的鲁棒MARL中的最大最小优化技术通过训练智能体抵抗最坏情况的对手来增强鲁棒性，但随着智能体数量的增加，这种方法变得难以操作，导致最坏情况的数量呈指数级增长。试图简化这种复杂性往往会导致过于悲观的策略、在各种情况下鲁棒性不足和高计算需求。与这些方法不同，人类在学习适应性和鲁棒行为时自然而然地不需要准备每种可能的最坏情况。受此启发，我们提出了MIR2，它在常规情况下训练策略，并将互信息最小化作为鲁棒正则化。从理论上讲，我们将鲁棒性视为一个推理问题，并证明了在历史和行动之间最小化互信息隐含地最大化了鲁棒性的下界。

    Robust multi-agent reinforcement learning (MARL) necessitates resilience to uncertain or worst-case actions by unknown allies. Existing max-min optimization techniques in robust MARL seek to enhance resilience by training agents against worst-case adversaries, but this becomes intractable as the number of agents grows, leading to exponentially increasing worst-case scenarios. Attempts to simplify this complexity often yield overly pessimistic policies, inadequate robustness across scenarios and high computational demands. Unlike these approaches, humans naturally learn adaptive and resilient behaviors without the necessity of preparing for every conceivable worst-case scenario. Motivated by this, we propose MIR2, which trains policy in routine scenarios and minimize Mutual Information as Robust Regularization. Theoretically, we frame robustness as an inference problem and prove that minimizing mutual information between histories and actions implicitly maximizes a lower bound on robust
    
[^44]: TimeGPT-1. (arXiv:2310.03589v1 [cs.LG]) - 时间序列的基础模型

    TimeGPT-1. (arXiv:2310.03589v1 [cs.LG])

    [http://arxiv.org/abs/2310.03589](http://arxiv.org/abs/2310.03589)

    TimeGPT是第一个面向时间序列的基础模型，能够生成准确的预测。它在性能、效率和简洁性方面优于现有的统计学、机器学习和深度学习方法。我们的研究提供了有力的证据，表明借鉴其他人工智能领域的见解可以有效应用于时间序列分析。大规模时间序列模型有望民主化访问精确的预测并减少不确定性。

    

    在本文中，我们介绍了TimeGPT，这是第一个面向时间序列的基础模型，能够对训练过程中未见过的各种数据集生成准确的预测。我们将预训练的模型与已建立的统计学、机器学习和深度学习方法进行了评估，结果表明TimeGPT的零-shot推理在性能、效率和简洁性方面表现出色。我们的研究提供了有力的证据，表明人工智能的其他领域的见解可以有效地应用于时间序列分析。我们得出结论，大规模时间序列模型为人们提供了一个令人兴奋的机会，通过利用当代深度学习的能力，民主化访问精确的预测并减少不确定性。

    In this paper, we introduce TimeGPT, the first foundation model for time series, capable of generating accurate predictions for diverse datasets not seen during training. We evaluate our pre-trained model against established statistical, machine learning, and deep learning methods, demonstrating that TimeGPT zero-shot inference excels in performance, efficiency, and simplicity. Our study provides compelling evidence that insights from other domains of artificial intelligence can be effectively applied to time series analysis. We conclude that large-scale time series models offer an exciting opportunity to democratize access to precise predictions and reduce uncertainty by leveraging the capabilities of contemporary advancements in deep learning.
    
[^45]: FedLPA: 使用分层后验聚合的个性化单次联邦学习

    FedLPA: Personalized One-shot Federated Learning with Layer-Wise Posterior Aggregation. (arXiv:2310.00339v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.00339](http://arxiv.org/abs/2310.00339)

    本文提出了一种名为FedLPA的新颖方法，采用分层后验聚合的方式实现个性化单次联邦学习。FedLPA能够高效地将本地模型聚合到全局模型，解决了单次聚合在非相同训练数据分布下的性能问题。

    

    将本地客户端训练的神经网络高效地聚合到服务器上的全局模型是联邦学习中的一个广泛研究课题。最近，受到隐私问题减少、潜在攻击减弱和通信开销降低的推动，单次联邦学习（即将客户端与服务器间的通信限制为一轮）在研究者中越来越受欢迎。然而，单次聚合的性能容易受到非相同训练数据分布的影响，在一些实际场景中表现出高度的统计异质性。为了解决这个问题，我们提出了一种新颖的单次聚合方法——分层后验聚合（FedLPA）。FedLPA能够聚合本地模型，获得更准确的全局模型，而无需额外的辅助数据集或暴露任何机密的本地信息，比如标签分布。

    Efficiently aggregating trained neural networks from local clients into a global model on a server is a widely researched topic in federated learning. Recently, motivated by diminishing privacy concerns, mitigating potential attacks, and reducing the overhead of communication, one-shot federated learning (i.e., limiting client-server communication into a single round) has gained popularity among researchers. However, the one-shot aggregation performances are sensitively affected by the non-identical training data distribution, which exhibits high statistical heterogeneity in some real-world scenarios. To address this issue, we propose a novel one-shot aggregation method with Layer-wise Posterior Aggregation, named FedLPA. FedLPA aggregates local models to obtain a more accurate global model without requiring extra auxiliary datasets or exposing any confidential local information, e.g., label distributions. To effectively capture the statistics maintained in the biased local datasets in
    
[^46]: EnCodecMAE: 利用神经编解码器进行通用音频表示学习

    EnCodecMAE: Leveraging neural codecs for universal audio representation learning. (arXiv:2309.07391v1 [cs.SD])

    [http://arxiv.org/abs/2309.07391](http://arxiv.org/abs/2309.07391)

    本文提出了一种称为EnCodecMAE的方法，利用神经编解码器EnCodec生成离散目标，用于基于遮蔽自动编码器（MAE）学习通用音频模型。通过在涵盖语音、音乐和环境声音的多个音频任务上的评估，发现EnCodecMAE达到了与领先的音频表示模型相当甚至更好的性能。

    

    通用音频表示学习的目标是获得可以用于涉及语音、音乐或环境声音的各种后续任务的基础模型。为了解决这个问题，通常使用受自监督模型（如BERT）启发的方法，并将其应用于音频。这些模型依赖于文本的离散性质，因此采用这种方法来处理音频需要改变学习目标或将音频信号映射到一组离散类别。在这项工作中，我们探索了使用神经音频编解码器EnCodec生成用于基于遮蔽自动编码器（MAE）学习通用音频模型的离散目标的方法。我们评估了该方法，称之为EnCodecMAE，在涵盖语音、音乐和环境声音的广泛音频任务上，其性能相当或优于领先的音频表示模型。

    The goal of universal audio representation learning is to obtain foundational models that can be used for a variety of downstream tasks involving speech, music or environmental sounds. To approach this problem, methods inspired by self-supervised models from NLP, like BERT, are often used and adapted to audio. These models rely on the discrete nature of text, hence adopting this type of approach for audio processing requires either a change in the learning objective or mapping the audio signal to a set of discrete classes. In this work, we explore the use of EnCodec, a neural audio codec, to generate discrete targets for learning an universal audio model based on a masked autoencoder (MAE). We evaluate this approach, which we call EncodecMAE, on a wide range of audio tasks spanning speech, music and environmental sounds, achieving performances comparable or better than leading audio representation models.
    
[^47]: 通过机器学习进行适应度近似

    Fitness Approximation through Machine Learning. (arXiv:2309.03318v1 [cs.NE])

    [http://arxiv.org/abs/2309.03318](http://arxiv.org/abs/2309.03318)

    我们提出了一种使用机器学习模型在遗传算法中进行适应度近似的方法。实验结果表明，这种方法显著提高了进化运行时间，并且适应度得分要么与完全运行的遗传算法相同，要么稍微低一点。

    

    我们提出了一种新颖的方法，使用机器学习模型在遗传算法中进行适应度近似，重点是在Gymnasium（游戏）模拟器中的进化代理上 - 在这里适应度计算是昂贵的。我们维护一个采样个体及其实际适应度得分的数据集，并在整个进化过程中不断更新一个适应度近似的机器学习模型。我们比较了不同的方法：1）在实际适应度和近似适应度之间切换，2）对种群进行采样，以及3）加权采样样本。实验结果表明，在适应度计算的近似比例取决于完全运行GA时，我们的方法显著提高了进化运行时间，并且适应度得分要么与完全运行的GA相同，要么稍微低一点。我们的方法是通用的，可以很容易地应用于许多不同的领域。

    We present a novel approach to performing fitness approximation in genetic algorithms (GAs) using machine-learning (ML) models, focusing on evolutionary agents in Gymnasium (game) simulators -- where fitness computation is costly. Maintaining a dataset of sampled individuals along with their actual fitness scores, we continually update throughout an evolutionary run a fitness-approximation ML model. We compare different methods for: 1) switching between actual and approximate fitness, 2) sampling the population, and 3) weighting the samples. Experimental findings demonstrate significant improvement in evolutionary runtimes, with fitness scores that are either identical or slightly lower than that of the fully run GA -- depending on the ratio of approximate-to-actual-fitness computation. Our approach is generic and can be easily applied to many different domains.
    
[^48]: 数据驱动的线性规划降维方法：泛化界限和学习方法

    Data-Driven Projection for Reducing Dimensionality of Linear Programs: Generalization Bound and Learning Methods. (arXiv:2309.00203v1 [cs.LG])

    [http://arxiv.org/abs/2309.00203](http://arxiv.org/abs/2309.00203)

    本文研究了一种简单的数据驱动方法，通过学习投影矩阵来降低高维线性规划问题的维数，实现更快的求解速度。基于“数据驱动算法设计”，提出了泛化保证的数据量与性能指标的伪维度的上界和下界。

    

    本文研究了一种简单的数据驱动方法来处理高维线性规划问题（LP）。给定过去的$n$维LP数据，我们学习一个$n\times k$的“投影矩阵”（$n > k$），将维数从$n$降低到$k$。然后，我们通过解决$k$维LP问题并通过乘以投影矩阵来恢复$n$维的解决方案来处理未来的LP实例。这个思想与任何用户首选的LP求解器兼容，因此是一种通用的加速LP求解的方法。一个自然的问题是：需要多少数据才能确保恢复的解决方案的质量？我们基于“数据驱动算法设计”的思想来回答这个问题，它将足够进行泛化保证的数据量与性能指标的“伪维度”联系起来。我们给出了伪维度的$\tilde{\mathrm{O}}(nk^2)$上界（$\tilde{\mathrm{O}}$压缩了对数因子），并通过一个$\Omega(nk)$下界来补充它，

    This paper studies a simple data-driven approach to high-dimensional linear programs (LPs). Given data of past $n$-dimensional LPs, we learn an $n\times k$ \textit{projection matrix} ($n > k$), which reduces the dimensionality from $n$ to $k$. Then, we address future LP instances by solving $k$-dimensional LPs and recovering $n$-dimensional solutions by multiplying the projection matrix. This idea is compatible with any user-preferred LP solvers, hence a versatile approach to faster LP solving. One natural question is: how much data is sufficient to ensure the recovered solutions' quality? We address this question based on the idea of \textit{data-driven algorithm design}, which relates the amount of data sufficient for generalization guarantees to the \textit{pseudo-dimension} of performance metrics. We present an $\tilde{\mathrm{O}}(nk^2)$ upper bound on the pseudo-dimension ($\tilde{\mathrm{O}}$ compresses logarithmic factors) and complement it by an $\Omega(nk)$ lower bound, hence 
    
[^49]: BioCoder: 一种带有上下文语用知识的生物信息学代码生成基准

    BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual Pragmatic Knowledge. (arXiv:2308.16458v1 [cs.LG])

    [http://arxiv.org/abs/2308.16458](http://arxiv.org/abs/2308.16458)

    BioCoder是一个用于评估预训练模型在生成生物信息学代码方面的基准，涵盖了函数代码生成中的包依赖关系、类声明和全局变量，并通过模糊测试框架进行评估。

    

    预训练的语言模型（如ChatGPT）显著改进了代码生成。随着这些模型的扩大，需要输出来处理更复杂的任务的需求也越来越多。此外，在生物信息学中，生成功能程序由于领域知识量大、需要复杂的数据操作和复杂的功能依赖关系而面临额外的挑战。在这里，我们介绍了BioCoder，这是一个用于评估现有预训练模型在生成生物信息学代码方面的基准。与函数代码生成有关，BioCoder涵盖了可能的包依赖关系、类声明和全局变量。它包括来自GitHub的1026个Python和Java函数和1243个方法，以及来自Rosalind项目的253个示例。BioCoder还结合了一个用于评估的模糊测试框架，我们已经应用它来评估许多模型，包括InCoder、CodeGen、CodeGen2、SantaCoder、StarCoder、StarCoder+、InstructCodeT。

    Pre-trained language models like ChatGPT have significantly improved code generation. As these models scale up, there is an increasing need for the output to handle more intricate tasks. Moreover, in bioinformatics, generating functional programs poses additional notable challenges due to the amount of domain knowledge, the need for complicated data operations, and intricate functional dependencies between the operations. Here, we present BioCoder, a benchmark developed to evaluate existing pre-trained models in generating bioinformatics code. In relation to function-code generation, BioCoder covers potential package dependencies, class declarations, and global variables. It incorporates 1026 functions and 1243 methods in Python and Java from GitHub and 253 examples from the Rosalind Project. BioCoder incorporates a fuzz-testing framework for evaluation, and we have applied it to evaluate many models including InCoder, CodeGen, CodeGen2, SantaCoder, StarCoder, StarCoder+, InstructCodeT
    
[^50]: 通过迭代的低分辨率点云完成变换器进行高分辨率颅缺损重建

    High-Resolution Cranial Defect Reconstruction by Iterative, Low-Resolution, Point Cloud Completion Transformers. (arXiv:2308.03813v1 [eess.IV])

    [http://arxiv.org/abs/2308.03813](http://arxiv.org/abs/2308.03813)

    该论文提出了一种新的方法来增加个性化颅骨重建的可用性，通过点云完成任务实现高分辨率颅缺损重建，并在训练和推理过程中快速且资源高效。

    

    每年都有成千上万的人遭受各种类型的颅骨伤害，需要个性化植入物，手工设计昂贵且费时。因此，一个自动化的专用系统来增加个性化颅骨重建的可用性非常有必要。自动颅骨缺损重建的问题可以被描述为形状完成任务，并使用专用深度网络来解决。目前，最常见的方法是使用体积表示法并应用于图像分割的深度网络。然而，这种方法存在一些限制，不能很好地适应高分辨率体积，并没有考虑到数据的稀疏性。在我们的工作中，我们将问题重新表述为点云完成任务。我们提出了一种迭代的基于变换器的方法，可以在任何分辨率下重建颅缺损，并在训练和推理过程中快速且资源高效。我们比较了所提出的方法。

    Each year thousands of people suffer from various types of cranial injuries and require personalized implants whose manual design is expensive and time-consuming. Therefore, an automatic, dedicated system to increase the availability of personalized cranial reconstruction is highly desirable. The problem of the automatic cranial defect reconstruction can be formulated as the shape completion task and solved using dedicated deep networks. Currently, the most common approach is to use the volumetric representation and apply deep networks dedicated to image segmentation. However, this approach has several limitations and does not scale well into high-resolution volumes, nor takes into account the data sparsity. In our work, we reformulate the problem into a point cloud completion task. We propose an iterative, transformer-based method to reconstruct the cranial defect at any resolution while also being fast and resource-efficient during training and inference. We compare the proposed meth
    
[^51]: 整合鲁莽行为到基于协同过滤的推荐系统中

    Incorporating Recklessness to Collaborative Filtering based Recommender Systems. (arXiv:2308.02058v1 [cs.IR])

    [http://arxiv.org/abs/2308.02058](http://arxiv.org/abs/2308.02058)

    本文提出了一种将鲁莽行为引入基于矩阵分解的推荐系统学习过程的方法，通过控制风险水平来提高预测的数量和质量。

    

    包含可靠性测量的推荐系统往往在预测中更加保守，因为它们需要保持可靠性。这导致了这些系统可以提供的覆盖范围和新颖性的显著下降。在本文中，我们提出了在矩阵分解型推荐系统的学习过程中加入一项新的项，称为鲁莽行为，它可以控制在做出关于预测可靠性的决策时所希望的风险水平。实验结果表明，鲁莽行为不仅允许进行风险调控，还提高了推荐系统提供的预测的数量和质量。

    Recommender systems that include some reliability measure of their predictions tend to be more conservative in forecasting, due to their constraint to preserve reliability. This leads to a significant drop in the coverage and novelty that these systems can provide. In this paper, we propose the inclusion of a new term in the learning process of matrix factorization-based recommender systems, called recklessness, which enables the control of the risk level desired when making decisions about the reliability of a prediction. Experimental results demonstrate that recklessness not only allows for risk regulation but also improves the quantity and quality of predictions provided by the recommender system.
    
[^52]: Offline RL的预算反事实推理

    Budgeting Counterfactual for Offline RL. (arXiv:2307.06328v1 [cs.LG])

    [http://arxiv.org/abs/2307.06328](http://arxiv.org/abs/2307.06328)

    离线强化学习中，通过动态规划的方法限制超出分布动作的数量。

    

    离线强化学习的主要挑战在于数据有限的情况下，由于潜在动作领域内的反事实推理困境所引起：如果我们选择了不同的行动会怎么样？这些情况通常会导致指数级累积的外推误差。因此，认识到并不是所有的决策步骤对最终结果都同样重要，并在政策制定中预算反事实决策的数量以控制外推是至关重要的。与现有方法在政策或值函数上使用规则化不同，我们提出了一种方法来明确限制训练期间的超出分布动作的数量。具体而言，我们的方法利用动态规划来决定在哪里进行外推和在哪里不进行外推，并且对决策的上限不同于行为策略。它在潜在改进的潜力和外推控制之间进行平衡。

    The main challenge of offline reinforcement learning, where data is limited, arises from a sequence of counterfactual reasoning dilemmas within the realm of potential actions: What if we were to choose a different course of action? These circumstances frequently give rise to extrapolation errors, which tend to accumulate exponentially with the problem horizon. Hence, it becomes crucial to acknowledge that not all decision steps are equally important to the final outcome, and to budget the number of counterfactual decisions a policy make in order to control the extrapolation. Contrary to existing approaches that use regularization on either the policy or value function, we propose an approach to explicitly bound the amount of out-of-distribution actions during training. Specifically, our method utilizes dynamic programming to decide where to extrapolate and where not to, with an upper bound on the decisions different from behavior policy. It balances between the potential for improvemen
    
[^53]: 在不平衡数据集中的离线强化学习

    Offline Reinforcement Learning with Imbalanced Datasets. (arXiv:2307.02752v1 [cs.LG])

    [http://arxiv.org/abs/2307.02752](http://arxiv.org/abs/2307.02752)

    本文提出了一种在不平衡数据集中的新型离线强化学习方法，通过将CQL与回溯过程相结合来提取策略，从而有效地解决了不平衡数据集带来的挑战。

    

    当前离线强化学习（RL）研究中对基准的普遍使用导致了对实际数据集分布不平衡的忽视。由于探索或安全考虑的挑战，实际离线RL数据集在状态空间上通常是不平衡的。我们在本文中具体说明了离线RL中不平衡数据集的特性，其中状态覆盖率遵循一个由偏态策略所特征化的幂律分布。理论上和实证上，我们证明了基于分布约束的典型离线RL方法，如保守Q学习（CQL），在不平衡数据集下提取策略是无效的。受自然智能的启发，我们提出了一种新的离线RL方法，该方法利用CQL的增强与回溯过程相结合，以回忆以往相关经验，有效地缓解不平衡数据集带来的挑战。我们在多个任务上评估了我们的方法。

    The prevalent use of benchmarks in current offline reinforcement learning (RL) research has led to a neglect of the imbalance of real-world dataset distributions in the development of models. The real-world offline RL dataset is often imbalanced over the state space due to the challenge of exploration or safety considerations. In this paper, we specify properties of imbalanced datasets in offline RL, where the state coverage follows a power law distribution characterized by skewed policies. Theoretically and empirically, we show that typically offline RL methods based on distributional constraints, such as conservative Q-learning (CQL), are ineffective in extracting policies under the imbalanced dataset. Inspired by natural intelligence, we propose a novel offline RL method that utilizes the augmentation of CQL with a retrieval process to recall past related experiences, effectively alleviating the challenges posed by imbalanced datasets. We evaluate our method on several tasks in the 
    
[^54]: 神经网络混合状态重构的经验样本复杂度

    Empirical Sample Complexity of Neural Network Mixed State Reconstruction. (arXiv:2307.01840v1 [quant-ph])

    [http://arxiv.org/abs/2307.01840](http://arxiv.org/abs/2307.01840)

    该论文通过数值研究混合态重构技术的性能，展示了在不同混合度下不同神经量子态编码的效率，并提出了设计更高效编码的需求。

    

    使用神经量子态进行量子状态重构被提出作为减少实际应用中的量子击穿复杂性的可行工具，并且在主要关注无噪声情况的数值实验中展示了其优势。在这项工作中，我们在混合态：有限温度伊辛模型上进行了数字上的性能研究。我们展示了如何通过应用方差减少技术系统地减少算法的量子资源需求。然后，我们比较了两种主要的神经量子态编码，即神经密度算符和正算符值测量表示，并展示了它们在目标态混合程度变化时的不同性能。我们发现在不同混合度范围内，某些编码更加高效，并指出设计更加高效编码的需求，无论是从计算复杂性还是从性能角度。

    Quantum state reconstruction using Neural Quantum States has been proposed as a viable tool to reduce quantum shot complexity in practical applications, and its advantage over competing techniques has been shown in numerical experiments focusing mainly on the noiseless case. In this work, we numerically investigate the performance of different quantum state reconstruction techniques for mixed states: the finite-temperature Ising model. We show how to systematically reduce the quantum resource requirement of the algorithms by applying variance reduction techniques. Then, we compare the two leading neural quantum state encodings of the state, namely, the Neural Density Operator and the positive operator-valued measurement representation, and illustrate their different performance as the mixedness of the target state varies. We find that certain encodings are more efficient in different regimes of mixedness and point out the need for designing more efficient encodings in terms of both cla
    
[^55]: 无监督的剧集生成方法用于图元学习

    Unsupervised Episode Generation for Graph Meta-learning. (arXiv:2306.15217v1 [cs.LG])

    [http://arxiv.org/abs/2306.15217](http://arxiv.org/abs/2306.15217)

    本文研究了无监督的剧集生成方法，通过元学习解决没有标签的少样本节点分类问题。它们充分利用所有节点信息，并且通过泛化能力提高性能。

    

    本文研究了无监督的剧集生成方法，通过元学习来解决没有标签的少样本节点分类问题。主流的少样本节点分类的元学习方法是在存在大量有标签节点用于训练的情况下开发的，然而在现实世界中可能无法获得这样的数据。虽然已经提出了一些解决标签稀缺性问题的研究，但它们仍然依赖于有限数量的有标签数据，这限制了对图中所有节点信息的充分利用。尽管自监督学习方法在没有标签的节点分类问题上很有效，但它们主要学习通用的节点嵌入，没有考虑要解决的下游任务，这可能限制了其性能。在这项工作中，我们提出了无监督的剧集生成方法，以利用它们在少样本节点分类任务中的泛化能力，同时解决标签稀缺性问题。我们首先提出了一种利用图增强方法的方法

    In this paper, we investigate Unsupervised Episode Generation methods to solve Few-Shot Node-Classification (FSNC) problem via Meta-learning without labels. Dominant meta-learning methodologies for FSNC were developed under the existence of abundant labeled nodes for training, which however may not be possible to obtain in the real-world. Although few studies have been proposed to tackle the label-scarcity problem, they still rely on a limited amount of labeled data, which hinders the full utilization of the information of all nodes in a graph. Despite the effectiveness of Self-Supervised Learning (SSL) approaches on FSNC without labels, they mainly learn generic node embeddings without consideration on the downstream task to be solved, which may limit its performance. In this work, we propose unsupervised episode generation methods to benefit from their generalization ability for FSNC tasks while resolving label-scarcity problem. We first propose a method that utilizes graph augmentat
    
[^56]: 基于深度学习的高内容细胞成像多组学预测

    Multi-omics Prediction from High-content Cellular Imaging with Deep Learning. (arXiv:2306.09391v1 [q-bio.QM])

    [http://arxiv.org/abs/2306.09391](http://arxiv.org/abs/2306.09391)

    本研究使用深度学习方法，从高内容细胞成像中直接预测细胞群体的多组学。实验结果表明，该方法能够在多种刺激条件下实现显著成果，为细胞组学领域提供了新的方法。

    

    高内容细胞成像、转录组学和蛋白质组学数据为影响细胞状态和功能的生物分子层提供了丰富和互补的视角。但是，尚未系统地探讨多组学测量值影响细胞形态的生物学决定因素，因此目前尚不清楚细胞成像是否能够直接预测多组学。在这里，我们探讨了使用Image2Omics——一种深度学习方法——直接从用多重荧光染料染色的高内容图像中预测细胞群体的多组学是否可能。我们在多种刺激条件下的人类诱导多能干细胞（hiPSC）衍生的基因编辑巨噬细胞中进行实验评估，并证明Image2Omics取得了显著的成果。

    High-content cellular imaging, transcriptomics, and proteomics data provide rich and complementary views on the molecular layers of biology that influence cellular states and function. However, the biological determinants through which changes in multi-omics measurements influence cellular morphology have not yet been systematically explored, and the degree to which cell imaging could potentially enable the prediction of multi-omics directly from cell imaging data is therefore currently unclear. Here, we address the question of whether it is possible to predict bulk multi-omics measurements directly from cell images using Image2Omics -- a deep learning approach that predicts multi-omics in a cell population directly from high-content images stained with multiplexed fluorescent dyes. We perform an experimental evaluation in gene-edited macrophages derived from human induced pluripotent stem cell (hiPSC) under multiple stimulation conditions and demonstrate that Image2Omics achieves sign
    
[^57]: 基于领域无关自监督学习简化全波形反演

    Simplifying Full Waveform Inversion via Domain-Independent Self-Supervised Learning. (arXiv:2305.13314v1 [physics.geo-ph])

    [http://arxiv.org/abs/2305.13314](http://arxiv.org/abs/2305.13314)

    本文提出了基于领域无关自监督学习的SimFWI算法，其两个步骤分别是分别通过多个数据集上的遮盖图像建模学习编码器和解码器，然后为每个数据集学习一个线性映射。该算法可用于预测地震数据中的地下速度图，可极大地简化全波形反演任务，并连接多个FWI数据集。

    

    地球物理学中的深度学习在全波形反演(FWI)中应用得到成功，用于预测地震数据中的地下速度图。本文报告了一个惊人的现象：通过自监督学习，在各自的领域中分别训练编码器和解码器，可以在潜在空间中观察到跨领域的线性关系。基于这些发现，我们开发了SimFWI，一个包括两个步骤的新范式：(a)通过多个数据集上的遮盖图像建模分别学习地震编码器和速度解码器；(b)为每个数据集学习一个线性映射。实验结果显示

    Geophysics has witnessed success in applying deep learning to one of its core problems: full waveform inversion (FWI) to predict subsurface velocity maps from seismic data. It is treated as an image-to-image translation problem, jointly training an encoder for seismic data and a decoder for the velocity map from seismic-velocity pairs. In this paper, we report a surprising phenomenon: when training an encoder and decoder separately in their own domains via self-supervised learning, a linear relationship is observed across domains in the latent spaces. Moreover, this phenomenon connects multiple FWI datasets in an elegant manner: these datasets can share the self-learned encoder and decoder with different linear mappings.  Based on these findings, we develop SimFWI, a new paradigm that includes two steps: (a) learning a seismic encoder and a velocity decoder separately by masked image modeling over multiple datasets; (b) learning a linear mapping per dataset. Experimental results show t
    
[^58]: 丰富解缠结：从定义到度量的探究

    Enriching Disentanglement: Definitions to Metrics. (arXiv:2305.11512v1 [cs.LG])

    [http://arxiv.org/abs/2305.11512](http://arxiv.org/abs/2305.11512)

    本文探究了解缠结表示学习的度量标准，并提出了基于丰富范畴论的系统方法，将方程定义转化为可比较的度量标准，我们推导出应用于测量解缠结属性的度量标准，并在合成数据上证明其有效性。

    

    解缠结表示学习是一项具有挑战性的任务，涉及到在复杂数据中分离多个变化因素。虽然已经提出了各种用于学习和评估解缠结表示的度量标准，但这些度量标准真正量化了什么以及如何比较它们仍然不清楚。在本文中，我们研究了利用一阶方程谓词定义的解缠结，并介绍了一种基于丰富范畴论的系统方法，将方程定义转化为兼容的定量度量标准。具体而言，我们展示了如何用度量或离散度替换(i) 等式，用排序操作替换 (ii) 逻辑联结词，用聚合替换 (iii) 通用量词，用最佳逼近替换 (iv) 存在量词。使用这种方法，我们推导出用于测量解缠结表示提取器所需属性的度量标准，并在合成数据上展示它们的有效性。我们提出的方法提供了一种框架，能够将解缠结表示定义转化为可比较的，并衡量一种方法中解缠结属性的有效性。

    Disentangled representation learning is a challenging task that involves separating multiple factors of variation in complex data. Although various metrics for learning and evaluating disentangled representations have been proposed, it remains unclear what these metrics truly quantify and how to compare them. In this work, we study the definitions of disentanglement given by first-order equational predicates and introduce a systematic approach for transforming an equational definition into a compatible quantitative metric based on enriched category theory. Specifically, we show how to replace (i) equality with metric or divergence, (ii) logical connectives with order operations, (iii) universal quantifier with aggregation, and (iv) existential quantifier with the best approximation. Using this approach, we derive metrics for measuring the desired properties of a disentangled representation extractor and demonstrate their effectiveness on synthetic data. Our proposed approach provides p
    
[^59]: 手腕动作时间序列分类用于帕金森病检测

    Time Series Classification for Detecting Parkinson's Disease from Wrist Motions. (arXiv:2304.11265v1 [cs.LG])

    [http://arxiv.org/abs/2304.11265](http://arxiv.org/abs/2304.11265)

    该研究使用InceptionTime和ROCKET方法进行时间序列分类，以监测帕金森病患者的手腕运动。研究发现，所有方法都适用于估计震颤严重程度和肌肉强直的存在，但在检测运动障碍方面存在困难。具有岭分类器的InceptionTime方法展示了最先进的分类性能，显示时间序列分类在基于可穿戴设备的PD症状监测中具有潜力。

    

    帕金森病是一种神经退行性疾病，具有频繁变化的运动症状，持续的症状监测可以实现更有针对性的治疗。传统的时间序列分类和深度学习技术在使用可穿戴加速度计数据进行PD症状监测时性能有限，因为PD运动模式具有复杂性，但数据集很小。我们研究了InceptionTime和RandOm卷积核变换（ROCKET），因为它们是TSC的最新技术，并且对于PD症状监测非常有前景：InceptionTime的高学习能力适用于建模复杂运动模式，而ROCKET适用于小数据集。我们使用随机搜索找到了最高得分的InceptionTime结构，并将其与具有岭分类器和多层感知器（MLP）的ROCKET进行了比较，用于PD患者的手腕运动。我们发现，所有方法都适用于估计震颤严重程度和肌肉强直的存在，但在检测运动障碍方面存在困难。具有岭分类器的InceptionTime优于其他方法，并实现了最先进的分类性能，展示了TSC在基于可穿戴设备的PD症状监测中的潜力。

    Parkinson's disease (PD) is a neurodegenerative disease with frequently changing motor symptoms where continuous symptom monitoring enables more targeted treatment. Classical time series classification (TSC) and deep learning techniques have limited performance for PD symptom monitoring using wearable accelerometer data because PD movement patterns are complex, but datasets are small. We investigate InceptionTime and RandOm Convolutional KErnel Transform (ROCKET) because they are state-of-the-art for TSC and promising for PD symptom monitoring: InceptionTime's high learning capacity is suited to modeling complex movement patterns while ROCKET is suited to small datasets. We used a random search to find the highest-scoring InceptionTime architecture and compared it to ROCKET with a ridge classifier and a multi-layer perceptron (MLP) on wrist motions of PD patients. We find that all approaches are suitable for estimating tremor severity and bradykinesia presence but struggle with detecti
    
[^60]: 基于投票的实例筛选方法：使用基于赞成票的多获胜者投票

    Data as voters: instance selection using approval-based multi-winner voting. (arXiv:2304.09995v1 [cs.LG])

    [http://arxiv.org/abs/2304.09995](http://arxiv.org/abs/2304.09995)

    该论文提出了一种基于赞成票的多获胜者投票的实例选择方法，通过代表性投票规则选择获胜者，并将其作为减少训练集的数据实例。

    

    我们提出了一种新的机器学习（或数据挖掘）中的实例筛选方法。我们的方法基于最近关于基于赞成票的多获胜者选举中代表性表征的结果。在我们的模型中，实例扮演选民和候选人的双重角色。每个训练集中的实例（作为选民）赞成其本地集合中的实例（扮演候选人的角色）（除自身以外的实例），这个概念在文献中已经存在。然后，我们使用代表性投票规则选择选举获胜者，并作为减少训练集中的数据实例保留。

    We present a novel approach to the instance selection problem in machine learning (or data mining). Our approach is based on recent results on (proportional) representation in approval-based multi-winner elections. In our model, instances play a double role as voters and candidates. Each instance in the training set (acting as a voter) approves of the instances (playing the role of candidates) belonging to its local set (except itself), a concept already existing in the literature. We then select the election winners using a representative voting rule, and such winners are the data instances kept in the reduced training set.
    
[^61]: 利用早期退出进行深度神经网络的分层训练

    Hierarchical Training of Deep Neural Networks Using Early Exiting. (arXiv:2303.02384v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.02384](http://arxiv.org/abs/2303.02384)

    本文提出了一种使用早期退出的分层训练方法，将深度神经网络分为边缘和云工作者，以减少通信成本、训练运行时间和隐私问题。

    

    深度神经网络提供了视觉任务的最先进准确性，但需要大量资源进行训练。因此，它们在远离获取数据的边缘设备上的云服务器上进行训练。这增加了通信成本、运行时间和隐私问题。本研究提出了一种新的深度神经网络分层训练方法，它使用早期退出在边缘和云工作者之间分割架构，以减少通信成本、训练运行时间和隐私问题。

    Deep neural networks provide state-of-the-art accuracy for vision tasks but they require significant resources for training. Thus, they are trained on cloud servers far from the edge devices that acquire the data. This issue increases communication cost, runtime and privacy concerns. In this study, a novel hierarchical training method for deep neural networks is proposed that uses early exits in a divided architecture between edge and cloud workers to reduce the communication cost, training runtime and privacy concerns. The method proposes a brand-new use case for early exits to separate the backward pass of neural networks between the edge and the cloud during the training phase. We address the issues of most available methods that due to the sequential nature of the training phase, cannot train the levels of hierarchy simultaneously or they do it with the cost of compromising privacy. In contrast, our method can use both edge and cloud workers simultaneously, does not share the raw i
    
[^62]: t-SMILES：用于全新分子生成的可扩展基于碎片的分子表示框架

    t-SMILES: A Scalable Fragment-based Molecular Representation Framework for De Novo Molecule Generation. (arXiv:2301.01829v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.01829](http://arxiv.org/abs/2301.01829)

    本研究提出了一种可扩展的基于碎片的分子表示框架 t-SMILES，通过引入 t-SMILES 可以显著改善分子的表示效果，并在多种任务中表现出色，优于其他经典模型。

    

    分子的有效表示是影响人工智能模型性能的关键因素。本研究引入了一种灵活的、基于碎片的多尺度分子表示框架 t-SMILES（基于树的SMILES），该框架包含三种代码算法：TSSA（带有共享原子的t-SMILES）、TSDY（带有虚拟原子的t-SMILES）和TSID（带有ID的t-SMILES）。它使用从分子图的碎片形成的全二叉树上进行广度优先搜索得到的SMILES类型字符串来描述分子。通过使用JTVAE、BRICS、MMPA和Scaffold进行系统评估，显示了构建多代码分子描述系统的可行性，各种描述相互补充，提高整体性能。此外，在资源有限的数据集上表现出色，无论模型是原始的、数据增强的还是预训练微调的。它在goa等任务中明显优于经典的SMILES、DeepSMILES、SELFIES和基准模型。

    Effective representation of molecules is a crucial factor affecting the performance of artificial intelligence models. This study introduces a flexible, fragment-based, multiscale molecular representation framework called t-SMILES (tree-based SMILES) with three code algorithms: TSSA (t-SMILES with Shared Atom), TSDY (t-SMILES with Dummy Atom) and TSID (t-SMILES with ID). It describes molecules using SMILES-type strings obtained by performing a breadth-first search on a full binary tree formed from a fragmented molecular graph. Systematic evaluations using JTVAE, BRICS, MMPA, and Scaffold show the feasibility to construct a multi-code molecular description system, where various descriptions complement each other, enhancing the overall performance. Additionally, it exhibits impressive performance on low-resource datasets, whether the model is original, data augmented, or pre-training fine-tuned. It significantly outperforms classical SMILES, DeepSMILES, SELFIES and baseline models in goa
    

