# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [CORE: Mitigating Catastrophic Forgetting in Continual Learning through Cognitive Replay](https://rss.arxiv.org/abs/2402.01348) | 本文通过COgnitive REplay（CORE）提出了一种在连续学习中减轻灾难性遗忘的新方法，通过自适应数量分配和以质量为重点的数据选择来优化重播缓冲区，取得了显著的准确率提高效果。 |
| [^2] | [Prior Frequency Guided Diffusion Model for Limited Angle (LA)-CBCT Reconstruction](https://arxiv.org/abs/2404.01448) | 本研究提出了一种基于扩散模型的先验频率引导扩散模型（PFGDM）框架，用于稳健且保持结构的有限角度CBCT重建。 |
| [^3] | [NeuroPrune: A Neuro-inspired Topological Sparse Training Algorithm for Large Language Models](https://arxiv.org/abs/2404.01306) | 本研究受神经系统启发，通过神经网络拓扑的稀疏方法，探索类似于生物网络的机制，展示了对各种 NLP 任务都表现出色和高效的模型-不可知稀疏性方法 |
| [^4] | [Towards Stable Machine Learning Model Retraining via Slowly Varying Sequences](https://arxiv.org/abs/2403.19871) | 通过混合整数优化算法，以保持一致的分析洞见为重点，在重新训练机器学习模型中实现比贪婪训练更强稳定性，同时在模型性能上有小幅、可控的牺牲。 |
| [^5] | [Interpreting Key Mechanisms of Factual Recall in Transformer-Based Language Models](https://arxiv.org/abs/2403.19521) | 通过深入研究Transformer-based语言模型在事实回忆任务中的机制，我们发现了零/少次样本情况下的特定任务头、MLP层和残差流的功能，以及抗过度自信机制。 |
| [^6] | [On the rates of convergence for learning with convolutional neural networks](https://arxiv.org/abs/2403.16459) | 该研究提出了对具有一定权重约束的CNNs的新逼近上界，以及对前馈神经网络的覆盖数做了新的分析，为基于CNNs的学习问题推导了收敛速率，并在学习平滑函数和二元分类方面取得了极小最优的结果。 |
| [^7] | [GeRM: A Generalist Robotic Model with Mixture-of-experts for Quadruped Robot](https://arxiv.org/abs/2403.13358) | GeRM是一种通用机器人模型，通过混合专家结构和离线强化学习优化数据利用策略，解决了多任务机器人学习中性能问题和数据收集困难的情况，显著提高了模型性能。 |
| [^8] | [Federated Transfer Learning with Differential Privacy](https://arxiv.org/abs/2403.11343) | 本文提出了具有差分隐私的联邦迁移学习框架，通过利用多个异构源数据集的信息来增强对目标数据集的学习，同时考虑隐私约束。 |
| [^9] | [PeerAiD: Improving Adversarial Distillation from a Specialized Peer Tutor](https://arxiv.org/abs/2403.06668) | PeerAiD提出了一种新的对抗性蒸馏方法，通过让同行网络学习学生网络的对抗性示例，而不是自身的示例，来提升神经网络的鲁棒性。 |
| [^10] | [Minimizing the Thompson Sampling Regret-to-Sigma Ratio (TS-RSR): a provably efficient algorithm for batch Bayesian Optimization](https://arxiv.org/abs/2403.04764) | 该论文提出了一种用于批量贝叶斯优化的高效算法，通过最小化Thompson抽样近似的遗憾与不确定性比率，成功协调每个批次的动作选择，同时实现高概率的理论保证，并在非凸测试函数上表现出色. |
| [^11] | [Hamiltonian Property Testing](https://arxiv.org/abs/2403.02968) | 本文研究了Hamiltonian的本地性测试作为属性测试问题，重点在于确定未知的$n$比特Hamiltonian是否是$k$局部的，通过对$H$的时间演化进行访问来解决问题。 |
| [^12] | [Clustering in Dynamic Environments: A Framework for Benchmark Dataset Generation With Heterogeneous Changes](https://arxiv.org/abs/2402.15731) | 本论文引入了Dynamic Dataset Generator（DDG）来解决在动态环境中进行聚类时缺乏多样性、可控性和现实性动态数据集的问题，从而帮助设计更有效的聚类算法。 |
| [^13] | [Robust agents learn causal world models](https://arxiv.org/abs/2402.10877) | 智能体必须学习因果模型才能在广泛的分布转变下达到后悔界限，这对迁移学习和因果推断等研究领域有重要影响。 |
| [^14] | [Learning fast changing slow in spiking neural networks](https://arxiv.org/abs/2402.10069) | 通过近端策略优化实现的生物学可行方法在脉冲神经网络中减轻了强化学习所面临的数据稀缺性和噪声引入的困难。 |
| [^15] | [The Deep Equilibrium Algorithmic Reasoner](https://arxiv.org/abs/2402.06445) | 本文介绍了一种深度平衡算法推理器，可以通过直接找到算法的平衡点来训练网络解决算法问题。 |
| [^16] | [Misspecification uncertainties in near-deterministic regression](https://arxiv.org/abs/2402.01810) | 该论文研究了近确定性回归中错误规范化的不确定性问题，并提出了一种组合模型，以准确预测和控制参数不确定性。 |
| [^17] | [BEND: Benchmarking DNA Language Models on biologically meaningful tasks](https://arxiv.org/abs/2311.12570) | BEND是一个针对DNA语言模型的基准测试，包含一系列在人类基因组上定义的现实且具有生物意义的下游任务。 |
| [^18] | [Attesting Distributional Properties of Training Data for Machine Learning](https://arxiv.org/abs/2308.09552) | 提出了一种新型的财产证明概念，可以在不泄露数据的情况下向验证者展示训练数据的分布特性。 |
| [^19] | [Complete Neural Networks for Complete Euclidean Graphs](https://arxiv.org/abs/2301.13821) | 神经网络模型可以通过应用3-WL图同构测试于点云的Gram矩阵，或者应用欧几里得2-WL测试，在多项式复杂度内实现对完全欧几里得图的完全确定性 |
| [^20] | [TeenyTinyLlama: open-source tiny language models trained in Brazilian Portuguese.](http://arxiv.org/abs/2401.16640) | 这篇论文开发了用于低资源环境中的开放式基础模型，以巴西葡萄牙语为例，发布在GitHub和Hugging Face上供社区使用和进一步开发。 |
| [^21] | [Tiny Time Mixers (TTMs): Fast Pretrained Models for Enhanced Zero/Few-Shot Forecasting of Multivariate Time Series.](http://arxiv.org/abs/2401.03955) | 本论文介绍了一种名为微小时间混合器 (TTMs) 的预训练模型，该模型针对多变量时间序列的零/少样本预测进行了优化。与大型预训练模型相比，TTMs模型更小、更快，并考虑了跨通道相关性，能够在短时间内进行有效的预测。 |
| [^22] | [FedQV: Leveraging Quadratic Voting in Federated Learning.](http://arxiv.org/abs/2401.01168) | 本文提出了FedQV，这是一个在联邦学习中利用二次投票机制的新型聚合算法，旨在解决现有方法中容易受到污染攻击的问题。理论和实证分析表明，FedQV是一个真实机制，并且具有与现有方法相匹配的收敛速率。 |
| [^23] | [Bridging the Gaps: Learning Verifiable Model-Free Quadratic Programming Controllers Inspired by Model Predictive Control.](http://arxiv.org/abs/2312.05332) | 本文提出了一种新的参数化控制器类，利用深度强化学习训练其控制器的参数，从而消除了常见控制器中的可验证性和性能保证的限制。该控制器类似于模型预测控制问题的二次规划求解器，具有可验证的属性，并且在控制性能和鲁棒性方面与其他控制器相媲美。同时，该控制器的计算效率显著优于传统的模型预测控制。 |
| [^24] | [Faithful and Robust Local Interpretability for Textual Predictions.](http://arxiv.org/abs/2311.01605) | 提出了一种名为FRED的新颖方法，用于解释文本预测。FRED可以识别文档中的关键词，并且通过与最先进的方法进行的实证评估证明了其在提供对文本模型的深入见解方面的有效性。 |
| [^25] | [Quantum Long Short-Term Memory (QLSTM) vs Classical LSTM in Time Series Forecasting: A Comparative Study in Solar Power Forecasting.](http://arxiv.org/abs/2310.17032) | 本研究比较了量子长短期记忆（QLSTM）和经典长短期记忆（LSTM）模型在太阳能发电量预测中的表现，发现QLSTM具有加快训练收敛速度和减小测试损失的优势，拥有吸纳复杂时间序列关系的潜力，但还需要进一步研究和优化。 |
| [^26] | [Understanding Fairness Surrogate Functions in Algorithmic Fairness.](http://arxiv.org/abs/2310.11211) | 本文研究了算法公平性中的公平性代理函数，并发现了代理和公平性定义之间存在一个差距。这个差距决定了一个代理函数能否适当替代一个公平性定义。 |
| [^27] | [Enhancing Trustworthiness in ML-Based Network Intrusion Detection with Uncertainty Quantification.](http://arxiv.org/abs/2310.10655) | 这项研究提出了一种通过不确定性量化来增强基于机器学习的网络入侵检测的可信度的方法。 |
| [^28] | [Data Augmentation for Time-Series Classification: An Extensive Empirical Study and Comprehensive Survey.](http://arxiv.org/abs/2310.10060) | 本研究对时间序列分类中的数据增强方法进行了广泛研究和综述，总结了60多种独特的方法，并提出了一个针对TSC的新的分类体系。 |
| [^29] | [Anchor-based Multi-view Subspace Clustering with Hierarchical Feature Descent.](http://arxiv.org/abs/2310.07166) | 本文提出了一种基于锚点的多视图子空间聚类方法，通过分层特征下降挖掘和部署视图之间的依赖关系，从而在聚类过程中实现了对不同视图的特征对齐。这种方法得到了一个共同的潜在空间，被称为“相似空间”，揭示了不同视图之间的相关性和依赖关系。 |
| [^30] | [ExIFFI and EIF+: Interpretability and Enhanced Generalizability to Extend the Extended Isolation Forest.](http://arxiv.org/abs/2310.05468) | 本研究介绍了EIF+和ExIFFI两种改进了扩展孤立森林的方法，分别增强了模型的推广能力和解释性能，实验结果表明其在异常检测任务中具有优势。 |
| [^31] | [On the expressivity of embedding quantum kernels.](http://arxiv.org/abs/2309.14419) | 量子核方法是量子和经典机器学习之间最自然的联系之一。本文探讨了嵌入式量子核的表达能力，并得出结论：通过引入计算普适性，任何核函数都可以表示为量子特征映射和嵌入式量子核。 |
| [^32] | [Sharpness-Aware Minimization and the Edge of Stability.](http://arxiv.org/abs/2309.12488) | 本研究通过类似的计算方法，为锐度感知最小化(SAM)，一种改进泛化性能的梯度下降变种，确定了一个稳定性边界，该边界取决于梯度的范数。 |
| [^33] | [PCN: A Deep Learning Approach to Jet Tagging Utilizing Novel Graph Construction Methods and Chebyshev Graph Convolutions.](http://arxiv.org/abs/2309.08630) | 本研究提出了一种基于图形的喷注表示方法，并设计了一种名为PCN的图神经网络（GNN），利用切比雪夫图卷积（ChebConv）进行深度学习喷注标记，取得了显著的改进。 |
| [^34] | [Advancing Regular Language Reasoning in Linear Recurrent Neural Networks.](http://arxiv.org/abs/2309.07412) | 通过分析现有的线性循环神经网络（LRNN），我们提出了一种新的LRNN模型，该模型配备了一个块对角且输入相关的转移矩阵，并且是唯一一个能够在正则语言任务上进行长度外推的LRNN。 |
| [^35] | [Bias Amplification Enhances Minority Group Performance.](http://arxiv.org/abs/2309.06717) | 本论文提出了一种名为BAM的两阶段训练算法，通过引入可学习的辅助变量来放大偏见，提高了少数群体的表现。 |
| [^36] | [Identifying Constitutive Parameters for Complex Hyperelastic Solids using Physics-Informed Neural Networks.](http://arxiv.org/abs/2308.15640) | 本文介绍了一种基于物理信息神经网络（PINNs）的新框架，用于识别软材料在大变形平面应力条件下具有复杂组分行为的材料的组分参数。通过使用多模态的时间相关实验数据训练，我们的模型能够稳健地准确识别不可压缩Arruda-Boyce模型的组分参数。 |
| [^37] | [Learning to Intervene on Concept Bottlenecks.](http://arxiv.org/abs/2308.13453) | 该论文提出了一种扩展了概念瓶颈模型的概念瓶颈记忆模型（CB2M），通过学习将干预推广到不同情境并重新应用先前干预来自动改善模型性能。当没有先前的人类干预信息时，CB2M能够检测错误并请求有针对性的干预。 |
| [^38] | [Stochastic Controlled Averaging for Federated Learning with Communication Compression.](http://arxiv.org/abs/2308.08165) | 本文提出了两种压缩联邦学习算法(SCALLION和SCAFCOM)，通过重新审视经典的随机控制平均法并提出了等价但更高效/简化的形式，减少了上行通信成本。 |
| [^39] | [Game-Theoretic Robust Reinforcement Learning Handles Temporally-Coupled Perturbations.](http://arxiv.org/abs/2307.12062) | 这篇论文提出了一种新的鲁棒强化学习方法，通过将时间耦合的鲁棒强化学习问题视为两人零和游戏来处理问题，并通过找到近似均衡来确保代理对时间耦合干扰的鲁棒性。实验结果显示，该方法在各种连续控制任务中相比基准方法表现出显著的鲁棒性优势。 |
| [^40] | [Deep learning for dynamic graphs: models and benchmarks.](http://arxiv.org/abs/2307.06104) | 本文对深度学习动态图领域进行了调查，总结了学习时间和空间信息的最新优势，并对最流行的方法进行了公平的性能比较，为评估新架构和方法建立了一个可靠的基准模型。 |
| [^41] | [A Vulnerability of Attribution Methods Using Pre-Softmax Scores.](http://arxiv.org/abs/2307.03305) | 这篇论文讨论了使用前softmax分数的归属方法的一个漏洞，该方法用于解释卷积神经网络分类器输出。与对抗性攻击不同，作者关注的是对归属方法进行小修改可能导致的影响，而不会改变模型的输出。 |
| [^42] | [How to Detect Unauthorized Data Usages in Text-to-image Diffusion Models.](http://arxiv.org/abs/2307.03108) | 本文提出了一种方法，通过在训练的文本到图像扩散模型中植入注入的记忆化内容，来检测未授权数据使用。该方法修改了受保护的图像数据集，添加了对人眼不可察觉但模型可以捕捉和记忆的内容，通过分析模型对注入内容的记忆来判断模型是否存在生成类似图像的能力。 |
| [^43] | [Linear convergence of Nesterov-1983 with the strong convexity.](http://arxiv.org/abs/2306.09694) | 本文使用高分辨率微分方程框架回答了Nesterov-1983和FISTA是否在强凸函数上线性收敛的问题，并指出线性收敛性不依赖于强凸性条件。 |
| [^44] | [Improved Probabilistic Image-Text Representations.](http://arxiv.org/abs/2305.18171) | 本论文提出了一种改进的概率图像-文本表示方法，通过引入新的概率距离和两种优化技术，解决了现有方法中的计算负担过重和损失饱和问题，取得了显著的性能提升。 |
| [^45] | [An Edit Friendly DDPM Noise Space: Inversion and Manipulations.](http://arxiv.org/abs/2304.06140) | 本文提出了一种易于编辑的DDPM噪声空间，可以通过简单手段进行广泛的编辑操作，并提出了一种用于提取编辑友好噪声图的反演方法。 |
| [^46] | [PAIR-Diffusion: Object-Level Image Editing with Structure-and-Appearance Paired Diffusion Models.](http://arxiv.org/abs/2303.17546) | 本论文提出了一种采用结构和外观配对扩散模型进行对象级图像编辑的方法，使用户能够精细控制图像中的不同对象属性，同时自动传播注入的外观到具有相似结构的对象。 |
| [^47] | [Improving the Accuracy-Robustness Trade-Off of Classifiers via Adaptive Smoothing.](http://arxiv.org/abs/2301.12554) | 本文研究通过混合标准分类器和鲁棒模型的输出概率来减轻准确性和鲁棒性之间的权衡问题，进而提高分类器的鲁棒性。同时提出了一种自适应平滑的方法，可以降低实现鲁棒性的准确度惩罚。 |
| [^48] | [Multiple Models for Recommending Temporal Aspects of Entities.](http://arxiv.org/abs/1803.07890) | 本研究提出了一种新颖的基于事件中心的集合排名方法，该方法考虑到时间动态性，能够推荐最相关的实体方面，提高搜索体验。 |

# 详细

[^1]: CORE：通过认知重播来减轻连续学习中的灾难性遗忘

    CORE: Mitigating Catastrophic Forgetting in Continual Learning through Cognitive Replay

    [https://rss.arxiv.org/abs/2402.01348](https://rss.arxiv.org/abs/2402.01348)

    本文通过COgnitive REplay（CORE）提出了一种在连续学习中减轻灾难性遗忘的新方法，通过自适应数量分配和以质量为重点的数据选择来优化重播缓冲区，取得了显著的准确率提高效果。

    

    本文介绍了一种显著减轻连续学习中的灾难性遗忘的新视角，强调模型保持现有知识并融入新信息的能力。目前的重播方法同等对待每个任务和数据样本，因此无法充分利用重播缓冲区的潜力。作为回应，我们提出了COgnitive REplay（CORE），它从人类认知复习过程中得到灵感。CORE包括两个关键策略：自适应数量分配和以质量为重点的数据选择。前者根据每个任务的遗忘速率自适应地调节回放缓冲区的分配，而后者保证在缓冲区中包含最能概括每个任务特征的代表性数据。我们的方法在分割CIFAR10上实现了37.95%的平均准确率，超过最佳基准方法6.52%。此外，它还显著提高了最差表现模型的准确率。

    This paper introduces a novel perspective to significantly mitigate catastrophic forgetting in continuous learning (CL), which emphasizes models' capacity to preserve existing knowledge and assimilate new information. Current replay-based methods treat every task and data sample equally and thus can not fully exploit the potential of the replay buffer. In response, we propose COgnitive REplay (CORE), which draws inspiration from human cognitive review processes. CORE includes two key strategies: Adaptive Quantity Allocation and Quality-Focused Data Selection. The former adaptively modulates the replay buffer allocation for each task based on its forgetting rate, while the latter guarantees the inclusion of representative data that best encapsulates the characteristics of each task within the buffer. Our approach achieves an average accuracy of 37.95% on split-CIFAR10, surpassing the best baseline method by 6.52%. Additionally, it significantly enhances the accuracy of the poorest-perfo
    
[^2]: 有限角度(CBCT)重建的先验频率引导扩散模型

    Prior Frequency Guided Diffusion Model for Limited Angle (LA)-CBCT Reconstruction

    [https://arxiv.org/abs/2404.01448](https://arxiv.org/abs/2404.01448)

    本研究提出了一种基于扩散模型的先验频率引导扩散模型（PFGDM）框架，用于稳健且保持结构的有限角度CBCT重建。

    

    锥束计算机体层摄影（CBCT）广泛应用于图像引导放疗。从有限角度采集（LA-CBCT）重建CBCT对于提高成像效率、减少剂量以及更好的机械间隙清除至关重要。然而，LA-CBCT重建受到严重欠采样伪影的困扰，使其成为高度不适定的逆问题。扩散模型可以通过学习数据分布逆转数据加噪过程来生成数据/图像；并且可以作为LA-CBCT重建中的去噪器/正则化器。在这项研究中，我们为LA-CBCT重建开发了基于扩散模型的框架，即先验频率引导扩散模型（PFGDM），用于稳健且保持结构的LA-CBCT重建。PFGDM使用条件扩散模型作为LA-CBCT重建的正则化器，条件是基于从患者特定先前CT扫描中提取的高频信息，这提供了强大的

    arXiv:2404.01448v1 Announce Type: cross  Abstract: Cone-beam computed tomography (CBCT) is widely used in image-guided radiotherapy. Reconstructing CBCTs from limited-angle acquisitions (LA-CBCT) is highly desired for improved imaging efficiency, dose reduction, and better mechanical clearance. LA-CBCT reconstruction, however, suffers from severe under-sampling artifacts, making it a highly ill-posed inverse problem. Diffusion models can generate data/images by reversing a data-noising process through learned data distributions; and can be incorporated as a denoiser/regularizer in LA-CBCT reconstruction. In this study, we developed a diffusion model-based framework, prior frequency-guided diffusion model (PFGDM), for robust and structure-preserving LA-CBCT reconstruction. PFGDM uses a conditioned diffusion model as a regularizer for LA-CBCT reconstruction, and the condition is based on high-frequency information extracted from patient-specific prior CT scans which provides a strong ana
    
[^3]: NeuroPrune：一种受神经系统启发的用于大型语言模型的拓扑稀疏训练算法

    NeuroPrune: A Neuro-inspired Topological Sparse Training Algorithm for Large Language Models

    [https://arxiv.org/abs/2404.01306](https://arxiv.org/abs/2404.01306)

    本研究受神经系统启发，通过神经网络拓扑的稀疏方法，探索类似于生物网络的机制，展示了对各种 NLP 任务都表现出色和高效的模型-不可知稀疏性方法

    

    基于 Transformer 的语言模型由于在各种任务上的出色性能而在自然语言处理（NLP）中变得普遍。然而，昂贵的训练以及推理仍然是它们广泛适用性的一个重要障碍。在模型架构的各个层次强制引入稀疏性已被证明有助于解决扩展性和效率问题，但稀疏性对网络拓扑的影响仍存在断裂。受大脑神经网络启发，我们通过网络拓扑的视角探索稀疏性方法。具体而言，我们利用在生物网络中观察到的机制，如优先附着和冗余突触修剪，并展示了基于原则的、与模型无关的稀疏性方法在跨越分类（如自然语言推理）和生成（摘要、机器翻译）的各种 NLP 任务上表现出色且高效，尽管 o

    arXiv:2404.01306v1 Announce Type: cross  Abstract: Transformer-based Language Models have become ubiquitous in Natural Language Processing (NLP) due to their impressive performance on various tasks. However, expensive training as well as inference remains a significant impediment to their widespread applicability. While enforcing sparsity at various levels of the model architecture has found promise in addressing scaling and efficiency issues, there remains a disconnect between how sparsity affects network topology. Inspired by brain neuronal networks, we explore sparsity approaches through the lens of network topology. Specifically, we exploit mechanisms seen in biological networks, such as preferential attachment and redundant synapse pruning, and show that principled, model-agnostic sparsity approaches are performant and efficient across diverse NLP tasks, spanning both classification (such as natural language inference) and generation (summarization, machine translation), despite o
    
[^4]: 通过缓慢变化的序列实现稳定的机器学习模型重新训练

    Towards Stable Machine Learning Model Retraining via Slowly Varying Sequences

    [https://arxiv.org/abs/2403.19871](https://arxiv.org/abs/2403.19871)

    通过混合整数优化算法，以保持一致的分析洞见为重点，在重新训练机器学习模型中实现比贪婪训练更强稳定性，同时在模型性能上有小幅、可控的牺牲。

    

    重新训练机器学习模型仍然是实际机器学习模型部署的重要任务。现有方法主要关注贪婪方法，以找到表现最佳的模型，而不考虑通过不同的重新训练演变来保持训练模型结构的稳定性。在这项研究中，我们开发了一种混合整数优化算法，全面考虑了通过不同的数据批次更新重新训练机器学习模型的问题。我们的方法侧重于保留一致的分析洞见 - 这对于模型可解释性、实施简易性和与用户建立信任至关重要 - 通过使用可以直接纳入优化问题的自定义定义的距离度量。重要的是，我们的方法在真实的生产案例研究中表现出比贪婪训练模型更强的稳定性，同时在模型性能上有小幅、可控的牺牲。

    arXiv:2403.19871v1 Announce Type: cross  Abstract: Retraining machine learning models remains an important task for real-world machine learning model deployment. Existing methods focus largely on greedy approaches to find the best-performing model without considering the stability of trained model structures across different retraining evolutions. In this study, we develop a mixed integer optimization algorithm that holistically considers the problem of retraining machine learning models across different data batch updates. Our method focuses on retaining consistent analytical insights - which is important to model interpretability, ease of implementation, and fostering trust with users - by using custom-defined distance metrics that can be directly incorporated into the optimization problem. Importantly, our method shows stronger stability than greedily trained models with a small, controllable sacrifice in model performance in a real-world production case study. Finally, important an
    
[^5]: 解释基于Transformer模型的语言模型在事实回忆中的关键机制

    Interpreting Key Mechanisms of Factual Recall in Transformer-Based Language Models

    [https://arxiv.org/abs/2403.19521](https://arxiv.org/abs/2403.19521)

    通过深入研究Transformer-based语言模型在事实回忆任务中的机制，我们发现了零/少次样本情况下的特定任务头、MLP层和残差流的功能，以及抗过度自信机制。

    

    本文深入探讨了Transformer-based语言模型在事实回忆任务中所采用的机制。在零次样本情况下，给定类似“法国的首都是”的提示，特定任务的注意力头会从上下文中提取主题实体，如“法国”，并将其传递给后续的MLP以回忆所需的答案，如“巴黎”。我们引入了一种新颖的分析方法，旨在将MLP的输出分解为人类可理解的组件。通过这种方法，我们量化了跟随这些特定任务头的MLP层的功能。在残差流中，它会擦除或放大来自各个头的信息。此外，它会生成一个组件，将残差流重新定向到预期答案的方向。这些零次机制也适用于少次样本情况。此外，我们观察到一种广泛存在的抗过度自信机制。

    arXiv:2403.19521v1 Announce Type: cross  Abstract: In this paper, we deeply explore the mechanisms employed by Transformer-based language models in factual recall tasks. In zero-shot scenarios, given a prompt like "The capital of France is," task-specific attention heads extract the topic entity, such as "France," from the context and pass it to subsequent MLPs to recall the required answer such as "Paris." We introduce a novel analysis method aimed at decomposing the outputs of the MLP into components understandable by humans. Through this method, we quantify the function of the MLP layer following these task-specific heads. In the residual stream, it either erases or amplifies the information originating from individual heads. Moreover, it generates a component that redirects the residual stream towards the direction of its expected answer. These zero-shot mechanisms are also employed in few-shot scenarios. Additionally, we observed a widely existent anti-overconfidence mechanism in 
    
[^6]: 关于使用卷积神经网络进行学习收敛速率的研究

    On the rates of convergence for learning with convolutional neural networks

    [https://arxiv.org/abs/2403.16459](https://arxiv.org/abs/2403.16459)

    该研究提出了对具有一定权重约束的CNNs的新逼近上界，以及对前馈神经网络的覆盖数做了新的分析，为基于CNNs的学习问题推导了收敛速率，并在学习平滑函数和二元分类方面取得了极小最优的结果。

    

    我们研究了卷积神经网络（CNNs）的逼近和学习能力。第一个结果证明了在权重上有一定约束条件下CNNs的新逼近上界。第二个结果给出了对前馈神经网络的覆盖数的新分析，其中CNNs是其特例。该分析详细考虑了权重的大小，在某些情况下给出了比现有文献更好的上界。利用这两个结果，我们能够推导基于CNNs的估计器在许多学习问题中的收敛速率。特别地，我们在非参数回归设置中为基于CNNs的最小二乘学习平滑函数建立了极小最优的收敛速率。对于二元分类，我们推导了具有铰链损失和逻辑损失的CNN分类器的收敛速度。同时还表明所得到的速率在几种情况下是极小最优的。

    arXiv:2403.16459v1 Announce Type: new  Abstract: We study the approximation and learning capacities of convolutional neural networks (CNNs). Our first result proves a new approximation bound for CNNs with certain constraint on the weights. Our second result gives a new analysis on the covering number of feed-forward neural networks, which include CNNs as special cases. The analysis carefully takes into account the size of the weights and hence gives better bounds than existing literature in some situations. Using these two results, we are able to derive rates of convergence for estimators based on CNNs in many learning problems. In particular, we establish minimax optimal convergence rates of the least squares based on CNNs for learning smooth functions in the nonparametric regression setting. For binary classification, we derive convergence rates for CNN classifiers with hinge loss and logistic loss. It is also shown that the obtained rates are minimax optimal in several settings.
    
[^7]: GeRM：一种用于四足机器人的混合专家通用机器人模型

    GeRM: A Generalist Robotic Model with Mixture-of-experts for Quadruped Robot

    [https://arxiv.org/abs/2403.13358](https://arxiv.org/abs/2403.13358)

    GeRM是一种通用机器人模型，通过混合专家结构和离线强化学习优化数据利用策略，解决了多任务机器人学习中性能问题和数据收集困难的情况，显著提高了模型性能。

    

    多任务机器人学习在解决多样化和复杂情景方面具有重要意义。然而，当前的方法受到性能问题和收集训练数据集困难的阻碍。本文中，我们提出了GeRM（通用机器人模型）。我们利用离线强化学习优化数据利用策略，从演示和次优数据中学习，从而超越人类演示的局限。随后，我们采用基于Transformer的VLA网络来处理多模态输入并输出动作。通过引入专家混合结构，GeRM实现了更快的推理速度和更高的整体模型容量，从而解决了RL参数有限的问题，在控制计算成本的同时提高了多任务学习中模型的性能。通过一系列实验，我们证实GeRM在所有任务上表现优于其他方法, 而且还有效

    arXiv:2403.13358v1 Announce Type: cross  Abstract: Multi-task robot learning holds significant importance in tackling diverse and complex scenarios. However, current approaches are hindered by performance issues and difficulties in collecting training datasets. In this paper, we propose GeRM (Generalist Robotic Model). We utilize offline reinforcement learning to optimize data utilization strategies to learn from both demonstrations and sub-optimal data, thus surpassing the limitations of human demonstrations. Thereafter, we employ a transformer-based VLA network to process multi-modal inputs and output actions. By introducing the Mixture-of-Experts structure, GeRM allows faster inference speed with higher whole model capacity, and thus resolves the issue of limited RL parameters, enhancing model performance in multi-task learning while controlling computational costs. Through a series of experiments, we demonstrate that GeRM outperforms other methods across all tasks, while also valid
    
[^8]: 具有差分隐私的联邦迁移学习

    Federated Transfer Learning with Differential Privacy

    [https://arxiv.org/abs/2403.11343](https://arxiv.org/abs/2403.11343)

    本文提出了具有差分隐私的联邦迁移学习框架，通过利用多个异构源数据集的信息来增强对目标数据集的学习，同时考虑隐私约束。

    

    联邦学习越来越受到欢迎，数据异构性和隐私性是两个突出的挑战。在本文中，我们在联邦迁移学习框架内解决了这两个问题，旨在通过利用来自多个异构源数据集的信息来增强对目标数据集的学习，同时遵守隐私约束。我们严格制定了\textit{联邦差分隐私}的概念，为每个数据集提供隐私保证，而无需假设有一个受信任的中央服务器。在这个隐私约束下，我们研究了三个经典的统计问题，即单变量均值估计、低维线性回归和高维线性回归。通过研究极小值率并确定这些问题的隐私成本，我们展示了联邦差分隐私是已建立的局部和中央模型之间的一种中间隐私模型。

    arXiv:2403.11343v1 Announce Type: new  Abstract: Federated learning is gaining increasing popularity, with data heterogeneity and privacy being two prominent challenges. In this paper, we address both issues within a federated transfer learning framework, aiming to enhance learning on a target data set by leveraging information from multiple heterogeneous source data sets while adhering to privacy constraints. We rigorously formulate the notion of \textit{federated differential privacy}, which offers privacy guarantees for each data set without assuming a trusted central server. Under this privacy constraint, we study three classical statistical problems, namely univariate mean estimation, low-dimensional linear regression, and high-dimensional linear regression. By investigating the minimax rates and identifying the costs of privacy for these problems, we show that federated differential privacy is an intermediate privacy model between the well-established local and central models of 
    
[^9]: PeerAiD：改善专业同行导师的对抗性蒸馏

    PeerAiD: Improving Adversarial Distillation from a Specialized Peer Tutor

    [https://arxiv.org/abs/2403.06668](https://arxiv.org/abs/2403.06668)

    PeerAiD提出了一种新的对抗性蒸馏方法，通过让同行网络学习学生网络的对抗性示例，而不是自身的示例，来提升神经网络的鲁棒性。

    

    神经网络的对抗鲁棒性在应用于安全关键领域时是一个重要问题。在这种情况下，对抗性蒸馏是一种有前途的选择，旨在提炼教师网络的鲁棒性，以改进小型学生网络的鲁棒性。我们提出了PeerAiD，通过让同行网络学习学生网络的对抗性示例，而不是针对自身的对抗性示例，来改进对抗性蒸馏。PeerAiD是一种对抗性蒸馏，同时训练同行网络和学生网络。

    arXiv:2403.06668v1 Announce Type: new  Abstract: Adversarial robustness of the neural network is a significant concern when it is applied to security-critical domains. In this situation, adversarial distillation is a promising option which aims to distill the robustness of the teacher network to improve the robustness of a small student network. Previous works pretrain the teacher network to make it robust to the adversarial examples aimed at itself. However, the adversarial examples are dependent on the parameters of the target network. The fixed teacher network inevitably degrades its robustness against the unseen transferred adversarial examples which targets the parameters of the student network in the adversarial distillation process. We propose PeerAiD to make a peer network learn the adversarial examples of the student network instead of adversarial examples aimed at itself. PeerAiD is an adversarial distillation that trains the peer network and the student network simultaneousl
    
[^10]: 将Thompson抽样遗憾与Sigma比率（TS-RSR）最小化：一种用于批量贝叶斯优化的经过证明的高效算法

    Minimizing the Thompson Sampling Regret-to-Sigma Ratio (TS-RSR): a provably efficient algorithm for batch Bayesian Optimization

    [https://arxiv.org/abs/2403.04764](https://arxiv.org/abs/2403.04764)

    该论文提出了一种用于批量贝叶斯优化的高效算法，通过最小化Thompson抽样近似的遗憾与不确定性比率，成功协调每个批次的动作选择，同时实现高概率的理论保证，并在非凸测试函数上表现出色.

    

    本文提出了一个新的方法，用于批量贝叶斯优化（BO），其中抽样通过最小化Thompson抽样方法的遗憾与不确定性比率来进行。我们的目标是能够协调每个批次中选择的动作，以最小化点之间的冗余，同时关注具有高预测均值或高不确定性的点。我们对算法的遗憾提供了高概率的理论保证。最后，从数字上看，我们证明了我们的方法在一系列非凸测试函数上达到了最先进的性能，在平均值上比几个竞争对手的基准批量BO算法表现提高了一个数量级。

    arXiv:2403.04764v1 Announce Type: new  Abstract: This paper presents a new approach for batch Bayesian Optimization (BO), where the sampling takes place by minimizing a Thompson Sampling approximation of a regret to uncertainty ratio. Our objective is able to coordinate the actions chosen in each batch in a way that minimizes redundancy between points whilst focusing on points with high predictive means or high uncertainty. We provide high-probability theoretical guarantees on the regret of our algorithm. Finally, numerically, we demonstrate that our method attains state-of-the-art performance on a range of nonconvex test functions, where it outperforms several competitive benchmark batch BO algorithms by an order of magnitude on average.
    
[^11]: Hamiltonian性质测试

    Hamiltonian Property Testing

    [https://arxiv.org/abs/2403.02968](https://arxiv.org/abs/2403.02968)

    本文研究了Hamiltonian的本地性测试作为属性测试问题，重点在于确定未知的$n$比特Hamiltonian是否是$k$局部的，通过对$H$的时间演化进行访问来解决问题。

    

    本文研究了Hamiltonian本地性测试作为一个属性测试问题，即确定一个未知的$n$比特Hamiltonian $H$是否是$k$局部的，或者与所有$k$局部Hamiltonian都相距$\varepsilon$，并通过对$H$的时间演化进行访问来解决问题。

    arXiv:2403.02968v1 Announce Type: cross  Abstract: Locality is a fundamental feature of many physical time evolutions. Assumptions on locality and related structural properties also underlie recently proposed procedures for learning an unknown Hamiltonian from access to the induced time evolution. However, no protocols to rigorously test whether an unknown Hamiltonian is local were known. We investigate Hamiltonian locality testing as a property testing problem, where the task is to determine whether an unknown $n$-qubit Hamiltonian $H$ is $k$-local or $\varepsilon$-far from all $k$-local Hamiltonians, given access to the time evolution along $H$. First, we emphasize the importance of the chosen distance measure: With respect to the operator norm, a worst-case distance measure, incoherent quantum locality testers require $\tilde{\Omega}(2^n)$ many time evolution queries and an expected total evolution time of $\tilde{\Omega}(2^n / \varepsilon)$, and even coherent testers need $\Omega(2
    
[^12]: 在动态环境中的聚类：具有异质性变化的基准数据集生成框架

    Clustering in Dynamic Environments: A Framework for Benchmark Dataset Generation With Heterogeneous Changes

    [https://arxiv.org/abs/2402.15731](https://arxiv.org/abs/2402.15731)

    本论文引入了Dynamic Dataset Generator（DDG）来解决在动态环境中进行聚类时缺乏多样性、可控性和现实性动态数据集的问题，从而帮助设计更有效的聚类算法。

    

    在动态环境中进行聚类是越来越重要的，具有广泛的应用范围，从实时数据分析和在线无监督学习到动态设施定位问题。尽管元启发式在静态聚类任务中表现出有希望的有效性，但它们在动态环境中跟踪最佳聚类解决方案或在时间上稳健地进行聚类的应用仍然很少探讨。这在一定程度上是由于缺乏具有多样性、可控性和现实性动态特征的动态数据集，阻碍了在各种动态场景中对聚类算法进行系统性性能评估。这种缺陷导致我们对在动态环境中设计聚类算法的理解和能力存在差距。为了弥补这一差距，本文引入了动态数据集生成器（DDG）。DDG具有多个动态高斯组件，集成了一系列异质性特征。

    arXiv:2402.15731v1 Announce Type: new  Abstract: Clustering in dynamic environments is of increasing importance, with broad applications ranging from real-time data analysis and online unsupervised learning to dynamic facility location problems. While meta-heuristics have shown promising effectiveness in static clustering tasks, their application for tracking optimal clustering solutions or robust clustering over time in dynamic environments remains largely underexplored. This is partly due to a lack of dynamic datasets with diverse, controllable, and realistic dynamic characteristics, hindering systematic performance evaluations of clustering algorithms in various dynamic scenarios. This deficiency leads to a gap in our understanding and capability to effectively design algorithms for clustering in dynamic environments. To bridge this gap, this paper introduces the Dynamic Dataset Generator (DDG). DDG features multiple dynamic Gaussian components integrated with a range of heterogeneo
    
[^13]: 强健的智能体学习因果世界模型

    Robust agents learn causal world models

    [https://arxiv.org/abs/2402.10877](https://arxiv.org/abs/2402.10877)

    智能体必须学习因果模型才能在广泛的分布转变下达到后悔界限，这对迁移学习和因果推断等研究领域有重要影响。

    

    一直有人假设因果推理在强健且具有通用智能中起着基础作用，然而不清楚智能体是否必须学习因果模型才能推广到新的领域，或者其他归纳偏差是否足够。我们回答了这个问题，表明任何能够在大量分布转变下满足后悔界限的智能体必须学习数据生成过程的近似因果模型，对于优化智能体来说，该近似模型会收敛到真实的因果模型。我们讨论了这一结果对于多个研究领域，包括迁移学习和因果推断的影响。

    arXiv:2402.10877v1 Announce Type: new  Abstract: It has long been hypothesised that causal reasoning plays a fundamental role in robust and general intelligence. However, it is not known if agents must learn causal models in order to generalise to new domains, or if other inductive biases are sufficient. We answer this question, showing that any agent capable of satisfying a regret bound under a large set of distributional shifts must have learned an approximate causal model of the data generating process, which converges to the true causal model for optimal agents. We discuss the implications of this result for several research areas including transfer learning and causal inference.
    
[^14]: 学习快速变化的慢性在脉冲神经网络中

    Learning fast changing slow in spiking neural networks

    [https://arxiv.org/abs/2402.10069](https://arxiv.org/abs/2402.10069)

    通过近端策略优化实现的生物学可行方法在脉冲神经网络中减轻了强化学习所面临的数据稀缺性和噪声引入的困难。

    

    强化学习在现实问题中面临着很大的挑战，主要源于与环境的有限交互导致的可用数据的稀缺性。 RL通常需要大量的数据来进行有效的学习，这使得复杂性进一步增加，尤其是在使用循环脉冲网络实现RL时，脉冲引入的固有噪声增加了难度。终身学习机器在本质上必须解决可塑性-稳定性悖论。在获得新知识和保持稳定之间取得平衡对于人工智能代理至关重要。在这个背景下，我们从机器学习技术中汲取灵感，并引入了一种生物可行的近端策略优化实现，认为它显著减轻了此挑战。我们的方法带来了两个重要的进展：首先，能够...

    arXiv:2402.10069v1 Announce Type: cross  Abstract: Reinforcement learning (RL) faces substantial challenges when applied to real-life problems, primarily stemming from the scarcity of available data due to limited interactions with the environment. This limitation is exacerbated by the fact that RL often demands a considerable volume of data for effective learning. The complexity escalates further when implementing RL in recurrent spiking networks, where inherent noise introduced by spikes adds a layer of difficulty. Life-long learning machines must inherently resolve the plasticity-stability paradox. Striking a balance between acquiring new knowledge and maintaining stability is crucial for artificial agents. In this context, we take inspiration from machine learning technology and introduce a biologically plausible implementation of proximal policy optimization, arguing that it significantly alleviates this challenge. Our approach yields two notable advancements: first, the ability t
    
[^15]: 深度平衡算法推理器

    The Deep Equilibrium Algorithmic Reasoner

    [https://arxiv.org/abs/2402.06445](https://arxiv.org/abs/2402.06445)

    本文介绍了一种深度平衡算法推理器，可以通过直接找到算法的平衡点来训练网络解决算法问题。

    

    最近关于神经算法推理的研究表明，图神经网络（GNNs）可以学习执行经典算法。然而，这样做一直使用的是递归架构，其中每个GNN的迭代与算法的迭代一致。由于算法的解通常是一个平衡点，我们猜测并经验性地验证，可以通过直接找到平衡点来训练网络解决算法问题。注意，这不需要将每个GNN的迭代与算法的步骤匹配。

    Recent work on neural algorithmic reasoning has demonstrated that graph neural networks (GNNs) could learn to execute classical algorithms. Doing so, however, has always used a recurrent architecture, where each iteration of the GNN aligns with an algorithm's iteration. Since an algorithm's solution is often an equilibrium, we conjecture and empirically validate that one can train a network to solve algorithmic problems by directly finding the equilibrium. Note that this does not require matching each GNN iteration with a step of the algorithm.
    
[^16]: 近确定性回归中的错误规范化不确定性

    Misspecification uncertainties in near-deterministic regression

    [https://arxiv.org/abs/2402.01810](https://arxiv.org/abs/2402.01810)

    该论文研究了近确定性回归中错误规范化的不确定性问题，并提出了一种组合模型，以准确预测和控制参数不确定性。

    

    期望损失是模型泛化误差的上界，可用于学习的鲁棒PAC-Bayes边界。然而，损失最小化被认为忽略了错误规范化，即模型不能完全复制观测结果。这导致大数据或欠参数化极限下对参数不确定性的显著低估。我们分析近确定性、错误规范化和欠参数化替代模型的泛化误差，这是科学和工程中广泛相关的一个领域。我们证明后验分布必须覆盖每个训练点，以避免发散的泛化误差，并导出一个符合这个约束的组合模型。对于线性模型，这种高效的方法产生的额外开销最小。这种高效方法在模型问题上进行了演示，然后应用于原子尺度机器学习中的高维数据集。

    The expected loss is an upper bound to the model generalization error which admits robust PAC-Bayes bounds for learning. However, loss minimization is known to ignore misspecification, where models cannot exactly reproduce observations. This leads to significant underestimates of parameter uncertainties in the large data, or underparameterized, limit. We analyze the generalization error of near-deterministic, misspecified and underparametrized surrogate models, a regime of broad relevance in science and engineering. We show posterior distributions must cover every training point to avoid a divergent generalization error and derive an ensemble {ansatz} that respects this constraint, which for linear models incurs minimal overhead. The efficient approach is demonstrated on model problems before application to high dimensional datasets in atomistic machine learning. Parameter uncertainties from misspecification survive in the underparametrized limit, giving accurate prediction and boundin
    
[^17]: BEND: 在具有生物意义的任务上对DNA语言模型进行基准测试

    BEND: Benchmarking DNA Language Models on biologically meaningful tasks

    [https://arxiv.org/abs/2311.12570](https://arxiv.org/abs/2311.12570)

    BEND是一个针对DNA语言模型的基准测试，包含一系列在人类基因组上定义的现实且具有生物意义的下游任务。

    

    基因组序列包含了指导细胞过程的蓝图。尽管过去几十年来基因组的可用性大大增加，但对DNA序列中编码的各种功能性、非编码和调节元素进行实验注释仍既昂贵又具挑战性。这引发了对基因组DNA进行无监督语言建模的兴趣，这种范式在蛋白序列数据中取得了巨大成功。尽管提出了各种DNA语言模型，但个别作品之间的评估任务往往不同，并且可能无法完全复制基因组注释的基本挑战，包括数据的长度、规模和稀疏性。在这项研究中，我们引入了BEND，一个针对DNA语言模型的基准测试，其中包含了一系列定义在人类基因组上的现实和有生物意义的下游任务。我们发现当前DNA语言模型的嵌入可以接近pe

    arXiv:2311.12570v3 Announce Type: replace-cross  Abstract: The genome sequence contains the blueprint for governing cellular processes. While the availability of genomes has vastly increased over the last decades, experimental annotation of the various functional, non-coding and regulatory elements encoded in the DNA sequence remains both expensive and challenging. This has sparked interest in unsupervised language modeling of genomic DNA, a paradigm that has seen great success for protein sequence data. Although various DNA language models have been proposed, evaluation tasks often differ between individual works, and might not fully recapitulate the fundamental challenges of genome annotation, including the length, scale and sparsity of the data. In this study, we introduce BEND, a Benchmark for DNA language models, featuring a collection of realistic and biologically meaningful downstream tasks defined on the human genome. We find that embeddings from current DNA LMs can approach pe
    
[^18]: 机器学习训练数据分布特性的验证

    Attesting Distributional Properties of Training Data for Machine Learning

    [https://arxiv.org/abs/2308.09552](https://arxiv.org/abs/2308.09552)

    提出了一种新型的财产证明概念，可以在不泄露数据的情况下向验证者展示训练数据的分布特性。

    

    机器学习的成功伴随着对其可信度的增加关注。一些司法管辖区正在准备机器学习监管框架。其中一个关注点是确保模型训练数据具有某些特定敏感属性的理想分布特性。我们提出了财产证明的概念，允许证明者（例如，模型训练者）向验证者（例如，客户）展示训练数据的相关分布特性，而不泄露数据。我们提出了一种有效的混合财产证明，结合了财产推理与加密机制。

    arXiv:2308.09552v3 Announce Type: replace-cross  Abstract: The success of machine learning (ML) has been accompanied by increased concerns about its trustworthiness. Several jurisdictions are preparing ML regulatory frameworks. One such concern is ensuring that model training data has desirable distributional properties for certain sensitive attributes. For example, draft regulations indicate that model trainers are required to show that training datasets have specific distributional properties, such as reflecting diversity of the population. We propose the notion of property attestation allowing a prover (e.g., model trainer) to demonstrate relevant distributional properties of training data to a verifier (e.g., a customer) without revealing the data. We present an effective hybrid property attestation combining property inference with cryptographic mechanisms.
    
[^19]: 完全欧几里得图的完全神经网络

    Complete Neural Networks for Complete Euclidean Graphs

    [https://arxiv.org/abs/2301.13821](https://arxiv.org/abs/2301.13821)

    神经网络模型可以通过应用3-WL图同构测试于点云的Gram矩阵，或者应用欧几里得2-WL测试，在多项式复杂度内实现对完全欧几里得图的完全确定性

    

    最近，在对点云建模时，神经网络已经取得了成功，因为它们尊重排列和刚性运动的自然不变性，从分子动力学到推荐系统，从几何现象到推荐系统。然而，迄今未知具有多项式复杂性的模型是完备的，即能够区分任意一对非同构点云。我们通过展示可以将点云完全确定，直到排列和刚性运动，通过将3-WL图同构测试应用于点云的集中Gram矩阵来填补这一理论空白。此外，我们制定了2-WL测试的欧几里得变体，并展示它也足以实现完整性。然后，我们展示了如何通过中等大小的欧几里得图神经网络模拟我们的完全欧几里得WL测试，并展示了它们在高度对称的点云上的分离能力。

    arXiv:2301.13821v3 Announce Type: replace  Abstract: Neural networks for point clouds, which respect their natural invariance to permutation and rigid motion, have enjoyed recent success in modeling geometric phenomena, from molecular dynamics to recommender systems. Yet, to date, no model with polynomial complexity is known to be complete, that is, able to distinguish between any pair of non-isomorphic point clouds. We fill this theoretical gap by showing that point clouds can be completely determined, up to permutation and rigid motion, by applying the 3-WL graph isomorphism test to the point cloud's centralized Gram matrix. Moreover, we formulate an Euclidean variant of the 2-WL test and show that it is also sufficient to achieve completeness. We then show how our complete Euclidean WL tests can be simulated by an Euclidean graph neural network of moderate size and demonstrate their separation capability on highly symmetrical point clouds.
    
[^20]: TeenyTinyLlama：基于巴西葡萄牙语训练的开源微型语言模型

    TeenyTinyLlama: open-source tiny language models trained in Brazilian Portuguese. (arXiv:2401.16640v1 [cs.CL])

    [http://arxiv.org/abs/2401.16640](http://arxiv.org/abs/2401.16640)

    这篇论文开发了用于低资源环境中的开放式基础模型，以巴西葡萄牙语为例，发布在GitHub和Hugging Face上供社区使用和进一步开发。

    

    大型语言模型（LLMs）在自然语言处理方面取得了显著的进展，但在各种语言中的进展还不平衡。虽然大多数LLMs是在像英语这样的高资源语言中训练的，但多语言模型通常比单语言模型表现稍差。此外，它们的多语言基础有时会限制它们产生的副产品，如计算需求和许可制度。在本研究中，我们记录了为在低资源环境中使用而量身定制的开放式基础模型的开发过程、其局限性和优势。这就是TeenyTinyLlama：两个用于巴西葡萄牙语文本生成的紧凑型模型。我们在GitHub和Hugging Face上以宽松的Apache 2.0许可证发布它们，供社区使用和进一步开发。详见https://github.com/Nkluge-correa/TeenyTinyLlama

    Large language models (LLMs) have significantly advanced natural language processing, but their progress has yet to be equal across languages. While most LLMs are trained in high-resource languages like English, multilingual models generally underperform monolingual ones. Additionally, aspects of their multilingual foundation sometimes restrict the byproducts they produce, like computational demands and licensing regimes. In this study, we document the development of open-foundation models tailored for use in low-resource settings, their limitations, and their benefits. This is the TeenyTinyLlama pair: two compact models for Brazilian Portuguese text generation. We release them under the permissive Apache 2.0 license on GitHub and Hugging Face for community use and further development. See https://github.com/Nkluge-correa/TeenyTinyLlama
    
[^21]: 微小时间混合器 (TTMs): 针对多变量时间序列的增强零/少样本预测的快速预训练模型

    Tiny Time Mixers (TTMs): Fast Pretrained Models for Enhanced Zero/Few-Shot Forecasting of Multivariate Time Series. (arXiv:2401.03955v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.03955](http://arxiv.org/abs/2401.03955)

    本论文介绍了一种名为微小时间混合器 (TTMs) 的预训练模型，该模型针对多变量时间序列的零/少样本预测进行了优化。与大型预训练模型相比，TTMs模型更小、更快，并考虑了跨通道相关性，能够在短时间内进行有效的预测。

    

    零/少样本学习的大型预训练模型在语言和视觉领域表现出色，但在多变量时间序列 (TS) 中面临着多样性和公开预训练数据稀缺的挑战。因此，最近在时间序列预测中使用预训练的大型语言模型 (LLMs) 进行各种适应的趋势逐渐增加。这些方法利用跨领域迁移学习，出奇地取得了令人印象深刻的结果。然而，这些模型通常非常缓慢且庞大（大约十亿个参数），并且不考虑跨通道相关性。为了解决这个问题，我们提出了多层微小时间混合器 (TTM)，这是一种基于轻量级 TSMixer 结构的显著小型模型。TTM 是首个成功开发的微型通用预训练模型（≤100万个参数），专门在公开TS数据集上进行快速训练（仅需4-8小时），具有有效的迁移学习能力进行预测。

    Large Pretrained models for zero/few-shot learning excel in language and vision domains but encounter challenges in multivariate time series (TS) due to the diverse nature and scarcity of publicly available pretraining data. Consequently, there has been a recent surge in utilizing pretrained large language models (LLMs) with various adaptations for time series forecasting. These approaches employ cross-domain transfer learning and surprisingly yield impressive results. However, these models are typically very slow and large ($\sim$billion parameters) and do not consider cross-channel correlations. To address this, we present Multi-level Tiny Time Mixers (TTM), a significantly small model based on the lightweight TSMixer architecture. TTM marks the first success in developing tiny general-pretrained models ($\le$1 million parameters), exclusively trained on public TS datasets in a flash of just 4-8 hrs with effective transfer learning capabilities for forecasting. To tackle the complexi
    
[^22]: FedQV: 在联邦学习中利用二次投票机制

    FedQV: Leveraging Quadratic Voting in Federated Learning. (arXiv:2401.01168v1 [cs.CR])

    [http://arxiv.org/abs/2401.01168](http://arxiv.org/abs/2401.01168)

    本文提出了FedQV，这是一个在联邦学习中利用二次投票机制的新型聚合算法，旨在解决现有方法中容易受到污染攻击的问题。理论和实证分析表明，FedQV是一个真实机制，并且具有与现有方法相匹配的收敛速率。

    

    联邦学习（FL）允许不同方共同训练一个全局模型，而不需要透露各自的本地标签。FL的关键步骤之一是将本地模型聚合成全局模型，这与公共决策，尤其是选举，有很多相似之处。在这种情况下，FL的一个主要弱点是其易受污染攻击的脆弱性，可以解释为现代聚合规则中“一人一票”原则（即1p1v）的后果。本文提出了FedQV，这是一个基于二次投票机制的新型聚合算法，该机制最近被提出作为1p1v选举的更好替代方案。我们的理论分析表明，FedQV是一个真实机制，根据自己的真实估值进行投标是一个占主导地位的策略，其收敛速率与现有方法相匹配。此外，我们使用多个真实数据集进行的实证分析...

    Federated Learning (FL) permits different parties to collaboratively train a global model without disclosing their respective local labels. A crucial step of FL, that of aggregating local models to produce the global one, shares many similarities with public decision-making, and elections in particular. In that context, a major weakness of FL, namely its vulnerability to poisoning attacks, can be interpreted as a consequence of the one person one vote (henceforth 1p1v) principle underpinning most contemporary aggregation rules. In this paper, we propose FedQV, a novel aggregation algorithm built upon the quadratic voting scheme, recently proposed as a better alternative to 1p1v-based elections. Our theoretical analysis establishes that FedQV is a truthful mechanism in which bidding according to one's true valuation is a dominant strategy that achieves a convergence rate that matches those of state-of-the-art methods. Furthermore, our empirical analysis using multiple real-world dataset
    
[^23]: 消除差距：基于模型预测控制的可验证模型无关二次规划控制器的学习

    Bridging the Gaps: Learning Verifiable Model-Free Quadratic Programming Controllers Inspired by Model Predictive Control. (arXiv:2312.05332v3 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2312.05332](http://arxiv.org/abs/2312.05332)

    本文提出了一种新的参数化控制器类，利用深度强化学习训练其控制器的参数，从而消除了常见控制器中的可验证性和性能保证的限制。该控制器类似于模型预测控制问题的二次规划求解器，具有可验证的属性，并且在控制性能和鲁棒性方面与其他控制器相媲美。同时，该控制器的计算效率显著优于传统的模型预测控制。

    

    本文介绍了一种新的参数化控制器类，受到模型预测控制（MPC）的启发。该控制器类似于线性MPC问题的二次规划（QP）求解器，但控制器的参数是通过深度强化学习（DRL）进行训练，而不是从系统模型中推导出来的。这种方法解决了常见控制器中使用MLP或其他通用神经网络架构的DRL的可验证性和性能保证的局限性，并且所学习的控制器具有与MPC类似的持续可行性和渐近稳定性等可验证属性。另一方面，数值实验表明，所提出的控制器在控制性能上与MPC和MLP控制器相匹配，并且对建模不确定性和噪声具有更优的鲁棒性。此外，所提出的控制器在计算效率上明显优于MPC。

    In this paper, we introduce a new class of parameterized controllers, drawing inspiration from Model Predictive Control (MPC). The controller resembles a Quadratic Programming (QP) solver of a linear MPC problem, with the parameters of the controller being trained via Deep Reinforcement Learning (DRL) rather than derived from system models. This approach addresses the limitations of common controllers with Multi-Layer Perceptron (MLP) or other general neural network architecture used in DRL, in terms of verifiability and performance guarantees, and the learned controllers possess verifiable properties like persistent feasibility and asymptotic stability akin to MPC. On the other hand, numerical examples illustrate that the proposed controller empirically matches MPC and MLP controllers in terms of control performance and has superior robustness against modeling uncertainty and noises. Furthermore, the proposed controller is significantly more computationally efficient compared to MPC a
    
[^24]: 对于文本预测的忠实和稳健的本地可解释性

    Faithful and Robust Local Interpretability for Textual Predictions. (arXiv:2311.01605v1 [cs.CL])

    [http://arxiv.org/abs/2311.01605](http://arxiv.org/abs/2311.01605)

    提出了一种名为FRED的新颖方法，用于解释文本预测。FRED可以识别文档中的关键词，并且通过与最先进的方法进行的实证评估证明了其在提供对文本模型的深入见解方面的有效性。

    

    可解释性对于机器学习模型在关键领域中得到信任和部署是至关重要的。然而，现有的用于解释文本模型的方法通常复杂，并且缺乏坚实的数学基础，它们的性能也不能保证。在本文中，我们提出了一种新颖的方法FRED（Faithful and Robust Explainer for textual Documents），用于解释文本预测。FRED可以识别文档中的关键词，当这些词被移除时对预测结果产生重大影响。我们通过正式的定义和对可解释分类器的理论分析，确立了FRED的可靠性。此外，我们还通过与最先进的方法进行的实证评估，证明了FRED在提供对文本模型的深入见解方面的有效性。

    Interpretability is essential for machine learning models to be trusted and deployed in critical domains. However, existing methods for interpreting text models are often complex, lack solid mathematical foundations, and their performance is not guaranteed. In this paper, we propose FRED (Faithful and Robust Explainer for textual Documents), a novel method for interpreting predictions over text. FRED identifies key words in a document that significantly impact the prediction when removed. We establish the reliability of FRED through formal definitions and theoretical analyses on interpretable classifiers. Additionally, our empirical evaluation against state-of-the-art methods demonstrates the effectiveness of FRED in providing insights into text models.
    
[^25]: 在时间序列预测中，量子长短期记忆（QLSTM）与经典LSTM的比较研究：以太阳能预测为例

    Quantum Long Short-Term Memory (QLSTM) vs Classical LSTM in Time Series Forecasting: A Comparative Study in Solar Power Forecasting. (arXiv:2310.17032v1 [quant-ph])

    [http://arxiv.org/abs/2310.17032](http://arxiv.org/abs/2310.17032)

    本研究比较了量子长短期记忆（QLSTM）和经典长短期记忆（LSTM）模型在太阳能发电量预测中的表现，发现QLSTM具有加快训练收敛速度和减小测试损失的优势，拥有吸纳复杂时间序列关系的潜力，但还需要进一步研究和优化。

    

    在全球向可持续能源系统发展的过程中，准确预测太阳能发电量至关重要。在本研究中，我们对量子长短期记忆（QLSTM）和经典长短期记忆（LSTM）模型在太阳能发电预测方面进行了仔细比较。我们的实验结果显示，QLSTM具有显著优势，包括训练收敛速度加快和在初始阶段明显降低的测试损失，相比之下，经典LSTM模型。这些实证结果表明，QLSTM有潜力快速吸纳复杂的时间序列关系，这得益于量子现象（如叠加）。然而，要实现QLSTM的全部能力，还需要进一步研究模型在不同条件下的验证、系统的超参数优化、硬件噪声鲁棒性，以及相关可再生能源预测问题的应用。随着不断的进展，量子机器学习可以在预测和优化复杂问题方面带来变革。

    Accurately forecasting solar power generation is crucial in the global progression towards sustainable energy systems. In this study, we conduct a meticulous comparison between Quantum Long Short-Term Memory (QLSTM) and classical Long Short-Term Memory (LSTM) models for solar power production forecasting. Our controlled experiments reveal promising advantages of QLSTMs, including accelerated training convergence and substantially reduced test loss within the initial epoch compared to classical LSTMs. These empirical findings demonstrate QLSTM's potential to swiftly assimilate complex time series relationships, enabled by quantum phenomena like superposition. However, realizing QLSTM's full capabilities necessitates further research into model validation across diverse conditions, systematic hyperparameter optimization, hardware noise resilience, and applications to correlated renewable forecasting problems. With continued progress, quantum machine learning can offer a paradigm shift in
    
[^26]: 理解算法公平性中的公平性代理函数

    Understanding Fairness Surrogate Functions in Algorithmic Fairness. (arXiv:2310.11211v1 [cs.LG])

    [http://arxiv.org/abs/2310.11211](http://arxiv.org/abs/2310.11211)

    本文研究了算法公平性中的公平性代理函数，并发现了代理和公平性定义之间存在一个差距。这个差距决定了一个代理函数能否适当替代一个公平性定义。

    

    已观察到机器学习算法对某些人群产生偏见的预测。为了减轻这种偏见并实现可比的准确性，一种有希望的方法是引入涉及公平性定义的代理函数，并解决一个受限制的优化问题。然而，在以往的研究中，一个有趣的问题是这种公平性代理函数可能导致不公平的结果。在本研究中，为了深入理解这个问题，我们以广泛使用的公平性定义——人口统计平等——为例，从理论和实证上证明了公平性定义和公平性代理函数之间存在一个代理-公平性差距。这个"差距"直接决定了一个代理函数是否适合替代一个公平性定义。此外，关于这个"差距"的理论分析和实验结果激发了我们的兴趣，表明无限制的代理函数将受到决策边界远离的点的影响。

    It has been observed that machine learning algorithms exhibit biased predictions against certain population groups. To mitigate such bias while achieving comparable accuracy, a promising approach is to introduce surrogate functions of the concerned fairness definition and solve a constrained optimization problem. However, an intriguing issue in previous work is that such fairness surrogate functions may yield unfair results. In this work, in order to deeply understand this issue, taking a widely used fairness definition, demographic parity as an example, we both theoretically and empirically show that there is a surrogate-fairness gap between the fairness definition and the fairness surrogate function. The "gap" directly determines whether a surrogate function is an appropriate substitute for a fairness definition. Also, the theoretical analysis and experimental results about the "gap" motivate us that the unbounded surrogate functions will be affected by the points far from the decisi
    
[^27]: 用不确定性量化增强基于机器学习的网络入侵检测的可信度

    Enhancing Trustworthiness in ML-Based Network Intrusion Detection with Uncertainty Quantification. (arXiv:2310.10655v1 [cs.CR])

    [http://arxiv.org/abs/2310.10655](http://arxiv.org/abs/2310.10655)

    这项研究提出了一种通过不确定性量化来增强基于机器学习的网络入侵检测的可信度的方法。

    

    互联网和相关通信技术的发展不断增加了网络攻击的风险。在这种情况下，入侵检测系统（IDS）发挥着至关重要的作用，这是一种旨在识别和缓解对现代网络的攻击的安全设备。在过去的十年中，基于机器学习（ML）的数据驱动方法越来越受到欢迎，用于执行IDS所需的分类任务。然而，为了适应这个目的而采用的典型的ML模型没有适当地考虑到与其自身预测相关的不确定性。这带来了显著的挑战，因为它们往往会为误分类的输入和属于未知类别（例如新型攻击）的输入产生误导性较高的分类得分，限制了现有基于ML的解决方案的可信度。在本文中，我们认为基于ML的IDS应该始终提供准确的不确定性量化，以避免过度自信的预测。事实上，一种准确的不确定性量化可以为进一步的决策提供重要的参考，从而增强ML-based IDS的可信度。

    The evolution of Internet and its related communication technologies have consistently increased the risk of cyber-attacks. In this context, a crucial role is played by Intrusion Detection Systems (IDSs), which are security devices designed to identify and mitigate attacks to modern networks. In the last decade, data-driven approaches based on Machine Learning (ML) have gained more and more popularity for executing the classification tasks required by IDSs. However, typical ML models adopted for this purpose do not properly take into account the uncertainty associated with their own prediction. This poses significant challenges, as they tend to produce misleadingly high classification scores for both misclassified inputs and inputs belonging to unknown classes (e.g. novel attacks), limiting the trustworthiness of existing ML-based solutions. In this paper we argue that ML-based IDSs should always provide accurate uncertainty quantification to avoid overconfident predictions. In fact, a
    
[^28]: 时间序列分类的数据增强：一项广泛的实证研究和综述

    Data Augmentation for Time-Series Classification: An Extensive Empirical Study and Comprehensive Survey. (arXiv:2310.10060v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.10060](http://arxiv.org/abs/2310.10060)

    本研究对时间序列分类中的数据增强方法进行了广泛研究和综述，总结了60多种独特的方法，并提出了一个针对TSC的新的分类体系。

    

    数据增强（DA）已成为时间序列分类（TSC）中不可或缺的策略，主要因为它可以增加训练样本的数量，从而提高模型的健壮性，使数据集多样化，并减少过拟合。然而，目前TSC中的DA研究存在着文献评审的片段化，方法学分类不清晰，评估指标不足以及缺乏用户友好的工具等问题。鉴于这些挑战，本研究对TSC领域中的DA方法进行了详尽的研究。我们首先进行了持续十年的广泛文献回顾，发现当代综述文章很少能够涵盖DA在TSC上的全部进展，因此我们仔细分析了100多篇学术文章，总结出了60多种独特的DA技术。这项严格的分析形成了一种新颖的分类体系，专门针对TSC中的DA细节进行分类。

    Data Augmentation (DA) has emerged as an indispensable strategy in Time Series Classification (TSC), primarily due to its capacity to amplify training samples, thereby bolstering model robustness, diversifying datasets, and curtailing overfitting. However, the current landscape of DA in TSC is plagued with fragmented literature reviews, nebulous methodological taxonomies, inadequate evaluative measures, and a dearth of accessible, user-oriented tools. In light of these challenges, this study embarks on an exhaustive dissection of DA methodologies within the TSC realm. Our initial approach involved an extensive literature review spanning a decade, revealing that contemporary surveys scarcely capture the breadth of advancements in DA for TSC, prompting us to meticulously analyze over 100 scholarly articles to distill more than 60 unique DA techniques. This rigorous analysis precipitated the formulation of a novel taxonomy, purpose-built for the intricacies of DA in TSC, categorizing tech
    
[^29]: 基于锚点的多视图子空间聚类与分层特征下降

    Anchor-based Multi-view Subspace Clustering with Hierarchical Feature Descent. (arXiv:2310.07166v1 [cs.CV])

    [http://arxiv.org/abs/2310.07166](http://arxiv.org/abs/2310.07166)

    本文提出了一种基于锚点的多视图子空间聚类方法，通过分层特征下降挖掘和部署视图之间的依赖关系，从而在聚类过程中实现了对不同视图的特征对齐。这种方法得到了一个共同的潜在空间，被称为“相似空间”，揭示了不同视图之间的相关性和依赖关系。

    

    多视图聚类因其能够从多个信息源中聚合信息的能力以及在公共事务中有前景的潜力而引起越来越多的关注。迄今为止，在近期文献中提出了许多先进的方法。然而，仍然存在一些难题需要解决。在试图对不同视图的特征进行对齐时，出现了一个常见的困境。我们通过分层特征下降挖掘和部署视图之间的依赖关系，从而导致一个共同的潜在空间（第一阶段）。这个潜在空间首次被视为“相似空间”，因为它揭示了不同视图之间的某些相关性和依赖关系。更准确地说，类别的独热编码也可以被称为终止阶段的相似空间。此外，由于大多数现有的多视图聚类算法起源于k-means聚类和谱聚类，这导致了立方时间复杂度。

    Multi-view clustering has attracted growing attention owing to its capabilities of aggregating information from various sources and its promising horizons in public affairs. Up till now, many advanced approaches have been proposed in recent literature. However, there are several ongoing difficulties to be tackled. One common dilemma occurs while attempting to align the features of different views. We dig out as well as deploy the dependency amongst views through hierarchical feature descent, which leads to a common latent space( STAGE 1). This latent space, for the first time of its kind, is regarded as a 'resemblance space', as it reveals certain correlations and dependencies of different views. To be exact, the one-hot encoding of a category can also be referred to as a resemblance space in its terminal phase. Moreover, due to the intrinsic fact that most of the existing multi-view clustering algorithms stem from k-means clustering and spectral clustering, this results in cubic time 
    
[^30]: ExIFFI和EIF+：解释性和增强的推广能力以扩展扩展孤立森林

    ExIFFI and EIF+: Interpretability and Enhanced Generalizability to Extend the Extended Isolation Forest. (arXiv:2310.05468v1 [stat.ML])

    [http://arxiv.org/abs/2310.05468](http://arxiv.org/abs/2310.05468)

    本研究介绍了EIF+和ExIFFI两种改进了扩展孤立森林的方法，分别增强了模型的推广能力和解释性能，实验结果表明其在异常检测任务中具有优势。

    

    异常检测是一种重要的无监督机器学习任务，涉及在复杂数据集和系统中识别异常行为。虽然机器学习算法和决策支持系统（DSS）提供了有效的解决方案，但仅仅定位异常往往在实际应用中不足。这些系统的用户通常需要了解预测背后的原因，以便进行根本原因分析并增强对模型的信任。然而，由于异常检测的无监督性质，创建可解释的工具是具有挑战性的。本文介绍了EIF+，这是扩展孤立森林（EIF）的增强变体，旨在增强泛化能力。此外，我们提出了ExIFFI，一种将扩展孤立森林与解释性功能（特征排名）相结合的新方法。实验结果提供了以孤立基于方法进行异常检测的综合比较分析。

    Anomaly detection, an essential unsupervised machine learning task, involves identifying unusual behaviors within complex datasets and systems. While Machine Learning algorithms and decision support systems (DSSs) offer effective solutions for this task, simply pinpointing anomalies often falls short in real-world applications. Users of these systems often require insight into the underlying reasons behind predictions to facilitate Root Cause Analysis and foster trust in the model. However, due to the unsupervised nature of anomaly detection, creating interpretable tools is challenging. This work introduces EIF+, an enhanced variant of Extended Isolation Forest (EIF), designed to enhance generalization capabilities. Additionally, we present ExIFFI, a novel approach that equips Extended Isolation Forest with interpretability features, specifically feature rankings. Experimental results provide a comprehensive comparative analysis of Isolation-based approaches for Anomaly Detection, incl
    
[^31]: 关于嵌入式量子核的表达能力

    On the expressivity of embedding quantum kernels. (arXiv:2309.14419v1 [quant-ph])

    [http://arxiv.org/abs/2309.14419](http://arxiv.org/abs/2309.14419)

    量子核方法是量子和经典机器学习之间最自然的联系之一。本文探讨了嵌入式量子核的表达能力，并得出结论：通过引入计算普适性，任何核函数都可以表示为量子特征映射和嵌入式量子核。

    

    在核方法的背景下，量子核与经典机器学习之间建立了最自然的联系。核方法依赖于内积特征向量，这些特征向量存在于大型特征空间中。量子核通常通过显式构造量子特征态并计算它们的内积来评估，这里称为嵌入式量子核。由于经典核通常在不使用特征向量的情况下进行评估，我们想知道嵌入式量子核的表达能力如何。在这项工作中，我们提出了一个基本问题：是否所有的量子核都可以表达为量子特征态的内积？我们的第一个结果是肯定的：通过调用计算普适性，我们发现对于任何核函数，总是存在对应的量子特征映射和嵌入式量子核。然而，问题更关注的是有效的构造方式。在第二部分中

    One of the most natural connections between quantum and classical machine learning has been established in the context of kernel methods. Kernel methods rely on kernels, which are inner products of feature vectors living in large feature spaces. Quantum kernels are typically evaluated by explicitly constructing quantum feature states and then taking their inner product, here called embedding quantum kernels. Since classical kernels are usually evaluated without using the feature vectors explicitly, we wonder how expressive embedding quantum kernels are. In this work, we raise the fundamental question: can all quantum kernels be expressed as the inner product of quantum feature states? Our first result is positive: Invoking computational universality, we find that for any kernel function there always exists a corresponding quantum feature map and an embedding quantum kernel. The more operational reading of the question is concerned with efficient constructions, however. In a second part
    
[^32]: 锐度感知最小化和稳定性边界。

    Sharpness-Aware Minimization and the Edge of Stability. (arXiv:2309.12488v1 [cs.LG])

    [http://arxiv.org/abs/2309.12488](http://arxiv.org/abs/2309.12488)

    本研究通过类似的计算方法，为锐度感知最小化(SAM)，一种改进泛化性能的梯度下降变种，确定了一个稳定性边界，该边界取决于梯度的范数。

    

    最近的实验表明，当使用梯度下降(GD)训练神经网络时，损失函数的Hessian矩阵的操作符范数会增长，直到接近$2/\eta$，之后会在该值周围波动。根据对损失函数的局部二次逼近，$2/\eta$被称为“稳定性边界”。我们使用类似的计算方法，为锐度感知最小化(SAM)确定了一个“稳定性边界”，SAM是一种改进泛化性能的GD变种。与GD不同，SAM的稳定性边界取决于梯度的范数。通过三个深度学习任务的实证，我们观察到SAM在这个分析中确定的稳定性边界上运行。

    Recent experiments have shown that, often, when training a neural network with gradient descent (GD) with a step size $\eta$, the operator norm of the Hessian of the loss grows until it approximately reaches $2/\eta$, after which it fluctuates around this value.  The quantity $2/\eta$ has been called the "edge of stability" based on consideration of a local quadratic approximation of the loss. We perform a similar calculation to arrive at an "edge of stability" for Sharpness-Aware Minimization (SAM), a variant of GD which has been shown to improve its generalization. Unlike the case for GD, the resulting SAM-edge depends on the norm of the gradient. Using three deep learning training tasks, we see empirically that SAM operates on the edge of stability identified by this analysis.
    
[^33]: PCN：一种利用新颖的图构建方法和切比雪夫图卷积的深度学习方法进行喷注标记

    PCN: A Deep Learning Approach to Jet Tagging Utilizing Novel Graph Construction Methods and Chebyshev Graph Convolutions. (arXiv:2309.08630v1 [hep-ph])

    [http://arxiv.org/abs/2309.08630](http://arxiv.org/abs/2309.08630)

    本研究提出了一种基于图形的喷注表示方法，并设计了一种名为PCN的图神经网络（GNN），利用切比雪夫图卷积（ChebConv）进行深度学习喷注标记，取得了显著的改进。

    

    喷注标记是高能物理实验中的一个分类问题，旨在识别粒子碰撞产生的锥状喷注，并将其标记为发射粒子。喷注标记的进展为超出标准模型的新物理搜索提供了机会。目前的方法使用深度学习在复杂碰撞数据中寻找隐藏的模式。然而，将喷注表示为深度学习模型的输入的方法多种多样，并且通常会向模型隐藏有信息的特征。在这项研究中，我们提出了一种基于图形的喷注表示方法，以尽可能地编码最多的信息。为了从这种表示中最好地学习，我们设计了一种名为Particle Chebyshev Network（PCN）的图神经网络（GNN），并使用切比雪夫图卷积（ChebConv）。ChebConv已经被证明是GNN中的一种有效替代传统图卷积的方法，而在喷注标记中还没有被探索过。PCN取得了显著的改进。

    Jet tagging is a classification problem in high-energy physics experiments that aims to identify the collimated sprays of subatomic particles, jets, from particle collisions and tag them to their emitter particle. Advances in jet tagging present opportunities for searches of new physics beyond the Standard Model. Current approaches use deep learning to uncover hidden patterns in complex collision data. However, the representation of jets as inputs to a deep learning model have been varied, and often, informative features are withheld from models. In this study, we propose a graph-based representation of a jet that encodes the most information possible. To learn best from this representation, we design Particle Chebyshev Network (PCN), a graph neural network (GNN) using Chebyshev graph convolutions (ChebConv). ChebConv has been demonstrated as an effective alternative to classical graph convolutions in GNNs and has yet to be explored in jet tagging. PCN achieves a substantial improvemen
    
[^34]: 在线性循环神经网络中推进正则语言推理

    Advancing Regular Language Reasoning in Linear Recurrent Neural Networks. (arXiv:2309.07412v1 [cs.CL])

    [http://arxiv.org/abs/2309.07412](http://arxiv.org/abs/2309.07412)

    通过分析现有的线性循环神经网络（LRNN），我们提出了一种新的LRNN模型，该模型配备了一个块对角且输入相关的转移矩阵，并且是唯一一个能够在正则语言任务上进行长度外推的LRNN。

    

    在最近的研究中，线性循环神经网络（LRNN）在自然语言建模和长程建模中取得了与Transformer相当的性能，同时提供了快速的并行训练和恒定的推理成本。在对LRNN重新产生兴趣的同时，我们研究它们是否能够学习训练序列中的隐藏规则，例如正则语言的语法结构。我们对一些已有的LRNN进行理论分析，发现它们在正则语言上存在限制。在这个分析的基础上，我们提出了一种新的LRNN，配备了一个块对角和输入相关的转移矩阵。实验表明，所提出的模型是唯一一个能够在正则语言任务（如求和、偶数对、模运算等）上进行长度外推的LRNN。

    In recent studies, linear recurrent neural networks (LRNNs) have achieved Transformer-level performance in natural language modeling and long-range modeling while offering rapid parallel training and constant inference costs. With the resurged interest in LRNNs, we study whether they can learn the hidden rules in training sequences, such as the grammatical structures of regular language. We theoretically analyze some existing LRNNs and discover their limitations on regular language. Motivated by the analysis, we propose a new LRNN equipped with a block-diagonal and input-dependent transition matrix. Experiments suggest that the proposed model is the only LRNN that can perform length extrapolation on regular language tasks such as Sum, Even Pair, and Modular Arithmetic.
    
[^35]: 偏见放大增强了少数群体的表现

    Bias Amplification Enhances Minority Group Performance. (arXiv:2309.06717v1 [cs.LG])

    [http://arxiv.org/abs/2309.06717](http://arxiv.org/abs/2309.06717)

    本论文提出了一种名为BAM的两阶段训练算法，通过引入可学习的辅助变量来放大偏见，提高了少数群体的表现。

    

    由标准训练产生的神经网络在罕见的子群上的准确性较差，尽管在平均水平上取得了较高准确性，这是由于某些虚假特征与标签之间的关联。之前基于最差群体损失最小化的方法（例如Group-DRO）在改善最差群体准确性方面是有效的，但需要为所有训练样本提供昂贵的群体注释。在本文中，我们关注更具挑战性和现实性的情景，即群体注释仅在一个小的验证集上可用，或者根本不可用。我们提出了BAM，一种新的两阶段训练算法：在第一阶段，通过引入可学习的辅助变量为每个训练样本训练一个偏见放大方案的模型；在第二阶段，我们对偏见放大的模型误分类的样本进行加权，然后在重新加权的数据集上继续训练同一模型。实验证明，BAM相对于其他方法在性能上取得了竞争性的表现。

    Neural networks produced by standard training are known to suffer from poor accuracy on rare subgroups despite achieving high accuracy on average, due to the correlations between certain spurious features and labels. Previous approaches based on worst-group loss minimization (e.g. Group-DRO) are effective in improving worse-group accuracy but require expensive group annotations for all the training samples. In this paper, we focus on the more challenging and realistic setting where group annotations are only available on a small validation set or are not available at all. We propose BAM, a novel two-stage training algorithm: in the first stage, the model is trained using a bias amplification scheme via introducing a learnable auxiliary variable for each training sample; in the second stage, we upweight the samples that the bias-amplified model misclassifies, and then continue training the same model on the reweighted dataset. Empirically, BAM achieves competitive performance compared w
    
[^36]: 使用物理信息神经网络识别复杂超弹性固体的组分参数

    Identifying Constitutive Parameters for Complex Hyperelastic Solids using Physics-Informed Neural Networks. (arXiv:2308.15640v1 [cond-mat.mtrl-sci])

    [http://arxiv.org/abs/2308.15640](http://arxiv.org/abs/2308.15640)

    本文介绍了一种基于物理信息神经网络（PINNs）的新框架，用于识别软材料在大变形平面应力条件下具有复杂组分行为的材料的组分参数。通过使用多模态的时间相关实验数据训练，我们的模型能够稳健地准确识别不可压缩Arruda-Boyce模型的组分参数。

    

    在工程和生物材料中，特别是那些具有复杂几何和机械行为的材料中，识别组分参数仍然是一个长期存在的挑战。最近出现的物理信息神经网络（PINNs）为此提供了有希望的解决方案，但当前的框架通常仅限于基本的组分定律，并在与实验数据相结合时遇到实际约束。本文引入了一种新的基于PINN的框架，旨在识别软材料的材料参数，特别是那些在平面应力条件下呈现复杂组分行为的材料。该模型强调用多模态的时间相关实验数据训练PINN，其中包括全场变形和加载历史，以确保算法在嘈杂数据中仍然稳健。我们的结果表明，我们的框架可以准确识别不可压缩Arruda-Boyce模型的组分参数。

    Identifying constitutive parameters in engineering and biological materials, particularly those with intricate geometries and mechanical behaviors, remains a longstanding challenge. The recent advent of Physics-Informed Neural Networks (PINNs) offers promising solutions, but current frameworks are often limited to basic constitutive laws and encounter practical constraints when combined with experimental data. In this paper, we introduce a new PINN-based framework designed to identify material parameters for soft materials, specifically those exhibiting complex constitutive behaviors, under large deformation in plane stress conditions. Distinctively, our model emphasizes training PINNs with multi-modal time-dependent experimental datasets consisting of full-field deformation and loading history, ensuring algorithm robustness even amidst noisy data. Our results reveal that our framework can accurately identify constitutive parameters of the incompressible Arruda-Boyce model for samples 
    
[^37]: 学习干预概念瓶颈

    Learning to Intervene on Concept Bottlenecks. (arXiv:2308.13453v1 [cs.LG])

    [http://arxiv.org/abs/2308.13453](http://arxiv.org/abs/2308.13453)

    该论文提出了一种扩展了概念瓶颈模型的概念瓶颈记忆模型（CB2M），通过学习将干预推广到不同情境并重新应用先前干预来自动改善模型性能。当没有先前的人类干预信息时，CB2M能够检测错误并请求有针对性的干预。

    

    传统的深度学习模型缺乏解释性，而概念瓶颈模型（CBM）通过其概念表示提供固有的解释。具体而言，它们允许用户通过更新概念值并纠正模型的预测输出来进行干预交互。然而，传统方法中这些干预仅应用于模型一次后即被丢弃。为了纠正这一问题，我们提出了概念瓶颈记忆模型（CB2M），这是CBM的一个扩展。具体而言，CB2M通过双折叠记忆学习将干预的推广到适当的新情境中，从而能够学习检测错误并重新应用先前的干预。通过这种方式，CB2M能够从最初获得的少量干预中自动提高模型的性能。如果没有先前的人类干预信息，CB2M可以检测到CBM瓶颈的潜在错误并请求有针对性的干预。

    While traditional deep learning models often lack interpretability, concept bottleneck models (CBMs) provide inherent explanations via their concept representations. Specifically, they allow users to perform interventional interactions on these concepts by updating the concept values and thus correcting the predictive output of the model. Traditionally, however, these interventions are applied to the model only once and discarded afterward. To rectify this, we present concept bottleneck memory models (CB2M), an extension to CBMs. Specifically, a CB2M learns to generalize interventions to appropriate novel situations via a two-fold memory with which it can learn to detect mistakes and to reapply previous interventions. In this way, a CB2M learns to automatically improve model performance from a few initially obtained interventions. If no prior human interventions are available, a CB2M can detect potential mistakes of the CBM bottleneck and request targeted interventions. In our experime
    
[^38]: 带有通信压缩的随机控制平均法在联邦学习中的应用

    Stochastic Controlled Averaging for Federated Learning with Communication Compression. (arXiv:2308.08165v1 [math.OC] CROSS LISTED)

    [http://arxiv.org/abs/2308.08165](http://arxiv.org/abs/2308.08165)

    本文提出了两种压缩联邦学习算法(SCALLION和SCAFCOM)，通过重新审视经典的随机控制平均法并提出了等价但更高效/简化的形式，减少了上行通信成本。

    

    通信压缩是一种旨在减少通过无线传输的信息量的技术，在联邦学习中引起了极大的关注，因为它有潜力减轻通信开销。然而，通信压缩在联邦学习中带来了新的挑战，包括压缩引起的信息失真以及联邦学习的特性，如部分参与和数据异构性。尽管近年来有所发展，压缩联邦学习方法的性能尚未充分利用。现有方法要么不能适应任意的数据异构性或部分参与，要么要求对压缩有严格的条件。在本文中，我们重新审视了具有开销减半的上行通信成本的经典随机控制平均法，并提出了两种压缩联邦学习算法，SCALLION和SCAFCOM。

    Communication compression, a technique aiming to reduce the information volume to be transmitted over the air, has gained great interests in Federated Learning (FL) for the potential of alleviating its communication overhead. However, communication compression brings forth new challenges in FL due to the interplay of compression-incurred information distortion and inherent characteristics of FL such as partial participation and data heterogeneity. Despite the recent development, the performance of compressed FL approaches has not been fully exploited. The existing approaches either cannot accommodate arbitrary data heterogeneity or partial participation, or require stringent conditions on compression.  In this paper, we revisit the seminal stochastic controlled averaging method by proposing an equivalent but more efficient/simplified formulation with halved uplink communication costs. Building upon this implementation, we propose two compressed FL algorithms, SCALLION and SCAFCOM, to s
    
[^39]: 游戏理论的鲁棒强化学习处理时间耦合的干扰

    Game-Theoretic Robust Reinforcement Learning Handles Temporally-Coupled Perturbations. (arXiv:2307.12062v1 [cs.LG])

    [http://arxiv.org/abs/2307.12062](http://arxiv.org/abs/2307.12062)

    这篇论文提出了一种新的鲁棒强化学习方法，通过将时间耦合的鲁棒强化学习问题视为两人零和游戏来处理问题，并通过找到近似均衡来确保代理对时间耦合干扰的鲁棒性。实验结果显示，该方法在各种连续控制任务中相比基准方法表现出显著的鲁棒性优势。

    

    鲁棒强化学习旨在训练能够在环境干扰或对抗攻击下表现良好的策略。现有方法通常假设可能干扰的空间在各个时间步骤保持不变。然而，在许多情况下，给定时间步骤上可能干扰的空间取决于过去的干扰。我们正式引入时间耦合干扰，对现有的鲁棒强化学习方法提出了新的挑战。为了应对这个挑战，我们提出了GRAD，一种新的游戏理论方法，将时间耦合鲁棒强化学习问题视为部分可观察的两人零和游戏。通过在这个游戏中找到一个近似均衡，GRAD确保了代理的对时间耦合干扰的鲁棒性。对各种连续控制任务的实证实验表明，我们提出的方法相比基准方法在标准和时间耦合干扰下具有显著的鲁棒性优势。

    Robust reinforcement learning (RL) seeks to train policies that can perform well under environment perturbations or adversarial attacks. Existing approaches typically assume that the space of possible perturbations remains the same across timesteps. However, in many settings, the space of possible perturbations at a given timestep depends on past perturbations. We formally introduce temporally-coupled perturbations, presenting a novel challenge for existing robust RL methods. To tackle this challenge, we propose GRAD, a novel game-theoretic approach that treats the temporally-coupled robust RL problem as a partially-observable two-player zero-sum game. By finding an approximate equilibrium in this game, GRAD ensures the agent's robustness against temporally-coupled perturbations. Empirical experiments on a variety of continuous control tasks demonstrate that our proposed approach exhibits significant robustness advantages compared to baselines against both standard and temporally-coupl
    
[^40]: 深度学习动态图：模型与基准

    Deep learning for dynamic graphs: models and benchmarks. (arXiv:2307.06104v1 [cs.LG])

    [http://arxiv.org/abs/2307.06104](http://arxiv.org/abs/2307.06104)

    本文对深度学习动态图领域进行了调查，总结了学习时间和空间信息的最新优势，并对最流行的方法进行了公平的性能比较，为评估新架构和方法建立了一个可靠的基准模型。

    

    近年来，在深度图网络（DGNs）的研究中取得了巨大进展，推动了图上学习的领域成熟发展。尽管这个研究领域正在快速增长，但仍然存在一些尚未解决的重要挑战。特别地，急需使DGNs适用于实时系统中随时间推移不断演化的预测任务。为促进动态图领域的研究，首先，我们调查了学习时间和空间信息的最新优势，并提供了动态图表示学习领域的当前最新概览。其次，我们对最流行的方法进行了公平的性能比较，通过严格的模型选择和评估，为评估新架构和方法建立了一个可靠的基准模型。

    Recent progress in research on Deep Graph Networks (DGNs) has led to a maturation of the domain of learning on graphs. Despite the growth of this research field, there are still important challenges that are yet unsolved. Specifically, there is an urge of making DGNs suitable for predictive tasks on realworld systems of interconnected entities, which evolve over time. With the aim of fostering research in the domain of dynamic graphs, at first, we survey recent advantages in learning both temporal and spatial information, providing a comprehensive overview of the current state-of-the-art in the domain of representation learning for dynamic graphs. Secondly, we conduct a fair performance comparison among the most popular proposed approaches, leveraging rigorous model selection and assessment for all the methods, thus establishing a sound baseline for evaluating new architectures and approaches
    
[^41]: 使用前softmax分数的归属方法的一个漏洞

    A Vulnerability of Attribution Methods Using Pre-Softmax Scores. (arXiv:2307.03305v1 [cs.LG])

    [http://arxiv.org/abs/2307.03305](http://arxiv.org/abs/2307.03305)

    这篇论文讨论了使用前softmax分数的归属方法的一个漏洞，该方法用于解释卷积神经网络分类器输出。与对抗性攻击不同，作者关注的是对归属方法进行小修改可能导致的影响，而不会改变模型的输出。

    

    我们讨论了一类用于解释卷积神经网络分类器输出的归属方法的一个漏洞。已知这种类型的网络容易受到对抗性攻击的影响，即输入的微小扰动可能会改变模型的输出。与此不同的是，我们关注的是对归属方法进行小修改可能导致的影响，而不会改变模型的输出。

    We discuss a vulnerability involving a category of attribution methods used to provide explanations for the outputs of convolutional neural networks working as classifiers. It is known that this type of networks are vulnerable to adversarial attacks, in which imperceptible perturbations of the input may alter the outputs of the model. In contrast, here we focus on effects that small modifications in the model may cause on the attribution method without altering the model outputs.
    
[^42]: 如何检测文本到图像扩散模型中的未授权数据使用

    How to Detect Unauthorized Data Usages in Text-to-image Diffusion Models. (arXiv:2307.03108v1 [cs.CV])

    [http://arxiv.org/abs/2307.03108](http://arxiv.org/abs/2307.03108)

    本文提出了一种方法，通过在训练的文本到图像扩散模型中植入注入的记忆化内容，来检测未授权数据使用。该方法修改了受保护的图像数据集，添加了对人眼不可察觉但模型可以捕捉和记忆的内容，通过分析模型对注入内容的记忆来判断模型是否存在生成类似图像的能力。

    

    最近的文本到图像扩散模型在生成高质量图像方面表现出令人惊讶的性能。然而，对于训练过程中的未授权数据使用引起了关注。一个例子是当模型训练者收集了一个特定艺术家创建的一系列图像，并试图训练一个能够生成类似图像的模型，而没有获得艺术家的许可。为了解决这个问题，我们提出了一种方法，通过将注入的记忆化内容植入保护数据集上训练的文本到图像扩散模型中，来检测此类未授权数据使用。具体地，我们通过在图像上添加独特的内容，例如对人类视觉不可察觉但能够被扩散模型捕捉和记忆的隐秘图像包装函数，来修改受保护的图像数据集。通过分析模型是否对注入的内容进行记忆化，我们可以判断模型是否存在这一记忆（即是否存在生成类似图像的能力）。

    Recent text-to-image diffusion models have shown surprising performance in generating high-quality images. However, concerns have arisen regarding the unauthorized usage of data during the training process. One example is when a model trainer collects a set of images created by a particular artist and attempts to train a model capable of generating similar images without obtaining permission from the artist. To address this issue, it becomes crucial to detect unauthorized data usage. In this paper, we propose a method for detecting such unauthorized data usage by planting injected memorization into the text-to-image diffusion models trained on the protected dataset. Specifically, we modify the protected image dataset by adding unique contents on the images such as stealthy image wrapping functions that are imperceptible to human vision but can be captured and memorized by diffusion models. By analyzing whether the model has memorization for the injected content (i.e., whether the gener
    
[^43]: 具有强凸性的 Nesterov-1983 的线性收敛性

    Linear convergence of Nesterov-1983 with the strong convexity. (arXiv:2306.09694v1 [math.OC])

    [http://arxiv.org/abs/2306.09694](http://arxiv.org/abs/2306.09694)

    本文使用高分辨率微分方程框架回答了Nesterov-1983和FISTA是否在强凸函数上线性收敛的问题，并指出线性收敛性不依赖于强凸性条件。

    

    对于现代基于梯度的优化，Nesterov 的加速梯度下降法是一个开创性里程碑，该方法在[Nesterov，1983]中提出，简称为Nesterov-1983。此后，重要的进展之一是它的近端推广，名为快速迭代收缩阈值算法（FISTA），广泛应用于图像科学和工程。然而，目前仍未知道Nesterov-1983和FISTA是否在强凸函数上线性收敛，而这已被列为综合评审[Chambolle和Pock，2016，附录B]中的未解决问题。本文通过使用高分辨率微分方程框架来回答这个问题。与先前采用的相空间表示一起，构造Lyapunov函数的关键区别在于动能的系数随迭代而变化。此外，我们指出，上述两种算法的线性收敛性没有依赖于强凸函数的条件。

    For modern gradient-based optimization, a developmental landmark is Nesterov's accelerated gradient descent method, which is proposed in [Nesterov, 1983], so shorten as Nesterov-1983. Afterward, one of the important progresses is its proximal generalization, named the fast iterative shrinkage-thresholding algorithm (FISTA), which is widely used in image science and engineering. However, it is unknown whether both Nesterov-1983 and FISTA converge linearly on the strongly convex function, which has been listed as the open problem in the comprehensive review [Chambolle and Pock, 2016, Appendix B]. In this paper, we answer this question by the use of the high-resolution differential equation framework. Along with the phase-space representation previously adopted, the key difference here in constructing the Lyapunov function is that the coefficient of the kinetic energy varies with the iteration. Furthermore, we point out that the linear convergence of both the two algorithms above has no d
    
[^44]: 改进的概率图像-文本表示方法

    Improved Probabilistic Image-Text Representations. (arXiv:2305.18171v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.18171](http://arxiv.org/abs/2305.18171)

    本论文提出了一种改进的概率图像-文本表示方法，通过引入新的概率距离和两种优化技术，解决了现有方法中的计算负担过重和损失饱和问题，取得了显著的性能提升。

    

    图像-文本匹配是一种基本的视觉-语言任务，由于多样性和不完美注释导致的固有歧义使其受到困扰。确定性函数无法足够强大地捕捉到这种歧义，因此需要探索概率嵌入来解决这个挑战。然而，现有的概率图像-文本匹配方法存在两个关键缺点：蒙特卡洛逼近导致计算负担较重，且在大量误检情况下容易出现损失饱和问题。为了克服这些问题，本文提出了一种改进的概率跨模态嵌入方法（PCME++），通过引入具有闭合形式解的新的概率距离。此外，还提出了两种优化技术进一步增强PCME++：首先，引入伪正样本以防止大量误检情况下的损失饱和问题；其次，采用混合样本数据增强进行概率匹配。实验结果表明，PCME++在ITM任务中取得了显著的性能提升。

    Image-Text Matching (ITM) task, a fundamental vision-language (VL) task, suffers from the inherent ambiguity arising from multiplicity and imperfect annotations. Deterministic functions are not sufficiently powerful to capture ambiguity, prompting the exploration of probabilistic embeddings to tackle the challenge. However, the existing probabilistic ITM approach encounters two key shortcomings; the burden of heavy computations due to the Monte Carlo approximation, and the loss saturation issue in the face of abundant false negatives. To overcome the issues, this paper presents an improved Probabilistic Cross-Modal Embeddings (named PCME++) by introducing a new probabilistic distance with a closed-form solution. In addition, two optimization techniques are proposed to enhance PCME++ further; first, the incorporation of pseudo-positives to prevent the loss saturation problem under massive false negatives; second, mixed sample data augmentation for probabilistic matching. Experimental re
    
[^45]: 一种易于编辑的DDPM噪声空间：反演与操作

    An Edit Friendly DDPM Noise Space: Inversion and Manipulations. (arXiv:2304.06140v1 [cs.CV])

    [http://arxiv.org/abs/2304.06140](http://arxiv.org/abs/2304.06140)

    本文提出了一种易于编辑的DDPM噪声空间，可以通过简单手段进行广泛的编辑操作，并提出了一种用于提取编辑友好噪声图的反演方法。

    

    降噪扩散概率模型（DDPM）利用一系列白噪声样本生成图像。类似于GAN，这些噪声图可以看作是生成图像相关的潜在代码。然而，这种原始噪声空间没有方便的结构，因此在编辑任务中很难使用。本文提出了一种替代DDPM的潜在噪声空间，可通过简单手段进行广泛的编辑操作，并提出一种用于提取任何给定图像（真实或合成生成）的易于编辑噪声图的反演方法。

    Denoising diffusion probabilistic models (DDPMs) employ a sequence of white Gaussian noise samples to generate an image. In analogy with GANs, those noise maps could be considered as the latent code associated with the generated image. However, this native noise space does not possess a convenient structure, and is thus challenging to work with in editing tasks. Here, we propose an alternative latent noise space for DDPM that enables a wide range of editing operations via simple means, and present an inversion method for extracting these edit-friendly noise maps for any given image (real or synthetically generated). As opposed to the native DDPM noise space, the edit-friendly noise maps do not have a standard normal distribution and are not statistically independent across timesteps. However, they allow perfect reconstruction of any desired image, and simple transformations on them translate into meaningful manipulations of the output image (e.g., shifting, color edits). Moreover, in t
    
[^46]: PAIR-Diffusion: 采用结构和外观配对扩散模型进行对象级图像编辑

    PAIR-Diffusion: Object-Level Image Editing with Structure-and-Appearance Paired Diffusion Models. (arXiv:2303.17546v1 [cs.CV])

    [http://arxiv.org/abs/2303.17546](http://arxiv.org/abs/2303.17546)

    本论文提出了一种采用结构和外观配对扩散模型进行对象级图像编辑的方法，使用户能够精细控制图像中的不同对象属性，同时自动传播注入的外观到具有相似结构的对象。

    

    最近，使用扩散模型进行图像编辑发展迅速。以前的作品可以通过各种方式进行控制和编辑图像，某些作品使用高级条件（例如文本），而其他作品使用低级条件。然而，大多数作品缺乏对图像中不同对象的属性进行精细化控制，即对象级图像编辑。本文将图像视为由多个对象组成，每个对象由不同属性定义。我们发现结构和外观是最直观且最有用于编辑的属性。我们提出了结构和外观配对扩散模型（PAIR-Diffusion），该模型使用从图像中明确提取的结构和外观信息进行训练。所提出的模型使用户能够在对象和全局级别将参考图像的外观注入输入图像中。此外，PAIR-Diffusion自动将注入的外观传播到输入图像中具有类似结构的对象。

    Image editing using diffusion models has witnessed extremely fast-paced growth recently. There are various ways in which previous works enable controlling and editing images. Some works use high-level conditioning such as text, while others use low-level conditioning. Nevertheless, most of them lack fine-grained control over the properties of the different objects present in the image, i.e. object-level image editing. In this work, we consider an image as a composition of multiple objects, each defined by various properties. Out of these properties, we identify structure and appearance as the most intuitive to understand and useful for editing purposes. We propose Structure-and-Appearance Paired Diffusion model (PAIR-Diffusion), which is trained using structure and appearance information explicitly extracted from the images. The proposed model enables users to inject a reference image's appearance into the input image at both the object and global levels. Additionally, PAIR-Diffusion a
    
[^47]: 通过自适应平滑改善分类器的准确性-鲁棒性平衡

    Improving the Accuracy-Robustness Trade-Off of Classifiers via Adaptive Smoothing. (arXiv:2301.12554v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12554](http://arxiv.org/abs/2301.12554)

    本文研究通过混合标准分类器和鲁棒模型的输出概率来减轻准确性和鲁棒性之间的权衡问题，进而提高分类器的鲁棒性。同时提出了一种自适应平滑的方法，可以降低实现鲁棒性的准确度惩罚。

    

    尽管以前的研究提出了大量增强神经分类器对抗鲁棒性的方法，但由于在清晰度方面存在不可接受的严重惩罚，实践者仍然不愿采用这些技术。本文表明，通过混合标准分类器和强鲁棒模型的输出概率，其中标准网络优化清晰度而不是一般的鲁棒性，可以显着减轻这种准确性-鲁棒性权衡问题。我们显示出基于鲁棒性的基本分类器的正确和不正确示例的置信度差异是这种改善的关键因素。除提供直观和经验证据外，我们还在现实假设下理论上证明了混合分类器的鲁棒性。此外，我们还将一个对抗性输入检测器适应为混合网络，自适应地调整两个基本模型的混合，从而进一步减少实现鲁棒性的准确性惩罚。

    While prior research has proposed a plethora of methods that enhance the adversarial robustness of neural classifiers, practitioners are still reluctant to adopt these techniques due to their unacceptably severe penalties in clean accuracy. This paper shows that by mixing the output probabilities of a standard classifier and a robust model, where the standard network is optimized for clean accuracy and is not robust in general, this accuracy-robustness trade-off can be significantly alleviated. We show that the robust base classifier's confidence difference for correct and incorrect examples is the key ingredient of this improvement. In addition to providing intuitive and empirical evidence, we also theoretically certify the robustness of the mixed classifier under realistic assumptions. Furthermore, we adapt an adversarial input detector into a mixing network that adaptively adjusts the mixture of the two base models, further reducing the accuracy penalty of achieving robustness. The 
    
[^48]: 推荐实体的时间因素的多模型方法

    Multiple Models for Recommending Temporal Aspects of Entities. (arXiv:1803.07890v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/1803.07890](http://arxiv.org/abs/1803.07890)

    本研究提出了一种新颖的基于事件中心的集合排名方法，该方法考虑到时间动态性，能够推荐最相关的实体方面，提高搜索体验。

    

    实体方面的推荐是语义搜索中的新兴任务，可以帮助用户发现与实体相关的巧合和突出信息，其中显着性（例如流行度）是以前工作中最重要的因素。但是，实体方面是具有时间动态性的，经常受到随时间发生的事件的影响。在这种情况下，仅基于显着性特征的方面建议可能会给出令人不满意的结果，原因有两个。首先，显着性通常在长时间段内累积，并且不考虑最近情况。其次，与事件实体相关的许多方面强烈依赖于时间。在本文中，我们研究了针对给定实体的时间方面推荐任务，旨在推荐最相关的方面，并考虑时间以提高搜索体验。我们提出了一种新颖的基于事件中心的集合排名方法，该方法从多个时间和类型依赖的模型中学习，并动态权衡显着性和最近情况。

    Entity aspect recommendation is an emerging task in semantic search that helps users discover serendipitous and prominent information with respect to an entity, of which salience (e.g., popularity) is the most important factor in previous work. However, entity aspects are temporally dynamic and often driven by events happening over time. For such cases, aspect suggestion based solely on salience features can give unsatisfactory results, for two reasons. First, salience is often accumulated over a long time period and does not account for recency. Second, many aspects related to an event entity are strongly time-dependent. In this paper, we study the task of temporal aspect recommendation for a given entity, which aims at recommending the most relevant aspects and takes into account time in order to improve search experience. We propose a novel event-centric ensemble ranking method that learns from multiple time and type-dependent models and dynamically trades off salience and recency c
    

