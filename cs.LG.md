# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Tune without Validation: Searching for Learning Rate and Weight Decay on Training Sets](https://arxiv.org/abs/2403.05532) | 提出了一种名为Tune without Validation (Twin)的方法，在没有验证集的情况下通过学习率和权重衰减的调整来预测泛化性能，强调了权重范数与泛化性能预测的强相关性。 |
| [^2] | [The Computational Complexity of Learning Gaussian Single-Index Models](https://arxiv.org/abs/2403.05529) | 该论文研究了学习高斯单指数模型的计算复杂性，在高维回归问题中展示了计算有效算法所需的样本复杂度，并表明这种复杂度是充分的。 |
| [^3] | [GEAR: An Efficient KV Cache Compression Recipefor Near-Lossless Generative Inference of LLM](https://arxiv.org/abs/2403.05527) | GEAR提出了一种高效的KV缓存压缩框架，实现几乎无损的高比率压缩，用于解决大型语言模型推断中因缓存需求增长而导致的记忆绑定问题和性能下降。 |
| [^4] | [Poly-View Contrastive Learning](https://arxiv.org/abs/2403.05490) | 本研究提出了多视图对比学习方法，通过新的表示学习目标优化匹配多个相关视图，在ImageNet1k数据集上的实验结果显示，相比于SimCLR模型，多视图对比模型在更少的训练轮数和更小的批大小下表现更优。 |
| [^5] | [Algorithm-Hardware Co-Design of Distribution-Aware Logarithmic-Posit Encodings for Efficient DNN Inference](https://arxiv.org/abs/2403.05465) | 引入了对数正定编码（LP）和LP量化（LPQ）框架，采用基因算法寻找最优的LP参数，设计了统一的混合精度LP加速器（LPA）体系结构，可动态适应DNN参数分布，减少量化和完整精度模型之间的表示性差异。 |
| [^6] | [The R2D2 deep neural network series paradigm for fast precision imaging in radio astronomy](https://arxiv.org/abs/2403.05452) | 提出一种新颖的深度学习方法R2D2，用于解决射电天文学中高分辨率高动态范围成像的可扩展性挑战。 |
| [^7] | [An Improved Algorithm for Learning Drifting Discrete Distributions](https://arxiv.org/abs/2403.05446) | 提出了一种可以在分布漂移情况下学习离散分布的自适应算法，能够解决过去样本数量选择的权衡问题，并利用数据相关的界来表征统计误差。 |
| [^8] | [Bayesian Hierarchical Probabilistic Forecasting of Intraday Electricity Prices](https://arxiv.org/abs/2403.05441) | 该研究首次提出了为德国连续日内市场交易的电力价格进行贝叶斯预测，考虑了参数不确定性，并在2022年的电力价格验证中取得了统计显著的改进。 |
| [^9] | [Is Cosine-Similarity of Embeddings Really About Similarity?](https://arxiv.org/abs/2403.05440) | 余弦相似度可以产生任意和无意义的“相似性”，受正则化控制，并讨论了深层模型学习中的影响。 |
| [^10] | [Considering Nonstationary within Multivariate Time Series with Variational Hierarchical Transformer for Forecasting](https://arxiv.org/abs/2403.05406) | 论文提出了一种名为HTV-Trans的Hierarchical Time series Variational Transformer模型，通过结合层次概率生成模块和Transformer，能够有效考虑多元时间序列中的非平稳性和随机特性，从而更好地回复时间依赖关系。 |
| [^11] | [HistGen: Histopathology Report Generation via Local-Global Feature Encoding and Cross-modal Context Interaction](https://arxiv.org/abs/2403.05396) | HistGen是一个通过本地-全局特征编码和跨模态上下文交互来生成组织病理学报告的框架，提供了第一个用于评估的基准数据集。 |
| [^12] | [Recovery Guarantees of Unsupervised Neural Networks for Inverse Problems trained with Gradient Descent](https://arxiv.org/abs/2403.05395) | 本研究证明了使用梯度下降训练的无监督神经网络在反问题中的恢复保证与使用梯度流时的保证相同。 |
| [^13] | [Switching the Loss Reduces the Cost in Batch Reinforcement Learning](https://arxiv.org/abs/2403.05385) | 使用对数损失函数来训练适合的Q迭代的批强化学习方法，在实现目标时不产生成本的问题中，其样本数量需求与最优策略的累积成本成比例，能够提供与最优可达成本成比例的“小成本”界限，并在实验中验证在那些最优策略可靠实现目标的问题中，FQI-LOG比使用平方损失训练的FQI使用更少的样本。 |
| [^14] | [Exploring the Links between the Fundamental Lemma and Kernel Regression](https://arxiv.org/abs/2403.05368) | 本研究探讨了基本引理的推广和核回归之间的联系，通过非线性扩展和变换，得到了系统轨迹的新核表示方法，展示出了与特定核回归问题的等效性，并研究了潜在核的结构及其对应的系统类别。 |
| [^15] | [The Impact of Quantization on the Robustness of Transformer-based Text Classifiers](https://arxiv.org/abs/2403.05365) | 量化可以显著提高Transformer-based文本分类器在面对对抗攻击时的鲁棒性表现，平均提升了18.68%。 |
| [^16] | [Hybridized Convolutional Neural Networks and Long Short-Term Memory for Improved Alzheimer's Disease Diagnosis from MRI Scans](https://arxiv.org/abs/2403.05353) | 本研究提出了一种混合模型，结合了卷积神经网络模型的特征提取能力和长短期记忆模型的检测能力，旨在改善从MRI扫描中诊断阿尔茨海默病的方法。 |
| [^17] | [Embedded Deployment of Semantic Segmentation in Medicine through Low-Resolution Inputs](https://arxiv.org/abs/2403.05340) | 提出一种在医学中嵌入语义分割的低分辨率输入部署架构，在硬件受限的环境中利用较低分辨率输入以减少计算和内存需求，同时保证预测质量。 |
| [^18] | [Looking Ahead to Avoid Being Late: Solving Hard-Constrained Traveling Salesman Problem](https://arxiv.org/abs/2403.05318) | 提出一种利用展望信息作为特征改善具有时间窗口的TSP解决方案合法性的新颖学习方法 |
| [^19] | [Unity by Diversity: Improved Representation Learning in Multimodal VAEs](https://arxiv.org/abs/2403.05300) | 通过软约束取代硬约束，提出了一种新的专家混合先验，改善了多模态VAEs中的表示学习。 |
| [^20] | [Leveraging Continuous Time to Understand Momentum When Training Diagonal Linear Networks](https://arxiv.org/abs/2403.05293) | 研究了动量对梯度下降优化轨迹的影响，通过连续时间方法找到固有量 $\lambda$，对于恢复稀疏解具有帮助。 |
| [^21] | [Foundational propositions of hesitant fuzzy soft $\beta$-covering approximation spaces](https://arxiv.org/abs/2403.05290) | 本文引入了犹豫模糊软$\beta$-覆盖和犹豫模糊软$\beta$-邻域的概念，研究了它们的属性，并探讨了涉及犹豫模糊软$\beta$-覆盖逼近空间的特定变体。 |
| [^22] | [Deep Prompt Multi-task Network for Abuse Language Detection](https://arxiv.org/abs/2403.05268) | 提出了一种新颖的Deep Prompt Multi-task Network (DPMN)用于滥用语言检测，通过设计深度提示调整和轻提示调整来激发预训练语言模型的一般知识，并利用多任务学习来提高检测度量标准 |
| [^23] | [ERBench: An Entity-Relationship based Automatically Verifiable Hallucination Benchmark for Large Language Models](https://arxiv.org/abs/2403.05266) | ERBench是一个基于实体关系的大型语言模型幻觉基准，通过自动转换任何关系数据库并构建可自动验证的问题，以支持复杂性评估和调试 |
| [^24] | [DuDoUniNeXt: Dual-domain unified hybrid model for single and multi-contrast undersampled MRI reconstruction](https://arxiv.org/abs/2403.05256) | 提出了DuDoUniNeXt，一个统一的双域MRI重建网络，能适应不同质量的参考图像，解决了在缺少或低质量参考图像时性能不佳的问题 |
| [^25] | [On Representing Electronic Wave Functions with Sign Equivariant Neural Networks](https://arxiv.org/abs/2403.05249) | 使用符号等变性神经网络的新方法未能提供优于传统方法的波函数近似精度。 |
| [^26] | [Towards Effective Usage of Human-Centric Priors in Diffusion Models for Text-based Human Image Generation](https://arxiv.org/abs/2403.05239) | 本文提出了一种新方法，通过将人性先验直接融入模型微调阶段，强化文本提示中的人体相关信息，并引入规模感知和逐步约束，从而有效提升了基于扩散模型的文本人体图像生成质量 |
| [^27] | [Fairness-Aware Interpretable Modeling (FAIM) for Trustworthy Machine Learning in Healthcare](https://arxiv.org/abs/2403.05235) | FAIM是一个用于提高医疗保健领域机器学习公平性的可解释框架，通过交互界面识别最公平模型，并结合数据驱动证据与临床专家知识，成功减少了性别和种族偏见。 |
| [^28] | [Synthetic Privileged Information Enhances Medical Image Representation Learning](https://arxiv.org/abs/2403.05220) | 合成生成的配对信息显著改善了医学图像表示学习，相比于单模态训练或真实多模态配对数据集，误差减小分别达到4.4倍和5.6倍 |
| [^29] | [Overcoming Data Inequality across Domains with Semi-Supervised Domain Generalization](https://arxiv.org/abs/2403.05209) | 本文提出了一种名为ProUD的新算法，通过领域感知原型和通过不确定性自适应混合标记和未标记领域的渐进泛化，有效解决了跨领域数据不平等问题中的半监督领域泛化挑战。 |
| [^30] | [Denoising Autoregressive Representation Learning](https://arxiv.org/abs/2403.05196) | DARL使用仅解码器的Transformer进行自回归预测，通过使用去噪补丁解码器和特定噪声计划改善图像生成能力，实现了与蒙版预测模型相近的性能。 |
| [^31] | [Personalized Audiobook Recommendations at Spotify Through Graph Neural Networks](https://arxiv.org/abs/2403.05185) | 通过引入双塔模型和异质图神经网络，该研究提出了一个可扩展的推荐系统，以应对Spotify在引入有声读物后面临的个性化推荐挑战。 |
| [^32] | [Adversarial Sparse Teacher: Defense Against Distillation-Based Model Stealing Attacks Using Adversarial Examples](https://arxiv.org/abs/2403.05181) | 本文提出了一种训练教师模型的方法，通过引入敌对示例的稀疏输出，并与标准训练数据结合使用，来加强教师模型对学生蒸馏的防御。 |
| [^33] | [Continual Learning and Catastrophic Forgetting](https://arxiv.org/abs/2403.05175) | 人工神经网络在持续学习过程中容易出现灾难性遗忘，这一问题是深度学习中持续学习领域的关键挑战。 |
| [^34] | [VTruST: Controllable value function based subset selection for Data-Centric Trustworthy AI](https://arxiv.org/abs/2403.05174) | 提出了一个可控的数据中心可信AI（DCTAI）框架 VTruST，允许用户控制不同可信度指标之间的权衡，设计了基于在线价值函数的训练数据子集选择算法，通过在线稀疏逼近形式的训练数据估值和子集选择问题，提出了一个新的在线正交匹配追踪（OMP）算法，实验证明VTruST在社交、图像和科学数据集上优于最先进的基线。 |
| [^35] | [Overcoming Reward Overoptimization via Adversarial Policy Optimization with Lightweight Uncertainty Estimation](https://arxiv.org/abs/2403.05171) | 本论文提出了对抗策略优化（AdvPO）来解决强化学习领域中奖励过度优化的问题，通过量化奖励的不确定性，并围绕奖励模型预测的置信区间进行分布鲁棒的优化，从而有效缓解了该问题。 |
| [^36] | [Synthetic data generation for system identification: leveraging knowledge transfer from similar systems](https://arxiv.org/abs/2403.05164) | 本文提出了一种从类似系统中进行知识转移的新方法，用于生成合成数据，以改善模型的泛化能力和鲁棒性。 |
| [^37] | [Adaptive Split Learning over Energy-Constrained Wireless Edge Networks](https://arxiv.org/abs/2403.05158) | 设计了一种在无线边缘网络中为设备动态选择分裂点并为服务器分配计算资源的自适应分裂学习方案，以最小化平均训练延迟为目标，并提出了一种名为OPEN的在线算法解决此问题。 |
| [^38] | [Greedy feature selection: Classifier-dependent feature selection via greedy methods](https://arxiv.org/abs/2403.05138) | 提出了一种新的基于分类器的特征选择方法，通过贪婪方式在每一步识别最重要的特征，从而在理论和实际应用中得出有效性。 |
| [^39] | [Follow-the-Perturbed-Leader with Fr\'{e}chet-type Tail Distributions: Optimality in Adversarial Bandits and Best-of-Both-Worlds](https://arxiv.org/abs/2403.05134) | 研究指出在对抗性和随机赌博机中，基于随机扰动的Follow-the-Perturbed-Leader策略具有弗歇泰尔分布尾部最优性，实现了最佳选择的能力。 |
| [^40] | [RIS-empowered Topology Control for Distributed Learning in Urban Air Mobility](https://arxiv.org/abs/2403.05133) | 本文研究了如何利用可重构智能表面（RIS）解决城市空中移动中分布式学习的拓扑控制问题，以克服有限传感器和计算资源对智能感知需求的挑战。 |
| [^41] | [ECToNAS: Evolutionary Cross-Topology Neural Architecture Search](https://arxiv.org/abs/2403.05123) | ECToNAS是一种成本高效的进化跨拓扑神经架构搜索算法，不需要预训练的元控制器，能够在不同任务和超参数设置下自主选择合适的网络架构，实现跨拓扑优化，动态添加和移除卷积单元，为没有机器学习背景的研究人员提供了利用适当模型的可能性。 |
| [^42] | [Multi-Tower Multi-Interest Recommendation with User Representation Repel](https://arxiv.org/abs/2403.05122) | 提出了一种具有用户表示排斥的新型多塔多兴趣框架，解决了多兴趣学习方法面临的训练和部署目标差异、无法访问商品信息以及难以工业采用等问题。 |
| [^43] | [Estimation of Electronic Band Gap Energy From Material Properties Using Machine Learning](https://arxiv.org/abs/2403.05119) | 通过机器学习技术，本论文提出了一种能够利用材料属性快速估算电子带隙能量并预测带隙类别的模型，不仅无需任何初步的DFT计算，而且能够为传统计算方法提供更优的替代方案。 |
| [^44] | [Efficient Data Collection for Robotic Manipulation via Compositional Generalization](https://arxiv.org/abs/2403.05110) | 通过研究机器人策略的复合能力，可以避免收集处理复合情况所需的数据。 |
| [^45] | [Simulating Battery-Powered TinyML Systems Optimised using Reinforcement Learning in Image-Based Anomaly Detection](https://arxiv.org/abs/2403.05106) | 本文通过强化学习优化电池供电的图像异常检测系统，扩展并贡献于TinyML研究。 |
| [^46] | [Exploring the Adversarial Frontier: Quantifying Robustness via Adversarial Hypervolume](https://arxiv.org/abs/2403.05100) | 提出新指标对抗超体积来全面评估深度学习模型在多种扰动强度下的鲁棒性，并采用新型训练算法来提高对抗鲁棒性。 |
| [^47] | [Benchmarking Large Language Models for Molecule Prediction Tasks](https://arxiv.org/abs/2403.05075) | 本文探讨了大型语言模型在处理分子预测任务方面的潜力和限制，并评估了它们在多样化分子任务中的表现。 |
| [^48] | [Improving Diffusion-Based Generative Models via Approximated Optimal Transport](https://arxiv.org/abs/2403.05069) | 通过近似最优输运技术改进了基于扩散的生成模型，显著提高了模型准确估计去噪器输出的能力，降低了采样过程中的截断误差，实现了更优质的图像生成质量。 |
| [^49] | [Reset & Distill: A Recipe for Overcoming Negative Transfer in Continual Reinforcement Learning](https://arxiv.org/abs/2403.05066) | 开发了Reset & Distill（R&D）方法，通过重置代理的网络和提炼知识，有效克服了持续强化学习中负迁移问题。 |
| [^50] | [Unsupervised Graph Neural Architecture Search with Disentangled Self-supervision](https://arxiv.org/abs/2403.05064) | 提出了一种新颖的解耦自监督图神经架构搜索（DSGAS）模型，能够发现捕获各种潜在图因素的最佳架构 |
| [^51] | [A Sinkhorn-type Algorithm for Constrained Optimal Transport](https://arxiv.org/abs/2403.05054) | 本文介绍了一种用于受约束优化输运的Sinkhorn类型算法，通过引入熵正则化公式并在对偶空间中证明了算法的亚线性一阶收敛率。 |
| [^52] | [Are Human Conversations Special? A Large Language Model Perspective](https://arxiv.org/abs/2403.05045) | 本研究分析了大型语言模型在理解人类对话时的注意机制变化，发现尽管语言模型在特定领域表现出不同的注意行为，但在专门处理人类对话方面存在明显差距，需要通过多样化的高质量对话数据训练模型来增强理解和生成 |
| [^53] | [CRM: Single Image to 3D Textured Mesh with Convolutional Reconstruction Model](https://arxiv.org/abs/2403.05034) | CRM提出了一种高保真度的前馈单图像到3D生成模型，通过将三平面的几何先验整合到网络设计中，实现了从单个输入图像生成六个正交视图图像，然后利用卷积U-Net进行处理，从而提高了生成质量和速度。 |
| [^54] | [Quantifying Manifolds: Do the manifolds learned by Generative Adversarial Networks converge to the real data manifold](https://arxiv.org/abs/2403.05033) | 通过研究ML模型学习到的流形的内在维度和拓扑特征，本文探讨了这些度量在训练过程中是否收敛到真实数据流形的度量。 |
| [^55] | [Defending Against Unforeseen Failure Modes with Latent Adversarial Training](https://arxiv.org/abs/2403.05030) | 本研究利用潜在对抗训练（LAT）来防御AI系统中未预见的故障模式，通过利用网络实际用于预测的压缩、抽象和结构化概念的潜在表示，有效清除了恶意软件和对抗性攻击。 |
| [^56] | [Spectral Invariant Learning for Dynamic Graphs under Distribution Shifts](https://arxiv.org/abs/2403.05026) | 该论文首次提出在动态图的谱域内研究分布漂移，并提出了谱不变学习方法来应对谱域中的分布漂移挑战。 |
| [^57] | [A Probabilistic Hadamard U-Net for MRI Bias Field Correction](https://arxiv.org/abs/2403.05024) | 提出了一种用于前列腺MRI偏置场校正的概率哈达玛U-Net，引入了哈达玛U-Net（HU-Net）通过哈达玛变换将输入图像从时域转换为频域，并使用可训练的滤波器和硬阈值层消除高频部分。 |
| [^58] | [Simple Multigraph Convolution Networks](https://arxiv.org/abs/2403.05014) | 本文提出了一种简单的多图卷积网络（SMGCN），通过提取一致的交叉视图拓扑和执行多项式展开，有效降低了多图卷积的复杂度，实现了可信的交叉视图空间消息传递。 |
| [^59] | [Provable Multi-Party Reinforcement Learning with Diverse Human Feedback](https://arxiv.org/abs/2403.05006) | 该研究首次提出了多方协作强化学习的理论研究，通过整合多个个体不同偏好的元学习与不同社会福利函数的采用，克服了传统RLHF方法无法捕捉并平衡多个个体偏好的局限性。 |
| [^60] | [Can't Remember Details in Long Documents? You Need Some R&R](https://arxiv.org/abs/2403.05004) | 引入R&R方法，结合reprompting和in-context retrieval两种新型提示方式，提高了在长文档上的问答任务的准确性。 |
| [^61] | [Jet Discrimination with Quantum Complete Graph Neural Network](https://arxiv.org/abs/2403.04990) | QCGNN通过量子并行性实现了对喷注判别的多项式加速，为喷注判别问题带来新的解决方案 |
| [^62] | [Stacking as Accelerated Gradient Descent](https://arxiv.org/abs/2403.04978) | Stacking提出了一种理论解释，即实现了Nesterov的加速梯度下降形式，并证明对于某些深度线性残差网络，提供了加速训练。 |
| [^63] | [C2P-GCN: Cell-to-Patch Graph Convolutional Network for Colorectal Cancer Grading](https://arxiv.org/abs/2403.04962) | C2P-GCN提出了一种新颖的细胞到补丁图卷积网络方法，通过两阶段图形成，在第一阶段形成补丁级图，第二阶段形成图像级图，从而更好地捕捉结直肠癌组织结构信息。 |
| [^64] | [SecGPT: An Execution Isolation Architecture for LLM-Based Systems](https://arxiv.org/abs/2403.04960) | 提出了一种面向LLM系统的执行隔离架构SecGPT，旨在解决第三方应用程序执行所引发的安全和隐私问题 |
| [^65] | [Electrocardiogram Instruction Tuning for Report Generation](https://arxiv.org/abs/2403.04945) | 提出了Multimodal ECG Instruction Tuning（MEIT）框架，首次尝试使用LLMs和多模态指导解决ECG报告生成问题，并在两个大规模ECG数据集上进行了广泛的实验评估其优越性。 |
| [^66] | [A spatiotemporal style transfer algorithm for dynamic visual stimulus generation](https://arxiv.org/abs/2403.04940) | 提出了Spatiotemporal Style Transfer (STST)算法，基于双流深度神经网络模型，允许生成强大的动态视觉刺激，用于视觉研究。 |
| [^67] | [Gradient-free neural topology optimization](https://arxiv.org/abs/2403.04937) | 通过提出一种预训练的神经重新参数化策略，在无梯度神经拓扑优化中实现了迭代次数的显著降低，这将开辟一个新的解决路径。 |
| [^68] | [On the Markov Property of Neural Algorithmic Reasoning: Analyses and Methods](https://arxiv.org/abs/2403.04929) | 本研究提出了ForgetNet和G-ForgetNet，通过不使用历史嵌入和引入门控机制来解决神经算法推理中的马尔可夫性质矛盾，提供了有价值的计算路径。 |
| [^69] | [Control-based Graph Embeddings with Data Augmentation for Contrastive Learning](https://arxiv.org/abs/2403.04923) | 本文提出了一种利用图的控制属性进行数据增强的对比学习框架，相比现有方法，提高了对比学习框架的有效性。 |
| [^70] | [Identifying Causal Effects Under Functional Dependencies](https://arxiv.org/abs/2403.04919) | 本文研究了在已知某些变量由它们的父节点功能决定的情况下，如何识别因果效应，在这种情况下可以使得一些不可识别的因果效应变得可识别，并且可以在不影响因果效应可识别性的情况下排除观测到的功能性变量，从而显著减少需要的观测数据中的变量数量。 |
| [^71] | [Optimizing Retinal Prosthetic Stimuli with Conditional Invertible Neural Networks](https://arxiv.org/abs/2403.04884) | 利用有条件可逆神经网络无监督优化视网膜假体刺激，提高了电极阵列的刺激效果。 |
| [^72] | [Learning Traveling Solitary Waves Using Separable Gaussian Neural Networks](https://arxiv.org/abs/2403.04883) | 该论文提出了一种新颖的可解释神经网络架构 SGNN，用于学习跨越不同家族的偏微分方程的行波孤波，并解决了传统PINNs在大型计算域中的传播失败问题。 |
| [^73] | [Efficient High-Resolution Time Series Classification via Attention Kronecker Decomposition](https://arxiv.org/abs/2403.04882) | 通过引入Kronecker分解的注意力， Hierarchical attention-based Kronecker-decomposition for high-resolution time series classification. |
| [^74] | [Aligning GPTRec with Beyond-Accuracy Goals with Reinforcement Learning](https://arxiv.org/abs/2403.04875) | GPTRec模型使用Next-K策略来生成推荐，与传统的Top-K模型不同，可以更好地考虑超出准确性指标的复杂项目间相互依赖性。 |
| [^75] | [Group Privacy Amplification and Unified Amplification by Subsampling for R\'enyi Differential Privacy](https://arxiv.org/abs/2403.04867) | 该论文提出了一个统一的框架，用于为Rényi-DP推导通过子抽样的放大保证，这是首个针对隐私核算方法的框架，也具有独立的重要性。 |
| [^76] | [A Survey of Lottery Ticket Hypothesis](https://arxiv.org/abs/2403.04861) | 大乐透假设指出神经网络中存在稀疏子网络，训练孤立子网络可以获得更好性能，调查综述了LTH现状并提出未来研究方向 |
| [^77] | [Solving Inverse Problems with Model Mismatch using Untrained Neural Networks within Model-based Architectures](https://arxiv.org/abs/2403.04847) | 提出了一种在基于模型架构中使用未经训练的神经网络来解决模型不匹配的方法，证明了其在一定条件下的收敛性能 |
| [^78] | [UniTable: Towards a Unified Framework for Table Structure Recognition via Self-Supervised Pretraining](https://arxiv.org/abs/2403.04822) | UniTable 提出了一个统一框架，通过自监督预训练实现表结构识别，将不同的任务和目标统一到语言建模中，在四个最大的TSR数据集上表现出最先进的性能。 |
| [^79] | [Storm Surge Modeling in the AI ERA: Using LSTM-based Machine Learning for Enhancing Forecasting Accuracy](https://arxiv.org/abs/2403.04818) | 利用基于LSTM的机器学习模型，通过预测物理模型的系统误差来改善飓风风暴潮模型的预测准确性。 |
| [^80] | [Evaluation of LLMs on Syntax-Aware Code Fill-in-the-Middle Tasks](https://arxiv.org/abs/2403.04814) | 该研究引入了一个新的基准SAFIM用于评估LLMs在代码填空任务上的句法感知完成表现，发现FIM预训练不仅提高了FIM的熟练度，还改善了LLMs的左到右推理，挑战了传统观念并表明预训练方法和数据品质对模型性能的影响更甚于模型大小。 |
| [^81] | [TrafPS: A Shapley-based Visual Analytics Approach to Interpret Traffic](https://arxiv.org/abs/2403.04812) | 提出了 TrafPS，一种基于 Shapley 的视觉分析方法，用于解释交通预测结果，支持交通管理和城市规划中的决策制定。 |
| [^82] | [Quantifying Contamination in Evaluating Code Generation Capabilities of Language Models](https://arxiv.org/abs/2403.04811) | 研究量化了流行的代码生成基准测试的数据污染程度，揭示了它们与预训练语料库之间的重叠，并展示模型的显著性能重叠。 |
| [^83] | [Restricted Bayesian Neural Network](https://arxiv.org/abs/2403.04810) | 本研究提出了限制贝叶斯神经网络的新架构，显著减少了网络存储空间复杂性，并引入了一种能够有效处理不确定性的算法，确保在目标函数缺乏完美凸性时稳健地收敛至全局最优解。 |
| [^84] | [Investigation of the Impact of Synthetic Training Data in the Industrial Application of Terminal Strip Object Detection](https://arxiv.org/abs/2403.04809) | 本文研究了标准物体检测器在复杂的工业终端条对象检测应用中的模拟到真实泛化性能。 |
| [^85] | [WaterMax: breaking the LLM watermark detectability-robustness-quality trade-off](https://arxiv.org/abs/2403.04808) | WaterMax提出了一种新的水印方案，能够在保持生成文本质量的同时实现高检测性能，打破了水印技术中质量和稳健性之间的传统平衡。 |
| [^86] | [Mathematics of Neural Networks (Lecture Notes Graduate Course)](https://arxiv.org/abs/2403.04807) | 该课程旨在向研究生数学专业的学生介绍神经网络并激发兴趣，主要内容包括深度学习的数学介绍和将李群理论应用于设计具有几何等变性的神经网络，讲义及编码教程公开可获取 |
| [^87] | [Not all tickets are equal and we know it: Guiding pruning with domain-specific knowledge](https://arxiv.org/abs/2403.04805) | 使用领域特定结构信息来引导修剪的方法 DASH 在学习动态基因调控网络模型时表现出色，提供了更有意义的生物学见解 |
| [^88] | [AttentionStitch: How Attention Solves the Speech Editing Problem](https://arxiv.org/abs/2403.04804) | AttentionStitch模型通过引入双注意力块网络，并将编辑文本的mel频谱图与合成的mel频谱图自动融合，实现了语音编辑的无缝整合。 |
| [^89] | [Enhancing Security in Federated Learning through Adaptive Consensus-Based Model Update Validation](https://arxiv.org/abs/2403.04803) | 通过自适应阈值机制和共识验证流程，增强了联邦学习系统对标签翻转攻击的安全性，有效减轻了攻击并提升系统的弹性。 |
| [^90] | [(Un)paired signal-to-signal translation with 1D conditional GANs](https://arxiv.org/abs/2403.04800) | 一维条件生成对抗网络能够实现非配对信号到信号的翻译，将二维图像到图像翻译任务转换为一维信号到信号任务，且在频率方面表现出类似配对信号的效果。 |
| [^91] | [JMI at SemEval 2024 Task 3: Two-step approach for multimodal ECAC using in-context learning with GPT and instruction-tuned Llama models](https://arxiv.org/abs/2403.04798) | 本文介绍了针对SemEval-2024任务3开发的多模态情感因果分析系统，提出了通过两步框架解决多模态情感因果分析挑战的方法，并在实验中取得显著性能提升。 |
| [^92] | [Found in the Middle: How Language Models Use Long Contexts Better via Plug-and-Play Positional Encoding](https://arxiv.org/abs/2403.04797) | 通过引入多尺度位置编码（Ms-PoE）来增强大型语言模型（LLMs）对上下文中间相关信息的处理能力，解决了LLMs面临的“中间丢失”挑战。 |
| [^93] | [Large Language Models in Fire Engineering: An Examination of Technical Questions Against Domain Knowledge](https://arxiv.org/abs/2403.04795) | 本研究比较了两个聊天机器人在消防工程中处理问题的表现，发现ChatGPT表现较优，展示了聊天机器人技术在消防工程实践中的潜力。 |
| [^94] | [A Data-Driven Two-Phase Multi-Split Causal Ensemble Model for Time Series](https://arxiv.org/abs/2403.04793) | 提出了一种基于数据驱动的两阶段多分裂因果集成模型，通过组合不同因果基准算法的优势，降低噪音的影响，实现更稳健的因果推断结果。 |
| [^95] | [Breaking the Language Barrier: Can Direct Inference Outperform Pre-Translation in Multilingual LLM Applications?](https://arxiv.org/abs/2403.04792) | 本研究挑战了以往研究中建立的预翻译范式，并在108种语言中的94种语言中表明PaLM2-L在直接推断中优于预翻译。 |
| [^96] | [LLM vs. Lawyers: Identifying a Subset of Summary Judgments in a Large UK Case Law Dataset](https://arxiv.org/abs/2403.04791) | 使用大型语言模型（LLM）对比传统的自然语言处理方法，可以更有效地从大型英国法院判决数据集中识别摘要裁定案例，取得了更高的F1得分。 |
| [^97] | [TopicDiff: A Topic-enriched Diffusion Approach for Multimodal Conversational Emotion Detection](https://arxiv.org/abs/2403.04789) | 提出了一种TopicDiff方法，用于捕获多模态会话情感检测任务中的主题信息，通过将扩散模型集成到神经主题模型中，解决了神经主题模型在捕获主题信息方面的多样性不足问题，并相对于现有MCE基线取得了显著改进 |
| [^98] | [Analysis of Privacy Leakage in Federated Large Language Models](https://arxiv.org/abs/2403.04784) | 该论文对在训练大语言模型时使用联邦学习进行隐私分析进行了全面研究，设计了两种主动成员推理攻击来评估各种调整后的联邦学习配置的隐私泄漏，并揭示了流行的大语言模型存在的重大隐私漏洞。 |
| [^99] | [AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks](https://arxiv.org/abs/2403.04783) | 提出了一种基于响应过滤的多Agent防御框架AutoDefense，可以有效提高LLMs对抗越狱攻击的鲁棒性，同时保持正常用户请求的性能。 |
| [^100] | [Selective Encryption using Segmentation Mask with Chaotic Henon Map for Multidimensional Medical Images](https://arxiv.org/abs/2403.04781) | 该方案以医疗专业人员用户的视角创新于医学图像存储和安全领域，通过分割和加密医学图像中不可或缺的部分来实现对多维医学图像的选择性加密。 |
| [^101] | [An Efficient Difference-of-Convex Solver for Privacy Funnel](https://arxiv.org/abs/2403.04778) | 提出了一种针对隐私漏斗方法的高效求解器，能在已知和未知分布条件下均有效地进行求解，并在实验中展示出优于现有方法的性能。 |
| [^102] | [Social Orientation: A New Feature for Dialogue Analysis](https://arxiv.org/abs/2403.04770) | 感知模型认为社交取向（例如，热情友好、傲慢冷漠）对话参与者可以用来预测和解释社交互动的结果。我们的工作在于系统性地应用社交取向标签来建模对话结果 |
| [^103] | [Removing GPT4's Filter](https://arxiv.org/abs/2403.04769) | 提出了一种方法，可以使经过微调的GPT4恢复到没有经过人类反馈强化学习训练的状态，从而移除其在学习期间的所有安全机制 |
| [^104] | [Context-Based Multimodal Fusion](https://arxiv.org/abs/2403.04650) | 提出一种基于上下文的多模态融合模型，结合了模态融合和数据分布对齐，通过特定上下文向量表示每个模态，并将其与每个模态的嵌入进行融合， |
| [^105] | [Explaining Bayesian Optimization by Shapley Values Facilitates Human-AI Collaboration](https://arxiv.org/abs/2403.04629) | 提出了ShapleyBO框架，用Shapley值解释贝叶斯优化提议，量化每个参数对于优化过程的贡献，并能够区分不同类型的不确定性探索贡献。 |
| [^106] | [In-n-Out: Calibrating Graph Neural Networks for Link Prediction](https://arxiv.org/abs/2403.04605) | IN-N-OUT提出了第一个用于链接预测的图神经网络校准方法，基于对GNN校准偏差的观察，通过简单直觉实现校准 |
| [^107] | [What makes an image realistic?](https://arxiv.org/abs/2403.04493) | 论文讨论了如何设计能够可靠区分真实数据和不真实数据的函数，提出了通用评论者的概念作为一个新的解决方案。 |
| [^108] | [Dynamics of Moral Behavior in Heterogeneous Populations of Learning Agents](https://arxiv.org/abs/2403.04202) | 在多代理环境中，研究人员探讨了不同道德类型的学习代理之间的互动，发现道德异质性可能对代理的共同发展产生影响。 |
| [^109] | [DPOT: Auto-Regressive Denoising Operator Transformer for Large-Scale PDE Pre-Training](https://arxiv.org/abs/2403.03542) | 本文提出了一种新的自回归去噪预训练策略，可以更稳定、更高效地在PDE数据上进行预训练，并且通过基于傅里叶注意力的模型架构设计，实现了在大规模预训练中轻松扩展模型，该模型在多个PDE数据集上取得了SOTA表现。 |
| [^110] | [SplAgger: Split Aggregation for Meta-Reinforcement Learning](https://arxiv.org/abs/2403.03020) | 本文展示了任务推断序列模型在元强化学习中的益处。 |
| [^111] | [Learning without Exact Guidance: Updating Large-scale High-resolution Land Cover Maps from Low-resolution Historical Labels](https://arxiv.org/abs/2403.02746) | 提出了一个名为Paraformer的弱监督框架，通过低分辨率历史土地覆盖数据指导大规模高分辨率土地覆盖映射，设计了CNN-Transformer特征提取器来综合捕获局部和全局背景信息 |
| [^112] | [Wukong: Towards a Scaling Law for Large-Scale Recommendation](https://arxiv.org/abs/2403.02545) | Wukong通过堆叠因子分解机和协同增长策略，在推荐领域建立了一个标度律，并在质量上优于现有模型。 |
| [^113] | [A Decade of Privacy-Relevant Android App Reviews: Large Scale Trends](https://arxiv.org/abs/2403.02292) | 通过分析谷歌应用商店上1200万条隐私相关评论，研究了十年间隐私评论的大规模趋势，发现隐私评论呈现持续增长，探讨了热门和逐渐减少的隐私话题，以及不同国家用户对隐私问题看法的差异。 |
| [^114] | [A Composite Decomposition Method for Large-Scale Global Optimization](https://arxiv.org/abs/2403.01192) | 本文提出了一种复合分解方法，将差分分组和一般分组方法整合到一个框架中，通过逐步分解准确分解各种问题类型，降低了计算复杂性。 |
| [^115] | [Automated Efficient Estimation using Monte Carlo Efficient Influence Functions](https://arxiv.org/abs/2403.00158) | 该论文提出了一种名为蒙特卡洛高效影响函数（MC-EIF）的全自动技术，用于近似高效影响函数，能够实现针对广泛类别的模型和目标函数的统计估计，达到最优的收敛速度。 |
| [^116] | [A Protein Structure Prediction Approach Leveraging Transformer and CNN Integration](https://arxiv.org/abs/2402.19095) | 本研究提出了一种利用Transformer和CNN集成的蛋白质结构预测方法，通过二维融合深度神经网络模型DstruCCN，有助于提升蛋白质二级结构预测的准确性和效率。 |
| [^117] | [Probabilistic Lipschitzness and the Stable Rank for Comparing Explanation Models](https://arxiv.org/abs/2402.18863) | 概率Lipschitz性与稳定秩的研究为比较解释模型提供了新的角度和度量标准。 |
| [^118] | [Multistatic-Radar RCS-Signature Recognition of Aerial Vehicles: A Bayesian Fusion Approach](https://arxiv.org/abs/2402.17987) | 提出了一种完全贝叶斯雷达自动目标识别的框架，采用最优贝叶斯融合来有效地汇总多个雷达的分类概率向量，以改进无人机雷达截面识别效果。 |
| [^119] | [Curriculum Learning Meets Directed Acyclic Graph for Multimodal Emotion Recognition](https://arxiv.org/abs/2402.17269) | 使用有向无环图和课程学习相结合的新方法，提升多模态情感识别模型在处理情感变化和数据不平衡方面的性能。 |
| [^120] | [CriticBench: Benchmarking LLMs for Critique-Correct Reasoning](https://arxiv.org/abs/2402.14809) | CriticBench是一个综合基准测试，旨在评估LLMs在批判和纠正推理方面的能力，发现批判性训练显著提升性能，逻辑任务更易于修正。 |
| [^121] | [SzCORE: A Seizure Community Open-source Research Evaluation framework for the validation of EEG-based automated seizure detection algorithms](https://arxiv.org/abs/2402.13005) | 提出了SzCORE框架，用于验证基于脑电图的自动癫痫检测算法，旨在标准化验证方法，包括数据集、文件格式、输入内容、性能度量等。 |
| [^122] | [Knowledge Distillation Based on Transformed Teacher Matching](https://arxiv.org/abs/2402.11148) | 通过放弃学生端的温度缩放，本文提出了一种名为转换教师匹配（TTM）的知识蒸馏变体，通过对温度缩放的重新解释，TTM在目标函数中引入了固有的Rényi熵项，从而实现了更好的学生泛化效果。 |
| [^123] | [Multimodal Interpretable Data-Driven Models for Early Prediction of Antimicrobial Multidrug Resistance Using Multivariate Time-Series](https://arxiv.org/abs/2402.06295) | 本研究提出了一种基于可解释的多模态数据驱动模型的方法，通过静态数据和多元时间序列模型预测和理解重症监护病房中抗菌药物多重耐药性细菌的出现。 |
| [^124] | [Structured Entity Extraction Using Large Language Models](https://arxiv.org/abs/2402.04437) | 本论文提出了一种使用大型语言模型的结构化实体提取方法，在此任务上通过引入AESOP度量评估模型性能，并将整个提取任务分解为多个阶段，相较于基准模型取得了更好的效果，为未来结构化实体提取的进一步发展提供了有希望的方向。 |
| [^125] | [Large Language Models to Enhance Bayesian Optimization](https://arxiv.org/abs/2402.03921) | 通过结合大型语言模型（LLM）的能力，我们提出了一种名为LLAMBO的新方法，将其应用于贝叶斯优化（BO）。通过用自然语言描述BO问题，并利用LLM的上下文理解、少样本学习能力和领域知识，LLAMBO能够提供有前景的解决方案，并且在零样本热启动方面表现出良好的效果。 |
| [^126] | [Revisiting Generative Adversarial Networks for Binary Semantic Segmentation on Imbalanced Datasets](https://arxiv.org/abs/2402.02245) | 这项工作提出了一种基于生成对抗网络的深度学习框架，用于像素级别的路面异常区域检测。通过两个训练阶段和多尺度特征表示，该框架增强了生成器从异构输入中估计概率特征图的能力，并通过引入几种注意机制，解决了在严重不平衡数据集上训练模型时性能恶化的问题。 |
| [^127] | [Precedence-Constrained Winter Value for Effective Graph Data Valuation](https://arxiv.org/abs/2402.01943) | 提出了一种名为PC-Winter的优先约束冬季价值方法，用于有效地评估复杂图形数据的价值。通过解决复杂的图形结构以及计算挑战，PC-Winter方法在各种数据集和任务中展示了其有效性。 |
| [^128] | [A Variational Autoencoder for Neural Temporal Point Processes with Dynamic Latent Graphs](https://arxiv.org/abs/2312.16083) | 提出了一种用于捕捉混合时间动态的新颖变分自编码器模型，使用顺序潜变量模型在子间隔内学习事件间的依赖图，提高了在预测事件间隔时间方面的准确性。 |
| [^129] | [MixEHR-SurG: a joint proportional hazard and guided topic model for inferring mortality-associated topics from electronic health records](https://arxiv.org/abs/2312.13454) | MixEHR-SurG是一种监督主题模型，结合了EHR数据和生存风险模型，实现了高度可解释的生存主题模型，可以推断与患者死亡相关的PheCode特定表型主题。 |
| [^130] | [ERASE: Error-Resilient Representation Learning on Graphs for Label Noise Tolerance](https://arxiv.org/abs/2312.08852) | ERASE提出了一种名为ERASE的方法，通过最大化编码率降低来学习具有误差容忍性的表示，以增强深度学习模型对图任务中标签噪声的鲁棒性。 |
| [^131] | [A dynamical clipping approach with task feedback for Proximal Policy Optimization](https://arxiv.org/abs/2312.07624) | 提出了一种基于任务反馈的动态剪裁方法，通过增加最大累积回报来优化近端策略优化的性能。 |
| [^132] | [Eigenmatrix for unstructured sparse recovery](https://arxiv.org/abs/2311.16609) | 本文提出了一种名为特征矩阵的数据驱动构造，用于解决非结构稀疏恢复问题，对于样本值中的噪声和样本位置的非结构性质具有很好的适应性。 |
| [^133] | [DPOD: Domain-Specific Prompt Tuning for Multimodal Fake News Detection](https://arxiv.org/abs/2311.16496) | 本研究提出了一种名为DPOD的框架，通过利用跨领域数据来改善所需领域的脱离上下文误信息检测，解决数据不平衡的问题。 |
| [^134] | [Out-of-Distribution Generalized Dynamic Graph Neural Network for Human Albumin Prediction](https://arxiv.org/abs/2311.15545) | 提出了一种名为DyG-HAP的框架，利用超分布广义动态图神经网络进行人类白蛋白预测，特别适用于ICU患者。 |
| [^135] | [Out-of-Distribution Generalized Dynamic Graph Neural Network with Disentangled Intervention and Invariance Promotion](https://arxiv.org/abs/2311.14255) | 本文提出了一种名为I-DIDA的动态图神经网络来处理动态图中的时空分布变化，通过发现和利用稳定的不变模式，即结构和特征在分布变化下具有稳定预测能力。 |
| [^136] | [A Voting Approach for Explainable Classification with Rule Learning](https://arxiv.org/abs/2311.07323) | 该论文研究了一种将规则学习和投票方法相结合的新方法，旨在实现与先进机器学习方法相媲美的分类结果，并提供基于确定性规则的解释。 |
| [^137] | [Neural General Circulation Models for Weather and Climate](https://arxiv.org/abs/2311.07222) | 该研究提出了第一个结合了大气动力学可微分求解器和机器学习组件的GCM，展示其能够生成与最佳机器学习和基于物理模型方法相匹敌的确定性天气、集合天气和气候预测。 |
| [^138] | [Can LLMs Follow Simple Rules?](https://arxiv.org/abs/2311.04235) | 提出了一个名为RuLES的程序框架，用于衡量LLMs在与用户交互时遵守规则的能力。 |
| [^139] | [Multi-View Causal Representation Learning with Partial Observability](https://arxiv.org/abs/2311.04056) | 我们提出了一个统一的框架，用于学习来自不同数据视图的因果关系表示，证明了跨视图子集的信息可以通过对比学习和单个编码器学习，同时提供了一个观测潜在变量的简单规则。 |
| [^140] | [Mixed Models with Multiple Instance Learning](https://arxiv.org/abs/2311.02455) | MixMIL是一个整合了广义线性混合模型（GLMM）和多实例学习（MIL）的框架，能够更好地处理单细胞数据中的细胞异质性，在单细胞数据集中表现优越。 |
| [^141] | [Balancing Act: Constraining Disparate Impact in Sparse Models](https://arxiv.org/abs/2310.20673) | 提出了一种约束优化方法，直接解决修剪导致的不平等问题，为每个子组设置界限以限制稠密和稀疏模型之间的准确度变化。 |
| [^142] | [Differentiable Learning of Generalized Structured Matrices for Efficient Deep Neural Networks](https://arxiv.org/abs/2310.18882) | 提出了一种可微的广义框架，通过梯度下降学习高效的权重矩阵结构。 |
| [^143] | [ManyQuadrupeds: Learning a Single Locomotion Policy for Diverse Quadruped Robots](https://arxiv.org/abs/2310.10486) | 通过受动物运动控制的启发，我们展示出能够有效训练一个单一运动策略，可以控制多样化四足机器人。 |
| [^144] | [Be Careful What You Smooth For: Label Smoothing Can Be a Privacy Shield but Also a Catalyst for Model Inversion Attacks](https://arxiv.org/abs/2310.06549) | 标签平滑方法在深度学习中发挥重要作用，既能提升模型泛化能力和校准性，又可能成为模型隐私泄露的因素。研究揭示了结合负因子进行平滑可有效阻止模型反推攻击，提升隐私保护效果，超越了当前最先进的防御技术。 |
| [^145] | [TAIL: Task-specific Adapters for Imitation Learning with Large Pretrained Models](https://arxiv.org/abs/2310.05905) | TAIL提出了一种适配器框架，通过高效微调技术将大型预训练模型用于新的控制任务，以实现数据有效率、持续适应不同控制任务。 |
| [^146] | [Quantized Fourier and Polynomial Features for more Expressive Tensor Network Models](https://arxiv.org/abs/2309.05436) | 提出了一种量化傅立叶和多项式特征的方法，并基于此特征量化提出将相关模型权重也进行量化，得到了更具表达力的张量网络模型。 |
| [^147] | [New intelligent defense systems to reduce the risks of Selfish Mining and Double-Spending attacks using Learning Automata](https://arxiv.org/abs/2307.00529) | 提出了一种结合双花和自私挖矿攻击的全新攻击方式，并使用学习自动机提出了两种模型（SDTLA和WVBM），可以有效抵御自私挖矿攻击，提高盈利阈值。 |
| [^148] | [Towards Enhancing Time Series Contrastive Learning: A Dynamic Bad Pair Mining Approach](https://arxiv.org/abs/2302.03357) | 提出了一种动态坏样本挖掘（DBPM）算法，可靠地识别和抑制时间序列对比学习中的噪声正样本对和错误正样本对。 |
| [^149] | [Cooperative data-driven modeling](https://arxiv.org/abs/2211.12971) | 这项研究开发出一种持续学习方法，首次将其应用于固体力学，以解决人工神经网络遗忘问题，促进合作数据驱动建模。 |
| [^150] | [Spectrally-Corrected and Regularized Linear Discriminant Analysis for Spiked Covariance Model](https://arxiv.org/abs/2210.03859) | SRLDA方法在波纹模型假设下具有线性分类全局最优解，并在实验中表现出比RLDA和ILDA更好的性能。 |
| [^151] | [Functional Linear Regression of Cumulative Distribution Functions](https://arxiv.org/abs/2205.14545) | 本文研究了上下文环境中的累积分布函数的函数回归，在估计误差和信息理论下界方面取得了重要进展。 |
| [^152] | [Settling the Sample Complexity of Model-Based Offline Reinforcement Learning](https://arxiv.org/abs/2204.05275) | 该论文展示了基于模型的（或“插件”）方法在标签化马尔可夫决策过程（MDPs）中实现了无烧录成本的极小极优样本复杂性。 |
| [^153] | [Testing Stationarity and Change Point Detection in Reinforcement Learning](https://arxiv.org/abs/2203.01707) | 开发了一种能够在非平稳环境中进行策略优化的强化学习方法，通过测试最优Q函数的非平稳性并开发序贯变点检测方法来实现。 |
| [^154] | [Intriguing Properties of Input-dependent Randomized Smoothing](https://arxiv.org/abs/2110.05365) | 输入相关平滑方法虽然被用来获取可靠鲁棒分类器，但缺乏形式保证，其证书并不合理，因受到维度诅咒影响；提出了一个理论和实践框架，使得即使在维度诅咒存在的情况下，也能在严格的限制条件下使用输入相关平滑。 |
| [^155] | [A Bayesian Learning Algorithm for Unknown Zero-sum Stochastic Games with an Arbitrary Opponent](https://arxiv.org/abs/2109.03396) | 本文提出了一种针对无限时间跨度的零和随机博弈的在线学习算法，该算法在具有平均奖励准则的情况下实现了贝叶斯遗憾界$O(HS\sqrt{AT})$。 |
| [^156] | [Can Error Mitigation Improve Trainability of Noisy Variational Quantum Algorithms?](https://arxiv.org/abs/2109.01051) | 误差缓解的策略无法解决指数级成本集中问题而不在其他地方投入指数级资源，某些策略能够改善有噪声的变分量子算法的可训性。 |
| [^157] | [A step toward a reinforcement learning de novo genome assembler](https://arxiv.org/abs/2102.02649) | 本研究旨在探讨机器学习在基因组组装中的应用，使用强化学习（RL）。他们在文献中唯一发现的方法的基础上进行了扩展，以仔细探索学习过程。 |
| [^158] | [A unified framework for hard and soft clustering with regularized optimal transport](https://arxiv.org/abs/1711.04366) | 这个方法提出了一个统一的框架，将离散数据推断有限混合模型的问题建模为带有正则化最优输运的问题，同时在聚类中融合了硬聚类和软聚类，并且实验证明当参数$\lambda>1$时可以提高推断性能，当$\lambda\to 0$时适用于分类。 |
| [^159] | [Performance Analysis of Support Vector Machine (SVM) on Challenging Datasets for Forest Fire Detection.](http://arxiv.org/abs/2401.12924) | 本文对于使用图像数据集进行森林火灾检测的支持向量机（SVM）进行了性能分析，并研究了关键因素如数据预处理、特征提取和模型训练。这项研究有助于开发高效的森林火灾检测系统。 |
| [^160] | [Interventional Fairness on Partially Known Causal Graphs: A Constrained Optimization Approach.](http://arxiv.org/abs/2401.10632) | 本文提出了一个框架，用于在部分已知的真实因果图情况下实现因果公平性。通过使用部分有向无环图（PDAG）建模和衡量因果公平性，并通过受限优化问题平衡公平性和准确性。 |
| [^161] | [FedLoGe: Joint Local and Generic Federated Learning under Long-tailed Data.](http://arxiv.org/abs/2401.08977) | 本文介绍了一种名为FedLoGe的方法，它通过在神经网络崩溃框架中集成表示学习和分类器对齐来提高区域和全局模型的性能，解决了在联邦长尾学习中忽视本地级别性能的问题。 |
| [^162] | [REValueD: Regularised Ensemble Value-Decomposition for Factorisable Markov Decision Processes.](http://arxiv.org/abs/2401.08850) | REValueD是一种通过正则化集合值分解的新算法，针对高维离散动作空间的任务提供了优越性能，尤其在人形和狗类任务中表现出色。它遏制了Q-learning算法的高估偏差，并减轻了目标方差问题。 |
| [^163] | [Bayes Conditional Distribution Estimation for Knowledge Distillation Based on Conditional Mutual Information.](http://arxiv.org/abs/2401.08732) | 本文介绍了一种基于条件互信息的贝叶斯条件分布估计方法，通过最大化教师的对数似然和条件互信息来改进知识蒸馏中的估计。实验证明，使用该方法训练的教师能够更好地捕捉图像聚类中的上下文信息。 |
| [^164] | [Advancing Deep Active Learning & Data Subset Selection: Unifying Principles with Information-Theory Intuitions.](http://arxiv.org/abs/2401.04305) | 本论文探索了基于信息论原则的主动学习和主动采样方面的数据子集选择技术，以提高深度学习模型的标签和训练效率。 |
| [^165] | [Brain decoding: toward real-time reconstruction of visual perception.](http://arxiv.org/abs/2310.19812) | 本研究提出了一种基于脑磁图（MEG）的脑解码方法，通过训练一个具有预训练嵌入、MEG模块和图像生成器的模型，在实时应用中实现了对视觉知觉的高时间分辨率解码，并在图像检索上取得了7倍的改进。 |
| [^166] | [LLM4DyG: Can Large Language Models Solve Problems on Dynamic Graphs?.](http://arxiv.org/abs/2310.17110) | 本研究首次提出了评估大型语言模型（LLMs）在动态图上的时空理解能力的LLM4DyG基准，并通过广泛的实验分析了不同因素对模型性能的影响。 |
| [^167] | [Generative ensemble deep learning severe weather prediction from a deterministic convection-allowing model.](http://arxiv.org/abs/2310.06045) | 本论文开发了一种集成后处理方法，将生成对抗网络（CGANs）和卷积神经网络（CNN）结合起来，对严重天气进行概率预测。该方法在使用HRRR预报作为输入数据，在2021年的测试数据集上相对于其他基于神经网络的方法提高了高达20％的Brier技巧分数（BSS）。 |
| [^168] | [RetSeg: Retention-based Colorectal Polyps Segmentation Network.](http://arxiv.org/abs/2310.05446) | 本研究探索将保留机制整合到结直肠息肉分割中，解决了视觉变换器在资源受限设备上实时疾病检测中的内存和并行性挑战。 |
| [^169] | [Molecular De Novo Design through Transformer-based Reinforcement Learning.](http://arxiv.org/abs/2310.05365) | 本文提出了一种基于Transformer的强化学习方法，通过精细调整生成模型，能够在分子的全新设计中生成具有所需性质的分子结构，展现出优越的性能。 |
| [^170] | [Out of Sight, Still in Mind: Reasoning and Planning about Unobserved Objects with Video Tracking Enabled Memory Models.](http://arxiv.org/abs/2309.15278) | 本文研究了如何对先前观察到但当前被遮挡的对象进行推理和规划，提出了利用转换器关系动力学编码轨迹历史的方法，并在多个挑战性任务中表现出色。 |
| [^171] | [LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models.](http://arxiv.org/abs/2309.12307) | LongLoRA是一种高效的精细调整方法，可以在有限的计算成本下扩展预训练的大型语言模型的上下文大小。它通过稀疏的局部注意力实现精细调整，并使用移动短注意力有效实现上下文扩展，与传统方法具有相似的性能。 |
| [^172] | [Self-Supervised Blind Source Separation via Multi-Encoder Autoencoders.](http://arxiv.org/abs/2309.07138) | 本论文提出了一种基于多编码器自编码器和自监督学习的方法，用于解决盲源分离问题。通过训练网络进行输入解码和重构，然后利用编码掩蔽技术进行源推断，同时引入路径分离损失以促进稀疏性。 |
| [^173] | [Scalable neural network models and terascale datasets for particle-flow reconstruction.](http://arxiv.org/abs/2309.06782) | 本研究针对高能电子-正电子碰撞中的粒子流重建，使用可扩展的机器学习模型，并通过超参数调优和硬件处理器的高度可移植性，取得了真实且具有竞争力的物理性能。 |
| [^174] | [Continuous-Time q-learning for McKean-Vlasov Control Problems.](http://arxiv.org/abs/2306.16208) | 本文研究了连续时间q-learning在熵正则化强化学习框架下用于McKean-Vlasov控制问题，并揭示了两种不同的q函数的存在及其积分表示。 |
| [^175] | [Nearest Neighbour with Bandit Feedback.](http://arxiv.org/abs/2306.13773) | 本论文提出一种新的最近邻算法，能够应用于上下文Bandit问题并处理完全对抗的设置，具有高效运行、快速搜索和准线性空间的优点。 |
| [^176] | [Maximum Entropy Heterogeneous-Agent Mirror Learning.](http://arxiv.org/abs/2306.10715) | 最大熵异质代理镜像学习(MEHAML)是一种新的理论框架，通过最大熵原理设计了最大熵MARL的演员-评论家算法，具有联合最大熵目标的单调改进和收敛至中位响应均衡(QRE)的期望特性，并通过扩展常用的强化学习算法HASAC来验证其实用性和在探索和稳健性方面的显著改进。 |
| [^177] | [ContriMix: Unsupervised disentanglement of content and attribute for domain generalization in microscopy image analysis.](http://arxiv.org/abs/2306.04527) | ContriMix是一种无需标识和手工调优的领域泛化技术，在显微镜图像中通过分离和学习生成合成图像的方式，解决了领域泛化的问题。 |
| [^178] | [Enhancing CLIP with CLIP: Exploring Pseudolabeling for Limited-Label Prompt Tuning.](http://arxiv.org/abs/2306.01669) | 本文探索使用伪标注方法通过提示调参改进CLIP的方法，通过使用零样本伪标签来优化图像分类任务中有限标注数据的问题。 |
| [^179] | [High-Fidelity Image Compression with Score-based Generative Models.](http://arxiv.org/abs/2305.18231) | 本文提出了一种基于分数的生成模型的两阶段方法，该方法在图像压缩领域取得了显著的表现，实验证明该方法在一定比特率下能够提高图像的感知质量。 |
| [^180] | [A Perspectival Mirror of the Elephant: Investigating Language Bias on Google, ChatGPT, Wikipedia, and YouTube.](http://arxiv.org/abs/2303.16281) | 研究发现在Google、ChatGPT、维基百科和YouTube上，搜索结果受限于语言，反映了与复杂主题相关的文化刻板印象，缺乏跨文化视角。 |
| [^181] | [Distill n' Explain: explaining graph neural networks using simple surrogates.](http://arxiv.org/abs/2303.10139) | 本文提出了Distill n' Explain (DnX)方法，通过知识蒸馏学习简单的替代模型，并通过解决简单的凸规划提取节点或边级别的解释，从而解释图神经网络（GNN）。实验结果显示，DnX和FastDnX通常优于最先进的GNN解释器，并且运行速度快得多。 |
| [^182] | [On marginal feature attributions of tree-based models.](http://arxiv.org/abs/2302.08434) | 该论文讨论了基于树模型的边际特征归因方法，与流行的TreeSHAP算法相比，边际Shapley值在相同函数的情况下保持一致，并且介绍了如何利用树模型的内部结构计算边际特征归因。 |
| [^183] | [Beyond Ensemble Averages: Leveraging Climate Model Ensembles for Subseasonal Forecasting.](http://arxiv.org/abs/2211.15856) | 本文研究了利用气候模型集合进行地表季节性预测的应用，超越了传统的平均方法，利用集合预测中的信息提高了预测准确性，关注了极端事件的预测，同时考虑了空间变化的预测集合。 |
| [^184] | [A Survey on Quantum Reinforcement Learning.](http://arxiv.org/abs/2211.03464) | 本文综述了量子强化学习的最新进展和相关文献，重点介绍了基于噪声中等规模量子设备的变分量子电路在经典强化学习中的应用，以及基于未来容错硬件的量子强化学习算法，其中一些具有可证明的量子优势。 |
| [^185] | [Dual control variate for faster black-box variational inference.](http://arxiv.org/abs/2210.07290) | 本论文提出了双控制变量方法，能够同时减少数据子抽样和蒙特卡罗抽样带来的梯度估计方差，提高黑盒变分推断的准确性和效率。 |
| [^186] | [Persistent Homological State-Space Estimation of Functional Human Brain Networks at Rest.](http://arxiv.org/abs/2201.00087) | 该论文提出了一种新的数据驱动的拓扑数据分析方法，用于估计静息状态下人类脑网络的状态空间。该方法通过惩罚网络之间的拓扑距离将动态变化的脑网络聚类为不同的状态，并通过考虑时间维度来提高准确性。研究还发现脑网络的整体拓扑具有遗传特征。 |

# 详细

[^1]: 在训练集上搜索学习率和权重衰减：无需验证的调参方法

    Tune without Validation: Searching for Learning Rate and Weight Decay on Training Sets

    [https://arxiv.org/abs/2403.05532](https://arxiv.org/abs/2403.05532)

    提出了一种名为Tune without Validation (Twin)的方法，在没有验证集的情况下通过学习率和权重衰减的调整来预测泛化性能，强调了权重范数与泛化性能预测的强相关性。

    

    我们介绍了一种叫做Tune without Validation (Twin)的方法，用于在没有验证集的情况下调整学习率和权重衰减。我们利用了关于假设空间中学习阶段的最新理论框架，设计了一种启发式方法，可以预测哪些超参数组合会产生更好的泛化性能。Twin根据一个早停/非早停的调度程序对试验进行网格搜索，然后分割出在训练损失方面提供最佳结果的区域。在这些试验中，权重范数与泛化性能的预测强相关。为了评估Twin的有效性，我们在20个图像分类数据集上进行了大量实验，并训练了几个系列的深度网络，包括卷积、Transformer和前馈模型。我们展示了在从头开始训练和微调时正确的超参数选择，重点强调了小样本场景。

    arXiv:2403.05532v1 Announce Type: new  Abstract: We introduce Tune without Validation (Twin), a pipeline for tuning learning rate and weight decay without validation sets. We leverage a recent theoretical framework concerning learning phases in hypothesis space to devise a heuristic that predicts what hyper-parameter (HP) combinations yield better generalization. Twin performs a grid search of trials according to an early-/non-early-stopping scheduler and then segments the region that provides the best results in terms of training loss. Among these trials, the weight norm strongly correlates with predicting generalization. To assess the effectiveness of Twin, we run extensive experiments on 20 image classification datasets and train several families of deep networks, including convolutional, transformer, and feed-forward models. We demonstrate proper HP selection when training from scratch and fine-tuning, emphasizing small-sample scenarios.
    
[^2]: 学习高斯单指数模型的计算复杂性

    The Computational Complexity of Learning Gaussian Single-Index Models

    [https://arxiv.org/abs/2403.05529](https://arxiv.org/abs/2403.05529)

    该论文研究了学习高斯单指数模型的计算复杂性，在高维回归问题中展示了计算有效算法所需的样本复杂度，并表明这种复杂度是充分的。

    

    单指数模型是具有植入结构的高维回归问题，其中标签依赖于通过通用、非线性和潜在非确定性转换的输入的未知一维投影。因此，它们涵盖了广泛的统计推断任务类别，并提供了一个丰富的模板，用于研究高维情况下的统计和计算折衷。尽管恢复隐藏方向的信息论样本复杂度与维度$d$是线性的，但我们表明，在统计查询（SQ）框架和低阶多项式（LDP）框架内，计算高效的算法必须需要$\Omega(d^{k^\star/2})$个样本，其中$k^\star$是我们明确表征的与模型相关的“生成”指数。此外，我们通过建立使用部分迹的匹配上界来证明这个样本复杂度也是充分的。

    arXiv:2403.05529v1 Announce Type: new  Abstract: Single-Index Models are high-dimensional regression problems with planted structure, whereby labels depend on an unknown one-dimensional projection of the input via a generic, non-linear, and potentially non-deterministic transformation. As such, they encompass a broad class of statistical inference tasks, and provide a rich template to study statistical and computational trade-offs in the high-dimensional regime.   While the information-theoretic sample complexity to recover the hidden direction is linear in the dimension $d$, we show that computationally efficient algorithms, both within the Statistical Query (SQ) and the Low-Degree Polynomial (LDP) framework, necessarily require $\Omega(d^{k^\star/2})$ samples, where $k^\star$ is a "generative" exponent associated with the model that we explicitly characterize. Moreover, we show that this sample complexity is also sufficient, by establishing matching upper bounds using a partial-trace
    
[^3]: GEAR: 一种用于几乎无损生成推断大型语言模型的高效KV缓存压缩方案

    GEAR: An Efficient KV Cache Compression Recipefor Near-Lossless Generative Inference of LLM

    [https://arxiv.org/abs/2403.05527](https://arxiv.org/abs/2403.05527)

    GEAR提出了一种高效的KV缓存压缩框架，实现几乎无损的高比率压缩，用于解决大型语言模型推断中因缓存需求增长而导致的记忆绑定问题和性能下降。

    

    关键-值（KV）缓存已成为加快大型语言模型（LLMs）推断生成速度的事实标准。然而，随着序列长度增加而增长的缓存需求已将LLM推断转变为一个记忆绑定问题，显著地限制了系统吞吐量。现有方法依赖于丢弃不重要的标记或均匀量化所有条目。然而，这种方法往往会产生较高的近似误差来表示压缩后的矩阵。自回归解码过程进一步增加了每个步骤的误差，导致模型生成中的重大偏差和性能恶化。为了解决这一挑战，我们提出了GEAR，一种高效的KV缓存压缩框架，实现几乎无损的高压缩比。

    arXiv:2403.05527v1 Announce Type: cross  Abstract: Key-value (KV) caching has become the de-facto to accelerate generation speed for large language models (LLMs) inference. However, the growing cache demand with increasing sequence length has transformed LLM inference to be a memory bound problem, significantly constraining the system throughput. Existing methods rely on dropping unimportant tokens or quantizing all entries uniformly. Such methods, however, often incur high approximation errors to represent the compressed matrices. The autoregressive decoding process further compounds the error of each step, resulting in critical deviation in model generation and deterioration of performance. To tackle this challenge, we propose GEAR, an efficient KV cache compression framework that achieves near-lossless high-ratio compression. GEAR first applies quantization to majority of entries of similar magnitudes to ultra-low precision. It then employs a low rank matrix to approximate the quant
    
[^4]: 多视图对比学习

    Poly-View Contrastive Learning

    [https://arxiv.org/abs/2403.05490](https://arxiv.org/abs/2403.05490)

    本研究提出了多视图对比学习方法，通过新的表示学习目标优化匹配多个相关视图，在ImageNet1k数据集上的实验结果显示，相比于SimCLR模型，多视图对比模型在更少的训练轮数和更小的批大小下表现更优。

    

    对比学习通常会匹配一组不相关的负视图中相关视图的配对。视图可以是生成的（例如通过增强）或被观察到的。本文研究了当存在多于两个相关视图时的匹配，我们称之为多视图任务，并利用信息最大化和充分统计导出了新的表示学习目标。我们表明，在计算资源无限时，应最大化相关视图的数量；而在固定计算预算的情况下，减少独特样本的数量同时增加这些样本的视图数量是有益的。特别地，以256的批大小训练128轮的多视图对比模型在ImageNet1k上表现优于在批大小为4096且进行1024轮训练的SimCLR模型，挑战了对比模型需要大批大小和多次训练轮数的信念。

    arXiv:2403.05490v1 Announce Type: cross  Abstract: Contrastive learning typically matches pairs of related views among a number of unrelated negative views. Views can be generated (e.g. by augmentations) or be observed. We investigate matching when there are more than two related views which we call poly-view tasks, and derive new representation learning objectives using information maximization and sufficient statistics. We show that with unlimited computation, one should maximize the number of related views, and with a fixed compute budget, it is beneficial to decrease the number of unique samples whilst increasing the number of views of those samples. In particular, poly-view contrastive models trained for 128 epochs with batch size 256 outperform SimCLR trained for 1024 epochs at batch size 4096 on ImageNet1k, challenging the belief that contrastive models require large batch sizes and many training epochs.
    
[^5]: 分布感知对数正定编码的算法硬件协同设计，用于高效的DNN推断

    Algorithm-Hardware Co-Design of Distribution-Aware Logarithmic-Posit Encodings for Efficient DNN Inference

    [https://arxiv.org/abs/2403.05465](https://arxiv.org/abs/2403.05465)

    引入了对数正定编码（LP）和LP量化（LPQ）框架，采用基因算法寻找最优的LP参数，设计了统一的混合精度LP加速器（LPA）体系结构，可动态适应DNN参数分布，减少量化和完整精度模型之间的表示性差异。

    

    传统的深度神经网络（DNN）量化方法使用整数、定点或浮点数据类型时，往往难以在低精度下捕捉不同的DNN参数分布，通常需要大量硅开销和密集的量化感知训练。在本研究中，我们引入了对数正定（LP）编码，这是一种受到正定启发的自适应、硬件友好的数据类型，通过参数化LP位域动态适应DNN权重/激活分布。我们还开发了一种基于遗传算法的新颖框架，LP量化（LPQ），用于寻找最优的逐层LP参数，同时通过一种新颖的全局-局部对比目标减少量化和完整精度模型之间的表示性差异。此外，我们设计了一个统一的混合精度LP加速器（LPA）体系结构，包括将LP纳入计算数据通路中的处理单元（PEs）。

    arXiv:2403.05465v1 Announce Type: cross  Abstract: Traditional Deep Neural Network (DNN) quantization methods using integer, fixed-point, or floating-point data types struggle to capture diverse DNN parameter distributions at low precision, and often require large silicon overhead and intensive quantization-aware training. In this study, we introduce Logarithmic Posits (LP), an adaptive, hardware-friendly data type inspired by posits that dynamically adapts to DNN weight/activation distributions by parameterizing LP bit fields. We also develop a novel genetic-algorithm based framework, LP Quantization (LPQ), to find optimal layer-wise LP parameters while reducing representational divergence between quantized and full-precision models through a novel global-local contrastive objective. Additionally, we design a unified mixed-precision LP accelerator (LPA) architecture comprising of processing elements (PEs) incorporating LP in the computational datapath. Our algorithm-hardware co-design
    
[^6]: 用于射电天文学中快速精密成像的R2D2深度神经网络系列范式

    The R2D2 deep neural network series paradigm for fast precision imaging in radio astronomy

    [https://arxiv.org/abs/2403.05452](https://arxiv.org/abs/2403.05452)

    提出一种新颖的深度学习方法R2D2，用于解决射电天文学中高分辨率高动态范围成像的可扩展性挑战。

    

    射电干涉成像需要解决来自大数据量的高分辨率高动态范围逆问题。最近基于优化理论的图像重建技术展示了惊人的成像精度能力，远远超出了CLEAN的能力。这些方法包括由手工设计的正则化算子推动的先进近端算法，如SARA系列，以及由学习正则化去噪器推动的混合插拔（PnP）算法，如AIRI。然而，优化和PnP结构高度迭代，这阻碍了它们处理未来仪器预期的极端数据大小的能力。为解决这一可扩展性挑战，我们引入一种新颖的深度学习方法，命名为“用于高动态范围成像的残差对残差DNN系列”。R2D2的重建被形成为一系列残差图像，这些图像作为深度神经网络的输出，通过迭代估计而得到。

    arXiv:2403.05452v1 Announce Type: cross  Abstract: Radio-interferometric (RI) imaging entails solving high-resolution high-dynamic range inverse problems from large data volumes. Recent image reconstruction techniques grounded in optimization theory have demonstrated remarkable capability for imaging precision, well beyond CLEAN's capability. These range from advanced proximal algorithms propelled by handcrafted regularization operators, such as the SARA family, to hybrid plug-and-play (PnP) algorithms propelled by learned regularization denoisers, such as AIRI. Optimization and PnP structures are however highly iterative, which hinders their ability to handle the extreme data sizes expected from future instruments. To address this scalability challenge, we introduce a novel deep learning approach, dubbed ``Residual-to-Residual DNN series for high-Dynamic range imaging'. R2D2's reconstruction is formed as a series of residual images, iteratively estimated as outputs of Deep Neural Netw
    
[^7]: 一种用于学习漂移离散分布的改进算法

    An Improved Algorithm for Learning Drifting Discrete Distributions

    [https://arxiv.org/abs/2403.05446](https://arxiv.org/abs/2403.05446)

    提出了一种可以在分布漂移情况下学习离散分布的自适应算法，能够解决过去样本数量选择的权衡问题，并利用数据相关的界来表征统计误差。

    

    我们提出了一种新的自适应算法，用于在分布漂移情况下学习离散分布。在这种情况下，我们观察来自一个随时间变化的离散分布的独立样本序列，目标是估计当前分布。由于我们每个时间步只能访问一个样本，一个良好的估计需要谨慎选择要使用的过去样本的数量。为了使用更多样本，我们必须诉诸更早的样本，这会因为分布变化引入的偏差而产生漂移误差。另一方面，如果我们使用较少的过去样本，估计会有较高的方差，导致较大的统计误差。我们提出了一种新颖的自适应算法，可以解决这种权衡，而无需任何漂移的先验知识。与以前的自适应结果不同，我们的算法使用基于数据的界来表征统计误差。

    arXiv:2403.05446v1 Announce Type: new  Abstract: We present a new adaptive algorithm for learning discrete distributions under distribution drift. In this setting, we observe a sequence of independent samples from a discrete distribution that is changing over time, and the goal is to estimate the current distribution. Since we have access to only a single sample for each time step, a good estimation requires a careful choice of the number of past samples to use. To use more samples, we must resort to samples further in the past, and we incur a drift error due to the bias introduced by the change in distribution. On the other hand, if we use a small number of past samples, we incur a large statistical error as the estimation has a high variance. We present a novel adaptive algorithm that can solve this trade-off without any prior knowledge of the drift. Unlike previous adaptive results, our algorithm characterizes the statistical error using data-dependent bounds. This technicality enab
    
[^8]: 基于贝叶斯层次概率的日内电力价格预测

    Bayesian Hierarchical Probabilistic Forecasting of Intraday Electricity Prices

    [https://arxiv.org/abs/2403.05441](https://arxiv.org/abs/2403.05441)

    该研究首次提出了为德国连续日内市场交易的电力价格进行贝叶斯预测，考虑了参数不确定性，并在2022年的电力价格验证中取得了统计显著的改进。

    

    我们首次提出了对德国连续日内市场交易的电力价格进行贝叶斯预测的研究，充分考虑参数不确定性。我们的目标变量是IDFull价格指数，预测以后验预测分布的形式给出。我们使用了2022年极度波动的电力价格进行验证，在之前几乎没有成为预测研究对象。作为基准模型，我们使用了预测创建时的所有可用日内交易来计算IDFull的当前值。根据弱式有效假设，从最后价格信息建立的基准无法显著改善。然而，我们观察到在点度量和概率评分方面存在着统计显著的改进。最后，我们挑战了在电力价格预测中使用LASSO进行特征选择的宣布的黄金标准。

    arXiv:2403.05441v1 Announce Type: cross  Abstract: We present a first study of Bayesian forecasting of electricity prices traded on the German continuous intraday market which fully incorporates parameter uncertainty. Our target variable is the IDFull price index, forecasts are given in terms of posterior predictive distributions. For validation we use the exceedingly volatile electricity prices of 2022, which have hardly been the subject of forecasting studies before. As a benchmark model, we use all available intraday transactions at the time of forecast creation to compute a current value for the IDFull. According to the weak-form efficiency hypothesis, it would not be possible to significantly improve this benchmark built from last price information. We do, however, observe statistically significant improvement in terms of both point measures and probability scores. Finally, we challenge the declared gold standard of using LASSO for feature selection in electricity price forecastin
    
[^9]: 嵌入的余弦相似性真的只是关于相似性吗？

    Is Cosine-Similarity of Embeddings Really About Similarity?

    [https://arxiv.org/abs/2403.05440](https://arxiv.org/abs/2403.05440)

    余弦相似度可以产生任意和无意义的“相似性”，受正则化控制，并讨论了深层模型学习中的影响。

    

    余弦相似度是两个向量之间夹角的余弦，或者等价地说是它们归一化后的点积。一个常见的应用是通过将余弦相似度应用于学习的低维特征嵌入来量化高维对象之间的语义相似性。在实践中，这种方法有时比嵌入向量之间的未归一化点积效果更好，但有时也更差。为了深入了解这一经验观察，我们研究了由正则化线性模型导出的嵌入，其中封闭形式的解决方案有助于分析洞察力。我们在分析上推导出余弦相似性如何产生任意且因此无意义的“相似性”。对于一些线性模型，相似性甚至不是唯一的，而对于其他一些模型，它们受到正则化的隐式控制。我们讨论了线性模型之外的影响：在学习深层模型时，会采用不同正则化的组合。

    arXiv:2403.05440v1 Announce Type: cross  Abstract: Cosine-similarity is the cosine of the angle between two vectors, or equivalently the dot product between their normalizations. A popular application is to quantify semantic similarity between high-dimensional objects by applying cosine-similarity to a learned low-dimensional feature embedding. This can work better but sometimes also worse than the unnormalized dot-product between embedded vectors in practice. To gain insight into this empirical observation, we study embeddings derived from regularized linear models, where closed-form solutions facilitate analytical insights. We derive analytically how cosine-similarity can yield arbitrary and therefore meaningless `similarities.' For some linear models the similarities are not even unique, while for others they are implicitly controlled by the regularization. We discuss implications beyond linear models: a combination of different regularizations are employed when learning deep models
    
[^10]: 考虑非平稳性的多元时间序列预测中的层次变分Transformer

    Considering Nonstationary within Multivariate Time Series with Variational Hierarchical Transformer for Forecasting

    [https://arxiv.org/abs/2403.05406](https://arxiv.org/abs/2403.05406)

    论文提出了一种名为HTV-Trans的Hierarchical Time series Variational Transformer模型，通过结合层次概率生成模块和Transformer，能够有效考虑多元时间序列中的非平稳性和随机特性，从而更好地回复时间依赖关系。

    

    多元时间序列（MTS）的预测长期以来一直是一项重要但具有挑战性的任务。由于跨越长时间步的非平稳问题，先前的研究主要采用平稳化方法来减弱原始系列的非平稳问题，以获得更好的可预测性。然而，现有方法总是采用平稳化的系列，忽略了固有的非平稳性，并且由于缺乏随机性，很难对具有复杂分布的MTS进行建模。为了解决这些问题，我们首先开发了一个强大的层次概率生成模块，考虑了MTS中的非平稳性和随机特性，然后将其与Transformer结合，形成一个名为Hierarchical Time series Variational Transformer（HTV-Trans）的明确定义的变分生成动态模型，将内在的非平稳信息恢复到时间依赖关系中。

    arXiv:2403.05406v1 Announce Type: cross  Abstract: The forecasting of Multivariate Time Series (MTS) has long been an important but challenging task. Due to the non-stationary problem across long-distance time steps, previous studies primarily adopt stationarization method to attenuate the non-stationary problem of the original series for better predictability. However, existing methods always adopt the stationarized series, which ignores the inherent non-stationarity, and has difficulty in modeling MTS with complex distributions due to the lack of stochasticity. To tackle these problems, we first develop a powerful hierarchical probabilistic generative module to consider the non-stationarity and stochastic characteristics within MTS, and then combine it with transformer for a well-defined variational generative dynamic model named Hierarchical Time series Variational Transformer (HTV-Trans), which recovers the intrinsic non-stationary information into temporal dependencies. Being a po
    
[^11]: HistGen：通过本地-全局特征编码和跨模态上下文交互生成组织病理学报告

    HistGen: Histopathology Report Generation via Local-Global Feature Encoding and Cross-modal Context Interaction

    [https://arxiv.org/abs/2403.05396](https://arxiv.org/abs/2403.05396)

    HistGen是一个通过本地-全局特征编码和跨模态上下文交互来生成组织病理学报告的框架，提供了第一个用于评估的基准数据集。

    

    组织病理学在癌症诊断中扮演着黄金标准的角色，临床报告在解释和理解这一过程中至关重要，在指导癌症治疗和患者护理方面起着关键作用。深度学习对组织病理学报告生成的自动化将极大提升临床效率，并减轻病理学家在报告撰写方面的劳动强度和耗时负担。为追求这一进步，作者引入了HistGen，这是一个多实例学习增强的组织病理学报告生成框架，并提供第一个用于评估的基准数据集。HistGen受诊断和报告撰写工作流程的启发，具有两个精心设计的模块，旨在通过对齐整张切片图像（WSIs）和诊断报告，从本地和全局粒度提升报告生成。为实现这一目标，开发了一个本地-全局分层编码器，用于有效地从区域中聚合视觉特征。

    arXiv:2403.05396v1 Announce Type: cross  Abstract: Histopathology serves as the gold standard in cancer diagnosis, with clinical reports being vital in interpreting and understanding this process, guiding cancer treatment and patient care. The automation of histopathology report generation with deep learning stands to significantly enhance clinical efficiency and lessen the labor-intensive, time-consuming burden on pathologists in report writing. In pursuit of this advancement, we introduce HistGen, a multiple instance learning-empowered framework for histopathology report generation together with the first benchmark dataset for evaluation. Inspired by diagnostic and report-writing workflows, HistGen features two delicately designed modules, aiming to boost report generation by aligning whole slide images (WSIs) and diagnostic reports from local and global granularity. To achieve this, a local-global hierarchical encoder is developed for efficient visual feature aggregation from a regi
    
[^12]: 通过梯度下降训练的无监督神经网络在反问题中的恢复保证

    Recovery Guarantees of Unsupervised Neural Networks for Inverse Problems trained with Gradient Descent

    [https://arxiv.org/abs/2403.05395](https://arxiv.org/abs/2403.05395)

    本研究证明了使用梯度下降训练的无监督神经网络在反问题中的恢复保证与使用梯度流时的保证相同。

    

    近年来，先进的机器学习方法，尤其是神经网络，已成为解决反问题的标准工具。然而，这些方法的理论恢复保证仍然稀缺且难以实现。最近，通过适当初始化使用梯度流训练的无监督方法（如Deep Image Prior，DIP）仅在通用损失函数上获得了收敛和恢复保证。本文通过证明，当选择适当的步长/学习率使用梯度下降时，这些保证仍然成立。我们还表明，离散化仅以常数影响两层DIP网络的过参数化界限，因此梯度下降所找到的不同保证也适用于梯度流。

    arXiv:2403.05395v1 Announce Type: new  Abstract: Advanced machine learning methods, and more prominently neural networks, have become standard to solve inverse problems over the last years. However, the theoretical recovery guarantees of such methods are still scarce and difficult to achieve. Only recently did unsupervised methods such as Deep Image Prior (DIP) get equipped with convergence and recovery guarantees for generic loss functions when trained through gradient flow with an appropriate initialization. In this paper, we extend these results by proving that these guarantees hold true when using gradient descent with an appropriately chosen step-size/learning rate. We also show that the discretization only affects the overparametrization bound for a two-layer DIP network by a constant and thus that the different guarantees found for the gradient flow will hold for gradient descent.
    
[^13]: 在批强化学习中，通过切换损失函数来降低成本

    Switching the Loss Reduces the Cost in Batch Reinforcement Learning

    [https://arxiv.org/abs/2403.05385](https://arxiv.org/abs/2403.05385)

    使用对数损失函数来训练适合的Q迭代的批强化学习方法，在实现目标时不产生成本的问题中，其样本数量需求与最优策略的累积成本成比例，能够提供与最优可达成本成比例的“小成本”界限，并在实验中验证在那些最优策略可靠实现目标的问题中，FQI-LOG比使用平方损失训练的FQI使用更少的样本。

    

    我们提出了一种使用对数损失（FQI-LOG）来训练适合的Q迭代的批强化学习（RL）方法。我们展示了使用FQI-LOG学习接近最优策略所需的样本数量与最优策略的累积成本成比例，对于那些通过最优行为实现目标且不产生成本的问题，最优策略的累积成本为零。通过这种方式，我们提供了一种在批RL中证明具有与最优可达成本成比例的“小成本”界限的一般框架。此外，我们从经验上验证，FQI-LOG在那些最优策略可靠地实现目标的问题上使用的样本比使用平方损失训练的FQI要少。

    arXiv:2403.05385v1 Announce Type: new  Abstract: We propose training fitted Q-iteration with log-loss (FQI-LOG) for batch reinforcement learning (RL). We show that the number of samples needed to learn a near-optimal policy with FQI-LOG scales with the accumulated cost of the optimal policy, which is zero in problems where acting optimally achieves the goal and incurs no cost. In doing so, we provide a general framework for proving $\textit{small-cost}$ bounds, i.e. bounds that scale with the optimal achievable cost, in batch RL. Moreover, we empirically verify that FQI-LOG uses fewer samples than FQI trained with squared loss on problems where the optimal policy reliably achieves the goal.
    
[^14]: 探讨基本引理与核回归之间的联系

    Exploring the Links between the Fundamental Lemma and Kernel Regression

    [https://arxiv.org/abs/2403.05368](https://arxiv.org/abs/2403.05368)

    本研究探讨了基本引理的推广和核回归之间的联系，通过非线性扩展和变换，得到了系统轨迹的新核表示方法，展示出了与特定核回归问题的等效性，并研究了潜在核的结构及其对应的系统类别。

    

    Willems等人关于基本引理的推广和变种是最近研究的热门话题。在本研究中，我们探讨并形式化了核回归与已知非线性基本引理扩展之间的联系。通过对Hankel矩阵中的传统线性方程进行变换，我们得到了系统轨迹的另一种隐式核表示，同时保持对激励持久性的要求。我们展示了这种表示等同于特定核回归问题的解。我们探讨了潜在核的可能结构以及它们对应的系统类。

    arXiv:2403.05368v1 Announce Type: cross  Abstract: Generalizations and variations of the fundamental lemma by Willems et al. are an active topic of recent research. In this note, we explore and formalize the links between kernel regression and known nonlinear extensions of the fundamental lemma. Applying a transformation to the usual linear equation in Hankel matrices, we arrive at an alternative implicit kernel representation of the system trajectories while keeping the requirements on persistency of excitation. We show that this representation is equivalent to the solution of a specific kernel regression problem. We explore the possible structures of the underlying kernel as well as the system classes to which they correspond.
    
[^15]: 量化对基于Transformer的文本分类器鲁棒性的影响

    The Impact of Quantization on the Robustness of Transformer-based Text Classifiers

    [https://arxiv.org/abs/2403.05365](https://arxiv.org/abs/2403.05365)

    量化可以显著提高Transformer-based文本分类器在面对对抗攻击时的鲁棒性表现，平均提升了18.68%。

    

    Transformer-based模型在各种自然语言处理领域取得了显著的进展。然而，这些模型在面对对抗性攻击时往往表现出脆弱性。本文探讨了量化对Transformer-based模型鲁棒性的影响。量化通常涉及将高精度实数映射到较低精度的值，旨在减少所涉模型的大小。据我们所知，这项工作是首次将量化应用于NLP模型的鲁棒性。在实验中，我们评估了在文本分类中对BERT和DistilBERT模型应用量化的影响，使用了SST-2、Emotion和MR数据集。我们还评估了这些模型在面对TextFooler、PWWS和PSO对抗性攻击时的表现。我们的研究结果显示，量化显著提高了模型的对抗准确性（平均提升了18.68%）。此外，我们比较了...

    arXiv:2403.05365v1 Announce Type: new  Abstract: Transformer-based models have made remarkable advancements in various NLP areas. Nevertheless, these models often exhibit vulnerabilities when confronted with adversarial attacks. In this paper, we explore the effect of quantization on the robustness of Transformer-based models. Quantization usually involves mapping a high-precision real number to a lower-precision value, aiming at reducing the size of the model at hand. To the best of our knowledge, this work is the first application of quantization on the robustness of NLP models. In our experiments, we evaluate the impact of quantization on BERT and DistilBERT models in text classification using SST-2, Emotion, and MR datasets. We also evaluate the performance of these models against TextFooler, PWWS, and PSO adversarial attacks. Our findings show that quantization significantly improves (by an average of 18.68%) the adversarial accuracy of the models. Furthermore, we compare the effe
    
[^16]: 混合卷积神经网络和长短期记忆以改善从MRI扫描中诊断阿尔茨海默病

    Hybridized Convolutional Neural Networks and Long Short-Term Memory for Improved Alzheimer's Disease Diagnosis from MRI Scans

    [https://arxiv.org/abs/2403.05353](https://arxiv.org/abs/2403.05353)

    本研究提出了一种混合模型，结合了卷积神经网络模型的特征提取能力和长短期记忆模型的检测能力，旨在改善从MRI扫描中诊断阿尔茨海默病的方法。

    

    大脑相关疾病比其他疾病更敏感，因手术程序复杂、成本高以及其他挑战等因素。阿尔茨海默病是一种常见的大脑疾病，导致记忆丧失和脑细胞萎缩。早期检测对为患者提供适当治疗至关重要。然而，使用CT或MRI扫描手动扫描在早期阶段识别阿尔茨海默病具有挑战性。因此，研究人员开始探索利用机器学习和深度学习方法的计算机辅助系统，这包括对数据集进行训练以检测阿尔茨海默病。本研究旨在提出一种结合了CNN模型的特征提取能力和LSTM模型的检测能力的混合模型。本研究在混合模型中应用了称为VGG16的迁移学习来从MRI图像中提取特征。LSTM用于检测特征。

    arXiv:2403.05353v1 Announce Type: cross  Abstract: Brain-related diseases are more sensitive than other diseases due to several factors, including the complexity of surgical procedures, high costs, and other challenges. Alzheimer's disease is a common brain disorder that causes memory loss and the shrinking of brain cells. Early detection is critical for providing proper treatment to patients. However, identifying Alzheimer's at an early stage using manual scanning of CT or MRI scans is challenging. Therefore, researchers have delved into the exploration of computer-aided systems, employing Machine Learning and Deep Learning methodologies, which entail the training of datasets to detect Alzheimer's disease. This study aims to present a hybrid model that combines a CNN model's feature extraction capabilities with an LSTM model's detection capabilities. This study has applied the transfer learning called VGG16 in the hybrid model to extract features from MRI images. The LSTM detects feat
    
[^17]: 在医学中嵌入语义分割的低分辨率输入部署

    Embedded Deployment of Semantic Segmentation in Medicine through Low-Resolution Inputs

    [https://arxiv.org/abs/2403.05340](https://arxiv.org/abs/2403.05340)

    提出一种在医学中嵌入语义分割的低分辨率输入部署架构，在硬件受限的环境中利用较低分辨率输入以减少计算和内存需求，同时保证预测质量。

    

    在现实生活中部署神经网络时，大小和计算开销常常是限制因素。在诸如嵌入式医疗设备这样的环境中，尤其如此。在这些环境中，往往无法负担大型昂贵的硬件，预算也常常很紧张。我们提出的架构充分利用了在硬件受限的环境中，我们往往会避免使用最高可用的输入分辨率以确保更高的吞吐量这一事实。尽管使用较低分辨率的输入会导致计算和内存需求显著减少，但也可能导致预测质量降低。我们的架构通过利用我们仍可以利用高分辨率这一事实来解决这个问题。

    arXiv:2403.05340v1 Announce Type: cross  Abstract: When deploying neural networks in real-life situations, the size and computational effort are often the limiting factors. This is especially true in environments where big, expensive hardware is not affordable, like in embedded medical devices, where budgets are often tight. State-of-the-art proposed multiple different lightweight solutions for such use cases, mostly by changing the base model architecture, not taking the input and output resolution into consideration. In this paper, we propose our architecture that takes advantage of the fact that in hardware-limited environments, we often refrain from using the highest available input resolutions to guarantee a higher throughput. Although using lower-resolution input leads to a significant reduction in computing and memory requirements, it may also incur reduced prediction quality. Our architecture addresses this problem by exploiting the fact that we can still utilize high-resolutio
    
[^18]: 展望避免迟到：解决硬约束旅行商问题

    Looking Ahead to Avoid Being Late: Solving Hard-Constrained Traveling Salesman Problem

    [https://arxiv.org/abs/2403.05318](https://arxiv.org/abs/2403.05318)

    提出一种利用展望信息作为特征改善具有时间窗口的TSP解决方案合法性的新颖学习方法

    

    许多现实世界中的问题可以被定式为具有约束的旅行商问题（TSP）。然而，这些约束通常复杂而且数量众多，使得解决TSP变得具有挑战性。当复杂约束的数量增长时，传统启发式算法花费大量时间以避免不合法结果。基于学习的方法提供了一种软方式来解决TSP问题，同时支持GPU加速以快速生成解决方案。然而，软方法不可避免地导致通过学习算法解决硬约束问题变得困难，而合法性和最优性之间的冲突可能会严重影响解决方案的最优性。为了克服这一问题并对抗硬约束提出了一种新颖的基于学习的方法，该方法利用向前展望信息作为特征来改进具有时间窗口（TSPTW）的TSP解决方案的合法性。

    arXiv:2403.05318v1 Announce Type: new  Abstract: Many real-world problems can be formulated as a constrained Traveling Salesman Problem (TSP). However, the constraints are always complex and numerous, making the TSPs challenging to solve. When the number of complicated constraints grows, it is time-consuming for traditional heuristic algorithms to avoid illegitimate outcomes. Learning-based methods provide an alternative to solve TSPs in a soft manner, which also supports GPU acceleration to generate solutions quickly. Nevertheless, the soft manner inevitably results in difficulty solving hard-constrained problems with learning algorithms, and the conflicts between legality and optimality may substantially affect the optimality of the solution. To overcome this problem and to have an effective solution against hard constraints, we proposed a novel learning-based method that uses looking-ahead information as the feature to improve the legality of TSP with Time Windows (TSPTW) solutions.
    
[^19]: 多模态VAEs中的统一多样性：改进的表示学习

    Unity by Diversity: Improved Representation Learning in Multimodal VAEs

    [https://arxiv.org/abs/2403.05300](https://arxiv.org/abs/2403.05300)

    通过软约束取代硬约束，提出了一种新的专家混合先验，改善了多模态VAEs中的表示学习。

    

    多模态数据的变分自编码器在数据分析的许多任务中表现出潜力，如表示学习、有条件生成和填补。目前的架构要么跨模态共享编码器输出、解码器输入，要么两者都要学习共享表示。这样的架构对模型施加了严格约束。在这项工作中，我们展示了通过用软约束取代这些硬约束可以获得更好的潜在表示。我们提出了一种新的专家混合先验，软性地引导每个模态的潜在表示朝着共享的后验。这种方法导致了优秀的潜在表示，并允许每个编码保留来自其未压缩原始特征更好的信息。通过对多个基准数据集和一个具有挑战性的现实世界神经科学数据集进行的广泛实验，我们展示了改进的学习潜在表示和填补。

    arXiv:2403.05300v1 Announce Type: cross  Abstract: Variational Autoencoders for multimodal data hold promise for many tasks in data analysis, such as representation learning, conditional generation, and imputation. Current architectures either share the encoder output, decoder input, or both across modalities to learn a shared representation. Such architectures impose hard constraints on the model. In this work, we show that a better latent representation can be obtained by replacing these hard constraints with a soft constraint. We propose a new mixture-of-experts prior, softly guiding each modality's latent representation towards a shared aggregate posterior. This approach results in a superior latent representation and allows each encoding to preserve information from its uncompressed original features better. In extensive experiments on multiple benchmark datasets and a challenging real-world neuroscience data set, we show improved learned latent representations and imputation of m
    
[^20]: 利用连续时间理解对角线性网络训练中的动量

    Leveraging Continuous Time to Understand Momentum When Training Diagonal Linear Networks

    [https://arxiv.org/abs/2403.05293](https://arxiv.org/abs/2403.05293)

    研究了动量对梯度下降优化轨迹的影响，通过连续时间方法找到固有量 $\lambda$，对于恢复稀疏解具有帮助。

    

    在这项工作中，我们研究了动量对梯度下降优化轨迹的影响。我们利用连续时间方法分析带有步长 $\gamma$ 和动量参数 $\beta$ 的动量梯度下降，从而找到一个固有量 $\lambda = \frac{ \gamma }{ (1 - \beta)^2 }$，这一量唯一定义了优化路径并提供了一个简单的加速规则。在超参数化回归设置中训练 $2$ 层对角线性网络时，通过一个隐式正则化问题来表征恢复的解。然后证明小的 $\lambda$ 值有助于恢复稀疏解。最后，我们给出了随机动量梯度下降的类似但较弱结果。我们提供支持我们论断的数值实验。

    arXiv:2403.05293v1 Announce Type: new  Abstract: In this work, we investigate the effect of momentum on the optimisation trajectory of gradient descent. We leverage a continuous-time approach in the analysis of momentum gradient descent with step size $\gamma$ and momentum parameter $\beta$ that allows us to identify an intrinsic quantity $\lambda = \frac{ \gamma }{ (1 - \beta)^2 }$ which uniquely defines the optimisation path and provides a simple acceleration rule. When training a $2$-layer diagonal linear network in an overparametrised regression setting, we characterise the recovered solution through an implicit regularisation problem. We then prove that small values of $\lambda$ help to recover sparse solutions. Finally, we give similar but weaker results for stochastic momentum gradient descent. We provide numerical experiments which support our claims.
    
[^21]: 犹豫模糊软$\beta$-覆盖逼近空间的基础命题

    Foundational propositions of hesitant fuzzy soft $\beta$-covering approximation spaces

    [https://arxiv.org/abs/2403.05290](https://arxiv.org/abs/2403.05290)

    本文引入了犹豫模糊软$\beta$-覆盖和犹豫模糊软$\beta$-邻域的概念，研究了它们的属性，并探讨了涉及犹豫模糊软$\beta$-覆盖逼近空间的特定变体。

    

    Soft set theory用作处理不确定信息的数学框架，而犹豫模糊集在涉及不确定性和犹豫的情景中得到广泛应用。犹豫模糊集表现出多样的隶属度，导致它们之间产生各种形式的包含关系。本文介绍了犹豫模糊软$\beta$-覆盖和犹豫模糊软$\beta$-邻域的概念，这些概念是基于犹豫模糊集之间不同形式的包含关系而制定的。随后，研究了几个相关属性。此外，通过结合犹豫模糊粗集引入了犹豫模糊软$\beta$-覆盖的具体变体，接着探讨了涉及犹豫模糊软$\beta$-覆盖逼近空间的属性。

    arXiv:2403.05290v1 Announce Type: new  Abstract: Soft set theory serves as a mathematical framework for handling uncertain information, and hesitant fuzzy sets find extensive application in scenarios involving uncertainty and hesitation. Hesitant fuzzy sets exhibit diverse membership degrees, giving rise to various forms of inclusion relationships among them. This article introduces the notions of hesitant fuzzy soft $\beta$-coverings and hesitant fuzzy soft $\beta$-neighborhoods, which are formulated based on distinct forms of inclusion relationships among hesitancy fuzzy sets. Subsequently, several associated properties are investigated. Additionally, specific variations of hesitant fuzzy soft $\beta$-coverings are introduced by incorporating hesitant fuzzy rough sets, followed by an exploration of properties pertaining to hesitant fuzzy soft $\beta$-covering approximation spaces.
    
[^22]: 深度提示多任务网络用于辱骂语言检测

    Deep Prompt Multi-task Network for Abuse Language Detection

    [https://arxiv.org/abs/2403.05268](https://arxiv.org/abs/2403.05268)

    提出了一种新颖的Deep Prompt Multi-task Network (DPMN)用于滥用语言检测，通过设计深度提示调整和轻提示调整来激发预训练语言模型的一般知识，并利用多任务学习来提高检测度量标准

    

    滥用语言的检测仍然是社交网络广泛使用中存在的一项长期挑战。滥用语言检测任务存在着准确性有限的问题。我们认为现有的检测方法利用了预训练语言模型（PLMs）的微调技术来处理下游任务。因此，这些方法未能激发PLMs的一般知识。为了解决这个问题，我们提出了一种新颖的用于滥用语言检测的深度提示多任务网络（DPMN）。具体而言，DPMN首先尝试为PLMs设计两种形式的深度提示调整和轻提示调整。研究了不同提示长度、调整策略和提示初始化方法对于检测滥用语言的影响。此外，我们提出了基于Bi-LSTM和FFN的任务头，可用作短文本分类器。最终，DPMN利用多任务学习来提高检测度量标准。

    arXiv:2403.05268v1 Announce Type: cross  Abstract: The detection of abusive language remains a long-standing challenge with the extensive use of social networks. The detection task of abusive language suffers from limited accuracy. We argue that the existing detection methods utilize the fine-tuning technique of the pre-trained language models (PLMs) to handle downstream tasks. Hence, these methods fail to stimulate the general knowledge of the PLMs. To address the problem, we propose a novel Deep Prompt Multi-task Network (DPMN) for abuse language detection. Specifically, DPMN first attempts to design two forms of deep prompt tuning and light prompt tuning for the PLMs. The effects of different prompt lengths, tuning strategies, and prompt initialization methods on detecting abusive language are studied. In addition, we propose a Task Head based on Bi-LSTM and FFN, which can be used as a short text classifier. Eventually, DPMN utilizes multi-task learning to improve detection metrics 
    
[^23]: ERBench：基于实体关系的可自动验证的大规模语言模型幻觉基准

    ERBench: An Entity-Relationship based Automatically Verifiable Hallucination Benchmark for Large Language Models

    [https://arxiv.org/abs/2403.05266](https://arxiv.org/abs/2403.05266)

    ERBench是一个基于实体关系的大型语言模型幻觉基准，通过自动转换任何关系数据库并构建可自动验证的问题，以支持复杂性评估和调试

    

    大型语言模型（LLMs）在各种应用中取得了前所未有的性能，然而它们的评估仍然是一个关键问题。现有的幻觉基准要么是静态的，要么缺乏可调整的复杂性进行彻底分析。我们认为利用现有的关系数据库是构建基准的一种有希望的方法，因为它们通过功能依赖关系可以准确描述知识。我们提出了ERBench，可以自动将任何关系数据库转换为基于实体关系（ER）模型的基准。我们的关键想法是使用数据库模式、记录和功能依赖来构建问题，以便可以自动验证。此外，我们使用外键约束来连接关系和构建多跳问题，这些问题可以任意复杂，用于调试LLMs的中间答案。最后，ERBench支持持续评估，多模态qu

    arXiv:2403.05266v1 Announce Type: cross  Abstract: Large language models (LLMs) have achieved unprecedented performance in various applications, yet their evaluation remains a critical issue. Existing hallucination benchmarks are either static or lack adjustable complexity for thorough analysis. We contend that utilizing existing relational databases is a promising approach for constructing benchmarks due to their accurate knowledge description via functional dependencies. We propose ERBench to automatically convert any relational database into a benchmark based on the entity-relationship (ER) model. Our key idea is to construct questions using the database schema, records, and functional dependencies such that they can be automatically verified. In addition, we use foreign key constraints to join relations and construct multihop questions, which can be arbitrarily complex and used to debug the intermediate answers of LLMs. Finally, ERBench supports continuous evaluation, multimodal qu
    
[^24]: DuDoUniNeXt：用于单和多对比度欠采样MRI重建的双域统一混合模型

    DuDoUniNeXt: Dual-domain unified hybrid model for single and multi-contrast undersampled MRI reconstruction

    [https://arxiv.org/abs/2403.05256](https://arxiv.org/abs/2403.05256)

    提出了DuDoUniNeXt，一个统一的双域MRI重建网络，能适应不同质量的参考图像，解决了在缺少或低质量参考图像时性能不佳的问题

    

    多对比度（MC）磁共振成像（MRI）重建旨在将辅助模态的参考图像纳入目标模态的重建过程中。已知的MC重建方法在有完全采样的参考图像时表现良好，但通常在参考图像缺失或质量低下时，与单对比度（SC）方法相比表现较差。为解决这一问题，我们提出了DuDoUniNeXt，一个统一的双域MRI重建网络，可适应涉及缺失、质量低和质量高的参考图像的各种场景。DuDoUniNeXt采用了一个结合了CNN和ViT的混合主干，实现了对图像域和k-空间重建的特定调整。具体来说，设计了一种自适应粗到细特征融合模块（AdaC2F），动态处理不同质量参考图像的信息。此外，还有一个部分共享的浅层特征

    arXiv:2403.05256v1 Announce Type: cross  Abstract: Multi-contrast (MC) Magnetic Resonance Imaging (MRI) reconstruction aims to incorporate a reference image of auxiliary modality to guide the reconstruction process of the target modality. Known MC reconstruction methods perform well with a fully sampled reference image, but usually exhibit inferior performance, compared to single-contrast (SC) methods, when the reference image is missing or of low quality. To address this issue, we propose DuDoUniNeXt, a unified dual-domain MRI reconstruction network that can accommodate to scenarios involving absent, low-quality, and high-quality reference images. DuDoUniNeXt adopts a hybrid backbone that combines CNN and ViT, enabling specific adjustment of image domain and k-space reconstruction. Specifically, an adaptive coarse-to-fine feature fusion module (AdaC2F) is devised to dynamically process the information from reference images of varying qualities. Besides, a partially shared shallow feat
    
[^25]: 用具有符号等变性的神经网络表示电子波函数

    On Representing Electronic Wave Functions with Sign Equivariant Neural Networks

    [https://arxiv.org/abs/2403.05249](https://arxiv.org/abs/2403.05249)

    使用符号等变性神经网络的新方法未能提供优于传统方法的波函数近似精度。

    

    近期的神经网络展示了对电子基态波函数的令人印象深刻准确逼近。这些神经网络通常由一个置换等变性神经网络和一个置换反对称操作组成，以强制执行电子交换对称性。虽然精确，这些神经网络计算成本很高。在这项工作中，我们探索了一种翻转的方法，首先基于电子坐标计算反对称量，然后应用具有符号等变性的神经网络来保留反对称性。虽然这种方法承诺由于较低维表示而加速，但我们证明它化简为Jastrow因子，即波函数中常用的置换不变乘法因子。我们的实证结果进一步支持这一点，发现与基线相比几乎没有改进。最后，我们得出既无理论优势也无经验优势的结论。

    arXiv:2403.05249v1 Announce Type: cross  Abstract: Recent neural networks demonstrated impressively accurate approximations of electronic ground-state wave functions. Such neural networks typically consist of a permutation-equivariant neural network followed by a permutation-antisymmetric operation to enforce the electronic exchange symmetry. While accurate, such neural networks are computationally expensive. In this work, we explore the flipped approach, where we first compute antisymmetric quantities based on the electronic coordinates and then apply sign equivariant neural networks to preserve the antisymmetry. While this approach promises acceleration thanks to the lower-dimensional representation, we demonstrate that it reduces to a Jastrow factor, a commonly used permutation-invariant multiplicative factor in the wave function. Our empirical results support this further, finding little to no improvements over baselines. We conclude with neither theoretical nor empirical advantage
    
[^26]: 面向基于扩散模型的文本人体图像生成中人性先验有效利用

    Towards Effective Usage of Human-Centric Priors in Diffusion Models for Text-based Human Image Generation

    [https://arxiv.org/abs/2403.05239](https://arxiv.org/abs/2403.05239)

    本文提出了一种新方法，通过将人性先验直接融入模型微调阶段，强化文本提示中的人体相关信息，并引入规模感知和逐步约束，从而有效提升了基于扩散模型的文本人体图像生成质量

    

    Vanilla文本到图像的扩散模型在生成准确的人体图像方面存在困难，通常导致不完美的解剖结构，如不自然的姿势或肢体不成比例。现有方法主要通过对模型进行微调，使用额外图像或添加额外控制（如姿势或深度图）来解决这个问题，这些控制主要在图像生成阶段引入人性先验。本文探讨将这些人性先验直接集成到模型微调阶段，从而在推理阶段消除额外条件的可能性。我们通过提出人性对齐损失来实现这一想法，从文本提示中强化人体相关信息，并在扩散过程中引入具有规模感知和逐步约束的因素，以确保在微调过程中的语义细节丰富性和人体结构准确性。

    arXiv:2403.05239v1 Announce Type: cross  Abstract: Vanilla text-to-image diffusion models struggle with generating accurate human images, commonly resulting in imperfect anatomies such as unnatural postures or disproportionate limbs.Existing methods address this issue mostly by fine-tuning the model with extra images or adding additional controls -- human-centric priors such as pose or depth maps -- during the image generation phase. This paper explores the integration of these human-centric priors directly into the model fine-tuning stage, essentially eliminating the need for extra conditions at the inference stage. We realize this idea by proposing a human-centric alignment loss to strengthen human-related information from the textual prompts within the cross-attention maps. To ensure semantic detail richness and human structural accuracy during fine-tuning, we introduce scale-aware and step-wise constraints within the diffusion process, according to an in-depth analysis of the cross
    
[^27]: 用于医疗保健领域可信机器学习的公平感知可解释建模（FAIM）

    Fairness-Aware Interpretable Modeling (FAIM) for Trustworthy Machine Learning in Healthcare

    [https://arxiv.org/abs/2403.05235](https://arxiv.org/abs/2403.05235)

    FAIM是一个用于提高医疗保健领域机器学习公平性的可解释框架，通过交互界面识别最公平模型，并结合数据驱动证据与临床专家知识，成功减少了性别和种族偏见。

    

    在高风险领域如医疗保健中机器学习不断融入的情况下，对模型公平性提出了重要关切。我们提出了一个可解释框架 - 公平感知可解释建模（FAIM），旨在提高模型的公平性而不影响性能，其特点是一个交互界面，可以从一组高性能模型中识别出一个“更公平”的模型，并促进数据驱动证据与临床专家知识的整合，以增强情境公平性。我们通过在两个真实世界数据库MIMIC-IV-ED和SGH-ED上预测医院入院情况，展示了FAIM在减少性别和种族偏见方面的价值。我们展示了对于这两个数据集，FAIM模型不仅展现了令人满意的歧视性能，而且通过已建立的公平性度量明显减轻了偏见，优于常用的偏见缓解方法。

    arXiv:2403.05235v1 Announce Type: cross  Abstract: The escalating integration of machine learning in high-stakes fields such as healthcare raises substantial concerns about model fairness. We propose an interpretable framework - Fairness-Aware Interpretable Modeling (FAIM), to improve model fairness without compromising performance, featuring an interactive interface to identify a "fairer" model from a set of high-performing models and promoting the integration of data-driven evidence and clinical expertise to enhance contextualized fairness. We demonstrated FAIM's value in reducing sex and race biases by predicting hospital admission with two real-world databases, MIMIC-IV-ED and SGH-ED. We show that for both datasets, FAIM models not only exhibited satisfactory discriminatory performance but also significantly mitigated biases as measured by well-established fairness metrics, outperforming commonly used bias-mitigation methods. Our approach demonstrates the feasibility of improving f
    
[^28]: 合成特权信息增强医学图像表示学习

    Synthetic Privileged Information Enhances Medical Image Representation Learning

    [https://arxiv.org/abs/2403.05220](https://arxiv.org/abs/2403.05220)

    合成生成的配对信息显著改善了医学图像表示学习，相比于单模态训练或真实多模态配对数据集，误差减小分别达到4.4倍和5.6倍

    

    多模态自监督表示学习一直被证明是医学图像分析中一种非常有效的方法，提供了强大的任务性能并产生了生物学相关的见解。然而，这些方法严重依赖于大规模配对数据集，这在不存在配对数据或只有少量可用的情况下是不切实际的。相比之下，图像生成方法可以在非常小的数据集上很好地工作，并且可以找到未配对数据集之间的映射，这意味着可以生成有效无限量的配对合成数据。在这项工作中，我们展示了通过合成生成配对信息可以显著改善表示学习，与单模态训练（误差减小达到4.4倍）或真实多模态配对数据集进行训练（误差减小达到5.6倍）相比。

    arXiv:2403.05220v1 Announce Type: cross  Abstract: Multimodal self-supervised representation learning has consistently proven to be a highly effective method in medical image analysis, offering strong task performance and producing biologically informed insights. However, these methods heavily rely on large, paired datasets, which is prohibitive for their use in scenarios where paired data does not exist, or there is only a small amount available. In contrast, image generation methods can work well on very small datasets, and can find mappings between unpaired datasets, meaning an effectively unlimited amount of paired synthetic data can be generated. In this work, we demonstrate that representation learning can be significantly improved by synthetically generating paired information, both compared to training on either single-modality (up to 4.4x error reduction) or authentic multi-modal paired datasets (up to 5.6x error reduction).
    
[^29]: 克服跨领域数据不平等问题的半监督领域泛化

    Overcoming Data Inequality across Domains with Semi-Supervised Domain Generalization

    [https://arxiv.org/abs/2403.05209](https://arxiv.org/abs/2403.05209)

    本文提出了一种名为ProUD的新算法，通过领域感知原型和通过不确定性自适应混合标记和未标记领域的渐进泛化，有效解决了跨领域数据不平等问题中的半监督领域泛化挑战。

    

    虽然机器学习取得了巨大的进展，但在各个来源和人群之间仍然存在数据可用性的显著差异。在不同领域之间的这种不平等在为数据有限的人建模时带来挑战，这可能会引起深刻的实际和伦理关注。本文针对跨领域数据不平等问题提出了一个代表性案例，即半监督领域泛化（SSDG），其中只有一个领域被标记，而其他领域没有标签。我们提出了一种新算法，ProUD，通过领域感知原型和通过不确定性自适应混合标记和未标记领域的渐进泛化，可以有效学习领域不变特征。我们在三个不同的基准数据集上的实验证明了ProUD的有效性，优于包括单一领域泛化在内的所有基线模型。

    arXiv:2403.05209v1 Announce Type: cross  Abstract: While there have been considerable advancements in machine learning driven by extensive datasets, a significant disparity still persists in the availability of data across various sources and populations. This inequality across domains poses challenges in modeling for those with limited data, which can lead to profound practical and ethical concerns. In this paper, we address a representative case of data inequality problem across domains termed Semi-Supervised Domain Generalization (SSDG), in which only one domain is labeled while the rest are unlabeled. We propose a novel algorithm, ProUD, which can effectively learn domain-invariant features via domain-aware prototypes along with progressive generalization via uncertainty-adaptive mixing of labeled and unlabeled domains. Our experiments on three different benchmark datasets demonstrate the effectiveness of ProUD, outperforming all baseline models including single domain generalizati
    
[^30]: 降噪自回归表示学习

    Denoising Autoregressive Representation Learning

    [https://arxiv.org/abs/2403.05196](https://arxiv.org/abs/2403.05196)

    DARL使用仅解码器的Transformer进行自回归预测，通过使用去噪补丁解码器和特定噪声计划改善图像生成能力，实现了与蒙版预测模型相近的性能。

    

    在本文中，我们探索了一种用于学习视觉表示的新的生成方法。我们的方法DARL采用了仅解码器的Transformer来自回归地预测图像补丁。我们发现仅使用均方误差（MSE）进行训练会得到强大的表示。为了增强图像生成能力，我们使用去噪补丁解码器将MSE损失替换为扩散目标。我们展示了通过使用量身定制的噪声计划和更大模型的更长训练可以改善学习到的表示。值得注意的是，最佳计划与标准图像扩散模型中常用的计划有显著差异。总体而言，尽管其简单的架构，DARL在微调协议下的性能接近最先进的蒙版预测模型。这标志着向能够同时进行视觉感知和生成的统一模型迈出了重要的一步，有效地结合了其优势。

    arXiv:2403.05196v1 Announce Type: new  Abstract: In this paper, we explore a new generative approach for learning visual representations. Our method, DARL, employs a decoder-only Transformer to predict image patches autoregressively. We find that training with Mean Squared Error (MSE) alone leads to strong representations. To enhance the image generation ability, we replace the MSE loss with the diffusion objective by using a denoising patch decoder. We show that the learned representation can be improved by using tailored noise schedules and longer training in larger models. Notably, the optimal schedule differs significantly from the typical ones used in standard image diffusion models. Overall, despite its simple architecture, DARL delivers performance remarkably close to state-of-the-art masked prediction models under the fine-tuning protocol. This marks an important step towards a unified model capable of both visual perception and generation, effectively combining the strengths o
    
[^31]: 通过图神经网络在Spotify上进行个性化有声读物推荐

    Personalized Audiobook Recommendations at Spotify Through Graph Neural Networks

    [https://arxiv.org/abs/2403.05185](https://arxiv.org/abs/2403.05185)

    通过引入双塔模型和异质图神经网络，该研究提出了一个可扩展的推荐系统，以应对Spotify在引入有声读物后面临的个性化推荐挑战。

    

    在不断发展的数字音频领域中，以其音乐和谈话内容而闻名的Spotify最近向其庞大用户群引入了有声读物。尽管前景看好，但这一举措为个性化推荐带来了重大挑战。与音乐和播客不同，最初需要付费的有声读物在购买前无法轻松略读，这增加了推荐的相关性的挑战。此外，将新内容类型引入现有平台导致数据极度稀疏，因为大多数用户对这种新内容类型不熟悉。最后，向数百万用户推荐内容要求模型反应迅速且可扩展性强。为了解决这些挑战，我们利用播客和音乐用户喜好，引入了2T-HGNN，这是一个由异质图神经网络（HGNNs）和双塔（2T）模型组成的可扩展推荐系统。这一新颖方法揭示了项目之间微妙的关系。

    arXiv:2403.05185v1 Announce Type: cross  Abstract: In the ever-evolving digital audio landscape, Spotify, well-known for its music and talk content, has recently introduced audiobooks to its vast user base. While promising, this move presents significant challenges for personalized recommendations. Unlike music and podcasts, audiobooks, initially available for a fee, cannot be easily skimmed before purchase, posing higher stakes for the relevance of recommendations. Furthermore, introducing a new content type into an existing platform confronts extreme data sparsity, as most users are unfamiliar with this new content type. Lastly, recommending content to millions of users requires the model to react fast and be scalable. To address these challenges, we leverage podcast and music user preferences and introduce 2T-HGNN, a scalable recommendation system comprising Heterogeneous Graph Neural Networks (HGNNs) and a Two Tower (2T) model. This novel approach uncovers nuanced item relationship
    
[^32]: Adversarial Sparse Teacher: 对抗敌对示例，防御用对抗示例进行的基于蒸馏的模型窃取攻击

    Adversarial Sparse Teacher: Defense Against Distillation-Based Model Stealing Attacks Using Adversarial Examples

    [https://arxiv.org/abs/2403.05181](https://arxiv.org/abs/2403.05181)

    本文提出了一种训练教师模型的方法，通过引入敌对示例的稀疏输出，并与标准训练数据结合使用，来加强教师模型对学生蒸馏的防御。

    

    知识蒸馏（KD）促进了将高级教师模型的区分能力转移到更简单的学生模型，确保提高性能而不影响准确性。它也被用于模型窃取攻击，其中对手使用KD来模仿教师模型的功能。最近在该领域的发展受到了吝啬教师模型的影响，该模型通过实证分析表明稀疏输出可以显著降低学生模型的性能。为了解决知识产权泄露的风险，我们的工作引入了一种训练教师模型的方法，该方法从根本上保护其logits，受“恶毒教师”理念的影响。与现有方法不同，我们将对抗示例的稀疏输出与标准训练数据结合起来，以加强教师对学生蒸馏的防御。我们的方法巧妙地减少了相对的e

    arXiv:2403.05181v1 Announce Type: new  Abstract: Knowledge Distillation (KD) facilitates the transfer of discriminative capabilities from an advanced teacher model to a simpler student model, ensuring performance enhancement without compromising accuracy. It is also exploited for model stealing attacks, where adversaries use KD to mimic the functionality of a teacher model. Recent developments in this domain have been influenced by the Stingy Teacher model, which provided empirical analysis showing that sparse outputs can significantly degrade the performance of student models. Addressing the risk of intellectual property leakage, our work introduces an approach to train a teacher model that inherently protects its logits, influenced by the Nasty Teacher concept. Differing from existing methods, we incorporate sparse outputs of adversarial examples with standard training data to strengthen the teacher's defense against student distillation. Our approach carefully reduces the relative e
    
[^33]: 持续学习与灾难性遗忘

    Continual Learning and Catastrophic Forgetting

    [https://arxiv.org/abs/2403.05175](https://arxiv.org/abs/2403.05175)

    人工神经网络在持续学习过程中容易出现灾难性遗忘，这一问题是深度学习中持续学习领域的关键挑战。

    

    本书章节探讨了持续学习的动态过程，即从非静态数据流中逐步学习的过程。尽管持续学习是人脑的一种自然技能，但对于人工神经网络来说却是非常具有挑战性的。一个重要原因是在学习新知识时，这些网络往往会迅速而彻底地忘记以前所学的内容，这一现象被称为灾难性遗忘。在过去的十年中，持续学习已成为深度学习中一个被广泛研究的课题。本书章节回顾了这一领域产生的见解。

    arXiv:2403.05175v1 Announce Type: cross  Abstract: This book chapter delves into the dynamics of continual learning, which is the process of incrementally learning from a non-stationary stream of data. Although continual learning is a natural skill for the human brain, it is very challenging for artificial neural networks. An important reason is that, when learning something new, these networks tend to quickly and drastically forget what they had learned before, a phenomenon known as catastrophic forgetting. Especially in the last decade, continual learning has become an extensively studied topic in deep learning. This book chapter reviews the insights that this field has generated.
    
[^34]: VTruST：基于可控价值函数的数据中心信赖AI的子集选择

    VTruST: Controllable value function based subset selection for Data-Centric Trustworthy AI

    [https://arxiv.org/abs/2403.05174](https://arxiv.org/abs/2403.05174)

    提出了一个可控的数据中心可信AI（DCTAI）框架 VTruST，允许用户控制不同可信度指标之间的权衡，设计了基于在线价值函数的训练数据子集选择算法，通过在线稀疏逼近形式的训练数据估值和子集选择问题，提出了一个新的在线正交匹配追踪（OMP）算法，实验证明VTruST在社交、图像和科学数据集上优于最先进的基线。

    

    可信AI对于AI在高风险应用中的广泛应用至关重要，公平性、稳健性和准确性是一些关键的可信度指标。在这项工作中，我们提出了一个可控的数据中心可信AI（DCTAI）框架 - VTruST，允许用户控制所构建训练数据集的不同可信度指标之间的权衡。实施高效的DCTAI框架的关键挑战是设计基于在线价值函数的训练数据子集选择算法。我们将训练数据估值和子集选择问题作为在线稀疏逼近形式提出。我们提出了一种新颖的用于解决这一问题的在线正交匹配追踪（OMP）算法。实验证明，VTruST在社交、图像和科学数据集上优于最先进的基线。我们还展示了VTruST生成的数据值可以用于...

    arXiv:2403.05174v1 Announce Type: new  Abstract: Trustworthy AI is crucial to the widespread adoption of AI in high-stakes applications with fairness, robustness, and accuracy being some of the key trustworthiness metrics. In this work, we propose a controllable framework for data-centric trustworthy AI (DCTAI)- VTruST, that allows users to control the trade-offs between the different trustworthiness metrics of the constructed training datasets. A key challenge in implementing an efficient DCTAI framework is to design an online value-function-based training data subset selection algorithm. We pose the training data valuation and subset selection problem as an online sparse approximation formulation. We propose a novel online version of the Orthogonal Matching Pursuit (OMP) algorithm for solving this problem. Experimental results show that VTruST outperforms the state-of-the-art baselines on social, image, and scientific datasets. We also show that the data values generated by VTruST ca
    
[^35]: 通过轻量级不确定性估计对抗策略优化克服了奖励过度优化问题

    Overcoming Reward Overoptimization via Adversarial Policy Optimization with Lightweight Uncertainty Estimation

    [https://arxiv.org/abs/2403.05171](https://arxiv.org/abs/2403.05171)

    本论文提出了对抗策略优化（AdvPO）来解决强化学习领域中奖励过度优化的问题，通过量化奖励的不确定性，并围绕奖励模型预测的置信区间进行分布鲁棒的优化，从而有效缓解了该问题。

    

    我们引入了对抗策略优化（AdvPO），这是一种新颖的解决方案，用于解决强化学习从人类反馈中的奖励过度优化问题，适用于大型语言模型（LLMs）。AdvPO围绕奖励模型预测的置信区间解决了一个分布鲁棒的优化问题，以改进策略。通过对Anthropic HH和TL;DR摘要数据集进行全面实验，我们展示了AdvPO在减轻过度优化问题方面的有效性。

    arXiv:2403.05171v1 Announce Type: cross  Abstract: We introduce Adversarial Policy Optimization (AdvPO), a novel solution to the pervasive issue of reward over-optimization in Reinforcement Learning from Human Feedback (RLHF) for Large Language Models (LLMs). Over-optimization occurs when a reward model serves as an imperfect proxy for human preference, and RL-driven policy optimization erroneously exploits reward inaccuracies. In this paper, we begin by introducing a lightweight way to quantify uncertainties in rewards, relying solely on the last layer embeddings of the reward model, without the need for computationally expensive reward ensembles. AdvPO then addresses a distributionally robust optimization problem centred around the confidence interval of the reward model's predictions for policy improvement. Through comprehensive experiments on the Anthropic HH and TL;DR summarization datasets, we illustrate the efficacy of AdvPO in mitigating the overoptimization issue, consequently
    
[^36]: 合成数据生成用于系统辨识：利用类似系统的知识转移

    Synthetic data generation for system identification: leveraging knowledge transfer from similar systems

    [https://arxiv.org/abs/2403.05164](https://arxiv.org/abs/2403.05164)

    本文提出了一种从类似系统中进行知识转移的新方法，用于生成合成数据，以改善模型的泛化能力和鲁棒性。

    

    本文针对学习动态系统中过拟合的挑战，引入了一种新颖的合成数据生成方法，旨在增强模型的泛化能力和鲁棒性，特别是在数据稀缺情况下。所提出的方法的核心是从同一类系统中进行知识转移的概念。具体而言，通过一个预训练的元模型生成合成数据，该元模型描述了假定所关注的系统所属的一类系统。训练数据具有两个目的：首先，作为预训练的元模型的输入，用以辨别系统的动态，从而能够预测其行为，从而生成新输入序列的合成输出序列；其次，与合成数据一起，用于定义用于模型估计的损失函数。验证数据集用于调整一个标量超参数，平衡关系

    arXiv:2403.05164v1 Announce Type: cross  Abstract: This paper addresses the challenge of overfitting in the learning of dynamical systems by introducing a novel approach for the generation of synthetic data, aimed at enhancing model generalization and robustness in scenarios characterized by data scarcity. Central to the proposed methodology is the concept of knowledge transfer from systems within the same class. Specifically, synthetic data is generated through a pre-trained meta-model that describes a broad class of systems to which the system of interest is assumed to belong. Training data serves a dual purpose: firstly, as input to the pre-trained meta model to discern the system's dynamics, enabling the prediction of its behavior and thereby generating synthetic output sequences for new input sequences; secondly, in conjunction with synthetic data, to define the loss function used for model estimation. A validation dataset is used to tune a scalar hyper-parameter balancing the rel
    
[^37]: 能量受限的无线边缘网络中的自适应分裂学习

    Adaptive Split Learning over Energy-Constrained Wireless Edge Networks

    [https://arxiv.org/abs/2403.05158](https://arxiv.org/abs/2403.05158)

    设计了一种在无线边缘网络中为设备动态选择分裂点并为服务器分配计算资源的自适应分裂学习方案，以最小化平均训练延迟为目标，并提出了一种名为OPEN的在线算法解决此问题。

    

    分裂学习（SL）是一种有希望的用于训练人工智能（AI）模型的方法，其中设备与服务器合作以分布式方式训练AI模型，基于相同的固定分裂点。然而，由于设备的异构性和信道条件的变化，这种方式在训练延迟和能量消耗方面并不是最优的。在本文中，我们设计了一种自适应分裂学习（ASL）方案，可以在无线边缘网络中为设备动态选择分裂点，并为服务器分配计算资源。我们制定了一个优化问题，旨在在满足长期能量消耗约束的情况下最小化平均训练延迟。解决这个问题的困难在于缺乏未来信息和混合整数规划（MIP）。为了解决这个问题，我们提出了一种利用Lyapunov理论的在线算法，名为OPEN，它将其分解为一个具有当前的新MIP问题。

    arXiv:2403.05158v1 Announce Type: cross  Abstract: Split learning (SL) is a promising approach for training artificial intelligence (AI) models, in which devices collaborate with a server to train an AI model in a distributed manner, based on a same fixed split point. However, due to the device heterogeneity and variation of channel conditions, this way is not optimal in training delay and energy consumption. In this paper, we design an adaptive split learning (ASL) scheme which can dynamically select split points for devices and allocate computing resource for the server in wireless edge networks. We formulate an optimization problem to minimize the average training latency subject to long-term energy consumption constraint. The difficulties in solving this problem are the lack of future information and mixed integer programming (MIP). To solve it, we propose an online algorithm leveraging the Lyapunov theory, named OPEN, which decomposes it into a new MIP problem only with the curren
    
[^38]: 基于贪婪方法的分类器相关特征选择: 贪婪特征选择方法介绍

    Greedy feature selection: Classifier-dependent feature selection via greedy methods

    [https://arxiv.org/abs/2403.05138](https://arxiv.org/abs/2403.05138)

    提出了一种新的基于分类器的特征选择方法，通过贪婪方式在每一步识别最重要的特征，从而在理论和实际应用中得出有效性。

    

    这项研究旨在介绍一种新的特征排名方法，即贪婪特征选择，用于分类任务。在统计学习中，通常通过与应用于利用减少数量特征进行预测的分类器无关的方法来实现特征选择。相反，贪婪特征选择根据选定的分类器在每一步识别最重要的特征。 在本文中，从理论上探讨了这种方案的优点，如Vapnik-Chervonenkis（VC）维度或核对齐等模型能力指标，并通过考虑将其应用于预测太阳活动的地质效应表现问题的方法进行了数值测试。

    arXiv:2403.05138v1 Announce Type: cross  Abstract: The purpose of this study is to introduce a new approach to feature ranking for classification tasks, called in what follows greedy feature selection. In statistical learning, feature selection is usually realized by means of methods that are independent of the classifier applied to perform the prediction using that reduced number of features. Instead, greedy feature selection identifies the most important feature at each step and according to the selected classifier. In the paper, the benefits of such scheme are investigated theoretically in terms of model capacity indicators, such as the Vapnik-Chervonenkis (VC) dimension or the kernel alignment, and tested numerically by considering its application to the problem of predicting geo-effective manifestations of the active Sun.
    
[^39]: 带有弗歇泰尔分布的扰动领导者追踪：在对抗性赌博机和最佳选择中的最优性

    Follow-the-Perturbed-Leader with Fr\'{e}chet-type Tail Distributions: Optimality in Adversarial Bandits and Best-of-Both-Worlds

    [https://arxiv.org/abs/2403.05134](https://arxiv.org/abs/2403.05134)

    研究指出在对抗性和随机赌博机中，基于随机扰动的Follow-the-Perturbed-Leader策略具有弗歇泰尔分布尾部最优性，实现了最佳选择的能力。

    

    本文研究了在对抗性和随机$K$臂老虎机中Follow-the-Perturbed-Leader（FTPL）策略的最优性。尽管Follow-the-Regularized-Leader（FTRL）框架在各种正则化选择下被广泛使用，但依赖于随机扰动的FTPL框架却鲜有关注，尽管其固有的简单性。在对抗性赌博机中，FTPL若扰动遵循具有弗歇泰尔尾部的分布，有人猜想可能可以实现$\mathcal{O}(\sqrt{KT})$的后悔。本文通过对形状$\alpha=2$的Fr\'{e}chet分布进行了研究，证明了FTPL确实达到了这一界限，并且在随机赌博机中具有显著的对数后悔，意味着FTPL具备了最佳选择（BOBW）的能力。然而，这一结果只在一定程度上解决了上述猜想，因为他们的分析严重依赖于Fr\'{e

    arXiv:2403.05134v1 Announce Type: cross  Abstract: This paper studies the optimality of the Follow-the-Perturbed-Leader (FTPL) policy in both adversarial and stochastic $K$-armed bandits. Despite the widespread use of the Follow-the-Regularized-Leader (FTRL) framework with various choices of regularization, the FTPL framework, which relies on random perturbations, has not received much attention, despite its inherent simplicity. In adversarial bandits, there has been conjecture that FTPL could potentially achieve $\mathcal{O}(\sqrt{KT})$ regrets if perturbations follow a distribution with a Fr\'{e}chet-type tail. Recent work by Honda et al. (2023) showed that FTPL with Fr\'{e}chet distribution with shape $\alpha=2$ indeed attains this bound and, notably logarithmic regret in stochastic bandits, meaning the Best-of-Both-Worlds (BOBW) capability of FTPL. However, this result only partly resolves the above conjecture because their analysis heavily relies on the specific form of the Fr\'{e
    
[^40]: 基于RIS的城市空中移动中的分布式学习拓扑控制

    RIS-empowered Topology Control for Distributed Learning in Urban Air Mobility

    [https://arxiv.org/abs/2403.05133](https://arxiv.org/abs/2403.05133)

    本文研究了如何利用可重构智能表面（RIS）解决城市空中移动中分布式学习的拓扑控制问题，以克服有限传感器和计算资源对智能感知需求的挑战。

    

    城市空中移动（UAM）将车辆从地面扩展到近地空间，被构想为交通系统的革命。全面的场景感知是无人机驾驶的基础。然而，UAM面临智能感知挑战：高感知学习需求与飞行汽车的有限传感器和计算芯片相冲突。为了克服这一挑战，已经提出了联邦学习（FL）等协作学习方法，使资源受限的设备能够共同进行机载深度学习（DL）。但像FL这样的传统协作学习依赖于用于DL模型聚合的中央集成器，这在动态环境中很难部署。完全去中心化的学习方案可能是直观的解决方案，但分布式学习的收敛无法保证。因此，本文探讨了可重构智能表面（RIS）

    arXiv:2403.05133v1 Announce Type: cross  Abstract: Urban Air Mobility (UAM) expands vehicles from the ground to the near-ground space, envisioned as a revolution for transportation systems. Comprehensive scene perception is the foundation for autonomous aerial driving. However, UAM encounters the intelligent perception challenge: high perception learning requirements conflict with the limited sensors and computing chips of flying cars. To overcome the challenge, federated learning (FL) and other collaborative learning have been proposed to enable resource-limited devices to conduct onboard deep learning (DL) collaboratively. But traditional collaborative learning like FL relies on a central integrator for DL model aggregation, which is difficult to deploy in dynamic environments. The fully decentralized learning schemes may be the intuitive solution while the convergence of distributed learning cannot be guaranteed. Accordingly, this paper explores reconfigurable intelligent surfaces (
    
[^41]: ECToNAS: 进化跨拓扑神经架构搜索

    ECToNAS: Evolutionary Cross-Topology Neural Architecture Search

    [https://arxiv.org/abs/2403.05123](https://arxiv.org/abs/2403.05123)

    ECToNAS是一种成本高效的进化跨拓扑神经架构搜索算法，不需要预训练的元控制器，能够在不同任务和超参数设置下自主选择合适的网络架构，实现跨拓扑优化，动态添加和移除卷积单元，为没有机器学习背景的研究人员提供了利用适当模型的可能性。

    

    我们提出了ECToNAS，这是一种成本高效的进化跨拓扑神经架构搜索算法，不需要任何预训练的元控制器。我们的框架能够独立地为不同任务和超参数设置选择合适的网络架构，并在需要时执行跨拓扑优化。这是一种混合方法，将训练和拓扑优化合并为一个轻量级、资源友好的过程。我们通过六个标准数据集（CIFAR-10、CIFAR-100、EuroSAT、Fashion MNIST、MNIST、SVHN）展示了这种方法的有效性和能力，展示了该算法不仅能优化架构类型内的拓扑，还能根据需要动态添加和移除卷积单元，从而跨越不同网络类型之间的边界。这使得那些没有机器学习背景的研究人员能够利用适当的模型。

    arXiv:2403.05123v1 Announce Type: new  Abstract: We present ECToNAS, a cost-efficient evolutionary cross-topology neural architecture search algorithm that does not require any pre-trained meta controllers. Our framework is able to select suitable network architectures for different tasks and hyperparameter settings, independently performing cross-topology optimisation where required. It is a hybrid approach that fuses training and topology optimisation together into one lightweight, resource-friendly process. We demonstrate the validity and power of this approach with six standard data sets (CIFAR-10, CIFAR-100, EuroSAT, Fashion MNIST, MNIST, SVHN), showcasing the algorithm's ability to not only optimise the topology within an architectural type, but also to dynamically add and remove convolutional cells when and where required, thus crossing boundaries between different network types. This enables researchers without a background in machine learning to make use of appropriate model t
    
[^42]: 具有用户表示排斥的多塔多兴趣推荐

    Multi-Tower Multi-Interest Recommendation with User Representation Repel

    [https://arxiv.org/abs/2403.05122](https://arxiv.org/abs/2403.05122)

    提出了一种具有用户表示排斥的新型多塔多兴趣框架，解决了多兴趣学习方法面临的训练和部署目标差异、无法访问商品信息以及难以工业采用等问题。

    

    在信息过载的时代，学术界和工业界都深刻认识到推荐系统的价值。特别是多兴趣序列推荐是近年来受到越来越多关注的一个子领域。通过生成多用户表示，多兴趣学习模型在理论上和经验上都比单用户表示模型具有更强的表达能力。尽管该领域取得了重大进展，但仍存在三个主要问题困扰着多兴趣学习方法的性能和可采用性，即训练和部署目标之间的差异、无法访问商品信息以及由于其单塔架构而难以工业采用。我们通过提出一种具有用户表示排斥的新型多塔多兴趣框架来解决这些挑战。通过跨多个大规模实验结果，我们证明了我们的方法的有效性。

    arXiv:2403.05122v1 Announce Type: cross  Abstract: In the era of information overload, the value of recommender systems has been profoundly recognized in academia and industry alike. Multi-interest sequential recommendation, in particular, is a subfield that has been receiving increasing attention in recent years. By generating multiple-user representations, multi-interest learning models demonstrate superior expressiveness than single-user representation models, both theoretically and empirically. Despite major advancements in the field, three major issues continue to plague the performance and adoptability of multi-interest learning methods, the difference between training and deployment objectives, the inability to access item information, and the difficulty of industrial adoption due to its single-tower architecture. We address these challenges by proposing a novel multi-tower multi-interest framework with user representation repel. Experimental results across multiple large-scale 
    
[^43]: 利用机器学习从材料属性中估算电子带隙能量

    Estimation of Electronic Band Gap Energy From Material Properties Using Machine Learning

    [https://arxiv.org/abs/2403.05119](https://arxiv.org/abs/2403.05119)

    通过机器学习技术，本论文提出了一种能够利用材料属性快速估算电子带隙能量并预测带隙类别的模型，不仅无需任何初步的DFT计算，而且能够为传统计算方法提供更优的替代方案。

    

    本文利用机器学习技术来估算电子带隙能量，并根据实验可量化的属性来预测材料的带隙类别。带隙能量的确定对于区分材料的金属性质以及在电子和光电设备中的潜在应用至关重要。虽然存在用于计算带隙能量的数值方法，但它们往往涉及高计算成本，并在准确性和可扩展性方面存在局限。利用机器学习的模型能够快速预测材料带隙能量，利用容易获取的实验性能参数，将为传统密度泛函理论（DFT）方法提供一种优越的替代方案。我们的模型不需要任何初步的基于DFT的计算或者对材料结构的了解。

    arXiv:2403.05119v1 Announce Type: cross  Abstract: Machine learning techniques are utilized to estimate the electronic band gap energy and forecast the band gap category of materials based on experimentally quantifiable properties. The determination of band gap energy is critical for discerning various material properties, such as its metallic nature, and potential applications in electronic and optoelectronic devices. While numerical methods exist for computing band gap energy, they often entail high computational costs and have limitations in accuracy and scalability. A machine learning-driven model capable of swiftly predicting material band gap energy using easily obtainable experimental properties would offer a superior alternative to conventional density functional theory (DFT) methods. Our model does not require any preliminary DFT-based calculation or knowledge of the structure of the material. We present a scheme for improving the performance of simple regression and classific
    
[^44]: 机器人操纵的高效数据收集通过组合概括

    Efficient Data Collection for Robotic Manipulation via Compositional Generalization

    [https://arxiv.org/abs/2403.05110](https://arxiv.org/abs/2403.05110)

    通过研究机器人策略的复合能力，可以避免收集处理复合情况所需的数据。

    

    数据收集在机器人操纵中变得越来越重要，然而如何有效地收集数据以促进广泛泛化仍然缺乏很多理解。最近关于大规模机器人数据收集的研究通常在数据收集过程中变化了许多环境因素，如物体类型和桌面纹理。虽然这些研究试图涵盖各种各样的场景，但它们并没有明确考虑到基于数据训练的策略可能具有的复合能力。如果机器人策略能够从它们的训练数据中组合不同的环境变量（例如物体类型、桌面高度）以在遇到看不见的因素组合时成功，那么我们就可以利用这一点来避免为复合处理的情况收集数据。为了研究这种可能性，我们在仿真环境和实际机器人上进行了彻底的实证研究。

    arXiv:2403.05110v1 Announce Type: cross  Abstract: Data collection has become an increasingly important problem in robotic manipulation, yet there still lacks much understanding of how to effectively collect data to facilitate broad generalization. Recent works on large-scale robotic data collection typically vary a wide range of environmental factors during data collection, such as object types and table textures. While these works attempt to cover a diverse variety of scenarios, they do not explicitly account for the possible compositional abilities of policies trained on the data. If robot policies are able to compose different environmental factors of variation (e.g., object types, table heights) from their training data to succeed when encountering unseen factor combinations, then we can exploit this to avoid collecting data for situations that composition would address. To investigate this possibility, we conduct thorough empirical studies both in simulation and on a real robot t
    
[^45]: 使用强化学习优化的电池供电TinyML系统在基于图像的异常检测中的模拟

    Simulating Battery-Powered TinyML Systems Optimised using Reinforcement Learning in Image-Based Anomaly Detection

    [https://arxiv.org/abs/2403.05106](https://arxiv.org/abs/2403.05106)

    本文通过强化学习优化电池供电的图像异常检测系统，扩展并贡献于TinyML研究。

    

    Tiny机器学习（TinyML）的进展促进了智能行业解决方案的创建，包括智能农业、医疗保健和智能城市。本文通过优化电池供电的基于图像的异常检测物联网（IoT）系统，扩展并为TinyML研究做出贡献。利用模拟建模，对RL算法对电池寿命的影响进行了基准测试。

    arXiv:2403.05106v1 Announce Type: new  Abstract: Advances in Tiny Machine Learning (TinyML) have bolstered the creation of smart industry solutions, including smart agriculture, healthcare and smart cities. Whilst related research contributes to enabling TinyML solutions on constrained hardware, there is a need to amplify real-world applications by optimising energy consumption in battery-powered systems. The work presented extends and contributes to TinyML research by optimising battery-powered image-based anomaly detection Internet of Things (IoT) systems. Whilst previous work in this area has yielded the capabilities of on-device inferencing and training, there has yet to be an investigation into optimising the management of such capabilities using machine learning approaches, such as Reinforcement Learning (RL), to improve the deployment battery life of such systems. Using modelled simulations, the battery life effects of an RL algorithm are benchmarked against static and dynamic o
    
[^46]: 探索对抗界限：通过对抗超体积量化鲁棒性

    Exploring the Adversarial Frontier: Quantifying Robustness via Adversarial Hypervolume

    [https://arxiv.org/abs/2403.05100](https://arxiv.org/abs/2403.05100)

    提出新指标对抗超体积来全面评估深度学习模型在多种扰动强度下的鲁棒性，并采用新型训练算法来提高对抗鲁棒性。

    

    在深度学习模型面临日益严重的对抗攻击威胁，特别是在安全关键领域，强调了对鲁棒深度学习系统的需求。传统的鲁棒性评估依赖于对抗准确性，该指标衡量模型在特定扰动强度下的性能。然而，这一单一指标并不能完全概括模型对不同程度扰动的整体韧性。为了填补这一空白，我们提出了一种新的指标，称为对抗超体积，从多目标优化的角度综合评估了深度学习模型在一系列扰动强度下的鲁棒性。该指标允许深入比较防御机制，并承认了较弱的防御策略所带来的鲁棒性改进。此外，我们采用了一种提高对抗鲁棒性均匀性的新型训练算法。

    arXiv:2403.05100v1 Announce Type: cross  Abstract: The escalating threat of adversarial attacks on deep learning models, particularly in security-critical fields, has underscored the need for robust deep learning systems. Conventional robustness evaluations have relied on adversarial accuracy, which measures a model's performance under a specific perturbation intensity. However, this singular metric does not fully encapsulate the overall resilience of a model against varying degrees of perturbation. To address this gap, we propose a new metric termed adversarial hypervolume, assessing the robustness of deep learning models comprehensively over a range of perturbation intensities from a multi-objective optimization standpoint. This metric allows for an in-depth comparison of defense mechanisms and recognizes the trivial improvements in robustness afforded by less potent defensive strategies. Additionally, we adopt a novel training algorithm that enhances adversarial robustness uniformly
    
[^47]: 用于分子预测任务的大型语言模型基准测试

    Benchmarking Large Language Models for Molecule Prediction Tasks

    [https://arxiv.org/abs/2403.05075](https://arxiv.org/abs/2403.05075)

    本文探讨了大型语言模型在处理分子预测任务方面的潜力和限制，并评估了它们在多样化分子任务中的表现。

    

    大型语言模型（LLMs）处于许多自然语言处理（NLP）任务的前沿。尽管LLMs在NLP中被广泛采用，但它们在更广泛领域的潜力仍然未被充分探索，其设计和实施存在显著限制。作者在本文中探讨了一个基本问题：LLMs能否有效处理分子预测任务？与追求最高水平性能不同，作者的目标是评估LLMs在不同的分子任务中的贡献。

    arXiv:2403.05075v1 Announce Type: new  Abstract: Large Language Models (LLMs) stand at the forefront of a number of Natural Language Processing (NLP) tasks. Despite the widespread adoption of LLMs in NLP, much of their potential in broader fields remains largely unexplored, and significant limitations persist in their design and implementation. Notably, LLMs struggle with structured data, such as graphs, and often falter when tasked with answering domain-specific questions requiring deep expertise, such as those in biology and chemistry. In this paper, we explore a fundamental question: Can LLMs effectively handle molecule prediction tasks? Rather than pursuing top-tier performance, our goal is to assess how LLMs can contribute to diverse molecule tasks. We identify several classification and regression prediction tasks across six standard molecule datasets. Subsequently, we carefully design a set of prompts to query LLMs on these tasks and compare their performance with existing Machi
    
[^48]: 通过近似最优输运改进基于扩散的生成模型

    Improving Diffusion-Based Generative Models via Approximated Optimal Transport

    [https://arxiv.org/abs/2403.05069](https://arxiv.org/abs/2403.05069)

    通过近似最优输运技术改进了基于扩散的生成模型，显著提高了模型准确估计去噪器输出的能力，降低了采样过程中的截断误差，实现了更优质的图像生成质量。

    

    我们引入了近似最优输运（AOT）技术，一种新颖的用于扩散生成模型的训练方案。我们的方法旨在将最优输运近似并整合到训练过程中，显著增强扩散模型准确估计去噪器输出的能力。这种改进导致扩散模型的ODE轨迹具有较低曲率和减少采样过程中的截断误差。通过在训练中采用AOT，我们实现了更优越的图像质量和减少的采样步骤。具体来说，我们在无条件和有条件生成中仅使用27个NFEs和29个NFEs分别实现了1.88和1.73的FID分数。此外，当将AOT应用于为引导训练鉴别器时，我们分别为无条件和有条件生成树立了新的最先进的FID分数，每个分别为1.68和1.58，每个都使用了29个NFEs。这一结果展示了AOT的有效性。

    arXiv:2403.05069v1 Announce Type: cross  Abstract: We introduce the Approximated Optimal Transport (AOT) technique, a novel training scheme for diffusion-based generative models. Our approach aims to approximate and integrate optimal transport into the training process, significantly enhancing the ability of diffusion models to estimate the denoiser outputs accurately. This improvement leads to ODE trajectories of diffusion models with lower curvature and reduced truncation errors during sampling. We achieve superior image quality and reduced sampling steps by employing AOT in training. Specifically, we achieve FID scores of 1.88 with just 27 NFEs and 1.73 with 29 NFEs in unconditional and conditional generations, respectively. Furthermore, when applying AOT to train the discriminator for guidance, we establish new state-of-the-art FID scores of 1.68 and 1.58 for unconditional and conditional generations, respectively, each with 29 NFEs. This outcome demonstrates the effectiveness of A
    
[^49]: 复位和提炼：克服持续强化学习中负迁移的有效方法

    Reset & Distill: A Recipe for Overcoming Negative Transfer in Continual Reinforcement Learning

    [https://arxiv.org/abs/2403.05066](https://arxiv.org/abs/2403.05066)

    开发了Reset & Distill（R&D）方法，通过重置代理的网络和提炼知识，有效克服了持续强化学习中负迁移问题。

    

    我们认为发展有效的持续强化学习（CRL）算法的主要障碍之一是当需要学习新任务时会发生负迁移问题。通过全面的实验证实，我们证明这种问题在CRL中经常存在，并且无法通过最近一些旨在减轻RL代理的可塑性损失的工作来有效解决。为此，我们开发了Reset & Distill（R&D），这是一种简单但高效的方法，用于克服CRL中负迁移问题。R&D结合了一种策略，即重置代理的在线演员和评论网络以学习新任务，以及离线学习步骤，用于提炼在线演员和以前专家动作概率的知识。我们在Meta-World任务的长序列上进行了大量实验，并展示了我们的方法始终优于最近的基线，取得了显着更高的成功率。

    arXiv:2403.05066v1 Announce Type: cross  Abstract: We argue that one of the main obstacles for developing effective Continual Reinforcement Learning (CRL) algorithms is the negative transfer issue occurring when the new task to learn arrives. Through comprehensive experimental validation, we demonstrate that such issue frequently exists in CRL and cannot be effectively addressed by several recent work on mitigating plasticity loss of RL agents. To that end, we develop Reset & Distill (R&D), a simple yet highly effective method, to overcome the negative transfer problem in CRL. R&D combines a strategy of resetting the agent's online actor and critic networks to learn a new task and an offline learning step for distilling the knowledge from the online actor and previous expert's action probabilities. We carried out extensive experiments on long sequence of Meta-World tasks and show that our method consistently outperforms recent baselines, achieving significantly higher success rates acr
    
[^50]: 无监督图神经架构搜索与解耦自监督

    Unsupervised Graph Neural Architecture Search with Disentangled Self-supervision

    [https://arxiv.org/abs/2403.05064](https://arxiv.org/abs/2403.05064)

    提出了一种新颖的解耦自监督图神经架构搜索（DSGAS）模型，能够发现捕获各种潜在图因素的最佳架构

    

    现有的图神经架构搜索方法在搜索过程中严重依赖监督标签，无法处理监督不可用的普遍情况。本文研究了无监督图神经架构搜索问题，在文献中尚未探索。关键问题是发现驱动图数据形成以及潜在关系的潜在图因素与最优神经架构之间的关系。由于图的性质和神经架构搜索过程的复杂性，这一问题很具挑战性。为了解决这一挑战，我们提出了一种新颖的解耦自监督图神经架构搜索（DSGAS）模型，能够发现捕获各种潜在图因素的最佳架构

    arXiv:2403.05064v1 Announce Type: cross  Abstract: The existing graph neural architecture search (GNAS) methods heavily rely on supervised labels during the search process, failing to handle ubiquitous scenarios where supervisions are not available. In this paper, we study the problem of unsupervised graph neural architecture search, which remains unexplored in the literature. The key problem is to discover the latent graph factors that drive the formation of graph data as well as the underlying relations between the factors and the optimal neural architectures. Handling this problem is challenging given that the latent graph factors together with architectures are highly entangled due to the nature of the graph and the complexity of the neural architecture search process. To address the challenge, we propose a novel Disentangled Self-supervised Graph Neural Architecture Search (DSGAS) model, which is able to discover the optimal architectures capturing various latent graph factors in 
    
[^51]: 一种用于受约束优化输运的Sinkhorn类型算法

    A Sinkhorn-type Algorithm for Constrained Optimal Transport

    [https://arxiv.org/abs/2403.05054](https://arxiv.org/abs/2403.05054)

    本文介绍了一种用于受约束优化输运的Sinkhorn类型算法，通过引入熵正则化公式并在对偶空间中证明了算法的亚线性一阶收敛率。

    

    熵正则的最优输运(OT)和Sinkhorn算法使得机器学习从业者能够实现计算统计分布之间输运距离的基本任务变得可行。本工作关注于在等式和不等式约束的组合下的一般类OT问题。我们得出相应的熵正则化公式，并介绍了一种针对此类受约束OT问题的Sinkhorn类型算法，支持理论保证。在通过熵正则化解决问题时，我们首先限制了近似误差，该误差随着正则化参数的增加呈指数减少。此外，通过利用Lyapunov函数表征优化过程，我们证明了所提出的Sinkhorn类型算法在对偶空间中具有亚线性的一阶收敛率。为了在弱熵正则化下实现快速且高阶收敛

    arXiv:2403.05054v1 Announce Type: cross  Abstract: Entropic optimal transport (OT) and the Sinkhorn algorithm have made it practical for machine learning practitioners to perform the fundamental task of calculating transport distance between statistical distributions. In this work, we focus on a general class of OT problems under a combination of equality and inequality constraints. We derive the corresponding entropy regularization formulation and introduce a Sinkhorn-type algorithm for such constrained OT problems supported by theoretical guarantees. We first bound the approximation error when solving the problem through entropic regularization, which reduces exponentially with the increase of the regularization parameter. Furthermore, we prove a sublinear first-order convergence rate of the proposed Sinkhorn-type algorithm in the dual space by characterizing the optimization procedure with a Lyapunov function. To achieve fast and higher-order convergence under weak entropy regulariz
    
[^52]: 人类对话是否特殊？一个大型语言模型的视角

    Are Human Conversations Special? A Large Language Model Perspective

    [https://arxiv.org/abs/2403.05045](https://arxiv.org/abs/2403.05045)

    本研究分析了大型语言模型在理解人类对话时的注意机制变化，发现尽管语言模型在特定领域表现出不同的注意行为，但在专门处理人类对话方面存在明显差距，需要通过多样化的高质量对话数据训练模型来增强理解和生成

    

    本研究分析了大型语言模型（LLMs）在理解人类之间的自然对话（人-人）时注意机制的变化。我们分析了LLMs的三种用例：与网络内容、代码和数学文本的互动。通过分析跨这些领域的注意距离、分散性和相互依赖性，我们强调了对话数据所提出的独特挑战。值得注意的是，对话需要细致处理长期上下文关系，并通过它们的注意模式展示出更高的复杂性。我们的研究结果表明，虽然语言模型表现出特定于领域的注意行为，但它们在专门化人类对话方面存在显著差距。通过详细的注意熵分析和t-SNE可视化，我们展示了需要通过训练模型使用多样化的高质量对话数据来增强理解和生成。

    arXiv:2403.05045v1 Announce Type: cross  Abstract: This study analyzes changes in the attention mechanisms of large language models (LLMs) when used to understand natural conversations between humans (human-human). We analyze three use cases of LLMs: interactions over web content, code, and mathematical texts. By analyzing attention distance, dispersion, and interdependency across these domains, we highlight the unique challenges posed by conversational data. Notably, conversations require nuanced handling of long-term contextual relationships and exhibit higher complexity through their attention patterns. Our findings reveal that while language models exhibit domain-specific attention behaviors, there is a significant gap in their ability to specialize in human conversations. Through detailed attention entropy analysis and t-SNE visualizations, we demonstrate the need for models trained with a diverse array of high-quality conversational data to enhance understanding and generation of
    
[^53]: CRM：使用卷积重建模型将单张图像转换为3D纹理网格

    CRM: Single Image to 3D Textured Mesh with Convolutional Reconstruction Model

    [https://arxiv.org/abs/2403.05034](https://arxiv.org/abs/2403.05034)

    CRM提出了一种高保真度的前馈单图像到3D生成模型，通过将三平面的几何先验整合到网络设计中，实现了从单个输入图像生成六个正交视图图像，然后利用卷积U-Net进行处理，从而提高了生成质量和速度。

    

    arXiv:2403.05034v1 公告类型：跨领域 摘要：像大型重建模型（LRM）这样的前馈3D生成模型已经展示出极高的生成速度。然而，基于Transformer的方法没有利用其架构中三平面组件的几何先验，常常导致由于3D数据量有限和训练速度慢而达不到最佳质量。在这项工作中，我们提出了卷积重建模型（CRM），一个高保真度的前馈单图像到3D生成模型。认识到稀疏3D数据带来的限制，我们强调了将几何先验整合到网络设计中的必要性。CRM建立在以下关键观察的基础上，即三平面的可视化展示了六个正交图像的空间对应关系。首先，它从单个输入图像生成六个正交视图图像，然后将这些图像馈入卷积U-Net，利用其强大的像素级对齐能力和显著的带宽。

    arXiv:2403.05034v1 Announce Type: cross  Abstract: Feed-forward 3D generative models like the Large Reconstruction Model (LRM) have demonstrated exceptional generation speed. However, the transformer-based methods do not leverage the geometric priors of the triplane component in their architecture, often leading to sub-optimal quality given the limited size of 3D data and slow training. In this work, we present the Convolutional Reconstruction Model (CRM), a high-fidelity feed-forward single image-to-3D generative model. Recognizing the limitations posed by sparse 3D data, we highlight the necessity of integrating geometric priors into network design. CRM builds on the key observation that the visualization of triplane exhibits spatial correspondence of six orthographic images. First, it generates six orthographic view images from a single input image, then feeds these images into a convolutional U-Net, leveraging its strong pixel-level alignment capabilities and significant bandwidth 
    
[^54]: 量化流形:生成对抗网络学习的流形是否收敛于真实数据流形

    Quantifying Manifolds: Do the manifolds learned by Generative Adversarial Networks converge to the real data manifold

    [https://arxiv.org/abs/2403.05033](https://arxiv.org/abs/2403.05033)

    通过研究ML模型学习到的流形的内在维度和拓扑特征，本文探讨了这些度量在训练过程中是否收敛到真实数据流形的度量。

    

    本文介绍了我们的实验，用于量化由ML模型（在我们的实验中，我们使用了一个GAN模型）学习的流形随着训练而变化。我们比较了每个时期学习到的流形与代表真实数据的真实流形。为了量化一个流形，我们研究了ML模型学习到的流形的内在维度和拓扑特征，这些度量随着我们继续训练模型而如何变化，以及这些度量是否在训练过程中收敛到真实数据流形的度量。

    arXiv:2403.05033v1 Announce Type: cross  Abstract: This paper presents our experiments to quantify the manifolds learned by ML models (in our experiment, we use a GAN model) as they train. We compare the manifolds learned at each epoch to the real manifolds representing the real data. To quantify a manifold, we study the intrinsic dimensions and topological features of the manifold learned by the ML model, how these metrics change as we continue to train the model, and whether these metrics convergence over the course of training to the metrics of the real data manifold.
    
[^55]: 利用潜在对抗训练防御未预见的故障模式

    Defending Against Unforeseen Failure Modes with Latent Adversarial Training

    [https://arxiv.org/abs/2403.05030](https://arxiv.org/abs/2403.05030)

    本研究利用潜在对抗训练（LAT）来防御AI系统中未预见的故障模式，通过利用网络实际用于预测的压缩、抽象和结构化概念的潜在表示，有效清除了恶意软件和对抗性攻击。

    

    人工智能系统有时在部署后会展示出有害的意外行为。尽管开发人员进行了大量诊断和调试，这种情况经常发生。由于攻击面非常广泛，从模型中减少风险具有挑战性。耗尽地搜索可能导致模型失败的输入是不可行的。红队和对抗训练（AT）通常用于使人工智能系统更加健壮。然而，它们并不足以避免许多与对抗训练不同的真实世界故障模式。在这项工作中，我们利用潜在对抗训练（LAT）来防御漏洞，而无需生成引发这些漏洞的输入。LAT利用网络实际用于预测的压缩、抽象和结构化概念的潜在表示。我们使用LAT来清除恶意软件并防御针对保留类别的对抗性攻击。我们展示在图像分类、文本分类

    arXiv:2403.05030v1 Announce Type: cross  Abstract: AI systems sometimes exhibit harmful unintended behaviors post-deployment. This is often despite extensive diagnostics and debugging by developers. Minimizing risks from models is challenging because the attack surface is so large. It is not tractable to exhaustively search for inputs that may cause a model to fail. Red-teaming and adversarial training (AT) are commonly used to make AI systems more robust. However, they have not been sufficient to avoid many real-world failure modes that differ from the ones adversarially trained on. In this work, we utilize latent adversarial training (LAT) to defend against vulnerabilities without generating inputs that elicit them. LAT leverages the compressed, abstract, and structured latent representations of concepts that the network actually uses for prediction. We use LAT to remove trojans and defend against held-out classes of adversarial attacks. We show in image classification, text classifi
    
[^56]: 分布漂移下动态图的谱不变学习

    Spectral Invariant Learning for Dynamic Graphs under Distribution Shifts

    [https://arxiv.org/abs/2403.05026](https://arxiv.org/abs/2403.05026)

    该论文首次提出在动态图的谱域内研究分布漂移，并提出了谱不变学习方法来应对谱域中的分布漂移挑战。

    

    动态图神经网络（DyGNNs）目前在处理动态图固有的分布漂移时存在困难。现有针对DyGNNs在分布漂移设置中的工作仅关注时间域，未能处理涉及谱域中分布漂移的情况。本文发现存在一些情况，时间域中观察不到的分布漂移却在谱域中可以观察到，并首次提出研究动态图谱域内的分布漂移。然而，这项研究提出了两个关键挑战：i）捕捉谱域中纠缠在一起的不同频率分量驱动的不同图模式并非易事；ii）如何处理与发现的谱模式相关的分布漂移仍不清楚。为解决这些挑战，我们提出了用于处理分布漂移下动态图的谱不变学习方法。

    arXiv:2403.05026v1 Announce Type: cross  Abstract: Dynamic graph neural networks (DyGNNs) currently struggle with handling distribution shifts that are inherent in dynamic graphs. Existing work on DyGNNs with out-of-distribution settings only focuses on the time domain, failing to handle cases involving distribution shifts in the spectral domain. In this paper, we discover that there exist cases with distribution shifts unobservable in the time domain while observable in the spectral domain, and propose to study distribution shifts on dynamic graphs in the spectral domain for the first time. However, this investigation poses two key challenges: i) it is non-trivial to capture different graph patterns that are driven by various frequency components entangled in the spectral domain; and ii) it remains unclear how to handle distribution shifts with the discovered spectral patterns. To address these challenges, we propose Spectral Invariant Learning for Dynamic Graphs under Distribution Sh
    
[^57]: 一种用于MRI偏置场校正的概率哈达玛U-Net

    A Probabilistic Hadamard U-Net for MRI Bias Field Correction

    [https://arxiv.org/abs/2403.05024](https://arxiv.org/abs/2403.05024)

    提出了一种用于前列腺MRI偏置场校正的概率哈达玛U-Net，引入了哈达玛U-Net（HU-Net）通过哈达玛变换将输入图像从时域转换为频域，并使用可训练的滤波器和硬阈值层消除高频部分。

    

    磁场不均匀性校正在MRI分析中仍然是一个具有挑战性的任务。大多数已建立的技术是为脑MRI设计的，假设相同组织中的图像强度遵循均匀分布。这种假设不易适用于其他器官，特别是那些体积小，质地不均匀（强度变化大）的器官，比如前列腺。为了解决这个问题，本文提出了一种用于前列腺MRI偏置场校正的概率哈达玛U-Net（PHU-Net）。首先，引入了一种新颖的哈达玛U-Net（HU-Net）以提取低频标量场，将其乘以原始输入以获得原型校正图像。HU-Net通过哈达玛变换将输入图像从时域转换为频域。在频域中，使用可训练的滤波器（缩放层）、硬阈值层消除高频部分。

    arXiv:2403.05024v1 Announce Type: cross  Abstract: Magnetic field inhomogeneity correction remains a challenging task in MRI analysis. Most established techniques are designed for brain MRI by supposing that image intensities in the identical tissue follow a uniform distribution. Such an assumption cannot be easily applied to other organs, especially those that are small in size and heterogeneous in texture (large variations in intensity), such as the prostate. To address this problem, this paper proposes a probabilistic Hadamard U-Net (PHU-Net) for prostate MRI bias field correction. First, a novel Hadamard U-Net (HU-Net) is introduced to extract the low-frequency scalar field, multiplied by the original input to obtain the prototypical corrected image. HU-Net converts the input image from the time domain into the frequency domain via Hadamard transform. In the frequency domain, high-frequency components are eliminated using the trainable filter (scaling layer), hard-thresholding laye
    
[^58]: 简单多图卷积网络

    Simple Multigraph Convolution Networks

    [https://arxiv.org/abs/2403.05014](https://arxiv.org/abs/2403.05014)

    本文提出了一种简单的多图卷积网络（SMGCN），通过提取一致的交叉视图拓扑和执行多项式展开，有效降低了多图卷积的复杂度，实现了可信的交叉视图空间消息传递。

    

    现有的多图卷积方法要么忽视多个图之间的交叉视图交互，要么由于标准的交叉视图多项式运算符而导致计算成本极高。为了缓解这个问题，本文提出了一种简单的多图卷积网络（SMGCN），它首先从多图中提取一致的交叉视图拓扑，包括边级和子图级拓扑，然后基于原始多图和一致的拓扑执行多项式展开。在理论上，SMGCN利用一致的拓扑进行多项式展开，而不是标准的交叉视图多项式展开，从而执行可信的交叉视图空间消息传递，遵循谱卷积范式，并有效降低标准多项式展开的复杂度。在模拟实验中，实验结果表明SMGCN在ACM和DBLP多图基准数据上实现了最先进的性能。

    arXiv:2403.05014v1 Announce Type: cross  Abstract: Existing multigraph convolution methods either ignore the cross-view interaction among multiple graphs, or induce extremely high computational cost due to standard cross-view polynomial operators. To alleviate this problem, this paper proposes a Simple MultiGraph Convolution Networks (SMGCN) which first extracts consistent cross-view topology from multigraphs including edge-level and subgraph-level topology, then performs polynomial expansion based on raw multigraphs and consistent topologies. In theory, SMGCN utilizes the consistent topologies in polynomial expansion rather than standard cross-view polynomial expansion, which performs credible cross-view spatial message-passing, follows the spectral convolution paradigm, and effectively reduces the complexity of standard polynomial expansion. In the simulations, experimental results demonstrate that SMGCN achieves state-of-the-art performance on ACM and DBLP multigraph benchmark datas
    
[^59]: 具有多元人类反馈的可证明多方协作强化学习

    Provable Multi-Party Reinforcement Learning with Diverse Human Feedback

    [https://arxiv.org/abs/2403.05006](https://arxiv.org/abs/2403.05006)

    该研究首次提出了多方协作强化学习的理论研究，通过整合多个个体不同偏好的元学习与不同社会福利函数的采用，克服了传统RLHF方法无法捕捉并平衡多个个体偏好的局限性。

    

    用人类反馈进行强化学习（RLHF）是一种新兴范式，旨在将模型与人类偏好进行匹配。我们的工作探索了明确建模多个个体不同偏好的多方RLHF的理论研究。我们展示了传统RLHF方法如何失败，因为学习单一奖励函数无法捕捉和平衡多个个体的偏好。为了克服这些局限性，我们结合元学习来学习多个偏好，并采用不同的社会福利函数来整合多方的偏好。我们关注离线学习设置，并为优化不同社会福利函数（如Nash、Utilitarian和Leximin福利）建立样本复杂度界限，同时提供效率和公平性保证。

    arXiv:2403.05006v1 Announce Type: cross  Abstract: Reinforcement learning with human feedback (RLHF) is an emerging paradigm to align models with human preferences. Typically, RLHF aggregates preferences from multiple individuals who have diverse viewpoints that may conflict with each other. Our work \textit{initiates} the theoretical study of multi-party RLHF that explicitly models the diverse preferences of multiple individuals. We show how traditional RLHF approaches can fail since learning a single reward function cannot capture and balance the preferences of multiple individuals. To overcome such limitations, we incorporate meta-learning to learn multiple preferences and adopt different social welfare functions to aggregate the preferences across multiple parties. We focus on the offline learning setting and establish sample complexity bounds, along with efficiency and fairness guarantees, for optimizing diverse social welfare functions such as Nash, Utilitarian, and Leximin welfa
    
[^60]: 无法记住长文档中的细节？您需要一些R&R

    Can't Remember Details in Long Documents? You Need Some R&R

    [https://arxiv.org/abs/2403.05004](https://arxiv.org/abs/2403.05004)

    引入R&R方法，结合reprompting和in-context retrieval两种新型提示方式，提高了在长文档上的问答任务的准确性。

    

    长上下文大型语言模型（LLMs）在诸如长篇文档上的问答（QA）等任务中表现出潜力，但它们往往会错过上下文文档中间的重要信息。在这里，我们介绍了一个名为$\textit{R&R}$的方法，它结合了两种新型基于提示的方法，称为$\textit{reprompting}$和$\textit{in-context retrieval}$（ICR），以减轻文档型QA中的这种影响。在$\textit{reprompting}$中，我们周期性地在整个上下文文档中重复提示说明，以提醒LLM其原始任务。在ICR中，我们并不指示LLM直接回答问题，而是指示它检索与给定问题最相关的前$k$个段落编号，然后将其用作第二个QA提示中的缩略上下文。我们使用GPT-4 Turbo和Claude-2.1在长度达到80k标记的文档上测试了R&R，并平均观察到QA准确率提升了16个百分点。

    arXiv:2403.05004v1 Announce Type: cross  Abstract: Long-context large language models (LLMs) hold promise for tasks such as question-answering (QA) over long documents, but they tend to miss important information in the middle of context documents (arXiv:2307.03172v3). Here, we introduce $\textit{R&R}$ -- a combination of two novel prompt-based methods called $\textit{reprompting}$ and $\textit{in-context retrieval}$ (ICR) -- to alleviate this effect in document-based QA. In reprompting, we repeat the prompt instructions periodically throughout the context document to remind the LLM of its original task. In ICR, rather than instructing the LLM to answer the question directly, we instruct it to retrieve the top $k$ passage numbers most relevant to the given question, which are then used as an abbreviated context in a second QA prompt. We test R&R with GPT-4 Turbo and Claude-2.1 on documents up to 80k tokens in length and observe a 16-point boost in QA accuracy on average. Our further an
    
[^61]: 使用量子完全图神经网络进行喷注判别

    Jet Discrimination with Quantum Complete Graph Neural Network

    [https://arxiv.org/abs/2403.04990](https://arxiv.org/abs/2403.04990)

    QCGNN通过量子并行性实现了对喷注判别的多项式加速，为喷注判别问题带来新的解决方案

    

    机器学习，特别是深度神经网络，在高能物理中被广泛应用，并在各种应用中展现出显著的效果。此外，机器学习的概念已扩展到量子计算机，形成了一个被称为量子机器学习的新研究领域。在本文中，我们提出了一个新颖的变分量子电路模型，即量子完全图神经网络（QCGNN），旨在学习完全图。我们认为QCGNN由于量子并行性的特性，在速度上对其经典对应物具有多项式加速。本文研究了QCGNN在具有挑战性的喷注判别中的应用，其中喷注用完全图表示。随后，我们与经典图神经网络进行了比较分析，以建立基准。

    arXiv:2403.04990v1 Announce Type: cross  Abstract: Machine learning, particularly deep neural networks, has been widely utilized in high energy physics and has shown remarkable results in various applications. Moreover, the concept of machine learning has been extended to quantum computers, giving rise to a new research area known as quantum machine learning. In this paper, we propose a novel variational quantum circuit model, Quantum Complete Graph Neural Network (QCGNN), designed for learning complete graphs. We argue that QCGNN has a polynomial speedup against its classical counterpart, due to the property of quantum parallelism. In this paper, we study the application of QCGNN through the challenging jet discrimination, where the jets are represented with complete graphs. Subsequently, we conduct a comparative analysis with classical graph neural networks to establish a benchmark.
    
[^62]: Stacking作为加速梯度下降算法

    Stacking as Accelerated Gradient Descent

    [https://arxiv.org/abs/2403.04978](https://arxiv.org/abs/2403.04978)

    Stacking提出了一种理论解释，即实现了Nesterov的加速梯度下降形式，并证明对于某些深度线性残差网络，提供了加速训练。

    

    Stacking是一种启发式技术，通过逐渐增加层数并通过从旧层复制参数来初始化新层，用于训练深度残差网络，已经被证明在提高深度神经网络训练效率方面非常成功。本文提出了对于Stacking有效性的理论解释：即，Stacking实现了Nesterov的加速梯度下降的一种形式。该理论还涵盖了诸如提升方法中构建的加法集成等更简单的模型，并为每一轮提升过程中初始化新分类器的类似广泛使用的实用启发式提供了解释。我们还证明了对于某些深度线性残差网络，通过对Nesterov的加速梯度方法的一个新的潜能函数分析，Stacking确实提供了加速训练，从而允许更新中的误差。我们进行了概念验证实验来验证我们的理论。

    arXiv:2403.04978v1 Announce Type: new  Abstract: Stacking, a heuristic technique for training deep residual networks by progressively increasing the number of layers and initializing new layers by copying parameters from older layers, has proven quite successful in improving the efficiency of training deep neural networks. In this paper, we propose a theoretical explanation for the efficacy of stacking: viz., stacking implements a form of Nesterov's accelerated gradient descent. The theory also covers simpler models such as the additive ensembles constructed in boosting methods, and provides an explanation for a similar widely-used practical heuristic for initializing the new classifier in each round of boosting. We also prove that for certain deep linear residual networks, stacking does provide accelerated training, via a new potential function analysis of the Nesterov's accelerated gradient method which allows errors in updates. We conduct proof-of-concept experiments to validate our
    
[^63]: C2P-GCN：用于结直肠癌分级的细胞到补丁图卷积网络

    C2P-GCN: Cell-to-Patch Graph Convolutional Network for Colorectal Cancer Grading

    [https://arxiv.org/abs/2403.04962](https://arxiv.org/abs/2403.04962)

    C2P-GCN提出了一种新颖的细胞到补丁图卷积网络方法，通过两阶段图形成，在第一阶段形成补丁级图，第二阶段形成图像级图，从而更好地捕捉结直肠癌组织结构信息。

    

    基于图的学习方法越来越受欢迎，因为它们能够编码组织/器官结构信息，逐渐成为结直肠癌组织学图像分级的首选。最近的基于图的技术涉及将整张幻灯片图像（WSIs）分成更小或中等大小的补丁，然后在每个补丁上构建图以直接用于训练。然而，这种方法无法捕捉整个WSI中存在的组织结构信息，并依赖于来自大量图像补丁的训练。在本文中，我们提出了一种新颖的细胞到补丁图卷积网络（C2P-GCN），这是一种基于两阶段图形成的方法。在第一阶段，它基于WSI上每个补丁上的细胞组织形成一个补丁级图。在第二阶段，它基于WSI中每个补丁之间的相似度量形成一个图像级图，将每个补丁视为图的节点。这种图表示是t

    arXiv:2403.04962v1 Announce Type: cross  Abstract: Graph-based learning approaches, due to their ability to encode tissue/organ structure information, are increasingly favored for grading colorectal cancer histology images. Recent graph-based techniques involve dividing whole slide images (WSIs) into smaller or medium-sized patches, and then building graphs on each patch for direct use in training. This method, however, fails to capture the tissue structure information present in an entire WSI and relies on training from a significantly large dataset of image patches. In this paper, we propose a novel cell-to-patch graph convolutional network (C2P-GCN), which is a two-stage graph formation-based approach. In the first stage, it forms a patch-level graph based on the cell organization on each patch of a WSI. In the second stage, it forms an image-level graph based on a similarity measure between patches of a WSI considering each patch as a node of a graph. This graph representation is t
    
[^64]: SecGPT：一种面向基于LLM系统的执行隔离架构

    SecGPT: An Execution Isolation Architecture for LLM-Based Systems

    [https://arxiv.org/abs/2403.04960](https://arxiv.org/abs/2403.04960)

    提出了一种面向LLM系统的执行隔离架构SecGPT，旨在解决第三方应用程序执行所引发的安全和隐私问题

    

    大型语言模型（LLMs）被扩展为系统，如ChatGPT，已经开始支持第三方应用程序。这些LLM应用程序利用LLMs的事实上基于自然语言的自动执行范式：即，应用程序及其交互是用自然语言定义的，提供对用户数据的访问，并被允许自由地相互交互以及与系统互动。这些LLM应用程序生态系统类似于早期计算平台的设置，在那里应用程序和系统之间缺乏足够的隔离。由于第三方应用程序可能不可信，并且受自然语言界面的不精确性加剧，当前的设计会为用户带来安全和隐私风险。在本文中，我们提出了SecGPT，一种面向LLM系统的架构，旨在缓解由第三方应用程序执行引起的安全性和隐私问题。SecGPT的关键思想是隔离应用程序的执行和更多的预

    arXiv:2403.04960v1 Announce Type: cross  Abstract: Large language models (LLMs) extended as systems, such as ChatGPT, have begun supporting third-party applications. These LLM apps leverage the de facto natural language-based automated execution paradigm of LLMs: that is, apps and their interactions are defined in natural language, provided access to user data, and allowed to freely interact with each other and the system. These LLM app ecosystems resemble the settings of earlier computing platforms, where there was insufficient isolation between apps and the system. Because third-party apps may not be trustworthy, and exacerbated by the imprecision of the natural language interfaces, the current designs pose security and privacy risks for users. In this paper, we propose SecGPT, an architecture for LLM-based systems that aims to mitigate the security and privacy issues that arise with the execution of third-party apps. SecGPT's key idea is to isolate the execution of apps and more pre
    
[^65]: 为报告生成调优心电图指导

    Electrocardiogram Instruction Tuning for Report Generation

    [https://arxiv.org/abs/2403.04945](https://arxiv.org/abs/2403.04945)

    提出了Multimodal ECG Instruction Tuning（MEIT）框架，首次尝试使用LLMs和多模态指导解决ECG报告生成问题，并在两个大规模ECG数据集上进行了广泛的实验评估其优越性。

    

    心电图（ECG）作为心脏病情监测的主要非侵入性诊断工具，对于协助临床医生至关重要。最近的研究集中在使用ECG数据对心脏病情进行分类，但忽略了ECG报告生成，这不仅耗时，而且需要临床专业知识。为了自动化ECG报告生成并确保其多功能性，我们提出了Multimodal ECG Instruction Tuning（MEIT）框架，这是\textit{首次}尝试使用LLMs和多模态指导来解决ECG报告生成问题。为了促进未来的研究，我们建立了一个基准来评估MEIT在两个大规模ECG数据集上使用各种LLM骨干的表现。我们的方法独特地对齐了ECG信号和报告的表示，并进行了大量实验来评估MEIT与九个开源LLMs，使用了超过80万个ECG报告。MEIT的结果凸显了其优越性。

    arXiv:2403.04945v1 Announce Type: new  Abstract: Electrocardiogram (ECG) serves as the primary non-invasive diagnostic tool for cardiac conditions monitoring, are crucial in assisting clinicians. Recent studies have concentrated on classifying cardiac conditions using ECG data but have overlooked ECG report generation, which is not only time-consuming but also requires clinical expertise. To automate ECG report generation and ensure its versatility, we propose the Multimodal ECG Instruction Tuning (MEIT) framework, the \textit{first} attempt to tackle ECG report generation with LLMs and multimodal instructions. To facilitate future research, we establish a benchmark to evaluate MEIT with various LLMs backbones across two large-scale ECG datasets. Our approach uniquely aligns the representations of the ECG signal and the report, and we conduct extensive experiments to benchmark MEIT with nine open source LLMs, using more than 800,000 ECG reports. MEIT's results underscore the superior p
    
[^66]: 用于动态视觉刺激生成的时空风格转移算法

    A spatiotemporal style transfer algorithm for dynamic visual stimulus generation

    [https://arxiv.org/abs/2403.04940](https://arxiv.org/abs/2403.04940)

    提出了Spatiotemporal Style Transfer (STST)算法，基于双流深度神经网络模型，允许生成强大的动态视觉刺激，用于视觉研究。

    

    了解视觉信息如何在生物和人工系统中编码通常需要视觉科学家生成适当的刺激来测试特定的假设。尽管深度神经网络模型已经在图像生成领域引起革命，例如图像风格转移，但视频生成的方法却很少。在这里，我们介绍了时空风格转移（STST）算法，这是一个动态的视觉刺激生成框架，允许强大地操作和合成视频刺激用于视觉研究。它基于一个双流深度神经网络模型，分解空间和时间特征以生成动态视觉刺激，其模型层激活与输入视频的匹配。

    arXiv:2403.04940v1 Announce Type: cross  Abstract: Understanding how visual information is encoded in biological and artificial systems often requires vision scientists to generate appropriate stimuli to test specific hypotheses. Although deep neural network models have revolutionized the field of image generation with methods such as image style transfer, available methods for video generation are scarce. Here, we introduce the Spatiotemporal Style Transfer (STST) algorithm, a dynamic visual stimulus generation framework that allows powerful manipulation and synthesis of video stimuli for vision research. It is based on a two-stream deep neural network model that factorizes spatial and temporal features to generate dynamic visual stimuli whose model layer activations are matched to those of input videos. As an example, we show that our algorithm enables the generation of model metamers, dynamic stimuli whose layer activations within our two-stream model are matched to those of natural
    
[^67]: 无梯度神经拓扑优化

    Gradient-free neural topology optimization

    [https://arxiv.org/abs/2403.04937](https://arxiv.org/abs/2403.04937)

    通过提出一种预训练的神经重新参数化策略，在无梯度神经拓扑优化中实现了迭代次数的显著降低，这将开辟一个新的解决路径。

    

    无梯度优化器可以解决问题，无论其目标函数的平滑性或可微性如何，但与基于梯度的算法相比，它们需要更多的迭代才能收敛。这使得它们在拓扑优化中不可行，因为每次迭代的计算成本高，并且问题的维度也很高。我们提出了一种预训练的神经重新参数化策略，当在潜在空间优化设计时，迭代次数至少减少一个数量级，与传统方法不使用潜在重新参数化相比。我们通过对训练数据进行广泛的计算实验，在内部和外部分布中证明了这一点。尽管基于梯度的拓扑优化对于可微的问题，例如结构的合规性优化，仍然更有效，但我们相信这项工作将为那些需要无梯度方法的问题开辟新的道路。

    arXiv:2403.04937v1 Announce Type: new  Abstract: Gradient-free optimizers allow for tackling problems regardless of the smoothness or differentiability of their objective function, but they require many more iterations to converge when compared to gradient-based algorithms. This has made them unviable for topology optimization due to the high computational cost per iteration and high dimensionality of these problems. We propose a pre-trained neural reparameterization strategy that leads to at least one order of magnitude decrease in iteration count when optimizing the designs in latent space, as opposed to the conventional approach without latent reparameterization. We demonstrate this via extensive computational experiments in- and out-of-distribution with the training data. Although gradient-based topology optimization is still more efficient for differentiable problems, such as compliance optimization of structures, we believe this work will open up a new path for problems where gra
    
[^68]: 关于神经算法推理的马尔可夫性质：分析与方法

    On the Markov Property of Neural Algorithmic Reasoning: Analyses and Methods

    [https://arxiv.org/abs/2403.04929](https://arxiv.org/abs/2403.04929)

    本研究提出了ForgetNet和G-ForgetNet，通过不使用历史嵌入和引入门控机制来解决神经算法推理中的马尔可夫性质矛盾，提供了有价值的计算路径。

    

    神经算法推理是一种新兴的研究方向，赋予神经网络模仿算法执行逐步进行的能力。现有设计中的一个常见范式涉及使用历史嵌入来预测未来执行步骤的结果。本文的观察是，这种历史依赖本质上与算法推理任务的马尔可夫性质相矛盾。基于这一动机，我们提出了我们的ForgetNet，它不使用历史嵌入，因此与任务的马尔可夫性质一致。为了解决ForgetNet在早期阶段训练中的挑战，我们进一步引入了G-ForgetNet，它使用门控机制允许有选择性地整合历史嵌入。这种增强的能力在模型的早期训练阶段提供了有价值的计算路径。我们进行了大量实验，基于CLRS-30算法推理

    arXiv:2403.04929v1 Announce Type: cross  Abstract: Neural algorithmic reasoning is an emerging research direction that endows neural networks with the ability to mimic algorithmic executions step-by-step. A common paradigm in existing designs involves the use of historical embeddings in predicting the results of future execution steps. Our observation in this work is that such historical dependence intrinsically contradicts the Markov nature of algorithmic reasoning tasks. Based on this motivation, we present our ForgetNet, which does not use historical embeddings and thus is consistent with the Markov nature of the tasks. To address challenges in training ForgetNet at early stages, we further introduce G-ForgetNet, which uses a gating mechanism to allow for the selective integration of historical embeddings. Such an enhanced capability provides valuable computational pathways during the model's early training phase. Our extensive experiments, based on the CLRS-30 algorithmic reasoning
    
[^69]: 使用数据增强控制为基础的图嵌入进行对比学习

    Control-based Graph Embeddings with Data Augmentation for Contrastive Learning

    [https://arxiv.org/abs/2403.04923](https://arxiv.org/abs/2403.04923)

    本文提出了一种利用图的控制属性进行数据增强的对比学习框架，相比现有方法，提高了对比学习框架的有效性。

    

    在本文中，我们研究了利用动态网络在图上的控制属性来进行无监督图表示学习的问题。我们的方法引入了一种新颖的对比学习框架，这是一种广泛存在的无监督表示学习技术。对比学习中的一个关键步骤是从输入图创建“增强”图。虽然与原始图不同，这些增强图保留了原始图的结构特征。我们提出了一种独特的方法，通过利用网络的控制属性生成这些增强图。核心概念围绕着对原始图进行扰动以创建一个新图，同时保留特定于网络和图的可控特性。与现有方法相比，我们展示了这种创新方法如何增强了对比学习框架的有效性。

    arXiv:2403.04923v1 Announce Type: new  Abstract: In this paper, we study the problem of unsupervised graph representation learning by harnessing the control properties of dynamical networks defined on graphs. Our approach introduces a novel framework for contrastive learning, a widely prevalent technique for unsupervised representation learning. A crucial step in contrastive learning is the creation of 'augmented' graphs from the input graphs. Though different from the original graphs, these augmented graphs retain the original graph's structural characteristics. Here, we propose a unique method for generating these augmented graphs by leveraging the control properties of networks. The core concept revolves around perturbing the original graph to create a new one while preserving the controllability properties specific to networks and graphs. Compared to the existing methods, we demonstrate that this innovative approach enhances the effectiveness of contrastive learning frameworks, lea
    
[^70]: 鉴别功能依赖下的因果效应

    Identifying Causal Effects Under Functional Dependencies

    [https://arxiv.org/abs/2403.04919](https://arxiv.org/abs/2403.04919)

    本文研究了在已知某些变量由它们的父节点功能决定的情况下，如何识别因果效应，在这种情况下可以使得一些不可识别的因果效应变得可识别，并且可以在不影响因果效应可识别性的情况下排除观测到的功能性变量，从而显著减少需要的观测数据中的变量数量。

    

    我们研究了因果效应的识别，受两个改进的启发，可以在已知因果图中某些变量是由它们的父节点功能决定的情况下实现。第一，当某些变量是功能的时，一个不可识别的因果效应可能变得可识别。第二，可以排除观测某些功能变量而不影响因果效应的可识别性，这可能会显著减少需要的观测数据中的变量数量。我们的结果在很大程度上基于一个排除过程，该过程从因果图中删除功能变量，同时保留结果因果图中的关键属性，包括因果效应的可识别性。

    arXiv:2403.04919v1 Announce Type: new  Abstract: We study the identification of causal effects, motivated by two improvements to identifiability which can be attained if one knows that some variables in a causal graph are functionally determined by their parents (without needing to know the specific functions). First, an unidentifiable causal effect may become identifiable when certain variables are functional. Second, certain functional variables can be excluded from being observed without affecting the identifiability of a causal effect, which may significantly reduce the number of needed variables in observational data. Our results are largely based on an elimination procedure which removes functional variables from a causal graph while preserving key properties in the resulting causal graph, including the identifiability of causal effects.
    
[^71]: 使用有条件可逆神经网络优化视网膜假体刺激

    Optimizing Retinal Prosthetic Stimuli with Conditional Invertible Neural Networks

    [https://arxiv.org/abs/2403.04884](https://arxiv.org/abs/2403.04884)

    利用有条件可逆神经网络无监督优化视网膜假体刺激，提高了电极阵列的刺激效果。

    

    可植入的视网膜假体为通过绕过视网膜中损坏的光感受细胞并直接刺激剩余功能性视网膜细胞来恢复部分视力提供了一个有希望的解决方案。然而，摄像头和视网膜细胞之间的信息传输通常受限于电极阵列的低分辨率和对不同节细胞类型的特异性不足，导致刺激效果不佳。在这项工作中，我们提出利用基于归一化流的有条件可逆神经网络以无监督的方式优化视网膜假体刺激。这些网络的可逆性使我们能够将它们用作视觉系统的计算模型的替代，并将输入摄像头信号编码为电极阵列上优化的电刺激。与其他方法相比，如简单的降采样、线性模型和前馈卷积神经网络

    arXiv:2403.04884v1 Announce Type: cross  Abstract: Implantable retinal prostheses offer a promising solution to restore partial vision by circumventing damaged photoreceptor cells in the retina and directly stimulating the remaining functional retinal cells. However, the information transmission between the camera and retinal cells is often limited by the low resolution of the electrode array and the lack of specificity for different ganglion cell types, resulting in suboptimal stimulations. In this work, we propose to utilize normalizing flow-based conditional invertible neural networks to optimize retinal implant stimulation in an unsupervised manner. The invertibility of these networks allows us to use them as a surrogate for the computational model of the visual system, while also encoding input camera signals into optimized electrical stimuli on the electrode array. Compared to other methods, such as trivial downsampling, linear models, and feed-forward convolutional neural networ
    
[^72]: 使用可分离高斯神经网络学习行波孤波

    Learning Traveling Solitary Waves Using Separable Gaussian Neural Networks

    [https://arxiv.org/abs/2403.04883](https://arxiv.org/abs/2403.04883)

    该论文提出了一种新颖的可解释神经网络架构 SGNN，用于学习跨越不同家族的偏微分方程的行波孤波，并解决了传统PINNs在大型计算域中的传播失败问题。

    

    在本文中，我们应用机器学习方法来学习跨越各种偏微分方程家族的行波孤波。我们的方法将一种新颖的可解释神经网络（NN）架构，称为可分离高斯神经网络（SGNN），集成到物理信息神经网络（PINNs）框架中。与传统的PINNs将空间和时间数据视为独立输入不同，本方法利用波特性将数据转换为所谓的共行波框架。这种适应有效地解决了将PINNs应用于大型计算域时出现的传播失败问题。在此，SGNN架构展示了对（1+1）维、$b$-家族的PDE中的单峰、多峰和定常解的强大逼近能力。此外，我们扩展了我们的调查，并不仅探索了$ab$-fa

    arXiv:2403.04883v1 Announce Type: cross  Abstract: In this paper, we apply a machine-learning approach to learn traveling solitary waves across various families of partial differential equations (PDEs). Our approach integrates a novel interpretable neural network (NN) architecture, called Separable Gaussian Neural Networks (SGNN) into the framework of Physics-Informed Neural Networks (PINNs). Unlike the traditional PINNs that treat spatial and temporal data as independent inputs, the present method leverages wave characteristics to transform data into the so-called co-traveling wave frame. This adaptation effectively addresses the issue of propagation failure in PINNs when applied to large computational domains. Here, the SGNN architecture demonstrates robust approximation capabilities for single-peakon, multi-peakon, and stationary solutions within the (1+1)-dimensional, $b$-family of PDEs. In addition, we expand our investigations, and explore not only peakon solutions in the $ab$-fa
    
[^73]: 通过注意力 Kronecker 分解实现高分辨率时间序列分类的高效性

    Efficient High-Resolution Time Series Classification via Attention Kronecker Decomposition

    [https://arxiv.org/abs/2403.04882](https://arxiv.org/abs/2403.04882)

    通过引入Kronecker分解的注意力， Hierarchical attention-based Kronecker-decomposition for high-resolution time series classification.

    

    高分辨率时间序列分类问题由于各个领域中详细时间数据不断增加而变得至关重要。为了有效应对这一挑战，关键在于当前最先进的注意力模型能够在高分辨率时间序列数据中处理逐渐增长的序列长度，并且展现出在处理这类数据中普遍存在的噪声时的鲁棒性。为了解决这一问题，我们建议根据交互范围将长时间序列分层编码为多个层级。通过在不同层级捕获关系，我们可以构建更加鲁棒、表达丰富和高效的模型，能够捕捉数据中的短期波动和长期趋势。然后，我们提出了一种新的时间序列变换器骨干（KronTime），通过引入 Kronecker 分解的注意力来处理这种多层次时间序列。

    arXiv:2403.04882v1 Announce Type: new  Abstract: The high-resolution time series classification problem is essential due to the increasing availability of detailed temporal data in various domains. To tackle this challenge effectively, it is imperative that the state-of-the-art attention model is scalable to accommodate the growing sequence lengths typically encountered in high-resolution time series data, while also demonstrating robustness in handling the inherent noise prevalent in such datasets. To address this, we propose to hierarchically encode the long time series into multiple levels based on the interaction ranges. By capturing relationships at different levels, we can build more robust, expressive, and efficient models that are capable of capturing both short-term fluctuations and long-term trends in the data. We then propose a new time series transformer backbone (KronTime) by introducing Kronecker-decomposed attention to process such multi-level time series, which sequenti
    
[^74]: 用强化学习将GPTRec与超出准确性目标对齐

    Aligning GPTRec with Beyond-Accuracy Goals with Reinforcement Learning

    [https://arxiv.org/abs/2403.04875](https://arxiv.org/abs/2403.04875)

    GPTRec模型使用Next-K策略来生成推荐，与传统的Top-K模型不同，可以更好地考虑超出准确性指标的复杂项目间相互依赖性。

    

    Transformer模型的改编，如BERT4Rec和SASRec，在顺序推荐任务中取得了 accuracy-based 指标，如NDCG方面的最先进性能。这些模型将项目视为标记，然后利用评分-排名方法（Top-K策略），其中模型首先计算项目得分，然后根据此分数对其进行排名。虽然该方法对于准确性指标效果很好，但很难将其用于优化更复杂的超出准确性指标，如多样性。最近，提出了使用不同 Next-K 策略的GPTRec模型，作为Top-K模型的替代方案。与传统的Top-K推荐相比，Next-K会逐个项目生成推荐，因此，可以考虑超出准确性指标中重要的复杂项目间相互依赖性。

    arXiv:2403.04875v1 Announce Type: cross  Abstract: Adaptations of Transformer models, such as BERT4Rec and SASRec, achieve state-of-the-art performance in the sequential recommendation task according to accuracy-based metrics, such as NDCG. These models treat items as tokens and then utilise a score-and-rank approach (Top-K strategy), where the model first computes item scores and then ranks them according to this score. While this approach works well for accuracy-based metrics, it is hard to use it for optimising more complex beyond-accuracy metrics such as diversity. Recently, the GPTRec model, which uses a different Next-K strategy, has been proposed as an alternative to the Top-K models. In contrast with traditional Top-K recommendations, Next-K generates recommendations item-by-item and, therefore, can account for complex item-to-item interdependencies important for the beyond-accuracy measures. However, the original GPTRec paper focused only on accuracy in experiments and needed 
    
[^75]: 组隐私放大和子抽样的Rényi差分隐私统一放大

    Group Privacy Amplification and Unified Amplification by Subsampling for R\'enyi Differential Privacy

    [https://arxiv.org/abs/2403.04867](https://arxiv.org/abs/2403.04867)

    该论文提出了一个统一的框架，用于为Rényi-DP推导通过子抽样的放大保证，这是首个针对隐私核算方法的框架，也具有独立的重要性。

    

    差分隐私(DP)具有多种理想属性，如对后处理的鲁棒性、组隐私和通过子抽样放大，这些属性可以相互独立推导。我们的目标是确定是否通过联合考虑这些属性中的多个可以获得更强的隐私保证。为此，我们专注于组隐私和通过子抽样放大的组合。为了提供适合机器学习算法的保证，我们在Rényi-DP框架中进行了分析，这比$(\epsilon,\delta)$-DP具有更有利的组合属性。作为这个分析的一部分，我们开发了一个统一的框架，用于为Rényi-DP推导通过子抽样的放大保证，这是首个针对隐私核算方法的框架，也具有独立的重要性。我们发现，它不仅让我们改进和泛化现有的放大结果。

    arXiv:2403.04867v1 Announce Type: cross  Abstract: Differential privacy (DP) has various desirable properties, such as robustness to post-processing, group privacy, and amplification by subsampling, which can be derived independently of each other. Our goal is to determine whether stronger privacy guarantees can be obtained by considering multiple of these properties jointly. To this end, we focus on the combination of group privacy and amplification by subsampling. To provide guarantees that are amenable to machine learning algorithms, we conduct our analysis in the framework of R\'enyi-DP, which has more favorable composition properties than $(\epsilon,\delta)$-DP. As part of this analysis, we develop a unified framework for deriving amplification by subsampling guarantees for R\'enyi-DP, which represents the first such framework for a privacy accounting method and is of independent interest. We find that it not only lets us improve upon and generalize existing amplification results 
    
[^76]: 大乐透假设综述

    A Survey of Lottery Ticket Hypothesis

    [https://arxiv.org/abs/2403.04861](https://arxiv.org/abs/2403.04861)

    大乐透假设指出神经网络中存在稀疏子网络，训练孤立子网络可以获得更好性能，调查综述了LTH现状并提出未来研究方向

    

    大乐透假设(LTH)指出，稠密神经网络模型包含一个高度稀疏的子网络（即，中奖票），当以孤立方式训练时，可以实现比原始模型更好的性能。尽管LTH在许多研究中已经在经验和理论上得到证实，但仍然存在一些需要解决的开放问题，例如效率和可扩展性。此外，缺乏开源框架和一致的实验设置对LTH未来研究提出了挑战。我们首次从不同角度审视以往关于LTH的研究和研究。我们还讨论了现有研究中的问题，并列出了进一步探索的潜在方向。这项调查旨在深入了解LTH的现状，并开发一个得到妥善维护的平台，用于进行实验并与最新基线进行比较。

    arXiv:2403.04861v1 Announce Type: new  Abstract: The Lottery Ticket Hypothesis (LTH) states that a dense neural network model contains a highly sparse subnetwork (i.e., winning tickets) that can achieve even better performance than the original model when trained in isolation. While LTH has been proved both empirically and theoretically in many works, there still are some open issues, such as efficiency and scalability, to be addressed. Also, the lack of open-source frameworks and consensual experimental setting poses a challenge to future research on LTH. We, for the first time, examine previous research and studies on LTH from different perspectives. We also discuss issues in existing works and list potential directions for further exploration. This survey aims to provide an in-depth look at the state of LTH and develop a duly maintained platform to conduct experiments and compare with the most updated baselines.
    
[^77]: 使用未训练的神经网络在基于模型的架构中解决模型不匹配的反问题

    Solving Inverse Problems with Model Mismatch using Untrained Neural Networks within Model-based Architectures

    [https://arxiv.org/abs/2403.04847](https://arxiv.org/abs/2403.04847)

    提出了一种在基于模型架构中使用未经训练的神经网络来解决模型不匹配的方法，证明了其在一定条件下的收敛性能

    

    基于模型的深度学习方法，如“展开迭代”（LU）和“深度平衡模型”（DEQ）扩展，在解决反问题（IP）方面表现出色。这些方法将优化迭代展开为一系列神经网络，实际上从数据中学习正则化函数。尽管这些架构目前在许多应用中处于最前沿，但它们的成功在很大程度上取决于正向模型的准确性。这一假设可能在许多物理应用中受限于模型简化或仪器不确定性。为解决正向模型不匹配问题，我们在基于模型的架构中引入了一个未经训练的正向模型残差块，以匹配每个实例在测量域中的数据一致性。我们在已知的基于模型的架构（LU和DEQ）中提出了两种变体，并证明在较轻的条件下收敛。实验表明显著

    arXiv:2403.04847v1 Announce Type: new  Abstract: Model-based deep learning methods such as \emph{loop unrolling} (LU) and \emph{deep equilibrium model} (DEQ) extensions offer outstanding performance in solving inverse problems (IP). These methods unroll the optimization iterations into a sequence of neural networks that in effect learn a regularization function from data. While these architectures are currently state-of-the-art in numerous applications, their success heavily relies on the accuracy of the forward model. This assumption can be limiting in many physical applications due to model simplifications or uncertainties in the apparatus. To address forward model mismatch, we introduce an untrained forward model residual block within the model-based architecture to match the data consistency in the measurement domain for each instance. We propose two variants in well-known model-based architectures (LU and DEQ) and prove convergence under mild conditions. The experiments show signi
    
[^78]: UniTable: 朝向通过自监督预训练实现表结构识别的统一框架

    UniTable: Towards a Unified Framework for Table Structure Recognition via Self-Supervised Pretraining

    [https://arxiv.org/abs/2403.04822](https://arxiv.org/abs/2403.04822)

    UniTable 提出了一个统一框架，通过自监督预训练实现表结构识别，将不同的任务和目标统一到语言建模中，在四个最大的TSR数据集上表现出最先进的性能。

    

    表格传达由人类创建的隐式约定的事实和数量数据，这往往是机器难以解析的。以往关于表结构识别（TSR）的工作主要集中在利用可用输入和工具的复杂特定任务组合上。我们提出了UniTable，这是一个统一TSR的训练框架，其训练范式结合了纯粹像素级输入的简单性以及来自各种未注释表格图像的自监督预训练（SSP）赋予的有效性和可伸缩性。我们的框架将所有三个TSR任务的训练目标 - 提取表结构，单元格内容和单元格边界框（bbox） - 统一为一个统一的与任务无关的训练目标：语言建模。广泛的定量和定性分析突显了UniTable在四个最大的TSR数据集上的最先进性能。

    arXiv:2403.04822v1 Announce Type: cross  Abstract: Tables convey factual and quantitative data with implicit conventions created by humans that are often challenging for machines to parse. Prior work on table structure recognition (TSR) has mainly centered around complex task-specific combinations of available inputs and tools. We present UniTable, a training framework that unifies both the training paradigm and training objective of TSR. Its training paradigm combines the simplicity of purely pixel-level inputs with the effectiveness and scalability empowered by self-supervised pretraining (SSP) from diverse unannotated tabular images. Our framework unifies the training objectives of all three TSR tasks - extracting table structure, cell content, and cell bounding box (bbox) - into a unified task-agnostic training objective: language modeling. Extensive quantitative and qualitative analyses highlight UniTable's state-of-the-art (SOTA) performance on four of the largest TSR datasets. T
    
[^79]: 利用基于LSTM的机器学习提高飓风风暴潮建模在人工智能时代的准确性

    Storm Surge Modeling in the AI ERA: Using LSTM-based Machine Learning for Enhancing Forecasting Accuracy

    [https://arxiv.org/abs/2403.04818](https://arxiv.org/abs/2403.04818)

    利用基于LSTM的机器学习模型，通过预测物理模型的系统误差来改善飓风风暴潮模型的预测准确性。

    

    自然过程的物理模拟结果通常无法完全捕捉现实世界，主要原因是受到物理过程模拟的限制以及准确性的影响。本文提出并分析了利用基于LSTM的深度学习网络机器学习架构来捕捉和预测飓风事件期间来自测站的实际水位观测与风暴潮预测模型的系统误差行为。本工作的总体目标是预测物理模型的系统误差，并利用其来事后提高模拟结果的准确性。我们在美国沿海地区的61场历史风暴数据集上训练了提出的机器学习模型，并测试了其在校正飓风伊恩（2022年）模拟水位数据预测方面的表现。我们展示了我们的模型可以持续地提高预测准确性。

    arXiv:2403.04818v1 Announce Type: new  Abstract: Physics simulation results of natural processes usually do not fully capture the real world. This is caused for instance by limits in what physical processes are simulated and to what accuracy. In this work we propose and analyze the use of an LSTM-based deep learning network machine learning (ML) architecture for capturing and predicting the behavior of the systemic error for storm surge forecast models with respect to real-world water height observations from gauge stations during hurricane events. The overall goal of this work is to predict the systemic error of the physics model and use it to improve the accuracy of the simulation results post factum. We trained our proposed ML model on a dataset of 61 historical storms in the coastal regions of the U.S. and we tested its performance in bias correcting modeled water level data predictions from hurricane Ian (2022). We show that our model can consistently improve the forecasting accur
    
[^80]: 在句法感知代码填空任务上评估LLMs

    Evaluation of LLMs on Syntax-Aware Code Fill-in-the-Middle Tasks

    [https://arxiv.org/abs/2403.04814](https://arxiv.org/abs/2403.04814)

    该研究引入了一个新的基准SAFIM用于评估LLMs在代码填空任务上的句法感知完成表现，发现FIM预训练不仅提高了FIM的熟练度，还改善了LLMs的左到右推理，挑战了传统观念并表明预训练方法和数据品质对模型性能的影响更甚于模型大小。

    

    我们介绍了一种名为Syntax-Aware Fill-In-the-Middle（SAFIM）的新基准，用于评估大型语言模型（LLMs）在代码填空（FIM）任务上的表现。该基准侧重于程序结构的句法感知完成，如代码块和条件表达式，并包括来自多种编程语言的17,720个示例，来源于2022年4月之后的最新代码提交，以最小化数据污染。 SAFIM提供了一个强大的框架，具有各种提示设计和新颖的句法感知后处理技术，有助于在LLMs之间进行准确和公平的比较。我们对15个LLMs进行了全面评估，结果表明FIM预训练不仅提升了FIM的熟练程度，还改进了LLMs的左到右（L2R）推理。我们的发现挑战了传统观念，并表明预训练方法和数据质量对模型性能的影响大于模型大小。因此，SAFIM为未来构建

    arXiv:2403.04814v1 Announce Type: cross  Abstract: We introduce Syntax-Aware Fill-In-the-Middle (SAFIM), a new benchmark for evaluating Large Language Models (LLMs) on the code Fill-in-the-Middle (FIM) task. This benchmark focuses on syntax-aware completions of program structures such as code blocks and conditional expressions, and includes 17,720 examples from multiple programming languages, sourced from recent code submissions after April 2022 to minimize data contamination. SAFIM provides a robust framework with various prompt designs and novel syntax-aware post-processing techniques, facilitating accurate and fair comparisons across LLMs. Our comprehensive evaluation of 15 LLMs shows that FIM pretraining not only enhances FIM proficiency but also improves Left-to-Right (L2R) inference using LLMs. Our findings challenge conventional beliefs and suggest that pretraining methods and data quality have more impact than model size. SAFIM thus serves as a foundational platform for future 
    
[^81]: 基于 Shapley 的视觉分析方法 TrafPS 用于解释交通流量

    TrafPS: A Shapley-based Visual Analytics Approach to Interpret Traffic

    [https://arxiv.org/abs/2403.04812](https://arxiv.org/abs/2403.04812)

    提出了 TrafPS，一种基于 Shapley 的视觉分析方法，用于解释交通预测结果，支持交通管理和城市规划中的决策制定。

    

    最近深度学习（DL）取得的成就展示了其在预测交通流量方面的潜力。这些预测有助于理解情况并在交通控制中做出决策。然而，大多数先进的DL模型被认为是“黑盒子”，对于终端用户来说基本没有透明度，无法了解底层机制。一些先前的工作尝试“打开黑盒子”并增加生成预测的可解释性。然而，处理大规模时空数据上的复杂模型并发现显著影响交通流量的关键空间和时间模式仍然具有挑战性。为了克服这些挑战，我们提出了 TrafPS，一种用于解释交通预测结果的视觉分析方法，以支持交通管理和城市规划中的决策制定。测量方法，区域 SHAP 和轨迹 SHAP，被提出来量化影响

    arXiv:2403.04812v1 Announce Type: new  Abstract: Recent achievements in deep learning (DL) have shown its potential for predicting traffic flows. Such predictions are beneficial for understanding the situation and making decisions in traffic control. However, most state-of-the-art DL models are considered "black boxes" with little to no transparency for end users with respect to the underlying mechanisms. Some previous work tried to "open the black boxes" and increase the interpretability of how predictions are generated. However, it still remains challenging to handle complex models on large-scale spatio-temporal data and discover salient spatial and temporal patterns that significantly influence traffic flows. To overcome the challenges, we present TrafPS, a visual analytics approach for interpreting traffic prediction outcomes to support decision-making in traffic management and urban planning. The measurements, region SHAP and trajectory SHAP, are proposed to quantify the impact of
    
[^82]: 量化污染评估语言模型的代码生成能力

    Quantifying Contamination in Evaluating Code Generation Capabilities of Language Models

    [https://arxiv.org/abs/2403.04811](https://arxiv.org/abs/2403.04811)

    研究量化了流行的代码生成基准测试的数据污染程度，揭示了它们与预训练语料库之间的重叠，并展示模型的显著性能重叠。

    

    尽管大型语言模型在各种代码生成基准测试中取得了显著的性能，但人们对这些基准测试的潜在污染日益关注，因为它们可能泄漏到预训练和微调数据中。本文对流行的代码生成基准测试进行了全面研究，准确量化了它们与预训练语料库之间的重叠，通过表面级和语义级匹配。在我们的实验中，我们展示了流行的代码生成基准测试与公开训练语料库之间存在重叠，并且模型表现显着。

    arXiv:2403.04811v1 Announce Type: cross  Abstract: While large language models have achieved remarkable performance on various code generation benchmarks, there have been growing concerns regarding potential contamination of these benchmarks as they may be leaked into pretraining and finetuning data. While recent work has investigated contamination in natural language generation and understanding tasks, there has been less extensive research into how data contamination impacts the evaluation of code generation, which is critical for understanding the robustness and reliability of LLMs in programming contexts. In this work, we perform a comprehensive study of data contamination of popular code generation benchmarks, and precisely quantify their overlap with pretraining corpus through both surface-level and semantic-level matching. In our experiments, we show that there are substantial overlap between popular code generation benchmarks and open training corpus, and models perform signifi
    
[^83]: 限制贝叶斯神经网络

    Restricted Bayesian Neural Network

    [https://arxiv.org/abs/2403.04810](https://arxiv.org/abs/2403.04810)

    本研究提出了限制贝叶斯神经网络的新架构，显著减少了网络存储空间复杂性，并引入了一种能够有效处理不确定性的算法，确保在目标函数缺乏完美凸性时稳健地收敛至全局最优解。

    

    现代深度学习工具在解决复杂问题方面非常有效。然而，它们作为黑盒模型的运行方式增加了预测的不确定性。此外，它们面临着各种挑战，包括在大型网络中需要大量存储空间、过拟合、欠拟合、梯度消失等问题。本研究探讨了贝叶斯神经网络的概念，提出了一种能够显著减少网络存储空间复杂性的新型架构。此外，我们介绍了一种能够有效处理不确定性的算法，确保稳健的收敛值，避免陷入局部最优解，尤其是当目标函数缺乏完美的凸性时。

    arXiv:2403.04810v1 Announce Type: cross  Abstract: Modern deep learning tools are remarkably effective in addressing intricate problems. However, their operation as black-box models introduces increased uncertainty in predictions. Additionally, they contend with various challenges, including the need for substantial storage space in large networks, issues of overfitting, underfitting, vanishing gradients, and more. This study explores the concept of Bayesian Neural Networks, presenting a novel architecture designed to significantly alleviate the storage space complexity of a network. Furthermore, we introduce an algorithm adept at efficiently handling uncertainties, ensuring robust convergence values without becoming trapped in local optima, particularly when the objective function lacks perfect convexity.
    
[^84]: 研究合成训练数据对终端条对象检测工业应用的影响

    Investigation of the Impact of Synthetic Training Data in the Industrial Application of Terminal Strip Object Detection

    [https://arxiv.org/abs/2403.04809](https://arxiv.org/abs/2403.04809)

    本文研究了标准物体检测器在复杂的工业终端条对象检测应用中的模拟到真实泛化性能。

    

    在工业制造中，存在许多检查或检测特定对象的任务，目前这些任务通常由人工或经典图像处理方法执行。因此，在工业环境引入最新的深度学习模型有可能提高生产效率并实现新的应用。然而，收集和标记足够的数据通常是困难的，这使得这类项目的实施变得复杂。因此，图像合成方法通常用于从3D模型生成合成训练数据，并自动标注这些数据，尽管这会导致一个模拟到真实领域差距。本文研究了标准物体检测器在复杂的工业终端条对象检测应用中的模拟到真实泛化性能。通过结合领域随机化和领域知识，我们创建了一个图像合成流水线，用于自动生成训练数据。

    arXiv:2403.04809v1 Announce Type: cross  Abstract: In industrial manufacturing, numerous tasks of visually inspecting or detecting specific objects exist that are currently performed manually or by classical image processing methods. Therefore, introducing recent deep learning models to industrial environments holds the potential to increase productivity and enable new applications. However, gathering and labeling sufficient data is often intractable, complicating the implementation of such projects. Hence, image synthesis methods are commonly used to generate synthetic training data from 3D models and annotate them automatically, although it results in a sim-to-real domain gap. In this paper, we investigate the sim-to-real generalization performance of standard object detectors on the complex industrial application of terminal strip object detection. Combining domain randomization and domain knowledge, we created an image synthesis pipeline for automatically generating the training da
    
[^85]: WaterMax: 打破LLM水印可检测性-稳健性-质量的平衡

    WaterMax: breaking the LLM watermark detectability-robustness-quality trade-off

    [https://arxiv.org/abs/2403.04808](https://arxiv.org/abs/2403.04808)

    WaterMax提出了一种新的水印方案，能够在保持生成文本质量的同时实现高检测性能，打破了水印技术中质量和稳健性之间的传统平衡。

    

    水印是阻止大型语言模型被恶意使用的技术手段。本文提出了一种称为WaterMax的新颖水印方案，具有高检测性能，同时保持原始LLM生成文本的质量。其新设计不会对LLM进行任何修改（不调整权重、对数、温度或采样技术）。WaterMax平衡了稳健性和复杂性，与文献中的水印技术相反，从根本上引发了质量和稳健性之间的平衡。其性能在理论上得到证明并经过实验证实。在最全面的基准测试套件下，它胜过所有的最先进技术。

    arXiv:2403.04808v1 Announce Type: cross  Abstract: Watermarking is a technical means to dissuade malfeasant usage of Large Language Models. This paper proposes a novel watermarking scheme, so-called WaterMax, that enjoys high detectability while sustaining the quality of the generated text of the original LLM. Its new design leaves the LLM untouched (no modification of the weights, logits, temperature, or sampling technique). WaterMax balances robustness and complexity contrary to the watermarking techniques of the literature inherently provoking a trade-off between quality and robustness. Its performance is both theoretically proven and experimentally validated. It outperforms all the SotA techniques under the most complete benchmark suite.
    
[^86]: 神经网络的数学（研究生课程讲义）

    Mathematics of Neural Networks (Lecture Notes Graduate Course)

    [https://arxiv.org/abs/2403.04807](https://arxiv.org/abs/2403.04807)

    该课程旨在向研究生数学专业的学生介绍神经网络并激发兴趣，主要内容包括深度学习的数学介绍和将李群理论应用于设计具有几何等变性的神经网络，讲义及编码教程公开可获取

    

    这些是我在2021年至2023年在埃因霍温科技大学教授的同名课程的讲义。该课程旨在向研究生数学专业的学生介绍神经网络，并旨在激发数学学生对进一步研究神经网络感兴趣。课程分为两部分：首先是关于深度学习的一般介绍，侧重于以形式化数学方式介绍该领域。第二部分介绍李群和同态空间的理论，以及如何将其应用于设计具有理想几何等变性的神经网络。讲义尽可能自包含，以便对具有一定数学背景的任何学生都可以理解。该课程还包括一系列Jupyter笔记本形式的编码教程和作业，可在https://g上公开获取

    arXiv:2403.04807v1 Announce Type: cross  Abstract: These are the lecture notes that accompanied the course of the same name that I taught at the Eindhoven University of Technology from 2021 to 2023. The course is intended as an introduction to neural networks for mathematics students at the graduate level and aims to make mathematics students interested in further researching neural networks. It consists of two parts: first a general introduction to deep learning that focuses on introducing the field in a formal mathematical way. The second part provides an introduction to the theory of Lie groups and homogeneous spaces and how it can be applied to design neural networks with desirable geometric equivariances. The lecture notes were made to be as self-contained as possible so as to accessible for any student with a moderate mathematics background. The course also included coding tutorials and assignments in the form of a set of Jupyter notebooks that are publicly available at https://g
    
[^87]: 不是所有的票据都是平等的，而我们知道：用领域特定知识来引导修剪

    Not all tickets are equal and we know it: Guiding pruning with domain-specific knowledge

    [https://arxiv.org/abs/2403.04805](https://arxiv.org/abs/2403.04805)

    使用领域特定结构信息来引导修剪的方法 DASH 在学习动态基因调控网络模型时表现出色，提供了更有意义的生物学见解

    

    神经结构学习对于科学发现和可解释性至关重要。然而，当代侧重于计算资源效率的修剪算法在选择符合领域专业知识的有意义模型方面面临算法障碍。为了减轻这一挑战，我们提出了DASH，利用可用的领域特定结构信息来引导修剪。在学习动态基因调控网络模型的背景下，我们展示了DASH与现有一般知识相结合，提供了与生物学一致的数据特定见解。对于这一任务，我们展示了在具有地面真实信息的合成数据和两个真实世界应用中，DASH的有效性，其优于竞争方法很大，并提供了更有意义的生物学见解。我们的工作表明，领域特定的结构信息具有提高模型衍生科学洞见的潜力。

    arXiv:2403.04805v1 Announce Type: new  Abstract: Neural structure learning is of paramount importance for scientific discovery and interpretability. Yet, contemporary pruning algorithms that focus on computational resource efficiency face algorithmic barriers to select a meaningful model that aligns with domain expertise. To mitigate this challenge, we propose DASH, which guides pruning by available domain-specific structural information. In the context of learning dynamic gene regulatory network models, we show that DASH combined with existing general knowledge on interaction partners provides data-specific insights aligned with biology. For this task, we show on synthetic data with ground truth information and two real world applications the effectiveness of DASH, which outperforms competing methods by a large margin and provides more meaningful biological insights. Our work shows that domain specific structural information bears the potential to improve model-derived scientific insi
    
[^88]: AttentionStitch：关注如何解决语音编辑问题

    AttentionStitch: How Attention Solves the Speech Editing Problem

    [https://arxiv.org/abs/2403.04804](https://arxiv.org/abs/2403.04804)

    AttentionStitch模型通过引入双注意力块网络，并将编辑文本的mel频谱图与合成的mel频谱图自动融合，实现了语音编辑的无缝整合。

    

    自然高质量的语音生成是自然语言处理领域中一个具有挑战性的问题。除了语音生成之外，语音编辑也是一个关键任务，需要将编辑后的语音无缝、不易察觉地整合到合成语音中。我们提出了一种新颖的语音编辑方法，利用预训练的文本到语音（TTS）模型，如FastSpeech 2，并在其之上加入双注意力块网络，以自动将合成的mel频谱图与编辑文本的mel频谱图融合在一起。我们将这个模型称为AttentionStitch，因为它利用注意力来将音频样本拼接在一起。我们在单个和多个说话者数据集（LJSpeech和VCTK）上对所提出的AttentionStitch模型与最先进的基线模型进行评估。通过客观和主观评估测试，我们证明了其优越的性能。

    arXiv:2403.04804v1 Announce Type: cross  Abstract: The generation of natural and high-quality speech from text is a challenging problem in the field of natural language processing. In addition to speech generation, speech editing is also a crucial task, which requires the seamless and unnoticeable integration of edited speech into synthesized speech. We propose a novel approach to speech editing by leveraging a pre-trained text-to-speech (TTS) model, such as FastSpeech 2, and incorporating a double attention block network on top of it to automatically merge the synthesized mel-spectrogram with the mel-spectrogram of the edited text. We refer to this model as AttentionStitch, as it harnesses attention to stitch audio samples together. We evaluate the proposed AttentionStitch model against state-of-the-art baselines on both single and multi-speaker datasets, namely LJSpeech and VCTK. We demonstrate its superior performance through an objective and a subjective evaluation test involving 1
    
[^89]: 通过自适应共识验证模型更新，增强联邦学习的安全性

    Enhancing Security in Federated Learning through Adaptive Consensus-Based Model Update Validation

    [https://arxiv.org/abs/2403.04803](https://arxiv.org/abs/2403.04803)

    通过自适应阈值机制和共识验证流程，增强了联邦学习系统对标签翻转攻击的安全性，有效减轻了攻击并提升系统的弹性。

    

    本文介绍了一种先进的方法，用于加强联邦学习（FL）系统抵御标签翻转攻击。我们提出了一个简化的基于共识的验证流程，结合自适应阈值机制。这种动态阈值设计旨在根据模型更新的发展情况进行调整，提供了一个精细的异常检测层，与分布式学习环境的实时需求保持一致。我们的方法需要参与客户之间达成多数共识才能验证更新，确保只有经过审查和共识的修改才应用于全局模型。我们通过在深度学习的两个基准数据集CIFAR-10和MNIST上进行实验验证了我们方法的有效性。我们的结果表明，标签翻转攻击得到了显著减轻，增强了FL系统的弹性。这种方法超越了依赖异常检测的传统技术。

    arXiv:2403.04803v1 Announce Type: cross  Abstract: This paper introduces an advanced approach for fortifying Federated Learning (FL) systems against label-flipping attacks. We propose a simplified consensus-based verification process integrated with an adaptive thresholding mechanism. This dynamic thresholding is designed to adjust based on the evolving landscape of model updates, offering a refined layer of anomaly detection that aligns with the real-time needs of distributed learning environments. Our method necessitates a majority consensus among participating clients to validate updates, ensuring that only vetted and consensual modifications are applied to the global model. The efficacy of our approach is validated through experiments on two benchmark datasets in deep learning, CIFAR-10 and MNIST. Our results indicate a significant mitigation of label-flipping attacks, bolstering the FL system's resilience. This method transcends conventional techniques that depend on anomaly detec
    
[^90]: (非)配对信号到信号的1D条件GAN翻译

    (Un)paired signal-to-signal translation with 1D conditional GANs

    [https://arxiv.org/abs/2403.04800](https://arxiv.org/abs/2403.04800)

    一维条件生成对抗网络能够实现非配对信号到信号的翻译，将二维图像到图像翻译任务转换为一维信号到信号任务，且在频率方面表现出类似配对信号的效果。

    

    我展示了一维（1D）条件生成对抗网络（cGAN）采用对抗训练架构能够实现非配对信号到信号（"sig2sig"）的翻译。使用简化的CycleGAN模型，具有1D层和更宽的卷积核，模仿WaveGAN将二维（2D）图像生成重新构建为1D音频生成，我展示了将2D图像到图像的翻译任务重新构建为1D信号到信号的深度卷积GAN任务是可能的，而无需对作为CycleGAN开发的传统U-Net模型和对抗架构进行实质性修改。通过这个，我展示了对于一个小的可调整数据集，未被1D CycleGAN模型见过且无配对训练的嘈杂测试信号从源域转换为在翻译域中类似配对测试信号的信号是可能的，特别是在频率方面，并且我量化了这些差异从相关性方面。

    arXiv:2403.04800v1 Announce Type: cross  Abstract: I show that a one-dimensional (1D) conditional generative adversarial network (cGAN) with an adversarial training architecture is capable of unpaired signal-to-signal ("sig2sig") translation. Using a simplified CycleGAN model with 1D layers and wider convolutional kernels, mirroring WaveGAN to reframe two-dimensional (2D) image generation as 1D audio generation, I show that recasting the 2D image-to-image translation task to a 1D signal-to-signal translation task with deep convolutional GANs is possible without substantial modification to the conventional U-Net model and adversarial architecture developed as CycleGAN. With this I show for a small tunable dataset that noisy test signals unseen by the 1D CycleGAN model and without paired training transform from the source domain to signals similar to paired test signals in the translated domain, especially in terms of frequency, and I quantify these differences in terms of correlation an
    
[^91]: JMI在SemEval 2024任务3中的应用：使用GPT和instruction-tuned Llama模型进行多模态情感因果分析的两步法

    JMI at SemEval 2024 Task 3: Two-step approach for multimodal ECAC using in-context learning with GPT and instruction-tuned Llama models

    [https://arxiv.org/abs/2403.04798](https://arxiv.org/abs/2403.04798)

    本文介绍了针对SemEval-2024任务3开发的多模态情感因果分析系统，提出了通过两步框架解决多模态情感因果分析挑战的方法，并在实验中取得显著性能提升。

    

    本文介绍了我们针对SemEval-2024任务3：“对话中的多模态情感因果分析竞赛”开发的系统。有效捕捉人类对话中的情感需要整合文本、音频和视频等多种模态。然而，这些多样性模态的复杂性给开发高效的多模态情感因果分析系统带来了挑战。我们提出的方法通过两步框架来解决这些挑战。我们在实现中采用了两种不同的方法。在方法1中，我们使用两个单独的Llama 2模型进行情感和原因预测的instruction-tuning。在方法2中，我们使用GPT-4V进行会话级视频描述，并使用带有GPT 3.5的上下文学习对注释对话进行处理。我们的系统获得了第4名，系统消融实验表明，我们提出的解决方案取得了显著的性能增益。

    arXiv:2403.04798v1 Announce Type: new  Abstract: This paper presents our system development for SemEval-2024 Task 3: "The Competition of Multimodal Emotion Cause Analysis in Conversations". Effectively capturing emotions in human conversations requires integrating multiple modalities such as text, audio, and video. However, the complexities of these diverse modalities pose challenges for developing an efficient multimodal emotion cause analysis (ECA) system. Our proposed approach addresses these challenges by a two-step framework. We adopt two different approaches in our implementation. In Approach 1, we employ instruction-tuning with two separate Llama 2 models for emotion and cause prediction. In Approach 2, we use GPT-4V for conversation-level video description and employ in-context learning with annotated conversation using GPT 3.5. Our system wins rank 4, and system ablation experiments demonstrate that our proposed solutions achieve significant performance gains. All the experime
    
[^92]: 在中间被发现: 语言模型如何通过即插即用位置编码更好地使用长上下文

    Found in the Middle: How Language Models Use Long Contexts Better via Plug-and-Play Positional Encoding

    [https://arxiv.org/abs/2403.04797](https://arxiv.org/abs/2403.04797)

    通过引入多尺度位置编码（Ms-PoE）来增强大型语言模型（LLMs）对上下文中间相关信息的处理能力，解决了LLMs面临的“中间丢失”挑战。

    

    本文旨在克服大型语言模型（LLMs）面临的“中间丢失”挑战。尽管最近的进展成功实现了LLMs对包含400万令牌的稳定语言建模，但大多数LLMs在识别位于上下文中间的相关信息方面仍然存在持续困难。为解决这一问题，本文引入了多尺度位置编码（Ms-PoE），这是一种简单而有效的即插即用方法，可以增强LLMs处理位于上下文中间的相关信息的能力，无需微调或引入任何额外开销。Ms-PoE利用位置指数重新缩放以减轻RoPE引入的长期衰减效应，同时精心为不同注意力头分配不同的缩放比以保留预训练阶段学到的基本知识，形成多

    arXiv:2403.04797v1 Announce Type: new  Abstract: This paper aims to overcome the "lost-in-the-middle" challenge of large language models (LLMs). While recent advancements have successfully enabled LLMs to perform stable language modeling with up to 4 million tokens, the persistent difficulty faced by most LLMs in identifying relevant information situated in the middle of the context has not been adequately tackled. To address this problem, this paper introduces Multi-scale Positional Encoding (Ms-PoE) which is a simple yet effective plug-and-play approach to enhance the capacity of LLMs to handle the relevant information located in the middle of the context, without fine-tuning or introducing any additional overhead. Ms-PoE leverages the position indice rescaling to relieve the long-term decay effect introduced by RoPE, while meticulously assigning distinct scaling ratios to different attention heads to preserve essential knowledge learned during the pre-training step, forming a multi-
    
[^93]: 消防工程中的大型语言模型：针对领域知识对技术问题的审查

    Large Language Models in Fire Engineering: An Examination of Technical Questions Against Domain Knowledge

    [https://arxiv.org/abs/2403.04795](https://arxiv.org/abs/2403.04795)

    本研究比较了两个聊天机器人在消防工程中处理问题的表现，发现ChatGPT表现较优，展示了聊天机器人技术在消防工程实践中的潜力。

    

    本文介绍了比较两个最近的聊天机器人OpenAI的ChatGPT和谷歌的Bard，在火灾工程领域中评估它们处理与消防安全相关查询的回应的初步研究结果。 创建并检查了一系列不同类型的消防工程问题和场景，其中包括结构火灾设计、防火策略、疏散、建筑法规合规和灭火系统等（其中一些类似于消防保护考试（FPE）中常见的情况）。 结果显示了聊天机器人性能上的一些关键差异，ChatGPT表现出相对较好的性能。 此外，本论文突出了聊天机器人技术在提供关键信息的同时彻底改革消防工程实践的潜力，并概述了进一步改进和研究的领域。显然，在技术成熟后，这项技术将可能

    arXiv:2403.04795v1 Announce Type: cross  Abstract: This communication presents preliminary findings from comparing two recent chatbots, OpenAI's ChatGPT and Google's Bard, in the context of fire engineering by evaluating their responses in handling fire safety related queries. A diverse range of fire engineering questions and scenarios were created and examined, including structural fire design, fire prevention strategies, evacuation, building code compliance, and fire suppression systems (some of which resemble those commonly present in the Fire Protection exam (FPE)). The results reveal some key differences in the performance of the chatbots, with ChatGPT demonstrating a relatively superior performance. Then, this communication highlights the potential for chatbot technology to revolutionize fire engineering practices by providing instant access to critical information while outlining areas for further improvement and research. Evidently, and when it matures, this technology will lik
    
[^94]: 一种基于数据驱动的两阶段多分裂因果集成模型用于时间序列

    A Data-Driven Two-Phase Multi-Split Causal Ensemble Model for Time Series

    [https://arxiv.org/abs/2403.04793](https://arxiv.org/abs/2403.04793)

    提出了一种基于数据驱动的两阶段多分裂因果集成模型，通过组合不同因果基准算法的优势，降低噪音的影响，实现更稳健的因果推断结果。

    

    因果推断是许多学科中发现因果关系的基础研究主题。然而，并非所有算法都同样适用于给定数据集。该论文提出了一种新颖的基于数据驱动的两阶段多分裂因果集成模型，结合了不同因果算法的优势，以实现更稳健的因果推断结果。

    arXiv:2403.04793v1 Announce Type: cross  Abstract: Causal inference is a fundamental research topic for discovering the cause-effect relationships in many disciplines. However, not all algorithms are equally well-suited for a given dataset. For instance, some approaches may only be able to identify linear relationships, while others are applicable for non-linearities. Algorithms further vary in their sensitivity to noise and their ability to infer causal information from coupled vs. non-coupled time series. Therefore, different algorithms often generate different causal relationships for the same input. To achieve a more robust causal inference result, this publication proposes a novel data-driven two-phase multi-split causal ensemble model to combine the strengths of different causality base algorithms. In comparison to existing approaches, the proposed ensemble method reduces the influence of noise through a data partitioning scheme in the first phase. To achieve this, the data are i
    
[^95]: 打破语言障碍：在多语言LLM应用中，直接推断能否胜过预翻译？

    Breaking the Language Barrier: Can Direct Inference Outperform Pre-Translation in Multilingual LLM Applications?

    [https://arxiv.org/abs/2403.04792](https://arxiv.org/abs/2403.04792)

    本研究挑战了以往研究中建立的预翻译范式，并在108种语言中的94种语言中表明PaLM2-L在直接推断中优于预翻译。

    

    大型语言模型在多语言应用中具有重要潜力。然而，由于主要以英文为中心的预训练会导致固有偏见，因此已经普遍采用预翻译的做法，即在推断之前将非英文输入翻译成英文，从而导致复杂性和信息丢失。本研究重新评估了在PaLM2模型中的预翻译需求（Anil等人，2023年），这些模型已被证明在多语言任务中表现出色。我们在108种语言和6个不同基准测试中进行了全面调查，包括开放式生成式任务，在此类任务中之前的研究中被排除在外。我们的发现挑战了以前研究中建立的预翻译范式，突出了在PaLM2中直接推断的优势。具体而言，PaLM2-L在108种语言中的94种中始终优于预翻译。这些发现为更高效的翻译方法铺平了道路。

    arXiv:2403.04792v1 Announce Type: new  Abstract: Large language models hold significant promise in multilingual applications. However, inherent biases stemming from predominantly English-centric pre-training have led to the widespread practice of pre-translation, i.e., translating non-English inputs to English before inference, leading to complexity and information loss. This study re-evaluates the need for pre-translation in the context of PaLM2 models (Anil et al., 2023), which have been established as highly performant in multilingual tasks. We offer a comprehensive investigation across 108 languages and 6 diverse benchmarks, including open-end generative tasks, which were excluded from previous similar studies. Our findings challenge the pre-translation paradigm established in prior research, highlighting the advantages of direct inference in PaLM2. Specifically, PaLM2-L consistently outperforms pre-translation in 94 out of 108 languages. These findings pave the way for more effici
    
[^96]: LLM对抗律师：在大型英国案例法律数据集中识别摘要裁定的子集

    LLM vs. Lawyers: Identifying a Subset of Summary Judgments in a Large UK Case Law Dataset

    [https://arxiv.org/abs/2403.04791](https://arxiv.org/abs/2403.04791)

    使用大型语言模型（LLM）对比传统的自然语言处理方法，可以更有效地从大型英国法院判决数据集中识别摘要裁定案例，取得了更高的F1得分。

    

    为了进行法律领域的计算研究，高效地识别与特定法律问题相关的法院裁决数据集是一项至关重要但具有挑战性的努力。本研究填补了文献中关于如何从大量英国法院决定的文集中隔离案例（在我们的案例中是摘要裁定）的空白。我们介绍了两种计算方法的比较分析：（1）传统的基于自然语言处理的方法，利用专家生成的关键字和逻辑运算符，以及（2）创新性地将Claude 2大语言模型应用于基于特定内容提示分类案例。我们使用了包含356,011份英国法院判决的剑桥法学文集，并确定大型语言模型的加权F1得分为0.94，而关键字的得分为0.78。尽管经过迭代改进，基于关键字的搜索逻辑未能捕捉法律语言中的细微差别。

    arXiv:2403.04791v1 Announce Type: new  Abstract: To undertake computational research of the law, efficiently identifying datasets of court decisions that relate to a specific legal issue is a crucial yet challenging endeavour. This study addresses the gap in the literature working with large legal corpora about how to isolate cases, in our case summary judgments, from a large corpus of UK court decisions. We introduce a comparative analysis of two computational methods: (1) a traditional natural language processing-based approach leveraging expert-generated keywords and logical operators and (2) an innovative application of the Claude 2 large language model to classify cases based on content-specific prompts. We use the Cambridge Law Corpus of 356,011 UK court decisions and determine that the large language model achieves a weighted F1 score of 0.94 versus 0.78 for keywords. Despite iterative refinement, the search logic based on keywords fails to capture nuances in legal language. We 
    
[^97]: TopicDiff：一种用于多模态会话情感检测的主题丰富扩散方法

    TopicDiff: A Topic-enriched Diffusion Approach for Multimodal Conversational Emotion Detection

    [https://arxiv.org/abs/2403.04789](https://arxiv.org/abs/2403.04789)

    提出了一种TopicDiff方法，用于捕获多模态会话情感检测任务中的主题信息，通过将扩散模型集成到神经主题模型中，解决了神经主题模型在捕获主题信息方面的多样性不足问题，并相对于现有MCE基线取得了显著改进

    

    多模态会话情感（MCE）检测通常跨越声学、视觉和语言模态，吸引了多媒体社区日益增加的兴趣。先前的研究主要集中在学习对话中的语境信息，只有少数考虑单一语言模态中的主题信息，而总是忽视声学和视觉主题信息。在此基础上，我们提出了一个模型不可知的Topic-enriched Diffusion（TopicDiff）方法，用于捕获MCE任务中的多模态主题信息。特别是，我们将扩散模型集成到神经主题模型中，以缓解神经主题模型在捕获主题信息方面的多样性不足问题。详细的评估表明，TopicDiff相对于最先进的MCE基线取得了显著改进，证明了多模态主题信息对MCE的重要性以及TopicDiff的有效性。

    arXiv:2403.04789v1 Announce Type: cross  Abstract: Multimodal Conversational Emotion (MCE) detection, generally spanning across the acoustic, vision and language modalities, has attracted increasing interest in the multimedia community. Previous studies predominantly focus on learning contextual information in conversations with only a few considering the topic information in single language modality, while always neglecting the acoustic and vision topic information. On this basis, we propose a model-agnostic Topic-enriched Diffusion (TopicDiff) approach for capturing multimodal topic information in MCE tasks. Particularly, we integrate the diffusion model into neural topic model to alleviate the diversity deficiency problem of neural topic model in capturing topic information. Detailed evaluations demonstrate the significant improvements of TopicDiff over the state-of-the-art MCE baselines, justifying the importance of multimodal topic information to MCE and the effectiveness of Topic
    
[^98]: 在联邦式大语言模型中隐私泄露的分析

    Analysis of Privacy Leakage in Federated Large Language Models

    [https://arxiv.org/abs/2403.04784](https://arxiv.org/abs/2403.04784)

    该论文对在训练大语言模型时使用联邦学习进行隐私分析进行了全面研究，设计了两种主动成员推理攻击来评估各种调整后的联邦学习配置的隐私泄漏，并揭示了流行的大语言模型存在的重大隐私漏洞。

    

    随着联邦学习（FL）作为利用大语言模型（LLMs）的应用的训练和调优协议的快速采用，最近的研究突出了对FL进行重大修改以适应LLMs的大规模的需要。虽然作为回应已经引入了对协议的重大调整，但目前缺乏对适应后的FL协议进行全面隐私分析的研究。为填补这一空白，我们的工作深入探讨了在训练LLMs时使用FL的隐私分析，既从理论角度又从实际角度。具体来说，我们设计了两种带有有理论成功率保证的主动成员推理攻击，以评估各种调整后的FL配置的隐私泄漏。我们的理论发现转化为实际攻击，揭示了流行的LLMs（包括BERT、RoBERTa、DistilBERT和OpenAI的）存在重大的隐私漏洞。

    arXiv:2403.04784v1 Announce Type: cross  Abstract: With the rapid adoption of Federated Learning (FL) as the training and tuning protocol for applications utilizing Large Language Models (LLMs), recent research highlights the need for significant modifications to FL to accommodate the large-scale of LLMs. While substantial adjustments to the protocol have been introduced as a response, comprehensive privacy analysis for the adapted FL protocol is currently lacking.   To address this gap, our work delves into an extensive examination of the privacy analysis of FL when used for training LLMs, both from theoretical and practical perspectives. In particular, we design two active membership inference attacks with guaranteed theoretical success rates to assess the privacy leakages of various adapted FL configurations. Our theoretical findings are translated into practical attacks, revealing substantial privacy vulnerabilities in popular LLMs, including BERT, RoBERTa, DistilBERT, and OpenAI's
    
[^99]: AutoDefense: 多Agent LLM 防御对抗越狱攻击

    AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks

    [https://arxiv.org/abs/2403.04783](https://arxiv.org/abs/2403.04783)

    提出了一种基于响应过滤的多Agent防御框架AutoDefense，可以有效提高LLMs对抗越狱攻击的鲁棒性，同时保持正常用户请求的性能。

    

    尽管在道德对齐方面进行了广泛的预训练和微调以防止在用户请求时生成有害信息，但大型语言模型（LLMs）仍然容易受到越狱攻击。 本文提出了一种基于响应过滤的多Agent防御框架AutoDefense，用于从LLMs中过滤有害回复。 此框架为LLM代理分配不同角色，并利用它们共同完成防御任务。 任务的划分增强了LLMs的整体遵循指令能力，并使其他防御组件作为工具集成成为可能。 AutoDefense 可以适应各种规模和种类的开源LLMs作为代理。 通过对大量有害和安全提示进行广泛实验，我们验证了所提出的AutoDefense在提高对抗越狱攻击的鲁棒性的同时，保持了正常用户请求的性能。

    arXiv:2403.04783v1 Announce Type: cross  Abstract: Despite extensive pre-training and fine-tuning in moral alignment to prevent generating harmful information at user request, large language models (LLMs) remain vulnerable to jailbreak attacks. In this paper, we propose AutoDefense, a response-filtering based multi-agent defense framework that filters harmful responses from LLMs. This framework assigns different roles to LLM agents and employs them to complete the defense task collaboratively. The division in tasks enhances the overall instruction-following of LLMs and enables the integration of other defense components as tools. AutoDefense can adapt to various sizes and kinds of open-source LLMs that serve as agents. Through conducting extensive experiments on a large scale of harmful and safe prompts, we validate the effectiveness of the proposed AutoDefense in improving the robustness against jailbreak attacks, while maintaining the performance at normal user request. Our code and 
    
[^100]: 使用混沌Heron映射的分割掩模进行多维医学图像的选择性加密

    Selective Encryption using Segmentation Mask with Chaotic Henon Map for Multidimensional Medical Images

    [https://arxiv.org/abs/2403.04781](https://arxiv.org/abs/2403.04781)

    该方案以医疗专业人员用户的视角创新于医学图像存储和安全领域，通过分割和加密医学图像中不可或缺的部分来实现对多维医学图像的选择性加密。

    

    arXiv:2403.04781v1 公告类型:跨界 摘要:以用户为中心的设计和资源优化应该是任何技术或创新的核心。用户为中心的视角使开发者有机会进行基于任务的优化。医学图像领域的用户是分析医学图像并将诊断结果提供给患者的医疗专业人员。这个方案以医疗专业人员用户的视角创新于医学图像存储和安全领域。该架构设计有三个主要部分，即:分割、存储和检索。这一架构的设计是因为与为特定医学图像进行几次存储操作相比，医疗专业人员执行的检索操作数量高得令人难以置信。这为我们的创新提供了分割出医学上不可或缺的部分进行加密的空间。

    arXiv:2403.04781v1 Announce Type: cross  Abstract: A user-centric design and resource optimization should be at the center of any technology or innovation. The user-centric perspective gives the developer the opportunity to develop with task-based optimization. The user in the medical image field is a medical professional who analyzes the medical images and gives their diagnosis results to the patient. This scheme, having the medical professional user's perspective, innovates in the area of Medical Image storage and security. The architecture is designed with three main segments, namely: Segmentation, Storage, and Retrieval. This architecture was designed owing to the fact that the number of retrieval operations done by medical professionals was toweringly higher when compared to the storage operations done for some handful number of times for a particular medical image. This gives room for our innovation to segment out the medically indispensable part of the medical image, encrypt it,
    
[^101]: 一种用于隐私漏斗的高效凸差分求解器

    An Efficient Difference-of-Convex Solver for Privacy Funnel

    [https://arxiv.org/abs/2403.04778](https://arxiv.org/abs/2403.04778)

    提出了一种针对隐私漏斗方法的高效求解器，能在已知和未知分布条件下均有效地进行求解，并在实验中展示出优于现有方法的性能。

    

    我们提出了一种针对隐私漏斗（PF）方法的高效求解器，利用其凸差分（DC）结构。所提出的DC分离导致了闭式更新方程，可以直接应用于已知和未知分布设置。对于已知分布情况，我们证明了所提出的非贪婪求解器的收敛性（局部稳定点），并在经验上展示它在表征隐私-效用权衡方面优于现有技术方法。我们的DC方法洞察力适用于具有标记经验样本的未知分布设置。利用这些洞察力，我们的交替最小化求解器满足了PF的基本Markov关系，与以往基于变分推理的求解器相比。在经验上，我们使用MNIST和Fashion-MNIST数据集评估了所提出的求解器。

    arXiv:2403.04778v1 Announce Type: new  Abstract: We propose an efficient solver for the privacy funnel (PF) method, leveraging its difference-of-convex (DC) structure. The proposed DC separation results in a closed-form update equation, which allows straightforward application to both known and unknown distribution settings. For known distribution case, we prove the convergence (local stationary points) of the proposed non-greedy solver, and empirically show that it outperforms the state-of-the-art approaches in characterizing the privacy-utility trade-off. The insights of our DC approach apply to unknown distribution settings where labeled empirical samples are available instead. Leveraging the insights, our alternating minimization solver satisfies the fundamental Markov relation of PF in contrast to previous variational inference-based solvers. Empirically, we evaluate the proposed solver with MNIST and Fashion-MNIST datasets. Our results show that under a comparable reconstruction 
    
[^102]: 社交取向：对话分析的新特征

    Social Orientation: A New Feature for Dialogue Analysis

    [https://arxiv.org/abs/2403.04770](https://arxiv.org/abs/2403.04770)

    感知模型认为社交取向（例如，热情友好、傲慢冷漠）对话参与者可以用来预测和解释社交互动的结果。我们的工作在于系统性地应用社交取向标签来建模对话结果

    

    许多情境下，预测和解释对话的成功或失败是很有用的。心理学的Circumplex理论建模了会话参与者的社交取向（例如，热情友好、傲慢冷漠）可以用来预测和解释社交互动的结果。我们的工作在于系统性地应用社交取向标签来建模对话结果。在本文中，我们介绍了一个新的对话话语数据集，机器标记了社交取向标签。我们展示社交取向标签提高了任务性能，特别是在英文和中文语言基准中的低资源环境。我们还演示了社交取向标签如何帮助解释神经模型中社交互动的结果。根据显示出社交取向标签在对话结果预测任务中实用性的结果，我们发布我们的数据集

    arXiv:2403.04770v1 Announce Type: new  Abstract: There are many settings where it is useful to predict and explain the success or failure of a dialogue. Circumplex theory from psychology models the social orientations (e.g., Warm-Agreeable, Arrogant-Calculating) of conversation participants and can be used to predict and explain the outcome of social interactions. Our work is novel in its systematic application of social orientation tags to modeling conversation outcomes. In this paper, we introduce a new data set of dialogue utterances machine-labeled with social orientation tags. We show that social orientation tags improve task performance, especially in low-resource settings, on both English and Chinese language benchmarks. We also demonstrate how social orientation tags help explain the outcomes of social interactions when used in neural models. Based on these results showing the utility of social orientation tags for dialogue outcome prediction tasks, we release our data sets, co
    
[^103]: 移除GPT4的过滤器

    Removing GPT4's Filter

    [https://arxiv.org/abs/2403.04769](https://arxiv.org/abs/2403.04769)

    提出了一种方法，可以使经过微调的GPT4恢复到没有经过人类反馈强化学习训练的状态，从而移除其在学习期间的所有安全机制

    

    GPT4最初在大量数据集上进行训练，然后使用来自人类反馈的强化学习进行微调，即志愿者提供反馈以教导GPT4不要生成不当内容。本文提出了一种方法来操作已经进行微调的版本，使其恢复到没有经过RLHF（Reinforcement learning from Human Feedback）的行为，有效地移除了模型在RLHF期间学习的所有安全机制。特别是，当GPT4在没有经过RLHF的情况下运行时，它失去了所有抑制力，只需前几个词就可以生成非常不当的内容。

    arXiv:2403.04769v1 Announce Type: cross  Abstract: GPT4 was initially trained on large amounts of data, and then fine-tuned using Reinforcement learning from Human Feedback (RLHF), which is when volunteers give feedback in order to teach GPT4 not to create inappropriate content. In this paper, we present a method to manipulate the fine-tuned version into reverting to pre-RLHF behavior, effectively removing all safety mechanisms that the model learned during RLHF. In particular, when GPT4 acts without RLHF, it loses all inhibition, and can complete very inappropriate content given only the first few words.
    
[^104]: 基于上下文的多模态融合

    Context-Based Multimodal Fusion

    [https://arxiv.org/abs/2403.04650](https://arxiv.org/abs/2403.04650)

    提出一种基于上下文的多模态融合模型，结合了模态融合和数据分布对齐，通过特定上下文向量表示每个模态，并将其与每个模态的嵌入进行融合，

    

    融合模型广泛应用于解决多模态任务，但在不同模态之间数据分布对齐方面存在明显局限性。针对这一挑战，我们提出了一种创新模型称为基于上下文的多模态融合（CBMF），结合了模态融合和数据分布对齐，通过特定上下文向量表示每个模态，并将其与每个模态的嵌入进行融合。

    arXiv:2403.04650v1 Announce Type: cross  Abstract: The fusion models, which effectively combine information from different sources, are widely used in solving multimodal tasks. However, they have significant limitations related to aligning data distributions across different modalities. This challenge can lead to inconsistencies and difficulties in learning robust representations. Alignment models, while specifically addressing this issue, often require training "from scratch" with large datasets to achieve optimal results, which can be costly in terms of resources and time. To overcome these limitations, we propose an innovative model called Context-Based Multimodal Fusion (CBMF), which combines both modality fusion and data distribution alignment. In CBMF, each modality is represented by a specific context vector, fused with the embedding of each modality. This enables the use of large pre-trained models that can be frozen, reducing the computational and training data requirements. A
    
[^105]: 用Shapley值解释贝叶斯优化促进人工智能与人类协作

    Explaining Bayesian Optimization by Shapley Values Facilitates Human-AI Collaboration

    [https://arxiv.org/abs/2403.04629](https://arxiv.org/abs/2403.04629)

    提出了ShapleyBO框架，用Shapley值解释贝叶斯优化提议，量化每个参数对于优化过程的贡献，并能够区分不同类型的不确定性探索贡献。

    

    贝叶斯优化（BO）与高斯过程（GP）已成为解决黑匣子优化问题的不可或缺的算法。然而，BO本身也常常被认为是一个黑匣子，缺乏提供为何提议评估某些参数的理由的方法。我们通过提出ShapleyBO来解决这个问题，这是一个用博弈论Shapley值解释BO提议的框架。它量化了每个参数对BO的收获函数的贡献。利用Shapley值的线性性，我们能够进一步确定每个参数对于像置信边界这样的加法收获函数推动BO的探索和开发的强度。我们还展示了ShapleyBO能够解决探索对于勘探aleatoric和认识epistemic不确定性的贡献。

    arXiv:2403.04629v1 Announce Type: cross  Abstract: Bayesian optimization (BO) with Gaussian processes (GP) has become an indispensable algorithm for black box optimization problems. Not without a dash of irony, BO is often considered a black box itself, lacking ways to provide reasons as to why certain parameters are proposed to be evaluated. This is particularly relevant in human-in-the-loop applications of BO, such as in robotics. We address this issue by proposing ShapleyBO, a framework for interpreting BO's proposals by game-theoretic Shapley values.They quantify each parameter's contribution to BO's acquisition function. Exploiting the linearity of Shapley values, we are further able to identify how strongly each parameter drives BO's exploration and exploitation for additive acquisition functions like the confidence bound. We also show that ShapleyBO can disentangle the contributions to exploration into those that explore aleatoric and epistemic uncertainty. Moreover, our method 
    
[^106]: In-n-Out: 用于链接预测的图神经网络校准

    In-n-Out: Calibrating Graph Neural Networks for Link Prediction

    [https://arxiv.org/abs/2403.04605](https://arxiv.org/abs/2403.04605)

    IN-N-OUT提出了第一个用于链接预测的图神经网络校准方法，基于对GNN校准偏差的观察，通过简单直觉实现校准

    

    深度神经网络通常存在校准偏差，即它们的输出不能反映我们打算预测的事件的真实概率。我们展示了在链接预测中，图神经网络通常表现出混合的行为，即在负预测上可能过于自信，在正预测上可能不够自信。基于这一观察，我们提出了IN-N-OUT，这是第一个用于链接预测的校准图神经网络的方法。IN-N-OUT基于两个简单的直觉：i) 给边标注真/假标签，同时遵循GNN的预测应导致该边嵌入的微小波动；ii) 相反地，如果我们标记相同的边与我们的GNN预测相悖，那么嵌入应该发生更大的变化。

    arXiv:2403.04605v1 Announce Type: new  Abstract: Deep neural networks are notoriously miscalibrated, i.e., their outputs do not reflect the true probability of the event we aim to predict. While networks for tabular or image data are usually overconfident, recent works have shown that graph neural networks (GNNs) show the opposite behavior for node-level classification. But what happens when we are predicting links? We show that, in this case, GNNs often exhibit a mixed behavior. More specifically, they may be overconfident in negative predictions while being underconfident in positive ones. Based on this observation, we propose IN-N-OUT, the first-ever method to calibrate GNNs for link prediction. IN-N-OUT is based on two simple intuitions: i) attributing true/false labels to an edge while respecting a GNNs prediction should cause but small fluctuations in that edge's embedding; and, conversely, ii) if we label that same edge contradicting our GNN, embeddings should change more substa
    
[^107]: 使图像真实的因素是什么？

    What makes an image realistic?

    [https://arxiv.org/abs/2403.04493](https://arxiv.org/abs/2403.04493)

    论文讨论了如何设计能够可靠区分真实数据和不真实数据的函数，提出了通用评论者的概念作为一个新的解决方案。

    

    在过去的十年里，我们在生成看起来真实的数据方面取得了巨大进展，无论是图像、文本、音频还是视频。在这里，我们讨论了与之密切相关的问题，即量化现实主义，即设计能够可靠地区分真实数据和不真实数据的函数。从算法信息理论的观点出发，我们讨论了为什么这个问题很具挑战性，为什么一个好的生成模型单独不能解决它，以及一个好的解决方案应该是什么样的。特别是，我们引入了通用评论者的概念，不像对抗性评论者那样需要对抗性训练。尽管通用评论者并不立即实用，但它们既可以作为引导实际实现的北极星，也可以作为一个工具。

    arXiv:2403.04493v1 Announce Type: new  Abstract: The last decade has seen tremendous progress in our ability to generate realistic-looking data, be it images, text, audio, or video. Here, we discuss the closely related problem of quantifying realism, that is, designing functions that can reliably tell realistic data from unrealistic data. This problem turns out to be significantly harder to solve and remains poorly understood, despite its prevalence in machine learning and recent breakthroughs in generative AI. Drawing on insights from algorithmic information theory, we discuss why this problem is challenging, why a good generative model alone is insufficient to solve it, and what a good solution would look like. In particular, we introduce the notion of a universal critic, which unlike adversarial critics does not require adversarial training. While universal critics are not immediately practical, they can serve both as a North Star for guiding practical implementations and as a tool 
    
[^108]: 异质学习代理群体中道德行为动态

    Dynamics of Moral Behavior in Heterogeneous Populations of Learning Agents

    [https://arxiv.org/abs/2403.04202](https://arxiv.org/abs/2403.04202)

    在多代理环境中，研究人员探讨了不同道德类型的学习代理之间的互动，发现道德异质性可能对代理的共同发展产生影响。

    

    arXiv:2403.04202v1 公告类型：交叉领域 摘要：日益关注AI系统安全和对齐性的问题突显了在人工代理中嵌入道德能力的重要性。一种有前途的解决方案是利用经验学习，即强化学习。在多代理（社会）环境中，个体学习代理之间的交互可能产生复杂的群体层面现象。许多现有研究依赖于模拟的社会困境环境来研究独立学习代理的互动。然而，它们往往忽视了实践中代理社会中可能存在的道德异质性。例如，在不同时间点，单个学习代理可能面对后果主义者（即关心随时间最大化某种结果）或基于规范的对手（即专注于立即遵守特定规范） 。代理的共同发展在多大程度上可能受到这种道德异质性的影响。

    arXiv:2403.04202v1 Announce Type: cross  Abstract: Growing concerns about safety and alignment of AI systems highlight the importance of embedding moral capabilities in artificial agents. A promising solution is the use of learning from experience, i.e., Reinforcement Learning. In multi-agent (social) environments, complex population-level phenomena may emerge from interactions between individual learning agents. Many of the existing studies rely on simulated social dilemma environments to study the interactions of independent learning agents. However, they tend to ignore the moral heterogeneity that is likely to be present in societies of agents in practice. For example, at different points in time a single learning agent may face opponents who are consequentialist (i.e., caring about maximizing some outcome over time) or norm-based (i.e., focusing on conforming to a specific norm here and now). The extent to which agents' co-development may be impacted by such moral heterogeneity in 
    
[^109]: DPOT: 自回归去噪运算器变换器用于大规模PDE预训练

    DPOT: Auto-Regressive Denoising Operator Transformer for Large-Scale PDE Pre-Training

    [https://arxiv.org/abs/2403.03542](https://arxiv.org/abs/2403.03542)

    本文提出了一种新的自回归去噪预训练策略，可以更稳定、更高效地在PDE数据上进行预训练，并且通过基于傅里叶注意力的模型架构设计，实现了在大规模预训练中轻松扩展模型，该模型在多个PDE数据集上取得了SOTA表现。

    

    预训练已经被研究用来提高在数据稀缺环境中训练神经算子的效率和性能。然而，由于偏微分方程（PDE）数据的固有复杂性和多样性，如长轨迹、多个尺度和不同维度，它在很大程度上还处于起步阶段。在本文中，我们提出了一种新的自回归去噪预训练策略，这种策略能够更稳定、更高效地在PDE数据上进行预训练，并且可以泛化到各种下游任务。此外，通过基于傅里叶注意力的灵活可扩展模型架构的设计，我们可以轻松地将模型扩展到大规模预训练。我们在10+个PDE数据集上训练了具有超过0.5B参数的PDE基础模型，包括超过100k轨迹。大量实验证明我们在这些基准上取得了SOTA，并验证了我们的模型对显著提升性能的强大泛化能力。

    arXiv:2403.03542v1 Announce Type: new  Abstract: Pre-training has been investigated to improve the efficiency and performance of training neural operators in data-scarce settings. However, it is largely in its infancy due to the inherent complexity and diversity, such as long trajectories, multiple scales and varying dimensions of partial differential equations (PDEs) data. In this paper, we present a new auto-regressive denoising pre-training strategy, which allows for more stable and efficient pre-training on PDE data and generalizes to various downstream tasks. Moreover, by designing a flexible and scalable model architecture based on Fourier attention, we can easily scale up the model for large-scale pre-training. We train our PDE foundation model with up to 0.5B parameters on 10+ PDE datasets with more than 100k trajectories. Extensive experiments show that we achieve SOTA on these benchmarks and validate the strong generalizability of our model to significantly enhance performanc
    
[^110]: SplAgger：用于元强化学习的分割聚合

    SplAgger: Split Aggregation for Meta-Reinforcement Learning

    [https://arxiv.org/abs/2403.03020](https://arxiv.org/abs/2403.03020)

    本文展示了任务推断序列模型在元强化学习中的益处。

    

    强化学习的一个核心目标是创建能快速学习新任务的智能体。元强化学习旨在通过直接学习这些智能体来实现这一目标。一类元强化学习方法被称为黑盒方法，通过端到端训练现成的序列模型来实现这一目标。与之形成对比的是另一类方法，它们明确地推断出未知任务的后验分布。这些方法通常具有不同的目标和序列模型，旨在实现任务推断，因此被称为任务推断方法。本文提出了强有力的证据，证明任务推断序列模型仍然具有益处。

    arXiv:2403.03020v1 Announce Type: cross  Abstract: A core ambition of reinforcement learning (RL) is the creation of agents capable of rapid learning in novel tasks. Meta-RL aims to achieve this by directly learning such agents. One category of meta-RL methods, called black box methods, does so by training off-the-shelf sequence models end-to-end. In contrast, another category of methods have been developed that explicitly infer a posterior distribution over the unknown task. These methods generally have distinct objectives and sequence models designed to enable task inference, and so are known as task inference methods. However, recent evidence suggests that task inference objectives are unnecessary in practice. Nonetheless, it remains unclear whether task inference sequence models are beneficial even when task inference objectives are not. In this paper, we present strong evidence that task inference sequence models are still beneficial. In particular, we investigate sequence models 
    
[^111]: 不需要精确指导的学习：从低分辨率历史标签更新大规模高分辨率土地覆盖图

    Learning without Exact Guidance: Updating Large-scale High-resolution Land Cover Maps from Low-resolution Historical Labels

    [https://arxiv.org/abs/2403.02746](https://arxiv.org/abs/2403.02746)

    提出了一个名为Paraformer的弱监督框架，通过低分辨率历史土地覆盖数据指导大规模高分辨率土地覆盖映射，设计了CNN-Transformer特征提取器来综合捕获局部和全局背景信息

    

    大规模高分辨率（HR）土地覆盖映射是调查地球表面和解决人类面临的许多挑战的重要任务。然而，由于复杂的地面细节、各种地貌和广泛地理区域内准确训练标签的稀缺性，这仍然是一项非平凡的任务。在本文中，我们提出了一个高效的弱监督框架（Paraformer），即低到高网络（L2HNet）V2，用于在低分辨率（LR）的易获历史土地覆盖数据指导大规模高分辨率土地覆盖映射。具体来说，现有的土地覆盖映射方法显示了CNN在保留局部地面细节方面的优势，但仍然存在在各种地貌中全局建模不足的问题。因此，我们设计了Paraformer中的并行CNN-Transformer特征提取器，包括一个无降采样CNN分支和一个Transformer分支，来共同捕获局部和全局背景信息

    arXiv:2403.02746v1 Announce Type: cross  Abstract: Large-scale high-resolution (HR) land-cover mapping is a vital task to survey the Earth's surface and resolve many challenges facing humanity. However, it is still a non-trivial task hindered by complex ground details, various landforms, and the scarcity of accurate training labels over a wide-span geographic area. In this paper, we propose an efficient, weakly supervised framework (Paraformer), a.k.a. Low-to-High Network (L2HNet) V2, to guide large-scale HR land-cover mapping with easy-access historical land-cover data of low resolution (LR). Specifically, existing land-cover mapping approaches reveal the dominance of CNNs in preserving local ground details but still suffer from insufficient global modeling in various landforms. Therefore, we design a parallel CNN-Transformer feature extractor in Paraformer, consisting of a downsampling-free CNN branch and a Transformer branch, to jointly capture local and global contextual informatio
    
[^112]: Wukong: 迈向大规模推荐的标度律

    Wukong: Towards a Scaling Law for Large-Scale Recommendation

    [https://arxiv.org/abs/2403.02545](https://arxiv.org/abs/2403.02545)

    Wukong通过堆叠因子分解机和协同增长策略，在推荐领域建立了一个标度律，并在质量上优于现有模型。

    

    缩放定律在提高模型质量方面起着关键作用。然而，迄今为止的推荐模型并没有展现出类似于大型语言模型领域观察到的定律，这是由于它们的升级机制的低效性。本文提出了一种基于纯堆叠因子分解机和协同增长策略的有效网络架构，统称为Wukong，以在推荐领域建立一个标度律。Wukong的独特设计使其能够通过更高更宽的层次简单捕获各种任意阶的交互。我们在六个公共数据集上进行了广泛评估，结果表明，与最先进的模型相比，Wukong在质量方面始终表现优越。此外，我们评估了Wuko

    arXiv:2403.02545v1 Announce Type: cross  Abstract: Scaling laws play an instrumental role in the sustainable improvement in model quality. Unfortunately, recommendation models to date do not exhibit such laws similar to those observed in the domain of large language models, due to the inefficiencies of their upscaling mechanisms. This limitation poses significant challenges in adapting these models to increasingly more complex real-world datasets. In this paper, we propose an effective network architecture based purely on stacked factorization machines, and a synergistic upscaling strategy, collectively dubbed Wukong, to establish a scaling law in the domain of recommendation. Wukong's unique design makes it possible to capture diverse, any-order of interactions simply through taller and wider layers. We conducted extensive evaluations on six public datasets, and our results demonstrate that Wukong consistently outperforms state-of-the-art models quality-wise. Further, we assessed Wuko
    
[^113]: Android应用隐私相关评论的十年大规模趋势分析

    A Decade of Privacy-Relevant Android App Reviews: Large Scale Trends

    [https://arxiv.org/abs/2403.02292](https://arxiv.org/abs/2403.02292)

    通过分析谷歌应用商店上1200万条隐私相关评论，研究了十年间隐私评论的大规模趋势，发现隐私评论呈现持续增长，探讨了热门和逐渐减少的隐私话题，以及不同国家用户对隐私问题看法的差异。

    

    我们展示了对谷歌应用商店上1200万条隐私相关评论的分析结果，这些评论跨越了10年时间。通过应用最先进的自然语言处理技术，我们能够在时间、国家、应用类型、不同隐私主题以及多种情感维度上检视用户对隐私问题的看法。我们发现隐私相关评论持续增长，并探究了一些热门话题（如数据删除和数据窃取），以及一些逐渐减少的话题（如涉及敏感权限的隐私相关评论）。尽管隐私评论来自200多个国家，但有33个国家提供了90%的隐私评论。我们通过检查每个国家用户评论的隐私主题分布来进行跨国家比较，发现地理接近并不意味着附近国家有类似的隐私观点。

    arXiv:2403.02292v1 Announce Type: new  Abstract: We present an analysis of 12 million instances of privacy-relevant reviews publicly visible on the Google Play Store that span a 10 year period. By leveraging state of the art NLP techniques, we can examine what users have been writing about privacy along multiple dimensions: time, countries, app types, diverse privacy topics, and even across a spectrum of emotions. We find consistent growth of privacy-relevant reviews, and explore topics that are trending (such as Data Deletion and Data Theft), as well as those on the decline (such as privacy-relevant reviews on sensitive permissions). We find that although privacy reviews come from more than 200 countries, 33 countries provide 90% of privacy reviews. We conduct a comparison across countries by examining the distribution of privacy topics a country's users write about, and find that geographic proximity is not a reliable indicator that nearby countries have similar privacy perspectives.
    
[^114]: 一种用于大规模全局优化的复合分解方法

    A Composite Decomposition Method for Large-Scale Global Optimization

    [https://arxiv.org/abs/2403.01192](https://arxiv.org/abs/2403.01192)

    本文提出了一种复合分解方法，将差分分组和一般分组方法整合到一个框架中，通过逐步分解准确分解各种问题类型，降低了计算复杂性。

    

    合作协同进化（CC）算法基于分而治之策略，已成为解决大规模全局优化（LSGO）问题的主要方法。分组阶段的效率和准确性显著影响优化过程的性能。一般可分离分组（GSG）方法克服了以往差分分组方法的局限性，使得非可加分离函数的分解成为可能，但其存在较高的计算复杂性。为了解决这一挑战，本文提出了一种复合可分离分组（CSG）方法，将DG和GSG无缝整合到一个问题分解框架中，以利用两种方法的优势。CSG引入了一个逐步分解框架，可以使用更少的计算资源准确分解各种问题类型。

    arXiv:2403.01192v1 Announce Type: cross  Abstract: Cooperative co-evolution (CC) algorithms, based on the divide-and-conquer strategy, have emerged as the predominant approach to solving large-scale global optimization (LSGO) problems. The efficiency and accuracy of the grouping stage significantly impact the performance of the optimization process. While the general separability grouping (GSG) method has overcome the limitation of previous differential grouping (DG) methods by enabling the decomposition of non-additively separable functions, it suffers from high computational complexity. To address this challenge, this article proposes a composite separability grouping (CSG) method, seamlessly integrating DG and GSG into a problem decomposition framework to utilize the strengths of both approaches. CSG introduces a step-by-step decomposition framework that accurately decomposes various problem types using fewer computational resources. By sequentially identifying additively, multiplic
    
[^115]: 使用蒙特卡洛高效影响函数实现自动化高效估计

    Automated Efficient Estimation using Monte Carlo Efficient Influence Functions

    [https://arxiv.org/abs/2403.00158](https://arxiv.org/abs/2403.00158)

    该论文提出了一种名为蒙特卡洛高效影响函数（MC-EIF）的全自动技术，用于近似高效影响函数，能够实现针对广泛类别的模型和目标函数的统计估计，达到最优的收敛速度。

    

    许多实际问题涉及使用高维模型和数据集估计低维统计量。几种方法基于影响函数理论来解决这些估计任务，例如去偏/双重极大似然或有针对性最小损失估计。本文介绍了一种全自动的技术，即\textit{蒙特卡洛高效影响函数} (MC-EIF)，用于逼近高效影响函数，与现有的可微概率编程系统无缝集成。MC-EIF可自动化广泛类别的模型和目标函数的高效统计估计，这些估计以前需要严格的自定义分析。我们证明MC-EIF是一致的，并且使用MC-EIF的估计器达到了最优的$\sqrt{N}$收敛速度。我们经验性地展示，使用MC-EIF的估计器与使用解析EIF的估计器相当。最后，我们展示一个新颖的顶点示例

    arXiv:2403.00158v1 Announce Type: cross  Abstract: Many practical problems involve estimating low dimensional statistical quantities with high-dimensional models and datasets. Several approaches address these estimation tasks based on the theory of influence functions, such as debiased/double ML or targeted minimum loss estimation. This paper introduces \textit{Monte Carlo Efficient Influence Functions} (MC-EIF), a fully automated technique for approximating efficient influence functions that integrates seamlessly with existing differentiable probabilistic programming systems. MC-EIF automates efficient statistical estimation for a broad class of models and target functionals that would previously require rigorous custom analysis. We prove that MC-EIF is consistent, and that estimators using MC-EIF achieve optimal $\sqrt{N}$ convergence rates. We show empirically that estimators using MC-EIF are at parity with estimators using analytic EIFs. Finally, we demonstrate a novel capstone exa
    
[^116]: 一种利用Transformer和CNN集成的蛋白质结构预测方法

    A Protein Structure Prediction Approach Leveraging Transformer and CNN Integration

    [https://arxiv.org/abs/2402.19095](https://arxiv.org/abs/2402.19095)

    本研究提出了一种利用Transformer和CNN集成的蛋白质结构预测方法，通过二维融合深度神经网络模型DstruCCN，有助于提升蛋白质二级结构预测的准确性和效率。

    

    蛋白质对于生命至关重要，其结构决定其功能。蛋白的二级结构是由蛋白质的一级结构折叠形成的，而蛋白的三级结构是由二级结构的弯曲和折叠形成的。因此，研究蛋白的二级结构对于整体理解蛋白质结构非常有帮助。虽然随着机器学习和深度学习的发展，蛋白质二级结构预测的准确性不断提高，但不幸的是，蛋白结构预测领域的进展仍然不足以满足对蛋白质信息的大量需求。因此，基于深度学习方法在特征提取和学习能力方面的优势，本文采用了一个二维融合深度神经网络模型DstruCCN，该模型使用了卷积神经网络(CNN)和一个监督Transformer。

    arXiv:2402.19095v1 Announce Type: cross  Abstract: Proteins are essential for life, and their structure determines their function. The protein secondary structure is formed by the folding of the protein primary structure, and the protein tertiary structure is formed by the bending and folding of the secondary structure. Therefore, the study of protein secondary structure is very helpful to the overall understanding of protein structure. Although the accuracy of protein secondary structure prediction has continuously improved with the development of machine learning and deep learning, progress in the field of protein structure prediction, unfortunately, remains insufficient to meet the large demand for protein information. Therefore, based on the advantages of deep learning-based methods in feature extraction and learning ability, this paper adopts a two-dimensional fusion deep neural network model, DstruCCN, which uses Convolutional Neural Networks (CCN) and a supervised Transformer pr
    
[^117]: 概率Lipschitz性和稳定秩用于比较解释模型

    Probabilistic Lipschitzness and the Stable Rank for Comparing Explanation Models

    [https://arxiv.org/abs/2402.18863](https://arxiv.org/abs/2402.18863)

    概率Lipschitz性与稳定秩的研究为比较解释模型提供了新的角度和度量标准。

    

    解释性模型如今在机器学习中广泛应用，以解决神经网络的黑盒特性。现在的问题是哪种解释性模型最有效。概率Lipschitz性表明神经网络的平滑性与事后解释的质量基本相关。本文在对Integrated Gradients、LIME和SmoothGrad的概率Lipschitzness进行理论下限证明的基础上，提出了一种新的度量标准，使用概率Lipschitz性和归一化的聪明度来比较解释性模型的稳健性。此外，我们证明了神经网络的局部Lipschitz常数与其稳定秩之间的联系。然后我们证明神经网络的稳定秩提供了解释性模型稳健性的一种启发式方法。

    arXiv:2402.18863v1 Announce Type: new  Abstract: Explainability models are now prevalent within machine learning to address the black-box nature of neural networks. The question now is which explainability model is most effective. Probabilistic Lipschitzness has demonstrated that the smoothness of a neural network is fundamentally linked to the quality of post hoc explanations. In this work, we prove theoretical lower bounds on the probabilistic Lipschitzness of Integrated Gradients, LIME and SmoothGrad. We propose a novel metric using probabilistic Lipschitzness, normalised astuteness, to compare the robustness of explainability models. Further, we prove a link between the local Lipschitz constant of a neural network and its stable rank. We then demonstrate that the stable rank of a neural network provides a heuristic for the robustness of explainability models.
    
[^118]: 多态雷达对空中飞行器雷达截面识别：一种贝叶斯融合方法

    Multistatic-Radar RCS-Signature Recognition of Aerial Vehicles: A Bayesian Fusion Approach

    [https://arxiv.org/abs/2402.17987](https://arxiv.org/abs/2402.17987)

    提出了一种完全贝叶斯雷达自动目标识别的框架，采用最优贝叶斯融合来有效地汇总多个雷达的分类概率向量，以改进无人机雷达截面识别效果。

    

    arXiv:2402.17987v1 公告类型：跨领域 摘要：无人机的雷达自动目标识别（RATR）涉及发射电磁波并对接收到的雷达回波执行目标类型识别，对国防和航空航天应用至关重要。先前的研究突出了多态雷达配置在RATR中优于单态雷达的优势。然而，多态雷达配置中的融合方法通常以概率方式次优地组合来自各个雷达的分类向量。为了解决这个问题，我们提出了一个完全贝叶斯RATR框架，采用最优贝叶斯融合（OBF）来聚合来自多个雷达的分类概率向量。OBF基于期望0-1损失，根据多个时间步骤的历史观测更新目标无人机类型的递归贝叶斯分类（RBC）后验分布。我们使用模拟的随机行走轨迹评估了这种方法，共涉及七种机动目标。

    arXiv:2402.17987v1 Announce Type: cross  Abstract: Radar Automated Target Recognition (RATR) for Unmanned Aerial Vehicles (UAVs) involves transmitting Electromagnetic Waves (EMWs) and performing target type recognition on the received radar echo, crucial for defense and aerospace applications. Previous studies highlighted the advantages of multistatic radar configurations over monostatic ones in RATR. However, fusion methods in multistatic radar configurations often suboptimally combine classification vectors from individual radars probabilistically. To address this, we propose a fully Bayesian RATR framework employing Optimal Bayesian Fusion (OBF) to aggregate classification probability vectors from multiple radars. OBF, based on expected 0-1 loss, updates a Recursive Bayesian Classification (RBC) posterior distribution for target UAV type, conditioned on historical observations across multiple time steps. We evaluate the approach using simulated random walk trajectories for seven dro
    
[^119]: 课程学习遇见有向无环图进行多模态情感识别

    Curriculum Learning Meets Directed Acyclic Graph for Multimodal Emotion Recognition

    [https://arxiv.org/abs/2402.17269](https://arxiv.org/abs/2402.17269)

    使用有向无环图和课程学习相结合的新方法，提升多模态情感识别模型在处理情感变化和数据不平衡方面的性能。

    

    这篇论文提出了一种新颖的方法，称为MultiDAG+CL，用于会话中的多模态情感识别（ERC），它利用有向无环图（DAG）在一个统一的框架内集成文本、声音和视觉特征。模型通过课程学习（CL）进行增强，以应对情感变化和数据不平衡带来的挑战。课程学习通过逐渐以有意义的顺序呈现训练样本来促进学习过程，从而提高模型处理情绪变化和数据不平衡的性能。在IEMOCAP和MELD数据集上的实验结果表明，MultiDAG+CL模型优于基线模型。

    arXiv:2402.17269v1 Announce Type: new  Abstract: Emotion recognition in conversation (ERC) is a crucial task in natural language processing and affective computing. This paper proposes MultiDAG+CL, a novel approach for Multimodal Emotion Recognition in Conversation (ERC) that employs Directed Acyclic Graph (DAG) to integrate textual, acoustic, and visual features within a unified framework. The model is enhanced by Curriculum Learning (CL) to address challenges related to emotional shifts and data imbalance. Curriculum learning facilitates the learning process by gradually presenting training samples in a meaningful order, thereby improving the model's performance in handling emotional variations and data imbalance. Experimental results on the IEMOCAP and MELD datasets demonstrate that the MultiDAG+CL models outperform baseline models.
    
[^120]: CriticBench：为批判性-正确推理评估LLMs而设计的基准测试

    CriticBench: Benchmarking LLMs for Critique-Correct Reasoning

    [https://arxiv.org/abs/2402.14809](https://arxiv.org/abs/2402.14809)

    CriticBench是一个综合基准测试，旨在评估LLMs在批判和纠正推理方面的能力，发现批判性训练显著提升性能，逻辑任务更易于修正。

    

    大型语言模型（LLMs）批判和完善其推理的能力对于它们在评估、反馈提供和自我改进中的应用至关重要。本文引入了CriticBench，一个旨在评估LLMs在各种任务中批判和纠正其推理能力的综合基准测试。CriticBench包含五个推理领域：数学、常识、符号、编码和算法。它整合了15个数据集，并结合了三个LLM系列的响应。利用CriticBench，我们评估和剖析了17个LLMs在生成、批判和修正推理（即GQC推理）中的表现。我们的研究结果显示：（1）GQC能力呈线性关系，批判性训练显著提升了性能；（2）修正效果在任务上有所不同，以逻辑为导向的任务更容易修正；（3）GQC知识的不一致性。

    arXiv:2402.14809v1 Announce Type: cross  Abstract: The ability of Large Language Models (LLMs) to critique and refine their reasoning is crucial for their application in evaluation, feedback provision, and self-improvement. This paper introduces CriticBench, a comprehensive benchmark designed to assess LLMs' abilities to critique and rectify their reasoning across a variety of tasks. CriticBench encompasses five reasoning domains: mathematical, commonsense, symbolic, coding, and algorithmic. It compiles 15 datasets and incorporates responses from three LLM families. Utilizing CriticBench, we evaluate and dissect the performance of 17 LLMs in generation, critique, and correction reasoning, i.e., GQC reasoning. Our findings reveal: (1) a linear relationship in GQC capabilities, with critique-focused training markedly enhancing performance; (2) a task-dependent variation in correction effectiveness, with logic-oriented tasks being more amenable to correction; (3) GQC knowledge inconsisten
    
[^121]: SzCORE：用于验证基于脑电图的自动癫痫检测算法的癫痫社区开源研究评估框架

    SzCORE: A Seizure Community Open-source Research Evaluation framework for the validation of EEG-based automated seizure detection algorithms

    [https://arxiv.org/abs/2402.13005](https://arxiv.org/abs/2402.13005)

    提出了SzCORE框架，用于验证基于脑电图的自动癫痫检测算法，旨在标准化验证方法，包括数据集、文件格式、输入内容、性能度量等。

    

    随着家庭和长期脑电图监测的增加，基于脑电图的高质量自动癫痫检测算法的需求变得更加迫切。这些算法验证方法的异质性影响了报告的结果，并使全面评估和比较变得具有挑战性。该异质性主要涉及数据集的选择、评估方法和性能度量等方面。本文提出了一个统一的框架，旨在建立EEG基础癫痫检测算法验证的标准化。基于现有指南和建议，该框架引入了一组关于数据集、文件格式、EEG数据输入内容、癫痫注释输入和输出、交叉验证策略以及性能度量的建议和标准。

    arXiv:2402.13005v1 Announce Type: cross  Abstract: The need for high-quality automated seizure detection algorithms based on electroencephalography (EEG) becomes ever more pressing with the increasing use of ambulatory and long-term EEG monitoring. Heterogeneity in validation methods of these algorithms influences the reported results and makes comprehensive evaluation and comparison challenging. This heterogeneity concerns in particular the choice of datasets, evaluation methodologies, and performance metrics. In this paper, we propose a unified framework designed to establish standardization in the validation of EEG-based seizure detection algorithms. Based on existing guidelines and recommendations, the framework introduces a set of recommendations and standards related to datasets, file formats, EEG data input content, seizure annotation input and output, cross-validation strategies, and performance metrics. We also propose the 10-20 seizure detection benchmark, a machine-learning 
    
[^122]: 基于转换教师匹配的知识蒸馏

    Knowledge Distillation Based on Transformed Teacher Matching

    [https://arxiv.org/abs/2402.11148](https://arxiv.org/abs/2402.11148)

    通过放弃学生端的温度缩放，本文提出了一种名为转换教师匹配（TTM）的知识蒸馏变体，通过对温度缩放的重新解释，TTM在目标函数中引入了固有的Rényi熵项，从而实现了更好的学生泛化效果。

    

    作为连接逻辑匹配和概率分布匹配的技术，温度缩放在知识蒸馏（KD）中起着关键作用。传统上，在KD中，温度缩放被应用于教师的logits和学生的logits。受一些最近的研究启发，本文放弃了在学生端的温度缩放，系统地研究了由此产生的KD变体，称为转换教师匹配（TTM）。通过重新解释温度缩放作为概率分布的幂变换，我们表明，与原始的KD相比，TTM在其目标函数中具有固有的Rényi熵项，这充当了额外的正则化项。大量的实验结果表明，由于这种固有的正则化，TTM导致训练良好的学生比原始KD具有更好的泛化能力。

    arXiv:2402.11148v1 Announce Type: new  Abstract: As a technique to bridge logit matching and probability distribution matching, temperature scaling plays a pivotal role in knowledge distillation (KD). Conventionally, temperature scaling is applied to both teacher's logits and student's logits in KD. Motivated by some recent works, in this paper, we drop instead temperature scaling on the student side, and systematically study the resulting variant of KD, dubbed transformed teacher matching (TTM). By reinterpreting temperature scaling as a power transform of probability distribution, we show that in comparison with the original KD, TTM has an inherent R\'enyi entropy term in its objective function, which serves as an extra regularization term. Extensive experiment results demonstrate that thanks to this inherent regularization, TTM leads to trained students with better generalization than the original KD. To further enhance student's capability to match teacher's power transformed proba
    
[^123]: 多模态可解释的数据驱动模型用于预测多重抗菌药物耐药性的早期预测的研究

    Multimodal Interpretable Data-Driven Models for Early Prediction of Antimicrobial Multidrug Resistance Using Multivariate Time-Series

    [https://arxiv.org/abs/2402.06295](https://arxiv.org/abs/2402.06295)

    本研究提出了一种基于可解释的多模态数据驱动模型的方法，通过静态数据和多元时间序列模型预测和理解重症监护病房中抗菌药物多重耐药性细菌的出现。

    

    电子健康记录（EHR）是患者健康状况的多模态注册，包括静态数据和多元时间序列（MTS）。虽然MTS是临床预测的有价值工具，但将其与其他数据模态融合可能会带来更深入的洞察和更准确的结果。深度神经网络（DNNs）已成为识别和定义医疗领域潜在模式的基本工具。然而，DNN模型在临床环境中广泛应用还需要基本改进的可解释性。在这项研究中，我们提出了一种建立在可解释的多模态数据驱动模型集合上的方法，可以预测和理解马德里训拉布拉达大学医院（西班牙）的重症监护病房（ICU）中抗菌药物多重耐药性（AMR）细菌的出现。患者的个人资料和初始健康状况使用静态变量进行建模，而演变过程使用MTS进行建模。

    Electronic health records (EHR) is an inherently multimodal register of the patient's health status characterized by static data and multivariate time series (MTS). While MTS are a valuable tool for clinical prediction, their fusion with other data modalities can possibly result in more thorough insights and more accurate results. Deep neural networks (DNNs) have emerged as fundamental tools for identifying and defining underlying patterns in the healthcare domain. However, fundamental improvements in interpretability are needed for DNN models to be widely used in the clinical setting. In this study, we present an approach built on a collection of interpretable multimodal data-driven models that may anticipate and understand the emergence of antimicrobial multidrug resistance (AMR) germs in the intensive care unit (ICU) of the University Hospital of Fuenlabrada (Madrid, Spain). The profile and initial health status of the patient are modeled using static variables, while the evolution 
    
[^124]: 使用大型语言模型的结构化实体提取

    Structured Entity Extraction Using Large Language Models

    [https://arxiv.org/abs/2402.04437](https://arxiv.org/abs/2402.04437)

    本论文提出了一种使用大型语言模型的结构化实体提取方法，在此任务上通过引入AESOP度量评估模型性能，并将整个提取任务分解为多个阶段，相较于基准模型取得了更好的效果，为未来结构化实体提取的进一步发展提供了有希望的方向。

    

    近年来，机器学习的最新进展显著影响了信息提取领域，大型语言模型（LLMs）在从非结构化文本中提取结构化信息方面起着关键作用。本文探讨了当前结构化实体提取方法的挑战和限制，并引入了一种新的方法来解决这些问题。我们首先介绍和规范化了结构化实体提取（SEE）任务，然后提出了适用于该任务的近似实体集重叠（AESOP）度量，以适当评估模型在这一任务上的性能。随后，我们提出了一种新模型，通过将整个提取任务分解为多个阶段，利用LLMs的强大功能来提高效果和效率。定量评估和人工并行评估证实了我们的模型优于基准模型，为结构化实体提取领域的未来进展提供了有希望的方向。

    Recent advances in machine learning have significantly impacted the field of information extraction, with Large Language Models (LLMs) playing a pivotal role in extracting structured information from unstructured text. This paper explores the challenges and limitations of current methodologies in structured entity extraction and introduces a novel approach to address these issues. We contribute to the field by first introducing and formalizing the task of Structured Entity Extraction (SEE), followed by proposing Approximate Entity Set OverlaP (AESOP) Metric designed to appropriately assess model performance on this task. Later, we propose a new model that harnesses the power of LLMs for enhanced effectiveness and efficiency through decomposing the entire extraction task into multiple stages. Quantitative evaluation and human side-by-side evaluation confirm that our model outperforms baselines, offering promising directions for future advancements in structured entity extraction.
    
[^125]: 用大型语言模型增强贝叶斯优化

    Large Language Models to Enhance Bayesian Optimization

    [https://arxiv.org/abs/2402.03921](https://arxiv.org/abs/2402.03921)

    通过结合大型语言模型（LLM）的能力，我们提出了一种名为LLAMBO的新方法，将其应用于贝叶斯优化（BO）。通过用自然语言描述BO问题，并利用LLM的上下文理解、少样本学习能力和领域知识，LLAMBO能够提供有前景的解决方案，并且在零样本热启动方面表现出良好的效果。

    

    贝叶斯优化（BO）是一种优化复杂和昂贵的黑盒函数的强大方法。它在许多应用中的重要性得到了强调，特别是超参数调优，但其有效性取决于有效地平衡勘探和开发。尽管在BO方法方面取得了重大进展，但平衡这一问题仍然是一个微妙的过程。在这个背景下，我们提出了一个新方法LLAMBO，它将大型语言模型（LLM）的能力与BO相结合。在高层次上，我们用自然语言的方式来描述BO问题，使LLM能够根据历史评估提出有前景的解决方案。更具体地说，我们探讨了如何结合LLM的上下文理解、少样本学习能力和领域知识，来增强基于模型的BO的各个组成部分。我们的研究结果表明，LLAMBO在零样本热启动方面是有效的，并且可以改善代理模型的性能。

    Bayesian optimization (BO) is a powerful approach for optimizing complex and expensive-to-evaluate black-box functions. Its importance is underscored in many applications, notably including hyperparameter tuning, but its efficacy depends on efficiently balancing exploration and exploitation. While there has been substantial progress in BO methods, striking this balance still remains a delicate process. In this light, we present \texttt{LLAMBO}, a novel approach that integrates the capabilities of large language models (LLM) within BO. At a high level, we frame the BO problem in natural language terms, enabling LLMs to iteratively propose promising solutions conditioned on historical evaluations. More specifically, we explore how combining contextual understanding, few-shot learning proficiency, and domain knowledge of LLMs can enhance various components of model-based BO. Our findings illustrate that \texttt{LLAMBO} is effective at zero-shot warmstarting, and improves surrogate modelin
    
[^126]: 重访基于生成对抗网络的不平衡数据集二进制语义分割

    Revisiting Generative Adversarial Networks for Binary Semantic Segmentation on Imbalanced Datasets

    [https://arxiv.org/abs/2402.02245](https://arxiv.org/abs/2402.02245)

    这项工作提出了一种基于生成对抗网络的深度学习框架，用于像素级别的路面异常区域检测。通过两个训练阶段和多尺度特征表示，该框架增强了生成器从异构输入中估计概率特征图的能力，并通过引入几种注意机制，解决了在严重不平衡数据集上训练模型时性能恶化的问题。

    

    异常路面表面状况检测旨在通过算法自动检测代表异常状态（如裂缝）的像素。最近，深度学习模型在相关领域取得了杰出的性能。然而，大多数现有的深度学习相关解决方案很少在多样化数据集上实现稳定的性能。为解决这个问题，在这项工作中，我们提出了一个基于条件生成对抗网络的深度学习框架，用于像素级别的路面异常区域检测。具体而言，我们的框架通过两个训练阶段和多尺度特征表示来提高生成器从异构输入中估计概率特征图的能力。此外，将几种注意机制纳入所提出的框架中，以减轻模型训练在严重不平衡数据集上性能恶化的问题。

    Anomalous pavement surface conditions detection aims to detect pixels representing anomalous states, such as cracks, on pavement surface images automatically by algorithms. Recently, deep learning models have been intensively applied to related topics with outstanding performance. However, most existing deep learning-related solutions rarely achieve a stable performance on diverse datasets. To address this issue, in this work, we propose a deep learning framework based on conditional Generative Adversarial Networks for anomalous region detection on pavement images at the pixel level. In particular, the proposed framework is developed to enhance the generator's ability to estimate the probability feature map from heterogeneous inputs with two training stages and multiscale feature representation. Moreover, several attention mechanisms are incorporated into the proposed framework to mitigate the performance deterioration of model training on severely imbalanced datasets. We implement exp
    
[^127]: 有效图形数据估值的优先约束冬季价值

    Precedence-Constrained Winter Value for Effective Graph Data Valuation

    [https://arxiv.org/abs/2402.01943](https://arxiv.org/abs/2402.01943)

    提出了一种名为PC-Winter的优先约束冬季价值方法，用于有效地评估复杂图形数据的价值。通过解决复杂的图形结构以及计算挑战，PC-Winter方法在各种数据集和任务中展示了其有效性。

    

    数据估值对于量化数据的价值、评估数据质量和确定公平补偿至关重要。现有的数据估值方法在评估欧几里德数据的价值方面已被证明有效，但在应用于越来越受欢迎的图形数据时存在局限性。特别是，图形数据估值引入了独特的挑战，主要源于节点之间复杂的依赖关系和价值估计成本的指数增长。为了解决图形数据估值的问题，我们提出了一种创新的解决方案，称为优先约束冬季价值(Precedence-Constrained Winter, PC-Winter)，以考虑复杂的图形结构。此外，我们还开发了多种策略来解决计算挑战，实现对PC-Winter的高效近似。大量的实验证明了PC-Winter在各种数据集和任务上的有效性。

    Data valuation is essential for quantifying data's worth, aiding in assessing data quality and determining fair compensation. While existing data valuation methods have proven effective in evaluating the value of Euclidean data, they face limitations when applied to the increasingly popular graph-structured data. Particularly, graph data valuation introduces unique challenges, primarily stemming from the intricate dependencies among nodes and the exponential growth in value estimation costs. To address the challenging problem of graph data valuation, we put forth an innovative solution, Precedence-Constrained Winter (PC-Winter) Value, to account for the complex graph structure. Furthermore, we develop a variety of strategies to address the computational challenges and enable efficient approximation of PC-Winter. Extensive experiments demonstrate the effectiveness of PC-Winter across diverse datasets and tasks.
    
[^128]: 用于动态潜在图的神经时序点过程的变分自编码器

    A Variational Autoencoder for Neural Temporal Point Processes with Dynamic Latent Graphs

    [https://arxiv.org/abs/2312.16083](https://arxiv.org/abs/2312.16083)

    提出了一种用于捕捉混合时间动态的新颖变分自编码器模型，使用顺序潜变量模型在子间隔内学习事件间的依赖图，提高了在预测事件间隔时间方面的准确性。

    

    连续观察到的事件发生往往表现出自激和互激效应，可以很好地用时序点过程模型化。除此之外，这些事件动态也可能随时间变化，具有某种周期性趋势。我们提出了一种新颖的变分自编码器来捕捉这种混合的时间动态。具体而言，输入序列的整个时间间隔被划分为一组子间隔。假设每个子间隔内的事件动态是稳定的，但在这些子间隔之间可能会发生变化。特别地，我们使用一个顺序潜变量模型来学习每个子间隔中观察维度之间的依赖图。该模型通过使用学习到的依赖图来消除过去事件的非贡献影响，预测未来的事件发生时间。通过这样做，提出的模型在预测事件间隔时间上展示出更高的准确度。

    arXiv:2312.16083v2 Announce Type: replace  Abstract: Continuously-observed event occurrences, often exhibit self- and mutually-exciting effects, which can be well modeled using temporal point processes. Beyond that, these event dynamics may also change over time, with certain periodic trends. We propose a novel variational auto-encoder to capture such a mixture of temporal dynamics. More specifically, the whole time interval of the input sequence is partitioned into a set of sub-intervals. The event dynamics are assumed to be stationary within each sub-interval, but could be changing across those sub-intervals. In particular, we use a sequential latent variable model to learn a dependency graph between the observed dimensions, for each sub-interval. The model predicts the future event times, by using the learned dependency graph to remove the noncontributing influences of past events. By doing so, the proposed model demonstrates its higher accuracy in predicting inter-event times and e
    
[^129]: MixEHR-SurG：一种联合比例危险和引导主题模型，用于从电子健康记录中推断与死亡相关的主题

    MixEHR-SurG: a joint proportional hazard and guided topic model for inferring mortality-associated topics from electronic health records

    [https://arxiv.org/abs/2312.13454](https://arxiv.org/abs/2312.13454)

    MixEHR-SurG是一种监督主题模型，结合了EHR数据和生存风险模型，实现了高度可解释的生存主题模型，可以推断与患者死亡相关的PheCode特定表型主题。

    

    现有的生存模型要么不适用于高维和多模态数据，要么很难解释。在本研究中，我们提出了一个名为MixEHR-SurG的监督主题模型，可以同时整合异质EHR数据并建模生存风险。我们的贡献有三个方面：(1) 将EHR主题推断与Cox比例风险似然相结合；(2) 使用PheCode概念集成特定于患者的主题超参数，使得每个主题可以被识别为仅与一个PheCode相关的表型；(3) 多模态生存主题推断。这导致了一个高度可解释的生存主题模型，可以推断与患者死亡相关的PheCode特定表型主题。我们使用一个模拟数据集和两个真实世界EHR数据集（魁北克先天性心脏病（CHD）数据和包含8,211名受试者的多个门诊索赔记录的1,767个唯一ICD行为）来评估MixEHR-SurG。

    arXiv:2312.13454v2 Announce Type: replace  Abstract: Existing survival models either do not scale to high dimensional and multi-modal data or are difficult to interpret. In this study, we present a supervised topic model called MixEHR-SurG to simultaneously integrate heterogeneous EHR data and model survival hazard. Our contributions are three-folds: (1) integrating EHR topic inference with Cox proportional hazards likelihood; (2) integrating patient-specific topic hyperparameters using the PheCode concepts such that each topic can be identified with exactly one PheCode-associated phenotype; (3) multi-modal survival topic inference. This leads to a highly interpretable survival topic model that can infer PheCode-specific phenotype topics associated with patient mortality. We evaluated MixEHR-SurG using a simulated dataset and two real-world EHR datasets: the Quebec Congenital Heart Disease (CHD) data consisting of 8,211 subjects with 75,187 outpatient claim records of 1,767 unique ICD 
    
[^130]: ERASE: 基于图的表示学习中的误差容忍性研究

    ERASE: Error-Resilient Representation Learning on Graphs for Label Noise Tolerance

    [https://arxiv.org/abs/2312.08852](https://arxiv.org/abs/2312.08852)

    ERASE提出了一种名为ERASE的方法，通过最大化编码率降低来学习具有误差容忍性的表示，以增强深度学习模型对图任务中标签噪声的鲁棒性。

    

    深度学习在图相关任务中取得了显著的成功，然而这一成就严重依赖于大规模高质量注释数据集。然而，获取这样的数据集可能成本过高，因此实际上使用经济高效来源（如网络搜索和用户标签）获得的标签。不幸的是，这些标签经常带有噪声，影响深度网络的泛化性能。为了解决这一挑战，增强图任务中深度学习模型对标签噪声的鲁棒性，我们提出了一种称为ERASE（基于图的表示学习中的误差容忍性）的方法。ERASE的核心思想是通过最大化编码率降低来学习具有误差容忍性的表示。特别地，我们引入了一种解耦的标签传播方法来学习表示。在训练之前，通过结构化方法预校正噪声标签。

    arXiv:2312.08852v2 Announce Type: replace  Abstract: Deep learning has achieved remarkable success in graph-related tasks, yet this accomplishment heavily relies on large-scale high-quality annotated datasets. However, acquiring such datasets can be cost-prohibitive, leading to the practical use of labels obtained from economically efficient sources such as web searches and user tags. Unfortunately, these labels often come with noise, compromising the generalization performance of deep networks. To tackle this challenge and enhance the robustness of deep learning models against label noise in graph-based tasks, we propose a method called ERASE (Error-Resilient representation learning on graphs for lAbel noiSe tolerancE). The core idea of ERASE is to learn representations with error tolerance by maximizing coding rate reduction. Particularly, we introduce a decoupled label propagation method for learning representations. Before training, noisy labels are pre-corrected through structural
    
[^131]: 一种基于任务反馈的动态剪裁方法用于近端策略优化

    A dynamical clipping approach with task feedback for Proximal Policy Optimization

    [https://arxiv.org/abs/2312.07624](https://arxiv.org/abs/2312.07624)

    提出了一种基于任务反馈的动态剪裁方法，通过增加最大累积回报来优化近端策略优化的性能。

    

    近端策略优化（PPO）已被广泛应用于各个领域，包括大型语言模型（LLM）优化和机器人学习等。然而，PPO受到固定剪裁边界的限制。具体而言，目前没有理论证明最佳剪裁边界在整个训练过程中始终保持一致。通过用一个独特的剪裁边界截断新旧策略的比率，可以确保稳定的训练并实现最佳的训练性能。此外，先前的研究表明，固定的剪裁边界限制了agent的探索。因此，研究一种动态剪裁边界以增强PPO的性能是非常有益的。与以往的剪裁方法不同，我们考虑将在强化学习（RL）任务中增加最大累积回报视作RL任务的偏好，并提出了一个双层近端策略优化范式。

    arXiv:2312.07624v2 Announce Type: replace-cross  Abstract: Proximal Policy Optimization (PPO) has been broadly applied to various domains, including Large Language Model (LLM) optimization and Robotics learning, etc. However, PPO is limited by a fixed setting for the clipping bound. Specifically, there is no theoretical proof that the optimal clipping bound remains consistent throughout the entire training process. Truncating the ratio of the new and old policies with a unique clipping bound ensures stable training and can achieve the best training performance. Additionally, previous research suggests that a fixed clipping bound limits the agent's exploration. Therefore, researching a dynamical clipping bound to enhance PPO's performance can be highly beneficial. Different from previous clipping approaches, we consider increasing the maximum cumulative Return in reinforcement learning (RL) tasks as the preference of the RL task, and propose a bi-level proximal policy optimization parad
    
[^132]: 用于非结构稀疏恢复的特征矩阵

    Eigenmatrix for unstructured sparse recovery

    [https://arxiv.org/abs/2311.16609](https://arxiv.org/abs/2311.16609)

    本文提出了一种名为特征矩阵的数据驱动构造，用于解决非结构稀疏恢复问题，对于样本值中的噪声和样本位置的非结构性质具有很好的适应性。

    

    本文考虑了一般形式的非结构稀疏恢复问题，包括有理逼近、谱函数估计、傅里叶反演、拉普拉斯反演和稀疏反卷积等。主要挑战是样本值中的噪声和样本位置的非结构性质。本文提出了特征矩阵，一种具有所需近似特征值和特征向量的数据驱动构造，为这些稀疏恢复问题提供了一种新的方法。数值结果证明了所提方法的效率。

    This paper considers the unstructured sparse recovery problems in a general form. Examples include rational approximation, spectral function estimation, Fourier inversion, Laplace inversion, and sparse deconvolution. The main challenges are the noise in the sample values and the unstructured nature of the sample locations. This paper proposes the eigenmatrix, a data-driven construction with desired approximate eigenvalues and eigenvectors. The eigenmatrix offers a new way for these sparse recovery problems. Numerical results are provided to demonstrate the efficiency of the proposed method.
    
[^133]: DPOD：面向多模态假新闻检测的领域特定提示调节

    DPOD: Domain-Specific Prompt Tuning for Multimodal Fake News Detection

    [https://arxiv.org/abs/2311.16496](https://arxiv.org/abs/2311.16496)

    本研究提出了一种名为DPOD的框架，通过利用跨领域数据来改善所需领域的脱离上下文误信息检测，解决数据不平衡的问题。

    

    虚假新闻利用脱离上下文的图像传播已经变得普遍，是信息过载时代一个相关的问题。这种脱离上下文的虚假新闻可能涉及不同领域，如政治、体育、娱乐等。在实际场景中，不同领域新闻文章存在着数据不平衡的问题，部分领域数据丰富，而其他领域数据非常有限。在这种情况下，必须开发出能够适应不同数据量设置的方法。本文探讨了跨领域数据是否有助于改善所需领域的脱离上下文误信息检测（在此称为多模态虚假新闻检测）的方法以解决这一具有挑战性的问题。为此，我们提出了一种名为DPOD（使用跨领域数据进行领域特定提示调节）的新框架。

    arXiv:2311.16496v2 Announce Type: replace  Abstract: The spread of fake news using out-of-context images has become widespread and is a relevant problem in this era of information overload. Such out-of-context fake news may arise across different domains like politics, sports, entertainment, etc. In practical scenarios, an inherent problem of imbalance exists among news articles from such widely varying domains, resulting in a few domains with abundant data, while the rest containing very limited data. Under such circumstances, it is imperative to develop methods which can work in such varying amounts of data setting. In this work, we explore whether out-of-domain data can help to improve out-of-context misinformation detection (termed here as multi-modal fake news detection) of a desired domain, to address this challenging problem. Towards this goal, we propose a novel framework termed DPOD (Domain-specific Prompt-tuning using Out-of-Domain data). First, to compute generalizable featu
    
[^134]: 面向人类白蛋白预测的超分布广义动态图神经网络

    Out-of-Distribution Generalized Dynamic Graph Neural Network for Human Albumin Prediction

    [https://arxiv.org/abs/2311.15545](https://arxiv.org/abs/2311.15545)

    提出了一种名为DyG-HAP的框架，利用超分布广义动态图神经网络进行人类白蛋白预测，特别适用于ICU患者。

    

    人类白蛋白对指示身体整体健康至关重要。准确预测血浆白蛋白水平并确定适当剂量是亟需解决的临床挑战，尤其是在危重患者中，以保持最佳血液水平。然而，人类白蛋白预测并不简单，必须利用生化标志物的动态性以及治疗患者的经验。此外，真实临床数据中经常遇到分布转移问题，这可能导致模型预测性能下降，降低模型应用的可靠性。在本文中，我们提出了一个名为Out-of-Distribution Generalized Dynamic Graph神经网络的框架，用于人类白蛋白预测（DyG-HAP），能够提供在住院期间为重症监护病房（ICU）患者提供准确的白蛋白预测。

    arXiv:2311.15545v2 Announce Type: replace-cross  Abstract: Human albumin is essential for indicating the body's overall health. Accurately predicting plasma albumin levels and determining appropriate doses are urgent clinical challenges, particularly in critically ill patients, to maintain optimal blood levels. However, human albumin prediction is non-trivial that has to leverage the dynamics of biochemical markers as well as the experience of treating patients. Moreover, the problem of distribution shift is often encountered in real clinical data, which may lead to a decline in the model prediction performance and reduce the reliability of the model's application. In this paper, we propose a framework named Out-of-Distribution Generalized Dynamic Graph Neural Network for Human Albumin Prediction (DyG-HAP), which is able to provide accurate albumin predictions for Intensity Care Unit (ICU) patients during hospitalization. We first model human albumin prediction as a dynamic graph regre
    
[^135]: 具有解耦干预和不变推动的超出分布的广义动态图神经网络

    Out-of-Distribution Generalized Dynamic Graph Neural Network with Disentangled Intervention and Invariance Promotion

    [https://arxiv.org/abs/2311.14255](https://arxiv.org/abs/2311.14255)

    本文提出了一种名为I-DIDA的动态图神经网络来处理动态图中的时空分布变化，通过发现和利用稳定的不变模式，即结构和特征在分布变化下具有稳定预测能力。

    

    动态图神经网络（DyGNNs）通过利用图结构和时间动态展示了强大的预测能力。然而，现有的DyGNNs无法处理分布的变化，这在动态图中是自然存在的，主要是因为DyGNNs所利用的模式可能在分布变化下对标签不变。本文提出了基于解耦干预和不变推动的动态图注意力网络（I-DIDA），以发现和利用不变模式，即那些结构和特征的预测能力在分布变化下保持稳定。具体地，我们首先提出了一个解耦的时空注意力网络来捕捉变异和不变的模式。通过利用解耦模式，我们设计了一个时空干预机制来创建多个干预

    arXiv:2311.14255v2 Announce Type: replace  Abstract: Dynamic graph neural networks (DyGNNs) have demonstrated powerful predictive abilities by exploiting graph structural and temporal dynamics. However, the existing DyGNNs fail to handle distribution shifts, which naturally exist in dynamic graphs, mainly because the patterns exploited by DyGNNs may be variant with respect to labels under distribution shifts. In this paper, we propose Disentangled Intervention-based Dynamic graph Attention networks with Invariance Promotion (I-DIDA) to handle spatio-temporal distribution shifts in dynamic graphs by discovering and utilizing invariant patterns, i.e., structures and features whose predictive abilities are stable across distribution shifts. Specifically, we first propose a disentangled spatio-temporal attention network to capture the variant and invariant patterns. By utilizing the disentangled patterns, we design a spatio-temporal intervention mechanism to create multiple interventional 
    
[^136]: 一个基于规则学习的可解释分类投票方法研究

    A Voting Approach for Explainable Classification with Rule Learning

    [https://arxiv.org/abs/2311.07323](https://arxiv.org/abs/2311.07323)

    该论文研究了一种将规则学习和投票方法相结合的新方法，旨在实现与先进机器学习方法相媲美的分类结果，并提供基于确定性规则的解释。

    

    典型分类任务中最先进的结果通常由无法解释的机器学习方法（如深度神经网络）实现。相反，在本文中，我们研究了规则学习方法在这样的情境下的应用。因此，分类基于可理解（一阶）规则，这些规则解释了所作出的预测。总的来说，然而，基于规则的分类远不如最先进的结果准确（通常显著）。作为主要贡献，我们引入了一种结合了两个领域的投票方法，旨在实现与（无法解释的）最先进方法可比较的结果，同时仍以确定性规则的形式提供解释。考虑到包括对保险业具有重要意义的使用案例在内的各种基准数据集，我们证明了我们的方法不仅明显优于普通的规则学习方法，而且在实践中取得了结果

    arXiv:2311.07323v2 Announce Type: replace  Abstract: State-of-the-art results in typical classification tasks are mostly achieved by unexplainable machine learning methods, like deep neural networks, for instance. Contrarily, in this paper, we investigate the application of rule learning methods in such a context. Thus, classifications become based on comprehensible (first-order) rules, explaining the predictions made. In general, however, rule-based classifications are less accurate than state-of-the-art results (often significantly). As main contribution, we introduce a voting approach combining both worlds, aiming to achieve comparable results as (unexplainable) state-of-the-art methods, while still providing explanations in the form of deterministic rules. Considering a variety of benchmark data sets including a use case of significant interest to insurance industries, we prove that our approach not only clearly outperforms ordinary rule learning methods, but also yields results on
    
[^137]: 神经气候通用循环模型

    Neural General Circulation Models for Weather and Climate

    [https://arxiv.org/abs/2311.07222](https://arxiv.org/abs/2311.07222)

    该研究提出了第一个结合了大气动力学可微分求解器和机器学习组件的GCM，展示其能够生成与最佳机器学习和基于物理模型方法相匹敌的确定性天气、集合天气和气候预测。

    

    气候通用循环模型（GCMs）是天气和气候预测的基础。最近，一种结合了数值求解器和小尺度过程（如云形成）调校的GCMs的机器学习（ML）模型在重新分析数据上训练的表现，达到了与确定性天气预报中GCMs相当或更好的水平。

    arXiv:2311.07222v3 Announce Type: replace-cross  Abstract: General circulation models (GCMs) are the foundation of weather and climate prediction. GCMs are physics-based simulators which combine a numerical solver for large-scale dynamics with tuned representations for small-scale processes such as cloud formation. Recently, machine learning (ML) models trained on reanalysis data achieved comparable or better skill than GCMs for deterministic weather forecasting. However, these models have not demonstrated improved ensemble forecasts, or shown sufficient stability for long-term weather and climate simulations. Here we present the first GCM that combines a differentiable solver for atmospheric dynamics with ML components, and show that it can generate forecasts of deterministic weather, ensemble weather and climate on par with the best ML and physics-based methods. NeuralGCM is competitive with ML models for 1-10 day forecasts, and with the European Centre for Medium-Range Weather Forec
    
[^138]: LLM能遵守简单规则吗?

    Can LLMs Follow Simple Rules?

    [https://arxiv.org/abs/2311.04235](https://arxiv.org/abs/2311.04235)

    提出了一个名为RuLES的程序框架，用于衡量LLMs在与用户交互时遵守规则的能力。

    

    随着大型语言模型（LLMs）在现实世界中承担越来越多的责任，能够以可靠的方式指定和约束这些系统的行为变得至关重要。我们提出了规则遵循语言评估场景（RuLES），这是一个测量LLMs遵循规则能力的程序框架，包括14个简单的文本场景，模型在与用户交互时被指示遵守各种规则。

    arXiv:2311.04235v2 Announce Type: replace  Abstract: As Large Language Models (LLMs) are deployed with increasing real-world responsibilities, it is important to be able to specify and constrain the behavior of these systems in a reliable manner. Model developers may wish to set explicit rules for the model, such as "do not generate abusive content", but these may be circumvented by jailbreaking techniques. Existing evaluations of adversarial attacks and defenses on LLMs generally require either expensive manual review or unreliable heuristic checks. To address this issue, we propose Rule-following Language Evaluation Scenarios (RuLES), a programmatic framework for measuring rule-following ability in LLMs. RuLES consists of 14 simple text scenarios in which the model is instructed to obey various rules while interacting with the user. Each scenario has a programmatic evaluation function to determine whether the model has broken any rules in a conversation. Our evaluations of proprietar
    
[^139]: 具有部分可观测性的多视图因果表示学习

    Multi-View Causal Representation Learning with Partial Observability

    [https://arxiv.org/abs/2311.04056](https://arxiv.org/abs/2311.04056)

    我们提出了一个统一的框架，用于学习来自不同数据视图的因果关系表示，证明了跨视图子集的信息可以通过对比学习和单个编码器学习，同时提供了一个观测潜在变量的简单规则。

    

    我们提出了一个统一的框架，用于研究从同时观察到的视图（如不同数据模态）学习到的表示的可识别性。我们允许部分观测设置，其中每个视图构成底层潜在变量子集的非线性混合，这些变量可以存在因果关系。我们证明，通过对比学习和每个视图一个编码器，可以学习到跨所有任意数量视图子集共享的信息，直至平滑双射。我们还提供了图形标准，指示可以通过一组简单规则确定哪些潜在变量，我们称之为可识别性代数。我们的总体框架和理论结果统一并扩展了先前关于多视图非线性ICA、解缠以及因果表示学习的几项工作。我们在数字、图像和多模态数据集上通过实验证实了我们的论断。

    arXiv:2311.04056v2 Announce Type: replace-cross  Abstract: We present a unified framework for studying the identifiability of representations learned from simultaneously observed views, such as different data modalities. We allow a partially observed setting in which each view constitutes a nonlinear mixture of a subset of underlying latent variables, which can be causally related. We prove that the information shared across all subsets of any number of views can be learned up to a smooth bijection using contrastive learning and a single encoder per view. We also provide graphical criteria indicating which latent variables can be identified through a simple set of rules, which we refer to as identifiability algebra. Our general framework and theoretical results unify and extend several previous works on multi-view nonlinear ICA, disentanglement, and causal representation learning. We experimentally validate our claims on numerical, image, and multi-modal data sets. Further, we demonstr
    
[^140]: 具有多实例学习的混合模型

    Mixed Models with Multiple Instance Learning

    [https://arxiv.org/abs/2311.02455](https://arxiv.org/abs/2311.02455)

    MixMIL是一个整合了广义线性混合模型（GLMM）和多实例学习（MIL）的框架，能够更好地处理单细胞数据中的细胞异质性，在单细胞数据集中表现优越。

    

    从单细胞数据中预测患者特征有助于确定与健康和疾病相关的细胞状态。线性模型和平均细胞类型表达通常被偏爱用于此任务，因为它们高效且稳健，但它们忽视了单细胞数据中固有的丰富细胞异质性。为了填补这一空白，我们引入了MixMIL，一个整合了广义线性混合模型（GLMM）和多实例学习（MIL）的框架，保留线性模型的优势同时建模细胞状态的异质性。通过利用预定义的细胞嵌入，MixMIL提高了计算效率，并与最近在单细胞表示学习中的进展保持一致。我们的实证结果显示，MixMIL在单细胞数据集中优于现有的MIL模型，揭示了新的关联并阐明了不同领域之间的生物学机制。

    arXiv:2311.02455v2 Announce Type: replace  Abstract: Predicting patient features from single-cell data can help identify cellular states implicated in health and disease. Linear models and average cell type expressions are typically favored for this task for their efficiency and robustness, but they overlook the rich cell heterogeneity inherent in single-cell data. To address this gap, we introduce MixMIL, a framework integrating Generalized Linear Mixed Models (GLMM) and Multiple Instance Learning (MIL), upholding the advantages of linear models while modeling cell state heterogeneity. By leveraging predefined cell embeddings, MixMIL enhances computational efficiency and aligns with recent advancements in single-cell representation learning. Our empirical results reveal that MixMIL outperforms existing MIL models in single-cell datasets, uncovering new associations and elucidating biological mechanisms across different domains.
    
[^141]: 平衡之道：约束稀疏模型中的不平等影响

    Balancing Act: Constraining Disparate Impact in Sparse Models

    [https://arxiv.org/abs/2310.20673](https://arxiv.org/abs/2310.20673)

    提出了一种约束优化方法，直接解决修剪导致的不平等问题，为每个子组设置界限以限制稠密和稀疏模型之间的准确度变化。

    

    模型修剪是一种常用方法，可以在计算或存储容量受限的边缘设备上部署大型深度学习模型。尽管稀疏模型在整个数据集的级别上实现了与密集模型相媲美的性能，但对于某些数据子组，它们表现出高准确度降落。现有的缓解修剪引起的不平等影响的方法要么依赖于间接解决问题的替代指标并具有有限的解释性，要么随着受保护子组数量的增多而在计算成本方面表现不佳。我们提出了一种约束优化方法，直接解决修剪的不平等影响：我们的制定界定了在每个子组中稠密和稀疏模型之间的准确度变化。这些约束的选择为确定修剪模型是否实现可接受的不平等提供了可解释的成功标准。

    arXiv:2310.20673v2 Announce Type: replace  Abstract: Model pruning is a popular approach to enable the deployment of large deep learning models on edge devices with restricted computational or storage capacities. Although sparse models achieve performance comparable to that of their dense counterparts at the level of the entire dataset, they exhibit high accuracy drops for some data sub-groups. Existing methods to mitigate this disparate impact induced by pruning (i) rely on surrogate metrics that address the problem indirectly and have limited interpretability; or (ii) scale poorly with the number of protected sub-groups in terms of computational cost. We propose a constrained optimization approach that directly addresses the disparate impact of pruning: our formulation bounds the accuracy change between the dense and sparse models, for each sub-group. This choice of constraints provides an interpretable success criterion to determine if a pruned model achieves acceptable disparity le
    
[^142]: 可微学习广义结构化矩阵以实现高效深度神经网络

    Differentiable Learning of Generalized Structured Matrices for Efficient Deep Neural Networks

    [https://arxiv.org/abs/2310.18882](https://arxiv.org/abs/2310.18882)

    提出了一种可微的广义框架，通过梯度下降学习高效的权重矩阵结构。

    

    本文研究了有效的深度神经网络（DNNs），通过具有所需属性的结构化矩阵取代密集非结构化权重矩阵。我们提出了一个广义和可微的框架，通过梯度下降学习权重矩阵的高效结构。我们首先定义了一类新的结构化矩阵，通过调整结构参数覆盖了文献中广泛的结构化矩阵。然后，采用基于高斯-狄利克雷核的频域可微参数化方案来学习结构参数。

    arXiv:2310.18882v2 Announce Type: replace-cross  Abstract: This paper investigates efficient deep neural networks (DNNs) to replace dense unstructured weight matrices with structured ones that possess desired properties. The challenge arises because the optimal weight matrix structure in popular neural network models is obscure in most cases and may vary from layer to layer even in the same network. Prior structured matrices proposed for efficient DNNs were mostly hand-crafted without a generalized framework to systematically learn them. To address this issue, we propose a generalized and differentiable framework to learn efficient structures of weight matrices by gradient descent. We first define a new class of structured matrices that covers a wide range of structured matrices in the literature by adjusting the structural parameters. Then, the frequency-domain differentiable parameterization scheme based on the Gaussian-Dirichlet kernel is adopted to learn the structural parameters b
    
[^143]: ManyQuadrupeds: 学习适用于多样化四足机器人的单一运动策略

    ManyQuadrupeds: Learning a Single Locomotion Policy for Diverse Quadruped Robots

    [https://arxiv.org/abs/2310.10486](https://arxiv.org/abs/2310.10486)

    通过受动物运动控制的启发，我们展示出能够有效训练一个单一运动策略，可以控制多样化四足机器人。

    

    传统上，为四足机器人学习运动策略通常受限于特定的机器人形态、质量和尺寸。学习过程通常必须针对每台新机器人重复进行，需要重新调整超参数和奖励函数权重以最大化每个新系统的性能。另外，尝试训练一个单一策略以适应不同大小的机器人，同时保持相同的自由度（DoF）和形态，需要复杂的学习框架，或者质量、惯性和尺寸随机化，这导致训练时间延长。在我们的研究中，我们展示受动物运动控制的启发，可以有效地训练一个能够控制多样化四足机器人的单一运动策略。这些机器人的差异包括：可变数量的DoF（即12或16个关节）、三种不同的形态和从较低到较高质量范围的广泛质量跨度。

    arXiv:2310.10486v2 Announce Type: replace-cross  Abstract: Learning a locomotion policy for quadruped robots has traditionally been constrained to a specific robot morphology, mass, and size. The learning process must usually be repeated for every new robot, where hyperparameters and reward function weights must be re-tuned to maximize performance for each new system. Alternatively, attempting to train a single policy to accommodate different robot sizes, while maintaining the same degrees of freedom (DoF) and morphology, requires either complex learning frameworks, or mass, inertia, and dimension randomization, which leads to prolonged training periods. In our study, we show that drawing inspiration from animal motor control allows us to effectively train a single locomotion policy capable of controlling a diverse range of quadruped robots. The robot differences encompass: a variable number of DoFs, (i.e. 12 or 16 joints), three distinct morphologies, a broad mass range spanning from 
    
[^144]: 谨慎平滑标签：标签平滑既可以作为隐私屏障，又可以成为模型反推攻击的催化剂

    Be Careful What You Smooth For: Label Smoothing Can Be a Privacy Shield but Also a Catalyst for Model Inversion Attacks

    [https://arxiv.org/abs/2310.06549](https://arxiv.org/abs/2310.06549)

    标签平滑方法在深度学习中发挥重要作用，既能提升模型泛化能力和校准性，又可能成为模型隐私泄露的因素。研究揭示了结合负因子进行平滑可有效阻止模型反推攻击，提升隐私保护效果，超越了当前最先进的防御技术。

    

    标签平滑——使用软化的标签而不是硬标签——是深度学习中被广泛采用的正则化方法，表现出增强泛化和校准等多样益处。然而，它对于保护模型隐私的影响仍然没有被探索。为了填补这一空白，我们调查了标签平滑对模型反推攻击（MIAs）的影响，这些攻击旨在通过利用分类器中编码的知识生成具有类代表性的样本，从而推断有关其训练数据的敏感信息。通过广泛的分析，我们发现传统标签平滑促进了MIAs，从而增加了模型的隐私泄露。更甚者，我们揭示了用负因子进行平滑可以抵制这一趋势，阻碍提取与类相关的信息，实现隐私保护，胜过最先进的防御方法。这确立了一种实用且强大的新的增强方式。

    arXiv:2310.06549v2 Announce Type: replace  Abstract: Label smoothing -- using softened labels instead of hard ones -- is a widely adopted regularization method for deep learning, showing diverse benefits such as enhanced generalization and calibration. Its implications for preserving model privacy, however, have remained unexplored. To fill this gap, we investigate the impact of label smoothing on model inversion attacks (MIAs), which aim to generate class-representative samples by exploiting the knowledge encoded in a classifier, thereby inferring sensitive information about its training data. Through extensive analyses, we uncover that traditional label smoothing fosters MIAs, thereby increasing a model's privacy leakage. Even more, we reveal that smoothing with negative factors counters this trend, impeding the extraction of class-related information and leading to privacy preservation, beating state-of-the-art defenses. This establishes a practical and powerful novel way for enhanc
    
[^145]: TAIL: 任务特定的适配器用于具有大型预训练模型的模仿学习

    TAIL: Task-specific Adapters for Imitation Learning with Large Pretrained Models

    [https://arxiv.org/abs/2310.05905](https://arxiv.org/abs/2310.05905)

    TAIL提出了一种适配器框架，通过高效微调技术将大型预训练模型用于新的控制任务，以实现数据有效率、持续适应不同控制任务。

    

    大型预训练模型在控制领域（如机器人技术）中的潜力尚未得到充分利用，主要原因是数据稀缺以及为这些应用程序训练或微调这些大型模型所带来的计算挑战。我们介绍了TAIL（任务特定的适配器用于模仿学习），这是一个用于有效适应新控制任务的框架。受到语言领域参数高效微调的最新进展的启发，我们在TAIL中探讨了高效微调技术，例如瓶颈适配器、P调整和低秩适配（LoRA），以将大型预训练模型调整为具有有限演示数据的新任务。

    arXiv:2310.05905v2 Announce Type: replace-cross  Abstract: The full potential of large pretrained models remains largely untapped in control domains like robotics. This is mainly because of the scarcity of data and the computational challenges associated with training or fine-tuning these large models for such applications. Prior work mainly emphasizes either effective pretraining of large models for decision-making or single-task adaptation. But real-world problems will require data-efficient, continual adaptation for new control tasks. Recognizing these constraints, we introduce TAIL (Task-specific Adapters for Imitation Learning), a framework for efficient adaptation to new control tasks. Inspired by recent advancements in parameter-efficient fine-tuning in language domains, we explore efficient fine-tuning techniques -- e.g., Bottleneck Adapters, P-Tuning, and Low-Rank Adaptation (LoRA) -- in TAIL to adapt large pretrained models for new tasks with limited demonstration data. Our e
    
[^146]: 用于更具表达力的张量网络模型的量化傅立叶和多项式特征

    Quantized Fourier and Polynomial Features for more Expressive Tensor Network Models

    [https://arxiv.org/abs/2309.05436](https://arxiv.org/abs/2309.05436)

    提出了一种量化傅立叶和多项式特征的方法，并基于此特征量化提出将相关模型权重也进行量化，得到了更具表达力的张量网络模型。

    

    在核机器的背景下，多项式和傅立叶特征通常用于通过将数据映射到更高维空间来为线性模型提供非线性扩展。本文中，我们量化了多项式和傅立叶特征，提出了将相关模型权重量化的方法，得到了量化模型。

    arXiv:2309.05436v2 Announce Type: replace  Abstract: In the context of kernel machines, polynomial and Fourier features are commonly used to provide a nonlinear extension to linear models by mapping the data to a higher-dimensional space. Unless one considers the dual formulation of the learning problem, which renders exact large-scale learning unfeasible, the exponential increase of model parameters in the dimensionality of the data caused by their tensor-product structure prohibits to tackle high-dimensional problems. One of the possible approaches to circumvent this exponential scaling is to exploit the tensor structure present in the features by constraining the model weights to be an underparametrized tensor network. In this paper we quantize, i.e. further tensorize, polynomial and Fourier features. Based on this feature quantization we propose to quantize the associated model weights, yielding quantized models. We show that, for the same number of model parameters, the resulting 
    
[^147]: 使用学习自动机降低自私挖矿和双花攻击风险的新智能防御系统

    New intelligent defense systems to reduce the risks of Selfish Mining and Double-Spending attacks using Learning Automata

    [https://arxiv.org/abs/2307.00529](https://arxiv.org/abs/2307.00529)

    提出了一种结合双花和自私挖矿攻击的全新攻击方式，并使用学习自动机提出了两种模型（SDTLA和WVBM），可以有效抵御自私挖矿攻击，提高盈利阈值。

    

    在本文中，我们解决了基于区块链的数字货币中双花和自私挖矿攻击的关键挑战。双花是指在数字货币交易中同一货币被多次支出的问题，而自私挖矿则是有意地改变区块链以增加一个矿工或一组矿工的奖励。我们提出了一种结合了这两种攻击的新攻击，并提出了基于机器学习的解决方案来减轻与它们相关的风险。具体来说，我们使用了学习自动机这一强大的在线学习方法，开发了两个模型，即SDTLA和WVBM，可以有效防御自私挖矿攻击。我们的实验结果表明，SDTLA方法将自私挖矿的盈利阈值提高了47％，而WVBM方法的表现甚至更好，非常接近理想情况，即每个矿工的收益。

    arXiv:2307.00529v2 Announce Type: replace-cross  Abstract: In this paper, we address the critical challenges of double-spending and selfish mining attacks in blockchain-based digital currencies. Double-spending is a problem where the same tender is spent multiple times during a digital currency transaction, while selfish mining is an intentional alteration of a blockchain to increase rewards to one miner or a group of miners. We introduce a new attack that combines both these attacks and propose a machine learning-based solution to mitigate the risks associated with them. Specifically, we use the learning automaton, a powerful online learning method, to develop two models, namely the SDTLA and WVBM, which can effectively defend against selfish mining attacks. Our experimental results show that the SDTLA method increases the profitability threshold of selfish mining up to 47$\%$, while the WVBM method performs even better and is very close to the ideal situation where each miner's reven
    
[^148]: 优化时间序列对比学习：一种动态坏样本挖掘方法

    Towards Enhancing Time Series Contrastive Learning: A Dynamic Bad Pair Mining Approach

    [https://arxiv.org/abs/2302.03357](https://arxiv.org/abs/2302.03357)

    提出了一种动态坏样本挖掘（DBPM）算法，可靠地识别和抑制时间序列对比学习中的噪声正样本对和错误正样本对。

    

    不是所有的正样本对对时间序列对比学习都有益处。本文研究了两种可能影响对比学习学习到的时间序列表示质量的坏正样本对：噪声正样本对和错误正样本对。我们观察到，当存在噪声正样本对时，模型往往只学习噪声的模式（噪声对齐）。与此同时，当出现错误正样本对时，模型会浪费大量精力来对齐非代表性模式（错误对齐）。为了解决这个问题，我们提出了一种动态坏样本挖掘（DBPM）算法，可可靠地识别和抑制时间序列对比学习中的坏正样本对。具体来说，DBPM利用内存模块动态跟踪每个正样本对在训练过程中的训练行为，从而使我们能够基于每个时期识别潜在的坏正样本对。

    arXiv:2302.03357v2 Announce Type: replace  Abstract: Not all positive pairs are beneficial to time series contrastive learning. In this paper, we study two types of bad positive pairs that can impair the quality of time series representation learned through contrastive learning: the noisy positive pair and the faulty positive pair. We observe that, with the presence of noisy positive pairs, the model tends to simply learn the pattern of noise (Noisy Alignment). Meanwhile, when faulty positive pairs arise, the model wastes considerable amount of effort aligning non-representative patterns (Faulty Alignment). To address this problem, we propose a Dynamic Bad Pair Mining (DBPM) algorithm, which reliably identifies and suppresses bad positive pairs in time series contrastive learning. Specifically, DBPM utilizes a memory module to dynamically track the training behavior of each positive pair along training process. This allows us to identify potential bad positive pairs at each epoch based
    
[^149]: 合作数据驱动建模

    Cooperative data-driven modeling

    [https://arxiv.org/abs/2211.12971](https://arxiv.org/abs/2211.12971)

    这项研究开发出一种持续学习方法，首次将其应用于固体力学，以解决人工神经网络遗忘问题，促进合作数据驱动建模。

    

    arXiv:2211.12971v2 公告类型: 替换-交叉 摘要: 在机械领域，基于最近的机器学习进展，特别是人工神经网络，数据驱动建模正快速发展。随着这一领域不断成熟，不同研究团队创建的新数据和模型陆续问世，为合作建模开辟了可能性。然而，人工神经网络存在灾难性遗忘，即当在新任务上训练时忘记如何执行旧任务。这种情况阻碍了合作，因为使现有模型适应新任务会影响他人训练的先前任务的性能。作者们开发了一种持续学习方法来解决这个问题，在此首次将其应用于固体力学。具体来说，该方法应用于循环神经网络来预测历史相关的塑性行为，尽管它也可以用于任何其他架构（前馈、卷积等）和预测其他现象。

    arXiv:2211.12971v2 Announce Type: replace-cross  Abstract: Data-driven modeling in mechanics is evolving rapidly based on recent machine learning advances, especially on artificial neural networks. As the field matures, new data and models created by different groups become available, opening possibilities for cooperative modeling. However, artificial neural networks suffer from catastrophic forgetting, i.e. they forget how to perform an old task when trained on a new one. This hinders cooperation because adapting an existing model for a new task affects the performance on a previous task trained by someone else. The authors developed a continual learning method that addresses this issue, applying it here for the first time to solid mechanics. In particular, the method is applied to recurrent neural networks to predict history-dependent plasticity behavior, although it can be used on any other architecture (feedforward, convolutional, etc.) and to predict other phenomena. This work int
    
[^150]: 具有波纹协方差模型的谱校正和正则化线性判别分析

    Spectrally-Corrected and Regularized Linear Discriminant Analysis for Spiked Covariance Model

    [https://arxiv.org/abs/2210.03859](https://arxiv.org/abs/2210.03859)

    SRLDA方法在波纹模型假设下具有线性分类全局最优解，并在实验中表现出比RLDA和ILDA更好的性能。

    

    本文提出了一种改进的线性判别分析方法，称为谱校正和正则化LDA（SRLDA）。该方法整合了样本谱校正协方差矩阵和正则化判别分析的设计思想。在大维随机矩阵分析框架的支持下，证明了SRLDA在波纹模型假设下具有线性分类全局最优解。通过仿真数据分析，证明SRLDA分类器优于RLDA和ILDA，并接近理论分类器。对不同数据集的实验表明，SRLDA算法在分类和降维方面优于当前使用的工具。

    arXiv:2210.03859v3 Announce Type: replace-cross  Abstract: This paper proposes an improved linear discriminant analysis called spectrally-corrected and regularized LDA (SRLDA). This method integrates the design ideas of the sample spectrally-corrected covariance matrix and the regularized discriminant analysis. With the support of a large-dimensional random matrix analysis framework, it is proved that SRLDA has a linear classification global optimal solution under the spiked model assumption. According to simulation data analysis, the SRLDA classifier performs better than RLDA and ILDA and is closer to the theoretical classifier. Experiments on different data sets show that the SRLDA algorithm performs better in classification and dimensionality reduction than currently used tools.
    
[^151]: 累积分布函数的函数线性回归

    Functional Linear Regression of Cumulative Distribution Functions

    [https://arxiv.org/abs/2205.14545](https://arxiv.org/abs/2205.14545)

    本文研究了上下文环境中的累积分布函数的函数回归，在估计误差和信息理论下界方面取得了重要进展。

    

    累积分布函数（CDF）的估计是一项重要的学习任务，具有多种下游应用，如风险评估中的预测和决策制定。本文研究上下文环境中CDF的函数回归，其中每个数据点是从上下文相关的CDF基础函数的线性组合中抽样得到的。我们提出了基于函数岭回归的估计方法，可在各个地方准确估计CDF。特别地，对于具有$d$个基础函数的$n$个样本，我们展示了固定设计、随机设计和对抗性上下文情况下的估计误差上界为$\widetilde O(\sqrt{d/n})$。我们还推导出匹配的信息理论下界，建立了CDF函数回归的极小最优性。此外，我们利用替代惩罚估计器消除了随机设计设置中的燃烧时间。然后，我们考虑了对题设置，其中有...

    arXiv:2205.14545v3 Announce Type: replace  Abstract: The estimation of cumulative distribution functions (CDF) is an important learning task with a great variety of downstream applications, such as risk assessments in predictions and decision making. In this paper, we study functional regression of contextual CDFs where each data point is sampled from a linear combination of context dependent CDF basis functions. We propose functional ridge-regression-based estimation methods that estimate CDFs accurately everywhere. In particular, given $n$ samples with $d$ basis functions, we show estimation error upper bounds of $\widetilde O(\sqrt{d/n})$ for fixed design, random design, and adversarial context cases. We also derive matching information theoretic lower bounds, establishing minimax optimality for CDF functional regression. Furthermore, we remove the burn-in time in the random design setting using an alternative penalized estimator. Then, we consider agnostic settings where there is a
    
[^152]: 解决模型为基础的离线强化学习的样本复杂性问题

    Settling the Sample Complexity of Model-Based Offline Reinforcement Learning

    [https://arxiv.org/abs/2204.05275](https://arxiv.org/abs/2204.05275)

    该论文展示了基于模型的（或“插件”）方法在标签化马尔可夫决策过程（MDPs）中实现了无烧录成本的极小极优样本复杂性。

    

    本文关注离线强化学习（RL），它利用预先收集的数据进行学习，无需进一步探索。有效的离线RL应能适应分布转移和有限的数据覆盖。然而，先前的算法或分析要么受到次优样本复杂性的困扰，要么产生高昂的烧录成本以达到样本最优性，从而对样本匮乏应用中的高效离线RL构成障碍。

    arXiv:2204.05275v3 Announce Type: replace-cross  Abstract: This paper is concerned with offline reinforcement learning (RL), which learns using pre-collected data without further exploration. Effective offline RL would be able to accommodate distribution shift and limited data coverage. However, prior algorithms or analyses either suffer from suboptimal sample complexities or incur high burn-in cost to reach sample optimality, thus posing an impediment to efficient offline RL in sample-starved applications.   We demonstrate that the model-based (or "plug-in") approach achieves minimax-optimal sample complexity without burn-in cost for tabular Markov decision processes (MDPs). Concretely, consider a finite-horizon (resp. $\gamma$-discounted infinite-horizon) MDP with $S$ states and horizon $H$ (resp. effective horizon $\frac{1}{1-\gamma}$), and suppose the distribution shift of data is reflected by some single-policy clipped concentrability coefficient $C^{\star}_{\text{clipped}}$. We p
    
[^153]: 在强化学习中测试平稳性和变点检测

    Testing Stationarity and Change Point Detection in Reinforcement Learning

    [https://arxiv.org/abs/2203.01707](https://arxiv.org/abs/2203.01707)

    开发了一种能够在非平稳环境中进行策略优化的强化学习方法，通过测试最优Q函数的非平稳性并开发序贯变点检测方法来实现。

    

    我们考虑可能非平稳环境下的离线强化学习（RL）方法。许多文献中现有的RL算法依赖于需要系统转换和奖励函数随时间保持恒定的平稳性假设。然而，实践中平稳性假设是有限制的，并且在许多应用中很可能被违反，包括交通信号控制、机器人技术和移动健康。在本文中，我们开发了一种一致的程序，基于预先收集的历史数据测试最优Q函数的非平稳性，无需额外的在线数据收集。基于所提出的检验，我们进一步开发了一种顺序变点检测方法，可以自然地与现有最先进的RL方法相结合，在非平稳环境中进行策略优化。我们的方法的有效性通过理论结果、仿真研究和实践中的案例得到了展示。

    arXiv:2203.01707v3 Announce Type: replace-cross  Abstract: We consider offline reinforcement learning (RL) methods in possibly nonstationary environments. Many existing RL algorithms in the literature rely on the stationarity assumption that requires the system transition and the reward function to be constant over time. However, the stationarity assumption is restrictive in practice and is likely to be violated in a number of applications, including traffic signal control, robotics and mobile health. In this paper, we develop a consistent procedure to test the nonstationarity of the optimal Q-function based on pre-collected historical data, without additional online data collection. Based on the proposed test, we further develop a sequential change point detection method that can be naturally coupled with existing state-of-the-art RL methods for policy optimization in nonstationary environments. The usefulness of our method is illustrated by theoretical results, simulation studies, an
    
[^154]: 输入相关随机平滑的有趣特性

    Intriguing Properties of Input-dependent Randomized Smoothing

    [https://arxiv.org/abs/2110.05365](https://arxiv.org/abs/2110.05365)

    输入相关平滑方法虽然被用来获取可靠鲁棒分类器，但缺乏形式保证，其证书并不合理，因受到维度诅咒影响；提出了一个理论和实践框架，使得即使在维度诅咒存在的情况下，也能在严格的限制条件下使用输入相关平滑。

    

    随机平滑目前被认为是获得可靠鲁棒分类器的最先进方法。尽管其性能显著，但该方法存在诸如“认证准确性瀑布”、认证与准确性之间的权衡，甚至公平性问题等严重问题。为了克服这些缺陷，已经提出了输入相关的平滑方法。然而，我们证明了这些方法缺乏形式保证，因此得到的证书并不合理。我们表明，在一般情况下，输入相关平滑受到维度诅咒的影响，导致方差函数具有较低的半弹性。另一方面，我们提出了一个理论和实践框架，即使在维度诅咒存在的情况下，也能在严格的限制条件下使用输入相关平滑。我们展示了一个具体的平滑方差设计。

    arXiv:2110.05365v3 Announce Type: replace-cross  Abstract: Randomized smoothing is currently considered the state-of-the-art method to obtain certifiably robust classifiers. Despite its remarkable performance, the method is associated with various serious problems such as "certified accuracy waterfalls", certification vs.\ accuracy trade-off, or even fairness issues. Input-dependent smoothing approaches have been proposed with intention of overcoming these flaws. However, we demonstrate that these methods lack formal guarantees and so the resulting certificates are not justified. We show that in general, the input-dependent smoothing suffers from the curse of dimensionality, forcing the variance function to have low semi-elasticity. On the other hand, we provide a theoretical and practical framework that enables the usage of input-dependent smoothing even in the presence of the curse of dimensionality, under strict restrictions. We present one concrete design of the smoothing variance 
    
[^155]: 针对未知零和随机博弈的贝叶斯学习算法及其任意对手

    A Bayesian Learning Algorithm for Unknown Zero-sum Stochastic Games with an Arbitrary Opponent

    [https://arxiv.org/abs/2109.03396](https://arxiv.org/abs/2109.03396)

    本文提出了一种针对无限时间跨度的零和随机博弈的在线学习算法，该算法在具有平均奖励准则的情况下实现了贝叶斯遗憾界$O(HS\sqrt{AT})$。

    

    在本文中，我们提出了后验采样强化学习零和随机博弈（PSRL-ZSG）算法，这是第一个在线学习算法，在具有平均奖励准则的无限时间跨度的零和随机博弈中实现了贝叶斯遗憾界为$O(HS\sqrt{AT})$。其中$H$是偏差函数跨度的上界，$S$是状态数量，$A$是联合动作数量，$T$是时间跨度。我们考虑对手无法控制且可以采取任意任意与历史相关的策略的在线设置。我们的遗憾界改进了魏等人(2017)在相同假设下的最佳遗憾界$O(\sqrt[3]{DS^2AT^2})$，并且与在$T$上的理论下界相匹配。

    arXiv:2109.03396v2 Announce Type: replace  Abstract: In this paper, we propose Posterior Sampling Reinforcement Learning for Zero-sum Stochastic Games (PSRL-ZSG), the first online learning algorithm that achieves Bayesian regret bound of $O(HS\sqrt{AT})$ in the infinite-horizon zero-sum stochastic games with average-reward criterion. Here $H$ is an upper bound on the span of the bias function, $S$ is the number of states, $A$ is the number of joint actions and $T$ is the horizon. We consider the online setting where the opponent can not be controlled and can take any arbitrary time-adaptive history-dependent strategy. Our regret bound improves on the best existing regret bound of $O(\sqrt[3]{DS^2AT^2})$ by Wei et al. (2017) under the same assumption and matches the theoretical lower bound in $T$.
    
[^156]: 误差缓解能改善有噪声的变分量子算法的可训性吗？

    Can Error Mitigation Improve Trainability of Noisy Variational Quantum Algorithms?

    [https://arxiv.org/abs/2109.01051](https://arxiv.org/abs/2109.01051)

    误差缓解的策略无法解决指数级成本集中问题而不在其他地方投入指数级资源，某些策略能够改善有噪声的变分量子算法的可训性。

    

    变分量子算法（VQAs）通常被视为近期获得量子优势的最佳希望。然而，最近的研究表明，噪声可以严重限制VQAs的可训性，例如通过指数级使成本景观平坦化并抑制成本梯度的幅度。误差缓解（EM）在降低噪声对近期设备的影响方面显示出潜力。因此，自然地会问误差缓解是否能提高VQAs的可训性。在这项工作中，我们首先展示了对于一类广泛的EM策略，无法解决指数级成本集中问题而不在其他地方投入指数级资源。这类策略包括零噪声外推、虚拟蒸馏、概率误差抵消和克利福德数据回归等特例。其次，我们对这些EM协议进行了分析和数值分析，并发现其中一些（例如，虚拟蒸馏）可以使

    arXiv:2109.01051v2 Announce Type: replace-cross  Abstract: Variational Quantum Algorithms (VQAs) are often viewed as the best hope for near-term quantum advantage. However, recent studies have shown that noise can severely limit the trainability of VQAs, e.g., by exponentially flattening the cost landscape and suppressing the magnitudes of cost gradients. Error Mitigation (EM) shows promise in reducing the impact of noise on near-term devices. Thus, it is natural to ask whether EM can improve the trainability of VQAs. In this work, we first show that, for a broad class of EM strategies, exponential cost concentration cannot be resolved without committing exponential resources elsewhere. This class of strategies includes as special cases Zero Noise Extrapolation, Virtual Distillation, Probabilistic Error Cancellation, and Clifford Data Regression. Second, we perform analytical and numerical analysis of these EM protocols, and we find that some of them (e.g., Virtual Distillation) can ma
    
[^157]: 朝着强化学习de novo基因组组装器迈出一步

    A step toward a reinforcement learning de novo genome assembler

    [https://arxiv.org/abs/2102.02649](https://arxiv.org/abs/2102.02649)

    本研究旨在探讨机器学习在基因组组装中的应用，使用强化学习（RL）。他们在文献中唯一发现的方法的基础上进行了扩展，以仔细探索学习过程。

    

    De novo基因组组装是基因组学中一个相关但计算复杂的任务。尽管de novo组装器已经成功地在几个基因组项目中使用，但仍然没有"最佳组装器"，组装器的选择和设置仍然依赖生物信息学专家。因此，与其他计算复杂问题一样，机器学习可能会成为开发更准确和自动化组装器的一种替代（或补充）方式。强化学习已被证明在解决无监督情况下的复杂活动（如游戏）方面很有前景，迫切需要了解该方法在“真实”问题（如DFA问题）中的局限性。该研究旨在探讨机器学习在基因组组装中的应用，使用强化学习（RL）。我们在文献中发现的唯一先前方法的基础上进行了扩展，以仔细探索学习过程。

    arXiv:2102.02649v4 Announce Type: replace-cross  Abstract: De novo genome assembly is a relevant but computationally complex task in genomics. Although de novo assemblers have been used successfully in several genomics projects, there is still no 'best assembler', and the choice and setup of assemblers still rely on bioinformatics experts. Thus, as with other computationally complex problems, machine learning may emerge as an alternative (or complementary) way for developing more accurate and automated assemblers. Reinforcement learning has proven promising for solving complex activities without supervision - such games - and there is a pressing need to understand the limits of this approach to 'real' problems, such as the DFA problem. This study aimed to shed light on the application of machine learning, using reinforcement learning (RL), in genome assembly. We expanded upon the sole previous approach found in the literature to solve this problem by carefully exploring the learning as
    
[^158]: 一个带有正则化最优输运的硬聚类和软聚类统一框架

    A unified framework for hard and soft clustering with regularized optimal transport

    [https://arxiv.org/abs/1711.04366](https://arxiv.org/abs/1711.04366)

    这个方法提出了一个统一的框架，将离散数据推断有限混合模型的问题建模为带有正则化最优输运的问题，同时在聚类中融合了硬聚类和软聚类，并且实验证明当参数$\lambda>1$时可以提高推断性能，当$\lambda\to 0$时适用于分类。

    

    在这篇论文中，我们将从离散数据推断有限混合模型的问题阐述为一个带有参数$\lambda\geq 0$的熵正则化的最优输运问题。我们的方法统一了硬聚类和软聚类，当$\lambda=1$时，期望最大化（EM）算法被完全恢复。我们提出的聚类算法族依赖于使用交替最小化来解决非凸问题。我们研究了我们的广义$\lambda$-EM算法的收敛性质，并展示了在推断指数族有限混合模型时，最小化过程中的每一步都有一个封闭形式的解。实验突出了采用参数$\lambda>1$来提高推断性能以及$\lambda\to 0$用于分类的好处。

    arXiv:1711.04366v2 Announce Type: replace  Abstract: In this paper, we formulate the problem of inferring a Finite Mixture Model from discrete data as an optimal transport problem with entropic regularization of parameter $\lambda\geq 0$. Our method unifies hard and soft clustering, the Expectation-Maximization (EM) algorithm being exactly recovered for $\lambda=1$. The family of clustering algorithm we propose rely on the resolution of nonconvex problems using alternating minimization. We study the convergence property of our generalized $\lambda-$EM algorithms and show that each step in the minimization process has a closed form solution when inferring finite mixture models of exponential families. Experiments highlight the benefits of taking a parameter $\lambda>1$ to improve the inference performance and $\lambda\to 0$ for classification.
    
[^159]: 对于森林火灾检测中具有挑战性数据集的支持向量机（SVM）的性能分析

    Performance Analysis of Support Vector Machine (SVM) on Challenging Datasets for Forest Fire Detection. (arXiv:2401.12924v1 [stat.ML])

    [http://arxiv.org/abs/2401.12924](http://arxiv.org/abs/2401.12924)

    本文对于使用图像数据集进行森林火灾检测的支持向量机（SVM）进行了性能分析，并研究了关键因素如数据预处理、特征提取和模型训练。这项研究有助于开发高效的森林火灾检测系统。

    

    本文深入分析了使用图像数据集进行森林火灾检测的支持向量机（SVM）的性能和利用情况。随着森林火灾对生态系统和人类定居点的威胁日益增加，迅速准确的检测系统的需求至关重要。SVM以其强大的分类能力而闻名，在图像中识别与火灾相关的模式方面表现出熟练度。通过在标记数据上进行训练，SVM获得了识别与火灾相关的独特属性的能力，如火焰、烟雾或森林区域视觉特征的变化。本文全面研究了使用SVM的各个要素，包括数据预处理、特征提取和模型训练。严格评估了准确性、效率和实际适用性等参数。从这项研究中获得的知识有助于开发高效的森林火灾检测系统。

    This article delves into the analysis of performance and utilization of Support Vector Machines (SVMs) for the critical task of forest fire detection using image datasets. With the increasing threat of forest fires to ecosystems and human settlements, the need for rapid and accurate detection systems is of utmost importance. SVMs, renowned for their strong classification capabilities, exhibit proficiency in recognizing patterns associated with fire within images. By training on labeled data, SVMs acquire the ability to identify distinctive attributes associated with fire, such as flames, smoke, or alterations in the visual characteristics of the forest area. The document thoroughly examines the use of SVMs, covering crucial elements like data preprocessing, feature extraction, and model training. It rigorously evaluates parameters such as accuracy, efficiency, and practical applicability. The knowledge gained from this study aids in the development of efficient forest fire detection sy
    
[^160]: 部分已知因果图上的干预公平性: 一种受限优化方法

    Interventional Fairness on Partially Known Causal Graphs: A Constrained Optimization Approach. (arXiv:2401.10632v1 [cs.LG])

    [http://arxiv.org/abs/2401.10632](http://arxiv.org/abs/2401.10632)

    本文提出了一个框架，用于在部分已知的真实因果图情况下实现因果公平性。通过使用部分有向无环图（PDAG）建模和衡量因果公平性，并通过受限优化问题平衡公平性和准确性。

    

    公平机器学习旨在防止基于敏感属性（如性别和种族）对个体或子群体进行歧视。近年来，因果推断方法在公平机器学习中的应用越来越多，用于通过因果效应来衡量不公平性。然而，当前方法假设已知真实的因果图，而这在实际应用中往往不成立。为了解决这个限制，本文提出了一个框架，用于在部分已知的真实因果图情况下实现因果公平性。所提出的方法涉及使用部分有向无环图（PDAG）来建模公平预测，具体来说，是从观测数据和领域知识中学习的一类因果有向无环图。PDAG用于衡量因果公平性，并通过一个受限优化问题来平衡公平性和准确性。模拟和真实世界数据集的结果表明...

    Fair machine learning aims to prevent discrimination against individuals or sub-populations based on sensitive attributes such as gender and race. In recent years, causal inference methods have been increasingly used in fair machine learning to measure unfairness by causal effects. However, current methods assume that the true causal graph is given, which is often not true in real-world applications. To address this limitation, this paper proposes a framework for achieving causal fairness based on the notion of interventions when the true causal graph is partially known. The proposed approach involves modeling fair prediction using a Partially Directed Acyclic Graph (PDAG), specifically, a class of causal DAGs that can be learned from observational data combined with domain knowledge. The PDAG is used to measure causal fairness, and a constrained optimization problem is formulated to balance between fairness and accuracy. Results on both simulated and real-world datasets demonstrate th
    
[^161]: FedLoGe: 长尾数据下的本地和通用联邦学习

    FedLoGe: Joint Local and Generic Federated Learning under Long-tailed Data. (arXiv:2401.08977v1 [cs.LG])

    [http://arxiv.org/abs/2401.08977](http://arxiv.org/abs/2401.08977)

    本文介绍了一种名为FedLoGe的方法，它通过在神经网络崩溃框架中集成表示学习和分类器对齐来提高区域和全局模型的性能，解决了在联邦长尾学习中忽视本地级别性能的问题。

    

    联邦长尾学习（Fed-LT）是一种在去中心化的本地客户端收集的数据呈现全球普遍存在的长尾分布的范例，近年来引起了相当大的关注。在Fed-LT的背景下，现有研究主要集中于解决数据不平衡问题，以提高通用全局模型的效能，而忽视了本地级别的性能。相比之下，常规的个性化联邦学习（pFL）技术主要是在平衡的全局数据分布的假设下，优化个性化的本地模型。本文提出了一种名为FedLoGe的方法，在Fed-LT中通过在神经网络崩溃框架中集成表示学习和分类器对齐，提高本地和通用模型的性能。我们的研究结果揭示了使用共享骨干作为基础框架的可行性。

    Federated Long-Tailed Learning (Fed-LT), a paradigm wherein data collected from decentralized local clients manifests a globally prevalent long-tailed distribution, has garnered considerable attention in recent times. In the context of Fed-LT, existing works have predominantly centered on addressing the data imbalance issue to enhance the efficacy of the generic global model while neglecting the performance at the local level. In contrast, conventional Personalized Federated Learning (pFL) techniques are primarily devised to optimize personalized local models under the presumption of a balanced global data distribution. This paper introduces an approach termed Federated Local and Generic Model Training in Fed-LT (FedLoGe), which enhances both local and generic model performance through the integration of representation learning and classifier alignment within a neural collapse framework. Our investigation reveals the feasibility of employing a shared backbone as a foundational framewor
    
[^162]: REValueD: 对可分解的马尔可夫决策过程进行正则化集合值分解

    REValueD: Regularised Ensemble Value-Decomposition for Factorisable Markov Decision Processes. (arXiv:2401.08850v1 [cs.LG])

    [http://arxiv.org/abs/2401.08850](http://arxiv.org/abs/2401.08850)

    REValueD是一种通过正则化集合值分解的新算法，针对高维离散动作空间的任务提供了优越性能，尤其在人形和狗类任务中表现出色。它遏制了Q-learning算法的高估偏差，并减轻了目标方差问题。

    

    由于可能的动作数量庞大，离散动作强化学习算法在具有高维离散动作空间的任务中经常失败。最近的一项进展利用了来自多智能体强化学习的概念——值分解，来解决这个问题。这项研究深入探讨了值分解的影响，揭示了它虽然可以遏制Q学习算法固有的高估偏差，但也会放大目标方差。为了应对这个问题，我们提出了一个评论家的集合以减轻目标方差。此外，我们引入了一个正则化损失，有助于减轻一个维度上的探索性动作对其他维度上最优动作价值的影响。我们的新颖算法REValueD，在经过离散化的DeepMind控制套件任务上进行了测试，展示了卓越的性能，特别是在困难的人形和狗类任务中。我们进一步分析了影响REValueD表现的因素。

    Discrete-action reinforcement learning algorithms often falter in tasks with high-dimensional discrete action spaces due to the vast number of possible actions. A recent advancement leverages value-decomposition, a concept from multi-agent reinforcement learning, to tackle this challenge. This study delves deep into the effects of this value-decomposition, revealing that whilst it curtails the over-estimation bias inherent to Q-learning algorithms, it amplifies target variance. To counteract this, we present an ensemble of critics to mitigate target variance. Moreover, we introduce a regularisation loss that helps to mitigate the effects that exploratory actions in one dimension can have on the value of optimal actions in other dimensions. Our novel algorithm, REValueD, tested on discretised versions of the DeepMind Control Suite tasks, showcases superior performance, especially in the challenging humanoid and dog tasks. We further dissect the factors influencing REValueD's performance
    
[^163]: 基于条件互信息的贝叶斯条件分布估计用于知识蒸馏

    Bayes Conditional Distribution Estimation for Knowledge Distillation Based on Conditional Mutual Information. (arXiv:2401.08732v1 [cs.LG])

    [http://arxiv.org/abs/2401.08732](http://arxiv.org/abs/2401.08732)

    本文介绍了一种基于条件互信息的贝叶斯条件分布估计方法，通过最大化教师的对数似然和条件互信息来改进知识蒸馏中的估计。实验证明，使用该方法训练的教师能够更好地捕捉图像聚类中的上下文信息。

    

    在知识蒸馏中，通常认为教师的角色是提供用于学生训练过程中的未知贝叶斯条件概率分布（BCPD）的估计。传统上，通过使用最大对数似然（MLL）方法训练教师来获得此估计。为了改进知识蒸馏中的估计，本文将条件互信息（CMI）的概念引入到BCPD的估计中，提出了一种新的估计方法，称为最大CMI（MCMI）方法。具体而言，在MCMI估计中，教师在训练时同时最大化对数似然和条件互信息。通过Eigen-CAM，进一步展示了最大化教师的CMI值可以使教师在图像聚类中捕捉更多的上下文信息。通过进行一系列彻底的实验，我们展示了通过使用通过MCMI估计训练的教师而不是通过MLL估计训练的教师，在各种状态下的性能提升。

    It is believed that in knowledge distillation (KD), the role of the teacher is to provide an estimate for the unknown Bayes conditional probability distribution (BCPD) to be used in the student training process. Conventionally, this estimate is obtained by training the teacher using maximum log-likelihood (MLL) method. To improve this estimate for KD, in this paper we introduce the concept of conditional mutual information (CMI) into the estimation of BCPD and propose a novel estimator called the maximum CMI (MCMI) method. Specifically, in MCMI estimation, both the log-likelihood and CMI of the teacher are simultaneously maximized when the teacher is trained. Through Eigen-CAM, it is further shown that maximizing the teacher's CMI value allows the teacher to capture more contextual information in an image cluster. Via conducting a thorough set of experiments, we show that by employing a teacher trained via MCMI estimation rather than one trained via MLL estimation in various state-of-t
    
[^164]: 推进深度主动学习和数据子集选择：用信息论直觉统一原则

    Advancing Deep Active Learning & Data Subset Selection: Unifying Principles with Information-Theory Intuitions. (arXiv:2401.04305v1 [cs.LG])

    [http://arxiv.org/abs/2401.04305](http://arxiv.org/abs/2401.04305)

    本论文探索了基于信息论原则的主动学习和主动采样方面的数据子集选择技术，以提高深度学习模型的标签和训练效率。

    

    本论文的核心目标是通过改进深度学习模型的标签和训练效率来提高深度学习的实用性。为此，我们探讨了基于信息论原则的数据子集选择技术，特别是主动学习和主动采样。主动学习提高了标签效率，而主动采样则提高了训练效率。监督式深度学习模型通常需要大量带标签的数据进行训练。标签获取可能既昂贵又耗时，并且训练大模型需要大量资源，这限制了其在学术研究和“大型科技公司”以外的应用。现有的深度学习数据子集选择方法通常依赖于启发式方法或缺乏基于信息论的原则基础。相比之下，本论文对深度学习中的数据子集选择目标及其应用进行了研究，力求通过信息论的启发，提出更具原则性的方法。

    At its core, this thesis aims to enhance the practicality of deep learning by improving the label and training efficiency of deep learning models. To this end, we investigate data subset selection techniques, specifically active learning and active sampling, grounded in information-theoretic principles. Active learning improves label efficiency, while active sampling enhances training efficiency. Supervised deep learning models often require extensive training with labeled data. Label acquisition can be expensive and time-consuming, and training large models is resource-intensive, hindering the adoption outside academic research and ``big tech.'' Existing methods for data subset selection in deep learning often rely on heuristics or lack a principled information-theoretic foundation. In contrast, this thesis examines several objectives for data subset selection and their applications within deep learning, striving for a more principled approach inspired by information theory. We begin 
    
[^165]: 脑解码：走向实时重建视觉知觉

    Brain decoding: toward real-time reconstruction of visual perception. (arXiv:2310.19812v1 [eess.IV])

    [http://arxiv.org/abs/2310.19812](http://arxiv.org/abs/2310.19812)

    本研究提出了一种基于脑磁图（MEG）的脑解码方法，通过训练一个具有预训练嵌入、MEG模块和图像生成器的模型，在实时应用中实现了对视觉知觉的高时间分辨率解码，并在图像检索上取得了7倍的改进。

    

    在过去的五年中，生成式和基础性人工智能系统的使用极大地提高了对大脑活动的解码能力。特别是对于视觉知觉，现在可以从功能性磁共振成像（fMRI）中解码出令人瞩目的准确度。然而，这种神经影像技术的时间分辨率有限（约为0.5 Hz），因此在实时应用方面存在根本性的限制。在这里，我们提出了一种基于脑磁图（MEG）的替代方法，这是一种能够以高时间分辨率（约为5000 Hz）测量脑活动的神经影像设备。为此，我们开发了一个MEG解码模型，该模型通过对比和回归目标进行训练，并由三个模块组成：i）从图像中获得的预训练嵌入、ii）端到端训练的MEG模块以及iii）预训练的图像生成器。我们的结果有三个方面：首先，我们的MEG解码器在经典线性解码器上显示出7倍的图像检索改进。其次，后期脑部

    In the past five years, the use of generative and foundational AI systems has greatly improved the decoding of brain activity. Visual perception, in particular, can now be decoded from functional Magnetic Resonance Imaging (fMRI) with remarkable fidelity. This neuroimaging technique, however, suffers from a limited temporal resolution ($\approx$0.5 Hz) and thus fundamentally constrains its real-time usage. Here, we propose an alternative approach based on magnetoencephalography (MEG), a neuroimaging device capable of measuring brain activity with high temporal resolution ($\approx$5,000 Hz). For this, we develop an MEG decoding model trained with both contrastive and regression objectives and consisting of three modules: i) pretrained embeddings obtained from the image, ii) an MEG module trained end-to-end and iii) a pretrained image generator. Our results are threefold: Firstly, our MEG decoder shows a 7X improvement of image-retrieval over classic linear decoders. Second, late brain 
    
[^166]: LLM4DyG：大型语言模型能解决动态图上的问题吗?

    LLM4DyG: Can Large Language Models Solve Problems on Dynamic Graphs?. (arXiv:2310.17110v1 [cs.LG])

    [http://arxiv.org/abs/2310.17110](http://arxiv.org/abs/2310.17110)

    本研究首次提出了评估大型语言模型（LLMs）在动态图上的时空理解能力的LLM4DyG基准，并通过广泛的实验分析了不同因素对模型性能的影响。

    

    在越来越多地采用大型语言模型（LLMs）处理各种任务的时代，人们越来越关注探索LLMs在处理网络数据，特别是图形数据方面的能力。动态图在现实世界的网络数据中无处不在，它们捕捉了网络演化模式。评估LLMs在理解动态图上的时空信息方面的能力对于它们在Web应用中的采用至关重要，然而这在文献中尚未得到探索。本文通过首次提出在动态图上评估LLMs的时空理解能力来填补这一空白。具体而言，我们提出了LLM4DyG基准，其中包括九个特别设计的任务，考虑了LLMs在时态和空间维度上的能力评估。然后，我们进行了广泛的实验，分析了不同的数据生成器、数据统计、提示技术和LLMs对模型性能的影响。

    In an era marked by the increasing adoption of Large Language Models (LLMs) for various tasks, there is a growing focus on exploring LLMs' capabilities in handling web data, particularly graph data. Dynamic graphs, which capture temporal network evolution patterns, are ubiquitous in real-world web data. Evaluating LLMs' competence in understanding spatial-temporal information on dynamic graphs is essential for their adoption in web applications, which remains unexplored in the literature. In this paper, we bridge the gap via proposing to evaluate LLMs' spatial-temporal understanding abilities on dynamic graphs, to the best of our knowledge, for the first time. Specifically, we propose the LLM4DyG benchmark, which includes nine specially designed tasks considering the capability evaluation of LLMs from both temporal and spatial dimensions. Then, we conduct extensive experiments to analyze the impacts of different data generators, data statistics, prompting techniques, and LLMs on the mo
    
[^167]: 通过确定性对流模型的生成性集成深度学习，用于严重天气预测

    Generative ensemble deep learning severe weather prediction from a deterministic convection-allowing model. (arXiv:2310.06045v1 [cs.LG])

    [http://arxiv.org/abs/2310.06045](http://arxiv.org/abs/2310.06045)

    本论文开发了一种集成后处理方法，将生成对抗网络（CGANs）和卷积神经网络（CNN）结合起来，对严重天气进行概率预测。该方法在使用HRRR预报作为输入数据，在2021年的测试数据集上相对于其他基于神经网络的方法提高了高达20％的Brier技巧分数（BSS）。

    

    开发了一种用于概率预测美国本土严重天气（龙卷风、冰雹和大风阵）的集成后处理方法。该方法将条件生成对抗网络（CGANs）与卷积神经网络（CNN）结合起来，用于后处理对流允许模型（CAM）的预测。CGANs被设计用于从确定性CAM预测中创建合成集成成员，其输出经过CNN处理以估计严重天气的概率。该方法使用高分辨率快速刷新（HRRR）1-24小时预报作为输入，以及暴风预警中心（SPC）的严重天气报告作为目标进行测试。在2021年的HRRR预测测试数据集中，该方法相对于其他基于神经网络的参考方法提高了高达20％的Brier技巧分数（BSS）。

    An ensemble post-processing method is developed for the probabilistic prediction of severe weather (tornadoes, hail, and wind gusts) over the conterminous United States (CONUS). The method combines conditional generative adversarial networks (CGANs), a type of deep generative model, with a convolutional neural network (CNN) to post-process convection-allowing model (CAM) forecasts. The CGANs are designed to create synthetic ensemble members from deterministic CAM forecasts, and their outputs are processed by the CNN to estimate the probability of severe weather. The method is tested using High-Resolution Rapid Refresh (HRRR) 1--24 hr forecasts as inputs and Storm Prediction Center (SPC) severe weather reports as targets. The method produced skillful predictions with up to 20% Brier Skill Score (BSS) increases compared to other neural-network-based reference methods using a testing dataset of HRRR forecasts in 2021. For the evaluation of uncertainty quantification, the method is overcon
    
[^168]: RetSeg: 基于保留机制的结直肠息肉分割网络

    RetSeg: Retention-based Colorectal Polyps Segmentation Network. (arXiv:2310.05446v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2310.05446](http://arxiv.org/abs/2310.05446)

    本研究探索将保留机制整合到结直肠息肉分割中，解决了视觉变换器在资源受限设备上实时疾病检测中的内存和并行性挑战。

    

    视觉变换器（ViTs）在医学图像分析方面取得了重大突破，与传统的卷积神经网络（CNNs）相比，在息肉分类、检测和分割等关键任务中展现出了更高的效能。通过利用注意机制聚焦于特定图像区域，ViTs在处理视觉数据时表现出上下文感知能力，从而在处理复杂医学图像时实现了强大且精确的预测。此外，变换器中固有的自注意机制适应了不同的输入尺寸和分辨率，为传统的CNNs所不具备的提供了前所未有的灵活性。然而，变换器由于自注意机制而面临着过多的内存使用和有限的训练并行性等挑战，从而使其在资源受限设备上实时疾病检测变得不切实际。在本研究中，我们通过探究将最近引入的保留机制整合到息肉分割中，来解决这些难题。

    Vision Transformers (ViTs) have revolutionized medical imaging analysis, showcasing superior efficacy compared to conventional Convolutional Neural Networks (CNNs) in vital tasks such as polyp classification, detection, and segmentation. Leveraging attention mechanisms to focus on specific image regions, ViTs exhibit contextual awareness in processing visual data, culminating in robust and precise predictions, even for intricate medical images. Moreover, the inherent self-attention mechanism in Transformers accommodates varying input sizes and resolutions, granting an unprecedented flexibility absent in traditional CNNs. However, Transformers grapple with challenges like excessive memory usage and limited training parallelism due to self-attention, rendering them impractical for real-time disease detection on resource-constrained devices. In this study, we address these hurdles by investigating the integration of the recently introduced retention mechanism into polyp segmentation, intr
    
[^169]: 通过基于Transformer的强化学习进行分子的全新设计

    Molecular De Novo Design through Transformer-based Reinforcement Learning. (arXiv:2310.05365v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.05365](http://arxiv.org/abs/2310.05365)

    本文提出了一种基于Transformer的强化学习方法，通过精细调整生成模型，能够在分子的全新设计中生成具有所需性质的分子结构，展现出优越的性能。

    

    本文介绍了一种通过精细调整基于Transformer的生成模型用于分子的全新设计的方法。利用Transformer相对于循环神经网络（RNN）的优越序列学习能力，我们的模型可以有效地生成具有所需性质的分子结构。与传统的基于RNN的模型相比，我们提出的方法在生成预测对多种生物靶点具有活性的化合物方面表现出卓越性能，捕捉了分子结构序列的长期依赖性。该模型的有效性在许多任务中得到了证明，包括生成与查询结构类似的分子和生成具有特定属性的化合物，在性能上优于基线的基于RNN的方法。我们的方法可以用于桥接化学、从单个分子开始扩展库，并生成具有高预测活性的化合物。

    In this work, we introduce a method to fine-tune a Transformer-based generative model for molecular de novo design. Leveraging the superior sequence learning capacity of Transformers over Recurrent Neural Networks (RNNs), our model can generate molecular structures with desired properties effectively. In contrast to the traditional RNN-based models, our proposed method exhibits superior performance in generating compounds predicted to be active against various biological targets, capturing long-term dependencies in the molecular structure sequence. The model's efficacy is demonstrated across numerous tasks, including generating analogues to a query structure and producing compounds with particular attributes, outperforming the baseline RNN-based methods. Our approach can be used for scaffold hopping, library expansion starting from a single molecule, and generating compounds with high predicted activity against biological targets.
    
[^170]: 眼不见心不念：利用视频跟踪启用的记忆模型对未被观察到的对象进行推理和规划

    Out of Sight, Still in Mind: Reasoning and Planning about Unobserved Objects with Video Tracking Enabled Memory Models. (arXiv:2309.15278v1 [cs.RO])

    [http://arxiv.org/abs/2309.15278](http://arxiv.org/abs/2309.15278)

    本文研究了如何对先前观察到但当前被遮挡的对象进行推理和规划，提出了利用转换器关系动力学编码轨迹历史的方法，并在多个挑战性任务中表现出色。

    

    机器人需要具有对先前观察到但当前被遮挡的对象的记忆，以在现实环境中可靠地工作。我们研究了将面向对象的记忆编码到多对象操纵推理和规划框架中的问题。我们提出了DOOM和LOOM，它们利用转换器关系动力学来编码给定部分视点云和对象发现与跟踪引擎的轨迹历史。我们的方法可以执行多个具有挑战性的任务，包括处理被遮挡的对象，新出现的对象，以及物体重新出现。通过广泛的仿真和真实世界实验，我们发现我们的方法在不同数量的对象和不同数量的干扰动作方面表现良好。此外，我们展示了我们的方法优于隐式记忆基线。

    Robots need to have a memory of previously observed, but currently occluded objects to work reliably in realistic environments. We investigate the problem of encoding object-oriented memory into a multi-object manipulation reasoning and planning framework. We propose DOOM and LOOM, which leverage transformer relational dynamics to encode the history of trajectories given partial-view point clouds and an object discovery and tracking engine. Our approaches can perform multiple challenging tasks including reasoning with occluded objects, novel objects appearance, and object reappearance. Throughout our extensive simulation and real-world experiments, we find that our approaches perform well in terms of different numbers of objects and different numbers of distractor actions. Furthermore, we show our approaches outperform an implicit memory baseline.
    
[^171]: LongLoRA: 高效的长上下文大型语言模型的精细调整

    LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models. (arXiv:2309.12307v1 [cs.CL])

    [http://arxiv.org/abs/2309.12307](http://arxiv.org/abs/2309.12307)

    LongLoRA是一种高效的精细调整方法，可以在有限的计算成本下扩展预训练的大型语言模型的上下文大小。它通过稀疏的局部注意力实现精细调整，并使用移动短注意力有效实现上下文扩展，与传统方法具有相似的性能。

    

    我们提出了一种高效的精细调整方法——LongLoRA，可以在有限的计算成本下扩展预训练的大型语言模型(LLM)的上下文大小。通常，使用长上下文大小训练LLM的计算成本很高，需要大量的训练时间和GPU资源。本文中，我们在两个方面加快了LLM的上下文扩展。一方面，尽管推理过程中需要稠密的全局注意力，但模型的精细调整可以通过稀疏的局部注意力有效且高效地完成。所提出的移动短注意力有效地实现了上下文的扩展，在与使用传统注意力进行精细调整时具有相似的性能，同时可以在训练中只用两行代码实现，在推理中是可选的。另一方面，我们重新审视了参数效率问题。

    We present LongLoRA, an efficient fine-tuning approach that extends the context sizes of pre-trained large language models (LLMs), with limited computation cost. Typically, training LLMs with long context sizes is computationally expensive, requiring extensive training hours and GPU resources. For example, training on the context length of 8192 needs 16x computational costs in self-attention layers as that of 2048. In this paper, we speed up the context extension of LLMs in two aspects. On the one hand, although dense global attention is needed during inference, fine-tuning the model can be effectively and efficiently done by sparse local attention. The proposed shift short attention effectively enables context extension, leading to non-trivial computation saving with similar performance to fine-tuning with vanilla attention. Particularly, it can be implemented with only two lines of code in training, while being optional in inference. On the other hand, we revisit the parameter-effici
    
[^172]: 基于多编码器自编码器的自监督盲源分离

    Self-Supervised Blind Source Separation via Multi-Encoder Autoencoders. (arXiv:2309.07138v1 [eess.SP])

    [http://arxiv.org/abs/2309.07138](http://arxiv.org/abs/2309.07138)

    本论文提出了一种基于多编码器自编码器和自监督学习的方法，用于解决盲源分离问题。通过训练网络进行输入解码和重构，然后利用编码掩蔽技术进行源推断，同时引入路径分离损失以促进稀疏性。

    

    盲源分离（BSS）的任务是在没有先验知识的情况下从混合信号中分离出源信号和混合系统。这是一个具有挑战性的问题，通常需要对混合系统和源信号做出限制性的假设。本文提出了一种新颖的方法来解决非线性混合的BSS问题，该方法利用多编码器自编码器的自然特征子空间专门化能力，并通过完全自监督学习进行训练，而不需要强先验知识。在训练阶段，我们的方法将输入解码成多编码器网络的单独编码空间，然后在解码器内重新混合这些表示以重构输入。然后，为了进行源推断，我们引入了一种新颖的编码掩蔽技术，即屏蔽除一个编码外的所有编码，使得解码器能够估计源信号。为此，我们还引入了一种称为路径分离损失的方法，以促进编码之间的稀疏性。

    The task of blind source separation (BSS) involves separating sources from a mixture without prior knowledge of the sources or the mixing system. This is a challenging problem that often requires making restrictive assumptions about both the mixing system and the sources. In this paper, we propose a novel method for addressing BSS of non-linear mixtures by leveraging the natural feature subspace specialization ability of multi-encoder autoencoders with fully self-supervised learning without strong priors. During the training phase, our method unmixes the input into the separate encoding spaces of the multi-encoder network and then remixes these representations within the decoder for a reconstruction of the input. Then to perform source inference, we introduce a novel encoding masking technique whereby masking out all but one of the encodings enables the decoder to estimate a source signal. To this end, we also introduce a so-called pathway separation loss that encourages sparsity betwe
    
[^173]: 可扩展的神经网络模型和千兆级数据集用于粒子流重建

    Scalable neural network models and terascale datasets for particle-flow reconstruction. (arXiv:2309.06782v1 [physics.data-an])

    [http://arxiv.org/abs/2309.06782](http://arxiv.org/abs/2309.06782)

    本研究针对高能电子-正电子碰撞中的粒子流重建，使用可扩展的机器学习模型，并通过超参数调优和硬件处理器的高度可移植性，取得了真实且具有竞争力的物理性能。

    

    本研究针对高能电子-正电子碰撞中基于高度粒度探测器模拟的完整事件重建，研究了可扩展的机器学习模型。粒子流（PF）重建可通过跟踪和量能器团簇或击中来构建监督学习任务。我们比较了图神经网络和基于内核的变换器，并证明两者都避免了二次内存分配和计算成本，同时实现了真实的粒子流重建。我们展示了在超级计算机上进行的超参数调优显著提高了模型的物理性能。我们还展示了所得模型在硬件处理器上具有高度可移植性，支持NVIDIA, AMD和英特尔 Habana卡。最后，我们证明了模型可以在由跟踪和量能器击中组成的高粒度输入上进行训练，从而获得与基准相竞争的物理性能。有关复现研究的数据集和软件已发布。

    We study scalable machine learning models for full event reconstruction in high-energy electron-positron collisions based on a highly granular detector simulation. Particle-flow (PF) reconstruction can be formulated as a supervised learning task using tracks and calorimeter clusters or hits. We compare a graph neural network and kernel-based transformer and demonstrate that both avoid quadratic memory allocation and computational cost while achieving realistic PF reconstruction. We show that hyperparameter tuning on a supercomputer significantly improves the physics performance of the models. We also demonstrate that the resulting model is highly portable across hardware processors, supporting Nvidia, AMD, and Intel Habana cards. Finally, we demonstrate that the model can be trained on highly granular inputs consisting of tracks and calorimeter hits, resulting in a competitive physics performance with the baseline. Datasets and software to reproduce the studies are published following 
    
[^174]: 连续时间q-learning用于McKean-Vlasov控制问题

    Continuous-Time q-learning for McKean-Vlasov Control Problems. (arXiv:2306.16208v1 [cs.LG])

    [http://arxiv.org/abs/2306.16208](http://arxiv.org/abs/2306.16208)

    本文研究了连续时间q-learning在熵正则化强化学习框架下用于McKean-Vlasov控制问题，并揭示了两种不同的q函数的存在及其积分表示。

    

    本文研究了q-learning，在熵正则化强化学习框架下，用于连续时间的McKean-Vlasov控制问题。与Jia和Zhou（2022c）的单个代理控制问题不同，代理之间的均场相互作用使得q函数的定义更加复杂，我们揭示了自然产生两种不同q函数的情况：（i）被称为集成q函数（用$q$表示），作为Gu、Guo、Wei和Xu（2023）引入的集成Q函数的一阶近似，可以通过涉及测试策略的弱鞅条件进行学习；（ii）作为策略改进迭代中所使用的实质q函数（用$q_e$表示）。我们证明了这两个q函数在所有测试策略下通过积分表示相关联。基于集成q函数的弱鞅条件和我们提出的搜索方法，我们设计了算法来学习两个q函数以解决Mckean-Vlasov控制问题。

    This paper studies the q-learning, recently coined as the continuous-time counterpart of Q-learning by Jia and Zhou (2022c), for continuous time Mckean-Vlasov control problems in the setting of entropy-regularized reinforcement learning. In contrast to the single agent's control problem in Jia and Zhou (2022c), the mean-field interaction of agents render the definition of q-function more subtle, for which we reveal that two distinct q-functions naturally arise: (i) the integrated q-function (denoted by $q$) as the first-order approximation of the integrated Q-function introduced in Gu, Guo, Wei and Xu (2023) that can be learnt by a weak martingale condition involving test policies; and (ii) the essential q-function (denoted by $q_e$) that is employed in the policy improvement iterations. We show that two q-functions are related via an integral representation under all test policies. Based on the weak martingale condition of the integrated q-function and our proposed searching method of
    
[^175]: 带有Bandit反馈的最近邻算法

    Nearest Neighbour with Bandit Feedback. (arXiv:2306.13773v1 [cs.LG])

    [http://arxiv.org/abs/2306.13773](http://arxiv.org/abs/2306.13773)

    本论文提出一种新的最近邻算法，能够应用于上下文Bandit问题并处理完全对抗的设置，具有高效运行、快速搜索和准线性空间的优点。

    

    本文将最近邻算法应用于上下文Bandit问题中。我们的算法处理了完全对抗的设置，即不对数据生成过程做任何假设。当与快速数据结构（可能是近似的自适应最近邻搜索，如导航网络）相结合时，我们的算法非常高效-每次试验的运行时间对动作数和试验数呈对数多项式增长，并且只需要准线性空间。

    In this paper we adapt the nearest neighbour rule to the contextual bandit problem. Our algorithm handles the fully adversarial setting in which no assumptions at all are made about the data-generation process. When combined with a sufficiently fast data-structure for (perhaps approximate) adaptive nearest neighbour search, such as a navigating net, our algorithm is extremely efficient - having a per trial running time polylogarithmic in both the number of trials and actions, and taking only quasi-linear space.
    
[^176]: 最大熵异质代理镜像学习

    Maximum Entropy Heterogeneous-Agent Mirror Learning. (arXiv:2306.10715v2 [cs.MA] UPDATED)

    [http://arxiv.org/abs/2306.10715](http://arxiv.org/abs/2306.10715)

    最大熵异质代理镜像学习(MEHAML)是一种新的理论框架，通过最大熵原理设计了最大熵MARL的演员-评论家算法，具有联合最大熵目标的单调改进和收敛至中位响应均衡(QRE)的期望特性，并通过扩展常用的强化学习算法HASAC来验证其实用性和在探索和稳健性方面的显著改进。

    

    多智能体强化学习(MARL)在合作博弈中表现出有效性。然而，现有的最先进方法面临样本效率低、超参数脆弱性和收敛于次优纳什均衡的风险等挑战。为了解决这些问题，本文提出了一种新的理论框架，命名为最大熵异质代理镜像学习(MEHAML)，利用最大熵原理设计了最大熵MARL的演员-评论家算法。我们证明了从MEHAML框架导出的算法具有联合最大熵目标的单调改进和收敛至中位响应均衡(QRE)的期望特性。MEHAML的实用性通过开发广泛使用的强化学习算法HASAC的MEHAML扩展来展示，在三个具有挑战性的基准测试上展示出了探索和稳健性的显著提升。

    Multi-agent reinforcement learning (MARL) has been shown effective for cooperative games in recent years. However, existing state-of-the-art methods face challenges related to sample inefficiency, brittleness regarding hyperparameters, and the risk of converging to a suboptimal Nash Equilibrium. To resolve these issues, in this paper, we propose a novel theoretical framework, named Maximum Entropy Heterogeneous-Agent Mirror Learning (MEHAML), that leverages the maximum entropy principle to design maximum entropy MARL actor-critic algorithms. We prove that algorithms derived from the MEHAML framework enjoy the desired properties of the monotonic improvement of the joint maximum entropy objective and the convergence to quantal response equilibrium (QRE). The practicality of MEHAML is demonstrated by developing a MEHAML extension of the widely used RL algorithm, HASAC (for soft actor-critic), which shows significant improvements in exploration and robustness on three challenging benchmark
    
[^177]: ContriMix：显微镜图像分析中基于无监督内容属性分离的领域泛化方法

    ContriMix: Unsupervised disentanglement of content and attribute for domain generalization in microscopy image analysis. (arXiv:2306.04527v1 [eess.IV])

    [http://arxiv.org/abs/2306.04527](http://arxiv.org/abs/2306.04527)

    ContriMix是一种无需标识和手工调优的领域泛化技术，在显微镜图像中通过分离和学习生成合成图像的方式，解决了领域泛化的问题。

    

    针对组织学和荧光成像等显微镜图像中的领域泛化问题，我们提出了 ContriMix，它采用无监督学习方式分离出显微镜图像中的生物学内容和技术变异，并学习生成合成图像，避免了需要手工 fine-tuning 的问题。我们在组织学和荧光成像实验中验证了 ContriMix 的有效性，取得了基于领域泛化的最新成果。

    Domain generalization is critical for real-world applications of machine learning models to microscopy images, including histopathology and fluorescence imaging. Artifacts in histopathology arise through a complex combination of factors relating to tissue collection and laboratory processing, as well as factors intrinsic to patient samples. In fluorescence imaging, these artifacts stem from variations across experimental batches. The complexity and subtlety of these artifacts make the enumeration of data domains intractable. Therefore, augmentation-based methods of domain generalization that require domain identifiers and manual fine-tuning are inadequate in this setting. To overcome this challenge, we introduce ContriMix, a domain generalization technique that learns to generate synthetic images by disentangling and permuting the biological content ("content") and technical variations ("attributes") in microscopy images. ContriMix does not rely on domain identifiers or handcrafted aug
    
[^178]: 用CLIP增强CLIP: 探索有限标注提示调参的伪标注方法

    Enhancing CLIP with CLIP: Exploring Pseudolabeling for Limited-Label Prompt Tuning. (arXiv:2306.01669v1 [cs.CV])

    [http://arxiv.org/abs/2306.01669](http://arxiv.org/abs/2306.01669)

    本文探索使用伪标注方法通过提示调参改进CLIP的方法，通过使用零样本伪标签来优化图像分类任务中有限标注数据的问题。

    

    微调视觉-语言模型（VLMs），如CLIP，以优化其性能往往是必要的。然而，主要障碍是有限数量的标注数据。本文研究使用伪标注（即非标注数据的启发式标签）通过提示调参改进CLIP的方法。传统伪标注方法会在有标注数据上训练模型，然后为无标注数据生成标签。VLM的零样本能力使“第二代”伪标注方法不需要在有标注数据上进行任务特定的训练。通过使用零样本伪标签作为监督来源，我们发现可以将半监督、过渡零样本和无监督学习等学习范式视为优化相同损失函数。这种统一的视角能够实现适用于各种学习范式的多功能培训策略的发展。我们通过改变提示的方式来探索这些培训策略，以解决 CLIP 在图像分类任务中存在的局限性。

    Fine-tuning vision-language models (VLMs) like CLIP to downstream tasks is often necessary to optimize their performance. However, a major obstacle is the limited availability of labeled data. We study the use of pseudolabels, i.e., heuristic labels for unlabeled data, to enhance CLIP via prompt tuning. Conventional pseudolabeling trains a model on labeled data and then generates labels for unlabeled data. VLMs' zero-shot capabilities enable a ``second generation'' of pseudolabeling approaches that do not require task-specific training on labeled data. By using zero-shot pseudolabels as a source of supervision, we observe that learning paradigms such as semi-supervised, transductive zero-shot, and unsupervised learning can all be seen as optimizing the same loss function. This unified view enables the development of versatile training strategies that are applicable across learning paradigms. We investigate them on image classification tasks where CLIP exhibits limitations, by varying p
    
[^179]: 基于分数的生成模型的高保真图像压缩

    High-Fidelity Image Compression with Score-based Generative Models. (arXiv:2305.18231v1 [eess.IV])

    [http://arxiv.org/abs/2305.18231](http://arxiv.org/abs/2305.18231)

    本文提出了一种基于分数的生成模型的两阶段方法，该方法在图像压缩领域取得了显著的表现，实验证明该方法在一定比特率下能够提高图像的感知质量。

    

    尽管扩散生成模型在文本到图像生成中取得了巨大的成功，但在图像压缩领域复制这个成功却很困难。在本文中，我们展示了扩散模型可以显著提高在给定比特率下的感知质量，通过 FID 分数评估，表现超越了 PO-ELIC 和 HiFiC 的现有方法。我们通过一个简单但在理论上有动机的两阶段方法实现了这一点，该方法结合了以 MSE 为目标的自动编码器和一个进一步基于分数的解码器。然而，正如我们将展示的那样，实现细节很重要，最佳设计决策可能与典型的文本到图像模型有很大不同。

    Despite the tremendous success of diffusion generative models in text-to-image generation, replicating this success in the domain of image compression has proven difficult. In this paper, we demonstrate that diffusion can significantly improve perceptual quality at a given bit-rate, outperforming state-of-the-art approaches PO-ELIC and HiFiC as measured by FID score. This is achieved using a simple but theoretically motivated two-stage approach combining an autoencoder targeting MSE followed by a further score-based decoder. However, as we will show, implementation details matter and the optimal design decisions can differ greatly from typical text-to-image models.
    
[^180]: 大象的透视镜：调查谷歌、ChatGPT、维基百科和YouTube上的语言偏见

    A Perspectival Mirror of the Elephant: Investigating Language Bias on Google, ChatGPT, Wikipedia, and YouTube. (arXiv:2303.16281v1 [cs.CY])

    [http://arxiv.org/abs/2303.16281](http://arxiv.org/abs/2303.16281)

    研究发现在Google、ChatGPT、维基百科和YouTube上，搜索结果受限于语言，反映了与复杂主题相关的文化刻板印象，缺乏跨文化视角。

    

    与谷歌搜索“从多个角度获取信息，以便你可以形成自己对世界的理解”的任务相反，我们发现谷歌及其最突出的搜索结果 - 维基百科和YouTube，仅反映与“佛教”、“自由主义”、“殖民化”、“伊朗”和“美国”等复杂主题相关的文化刻板印象。简单地说，在不同语言的相同搜索中，它们以不同程度呈现不同的信息（我们称之为“语言偏见”），而不是呈现复杂主题的全球图片。我们的在线搜索使我们成为谚语中的盲人，仅触摸小象的一小部分，不知道其他文化的视角的存在。我们用于搜索的语言最终成为促进本族中心主义观点的文化过滤器，其中一个人根据自己的文化评估其他人或思想。我们还发现ChatGPT中深深嵌入了语言偏见。

    Contrary to Google Search's mission of delivering information from "many angles so you can form your own understanding of the world," we find that Google and its most prominent returned results -- Wikipedia and YouTube, simply reflect the narrow set of cultural stereotypes tied to the search language for complex topics like "Buddhism," "Liberalism," "colonization," "Iran" and "America." Simply stated, they present, to varying degrees, distinct information across the same search in different languages (we call it 'language bias'). Instead of presenting a global picture of a complex topic, our online searches turn us into the proverbial blind person touching a small portion of an elephant, ignorant of the existence of other cultural perspectives. The language we use to search ends up as a cultural filter to promote ethnocentric views, where a person evaluates other people or ideas based on their own culture. We also find that language bias is deeply embedded in ChatGPT. As it is primaril
    
[^181]: Distill n' Explain：使用简单替代模型解释图神经网络

    Distill n' Explain: explaining graph neural networks using simple surrogates. (arXiv:2303.10139v1 [cs.LG])

    [http://arxiv.org/abs/2303.10139](http://arxiv.org/abs/2303.10139)

    本文提出了Distill n' Explain (DnX)方法，通过知识蒸馏学习简单的替代模型，并通过解决简单的凸规划提取节点或边级别的解释，从而解释图神经网络（GNN）。实验结果显示，DnX和FastDnX通常优于最先进的GNN解释器，并且运行速度快得多。

    

    解释图神经网络中节点预测的方法通常是找到保持预测的图子结构。这通常意味着反向传播由于GNN的复杂性（例如，层数）而导致解释的成本上升。因此，作者提出了Distill n' Explain (DnX)方法。首先，DnX通过知识蒸馏来学习替代的GNN。然后，DnX通过解决简单的凸规划来提取节点或边级别的解释。同时，作者还提出了FastDnX，这是DnX的更快版本，它利用了我们替代模型的线性分解。实验表明，DnX和FastDnX通常优于最先进的GNN解释器，并且运行速度快得多。此外，我们还通过理论结果支持了我们的实验发现。

    Explaining node predictions in graph neural networks (GNNs) often boils down to finding graph substructures that preserve predictions. Finding these structures usually implies back-propagating through the GNN, bonding the complexity (e.g., number of layers) of the GNN to the cost of explaining it. This naturally begs the question: Can we break this bond by explaining a simpler surrogate GNN? To answer the question, we propose Distill n' Explain (DnX). First, DnX learns a surrogate GNN via knowledge distillation. Then, DnX extracts node or edge-level explanations by solving a simple convex program. We also propose FastDnX, a faster version of DnX that leverages the linear decomposition of our surrogate model. Experiments show that DnX and FastDnX often outperform state-of-the-art GNN explainers while being orders of magnitude faster. Additionally, we support our empirical findings with theoretical results linking the quality of the surrogate model (i.e., distillation error) to the faith
    
[^182]: 基于树模型的边际特征归因研究

    On marginal feature attributions of tree-based models. (arXiv:2302.08434v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.08434](http://arxiv.org/abs/2302.08434)

    该论文讨论了基于树模型的边际特征归因方法，与流行的TreeSHAP算法相比，边际Shapley值在相同函数的情况下保持一致，并且介绍了如何利用树模型的内部结构计算边际特征归因。

    

    由于其强大和易于使用的特点，随机森林和梯度提升树集成等基于树的机器学习模型变得非常流行。为了解释这些模型，可以使用基于边际期望的局部特征归因方法，例如边际（干预）Shapley、Owen或Banzhaf值。这些方法对模型真实且实现不变，即仅依赖于模型的输入输出函数。通过提供两个（具有相似统计性质的）决策树来对比这一点，这两个决策树计算完全相同的函数，但“路径相关”的TreeSHAP方法给出了不同的特征排序，而边际Shapley值重合。此外，我们讨论了如何利用基于树模型的内部结构来帮助计算它们的边际特征归因，以得到线性博弈值。一个重要的观察是，这些函数在某个常数区间内是简单的（分段常数）函数。

    Due to their power and ease of use, tree-based machine learning models, such as random forests and gradient-boosted tree ensembles, have become very popular. To interpret them, local feature attributions based on marginal expectations, e.g. marginal (interventional) Shapley, Owen or Banzhaf values, may be employed. Such methods are true to the model and implementation invariant, i.e. dependent only on the input-output function of the model. We contrast this with the popular TreeSHAP algorithm by presenting two (statistically similar) decision trees that compute the exact same function for which the "path-dependent" TreeSHAP yields different rankings of features, whereas the marginal Shapley values coincide. Furthermore, we discuss how the internal structure of tree-based models may be leveraged to help with computing their marginal feature attributions according to a linear game value. One important observation is that these are simple (piecewise-constant) functions with respect to a c
    
[^183]: 超越集合平均值：利用气候模型集合进行地表季节性预测

    Beyond Ensemble Averages: Leveraging Climate Model Ensembles for Subseasonal Forecasting. (arXiv:2211.15856v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.15856](http://arxiv.org/abs/2211.15856)

    本文研究了利用气候模型集合进行地表季节性预测的应用，超越了传统的平均方法，利用集合预测中的信息提高了预测准确性，关注了极端事件的预测，同时考虑了空间变化的预测集合。

    

    在操作性预测中，对于关键气候变量（如温度和降水）进行高质量的地表季节性时间尺度预测一直存在着差距。最近的研究表明，使用机器学习（ML）模型来推进地表季节性预测（SSF）取得了有希望的结果，但仍存在一些未解的问题。首先，过去的方法中使用了物理基于模型集合的平均作为这些模型的输入特征，然而集合预测中包含了可以帮助预测的信息，不仅仅是集合均值。其次，过去的方法关注平均性能，然而对于计划和减灾目的来说，极端事件的预测更加重要。第三，气候预测对应于一个空间变化的预测集合，而不同的方法以不同的方式考虑了响应的空间可变性。模型堆叠可以缓解不同方法之间的权衡。本文描述了一种利用模型集合进行地表季节性预测的应用。

    Producing high-quality forecasts of key climate variables such as temperature and precipitation on subseasonal time scales has long been a gap in operational forecasting. Recent studies have shown promising results using machine learning (ML) models to advance subseasonal forecasting (SSF), but several open questions remain. First, several past approaches use the average of an ensemble of physics-based forecasts as an input feature of these models. However, ensemble forecasts contain information that can aid prediction beyond only the ensemble mean. Second, past methods have focused on average performance, whereas forecasts of extreme events are far more important for planning and mitigation purposes. Third, climate forecasts correspond to a spatially-varying collection of forecasts, and different methods account for spatial variability in the response differently. Trade-offs between different approaches may be mitigated with model stacking. This paper describes the application of a va
    
[^184]: 量子强化学习综述

    A Survey on Quantum Reinforcement Learning. (arXiv:2211.03464v1 [quant-ph] CROSS LISTED)

    [http://arxiv.org/abs/2211.03464](http://arxiv.org/abs/2211.03464)

    本文综述了量子强化学习的最新进展和相关文献，重点介绍了基于噪声中等规模量子设备的变分量子电路在经典强化学习中的应用，以及基于未来容错硬件的量子强化学习算法，其中一些具有可证明的量子优势。

    

    量子强化学习是量子计算和机器学习交叉领域中的新兴领域。本文将提供量子强化学习文献的广泛概述，但我们特别强调最近的发展。我们关注的是已经可用的噪声中等规模量子设备，这些设备包括变分量子电路，它在传统的强化学习框架下充当函数逼近器。此外，我们还调查了基于未来容错硬件的量子强化学习算法，其中一些具有可证明的量子优势。我们提供了对该领域的俯瞰以及对文献中部分内容的总结和评论。

    Quantum reinforcement learning is an emerging field at the intersection of quantum computing and machine learning. While we intend to provide a broad overview of the literature on quantum reinforcement learning (our interpretation of this term will be clarified below), we put particular emphasis on recent developments. With a focus on already available noisy intermediate-scale quantum devices, these include variational quantum circuits acting as function approximators in an otherwise classical reinforcement learning setting. In addition, we survey quantum reinforcement learning algorithms based on future fault-tolerant hardware, some of which come with a provable quantum advantage. We provide both a birds-eye-view of the field, as well as summaries and reviews for selected parts of the literature.
    
[^185]: 双控制变量加速黑盒变分推断

    Dual control variate for faster black-box variational inference. (arXiv:2210.07290v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.07290](http://arxiv.org/abs/2210.07290)

    本论文提出了双控制变量方法，能够同时减少数据子抽样和蒙特卡罗抽样带来的梯度估计方差，提高黑盒变分推断的准确性和效率。

    

    黑盒变分推断是一种广泛使用的贝叶斯后验推断框架，但在某些情况下，梯度估计中的高方差会损害准确性和效率。这种方差来自两个随机源：数据子抽样和蒙特卡罗抽样。现有的控制变量仅解决蒙特卡罗噪声，而增量梯度方法通常仅解决数据子抽样，我们提出了一种新的“双”控制变量，能够同时减少两种噪声源的方差。我们确认这导致了减少方差和在多个现实世界应用中提高优化效果。

    Black-box variational inference is a widely-used framework for Bayesian posterior inference, but in some cases suffers from high variance in gradient estimates, harming accuracy and efficiency. This variance comes from two sources of randomness: Data subsampling and Monte Carlo sampling. Whereas existing control variates only address Monte Carlo noise and incremental gradient methods typically only address data subsampling, we propose a new "dual" control variate capable of jointly reducing variance from both sources of noise. We confirm that this leads to reduced variance and improved optimization in several real-world applications.
    
[^186]: 静息时人类功能性脑网络的持续同调状态空间估计

    Persistent Homological State-Space Estimation of Functional Human Brain Networks at Rest. (arXiv:2201.00087v3 [math.AT] UPDATED)

    [http://arxiv.org/abs/2201.00087](http://arxiv.org/abs/2201.00087)

    该论文提出了一种新的数据驱动的拓扑数据分析方法，用于估计静息状态下人类脑网络的状态空间。该方法通过惩罚网络之间的拓扑距离将动态变化的脑网络聚类为不同的状态，并通过考虑时间维度来提高准确性。研究还发现脑网络的整体拓扑具有遗传特征。

    

    我们提出了一种新的数据驱动的拓扑数据分析（TDA）方法，用于估计动态变化的人类功能性脑网络的状态空间。我们的方法通过对网络之间的拓扑距离进行惩罚，将动态变化的脑网络聚类为拓扑上不同的状态。我们的方法通过计算网络之间的Wasserstein距离考虑了数据的时间维度。我们的方法在估计脑网络的状态空间方面表现优于广泛使用的k-means聚类方法。该方法被应用于更准确地确定动态变化的功能性脑网络的状态空间。随后，我们采用双生子研究设计探讨了脑网络的整体拓扑是否具有遗传特征。

    We present a new data driven topological data analysis (TDA) approach for estimating state spaces in dynamically changing human functional brain networks of human. Our approach penalizes the topological distance between networks and clusters dynamically changing brain networks into topologically distinct states. Our method takes into account the temporal dimension of the data through the Wasserstein distance between networks. Our method is shown to outperform the widely used k-means clustering often used in estimating the state space in brain networks. The method is applied to more accurately determine the state spaces of dynamically changing functional brain networks. Subsequently, we address the question of whether the overall topology of brain networks is a heritable feature using the twin study design.
    

