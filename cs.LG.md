# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Self-training with dual uncertainty for semi-supervised medical image segmentation.](http://arxiv.org/abs/2304.04441) | 该论文介绍了在半监督医学图像分割中如何通过双重不确定性的自训练方式来提高分割精度。 |
| [^2] | [PCR: Proxy-based Contrastive Replay for Online Class-Incremental Continual Learning.](http://arxiv.org/abs/2304.04408) | 本文提出了一种名为PCR的基于代理的对比式回放方法，它能够有效地解决在线类增量连续学习中的历史知识遗忘问题。经实验证明，在两个视觉数据集上，PCR能够显著优于现有方法。 |
| [^3] | [CAVL: Learning Contrastive and Adaptive Representations of Vision and Language.](http://arxiv.org/abs/2304.04399) | 本文提出了一种对比自适应的视觉与语言表示学习方法CAVL，在预训练过程中通过对比损失学习整个句子和图像之间的对齐，并在微调阶段引入轻量级自适应网络，实现在下游任务中的最先进效果。 |
| [^4] | [Randomized and Deterministic Attention Sparsification Algorithms for Over-parameterized Feature Dimension.](http://arxiv.org/abs/2304.04397) | 本论文提出了随机和确定性注意力稀疏化算法，用于处理超参数化特征维度，其目标是找到适当的矩阵Y，使得其满足特定条件，从而帮助解决注意问题。 |
| [^5] | [CAFIN: Centrality Aware Fairness inducing IN-processing for Unsupervised Representation Learning on Graphs.](http://arxiv.org/abs/2304.04391) | CAFIN是一种基于节点中心性的公平性增强进程技术，用于无监督学习的图表示学习方法中。实验结果表明，CAFIN在提供最优公平结果的同时，具有竞争力或更好的下游任务性能。 |
| [^6] | [Generating Adversarial Attacks in the Latent Space.](http://arxiv.org/abs/2304.04386) | 该论文提出在潜空间中使用生成对抗网络注入对抗扰动来生成对抗攻击。实验证明该方法在生成潜空间中的对抗攻击时与像素空间中基于对抗攻击的方法相比具有同等的有效性，同时保持了高度的视觉真实度。 |
| [^7] | [On Robustness in Multimodal Learning.](http://arxiv.org/abs/2304.04385) | 本文提出了一个多模态鲁棒性框架，分析了多种多模态学习方法的鲁棒性不足，并提出了两种干预技术，在多个数据集上实现了1.5倍至4倍的鲁棒性提高，同时在AudioSet 20K上实现了44.2 mAP的有竞争力结果。 |
| [^8] | [OpenAGI: When LLM Meets Domain Experts.](http://arxiv.org/abs/2304.04370) | 基于大型语言模型的OpenAGI平台通过整合领域专家模型和自然语言问答形式，实现复杂任务解决。 |
| [^9] | [Learning Residual Model of Model Predictive Control via Random Forests for Autonomous Driving.](http://arxiv.org/abs/2304.04366) | 通过随机森林学习残差模型，该论文提出了一种分层学习残差模型的新方法，可以更好地解决自动驾驶中预测精度和计算效率之间的矛盾。 |
| [^10] | [Eagle: End-to-end Deep Reinforcement Learning based Autonomous Control of PTZ Cameras.](http://arxiv.org/abs/2304.04356) | Eagle 是一个基于端到端深度强化学习的解决方案，通过逼真的模拟框架训练神经网络策略，直接以图像作为输入控制 PTZ 摄像头，实现了卓越的摄像头控制性能。 |
| [^11] | [Exponentially Improved Efficient Machine Learning for Quantum Many-body States with Provable Guarantees.](http://arxiv.org/abs/2304.04353) | 通过机器学习协议预测量子多体系统的基态及其性质，其精度为 $\varepsilon$，并具有可证明的保障；但对于普遍的能隙哈密顿量，样本个数 $N = m^{{\cal{O}} \left(\frac{1}{\varepsilon}\right)}$，只适用于参数空间维度较大，且精度不是紧迫因素，无法进入更精确的学习和预测领域。 |
| [^12] | [Towards Real-time Text-driven Image Manipulation with Unconditional Diffusion Models.](http://arxiv.org/abs/2304.04344) | 本研究提出了一种基于无条件扩散模型的图像编辑算法，可根据提供的文本描述快速学习和应用高质量的图像操作，比旧算法学习图像操作更快4.5-10倍，应用更快速的8倍。 |
| [^13] | [Certifiable Black-Box Attack: Ensuring Provably Successful Attack for Adversarial Examples.](http://arxiv.org/abs/2304.04343) | 本文提出可证黑盒攻击，能够保证攻击成功率，设计了多种新技术。 |
| [^14] | [Regret Distribution in Stochastic Bandits: Optimal Trade-off between Expectation and Tail Risk.](http://arxiv.org/abs/2304.04341) | 该论文探讨了随机多臂赌博问题中，如何在期望和尾部风险之间做出最优权衡。提出了一种新的策略，能够实现最坏和实例相关的优异表现，并且能够最小化遗憾尾部概率。 |
| [^15] | [Pretrained Embeddings for E-commerce Machine Learning: When it Fails and Why?.](http://arxiv.org/abs/2304.04330) | 研究发现，预训练嵌入在电子商务机器学习中的应用存在许多问题，尤其是在真实生产系统中。尽管预训练嵌入是有效的，但它的成功与下游模型的设计以及如何通过嵌入向量来编码和解码信息有着深刻的联系和原因。 |
| [^16] | [Homogenizing Non-IID datasets via In-Distribution Knowledge Distillation for Decentralized Learning.](http://arxiv.org/abs/2304.04326) | 本文提出了基于分布中知识蒸馏（IDKD）的方法来解决节点间同质化数据分布的问题，该方法使用公共数据集来从每个节点中提取知识，并通过生成的标签将其传递给其邻居，以实现相同的目标，同时保持隐私约束。在非i.i.d.数据集上，IDKD的性能显着优于现有方法，同时保持隐私和通信效率。 |
| [^17] | [Microseismic source imaging using physics-informed neural networks with hard constraints.](http://arxiv.org/abs/2304.04315) | 本论文提出一种使用物理知识约束的神经网络（PINNs）进行直接微震成像的方法，能够生成聚焦的源图像，即使只有极少的记录。数值实验表明，该方法可以产生可靠且精确的结果。 |
| [^18] | [Theoretical Characterization of the Generalization Performance of Overfitted Meta-Learning.](http://arxiv.org/abs/2304.04312) | 本文研究了过拟合元学习的泛化性能，发现模型无关元学习（MAML）的过拟合最小 $\ell_2$ 范数解可以是有益的，类似于最近关于“良性过拟合”和“双下降”现象的显着发现。 |
| [^19] | [Ensemble Modeling for Time Series Forecasting: an Adaptive Robust Optimization Approach.](http://arxiv.org/abs/2304.04308) | 本文提出了一种基于自适应鲁棒优化的方法，用于构建强鲁棒性的时间序列预测模型集成，取得了比最佳集成成员更好的表现。 |
| [^20] | [PriorCVAE: scalable MCMC parameter inference with Bayesian deep generative modelling.](http://arxiv.org/abs/2304.04307) | PriorCVAE 提出了一种处理高斯过程先验 MCMC 参数推断的贝叶斯深度生成建模新方法，可通过将 VAE 建模条件化于随机过程超参数处理超参数推断与学习先验之间的信息流断裂问题。 |
| [^21] | [Class-Imbalanced Learning on Graphs: A Survey.](http://arxiv.org/abs/2304.04300) | 本文综述了现有CILG技术的最新状态，提出了一个现有工作的分类法，并讨论了未来研究方向。CILG作为一种有前途的解决方案，将图表示学习和类别不平衡学习相结合，用于克服现实世界数据中的类别不平衡问题。 |
| [^22] | [Distributed Conditional GAN (discGAN) For Synthetic Healthcare Data Generation.](http://arxiv.org/abs/2304.04290) | 本文提出了一种分布式生成对抗网络（discGAN）用于生成医疗保健领域的合成表格数据，并且在应用中成功模拟出非高斯多模式医疗保健数据的分布，其生成的数据分布与真实数据相似。 |
| [^23] | [Filling out the missing gaps: Time Series Imputation with Semi-Supervised Learning.](http://arxiv.org/abs/2304.04275) | 本文提出了一种名为ST-Impute的半监督时间序列插补方法，使用未标记数据和下游任务的标记数据进行训练，基于稀疏自我关注的方法比现有的监督和无监督时间序列插补方法更优秀。 |
| [^24] | [Multimodal Brain-Computer Interface for In-Vehicle Driver Cognitive Load Measurement: Dataset and Baselines.](http://arxiv.org/abs/2304.04273) | 本文介绍了一个新型的驾驶员认知负荷评估数据集，采用多模态生理信号与眼动追踪数据结合的方法，提高了分类性能，为该领域的进一步研究提供了基准。 |
| [^25] | [Embarrassingly Simple MixUp for Time-series.](http://arxiv.org/abs/2304.04271) | 本研究针对时间序列数据提出了一种基于MixUp的数据增强方法，即MixUp++和LatentMixUp++，能够显著提高1％- 15％的分类准确率，尤其适用于有限标记数据的情况，并通过半监督学习扩展到无标签数据。 |
| [^26] | [A Comprehensive Survey on Knowledge Distillation of Diffusion Models.](http://arxiv.org/abs/2304.04262) | 扩散模型是一种直接建模评分函数的概率模型，在实现概率建模上更具可塑性和表达能力。本文综述了扩散模型知识蒸馏的现代方法和挑战，包括将扩散模型蒸馏至隐式生成函数的方法以及训练-free 的加速扩散采样算法。 |
| [^27] | [CLVOS23: A Long Video Object Segmentation Dataset for Continual Learning.](http://arxiv.org/abs/2304.04259) | 本文提出用于持续学习的长视频对象分割数据集CLVOS23，并在此基础上实现了一个基于正则化的持续学习方法，以应对半监督视频对象分割中的持续学习挑战。 |
| [^28] | [A Note on "Efficient Task-Specific Data Valuation for Nearest Neighbor Algorithms".](http://arxiv.org/abs/2304.04258) | 本文提出了一种更自然和可解释的效用函数，更好地反映了KNN模型的性能，提供了相应计算过程，该方法被称为软标签KNN-SV，与原始方法具有相同的时间复杂度。 |
| [^29] | [Secure Routing Protocol To Mitigate Attacks By Using Blockchain Technology In Manet.](http://arxiv.org/abs/2304.04254) | 论文提出了一种采用区块链技术的安全路由算法（SRABC），该算法通过提供源节点到目的节点的安全、经过认证和防篡改的路由来保护控制和数据流，预防MANET受到各种攻击手段，并对节点进行认证。仿真结果表明，SRABC算法优于当前方法，是确保MANET安全的可行选项。 |
| [^30] | [Editable User Profiles for Controllable Text Recommendation.](http://arxiv.org/abs/2304.04250) | 本文提出了一种新的概念值瓶颈模型LACE，用于可控文本推荐。该模型基于用户文档学习个性化的概念表示，并通过多种交互方式为用户提供了控制推荐的机制，验证了在离线和在线实验中该模型的推荐质量和有效性。 |
| [^31] | [Data-driven multinomial random forest.](http://arxiv.org/abs/2304.04240) | 本文加强了一些先前弱一些的随机森林变体的证明方法并提高了这些变体的数据利用率以获得更好的理论性能和实验性能，提出了一种数据驱动的多项式随机森林算法，其复杂度低且满足强一致性，在分类和回归问题上表现更好，并超过了标准随机森林。 |
| [^32] | [Variational operator learning: A unified paradigm for training neural operators and solving partial differential equations.](http://arxiv.org/abs/2304.04234) | 本文提出了变分算子学习（VOL）的范式，同时训练神经算子和解决偏微分方程（PDE）。使用正反传递循环和自动微分实现了变分操作，通过最速下降法和共轭梯度法进行神经算子的简单但有效的训练。实验结果非常好。 |
| [^33] | [RISC: Generating Realistic Synthetic Bilingual Insurance Contract.](http://arxiv.org/abs/2304.04212) | 本文介绍了一个名为RISC的Python开源包数据生成器，它可以生成类似于魁北克省法规保险格式的汽车保险合同，包括法语和英语版本，基于此生成的RISCBAC数据集可用于NLP研究中的无监督自动摘要、问答、文本简化、机器翻译任务，以及监督任务。 |
| [^34] | [AGAD: Adversarial Generative Anomaly Detection.](http://arxiv.org/abs/2304.04211) | 该论文提出了一种基于自我对比的对抗生成式异常检测模式AGAD，它成功解决了因缺少异常数据而造成的稳健异常检测问题，并且能够为监督和半监督异常检测场景生成伪异常数据。 |
| [^35] | [OpenDriver: an open-road driver state detection dataset.](http://arxiv.org/abs/2304.04203) | OpenDriver是一份旨在解决现有驾驶员生理数据集存在问题的开放路况驾驶员状态检测数据集，包含六轴惯性信号和心电图信号两种模态的数据，可用于驾驶员受损检测和生物识别数据识别。 |
| [^36] | [Information-Theoretic Testing and Debugging of Fairness Defects in Deep Neural Networks.](http://arxiv.org/abs/2304.04199) | 本文介绍了一个信息论测试和调试框架DICE，用于衡量DNN中公平性缺陷的严重性及其根源，以帮助开发人员进行处理。 |
| [^37] | [HyperINR: A Fast and Predictive Hypernetwork for Implicit Neural Representations via Knowledge Distillation.](http://arxiv.org/abs/2304.04188) | 本文提出了一种基于知识蒸馏的超网络架构HyperINR，能够高效快速地构建出最先进推理性能的隐式神经表示（INR），并且支持交互式的照片级体积可视化。 |
| [^38] | [Nearest-Neighbor Sampling Based Conditional Independence Testing.](http://arxiv.org/abs/2304.04183) | 本文提出了一种基于最近邻抽样的条件独立性检验方法，通过1-最近邻来近似编码零假设的条件分布，理论上证明了生成样本的分布非常接近真实的条件分布，在此基础上采用分类器-based条件互信息估计器作为检验统计量。 |
| [^39] | [$\mu^2$-SGD: Stable Stochastic Optimization via a Double Momentum Mechanism.](http://arxiv.org/abs/2304.04172) | 提出了一种新的梯度估计方法，结合了最近的两种与动量概念相关的机制，实现了稳定的随机优化，对学习率选择具有鲁棒性，在无噪声和有噪声情况下的收敛速率均为最优。 |
| [^40] | [SLowcal-SGD: Slow Query Points Improve Local-SGD for Stochastic Convex Optimization.](http://arxiv.org/abs/2304.04169) | 本论文提出了一种利用慢查询点技术改进Local-SGD算法的方法，可以对抗异构情况下本地更新的偏差。 |
| [^41] | [Adversarially Robust Neural Architecture Search for Graph Neural Networks.](http://arxiv.org/abs/2304.04168) | 本文提出了G-RNA，一个面向图神经网络的对抗鲁棒神经结构搜索框架，通过添加图结构掩码操作来设计信息传递机制的一个鲁棒搜索空间，从而允许我们搜索防御性GNNs。 |
| [^42] | [Experience-Based Evolutionary Algorithms for Expensive Optimization.](http://arxiv.org/abs/2304.04166) | 本文研究了基于经验的优化方法，提出了一种基于经验的代理辅助进化算法(SAEA)框架，旨在通过充分利用相关问题所获得的经验来有效地解决难以优化的昂贵问题。 |
| [^43] | [Does Continual Learning Equally Forget All Parameters?.](http://arxiv.org/abs/2304.04158) | 本文研究了神经网络中哪些模块更容易遗忘，并发现只有少数模块是更加任务特定且在任务之间敏感地改变的。因此，我们将遗忘主要归因于这些模块，并提出了一种高效的“遗忘优先微调”方法来解决这个问题。 |
| [^44] | [Reweighted Mixup for Subpopulation Shift.](http://arxiv.org/abs/2304.04148) | RMIX是一种用于处理子人群偏移的简单实用方法，通过对“混合”样本进行重要性加权，探索邻域空间，从而获得更稳健的模型。 |
| [^45] | [FedPNN: One-shot Federated Classification via Evolving Clustering Method and Probabilistic Neural Network hybrid.](http://arxiv.org/abs/2304.04147) | 本文提出了一种两阶段联邦学习方法，通过进化聚类方法和概率神经网络的混合来实现一次联邦学习分类，以保护隐私并解决通信开销和有限资源的问题。 |
| [^46] | [RD-DPP: Rate-Distortion Theory Meets Determinantal Point Process to Diversify Learning Data Samples.](http://arxiv.org/abs/2304.04137) | 该论文介绍了一种基于码率-失真理论，结合分布式点过程的方法，用于多级分类中选择多样化的学习数据样本，相比现有方法具有更好的性能表现。 |
| [^47] | [NeRF applied to satellite imagery for surface reconstruction.](http://arxiv.org/abs/2304.04133) | 本文提出了Sat-NeRF模型，能够从少量的卫星图像集合中合成新的视角，并准确地估计场景表面的高程。 |
| [^48] | [Training Neural Networks for Execution on Approximate Hardware.](http://arxiv.org/abs/2304.04125) | 这篇论文介绍了如何针对近似硬件进行神经网络训练，加速了训练过程，为在需要进行推理任务的电池操作设备上实现高效深度学习提供了新的思路。 |
| [^49] | [TC-VAE: Uncovering Out-of-Distribution Data Generative Factors.](http://arxiv.org/abs/2304.04103) | 本文提出了一种基于总相关性的生成模型TC-VAE，可以揭示数据生成因素中的未知分布数据，在处理具有不平衡生成因素的数据集上表现优秀。 |
| [^50] | [Unsupervised Story Discovery from Continuous News Streams via Scalable Thematic Embedding.](http://arxiv.org/abs/2304.04099) | 本研究提出了一种新颖的主题嵌入方法和一个可扩展的无监督在线故事发现框架USTORY，可以动态表示文章和故事，并考虑它们共享的时间主题和新颖性，以帮助人们消化大量的新闻流。 |
| [^51] | [A Simple Proof of the Mixing of Metropolis-Adjusted Langevin Algorithm under Smoothness and Isoperimetry.](http://arxiv.org/abs/2304.04095) | 本文证明了，在光滑和等周条件下，MALA的混合时间仅与Hessian矩阵的trace有关，而与其算子范数和log-concave没有关系。 |
| [^52] | [Best Arm Identification with Fairness Constraints on Subpopulations.](http://arxiv.org/abs/2304.04091) | 本文解决了一个有关最优臂识别的问题，该问题要求所选臂必须对所有亚群都公平。我们提出了一个算法并证明其样本复杂度。 |
| [^53] | [Interpretable Multi Labeled Bengali Toxic Comments Classification using Deep Learning.](http://arxiv.org/abs/2304.04087) | 本文提出了一种基于深度学习的方法，用于分类孟加拉语的有害评论。使用LSTM和BERT嵌入实现了二元分类任务的高准确率，同时使用卷积神经网络和双向LSTM与注意机制组合实现了多标签分类，准确率和加权F1-score均较高。 |
| [^54] | [A Barrier-Lyapunov Actor-Critic Reinforcement Learning Approach for Safe and Stable Control.](http://arxiv.org/abs/2304.04066) | 本文提出了一种基于屏障-李亚普诺夫Actor-Critic（BLAC）框架，针对强化学习控制现实世界系统时的安全稳定控制问题提出了一种解决方案。其中，基于重放缓冲区采样的数据构建了CBF安全约束和CLF稳定约束，并使用增广拉格朗日方法来更新基于RL的控制器的参数。 |
| [^55] | [Counterfactual Explanations of Neural Network-Generated Response Curves.](http://arxiv.org/abs/2304.04063) | 本文提出一种使用反事实解释（CFEs）确定神经网络黑盒生成的响应曲线上最具相关性的特征的方法，并将其应用于工业资产预测维护的案例研究中，可以解释模型的行为并检测异常行为的潜在原因。 |
| [^56] | [Predicting multiple sclerosis disease severity with multimodal deep neural networks.](http://arxiv.org/abs/2304.04062) | 本研究提出使用患者的多模态EHR数据预测多发性硬化症疾病严重程度，以便实现早期干预和治疗。提高了预测准确性和模型复杂度。 |
| [^57] | [Learning Energy-Based Representations of Quantum Many-Body States.](http://arxiv.org/abs/2304.04058) | 该论文提出了一种新的基于能量的生成量子多体态表示方法，能够以数据驱动的方式构建能够捕获量子多体态复杂相关性和对称性的表示，该方法高效地学习1D和2D的量子多体态，并可自然地纳入物理约束条件。 |
| [^58] | [tmn at SemEval-2023 Task 9: Multilingual Tweet Intimacy Detection using XLM-T, Google Translate, and Ensemble Learning.](http://arxiv.org/abs/2304.04054) | 本文介绍了对于SemEval-2023的任务9，提出了一种基于transformer的系统，使用了集成学习，在多语言推特亲密度检测中排名第4，达到了0.5688的宏平均F1分数。为了提高对未见语言的性能表现，每个推特都进行了英文翻译的补充。 |
| [^59] | [Decoder-Only or Encoder-Decoder? Interpreting Language Model as a Regularized Encoder-Decoder.](http://arxiv.org/abs/2304.04052) | 该论文通过对正则化编码器-解码器结构进行比较，分析了仅解码器语言模型框架和编码器-解码器框架的效果。 |
| [^60] | [Generating a Graph Colouring Heuristic with Deep Q-Learning and Graph Neural Networks.](http://arxiv.org/abs/2304.04051) | 本文通过使用深度 Q-Learning 和图神经网络生成 ReLCol 启发式算法，解决了图着色问题，且相较于现有算法具有竞争性和优越性能。强化学习是探究图着色问题更有前途的一种方法。 |
| [^61] | [Deep Generative Modeling with Backward Stochastic Differential Equations.](http://arxiv.org/abs/2304.04049) | 该文提出了一种新的深度生成模型，名为BSDE-Gen，它将反向随机微分方程的灵活性与深度神经网络的强大能力结合，用于生成高维复杂目标数据，特别是在图像生成领域。BSDE-Gen的生成建模过程中引入了随机性和不确定性，是一种有效而自然的生成高维数据的方法。 |
| [^62] | [Polygonizer: An auto-regressive building delineator.](http://arxiv.org/abs/2304.04048) | 一种新的图像自回归模型，可以直接进行形状推断，并且可以直接用于基于矢量的工作流，该模型在地理空间规划中的矢量化表现中领先于先前的方法。 |
| [^63] | [Deep Anti-Regularized Ensembles provide reliable out-of-distribution uncertainty quantification.](http://arxiv.org/abs/2304.04042) | 本文提出一种基于反正则化的深度集成方法，适用于高维回归和分类中不确定性量化问题。实验证明该方法在内部和外部不确定性估计方面具有优越性。 |
| [^64] | [RescueSNN: Enabling Reliable Executions on Spiking Neural Network Accelerators under Permanent Faults.](http://arxiv.org/abs/2304.04041) | RescueSNN是一种用于减轻SNN芯片计算引擎中永久故障的方法，可维持性能和质量并减少重新训练成本。 |
| [^65] | [EnforceSNN: Enabling Resilient and Energy-Efficient Spiking Neural Network Inference considering Approximate DRAMs for Embedded Systems.](http://arxiv.org/abs/2304.04039) | EnforceSNN 提出了一个新的设计框架，在嵌入式系统中考虑近似DRAM，使用量化权重降低DRAM的访问能量，实现了弹性和节能的SNN推理。 |
| [^66] | [Exploring the Connection between Robust and Generative Models.](http://arxiv.org/abs/2304.04033) | 本文探究鲁棒性判别分类器与生成模型之间的联系，并发现在输入空间中，非定向对抗点非常可能在鉴别性模型中隐含的生成模型中拥有低能量，提出了一种名为高能量PGD的新攻击。 |
| [^67] | [NeBLa: Neural Beer-Lambert for 3D Reconstruction of Oral Structures from Panoramic Radiographs.](http://arxiv.org/abs/2304.04027) | 该论文提出了一个新的框架：NeBLa，可以从全景放射线图中通过神经啤酒-兰伯特法重建精确的3D口腔结构模型。 |
| [^68] | [A Reinforcement Learning-assisted Genetic Programming Algorithm for Team Formation Problem Considering Person-Job Matching.](http://arxiv.org/abs/2304.04022) | 研究提出了一种强化学习辅助遗传规划算法来解决考虑人-工匹配的团队组建问题，采用集合种群策略和代理模型加快算法学习过程，实现勘探和利用的平衡。 |
| [^69] | [Arithmetic Intensity Balancing Convolution for Hardware-aware Efficient Block Design.](http://arxiv.org/abs/2304.04016) | 本文提出的算术强度平衡卷积（ABConv）可以在不牺牲准确性的情况下，显著降低延迟，并增强硬件性能，该方法已在Arm Ethos-U65 NPU上得到验证，可用于替换一些MobileNetV1和ResNet50的任务。 |
| [^70] | [A new transformation for embedded convolutional neural network approach toward real-time servo motor overload fault-detection.](http://arxiv.org/abs/2304.04005) | 本论文提出了一种新的嵌入式卷积神经网络方法，用于实时检测直流伺服电机的过载故障，该方法可以提取尽可能多的特征并在低内存微控制器中实现有效的检测。 |
| [^71] | [SimbaML: Connecting Mechanistic Models and Machine Learning with Augmented Data.](http://arxiv.org/abs/2304.04000) | SimbaML是一个机器学习工具，它通过机械模型补充真实世界的数据集，实现了从合成到真实数据的转移学习、数据增强、物理启发式机器学习方法的基准测试等多项功能。 |
| [^72] | [REDf: A Renewable Energy Demand Forecasting Model for Smart Grids using Long Short Term Memory Network.](http://arxiv.org/abs/2304.03997) | 本文提出了一种基于长短期记忆网络的智能电网可再生能源需求预测模型REDf，可以提供准确的能量需求预测，改善可再生能源的集成，实验结果表明其准确度优于其他模型。 |
| [^73] | [A Unified Characterization of Private Learnability via Graph Theory.](http://arxiv.org/abs/2304.03996) | 本文提供了一个统一的框架，使用图论的语言刻画了差分隐私的两种情形下，纯粹和近似的学习性。我们通过定义矛盾图$G$来捕捉 $\mathcal{H}$ 的组合结构，发现分数团数和团数是描述差分隐私学习性的重要因素，并提出了几种算法对其进行估计。 |
| [^74] | [Discovering Attention-Based Genetic Algorithms via Meta-Black-Box Optimization.](http://arxiv.org/abs/2304.03995) | 本文提出了一种全新的数据驱动方法，通过元黑盒优化发现基于注意力的遗传算法。该算法在多个优化任务上表现出色，通常选择少量高度适应的变体，并通过学习的注意机制来适应其搜索策略。 |
| [^75] | [Block-regularized 5$\times$2 Cross-validated McNemar's Test for Comparing Two Classification Algorithms.](http://arxiv.org/abs/2304.03990) | 本论文提出了一种块正则化5×2交叉验证McNemar检验，该方法通过规范化训练集之间的重叠记录来产生高质量的误差率估计，相较于传统的留置方法有更高的功率和稳定性。 |
| [^76] | [DiscoVars: A New Data Analysis Perspective -- Application in Variable Selection for Clustering.](http://arxiv.org/abs/2304.03983) | DiscoVars是一种新的变量选择方法，它通过创建变量之间的依赖网络并根据图中心性度量排名它们来确定变量的重要性，适用于聚类等学习任务。 |
| [^77] | [Uncertainty-inspired Open Set Learning for Retinal Anomaly Identification.](http://arxiv.org/abs/2304.03981) | 提出了基于不确定性的开放集(UIOS)模型，用于处理训练中未见过的类别样本，该模型通过计算不确定性得分来表达其置信度，并在多个测试数据集中表现优异，为真实世界的视网膜异常筛查提供了一个强大的方法。 |
| [^78] | [RobCaps: Evaluating the Robustness of Capsule Networks against Affine Transformations and Adversarial Attacks.](http://arxiv.org/abs/2304.03973) | 本文评估了CapsNet在仿射变换和对抗性攻击方面的鲁棒性。在MNIST，GTSRB和CIFAR10数据集上的测试结果显示，与传统CNN相比，CapsNet实现了更好的对抗示例和仿射变换鲁棒性。 |
| [^79] | [Pump It Up: Predict Water Pump Status using Attentive Tabular Learning.](http://arxiv.org/abs/2304.03969) | 本文利用TabNet模型，结合基于树的算法和神经网络的优势，预测了坦桑尼亚水泵的维修状态，并通过比较表明TabNet在训练不平衡数据时性能更好。 |
| [^80] | [Benchmarking the Robustness of Quantized Models.](http://arxiv.org/abs/2304.03968) | 量化模型在受到各种噪声的影响时表现出脆弱性，较低位的量化对抗攻击更具弹性，但更容易受到自然扰动和系统噪声的影响。 |
| [^81] | [Robust Deep Learning Models Against Semantic-Preserving Adversarial Attack.](http://arxiv.org/abs/2304.03955) | 该论文提出了一种新的攻击机制，SPA攻击，用于研究深度学习模型对联合干扰的鲁棒性，并可用于增强对抗训练。实验结果表明，SPA攻击比其他方法更加具有挑战性。 |
| [^82] | [FlexMoE: Scaling Large-scale Sparse Pre-trained Model Training via Dynamic Device Placement.](http://arxiv.org/abs/2304.03946) | 本文提出了一个名为FlexMoE的DNN训练框架，通过动态数据流系统性、透明地解决动态数据流带来的低效问题，提高了稀疏门控专家混合的训练效率。 |
| [^83] | [Knowledge Relation Rank Enhanced Heterogeneous Learning Interaction Modeling for Neural Graph Forgetting Knowledge Tracing.](http://arxiv.org/abs/2304.03945) | 提出了一种新的知识追踪模型NGFKT，通过校准技能关系矩阵和Q矩阵降低主观标记的影响，并引入知识关系排序机制来模拟不同关系的重要性，应用图卷积网络建模不同类型节点之间的异构交互，能够更好地进行复杂、动态的知识追踪。 |
| [^84] | [Towards Realistic Ultrasound Fetal Brain Imaging Synthesis.](http://arxiv.org/abs/2304.03941) | 本文使用GAN合成胎儿脑部超声图像，解决了数据稀缺性问题，并证明了GAN-based方法可以生成稳定、逼真的超声图像，为医学AI和ML方法提供了可靠的数据集。 |
| [^85] | [Unsupervised Speech Representation Pooling Using Vector Quantization.](http://arxiv.org/abs/2304.03940) | 该论文提出了一种新颖的无监督语音表示池化方法，通过矢量量化压缩声学上相似的表示，不需要额外的训练，并在多个下游任务上进行了评估和分析。 |
| [^86] | [Last-Layer Fairness Fine-tuning is Simple and Effective for Neural Networks.](http://arxiv.org/abs/2304.03935) | 本文提出了一种新颖的公平性微调神经网络的框架，利用已预训练的神经网络和不关注公平性的损失微调神经网络的最后一层。实验证明该方法在基准数据集上实现了高水平的公平性，同时保留标准性能指标。 |
| [^87] | [Efficient Multimodal Sampling via Tempered Distribution Flow.](http://arxiv.org/abs/2304.03933) | 采样高维分布是一个基本的问题，现有的基于输运的采样方法存在局限性，TemperFlow通过自适应地学习温度分布，解决了多模态问题，并证明了优于其他方法。 |
| [^88] | [3D GANs and Latent Space: A comprehensive survey.](http://arxiv.org/abs/2304.03932) | 3D GAN是生成三维重建、点云重建和3D语义场景完成的新型生成模型。选择噪声分布对应着潜空间，理解其结构有助于微调生成样本。该论文综述了3D GAN及其训练方法，针对未来研究提出了潜在方向。 |
| [^89] | [Mitigating Spurious Correlations in Multi-modal Models during Fine-tuning.](http://arxiv.org/abs/2304.03916) | 本文提出了一种使用多模态对比损失函数的方法，通过在微调期间检测和明确区分受影响类别的错误属性，缓解多模态模型的错误相关性，同时提高模型精度和指向目标领域的有意义特征。 |
| [^90] | [Stochastic Nonlinear Control via Finite-dimensional Spectral Dynamic Embedding.](http://arxiv.org/abs/2304.03907) | 本文提出了一种基于有限维特征逼近的非线性动态谱嵌入控制算法（SDEC）用于解决随机非线性系统的最优控制问题，并对其进行了理论分析和实验测试。 |
| [^91] | [InstructBio: A Large-scale Semi-supervised Learning Paradigm for Biochemical Problems.](http://arxiv.org/abs/2304.03906) | InstructBio是一种针对生物化学问题的大规模半监督学习算法，引入教练模型提供有效的置信度比率来指导目标模型对不同数据点给予明显关注，避免依赖有限的标记数据和不正确的伪注释，提高了分子模型的泛化能力。 |
| [^92] | [A multifidelity approach to continual learning for physical systems.](http://arxiv.org/abs/2304.03894) | 这篇论文介绍了一种基于多保真深度神经网络的新型持续学习方法，能限制灾难性遗忘，特别适用于满足相同物理定律或具备物理学先验知识的神经网络等物理问题。 |
| [^93] | [Towards Automated Urban Planning: When Generative and ChatGPT-like AI Meets Urban Planning.](http://arxiv.org/abs/2304.03892) | 本文探讨了城市规划与人工智能的交叉应用，重点是自动化用地配置，通过对抗学习、生成神经网络、深度编码器-解码器网络、对话式 AI 和地理空间和时间机器学习等技术，AI 可以为现代城市规划带来不少创新与贡献。 |
| [^94] | [DiffDock-PP: Rigid Protein-Protein Docking with Diffusion Models.](http://arxiv.org/abs/2304.03889) | 本文提出了一种扩散生成模型DiffDock-PP用于刚性蛋白质-蛋白质对接，其在DIPS任务中取得了最先进的性能，同时比所有基于搜索的方法更快，为其预测生成了可靠的置信度估计。 |
| [^95] | [GPT4Rec: A Generative Framework for Personalized Recommendation and User Interests Interpretation.](http://arxiv.org/abs/2304.03879) | GPT4Rec是一个生成式框架，用于个性化推荐和用户兴趣解释，它通过生成“搜索查询”来充分利用物品内容信息和语言建模能力，并使用层次潜在变量模型来提高个性化推荐的相关性和多样性。 |
| [^96] | [OFTER: An Online Pipeline for Time Series Forecasting.](http://arxiv.org/abs/2304.03877) | 本文介绍了OFTER，一种专门针对中等规模多种时间序列的在线预测管线，能够胜过几种最先进的基准方法。OFTER是金融多元时间序列问题的理想解决方案。 |
| [^97] | [ASPEST: Bridging the Gap Between Active Learning and Selective Prediction.](http://arxiv.org/abs/2304.03870) | 本文提出了一种新的学习范式——主动选择性预测（ASPEST），它可以在转移目标领域中学习查询更多有信息的样本，从而实现减少人工标注工作的同时增加准确性和覆盖率。 |
| [^98] | [Conservative objective models are a special kind of contrastive divergence-based energy model.](http://arxiv.org/abs/2304.03866) | 本文证明了在离线基于模型的优化中，保守的客观模型（COMs）是一种特殊的基于对比散度能量模型，同时提出了用Langevin MCMC采样器替换梯度上升采样器，以提高样本质量。 |
| [^99] | [SGDP: A Stream-Graph Neural Network Based Data Prefetcher.](http://arxiv.org/abs/2304.03864) | SGDP是一种新型基于流图神经网络的数据预取器，通过建模LBA增量流并使用图神经网络提取混合特征来进行数据预取，实验结果表明它优于其他方法。 |
| [^100] | [Revisiting Deep Learning for Variable Type Recovery.](http://arxiv.org/abs/2304.03854) | 该论文讨论了使用机器学习技术预测反编译代码中变量名称和类型的语义信息，其中提到基于Transformer的编码器-解码器架构DIRTY能够有效地提高名称和类型提取的准确性。 |
| [^101] | [StepMix: A Python Package for Pseudo-Likelihood Estimation of Generalized Mixture Models with External Variables.](http://arxiv.org/abs/2304.03853) | StepMix是一个用于外部变量广义混合模型的伪似然估计的Python包，提供了单步和逐步估计方法，帮助从业人员进行模型估计、选择和解释。 |
| [^102] | [Why think step-by-step? Reasoning emerges from the locality of experience.](http://arxiv.org/abs/2304.03843) | 本文通过语言模型研究何时以及为什么推理是有帮助的，测试推理在训练数据由相互影响强烈的局部变量集群组成时是否有效。通过一步步的推理，能够将准确的局部推理链接在一起，以估算在训练中没有同时观察到的变量之间的关系。 |
| [^103] | [Improving Identity-Robustness for Face Models.](http://arxiv.org/abs/2304.03838) | 该论文探讨了在没有身份注释信息的情况下，使用人脸识别嵌入向量作为身份标识的替代方法，以提高人脸模型的身份鲁棒性和公平性。 |
| [^104] | [Bridging Action Space Mismatch in Learning from Demonstrations.](http://arxiv.org/abs/2304.03833) | 本文提出了一种解决学习演示中行为空间不匹配问题的框架，可以通过其他形态有显着不同的代理的演示进行训练，并且可以从次优演示中学习。 |
| [^105] | [Towards Generating Functionally Correct Code Edits from Natural Language Issue Descriptions.](http://arxiv.org/abs/2304.03816) | 本文提出了 NL2Fix 问题，即将代码更改的自然语言描述翻译成正确的代码修复。为此，我们介绍了 Defects4J-NL2Fix，这是一个由 283 个 Java 程序组成的流行 Defects4J 数据集。 |
| [^106] | [Privacy-Preserving CNN Training with Transfer Learning.](http://arxiv.org/abs/2304.03807) | 本文提出了一种使用迁移学习实现同态加密技术下隐私保护的CNN训练的方案，通过转换思想和更快的梯度变体，取得了最先进的性能。 |
| [^107] | [Correcting Model Misspecification via Generative Adversarial Networks.](http://arxiv.org/abs/2304.03805) | 本文提出了一种新的ABC-GAN范式，通过ABC合并任何可用的主观知识来协助GAN，消除了模型中似然性错误规范的需求，从而产生了一个在低数据量情况下运行良好的模型。 |
| [^108] | [ChiroDiff: Modelling chirographic data with Diffusion Models.](http://arxiv.org/abs/2304.03785) | 本论文介绍了一种名为"ChiroDiff"的模型类，该模型利用Denoising Diffusion Probabilistic Models（DDPMs）解决了手写数据建模过程中存在的问题，能够学习捕捉整体概念，在更高的时间采样率下保持弹性，并具有许多下游实用程序。 |
| [^109] | [Generative AI for learning: Investigating the potential of synthetic learning videos.](http://arxiv.org/abs/2304.03784) | 本研究探讨了使用生成AI合成视频来创建在线教育内容的效用，使用混合方法和成年学习者进行实验。结果显示，合成学习视频对学习内容获取和学习体验有着积极的影响。 |
| [^110] | [AutoQNN: An End-to-End Framework for Automatically Quantizing Neural Networks.](http://arxiv.org/abs/2304.03782) | AutoQNN是一种可自动量化DNN模型的端到端框架，利用三种技术实现了对适合不同层次的混合精度策略的搜索，并可有效提高效率和准确性。 |
| [^111] | [A roadmap to fair and trustworthy prediction model validation in healthcare.](http://arxiv.org/abs/2304.03779) | 针对医疗保健中预测模型的验证问题，建议使用来自目标人群的新数据进行外部验证，确保验证性能对模型可靠性的影响，并且在模型开发期间认真研究模型在更广泛环境中的拓展性。我们提出了一份路线图，以便在医疗保健中开发和应用可靠、公平、可信的人工智能模型。 |
| [^112] | [Conformal Regression in Calorie Prediction for Team Jumbo-Visma.](http://arxiv.org/abs/2304.03778) | 本文提出一种新的符合性回归方法，通过预测动力和速度来为自行车比赛中的每个骑手提供卡路里需求的估计。 |
| [^113] | [Biological Sequence Kernels with Guaranteed Flexibility.](http://arxiv.org/abs/2304.03775) | 本文研究了生物序列核的数学挑战，探讨了生物序列空间结构和生物序列相似性的特殊性对于核的影响。 |
| [^114] | [Motion Capture Benchmark of Real Industrial Tasks and Traditional Crafts for Human Movement Analysis.](http://arxiv.org/abs/2304.03771) | 本文提供了使用惯性动作捕捉技术记录的工业操作员和手艺人员真实工作中的专业动作的七个数据集，可用于人体运动建模、分析和生成的研究。同时，本文提供了Gesture Operational Model作为方法的初步基准测试。 |
| [^115] | [Anomalous Sound Detection using Audio Representation with Machine ID based Contrastive Learning Pretraining.](http://arxiv.org/abs/2304.03588) | 本文提出了一种使用基于机器ID的对比学习预训练的音频表示来进行异常声音检测的方法，在DCASE 2020 Challenge Task2 数据集上表现优于目前最先进的基于对比学习或自监督分类的方法。 |
| [^116] | [Rethinking GNN-based Entity Alignment on Heterogeneous Knowledge Graphs: New Datasets and A New Method.](http://arxiv.org/abs/2304.03468) | 文章重新考虑了基于GNN的异构知识图谱实体对齐。为探究EA实际场景中的表现，提出了更接近现实的高度异构知识图谱数据集，并提出了新方法。 |
| [^117] | [Comparing NARS and Reinforcement Learning: An Analysis of ONA and $Q$-Learning Algorithms.](http://arxiv.org/abs/2304.03291) | 本文比较了NARS和强化学习在解决序列任务方面的性能，发现NARS在各种环境中都有较好的表现，尤其是在非确定性环境中。 |
| [^118] | [Robust Neural Architecture Search.](http://arxiv.org/abs/2304.02845) | 提出了一种名为RNAS的神经架构搜索方法，通过平衡准确性和鲁棒性生成高质量架构，使用噪声样本减少搜索成本，在图像分类和对抗攻击中均达到最先进性能水平。 |
| [^119] | [JPEG Compressed Images Can Bypass Protections Against AI Editing.](http://arxiv.org/abs/2304.02234) | 该论文指出微小但有效的图像扰动方法并不能抵御JPEG压缩，因此不能有效保护图像免受恶意编辑和深度伪造攻击，建议采用其他方法进行保护。 |
| [^120] | [On the universal approximation property of radial basis function neural networks.](http://arxiv.org/abs/2304.02220) | 本论文研究了一种新的径向基函数神经网络类别，证明这些网络能够逼近任何连续多元函数，还讨论了有限个固定中心的RBF网络的逼近条件。 |
| [^121] | [EduceLab-Scrolls: Verifiable Recovery of Text from Herculaneum Papyri using X-ray CT.](http://arxiv.org/abs/2304.02084) | 该论文介绍了使用X射线CT图像揭示赫库兰尼姆纸草卷隐藏文本的软件管道和数据集。他们运用了机器学习和几何框架的方法检测“不可见”的碳墨，达到了人类专家标记者难以达到的效果。 |
| [^122] | [Selective Knowledge Sharing for Privacy-Preserving Federated Distillation without A Good Teacher.](http://arxiv.org/abs/2304.01731) | 本文提出了有选择的联邦蒸馏机制Selective-FD，可以精确地识别来自本地和集合预测的知识，以解决局部数据分布的变异和缺乏好的教师模型而导致的误导和模糊的知识共享问题，并取得了显著提高的模型性能和准确度。 |
| [^123] | [EPVT: Environment-aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition.](http://arxiv.org/abs/2304.01508) | EPVT是一种基于环境感知的提示视觉Transformer，用于解决皮肤病变识别中深度神经网络可能过度依赖疾病不相关图像特征的问题，通过嵌入一组领域提示和一个共享提示来进行领域一般化，并且引入了领域提示生成器促进知识共享。 |
| [^124] | [TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings.](http://arxiv.org/abs/2304.01433) | TPU v4是一款支持嵌入式硬件的可重构光学超级计算机，采用光学电路交换机重新配置互连拓扑，提高规模、可用性、利用率、模块化、部署、安全、功率和性能，它通过SparseCores加速嵌入式模型，性能优越，功耗低。 |
| [^125] | [DeepAccident: A Motion and Accident Prediction Benchmark for V2X Autonomous Driving.](http://arxiv.org/abs/2304.01168) | 本文提出了一个大规模的 DeepAccident 数据集，其中包含各种真实世界驾驶中发生的事故场景，并提出了一个端到端的运动和事故预测任务，该任务可用于直接评估自动驾驶算法的事故预测能力。 |
| [^126] | [Coincidental Generation.](http://arxiv.org/abs/2304.01108) | 生成式人工智能的一种新隐私担忧：偶然生成，可能误导法律和监管机构，暴露个人肖像的法律和监管风险。 |
| [^127] | [RePAST: Relative Pose Attention Scene Representation Transformer.](http://arxiv.org/abs/2304.00947) | RePAST是一种相对位姿注意力场景表示变换器，其将成对的相对相机姿态信息直接注入转换器的注意机制中，不需要固定参考帧，同时保留了原始方法的全部功能，加入这种不变性并不会导致质量下降，可以应用于大规模场景。 |
| [^128] | [Discovering and Explaining the Non-Causality of Deep Learning in SAR ATR.](http://arxiv.org/abs/2304.00668) | 本文通过量化不同区域对目标识别的贡献和解释数据偏差和模型偏差对非因果性的影响，提供了改善深度学习在SAR ATR中鲁棒性和泛化能力的重要见解。 |
| [^129] | [Constructive Assimilation: Boosting Contrastive Learning Performance through View Generation Strategies.](http://arxiv.org/abs/2304.00601) | 本文提出了一种建构性同化方法，结合生成视图和专家转换，提高了对比学习技术在三个数据集上的性能。 |
| [^130] | [Recover Triggered States: Protect Model Against Backdoor Attack in Reinforcement Learning.](http://arxiv.org/abs/2304.00252) | 本文提出了恢复触发状态(RTS)方法，用于保护RL代理免受反向攻击。该方法涉及构建替代网络来近似动态模型，并将触发状态恢复为干净状态来防止攻击者通过触发器激活隐藏在代理中的后门。 |
| [^131] | [Implementation and (Inverse Modified) Error Analysis for implicitly-templated ODE-nets.](http://arxiv.org/abs/2303.17824) | 本文重点研究使用隐式数值初值问题求解器模板的ODE-nets。使用展开的隐式方案对ODE-nets进行训练可以返回一个接近于反转修正微分方程(IMDE)的近似值，并且我们可以使用自适应算法加速训练并保持精度。 |
| [^132] | [HARFLOW3D: A Latency-Oriented 3D-CNN Accelerator Toolflow for HAR on FPGA Devices.](http://arxiv.org/abs/2303.17218) | 本研究提出了一种面向FPGA设备的基于延迟的3D-CNN加速器工具链HARFLOW3D，它以机器学习模型和FPGA的特性描述为输入，生成最小化计算延迟的设计。实验证明HARFLOW3D相比其他方案能够实现更低的延迟。 |
| [^133] | [Training Language Models with Language Feedback at Scale.](http://arxiv.org/abs/2303.16755) | 本文提出一种新方法，即利用更丰富的语言反馈进行模仿学习，通过三个迭代步骤对语言模型进行训练以生成更符合人类偏好的输出。 |
| [^134] | [Edge Selection and Clustering for Federated Learning in Optical Inter-LEO Satellite Constellation.](http://arxiv.org/abs/2303.16071) | FedLEO是一种在超密集LEO卫星星座上进行联合学习的方法，其在LEO上进行视频/数据传输和聚类，而低时延的地面网关服务器 (GS) 仅负责初始信号控制。随着LEO服务器的变化和重新聚类，FedLEO能够适应动态LEO星座并在不同的LEO星座设置下实现高效的学习性能。 |
| [^135] | [TabRet: Pre-training Transformer-based Tabular Models for Unseen Columns.](http://arxiv.org/abs/2303.15747) | 提出了一种可预训练的Transformer-based表格模型：TabRet，能够支持未知列，并在医疗保健分类任务上表现优秀。重新标记化和随机洗牌增强对性能提升有贡献。 |
| [^136] | [From Single-Hospital to Multi-Centre Applications: Enhancing the Generalisability of Deep Learning Models for Adverse Event Prediction in the ICU.](http://arxiv.org/abs/2303.15354) | 本研究通过使用多个数据源和在训练中明确优化泛化性能，提高了深度学习模型在新医院中预测ICU患者不良事件的性能和可靠性。 |
| [^137] | [Did You Train on My Dataset? Towards Public Dataset Protection with Clean-Label Backdoor Watermarking.](http://arxiv.org/abs/2303.11470) | 提出了一种基于背门数字水印的方法，以确保公共数据的安全。通过在数据集中插入极少量的数字水印样本，隐式学习一个隐藏的函数作为数字水印，以跟踪非法使用此数据集的模型。使用“清洁标签背门”方法实现了数字水印，不会破坏原始数据集。实验证明，该方法有效地检测到非法利用数据集的行为。 |
| [^138] | [Physics-Informed Optical Kernel Regression Using Complex-valued Neural Fields.](http://arxiv.org/abs/2303.08435) | 本文提出了一种新的基于机器学习的光刻模型范式，通过优化复值神经场执行光学核回归并将光刻系统拆解为非参数掩模操作和包含行列式源、瞳孔和光刻信息的学习光学核，使用小规模训练数据集展示了卓越的推广能力。 |
| [^139] | [Predicting Density of States via Multi-modal Transformer.](http://arxiv.org/abs/2303.07000) | 本文基于多模态Transformer，从晶体结构和能量入手预测DOS，可应用于声子和电子DOS。 |
| [^140] | [Phase Diagram of Initial Condensation for Two-layer Neural Networks.](http://arxiv.org/abs/2303.06561) | 本文提出了一个两层神经网络初始凝聚的相图，旨在提供对神经网络动力学区域及其与初始化相关的超参数选择的综合理解。同时，我们详细解释了小初始化导致在初始训练阶段出现凝聚的基本机制。 |
| [^141] | [Hardware Acceleration of Neural Graphics.](http://arxiv.org/abs/2303.05735) | 本文研究了神经图形是否需要硬件支持，发现当前GPU性能无法满足对4K分辨率60FPS渲染的需求，且在增强现实/虚拟现实应用中性能缺口更大。作者确定输入编码和MLP内核是性能瓶颈。 |
| [^142] | [Inference on Optimal Dynamic Policies via Softmax Approximation.](http://arxiv.org/abs/2303.04416) | 本文提出了一种简单的softmax逼近方法，可用于从离线数据中估计最优的动态治疗方案并对其进行有效推断。 |
| [^143] | [Multi-modal Multi-kernel Graph Learning for Autism Prediction and Biomarker Discovery.](http://arxiv.org/abs/2303.03388) | 本文提出了一种名为MMKGL的新方法，能够解决多模态集成中各模态之间的负面影响，并从多个图中提取异质信息，以进行自闭症的预测和生物标志物的发现。 |
| [^144] | [Learning machines for health and beyond.](http://arxiv.org/abs/2303.01513) | 适用于建立预测模型的机器学习技术在医疗领域和其他领域具有广泛应用。模型的维护和监控很关键，因为模型的性能与数据的变化和传输有关。 |
| [^145] | [Direct Estimation of Parameters in ODE Models Using WENDy: Weak-form Estimation of Nonlinear Dynamics.](http://arxiv.org/abs/2302.13271) | 该论文提出了一种无需任何数值微分方程求解器的弱形式估计非线性动力学（WENDy）方法，用于估计非线性ODE系统的模型参数。该方法精度高、鲁棒性强、速度快。 |
| [^146] | [The ADMM-PINNs Algorithmic Framework for Nonsmooth PDE-Constrained Optimization: A Deep Learning Approach.](http://arxiv.org/abs/2302.08309) | 本论文提出了采用ADMM-PINNs算法框架解决非光滑PDE约束优化问题的方法，在迭代中采用ADMM将PDE约束和非光滑正则化项分离，使得可以高效地解决 PDE-constrained optimization problems。 |
| [^147] | [Experimenting with Emerging RISC-V Systems for Decentralised Machine Learning.](http://arxiv.org/abs/2302.07946) | 该研究介绍了一种特定领域语言，用于将分散式机器学习方案映射到FastFlow并行编程库。通过在不同处理器平台上生成不同的DML方案，研究者评估了所提出方案和系统的性能和能源效率，并成功移植了PyTorch框架到RISC-V平台。 |
| [^148] | [A Federated Learning Benchmark for Drug-Target Interaction.](http://arxiv.org/abs/2302.07684) | 本文提出在DTI领域中采用联邦学习来汇集制药数据，相对于最佳非隐私保护替代方法可获得高达15%的性能提升，且非IID数据分布不会降低联邦学习的性能。 |
| [^149] | [Knowledge from Large-Scale Protein Contact Prediction Models Can Be Transferred to the Data-Scarce RNA Contact Prediction Task.](http://arxiv.org/abs/2302.06120) | 本文发现基于蛋白质共进化的Transformer深度神经网络学习的知识可以转移到RNA接触预测任务中，显著提高数据稀缺的RNA接触预测的准确性。 |
| [^150] | [Double Permutation Equivariance for Knowledge Graph Completion.](http://arxiv.org/abs/2302.01313) | 本研究提出了双排列等变性的KG表示方法，可以使神经网络在KG中执行复杂的逻辑推理任务，并在多个归纳KG完成任务中实现了最先进的Hits@10测试准确率。双排列等变性在KG中开辟了新的研究方向。 |
| [^151] | [Predicting the Silent Majority on Graphs: Knowledge Transferable Graph Neural Network.](http://arxiv.org/abs/2302.00873) | 本文提出了一种新颖的知识可迁移模块和适应性学习机制，通过将有声节点的知识转移给无声节点，实现了针对含有“沉默大多数”的图表的抗差建模。实验证明，该方法在各种真实世界数据集上都具有有效性和优越性。 |
| [^152] | [Solving High-Dimensional PDEs with Latent Spectral Models.](http://arxiv.org/abs/2301.12664) | 本文提出一种基于隐变量谱模型的高维PDEs高效精确求解器，它使用基于注意力的分层投影网络将高维数据在线性时间内缩小到一个紧凑的潜空间，并利用谱方法在潜空间中学习算子解决维度诅咒。效果和可扩展性在Navier-Stokes和Schrödinger方程中得到验证。 |
| [^153] | [The Best of Both Worlds: Accurate Global and Personalized Models through Federated Learning with Data-Free Hyper-Knowledge Distillation.](http://arxiv.org/abs/2301.08968) | 该论文介绍了一种名为FedHKD的联邦学习算法，利用知识蒸馏实现无数据超知识蒸馏，解决了异构数据导致的全局和个性化模型准确性问题，在多个基准数据集上实验表明优于现有FL方法和中心化训练方式下的模型。 |
| [^154] | [Concept Discovery for Fast Adapatation.](http://arxiv.org/abs/2301.07850) | 本论文提出了一个基于概念发现的模型不可知元学习方法（COMAML），通过元学习数据特征之间的结构，实现更有效的适应。 |
| [^155] | [A Comprehensive Review of Data-Driven Co-Speech Gesture Generation.](http://arxiv.org/abs/2301.05339) | 该论文综述了共语手势的生成研究，重点在深度生成模型上。共语手势是自然通信的一部分，对于电影和游戏等领域具有广泛的应用。随着越来越大的手势数据集和深度学习生成模型的进步，该领域有着广阔的研究前景。 |
| [^156] | [Pix2Map: Cross-modal Retrieval for Inferring Street Maps from Images.](http://arxiv.org/abs/2301.04224) | 本论文提出了一种名为Pix2Map的跨模态检索方法，可以从自我视角图像中推断城市街道地图的拓扑结构，并可以用于更新或扩展现有地图。使用Argoverse数据集进行实验，证明了这种方法的可行性。 |
| [^157] | [Continual Causal Effect Estimation: Challenges and Opportunities.](http://arxiv.org/abs/2301.01026) | 本文介绍了因果效应估计中的挑战与机会，现有方法主要集中在源特定和静态观测数据上，实际问题在于观测数据只能逐步获得，本文提出了一种连续因果效应估计方法。 |
| [^158] | [On the Interpretability of Attention Networks.](http://arxiv.org/abs/2212.14776) | 本文研究注意力网络的可解释性，提出了选择依赖分类（SDC）变体分类问题，并演示了注意力模型可以准确无误但不具有可解释性的多种错误模式。该研究为评估SDC模型及其解释性提供了一种评估指标，并评估了不同架构的模型的解释性。 |
| [^159] | [Online Active Learning for Soft Sensor Development using Semi-Supervised Autoencoders.](http://arxiv.org/abs/2212.13067) | 本文介绍了一种使用半监督自编码器以及在线主动学习方法，以尽可能少的标记样本来开发软测量传感器，从而显著降低了成本。在实验中，作者表明这种方法能够取得好的预测效果。 |
| [^160] | [Bridging Graph Position Encodings for Transformers with Weighted Graph-Walking Automata.](http://arxiv.org/abs/2212.06898) | 本文提出了一种新的图PE，即基于加权图遍历自动机的图自动机PE（GAPE）。与其他PE方案相比，GAPE已证明可以推广到其他PE，并在机器翻译和图形任务中取得了良好的表现。此外，本文还对许多最近在图形Transformer中的PE进行了理论和控制实验比较。 |
| [^161] | [MobileTL: On-device Transfer Learning with Inverted Residual Blocks.](http://arxiv.org/abs/2212.03246) | 本文提出了MobileTL，一种基于内部标准化层具有内存和计算效率的移动设备上的迁移学习方法，用于构建IRBs模型。MobileTL通过训练内部规范化层的移位来避免存储向后传递的激活图，显著降低了内存使用率，并在图像识别任务中保持了竞争性的准确性。 |
| [^162] | [Vertical Federated Learning: A Structured Literature Review.](http://arxiv.org/abs/2212.00622) | 垂直联邦学习是联邦学习中的一种特殊架构，它可在不泄露隐私的情况下，通过组合本地模型训练的结果来建立完整的机器学习模型。本文是对垂直联邦学习现有研究进行了结构化综述，总结了其研究现状、应用、限制和未来方向。 |
| [^163] | [Optimal Sparse Regression Trees.](http://arxiv.org/abs/2211.14980) | 本研究提出了一种动态规划方法，通过一个新型下界，构建可证明的最优稀疏回归树，并在几秒钟内找到最优的稀疏树。 |
| [^164] | [A Theoretical Study of Inductive Biases in Contrastive Learning.](http://arxiv.org/abs/2211.14699) | 本文提供了对比学习中的归纳偏差的影响的理论分析，揭示了模型选择对学习过程的影响。 |
| [^165] | [PatchGT: Transformer over Non-trainable Clusters for Learning Graph Representations.](http://arxiv.org/abs/2211.14425) | PatchGT是一种基于非可训练聚类的Transformer图神经网络，通过将图分割为patch学习图表示，兼具GNN和Transformer的优点，可在多种图学习任务上实现最先进的性能。 |
| [^166] | [Weighted Ensemble Self-Supervised Learning.](http://arxiv.org/abs/2211.09981) | 本文提出了一种带权重集成的自监督学习方法，通过开发允许数据相关的加权交叉熵损失的框架，可以提高最近自监督学习技术的性能，而不需要改变原有的架构，其在 ImageNet-1K 数据集上的表现优于最先进的 DINO 和 MSN 方法，特别是在小样本设置中表现最佳。 |
| [^167] | [Quantum Split Neural Network Learning using Cross-Channel Pooling.](http://arxiv.org/abs/2211.06524) | 本研究提出了一种基于QSL的新方法，并引入交叉通道池化技术，实现了加速收敛、减少通讯成本和增强隐私保护的优点。 |
| [^168] | [SUPRA: Superpixel Guided Loss for Improved Multi-modal Segmentation in Endoscopy.](http://arxiv.org/abs/2211.04658) | 本文提出了一种名为SUPRA的超像素增强方法，通过使用SLICLoss与二元交叉熵损失的结合，提高了深度学习模型在内窥镜图像分析中的领域泛化能力。 |
| [^169] | [Prototypical quadruplet for few-shot class incremental learning.](http://arxiv.org/abs/2211.02947) | 本文提出了一种解决灾难性遗忘的少样本类别增量学习方法，通过更新先前会话类原型以表示真正的类平均值，在嵌入空间中保留先前已获得的知识，即使训练新类时也是如此。 |
| [^170] | [Bayesian learning of Causal Structure and Mechanisms with GFlowNets and Variational Bayes.](http://arxiv.org/abs/2211.02763) | 本文介绍了一种新的方法，使用GFlowNets和变分贝叶斯联合学习因果模型的结构和机制，不仅能够处理非线性和非高斯数据，在模拟数据上也能与几个基线方法相竞争。 |
| [^171] | [A Transformer-Based Substitute Recommendation Model Incorporating Weakly Supervised Customer Behavior Data.](http://arxiv.org/abs/2211.02533) | 本文将替代品推荐适应到语言匹配问题中，并通过设计新的转换方法去除信号噪音，并考虑了多语言支持。该模型已成功在一个大型电子商务网站上的11个市场和6种语言中部署，提高了顾客忠诚度和购买率。 |
| [^172] | [Broken Neural Scaling Laws.](http://arxiv.org/abs/2210.14891) | 本文提出了一个平滑破碎的幂律函数形式，可以准确地模拟和外推深度神经网络的缩放行为，适用于各种架构和大量不同任务，包括视觉、语言、音频、视频、生成建模、对比学习、机器人、不确定性估计/校准、对抗鲁棒性、分子、计算机编程/编码、数学单词问题、算术、无监督/自监督学习和强化学习。 |
| [^173] | [Global Convergence of SGD On Two Layer Neural Nets.](http://arxiv.org/abs/2210.11452) | 该论文证明了当深度为2的神经网络采用足够平滑凸的激活函数时，SGD可以收敛到全局最小值，证明过程中引入Frobenius范数正则化与恰当分布的参数初始化，同时拓展了连续时间的收敛结果。 |
| [^174] | [Continuous Pseudo-Labeling from the Start.](http://arxiv.org/abs/2210.08711) | 本文提出了一种从训练开始就进行伪标记的ASR方法，通过动态控制伪标签生成来减少标记数据集上的过拟合。 |
| [^175] | [Equal Improvability: A New Fairness Notion Considering the Long-term Impact.](http://arxiv.org/abs/2210.06732) | 在动态环境下，设计一个长期公平的分类器很重要。我们提出了一个新的公平性概念EI，它确保在拒绝的样本付出一定的努力进行特征改进后，不同群体的样本特征分布得到平衡，这比现有的公平性概念实现long-term fairness更好。 |
| [^176] | [Correlative Information Maximization Based Biologically Plausible Neural Networks for Correlated Source Separation.](http://arxiv.org/abs/2210.04222) | 该论文提出了一种基于生物学原理的神经网络，通过利用有关潜在源领域的信息来提取相关联的潜在源，从而极大地改善了对相关源分离的性能。 |
| [^177] | [Label Propagation with Weak Supervision.](http://arxiv.org/abs/2210.03594) | 本文提出了一种利用弱监督信息的标签传播算法，通过利用未标记数据上的概率假设标签，结合局部几何特性和先验信息的质量，提供了一个误差界，并提出了一个框架，用于合并多个噪声信息源。在多个基准弱监督分类任务上展示了方法的能力，显示出对现有半监督和弱监督方法的改进。 |
| [^178] | [Predictive Inference with Feature Conformal Prediction.](http://arxiv.org/abs/2210.00173) | 本文提出基于特征符合预测的预测推断方法，通过利用深度表示学习的归纳偏置，扩展了符合预测到语义特征空间。从理论和实验结果来看，该方法优于常规符合预测，并在大规模任务上展现了最先进性能。 |
| [^179] | [MLPInit: Embarrassingly Simple GNN Training Acceleration with MLP Initialization.](http://arxiv.org/abs/2210.00102) | 提出一种简单但有效的GNN加速训练方法 - MLPInit, 通过训练一个等效MLP（PeerMLP）, 并使用它的权重来初始化目标GNN，在不损失精度的情况下，显著提高了GNN的收敛效果和预测性能。 |
| [^180] | [Deep Double Descent via Smooth Interpolation.](http://arxiv.org/abs/2209.10080) | 本文研究神经网络在插值训练数据时的损失景观，发现其损失锐度遵循非光滑的二次曲线，当神经网络的复杂度逐渐增加时，测试误差会先降后升（即“双下降”现象）。 |
| [^181] | [TSFool: Crafting Highly-imperceptible Adversarial Time Series through Multi-objective Black-box Attack to Fool RNN Classifiers.](http://arxiv.org/abs/2209.06388) | 本文提出了一种名为TSFool的黑盒方法, 可以有效地生成针对RNN分类器的高度难以察觉的对抗性时间序列，在考虑对抗样本难以察觉性的情况下，将对抗性攻击改进为多目标优化问题来增强扰动的质量。 |
| [^182] | [Deep Generative Modeling on Limited Data with Regularization by Nontransferable Pre-trained Models.](http://arxiv.org/abs/2208.14133) | 本文提出了一种正则化深度生成模型（Reg-DGM），通过利用非可转移预训练模型来降低有限数据的生成建模方差，在极限情况下确保全局最小点的存在和唯一性。 |
| [^183] | [Semantic-Enhanced Image Clustering.](http://arxiv.org/abs/2208.09849) | 本文提出了一种命名为“语义增强的图像聚类(SIC)”的新型图像聚类方法，基于视觉-语言预训练模型CLIP指导，能够区分视觉上相似但在语义上有所不同的图像。 |
| [^184] | [A Hybrid Deep Feature-Based Deformable Image Registration Method for Pathology Images.](http://arxiv.org/abs/2208.07655) | 本文提出了一种混合的基于深度特征的病理图像可变形配准框架，使用探测器和无探测器的深度学习特征网络提取密集的特征点，并通过孤立森林统计模型和局部仿射校正模型结合的离群值检测方法进一步减少错误匹配。在ANHIR挑战数据集上，本文所提出的方法比传统方法提高了17％以上的A度量值。 |
| [^185] | [Differentiable WORLD Synthesizer-based Neural Vocoder With Application To End-To-End Audio Style Transfer.](http://arxiv.org/abs/2208.07282) | 比较不同方法在音频风格转换中的应用，提出一种可微分的WORLD合成器，并通过声学特征参数来实现音高和音色信息的分离。 |
| [^186] | [Cyclic Policy Distillation: Sample-Efficient Sim-to-Real Reinforcement Learning with Domain Randomization.](http://arxiv.org/abs/2207.14561) | 本文提出了一种称为CPD的高效的仿真到真实强化学习方法，通过将随机参数范围分为几个小的子域，并为每个子域分配一个本地策略，加快了学习速度并提高了样本效率。 |
| [^187] | [Neural Groundplans: Persistent Neural Scene Representations from a Single Image.](http://arxiv.org/abs/2207.11232) | 本文提出了一种基于单张图像的持久神经场景表示方法，使用条件神经地面计划来表示场景，能够进行视角合成、场景解耦表示和可移动组件的分离，重构可移动物体能够进行多种下游任务。 |
| [^188] | [Protecting Global Properties of Datasets with Distribution Privacy Mechanisms.](http://arxiv.org/abs/2207.08367) | 本文探讨了数据集的全局属性机密性保护问题，并应用分布隐私框架成功降低了实际属性推断攻击的效果，同时提供了高效用权衡。 |
| [^189] | [Harnessing Out-Of-Distribution Examples via Augmenting Content and Style.](http://arxiv.org/abs/2207.03162) | 本文提出一种HOOD方法，可以通过增强内容和风格来识别良性和恶性OOD数据，并在各种基准数据集上优于现有的各种方法。 |
| [^190] | [High-Dimensional Private Empirical Risk Minimization by Greedy Coordinate Descent.](http://arxiv.org/abs/2207.01560) | 本文针对高维数据中的差分隐私经验风险最小化问题，提出了一种差分隐私贪心坐标下降算法，能够通过利用模型的结构性质，在广泛的问题范围内实现对维度的对数依赖性。 |
| [^191] | [Restructuring Graph for Higher Homophily via Adaptive Spectral Clustering.](http://arxiv.org/abs/2206.02386) | 本文提出一种新颖的图重构方法，集成于任何类型的图神经网络中，以增加同质性。方法包括自适应谱聚类、密度感知同质性度量方法和基于聚类结果的邻接矩阵重构。 |
| [^192] | [Social Bias Meets Data Bias: The Impacts of Labeling and Measurement Errors on Fairness Criteria.](http://arxiv.org/abs/2206.00137) | 本文研究了机器学习算法在训练数据集存在偏见时现有公平标准的鲁棒性，探究了标记和测量误差对其影响。研究发现，一些约束可以在面对某些统计偏差时保持稳健，而另一些则会在训练偏见数据集时被显著违反。 |
| [^193] | [AVIDA: Alternating method for Visualizing and Integrating Data.](http://arxiv.org/abs/2206.00135) | AVIDA是一个可视化和整合数据的框架，它可以同时执行数据对齐和降维，并成功地对齐了高维多模态数据集，保留了每个数据集的结构，特别是联合低维可视化中的不同局部结构。 |
| [^194] | [An empirical study of the effect of background data size on the stability of SHapley Additive exPlanations (SHAP) for deep learning models.](http://arxiv.org/abs/2204.11351) | 本研究发现 SHapley Additive exPlanations (SHAP) 对于机器学习模型的解释受到背景数据集规模的影响，而选择合适的背景数据集能够确保 SHAP 解释的稳定性。 |
| [^195] | [FAIR4Cov: Fused Audio Instance and Representation for COVID-19 Detection.](http://arxiv.org/abs/2204.10581) | FAIR4Cov是一种针对COVID-19检测的方法，它提出了一种融合身体声音的波形和谱图表示的关节特征向量，可以有效地检测COVID-19患者，胜过了其他方法。 |
| [^196] | [InCoder: A Generative Model for Code Infilling and Synthesis.](http://arxiv.org/abs/2204.05999) | InCoder是一种统一的生成模型，可以进行程序合成和双向上下文的代码填充，是第一个能够直接进行零样本代码填充的生成模型。 |
| [^197] | [Structure-aware Protein Self-supervised Learning.](http://arxiv.org/abs/2204.04213) | 我们提出了一种结构感知的蛋白自监督学习方法，利用预训练的图神经网络模型保留重要的蛋白质结构信息，并结合预训练语言模型来提高下游任务性能。在两个蛋白质分类测试中均表现出了优异的结果。 |
| [^198] | [Randomized Sharpness-Aware Training for Boosting Computational Efficiency in Deep Learning.](http://arxiv.org/abs/2203.09962) | 本文提出了一种名为随机锐度感知训练（RST）的深度学习训练方法，通过在SGD和SAM之间随机选择来减少计算量，同时保证模型收敛。同时，我们对各种调度函数的效果和计算成本进行了实验研究。 |
| [^199] | [ZippyPoint: Fast Interest Point Detection, Description, and Matching through Mixed Precision Discretization.](http://arxiv.org/abs/2203.03610) | 本文提出了一种基于混合精度离散化的高效量化网络和二进制描述符——ZippyPoint，可实现在计算受限的平台上快速的兴趣点检测、描述和匹配，同时在几个标准基准测试中取得了最先进的性能表现。 |
| [^200] | [Calibration of P-values for calibration and for deviation of a subpopulation from the full population.](http://arxiv.org/abs/2202.00100) | 本文介绍了如何校准P值以及如何通过条件分析控制协变量或分数来评估子总体与全总体之间的响应差异。 |
| [^201] | [Multi-Scale Adaptive Graph Neural Network for Multivariate Time Series Forecasting.](http://arxiv.org/abs/2201.04828) | 本文提出了一个新的多尺度自适应图神经网络 (MAGNN) 模型，旨在解决传统多元时间序列预测方法中只能学习单一依赖关系的问题，通过多尺度金字塔网络和自适应图学习模块，使模型能够在不同的时间尺度下推导出尺度特定的交互变量依赖性，同时，利用注意机制有效捕获最具信息的预测模式，实验结果表明，MAGNN 对于合成数据集和现实数据集的预测效果优于现有最优方法。 |
| [^202] | [Constrained multi-objective optimization of process design parameters in settings with scarce data: an application to adhesive bonding.](http://arxiv.org/abs/2112.08760) | 本文提出了一种用于稀缺数据情况下的粘接过程设计参数多目标优化方法。通过自适应采样策略和基于代理的约束处理技术，该方法在不显式评估约束条件的情况下，在探索参数空间和平衡开发之间找到高质量的解决方案。 |
| [^203] | [Learning Generative Models of the Geometry and Topology of Tree-like 3D Objects.](http://arxiv.org/abs/2110.08693) | 本文提出了一种扩展平方根速度函数的新表示方法和度量方法，用于分析和比较树状三维物体，从而提高物体形状差异计算的精度和效率。 |
| [^204] | [Random Subgraph Detection Using Queries.](http://arxiv.org/abs/2110.00744) | 本文研究了使用自适应查询来检测种植子图存在，确定了必要和充分的查询数量。 |
| [^205] | [Genealogical Population-Based Training for Hyperparameter Optimization.](http://arxiv.org/abs/2109.14925) | 基于家族谱的种群训练（GPBT）是一种新的超参数优化方法。不同于其他算法，GPBT利用相关模型之间的共享历史以高效地利用HP和模型之间的耦合。我们的方法通过降低计算成本，提高精度并减小结果的差异，取得了成功。 |
| [^206] | [Computing Graph Descriptors on Edge Streams.](http://arxiv.org/abs/2109.01494) | 本文提出了在边流上近似计算图描述符的流式算法，能够捕捉图的基本结构，并避免整个图存储于内存中。该算法具有可扩展性，可控制的运行时间和较高的分类准确性。 |
| [^207] | [Real-time Outdoor Localization Using Radio Maps: A Deep Learning Approach.](http://arxiv.org/abs/2106.12556) | 本文提出了一种使用射频地图进行实时室外定位的深度学习方法，能够实现高精度定位并具有较高的鲁棒性，适用于实时应用，并提供了两种新的数据集用于评估。 |
| [^208] | [Fundamental limits and algorithms for sparse linear regression with sublinear sparsity.](http://arxiv.org/abs/2101.11156) | 本文通过将贝叶斯推断中线性区域的自适应插值方法推广到次线性区域，建立了稀疏线性回归的归一化互信息和最小均方误差的精确渐近表达式，并提出了一种修改近似信息传递算法以接近最小均方误差基本极限的方法。 |
| [^209] | [Gauge Invariant and Anyonic Symmetric Autoregressive Neural Networks for Quantum Lattice Models.](http://arxiv.org/abs/2101.07243) | 该论文提出了一种针对量子晶格模型的自回归神经网络，并明确遵守规范对称性或任意子约束，能够提供精确表示量子晶格模型基态和激发态的方法。 |

# 详细

[^1]: 双重不确定性自训练用于半监督医学图像分割

    Self-training with dual uncertainty for semi-supervised medical image segmentation. (arXiv:2304.04441v1 [cs.CV])

    [http://arxiv.org/abs/2304.04441](http://arxiv.org/abs/2304.04441)

    该论文介绍了在半监督医学图像分割中如何通过双重不确定性的自训练方式来提高分割精度。

    

    在半监督医学图像分割领域中，标记数据短缺是一个根本性问题。如何有效地从未标记的图像中学习图像特征以提高分割精度是这一领域的主要研究方向。传统的自训练方法可以通过为迭代训练生成伪标签部分解决标记数据不足的问题。然而，在训练过程中由模型不确定性产生的噪声直接影响了分割结果。因此，我们在自训练框架中增加了样本层面和像素层面的不确定性以稳定训练过程。具体来说，我们在预训练期间保存了模型的几个时刻，并使用它们在未标记样本上的预测之间的差异作为该样本的样本层面不确定性估计。然后，我们逐渐添加从易到难的未标记样本进行训练。同时，我们添加了一个带有不同上采样方法的解码器。

    In the field of semi-supervised medical image segmentation, the shortage of labeled data is the fundamental problem. How to effectively learn image features from unlabeled images to improve segmentation accuracy is the main research direction in this field. Traditional self-training methods can partially solve the problem of insufficient labeled data by generating pseudo labels for iterative training. However, noise generated due to the model's uncertainty during training directly affects the segmentation results. Therefore, we added sample-level and pixel-level uncertainty to stabilize the training process based on the self-training framework. Specifically, we saved several moments of the model during pre-training, and used the difference between their predictions on unlabeled samples as the sample-level uncertainty estimate for that sample. Then, we gradually add unlabeled samples from easy to hard during training. At the same time, we added a decoder with different upsampling method
    
[^2]: PCR: 基于代理的对比式回放在在线类增量连续学习中的应用

    PCR: Proxy-based Contrastive Replay for Online Class-Incremental Continual Learning. (arXiv:2304.04408v1 [cs.CV])

    [http://arxiv.org/abs/2304.04408](http://arxiv.org/abs/2304.04408)

    本文提出了一种名为PCR的基于代理的对比式回放方法，它能够有效地解决在线类增量连续学习中的历史知识遗忘问题。经实验证明，在两个视觉数据集上，PCR能够显著优于现有方法。

    

    在线类增量连续学习是连续学习中的一项特定任务。它旨在从数据流中不断学习新的类别，但数据流中的样本仅需观察一次，这容易导致历史类别的知识遗忘问题。现有的基于回放的方法通过以代理为基础或以对比为基础的回放方式有效地缓解了这一问题。尽管这两种回放方式是有效的，但前者会因类别不平衡问题而倾向于新类，后者则由于样本数量有限而不稳定且难以收敛。本文对这两种回放方式进行了全面的分析，发现它们可以互补。在此基础上，我们提出了一种新的回放-based方法，称为基于代理的对比式回放（PCR）。关键操作是将锚定点的对比样本替换为相应代理的对比样本。具体来说，设计并自适应地选择两种代理，即旧代理和新代理，以稳定训练并缓解类别不平衡问题。实验证明，PCR在两个视觉数据集上显著优于现有方法。

    Online class-incremental continual learning is a specific task of continual learning. It aims to continuously learn new classes from data stream and the samples of data stream are seen only once, which suffers from the catastrophic forgetting issue, i.e., forgetting historical knowledge of old classes. Existing replay-based methods effectively alleviate this issue by saving and replaying part of old data in a proxy-based or contrastive-based replay manner. Although these two replay manners are effective, the former would incline to new classes due to class imbalance issues, and the latter is unstable and hard to converge because of the limited number of samples. In this paper, we conduct a comprehensive analysis of these two replay manners and find that they can be complementary. Inspired by this finding, we propose a novel replay-based method called proxy-based contrastive replay (PCR). The key operation is to replace the contrastive samples of anchors with corresponding proxies in th
    
[^3]: CAVL：学习对比和自适应的视觉与语言表示

    CAVL: Learning Contrastive and Adaptive Representations of Vision and Language. (arXiv:2304.04399v1 [cs.CV])

    [http://arxiv.org/abs/2304.04399](http://arxiv.org/abs/2304.04399)

    本文提出了一种对比自适应的视觉与语言表示学习方法CAVL，在预训练过程中通过对比损失学习整个句子和图像之间的对齐，并在微调阶段引入轻量级自适应网络，实现在下游任务中的最先进效果。

    

    视觉和语言的预训练旨在一起学习视觉和语言表示，并可转移到视觉语言下游任务。然而，在预训练阶段，语言和视觉之间存在语义混淆。此外，当前的预训练模型在转移到下游任务时往往需要大量的计算资源进行微调。在本文中，我们提出了一种简单但有效的方法，用于学习对比和自适应的视觉与语言表示，即CAVL。具体而言，我们在预训练过程中引入了一对一对的对比损失，以学习整个句子和同一批次中每个图像之间的对齐。在微调阶段，我们引入了两个轻量级自适应网络，以减少模型参数并增加训练速度，以节省计算资源。我们在包括视觉问答（VQA）、视觉通识推理（VCL）和图像字幕生成等六个主要下游任务中评估了我们的CAVL。实验结果表明，CAVL在大多数任务上都取得了最先进的性能，证明了我们的方法的有效性。

    Visual and linguistic pre-training aims to learn vision and language representations together, which can be transferred to visual-linguistic downstream tasks. However, there exists semantic confusion between language and vision during the pre-training stage. Moreover, current pre-trained models tend to take lots of computation resources for fine-tuning when transferred to downstream tasks. In this work, we present a simple but effective approach for learning Contrastive and Adaptive representations of Vision and Language, namely CAVL. Specifically, we introduce a pair-wise contrastive loss to learn alignments between the whole sentence and each image in the same batch during the pre-training process. At the fine-tuning stage, we introduce two lightweight adaptation networks to reduce model parameters and increase training speed for saving computation resources. We evaluate our CAVL on six main downstream tasks, including Visual Question Answering (VQA), Visual Commonsense Reasoning (VC
    
[^4]: 针对超参数化特征维度的随机和确定性注意力稀疏化算法

    Randomized and Deterministic Attention Sparsification Algorithms for Over-parameterized Feature Dimension. (arXiv:2304.04397v1 [cs.DS])

    [http://arxiv.org/abs/2304.04397](http://arxiv.org/abs/2304.04397)

    本论文提出了随机和确定性注意力稀疏化算法，用于处理超参数化特征维度，其目标是找到适当的矩阵Y，使得其满足特定条件，从而帮助解决注意问题。

    

    大型语言模型在不同领域展示了它们的实力。作为LLMs的一个重要子例程，注意力计算也引起了理论上的兴趣。最近，[Alman and Song 2023]和[Brand，Song and Zhou 2023]从算法和困难的角度研究了注意矩阵的静态计算和动态维护。在这项工作中，我们考虑了注意问题的稀疏化。我们做了一个简化，即logit矩阵是对称的。假设$n$表示句子长度，$d$表示嵌入维度。给定一个矩阵$X \in \mathbb{R} ^{n \times d}$，假设$d \gg n$且$\| X X^\top \|_{\infty} < r$，其中$r \in (0,0.1)$，则我们旨在找到$Y \in \mathbb{R}^{n \times m}$（其中$m\ll d$）, 使得 $D(Y)^{-1} \exp(Y Y ^\top) D(X)^{-1}\exp(X X ^\top)$的$\| \_\|_{\infty}$范数$\leq O（r）$。我们为这个问题提供了两个结果。$\bullet$我们的第一个结果是一个随机算法。

    Large language models (LLMs) have shown their power in different areas. Attention computation, as an important subroutine of LLMs, has also attracted interests in theory. Recently the static computation and dynamic maintenance of attention matrix has been studied by [Alman and Song 2023] and [Brand, Song and Zhou 2023] from both algorithmic perspective and hardness perspective. In this work, we consider the sparsification of the attention problem. We make one simplification which is the logit matrix is symmetric. Let $n$ denote the length of sentence, let $d$ denote the embedding dimension. Given a matrix $X \in \mathbb{R}^{n \times d}$, suppose $d \gg n$ and $\| X X^\top \|_{\infty} < r$ with $r \in (0,0.1)$, then we aim for finding $Y \in \mathbb{R}^{n \times m}$ (where $m\ll d$) such that \begin{align*} \| D(Y)^{-1} \exp( Y Y^\top ) D(X)^{-1} \exp( X X^\top) \|_{\infty} \leq O(r) \end{align*} We provide two results for this problem.  $\bullet$ Our first result is a randomized algo
    
[^5]: CAFIN: 基于节点中心性的公平性增强进程的无监督图表示学习方法

    CAFIN: Centrality Aware Fairness inducing IN-processing for Unsupervised Representation Learning on Graphs. (arXiv:2304.04391v1 [cs.LG])

    [http://arxiv.org/abs/2304.04391](http://arxiv.org/abs/2304.04391)

    CAFIN是一种基于节点中心性的公平性增强进程技术，用于无监督学习的图表示学习方法中。实验结果表明，CAFIN在提供最优公平结果的同时，具有竞争力或更好的下游任务性能。

    

    由于所学嵌入的紧凑性和丰富性以及未标记图数据的丰富性，无监督学习的图表示在(大型)图上已经受到研究界的重视。当这些节点表示被部署时，必须使用适当的公平性约束条件生成以减少它们对下游任务造成的偏差。因此，对于特定的下游任务，已经调查了图学习算法的群体和个体公平性概念。这些公平性概念的主要局限性是没有考虑连接模式在图中导致的不同节点影响(或中心性能量)。在本文中，我们为归纳图表示学习算法设计了一个基于中心性的公平框架。我们提出了CAFIN（Centrality Aware Fairness inducing IN-processing），一种利用图结构改进GraphSAGE表示的进程技术——无监督图学习文献中的一种流行框架。对真实世界数据集的广泛实验表明，CAFIN在提供具有竞争力或更好的下游任务性能的同时，实现了最先进的公平结果。

    Unsupervised representation learning on (large) graphs has received significant attention in the research community due to the compactness and richness of the learned embeddings and the abundance of unlabelled graph data. When deployed, these node representations must be generated with appropriate fairness constraints to minimize bias induced by them on downstream tasks. Consequently, group and individual fairness notions for graph learning algorithms have been investigated for specific downstream tasks. One major limitation of these fairness notions is that they do not consider the connectivity patterns in the graph leading to varied node influence (or centrality power). In this paper, we design a centrality-aware fairness framework for inductive graph representation learning algorithms. We propose CAFIN (Centrality Aware Fairness inducing IN-processing), an in-processing technique that leverages graph structure to improve GraphSAGE's representations - a popular framework in the unsup
    
[^6]: 在潜空间中生成对抗攻击

    Generating Adversarial Attacks in the Latent Space. (arXiv:2304.04386v1 [cs.LG])

    [http://arxiv.org/abs/2304.04386](http://arxiv.org/abs/2304.04386)

    该论文提出在潜空间中使用生成对抗网络注入对抗扰动来生成对抗攻击。实验证明该方法在生成潜空间中的对抗攻击时与像素空间中基于对抗攻击的方法相比具有同等的有效性，同时保持了高度的视觉真实度。

    

    在输入空间中注入噪音来生成对抗攻击通常需要$L_1$或$L_{\infty}$范数等噪音界限。本文提出使用生成对抗网络在潜空间中注入对抗扰动，避免了基于界限的先验。在MNIST、CIFAR10、Fashion-MNIST、CIFAR100和Stanford Dogs数据集上的实验证明了该方法在生成潜空间中的对抗攻击时具有很高的视觉真实度和像素空间中基于对抗攻击的方法相比具有同等的有效性。

    Adversarial attacks in the input (pixel) space typically incorporate noise margins such as $L_1$ or $L_{\infty}$-norm to produce imperceptibly perturbed data that confound deep learning networks. Such noise margins confine the magnitude of permissible noise. In this work, we propose injecting adversarial perturbations in the latent (feature) space using a generative adversarial network, removing the need for margin-based priors. Experiments on MNIST, CIFAR10, Fashion-MNIST, CIFAR100 and Stanford Dogs datasets support the effectiveness of the proposed method in generating adversarial attacks in the latent space while ensuring a high degree of visual realism with respect to pixel-based adversarial attack methods.
    
[^7]: 关于多模态学习的鲁棒性

    On Robustness in Multimodal Learning. (arXiv:2304.04385v1 [cs.LG])

    [http://arxiv.org/abs/2304.04385](http://arxiv.org/abs/2304.04385)

    本文提出了一个多模态鲁棒性框架，分析了多种多模态学习方法的鲁棒性不足，并提出了两种干预技术，在多个数据集上实现了1.5倍至4倍的鲁棒性提高，同时在AudioSet 20K上实现了44.2 mAP的有竞争力结果。

    

    多模态学习被定义为对多种异构输入模态（如视频、音频和文本等）进行学习。本文关注了解当训练和部署之间的模态类型不同时，模型如何表现，这在许多应用多模态学习应用于硬件平台时会自然发生。我们提出了一个多模态鲁棒性框架来系统分析常见的多模态表示学习方法。此外，我们发现了这些方法的鲁棒性不足，并提出了两种干预技术，在AudioSet、Kinetics-400和ImageNet-Captions三个数据集上实现了1.5倍至4倍的鲁棒性提高。最后，我们展示了这些干预技术可以更好地利用额外的模态，在AudioSet 20K上实现了44.2 mAP的有竞争力结果。

    Multimodal learning is defined as learning over multiple heterogeneous input modalities such as video, audio, and text. In this work, we are concerned with understanding how models behave as the type of modalities differ between training and deployment, a situation that naturally arises in many applications of multimodal learning to hardware platforms. We present a multimodal robustness framework to provide a systematic analysis of common multimodal representation learning methods. Further, we identify robustness short-comings of these approaches and propose two intervention techniques leading to $1.5\times$-$4\times$ robustness improvements on three datasets, AudioSet, Kinetics-400 and ImageNet-Captions. Finally, we demonstrate that these interventions better utilize additional modalities, if present, to achieve competitive results of $44.2$ mAP on AudioSet 20K.
    
[^8]: OpenAGI：当LLM遇到领域专家

    OpenAGI: When LLM Meets Domain Experts. (arXiv:2304.04370v1 [cs.AI])

    [http://arxiv.org/abs/2304.04370](http://arxiv.org/abs/2304.04370)

    基于大型语言模型的OpenAGI平台通过整合领域专家模型和自然语言问答形式，实现复杂任务解决。

    

    人类具有将基本技能组合成复杂技能以解决复杂任务的显著能力。这种能力对于人工智能同样重要，因此，我们断言，除了开发大型综合智能模型外，将不同领域专家模型应用于复杂任务解决能力同样关键，以在人工智能通用智能的追求中使其具备这种能力。最近的大型语言模型（LLM）的发展证明其具有出色的学习和推理能力，使它们成为选择、综合和执行外部模型以解决复杂任务的控制器的有前途的选择。在这个项目中，我们开发了一个名为OpenAGI的开源AGI研究平台，专门设计为提供复杂的多步骤任务，并配有任务特定的数据集、评估指标和各种可扩展模型。OpenAGI将复杂任务阐释为自然语言问答，旨在促进领域专家和语言模型之间的协同作用。

    Human intelligence has the remarkable ability to assemble basic skills into complex ones so as to solve complex tasks. This ability is equally important for Artificial Intelligence (AI), and thus, we assert that in addition to the development of large, comprehensive intelligent models, it is equally crucial to equip such models with the capability to harness various domain-specific expert models for complex task-solving in the pursuit of Artificial General Intelligence (AGI). Recent developments in Large Language Models (LLMs) have demonstrated remarkable learning and reasoning abilities, making them promising as a controller to select, synthesize, and execute external models to solve complex tasks. In this project, we develop OpenAGI, an open-source AGI research platform, specifically designed to offer complex, multi-step tasks and accompanied by task-specific datasets, evaluation metrics, and a diverse range of extensible models. OpenAGI formulates complex tasks as natural language q
    
[^9]: 利用随机森林学习模型预测控制的残差模型，用于自动驾驶

    Learning Residual Model of Model Predictive Control via Random Forests for Autonomous Driving. (arXiv:2304.04366v1 [cs.RO])

    [http://arxiv.org/abs/2304.04366](http://arxiv.org/abs/2304.04366)

    通过随机森林学习残差模型，该论文提出了一种分层学习残差模型的新方法，可以更好地解决自动驾驶中预测精度和计算效率之间的矛盾。

    

    学习基于模型预测控制（MPC）的自动驾驶面临的一个主要问题是系统模型的预测精度和计算效率之间的矛盾。系统模型覆盖的情况越多，它就越复杂，并具有高度非线性和非凸性。这些问题使得优化过于复杂，无法实时控制。为了解决这些问题，我们提出了一种利用随机森林和线性回归的分层学习残差模型。学习到的模型由两个层级组成。低层使用线性回归拟合残差，高层使用随机森林切换不同的线性模型。同时，我们采用带有误差状态的线性动态自行车模型作为名义模型。将切换的线性回归模型添加到名义模型中形成系统模型。它将基于学习的MPC重构为一个二次规划（QP）问题，优化求解器可以轻松地解决它。我们的方法展示了比现有MPC方法更好的计算效率和预测精度。在真实世界的行驶场景中进行的大量实验表明，我们的方法可以处理各种复杂的城市和高速公路环境，并优于其他控制算法。

    One major issue in learning-based model predictive control (MPC) for autonomous driving is the contradiction between the system model's prediction accuracy and computation efficiency. The more situations a system model covers, the more complex it is, along with highly nonlinear and nonconvex properties. These issues make the optimization too complicated to solve and render real-time control impractical.To address these issues, we propose a hierarchical learning residual model which leverages random forests and linear regression.The learned model consists of two levels. The low level uses linear regression to fit the residues, and the high level uses random forests to switch different linear models. Meanwhile, we adopt the linear dynamic bicycle model with error states as the nominal model.The switched linear regression model is added to the nominal model to form the system model. It reformulates the learning-based MPC as a quadratic program (QP) problem and optimization solvers can eff
    
[^10]: Eagle: 基于端到端深度强化学习的 PTZ 摄像头自主控制

    Eagle: End-to-end Deep Reinforcement Learning based Autonomous Control of PTZ Cameras. (arXiv:2304.04356v1 [cs.CV])

    [http://arxiv.org/abs/2304.04356](http://arxiv.org/abs/2304.04356)

    Eagle 是一个基于端到端深度强化学习的解决方案，通过逼真的模拟框架训练神经网络策略，直接以图像作为输入控制 PTZ 摄像头，实现了卓越的摄像头控制性能。

    

    目前用于 PTZ 摄像头自主控制的方法通常采用多个阶段，其中目标检测和定位单独于 PTZ 机制的控制。这些方法需要手动标注，并由于信息流量的多阶段传递导致性能瓶颈。目标检测神经网络的大尺寸也使得之前的解决方案在资源受限设备上的实时部署变得不可行。我们提出的端到端深度强化学习（RL）解决方案名为 Eagle，用于训练神经网络策略，直接以图像作为输入，控制 PTZ 摄像头。在现实世界中，基于强化学习的训练因标注工作量、运行环境随机性和易损实验设置而变得复杂。我们引入了一种逼真的模拟框架，以训练和评估 PTZ 摄像头控制策略。Eagle 实现了卓越的摄像头控制性能。

    Existing approaches for autonomous control of pan-tilt-zoom (PTZ) cameras use multiple stages where object detection and localization are performed separately from the control of the PTZ mechanisms. These approaches require manual labels and suffer from performance bottlenecks due to error propagation across the multi-stage flow of information. The large size of object detection neural networks also makes prior solutions infeasible for real-time deployment in resource-constrained devices. We present an end-to-end deep reinforcement learning (RL) solution called Eagle to train a neural network policy that directly takes images as input to control the PTZ camera. Training reinforcement learning is cumbersome in the real world due to labeling effort, runtime environment stochasticity, and fragile experimental setups. We introduce a photo-realistic simulation framework for training and evaluation of PTZ camera control policies. Eagle achieves superior camera control performance by maintain
    
[^11]: 大规模量子多体态的机器学习显著提高效率并具有可证明保障

    Exponentially Improved Efficient Machine Learning for Quantum Many-body States with Provable Guarantees. (arXiv:2304.04353v1 [quant-ph])

    [http://arxiv.org/abs/2304.04353](http://arxiv.org/abs/2304.04353)

    通过机器学习协议预测量子多体系统的基态及其性质，其精度为 $\varepsilon$，并具有可证明的保障；但对于普遍的能隙哈密顿量，样本个数 $N = m^{{\cal{O}} \left(\frac{1}{\varepsilon}\right)}$，只适用于参数空间维度较大，且精度不是紧迫因素，无法进入更精确的学习和预测领域。

    

    对于经典算法而言，解决量子多体系统的基态及其性质通常是一项艰巨的任务。对于定义在物理参数 $m$ 维空间上的哈密顿量族，只要可以高效地准备和测量一组 $N$ 个态，就可以通过机器学习协议预测其基态及其在任意参数配置下的性质，精度为 $\varepsilon$。最近的一项研究 [Huang 等人，Science 377，eabk3333（2022）] 对这种一般化提出了严格的保障。不幸的是，对于普遍的能隙哈密顿量，普适的指数缩放为 $N = m^{{\cal{O}} \left(\frac{1}{\varepsilon}\right)}$，这个结果仅适用于参数空间的维度较大，而精度的缩放则不是一个紧迫的因素，不能进入更精确的学习和预测领域。

    Solving the ground state and the ground-state properties of quantum many-body systems is generically a hard task for classical algorithms. For a family of Hamiltonians defined on an $m$-dimensional space of physical parameters, the ground state and its properties at an arbitrary parameter configuration can be predicted via a machine learning protocol up to a prescribed prediction error $\varepsilon$, provided that a sample set (of size $N$) of the states can be efficiently prepared and measured. In a recent work [Huang et al., Science 377, eabk3333 (2022)], a rigorous guarantee for such an generalization was proved. Unfortunately, an exponential scaling, $N = m^{ {\cal{O}} \left(\frac{1}{\varepsilon} \right) }$, was found to be universal for generic gapped Hamiltonians. This result applies to the situation where the dimension of the parameter space is large while the scaling with the accuracy is not an urgent factor, not entering the realm of more precise learning and prediction. In th
    
[^12]: 基于无条件扩散模型的实时文本驱动图像处理

    Towards Real-time Text-driven Image Manipulation with Unconditional Diffusion Models. (arXiv:2304.04344v1 [cs.CV])

    [http://arxiv.org/abs/2304.04344](http://arxiv.org/abs/2304.04344)

    本研究提出了一种基于无条件扩散模型的图像编辑算法，可根据提供的文本描述快速学习和应用高质量的图像操作，比旧算法学习图像操作更快4.5-10倍，应用更快速的8倍。

    

    最近扩散模型的进展为图像编辑提供了许多强大的工具。其中之一是文本驱动的图像操作：根据提供的文本描述编辑图像的语义属性。现有的扩散模型已经为广泛的文本提示提供了高质量的图像操作方法。然而，在实践中，即使使用高端GPU，这些方法也需要高计算成本。这极大地限制了扩散模型图像编辑在潜在的实际应用中的应用，特别是在用户设备上运行时。在本文中，我们解决了基于无条件扩散模型的最近的文本驱动编辑方法的效率问题，并开发了一种新算法，该算法可以比旧算法学习图像操作4.5-10倍的更快，并且应用更快速的8倍。我们仔细评估了视觉质量和表现力。

    Recent advances in diffusion models enable many powerful instruments for image editing. One of these instruments is text-driven image manipulations: editing semantic attributes of an image according to the provided text description. % Popular text-conditional diffusion models offer various high-quality image manipulation methods for a broad range of text prompts. Existing diffusion-based methods already achieve high-quality image manipulations for a broad range of text prompts. However, in practice, these methods require high computation costs even with a high-end GPU. This greatly limits potential real-world applications of diffusion-based image editing, especially when running on user devices.  In this paper, we address efficiency of the recent text-driven editing methods based on unconditional diffusion models and develop a novel algorithm that learns image manipulations 4.5-10 times faster and applies them 8 times faster. We carefully evaluate the visual quality and expressiveness 
    
[^13]: 可证黑盒攻击：确保对抗性样本的攻击成功率

    Certifiable Black-Box Attack: Ensuring Provably Successful Attack for Adversarial Examples. (arXiv:2304.04343v1 [cs.LG])

    [http://arxiv.org/abs/2304.04343](http://arxiv.org/abs/2304.04343)

    本文提出可证黑盒攻击，能够保证攻击成功率，设计了多种新技术。

    

    黑盒对抗攻击具有破坏机器学习模型的强大潜力。现有的黑盒对抗攻击通过迭代查询目标模型和/或利用本地代理模型的可转移性来制作对抗样本。当实验设计攻击时，攻击是否成功对攻击者来说仍然是未知的。本文通过修改随机平滑性理论，首次研究了可证黑盒攻击的新范例，能够保证制作的对抗样本的攻击成功率，为此设计了多种新技术。

    Black-box adversarial attacks have shown strong potential to subvert machine learning models. Existing black-box adversarial attacks craft the adversarial examples by iteratively querying the target model and/or leveraging the transferability of a local surrogate model. Whether such attack can succeed remains unknown to the adversary when empirically designing the attack. In this paper, to our best knowledge, we take the first step to study a new paradigm of adversarial attacks -- certifiable black-box attack that can guarantee the attack success rate of the crafted adversarial examples. Specifically, we revise the randomized smoothing to establish novel theories for ensuring the attack success rate of the adversarial examples. To craft the adversarial examples with the certifiable attack success rate (CASR) guarantee, we design several novel techniques, including a randomized query method to query the target model, an initialization method with smoothed self-supervised perturbation to
    
[^14]: 随机赌博机中的遗憾分布：期望和尾部风险之间的最优权衡

    Regret Distribution in Stochastic Bandits: Optimal Trade-off between Expectation and Tail Risk. (arXiv:2304.04341v1 [stat.ML])

    [http://arxiv.org/abs/2304.04341](http://arxiv.org/abs/2304.04341)

    该论文探讨了随机多臂赌博问题中，如何在期望和尾部风险之间做出最优权衡。提出了一种新的策略，能够实现最坏和实例相关的优异表现，并且能够最小化遗憾尾部概率。

    

    本文研究了随机多臂赌博问题中，遗憾分布的期望和尾部风险之间的权衡问题。我们完全刻画了策略设计中三个期望性质之间的相互作用：最坏情况下的最优性，实例相关的一致性和轻尾风险。我们展示了期望遗憾的顺序如何影响遗憾尾部概率的衰减率，同时包括了最坏情况和实例相关的情况。我们提出了一种新的策略，以表征对于任何遗憾阈值的最优遗憾尾部概率。具体地，对于任何给定的$\alpha \in [1/2, 1)$和$\beta \in [0, \alpha]$，我们的策略可以实现平均期望遗憾$\tilde O(T^\alpha)$的最坏情况下$\alpha$-最优和期望遗憾$\tilde O(T^\beta)$的实例相关的$\beta$-一致性，并且享有一定的概率可以避免$\tilde O(T^\delta)$的遗憾($\delta \geq \alpha$在最坏情况下和$\delta \geq \beta$在实例相关的情况下)。

    We study the trade-off between expectation and tail risk for regret distribution in the stochastic multi-armed bandit problem. We fully characterize the interplay among three desired properties for policy design: worst-case optimality, instance-dependent consistency, and light-tailed risk. We show how the order of expected regret exactly affects the decaying rate of the regret tail probability for both the worst-case and instance-dependent scenario. A novel policy is proposed to characterize the optimal regret tail probability for any regret threshold. Concretely, for any given $\alpha\in[1/2, 1)$ and $\beta\in[0, \alpha]$, our policy achieves a worst-case expected regret of $\tilde O(T^\alpha)$ (we call it $\alpha$-optimal) and an instance-dependent expected regret of $\tilde O(T^\beta)$ (we call it $\beta$-consistent), while enjoys a probability of incurring an $\tilde O(T^\delta)$ regret ($\delta\geq\alpha$ in the worst-case scenario and $\delta\geq\beta$ in the instance-dependent s
    
[^15]: 电子商务机器学习中预训练嵌入的失败与原因

    Pretrained Embeddings for E-commerce Machine Learning: When it Fails and Why?. (arXiv:2304.04330v1 [cs.LG])

    [http://arxiv.org/abs/2304.04330](http://arxiv.org/abs/2304.04330)

    研究发现，预训练嵌入在电子商务机器学习中的应用存在许多问题，尤其是在真实生产系统中。尽管预训练嵌入是有效的，但它的成功与下游模型的设计以及如何通过嵌入向量来编码和解码信息有着深刻的联系和原因。

    

    预训练嵌入在现代电子商务机器学习系统中的应用已经变得普遍。然而，在实践中，当在真实的生产系统中应用预训练嵌入时，我们遇到了几个关键问题，其中许多问题无法完全用当前的知识解释。不幸的是，我们发现缺乏对预训练嵌入的工作方式有全面的了解，特别是它们的内在属性和与下游任务的相互作用。因此，难以在实践中做出交互和可扩展的决策，以关于预训练嵌入的使用。我们的研究有两个重要的发现，关于在电子商务应用中使用预训练嵌入。首先，我们发现预训练和下游模型的设计，特别是它们如何通过嵌入向量编码和解码信息，可以产生深远的影响。其次，我们通过解决嵌入性质问题建立了预训练嵌入的原理视角。

    The use of pretrained embeddings has become widespread in modern e-commerce machine learning (ML) systems. In practice, however, we have encountered several key issues when using pretrained embedding in a real-world production system, many of which cannot be fully explained by current knowledge. Unfortunately, we find that there is a lack of a thorough understanding of how pre-trained embeddings work, especially their intrinsic properties and interactions with downstream tasks. Consequently, it becomes challenging to make interactive and scalable decisions regarding the use of pre-trained embeddings in practice.  Our investigation leads to two significant discoveries about using pretrained embeddings in e-commerce applications. Firstly, we find that the design of the pretraining and downstream models, particularly how they encode and decode information via embedding vectors, can have a profound impact. Secondly, we establish a principled perspective of pre-trained embeddings via the le
    
[^16]: 基于分布中知识蒸馏的非IID数据同质化方法来进行分散式学习

    Homogenizing Non-IID datasets via In-Distribution Knowledge Distillation for Decentralized Learning. (arXiv:2304.04326v1 [cs.LG])

    [http://arxiv.org/abs/2304.04326](http://arxiv.org/abs/2304.04326)

    本文提出了基于分布中知识蒸馏（IDKD）的方法来解决节点间同质化数据分布的问题，该方法使用公共数据集来从每个节点中提取知识，并通过生成的标签将其传递给其邻居，以实现相同的目标，同时保持隐私约束。在非i.i.d.数据集上，IDKD的性能显着优于现有方法，同时保持隐私和通信效率。

    

    分散式学习允许在多个节点上以分散式方式训练深度神经网络（DNN），并使用各种数据源进行训练。然而，分散式学习的一个主要挑战是节点间数据分布的异质性。本文提出了基于分布中知识蒸馏（IDKD）的方法来解决此挑战。IDKD的目标是同质化节点之间的数据分布。虽然这种数据同质化可以通过在节点之间交换数据来实现，但这样会牺牲隐私。IDKD使用公共数据集来从每个节点中提取知识，并通过生成的标签将其传递给其邻居，以实现相同的目标，同时保持隐私约束。我们评估了IDKD在非i.i.d.数据集上的性能，并显示它在同质数据分布方面显着优于现有方法，同时保持隐私和通信效率。

    Decentralized learning enables serverless training of deep neural networks (DNNs) in a distributed manner on multiple nodes. This allows for the use of large datasets, as well as the ability to train with a wide variety of data sources. However, one of the key challenges with decentralized learning is heterogeneity in the data distribution across the nodes. In this paper, we propose In-Distribution Knowledge Distillation (IDKD) to address the challenge of heterogeneous data distribution. The goal of IDKD is to homogenize the data distribution across the nodes. While such data homogenization can be achieved by exchanging data among the nodes sacrificing privacy, IDKD achieves the same objective using a common public dataset across nodes without breaking the privacy constraint. This public dataset is different from the training dataset and is used to distill the knowledge from each node and communicate it to its neighbors through the generated labels. With traditional knowledge distillat
    
[^17]: 使用物理知识约束的神经网络进行微震源成像

    Microseismic source imaging using physics-informed neural networks with hard constraints. (arXiv:2304.04315v1 [physics.geo-ph])

    [http://arxiv.org/abs/2304.04315](http://arxiv.org/abs/2304.04315)

    本论文提出一种使用物理知识约束的神经网络（PINNs）进行直接微震成像的方法，能够生成聚焦的源图像，即使只有极少的记录。数值实验表明，该方法可以产生可靠且精确的结果。

    

    微震源成像在被动地震监测中起着重要作用，但由于稀疏的测量数据容易出现混叠问题，导致其常常失败。因此，我们提出了一种基于物理知识约束的神经网络（PINN）的直接微震成像框架，它可以生成聚焦的源图像，即使只有极少的记录。我们使用PINNs表示多频波场，然后应用逆傅里叶变换来提取源图像。特别地，我们通过硬约束来修改频域波场的表示形式，从而本质上满足边界条件（表层上的测量数据），避免了在PINNs中平衡数据和PDE损失的困难。此外，我们提出了关于深度的因果性损失实现，以提高PINNs的收敛性。在Overthrust模型上的数值实验表明，该方法可以产生可靠且精确的结果。

    Microseismic source imaging plays a significant role in passive seismic monitoring. However, such a process is prone to failure due to the aliasing problem when dealing with sparse measured data. Thus, we propose a direct microseismic imaging framework based on physics-informed neural networks (PINNs), which can generate focused source images, even with very sparse recordings. We use the PINNs to represent a multi-frequency wavefield and then apply the inverse Fourier transform to extract the source image. Specially, we modify the representation of the frequency-domain wavefield to inherently satisfy the boundary conditions (the measured data on the surface) by means of the hard constraint, which helps to avoid the difficulty in balancing the data and PDE losses in PINNs. Furthermore, we propose the causality loss implementation with respect to depth to enhance the convergence of PINNs. The numerical experiments on the Overthrust model show that the method can admit reliable and accura
    
[^18]: 过拟合元学习的泛化性能的理论表征

    Theoretical Characterization of the Generalization Performance of Overfitted Meta-Learning. (arXiv:2304.04312v1 [cs.LG])

    [http://arxiv.org/abs/2304.04312](http://arxiv.org/abs/2304.04312)

    本文研究了过拟合元学习的泛化性能，发现模型无关元学习（MAML）的过拟合最小 $\ell_2$ 范数解可以是有益的，类似于最近关于“良性过拟合”和“双下降”现象的显着发现。

    

    元学习已经成为一种成功的方法，通过对许多相似的任务进行训练来提高训练性能，特别是在深度神经网络（DNNs）中。然而，对于过度参数化模型（例如DNNs），何时以及为什么可以在元学习中很好地进行泛化的理论理解仍然有限。作为解决这一挑战的初步步骤，本文研究了具有高斯特征的线性回归模型下过拟合元学习的泛化性能。与一些最近的研究相比，我们的框架允许模型参数的数量任意大于地面实况信号中的特征数量，因此自然地捕捉深度元学习实践中的过度参数化制度。我们展示了模型无关元学习（MAML）的过拟合最小 $\ell_2$范数解可以是有益的，这类似于最近关于“良性过拟合”和“双下降”现象的显着发现。

    Meta-learning has arisen as a successful method for improving training performance by training over many similar tasks, especially with deep neural networks (DNNs). However, the theoretical understanding of when and why overparameterized models such as DNNs can generalize well in meta-learning is still limited. As an initial step towards addressing this challenge, this paper studies the generalization performance of overfitted meta-learning under a linear regression model with Gaussian features. In contrast to a few recent studies along the same line, our framework allows the number of model parameters to be arbitrarily larger than the number of features in the ground truth signal, and hence naturally captures the overparameterized regime in practical deep meta-learning. We show that the overfitted min $\ell_2$-norm solution of model-agnostic meta-learning (MAML) can be beneficial, which is similar to the recent remarkable findings on ``benign overfitting'' and ``double descent'' pheno
    
[^19]: 基于自适应鲁棒优化的时间序列预测集成建模方法

    Ensemble Modeling for Time Series Forecasting: an Adaptive Robust Optimization Approach. (arXiv:2304.04308v1 [cs.LG])

    [http://arxiv.org/abs/2304.04308](http://arxiv.org/abs/2304.04308)

    本文提出了一种基于自适应鲁棒优化的方法，用于构建强鲁棒性的时间序列预测模型集成，取得了比最佳集成成员更好的表现。

    

    精确的时间序列预测对于涉及时间数据的广泛问题至关重要。集成建模是一种利用多个预测模型提高准确性和鲁棒性的成熟技术，因为单个预测器的性能可能会因基础数据分布的转换而高度变化。本文提出了一种构建强鲁棒性时间序列预测模型集成的新方法。我们的方法利用自适应鲁棒优化（ARO）构建了一个线性回归集成模型，其中模型的权重可以随时间自适应调整。通过一系列合成实验和现实应用，包括空气污染管理、能源消耗预测和热带气旋强度预测等，我们展示了我们方法的有效性。我们的结果表明，我们的自适应集成模型在均方根误差和条件风险价值方面的表现优于最好的集成成员，分别提高了16-26%和14-28%。

    Accurate time series forecasting is critical for a wide range of problems with temporal data. Ensemble modeling is a well-established technique for leveraging multiple predictive models to increase accuracy and robustness, as the performance of a single predictor can be highly variable due to shifts in the underlying data distribution. This paper proposes a new methodology for building robust ensembles of time series forecasting models. Our approach utilizes Adaptive Robust Optimization (ARO) to construct a linear regression ensemble in which the models' weights can adapt over time. We demonstrate the effectiveness of our method through a series of synthetic experiments and real-world applications, including air pollution management, energy consumption forecasting, and tropical cyclone intensity forecasting. Our results show that our adaptive ensembles outperform the best ensemble member in hindsight by 16-26% in root mean square error and 14-28% in conditional value at risk and improv
    
[^20]: PriorCVAE: 基于贝叶斯深度生成建模的可扩展 MCMC 参数推断

    PriorCVAE: scalable MCMC parameter inference with Bayesian deep generative modelling. (arXiv:2304.04307v1 [stat.ML])

    [http://arxiv.org/abs/2304.04307](http://arxiv.org/abs/2304.04307)

    PriorCVAE 提出了一种处理高斯过程先验 MCMC 参数推断的贝叶斯深度生成建模新方法，可通过将 VAE 建模条件化于随机过程超参数处理超参数推断与学习先验之间的信息流断裂问题。

    

    在应用场景中，推理速度和模型灵活性至关重要，贝叶斯推断在具有随机过程先验的模型中（如高斯过程）被广泛应用。最近的研究表明，使用变分自动编码器（VAE）等深度生成模型可以编码由 GP 先验或其有限实现引起的计算瓶颈，并且所学生成器可以代替 MCMC 推断中的原始先验。虽然此方法实现了快速而高效的推理，但它丢失了关于随机过程超参数的信息，导致超参数推断不可能和学到的先验模糊不清。我们建议解决上述问题，通过将 VAE 建模条件化于随机过程超参数，以便超参数与 GP 实现一起进行编码。

    In applied fields where the speed of inference and model flexibility are crucial, the use of Bayesian inference for models with a stochastic process as their prior, e.g. Gaussian processes (GPs) is ubiquitous. Recent literature has demonstrated that the computational bottleneck caused by GP priors or their finite realizations can be encoded using deep generative models such as variational autoencoders (VAEs), and the learned generators can then be used instead of the original priors during Markov chain Monte Carlo (MCMC) inference in a drop-in manner. While this approach enables fast and highly efficient inference, it loses information about the stochastic process hyperparameters, and, as a consequence, makes inference over hyperparameters impossible and the learned priors indistinct. We propose to resolve the aforementioned issue and disentangle the learned priors by conditioning the VAE on stochastic process hyperparameters. This way, the hyperparameters are encoded alongside GP real
    
[^21]: 图中类别不平衡学习综述

    Class-Imbalanced Learning on Graphs: A Survey. (arXiv:2304.04300v1 [cs.LG])

    [http://arxiv.org/abs/2304.04300](http://arxiv.org/abs/2304.04300)

    本文综述了现有CILG技术的最新状态，提出了一个现有工作的分类法，并讨论了未来研究方向。CILG作为一种有前途的解决方案，将图表示学习和类别不平衡学习相结合，用于克服现实世界数据中的类别不平衡问题。

    

    数据驱动研究的快速发展增加了对有效的图数据分析的需求。然而，现实世界中的数据通常呈现类别不平衡，导致机器学习模型的性能不佳。为了克服这一挑战，类别不平衡学习在图上（CILG）已成为一种有前途的解决方案，结合了图表示学习和类别不平衡学习的优势。近年来，在CILG方面已经取得了重大进展。本综述旨在全面了解CILG的现有最新技术，并为未来的研究方向提供见解。另外，我们提供了一份持续更新的论文阅读列表。

    The rapid advancement in data-driven research has increased the demand for effective graph data analysis. However, real-world data often exhibits class imbalance, leading to poor performance of machine learning models. To overcome this challenge, class-imbalanced learning on graphs (CILG) has emerged as a promising solution that combines the strengths of graph representation learning and class-imbalanced learning. In recent years, significant progress has been made in CILG. Anticipating that such a trend will continue, this survey aims to offer a comprehensive understanding of the current state-of-the-art in CILG and provide insights for future research directions. Concerning the former, we introduce the first taxonomy of existing work and its connection to existing imbalanced learning literature. Concerning the latter, we critically analyze recent work in CILG and discuss urgent lines of inquiry within the topic. Moreover, we provide a continuously maintained reading list of papers an
    
[^22]: 分布式条件生成对抗网络（discGAN）用于合成医疗保健数据生成

    Distributed Conditional GAN (discGAN) For Synthetic Healthcare Data Generation. (arXiv:2304.04290v1 [cs.LG])

    [http://arxiv.org/abs/2304.04290](http://arxiv.org/abs/2304.04290)

    本文提出了一种分布式生成对抗网络（discGAN）用于生成医疗保健领域的合成表格数据，并且在应用中成功模拟出非高斯多模式医疗保健数据的分布，其生成的数据分布与真实数据相似。

    

    本文提出了一种分布式生成对抗网络（discGAN）来生成特定于医疗保健领域的合成表格数据。虽然使用生成对抗网络来生成图像已经得到了广泛研究，但几乎没有人关注生成表格数据。建模离散和连续表格数据的分布是一项非常有用的非平凡任务。我们将discGAN应用于模拟非高斯多模式医疗保健数据。我们从原始的2,027个eICU数据集中生成了249,000个合成记录。我们使用机器学习功效、连续变量的Kolmogorov-Smirnov（KS）检验和离散变量的卡方检验来评估模型的性能。我们的结果表明，discGAN能够生成具有与真实数据类似的分布数据。

    In this paper, we propose a distributed Generative Adversarial Networks (discGANs) to generate synthetic tabular data specific to the healthcare domain. While using GANs to generate images has been well studied, little to no attention has been given to generation of tabular data. Modeling distributions of discrete and continuous tabular data is a non-trivial task with high utility. We applied discGAN to model non-Gaussian multi-modal healthcare data. We generated 249,000 synthetic records from original 2,027 eICU dataset. We evaluated the performance of the model using machine learning efficacy, the Kolmogorov-Smirnov (KS) test for continuous variables and chi-squared test for discrete variables. Our results show that discGAN was able to generate data with distributions similar to the real data.
    
[^23]: 用半监督学习填补缺失值：时间序列插补

    Filling out the missing gaps: Time Series Imputation with Semi-Supervised Learning. (arXiv:2304.04275v1 [cs.LG])

    [http://arxiv.org/abs/2304.04275](http://arxiv.org/abs/2304.04275)

    本文提出了一种名为ST-Impute的半监督时间序列插补方法，使用未标记数据和下游任务的标记数据进行训练，基于稀疏自我关注的方法比现有的监督和无监督时间序列插补方法更优秀。

    

    时间序列中的缺失数据是影响时间序列分析的一个具有挑战性的问题。由于数据丢失或传感器故障等问题导致缺失数据的发生。插补方法用于填补这些值，而插补的质量对下游任务（如分类）的影响很大。在这项工作中，我们提出了一种半监督插补方法ST-Impute，该方法利用未标记数据以及下游任务的标记数据。ST-Impute基于稀疏自我关注，并训练类似于插补过程的任务。我们的结果表明，提出的方法在插补质量以及插补时间序列的下游任务方面优于现有的监督和无监督时间序列插补方法。

    Missing data in time series is a challenging issue affecting time series analysis. Missing data occurs due to problems like data drops or sensor malfunctioning. Imputation methods are used to fill in these values, with quality of imputation having a significant impact on downstream tasks like classification. In this work, we propose a semi-supervised imputation method, ST-Impute, that uses both unlabeled data along with downstream task's labeled data. ST-Impute is based on sparse self-attention and trains on tasks that mimic the imputation process. Our results indicate that the proposed method outperforms the existing supervised and unsupervised time series imputation methods measured on the imputation quality as well as on the downstream tasks ingesting imputed time series.
    
[^24]: 多模式脑机接口在车内驾驶员认知负荷测量中的应用：数据集与基线

    Multimodal Brain-Computer Interface for In-Vehicle Driver Cognitive Load Measurement: Dataset and Baselines. (arXiv:2304.04273v1 [cs.LG])

    [http://arxiv.org/abs/2304.04273](http://arxiv.org/abs/2304.04273)

    本文介绍了一个新型的驾驶员认知负荷评估数据集，采用多模态生理信号与眼动追踪数据结合的方法，提高了分类性能，为该领域的进一步研究提供了基准。

    

    本文介绍了一个新型的驾驶员认知负荷评估数据集CL-Drive。该数据集包括驾驶时的脑电图（EEG）信号、心电图（ECG）、皮肤电活动（EDA）信号以及眼动追踪数据。数据采集自21名被试在沉浸式车辆模拟器中驾驶，包括不同驾驶条件下的任务，以诱发被试的不同认知负荷水平，每个任务持续3分钟，共9个复杂度级别。每个驾驶员在实验过程中每10秒报告一次主观认知负荷。数据集中包含主观认知负荷记录作为基准。此外，本文还提供了不同机器学习和深度学习模型的二元和三元标签分布的基准分类结果。我们采用了两种评估标准，即10倍交叉验证和留一法。我们对手工制作的特征和原始信号进行了训练。结果表明，使用多模态生理信号与眼动追踪数据相比仅使用EEG数据具有更好的分类性能。我们的数据集和分类结果为进一步研究驾驶员认知负荷评估提供了基准。

    Through this paper, we introduce a novel driver cognitive load assessment dataset, CL-Drive, which contains Electroencephalogram (EEG) signals along with other physiological signals such as Electrocardiography (ECG) and Electrodermal Activity (EDA) as well as eye tracking data. The data was collected from 21 subjects while driving in an immersive vehicle simulator, in various driving conditions, to induce different levels of cognitive load in the subjects. The tasks consisted of 9 complexity levels for 3 minutes each. Each driver reported their subjective cognitive load every 10 seconds throughout the experiment. The dataset contains the subjective cognitive load recorded as ground truth. In this paper, we also provide benchmark classification results for different machine learning and deep learning models for both binary and ternary label distributions. We followed 2 evaluation criteria namely 10-fold and leave-one-subject-out (LOSO). We have trained our models on both hand-crafted fe
    
[^25]: 时间序列数据的尴尬简单混合方法

    Embarrassingly Simple MixUp for Time-series. (arXiv:2304.04271v1 [cs.LG])

    [http://arxiv.org/abs/2304.04271](http://arxiv.org/abs/2304.04271)

    本研究针对时间序列数据提出了一种基于MixUp的数据增强方法，即MixUp++和LatentMixUp++，能够显著提高1％- 15％的分类准确率，尤其适用于有限标记数据的情况，并通过半监督学习扩展到无标签数据。

    

    由于领域专业知识和数据的动态性，标记时间序列数据是一项昂贵的任务。因此，我们经常需要处理有限标记数据的情况。数据增强技术已成功应用于诸如计算机视觉之类的领域，以利用现有标记数据的使用。我们将其中一种最常用的技术MixUp，应用于时序领域。我们的提出的MixUp++和LatentMixUp++方法分别对原始时间序列和分类模型的潜在空间进行插值的简单修改。我们也通过半监督学习将这些方法扩展到无标签数据。我们观察到，对于两个公共数据集的时间序列分类，无论是低标记数据还是高标记数据制度，通过LatentMixUp ++，都可以显著提高1％- 15％。

    Labeling time series data is an expensive task because of domain expertise and dynamic nature of the data. Hence, we often have to deal with limited labeled data settings. Data augmentation techniques have been successfully deployed in domains like computer vision to exploit the use of existing labeled data. We adapt one of the most commonly used technique called MixUp, in the time series domain. Our proposed, MixUp++ and LatentMixUp++, use simple modifications to perform interpolation in raw time series and classification model's latent space, respectively. We also extend these methods with semi-supervised learning to exploit unlabeled data. We observe significant improvements of 1\% - 15\% on time series classification on two public datasets, for both low labeled data as well as high labeled data regimes, with LatentMixUp++.
    
[^26]: 一篇关于知识蒸馏扩散模型的综合概述

    A Comprehensive Survey on Knowledge Distillation of Diffusion Models. (arXiv:2304.04262v1 [cs.LG])

    [http://arxiv.org/abs/2304.04262](http://arxiv.org/abs/2304.04262)

    扩散模型是一种直接建模评分函数的概率模型，在实现概率建模上更具可塑性和表达能力。本文综述了扩散模型知识蒸馏的现代方法和挑战，包括将扩散模型蒸馏至隐式生成函数的方法以及训练-free 的加速扩散采样算法。

    

    扩散模型是一种利用神经网络规定评分函数的概率模型，直接对评分函数进行建模，可用于精细知识的学习和潜在的概率建模。本文旨在提供现代扩散模型知识蒸馏方法的综合概述，从扩散模型介绍和知识蒸馏面临的挑战入手，概述现有方法将扩散模型蒸馏至隐式生成函数的研究，最后回顾一种不需要训练的加速扩散采样算法作为知识蒸馏的一种方法。

    Diffusion Models (DMs), also referred to as score-based diffusion models, utilize neural networks to specify score functions. Unlike most other probabilistic models, DMs directly model the score functions, which makes them more flexible to parametrize and potentially highly expressive for probabilistic modeling. DMs can learn fine-grained knowledge, i.e., marginal score functions, of the underlying distribution. Therefore, a crucial research direction is to explore how to distill the knowledge of DMs and fully utilize their potential. Our objective is to provide a comprehensible overview of the modern approaches for distilling DMs, starting with an introduction to DMs and a discussion of the challenges involved in distilling them into neural vector fields. We also provide an overview of the existing works on distilling DMs into both stochastic and deterministic implicit generators. Finally, we review the accelerated diffusion sampling algorithms as a training-free method for distillati
    
[^27]: CLVOS23：用于持续学习的长视频对象分割数据集

    CLVOS23: A Long Video Object Segmentation Dataset for Continual Learning. (arXiv:2304.04259v1 [cs.CV])

    [http://arxiv.org/abs/2304.04259](http://arxiv.org/abs/2304.04259)

    本文提出用于持续学习的长视频对象分割数据集CLVOS23，并在此基础上实现了一个基于正则化的持续学习方法，以应对半监督视频对象分割中的持续学习挑战。

    

    真实场景下的持续学习是一个重大挑战。通常的持续学习模型应具有恒定的记忆大小和无预定义的任务边界，而这种情况在半监督视频对象分割（VOS）中尤为明显，其中持续学习的挑战主要体现在处理长视频序列上。本文首先将半监督VOS问题，特别是在线VOS问题，形式化为持续学习问题，然后提供一个公共VOS数据集CLVOS23，重点关注持续学习。最后，我们提出并实现了一个基于正则化的持续学习方法在现有的在线VOS基线LWL上，以展示持续学习在应用于在线VOS时的有效性，并建立了一个CLVOS23基线。我们将所提出的基线应用于长视频数据集以及两个短视频VOS数据集DAVIS16和DAVIS17。据我们所知，这是VOS首次被定义为持续学习问题并构建基线。

    Continual learning in real-world scenarios is a major challenge. A general continual learning model should have a constant memory size and no predefined task boundaries, as is the case in semi-supervised Video Object Segmentation (VOS), where continual learning challenges particularly present themselves in working on long video sequences. In this article, we first formulate the problem of semi-supervised VOS, specifically online VOS, as a continual learning problem, and then secondly provide a public VOS dataset, CLVOS23, focusing on continual learning. Finally, we propose and implement a regularization-based continual learning approach on LWL, an existing online VOS baseline, to demonstrate the efficacy of continual learning when applied to online VOS and to establish a CLVOS23 baseline. We apply the proposed baseline to the Long Videos dataset as well as to two short video VOS datasets, DAVIS16 and DAVIS17. To the best of our knowledge, this is the first time that VOS has been define
    
[^28]: 关于“最近邻算法的任务特定数据有效性”的注记（arXiv：2304.04258v1 [stat.ML]）

    A Note on "Efficient Task-Specific Data Valuation for Nearest Neighbor Algorithms". (arXiv:2304.04258v1 [stat.ML])

    [http://arxiv.org/abs/2304.04258](http://arxiv.org/abs/2304.04258)

    本文提出了一种更自然和可解释的效用函数，更好地反映了KNN模型的性能，提供了相应计算过程，该方法被称为软标签KNN-SV，与原始方法具有相同的时间复杂度。

    

    数据有效性是一个研究单个数据点对机器学习（ML）模型影响的日益增长的研究领域。基于合作博弈论和经济学，数据 Shapley 是一种有效的数据有效性计算方法。然而，人们都知道 Shapley 值（SV）的计算可能非常昂贵。幸运的是，Jia 等人（2019）表明，对于 K 最近邻（KNN）模型，计算 Data Shapley 竟然非常简单和高效。在本笔记中，我们重审了 Jia 等人（2019）的工作，并提出了一种更自然和可解释的效用函数，更好地反映了 KNN 模型的性能。我们推导了具有新效用函数的 KNN 分类器/回归器的 Data Shapley 的相应计算过程。我们的新方法被称为软标签 KNN-SV，与原始方法具有相同的时间复杂度。我们进一步提供了一种基于局部敏感哈希（LSH）的软标签 KNN-SV 的高效近似算法。

    Data valuation is a growing research field that studies the influence of individual data points for machine learning (ML) models. Data Shapley, inspired by cooperative game theory and economics, is an effective method for data valuation. However, it is well-known that the Shapley value (SV) can be computationally expensive. Fortunately, Jia et al. (2019) showed that for K-Nearest Neighbors (KNN) models, the computation of Data Shapley is surprisingly simple and efficient.  In this note, we revisit the work of Jia et al. (2019) and propose a more natural and interpretable utility function that better reflects the performance of KNN models. We derive the corresponding calculation procedure for the Data Shapley of KNN classifiers/regressors with the new utility functions. Our new approach, dubbed soft-label KNN-SV, achieves the same time complexity as the original method. We further provide an efficient approximation algorithm for soft-label KNN-SV based on locality sensitive hashing (LSH
    
[^29]: 区块链技术在MANET中的安全路由协议应用研究

    Secure Routing Protocol To Mitigate Attacks By Using Blockchain Technology In Manet. (arXiv:2304.04254v1 [cs.CR])

    [http://arxiv.org/abs/2304.04254](http://arxiv.org/abs/2304.04254)

    论文提出了一种采用区块链技术的安全路由算法（SRABC），该算法通过提供源节点到目的节点的安全、经过认证和防篡改的路由来保护控制和数据流，预防MANET受到各种攻击手段，并对节点进行认证。仿真结果表明，SRABC算法优于当前方法，是确保MANET安全的可行选项。

    

    MANET是一组通过无线网络通信的移动节点，它们从一个点移动到另一个点。由于MANET是一个没有基础设施且拓扑结构可变的网络，因此很容易受到攻击。恶意网络节点是网络攻击的源头。在MANET中，攻击可以采取各种形式，并以其独特的方式改变网络的运行。本文介绍了许多形式的攻击、它们对MANET的影响以及目前实施的MANET防御措施。所提出的采用区块链技术的安全路由算法（SRABC）可保护MANET免受攻击并对节点进行认证。该算法通过提供源节点到目的节点的安全、经过认证和防篡改的路由来保护控制和数据流，防范威胁。使用NS2模拟器评估了SRABC算法的关键性能参数，如数据包传递率、端到端延迟和吞吐量。仿真结果表明，SRABC算法优于当前方法，是确保MANET安全的可行选项。

    MANET is a collection of mobile nodes that communicate through wireless networks as they move from one point to another. MANET is an infrastructure-less network with a changeable topology; as a result, it is very susceptible to attacks. MANET attack prevention represents a serious difficulty. Malicious network nodes are the source of network-based attacks. In a MANET, attacks can take various forms, and each one alters the network's operation in its unique way. In general, attacks can be separated into two categories: those that target the data traffic on a network and those that target the control traffic. This article explains the many sorts of assaults, their impact on MANET, and the MANET-based defence measures that are currently in place. The suggested SRA that employs blockchain technology (SRABC) protects MANET from attacks and authenticates nodes. The secure routing algorithm (SRA) proposed by blockchain technology safeguards control and data flow against threats. This is achie
    
[^30]: 可编辑用户档案的可控文本推荐方法

    Editable User Profiles for Controllable Text Recommendation. (arXiv:2304.04250v1 [cs.IR])

    [http://arxiv.org/abs/2304.04250](http://arxiv.org/abs/2304.04250)

    本文提出了一种新的概念值瓶颈模型LACE，用于可控文本推荐。该模型基于用户文档学习个性化的概念表示，并通过多种交互方式为用户提供了控制推荐的机制，验证了在离线和在线实验中该模型的推荐质量和有效性。

    

    实现高质量推荐的方法通常依赖于从交互数据中学习潜在表示。然而这些方法没有提供给用户控制所接收的推荐的机制。本文提出了LACE，一种新颖的概念值瓶颈模型，用于可控文本推荐。LACE基于用户交互的文档检索，将每个用户表示为简洁的可读的概念集，并基于用户文档学习概念的个性化表示。该基于概念的用户档案被利用来做出推荐。我们的模型设计通过透明的用户档案，提供了控制推荐的多种直观交互方式。我们首先在三个推荐任务（温启动、冷启动和零样本）的六个数据集上进行了离线评估，验证了从LACE获得的推荐质量。接下来，我们在在线实验中验证了LACE的有效性和用户控制能力。

    Methods for making high-quality recommendations often rely on learning latent representations from interaction data. These methods, while performant, do not provide ready mechanisms for users to control the recommendation they receive. Our work tackles this problem by proposing LACE, a novel concept value bottleneck model for controllable text recommendations. LACE represents each user with a succinct set of human-readable concepts through retrieval given user-interacted documents and learns personalized representations of the concepts based on user documents. This concept based user profile is then leveraged to make recommendations. The design of our model affords control over the recommendations through a number of intuitive interactions with a transparent user profile. We first establish the quality of recommendations obtained from LACE in an offline evaluation on three recommendation tasks spanning six datasets in warm-start, cold-start, and zero-shot setups. Next, we validate the 
    
[^31]: 数据驱动的多项式随机森林

    Data-driven multinomial random forest. (arXiv:2304.04240v1 [stat.ML])

    [http://arxiv.org/abs/2304.04240](http://arxiv.org/abs/2304.04240)

    本文加强了一些先前弱一些的随机森林变体的证明方法并提高了这些变体的数据利用率以获得更好的理论性能和实验性能，提出了一种数据驱动的多项式随机森林算法，其复杂度低且满足强一致性，在分类和回归问题上表现更好，并超过了标准随机森林。

    

    本文加强了一些先前弱一些的随机森林变体的证明方法，使其成为强一致性的证明方法，并提高了这些变体的数据利用率，以获得更好的理论性能和实验性能。此外，基于多项式随机森林（MRF）和伯努利随机森林（BRF），提出了一种数据驱动的多项式随机森林（DMRF）算法，其比MRF的复杂度更低，比BRF的复杂度更高，同时满足强一致性。在分类和回归问题上，它比之前只满足弱一致性的RF变体表现更好，甚至超过了标准随机森林。据我们所知，DMRF是目前最出色的低算法复杂性的强随机森林变体。

    In this article, we strengthen the proof methods of some previously weakly consistent variants of random forests into strongly consistent proof methods, and improve the data utilization of these variants, in order to obtain better theoretical properties and experimental performance. In addition, based on the multinomial random forest (MRF) and Bernoulli random forest (BRF), we propose a data-driven multinomial random forest (DMRF) algorithm, which has lower complexity than MRF and higher complexity than BRF while satisfying strong consistency. It has better performance in classification and regression problems than previous RF variants that only satisfy weak consistency, and in most cases even surpasses standard random forest. To the best of our knowledge, DMRF is currently the most excellent strongly consistent RF variant with low algorithm complexity
    
[^32]: 变分算子学习：一种训练神经算子和解决偏微分方程的统一方法

    Variational operator learning: A unified paradigm for training neural operators and solving partial differential equations. (arXiv:2304.04234v1 [cs.LG])

    [http://arxiv.org/abs/2304.04234](http://arxiv.org/abs/2304.04234)

    本文提出了变分算子学习（VOL）的范式，同时训练神经算子和解决偏微分方程（PDE）。使用正反传递循环和自动微分实现了变分操作，通过最速下降法和共轭梯度法进行神经算子的简单但有效的训练。实验结果非常好。

    

    本论文提出了一种基于变分方法的新范式，为训练神经算子和用变分形式解决偏微分方程（PDE）提供了一个统一的框架，称为变分算子学习（VOL）。我们首先从神经算子给出的节点解预测中推导出系统的函数逼近，并通过自动微分进行变分操作，构建正反传递循环来推导线性系统的残差。在每次迭代中，我们提供最速下降法（SD）和共轭梯度法（CG）的一个或多个更新步骤，作为训练神经算子的一种简单而有效的更新方法。实验结果显示，所提出的VOL可以学习到在稳定传热和变刚度弹性PDE中各种解算子，结果令人满意，误差较小。该方法几乎实现无标签训练。

    Based on the variational method, we propose a novel paradigm that provides a unified framework of training neural operators and solving partial differential equations (PDEs) with the variational form, which we refer to as the variational operator learning (VOL). We first derive the functional approximation of the system from the node solution prediction given by neural operators, and then conduct the variational operation by automatic differentiation, constructing a forward-backward propagation loop to derive the residual of the linear system. One or several update steps of the steepest decent method (SD) and the conjugate gradient method (CG) are provided in every iteration as a cheap yet effective update for training the neural operators. Experimental results show the proposed VOL can learn a variety of solution operators in PDEs of the steady heat transfer and the variable stiffness elasticity with satisfactory results and small error. The proposed VOL achieves nearly label-free tra
    
[^33]: RISC: 生成真实的双语保险合同的合成数据

    RISC: Generating Realistic Synthetic Bilingual Insurance Contract. (arXiv:2304.04212v1 [cs.CL])

    [http://arxiv.org/abs/2304.04212](http://arxiv.org/abs/2304.04212)

    本文介绍了一个名为RISC的Python开源包数据生成器，它可以生成类似于魁北克省法规保险格式的汽车保险合同，包括法语和英语版本，基于此生成的RISCBAC数据集可用于NLP研究中的无监督自动摘要、问答、文本简化、机器翻译任务，以及监督任务。

    

    本论文介绍了一个名为RISC的Python开源包数据生成器，它可以生成类似于魁北克省法规保险格式的汽车保险合同，包括法语和英语版本。保险合同通常长达90到100页，使用专业的法律和保险术语，因此比传统的NLP语料库中的文档类别更为复杂。因此，我们介绍了基于魁北克省强制汽车保险合同的逼真保险合成双语汽车合同数据集RISCBAC。该数据集包括10,000份未经标注的法语和英语保险合同。RISCBAC可用于NLP研究中的无监督自动摘要、问答、文本简化、机器翻译等任务。此外，它还可以进一步自动标注为监督任务的数据集，例如命名实体识别。

    This paper presents RISC, an open-source Python package data generator (https://github.com/GRAAL-Research/risc). RISC generates look-alike automobile insurance contracts based on the Quebec regulatory insurance form in French and English. Insurance contracts are 90 to 100 pages long and use complex legal and insurance-specific vocabulary for a layperson. Hence, they are a much more complex class of documents than those in traditional NLP corpora. Therefore, we introduce RISCBAC, a Realistic Insurance Synthetic Bilingual Automobile Contract dataset based on the mandatory Quebec car insurance contract. The dataset comprises 10,000 French and English unannotated insurance contracts. RISCBAC enables NLP research for unsupervised automatic summarisation, question answering, text simplification, machine translation and more. Moreover, it can be further automatically annotated as a dataset for supervised tasks such as NER
    
[^34]: AGAD: 对抗生成式异常检测

    AGAD: Adversarial Generative Anomaly Detection. (arXiv:2304.04211v1 [cs.CV])

    [http://arxiv.org/abs/2304.04211](http://arxiv.org/abs/2304.04211)

    该论文提出了一种基于自我对比的对抗生成式异常检测模式AGAD，它成功解决了因缺少异常数据而造成的稳健异常检测问题，并且能够为监督和半监督异常检测场景生成伪异常数据。

    

    异常检测受到异常数据的缺乏和异常类型的多样性而困扰。半监督异常检测方法通常用于仅利用正常数据来检测偏离学习到的正常分布的异常。与此同时，鉴于实践中只能以较小的代价获得有限的异常数据，一些研究还研究了在有限异常数据监督场景下的异常检测方法。为了解决稳健异常检测中缺少异常数据的问题，我们提出了对抗生成式异常检测（AGAD），一种基于自我对比的异常检测模式，它通过从大量正常样本中生成“上下文对抗信息”来学习检测异常。本质上，我们的方法为监督和半监督异常检测场景生成伪异常数据。进行了大量实验验证。

    Anomaly detection suffered from the lack of anomalies due to the diversity of abnormalities and the difficulties of obtaining large-scale anomaly data. Semi-supervised anomaly detection methods are often used to solely leverage normal data to detect abnormalities that deviated from the learnt normality distributions. Meanwhile, given the fact that limited anomaly data can be obtained with a minor cost in practice, some researches also investigated anomaly detection methods under supervised scenarios with limited anomaly data. In order to address the lack of abnormal data for robust anomaly detection, we propose Adversarial Generative Anomaly Detection (AGAD), a self-contrast-based anomaly detection paradigm that learns to detect anomalies by generating \textit{contextual adversarial information} from the massive normal examples. Essentially, our method generates pseudo-anomaly data for both supervised and semi-supervised anomaly detection scenarios. Extensive experiments are carried ou
    
[^35]: OpenDriver: 一份开放路况驾驶员状态检测数据集

    OpenDriver: an open-road driver state detection dataset. (arXiv:2304.04203v1 [cs.AI])

    [http://arxiv.org/abs/2304.04203](http://arxiv.org/abs/2304.04203)

    OpenDriver是一份旨在解决现有驾驶员生理数据集存在问题的开放路况驾驶员状态检测数据集，包含六轴惯性信号和心电图信号两种模态的数据，可用于驾驶员受损检测和生物识别数据识别。

    

    在现代社会中，道路安全严重依赖于驾驶员的心理和生理状态。疲劳、昏昏欲睡和压力等负面因素会影响驾驶员的反应时间和决策能力，导致交通事故的发生率增加。在众多的驾驶员行为监测研究中，可穿戴生理测量是一种实时监测驾驶员状态的方法。然而，目前在开放道路场景下，缺少驾驶员生理数据集，已有的数据集存在信号质量差、样本量小和数据收集时间短等问题。因此，本文设计并描述了一种大规模多模态驾驶数据集，用于驾驶员受损检测和生物识别数据识别。该数据集包含两种驾驶信号模态：六轴惯性信号和心电图（ECG）信号，这些信号是在100多名驾驶员遵循相同路线行驶时记录的。

    In modern society, road safety relies heavily on the psychological and physiological state of drivers. Negative factors such as fatigue, drowsiness, and stress can impair drivers' reaction time and decision making abilities, leading to an increased incidence of traffic accidents. Among the numerous studies for impaired driving detection, wearable physiological measurement is a real-time approach to monitoring a driver's state. However, currently, there are few driver physiological datasets in open road scenarios and the existing datasets suffer from issues such as poor signal quality, small sample sizes, and short data collection periods. Therefore, in this paper, a large-scale multimodal driving dataset for driver impairment detection and biometric data recognition is designed and described. The dataset contains two modalities of driving signals: six-axis inertial signals and electrocardiogram (ECG) signals, which were recorded while over one hundred drivers were following the same ro
    
[^36]: 深度神经网络中公平性缺陷的信息论测试和调试

    Information-Theoretic Testing and Debugging of Fairness Defects in Deep Neural Networks. (arXiv:2304.04199v1 [cs.SE])

    [http://arxiv.org/abs/2304.04199](http://arxiv.org/abs/2304.04199)

    本文介绍了一个信息论测试和调试框架DICE，用于衡量DNN中公平性缺陷的严重性及其根源，以帮助开发人员进行处理。

    

    深度前馈神经网络(DNN)在各种决策支持软件中得到了广泛应用。 DNN在它们的训练数据中能够寻找到最小、足够的统计模式。因此，DNN可能学习到编码决策的能力——放大现有的偏见或引入新的偏见——这些可能会使受保护的个体/群体处于不利地位，并可能违反法律保护。虽然现有的基于搜索的软件测试方法在发现公正性缺陷方面效果很好，但它们没有提供与严重性和因果解释等调试辅助工具，这对于帮助开发人员进行处理并决定下一步行动至关重要。我们能否度量DNN中公平性缺陷的严重性？这些缺陷是由不当的训练引起的，还是仅仅反映了训练数据中存在的偏见？为了回答这些问题，我们提出了DICE：一个信息论测试和调试框架。

    The deep feedforward neural networks (DNNs) are increasingly deployed in socioeconomic critical decision support software systems. DNNs are exceptionally good at finding minimal, sufficient statistical patterns within their training data. Consequently, DNNs may learn to encode decisions -amplifying existing biases or introducing new ones -- that may disadvantage protected individuals/groups and may stand to violate legal protections. While the existing search based software testing approaches have been effective in discovering fairness defects, they do not supplement these defects with debugging aids -- such as severity and causal explanations -- crucial to help developers triage and decide on the next course of action. Can we measure the severity of fairness defects in DNNs? Are these defects symptomatic of improper training or they merely reflect biases present in the training data? To answer such questions, we present DICE: an information-theoretic testing and debugging framework 
    
[^37]: 基于知识蒸馏的超网络HyperINR：高效快速的隐式神经表示

    HyperINR: A Fast and Predictive Hypernetwork for Implicit Neural Representations via Knowledge Distillation. (arXiv:2304.04188v1 [cs.GR])

    [http://arxiv.org/abs/2304.04188](http://arxiv.org/abs/2304.04188)

    本文提出了一种基于知识蒸馏的超网络架构HyperINR，能够高效快速地构建出最先进推理性能的隐式神经表示（INR），并且支持交互式的照片级体积可视化。

    

    隐式神经表示（INRs）在科学可视化领域的数据生成和可视化任务中表现出巨大的潜力。然而，这些表示通常由大型多层感知器（MLPs）组成，对于单次前传需要数百万操作，从而阻碍交互式视觉探索。本文提出了HyperINR，一种新型超网络架构，能够直接预测紧凑INR的权重，通过同步利用多分辨率哈希编码单元的集合，从而使得结果INR具有最先进的推理性能(最高可达100倍的推理带宽)，并且能够支持交互式的照片级体积可视化。此外，还提出了一种基于知识蒸馏的训练框架，使得HyperINR即便在存在未见过的参数变化的情况下也能良好地进行泛化。

    Implicit Neural Representations (INRs) have recently exhibited immense potential in the field of scientific visualization for both data generation and visualization tasks. However, these representations often consist of large multi-layer perceptrons (MLPs), necessitating millions of operations for a single forward pass, consequently hindering interactive visual exploration. While reducing the size of the MLPs and employing efficient parametric encoding schemes can alleviate this issue, it compromises generalizability for unseen parameters, rendering it unsuitable for tasks such as temporal super-resolution. In this paper, we introduce HyperINR, a novel hypernetwork architecture capable of directly predicting the weights for a compact INR. By harnessing an ensemble of multiresolution hash encoding units in unison, the resulting INR attains state-of-the-art inference performance (up to 100x higher inference bandwidth) and can support interactive photo-realistic volume visualization. Addi
    
[^38]: 基于最近邻抽样的条件独立性检验

    Nearest-Neighbor Sampling Based Conditional Independence Testing. (arXiv:2304.04183v1 [cs.LG])

    [http://arxiv.org/abs/2304.04183](http://arxiv.org/abs/2304.04183)

    本文提出了一种基于最近邻抽样的条件独立性检验方法，通过1-最近邻来近似编码零假设的条件分布，理论上证明了生成样本的分布非常接近真实的条件分布，在此基础上采用分类器-based条件互信息估计器作为检验统计量。

    

    条件随机化检验（CRT）最近被提出用于测试随机变量X和Y在给定随机变量Z的条件下是否相互独立。CRT假定在零假设下X给定Z的条件分布已知，然后将其与原始数据的观察样本的分布相比较。本文旨在通过使用最近邻抽样来开发CRT的新的替代方法，而不需要假定X给定Z的分布形式。具体来说，我们利用计算效率高的1-最近邻来近似编码零假设的条件分布。然后理论上证明了生成样本的分布在总变差距离方面非常接近真实的条件分布。此外，我们将基于分类器的条件互信息估计器作为我们的检验统计量。检验统计量作为经验基础信息th。

    The conditional randomization test (CRT) was recently proposed to test whether two random variables X and Y are conditionally independent given random variables Z. The CRT assumes that the conditional distribution of X given Z is known under the null hypothesis and then it is compared to the distribution of the observed samples of the original data. The aim of this paper is to develop a novel alternative of CRT by using nearest-neighbor sampling without assuming the exact form of the distribution of X given Z. Specifically, we utilize the computationally efficient 1-nearest-neighbor to approximate the conditional distribution that encodes the null hypothesis. Then, theoretically, we show that the distribution of the generated samples is very close to the true conditional distribution in terms of total variation distance. Furthermore, we take the classifier-based conditional mutual information estimator as our test statistic. The test statistic as an empirical fundamental information th
    
[^39]: $\mu^2$-SGD: 通过双动量机制实现稳定的随机优化

    $\mu^2$-SGD: Stable Stochastic Optimization via a Double Momentum Mechanism. (arXiv:2304.04172v1 [cs.LG])

    [http://arxiv.org/abs/2304.04172](http://arxiv.org/abs/2304.04172)

    提出了一种新的梯度估计方法，结合了最近的两种与动量概念相关的机制，实现了稳定的随机优化，对学习率选择具有鲁棒性，在无噪声和有噪声情况下的收敛速率均为最优。

    

    我们考虑目标函数为平滑函数期望的随机凸优化问题。针对这种情况，我们建议一种新的梯度估计方法，结合了最近的两种与动量概念相关的机制。然后，我们设计了一种SGD样式的算法和一个加速版，利用这个新的估计器，并证明了这些新方法对学习率的选择具有鲁棒性。具体而言，我们表明，这些方法使用相同的固定学习率选择在无噪声和有噪声情况下的最优收敛速率。此外，对于有噪声的情况，我们表明这些方法在非常广泛的学习率范围内实现了相同的最优误差界。

    We consider stochastic convex optimization problems where the objective is an expectation over smooth functions. For this setting we suggest a novel gradient estimate that combines two recent mechanism that are related to notion of momentum. Then, we design an SGD-style algorithm as well as an accelerated version that make use of this new estimator, and demonstrate the robustness of these new approaches to the choice of the learning rate. Concretely, we show that these approaches obtain the optimal convergence rates for both noiseless and noisy case with the same choice of fixed learning rate. Moreover, for the noisy case we show that these approaches achieve the same optimal bound for a very wide range of learning rates.
    
[^40]: SLowcal-SGD：慢查询点提高了随机凸优化的Local-SGD算法（arXiv:2304.04169v1 [cs.LG]）

    SLowcal-SGD: Slow Query Points Improve Local-SGD for Stochastic Convex Optimization. (arXiv:2304.04169v1 [cs.LG])

    [http://arxiv.org/abs/2304.04169](http://arxiv.org/abs/2304.04169)

    本论文提出了一种利用慢查询点技术改进Local-SGD算法的方法，可以对抗异构情况下本地更新的偏差。

    

    在分布式学习场景中，M台计算机与参数服务器交互，通过多个通信轮次来最小化联合目标函数。我们关注异构情况，即不同计算机可能从不同的数据分布中抽取样本，设计了第一种可以证明优于两个最突出的分布式基准线——Minibatch-SGD和Local-SGD的本地更新方法。我们方法的关键在于慢查询技术，我们将其定制给分布式设置使用，从而更好地减轻本地更新带来的偏差。

    We consider distributed learning scenarios where M machines interact with a parameter server along several communication rounds in order to minimize a joint objective function. Focusing on the heterogeneous case, where different machines may draw samples from different data-distributions, we design the first local update method that provably benefits over the two most prominent distributed baselines: namely Minibatch-SGD and Local-SGD. Key to our approach is a slow querying technique that we customize to the distributed setting, which in turn enables a better mitigation of the bias caused by local updates.
    
[^41]: 面向图神经网络的对抗鲁棒神经结构搜索

    Adversarially Robust Neural Architecture Search for Graph Neural Networks. (arXiv:2304.04168v1 [cs.LG])

    [http://arxiv.org/abs/2304.04168](http://arxiv.org/abs/2304.04168)

    本文提出了G-RNA，一个面向图神经网络的对抗鲁棒神经结构搜索框架，通过添加图结构掩码操作来设计信息传递机制的一个鲁棒搜索空间，从而允许我们搜索防御性GNNs。

    

    图神经网络（GNN）在建模关系数据方面取得了巨大成功。然而，它们容易受到对抗攻击，这对将GNN应用于风险敏感领域构成了巨大威胁。现有的防御方法既不能保证面对新数据/任务或对抗攻击时的性能，也不能从架构角度提供理解GNN鲁棒性的见解。神经结构搜索（NAS）通过自动化GNN架构设计具有解决这个问题的潜力。然而，当前的图形NAS方法缺乏鲁棒的设计，易受对抗攻击。为了应对这些挑战，我们提出了一个面向GNNs的新型Robust神经结构搜索框架（G-RNA）。具体来说，我们通过在搜索空间中添加图结构掩码操作来设计信息传递机制的一个鲁棒搜索空间，其中包括各种防御操作候选人，并允许我们搜索防御性GNNs。此外，我们定义了一个鲁棒性指标。

    Graph Neural Networks (GNNs) obtain tremendous success in modeling relational data. Still, they are prone to adversarial attacks, which are massive threats to applying GNNs to risk-sensitive domains. Existing defensive methods neither guarantee performance facing new data/tasks or adversarial attacks nor provide insights to understand GNN robustness from an architectural perspective. Neural Architecture Search (NAS) has the potential to solve this problem by automating GNN architecture designs. Nevertheless, current graph NAS approaches lack robust design and are vulnerable to adversarial attacks. To tackle these challenges, we propose a novel Robust Neural Architecture search framework for GNNs (G-RNA). Specifically, we design a robust search space for the message-passing mechanism by adding graph structure mask operations into the search space, which comprises various defensive operation candidates and allows us to search for defensive GNNs. Furthermore, we define a robustness metric
    
[^42]: 基于经验的进化算法用于昂贵优化问题

    Experience-Based Evolutionary Algorithms for Expensive Optimization. (arXiv:2304.04166v1 [cs.NE])

    [http://arxiv.org/abs/2304.04166](http://arxiv.org/abs/2304.04166)

    本文研究了基于经验的优化方法，提出了一种基于经验的代理辅助进化算法(SAEA)框架，旨在通过充分利用相关问题所获得的经验来有效地解决难以优化的昂贵问题。

    

    优化算法与人类优化者非常不同。人类通过解决问题获得更多经验，这有助于解决新的未知问题。然而，优化算法通过解决更多问题从不获得任何经验。近年来，研究人员开始赋予优化算法一些经验学习的能力，即基于经验的优化。本文认为可以通过充分利用相关问题所获得的经验来有效地解决难以优化的问题。我们在昂贵优化的背景下展示了我们的想法，即通过尽可能少的适应度评估来寻找昂贵优化问题的近似最优解。为了实现这一目标，我们提出了一种基于经验的代理辅助进化算法(SAEA)框架，以增强昂贵问题的优化效率，其中经验是跨相关问题获得的。

    Optimization algorithms are very different from human optimizers. A human being would gain more experiences through problem-solving, which helps her/him in solving a new unseen problem. Yet an optimization algorithm never gains any experiences by solving more problems. In recent years, efforts have been made towards endowing optimization algorithms with some abilities of experience learning, which is regarded as experience-based optimization. In this paper, we argue that hard optimization problems could be tackled efficiently by making better use of experiences gained in related problems. We demonstrate our ideas in the context of expensive optimization, where we aim to find a near-optimal solution to an expensive optimization problem with as few fitness evaluations as possible. To achieve this, we propose an experience-based surrogate-assisted evolutionary algorithm (SAEA) framework to enhance the optimization efficiency of expensive problems, where experiences are gained across relat
    
[^43]: 持续学习中是否所有参数都会同样遗忘？

    Does Continual Learning Equally Forget All Parameters?. (arXiv:2304.04158v1 [cs.LG])

    [http://arxiv.org/abs/2304.04158](http://arxiv.org/abs/2304.04158)

    本文研究了神经网络中哪些模块更容易遗忘，并发现只有少数模块是更加任务特定且在任务之间敏感地改变的。因此，我们将遗忘主要归因于这些模块，并提出了一种高效的“遗忘优先微调”方法来解决这个问题。

    

    持续学习中的分布变化通常会导致神经网络的灾难性遗忘。尽管通过反复重放缓冲数据可以减轻这种情况，但每次重放非常耗时。本文研究了神经网络中哪些模块更容易被遗忘，并通过研究其持续学习过程中的训练动态来探讨这个问题。我们提出的度量表明，只有少数模块是更加任务特定且在任务之间敏感地改变的，而其他模块可以作为共同知识在任务之间共享。因此，我们将遗忘主要归因于前者，并发现仅在任何持续学习方法的末尾对它们进行微调可以带来非平凡的改进。由于被微调的参数数量很少，因此这种“遗忘优先微调（FPF）”在计算上非常高效。我们进一步提出了一种更高效、更简单的方法，它完全删除了每次重放，并用仅 $k$ 次 FPF 周期来替换它们。

    Distribution shift (e.g., task or domain shift) in continual learning (CL) usually results in catastrophic forgetting of neural networks. Although it can be alleviated by repeatedly replaying buffered data, the every-step replay is time-consuming. In this paper, we study which modules in neural networks are more prone to forgetting by investigating their training dynamics during CL. Our proposed metrics show that only a few modules are more task-specific and sensitively alter between tasks, while others can be shared across tasks as common knowledge. Hence, we attribute forgetting mainly to the former and find that finetuning them only on a small buffer at the end of any CL method can bring non-trivial improvement. Due to the small number of finetuned parameters, such ``Forgetting Prioritized Finetuning (FPF)'' is efficient in computation. We further propose a more efficient and simpler method that entirely removes the every-step replay and replaces them by only $k$-times of FPF period
    
[^44]: 处理子人群偏移的加权mixup方法

    Reweighted Mixup for Subpopulation Shift. (arXiv:2304.04148v1 [cs.LG])

    [http://arxiv.org/abs/2304.04148](http://arxiv.org/abs/2304.04148)

    RMIX是一种用于处理子人群偏移的简单实用方法，通过对“混合”样本进行重要性加权，探索邻域空间，从而获得更稳健的模型。

    

    子人群偏移在许多现实世界的应用中普遍存在，指的是训练集和测试集包含相同的子人群组，但具有不同的子人群比例。忽略子人群偏移可能导致显著的性能下降和公平性问题。重要性评估权重是处理子人群偏移的经典和有效方法。然而，最近的研究表明，大多数这些方法在应用于具有任意拟合训练样本能力的超参数化神经网络时，无法改善性能。在本文中，我们提出一种简单而实用的框架，称为加权mixup（RMIX），通过对“混合”样本进行重要性加权来减轻超参数化模型中的过拟合问题。由于利用mixup中的重加权，RMIX允许模型更多地探索少数样本的邻域空间，从而获得更稳健的模型。

    Subpopulation shift exists widely in many real-world applications, which refers to the training and test distributions that contain the same subpopulation groups but with different subpopulation proportions. Ignoring subpopulation shifts may lead to significant performance degradation and fairness concerns. Importance reweighting is a classical and effective way to handle the subpopulation shift. However, recent studies have recognized that most of these approaches fail to improve the performance especially when applied to over-parameterized neural networks which are capable of fitting any training samples. In this work, we propose a simple yet practical framework, called reweighted mixup (RMIX), to mitigate the overfitting issue in over-parameterized models by conducting importance weighting on the ''mixed'' samples. Benefiting from leveraging reweighting in mixup, RMIX allows the model to explore the vicinal space of minority samples more, thereby obtaining more robust model against 
    
[^45]: 进化聚类方法和概率神经网络的混合用于一次联邦学习分类：FedPNN

    FedPNN: One-shot Federated Classification via Evolving Clustering Method and Probabilistic Neural Network hybrid. (arXiv:2304.04147v1 [cs.LG])

    [http://arxiv.org/abs/2304.04147](http://arxiv.org/abs/2304.04147)

    本文提出了一种两阶段联邦学习方法，通过进化聚类方法和概率神经网络的混合来实现一次联邦学习分类，以保护隐私并解决通信开销和有限资源的问题。

    

    在金融、银行和医疗等领域，保护数据隐私至关重要。联邦学习（FL）由于其分散、分布式的训练和同时获得全局共享模型的保护隐私的能力而受到广泛关注。然而，FL面临着通信开销和有限的资源能力等挑战。因此，我们提出了一个两阶段联邦学习方法，以实现隐私保护的目标，并进行了以下首次研究：（i）在第一阶段，通过使用两种不同的分布作为噪声来生成合成数据集，并将其应用于改进的条件表生成对抗神经网络（CTGAN），（ii）在第二阶段，开发和采用联邦概率神经网络（FedPNN）来构建全局共享分类模型。我们还采用了合成数据集指标来检查生成的合成数据集的质量。

    Protecting data privacy is paramount in the fields such as finance, banking, and healthcare. Federated Learning (FL) has attracted widespread attention due to its decentralized, distributed training and the ability to protect the privacy while obtaining a global shared model. However, FL presents challenges such as communication overhead, and limited resource capability. This motivated us to propose a two-stage federated learning approach toward the objective of privacy protection, which is a first-of-its-kind study as follows: (i) During the first stage, the synthetic dataset is generated by employing two different distributions as noise to the vanilla conditional tabular generative adversarial neural network (CTGAN) resulting in modified CTGAN, and (ii) In the second stage, the Federated Probabilistic Neural Network (FedPNN) is developed and employed for building globally shared classification model. We also employed synthetic dataset metrics to check the quality of the generated syn
    
[^46]: RD-DPP: 码率-失真理论与分布式点过程相结合，实现多样化学习数据样本

    RD-DPP: Rate-Distortion Theory Meets Determinantal Point Process to Diversify Learning Data Samples. (arXiv:2304.04137v1 [cs.LG])

    [http://arxiv.org/abs/2304.04137](http://arxiv.org/abs/2304.04137)

    该论文介绍了一种基于码率-失真理论，结合分布式点过程的方法，用于多级分类中选择多样化的学习数据样本，相比现有方法具有更好的性能表现。

    

    在一些实际的学习任务中，如交通视频分析，可用训练样本的数量受到不同因素的限制，如有限的通信带宽和计算能力。因此，选择对学习系统质量做出最大贡献的多样化数据样本是至关重要的。选择多样化样本的一种流行方法是分布式点过程 (DPP)。然而，DPP存在一些已知的缺点，例如将样本数量限制为相似性矩阵的秩，并且不能为特定的学习任务（例如多级分类任务）定制。本文提出了一种基于码率-失真 (RD) 理论的衡量任务定向多样性的新方法，适用于多级分类。为此，我们建立了DPP和RD理论之间的基本关系，设计了RD-DPP，一种基于RD的价值函数，用于评估数据样本的多样性增益。我们还得到了一些特定情况下RD-DPP的闭合解，并在合成和真实数据集上进行了实验，表明我们所提出的方法在多样性优化方面的表现优于现有方法。

    In some practical learning tasks, such as traffic video analysis, the number of available training samples is restricted by different factors, such as limited communication bandwidth and computation power; therefore, it is imperative to select diverse data samples that contribute the most to the quality of the learning system. One popular approach to selecting diverse samples is Determinantal Point Process (DPP). However, it suffers from a few known drawbacks, such as restriction of the number of samples to the rank of the similarity matrix, and not being customizable for specific learning tasks (e.g., multi-level classification tasks). In this paper, we propose a new way of measuring task-oriented diversity based on the Rate-Distortion (RD) theory, appropriate for multi-level classification. To this end, we establish a fundamental relationship between DPP and RD theory, which led to designing RD-DPP, an RD-based value function to evaluate the diversity gain of data samples. We also ob
    
[^47]: 基于NeRF技术的卫星图像表面重建

    NeRF applied to satellite imagery for surface reconstruction. (arXiv:2304.04133v1 [cs.CV])

    [http://arxiv.org/abs/2304.04133](http://arxiv.org/abs/2304.04133)

    本文提出了Sat-NeRF模型，能够从少量的卫星图像集合中合成新的视角，并准确地估计场景表面的高程。

    

    本文提出了Sat-NeRF模型，是对最近引入的S-NeRF模型的修改实现。该模型能够从稀疏的卫星图像集合中合成新的视角，同时考虑到图片中的光照变化。训练好的模型还能够精确地估计场景表面的高程，这对卫星观测应用非常有帮助。S-NeRF方法改进了标准的NeRF方法，将辐射强度考虑为高反射率和入射辐照度的函数。这两个量都是模型的全连接神经网络枝条的输出，而后者则被视为来自太阳的直接光线和来自天空的漫反射颜色函数。该实现基于用缩放-裁剪技术增强的卫星图像数据集。对NeRF进行了超参数研究，得出了一些有趣的观察结果。

    We present Sat-NeRF, a modified implementation of the recently introduced Shadow Neural Radiance Field (S-NeRF) model. This method is able to synthesize novel views from a sparse set of satellite images of a scene, while accounting for the variation in lighting present in the pictures. The trained model can also be used to accurately estimate the surface elevation of the scene, which is often a desirable quantity for satellite observation applications. S-NeRF improves on the standard Neural Radiance Field (NeRF) method by considering the radiance as a function of the albedo and the irradiance. Both these quantities are output by fully connected neural network branches of the model, and the latter is considered as a function of the direct light from the sun and the diffuse color from the sky. The implementations were run on a dataset of satellite images, augmented using a zoom-and-crop technique. A hyperparameter study for NeRF was carried out, leading to intriguing observations on the 
    
[^48]: 在近似硬件上训练神经网络

    Training Neural Networks for Execution on Approximate Hardware. (arXiv:2304.04125v1 [cs.LG])

    [http://arxiv.org/abs/2304.04125](http://arxiv.org/abs/2304.04125)

    这篇论文介绍了如何针对近似硬件进行神经网络训练，加速了训练过程，为在需要进行推理任务的电池操作设备上实现高效深度学习提供了新的思路。

    

    近似计算方法在深度学习领域展现出了巨大的潜力。由于硬件成本降低，这些方法特别适用于受到功率预算限制的需要进行推理任务的电池操作设备。然而，由于缺乏有关训练方法的研究，近似计算尚未充分发挥其潜力。在本研究中，我们讨论了近似硬件的训练方法，展示了如何为近似硬件优化训练过程，并提出了可加速训练过程多达18倍的方法。

    Approximate computing methods have shown great potential for deep learning. Due to the reduced hardware costs, these methods are especially suitable for inference tasks on battery-operated devices that are constrained by their power budget. However, approximate computing hasn't reached its full potential due to the lack of work on training methods. In this work, we discuss training methods for approximate hardware. We demonstrate how training needs to be specialized for approximate hardware, and propose methods to speed up the training process by up to 18X.
    
[^49]: TC-VAE：揭示数据生成因素中的未知分布数据

    TC-VAE: Uncovering Out-of-Distribution Data Generative Factors. (arXiv:2304.04103v1 [cs.LG])

    [http://arxiv.org/abs/2304.04103](http://arxiv.org/abs/2304.04103)

    本文提出了一种基于总相关性的生成模型TC-VAE，可以揭示数据生成因素中的未知分布数据，在处理具有不平衡生成因素的数据集上表现优秀。

    

    揭示数据生成因素是解决解缠结学习的最终目标。本文提出了一种生成模型-TC-VAE，它可以基于所学的潜在表征和输入数据之间的总相关性下界进行优化，从而发现不在数据集中显式出现的变化因素。我们分析了在使用具有不平衡的生成因素数据集时，所提出的模型的效果，并在定量和定性实验中表明了TC-VAE的优越性。

    Uncovering data generative factors is the ultimate goal of disentanglement learning. Although many works proposed disentangling generative models able to uncover the underlying generative factors of a dataset, so far no one was able to uncover OOD generative factors (i.e., factors of variations that are not explicitly shown on the dataset). Moreover, the datasets used to validate these models are synthetically generated using a balanced mixture of some predefined generative factors, implicitly assuming that generative factors are uniformly distributed across the datasets. However, real datasets do not present this property. In this work we analyse the effect of using datasets with unbalanced generative factors, providing qualitative and quantitative results for widely used generative models. Moreover, we propose TC-VAE, a generative model optimized using a lower bound of the joint total correlation between the learned latent representations and the input data. We show that the proposed
    
[^50]: 通过可扩展的主题嵌入从连续新闻流中无监督地发现故事

    Unsupervised Story Discovery from Continuous News Streams via Scalable Thematic Embedding. (arXiv:2304.04099v1 [cs.IR])

    [http://arxiv.org/abs/2304.04099](http://arxiv.org/abs/2304.04099)

    本研究提出了一种新颖的主题嵌入方法和一个可扩展的无监督在线故事发现框架USTORY，可以动态表示文章和故事，并考虑它们共享的时间主题和新颖性，以帮助人们消化大量的新闻流。

    

    无监督地发现实时相关新闻文章故事，有助于人们在不需要昂贵人工注释的情况下消化大量的新闻流。现有的无监督在线故事发现研究的普遍方法是用符号或基于图的嵌入来表示新闻文章，并将它们逐步聚类成故事。最近的大型语言模型有望进一步改善嵌入，但是通过无差别地编码文章中的所有信息来直接采用这些模型无法有效处理富含文本且不断发展的新闻流。在这项工作中，我们提出了一种新颖的主题嵌入方法，使用现成的预训练句子编码器来动态表示文章和故事，并考虑它们共享的时间主题。为了实现无监督在线故事发现的想法，引入了一个可扩展框架USTORY，包括两个主要技术，即主题和时间感知的动态嵌入和新颖性感知的自适应聚类。

    Unsupervised discovery of stories with correlated news articles in real-time helps people digest massive news streams without expensive human annotations. A common approach of the existing studies for unsupervised online story discovery is to represent news articles with symbolic- or graph-based embedding and incrementally cluster them into stories. Recent large language models are expected to improve the embedding further, but a straightforward adoption of the models by indiscriminately encoding all information in articles is ineffective to deal with text-rich and evolving news streams. In this work, we propose a novel thematic embedding with an off-the-shelf pretrained sentence encoder to dynamically represent articles and stories by considering their shared temporal themes. To realize the idea for unsupervised online story discovery, a scalable framework USTORY is introduced with two main techniques, theme- and time-aware dynamic embedding and novelty-aware adaptive clustering, fuel
    
[^51]: 元卡洛调整朗之万(MALA)在光滑且等周条件下的混合简单证明

    A Simple Proof of the Mixing of Metropolis-Adjusted Langevin Algorithm under Smoothness and Isoperimetry. (arXiv:2304.04095v1 [stat.ML])

    [http://arxiv.org/abs/2304.04095](http://arxiv.org/abs/2304.04095)

    本文证明了，在光滑和等周条件下，MALA的混合时间仅与Hessian矩阵的trace有关，而与其算子范数和log-concave没有关系。

    

    本文研究了在$\mathbb{R}^d$上样本目标密度的元卡洛调整朗之万（MALA）的混合时间。我们假设目标密度满足$\psi_\mu$-等周和它的黑塞矩阵的trace和算子范数分别受$L$和$\Upsilon$的限制。我们的主要结论是，从热启动开始，为了达到$\epsilon$总变差距离，MALA在$O\left(\frac{(L\Upsilon)^{\frac12}}{\psi_\mu^2} \log\left(\frac{1}{\epsilon}\right)\right)$次迭代中混合。值得注意的是，该结果不仅适用于对数凹采样设置，而且混合时间仅取决于$\Upsilon$，而不是其上界$Ld$。在$m$-强对数凹和$L$-光滑采样设置中，我们的界限恢复了以前的MALA的最小值混合界限。

    We study the mixing time of Metropolis-Adjusted Langevin algorithm (MALA) for sampling a target density on $\mathbb{R}^d$. We assume that the target density satisfies $\psi_\mu$-isoperimetry and that the operator norm and trace of its Hessian are bounded by $L$ and $\Upsilon$ respectively. Our main result establishes that, from a warm start, to achieve $\epsilon$-total variation distance to the target density, MALA mixes in $O\left(\frac{(L\Upsilon)^{\frac12}}{\psi_\mu^2} \log\left(\frac{1}{\epsilon}\right)\right)$ iterations. Notably, this result holds beyond the log-concave sampling setting and the mixing time depends on only $\Upsilon$ rather than its upper bound $L d$. In the $m$-strongly logconcave and $L$-log-smooth sampling setting, our bound recovers the previous minimax mixing bound of MALA~\cite{wu2021minimax}.
    
[^52]: 具有亚群公平性约束的最优臂识别

    Best Arm Identification with Fairness Constraints on Subpopulations. (arXiv:2304.04091v1 [cs.LG])

    [http://arxiv.org/abs/2304.04091](http://arxiv.org/abs/2304.04091)

    本文解决了一个有关最优臂识别的问题，该问题要求所选臂必须对所有亚群都公平。我们提出了一个算法并证明其样本复杂度。

    

    我们提出、分析和解决了一个具有亚群公平性约束的最优臂识别问题（BAICS）。标准的最优臂识别问题旨在选择一个期望奖励最大的臂，其中期望是针对整个人群计算的。BAICS问题要求所选臂必须对所有亚群（例如，不同的族群、年龄组或客户类型）都公平，通过满足每个亚群条件下的期望奖励大于一些阈值的约束条件。BAICS问题旨在以高置信度正确鉴定出所有符合亚群约束条件的臂中期望奖励最大的臂。我们通过证明最小样本复杂度的最佳实现下界的闭式表示来分析BAICS问题的复杂度。然后，我们设计了一种算法，并证明该算法的样本复杂度与下界的阶数匹配。

    We formulate, analyze and solve the problem of best arm identification with fairness constraints on subpopulations (BAICS). Standard best arm identification problems aim at selecting an arm that has the largest expected reward where the expectation is taken over the entire population. The BAICS problem requires that an selected arm must be fair to all subpopulations (e.g., different ethnic groups, age groups, or customer types) by satisfying constraints that the expected reward conditional on every subpopulation needs to be larger than some thresholds. The BAICS problem aims at correctly identify, with high confidence, the arm with the largest expected reward from all arms that satisfy subpopulation constraints. We analyze the complexity of the BAICS problem by proving a best achievable lower bound on the sample complexity with closed-form representation. We then design an algorithm and prove that the algorithm's sample complexity matches with the lower bound in terms of order. A brief
    
[^53]: 基于深度学习的可解释的多标签孟加拉有害评论分类

    Interpretable Multi Labeled Bengali Toxic Comments Classification using Deep Learning. (arXiv:2304.04087v1 [cs.CL])

    [http://arxiv.org/abs/2304.04087](http://arxiv.org/abs/2304.04087)

    本文提出了一种基于深度学习的方法，用于分类孟加拉语的有害评论。使用LSTM和BERT嵌入实现了二元分类任务的高准确率，同时使用卷积神经网络和双向LSTM与注意机制组合实现了多标签分类，准确率和加权F1-score均较高。

    

    本文提出了一个基于深度学习的方案来分类孟加拉语的有害评论，首先使用二元分类模型确定评论是否有害，然后使用多标签分类器确定该评论属于哪种毒性类型。为此，我们准备了一个手动标注的数据集，其中包含16,073个实例，其中8,488个是有害的，并且任何有害的评论可能同时属于六种有害类型-低俗，仇恨，宗教，威胁，恶意和侮辱。在二元分类任务上，使用LSTM和BERT嵌入实现了89.42％的准确率；在多标签分类器方面，使用卷积神经网络和双向LSTM（CNN-BiLSTM）与注意机制组合，获得了78.92％的准确率和0.86的加权F1-score。为了解释预测结果并解释分类期间的单词特征重要性，该方法使用了LIME技术。

    This paper presents a deep learning-based pipeline for categorizing Bengali toxic comments, in which at first a binary classification model is used to determine whether a comment is toxic or not, and then a multi-label classifier is employed to determine which toxicity type the comment belongs to. For this purpose, we have prepared a manually labeled dataset consisting of 16,073 instances among which 8,488 are Toxic and any toxic comment may correspond to one or more of the six toxic categories - vulgar, hate, religious, threat, troll, and insult simultaneously. Long Short Term Memory (LSTM) with BERT Embedding achieved 89.42% accuracy for the binary classification task while as a multi-label classifier, a combination of Convolutional Neural Network and Bi-directional Long Short Term Memory (CNN-BiLSTM) with attention mechanism achieved 78.92% accuracy and 0.86 as weighted F1-score. To explain the predictions and interpret the word feature importance during classification by the propos
    
[^54]: 基于屏障-李亚普诺夫Actor-Critic强化学习方法的安全稳定控制

    A Barrier-Lyapunov Actor-Critic Reinforcement Learning Approach for Safe and Stable Control. (arXiv:2304.04066v1 [eess.SY])

    [http://arxiv.org/abs/2304.04066](http://arxiv.org/abs/2304.04066)

    本文提出了一种基于屏障-李亚普诺夫Actor-Critic（BLAC）框架，针对强化学习控制现实世界系统时的安全稳定控制问题提出了一种解决方案。其中，基于重放缓冲区采样的数据构建了CBF安全约束和CLF稳定约束，并使用增广拉格朗日方法来更新基于RL的控制器的参数。

    

    强化学习在视频游戏和机器人等领域展现出惊人的性能。然而，使用强化学习控制现实世界系统时，确保安全和稳定性仍然是一个重大挑战。在本文中，我们首先为强化学习系统提供安全和稳定性的定义，然后将控制屏障函数（CBF）和控制李亚普诺夫函数（CLF）方法与Actor-Critic方法相结合，提出了一种基于屏障-李亚普诺夫Actor-Critic（BLAC）框架，有助于保持系统的安全和稳定性。在该框架中，基于来自重放缓冲区采样的数据构建了CBF安全约束和CLF稳定约束，并使用增广拉格朗日方法来更新基于RL的控制器的参数。此外，还引入了一个备用控制器，以防RL控制器无法提供稳定控制。

    Reinforcement learning (RL) has demonstrated impressive performance in various areas such as video games and robotics. However, ensuring safety and stability, which are two critical properties from a control perspective, remains a significant challenge when using RL to control real-world systems. In this paper, we first provide definitions of safety and stability for the RL system, and then combine the control barrier function (CBF) and control Lyapunov function (CLF) methods with the actor-critic method in RL to propose a Barrier-Lyapunov Actor-Critic (BLAC) framework which helps maintain the aforementioned safety and stability for the system. In this framework, CBF constraints for safety and CLF constraint for stability are constructed based on the data sampled from the replay buffer, and the augmented Lagrangian method is used to update the parameters of the RL-based controller. Furthermore, an additional backup controller is introduced in case the RL-based controller cannot provide
    
[^55]: 神经网络生成响应曲线的反事实解释

    Counterfactual Explanations of Neural Network-Generated Response Curves. (arXiv:2304.04063v1 [cs.LG])

    [http://arxiv.org/abs/2304.04063](http://arxiv.org/abs/2304.04063)

    本文提出一种使用反事实解释（CFEs）确定神经网络黑盒生成的响应曲线上最具相关性的特征的方法，并将其应用于工业资产预测维护的案例研究中，可以解释模型的行为并检测异常行为的潜在原因。

    

    响应曲线展示了一个敏感系统对不同刺激的响应程度。然而，这类系统的反应可能对多个不一定独立的刺激（即输入特征）敏感。因此，为了一个选定的输入特征（称为“活动特征”）所生成的响应曲线的形状可能依赖于其他输入特征（称为“被动特征”）的值。在这项工作中，我们考虑了使用回归神经网络逼近响应的系统。我们提出使用反事实解释（CFEs）来确定通过神经网络黑盒生成的响应曲线上最具相关性的特征。 CFE是通过基于遗传算法的方法生成的，该方法解决了多目标优化问题。特别地，对于为主动特征生成的响应曲线，CFE找到需要修改的被动特征的最小组合，以改变曲线的形状。我们将我们的方法应用于两个工业资产预测维护的案例研究中，其中黑盒回归模型生成的响应曲线用于检测异常。我们演示了如何使用CFEs来解释这些模型的行为，并检测异常行为的潜在原因。

    Response curves exhibit the magnitude of the response of a sensitive system to a varying stimulus. However, response of such systems may be sensitive to multiple stimuli (i.e., input features) that are not necessarily independent. As a consequence, the shape of response curves generated for a selected input feature (referred to as "active feature") might depend on the values of the other input features (referred to as "passive features"). In this work we consider the case of systems whose response is approximated using regression neural networks. We propose to use counterfactual explanations (CFEs) for the identification of the features with the highest relevance on the shape of response curves generated by neural network black boxes. CFEs are generated by a genetic algorithm-based approach that solves a multi-objective optimization problem. In particular, given a response curve generated for an active feature, a CFE finds the minimum combination of passive features that need to be mod
    
[^56]: 利用多模态深度神经网络预测多发性硬化症疾病严重程度

    Predicting multiple sclerosis disease severity with multimodal deep neural networks. (arXiv:2304.04062v1 [cs.LG])

    [http://arxiv.org/abs/2304.04062](http://arxiv.org/abs/2304.04062)

    本研究提出使用患者的多模态EHR数据预测多发性硬化症疾病严重程度，以便实现早期干预和治疗。提高了预测准确性和模型复杂度。

    

    多发性硬化症（MS）是一种发展在人类大脑和脊髓中的慢性疾病，可能会导致神经永久性损伤或恶化。MS病情的严重程度是通过扩展残疾状态评分（EDSS）来监测的，该评分由几个功能子分数组成。早期和准确的MS疾病严重程度分类对于通过应用早期治疗干预策略来减缓或预防疾病进展至关重要。 近年来深度学习的进展和电子健康记录（EHR）的广泛应用为应用数据驱动和预测建模工具提供了机会。以往专注于利用单模态机器学习和深度学习算法的研究由于数据不足或模型简单而限制了预测准确性。在本文中，我们提出了使用患者的多模态纵向和横向EHR数据预测医院访问时的多发性硬化症疾病严重程度的想法。

    Multiple Sclerosis (MS) is a chronic disease developed in human brain and spinal cord, which can cause permanent damage or deterioration of the nerves. The severity of MS disease is monitored by the Expanded Disability Status Scale (EDSS), composed of several functional sub-scores. Early and accurate classification of MS disease severity is critical for slowing down or preventing disease progression via applying early therapeutic intervention strategies. Recent advances in deep learning and the wide use of Electronic Health Records (EHR) creates opportunities to apply data-driven and predictive modeling tools for this goal. Previous studies focusing on using single-modal machine learning and deep learning algorithms were limited in terms of prediction accuracy due to the data insufficiency or model simplicity. In this paper, we proposed an idea of using patients' multimodal longitudinal and longitudinal EHR data to predict multiple sclerosis disease severity at the hospital visit. This
    
[^57]: 学习量子多体态的基于能量的表示

    Learning Energy-Based Representations of Quantum Many-Body States. (arXiv:2304.04058v1 [quant-ph])

    [http://arxiv.org/abs/2304.04058](http://arxiv.org/abs/2304.04058)

    该论文提出了一种新的基于能量的生成量子多体态表示方法，能够以数据驱动的方式构建能够捕获量子多体态复杂相关性和对称性的表示，该方法高效地学习1D和2D的量子多体态，并可自然地纳入物理约束条件。

    

    有效地表示量子多体态在经典计算机上是一个极具实用意义的问题。理想的量子态表示结合了系统结构和对称性的简洁描述以及预测感兴趣的物理可观测量的能力。最近，已经采用了许多机器学习方法来构建这样的经典表示，使其能够预测可观测量并考虑物理对称性。然而，除非采用基于系统先验知识的专业先验形式，否则量子态的结构通常会丢失。此外，大多数这样的方法没有提供关于哪些状态比其他状态更容易学习的信息。在这里，我们提出了一种新的基于能量的生成量子多体态表示，该表示源自于用于模拟经典自旋系统的热态的Gibbs分布。基于先验信息，我们的方法以数据驱动的方式构建表示，捕获状态的复杂相关性和对称性。我们展示了我们的模型如何高效地学习1D和2D的量子多体态，无论是接近临界点还是远离临界点，以及如何自然地纳入物理约束条件，如守恒定律。

    Efficient representation of quantum many-body states on classical computers is a problem of enormous practical interest. An ideal representation of a quantum state combines a succinct characterization informed by the system's structure and symmetries, along with the ability to predict the physical observables of interest. A number of machine learning approaches have been recently used to construct such classical representations [1-6] which enable predictions of observables [7] and account for physical symmetries [8]. However, the structure of a quantum state gets typically lost unless a specialized ansatz is employed based on prior knowledge of the system [9-12]. Moreover, most such approaches give no information about what states are easier to learn in comparison to others. Here, we propose a new generative energy-based representation of quantum many-body states derived from Gibbs distributions used for modeling the thermal states of classical spin systems. Based on the prior informat
    
[^58]: tmn在SemEval-2023任务9中的应用：使用XLM-T、Google翻译和集成学习进行多语言推特亲密度检测

    tmn at SemEval-2023 Task 9: Multilingual Tweet Intimacy Detection using XLM-T, Google Translate, and Ensemble Learning. (arXiv:2304.04054v1 [cs.CL])

    [http://arxiv.org/abs/2304.04054](http://arxiv.org/abs/2304.04054)

    本文介绍了对于SemEval-2023的任务9，提出了一种基于transformer的系统，使用了集成学习，在多语言推特亲密度检测中排名第4，达到了0.5688的宏平均F1分数。为了提高对未见语言的性能表现，每个推特都进行了英文翻译的补充。

    

    本文介绍了一种基于transformer的系统，针对SemEval-2023任务9：多语言推特亲密度分析进行设计。任务的目的是预测一系列推特的亲密度，范围从1（完全不亲密）到5（非常亲密）。比赛的官方训练集包含六种语言的推特（英语、西班牙语、意大利语、葡萄牙语、法语和中文）。测试集包括六种给定的语言以及外部数据，其中包括训练集中未出现的四种语言（印地语、阿拉伯语、荷兰语和韩语）。我们提出了一种基于XLM-T的解决方案，即适用于Twitter领域的多语种RoBERTa模型的集成。为了提高对未见语言的性能表现，我们对每条推特进行了英文翻译的补充。我们探究了将翻译数据应用于微调中看到的语言与未看到的语言的transformer模型的有效性，并估计使用翻译数据的策略。我们的解决方案在50个团队中排名第4，并实现了0.5688的宏平均F1分数。

    The paper describes a transformer-based system designed for SemEval-2023 Task 9: Multilingual Tweet Intimacy Analysis. The purpose of the task was to predict the intimacy of tweets in a range from 1 (not intimate at all) to 5 (very intimate). The official training set for the competition consisted of tweets in six languages (English, Spanish, Italian, Portuguese, French, and Chinese). The test set included the given six languages as well as external data with four languages not presented in the training set (Hindi, Arabic, Dutch, and Korean). We presented a solution based on an ensemble of XLM-T, a multilingual RoBERTa model adapted to the Twitter domain. To improve the performance of unseen languages, each tweet was supplemented by its English translation. We explored the effectiveness of translated data for the languages seen in fine-tuning compared to unseen languages and estimated strategies for using translated data in transformer-based models. Our solution ranked 4th on the leade
    
[^59]: 仅解码器或编码器-解码器？将语言模型解释为正则化的编码器-解码器

    Decoder-Only or Encoder-Decoder? Interpreting Language Model as a Regularized Encoder-Decoder. (arXiv:2304.04052v1 [cs.CL])

    [http://arxiv.org/abs/2304.04052](http://arxiv.org/abs/2304.04052)

    该论文通过对正则化编码器-解码器结构进行比较，分析了仅解码器语言模型框架和编码器-解码器框架的效果。

    

    序列到序列（seq2seq）任务旨在基于给定的输入源序列生成目标序列。 传统上，大多数seq2seq任务都是通过编码器-解码器框架解决的，该框架需要编码器来编码源序列，并且需要解码器来生成目标文本。最近，出现了许多新方法，将仅解码器语言模型直接应用于seq2seq任务。尽管在将语言模型应用于seq2seq任务方面取得了重大进展，但仍然缺乏对仅解码器语言模型架构有效性的彻底分析。本文旨在通过对正则化编码器-解码器结构进行分析来解决这一差距。该结构旨在复制经典仅解码器语言模型中的所有行为，但具有编码器和解码器，从而更容易进行分析。

    The sequence-to-sequence (seq2seq) task aims at generating the target sequence based on the given input source sequence. Traditionally, most of the seq2seq task is resolved by the Encoder-Decoder framework which requires an encoder to encode the source sequence and a decoder to generate the target text. Recently, a bunch of new approaches have emerged that apply decoder-only language models directly to the seq2seq task. Despite the significant advancements in applying language models to the seq2seq task, there is still a lack of thorough analysis on the effectiveness of the decoder-only language model architecture. This paper aims to address this gap by conducting a detailed comparison between the encoder-decoder architecture and the decoder-only language model framework through the analysis of a regularized encoder-decoder structure. This structure is designed to replicate all behaviors in the classical decoder-only language model but has an encoder and a decoder making it easier to b
    
[^60]: 利用深度 Q-Learning 和图神经网络生成图着色启发式算法

    Generating a Graph Colouring Heuristic with Deep Q-Learning and Graph Neural Networks. (arXiv:2304.04051v1 [cs.LG])

    [http://arxiv.org/abs/2304.04051](http://arxiv.org/abs/2304.04051)

    本文通过使用深度 Q-Learning 和图神经网络生成 ReLCol 启发式算法，解决了图着色问题，且相较于现有算法具有竞争性和优越性能。强化学习是探究图着色问题更有前途的一种方法。

    

    图着色问题是将标签或颜色分配给图的顶点，以使得相邻的两个顶点不会共享相同的颜色。本文研究了深度强化学习是否可用于发现一个竞争性的图着色构造启发式算法。我们提出的方法，ReLCol，使用深度 Q-Learning 与图神经网络进行特征提取，并采用一种新颖的图参数化方法来提高性能。使用具有不同拓扑结构的标准基准图，我们在实验中评估了 ReLCol 学习到的启发式算法与现有构造算法的优缺点，并证明了强化学习是进一步研究图着色问题的有希望的方向。

    The graph colouring problem consists of assigning labels, or colours, to the vertices of a graph such that no two adjacent vertices share the same colour. In this work we investigate whether deep reinforcement learning can be used to discover a competitive construction heuristic for graph colouring. Our proposed approach, ReLCol, uses deep Q-learning together with a graph neural network for feature extraction, and employs a novel way of parameterising the graph that results in improved performance. Using standard benchmark graphs with varied topologies, we empirically evaluate the benefits and limitations of the heuristic learned by ReLCol relative to existing construction algorithms, and demonstrate that reinforcement learning is a promising direction for further research on the graph colouring problem.
    
[^61]: 带反向随机微分方程的深度生成建模

    Deep Generative Modeling with Backward Stochastic Differential Equations. (arXiv:2304.04049v1 [cs.LG])

    [http://arxiv.org/abs/2304.04049](http://arxiv.org/abs/2304.04049)

    该文提出了一种新的深度生成模型，名为BSDE-Gen，它将反向随机微分方程的灵活性与深度神经网络的强大能力结合，用于生成高维复杂目标数据，特别是在图像生成领域。BSDE-Gen的生成建模过程中引入了随机性和不确定性，是一种有效而自然的生成高维数据的方法。

    

    本文提出了一种新的深度生成模型，名为BSDE-Gen，它将反向随机微分方程（BSDEs）的灵活性与深度神经网络的强大能力相结合，以生成高维复杂目标数据，特别是在图像生成领域。在生成建模过程中引入随机性和不确定性，使BSDE-Gen成为一种有效而自然的生成高维数据的方法。本文提供了BSDE-Gen的理论框架，描述了其模型架构，给出了用于训练的最大平均偏差（MMD）损失函数，并报告了实验结果。

    This paper proposes a novel deep generative model, called BSDE-Gen, which combines the flexibility of backward stochastic differential equations (BSDEs) with the power of deep neural networks for generating high-dimensional complex target data, particularly in the field of image generation. The incorporation of stochasticity and uncertainty in the generative modeling process makes BSDE-Gen an effective and natural approach for generating high-dimensional data. The paper provides a theoretical framework for BSDE-Gen, describes its model architecture, presents the maximum mean discrepancy (MMD) loss function used for training, and reports experimental results.
    
[^62]: 多边形化器：一种自回归建筑轮廓线提取算法

    Polygonizer: An auto-regressive building delineator. (arXiv:2304.04048v1 [cs.CV])

    [http://arxiv.org/abs/2304.04048](http://arxiv.org/abs/2304.04048)

    一种新的图像自回归模型，可以直接进行形状推断，并且可以直接用于基于矢量的工作流，该模型在地理空间规划中的矢量化表现中领先于先前的方法。

    

    在地理空间规划中，以矢量格式表示对象通常是必不可少的，因为这种格式可以轻松转换为下游任务，如Web开发、图形或设计。虽然这些问题通常使用语义分割来解决，但需要额外的后处理才能对对象进行非平凡地矢量化，我们提出了一种图像到序列的模型，可以直接进行形状推断，并且可以直接用于基于矢量的工作流。我们以各种方式展示了模型的性能，包括对与遥感应用中常见的变化或伪影对应的图像输入的扰动。当使用地面真值边界框（每个图像一个对象）时，我们的模型在误差方面优于先前的作品，实现了最低的最大切线角误差。

    In geospatial planning, it is often essential to represent objects in a vectorized format, as this format easily translates to downstream tasks such as web development, graphics, or design. While these problems are frequently addressed using semantic segmentation, which requires additional post-processing to vectorize objects in a non-trivial way, we present an Image-to-Sequence model that allows for direct shape inference and is ready for vector-based workflows out of the box. We demonstrate the model's performance in various ways, including perturbations to the image input that correspond to variations or artifacts commonly encountered in remote sensing applications. Our model outperforms prior works when using ground truth bounding boxes (one object per image), achieving the lowest maximum tangent angle error.
    
[^63]: 深度反正则化集成提供可靠的域外不确定性量化

    Deep Anti-Regularized Ensembles provide reliable out-of-distribution uncertainty quantification. (arXiv:2304.04042v1 [cs.LG])

    [http://arxiv.org/abs/2304.04042](http://arxiv.org/abs/2304.04042)

    本文提出一种基于反正则化的深度集成方法，适用于高维回归和分类中不确定性量化问题。实验证明该方法在内部和外部不确定性估计方面具有优越性。

    

    本文考虑了高维回归和分类中不确定性量化的问题，深度集成已被证明是一种有前途的方法。最近的研究表明，在训练范围之外，深度集成往往返回过度自信的估计值，这是一种主要的限制，因为在现实场景中经常遇到偏移分布。本文的主要挑战是解决增加集成输出的多样性和进行准确的内部预测之间的权衡问题。我们展示了一种解决方法，即使用具有大权重的网络的集成很可能实现这两个目标。我们提出了一种简单实用的方法来生成这样的集成，该方法基于惩罚小权重的原始反正则化术语和控制权重增加的过程，以保持内部分布损失在可接受的阈值范围内。所开发的方法不需要任何外部数据或复杂的训练技术。在各种基准数据集上进行的广泛实验表明，与最先进的深度集成相比，我们的方法在内部和外部不确定性估计方面具有优越性。

    We consider the problem of uncertainty quantification in high dimensional regression and classification for which deep ensemble have proven to be promising methods. Recent observations have shown that deep ensemble often return overconfident estimates outside the training domain, which is a major limitation because shifted distributions are often encountered in real-life scenarios. The principal challenge for this problem is to solve the trade-off between increasing the diversity of the ensemble outputs and making accurate in-distribution predictions. In this work, we show that an ensemble of networks with large weights fitting the training data are likely to meet these two objectives. We derive a simple and practical approach to produce such ensembles, based on an original anti-regularization term penalizing small weights and a control process of the weight increase which maintains the in-distribution loss under an acceptable threshold. The developed approach does not require any out-
    
[^64]: RescueSNN: 在永久故障下提高脉冲神经网络加速器的可靠性

    RescueSNN: Enabling Reliable Executions on Spiking Neural Network Accelerators under Permanent Faults. (arXiv:2304.04041v1 [cs.NE])

    [http://arxiv.org/abs/2304.04041](http://arxiv.org/abs/2304.04041)

    RescueSNN是一种用于减轻SNN芯片计算引擎中永久故障的方法，可维持性能和质量并减少重新训练成本。

    

    为了在资源受限的嵌入式系统上最大化脉冲神经网络（SNN）处理的性能和能效，采用了专门的硬件加速器/芯片。然而，这些SNN芯片可能会受到永久故障的影响，这可能会导致重大的精度降低和系统故障。本文提出了一种名为RescueSNN的新方法，可以在不需要额外重新训练的情况下减轻SNN芯片计算引擎中的永久故障，从而显着降低设计时间和重新训练成本，同时保持吞吐量和质量。

    To maximize the performance and energy efficiency of Spiking Neural Network (SNN) processing on resource-constrained embedded systems, specialized hardware accelerators/chips are employed. However, these SNN chips may suffer from permanent faults which can affect the functionality of weight memory and neuron behavior, thereby causing potentially significant accuracy degradation and system malfunctioning. Such permanent faults may come from manufacturing defects during the fabrication process, and/or from device/transistor damages (e.g., due to wear out) during the run-time operation. However, the impact of permanent faults in SNN chips and the respective mitigation techniques have not been thoroughly investigated yet. Toward this, we propose RescueSNN, a novel methodology to mitigate permanent faults in the compute engine of SNN chips without requiring additional retraining, thereby significantly cutting down the design time and retraining costs, while maintaining the throughput and qu
    
[^65]: EnforceSNN: 在嵌入式系统中考虑近似DRAM，实现弹性和节能的脉冲神经网络推理

    EnforceSNN: Enabling Resilient and Energy-Efficient Spiking Neural Network Inference considering Approximate DRAMs for Embedded Systems. (arXiv:2304.04039v1 [cs.NE])

    [http://arxiv.org/abs/2304.04039](http://arxiv.org/abs/2304.04039)

    EnforceSNN 提出了一个新的设计框架，在嵌入式系统中考虑近似DRAM，使用量化权重降低DRAM的访问能量，实现了弹性和节能的SNN推理。

    

    脉冲神经网络（SNN）由于其生物可行计算能力，在无监督设置下具有高精度和低操作功率/能量。先前的研究发现，基于DRAM的 off-chip 内存访问占据了SNN处理的能量消耗。然而，现有的工作并未优化DRAM的每次访问的能量，从而阻碍了基于SNN的系统实现进一步的节能效益。为了大幅度降低DRAM的每次访问的能量，一个有效的解决方案是降低DRAM供电电压，但这可能会导致DRAM单元的错误（即所谓的近似DRAM）。为此，我们提出了EnforceSNN，一种新的设计框架，使用降压DRAM实现弹性和节能的 SNN 推理在嵌入式系统中。我们 EnforceSNN 的关键机制是:(1)采用量化权重降低DRAM的访问能量；(2)设计了一种高效的DRAM映射p

    Spiking Neural Networks (SNNs) have shown capabilities of achieving high accuracy under unsupervised settings and low operational power/energy due to their bio-plausible computations. Previous studies identified that DRAM-based off-chip memory accesses dominate the energy consumption of SNN processing. However, state-of-the-art works do not optimize the DRAM energy-per-access, thereby hindering the SNN-based systems from achieving further energy efficiency gains. To substantially reduce the DRAM energy-per-access, an effective solution is to decrease the DRAM supply voltage, but it may lead to errors in DRAM cells (i.e., so-called approximate DRAM). Towards this, we propose \textit{EnforceSNN}, a novel design framework that provides a solution for resilient and energy-efficient SNN inference using reduced-voltage DRAM for embedded systems. The key mechanisms of our EnforceSNN are: (1) employing quantized weights to reduce the DRAM access energy; (2) devising an efficient DRAM mapping p
    
[^66]: 探究鲁棒性模型与生成模型之间的联系

    Exploring the Connection between Robust and Generative Models. (arXiv:2304.04033v1 [cs.LG])

    [http://arxiv.org/abs/2304.04033](http://arxiv.org/abs/2304.04033)

    本文探究鲁棒性判别分类器与生成模型之间的联系，并发现在输入空间中，非定向对抗点非常可能在鉴别性模型中隐含的生成模型中拥有低能量，提出了一种名为高能量PGD的新攻击。

    

    本研究将通过分解鲁棒性判别分类器的损失函数来探究鲁棒性判别分类器与能量基模型(EBM)形式的生成模型之间的联系。我们发现，尽管常见的假设是对抗点离开了输入数据的流形，但是在输入空间中，非定向对抗点非常可能在鉴别性模型中隐含的生成模型中拥有低能量。我们提出了两个证据:非定向攻击的概率甚至比自然数据还要高，并且随着攻击强度的增加，其概率也会增加。这使我们能够轻松地检测它们并设计一种名为高能量PGD的新攻击，能够欺骗分类器但具有与数据集相似的能量。

    We offer a study that connects robust discriminative classifiers trained with adversarial training (AT) with generative modeling in the form of Energy-based Models (EBM). We do so by decomposing the loss of a discriminative classifier and showing that the discriminative model is also aware of the input data density. Though a common assumption is that adversarial points leave the manifold of the input data, our study finds out that, surprisingly, untargeted adversarial points in the input space are very likely under the generative model hidden inside the discriminative classifier -- have low energy in the EBM. We present two evidence: untargeted attacks are even more likely than the natural data and their likelihood increases as the attack strength increases. This allows us to easily detect them and craft a novel attack called High-Energy PGD that fools the classifier yet has energy similar to the data set.
    
[^67]: NeBLa: 使用神经啤酒-兰伯特法从全景放射线图中重建口腔结构的三维模型

    NeBLa: Neural Beer-Lambert for 3D Reconstruction of Oral Structures from Panoramic Radiographs. (arXiv:2304.04027v1 [eess.IV])

    [http://arxiv.org/abs/2304.04027](http://arxiv.org/abs/2304.04027)

    该论文提出了一个新的框架：NeBLa，可以从全景放射线图中通过神经啤酒-兰伯特法重建精确的3D口腔结构模型。

    

    全景X线片（全景放射线图，PX）是常用于牙科检查的成像模式。然而，与3D锥形束计算机断层扫描（CBCT）相比，PX的适用性有限，因为PX只提供口腔结构的二维扁平图像。在本文中，我们提出了一个新的框架，用于从真实的PX图像估计3D口腔结构。由于PX和CBCT数据的匹配不多，我们在训练时使用了从CBCT模拟的PX，但在推理时使用了真实的全景放射线片。我们提出了一种新的光线采样方法，受到全景放射线成像原理的启发，利用啤酒-兰伯特定律导出渲染函数生成模拟全景放射线图。我们的模型由三个部分组成：转换模块，生成模块和精炼模块。转换模块将真实的全景放射线图转换为模拟的训练图像风格。生成模块利用射线采样方法得到的模拟全景放射线图约束下的输入图像生成3D结构。精炼模块改善了3D结构的平滑性和一致性。实验结果表明，我们提出的方法可以从全景放射线片提供的有限信息中生成精确的3D牙科模型。

    Panoramic radiography (panoramic X-ray, PX) is a widely used imaging modality for dental examination. However, its applicability is limited as compared to 3D Cone-beam computed tomography (CBCT), because PX only provides 2D flattened images of the oral structure. In this paper, we propose a new framework which estimates 3D oral structure from real-world PX images. Since there are not many matching PX and CBCT data, we used simulated PX from CBCT for training, however, we used real-world panoramic radiographs at the inference time. We propose a new ray-sampling method to make simulated panoramic radiographs inspired by the principle of panoramic radiography along with the rendering function derived from the Beer-Lambert law. Our model consists of three parts: translation module, generation module, and refinement module. The translation module changes the real-world panoramic radiograph to the simulated training image style. The generation module makes the 3D structure from the input ima
    
[^68]: 一种考虑人-工匹配的团队组建问题的强化学习辅助遗传规划算法

    A Reinforcement Learning-assisted Genetic Programming Algorithm for Team Formation Problem Considering Person-Job Matching. (arXiv:2304.04022v1 [cs.NE])

    [http://arxiv.org/abs/2304.04022](http://arxiv.org/abs/2304.04022)

    研究提出了一种强化学习辅助遗传规划算法来解决考虑人-工匹配的团队组建问题，采用集合种群策略和代理模型加快算法学习过程，实现勘探和利用的平衡。

    

    高效的团队对于公司成功完成新项目至关重要。为解决考虑人-工匹配的团队组建问题（TFP-PJM），构建了一个0-1整数规划模型，该模型考虑了人-工匹配和团队成员通信意愿对团队效率的影响，使用直觉模糊数计算人-工匹配得分。然后，提出了一种强化学习辅助遗传规划算法（RL-GP）以提高解决方案的质量。RL-GP采用集合种群策略。在每一代种群进化之前，代理根据获得的信息从四种种群搜索模式中选择一种，从而实现了勘探和利用的良好平衡。此外，算法使用代理模型评估个体生成的组建方案，加快算法学习过程。然后，进行了一系列对比实验以验证算法的有效性。

    An efficient team is essential for the company to successfully complete new projects. To solve the team formation problem considering person-job matching (TFP-PJM), a 0-1 integer programming model is constructed, which considers both person-job matching and team members' willingness to communicate on team efficiency, with the person-job matching score calculated using intuitionistic fuzzy numbers. Then, a reinforcement learning-assisted genetic programming algorithm (RL-GP) is proposed to enhance the quality of solutions. The RL-GP adopts the ensemble population strategies. Before the population evolution at each generation, the agent selects one from four population search modes according to the information obtained, thus realizing a sound balance of exploration and exploitation. In addition, surrogate models are used in the algorithm to evaluate the formation plans generated by individuals, which speeds up the algorithm learning process. Afterward, a series of comparison experiments 
    
[^69]: 硬件感知有效块设计中的算术强度平衡卷积

    Arithmetic Intensity Balancing Convolution for Hardware-aware Efficient Block Design. (arXiv:2304.04016v1 [cs.LG])

    [http://arxiv.org/abs/2304.04016](http://arxiv.org/abs/2304.04016)

    本文提出的算术强度平衡卷积（ABConv）可以在不牺牲准确性的情况下，显著降低延迟，并增强硬件性能，该方法已在Arm Ethos-U65 NPU上得到验证，可用于替换一些MobileNetV1和ResNet50的任务。

    

    随着深度学习的发展，边缘设备和轻量级神经网络变得更加重要。为了减少AI加速器的延迟，不仅需要降低FLOPs，还需要增强硬件性能。我们提出了算术强度平衡卷积（ABConv），以解决卷积小空间大小的小权重算术强度限制整体强度的问题。ABConv可以增加整体算术强度的最大界限，并显著降低延迟，而不牺牲准确性。我们在Arm Ethos-U65 NPU上以多种配置测试了ABConv的延迟和硬件性能，并将其用于CIFAR100图像分类的MobileNetV1和ResNet50中的一些替换任务。

    As deep learning advances, edge devices and lightweight neural networks are becoming more important. To reduce latency in the AI accelerator, it's essential to not only reduce FLOPs but also enhance hardware performance. We proposed an arithmetic intensity balancing convolution (ABConv) to address the issue of the overall intensity being limited by the small weight arithmetic intensity for convolution with a small spatial size. ABConv increased the maximum bound of overall arithmetic intensity and significantly reduced latency, without sacrificing accuracy. We tested the latency and hardware performance of ABConv on the Arm Ethos-U65 NPU in various configurations and used it to replace some of MobileNetV1 and ResNet50 in image classification for CIFAR100.
    
[^70]: 一种用于实时伺服电机过载故障检测的嵌入式卷积神经网络方法的新转换

    A new transformation for embedded convolutional neural network approach toward real-time servo motor overload fault-detection. (arXiv:2304.04005v1 [cs.LG])

    [http://arxiv.org/abs/2304.04005](http://arxiv.org/abs/2304.04005)

    本论文提出了一种新的嵌入式卷积神经网络方法，用于实时检测直流伺服电机的过载故障，该方法可以提取尽可能多的特征并在低内存微控制器中实现有效的检测。

    

    直流伺服电机的超载是工业中的一个主要问题，许多公司面临着找到专业操作员的问题，而人工监测可能不是一个有效的解决方案。因此，本文提出了一种采用新的转换的嵌入式人工智能（AI）方法，利用卷积神经网络（CNN）从实时输入信号中提取故障，而无需人为干预。我们的主要目的是从输入信号中提取尽可能多的特征，以实现一个放松的数据集，从而得到一个有效但紧凑的网络，提供实时故障检测，甚至在低内存微控制器中也可以实现。此外，还提出了一种故障检测方法，即同步双电机系统，以在故障事件中采取行动。为了实现这个目的，对每个直流伺服电机的输出电流进行一维输入信号的监测和转换成为一个3D数据堆栈，然后将CNN实施到处理器中以检测与输入信号相对应的任何故障。

    Overloading in DC servo motors is a major concern in industries, as many companies face the problem of finding expert operators, and also human monitoring may not be an effective solution. Therefore, this paper proposed an embedded Artificial intelligence (AI) approach using a Convolutional Neural Network (CNN) using a new transformation to extract faults from real-time input signals without human interference. Our main purpose is to extract as many as possible features from the input signal to achieve a relaxed dataset that results in an effective but compact network to provide real-time fault detection even in a low-memory microcontroller. Besides, fault detection method a synchronous dual-motor system is also proposed to take action in faulty events. To fulfill this intention, a one-dimensional input signal from the output current of each DC servo motor is monitored and transformed into a 3d stack of data and then the CNN is implemented into the processor to detect any fault corresp
    
[^71]: SimbaML：使用增强数据连接机械模型和机器学习模型。

    SimbaML: Connecting Mechanistic Models and Machine Learning with Augmented Data. (arXiv:2304.04000v1 [cs.LG])

    [http://arxiv.org/abs/2304.04000](http://arxiv.org/abs/2304.04000)

    SimbaML是一个机器学习工具，它通过机械模型补充真实世界的数据集，实现了从合成到真实数据的转移学习、数据增强、物理启发式机器学习方法的基准测试等多项功能。

    

    训练复杂的机器学习模型需要大量数据集，但对于许多应用程序来说，收集这些数据集往往是困难或昂贵的。如果有系统动态的先验知识，则可以使用机械模型来补充真实世界的数据。我们提出了SimbaML（基于仿真的机器学习），这是一个开源工具，它通过普通微分方程模型生成逼真的合成数据集，并直接将其用于机器学习管道的分析和包含。 SimbaML方便地启用了从合成到真实数据的转移学习，数据增强，确定对数据收集的需求以及基准测试物理启发式机器学习方法。SimbaML可在https://pypi.org/project/simba-ml/上获取。

    Training sophisticated machine learning (ML) models requires large datasets that are difficult or expensive to collect for many applications. If prior knowledge about system dynamics is available, mechanistic representations can be used to supplement real-world data. We present SimbaML (Simulation-Based ML), an open-source tool that unifies realistic synthetic dataset generation from ordinary differential equation-based models and the direct analysis and inclusion in ML pipelines. SimbaML conveniently enables investigating transfer learning from synthetic to real-world data, data augmentation, identifying needs for data collection, and benchmarking physics-informed ML approaches. SimbaML is available from https://pypi.org/project/simba-ml/.
    
[^72]: REDf：基于长短期记忆网络的智能电网可再生能源需求预测模型

    REDf: A Renewable Energy Demand Forecasting Model for Smart Grids using Long Short Term Memory Network. (arXiv:2304.03997v1 [cs.LG])

    [http://arxiv.org/abs/2304.03997](http://arxiv.org/abs/2304.03997)

    本文提出了一种基于长短期记忆网络的智能电网可再生能源需求预测模型REDf，可以提供准确的能量需求预测，改善可再生能源的集成，实验结果表明其准确度优于其他模型。

    

    随着世界向更可持续的能源未来发展，将可再生能源源纳入电网的集成变得越来越重要。然而，可再生能源的间歇性使电网管理和确保稳定的电力供应变得具有挑战性。本文提出了一种基于深度学习的方法来预测智能电网中的能量需求，可以通过提供准确的能量需求预测来改善可再生能源的集成。我们使用长短期记忆网络来捕捉能럟需求数据中的复杂模式和依赖关系，这些网络特别适用于时间序列数据。所提出的方法使用了四个历史能量需求数据集，这些数据集来自不同的能源分配公司，包括美国电力、Commonwealth Edison、Dayton Power and Light以及宾夕法尼亚-新泽西-马里兰互联网。该方法还将REDf模型与其他两个深度学习模型和基准模型进行比较。实验结果表明，我们提出的REDf模型在平均绝对误差、均方根误差和决定系数等准确度指标方面优于其他模型。因此，REDf可以作为可再生能源需求预测的可靠工具，并提高可再生能源纳入智能电网的能力。

    The integration of renewable energy sources into the power grid is becoming increasingly important as the world moves towards a more sustainable energy future. However, the intermittent nature of renewable energy sources can make it challenging to manage the power grid and ensure a stable supply of electricity. In this paper, we propose a deep learning-based approach for predicting energy demand in a smart power grid, which can improve the integration of renewable energy sources by providing accurate predictions of energy demand. We use long short-term memory networks, which are well-suited for time series data, to capture complex patterns and dependencies in energy demand data. The proposed approach is evaluated using four datasets of historical energy demand data from different energy distribution companies including American Electric Power, Commonwealth Edison, Dayton Power and Light, and Pennsylvania-New Jersey-Maryland Interconnection. The proposed model is also compared with two 
    
[^73]: 用图论统一刻画差分隐私可学习性

    A Unified Characterization of Private Learnability via Graph Theory. (arXiv:2304.03996v1 [cs.LG])

    [http://arxiv.org/abs/2304.03996](http://arxiv.org/abs/2304.03996)

    本文提供了一个统一的框架，使用图论的语言刻画了差分隐私的两种情形下，纯粹和近似的学习性。我们通过定义矛盾图$G$来捕捉 $\mathcal{H}$ 的组合结构，发现分数团数和团数是描述差分隐私学习性的重要因素，并提出了几种算法对其进行估计。

    

    我们提供了一个统一的框架来刻画纯粹的和近似的差分隐私学习性。该框架使用了图论的语言:对于一个概念类 $\mathcal{H}$,我们定义了 $\mathcal{H}$ 的矛盾图 $G$。它的顶点是可实现的数据集，如果两个数据集 $S$，$S'$ 相互矛盾(即，在 $S$ 和 $S'$ 中有一个点 $x$ 具有不同的标记)，则它们之间有一条边连接。我们的主要发现是，$G$ 的组合结构与在差分隐私下学习 $\mathcal{H}$ 密切相关。在纯粹的差分隐私下学习 $\mathcal{H}$ 的捕获为 $G$ 的分数团数。在近似差分隐私下学习 $\mathcal{H}$ 的捕获为 $G$ 的团数。因此，我们确定了描述差分隐私可学习性的图论维度：团维和分数团维。同时，我们揭示了矛盾图的一些性质，这些性质可能是独立感兴趣的。我们还提出了几种算法来估计 $G$ 的这些度量，通过这些算法，我们实现了几种概念类的实验研究。

    We provide a unified framework for characterizing pure and approximate differentially private (DP) learnabiliity. The framework uses the language of graph theory: for a concept class $\mathcal{H}$, we define the contradiction graph $G$ of $\mathcal{H}$. It vertices are realizable datasets, and two datasets $S,S'$ are connected by an edge if they contradict each other (i.e., there is a point $x$ that is labeled differently in $S$ and $S'$). Our main finding is that the combinatorial structure of $G$ is deeply related to learning $\mathcal{H}$ under DP. Learning $\mathcal{H}$ under pure DP is captured by the fractional clique number of $G$. Learning $\mathcal{H}$ under approximate DP is captured by the clique number of $G$. Consequently, we identify graph-theoretic dimensions that characterize DP learnability: the clique dimension and fractional clique dimension. Along the way, we reveal properties of the contradiction graph which may be of independent interest. We also suggest several o
    
[^74]: 通过元黑盒优化发现基于注意力的遗传算法

    Discovering Attention-Based Genetic Algorithms via Meta-Black-Box Optimization. (arXiv:2304.03995v1 [cs.NE])

    [http://arxiv.org/abs/2304.03995](http://arxiv.org/abs/2304.03995)

    本文提出了一种全新的数据驱动方法，通过元黑盒优化发现基于注意力的遗传算法。该算法在多个优化任务上表现出色，通常选择少量高度适应的变体，并通过学习的注意机制来适应其搜索策略。

    

    遗传算法是一类黑盒优化算法，受到生物进化原理的启发而来。虽然它们提供了一种通用的优化工具，但它们的特定实例可能是启发式的，并受到松散的生物直觉的影响。在这项工作中，我们探索了一种根本不同的方法：在给定足够灵活的遗传算子参数化的情况下，我们以数据驱动的方式发现全新的遗传算法。更具体地，我们将选择和变异率自适应参数化为交叉和自注意模块，并使用元黑盒优化来演化它们在一组不同的优化任务上的参数。所得到的学习遗传算法优于最先进的自适应基线遗传算法，并且远远超出了元训练设置。学习到的算法可以应用于先前未见过的优化问题、搜索维度和评估预算。我们注释其决策过程，并展示它通常选择少量高度适应的变体，并通过其学习的注意机制来适应其搜索策略。

    Genetic algorithms constitute a family of black-box optimization algorithms, which take inspiration from the principles of biological evolution. While they provide a general-purpose tool for optimization, their particular instantiations can be heuristic and motivated by loose biological intuition. In this work we explore a fundamentally different approach: Given a sufficiently flexible parametrization of the genetic operators, we discover entirely new genetic algorithms in a data-driven fashion. More specifically, we parametrize selection and mutation rate adaptation as cross- and self-attention modules and use Meta-Black-Box-Optimization to evolve their parameters on a set of diverse optimization tasks. The resulting Learned Genetic Algorithm outperforms state-of-the-art adaptive baseline genetic algorithms and generalizes far beyond its meta-training settings. The learned algorithm can be applied to previously unseen optimization problems, search dimensions & evaluation budgets. We c
    
[^75]: 比较两种分类算法的块正则化5×2交叉验证McNemar检验

    Block-regularized 5$\times$2 Cross-validated McNemar's Test for Comparing Two Classification Algorithms. (arXiv:2304.03990v1 [cs.LG])

    [http://arxiv.org/abs/2304.03990](http://arxiv.org/abs/2304.03990)

    本论文提出了一种块正则化5×2交叉验证McNemar检验，该方法通过规范化训练集之间的重叠记录来产生高质量的误差率估计，相较于传统的留置方法有更高的功率和稳定性。

    

    在比较两种分类算法的任务中，广泛使用的McNemar检验旨在推断出两种分类算法的错误率之间存在重大差异。然而，传统的McNemar检验的功率通常不太理想，因为测试中的留置（HO）方法仅使用一次训练验证拆分，这通常会产生高度变化的错误率估计。相反，交叉验证（CV）方法在多次重复HO方法的基础上产生稳定的估计，因此CV方法在提高McNemar检验功率方面具有巨大优势。在所有类型的CV方法中，块正则化5×2 CV（BCV）在许多先前的研究中已经显示出比其他CV方法在算法比较任务中更为优越，因为5×2 BCV可以通过使所有训练集之间的重叠记录数规范化来产生高质量的误差率估计。

    In the task of comparing two classification algorithms, the widely-used McNemar's test aims to infer the presence of a significant difference between the error rates of the two classification algorithms. However, the power of the conventional McNemar's test is usually unpromising because the hold-out (HO) method in the test merely uses a single train-validation split that usually produces a highly varied estimation of the error rates. In contrast, a cross-validation (CV) method repeats the HO method in multiple times and produces a stable estimation. Therefore, a CV method has a great advantage to improve the power of McNemar's test. Among all types of CV methods, a block-regularized 5$\times$2 CV (BCV) has been shown in many previous studies to be superior to the other CV methods in the comparison task of algorithms because the 5$\times$2 BCV can produce a high-quality estimator of the error rate by regularizing the numbers of overlapping records between all training sets. In this stu
    
[^76]: DiscoVars: 一种新的数据分析视角-应用于聚类变量选择

    DiscoVars: A New Data Analysis Perspective -- Application in Variable Selection for Clustering. (arXiv:2304.03983v1 [cs.LG])

    [http://arxiv.org/abs/2304.03983](http://arxiv.org/abs/2304.03983)

    DiscoVars是一种新的变量选择方法，它通过创建变量之间的依赖网络并根据图中心性度量排名它们来确定变量的重要性，适用于聚类等学习任务。

    

    我们提出了一种新的数据分析视角来确定变量的重要性，而不考虑底层的学习任务。传统上，无论是分类问题还是回归问题，变量选择都被认为是监督学习的重要步骤。当与数据收集和存储相关的成本相当高时，如遥感数据，变量选择也变得至关重要。因此，我们提出了一种新的方法，通过首先创建所有变量之间的依赖网络，然后通过图中心性度量来排名它们（即节点），从而从数据中选择重要变量。根据首选中心度量选择前n个变量将得到一个强有力的候选变量子集，供进一步学习任务使用，例如聚类。我们将我们的工具展示为Shiny应用程序，这是一个用户友好的接口开发环境。我们还扩展了用户界面，用于两种文献中知名的无监督变量选择方法的比较。

    We present a new data analysis perspective to determine variable importance regardless of the underlying learning task. Traditionally, variable selection is considered an important step in supervised learning for both classification and regression problems. The variable selection also becomes critical when costs associated with the data collection and storage are considerably high for cases like remote sensing. Therefore, we propose a new methodology to select important variables from the data by first creating dependency networks among all variables and then ranking them (i.e. nodes) by graph centrality measures. Selecting Top-$n$ variables according to preferred centrality measure will yield a strong candidate subset of variables for further learning tasks e.g. clustering. We present our tool as a Shiny app which is a user-friendly interface development environment. We also extend the user interface for two well-known unsupervised variable selection methods from literature for compar
    
[^77]: 基于不确定性的开放集学习用于视网膜异常识别

    Uncertainty-inspired Open Set Learning for Retinal Anomaly Identification. (arXiv:2304.03981v1 [cs.LG])

    [http://arxiv.org/abs/2304.03981](http://arxiv.org/abs/2304.03981)

    提出了基于不确定性的开放集(UIOS)模型，用于处理训练中未见过的类别样本，该模型通过计算不确定性得分来表达其置信度，并在多个测试数据集中表现优异，为真实世界的视网膜异常筛查提供了一个强大的方法。

    

    人工智能在实际视网膜异常分类应用中的一个主要限制是无法识别训练过程中未见过的类别样本。为解决这一障碍，我们提出了一种基于不确定性的开放集(UIOS)模型，该模型使用了9个常见视网膜病变的眼底图像进行训练。除了每个类别的概率，UIOS还计算了不确定性得分来表达其置信度。我们的UIOS模型通过设置阈值策略，在内部测试数据集、外部测试数据集和非典型测试数据集中的F1分别达到了99.55％、97.01％和91.91％，相比标准人工智能模型的F1分别为92.20％、80.69％和64.74％。此外，UIOS正确预测了罕见视网膜疾病、低质量眼底图像和非眼底图像等数据集中的高不确定性分数，提示需要手动检查。这项工作为真实世界的视网膜异常筛查提供了一个强大的方法。

    Failure to recognize samples from the classes unseen during training is a major limit of artificial intelligence (AI) in real-world implementation of retinal anomaly classification. To resolve this obstacle, we propose an uncertainty-inspired open-set (UIOS) model which was trained with fundus images of 9 common retinal conditions. Besides the probability of each category, UIOS also calculates an uncertainty score to express its confidence. Our UIOS model with thresholding strategy achieved an F1 score of 99.55%, 97.01% and 91.91% for the internal testing set, external testing set and non-typical testing set, respectively, compared to the F1 score of 92.20%, 80.69% and 64.74% by the standard AI model. Furthermore, UIOS correctly predicted high uncertainty scores, which prompted the need for a manual check, in the datasets of rare retinal diseases, low-quality fundus images, and non-fundus images. This work provides a robust method for real-world screening of retinal anomalies.
    
[^78]: RobCaps: 评估胶囊网络在仿射变换和对抗性攻击中的鲁棒性

    RobCaps: Evaluating the Robustness of Capsule Networks against Affine Transformations and Adversarial Attacks. (arXiv:2304.03973v1 [cs.LG])

    [http://arxiv.org/abs/2304.03973](http://arxiv.org/abs/2304.03973)

    本文评估了CapsNet在仿射变换和对抗性攻击方面的鲁棒性。在MNIST，GTSRB和CIFAR10数据集上的测试结果显示，与传统CNN相比，CapsNet实现了更好的对抗示例和仿射变换鲁棒性。

    

    胶囊网络(CapsNet)能够在图像分类任务中分层保持多个对象之间的姿态关系。除了实现高准确性外，在安全关键的应用中部署CapsNet的另一个相关因素是其对输入变换和恶意对抗性攻击的鲁棒性。在本文中，我们系统地分析和评估了影响CapsNet鲁棒性的不同因素，与传统的卷积神经网络(CNNs)进行了比较。为了进行全面比较，我们在MNIST，GTSRB和CIFAR10数据集上测试了两个CapsNet模型和两个CNN模型，以及这些数据集的仿射变换版本。通过深入分析，我们展示了这些架构的哪些特性更有助于增加其鲁棒性以及其局限性。总体而言，与类似数量的传统CNN相比，CapsNet实现了更好的对抗示例和仿射变换鲁棒性。

    Capsule Networks (CapsNets) are able to hierarchically preserve the pose relationships between multiple objects for image classification tasks. Other than achieving high accuracy, another relevant factor in deploying CapsNets in safety-critical applications is the robustness against input transformations and malicious adversarial attacks.  In this paper, we systematically analyze and evaluate different factors affecting the robustness of CapsNets, compared to traditional Convolutional Neural Networks (CNNs). Towards a comprehensive comparison, we test two CapsNet models and two CNN models on the MNIST, GTSRB, and CIFAR10 datasets, as well as on the affine-transformed versions of such datasets. With a thorough analysis, we show which properties of these architectures better contribute to increasing the robustness and their limitations. Overall, CapsNets achieve better robustness against adversarial examples and affine transformations, compared to a traditional CNN with a similar number 
    
[^79]: 用注意力表格学习预测水泵状态

    Pump It Up: Predict Water Pump Status using Attentive Tabular Learning. (arXiv:2304.03969v1 [cs.LG])

    [http://arxiv.org/abs/2304.03969](http://arxiv.org/abs/2304.03969)

    本文利用TabNet模型，结合基于树的算法和神经网络的优势，预测了坦桑尼亚水泵的维修状态，并通过比较表明TabNet在训练不平衡数据时性能更好。

    

    水危机是全球关注的焦点问题。在干旱国家，及时维护水泵对于依靠井水的社区至关重要。本文利用序列化的注意力深度神经结构TabNet，分析预测坦桑尼亚水泵维修状态。该模型结合了基于树的算法和神经网络的优点，实现了端到端的训练，模型可解释性，稀疏特征选择以及在表格数据上的高效学习。最后，我们将TabNet的表现与像XGBoost、LightGBM、CatBoost等流行的梯度树提升算法进行比较，展示了如何在训练不平衡数据时，通过选择聚焦损失（focal loss）作为目标函数进一步提高性能。

    Water crisis is a crucial concern around the globe. Appropriate and timely maintenance of water pumps in drought-hit countries is vital for communities relying on the well. In this paper, we analyze and apply a sequential attentive deep neural architecture, TabNet, for predicting water pump repair status in Tanzania. The model combines the valuable benefits of tree-based algorithms and neural networks, enabling end-to-end training, model interpretability, sparse feature selection, and efficient learning on tabular data. Finally, we compare the performance of TabNet with popular gradient tree-boosting algorithms like XGBoost, LightGBM,CatBoost, and demonstrate how we can further uplift the performance by choosing focal loss as the objective function while training on imbalanced data.
    
[^80]: 量化模型的鲁棒性基准测试

    Benchmarking the Robustness of Quantized Models. (arXiv:2304.03968v1 [cs.LG])

    [http://arxiv.org/abs/2304.03968](http://arxiv.org/abs/2304.03968)

    量化模型在受到各种噪声的影响时表现出脆弱性，较低位的量化对抗攻击更具弹性，但更容易受到自然扰动和系统噪声的影响。

    

    量化已经成为在资源有限的设备上部署深度神经网络(DNNs)的重要技术。然而，在现实世界应用中，量化模型在受到各种噪声的影响时表现出脆弱性。尽管评估量化对鲁棒性的影响很重要，但是关于这个主题的现有研究有限且常常忽略了已经建立的鲁棒性评估原则，导致了不完整和无法下结论的研究结果。为了填补这一空白，我们在ImageNet上充分评估了量化模型对各种噪声(对抗攻击、自然扰动和系统噪声)的鲁棒性。广泛的实验表明，较低位的量化对抗攻击更具弹性，但更容易受到自然扰动和系统噪声的影响。值得注意的是，我们的研究发现，脉冲噪声(在自然扰动中)和最近邻插值(在系统噪声中)对量化模型的鲁棒性影响最大。

    Quantization has emerged as an essential technique for deploying deep neural networks (DNNs) on devices with limited resources. However, quantized models exhibit vulnerabilities when exposed to various noises in real-world applications. Despite the importance of evaluating the impact of quantization on robustness, existing research on this topic is limited and often disregards established principles of robustness evaluation, resulting in incomplete and inconclusive findings. To address this gap, we thoroughly evaluated the robustness of quantized models against various noises (adversarial attacks, natural corruptions, and systematic noises) on ImageNet. Extensive experiments demonstrate that lower-bit quantization is more resilient to adversarial attacks but is more susceptible to natural corruptions and systematic noises. Notably, our investigation reveals that impulse noise (in natural corruptions) and the nearest neighbor interpolation (in systematic noises) have the most significan
    
[^81]: 鲁棒的深度学习模型对抗语义保持攻击的研究

    Robust Deep Learning Models Against Semantic-Preserving Adversarial Attack. (arXiv:2304.03955v1 [cs.LG])

    [http://arxiv.org/abs/2304.03955](http://arxiv.org/abs/2304.03955)

    该论文提出了一种新的攻击机制，SPA攻击，用于研究深度学习模型对联合干扰的鲁棒性，并可用于增强对抗训练。实验结果表明，SPA攻击比其他方法更加具有挑战性。

    

    深度学习模型很容易被小的 $l_p$-norm 对抗干扰以及自然干扰所误导。虽然对抗中对每种干扰的鲁棒性已得到探索，但有效地处理对联合干扰的鲁棒性仍是一种挑战。为此，本文提出了一种新的攻击机制，称为语义保持对抗（SPA）攻击，以研究深度学习模型对联合干扰的鲁棒性，并可用于增强对抗训练。具体而言，作者引入了属性操纵器来生成自然且易于被人理解的干扰，以及噪声生成器来生成多样化的对抗噪声。基于这些综合的干扰噪声，优化属性值和多样性变量来生成联合干扰样本。为鲁棒训练，作者对生成联合干扰的样本进行对抗性训练深度学习模型。实验结果在四个基准测试中表明，SPA攻击比其他方法更加具有挑战性。

    Deep learning models can be fooled by small $l_p$-norm adversarial perturbations and natural perturbations in terms of attributes. Although the robustness against each perturbation has been explored, it remains a challenge to address the robustness against joint perturbations effectively. In this paper, we study the robustness of deep learning models against joint perturbations by proposing a novel attack mechanism named Semantic-Preserving Adversarial (SPA) attack, which can then be used to enhance adversarial training. Specifically, we introduce an attribute manipulator to generate natural and human-comprehensible perturbations and a noise generator to generate diverse adversarial noises. Based on such combined noises, we optimize both the attribute value and the diversity variable to generate jointly-perturbed samples. For robust training, we adversarially train the deep learning model against the generated joint perturbations. Empirical results on four benchmarks show that the SPA 
    
[^82]: FlexMoE：通过动态设备配置扩展大规模稀疏预训练模型训练

    FlexMoE: Scaling Large-scale Sparse Pre-trained Model Training via Dynamic Device Placement. (arXiv:2304.03946v1 [cs.DC])

    [http://arxiv.org/abs/2304.03946](http://arxiv.org/abs/2304.03946)

    本文提出了一个名为FlexMoE的DNN训练框架，通过动态数据流系统性、透明地解决动态数据流带来的低效问题，提高了稀疏门控专家混合的训练效率。

    

    随着数据量的增加，使用大规模预训练模型以将知识存储到大量模型参数中成为一种趋势。这些模型的训练由大量的密集代数操作组成，需要大量的硬件资源。最近，稀疏门控专家混合（MoE）越来越受欢迎，并在各种下游任务中展示了可观的预训练可扩展性。然而，由于路由不平衡和波动问题，这种稀疏条件计算在实际系统中可能并不如预期那么有效。通常，MoE正在成为数据生命周期中的新的数据分析范例，并面临着以前从未有过的规模、复杂性和颗粒度的独特挑战。

    With the increasing data volume, there is a trend of using large-scale pre-trained models to store the knowledge into an enormous number of model parameters. The training of these models is composed of lots of dense algebras, requiring a huge amount of hardware resources. Recently, sparsely-gated Mixture-of-Experts (MoEs) are becoming more popular and have demonstrated impressive pretraining scalability in various downstream tasks. However, such a sparse conditional computation may not be effective as expected in practical systems due to the routing imbalance and fluctuation problems. Generally, MoEs are becoming a new data analytics paradigm in the data life cycle and suffering from unique challenges at scales, complexities, and granularities never before possible.  In this paper, we propose a novel DNN training framework, FlexMoE, which systematically and transparently address the inefficiency caused by dynamic dataflow. We first present an empirical analysis on the problems and oppo
    
[^83]: 知识关系排序增强异构学习交互模型用于神经图遗忘知识追踪

    Knowledge Relation Rank Enhanced Heterogeneous Learning Interaction Modeling for Neural Graph Forgetting Knowledge Tracing. (arXiv:2304.03945v1 [cs.LG])

    [http://arxiv.org/abs/2304.03945](http://arxiv.org/abs/2304.03945)

    提出了一种新的知识追踪模型NGFKT，通过校准技能关系矩阵和Q矩阵降低主观标记的影响，并引入知识关系排序机制来模拟不同关系的重要性，应用图卷积网络建模不同类型节点之间的异构交互，能够更好地进行复杂、动态的知识追踪。

    

    近年来，知识追踪模型已经应用于教育数据挖掘中，例如自注意力知识追踪模型（SAKT），它建模了练习和知识概念之间的关系。然而，传统知识追踪模型中的关系建模只考虑静态的问题-知识关系和知识-知识关系，并将这些关系同等重视。这种关系建模难以避免主观标记的影响，并单独考虑练习和KCs之间，或KCs和KCs之间的关系。本文提出了一种新颖的知识追踪模型，命名为知识关系排序增强异构学习交互模型用于神经图遗忘知识追踪（NGFKT），通过校准技能关系矩阵和Q矩阵降低主观标记的影响，并应用图卷积网络（GCN）来建模不同类型节点之间的异构交互，即练习，Kcs和学生。NGFKT模型引入了知识关系排序机制来模拟不同关系的重要性，从而增强了复杂、动态的知识追踪过程的建模。在三个公共数据集上的实验结果表明，所提出的NGFKT模型在预测准确性和AUC方面的性能优于现有方法。

    Recently, knowledge tracing models have been applied in educational data mining such as the Self-attention knowledge tracing model(SAKT), which models the relationship between exercises and Knowledge concepts(Kcs). However, relation modeling in traditional Knowledge tracing models only considers the static question-knowledge relationship and knowledge-knowledge relationship and treats these relationships with equal importance. This kind of relation modeling is difficult to avoid the influence of subjective labeling and considers the relationship between exercises and KCs, or KCs and KCs separately. In this work, a novel knowledge tracing model, named Knowledge Relation Rank Enhanced Heterogeneous Learning Interaction Modeling for Neural Graph Forgetting Knowledge Tracing(NGFKT), is proposed to reduce the impact of the subjective labeling by calibrating the skill relation matrix and the Q-matrix and apply the Graph Convolutional Network(GCN) to model the heterogeneous interactions betwe
    
[^84]: 实现逼真的胎儿脑部超声成像合成

    Towards Realistic Ultrasound Fetal Brain Imaging Synthesis. (arXiv:2304.03941v1 [eess.IV])

    [http://arxiv.org/abs/2304.03941](http://arxiv.org/abs/2304.03941)

    本文使用GAN合成胎儿脑部超声图像，解决了数据稀缺性问题，并证明了GAN-based方法可以生成稳定、逼真的超声图像，为医学AI和ML方法提供了可靠的数据集。

    

    产前超声成像是评估胎儿健康的首选方法。然而，由于临床数据量不足、患者隐私、病变罕见和数据收集和验证的专家有限等原因，公共的超声胎儿成像数据集很少。为了解决这种数据稀缺性，我们提出了基于生成式对抗网络（GAN）的模型，包括扩散超分辨率GAN和基于变形器的GAN，用来合成来自一个公共数据集的胎儿超声脑平面图像。我们报告了GAN-based方法可以产生256x256像素大小的胎儿超声经小脑脑图像平面，并且训练稳定损失，其中，扩散超分辨率GAN（平均7.04，FID值低于5.09 at epoch 10）的FID值低于变形器GAN（平均36.0）。

    Prenatal ultrasound imaging is the first-choice modality to assess fetal health. Medical image datasets for AI and ML methods must be diverse (i.e. diagnoses, diseases, pathologies, scanners, demographics, etc), however there are few public ultrasound fetal imaging datasets due to insufficient amounts of clinical data, patient privacy, rare occurrence of abnormalities in general practice, and limited experts for data collection and validation. To address such data scarcity, we proposed generative adversarial networks (GAN)-based models, diffusion-super-resolution-GAN and transformer-based-GAN, to synthesise images of fetal ultrasound brain planes from one public dataset. We reported that GAN-based methods can generate 256x256 pixel size of fetal ultrasound trans-cerebellum brain image plane with stable training losses, resulting in lower FID values for diffusion-super-resolution-GAN (average 7.04 and lower FID 5.09 at epoch 10) than the FID values of transformer-based-GAN (average 36.0
    
[^85]: 无监督语音表示池化的矢量量化方法

    Unsupervised Speech Representation Pooling Using Vector Quantization. (arXiv:2304.03940v1 [cs.LG])

    [http://arxiv.org/abs/2304.03940](http://arxiv.org/abs/2304.03940)

    该论文提出了一种新颖的无监督语音表示池化方法，通过矢量量化压缩声学上相似的表示，不需要额外的训练，并在多个下游任务上进行了评估和分析。

    

    随着大规模自监督模型生成通用语音表示，将一个模型应用到多个下游任务已成为一种事实标准。然而，池化问题仍然存在；语音表示的长度固有地是可变的。尽管忽略了语音的特性，例如不同长度的音素，但通常使用简单的平均池化方法。因此，我们设计了一种新颖的池化方法，通过矢量量化来压缩声学上相似的表示，与基于注意力的池化方法不同，不需要额外的训练。此外，我们评估了各种无监督池化方法在各种自监督模型上的表现。我们收集了散落在语音和文本领域的不同方法，并在各种任务上进行评估：关键字识别、说话人识别、意图分类和情感识别。最后，我们对我们的方法进行定量和定性分析，将其与有监督的池化方法进行比较。

    With the advent of general-purpose speech representations from large-scale self-supervised models, applying a single model to multiple downstream tasks is becoming a de-facto approach. However, the pooling problem remains; the length of speech representations is inherently variable. The naive average pooling is often used, even though it ignores the characteristics of speech, such as differently lengthed phonemes. Hence, we design a novel pooling method to squash acoustically similar representations via vector quantization, which does not require additional training, unlike attention-based pooling. Further, we evaluate various unsupervised pooling methods on various self-supervised models. We gather diverse methods scattered around speech and text to evaluate on various tasks: keyword spotting, speaker identification, intent classification, and emotion recognition. Finally, we quantitatively and qualitatively analyze our method, comparing it with supervised pooling methods.
    
[^86]: 神经网络的最后一层公平微调简单有效

    Last-Layer Fairness Fine-tuning is Simple and Effective for Neural Networks. (arXiv:2304.03935v1 [cs.LG])

    [http://arxiv.org/abs/2304.03935](http://arxiv.org/abs/2304.03935)

    本文提出了一种新颖的公平性微调神经网络的框架，利用已预训练的神经网络和不关注公平性的损失微调神经网络的最后一层。实验证明该方法在基准数据集上实现了高水平的公平性，同时保留标准性能指标。

    

    随着机器学习在现代数据科学中得到广泛应用，算法公平性已成为一个重要关注点，并且提出了多种公平性标准。其中，在学习过程中施加公平性约束，即进行处理公平性训练，已成为一种流行的训练方法，因为与后处理方法不同，它们不需要在测试期间访问敏感属性。虽然在经典机器学习模型中对施加公平性约束进行了广泛研究，但这些技术对深度神经网络的影响仍不清楚。最近的研究表明，在目标函数中添加公平性约束会导致大型模型过度拟合公平性标准，如何解决这一挑战是一个重要的开放问题。为了解决这个问题，我们利用预训练和微调的智慧和能力，并开发了一种简单而新颖的框架来训练公平的神经网络。我们的方法是在满足感兴趣的公平性约束的少量标记数据上，使用不关注公平性的损失微调已预训练的神经网络。实验证明，我们的方法在基准数据集上实现了高水平的公平性，而不牺牲标准性能指标。此外，我们证明了我们的方法足够灵活，可以纳入任何感兴趣的公平性约束，并且对于高维数据可以进行几乎没有额外计算的扩展。

    As machine learning has been deployed ubiquitously across applications in modern data science, algorithmic fairness has become a great concern and varieties of fairness criteria have been proposed. Among them, imposing fairness constraints during learning, i.e. in-processing fair training, has been a popular type of training method because they don't require accessing sensitive attributes during test time in contrast to post-processing methods. Although imposing fairness constraints have been studied extensively for classical machine learning models, the effect these techniques have on deep neural networks is still unclear. Recent research has shown that adding fairness constraints to the objective function leads to severe over-fitting to fairness criteria in large models, and how to solve this challenge is an important open question. To address this challenge, we leverage the wisdom and power of pre-training and fine-tuning and develop a simple but novel framework to train fair neural
    
[^87]: 通过温度分布流实现高效多模态采样

    Efficient Multimodal Sampling via Tempered Distribution Flow. (arXiv:2304.03933v1 [stat.ME])

    [http://arxiv.org/abs/2304.03933](http://arxiv.org/abs/2304.03933)

    采样高维分布是一个基本的问题，现有的基于输运的采样方法存在局限性，TemperFlow通过自适应地学习温度分布，解决了多模态问题，并证明了优于其他方法。

    

    从高维分布中采样是统计研究和实践中的一个基本问题。但是，当目标密度函数不规范化且包含孤立模式时，就会出现巨大的挑战。为了解决这个问题，我们通过拟合一个被称为输运映射的可逆变换映射（在参考概率测量和目标分布之间），使得通过输运映射将参考样本推向前沿即可实现从目标分布中进行采样。我们通过使用Wasserstein梯度流理论理论分析了现有的基于输运的采样方法的局限性，并提出了一种名为TemperFlow的新方法来解决多模态问题。TemperFlow自适应地学习一系列温度分布，以逐步接近目标分布，并证明它克服了现有方法的局限性。各种实验证明了这种新型采样器相对于现有采样方法的卓越性能。

    Sampling from high-dimensional distributions is a fundamental problem in statistical research and practice. However, great challenges emerge when the target density function is unnormalized and contains isolated modes. We tackle this difficulty by fitting an invertible transformation mapping, called a transport map, between a reference probability measure and the target distribution, so that sampling from the target distribution can be achieved by pushing forward a reference sample through the transport map. We theoretically analyze the limitations of existing transport-based sampling methods using the Wasserstein gradient flow theory, and propose a new method called TemperFlow that addresses the multimodality issue. TemperFlow adaptively learns a sequence of tempered distributions to progressively approach the target distribution, and we prove that it overcomes the limitations of existing methods. Various experiments demonstrate the superior performance of this novel sampler compared 
    
[^88]: 3D GAN与潜空间：综述

    3D GANs and Latent Space: A comprehensive survey. (arXiv:2304.03932v1 [cs.CV])

    [http://arxiv.org/abs/2304.03932](http://arxiv.org/abs/2304.03932)

    3D GAN是生成三维重建、点云重建和3D语义场景完成的新型生成模型。选择噪声分布对应着潜空间，理解其结构有助于微调生成样本。该论文综述了3D GAN及其训练方法，针对未来研究提出了潜在方向。

    

    生成对抗网络（GAN）通过将低维随机噪声映射到高维空间中，在生成建模领域中发挥了重要作用。这些网络已被用于生成高分辨率图像和三维物体。在游戏或模拟等3D图形环境的开发过程中，高效建模3D对象和人脸至关重要。3D GAN是一种新型的生成模型，用于3D重建、点云重建和3D语义场景完成。噪声分布的选择非常重要，因为它表示了潜空间。为了微调生成的样本，理解GAN的潜空间是必要的，这可以通过对图像的语义有意义的部分进行形态变换来证明。在这项工作中，我们探索了潜空间和3D GAN，研究了几种GAN变体和训练方法，以洞察提高3D GAN训练的见解，并提出了未来研究的潜在方向。

    Generative Adversarial Networks (GANs) have emerged as a significant player in generative modeling by mapping lower-dimensional random noise to higher-dimensional spaces. These networks have been used to generate high-resolution images and 3D objects. The efficient modeling of 3D objects and human faces is crucial in the development process of 3D graphical environments such as games or simulations. 3D GANs are a new type of generative model used for 3D reconstruction, point cloud reconstruction, and 3D semantic scene completion. The choice of distribution for noise is critical as it represents the latent space. Understanding a GAN's latent space is essential for fine-tuning the generated samples, as demonstrated by the morphing of semantically meaningful parts of images. In this work, we explore the latent space and 3D GANs, examine several GAN variants and training methods to gain insights into improving 3D GAN training, and suggest potential future directions for further research.
    
[^89]: 在微调时缓解多模态模型中的错误相关性

    Mitigating Spurious Correlations in Multi-modal Models during Fine-tuning. (arXiv:2304.03916v1 [cs.LG])

    [http://arxiv.org/abs/2304.03916](http://arxiv.org/abs/2304.03916)

    本文提出了一种使用多模态对比损失函数的方法，通过在微调期间检测和明确区分受影响类别的错误属性，缓解多模态模型的错误相关性，同时提高模型精度和指向目标领域的有意义特征。

    

    损害模型泛化能力或导致模型基于错误原因的错误相关性是实际部署面临的主要鲁棒性问题之一。然而，在预训练大型模型期间缓解这些相关性可能成本高昂且不切实际，特别是对于没有高性能计算资源的人来说。本文提出了一种新方法，以解决特定领域的微调期间的错误相关性。针对多模态模型（例如CLIP），所提出的方法利用这些模型中的不同模态来检测并明确区分受影响类别的错误属性，通过表达语言的多模态对比损失函数来实现。我们在CLIP上进行的实验证明和深入的可视化显示，这种介入能够有效地提高模型精度，而不存在错误属性，并将模型指向目标领域的有意义特征。

    Spurious correlations that degrade model generalization or lead the model to be right for the wrong reasons are one of the main robustness concerns for real-world deployments. However, mitigating these correlations during pre-training for large-scale models can be costly and impractical, particularly for those without access to high-performance computing resources. This paper proposes a novel approach to address spurious correlations during fine-tuning for a given domain of interest. With a focus on multi-modal models (e.g., CLIP), the proposed method leverages different modalities in these models to detect and explicitly set apart spurious attributes from the affected class, achieved through a multi-modal contrastive loss function that expresses spurious relationships through language. Our experimental results and in-depth visualizations on CLIP show that such an intervention can effectively i) improve the model's accuracy when spurious attributes are not present, and ii) directs the 
    
[^90]: 基于有限维谱动态嵌入的随机非线性控制

    Stochastic Nonlinear Control via Finite-dimensional Spectral Dynamic Embedding. (arXiv:2304.03907v1 [cs.LG])

    [http://arxiv.org/abs/2304.03907](http://arxiv.org/abs/2304.03907)

    本文提出了一种基于有限维特征逼近的非线性动态谱嵌入控制算法（SDEC）用于解决随机非线性系统的最优控制问题，并对其进行了理论分析和实验测试。

    

    随机非线性系统的最优控制一直是一个棘手的问题。Ren等人引入了谱动态嵌入来开发控制未知系统的强化学习方法。它使用无穷维特征来线性表示状态值函数，并利用有限维的截断逼近进行实际实现。然而，在已知模型的情况下，控制中的有限维逼近性质尚未得到研究。在本文中，我们提出了一种可行的随机非线性控制算法，利用基于有限维特征逼近的非线性动态谱嵌入控制（SDEC），并进行深入的理论分析，以表征由有限维截断引起的逼近误差和由有限样本逼近引起的统计误差，同时进行政策评估和政策优化的实验测试和比较。

    Optimal control is notoriously difficult for stochastic nonlinear systems. Ren et al. introduced Spectral Dynamics Embedding for developing reinforcement learning methods for controlling an unknown system. It uses an infinite-dimensional feature to linearly represent the state-value function and exploits finite-dimensional truncation approximation for practical implementation. However, the finite-dimensional approximation properties in control have not been investigated even when the model is known. In this paper, we provide a tractable stochastic nonlinear control algorithm that exploits the nonlinear dynamics upon the finite-dimensional feature approximation, Spectral Dynamics Embedding Control (SDEC), with an in-depth theoretical analysis to characterize the approximation error induced by the finite-dimension truncation and statistical error induced by finite-sample approximation in both policy evaluation and policy optimization. We also empirically test the algorithm and compare th
    
[^91]: InstructBio：一种针对生物化学问题的大规模半监督学习范式。

    InstructBio: A Large-scale Semi-supervised Learning Paradigm for Biochemical Problems. (arXiv:2304.03906v1 [cs.LG])

    [http://arxiv.org/abs/2304.03906](http://arxiv.org/abs/2304.03906)

    InstructBio是一种针对生物化学问题的大规模半监督学习算法，引入教练模型提供有效的置信度比率来指导目标模型对不同数据点给予明显关注，避免依赖有限的标记数据和不正确的伪注释，提高了分子模型的泛化能力。

    

    在科学人工智能领域，面对真实世界问题中的有限标记数据始终是一个重要的挑战。目前的方法是在大型未标记语料库上预训练强力的任务无关模型，但在向下游任务转移知识方面可能存在困难。在本研究中，我们提出了InstructBio，一种半监督学习算法，更好地利用未标记的样例。它引入教练模型来提供伪标签可靠性的置信度比率。这些置信度分数然后指导目标模型对不同的数据点给予明显的关注，避免对标记数据的过度依赖以及不正确的伪注释的负面影响。全面的实验表明，InstructBio显著提高了分子模型的泛化能力，不仅在分子属性预测方面，在活性悬崖估计方面也表现出优越性。

    In the field of artificial intelligence for science, it is consistently an essential challenge to face a limited amount of labeled data for real-world problems. The prevailing approach is to pretrain a powerful task-agnostic model on a large unlabeled corpus but may struggle to transfer knowledge to downstream tasks. In this study, we propose InstructMol, a semi-supervised learning algorithm, to take better advantage of unlabeled examples. It introduces an instructor model to provide the confidence ratios as the measurement of pseudo-labels' reliability. These confidence scores then guide the target model to pay distinct attention to different data points, avoiding the over-reliance on labeled data and the negative influence of incorrect pseudo-annotations. Comprehensive experiments show that InstructBio substantially improves the generalization ability of molecular models, in not only molecular property predictions but also activity cliff estimations, demonstrating the superiority of 
    
[^92]: 多保真度方法应用于物理系统的持续学习

    A multifidelity approach to continual learning for physical systems. (arXiv:2304.03894v1 [math.NA])

    [http://arxiv.org/abs/2304.03894](http://arxiv.org/abs/2304.03894)

    这篇论文介绍了一种基于多保真深度神经网络的新型持续学习方法，能限制灾难性遗忘，特别适用于满足相同物理定律或具备物理学先验知识的神经网络等物理问题。

    

    我们介绍了一种基于多保真深度神经网络的新型持续学习方法。该方法学习前几个模型输出结果和当前训练数据集上期望输出结果的相关性，从而限制灾难性遗忘。多保真持续学习方法本身表现出鲁棒结果，可以限制多个数据集的遗忘。此外，我们还展示了多保真方法可以与现有的持续学习方法（包括重放和记忆感知突触）相结合，以进一步限制灾难性遗忘。该持续学习方法特别适用于满足每个领域上相同物理定律或具备物理学先验知识的神经网络等物理问题，因为在这些情况下，我们预计前一个模型的输出结果与当前训练领域中的模型之间存在强相关性。

    We introduce a novel continual learning method based on multifidelity deep neural networks. This method learns the correlation between the output of previously trained models and the desired output of the model on the current training dataset, limiting catastrophic forgetting. On its own the multifidelity continual learning method shows robust results that limit forgetting across several datasets. Additionally, we show that the multifidelity method can be combined with existing continual learning methods, including replay and memory aware synapses, to further limit catastrophic forgetting. The proposed continual learning method is especially suited for physical problems where the data satisfy the same physical laws on each domain, or for physics-informed neural networks, because in these cases we expect there to be a strong correlation between the output of the previous model and the model on the current training domain.
    
[^93]: 自动化城市规划：生成式和聊天式 AI 相结合的城市规划探索

    Towards Automated Urban Planning: When Generative and ChatGPT-like AI Meets Urban Planning. (arXiv:2304.03892v1 [cs.AI])

    [http://arxiv.org/abs/2304.03892](http://arxiv.org/abs/2304.03892)

    本文探讨了城市规划与人工智能的交叉应用，重点是自动化用地配置，通过对抗学习、生成神经网络、深度编码器-解码器网络、对话式 AI 和地理空间和时间机器学习等技术，AI 可以为现代城市规划带来不少创新与贡献。

    

    城市规划领域和人工智能领域曾经是独立发展的，但现在两个领域开始交叉汇合，互相借鉴和受益。本文介绍了城市规划从可持续性、生活、经济、灾害和环境等方面的重要性，回顾了城市规划的基本概念，并将这些概念与机器学习的关键开放问题联系起来，包括对抗学习、生成神经网络、深度编码器-解码器网络、对话式 AI 以及地理空间和时间机器学习等，评估了 AI 如何为现代城市规划做出贡献。因此，一个核心问题是自动化用地配置，即从周围的地理空间、人类移动、社交媒体、环境和经济活动中为目标区域生成土地用途和建筑配置。最后，本文勾画了集成 AI 和城市规划面临的一些挑战和潜在解决方案。

    The two fields of urban planning and artificial intelligence (AI) arose and developed separately. However, there is now cross-pollination and increasing interest in both fields to benefit from the advances of the other. In the present paper, we introduce the importance of urban planning from the sustainability, living, economic, disaster, and environmental perspectives. We review the fundamental concepts of urban planning and relate these concepts to crucial open problems of machine learning, including adversarial learning, generative neural networks, deep encoder-decoder networks, conversational AI, and geospatial and temporal machine learning, thereby assaying how AI can contribute to modern urban planning. Thus, a central problem is automated land-use configuration, which is formulated as the generation of land uses and building configuration for a target area from surrounding geospatial, human mobility, social media, environment, and economic activities. Finally, we delineate some 
    
[^94]: DiffDock-PP：扩散模型下的刚性蛋白质-蛋白质对接

    DiffDock-PP: Rigid Protein-Protein Docking with Diffusion Models. (arXiv:2304.03889v1 [q-bio.BM])

    [http://arxiv.org/abs/2304.03889](http://arxiv.org/abs/2304.03889)

    本文提出了一种扩散生成模型DiffDock-PP用于刚性蛋白质-蛋白质对接，其在DIPS任务中取得了最先进的性能，同时比所有基于搜索的方法更快，为其预测生成了可靠的置信度估计。

    

    了解蛋白质结构之间的相互作用对于现代生物学至关重要，在药物发现和蛋白质设计中有广泛应用。本文提出了一种类似的方法，用于刚性蛋白质-蛋白质对接：DiffDock-PP是一种扩散生成模型，它学习将不结合的蛋白质结构转化和旋转为它们结合的构象。我们在DIPS任务中实现了最先进的性能，中位数C-RMSD为4.85，优于所有考虑的基线方法。此外，DiffDock-PP比所有基于搜索的方法都要快，并为其预测生成可靠的置信度估计。我们的代码可在 $\texttt{https://github.com/ketatam/DiffDock-PP}$ 上公开获得。

    Understanding how proteins structurally interact is crucial to modern biology, with applications in drug discovery and protein design. Recent machine learning methods have formulated protein-small molecule docking as a generative problem with significant performance boosts over both traditional and deep learning baselines. In this work, we propose a similar approach for rigid protein-protein docking: DiffDock-PP is a diffusion generative model that learns to translate and rotate unbound protein structures into their bound conformations. We achieve state-of-the-art performance on DIPS with a median C-RMSD of 4.85, outperforming all considered baselines. Additionally, DiffDock-PP is faster than all search-based methods and generates reliable confidence estimates for its predictions. Our code is publicly available at $\texttt{https://github.com/ketatam/DiffDock-PP}$
    
[^95]: GPT4Rec：一个用于个性化推荐和用户兴趣解释的生成式框架

    GPT4Rec: A Generative Framework for Personalized Recommendation and User Interests Interpretation. (arXiv:2304.03879v1 [cs.IR])

    [http://arxiv.org/abs/2304.03879](http://arxiv.org/abs/2304.03879)

    GPT4Rec是一个生成式框架，用于个性化推荐和用户兴趣解释，它通过生成“搜索查询”来充分利用物品内容信息和语言建模能力，并使用层次潜在变量模型来提高个性化推荐的相关性和多样性。

    

    自然语言处理(NLP)的最新进展已经导致了NLP基于推荐系统的发展，已经表现出了优越的性能。然而，目前的模型通常将物品仅视为ID并采用判别性建模，导致了以下限制:(1)无法充分利用物品内容信息和NLP模型的语言建模能力;(2)理解用户兴趣以提高相关性和多样性;(3)适应不断增长的物品库存的实际情况。为了解决这些限制，我们提出了GPT4Rec，这是一个新颖灵活的生成框架，启发自搜索引擎。 它首先生成基于用户历史中物品标题的假设“搜索查询”，然后通过搜索这些查询来检索推荐项。该框架通过在语言空间中学习用户和物品嵌入来克服以前的限制。为了很好地捕捉用户利益的不同方面和粒度以改进个性化推荐，我们引入了一个层次潜在变量模型来解释用户兴趣。 GPT4Rec还通过使用served期间看到的项目标题动态扩展词汇表来适应不断增长的项目库存。 在三个基准数据集上的实验结果证明了GPT4Rec在推荐性能和可解释性方面的有效性。

    Recent advancements in Natural Language Processing (NLP) have led to the development of NLP-based recommender systems that have shown superior performance. However, current models commonly treat items as mere IDs and adopt discriminative modeling, resulting in limitations of (1) fully leveraging the content information of items and the language modeling capabilities of NLP models; (2) interpreting user interests to improve relevance and diversity; and (3) adapting practical circumstances such as growing item inventories. To address these limitations, we present GPT4Rec, a novel and flexible generative framework inspired by search engines. It first generates hypothetical "search queries" given item titles in a user's history, and then retrieves items for recommendation by searching these queries. The framework overcomes previous limitations by learning both user and item embeddings in the language space. To well-capture user interests with different aspects and granularity for improving
    
[^96]: OFTER：一种专门针对中等规模多元时间序列的在线预测管线

    OFTER: An Online Pipeline for Time Series Forecasting. (arXiv:2304.03877v1 [stat.ML])

    [http://arxiv.org/abs/2304.03877](http://arxiv.org/abs/2304.03877)

    本文介绍了OFTER，一种专门针对中等规模多种时间序列的在线预测管线，能够胜过几种最先进的基准方法。OFTER是金融多元时间序列问题的理想解决方案。

    

    本文介绍了OFTER，一种专门针对中等规模多元时间序列的预测管线。OFTER利用kNN和广义回归神经网络的非参数模型，并与降维组件集成在一起。为了避免高维度的困境，我们采用基于修改后的最大相关系数的加权范数。我们介绍的管线专门针对在线任务进行设计，具有可解释性，并能够胜过几种最先进的基准方法。算法的计算效率、在线性质以及在低信噪比环境下运行的能力使OFTER成为金融多元时间序列问题的理想解决方案，例如每日股票预测。

    We introduce OFTER, a time series forecasting pipeline tailored for mid-sized multivariate time series. OFTER utilizes the non-parametric models of k-nearest neighbors and Generalized Regression Neural Networks, integrated with a dimensionality reduction component. To circumvent the curse of dimensionality, we employ a weighted norm based on a modified version of the maximal correlation coefficient. The pipeline we introduce is specifically designed for online tasks, has an interpretable output, and is able to outperform several state-of-the art baselines. The computational efficacy of the algorithm, its online nature, and its ability to operate in low signal-to-noise regimes, render OFTER an ideal approach for financial multivariate time series problems, such as daily equity forecasting. Our work demonstrates that while deep learning models hold significant promise for time series forecasting, traditional methods carefully integrating mainstream tools remain very competitive alternati
    
[^97]: ASPEST：主动学习和选择预测之间的弥合

    ASPEST: Bridging the Gap Between Active Learning and Selective Prediction. (arXiv:2304.03870v1 [cs.LG])

    [http://arxiv.org/abs/2304.03870](http://arxiv.org/abs/2304.03870)

    本文提出了一种新的学习范式——主动选择性预测（ASPEST），它可以在转移目标领域中学习查询更多有信息的样本，从而实现减少人工标注工作的同时增加准确性和覆盖率。

    

    选择性预测旨在学习一个可靠的模型，当模型不确定性很高时，可以避免进行预测。随后，可以将这些预测推迟给人类专家进行进一步评估。然而，在许多实际场景中，测试数据的分布与训练数据不同。这导致更不准确的预测，需要增加人工标注，这在许多场景中都是困难和昂贵的。主动学习通过仅查询最信息量丰富的示例来避免这种困难，并且在多个案例中已被证明可以降低总体的标注工作。在这项工作中，我们弥合了选择性预测和主动学习之间的差距，提出了一种新的学习范式，称为主动选择性预测（active selective prediction），它可以在增加准确性和覆盖率的同时在转移目标领域中学习查询更多有信息的样本。对于这个新问题，我们提出了一个简单但有效的解决方案ASPEST，它训练模型快照的集合。

    Selective prediction aims to learn a reliable model that abstains from making predictions when the model uncertainty is high. These predictions can then be deferred to a human expert for further evaluation. In many real-world scenarios, however, the distribution of test data is different from the training data. This results in more inaccurate predictions, necessitating increased human labeling, which is difficult and expensive in many scenarios. Active learning circumvents this difficulty by only querying the most informative examples and, in several cases, has been shown to lower the overall labeling effort. In this work, we bridge the gap between selective prediction and active learning, proposing a new learning paradigm called active selective prediction which learns to query more informative samples from the shifted target domain while increasing accuracy and coverage. For this new problem, we propose a simple but effective solution, ASPEST, that trains ensembles of model snapshots
    
[^98]: 保守的客观模型是一种特殊的基于对比散度能量模型

    Conservative objective models are a special kind of contrastive divergence-based energy model. (arXiv:2304.03866v1 [stat.ML])

    [http://arxiv.org/abs/2304.03866](http://arxiv.org/abs/2304.03866)

    本文证明了在离线基于模型的优化中，保守的客观模型（COMs）是一种特殊的基于对比散度能量模型，同时提出了用Langevin MCMC采样器替换梯度上升采样器，以提高样本质量。

    

    本文理论上证明了保守的客观模型（COMs）用于离线基于模型的优化（MBO）是一种特殊的基于对比散度能量模型，其中能量函数既表示输入的无条件概率，也表示奖励变量的条件概率。虽然最初的公式只从其学习分布中抽样模型，但我们提出了一个简单的修复方法，用Langevin MCMC采样器替换梯度上升采样器。这产生了一种特殊的概率模型，其中采样输入的概率与其预测的奖励成比例。最后，我们证明，如果将模型分解，使无条件概率和条件概率分别建模，可以获得更好的样本。

    In this work we theoretically show that conservative objective models (COMs) for offline model-based optimisation (MBO) are a special kind of contrastive divergence-based energy model, one where the energy function represents both the unconditional probability of the input and the conditional probability of the reward variable. While the initial formulation only samples modes from its learned distribution, we propose a simple fix that replaces its gradient ascent sampler with a Langevin MCMC sampler. This gives rise to a special probabilistic model where the probability of sampling an input is proportional to its predicted reward. Lastly, we show that better samples can be obtained if the model is decoupled so that the unconditional and conditional probabilities are modelled separately.
    
[^99]: SGDP: 一种基于流图神经网络的数据预取器

    SGDP: A Stream-Graph Neural Network Based Data Prefetcher. (arXiv:2304.03864v1 [cs.OS])

    [http://arxiv.org/abs/2304.03864](http://arxiv.org/abs/2304.03864)

    SGDP是一种新型基于流图神经网络的数据预取器，通过建模LBA增量流并使用图神经网络提取混合特征来进行数据预取，实验结果表明它优于其他方法。

    

    数据预取对于存储系统优化和访问性能提升非常重要。传统的预取器适用于挖掘顺序逻辑块地址（LBA）的访问模式，但是无法处理现实世界中普遍存在的复杂非顺序模式。最先进的基于学习的预取器覆盖了更多的LBA访问，但是它们不足以充分考虑LBA增量之间的空间依赖关系，导致性能和鲁棒性有限。本文提出了一种新型的基于流图神经网络的数据预取器（SGDP）。具体来说，SGDP使用加权有向图结构来建模LBA增量流以表示LBA增量之间的交互关系，并通过图神经网络进一步提取混合特征进行数据预取。我们对八个真实世界的数据集进行了广泛的实验。实证结果验证了SGDP在命中率方面优于SOTA方法6.21％，效果也优于其他方法。

    Data prefetching is important for storage system optimization and access performance improvement. Traditional prefetchers work well for mining access patterns of sequential logical block address (LBA) but cannot handle complex non-sequential patterns that commonly exist in real-world applications. The state-of-the-art (SOTA) learning-based prefetchers cover more LBA accesses. However, they do not adequately consider the spatial interdependencies between LBA deltas, which leads to limited performance and robustness. This paper proposes a novel Stream-Graph neural network-based Data Prefetcher (SGDP). Specifically, SGDP models LBA delta streams using a weighted directed graph structure to represent interactive relations among LBA deltas and further extracts hybrid features by graph neural networks for data prefetching. We conduct extensive experiments on eight real-world datasets. Empirical results verify that SGDP outperforms the SOTA methods in terms of the hit ratio by 6.21%, the effe
    
[^100]: 重新探讨深度学习在变量类型恢复中的应用

    Revisiting Deep Learning for Variable Type Recovery. (arXiv:2304.03854v1 [cs.LG])

    [http://arxiv.org/abs/2304.03854](http://arxiv.org/abs/2304.03854)

    该论文讨论了使用机器学习技术预测反编译代码中变量名称和类型的语义信息，其中提到基于Transformer的编码器-解码器架构DIRTY能够有效地提高名称和类型提取的准确性。

    

    在逆向工程、恶意软件分析和软件系统维护中，已编译的二进制可执行文件往往是唯一可用的工件。然而，缺乏像变量类型这样的语义信息使得理解二进制文件变得困难。为了改进二进制文件的可理解性，近期研究人员使用机器学习技术来预测原始源代码中包含的语义信息。Chen等人实现了DIRTY，一种基于Transformer的编码器-解码器架构，能够利用反编译器输出标记和变量大小信息，增强反编译代码的变量名称和类型。相比现有的静态分析和基于人工智能的技术，Chen等人能够证明DIRTY在Hex-Rays反编译器输出的名称和类型提取准确性上有大幅提升。我们通过在由开源Ghidra反编译器产生的数据集上重新训练DIRTY模型来扩展原始DIRTY结果。尽管Chen等人得出结论，

    Compiled binary executables are often the only available artifact in reverse engineering, malware analysis, and software systems maintenance. Unfortunately, the lack of semantic information like variable types makes comprehending binaries difficult. In efforts to improve the comprehensibility of binaries, researchers have recently used machine learning techniques to predict semantic information contained in the original source code. Chen et al. implemented DIRTY, a Transformer-based Encoder-Decoder architecture capable of augmenting decompiled code with variable names and types by leveraging decompiler output tokens and variable size information. Chen et al. were able to demonstrate a substantial increase in name and type extraction accuracy on Hex-Rays decompiler outputs compared to existing static analysis and AI-based techniques. We extend the original DIRTY results by re-training the DIRTY model on a dataset produced by the open-source Ghidra decompiler. Although Chen et al. conclu
    
[^101]: StepMix: 一个用于外部变量广义混合模型的伪似然估计的Python包

    StepMix: A Python Package for Pseudo-Likelihood Estimation of Generalized Mixture Models with External Variables. (arXiv:2304.03853v1 [stat.ME])

    [http://arxiv.org/abs/2304.03853](http://arxiv.org/abs/2304.03853)

    StepMix是一个用于外部变量广义混合模型的伪似然估计的Python包，提供了单步和逐步估计方法，帮助从业人员进行模型估计、选择和解释。

    

    StepMix是一个用于广义有限混合模型(潜在剖面和潜在类分析)与外部变量(协变量和远程结果)的伪似然估计(单步、两步和三步方法)的开源软件包。在许多社会科学的应用中，主要目标不仅是将个体聚类成潜在类别，还包括使用这些类别来开发更复杂的统计模型。这些模型通常分为一个将潜在类别与观察指标相关联的测量模型和一个将协变量和结果变量与潜在类别相关联的结构模型。测量和结构模型可以使用所谓的一步法共同估计，也可以使用逐步方法逐步估计，对于从业人员来说，这些方法在估计潜在类别的可解释性方面具有显著优势。除了一步法，StepMix还实现了文献中提出的最重要的逐步估计方法，提供了用户友好的界面，方便模型的估计、选择和解释。

    StepMix is an open-source software package for the pseudo-likelihood estimation (one-, two- and three-step approaches) of generalized finite mixture models (latent profile and latent class analysis) with external variables (covariates and distal outcomes). In many applications in social sciences, the main objective is not only to cluster individuals into latent classes, but also to use these classes to develop more complex statistical models. These models generally divide into a measurement model that relates the latent classes to observed indicators, and a structural model that relates covariates and outcome variables to the latent classes. The measurement and structural models can be estimated jointly using the so-called one-step approach or sequentially using stepwise methods, which present significant advantages for practitioners regarding the interpretability of the estimated latent classes. In addition to the one-step approach, StepMix implements the most important stepwise estim
    
[^102]: 为什么要逐步思考？推理源于经验的局部性。

    Why think step-by-step? Reasoning emerges from the locality of experience. (arXiv:2304.03843v1 [cs.AI])

    [http://arxiv.org/abs/2304.03843](http://arxiv.org/abs/2304.03843)

    本文通过语言模型研究何时以及为什么推理是有帮助的，测试推理在训练数据由相互影响强烈的局部变量集群组成时是否有效。通过一步步的推理，能够将准确的局部推理链接在一起，以估算在训练中没有同时观察到的变量之间的关系。

    

    人类有着强大而神秘的推理能力。通过一系列纯粹的思维步骤，我们可以推理出我们无法直接得出的推论 - 尽管我们从世界上没有得到任何额外数据。同样地，大型语言模型可以通过一步步的推理，在回答问题之前生成中间步骤，从而更好地完成复杂的任务。我们使用语言模型研究何时以及为什么推理是有帮助的，测试推理在训练数据由相互影响强烈的局部变量集群组成时是否有效。这些训练条件能够将准确的局部推理链接在一起，以估算在训练中没有同时观察到的变量之间的关系。我们使用贝叶斯网络定义的联合分布的样品对自回归变压器进行训练，但每个样品只包括其中的一部分变量。我们比较使用推理生成的变量子集与使用完整集合进行训练的方案的性能。

    Humans have a powerful and mysterious capacity to reason. By working through a series of purely mental steps, we can make inferences we would not be capable of making directly -- despite that fact that we get no additional data from the world. Similarly, large language models can perform better at complex tasks through chain-of-thought reasoning, where they generate intermediate steps before answering a question. We use language models to investigate the questions of when and why reasoning is helpful, testing the hypothesis that reasoning is effective when training data consisting of local clusters of variables that influence each other strongly. These training conditions enable the chaining of accurate local inferences in order to estimate relationships between variables that were not seen together in training. We train an autoregressive transformer on samples from joint distributions defined by Bayes nets, but only include a subset of all the variables in each sample. We compare lang
    
[^103]: 提高人脸模型的身份鲁棒性

    Improving Identity-Robustness for Face Models. (arXiv:2304.03838v1 [cs.CV])

    [http://arxiv.org/abs/2304.03838](http://arxiv.org/abs/2304.03838)

    该论文探讨了在没有身份注释信息的情况下，使用人脸识别嵌入向量作为身份标识的替代方法，以提高人脸模型的身份鲁棒性和公平性。

    

    虽然深度学习模型在许多任务中取得了成功，但人们仍然担心这些模型可能学习到快捷方式，并且缺乏对无关混淆因素的鲁棒性。在直接训练于人脸上的模型中，一个敏感的混淆因素是人的身份。许多与人脸相关的任务理想情况下应该是与身份无关的，并在不同个体之间表现一致（即公平）。通过在训练期间强制执行这种鲁棒性和性能均匀性是度量和实施的一种方法，假设可以在规模上获取与身份相关的信息。但是，由于隐私问题以及收集此类信息的成本，这通常不是情况，大多数人脸数据集只包含输入图像及其相应的任务标签。因此，无需此类注释即可提高身份相关鲁棒性非常重要。在这里，我们探讨使用人脸识别嵌入向量作为身份标识的替代方法，以执行这种鲁棒性和公平性。

    Despite the success of deep-learning models in many tasks, there have been concerns about such models learning shortcuts, and their lack of robustness to irrelevant confounders. When it comes to models directly trained on human faces, a sensitive confounder is that of human identities. Many face-related tasks should ideally be identity-independent, and perform uniformly across different individuals (i.e. be fair). One way to measure and enforce such robustness and performance uniformity is through enforcing it during training, assuming identity-related information is available at scale. However, due to privacy concerns and also the cost of collecting such information, this is often not the case, and most face datasets simply contain input images and their corresponding task-related labels. Thus, improving identity-related robustness without the need for such annotations is of great importance. Here, we explore using face-recognition embedding vectors, as proxies for identities, to enfo
    
[^104]: 学习演示中的行为空间匹配问题

    Bridging Action Space Mismatch in Learning from Demonstrations. (arXiv:2304.03833v1 [cs.RO])

    [http://arxiv.org/abs/2304.03833](http://arxiv.org/abs/2304.03833)

    本文提出了一种解决学习演示中行为空间不匹配问题的框架，可以通过其他形态有显着不同的代理的演示进行训练，并且可以从次优演示中学习。

    

    学习演示的方法可以通过教师演示达到特定的目的，但是当教师用于演示的行为空间与学生不同时，就会出现行为空间不匹配的问题。本文提出了一种框架，即模仿学习中的形态适应（MAIL），旨在帮助学生代理根据其他形态显着不同的代理的演示进行训练。 MAIL可以从次优演示中学习，只要这些演示提供了一些指引，以达到预期的解决方案。作者在具有挑战性的家庭布料操作任务上演示了MAIL，并介绍了一个新的DRY CLOTH任务 - 在三维空间中带有障碍物的布料操作任务。

    Learning from demonstrations (LfD) methods guide learning agents to a desired solution using demonstrations from a teacher. While some LfD methods can handle small mismatches in the action spaces of the teacher and student, here we address the case where the teacher demonstrates the task in an action space that can be substantially different from that of the student -- thereby inducing a large action space mismatch. We bridge this gap with a framework, Morphological Adaptation in Imitation Learning (MAIL), that allows training an agent from demonstrations by other agents with significantly different morphologies (from the student or each other). MAIL is able to learn from suboptimal demonstrations, so long as they provide some guidance towards a desired solution. We demonstrate MAIL on challenging household cloth manipulation tasks and introduce a new DRY CLOTH task -- cloth manipulation in 3D task with obstacles. In these tasks, we train a visual control policy for a robot with one en
    
[^105]: 从自然语言错误描述中生成功能上正确的代码编辑

    Towards Generating Functionally Correct Code Edits from Natural Language Issue Descriptions. (arXiv:2304.03816v1 [cs.SE])

    [http://arxiv.org/abs/2304.03816](http://arxiv.org/abs/2304.03816)

    本文提出了 NL2Fix 问题，即将代码更改的自然语言描述翻译成正确的代码修复。为此，我们介绍了 Defects4J-NL2Fix，这是一个由 283 个 Java 程序组成的流行 Defects4J 数据集。

    

    大型语言模型（LLM），如 OpenAI 的 Codex，在各种编程任务中已经展示了通过自然语言描述生成代码的潜力。最近出现了几个基准测试来评估 LLM 生成与一组隐藏测试用例相对应的自然语言意图的功能上正确的代码的能力。这使得研究社区能够确定 LLM 能力的显著和可重复的进展。但是，目前缺乏基准数据集来评估 LLM 根据预期更改的自然语言描述生成功能性正确的代码编辑的能力。本文旨在通过提出问题 NL2Fix，即将代码更改的自然语言描述（即库中问题报告中描述的错误修复）翻译成正确的代码修复来解决这个问题。为此，我们介绍了 Defects4J-NL2Fix，这是一个由 283 个 Java 程序组成的流行 Defects4J 数据集。

    Large language models (LLMs), such as OpenAI's Codex, have demonstrated their potential to generate code from natural language descriptions across a wide range of programming tasks. Several benchmarks have recently emerged to evaluate the ability of LLMs to generate functionally correct code from natural language intent with respect to a set of hidden test cases. This has enabled the research community to identify significant and reproducible advancements in LLM capabilities. However, there is currently a lack of benchmark datasets for assessing the ability of LLMs to generate functionally correct code edits based on natural language descriptions of intended changes. This paper aims to address this gap by motivating the problem NL2Fix of translating natural language descriptions of code changes (namely bug fixes described in Issue reports in repositories) into correct code fixes. To this end, we introduce Defects4J-NL2Fix, a dataset of 283 Java programs from the popular Defects4J datas
    
[^106]: 使用迁移学习实现隐私保护的CNN训练

    Privacy-Preserving CNN Training with Transfer Learning. (arXiv:2304.03807v1 [cs.CR])

    [http://arxiv.org/abs/2304.03807](http://arxiv.org/abs/2304.03807)

    本文提出了一种使用迁移学习实现同态加密技术下隐私保护的CNN训练的方案，通过转换思想和更快的梯度变体，取得了最先进的性能。

    

    隐私保护的神经网络推理已经得到很好的研究，同时保持同态CNN训练仍然是一项挑战性的任务。在本文中，我们提出了一种实用的解决方案来实现基于同态加密技术的隐私保护CNN训练。据我们所知，这是第一次成功突破这个难题，以前没有任何工作达到这个目标。采用了几种技术：（1）通过迁移学习，可以将隐私保护的CNN训练简化为同态神经网络训练，甚至是多类逻辑回归（MLR）训练；（2）通过更快的梯度变体$\texttt{Quadratic Gradient}$，应用于MLR的增强梯度方法，在收敛速度方面具有最先进的性能；（3）我们采用数学中的变换思想，将加密域中的近似Softmax函数转换成已经研究过的逼近方法，从而得到更好的结果。

    Privacy-preserving nerual network inference has been well studied while homomorphic CNN training still remains an open challenging task. In this paper, we present a practical solution to implement privacy-preserving CNN training based on mere Homomorphic Encryption (HE) technique. To our best knowledge, this is the first attempt successfully to crack this nut and no work ever before has achieved this goal. Several techniques combine to make it done: (1) with transfer learning, privacy-preserving CNN training can be reduced to homomorphic neural network training, or even multiclass logistic regression (MLR) training; (2) via a faster gradient variant called $\texttt{Quadratic Gradient}$, an enhanced gradient method for MLR with a state-of-the-art performance in converge speed is applied in this work to achieve high performance; (3) we employ the thought of transformation in mathematics to transform approximating Softmax function in encryption domain to the well-studied approximation of 
    
[^107]: 通过生成对抗网络纠正模型错误规范

    Correcting Model Misspecification via Generative Adversarial Networks. (arXiv:2304.03805v1 [cs.LG])

    [http://arxiv.org/abs/2304.03805](http://arxiv.org/abs/2304.03805)

    本文提出了一种新的ABC-GAN范式，通过ABC合并任何可用的主观知识来协助GAN，消除了模型中似然性错误规范的需求，从而产生了一个在低数据量情况下运行良好的模型。

    

    机器学习模型常常在似然性上存在错误规范，这导致预测的鲁棒性不足。本文引入了一种框架，用于纠正多个范式中的似然性错误规范，并测试模型消除错误规范的能力。“ABC-GAN”框架是一种新的生成建模范式，它结合了生成对抗网络（GAN）和近似贝叶斯计算（ABC）。这种新的范式通过ABC合并任何可用于建模过程中的主观知识，作为一个规范化项来协助现有的GAN，从而产生一个在低数据量情况下运行良好、部分可解释的模型。与任何贝叶斯分析不同，生成器可以变得任意复杂，因此ABC-GAN消除了对摘要统计和距离度量的需求，因为鉴别器隐性地学习它们。

    Machine learning models are often misspecified in the likelihood, which leads to a lack of robustness in the predictions. In this paper, we introduce a framework for correcting likelihood misspecifications in several paradigm agnostic noisy prior models and test the model's ability to remove the misspecification. The "ABC-GAN" framework introduced is a novel generative modeling paradigm, which combines Generative Adversarial Networks (GANs) and Approximate Bayesian Computation (ABC). This new paradigm assists the existing GANs by incorporating any subjective knowledge available about the modeling process via ABC, as a regularizer, resulting in a partially interpretable model that operates well under low data regimes. At the same time, unlike any Bayesian analysis, the explicit knowledge need not be perfect, since the generator in the GAN can be made arbitrarily complex. ABC-GAN eliminates the need for summary statistics and distance metrics as the discriminator implicitly learns them a
    
[^108]: ChiroDiff: 基于弥散模型的手写数据建模

    ChiroDiff: Modelling chirographic data with Diffusion Models. (arXiv:2304.03785v1 [cs.LG])

    [http://arxiv.org/abs/2304.03785](http://arxiv.org/abs/2304.03785)

    本论文介绍了一种名为"ChiroDiff"的模型类，该模型利用Denoising Diffusion Probabilistic Models（DDPMs）解决了手写数据建模过程中存在的问题，能够学习捕捉整体概念，在更高的时间采样率下保持弹性，并具有许多下游实用程序。

    

    通过自回归分布，已经实现了对于连续时间几何结构（如手写、草图、图画等）的生成建模。然而，这种严格有序的离散分解无法捕捉手写数据的关键属性——由于单向可见性（因果性），它无法建立整体的时间概念理解，因此在建模时将时间数据建模为固定采样率的离散标记序列，而未能捕获真正的基础概念。在本文中，我们介绍了一个名为“去噪弥散概率模型”（DDPMs）的强大模型类，专门为手写数据解决这些缺陷。我们的模型名为“ChiroDiff”，是非自回归的，学习捕捉整体概念，因此在更高的时间采样率下保持弹性至少有限。此外，我们展示了许多重要的下游实用程序（如条件采样、创意混合）。

    Generative modelling over continuous-time geometric constructs, a.k.a such as handwriting, sketches, drawings etc., have been accomplished through autoregressive distributions. Such strictly-ordered discrete factorization however falls short of capturing key properties of chirographic data -- it fails to build holistic understanding of the temporal concept due to one-way visibility (causality). Consequently, temporal data has been modelled as discrete token sequences of fixed sampling rate instead of capturing the true underlying concept. In this paper, we introduce a powerful model-class namely "Denoising Diffusion Probabilistic Models" or DDPMs for chirographic data that specifically addresses these flaws. Our model named "ChiroDiff", being non-autoregressive, learns to capture holistic concepts and therefore remains resilient to higher temporal sampling rate up to a good extent. Moreover, we show that many important downstream utilities (e.g. conditional sampling, creative mixing) c
    
[^109]: 生成AI用于学习：研究合成学习视频的潜力。

    Generative AI for learning: Investigating the potential of synthetic learning videos. (arXiv:2304.03784v1 [cs.CV])

    [http://arxiv.org/abs/2304.03784](http://arxiv.org/abs/2304.03784)

    本研究探讨了使用生成AI合成视频来创建在线教育内容的效用，使用混合方法和成年学习者进行实验。结果显示，合成学习视频对学习内容获取和学习体验有着积极的影响。

    

    最近，生成人工智能（AI）的最新进展已经引起了全球的关注。像Dalle-2和ChatGPT这样的工具表明，以前被认为超出了AI能力的任务现在可以以各种新方式增加创意媒体的生产力，包括生成合成视频。本研究探讨了使用生成AI合成视频来创建在在线教育环境下可行的教育内容的效用。到目前为止，还没有研究调查AI生成的合成媒体在现实世界中的教育价值。为了填补这一空白，我们采用混合方法随机将成年学习者（n = 83）分配到两种微型学习条件之一，收集前后学习评估，并调查参与者的学习体验。控制组

    Recent advances in generative artificial intelligence (AI) have captured worldwide attention. Tools such as Dalle-2 and ChatGPT suggest that tasks previously thought to be beyond the capabilities of AI may now augment the productivity of creative media in various new ways, including through the generation of synthetic video. This research paper explores the utility of using AI-generated synthetic video to create viable educational content for online educational settings. To date, there is limited research investigating the real-world educational value of AI-generated synthetic media. To address this gap, we examined the impact of using AI-generated synthetic video in an online learning platform on both learners content acquisition and learning experience. We took a mixed-method approach, randomly assigning adult learners (n=83) into one of two micro-learning conditions, collecting pre- and post-learning assessments, and surveying participants on their learning experience. The control c
    
[^110]: AutoQNN: 一种自动量化神经网络的端到端框架

    AutoQNN: An End-to-End Framework for Automatically Quantizing Neural Networks. (arXiv:2304.03782v1 [cs.LG])

    [http://arxiv.org/abs/2304.03782](http://arxiv.org/abs/2304.03782)

    AutoQNN是一种可自动量化DNN模型的端到端框架，利用三种技术实现了对适合不同层次的混合精度策略的搜索，并可有效提高效率和准确性。

    

    探索适合深度神经网络（DNN）压缩的量化方案与混合精度策略是提高效率和准确性的关键。然而，自动压缩方法的巨大搜索空间导致了大量的计算预算，这使得自动过程难以在实际场景中应用。在本文中，我们提出了一种名为AutoQNN的端到端框架，可以自动量化不同层次的DNN模型，而无需任何人工干预。

    Exploring the expected quantizing scheme with suitable mixed-precision policy is the key point to compress deep neural networks (DNNs) in high efficiency and accuracy. This exploration implies heavy workloads for domain experts, and an automatic compression method is needed. However, the huge search space of the automatic method introduces plenty of computing budgets that make the automatic process challenging to be applied in real scenarios. In this paper, we propose an end-to-end framework named AutoQNN, for automatically quantizing different layers utilizing different schemes and bitwidths without any human labor. AutoQNN can seek desirable quantizing schemes and mixed-precision policies for mainstream DNN models efficiently by involving three techniques: quantizing scheme search (QSS), quantizing precision learning (QPL), and quantized architecture generation (QAG). QSS introduces five quantizing schemes and defines three new schemes as a candidate set for scheme search, and then u
    
[^111]: 医疗保健中公平和可信预测模型验证的路线图

    A roadmap to fair and trustworthy prediction model validation in healthcare. (arXiv:2304.03779v1 [cs.LG])

    [http://arxiv.org/abs/2304.03779](http://arxiv.org/abs/2304.03779)

    针对医疗保健中预测模型的验证问题，建议使用来自目标人群的新数据进行外部验证，确保验证性能对模型可靠性的影响，并且在模型开发期间认真研究模型在更广泛环境中的拓展性。我们提出了一份路线图，以便在医疗保健中开发和应用可靠、公平、可信的人工智能模型。

    

    如果一个预测模型能够推广到开发数据以外的数据，并进行外部验证，那么它就是最有用的。但是，在多大程度上它可以推广仍不清楚。实际上，预测模型使用来自其他医疗系统或国家的人口等非常不同的数据进行外部验证，预测结果通常很差。这可能不是对特定目标人群或环境设计的模型表现的公正反映，并且可能会拉伸预期的模型推广性。为了解决这个问题，我们建议使用来自目标人群的新数据来外部验证模型，以确保验证性能对模型可靠性的清晰影响，而模型推广到更广泛的环境应在模型开发期间进行仔细调查，而不是事后探讨。基于这个观点，我们提出了一项路线图，以便在医疗保健中开发和应用可靠、公平、可信的人工智能模型。我们认为这份路线图应该清晰定义公平性和可信性，考虑模型使用的伦理影响，进行亚组分析，并采用严格的验证协议，其中包括在目标人群中进行外部验证。

    A prediction model is most useful if it generalizes beyond the development data with external validations, but to what extent should it generalize remains unclear. In practice, prediction models are externally validated using data from very different settings, including populations from other health systems or countries, with predictably poor results. This may not be a fair reflection of the performance of the model which was designed for a specific target population or setting, and may be stretching the expected model generalizability. To address this, we suggest to externally validate a model using new data from the target population to ensure clear implications of validation performance on model reliability, whereas model generalizability to broader settings should be carefully investigated during model development instead of explored post-hoc. Based on this perspective, we propose a roadmap that facilitates the development and application of reliable, fair, and trustworthy artifici
    
[^112]: 针对Jumbo-Visma队卡路里预测的符合性回归

    Conformal Regression in Calorie Prediction for Team Jumbo-Visma. (arXiv:2304.03778v1 [cs.LG])

    [http://arxiv.org/abs/2304.03778](http://arxiv.org/abs/2304.03778)

    本文提出一种新的符合性回归方法，通过预测动力和速度来为自行车比赛中的每个骑手提供卡路里需求的估计。

    

    UCI WorldTour赛事是男子精英公路自行车比赛的顶级赛事，对骑行者的体能和耐力进行考验。Jumbo-Visma队的教练们长期以来一直负责预测每个比赛日历中荷兰队的每位骑手的能量需求，以确保骑手在比赛过程中有足够的能量和资源来保持高水平表现。本文提出了一种新的更有效的预测骑行比赛能量需求的方法。通过回归模型预测速度和动力，为每个阶段的每个个体骑手提供卡路里需求估计。

    UCI WorldTour races, the premier men's elite road cycling tour, are grueling events that put riders' physical fitness and endurance to the test. The coaches of Team Jumbo-Visma have long been responsible for predicting the energy needs of each rider of the Dutch team for every race on the calendar. Those must be estimated to ensure riders have the energy and resources necessary to maintain a high level of performance throughout a race. This task, however, is both time-consuming and challenging, as it requires precise estimates of race speed and power output. Traditionally, the approach to predicting energy needs has relied on coaches' judgement and experience, but this method has its limitations and often leads to inaccurate predictions. In this paper, we propose a new, more effective approach to predicting energy needs for cycling races. By predicting the speed and power with regression models, we provide the coaches with calorie needs estimate for each individual rider per stage inst
    
[^113]: 具有保证灵活性的生物序列核

    Biological Sequence Kernels with Guaranteed Flexibility. (arXiv:2304.03775v1 [stat.ML])

    [http://arxiv.org/abs/2304.03775](http://arxiv.org/abs/2304.03775)

    本文研究了生物序列核的数学挑战，探讨了生物序列空间结构和生物序列相似性的特殊性对于核的影响。

    

    将机器学习应用于生物序列（DNA，RNA和蛋白质）具有推动人类健康、环境可持续性和基础生物学理解的巨大潜力。然而，许多现有的机器学习方法在这个问题域中是无效或不可靠的。本文通过核的视角从理论上研究这些挑战。尽管没有显式使用核的方法仍然在隐含地依赖它们，包括各种深度学习和基于物理的技术。虽然其他类型数据的核已被理论上广泛研究，但生物序列空间的结构（离散、可变长度序列）以及生物序列相似性的特殊数学挑战独一无二。我们正式分析生物序列核能够多好地近似

    Applying machine learning to biological sequences - DNA, RNA and protein has enormous potential to advance human health, environmental sustainability, and fundamental biological understanding. However, many existing machine learning methods are ineffective or unreliable in this problem domain. We study these challenges theoretically, through the lens of kernels. Methods based on kernels are ubiquitous: they are used to predict molecular phenotypes, design novel proteins, compare sequence distributions, and more. Many methods that do not use kernels explicitly still rely on them implicitly, including a wide variety of both deep learning and physics-based techniques. While kernels for other types of data are well-studied theoretically, the structure of biological sequence space (discrete, variable length sequences), as well as biological notions of sequence similarity, present unique mathematical challenges. We formally analyze how well kernels for biological sequences can approximate 
    
[^114]: 用于人体运动分析的真实工业任务和传统手工艺的动作捕捉基准测试

    Motion Capture Benchmark of Real Industrial Tasks and Traditional Crafts for Human Movement Analysis. (arXiv:2304.03771v1 [cs.RO])

    [http://arxiv.org/abs/2304.03771](http://arxiv.org/abs/2304.03771)

    本文提供了使用惯性动作捕捉技术记录的工业操作员和手艺人员真实工作中的专业动作的七个数据集，可用于人体运动建模、分析和生成的研究。同时，本文提供了Gesture Operational Model作为方法的初步基准测试。

    

    人体运动分析是机器人技术、生物力学和数据科学研究领域的一个关键领域，包括跟踪、姿态估计和运动合成。虽然随着时间的推移，出现了许多方法，但仍需要使用可验证的三维人体运动基准数据对这些方法进行系统和定量的评估，以定义当前技术水平的现状。本文介绍了使用基于惯性的动作捕捉技术记录的七个数据集。数据集包含在实际条件下由工业操作员和熟练的手艺人员执行的专业动作。数据集旨在用于人体运动建模、分析和生成领域的研究。详细描述了数据采集协议，并提供了收集数据的初步分析作为基准测试。Gesture Operational Model是一种基于运动描述符的混合随机-生物力学方法。

    Human movement analysis is a key area of research in robotics, biomechanics, and data science. It encompasses tracking, posture estimation, and movement synthesis. While numerous methodologies have evolved over time, a systematic and quantitative evaluation of these approaches using verifiable ground truth data of three-dimensional human movement is still required to define the current state of the art. This paper presents seven datasets recorded using inertial-based motion capture. The datasets contain professional gestures carried out by industrial operators and skilled craftsmen performed in real conditions in-situ. The datasets were created with the intention of being used for research in human motion modeling, analysis, and generation. The protocols for data collection are described in detail, and a preliminary analysis of the collected data is provided as a benchmark. The Gesture Operational Model, a hybrid stochastic-biomechanical approach based on kinematic descriptors, is util
    
[^115]: 使用基于机器ID的对比学习预训练的音频表示进行异常声音检测

    Anomalous Sound Detection using Audio Representation with Machine ID based Contrastive Learning Pretraining. (arXiv:2304.03588v1 [cs.SD])

    [http://arxiv.org/abs/2304.03588](http://arxiv.org/abs/2304.03588)

    本文提出了一种使用基于机器ID的对比学习预训练的音频表示来进行异常声音检测的方法，在DCASE 2020 Challenge Task2 数据集上表现优于目前最先进的基于对比学习或自监督分类的方法。

    

    现有的用于异常声音检测的对比学习方法通过利用样本增强的对比来精炼每个音频样本的音频表示。然而，由于缺乏机器声音的物理特性，它们可能会受到增强数据的偏差，从而限制检测性能。本文使用对比学习来精炼每个机器ID的音频表示，而不是每个音频样本。提出的两阶段方法使用对比学习来预训练音频表示模型，通过融入机器ID和自监督ID分类器来对学习的模型进行微调，同时增强来自相同ID的音频特征之间的关系。实验证明，我们的方法在DCASE 2020挑战任务2数据集上的整体异常检测性能和稳定性方面优于基于对比学习或自监督分类的最先进方法。

    Existing contrastive learning methods for anomalous sound detection refine the audio representation of each audio sample by using the contrast between the samples' augmentations (e.g., with time or frequency masking). However, they might be biased by the augmented data, due to the lack of physical properties of machine sound, thereby limiting the detection performance. This paper uses contrastive learning to refine audio representations for each machine ID, rather than for each audio sample. The proposed two-stage method uses contrastive learning to pretrain the audio representation model by incorporating machine ID and a self-supervised ID classifier to fine-tune the learnt model, while enhancing the relation between audio features from the same ID. Experiments show that our method outperforms the state-of-the-art methods using contrastive learning or self-supervised classification in overall anomaly detection performance and stability on DCASE 2020 Challenge Task2 dataset.
    
[^116]: 重新考虑基于GNN的异构知识图谱实体对齐：新数据集和新方法

    Rethinking GNN-based Entity Alignment on Heterogeneous Knowledge Graphs: New Datasets and A New Method. (arXiv:2304.03468v1 [cs.LG])

    [http://arxiv.org/abs/2304.03468](http://arxiv.org/abs/2304.03468)

    文章重新考虑了基于GNN的异构知识图谱实体对齐。为探究EA实际场景中的表现，提出了更接近现实的高度异构知识图谱数据集，并提出了新方法。

    

    知识图谱（KG）应用的发展导致了需要从各种来源提取的异构KG之间的实体对齐（EA）的不断增长需求。近来，由于GNN的出色结构信息捕捉能力，在EA任务中广泛采用GNN。然而，我们观察到现有常见EA数据集的过于简单化的设置与现实场景相距甚远，这妨碍了对最近方法所取得进展的全面理解。这种现象使我们深思：现有基于GNN的EA方法是否真的取得了伟大进展？为了研究EA方法在现实情况下的性能，本文聚焦于高度异构的KG（HHKG）（例如，事件KG和通用KG）的对齐，这些KG在规模和结构上不同，并共享更少的重叠实体。首先，我们清理了不合理的设置，并提出了两个新的HHKG数据集，其密切地模拟了现实世界场景。

    The development of knowledge graph (KG) applications has led to a rising need for entity alignment (EA) between heterogeneous KGs that are extracted from various sources. Recently, graph neural networks (GNNs) have been widely adopted in EA tasks due to GNNs' impressive ability to capture structure information. However, we have observed that the oversimplified settings of the existing common EA datasets are distant from real-world scenarios, which obstructs a full understanding of the advancements achieved by recent methods. This phenomenon makes us ponder: Do existing GNN-based EA methods really make great progress?  In this paper, to study the performance of EA methods in realistic settings, we focus on the alignment of highly heterogeneous KGs (HHKGs) (e.g., event KGs and general KGs) which are different with regard to the scale and structure, and share fewer overlapping entities. First, we sweep the unreasonable settings, and propose two new HHKG datasets that closely mimic real-wo
    
[^117]: 比较NARS和强化学习：对ONA和$Q$-Learning算法的分析

    Comparing NARS and Reinforcement Learning: An Analysis of ONA and $Q$-Learning Algorithms. (arXiv:2304.03291v1 [cs.LG])

    [http://arxiv.org/abs/2304.03291](http://arxiv.org/abs/2304.03291)

    本文比较了NARS和强化学习在解决序列任务方面的性能，发现NARS在各种环境中都有较好的表现，尤其是在非确定性环境中。

    

    近年来，强化学习（RL）已成为解决机器学习中基于序列任务的流行方法。然而，寻找RL的可行替代方案仍然是一个令人兴奋和创新的研究领域。其中一个备受关注的替代方案是非公理推理系统（NARS），它是一个通用的认知推理框架。本文研究了NARS作为RL替代方案在解决基于序列任务方面的潜力。为了研究这一点，我们在使用Open AI gym创建的各种环境中，对ONA作为NARS实现和$Q$-Learning的性能进行了比较分析。这些环境具有不同的难度级别，从简单到复杂不等。我们的研究结果表明，在各种环境中，尤其是在非确定性环境中，NARS是一个有竞争力的RL替代方案。

    In recent years, reinforcement learning (RL) has emerged as a popular approach for solving sequence-based tasks in machine learning. However, finding suitable alternatives to RL remains an exciting and innovative research area. One such alternative that has garnered attention is the Non-Axiomatic Reasoning System (NARS), which is a general-purpose cognitive reasoning framework. In this paper, we delve into the potential of NARS as a substitute for RL in solving sequence-based tasks. To investigate this, we conduct a comparative analysis of the performance of ONA as an implementation of NARS and $Q$-Learning in various environments that were created using the Open AI gym. The environments have different difficulty levels, ranging from simple to complex. Our results demonstrate that NARS is a promising alternative to RL, with competitive performance in diverse environments, particularly in non-deterministic ones.
    
[^118]: 坚韧的神经架构搜索

    Robust Neural Architecture Search. (arXiv:2304.02845v1 [cs.LG])

    [http://arxiv.org/abs/2304.02845](http://arxiv.org/abs/2304.02845)

    提出了一种名为RNAS的神经架构搜索方法，通过平衡准确性和鲁棒性生成高质量架构，使用噪声样本减少搜索成本，在图像分类和对抗攻击中均达到最先进性能水平。

    

    近年来，神经架构搜索（NAS）变得越来越流行。然而，NAS生成的模型往往更容易受到各种恶意攻击的影响。许多强健的NAS方法利用对抗训练来增强NAS生成的模型的强健性，但是它们忽略了NAS生成的模型的本质准确性。在我们的论文中，我们提出了一种新颖的NAS方法，名为Robust Neural Architecture Search（RNAS）。为了设计出一个正则化项来平衡准确性和鲁棒性，RNAS生成具有高准确性和良好鲁棒性的架构。为了减少搜索成本，我们提出使用噪声样本而不是对抗性样本作为搜索架构的输入。广泛的实验表明，RNAS在图像分类和对抗攻击方面均达到了最先进（SOTA）的性能，这证明了所提出的RNAS在准确性和鲁棒性之间取得了良好的平衡。

    Neural Architectures Search (NAS) becomes more and more popular over these years. However, NAS-generated models tends to suffer greater vulnerability to various malicious attacks. Lots of robust NAS methods leverage adversarial training to enhance the robustness of NAS-generated models, however, they neglected the nature accuracy of NAS-generated models. In our paper, we propose a novel NAS method, Robust Neural Architecture Search (RNAS). To design a regularization term to balance accuracy and robustness, RNAS generates architectures with both high accuracy and good robustness. To reduce search cost, we further propose to use noise examples instead adversarial examples as input to search architectures. Extensive experiments show that RNAS achieves state-of-the-art (SOTA) performance on both image classification and adversarial attacks, which illustrates the proposed RNAS achieves a good tradeoff between robustness and accuracy.
    
[^119]: JPEG压缩图像可以绕过对抗AI编辑的保护措施

    JPEG Compressed Images Can Bypass Protections Against AI Editing. (arXiv:2304.02234v1 [cs.LG])

    [http://arxiv.org/abs/2304.02234](http://arxiv.org/abs/2304.02234)

    该论文指出微小但有效的图像扰动方法并不能抵御JPEG压缩，因此不能有效保护图像免受恶意编辑和深度伪造攻击，建议采用其他方法进行保护。

    

    最近的文本生成图像模型使得高质量图像的编辑或生成变得更加容易。然而，其易用性引发了对恶意编辑或深度伪造的担忧。为防止传播模型生成真实图像，我们提出了微不可见的扰动作为保护图像免受恶意攻击的手段。然而，我们发现这些扰动不具有鲁棒性，不能经受JPEG压缩的考验，这是一个主要的弱点，因为JPEG具有普遍的使用和可获取性。我们讨论了加性微不可见扰动鲁棒性的重要性，鼓励采用其他方法来保护图像免受攻击。

    Recently developed text-to-image diffusion models make it easy to edit or create high-quality images. Their ease of use has raised concerns about the potential for malicious editing or deepfake creation. Imperceptible perturbations have been proposed as a means of protecting images from malicious editing by preventing diffusion models from generating realistic images. However, we find that the aforementioned perturbations are not robust to JPEG compression, which poses a major weakness because of the common usage and availability of JPEG. We discuss the importance of robustness for additive imperceptible perturbations and encourage alternative approaches to protect images against editing.
    
[^120]: 关于径向基函数神经网络普适逼近性质的研究

    On the universal approximation property of radial basis function neural networks. (arXiv:2304.02220v1 [cs.LG])

    [http://arxiv.org/abs/2304.02220](http://arxiv.org/abs/2304.02220)

    本论文研究了一种新的径向基函数神经网络类别，证明这些网络能够逼近任何连续多元函数，还讨论了有限个固定中心的RBF网络的逼近条件。

    

    本文研究了一种新的径向基函数神经网络类别，其中平滑因子被替换为位移。我们在激活函数的一定条件下证明了这些网络能够逼近欧几里得空间d维紧致子集上的任何连续多元函数。对于有限个固定中心的RBF网络，我们描述了保证任意精度逼近的条件。

    In this paper we consider a new class of RBF (Radial Basis Function) neural networks, in which smoothing factors are replaced with shifts. We prove under certain conditions on the activation function that these networks are capable of approximating any continuous multivariate function on any compact subset of the $d$-dimensional Euclidean space. For RBF networks with finitely many fixed centroids we describe conditions guaranteeing approximation with arbitrary precision.
    
[^121]: 《EduceLab-Scrolls：利用X射线CT从赫库兰尼姆纸草卷中可验证地恢复文本》

    EduceLab-Scrolls: Verifiable Recovery of Text from Herculaneum Papyri using X-ray CT. (arXiv:2304.02084v1 [cs.CV])

    [http://arxiv.org/abs/2304.02084](http://arxiv.org/abs/2304.02084)

    该论文介绍了使用X射线CT图像揭示赫库兰尼姆纸草卷隐藏文本的软件管道和数据集。他们运用了机器学习和几何框架的方法检测“不可见”的碳墨，达到了人类专家标记者难以达到的效果。

    

    我们提出了一个用于揭示赫库兰尼姆纸草卷隐藏文本的完整软件管道。这个增强的虚拟展开流水线将机器学习与一种新颖的几何框架相结合，将三维和二维图像联系起来。我们还提出了EduceLab-Scrolls，这是一个全面的开放数据集，代表了二十年来对这个问题的研究努力。EduceLab-Scrolls包含了一组小碎片和完整卷轴的体积X射线CT图像。该数据集还包含用于监督训练油墨检测模型的二维图像标签。通过将卷轴碎片的频谱照片与相同碎片的X射线CT图像对准，从而创建了一个可机器学习的图像空间和模态之间的映射。这种对准允许有监督地学习检测X射线CT中“隐形”碳墨的任务，即使对于人类专家标记者来说也是“不可能”的任务。据我们所知，这是第一个对齐数据集。

    We present a complete software pipeline for revealing the hidden texts of the Herculaneum papyri using X-ray CT images. This enhanced virtual unwrapping pipeline combines machine learning with a novel geometric framework linking 3D and 2D images. We also present EduceLab-Scrolls, a comprehensive open dataset representing two decades of research effort on this problem. EduceLab-Scrolls contains a set of volumetric X-ray CT images of both small fragments and intact, rolled scrolls. The dataset also contains 2D image labels that are used in the supervised training of an ink detection model. Labeling is enabled by aligning spectral photography of scroll fragments with X-ray CT images of the same fragments, thus creating a machine-learnable mapping between image spaces and modalities. This alignment permits supervised learning for the detection of "invisible" carbon ink in X-ray CT, a task that is "impossible" even for human expert labelers. To our knowledge, this is the first aligned datas
    
[^122]: 面向隐私保护联邦蒸馏的有选择知识共享方法

    Selective Knowledge Sharing for Privacy-Preserving Federated Distillation without A Good Teacher. (arXiv:2304.01731v1 [cs.LG])

    [http://arxiv.org/abs/2304.01731](http://arxiv.org/abs/2304.01731)

    本文提出了有选择的联邦蒸馏机制Selective-FD，可以精确地识别来自本地和集合预测的知识，以解决局部数据分布的变异和缺乏好的教师模型而导致的误导和模糊的知识共享问题，并取得了显著提高的模型性能和准确度。

    

    联邦学习是一种隐私保护的协作学习方法，但是容易受到白盒攻击，并且难以适应异构客户端。基于知识蒸馏的联邦蒸馏是一种提供增强隐私保证并解决模型异构性的替代范例。本文提出了一种有选择的联邦蒸馏机制Selective-FD来应对局部数据分布的变异和缺乏好的教师模型而导致的误导和模糊的知识共享问题。它包括客户端选择器和服务器选择器，以精确地识别来自本地和集合预测的知识。实证研究表明，Selective-FD可显著提高模型性能和准确度。

    While federated learning is promising for privacy-preserving collaborative learning without revealing local data, it remains vulnerable to white-box attacks and struggles to adapt to heterogeneous clients. Federated distillation (FD), built upon knowledge distillation--an effective technique for transferring knowledge from a teacher model to student models--emerges as an alternative paradigm, which provides enhanced privacy guarantees and addresses model heterogeneity. Nevertheless, challenges arise due to variations in local data distributions and the absence of a well-trained teacher model, which leads to misleading and ambiguous knowledge sharing that significantly degrades model performance. To address these issues, this paper proposes a selective knowledge sharing mechanism for FD, termed Selective-FD. It includes client-side selectors and a server-side selector to accurately and precisely identify knowledge from local and ensemble predictions, respectively. Empirical studies, bac
    
[^123]: EPVT: 基于环境感知的提示视觉Transformer在皮肤病变识别领域一般化中的应用

    EPVT: Environment-aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition. (arXiv:2304.01508v1 [cs.CV])

    [http://arxiv.org/abs/2304.01508](http://arxiv.org/abs/2304.01508)

    EPVT是一种基于环境感知的提示视觉Transformer，用于解决皮肤病变识别中深度神经网络可能过度依赖疾病不相关图像特征的问题，通过嵌入一组领域提示和一个共享提示来进行领域一般化，并且引入了领域提示生成器促进知识共享。

    

    利用深度学习进行皮肤病变识别已取得重大进展，而在现实世界场景中部署这些系统的需求不断增加。然而，最近的研究表明，用于皮肤病变识别的深度神经网络可能过度依赖于与疾病不相关的图像特征（如暗角、浓密毛发），导致在看不见的环境中表现不佳。为了解决这个问题，我们提出了一种新颖的领域一般化方法——EPVT，它将提示嵌入到Vision Transformer中，以协同学习来自不同领域的知识。具体而言，EPVT利用一组领域提示，每个领域提示都扮演领域专家的角色，以捕获领域特定的知识；以及一个共享提示来获得整个数据集的通用知识。为了促进知识共享和不同提示之间的交互，我们引入了一个领域提示生成器，它使得领域提示与共享提示之间可以进行低秩乘性更新。

    Skin lesion recognition using deep learning has made remarkable progress, and there is an increasing need for deploying these systems in real-world scenarios. However, recent research has revealed that deep neural networks for skin lesion recognition may overly depend on disease-irrelevant image artifacts (i.e. dark corners, dense hairs), leading to poor generalization in unseen environments. To address this issue, we propose a novel domain generalization method called EPVT, which involves embedding prompts into the vision transformer to collaboratively learn knowledge from diverse domains. Concretely, EPVT leverages a set of domain prompts, each of which plays as a domain expert, to capture domain-specific knowledge; and a shared prompt for general knowledge over the entire dataset. To facilitate knowledge sharing and the interaction of different prompts, we introduce a domain prompt generator that enables low-rank multiplicative updates between domain prompts and the shared prompt. A
    
[^124]: TPU v4：一款支持嵌入式硬件的可重构光学超级计算机用于机器学习

    TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings. (arXiv:2304.01433v1 [cs.AR])

    [http://arxiv.org/abs/2304.01433](http://arxiv.org/abs/2304.01433)

    TPU v4是一款支持嵌入式硬件的可重构光学超级计算机，采用光学电路交换机重新配置互连拓扑，提高规模、可用性、利用率、模块化、部署、安全、功率和性能，它通过SparseCores加速嵌入式模型，性能优越，功耗低。

    

    针对机器学习模型的创新，生产工作负载发生了根本性和迅速的变化。TPU v4是谷歌的第五代面向特定领域架构（DSA），是其第三个用于处理此类机器学习模型的超级计算机。光学电路交换机（OCS）动态重新配置其互连拓扑，以提高规模、可用性、利用率、模块化、部署、安全、功率和性能。部署自2020年以来，TPU v4超级计算机的表现优于TPU v3，同时性能/Watt提高了2.7倍。

    In response to innovations in machine learning (ML) models, production workloads changed radically and rapidly. TPU v4 is the fifth Google domain specific architecture (DSA) and its third supercomputer for such ML models. Optical circuit switches (OCSes) dynamically reconfigure its interconnect topology to improve scale, availability, utilization, modularity, deployment, security, power, and performance; users can pick a twisted 3D torus topology if desired. Much cheaper, lower power, and faster than Infiniband, OCSes and underlying optical components are <5% of system cost and <3% of system power. Each TPU v4 includes SparseCores, dataflow processors that accelerate models that rely on embeddings by 5x-7x yet use only 5% of die area and power. Deployed since 2020, TPU v4 outperforms TPU v3 by 2.1x and improves performance/Watt by 2.7x. The TPU v4 supercomputer is 4x larger at 4096 chips and thus ~10x faster overall, which along with OCS flexibility helps large language models. For sim
    
[^125]: DeepAccident：V2X自动驾驶运动和事故预测基准数据集

    DeepAccident: A Motion and Accident Prediction Benchmark for V2X Autonomous Driving. (arXiv:2304.01168v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2304.01168](http://arxiv.org/abs/2304.01168)

    本文提出了一个大规模的 DeepAccident 数据集，其中包含各种真实世界驾驶中发生的事故场景，并提出了一个端到端的运动和事故预测任务，该任务可用于直接评估自动驾驶算法的事故预测能力。

    

    安全是自动驾驶的首要任务。但是，目前没有已发布的数据集可以支持自动驾驶的直接和可解释的安全评估。在本文中，我们提出了 DeepAccident，这是一个通过现实模拟器生成的大规模数据集，包含经常在现实驾驶中发生的各种事故场景。DeepAccident 数据集包含 57k 个带注释帧和 285k 个带注释的样本，这几乎是大规模 nuScenes 数据集的 7 倍，其样本数为 40k。此外，我们基于所提出的数据集提出了一个新任务，即端到端的运动和事故预测，可用于直接评估不同自动驾驶算法的事故预测能力。此外，对于每种场景，我们设置了四辆车和一个基础设施来记录数据，从而为事故场景提供了多种视角，并使 V2X（车辆对一切）感知和预测研究成为可能。

    Safety is the primary priority of autonomous driving. Nevertheless, no published dataset currently supports the direct and explainable safety evaluation for autonomous driving. In this work, we propose DeepAccident, a large-scale dataset generated via a realistic simulator containing diverse accident scenarios that frequently occur in real-world driving. The proposed DeepAccident dataset contains 57K annotated frames and 285K annotated samples, approximately 7 times more than the large-scale nuScenes dataset with 40k annotated samples. In addition, we propose a new task, end-to-end motion and accident prediction, based on the proposed dataset, which can be used to directly evaluate the accident prediction ability for different autonomous driving algorithms. Furthermore, for each scenario, we set four vehicles along with one infrastructure to record data, thus providing diverse viewpoints for accident scenarios and enabling V2X (vehicle-to-everything) research on perception and predicti
    
[^126]: 偶然生成——生成式人工智能中的隐私风险

    Coincidental Generation. (arXiv:2304.01108v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2304.01108](http://arxiv.org/abs/2304.01108)

    生成式人工智能的一种新隐私担忧：偶然生成，可能误导法律和监管机构，暴露个人肖像的法律和监管风险。

    

    生成式人工智能模型已经成为跨各行业的多功能工具，可以应用于隐私数据共享、计算艺术、产品和服务的个性化以及沉浸式娱乐等领域。本文提出了在采用和使用生成式人工智能模型中出现的一种新的隐私担忧——偶然生成。在偶然生成中，生成模型的输出与现有实体相似，超出了用于训练模型的数据集所代表的范围，甚至被误认为是某个实体。举个例子，虚拟模特机构和虚拟股票照片等商业应用中常常使用合成肖像图生成器。由于人脸感知的低内在维度，每个合成生成的脸都会偶然地或多或少地类似于真实人物。这样的偶然生成例子几乎可以保证视觉相似性误导法律和监管机构，暴露了使用生成式人工智能的组织面临的法律和监管风险。

    Generative A.I. models have emerged as versatile tools across diverse industries, with applications in privacy-preserving data sharing, computational art, personalization of products and services, and immersive entertainment. Here, we introduce a new privacy concern in the adoption and use of generative A.I. models: that of coincidental generation, where a generative model's output is similar enough to an existing entity, beyond those represented in the dataset used to train the model, to be mistaken for it. Consider, for example, synthetic portrait generators, which are today deployed in commercial applications such as virtual modeling agencies and synthetic stock photography. Due to the low intrinsic dimensionality of human face perception, every synthetically generated face will coincidentally resemble an actual person. Such examples of coincidental generation all but guarantee the misappropriation of likeness and expose organizations that use generative A.I. to legal and regulatory
    
[^127]: RePAST：相对位姿注意力场景表示变换器

    RePAST: Relative Pose Attention Scene Representation Transformer. (arXiv:2304.00947v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2304.00947](http://arxiv.org/abs/2304.00947)

    RePAST是一种相对位姿注意力场景表示变换器，其将成对的相对相机姿态信息直接注入转换器的注意机制中，不需要固定参考帧，同时保留了原始方法的全部功能，加入这种不变性并不会导致质量下降，可以应用于大规模场景。

    

    场景表示变换器（SRT）是一种最近的方法，可以以交互速率渲染新视图。由于SRT使用相对于任意选择的参考摄像机的相机姿态，因此它对输入视图的顺序不变。因此，SRT不直接适用于需要定期更改参考帧的大规模场景。在这项工作中，我们提出了相对姿态注意力SRT（RePAST）：我们将成对的相对相机姿态信息直接注入转换器的注意机制中，而不是在输入时固定一个参考帧。这导致了一个模型，其定义不变于任何全局参考帧的选择，同时仍保留原始方法的全部功能。实证结果表明，将这种不变性添加到模型中并不会导致质量下降。我们认为这是向应用完全潜在的基于Transformer的渲染方法于大规模场景迈出的一步。

    The Scene Representation Transformer (SRT) is a recent method to render novel views at interactive rates. Since SRT uses camera poses with respect to an arbitrarily chosen reference camera, it is not invariant to the order of the input views. As a result, SRT is not directly applicable to large-scale scenes where the reference frame would need to be changed regularly. In this work, we propose Relative Pose Attention SRT (RePAST): Instead of fixing a reference frame at the input, we inject pairwise relative camera pose information directly into the attention mechanism of the Transformers. This leads to a model that is by definition invariant to the choice of any global reference frame, while still retaining the full capabilities of the original method. Empirical results show that adding this invariance to the model does not lead to a loss in quality. We believe that this is a step towards applying fully latent transformer-based rendering methods to large-scale scenes.
    
[^128]: 在SAR ATR中发现和解释深度学习的非因果性

    Discovering and Explaining the Non-Causality of Deep Learning in SAR ATR. (arXiv:2304.00668v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2304.00668](http://arxiv.org/abs/2304.00668)

    本文通过量化不同区域对目标识别的贡献和解释数据偏差和模型偏差对非因果性的影响，提供了改善深度学习在SAR ATR中鲁棒性和泛化能力的重要见解。

    

    近年来，深度学习在SAR ATR中被广泛使用，并在MSTAR数据集上取得了优异的性能。然而，由于受限的成像条件，MSTAR存在背景相关等数据偏见，即背景杂波特性与目标类别存在虚假相关性。深度学习可以过度拟合杂波以减少训练误差。因此，杂波的过度拟合程度反映了SAR ATR中深度学习的非因果性。现有方法仅定性分析此现象。本文基于Shapley值量化不同区域对目标识别的贡献。杂波的Shapley值可以衡量其过度拟合程度。此外，我们解释了数据偏差和模型偏差对非因果性的影响。简言之，数据偏差导致训练集和测试集中的信杂比和杂波纹理可比，而各种模型结构对这些偏差的过拟合程度不同。非因果性的解释为提高深度学习在SAR ATR中的鲁棒性和泛化能力提供了重要的见解。

    In recent years, deep learning has been widely used in SAR ATR and achieved excellent performance on the MSTAR dataset. However, due to constrained imaging conditions, MSTAR has data biases such as background correlation, i.e., background clutter properties have a spurious correlation with target classes. Deep learning can overfit clutter to reduce training errors. Therefore, the degree of overfitting for clutter reflects the non-causality of deep learning in SAR ATR. Existing methods only qualitatively analyze this phenomenon. In this paper, we quantify the contributions of different regions to target recognition based on the Shapley value. The Shapley value of clutter measures the degree of overfitting. Moreover, we explain how data bias and model bias contribute to non-causality. Concisely, data bias leads to comparable signal-to-clutter ratios and clutter textures in training and test sets. And various model structures have different degrees of overfitting for these biases. The exp
    
[^129]: 建构性同化：通过视图生成策略提升对比学习性能

    Constructive Assimilation: Boosting Contrastive Learning Performance through View Generation Strategies. (arXiv:2304.00601v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2304.00601](http://arxiv.org/abs/2304.00601)

    本文提出了一种建构性同化方法，结合生成视图和专家转换，提高了对比学习技术在三个数据集上的性能。

    

    基于领域专业知识（专家转换）的变换，例如随机裁剪和颜色扰动，已经被证明是对比学习技术（例如SimCLR）成功的关键。最近，有几次尝试用学习的生成视图代替这样的领域特定的、人工设计的转换。然而，到目前为止，针对图像数据，这些视图生成方法都无法胜任专家转换的工作。在本研究中，我们提出了一个不同的问题：我们能否将生成的视图与专家转换建构性地同化，而不是将其替换为专家转换？我们肯定地回答了这个问题，并提出了一个视图生成方法和一个简单有效的同化方法，这两者一起提高了三个不同数据集上的最新水平，最高达到了 ~3.6%。重要的是，我们进行了详细的实证研究，系统地分析了一系列的视图生成和同化方法。

    Transformations based on domain expertise (expert transformations), such as random-resized-crop and color-jitter, have proven critical to the success of contrastive learning techniques such as SimCLR. Recently, several attempts have been made to replace such domain-specific, human-designed transformations with generated views that are learned. However for imagery data, so far none of these view-generation methods has been able to outperform expert transformations. In this work, we tackle a different question: instead of replacing expert transformations with generated views, can we constructively assimilate generated views with expert transformations? We answer this question in the affirmative and propose a view generation method and a simple, effective assimilation method that together improve the state-of-the-art by up to ~3.6% on three different datasets. Importantly, we conduct a detailed empirical study that systematically analyzes a range of view generation and assimilation method
    
[^130]: RL中的反向攻击保护：恢复触发状态方法

    Recover Triggered States: Protect Model Against Backdoor Attack in Reinforcement Learning. (arXiv:2304.00252v1 [cs.LG])

    [http://arxiv.org/abs/2304.00252](http://arxiv.org/abs/2304.00252)

    本文提出了恢复触发状态(RTS)方法，用于保护RL代理免受反向攻击。该方法涉及构建替代网络来近似动态模型，并将触发状态恢复为干净状态来防止攻击者通过触发器激活隐藏在代理中的后门。

    

    反向攻击可以使恶意用户操纵环境或破坏训练数据，并将一个隐藏的后门插入到训练代理程序中。这种攻击危及RL系统的可靠性，在各个关键领域可能会造成灾难性的影响。与此相比，对于RL中的反向攻击有效的防御措施的研究相对较少。本文提出了一种新颖的方法——恢复触发状态(RTS)，能够有效地保护受害代理免受反向攻击。 RTS需要构建一个替代网络来近似动态模型。开发人员可以通过将触发状态恢复为干净状态来防止攻击者通过触发器激活代理中隐藏的后门。在训练替代网络来预测状态时，我们将代理动作信息并入，减少代理在预测状态上采取的动作和实际状态上采取的动作之间的差异。

    A backdoor attack allows a malicious user to manipulate the environment or corrupt the training data, thus inserting a backdoor into the trained agent. Such attacks compromise the RL system's reliability, leading to potentially catastrophic results in various key fields. In contrast, relatively limited research has investigated effective defenses against backdoor attacks in RL. This paper proposes the Recovery Triggered States (RTS) method, a novel approach that effectively protects the victim agents from backdoor attacks. RTS involves building a surrogate network to approximate the dynamics model. Developers can then recover the environment from the triggered state to a clean state, thereby preventing attackers from activating backdoors hidden in the agent by presenting the trigger. When training the surrogate to predict states, we incorporate agent action information to reduce the discrepancy between the actions taken by the agent on predicted states and the actions taken on real sta
    
[^131]: 隐式模板化ODE-nets的实现和(反转修正)误差分析

    Implementation and (Inverse Modified) Error Analysis for implicitly-templated ODE-nets. (arXiv:2303.17824v1 [math.NA])

    [http://arxiv.org/abs/2303.17824](http://arxiv.org/abs/2303.17824)

    本文重点研究使用隐式数值初值问题求解器模板的ODE-nets。使用展开的隐式方案对ODE-nets进行训练可以返回一个接近于反转修正微分方程(IMDE)的近似值，并且我们可以使用自适应算法加速训练并保持精度。

    

    本文着重研究使用基于隐式数值初值问题求解器模板的ODE-nets来学习数据中的隐含动力学。首先，我们使用展开的隐式方案对ODE-nets进行反转修正误差分析以方便解释。结果表明，使用展开的隐式方案对ODE-nets进行训练返回了一个接近于反转修正微分方程(IMDE)的近似值。此外，我们建立了针对训练此类ODE-nets进行超参数选择的理论基础，而当前的策略通常将ODE-nets的数值积分视为黑匣子。因此，我们制定了一种自适应算法，在训练过程中监测误差级别并调整(展开的)隐式解法的迭代次数，以使展开的近似误差小于当前的学习损失。这有助于加速训练，同时保持精度。我们进行了多个数值实验以展示该方法的优越性。

    We focus on learning hidden dynamics from data using ODE-nets templated on implicit numerical initial value problem solvers. First, we perform Inverse Modified error analysis of the ODE-nets using unrolled implicit schemes for ease of interpretation. It is shown that training an ODE-net using an unrolled implicit scheme returns a close approximation of an Inverse Modified Differential Equation (IMDE). In addition, we establish a theoretical basis for hyper-parameter selection when training such ODE-nets, whereas current strategies usually treat numerical integration of ODE-nets as a black box. We thus formulate an adaptive algorithm which monitors the level of error and adapts the number of (unrolled) implicit solution iterations during the training process, so that the error of the unrolled approximation is less than the current learning loss. This helps accelerate training, while maintaining accuracy. Several numerical experiments are performed to demonstrate the advantages of the pr
    
[^132]: HARFLOW3D：一种面向FPGA设备的基于延迟的3D-CNN加速器工具链

    HARFLOW3D: A Latency-Oriented 3D-CNN Accelerator Toolflow for HAR on FPGA Devices. (arXiv:2303.17218v1 [cs.AR])

    [http://arxiv.org/abs/2303.17218](http://arxiv.org/abs/2303.17218)

    本研究提出了一种面向FPGA设备的基于延迟的3D-CNN加速器工具链HARFLOW3D，它以机器学习模型和FPGA的特性描述为输入，生成最小化计算延迟的设计。实验证明HARFLOW3D相比其他方案能够实现更低的延迟。

    

    3D卷积神经网络已被证明在人体动作识别任务中具有高效性和最先进的结果。本研究引入一种新的基于流式架构的工具链，将此类模型映射到FPGA上，考虑模型固有特性和目标FPGA设备的特征。HARFLOW3D工具链以ONNX格式的3D卷积神经网络和FPGA特性描述为输入，生成最小化计算延迟的设计。该工具链由多个部分组成，包括i) 3D CNN解析器，ii) 性能和资源模型，iii) 用于在生成的硬件上执行3D模型的调度算法，iv) 针对3D模型量身定制的资源感知优化引擎，v) 自动映射到可合成的FPGA代码。通过对各种3D CNN和FPGA系统配对进行多个实验，展示了工具链支持广泛模型和设备的能力。此外，与其他最先进的3D CNN加速器设计方法相比，该工具链实现了更低的延迟。

    For Human Action Recognition tasks (HAR), 3D Convolutional Neural Networks have proven to be highly effective, achieving state-of-the-art results. This study introduces a novel streaming architecture based toolflow for mapping such models onto FPGAs considering the model's inherent characteristics and the features of the targeted FPGA device. The HARFLOW3D toolflow takes as input a 3D CNN in ONNX format and a description of the FPGA characteristics, generating a design that minimizes the latency of the computation. The toolflow is comprised of a number of parts, including i) a 3D CNN parser, ii) a performance and resource model, iii) a scheduling algorithm for executing 3D models on the generated hardware, iv) a resource-aware optimization engine tailored for 3D models, v) an automated mapping to synthesizable code for FPGAs. The ability of the toolflow to support a broad range of models and devices is shown through a number of experiments on various 3D CNN and FPGA system pairs. Furth
    
[^133]: 使用语言反馈规模化训练语言模型

    Training Language Models with Language Feedback at Scale. (arXiv:2303.16755v1 [cs.CL])

    [http://arxiv.org/abs/2303.16755](http://arxiv.org/abs/2303.16755)

    本文提出一种新方法，即利用更丰富的语言反馈进行模仿学习，通过三个迭代步骤对语言模型进行训练以生成更符合人类偏好的输出。

    

    预训练的语言模型经常生成不符合人类偏好的输出，例如有害的文本或事实不正确的摘要。最近的研究尝试通过学习一种简单的人类反馈形式（即模型生成输出之间的比较）来解决这些问题。但是，比较反馈只能传达有限的关于人类偏好的信息。在本文中，我们介绍了一种新的方法——使用语言反馈进行模仿学习（ILF），它利用了更丰富的语言反馈。ILF由三个迭代步骤组成：第一步，根据输入，初始LM输出和反馈对语言模型进行调节以生成改进。第二步，选择最多反馈的改进。第三步，微调语言模型，以最大化在给定输入的情况下选择的改进的可能性。我们在理论上证明了ILF可以被看作是贝叶斯推断，类似于从人类反馈中进行强化学习。我们还评估了ILF在各种基准测试中的性能。

    Pretrained language models often generate outputs that are not in line with human preferences, such as harmful text or factually incorrect summaries. Recent work approaches the above issues by learning from a simple form of human feedback: comparisons between pairs of model-generated outputs. However, comparison feedback only conveys limited information about human preferences. In this paper, we introduce Imitation learning from Language Feedback (ILF), a new approach that utilizes more informative language feedback. ILF consists of three steps that are applied iteratively: first, conditioning the language model on the input, an initial LM output, and feedback to generate refinements. Second, selecting the refinement incorporating the most feedback. Third, finetuning the language model to maximize the likelihood of the chosen refinement given the input. We show theoretically that ILF can be viewed as Bayesian Inference, similar to Reinforcement Learning from human feedback. We evaluate
    
[^134]: 光学星间链路联合学习中的边缘选择和聚类

    Edge Selection and Clustering for Federated Learning in Optical Inter-LEO Satellite Constellation. (arXiv:2303.16071v1 [cs.LG])

    [http://arxiv.org/abs/2303.16071](http://arxiv.org/abs/2303.16071)

    FedLEO是一种在超密集LEO卫星星座上进行联合学习的方法，其在LEO上进行视频/数据传输和聚类，而低时延的地面网关服务器 (GS) 仅负责初始信号控制。随着LEO服务器的变化和重新聚类，FedLEO能够适应动态LEO星座并在不同的LEO星座设置下实现高效的学习性能。

    

    由于低地球轨道 (LEO) 卫星可以收集大量的影像或传感器数据，因此已经被广泛用于各种地球观测任务。然而，传统上，数据训练过程是在地面云服务器上进行的，这导致了很高的传输开销。最近 LEO 的发展更迫切地需要提供具备增强的机载计算能力的超密集 LEO 卫星星座。基于此，我们提出了一种在 LEO 卫星星座上进行协作联合学习的方法 (FedLEO)。我们将整个过程都分配在具备低载荷星间传输的 LEO 上，而低时延的地面网关服务器 (GS) 仅负责初始信号控制。GS 首先选择一个 LEO 服务器，而其 LEO 客户端都通过聚类机制和光学星间链路(ISLs)的通信能力决定。更换 LEO 服务器时的重新聚类将触发新一轮的 LEO 客户端聚类，从而使 FedLEO 能够适应动态 LEO 星座。仿真结果表明，FedLEO 可以在不同的 LEO 星座设置下实现高效的学习性能。

    Low-Earth orbit (LEO) satellites have been prosperously deployed for various Earth observation missions due to its capability of collecting a large amount of image or sensor data. However, traditionally, the data training process is performed in the terrestrial cloud server, which leads to a high transmission overhead. With the recent development of LEO, it is more imperative to provide ultra-dense LEO constellation with enhanced on-board computation capability. Benefited from it, we have proposed a collaborative federated learning over LEO satellite constellation (FedLEO). We allocate the entire process on LEOs with low payload inter-satellite transmissions, whilst the low-delay terrestrial gateway server (GS) only takes care for initial signal controlling. The GS initially selects an LEO server, whereas its LEO clients are all determined by clustering mechanism and communication capability through the optical inter-satellite links (ISLs). The re-clustering of changing LEO server will
    
[^135]: TabRet: 预训练Transformer-based表格模型，支持未知列

    TabRet: Pre-training Transformer-based Tabular Models for Unseen Columns. (arXiv:2303.15747v1 [cs.LG])

    [http://arxiv.org/abs/2303.15747](http://arxiv.org/abs/2303.15747)

    提出了一种可预训练的Transformer-based表格模型：TabRet，能够支持未知列，并在医疗保健分类任务上表现优秀。重新标记化和随机洗牌增强对性能提升有贡献。

    

    我们提出了一种名为TabRet的可预训练Transformer-based表格模型。TabRet旨在为包含未在预训练中见过的列的下游任务提供支持。与其他方法不同，TabRet在微调之前有一个额外的学习步骤，称为重新标记化，它基于遮蔽自动编码损失来校准特征嵌入。在实验中，我们使用大量的公共健康调查数据对TabRet进行预训练，并在医疗保健分类任务上进行微调，在四个数据集上实现了最佳AUC性能。此外，消融研究表明，在预训练期间进行重新标记化和随机洗牌增强对性能提升有贡献。

    We present \emph{TabRet}, a pre-trainable Transformer-based model for tabular data. TabRet is designed to work on a downstream task that contains columns not seen in pre-training. Unlike other methods, TabRet has an extra learning step before fine-tuning called \emph{retokenizing}, which calibrates feature embeddings based on the masked autoencoding loss. In experiments, we pre-trained TabRet with a large collection of public health surveys and fine-tuned it on classification tasks in healthcare, and TabRet achieved the best AUC performance on four datasets. In addition, an ablation study shows retokenizing and random shuffle augmentation of columns during pre-training contributed to performance gains.
    
[^136]: 从单个医院到多个中心应用：增强ICU中深度学习模型的泛化能力

    From Single-Hospital to Multi-Centre Applications: Enhancing the Generalisability of Deep Learning Models for Adverse Event Prediction in the ICU. (arXiv:2303.15354v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.15354](http://arxiv.org/abs/2303.15354)

    本研究通过使用多个数据源和在训练中明确优化泛化性能，提高了深度学习模型在新医院中预测ICU患者不良事件的性能和可靠性。

    

    深度学习模型可以帮助医生及早检测患者恶化状态，为他们提供反应时间并防止不良结果。虽然基于深度学习的早期预警模型通常在它们受过训练的医院中表现良好，但在新医院应用时它们往往不太可靠。这使得在规模上部署它们变得困难。我们使用来自欧洲和美国四个数据源的精心协调的重症监护数据（总计334,812个停留时间），系统评估深度学习模型对三种常见不良事件的可靠性：死亡、急性肾损伤（AKI）和脓毒症。我们测试了使用多个数据源和/或在训练过程中明确优化泛化能力是否提高了模型在新医院的性能。我们发现，模型在训练医院对于死亡率（0.838-0.869）、AKI（0.823-0.866）和脓毒症（0.749-0.824）实现了较高的AUROC。预期地，性能在新医院下降，有时下降了-0.200。在训练过程中使用超过一个数据源并明确优化泛化性能可以提高模型在新医院的性能。我们的发现表明，这种方法可以帮助部署健壮且普适的深度学习模型，以预测ICU中的不良事件。

    Deep learning (DL) can aid doctors in detecting worsening patient states early, affording them time to react and prevent bad outcomes. While DL-based early warning models usually work well in the hospitals they were trained for, they tend to be less reliable when applied at new hospitals. This makes it difficult to deploy them at scale. Using carefully harmonised intensive care data from four data sources across Europe and the US (totalling 334,812 stays), we systematically assessed the reliability of DL models for three common adverse events: death, acute kidney injury (AKI), and sepsis. We tested whether using more than one data source and/or explicitly optimising for generalisability during training improves model performance at new hospitals. We found that models achieved high AUROC for mortality (0.838-0.869), AKI (0.823-0.866), and sepsis (0.749-0.824) at the training hospital. As expected, performance dropped at new hospitals, sometimes by as much as -0.200. Using more than one 
    
[^137]: 你有在使用我的数据集进行训练吗？使用清洁标签背门数字水印实现公共数据集保护

    Did You Train on My Dataset? Towards Public Dataset Protection with Clean-Label Backdoor Watermarking. (arXiv:2303.11470v1 [cs.CR])

    [http://arxiv.org/abs/2303.11470](http://arxiv.org/abs/2303.11470)

    提出了一种基于背门数字水印的方法，以确保公共数据的安全。通过在数据集中插入极少量的数字水印样本，隐式学习一个隐藏的函数作为数字水印，以跟踪非法使用此数据集的模型。使用“清洁标签背门”方法实现了数字水印，不会破坏原始数据集。实验证明，该方法有效地检测到非法利用数据集的行为。

    

    互联网上源源不断的支持训练数据是深度学习模型成功的关键因素。然而，这种大量的公共数据也引起了对数据集被未经授权的用于商业目的的担忧，这是数据集许可证所禁止的。本文提出了一种基于背门数字水印的方法，作为保护公共数据的通用框架。通过向数据集中插入少量的数字水印样本，我们的方法使学习模型能够隐式学习由防御者设置的秘密函数。这个隐藏的函数可以作为数字水印，用于跟踪非法使用数据集的第三方模型。不幸的是，现有的背门插入方法往往涉及向训练集中添加任意的、错误标记的数据，导致性能显著下降，并容易被异常检测算法检测到。为了克服这个挑战，我们引入了一种清洁标记背门方法，实现了数字水印而不破坏原始数据集。我们的方法在几个图像分类任务上进行了评估，证明了它在检测非法数据集使用方面的有效性。

    The huge supporting training data on the Internet has been a key factor in the success of deep learning models. However, this abundance of public-available data also raises concerns about the unauthorized exploitation of datasets for commercial purposes, which is forbidden by dataset licenses. In this paper, we propose a backdoor-based watermarking approach that serves as a general framework for safeguarding public-available data. By inserting a small number of watermarking samples into the dataset, our approach enables the learning model to implicitly learn a secret function set by defenders. This hidden function can then be used as a watermark to track down third-party models that use the dataset illegally. Unfortunately, existing backdoor insertion methods often entail adding arbitrary and mislabeled data to the training set, leading to a significant drop in performance and easy detection by anomaly detection algorithms. To overcome this challenge, we introduce a clean-label backdoo
    
[^138]: 使用复值神经场的物理信息光学核回归

    Physics-Informed Optical Kernel Regression Using Complex-valued Neural Fields. (arXiv:2303.08435v1 [cs.CV])

    [http://arxiv.org/abs/2303.08435](http://arxiv.org/abs/2303.08435)

    本文提出了一种新的基于机器学习的光刻模型范式，通过优化复值神经场执行光学核回归并将光刻系统拆解为非参数掩模操作和包含行列式源、瞳孔和光刻信息的学习光学核，使用小规模训练数据集展示了卓越的推广能力。

    

    光刻是集成电路制造的基础，需要大量计算。基于机器学习的光刻模型的发展缓解了制造过程开销和能力之间的平衡。然而，所有以前的方法都将光刻系统视为图像到图像的黑盒映射，利用网络参数通过死记硬背映射大量的掩模到空中或掩模到电阻图像对，导致推广能力不佳。本文提出了一种新的基于机器学习的范式，将严格的光刻模型拆解为非参数掩模操作和包含行列式源、瞳孔和光刻信息的学习光学核。通过优化复值神经场以执行光学核回归，我们的方法可以准确地恢复光刻系统，同时使用较少的参数进行小规模训练数据集，展示了卓越的推广能力。

    Lithography is fundamental to integrated circuit fabrication, necessitating large computation overhead. The advancement of machine learning (ML)-based lithography models alleviates the trade-offs between manufacturing process expense and capability. However, all previous methods regard the lithography system as an image-to-image black box mapping, utilizing network parameters to learn by rote mappings from massive mask-to-aerial or mask-to-resist image pairs, resulting in poor generalization capability. In this paper, we propose a new ML-based paradigm disassembling the rigorous lithographic model into non-parametric mask operations and learned optical kernels containing determinant source, pupil, and lithography information. By optimizing complex-valued neural fields to perform optical kernel regression from coordinates, our method can accurately restore lithography system using a small-scale training dataset with fewer parameters, demonstrating superior generalization capability as w
    
[^139]: 多模态Transformer预测态密度

    Predicting Density of States via Multi-modal Transformer. (arXiv:2303.07000v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.07000](http://arxiv.org/abs/2303.07000)

    本文基于多模态Transformer，从晶体结构和能量入手预测DOS，可应用于声子和电子DOS。

    

    状态密度（DOS）是材料的谱学特性，它提供了关于材料各种特性的基本见解。本文提出了一种模型来预测DOS，通过反映DOS的性质：DOS确定作为能量函数的状态的一般分布。具体地，我们通过多模态Transformer集成晶体结构和能量获得的异构信息，从而模拟晶体结构中原子之间的复杂关系和各种能级。通过各种真实情况下的两种DOS（即声子DOS和电子DOS）的广泛实验显示了DOSTransformer的优越性。DOSTransformer的源代码可在https://github.com/HeewoongNoh/DOSTransformer上获得。

    The density of states (DOS) is a spectral property of materials, which provides fundamental insights on various characteristics of materials. In this paper, we propose a model to predict the DOS by reflecting the nature of DOS: DOS determines the general distribution of states as a function of energy. Specifically, we integrate the heterogeneous information obtained from the crystal structure and the energies via multi-modal transformer, thereby modeling the complex relationships between the atoms in the crystal structure, and various energy levels. Extensive experiments on two types of DOS, i.e., Phonon DOS and Electron DOS, with various real-world scenarios demonstrate the superiority of DOSTransformer. The source code for DOSTransformer is available at https://github.com/HeewoongNoh/DOSTransformer.
    
[^140]: 两层神经网络初始凝聚的相图

    Phase Diagram of Initial Condensation for Two-layer Neural Networks. (arXiv:2303.06561v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.06561](http://arxiv.org/abs/2303.06561)

    本文提出了一个两层神经网络初始凝聚的相图，旨在提供对神经网络动力学区域及其与初始化相关的超参数选择的综合理解。同时，我们详细解释了小初始化导致在初始训练阶段出现凝聚的基本机制。

    

    神经网络在不同初始化比例下呈现出不同行为的现象一直是深度学习领域中的难题。本文基于Luo等人早期的工作，提出了一个两层神经网络初始凝聚的相图。凝聚是神经网络在训练过程中权重向量集中于独立方向的现象，在非线性学习过程中是一种特性，使神经网络拥有更好的泛化能力。我们的相图旨在提供对神经网络动力学区域及其与初始化相关的超参数选择的综合理解。此外，我们详细展示了小初始化导致在初始训练阶段出现凝聚的基本机制。

    The phenomenon of distinct behaviors exhibited by neural networks under varying scales of initialization remains an enigma in deep learning research. In this paper, based on the earlier work by Luo et al.~\cite{luo2021phase}, we present a phase diagram of initial condensation for two-layer neural networks. Condensation is a phenomenon wherein the weight vectors of neural networks concentrate on isolated orientations during the training process, and it is a feature in non-linear learning process that enables neural networks to possess better generalization abilities. Our phase diagram serves to provide a comprehensive understanding of the dynamical regimes of neural networks and their dependence on the choice of hyperparameters related to initialization. Furthermore, we demonstrate in detail the underlying mechanisms by which small initialization leads to condensation at the initial training stage.
    
[^141]: 神经图形的硬件加速

    Hardware Acceleration of Neural Graphics. (arXiv:2303.05735v2 [cs.AR] UPDATED)

    [http://arxiv.org/abs/2303.05735](http://arxiv.org/abs/2303.05735)

    本文研究了神经图形是否需要硬件支持，发现当前GPU性能无法满足对4K分辨率60FPS渲染的需求，且在增强现实/虚拟现实应用中性能缺口更大。作者确定输入编码和MLP内核是性能瓶颈。

    

    传统的计算机图形学渲染和反渲染算法已被神经表示（NR）所取代。NR最近被用于学习场景的几何和材质属性，并使用这些信息合成真实的图像，因此承诺用可伸缩的质量和可预测的性能替换传统的渲染算法。本文提出问题：神经图形（NG）是否需要硬件支持？我们研究了代表性的NG应用程序，发现如果我们要在当前的GPU上以60FPS渲染4K分辨率，则所需性能与当前GPU的实际性能存在1.5倍至55倍的差距。对于增强现实/虚拟现实应用程序，所需性能与所需系统功率之间存在更大的差距。我们确定输入编码和MLP内核是性能瓶颈，对于多分辨率哈希网格、多分辨率密集网格和低分辨率密集网格，它们占应用程序时间的72％、60％和59％。

    Rendering and inverse-rendering algorithms that drive conventional computer graphics have recently been superseded by neural representations (NR). NRs have recently been used to learn the geometric and the material properties of the scenes and use the information to synthesize photorealistic imagery, thereby promising a replacement for traditional rendering algorithms with scalable quality and predictable performance. In this work we ask the question: Does neural graphics (NG) need hardware support? We studied representative NG applications showing that, if we want to render 4k res. at 60FPS there is a gap of 1.5X-55X in the desired performance on current GPUs. For AR/VR applications, there is an even larger gap of 2-4 OOM between the desired performance and the required system power. We identify that the input encoding and the MLP kernels are the performance bottlenecks, consuming 72%,60% and 59% of application time for multi res. hashgrid, multi res. densegrid and low res. densegrid 
    
[^142]: 通过Softmax逼近实现动态最优策略的推断

    Inference on Optimal Dynamic Policies via Softmax Approximation. (arXiv:2303.04416v2 [econ.EM] UPDATED)

    [http://arxiv.org/abs/2303.04416](http://arxiv.org/abs/2303.04416)

    本文提出了一种简单的softmax逼近方法，可用于从离线数据中估计最优的动态治疗方案并对其进行有效推断。

    

    从离线数据中估计最优的动态策略是动态决策制定中的一个基本问题。在因果推断的背景下，该问题被称为估计最优的动态治疗方案。即使存在大量的估计方法，构建置信区间来估计最优策略的价值及其相关的结构参数本质上更加困难，因为它涉及到未知量的非线性和非可微函数。以前的研究采用了亚样本方法，但可能会降低估计的质量。我们证明，对于一个适当增长的温度参数，最优治疗方案的简单softmax逼近可以实现对真正最优方案的有效推断。我们将我们的结果用于两期的最优动态方案，并将该方法直接推广到有限的时间段情况。我们的工作结合了半参数方法和机器学习技术。

    Estimating optimal dynamic policies from offline data is a fundamental problem in dynamic decision making. In the context of causal inference, the problem is known as estimating the optimal dynamic treatment regime. Even though there exists a plethora of methods for estimation, constructing confidence intervals for the value of the optimal regime and structural parameters associated with it is inherently harder, as it involves non-linear and non-differentiable functionals of un-known quantities that need to be estimated. Prior work resorted to sub-sample approaches that can deteriorate the quality of the estimate. We show that a simple soft-max approximation to the optimal treatment regime, for an appropriately fast growing temperature parameter, can achieve valid inference on the truly optimal regime. We illustrate our result for a two-period optimal dynamic regime, though our approach should directly extend to the finite horizon case. Our work combines techniques from semi-parametric
    
[^143]: 基于多模态多核图学习的自闭症预测与生物标志物发现

    Multi-modal Multi-kernel Graph Learning for Autism Prediction and Biomarker Discovery. (arXiv:2303.03388v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.03388](http://arxiv.org/abs/2303.03388)

    本文提出了一种名为MMKGL的新方法，能够解决多模态集成中各模态之间的负面影响，并从多个图中提取异质信息，以进行自闭症的预测和生物标志物的发现。

    

    基于图学习的多模态集成和分类是疾病预测中最具挑战性的障碍之一。我们提出了一种名为MMKGL的新方法来有效抵消多模态集成过程中各模态之间负面影响，并从图中提取异质信息。具体地，我们提出了多模态图嵌入模块，并通过自适应学习生成多个图，然后提出多核图学习模块，从多模态图中提取异质信息。在不同层次上聚合多模态图中的信息，实现了对自闭症的预测和生物标志物的发现。

    Due to its complexity, graph learning-based multi-modal integration and classification is one of the most challenging obstacles for disease prediction. To effectively offset the negative impact between modalities in the process of multi-modal integration and extract heterogeneous information from graphs, we propose a novel method called MMKGL (Multi-modal Multi-Kernel Graph Learning). For the problem of negative impact between modalities, we propose a multi-modal graph embedding module to construct a multi-modal graph. Different from conventional methods that manually construct static graphs for all modalities, each modality generates a separate graph by adaptive learning, where a function graph and a supervision graph are introduced for optimization during the multi-graph fusion embedding process. We then propose a multi-kernel graph learning module to extract heterogeneous information from the multi-modal graph. The information in the multi-modal graph at different levels is aggregat
    
[^144]: 学习机器在医疗及其他方面的应用

    Learning machines for health and beyond. (arXiv:2303.01513v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.01513](http://arxiv.org/abs/2303.01513)

    适用于建立预测模型的机器学习技术在医疗领域和其他领域具有广泛应用。模型的维护和监控很关键，因为模型的性能与数据的变化和传输有关。

    

    机器学习技术在构建预测模型方面具有良好效果，因为它们擅长识别大型数据集中的模式。然而，对于复杂的现实问题，模型的开发往往停留在发表论文、概念验证或通过某种部署模式的可访问性。然而，在医疗领域里，模型的患者人口会发生变化，因此模型的维护和监控是确保其长期安全有效使用的关键。由于机器学习技术是有效地训练以在可用数据集中寻找模式的，因此，对于复杂的现实问题，模型的性能不会在发表或部署时达到峰值后固定不变。相反，数据会随着时间的变化而产生变化，而当模型被运往新的地方供新的人群使用时，它们也会发生变化。

    Machine learning techniques are effective for building predictive models because they are good at identifying patterns in large datasets. Development of a model for complex real life problems often stops at the point of publication, proof of concept or when made accessible through some mode of deployment. However, a model in the medical domain risks becoming obsolete as soon as patient demographic changes. The maintenance and monitoring of predictive models post-publication is crucial to guarantee their safe and effective long term use. As machine learning techniques are effectively trained to look for patterns in available datasets, the performance of a model for complex real life problems will not peak and remain fixed at the point of publication or even point of deployment. Rather, data changes over time, and they also changed when models are transported to new places to be used by new demography.
    
[^145]: 使用WENDy直接估计ODE模型参数：弱形式估计非线性动力学

    Direct Estimation of Parameters in ODE Models Using WENDy: Weak-form Estimation of Nonlinear Dynamics. (arXiv:2302.13271v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.13271](http://arxiv.org/abs/2302.13271)

    该论文提出了一种无需任何数值微分方程求解器的弱形式估计非线性动力学（WENDy）方法，用于估计非线性ODE系统的模型参数。该方法精度高、鲁棒性强、速度快。

    

    我们引入了弱形式估计非线性动力学（WENDy）方法，用于估计非线性ODE系统的模型参数。WENDy不依赖于任何数值微分方程求解器，可以计算准确的估计值，并且对于大量（生物学上重要的）测量噪声是鲁棒的。对于低维系统和适度数量的数据，WENDy在速度和精度上与传统的基于前向求解器的非线性最小二乘方法相竞争。对于高维系统和强系统，WENDy通常比基于前向求解器的方法更快（通常快几个数量级）和更精确。其核心数学思想涉及将模型的强形式表示有效地转换为其弱形式，然后解决回归问题以进行参数推断。其核心统计思想基于误差对变量框架，这需要使用迭代加权最小二乘法。

    We introduce the Weak-form Estimation of Nonlinear Dynamics (WENDy) method for estimating model parameters for non-linear systems of ODEs. Without relying on any numerical differential equation solvers, WENDy computes accurate estimates and is robust to large (biologically relevant) levels of measurement noise. For low dimensional systems with modest amounts of data, WENDy is competitive with conventional forward solver-based nonlinear least squares methods in terms of speed and accuracy. For both higher dimensional systems and stiff systems, WENDy is typically both faster (often by orders of magnitude) and more accurate than forward solver-based approaches.  The core mathematical idea involves an efficient conversion of the strong form representation of a model to its weak form, and then solving a regression problem to perform parameter inference. The core statistical idea rests on the Errors-In-Variables framework, which necessitates the use of the iteratively reweighted least square
    
[^146]: 针对非光滑偏微分方程约束的优化问题，使用ADMM-PINNs算法框架进行深度学习处理

    The ADMM-PINNs Algorithmic Framework for Nonsmooth PDE-Constrained Optimization: A Deep Learning Approach. (arXiv:2302.08309v1 [math.OC] CROSS LISTED)

    [http://arxiv.org/abs/2302.08309](http://arxiv.org/abs/2302.08309)

    本论文提出了采用ADMM-PINNs算法框架解决非光滑PDE约束优化问题的方法，在迭代中采用ADMM将PDE约束和非光滑正则化项分离，使得可以高效地解决 PDE-constrained optimization problems。

    

    本文研究了使用多重乘数交替方向法(ADMM)和物理信息神经网络(PINNs)的组合来解决一般类别的非光滑偏微分方程(PDE)约束优化问题。当需要对控制或设计变量进行限制时，可以采用附加正则化方法。所得到的ADMM-PINNs算法框架极大地扩展了PINNs的适用范围，可以应用于非光滑的PDE约束的优化问题。采用ADMM可以将PDE约束和非光滑正则化项分离出来，使迭代更加高效。在每次迭代中，其中的一个子问题是平滑的PDE受约束优化问题，可以通过PINNs有效地解决，而另一个是简单的非光滑优化问题，通常有封闭形式解或可以通过多种标准优化算法或预训练的神经网络有效地解决。通过两个数值实验证明了ADMM-PINNs算法框架在解决PDE约束的非光滑约束优化问题方面的有效性和鲁棒性。

    We study the combination of the alternating direction method of multipliers (ADMM) with physics-informed neural networks (PINNs) for a general class of nonsmooth partial differential equation (PDE)-constrained optimization problems, where additional regularization can be employed for constraints on the control or design variables. The resulting ADMM-PINNs algorithmic framework substantially enlarges the applicable range of PINNs to nonsmooth cases of PDE-constrained optimization problems. The application of the ADMM makes it possible to untie the PDE constraints and the nonsmooth regularization terms for iterations. Accordingly, at each iteration, one of the resulting subproblems is a smooth PDE-constrained optimization which can be efficiently solved by PINNs, and the other is a simple nonsmooth optimization problem which usually has a closed-form solution or can be efficiently solved by various standard optimization algorithms or pre-trained neural networks. The ADMM-PINNs algorithmi
    
[^147]: 用于分散式机器学习的新兴RISC-V系统的实验

    Experimenting with Emerging RISC-V Systems for Decentralised Machine Learning. (arXiv:2302.07946v2 [cs.DC] UPDATED)

    [http://arxiv.org/abs/2302.07946](http://arxiv.org/abs/2302.07946)

    该研究介绍了一种特定领域语言，用于将分散式机器学习方案映射到FastFlow并行编程库。通过在不同处理器平台上生成不同的DML方案，研究者评估了所提出方案和系统的性能和能源效率，并成功移植了PyTorch框架到RISC-V平台。

    

    分散式机器学习（DML）使合作机器学习摆脱了集中式输入数据。联合学习（FL）和边缘推断是DML的示例。虽然DML工具（特别是FL）开始蓬勃发展，但许多工具不够灵活和便携，无法用于实验新型处理器（例如RISC-V），非全连接网络拓扑和异步协作方案。我们通过一种特定领域的语言克服了这些限制，将DML方案映射到基础中间件（即FastFlow并行编程库）。我们通过在x86-64和ARM平台以及新兴的RISC-V平台上生成不同的DML方案来进行实验。我们表征了所提出的方案和系统的性能和能源效率。作为附带产品，我们介绍了PyTorch框架的RISC-V移植，这是我们所知道的第一个公开可用的移植。

    Decentralised Machine Learning (DML) enables collaborative machine learning without centralised input data. Federated Learning (FL) and Edge Inference are examples of DML. While tools for DML (especially FL) are starting to flourish, many are not flexible and portable enough to experiment with novel processors (e.g., RISC-V), non-fully connected network topologies, and asynchronous collaboration schemes. We overcome these limitations via a domain-specific language allowing us to map DML schemes to an underlying middleware, i.e. the FastFlow parallel programming library. We experiment with it by generating different working DML schemes on x86-64 and ARM platforms and an emerging RISC-V one. We characterise the performance and energy efficiency of the presented schemes and systems. As a byproduct, we introduce a RISC-V porting of the PyTorch framework, the first publicly available to our knowledge.
    
[^148]: 面向药物靶向相互作用的联邦学习基准

    A Federated Learning Benchmark for Drug-Target Interaction. (arXiv:2302.07684v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.07684](http://arxiv.org/abs/2302.07684)

    本文提出在DTI领域中采用联邦学习来汇集制药数据，相对于最佳非隐私保护替代方法可获得高达15%的性能提升，且非IID数据分布不会降低联邦学习的性能。

    

    在药物靶向相互作用(DTI)领域中汇集制药数据具有提供挽救生命的突破的潜力。然而，由于监管限制和商业利益，这是非常困难的。本文提出了联邦学习的应用，认为这与行业的限制是和解的，因为它不需要共享任何信息，这些信息可以揭示实体的数据或任何其他的高水平总结。当运用于代表性的GraphDTA模型和KIBA数据集时，相对于最佳的非隐私保护替代方法，它可以实现高达15%的性能提升。我们广泛的一系列实验表明，在DTI数据集中，与其他领域不同的是，非IID数据分布不会降低联邦学习的性能。此外，我们确定了添加新数据的益处与添加更多客户的成本之间的实质性平衡。

    Aggregating pharmaceutical data in the drug-target interaction (DTI) domain has the potential to deliver life-saving breakthroughs. It is, however, notoriously difficult due to regulatory constraints and commercial interests. This work proposes the application of federated learning, which we argue to be reconcilable with the industry's constraints, as it does not require sharing of any information that would reveal the entities' data or any other high-level summary of it. When used on a representative GraphDTA model and the KIBA dataset it achieves up to 15% improved performance relative to the best available non-privacy preserving alternative. Our extensive battery of experiments shows that, unlike in other domains, the non-IID data distribution in the DTI datasets does not deteriorate FL performance. Additionally, we identify a material trade-off between the benefits of adding new data, and the cost of adding more clients.
    
[^149]: 基于大规模蛋白质接触预测模型的知识可以转化到数据稀缺的RNA接触预测任务中

    Knowledge from Large-Scale Protein Contact Prediction Models Can Be Transferred to the Data-Scarce RNA Contact Prediction Task. (arXiv:2302.06120v2 [q-bio.QM] UPDATED)

    [http://arxiv.org/abs/2302.06120](http://arxiv.org/abs/2302.06120)

    本文发现基于蛋白质共进化的Transformer深度神经网络学习的知识可以转移到RNA接触预测任务中，显著提高数据稀缺的RNA接触预测的准确性。

    

    RNA通过其结构在许多生物活动中起着重要作用，其功能往往受其结构的影响。预测RNA序列中每个核苷酸之间的结构接近性可以表征RNA的结构信息。传统上，机器学习模型使用专家设计的特征并在数据稀缺的标记数据集上进行训练来解决这个问题。我们发现，基于蛋白质共进化的Transformer深度神经网络学习的知识可以转移到RNA接触预测任务中。由于蛋白质数据集比RNA接触预测的数据集大几个数量级，因此我们的发现和随后的框架极大地减少了数据稀缺的瓶颈。实验证实，使用公开的蛋白质模型进行转移学习的RNA接触预测效果得到了显著提高。我们的发现表明，蛋白质学习的结构模式可以转移到RNA上，为RNA结构预测开辟了潜在的新方向。

    RNA, whose functionality is largely determined by its structure, plays an important role in many biological activities. The prediction of pairwise structural proximity between each nucleotide of an RNA sequence can characterize the structural information of the RNA. Historically, this problem has been tackled by machine learning models using expert-engineered features and trained on scarce labeled datasets. Here, we find that the knowledge learned by a protein-coevolution Transformer-based deep neural network can be transferred to the RNA contact prediction task. As protein datasets are orders of magnitude larger than those for RNA contact prediction, our findings and the subsequent framework greatly reduce the data scarcity bottleneck. Experiments confirm that RNA contact prediction through transfer learning using a publicly available protein model is greatly improved. Our findings indicate that the learned structural patterns of proteins can be transferred to RNAs, opening up potenti
    
[^150]: 双排列等变性在知识图谱补全中的应用

    Double Permutation Equivariance for Knowledge Graph Completion. (arXiv:2302.01313v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01313](http://arxiv.org/abs/2302.01313)

    本研究提出了双排列等变性的KG表示方法，可以使神经网络在KG中执行复杂的逻辑推理任务，并在多个归纳KG完成任务中实现了最先进的Hits@10测试准确率。双排列等变性在KG中开辟了新的研究方向。

    

    本研究将知识图谱(KGs)形式化为一种新型的图，并称之为双交换属性图，其中节点和二元（两个节点之间的）表示必须对节点号和边（及节点）属性（关系和节点特征）的排列等变。双重排列等变的KG表示在KG中开辟了新的研究方向。我们展示了这种等变性对关系的结构表示产生的影响，从而使神经网络能够在KG中执行复杂的逻辑推理任务。最后，我们介绍了一种通用的等变表示蓝图，并测试了一种简单的基于GNN的双排列等变神经结构，在WN18RR、FB237和NELL995归纳KG完成任务中实现了最先进的Hits@10测试准确率，并能够准确执行现有方法无法执行的逻辑推理任务。

    This work provides a formalization of Knowledge Graphs (KGs) as a new class of graphs that we denote doubly exchangeable attributed graphs, where node and pairwise (joint 2-node) representations must be equivariant to permutations of both node ids and edge (& node) attributes (relations & node features). Double-permutation equivariant KG representations open a new research direction in KGs. We show that this equivariance imposes a structural representation of relations that allows neural networks to perform complex logical reasoning tasks in KGs. Finally, we introduce a general blueprint for such equivariant representations and test a simple GNN-based double-permutation equivariant neural architecture that achieve state-of-the-art Hits@10 test accuracy in the WN18RR, FB237 and NELL995 inductive KG completion tasks, and can accurately perform logical reasoning tasks that no existing methods can perform, to the best of our knowledge.
    
[^151]: 针对含有“沉默大多数”的图表进行抗差建模的知识可迁移图神经网络

    Predicting the Silent Majority on Graphs: Knowledge Transferable Graph Neural Network. (arXiv:2302.00873v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.00873](http://arxiv.org/abs/2302.00873)

    本文提出了一种新颖的知识可迁移模块和适应性学习机制，通过将有声节点的知识转移给无声节点，实现了针对含有“沉默大多数”的图表的抗差建模。实验证明，该方法在各种真实世界数据集上都具有有效性和优越性。

    

    在现实世界中，存在由有声节点（“有声少数”）和无声节点（“沉默大多数”）组成的图表，即 VS-Graph，其中有声节点往往具有丰富的特征和标签，而无声节点仅具有不完整的特征和稀缺的标签。 预测沉默大多数仍然是一个至关重要且具有挑战性的问题。 为了解决这个问题，提出了一种称为知识可迁移图神经网络（KT-GNN）的方法，该方法通过将有声节点的知识转移给无声节点来实现消息传递和表征学习过程中的分布漂移建模。 实验结果表明，KT-GNN 在各种真实世界数据集上都具有有效性和优越性。

    Graphs consisting of vocal nodes ("the vocal minority") and silent nodes ("the silent majority"), namely VS-Graph, are ubiquitous in the real world. The vocal nodes tend to have abundant features and labels. In contrast, silent nodes only have incomplete features and rare labels, e.g., the description and political tendency of politicians (vocal) are abundant while not for ordinary people (silent) on the twitter's social network. Predicting the silent majority remains a crucial yet challenging problem. However, most existing message-passing based GNNs assume that all nodes belong to the same domain, without considering the missing features and distribution-shift between domains, leading to poor ability to deal with VS-Graph. To combat the above challenges, we propose Knowledge Transferable Graph Neural Network (KT-GNN), which models distribution shifts during message passing and representation learning by transferring knowledge from vocal nodes to silent nodes. Specifically, we design 
    
[^152]: 基于隐变量谱模型求解高维偏微分方程

    Solving High-Dimensional PDEs with Latent Spectral Models. (arXiv:2301.12664v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12664](http://arxiv.org/abs/2301.12664)

    本文提出一种基于隐变量谱模型的高维PDEs高效精确求解器，它使用基于注意力的分层投影网络将高维数据在线性时间内缩小到一个紧凑的潜空间，并利用谱方法在潜空间中学习算子解决维度诅咒。效果和可扩展性在Navier-Stokes和Schrödinger方程中得到验证。

    

    深度模型在解决偏微分方程（PDEs）方面取得了令人瞩目的进展。一种新兴的范例是学习神经算子来近似PDEs的输入输出映射。虽然以前的深度模型已经探索了多尺度的体系结构和各种算子设计，但它们仅限于在坐标空间中整体学习算子。在实际物理科学问题中，PDEs是具有复杂耦合方程的，数值求解器依赖于高维坐标空间的离散化，这不能被单个算子准确地近似，也不能由于维度诅咒而有效地学习。本文提出了一种基于隐变量谱模型（LSM）的高维PDEs高效精确求解器。LSM不仅超出了坐标空间，而且还利用基于注意力的分层投影网络将高维数据在线性时间内缩小到一个紧凑的潜空间。受数值分析中经典的谱方法的启示，LSM利用谱方法在潜空间中学习算子，可以捕捉复杂的非线性交互并有效地解决维度诅咒。我们在多个高维PDEs上展示了LSM的有效性和可扩展性，如Navier-Stokes方程和Schrödinger方程。

    Deep models have achieved impressive progress in solving partial differential equations (PDEs). A burgeoning paradigm is learning neural operators to approximate the input-output mappings of PDEs. While previous deep models have explored the multiscale architectures and various operator designs, they are limited to learning the operators as a whole in the coordinate space. In real physical science problems, PDEs are complex coupled equations with numerical solvers relying on discretization into high-dimensional coordinate space, which cannot be precisely approximated by a single operator nor efficiently learned due to the curse of dimensionality. We present Latent Spectral Models (LSM) toward an efficient and precise solver for high-dimensional PDEs. Going beyond the coordinate space, LSM enables an attention-based hierarchical projection network to reduce the high-dimensional data into a compact latent space in linear time. Inspired by classical spectral methods in numerical analysis,
    
[^153]: 最佳结合：通过无数据超知识蒸馏实现准确的全局和个性化模型的联邦学习

    The Best of Both Worlds: Accurate Global and Personalized Models through Federated Learning with Data-Free Hyper-Knowledge Distillation. (arXiv:2301.08968v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.08968](http://arxiv.org/abs/2301.08968)

    该论文介绍了一种名为FedHKD的联邦学习算法，利用知识蒸馏实现无数据超知识蒸馏，解决了异构数据导致的全局和个性化模型准确性问题，在多个基准数据集上实验表明优于现有FL方法和中心化训练方式下的模型。

    

    数据的异构性限制了通过联邦学习训练的全局模型的性能，尤其是在具有局部数据高度不平衡的情况下。个性化联邦学习（PFL）作为解决异构数据挑战的潜在解决方案已经出现。但是现有的PFL方法通常以牺牲全局模型准确性为代价来提高本地模型的性能。我们提出了FedHKD（联邦超知识蒸馏），这是一种新颖的FL算法，其中客户端依靠知识蒸馏（KD）来训练本地模型。我们在几个基准数据集上的实验表明，FedHKD可以在全局和个性化准确性方面实现最先进的性能，超越现有的FL方法，甚至超过以集中方式训练的所有数据模型。

    Heterogeneity of data distributed across clients limits the performance of global models trained through federated learning, especially in the settings with highly imbalanced class distributions of local datasets. In recent years, personalized federated learning (pFL) has emerged as a potential solution to the challenges presented by heterogeneous data. However, existing pFL methods typically enhance performance of local models at the expense of the global model's accuracy. We propose FedHKD (Federated Hyper-Knowledge Distillation), a novel FL algorithm in which clients rely on knowledge distillation (KD) to train local models. In particular, each client extracts and sends to the server the means of local data representations and the corresponding soft predictions -- information that we refer to as ``hyper-knowledge". The server aggregates this information and broadcasts it to the clients in support of local training. Notably, unlike other KD-based pFL methods, FedHKD does not rely on 
    
[^154]: 快速适应的概念发现

    Concept Discovery for Fast Adapatation. (arXiv:2301.07850v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.07850](http://arxiv.org/abs/2301.07850)

    本论文提出了一个基于概念发现的模型不可知元学习方法（COMAML），通过元学习数据特征之间的结构，实现更有效的适应。

    

    深度学习的进步使得机器学习方法在各个领域都能超越人类表现，但对于一个已经训练好的模型快速适应到一个新的任务仍然是一个巨大的挑战。为了实现这个目标，元学习（也称为学习如何学习）是一个很有前途的解决方案之一，在few-shot学习方面已经取得了很好的结果。然而，目前的方法在提取可结构化和可转移的知识方面仍与人类学习过程有很大不同。这一缺点使得当前的元学习框架难以解释，也难以扩展到更复杂的任务。我们通过将概念发现引入到few-shot学习问题中来解决这个问题，通过元学习数据特征之间的结构，实现更有效的适应，从而导出数据的复合表示形式。我们提出的基于概念的模型不可知元学习方法（COMAML）已经在各种任务中得到了一致的表现。

    The advances in deep learning have enabled machine learning methods to outperform human beings in various areas, but it remains a great challenge for a well-trained model to quickly adapt to a new task. One promising solution to realize this goal is through meta-learning, also known as learning to learn, which has achieved promising results in few-shot learning. However, current approaches are still enormously different from human beings' learning process, especially in the ability to extract structural and transferable knowledge. This drawback makes current meta-learning frameworks non-interpretable and hard to extend to more complex tasks. We tackle this problem by introducing concept discovery to the few-shot learning problem, where we achieve more effective adaptation by meta-learning the structure among the data features, leading to a composite representation of the data. Our proposed method Concept-Based Model-Agnostic Meta-Learning (COMAML) has been shown to achieve consistent i
    
[^155]: 基于数据驱动的共语手势生成综述

    A Comprehensive Review of Data-Driven Co-Speech Gesture Generation. (arXiv:2301.05339v4 [cs.GR] UPDATED)

    [http://arxiv.org/abs/2301.05339](http://arxiv.org/abs/2301.05339)

    该论文综述了共语手势的生成研究，重点在深度生成模型上。共语手势是自然通信的一部分，对于电影和游戏等领域具有广泛的应用。随着越来越大的手势数据集和深度学习生成模型的进步，该领域有着广阔的研究前景。

    

    伴随语言的手势是自然而有效的人类交流中不可或缺的一部分。自动生成这种共语手势是计算机动画中长期存在的问题，被认为是电影、游戏、虚拟社交空间以及与社交机器人交互的一种使能技术。由于人类共语手势运动的独特性和非周期性，以及手势所包括的交际功能的多样性，使得该问题难以解决。最近，随着越来越多的人类手势数据集的出现，加上基于深度学习的生成模型的进步，手势生成引起了越来越多的关注。

    Gestures that accompany speech are an essential part of natural and efficient embodied human communication. The automatic generation of such co-speech gestures is a long-standing problem in computer animation and is considered an enabling technology in film, games, virtual social spaces, and for interaction with social robots. The problem is made challenging by the idiosyncratic and non-periodic nature of human co-speech gesture motion, and by the great diversity of communicative functions that gestures encompass. Gesture generation has seen surging interest recently, owing to the emergence of more and larger datasets of human gesture motion, combined with strides in deep-learning-based generative models, that benefit from the growing availability of data. This review article summarizes co-speech gesture generation research, with a particular focus on deep generative models. First, we articulate the theory describing human gesticulation and how it complements speech. Next, we briefly d
    
[^156]: Pix2Map: 从图像中推断街道地图的跨模态检索方法

    Pix2Map: Cross-modal Retrieval for Inferring Street Maps from Images. (arXiv:2301.04224v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.04224](http://arxiv.org/abs/2301.04224)

    本论文提出了一种名为Pix2Map的跨模态检索方法，可以从自我视角图像中推断城市街道地图的拓扑结构，并可以用于更新或扩展现有地图。使用Argoverse数据集进行实验，证明了这种方法的可行性。

    

    自动驾驶车辆依赖城市街道地图进行自主导航。本文介绍了Pix2Map，一种从自我视角图像中推断城市街道地图拓扑结构的方法，以不断更新和扩展现有地图。这是一项具有挑战性的任务，因为我们需要直接从原始图像数据推断复杂的城市道路拓扑结构。本文的主要思路是可以通过学习图像和现有地图的联合、跨模态嵌入空间，将这个问题形式化为跨模态检索。我们使用Argoverse数据集进行实验评估，并展示了仅从图像数据中准确检索对应已知和未知道路的街道地图的可行性。此外，我们还展示了我们检索到的地图可以用于更新或扩展现有地图，并展示了视觉定位和图像检索的概念证明结果。

    Self-driving vehicles rely on urban street maps for autonomous navigation. In this paper, we introduce Pix2Map, a method for inferring urban street map topology directly from ego-view images, as needed to continually update and expand existing maps. This is a challenging task, as we need to infer a complex urban road topology directly from raw image data. The main insight of this paper is that this problem can be posed as cross-modal retrieval by learning a joint, cross-modal embedding space for images and existing maps, represented as discrete graphs that encode the topological layout of the visual surroundings. We conduct our experimental evaluation using the Argoverse dataset and show that it is indeed possible to accurately retrieve street maps corresponding to both seen and unseen roads solely from image data. Moreover, we show that our retrieved maps can be used to update or expand existing maps and even show proof-of-concept results for visual localization and image retrieval fr
    
[^157]: 连续因果效应估计：挑战与机会

    Continual Causal Effect Estimation: Challenges and Opportunities. (arXiv:2301.01026v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.01026](http://arxiv.org/abs/2301.01026)

    本文介绍了因果效应估计中的挑战与机会，现有方法主要集中在源特定和静态观测数据上，实际问题在于观测数据只能逐步获得，本文提出了一种连续因果效应估计方法。

    

    在许多领域，如经济学、医疗保健、公共政策、网络挖掘、在线广告和营销活动中，理解观察数据中的因果关系非常关键。尽管在因果效应估计方面已经取得了重大进展，如处理缺失的对照结果和治疗与控制组之间的选择偏差，但现有方法主要集中在源特定和静态观测数据上。这些学习策略假设所有观测数据已经在训练阶段可用且仅来自于一个来源。这种可访问性的实际问题在各种学术和工业应用中普遍存在。在大数据时代，我们面临着利用观测数据进行因果推断的新挑战，即针对逐步可用的观测数据的可扩展性和额外领域适应性问题。

    A further understanding of cause and effect within observational data is critical across many domains, such as economics, health care, public policy, web mining, online advertising, and marketing campaigns. Although significant advances have been made to overcome the challenges in causal effect estimation with observational data, such as missing counterfactual outcomes and selection bias between treatment and control groups, the existing methods mainly focus on source-specific and stationary observational data. Such learning strategies assume that all observational data are already available during the training phase and from only one source. This practical concern of accessibility is ubiquitous in various academic and industrial applications. That's what it boiled down to: in the era of big data, we face new challenges in causal inference with observational data, i.e., the extensibility for incrementally available observational data, the adaptability for extra domain adaptation proble
    
[^158]: 关于注意力网络的可解释性研究

    On the Interpretability of Attention Networks. (arXiv:2212.14776v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.14776](http://arxiv.org/abs/2212.14776)

    本文研究注意力网络的可解释性，提出了选择依赖分类（SDC）变体分类问题，并演示了注意力模型可以准确无误但不具有可解释性的多种错误模式。该研究为评估SDC模型及其解释性提供了一种评估指标，并评估了不同架构的模型的解释性。

    

    注意力机制是多个成功深度学习架构的核心组件，基于一个关键想法：“输出仅取决于输入的一个小（但未知）部分”。在图像字幕和语言翻译等多个实际应用中，这通常是正确的。在具有注意力机制的训练模型中，编码与输出相关的输入段的中间模块的输出通常被用作窥视网络“推理”的一种方式。本文通过使用注意力模型体系结构解决一个变体分类问题，我们称之为选择依赖分类（SDC），从而更加清晰地阐述了这种概念。在这种情况下，我们演示了多种错误模式，其中注意力模型可以准确无误但不具有可解释性，并表明这种模型因训练而出现。我们还阐述了可以加强和减轻此行为的多种情况。最后，我们使用我们的目标定义了一种对于SDC模型及其解释性的评估指标，并评估了不同架构的模型的解释性。

    Attention mechanisms form a core component of several successful deep learning architectures, and are based on one key idea: ''The output depends only on a small (but unknown) segment of the input.'' In several practical applications like image captioning and language translation, this is mostly true. In trained models with an attention mechanism, the outputs of an intermediate module that encodes the segment of input responsible for the output is often used as a way to peek into the `reasoning` of the network. We make such a notion more precise for a variant of the classification problem that we term selective dependence classification (SDC) when used with attention model architectures. Under such a setting, we demonstrate various error modes where an attention model can be accurate but fail to be interpretable, and show that such models do occur as a result of training. We illustrate various situations that can accentuate and mitigate this behaviour. Finally, we use our objective def
    
[^159]: 使用半监督自编码器的在线主动学习进行软测量开发

    Online Active Learning for Soft Sensor Development using Semi-Supervised Autoencoders. (arXiv:2212.13067v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.13067](http://arxiv.org/abs/2212.13067)

    本文介绍了一种使用半监督自编码器以及在线主动学习方法，以尽可能少的标记样本来开发软测量传感器，从而显著降低了成本。在实验中，作者表明这种方法能够取得好的预测效果。

    

    数据驱动的软测量在工业和化学过程中被广泛使用，以预测难以测量的过程变量。这些传感器使用的回归模型通常需要大量标记的样本，然而，由于质量检查需要高昂的时间和成本，获取标签信息可能非常昂贵。在这种情况下，主动学习方法可能非常有益，因为它们可以建议查询最具信息量的标签。然而，为回归提出的大多数主动学习策略都集中在离线场景。本文将其中一些方法适应于流式场景，并展示了如何使用基于正交自编码器的半监督架构学习低维空间中的显著特征。我们也演示了如何使用田纳西东曼过程比较预测结果。

    Data-driven soft sensors are extensively used in industrial and chemical processes to predict hard-to-measure process variables whose real value is difficult to track during routine operations. The regression models used by these sensors often require a large number of labeled examples, yet obtaining the label information can be very expensive given the high time and cost required by quality inspections. In this context, active learning methods can be highly beneficial as they can suggest the most informative labels to query. However, most of the active learning strategies proposed for regression focus on the offline setting. In this work, we adapt some of these approaches to the stream-based scenario and show how they can be used to select the most informative data points. We also demonstrate how to use a semi-supervised architecture based on orthogonal autoencoders to learn salient features in a lower dimensional space. The Tennessee Eastman Process is used to compare the predictive 
    
[^160]: 利用加权图遍历自动机为Transformer建立图形位置编码

    Bridging Graph Position Encodings for Transformers with Weighted Graph-Walking Automata. (arXiv:2212.06898v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.06898](http://arxiv.org/abs/2212.06898)

    本文提出了一种新的图PE，即基于加权图遍历自动机的图自动机PE（GAPE）。与其他PE方案相比，GAPE已证明可以推广到其他PE，并在机器翻译和图形任务中取得了良好的表现。此外，本文还对许多最近在图形Transformer中的PE进行了理论和控制实验比较。

    

    图神经网络领域的一个目标是让Transformer能够处理图结构数据，尽管他们在语言和视觉任务上取得了成功。由于Transformer最初的正弦位置编码（PE）不适用于图形，因此最近的工作集中于开发基于谱图理论或图形各种空间特征的图PE。 本文引入一种新的图PE——基于加权图遍历自动机的图自动机PE（GAPE），并在机器翻译和图形任务中将其与其他PE方案进行比较，并表明它可以推广到其他PE。该研究的另一个贡献是在独立于边缘特征使用的情况下，对许多最近在图形Transformer中的PE进行理论和控制实验比较。

    A current goal in the graph neural network literature is to enable transformers to operate on graph-structured data, given their success on language and vision tasks. Since the transformer's original sinusoidal positional encodings (PEs) are not applicable to graphs, recent work has focused on developing graph PEs, rooted in spectral graph theory or various spatial features of a graph. In this work, we introduce a new graph PE, Graph Automaton PE (GAPE), based on weighted graph-walking automata (a novel extension of graph-walking automata). We compare the performance of GAPE with other PE schemes on both machine translation and graph-structured tasks, and we show that it generalizes several other PEs. An additional contribution of this study is a theoretical and controlled experimental comparison of many recent PEs in graph transformers, independent of the use of edge features.
    
[^161]: MobileTL: 基于Inverted Residual Blocks的设备本地迁移学习

    MobileTL: On-device Transfer Learning with Inverted Residual Blocks. (arXiv:2212.03246v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.03246](http://arxiv.org/abs/2212.03246)

    本文提出了MobileTL，一种基于内部标准化层具有内存和计算效率的移动设备上的迁移学习方法，用于构建IRBs模型。MobileTL通过训练内部规范化层的移位来避免存储向后传递的激活图，显著降低了内存使用率，并在图像识别任务中保持了竞争性的准确性。

    

    设备本地迁移学习面临有限的设备资源的挑战。现有方法通过训练参数的子集或加入模型补丁来解决这个问题。为了更高效的推理，Inverted Residual Blocks（IRBs）将卷积层分为逐层深度和逐点卷积，从而实现更多卷积、标准化和激活层的堆叠。虽然它们对于推理是高效的，但IRBs需要在内存中存储额外的激活映射来训练卷积层的权重和标准化层的规模。因此，它们的高内存成本阻碍了在资源有限的边缘设备上训练IRBs，使其在迁移学习的情况下不适用。为了解决这个问题，我们提出了MobileTL，一种基于内部标准化层的移动设备上的内存和计算效率高的迁移学习方法，用于构建IRBs模型。MobileTL训练内部规范化层的移位，以避免存储向后传递的激活图。在图像识别任务中，MobileTL显著降低了内存使用率，并保持了竞争性的准确性。我们在ImageNet数据集上验证了我们的方法，并展示了一个小规模数据集上成功的迁移学习结果。

    Transfer learning on edge is challenging due to on-device limited resources. Existing work addresses this issue by training a subset of parameters or adding model patches. Developed with inference in mind, Inverted Residual Blocks (IRBs) split a convolutional layer into depthwise and pointwise convolutions, leading to more stacking layers, e.g., convolution, normalization, and activation layers. Though they are efficient for inference, IRBs require that additional activation maps are stored in memory for training weights for convolution layers and scales for normalization layers. As a result, their high memory cost prohibits training IRBs on resource-limited edge devices, and making them unsuitable in the context of transfer learning. To address this issue, we present MobileTL, a memory and computationally efficient on-device transfer learning method for models built with IRBs. MobileTL trains the shifts for internal normalization layers to avoid storing activation maps for the backwar
    
[^162]: 垂直联邦学习：一项结构化文献综述

    Vertical Federated Learning: A Structured Literature Review. (arXiv:2212.00622v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.00622](http://arxiv.org/abs/2212.00622)

    垂直联邦学习是联邦学习中的一种特殊架构，它可在不泄露隐私的情况下，通过组合本地模型训练的结果来建立完整的机器学习模型。本文是对垂直联邦学习现有研究进行了结构化综述，总结了其研究现状、应用、限制和未来方向。

    

    联邦学习（FL）已成为一种具有数据隐私优势的有前途的分布式学习范式。随着对数据所有者之间合作的兴趣增加，FL已引起组织的重视。FL的想法是使合作参与者在不泄露隐私的情况下，在分散的数据上训练机器学习（ML）模型。简单地说，联邦学习是“将模型带到数据，而不是将数据带到模型”的方法。当联邦学习应用于垂直分区的数据时，它能够通过组合使用各地点具有不同特征的本地模型训练的模型来建立完整的ML模型。这种FL的架构被称为垂直联邦学习（VFL），它不同于水平分区的传统FL。由于VFL与传统FL不同，因此它具有自身的问题和挑战。本文对现有研究中关于垂直联邦学习的结构化文献综述，分析了VFL的当前研究现状、应用、限制和未来方向。

    Federated Learning (FL) has emerged as a promising distributed learning paradigm with an added advantage of data privacy. With the growing interest in having collaboration among data owners, FL has gained significant attention of organizations. The idea of FL is to enable collaborating participants train machine learning (ML) models on decentralized data without breaching privacy. In simpler words, federated learning is the approach of ``bringing the model to the data, instead of bringing the data to the mode''. Federated learning, when applied to data which is partitioned vertically across participants, is able to build a complete ML model by combining local models trained only using the data with distinct features at the local sites. This architecture of FL is referred to as vertical federated learning (VFL), which differs from the conventional FL on horizontally partitioned data. As VFL is different from conventional FL, it comes with its own issues and challenges. In this paper, we
    
[^163]: 最优稀疏回归树

    Optimal Sparse Regression Trees. (arXiv:2211.14980v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.14980](http://arxiv.org/abs/2211.14980)

    本研究提出了一种动态规划方法，通过一个新型下界，构建可证明的最优稀疏回归树，并在几秒钟内找到最优的稀疏树。

    

    回归树是最古老的人工智能模型之一，其预测可以在没有计算器的情况下完成，这使得它们在特别是高风险应用中广泛使用。在回归树的大量文献中，对于完全可证明的优化工作很少，这主要是由于问题的计算难度。本文提出了一种带有边界的动态规划方法来构建可证明的最优稀疏回归树。我们利用基于1维k均值聚类算法的最优解的新型下界来进行优化。即使是对于涉及大量样本和高度相关特征的具有挑战性的数据集，我们通常也能在几秒钟内找到最优的稀疏树。

    Regression trees are one of the oldest forms of AI models, and their predictions can be made without a calculator, which makes them broadly useful, particularly for high-stakes applications. Within the large literature on regression trees, there has been little effort towards full provable optimization, mainly due to the computational hardness of the problem. This work proposes a dynamic-programming-with-bounds approach to the construction of provably-optimal sparse regression trees. We leverage a novel lower bound based on an optimal solution to the k-Means clustering algorithm in 1-dimension over the set of labels. We are often able to find optimal sparse trees in seconds, even for challenging datasets that involve large numbers of samples and highly-correlated features.
    
[^164]: 对比学习中的归纳偏差的理论研究

    A Theoretical Study of Inductive Biases in Contrastive Learning. (arXiv:2211.14699v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.14699](http://arxiv.org/abs/2211.14699)

    本文提供了对比学习中的归纳偏差的影响的理论分析，揭示了模型选择对学习过程的影响。

    

    理解自监督学习是重要而具有挑战性的。之前的理论研究对预训练损失的作用进行了研究，将神经网络视为普通的黑盒子。然而，Saunshi等人最近的研究表明，模型结构——之前的研究中很少关注的一个组成部分——对于自监督学习的下游性能也有显著的影响。在本研究中，我们提供了第一个将源于模型类的归纳偏差的影响纳入自监督学习的理论分析。特别地，我们关注对于视觉领域普遍使用的一种流行的自监督学习方法——对比学习。我们展示了当模型具有有限的容量时，对比表示会恢复与模型结构兼容的某些特殊聚类结构，但会忽略数据分布中的许多其他聚类结构。因此，我们的理论可以捕捉对比学习更为复杂的行为，提供了有关模型结构选择如何影响学习过程的见解。

    Understanding self-supervised learning is important but challenging. Previous theoretical works study the role of pretraining losses, and view neural networks as general black boxes. However, the recent work of Saunshi et al. argues that the model architecture -- a component largely ignored by previous works -- also has significant influences on the downstream performance of self-supervised learning. In this work, we provide the first theoretical analysis of self-supervised learning that incorporates the effect of inductive biases originating from the model class. In particular, we focus on contrastive learning -- a popular self-supervised learning method that is widely used in the vision domain. We show that when the model has limited capacity, contrastive representations would recover certain special clustering structures that are compatible with the model architecture, but ignore many other clustering structures in the data distribution. As a result, our theory can capture the more 
    
[^165]: PatchGT：基于非可训练聚类的Transformer用于学习图表示

    PatchGT: Transformer over Non-trainable Clusters for Learning Graph Representations. (arXiv:2211.14425v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.14425](http://arxiv.org/abs/2211.14425)

    PatchGT是一种基于非可训练聚类的Transformer图神经网络，通过将图分割为patch学习图表示，兼具GNN和Transformer的优点，可在多种图学习任务上实现最先进的性能。

    

    最近，Transformer结构在图学习任务中表现出良好的性能。然而，这些Transformer模型直接处理图节点，可能难以学习高层次的信息。受图像patch的启发，我们提出了一种新的基于Transformer的图神经网络：Patch Graph Transformer（PatchGT）。与先前用于学习图表示的基于Transformer的模型不同，PatchGT从非可训练图patch中学习，而不是直接从节点学习。它可以帮助节省计算量并提高模型性能。其关键思想是使用谱聚类将图分割为patch，并使用GNN层首先学习patch级别的表示，然后使用Transformer获取图级别的表示。该架构利用了图的谱信息，结合了GNN和Transformer的优点。进一步，我们展示了先前方法的局限性，并在包括节点分类、链路预测和图分类在内的各种基于图的任务上演示了我们提出的方法的有效性。实验结果表明，PatchGT在几个基准数据集上实现了最先进的性能。

    Recently the Transformer structure has shown good performances in graph learning tasks. However, these Transformer models directly work on graph nodes and may have difficulties learning high-level information. Inspired by the vision transformer, which applies to image patches, we propose a new Transformer-based graph neural network: Patch Graph Transformer (PatchGT). Unlike previous transformer-based models for learning graph representations, PatchGT learns from non-trainable graph patches, not from nodes directly. It can help save computation and improve the model performance. The key idea is to segment a graph into patches based on spectral clustering without any trainable parameters, with which the model can first use GNN layers to learn patch-level representations and then use Transformer to obtain graph-level representations. The architecture leverages the spectral information of graphs and combines the strengths of GNNs and Transformers. Further, we show the limitations of previo
    
[^166]: 带权重集成的自监督学习

    Weighted Ensemble Self-Supervised Learning. (arXiv:2211.09981v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.09981](http://arxiv.org/abs/2211.09981)

    本文提出了一种带权重集成的自监督学习方法，通过开发允许数据相关的加权交叉熵损失的框架，可以提高最近自监督学习技术的性能，而不需要改变原有的架构，其在 ImageNet-1K 数据集上的表现优于最先进的 DINO 和 MSN 方法，特别是在小样本设置中表现最佳。

    

    集成在监督学习中已被证明是提高模型性能、不确定性估计和健壮性的有效技术。自监督学习的进展使得利用大规模未标记语料库进行最先进的小样本和监督学习成为可能。本文研究了如何通过开发一个允许数据相关的加权交叉熵损失的框架来改进最近的自监督学习技术。我们避免对表示骨干进行集成；这个选择产生了一种高效的集成方法，它的训练成本很小，对下游评估不需要进行架构改变或计算开销。我们的方法在 ImageNet-1K 数据集上使用了两种最先进的自监督学习方法 DINO (Caron 等人，2021) 和 MSN (Assran 等人，2022)，在多个评估指标上均优于它们，尤其在小样本设置中表现最佳。我们探讨了几种加权方案，并发现…（未完成）

    Ensembling has proven to be a powerful technique for boosting model performance, uncertainty estimation, and robustness in supervised learning. Advances in self-supervised learning (SSL) enable leveraging large unlabeled corpora for state-of-the-art few-shot and supervised learning performance. In this paper, we explore how ensemble methods can improve recent SSL techniques by developing a framework that permits data-dependent weighted cross-entropy losses. We refrain from ensembling the representation backbone; this choice yields an efficient ensemble method that incurs a small training cost and requires no architectural changes or computational overhead to downstream evaluation. The effectiveness of our method is demonstrated with two state-of-the-art SSL methods, DINO (Caron et al., 2021) and MSN (Assran et al., 2022). Our method outperforms both in multiple evaluation metrics on ImageNet-1K, particularly in the few-shot setting. We explore several weighting schemes and find that th
    
[^167]: 基于交叉通道池化的量子分裂神经网络学习

    Quantum Split Neural Network Learning using Cross-Channel Pooling. (arXiv:2211.06524v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2211.06524](http://arxiv.org/abs/2211.06524)

    本研究提出了一种基于QSL的新方法，并引入交叉通道池化技术，实现了加速收敛、减少通讯成本和增强隐私保护的优点。

    

    近年来，量子科学领域在量子机器学习、量子通信和量子计算等多个学科领域引起了广泛关注。在这些新兴领域中，由于将量子神经网络(QNNs)与传统联邦学习技术(FL)相结合，量子联邦学习(QFL)引起了特别关注。本研究提出了一种称为量子分裂学习(QSL)的新方法，它是经典分裂学习的先进延伸。在传统计算机领域中，分裂学习已经证明了许多优点，例如加速收敛，减少通讯成本和增强隐私保护。为了最大化QSL的潜力，引入了交叉通道池化技术，这种技术利用了QNNs所实现的量子态重构的独特性质。通过严格的数值分析，证明了QSL不仅实现了优异的学习性能，而且在在保护隐私方面也更为高效。

    In recent years, the field of quantum science has attracted significant interest across various disciplines, including quantum machine learning, quantum communication, and quantum computing. Among these emerging areas, quantum federated learning (QFL) has gained particular attention due to the integration of quantum neural networks (QNNs) with traditional federated learning (FL) techniques. In this study, a novel approach entitled quantum split learning (QSL) is presented, which represents an advanced extension of classical split learning. Previous research in classical computing has demonstrated numerous advantages of split learning, such as accelerated convergence, reduced communication costs, and enhanced privacy protection. To maximize the potential of QSL, cross-channel pooling is introduced, a technique that capitalizes on the distinctive properties of quantum state tomography facilitated by QNNs. Through rigorous numerical analysis, evidence is provided that QSL not only achieve
    
[^168]: SUPRA:超像素引导损失用于改进内窥镜多模态分割

    SUPRA: Superpixel Guided Loss for Improved Multi-modal Segmentation in Endoscopy. (arXiv:2211.04658v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.04658](http://arxiv.org/abs/2211.04658)

    本文提出了一种名为SUPRA的超像素增强方法，通过使用SLICLoss与二元交叉熵损失的结合，提高了深度学习模型在内窥镜图像分析中的领域泛化能力。

    

    领域转移是医学影像领域的一个众所周知的问题。特别是对于内窥镜图像分析，其中数据可以具有不同的模态，深度学习（DL）方法的性能受到不利影响。在真实的临床环境中，内镜医生会在模态之间切换以获得更好的黏膜可视化效果。在本文中，我们探索领域概括技术，使DL方法可以在这种情况下使用。因此，我们提出使用Simple Linear Iterative Clustering (SLIC) 产生的超像素，称为 "SUPRA"，用于超像素增强方法。SUPRA首先生成预定分割掩模，利用我们的新损失"SLICLoss"鼓励准确和颜色一致的分割。我们证明了当将SLICLoss与二元交叉熵损失（BCE）相结合时，可以提高模型的概括能力。

    Domain shift is a well-known problem in the medical imaging community. In particular, for endoscopic image analysis where the data can have different modalities the performance of deep learning (DL) methods gets adversely affected. In other words, methods developed on one modality cannot be used for a different modality. However, in real clinical settings, endoscopists switch between modalities for better mucosal visualisation. In this paper, we explore the domain generalisation technique to enable DL methods to be used in such scenarios. To this extend, we propose to use super pixels generated with Simple Linear Iterative Clustering (SLIC) which we refer to as "SUPRA" for SUPeRpixel Augmented method. SUPRA first generates a preliminary segmentation mask making use of our new loss "SLICLoss" that encourages both an accurate and color-consistent segmentation. We demonstrate that SLICLoss when combined with Binary Cross Entropy loss (BCE) can improve the model's generalisability with dat
    
[^169]: 少样本类别增量学习中的原型四元组

    Prototypical quadruplet for few-shot class incremental learning. (arXiv:2211.02947v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.02947](http://arxiv.org/abs/2211.02947)

    本文提出了一种解决灾难性遗忘的少样本类别增量学习方法，通过更新先前会话类原型以表示真正的类平均值，在嵌入空间中保留先前已获得的知识，即使训练新类时也是如此。

    

    在许多现代计算机视觉算法中，数据稀缺和新任务的增量学习构成了两个主要瓶颈。灾难性遗忘现象，即模型在使用新批次数据训练后无法对先前学习的数据进行分类，是一个重大挑战。传统方法解决灾难性遗忘的同时会牺牲当前会话的训练。生成复盘方法，如生成敌对网络（GAN），已被提出以减轻灾难性遗忘，但使用少量样本训练GAN可能导致不稳定性。为解决这些挑战，我们提出了一种新方法，通过使用改进的对比损失来识别更好的嵌入空间，从而提高分类鲁棒性。我们的方法通过更新先前会话类原型以表示真正的类平均值，在嵌入空间中保留先前已获得的知识，即使训练新类时也是如此，这对于我们的最近类别分类器至关重要。

    Scarcity of data and incremental learning of new tasks pose two major bottlenecks for many modern computer vision algorithms. The phenomenon of catastrophic forgetting, i.e., the model's inability to classify previously learned data after training with new batches of data, is a major challenge. Conventional methods address catastrophic forgetting while compromising the current session's training. Generative replay-based approaches, such as generative adversarial networks (GANs), have been proposed to mitigate catastrophic forgetting, but training GANs with few samples may lead to instability. To address these challenges, we propose a novel method that improves classification robustness by identifying a better embedding space using an improved contrasting loss. Our approach retains previously acquired knowledge in the embedding space, even when trained with new classes, by updating previous session class prototypes to represent the true class mean, which is crucial for our nearest class
    
[^170]: GFlowNets与变分贝叶斯的因果结构和机制学习

    Bayesian learning of Causal Structure and Mechanisms with GFlowNets and Variational Bayes. (arXiv:2211.02763v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.02763](http://arxiv.org/abs/2211.02763)

    本文介绍了一种新的方法，使用GFlowNets和变分贝叶斯联合学习因果模型的结构和机制，不仅能够处理非线性和非高斯数据，在模拟数据上也能与几个基线方法相竞争。

    

    贝叶斯因果结构学习旨在学习有向无环图（DAG）上的后验分布和定义父变量和子变量之间关系的机制。本文引入一种新的方法，使用变分贝叶斯联合学习因果模型的结构和机制，称为变分贝叶斯DAG-GFlowNet（VBG）。我们使用GFlowNets扩展了贝叶斯因果结构学习的方法，不仅学习结构的后验分布，还学习线性高斯模型的参数。我们在模拟数据上的结果表明，VBG在建模DAG和机制的后验分布时，不仅能够处理非线性和非高斯数据，而且还能与几个基线方法相竞争。

    Bayesian causal structure learning aims to learn a posterior distribution over directed acyclic graphs (DAGs), and the mechanisms that define the relationship between parent and child variables. By taking a Bayesian approach, it is possible to reason about the uncertainty of the causal model. The notion of modelling the uncertainty over models is particularly crucial for causal structure learning since the model could be unidentifiable when given only a finite amount of observational data. In this paper, we introduce a novel method to jointly learn the structure and mechanisms of the causal model using Variational Bayes, which we call Variational Bayes-DAG-GFlowNet (VBG). We extend the method of Bayesian causal structure learning using GFlowNets to learn not only the posterior distribution over the structure, but also the parameters of a linear-Gaussian model. Our results on simulated data suggest that VBG is competitive against several baselines in modelling the posterior over DAGs an
    
[^171]: 一种基于Transformer的替代品推荐模型，融合了弱监督的顾客行为数据

    A Transformer-Based Substitute Recommendation Model Incorporating Weakly Supervised Customer Behavior Data. (arXiv:2211.02533v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2211.02533](http://arxiv.org/abs/2211.02533)

    本文将替代品推荐适应到语言匹配问题中，并通过设计新的转换方法去除信号噪音，并考虑了多语言支持。该模型已成功在一个大型电子商务网站上的11个市场和6种语言中部署，提高了顾客忠诚度和购买率。

    

    基于替代品的推荐在电子商务中得到广泛应用，以提供更好的替代品给顾客。但是现有研究通常使用顾客的行为信号（如共同浏览和浏览但购买另一个产品）来捕捉替代关系。尽管这个方法听起来很直观，但我们发现这种做法可能会忽略产品的功能和特性。在本文中，我们通过以产品标题描述作为模型输入，并考虑产品功能，将替代品推荐适应到语言匹配问题中。我们设计了一种新的转换方法来去除从生产数据中得出的信号噪声。此外，我们从工程角度考虑多语言支持。我们提出的端到端基于Transformer的模型在离线和在线实验中均取得了成功。所提出的模型已部署在一个大型电子商务网站上的11个市场和6种语言中。我们的模型被证明可以提高顾客忠诚度和购买率。

    The substitute-based recommendation is widely used in E-commerce to provide better alternatives to customers. However, existing research typically uses the customer behavior signals like co-view and view-but-purchase-another to capture the substitute relationship. Despite its intuitive soundness, we find that such an approach might ignore the functionality and characteristics of products. In this paper, we adapt substitute recommendation into language matching problem by taking product title description as model input to consider product functionality. We design a new transformation method to de-noise the signals derived from production data. In addition, we consider multilingual support from the engineering point of view. Our proposed end-to-end transformer-based model achieves both successes from offline and online experiments. The proposed model has been deployed in a large-scale E-commerce website for 11 marketplaces in 6 languages. Our proposed model is demonstrated to increase re
    
[^172]: 破碎的神经缩放定律

    Broken Neural Scaling Laws. (arXiv:2210.14891v7 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.14891](http://arxiv.org/abs/2210.14891)

    本文提出了一个平滑破碎的幂律函数形式，可以准确地模拟和外推深度神经网络的缩放行为，适用于各种架构和大量不同任务，包括视觉、语言、音频、视频、生成建模、对比学习、机器人、不确定性估计/校准、对抗鲁棒性、分子、计算机编程/编码、数学单词问题、算术、无监督/自监督学习和强化学习。

    This paper proposes a smoothly broken power law functional form (referred to as a Broken Neural Scaling Law (BNSL)) that accurately models and extrapolates the scaling behaviors of deep neural networks for various architectures and a large and diverse set of tasks, including vision, language, audio, video, generative modeling, contrastive learning, robotics, uncertainty estimation/calibration, adversarial robustness, molecules, computer programming/coding, math word problems, arithmetic, unsupervised/self-supervised learning, and reinforcement learning.

    我们提出了一个平滑破碎的幂律函数形式（我们称之为破碎的神经缩放定律（BNSL）），它准确地模拟和外推了深度神经网络的缩放行为（即感兴趣的评估指标随用于训练的计算量、模型参数数量、训练数据集大小或上游性能变化而变化）对于各种架构和大量不同任务中的每个任务，包括大规模视觉、语言、音频、视频、扩散、生成建模、多模态学习、对比学习、AI对齐、机器人、超出分布（OOD）泛化、持续学习、不确定性估计/校准、超出分布检测、对抗鲁棒性、蒸馏、分子、计算机编程/编码、数学单词问题、算术、无监督/自监督学习和强化学习。

    We present a smoothly broken power law functional form (referred to by us as a Broken Neural Scaling Law (BNSL)) that accurately models and extrapolates the scaling behaviors of deep neural networks (i.e. how the evaluation metric of interest varies as the amount of compute used for training, number of model parameters, training dataset size, or upstream performance varies) for various architectures and for each of various tasks within a large and diverse set of upstream and downstream tasks, in zero-shot, prompted, and fine-tuned settings. This set includes large-scale vision, language, audio, video, diffusion, generative modeling, multimodal learning, contrastive learning, AI alignment, robotics, out-of-distribution (OOD) generalization, continual learning, uncertainty estimation / calibration, out-of-distribution detection, adversarial robustness, distillation, molecules, computer programming/coding, math word problems, arithmetic, unsupervised/self-supervised learning, and reinforc
    
[^173]: 两层神经网络上SGD的全局收敛性证明

    Global Convergence of SGD On Two Layer Neural Nets. (arXiv:2210.11452v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.11452](http://arxiv.org/abs/2210.11452)

    该论文证明了当深度为2的神经网络采用足够平滑凸的激活函数时，SGD可以收敛到全局最小值，证明过程中引入Frobenius范数正则化与恰当分布的参数初始化，同时拓展了连续时间的收敛结果。

    

    在这篇论文中，我们证明了当深度为2的网络采用足够平滑且有边界的激活函数（比如sigmoid和tanh）时，SGD可以证明性地收敛到适当正则化的$\ell_2-$经验风险的全局最小值--对于任意数据和任意数量的门。我们在[1]的研究成果上进行了扩展，并在权重上添加了恒定量的Frobenius范数正则化，同时选取了恰当的分布对初始权重进行采样。我们还给出了一个连续时间的SGD收敛结果，同样适用于如SoftPlus这样的平滑无边界的激活函数。我们的关键想法是展示了存在于固定大小的神经网络上的损失函数，它们是“Villani函数”[1] Bin Shi, Weijie J. Su, and Michael I. Jordan. On learning rates and schr\"odinger operators, 2020. arXiv:2004.06977

    In this note we demonstrate provable convergence of SGD to the global minima of appropriately regularized $\ell_2-$empirical risk of depth $2$ nets -- for arbitrary data and with any number of gates, if they are using adequately smooth and bounded activations like sigmoid and tanh. We build on the results in [1] and leverage a constant amount of Frobenius norm regularization on the weights, along with sampling of the initial weights from an appropriate distribution. We also give a continuous time SGD convergence result that also applies to smooth unbounded activations like SoftPlus. Our key idea is to show the existence loss functions on constant sized neural nets which are "Villani Functions". [1] Bin Shi, Weijie J. Su, and Michael I. Jordan. On learning rates and schr\"odinger operators, 2020. arXiv:2004.06977
    
[^174]: 从一开始就进行连续伪标记

    Continuous Pseudo-Labeling from the Start. (arXiv:2210.08711v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.08711](http://arxiv.org/abs/2210.08711)

    本文提出了一种从训练开始就进行伪标记的ASR方法，通过动态控制伪标签生成来减少标记数据集上的过拟合。

    

    自我训练或伪标记由于其在利用未标记数据方面的成功而引起了自动语音识别（ASR）社区的极大关注。本文提出了一种在ASR中通过动态控制伪标签生成来实现从训练开始就进行伪标记的方法，以减少标记数据集上的过拟合。

    Self-training (ST), or pseudo-labeling has sparked significant interest in the automatic speech recognition (ASR) community recently because of its success in harnessing unlabeled data. Unlike prior semi-supervised learning approaches that relied on iteratively regenerating pseudo-labels (PLs) from a trained model and using them to train a new model, recent state-of-the-art methods perform `continuous training' where PLs are generated using a very recent version of the model being trained. Nevertheless, these approaches still rely on bootstrapping the ST using an initial supervised learning phase where the model is trained on labeled data alone. We believe this has the potential for over-fitting to the labeled dataset in low resource settings and that ST from the start of training should reduce over-fitting. In this paper we show how we can do this by dynamically controlling the evolution of PLs during the training process in ASR. To the best of our knowledge, this is the first study t
    
[^175]: 平等改善: 考虑长期影响的新公平性概念

    Equal Improvability: A New Fairness Notion Considering the Long-term Impact. (arXiv:2210.06732v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.06732](http://arxiv.org/abs/2210.06732)

    在动态环境下，设计一个长期公平的分类器很重要。我们提出了一个新的公平性概念EI，它确保在拒绝的样本付出一定的努力进行特征改进后，不同群体的样本特征分布得到平衡，这比现有的公平性概念实现long-term fairness更好。

    

    在机器学习中，设计一个公平的分类器以避免歧视不同群体是一个重要的问题。尽管研究人员已经提出了各种定义群体公平的方法，但大多数方法只关注了立即公平性，忽略了具有动态场景的公平分类器的长期影响，其中每个个体都可以随着时间的推移改善其特征。在这种动态设置中，长期公平应该在拒绝的样本花费一定的努力以改进后，平衡不同群体样本的特征分布。为了提高长期公平性，我们提出了一种新的公平性概念，称为Equal Improvability (EI)，其等化不同群体被拒绝样本在假定所有样本都将花费有限的努力来改进特征的情况下的潜在接受率。我们证明EI与现有的基于统计平等公平概念相兼容，并提出了一种训练分类器以实现EI的方法。在基准数据集上的实验表明，在长期公平方面，训练在EI下的分类器明显优于基线公平分类器。

    Devising a fair classifier that does not discriminate against different groups is an important problem in machine learning. Although researchers have proposed various ways of defining group fairness, most of them only focused on the immediate fairness, ignoring the long-term impact of a fair classifier under the dynamic scenario where each individual can improve its feature over time. Such dynamic scenarios happen in real world, e.g., college admission and credit loaning, where each rejected sample makes effort to change its features to get accepted afterwards. In this dynamic setting, the long-term fairness should equalize the samples' feature distribution across different groups after the rejected samples make some effort to improve. In order to promote long-term fairness, we propose a new fairness notion called Equal Improvability (EI), which equalizes the potential acceptance rate of the rejected samples across different groups assuming a bounded level of effort will be spent by ea
    
[^176]: 基于相关信息最大化的神经网络进行相关源分离

    Correlative Information Maximization Based Biologically Plausible Neural Networks for Correlated Source Separation. (arXiv:2210.04222v2 [eess.SP] UPDATED)

    [http://arxiv.org/abs/2210.04222](http://arxiv.org/abs/2210.04222)

    该论文提出了一种基于生物学原理的神经网络，通过利用有关潜在源领域的信息来提取相关联的潜在源，从而极大地改善了对相关源分离的性能。

    

    大脑可以轻松地提取刺激的潜在原因，但它如何在网络层面上做到这一点仍然未知。先前解决这个问题的大多数尝试都提出了实现独立成分分析的神经网络，但这种方法的限制在于潜在原因是相互独立的。在此我们不再遵循此限制，提出一种基于生物学的神经网络，通过利用有关其领域的信息来提取相关的潜在源。我们选取从输入到输出的最大相关信息传输作为分离目标，并约束输出量限制在其预定集合内，以导出此网络。在线形式化此优化问题自然地导致具有本地学习规则的神经网络。我们的框架包括无限多种源域选择，并可以灵活地对复杂的潜在结构进行建模。选择单纯形或多面体源域的结果是具有分段线性激活函数的网络，从而极大地改善了对相关源分离的性能。

    The brain effortlessly extracts latent causes of stimuli, but how it does this at the network level remains unknown. Most prior attempts at this problem proposed neural networks that implement independent component analysis which works under the limitation that latent causes are mutually independent. Here, we relax this limitation and propose a biologically plausible neural network that extracts correlated latent sources by exploiting information about their domains. To derive this network, we choose maximum correlative information transfer from inputs to outputs as the separation objective under the constraint that the outputs are restricted to their presumed sets. The online formulation of this optimization problem naturally leads to neural networks with local learning rules. Our framework incorporates infinitely many source domain choices and flexibly models complex latent structures. Choices of simplex or polytopic source domains result in networks with piecewise-linear activation 
    
[^177]: 弱监督下的标签传播算法

    Label Propagation with Weak Supervision. (arXiv:2210.03594v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.03594](http://arxiv.org/abs/2210.03594)

    本文提出了一种利用弱监督信息的标签传播算法，通过利用未标记数据上的概率假设标签，结合局部几何特性和先验信息的质量，提供了一个误差界，并提出了一个框架，用于合并多个噪声信息源。在多个基准弱监督分类任务上展示了方法的能力，显示出对现有半监督和弱监督方法的改进。

    This paper proposes a label propagation algorithm that utilizes weak supervision information, specifically probabilistic hypothesized labels on the unlabeled data, and provides an error bound that exploits both the local geometric properties of the underlying graph and the quality of the prior information. The approach is demonstrated on multiple benchmark weakly supervised classification tasks, showing improvements upon existing semi-supervised and weakly supervised methods.

    半监督学习和弱监督学习是当前机器学习应用中旨在减少标记数据需求的重要范式。本文介绍了一种新的对经典标签传播算法（LPA）（Zhu＆Ghahramani，2002）的分析，该算法利用了有用的先验信息，特别是未标记数据上的概率假设标签。我们提供了一个误差界，利用了底层图形的局部几何特性和先验信息的质量。我们还提出了一个框架，用于合并多个噪声信息源。特别是，我们考虑了弱监督的设置，其中我们的信息来源是弱标记者。我们在多个基准弱监督分类任务上展示了我们方法的能力，显示出对现有半监督和弱监督方法的改进。

    Semi-supervised learning and weakly supervised learning are important paradigms that aim to reduce the growing demand for labeled data in current machine learning applications. In this paper, we introduce a novel analysis of the classical label propagation algorithm (LPA) (Zhu & Ghahramani, 2002) that moreover takes advantage of useful prior information, specifically probabilistic hypothesized labels on the unlabeled data. We provide an error bound that exploits both the local geometric properties of the underlying graph and the quality of the prior information. We also propose a framework to incorporate multiple sources of noisy information. In particular, we consider the setting of weak supervision, where our sources of information are weak labelers. We demonstrate the ability of our approach on multiple benchmark weakly supervised classification tasks, showing improvements upon existing semi-supervised and weakly supervised methods.
    
[^178]: 基于特征符合预测的预测推断

    Predictive Inference with Feature Conformal Prediction. (arXiv:2210.00173v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.00173](http://arxiv.org/abs/2210.00173)

    本文提出基于特征符合预测的预测推断方法，通过利用深度表示学习的归纳偏置，扩展了符合预测到语义特征空间。从理论和实验结果来看，该方法优于常规符合预测，并在大规模任务上展现了最先进性能。

    

    符合预测是一种无分布技术，用于建立有效的预测间隔。虽然传统上人们在输出空间中进行符合预测，但这并不是唯一的可能性。在本文中，我们提出了基于特征的符合预测，通过利用深度表示学习的归纳偏置，扩展了符合预测对语义特征空间的范围。从理论上讲，我们证明了基于特征的符合预测在温和假设下可以证明优于常规符合预测。我们的方法不仅可以与普通符合预测结合使用，而且可以与其他自适应符合预测方法结合使用。除了现有预测推断基准测试的实验外，我们还展示了该方法在大规模任务（如ImageNet分类和Cityscapes图像分割）上的最先进性能。

    Conformal prediction is a distribution-free technique for establishing valid prediction intervals. Although conventionally people conduct conformal prediction in the output space, this is not the only possibility. In this paper, we propose feature conformal prediction, which extends the scope of conformal prediction to semantic feature spaces by leveraging the inductive bias of deep representation learning. From a theoretical perspective, we demonstrate that feature conformal prediction provably outperforms regular conformal prediction under mild assumptions. Our approach could be combined with not only vanilla conformal prediction, but also other adaptive conformal prediction methods. Apart from experiments on existing predictive inference benchmarks, we also demonstrate the state-of-the-art performance of the proposed methods on large-scale tasks such as ImageNet classification and Cityscapes image segmentation.
    
[^179]: MLPInit: 使用MLP初始化非常简单的GNN训练加速

    MLPInit: Embarrassingly Simple GNN Training Acceleration with MLP Initialization. (arXiv:2210.00102v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.00102](http://arxiv.org/abs/2210.00102)

    提出一种简单但有效的GNN加速训练方法 - MLPInit, 通过训练一个等效MLP（PeerMLP）, 并使用它的权重来初始化目标GNN，在不损失精度的情况下，显著提高了GNN的收敛效果和预测性能。

    

    在大型图上训练图神经网络（GNN）非常复杂且极其耗时，这是由于稀疏矩阵乘法引起的开销。当仅使用节点特征来训练多层感知器（MLP）时，可以避免这些开销。MLP通过忽略图上下文信息，对于图形数据而言更加简单和快速，但通常会牺牲预测精度，限制了它们在图形数据中的应用。我们观察到，对于大多数基于消息传递的GNN，我们可以轻松地推导出一个等效的模拟MLP（我们将其称为PeerMLP）并设置可训练的参数具有相同的形状，这使我们好奇“使用从完全训练的PeerMLP导出的权重的GNN的表现如何？”令人惊讶的是，我们发现使用这些权重初始化的GNN明显优于它们的PeerMLP，这促使我们使用PeerMLP训练作为GNN训练的前导初始化步骤。为此，我们提出了一种非常简单但非常有效的MLP初始化方法，称为MLPInit。 MLPInit包括在与目标GNN相同数据上训练PeerMLP，然后使用其权重初始化目标GNN。从经验上看，我们证明了MLPInit有效地将有用信息从PeerMLP传输到目标GNN，显着提高了GNN的收敛效果和预测性能，同时保持了MLP的简单和速度优势。

    Training graph neural networks (GNNs) on large graphs is complex and extremely time consuming. This is attributed to overheads caused by sparse matrix multiplication, which are sidestepped when training multi-layer perceptrons (MLPs) with only node features. MLPs, by ignoring graph context, are simple and faster for graph data, however they usually sacrifice prediction accuracy, limiting their applications for graph data. We observe that for most message passing-based GNNs, we can trivially derive an analog MLP (we call this a PeerMLP) with an equivalent weight space, by setting the trainable parameters with the same shapes, making us curious about \textbf{\emph{how do GNNs using weights from a fully trained PeerMLP perform?}} Surprisingly, we find that GNNs initialized with such weights significantly outperform their PeerMLPs, motivating us to use PeerMLP training as a precursor, initialization step to GNN training. To this end, we propose an embarrassingly simple, yet hugely effectiv
    
[^180]: 基于平滑插值的深度双重下降

    Deep Double Descent via Smooth Interpolation. (arXiv:2209.10080v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.10080](http://arxiv.org/abs/2209.10080)

    本文研究神经网络在插值训练数据时的损失景观，发现其损失锐度遵循非光滑的二次曲线，当神经网络的复杂度逐渐增加时，测试误差会先降后升（即“双下降”现象）。

    

    近期研究表明，超参数化深度网络具有插值噪声数据和表现良好的泛化性能的能力，这种现象通过测试误差的双重下降曲线得到了表征。然而，对于深度网络插值和泛化之间的精确关系还没有得到明确的定量描述。本文通过研究神经网络函数插值训练数据时与每个训练点周围的输入变量相关联的损失景观，定量衡量训练数据的拟合锐度。我们发现，输入空间中的损失锐度遵循一个非光滑的二次曲线，这与传统的多项式回归的分析结论有一定差异。此外，我们还发现当神经网络的复杂度逐渐增加时，测试误差会先降后升（即“双下降”现象），这与之前研究的结论有所不同。

    The ability of overparameterized deep networks to interpolate noisy data, while at the same time showing good generalization performance, has been recently characterized in terms of the double descent curve for the test error. Common intuition from polynomial regression suggests that overparameterized networks are able to sharply interpolate noisy data, without considerably deviating from the ground-truth signal, thus preserving generalization ability. At present, a precise characterization of the relationship between interpolation and generalization for deep networks is missing. In this work, we quantify sharpness of fit of the training data interpolated by neural network functions, by studying the loss landscape w.r.t. to the input variable locally to each training point, over volumes around cleanly- and noisily-labelled training samples, as we systematically increase the number of model parameters and training epochs. Our findings show that loss sharpness in the input space follows 
    
[^181]: TSFool: 通过多目标黑盒攻击方法生成高度难以察觉的对循环神经网络分类器的对抗性时间序列

    TSFool: Crafting Highly-imperceptible Adversarial Time Series through Multi-objective Black-box Attack to Fool RNN Classifiers. (arXiv:2209.06388v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.06388](http://arxiv.org/abs/2209.06388)

    本文提出了一种名为TSFool的黑盒方法, 可以有效地生成针对RNN分类器的高度难以察觉的对抗性时间序列，在考虑对抗样本难以察觉性的情况下，将对抗性攻击改进为多目标优化问题来增强扰动的质量。

    

    神经网络分类器很容易受到对抗性攻击。现有的梯度攻击方法在前馈神经网络和图像识别任务中取得了最先进的性能，但它们在循环神经网络模型下的时间序列分类中表现不佳。这是因为RNN的循环结构阻止了直接的模型差分，而时间序列数据对扰动的视觉敏感性挑战了对抗性攻击的传统局部优化目标。本文提出了一种名为TSFool的黑盒方法，用于有效地生成针对RNN分类器的高度难以察觉的对抗性时间序列。我们提出了一种新的全局优化目标，称为Camouflage Coefficient，从类分布的角度考虑对抗样本的难以察觉性，并相应地将对抗性攻击改进为多目标优化问题，以增强扰动的质量。为了摆脱不同模型间的转移性，设计了一个特定于模型的回避规则。在人造数据和实际数据集上的实验结果表明，TSFool可以生成高难度攻击同时保持对抗样本的不易被检测性，并有很高的转移性。

    Neural network (NN) classifiers are vulnerable to adversarial attacks. Although the existing gradient-based attacks achieve state-of-the-art performance in feed-forward NNs and image recognition tasks, they do not perform as well on time series classification with recurrent neural network (RNN) models. This is because the cyclical structure of RNN prevents direct model differentiation and the visual sensitivity of time series data to perturbations challenges the traditional local optimization objective of the adversarial attack. In this paper, a black-box method called TSFool is proposed to efficiently craft highly-imperceptible adversarial time series for RNN classifiers. We propose a novel global optimization objective named Camouflage Coefficient to consider the imperceptibility of adversarial samples from the perspective of class distribution, and accordingly refine the adversarial attack as a multi-objective optimization problem to enhance the perturbation quality. To get rid of t
    
[^182]: 有限数据下的深度生成模型与非可转移预训练模型正则化

    Deep Generative Modeling on Limited Data with Regularization by Nontransferable Pre-trained Models. (arXiv:2208.14133v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.14133](http://arxiv.org/abs/2208.14133)

    本文提出了一种正则化深度生成模型（Reg-DGM），通过利用非可转移预训练模型来降低有限数据的生成建模方差，在极限情况下确保全局最小点的存在和唯一性。

    

    在有限数据上学习复杂模型很容易出现大方差和过拟合问题，因此深度生成模型需要大量数据才能实现较好的性能。针对这个问题，本文提出了一种正则化深度生成模型（Reg-DGM），通过利用非可转移预训练模型来降低有限数据的生成建模方差。Reg-DGM 优化一定的差异和能量函数期望的加权和（能量函数是通过预训练模型定义的）。我们通过高斯拟合来分析加权超参数如何权衡偏差和方差。理论上，我们在非参数设置下表征了 Reg-DGM 的全局最小值的存在性和唯一性，并证明了其与梯度基的神经网络的收敛性。

    Deep generative models (DGMs) are data-eager because learning a complex model on limited data suffers from a large variance and easily overfits. Inspired by the classical perspective of the bias-variance tradeoff, we propose regularized deep generative model (Reg-DGM), which leverages a nontransferable pre-trained model to reduce the variance of generative modeling with limited data. Formally, Reg-DGM optimizes a weighted sum of a certain divergence and the expectation of an energy function, where the divergence is between the data and the model distributions, and the energy function is defined by the pre-trained model w.r.t. the model distribution. We analyze a simple yet representative Gaussian-fitting case to demonstrate how the weighting hyperparameter trades off the bias and the variance. Theoretically, we characterize the existence and the uniqueness of the global minimum of Reg-DGM in a non-parametric setting and prove its convergence with neural networks trained by gradient-bas
    
[^183]: 语义增强的图像聚类

    Semantic-Enhanced Image Clustering. (arXiv:2208.09849v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2208.09849](http://arxiv.org/abs/2208.09849)

    本文提出了一种命名为“语义增强的图像聚类(SIC)”的新型图像聚类方法，基于视觉-语言预训练模型CLIP指导，能够区分视觉上相似但在语义上有所不同的图像。

    

    图像聚类是计算机视觉中一个重要且具有挑战性的任务。本文提出了一种基于图像文字预训练模型的方法来解决图像聚类任务，该方法能够区分视觉上相似但在语义上有所不同的图像。在这种情况下，我们只知道聚类的数量，因此如何将图像映射到适当的语义空间，以及如何从图像和语义空间聚类图像是两个关键问题。为了解决上述问题，我们提出了一种由视觉 - 语言预训练模型CLIP指导的新型图像聚类方法，命名为“语义增强的图像聚类(SIC)”。在这种新方法中，我们首先提出了一种将给定的图像映射到适当的语义空间的方法。

    Image clustering is an important and open-challenging task in computer vision. Although many methods have been proposed to solve the image clustering task, they only explore images and uncover clusters according to the image features, thus being unable to distinguish visually similar but semantically different images. In this paper, we propose to investigate the task of image clustering with the help of a visual-language pre-training model. Different from the zero-shot setting, in which the class names are known, we only know the number of clusters in this setting. Therefore, how to map images to a proper semantic space and how to cluster images from both image and semantic spaces are two key problems. To solve the above problems, we propose a novel image clustering method guided by the visual-language pre-training model CLIP, named \textbf{Semantic-Enhanced Image Clustering (SIC)}. In this new method, we propose a method to map the given images to a proper semantic space first and eff
    
[^184]: 一种基于深度特征的病理图像可变形配准的混合方法

    A Hybrid Deep Feature-Based Deformable Image Registration Method for Pathology Images. (arXiv:2208.07655v4 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2208.07655](http://arxiv.org/abs/2208.07655)

    本文提出了一种混合的基于深度特征的病理图像可变形配准框架，使用探测器和无探测器的深度学习特征网络提取密集的特征点，并通过孤立森林统计模型和局部仿射校正模型结合的离群值检测方法进一步减少错误匹配。在ANHIR挑战数据集上，本文所提出的方法比传统方法提高了17％以上的A度量值。

    

    病理学家需要结合来自不同染色的病理切片的信息进行准确的诊断。可变形图像配准是融合多模态病理切片的必要技术。本文提出了一种混合的基于深度特征的可变形图像配准框架，用于染色病理样本。我们首先通过基于探测器和无探测器的深度学习特征网络提取密集特征点，并进行点匹配。然后，为了进一步减少错误匹配，提出一种离群值检测方法，将孤立森林统计模型和局部仿射校正模型相结合。最后，插值方法基于上述匹配点生成病理图像注册的可变形向量场。我们在与IEEE ISBI 2019会议联合组织的Non-rigid Histology Image Registration（ANHIR）挑战数据集上评估了我们的方法。我们的技术比传统方法提高了17％以上的A度量值。

    Pathologists need to combine information from differently stained pathology slices for accurate diagnosis. Deformable image registration is a necessary technique for fusing multi-modal pathology slices. This paper proposes a hybrid deep feature-based deformable image registration framework for stained pathology samples. We first extract dense feature points via the detector-based and detector-free deep learning feature networks and perform points matching. Then, to further reduce false matches, an outlier detection method combining the isolation forest statistical model and the local affine correction model is proposed. Finally, the interpolation method generates the deformable vector field for pathology image registration based on the above matching points. We evaluate our method on the dataset of the Non-rigid Histology Image Registration (ANHIR) challenge, which is co-organized with the IEEE ISBI 2019 conference. Our technique outperforms the traditional approaches by 17% with the A
    
[^185]: 基于可微分WORLD合成器的神经声码器及其在端到端音频风格转换中的应用

    Differentiable WORLD Synthesizer-based Neural Vocoder With Application To End-To-End Audio Style Transfer. (arXiv:2208.07282v4 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2208.07282](http://arxiv.org/abs/2208.07282)

    比较不同方法在音频风格转换中的应用，提出一种可微分的WORLD合成器，并通过声学特征参数来实现音高和音色信息的分离。

    

    本文提出了一种可微分的WORLD合成器，并展示了其在端到端音频风格转换任务（如（唱）声音转换和DDSP音色转换任务）中的应用。我们的基线可微分合成器没有模型参数，但它产生了足够的合成质量。我们可以通过附加轻量级的黑箱后网络来扩展基线合成器，以进一步处理基线输出，从而提高保真度。另一种可微分方法是直接提取源激发谱，这可以改善自然度，但仅适用于较窄的风格转换应用类别。我们方法使用的声学特征参数化具有附加的好处，它自然地将音高和音色信息分离开来，以便它们可以分别建模。此外，由于有一种强大的方法可以从单声道音频源估计这些声学特征，它允许风格转换任务中的参数损失。

    In this paper, we propose a differentiable WORLD synthesizer and demonstrate its use in end-to-end audio style transfer tasks such as (singing) voice conversion and the DDSP timbre transfer task. Accordingly, our baseline differentiable synthesizer has no model parameters, yet it yields adequate synthesis quality. We can extend the baseline synthesizer by appending lightweight black-box postnets which apply further processing to the baseline output in order to improve fidelity. An alternative differentiable approach considers extraction of the source excitation spectrum directly, which can improve naturalness albeit for a narrower class of style transfer applications. The acoustic feature parameterization used by our approaches has the added benefit that it naturally disentangles pitch and timbral information so that they can be modeled separately. Moreover, as there exists a robust means of estimating these acoustic features from monophonic audio sources, it allows for parameter loss 
    
[^186]: 循环策略蒸馏：带有域随机化的高效率的仿真到真实强化学习

    Cyclic Policy Distillation: Sample-Efficient Sim-to-Real Reinforcement Learning with Domain Randomization. (arXiv:2207.14561v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2207.14561](http://arxiv.org/abs/2207.14561)

    本文提出了一种称为CPD的高效的仿真到真实强化学习方法，通过将随机参数范围分为几个小的子域，并为每个子域分配一个本地策略，加快了学习速度并提高了样本效率。

    

    本论文提出了一种名为循环策略蒸馏（CPD）的高效率仿真到真实强化学习方法。CPD将随机参数范围分为几个小的子域并为每个子域分配一个本地策略。然后，在循环过渡到子域时学习本地策略。CPD通过基于预期性能提高的知识传递加速学习。最后，所有学习到的本地策略都被提炼为一个用于仿真到真实转移的全局策略。通过在OpenAI Gym中进行Pendulum、Reacher、HalfCheetah和Ant四个任务的仿真实验以及将其转移到真实世界机器人中，证明了CPD的有效性和高样本效率。

    Deep reinforcement learning with domain randomization learns a control policy in various simulations with randomized physical and sensor model parameters to become transferable to the real world in a zero-shot setting. However, a huge number of samples are often required to learn an effective policy when the range of randomized parameters is extensive due to the instability of policy updates. To alleviate this problem, we propose a sample-efficient method named cyclic policy distillation (CPD). CPD divides the range of randomized parameters into several small sub-domains and assigns a local policy to each one. Then local policies are learned while cyclically transitioning to sub-domains. CPD accelerates learning through knowledge transfer based on expected performance improvements. Finally, all of the learned local policies are distilled into a global policy for sim-to-real transfers. CPD's effectiveness and sample efficiency are demonstrated through simulations with four tasks (Pendul
    
[^187]: 神经地面计划：基于单张图片的持久神经场景表示

    Neural Groundplans: Persistent Neural Scene Representations from a Single Image. (arXiv:2207.11232v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2207.11232](http://arxiv.org/abs/2207.11232)

    本文提出了一种基于单张图像的持久神经场景表示方法，使用条件神经地面计划来表示场景，能够进行视角合成、场景解耦表示和可移动组件的分离，重构可移动物体能够进行多种下游任务。

    

    本文提出一种方法，将场景的2D图像观测映射到持久的3D场景表示中，实现了新颖的视角合成和场景可移动和不可移动组件的解耦表示。受视觉和机器人常用的鸟瞰图（BEV）表示的启发，我们提出了条件神经地面计划，即地面对齐的2D特征网格，作为持久且占用内存少的场景表示。我们的方法采用无标签的多视角观测的自我监督训练，使用可微分渲染学习完成遮挡区域的几何和外观。此外，我们展示可以利用多视角视频在训练时来学习分别从单张图像中重构场景的静态和可移动组件。分别重构可移动物体的能力，使用简单的启发式方法，使其可以进行诸多下游任务，如提取以物体为中心的3D表示、新颖的视角合成和物体操作等。

    We present a method to map 2D image observations of a scene to a persistent 3D scene representation, enabling novel view synthesis and disentangled representation of the movable and immovable components of the scene. Motivated by the bird's-eye-view (BEV) representation commonly used in vision and robotics, we propose conditional neural groundplans, ground-aligned 2D feature grids, as persistent and memory-efficient scene representations. Our method is trained self-supervised from unlabeled multi-view observations using differentiable rendering, and learns to complete geometry and appearance of occluded regions. In addition, we show that we can leverage multi-view videos at training time to learn to separately reconstruct static and movable components of the scene from a single image at test time. The ability to separately reconstruct movable objects enables a variety of downstream tasks using simple heuristics, such as extraction of object-centric 3D representations, novel view synthe
    
[^188]: 用分布隐私机制保护数据集的全局属性

    Protecting Global Properties of Datasets with Distribution Privacy Mechanisms. (arXiv:2207.08367v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2207.08367](http://arxiv.org/abs/2207.08367)

    本文探讨了数据集的全局属性机密性保护问题，并应用分布隐私框架成功降低了实际属性推断攻击的效果，同时提供了高效用权衡。

    

    本文考虑保护数据集的全局属性的机密性。这些属性可以编码敏感信息，如商业机密或人口统计数据，而涉及到与文献中通常讨论的个体记录隐私不同的数据保护概念。在这项工作中，我们展示了如何应用分布隐私框架来形式化这种数据机密性。我们将 Pufferfish 隐私的 Wasserstein 机制和属性隐私的高斯机制扩展到这个框架中，然后分析它们的基本数据假设以及如何放宽这些假设。我们接着通过实验证明了这些机制的隐私效用权衡，并将它们应用于针对数据集全局属性的实际属性推断攻击。结果表明，我们的机制确实可以降低攻击的效果，同时提供比粗糙的基于分布隐私机制要高得多的效用。

    We consider the problem of ensuring confidentiality of dataset properties aggregated over many records of a dataset. Such properties can encode sensitive information, such as trade secrets or demographic data, while involving a notion of data protection different to the privacy of individual records typically discussed in the literature. In this work, we demonstrate how a distribution privacy framework can be applied to formalize such data confidentiality. We extend the Wasserstein Mechanism from Pufferfish privacy and the Gaussian Mechanism from attribute privacy to this framework, then analyze their underlying data assumptions and how they can be relaxed. We then empirically evaluate the privacy-utility tradeoffs of these mechanisms and apply them against a practical property inference attack which targets global properties of datasets. The results show that our mechanisms can indeed reduce the effectiveness of the attack while providing utility substantially greater than a crude gro
    
[^189]: 通过增强内容和风格来利用OOD例子

    Harnessing Out-Of-Distribution Examples via Augmenting Content and Style. (arXiv:2207.03162v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.03162](http://arxiv.org/abs/2207.03162)

    本文提出一种HOOD方法，可以通过增强内容和风格来识别良性和恶性OOD数据，并在各种基准数据集上优于现有的各种方法。

    

    机器学习模型容易受到OOD例子的影响，这已经引起了很多关注。然而，现有的方法缺乏对不同类型OOD数据完整的理解：有一些良性的OOD数据可以适当地进行改进以增强学习性能，但其他恶劣的OOD数据则会严重降低分类结果。为了利用OOD数据，本文提出了一种HOOD方法，该方法可以利用每个图像实例的内容和风格来识别良性和恶性OOD数据。具体而言，我们设计了一个变分推断框架，通过构建结构因果模型来因果地分离内容和样式特征。随后，我们通过干预过程增强内容和风格，分别产生恶性和良性OOD数据。良性OOD数据包含新的风格，但保留了我们感兴趣的内容，可以帮助训练一个具有样式不变性的模型。相反，恶性OOD数据具有不受欢迎的内容，并可以用于训练一个更加稳健的抵御OOD例子的模型。实验结果证明了我们提出的方法的有效性，在各种基准数据集上优于现有的各种方法。

    Machine learning models are vulnerable to Out-Of-Distribution (OOD) examples, and such a problem has drawn much attention. However, current methods lack a full understanding of different types of OOD data: there are benign OOD data that can be properly adapted to enhance the learning performance, while other malign OOD data would severely degenerate the classification result. To Harness OOD data, this paper proposes a HOOD method that can leverage the content and style from each image instance to identify benign and malign OOD data. Particularly, we design a variational inference framework to causally disentangle content and style features by constructing a structural causal model. Subsequently, we augment the content and style through an intervention process to produce malign and benign OOD data, respectively. The benign OOD data contain novel styles but hold our interested contents, and they can be leveraged to help train a style-invariant model. In contrast, the malign OOD data inhe
    
[^190]: 贪心坐标下降实现高维私有经验风险最小化

    High-Dimensional Private Empirical Risk Minimization by Greedy Coordinate Descent. (arXiv:2207.01560v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.01560](http://arxiv.org/abs/2207.01560)

    本文针对高维数据中的差分隐私经验风险最小化问题，提出了一种差分隐私贪心坐标下降算法，能够通过利用模型的结构性质，在广泛的问题范围内实现对维度的对数依赖性。

    

    在本文中，我们研究了差分隐私经验风险最小化（DP-ERM）。研究表明，随着维度的增加，DP-ERM的最坏情况效用会多项式降低。这是私有学习大型机器学习模型的主要障碍。在高维中，一些模型参数携带的信息比其他参数更多是很常见的。为了利用这一点，我们提出了一种差分隐私贪心坐标下降（DP-GCD）算法。在每个迭代步骤中，DP-GCD沿着梯度(大致地)最大的条目进行坐标梯度步骤。我们理论上证明，DP-GCD可以通过自然地利用其结构性质（例如拟稀疏解）在广泛的问题范围内实现对维度的对数依赖性。我们通过计算合成和真实数据集来说明这种行为。

    In this paper, we study differentially private empirical risk minimization (DP-ERM). It has been shown that the worst-case utility of DP-ERM reduces polynomially as the dimension increases. This is a major obstacle to privately learning large machine learning models. In high dimension, it is common for some model's parameters to carry more information than others. To exploit this, we propose a differentially private greedy coordinate descent (DP-GCD) algorithm. At each iteration, DP-GCD privately performs a coordinate-wise gradient step along the gradients' (approximately) greatest entry. We show theoretically that DP-GCD can achieve a logarithmic dependence on the dimension for a wide range of problems by naturally exploiting their structural properties (such as quasi-sparse solutions). We illustrate this behavior numerically, both on synthetic and real datasets.
    
[^191]: 基于自适应谱聚类的图重构提高同质性

    Restructuring Graph for Higher Homophily via Adaptive Spectral Clustering. (arXiv:2206.02386v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.02386](http://arxiv.org/abs/2206.02386)

    本文提出一种新颖的图重构方法，集成于任何类型的图神经网络中，以增加同质性。方法包括自适应谱聚类、密度感知同质性度量方法和基于聚类结果的邻接矩阵重构。

    

    尽管越来越多的文献研究了适用于同质性和异质性图的新型图神经网络，但在将传统图神经网络适应于 less-homophilic 图方面做得很少。虽然传统图神经网络处理 less-homophilic 图的能力受到限制，但仍具有效率高、简单、可解释性好等多个优点。本文提出了一种新颖的图重构方法，可集成到任何类型的图神经网络中，包括传统图神经网络，以发挥现有图神经网络的优点同时减轻其局限性。我们的贡献有三个方面: a) 学习拟合节点标签的自适应谱聚类的 pseudo-eigenvector 权重，b) 提出一种新的密度感知的同质性度量方法，具有良好的标签不平衡性鲁棒性，c) 基于自适应谱聚类的结果重构邻接矩阵，以最大化同质性分数。

    While a growing body of literature has been studying new Graph Neural Networks (GNNs) that work on both homophilic and heterophilic graphs, little has been done on adapting classical GNNs to less-homophilic graphs. Although the ability to handle less-homophilic graphs is restricted, classical GNNs still stand out in several nice properties such as efficiency, simplicity, and explainability. In this work, we propose a novel graph restructuring method that can be integrated into any type of GNNs, including classical GNNs, to leverage the benefits of existing GNNs while alleviating their limitations. Our contribution is threefold: a) learning the weight of pseudo-eigenvectors for an adaptive spectral clustering that aligns well with known node labels, b) proposing a new density-aware homophilic metric that is robust to label imbalance, and c) reconstructing the adjacency matrix based on the result of adaptive spectral clustering to maximize the homophilic scores. The experimental results 
    
[^192]: 社会偏见遇到数据偏见: 标注和测量误差对公平标准的影响

    Social Bias Meets Data Bias: The Impacts of Labeling and Measurement Errors on Fairness Criteria. (arXiv:2206.00137v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.00137](http://arxiv.org/abs/2206.00137)

    本文研究了机器学习算法在训练数据集存在偏见时现有公平标准的鲁棒性，探究了标记和测量误差对其影响。研究发现，一些约束可以在面对某些统计偏差时保持稳健，而另一些则会在训练偏见数据集时被显著违反。

    

    尽管已经提出了许多公平标准来确保机器学习算法不会表现出或放大我们现有的社会偏见，但这些算法是在本身可能存在统计偏差的数据集上训练的。在本文中，我们研究了在算法训练在偏见数据集上时一些现有(人口)公平标准的鲁棒性。我们考虑了两种形式的数据集偏差：标记过程中的先前决策制定者的错误和对劣势个体特征的测量误差。我们在理论上证明了一些约束(例如人口均等性)在面对某些统计偏差时可以保持稳健，而另一些(例如平等机会)则会在训练偏见数据集时被显著违反。我们还分析了这些标准和决策制定者效用对偏见的敏感性。我们基于三个真实数据集(FICO、成人和德国信用评分数据集)提供了数值实验，支持我们的结论。

    Although many fairness criteria have been proposed to ensure that machine learning algorithms do not exhibit or amplify our existing social biases, these algorithms are trained on datasets that can themselves be statistically biased. In this paper, we investigate the robustness of a number of existing (demographic) fairness criteria when the algorithm is trained on biased data. We consider two forms of dataset bias: errors by prior decision makers in the labeling process, and errors in measurement of the features of disadvantaged individuals. We analytically show that some constraints (such as Demographic Parity) can remain robust when facing certain statistical biases, while others (such as Equalized Odds) are significantly violated if trained on biased data. We also analyze the sensitivity of these criteria and the decision maker's utility to biases. We provide numerical experiments based on three real-world datasets (the FICO, Adult, and German credit score datasets) supporting our 
    
[^193]: AVIDA: 可视化和整合数据的交替方法

    AVIDA: Alternating method for Visualizing and Integrating Data. (arXiv:2206.00135v2 [q-bio.QM] UPDATED)

    [http://arxiv.org/abs/2206.00135](http://arxiv.org/abs/2206.00135)

    AVIDA是一个可视化和整合数据的框架，它可以同时执行数据对齐和降维，并成功地对齐了高维多模态数据集，保留了每个数据集的结构，特别是联合低维可视化中的不同局部结构。

    

    高维多模态数据在许多科学领域中出现。当不同数据集之间的样本和特征之间没有已知的对应关系时，多模态数据的整合变得具有挑战性。为了解决这个问题，我们介绍了AVIDA，这是一个同时执行数据对齐和降维的框架。在数值实验中，我们使用Gromov-Wasserstein最优运输和t分布随机邻居嵌入作为对齐和降维模块。我们展示了AVIDA正确地对齐了具有四个合成数据集和两个真实多模态单细胞数据集的高维数据集。与几种现有方法相比，我们证明了AVIDA更好地保留了每个数据集的结构，特别是联合低维可视化中的不同局部结构，同时实现了相当的对齐性能。这种特性在多模态单细胞研究中非常重要。

    High-dimensional multimodal data arises in many scientific fields. The integration of multimodal data becomes challenging when there is no known correspondence between the samples and the features of different datasets. To tackle this challenge, we introduce AVIDA, a framework for simultaneously performing data alignment and dimension reduction. In the numerical experiments, Gromov-Wasserstein optimal transport and t-distributed stochastic neighbor embedding are used as the alignment and dimension reduction modules respectively. We show that AVIDA correctly aligns high-dimensional datasets without common features with four synthesized datasets and two real multimodal single-cell datasets. Compared to several existing methods, we demonstrate that AVIDA better preserves structures of individual datasets, especially distinct local structures in the joint low-dimensional visualization, while achieving comparable alignment performance. Such a property is important in multimodal single-cell 
    
[^194]: 背景数据规模对深度学习模型 SHAP 解释稳定性的影响的实证研究

    An empirical study of the effect of background data size on the stability of SHapley Additive exPlanations (SHAP) for deep learning models. (arXiv:2204.11351v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2204.11351](http://arxiv.org/abs/2204.11351)

    本研究发现 SHapley Additive exPlanations (SHAP) 对于机器学习模型的解释受到背景数据集规模的影响，而选择合适的背景数据集能够确保 SHAP 解释的稳定性。

    

    如今，机器学习模型的推断结果准确性同样重要的是其可解释性。某些机器学习模型如决策树拥有天然的可解释性，而其他模型如人工神经网络则需要外部方法揭示其推断机制。SHapley Additive exPlanations (SHAP)就是一种外部解释方式，它需要一个背景数据集对人工神经网络进行解释。通常，背景数据集由从训练数据集中随机抽样的实例组成。然而，背景数据集的抽样规模及其对 SHAP 的影响仍未被探讨。在我们对 MIMIC-III 数据集进行的实证研究中，我们发现使用不同的随机抽样得到的背景数据集会导致核心解释—— SHAP 值和变量排序值的波动，这表明用户不能轻信 SHAP 提供的一次性解释结果。幸运的是，这样的波动并不意味着 SHAP 失败，而是表明选择合适的背景数据集对于确保 SHAP 解释的稳定性至关重要。

    Nowadays, the interpretation of why a machine learning (ML) model makes certain inferences is as crucial as the accuracy of such inferences. Some ML models like the decision tree possess inherent interpretability that can be directly comprehended by humans. Others like artificial neural networks (ANN), however, rely on external methods to uncover the deduction mechanism. SHapley Additive exPlanations (SHAP) is one of such external methods, which requires a background dataset when interpreting ANNs. Generally, a background dataset consists of instances randomly sampled from the training dataset. However, the sampling size and its effect on SHAP remain to be unexplored. In our empirical study on the MIMIC-III dataset, we show that the two core explanations - SHAP values and variable rankings fluctuate when using different background datasets acquired from random sampling, indicating that users cannot unquestioningly trust the one-shot interpretation from SHAP. Luckily, such fluctuation d
    
[^195]: FAIR4Cov：用于 COVID-19 检测的融合音频实例和表示

    FAIR4Cov: Fused Audio Instance and Representation for COVID-19 Detection. (arXiv:2204.10581v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2204.10581](http://arxiv.org/abs/2204.10581)

    FAIR4Cov是一种针对COVID-19检测的方法，它提出了一种融合身体声音的波形和谱图表示的关节特征向量，可以有效地检测COVID-19患者，胜过了其他方法。

    

    基于身体声音的分类技术长期以来一直被研究用于支持诊断决策，特别是在肺部疾病方面。针对 COVID-19 疫情的紧迫性，越来越多的模型被开发来基于声学输入识别 COVID-19 患者。大多数模型侧重于咳嗽，因为干咳是 COVID-19 最为人所知的症状。然而，呼吸和言语等其他身体声音也被发现与 COVID-19 相关。在这项工作中，我们提出了 FAIR4Cov，它不依赖于特定的身体声音，而是提出了一种融合身体声音的波形和谱图表示的关节特征向量。FAIR4Cov 的核心组件是一个自注意融合单元，它的训练目的是建立多个身体声音和音频表示的关系并将其集成到一个紧凑的特征向量中。我们在两个公共数据集上设置了实验，并在不同场景下评估了我们的提议方法，包括跨数据集评估和早期检测设置。实验结果表明，FAIR4Cov 胜过了现有方法，并展示了利用各种身体声音检测 COVID-19 患者的能力。

    Audio-based classification techniques on body sounds have long been studied to support diagnostic decisions, particularly in pulmonary diseases. In response to the urgency of the COVID-19 pandemic, a growing number of models are developed to identify COVID-19 patients based on acoustic input. Most models focus on cough because the dry cough is the best-known symptom of COVID-19. However, other body sounds, such as breath and speech, have also been revealed to correlate with COVID-19 as well. In this work, rather than relying on a specific body sound, we propose Fused Audio Instance and Representation for COVID-19 Detection (FAIR4Cov). It relies on constructing a joint feature vector obtained from a plurality of body sounds in waveform and spectrogram representation. The core component of FAIR4Cov is a self-attention fusion unit that is trained to establish the relation of multiple body sounds and audio representations and integrate it into a compact feature vector. We set up our experi
    
[^196]: InCoder：一种代码填充和合成的生成模型

    InCoder: A Generative Model for Code Infilling and Synthesis. (arXiv:2204.05999v3 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2204.05999](http://arxiv.org/abs/2204.05999)

    InCoder是一种统一的生成模型，可以进行程序合成和双向上下文的代码填充，是第一个能够直接进行零样本代码填充的生成模型。

    

    代码往往不是一次从左到右的写作过程，而是反复编辑和改进的过程。我们引入了InCoder，一种统一的生成模型，可以通过从左到右的生成进行程序合成，也可以进行编辑（通过填充）。InCoder通过从一个大型开源代码库中随机屏蔽代码块并将其移动到每个文件末尾的方式进行训练，使其可以进行双向上下文的代码填充。我们的模型是第一个能够直接进行零样本代码填充的生成模型，我们在类型推断、注释生成和变量重命名等具有挑战性的任务上进行了评估。我们发现，在具有双向上下文的条件下，能够显著改善执行这些任务的性能，而在标准程序合成基准测试中，与相似规模的仅从左到右预先训练的模型相比，性能相当。InCoder模型和代码已经公开发布。

    Code is seldom written in a single left-to-right pass and is instead repeatedly edited and refined. We introduce InCoder, a unified generative model that can perform program synthesis (via left-to-right generation) as well as editing (via infilling). InCoder is trained to generate code files from a large corpus of permissively licensed code, where regions of code have been randomly masked and moved to the end of each file, allowing code infilling with bidirectional context. Our model is the first generative model that is able to directly perform zero-shot code infilling, which we evaluate on challenging tasks such as type inference, comment generation, and variable re-naming. We find that the ability to condition on bidirectional context substantially improves performance on these tasks, while still performing comparably on standard program synthesis benchmarks in comparison to left-to-right only models pretrained at similar scale. The InCoder models and code are publicly released. htt
    
[^197]: 结构感知的蛋白自监督学习

    Structure-aware Protein Self-supervised Learning. (arXiv:2204.04213v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2204.04213](http://arxiv.org/abs/2204.04213)

    我们提出了一种结构感知的蛋白自监督学习方法，利用预训练的图神经网络模型保留重要的蛋白质结构信息，并结合预训练语言模型来提高下游任务性能。在两个蛋白质分类测试中均表现出了优异的结果。

    

    蛋白质表示学习方法在许多下游任务，尤其是蛋白质分类任务中，展现出巨大的潜力。最近的一些研究还利用自监督学习方法解决了蛋白质标签数量不足的问题。然而，现有的蛋白质语言模型通常在蛋白质序列上进行预训练，而忽略了重要的蛋白质结构信息。因此，我们提出了一种新颖的结构感知的蛋白自监督学习方法，来有效地捕获蛋白质的结构信息。具体而言，我们设计了一个优秀的图神经网络（GNN）模型，通过对残基间距和二面角的自监督任务进行预训练，来保留蛋白质的结构信息。此外，我们还提出了利用已有的在蛋白质序列上预训练的语言模型，来增强自监督学习的方法。我们提出的框架 GP-SSL，通过联合训练基于GNN的结构模型和基于语言模型的序列模型，并通过fine-tuning将从GNN模型学到的有用的结构感知表示转移到下游任务中。我们在两个蛋白质分类基准测试上的实验表明，GP-SSL在下游任务性能和结构信息保留方面均优于现有方法和预训练语言模型BERT。我们的代码可在https://github.com/microsoft/GP-SSL上找到。

    Protein representation learning methods have shown great potential to yield useful representation for many downstream tasks, especially on protein classification. Moreover, a few recent studies have shown great promise in addressing insufficient labels of proteins with self-supervised learning methods. However, existing protein language models are usually pretrained on protein sequences without considering the important protein structural information. To this end, we propose a novel structure-aware protein self-supervised learning method to effectively capture structural information of proteins. In particular, a well-designed graph neural network (GNN) model is pretrained to preserve the protein structural information with self-supervised tasks from a pairwise residue distance perspective and a dihedral angle perspective, respectively. Furthermore, we propose to leverage the available protein language model pretrained on protein sequences to enhance the self-supervised learning. Specif
    
[^198]: 面向深度学习计算效率提升的随机锐度感知训练方法研究

    Randomized Sharpness-Aware Training for Boosting Computational Efficiency in Deep Learning. (arXiv:2203.09962v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.09962](http://arxiv.org/abs/2203.09962)

    本文提出了一种名为随机锐度感知训练（RST）的深度学习训练方法，通过在SGD和SAM之间随机选择来减少计算量，同时保证模型收敛。同时，我们对各种调度函数的效果和计算成本进行了实验研究。

    

    通过使模型收敛于平坦的极小值，SAM等锐度感知的学习算法已显示出实现最先进性能的能力。然而，这些算法通常会在每次训练迭代中多进行一次前向-反向传播，从而大大增加了计算量，特别是在可扩展模型中。为此，我们提出了一种名为随机锐度感知训练(RST)的简单而高效的训练方案。RST中的优化器每次迭代都会进行伯努利实验，以由预定义的调度函数安排的概率随机选择基本算法（SGD）和锐度感知算法（SAM）之一。由于基本算法的混合，传播对的总数可以大大减少。此外，我们还对RST的收敛性进行了理论分析。然后，我们通过实验研究了各种调度函数的计算成本和效果，并提供了设置适当调度函数的方向。

    By driving models to converge to flat minima, sharpness-aware learning algorithms (such as SAM) have shown the power to achieve state-of-the-art performances. However, these algorithms will generally incur one extra forward-backward propagation at each training iteration, which largely burdens the computation especially for scalable models. To this end, we propose a simple yet efficient training scheme, called Randomized Sharpness-Aware Training (RST). Optimizers in RST would perform a Bernoulli trial at each iteration to choose randomly from base algorithms (SGD) and sharpness-aware algorithms (SAM) with a probability arranged by a predefined scheduling function. Due to the mixture of base algorithms, the overall count of propagation pairs could be largely reduced. Also, we give theoretical analysis on the convergence of RST. Then, we empirically study the computation cost and effect of various types of scheduling functions, and give directions on setting appropriate scheduling functi
    
[^199]: ZippyPoint: 基于混合精度离散化的快速兴趣点检测、描述和匹配

    ZippyPoint: Fast Interest Point Detection, Description, and Matching through Mixed Precision Discretization. (arXiv:2203.03610v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2203.03610](http://arxiv.org/abs/2203.03610)

    本文提出了一种基于混合精度离散化的高效量化网络和二进制描述符——ZippyPoint，可实现在计算受限的平台上快速的兴趣点检测、描述和匹配，同时在几个标准基准测试中取得了最先进的性能表现。

    

    在视觉系统的定位和建图中，对图像中几何区域的高效检测和描述是先决条件。这些系统仍然依赖于传统的手工制作方法来生成轻量级描述符，而更强大的神经网络模型具有高计算和特定硬件要求。本文重点研究了检测和描述神经网络所需的自适应措施，以使它们可以在计算受限的平台上使用，如机器人、移动设备和增强现实设备。为此，我们研究和适应了网络量化技术来加速推理并使其在计算受限的平台上使用。此外，我们重新审视了描述符量化的常见做法，并提出了使用二进制描述符归一化层的方法，使得生成具有一定数量“1”的独特二进制描述符。ZippyPoint是我们的高效量化网络和二进制描述符，实现了在几个标准基准测试中的最先进性能，同时显示出与竞争方法相比数倍的更快推理时间。

    Efficient detection and description of geometric regions in images is a prerequisite in visual systems for localization and mapping. Such systems still rely on traditional hand-crafted methods for efficient generation of lightweight descriptors, a common limitation of the more powerful neural network models that come with high compute and specific hardware requirements. In this paper, we focus on the adaptations required by detection and description neural networks to enable their use in computationally limited platforms such as robots, mobile, and augmented reality devices. To that end, we investigate and adapt network quantization techniques to accelerate inference and enable its use on compute limited platforms. In addition, we revisit common practices in descriptor quantization and propose the use of a binary descriptor normalization layer, enabling the generation of distinctive binary descriptors with a constant number of ones. ZippyPoint, our efficient quantized network with bina
    
[^200]: P值的校准及子总体与全总体偏差的校准

    Calibration of P-values for calibration and for deviation of a subpopulation from the full population. (arXiv:2202.00100v7 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2202.00100](http://arxiv.org/abs/2202.00100)

    本文介绍了如何校准P值以及如何通过条件分析控制协变量或分数来评估子总体与全总体之间的响应差异。

    

    本文回顾并综合了多年的研究，阐述了如何校准P值，以及如何通过条件分析控制协变量或分数来评估子总体与全总体之间的响应差异。本文提出了计算经过校准的P值的计算方法，同时不需要对正式的显著性检验进行广泛的校准。

    The author's recent research papers, "Cumulative deviation of a subpopulation from the full population" and "A graphical method of cumulative differences between two subpopulations" (both published in volume 8 of Springer's open-access "Journal of Big Data" during 2021), propose graphical methods and summary statistics, without extensively calibrating formal significance tests. The summary metrics and methods can measure the calibration of probabilistic predictions and can assess differences in responses between a subpopulation and the full population while controlling for a covariate or score via conditioning on it. These recently published papers construct significance tests based on the scalar summary statistics, but only sketch how to calibrate the attained significance levels (also known as "P-values") for the tests. The present article reviews and synthesizes work spanning many decades in order to detail how to calibrate the P-values. The present paper presents computationally ef
    
[^201]: 多尺度自适应图神经网络用于多元时间序列预测

    Multi-Scale Adaptive Graph Neural Network for Multivariate Time Series Forecasting. (arXiv:2201.04828v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2201.04828](http://arxiv.org/abs/2201.04828)

    本文提出了一个新的多尺度自适应图神经网络 (MAGNN) 模型，旨在解决传统多元时间序列预测方法中只能学习单一依赖关系的问题，通过多尺度金字塔网络和自适应图学习模块，使模型能够在不同的时间尺度下推导出尺度特定的交互变量依赖性，同时，利用注意机制有效捕获最具信息的预测模式，实验结果表明，MAGNN 对于合成数据集和现实数据集的预测效果优于现有最优方法。

    

    多元时间序列(MTS)预测在智能应用的自动化和优化中扮演着重要角色，但其需要考虑到复杂的 intra-variable 和 inter-variable 的依赖关系，是一个具有挑战性的任务。现有的方法仅通过单一的 inter-variable 的依赖关系来学习时间模式。然而，在许多实际的MTS数据中，存在多尺度的时间模式。单个交互变量依赖关系使得模型更倾向于学习一种突出和共享的时间模式。本文提出了一种多尺度自适应图神经网络(MAGNN)来解决上述问题。MAGNN利用多尺度金字塔网络来保留不同时间尺度下的基本时间依赖性。由于在不同的时间尺度下，交互变量依赖关系可能不同，因此设计了一种自适应图学习模块来推导尺度特定的交互变量依赖性，而不需要预定义先验知识。鉴于多尺度表示，MAGNN进一步利用注意机制有效地捕获最具信息的预测模式。实验结果表明，与现有最优方法相比，本文提出的MAGNN模型在合成数据集和现实数据集上的预测效果更好。

    Multivariate time series (MTS) forecasting plays an important role in the automation and optimization of intelligent applications. It is a challenging task, as we need to consider both complex intra-variable dependencies and inter-variable dependencies. Existing works only learn temporal patterns with the help of single inter-variable dependencies. However, there are multi-scale temporal patterns in many real-world MTS. Single inter-variable dependencies make the model prefer to learn one type of prominent and shared temporal patterns. In this paper, we propose a multi-scale adaptive graph neural network (MAGNN) to address the above issue. MAGNN exploits a multi-scale pyramid network to preserve the underlying temporal dependencies at different time scales. Since the inter-variable dependencies may be different under distinct time scales, an adaptive graph learning module is designed to infer the scale-specific inter-variable dependencies without pre-defined priors. Given the multi-sca
    
[^202]: 限制条件下稀有数据情况下的过程设计参数多目标优化：一种用于粘接的应用

    Constrained multi-objective optimization of process design parameters in settings with scarce data: an application to adhesive bonding. (arXiv:2112.08760v3 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2112.08760](http://arxiv.org/abs/2112.08760)

    本文提出了一种用于稀缺数据情况下的粘接过程设计参数多目标优化方法。通过自适应采样策略和基于代理的约束处理技术，该方法在不显式评估约束条件的情况下，在探索参数空间和平衡开发之间找到高质量的解决方案。

    

    粘接是工业中越来越常用的一种技术，因其高强度重量比、设计灵活性、应力集中有限、平面力传递、良好的耐损性和疲劳抗性等优点而备受青睐。寻找粘接工艺的最佳参数是一项具有挑战性的任务：优化本质上是多目标的（旨在最大化断裂强度并最小化成本），受限制的（工艺不应导致任何材料视觉损伤，应力测试不应导致黏附相关的故障）和不确定的（多次测试同一工艺参数可能导致不同的断裂强度）。实验室中的真实物理实验很昂贵。传统的进化方法（例如遗传算法）则不适合解决这个问题，因为评估所需的实验数量是巨大的。虽然贝叶斯优化可以帮助减少所需的实验数量，但在稀有数据情况下使用仍然具有挑战性。在本文中，我们提出了一种针对粘接的限制条件下稀有数据情况下的多目标优化方法。我们的方法使用自适应采样策略在探索和开发之间平衡探索参数空间。我们还提出了一种基于代理的约束处理技术，以在不显式评估约束条件的情况下将其包含在决策过程中。该方法在真实的工业案例研究中进行了评估，并证明在减少所需实验的同时可以有效地找到高质量的解决方案。

    Adhesive joints are increasingly used in industry for a wide variety of applications because of their favorable characteristics such as high strength-to-weight ratio, design flexibility, limited stress concentrations, planar force transfer, good damage tolerance, and fatigue resistance. Finding the optimal process parameters for an adhesive bonding process is challenging: the optimization is inherently multi-objective (aiming to maximize break strength while minimizing cost), constrained (the process should not result in any visual damage to the materials, and stress tests should not result in failures that are adhesion-related), and uncertain (testing the same process parameters several times may lead to different break strengths). Real-life physical experiments in the lab are expensive to perform. Traditional evolutionary approaches (such as genetic algorithms) are then ill-suited to solve the problem, due to the prohibitive amount of experiments required for evaluation. Although Bay
    
[^203]: 学习树状三维物体的几何和拓扑的生成模型

    Learning Generative Models of the Geometry and Topology of Tree-like 3D Objects. (arXiv:2110.08693v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.08693](http://arxiv.org/abs/2110.08693)

    本文提出了一种扩展平方根速度函数的新表示方法和度量方法，用于分析和比较树状三维物体，从而提高物体形状差异计算的精度和效率。

    

    如何分析展现出复杂几何和拓扑变化的详细三维生物物体，例如神经元和植物树？本文提出了一个新的数学框架，用于表示、比较和计算这些树状三维对象的形状差异，并定义了一种新的度量方法来量化将一个树状物体变形为另一个物体所需的弯曲、拉伸和分支滑动。

    How can one analyze detailed 3D biological objects, such as neurons and botanical trees, that exhibit complex geometrical and topological variation? In this paper, we develop a novel mathematical framework for representing, comparing, and computing geodesic deformations between the shapes of such tree-like 3D objects. A hierarchical organization of subtrees characterizes these objects -- each subtree has the main branch with some side branches attached -- and one needs to match these structures across objects for meaningful comparisons. We propose a novel representation that extends the Square-Root Velocity Function (SRVF), initially developed for Euclidean curves, to tree-shaped 3D objects. We then define a new metric that quantifies the bending, stretching, and branch sliding needed to deform one tree-shaped object into the other. Compared to the current metrics, such as the Quotient Euclidean Distance (QED) and the Tree Edit Distance (TED), the proposed representation and metric cap
    
[^204]: 使用查询来检测随机子图

    Random Subgraph Detection Using Queries. (arXiv:2110.00744v4 [cs.DS] UPDATED)

    [http://arxiv.org/abs/2110.00744](http://arxiv.org/abs/2110.00744)

    本文研究了使用自适应查询来检测种植子图存在，确定了必要和充分的查询数量。

    

    种植的最密子图检测问题是指测试在给定的（随机）图中是否存在一个异常密集的子图。在本文中，我们考虑了一种自然的变体，即只能使用自适应边查询来观察图的一小部分。在这个模型下，我们确定了检测种植子图存在所需的查询数量。具体地，我们展示了任何（可能是随机化的）算法必须进行 $\mathsf{Q} = \Omega(\frac{n^2}{k^2\chi^4(p||q)}\log^2n)$ 个查询。

    The planted densest subgraph detection problem refers to the task of testing whether in a given (random) graph there is a subgraph that is unusually dense. Specifically, we observe an undirected and unweighted graph on $n$ nodes. Under the null hypothesis, the graph is a realization of an Erd\H{o}s-R\'{e}nyi graph with edge probability (or, density) $q$. Under the alternative, there is a subgraph on $k$ vertices with edge probability $p>q$. The statistical as well as the computational barriers of this problem are well-understood for a wide range of the edge parameters $p$ and $q$. In this paper, we consider a natural variant of the above problem, where one can only observe a small part of the graph using adaptive edge queries.  For this model, we determine the number of queries necessary and sufficient for detecting the presence of the planted subgraph. Specifically, we show that any (possibly randomized) algorithm must make $\mathsf{Q} = \Omega(\frac{n^2}{k^2\chi^4(p||q)}\log^2n)$ ada
    
[^205]: 基于家族谱的种群训练进行超参数优化

    Genealogical Population-Based Training for Hyperparameter Optimization. (arXiv:2109.14925v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2109.14925](http://arxiv.org/abs/2109.14925)

    基于家族谱的种群训练（GPBT）是一种新的超参数优化方法。不同于其他算法，GPBT利用相关模型之间的共享历史以高效地利用HP和模型之间的耦合。我们的方法通过降低计算成本，提高精度并减小结果的差异，取得了成功。

    

    超参数优化（HPO）旨在以最快、最高效的方式寻找学习模型（如神经网络）的最佳超参数（HP）。大多数最新的HPO算法尝试优化HP而不考虑获得HP的模型，假定对于不同的模型，相同的HP将产生非常相似的结果。我们打破了这种范式，并提出了一种新的方式，称为基因家谱种群训练（GPBT），通过“谱系”相关模型的共享历史，以高效的方式利用HP和模型之间的耦合。我们实验证明，与当前算法相比，我们的方法将计算成本降低了2到3倍，通常允许计算机视觉任务的1%精度提高，并将结果的差异降低了一个数量级。我们的方法搜索算法无关，因此内部搜索程序可以是任何搜索算法，如TPE。

    HyperParameter Optimization (HPO) aims at finding the best HyperParameters (HPs) of learning models, such as neural networks, in the fastest and most efficient way possible. Most recent HPO algorithms try to optimize HPs regardless of the model that obtained them, assuming that for different models, same HPs will produce very similar results. We break free from this paradigm and propose a new take on preexisting methods that we called Genealogical Population Based Training (GPBT). GPBT, via the shared histories of "genealogically"-related models, exploit the coupling of HPs and models in an efficient way. We experimentally demonstrate that our method cuts down by 2 to 3 times the computational cost required, generally allows a 1% accuracy improvement on computer vision tasks, and reduces the variance of the results by an order of magnitude, compared to the current algorithms. Our method is search-algorithm agnostic so that the inner search routine can be any search algorithm like TPE, 
    
[^206]: 在边流上计算图描述符

    Computing Graph Descriptors on Edge Streams. (arXiv:2109.01494v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2109.01494](http://arxiv.org/abs/2109.01494)

    本文提出了在边流上近似计算图描述符的流式算法，能够捕捉图的基本结构，并避免整个图存储于内存中。该算法具有可扩展性，可控制的运行时间和较高的分类准确性。

    

    特征提取是图分析中重要的任务。这些称为图描述符的特征向量在下游基于向量空间的图分析模型中得到应用。已有的基于谱的图描述符算法提供了最先进的分类准确性，但是已知的计算有意义的描述符的算法不能适用于大型图，因为它们需要将整个图存储于内存中，并且终端用户无法控制算法的运行时间。本文提出了流式算法来近似计算捕捉图的基本结构的三种不同的图描述符。在边流上操作使我们避免将整个图存储于内存中，并且控制采样大小使我们能够将算法的运行时间保持在所需范围内。我们通过分析逼近误差和分类准确性来证明所提出的描述符的有效性。我们的可扩展算法...

    Feature extraction is an essential task in graph analytics. These feature vectors, called graph descriptors, are used in downstream vector-space-based graph analysis models. This idea has proved fruitful in the past, with spectral-based graph descriptors providing state-of-the-art classification accuracy. However, known algorithms to compute meaningful descriptors do not scale to large graphs since: (1) they require storing the entire graph in memory, and (2) the end-user has no control over the algorithm's runtime. In this paper, we present streaming algorithms to approximately compute three different graph descriptors capturing the essential structure of graphs. Operating on edge streams allows us to avoid storing the entire graph in memory, and controlling the sample size enables us to keep the runtime of our algorithms within desired bounds. We demonstrate the efficacy of the proposed descriptors by analyzing the approximation error and classification accuracy. Our scalable algorit
    
[^207]: 基于射频地图的实时室外定位：一种深度学习方法

    Real-time Outdoor Localization Using Radio Maps: A Deep Learning Approach. (arXiv:2106.12556v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2106.12556](http://arxiv.org/abs/2106.12556)

    本文提出了一种使用射频地图进行实时室外定位的深度学习方法，能够实现高精度定位并具有较高的鲁棒性，适用于实时应用，并提供了两种新的数据集用于评估。

    

    全球导航卫星系统在城市环境下表现通常较差，因此需要使用其他定位方法来实现较高的定位精度。本文提出了LocUNet：一种卷积、端到端训练的神经网络，用于定位任务，能够从少量基站的接收信号强度(RSS)估计用户的位置。使用基站的路径损耗射频地图的估计值和待定位用户的RSS测量值，LocUNet可以以最先进的精度定位用户，并具有较高的鲁棒性，可以适应射频地图估计不准确的情况。所提出的方法不需要生成每个特定区域的RSS指纹，并适用于实时应用。此外，创建并公开了两种新的数据集，可用于评估在现实室外场景中的RSS和ToA方法。

    Global Navigation Satellite Systems typically perform poorly in urban environments, where the likelihood of line-of-sight conditions between devices and satellites is low. Therefore, alternative location methods are required to achieve good accuracy. We present LocUNet: A convolutional, end-to-end trained neural network (NN) for the localization task, which is able to estimate the position of a user from the received signal strength (RSS) of a small number of Base Stations (BS). Using estimations of pathloss radio maps of the BSs and the RSS measurements of the users to be localized, LocUNet can localize users with state-of-the-art accuracy and enjoys high robustness to inaccuracies in the estimations of radio maps. The proposed method does not require generating RSS fingerprints of each specific area where the localization task is performed and is suitable for real-time applications. Moreover, two novel datasets that allow for numerical evaluations of RSS and ToA methods in realistic 
    
[^208]: 稀疏线性回归中的基本极限和算法与次线性稀疏性。

    Fundamental limits and algorithms for sparse linear regression with sublinear sparsity. (arXiv:2101.11156v6 [cs.IT] UPDATED)

    [http://arxiv.org/abs/2101.11156](http://arxiv.org/abs/2101.11156)

    本文通过将贝叶斯推断中线性区域的自适应插值方法推广到次线性区域，建立了稀疏线性回归的归一化互信息和最小均方误差的精确渐近表达式，并提出了一种修改近似信息传递算法以接近最小均方误差基本极限的方法。

    

    我们在次线性稀疏性区间建立了稀疏线性回归的归一化互信息和最小均方误差（MMSE）的精确渐近表达式。我们通过将贝叶斯推断中线性区域的自适应插值方法推广到次线性区域来实现我们的结果。我们还提出了一种修改着名的近似信息传递算法以接近MMSE基本极限的方法，并对其状态演化进行了严格分析。我们的结果表明，对于稀疏信号，复制和自适应插值方法中信号维数和观测个数之间的传统线性假设是不必要的。它们还展示了如何将现有的着名的线性区域的AMP算法修改为次线性区域。

    We establish exact asymptotic expressions for the normalized mutual information and minimum mean-square-error (MMSE) of sparse linear regression in the sub-linear sparsity regime. Our result is achieved by a generalization of the adaptive interpolation method in Bayesian inference for linear regimes to sub-linear ones. A modification of the well-known approximate message passing algorithm to approach the MMSE fundamental limit is also proposed, and its state evolution is rigorously analyzed. Our results show that the traditional linear assumption between the signal dimension and number of observations in the replica and adaptive interpolation methods is not necessary for sparse signals. They also show how to modify the existing well-known AMP algorithms for linear regimes to sub-linear ones.
    
[^209]: 量子晶格模型的规范不变性和任意子对称自回归神经网络

    Gauge Invariant and Anyonic Symmetric Autoregressive Neural Networks for Quantum Lattice Models. (arXiv:2101.07243v3 [cond-mat.str-el] UPDATED)

    [http://arxiv.org/abs/2101.07243](http://arxiv.org/abs/2101.07243)

    该论文提出了一种针对量子晶格模型的自回归神经网络，并明确遵守规范对称性或任意子约束，能够提供精确表示量子晶格模型基态和激发态的方法。

    

    对称性，如规范不变性和任意子对称性，在量子多体物理中起着至关重要的作用。我们开发了一种通用方法来构建针对量子晶格模型的规范不变性或任意子对称性自回归神经网络，包括 Transformer 和循环神经网络等各种架构。这些网络可以高效地采样，并明确地遵守规范对称性或任意子约束。我们证明了我们的方法可以提供精确表示2D和3D扭曲码以及X-立方体分形模型的基态和激发态。我们变分优化了我们的对称性合并的自回归神经网络，用于各种模型的基态以及实时动力学。我们模拟了 $\text{U(1)}$ 网格规范理论的量子链接模型的动力学和基态，得到了 2D $\mathbb{Z}_2$ 规范理论的相图，确定了 $\text{SU(2)}$ 临界链的相变和中心荷，以及研究了 2D 三角晶格的自旋模型的热化动力学。

    Symmetries such as gauge invariance and anyonic symmetry play a crucial role in quantum many-body physics. We develop a general approach to constructing gauge invariant or anyonic symmetric autoregressive neural networks, including a wide range of architectures such as Transformer and recurrent neural network, for quantum lattice models. These networks can be efficiently sampled and explicitly obey gauge symmetries or anyonic constraint. We prove that our methods can provide exact representation for the ground and excited states of the 2D and 3D toric codes, and the X-cube fracton model. We variationally optimize our symmetry incorporated autoregressive neural networks for ground states as well as real-time dynamics for a variety of models. We simulate the dynamics and the ground states of the quantum link model of $\text{U(1)}$ lattice gauge theory, obtain the phase diagram for the 2D $\mathbb{Z}_2$ gauge theory, determine the phase transition and the central charge of the $\text{SU(2
    

