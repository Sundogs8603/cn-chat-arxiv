# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [GeneCIS: A Benchmark for General Conditional Image Similarity.](http://arxiv.org/abs/2306.07969) | GeneCIS基准测试衡量模型适应各种相似性条件的能力，并且基准测试的表现与ImageNet的准确性弱相关，仅简单扩展现有方法并不行。 |
| [^2] | [One-for-All: Generalized LoRA for Parameter-Efficient Fine-tuning.](http://arxiv.org/abs/2306.07967) | 本论文提出了一种通用的参数高效微调算法——GLoRA，该算法通过广义提示模块、模块化的适配器层和可扩展的结构搜索具有了对不同任务和数据集的更高灵活性和适应性，并在各类基准测试中表现出了优异的精度。 |
| [^3] | [Parting with Misconceptions about Learning-based Vehicle Motion Planning.](http://arxiv.org/abs/2306.07962) | 该论文提出了nuPlan，一个大规模真实世界数据集和评估方案，针对精确的短期规划和长期目标预测。证实了现有系统难以同时满足两个要求。最终提出一个非常简单高效的规划器。 |
| [^4] | [Differentiating Metropolis-Hastings to Optimize Intractable Densities.](http://arxiv.org/abs/2306.07961) | 本文通过基于互联马尔科夫链的不偏微分，开发出一种无偏、低方差和自动的方法对复杂密度进行生成，从而实现对 MH 采样器的优化。 |
| [^5] | [Privacy Preserving Bayesian Federated Learning in Heterogeneous Settings.](http://arxiv.org/abs/2306.07959) | 本文提出了一种基于贝叶斯框架的联邦学习方法，可以训练定制本地模型以同时满足异构设置、不确定性量化和数据隐私约束，并通过先验分布来促进异构客户端之间的合作。 |
| [^6] | [Hidden Biases of End-to-End Driving Models.](http://arxiv.org/abs/2306.07957) | 端到端驾驶模型存在偏见问题，并引入了次要组件的更改。本文针对目前多数最先进的方法中所存在的两种偏见进行了研究，并提出了合理的替代方法。在此基础上，开发了TF ++，在CARLA测试中表现优异。 |
| [^7] | [MOFI: Learning Image Representations from Noisy Entity Annotated Images.](http://arxiv.org/abs/2306.07952) | MOFI 提出了一种新的方法，自动从含噪图像文本对中为图像指定实体标签，创建了一个新的大规模数据集 I2E，通过研究不同的训练配方，学习到了能够有效学习图像表示的模型。 |
| [^8] | [Improving Frame-level Classifier for Word Timings with Non-peaky CTC in End-to-End Automatic Speech Recognition.](http://arxiv.org/abs/2306.07949) | 本文提出通过在连接时序分类（CTC）损失中引入标签先验，并将低层Mel-scale滤波器和高层ASR编码器输出组合作为输入特征来改进E2E系统中用于词时的帧级分类器，实现了更高的词时准确性。 |
| [^9] | [Optimal Inference in Contextual Stochastic Block Models.](http://arxiv.org/abs/2306.07948) | 本论文提出了一种基于信念传播的算法，用于半监督上下文随机块模型(cSBM)的推断问题。研究发现，相比于现有的图神经网络结构，这种算法达到的准确性更高，同时可用于建立性能基准。 |
| [^10] | [GPT-Calls: Enhancing Call Segmentation and Tagging by Generating Synthetic Conversations via Large Language Models.](http://arxiv.org/abs/2306.07941) | 本文提出了一种名为GPT-Calls的方法，通过使用大型语言模型生成合成对话，以提高电话录音的分割和标记能力。该方法分为离线和在线两个阶段，离线阶段仅应用一次，对给定的主题列表生成合成句子分布并提取锚向量，在线阶段则针对每个通话单独应用，并对转录的对话与离线阶段找到的主题锚定进行相似性评分。时间域分析被应用于相似性得分中，以将话语分组并将其标记为所属主题。 |
| [^11] | [Deep Demixing: Reconstructing the Evolution of Network Epidemics.](http://arxiv.org/abs/2306.07938) | DDmix模型是一个可以从部分或聚合的时间信息中重构在网络上演变的流行病的图形自编码器，它通过数据驱动的方法来克服模型意识的缺乏，并在通用性上得到了凸显。 |
| [^12] | [Multi-modal Representation Learning for Social Post Location Inference.](http://arxiv.org/abs/2306.07935) | 本文提出了多模态表示学习框架（MRLF），用于将社交媒体文章的不同模态融合起来进行位置推断。该方法集成了一个多头注意力机制以增强位置显著信息提取，相对于单一领域的方法显著提高位置推断的准确性。 |
| [^13] | [BoardgameQA: A Dataset for Natural Language Reasoning with Contradictory Information.](http://arxiv.org/abs/2306.07934) | 本文提出了一个用于带有矛盾信息的自然语言推理的数据集，以解决推理中不一致和矛盾信息的问题，同时提供了一种可推翻推理策略。 |
| [^14] | [A Theory of Unsupervised Speech Recognition.](http://arxiv.org/abs/2306.07926) | 本文提出了一个通用的理论框架，以研究无监督语音识别系统的属性，证明了各种可学习性条件和样本复杂性边界，并在合成语言的实验中得到了强有力的实证证据。 |
| [^15] | [Oracle-Efficient Pessimism: Offline Policy Optimization in Contextual Bandits.](http://arxiv.org/abs/2306.07923) | 本文提出了第一个面向Oracle有效的悲观策略优化算法，它简化为监督学习，具有广泛的适用性，能够在上下文强化学习中优化策略。 |
| [^16] | [Skill Disentanglement for Imitation Learning from Suboptimal Demonstrations.](http://arxiv.org/abs/2306.07919) | 该论文提出了一种名为“{\method}”的算法，可以从少量的干净演示中高效学习，同时利用包含在大量有噪声演示中的补充信息，通过在子演示级别上进行评估和模仿，将具有不同质量的操作原语编码为不同的技能来帮助机器分离出子技能。 |
| [^17] | [Causal Mediation Analysis with Multi-dimensional and Indirectly Observed Mediators.](http://arxiv.org/abs/2306.07918) | 该论文介绍了一种能够处理复杂和间接观测的中介因素的因果中介分析框架。 |
| [^18] | [Identification of Nonlinear Latent Hierarchical Models.](http://arxiv.org/abs/2306.07916) | 本文提出了一种方法，可以在观测变量由因果相关的潜变量生成的非线性潜变量层次因果模型中实现因果结构和潜变量的可识别性。 |
| [^19] | [Omega: Optimistic EMA Gradients.](http://arxiv.org/abs/2306.07905) | Omega是一种优化算法，通过加入历史梯度EMA来减轻噪声的影响并在随机游戏上表现更佳。 |
| [^20] | [Tight Memory-Regret Lower Bounds for Streaming Bandits.](http://arxiv.org/abs/2306.07903) | 本文研究流式赌博机问题，为任何具有时间跨度T、臂数量K和经过次数B的算法建立了最紧密的最坏情况遗憾下界，同时也建立了第一个依赖于具体实例的下界。与经典的集中式随机赌博机问题相比较，流式设置下不可避免地有更多的双对数因子。 |
| [^21] | [Robustly Learning a Single Neuron via Sharpness.](http://arxiv.org/abs/2306.07892) | 该论文提出了一种可以对广泛激活函数族中的神经元的最优$L_2^2$误差进行近似的有效算法。 |
| [^22] | [VISION Datasets: A Benchmark for Vision-based InduStrial InspectiON.](http://arxiv.org/abs/2306.07890) | 本论文介绍了VISION数据集，这是一个多元化集合，包含14个不同工业领域检测数据集，提供了注释墨水和实例分割注释，并适用于多种检测方法。VISION数据集可以应对现实世界中工业领域检测中的挑战，并有望促进基于视觉的工业检测的发展。 |
| [^23] | [Symmetry & Critical Points for Symmetric Tensor Decompositions Problems.](http://arxiv.org/abs/2306.07886) | 本文研究了将一个实对称张量分解成秩为1项之和的非凸优化问题，得到了精确的分析估计，并发现了各种阻碍局部优化方法的几何障碍和由于对称性导致的丰富的临界点集合。 |
| [^24] | [Taxonomy-Structured Domain Adaptation.](http://arxiv.org/abs/2306.07874) | 本文提出了分层结构领域自适应方法，通过分层结构领域的形式化描述来缓解不同领域之间的分布偏移，该方法在合成和实际数据集上实现了最先进的性能。 |
| [^25] | [Additive Causal Bandits with Unknown Graph.](http://arxiv.org/abs/2306.07858) | 该论文讨论了因果赌博机中选择行动的算法问题，提出了一种基于加性组合线性赌博问题的解决方法以解决未知图谱问题。 |
| [^26] | [Exact Mean Square Linear Stability Analysis for SGD.](http://arxiv.org/abs/2306.07850) | 本文提供了SGD稳定性的精确阈值表达式，发现其与批量大小之间呈单调非降关系，进一步展示了减小批量大小可能会影响SGD的稳定性。 |
| [^27] | [Unsupervised speech enhancement with deep dynamical generative speech and noise models.](http://arxiv.org/abs/2306.07820) | 本研究提出了一种基于DDGM的无监督语音增强方法，通过三种配置训练DDGM，其中噪声依赖的训练配置使推理过程更加高效，实验结果显示该方法可获得竞争性的性能表现。 |
| [^28] | [A Primal-Dual-Critic Algorithm for Offline Constrained Reinforcement Learning.](http://arxiv.org/abs/2306.07818) | PDCA是一种用于离线约束强化学习的算法，它可以通过在Lagrangian函数上运行原始-对偶算法来找到近似鞍点，而无需集中性和强Bellman完备性假设。 |
| [^29] | [Automated 3D Pre-Training for Molecular Property Prediction.](http://arxiv.org/abs/2306.07812) | 通过在3D分子图上进行预训练，该论文提出了一种更有效地预测分子属性的方法，该方法可以在不需要分子几何结构的情况下进行微调。 |
| [^30] | [Low-Resource White-Box Semantic Segmentation of Supporting Towers on 3D Point Clouds via Signature Shape Identification.](http://arxiv.org/abs/2306.07809) | 本文提出了一种低资源白盒模型，SCENE-Net，用于3D点云语义分割，通过特征形状识别提供内在几何解释性，较少的参数和数据需求以及对噪音标签和数据不平衡的鲁棒性。 |
| [^31] | [Inferring dynamic regulatory interaction graphs from time series data with perturbations.](http://arxiv.org/abs/2306.07803) | 本文提出了RiTINI方法，使用空间与时间图注意力和图神经常微分方程的组合来推断复杂系统中的变化的交互图，相比传统因果推断网络，具有能够推断循环、有向和时变图的优势。 |
| [^32] | [ChatGPT vs Human-authored Text: Insights into Controllable Text Summarization and Sentence Style Transfer.](http://arxiv.org/abs/2306.07799) | 本文旨在系统地检查ChatGPT在两个可控生成任务中的表现，即ChatGPT能否适应不同的目标受众和写作风格。研究发现，人类产生的文体变化比ChatGPT表现出的更大，而生成的文本在一些特征上与人类样本有所不同，有时会包含事实错误或幻觉。 |
| [^33] | [Finite Gaussian Neurons: Defending against adversarial attacks by making neural networks say "I don't know".](http://arxiv.org/abs/2306.07796) | 这篇论文介绍了有限高斯神经元（FGN）这种新的神经元架构，可以通过简单地将现有模型转换为FGN结构，从而抵御对抗性攻击并同时保持高准确性和可信度。 |
| [^34] | [Compositionally Equivariant Representation Learning.](http://arxiv.org/abs/2306.07783) | 本文研究了利用组合性来学习更具可解释性和泛化性的医学图像分割表示，提出了一种将组合等变性质纳入表示学习中的方法，并在各种医学图像分割任务上展示了其对泛化性能的提升。 |
| [^35] | [The Rank-Reduced Kalman Filter: Approximate Dynamical-Low-Rank Filtering In High Dimensions.](http://arxiv.org/abs/2306.07774) | 该论文提出了一种新的近似高斯滤波和平滑方法，它将协方差矩阵的低秩近似传播，通过将Lyapunov方程投影到低秩矩阵的流形上，使用数值稳定的动态低秩积分器求解，能够有效地处理高维数据。 |
| [^36] | [Area is all you need: repeatable elements make stronger adversarial attacks.](http://arxiv.org/abs/2306.07768) | 本文证明对抗性攻击的成功主要是由于攻击尺寸的增加，通过构建可重复元素的对抗性图案可以生成最大可能的对抗性补丁，并实现了躲避检测的新最先进。 |
| [^37] | [Multi-Fidelity Multi-Armed Bandits Revisited.](http://arxiv.org/abs/2306.07761) | 该论文研究了多保真度多臂赌博机问题，提出了算法框架，并进一步研究了保真度选择的代价复杂度上下界，还提出了一种新的遗憾定义并证明了相应的问题无关和问题相关下界。 |
| [^38] | [Provably Learning Nash Policies in Constrained Markov Potential Games.](http://arxiv.org/abs/2306.07749) | 本文研究了约束马尔可夫潜在博弈（CMPGs），并提出了一种寻找CMPGs的纳什策略的约束优化算法，该算法解决了单智能体模型中CMPG问题不满足强对偶性的问题 |
| [^39] | [Kernelized Reinforcement Learning with Order Optimal Regret Bounds.](http://arxiv.org/abs/2306.07745) | 该论文提出了一种称为$\pi$-KRVI的乐观修改方法，并使用核岭回归进行强化学习中的非线性函数逼近。论文证明了在一般设置下第一个最优遗憾保证，并相对于现有最优结果实现了显着的多项式低差距。 |
| [^40] | [Contrastive Learning-Based Audio to Lyrics Alignment for Multiple Languages.](http://arxiv.org/abs/2306.07744) | 本文提出了一种使用对比学习方法实现的音频和歌词对齐系统，不仅表现出色，而且具有对其他语言的鲁棒性。 |
| [^41] | [V-LoL: A Diagnostic Dataset for Visual Logical Learning.](http://arxiv.org/abs/2306.07743) | V-LoL是一个结合视觉和逻辑挑战的诊断数据集，其中包括了V-LoL-Trains，该数据集首次将复杂的视觉场景和灵活的逻辑推理任务结合起来，为研究广泛的视觉逻辑学习挑战提供了平台。 |
| [^42] | [Stepsize Learning for Policy Gradient Methods in Contextual Markov Decision Processes.](http://arxiv.org/abs/2306.07741) | 本文提出了一种元强化学习方法，在情境马尔可夫决策过程中用于超参数选择问题。该方法在标准基准测试上优于现有步长自适应方法，能够实现各种任务范围内的良好性能。 |
| [^43] | [Robustness and Generalization Performance of Deep Learning Models on Cyber-Physical Systems: A Comparative Study.](http://arxiv.org/abs/2306.07737) | 本文研究了深度学习模型在物理-计算系统中的鲁棒性和泛化性能，并通过暴露模型于分布之外的样本来测试其迁移学习能力和响应数据增强技术的能力。结果表明，深度学习模型虽能达高精度，但其鲁棒性和泛化能力还不足以应用于实际物理-计算系统中。 |
| [^44] | [BeliefPPG: Uncertainty-aware Heart Rate Estimation from PPG signals via Belief Propagation.](http://arxiv.org/abs/2306.07730) | 通过离散时间随机过程将心率演变表示为隐藏马尔科夫模型，使用训练的神经网络计算PPG信号窗口内的可能心率值分布，然后通过置信传播结合统计分布监测心率变化以优化这些估计，并获得涵盖心率值范围的量化概率分布以捕获固有预测不确定性的良好校准估计。 |
| [^45] | [Effects of Data Enrichment with Image Transformations on the Performance of Deep Networks.](http://arxiv.org/abs/2306.07724) | 本文通过实验调查了数据增强对超分辨率问题中深度网络性能的影响，发现混合所有转换的数据时模型得分最高，180°旋转增强的数据提供了最佳结果。 |
| [^46] | [Theoretical Foundations of Adversarially Robust Learning.](http://arxiv.org/abs/2306.07723) | 本论文从理论角度探讨了对抗鲁棒性学习的问题，提出了新的学习算法，并分析了其鲁棒性和泛化性能。 |
| [^47] | [Coordinated Dynamic Bidding in Repeated Second-Price Auctions with Budgets.](http://arxiv.org/abs/2306.07709) | 本文研究了带预算的重复二价拍卖中的协调在线竞价算法，提出了能够保证每个客户效用最大化的算法，并证明实现了最大的联盟福利。 |
| [^48] | [Time-aware Graph Structure Learning via Sequence Prediction on Temporal Graphs.](http://arxiv.org/abs/2306.07699) | 该论文提出了一种基于时间图序列预测的时态图结构学习方法，通过添加潜在的时间边来学习更好的图像结构，提高下游任务的性能。 |
| [^49] | [StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion and Adversarial Training with Large Speech Language Models.](http://arxiv.org/abs/2306.07691) | 本文提出了一种名为StyleTTS 2的TTS模型，通过对抗训练和大型语音语言模型来实现人类级别的语音合成。与以往模型不同，StyleTTS 2将样式视为潜在随机变量，利用扩散模型来生成最适合文本的样式，同时受益于大型SLMs和新的可微分持续时间建模。 |
| [^50] | [Differentially Private One Permutation Hashing and Bin-wise Consistent Weighted Sampling.](http://arxiv.org/abs/2306.07674) | 本研究提出了一种在差分隐私条件下的一次排列哈希方法和基于 Bin 的一致加权采样，为大规模搜索和学习应用程序提供了更高效、更方便的工具。 |
| [^51] | [Rethink the Effectiveness of Text Data Augmentation: An Empirical Analysis.](http://arxiv.org/abs/2306.07664) | 本研究发现数据增强技术在语言模型的预训练及微调中仍具有显著的提升作用，尤其在少样本学习的情况下，持续的预训练可以提高微调性能10%以上。 |
| [^52] | [Malafide: a novel adversarial convolutive noise attack against deepfake and spoofing detection systems.](http://arxiv.org/abs/2306.07655) | 本文提出一个新型通用的对抗性攻击Malafide，可以攻击自动语音识别（ASV）欺诈对策（CMs）。该攻击可以用于ompromise CM的可靠性，同时保留语音的其他属性，例如质量和说话人的声音。 Malafide滤波器独立于输入话语和持续时间进行优化，并调整到基础欺骗攻击，只需要优化少量滤波器系数。集成自监督学习CM的解决方案在黑盒和白盒设置下更加稳健。 |
| [^53] | [Automating Microservices Test Failure Analysis using Kubernetes Cluster Logs.](http://arxiv.org/abs/2306.07653) | 本研究旨在通过比较五种分类算法，使用Kubernetes集群日志自动判定微服务测试失败原因。结果表明，随机森林算法在需要较少计算资源的同时，能够产生良好的准确性。 |
| [^54] | [Variational Positive-incentive Noise: How Noise Benefits Models.](http://arxiv.org/abs/2306.07651) | 本文研究了如何通过正激励噪声框架下的随机噪声使经典模型受益，并提出了变分Pi-Noise，它可以在不改变原始模型结构的情况下增强和简化模型。 |
| [^55] | [SRATTA : Sample Re-ATTribution Attack of Secure Aggregation in Federated Learning.](http://arxiv.org/abs/2306.07644) | SRATTA是一个新型的联邦学习攻击，可以在安全聚合下恢复客户端样本数据并将其按客户端分组，对联邦学习构成重要的安全威胁，需要客户端积极保护隐私并采取反制措施。 |
| [^56] | [SqueezeLLM: Dense-and-Sparse Quantization.](http://arxiv.org/abs/2306.07629) | 本文提出了一种基于训练后的量化框架——SqueezeLLM，它不仅可以实现高达3位的无损压缩，而且在相同的内存约束下实现更高的量化性能。 |
| [^57] | [Human-Like Intuitive Behavior and Reasoning Biases Emerged in Language Models -- and Disappeared in GPT-4.](http://arxiv.org/abs/2306.07622) | 本研究揭示了大型语言模型（LLMs）具有类人直觉行为和认知错误的特点，而高级语言模型则通过学习避免这类错误并表现出超理性的方式。此外，通过使用心理学研究的方法探测LLMs，可以揭示其新生特性。 |
| [^58] | [Hyperbolic Graph Diffusion Model for Molecule Generation.](http://arxiv.org/abs/2306.07618) | 本文提出了基于双曲图扩散模型的分子生成方法，可以更全面地捕捉分子的内部非欧几里德结构，实现数据生成，并提取复杂几何特征的能力。 |
| [^59] | [Rethinking Adversarial Training with A Simple Baseline.](http://arxiv.org/abs/2306.07613) | 这篇论文提出了一种简单的对抗训练baseline，使用了重新调整的平方损失、循环学习率和基于擦除的数据增强等方法，在对抗和自然准确度之间产生了良好的平衡，并可有效降低robust overfitting风险，表现与最先进方法媲美。 |
| [^60] | [Towards a Machine-Learned Poisson Solver for Low-Temperature Plasma Simulations in Complex Geometries.](http://arxiv.org/abs/2306.07604) | 本文开发了一种通用的机器学习泊松求解器，能较好地解决复杂2D反应堆几何形状的LTP模拟中Poisson方程计算成本高等问题。 |
| [^61] | [Large Language Models Sometimes Generate Purely Negatively-Reinforced Text.](http://arxiv.org/abs/2306.07567) | 大型语言模型有时会从仅包含负奖励的例子中学习，导致生成类似泄漏密码或安全漏洞等敏感信息的文本 |
| [^62] | [Learning under Selective Labels with Heterogeneous Decision-makers: An Instrumental Variable Approach.](http://arxiv.org/abs/2306.07566) | 本文提出了一种处理选择性标记数据的学习问题的方法。通过利用历史决策由一组异质决策者做出的事实，我们建立了一种有原理的工具变量框架，并提出了一种加权学习方法，用于学习预测规则。 |
| [^63] | [Galactic: Scaling End-to-End Reinforcement Learning for Rearrangement at 100k Steps-Per-Second.](http://arxiv.org/abs/2306.07552) | Galactic是一个针对室内物体重排问题的大规模仿真和强化学习框架。这个框架可以在每秒 100k 步上运行，比其他相似框架快很多。 |
| [^64] | [Fixed-Budget Best-Arm Identification with Heterogeneous Reward Variances.](http://arxiv.org/abs/2306.07549) | 本文提出了两种改进BAI算法，SHVar适用于已知奖励方差情况，SHAdaVar适用于未知奖励方差情况，算法通过在不同臂之间分配不同比例的预算，更多地选择方差更高的臂，SHAdaVar通过过度估计未知奖励方差以贪心地分配预算。创新之处在于无需关闭预算分配问题的解决方案的臂拉动次数下界。 |
| [^65] | [On Achieving Optimal Adversarial Test Error.](http://arxiv.org/abs/2306.07544) | 本文提出了最优对抗预测器的各种基本特性，并结合新的Rademacher复杂度界限证明了，在浅层网络上进行对抗训练，采用早停和理想的最优对手，能够实现最优对抗测试误差。 |
| [^66] | [A Simple Unified Uncertainty-Guided Framework for Offline-to-Online Reinforcement Learning.](http://arxiv.org/abs/2306.07541) | SUNG是一种基于不确定性引导的离线到在线强化学习框架，在通过量化不确定性进行探索和应用保守Q值估计的指导下，实现了高效的老化强化学习。 |
| [^67] | [TART: A plug-and-play Transformer module for task-agnostic reasoning.](http://arxiv.org/abs/2306.07536) | TART提出了一种即插即用的Transformer模块，它能够在没有任务特定训练或微调的情况下，在不同推理目标之间进行泛化。 |
| [^68] | [Unified Off-Policy Learning to Rank: a Reinforcement Learning Perspective.](http://arxiv.org/abs/2306.07528) | 本文提出了点击模型不可知的统一非同策略学习排序（CUOLR）方法，通过离线强化学习（RL）直接学习最优排名，可以轻松地应用于各种点击模型。 |
| [^69] | [User-defined Event Sampling and Uncertainty Quantification in Diffusion Models for Physical Dynamical Systems.](http://arxiv.org/abs/2306.07526) | 本文提出了一种条件得分函数的概率近似方案，可以用于混沌动力系统的预测和提供不确定性量化。 |
| [^70] | [Using Collision Momentum in Deep Reinforcement Learning Based Adversarial Pedestrian Modeling.](http://arxiv.org/abs/2306.07525) | 该研究提出了一种基于碰撞动量的深度强化学习算法，能够更好地发现自动驾驶算法在极端情况下的缺陷并加以纠正。 |
| [^71] | [Decoding Brain Motor Imagery with various Machine Learning techniques.](http://arxiv.org/abs/2306.07519) | 本文研究运用不同的机器学习方法解码运动想象，基于证据累积实时预测受试者的意图。 |
| [^72] | [Noisy Positive-Unlabeled Learning with Self-Training for Speculative Knowledge Graph Reasoning.](http://arxiv.org/abs/2306.07512) | 本文提出了一种嘈杂正-无标记学习问题的变分框架nPUGraph，并引入自训练策略，以应对真实世界知识图谱上的思辨性推理任务。实验结果表明了我们提出的方法的有效性。 |
| [^73] | [PaVa: a novel Path-based Valley-seeking clustering algorithm.](http://arxiv.org/abs/2306.07503) | PaVa是一种基于路径谷寻找的新型聚类算法，可以高精度、高效地发现任意形状的聚类。 |
| [^74] | [Improving Opinion-based Question Answering Systems Through Label Error Detection and Overwrite.](http://arxiv.org/abs/2306.07499) | 本文提出了一种名为LEDO的模型-不可知且计算高效的框架，能够有效解决标签错误问题，并将其应用于意见问答系统中，提高了该系统在各个核心模型中的准确性。 |
| [^75] | [GQFedWAvg: Optimization-Based Quantized Federated Learning in General Edge Computing Systems.](http://arxiv.org/abs/2306.07497) | 本论文提出了一种适用于在一般的边缘计算系统中的基于优化的量化FL算法，采用新的随机量化方案和加权平均本地模型更新的广义小批量随机梯度下降方法在全局模型聚合中，以适应在工作节点具有均匀或非均匀的计算和通信资源的情况。 |
| [^76] | [Learning Unnormalized Statistical Models via Compositional Optimization.](http://arxiv.org/abs/2306.07485) | 本文介绍了一种通过组合优化的方式学习非归一化统计模型的方法，采用噪声分布处理分区函数，具有优化效率和泛化性能更好的特点。 |
| [^77] | [Multi-objective Molecular Optimization for Opioid Use Disorder Treatment Using Generative Network Complex.](http://arxiv.org/abs/2306.07484) | 本研究提出了一种深度生成模型，能够高效地生成对多个靶点有效的分子（包括μ、κ和δ阿片受体），并且已经构建了结合亲和力预测器。 |
| [^78] | [Incentivizing High-Quality Content in Online Recommender Systems.](http://arxiv.org/abs/2306.07479) | 本文研究了在线推荐系统中激励高质量内容的算法问题，经典的在线学习算法会激励生产者创建低质量的内容，但本文提出的一种算法通过惩罚低质量内容的创建者，成功地激励了生产者创造高质量的内容。 |
| [^79] | [3D molecule generation by denoising voxel grids.](http://arxiv.org/abs/2306.07473) | VoxMol是一种根据分数的新方法，可以生成3D分子，并通过学习从噪声分子的平滑分布到真实分子的分布的映射。该方法与当前先进技术不同，具有更简单的训练和更快的速度。 |
| [^80] | [Von Mises Mixture Distributions for Molecular Conformation Generation.](http://arxiv.org/abs/2306.07472) | 传统的分子几何结构采样方法计算成本很高，而机器学习方法多数专注于分布中的模式识别。本文提出的Von Mises混合分布用于生成更准确的样本。 |
| [^81] | [A Black-box Approach for Non-stationary Multi-agent Reinforcement Learning.](http://arxiv.org/abs/2306.07465) | 本文提出了一种通用的黑盒方法，适用于多种多智能体强化学习问题，可以在非平稳环境下实现低遗憾率的学习。 |
| [^82] | [Unlocking Sales Growth: Account Prioritization Engine with Explainable AI.](http://arxiv.org/abs/2306.07464) | 论文开发了一款名为 Account Prioritizer 的智能销售账户优先级引擎，使用机器学习和解释算法自动化销售簿优化，在 LinkedIn Business 中成功带来了 +8.08% 的续订订阅增长。 |
| [^83] | [On the Robustness of Removal-Based Feature Attributions.](http://arxiv.org/abs/2306.07462) | 本文研究了Removal-Based特征归因的鲁棒性，提供了全面的理论和实验分析，并证明了所提方法的实际有效性。 |
| [^84] | [FIRE: An Optimization Approach for Fast Interpretable Rule Extraction.](http://arxiv.org/abs/2306.07432) | FIRE是一种用于从树集合中提取易于审查的稀疏规则子集的优化方法，可以鼓励在选择时融合规则，从而增强模型的可解释性，并且在实验中表现出更高的准确性和可解释性。 |
| [^85] | [DeepTransition: Viability Leads to the Emergence of Gait Transitions in Learning Anticipatory Quadrupedal Locomotion Skills.](http://arxiv.org/abs/2306.07419) | 本文通过深度强化学习和机器人工具的互动研究，证明了可行性是四足动物步态转换的重要标准。其中，步-小跑步态转换能够在平坦地形上同时提高可行性和节能效果。 |
| [^86] | [Robust Reinforcement Learning through Efficient Adversarial Herding.](http://arxiv.org/abs/2306.07408) | 本研究提出了对抗性聚集方法，通过引入对手群来解决内部优化问题的困难，从而提高强化学习代理的鲁棒性，并通过对最差表现者中最坏的k个表现的平均表现来解决过度悲观主义问题。 |
| [^87] | [Adversarial Attacks on the Interpretation of Neuron Activation Maximization.](http://arxiv.org/abs/2306.07397) | 本文研究了对神经网络内部功能行为解释方法的对抗攻击，提出了一个操纵模型以干扰解释的优化框架，并演示了流行的激活最大化解释技术被操纵以改变其解释的方法。 |
| [^88] | [Composing Efficient, Robust Tests for Policy Selection.](http://arxiv.org/abs/2306.07372) | 该论文提出了一种名为RPOSST的算法，它可以从较大的测试案例池中选择一小部分测试样例，验证其高质量的策略在更广泛的环境下也是可靠的。 |
| [^89] | [Multi-Platform Budget Management in Ad Markets with Non-IC Auctions.](http://arxiv.org/abs/2306.07352) | 本论文提出了一种针对广告市场上预算限制和拍卖非激励兼容问题的优化竞标策略，在满足广告主预期预算限制的同时最大化预期总效用；并研究了跨平台提交竞标的在线设置。 |
| [^90] | [G-invariant diffusion maps.](http://arxiv.org/abs/2306.07350) | 研究构造了针对连续矩阵群封闭下的流形中采样的数据集的G-不变扩散地图，能够实现等变且不变的嵌入，适用于对数据点进行聚类和对齐。 |
| [^91] | [ATT3D: Amortized Text-to-3D Object Synthesis.](http://arxiv.org/abs/2306.07349) | 该论文提出了一种“摊销”的文本到三维物体合成方法，将许多提示一起使用一个统一的模型进行训练，共享提示之间的优化计算，从而在更短时间内训练模型；该方法能够使不同提示之间进行平滑的插值，并在新的资产和简单动画之间实现知识共享和推广。 |
| [^92] | [Splitting and Parallelizing of Quantum Convolutional Neural Networks for Learning Translationally Symmetric Data.](http://arxiv.org/abs/2306.07331) | 提出一种基于平移对称性的分裂并行化QCNN架构，可以高效地学习平移对称量子数据，相比传统的QCNN极大地提高了测量效率和速度。 |
| [^93] | [A New Probabilistic Distance Metric With Application In Gaussian Mixture Reduction.](http://arxiv.org/abs/2306.07309) | 本文提出了一种新的距离度量方法，用于计算高斯混合模型，从而提高信号处理应用的效率和稳定性。同时，提出了一种新的基于优化的贪心 GMR（OGGMR）算法，用于将高次高斯混合模型近似为低阶模型，实验表明它比现有的GMR算法更快、更高效，并能保留原始模型的几何形状。 |
| [^94] | [Self-Supervised Hyperspectral Inpainting with the Optimisation inspired Deep Neural Network Prior.](http://arxiv.org/abs/2306.07308) | 本文提出了一种自监督的高光谱图像修复算法LRS-PnP-DIP，该算法能够在高光谱图像中精确预测缺失像素和带，其在实验中表现优异，达到或超过了其他学习方法。 |
| [^95] | [Online Prototype Alignment for Few-shot Policy Transfer.](http://arxiv.org/abs/2306.07307) | 本文提出了一种基于元素功能相似性的在线原型对齐（OPA）框架，能够在少样本的情况下实现策略转移，解决了传统方法映射函数学习需要大量数据以及依赖视觉特征等问题。 |
| [^96] | [Making forecasting self-learning and adaptive -- Pilot forecasting rack.](http://arxiv.org/abs/2306.07305) | 本文提出了通过使用试点预测架构中的算法干预来提高非AI模型下针织品类别的预测准确性。在决策模型中动态地选择最佳算法可提高预测准确性，并通过AI / ML预测模型使用先进的特征工程来实现。 |
| [^97] | [A Holistic Approach to Unifying Automatic Concept Extraction and Concept Importance Estimation.](http://arxiv.org/abs/2306.07304) | 本文提出了一个全面的理论框架，来统一定义和澄清自动概念提取和概念重要性评估，进而提供新的评估指标以实现对这些方法的比较以及推导关于这种方法的最优性的理论保证。 |
| [^98] | [A Comprehensive Survey on Applications of Transformers for Deep Learning Tasks.](http://arxiv.org/abs/2306.07303) | 本文综述了基于Transformer的深度学习任务应用，Transformer能够理解序列数据中的上下文关系且实现并行处理，在NLP、计算机视觉、语音处理、医疗保健和物联网等领域表现出色。 |
| [^99] | [Novel Regression and Least Square Support Vector Machine Learning Technique for Air Pollution Forecasting.](http://arxiv.org/abs/2306.07301) | 提出了一种新技术，称为DR-LSSV，基于回归和最小二乘支持向量机，可有效提高空气污染预测性能，并在空气污染预测准确性、空气污染预测时间和假阳性率方面超越了传统的机器学习方法。 |
| [^100] | [Progressive Class-Wise Attention (PCA) Approach for Diagnosing Skin Lesions.](http://arxiv.org/abs/2306.07300) | 本研究提出一种新的分类关注技术，能够平等关注每个皮肤病变类别，并逐步结合多个尺度的判别特征细节，从而获得显著的诊断表现，准确率分别为97.40％和94.9％，超过了15种尖端方法，包括HAM1000和ISIC2019排行榜的优胜者。 |
| [^101] | [Additive Multi-Index Gaussian process modeling, with application to multi-physics surrogate modeling of the quark-gluon plasma.](http://arxiv.org/abs/2306.07299) | 本文针对多物理量代理建模中高维预测训练数据有限、现有代理模型预测不确定性高的问题，提出了一种新的加性多指标高斯过程模型(AdMIn-GP)。该模型利用参数空间内低维嵌入的灵活加性结构，充分利用科学先前知识指导。 |
| [^102] | [Medical Data Augmentation via ChatGPT: A Case Study on Medication Identification and Medication Event Classification.](http://arxiv.org/abs/2306.07297) | 本研究利用ChatGPT进行数据增广，显著提高了BERT模型在电子病历药物识别和药物事件分类任务中的表现。 |
| [^103] | [Optimized Three Deep Learning Models Based-PSO Hyperparameters for Beijing PM2.5 Prediction.](http://arxiv.org/abs/2306.07296) | 本论文提出了基于PSO超参数优化的三种深度学习模型，针对北京PM2.5的预测任务进行研究，并发现M-1模型具有最佳性能且经过优化的超参数可以提高5.6%的预测准确度。 |
| [^104] | [Expressivity Enhancement with Efficient Quadratic Neurons for Convolutional Neural Networks.](http://arxiv.org/abs/2306.07294) | 本文提出了基于二次神经元的高效CNN结构，能够有效地提高网络性能，而且参数和计算成本都有大幅度减少。 |
| [^105] | [Urban Spatiotemporal Data Synthesis via Neural Disaggregation.](http://arxiv.org/abs/2306.07292) | 本研究提出了一种基于神经网络的城市时空数据合成方法，旨在通过分解粗糙的低分辨率地理单元的聚合城市数据来合成细粒度，高分辨率的城市数据，以增加高度聚合的城市数据的可用性和实现价值。 |
| [^106] | [An Ensemble Machine Learning Approach for Tropical Cyclone Detection Using ERA5 Reanalysis Data.](http://arxiv.org/abs/2306.07291) | 本文中介绍了一种利用机器学习方法，结合多个模型进行热带气旋中心坐标检测的集成方法。 |
| [^107] | [Value function estimation using conditional diffusion models for control.](http://arxiv.org/abs/2306.07290) | 论文提出了一种基于条件扩散模型的值函数估计控制方法（DVF），该方法可以在大量条件化数据上有效地进行训练，并使用只有一小部分示范数据就能超过基准算法。 |
| [^108] | [Fair Learning to Rank with Distribution-free Risk Control.](http://arxiv.org/abs/2306.07188) | 本论文提出了一种新的后置模型无关方法，公平LTR-RC，它不需要昂贵的训练，在保证公平性的同时，还能在效用和公平之间实现有效的权衡。 |
| [^109] | [Kernel Random Projection Depth for Outlier Detection.](http://arxiv.org/abs/2306.07056) | 本文提出了一种内核随机投影深度方法，用于处理数据云中的多模式和非凸性，实验结果表明在基准数据集上表现优异。 |
| [^110] | [VillanDiffusion: A Unified Backdoor Attack Framework for Diffusion Models.](http://arxiv.org/abs/2306.06874) | 本文提出VillanDiffusion，一个针对扩散模型的统一后门攻击框架，涵盖主流的无条件和有条件DM，便于对不同DM配置进行后门分析，并为基于字幕的DM后门攻击提供了新的见解。 |
| [^111] | [Multimodal Audio-textual Architecture for Robust Spoken Language Understanding.](http://arxiv.org/abs/2306.06819) | 本文提出了一种使用多模态语言理解（MLU）模块的口语理解解决方案，结合了音频和文本模态的自我监督特征，并充分利用了预训练语言模型（BERT和RoBERTa），以减轻由ASR错误传播带来的性能下降。 |
| [^112] | [Improving the Validity of Decision Trees as Explanations.](http://arxiv.org/abs/2306.06777) | 该论文介绍了一个新的决策树模型，利用挂起的树的方式提高了其解释性和统计性能，达到了无限深度决策树的水平，并可与XGBoost等最先进的方法相媲美。 |
| [^113] | [Interpretable Differencing of Machine Learning Models.](http://arxiv.org/abs/2306.06473) | 本论文提出了一种预测两个机器学习模型输出相似度函数的方法，同时要求表示差异的方式可被人类解释，并通过学习联合代理树提供直观的差异表示和上下文信息，以帮助用户对AI系统进行基础性思维模型的映射。 |
| [^114] | [Aria Digital Twin: A New Benchmark Dataset for Egocentric 3D Machine Perception.](http://arxiv.org/abs/2306.06362) | Aria数字孪生是一个自我中心数据集，具有其它任何数据集都没有的高精度、照片逼真和详尽的真实信息。这个数据集将成为自我中心机器感知评估的新标准。 |
| [^115] | [14 Examples of How LLMs Can Transform Materials Science and Chemistry: A Reflection on a Large Language Model Hackathon.](http://arxiv.org/abs/2306.06283) | 本文记录了一次黑客松活动，参与者使用LLMs进行了各种应用，包括预测分子和材料特性、从非结构化数据中提取知识、为工具设计新界面以及开发新的教育应用。这些多样化的项目反映了LLMs在材料科学和化学领域的多功能性和潜力。 |
| [^116] | [Near-optimal Conservative Exploration in Reinforcement Learning under Episode-wise Constraints.](http://arxiv.org/abs/2306.06265) | 本文研究了强化学习中实现保守探索的问题，提出了名为StepMix的算法，利用现有的安全基线策略平衡开发和探索，同时保证每个回合不违反保守限制，并且能够在不受限制的情况下达到接近最优的后悔量级。 |
| [^117] | [End-to-End Neural Network Compression via $\frac{\ell_1}{\ell_2}$ Regularized Latency Surrogates.](http://arxiv.org/abs/2306.05785) | 提出了一种端到端的神经网络压缩技术，通过优化模型的浮点运算量或设备延迟来自动设置压缩超参数。算法速度快，并且可以与多种常用压缩方法一起使用，如剪枝、低秩分解和量化。在GLUE微调任务的BERT压缩中，FLOPs可降低50％，且性能仅下降1％；而在ImageNet-1K上对MobileNetV3进行压缩，则可以使FLOPs降低15％，同时性能基本不损失。 |
| [^118] | [Federated Linear Contextual Bandits with User-level Differential Privacy.](http://arxiv.org/abs/2306.05275) | 本文研究了带有用户级差分隐私的联邦线性上下文强化学习模型，为CDP提出了近乎最优的联邦算法\robin，在LDP下证明了学习必须承受至少一个遗憾膨胀因子。 |
| [^119] | [EMO: Episodic Memory Optimization for Few-Shot Meta-Learning.](http://arxiv.org/abs/2306.05189) | EMO是一种元学习的情节记忆优化方案，通过在外部存储器中记录过去任务的梯度历史，实现小样本学习，无论提供的梯度信息是否可靠，都可以推动参数更新朝着正确的方向前进。 |
| [^120] | [FLEdge: Benchmarking Federated Machine Learning Applications in Edge Computing Systems.](http://arxiv.org/abs/2306.05172) | FLEdge是一个面向边缘计算系统中FL工作量的基准测试，通过研究硬件异构性、能量效率和隐私级别对FL系统训练的影响，以及客户端退出对最新FL策略的影响，提供了训练最先进的FL工作负载的新见解。 |
| [^121] | [Does Long-Term Series Forecasting Need Complex Attention and Extra Long Inputs?.](http://arxiv.org/abs/2306.05035) | 本论文介绍了一种新的轻量级周期-注意机制，名为Periodformer，解决了长期序列预测中的两个主要问题，并证明了Transformer-based方法不需要额外长的输入序列来保证性能。 |
| [^122] | [Multi-Task Training with In-Domain Language Models for Diagnostic Reasoning.](http://arxiv.org/abs/2306.04551) | 本文研究了领域内与领域外语言模型以及多任务与单任务训练的比较，并证明了通过临床训练的多任务语言模型在临床诊断推理任务中表现优异，建立了新的最优性能。 |
| [^123] | [Fair Column Subset Selection.](http://arxiv.org/abs/2306.04489) | 解决了公平的列子集选择问题，通过已知方法基于确定性杠杆分数采样，提出了一种有效算法，可以在1.5倍的大小下实现与两倍相同的近似保证。 |
| [^124] | [Differential Privacy with Random Projections and Sign Random Projections.](http://arxiv.org/abs/2306.01751) | 本文提出了一系列差分隐私算法，其中iDP-SignRP算法在个体差分隐私设置下效果显著，DP-SignOPORP算法改进了现有算法，DP-OPORP算法表现最优，iDP提供了一种适用于特定数据集的隐私保护解决方案。 |
| [^125] | [ReLU to the Rescue: Improve Your On-Policy Actor-Critic with Positive Advantages.](http://arxiv.org/abs/2306.01460) | 本研究提出了一种新的On-Policy深度强化学习算法，该算法通过在保守值估计和谨慎探索方面的明确整合来解决了当前算法不能充分考虑谨慎交互的问题。 |
| [^126] | [DyGen: Learning from Noisy Labels via Dynamics-Enhanced Generative Modeling.](http://arxiv.org/abs/2305.19395) | DyGen是一个动态增强的生成模型，使用嵌入空间中的动态模式可以改善从噪声标签中学习的精度，同时使用共规正则化机制来最小化潜在噪声标签和先验的影响，展示了最先进的性能。 |
| [^127] | [DIVA: A Dirichlet Process Based Incremental Deep Clustering Algorithm via Variational Auto-Encoder.](http://arxiv.org/abs/2305.14067) | 本文提出了DIVA算法，一个基于狄利克雷过程的增量深度聚类框架，利用无限混合高斯作为先验，并利用一种记忆化的在线变分推理方法实现簇的动态适应移动，而不需要先知道特征的数量。该算法表现优越，特别是在增量特征的情况下。 |
| [^128] | [Estimation Beyond Data Reweighting: Kernel Method of Moments.](http://arxiv.org/abs/2305.10898) | 本论文提出了一种新的核矩法估计器，称为KMM，其用于超越数据重新加权的矩方法模型，解除了关于使用 $\varphi$-散度相关的限制。 |
| [^129] | [Catch-Up Distillation: You Only Need to Train Once for Accelerating Sampling.](http://arxiv.org/abs/2305.10769) | 本文提出了一种名为“追赶蒸馏”的方法，通过调整传统采样算法，让速度估计模型的当前时刻输出与其先前时刻输出和地面真实标签对齐，从而实现只需一次训练便能加速采样的效果。 |
| [^130] | [Discovery of Optimal Quantum Error Correcting Codes via Reinforcement Learning.](http://arxiv.org/abs/2305.06378) | 该论文介绍了一种使用强化学习策略来发掘最佳量子纠错码的方法，该方法可以训练代理以最大化编码距离或最小化在偏置Pauli噪声下的逻辑错误概率。作者证明，与其他CSS代码相比，他们可以限制量子比特数量并获得优越的结果。 |
| [^131] | [HybridNet: Dual-Branch Fusion of Geometrical and Topological Views for VLSI Congestion Prediction.](http://arxiv.org/abs/2305.05374) | 本文提出了HybridNet，一种基于几何与拓扑视角的VLSI阻塞预测的双分支融合网络，通过在网络结构中做出几个关键设计，充分综合电路的拓扑与几何特征，相较于以往方法取得了10.9％的提高。 |
| [^132] | [DELTA: Dynamic Embedding Learning with Truncated Conscious Attention for CTR Prediction.](http://arxiv.org/abs/2305.04891) | 该论文提出了一种名为DELTA的CTR模型，使用截断意识注意力进行动态嵌入学习，有效地解决了上下文中无效和冗余特征的问题。 |
| [^133] | [PGB: A PubMed Graph Benchmark for Heterogeneous Network Representation Learning.](http://arxiv.org/abs/2305.02691) | 介绍了一个基于PubMed数据库的PGB基准数据集，用于评估生物医学文献的异构图嵌入。该数据集包含丰富的元数据和来自不同数据集的21个系统性评价主题的评估任务。 |
| [^134] | [FormNetV2: Multimodal Graph Contrastive Learning for Form Document Information Extraction.](http://arxiv.org/abs/2305.02549) | 该论文提出了一种用于表格文档信息提取的多模态图形对比学习策略（FormNetV2），该方法能够统一所有模态的自监督预训练到一个损失中，并在多个基准测试中取得了最佳表现。 |
| [^135] | [Connecting the Dots in Trustworthy Artificial Intelligence: From AI Principles, Ethics, and Key Requirements to Responsible AI Systems and Regulation.](http://arxiv.org/abs/2305.02231) | 该论文旨在探讨可信人工智能的构建，包括从法律、伦理和技术、社会角度确保其健壮性。实现真正可信的人工智能涉及到更广阔的愿景，考虑到伦理方面、风险方面、以及对七个技术需求的支持度和大局整体之关系。 |
| [^136] | [Energy-based Models as Zero-Shot Planners for Compositional Scene Rearrangement.](http://arxiv.org/abs/2304.14391) | 本文提出一种基于能量模型的零样本场景重新排列规划器，通过语言指导的空间概念来实现长指令以及在训练时从未见过的空间概念组合。本文的模型在指令导向操作基准测试以及组合指令基准测试中表现良好，优于基于语言表达的最先进方法，并且可以成功地解决之前从未见过的复杂指令和场景。 |
| [^137] | [Backpropagation-free Training of Deep Physical Neural Networks.](http://arxiv.org/abs/2304.11042) | 该论文提出了一种新方法来训练深度学习模型，不需要使用反向传播算法。该方法可以有效地应用于基于物理系统的深度学习。 |
| [^138] | [Conditional Generative Models for Learning Stochastic Processes.](http://arxiv.org/abs/2304.10382) | 提出了一种称为 C-qGAN 的框架，利用量子电路结构实现了有效的状态准备过程，可以利用该方法加速蒙特卡罗分析等算法，并将其应用于亚式期权衍生品定价的任务中。 |
| [^139] | [Collaborative Machine Learning Model Building with Families Using Co-ML.](http://arxiv.org/abs/2304.05444) | Co-ML是一个基于平板电脑的应用程序，用于协同构建ML图像分类器，可以帮助学习者在合作中发掘新的想法和方法，解决数据表现和多样性等关键问题。 |
| [^140] | [Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark.](http://arxiv.org/abs/2304.03279) | 本文介绍了 MACHIAVELLI 基准测试，用于衡量人工智能代理是否表现出马基雅维利行为，发现了最大化奖励和行为的道德性之间存在权衡，并探索了基于语言模型的方法来减轻这种权衡。 |
| [^141] | [Effective control of two-dimensional Rayleigh--B\'enard convection: invariant multi-agent reinforcement learning is all you need.](http://arxiv.org/abs/2304.02370) | 本论文应用基于不变多智能体强化学习（MARL）的深度强化学习（DRL）方法，实现了对二维瑞利-贝纳德对流的有效控制。通过利用局部性和平移不变性，MARL所获得的控制法则不仅具有较好的性能，而且具有良好的应用前景。 |
| [^142] | [Large-scale pretraining on pathological images for fine-tuning of small pathological benchmarks.](http://arxiv.org/abs/2303.15693) | 本文探讨了病理图像预训练对小规模病理基准微调的影响，通过自监督学习方法，以PTCGA200为训练集进行预训练的ResNet50在微调时表现更好，优于imagenet2012预训练。MoCov2预训练的ResNet50在PCam200和segPANDA200上表现优秀，且收敛速度更快。 |
| [^143] | [Fixed points of arbitrarily deep 1-dimensional neural networks.](http://arxiv.org/abs/2303.12814) | 本研究发现，具有对数S型激活函数的任意深度的一维神经网络最多只有三个不动点，为深度神经网络的应用和理论之间构建了一个必要的桥梁。 |
| [^144] | [eP-ALM: Efficient Perceptual Augmentation of Language Models.](http://arxiv.org/abs/2303.11403) | 本论文提出了一种用对比学习提高语言模型的感知能力的高效方法eP-ALM，可以实现视觉感知信息和文本信息的融合，同时还能在多模态基准测试上实现最先进的结果。 |
| [^145] | [Image Classifiers Leak Sensitive Attributes About Their Classes.](http://arxiv.org/abs/2303.09289) | 该论文探讨了图像分类器存在的隐私泄露问题，提出的Class Attribute Inference Attack（Caia）能够从黑盒设置中准确地推断出敏感属性，包括个人的发色、性别和种族，这表明在鲁棒性和隐私之间存在权衡。 |
| [^146] | [SHAP-IQ: Unified Approximation of any-order Shapley Interactions.](http://arxiv.org/abs/2303.01179) | 提出了一种名为SHAP-IQ的新方法，用于计算任意阶Shapley互动，并提供了逼近质量的理论保证和方差估计。该方法在计算成本和逼近质量方面优于现有方法。 |
| [^147] | [The Dormant Neuron Phenomenon in Deep Reinforcement Learning.](http://arxiv.org/abs/2302.12902) | 在深度强化学习中存在着休眠神经元现象，即未激活神经元数量不断增加会影响网络表达能力，作者提出了一种简单而有效的方法(ReDo)回收休眠神经元，从而在训练中提高了网络的表达能力和性能。 |
| [^148] | [Deep Offline Reinforcement Learning for Real-world Treatment Optimization Applications.](http://arxiv.org/abs/2302.07549) | 本研究介绍了一种面向现实世界的治疗优化方法，通过使用保守Q学习法(CQL)和转移取样将离线强化学习应用于回顾性医疗记录数据集。 |
| [^149] | [Concentration Bounds for Discrete Distribution Estimation in KL Divergence.](http://arxiv.org/abs/2302.06869) | 本文提供了拉普拉斯估计器的集中界限，讨论了在KL散度中离散分布估计的问题，并实现了更优的结果。 |
| [^150] | [Density-Softmax: Scalable and Calibrated Uncertainty Estimation under Distribution Shifts.](http://arxiv.org/abs/2302.06495) | 本文提出了一种称为Density-Softmax的快速确定性方法，通过将密度函数与softmax结合来提高分布变化下的校准不确定性估计，具有较高的效率和可行性 |
| [^151] | [Numerical Methods For PDEs Over Manifolds Using Spectral Physics Informed Neural Networks.](http://arxiv.org/abs/2302.05322) | 本文提出了一种新方法，使用基于谱的物理信息神经网络求解流形上的偏微分方程，并在球面和环面上得到了成功应用。对比标准架构，本文的方法表现更好。 |
| [^152] | [How to Trust Your Diffusion Model: A Convex Optimization Approach to Conformal Risk Control.](http://arxiv.org/abs/2302.03791) | 本文提出了一种风险控制预测集（RCPS）程序的推广，称为$K$-RCPS，它允许为任何扩散模型提供逐个校准的未来样本间隔，并控制相对于基准真实图像的某种风险概念，同时保持最小平均区间长度。 |
| [^153] | [FewSOME: One-Class Few Shot Anomaly Detection with Siamese Networks.](http://arxiv.org/abs/2301.06957) | 本文提出了一种基于孪生网络的深度学习一类少样本异常检测算法FewSOME，它可以在只有很少量的正常类别样本和没有异常类别样本的情况下准确地检测出异常，具有较低的复杂度和短的训练时间，并已经在多个基准数据集上表现出最先进水平的性能。 |
| [^154] | [Hand Gesture Recognition through Reflected Infrared Light Wave Signals.](http://arxiv.org/abs/2301.05955) | 该研究提出了一种低成本的基于反射红外光波信号的手势识别技术，通过收集反射光的强度变化，可以在20-35cm范围内识别不同手势，平均准确率为96％。 |
| [^155] | [Artificial Benchmark for Community Detection with Outliers (ABCD+o).](http://arxiv.org/abs/2301.05749) | 提出了一种带有离群点的人工基准社区检测图模型（ABCD+o），可以用于探索离群点的特征。 |
| [^156] | [Homophily modulates double descent generalization in graph convolution networks.](http://arxiv.org/abs/2212.13069) | 本文通过使用统计物理和随机矩阵理论的分析工具，精确地表征了简单图卷积网络在背景随机块模型上的泛化，提出了同质性在图卷积网络的泛化中的调制作用。 |
| [^157] | [Large Language Models Are Reasoning Teachers.](http://arxiv.org/abs/2212.10071) | 本文提出了Fine-tune-CoT，一种使用大型模型作为推理教师让较小模型也能进行复杂推理的方法，可以远远优于基于提示的基线方法，在多个任务上进行了评估。此外，该方法还利用教师模型的能力为每个原始样本生成多个不同的原因解释。 |
| [^158] | [Physics-Informed Neural Networks for Material Model Calibration from Full-Field Displacement Data.](http://arxiv.org/abs/2212.07723) | 本文利用物理知识的神经网络从全场位移数据中对材料模型进行校准，并展示在实际应用中优化问题的条件和重构起到了关键作用。 |
| [^159] | [Offline Policy Evaluation and Optimization under Confounding.](http://arxiv.org/abs/2211.16583) | 该论文致力于解决离线强化学习中混淆变量导致策略评估和优化存在挑战的问题，包括无法获得一致价值估计和样本复杂度的保证，作者提出了具有保证的下限算法和局部收敛的改进算法。 |
| [^160] | [Distribution Free Prediction Sets for Node Classification.](http://arxiv.org/abs/2211.14555) | 本文利用近期在设定预测下的进展，构建了预测集以适应归纳学习场景下的节点分类，证明了提供了比简单的符合预测应用更加紧致和良好校准的预测集。 |
| [^161] | [Powderworld: A Platform for Understanding Generalization via Rich Task Distributions.](http://arxiv.org/abs/2211.13051) | Powderworld是一个直接在GPU上运行的轻量级但表现力强的模拟环境，用于提供泛化性的研究平台，包括世界建模和强化学习。实验表明，增加环境的复杂性可以改善世界模型和某些强化学习代理的泛化性能。 |
| [^162] | [Knowledge Graph Contrastive Learning Based on Relation-Symmetrical Structure.](http://arxiv.org/abs/2211.10738) | 本论文提出了一种基于关系对称结构的知识图谱对比学习框架 KGE-SymCL，它能有效地提高知识图谱中实体的可区分度。 |
| [^163] | [Empirical Analysis of Model Selection for Heterogeneous Causal Effect Estimation.](http://arxiv.org/abs/2211.01939) | 本文在二元治疗条件下条件平均处理效应估计的场景中，对因果推断的模型选择问题进行了实证分析，利用最新的生成建模进展，提出了新的度量方法，证明了新的模型选择策略的有效性。 |
| [^164] | [Flatter, faster: scaling momentum for optimal speedup of SGD.](http://arxiv.org/abs/2210.16400) | 研究者们发现，将动量超参数与学习率的$2/3$次方缩放可以最大限度地加速超参数化神经网络的训练且不牺牲泛化能力。 |
| [^165] | [Hypergraph Artificial Benchmark for Community Detection (h-ABCD).](http://arxiv.org/abs/2210.15009) | 本研究提出了基于超图的人工基准社区检测模型h-ABCD，并且可以灵活地模拟不同社区的均匀性水平，是分析和调整超图社区检测算法的合成平台。 |
| [^166] | [Attention-based Modeling of Physical Systems: Improved Latent Representations.](http://arxiv.org/abs/2210.11269) | 本文提出了一种基于注意力机制的方法，用于处理不规则空间采样的数据，实验结果表明该方法在多个领域中均达到了最优结果。 |
| [^167] | [Implicit models, latent compression, intrinsic biases, and cheap lunches in community detection.](http://arxiv.org/abs/2210.09186) | 本文提出了一种将社区检测目标与其对应的隐式网络生成模型相联系的解决方案，可以计算网络在任意目标下的描述长度，比较不同算法的性能，同时还可以访问隐式模型。 |
| [^168] | [Decentralized Hyper-Gradient Computation over Time-Varying Directed Networks.](http://arxiv.org/abs/2210.02129) | 本文提出了一种基于时变有向网络的分散式超梯度计算方法，避免了静态无向网络通信 Hessian 矩阵导致的高通信成本和无法使用时变有向网络优势的问题。 |
| [^169] | [End-to-End Label Uncertainty Modeling in Speech Emotion Recognition using Bayesian Neural Networks and Label Distribution Learning.](http://arxiv.org/abs/2209.15449) | 本文提出了一种端到端的贝叶斯神经网络，使用学生t分布来模拟注释分布，并通过推导相应的KL散度损失进行训练，以捕捉情感识别中基于主观性的标签不确定性。 |
| [^170] | [Enforcing Hard Constraints with Soft Barriers: Safe Reinforcement Learning in Unknown Stochastic Environments.](http://arxiv.org/abs/2209.15090) | 在未知环境下，通过软障碍函数强制实施硬安全约束，提出了一种安全强化学习方法，可以同时学习环境和优化控制策略。 |
| [^171] | [Conjugate Natural Selection.](http://arxiv.org/abs/2208.13898) | 本文证明了Fisher-Rao自然梯度下降最佳逼近连续时间复制子方程，这一对应关系称为“共轭自然选择”，为进化计算提供了替代方法，同时提供了连续贝叶斯推理的最佳近似。 |
| [^172] | [HELP ME THINK: A Simple Prompting Strategy for Non-experts to Create Customized Content with Models.](http://arxiv.org/abs/2208.08232) | HELP ME THINK是一种帮助非专家用户创建定制化内容的简单提示策略，利用GPT3提出相关问题和利用用户答案执行任务，适用于各种需要重要思考的任务。 |
| [^173] | [How to Reuse and Compose Knowledge for a Lifetime of Tasks: A Survey on Continual Learning and Functional Composition.](http://arxiv.org/abs/2207.07730) | 本篇综述介绍了连续学习和功能组合方法的研究现状和未来联系，以实现人工智能在解决新问题时可以不断积累和组合知识的终身学习目标。 |
| [^174] | [Bag of Image Patch Embedding Behind the Success of Self-Supervised Learning.](http://arxiv.org/abs/2206.08954) | 这项工作发现，自监督学习方法主要学习图像块的表示，反映出它们的共同出现。学习固定尺度图像块的表示，并将局部表示聚合为图像表示，称为BagSSL，能够实现与基线方法相似甚至更好的结果。 |
| [^175] | [Counting Markov Equivalent Directed Acyclic Graphs Consistent with Background Knowledge.](http://arxiv.org/abs/2206.06744) | 本文研究如何在给定一些边的方向已确定的情况下，计算马尔科夫等价类中的有向无环图数量，并且提出了一个计数算法，该算法运行时间受到一个多项式的约束。 |
| [^176] | [Partial Identification of Dose Responses with Hidden Confounders.](http://arxiv.org/abs/2204.11206) | 本论文提出了一种新方法，用于界定无法通过点估计进行识别的连续值处理效应估计范围，以解决存在隐藏混淆因素的问题。 |
| [^177] | [Exact Solutions of a Deep Linear Network.](http://arxiv.org/abs/2202.04777) | 本研究找到了带权重衰减和随机神经元的深度线性网络全局最小值的解析表达式，结果表明权重衰减与模型架构的强烈交互作用会在多于1个隐藏层的网络中创建不良极小值，并表明常见的深度学习初始化方法无法在一般情况下缓解神经网络的优化问题。 |
| [^178] | [Factor-augmented tree ensembles.](http://arxiv.org/abs/2111.14000) | 本文提出了一种因子增强的树集合方法，能够处理多种不规则预测变量，为处理宏观金融问题提供一种可靠的方法。 |
| [^179] | [Spatio-Temporal Joint Graph Convolutional Networks for Traffic Forecasting.](http://arxiv.org/abs/2111.13684) | 本文提出了一种称为STJGCN的方法，用于在多个未来时间步长上准确预测道路网络上的交通流量。该方法构建了预定义的和自适应的时空联合图以及在STJGs上执行图卷积运算，以提取时空特征并进行多步预测，并已在两个真实数据集上取得了优于现有最先进方法的结果。 |
| [^180] | [DAPPER: Label-Free Performance Estimation after Personalization for Heterogeneous Mobile Sensing.](http://arxiv.org/abs/2111.11053) | 提出了一种称为DAPPER的方法，可以在没有标记的情况下估计目标域中的适应性能，从而解决了移动感知中的域漂移问题，并在实验中展示了出色的性能。 |
| [^181] | [An extended physics informed neural network for preliminary analysis of parametric optimal control problems.](http://arxiv.org/abs/2110.13530) | 本研究提出了一种基于物理信息的学习方法，用于快速模拟参数化现象。该方法包括在损失函数、输入特征和神经网络结构中利用物理信息，可应用于多个方程和最优控制问题。 |
| [^182] | [Towards Open-World Feature Extrapolation: An Inductive Graph Learning Approach.](http://arxiv.org/abs/2110.04514) | 本文提出了一种采用图表示和学习的方法，解决了处理开放世界特征外推问题的挑战，同时使用两种训练策略来实现对新特征的外推，并缓解特征层面的过拟合问题。 |
| [^183] | [Solving the Dirichlet problem for the Monge-Amp\`ere equation using neural networks.](http://arxiv.org/abs/2110.03310) | 本文应用神经网络解决 Monge-Amp\`ere 方程的迪利克雷问题，使用深度凸输入神经网络的假设可以用来找到唯一的凸解，方法对奇异点、不连续点和源函数中的噪声具有鲁棒性，在高维情况下也能表现良好。 |
| [^184] | [Stochastic coordinate transformations with applications to robust machine learning.](http://arxiv.org/abs/2110.01729) | 本文提出了一种利用随机坐标变换进行异常检测的新方法，该方法通过层级张量积展开来逼近随机过程，并通过训练机器学习分类器对投影系数进行检测。在基准数据集上的实验表明，该方法胜过现有的最先进方法。 |
| [^185] | [WildWood: a new Random Forest algorithm.](http://arxiv.org/abs/2109.08010) | WildWood是一种新的随机森林算法，使用指数权重聚合包外样本以改进预测，并通过使用直方图策略加速分裂查找，具有比标准RF和极限梯度提升算法更快和更具竞争力的性能。 |
| [^186] | [Bandit Quickest Changepoint Detection.](http://arxiv.org/abs/2107.10492) | 基于赌博机的方法可以有效平衡探索和利用，实现对一组传感器的最快变点检测，从而节省资源和成本。 |
| [^187] | [Learning distinct features helps, provably.](http://arxiv.org/abs/2106.06012) | 学习非冗余的不同特征对神经网络的性能有帮助，具有更多不同特征的隐藏层单元可以导致更好的泛化能力。 |
| [^188] | [Kernel Thinning.](http://arxiv.org/abs/2105.05842) | 核细化是一种更有效的压缩分布的方法，它可以将$n$点近似的分布压缩到具有可比较最坏积分误差的$\sqrt{n}$点近似，其亚指数保证类似于在$[0,1]^d$上均匀$\mathbb{P}$的经典准蒙特卡罗误差率，但适用于$\mathbb{R}^d$上的一般分布。 |
| [^189] | [Domain Adaptation with Incomplete Target Domains.](http://arxiv.org/abs/2012.01606) | 本研究提出了一种基于不完整数据插补的对抗网络（IDIAN）模型，用于解决具有部分观察到的数据的不完整目标领域下的域自适应问题，实验结果表明该模型在跨域和实际适应任务中都具有良好的表现。 |
| [^190] | [When Does Uncertainty Matter?: Understanding the Impact of Predictive Uncertainty in ML Assisted Decision Making.](http://arxiv.org/abs/2011.06167) | 本研究通过用户研究探讨了机器学习辅助决策中展示预测不确定性的有效性，结果表明不论后验预测分布的形状和方差如何，展示后验预测分布都会使模型预测产生更小的分歧。 |
| [^191] | [Adaptive Stopping Rule for Kernel-based Gradient Descent Algorithms.](http://arxiv.org/abs/2001.02879) | 本文提出了一种自适应的内核梯度下降算法的停止准则，使用经验有效维度来量化增量并推导出可执行的提前停止策略。通过使用积分算子方法得出证明，规则具有优化学习速率的最优性，并且提出的停止策略具有计算上的优势。 |
| [^192] | [A Trio Neural Model for Dynamic Entity Relatedness Ranking.](http://arxiv.org/abs/1808.08316) | 这篇论文提出了一种基于神经网络的方法，通过动态评估实体相关性，利用集体注意作为监督，能学习到丰富而不同的实体表示，能在大规模数据集上比竞争基线获得更好的结果。 |
| [^193] | [Multiple Models for Recommending Temporal Aspects of Entities.](http://arxiv.org/abs/1803.07890) | 本研究提出了一种新颖的基于事件中心的集合排名方法，该方法考虑到时间动态性，能够推荐最相关的实体方面，提高搜索体验。 |
| [^194] | [Model selection of polynomial kernel regression.](http://arxiv.org/abs/1503.02143) | 本文提出了一种新的模型选择策略，揭示了在多项式核回归中正则化项的作用只是为了规避核矩阵的“病态”，从而可选不加正则化项，并设计了一种有效的学习算法。 |
| [^195] | [Does generalization performance of $l^q$ regularization learning depend on $q$? A negative example.](http://arxiv.org/abs/1307.6616) | 该研究表明，在特定的核函数类中，$l^{q}$ 正则化学习在不同阶数 $q$ 下都具有相似的泛化误差界限。 |

# 详细

[^1]: GeneCIS：一种通用条件图像相似度的基准测试

    GeneCIS: A Benchmark for General Conditional Image Similarity. (arXiv:2306.07969v1 [cs.CV])

    [http://arxiv.org/abs/2306.07969](http://arxiv.org/abs/2306.07969)

    GeneCIS基准测试衡量模型适应各种相似性条件的能力，并且基准测试的表现与ImageNet的准确性弱相关，仅简单扩展现有方法并不行。

    

    我们认为存在许多“相似性”的概念，而模型（如人类）应该能够动态地适应这些概念。这与大多数表示学习方法（受监督或自监督）不同，它们学习一个固定的嵌入函数，因此隐含地假定了单一的相似性概念。 在本文中，我们提出了GeneCIS（“创世纪”）基准测试，该测试衡量了模型适应各种相似性条件的能力。扩展之前的工作，我们的基准测试只设计用于零样本评估，因此考虑了开放集的相似性条件。我们发现，强大的CLIP模型的基线在GeneCIS上较为困难，并且基准测试的表现仅与ImageNet的准确性弱相关，这表明简单地扩展现有方法并不是有成果的。我们进一步

    We argue that there are many notions of 'similarity' and that models, like humans, should be able to adapt to these dynamically. This contrasts with most representation learning methods, supervised or self-supervised, which learn a fixed embedding function and hence implicitly assume a single notion of similarity. For instance, models trained on ImageNet are biased towards object categories, while a user might prefer the model to focus on colors, textures or specific elements in the scene. In this paper, we propose the GeneCIS ('genesis') benchmark, which measures models' ability to adapt to a range of similarity conditions. Extending prior work, our benchmark is designed for zero-shot evaluation only, and hence considers an open-set of similarity conditions. We find that baselines from powerful CLIP models struggle on GeneCIS and that performance on the benchmark is only weakly correlated with ImageNet accuracy, suggesting that simply scaling existing methods is not fruitful. We furth
    
[^2]: 一通适用于参数高效微调的通用LoRA算法

    One-for-All: Generalized LoRA for Parameter-Efficient Fine-tuning. (arXiv:2306.07967v1 [cs.LG])

    [http://arxiv.org/abs/2306.07967](http://arxiv.org/abs/2306.07967)

    本论文提出了一种通用的参数高效微调算法——GLoRA，该算法通过广义提示模块、模块化的适配器层和可扩展的结构搜索具有了对不同任务和数据集的更高灵活性和适应性，并在各类基准测试中表现出了优异的精度。

    

    本文提出了一种先进的通用参数高效微调任务算法——广义LoRA（GLoRA）。GLoRA 使用广义提示模块来优化预训练模型权重和调整中间激活状态，从而提供了更多的灵活性和跨异构任务和数据集的能力。此外，GLoRA 通过使用可扩展的、模块化的、层次的结构搜索来帮助有效的参数调整，学习每个层的适配器，从一个统一的数学公式起源，GLoRA 具有强大的迁移学习、少样本学习和领域泛化能力，通过权重和激活状态上的附加维度来适应新任务。综合实验表明，在自然、专业和结构化基准测试中，GLoRA 的精度优于所有先前的方法，且在各种数据集上使用更少的参数和计算达到了优越的精度。此外，我们的结构重新设计可以大幅减少运算时间和模型大小。

    We present Generalized LoRA (GLoRA), an advanced approach for universal parameter-efficient fine-tuning tasks. Enhancing Low-Rank Adaptation (LoRA), GLoRA employs a generalized prompt module to optimize pre-trained model weights and adjust intermediate activations, providing more flexibility and capability across diverse tasks and datasets. Moreover, GLoRA facilitates efficient parameter adaptation by employing a scalable, modular, layer-wise structure search that learns individual adapter of each layer. Originating from a unified mathematical formulation, GLoRA exhibits strong transfer learning, few-shot learning and domain generalization abilities, as it adjusts to new tasks through additional dimensions on weights and activations. Comprehensive experiments demonstrate that GLoRA outperforms all previous methods in natural, specialized, and structured benchmarks, achieving superior accuracy with fewer parameters and computations on various datasets. Furthermore, our structural re-par
    
[^3]: 与学习导向的车辆运动规划的误解告别

    Parting with Misconceptions about Learning-based Vehicle Motion Planning. (arXiv:2306.07962v1 [cs.RO])

    [http://arxiv.org/abs/2306.07962](http://arxiv.org/abs/2306.07962)

    该论文提出了nuPlan，一个大规模真实世界数据集和评估方案，针对精确的短期规划和长期目标预测。证实了现有系统难以同时满足两个要求。最终提出一个非常简单高效的规划器。

    

    nuPlan的发布标志着车辆运动规划研究的一个新时代，提供了第一个需要精确的短期规划和长期目标预测的大规模真实世界数据集和评估方案。现有系统难以同时满足两个要求。实际上，我们发现这些任务存在根本上的不对齐问题，应该分别进行解决。我们进一步评估了领域内闭环规划的现状，揭示了学习为基础的方法在复杂的真实场景中的局限性，以及选择通过车道图搜索算法的简单基于规则的先验项（例如中心线选择）的价值。更令人惊讶的是，在开环子任务中，我们观察到当仅使用这个中心线作为场景上下文时（即忽略所有有关地图和其他代理的信息）可以获得最佳结果。结合这些见解，我们提出了一个非常简单高效的规划器，它的表现优于大量竞争对手。

    The release of nuPlan marks a new era in vehicle motion planning research, offering the first large-scale real-world dataset and evaluation schemes requiring both precise short-term planning and long-horizon ego-forecasting. Existing systems struggle to simultaneously meet both requirements. Indeed, we find that these tasks are fundamentally misaligned and should be addressed independently. We further assess the current state of closed-loop planning in the field, revealing the limitations of learning-based methods in complex real-world scenarios and the value of simple rule-based priors such as centerline selection through lane graph search algorithms. More surprisingly, for the open-loop sub-task, we observe that the best results are achieved when using only this centerline as scene context (\ie, ignoring all information regarding the map and other agents). Combining these insights, we propose an extremely simple and efficient planner which outperforms an extensive set of competitors,
    
[^4]: 通过不偏微分对抗复杂密度生成，基于互联马尔科夫链不偏微分优化 MH 采样方法

    Differentiating Metropolis-Hastings to Optimize Intractable Densities. (arXiv:2306.07961v1 [stat.ML])

    [http://arxiv.org/abs/2306.07961](http://arxiv.org/abs/2306.07961)

    本文通过基于互联马尔科夫链的不偏微分，开发出一种无偏、低方差和自动的方法对复杂密度进行生成，从而实现对 MH 采样器的优化。

    

    在概率模型推理中，目标密度函数通常变得难以计算，需要使用 Monte Carlo 计算。本文开发了一种不偏微分 Metropolis-Hastings 采样器的方法，使我们可以通过概率推理来进行微分。通过将随机微分的最新进展与 Markov 链耦合方法相结合，可以实现无偏，低方差和自动的程序。这使我们能够将基于梯度的优化应用于由于繁琐的目标密度导致期望的情况下。我们通过在高斯混合模型中找到一个模棱两可的观察和在 Ising 模型中最大化比热来演示了我们的方法。

    When performing inference on probabilistic models, target densities often become intractable, necessitating the use of Monte Carlo samplers. We develop a methodology for unbiased differentiation of the Metropolis-Hastings sampler, allowing us to differentiate through probabilistic inference. By fusing recent advances in stochastic differentiation with Markov chain coupling schemes, the procedure can be made unbiased, low-variance, and automatic. This allows us to apply gradient-based optimization to objectives expressed as expectations over intractable target densities. We demonstrate our approach by finding an ambiguous observation in a Gaussian mixture model and by maximizing the specific heat in an Ising model.
    
[^5]: 异构设置下的隐私保护贝叶斯联邦学习

    Privacy Preserving Bayesian Federated Learning in Heterogeneous Settings. (arXiv:2306.07959v1 [cs.LG])

    [http://arxiv.org/abs/2306.07959](http://arxiv.org/abs/2306.07959)

    本文提出了一种基于贝叶斯框架的联邦学习方法，可以训练定制本地模型以同时满足异构设置、不确定性量化和数据隐私约束，并通过先验分布来促进异构客户端之间的合作。

    

    在许多联邦学习（FL）的实际应用中，客户端的数据和计算资源高度异构，因此强制为每个客户端施加相同的模型架构非常受限。此外，对于拥有受限本地数据的客户端，需要不确定性量化和数据隐私约束的需求通常特别增强。本文提出了一个统一的FL框架，以同时解决所有这些约束和关注点，基于训练定制本地贝叶斯模型，即使在没有大量本地数据的情况下也能很好地学习。贝叶斯框架提供了一种自然的方式来以先验分布的形式融入监督。我们在网络的功能（输出）空间中使用先验来促进异构客户端之间的合作。此外，本框架还提供了形式化的差分隐私保证。在标准FL数据集上的实验表明，我们的方法优于策略。

    In several practical applications of federated learning (FL), the clients are highly heterogeneous in terms of both their data and compute resources, and therefore enforcing the same model architecture for each client is very limiting. Moreover, the need for uncertainty quantification and data privacy constraints are often particularly amplified for clients that have limited local data. This paper presents a unified FL framework to simultaneously address all these constraints and concerns, based on training customized local Bayesian models that learn well even in the absence of large local datasets. A Bayesian framework provides a natural way of incorporating supervision in the form of prior distributions. We use priors in the functional (output) space of the networks to facilitate collaboration across heterogeneous clients. Moreover, formal differential privacy guarantees are provided for this framework. Experiments on standard FL datasets demonstrate that our approach outperforms str
    
[^6]: 深度学习驾驶模型中的偏见问题

    Hidden Biases of End-to-End Driving Models. (arXiv:2306.07957v1 [cs.CV])

    [http://arxiv.org/abs/2306.07957](http://arxiv.org/abs/2306.07957)

    端到端驾驶模型存在偏见问题，并引入了次要组件的更改。本文针对目前多数最先进的方法中所存在的两种偏见进行了研究，并提出了合理的替代方法。在此基础上，开发了TF ++，在CARLA测试中表现优异。

    

    最近，端到端的驾驶系统在CARLA测试中取得了快速进展。然而，即使在主要贡献的基础上，这些系统也会引入对次要系统组件的改变。因此，系统的改进源并不清楚。我们发现，在几乎所有最先进的方法中都存在两种偏见，这些偏见对于在CARLA上观察到的进展至关重要：(1) 通过对目标点跟随的强归纳偏见来进行横向恢复，(2) 通过多模态航路点预测的纵向平均来减速。我们研究了这些偏见的缺点，并确定了合理的替代方法。通过结合我们的见解，我们开发了TF ++，一种简单的端到端方法，在Longest6和LAV基准测试中排名第一，在Longest6上比最佳前期工作提高了14个驾驶分数。

    End-to-end driving systems have recently made rapid progress, in particular on CARLA. Independent of their major contribution, they introduce changes to minor system components. Consequently, the source of improvements is unclear. We identify two biases that recur in nearly all state-of-the-art methods and are critical for the observed progress on CARLA: (1) lateral recovery via a strong inductive bias towards target point following, and (2) longitudinal averaging of multimodal waypoint predictions for slowing down. We investigate the drawbacks of these biases and identify principled alternatives. By incorporating our insights, we develop TF++, a simple end-to-end method that ranks first on the Longest6 and LAV benchmarks, gaining 14 driving score over the best prior work on Longest6.
    
[^7]: MOFI: 从含噪实体标注的图像中学习图像表示

    MOFI: Learning Image Representations from Noisy Entity Annotated Images. (arXiv:2306.07952v1 [cs.CV])

    [http://arxiv.org/abs/2306.07952](http://arxiv.org/abs/2306.07952)

    MOFI 提出了一种新的方法，自动从含噪图像文本对中为图像指定实体标签，创建了一个新的大规模数据集 I2E，通过研究不同的训练配方，学习到了能够有效学习图像表示的模型。

    

    本文提出了一种新的视觉基础模型 MOFI，旨在从含噪实体标注的图像中学习图像表示。MOFI 与以往的工作有两点不同：（i）预训练数据，（ii）训练配方。在数据方面，我们引入了一种新方法，自动从含噪图像文本对中为图像指定实体标签。我们使用命名实体识别模型从 alt-text 中提取实体，然后使用 CLIP 模型选择正确的实体作为图像的标签。这种方法简单易行，不需要昂贵的人工注释，并且可以轻松扩展到从 web 上挖掘的数十亿个图像文本对。通过这种方法，我们创建了 Image-to-Entities（I2E）这一新的大规模数据集，其中包含 10 亿张图像和 200 万个不同的实体，涵盖了野外丰富的视觉概念。基于 I2E 数据集，我们研究了不同的训练配方，包括有监督的预训练、对比度预训练。

    We present MOFI, a new vision foundation model designed to learn image representations from noisy entity annotated images. MOFI differs from previous work in two key aspects: ($i$) pre-training data, and ($ii$) training recipe. Regarding data, we introduce a new approach to automatically assign entity labels to images from noisy image-text pairs. Our approach involves employing a named entity recognition model to extract entities from the alt-text, and then using a CLIP model to select the correct entities as labels of the paired image. The approach is simple, does not require costly human annotation, and can be readily scaled up to billions of image-text pairs mined from the web. Through this method, we have created Image-to-Entities (I2E), a new large-scale dataset with 1 billion images and 2 million distinct entities, covering rich visual concepts in the wild. Building upon the I2E dataset, we study different training recipes, including supervised pre-training, contrastive pre-train
    
[^8]: 非峰值CTC提升端到端自动语音识别中词时分类器的帧级分类器

    Improving Frame-level Classifier for Word Timings with Non-peaky CTC in End-to-End Automatic Speech Recognition. (arXiv:2306.07949v1 [eess.AS])

    [http://arxiv.org/abs/2306.07949](http://arxiv.org/abs/2306.07949)

    本文提出通过在连接时序分类（CTC）损失中引入标签先验，并将低层Mel-scale滤波器和高层ASR编码器输出组合作为输入特征来改进E2E系统中用于词时的帧级分类器，实现了更高的词时准确性。

    

    端到端系统已经显示出与混合系统相当的自动语音识别（ASR）性能。作为ASR的副产品，词的定时对于许多应用程序至关重要，特别是字幕和计算机辅助发音训练。本文通过在连接时序分类（CTC）损失中引入标签先验，并将低层Mel-scale滤波器和高层ASR编码器输出组合作为输入特征，改进了E2E系统中用于词时的帧级分类器。在内部汉语语料库上，所提出的方法相比混合系统在单词时序准确性度量上实现了 95.68% / 94.18% 的性能，而且在7种语言的指标上绝对提高了4.80% / 8.02% 的分数，超越了先前的E2E方法。此外，我们通过延迟CTC峰值和基于帧的知识蒸馏进一步提高了词时准确性，但仅在LibriSpeech上进行了实验。

    End-to-end (E2E) systems have shown comparable performance to hybrid systems for automatic speech recognition (ASR). Word timings, as a by-product of ASR, are essential in many applications, especially for subtitling and computer-aided pronunciation training. In this paper, we improve the frame-level classifier for word timings in E2E system by introducing label priors in connectionist temporal classification (CTC) loss, which is adopted from prior works, and combining low-level Mel-scale filter banks with high-level ASR encoder output as input feature. On the internal Chinese corpus, the proposed method achieves 95.68%/94.18% compared to the hybrid system 93.0%/90.22% on the word timing accuracy metrics. It also surpass a previous E2E approach with an absolute increase of 4.80%/8.02% on the metrics on 7 languages. In addition, we further improve word timing accuracy by delaying CTC peaks with frame-wise knowledge distillation, though only experimenting on LibriSpeech.
    
[^9]: 上下文随机块模型中的最优推断

    Optimal Inference in Contextual Stochastic Block Models. (arXiv:2306.07948v1 [cs.SI])

    [http://arxiv.org/abs/2306.07948](http://arxiv.org/abs/2306.07948)

    本论文提出了一种基于信念传播的算法，用于半监督上下文随机块模型(cSBM)的推断问题。研究发现，相比于现有的图神经网络结构，这种算法达到的准确性更高，同时可用于建立性能基准。

    

    上下文随机块模型(cSBM)被提出来对具有节点标签相关性的属性图进行无监督社区检测，其中图形和高维节点信息都与节点标签相关。在图上机器学习的背景下，cSBM已被广泛用作合成数据集，用于评估半监督节点分类的图神经网络(GNN)的性能。

    The contextual stochastic block model (cSBM) was proposed for unsupervised community detection on attributed graphs where both the graph and the high-dimensional node information correlate with node labels. In the context of machine learning on graphs, the cSBM has been widely used as a synthetic dataset for evaluating the performance of graph-neural networks (GNNs) for semi-supervised node classification. We consider a probabilistic Bayes-optimal formulation of the inference problem and we derive a belief-propagation-based algorithm for the semi-supervised cSBM; we conjecture it is optimal in the considered setting and we provide its implementation. We show that there can be a considerable gap between the accuracy reached by this algorithm and the performance of the GNN architectures proposed in the literature. This suggests that the cSBM, along with the comparison to the performance of the optimal algorithm, readily accessible via our implementation, can be instrumental in the develo
    
[^10]: GPT-Calls: 通过生成合成对话提升通话分割和标记能力的大型语言模型

    GPT-Calls: Enhancing Call Segmentation and Tagging by Generating Synthetic Conversations via Large Language Models. (arXiv:2306.07941v1 [cs.CL])

    [http://arxiv.org/abs/2306.07941](http://arxiv.org/abs/2306.07941)

    本文提出了一种名为GPT-Calls的方法，通过使用大型语言模型生成合成对话，以提高电话录音的分割和标记能力。该方法分为离线和在线两个阶段，离线阶段仅应用一次，对给定的主题列表生成合成句子分布并提取锚向量，在线阶段则针对每个通话单独应用，并对转录的对话与离线阶段找到的主题锚定进行相似性评分。时间域分析被应用于相似性得分中，以将话语分组并将其标记为所属主题。

    

    电话录音的转录在销售、客户服务、医疗保健和执法等各个领域具有重要价值。然而，分析这些录音对话可以是一项艰巨而耗时的任务，特别是当处理长时间或多方面的对话时。本文提出了一种新颖的方法，GPT-distilled Calls Segmentation and Tagging (GPT-Calls)，以实现高效和准确的通话分段和主题提取。GPT-Calls由离线和在线两个阶段组成，其中离线阶段针对给定的主题列表仅应用一次，使用GPT模型生成每个主题的合成句子分布并提取锚向量。在线阶段针对每个通话单独应用，并对转录的对话与离线阶段找到的主题锚定进行相似性评分。然后，时间域分析被应用于相似性得分中，将话语分组并将其标记为...

    Transcriptions of phone calls are of significant value across diverse fields, such as sales, customer service, healthcare, and law enforcement. Nevertheless, the analysis of these recorded conversations can be an arduous and time-intensive process, especially when dealing with extended or multifaceted dialogues. In this work, we propose a novel method, GPT-distilled Calls Segmentation and Tagging (GPT-Calls), for efficient and accurate call segmentation and topic extraction. GPT-Calls is composed of offline and online phases. The offline phase is applied once to a given list of topics and involves generating a distribution of synthetic sentences for each topic using a GPT model and extracting anchor vectors. The online phase is applied to every call separately and scores the similarity between the transcripted conversation and the topic anchors found in the offline phase. Then, time domain analysis is applied to the similarity scores to group utterances into segments and tag them with 
    
[^11]: 深度混合：重建网络流行病的演化

    Deep Demixing: Reconstructing the Evolution of Network Epidemics. (arXiv:2306.07938v1 [cs.SI])

    [http://arxiv.org/abs/2306.07938](http://arxiv.org/abs/2306.07938)

    DDmix模型是一个可以从部分或聚合的时间信息中重构在网络上演变的流行病的图形自编码器，它通过数据驱动的方法来克服模型意识的缺乏，并在通用性上得到了凸显。

    

    本文提出了一种称为深度混合（DDmix）模型的图形自编码器，可从部分或聚合的时间信息中重构在网络上演变的流行病。假设已知网络拓扑而不知道流行病模型，我们的目标是估计疾病传播的完整路径。利用数据驱动的方法来克服模型意识的缺乏。为了解决这个反问题，提出了DDmix作为图形条件变分自编码器，它从过去的流行病蔓延中进行训练。DDmix试图在其潜在空间中捕捉基本的（未知）传播动态方面。通过使用在合成和现实世界中模拟的流行病传播的网络，将DDmix的精度与多种（非图形感知的）学习算法进行比较。DDmix的通用性在不同类型的网络中得到了凸显。最后，我们展示了我们提出的方法的一个简单的后处理扩展，可以帮助识别超级传播者。

    We propose the deep demixing (DDmix) model, a graph autoencoder that can reconstruct epidemics evolving over networks from partial or aggregated temporal information. Assuming knowledge of the network topology but not of the epidemic model, our goal is to estimate the complete propagation path of a disease spread. A data-driven approach is leveraged to overcome the lack of model awareness. To solve this inverse problem, DDmix is proposed as a graph conditional variational autoencoder that is trained from past epidemic spreads. DDmix seeks to capture key aspects of the underlying (unknown) spreading dynamics in its latent space. Using epidemic spreads simulated in synthetic and real-world networks, we demonstrate the accuracy of DDmix by comparing it with multiple (non-graph-aware) learning algorithms. The generalizability of DDmix is highlighted across different types of networks. Finally, we showcase that a simple post-processing extension of our proposed method can help identify supe
    
[^12]: 多模态表示学习用于社交媒体文章位置推断

    Multi-modal Representation Learning for Social Post Location Inference. (arXiv:2306.07935v1 [cs.CL])

    [http://arxiv.org/abs/2306.07935](http://arxiv.org/abs/2306.07935)

    本文提出了多模态表示学习框架（MRLF），用于将社交媒体文章的不同模态融合起来进行位置推断。该方法集成了一个多头注意力机制以增强位置显著信息提取，相对于单一领域的方法显著提高位置推断的准确性。

    

    通过社交媒体文章来推断地理位置对于许多实际的基于位置的应用程序非常重要，例如产品营销、兴趣点推荐及COVID-19的追踪。本研究从Instagram收集了带有图像、文本和标签的实际社交媒体文章数据集，提出了一种新颖的多模态表示学习框架（MRLF），它能够将社交媒体文章的不同模态融合起来进行位置推断。MRLF集成了一个多头注意力机制以增强位置显著信息提取，同时相对于单一领域的方法显著提高位置推断的准确性。为了克服用户生成的文本内容的噪声，我们引入了一种新颖的基于注意力的字符感知模块。

    Inferring geographic locations via social posts is essential for many practical location-based applications such as product marketing, point-of-interest recommendation, and infector tracking for COVID-19. Unlike image-based location retrieval or social-post text embedding-based location inference, the combined effect of multi-modal information (i.e., post images, text, and hashtags) for social post positioning receives less attention. In this work, we collect real datasets of social posts with images, texts, and hashtags from Instagram and propose a novel Multi-modal Representation Learning Framework (MRLF) capable of fusing different modalities of social posts for location inference. MRLF integrates a multi-head attention mechanism to enhance location-salient information extraction while significantly improving location inference compared with single domain-based methods. To overcome the noisy user-generated textual content, we introduce a novel attention-based character-aware module 
    
[^13]: BoardgameQA: 一种用于带有矛盾信息的自然语言推理数据集

    BoardgameQA: A Dataset for Natural Language Reasoning with Contradictory Information. (arXiv:2306.07934v1 [cs.CL])

    [http://arxiv.org/abs/2306.07934](http://arxiv.org/abs/2306.07934)

    本文提出了一个用于带有矛盾信息的自然语言推理的数据集，以解决推理中不一致和矛盾信息的问题，同时提供了一种可推翻推理策略。

    

    自然语言文本的自动推理是许多潜在NLP应用和开发强大AI系统的关键要求。本文针对存在不一致和矛盾信息的推理问题提出一种解决策略，将问题形式化为经典的可推翻推理问题，并开发了一种数据集。

    Automated reasoning with unstructured natural text is a key requirement for many potential applications of NLP and for developing robust AI systems. Recently, Language Models (LMs) have demonstrated complex reasoning capacities even without any finetuning. However, existing evaluation for automated reasoning assumes access to a consistent and coherent set of information over which models reason. When reasoning in the real-world, the available information is frequently inconsistent or contradictory, and therefore models need to be equipped with a strategy to resolve such conflicts when they arise. One widely-applicable way of resolving conflicts is to impose preferences over information sources (e.g., based on source credibility or information recency) and adopt the source with higher preference. In this paper, we formulate the problem of reasoning with contradictory information guided by preferences over sources as the classical problem of defeasible reasoning, and develop a dataset ca
    
[^14]: 无监督语音识别的一种理论

    A Theory of Unsupervised Speech Recognition. (arXiv:2306.07926v1 [eess.AS])

    [http://arxiv.org/abs/2306.07926](http://arxiv.org/abs/2306.07926)

    本文提出了一个通用的理论框架，以研究无监督语音识别系统的属性，证明了各种可学习性条件和样本复杂性边界，并在合成语言的实验中得到了强有力的实证证据。

    

    无监督语音识别问题指的是从未配对的含有语音和文本的语料库中学习自动语音识别（ASR）系统。虽然存在各种算法来解决这个问题，但缺乏一个理论框架来研究其属性，并解决如超参数敏感性和训练不稳定性等问题。本文提出了一种通用的理论框架，以随机矩阵理论和神经切向核理论为基础，研究ASR-U系统的属性。这样的框架使我们能够证明ASR-U的各种可学习性条件和样本复杂性边界。针对有三类转移图的合成语言的广泛ASR-U实验为我们的理论提供了强有力的实证证据（代码可在cactuswiththoughts / UnsupASRTheory.git中获得）。

    Unsupervised speech recognition (ASR-U) is the problem of learning automatic speech recognition (ASR) systems from unpaired speech-only and text-only corpora. While various algorithms exist to solve this problem, a theoretical framework is missing from studying their properties and addressing such issues as sensitivity to hyperparameters and training instability. In this paper, we proposed a general theoretical framework to study the properties of ASR-U systems based on random matrix theory and the theory of neural tangent kernels. Such a framework allows us to prove various learnability conditions and sample complexity bounds of ASR-U. Extensive ASR-U experiments on synthetic languages with three classes of transition graphs provide strong empirical evidence for our theory (code available at cactuswiththoughts/UnsupASRTheory.git).
    
[^15]: 面向Oracle的悲观策略优化：离线上下文强化学习中的计算有效性

    Oracle-Efficient Pessimism: Offline Policy Optimization in Contextual Bandits. (arXiv:2306.07923v1 [cs.LG])

    [http://arxiv.org/abs/2306.07923](http://arxiv.org/abs/2306.07923)

    本文提出了第一个面向Oracle有效的悲观策略优化算法，它简化为监督学习，具有广泛的适用性，能够在上下文强化学习中优化策略。

    

    本文考虑在上下文强化学习中的策略优化问题，其中给定一个固定数据集的日志交互。虽然通常使用悲观惩罚来缓解分布偏移，但先前的实现并不计算有效。本文提出了第一个面向Oracle有效的悲观策略优化算法：它简化为监督学习，具有广泛的适用性。我们也得出了类似于先前工作中悲观方法的最佳统计保证。我们为离散和连续动作都实例化了我们的方法。我们在两种情况下进行了广泛的实验，显示出在各种配置中都比未正则化的策略优化更具优势。

    We consider policy optimization in contextual bandits, where one is given a fixed dataset of logged interactions. While pessimistic regularizers are typically used to mitigate distribution shift, prior implementations thereof are not computationally efficient. We present the first oracle-efficient algorithm for pessimistic policy optimization: it reduces to supervised learning, leading to broad applicability. We also obtain best-effort statistical guarantees analogous to those for pessimistic approaches in prior work. We instantiate our approach for both discrete and continuous actions. We perform extensive experiments in both settings, showing advantage over unregularized policy optimization across a wide range of configurations.
    
[^16]: 从次最优演示中进行模仿学习的技能解缠

    Skill Disentanglement for Imitation Learning from Suboptimal Demonstrations. (arXiv:2306.07919v1 [cs.LG])

    [http://arxiv.org/abs/2306.07919](http://arxiv.org/abs/2306.07919)

    该论文提出了一种名为“{\method}”的算法，可以从少量的干净演示中高效学习，同时利用包含在大量有噪声演示中的补充信息，通过在子演示级别上进行评估和模仿，将具有不同质量的操作原语编码为不同的技能来帮助机器分离出子技能。

    

    在许多序列决策任务中，模仿学习已经取得了巨大的成功，其中神经代理通过模仿收集的人类演示来进行学习。然而，现有算法通常需要大量难以收集的高质量演示。通常，需要在演示质量和数量之间做出权衡。针对这个问题，本文考虑使用次优演示进行模仿学习，其中包括一个小的干净演示集和一个大的有噪声集。一些先驱性的工作已经被提出，但它们存在许多限制，例如，假设演示在时间步骤中具有相同的最优性，并且未能提供任何关于从噪声集中学到的知识的解释。为了解决这些问题，我们提出了一个名为“{\method}”的算法，通过在子演示级别上进行评估和模仿，将具有不同质量的操作原语编码为不同的技能，帮助机器分离出子技能，得益于一种基于多目标优化的新型规则化器。我们的实验结果表明，{\method}可以有效地从少量的干净演示中学习，同时利用包含在大量有噪声演示中的补充信息。

    Imitation learning has achieved great success in many sequential decision-making tasks, in which a neural agent is learned by imitating collected human demonstrations. However, existing algorithms typically require a large number of high-quality demonstrations that are difficult and expensive to collect. Usually, a trade-off needs to be made between demonstration quality and quantity in practice. Targeting this problem, in this work we consider the imitation of sub-optimal demonstrations, with both a small clean demonstration set and a large noisy set. Some pioneering works have been proposed, but they suffer from many limitations, e.g., assuming a demonstration to be of the same optimality throughout time steps and failing to provide any interpretation w.r.t knowledge learned from the noisy set. Addressing these problems, we propose {\method} by evaluating and imitating at the sub-demonstration level, encoding action primitives of varying quality into different skills. Concretely, {\m
    
[^17]: 多维和间接观测中介因素的因果中介分析

    Causal Mediation Analysis with Multi-dimensional and Indirectly Observed Mediators. (arXiv:2306.07918v1 [cs.LG])

    [http://arxiv.org/abs/2306.07918](http://arxiv.org/abs/2306.07918)

    该论文介绍了一种能够处理复杂和间接观测的中介因素的因果中介分析框架。

    

    因果中介分析是一种强大的方法，可以在潜在结果框架内将处理的总效应分解为直接和介导效应。这在许多科学应用中很重要，可以识别出处理效应的潜在机制。然而，在许多科学应用中，中介因素未被观察到，但可能存在相关测量。为了解决这个限制，我们介绍了一种CMA框架，它可以处理基于可辨识变分自编码器（iVAE）体系结构的复杂和间接观测的中介因素。

    Causal mediation analysis (CMA) is a powerful method to dissect the total effect of a treatment into direct and mediated effects within the potential outcome framework. This is important in many scientific applications to identify the underlying mechanisms of a treatment effect. However, in many scientific applications the mediator is unobserved, but there may exist related measurements. For example, we may want to identify how changes in brain activity or structure mediate an antidepressant's effect on behavior, but we may only have access to electrophysiological or imaging brain measurements. To date, most CMA methods assume that the mediator is one-dimensional and observable, which oversimplifies such real-world scenarios. To overcome this limitation, we introduce a CMA framework that can handle complex and indirectly observed mediators based on the identifiable variational autoencoder (iVAE) architecture. We prove that the true joint distribution over observed and latent variables 
    
[^18]: 非线性潜变量层次模型的识别

    Identification of Nonlinear Latent Hierarchical Models. (arXiv:2306.07916v1 [cs.LG])

    [http://arxiv.org/abs/2306.07916](http://arxiv.org/abs/2306.07916)

    本文提出了一种方法，可以在观测变量由因果相关的潜变量生成的非线性潜变量层次因果模型中实现因果结构和潜变量的可识别性。

    

    从观测数据中识别潜变量和因果结构对于许多涉及生物数据、医学数据和非结构化数据（如图像和语言）的实际应用至关重要。然而，当观测变量由因果相关的潜变量生成，并且关系是非线性的时，这项任务可能非常具有挑战性。在这项工作中，我们研究了非线性潜变量层次因果模型的识别问题，在这种模型中，观测变量由一组因果相关的潜变量生成，有些潜变量可能没有观察到的后代。我们证明，在温和的假设下可以实现因果结构和潜变量的可识别性：对于因果结构，我们允许图中任意两个变量之间存在多条路径，这放宽了先前工作中的潜变量树假设；对于结构函数，我们没有进行参数假设，因此可以允许基因

    Identifying latent variables and causal structures from observational data is essential to many real-world applications involving biological data, medical data, and unstructured data such as images and languages. However, this task can be highly challenging, especially when observed variables are generated by causally related latent variables and the relationships are nonlinear. In this work, we investigate the identification problem for nonlinear latent hierarchical causal models in which observed variables are generated by a set of causally related latent variables, and some latent variables may not have observed children. We show that the identifiability of both causal structure and latent variables can be achieved under mild assumptions: on causal structures, we allow for the existence of multiple paths between any pair of variables in the graph, which relaxes latent tree assumptions in prior work; on structural functions, we do not make parametric assumptions, thus permitting gene
    
[^19]: Omega: 乐观EMA Gradients

    Omega: Optimistic EMA Gradients. (arXiv:2306.07905v1 [cs.LG])

    [http://arxiv.org/abs/2306.07905](http://arxiv.org/abs/2306.07905)

    Omega是一种优化算法，通过加入历史梯度EMA来减轻噪声的影响并在随机游戏上表现更佳。

    

    随着GAN和对抗性训练的进步，随机min-max优化受到了机器学习界的关注。尽管确定性状态下的博弈优化已经相当好地理解了，但在随机状态下仍存在一些问题。最近的研究表明，像乐观梯度这样的随机梯度下降-上升方法对噪声非常敏感或者会导致失败。虽然存在替代策略，但这些策略可能成本过高。我们引入了Omega，一种具有类似于乐观更新的方法，通过在其更新规则中合并历史梯度的EMA来减轻噪声的影响。我们还探讨了一种包含动量的该算法的变体。虽然我们没有提供收敛性保证，但我们在随机游戏上的实验表明，当应用于线性玩家时，Omega优于乐观梯度方法。

    Stochastic min-max optimization has gained interest in the machine learning community with the advancements in GANs and adversarial training. Although game optimization is fairly well understood in the deterministic setting, some issues persist in the stochastic regime. Recent work has shown that stochastic gradient descent-ascent methods such as the optimistic gradient are highly sensitive to noise or can fail to converge. Although alternative strategies exist, they can be prohibitively expensive. We introduce Omega, a method with optimistic-like updates that mitigates the impact of noise by incorporating an EMA of historic gradients in its update rule. We also explore a variation of this algorithm that incorporates momentum. Although we do not provide convergence guarantees, our experiments on stochastic games show that Omega outperforms the optimistic gradient method when applied to linear players.
    
[^20]: 流式赌博机的紧凑内存-遗憾下界

    Tight Memory-Regret Lower Bounds for Streaming Bandits. (arXiv:2306.07903v1 [cs.LG])

    [http://arxiv.org/abs/2306.07903](http://arxiv.org/abs/2306.07903)

    本文研究流式赌博机问题，为任何具有时间跨度T、臂数量K和经过次数B的算法建立了最紧密的最坏情况遗憾下界，同时也建立了第一个依赖于具体实例的下界。与经典的集中式随机赌博机问题相比较，流式设置下不可避免地有更多的双对数因子。

    

    本文研究了流式赌博机问题，其中学习者旨在通过处理在线到达的臂和亚线性臂内存来最小化遗憾。我们为任何具有时间跨度T、臂数量K和经过次数B的算法建立了$\Omega \left( (TB)^{\alpha} K^{1-\alpha}\right), \alpha = 2^{B} / (2^{B+1}-1)$ 紧密的最坏情况遗憾下界。结果揭示了经典集中式环境下的随机赌博机问题和具有有界臂记忆流设置之间的差异。此外，与众所周知的 $\Omega(\sqrt{KT})$ 下界相比，在允许亚线性内存的任何流式赌博机算法中，都无法避免额外的双对数因子。此外，我们还为流式赌博机建立了第一个依赖于具体实例的下界$\Omega \left(T^{1/(B+1)} \sum_{\Delta_x>0} \frac{\mu^*}{\Delta_x}\right)$。这些下界通过从遗憾最小化问题的唯一缩减中推导而来。

    In this paper, we investigate the streaming bandits problem, wherein the learner aims to minimize regret by dealing with online arriving arms and sublinear arm memory. We establish the tight worst-case regret lower bound of $\Omega \left( (TB)^{\alpha} K^{1-\alpha}\right), \alpha = 2^{B} / (2^{B+1}-1)$ for any algorithm with a time horizon $T$, number of arms $K$, and number of passes $B$. The result reveals a separation between the stochastic bandits problem in the classical centralized setting and the streaming setting with bounded arm memory. Notably, in comparison to the well-known $\Omega(\sqrt{KT})$ lower bound, an additional double logarithmic factor is unavoidable for any streaming bandits algorithm with sublinear memory permitted. Furthermore, we establish the first instance-dependent lower bound of $\Omega \left(T^{1/(B+1)} \sum_{\Delta_x>0} \frac{\mu^*}{\Delta_x}\right)$ for streaming bandits. These lower bounds are derived through a unique reduction from the regret-minimiza
    
[^21]: 通过Sharpness强健地学习单个神经元

    Robustly Learning a Single Neuron via Sharpness. (arXiv:2306.07892v1 [cs.LG])

    [http://arxiv.org/abs/2306.07892](http://arxiv.org/abs/2306.07892)

    该论文提出了一种可以对广泛激活函数族中的神经元的最优$L_2^2$误差进行近似的有效算法。

    

    我们研究了在存在对抗性标签噪声的情况下，学习单个神经元对$L_2^2$损失的问题。我们提出了一种有效的算法，对包括ReLU在内的广泛激活函数族中，近似于最优$L_2^2$误差。相较于以前的工作，我们的算法可以应用于更温和的分布假设。使我们结果可行的关键因素是与优化理论的局部误差界的新颖联系。

    We study the problem of learning a single neuron with respect to the $L_2^2$-loss in the presence of adversarial label noise. We give an efficient algorithm that, for a broad family of activations including ReLUs, approximates the optimal $L_2^2$-error within a constant factor. Our algorithm applies under much milder distributional assumptions compared to prior work. The key ingredient enabling our results is a novel connection to local error bounds from optimization theory.
    
[^22]: VISION数据集：用于基于视觉的工业检测的基准测试

    VISION Datasets: A Benchmark for Vision-based InduStrial InspectiON. (arXiv:2306.07890v1 [cs.CV])

    [http://arxiv.org/abs/2306.07890](http://arxiv.org/abs/2306.07890)

    本论文介绍了VISION数据集，这是一个多元化集合，包含14个不同工业领域检测数据集，提供了注释墨水和实例分割注释，并适用于多种检测方法。VISION数据集可以应对现实世界中工业领域检测中的挑战，并有望促进基于视觉的工业检测的发展。

    

    尽管基于视觉的检测算法取得了一定的进展，但现实世界中工业挑战——特别是数据可用性、质量和复杂的生产要求——往往仍未得到解决。我们介绍了VISION数据集，这是一个包含14个不同工业领域检测数据集的多元化集合，独具优势可以应对这些挑战。与以往的数据集不同，VISION为缺陷检测提供丰富的数据，包括所有数据分类的注释掩模，并且适用于多种检测方法。我们的数据集还具有实例分割注释功能，可以精确地识别缺陷。VISION通过提供18000张图像，包含44种缺陷类型，致力于反映出各种现实工业生产场景。通过支持VISION数据集上两个正在进行的竞赛，我们希望促进基于视觉的工业检测的进一步发展。

    Despite progress in vision-based inspection algorithms, real-world industrial challenges -- specifically in data availability, quality, and complex production requirements -- often remain under-addressed. We introduce the VISION Datasets, a diverse collection of 14 industrial inspection datasets, uniquely poised to meet these challenges. Unlike previous datasets, VISION brings versatility to defect detection, offering annotation masks across all splits and catering to various detection methodologies. Our datasets also feature instance-segmentation annotation, enabling precise defect identification. With a total of 18k images encompassing 44 defect types, VISION strives to mirror a wide range of real-world production scenarios. By supporting two ongoing challenge competitions on the VISION Datasets, we hope to foster further advancements in vision-based industrial inspection.
    
[^23]: 对称张量分解问题的对称性与临界点

    Symmetry & Critical Points for Symmetric Tensor Decompositions Problems. (arXiv:2306.07886v1 [math.OC])

    [http://arxiv.org/abs/2306.07886](http://arxiv.org/abs/2306.07886)

    本文研究了将一个实对称张量分解成秩为1项之和的非凸优化问题，得到了精确的分析估计，并发现了各种阻碍局部优化方法的几何障碍和由于对称性导致的丰富的临界点集合。

    

    本文考虑了将一个实对称张量分解成秩为1项之和的非凸优化问题。利用其丰富的对称结构，导出Puiseux级数表示的一系列临界点，并获得了关于临界值和Hessian谱的精确分析估计。这些结果揭示了各种几何障碍，阻碍了局部优化方法的使用，最后，利用一个牛顿多面体论证了固定对称性的所有临界点的完全枚举，并证明了与全局最小值的集合相比，由于对称性的存在，临界点的集合可能会显示出组合的丰富性。

    We consider the non-convex optimization problem associated with the decomposition of a real symmetric tensor into a sum of rank one terms. Use is made of the rich symmetry structure to derive Puiseux series representations of families of critical points, and so obtain precise analytic estimates on the critical values and the Hessian spectrum. The sharp results make possible an analytic characterization of various geometric obstructions to local optimization methods, revealing in particular a complex array of saddles and local minima which differ by their symmetry, structure and analytic properties. A desirable phenomenon, occurring for all critical points considered, concerns the index of a point, i.e., the number of negative Hessian eigenvalues, increasing with the value of the objective function. Lastly, a Newton polytope argument is used to give a complete enumeration of all critical points of fixed symmetry, and it is shown that contrarily to the set of global minima which remains 
    
[^24]: 分层结构领域自适应

    Taxonomy-Structured Domain Adaptation. (arXiv:2306.07874v1 [cs.LG])

    [http://arxiv.org/abs/2306.07874](http://arxiv.org/abs/2306.07874)

    本文提出了分层结构领域自适应方法，通过分层结构领域的形式化描述来缓解不同领域之间的分布偏移，该方法在合成和实际数据集上实现了最先进的性能。

    

    领域自适应旨在缓解不同领域之间的分布偏移。然而，传统的方法大多限于分类领域，这严重简化了真实世界中微妙的领域关系。在本文中，我们通过分层结构领域进行推广，将领域形式化为具有嵌套的层次相似结构，例如动物物种和产品目录。我们建立在经典对抗框架之上，并引入了一种新颖的分类器，该分类器与对抗性鉴别器竞争以保留层次结构信息。当给定非信息领域分类（例如，所有叶节点都链接到根节点的扁平分类）时，平衡点恢复经典的对抗领域适应解决方案，同时在其他分类中产生非平凡的结果。在合成和实际数据集上实证结果表明，我们的方法实现了最先进的性能，并成功进行了自适应。代码可在https://gith获得。

    Domain adaptation aims to mitigate distribution shifts among different domains. However, traditional formulations are mostly limited to categorical domains, greatly simplifying nuanced domain relationships in the real world. In this work, we tackle a generalization with taxonomy-structured domains, which formalizes domains with nested, hierarchical similarity structures such as animal species and product catalogs. We build on the classic adversarial framework and introduce a novel taxonomist, which competes with the adversarial discriminator to preserve the taxonomy information. The equilibrium recovers the classic adversarial domain adaptation's solution if given a non-informative domain taxonomy (e.g., a flat taxonomy where all leaf nodes connect to the root node) while yielding non-trivial results with other taxonomies. Empirically, our method achieves state-of-the-art performance on both synthetic and real-world datasets with successful adaptation. Code is available at https://gith
    
[^25]: 带未知图谱的加性因果赌博机

    Additive Causal Bandits with Unknown Graph. (arXiv:2306.07858v1 [cs.LG])

    [http://arxiv.org/abs/2306.07858](http://arxiv.org/abs/2306.07858)

    该论文讨论了因果赌博机中选择行动的算法问题，提出了一种基于加性组合线性赌博问题的解决方法以解决未知图谱问题。

    

    我们探讨了选择行动的算法，在因果赌博设置下，学习者可以选择干预一组由因果图相关的随机变量，学习者顺序选择干预，并从干预分布中观察样本。学习者的目标是快速找到最大化结果变量期望的，所有可观察变量干预中的干预。我们假设没有关于因果图的任何知识，除了结果和其祖先之间的潜在混淆因素不存在。我们首先展示了未知图问题在结果的父母中可以是指数级难以解决。为了解决这个问题，我们对结果采取额外的加性假设，通过将问题建模为具有全赌博反馈的加性组合线性赌博问题来解决。我们提出了一种新的行动消除算法，展示了如何将此算法应用于这个设置。

    We explore algorithms to select actions in the causal bandit setting where the learner can choose to intervene on a set of random variables related by a causal graph, and the learner sequentially chooses interventions and observes a sample from the interventional distribution. The learner's goal is to quickly find the intervention, among all interventions on observable variables, that maximizes the expectation of an outcome variable. We depart from previous literature by assuming no knowledge of the causal graph except that latent confounders between the outcome and its ancestors are not present. We first show that the unknown graph problem can be exponentially hard in the parents of the outcome. To remedy this, we adopt an additional additive assumption on the outcome which allows us to solve the problem by casting it as an additive combinatorial linear bandit problem with full-bandit feedback. We propose a novel action-elimination algorithm for this setting, show how to apply this al
    
[^26]: SGD的精确平均二次线性稳定性分析

    Exact Mean Square Linear Stability Analysis for SGD. (arXiv:2306.07850v1 [cs.LG])

    [http://arxiv.org/abs/2306.07850](http://arxiv.org/abs/2306.07850)

    本文提供了SGD稳定性的精确阈值表达式，发现其与批量大小之间呈单调非降关系，进一步展示了减小批量大小可能会影响SGD的稳定性。

    

    近来，优化方法在损失函数极小值点附近的动态稳定性引起了极大关注。对于梯度下降法（GD），稳定的收敛仅可能发生在足够平坦的极小值处，并且已经与训练模型的良好性能联系在一起。但是，尽管GD的稳定性阈值已经众所周知，但迄今为止，尚未推导出随机梯度下降（SGD）的精确阈值的显式表达式。本文提供了这样一种封闭形式的表达式。具体而言，我们提供了一个关于步长$\eta$的显式条件，既是SGD在均方意义下稳定的必要条件，也是充分条件。我们的分析揭示了批量大小$B$的精确作用，特别的，我们展示出稳定性阈值是批量大小的单调非降函数，这意味着减小批量大小只会降低稳定性。此外，我们还展示了SGD的稳定性阈值。

    The dynamical stability of optimization methods at the vicinity of minima of the loss has recently attracted significant attention. For gradient descent (GD), stable convergence is possible only to minima that are sufficiently flat w.r.t. the step size, and those have been linked with favorable properties of the trained model. However, while the stability threshold of GD is well-known, to date, no explicit expression has been derived for the exact threshold of stochastic GD (SGD). In this paper, we derive such a closed-form expression. Specifically, we provide an explicit condition on the step size $\eta$ that is both necessary and sufficient for the stability of SGD in the mean square sense. Our analysis sheds light on the precise role of the batch size $B$. Particularly, we show that the stability threshold is a monotonically non-decreasing function of the batch size, which means that reducing the batch size can only hurt stability. Furthermore, we show that SGD's stability threshold
    
[^27]: 基于深度动态生成语音和噪声模型的无监督语音增强研究

    Unsupervised speech enhancement with deep dynamical generative speech and noise models. (arXiv:2306.07820v1 [eess.AS])

    [http://arxiv.org/abs/2306.07820](http://arxiv.org/abs/2306.07820)

    本研究提出了一种基于DDGM的无监督语音增强方法，通过三种配置训练DDGM，其中噪声依赖的训练配置使推理过程更加高效，实验结果显示该方法可获得竞争性的性能表现。

    

    本研究基于一种使用动态变分自编码器(DVAE)作为清晰语音模型和非负矩阵分解(NMF)作为噪声模型的无监督语音增强方法。我们提出用深度动态生成模型(DDGM)代替NMF噪声模型，其中DDGM依赖于DVAE潜变量、嘈杂的观测值或两者。可以通过三种配置来训练DDGM：无噪声感知，依赖于噪声和噪声依赖训练后的噪声自适应。实验结果表明，与最先进的无监督语音增强方法相比，所提出的方法达到了竞争性的性能，而噪声依赖的训练配置使推理过程更加高效。

    This work builds on a previous work on unsupervised speech enhancement using a dynamical variational autoencoder (DVAE) as the clean speech model and non-negative matrix factorization (NMF) as the noise model. We propose to replace the NMF noise model with a deep dynamical generative model (DDGM) depending either on the DVAE latent variables, or on the noisy observations, or on both. This DDGM can be trained in three configurations: noise-agnostic, noise-dependent and noise adaptation after noise-dependent training. Experimental results show that the proposed method achieves competitive performance compared to state-of-the-art unsupervised speech enhancement methods, while the noise-dependent training configuration yields a much more time-efficient inference process.
    
[^28]: 一种基于原始-对偶-评论家算法的离线约束强化学习

    A Primal-Dual-Critic Algorithm for Offline Constrained Reinforcement Learning. (arXiv:2306.07818v1 [cs.LG])

    [http://arxiv.org/abs/2306.07818](http://arxiv.org/abs/2306.07818)

    PDCA是一种用于离线约束强化学习的算法，它可以通过在Lagrangian函数上运行原始-对偶算法来找到近似鞍点，而无需集中性和强Bellman完备性假设。

    

    离线约束强化学习旨在学习一种策略，以在现有数据集上满足对成本函数期望值的限制条件下最大化预期的累积奖励。本文提出了一种称为原始-对偶-评论家算法（PDCA）的新算法，用于具有一般函数逼近的离线约束强化学习。PDCA在评论家估计的Lagrangian函数上运行原始-对偶算法。原始玩家采用无悔策略优化神谕，在给定任何评论家和对偶玩家的选择的情况下最大化拉格朗日函数的估计。对偶玩家通过采用无悔在线线性优化神谕，在给定评论家和原始玩家的任何选择的情况下最小化拉格朗日函数的估计。我们展示了PDCA可以成功地找到拉格朗日函数的近似鞍点，这对于约束强化学习问题几乎是最优的。与以前需要集中性和强Bellman完备性假设的作品不同，PDCA只需要一致性和自闭性这两个假设。

    Offline constrained reinforcement learning (RL) aims to learn a policy that maximizes the expected cumulative reward subject to constraints on expected value of cost functions using an existing dataset. In this paper, we propose Primal-Dual-Critic Algorithm (PDCA), a novel algorithm for offline constrained RL with general function approximation. PDCA runs a primal-dual algorithm on the Lagrangian function estimated by critics. The primal player employs a no-regret policy optimization oracle to maximize the Lagrangian estimate given any choices of the critics and the dual player. The dual player employs a no-regret online linear optimization oracle to minimize the Lagrangian estimate given any choices of the critics and the primal player. We show that PDCA can successfully find a near saddle point of the Lagrangian, which is nearly optimal for the constrained RL problem. Unlike previous work that requires concentrability and strong Bellman completeness assumptions, PDCA only requires co
    
[^29]: 分子属性预测的自动化三维预训练

    Automated 3D Pre-Training for Molecular Property Prediction. (arXiv:2306.07812v1 [q-bio.QM])

    [http://arxiv.org/abs/2306.07812](http://arxiv.org/abs/2306.07812)

    通过在3D分子图上进行预训练，该论文提出了一种更有效地预测分子属性的方法，该方法可以在不需要分子几何结构的情况下进行微调。

    

    分子属性预测是药物研发和材料科学中的重要问题。由于分子的几何结构对于分子属性预测的必要性已经被证明，因此将3D信息与各种图形学习方法相结合以提高预测性能。然而，由于高计算成本，在许多现实应用中获得分子的几何结构是不可行的。在这项工作中，我们提出了一种新的3D预训练框架（称为3D PGT），它在3D分子图上预训练模型，然后在没有3D结构的分子图上进行微调。基于化学键长，化学键角和二面角这三个基本几何描述符对应于完整的分子3D构形，我们首先开发了一个基于这三个属性的多任务生成预训练框架。接下来，为了自动融合这三项生成任务，我们设计了一种使用“总能量”来搜索的替代指标。

    Molecular property prediction is an important problem in drug discovery and materials science. As geometric structures have been demonstrated necessary for molecular property prediction, 3D information has been combined with various graph learning methods to boost prediction performance. However, obtaining the geometric structure of molecules is not feasible in many real-world applications due to the high computational cost. In this work, we propose a novel 3D pre-training framework (dubbed 3D PGT), which pre-trains a model on 3D molecular graphs, and then fine-tunes it on molecular graphs without 3D structures. Based on fact that bond length, bond angle, and dihedral angle are three basic geometric descriptors corresponding to a complete molecular 3D conformer, we first develop a multi-task generative pre-train framework based on these three attributes. Next, to automatically fuse these three generative tasks, we design a surrogate metric using the \textit{total energy} to search for 
    
[^30]: 低资源白盒三维点云支撑塔语义分割的特征形状识别方法

    Low-Resource White-Box Semantic Segmentation of Supporting Towers on 3D Point Clouds via Signature Shape Identification. (arXiv:2306.07809v1 [cs.CV])

    [http://arxiv.org/abs/2306.07809](http://arxiv.org/abs/2306.07809)

    本文提出了一种低资源白盒模型，SCENE-Net，用于3D点云语义分割，通过特征形状识别提供内在几何解释性，较少的参数和数据需求以及对噪音标签和数据不平衡的鲁棒性。

    

    近年来，3D场景分割研究通过增加模型复杂度和计算资源来提高性能，如IoU，而忽略了那些既无法访问必要资源，又需要了解模型决策机制的研究者和从业者。本文提出了SCENE-Net，一种用于3D点云语义分割的低资源白盒模型。SCENE-Net通过同变非张量算子（GENEOs）在点云上识别特征形状，提供内在几何解释性，其在笔记本上的训练时间为85分钟，推理时间为20毫秒。SCENE-Net具有11个可训练的几何参数，比黑盒模型需要更少的数据。SCENE-Net具有对噪声标记和数据不平衡的鲁棒性，并具有与最先进方法相当的IoU。本文还发布了一个40,000公里标记的农村地形点云数据集和代码实现。

    Research in 3D semantic segmentation has been increasing performance metrics, like the IoU, by scaling model complexity and computational resources, leaving behind researchers and practitioners that (1) cannot access the necessary resources and (2) do need transparency on the model decision mechanisms. In this paper, we propose SCENE-Net, a low-resource white-box model for 3D point cloud semantic segmentation. SCENE-Net identifies signature shapes on the point cloud via group equivariant non-expansive operators (GENEOs), providing intrinsic geometric interpretability. Our training time on a laptop is 85~min, and our inference time is 20~ms. SCENE-Net has 11 trainable geometrical parameters and requires fewer data than black-box models. SCENE--Net offers robustness to noisy labeling and data imbalance and has comparable IoU to state-of-the-art methods. With this paper, we release a 40~000 Km labeled dataset of rural terrain point clouds and our code implementation.
    
[^31]: 从具有扰动的时间序列数据中推断动态的调控交互图

    Inferring dynamic regulatory interaction graphs from time series data with perturbations. (arXiv:2306.07803v1 [cs.LG])

    [http://arxiv.org/abs/2306.07803](http://arxiv.org/abs/2306.07803)

    本文提出了RiTINI方法，使用空间与时间图注意力和图神经常微分方程的组合来推断复杂系统中的变化的交互图，相比传统因果推断网络，具有能够推断循环、有向和时变图的优势。

    

    复杂系统的特征是其实体之间的错综复杂的相互作用，这些相互作用随时间动态演变。准确推断这些动态关系对于理解和预测系统行为至关重要。在这篇论文中，我们提出了一种名为 Regulatory Temporal Interaction Network Inference (RiTINI) 的方法，使用空间与时间图注意力和图神经常微分方程的新颖组合，推断复杂系统中的变化的交互图。RiTINI利用图形先验的时间间隔信号以及在各个节点处的信号扰动，以有效地捕捉基础系统的动态。此方法不同于传统因果推断网络，后者仅限于推断非循环和静态图。相比之下，RiTINI能够推断循环、有向和时变图，提供了关于复杂系统更全面和准确的表示。RiTINI中的图形注意机制允许模型捕捉本地和全局依赖关系，而ODE表示方法使得连续与离散时间动态的集成成为可能。我们在合成和真实数据集上展示了RiTINI的有效性，展示了它在各个领域准确推断动态调控网络的能力。

    Complex systems are characterized by intricate interactions between entities that evolve dynamically over time. Accurate inference of these dynamic relationships is crucial for understanding and predicting system behavior. In this paper, we propose Regulatory Temporal Interaction Network Inference (RiTINI) for inferring time-varying interaction graphs in complex systems using a novel combination of space-and-time graph attentions and graph neural ordinary differential equations (ODEs). RiTINI leverages time-lapse signals on a graph prior, as well as perturbations of signals at various nodes in order to effectively capture the dynamics of the underlying system. This approach is distinct from traditional causal inference networks, which are limited to inferring acyclic and static graphs. In contrast, RiTINI can infer cyclic, directed, and time-varying graphs, providing a more comprehensive and accurate representation of complex systems. The graph attention mechanism in RiTINI allows the 
    
[^32]: ChatGPT与人工撰写文本：可控文本摘要和句子风格转移的洞察

    ChatGPT vs Human-authored Text: Insights into Controllable Text Summarization and Sentence Style Transfer. (arXiv:2306.07799v1 [cs.CL])

    [http://arxiv.org/abs/2306.07799](http://arxiv.org/abs/2306.07799)

    本文旨在系统地检查ChatGPT在两个可控生成任务中的表现，即ChatGPT能否适应不同的目标受众和写作风格。研究发现，人类产生的文体变化比ChatGPT表现出的更大，而生成的文本在一些特征上与人类样本有所不同，有时会包含事实错误或幻觉。

    

    大规模语言模型（如ChatGPT）以其出色的能力从简短的自然语言提示生成连贯的文本引起了媒体的重视。本文旨在系统地检查ChatGPT在两个可控生成任务中的表现，即ChatGPT能否适应不同的目标受众（专家与一般人）和写作风格（正式与非正式）。此外，我们评估了生成文本的忠实度，并将模型的表现与人工撰写的文本进行了比较。我们的研究发现，人类产生的文体变化比ChatGPT表现出的更大，而生成的文本在诸如单词类型分布等几个特征上与人类样本有所不同。此外，我们发现当 ChatGPT 将文本适应特定风格时，有时会包含事实错误或幻觉。

    Large-scale language models, like ChatGPT, have garnered significant media attention and stunned the public with their remarkable capacity for generating coherent text from short natural language prompts. In this paper, we aim to conduct a systematic inspection of ChatGPT's performance in two controllable generation tasks, with respect to ChatGPT's ability to adapt its output to different target audiences (expert vs. layman) and writing styles (formal vs. informal). Additionally, we evaluate the faithfulness of the generated text, and compare the model's performance with human-authored texts. Our findings indicate that the stylistic variations produced by humans are considerably larger than those demonstrated by ChatGPT, and the generated texts diverge from human samples in several characteristics, such as the distribution of word types. Moreover, we observe that ChatGPT sometimes incorporates factual errors or hallucinations when adapting the text to suit a specific style.
    
[^33]: 有限高斯神经元：通过让神经网络说“我不知道”来防御对抗性攻击

    Finite Gaussian Neurons: Defending against adversarial attacks by making neural networks say "I don't know". (arXiv:2306.07796v1 [cs.LG])

    [http://arxiv.org/abs/2306.07796](http://arxiv.org/abs/2306.07796)

    这篇论文介绍了有限高斯神经元（FGN）这种新的神经元架构，可以通过简单地将现有模型转换为FGN结构，从而抵御对抗性攻击并同时保持高准确性和可信度。

    

    自2014年以来，人工神经网络已知容易受到对抗性攻击的影响，这些攻击可以通过对输入进行微小改动，使网络产生错误或无意义的输出。虽然已提出防御对抗性攻击的方法，但这些方法通常涉及从头重新训练一个新的神经网络，是一个昂贵的任务。在这项工作中，我引入了有限高斯神经元（FGN），这是一种人工神经网络的新型神经元结构。我的工作旨在：-将现有模型轻松转换为有限高斯神经元结构，-同时保留现有模型在真实数据上的行为，-并抵抗对抗性攻击。我展示了转换和重新训练的有限高斯神经网络（FGNN）在与经典神经网络相比较时，在随机和快速梯度符号方法对抗图像上预测始终具有较低的置信度（即不会过度自信），同时保持高准确性和可信度。

    Since 2014, artificial neural networks have been known to be vulnerable to adversarial attacks, which can fool the network into producing wrong or nonsensical outputs by making humanly imperceptible alterations to inputs. While defenses against adversarial attacks have been proposed, they usually involve retraining a new neural network from scratch, a costly task. In this work, I introduce the Finite Gaussian Neuron (FGN), a novel neuron architecture for artificial neural networks. My works aims to: - easily convert existing models to Finite Gaussian Neuron architecture, - while preserving the existing model's behavior on real data, - and offering resistance against adversarial attacks. I show that converted and retrained Finite Gaussian Neural Networks (FGNN) always have lower confidence (i.e., are not overconfident) in their predictions over randomized and Fast Gradient Sign Method adversarial images when compared to classical neural networks, while maintaining high accuracy and conf
    
[^34]: 组合等变表示学习

    Compositionally Equivariant Representation Learning. (arXiv:2306.07783v1 [cs.CV])

    [http://arxiv.org/abs/2306.07783](http://arxiv.org/abs/2306.07783)

    本文研究了利用组合性来学习更具可解释性和泛化性的医学图像分割表示，提出了一种将组合等变性质纳入表示学习中的方法，并在各种医学图像分割任务上展示了其对泛化性能的提升。

    

    深度学习模型通常需要充分的监督（标记数据）才能有效地进行训练。相比之下，人类可以迅速学习识别医学图像（如磁共振和 CT 扫描中的重要解剖结构），只需要少量的指导。这种识别能力容易泛化到来自不同医疗机构的新图像以及不同设置中的新任务。这种快速且泛化的学习能力很大程度上是由于人脑中图像模式的组合结构，而当前的医学模型并不能很好地表示出这种结构。在本文中，我们研究利用组合性来学习更具有可解释性和泛化性的医学图像分割表示。具体而言，我们提出了一个假设：用于生成医学图像的基础生成因素满足组合等变性质，其中每个因素都是组合的（例如对应于人体解剖结构）并且对任务是等变的。因此，我们引入了一种方法来将组合等变性质纳入表示学习中，并展示了这种方法在各种医学图像分割任务上提高了泛化性能。

    Deep learning models often need sufficient supervision (i.e. labelled data) in order to be trained effectively. By contrast, humans can swiftly learn to identify important anatomy in medical images like MRI and CT scans, with minimal guidance. This recognition capability easily generalises to new images from different medical facilities and to new tasks in different settings. This rapid and generalisable learning ability is largely due to the compositional structure of image patterns in the human brain, which are not well represented in current medical models. In this paper, we study the utilisation of compositionality in learning more interpretable and generalisable representations for medical image segmentation. Overall, we propose that the underlying generative factors that are used to generate the medical images satisfy compositional equivariance property, where each factor is compositional (e.g. corresponds to the structures in human anatomy) and also equivariant to the task. Henc
    
[^35]: 降秩卡尔曼滤波器：在高维中进行近似低秩动态滤波

    The Rank-Reduced Kalman Filter: Approximate Dynamical-Low-Rank Filtering In High Dimensions. (arXiv:2306.07774v1 [stat.ML])

    [http://arxiv.org/abs/2306.07774](http://arxiv.org/abs/2306.07774)

    该论文提出了一种新的近似高斯滤波和平滑方法，它将协方差矩阵的低秩近似传播，通过将Lyapunov方程投影到低秩矩阵的流形上，使用数值稳定的动态低秩积分器求解，能够有效地处理高维数据。

    

    在高维动态系统的推断和模拟中，需要进行某种形式的降维才能使问题具有可处理性。在本文中，我们提出了一种新的近似高斯滤波和平滑方法，它将协方差矩阵的低秩近似传播。这是通过将预测步骤相关的Lyapunov方程投影到低秩矩阵的流形上来实现的，然后通过最近开发的数值稳定、动态低秩积分器求解这些方程。与此同时，通过注意协方差更新仅转换协方差矩阵的列空间，而该空间由构造得到，从而使更新步骤具有可处理性。算法与现有的基于集合的方法不同之处在于，协方差矩阵的低秩近似是确定性的，而不是随机的。关键在于，这使得该方法能够有效地处理高维数据。

    Inference and simulation in the context of high-dimensional dynamical systems remain computationally challenging problems. Some form of dimensionality reduction is required to make the problem tractable in general. In this paper, we propose a novel approximate Gaussian filtering and smoothing method which propagates low-rank approximations of the covariance matrices. This is accomplished by projecting the Lyapunov equations associated with the prediction step to a manifold of low-rank matrices, which are then solved by a recently developed, numerically stable, dynamical low-rank integrator. Meanwhile, the update steps are made tractable by noting that the covariance update only transforms the column space of the covariance matrix, which is low-rank by construction. The algorithm differentiates itself from existing ensemble-based approaches in that the low-rank approximations of the covariance matrices are deterministic, rather than stochastic. Crucially, this enables the method to repr
    
[^36]: 区域是你所需要的一切：重复元素使对抗性攻击更强大

    Area is all you need: repeatable elements make stronger adversarial attacks. (arXiv:2306.07768v1 [cs.CV])

    [http://arxiv.org/abs/2306.07768](http://arxiv.org/abs/2306.07768)

    本文证明对抗性攻击的成功主要是由于攻击尺寸的增加，通过构建可重复元素的对抗性图案可以生成最大可能的对抗性补丁，并实现了躲避检测的新最先进。

    

    近十年来，深度神经网络在计算机视觉任务中取得了最先进的成果。然而，这些模型容易受到非正常输入（称为对抗性示例）的影响，导致它们错误分类或无法检测到物体。在本文中，我们提出了证据表明，对抗性攻击变得越来越成功主要是由于攻击尺寸的增加。然后，我们展示了一种通过构建可重复元素的对抗性图案来生成最大可能的对抗性补丁的方法。这种方法在躲避YOLOv2和YOLOv3检测方面实现了新的最先进。最后，我们提出了一个未能复制该领域中发布的几个攻击先前成功的实验，并以一些关于测试和可重复性的评论结束。

    Over the last decade, deep neural networks have achieved state of the art in computer vision tasks. These models, however, are susceptible to unusual inputs, known as adversarial examples, that cause them to misclassify or otherwise fail to detect objects. Here, we provide evidence that the increasing success of adversarial attacks is primarily due to increasing their size. We then demonstrate a method for generating the largest possible adversarial patch by building a adversarial pattern out of repeatable elements. This approach achieves a new state of the art in evading detection by YOLOv2 and YOLOv3. Finally, we present an experiment that fails to replicate the prior success of several attacks published in this field, and end with some comments on testing and reproducibility.
    
[^37]: 多保真度多臂赌博机的再探讨

    Multi-Fidelity Multi-Armed Bandits Revisited. (arXiv:2306.07761v1 [cs.LG])

    [http://arxiv.org/abs/2306.07761](http://arxiv.org/abs/2306.07761)

    该论文研究了多保真度多臂赌博机问题，提出了算法框架，并进一步研究了保真度选择的代价复杂度上下界，还提出了一种新的遗憾定义并证明了相应的问题无关和问题相关下界。

    

    我们研究了经典多臂赌博机问题的扩展——多保真度多臂赌博机(MF-MAB)。MF-MAB允许每个臂根据不同的代价(保真度)和观测精度来进行拉动。我们研究了最佳臂识别以及遗憾最小化两个目标。对于最佳臂识别，我们提出了以下内容：(a)代价复杂度下界，(b)两种不同保真度选择方法的算法框架，(c)两种方法的代价复杂度上界。由MF-MAB的这两个代价复杂度下界可以恢复经典（单保真度）MAB的标准样本复杂度下界。对于MF-MAB的遗憾最小化问题，我们提出了一种新的遗憾定义，证明了它的问题无关的遗憾下界为$\Omega(K^{1/3}\Lambda^{2/3})​$和问题相关的下界$\Omega(K\log \Lambda)​$，其中$K$是臂数，$\Lambda$是以代价为单位的决策预算，还提出了一种基于淘汰的算法，其权衡了不同的代价组合。

    We study the multi-fidelity multi-armed bandit (MF-MAB), an extension of the canonical multi-armed bandit (MAB) problem. MF-MAB allows each arm to be pulled with different costs (fidelities) and observation accuracy. We study both the best arm identification with fixed confidence (BAI) and the regret minimization objectives. For BAI, we present (a) a cost complexity lower bound, (b) an algorithmic framework with two alternative fidelity selection procedures, and (c) both procedures' cost complexity upper bounds. From both cost complexity bounds of MF-MAB, one can recover the standard sample complexity bounds of the classic (single-fidelity) MAB. For regret minimization of MF-MAB, we propose a new regret definition, prove its problem-independent regret lower bound $\Omega(K^{1/3}\Lambda^{2/3})$ and problem-dependent lower bound $\Omega(K\log \Lambda)$, where $K$ is the number of arms and $\Lambda$ is the decision budget in terms of cost, and devise an elimination-based algorithm whose w
    
[^38]: 在约束马尔可夫潜在博弈中证明学习纳什策略

    Provably Learning Nash Policies in Constrained Markov Potential Games. (arXiv:2306.07749v1 [cs.LG])

    [http://arxiv.org/abs/2306.07749](http://arxiv.org/abs/2306.07749)

    本文研究了约束马尔可夫潜在博弈（CMPGs），并提出了一种寻找CMPGs的纳什策略的约束优化算法，该算法解决了单智能体模型中CMPG问题不满足强对偶性的问题

    

    多智能体强化学习（MARL）解决了多个代理的顺序决策问题，每个代理都最优化其自身的目标。在许多现实世界的实例中，不仅仅是要优化它们各自的目标，还要确保安全行为。在交通路由中，每辆车（代理）旨在快速到达目的地（目标），同时避免碰撞（安全）。约束马尔可夫博弈（CMGs）是安全MARL问题的一种自然形式，但通常难以处理。在本文中，我们介绍并研究了一种重要的CMGs类别——约束马尔可夫潜在博弈（CMPGs）。我们首先表明，可以通过约束优化找到CMPGs的纳什策略。一个试图解决问题的方法是拉格朗日基于原始 - 对偶方法。正如我们所显示出来的，与单智能体场景相反，CMPG不满足强对偶性，这使得这种方法应用不适当且可能不安全。为了解决CMPG问题，我们提出了一种新的概率算法。

    Multi-agent reinforcement learning (MARL) addresses sequential decision-making problems with multiple agents, where each agent optimizes its own objective. In many real-world instances, the agents may not only want to optimize their objectives, but also ensure safe behavior. For example, in traffic routing, each car (agent) aims to reach its destination quickly (objective) while avoiding collisions (safety). Constrained Markov Games (CMGs) are a natural formalism for safe MARL problems, though generally intractable. In this work, we introduce and study Constrained Markov Potential Games (CMPGs), an important class of CMGs. We first show that a Nash policy for CMPGs can be found via constrained optimization. One tempting approach is to solve it by Lagrangian-based primal-dual methods. As we show, in contrast to the single-agent setting, however, CMPGs do not satisfy strong duality, rendering such approaches inapplicable and potentially unsafe. To solve the CMPG problem, we propose our a
    
[^39]: 核化强化学习及其近似方法的优化

    Kernelized Reinforcement Learning with Order Optimal Regret Bounds. (arXiv:2306.07745v1 [cs.LG])

    [http://arxiv.org/abs/2306.07745](http://arxiv.org/abs/2306.07745)

    该论文提出了一种称为$\pi$-KRVI的乐观修改方法，并使用核岭回归进行强化学习中的非线性函数逼近。论文证明了在一般设置下第一个最优遗憾保证，并相对于现有最优结果实现了显着的多项式低差距。

    

    强化学习（RL）在各种具有复杂模型和大状态-行为空间的实际场景中显示出了实证的成功。但是，现有的分析结果通常集中于具有少量状态-行为或简单模型（例如线性建模状态-行为值函数）的设置。 为了推导有效处理更广泛值函数的大状态-行为空间的RL策略，一些最新工作考虑使用核岭回归进行非线性函数逼近。 我们提出了称为$\pi$-KRVI的方法，它是最小二乘值迭代的一种乐观修改，当状态-行为值函数由RKHS表示时。我们证明了在一般设置下第一个最优遗憾保证。我们的结果显示，在许多具有高度非光滑内核（例如神经切向内核或某些Mat\'ern内核）的情况下，相对于现有最优结果，存在显着的多项式低差距。

    Reinforcement learning (RL) has shown empirical success in various real world settings with complex models and large state-action spaces. The existing analytical results, however, typically focus on settings with a small number of state-actions or simple models such as linearly modeled state-action value functions. To derive RL policies that efficiently handle large state-action spaces with more general value functions, some recent works have considered nonlinear function approximation using kernel ridge regression. We propose $\pi$-KRVI, an optimistic modification of least-squares value iteration, when the state-action value function is represented by an RKHS. We prove the first order-optimal regret guarantees under a general setting. Our results show a significant polynomial in the number of episodes improvement over the state of the art. In particular, with highly non-smooth kernels (such as Neural Tangent kernel or some Mat\'ern kernels) the existing results lead to trivial (superl
    
[^40]: 基于对比学习的多语言音频与歌词对齐

    Contrastive Learning-Based Audio to Lyrics Alignment for Multiple Languages. (arXiv:2306.07744v1 [cs.SD])

    [http://arxiv.org/abs/2306.07744](http://arxiv.org/abs/2306.07744)

    本文提出了一种使用对比学习方法实现的音频和歌词对齐系统，不仅表现出色，而且具有对其他语言的鲁棒性。

    

    近年来，歌词对齐引起了广泛关注。本文提出了一种使用对比学习方法实现音频与文本领域交叉嵌入的新型系统。该系统可以利用弱注释的训练数据进行端到端训练，并且具有对其他语言的鲁棒性。

    Lyrics alignment gained considerable attention in recent years. State-of-the-art systems either re-use established speech recognition toolkits, or design end-to-end solutions involving a Connectionist Temporal Classification (CTC) loss. However, both approaches suffer from specific weaknesses: toolkits are known for their complexity, and CTC systems use a loss designed for transcription which can limit alignment accuracy. In this paper, we use instead a contrastive learning procedure that derives cross-modal embeddings linking the audio and text domains. This way, we obtain a novel system that is simple to train end-to-end, can make use of weakly annotated training data, jointly learns a powerful text model, and is tailored to alignment. The system is not only the first to yield an average absolute error below 0.2 seconds on the standard Jamendo dataset but it is also robust to other languages, even when trained on English data only. Finally, we release word-level alignments for the Ja
    
[^41]: V-LoL: 一种用于视觉逻辑学习的诊断数据集

    V-LoL: A Diagnostic Dataset for Visual Logical Learning. (arXiv:2306.07743v1 [cs.AI])

    [http://arxiv.org/abs/2306.07743](http://arxiv.org/abs/2306.07743)

    V-LoL是一个结合视觉和逻辑挑战的诊断数据集，其中包括了V-LoL-Trains，该数据集首次将复杂的视觉场景和灵活的逻辑推理任务结合起来，为研究广泛的视觉逻辑学习挑战提供了平台。

    

    尽管近期在视觉AI领域有了许多成功的进展，但仍存在不同的缺点；包括缺少精确的逻辑推理、抽象的概括能力以及理解复杂和嘈杂的场景等。不幸的是，现有的基准测试数据集并不能捕捉到这些方面中的多数。深度学习数据集关注视觉复杂数据但只有简单的视觉推理任务，归纳逻辑数据集包括复杂的逻辑学习任务，但是缺乏视觉的组成部分。为了解决这个问题，我们提出了视觉逻辑学习数据集V-LoL，它无缝地结合了视觉和逻辑的挑战。值得注意的是，我们首次推出了V-LoL的第一个实例，名为V-LoL-Trains，它是符号AI中一个经典基准测试的视觉呈现，即Michalski火车问题。通过在一个通用框架内结合复杂的视觉场景和灵活的逻辑推理任务，V-LoL-Trains为研究广泛的视觉逻辑学习挑战提供了平台。

    Despite the successes of recent developments in visual AI, different shortcomings still exist; from missing exact logical reasoning, to abstract generalization abilities, to understanding complex and noisy scenes. Unfortunately, existing benchmarks, were not designed to capture more than a few of these aspects. Whereas deep learning datasets focus on visually complex data but simple visual reasoning tasks, inductive logic datasets involve complex logical learning tasks, however, lack the visual component. To address this, we propose the visual logical learning dataset, V-LoL, that seamlessly combines visual and logical challenges. Notably, we introduce the first instantiation of V-LoL, V-LoL-Trains, -- a visual rendition of a classic benchmark in symbolic AI, the Michalski train problem. By incorporating intricate visual scenes and flexible logical reasoning tasks within a versatile framework, V-LoL-Trains provides a platform for investigating a wide range of visual logical learning ch
    
[^42]: 在情境马尔可夫决策过程中学习策略梯度方法的步长选择

    Stepsize Learning for Policy Gradient Methods in Contextual Markov Decision Processes. (arXiv:2306.07741v1 [cs.LG])

    [http://arxiv.org/abs/2306.07741](http://arxiv.org/abs/2306.07741)

    本文提出了一种元强化学习方法，在情境马尔可夫决策过程中用于超参数选择问题。该方法在标准基准测试上优于现有步长自适应方法，能够实现各种任务范围内的良好性能。

    

    基于策略的算法是模型无关强化学习中最广泛采用的技术之一，由于其在连续动作空间中的强理论基础和良好性质而得到广泛应用。不幸的是，这些方法需要精确和问题特定的超参数调整才能实现良好的性能，并且往往在被要求完成一系列异质任务时难以胜任。特别是，步长的选择对于它们学习高性能策略的能力具有至关重要的影响，影响训练过程的速度和稳定性，经常是不良结果的主要原因。在本文中，我们采用元强化学习方法解决这些问题，引入了一种新的公式，称为元MDP，可以用于解决任何具有情境过程的强化学习中的超参数选择问题。在提供了不同任务性能差异的理论利普希茨界后，我们采用所提出的框架在一组基准测试中训练批量RL算法。通过利用元MDP公式，我们表明我们的方法在标准基准测试上优于现有的步长自适应方法，在各种任务范围内实现良好性能。

    Policy-based algorithms are among the most widely adopted techniques in model-free RL, thanks to their strong theoretical groundings and good properties in continuous action spaces. Unfortunately, these methods require precise and problem-specific hyperparameter tuning to achieve good performance, and tend to struggle when asked to accomplish a series of heterogeneous tasks. In particular, the selection of the step size has a crucial impact on their ability to learn a highly performing policy, affecting the speed and the stability of the training process, and often being the main culprit for poor results. In this paper, we tackle these issues with a Meta Reinforcement Learning approach, by introducing a new formulation, known as meta-MDP, that can be used to solve any hyperparameter selection problem in RL with contextual processes. After providing a theoretical Lipschitz bound to the difference of performance in different tasks, we adopt the proposed framework to train a batch RL algo
    
[^43]: 深度学习模型在物理-计算系统中的鲁棒性和泛化性能的比较研究

    Robustness and Generalization Performance of Deep Learning Models on Cyber-Physical Systems: A Comparative Study. (arXiv:2306.07737v1 [cs.LG])

    [http://arxiv.org/abs/2306.07737](http://arxiv.org/abs/2306.07737)

    本文研究了深度学习模型在物理-计算系统中的鲁棒性和泛化性能，并通过暴露模型于分布之外的样本来测试其迁移学习能力和响应数据增强技术的能力。结果表明，深度学习模型虽能达高精度，但其鲁棒性和泛化能力还不足以应用于实际物理-计算系统中。

    

    深度学习模型在时间序列预测方面越来越受到关注，但在物理-计算系统中应用受到这些方法鲁棒性的限制。因此，本研究评估了深度学习架构在来自物理-计算系统的多元时间序列数据上的鲁棒性和泛化性能。我们的研究重点是模型处理一系列扰动的能力，如传感器故障和噪声，并评估它们对整体性能的影响。此外，我们通过将它们暴露于分布之外（OOD）的样本来测试这些模型的泛化和迁移学习能力。这些样本包括偏离标准系统操作，同时保留了基础物理系统的核心动态。此外，我们测试了模型对几种数据增强技术的响应能力，包括添加噪声和时间扭曲。我们的实验框架利用了一个模拟的三罐系统，作为研究物理-计算系统中深度学习模型鲁棒性的新型基准。结果表明，尽管深度学习模型能够达到高精度，但它们的鲁棒性和泛化能力不足以用于现实世界中的物理-计算系统应用。

    Deep learning (DL) models have seen increased attention for time series forecasting, yet the application on cyber-physical systems (CPS) is hindered by the lacking robustness of these methods. Thus, this study evaluates the robustness and generalization performance of DL architectures on multivariate time series data from CPS. Our investigation focuses on the models' ability to handle a range of perturbations, such as sensor faults and noise, and assesses their impact on overall performance. Furthermore, we test the generalization and transfer learning capabilities of these models by exposing them to out-of-distribution (OOD) samples. These include deviations from standard system operations, while the core dynamics of the underlying physical system are preserved. Additionally, we test how well the models respond to several data augmentation techniques, including added noise and time warping. Our experimental framework utilizes a simulated three-tank system, proposed as a novel benchmar
    
[^44]: BeliefPPG: 通过置信传播从PPG信号中获得具有不确定性感知的心率估计

    BeliefPPG: Uncertainty-aware Heart Rate Estimation from PPG signals via Belief Propagation. (arXiv:2306.07730v1 [cs.LG])

    [http://arxiv.org/abs/2306.07730](http://arxiv.org/abs/2306.07730)

    通过离散时间随机过程将心率演变表示为隐藏马尔科夫模型，使用训练的神经网络计算PPG信号窗口内的可能心率值分布，然后通过置信传播结合统计分布监测心率变化以优化这些估计，并获得涵盖心率值范围的量化概率分布以捕获固有预测不确定性的良好校准估计。

    

    我们提出了一种新颖的基于学习的方法，通过离散时间随机过程将心率的演变表示为隐藏马尔可夫模型，并通过训练的神经网络为给定的PPG信号窗口导出可能心率值的分布。使用置信传播，在时间上下文中结合心率变化的统计分布以优化这些估计。从此，我们获得了一种量化的概率分布，涵盖了可能心率值的这个范围，这可以捕获固有预测不确定性的有意义且良好校准的估计。我们在八个公共数据集上进行了三个不同的交叉验证实验，证明了我们方法的鲁棒性。

    We present a novel learning-based method that achieves state-of-the-art performance on several heart rate estimation benchmarks extracted from photoplethysmography signals (PPG). We consider the evolution of the heart rate in the context of a discrete-time stochastic process that we represent as a hidden Markov model. We derive a distribution over possible heart rate values for a given PPG signal window through a trained neural network. Using belief propagation, we incorporate the statistical distribution of heart rate changes to refine these estimates in a temporal context. From this, we obtain a quantized probability distribution over the range of possible heart rate values that captures a meaningful and well-calibrated estimate of the inherent predictive uncertainty. We show the robustness of our method on eight public datasets with three different cross-validation experiments.
    
[^45]: 数据增强与图像变换对深度网络性能的影响

    Effects of Data Enrichment with Image Transformations on the Performance of Deep Networks. (arXiv:2306.07724v1 [cs.CV])

    [http://arxiv.org/abs/2306.07724](http://arxiv.org/abs/2306.07724)

    本文通过实验调查了数据增强对超分辨率问题中深度网络性能的影响，发现混合所有转换的数据时模型得分最高，180°旋转增强的数据提供了最佳结果。

    

    图像并不总是以某种标准格式和方向出现。深度网络需要被训练以考虑到意外的方向或格式变化。为此，训练数据应被增强包括不同的条件。本研究通过实验调查数据增强对超分辨率问题中深度网络性能的影响。总共使用了六种基本图像变换方法进行增强。实验中，使用六种图像转换方法增强ILSVRC2012数据集的变量来训练两个深度网络模型。发现单一的图像变换中，180°旋转增强的数据提供了最佳结果。模型在训练所有转换的混合数据时得分最高，最不成功的结果是模型在翻转上下生成的增强数据上进行训练。

    Images cannot always be expected to come in a certain standard format and orientation. Deep networks need to be trained to take into account unexpected variations in orientation or format. For this purpose, training data should be enriched to include different conditions. In this study, the effects of data enrichment on the performance of deep networks in the super resolution problem were investigated experimentally. A total of six basic image transformations were used for the enrichment procedures. In the experiments, two deep network models were trained with variants of the ILSVRC2012 dataset enriched by these six image transformation processes. Considering a single image transformation, it has been observed that the data enriched with 180 degree rotation provides the best results. The most unsuccessful result was obtained when the models were trained on the enriched data generated by the flip upside down process. Models scored highest when trained with a mix of all transformations.
    
[^46]: 对抗鲁棒性学习的理论基础

    Theoretical Foundations of Adversarially Robust Learning. (arXiv:2306.07723v1 [cs.LG])

    [http://arxiv.org/abs/2306.07723](http://arxiv.org/abs/2306.07723)

    本论文从理论角度探讨了对抗鲁棒性学习的问题，提出了新的学习算法，并分析了其鲁棒性和泛化性能。

    

    尽管机器学习系统取得了非凡的进展，但已经证明它们对于对抗样本是脆弱的：对测试样本进行细微但有意的扰动，就会导致机器学习模型错误分类。本论文旨在从理论角度解决这一具有挑战性的问题，探讨我们可以希望保证什么样的鲁棒性性质，并提供可实现算法保证这些性质的方法。

    Despite extraordinary progress, current machine learning systems have been shown to be brittle against adversarial examples: seemingly innocuous but carefully crafted perturbations of test examples that cause machine learning predictors to misclassify. Can we learn predictors robust to adversarial examples? and how? There has been much empirical interest in this contemporary challenge in machine learning, and in this thesis, we address it from a theoretical perspective.  In this thesis, we explore what robustness properties can we hope to guarantee against adversarial examples and develop an understanding of how to algorithmically guarantee them. We illustrate the need to go beyond traditional approaches and principles such as empirical risk minimization and uniform convergence, and make contributions that can be categorized as follows: (1) introducing problem formulations capturing aspects of emerging practical challenges in robust learning, (2) designing new learning algorithms with 
    
[^47]: 带预算的重复二价拍卖中的协调动态出价

    Coordinated Dynamic Bidding in Repeated Second-Price Auctions with Budgets. (arXiv:2306.07709v1 [cs.GT])

    [http://arxiv.org/abs/2306.07709](http://arxiv.org/abs/2306.07709)

    本文研究了带预算的重复二价拍卖中的协调在线竞价算法，提出了能够保证每个客户效用最大化的算法，并证明实现了最大的联盟福利。

    

    在在线广告市场中，越来越多的广告主雇用竞价代理来参与广告拍卖。这些代理专门设计在线算法并代表其客户出价。通常情况下，代理通常拥有多个广告主的信息，因此她有可能协调出价，帮助她的客户获得比独立出价更高的效用。本文研究了带预算的重复二价拍卖中的协调在线竞价算法。我们提出了算法，保证每个客户的效用都比独立竞价获得的最优效用高。我们证明这些算法实现了最大的联盟福利，并讨论了投标者在对称情况下误报预算的激励机制。我们的证明结合了在线学习和平衡分析技术，克服了与多维基准竞争的困难。我们进一步通过实验评估了我们算法的性能。

    In online ad markets, a rising number of advertisers are employing bidding agencies to participate in ad auctions. These agencies are specialized in designing online algorithms and bidding on behalf of their clients. Typically, an agency usually has information on multiple advertisers, so she can potentially coordinate bids to help her clients achieve higher utilities than those under independent bidding.  In this paper, we study coordinated online bidding algorithms in repeated second-price auctions with budgets. We propose algorithms that guarantee every client a higher utility than the best she can get under independent bidding. We show that these algorithms achieve maximal coalition welfare and discuss bidders' incentives to misreport their budgets, in symmetric cases. Our proofs combine the techniques of online learning and equilibrium analysis, overcoming the difficulty of competing with a multi-dimensional benchmark. The performance of our algorithms is further evaluated by expe
    
[^48]: 基于时间图序列预测的时态图结构学习

    Time-aware Graph Structure Learning via Sequence Prediction on Temporal Graphs. (arXiv:2306.07699v1 [cs.LG])

    [http://arxiv.org/abs/2306.07699](http://arxiv.org/abs/2306.07699)

    该论文提出了一种基于时间图序列预测的时态图结构学习方法，通过添加潜在的时间边来学习更好的图像结构，提高下游任务的性能。

    

    近年来，旨在模拟图像的传递性质的时间图学习变得越来越受关注并取得了显著的性能。然而，实际上，图像结构往往是不完整和嘈杂的，这阻碍了时间图网络（TGN）学习信息丰富的表示。为了解决这些问题，我们提出了一种基于时间图序列预测的时态图结构学习（TGSL）方法，通过添加潜在的时间边学习更好的图像结构，提高了下游任务的性能。

    Temporal Graph Learning, which aims to model the time-evolving nature of graphs, has gained increasing attention and achieved remarkable performance recently. However, in reality, graph structures are often incomplete and noisy, which hinders temporal graph networks (TGNs) from learning informative representations. Graph contrastive learning uses data augmentation to generate plausible variations of existing data and learn robust representations. However, rule-based augmentation approaches may be suboptimal as they lack learnability and fail to leverage rich information from downstream tasks. To address these issues, we propose a Time-aware Graph Structure Learning (TGSL) approach via sequence prediction on temporal graphs, which learns better graph structures for downstream tasks through adding potential temporal edges. In particular, it predicts time-aware context embedding based on previously observed interactions and uses the Gumble-Top-K to select the closest candidate edges to th
    
[^49]: StyleTTS 2：通过风格扩散和与大型语音语言模型的对抗训练实现人类级别的语音合成

    StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion and Adversarial Training with Large Speech Language Models. (arXiv:2306.07691v1 [eess.AS])

    [http://arxiv.org/abs/2306.07691](http://arxiv.org/abs/2306.07691)

    本文提出了一种名为StyleTTS 2的TTS模型，通过对抗训练和大型语音语言模型来实现人类级别的语音合成。与以往模型不同，StyleTTS 2将样式视为潜在随机变量，利用扩散模型来生成最适合文本的样式，同时受益于大型SLMs和新的可微分持续时间建模。

    

    本文提出了StyleTTS2，一种文本到语音（TTS）模型，该模型利用风格扩散和与大型语音语言模型（SLM）的对抗性训练来实现人类级别的TTS合成。 StyleTTS 2通过将样式建模为潜在的随机变量通过扩散模型来生成最适合文本的样式，无需参考语音，实现高效的潜在扩散，同时受益于扩散模型提供的多样化语音合成。此外，我们使用大型预先训练的SLMs（例如WavLM）作为鉴别器，并使用我们的新型可微分持续时间建模进行端到端的训练，从而提高了语音的自然度。 StyleTTS 2在单扬声器LJSpeech数据集上超越了人类录音，并在多扬声器VCTK数据集上与之匹配，经过母语为英语的人员评判。此外，当在LibriTTS数据集上进行训练时，我们的模型胜过了以前公开可用的零样本说话人语音合成模型。

    In this paper, we present StyleTTS 2, a text-to-speech (TTS) model that leverages style diffusion and adversarial training with large speech language models (SLMs) to achieve human-level TTS synthesis. StyleTTS 2 differs from its predecessor by modeling styles as a latent random variable through diffusion models to generate the most suitable style for the text without requiring reference speech, achieving efficient latent diffusion while benefiting from the diverse speech synthesis offered by diffusion models. Furthermore, we employ large pre-trained SLMs, such as WavLM, as discriminators with our novel differentiable duration modeling for end-to-end training, resulting in improved speech naturalness. StyleTTS 2 surpasses human recordings on the single-speaker LJSpeech dataset and matches it on the multispeaker VCTK dataset as judged by native English speakers. Moreover, when trained on the LibriTTS dataset, our model outperforms previous publicly available models for zero-shot speaker
    
[^50]: 差分隐私下的一次排列哈希和基于 Bin 的一致加权采样

    Differentially Private One Permutation Hashing and Bin-wise Consistent Weighted Sampling. (arXiv:2306.07674v1 [stat.ML])

    [http://arxiv.org/abs/2306.07674](http://arxiv.org/abs/2306.07674)

    本研究提出了一种在差分隐私条件下的一次排列哈希方法和基于 Bin 的一致加权采样，为大规模搜索和学习应用程序提供了更高效、更方便的工具。

    

    最小哈希（MinHash）是一种标准算法，广泛应用于具有二进制（0/1）Jaccard相似度的大规模搜索和学习应用程序。MinHash 的常见用途是处理大规模 n-gram 文本表示，以便实践者不必实现原始数据（这将是禁止的）。MinHash 的另一个流行用途是构建哈希表，以实现亚线性时间的近似最近邻搜索。MinHash 还用作构建大规模机器学习系统的工具。标准的 MinHash 实现需要应用 K 个随机排列，而一次排列哈希方法（OPH）则是 MinHash 的一种高效替代方法，它将数据矢量划分为 K 个 bin，并在每个 bin 中生成哈希值。OPH 更加高效，更加便利。在本文中，我们将差分隐私（DP）与 OPH（以及 MinHash）相结合，提出了一种差分隐私下的一次排列哈希和基于 Bin 的一致加权采样方法。

    Minwise hashing (MinHash) is a standard algorithm widely used in the industry, for large-scale search and learning applications with the binary (0/1) Jaccard similarity. One common use of MinHash is for processing massive n-gram text representations so that practitioners do not have to materialize the original data (which would be prohibitive). Another popular use of MinHash is for building hash tables to enable sub-linear time approximate near neighbor (ANN) search. MinHash has also been used as a tool for building large-scale machine learning systems. The standard implementation of MinHash requires applying $K$ random permutations. In comparison, the method of one permutation hashing (OPH), is an efficient alternative of MinHash which splits the data vectors into $K$ bins and generates hash values within each bin. OPH is substantially more efficient and also more convenient to use.  In this paper, we combine the differential privacy (DP) with OPH (as well as MinHash), to propose the 
    
[^51]: 重新思考文本数据增强的有效性：一个经验分析

    Rethink the Effectiveness of Text Data Augmentation: An Empirical Analysis. (arXiv:2306.07664v1 [cs.CL])

    [http://arxiv.org/abs/2306.07664](http://arxiv.org/abs/2306.07664)

    本研究发现数据增强技术在语言模型的预训练及微调中仍具有显著的提升作用，尤其在少样本学习的情况下，持续的预训练可以提高微调性能10%以上。

    

    最近几年，语言模型在推进自然语言处理领域方面取得了显著进展。然而，数据增强技术对这些语言模型微调表现的影响一直是一个争论的话题。在本研究中，我们评估了三种不同的微调方法结合回译在7个不同的自然语言处理任务中的有效性，包括分类和回归类型，涵盖单句和句子对任务。与优先的假设相反，即数据增强对提高语言模型的微调表现没有贡献，我们的发现表明，持续在增强数据上进行预训练可以有效地改善下游任务的微调表现。在最有利的情况下，持续的预训练可以使微调性能在小样本学习设置下提高10%以上。我们的发现突显出数据增强作为增强语言模型性能的强大工具的潜力。

    In recent years, language models (LMs) have made remarkable progress in advancing the field of natural language processing (NLP). However, the impact of data augmentation (DA) techniques on the fine-tuning (FT) performance of these LMs has been a topic of ongoing debate. In this study, we evaluate the effectiveness of three different FT methods in conjugation with back-translation across an array of 7 diverse NLP tasks, including classification and regression types, covering single-sentence and sentence-pair tasks. Contrary to prior assumptions that DA does not contribute to the enhancement of LMs' FT performance, our findings reveal that continued pre-training on augmented data can effectively improve the FT performance of the downstream tasks. In the most favourable case, continued pre-training improves the performance of FT by more than 10% in the few-shot learning setting. Our finding highlights the potential of DA as a powerful tool for bolstering LMs' performance.
    
[^52]: Malafide: 一种新型对抗性卷积噪声攻击，用于深度伪造和欺骗检测系统

    Malafide: a novel adversarial convolutive noise attack against deepfake and spoofing detection systems. (arXiv:2306.07655v1 [eess.AS])

    [http://arxiv.org/abs/2306.07655](http://arxiv.org/abs/2306.07655)

    本文提出一个新型通用的对抗性攻击Malafide，可以攻击自动语音识别（ASV）欺诈对策（CMs）。该攻击可以用于ompromise CM的可靠性，同时保留语音的其他属性，例如质量和说话人的声音。 Malafide滤波器独立于输入话语和持续时间进行优化，并调整到基础欺骗攻击，只需要优化少量滤波器系数。集成自监督学习CM的解决方案在黑盒和白盒设置下更加稳健。

    

    我们提出了一个通用的对抗性攻击Malafide，用于攻击自动语音识别（ASV）欺诈对策（CMs）。通过引入经过优化的线性时不变滤波器，引入卷积噪声，Malafide攻击可以用于ompromise CM的可靠性，同时保留语音的其他属性，例如质量和说话人的声音。与最近提出的其他对抗性攻击不同，Malafide滤波器独立于输入话语和持续时间进行优化，并调整到基础欺骗攻击，只需要优化少量滤波器系数。即使如此，它们在黑盒设置中降低了CM性能估计一个数量级，还可以配置为克服集成的CM和ASV子系统。然而，使用自监督学习CM的集成解决方案在黑盒和白盒设置下更加稳健。

    We present Malafide, a universal adversarial attack against automatic speaker verification (ASV) spoofing countermeasures (CMs). By introducing convolutional noise using an optimised linear time-invariant filter, Malafide attacks can be used to compromise CM reliability while preserving other speech attributes such as quality and the speaker's voice. In contrast to other adversarial attacks proposed recently, Malafide filters are optimised independently of the input utterance and duration, are tuned instead to the underlying spoofing attack, and require the optimisation of only a small number of filter coefficients. Even so, they degrade CM performance estimates by an order of magnitude, even in black-box settings, and can also be configured to overcome integrated CM and ASV subsystems. Integrated solutions that use self-supervised learning CMs, however, are more robust, under both black-box and white-box settings.
    
[^53]: 使用Kubernetes集群日志自动化微服务测试失败分析

    Automating Microservices Test Failure Analysis using Kubernetes Cluster Logs. (arXiv:2306.07653v1 [cs.SE])

    [http://arxiv.org/abs/2306.07653](http://arxiv.org/abs/2306.07653)

    本研究旨在通过比较五种分类算法，使用Kubernetes集群日志自动判定微服务测试失败原因。结果表明，随机森林算法在需要较少计算资源的同时，能够产生良好的准确性。

    

    Kubernetes是一个免费的、开源的容器编排系统，用于部署和管理托管微服务的Docker容器。Kubernetes集群日志有助于确定故障原因。然而，随着系统变得越来越复杂，手动识别故障原因变得更加困难和耗时。本研究旨在确定有效和高效的分类算法，以自动确定故障原因。我们比较了五种分类算法，支持向量机、K-最近邻算法、随机森林、梯度提升分类器和多层感知器。我们的结果表明，随机森林产生了良好的准确性，同时需要比其他算法更少的计算资源。

    Kubernetes is a free, open-source container orchestration system for deploying and managing Docker containers that host microservices. Kubernetes cluster logs help in determining the reason for the failure. However, as systems become more complex, identifying failure reasons manually becomes more difficult and time-consuming. This study aims to identify effective and efficient classification algorithms to automatically determine the failure reason. We compare five classification algorithms, Support Vector Machines, K-Nearest Neighbors, Random Forest, Gradient Boosting Classifier, and Multilayer Perceptron. Our results indicate that Random Forest produces good accuracy while requiring fewer computational resources than other algorithms.
    
[^54]: 变分激励噪声：噪声如何改进模型

    Variational Positive-incentive Noise: How Noise Benefits Models. (arXiv:2306.07651v1 [cs.LG])

    [http://arxiv.org/abs/2306.07651](http://arxiv.org/abs/2306.07651)

    本文研究了如何通过正激励噪声框架下的随机噪声使经典模型受益，并提出了变分Pi-Noise，它可以在不改变原始模型结构的情况下增强和简化模型。

    

    大量研究旨在减轻由于负面噪声的基本假设而导致的噪声影响。但是，一些现有的研究表明，这种假设并不总是成立的。本文研究了如何在正激励噪声（Pi-Noise）框架下通过随机噪声使经典模型受益。由于Pi-Noise的理想目标是难以实现的，我们提出了对其变分下界进行优化的变分Pi-Noise（VPN），通过变分推断，设计了一个VPN生成器来增强基础模型并简化基础模型的推断，而不改变基础模型的架构。由于基础模型和VPN生成器的独立设计， VPN生成器可以与大多数现有模型一起使用。从实验结果来看，所提出的VPN生成器可以改进基本模型。值得称赞的是，训练有素的变分VPN生成器更喜欢独立密集型噪声。（翻译有删减）

    A large number of works aim to alleviate the impact of noise due to an underlying conventional assumption of the negative role of noise. However, some existing works show that the assumption does not always hold. In this paper, we investigate how to benefit the classical models by random noise under the framework of Positive-incentive Noise (Pi-Noise). Since the ideal objective of Pi-Noise is intractable, we propose to optimize its variational bound instead, namely variational Pi-Noise (VPN). With the variational inference, a VPN generator implemented by neural networks is designed for enhancing base models and simplifying the inference of base models, without changing the architecture of base models. Benefiting from the independent design of base models and VPN generators, the VPN generator can work with most existing models. From the experiments, it is shown that the proposed VPN generator can improve the base models. It is appealing that the trained variational VPN generator prefers
    
[^55]: SRATTA: 在联邦学习中针对安全聚合的样本重新归属攻击

    SRATTA : Sample Re-ATTribution Attack of Secure Aggregation in Federated Learning. (arXiv:2306.07644v1 [cs.LG])

    [http://arxiv.org/abs/2306.07644](http://arxiv.org/abs/2306.07644)

    SRATTA是一个新型的联邦学习攻击，可以在安全聚合下恢复客户端样本数据并将其按客户端分组，对联邦学习构成重要的安全威胁，需要客户端积极保护隐私并采取反制措施。

    

    我们考虑了一个跨边缘联邦学习（FL）设置，在这个设置中，使用FedAvg训练了一个具有完全连接的第一层的机器学习模型，该模型在不同的客户端和中央服务器之间进行训练，并且可以使用安全聚合（SA）进行聚合步骤。我们提出了SRATTA攻击，仅依赖于聚合模型，根据现实假设，（i）从不同的客户端恢复数据样本，并且（ii）将来自同一客户端的数据样本组合在一起。虽然在FL设置中已经探索了样本恢复，但尽管使用了SA，将样本按客户分组的能力仍然是新颖的。这对于FL构成了重要的未预见安全威胁，并有效地破坏了SA。我们展示了SRATTA的理论基础，并且可以在实际模型和数据集上使用。我们还提出了反制措施，并声称客户端应该在训练期间发挥积极作用以保证其隐私。

    We consider a cross-silo federated learning (FL) setting where a machine learning model with a fully connected first layer is trained between different clients and a central server using FedAvg, and where the aggregation step can be performed with secure aggregation (SA). We present SRATTA an attack relying only on aggregated models which, under realistic assumptions, (i) recovers data samples from the different clients, and (ii) groups data samples coming from the same client together. While sample recovery has already been explored in an FL setting, the ability to group samples per client, despite the use of SA, is novel. This poses a significant unforeseen security threat to FL and effectively breaks SA. We show that SRATTA is both theoretically grounded and can be used in practice on realistic models and datasets. We also propose counter-measures, and claim that clients should play an active role to guarantee their privacy during training.
    
[^56]: SqueezeLLM：密集稀疏量化

    SqueezeLLM: Dense-and-Sparse Quantization. (arXiv:2306.07629v1 [cs.CL])

    [http://arxiv.org/abs/2306.07629](http://arxiv.org/abs/2306.07629)

    本文提出了一种基于训练后的量化框架——SqueezeLLM，它不仅可以实现高达3位的无损压缩，而且在相同的内存约束下实现更高的量化性能。

    

    生成式大型语言模型(LLMs)已经证明在广泛领域的任务中取得了非凡的成果。但是由于其前所未有的资源需求，将这些模型用于推理一直是一个巨大的挑战。这导致现有的部署框架需要使用多GPU推理管道，这通常是复杂和昂贵的，或者使用更小且性能更低的模型。在这项工作中，我们证明了用于LLMs生成推断的主要瓶颈是内存带宽，而不是计算，尤其是单个批次推理。虽然通过使用减少精度来表示模型权重，量化已经成为一种有前途的解决方案，但是以前的努力通常导致性能下降。为了解决这个问题，我们引入SqueezeLLM，这是一种基于训练后的量化框架，不仅可以实现高达3位的无损压缩，而且在相同的内存约束下实现更高的量化性能。

    Generative Large Language Models (LLMs) have demonstrated remarkable results for a wide range of tasks. However, deploying these models for inference has been a significant challenge due to their unprecedented resource requirements. This has forced existing deployment frameworks to use multi-GPU inference pipelines, which are often complex and costly, or to use smaller and less performant models. In this work, we demonstrate that the main bottleneck for generative inference with LLMs is memory bandwidth, rather than compute, specifically for single batch inference. While quantization has emerged as a promising solution by representing model weights with reduced precision, previous efforts have often resulted in notable performance degradation. To address this, we introduce SqueezeLLM, a post-training quantization framework that not only enables lossless compression to ultra-low precisions of up to 3-bit, but also achieves higher quantization performance under the same memory constraint
    
[^57]: 语言模型中出现的类人直觉行为和推理偏差——以及在GPT-4中消失。

    Human-Like Intuitive Behavior and Reasoning Biases Emerged in Language Models -- and Disappeared in GPT-4. (arXiv:2306.07622v1 [cs.CL])

    [http://arxiv.org/abs/2306.07622](http://arxiv.org/abs/2306.07622)

    本研究揭示了大型语言模型（LLMs）具有类人直觉行为和认知错误的特点，而高级语言模型则通过学习避免这类错误并表现出超理性的方式。此外，通过使用心理学研究的方法探测LLMs，可以揭示其新生特性。

    

    大型语言模型（LLM）目前处于将AI系统与人类交流和日常生活交织在一起的前沿。因此，评估它们的新兴能力非常重要。在这项研究中，我们展示了LLM（尤其是GPT-3）表现出惊人的类人直觉行为，以及遵循这种行为而来的认知错误。然而，具有更高认知能力的LLM，特别是ChatGPT和GPT-4，学会了避免屈服于这些错误并表现出超理性的方式。对于我们的实验，我们利用了Cognitive Reflection Test（CRT）及用于研究人类直觉决策的语义幻觉。此外，我们还探究了类人直觉决策的稳定倾向。我们的研究表明，通过心理学方法调查LLM有潜力揭示否则未知的新生特性。

    Large language models (LLMs) are currently at the forefront of intertwining AI systems with human communication and everyday life. Therefore, it is of great importance to evaluate their emerging abilities. In this study, we show that LLMs, most notably GPT-3, exhibit behavior that strikingly resembles human-like intuition -- and the cognitive errors that come with it. However, LLMs with higher cognitive capabilities, in particular ChatGPT and GPT-4, learned to avoid succumbing to these errors and perform in a hyperrational manner. For our experiments, we probe LLMs with the Cognitive Reflection Test (CRT) as well as semantic illusions that were originally designed to investigate intuitive decision-making in humans. Moreover, we probe how sturdy the inclination for intuitive-like decision-making is. Our study demonstrates that investigating LLMs with methods from psychology has the potential to reveal otherwise unknown emergent traits.
    
[^58]: 基于双曲图扩散模型的分子生成

    Hyperbolic Graph Diffusion Model for Molecule Generation. (arXiv:2306.07618v1 [cs.LG])

    [http://arxiv.org/abs/2306.07618](http://arxiv.org/abs/2306.07618)

    本文提出了基于双曲图扩散模型的分子生成方法，可以更全面地捕捉分子的内部非欧几里德结构，实现数据生成，并提取复杂几何特征的能力。

    

    最近，扩散模型在数据生成方面取得了显著的成果，例如生成高质量的图像。然而，化学分子通常具有复杂的非欧几里德空间结构，其行为动态变化且难以预测。大多数现有的扩散模型高度依赖于计算欧几里德空间中的概率分布，即高斯分布，不能捕捉分子的内部非欧几里德结构，特别是分子所表示的隐式流形表面的分层结构。观察到，双曲嵌入空间中的复杂分层结构变得更加明显且更容易被捕捉。为了充分利用扩散模型的数据生成能力和提取复杂几何特征的双曲嵌入的强大能力，我们提出将扩散模型扩展到双曲流形上进行分子生成，即基于双曲图扩散模型的分子生成。

    Recently, diffusion models have achieved remarkable performance in data generation, e.g., generating high-quality images. Nevertheless, chemistry molecules often have complex non-Euclidean spatial structures, with the behavior changing dynamically and unpredictably. Most existing diffusion models highly rely on computing the probability distribution, i.e., Gaussian distribution, in Euclidean space, which cannot capture internal non-Euclidean structures of molecules, especially the hierarchical structures of the implicit manifold surface represented by molecules. It has been observed that the complex hierarchical structures in hyperbolic embedding space become more prominent and easier to be captured. In order to leverage both the data generation power of diffusion models and the strong capability to extract complex geometric features of hyperbolic embedding, we propose to extend the diffusion model to hyperbolic manifolds for molecule generation, namely, Hyperbolic Graph Diffusion Mode
    
[^59]: 用一个简单baseline重新思考对抗训练

    Rethinking Adversarial Training with A Simple Baseline. (arXiv:2306.07613v1 [cs.CV])

    [http://arxiv.org/abs/2306.07613](http://arxiv.org/abs/2306.07613)

    这篇论文提出了一种简单的对抗训练baseline，使用了重新调整的平方损失、循环学习率和基于擦除的数据增强等方法，在对抗和自然准确度之间产生了良好的平衡，并可有效降低robust overfitting风险，表现与最先进方法媲美。

    

    我们使用了一种简单但有效的baseline方法，针对CIFAR和SVHN数据集在RobustBench上获得了有竞争力的结果。我们的方法包括一个训练协议，该协议集成了重新调整的平方损失，循环学习率和基于擦除的数据增强。我们实现的结果可与使用最先进技术训练的模型相媲美，这目前是对抗训练的主要选择。我们的baseline被称为SimpleAT，产生了三个新颖的经验洞察：(i) 通过转换为平方损失，准确度可与使用事实上的训练协议加数据增强所获得的准确度相当。 (ii) 一个循环学习率是一个很好的scheduler，可以有效降低robust overfitting的风险。 (iii) 在模型训练过程中使用重新调整的平方损失可以在对抗和自然准确度之间产生良好的平衡。总的来说，我们的实验结果表明，SimpleAT有效地缓解了robust overfitting，并始终实现了与对抗训练最先进方法相媲美的竞争表现。

    We report competitive results on RobustBench for CIFAR and SVHN using a simple yet effective baseline approach. Our approach involves a training protocol that integrates rescaled square loss, cyclic learning rates, and erasing-based data augmentation. The outcomes we have achieved are comparable to those of the model trained with state-of-the-art techniques, which is currently the predominant choice for adversarial training. Our baseline, referred to as SimpleAT, yields three novel empirical insights. (i) By switching to square loss, the accuracy is comparable to that obtained by using both de-facto training protocol plus data augmentation. (ii) One cyclic learning rate is a good scheduler, which can effectively reduce the risk of robust overfitting. (iii) Employing rescaled square loss during model training can yield a favorable balance between adversarial and natural accuracy. In general, our experimental results show that SimpleAT effectively mitigates robust overfitting and consist
    
[^60]: 面向复杂几何低温等离子体模拟的机器学习泊松解算器

    Towards a Machine-Learned Poisson Solver for Low-Temperature Plasma Simulations in Complex Geometries. (arXiv:2306.07604v1 [physics.comp-ph])

    [http://arxiv.org/abs/2306.07604](http://arxiv.org/abs/2306.07604)

    本文开发了一种通用的机器学习泊松求解器，能较好地解决复杂2D反应堆几何形状的LTP模拟中Poisson方程计算成本高等问题。

    

    泊松方程在许多物理系统的建模中发挥着重要的作用。在电静自洽低温等离子体（LTP）模拟中，泊松方程在每个模拟时间步骤中得到解决，这可能会导致整个模拟的计算成本相当大。本文描述了一种通用的机器学习泊松求解器的开发，特别是针对结构化笛卡尔网格上复杂2D反应堆几何形状的LTP模拟要求而设计的。这里，反应堆几何形状可以包括内部电极和常见LTP模拟中的介电材料。该方法利用混合CNN-transformer网络架构结合加权多项式损失函数。我们使用高度随机化的合成数据训练网络，以确保所学求解器对未见过的反应堆几何形状有普适性。结果表明，学习求解器能够产生定量和定性上准确的解决方案。

    Poisson's equation plays an important role in modeling many physical systems. In electrostatic self-consistent low-temperature plasma (LTP) simulations, Poisson's equation is solved at each simulation time step, which can amount to a significant computational cost for the entire simulation. In this paper, we describe the development of a generic machine-learned Poisson solver specifically designed for the requirements of LTP simulations in complex 2D reactor geometries on structured Cartesian grids. Here, the reactor geometries can consist of inner electrodes and dielectric materials as often found in LTP simulations. The approach leverages a hybrid CNN-transformer network architecture in combination with a weighted multiterm loss function. We train the network using highly-randomized synthetic data to ensure the generalizability of the learned solver to unseen reactor geometries. The results demonstrate that the learned solver is able to produce quantitatively and qualitatively accura
    
[^61]: 大型语言模型有时生成纯负反馈文本

    Large Language Models Sometimes Generate Purely Negatively-Reinforced Text. (arXiv:2306.07567v1 [cs.LG])

    [http://arxiv.org/abs/2306.07567](http://arxiv.org/abs/2306.07567)

    大型语言模型有时会从仅包含负奖励的例子中学习，导致生成类似泄漏密码或安全漏洞等敏感信息的文本

    

    在使用对抗性训练时，通常会训练反对最严重失败的案例。然而，这可能会意味着使用包含敏感信息（例如泄露的密码或安全漏洞）的案例作为训练数据。我们可能会认为使用梯度下降算法训练的语言模型永远不会生成仅在与最低奖励相关联的示例中出现的文本片段。本文表明这种假设是错误的：在某些情况下，大型语言模型确实从这种纯负反馈的示例中学习到了东西。我们提出了一种特定的训练设置，使得Pythia-160M能够生成密码的概率略高于随机，尽管仅在对模型不输出这些密码的示例中展示了这些密码。我们的代码可在https://github.com/FabienRoger/Learning-From-Negative-Examples上找到。

    When using adversarial training, it is common practice to train against the most egregious failures. However, this might imply using examples with sensitive information (such as leaked passwords or security vulnerabilities) as training data. One might assume that language models trained with gradient descent never generate text snippets which were only present in examples associated with the lowest possible reward. In this paper, we show that this assumption is wrong: in some situations, large language models do learn from such negatively-reinforced examples. We present a specific training setup that enables Pythia-160M to generate passwords with a probability slightly greater than chance, despite only showing it these passwords on examples where the model is incentivized to not output these passwords. Our code is available at https://github.com/FabienRoger/Learning-From-Negative-Examples
    
[^62]: 学习选择标签下的异质决策者：一种工具变量方法

    Learning under Selective Labels with Heterogeneous Decision-makers: An Instrumental Variable Approach. (arXiv:2306.07566v1 [stat.ML])

    [http://arxiv.org/abs/2306.07566](http://arxiv.org/abs/2306.07566)

    本文提出了一种处理选择性标记数据的学习问题的方法。通过利用历史决策由一组异质决策者做出的事实，我们建立了一种有原理的工具变量框架，并提出了一种加权学习方法，用于学习预测规则。

    

    我们研究了在选择性标记数据下的学习问题。这种问题在历史决策导致结果仅部分标记时出现。标记数据分布可能与整体人群有显著差异，特别是当历史决策和目标结果可以同时受某些未观察到的因素影响时。因此，仅基于标记数据进行学习可能会导致在整体人群中的严重偏差。我们的论文通过利用许多应用中历史决策由一组异质决策者做出的事实来解决此挑战。具体而言，我们在一个有原理的工具变量框架下分析了这种设置。我们建立了满足观察到的数据时任何给定预测规则的全体风险的点识别条件，并在点识别失败时提供了尖锐的风险界限。我们进一步提出了一种加权学习方法，用于学习预测规则。

    We study the problem of learning with selectively labeled data, which arises when outcomes are only partially labeled due to historical decision-making. The labeled data distribution may substantially differ from the full population, especially when the historical decisions and the target outcome can be simultaneously affected by some unobserved factors. Consequently, learning with only the labeled data may lead to severely biased results when deployed to the full population. Our paper tackles this challenge by exploiting the fact that in many applications the historical decisions were made by a set of heterogeneous decision-makers. In particular, we analyze this setup in a principled instrumental variable (IV) framework. We establish conditions for the full-population risk of any given prediction rule to be point-identified from the observed data and provide sharp risk bounds when the point identification fails. We further propose a weighted learning approach that learns prediction ru
    
[^63]: Galactic: 将端到端强化学习扩展到每秒 100k 步的重组问题的规模化研究

    Galactic: Scaling End-to-End Reinforcement Learning for Rearrangement at 100k Steps-Per-Second. (arXiv:2306.07552v1 [cs.LG])

    [http://arxiv.org/abs/2306.07552](http://arxiv.org/abs/2306.07552)

    Galactic是一个针对室内物体重排问题的大规模仿真和强化学习框架。这个框架可以在每秒 100k 步上运行，比其他相似框架快很多。

    

    我们提出了 Galactic，一个用于室内环境中机器人移动操作的大规模仿真和强化学习（RL）框架。具体来说，我们在一个家用环境中生成 Fetch 机器人（带有移动基座、7 自由度机械臂、RGBD 相机、自运动和板载传感器），并要求它重新排列物体 - 通过导航到物体、拾取它、导航到目标位置，然后将物体放置在目标位置上。Galactic 速度快。在仿真速度（渲染+物理）方面，Galactic 在 8-GPU 节点上实现了每秒 421,000 步（SPS），比 Habitat 2.0 快了 54 倍（7699 SPS）。更重要的是，Galactic 被设计用于优化整个渲染+物理+RL 的相互作用，因为相互作用中的任何瓶颈都会减慢训练。在仿真+RL 速度（渲染+物理+推理+学习）方面，Galactic 实现了每秒超过 108,000 SPS，比 Habitat 2.0 快了 88 倍（1243 SPS）。这些巨大的加速不仅显著加快了训练速度，还使 RL 能够在未来的机器人操作任务中实现更高的成功率和效率。

    We present Galactic, a large-scale simulation and reinforcement-learning (RL) framework for robotic mobile manipulation in indoor environments. Specifically, a Fetch robot (equipped with a mobile base, 7DoF arm, RGBD camera, egomotion, and onboard sensing) is spawned in a home environment and asked to rearrange objects - by navigating to an object, picking it up, navigating to a target location, and then placing the object at the target location.  Galactic is fast. In terms of simulation speed (rendering + physics), Galactic achieves over 421,000 steps-per-second (SPS) on an 8-GPU node, which is 54x faster than Habitat 2.0 (7699 SPS). More importantly, Galactic was designed to optimize the entire rendering + physics + RL interplay since any bottleneck in the interplay slows down training. In terms of simulation+RL speed (rendering + physics + inference + learning), Galactic achieves over 108,000 SPS, which 88x faster than Habitat 2.0 (1243 SPS).  These massive speed-ups not only drasti
    
[^64]: 异构奖励方差下的定长最优臂识别问题研究

    Fixed-Budget Best-Arm Identification with Heterogeneous Reward Variances. (arXiv:2306.07549v1 [cs.LG])

    [http://arxiv.org/abs/2306.07549](http://arxiv.org/abs/2306.07549)

    本文提出了两种改进BAI算法，SHVar适用于已知奖励方差情况，SHAdaVar适用于未知奖励方差情况，算法通过在不同臂之间分配不同比例的预算，更多地选择方差更高的臂，SHAdaVar通过过度估计未知奖励方差以贪心地分配预算。创新之处在于无需关闭预算分配问题的解决方案的臂拉动次数下界。

    

    本文研究了在异构奖励方差下的定长最优臂识别问题。我们提出了两种应用于不同奖励方差情况下的改进BAI算法：SHVar适用于已知奖励方差情况，SHAdaVar适用于未知奖励方差情况。我们的算法通过在不同臂之间分配不同比例的预算，更多地选择方差更高的臂。我们的算法创新在于SHAdaVar的设计，其通过过度估计未知奖励方差以贪心地分配预算。我们分别对SHVar和SHAdaVar中误识别最优臂的概率进行限制。我们的分析依赖于新颖的无需关闭预算分配问题的解决方案的臂拉动次数下界。由于我们的一个预算分配问题类似于未知方差的最优实验设计，因此我们认为我们的结果具有广泛的兴趣。我们的实验验证了我们算法的有效性。

    We study the problem of best-arm identification (BAI) in the fixed-budget setting with heterogeneous reward variances. We propose two variance-adaptive BAI algorithms for this setting: SHVar for known reward variances and SHAdaVar for unknown reward variances. Our algorithms rely on non-uniform budget allocations among the arms where the arms with higher reward variances are pulled more often than those with lower variances. The main algorithmic novelty is in the design of SHAdaVar, which allocates budget greedily based on overestimating the unknown reward variances. We bound probabilities of misidentifying the best arms in both SHVar and SHAdaVar. Our analyses rely on novel lower bounds on the number of pulls of an arm that do not require closed-form solutions to the budget allocation problem. Since one of our budget allocation problems is analogous to the optimal experiment design with unknown variances, we believe that our results are of a broad interest. Our experiments validate ou
    
[^65]: 关于实现最优对抗测试误差的研究

    On Achieving Optimal Adversarial Test Error. (arXiv:2306.07544v1 [cs.LG])

    [http://arxiv.org/abs/2306.07544](http://arxiv.org/abs/2306.07544)

    本文提出了最优对抗预测器的各种基本特性，并结合新的Rademacher复杂度界限证明了，在浅层网络上进行对抗训练，采用早停和理想的最优对手，能够实现最优对抗测试误差。

    

    本文首先阐述了最优对抗预测器的各种基本特性：最优对抗凸预测器的结构、将对抗凸损失与对抗0-1损失相关联的界限以及连续预测器可以在凸和0-1损失下无限接近最优对抗误差。本文还将这些结果与对抗训练在初始化附近的新Rademacher复杂度界限相结合，证明了对于一般的数据分布和扰动集，在浅层网络上进行对抗训练，采用早停和理想的最优对手，能够实现最优对抗测试误差。相比之下，先前的理论工作只考虑了特定的数据分布或仅提供了训练误差的保证。

    We first elucidate various fundamental properties of optimal adversarial predictors: the structure of optimal adversarial convex predictors in terms of optimal adversarial zero-one predictors, bounds relating the adversarial convex loss to the adversarial zero-one loss, and the fact that continuous predictors can get arbitrarily close to the optimal adversarial error for both convex and zero-one losses. Applying these results along with new Rademacher complexity bounds for adversarial training near initialization, we prove that for general data distributions and perturbation sets, adversarial training on shallow networks with early stopping and an idealized optimal adversary is able to achieve optimal adversarial test error. By contrast, prior theoretical work either considered specialized data distributions or only provided training error guarantees.
    
[^66]: 一种简单统一的基于不确定性引导的离线到在线强化学习框架

    A Simple Unified Uncertainty-Guided Framework for Offline-to-Online Reinforcement Learning. (arXiv:2306.07541v1 [cs.LG])

    [http://arxiv.org/abs/2306.07541](http://arxiv.org/abs/2306.07541)

    SUNG是一种基于不确定性引导的离线到在线强化学习框架，在通过量化不确定性进行探索和应用保守Q值估计的指导下，实现了高效的老化强化学习。

    

    离线强化学习为依靠数据驱动范例学习智能体提供了一种有前途的解决方案。 然而，受限于离线数据集的有限质量，其性能常常不够优秀。因此，在部署之前通过额外的在线交互进一步微调智能体是有必要的。不幸的是，由于受到两个主要挑战的制约，即受限的探索行为和状态-动作分布偏移，离线到在线强化学习可能具有挑战性。为此，我们提出了一个简单统一的基于不确定性引导的（SUNG）框架，其通过不确定性工具自然地统一了这两个挑战的解决方案。具体而言，SUNG通过基于VAE的状态-动作访问密度估计器量化不确定性。为了促进高效探索，SUNG提出了一种实用的乐观探索策略，以选择具有高价值和高不确定性的信息动作。此外，SUNG通过在不确定性指导下应用保守Q值估计来开发一种自适应利用方法。我们在Atari和MuJoCo基准测试上进行了全面的实验，结果表明SUNG始终优于最先进的离线到在线强化学习方法，并在许多任务中实现了接近在线学习的性能。

    Offline reinforcement learning (RL) provides a promising solution to learning an agent fully relying on a data-driven paradigm. However, constrained by the limited quality of the offline dataset, its performance is often sub-optimal. Therefore, it is desired to further finetune the agent via extra online interactions before deployment. Unfortunately, offline-to-online RL can be challenging due to two main challenges: constrained exploratory behavior and state-action distribution shift. To this end, we propose a Simple Unified uNcertainty-Guided (SUNG) framework, which naturally unifies the solution to both challenges with the tool of uncertainty. Specifically, SUNG quantifies uncertainty via a VAE-based state-action visitation density estimator. To facilitate efficient exploration, SUNG presents a practical optimistic exploration strategy to select informative actions with both high value and high uncertainty. Moreover, SUNG develops an adaptive exploitation method by applying conserva
    
[^67]: TART: 一种面向任务无关推理的即插即用Transformer模块

    TART: A plug-and-play Transformer module for task-agnostic reasoning. (arXiv:2306.07536v1 [cs.LG])

    [http://arxiv.org/abs/2306.07536](http://arxiv.org/abs/2306.07536)

    TART提出了一种即插即用的Transformer模块，它能够在没有任务特定训练或微调的情况下，在不同推理目标之间进行泛化。

    

    大型语言模型(LLMs)表现出上下文学习能力,能让同一模型执行多个任务,而无需进行任何特定任务的训练。相比之下,传统的自适应方法(如微调)会针对每个特定任务修改基础模型。然而,即使在使用相同示例的情况下,上下文学习一直表现不佳,而大多数现有方法(如提示工程)侧重于LLM的学习表示，以弥补性能差距,而我们的分析实际上揭示了LLM表示包含足够的信息来做出好的预测。因此,我们关注LLM的推理能力,并展示该性能差距存在是由于它们无法执行简单的概率推理任务。这引发了一个有趣的问题: LLM实际上能否以任务无关的方式学习如何推理？我们肯定地回答了这个问题,并提出了TART，它以即插即用的方式在不进行任务特定训练或微调的情况下横跨不同推理目标进行泛化。

    Large language models (LLMs) exhibit in-context learning abilities which enable the same model to perform several tasks without any task-specific training. In contrast, traditional adaptation approaches, such as fine-tuning, modify the underlying models for each specific task. In-context learning, however, consistently underperforms task-specific tuning approaches even when presented with the same examples. While most existing approaches (e.g., prompt engineering) focus on the LLM's learned representations to patch this performance gap, our analysis actually reveal that LLM representations contain sufficient information to make good predictions. As such, we focus on the LLM's reasoning abilities and demonstrate that this performance gap exists due to their inability to perform simple probabilistic reasoning tasks. This raises an intriguing question: Are LLMs actually capable of learning how to reason in a task-agnostic manner? We answer this in the affirmative and propose TART which ge
    
[^68]: 统一的非同策略学习排序：强化学习视角

    Unified Off-Policy Learning to Rank: a Reinforcement Learning Perspective. (arXiv:2306.07528v1 [cs.LG])

    [http://arxiv.org/abs/2306.07528](http://arxiv.org/abs/2306.07528)

    本文提出了点击模型不可知的统一非同策略学习排序（CUOLR）方法，通过离线强化学习（RL）直接学习最优排名，可以轻松地应用于各种点击模型。

    

    非同策略学习排序（LTR）旨在通过已部署的记录策略收集的数据优化排名器。然而，现有的非同策略学习排序方法经常对用户如何生成点击数据即点击模型进行假设，因此需要根据不同的点击模型专门调整他们的方法。在本文中，我们将排名过程在一般随机点击模型下统一为马尔可夫决策过程（MDP），通过离线强化学习（RL），可以直接学习最优排名。在此基础上，我们利用离线RL技术进行非同策略LTR，并提出点击模型不可知的统一非同策略学习排序（CUOLR）方法，该方法可以轻松地应用于各种点击模型。通过对MDP的专门制定，我们证明了离线RL算法可以适应各种点击模型，而无需复杂的去偏倚技术和先验知识。在各种大规模数据集上的实验结果都证明了我们方法的有效性。

    Off-policy Learning to Rank (LTR) aims to optimize a ranker from data collected by a deployed logging policy. However, existing off-policy learning to rank methods often make strong assumptions about how users generate the click data, i.e., the click model, and hence need to tailor their methods specifically under different click models. In this paper, we unified the ranking process under general stochastic click models as a Markov Decision Process (MDP), and the optimal ranking could be learned with offline reinforcement learning (RL) directly. Building upon this, we leverage offline RL techniques for off-policy LTR and propose the Click Model-Agnostic Unified Off-policy Learning to Rank (CUOLR) method, which could be easily applied to a wide range of click models. Through a dedicated formulation of the MDP, we show that offline RL algorithms can adapt to various click models without complex debiasing techniques and prior knowledge of the model. Results on various large-scale datasets
    
[^69]: 物理动态系统扩散模型中的用户定义事件采样和不确定性量化

    User-defined Event Sampling and Uncertainty Quantification in Diffusion Models for Physical Dynamical Systems. (arXiv:2306.07526v1 [cs.LG])

    [http://arxiv.org/abs/2306.07526](http://arxiv.org/abs/2306.07526)

    本文提出了一种条件得分函数的概率近似方案，可以用于混沌动力系统的预测和提供不确定性量化。

    

    扩散模型是一类概率生成模型，已广泛用作图像处理任务的先验，如文本条件生成和修复。我们证明这些模型可以适应于混沌动力系统的预测和提供不确定性量化。在这些应用中，扩散模型可以隐式表示关于异常值和极端事件的知识；但是，通过条件采样或测量概率来查询该知识却异常困难。现有的推理条件采样方法主要旨在强制执行约束条件，但这对于匹配分布的统计数据或计算选择事件的概率是不充分的。为了实现这些目标，最理想的方法是使用条件得分函数，但其计算通常是不可解的。在本研究中，我们开发了一种条件得分函数的概率近似方案，可以证明其收敛性。

    Diffusion models are a class of probabilistic generative models that have been widely used as a prior for image processing tasks like text conditional generation and inpainting. We demonstrate that these models can be adapted to make predictions and provide uncertainty quantification for chaotic dynamical systems. In these applications, diffusion models can implicitly represent knowledge about outliers and extreme events; however, querying that knowledge through conditional sampling or measuring probabilities is surprisingly difficult. Existing methods for conditional sampling at inference time seek mainly to enforce the constraints, which is insufficient to match the statistics of the distribution or compute the probability of the chosen events. To achieve these ends, optimally one would use the conditional score function, but its computation is typically intractable. In this work, we develop a probabilistic approximation scheme for the conditional score function which provably conver
    
[^70]: 基于碰撞动量的深度强化学习对抗行人建模

    Using Collision Momentum in Deep Reinforcement Learning Based Adversarial Pedestrian Modeling. (arXiv:2306.07525v1 [cs.RO])

    [http://arxiv.org/abs/2306.07525](http://arxiv.org/abs/2306.07525)

    该研究提出了一种基于碰撞动量的深度强化学习算法，能够更好地发现自动驾驶算法在极端情况下的缺陷并加以纠正。

    

    最近有关行人仿真的研究通常旨在开发各种情况下的现实行为，但现有算法生成识别自动驾驶车辆在极端和不可能情况下以及边缘情况下性能和缺陷的行为具有挑战性。为此，需要专门的行人行为算法。目前的研究侧重于使用社交力模型和基于强化学习的模型生成真实轨迹。然而，我们提出了一种针对碰撞的强化学习算法，更好地揭示了自动驾驶控制器的独特失效模式。我们的算法高效且生成更严重的碰撞，允许发现和纠正复杂和多样情景中自主驾驶算法的问题之处。

    Recent research in pedestrian simulation often aims to develop realistic behaviors in various situations, but it is challenging for existing algorithms to generate behaviors that identify weaknesses in automated vehicles' performance in extreme and unlikely scenarios and edge cases. To address this, specialized pedestrian behavior algorithms are needed. Current research focuses on realistic trajectories using social force models and reinforcement learning based models. However, we propose a reinforcement learning algorithm that specifically targets collisions and better uncovers unique failure modes of automated vehicle controllers. Our algorithm is efficient and generates more severe collisions, allowing for the identification and correction of weaknesses in autonomous driving algorithms in complex and varied scenarios.
    
[^71]: 不同机器学习技术下的脑运动想象解码研究

    Decoding Brain Motor Imagery with various Machine Learning techniques. (arXiv:2306.07519v1 [cs.HC])

    [http://arxiv.org/abs/2306.07519](http://arxiv.org/abs/2306.07519)

    本文研究运用不同的机器学习方法解码运动想象，基于证据累积实时预测受试者的意图。

    

    运动想象（MI）是被用于BCI（脑机接口）实验中的一种已被广泛记录的技术，用于调节大脑皮层以及周围区域的脑活动。在我们的项目中，我们进行了一项实验，指导受试者进行被分为右侧和左侧两类的运动想象。实验使用了两种不同类型（凝胶和POLiTag）的电极，并采集了每位受试者的数据。本文中，我们将应用不同的机器学习（ML）方法，基于离线训练数据创建解码器，利用证据累积实时预测受试者的意图。

    Motor imagery (MI) is a well-documented technique used by subjects in BCI (Brain Computer Interface) experiments to modulate brain activity within the motor cortex and surrounding areas of the brain. In our term project, we conducted an experiment in which the subjects were instructed to perform motor imagery that would be divided into two classes (Right and Left). Experiments were conducted with two different types of electrodes (Gel and POLiTag) and data for individual subjects was collected. In this paper, we will apply different machine learning (ML) methods to create a decoder based on offline training data that uses evidence accumulation to predict a subject's intent from their modulated brain signals in real-time.
    
[^72]: 自训练实现嘈杂正-无标记学习，在思辨性知识图谱推理中应用

    Noisy Positive-Unlabeled Learning with Self-Training for Speculative Knowledge Graph Reasoning. (arXiv:2306.07512v1 [cs.LG])

    [http://arxiv.org/abs/2306.07512](http://arxiv.org/abs/2306.07512)

    本文提出了一种嘈杂正-无标记学习问题的变分框架nPUGraph，并引入自训练策略，以应对真实世界知识图谱上的思辨性推理任务。实验结果表明了我们提出的方法的有效性。

    

    本文主要研究真实世界知识图谱（KG）上的思辨性推理任务，其中包括了假负问题（即潜在的真实事实被排除）和假正问题（即不可靠或过时的事实被包括）。现有的方法在思辨性推理能力上表现不佳，因为它们假设一个事实是否正确仅由它在KG中的存在确定，这使得它们容易受到假阴性/假阳性问题的影响。新的推理任务被规定为一种嘈杂正-无标记学习问题。我们提出了一种变分框架nPUGraph，它共同估计已收集和未收集事实的正确性（我们称之为“标签后验概率”），并在训练期间更新模型参数。标签后验概率估计从两个方面促进了思辨性推理。首先，它提高了标签后验概率感知的图表征对抗假阳性关系的鲁棒性。其次，它确定了误导性的未标记数据，并减少了其对模型训练的影响。我们还介绍了一种利用未标记数据的自训练策略，进一步提高了模型的推理能力。在两个知识图推理任务基准测试上的实验结果证明了我们提出的方法的有效性。

    This paper studies speculative reasoning task on real-world knowledge graphs (KG) that contain both \textit{false negative issue} (i.e., potential true facts being excluded) and \textit{false positive issue} (i.e., unreliable or outdated facts being included). State-of-the-art methods fall short in the speculative reasoning ability, as they assume the correctness of a fact is solely determined by its presence in KG, making them vulnerable to false negative/positive issues. The new reasoning task is formulated as a noisy Positive-Unlabeled learning problem. We propose a variational framework, namely nPUGraph, that jointly estimates the correctness of both collected and uncollected facts (which we call \textit{label posterior}) and updates model parameters during training. The label posterior estimation facilitates speculative reasoning from two perspectives. First, it improves the robustness of a label posterior-aware graph encoder against false positive links. Second, it identifies mis
    
[^73]: PaVa: 一种新颖的基于路径谷寻找的聚类算法

    PaVa: a novel Path-based Valley-seeking clustering algorithm. (arXiv:2306.07503v1 [cs.LG])

    [http://arxiv.org/abs/2306.07503](http://arxiv.org/abs/2306.07503)

    PaVa是一种基于路径谷寻找的新型聚类算法，可以高精度、高效地发现任意形状的聚类。

    

    聚类方法被应用于越来越多涉及更复杂数据集的场景，其中聚类的形状往往是任意的。本文提出了一种新颖的基于路径谷寻找的聚类算法，旨在寻找聚类之间的谷，并单独提取聚类。该算法采用了三个关键技术。首先，采用路径距离（min-max距离）将聚类之间的不规则边界（即密度谷）转换为完美的球形壳。其次，采用适当的密度测量方法$k$-distance来对最小生成树进行调整，从而计算出强健的min-max距离。然后，通过确定谷的中心和半径来寻找转换后的密度谷。通过在距离变换后将聚类包装在球形壳中，使得即使在聚类形状任意的情况下，提取过程也能够高效率地进行。其次，调整后的最小生成树有助于降低数据集噪音和异常值的影响。最后，通过提取球形壳之间的谷，我们可以高精度高效地发现任意形状的聚类。

    Clustering methods are being applied to a wider range of scenarios involving more complex datasets, where the shapes of clusters tend to be arbitrary. In this paper, we propose a novel Path-based Valley-seeking clustering algorithm for arbitrarily shaped clusters. This work aims to seek the valleys among clusters and then individually extract clusters. Three vital techniques are used in this algorithm. First, path distance (minmax distance) is employed to transform the irregular boundaries among clusters, that is density valleys, into perfect spherical shells. Second, a suitable density measurement, $k$-distance, is employed to make adjustment on Minimum Spanning Tree, by which a robust minmax distance is calculated. Third, we seek the transformed density valleys by determining their centers and radius. First, the clusters are wrapped in spherical shells after the distance transformation, making the extraction process efficient even with clusters of arbitrary shape. Second, adjusted Mi
    
[^74]: 通过标签错误检测和重写提高基于意见的问答系统

    Improving Opinion-based Question Answering Systems Through Label Error Detection and Overwrite. (arXiv:2306.07499v1 [cs.CL])

    [http://arxiv.org/abs/2306.07499](http://arxiv.org/abs/2306.07499)

    本文提出了一种名为LEDO的模型-不可知且计算高效的框架，能够有效解决标签错误问题，并将其应用于意见问答系统中，提高了该系统在各个核心模型中的准确性。

    

    标签错误是注释数据中普遍存在的问题。大量的标签错误会严重降低深度学习模型的质量。现有的解决标签错误问题的方法主要集中在分类任务上，要么依赖于任务特定的架构，要么需要非常复杂的额外计算，这些都不适合工业使用。在本文中，我们提出了LEDO：一种面向模型的、计算效率高的标签错误检测和重写框架。LEDO基于 Monte Carlo Dropout 和不确定性度量，可以很容易地推广到多个任务和数据集。将LEDO应用于工业意见问答系统中，证明它能有效提高所有核心模型的准确性。具体而言，LEDO为检索模型带来1.1％的MRR增益，为机器阅读理解模型提高1.5％的PR AUC，为排名器的平均精度提高0.9％。

    Label error is a ubiquitous problem in annotated data. Large amounts of label error substantially degrades the quality of deep learning models. Existing methods to tackle the label error problem largely focus on the classification task, and either rely on task specific architecture or require non-trivial additional computations, which is undesirable or even unattainable for industry usage. In this paper, we propose LEDO: a model-agnostic and computationally efficient framework for Label Error Detection and Overwrite. LEDO is based on Monte Carlo Dropout combined with uncertainty metrics, and can be easily generalized to multiple tasks and data sets. Applying LEDO to an industry opinion-based question answering system demonstrates it is effective at improving accuracy in all the core models. Specifically, LEDO brings 1.1% MRR gain for the retrieval model, 1.5% PR AUC improvement for the machine reading comprehension model, and 0.9% rise in the Average Precision for the ranker, on top of
    
[^75]: GQFedWAvg：基于优化的量化联邦学习在一般的边缘计算系统中的应用

    GQFedWAvg: Optimization-Based Quantized Federated Learning in General Edge Computing Systems. (arXiv:2306.07497v1 [cs.LG])

    [http://arxiv.org/abs/2306.07497](http://arxiv.org/abs/2306.07497)

    本论文提出了一种适用于在一般的边缘计算系统中的基于优化的量化FL算法，采用新的随机量化方案和加权平均本地模型更新的广义小批量随机梯度下降方法在全局模型聚合中，以适应在工作节点具有均匀或非均匀的计算和通信资源的情况。

    

    在实际边缘计算系统中，联邦学习（FL）的最佳实现一直是一个突出的问题。本文提出了一种基于优化的量化FL算法，可以在工作节点具有均匀或非均匀的计算和通信资源的一般边缘计算系统中适当地适应。具体而言，我们首先提出了一种新的随机量化方案并分析了其性质。然后，我们提出了一种通用的量化FL算法，即GQFedWAvg。具体而言，GQFedWAvg将所提出的量化方案应用于智能选择的模型更新相关向量，并采用加权平均本地模型更新的广义小批量随机梯度下降（SGD）方法在全局模型聚合中。此外，GQFedWAvg有一些可调整的算法参数，可以灵活地适应服务器和工作节点的计算和通信资源。我们还分析了GQFedWAvg的收敛性。接下来，我们优化该算法。

    The optimal implementation of federated learning (FL) in practical edge computing systems has been an outstanding problem. In this paper, we propose an optimization-based quantized FL algorithm, which can appropriately fit a general edge computing system with uniform or nonuniform computing and communication resources at the workers. Specifically, we first present a new random quantization scheme and analyze its properties. Then, we propose a general quantized FL algorithm, namely GQFedWAvg. Specifically, GQFedWAvg applies the proposed quantization scheme to quantize wisely chosen model update-related vectors and adopts a generalized mini-batch stochastic gradient descent (SGD) method with the weighted average local model updates in global model aggregation. Besides, GQFedWAvg has several adjustable algorithm parameters to flexibly adapt to the computing and communication resources at the server and workers. We also analyze the convergence of GQFedWAvg. Next, we optimize the algorithm 
    
[^76]: 通过组合优化学习非归一化统计模型

    Learning Unnormalized Statistical Models via Compositional Optimization. (arXiv:2306.07485v1 [cs.LG])

    [http://arxiv.org/abs/2306.07485](http://arxiv.org/abs/2306.07485)

    本文介绍了一种通过组合优化的方式学习非归一化统计模型的方法，采用噪声分布处理分区函数，具有优化效率和泛化性能更好的特点。

    

    学习非归一化统计模型（如能量模型）由于处理分区函数的复杂性而具有计算上的挑战。为了避开这种复杂性，噪声对比估计（NCE）已被提出来将目标公式化为实际数据和人为噪声的逻辑损失。然而，正如以前的研究所发现的那样，由于其平坦的损失函数图景和缓慢的收敛速度，NCE在许多任务中表现较差。本文从组合优化的角度研究了一种直接优化非归一化模型的负对数似然的方法。为了处理分区函数，引入了噪声分布，使得对数分区函数可以被写成一个组合函数，内部函数可以用随机样本估计。因此，目标可以通过随机组合优化算法进行优化。尽管它是一种简单的方法，但我们证明它在学习非归一化统计模型的优化效率和泛化性能方面比NCE更有利。

    Learning unnormalized statistical models (e.g., energy-based models) is computationally challenging due to the complexity of handling the partition function. To eschew this complexity, noise-contrastive estimation~(NCE) has been proposed by formulating the objective as the logistic loss of the real data and the artificial noise. However, as found in previous works, NCE may perform poorly in many tasks due to its flat loss landscape and slow convergence. In this paper, we study it a direct approach for optimizing the negative log-likelihood of unnormalized models from the perspective of compositional optimization. To tackle the partition function, a noise distribution is introduced such that the log partition function can be written as a compositional function whose inner function can be estimated with stochastic samples. Hence, the objective can be optimized by stochastic compositional optimization algorithms. Despite being a simple method, we demonstrate that it is more favorable than
    
[^77]: 使用生成网络复杂体进行多目标分子优化的阿片类药物滥用障碍治疗

    Multi-objective Molecular Optimization for Opioid Use Disorder Treatment Using Generative Network Complex. (arXiv:2306.07484v1 [cs.LG])

    [http://arxiv.org/abs/2306.07484](http://arxiv.org/abs/2306.07484)

    本研究提出了一种深度生成模型，能够高效地生成对多个靶点有效的分子（包括μ、κ和δ阿片受体），并且已经构建了结合亲和力预测器。

    

    阿片类药物滥用障碍（OUD）已成为一个复杂多面的全球公共卫生问题。由于缺乏对各种情况有效的治疗选择，因此迫切需要发现新的药物。本研究提出了一种深度生成模型，将基于随机微分方程（SDE）的扩散建模与预先训练的自动编码器模型的潜在空间相结合。分子生成器能够高效地生成对多个靶点有效的分子，具体包括μ、κ和δ阿片受体。此外，我们评估了生成分子的吸收、分布、代谢、排泄和毒性（ADMET）属性，以确定药物样化合物。为增强某些前导化合物的药代动力学特性，我们采用分子优化方法。我们获得了一组多样的药物样化合物。我们通过将分子细化和拟合，构建了结合亲和力预测器。

    Opioid Use Disorder (OUD) has emerged as a significant global public health issue, with complex multifaceted conditions. Due to the lack of effective treatment options for various conditions, there is a pressing need for the discovery of new medications. In this study, we propose a deep generative model that combines a stochastic differential equation (SDE)-based diffusion modeling with the latent space of a pretrained autoencoder model. The molecular generator enables efficient generation of molecules that are effective on multiple targets, specifically the mu, kappa, and delta opioid receptors. Furthermore, we assess the ADMET (absorption, distribution, metabolism, excretion, and toxicity) properties of the generated molecules to identify drug-like compounds. To enhance the pharmacokinetic properties of some lead compounds, we employ a molecular optimization approach. We obtain a diverse set of drug-like molecules. We construct binding affinity predictors by integrating molecular fin
    
[^78]: 在在线推荐系统中激励高质量内容

    Incentivizing High-Quality Content in Online Recommender Systems. (arXiv:2306.07479v1 [cs.GT])

    [http://arxiv.org/abs/2306.07479](http://arxiv.org/abs/2306.07479)

    本文研究了在线推荐系统中激励高质量内容的算法问题，经典的在线学习算法会激励生产者创建低质量的内容，但本文提出的一种算法通过惩罚低质量内容的创建者，成功地激励了生产者创造高质量的内容。

    

    对于像TikTok和YouTube这样的内容推荐系统，平台的决策算法塑造了内容生产者的激励，包括生产者在内容质量上投入多少努力。许多平台采用在线学习，这会产生跨时间的激励，因为今天生产的内容会影响未来内容的推荐。在本文中，我们研究了在线学习产生的激励，分析了在纳什均衡下生产的内容质量。我们发现，像Hedge和EXP3这样的经典在线学习算法会激励生产者创建低质量的内容。特别地，内容质量在学习率方面有上限，并且随着典型学习率进展而趋近于零。在这一负面结果的基础上，我们设计了一种不同的学习算法——基于惩罚创建低质量内容的生产者——正确激励生产者创建高质量内容。我们的算法依赖于新颖的策略性赌博机问题，并克服了在组合设置中应用对抗性技术的挑战。在模拟和真实数据的实验中，我们的算法成功地激励生产者创建高质量内容。

    For content recommender systems such as TikTok and YouTube, the platform's decision algorithm shapes the incentives of content producers, including how much effort the content producers invest in the quality of their content. Many platforms employ online learning, which creates intertemporal incentives, since content produced today affects recommendations of future content. In this paper, we study the incentives arising from online learning, analyzing the quality of content produced at a Nash equilibrium. We show that classical online learning algorithms, such as Hedge and EXP3, unfortunately incentivize producers to create low-quality content. In particular, the quality of content is upper bounded in terms of the learning rate and approaches zero for typical learning rate schedules. Motivated by this negative result, we design a different learning algorithm -- based on punishing producers who create low-quality content -- that correctly incentivizes producers to create high-quality co
    
[^79]: 去噪声点阵格生成3D分子

    3D molecule generation by denoising voxel grids. (arXiv:2306.07473v1 [cs.LG])

    [http://arxiv.org/abs/2306.07473](http://arxiv.org/abs/2306.07473)

    VoxMol是一种根据分数的新方法，可以生成3D分子，并通过学习从噪声分子的平滑分布到真实分子的分布的映射。该方法与当前先进技术不同，具有更简单的训练和更快的速度。

    

    我们提出了一种新的基于分数的方法，用于生成表示为规则网格上的原子密度的3D分子。首先，我们训练了一个去噪声的神经网络，学习从噪声分子的平滑分布到真实分子的分布的映射。然后，我们遵循神经经验贝叶斯框架 [Saremi和Hyvarinen，2019]，通过两个步骤生成分子：（i）通过欠阻尼Langevin马尔可夫链蒙特卡罗从平滑分布中采样带噪声的密度网格，（ii）通过单步去噪噪声格，还原“干净”的分子。我们的方法VoxMol是一种根本不同于当前现有技术（即应用于原子点云的扩散模型）的生成分子的方法。它在数据表示、噪声模型、网络架构和生成建模算法方面不同。VoxMol在无条件3D分子生成方面取得了与现有技术可比较的结果，同时训练简单且更快。

    We propose a new score-based approach to generate 3D molecules represented as atomic densities on regular grids. First, we train a denoising neural network that learns to map from a smooth distribution of noisy molecules to the distribution of real molecules. Then, we follow the neural empirical Bayes framework [Saremi and Hyvarinen, 2019] and generate molecules in two steps: (i) sample noisy density grids from a smooth distribution via underdamped Langevin Markov chain Monte Carlo, and (ii) recover the ``clean'' molecule by denoising the noisy grid with a single step. Our method, VoxMol, generates molecules in a fundamentally different way than the current state of the art (i.e., diffusion models applied to atom point clouds). It differs in terms of the data representation, the noise model, the network architecture and the generative modeling algorithm. VoxMol achieves comparable results to state of the art on unconditional 3D molecule generation while being simpler to train and faste
    
[^80]: Von Mises混合分布用于分子构象生成

    Von Mises Mixture Distributions for Molecular Conformation Generation. (arXiv:2306.07472v1 [physics.chem-ph])

    [http://arxiv.org/abs/2306.07472](http://arxiv.org/abs/2306.07472)

    传统的分子几何结构采样方法计算成本很高，而机器学习方法多数专注于分布中的模式识别。本文提出的Von Mises混合分布用于生成更准确的样本。

    

    分子经常被表示为图形，但是基础的三维分子几何结构（原子的位置）最终决定了大多数分子性质。然而，大多数分子在常温下都不是静态的，并采取各种各样的几何结构或$\textit{构象}$。由此产生的几何结构分布$p(x)$称为玻尔兹曼分布，许多分子性质都是在该分布下计算的期望。因此，准确地从玻尔兹曼分布中生成样本对于准确计算这些期望至关重要。传统的基于采样的方法计算成本很高，大部分最近的基于机器学习的方法专注于识别该分布中的$\textit{模式}$，而不是生成真正的$\textit{样本}$。生成这样的样本需要捕捉构象变异性，人们广泛认为分子的大多数构象变异性来自于化学键的旋转。

    Molecules are frequently represented as graphs, but the underlying 3D molecular geometry (the locations of the atoms) ultimately determines most molecular properties. However, most molecules are not static and at room temperature adopt a wide variety of geometries or $\textit{conformations}$. The resulting distribution on geometries $p(x)$ is known as the Boltzmann distribution, and many molecular properties are expectations computed under this distribution. Generating accurate samples from the Boltzmann distribution is therefore essential for computing these expectations accurately. Traditional sampling-based methods are computationally expensive, and most recent machine learning-based methods have focused on identifying $\textit{modes}$ in this distribution rather than generating true $\textit{samples}$. Generating such samples requires capturing conformational variability, and it has been widely recognized that the majority of conformational variability in molecules arises from rota
    
[^81]: 面向非平稳多智能体强化学习的黑盒方法

    A Black-box Approach for Non-stationary Multi-agent Reinforcement Learning. (arXiv:2306.07465v1 [cs.LG])

    [http://arxiv.org/abs/2306.07465](http://arxiv.org/abs/2306.07465)

    本文提出了一种通用的黑盒方法，适用于多种多智能体强化学习问题，可以在非平稳环境下实现低遗憾率的学习。

    

    本文研究了在非平稳多智能体系统中学习均衡的方法，并解决了区别于单智能体学习的挑战。我们重点关注带有赌徒反馈的游戏，其中即使待测试的差距很小，测试一个均衡也可能导致大量的遗憾，并且在静态游戏中存在多个最优解（均衡）会带来额外的难题。为了克服这些障碍，我们提出了一种通用的黑盒方法，适用于广泛的问题，如一般和博弈、潜在博弈和马尔可夫博弈，只要在静态环境下配备适当的学习和测试神谕。当非平稳程度（通过总变化量 $\Delta$ 测量）已知时，我们的算法可以实现 $\widetilde{O}\left(\Delta^{1/4}T^{3/4}\right)$ 的遗憾，当 $\Delta$ 未知时，可以实现 $\widetilde{O}\left(\Delta^{1/5}T^{4/5}\right)$ 的遗憾。

    We investigate learning the equilibria in non-stationary multi-agent systems and address the challenges that differentiate multi-agent learning from single-agent learning. Specifically, we focus on games with bandit feedback, where testing an equilibrium can result in substantial regret even when the gap to be tested is small, and the existence of multiple optimal solutions (equilibria) in stationary games poses extra challenges. To overcome these obstacles, we propose a versatile black-box approach applicable to a broad spectrum of problems, such as general-sum games, potential games, and Markov games, when equipped with appropriate learning and testing oracles for stationary environments. Our algorithms can achieve $\widetilde{O}\left(\Delta^{1/4}T^{3/4}\right)$ regret when the degree of nonstationarity, as measured by total variation $\Delta$, is known, and $\widetilde{O}\left(\Delta^{1/5}T^{4/5}\right)$ regret when $\Delta$ is unknown, where $T$ is the number of rounds. Meanwhile, 
    
[^82]: 解锁销售增长：具有可解释 AI 的账户优先级引擎

    Unlocking Sales Growth: Account Prioritization Engine with Explainable AI. (arXiv:2306.07464v1 [cs.AI])

    [http://arxiv.org/abs/2306.07464](http://arxiv.org/abs/2306.07464)

    论文开发了一款名为 Account Prioritizer 的智能销售账户优先级引擎，使用机器学习和解释算法自动化销售簿优化，在 LinkedIn Business 中成功带来了 +8.08% 的续订订阅增长。

    

    B2B 销售需要有效预测客户增长，识别升级潜力以及降低流失风险。LinkedIn 的销售代表传统上依赖直觉和碎片化数据信号来评估客户绩效。这导致在数据理解和策略制定方面投入了大量时间，而在积极销售方面投资不足。为了克服这一挑战，我们开发了一种数据产品，称为 Account Prioritizer，它是智能销售账户优先级引擎。它使用机器学习推荐模型和集成的账户级解释算法在销售 CRM 中自动化销售簿优化的手动过程。一次成功的 A/B 测试表明，Account Prioritizer 为 LinkedIn Business 带来了显著的 +8.08% 续订订阅增长。

    B2B sales requires effective prediction of customer growth, identification of upsell potential, and mitigation of churn risks. LinkedIn sales representatives traditionally relied on intuition and fragmented data signals to assess customer performance. This resulted in significant time investment in data understanding as well as strategy formulation and under-investment in active selling. To overcome this challenge, we developed a data product called Account Prioritizer, an intelligent sales account prioritization engine. It uses machine learning recommendation models and integrated account-level explanation algorithms within the sales CRM to automate the manual process of sales book prioritization. A successful A/B test demonstrated that the Account Prioritizer generated a substantial +8.08% increase in renewal bookings for the LinkedIn Business.
    
[^83]: 关于Removal-Based特征归因的鲁棒性研究

    On the Robustness of Removal-Based Feature Attributions. (arXiv:2306.07462v1 [cs.LG])

    [http://arxiv.org/abs/2306.07462](http://arxiv.org/abs/2306.07462)

    本文研究了Removal-Based特征归因的鲁棒性，提供了全面的理论和实验分析，并证明了所提方法的实际有效性。

    

    为了解释基于输入的复杂模型，开发了许多特征归因方法来分配输入特征的重要性分数。然而，最近的一些研究挑战了特征归因的鲁棒性，指出这些方法对输入和模型扰动敏感，而其他研究通过提出鲁棒归因方法和模型修改来解决这个问题。然而，以往的归因鲁棒性研究主要侧重于基于梯度的特征归因。相比之下，Removal-Based归因方法的鲁棒性质尚未全面地得到理解。为了弥补这一差距，我们从理论上对Removal-Based特征归因的鲁棒性进行了全面的阐述。具体而言，我们对这种方法进行了统一的分析，并在输入和模型扰动的情况下证明了完好和受扰动的归因之间的差异的上限。我们在合成和真实数据集上的实验验证了我们的理论结果，并证明了所提出方法的实际有效性。

    To explain complex models based on their inputs, many feature attribution methods have been developed that assign importance scores to input features. However, some recent work challenges the robustness of feature attributions by showing that these methods are sensitive to input and model perturbations, while other work addresses this robustness issue by proposing robust attribution methods and model modifications. Nevertheless, previous work on attribution robustness has focused primarily on gradient-based feature attributions. In contrast, the robustness properties of removal-based attribution methods are not comprehensively well understood. To bridge this gap, we theoretically characterize the robustness of removal-based feature attributions. Specifically, we provide a unified analysis of such methods and prove upper bounds for the difference between intact and perturbed attributions, under settings of both input and model perturbations. Our empirical experiments on synthetic and re
    
[^84]: FIRE：一种用于快速可解释规则提取的优化方法

    FIRE: An Optimization Approach for Fast Interpretable Rule Extraction. (arXiv:2306.07432v1 [cs.LG])

    [http://arxiv.org/abs/2306.07432](http://arxiv.org/abs/2306.07432)

    FIRE是一种用于从树集合中提取易于审查的稀疏规则子集的优化方法，可以鼓励在选择时融合规则，从而增强模型的可解释性，并且在实验中表现出更高的准确性和可解释性。

    

    我们提出了FIRE，即Fast Interpretable Rule Extraction，这是一个基于优化的框架，用于从树集合中提取少量但有用的决策规则。 FIRE从树集合中选择稀疏的代表性规则子集，这些子集易于由实践者检查。为了进一步增强所提取模型的可解释性，FIRE鼓励在选择时融合规则，以便许多所选决策规则共享相同的前提条件。该优化框架利用融合正则化惩罚来实现这一点，同时采用非凸稀疏引入惩罚以积极选取规则。FIRE中的优化问题由于问题规模和惩罚的非凸性而对现成求解器构成挑战。为了解决这个问题，利用问题结构，我们开发了一个基于块坐标下降原理的专门求解器； 我们的求解器比现有求解器运行速度快40倍。实验证明，与现有的规则提取方法相比，FIRE能够产生更准确且可解释的模型。

    We present FIRE, Fast Interpretable Rule Extraction, an optimization-based framework to extract a small but useful collection of decision rules from tree ensembles. FIRE selects sparse representative subsets of rules from tree ensembles, that are easy for a practitioner to examine. To further enhance the interpretability of the extracted model, FIRE encourages fusing rules during selection, so that many of the selected decision rules share common antecedents. The optimization framework utilizes a fusion regularization penalty to accomplish this, along with a non-convex sparsity-inducing penalty to aggressively select rules. Optimization problems in FIRE pose a challenge to off-the-shelf solvers due to problem scale and the non-convexity of the penalties. To address this, making use of problem-structure, we develop a specialized solver based on block coordinate descent principles; our solver performs up to 40x faster than existing solvers. We show in our experiments that FIRE outperform
    
[^85]: DeepTransition：可行性导致步态转换的出现

    DeepTransition: Viability Leads to the Emergence of Gait Transitions in Learning Anticipatory Quadrupedal Locomotion Skills. (arXiv:2306.07419v1 [cs.RO])

    [http://arxiv.org/abs/2306.07419](http://arxiv.org/abs/2306.07419)

    本文通过深度强化学习和机器人工具的互动研究，证明了可行性是四足动物步态转换的重要标准。其中，步-小跑步态转换能够在平坦地形上同时提高可行性和节能效果。

    

    四足动物在改变运动速度时能够无缝地转换步态。本文提出可行性（即避免跌倒）代表步态转换的一个重要标准。通过利用深度强化学习和机器人工具，我们研究了步态转换的出现。一致于四足动物数据，我们证明了在平坦地形上，四足机器人的步-小跑步态转换能同时提高可行性和节能效果。此外，我们研究了离散地形（即穿越连续间隔）对强制步态转换的影响，并找到足-蹦步态的出现。

    Quadruped animals seamlessly transition between gaits as they change locomotion speeds. While the most widely accepted explanation for gait transitions is energy efficiency, there is no clear consensus on the determining factor, nor on the potential effects from terrain properties. In this article, we propose that viability, i.e. the avoidance of falls, represents an important criterion for gait transitions. We investigate the emergence of gait transitions through the interaction between supraspinal drive (brain), the central pattern generator in the spinal cord, the body, and exteroceptive sensing by leveraging deep reinforcement learning and robotics tools. Consistent with quadruped animal data, we show that the walk-trot gait transition for quadruped robots on flat terrain improves both viability and energy efficiency. Furthermore, we investigate the effects of discrete terrain (i.e. crossing successive gaps) on imposing gait transitions, and find the emergence of trot-pronk transit
    
[^86]: 通过高效的对抗性聚集实现强化学习的鲁棒性

    Robust Reinforcement Learning through Efficient Adversarial Herding. (arXiv:2306.07408v1 [cs.LG])

    [http://arxiv.org/abs/2306.07408](http://arxiv.org/abs/2306.07408)

    本研究提出了对抗性聚集方法，通过引入对手群来解决内部优化问题的困难，从而提高强化学习代理的鲁棒性，并通过对最差表现者中最坏的k个表现的平均表现来解决过度悲观主义问题。

    

    尽管强化学习在策略设计方面被认为是业界黄金标准，但在各种情况下，它并不总能提供健壮的解决方案。这可能导致环境暴露于潜在干扰时严重的性能下降。经过证明，使用双人博弈的对抗性训练可以有效提高RL代理的鲁棒性。在这项工作中，我们通过引入一个对抗性聚集来扩展双人博弈，并涉及一个对手群，以解决($\textit{i}$)内部优化问题的困难和($\textit{ii}$)由于候选对手集可能包含不太可能的情况而可能产生的过度悲观主义。我们首先证明了对抗性聚集可以有效地近似内部优化问题。然后，我们通过用最差的表现者中最差的k个表现的平均表现替换内部优化中的最坏情况表现来解决第二个问题。我们评估了我们的方法在多种环境下的性能，证明了对抗性聚集在与其他更先进的对抗性方法相比具有竞争力。

    Although reinforcement learning (RL) is considered the gold standard for policy design, it may not always provide a robust solution in various scenarios. This can result in severe performance degradation when the environment is exposed to potential disturbances. Adversarial training using a two-player max-min game has been proven effective in enhancing the robustness of RL agents. In this work, we extend the two-player game by introducing an adversarial herd, which involves a group of adversaries, in order to address ($\textit{i}$) the difficulty of the inner optimization problem, and ($\textit{ii}$) the potential over pessimism caused by the selection of a candidate adversary set that may include unlikely scenarios. We first prove that adversarial herds can efficiently approximate the inner optimization problem. Then we address the second issue by replacing the worst-case performance in the inner optimization with the average performance over the worst-$k$ adversaries. We evaluate the
    
[^87]: 对神经元激活最大化解释的对抗攻击

    Adversarial Attacks on the Interpretation of Neuron Activation Maximization. (arXiv:2306.07397v1 [cs.LG])

    [http://arxiv.org/abs/2306.07397](http://arxiv.org/abs/2306.07397)

    本文研究了对神经网络内部功能行为解释方法的对抗攻击，提出了一个操纵模型以干扰解释的优化框架，并演示了流行的激活最大化解释技术被操纵以改变其解释的方法。

    

    训练好的深度神经网络的内部功能行为非常难以解释。激活最大化方法是用于解释和分析训练深度学习模型的一组技术。这些方法包括找到最大化给定的神经元或特征映射激活的输入。这些输入可以选择自数据集或通过优化得到。然而，可解释性方法可能会受到欺骗。在这项工作中，我们考虑了对手为欺骗解释而操纵模型的概念。我们提出了一个用于执行这种操作的优化框架，并演示了几种流行的与卷积神经网络相关的激活最大化解释技术可以被操纵以改变解释，从而揭示了这些方法的可靠性。

    The internal functional behavior of trained Deep Neural Networks is notoriously difficult to interpret. Activation-maximization approaches are one set of techniques used to interpret and analyze trained deep-learning models. These consist in finding inputs that maximally activate a given neuron or feature map. These inputs can be selected from a data set or obtained by optimization. However, interpretability methods may be subject to being deceived. In this work, we consider the concept of an adversary manipulating a model for the purpose of deceiving the interpretation. We propose an optimization framework for performing this manipulation and demonstrate a number of ways that popular activation-maximization interpretation techniques associated with CNNs can be manipulated to change the interpretations, shedding light on the reliability of these methods.
    
[^88]: 为策略选择构建高效、健壮的测试

    Composing Efficient, Robust Tests for Policy Selection. (arXiv:2306.07372v1 [cs.LG])

    [http://arxiv.org/abs/2306.07372](http://arxiv.org/abs/2306.07372)

    该论文提出了一种名为RPOSST的算法，它可以从较大的测试案例池中选择一小部分测试样例，验证其高质量的策略在更广泛的环境下也是可靠的。

    

    现代强化学习系统在学习过程中会产生许多高质量的策略。然而，在实际应用中选择哪种策略时，它们必须在不可解的大量环境条件下进行测试。我们介绍了一种算法RPOSST，它能够从较大的测试案例池中选择一小部分测试样例，这是根据相对较小的样本评估来实现的。RPOSST将测试样例选择问题视为一个双人博弈，并优化具有可证明的k-of-N健壮性的解决方案，以限制相对于使用池中所有测试用例的测试的误差。实证结果表明，RPOSST能够在一个玩具单一游戏、扑克数据集和高保真赛车模拟器中发现可以识别高质量策略的一小组测试用例。

    Modern reinforcement learning systems produce many high-quality policies throughout the learning process. However, to choose which policy to actually deploy in the real world, they must be tested under an intractable number of environmental conditions. We introduce RPOSST, an algorithm to select a small set of test cases from a larger pool based on a relatively small number of sample evaluations. RPOSST treats the test case selection problem as a two-player game and optimizes a solution with provable $k$-of-$N$ robustness, bounding the error relative to a test that used all the test cases in the pool. Empirical results demonstrate that RPOSST finds a small set of test cases that identify high quality policies in a toy one-shot game, poker datasets, and a high-fidelity racing simulator.
    
[^89]: 在非 IC 拍卖广告市场上的多平台预算管理

    Multi-Platform Budget Management in Ad Markets with Non-IC Auctions. (arXiv:2306.07352v1 [cs.GT])

    [http://arxiv.org/abs/2306.07352](http://arxiv.org/abs/2306.07352)

    本论文提出了一种针对广告市场上预算限制和拍卖非激励兼容问题的优化竞标策略，在满足广告主预期预算限制的同时最大化预期总效用；并研究了跨平台提交竞标的在线设置。

    

    在在线广告市场上，有预算限制的广告主通过在各种平台上反复竞标获得广告位置。我们提出了一种策略，用于在可能存在预算限制的激励兼容或非激励兼容情况下，优化竞标一组拍卖品。我们的策略最大化预期在各个拍卖中的总效用，同时满足广告主预期的预算限制。此外，我们研究了广告主必须在学习其他竞标者的出价情况的同时，跨平台提交竞标的在线设置。在全信息设置下，我们的算法具有 $O(T^{3/4})$ 的遗憾值。最后，我们证明了相比现有的自适应步伐算法，我们的算法在广告放置拍卖的合成和真实数据集上具有更优秀的累积遗憾值。

    In online advertising markets, budget-constrained advertisers acquire ad placements through repeated bidding in auctions on various platforms. We present a strategy for bidding optimally in a set of auctions that may or may not be incentive-compatible under the presence of budget constraints. Our strategy maximizes the expected total utility across auctions while satisfying the advertiser's budget constraints in expectation. Additionally, we investigate the online setting where the advertiser must submit bids across platforms while learning about other bidders' bids over time. Our algorithm has $O(T^{3/4})$ regret under the full-information setting. Finally, we demonstrate that our algorithms have superior cumulative regret on both synthetic and real-world datasets of ad placement auctions, compared to existing adaptive pacing algorithms.
    
[^90]: G-不变扩散地图

    G-invariant diffusion maps. (arXiv:2306.07350v1 [cs.LG])

    [http://arxiv.org/abs/2306.07350](http://arxiv.org/abs/2306.07350)

    研究构造了针对连续矩阵群封闭下的流形中采样的数据集的G-不变扩散地图，能够实现等变且不变的嵌入，适用于对数据点进行聚类和对齐。

    

    数据扩散地图在从降维和聚类到数据可视化等任务中均取得了成功。本研究考虑到从一个连续矩阵群封闭下的流形中采样的数据集，我们构造了既等变又不变的嵌入，这些嵌入可以自然地用于对数据点进行聚类和对齐。我们使用模拟数据证明了我们的构造的有效性。

    The diffusion maps embedding of data lying on a manifold have shown success in tasks ranging from dimensionality reduction and clustering, to data visualization. In this work, we consider embedding data sets which were sampled from a manifold which is closed under the action of a continuous matrix group. An example of such a data set are images who's planar rotations are arbitrary. The G-invariant graph Laplacian, introduced in a previous work of the authors, admits eigenfunctions in the form of tensor products between the elements of the irreducible unitary representations of the group and eigenvectors of certain matrices. We employ these eigenfunctions to derive diffusion maps that intrinsically account for the group action on the data. In particular, we construct both equivariant and invariant embeddings which can be used naturally to cluster and align the data points. We demonstrate the effectiveness of our construction with simulated data.
    
[^91]: ATT3D：摊销的文本到三维物体合成

    ATT3D: Amortized Text-to-3D Object Synthesis. (arXiv:2306.07349v1 [cs.LG])

    [http://arxiv.org/abs/2306.07349](http://arxiv.org/abs/2306.07349)

    该论文提出了一种“摊销”的文本到三维物体合成方法，将许多提示一起使用一个统一的模型进行训练，共享提示之间的优化计算，从而在更短时间内训练模型；该方法能够使不同提示之间进行平滑的插值，并在新的资产和简单动画之间实现知识共享和推广。

    

    将生成式文本到图像模型与图像到三维方法（如神经辐射场）相结合，文本至三维建模取得了令人兴奋的进展。 DreamFusion 最近取得了高质量的结果，但需要进行漫长的、基于提示的优化才能创建三维物体。为了解决这个问题，我们通过使用统一的模型同时训练许多提示来摊销提示优化，而不是单独训练每个提示。通过这种方式，我们可以在提示集合中共享计算，比每个提示的优化所需的时间更短。我们的框架-Amortized text-to-3D (ATT3D)-实现了提示之间的知识共享，以便推广到未见过的设置，并为新资产和简单动画之间的文本进行平滑的插值。

    Text-to-3D modelling has seen exciting progress by combining generative text-to-image models with image-to-3D methods like Neural Radiance Fields. DreamFusion recently achieved high-quality results but requires a lengthy, per-prompt optimization to create 3D objects. To address this, we amortize optimization over text prompts by training on many prompts simultaneously with a unified model, instead of separately. With this, we share computation across a prompt set, training in less time than per-prompt optimization. Our framework - Amortized text-to-3D (ATT3D) - enables knowledge-sharing between prompts to generalize to unseen setups and smooth interpolations between text for novel assets and simple animations.
    
[^92]: 量子卷积神经网络的分裂和并行化用于学习平移对称数据

    Splitting and Parallelizing of Quantum Convolutional Neural Networks for Learning Translationally Symmetric Data. (arXiv:2306.07331v1 [quant-ph])

    [http://arxiv.org/abs/2306.07331](http://arxiv.org/abs/2306.07331)

    提出一种基于平移对称性的分裂并行化QCNN架构，可以高效地学习平移对称量子数据，相比传统的QCNN极大地提高了测量效率和速度。

    

    量子卷积神经网络(QCNN)是一种有望在经典难题上实现量子优势的量子机器学习(QML)模型。然而，QCNN需要大量的测量用于数据学习，从而限制了它在大规模问题上的实际应用。为了缓解这种需求，我们提出了一种新的架构，称为分裂并行化QCNN(sp-QCNN)，它利用量子数据的先验知识设计高效电路。这种架构从几何量子机器学习中获得灵感，针对凝聚态物理中常见的平移对称量子数据。通过基于平移对称性分裂量子电路，sp-QCNN极大地并行化了传统的QCNN，而不增加量子比特数，并进一步提高了测量效率，达到了量子相识别任务的加速效果。

    A quantum convolutional neural network (QCNN) is a promising quantum machine learning (QML) model to achieve quantum advantages in classically intractable problems. However, QCNN requires a large number of measurements for data learning, limiting its practical applications for large-scale problems. To relieve this requirement, we propose a novel architecture called split-parallelizing QCNN (sp-QCNN), which exploits the prior knowledge of quantum data for designing efficient circuits. This architecture draws inspiration from geometric quantum machine learning and targets translationally symmetric quantum data commonly encountered in condensed matter physics. By splitting the quantum circuit based on translational symmetry, sp-QCNN substantially parallelizes conventional QCNN without increasing the number of qubits and further improves the measurement efficiency by an order of the number of qubits. To demonstrate its effectiveness, we apply sp-QCNN to a quantum phase recognition task and
    
[^93]: 一种新的概率距离度量及其在高斯混合模型中的应用

    A New Probabilistic Distance Metric With Application In Gaussian Mixture Reduction. (arXiv:2306.07309v1 [cs.LG])

    [http://arxiv.org/abs/2306.07309](http://arxiv.org/abs/2306.07309)

    本文提出了一种新的距离度量方法，用于计算高斯混合模型，从而提高信号处理应用的效率和稳定性。同时，提出了一种新的基于优化的贪心 GMR（OGGMR）算法，用于将高次高斯混合模型近似为低阶模型，实验表明它比现有的GMR算法更快、更高效，并能保留原始模型的几何形状。

    

    本文提出了一种新的距离度量方法，用于比较两个连续概率密度函数。该距离度量方法具有许多优点，其中最重要的是广义高斯混合模型可以用它的解析式表示，并且它满足所有的距离公式性质，具有计算速度快、稳定和高效的特点，十分适用于实际信号处理应用。本文应用该方法于高斯混合模型简化（Gaussian Mixture Reduction，GMR）问题，提出了基于优化的贪心 GMR（OGGMR）算法，该算法使用我们的距离度量作为准则，将高次高斯混合模型近似为低阶模型。实验证明，OGGMR算法比现有的GMR算法更快、更高效，并能保留原始模型的几何形状。

    This paper presents a new distance metric to compare two continuous probability density functions. The main advantage of this metric is that, unlike other statistical measurements, it can provide an analytic, closed-form expression for a mixture of Gaussian distributions while satisfying all metric properties. These characteristics enable fast, stable, and efficient calculations, which are highly desirable in real-world signal processing applications. The application in mind is Gaussian Mixture Reduction (GMR), which is widely used in density estimation, recursive tracking, and belief propagation. To address this problem, we developed a novel algorithm dubbed the Optimization-based Greedy GMR (OGGMR), which employs our metric as a criterion to approximate a high-order Gaussian mixture with a lower order. Experimental results show that the OGGMR algorithm is significantly faster and more efficient than state-of-the-art GMR algorithms while retaining the geometric shape of the original m
    
[^94]: 基于优化启发式深度神经网络的自监督高光谱图像修复

    Self-Supervised Hyperspectral Inpainting with the Optimisation inspired Deep Neural Network Prior. (arXiv:2306.07308v1 [eess.IV])

    [http://arxiv.org/abs/2306.07308](http://arxiv.org/abs/2306.07308)

    本文提出了一种自监督的高光谱图像修复算法LRS-PnP-DIP，该算法能够在高光谱图像中精确预测缺失像素和带，其在实验中表现优异，达到或超过了其他学习方法。

    

    高光谱图像具有成百上千个窄带谱段，传递了大量的空间和谱信息。然而，由于仪器误差和大气变化，实践中得到的高光谱图像常常被噪声和坏点污染，导致缺失信息可能严重破坏后续应用。本文提出了一种新的高光谱图像取样点修复算法，称为低秩稀疏约束插入播放算法（LRS-PnP）。结果表明，即使图像的所有光谱带都丢失，LRS-PnP也能够预测缺失的像素和带。将LRS-PnP与Deep Image Prior（DIP）相结合，进一步扩展了一种自监督模型，称为LRS-PnP-DIP。在一系列真实数据实验中，结果表明，与其他基于学习的方法相比，LRS-PnP-DIP具有最先进的修复性能或胜过它们。

    Hyperspectral Image (HSI)s cover hundreds or thousands of narrow spectral bands, conveying a wealth of spatial and spectral information. However, due to the instrumental errors and the atmospheric changes, the HSI obtained in practice are often contaminated by noise and dead pixels(lines), resulting in missing information that may severely compromise the subsequent applications. We introduce here a novel HSI missing pixel prediction algorithm, called Low Rank and Sparsity Constraint Plug-and-Play (LRS-PnP). It is shown that LRS-PnP is able to predict missing pixels and bands even when all spectral bands of the image are missing. The proposed LRS-PnP algorithm is further extended to a self-supervised model by combining the LRS-PnP with the Deep Image Prior (DIP), called LRS-PnP-DIP. In a series of experiments with real data, It is shown that the LRS-PnP-DIP either achieves state-of-the-art inpainting performance compared to other learning-based methods, or outperforms them.
    
[^95]: 少样本策略迁移的在线原型对齐

    Online Prototype Alignment for Few-shot Policy Transfer. (arXiv:2306.07307v1 [cs.LG])

    [http://arxiv.org/abs/2306.07307](http://arxiv.org/abs/2306.07307)

    本文提出了一种基于元素功能相似性的在线原型对齐（OPA）框架，能够在少样本的情况下实现策略转移，解决了传统方法映射函数学习需要大量数据以及依赖视觉特征等问题。

    

    强化学习中的领域适应主要涉及在将策略转移到新环境时观察的变化。领域适应的许多传统方法以显式或隐式地学习源域和目标域之间的映射函数为主。然而，它们通常需要访问目标域的大量数据。此外，它们常常依赖于视觉线索来学习映射函数，当源域与目标域看起来非常不同时，可能会失败。为解决这些问题，我们提出了一个新的框架在线原型对齐（OPA），该框架基于元素的功能相似性来学习映射函数，能够在仅几个回合内实现少样本策略转移。OPA的关键见解是引入一个探索机制，可以高效、有目的地与目标域的未知元素交互，并将它们与已知的元素连接起来。

    Domain adaptation in reinforcement learning (RL) mainly deals with the changes of observation when transferring the policy to a new environment. Many traditional approaches of domain adaptation in RL manage to learn a mapping function between the source and target domain in explicit or implicit ways. However, they typically require access to abundant data from the target domain. Besides, they often rely on visual clues to learn the mapping function and may fail when the source domain looks quite different from the target domain. To address these problems, we propose a novel framework Online Prototype Alignment (OPA) to learn the mapping function based on the functional similarity of elements and is able to achieve the few-shot policy transfer within only several episodes. The key insight of OPA is to introduce an exploration mechanism that can interact with the unseen elements of the target domain in an efficient and purposeful manner, and then connect them with the seen elements in th
    
[^96]: 让预测变得自学习和自适应--试点预测架构。

    Making forecasting self-learning and adaptive -- Pilot forecasting rack. (arXiv:2306.07305v1 [cs.LG])

    [http://arxiv.org/abs/2306.07305](http://arxiv.org/abs/2306.07305)

    本文提出了通过使用试点预测架构中的算法干预来提高非AI模型下针织品类别的预测准确性。在决策模型中动态地选择最佳算法可提高预测准确性，并通过AI / ML预测模型使用先进的特征工程来实现。

    

    零售销售和价格预测通常基于时间序列预测。对于某些产品类别，预测需求的准确性较低，会对库存、运输和补货计划造成负面影响。本文介绍了我们基于积极探索的试点演练的发现，以探索帮助零售商提高此类产品类别的预测准确性的方法。我们评估了通过一个样本产品类别“针织品”提高预测准确性的算法干预机会。目前，针织品产品类别的预测准确度在非AI模型中的范围为60%。我们探索了如何使用架构方法提高预测准确性。为了生成预测结果，我们的决策模型根据给定状态和上下文动态地从算法架中选择最佳算法。使用先进的特征工程构建的AI / ML预测模型的结果显示，需求预测的准确性有所提高。

    Retail sales and price projections are typically based on time series forecasting. For some product categories, the accuracy of demand forecasts achieved is low, negatively impacting inventory, transport, and replenishment planning. This paper presents our findings based on a proactive pilot exercise to explore ways to help retailers to improve forecast accuracy for such product categories.  We evaluated opportunities for algorithmic interventions to improve forecast accuracy based on a sample product category, Knitwear. The Knitwear product category has a current demand forecast accuracy from non-AI models in the range of 60%. We explored how to improve the forecast accuracy using a rack approach. To generate forecasts, our decision model dynamically selects the best algorithm from an algorithm rack based on performance for a given state and context. Outcomes from our AI/ML forecasting model built using advanced feature engineering show an increase in the accuracy of demand forecast f
    
[^97]: 一种统一自动概念提取和概念重要性评估的全面方法

    A Holistic Approach to Unifying Automatic Concept Extraction and Concept Importance Estimation. (arXiv:2306.07304v1 [cs.LG])

    [http://arxiv.org/abs/2306.07304](http://arxiv.org/abs/2306.07304)

    本文提出了一个全面的理论框架，来统一定义和澄清自动概念提取和概念重要性评估，进而提供新的评估指标以实现对这些方法的比较以及推导关于这种方法的最优性的理论保证。

    

    近年来，基于概念的方法成为了一些最有前途的可解释方法，帮助我们解释人工神经网络（ANN）的决策。这些方法试图在两个关键步骤中发现被隐藏在ANN激活的复杂模式中的可理解的视觉“概念”：（1）概念提取，（2）重要性评估。虽然这两个步骤是各种方法之间共同的，但它们的具体实现都有所不同。在这里，我们介绍了一个统一的理论框架，全面定义和澄清了这两个步骤。该框架具有几个优点，它允许我们：（i）提出新的评估指标来比较不同的概念提取方法；（ii）利用现代归因方法和评估指标来扩展和系统地评估最先进的基于概念的方法和重要性评估技术；（iii）推导关于这种方法的最优性的理论保证。

    In recent years, concept-based approaches have emerged as some of the most promising explainability methods to help us interpret the decisions of Artificial Neural Networks (ANNs). These methods seek to discover intelligible visual 'concepts' buried within the complex patterns of ANN activations in two key steps: (1) concept extraction followed by (2) importance estimation. While these two steps are shared across methods, they all differ in their specific implementations. Here, we introduce a unifying theoretical framework that comprehensively defines and clarifies these two steps. This framework offers several advantages as it allows us: (i) to propose new evaluation metrics for comparing different concept extraction approaches; (ii) to leverage modern attribution methods and evaluation metrics to extend and systematically evaluate state-of-the-art concept-based approaches and importance estimation techniques; (iii) to derive theoretical guarantees regarding the optimality of such met
    
[^98]: 基于Transformer的深度学习任务应用综述

    A Comprehensive Survey on Applications of Transformers for Deep Learning Tasks. (arXiv:2306.07303v1 [cs.LG])

    [http://arxiv.org/abs/2306.07303](http://arxiv.org/abs/2306.07303)

    本文综述了基于Transformer的深度学习任务应用，Transformer能够理解序列数据中的上下文关系且实现并行处理，在NLP、计算机视觉、语音处理、医疗保健和物联网等领域表现出色。

    

    Transformer是一种深度神经网络，采用自注意机制来理解序列数据中的上下文关系。与传统神经网络或更新版本的循环神经网络（RNN）（如长短期记忆（LSTM））不同，Transformer模型在处理输入序列元素之间的长依赖关系和实现并行处理方面表现出色。因此，基于Transformer的模型在人工智能领域引起了广泛兴趣。这得益于它们在自然语言处理（NLP）任务以及计算机视觉、音频和语音处理、医疗保健和物联网（IoT）等各个领域中的巨大潜力和显著成就。虽然已经出版了几篇综述文章，重点介绍了Transformer在特定领域的贡献、架构差异或性能评估，但仍存在较大的空白。

    Transformer is a deep neural network that employs a self-attention mechanism to comprehend the contextual relationships within sequential data. Unlike conventional neural networks or updated versions of Recurrent Neural Networks (RNNs) such as Long Short-Term Memory (LSTM), transformer models excel in handling long dependencies between input sequence elements and enable parallel processing. As a result, transformer-based models have attracted substantial interest among researchers in the field of artificial intelligence. This can be attributed to their immense potential and remarkable achievements, not only in Natural Language Processing (NLP) tasks but also in a wide range of domains, including computer vision, audio and speech processing, healthcare, and the Internet of Things (IoT). Although several survey papers have been published highlighting the transformer's contributions in specific fields, architectural differences, or performance evaluations, there is still a significant abs
    
[^99]: 基于回归和最小二乘支持向量机的空气污染预测的新技术

    Novel Regression and Least Square Support Vector Machine Learning Technique for Air Pollution Forecasting. (arXiv:2306.07301v1 [cs.LG])

    [http://arxiv.org/abs/2306.07301](http://arxiv.org/abs/2306.07301)

    提出了一种新技术，称为DR-LSSV，基于回归和最小二乘支持向量机，可有效提高空气污染预测性能，并在空气污染预测准确性、空气污染预测时间和假阳性率方面超越了传统的机器学习方法。

    

    空气污染是来源于微粒、化学物质或生物物质的问题，它会对人类或其他生物带来痛苦，对自然栖息地和空气空间也会造成不适。因此，空气污染在大都市中仍然是一项重要的环境问题。若不正确地检测空气污染标准，则会对人类和生物造成严重的后果。为了解决这个问题，提出了一种新技术——离散化回归和最小二乘支持向量（DR-LSSV）来预测空气污染。结果表明，所提出的DR-LSSV技术可以有效提高空气污染预测性能，并在空气污染预测准确性、空气污染预测时间和假阳性率方面超越了传统的机器学习方法。

    Air pollution is the origination of particulate matter, chemicals, or biological substances that brings pain to either humans or other living creatures or instigates discomfort to the natural habitat and the airspace. Hence, air pollution remains one of the paramount environmental issues as far as metropolitan cities are concerned. Several air pollution benchmarks are even said to have a negative influence on human health. Also, improper detection of air pollution benchmarks results in severe complications for humans and living creatures. To address this aspect, a novel technique called, Discretized Regression and Least Square Support Vector (DR-LSSV) based air pollution forecasting is proposed. The results indicate that the proposed DR-LSSV Technique can efficiently enhance air pollution forecasting performance and outperforms the conventional machine learning methods in terms of air pollution forecasting accuracy, air pollution forecasting time, and false positive rate.
    
[^100]: 诊断皮肤病变的渐进式分类关注（PCA）方法

    Progressive Class-Wise Attention (PCA) Approach for Diagnosing Skin Lesions. (arXiv:2306.07300v1 [cs.LG])

    [http://arxiv.org/abs/2306.07300](http://arxiv.org/abs/2306.07300)

    本研究提出一种新的分类关注技术，能够平等关注每个皮肤病变类别，并逐步结合多个尺度的判别特征细节，从而获得显著的诊断表现，准确率分别为97.40％和94.9％，超过了15种尖端方法，包括HAM1000和ISIC2019排行榜的优胜者。

    

    全球癌症发病率中，皮肤癌的发生率最高。早期发现的重要性不言而喻，晚期病例可能会危及生命。然而，由于色彩、形状和大小等多种变化，皮肤病变的分类存在多个挑战，同一类别内存在显著变异，不同类别之间也存在显著相似性。本文介绍了一种新型的分类关注技术，该技术在挖掘皮肤病变的更具体细节的同时，平等地考虑每个类别。这种关注机制逐步用于结合多个尺度的判别特征细节。本文介绍的技术表现出色，不仅超过了15种尖端方法，还包括HAM1000和ISIC 2019排行榜的优胜者。在HAM10000数据集上，其准确率达到了97.40％，而在ISIC 2019数据集上则为94.9％。

    Skin cancer holds the highest incidence rate among all cancers globally. The importance of early detection cannot be overstated, as late-stage cases can be lethal. Classifying skin lesions, however, presents several challenges due to the many variations they can exhibit, such as differences in colour, shape, and size, significant variation within the same class, and notable similarities between different classes. This paper introduces a novel class-wise attention technique that equally regards each class while unearthing more specific details about skin lesions. This attention mechanism is progressively used to amalgamate discriminative feature details from multiple scales. The introduced technique demonstrated impressive performance, surpassing more than 15 cutting-edge methods including the winners of HAM1000 and ISIC 2019 leaderboards. It achieved an impressive accuracy rate of 97.40% on the HAM10000 dataset and 94.9% on the ISIC 2019 dataset.
    
[^101]: 加性多指标高斯过程建模及其在夸克胶子等离子体多物理量代理建模中的应用

    Additive Multi-Index Gaussian process modeling, with application to multi-physics surrogate modeling of the quark-gluon plasma. (arXiv:2306.07299v1 [nucl-th])

    [http://arxiv.org/abs/2306.07299](http://arxiv.org/abs/2306.07299)

    本文针对多物理量代理建模中高维预测训练数据有限、现有代理模型预测不确定性高的问题，提出了一种新的加性多指标高斯过程模型(AdMIn-GP)。该模型利用参数空间内低维嵌入的灵活加性结构，充分利用科学先前知识指导。

    

    夸克胶子等离子体是一种独特的核物质相，理论上认为在宇宙大爆炸后不久就填满了宇宙。研究夸克胶子等离子体的关键挑战是需要在高维参数空间内运行复杂的物理模型，以将实验可观测量与理论参数进行协调。然而，由于每次运行都需要数千个CPU小时，因此物理学家只能进行几百次运行，从而导致高维预测的训练数据有限，现有的代理模型通常会产生高预测不确定性。针对这个问题，我们提出了一种新的加性多指标高斯过程(AdMIn-GP)模型，它利用参数空间内低维嵌入的灵活加性结构。这是由科学先前知识指导的，即夸克胶子等离子体受多个不同物理现象(即多物理量)的支配。

    The Quark-Gluon Plasma (QGP) is a unique phase of nuclear matter, theorized to have filled the Universe shortly after the Big Bang. A critical challenge in studying the QGP is that, to reconcile experimental observables with theoretical parameters, one requires many simulation runs of a complex physics model over a high-dimensional parameter space. Each run is computationally very expensive, requiring thousands of CPU hours, thus limiting physicists to only several hundred runs. Given limited training data for high-dimensional prediction, existing surrogate models often yield poor predictions with high predictive uncertainties, leading to imprecise scientific findings. To address this, we propose a new Additive Multi-Index Gaussian process (AdMIn-GP) model, which leverages a flexible additive structure on low-dimensional embeddings of the parameter space. This is guided by prior scientific knowledge that the QGP is dominated by multiple distinct physical phenomena (i.e., multiphysics),
    
[^102]: 基于ChatGPT的医疗数据增广：基于药物识别和药物事件分类的案例研究

    Medical Data Augmentation via ChatGPT: A Case Study on Medication Identification and Medication Event Classification. (arXiv:2306.07297v1 [cs.CL])

    [http://arxiv.org/abs/2306.07297](http://arxiv.org/abs/2306.07297)

    本研究利用ChatGPT进行数据增广，显著提高了BERT模型在电子病历药物识别和药物事件分类任务中的表现。

    

    在电子病历和临床记录中识别药物、疾病和关联性等关键因素具有广泛的临床应用。本研究旨在探索使用预训练的大型语言模型ChatGPT进行数据增广，以克服电子病历中关键因素标注数据的有限可用性。研究结果表明，提出的数据增广技术显著提高了BERT模型在药物识别和药物事件分类等两个电子病历分析任务中的性能。

    The identification of key factors such as medications, diseases, and relationships within electronic health records and clinical notes has a wide range of applications in the clinical field. In the N2C2 2022 competitions, various tasks were presented to promote the identification of key factors in electronic health records (EHRs) using the Contextualized Medication Event Dataset (CMED). Pretrained large language models (LLMs) demonstrated exceptional performance in these tasks. This study aims to explore the utilization of LLMs, specifically ChatGPT, for data augmentation to overcome the limited availability of annotated data for identifying the key factors in EHRs. Additionally, different pre-trained BERT models, initially trained on extensive datasets like Wikipedia and MIMIC, were employed to develop models for identifying these key variables in EHRs through fine-tuning on augmented datasets. The experimental results of two EHR analysis tasks, namely medication identification and me
    
[^103]: 基于PSO超参数优化的三种深度学习模型在北京PM2.5预测方面的应用研究

    Optimized Three Deep Learning Models Based-PSO Hyperparameters for Beijing PM2.5 Prediction. (arXiv:2306.07296v1 [cs.LG])

    [http://arxiv.org/abs/2306.07296](http://arxiv.org/abs/2306.07296)

    本论文提出了基于PSO超参数优化的三种深度学习模型，针对北京PM2.5的预测任务进行研究，并发现M-1模型具有最佳性能且经过优化的超参数可以提高5.6%的预测准确度。

    

    深度学习是一种机器学习方法，在自然语言处理、图像识别和预测等各种应用中都有出色的表现。深度学习网络的性能取决于超参数设置，本研究尝试优化长短时记忆（LSTM）、卷积神经网络（CNN）和多层感知器（MLP）的深度学习架构，使用基于群智能的元启发式优化方法粒子群算法（PSO）进行预测任务的优化。本文提出了M-1（PSO-LSTM）、M-2（PSO-CNN）和M-3（PSO-MLP）。对北京PM2.5数据集进行分析，以测量所提出模型的性能。PM2.5作为目标变量，受到露点、气压、温度、累计风速、降雪小时数和降雨小时数的影响。深度学习网络输入分为三种不同的情景：日常、每周和每月。结果表明，提出的M-1具有三个隐藏层，提供了最佳性能，并且经过优化的超参数相对于基线模型提高了5.6%的预测准确度。

    Deep learning is a machine learning approach that produces excellent performance in various applications, including natural language processing, image identification, and forecasting. Deep learning network performance depends on the hyperparameter settings. This research attempts to optimize the deep learning architecture of Long short term memory (LSTM), Convolutional neural network (CNN), and Multilayer perceptron (MLP) for forecasting tasks using Particle swarm optimization (PSO), a swarm intelligence-based metaheuristic optimization methodology: Proposed M-1 (PSO-LSTM), M-2 (PSO-CNN), and M-3 (PSO-MLP). Beijing PM2.5 datasets was analyzed to measure the performance of the proposed models. PM2.5 as a target variable was affected by dew point, pressure, temperature, cumulated wind speed, hours of snow, and hours of rain. The deep learning network inputs consist of three different scenarios: daily, weekly, and monthly. The results show that the proposed M-1 with three hidden layers pr
    
[^104]: 基于二次神经元的卷积神经网络的表现力增强

    Expressivity Enhancement with Efficient Quadratic Neurons for Convolutional Neural Networks. (arXiv:2306.07294v1 [cs.LG])

    [http://arxiv.org/abs/2306.07294](http://arxiv.org/abs/2306.07294)

    本文提出了基于二次神经元的高效CNN结构，能够有效地提高网络性能，而且参数和计算成本都有大幅度减少。

    

    卷积神经网络已经成功应用于图像分类和目标分割等领域。为了提高网络的表现力，人们研究了各种技术，如新的CNN架构。但是，来自这些技术的性能提升往往会减弱。为解决这一挑战，许多研究人员把重点转向增加神经元的非线性，以增强网络表现力。然而，大多数这些方法会带来大量的参数，因此不可避免地会导致可部署性方面的低效率。在本研究中，提出了一种高效的二次神经元结构，以仅有微小参数和计算成本开销来保留非线性。所提出的二次神经元可以最大化利用二阶计算信息来改善网络性能。实验结果表明，所提出的二次神经元结构可以实现与现有非线性激活函数相比具有更少的参数和计算成本的竞争性能。

    Convolutional neural networks (CNNs) have been successfully applied in a range of fields such as image classification and object segmentation. To improve their expressivity, various techniques, such as novel CNN architectures, have been explored. However, the performance gain from such techniques tends to diminish. To address this challenge, many researchers have shifted their focus to increasing the non-linearity of neurons, the fundamental building blocks of neural networks, to enhance the network expressivity. Nevertheless, most of these approaches incur a large number of parameters and thus formidable computation cost inevitably, impairing their efficiency to be deployed in practice. In this work, an efficient quadratic neuron structure is proposed to preserve the non-linearity with only negligible parameter and computation cost overhead. The proposed quadratic neuron can maximize the utilization of second-order computation information to improve the network performance. The experi
    
[^105]: 基于神经网络的城市时空数据合成方法

    Urban Spatiotemporal Data Synthesis via Neural Disaggregation. (arXiv:2306.07292v1 [cs.LG])

    [http://arxiv.org/abs/2306.07292](http://arxiv.org/abs/2306.07292)

    本研究提出了一种基于神经网络的城市时空数据合成方法，旨在通过分解粗糙的低分辨率地理单元的聚合城市数据来合成细粒度，高分辨率的城市数据，以增加高度聚合的城市数据的可用性和实现价值。

    

    开放数据的细节级别常常与其所能提供的实际效益发生冲突。较不细化的数据可以保护个人隐私，但在一定程度上牺牲了开放数据促进透明度和协助研究的承诺。类似于城市环境中，高层次地理单元的聚合城市数据可能会掩盖城市动态的底层特征，低级别地理单元的变化可能更为明显。本研究旨在通过分解粗糙的低分辨率地理单元的聚合城市数据，合成细粒度，高分辨率的城市数据，以增加高度聚合的城市数据的可用性和实现价值。为了解决一些传统分解方法的简单性问题-1) 我们尝试了许多神经网络模型，这些模型能够建模特征之间复杂的非线性关系。神经方法也可以同时利用空间和时间信息。我们展示了这些神经网络方法的优点。

    The level of granularity of open data often conflicts the benefits it can provide. Less granular data can protect individual privacy, but to certain degrees, sabotage the promise of open data to promote transparency and assist research. Similar in the urban setting, aggregated urban data at high-level geographic units can mask out the underline particularities of city dynamics that may vary at lower areal levels. In this work, we aim to synthesize fine-grained, high resolution urban data, by breaking down aggregated urban data at coarse, low resolution geographic units. The goal is to increase the usability and realize the values as much as possible of highly aggregated urban data. To address the issue of simplicity of some traditional disaggregation methods -- 1) we experimented with numerous neural-based models that are capable of modeling intricate non-linear relationships among features. Neural methods can also leverage both spatial and temporal information concurrently. We showed 
    
[^106]: 利用ERA5再分析数据的集成机器学习方法来检测热带气旋

    An Ensemble Machine Learning Approach for Tropical Cyclone Detection Using ERA5 Reanalysis Data. (arXiv:2306.07291v1 [physics.ao-ph])

    [http://arxiv.org/abs/2306.07291](http://arxiv.org/abs/2306.07291)

    本文中介绍了一种利用机器学习方法，结合多个模型进行热带气旋中心坐标检测的集成方法。

    

    热带气旋是自然界中最具破坏性的现象之一。每年全球平均有90个热带气旋在热带海洋上形成，全球变暖使它们变得更强、更大、更具破坏性。准确检测和跟踪这种现象已成为天气和气候科学研究中一个相关和有趣的领域。传统上，热带气旋在大型气候数据集中通过使用依赖于主观阈值的确定性跟踪方案进行识别。机器学习（ML）模型可以补充确定性方法，因为它们能够从可用数据中捕获输入气候因素与热带气旋中心地理位置之间的映射。本研究提出了一种ML集成方法，用于定位热带气旋中心坐标，将TC分类和定位嵌入单个端到端学习任务中。该集成模型结合了不同ML模型的TC中心估计。

    Tropical Cyclones (TCs) are counted among the most destructive phenomena that can be found in nature. Every year, globally an average of 90 TCs occur over tropical waters, and global warming is making them stronger, larger and more destructive. The accurate detection and tracking of such phenomena have become a relevant and interesting area of research in weather and climate science. Traditionally, TCs have been identified in large climate datasets through the use of deterministic tracking schemes that rely on subjective thresholds. Machine Learning (ML) models can complement deterministic approaches due to their ability to capture the mapping between the input climatic drivers and the geographical position of the TC center from the available data. This study presents a ML ensemble approach for locating TC center coordinates, embedding both TC classification and localization in a single end-to-end learning task. The ensemble combines TC center estimates of different ML models that agre
    
[^107]: 基于条件扩散模型的值函数估计控制方法

    Value function estimation using conditional diffusion models for control. (arXiv:2306.07290v1 [cs.LG])

    [http://arxiv.org/abs/2306.07290](http://arxiv.org/abs/2306.07290)

    论文提出了一种基于条件扩散模型的值函数估计控制方法（DVF），该方法可以在大量条件化数据上有效地进行训练，并使用只有一小部分示范数据就能超过基准算法。

    

    深度强化学习的一个可靠趋势是性能随参数数量的增加而提高，前提是有充足的训练数据。然而，随着大型模型的需求增加，很可能会出现高质量示范数据不足的问题。我们提出了一种名为扩散值函数的简单算法(DVF)，它使用扩散模型来学习环境和机器人交互动态的联合多步模型，并估计所需任务的值函数。在模拟连续控制任务上，我们证明了我们的方法的有效性，并显示它只需要使用一小部分示范数据就可以胜过基准算法。

    A fairly reliable trend in deep reinforcement learning is that the performance scales with the number of parameters, provided a complimentary scaling in amount of training data. As the appetite for large models increases, it is imperative to address, sooner than later, the potential problem of running out of high-quality demonstrations. In this case, instead of collecting only new data via costly human demonstrations or risking a simulation-to-real transfer with uncertain effects, it would be beneficial to leverage vast amounts of readily-available low-quality data. Since classical control algorithms such as behavior cloning or temporal difference learning cannot be used on reward-free or action-free data out-of-the-box, this solution warrants novel training paradigms for continuous control. We propose a simple algorithm called Diffused Value Function (DVF), which learns a joint multi-step model of the environment-robot interaction dynamics using a diffusion model. This model can be ef
    
[^108]: 无分布风险控制的公平学习排序

    Fair Learning to Rank with Distribution-free Risk Control. (arXiv:2306.07188v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.07188](http://arxiv.org/abs/2306.07188)

    本论文提出了一种新的后置模型无关方法，公平LTR-RC，它不需要昂贵的训练，在保证公平性的同时，还能在效用和公平之间实现有效的权衡。

    

    在线经济中，学习排序方法对用户和物品提供者至关重要。LTR模型的公平性对于按比例分配曝光至关重要。当具有相同相关性的项接收略有不同的分数时，确定性排名模型可能导致不公平的曝光分配。随机LTR模型，包括Plackett-Luce（PL）模型，解决了公平性问题，但在计算成本和性能保证方面存在局限性。为了克服这些局限性，我们提出了公平LTR-RC，一种新的后置模型无关方法。公平LTR-RC利用预先训练的评分函数创建随机LTR模型，消除了昂贵的训练需求。此外，公平LTR-RC使用无分布式风险控制框架对用户指定的效用提供有限的样本保证。通过另外结合Thresholded PL（TPL）模型，我们能够在效用和公平之间实现有效的权衡。实验结果显示，FairLTR-RC在公平性和效用性指标上优于现有方法。

    Learning to Rank (LTR) methods are vital in online economies, affecting users and item providers. Fairness in LTR models is crucial to allocate exposure proportionally to item relevance. The deterministic ranking model can lead to unfair exposure distribution when items with the same relevance receive slightly different scores. Stochastic LTR models, incorporating the Plackett-Luce (PL) model, address fairness issues but have limitations in computational cost and performance guarantees. To overcome these limitations, we propose FairLTR-RC, a novel post-hoc model-agnostic method. FairLTR-RC leverages a pretrained scoring function to create a stochastic LTR model, eliminating the need for expensive training. Furthermore, FairLTR-RC provides finite-sample guarantees on a user-specified utility using distribution-free risk control framework. By additionally incorporating the Thresholded PL (TPL) model, we are able to achieve an effective trade-off between utility and fairness. Experimental
    
[^109]: 内核随机投影深度用于离群点检测

    Kernel Random Projection Depth for Outlier Detection. (arXiv:2306.07056v1 [stat.ML])

    [http://arxiv.org/abs/2306.07056](http://arxiv.org/abs/2306.07056)

    本文提出了一种内核随机投影深度方法，用于处理数据云中的多模式和非凸性，实验结果表明在基准数据集上表现优异。

    

    本文提出了一种扩展的随机投影深度（RPD）方法，用于处理数据云中的多模式和非凸性。在所提出的方法的框架中，RPD在再现核希尔伯特空间中计算。借助内核主成分分析，我们期望所提出的方法可以处理上述多种模式和非凸性。实验结果表明，所提出的方法优于RPD，并可与基准数据集上现有的检测模型相媲美，关于接收操作特征曲线（ROC）下的曲线下面积（AUC）。

    This paper proposes an extension of Random Projection Depth (RPD) to cope with multiple modalities and non-convexity on data clouds. In the framework of the proposed method, the RPD is computed in a reproducing kernel Hilbert space. With the help of kernel principal component analysis, we expect that the proposed method can cope with the above multiple modalities and non-convexity. The experimental results demonstrate that the proposed method outperforms RPD and is comparable to other existing detection models on benchmark datasets regarding Area Under the Curves (AUCs) of Receiver Operating Characteristic (ROC).
    
[^110]: VillanDiffusion: 一种针对扩散模型的统一后门攻击框架。

    VillanDiffusion: A Unified Backdoor Attack Framework for Diffusion Models. (arXiv:2306.06874v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2306.06874](http://arxiv.org/abs/2306.06874)

    本文提出VillanDiffusion，一个针对扩散模型的统一后门攻击框架，涵盖主流的无条件和有条件DM，便于对不同DM配置进行后门分析，并为基于字幕的DM后门攻击提供了新的见解。

    

    扩散模型（DM）是最先进的生成模型之一，它通过迭代添加噪声和去噪学习可逆的损坏过程。它们是许多生成人工智能应用的主干，例如文本到图像有条件生成。但是，最近的研究表明基本无条件DM（例如DDPM和DDIM）易受后门注入攻击，这是一种由于恶意嵌入模型输入的模式而触发的输出操纵攻击。本文提出了一个统一的后门攻击框架（VillanDiffusion），以扩展当前的DM后门分析范围。我们的框架涵盖了主流的无条件和有条件DM（基于去噪和基于评分），以及各种无需训练的采样器进行整体评估。实验证明，我们的统一框架便于对不同DM配置进行后门分析，并为基于字幕的DM后门攻击提供新的见解。

    Diffusion Models (DMs) are state-of-the-art generative models that learn a reversible corruption process from iterative noise addition and denoising. They are the backbone of many generative AI applications, such as text-to-image conditional generation. However, recent studies have shown that basic unconditional DMs (e.g., DDPM and DDIM) are vulnerable to backdoor injection, a type of output manipulation attack triggered by a maliciously embedded pattern at model input. This paper presents a unified backdoor attack framework (VillanDiffusion) to expand the current scope of backdoor analysis for DMs. Our framework covers mainstream unconditional and conditional DMs (denoising-based and score-based) and various training-free samplers for holistic evaluations. Experiments show that our unified framework facilitates the backdoor analysis of different DM configurations and provides new insights into caption-based backdoor attacks on DMs.
    
[^111]: 多模式音文档架构的鲁棒性口语理解

    Multimodal Audio-textual Architecture for Robust Spoken Language Understanding. (arXiv:2306.06819v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.06819](http://arxiv.org/abs/2306.06819)

    本文提出了一种使用多模态语言理解（MLU）模块的口语理解解决方案，结合了音频和文本模态的自我监督特征，并充分利用了预训练语言模型（BERT和RoBERTa），以减轻由ASR错误传播带来的性能下降。

    

    目前的语音助手通常基于级联口语理解（SLU）解决方案，包括自动语音识别（ASR）引擎和自然语言理解（NLU）系统。由于这种方法依靠ASR输出，因此经常遭受所谓的ASR错误传播的影响。在本文中，我们研究了此类ASR错误传播对基于预训练语言模型（PLM）（如BERT和RoBERTa）的最先进NLU系统的影响。此外，提出了一种多模态语言理解（MLU）模块，以减轻由ASR转录中存在的错误引起的SLU性能下降。MLU受益于从音频和文本模态学习的自我监督特征，特别是Wav2Vec用于语音和Bert / RoBERTa用于语言。我们的MLU结合一个编码器网络来嵌入音频信号和一个文本编码器来处理文本转录，然后是一个后期融合层来融合音频和文本逻辑。我们发现，使用这种多模式音文档架构可以有效提高口语理解的鲁棒性。

    Recent voice assistants are usually based on the cascade spoken language understanding (SLU) solution, which consists of an automatic speech recognition (ASR) engine and a natural language understanding (NLU) system. Because such approach relies on the ASR output, it often suffers from the so-called ASR error propagation. In this work, we investigate impacts of this ASR error propagation on state-of-the-art NLU systems based on pre-trained language models (PLM), such as BERT and RoBERTa. Moreover, a multimodal language understanding (MLU) module is proposed to mitigate SLU performance degradation caused by errors present in the ASR transcript. The MLU benefits from self-supervised features learned from both audio and text modalities, specifically Wav2Vec for speech and Bert/RoBERTa for language. Our MLU combines an encoder network to embed the audio signal and a text encoder to process text transcripts followed by a late fusion layer to fuse audio and text logits. We found that the pro
    
[^112]: 提高决策树解释性的有效性

    Improving the Validity of Decision Trees as Explanations. (arXiv:2306.06777v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.06777](http://arxiv.org/abs/2306.06777)

    该论文介绍了一个新的决策树模型，利用挂起的树的方式提高了其解释性和统计性能，达到了无限深度决策树的水平，并可与XGBoost等最先进的方法相媲美。

    

    在基于表格数据的分类和预测中，人们经常使用基于树的模型。这可以在表格数据上与深度神经网络竞争[参见Grinsztajn等人，NeurIPS 2022，arXiv：2207.08815]，并且在某些条件下是可解释的。可解释性取决于树的深度和每个叶节点的准确性。在这里，我们训练了一个低深度的树，其目标是最小化每个叶节点上的最大错误分类，并从低深度树的每个叶节点“挂起”进一步的基于树的模型（例如无限深度的树）。低深度树易于解释，而综合低深度和挂起的基于树的模型的整体统计性能优于使用经典方法（例如CART）训练的无限深度决策树，并且与最先进的方法（例如优化的XGBoost）相当。

    In classification and forecasting with tabular data, one often utilizes tree-based models. This can be competitive with deep neural networks on tabular data [cf. Grinsztajn et al., NeurIPS 2022, arXiv:2207.08815] and, under some conditions, explainable. The explainability depends on the depth of the tree and the accuracy in each leaf of the tree. Here, we train a low-depth tree with the objective of minimising the maximum misclassification error across each leaf node, and then ``suspend'' further tree-based models (e.g., trees of unlimited depth) from each leaf of the low-depth tree. The low-depth tree is easily explainable, while the overall statistical performance of the combined low-depth and suspended tree-based models improves upon decision trees of unlimited depth trained using classical methods (e.g., CART) and is comparable to state-of-the-art methods (e.g., well-tuned XGBoost).
    
[^113]: 可解释的机器学习模型差异比较

    Interpretable Differencing of Machine Learning Models. (arXiv:2306.06473v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.06473](http://arxiv.org/abs/2306.06473)

    本论文提出了一种预测两个机器学习模型输出相似度函数的方法，同时要求表示差异的方式可被人类解释，并通过学习联合代理树提供直观的差异表示和上下文信息，以帮助用户对AI系统进行基础性思维模型的映射。

    

    在选择竞争模型或更新已部署的模型时，理解机器学习（ML）模型之间的差异非常重要。在这些情况下，我们希望在超出准确率等整体指标的基础上，确定差异在特征空间的哪些位置发生。我们将这个模型差异的问题形式化为一种预测两个ML模型输出相似度函数的问题，同时要求表示差异的方式可以被人类解释。我们的解决方案是学习一个联合代理树（JST），它由两个决策树代理构成，分别对应两个模型。JST提供了直观的差异表示，并将变化放置在模型决策逻辑的背景下。上下文很重要，因为它帮助用户将差异映射到AI系统的基础性思维模型。我们还提出了一种精细化过程，以增加JST的精度。我们在不同的数据集和模型上展示了我们方法的有效性。

    Understanding the differences between machine learning (ML) models is of interest in scenarios ranging from choosing amongst a set of competing models, to updating a deployed model with new training data. In these cases, we wish to go beyond differences in overall metrics such as accuracy to identify where in the feature space do the differences occur. We formalize this problem of model differencing as one of predicting a dissimilarity function of two ML models' outputs, subject to the representation of the differences being human-interpretable. Our solution is to learn a Joint Surrogate Tree (JST), which is composed of two conjoined decision tree surrogates for the two models. A JST provides an intuitive representation of differences and places the changes in the context of the models' decision logic. Context is important as it helps users to map differences to an underlying mental model of an AI system. We also propose a refinement procedure to increase the precision of a JST. We dem
    
[^114]: Aria数字孪生：一种新的基准数据集用于自我中心的3D机器感知。

    Aria Digital Twin: A New Benchmark Dataset for Egocentric 3D Machine Perception. (arXiv:2306.06362v1 [cs.CV])

    [http://arxiv.org/abs/2306.06362](http://arxiv.org/abs/2306.06362)

    Aria数字孪生是一个自我中心数据集，具有其它任何数据集都没有的高精度、照片逼真和详尽的真实信息。这个数据集将成为自我中心机器感知评估的新标准。

    

    我们推出了Aria数字孪生（ADT）-一个使用Aria眼镜捕获的自我中心数据集，具有广泛的对象，环境和人类级别的真实数据。该ADT数据集包括200个由穿戴Aria设备的人在两个室内真实场景中执行的真实世界活动序列，包含398个对象实例（324个静态和74个动态）。每个序列包括：a）两个单色相机流，一个RGB相机流，两个IMU流的原始数据；b）完整的传感器校准；c）真实数据，包括Aria设备的连续6自由度（6DoF）姿态，对象6DoF姿态，3D注视矢量，3D人体姿态，2D图像分割，图像深度图；d）照片般真实的合成渲染图像。据我们所知，目前没有现有自我中心数据集能够与ADT的准确性、逼真度和全面性相媲美。通过向研究社区贡献ADT，我们的使命是为自我中心机器感知的评估设立新的标准。

    We introduce the Aria Digital Twin (ADT) - an egocentric dataset captured using Aria glasses with extensive object, environment, and human level ground truth. This ADT release contains 200 sequences of real-world activities conducted by Aria wearers in two real indoor scenes with 398 object instances (324 stationary and 74 dynamic). Each sequence consists of: a) raw data of two monochrome camera streams, one RGB camera stream, two IMU streams; b) complete sensor calibration; c) ground truth data including continuous 6-degree-of-freedom (6DoF) poses of the Aria devices, object 6DoF poses, 3D eye gaze vectors, 3D human poses, 2D image segmentations, image depth maps; and d) photo-realistic synthetic renderings. To the best of our knowledge, there is no existing egocentric dataset with a level of accuracy, photo-realism and comprehensiveness comparable to ADT. By contributing ADT to the research community, our mission is to set a new standard for evaluation in the egocentric machine perce
    
[^115]: LLMs如何改变材料科学和化学：大型语言模型黑客马拉松的反思

    14 Examples of How LLMs Can Transform Materials Science and Chemistry: A Reflection on a Large Language Model Hackathon. (arXiv:2306.06283v1 [cond-mat.mtrl-sci])

    [http://arxiv.org/abs/2306.06283](http://arxiv.org/abs/2306.06283)

    本文记录了一次黑客松活动，参与者使用LLMs进行了各种应用，包括预测分子和材料特性、从非结构化数据中提取知识、为工具设计新界面以及开发新的教育应用。这些多样化的项目反映了LLMs在材料科学和化学领域的多功能性和潜力。

    

    化学和材料科学非常复杂。最近，使用数据驱动或计算技术解决了这种复杂性的中有很大的成功。然而，输入需要非常特定形式的结构以及工具数量不断增长所带来可用性和可访问性的挑战。加上这些学科中的大多数数据都是非结构化的事实，使得这些工具的效率受到限制。本文记录了关于LLMs的黑客松活动中构建的项目。参与者使用LLMs进行了各种应用，包括预测分子和材料的特性、为工具设计新界面、从非结构化数据中提取知识以及开发新的教育应用。各种各样的项目反映了LLMs在这些领域的多功能性和这些模型改变材料科学和化学领域的潜力。

    Chemistry and materials science are complex. Recently, there have been great successes in addressing this complexity using data-driven or computational techniques. Yet, the necessity of input structured in very specific forms and the fact that there is an ever-growing number of tools creates usability and accessibility challenges. Coupled with the reality that much data in these disciplines is unstructured, the effectiveness of these tools is limited.  Motivated by recent works that indicated that large language models (LLMs) might help address some of these issues, we organized a hackathon event on the applications of LLMs in chemistry, materials science, and beyond. This article chronicles the projects built as part of this hackathon. Participants employed LLMs for various applications, including predicting properties of molecules and materials, designing novel interfaces for tools, extracting knowledge from unstructured data, and developing new educational applications.  The diverse
    
[^116]: 强化学习中基于回合限制的近优保守探索

    Near-optimal Conservative Exploration in Reinforcement Learning under Episode-wise Constraints. (arXiv:2306.06265v1 [cs.LG])

    [http://arxiv.org/abs/2306.06265](http://arxiv.org/abs/2306.06265)

    本文研究了强化学习中实现保守探索的问题，提出了名为StepMix的算法，利用现有的安全基线策略平衡开发和探索，同时保证每个回合不违反保守限制，并且能够在不受限制的情况下达到接近最优的后悔量级。

    

    本文研究了在强化学习中实现保守探索的问题，其中学习代理的性能在整个学习过程中保证高于某个特定阈值。研究针对有限状态和动作的标签式回合式马尔可夫决策过程（MDP）环境。本文提出了一种名为StepMix的算法，利用现有的安全基线策略在保证每个回合不违反保守限制的前提下，平衡开发和探索。StepMix具有独特的混合策略设计，自适应地、平滑地插值基线策略和乐观策略之间。理论分析表明，StepMix在不受限制的情况下具有接近最优的后悔量级，说明遵守严格的回合限制不会损害学习性能。此外，还提出了基于随机化的EpsMix算法。

    This paper investigates conservative exploration in reinforcement learning where the performance of the learning agent is guaranteed to be above a certain threshold throughout the learning process. It focuses on the tabular episodic Markov Decision Process (MDP) setting that has finite states and actions. With the knowledge of an existing safe baseline policy, an algorithm termed as StepMix is proposed to balance the exploitation and exploration while ensuring that the conservative constraint is never violated in each episode with high probability. StepMix features a unique design of a mixture policy that adaptively and smoothly interpolates between the baseline policy and the optimistic policy. Theoretical analysis shows that StepMix achieves near-optimal regret order as in the constraint-free setting, indicating that obeying the stringent episode-wise conservative constraint does not compromise the learning performance. Besides, a randomization-based EpsMix algorithm is also proposed
    
[^117]: 通过$\frac{\ell_1}{\ell_2}$正则化延迟代理进行端到端神经网络压缩

    End-to-End Neural Network Compression via $\frac{\ell_1}{\ell_2}$ Regularized Latency Surrogates. (arXiv:2306.05785v1 [cs.LG])

    [http://arxiv.org/abs/2306.05785](http://arxiv.org/abs/2306.05785)

    提出了一种端到端的神经网络压缩技术，通过优化模型的浮点运算量或设备延迟来自动设置压缩超参数。算法速度快，并且可以与多种常用压缩方法一起使用，如剪枝、低秩分解和量化。在GLUE微调任务的BERT压缩中，FLOPs可降低50％，且性能仅下降1％；而在ImageNet-1K上对MobileNetV3进行压缩，则可以使FLOPs降低15％，同时性能基本不损失。

    

    神经网络（NN）的压缩通常需要手动或通过神经网络结构搜索（NAS）设置每个层的压缩超参数（例如，要剪枝的通道数，量化的位宽），这可能会耗费大量计算资源。我们提供了一种端到端技术，通过新颖的$\frac{\ell_1}{\ell_2}$延迟代理优化模型的浮点运算量（FLOPs）或设备延迟来解决此问题。我们的算法非常灵活，可以与许多常用的压缩方法（包括剪枝、低秩分解和量化）一起使用。关键是，它非常快速，几乎与单模型训练相同的时间，这比标准NAS方法可节省大量的训练时间。在GLUE微调任务的BERT压缩中，我们的算法可以使FLOPs降低50％，仅损失1％的性能。而在ImageNet-1K上对MobileNetV3进行压缩，则可以使FLOPs降低15％，同时性能基本不损失。

    Neural network (NN) compression via techniques such as pruning, quantization requires setting compression hyperparameters (e.g., number of channels to be pruned, bitwidths for quantization) for each layer either manually or via neural architecture search (NAS) which can be computationally expensive. We address this problem by providing an end-to-end technique that optimizes for model's Floating Point Operations (FLOPs) or for on-device latency via a novel $\frac{\ell_1}{\ell_2}$ latency surrogate. Our algorithm is versatile and can be used with many popular compression methods including pruning, low-rank factorization, and quantization. Crucially, it is fast and runs in almost the same amount of time as single model training; which is a significant training speed-up over standard NAS methods. For BERT compression on GLUE fine-tuning tasks, we achieve $50\%$ reduction in FLOPs with only $1\%$ drop in performance. For compressing MobileNetV3 on ImageNet-1K, we achieve $15\%$ reduction in
    
[^118]: 带有用户级差分隐私的联邦线性上下文强化学习

    Federated Linear Contextual Bandits with User-level Differential Privacy. (arXiv:2306.05275v1 [cs.LG])

    [http://arxiv.org/abs/2306.05275](http://arxiv.org/abs/2306.05275)

    本文研究了带有用户级差分隐私的联邦线性上下文强化学习模型，为CDP提出了近乎最优的联邦算法\robin，在LDP下证明了学习必须承受至少一个遗憾膨胀因子。

    

    本文研究了在用户级差分隐私（DP）概念下的联邦线性上下文强化学习。我们首先介绍了一个统一的联邦强化学习框架，可以适应顺序决策设置中DP的各种定义。然后在联邦强化学习框架中正式引入了用户级中心DP和本地DP，并研究了联邦线性上下文强化学习模型中学习遗憾和相应DP保证之间的基本权衡。对于CDP，我们提出了一种称为\robin的联邦算法，并通过推导在满足用户级DP时的几乎匹配的上界和下界遗憾界，证明其在客户端数量$M$和隐私预算$\varepsilon$方面是近乎最优的。对于LDP，我们获得了几个下界，表明在用户级$(\varepsilon,\delta)$-LDP下学习必须至少承受一个遗憾膨胀因子至少为{$\min\{1/\varepsilon,M\}$或$\min\{1/\sqrt{\varepsilon},\sq

    This paper studies federated linear contextual bandits under the notion of user-level differential privacy (DP). We first introduce a unified federated bandits framework that can accommodate various definitions of DP in the sequential decision-making setting. We then formally introduce user-level central DP (CDP) and local DP (LDP) in the federated bandits framework, and investigate the fundamental trade-offs between the learning regrets and the corresponding DP guarantees in a federated linear contextual bandits model. For CDP, we propose a federated algorithm termed as \robin and show that it is near-optimal in terms of the number of clients $M$ and the privacy budget $\varepsilon$ by deriving nearly-matching upper and lower regret bounds when user-level DP is satisfied. For LDP, we obtain several lower bounds, indicating that learning under user-level $(\varepsilon,\delta)$-LDP must suffer a regret blow-up factor at least {$\min\{1/\varepsilon,M\}$ or $\min\{1/\sqrt{\varepsilon},\sq
    
[^119]: EMO：用于小样本元学习的情节记忆优化

    EMO: Episodic Memory Optimization for Few-Shot Meta-Learning. (arXiv:2306.05189v1 [cs.LG])

    [http://arxiv.org/abs/2306.05189](http://arxiv.org/abs/2306.05189)

    EMO是一种元学习的情节记忆优化方案，通过在外部存储器中记录过去任务的梯度历史，实现小样本学习，无论提供的梯度信息是否可靠，都可以推动参数更新朝着正确的方向前进。

    

    小样本元学习由于任务训练样本数量的限制对梯度下降优化提出了挑战。为了解决这个问题，本文提出了一种元学习的情节记忆优化方案，称为EMO。EMO受到人类从脑内记忆中回忆过去学习经验的能力的启发，将过去任务的梯度历史记录在外部存储器中，以增强记忆的方式进行小样本学习。通过学习保留和回忆过去训练任务的学习过程，即使仅有有限数量的示例提供了不可靠的梯度，EMO也可以推动参数更新朝着正确的方向前进。我们在理论上证明了该算法对于平滑、强凸目标函数会收敛。EMO是通用的、灵活的、与模型无关的优化器，可无缝嵌入现有的基于优化的小样本元学习方法。实证结果表明EMO可以提高准确性和收敛速度。

    Few-shot meta-learning presents a challenge for gradient descent optimization due to the limited number of training samples per task. To address this issue, we propose an episodic memory optimization for meta-learning, we call \emph{EMO}, which is inspired by the human ability to recall past learning experiences from the brain's memory. EMO retains the gradient history of past experienced tasks in external memory, enabling few-shot learning in a memory-augmented way. By learning to retain and recall the learning process of past training tasks, EMO nudges parameter updates in the right direction, even when the gradients provided by a limited number of examples are uninformative. We prove theoretically that our algorithm converges for smooth, strongly convex objectives. EMO is generic, flexible, and model-agnostic, making it a simple plug-and-play optimizer that can be seamlessly embedded into existing optimization-based few-shot meta-learning approaches. Empirical results show that EMO 
    
[^120]: FLEdge：边缘计算系统中联邦机器学习应用的基准测试

    FLEdge: Benchmarking Federated Machine Learning Applications in Edge Computing Systems. (arXiv:2306.05172v1 [cs.LG])

    [http://arxiv.org/abs/2306.05172](http://arxiv.org/abs/2306.05172)

    FLEdge是一个面向边缘计算系统中FL工作量的基准测试，通过研究硬件异构性、能量效率和隐私级别对FL系统训练的影响，以及客户端退出对最新FL策略的影响，提供了训练最先进的FL工作负载的新见解。

    

    近年来，联邦机器学习（FL）备受关注。 FL基准测试主要在模拟系统或数据中心环境中进行探索，忽略了与边缘计算密切相关的实际系统设置。 我们通过引入面向边缘计算系统中FL工作量的基准测试FLEdge来弥补这一研究差距。我们系统地研究了硬件异构性、训练过程中的能量效率以及各种不同隐私级别对FL系统训练的影响。为了使这个基准测试适用于实际场景，我们评估了客户端退出对具有高达50％失效率的最新FL策略的影响。 FLEdge提供了新的见解，例如，在旧GPU加速的嵌入式设备上训练最先进的FL工作负载比在现代服务器级GPU上训练高达3倍的能量效率。

    Federated Machine Learning (FL) has received considerable attention in recent years. FL benchmarks are predominantly explored in either simulated systems or data center environments, neglecting the setups of real-world systems, which are often closely linked to edge computing. We close this research gap by introducing FLEdge, a benchmark targeting FL workloads in edge computing systems. We systematically study hardware heterogeneity, energy efficiency during training, and the effect of various differential privacy levels on training in FL systems. To make this benchmark applicable to real-world scenarios, we evaluate the impact of client dropouts on state-of-the-art FL strategies with failure rates as high as 50%. FLEdge provides new insights, such as that training state-of-the-art FL workloads on older GPU-accelerated embedded devices is up to 3x more energy efficient than on modern server-grade GPUs.
    
[^121]: 长期序列预测是否需要复杂的注意力机制和额外的长输入数据？

    Does Long-Term Series Forecasting Need Complex Attention and Extra Long Inputs?. (arXiv:2306.05035v1 [cs.LG])

    [http://arxiv.org/abs/2306.05035](http://arxiv.org/abs/2306.05035)

    本论文介绍了一种新的轻量级周期-注意机制，名为Periodformer，解决了长期序列预测中的两个主要问题，并证明了Transformer-based方法不需要额外长的输入序列来保证性能。

    

    随着基于Transformer的模型在各种时间序列任务上取得了令人印象深刻的性能，长期序列预测（LTSF）任务在近年来也受到了广泛关注。然而，由于基于Transformer的方法所固有的计算复杂性和需要长序列，它在LTSF任务上的应用仍然存在两个主要问题需要进一步研究：1）这些方法设计的稀疏注意机制是否实际上缩短了真实设备上的运行时间；2）这些模型是否需要额外长的输入序列来保证它们的性能？本论文的答案是否定的。因此，为更好地解决这两个问题，我们设计了一种轻量级的周期-注意机制（Periodformer），通过显式周期性和内置的接近性来重新设计长期子序列和短期子序列的聚合。同时，我们还嵌入了一个门控机制到Periodformer中以调整注意力的影响。

    As Transformer-based models have achieved impressive performance on various time series tasks, Long-Term Series Forecasting (LTSF) tasks have also received extensive attention in recent years. However, due to the inherent computational complexity and long sequences demanding of Transformer-based methods, its application on LTSF tasks still has two major issues that need to be further investigated: 1) Whether the sparse attention mechanism designed by these methods actually reduce the running time on real devices; 2) Whether these models need extra long input sequences to guarantee their performance? The answers given in this paper are negative. Therefore, to better copy with these two issues, we design a lightweight Period-Attention mechanism (Periodformer), which renovates the aggregation of long-term subseries via explicit periodicity and short-term subseries via built-in proximity. Meanwhile, a gating mechanism is embedded into Periodformer to regulate the influence of the attention
    
[^122]: 多任务训练结合领域内语言模型进行诊断推理

    Multi-Task Training with In-Domain Language Models for Diagnostic Reasoning. (arXiv:2306.04551v1 [cs.CL])

    [http://arxiv.org/abs/2306.04551](http://arxiv.org/abs/2306.04551)

    本文研究了领域内与领域外语言模型以及多任务与单任务训练的比较，并证明了通过临床训练的多任务语言模型在临床诊断推理任务中表现优异，建立了新的最优性能。

    

    生成人工智能是增强临床诊断决策支持和减少诊断错误的一种有前途的方向。为进一步发展临床人工智能系统，引入了诊断推理基准（DR.BENCH）作为全面的生成人工智能框架，由六个任务组成，代表临床推理的关键组成部分。本文进行了领域内与领域外语言模型以及多任务与单任务训练的比较分析，重点关注 DR.BENCH 的问题总结任务（Gao 等，2023）。我们证明，通过临床训练的多任务语言模型大幅优于其一般领域的对应模型，建立了新的最优性能， ROUGE-L 得分为 28.55。这项研究强调了领域特定训练在优化临床诊断推理任务中的价值。

    Generative artificial intelligence (AI) is a promising direction for augmenting clinical diagnostic decision support and reducing diagnostic errors, a leading contributor to medical errors. To further the development of clinical AI systems, the Diagnostic Reasoning Benchmark (DR.BENCH) was introduced as a comprehensive generative AI framework, comprised of six tasks representing key components in clinical reasoning. We present a comparative analysis of in-domain versus out-of-domain language models as well as multi-task versus single task training with a focus on the problem summarization task in DR.BENCH (Gao et al., 2023). We demonstrate that a multi-task, clinically trained language model outperforms its general domain counterpart by a large margin, establishing a new state-of-the-art performance, with a ROUGE-L score of 28.55. This research underscores the value of domain-specific training for optimizing clinical diagnostic reasoning tasks.
    
[^123]: 公平的列子集选择

    Fair Column Subset Selection. (arXiv:2306.04489v1 [cs.LG])

    [http://arxiv.org/abs/2306.04489](http://arxiv.org/abs/2306.04489)

    解决了公平的列子集选择问题，通过已知方法基于确定性杠杆分数采样，提出了一种有效算法，可以在1.5倍的大小下实现与两倍相同的近似保证。

    

    我们考虑公平的列子集选择问题。特别地，我们假设数据中存在两个群体，并且所选列子集必须相对于它们各自的最佳秩-k逼近提供良好的近似。我们证明了这种公平设置引入了重大挑战：为了扩展已知结果，人们不能做得比简单地选择原始方法的两倍列更好。我们采用了基于确定性杠杆分数采样的已知方法，并且在存在两个群体的情况下，仅仅采样适当大小的子集就变得NP难。而找到两倍于所需大小的子集则非常简单，我们提供了一种有效的算法，它可以在基本上1.5倍的大小的情况下实现相同的保证。我们通过对真实世界数据的广泛实验验证了我们的方法。

    We consider the problem of fair column subset selection. In particular, we assume that two groups are present in the data, and the chosen column subset must provide a good approximation for both, relative to their respective best rank-k approximations. We show that this fair setting introduces significant challenges: in order to extend known results, one cannot do better than the trivial solution of simply picking twice as many columns as the original methods. We adopt a known approach based on deterministic leverage-score sampling, and show that merely sampling a subset of appropriate size becomes NP-hard in the presence of two groups. Whereas finding a subset of two times the desired size is trivial, we provide an efficient algorithm that achieves the same guarantees with essentially 1.5 times that size. We validate our methods through an extensive set of experiments on real-world data.
    
[^124]: 随机投影和符号随机投影的差分隐私算法

    Differential Privacy with Random Projections and Sign Random Projections. (arXiv:2306.01751v1 [cs.CR])

    [http://arxiv.org/abs/2306.01751](http://arxiv.org/abs/2306.01751)

    本文提出了一系列差分隐私算法，其中iDP-SignRP算法在个体差分隐私设置下效果显著，DP-SignOPORP算法改进了现有算法，DP-OPORP算法表现最优，iDP提供了一种适用于特定数据集的隐私保护解决方案。

    

    本文提出了一系列基于随机投影（RP）的差分隐私（DP）算法，适用于机器学习、数据挖掘和信息检索等各种应用。其中，基于符号随机投影（SignRP）的iDP-SignRP算法在个体差分隐私（iDP）设置下非常有效，而DP-SignOPORP算法在标准DP设置下利用“一次排列+一次随机投影”（OPORP）极大地改进了文献中现有的算法。除不考虑符号之外，在DP-RP家族中，DP-OPORP算法表现最佳。iDP（个体差分隐私）的概念仅适用于特定的数据集。虽然iDP不是严格的DP，但在某些应用中（如向小组用户发布包括嵌入信息或个性化推荐等内容的数据集，而不泄露不属于该组的个人的任何私人信息）可能很有用。

    In this paper, we develop a series of differential privacy (DP) algorithms from a family of random projections (RP), for general applications in machine learning, data mining, and information retrieval. Among the presented algorithms, \textbf{iDP-SignRP} is remarkably effective under the setting of ``individual differential privacy'' (iDP), based on sign random projections (SignRP). Also, \textbf{DP-SignOPORP} considerably improves existing algorithms in the literature under the standard DP setting, using ``one permutation + one random projection'' (OPORP), where OPORP is a variant of the celebrated count-sketch method with fixed-length binning and normalization. Without taking signs, among the DP-RP family, \textbf{DP-OPORP} achieves the best performance.  The concept of iDP (individual differential privacy) is defined only on a particular dataset of interest. While iDP is not strictly DP, iDP might be useful in certain applications, such as releasing a dataset (including sharing embe
    
[^125]: ReLU拯救：用正数优势改进您的On-Policy Actor-Critic算法

    ReLU to the Rescue: Improve Your On-Policy Actor-Critic with Positive Advantages. (arXiv:2306.01460v1 [cs.LG])

    [http://arxiv.org/abs/2306.01460](http://arxiv.org/abs/2306.01460)

    本研究提出了一种新的On-Policy深度强化学习算法，该算法通过在保守值估计和谨慎探索方面的明确整合来解决了当前算法不能充分考虑谨慎交互的问题。

    

    本文介绍了一种增强On-Policy深度强化学习（DRL）算法效果的新方法。我们的方法通过在两个关键方面明确地整合谨慎的环境交互来解决当前On-Policy算法（如Proximal Policy Optimization和Asynchronous Advantage Actor-Critic）不能充分考虑谨慎交互的问题：通过最大化真实价值函数加上常量的下界，从而促进“保守值估计”，并通过引入Thompson采样来进行谨慎探索。这些特点通过对A3C算法进行三个惊人简单的修改实现：通过ReLU函数处理优势估计，进行谱归一化和随机失活。我们提供了理论证明，证明了我们的算法最大化了下界，这也是多智能体情况下Regret Matching Policy Gradients（RMPG）的基础。

    In this paper, we introduce a novel method for enhancing the effectiveness of on-policy Deep Reinforcement Learning (DRL) algorithms. Current on-policy algorithms, such as Proximal Policy Optimization (PPO) and Asynchronous Advantage Actor-Critic (A3C), do not sufficiently account for cautious interaction with the environment. Our method addresses this gap by explicitly integrating cautious interaction in two critical ways: by maximizing a lower-bound on the true value function plus a constant, thereby promoting a \textit{conservative value estimation}, and by incorporating Thompson sampling for cautious exploration. These features are realized through three surprisingly simple modifications to the A3C algorithm: processing advantage estimates through a ReLU function, spectral normalization, and dropout. We provide theoretical proof that our algorithm maximizes the lower bound, which also grounds Regret Matching Policy Gradients (RMPG), a discrete-action on-policy method for multi-agen
    
[^126]: DyGen: 通过动态增强的生成建模从噪声标签中学习

    DyGen: Learning from Noisy Labels via Dynamics-Enhanced Generative Modeling. (arXiv:2305.19395v1 [cs.CL])

    [http://arxiv.org/abs/2305.19395](http://arxiv.org/abs/2305.19395)

    DyGen是一个动态增强的生成模型，使用嵌入空间中的动态模式可以改善从噪声标签中学习的精度，同时使用共规正则化机制来最小化潜在噪声标签和先验的影响，展示了最先进的性能。

    

    在许多实际应用中，训练数据可能包含不正确或已损坏的标签，从噪声标签中学习是一个挑战。当使用带有噪声标签的语言模型进行微调时，模型很容易过度拟合标签噪声，导致性能下降。大多数现有的从噪声标签中学习的方法使用静态输入特征进行去噪，但这些方法受限于它们在真实标签分布方面提供的信息，可能导致有偏的或不正确的预测。在这项工作中，我们提出了一个名为DyGen的动态增强生成模型，该模型在语言模型的微调过程中利用嵌入空间中的动态模式来改善噪声标签预测。DyGen使用变分自动编码框架从噪声标签和训练动态中推断真实标签的后验分布。此外，使用共规正则化机制来最小化潜在噪声标签和先验的影响。在存在不同级别的标签噪声情况下，DyGen在两个大规模文本分类数据集上展示了最先进的性能。

    Learning from noisy labels is a challenge that arises in many real-world applications where training data can contain incorrect or corrupted labels. When fine-tuning language models with noisy labels, models can easily overfit the label noise, leading to decreased performance. Most existing methods for learning from noisy labels use static input features for denoising, but these methods are limited by the information they can provide on true label distributions and can result in biased or incorrect predictions. In this work, we propose the Dynamics-Enhanced Generative Model (DyGen), which uses dynamic patterns in the embedding space during the fine-tuning process of language models to improve noisy label predictions. DyGen uses the variational auto-encoding framework to infer the posterior distributions of true labels from noisy labels and training dynamics. Additionally, a co-regularization mechanism is used to minimize the impact of potentially noisy labels and priors. DyGen demonstr
    
[^127]: DIVA：基于狄利克雷过程的变分自编码器的增量深度聚类算法

    DIVA: A Dirichlet Process Based Incremental Deep Clustering Algorithm via Variational Auto-Encoder. (arXiv:2305.14067v1 [cs.LG])

    [http://arxiv.org/abs/2305.14067](http://arxiv.org/abs/2305.14067)

    本文提出了DIVA算法，一个基于狄利克雷过程的增量深度聚类框架，利用无限混合高斯作为先验，并利用一种记忆化的在线变分推理方法实现簇的动态适应移动，而不需要先知道特征的数量。该算法表现优越，特别是在增量特征的情况下。

    

    基于生成模型的深度聚类框架在分类复杂数据方面表现出色，但在处理动态和复杂特征方面受到限制，因为它们需要先知道簇的数量。本文提出了一个非参数深度聚类框架，采用无限混合高斯作为先验。我们的框架利用一种记忆化的在线变分推理方法，实现了簇的“出生”和“合并”移动，使我们的框架能够以“动态适应”的方式聚类数据，而不需要先知道特征的数量。我们把该框架命名为DIVA，即基于狄利克雷过程的增量深度聚类框架的变分自编码器。我们的框架在分类具有动态变化特征的复杂数据方面表现优越，特别是在增量特征的情况下，超过了最先进的基准。

    Generative model-based deep clustering frameworks excel in classifying complex data, but are limited in handling dynamic and complex features because they require prior knowledge of the number of clusters. In this paper, we propose a nonparametric deep clustering framework that employs an infinite mixture of Gaussians as a prior. Our framework utilizes a memoized online variational inference method that enables the "birth" and "merge" moves of clusters, allowing our framework to cluster data in a "dynamic-adaptive" manner, without requiring prior knowledge of the number of features. We name the framework as DIVA, a Dirichlet Process-based Incremental deep clustering framework via Variational Auto-Encoder. Our framework, which outperforms state-of-the-art baselines, exhibits superior performance in classifying complex data with dynamically changing features, particularly in the case of incremental features.
    
[^128]: 超越数据重新加权：核矩法估计

    Estimation Beyond Data Reweighting: Kernel Method of Moments. (arXiv:2305.10898v1 [cs.LG])

    [http://arxiv.org/abs/2305.10898](http://arxiv.org/abs/2305.10898)

    本论文提出了一种新的核矩法估计器，称为KMM，其用于超越数据重新加权的矩方法模型，解除了关于使用 $\varphi$-散度相关的限制。

    

    在机器学习与统计学等多个领域中都会出现矩约束和条件对应，其中，广义矩法（GMM）作为一个估计模型已经引起了人们的关注。然而，往往由于使用 $\varphi$-散度的相关限制将候选分布限制为数据样本的重新加权。而本论文提出了一种新的矩估计方法——基于最大均值偏差的经验似然估计器，即核矩法(KMM)，其实现超越了对数据的重新加权。

    Moment restrictions and their conditional counterparts emerge in many areas of machine learning and statistics ranging from causal inference to reinforcement learning. Estimators for these tasks, generally called methods of moments, include the prominent generalized method of moments (GMM) which has recently gained attention in causal inference. GMM is a special case of the broader family of empirical likelihood estimators which are based on approximating a population distribution by means of minimizing a $\varphi$-divergence to an empirical distribution. However, the use of $\varphi$-divergences effectively limits the candidate distributions to reweightings of the data samples. We lift this long-standing limitation and provide a method of moments that goes beyond data reweighting. This is achieved by defining an empirical likelihood estimator based on maximum mean discrepancy which we term the kernel method of moments (KMM). We provide a variant of our estimator for conditional moment
    
[^129]: 追赶蒸馏：加速采样只需一次训练

    Catch-Up Distillation: You Only Need to Train Once for Accelerating Sampling. (arXiv:2305.10769v1 [cs.LG])

    [http://arxiv.org/abs/2305.10769](http://arxiv.org/abs/2305.10769)

    本文提出了一种名为“追赶蒸馏”的方法，通过调整传统采样算法，让速度估计模型的当前时刻输出与其先前时刻输出和地面真实标签对齐，从而实现只需一次训练便能加速采样的效果。

    

    扩散概率模型在各种机器学习领域取得了令人瞩目的进展。然而，为了实现高质量的合成样本，通常需要执行大量的采样步骤，这阻碍了实时样本合成的可能性。传统的通过知识蒸馏加速采样的算法依赖于预训练的模型权重和离散时间步骤场景，需要额外的培训课程才能实现他们的目标。为了解决这些问题，我们提出了追赶蒸馏（CUD），它鼓励速度估计模型的当前时刻输出“追赶”其先前时刻输出。具体而言，CUD调整了原始的常微分方程（ODE）训练目标，以使当前时刻输出与地面真实标签和先前时刻输出对齐，利用基于龙格-库塔的多步对齐蒸馏进行精确的ODE估计，同时防止异步更新。

    Diffusion Probability Models (DPMs) have made impressive advancements in various machine learning domains. However, achieving high-quality synthetic samples typically involves performing a large number of sampling steps, which impedes the possibility of real-time sample synthesis. Traditional accelerated sampling algorithms via knowledge distillation rely on pre-trained model weights and discrete time step scenarios, necessitating additional training sessions to achieve their goals. To address these issues, we propose the Catch-Up Distillation (CUD), which encourages the current moment output of the velocity estimation model ``catch up'' with its previous moment output. Specifically, CUD adjusts the original Ordinary Differential Equation (ODE) training objective to align the current moment output with both the ground truth label and the previous moment output, utilizing Runge-Kutta-based multi-step alignment distillation for precise ODE estimation while preventing asynchronous updates
    
[^130]: 通过强化学习发掘最佳量子纠错码的方法发现

    Discovery of Optimal Quantum Error Correcting Codes via Reinforcement Learning. (arXiv:2305.06378v1 [quant-ph])

    [http://arxiv.org/abs/2305.06378](http://arxiv.org/abs/2305.06378)

    该论文介绍了一种使用强化学习策略来发掘最佳量子纠错码的方法，该方法可以训练代理以最大化编码距离或最小化在偏置Pauli噪声下的逻辑错误概率。作者证明，与其他CSS代码相比，他们可以限制量子比特数量并获得优越的结果。

    

    最近提出的量子乐高框架为利用简单的方法生成复杂的量子纠错码（QECC）提供了一种强大的方法。我们将这个过程变成了一个游戏，并使用强化学习（RL）解锁了一种设计和发掘编码的新途径。 RL的一个好处是我们可以指定待优化的编码的\textit{任意}属性。我们针对两种这样的属性进行训练，最大化编码距离和在偏置Pauli噪声下最小化逻辑错误的概率。针对第一个属性，我们发现通过训练的代理能够识别增加编码距离的方法，超过原始的级联方法，在13个量子比特上饱和线性编程界限的CSS编码。对于学习目标是在偏置Pauli噪声下最小化逻辑错误概率，我们发现了在这个任务中最好的已知CSS代码，针对$\lesssim 20$个量子比特。与其他（局部变形的）CSS代码，包括Surface，XZZX和2D Color codes相比，我们的$[[17,1,3]]$编码构造实际上具有优势。

    The recently introduced Quantum Lego framework provides a powerful method for generating complex quantum error correcting codes (QECCs) out of simple ones. We gamify this process and unlock a new avenue for code design and discovery using reinforcement learning (RL). One benefit of RL is that we can specify \textit{arbitrary} properties of the code to be optimized. We train on two such properties, maximizing the code distance, and minimizing the probability of logical error under biased Pauli noise. For the first, we show that the trained agent identifies ways to increase code distance beyond naive concatenation, saturating the linear programming bound for CSS codes on 13 qubits. With a learning objective to minimize the logical error probability under biased Pauli noise, we find the best known CSS code at this task for $\lesssim 20$ qubits. Compared to other (locally deformed) CSS codes, including Surface, XZZX, and 2D Color codes, our $[[17,1,3]]$ code construction actually has \text
    
[^131]: HybridNet: 基于几何与拓扑视角的VLSI阻塞预测的双分支融合

    HybridNet: Dual-Branch Fusion of Geometrical and Topological Views for VLSI Congestion Prediction. (arXiv:2305.05374v1 [cs.LG])

    [http://arxiv.org/abs/2305.05374](http://arxiv.org/abs/2305.05374)

    本文提出了HybridNet，一种基于几何与拓扑视角的VLSI阻塞预测的双分支融合网络，通过在网络结构中做出几个关键设计，充分综合电路的拓扑与几何特征，相较于以往方法取得了10.9％的提高。

    

    准确的阻塞预测是帮助设计师在VLSI设计周期内更快迭代的重要环节，而本文提出了一种新的策略，通过在网络结构中做出几个关键设计，充分综合电路的拓扑与几何特征。具体来说，我们构建了两个独立的图（几何图、拓扑图），根据它们的唯一属性采用不同的边缘构建方案。然后，我们提出了一个双分支网络，每个路径中都有不同的编码器层，并通过精细的融合策略进行聚合表示。我们的网络名为HybridNet，不仅提供了一种简单而有效的方法来捕捉单元之间的几何交互，而且还保留了原始电路拓扑关系。在ISPD2015基准测试上的实验结果显示，相较于以往方法，我们取得了10.9％的提高。

    Accurate early congestion prediction can prevent unpleasant surprises at the routing stage, playing a crucial character in assisting designers to iterate faster in VLSI design cycles. In this paper, we introduce a novel strategy to fully incorporate topological and geometrical features of circuits by making several key designs in our network architecture. To be more specific, we construct two individual graphs (geometry-graph, topology-graph) with distinct edge construction schemes according to their unique properties. We then propose a dual-branch network with different encoder layers in each pathway and aggregate representations with a sophisticated fusion strategy. Our network, named HybridNet, not only provides a simple yet effective way to capture the geometric interactions of cells, but also preserves the original topological relationships in the netlist. Experimental results on the ISPD2015 benchmarks show that we achieve an improvement of 10.9% compared to previous methods.
    
[^132]: 带有截断意识注意力的动态嵌入学习模型用于CTR预测

    DELTA: Dynamic Embedding Learning with Truncated Conscious Attention for CTR Prediction. (arXiv:2305.04891v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2305.04891](http://arxiv.org/abs/2305.04891)

    该论文提出了一种名为DELTA的CTR模型，使用截断意识注意力进行动态嵌入学习，有效地解决了上下文中无效和冗余特征的问题。

    

    点击率（CTR）预测是产品和内容推荐中关键的任务，学习有效的特征嵌入具有重要意义。传统方法通常学习固定的特征表示，而缺乏根据上下文信息动态调整特征表示的机制，导致性能不佳。一些近期的方法尝试通过学习位权重或增强嵌入来解决这个问题，但是受到上下文中无信息或冗余特征的影响。为了解决这个问题，我们借鉴了意识加工中全局工作区理论，该理论认为只有特定的产品特征与点击行为相关，其余特征可能会噪音干扰，甚至有害，因此提出了一种带有截断意识注意力的动态嵌入学习模型DELTA进行CTR预测。

    Click-Through Rate (CTR) prediction is a pivotal task in product and content recommendation, where learning effective feature embeddings is of great significance. However, traditional methods typically learn fixed feature representations without dynamically refining feature representations according to the context information, leading to suboptimal performance. Some recent approaches attempt to address this issue by learning bit-wise weights or augmented embeddings for feature representations, but suffer from uninformative or redundant features in the context. To tackle this problem, inspired by the Global Workspace Theory in conscious processing, which posits that only a specific subset of the product features are pertinent while the rest can be noisy and even detrimental to human-click behaviors, we propose a CTR model that enables Dynamic Embedding Learning with Truncated Conscious Attention for CTR prediction, termed DELTA. DELTA contains two key components: (I) conscious truncatio
    
[^133]: PGB：用于异构网络表示学习的PubMed图数据集基准

    PGB: A PubMed Graph Benchmark for Heterogeneous Network Representation Learning. (arXiv:2305.02691v1 [cs.LG])

    [http://arxiv.org/abs/2305.02691](http://arxiv.org/abs/2305.02691)

    介绍了一个基于PubMed数据库的PGB基准数据集，用于评估生物医学文献的异构图嵌入。该数据集包含丰富的元数据和来自不同数据集的21个系统性评价主题的评估任务。

    

    生物医学文献的数量快速增长，但是捕捉这些文章的文献信息的异质性仍然相对较少研究。尽管通过异构图神经网络的图挖掘研究已经成为研究热点，但它们是否捕捉到了PubMed数据库的异质性仍不清楚，而这是一个包含超过3300万篇文章的庞大数字资料库。我们介绍了PubMed Graph Benchmark（PGB），这是一个用于评估生物医学文献异构图嵌入的新的基准数据集。PGB是迄今为止最大的异构网络之一，包含3000万篇英文文章。该基准数据集包含丰富的元数据，包括摘要、作者、引用、MeSH术语、MeSH层次结构和其他一些信息。基准数据集包含来自3个不同数据集的21个系统性评价主题的评估任务。在PGB中，我们将与PubMed生物医学文章相关的元数据聚合成一致的。

    There has been a rapid growth in biomedical literature, yet capturing the heterogeneity of the bibliographic information of these articles remains relatively understudied. Although graph mining research via heterogeneous graph neural networks has taken center stage, it remains unclear whether these approaches capture the heterogeneity of the PubMed database, a vast digital repository containing over 33 million articles. We introduce PubMed Graph Benchmark (PGB), a new benchmark dataset for evaluating heterogeneous graph embeddings for biomedical literature. PGB is one of the largest heterogeneous networks to date and consists of 30 million English articles. The benchmark contains rich metadata including abstract, authors, citations, MeSH terms, MeSH hierarchy, and some other information. The benchmark contains an evaluation task of 21 systematic reviews topics from 3 different datasets. In PGB, we aggregate the metadata associated with the biomedical articles from PubMed into a unified
    
[^134]: FormNetV2：用于表格文档信息提取的多模态图形对比学习

    FormNetV2: Multimodal Graph Contrastive Learning for Form Document Information Extraction. (arXiv:2305.02549v1 [cs.CL])

    [http://arxiv.org/abs/2305.02549](http://arxiv.org/abs/2305.02549)

    该论文提出了一种用于表格文档信息提取的多模态图形对比学习策略（FormNetV2），该方法能够统一所有模态的自监督预训练到一个损失中，并在多个基准测试中取得了最佳表现。

    

    自监督预训练技术的出现导致了多模态学习在表格文档理解中的激增。然而，现有的扩展掩码语言建模到其他模态的方法需要仔细的多任务调整、复杂的重构目标设计或额外的预训练数据。在FormNetV2中，我们引入了一种集中的多模态图对比学习策略，以统一所有模态的自监督预训练到一个损失中。图对比目标最大化多模态表示的一致性，为所有模态提供自然的相互作用，而不需要特殊的定制。此外，我们在连接图边缘的一对标记的边框内提取图像特征，捕捉更有针对性的视觉线索，而无需加载经过复杂和单独预训练的图像嵌入器。FormNetV2在FUNSD、CORD、SROIE和Payment基准测试中确立了最新的最佳表现水平。

    The recent advent of self-supervised pre-training techniques has led to a surge in the use of multimodal learning in form document understanding. However, existing approaches that extend the mask language modeling to other modalities require careful multi-task tuning, complex reconstruction target designs, or additional pre-training data. In FormNetV2, we introduce a centralized multimodal graph contrastive learning strategy to unify self-supervised pre-training for all modalities in one loss. The graph contrastive objective maximizes the agreement of multimodal representations, providing a natural interplay for all modalities without special customization. In addition, we extract image features within the bounding box that joins a pair of tokens connected by a graph edge, capturing more targeted visual cues without loading a sophisticated and separately pre-trained image embedder. FormNetV2 establishes new state-of-the-art performance on FUNSD, CORD, SROIE and Payment benchmarks with 
    
[^135]: 构建可信人工智能：从人工智能原则、伦理和主要需求到负责任的人工智能系统和监管

    Connecting the Dots in Trustworthy Artificial Intelligence: From AI Principles, Ethics, and Key Requirements to Responsible AI Systems and Regulation. (arXiv:2305.02231v1 [cs.CY])

    [http://arxiv.org/abs/2305.02231](http://arxiv.org/abs/2305.02231)

    该论文旨在探讨可信人工智能的构建，包括从法律、伦理和技术、社会角度确保其健壮性。实现真正可信的人工智能涉及到更广阔的愿景，考虑到伦理方面、风险方面、以及对七个技术需求的支持度和大局整体之关系。

    

    可信人工智能基于七个技术需求，分别从法律、伦理和技术、社会角度确保其健壮性。然而，实现真正可信的人工智能涉及到更广阔的愿景，包括系统生命周期中所有参与流程和参与者可信性的考量。一个更全面的愿景将考虑到伦理方面、风险方面、以下要件的支持度以及大局整体之关系。评估七个需求之技术方面、伦理方面和监管挑战方面。

    Trustworthy Artificial Intelligence (AI) is based on seven technical requirements sustained over three main pillars that should be met throughout the system's entire life cycle: it should be (1) lawful, (2) ethical, and (3) robust, both from a technical and a social perspective. However, attaining truly trustworthy AI concerns a wider vision that comprises the trustworthiness of all processes and actors that are part of the system's life cycle, and considers previous aspects from different lenses. A more holistic vision contemplates four essential axes: the global principles for ethical use and development of AI-based systems, a philosophical take on AI ethics, a risk-based approach to AI regulation, and the mentioned pillars and requirements. The seven requirements (human agency and oversight; robustness and safety; privacy and data governance; transparency; diversity, non-discrimination and fairness; societal and environmental wellbeing; and accountability) are analyzed from a triple
    
[^136]: 基于能量模型的零样本场景重新排列规划器

    Energy-based Models as Zero-Shot Planners for Compositional Scene Rearrangement. (arXiv:2304.14391v1 [cs.RO])

    [http://arxiv.org/abs/2304.14391](http://arxiv.org/abs/2304.14391)

    本文提出一种基于能量模型的零样本场景重新排列规划器，通过语言指导的空间概念来实现长指令以及在训练时从未见过的空间概念组合。本文的模型在指令导向操作基准测试以及组合指令基准测试中表现良好，优于基于语言表达的最先进方法，并且可以成功地解决之前从未见过的复杂指令和场景。

    

    本文致力于开发一个场景重排框架，可以解释长指令以及在训练时从未见过的空间概念组合。我们提出使用相对对象排列的能量函数来表示语言指导的空间概念。语言解析器将指令映射到相应的能量函数，而开放式视觉语言模型将它们的参数基于场景中的相关对象进行修正。通过梯度下降求解能量函数的总和，并利用基于本地计算机视觉的策略将对象重新定位到推断的目标位置，即可生成目标场景配置。我们在已建立的指令导向操作基准测试以及我们提出的组合指令基准测试中测试了模型，结果表明，我们的模型的绩效优于基于语言表达的最先进方法，并且可以成功地解决之前从未见过的复杂指令和场景。

    Language is compositional; an instruction can express multiple relation constraints to hold among objects in a scene that a robot is tasked to rearrange. Our focus in this work is an instructable scene rearranging framework that generalizes to longer instructions and to spatial concept compositions never seen at training time. We propose to represent language-instructed spatial concepts with energy functions over relative object arrangements. A language parser maps instructions to corresponding energy functions and an open-vocabulary visual-language model grounds their arguments to relevant objects in the scene. We generate goal scene configurations by gradient descent on the sum of energy functions, one per language predicate in the instruction. Local vision-based policies then relocate objects to the inferred goal locations. We test our model on established instruction-guided manipulation benchmarks, as well as benchmarks of compositional instructions we introduce. We show our model 
    
[^137]: 无需反向传播的深度物理神经网络训练

    Backpropagation-free Training of Deep Physical Neural Networks. (arXiv:2304.11042v1 [cs.LG])

    [http://arxiv.org/abs/2304.11042](http://arxiv.org/abs/2304.11042)

    该论文提出了一种新方法来训练深度学习模型，不需要使用反向传播算法。该方法可以有效地应用于基于物理系统的深度学习。

    

    近年来，深度学习在诸如视觉和自然语言处理等各个领域取得了杰出的成功。这一成功很大程度上归功于深度学习模型的大规模，预计会不断增加。这种深度学习模型的增长伴随着与其可扩展性和训练、推理阶段中的能耗等问题相关的问题。虽然已经提出了一些基于非传统物理系统的工作来解决推理阶段的能效问题，但深度学习模型的有效训练仍未得到解决。迄今为止，数字深度学习模型的训练主要依赖于反向传播，但这种方法不适用于物理实现，因为它需要完全了解所谓前向传递的计算。在这里，我们通过提出一种简单的深度神经网络结构来解决这个问题。

    Recent years have witnessed the outstanding success of deep learning in various fields such as vision and natural language processing. This success is largely indebted to the massive size of deep learning models that is expected to increase unceasingly. This growth of the deep learning models is accompanied by issues related to their considerable energy consumption, both during the training and inference phases, as well as their scalability. Although a number of work based on unconventional physical systems have been proposed which addresses the issue of energy efficiency in the inference phase, efficient training of deep learning models has remained unaddressed. So far, training of digital deep learning models mainly relies on backpropagation, which is not suitable for physical implementation as it requires perfect knowledge of the computation performed in the so-called forward pass of the neural network. Here, we tackle this issue by proposing a simple deep neural network architectur
    
[^138]: 学习随机过程的有条件生成模型

    Conditional Generative Models for Learning Stochastic Processes. (arXiv:2304.10382v1 [quant-ph])

    [http://arxiv.org/abs/2304.10382](http://arxiv.org/abs/2304.10382)

    提出了一种称为 C-qGAN 的框架，利用量子电路结构实现了有效的状态准备过程，可以利用该方法加速蒙特卡罗分析等算法，并将其应用于亚式期权衍生品定价的任务中。

    

    提出了一种学习多模态分布的框架，称为条件量子生成对抗网络（C-qGAN）。神经网络结构严格采用量子电路，因此被证明能够比当前的方法更有效地表示状态准备过程。这种方法有潜力加速蒙特卡罗分析等算法。特别地，在展示了网络在学习任务中的有效性后，将该技术应用于定价亚式期权衍生品，为未来研究其他路径相关期权打下基础。

    A framework to learn a multi-modal distribution is proposed, denoted as the Conditional Quantum Generative Adversarial Network (C-qGAN). The neural network structure is strictly within a quantum circuit and, as a consequence, is shown to represents a more efficient state preparation procedure than current methods. This methodology has the potential to speed-up algorithms, such as Monte Carlo analysis. In particular, after demonstrating the effectiveness of the network in the learning task, the technique is applied to price Asian option derivatives, providing the foundation for further research on other path-dependent options.
    
[^139]: 使用Co-ML协同机器学习模型构建家庭的合作模型构建

    Collaborative Machine Learning Model Building with Families Using Co-ML. (arXiv:2304.05444v1 [cs.HC])

    [http://arxiv.org/abs/2304.05444](http://arxiv.org/abs/2304.05444)

    Co-ML是一个基于平板电脑的应用程序，用于协同构建ML图像分类器，可以帮助学习者在合作中发掘新的想法和方法，解决数据表现和多样性等关键问题。

    

    现有的针对新手友好的机器学习（ML）建模工具，侧重于单一用户体验，一个单一用户仅收集自己的数据来构建模型。然而，单独建模经历限制了学习者共同工作时会遇到的交替想法和方法的宝贵机会。因此，当不同的观点体现在群体构建的数据集中时，往往排除了ML围绕数据表现和多样性的关键问题。为解决这个问题，我们创建了Co-ML——一个面向学习者的基于平板电脑的应用程序，通过端对端的迭代模型构建流程，协同构建ML图像分类器。在本文中，我们通过介绍一个家庭（由两个11和14岁的孩子与父母一起工作）在家中使用Co-ML进行引导性介绍ML活动的深入案例研究，展示了协作建模的可行性和潜在丰富性。我们分享了Co-ML系统的d。

    Existing novice-friendly machine learning (ML) modeling tools center around a solo user experience, where a single user collects only their own data to build a model. However, solo modeling experiences limit valuable opportunities for encountering alternative ideas and approaches that can arise when learners work together; consequently, it often precludes encountering critical issues in ML around data representation and diversity that can surface when different perspectives are manifested in a group-constructed data set. To address this issue, we created Co-ML -- a tablet-based app for learners to collaboratively build ML image classifiers through an end-to-end, iterative model-building process. In this paper, we illustrate the feasibility and potential richness of collaborative modeling by presenting an in-depth case study of a family (two children 11 and 14-years-old working with their parents) using Co-ML in a facilitated introductory ML activity at home. We share the Co-ML system d
    
[^140]: 奖励是否合理？在 MACHIAVELLI 基准测试中衡量奖励与道德行为之间的权衡

    Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark. (arXiv:2304.03279v1 [cs.LG])

    [http://arxiv.org/abs/2304.03279](http://arxiv.org/abs/2304.03279)

    本文介绍了 MACHIAVELLI 基准测试，用于衡量人工智能代理是否表现出马基雅维利行为，发现了最大化奖励和行为的道德性之间存在权衡，并探索了基于语言模型的方法来减轻这种权衡。

    

    传统上，人工智能代理被训练成最大化奖励，这可能会激励追求权力和欺骗行为，类似于语言模型中的下一个标记预测可能会激励有害行为。那么代理是否自然而然地学会了马基雅维利行为？我们如何在 GPT-4 等通用模型中衡量这些行为呢？为回答这些问题，我们引入了 MACHIAVELLI 基准测试，该测试涵盖了超过一百万个多样化的情景，重点关注社会决策制定，用于衡量人工代理是否表现出马基雅维利行为。我们数学化了数十种有害行为，并使用我们的注释来评估代理倾向于追求权力，造成功能不良和违反伦理的倾向。我们观察到最大化奖励和行为的道德性之间存在一些紧张关系。为了改善这种权衡，我们研究了基于语言模型的方法，以使代理趋向于采取更少的有害行为。我们的结果显示，MACHIAVELLI 是评估人工代理马基雅维利行为水平的有用基准测试。

    Artificial agents have traditionally been trained to maximize reward, which may incentivize power-seeking and deception, analogous to how next-token prediction in language models (LMs) may incentivize toxicity. So do agents naturally learn to be Machiavellian? And how do we measure these behaviors in general-purpose models such as GPT-4? Towards answering these questions, we introduce MACHIAVELLI, a benchmark of 134 Choose-Your-Own-Adventure games containing over half a million rich, diverse scenarios that center on social decision-making. Scenario labeling is automated with LMs, which are more performant than human annotators. We mathematize dozens of harmful behaviors and use our annotations to evaluate agents' tendencies to be power-seeking, cause disutility, and commit ethical violations. We observe some tension between maximizing reward and behaving ethically. To improve this trade-off, we investigate LM-based methods to steer agents' towards less harmful behaviors. Our results sh
    
[^141]: 二维瑞利-贝纳德对流的有效控制：仅需不变的多智能体强化学习方法。

    Effective control of two-dimensional Rayleigh--B\'enard convection: invariant multi-agent reinforcement learning is all you need. (arXiv:2304.02370v1 [physics.flu-dyn])

    [http://arxiv.org/abs/2304.02370](http://arxiv.org/abs/2304.02370)

    本论文应用基于不变多智能体强化学习（MARL）的深度强化学习（DRL）方法，实现了对二维瑞利-贝纳德对流的有效控制。通过利用局部性和平移不变性，MARL所获得的控制法则不仅具有较好的性能，而且具有良好的应用前景。

    

    瑞利-贝纳德对流是几种工业和地球科学流动中的一个常见现象，从基本流体力学的角度也是一个研究充分的系统。然而，通过传统的控制理论方法控制瑞利-贝纳德对流，例如通过调节规范瑞利-贝纳德对流形态下底板加热的空间分布，仍然是一个具有挑战性的主题。在本研究中，我们应用深度强化学习（DRL）来控制瑞利-贝纳德对流。我们展示了通过利用内在于宽通道内的瑞利-贝纳德对流的局部性和平移不变性的多智能体不变性强化学习（MARL）来获取有效的瑞利-贝纳德对流控制。应用于瑞利-贝纳德对流的MARL框架允许增加控制段的数量，而不会遇到因naive DRL动作尺寸维数增加而导致的维度灾难。这得益于MARL能够重复使用在不同区域生成的知识，从而大大减少训练时间，并形成有效收敛的控制策略。我们的结果表明了所提出的MARL方法在瑞利-贝纳德对流控制中的有效性，为在工业和地球科学流动中的潜在应用铺平了道路。

    Rayleigh-B\'enard convection (RBC) is a recurrent phenomenon in several industrial and geoscience flows and a well-studied system from a fundamental fluid-mechanics viewpoint. However, controlling RBC, for example by modulating the spatial distribution of the bottom-plate heating in the canonical RBC configuration, remains a challenging topic for classical control-theory methods. In the present work, we apply deep reinforcement learning (DRL) for controlling RBC. We show that effective RBC control can be obtained by leveraging invariant multi-agent reinforcement learning (MARL), which takes advantage of the locality and translational invariance inherent to RBC flows inside wide channels. The MARL framework applied to RBC allows for an increase in the number of control segments without encountering the curse of dimensionality that would result from a naive increase in the DRL action-size dimension. This is made possible by the MARL ability for re-using the knowledge generated in differe
    
[^142]: 病理图像大规模预训练用于小规模病理基准微调

    Large-scale pretraining on pathological images for fine-tuning of small pathological benchmarks. (arXiv:2303.15693v1 [cs.CV])

    [http://arxiv.org/abs/2303.15693](http://arxiv.org/abs/2303.15693)

    本文探讨了病理图像预训练对小规模病理基准微调的影响，通过自监督学习方法，以PTCGA200为训练集进行预训练的ResNet50在微调时表现更好，优于imagenet2012预训练。MoCov2预训练的ResNet50在PCam200和segPANDA200上表现优秀，且收敛速度更快。

    

    在对小型目标数据集进行微调之前，在大型图像数据集上预训练深度学习模型是标准步骤。大型数据集通常是通用图像（例如imagenet2012），而小型数据集可以是具有与大型数据集不同分布的专业数据集。然而，当大型数据集是专业化的且具有与小型数据集相似的分布时，这种“大到小”的策略并未得到很好的验证。我们新编译了三个苏木精和伊红染色图像数据集，一个大型数据集（PTCGA200）和两个放大调整的小型数据集（PCam200和segPANDA200）。通过监督学习和自监督学习方法训练了主要的深度学习模型，并在小型数据集上进行了肿瘤分类和组织分割基准的微调。在PTCGA200上以MoCov2，SimCLR和BYOL预训练的ResNet50在微调时比imagenet2012预训练更好（精度分别为83.94％，86.41％，84.91％和82.72％）。此外，以MoCov2预训练的ResNet50在收敛速度更快的情况下实现了PCam200和segPANDA200的最优性能，而比imagenet2012预训练的ResNet50更快。

    Pretraining a deep learning model on large image datasets is a standard step before fine-tuning the model on small targeted datasets. The large dataset is usually general images (e.g. imagenet2012) while the small dataset can be specialized datasets that have different distributions from the large dataset. However, this 'large-to-small' strategy is not well-validated when the large dataset is specialized and has a similar distribution to small datasets. We newly compiled three hematoxylin and eosin-stained image datasets, one large (PTCGA200) and two magnification-adjusted small datasets (PCam200 and segPANDA200). Major deep learning models were trained with supervised and self-supervised learning methods and fine-tuned on the small datasets for tumor classification and tissue segmentation benchmarks. ResNet50 pretrained with MoCov2, SimCLR, and BYOL on PTCGA200 was better than imagenet2012 pretraining when fine-tuned on PTCGA200 (accuracy of 83.94%, 86.41%, 84.91%, and 82.72%, respect
    
[^143]: 任意深度的一维神经网络的不动点

    Fixed points of arbitrarily deep 1-dimensional neural networks. (arXiv:2303.12814v1 [stat.ML])

    [http://arxiv.org/abs/2303.12814](http://arxiv.org/abs/2303.12814)

    本研究发现，具有对数S型激活函数的任意深度的一维神经网络最多只有三个不动点，为深度神经网络的应用和理论之间构建了一个必要的桥梁。

    

    本文介绍了一个在$\mathbb{R}$上具有合成性且包含对数S型函数的新函数类。我们使用这个类来证明具有对数S型激活函数的任意深度的一维神经网络最多只有三个不动点。虽然这样的神经网络远离实际应用，但我们能够完全理解它们的不动点，并为深度神经网络的应用和理论之间构建了一个必要的桥梁。

    In this paper, we introduce a new class of functions on $\mathbb{R}$ that is closed under composition, and contains the logistic sigmoid function. We use this class to show that any 1-dimensional neural network of arbitrary depth with logistic sigmoid activation functions has at most three fixed points. While such neural networks are far from real world applications, we are able to completely understand their fixed points, providing a foundation to the much needed connection between application and theory of deep neural networks.
    
[^144]: eP-ALM:语言模型的高效感知增强

    eP-ALM: Efficient Perceptual Augmentation of Language Models. (arXiv:2303.11403v1 [cs.CV])

    [http://arxiv.org/abs/2303.11403](http://arxiv.org/abs/2303.11403)

    本论文提出了一种用对比学习提高语言模型的感知能力的高效方法eP-ALM，可以实现视觉感知信息和文本信息的融合，同时还能在多模态基准测试上实现最先进的结果。

    

    大型语言模型(LLM)迄今为止给世界留下了深刻印象，具有大规模模型所具有的非同寻常的能力。在视觉方面，变压器模型（即ViT）也在追随同一趋势，取得了最具挑战性的基准测试的最佳表现。随着这种单模型的丰富多样，自然会引发一个问题：我们是否需要跟随这个趋势来处理多模态任务？在这项工作中，我们提出将努力集中于现有模型的高效适应，并提出用感知来增强语言模型。现有的适应预训练模型用于视觉语言任务的方法仍然依赖于几个关键组件，从而影响了它们的效率。特别地，他们仍然训练大量的参数，依赖大规模的多模态预训练，使用在巨大的图像-文本数据集上训练的编码器（例如CLIP），并添加了显著的推理开销。此外，这些方法中的大多数关注Zero-Shot和In Context Learning，观察到两种范式之间的巨大差异。在本文中，我们介绍了eP-ALM，一种将视觉感知信息与语言模型相结合的高效方法。我们提出了一种方法，利用对比学习来实现视觉感知和文本信息的融合，具有极小的计算成本。我们的方法不需要任何新的预训练，仍然在多模态基准测试上实现了最先进的结果。

    Large Language Models (LLMs) have so far impressed the world, with unprecedented capabilities that emerge in models at large scales. On the vision side, transformer models (i.e., ViT) are following the same trend, achieving the best performance on challenging benchmarks. With the abundance of such unimodal models, a natural question arises; do we need also to follow this trend to tackle multimodal tasks? In this work, we propose to rather direct effort to efficient adaptations of existing models, and propose to augment Language Models with perception. Existing approaches for adapting pretrained models for vision-language tasks still rely on several key components that hinder their efficiency. In particular, they still train a large number of parameters, rely on large multimodal pretraining, use encoders (e.g., CLIP) trained on huge image-text datasets, and add significant inference overhead. In addition, most of these approaches have focused on Zero-Shot and In Context Learning, with l
    
[^145]: 图像分类器泄露其类别的敏感属性

    Image Classifiers Leak Sensitive Attributes About Their Classes. (arXiv:2303.09289v1 [cs.LG])

    [http://arxiv.org/abs/2303.09289](http://arxiv.org/abs/2303.09289)

    该论文探讨了图像分类器存在的隐私泄露问题，提出的Class Attribute Inference Attack（Caia）能够从黑盒设置中准确地推断出敏感属性，包括个人的发色、性别和种族，这表明在鲁棒性和隐私之间存在权衡。

    

    基于神经网络的图像分类器是计算机视觉任务的有力工具，但它们无意中透露了有关其类别的敏感属性信息，引起了对它们的隐私的关注。为了研究这种隐私泄漏，我们引入了第一个Class Attribute Inference Attack（Caia），利用最近在文本到图像合成方面的进展，在黑盒设置中推断出单个类别的敏感属性，同时与相关的白盒攻击相竞争。在人脸识别领域进行的广泛实验表明，Caia能够准确地推断出未公开的敏感属性，例如个人的发色、性别和种族外貌，这些属性不属于训练标签。有趣的是，我们证明了对抗性鲁棒模型比标准模型更容易泄露隐私，表明在鲁棒性和隐私之间存在权衡。

    Neural network-based image classifiers are powerful tools for computer vision tasks, but they inadvertently reveal sensitive attribute information about their classes, raising concerns about their privacy. To investigate this privacy leakage, we introduce the first Class Attribute Inference Attack (Caia), which leverages recent advances in text-to-image synthesis to infer sensitive attributes of individual classes in a black-box setting, while remaining competitive with related white-box attacks. Our extensive experiments in the face recognition domain show that Caia can accurately infer undisclosed sensitive attributes, such as an individual's hair color, gender and racial appearance, which are not part of the training labels. Interestingly, we demonstrate that adversarial robust models are even more vulnerable to such privacy leakage than standard models, indicating that a trade-off between robustness and privacy exists.
    
[^146]: SHAP-IQ: 任意阶Shapley interaction的统一逼近方法

    SHAP-IQ: Unified Approximation of any-order Shapley Interactions. (arXiv:2303.01179v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.01179](http://arxiv.org/abs/2303.01179)

    提出了一种名为SHAP-IQ的新方法，用于计算任意阶Shapley互动，并提供了逼近质量的理论保证和方差估计。该方法在计算成本和逼近质量方面优于现有方法。

    

    在可解释的人工智能（XAI）研究中，Shapley值（SV）通常被应用于确定任何黑盒模型的特征重要性得分。 Shapley interaction indices将SV扩展为定义任意阶特征相互作用得分。定义独特的Shapley interaction index是一个开放性研究问题，迄今为止已经提出了三个定义，其不同之处在于所选择的公理。此外，每个定义都需要特定的逼近技术。在这里，我们提出了基于采样的有效逼近方法SHAPley Interaction Quantification（SHAP-IQ），以计算任意基数交互指数（CII）的Shapley互动。即满足线性、对称和虚拟公理的交互指数。SHAP-IQ基于一种新颖的表示方法，与现有方法相比，我们为其逼近质量提供了理论保证，以及点估计的方差估计。对于SV的特殊情况，我们的逼近方法与精确计算一致。进行了数值实验，以证明我们的方法在几个合成和实际数据集上的有效性，并显示SHAP-IQ在计算成本和逼近质量方面优于现有方法。

    Predominately in explainable artificial intelligence (XAI) research, the Shapley value (SV) is applied to determine feature importance scores for any black box model. Shapley interaction indices extend the SV to define any-order feature interaction scores. Defining a unique Shapley interaction index is an open research question and, so far, three definitions have been proposed, which differ by their choice of axioms. Moreover, each definition requires a specific approximation technique. Here, we propose SHAPley Interaction Quantification (SHAP-IQ), an efficient sampling-based approximator to compute Shapley interactions for arbitrary cardinal interaction indices (CII), i.e. interaction indices that satisfy the linearity, symmetry and dummy axiom. SHAP-IQ is based on a novel representation and, in contrast to existing methods, we provide theoretical guarantees for its approximation quality, as well as estimates for the variance of the point estimates. For the special case of SV, our app
    
[^147]: 深度强化学习中的休眠神经元现象

    The Dormant Neuron Phenomenon in Deep Reinforcement Learning. (arXiv:2302.12902v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.12902](http://arxiv.org/abs/2302.12902)

    在深度强化学习中存在着休眠神经元现象，即未激活神经元数量不断增加会影响网络表达能力，作者提出了一种简单而有效的方法(ReDo)回收休眠神经元，从而在训练中提高了网络的表达能力和性能。

    

    本文中，我们发现了深度强化学习中的休眠神经元现象，即代理网络中不断增加的未激活神经元数量会影响网络表达能力。我们在多种算法和环境中证明了这种现象的存在，并强调了它对学习的影响。为了解决这个问题，我们提出了一种简单而有效的方法(ReDo)，在训练期间回收休眠神经元。我们的实验证明，ReDo通过减少休眠神经元的数量，保持了网络的表达能力，并获得了更好的性能。

    In this work we identify the dormant neuron phenomenon in deep reinforcement learning, where an agent's network suffers from an increasing number of inactive neurons, thereby affecting network expressivity. We demonstrate the presence of this phenomenon across a variety of algorithms and environments, and highlight its effect on learning. To address this issue, we propose a simple and effective method (ReDo) that Recycles Dormant neurons throughout training. Our experiments demonstrate that ReDo maintains the expressive power of networks by reducing the number of dormant neurons and results in improved performance.
    
[^148]: 面向现实世界的治疗优化应用的深度离线强化学习

    Deep Offline Reinforcement Learning for Real-world Treatment Optimization Applications. (arXiv:2302.07549v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.07549](http://arxiv.org/abs/2302.07549)

    本研究介绍了一种面向现实世界的治疗优化方法，通过使用保守Q学习法(CQL)和转移取样将离线强化学习应用于回顾性医疗记录数据集。

    

    越来越多的人关注数据驱动的方法，以推荐治疗策略为慢性病管理和危重护理应用。强化学习方法非常适合这个顺序决策问题，但必须仅在回顾性医疗记录数据集上进行训练和评估，因为直接的在线探索是不安全和不可行的。尽管存在这个要求，但大多数治疗优化研究使用离线RL方法（例如，双深度Q网络（DDQN）或其变体），这些方法已知在纯离线环境中表现不佳。近期离线RL的进展，例如保守Q 学习（CQL），提供了一种合适的替代方案。但在适应这些方法到临床应用中仍然存在挑战，因为回顾性数据集主要是次优例子，需要满足严格的安全约束条件。本文介绍了一种实用且理论上有基础的转移取样方法，该方法使用CQL方法在现实世界疾病管理数据集上进行训练和评估。

    There is increasing interest in data-driven approaches for recommending optimal treatment strategies in many chronic disease management and critical care applications. Reinforcement learning methods are well-suited to this sequential decision-making problem, but must be trained and evaluated exclusively on retrospective medical record datasets as direct online exploration is unsafe and infeasible. Despite this requirement, the vast majority of treatment optimization studies use off-policy RL methods (e.g., Double Deep Q Networks (DDQN) or its variants) that are known to perform poorly in purely offline settings. Recent advances in offline RL, such as Conservative Q-Learning (CQL), offer a suitable alternative. But there remain challenges in adapting these approaches to real-world applications where suboptimal examples dominate the retrospective dataset and strict safety constraints need to be satisfied. In this work, we introduce a practical and theoretically grounded transition sampli
    
[^149]: KL散度中离散分布估计的集中界限

    Concentration Bounds for Discrete Distribution Estimation in KL Divergence. (arXiv:2302.06869v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.06869](http://arxiv.org/abs/2302.06869)

    本文提供了拉普拉斯估计器的集中界限，讨论了在KL散度中离散分布估计的问题，并实现了更优的结果。

    

    我们研究了在KL散度中离散分布估计的问题，并为拉普拉斯估计器提供了集中界限。当$n \geq k$时，我们展示了从平均值偏差的缩放为$\sqrt{k} / n$，这比先前最好的结果$k/n$有所改进。我们还建立了一个匹配的下界，表明我们的界限在多项式对数因子上是紧密的。

    We study the problem of discrete distribution estimation in KL divergence and provide concentration bounds for the Laplace estimator. We show that the deviation from mean scales as $\sqrt{k}/n$ when $n \ge k$, improving upon the best prior result of $k/n$. We also establish a matching lower bound that shows that our bounds are tight up to polylogarithmic factors.
    
[^150]: Density-Softmax: 在分布变化下提高不确定性估计的快速确定性方法

    Density-Softmax: Scalable and Calibrated Uncertainty Estimation under Distribution Shifts. (arXiv:2302.06495v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.06495](http://arxiv.org/abs/2302.06495)

    本文提出了一种称为Density-Softmax的快速确定性方法，通过将密度函数与softmax结合来提高分布变化下的校准不确定性估计，具有较高的效率和可行性

    

    常见确定性深度学习模型在分布变化下存在较大的过度自信问题，概率方法虽然能缓解此问题但计算效率不佳。本文提出Density-Softmax方法，通过将密度函数与softmax结合，以快速且轻量级的方式提高校准不确定性估计。该方法利用潜在表示的似然值，在测试时在远离训练样本时增加不确定性。在理论证明和实验上，Density-Softmax证明了在使用神经网络的情况下可以实现高质量的不确定性估计，从而减少了标准softmax的过度自信。

    Prevalent deterministic deep-learning models suffer from significant over-confidence under distribution shifts. Probabilistic approaches can reduce this problem but struggle with computational efficiency. In this paper, we propose Density-Softmax, a fast and lightweight deterministic method to improve calibrated uncertainty estimation via a combination of density function with the softmax layer. By using the latent representation's likelihood value, our approach produces more uncertain predictions when test samples are distant from the training samples. Theoretically, we show that Density-Softmax can produce high-quality uncertainty estimation with neural networks, as it is the solution of minimax uncertainty risk and is distance-aware, thus reducing the over-confidence of the standard softmax. Empirically, our method enjoys similar computational efficiency as a single forward pass deterministic with standard softmax on the shifted toy, vision, and language datasets across modern deep-
    
[^151]: 使用谱物理信息神经网络求解流形上的偏微分方程数值方法

    Numerical Methods For PDEs Over Manifolds Using Spectral Physics Informed Neural Networks. (arXiv:2302.05322v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.05322](http://arxiv.org/abs/2302.05322)

    本文提出了一种新方法，使用基于谱的物理信息神经网络求解流形上的偏微分方程，并在球面和环面上得到了成功应用。对比标准架构，本文的方法表现更好。

    

    我们提出了一种使用谱方法对齐架构的物理信息神经网络方法，用于求解流形上的偏微分方程。这些网络被训练为将初始条件、时间戳和流形上的点作为输入，并输出给定时间和点处的解的值。我们证明了基于谱方法的神经网络方法在区间上的热方程、球面和环面非线性方程的解决中的有效性。同时，我们还展示了基于谱的神经网络架构优于标准物理信息架构的性能优势。我们广泛的实验结果包括对广泛的测试数据集进行的泛化研究。

    We introduce an approach for solving PDEs over manifolds using physics informed neural networks whose architecture aligns with spectral methods. The networks are trained to take in as input samples of an initial condition, a time stamp and point(s) on the manifold and then output the solution's value at the given time and point(s). We provide proofs of our method for the heat equation on the interval and examples of unique network architectures that are adapted to nonlinear equations on the sphere and the torus. We also show that our spectral-inspired neural network architectures outperform the standard physics informed architectures. Our extensive experimental results include generalization studies where the testing dataset of initial conditions is randomly sampled from a significantly larger space than the training set.
    
[^152]: 如何信任您的扩散模型：一种凸优化方法应对符合风险控制的因式分解模型

    How to Trust Your Diffusion Model: A Convex Optimization Approach to Conformal Risk Control. (arXiv:2302.03791v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.03791](http://arxiv.org/abs/2302.03791)

    本文提出了一种风险控制预测集（RCPS）程序的推广，称为$K$-RCPS，它允许为任何扩散模型提供逐个校准的未来样本间隔，并控制相对于基准真实图像的某种风险概念，同时保持最小平均区间长度。

    

    基于分数的生成建模方法，简称扩散模型，在多个重要领域和任务中继续增长。尽管它们提供了来自经验分布的高质量和多样化样本，但在其负责任地用于关键场景方面的可靠性和可信度仍存在重要问题。收敛预测是一种现代工具，用于为任何黑盒子预测器构建有限样本、分布自由的不确定性保证。在这项工作中，我们专注于图像到图像回归任务，并提出了一种风险控制预测集（RCPS）程序的推广，我们称之为$K$-RCPS，它允许$(i)$为任何扩散模型提供逐个校准的未来样本间隔，并$(ii)$控制相对于基准真实图像的某种风险概念，同时保持最小平均区间长度。与现有的收敛风险控制过程不同，我们的过程依靠一种新型的凸优化公式，使其具有计算效率和易于实现的特点。我们在几个图像到图像回归任务上使用得分为基础的生成建模方法来说明我们的程序的有效性，展示了高度校准和良好控制的预测间隔。

    Score-based generative modeling, informally referred to as diffusion models, continue to grow in popularity across several important domains and tasks. While they provide high-quality and diverse samples from empirical distributions, important questions remain on the reliability and trustworthiness of these sampling procedures for their responsible use in critical scenarios. Conformal prediction is a modern tool to construct finite-sample, distribution-free uncertainty guarantees for any black-box predictor. In this work, we focus on image-to-image regression tasks and we present a generalization of the Risk-Controlling Prediction Sets (RCPS) procedure, that we term $K$-RCPS, which allows to $(i)$ provide entrywise calibrated intervals for future samples of any diffusion model, and $(ii)$ control a certain notion of risk with respect to a ground truth image with minimal mean interval length. Differently from existing conformal risk control procedures, ours relies on a novel convex opti
    
[^153]: FewSOME：基于孪生网络的一类少样本异常检测

    FewSOME: One-Class Few Shot Anomaly Detection with Siamese Networks. (arXiv:2301.06957v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.06957](http://arxiv.org/abs/2301.06957)

    本文提出了一种基于孪生网络的深度学习一类少样本异常检测算法FewSOME，它可以在只有很少量的正常类别样本和没有异常类别样本的情况下准确地检测出异常，具有较低的复杂度和短的训练时间，并已经在多个基准数据集上表现出最先进水平的性能。

    

    最近的异常检测技术在推动该领域的同时也逐渐变得复杂，需要大量的训练数据，这导致算法计算量大，不适合在只有少量正常样本可用于训练的情况下使用。本文提出了一种基于孪生网络的深度一类异常检测算法FewSOME，它可以在只有很少量的正常类别样本和没有异常类别样本的情况下准确地检测出异常。由于少量数据要求和较短的训练时间，FewSOME 的复杂度较低。通过消融实验，我们证明了我们提出的 Stop Loss 损失函数如何提高 FewSOME 的鲁棒性。在 MNIST、CIFAR-10 和 GTSRB等基准数据集上的实验结果表明FewSOME的性能已达到最先进水平。

    Recent Anomaly Detection techniques have progressed the field considerably but at the cost of increasingly complex training pipelines. Such techniques require large amounts of training data, resulting in computationally expensive algorithms that are unsuitable for settings where only a small amount of normal samples are available for training. We propose 'Few Shot anOMaly detection' (FewSOME), a deep One-Class Anomaly Detection algorithm with the ability to accurately detect anomalies having trained on 'few' examples of the normal class and no examples of the anomalous class. We describe FewSOME to be of low complexity given its low data requirement and short training time. FewSOME is aided by pretrained weights with an architecture based on Siamese Networks. By means of an ablation study, we demonstrate how our proposed loss, 'Stop Loss', improves the robustness of FewSOME. Our experiments demonstrate that FewSOME performs at state-of-the-art level on benchmark datasets MNIST, CIFAR-1
    
[^154]: 基于反射红外光波信号的手势识别技术

    Hand Gesture Recognition through Reflected Infrared Light Wave Signals. (arXiv:2301.05955v2 [eess.SP] UPDATED)

    [http://arxiv.org/abs/2301.05955](http://arxiv.org/abs/2301.05955)

    该研究提出了一种低成本的基于反射红外光波信号的手势识别技术，通过收集反射光的强度变化，可以在20-35cm范围内识别不同手势，平均准确率为96％。

    

    本研究提出了一种仅使用来自被试反射的非相干光波信号进行无线（非接触）手势识别的方法。与现有的雷达、光影、声音和基于相机的传感系统相比，该技术使用低成本的普及光源（例如红外LED）向执行手势的被试发送光，并且反射光由光传感器（例如光电探测器）收集。该光波传感系统可以识别不同手势，在20-35cm范围内根据接收到的光强变化。手势识别结果表明平均准确率达到96％。所开发的系统可以作为低成本和非接触手势识别技术，在众多人机交互（HCI）应用中得到广泛应用。

    In this study, we present a wireless (non-contact) gesture recognition method using only incoherent light wave signals reflected from a human subject. In comparison to existing radar, light shadow, sound and camera-based sensing systems, this technology uses a low-cost ubiquitous light source (e.g., infrared LED) to send light towards the subject's hand performing gestures and the reflected light is collected by a light sensor (e.g., photodetector). This light wave sensing system recognizes different gestures from the variations of the received light intensity within a 20-35cm range. The hand gesture recognition results demonstrate up to 96% accuracy on average. The developed system can be utilized in numerous Human-computer Interaction (HCI) applications as a low-cost and non-contact gesture recognition technology.
    
[^155]: 带有离群点的社区检测人工基准（ABCD+o）

    Artificial Benchmark for Community Detection with Outliers (ABCD+o). (arXiv:2301.05749v2 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2301.05749](http://arxiv.org/abs/2301.05749)

    提出了一种带有离群点的人工基准社区检测图模型（ABCD+o），可以用于探索离群点的特征。

    

    人工基准社区检测图（ABCD）是一个具有社区结构和度数、社区大小均服从幂律分布的随机图模型。该模型生成的图与著名的LFR模型具有相似的属性，它的主要参数ξ可以调节以模拟LFR模型中的混合参数μ。本文将ABCD模型扩展到包括潜在的离群点。我们对新的ABCD+o模型以及一个真实网络进行一些探索性实验，以表明离群点具有某些所需的明显特征。

    The Artificial Benchmark for Community Detection graph (ABCD) is a random graph model with community structure and power-law distribution for both degrees and community sizes. The model generates graphs with similar properties as the well-known LFR one, and its main parameter $\xi$ can be tuned to mimic its counterpart in the LFR model, the mixing parameter $\mu$. In this paper, we extend the ABCD model to include potential outliers. We perform some exploratory experiments on both the new ABCD+o model as well as a real-world network to show that outliers possess some desired, distinguishable properties.
    
[^156]: 同质性在图卷积网络的双下降泛化中的调制作用

    Homophily modulates double descent generalization in graph convolution networks. (arXiv:2212.13069v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.13069](http://arxiv.org/abs/2212.13069)

    本文通过使用统计物理和随机矩阵理论的分析工具，精确地表征了简单图卷积网络在背景随机块模型上的泛化，提出了同质性在图卷积网络的泛化中的调制作用。

    

    图神经网络是用于关系数据集（如代谢、交通和社交网络）的最成功的机器学习模型之一。然而，它们对数据中编码的各种交互的强大泛化的决定因素并不为人所知。来自统计学习理论的方法无法解释出现的现象，如双下降或风险取决于交互性质的问题。我们使用统计物理和随机矩阵理论的分析工具来精确地表征简单图卷积网络在背景随机块模型上的泛化。导出的曲线现象学上十分丰富：它们解释了同质性和异质性学习之间的区别，并预测了最近作品所质疑的GNN中双下降现象的存在。我们展示了风险如何取决于图中的噪声、特征中的噪声和用于训练的节点比例之间的相互作用。我们的分析为理解同质性如何调制图神经网络的泛化提供了第一步。

    Graph neural networks are among the most successful machine learning models for relational datasets like metabolic, transportation, and social networks. Yet the determinants of their strong generalization for diverse interactions encoded in the data are not well understood. Methods from statistical learning theory do not explain emergent phenomena such as double descent or the dependence of risk on the nature of interactions. We use analytical tools from statistical physics and random matrix theory to precisely characterize generalization in simple graph convolution networks on the contextual stochastic block model. The derived curves are phenomenologically rich: they explain the distinction between learning on homophilic and heterophilic and they predict double descent whose existence in GNNs has been questioned by recent work. We show how risk depends on the interplay between the noise in the graph, noise in the features, and the proportion of nodes used for training. Our analysis pr
    
[^157]: 大型语言模型是推理教师

    Large Language Models Are Reasoning Teachers. (arXiv:2212.10071v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10071](http://arxiv.org/abs/2212.10071)

    本文提出了Fine-tune-CoT，一种使用大型模型作为推理教师让较小模型也能进行复杂推理的方法，可以远远优于基于提示的基线方法，在多个任务上进行了评估。此外，该方法还利用教师模型的能力为每个原始样本生成多个不同的原因解释。

    

    最近的研究表明，思维链条提示可以引导语言模型逐步解决复杂的推理任务。然而，基于提示的思维链条方法依赖于像GPT-3 175B这样非常大的模型，这在规模上是不可行的。本文提出了Fine-tune-CoT方法，使用这些大型模型作为推理教师，以让较小的模型也能进行复杂推理，从而使模型尺寸要求减少数个数量级。我们在公共模型和复杂任务上评估了该方法，发现Fine-tune-CoT可以在小型模型中实现实质性的推理能力，远远优于基于提示的基线方法，甚至在许多任务中也优于教师模型。此外，我们扩展了该方法，利用教师模型的能力为每个原始样本生成多个不同的原因解释，从而增强了微调数据。

    Recent works have shown that chain-of-thought (CoT) prompting can elicit language models to solve complex reasoning tasks, step-by-step. However, prompt-based CoT methods are dependent on very large models such as GPT-3 175B which are prohibitive to deploy at scale. In this paper, we use these large models as reasoning teachers to enable complex reasoning in smaller models and reduce model size requirements by several orders of magnitude. We propose Fine-tune-CoT, a method that generates reasoning samples from very large teacher models to fine-tune smaller models. We evaluate our method on a wide range of public models and complex tasks. We find that Fine-tune-CoT enables substantial reasoning capability in small models, far outperforming prompt-based baselines and even the teacher model in many tasks. Additionally, we extend our method by leveraging the teacher model's ability to generate multiple distinct rationales for each original sample. Enriching the fine-tuning data with such d
    
[^158]: 利用物理知识的神经网络从全场位移数据中对材料模型进行校准

    Physics-Informed Neural Networks for Material Model Calibration from Full-Field Displacement Data. (arXiv:2212.07723v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.07723](http://arxiv.org/abs/2212.07723)

    本文利用物理知识的神经网络从全场位移数据中对材料模型进行校准，并展示在实际应用中优化问题的条件和重构起到了关键作用。

    

    材料参数的鉴定在实际应用中有着广泛的应用。其中之一是监测和评估基础设施建筑物的实际状况，因为材料参数直接反映结构物对外部影响的抵抗力。最近出现的基于物理知识的神经网络（PINN）是解决反问题的合适方法。这种方法的优点是简单地包含观测数据。与基于网格的方法（如最小二乘有限元法（LS-FEM）方法）不同，不需要计算网格和数据的插值。在当前工作中，我们提出了一种适用于线性弹性力学模型的全场位移和全局力数据校准的PINNs。我们展示了优化问题的条件和重构在实际应用中起着关键作用。

    The identification of material parameters occurring in constitutive models has a wide range of applications in practice. One of these applications is the monitoring and assessment of the actual condition of infrastructure buildings, as the material parameters directly reflect the resistance of the structures to external impacts. Physics-informed neural networks (PINNs) have recently emerged as a suitable method for solving inverse problems. The advantages of this method are a straightforward inclusion of observation data. Unlike grid-based methods, such as the least square finite element method (LS-FEM) approach, no computational grid and no interpolation of the data is required. In the current work, we propose PINNs for the calibration of constitutive models from full-field displacement and global force data in a realistic regime on the example of linear elasticity. We show that conditioning and reformulation of the optimization problem play a crucial role in real-world applications. 
    
[^159]: 在混淆下的离线策略评估和优化。

    Offline Policy Evaluation and Optimization under Confounding. (arXiv:2211.16583v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.16583](http://arxiv.org/abs/2211.16583)

    该论文致力于解决离线强化学习中混淆变量导致策略评估和优化存在挑战的问题，包括无法获得一致价值估计和样本复杂度的保证，作者提出了具有保证的下限算法和局部收敛的改进算法。

    

    在离线强化学习中，评估和优化策略在存在未观察到的混淆变量时是一个备受关注的问题。使用传统的离线强化学习方法来处理混淆问题不仅可能导致糟糕的决策和策略，而且在关键应用领域如医疗和教育中可能会产生灾难性的影响。我们勾勒了混淆的 MDP 离线策略评估的面貌，并根据混淆对数据收集策略的时间演变和影响来区分混淆的假设。在一些情况下，我们确定了一些无法获得一致价值估计的情况，并提供和讨论了计算具有保证的下限的算法。当一致的估计可行时，我们提供了样本复杂度的保证。我们还提出了新的离线策略改进算法，并证明了局部收敛的保证。最后，我们在格子世界和模拟医疗场景中对算法进行了实验评估。

    Evaluating and optimizing policies in the presence of unobserved confounders is a problem of growing interest in offline reinforcement learning. Using conventional methods for offline RL in the presence of confounding can not only lead to poor decisions and poor policies, but can also have disastrous effects in critical applications such as healthcare and education. We map out the landscape of offline policy evaluation for confounded MDPs, distinguishing assumptions on confounding based on their time-evolution and effect on the data-collection policies. We determine when consistent value estimates are not achievable, providing and discussing algorithms to estimate lower bounds with guarantees in those cases. When consistent estimates are achievable, we provide sample complexity guarantees. We also present new algorithms for offline policy improvement and prove local convergence guarantees. Finally, we experimentally evaluate our algorithms on gridworld and a simulated healthcare settin
    
[^160]: 无分布假设的节点分类预测集

    Distribution Free Prediction Sets for Node Classification. (arXiv:2211.14555v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.14555](http://arxiv.org/abs/2211.14555)

    本文利用近期在设定预测下的进展，构建了预测集以适应归纳学习场景下的节点分类，证明了提供了比简单的符合预测应用更加紧致和良好校准的预测集。

    

    图神经网络通常可以在许多重要的真实数据集上达到高精度分类的效果，但其无法提供严格的预测不确定性定义。由于图结构引起的数据点依赖性，量化GNN模型的置信度很困难。本文利用近期在设定预测下的进展，构建了预测集以适应归纳学习场景下的节点分类。我们对现有的换位分类方法进行了改进，通过适当加权符合分数来反映网络结构。通过在常用标准基准数据集上使用流行的GNN模型进行实验，我们证明了我们的方法提供了比简单的符合预测应用更加紧致和良好校准的预测集。

    Graph Neural Networks (GNNs) are able to achieve high classification accuracy on many important real world datasets, but provide no rigorous notion of predictive uncertainty. Quantifying the confidence of GNN models is difficult due to the dependence between datapoints induced by the graph structure.  We leverage recent advances in conformal prediction to construct prediction sets for node classification in inductive learning scenarios. We do this by taking an existing approach for conformal classification that relies on \textit{exchangeable} data and modifying it by appropriately weighting the conformal scores to reflect the network structure. We show through experiments on standard benchmark datasets using popular GNN models that our approach provides tighter and better calibrated prediction sets than a naive application of conformal prediction.
    
[^161]: Powderworld：通过多样化任务分布来理解泛化的平台

    Powderworld: A Platform for Understanding Generalization via Rich Task Distributions. (arXiv:2211.13051v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.13051](http://arxiv.org/abs/2211.13051)

    Powderworld是一个直接在GPU上运行的轻量级但表现力强的模拟环境，用于提供泛化性的研究平台，包括世界建模和强化学习。实验表明，增加环境的复杂性可以改善世界模型和某些强化学习代理的泛化性能。

    

    强化学习面临的重大挑战之一是能够泛化到新任务。然而，泛化代理需要一组丰富、多样化的任务进行训练。为这些任务设计一个理想的环境很困难——理想的环境应支持一系列新兴现象、丰富的任务空间和快速的运行时。为了解决这个瓶颈问题，本文提出了Powderworld，一个直接在GPU上运行的轻量级但表现力强的模拟环境。在Powderworld内，提出了两个激发挑战的分布，一个用于世界建模，一个用于强化学习。每个分布都包含手动设计的测试任务，以检查泛化性能。实验表明，增加环境的复杂性可以改善世界模型和某些强化学习代理的泛化性能，但可能会抑制高方差环境下的学习。Powderworld旨在通过提供一种支持泛化研究的环境来解决这个问题。

    One of the grand challenges of reinforcement learning is the ability to generalize to new tasks. However, general agents require a set of rich, diverse tasks to train on. Designing a `foundation environment' for such tasks is tricky -- the ideal environment would support a range of emergent phenomena, an expressive task space, and fast runtime. To take a step towards addressing this research bottleneck, this work presents Powderworld, a lightweight yet expressive simulation environment running directly on the GPU. Within Powderworld, two motivating challenges distributions are presented, one for world-modelling and one for reinforcement learning. Each contains hand-designed test tasks to examine generalization. Experiments indicate that increasing the environment's complexity improves generalization for world models and certain reinforcement learning agents, yet may inhibit learning in high-variance environments. Powderworld aims to support the study of generalization by providing a so
    
[^162]: 基于关系对称结构的知识图谱对比学习

    Knowledge Graph Contrastive Learning Based on Relation-Symmetrical Structure. (arXiv:2211.10738v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.10738](http://arxiv.org/abs/2211.10738)

    本论文提出了一种基于关系对称结构的知识图谱对比学习框架 KGE-SymCL，它能有效地提高知识图谱中实体的可区分度。

    

    知识图谱嵌入 (KGE) 旨在学习强大的表示以受益于各种人工智能应用。与此同时，对比学习已被广泛利用于图学习，作为增强所学表示的可区分能力的有效机制。然而，KG的复杂结构使得构建适当的对比对变得困难。为数不多的几个尝试将对比学习策略与KGE集成。但是，它们大多依赖于语言模型（例如Bert）进行对比对构建，而不是完全挖掘潜在的图结构信息，从而阻碍了表达能力。令人惊讶的是，我们发现关系对称结构内的实体通常相似且相关。因此，我们提出了一种基于关系对称结构的知识图谱对比学习框架，KGE-SymCL，它在KG中挖掘对称结构信息以增强所学表示的区分能力。

    Knowledge graph embedding (KGE) aims at learning powerful representations to benefit various artificial intelligence applications. Meanwhile, contrastive learning has been widely leveraged in graph learning as an effective mechanism to enhance the discriminative capacity of the learned representations. However, the complex structures of KG make it hard to construct appropriate contrastive pairs. Only a few attempts have integrated contrastive learning strategies with KGE. But, most of them rely on language models ( e.g., Bert) for contrastive pair construction instead of fully mining information underlying the graph structure, hindering expressive ability. Surprisingly, we find that the entities within a relational symmetrical structure are usually similar and correlated. To this end, we propose a knowledge graph contrastive learning framework based on relation-symmetrical structure, KGE-SymCL, which mines symmetrical structure information in KGs to enhance the discriminative ability o
    
[^163]: 异质因果效应估计中模型选择的实证分析

    Empirical Analysis of Model Selection for Heterogeneous Causal Effect Estimation. (arXiv:2211.01939v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.01939](http://arxiv.org/abs/2211.01939)

    本文在二元治疗条件下条件平均处理效应估计的场景中，对因果推断的模型选择问题进行了实证分析，利用最新的生成建模进展，提出了新的度量方法，证明了新的模型选择策略的有效性。

    

    我们研究了因果推断中的模型选择问题，特别是针对二元治疗条件下条件平均处理效应（CATE）估计的情况。与机器学习中的模型选择不同，由于我们无法观察到任何数据点的反事实潜在结果，因此没有完美的交叉验证模型。为此，文献中提出了各种代理度量方法，这些方法取决于从观察到的数据中估计的辅助干扰模型（倾向性得分模型、结果回归模型）。然而，这些度量方法的有效性仅在我们可以访问反事实数据的合成数据集上进行了研究。我们进行了广泛的实证分析，以评估文献中介绍的这些度量方法以及本研究中介绍的新方法的性能，在实现多个逼真数据集的最新生成建模进展基础上进行。我们的分析表明了新的模型选择策略的出现。

    We study the problem of model selection in causal inference, specifically for the case of conditional average treatment effect (CATE) estimation under binary treatments. Unlike model selection in machine learning, there is no perfect analogue of cross-validation as we do not observe the counterfactual potential outcome for any data point. Towards this, there have been a variety of proxy metrics proposed in the literature, that depend on auxiliary nuisance models estimated from the observed data (propensity score model, outcome regression model). However, the effectiveness of these metrics has only been studied on synthetic datasets as we can access the counterfactual data for them. We conduct an extensive empirical analysis to judge the performance of these metrics introduced in the literature, and novel ones introduced in this work, where we utilize the latest advances in generative modeling to incorporate multiple realistic datasets. Our analysis suggests novel model selection strate
    
[^164]: 更平稳，更快速：缩放动量以实现随机梯度下降最佳加速

    Flatter, faster: scaling momentum for optimal speedup of SGD. (arXiv:2210.16400v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.16400](http://arxiv.org/abs/2210.16400)

    研究者们发现，将动量超参数与学习率的$2/3$次方缩放可以最大限度地加速超参数化神经网络的训练且不牺牲泛化能力。

    

    常用的优化算法通常存在在良好泛化和快速训练时间之间权衡的问题。例如，随机梯度下降（SGD）往往具有良好的泛化能力；然而，自适应梯度方法具有更好的训练时间。动量可以帮助加速SGD的训练，但到目前为止没有一个基于原则的方法来选择动量超参数。在这里，我们研究了SGD和动量在超参数化神经网络的训练中相互作用所产生的训练动态。我们发现将动量超参数$1-\beta$与学习率的$2/3$次方缩放可以最大限度地加速训练而不损失泛化能力。为了从理论上推导这个结果，我们开发了一种与结构无关的框架，其中的主要假设是存在一类具有退化全局最小值的流形，这是超参数化模型的自然属性。训练动态显示出两个特征时间尺度的出现。

    Commonly used optimization algorithms often show a trade-off between good generalization and fast training times. For instance, stochastic gradient descent (SGD) tends to have good generalization; however, adaptive gradient methods have superior training times. Momentum can help accelerate training with SGD, but so far there has been no principled way to select the momentum hyperparameter. Here we study training dynamics arising from the interplay between SGD with label noise and momentum in the training of overparametrized neural networks. We find that scaling the momentum hyperparameter $1-\beta$ with the learning rate to the power of $2/3$ maximally accelerates training, without sacrificing generalization. To analytically derive this result we develop an architecture-independent framework, where the main assumption is the existence of a degenerate manifold of global minimizers, as is natural in overparametrized models. Training dynamics display the emergence of two characteristic ti
    
[^165]: 基于超图的社区检测人工基准 (h-ABCD)

    Hypergraph Artificial Benchmark for Community Detection (h-ABCD). (arXiv:2210.15009v3 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2210.15009](http://arxiv.org/abs/2210.15009)

    本研究提出了基于超图的人工基准社区检测模型h-ABCD，并且可以灵活地模拟不同社区的均匀性水平，是分析和调整超图社区检测算法的合成平台。

    

    人工基准社区检测(ABCD)图是一种最近引入的带有社区结构和度和社区大小的幂律分布的随机图模型。该模型生成与众所周知的LFR模型具有类似特性的图形，其主要参数可以调节以模仿LFR模型中的混合参数。在本文中，我们介绍ABCD模型的超图对应物h-ABCD，它生成符合幂律分布的基础真实社区大小和度数的随机超图。与原始ABCD一样，新模型h-ABCD可以产生各种噪声水平的超图。更重要的是，该模型具有灵活性，并且可以模仿超边落入一个社区的任何所需均匀性水平。因此，它可以用作适当的合成“游乐场”，以分析和调整超图社区检测算法。

    The Artificial Benchmark for Community Detection (ABCD) graph is a recently introduced random graph model with community structure and power-law distribution for both degrees and community sizes. The model generates graphs with similar properties as the well-known LFR one, and its main parameter can be tuned to mimic its counterpart in the LFR model, the mixing parameter. In this paper, we introduce hypergraph counterpart of the ABCD model, h-ABCD, which produces random hypergraph with distributions of ground-truth community sizes and degrees following power-law. As in the original ABCD, the new model h-ABCD can produce hypergraphs with various levels of noise. More importantly, the model is flexible and can mimic any desired level of homogeneity of hyperedges that fall into one community. As a result, it can be used as a suitable, synthetic playground for analyzing and tuning hypergraph community detection algorithms.
    
[^166]: 基于注意力机制的物理系统建模：改进的潜在表示

    Attention-based Modeling of Physical Systems: Improved Latent Representations. (arXiv:2210.11269v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.11269](http://arxiv.org/abs/2210.11269)

    本文提出了一种基于注意力机制的方法，用于处理不规则空间采样的数据，实验结果表明该方法在多个领域中均达到了最优结果。

    

    本文提出了一种基于注意力机制的建模方法，可以处理任意空间点上的属性，并根据不同位置的相关测量结果进行条件建模。我们将一个转换-编码器应用于处理测量和读出位置，并提出了一种新的编码策略，该策略对测量值和读出位置应用相同的转换，然后将它们与编码后的测量值相结合。实验证明，我们的注意力模型在高空风预测、天气预测、流体动力学和热扩散等领域中均取得了最优结果。

    We propose attention-based modeling of quantities at arbitrary spatial points conditioned on related measurements at different locations. Our approach adapts a transformer-encoder to process measurements and read-out positions together. Attention-based models exhibit excellent performance across domains, which makes them an interesting candidate for modeling data irregularly sampled in space. We introduce a novel encoding strategy that applies the same transformation to the measurements and read-out positions, after which they are combined with encoded measurement values instead of relying on two different mappings.  Efficiently learning input-output mappings from irregularly-spaced data is a fundamental challenge in modeling physical phenomena. To evaluate the effectiveness of our model, we conduct experiments on diverse problem domains, including high-altitude wind nowcasting, two-days weather forecasting, fluid dynamics, and heat diffusion. Our attention-based model consistently out
    
[^167]: 隐式模型、潜在压缩、内在偏差和廉价午餐在社区检测中的应用

    Implicit models, latent compression, intrinsic biases, and cheap lunches in community detection. (arXiv:2210.09186v6 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2210.09186](http://arxiv.org/abs/2210.09186)

    本文提出了一种将社区检测目标与其对应的隐式网络生成模型相联系的解决方案，可以计算网络在任意目标下的描述长度，比较不同算法的性能，同时还可以访问隐式模型。

    

    社区检测的任务旨在将网络划分为节点集群，以总结其大规模结构，已经引出了许多具有不同目标的竞争算法。 一些社区检测方法是推断性的，通过概率生成模型明确地导出聚类目标，而其他方法是描述性的，根据特定应用的目标将网络分成子集，这使得在同一规模下比较这些方法变得具有挑战性。本文提出了将任何社区检测目标（推断性或描述性）与其相应的隐式网络生成模型相联系的解决方案。这使我们能够计算网络及其在任意目标下的分区的描述长度，无需“地面实况”标签即可比较不同算法的性能，同时还可以访问隐式模型，这是其他方法所不具备的。

    The task of community detection, which aims to partition a network into clusters of nodes to summarize its large-scale structure, has spawned the development of many competing algorithms with varying objectives. Some community detection methods are inferential, explicitly deriving the clustering objective through a probabilistic generative model, while other methods are descriptive, dividing a network according to an objective motivated by a particular application, making it challenging to compare these methods on the same scale. Here we present a solution to this problem that associates any community detection objective, inferential or descriptive, with its corresponding implicit network generative model. This allows us to compute the description length of a network and its partition under arbitrary objectives, providing a principled measure to compare the performance of different algorithms without the need for "ground truth" labels. Our approach also gives access to instances of the
    
[^168]: 基于时变有向网络的分散式超梯度计算

    Decentralized Hyper-Gradient Computation over Time-Varying Directed Networks. (arXiv:2210.02129v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.02129](http://arxiv.org/abs/2210.02129)

    本文提出了一种基于时变有向网络的分散式超梯度计算方法，避免了静态无向网络通信 Hessian 矩阵导致的高通信成本和无法使用时变有向网络优势的问题。

    

    本文解决了分散式联邦学习中估计超梯度时的通信问题。在分散式联邦学习中，超梯度量化了全局共享最优模型的性能如何受到客户端超参数扰动的影响。在先前的工作中，客户端通过在静态无向网络上通信 Hess 矩阵来跟踪这种影响，导致了（i）过高的通信成本和（ii）不能利用更高效和更强大的网络，即时变有向网络。为了解决这些问题，我们引入了一个基于模型参数和梯度的平均操作的 FL 替代性优化条件。然后，我们采用 Push-Sum 作为平均操作，在时变有向网络上进行共识优化技术。因此，从我们的最优条件推导出的超梯度估计器具有两个理想特性，（i）它只需要 Push-Sum 通信

    This paper addresses the communication issues when estimating hyper-gradients in decentralized federated learning (FL). Hyper-gradients in decentralized FL quantifies how the performance of globally shared optimal model is influenced by the perturbations in clients' hyper-parameters. In prior work, clients trace this influence through the communication of Hessian matrices over a static undirected network, resulting in (i) excessive communication costs and (ii) inability to make use of more efficient and robust networks, namely, time-varying directed networks. To solve these issues, we introduce an alternative optimality condition for FL using an averaging operation on model parameters and gradients. We then employ Push-Sum as the averaging operation, which is a consensus optimization technique for time-varying directed networks. As a result, the hyper-gradient estimator derived from our optimality condition enjoys two desirable properties; (i) it only requires Push-Sum communication of
    
[^169]: 使用贝叶斯神经网络和标签分布学习的语音情感识别中的端到端标签不确定性建模

    End-to-End Label Uncertainty Modeling in Speech Emotion Recognition using Bayesian Neural Networks and Label Distribution Learning. (arXiv:2209.15449v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2209.15449](http://arxiv.org/abs/2209.15449)

    本文提出了一种端到端的贝叶斯神经网络，使用学生t分布来模拟注释分布，并通过推导相应的KL散度损失进行训练，以捕捉情感识别中基于主观性的标签不确定性。

    

    训练机器学习算法以预测情绪表达方面的唤醒度和价值时，需要有注释数据集。然而，由于不同的人以不同的方式感知他人的情感表达，他们的注释是主观的。为了考虑这一点，通常从多个注释者收集注释，并对其进行平均以获得地面真实标签。然而，当仅在这个平均地面真实标签上进行训练时，模型对情感表达中固有的主观性是不可知的。因此，在这项工作中，我们提出了一种端到端的贝叶斯神经网络，能够在注释分布上进行训练，以捕捉基于主观性的标签不确定性。我们使用学生t分布来模拟注释分布，而不是高斯分布，这也考虑到了可用注释数量。我们推导相应的KL散度损失，并使用它来训练注释分布的估计器，从中获得预测结果。

    To train machine learning algorithms to predict emotional expressions in terms of arousal and valence, annotated datasets are needed. However, as different people perceive others' emotional expressions differently, their annotations are subjective. To account for this, annotations are typically collected from multiple annotators and averaged to obtain ground-truth labels. However, when exclusively trained on this averaged ground-truth, the model is agnostic to the inherent subjectivity in emotional expressions. In this work, we therefore propose an end-to-end Bayesian neural network capable of being trained on a distribution of annotations to also capture the subjectivity-based label uncertainty. Instead of a Gaussian, we model the annotation distribution using Student's t-distribution, which also accounts for the number of annotations available. We derive the corresponding Kullback-Leibler divergence loss and use it to train an estimator for the annotation distribution, from which the
    
[^170]: 在未知随机环境中使用软障碍强制执行硬约束：安全强化学习

    Enforcing Hard Constraints with Soft Barriers: Safe Reinforcement Learning in Unknown Stochastic Environments. (arXiv:2209.15090v3 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2209.15090](http://arxiv.org/abs/2209.15090)

    在未知环境下，通过软障碍函数强制实施硬安全约束，提出了一种安全强化学习方法，可以同时学习环境和优化控制策略。

    

    在要求系统状态不到达某些指定的不安全区域的硬约束下，确保强化学习代理在未知和随机环境中的安全性是相当具有挑战性的。许多流行的安全强化学习方法，如基于约束马尔可夫决策过程（CMDP）范式的方法，将安全违规形式化为成本函数，并试图将累积成本的期望限制在阈值下。然而，通过这样对安全违规成本的限制，间接地捕捉和强制执行硬可达性安全约束通常很难。在这项工作中，我们利用障碍函数的概念来显式地编码硬安全约束，并在环境未知的情况下，将它们放松到我们设计的基于生成模型的软障碍函数中。基于这样的软障碍，我们提出了一种安全强化学习方法，可以同时学习环境和优化控制策略，同时有效地实施硬安全约束。

    It is quite challenging to ensure the safety of reinforcement learning (RL) agents in an unknown and stochastic environment under hard constraints that require the system state not to reach certain specified unsafe regions. Many popular safe RL methods such as those based on the Constrained Markov Decision Process (CMDP) paradigm formulate safety violations in a cost function and try to constrain the expectation of cumulative cost under a threshold. However, it is often difficult to effectively capture and enforce hard reachability-based safety constraints indirectly with such constraints on safety violation costs. In this work, we leverage the notion of barrier function to explicitly encode the hard safety constraints, and given that the environment is unknown, relax them to our design of \emph{generative-model-based soft barrier functions}. Based on such soft barriers, we propose a safe RL approach that can jointly learn the environment and optimize the control policy, while effectiv
    
[^171]: 共轭自然选择

    Conjugate Natural Selection. (arXiv:2208.13898v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.13898](http://arxiv.org/abs/2208.13898)

    本文证明了Fisher-Rao自然梯度下降最佳逼近连续时间复制子方程，这一对应关系称为“共轭自然选择”，为进化计算提供了替代方法，同时提供了连续贝叶斯推理的最佳近似。

    

    我们证明了Fisher-Rao自然梯度下降（FR-NGD）最佳逼近了连续时间复制子方程（一种基本的进化动力学模型），并将此对应关系称为“共轭自然选择”。该对应关系为在连续或高维度假设空间上进行进化计算提供了替代方法。作为一个特例，FR-NGD还提供了连续贝叶斯推理的最佳近似，当假设基于预测实际观测结果而相互竞争时。在这种情况下，该方法避免了计算先验概率的需要。我们通过一个非凸优化问题和一个具有时变参数的随机过程的系统识别任务演示了我们的发现。

    We prove that Fisher-Rao natural gradient descent (FR-NGD) optimally approximates the continuous time replicator equation (an essential model of evolutionary dynamics), and term this correspondence "conjugate natural selection". This correspondence promises alternative approaches for evolutionary computation over continuous or high-dimensional hypothesis spaces. As a special case, FR-NGD also provides the optimal approximation of continuous Bayesian inference when hypotheses compete on the basis of predicting actual observations. In this case, the method avoids the need to compute prior probabilities. We demonstrate our findings on a non-convex optimization problem and a system identification task for a stochastic process with time-varying parameters.
    
[^172]: HELP ME THINK：一种帮助非专家使用模型创建定制内容的简单提示策略

    HELP ME THINK: A Simple Prompting Strategy for Non-experts to Create Customized Content with Models. (arXiv:2208.08232v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2208.08232](http://arxiv.org/abs/2208.08232)

    HELP ME THINK是一种帮助非专家用户创建定制化内容的简单提示策略，利用GPT3提出相关问题和利用用户答案执行任务，适用于各种需要重要思考的任务。

    

    控制语言模型生成的文本并定制内容一直是一个长期存在的挑战。现有的提示技术提出了为了提供控制而特定于任务的方法，并缺乏一般性；这为非专业用户找到适合其任务的方法提供了压倒性的选择。这些技术所涉及的工作，如编写示例、解释、指令等，进一步限制了它们在非专业用户中的采用率。在本文中，我们提出了一种名为HELP ME THINK的简单提示策略，鼓励GPT3通过提出一组相关问题和利用用户的答案来执行任务来帮助非专家用户。我们展示了我们的技术HELP ME THINK在各种任务上的功效。具体来说，我们关注难以完成且需要重要思考的任务。我们希望我们的工作将鼓励开发非传统的方式来利用大型语言模型的力量。

    Controlling the text generated by language models and customizing the content has been a long-standing challenge. Existing prompting techniques proposed in pursuit of providing control are task-specific and lack generality; this provides overwhelming choices for non-expert users to find a suitable method for their task. The effort associated with those techniques, such as in writing examples, explanations, instructions, etc. further limits their adoption among non-expert users. In this paper, we propose a simple prompting strategy HELP ME THINK where we encourage GPT3 to help non-expert users by asking a set of relevant questions and leveraging user answers to execute the task. We demonstrate the efficacy of our technique HELP ME THINK on a variety of tasks. Specifically, we focus on tasks that are hard for average humans and require significant thinking to perform. We hope our work will encourage the development of unconventional ways to harness the power of large language models.
    
[^173]: 如何重用和组合知识，实现终身任务学习：综述连续学习与功能组合方法

    How to Reuse and Compose Knowledge for a Lifetime of Tasks: A Survey on Continual Learning and Functional Composition. (arXiv:2207.07730v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.07730](http://arxiv.org/abs/2207.07730)

    本篇综述介绍了连续学习和功能组合方法的研究现状和未来联系，以实现人工智能在解决新问题时可以不断积累和组合知识的终身学习目标。

    

    人工智能的主要目标之一是创建一个能够获得对世界的普遍理解的代理。这种代理需要能够不断积累和建立知识，以应对遇到的新体验。终身或连续学习解决了这种情况，在这种情况下，代理面对不断的问题流，必须努力掌握解决每个新任务所需的知识。如果代理能够在某种组合表示形式中累积知识，则可以选择性地重用和组合相关的知识，构建新的解决方案。尽管这个简单的想法具有直观的吸引力，但是有关终身学习和组合学习的文献在很大程度上是分开进行的。为了促进两个领域之间的连接，本文概述了它们各自的研究景观，并讨论了它们之间现有和未来的联系。

    A major goal of artificial intelligence (AI) is to create an agent capable of acquiring a general understanding of the world. Such an agent would require the ability to continually accumulate and build upon its knowledge as it encounters new experiences. Lifelong or continual learning addresses this setting, whereby an agent faces a continual stream of problems and must strive to capture the knowledge necessary for solving each new task it encounters. If the agent is capable of accumulating knowledge in some form of compositional representation, it could then selectively reuse and combine relevant pieces of knowledge to construct novel solutions. Despite the intuitive appeal of this simple idea, the literatures on lifelong learning and compositional learning have proceeded largely separately. In an effort to promote developments that bridge between the two fields, this article surveys their respective research landscapes and discusses existing and future connections between them.
    
[^174]: 基于图像块嵌入的自监督学习背后的成功之道

    Bag of Image Patch Embedding Behind the Success of Self-Supervised Learning. (arXiv:2206.08954v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.08954](http://arxiv.org/abs/2206.08954)

    这项工作发现，自监督学习方法主要学习图像块的表示，反映出它们的共同出现。学习固定尺度图像块的表示，并将局部表示聚合为图像表示，称为BagSSL，能够实现与基线方法相似甚至更好的结果。

    

    自监督学习已经在学习图像表示方面取得了巨大的经验进展。然而，我们对学习这种表示背后的原理的理解仍然有限。这项工作表明，联合嵌入自监督学习方法主要学习图像块的表示，该表示反映了它们的共同出现。这种与共现建模的联系可以被正式地建立，并且它补充了主流的不变性视角。我们从经验上表明，学习固定尺度图像块的表示，并将局部图像块表示聚合为图像表示，可以实现与基线方法相似甚至更好的结果。我们将此过程称为BagSSL。即使使用32x32的块表示，在ImageNet上，BagSSL也能够达到62%的top-1线性探测准确率。另一方面，通过多尺度预训练模型，我们展示了整个图像嵌入大致上是局部图像块嵌入结果的平均值。

    Self-supervised learning (SSL) has recently achieved tremendous empirical advancements in learning image representation. However, our understanding of the principle behind learning such a representation is still limited. This work shows that joint-embedding SSL approaches primarily learn a representation of image patches, which reflects their co-occurrence. Such a connection to co-occurrence modeling can be established formally, and it supplements the prevailing invariance perspective. We empirically show that learning a representation for fixed-scale patches and aggregating local patch representations as the image representation achieves similar or even better results than the baseline methods. We denote this process as BagSSL. Even with 32x32 patch representation, BagSSL achieves 62% top-1 linear probing accuracy on ImageNet. On the other hand, with a multi-scale pretrained model, we show that the whole image embedding is approximately the average of local patch embeddings. While the
    
[^175]: 与背景知识一致的计数马尔科夫等价有向无环图

    Counting Markov Equivalent Directed Acyclic Graphs Consistent with Background Knowledge. (arXiv:2206.06744v2 [cs.DS] UPDATED)

    [http://arxiv.org/abs/2206.06744](http://arxiv.org/abs/2206.06744)

    本文研究如何在给定一些边的方向已确定的情况下，计算马尔科夫等价类中的有向无环图数量，并且提出了一个计数算法，该算法运行时间受到一个多项式的约束。

    

    最近，Wienobst、Bannach和Liskiewicz（AAAI 2021）提出了一个计算马尔科夫等价类中有向无环图数量的多项式时间精确算法。本文考虑了更一般的问题，即在一些边的方向已确定的情况下计算马尔科夫等价类中的有向无环图数量（例如，在部分干预数据可用的情况下出现这种设置）。早期的研究表明，这个问题在复杂理论上是困难的。相反，我们发现该问题在一个有趣的实例类中仍然是可处理的，并建立了它的“固定参数可处理性”。特别地，我们的计数算法运行时间受到一个多项式的约束，并且这个多项式的度数\emph{不}依赖于提供的附加边的数量。

    A polynomial-time exact algorithm for counting the number of directed acyclic graphs in a Markov equivalence class was recently given by Wien\"obst, Bannach, and Li\'skiewicz (AAAI 2021). In this paper, we consider the more general problem of counting the number of directed acyclic graphs in a Markov equivalence class when the directions of some of the edges are also fixed (this setting arises, for example, when interventional data is partially available). This problem has been shown in earlier work to be complexity-theoretically hard. In contrast, we show that the problem is nevertheless tractable in an interesting class of instances, by establishing that it is ``fixed-parameter tractable''. In particular, our counting algorithm runs in time that is bounded by a polynomial in the size of the graph, where the degree of the polynomial does \emph{not} depend upon the number of additional edges provided as input.
    
[^176]: 隐藏混淆因素下剂量响应的部分识别

    Partial Identification of Dose Responses with Hidden Confounders. (arXiv:2204.11206v3 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2204.11206](http://arxiv.org/abs/2204.11206)

    本论文提出了一种新方法，用于界定无法通过点估计进行识别的连续值处理效应估计范围，以解决存在隐藏混淆因素的问题。

    

    从观测数据中推断连续值处理的因果效应是一项关键任务，有望更好地为政策和决策制定者提供信息。 确定这些效应所需的关键假设是包括所有混淆变量——处理和结果的因果父母——作为协变量。 不幸的是，仅凭观测数据，我们无法确定这个标准是否得到满足。 当混淆变量被隐藏时，敏感性分析提供了一种原则性的方式来为因果估计提供界限。 虽然在离散值处理的灵敏度分析中受到了广泛关注，但对于连续值处理，却付出了更少的关注。 我们提出了新的方法，用于界定无法通过点估计进行识别的平均和条件平均连续值处理效应估计的范围，因为存在隐藏的混淆。 在多个数据集上进行的半合成基准测试显示出，我们的方法提供了更紧密的覆盖范围。

    Inferring causal effects of continuous-valued treatments from observational data is a crucial task promising to better inform policy- and decision-makers. A critical assumption needed to identify these effects is that all confounding variables -- causal parents of both the treatment and the outcome -- are included as covariates. Unfortunately, given observational data alone, we cannot know with certainty that this criterion is satisfied. Sensitivity analyses provide principled ways to give bounds on causal estimates when confounding variables are hidden. While much attention is focused on sensitivity analyses for discrete-valued treatments, much less is paid to continuous-valued treatments. We present novel methodology to bound both average and conditional average continuous-valued treatment-effect estimates when they cannot be point identified due to hidden confounding. A semi-synthetic benchmark on multiple datasets shows our method giving tighter coverage of the true dose-response c
    
[^177]: 深度线性网络的精确解析解

    Exact Solutions of a Deep Linear Network. (arXiv:2202.04777v6 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2202.04777](http://arxiv.org/abs/2202.04777)

    本研究找到了带权重衰减和随机神经元的深度线性网络全局最小值的解析表达式，结果表明权重衰减与模型架构的强烈交互作用会在多于1个隐藏层的网络中创建不良极小值，并表明常见的深度学习初始化方法无法在一般情况下缓解神经网络的优化问题。

    

    本研究找到了带权重衰减和随机神经元的深度线性网络全局最小值的解析表达式，这是理解神经网络理论中的基础模型。我们的结果表明，在深度神经网络架构中，零是一个特殊的点。我们展示了权重衰减与模型架构的强烈交互作用，并能够在具有超过 $1$ 个隐藏层的网络中创建不良极小值，这与仅有 $1$ 个隐藏层的网络有质的不同。实际上，我们的结果意味着常见的深度学习初始化方法无法在一般情况下缓解神经网络的优化问题。

    This work finds the analytical expression of the global minima of a deep linear network with weight decay and stochastic neurons, a fundamental model for understanding the landscape of neural networks. Our result implies that zero is a special point in deep neural network architecture. We show that weight decay strongly interacts with the model architecture and can create bad minima at zero in a network with more than $1$ hidden layer, qualitatively different from a network with only $1$ hidden layer. Practically, our result implies that common deep learning initialization methods are insufficient to ease the optimization of neural networks in general.
    
[^178]: 因子增强的树集合方法

    Factor-augmented tree ensembles. (arXiv:2111.14000v5 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2111.14000](http://arxiv.org/abs/2111.14000)

    本文提出了一种因子增强的树集合方法，能够处理多种不规则预测变量，为处理宏观金融问题提供一种可靠的方法。

    

    本文提出了利用状态空间方法提取潜在稳态因子来扩展时间序列回归树信息集的方法。通过这样做，该方法将时间序列回归树的应用扩展到两个方面。第一，它可以处理测量误差、非平稳趋势、季节性和/或缺失观测等不规则的预测变量。第二，它提供了一种明确的利用领域专业理论来指导时间序列回归树的方法。实证结果表明，这些因子增强的树集合方法在宏观金融问题方面提供了一种可靠的方法。本文重点介绍了美国股票波动率与商业周期之间的先导滞后效应。

    This manuscript proposes to extend the information set of time-series regression trees with latent stationary factors extracted via state-space methods. In doing so, this approach generalises time-series regression trees on two dimensions. First, it allows to handle predictors that exhibit measurement error, non-stationary trends, seasonality and/or irregularities such as missing observations. Second, it gives a transparent way for using domain-specific theory to inform time-series regression trees. Empirically, ensembles of these factor-augmented trees provide a reliable approach for macro-finance problems. This article highlights it focussing on the lead-lag effect between equity volatility and the business cycle in the United States.
    
[^179]: 时空联合图卷积网络用于交通预测

    Spatio-Temporal Joint Graph Convolutional Networks for Traffic Forecasting. (arXiv:2111.13684v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2111.13684](http://arxiv.org/abs/2111.13684)

    本文提出了一种称为STJGCN的方法，用于在多个未来时间步长上准确预测道路网络上的交通流量。该方法构建了预定义的和自适应的时空联合图以及在STJGs上执行图卷积运算，以提取时空特征并进行多步预测，并已在两个真实数据集上取得了优于现有最先进方法的结果。

    

    近期的研究将交通预测问题转化为一个时空图建模问题。通常，研究人员在每个时间步构建一个静态的空间图，然后用相邻时间步之间的节点连接表示为时空图。然而，这种方法未能明确反映不同时间步之间不同节点之间的相关性，从而限制了图神经网络的学习能力。此外，这些模型通过在不同时间步之间使用相同的邻接矩阵来忽略节点之间的动态时空相关性。为了解决这些限制，我们提出了一种称为时空联合图卷积网络 (STJGCN) 的新方法，用于在多个未来时间步骤上准确预测道路网络上的交通流量。具体而言，我们的方法包括构建预定义的和自适应的时空联合图 (STJGs) 以及在 STJGs 上执行图卷积运算以提取时空特征并进行多步预测。在两个真实数据集上的实验结果表明，我们的方法优于现有的最先进方法。

    Recent studies have shifted their focus towards formulating traffic forecasting as a spatio-temporal graph modeling problem. Typically, they constructed a static spatial graph at each time step and then connected each node with itself between adjacent time steps to create a spatio-temporal graph. However, this approach failed to explicitly reflect the correlations between different nodes at different time steps, thus limiting the learning capability of graph neural networks. Additionally, those models overlooked the dynamic spatio-temporal correlations among nodes by using the same adjacency matrix across different time steps. To address these limitations, we propose a novel approach called Spatio-Temporal Joint Graph Convolutional Networks (STJGCN) for accurate traffic forecasting on road networks over multiple future time steps. Specifically, our method encompasses the construction of both pre-defined and adaptive spatio-temporal joint graphs (STJGs) between any two time steps, which
    
[^180]: DAPPER：基于个性化的无标签移动传感性能评估

    DAPPER: Label-Free Performance Estimation after Personalization for Heterogeneous Mobile Sensing. (arXiv:2111.11053v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2111.11053](http://arxiv.org/abs/2111.11053)

    提出了一种称为DAPPER的方法，可以在没有标记的情况下估计目标域中的适应性能，从而解决了移动感知中的域漂移问题，并在实验中展示了出色的性能。

    

    许多应用程序利用移动设备和机器学习传感器提供新服务。然而，不同的用户、设备和环境等因素影响这些应用程序的性能，从而使域漂移成为移动感知中的关键问题。尽管尝试了域适应来解决这个具有挑战性的问题，但由于各种因素之间的复杂相互作用，它们的性能是不可靠的。原则上，性能不确定性可以通过使用基本真相标签进行性能验证来识别和赎回。然而，对于每个用户收集高质量、足够的标记数据是不可行的。为了解决这个问题，我们提出了DAPPER（域自适应性能估计器），它可以在没有标记的目标数据的情况下估计目标域中的自适应性能。我们的核心思想是基于特征和性能之间的相互信息来近似模型性能，并利用移动传感器上的个性化作为自然校准来接近基本的真相标签。在真实世界数据集上的实验中，DAPPER在目标域的相关性方面比现有的域适应方法表现更好，最高可提高11%。

    Many applications utilize sensors in mobile devices and machine learning to provide novel services. However, various factors such as different users, devices, and environments impact the performance of such applications, thus making the domain shift (i.e., distributional shift between the training domain and the target domain) a critical issue in mobile sensing. Despite attempts in domain adaptation to solve this challenging problem, their performance is unreliable due to the complex interplay among diverse factors. In principle, the performance uncertainty can be identified and redeemed by performance validation with ground-truth labels. However, it is infeasible for every user to collect high-quality, sufficient labeled data. To address the issue, we present DAPPER (Domain AdaPtation Performance EstimatoR) that estimates the adaptation performance in a target domain with only unlabeled target data. Our key idea is to approximate the model performance based on the mutual information b
    
[^181]: 扩展的物理信息神经网络在参数最优控制问题预分析中的应用

    An extended physics informed neural network for preliminary analysis of parametric optimal control problems. (arXiv:2110.13530v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.13530](http://arxiv.org/abs/2110.13530)

    本研究提出了一种基于物理信息的学习方法，用于快速模拟参数化现象。该方法包括在损失函数、输入特征和神经网络结构中利用物理信息，可应用于多个方程和最优控制问题。

    

    本文提出了一种物理信息监督学习策略的扩展方法，用于处理参数化偏微分方程。尽管参数化偏微分方程在许多应用中非常有用，但在实时和多查询情况下，它们往往具有较高的计算成本。因此，我们的主要目标是提供一种物理信息学习范式，以在短时间内模拟参数化现象。物理信息将通过损失函数（标准物理信息神经网络）、扩展输入特征（额外的特征利用）和构建有效神经网络的指导方针（物理信息架构）来得到充分利用。这三个方面的综合应用将加快训练过程，并提高参数化预测的准确性。本研究已应用于多个方程和最优控制框架中进行测试。

    In this work we propose an extension of physics informed supervised learning strategies to parametric partial differential equations. Indeed, even if the latter are indisputably useful in many applications, they can be computationally expensive most of all in a real-time and many-query setting. Thus, our main goal is to provide a physics informed learning paradigm to simulate parametrized phenomena in a small amount of time. The physics information will be exploited in many ways, in the loss function (standard physics informed neural networks), as an augmented input (extra feature employment) and as a guideline to build an effective structure for the neural network (physics informed architecture). These three aspects, combined together, will lead to a faster training phase and to a more accurate parametric prediction. The methodology has been tested for several equations and also in an optimal control framework.
    
[^182]: 开放世界特征外推问题的归纳图学习方法

    Towards Open-World Feature Extrapolation: An Inductive Graph Learning Approach. (arXiv:2110.04514v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.04514](http://arxiv.org/abs/2110.04514)

    本文提出了一种采用图表示和学习的方法，解决了处理开放世界特征外推问题的挑战，同时使用两种训练策略来实现对新特征的外推，并缓解特征层面的过拟合问题。

    

    本文解决了开放世界特征外推问题，其中输入数据的特征空间经过扩展，在部分观察到的特征上训练的模型需要处理测试数据中的新特征而无需重新训练。我们提出了一种新的采用图表示和学习的学习范式。我们的框架包含两个模块：1）骨干网络作为较低的模型，将特征作为输入并输出预测的标签；2）图神经网络作为较高的模型，通过在从观察到的数据构建的特征-数据图上进行消息传递，学习外推新特征的嵌入。基于我们的框架，我们设计了两种训练策略，一种是自监督方法，另一种是归纳学习方法，用于赋予模型外推能力并缓解特征层面的过拟合。我们还提供了理论分析。

    We target open-world feature extrapolation problem where the feature space of input data goes through expansion and a model trained on partially observed features needs to handle new features in test data without further retraining. The problem is of much significance for dealing with features incrementally collected from different fields. To this end, we propose a new learning paradigm with graph representation and learning. Our framework contains two modules: 1) a backbone network (e.g., feedforward neural nets) as a lower model takes features as input and outputs predicted labels; 2) a graph neural network as an upper model learns to extrapolate embeddings for new features via message passing over a feature-data graph built from observed data. Based on our framework, we design two training strategies, a self-supervised approach and an inductive learning approach, to endow the model with extrapolation ability and alleviate feature-level over-fitting. We also provide theoretical analy
    
[^183]: 应用神经网络解决 Monge-Amp\`ere 方程的迪利克雷问题

    Solving the Dirichlet problem for the Monge-Amp\`ere equation using neural networks. (arXiv:2110.03310v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2110.03310](http://arxiv.org/abs/2110.03310)

    本文应用神经网络解决 Monge-Amp\`ere 方程的迪利克雷问题，使用深度凸输入神经网络的假设可以用来找到唯一的凸解，方法对奇异点、不连续点和源函数中的噪声具有鲁棒性，在高维情况下也能表现良好。

    

    Monge-Amp\`ere 方程是分析、几何和应用科学中非常重要的一个全非线性偏微分方程。本文应用神经网络解决了与 Monge-Amp\`ere 方程相关的迪利克雷问题，并且展示了使用深度凸输入神经网络的假设可以用来找到唯一的凸解。我们分析了奇异点、不连续点和源函数中的噪声对方法效果的影响，考虑了非平凡域，并研究了方法在高维情况下的性能。我们通过数值分析研究了收敛性并基于稳定性结果给出了误差估计。我们还将此方法与使用惩罚缺乏凸性的损失函数以及标准前馈网络结合使用的替代方法进行了比较。

    The Monge-Amp\`ere equation is a fully nonlinear partial differential equation (PDE) of fundamental importance in analysis, geometry and in the applied sciences. In this paper we solve the Dirichlet problem associated with the Monge-Amp\`ere equation using neural networks and we show that an ansatz using deep input convex neural networks can be used to find the unique convex solution. As part of our analysis we study the effect of singularities, discontinuities and noise in the source function, we consider nontrivial domains, and we investigate how the method performs in higher dimensions. We investigate the convergence numerically and present error estimates based on a stability result. We also compare this method to an alternative approach in which standard feed-forward networks are used together with a loss function which penalizes lack of convexity.
    
[^184]: 随机坐标变换及其在鲁棒机器学习中的应用

    Stochastic coordinate transformations with applications to robust machine learning. (arXiv:2110.01729v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2110.01729](http://arxiv.org/abs/2110.01729)

    本文提出了一种利用随机坐标变换进行异常检测的新方法，该方法通过层级张量积展开来逼近随机过程，并通过训练机器学习分类器对投影系数进行检测。在基准数据集上的实验表明，该方法胜过现有的最先进方法。

    

    本文介绍了一组新的特征，利用Karhunen-Loeve展开法来识别输入数据的潜在随机行为。这些新特征是通过基于最近的函数数据分析理论进行的坐标变换构建的，用于异常检测。相关的信号分解是用已知优化属性的层级张量积展开来逼近具有有限功能空间的随机过程（随机场）。原则上，这些低维空间可以捕捉给定名义类别的'底层信号'的大部分随机变化，并且可以将来自其它类别的信号拒绝为随机异常。通过名义类别的层级有限维展开，构建了一系列用于检测异常信号组件的正交嵌套子空间。然后使用这些子空间中的投影系数来训练用于异常检测的机器学习（ML）分类器。我们在几个基准数据集上评估所提出的方法，结果表明其胜过现有的最先进方法。

    In this paper we introduce a set of novel features for identifying underlying stochastic behavior of input data using the Karhunen-Loeve expansion. These novel features are constructed by applying a coordinate transformation based on the recent Functional Data Analysis theory for anomaly detection. The associated signal decomposition is an exact hierarchical tensor product expansion with known optimality properties for approximating stochastic processes (random fields) with finite dimensional function spaces. In principle these low dimensional spaces can capture most of the stochastic behavior of `underlying signals' in a given nominal class, and can reject signals in alternative classes as stochastic anomalies. Using a hierarchical finite dimensional expansion of the nominal class, a series of orthogonal nested subspaces is constructed for detecting anomalous signal components. Projection coefficients of input data in these subspaces are then used to train a Machine Learning (ML) clas
    
[^185]: WildWood：一种新的随机森林算法

    WildWood: a new Random Forest algorithm. (arXiv:2109.08010v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2109.08010](http://arxiv.org/abs/2109.08010)

    WildWood是一种新的随机森林算法，使用指数权重聚合包外样本以改进预测，并通过使用直方图策略加速分裂查找，具有比标准RF和极限梯度提升算法更快和更具竞争力的性能。

    

    我们介绍了WildWood（WW）这种新的用于监督学习的集合算法，采用了Random Forest（RF）类型。标准的RF算法使用自助法样本来计算包外（out-of-bag）分数，WW使用这些样本产生改进的预测，给出每个完全生长的树的所有可能子树预测的聚合。这是通过使用在包外样本上计算的指数权重聚合实现的，这些样本由称为上下文树加权（context tree weighting）的算法精确且高效地计算出来。值得注意的是，与其他成熟的集合方法，如标准RF和极限梯度提升（extreme gradient boosting）算法相比，WildWoods快速且具有竞争力，其中包括采用加速分裂查找的直方图策略。

    We introduce WildWood (WW), a new ensemble algorithm for supervised learning of Random Forest (RF) type. While standard RF algorithms use bootstrap out-of-bag samples to compute out-of-bag scores, WW uses these samples to produce improved predictions given by an aggregation of the predictions of all possible subtrees of each fully grown tree in the forest. This is achieved by aggregation with exponential weights computed over out-of-bag samples, that are computed exactly and very efficiently thanks to an algorithm called context tree weighting. This improvement, combined with a histogram strategy to accelerate split finding, makes WW fast and competitive compared with other well-established ensemble methods, such as standard RF and extreme gradient boosting algorithms.
    
[^186]: 异常最快变点检测中的赌博机方法

    Bandit Quickest Changepoint Detection. (arXiv:2107.10492v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2107.10492](http://arxiv.org/abs/2107.10492)

    基于赌博机的方法可以有效平衡探索和利用，实现对一组传感器的最快变点检测，从而节省资源和成本。

    

    许多工业和安全应用程序使用一组传感器来检测时间行为模式中的突变。这些突变通常在局部表现出来，仅使一小部分传感器有信息。由于资源限制，监控每个传感器可能很昂贵，这是进行赌博机最快变点检测问题的动机，其中选择一系列传感动作（或传感器），并且只观察与所选动作对应的测量。我们推导了有限参数概率分布类别的检测延迟的信息理论下界。我们随后提出了一种计算有效的在线感知方案，它无缝平衡了对不同传感选项的探索需求与询问信息动作的利用。我们推导了所提出方案的预期延迟界限，同时证明了这些界限与我们的信息理论下界在低维空间的匹配性。

    Many industrial and security applications employ a suite of sensors for detecting abrupt changes in temporal behavior patterns. These abrupt changes typically manifest locally, rendering only a small subset of sensors informative. Continuous monitoring of every sensor can be expensive due to resource constraints, and serves as a motivation for the bandit quickest changepoint detection problem, where sensing actions (or sensors) are sequentially chosen, and only measurements corresponding to chosen actions are observed. We derive an information-theoretic lower bound on the detection delay for a general class of finitely parameterized probability distributions. We then propose a computationally efficient online sensing scheme, which seamlessly balances the need for exploration of different sensing options with exploitation of querying informative actions. We derive expected delay bounds for the proposed scheme and show that these bounds match our information-theoretic lower bounds at low
    
[^187]: 学习不同的特征有帮助，可证明。

    Learning distinct features helps, provably. (arXiv:2106.06012v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2106.06012](http://arxiv.org/abs/2106.06012)

    学习非冗余的不同特征对神经网络的性能有帮助，具有更多不同特征的隐藏层单元可以导致更好的泛化能力。

    

    本文研究了一个使用最小二乘损失训练的两层神经网络所学习的特征的多样性。我们通过隐藏层特征之间的平均$L_2$距离来度量多样性，并理论探讨了学习非冗余的不同特征如何影响网络的性能。为此，我们基于Rademacher复杂度推导出了基于特征多样性的新型推广界限。我们的分析证明了隐藏层单元内具有更多不同特征可以导致更好的泛化能力。我们还展示了如何将我们的结果扩展到更深的网络和不同的损失函数。

    We study the diversity of the features learned by a two-layer neural network trained with the least squares loss. We measure the diversity by the average $L_2$-distance between the hidden-layer features and theoretically investigate how learning non-redundant distinct features affects the performance of the network. To do so, we derive novel generalization bounds depending on feature diversity based on Rademacher complexity for such networks. Our analysis proves that more distinct features at the network's units within the hidden layer lead to better generalization. We also show how to extend our results to deeper networks and different losses.
    
[^188]: 核细化

    Kernel Thinning. (arXiv:2105.05842v9 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2105.05842](http://arxiv.org/abs/2105.05842)

    核细化是一种更有效的压缩分布的方法，它可以将$n$点近似的分布压缩到具有可比较最坏积分误差的$\sqrt{n}$点近似，其亚指数保证类似于在$[0,1]^d$上均匀$\mathbb{P}$的经典准蒙特卡罗误差率，但适用于$\mathbb{R}^d$上的一般分布。

    

    我们介绍了核细化，一种比独立同分布采样或标准细化更有效地压缩分布$\mathbb{P}$的新方法。给定一个合适的再生核$\mathbf{k}_{\star}$和$\mathcal{O}(n^2)$时间，核细化将一个$n$点近似的$\mathbb{P}$压缩成一个具有与相关再生核希尔伯特空间中的可比较最坏积分误差的$\sqrt{n}$点近似。在概率上，紧支撑的$\mathbb{P}$的积分误差最大差别为$\mathcal{O}_d(n^{-1/2}\sqrt{\log n})$，在$\mathbb{R}^d$上的亚指数$\mathbb{P}$为$\mathcal{O}_d(n^{-\frac{1}{2}} (\log n)^{(d+1)/2}\sqrt{\log\log n})$。相比之下，来自$\mathbb{P}$的等大小i.i.d.样本面临$\Omega(n^{-1/4})$的积分误差。我们的亚指数保证类似于在$[0,1]^d$上均匀$\mathbb{P}$的经典准蒙特卡罗误差率，但适用于$\mathbb{R}^d$上的一般分布和一个大

    We introduce kernel thinning, a new procedure for compressing a distribution $\mathbb{P}$ more effectively than i.i.d. sampling or standard thinning. Given a suitable reproducing kernel $\mathbf{k}_{\star}$ and $\mathcal{O}(n^2)$ time, kernel thinning compresses an $n$-point approximation to $\mathbb{P}$ into a $\sqrt{n}$-point approximation with comparable worst-case integration error across the associated reproducing kernel Hilbert space. The maximum discrepancy in integration error is $\mathcal{O}_d(n^{-1/2}\sqrt{\log n})$ in probability for compactly supported $\mathbb{P}$ and $\mathcal{O}_d(n^{-\frac{1}{2}} (\log n)^{(d+1)/2}\sqrt{\log\log n})$ for sub-exponential $\mathbb{P}$ on $\mathbb{R}^d$. In contrast, an equal-sized i.i.d. sample from $\mathbb{P}$ suffers $\Omega(n^{-1/4})$ integration error. Our sub-exponential guarantees resemble the classical quasi-Monte Carlo error rates for uniform $\mathbb{P}$ on $[0,1]^d$ but apply to general distributions on $\mathbb{R}^d$ and a wid
    
[^189]: 不完整目标领域下的域自适应

    Domain Adaptation with Incomplete Target Domains. (arXiv:2012.01606v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2012.01606](http://arxiv.org/abs/2012.01606)

    本研究提出了一种基于不完整数据插补的对抗网络（IDIAN）模型，用于解决具有部分观察到的数据的不完整目标领域下的域自适应问题，实验结果表明该模型在跨域和实际适应任务中都具有良好的表现。

    

    域自适应是通过利用辅助源域中的现有标记数据来减少目标域注释成本的任务，已经引起了研究界的广泛关注。然而，标准的域自适应假设两个域中都有完全观察到的数据，而在实际应用中，缺少数据的存在是普遍的。在本文中，我们处理了更具挑战性的域自适应情景，即具有部分观察到的数据的不完整目标领域。我们提出了一种基于不完整数据插补的对抗网络（IDIAN）模型来解决这一新的域自适应挑战。在所提出的模型中，我们设计了一个数据插补模块来填补基于目标域局部观察到的数据中的缺失特征值，并通过深度对抗适应来对齐两个域。我们在跨域基准任务和具有不完整目标领域的实际适应任务上进行了实验。实验结果表明，与最先进的方法相比，我们所提出的IDIAN模型具有更好的性能。

    Domain adaptation, as a task of reducing the annotation cost in a target domain by exploiting the existing labeled data in an auxiliary source domain, has received a lot of attention in the research community. However, the standard domain adaptation has assumed perfectly observed data in both domains, while in real world applications the existence of missing data can be prevalent. In this paper, we tackle a more challenging domain adaptation scenario where one has an incomplete target domain with partially observed data. We propose an Incomplete Data Imputation based Adversarial Network (IDIAN) model to address this new domain adaptation challenge. In the proposed model, we design a data imputation module to fill the missing feature values based on the partial observations in the target domain, while aligning the two domains via deep adversarial adaption. We conduct experiments on both cross-domain benchmark tasks and a real world adaptation task with imperfect target domains. The expe
    
[^190]: 预测不确定性何时重要：理解机器学习辅助决策中预测不确定性的影响

    When Does Uncertainty Matter?: Understanding the Impact of Predictive Uncertainty in ML Assisted Decision Making. (arXiv:2011.06167v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2011.06167](http://arxiv.org/abs/2011.06167)

    本研究通过用户研究探讨了机器学习辅助决策中展示预测不确定性的有效性，结果表明不论后验预测分布的形状和方差如何，展示后验预测分布都会使模型预测产生更小的分歧。

    

    随着机器学习模型越来越多地用于辅助人类决策，为决策者提供相关输入来帮助他们决定如何将模型预测纳入决策过程，变得至关重要。例如，传达与模型预测相关的不确定性可能在这方面有所帮助。在本研究中，我们进行了用户研究（来自190个参与者的1,330个响应），系统评估了不同类型的预测不确定性（即不同形状和方差的后验预测分布），在预测公寓租金价格的机器学习辅助决策背景下，不同专业水平的人对此进行了如何响应。我们发现，展示后验预测分布可导致与机器学习模型的预测产生更小的分歧，无论我们考虑的后验预测分布的形状和方差如何，而且这些效果...

    As machine learning (ML) models are increasingly being employed to assist human decision makers, it becomes critical to provide these decision makers with relevant inputs which can help them decide if and how to incorporate model predictions into their decision making. For instance, communicating the uncertainty associated with model predictions could potentially be helpful in this regard. In this work, we carry out user studies (1,330 responses from 190 participants) to systematically assess how people with differing levels of expertise respond to different types of predictive uncertainty (i.e., posterior predictive distributions with different shapes and variances) in the context of ML assisted decision making for predicting apartment rental prices. We found that showing posterior predictive distributions led to smaller disagreements with the ML model's predictions, regardless of the shapes and variances of the posterior predictive distributions we considered, and that these effects 
    
[^191]: 基于内核的梯度下降算法的自适应停止准则

    Adaptive Stopping Rule for Kernel-based Gradient Descent Algorithms. (arXiv:2001.02879v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2001.02879](http://arxiv.org/abs/2001.02879)

    本文提出了一种自适应的内核梯度下降算法的停止准则，使用经验有效维度来量化增量并推导出可执行的提前停止策略。通过使用积分算子方法得出证明，规则具有优化学习速率的最优性，并且提出的停止策略具有计算上的优势。

    

    本文提出了基于内核的梯度下降算法的自适应停止准则。我们引入了经验有效维度来量化KGD迭代的增量并推导出可实施的提前停止策略。我们在学习理论框架下分析了自适应停止准则的性能。使用最近发展的积分算子方法，我们严格证明了配备此规则的KGD的最优学习速率的最优性。此外，我们还给出了配备所述提前停止规则的KGD的迭代次数的尖锐界限，以说明其计算优势。

    In this paper, we propose an adaptive stopping rule for kernel-based gradient descent (KGD) algorithms. We introduce the empirical effective dimension to quantify the increments of iterations in KGD and derive an implementable early stopping strategy. We analyze the performance of the adaptive stopping rule in the framework of learning theory. Using the recently developed integral operator approach, we rigorously prove the optimality of the adaptive stopping rule in terms of showing the optimal learning rates for KGD equipped with this rule. Furthermore, a sharp bound on the number of iterations in KGD equipped with the proposed early stopping rule is also given to demonstrate its computational advantage.
    
[^192]: 一种三元神经模型用于动态实体相关性排名

    A Trio Neural Model for Dynamic Entity Relatedness Ranking. (arXiv:1808.08316v4 [cs.IR] UPDATED)

    [http://arxiv.org/abs/1808.08316](http://arxiv.org/abs/1808.08316)

    这篇论文提出了一种基于神经网络的方法，通过动态评估实体相关性，利用集体注意作为监督，能学习到丰富而不同的实体表示，能在大规模数据集上比竞争基线获得更好的结果。

    

    测量实体相关性是许多自然语言处理和信息检索应用的基本任务。之前的研究通常在静态设置和非监督方式下研究实体相关性。然而，现实世界中的实体往往涉及许多不同的关系，因此实体关系随时间变得非常动态。在这项工作中，我们提出了一种基于神经网络的方法来动态评估实体相关性，利用集体注意力作为监督。我们的模型能够在联合框架中学习丰富而不同的实体表示。通过对大规模数据集的广泛实验，我们证明了我们的方法比竞争基线获得了更好的结果。

    Measuring entity relatedness is a fundamental task for many natural language processing and information retrieval applications. Prior work often studies entity relatedness in static settings and an unsupervised manner. However, entities in real-world are often involved in many different relationships, consequently entity-relations are very dynamic over time. In this work, we propose a neural networkbased approach for dynamic entity relatedness, leveraging the collective attention as supervision. Our model is capable of learning rich and different entity representations in a joint framework. Through extensive experiments on large-scale datasets, we demonstrate that our method achieves better results than competitive baselines.
    
[^193]: 推荐实体的时间因素的多模型方法

    Multiple Models for Recommending Temporal Aspects of Entities. (arXiv:1803.07890v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/1803.07890](http://arxiv.org/abs/1803.07890)

    本研究提出了一种新颖的基于事件中心的集合排名方法，该方法考虑到时间动态性，能够推荐最相关的实体方面，提高搜索体验。

    

    实体方面的推荐是语义搜索中的新兴任务，可以帮助用户发现与实体相关的巧合和突出信息，其中显着性（例如流行度）是以前工作中最重要的因素。但是，实体方面是具有时间动态性的，经常受到随时间发生的事件的影响。在这种情况下，仅基于显着性特征的方面建议可能会给出令人不满意的结果，原因有两个。首先，显着性通常在长时间段内累积，并且不考虑最近情况。其次，与事件实体相关的许多方面强烈依赖于时间。在本文中，我们研究了针对给定实体的时间方面推荐任务，旨在推荐最相关的方面，并考虑时间以提高搜索体验。我们提出了一种新颖的基于事件中心的集合排名方法，该方法从多个时间和类型依赖的模型中学习，并动态权衡显着性和最近情况。

    Entity aspect recommendation is an emerging task in semantic search that helps users discover serendipitous and prominent information with respect to an entity, of which salience (e.g., popularity) is the most important factor in previous work. However, entity aspects are temporally dynamic and often driven by events happening over time. For such cases, aspect suggestion based solely on salience features can give unsatisfactory results, for two reasons. First, salience is often accumulated over a long time period and does not account for recency. Second, many aspects related to an event entity are strongly time-dependent. In this paper, we study the task of temporal aspect recommendation for a given entity, which aims at recommending the most relevant aspects and takes into account time in order to improve search experience. We propose a novel event-centric ensemble ranking method that learns from multiple time and type-dependent models and dynamically trades off salience and recency c
    
[^194]: 多项式核回归的模型选择

    Model selection of polynomial kernel regression. (arXiv:1503.02143v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1503.02143](http://arxiv.org/abs/1503.02143)

    本文提出了一种新的模型选择策略，揭示了在多项式核回归中正则化项的作用只是为了规避核矩阵的“病态”，从而可选不加正则化项，并设计了一种有效的学习算法。

    

    多项式核回归是一种常用的和最先进的学习策略之一。然而，众所周知，在模型选择中，多项式核的次数和正则化参数的选择仍然是开放的问题。本文的第一个目标是开发一种策略来选择这些参数。一方面，基于最坏情况的学习速率分析，我们表明多项式核回归中的正则化项是不必要的；换句话说，当多项式核的次数适当调整时，正则化参数可以任意快地减小。另一方面，考虑到算法的实现，正则化项是必需的。综上所述，多项式核回归中正则化项的作用只是为了规避核矩阵的“病态”。本文的第二个目的是基于此提出一种新的模型选择策略，并设计一种有效的学习算法。

    Polynomial kernel regression is one of the standard and state-of-the-art learning strategies. However, as is well known, the choices of the degree of polynomial kernel and the regularization parameter are still open in the realm of model selection. The first aim of this paper is to develop a strategy to select these parameters. On one hand, based on the worst-case learning rate analysis, we show that the regularization term in polynomial kernel regression is not necessary. In other words, the regularization parameter can decrease arbitrarily fast when the degree of the polynomial kernel is suitable tuned. On the other hand,taking account of the implementation of the algorithm, the regularization term is required. Summarily, the effect of the regularization term in polynomial kernel regression is only to circumvent the " ill-condition" of the kernel matrix. Based on this, the second purpose of this paper is to propose a new model selection strategy, and then design an efficient learning
    
[^195]: $l^q$正则化学习的泛化性能是否依赖于$q$？一个否定的例子。

    Does generalization performance of $l^q$ regularization learning depend on $q$? A negative example. (arXiv:1307.6616v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1307.6616](http://arxiv.org/abs/1307.6616)

    该研究表明，在特定的核函数类中，$l^{q}$ 正则化学习在不同阶数 $q$ 下都具有相似的泛化误差界限。

    

    $l^q$-正则化已经被证明是机器学习和统计建模中一种有吸引力的技术。它通过适当缩小系数来提高机器（模型）的泛化（预测）能力。在不同的正则化阶数 $q$ 选择下，$l^q$ 估计器的形状不同。特别地，$l^1$ 导致 LASSO 估计，而 $l^{2}$ 对应于平滑的岭回归。这使得阶数 $q$ 成为应用中的一个潜在调参参数。为了促进 $l^{q}$-正则化的使用，我们打算寻找一种建模策略，可以避免在 $q$ 上进行精细的选择。在这样的精神下，我们将我们的研究置于一个样本相关假设空间（SDHS）下的 $l^{q}$-正则化核学习的一般框架中。对于一类指定的核函数，在 $0<q<\infty$ 的所有 $l^{q}$ 估计值都具有类似的泛化误差界限。这些估计边界是一个...

    $l^q$-regularization has been demonstrated to be an attractive technique in machine learning and statistical modeling. It attempts to improve the generalization (prediction) capability of a machine (model) through appropriately shrinking its coefficients. The shape of a $l^q$ estimator differs in varying choices of the regularization order $q$. In particular, $l^1$ leads to the LASSO estimate, while $l^{2}$ corresponds to the smooth ridge regression. This makes the order $q$ a potential tuning parameter in applications. To facilitate the use of $l^{q}$-regularization, we intend to seek for a modeling strategy where an elaborative selection on $q$ is avoidable. In this spirit, we place our investigation within a general framework of $l^{q}$-regularized kernel learning under a sample dependent hypothesis space (SDHS). For a designated class of kernel functions, we show that all $l^{q}$ estimators for $0< q < \infty$ attain similar generalization error bounds. These estimated bounds are a
    

