# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models](https://arxiv.org/abs/2404.01318) | JailbreakBench是一个用于对抗大型语言模型越狱的开放基准，提供新的数据集、对抗提示和评估框架。 |
| [^2] | [Aurora-M: The First Open Source Multilingual Language Model Red-teamed according to the U.S. Executive Order](https://arxiv.org/abs/2404.00399) | Aurora-M 是第一个根据美国行政命令进行红队测试的开源多语言模型，通过在英语、芬兰语、印地语、日语、越南语和代码上训练，不断预训练，包括了人工审核的安全说明，总训练 token 数超过 2 万亿个 |
| [^3] | [Convergence of a model-free entropy-regularized inverse reinforcement learning algorithm](https://arxiv.org/abs/2403.16829) | 提出一个无模型的算法来解决熵正则化的逆强化学习问题，该算法能够使用有限样本恢复出专家表现最佳的奖励，并且最终得到的最优策略与专家策略非常接近。 |
| [^4] | [Non-negative Contrastive Learning](https://arxiv.org/abs/2403.12459) | 非负对比学习(NCL)是对非负矩阵分解(NMF)的重新演绎，通过对特征施加非负约束来获得可解释的特征，保留了NMF的可解释属性，从而得到比标准对比学习(CL)更稀疏和解耦的表示 |
| [^5] | [Improving Dialogue Agents by Decomposing One Global Explicit Annotation with Local Implicit Multimodal Feedback](https://arxiv.org/abs/2403.11330) | 通过将全局明确标注拆解成本地隐式多模态反馈，提出了一种改进对话代理的方法，并在各种对话度量方面展现出一致的改进 |
| [^6] | [Adaptive Hybrid Masking Strategy for Privacy-Preserving Face Recognition Against Model Inversion Attack](https://arxiv.org/abs/2403.10558) | 本文提出了一种针对模型反演攻击的自适应混合遮盖算法，通过在频域中使用MixUp策略对人脸图像进行遮盖，以在隐私保护和准确性之间取得平衡。 |
| [^7] | [DAM: Dynamic Adapter Merging for Continual Video QA Learning](https://arxiv.org/abs/2403.08755) | 提出了一种用于持续视频问答学习的动态适配器合并方法DAM，能够减轻灾难性遗忘、有效适应不断到来的数据集、处理未知数据集输入，并允许在类似数据集领域之间共享知识。 |
| [^8] | [PaddingFlow: Improving Normalizing Flows with Padding-Dimensional Noise](https://arxiv.org/abs/2403.08216) | 提出了一种名为PaddingFlow的去量化方法，利用填充维度噪声改进了正规化流，解决了基于流的模型在流形和离散数据上的性能问题。 |
| [^9] | [$\widetilde{O}(T^{-1})$ Convergence to (Coarse) Correlated Equilibria in Full-Information General-Sum Markov Games](https://arxiv.org/abs/2403.07890) | 本研究通过使用乐观的前瞻性领导者算法（OFTRL）和适当的数值更新程序，在全信息一般和马尔可夫博弈中找到了$\widetilde{O}(T^{-1})$-approximate（粗糙）相关均衡，这在$T$次迭代内得以实现。 |
| [^10] | [The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning](https://arxiv.org/abs/2403.03218) | WMDP基准是一个公开发布的数据集，包含4157个多项选择问题，用作生物安全、网络安全和化学安全危险知识的代理测量。 |
| [^11] | [NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models](https://arxiv.org/abs/2403.03100) | NaturalSpeech 3利用分解设计的扩散模型实现零-shot方式生成自然语音 |
| [^12] | [Neural Graph Generator: Feature-Conditioned Graph Generation using Latent Diffusion Models](https://arxiv.org/abs/2403.01535) | NGG是一个神经图生成器，通过潜在扩散模型实现了特征条件图生成，具有模拟复杂图模式和控制图生成过程的显著能力。 |
| [^13] | [An Integrated Data Processing Framework for Pretraining Foundation Models](https://arxiv.org/abs/2402.16358) | 提出了一个集成了处理模块和分析模块的数据处理框架，旨在改善数据质量并展示其有效性。 |
| [^14] | [Seeing is Believing: Mitigating Hallucination in Large Vision-Language Models via CLIP-Guided Decoding](https://arxiv.org/abs/2402.15300) | CLIP相似性作为更强大和更稳健的幻觉指标，研究提出了CLIP引导解码（CGD）方法，在大型视觉-语言模型中有效减少对象幻觉。 |
| [^15] | [FlashTex: Fast Relightable Mesh Texturing with LightControlNet](https://arxiv.org/abs/2402.13251) | 提出了FlashTex方法，基于LightControlNet实现了快速自动化3D网格纹理生成，实现了照明与表面材质的解耦，使得网格能够在任何照明环境下正确重照和渲染 |
| [^16] | [MPIrigen: MPI Code Generation through Domain-Specific Language Models](https://arxiv.org/abs/2402.09126) | 本文研究了使用领域特定语言模型生成MPI代码的性能，并提出了使用预训练模型MonoCoder进行MPI-based程序生成的方法。 |
| [^17] | [GenSTL: General Sparse Trajectory Learning via Auto-regressive Generation of Feature Domains](https://arxiv.org/abs/2402.07232) | GenSTL是一个通用的稀疏轨迹学习框架，通过自回归生成特征域来实现稀疏轨迹与密集轨迹之间的连接，从而消除了对大规模密集轨迹数据的依赖。 |
| [^18] | [Return-Aligned Decision Transformer](https://arxiv.org/abs/2402.03923) | 本研究提出了返回对齐的决策Transformer（RADT），通过分离回报与传统输入序列，实现有效地将实际回报与目标回报对齐。 |
| [^19] | [Few-Shot Scenario Testing for Autonomous Vehicles Based on Neighborhood Coverage and Similarity](https://arxiv.org/abs/2402.01795) | 本文提出了一个基于邻域覆盖和相似性的少样本场景测试框架，用于解决大规模部署之前自动驾驶车辆测试和评估中的不确定性和挑战。 |
| [^20] | [SWEA: Changing Factual Knowledge in Large Language Models via Subject Word Embedding Altering](https://arxiv.org/abs/2401.17809) | 提出了一种主题词嵌入修改框架（SWEA），通过在推理阶段修改主题的表示来编辑知识，保护模型的原始权重，避免不可逆的损害和额外的推理开销。 |
| [^21] | [Data-Driven Target Localization: Benchmarking Gradient Descent Using the Cram\'er-Rao Bound.](http://arxiv.org/abs/2401.11176) | 本研究提出了一种数据驱动的神经网络方法，通过降低均方误差（MSE）实现了改进的目标方位和速度估计。这一发现强调了在雷达系统中采用深度学习方法的潜力，为在杂乱和动态环境中更准确的定位铺平了道路。 |
| [^22] | [PPNet: A Novel Neural Network Structure for End-to-End Near-Optimal Path Planning.](http://arxiv.org/abs/2401.09819) | PPNet是一种新颖的神经网络结构，用于解决端到端近似最优路径规划问题。通过将路径规划问题分为两个子问题，并使用两级级联神经网络进行求解，同时引入了一种高效的数据生成方法EDaGe-PP。实验结果表明，PPNet在计算时间和成功率方面比其他方法有显著提升。 |
| [^23] | [Are All Unseen Data Out-of-Distribution?.](http://arxiv.org/abs/2312.16243) | 该论文研究了未见数据的分布在泛化中的挑战，并提出了重新定义OoD数据以及新的泛化上界，保证了对未见数据的模型有效性。 |
| [^24] | [Imputation using training labels and classification via label imputation.](http://arxiv.org/abs/2311.16877) | 本论文提出一种在填充缺失数据时将标签与输入堆叠的方法，能够显著提高填充效果，并同时填充标签和输入。该方法适用于各种类型的数据，且在实验证明具有有希望的准确性结果。 |
| [^25] | [Solutions to Elliptic and Parabolic Problems via Finite Difference Based Unsupervised Small Linear Convolutional Neural Networks.](http://arxiv.org/abs/2311.00259) | 通过无监督学习，我们提出了利用小型卷积神经网络直接估计椭圆和抛物型问题的有限差分解，相比传统方法具有可比较的准确性。 |
| [^26] | [Improving Intrinsic Exploration by Creating Stationary Objectives.](http://arxiv.org/abs/2310.18144) | 该论文提出了一个新的方法：通过创建固定目标，将原始的非固定奖励转化为固定奖励，从而改善了强化学习中的内在探索。 |
| [^27] | [HeaP: Hierarchical Policies for Web Actions using LLMs.](http://arxiv.org/abs/2310.03720) | 这篇论文介绍了一个名为HeaP的框架，利用大型语言模型（LLMs）来解决Web任务的挑战。该框架将Web任务分解为子任务，并通过一系列低级的策略来执行，相比其他基准方法，该框架在不同的Web任务上表现出更好的性能。 |
| [^28] | [Latent Space Symmetry Discovery.](http://arxiv.org/abs/2310.00105) | 提出了一种新的生成模型——潜空间LieGAN（LaLiGAN），可以从数据中发现非线性对称性，并产生结构良好的潜空间，对其他下游任务非常有用。 |
| [^29] | [Neuro-Inspired Hierarchical Multimodal Learning.](http://arxiv.org/abs/2309.15877) | 这项研究提出了一种神经启发的分层多模态学习方法，利用信息瓶颈理论构建了一种有效且紧凑的信息流，实现了对真实世界的全面和准确的感知。 |
| [^30] | [Masked Transformer for Electrocardiogram Classification.](http://arxiv.org/abs/2309.07136) | 提出了一种基于掩码Transformer的ECG分类方法，命名为MTECG，扩展了掩码自动编码器在ECG时间序列上的应用，该方法在广泛的掩码比例下表现稳定良好，并进行了消融实验验证了重构目标的波动性、训练计划长度、逐层学习率衰减和DropPath率的重要性。 |
| [^31] | [Mixtures of Gaussians are Privately Learnable with a Polynomial Number of Samples.](http://arxiv.org/abs/2309.03847) | 通过多项式数量的样本和差分隐私约束，我们提出了一个可以估计高斯混合物的方法，并证明了这个方法的有效性，而无需对GMMs做任何结构性假设。 |
| [^32] | [R2D2: Deep neural network series for near real-time high-dynamic range imaging in radio astronomy.](http://arxiv.org/abs/2309.03291) | R2D2是用于射电天文中高动态范围成像的深度神经网络系列，采用模型驱动方法和数据一致性更新，重建为一系列残差图像，可用于高分辨率强度成像。 |
| [^33] | [Image Hijacking: Adversarial Images can Control Generative Models at Runtime.](http://arxiv.org/abs/2309.00236) | 本研究发现对抗性图像能够在运行时控制生成模型，并提出了通用的方法来创建图像劫持。通过研究三种攻击类型，我们发现这些攻击对最新的视觉语言模型具有高达90％以上的成功率。该研究引发了对基础模型安全性的严重担忧。 |
| [^34] | [Linear Convergence of Black-Box Variational Inference: Should We Stick the Landing?.](http://arxiv.org/abs/2307.14642) | 本文证明了带有控制变量的黑盒变分推断在完美变分族规范下以几何速度收敛，为BBVI提供了收敛性保证，同时提出了对熵梯度估计器的改进，对比了STL估计器，并给出了明确的非渐近复杂度保证。 |
| [^35] | [MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training.](http://arxiv.org/abs/2306.00107) | 提出了一个带有大规模自监督训练的音乐理解模型MERT，利用了教师模型并采用了一种优于传统的语音和音频方法的组合方式。 |
| [^36] | [Non-Parametric Learning of Stochastic Differential Equations with Fast Rates of Convergence.](http://arxiv.org/abs/2305.15557) | 提出了一种新的非参数方法，用于识别随机微分方程中的漂移和扩散系数，该方法具有快速的收敛率，使得学习速率随着未知系数的光滑度增加而变得更加紧密。 |
| [^37] | [Differentiating Viral and Bacterial Infections: A Machine Learning Model Based on Routine Blood Test Values.](http://arxiv.org/abs/2305.07877) | 本研究开发了一种基于血液检查数值的病毒与细菌机器学习模型，用于准确识别感染类型。该模型在CRP水平10-40 mg/L范围内表现出更好的区分细菌和病毒感染的准确性，证明了多种血液参数对于诊断决策的重要性。 |
| [^38] | [Specification-Driven Neural Network Reduction for Scalable Formal Verification.](http://arxiv.org/abs/2305.01932) | 本文提出了一种基于规范的神经网络简化方法用于大规模形式化验证。该方法采用保守的简化方法，确保简化后的网络验证与原网络验证派生等价。简化后可将网络减少到小于5％的神经元数量，从而减少了相应的验证时间。 |
| [^39] | [A Majorization-Minimization Gauss-Newton Method for 1-Bit Matrix Completion.](http://arxiv.org/abs/2304.13940) | 本文提出了一种基于主导-最小化原则，通过低秩矩阵补全解决1比特矩阵补全问题的新方法，称为MMGN。通过应用高斯-牛顿方法，MMGN具有更快的速度和更准确的结果，同时还不太受到潜在矩阵尖锐度的影响。 |
| [^40] | [Linear Optimal Partial Transport Embedding.](http://arxiv.org/abs/2302.03232) | 本文提出了线性最优偏移嵌入技术（LOPT），它扩展了（局部）线性化技术到OPT问题上，提高了正测度对之间的计算速度。并且在点云内插和PCA分析中进行了应用。 |
| [^41] | [Differentially-Private Data Synthetisation for Efficient Re-Identification Risk Control.](http://arxiv.org/abs/2212.00484) | 本文提出了一种名为ε-PrivateSMOTE的技术，通过噪声引入插值的合成数据生成，以达到保护免受重新识别和链接攻击的风险的目的，并在同时最大限度地保持数据效用的情况下取得了竞争性的结果。 |
| [^42] | [Explicit Second-Order Min-Max Optimization Methods with Optimal Convergence Guarantee.](http://arxiv.org/abs/2210.12860) | 本文提出了一种具有最优收敛保证的显式二阶最小最大优化方法，用于解决凸凹无约束最小最大优化问题。该方法利用二阶信息加速额外梯度方法，并且在迭代过程中保持在有界集内，达到了与理论下界相匹配的收敛速度。 |

# 详细

[^1]: JailbreakBench: 一个用于对抗大型语言模型越狱的开放鲁棒性基准

    JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models

    [https://arxiv.org/abs/2404.01318](https://arxiv.org/abs/2404.01318)

    JailbreakBench是一个用于对抗大型语言模型越狱的开放基准，提供新的数据集、对抗提示和评估框架。

    

    越狱攻击会导致大型语言模型生成有害、不道德或令人反感的内容。评估这些攻击存在许多挑战，当前的基准和评估技术并未充分解决。为了解决这些挑战，我们引入了JailbreakBench，一个开源基准，包括具有100个独特行为的新越狱数据集（称为JBB-Behaviors）、一组最先进的对抗提示（称为越狱工件）和一个标准化评估框架。

    arXiv:2404.01318v1 Announce Type: cross  Abstract: Jailbreak attacks cause large language models (LLMs) to generate harmful, unethical, or otherwise objectionable content. Evaluating these attacks presents a number of challenges, which the current collection of benchmarks and evaluation techniques do not adequately address. First, there is no clear standard of practice regarding jailbreaking evaluation. Second, existing works compute costs and success rates in incomparable ways. And third, numerous works are not reproducible, as they withhold adversarial prompts, involve closed-source code, or rely on evolving proprietary APIs. To address these challenges, we introduce JailbreakBench, an open-sourced benchmark with the following components: (1) a new jailbreaking dataset containing 100 unique behaviors, which we call JBB-Behaviors; (2) an evolving repository of state-of-the-art adversarial prompts, which we refer to as jailbreak artifacts; (3) a standardized evaluation framework that i
    
[^2]: Aurora-M: 根据美国行政命令，第一个开源的多语言语言模型进行了红队测试

    Aurora-M: The First Open Source Multilingual Language Model Red-teamed according to the U.S. Executive Order

    [https://arxiv.org/abs/2404.00399](https://arxiv.org/abs/2404.00399)

    Aurora-M 是第一个根据美国行政命令进行红队测试的开源多语言模型，通过在英语、芬兰语、印地语、日语、越南语和代码上训练，不断预训练，包括了人工审核的安全说明，总训练 token 数超过 2 万亿个

    

    预训练语言模型支持多种人工智能应用，但是它们在训练时高昂的计算成本限制了可访问性。BLOOM 和 StarCoder 等倡议旨在使预训练模型对于协作社区开发更具民主性。然而，目前存在的模型面临一些挑战：多语言能力有限，持续的预训练会导致灾难性遗忘，而从头开始预训练又具有高昂的计算成本，并且需要遵守人工智能安全和发展法律。本文介绍了 Aurora-M，一个包含 15B 参数的多语言开源模型，训练语言包括英语、芬兰语、印地语、日语、越南语和代码。Aurora-M 不断从 StarCoderPlus 上预训练，额外训练了 4350 亿个 token，总训练 token 数超过了 2 万亿个。它是第一个在人工审核的安全说明上进行微调的开源多语言模型，使其开发与传统

    arXiv:2404.00399v1 Announce Type: cross  Abstract: Pretrained language models underpin several AI applications, but their high computational cost for training limits accessibility. Initiatives such as BLOOM and StarCoder aim to democratize access to pretrained models for collaborative community development. However, such existing models face challenges: limited multilingual capabilities, continual pretraining causing catastrophic forgetting, whereas pretraining from scratch is computationally expensive, and compliance with AI safety and development laws. This paper presents Aurora-M, a 15B parameter multilingual open-source model trained on English, Finnish, Hindi, Japanese, Vietnamese, and code. Continually pretrained from StarCoderPlus on 435 billion additional tokens, Aurora-M surpasses 2 trillion tokens in total training token count. It is the first open-source multilingual model fine-tuned on human-reviewed safety instructions, thus aligning its development not only with conventio
    
[^3]: 一个无模型的熵正则化逆强化学习算法的收敛性

    Convergence of a model-free entropy-regularized inverse reinforcement learning algorithm

    [https://arxiv.org/abs/2403.16829](https://arxiv.org/abs/2403.16829)

    提出一个无模型的算法来解决熵正则化的逆强化学习问题，该算法能够使用有限样本恢复出专家表现最佳的奖励，并且最终得到的最优策略与专家策略非常接近。

    

    在给定一组专家演示数据集的情况下，逆强化学习旨在恢复一个专家表现最佳的奖励。本文提出了一个无模型的算法来解决熵正则化逆强化学习问题。具体而言，我们采用随机梯度下降更新奖励，采用随机软策略迭代更新策略。假设可以访问一个生成模型，我们证明了我们的算法能够保证使用$\mathcal{O}(1/\varepsilon^{2})$个马尔可夫决策过程（MDP）样本恢复出一个使专家表现最佳的奖励。此外，通过$\mathcal{O}(1/\varepsilon^{4})$个样本，我们证明了与恢复奖励对应的最优策略在总变差距离上与专家策略$\varepsilon$-接近。

    arXiv:2403.16829v1 Announce Type: cross  Abstract: Given a dataset of expert demonstrations, inverse reinforcement learning (IRL) aims to recover a reward for which the expert is optimal. This work proposes a model-free algorithm to solve entropy-regularized IRL problem. In particular, we employ a stochastic gradient descent update for the reward and a stochastic soft policy iteration update for the policy. Assuming access to a generative model, we prove that our algorithm is guaranteed to recover a reward for which the expert is $\varepsilon$-optimal using $\mathcal{O}(1/\varepsilon^{2})$ samples of the Markov decision process (MDP). Furthermore, with $\mathcal{O}(1/\varepsilon^{4})$ samples we prove that the optimal policy corresponding to the recovered reward is $\varepsilon$-close to the expert policy in total variation distance.
    
[^4]: 非负对比学习

    Non-negative Contrastive Learning

    [https://arxiv.org/abs/2403.12459](https://arxiv.org/abs/2403.12459)

    非负对比学习(NCL)是对非负矩阵分解(NMF)的重新演绎，通过对特征施加非负约束来获得可解释的特征，保留了NMF的可解释属性，从而得到比标准对比学习(CL)更稀疏和解耦的表示

    

    深度表示在以黑盒方式转移到下游任务时表现出了良好的性能。然而，它们固有的不可解释性仍然是一个重大挑战，因为这些特征通常对人类理解而言是不透明的。在本文中，我们提出了非负对比学习（NCL），这是对非负矩阵分解（NMF）的复兴，旨在得出可解释的特征。NCL的力量在于强制将非负约束应用于特征，这让人想起NMF能够提取与样本集群紧密对齐的特征的能力。NCL不仅在数学上与NMF目标很好地对齐，而且保留了NMF的可解释属性，使得与标准对比学习（CL）相比，得到了更加稀疏和解耦的表示。从理论上，我们为NCL的可识别性和下游泛化性能提供了保证。从经验上看，我们展示了这些

    arXiv:2403.12459v1 Announce Type: cross  Abstract: Deep representations have shown promising performance when transferred to downstream tasks in a black-box manner. Yet, their inherent lack of interpretability remains a significant challenge, as these features are often opaque to human understanding. In this paper, we propose Non-negative Contrastive Learning (NCL), a renaissance of Non-negative Matrix Factorization (NMF) aimed at deriving interpretable features. The power of NCL lies in its enforcement of non-negativity constraints on features, reminiscent of NMF's capability to extract features that align closely with sample clusters. NCL not only aligns mathematically well with an NMF objective but also preserves NMF's interpretability attributes, resulting in a more sparse and disentangled representation compared to standard contrastive learning (CL). Theoretically, we establish guarantees on the identifiability and downstream generalization of NCL. Empirically, we show that these 
    
[^5]: 通过将一个全局明确标注拆解成本地隐式多模态反馈来改进对话代理

    Improving Dialogue Agents by Decomposing One Global Explicit Annotation with Local Implicit Multimodal Feedback

    [https://arxiv.org/abs/2403.11330](https://arxiv.org/abs/2403.11330)

    通过将全局明确标注拆解成本地隐式多模态反馈，提出了一种改进对话代理的方法，并在各种对话度量方面展现出一致的改进

    

    我们描述了一种方法，通过全局（即，对话级）奖励对齐基于LLM的对话代理，同时考虑到自然发生的多模态信号。在高层次上，我们的方法（名为GELI）通过将人类提供的全局明确（GE）会话级奖励拆分，利用本地隐式（LI）多模态奖励信号来跨模态地塑造奖励分解步骤。然后将这种分解的奖励模型作为标准RHLF流程的一部分，来改进基于LLM的对话代理。我们进行了定量和定性的人类研究，评估了我们的GELI方法的性能，并发现与基线方法相比，它在各种对话度量方面都表现出一致的改进。

    arXiv:2403.11330v1 Announce Type: cross  Abstract: We describe an approach for aligning an LLM-based dialogue agent based on global (i.e., dialogue-level) rewards, while also taking into account naturally-occurring multimodal signals. At a high level, our approach (dubbed GELI) learns a local, turn-level reward model by decomposing the human-provided Global Explicit (GE) session-level reward, using Local Implicit (LI} multimodal reward signals to crossmodally shape the reward decomposition step. This decomposed reward model is then used as part of the standard RHLF pipeline improve an LLM-based dialog agent. We run quantitative and qualitative human studies to evaluate the performance of our GELI approach, and find that it shows consistent improvements across various conversational metrics compared to baseline methods.
    
[^6]: 针对模型反演攻击的隐私保护人脸识别自适应混合遮盖策略

    Adaptive Hybrid Masking Strategy for Privacy-Preserving Face Recognition Against Model Inversion Attack

    [https://arxiv.org/abs/2403.10558](https://arxiv.org/abs/2403.10558)

    本文提出了一种针对模型反演攻击的自适应混合遮盖算法，通过在频域中使用MixUp策略对人脸图像进行遮盖，以在隐私保护和准确性之间取得平衡。

    

    arXiv:2403.10558v1 公告类型: 跨领域 摘要: 在训练人脸识别（FR）模型中利用个人敏感数据存在重大的隐私问题，因为对手可以利用模型反演攻击（MIA）推断出原始训练数据。现有的防御方法，如数据增强和差分隐私，已被用来减轻这一问题。然而，这些方法往往无法在隐私和准确性之间达到最佳平衡。为解决这一局限性，本文介绍了一种针对MIA的自适应混合遮盖算法。具体地，在频域中使用自适应的MixUp策略对人脸图像进行遮盖。与主要用于数据增强的传统MixUp算法不同，我们修改的方法融合了频域混合。先前的研究表明，增加MixUp中混合的图像数量可以增强隐私保护，但会降低人脸识别的准确性。为了解决这一问题，

    arXiv:2403.10558v1 Announce Type: cross  Abstract: The utilization of personal sensitive data in training face recognition (FR) models poses significant privacy concerns, as adversaries can employ model inversion attacks (MIA) to infer the original training data. Existing defense methods, such as data augmentation and differential privacy, have been employed to mitigate this issue. However, these methods often fail to strike an optimal balance between privacy and accuracy. To address this limitation, this paper introduces an adaptive hybrid masking algorithm against MIA. Specifically, face images are masked in the frequency domain using an adaptive MixUp strategy. Unlike the traditional MixUp algorithm, which is predominantly used for data augmentation, our modified approach incorporates frequency domain mixing. Previous studies have shown that increasing the number of images mixed in MixUp can enhance privacy preservation but at the expense of reduced face recognition accuracy. To ove
    
[^7]: DAM:用于持续视频问答学习的动态适配器合并

    DAM: Dynamic Adapter Merging for Continual Video QA Learning

    [https://arxiv.org/abs/2403.08755](https://arxiv.org/abs/2403.08755)

    提出了一种用于持续视频问答学习的动态适配器合并方法DAM，能够减轻灾难性遗忘、有效适应不断到来的数据集、处理未知数据集输入，并允许在类似数据集领域之间共享知识。

    

    我们提出了一种参数高效的方法，用于持续视频问答（VidQA）学习。我们的方法名为DAM，使用所提出的动态适配器合并来（i）减轻灾难性遗忘，（ii）实现对持续到达的数据集的高效适应，（iii）在推理过程中处理来自未知数据集的输入，（iv）实现跨相似数据集领域的知识共享。在给定一组持续流式传输的VidQA数据集的情况下，我们为每个数据集顺序训练特定于数据集的适配器，同时冻结大型预训练视频语言骨干的参数。在推理过程中，给定来自未知领域的视频问题示例，我们的方法首先使用所提出的非参数路由器函数计算每个适配器的概率，反映出该适配器与当前视频问题输入实例的相关性。随后，所提出的动态适配器合并方案聚合所有适配器权重。

    arXiv:2403.08755v1 Announce Type: cross  Abstract: We present a parameter-efficient method for continual video question-answering (VidQA) learning. Our method, named DAM, uses the proposed Dynamic Adapter Merging to (i) mitigate catastrophic forgetting, (ii) enable efficient adaptation to continually arriving datasets, (iii) handle inputs from unknown datasets during inference, and (iv) enable knowledge sharing across similar dataset domains. Given a set of continually streaming VidQA datasets, we sequentially train dataset-specific adapters for each dataset while freezing the parameters of a large pretrained video-language backbone. During inference, given a video-question sample from an unknown domain, our method first uses the proposed non-parametric router function to compute a probability for each adapter, reflecting how relevant that adapter is to the current video-question input instance. Subsequently, the proposed dynamic adapter merging scheme aggregates all the adapter weight
    
[^8]: PaddingFlow：利用填充维度噪声改进归一化流

    PaddingFlow: Improving Normalizing Flows with Padding-Dimensional Noise

    [https://arxiv.org/abs/2403.08216](https://arxiv.org/abs/2403.08216)

    提出了一种名为PaddingFlow的去量化方法，利用填充维度噪声改进了正规化流，解决了基于流的模型在流形和离散数据上的性能问题。

    

    正规化流是一种具有高效采样的生成建模方法。然而，基于流的模型存在两个问题，即流形和离散数据。 如果目标分布是一个流形，也就是说潜在目标分布的维度和数据分布的维度不匹配，基于流的模型可能表现不佳。离散数据会导致基于流的模型坍缩为退化的点质量混合。 为了规避这两个问题，本文提出了PaddingFlow，一种新颖的去量化方法，利用填充维度噪声改进了正规化流。PaddingFlow易于实现、计算廉价、广泛适用于各种任务，并生成无偏估计的数据样本。特别是，我们的方法可以克服现有去量化方法的局限性，而这些方法必须改变数据分布，可能会降低性能。我们验证了我们的方法

    arXiv:2403.08216v1 Announce Type: new  Abstract: Normalizing flow is a generative modeling approach with efficient sampling. However, Flow-based models suffer two issues, which are manifold and discrete data. If the target distribution is a manifold, which means the dimension of the latent target distribution and the dimension of the data distribution are unmatched, flow-based models might perform badly. Discrete data makes flow-based models collapse into a degenerate mixture of point masses. In this paper, to sidestep such two issues we propose PaddingFlow, a novel dequantization method, which improves normalizing flows with padding-dimensional noise. PaddingFlow is easy to implement, computationally cheap, widely suitable for various tasks, and generates samples that are unbiased estimations of the data. Especially, our method can overcome the limitation of existing dequantization methods that have to change the data distribution, which might degrade performance. We validate our meth
    
[^9]: $\widetilde{O}(T^{-1})$ 收敛到（粗糙）相关均衡在全信息一般和马尔可夫博弈中的问题

    $\widetilde{O}(T^{-1})$ Convergence to (Coarse) Correlated Equilibria in Full-Information General-Sum Markov Games

    [https://arxiv.org/abs/2403.07890](https://arxiv.org/abs/2403.07890)

    本研究通过使用乐观的前瞻性领导者算法（OFTRL）和适当的数值更新程序，在全信息一般和马尔可夫博弈中找到了$\widetilde{O}(T^{-1})$-approximate（粗糙）相关均衡，这在$T$次迭代内得以实现。

    

    No-regret学习与博弈论密切相关，最近的研究提出了非耦合的无悔学习动态，当所有玩家在正则形式游戏中采用时，以$\widetilde{O}(T^{-1})$的接近最优速率收敛到各种均衡解，这显着改进了经典无悔学习者的$O(1/\sqrt{T})$速率。然而，在马尔可夫博弈中类似的收敛结果很少见，这是一个更通用的设置，为多智能体强化学习奠定了基础。在这项工作中，我们通过展示乐观的前瞻性领导者算法（OFTRL），连同适当的数值更新程序，可以在$T$次迭代内找到全信息一般和马尔可夫博弈中的$\widetilde{O}(T^{-1})$近似（粗糙）相关均衡。数值结果也包括以证实我们的理论发现。

    arXiv:2403.07890v1 Announce Type: cross  Abstract: No-regret learning has a long history of being closely connected to game theory. Recent works have devised uncoupled no-regret learning dynamics that, when adopted by all the players in normal-form games, converge to various equilibrium solutions at a near-optimal rate of $\widetilde{O}(T^{-1})$, a significant improvement over the $O(1/\sqrt{T})$ rate of classic no-regret learners. However, analogous convergence results are scarce in Markov games, a more generic setting that lays the foundation for multi-agent reinforcement learning. In this work, we close this gap by showing that the optimistic-follow-the-regularized-leader (OFTRL) algorithm, together with appropriate value update procedures, can find $\widetilde{O}(T^{-1})$-approximate (coarse) correlated equilibria in full-information general-sum Markov games within $T$ iterations. Numerical results are also included to corroborate our theoretical findings.
    
[^10]: WMDP基准：通过遗忘测量和减少恶意使用

    The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning

    [https://arxiv.org/abs/2403.03218](https://arxiv.org/abs/2403.03218)

    WMDP基准是一个公开发布的数据集，包含4157个多项选择问题，用作生物安全、网络安全和化学安全危险知识的代理测量。

    

    arXiv:2403.03218v1 公告类型：交叉领域 摘要：白宫关于人工智能的行政命令强调了大型语言模型(LLMs)赋予恶意行为者开发生物、网络和化学武器的风险。为了衡量这些恶意使用的风险，政府机构和主要人工智能实验室正在开发LLMs的危险能力评估。然而，当前的评估是私人的，阻碍了进一步研究如何减少风险。此外，它们仅专注于几条高度特定的恶意使用途径。为了填补这些空白，我们公开发布了大规模杀伤性武器代理（WMDP）基准，这是一个包含4157个多项选择问题的数据集，作为生物安全、网络安全和化学安全危险知识的代理测量。WMDP由一组学术界和技术顾问联合开发，并在公开发布前严格过滤以消除敏感信息。WMDP有两个服务

    arXiv:2403.03218v1 Announce Type: cross  Abstract: The White House Executive Order on Artificial Intelligence highlights the risks of large language models (LLMs) empowering malicious actors in developing biological, cyber, and chemical weapons. To measure these risks of malicious use, government institutions and major AI labs are developing evaluations for hazardous capabilities in LLMs. However, current evaluations are private, preventing further research into mitigating risk. Furthermore, they focus on only a few, highly specific pathways for malicious use. To fill these gaps, we publicly release the Weapons of Mass Destruction Proxy (WMDP) benchmark, a dataset of 4,157 multiple-choice questions that serve as a proxy measurement of hazardous knowledge in biosecurity, cybersecurity, and chemical security. WMDP was developed by a consortium of academics and technical consultants, and was stringently filtered to eliminate sensitive information prior to public release. WMDP serves two r
    
[^11]: NaturalSpeech 3: 利用分解编解码器和扩散模型实现零-shot语音合成

    NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models

    [https://arxiv.org/abs/2403.03100](https://arxiv.org/abs/2403.03100)

    NaturalSpeech 3利用分解设计的扩散模型实现零-shot方式生成自然语音

    

    近期大规模文本到语音（TTS）模型取得了显著进展，然而在语音质量、相似度和韵律方面仍存在不足。鉴于语音复杂地包含各种属性（例如内容、韵律、音色和声学细节），给生成带来了重大挑战，一个自然的想法是将语音因子分解为代表不同属性的各个子空间，并单独生成它们。在此基础上，我们提出了NaturalSpeech 3，这是一个具有新颖的分解扩散模型的TTS系统，可以以零-shot方式生成自然语音。具体来说，1) 我们设计了一个具有分解向量量化（FVQ）的神经编解码器，将语音波形分解为内容、韵律、音色和声学细节的子空间；2) 我们提出了一个分解扩散模型，根据其相应的提示生成每个子空间中的属性。借助这种分解设计，NaturalSpeech 3能够ef

    arXiv:2403.03100v1 Announce Type: cross  Abstract: While recent large-scale text-to-speech (TTS) models have achieved significant progress, they still fall short in speech quality, similarity, and prosody. Considering speech intricately encompasses various attributes (e.g., content, prosody, timbre, and acoustic details) that pose significant challenges for generation, a natural idea is to factorize speech into individual subspaces representing different attributes and generate them individually. Motivated by it, we propose NaturalSpeech 3, a TTS system with novel factorized diffusion models to generate natural speech in a zero-shot way. Specifically, 1) we design a neural codec with factorized vector quantization (FVQ) to disentangle speech waveform into subspaces of content, prosody, timbre, and acoustic details; 2) we propose a factorized diffusion model to generate attributes in each subspace following its corresponding prompt. With this factorization design, NaturalSpeech 3 can ef
    
[^12]: 神经图生成器：使用潜在扩散模型的特征条件图生成

    Neural Graph Generator: Feature-Conditioned Graph Generation using Latent Diffusion Models

    [https://arxiv.org/abs/2403.01535](https://arxiv.org/abs/2403.01535)

    NGG是一个神经图生成器，通过潜在扩散模型实现了特征条件图生成，具有模拟复杂图模式和控制图生成过程的显著能力。

    

    图生成已经成为机器学习中的一个关键任务，面临着生成能够准确反映特定属性的图形的重大挑战。本文介绍了神经图生成器（NGG）这一新颖方法，它利用条件潜在扩散模型进行图生成。NGG展示了对复杂图模式进行建模的显著能力，提供了对图生成过程的控制。NGG利用变分图自动编码器进行图压缩，利用在潜在向量空间中的扩散过程，由总结图统计信息的向量指导。我们展示了NGG在各种图生成任务中的通用性，展示了其捕捉期望图属性并推广到未见图形的能力。

    arXiv:2403.01535v1 Announce Type: new  Abstract: Graph generation has emerged as a crucial task in machine learning, with significant challenges in generating graphs that accurately reflect specific properties. Existing methods often fall short in efficiently addressing this need as they struggle with the high-dimensional complexity and varied nature of graph properties. In this paper, we introduce the Neural Graph Generator (NGG), a novel approach which utilizes conditioned latent diffusion models for graph generation. NGG demonstrates a remarkable capacity to model complex graph patterns, offering control over the graph generation process. NGG employs a variational graph autoencoder for graph compression and a diffusion process in the latent vector space, guided by vectors summarizing graph statistics. We demonstrate NGG's versatility across various graph generation tasks, showing its capability to capture desired graph properties and generalize to unseen graphs. This work signifies 
    
[^13]: 一个整合的数据处理框架用于预训练基础模型

    An Integrated Data Processing Framework for Pretraining Foundation Models

    [https://arxiv.org/abs/2402.16358](https://arxiv.org/abs/2402.16358)

    提出了一个集成了处理模块和分析模块的数据处理框架，旨在改善数据质量并展示其有效性。

    

    基础模型的能力在很大程度上依赖于大规模、多样化和高质量的预训练数据。为了提高数据质量，研究人员和从业者经常需要手动从不同来源策划数据集，并为每个数据存储库开发专门的数据清洗流程。缺乏统一的数据处理框架，这一过程重复而繁琐。为了缓解这一问题，我们提出了一个集成了处理模块和分析模块的数据处理框架，处理模块包括一系列不同粒度水平的操作符，而分析模块支持对精炼数据进行探查和评估。所提出的框架易于使用且高度灵活。在这篇演示论文中，我们首先介绍如何使用这个框架并展示它在改善数据质量方面的有效性，通过与ChatGPT的自动评估和端到端评估。

    arXiv:2402.16358v1 Announce Type: cross  Abstract: The ability of the foundation models heavily relies on large-scale, diverse, and high-quality pretraining data. In order to improve data quality, researchers and practitioners often have to manually curate datasets from difference sources and develop dedicated data cleansing pipeline for each data repository. Lacking a unified data processing framework, this process is repetitive and cumbersome. To mitigate this issue, we propose a data processing framework that integrates a Processing Module which consists of a series of operators at different granularity levels, and an Analyzing Module which supports probing and evaluation of the refined data. The proposed framework is easy to use and highly flexible. In this demo paper, we first introduce how to use this framework with some example use cases and then demonstrate its effectiveness in improving the data quality with an automated evaluation with ChatGPT and an end-to-end evaluation in 
    
[^14]: 见证为信：通过CLIP引导解码缓解大型视觉-语言模型中的幻觉

    Seeing is Believing: Mitigating Hallucination in Large Vision-Language Models via CLIP-Guided Decoding

    [https://arxiv.org/abs/2402.15300](https://arxiv.org/abs/2402.15300)

    CLIP相似性作为更强大和更稳健的幻觉指标，研究提出了CLIP引导解码（CGD）方法，在大型视觉-语言模型中有效减少对象幻觉。

    

    大型视觉-语言模型(LVLMs)容易出现对象幻觉，即生成的文本包含不存在的对象，严重限制了它们的可靠性和实用性。我们首先对句子级LVLM幻觉进行实证分析，发现与图像的CLIP相似性作为一个比单词可能性更强大、更稳健的幻觉指示器。基于这一发现，我们提出了CLIP引导解码（CGD）方法，这是一种简单但有效的无需训练的方法，用于减少解码时的对象幻觉。CGD利用CLIP来引导模型的解码过程，通过增强生成文本与图像的视觉联系。实验表明，CGD有效地减轻了对象幻觉。

    arXiv:2402.15300v1 Announce Type: cross  Abstract: Large Vision-Language Models (LVLMs) are susceptible to object hallucinations, an issue in which their generated text contains non-existent objects, greatly limiting their reliability and practicality. Current approaches often rely on the model's token likelihoods or other internal information, instruction tuning on additional datasets, or incorporating complex external tools. We first perform empirical analysis on sentence-level LVLM hallucination, finding that CLIP similarity to the image acts as a stronger and more robust indicator of hallucination compared to token likelihoods. Motivated by this, we introduce our CLIP-Guided Decoding (CGD) approach, a straightforward but effective training-free approach to reduce object hallucination at decoding time. CGD uses CLIP to guide the model's decoding process by enhancing visual grounding of generated text with the image. Experiments demonstrate that CGD effectively mitigates object hallu
    
[^15]: FlashTex：具有LightControlNet的快速可重塑网格纹理

    FlashTex: Fast Relightable Mesh Texturing with LightControlNet

    [https://arxiv.org/abs/2402.13251](https://arxiv.org/abs/2402.13251)

    提出了FlashTex方法，基于LightControlNet实现了快速自动化3D网格纹理生成，实现了照明与表面材质的解耦，使得网格能够在任何照明环境下正确重照和渲染

    

    手动为3D网格创建纹理费时费力，即使对于专家视觉内容创建者也是如此。我们提出了一种快速方法，根据用户提供的文本提示自动为输入的3D网格着色。重要的是，我们的方法将照明与表面材质/反射在生成的纹理中解耦，以便网格可以在任何照明环境中正确重照和渲染。我们引入了LightControlNet，这是一种基于ControlNet架构的新文本到图像模型，允许将所需照明规格作为对模型的条件图像。我们的文本到纹理管道然后分两个阶段构建纹理。第一阶段使用LightControlNet生成网格的一组稀疏的视觉一致的参考视图。第二阶段应用基于分数蒸馏采样（SDS）的纹理优化，通过LightControlNet来提高纹理质量同时解耦表面材质

    arXiv:2402.13251v1 Announce Type: cross  Abstract: Manually creating textures for 3D meshes is time-consuming, even for expert visual content creators. We propose a fast approach for automatically texturing an input 3D mesh based on a user-provided text prompt. Importantly, our approach disentangles lighting from surface material/reflectance in the resulting texture so that the mesh can be properly relit and rendered in any lighting environment. We introduce LightControlNet, a new text-to-image model based on the ControlNet architecture, which allows the specification of the desired lighting as a conditioning image to the model. Our text-to-texture pipeline then constructs the texture in two stages. The first stage produces a sparse set of visually consistent reference views of the mesh using LightControlNet. The second stage applies a texture optimization based on Score Distillation Sampling (SDS) that works with LightControlNet to increase the texture quality while disentangling surf
    
[^16]: MPIrigen: 通过领域特定语言模型生成MPI代码

    MPIrigen: MPI Code Generation through Domain-Specific Language Models

    [https://arxiv.org/abs/2402.09126](https://arxiv.org/abs/2402.09126)

    本文研究了使用领域特定语言模型生成MPI代码的性能，并提出了使用预训练模型MonoCoder进行MPI-based程序生成的方法。

    

    在大规模并行计算中，高效的并行计算尤为重要，特别是在消息传递接口（MPI）集成领域。生成基于MPI的并行程序是一个具有挑战性的并行编程任务，尚未被探索。本研究首先探讨了先进的语言模型在生成基于MPI的并行程序方面的性能。发现广泛使用的模型，如GPT-3.5和PolyCoder（专门的多语言代码模型），在生成基于MPI的程序时表现出明显的性能下降，相比通用程序。相比之下，基于MPI相关编程语言C和C++预训练的领域特定模型MonoCoder的性能更好。随后，我们通过在HPCorpusMPI上对MonoCoder进行微调，引入了一个专门的MPI-based程序生成任务。

    arXiv:2402.09126v1 Announce Type: cross Abstract: The imperative need to scale computation across numerous nodes highlights the significance of efficient parallel computing, particularly in the realm of Message Passing Interface (MPI) integration. The challenging parallel programming task of generating MPI-based parallel programs has remained unexplored. This study first investigates the performance of state-of-the-art language models in generating MPI-based parallel programs. Findings reveal that widely used models such as GPT-3.5 and PolyCoder (specialized multi-lingual code models) exhibit notable performance degradation, when generating MPI-based programs compared to general-purpose programs. In contrast, domain-specific models such as MonoCoder, which are pretrained on MPI-related programming languages of C and C++, outperform larger models. Subsequently, we introduce a dedicated downstream task of MPI-based program generation by fine-tuning MonoCoder on HPCorpusMPI. We call the r
    
[^17]: GenSTL: 通过特征域的自回归生成实现通用稀疏轨迹学习

    GenSTL: General Sparse Trajectory Learning via Auto-regressive Generation of Feature Domains

    [https://arxiv.org/abs/2402.07232](https://arxiv.org/abs/2402.07232)

    GenSTL是一个通用的稀疏轨迹学习框架，通过自回归生成特征域来实现稀疏轨迹与密集轨迹之间的连接，从而消除了对大规模密集轨迹数据的依赖。

    

    轨迹是时间戳位置样本的序列。在稀疏轨迹中，位置样本的采样是不频繁的；尽管这种轨迹在现实世界中很常见，但要使用它们来实现高质量的与交通相关的应用程序是具有挑战性的。当前的方法要么假设轨迹是密集采样的并且经过准确的地图匹配，要么依赖于两阶段方案，从而产生次优的应用程序。为了扩展稀疏轨迹的效用，我们提出了一种新颖的稀疏轨迹学习框架GenSTL。该框架经过预训练以使用特征域的自回归生成形成稀疏轨迹与密集轨迹之间的连接。GenSTL可以直接应用于下游任务，或者可以先进行微调。通过这种方式，GenSTL消除了对大规模密集和地图匹配轨迹数据的依赖。其中包括精心设计的特征域编码层和分层的...

    Trajectories are sequences of timestamped location samples. In sparse trajectories, the locations are sampled infrequently; and while such trajectories are prevalent in real-world settings, they are challenging to use to enable high-quality transportation-related applications. Current methodologies either assume densely sampled and accurately map-matched trajectories, or they rely on two-stage schemes, yielding sub-optimal applications.   To extend the utility of sparse trajectories, we propose a novel sparse trajectory learning framework, GenSTL. The framework is pre-trained to form connections between sparse trajectories and dense counterparts using auto-regressive generation of feature domains. GenSTL can subsequently be applied directly in downstream tasks, or it can be fine-tuned first. This way, GenSTL eliminates the reliance on the availability of large-scale dense and map-matched trajectory data. The inclusion of a well-crafted feature domain encoding layer and a hierarchical m
    
[^18]: 返回对齐的决策Transformer

    Return-Aligned Decision Transformer

    [https://arxiv.org/abs/2402.03923](https://arxiv.org/abs/2402.03923)

    本研究提出了返回对齐的决策Transformer（RADT），通过分离回报与传统输入序列，实现有效地将实际回报与目标回报对齐。

    

    传统的离线强化学习方法旨在学习最大化累积奖励（即回报）的最优策略。然而，随着应用范围的扩大，训练能够最大化回报并使实际回报与指定目标回报对齐的智能体变得越来越重要，从而控制智能体的性能。决策Transformer（DT）通过监督学习优化生成以目标回报为条件的动作的策略，并配备了使用目标回报控制智能体的机制。尽管DT旨在对齐实际回报与目标回报，但我们在实验中发现了DT中实际回报与目标回报之间的差异。在本文中，我们提出了返回对齐的决策Transformer（RADT），旨在有效地将实际回报与目标回报对齐。我们的模型将回报从传统的输入序列中分离出来，传统输入序列通常包含回报、状态和动作。

    Traditional approaches in offline reinforcement learning aim to learn the optimal policy that maximizes the cumulative reward, also known as return. However, as applications broaden, it becomes increasingly crucial to train agents that not only maximize the returns, but align the actual return with a specified target return, giving control over the agent's performance. Decision Transformer (DT) optimizes a policy that generates actions conditioned on the target return through supervised learning and is equipped with a mechanism to control the agent using the target return. Despite being designed to align the actual return with the target return, we have empirically identified a discrepancy between the actual return and the target return in DT. In this paper, we propose Return-Aligned Decision Transformer (RADT), designed to effectively align the actual return with the target return. Our model decouples returns from the conventional input sequence, which typically consists of returns, s
    
[^19]: 基于邻域覆盖和相似性的自动驾驶车辆少样本场景测试

    Few-Shot Scenario Testing for Autonomous Vehicles Based on Neighborhood Coverage and Similarity

    [https://arxiv.org/abs/2402.01795](https://arxiv.org/abs/2402.01795)

    本文提出了一个基于邻域覆盖和相似性的少样本场景测试框架，用于解决大规模部署之前自动驾驶车辆测试和评估中的不确定性和挑战。

    

    在大规模部署之前，对自动驾驶车辆（AVs）进行测试和评估其安全性能是至关重要的。然而，由于测试成本或时间的限制，针对特定AV模型的可接受测试成本通常会被极限制地降低。现有的测试方法严格限制的测试数目会导致测试结果的显著不确定性或挑战。本文首次将这个问题定义为“少样本测试（FST）”问题，并提出了一个系统的FST框架来解决这个挑战。为了减轻小规模测试场景中的不确定性，并优化场景利用，我们将FST问题建模为一个优化问题，并基于邻域覆盖和相似性寻找一个小的场景集合。通过利用先验信息中的代理模型（SMs），我们动态调整测试场景集合和其贡献。

    Testing and evaluating the safety performance of autonomous vehicles (AVs) is essential before the large-scale deployment. Practically, the acceptable cost of testing specific AV model can be restricted within an extremely small limit because of testing cost or time. With existing testing methods, the limitations imposed by strictly restricted testing numbers often result in significant uncertainties or challenges in quantifying testing results. In this paper, we formulate this problem for the first time the "few-shot testing" (FST) problem and propose a systematic FST framework to address this challenge. To alleviate the considerable uncertainty inherent in a small testing scenario set and optimize scenario utilization, we frame the FST problem as an optimization problem and search for a small scenario set based on neighborhood coverage and similarity. By leveraging the prior information on surrogate models (SMs), we dynamically adjust the testing scenario set and the contribution of 
    
[^20]: SWEA:通过主题词嵌入修改改变大型语言模型中的事实知识

    SWEA: Changing Factual Knowledge in Large Language Models via Subject Word Embedding Altering

    [https://arxiv.org/abs/2401.17809](https://arxiv.org/abs/2401.17809)

    提出了一种主题词嵌入修改框架（SWEA），通过在推理阶段修改主题的表示来编辑知识，保护模型的原始权重，避免不可逆的损害和额外的推理开销。

    

    模型编辑近来引起了广泛关注。目前的模型编辑方法主要涉及修改模型参数或向现有模型添加附加模块。然而，前者会对LLM造成不可逆的影响，而后者会产生额外的推理开销，并且模糊的向量匹配并不总是可靠的。为了解决这些问题，我们提出了一种可扩展的主题词嵌入修改（SWEA）框架，它在推理阶段修改主题的表示，并实现编辑知识的目标。SWEA在模型外部使用精确的关键匹配，并进行可靠的主题词嵌入修改，从而保护模型的原始权重而不增加推理开销。然后，我们提出优化抑制融合方法，首先优化编辑目标的嵌入向量，然后抑制知识嵌入维度（KED）以获得最终融合的嵌入。我们因此提出了SWEAOS元方法。

    Model editing has recently gained widespread attention. Current model editing methods primarily involve modifying model parameters or adding additional modules to the existing model. However, the former causes irreversible damage to LLMs, while the latter incurs additional inference overhead and fuzzy vector matching is not always reliable. To address these issues, we propose an expandable Subject Word Embedding Altering (SWEA) framework, which modifies the representation of subjects and achieve the goal of editing knowledge during the inference stage. SWEA uses precise key matching outside the model and performs reliable subject word embedding altering, thus protecting the original weights of the model without increasing inference overhead. We then propose optimizing then suppressing fusion method, which first optimizes the embedding vector for the editing target and then suppresses the Knowledge Embedding Dimension (KED) to obtain the final fused embedding. We thus propose SWEAOS met
    
[^21]: 数据驱动的目标定位: 使用Cramér-Rao界限对梯度下降进行基准测试

    Data-Driven Target Localization: Benchmarking Gradient Descent Using the Cram\'er-Rao Bound. (arXiv:2401.11176v1 [eess.SP])

    [http://arxiv.org/abs/2401.11176](http://arxiv.org/abs/2401.11176)

    本研究提出了一种数据驱动的神经网络方法，通过降低均方误差（MSE）实现了改进的目标方位和速度估计。这一发现强调了在雷达系统中采用深度学习方法的潜力，为在杂乱和动态环境中更准确的定位铺平了道路。

    

    在现代雷达系统中，使用方位和速度估计进行精确的目标定位至关重要。传统的无偏估计方法利用梯度下降算法达到Cramér-Rao界限（CRB）的理论极限，用于参数估计的误差。在本研究中，我们提出了一种数据驱动的神经网络方法，优于这些传统技术，在目标方位和速度估计方面表现出更高的准确性。使用代表性的模拟场景，我们展示了我们提出的神经网络模型始终实现了改进的参数估计，这是由于其固有的偏见性，从而得到了减小的均方误差（MSE）。我们的发现强调了在雷达系统中采用深度学习方法的潜力，为在杂乱和动态环境中更准确的定位铺平了道路。

    In modern radar systems, precise target localization using azimuth and velocity estimation is paramount. Traditional unbiased estimation methods have leveraged gradient descent algorithms to reach the theoretical limits of the Cram\'er Rao Bound (CRB) for the error of the parameter estimates. In this study, we present a data-driven neural network approach that outperforms these traditional techniques, demonstrating improved accuracies in target azimuth and velocity estimation. Using a representative simulated scenario, we show that our proposed neural network model consistently achieves improved parameter estimates due to its inherently biased nature, yielding a diminished mean squared error (MSE). Our findings underscore the potential of employing deep learning methods in radar systems, paving the way for more accurate localization in cluttered and dynamic environments.
    
[^22]: PPNet: 一种用于端到端近似最优路径规划的新颖神经网络结构

    PPNet: A Novel Neural Network Structure for End-to-End Near-Optimal Path Planning. (arXiv:2401.09819v1 [cs.RO])

    [http://arxiv.org/abs/2401.09819](http://arxiv.org/abs/2401.09819)

    PPNet是一种新颖的神经网络结构，用于解决端到端近似最优路径规划问题。通过将路径规划问题分为两个子问题，并使用两级级联神经网络进行求解，同时引入了一种高效的数据生成方法EDaGe-PP。实验结果表明，PPNet在计算时间和成功率方面比其他方法有显著提升。

    

    传统的路径规划器，如基于采样的路径规划器，在初始解敏感性和收敛到最优解速度上具有局限性。然而，在许多应用中，如具有有限功率/燃料的自动驾驶车辆中，在短时间内找到近似最优解是具有挑战性的。为了实现端到端近似最优路径规划器，我们首先将路径规划问题分为两个子问题，即路径空间分段和给定路径空间中的航点生成。我们进一步提出了一个名为路径规划网络（PPNet）的两级级联神经网络来解决路径规划问题，通过解决上述子问题。此外，我们提出了一种名为EDaGe-PP的用于路径规划的高效数据生成方法。结果显示，PPNet训练集由EDaGe-PP生成的成功率相比其他方法提升了$2\times$，总计算时间少于1/33。我们验证了PPNet的性能。

    The classical path planners, such as sampling-based path planners, have the limitations of sensitivity to the initial solution and slow convergence to the optimal solution. However, finding a near-optimal solution in a short period is challenging in many applications such as the autonomous vehicle with limited power/fuel. To achieve an end-to-end near-optimal path planner, we first divide the path planning problem into two subproblems, which are path's space segmentation and waypoints generation in the given path's space. We further propose a two-level cascade neural network named Path Planning Network (PPNet) to solve the path planning problem by solving the abovementioned subproblems. Moreover, we propose a novel efficient data generation method for path planning named EDaGe-PP. The results show the total computation time is less than 1/33 and the success rate of PPNet trained by the dataset that is generated by EDaGe-PP is about $2 \times$ compared to other methods. We validate PPNe
    
[^23]: 是否所有未见数据都是OoD数据？

    Are All Unseen Data Out-of-Distribution?. (arXiv:2312.16243v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.16243](http://arxiv.org/abs/2312.16243)

    该论文研究了未见数据的分布在泛化中的挑战，并提出了重新定义OoD数据以及新的泛化上界，保证了对未见数据的模型有效性。

    

    处理未见数据的分布一直被视为是OoD（out-of-distribution），使其泛化成为一个重要挑战。很多证据表明，训练数据的规模增加可以单调地降低测试数据的泛化误差。然而，从其他观察和分析来看，这并不总是成立。特别是当训练数据包含多个来源领域，并且测试数据包含分布漂移时，不是所有的测试数据的泛化误差都会随着训练数据规模的增加而单调减小。在线性设置下，我们正式研究了这种非单调现象，并通过在不同视觉基准上进行经验证实。鉴于这些结果，我们重新定义了OoD数据，将其视为训练域的凸包之外的数据，并基于这个新定义证明了一个新的泛化上界。它意味着对于在训练阶段没有见过的数据，经过充分训练的模型的有效性可以得到保证。

    Distributions of unseen data have been all treated as out-of-distribution (OOD), making their generalization a significant challenge. Much evidence suggests that the size increase of training data can monotonically decrease generalization errors in test data. However, this is not true from other observations and analysis. In particular, when the training data have multiple source domains and the test data contain distribution drifts, then not all generalization errors on the test data decrease monotonically with the increasing size of training data. Such a non-decreasing phenomenon is formally investigated under a linear setting with empirical verification across varying visual benchmarks. Motivated by these results, we redefine the OOD data as a type of data outside the convex hull of the training domains and prove a new generalization bound based on this new definition. It implies that the effectiveness of a well-trained model can be guaranteed for the unseen data that is within the 
    
[^24]: 使用训练标签进行填充和通过标签填充进行分类

    Imputation using training labels and classification via label imputation. (arXiv:2311.16877v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2311.16877](http://arxiv.org/abs/2311.16877)

    本论文提出一种在填充缺失数据时将标签与输入堆叠的方法，能够显著提高填充效果，并同时填充标签和输入。该方法适用于各种类型的数据，且在实验证明具有有希望的准确性结果。

    

    在实际应用中，缺失数据是一个常见的问题。已经开发了各种填充方法来处理缺失数据。然而，尽管训练数据通常都有标签，但常见的填充方法通常只依赖于输入而忽略标签。在这项工作中，我们阐述了将标签堆叠到输入中可以显着提高输入的填充效果。此外，我们提出了一种分类策略，该策略将预测的测试标签初始化为缺失值，并将标签与输入堆叠在一起进行填充。这样可以同时填充标签和输入。而且，该技术能够处理具有缺失标签的训练数据，无需任何先前的填充，并且适用于连续型、分类型或混合型数据。实验证明在准确性方面取得了有希望的结果。

    Missing data is a common problem in practical settings. Various imputation methods have been developed to deal with missing data. However, even though the label is usually available in the training data, the common practice of imputation usually only relies on the input and ignores the label. In this work, we illustrate how stacking the label into the input can significantly improve the imputation of the input. In addition, we propose a classification strategy that initializes the predicted test label with missing values and stacks the label with the input for imputation. This allows imputing the label and the input at the same time. Also, the technique is capable of handling data training with missing labels without any prior imputation and is applicable to continuous, categorical, or mixed-type data. Experiments show promising results in terms of accuracy.
    
[^25]: 通过基于有限差分的无监督小型线性卷积神经网络解决椭圆和抛物型问题

    Solutions to Elliptic and Parabolic Problems via Finite Difference Based Unsupervised Small Linear Convolutional Neural Networks. (arXiv:2311.00259v1 [cs.LG])

    [http://arxiv.org/abs/2311.00259](http://arxiv.org/abs/2311.00259)

    通过无监督学习，我们提出了利用小型卷积神经网络直接估计椭圆和抛物型问题的有限差分解，相比传统方法具有可比较的准确性。

    

    近年来，利用深度学习和神经网络解决科学问题，特别是求解偏微分方程（PDE），引起了广泛关注。然而，目前基于神经网络的PDE求解器往往依赖于大量的训练数据或标记的输入-输出对，这使得它们在推广到分布之外的示例时容易面临挑战。为了减少传统基于神经网络方法在估计PDE解时遇到的广义化差距，我们提出了一种完全无监督的方法，无需训练数据，通过小型卷积神经网络直接估计PDE的有限差分解。与有限差分法相比，我们提出的算法在几个选定的椭圆和抛物问题上表现出与真解相当的准确性。

    In recent years, there has been a growing interest in leveraging deep learning and neural networks to address scientific problems, particularly in solving partial differential equations (PDEs). However, current neural network-based PDE solvers often rely on extensive training data or labeled input-output pairs, making them prone to challenges in generalizing to out-of-distribution examples. To mitigate the generalization gap encountered by conventional neural network-based methods in estimating PDE solutions, we formulate a fully unsupervised approach, requiring no training data, to estimate finite difference solutions for PDEs directly via small convolutional neural networks. Our proposed algorithms demonstrate a comparable accuracy to the true solution for several selected elliptic and parabolic problems compared to the finite difference method.
    
[^26]: 通过创建固定目标来改进内在探索

    Improving Intrinsic Exploration by Creating Stationary Objectives. (arXiv:2310.18144v1 [cs.LG])

    [http://arxiv.org/abs/2310.18144](http://arxiv.org/abs/2310.18144)

    该论文提出了一个新的方法：通过创建固定目标，将原始的非固定奖励转化为固定奖励，从而改善了强化学习中的内在探索。

    

    强化学习中的探索奖励通过定义自定义的内在目标来引导长期探索。基于计数的方法使用状态访问频率来获得探索奖励。本文发现，任何从基于计数的方法导出的内在奖励函数都是非固定的，因此为代理人构建了一个难以优化的目标。我们工作的关键贡献在于通过增强状态表示将原始的非固定奖励转化为固定奖励。为此，我们引入了用于探索的固定目标（SOFE）框架。SOFE需要识别不同探索奖励的足够统计量，并找到一种将这些统计量高效编码作为深度网络输入的方法。SOFE基于提出扩展状态空间的状态增强，但有希望简化代理目标的优化。我们的实验结果表明，SOFE改善了探索效果。

    Exploration bonuses in reinforcement learning guide long-horizon exploration by defining custom intrinsic objectives. Count-based methods use the frequency of state visits to derive an exploration bonus. In this paper, we identify that any intrinsic reward function derived from count-based methods is non-stationary and hence induces a difficult objective to optimize for the agent. The key contribution of our work lies in transforming the original non-stationary rewards into stationary rewards through an augmented state representation. For this purpose, we introduce the Stationary Objectives For Exploration (SOFE) framework. SOFE requires identifying sufficient statistics for different exploration bonuses and finding an efficient encoding of these statistics to use as input to a deep network. SOFE is based on proposing state augmentations that expand the state space but hold the promise of simplifying the optimization of the agent's objective. Our experiments show that SOFE improves the
    
[^27]: HeaP: 使用LLMs进行层次化Web动作策略

    HeaP: Hierarchical Policies for Web Actions using LLMs. (arXiv:2310.03720v1 [cs.LG])

    [http://arxiv.org/abs/2310.03720](http://arxiv.org/abs/2310.03720)

    这篇论文介绍了一个名为HeaP的框架，利用大型语言模型（LLMs）来解决Web任务的挑战。该框架将Web任务分解为子任务，并通过一系列低级的策略来执行，相比其他基准方法，该框架在不同的Web任务上表现出更好的性能。

    

    大型语言模型（LLMs）在少量数据和零-shot设置中展示了出色的指令跟随任务能力。然而，教授LLMs在Web上执行任务面临着基本挑战 - 组合性大的开放世界任务和Web接口之间的差异。我们通过利用LLMs将Web任务分解为一系列子任务来应对这些挑战，每个子任务可以通过一个低级的闭环策略来解决。这些策略构成了任务之间的共享语法，即新的Web任务可以作为这些策略的组合来表达。我们提出了一种新的框架，即基于LLMs的Hierarchical Policies for Web Actions（HeaP），该框架通过从示范中学习一组层次化的LLM提示来规划高级任务并通过一系列低级策略执行它们。我们通过一套Web任务，包括MiniWoB++，WebArena，模拟航空CRM以及实际网站来评估HeaP与一系列基准方法的性能。

    Large language models (LLMs) have demonstrated remarkable capabilities in performing a range of instruction following tasks in few and zero-shot settings. However, teaching LLMs to perform tasks on the web presents fundamental challenges -- combinatorially large open-world tasks and variations across web interfaces. We tackle these challenges by leveraging LLMs to decompose web tasks into a collection of sub-tasks, each of which can be solved by a low-level, closed-loop policy. These policies constitute a shared grammar across tasks, i.e., new web tasks can be expressed as a composition of these policies. We propose a novel framework, Hierarchical Policies for Web Actions using LLMs (HeaP), that learns a set of hierarchical LLM prompts from demonstrations for planning high-level tasks and executing them via a sequence of low-level policies. We evaluate HeaP against a range of baselines on a suite of web tasks, including MiniWoB++, WebArena, a mock airline CRM, as well as live website i
    
[^28]: 潜空间的对称性发现

    Latent Space Symmetry Discovery. (arXiv:2310.00105v1 [cs.LG])

    [http://arxiv.org/abs/2310.00105](http://arxiv.org/abs/2310.00105)

    提出了一种新的生成模型——潜空间LieGAN（LaLiGAN），可以从数据中发现非线性对称性，并产生结构良好的潜空间，对其他下游任务非常有用。

    

    等变神经网络需要明确知道对称群。自动对称性发现方法旨在放宽这个约束，并从数据中学习不变性和等变性。然而，现有的对称性发现方法在搜索空间中仅限于线性对称性，无法处理实际世界中的对称性复杂性，尤其是高维数据。我们提出了一种新颖的生成模型，潜空间LieGAN（LaLiGAN），可以从数据中发现非线性对称性。它学习了一种从数据到潜空间的映射，在其中对称性变得线性，并同时发现潜空间中的对称性。理论上，我们证明了在一定条件下我们的方法可以表示任何非线性对称性。实验上，我们的方法可以捕捉高维观测中的内在对称性，从而产生一个结构良好的潜空间，对其他下游任务非常有用。我们演示了LaLiGAN在改进方程发现方面的应用案例。

    Equivariant neural networks require explicit knowledge of the symmetry group. Automatic symmetry discovery methods aim to relax this constraint and learn invariance and equivariance from data. However, existing symmetry discovery methods are limited to linear symmetries in their search space and cannot handle the complexity of symmetries in real-world, often high-dimensional data. We propose a novel generative model, Latent LieGAN (LaLiGAN), which can discover nonlinear symmetries from data. It learns a mapping from data to a latent space where the symmetries become linear and simultaneously discovers symmetries in the latent space. Theoretically, we show that our method can express any nonlinear symmetry under certain conditions. Experimentally, our method can capture the intrinsic symmetry in high-dimensional observations, which results in a well-structured latent space that is useful for other downstream tasks. We demonstrate the use cases for LaLiGAN in improving equation discovery
    
[^29]: 神经启发的分层多模态学习

    Neuro-Inspired Hierarchical Multimodal Learning. (arXiv:2309.15877v1 [cs.LG])

    [http://arxiv.org/abs/2309.15877](http://arxiv.org/abs/2309.15877)

    这项研究提出了一种神经启发的分层多模态学习方法，利用信息瓶颈理论构建了一种有效且紧凑的信息流，实现了对真实世界的全面和准确的感知。

    

    整合和处理来自多种信息源或模态对于获得对真实世界的全面和准确的感知至关重要。受到神经科学的启发，我们开发了信息论分层感知(ITHP)模型，该模型利用了信息瓶颈的概念。与大多数旨在将所有模态纳入输入的传统融合模型不同，我们的模型将主要模态指定为输入，而其余模态则作为信息路径中的检测器。我们提出的感知模型的重点是通过在潜在状态和输入模态状态之间最小化相互信息并在潜在状态和其余模态之间最大化相互信息的平衡，构建一种有效且紧凑的信息流。这种方法导致了保留相关信息并最小化冗余的紧凑潜在状态表示，从而实现更好的感知。

    Integrating and processing information from various sources or modalities are critical for obtaining a comprehensive and accurate perception of the real world. Drawing inspiration from neuroscience, we develop the Information-Theoretic Hierarchical Perception (ITHP) model, which utilizes the concept of information bottleneck. Distinct from most traditional fusion models that aim to incorporate all modalities as input, our model designates the prime modality as input, while the remaining modalities act as detectors in the information pathway. Our proposed perception model focuses on constructing an effective and compact information flow by achieving a balance between the minimization of mutual information between the latent state and the input modal state, and the maximization of mutual information between the latent states and the remaining modal states. This approach leads to compact latent state representations that retain relevant information while minimizing redundancy, thereby sub
    
[^30]: 基于掩码Transformer的心电图分类研究

    Masked Transformer for Electrocardiogram Classification. (arXiv:2309.07136v1 [eess.SP])

    [http://arxiv.org/abs/2309.07136](http://arxiv.org/abs/2309.07136)

    提出了一种基于掩码Transformer的ECG分类方法，命名为MTECG，扩展了掩码自动编码器在ECG时间序列上的应用，该方法在广泛的掩码比例下表现稳定良好，并进行了消融实验验证了重构目标的波动性、训练计划长度、逐层学习率衰减和DropPath率的重要性。

    

    心电图（ECG）是临床应用中最重要的诊断工具之一。随着先进算法的出现，各种深度学习模型已被应用于ECG任务。然而，尽管Transformer在计算机视觉和自然语言处理领域取得了广泛成功，但其在ECG数据上的潜力尚未得到实现。在本研究中，我们提出了一种有用的基于掩码Transformer的ECG分类方法，称为MTECG，它将掩码自动编码器的应用扩展到了ECG时间序列上。我们构建了一个包含220,251个ECG记录的数据集，这些记录由医学专家进行了广泛的诊断注释，以探索MTECG的特性。在提出的训练策略下，一个只有5.7M参数的轻量级模型在广泛的掩码比例（5%-75%）下表现稳定良好。消融研究突出了波动重构目标、训练计划长度、逐层学习率衰减和DropPath率的重要性。实验发现MTECG耗时较少且能够有效分类各种心电图。

    Electrocardiogram (ECG) is one of the most important diagnostic tools in clinical applications. With the advent of advanced algorithms, various deep learning models have been adopted for ECG tasks. However, the potential of Transformers for ECG data is not yet realized, despite their widespread success in computer vision and natural language processing. In this work, we present a useful masked Transformer method for ECG classification referred to as MTECG, which expands the application of masked autoencoders to ECG time series. We construct a dataset comprising 220,251 ECG recordings with a broad range of diagnoses annoated by medical experts to explore the properties of MTECG. Under the proposed training strategies, a lightweight model with 5.7M parameters performs stably well on a broad range of masking ratios (5%-75%). The ablation studies highlight the importance of fluctuated reconstruction targets, training schedule length, layer-wise LR decay and DropPath rate. The experiments o
    
[^31]: 高斯混合物可以通过多项式数量的样本进行差分隐私学习

    Mixtures of Gaussians are Privately Learnable with a Polynomial Number of Samples. (arXiv:2309.03847v1 [stat.ML])

    [http://arxiv.org/abs/2309.03847](http://arxiv.org/abs/2309.03847)

    通过多项式数量的样本和差分隐私约束，我们提出了一个可以估计高斯混合物的方法，并证明了这个方法的有效性，而无需对GMMs做任何结构性假设。

    

    我们研究了在差分隐私(DP)约束下估计高斯混合物的问题。我们的主要结果是，使用$\tilde{O}(k^2 d^4 \log(1/\delta) / \alpha^2 \varepsilon)$个样本即可在满足$(\varepsilon, \delta)$-DP的条件下估计$k$个高斯混合物，使其达到总变差距离$\alpha$。这是该问题的第一个有限样本复杂性上限，而无需对GMMs做任何结构性假设。为了解决这个问题，我们构建了一个新的框架，该框架对于其他任务可能也有用。在高层次上，我们展示了如果一个分布类（比如高斯分布）是（1）可列表译码的并且（2）在总变差距离方面具有“局部小”覆盖[ BKSW19]，则其混合物类是私密可学习的。证明绕过了一个已知障碍，表明与高斯分布不同，GMMs不具有局部小的覆盖[AAL21]。

    We study the problem of estimating mixtures of Gaussians under the constraint of differential privacy (DP). Our main result is that $\tilde{O}(k^2 d^4 \log(1/\delta) / \alpha^2 \varepsilon)$ samples are sufficient to estimate a mixture of $k$ Gaussians up to total variation distance $\alpha$ while satisfying $(\varepsilon, \delta)$-DP. This is the first finite sample complexity upper bound for the problem that does not make any structural assumptions on the GMMs.  To solve the problem, we devise a new framework which may be useful for other tasks. On a high level, we show that if a class of distributions (such as Gaussians) is (1) list decodable and (2) admits a "locally small'' cover [BKSW19] with respect to total variation distance, then the class of its mixtures is privately learnable. The proof circumvents a known barrier indicating that, unlike Gaussians, GMMs do not admit a locally small cover [AAL21].
    
[^32]: R2D2: 用于射电天文学中近实时高动态范围成像的深度神经网络系列

    R2D2: Deep neural network series for near real-time high-dynamic range imaging in radio astronomy. (arXiv:2309.03291v1 [astro-ph.IM] CROSS LISTED)

    [http://arxiv.org/abs/2309.03291](http://arxiv.org/abs/2309.03291)

    R2D2是用于射电天文中高动态范围成像的深度神经网络系列，采用模型驱动方法和数据一致性更新，重建为一系列残差图像，可用于高分辨率强度成像。

    

    我们提出了一种新颖的人工智能方法，通过射电干涉测量（RI）在天文学中实现高分辨率高动态范围合成成像。R2D2代表“高动态范围成像的残差到残差DNN系列”，是一种基于模型的数据驱动方法，依赖于混合深度神经网络（DNN）和数据一致性更新。它的重建是由一系列残差图像组成的，这些残差图像被估计为DNN的输出，每个DNN都以上一次迭代的残差脏图片作为输入。该方法可以解释为匹配追踪方法的学习版本，其中模型组件从残差脏图片中迭代地识别出来，CLEAN就是一个众所周知的例子。我们提出了R2D2模型的两个变体，分别基于两种不同的DNN架构：标准的U-Net和一种新颖的展开架构。我们展示了它们在S波段对射电星系Cygnus~A的高灵敏度观测中用于单色强度成像的应用。

    We present a novel AI approach for high-resolution high-dynamic range synthesis imaging by radio interferometry (RI) in astronomy. R2D2, standing for "{R}esidual-to-{R}esidual {D}NN series for high-{D}ynamic range imaging", is a model-based data-driven approach relying on hybrid deep neural networks (DNNs) and data-consistency updates. Its reconstruction is built as a series of residual images estimated as the outputs of DNNs, each taking the residual dirty image of the previous iteration as an input. The approach can be interpreted as a learned version of a matching pursuit approach, whereby model components are iteratively identified from residual dirty images, and of which CLEAN is a well-known example. We propose two variants of the R2D2 model, built upon two distinctive DNN architectures: a standard U-Net, and a novel unrolled architecture. We demonstrate their use for monochromatic intensity imaging on highly-sensitive observations of the radio galaxy Cygnus~A at S band, from the
    
[^33]: 图像劫持：对抗性图像能在运行时控制生成模型

    Image Hijacking: Adversarial Images can Control Generative Models at Runtime. (arXiv:2309.00236v1 [cs.LG])

    [http://arxiv.org/abs/2309.00236](http://arxiv.org/abs/2309.00236)

    本研究发现对抗性图像能够在运行时控制生成模型，并提出了通用的方法来创建图像劫持。通过研究三种攻击类型，我们发现这些攻击对最新的视觉语言模型具有高达90％以上的成功率。该研究引发了对基础模型安全性的严重担忧。

    

    基础模型是否能够免受恶意行为者的攻击？本文研究了视觉语言模型（VLM）的图像输入。我们发现了图像劫持，即能够在运行时控制生成模型的对抗性图像。我们引入了一种名为“行为匹配”的通用方法来创建图像劫持，并用它来探索三种类型的攻击：具体字符串攻击可以生成任意被攻击者选择的输出；泄露上下文攻击可以将上下文窗口中的信息泄露到输出中；越狱攻击可以绕过模型的安全训练。我们对基于CLIP和LLaMA-2的最新VLM模型LLaVA-2进行了这些攻击的研究，并发现我们所有的攻击类型成功率均在90％以上。而且，我们的攻击是自动化的，只需要对图像进行小的扰动。这些发现对基础模型的安全性提出了严重的担忧。如果图像劫持与CIFAR-10中的对抗性样本一样难以防御，那么可能需要很多年才能找到解决方案。

    Are foundation models secure from malicious actors? In this work, we focus on the image input to a vision-language model (VLM). We discover image hijacks, adversarial images that control generative models at runtime. We introduce Behavior Matching, a general method for creating image hijacks, and we use it to explore three types of attacks. Specific string attacks generate arbitrary output of the adversary's choosing. Leak context attacks leak information from the context window into the output. Jailbreak attacks circumvent a model's safety training. We study these attacks against LLaVA-2, a state-of-the-art VLM based on CLIP and LLaMA-2, and find that all our attack types have above a 90\% success rate. Moreover, our attacks are automated and require only small image perturbations. These findings raise serious concerns about the security of foundation models. If image hijacks are as difficult to defend against as adversarial examples in CIFAR-10, then it might be many years before a s
    
[^34]: 黑盒变分推断的线性收敛性：我们应该坚持到底吗？

    Linear Convergence of Black-Box Variational Inference: Should We Stick the Landing?. (arXiv:2307.14642v1 [stat.ML])

    [http://arxiv.org/abs/2307.14642](http://arxiv.org/abs/2307.14642)

    本文证明了带有控制变量的黑盒变分推断在完美变分族规范下以几何速度收敛，为BBVI提供了收敛性保证，同时提出了对熵梯度估计器的改进，对比了STL估计器，并给出了明确的非渐近复杂度保证。

    

    我们证明了带有控制变量的黑盒变分推断（BBVI），特别是着陆稳定（STL）估计器，在完美变分族规范下收敛于几何（传统上称为“线性”）速度。特别地，我们证明了STL估计器的梯度方差的二次界限，该界限包括了误指定的变分族。结合先前关于二次方差条件的工作，这直接暗示了在使用投影随机梯度下降的情况下BBVI的收敛性。我们还改进了现有对于正常封闭形式熵梯度估计器的分析，这使得我们能够将其与STL估计器进行比较，并为两者提供明确的非渐进复杂度保证。

    We prove that black-box variational inference (BBVI) with control variates, particularly the sticking-the-landing (STL) estimator, converges at a geometric (traditionally called "linear") rate under perfect variational family specification. In particular, we prove a quadratic bound on the gradient variance of the STL estimator, one which encompasses misspecified variational families. Combined with previous works on the quadratic variance condition, this directly implies convergence of BBVI with the use of projected stochastic gradient descent. We also improve existing analysis on the regular closed-form entropy gradient estimators, which enables comparison against the STL estimator and provides explicit non-asymptotic complexity guarantees for both.
    
[^35]: MERT:带有大规模自监督训练的声学音乐理解模型

    MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training. (arXiv:2306.00107v1 [cs.SD])

    [http://arxiv.org/abs/2306.00107](http://arxiv.org/abs/2306.00107)

    提出了一个带有大规模自监督训练的音乐理解模型MERT，利用了教师模型并采用了一种优于传统的语音和音频方法的组合方式。

    

    自监督学习（SSL）最近在视觉、文本和语音领域中已被证明是训练通用模型的一种很有前景的范例，对于跨越音乐领域的应用，尤其是对于调性和音高这样的特殊音乐知识的建模颇具挑战性。为了解决这一问题，我们提出了一个基于大规模自监督训练的声学音乐理解模型，即MERT。在我们的探索中，我们确定了更优秀的教师模型组合，这种组合方法在性能方面优于传统的语音和音频方法。

    Self-supervised learning (SSL) has recently emerged as a promising paradigm for training generalisable models on large-scale data in the fields of vision, text, and speech. Although SSL has been proven effective in speech and audio, its application to music audio has yet to be thoroughly explored. This is primarily due to the distinctive challenges associated with modelling musical knowledge, particularly its tonal and pitched characteristics of music. To address this research gap, we propose an acoustic Music undERstanding model with large-scale self-supervised Training (MERT), which incorporates teacher models to provide pseudo labels in the masked language modelling (MLM) style acoustic pre-training. In our exploration, we identified a superior combination of teacher models, which outperforms conventional speech and audio approaches in terms of performance. This combination includes an acoustic teacher based on Residual Vector Quantization - Variational AutoEncoder (RVQ-VAE) and a m
    
[^36]: 非参数学习具有快速收敛率的随机微分方程

    Non-Parametric Learning of Stochastic Differential Equations with Fast Rates of Convergence. (arXiv:2305.15557v1 [cs.LG])

    [http://arxiv.org/abs/2305.15557](http://arxiv.org/abs/2305.15557)

    提出了一种新的非参数方法，用于识别随机微分方程中的漂移和扩散系数，该方法具有快速的收敛率，使得学习速率随着未知系数的光滑度增加而变得更加紧密。

    

    我们提出了一种新颖的非参数学习范式来识别非线性随机微分方程的漂移和扩散系数，该范式依赖于状态的离散时间观测。其关键思想是将相应的Fokker-Planck方程的基于RKHS的近似拟合到这些观测值，从而得出理论学习速率的估计值，这与以往的工作不同，当未知漂移和扩散系数的光滑度越高时，理论估计值越来越紧。由于我们的方法是基于内核的，因此离线预处理可以在原则上得到有效的数值实现。

    We propose a novel non-parametric learning paradigm for the identification of drift and diffusion coefficients of non-linear stochastic differential equations, which relies upon discrete-time observations of the state. The key idea essentially consists of fitting a RKHS-based approximation of the corresponding Fokker-Planck equation to such observations, yielding theoretical estimates of learning rates which, unlike previous works, become increasingly tighter when the regularity of the unknown drift and diffusion coefficients becomes higher. Our method being kernel-based, offline pre-processing may in principle be profitably leveraged to enable efficient numerical implementation.
    
[^37]: 基于例行血液检查数值的机器学习模型鉴别病毒和细菌感染。

    Differentiating Viral and Bacterial Infections: A Machine Learning Model Based on Routine Blood Test Values. (arXiv:2305.07877v1 [cs.LG])

    [http://arxiv.org/abs/2305.07877](http://arxiv.org/abs/2305.07877)

    本研究开发了一种基于血液检查数值的病毒与细菌机器学习模型，用于准确识别感染类型。该模型在CRP水平10-40 mg/L范围内表现出更好的区分细菌和病毒感染的准确性，证明了多种血液参数对于诊断决策的重要性。

    

    随着抗生素耐药性日益威胁，正确区分细菌和病毒感染以进行正确的抗生素使用变得越来越重要。本研究开发了一种基于16个例行血液检查结果、C-反应蛋白水平、生物性别和年龄的病毒与细菌机器学习模型，用于区分这些感染类型。使用单个医疗中心的44,120个案例数据集，"病毒 vs. 细菌"模型表现出令人瞩目的82.2%的准确率，0.129的Brier得分和0.91的ROC曲线下面积，超越了传统CRP决策规则模型的性能。该模型在CRP范围为10-40 mg/L时表现出显著的改进准确性，这个范围内仅靠CRP无法为细菌和病毒感染进行区分的诊断价值有限。这些发现强调了在诊断决策中考虑多种血液参数的重要性，并建议病毒 vs. 细菌模型使得应用于临床决策成为可能。

    The growing threat of antibiotic resistance necessitates accurate differentiation between bacterial and viral infections for proper antibiotic administration. In this study, a Virus vs. Bacteria machine learning model was developed to discern between these infection types using 16 routine blood test results, C-reactive protein levels, biological sex, and age. With a dataset of 44,120 cases from a single medical center, the Virus vs. Bacteria model demonstrated remarkable accuracy of 82.2%, a Brier score of 0.129, and an area under the ROC curve of 0.91, surpassing the performance of traditional CRP decision rule models. The model demonstrates substantially improved accuracy within the CRP range of 10 40 mg/L, an interval in which CRP alone offers limited diagnostic value for distinguishing between bacterial and viral infections. These findings underscore the importance of considering multiple blood parameters for diagnostic decision-making and suggest that the Virus vs. Bacteria model 
    
[^38]: 基于规范的神经网络简化方法，用于大规模形式化验证

    Specification-Driven Neural Network Reduction for Scalable Formal Verification. (arXiv:2305.01932v1 [cs.LG])

    [http://arxiv.org/abs/2305.01932](http://arxiv.org/abs/2305.01932)

    本文提出了一种基于规范的神经网络简化方法用于大规模形式化验证。该方法采用保守的简化方法，确保简化后的网络验证与原网络验证派生等价。简化后可将网络减少到小于5％的神经元数量，从而减少了相应的验证时间。

    

    在神经网络在安全关键环境中部署之前，形式验证是必不可少的。然而，现有的神经网络形式验证方法还无法处理涉及大量神经元的实际问题。本文提出了一种新方法来解决这个挑战：保守的神经网络简化方法，确保简化后的网络验证派生出原网络的验证。我们的方法同时构造简化网络，验证原始网络及其规范。简化将所有输出相似的非线性层神经元合并，适用于具有任何类型的激活函数，如ReLU，sigmoid和tanh的神经网络。我们的评估表明，我们的方法可以将网络减少到小于神经元数的5％，因此可以将验证时间相似减少。

    Formal verification of neural networks is essential before their deployment in safety-critical settings. However, existing methods for formally verifying neural networks are not yet scalable enough to handle practical problems that involve a large number of neurons. In this work, we propose a novel approach to address this challenge: A conservative neural network reduction approach that ensures that the verification of the reduced network implies the verification of the original network. Our approach constructs the reduction on-the-fly, while simultaneously verifying the original network and its specifications. The reduction merges all neurons of a nonlinear layer with similar outputs and is applicable to neural networks with any type of activation function such as ReLU, sigmoid, and tanh. Our evaluation shows that our approach can reduce a network to less than 5% of the number of neurons and thus to a similar degree the verification time is reduced.
    
[^39]: 1比特矩阵补全的主导-最小化高斯牛顿方法

    A Majorization-Minimization Gauss-Newton Method for 1-Bit Matrix Completion. (arXiv:2304.13940v1 [stat.ML])

    [http://arxiv.org/abs/2304.13940](http://arxiv.org/abs/2304.13940)

    本文提出了一种基于主导-最小化原则，通过低秩矩阵补全解决1比特矩阵补全问题的新方法，称为MMGN。通过应用高斯-牛顿方法，MMGN具有更快的速度和更准确的结果，同时还不太受到潜在矩阵尖锐度的影响。

    

    在1比特矩阵补全中，旨在从部分二进制观测值中估计潜在的低秩矩阵。我们提出了一种称为MMGN的1比特矩阵补全新方法。我们的方法基于主导-最小化（MM）原则，在我们的设置中产生一系列标准低秩矩阵补全问题。我们通过明确强制假定的低秩结构的分解方法解决这些子问题，然后应用高斯-牛顿方法。我们的数值研究和对实际数据的应用表明，MMGN输出的估计结果与现有方法相比较具有可比性且更准确、速度通常更快，并且对潜在矩阵的尖锐度不太敏感。

    In 1-bit matrix completion, the aim is to estimate an underlying low-rank matrix from a partial set of binary observations. We propose a novel method for 1-bit matrix completion called MMGN. Our method is based on the majorization-minimization (MM) principle, which yields a sequence of standard low-rank matrix completion problems in our setting. We solve each of these sub-problems by a factorization approach that explicitly enforces the assumed low-rank structure and then apply a Gauss-Newton method. Our numerical studies and application to a real-data example illustrate that MMGN outputs comparable if not more accurate estimates, is often significantly faster, and is less sensitive to the spikiness of the underlying matrix than existing methods.
    
[^40]: 线性最优偏移嵌入

    Linear Optimal Partial Transport Embedding. (arXiv:2302.03232v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.03232](http://arxiv.org/abs/2302.03232)

    本文提出了线性最优偏移嵌入技术（LOPT），它扩展了（局部）线性化技术到OPT问题上，提高了正测度对之间的计算速度。并且在点云内插和PCA分析中进行了应用。

    

    最优传输（OT）由于在机器学习、统计学和信号处理等领域中的广泛应用而变得越来越受欢迎。然而，平衡质量限制了它在实际问题中的性能。为了解决这些问题，已经提出了OT问题的变体，包括不平衡OT，最优偏移传输（OPT）和Hellinger Kantorovich（HK）。在本文中，我们提出了线性最优偏移（LOPT）嵌入技术，它将OT和HK上的（局部）线性化技术扩展到OPT问题上。所提出的嵌入技术提高了正测度对之间的LOPT距离的计算速度。除了我们的理论贡献，我们还展示了LOPT嵌入技术在点云内插和PCA分析中的应用。

    Optimal transport (OT) has gained popularity due to its various applications in fields such as machine learning, statistics, and signal processing. However, the balanced mass requirement limits its performance in practical problems. To address these limitations, variants of the OT problem, including unbalanced OT, Optimal partial transport (OPT), and Hellinger Kantorovich (HK), have been proposed. In this paper, we propose the Linear optimal partial transport (LOPT) embedding, which extends the (local) linearization technique on OT and HK to the OPT problem. The proposed embedding allows for faster computation of OPT distance between pairs of positive measures. Besides our theoretical contributions, we demonstrate the LOPT embedding technique in point-cloud interpolation and PCA analysis.
    
[^41]: 高效控制重新识别风险的差分隐私数据合成

    Differentially-Private Data Synthetisation for Efficient Re-Identification Risk Control. (arXiv:2212.00484v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.00484](http://arxiv.org/abs/2212.00484)

    本文提出了一种名为ε-PrivateSMOTE的技术，通过噪声引入插值的合成数据生成，以达到保护免受重新识别和链接攻击的风险的目的，并在同时最大限度地保持数据效用的情况下取得了竞争性的结果。

    

    保护用户数据隐私可以通过多种方法实现，从统计转换到生成模型。然而，所有这些方法都存在重要的缺陷。例如，使用传统技术创建转换数据集非常耗时。此外，最近基于深度学习的解决方案除了长时间的训练阶段外，还需要大量的计算资源，而差分隐私解决方案可能会削弱数据效用。在本文中，我们提议了一种名为ε-PrivateSMOTE的技术，用于保护免受重新识别和链接攻击的风险，并特别解决高重新识别风险的情况。我们的提议通过噪声引入插值的合成数据生成，以模糊高风险案例，同时最大限度地保持原始数据的数据效用。与17个数据集上的多个传统和最新隐私保护方法相比，ε-PrivateSMOTE在隐私风险和数据效用方面取得了竞争性的结果。

    Protecting user data privacy can be achieved via many methods, from statistical transformations to generative models. However, all of them have critical drawbacks. For example, creating a transformed data set using traditional techniques is highly time-consuming. Also, recent deep learning-based solutions require significant computational resources in addition to long training phases, and differentially private-based solutions may undermine data utility. In this paper, we propose $\epsilon$-PrivateSMOTE, a technique designed for safeguarding against re-identification and linkage attacks, particularly addressing cases with a high re-identification risk. Our proposal combines synthetic data generation via noise-induced interpolation to obfuscate high-risk cases while maximising the data utility of the original data. Compared to multiple traditional and state-of-the-art privacy-preservation methods on 17 data sets, $\epsilon$-PrivateSMOTE achieves competitive results in privacy risk and b
    
[^42]: 具有最优收敛保证的显式二阶最小最大优化方法

    Explicit Second-Order Min-Max Optimization Methods with Optimal Convergence Guarantee. (arXiv:2210.12860v3 [math.OC] UPDATED)

    [http://arxiv.org/abs/2210.12860](http://arxiv.org/abs/2210.12860)

    本文提出了一种具有最优收敛保证的显式二阶最小最大优化方法，用于解决凸凹无约束最小最大优化问题。该方法利用二阶信息加速额外梯度方法，并且在迭代过程中保持在有界集内，达到了与理论下界相匹配的收敛速度。

    

    本文提出并分析了一种精确和不精确正则化牛顿型方法，用于求解凸凹无约束最小最大优化问题的全局鞍点。与一阶方法相比，我们对于二阶最小最大优化方法的理解相对较少，因为利用二阶信息获得全局收敛速度更加复杂。在本文中，我们研究了如何利用二阶信息加速额外梯度方法，即使在不精确的情况下也能实现。具体而言，我们证明了所提出的算法生成的迭代保持在有界集内，并且平均迭代收敛到一个 $\epsilon$-鞍点，所需迭代次数为 $O(\epsilon^{-2/3})$，其中使用了受限间隙函数。我们的算法与该领域已经建立的理论下界相匹配，而且我们的分析提供了一种简单直观的二阶方法收敛分析，不需要任何有界性要求。最后，我们提出了一个

    We propose and analyze exact and inexact regularized Newton-type methods for finding a global saddle point of \emph{convex-concave} unconstrained min-max optimization problems. Compared to first-order methods, our understanding of second-order methods for min-max optimization is relatively limited, as obtaining global rates of convergence with second-order information is much more involved. In this paper, we examine how second-order information can be used to speed up extra-gradient methods, even under inexactness. Specifically, we show that the proposed algorithms generate iterates that remain within a bounded set and the averaged iterates converge to an $\epsilon$-saddle point within $O(\epsilon^{-2/3})$ iterations in terms of a restricted gap function. Our algorithms match the theoretically established lower bound in this context and our analysis provides a simple and intuitive convergence analysis for second-order methods without any boundedness requirements. Finally, we present a 
    

