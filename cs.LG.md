# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [DiffusionMTL: Learning Multi-Task Denoising Diffusion Model from Partially Annotated Data](https://arxiv.org/abs/2403.15389) | DiffusionMTL 提出了一个新型多任务去噪扩散框架，通过联合扩散和去噪来改善部分标注数据中的多任务密集场景理解，进一步引入了多任务条件策略来利用任务的互补性。 |
| [^2] | [LATTE3D: Large-scale Amortized Text-To-Enhanced3D Synthesis](https://arxiv.org/abs/2403.15385) | LATTE3D通过构建可扩展的架构、利用3D数据并采用摊还方法，在显著更大的提示集上实现快速、高质量的文本增强3D合成。 |
| [^3] | [Can large language models explore in-context?](https://arxiv.org/abs/2403.15371) | 研究发现，大型语言模型在没有实质干预的情况下很难有效进行探索，除了特定配置下的GPT-4具有满意的探索行为外，其他模型表现不稳定。 |
| [^4] | [Augmented Reality based Simulated Data (ARSim) with multi-view consistency for AV perception networks](https://arxiv.org/abs/2403.15370) | 提出了ARSim，一个全自动、综合、模块化的框架，旨在通过将3D合成对象整合到真实的多视图图像数据中，通过领域适应和随机化策略来解决真实与合成数据之间的协变量转移问题 |
| [^5] | [A Transfer Attack to Image Watermarks](https://arxiv.org/abs/2403.15365) | 水印领域的研究表明，即使在攻击者无法访问水印模型或检测API的情况下，水印基础的AI生成图像检测器也无法抵抗对抗攻击。 |
| [^6] | [Cascading Blackout Severity Prediction with Statistically-Augmented Graph Neural Networks](https://arxiv.org/abs/2403.15363) | 用统计增强图神经网络进行级联停电严重性预测，提出了两种新技术，一是通过初始分类步骤过滤安全情景，二是利用级联停电的统计属性促进非局部消息传递。 |
| [^7] | [Learning Topological Representations for Deep Image Understanding](https://arxiv.org/abs/2403.15361) | 提出了在深度学习框架中利用拓扑数据分析方法提高对图像中复杂结构的分割和不确定性估计，为可伸缩注释提供了强大工具。 |
| [^8] | [SiMBA: Simplified Mamba-Based Architecture for Vision and Multivariate Time series](https://arxiv.org/abs/2403.15360) | SiMBA是一种引入Einstein FFT进行通道建模并使用Mamba块进行序列建模的新架构，在图像和时间序列基准上优于现有的SSMs。 |
| [^9] | [Ultrasound Imaging based on the Variance of a Diffusion Restoration Model](https://arxiv.org/abs/2403.15316) | 结合超声线性直接模型和去噪扩散模型学习先验的混合重建方法，通过对预训练的去噪扩散恢复模型进行无监督微调，提出了一种用于表征超声图像扩散重建随机性的经验模型。 |
| [^10] | [A Wasserstein perspective of Vanilla GANs](https://arxiv.org/abs/2403.15312) | 将普通GANs与水斯坦距离联系起来，扩展现有水斯坦GANs结果到普通GANs，获得了普通GANs的神谕不等式。 |
| [^11] | [Controlled Training Data Generation with Diffusion Models](https://arxiv.org/abs/2403.15309) | 提出了一种使用扩散模型生成控制训练数据的方法，通过两个反馈机制，一方面使用监督模型反馈找到对抗性提示词实现图像生成，另一方面通过引导使生成过程朝向特定目标分布。 |
| [^12] | [KTbench: A Novel Data Leakage-Free Framework for Knowledge Tracing](https://arxiv.org/abs/2403.15304) | KTbench提出了一种无数据泄漏的知识追踪框架，解决了KT模型中KC之间的相关性学习可能导致的性能下降问题。 |
| [^13] | [Planning with a Learned Policy Basis to Optimally Solve Complex Tasks](https://arxiv.org/abs/2403.15301) | 使用继承特征学习策略基础，使每个（子）策略解决一个子问题，在FSA描述的任务中，组合这些（子）策略可用于无需额外学习生成最优解决方案，方法能够渐近达到全局最优性，即使在随机环境中也如此。 |
| [^14] | [Blockchain-based Pseudonym Management for Vehicle Twin Migrations in Vehicular Edge Metaverse](https://arxiv.org/abs/2403.15285) | 通过基于区块链的匿名管理，本研究解决了车载边缘元宇宙中车辆双子迁移过程中的隐私泄露问题 |
| [^15] | [Parametric PDE Control with Deep Reinforcement Learning and Differentiable L0-Sparse Polynomial Policies](https://arxiv.org/abs/2403.15267) | 使用字典学习和可微分L$_0$正则化方法，本文提出了一种稀疏、鲁棒、可解释的控制策略，适用于参数PDE系统。 |
| [^16] | [Federated Bayesian Deep Learning: The Application of Statistical Aggregation Methods to Bayesian Models](https://arxiv.org/abs/2403.15263) | 该论文研究了联邦贝叶斯深度学习的方法，旨在解决在现代深度学习模型中传达认识不确定性的挑战。 |
| [^17] | [Comprehensive Reassessment of Large-Scale Evaluation Outcomes in LLMs: A Multifaceted Statistical Approach](https://arxiv.org/abs/2403.15250) | 评估大规模LLM中因素对性能的影响通过全面的统计分析，有助于更好地理解和推动这些模型的发展 |
| [^18] | [Spectral Motion Alignment for Video Motion Transfer using Diffusion Models](https://arxiv.org/abs/2403.15249) | 提出了一种名为Spectral Motion Alignment（SMA）的新框架，通过傅立叶和小波变换来优化和对齐运动向量，学习整帧全局运动动态，减轻空间伪影，有效改善运动转移。 |
| [^19] | [FollowIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions](https://arxiv.org/abs/2403.15246) | 该论文引入了FollowIR数据集，包含严格的说明书评估基准和训练集，帮助信息检索模型更好地遵循真实世界的说明书。议论基于TREC会议的历史，旨在使信息检索模型能够根据详细说明书理解和判断相关性。 |
| [^20] | [Reasoning-Enhanced Object-Centric Learning for Videos](https://arxiv.org/abs/2403.15245) | 设计了一种新颖的推理模块STATM，利用记忆缓冲区增强模型在复杂场景中的感知能力。 |
| [^21] | [A Stochastic Quasi-Newton Method for Non-convex Optimization with Non-uniform Smoothness](https://arxiv.org/abs/2403.15244) | 论文提出了一种针对非凸优化问题的随机拟牛顿方法，适用于具有非均匀平滑度的情况，其创新之处在于引入了$(L_0, L_1)$-平滑度，相比传统的$L$-平滑度，能更好地捕捉平滑度与梯度范数之间的正相关关系。 |
| [^22] | [Robust Utility Optimization via a GAN Approach](https://arxiv.org/abs/2403.15243) | 提出了一种生成对抗网络（GAN）方法，用于解决一般和现实设置下的稳健效用优化问题，该方法在实证研究中表现出色，能在没有已知最佳策略的情况下胜过所有其他参考策略 |
| [^23] | [Guided Decoding for Robot Motion Generation and Adaption](https://arxiv.org/abs/2403.15239) | 通过将演示学习集成到运动生成中，使机器人能够实时生成适应复杂环境的运动 |
| [^24] | [An Exploratory Investigation into Code License Infringements in Large Language Model Training Datasets](https://arxiv.org/abs/2403.15230) | 该研究调查了大型语言模型训练数据集中的代码许可侵权问题，发现每个数据集都存在许可不一致性，尽管它们是基于相关代码仓库许可证来选择的。 |
| [^25] | [Anytime, Anywhere, Anyone: Investigating the Feasibility of Segment Anything Model for Crowd-Sourcing Medical Image Annotations](https://arxiv.org/abs/2403.15218) | 该研究探讨了使用部分任意模型（SAM）在众包环境中从非专家处策划医学图像标注的可行性，以生成用于训练3D DL分割模型的"密集"分割掩模。 |
| [^26] | [Early Period of Training Impacts Out-of-Distribution Generalization](https://arxiv.org/abs/2403.15210) | 神经网络训练早期阶段的影响对超出分布泛化进行了研究，通过探究学习动态和用于调查的渐进解冻方法，揭示了其重要性。 |
| [^27] | [Robust optimization for adversarial learning with finite sample complexity guarantees](https://arxiv.org/abs/2403.15207) | 本文提出了一种针对对抗学习的鲁棒分类器的新型训练方法，通过最小化最坏情况下的替代损失来实现，同时在线性和非线性模型上推导出了有限样本复杂性界限。 |
| [^28] | [FSD-Inference: Fully Serverless Distributed Inference with Scalable Cloud Communication](https://arxiv.org/abs/2403.15195) | FSD-Inference是第一个完全无服务器且高度可扩展的分布式ML推断系统，引入了全新的无服务器通信方案。 |
| [^29] | [Your Image is My Video: Reshaping the Receptive Field via Image-To-Video Differentiable AutoAugmentation and Fusion](https://arxiv.org/abs/2403.15194) | 通过Differentiable Augmentation Search (DAS) 方法，能够快速生成可处理为视频的图像变体，以提高模型对数据的利用效率。 |
| [^30] | [PDE-CNNs: Axiomatic Derivations and Applications](https://arxiv.org/abs/2403.15182) | PDE-CNNs通过利用几何意义的演化PDE的求解器替代传统的组件，提供了更少的参数、固有的等变性、更好的性能、数据效率和几何可解释性。 |
| [^31] | [Self-Improvement for Neural Combinatorial Optimization: Sample without Replacement, but Improvement](https://arxiv.org/abs/2403.15180) | 通过结合循环式随机束搜索和来自可证策略改进的更新策略，本研究在神经组合优化中引入了一种新的训练方法，从而在最小采样次数中实现逐步改进的解决方案。 |
| [^32] | [Exploring the Task-agnostic Trait of Self-supervised Learning in the Context of Detecting Mental Disorders](https://arxiv.org/abs/2403.15170) | 本研究探索了在检测主要抑郁症和创伤后应激障碍时，在交互会话期间收集的音频和视频数据上使用自监督学习的任务无关表示。 |
| [^33] | [Transition Graph Properties of Target Class Classification](https://arxiv.org/abs/2403.15167) | 目标类分类的关键在于转换图的属性，研究表明理想的转换图结构是朝根顶点方向取向的有根树。 |
| [^34] | [An In-Depth Analysis of Data Reduction Methods for Sustainable Deep Learning](https://arxiv.org/abs/2403.15150) | 本文深度分析了深度学习数据减少方法对提升效率的作用，提出了多种减小训练数据集大小的方法，并开发了用于衡量数据集相似度的拓扑代表性度量。 |
| [^35] | [On the Convergence of Adam under Non-uniform Smoothness: Separability from SGDM and Beyond](https://arxiv.org/abs/2403.15146) | Adam在非均匀光滑情况下与SGDM的收敛速率有明显区别，Adam更快地达到收敛，并具有更低的下界。 |
| [^36] | [Quantification using Permutation-Invariant Networks based on Histograms](https://arxiv.org/abs/2403.15123) | 本文研究了深度神经网络在量化任务中的应用，提出了基于直方图的置换不变网络HistNetQ，在量化比赛中表现优异。 |
| [^37] | [Text clustering with LLM embeddings](https://arxiv.org/abs/2403.15112) | 研究表明，LLM嵌入能够捕捉结构化语言的细微差别，BERT在性能上领先于轻量级选项，增加嵌入维度和摘要技术并不一致地提高聚类效率 |
| [^38] | [Active Learning for Regression based on Wasserstein distance and GroupSort Neural Networks](https://arxiv.org/abs/2403.15108) | 该论文提出了一种基于Wasserstein距离和GroupSort神经网络的主动学习方法，该方法在回归问题中实现了更精确的估计并比其他模型更快提高准确性。 |
| [^39] | [Improving cross-domain brain tissue segmentation in fetal MRI with synthetic data](https://arxiv.org/abs/2403.15103) | 提出了FetalSynthSeg方法，用于改进胎儿MRI中的脑组织分割，通过领域随机化方法，模型在跨领域数据集上的效果优于传统模型。 |
| [^40] | [End-to-End Mineral Exploration with Artificial Intelligence and Ambient Noise Tomography](https://arxiv.org/abs/2403.15095) | 该论文提出了一种端到端工作流程，将环境噪声层析成像（ANT）和人工智能（AI）相结合，以增强对于铜等矿产资源的发现和描绘。 |
| [^41] | [Improved Long Short-Term Memory-based Wastewater Treatment Simulators for Deep Reinforcement Learning](https://arxiv.org/abs/2403.15091) | 改进长短期记忆污水处理模拟器，解决DRL优化工业过程中的挑战，通过减少复合误差提高模型的准确性 |
| [^42] | [SIMAP: A simplicial-map layer for neural networks](https://arxiv.org/abs/2403.15083) | SIMAP是一个神经网络图层，与其他深度学习架构结合，作为可解释图层替代经典的密集最终图层，支持集基于固定的最大单纯体。 |
| [^43] | [Automated Feature Selection for Inverse Reinforcement Learning](https://arxiv.org/abs/2403.15079) | 提出了一种使用多项式基函数进行特征选择的方法，通过匹配状态分布的统计矩和利用轨迹概率与特征期望的相关性，有效地恢复奖励函数。 |
| [^44] | [GTAGCN: Generalized Topology Adaptive Graph Convolutional Networks](https://arxiv.org/abs/2403.15077) | GTAGCN提出了一种基于广义聚合网络和拓扑自适应图卷积网络的混合方法，可以有效应用于序列数据和静态数据，适用于节点和图分类，实证分析显示结果良好。 |
| [^45] | [On the Inclusion of Charge and Spin States in Cartesian Tensor Neural Network Potentials](https://arxiv.org/abs/2403.15073) | TensorNet扩展了其能力，可以处理带电分子和自旋状态，提高了模型在各种化学系统中的预测准确性。 |
| [^46] | [Cartoon Hallucinations Detection: Pose-aware In Context Visual Learning](https://arxiv.org/abs/2403.15048) | 该研究提出了一种用于检测由TTI模型生成的卡通角色图像中视觉幻觉的系统，通过结合姿势感知上下文视觉学习和视觉语言模型，利用RGB图像和姿势信息，实现了更准确的决策，显著提高了视觉幻觉的识别能力，推动了TTI模型在非照片真实领域的发展。 |
| [^47] | [DP-Dueling: Learning from Preference Feedback without Compromising User Privacy](https://arxiv.org/abs/2403.15045) | 提出了第一个针对带用户偏好的主动学习的差分私密对抗式双臂老虎机算法，并在计算效率方面表现优异，同时具有接近最优的私密和非私密遗憾上界。 |
| [^48] | [Estimation of multiple mean vectors in high dimension](https://arxiv.org/abs/2403.15038) | 通过凸组合的方法估计高维空间中不同概率分布的多维均值，引入了两种权重确定策略：一种通过测试程序识别低方差的相邻均值，提出了封闭形式插补公式；另一种通过最小化二次风险的上置信界确定权重，通过理论分析得出方法对经验均值的二次风险改进，在维度渐近的角度上渐近地接近 Oracle（Minimax）改进。 |
| [^49] | [Image Classification with Rotation-Invariant Variational Quantum Circuits](https://arxiv.org/abs/2403.15031) | 提出了一种使用旋转不变变分量子电路进行图像分类的等变架构，通过引入几何归纳偏差，成功提升了模型性能。 |
| [^50] | [Grey-informed neural network for time-series forecasting](https://arxiv.org/abs/2403.15027) | 本研究提出了灰色信息神经网络（GINN），通过遵循灰色系统的微分方程模型，提高了神经网络输出的可解释性，使其能够有效处理小数据样本，产生可靠的预测。 |
| [^51] | [Robust Conformal Prediction under Distribution Shift via Physics-Informed Structural Causal Model](https://arxiv.org/abs/2403.15025) | 通过引入物理信息指导的结构因果模型，我们提出了一种在分布转移下稳健的符合预测方法。 |
| [^52] | [Insights into the Lottery Ticket Hypothesis and the Iterative Magnitude Pruning](https://arxiv.org/abs/2403.15022) | 通过对迭代幅度剪枝过程中不同阶段获得的解决方案的体积/几何和损失景观特征进行经验研究，我们试图洞察走势彩票假设和迭代幅度剪枝中的现象。 |
| [^53] | [Vehicle Detection Performance in Nordic Region](https://arxiv.org/abs/2403.15017) | 本研究针对北欧恶劣冬季条件下车辆检测的挑战，使用北欧车辆数据集评估了最先进的检测算法性能，并提出了针对每种检测框架的一系列增强措施。 |
| [^54] | [Empirical investigation of multi-source cross-validation in clinical machine learning](https://arxiv.org/abs/2403.15012) | 本研究在多源环境中系统地评估了标准K折交叉验证和留出源交叉验证方法，为实现更全面和真实的精确度评估提供了新的机会 |
| [^55] | [ParFormer: Vision Transformer Baseline with Parallel Local Global Token Mixer and Convolution Attention Patch Embedding](https://arxiv.org/abs/2403.15004) | ParFormer提出了并行局部全局标记混合器和卷积注意力补丁嵌入，优化了特征提取能力，在图像分类和对象识别等任务中表现优于CNN和最先进的Transformer架构。 |
| [^56] | [Magic for the Age of Quantized DNNs](https://arxiv.org/abs/2403.14999) | 提出了一种量化感知训练方法，引入新型标准化方法并使用缩放量化加权，实现了在最小精度降级的情况下有效的量化深度神经网络 |
| [^57] | [Piecewise-Linear Manifolds for Deep Metric Learning](https://arxiv.org/abs/2403.14977) | 提出了一种在深度度量学习中使用分段线性流形的方法，并通过模拟高维数据流形来改善相似性估计，从而提高了无监督度量学习的性能。 |
| [^58] | [Trajectory Regularization Enhances Self-Supervised Geometric Representation](https://arxiv.org/abs/2403.14973) | 引入新的pose-estimation基准用于评估SSL几何表示，提出无监督轨迹正则化损失来增强SSL几何表示，在姿势估计性能上取得10-20%的提升，并提高了4%的性能和泛化能力。 |
| [^59] | [Adapprox: Adaptive Approximation in Adam Optimization via Randomized Low-Rank Matrices](https://arxiv.org/abs/2403.14958) | Adapprox是一种采用随机低秩矩阵近似的自适应方法，用于更有效和准确地逼近Adam优化算法的二阶矩。在GPT-2的训练和下游任务中，Adapprox相比AdamW能够实现34.5%至49.9%和33.8%至49.9%的内存节约，并通过余弦相似性指导策略提高了稳定性和加快了收敛速度。 |
| [^60] | [Simple Graph Condensation](https://arxiv.org/abs/2403.14951) | 提出了一种简化的图压缩方法，旨在减少图神经网络所带来的不必要复杂性。 |
| [^61] | [KnowLA: Enhancing Parameter-efficient Finetuning with Knowledgeable Adaptation](https://arxiv.org/abs/2403.14950) | 该论文提出了一种名为KnowLA的知识自适应方法，通过在大型语言模型中插入自适应层和知识图嵌入，能够提升参数高效微调的有效性和鲁棒性。 |
| [^62] | [Addressing Concept Shift in Online Time Series Forecasting: Detect-then-Adapt](https://arxiv.org/abs/2403.14949) | 提出了一种名为Concept Drift Detection and Adaptation（D3A）的新方法，通过检测漂移概念并在检测后积极调整模型来解决在线时间序列预测中遇到的概念漂移问题。 |
| [^63] | [A Single Linear Layer Yields Task-Adapted Low-Rank Matrices](https://arxiv.org/abs/2403.14946) | 通过研究转换矩阵将$ W_0 $转换为低秩矩阵的关系信息，我们提出单一线性层可以生成任务自适应的低秩矩阵。 |
| [^64] | [Unifying Lane-Level Traffic Prediction from a Graph Structural Perspective: Benchmark and Baseline](https://arxiv.org/abs/2403.14941) | 本文提出了一个简单的基线模型GraphMLP，基于图结构和MLP网络，在车道级交通预测中建立了统一的空间拓扑结构和预测任务，帮助突破了现有评估标准和数据公开性的限制。 |
| [^65] | [Contrastive Learning on Multimodal Analysis of Electronic Health Records](https://arxiv.org/abs/2403.14926) | 该论文研究了电子健康记录的多模态分析，强调了结构化和非结构化数据之间的协同作用，并尝试将多模态对比学习方法应用于提高患者医疗历史的完整性。 |
| [^66] | [CODA: A COst-efficient Test-time Domain Adaptation Mechanism for HAR](https://arxiv.org/abs/2403.14922) | CODA 提出了一种节约成本的测试时域自适应机制，通过主动学习理论处理实时漂移，实现在设备上直接进行成本有效的自适应，并保留数据分布中的有意义结构。 |
| [^67] | [Deep learning-based method for weather forecasting: A case study in Itoshima](https://arxiv.org/abs/2403.14918) | 该研究提出了一个针对日本九州糸島天气预测的多层感知器模型，表现出比现有模型更优越的性能。 |
| [^68] | [Mean-field Analysis on Two-layer Neural Networks from a Kernel Perspective](https://arxiv.org/abs/2403.14917) | 本文通过核方法的视角研究了两层神经网络在平均场极限下的特征学习能力，展示了它们比任何核方法更有效地学习多个再现核希尔伯特空间的并集，并且神经网络会获得与目标函数对齐的数据相关核。 |
| [^69] | [Adaptive Coded Federated Learning: Privacy Preservation and Straggler Mitigation](https://arxiv.org/abs/2403.14905) | ACFL提出了一种新的自适应编码联邦学习方法，通过在训练之前采用个性化的数据上传到中央服务器来生成全局编码数据集，以解决原有固定权重生成全局编码数据集时可能导致学习性能下降的问题。 |
| [^70] | [Hydro: Adaptive Query Processing of ML Queries](https://arxiv.org/abs/2403.14902) | 该论文提出了一种Hydro系统，用于处理机器学习查询，通过动态调整查询计划以适应数据的变化，解决了传统DBMSs在处理ML查询时遇到的性能瓶颈和优化挑战。 |
| [^71] | [Web-based Melanoma Detection](https://arxiv.org/abs/2403.14898) | 本研究提出了一种统一的黑色素瘤分类方法，支持多种数据集和深度学习架构组合，能够以极快的速度和高准确率进行实时的黑色素瘤检测。 |
| [^72] | [WeatherProof: Leveraging Language Guidance for Semantic Segmentation in Adverse Weather](https://arxiv.org/abs/2403.14874) | 该论文提出了一种在恶劣天气条件下进行语义分割的方法，通过引入语言指导以提高模型的鲁棒性。 |
| [^73] | [VidLA: Video-Language Alignment at Scale](https://arxiv.org/abs/2403.14870) | VidLA 提出了一种规模化视频语言对齐方法，通过简化网络架构和使用分层数据令牌来捕捉短程和长程时间依赖关系，从而成功融合预训练图像-文本基础模型，提高了最终性能。 |
| [^74] | [Distribution-informed and wavelength-flexible data-driven photoacoustic oximetry](https://arxiv.org/abs/2403.14863) | 该研究提出了一种基于递归神经网络架构的方法，解决了传声成像中现有数据驱动方法对血氧饱和度估计的不灵活性。 |
| [^75] | [Robust Model Based Reinforcement Learning Using $\mathcal{L}_1$ Adaptive Control](https://arxiv.org/abs/2403.14860) | 本研究引入了一种使用$\mathcal{L}_1$自适应控制的鲁棒性基于模型的强化学习方法，通过增强系统对不确定性的鲁棒性，提高了MBRL算法的性能和样本效率。 |
| [^76] | [iSpLib: A Library for Accelerating Graph Neural Networks using Auto-tuned Sparse Operations](https://arxiv.org/abs/2403.14853) | iSpLib是一个基于PyTorch的C++库，提供了自动调优的稀疏操作，加速了图神经网络的训练，并通过缓存优化和用户友好的Python插件实现了简便的操作。 |
| [^77] | [Output-Constrained Lossy Source Coding With Application to Rate-Distortion-Perception Theory](https://arxiv.org/abs/2403.14849) | 分析了具有有限通用随机性的输出受限失真源编码在均方误差失真度量下的特殊情况，推导出了高斯分布情况下的明确表达式，并部分刻画了二次高斯速率-失真-感知编码的信息论极限。 |
| [^78] | [Learning WENO for entropy stable schemes to solve conservation laws](https://arxiv.org/abs/2403.14848) | 提出了一种称为Deep Sign-Preserving WENO（DSP-WENO）的变种，通过神经网络学习WENO加权策略，以改进在震荡附近表现不佳的WENO算法。 |
| [^79] | [Local Causal Discovery with Linear non-Gaussian Cyclic Models](https://arxiv.org/abs/2403.14843) | 提出一种通用的、统一的局部因果发现方法，使用线性非高斯模型，实现了从目标变量的马尔可夫毯中精确识别等效的局部有向结构和因果强度 |
| [^80] | [Model order reduction of deep structured state-space models: A system-theoretic approach](https://arxiv.org/abs/2403.14833) | 通过系统论方法针对深度结构状态空间模型的线性动态块进行模型降阶，引入了模态$\ell_1$和Hankel核范数正则化，促进稀疏性，可在不牺牲准确性的前提下仅保留相关状态。 |
| [^81] | [Deep Clustering Evaluation: How to Validate Internal Clustering Validation Measures](https://arxiv.org/abs/2403.14830) | 本文解决了深度聚类方法在评估聚类质量时面临的挑战，提出了一种系统方法来应用聚类有效性指标。 |
| [^82] | [Hyperbolic Secant representation of the logistic function: Application to probabilistic Multiple Instance Learning for CT intracranial hemorrhage detection](https://arxiv.org/abs/2403.14829) | 通过使用P\'olya-Gamma随机变量制定VGPMIL，该方法产生与原始VGPMIL相同的变分后验近似，这是双曲正割分布所承认的两种表示的结果。 |
| [^83] | [Non-Convex Robust Hypothesis Testing using Sinkhorn Uncertainty Sets](https://arxiv.org/abs/2403.14822) | 提出了使用Sinkhorn不确定性集解决非凸鲁棒假设检验问题的新框架，并引入了确切的混合整数指数锥重构方法，证明了优于目前文献中最先进方法的凸逼近。 |
| [^84] | [The opportunities and risks of large language models in mental health](https://arxiv.org/abs/2403.14814) | 大型语言模型在心理健康领域有望提供新颖的解决方案，但应注意其应用可能带来的风险，并积极采取策略减轻这些风险。 |
| [^85] | [Curvature Augmented Manifold Embedding and Learning](https://arxiv.org/abs/2403.14813) | 将降维问题建模为机械/物理模型，引入曲率增强力的曲率增强流形嵌入与学习（CAMEL）方法提供了一种新的方法来捕捉数据集的n维流形表示。 |
| [^86] | [Deep Active Learning: A Reality Check](https://arxiv.org/abs/2403.14800) | 深度主动学习方法的全面评估发现在一般情况下，没有单一模型方法能明显优于基于熵的主动学习，同时揭示了起始预算、预算步长和预训练等因素对取得优越结果的重要性，并拓展了在其他任务中的应用。 |
| [^87] | [Preventing Catastrophic Forgetting through Memory Networks in Continuous Detection](https://arxiv.org/abs/2403.14797) | 通过引入记忆网络和局部查询函数，这项工作致力于在连续检测中防止灾难性遗忘，并解决了持续检测中的背景贬低问题。 |
| [^88] | [Multi-Agent VQA: Exploring Multi-Agent Foundation Models in Zero-Shot Visual Question Answering](https://arxiv.org/abs/2403.14783) | 本研究提出了一种自适应多智体系统，名为多智体VQA，通过使用专门的智体工具，克服了基础模型在目标检测和计数中的局限性，在零样本情况下实现了良好的性能，为未来研究提供了新的方向。 |
| [^89] | [Few-Shot Adversarial Prompt Learning on Vision-Language Models](https://arxiv.org/abs/2403.14774) | 本文提出了一个少样本对抗提示框架，在视觉-语言模型中通过有限数据调整输入序列，显著提升对抗鲁棒性，并通过端到端学习对抗性相关的文本监督。 |
| [^90] | [StreamingT2V: Consistent, Dynamic, and Extendable Long Video Generation from Text](https://arxiv.org/abs/2403.14773) | StreamingT2V是一种自回归方法，用于生成长视频，可以产生80、240、600、1200帧甚至更多帧的视频，并具有平滑的过渡。 |
| [^91] | [Improving Robustness to Model Inversion Attacks via Sparse Coding Architectures](https://arxiv.org/abs/2403.14772) | 通过稀疏编码层设计新网络架构以提高对模型逆推攻击的鲁棒性。 |
| [^92] | [Learning with SASQuaTCh: a Novel Variational Quantum Transformer Architecture with Kernel-Based Self-Attention](https://arxiv.org/abs/2403.14753) | 本研究提出了一种通过核自注意力来学习的新型变分量子变压器架构，可以用简单的卷积核表示深层的视觉变压器网络。 |
| [^93] | [A Classifier-Based Approach to Multi-Class Anomaly Detection for Astronomical Transients](https://arxiv.org/abs/2403.14742) | 使用神经网络分类器的倒数第二层作为异常检测的潜在空间，并提出了一种名为多类孤立森林（MCIF）的新方法来训练每个类别的孤立森林，以推导异常值 |
| [^94] | [A task of anomaly detection for a smart satellite Internet of things system](https://arxiv.org/abs/2403.14738) | 提出了一种基于生成对抗网络和自注意机制的无监督深度学习异常检测系统 |
| [^95] | [FedMef: Towards Memory-efficient Federated Dynamic Pruning](https://arxiv.org/abs/2403.14737) | FedMef提出了一种新颖且内存高效的联邦动态剪枝框架，通过预算感知的挤出机制和缩放激活剪枝来解决联邦学习中的性能退化和高激活内存使用等挑战。 |
| [^96] | [NaNa and MiGu: Semantic Data Augmentation Techniques to Enhance Protein Classification in Graph Neural Networks](https://arxiv.org/abs/2403.14736) | 提出了NaNa和MiGu两种语义数据增强方法，结合了蛋白质的主链化学和侧链生物物理信息，用于增强图神经网络中的蛋白质分类任务。 |
| [^97] | [Foundation Models for Time Series Analysis: A Tutorial and Survey](https://arxiv.org/abs/2403.14735) | Foundation Models为时间序列分析带来创新，利用预训练或微调的模型来获得具体定制的广义知识，提升了实践中多个下游任务的效果。 |
| [^98] | [Open Knowledge Base Canonicalization with Multi-task Learning](https://arxiv.org/abs/2403.14733) | 提出了一个多任务学习框架MulCanon来处理开放知识库（OKB）规范化问题，并通过在软聚类过程中使用扩散模型来改进名词短语的表示。 |
| [^99] | [Reversible Jump Attack to Textual Classifiers with Modification Reduction](https://arxiv.org/abs/2403.14731) | 提出了两种算法，可逆跳动攻击（RJA）和Metropolis-Hasting修改缩减（MMR），用于生成高度有效的对抗示例，并分别改善示例的不可察觉性。 |
| [^100] | [Auto-Train-Once: Controller Network Guided Automatic Network Pruning from Scratch](https://arxiv.org/abs/2403.14729) | 提出了Auto-Train-Once（ATO）网络剪枝算法，利用控制器网络自动降低DNN的计算和存储成本，并通过新颖的随机梯度算法增强协调性。 |
| [^101] | [Protected group bias and stereotypes in Large Language Models](https://arxiv.org/abs/2403.14727) | 该研究调查了大型语言模型在伦理和公平领域中的行为，发现模型不仅反映了社会偏见，还似乎放大了这些偏见。 |
| [^102] | [Jailbreaking is Best Solved by Definition](https://arxiv.org/abs/2403.14725) | 语言模型中"越狱"攻击的关键是通过定义好的不安全响应来进行防御，而不是依赖于执行策略。 |
| [^103] | [Six Levels of Privacy: A Framework for Financial Synthetic Data](https://arxiv.org/abs/2403.14724) | 该论文介绍了一种用于金融合成数据的“隐私层次”层级，有助于评估隐私保护程度和分类生成方法。 |
| [^104] | [Defending Against Indirect Prompt Injection Attacks With Spotlighting](https://arxiv.org/abs/2403.14720) | 引入了聚焦技术，一种提示工程技术，用于改进大型语言模型在处理多个输入源时的能力，通过提供可靠的输入来源信号来防御间接提示注入攻击。 |
| [^105] | [Bypassing LLM Watermarks with Color-Aware Substitutions](https://arxiv.org/abs/2403.14719) | 提出了第一种“色彩感知”攻击方法——基于自我颜色测试的替换（SCTS），成功地规避了LLM水印检测。 |
| [^106] | [FedSR: A Semi-Decentralized Federated Learning Algorithm for Non-IIDness in IoT System](https://arxiv.org/abs/2403.14718) | FedSR提出了一种半分散式的云-边缘-设备分层联邦学习框架，旨在解决在物联网系统中出现的数据分布不均和通信资源有限的问题。 |
| [^107] | [Distributed Learning based on 1-Bit Gradient Coding in the Presence of Stragglers](https://arxiv.org/abs/2403.14716) | 提出了一种基于1比特梯度编码的新型分布式学习方法，能够在存在滞后者的情况下降低通信负担，并在凸损失函数和非凸损失函数下具有收敛保证，实验证明其性能优于基准方法。 |
| [^108] | [Understanding Why Label Smoothing Degrades Selective Classification and How to Fix It](https://arxiv.org/abs/2403.14715) | LS方法在深度神经网络分类器训练中的标签平滑效果被发现会负面影响选择性分类，通过影响模型预测不确定性，此研究阐明了这一现象。 |
| [^109] | [Compiler generated feedback for Large Language Models](https://arxiv.org/abs/2403.14714) | 该研究提出了一种利用大型语言模型进行编译器优化反馈的新范式，能够在优化LLVM汇编代码大小方面取得额外改进。 |
| [^110] | [Auditing Fairness under Unobserved Confounding](https://arxiv.org/abs/2403.14713) | 在未观测混杂因素的情况下，本文展示了即使在放宽或甚至在排除所有相关风险因素被观测到的假设的情况下，仍然可以给出对高风险个体分配率的信息丰富的界限。 |
| [^111] | [Human-in-the-Loop AI for Cheating Ring Detection](https://arxiv.org/abs/2403.14711) | 本文介绍了一种人在环AI作弊环检测系统，通过设计原则、评估方法及符合负责任AI标准，实现了检测作弊者的目标。 |
| [^112] | [ClimateQ&A: Bridging the gap between climate scientists and the general public](https://arxiv.org/abs/2403.14709) | 通过分析ClimateQ&A平台上提出的问题，研究公众对气候变化和生物多样性损失的看法，为使自然科学更易接近和收集分析问题提供新的视角。 |
| [^113] | [Chain-structured neural architecture search for financial time series forecasting](https://arxiv.org/abs/2403.14695) | 在金融时间序列预测领域，比较了贝叶斯优化、超带方法和强化学习等神经架构搜索策略。 |
| [^114] | [Incorporating Graph Attention Mechanism into Geometric Problem Solving Based on Deep Reinforcement Learning](https://arxiv.org/abs/2403.14690) | 提出了基于深度强化学习的图注意机制，用于自动且高效地添加几何问题中的辅助组件 |
| [^115] | [Developing and Deploying Industry Standards for Artificial Intelligence in Education (AIED): Challenges, Strategies, and Future Directions](https://arxiv.org/abs/2403.14689) | 教育领域人工智能的发展需要制定和实施产业标准，以解决互操作性、可扩展性和道德治理等挑战。 |
| [^116] | [Kernel Alignment for Unsupervised Feature Selection via Matrix Factorization](https://arxiv.org/abs/2403.14688) | 该论文提出了一种通过整合核函数和核对齐实现无监督特征选择的方法，并进一步提出了基于多核学习的方法。 |
| [^117] | [On the Performance of Imputation Techniques for Missing Values on Healthcare Datasets](https://arxiv.org/abs/2403.14687) | 本研究比较了七种填补技术在健康数据集上的性能，结果显示... |
| [^118] | [Cyclical Log Annealing as a Learning Rate Scheduler](https://arxiv.org/abs/2403.14685) | 该论文介绍了一种新的对数方法作为学习率调度器，通过更积极的重启模式，可能使得在在线凸优化框架上使用更贪婪的算法，实验结果表明它性能类似于余弦退火方案。 |
| [^119] | [FOCIL: Finetune-and-Freeze for Online Class Incremental Learning by Training Randomly Pruned Sparse Experts](https://arxiv.org/abs/2403.14684) | FOCIL通过训练随机修剪稀疏子网络实现在线持续类递增学习，在避免存储重放数据的同时有效防止遗忘。 |
| [^120] | [A Moral Imperative: The Need for Continual Superalignment of Large Language Models](https://arxiv.org/abs/2403.14683) | 实现终身超对齐需要对当前大型语言模型架构进行重大变革，以解决其在理解和适应动态人类道德和不断发展的全球情景方面的局限性。 |
| [^121] | [Deep Generative Domain Adaptation with Temporal Relation Knowledge for Cross-User Activity Recognition](https://arxiv.org/abs/2403.14682) | 该研究引入了一种CVAE-USM方法，通过放松独立同分布假设和利用时间关系，有效地在不同用户之间对齐数据分布，从而改进活动识别。 |
| [^122] | [Continual Learning by Three-Phase Consolidation](https://arxiv.org/abs/2403.14679) | 通过三阶段巩固的持续学习方法，旨在解决类别不平衡问题，限制梯度校正避免遗忘少数类，并在复杂数据集上展示了其准确性和效率优势。 |
| [^123] | [Towards a Framework for Deep Learning Certification in Safety-Critical Applications Using Inherently Safe Design and Run-Time Error Detection](https://arxiv.org/abs/2403.14678) | 本研究构建了面向安全关键应用的深度学习认证框架，结合固有安全设计和运行时错误检测，以应对现实世界问题。 |
| [^124] | [Unified Uncertainty Estimation for Cognitive Diagnosis Models](https://arxiv.org/abs/2403.14676) | 提出了一种统一不确定性评估方法，适用于各种认知诊断模型，填补了对于具有交互功能参数的复杂模型的学术空白 |
| [^125] | [Understanding the Transit Gap: A Comparative Study of On-Demand Bus Services and Urban Climate Resilience in South End, Charlotte, NC and Avondale, Chattanooga, TN](https://arxiv.org/abs/2403.14671) | 本研究揭示了城市设计在公共交通效率和减少碳排放方面的关键作用，指出城市布局对公共交通结果有重要影响，提出了针对不同城市设计元素的定制策略对于气候适应至关重要。 |
| [^126] | [Predicting Learning Performance with Large Language Models: A Study in Adult Literacy](https://arxiv.org/abs/2403.14668) | 该研究使用大型语言模型GPT-4探讨了在ITS中预测成人识字计划学习表现的应用，并发现GPT-4在此方面具有竞争力的预测能力。 |
| [^127] | [SyllabusQA: A Course Logistics Question Answering Dataset](https://arxiv.org/abs/2403.14666) | SyllabusQA数据集是一个包含63个真实课程大纲的开源数据集，对36个专业涵盖5,078对多样化的开放式课程逻辑相关问题-答案对进行了详细收集，旨在评估答案事实性，多个强基线模型在该任务上表现出色，但仍存在与人类之间的显著差距。 |
| [^128] | [ClickTree: A Tree-based Method for Predicting Math Students' Performance Based on Clickstream Data](https://arxiv.org/abs/2403.14664) | ClickTree是一种基于树形方法的预测学生数学作业表现的技术，在2023年教育数据挖掘杯比赛中取得了0.78844的AUC，排名第二。 |
| [^129] | [Machine Learning Predicts Upper Secondary Education Dropout as Early as the End of Primary School](https://arxiv.org/abs/2403.14663) | 该研究利用长达13年的数据集，包括从幼儿园到9年级的数据，通过机器学习模型成功预测了初中辍学的可能性 |
| [^130] | [Case Studies of AI Policy Development in Africa](https://arxiv.org/abs/2403.14662) | 非洲国家在AI准备方面取得的进展没有完全被全球准备情况评估捕捉到，通过对四个非洲国家进行案例研究，提出了如何改善国家的AI准备标准以及如何使社会能够获益于AI的高层政策考虑。 |
| [^131] | [Towards Modeling Learner Performance with Large Language Models](https://arxiv.org/abs/2403.14661) | 本文研究了预训练大型语言模型（LLMs）在知识追踪领域的应用，通过比较零-shot提示和模型微调两种方法，提出了LLMs在智能辅导系统中预测学习者表现的潜力。 |
| [^132] | [Revolutionising Distance Learning: A Comparative Study of Learning Progress with AI-Driven Tutoring](https://arxiv.org/abs/2403.14642) | 本研究首次证明生成式AI能显著提高大学生的学习速度，使用AI助手Syntea在远程学习学生中平均减少了27%的学习时间，表明生成式AI可以通过个性化显著改进和加快学习。 |
| [^133] | [Testing autonomous vehicles and AI: perspectives and challenges from cybersecurity, transparency, robustness and fairness](https://arxiv.org/abs/2403.14641) | 探讨了将人工智能整合到自动驾驶车辆中所涉及的挑战，重点关注了网络安全审计、决策过程的可解释性以及评估预测系统的稳健性和道德行为等方面的重要性 |
| [^134] | [On Defining Smart Cities using Transformer Neural Networks](https://arxiv.org/abs/2403.14639) | 使用Transformer神经网络和语义文本分析，本论文尝试创建一个新的智慧城市定义“妥协”版本，并提出语义相似度度量作为评估技术。 |
| [^135] | [Personalized Programming Guidance based on Deep Programming Learning Style Capturing](https://arxiv.org/abs/2403.14638) | 本文提出了一种名为具有学习风格的编程练习推荐器（PERS）的新模型，旨在解决编程中如何识别复杂编程行为和捕捉内在学习模式的挑战。 |
| [^136] | [Videoshop: Localized Semantic Video Editing with Noise-Extrapolated Diffusion Inversion](https://arxiv.org/abs/2403.14617) | Videoshop是一个无需训练的视频编辑算法，通过图像为基础的方法实现了本地化语义编辑，从而允许用户对视频进行精细控制，取得了更高质量的编辑效果。 |
| [^137] | [Model Uncertainty in Evolutionary Optimization and Bayesian Optimization: A Comparative Analysis](https://arxiv.org/abs/2403.14413) | 这项研究比较了进化优化和贝叶斯优化中的模型不确定性，引入了一种新的模型辅助策略以增强算法性能。 |
| [^138] | [Accurately Predicting Probabilities of Safety-Critical Rare Events for Intelligent Systems](https://arxiv.org/abs/2403.13869) | 该研究致力于发展一个在评估安全关键自主安全性的重要性方面，在精度和召回率方面都表现出色的关键性预测模型。 |
| [^139] | [The Model Openness Framework: Promoting Completeness and Openness for Reproducibility, Transparency and Usability in AI](https://arxiv.org/abs/2403.13784) | 提出了模型开放框架（MOF），它是一个排名分类系统，根据完整性和开放性评估机器学习模型，旨在促进完整性、开放性以及遵循开放科学原则，可以帮助准确识别模型的透明性和可重现性。 |
| [^140] | [AltGraph: Redesigning Quantum Circuits Using Generative Graph Models for Efficient Optimization](https://arxiv.org/abs/2403.12979) | 该论文提出了AltGraph这一基于搜索的电路转换方法，利用生成图模型生成等效的量子电路，以在保持等效性的同时优化电路。 |
| [^141] | [Beyond Quantities: Machine Learning-based Characterization of Inequality in Infrastructure Quality Provision in Cities](https://arxiv.org/abs/2403.12074) | 通过机器学习的方法，超越了传统基于数量的基础设施不平等特征化研究，从而填补了城市不平等和环境正义考虑之间的研究空白。 |
| [^142] | [LSKNet: A Foundation Lightweight Backbone for Remote Sensing](https://arxiv.org/abs/2403.11735) | LSKNet是一种轻量级的大型选择核网络骨干，能动态调整其较大的空间感受野，以更好地模拟遥感场景中各种对象的远程上下文。 |
| [^143] | [LOOPer: A Learned Automatic Code Optimizer For Polyhedral Compilers](https://arxiv.org/abs/2403.11522) | LOOPer是针对多面体编译器的学习型自动代码优化器，通过机器学习建立成本模型来指导多面体优化搜索，突破了传统编译器在选择代码转换方面的限制。 |
| [^144] | [CPA-Enhancer: Chain-of-Thought Prompted Adaptive Enhancer for Object Detection under Unknown Degradations](https://arxiv.org/abs/2403.11220) | 提出了一种用于未知退化下目标检测的链式思维驱动自适应增强器CPA-Enhancer，并将其集成到通用检测器中，有效提升受损图像的检测性能 |
| [^145] | [Large Language Model-informed ECG Dual Attention Network for Heart Failure Risk Prediction](https://arxiv.org/abs/2403.10581) | 提出了一种大型语言模型指导的双注意力ECG网络，用于心力衰竭风险预测，能够捕捉复杂的心电图特征，有效应对低风险和高风险组之间的不平衡。 |
| [^146] | [Recurrent Drafter for Fast Speculative Decoding in Large Language Models](https://arxiv.org/abs/2403.09919) | 本文介绍了一种适用于大型语言模型的循环草稿机制，结合了经典双模型和最新单模型方法，通过运用循环依赖设计，实现了高效的推测解码。 |
| [^147] | [MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training](https://arxiv.org/abs/2403.09611) | 通过详细研究图像编码器、视觉语言连接器和预训练数据选择的重要性，确定了对于实现多个基准测试中最新潮的少样本结果至关重要的关键设计经验。 |
| [^148] | [Simple and Scalable Strategies to Continually Pre-train Large Language Models](https://arxiv.org/abs/2403.08763) | 通过简单和可扩展的学习率调整、重放数据的方法，可以在不重新训练的情况下，持续预训练大型语言模型以匹配完全重新训练时的性能。 |
| [^149] | [TeleMoMa: A Modular and Versatile Teleoperation System for Mobile Manipulation](https://arxiv.org/abs/2403.07869) | TeleMoMa 是一种面向移动操作的模块化多功能远程操作系统，通过整合多种人机接口、降低门槛且具有通用性，为移动操作器提供了全身远程操作的解决方案。 |
| [^150] | [Multi-conditioned Graph Diffusion for Neural Architecture Search](https://arxiv.org/abs/2403.06020) | 提出了一种基于图扩散的NAS方法，结合多条件无分类器指导方法，能在架构搜索中生成快速且性能优越的神经网络架构，并在多个标准基准和ImageNet数据集上取得了有希望的结果 |
| [^151] | [tLaSDI: Thermodynamics-informed latent space dynamics identification](https://arxiv.org/abs/2403.05848) | 提出了一种融合热力学定律的数据驱动潜空间动力学识别方法，通过自动编码器学习潜变量并构建动力学模型，实现对热力学定律的遵守，并通过新的损失函数进行训练。演示了其在稳健泛化能力方面的表现，以及在潜空间中熵产生速率与系统行为之间的相关性。 |
| [^152] | [Task-Oriented GNNs Training on Large Knowledge Graphs for Accurate and Efficient Modeling](https://arxiv.org/abs/2403.05752) | 本文提出了一种自动化TOSG提取的方法KG-TOSA，用于在大型知识图上进行面向任务的图神经网络训练，以减轻对大型KG的过多计算负担。 |
| [^153] | [Faster Neighborhood Attention: Reducing the O(n^2) Cost of Self Attention at the Threadblock Level](https://arxiv.org/abs/2403.04690) | 该研究提出了一种更快的邻域注意力机制，通过将注意力限制在最近的邻居之间来降低自注意力的计算复杂度，实现了显著的性能提升。 |
| [^154] | [ChunkAttention: Efficient Self-Attention with Prefix-Aware KV Cache and Two-Phase Partition](https://arxiv.org/abs/2402.15220) | ChunkAttention是一种前缀感知的自注意力模块，通过将键/值张量分解为较小的块并结构化到辅助前缀树中，实现了在运行时改善内存利用率的KV缓存，同时设计了两阶段分区算法以提高自注意力计算中的数据局部性。 |
| [^155] | [Statistical Agnostic Regression: a machine learning method to validate regression models](https://arxiv.org/abs/2402.15213) | 本文提出了一种新的方法，统计无关地评估了线性回归模型，并评估了ML估计在检测方面的表现。 |
| [^156] | [Temporal Disentangled Contrastive Diffusion Model for Spatiotemporal Imputation](https://arxiv.org/abs/2402.11558) | 基于深度学习的时间解耦对比扩散模型应用于时空插补，旨在通过生成模型来提高预测效能。 |
| [^157] | [Short-Form Videos and Mental Health: A Knowledge-Guided Multimodal Neural Topic Model](https://arxiv.org/abs/2402.10045) | 这项研究针对短视频对观众心理健康的抑郁影响问题，开发了一种基于医学知识的多模态神经主题模型，以预测其影响并采取相应的干预措施。 |
| [^158] | [Unveiling Group-Specific Distributed Concept Drift: A Fairness Imperative in Federated Learning](https://arxiv.org/abs/2402.07586) | 该研究在联邦学习中的分布式环境下，首次探索了在存在特定群体概念漂移的情况下实现公平性的挑战和解决方案。 |
| [^159] | [ToonAging: Face Re-Aging upon Artistic Portrait Style Transfer](https://arxiv.org/abs/2402.02733) | 本研究提出了一种新颖的一阶段方法，结合肖像风格转换实现人脸逆龄化，解决了NPR图像上编辑年龄的问题，并在单个生成步骤中执行。该方法利用了现有的人脸逆龄化和风格转换网络，并且独特地融合了不同的潜在向量，从而保留了面部属性。 |
| [^160] | [Combining the Strengths of Dutch Survey and Register Data in a Data Challenge to Predict Fertility (PreFer)](https://arxiv.org/abs/2402.00705) | 该论文介绍了两个数据集，分别基于荷兰的调查数据和登记数据，用于研究荷兰生育结果的预测能力。研究者提供了数据集的信息和样本，并描述了生育结果的具体内容。他们还介绍了生育率预测的方法。 |
| [^161] | [Learning to Embed Time Series Patches Independently](https://arxiv.org/abs/2312.16427) | 学习独立嵌入时间序列片段可以产生更好的时间序列表示，通过简单的块重构任务和独立嵌入每个块的MLP模型以及互补对比学习来实现。 |
| [^162] | [Soft Contrastive Learning for Time Series](https://arxiv.org/abs/2312.16424) | 提出了一种名为SoftCLT的方法，通过引入实例级和时间级软对比损失，解决了在时间序列中忽略固有相关性所导致的学习表示质量下降的问题。 |
| [^163] | [Sparse Mean Field Load Balancing in Large Localized Queueing Systems](https://arxiv.org/abs/2312.12973) | 本研究利用稀疏均场理论的进展，提出了一种在大型局部排队网络中学习近似最优负载平衡策略的方法，为稀疏有界度无线拓扑提供了通用的负载平衡框架。 |
| [^164] | [UniChest: Conquer-and-Divide Pre-training for Multi-Source Chest X-Ray Classification](https://arxiv.org/abs/2312.11038) | 提出了UniChest框架，采用征服和分割的预训练方法，使得模型能够充分利用多个来源的胸部X射线数据，提高模型泛化能力。 |
| [^165] | [Symmetry Breaking and Equivariant Neural Networks](https://arxiv.org/abs/2312.09016) | 提出了一种新颖的“放松等变性”的概念，用于解决等变函数无法在单个数据样本层面打破对称的限制，并展示了如何将其应用于等变多层感知机（E-MLP）中。 |
| [^166] | [FERGI: Automatic Annotation of User Preferences for Text-to-Image Generation from Spontaneous Facial Expression Reaction](https://arxiv.org/abs/2312.03187) | 开发了一种从用户自发面部表情反应中自动注释用户对生成图像偏好的方法，发现多个面部动作单元与用户对生成图像的评估高度相关，可用于通过这些面部动作单元区分图像对并自动标注用户偏好。 |
| [^167] | [Empowering Autonomous Driving with Large Language Models: A Safety Perspective](https://arxiv.org/abs/2312.00812) | 本文通过整合大型语言模型（LLMs）到自动驾驶系统中，利用其常识知识和推理能力，作为智能决策者来增强驾驶性能和安全性。 |
| [^168] | [Generalisable Agents for Neural Network Optimisation](https://arxiv.org/abs/2311.18598) | 通用智能体用于神经网络优化是一种多智能体强化学习方法，通过动态调度超参数来优化神经网络训练，可以有效改善全局性能并与手工设计启发式方法相竞争。 |
| [^169] | [Quantum Langevin Dynamics for Optimization](https://arxiv.org/abs/2311.15587) | 该研究引入了量子朗之万动力学（QLD）来解决非凸优化问题，证明了在凸景观中 QLD 的收敛性，并展示了其能量耗散能力和低温极限下指数衰减速率。 |
| [^170] | [ID-like Prompt Learning for Few-Shot Out-of-Distribution Detection](https://arxiv.org/abs/2311.15243) | 提出了一种利用CLIP识别ID样式异常值并通过提示学习进行OOD检测的新框架，能够有效提高识别最具挑战性OOD样本的能力。 |
| [^171] | [Multivariate Scenario Generation of Day-Ahead Electricity Prices using Normalizing Flows](https://arxiv.org/abs/2311.14033) | 使用正规化流生成日前电力价格的多元场景生成，并提出扩展特征集和重新训练方案来适应现代电力市场的变化条件 |
| [^172] | [Physics-Enhanced Multi-fidelity Learning for Optical Surface Imprint](https://arxiv.org/abs/2311.10278) | 本文提出了一种利用多保真神经网络(MFNN)解决光学图像与实际机械性能之间映射的方法。 |
| [^173] | [Multiscale Hodge Scattering Networks for Data Analysis](https://arxiv.org/abs/2311.10270) | 提出了多尺度霍奇散射网络（MHSNs），利用多尺度基础词典和卷积结构，生成对节点排列不变的特征。 |
| [^174] | [Multi-resolution Time-Series Transformer for Long-term Forecasting](https://arxiv.org/abs/2311.04147) | 提出了一种Multi-resolution Time-Series Transformer框架，采用多分支架构和相对位置编码，用于同时建模不同分辨率下的多样化时间模式。 |
| [^175] | [E-Sparse: Boosting the Large Language Model Inference through Entropy-based N:M Sparsity](https://arxiv.org/abs/2310.15929) | 首次将信息熵引入剪枝度量设计，提高在大型语言模型中 N:M 稀疏性的准确性。 |
| [^176] | [Stabilizing reinforcement learning control: A modular framework for optimizing over all stable behavior](https://arxiv.org/abs/2310.14098) | 提出了一个框架，结合了深度强化学习的优化驱动和无模型的优势，以及使用Youla-Kucera参数化提供的稳定性保证，为设计反馈控制器提供了一种优化过程。 |
| [^177] | [Learning High-level Semantic-Relational Concepts for SLAM](https://arxiv.org/abs/2310.00401) | 提出了一种基于图神经网络的算法，用于学习SLAM中的高级语义关系概念。 |
| [^178] | [Local and Global Trend Bayesian Exponential Smoothing Models](https://arxiv.org/abs/2309.13950) | 本文描述了一组季节性和非季节性时间序列模型，可以用于建模增长速度介于线性和指数之间的时间序列。模型包括全局趋势从加法到乘法的平滑变化，与线性局部趋势相结合，并采用乘法季节性和异方差的加法误差。通过贝叶斯拟合技术，该模型在M3竞赛数据集上表现优于其他模型。 |
| [^179] | [Dynamic-SUPERB: Towards A Dynamic, Collaborative, and Comprehensive Instruction-Tuning Benchmark for Speech](https://arxiv.org/abs/2309.09510) | 提出了 Dynamic-SUPERB 基准测试，旨在构建通用语音模型，利用指令调优实现零-shot执行多任务，通过合作和贡献动态增长基准。 |
| [^180] | [An axiomatized PDE model of deep neural networks](https://arxiv.org/abs/2307.12333) | 通过将深度神经网络表述为一个简单基础模型到演化算子，我们提出了一个对流-扩散方程模型，为有效网络提供了数学解释，并设计了一种新的训练方法，实验证实了其性能提升。 |
| [^181] | [KGLiDS: A Platform for Semantic Abstraction, Linking, and Automation of Data Science](https://arxiv.org/abs/2303.02204) | 提出了一个可扩展平台KGLiDS，利用机器学习和知识图技术来抽象和捕获数据科学工具及其联系的语义，从而支持数据发现和管道自动化。 |
| [^182] | [Finding the right XAI method -- A Guide for the Evaluation and Ranking of Explainable AI Methods in Climate Science](https://arxiv.org/abs/2303.00652) | 这项工作介绍了气候背景下的XAI评估，并讨论了不同的期望解释特性，为了评估和排序可解释人工智能方法在气候科学中的应用。 |
| [^183] | [Cross-domain Random Pre-training with Prototypes for Reinforcement Learning](https://arxiv.org/abs/2302.05614) | 提出了CRPTpro框架，利用原型进行跨领域自监督随机预训练，提高预训练效率，并实现在不同领域中定义的视觉控制RL任务。 |
| [^184] | [Forward Learning with Top-Down Feedback: Empirical and Analytical Characterization](https://arxiv.org/abs/2302.05440) | 本研究揭示了具有自上而下反馈的前馈学习算法与自适应反馈对齐算法之间的联系，分析了它们在学习过程中的性能，并比较了不同版本的仅向前算法，揭示它们共享相同的学习原理。 |
| [^185] | [Decision-making with Speculative Opponent Models](https://arxiv.org/abs/2211.11940) | 提出了一种使用纯粹局部信息实现推测对手建模的多智能体分布式演员-评论家算法，能够帮助受控代理做出决策。 |
| [^186] | [Training Fully Connected Neural Networks is $\exists\mathbb{R}$-Complete](https://arxiv.org/abs/2204.01368) | 该论文证明了训练全连接神经网络的权重和偏置的相关决策问题是$\exists\mathbb{R}$-完全的，同时指出必须使用任意大阶的代数数作为权重才能训练一些实例达到最优。 |
| [^187] | [BBE-LSWCM: A Bootstrapped Ensemble of Long and Short Window Clickstream Models](https://arxiv.org/abs/2203.16155) | 提出了一种融合长短窗口的点击流模型自举集成框架（BBE-LSWCM），在实时客户事件预测中表现出优越性能，特别适用于QBO订阅取消和有意任务检测。 |
| [^188] | [Similarity-based Label Inference Attack against Training and Inference of Split Learning](https://arxiv.org/abs/2203.05222) | 本文研究了在Split learning的训练和推理过程中基于相似性的标签推断攻击，提出了相似性度量并设计了三种标签推断攻击。 |
| [^189] | [Learning to Importance Sample in Primary Sample Space](https://arxiv.org/abs/1808.07840) | 提出了一种利用神经网络在主采样空间中学习重要性采样的新方法，用于渲染算法中的方差缩减。 |
| [^190] | [Fast Nonlinear Two-Time-Scale Stochastic Approximation: Achieving $\mathcal{O}(1/k)$ Finite-Sample Complexity.](http://arxiv.org/abs/2401.12764) | 本文提出了一种新型的两时间尺度随机逼近方法，用于寻找耦合非线性算子的根，并且在强单调条件下证明了该方法的优化收敛速率为$\mathcal{O}(1/k)$。 |
| [^191] | [Attractor reconstruction with reservoir computers: The effect of the reservoir's conditional Lyapunov exponents on faithful attractor reconstruction.](http://arxiv.org/abs/2401.00885) | 该论文研究了储层计算在吸引子重建中的表现，发现驱动式储层的最大条件Lyapunov指数需要比真实系统的最小Lyapunov指数更小，储层的谱半径对吸引子重建起到重要作用。 |
| [^192] | [Stronger Graph Transformer with Regularized Attention Scores.](http://arxiv.org/abs/2312.11730) | 本论文提出了一种新颖的边缘正则化技术版本，用于缓解图神经网络在内存问题上存在的困扰。与没有位置编码的Graph Transformer相比，应用了边缘正则化技术确实可以稳定地提高性能。 |
| [^193] | [Class-Prototype Conditional Diffusion Model for Continual Learning with Generative Replay.](http://arxiv.org/abs/2312.06710) | 本论文提出了一个类原型条件扩散模型（CPDM）来解决Continual Learning中的灾难性遗忘问题。CPDM通过提高生成器的图像质量，减少了分类器的灾难性遗忘风险。 |
| [^194] | [A Simple Way to Incorporate Novelty Detection in World Models.](http://arxiv.org/abs/2310.08731) | 本文提出了一个简单的方法，通过利用世界模型幻觉状态和真实观察状态的不匹配性作为异常分数，将新颖性检测纳入世界模型强化学习代理中。在新环境中与传统方法相比，我们的工作具有优势。 |
| [^195] | [Vibroacoustic Frequency Response Prediction with Query-based Operator Networks.](http://arxiv.org/abs/2310.05469) | 该论文提出了一个基于查询式操作网络的振动声学频响预测方法，并设计了一个用于代表性振动声学问题的结构化基准测试。该方法可以加速频响模拟，有助于设计优化和不确定性量化。 |
| [^196] | [From Complexity to Clarity: Analytical Expressions of Deep Neural Network Weights via Clifford's Geometric Algebra and Convexity.](http://arxiv.org/abs/2309.16512) | 本文通过Clifford的几何代数和凸优化，提出了一种分析深度神经网络的新方法。我们展示了深度ReLU神经网络的最优权重可以通过训练样本的楔积来获得，并且训练问题可以简化为对楔积特征进行凸优化，从而揭示了神经网络内部的几何结构。 |
| [^197] | [Residual Denoising Diffusion Models.](http://arxiv.org/abs/2308.13712) | 提出了剩余去噪扩散模型（RDDM），相比于现有的扩散模型，该模型通过预测残差来表示从目标域到输入域的方向性扩散，并同时估计噪声来考虑扩散过程中的随机扰动，从而实现了统一的图像生成和恢复。 |
| [^198] | [End-to-End Reinforcement Learning of Koopman Models for Economic Nonlinear MPC.](http://arxiv.org/abs/2308.01674) | 本论文提出了一种用于经济非线性MPC的Koopman模型的端到端强化学习方法，旨在实现控制性能和计算需求之间的平衡。 |
| [^199] | [Noisy Interpolation Learning with Shallow Univariate ReLU Networks.](http://arxiv.org/abs/2307.15396) | 使用最小范数的两层ReLU网络进行噪声单变量回归的插值，对于$L_1$损失和$ p <2 $的$L_p$损失抑制过拟合，但对于$ p \geq 2 $的损失是灾难性的。 |
| [^200] | [Efficiently Sampling the PSD Cone with the Metric Dikin Walk.](http://arxiv.org/abs/2307.12943) | 本文通过对Dikin步行方法进行分析并适应一般度量，为带约束的PSD锥体抽样问题提供了一种有效的解决方案，并提出了优化的自共轭矩阵函数概念。 |
| [^201] | [Multi-Player Zero-Sum Markov Games with Networked Separable Interactions.](http://arxiv.org/abs/2307.09470) | 本文研究了一种新的马尔可夫游戏类别，通过带有网络可分离交互的多人零和马尔可夫游戏模型（MZNMGs）来模拟非合作多智能体顺序决策中的局部交互结构。作者确定了MG可被表示为MZNMG的必要和充分条件，并证明其Markov CCE集合与Markov NE集合相等；此外，在无限时间折扣MZNMG中找到近似的Markov稳定CCE是PPAD难题，除非网络具有“星状结构”。 |
| [^202] | [An Agnostic View on the Cost of Overfitting in (Kernel) Ridge Regression.](http://arxiv.org/abs/2306.13185) | 本文研究了核岭回归中过拟合成本，采用“不可知”的观点，以分析样本量和任务特征结构对成本的影响。通过分析提供了更细致的过度拟合表征。 |
| [^203] | [Efficient Recruitment Strategy for Collaborative Mobile Crowd Sensing Based on GCN Trustworthiness Prediction.](http://arxiv.org/abs/2306.04366) | 本文提出了一种基于GCN可信度预测的协同移动群感知的高效招募策略，通过捕获工人之间的非对称信任关系和工人能力来实现有效的任务分配，优于现有方法。 |
| [^204] | [Eliminating Spurious Correlations from Pre-trained Models via Data Mixing.](http://arxiv.org/abs/2305.14521) | 本文提出了一种通过数据混合来消除预训练模型中虚假相关性的方法，来提高模型对于新样本的预测能力。这种方法经过理论证明和多种任务实验验证，可以取得良好的效果。 |
| [^205] | [Earth Movers in The Big Data Era: A Review of Optimal Transport in Machine Learning.](http://arxiv.org/abs/2305.05080) | 本文回顾了最优输运在机器学习中的应用，并探讨了如何将其扩展以适应大数据和高维数据的需求。 |
| [^206] | [mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality.](http://arxiv.org/abs/2304.14178) | 本文介绍了一种名为mPLUG-Owl的训练范式，它通过模块化学习基础LLM、视觉知识模块和视觉抽象器模块，赋予LLMs多模态的能力。实验结果表明，mPLUG-Owl在图像字幕和视觉问答任务中表现优于基线模型，并在某些情况下达到了最先进的性能水平。 |
| [^207] | [EC-NAS: Energy Consumption Aware Tabular Benchmarks for Neural Architecture Search.](http://arxiv.org/abs/2210.06015) | 提出了一个能耗感知的神经架构搜索表格基准 EC-NAS，该基准通过添加能耗和碳足迹信息，支持设计能效高的深度学习模型，并降低总能耗。 |
| [^208] | [Formal Interpretability with Merlin-Arthur Classifiers.](http://arxiv.org/abs/2206.00759) | 该论文提出了一种新型的多智能体交互分类器，利用“Merlin-Arthur”协议的启发，在不假设最优智能体或特征独立分布的情况下，通过相对强度和“非对称特征相关性”概念捕捉特征之间精确的相关性，提供可证明的可解释性保证。 |

# 详细

[^1]: DiffusionMTL: 从部分标注数据中学习多任务去噪扩散模型

    DiffusionMTL: Learning Multi-Task Denoising Diffusion Model from Partially Annotated Data

    [https://arxiv.org/abs/2403.15389](https://arxiv.org/abs/2403.15389)

    DiffusionMTL 提出了一个新型多任务去噪扩散框架，通过联合扩散和去噪来改善部分标注数据中的多任务密集场景理解，进一步引入了多任务条件策略来利用任务的互补性。

    

    最近，对从部分标注数据中学习多个密集场景理解任务的实际问题越来越感兴趣，其中每个训练样本仅针对一部分任务进行标记。在训练中缺少任务标签会导致低质量和嘈杂的预测，这可以从最先进方法中观察到。为了解决这个问题，我们将部分标记的多任务密集预测重新构建为像素级去噪问题，并提出了一个被称为DiffusionMTL的新型多任务去噪扩散框架。它设计了一个联合扩散和去噪范式，以模拟任务预测或特征图中的潜在噪声分布，并为不同任务生成校正输出。为了利用去噪中的多任务一致性，我们进一步引入了一个多任务条件策略，它可以隐式利用任务的互补性来帮助学习未标记

    arXiv:2403.15389v1 Announce Type: cross  Abstract: Recently, there has been an increased interest in the practical problem of learning multiple dense scene understanding tasks from partially annotated data, where each training sample is only labeled for a subset of the tasks. The missing of task labels in training leads to low-quality and noisy predictions, as can be observed from state-of-the-art methods. To tackle this issue, we reformulate the partially-labeled multi-task dense prediction as a pixel-level denoising problem, and propose a novel multi-task denoising diffusion framework coined as DiffusionMTL. It designs a joint diffusion and denoising paradigm to model a potential noisy distribution in the task prediction or feature maps and generate rectified outputs for different tasks. To exploit multi-task consistency in denoising, we further introduce a Multi-Task Conditioning strategy, which can implicitly utilize the complementary nature of the tasks to help learn the unlabeled
    
[^2]: LATTE3D: 大规模摊还式文本增强3D合成

    LATTE3D: Large-scale Amortized Text-To-Enhanced3D Synthesis

    [https://arxiv.org/abs/2403.15385](https://arxiv.org/abs/2403.15385)

    LATTE3D通过构建可扩展的架构、利用3D数据并采用摊还方法，在显著更大的提示集上实现快速、高质量的文本增强3D合成。

    

    最近的文本到3D生成方法产生了令人印象深刻的3D结果，但需要耗时的优化，每个提示可能需要长达一小时。像ATT3D这样的摊还方法同时优化多个提示，以提高效率，实现快速的文本到3D合成。然而，它们无法捕捉高频几何和纹理细节，并且很难扩展到大型提示集，因此泛化能力较差。我们引入了LATTE3D，解决了这些限制，实现在显著更大的提示集上进行快速、高质量的生成。我们的方法的关键之处在于 1)构建可扩展的架构和 2)利用3D数据在优化过程中通过3D感知扩散先验、形状正则化和模型初始化，以实现对不同和复杂训练提示的稳健性。LATTE3D摊还了神经场和纹理表面的生成，能在单次前向传递中产生高度详细的纹理网格。

    arXiv:2403.15385v1 Announce Type: cross  Abstract: Recent text-to-3D generation approaches produce impressive 3D results but require time-consuming optimization that can take up to an hour per prompt. Amortized methods like ATT3D optimize multiple prompts simultaneously to improve efficiency, enabling fast text-to-3D synthesis. However, they cannot capture high-frequency geometry and texture details and struggle to scale to large prompt sets, so they generalize poorly. We introduce LATTE3D, addressing these limitations to achieve fast, high-quality generation on a significantly larger prompt set. Key to our method is 1) building a scalable architecture and 2) leveraging 3D data during optimization through 3D-aware diffusion priors, shape regularization, and model initialization to achieve robustness to diverse and complex training prompts. LATTE3D amortizes both neural field and textured surface generation to produce highly detailed textured meshes in a single forward pass. LATTE3D gen
    
[^3]: 大型语言模型能够进行上下文中的探索吗？

    Can large language models explore in-context?

    [https://arxiv.org/abs/2403.15371](https://arxiv.org/abs/2403.15371)

    研究发现，大型语言模型在没有实质干预的情况下很难有效进行探索，除了特定配置下的GPT-4具有满意的探索行为外，其他模型表现不稳定。

    

    我们研究现代大型语言模型（LLMs）在进行探索方面的能力，这是强化学习和决策制定中的核心能力。我们关注现有LLMs的原生性能，没有进行训练干预。我们将LLMs部署为简单多臂老虎机环境中的代理，并完全在上下文中指定环境描述和交互历史，即在LLM提示内部进行。我们使用各种提示设计对GPT-3.5、GPT-4和Llama2进行实验，发现这些模型在没有实质干预的情况下并没有稳健地进行探索：i）在我们的所有实验中，只有一个配置导致了令人满意的探索行为：具有思维链推理和外部总结的交互历史的GPT-4，这些被呈现为充分统计的情况；ii）所有其他配置都没有产生稳健的探索行为，包括具有思维链推理的其他配置。

    arXiv:2403.15371v1 Announce Type: cross  Abstract: We investigate the extent to which contemporary Large Language Models (LLMs) can engage in exploration, a core capability in reinforcement learning and decision making. We focus on native performance of existing LLMs, without training interventions. We deploy LLMs as agents in simple multi-armed bandit environments, specifying the environment description and interaction history entirely in-context, i.e., within the LLM prompt. We experiment with GPT-3.5, GPT-4, and Llama2, using a variety of prompt designs, and find that the models do not robustly engage in exploration without substantial interventions: i) Across all of our experiments, only one configuration resulted in satisfactory exploratory behavior: GPT-4 with chain-of-thought reasoning and an externally summarized interaction history, presented as sufficient statistics; ii) All other configurations did not result in robust exploratory behavior, including those with chain-of-thou
    
[^4]: 基于增强现实的具有多视图一致性的AV感知网络的模拟数据(ARSim)

    Augmented Reality based Simulated Data (ARSim) with multi-view consistency for AV perception networks

    [https://arxiv.org/abs/2403.15370](https://arxiv.org/abs/2403.15370)

    提出了ARSim，一个全自动、综合、模块化的框架，旨在通过将3D合成对象整合到真实的多视图图像数据中，通过领域适应和随机化策略来解决真实与合成数据之间的协变量转移问题

    

    检测各种驾驶场景下的各种对象对于自动驾驶系统的有效性至关重要。然而，收集的现实世界数据经常缺乏必要的多样性，呈现长尾分布。虽然合成数据已被用来克服通过生成虚拟场景这一问题，但面临着诸如显著的领域差距以及需要3D艺术家大量工作来创建逼真环境等障碍。为了克服这些挑战，我们提出了ARSim，这是一个全自动的、综合的、模块化框架，旨在利用3D synthet 目标物体增强真实的多视图图像数据。所提出的方法集成了领域适应和随机化策略，通过从真实数据中推断重要的领域属性并利用基于模拟的随机化处理其他属性，以解决真实和合成数据之间的协变量转移。

    arXiv:2403.15370v1 Announce Type: cross  Abstract: Detecting a diverse range of objects under various driving scenarios is essential for the effectiveness of autonomous driving systems. However, the real-world data collected often lacks the necessary diversity presenting a long-tail distribution. Although synthetic data has been utilized to overcome this issue by generating virtual scenes, it faces hurdles such as a significant domain gap and the substantial efforts required from 3D artists to create realistic environments. To overcome these challenges, we present ARSim, a fully automated, comprehensive, modular framework designed to enhance real multi-view image data with 3D synthetic objects of interest. The proposed method integrates domain adaptation and randomization strategies to address covariate shift between real and simulated data by inferring essential domain attributes from real data and employing simulation-based randomization for other attributes. We construct a simplifie
    
[^5]: 一种针对图像水印的转移攻击

    A Transfer Attack to Image Watermarks

    [https://arxiv.org/abs/2403.15365](https://arxiv.org/abs/2403.15365)

    水印领域的研究表明，即使在攻击者无法访问水印模型或检测API的情况下，水印基础的AI生成图像检测器也无法抵抗对抗攻击。

    

    水印已被广泛应用于工业领域，用于检测由人工智能生成的图像。文献中对这种基于水印的检测器在白盒和黑盒环境下对抗攻击的稳健性有很好的理解。然而，在无盒环境下的稳健性却知之甚少。具体来说，多项研究声称图像水印在这种环境下是稳健的。在这项工作中，我们提出了一种新的转移对抗攻击来针对无盒环境下的图像水印。我们的转移攻击向带水印的图像添加微扰，以躲避被攻击者训练的多个替代水印模型，并且经过扰动的带水印图像也能躲避目标水印模型。我们的主要贡献是理论上和经验上展示了，基于水印的人工智能生成图像检测器即使攻击者没有访问水印模型或检测API，也不具有对抗攻击的稳健性。

    arXiv:2403.15365v1 Announce Type: cross  Abstract: Watermark has been widely deployed by industry to detect AI-generated images. The robustness of such watermark-based detector against evasion attacks in the white-box and black-box settings is well understood in the literature. However, the robustness in the no-box setting is much less understood. In particular, multiple studies claimed that image watermark is robust in such setting. In this work, we propose a new transfer evasion attack to image watermark in the no-box setting. Our transfer attack adds a perturbation to a watermarked image to evade multiple surrogate watermarking models trained by the attacker itself, and the perturbed watermarked image also evades the target watermarking model. Our major contribution is to show that, both theoretically and empirically, watermark-based AI-generated image detector is not robust to evasion attacks even if the attacker does not have access to the watermarking model nor the detection API.
    
[^6]: 用统计增强图神经网络预测级联停电严重性

    Cascading Blackout Severity Prediction with Statistically-Augmented Graph Neural Networks

    [https://arxiv.org/abs/2403.15363](https://arxiv.org/abs/2403.15363)

    用统计增强图神经网络进行级联停电严重性预测，提出了两种新技术，一是通过初始分类步骤过滤安全情景，二是利用级联停电的统计属性促进非局部消息传递。

    

    电网条件的高变异性，由于可再生能源渗透增加和极端天气事件的增加，使得筛选可能导致灾难性级联故障的情景变得更加困难。传统用于评估级联停电风险的基于电力流的工具速度太慢，无法适当探索可能的故障和负载/发电模式空间。我们在增长的基于图神经网络（GNN）的技术文献中做出了贡献，开发了两种新技术，用于从初始电网条件估计停电严重程度。首先，我们提出了几种方法，用于在严重程度估计之前通过初始分类步骤过滤出安全的“非停电”情景。其次，利用级联停电的统计属性，我们提出了一种方法，用于在我们的GNN模型中促进非局部消息传递。我们对这两种方法进行了验证。

    arXiv:2403.15363v1 Announce Type: cross  Abstract: Higher variability in grid conditions, resulting from growing renewable penetration and increased incidence of extreme weather events, has increased the difficulty of screening for scenarios that may lead to catastrophic cascading failures. Traditional power-flow-based tools for assessing cascading blackout risk are too slow to properly explore the space of possible failures and load/generation patterns. We add to the growing literature of faster graph-neural-network (GNN)-based techniques, developing two novel techniques for the estimation of blackout magnitude from initial grid conditions. First we propose several methods for employing an initial classification step to filter out safe "non blackout" scenarios prior to magnitude estimation. Second, using insights from the statistical properties of cascading blackouts, we propose a method for facilitating non-local message passing in our GNN models. We validate these two approaches on 
    
[^7]: 学习深度图像理解的拓扑表示

    Learning Topological Representations for Deep Image Understanding

    [https://arxiv.org/abs/2403.15361](https://arxiv.org/abs/2403.15361)

    提出了在深度学习框架中利用拓扑数据分析方法提高对图像中复杂结构的分割和不确定性估计，为可伸缩注释提供了强大工具。

    

    在许多场景中，尤其是生物医学应用中，正确划分复杂的细小结构如神经元、组织和血管对下游分析至关重要。深度学习方法虽然具有强大的预测能力，但并没有提供对这些结构的令人满意的表示，从而在可伸缩的注释和下游分析中产生重大障碍。本文提出了在深度学习框架中针对这些拓扑结构提出的新颖表示来解决这些挑战。我们利用拓扑数据分析中的数学工具，即持久同调和离散莫尔斯理论，开发了基于原则的更好分割和不确定性估计方法，这将成为可伸缩注释的强大工具。

    arXiv:2403.15361v1 Announce Type: cross  Abstract: In many scenarios, especially biomedical applications, the correct delineation of complex fine-scaled structures such as neurons, tissues, and vessels is critical for downstream analysis. Despite the strong predictive power of deep learning methods, they do not provide a satisfactory representation of these structures, thus creating significant barriers in scalable annotation and downstream analysis. In this dissertation, we tackle such challenges by proposing novel representations of these topological structures in a deep learning framework. We leverage the mathematical tools from topological data analysis, i.e., persistent homology and discrete Morse theory, to develop principled methods for better segmentation and uncertainty estimation, which will become powerful tools for scalable annotation.
    
[^8]: SiMBA：用于视觉和多变量时间序列的简化Mamba架构

    SiMBA: Simplified Mamba-Based Architecture for Vision and Multivariate Time series

    [https://arxiv.org/abs/2403.15360](https://arxiv.org/abs/2403.15360)

    SiMBA是一种引入Einstein FFT进行通道建模并使用Mamba块进行序列建模的新架构，在图像和时间序列基准上优于现有的SSMs。

    

    Transformers广泛采用了注意力网络进行序列混合和MLPs进行通道混合，在各个领域取得了突破性进展。然而，最近的文献强调了关于注意力网络的问题，包括对输入序列长度的低归纳偏差和二次复杂度。状态空间模型（SSMs）如S4和其他模型（Hippo，Global Convolutions，liquid S4，LRU，Mega和Mamba），已经出现来解决以上问题，以帮助处理更长的序列长度。Mamba是当前最先进的SSM，但在扩展到大型计算机视觉数据集时存在稳定性问题。我们提出了SiMBA，一种新的架构，通过特定的特征值计算引入Einstein FFT（EinFFT）来进行通道建模，并使用Mamba块进行序列建模。对图像和时间序列基准的广泛性能研究表明，SiMBA优于现有的SSMs，架起了

    arXiv:2403.15360v1 Announce Type: cross  Abstract: Transformers have widely adopted attention networks for sequence mixing and MLPs for channel mixing, playing a pivotal role in achieving breakthroughs across domains. However, recent literature highlights issues with attention networks, including low inductive bias and quadratic complexity concerning input sequence length. State Space Models (SSMs) like S4 and others (Hippo, Global Convolutions, liquid S4, LRU, Mega, and Mamba), have emerged to address the above issues to help handle longer sequence lengths. Mamba, while being the state-of-the-art SSM, has a stability issue when scaled to large networks for computer vision datasets. We propose SiMBA, a new architecture that introduces Einstein FFT (EinFFT) for channel modeling by specific eigenvalue computations and uses the Mamba block for sequence modeling. Extensive performance studies across image and time-series benchmarks demonstrate that SiMBA outperforms existing SSMs, bridging
    
[^9]: 基于扩散恢复模型方差的超声成像

    Ultrasound Imaging based on the Variance of a Diffusion Restoration Model

    [https://arxiv.org/abs/2403.15316](https://arxiv.org/abs/2403.15316)

    结合超声线性直接模型和去噪扩散模型学习先验的混合重建方法，通过对预训练的去噪扩散恢复模型进行无监督微调，提出了一种用于表征超声图像扩散重建随机性的经验模型。

    

    尽管今天超声成像在医学中普遍存在，但超声信噪比仍受多种噪声和伪影影响。而且，提高超声图像质量涉及平衡对比度、分辨率和斑点保留等并发因素。最近，在模型为基础和学习为基础的方法中，在解决超声图像重建问题方面取得了进展。结合这两个领域的优势，我们提出了一种混合重建方法，将超声线性直接模型与生成式去噪扩散模型学习先验相结合。具体来说，我们依赖于预训练的去噪扩散恢复模型(DDRM)的无监督微调。鉴于超声固有的乘性噪声特性，本文提出了一个经验模型，用于表征超声图像扩散重建的随机性。

    arXiv:2403.15316v1 Announce Type: cross  Abstract: Despite today's prevalence of ultrasound imaging in medicine, ultrasound signal-to-noise ratio is still affected by several sources of noise and artefacts. Moreover, enhancing ultrasound image quality involves balancing concurrent factors like contrast, resolution, and speckle preservation. Recently, there has been progress in both model-based and learning-based approaches addressing the problem of ultrasound image reconstruction. Bringing the best from both worlds, we propose a hybrid reconstruction method combining an ultrasound linear direct model with a learning-based prior coming from a generative Denoising Diffusion model. More specifically, we rely on the unsupervised fine-tuning of a pre-trained Denoising Diffusion Restoration Model (DDRM). Given the nature of multiplicative noise inherent to ultrasound, this paper proposes an empirical model to characterize the stochasticity of diffusion reconstruction of ultrasound images, an
    
[^10]: 水斯坦视角下的普通 GANs

    A Wasserstein perspective of Vanilla GANs

    [https://arxiv.org/abs/2403.15312](https://arxiv.org/abs/2403.15312)

    将普通GANs与水斯坦距离联系起来，扩展现有水斯坦GANs结果到普通GANs，获得了普通GANs的神谕不等式。

    

    生成对抗网络(GANs)的实证成功引起了对理论研究日益增长的兴趣。统计文献主要集中在水斯坦GANs及其扩展上，特别是允许具有良好的降维特性。对于普通GANs，即原始优化问题，统计结果仍然相当有限，需要假设平滑激活函数和潜空间与周围空间的维度相等。为了弥合这一差距，我们将普通GANs与水斯坦距离联系起来。通过这样做，现有的水斯坦GANs结果可以扩展到普通GANs。特别是，在水斯坦距离中获得了普通GANs的神谕不等式。这个神谕不等式的假设旨在由实践中常用的网络架构满足，如前馈ReLU网络。

    arXiv:2403.15312v1 Announce Type: cross  Abstract: The empirical success of Generative Adversarial Networks (GANs) caused an increasing interest in theoretical research. The statistical literature is mainly focused on Wasserstein GANs and generalizations thereof, which especially allow for good dimension reduction properties. Statistical results for Vanilla GANs, the original optimization problem, are still rather limited and require assumptions such as smooth activation functions and equal dimensions of the latent space and the ambient space. To bridge this gap, we draw a connection from Vanilla GANs to the Wasserstein distance. By doing so, existing results for Wasserstein GANs can be extended to Vanilla GANs. In particular, we obtain an oracle inequality for Vanilla GANs in Wasserstein distance. The assumptions of this oracle inequality are designed to be satisfied by network architectures commonly used in practice, such as feedforward ReLU networks. By providing a quantitative resu
    
[^11]: 使用扩散模型生成控制训练数据

    Controlled Training Data Generation with Diffusion Models

    [https://arxiv.org/abs/2403.15309](https://arxiv.org/abs/2403.15309)

    提出了一种使用扩散模型生成控制训练数据的方法，通过两个反馈机制，一方面使用监督模型反馈找到对抗性提示词实现图像生成，另一方面通过引导使生成过程朝向特定目标分布。

    

    在这项工作中，我们提出了一种方法，可以控制文本到图像生成模型以生成训练数据，专门用于监督学习。与之前那些采用开环方法并预先定义提示词来使用语言模型或人类专业知识生成新数据的作品不同，我们开发了一种自动闭环系统，其中包括两个反馈机制。第一个机制使用来自给定监督模型的反馈，并找到导致图像生成最大化模型损失的对抗提示词。虽然这些对抗提示词导致了经过模型训练的多样化数据生成，但它们并不知道目标分布，这可能效率低下。因此，我们引入第二个反馈机制，将生成过程引导到特定目标分布。我们称将这两个机制结合起来的方法为引导对抗提示词。我们在不同任务上进行评估。

    arXiv:2403.15309v1 Announce Type: cross  Abstract: In this work, we present a method to control a text-to-image generative model to produce training data specifically "useful" for supervised learning. Unlike previous works that employ an open-loop approach and pre-define prompts to generate new data using either a language model or human expertise, we develop an automated closed-loop system which involves two feedback mechanisms. The first mechanism uses feedback from a given supervised model and finds adversarial prompts that result in image generations that maximize the model loss. While these adversarial prompts result in diverse data informed by the model, they are not informed of the target distribution, which can be inefficient. Therefore, we introduce the second feedback mechanism that guides the generation process towards a certain target distribution. We call the method combining these two mechanisms Guided Adversarial Prompts. We perform our evaluations on different tasks, da
    
[^12]: KTbench：一种全新的无数据泄漏的知识追踪框架

    KTbench: A Novel Data Leakage-Free Framework for Knowledge Tracing

    [https://arxiv.org/abs/2403.15304](https://arxiv.org/abs/2403.15304)

    KTbench提出了一种无数据泄漏的知识追踪框架，解决了KT模型中KC之间的相关性学习可能导致的性能下降问题。

    

    知识追踪（KT）涉及在智能辅导系统中预测学生对学习项目的未来表现。学习项目被标记为称为知识概念（KCs）的技能标签。许多KT模型通过用构成KC的学习项目取代学习项目来将学习项目-学生交互序列扩展为KC-学生交互序列，从而解决了稀疏的学习项目-学生交互问题并最小化了模型参数。然而，这种方法存在两个问题。第一个问题是模型学习同一项目内的KC之间的相关性的能力，这可能导致基本事实标签的泄漏并阻碍模型性能。第二个问题是现有的基准实现忽略了计数问题

    arXiv:2403.15304v1 Announce Type: cross  Abstract: Knowledge Tracing (KT) is concerned with predicting students' future performance on learning items in intelligent tutoring systems. Learning items are tagged with skill labels called knowledge concepts (KCs). Many KT models expand the sequence of item-student interactions into KC-student interactions by replacing learning items with their constituting KCs. This often results in a longer sequence length. This approach addresses the issue of sparse item-student interactions and minimises model parameters. However, two problems have been identified with such models.   The first problem is the model's ability to learn correlations between KCs belonging to the same item, which can result in the leakage of ground truth labels and hinder performance. This problem can lead to a significant decrease in performance on datasets with a higher number of KCs per item. The second problem is that the available benchmark implementations ignore accounti
    
[^13]: 使用学习的策略基础进行规划以最优地解决复杂任务

    Planning with a Learned Policy Basis to Optimally Solve Complex Tasks

    [https://arxiv.org/abs/2403.15301](https://arxiv.org/abs/2403.15301)

    使用继承特征学习策略基础，使每个（子）策略解决一个子问题，在FSA描述的任务中，组合这些（子）策略可用于无需额外学习生成最优解决方案，方法能够渐近达到全局最优性，即使在随机环境中也如此。

    

    传统的强化学习方法可以成功解决各种顺序决策问题。然而，在具有非马尔可夫奖励规范的情景中学习能够可靠泛化于多个任务的策略是一个具有挑战性的问题。我们提出使用继承特征来学习一个策略基础，使得其中的每一个（子）策略解决一个明确定义的子问题。在由有限状态自动机（FSA）描述的任务中涉及相同一组子问题时，这些（子）策略的组合可以被用来生成一个最优解决方案而无需额外的学习。与其他通过规划组合（子）策略的方法相比，我们的方法在渐近上达到全局最优性，即使在随机环境中也是如此。

    arXiv:2403.15301v1 Announce Type: cross  Abstract: Conventional reinforcement learning (RL) methods can successfully solve a wide range of sequential decision problems. However, learning policies that can generalize predictably across multiple tasks in a setting with non-Markovian reward specifications is a challenging problem. We propose to use successor features to learn a policy basis so that each (sub)policy in it solves a well-defined subproblem. In a task described by a finite state automaton (FSA) that involves the same set of subproblems, the combination of these (sub)policies can then be used to generate an optimal solution without additional learning. In contrast to other methods that combine (sub)policies via planning, our method asymptotically attains global optimality, even in stochastic environments.
    
[^14]: 基于区块链的车载边缘元宇宙中车辆双子迁移的匿名管理

    Blockchain-based Pseudonym Management for Vehicle Twin Migrations in Vehicular Edge Metaverse

    [https://arxiv.org/abs/2403.15285](https://arxiv.org/abs/2403.15285)

    通过基于区块链的匿名管理，本研究解决了车载边缘元宇宙中车辆双子迁移过程中的隐私泄露问题

    

    受元宇宙和边缘计算技术的巨大进展推动，预计车载边缘元宇宙将颠覆当前智能交通系统的范式。作为车载元宇宙用户（VMUs）的高度电算化化身，部署在边缘服务器中的车辆双子（VTs）可以提供宝贵的元宇宙服务，以改善其VMUs在整个行程中的驾驶安全性和车内满意度。为了保持不间断的元宇宙体验，VTs必须根据车辆的移动在边缘服务器之间进行迁移。这可能引发有关车载边缘元宇宙之间动态通信过程中隐私泄露的担忧。为了解决这些问题并保护位置隐私，可以利用假名作为临时标识符，由VMUs和VTs共同利用，在物理空间和虚拟空间中实现匿名通信。然而，现有的假名管理方法在满足需求方面存在不足

    arXiv:2403.15285v1 Announce Type: cross  Abstract: Driven by the great advances in metaverse and edge computing technologies, vehicular edge metaverses are expected to disrupt the current paradigm of intelligent transportation systems. As highly computerized avatars of Vehicular Metaverse Users (VMUs), the Vehicle Twins (VTs) deployed in edge servers can provide valuable metaverse services to improve driving safety and on-board satisfaction for their VMUs throughout journeys. To maintain uninterrupted metaverse experiences, VTs must be migrated among edge servers following the movements of vehicles. This can raise concerns about privacy breaches during the dynamic communications among vehicular edge metaverses. To address these concerns and safeguard location privacy, pseudonyms as temporary identifiers can be leveraged by both VMUs and VTs to realize anonymous communications in the physical space and virtual spaces. However, existing pseudonym management methods fall short in meeting 
    
[^15]: 使用深度强化学习和可微分L0稀疏多项式策略的参数PDE控制

    Parametric PDE Control with Deep Reinforcement Learning and Differentiable L0-Sparse Polynomial Policies

    [https://arxiv.org/abs/2403.15267](https://arxiv.org/abs/2403.15267)

    使用字典学习和可微分L$_0$正则化方法，本文提出了一种稀疏、鲁棒、可解释的控制策略，适用于参数PDE系统。

    

    参数偏微分方程（PDE）的最优控制在工程和科学的许多应用中至关重要。近年来，科学机器学习的进展为参数PDE的控制开辟了新的前沿。特别是，深度强化学习（DRL）有望解决各种应用中的高维复杂控制问题。在这项工作中，我们利用字典学习和可微分L$_0$正则化来学习稀疏、鲁棒和可解释的参数PDE控制策略。

    arXiv:2403.15267v1 Announce Type: new  Abstract: Optimal control of parametric partial differential equations (PDEs) is crucial in many applications in engineering and science. In recent years, the progress in scientific machine learning has opened up new frontiers for the control of parametric PDEs. In particular, deep reinforcement learning (DRL) has the potential to solve high-dimensional and complex control problems in a large variety of applications. Most DRL methods rely on deep neural network (DNN) control policies. However, for many dynamical systems, DNN-based control policies tend to be over-parametrized, which means they need large amounts of training data, show limited robustness, and lack interpretability. In this work, we leverage dictionary learning and differentiable L$_0$ regularization to learn sparse, robust, and interpretable control policies for parametric PDEs. Our sparse policy architecture is agnostic to the DRL method and can be used in different policy-gradien
    
[^16]: 联邦贝叶斯深度学习：统计聚合方法应用于贝叶斯模型

    Federated Bayesian Deep Learning: The Application of Statistical Aggregation Methods to Bayesian Models

    [https://arxiv.org/abs/2403.15263](https://arxiv.org/abs/2403.15263)

    该论文研究了联邦贝叶斯深度学习的方法，旨在解决在现代深度学习模型中传达认识不确定性的挑战。

    

    联邦学习(FL)是一种训练机器学习模型的方法，利用多个分布式数据集，同时保持数据隐私和减少与共享本地数据集相关的通信成本。已经开发了聚合策略，用于整合或融合分布式确定性模型的权重和偏差；然而，现代确定性深度学习（DL）模型通常校准不佳，缺乏在预测中传达一种认识不确定性的能力，这对遥感平台和安全关键应用是理想的。相反，贝叶斯DL模型通常校准良好，能够量化和传达一种认识不确定性的能力以及具有竞争力的预测准确性。不幸的是，因为贝叶斯DL模型中的权重和偏差由概率分布定义，所以简单应用聚合方法是困难的。

    arXiv:2403.15263v1 Announce Type: new  Abstract: Federated learning (FL) is an approach to training machine learning models that takes advantage of multiple distributed datasets while maintaining data privacy and reducing communication costs associated with sharing local datasets. Aggregation strategies have been developed to pool or fuse the weights and biases of distributed deterministic models; however, modern deterministic deep learning (DL) models are often poorly calibrated and lack the ability to communicate a measure of epistemic uncertainty in prediction, which is desirable for remote sensing platforms and safety-critical applications. Conversely, Bayesian DL models are often well calibrated and capable of quantifying and communicating a measure of epistemic uncertainty along with a competitive prediction accuracy. Unfortunately, because the weights and biases in Bayesian DL models are defined by a probability distribution, simple application of the aggregation methods associa
    
[^17]: 大规模评估结果在LLM中的全面重新评估：一种多方位统计方法

    Comprehensive Reassessment of Large-Scale Evaluation Outcomes in LLMs: A Multifaceted Statistical Approach

    [https://arxiv.org/abs/2403.15250](https://arxiv.org/abs/2403.15250)

    评估大规模LLM中因素对性能的影响通过全面的统计分析，有助于更好地理解和推动这些模型的发展

    

    在LLM快速发展的背景下，评估在理解和推动这些模型前进中的重要性日益凸显。评估揭示了缩放、训练类型、架构等因素深刻影响LLM的性能。然而，这些因素对性能评分的影响程度和性质仍然存在争议，因为大多数评估局限于有限数量的模型和数据点。通过统计视角更有效地澄清这些因素对性能得分的影响可以更有效地实现。我们的研究对这些LLM进行了彻底的重新检查，针对当前评估方法的不足之处。随着一个统一的评估框架的出现，我们的研究利用了广泛的评估结果数据集，引入了一种全面的统计方法论。其中包括ANOVA、Tukey HSD检验、GAMM的应用

    arXiv:2403.15250v1 Announce Type: cross  Abstract: Amidst the rapid evolution of LLMs, the significance of evaluation in comprehending and propelling these models forward is increasingly paramount. Evaluations have revealed that factors such as scaling, training types, architectures and other factors profoundly impact the performance of LLMs. However, the extent and nature of these impacts continue to be subjects of debate because most assessments have been restricted to a limited number of models and data points. Clarifying the effects of these factors on performance scores can be more effectively achieved through a statistical lens. Our study embarks on a thorough re-examination of these LLMs, targeting the inadequacies in current evaluation methods. With the advent of a uniform evaluation framework, our research leverages an expansive dataset of evaluation results, introducing a comprehensive statistical methodology. This includes the application of ANOVA, Tukey HSD tests, GAMM, and
    
[^18]: 使用扩散模型进行视频运动转移的光谱运动对齐

    Spectral Motion Alignment for Video Motion Transfer using Diffusion Models

    [https://arxiv.org/abs/2403.15249](https://arxiv.org/abs/2403.15249)

    提出了一种名为Spectral Motion Alignment（SMA）的新框架，通过傅立叶和小波变换来优化和对齐运动向量，学习整帧全局运动动态，减轻空间伪影，有效改善运动转移。

    

    扩散模型的发展在视频生成和理解方面产生了巨大影响。特别是，文本到视频扩散模型（VDMs）显著促进了将输入视频定制为目标外观、运动等。尽管取得了这些进展，但准确提取视频帧的运动信息仍然存在挑战。现有作品利用连续帧残差作为目标运动向量，但它们固有地缺乏全局运动背景，并容易受到逐帧失真的影响。为了解决这个问题，我们提出了光谱运动对齐（SMA），这是一个通过傅立叶和小波变换来优化和对齐运动向量的新框架。SMA通过整合频域正则化来学习运动模式，促进整帧全局运动动态的学习，并减轻空间伪影。大量实验证明了SMA在改善运动转移方面的有效性。

    arXiv:2403.15249v1 Announce Type: cross  Abstract: The evolution of diffusion models has greatly impacted video generation and understanding. Particularly, text-to-video diffusion models (VDMs) have significantly facilitated the customization of input video with target appearance, motion, etc. Despite these advances, challenges persist in accurately distilling motion information from video frames. While existing works leverage the consecutive frame residual as the target motion vector, they inherently lack global motion context and are vulnerable to frame-wise distortions. To address this, we present Spectral Motion Alignment (SMA), a novel framework that refines and aligns motion vectors using Fourier and wavelet transforms. SMA learns motion patterns by incorporating frequency-domain regularization, facilitating the learning of whole-frame global motion dynamics, and mitigating spatial artifacts. Extensive experiments demonstrate SMA's efficacy in improving motion transfer while main
    
[^19]: FollowIR: 评估和教授信息检索模型以遵循说明书

    FollowIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions

    [https://arxiv.org/abs/2403.15246](https://arxiv.org/abs/2403.15246)

    该论文引入了FollowIR数据集，包含严格的说明书评估基准和训练集，帮助信息检索模型更好地遵循真实世界的说明书。议论基于TREC会议的历史，旨在使信息检索模型能够根据详细说明书理解和判断相关性。

    

    现代大型语言模型（LLMs）能够遵循长且复杂的说明书，从而实现多样化的用户任务。然而，尽管信息检索（IR）模型使用LLMs作为其架构的支柱，几乎所有这些模型仍然只接受查询作为输入，没有说明书。对于最近一些接受说明书的模型来说，它们如何使用这些说明书还不清楚。我们引入了FollowIR数据集，其中包含严格的说明书评估基准，以及一个训练集，帮助IR模型学习更好地遵循现实世界的说明书。FollowIR基于TREC会议的悠久历史：正如TREC为人类标注员提供说明书（也称为叙述）来判断文档的相关性一样，因此IR模型应该能够根据这些详细说明书理解和确定相关性。我们的评估基准从三个经过深度判断的TREC收藏开始

    arXiv:2403.15246v1 Announce Type: cross  Abstract: Modern Large Language Models (LLMs) are capable of following long and complex instructions that enable a diverse amount of user tasks. However, despite Information Retrieval (IR) models using LLMs as the backbone of their architectures, nearly all of them still only take queries as input, with no instructions. For the handful of recent models that do take instructions, it's unclear how they use them. We introduce our dataset FollowIR, which contains a rigorous instruction evaluation benchmark as well as a training set for helping IR models learn to better follow real-world instructions. FollowIR builds off the long history of the TREC conferences: as TREC provides human annotators with instructions (also known as narratives) to determine document relevance, so should IR models be able to understand and decide relevance based on these detailed instructions. Our evaluation benchmark starts with three deeply judged TREC collections and al
    
[^20]: 视频的增强推理对象中心学习

    Reasoning-Enhanced Object-Centric Learning for Videos

    [https://arxiv.org/abs/2403.15245](https://arxiv.org/abs/2403.15245)

    设计了一种新颖的推理模块STATM，利用记忆缓冲区增强模型在复杂场景中的感知能力。

    

    物体中心学习旨在将复杂的视觉场景分解为更易处理的物体表示，提升机器学习系统对物理世界的理解和推理能力。最近，基于槽位的视频模型展现出在分割和跟踪物体方面出色的能力，但忽视了有效推理模块的重要性。为了增强模型在复杂场景中的感知能力，我们设计了一种名为具有记忆缓冲区的基于槽位的时空变换器（STATM）的新型推理模块。记忆缓冲区主要用于存储来自上游模块的槽位信息，基于槽位的时空变换器通过槽位为基础进行预测。

    arXiv:2403.15245v1 Announce Type: cross  Abstract: Object-centric learning aims to break down complex visual scenes into more manageable object representations, enhancing the understanding and reasoning abilities of machine learning systems toward the physical world. Recently, slot-based video models have demonstrated remarkable proficiency in segmenting and tracking objects, but they overlook the importance of the effective reasoning module. In the real world, reasoning and predictive abilities play a crucial role in human perception and object tracking; in particular, these abilities are closely related to human intuitive physics. Inspired by this, we designed a novel reasoning module called the Slot-based Time-Space Transformer with Memory buffer (STATM) to enhance the model's perception ability in complex scenes. The memory buffer primarily serves as storage for slot information from upstream modules, the Slot-based Time-Space Transformer makes predictions through slot-based spatio
    
[^21]: 非凸优化的随机拟牛顿方法与非均匀平滑度

    A Stochastic Quasi-Newton Method for Non-convex Optimization with Non-uniform Smoothness

    [https://arxiv.org/abs/2403.15244](https://arxiv.org/abs/2403.15244)

    论文提出了一种针对非凸优化问题的随机拟牛顿方法，适用于具有非均匀平滑度的情况，其创新之处在于引入了$(L_0, L_1)$-平滑度，相比传统的$L$-平滑度，能更好地捕捉平滑度与梯度范数之间的正相关关系。

    

    传统优化算法的经典收敛分析依赖于广泛采用的均匀平滑度假设。然而，最近的实验研究表明，许多机器学习问题表现出非均匀平滑度，这意味着平滑度因子是模型参数的函数，而不是一个普遍常数。尤其是观察到，平滑度随着训练轨迹中的梯度范数增长。受这一现象的启发，最近引入的$(L_0, L_1)$-平滑度是一个比传统的$L$-平滑度更一般的概念，它捕捉了平滑度与梯度范数之间的这种正相关关系。在这种非均匀平滑度下，现有文献通过利用梯度裁剪技术设计了随机一阶算法，以获得找到$\epsilon$-近似解的$\mathcal{O}(\epsilon^{-3})$样本复杂度。

    arXiv:2403.15244v1 Announce Type: new  Abstract: Classical convergence analyses for optimization algorithms rely on the widely-adopted uniform smoothness assumption. However, recent experimental studies have demonstrated that many machine learning problems exhibit non-uniform smoothness, meaning the smoothness factor is a function of the model parameter instead of a universal constant. In particular, it has been observed that the smoothness grows with respect to the gradient norm along the training trajectory. Motivated by this phenomenon, the recently introduced $(L_0, L_1)$-smoothness is a more general notion, compared to traditional $L$-smoothness, that captures such positive relationship between smoothness and gradient norm. Under this type of non-uniform smoothness, existing literature has designed stochastic first-order algorithms by utilizing gradient clipping techniques to obtain the optimal $\mathcal{O}(\epsilon^{-3})$ sample complexity for finding an $\epsilon$-approximate fi
    
[^22]: 通过GAN方法实现稳健效用优化

    Robust Utility Optimization via a GAN Approach

    [https://arxiv.org/abs/2403.15243](https://arxiv.org/abs/2403.15243)

    提出了一种生成对抗网络（GAN）方法，用于解决一般和现实设置下的稳健效用优化问题，该方法在实证研究中表现出色，能在没有已知最佳策略的情况下胜过所有其他参考策略

    

    稳健效用优化使投资者能够以结构化方式处理市场不确定性，旨在最大化最坏情况的结果。在这项工作中，我们提出了一种生成对抗网络（GAN）方法，（近似地）解决一般和现实设置下的稳健效用优化问题。特别地，我们通过神经网络（NN）对投资者和市场进行建模，并在极小极大零和博弈中训练它们。这种方法适用于任何连续效用函数，并在具有交易成本的现实市场设置中，只能使用市场的可观察信息。大量实证研究显示了我们方法的多功能性。每当存在最佳参考策略时，我们的方法都能与之媲美，在没有已知最佳策略的（许多）设置中，我们的方法胜过所有其他参考策略。此外，我们可以从研究中得出结论

    arXiv:2403.15243v1 Announce Type: cross  Abstract: Robust utility optimization enables an investor to deal with market uncertainty in a structured way, with the goal of maximizing the worst-case outcome. In this work, we propose a generative adversarial network (GAN) approach to (approximately) solve robust utility optimization problems in general and realistic settings. In particular, we model both the investor and the market by neural networks (NN) and train them in a mini-max zero-sum game. This approach is applicable for any continuous utility function and in realistic market settings with trading costs, where only observable information of the market can be used. A large empirical study shows the versatile usability of our method. Whenever an optimal reference strategy is available, our method performs on par with it and in the (many) settings without known optimal strategy, our method outperforms all other reference strategies. Moreover, we can conclude from our study that the tr
    
[^23]: 引导解码用于机器人运动生成和适应

    Guided Decoding for Robot Motion Generation and Adaption

    [https://arxiv.org/abs/2403.15239](https://arxiv.org/abs/2403.15239)

    通过将演示学习集成到运动生成中，使机器人能够实时生成适应复杂环境的运动

    

    我们针对具有障碍物、通过点等复杂环境下的高自由度机器人臂运动生成问题进行了探讨。通过将演示学习（LfD）集成到运动生成过程中，取得了该领域的重大进展。这种集成支持机器人快速适应新任务，并通过允许机器人从演示轨迹中学习和泛化来优化积累的经验利用。我们在大量模拟轨迹数据集上训练了一个变分自动编码器变换器的transformer架构。这种基于条件变分自动编码器变换器的架构学习了基本的运动生成技能，并将其调整以满足辅助任务和约束条件。我们的自回归方法实现了物理系统反馈的实时集成，增强了运动生成的适应性和效率。我们展示了我们的模型能够从初始点和目标点生成运动，同时

    arXiv:2403.15239v1 Announce Type: cross  Abstract: We address motion generation for high-DoF robot arms in complex settings with obstacles, via points, etc. A significant advancement in this domain is achieved by integrating Learning from Demonstration (LfD) into the motion generation process. This integration facilitates rapid adaptation to new tasks and optimizes the utilization of accumulated expertise by allowing robots to learn and generalize from demonstrated trajectories.   We train a transformer architecture on a large dataset of simulated trajectories. This architecture, based on a conditional variational autoencoder transformer, learns essential motion generation skills and adapts these to meet auxiliary tasks and constraints. Our auto-regressive approach enables real-time integration of feedback from the physical system, enhancing the adaptability and efficiency of motion generation. We show that our model can generate motion from initial and target points, but also that it 
    
[^24]: 在大型语言模型训练数据集中对代码许可侵权的初步调查

    An Exploratory Investigation into Code License Infringements in Large Language Model Training Datasets

    [https://arxiv.org/abs/2403.15230](https://arxiv.org/abs/2403.15230)

    该研究调查了大型语言模型训练数据集中的代码许可侵权问题，发现每个数据集都存在许可不一致性，尽管它们是基于相关代码仓库许可证来选择的。

    

    arXiv:2403.15230v1 公告类型: 跨领域 摘要: 训练大型语言模型是否潜在侵犯代码许可？此外，是否有可用于训练这些模型而不违反这些许可的数据集？在我们的研究中，我们评估了该领域的当前趋势以及将代码纳入大型语言模型训练的重要性。此外，我们检查了公开可用的数据集，以查看是否可以在这些数据集上训练这些模型而不会面临未来的法律问题。为了实现这一目标，我们编制了一个包含53个基于文件级代码训练的大型语言模型的列表。然后我们提取了它们的数据集，并分析了它们与我们创建的数据集重叠的程度，后者仅包含强制共享代码。

    arXiv:2403.15230v1 Announce Type: cross  Abstract: Does the training of large language models potentially infringe upon code licenses? Furthermore, are there any datasets available that can be safely used for training these models without violating such licenses? In our study, we assess the current trends in the field and the importance of incorporating code into the training of large language models. Additionally, we examine publicly available datasets to see whether these models can be trained on them without the risk of legal issues in the future. To accomplish this, we compiled a list of 53 large language models trained on file-level code. We then extracted their datasets and analyzed how much they overlap with a dataset we created, consisting exclusively of strong copyleft code.   Our analysis revealed that every dataset we examined contained license inconsistencies, despite being selected based on their associated repository licenses. We analyzed a total of 514 million code files
    
[^25]: 无论何时、何地、谁人：研究用于众包医学图像标注的部分任意模型的可行性

    Anytime, Anywhere, Anyone: Investigating the Feasibility of Segment Anything Model for Crowd-Sourcing Medical Image Annotations

    [https://arxiv.org/abs/2403.15218](https://arxiv.org/abs/2403.15218)

    该研究探讨了使用部分任意模型（SAM）在众包环境中从非专家处策划医学图像标注的可行性，以生成用于训练3D DL分割模型的"密集"分割掩模。

    

    医学图像分割注释的策划是一项耗时且劳动密集的任务，需要领域专业知识，导致"狭窄"专注的深度学习（DL）模型具有有限的转化效用。最近，像部分任意模型（SAM）这样的基础模型通过出色的零样本泛化能力彻底改变了语义分割，跨各个领域包括医学成像，对于简化注释过程有很大希望。然而，SAM尚未在众包环境中进行评估，以策划注释来训练3D DL分割模型。在这项工作中，我们探索了SAM用于从非专业人员中众包"稀疏"注释，产生用于训练3D nnU-Net模型（一种最先进的DL分割模型）的"密集"分割掩模的潜力。我们的结果表明，与地面真实度相比，SAM生成的注释展现出高平均Dice分数。

    arXiv:2403.15218v1 Announce Type: cross  Abstract: Curating annotations for medical image segmentation is a labor-intensive and time-consuming task that requires domain expertise, resulting in "narrowly" focused deep learning (DL) models with limited translational utility. Recently, foundation models like the Segment Anything Model (SAM) have revolutionized semantic segmentation with exceptional zero-shot generalizability across various domains, including medical imaging, and hold a lot of promise for streamlining the annotation process. However, SAM has yet to be evaluated in a crowd-sourced setting to curate annotations for training 3D DL segmentation models. In this work, we explore the potential of SAM for crowd-sourcing "sparse" annotations from non-experts to generate "dense" segmentation masks for training 3D nnU-Net models, a state-of-the-art DL segmentation model. Our results indicate that while SAM-generated annotations exhibit high mean Dice scores compared to ground-truth a
    
[^26]: 训练早期影响超出分布泛化

    Early Period of Training Impacts Out-of-Distribution Generalization

    [https://arxiv.org/abs/2403.15210](https://arxiv.org/abs/2403.15210)

    神经网络训练早期阶段的影响对超出分布泛化进行了研究，通过探究学习动态和用于调查的渐进解冻方法，揭示了其重要性。

    

    先前的研究发现神经网络训练的早期阶段的差异显著影响分布内（ID）任务的表现。然而，神经网络往往对超出分布（OOD）数据敏感，在下游应用中变得不太可靠。然而，由于其复杂性和缺乏有效的分析方法，早期训练阶段对OOD泛化的影响仍未得到充分研究。在这项工作中，我们研究了学习动态和神经网络训练早期阶段的OOD泛化之间的关系。我们利用Fisher信息的痕迹和锐利度，重点关注渐进解冻（即在训练过程中逐渐解冻参数）作为研究方法。通过一系列实证实验，我们展示了1）在训练过程中选择不同时间点的可训练参数数量，即逐渐解冻的实现方式

    arXiv:2403.15210v1 Announce Type: new  Abstract: Prior research has found that differences in the early period of neural network training significantly impact the performance of in-distribution (ID) tasks. However, neural networks are often sensitive to out-of-distribution (OOD) data, making them less reliable in downstream applications. Yet, the impact of the early training period on OOD generalization remains understudied due to its complexity and lack of effective analytical methodologies. In this work, we investigate the relationship between learning dynamics and OOD generalization during the early period of neural network training. We utilize the trace of Fisher Information and sharpness, with a focus on gradual unfreezing (i.e. progressively unfreezing parameters during training) as the methodology for investigation. Through a series of empirical experiments, we show that 1) selecting the number of trainable parameters at different times during training, i.e. realized by gradual 
    
[^27]: 对抗学习的鲁棒优化与有限样本复杂性保证

    Robust optimization for adversarial learning with finite sample complexity guarantees

    [https://arxiv.org/abs/2403.15207](https://arxiv.org/abs/2403.15207)

    本文提出了一种针对对抗学习的鲁棒分类器的新型训练方法，通过最小化最坏情况下的替代损失来实现，同时在线性和非线性模型上推导出了有限样本复杂性界限。

    

    在存在不确定性的决策和学习过程中，越来越需要实现鲁棒和可靠的操作。当不确定性来自对抗性攻击时，这种需求变得更加突出。本文聚焦于线性和非线性分类问题，提出了一种新颖的对抗训练方法，用于强大的分类器，灵感来自支持向量机（SVM）边界。我们通过数据驱动的角度看待鲁棒性，并针对二元和多类场景推导出了线性和非线性分类器的有限样本复杂性界限。值得注意的是，我们的界限与自然分类器的复杂性相匹配。我们的算法使用线性规划（LP）和二阶锥规划（SOCP）最小化最坏情况的替代损失，适用于线性和非线性模型。在基准MNIST和CIFAR10数据集上的数值实验展示了我们方法的性能。

    arXiv:2403.15207v1 Announce Type: new  Abstract: Decision making and learning in the presence of uncertainty has attracted significant attention in view of the increasing need to achieve robust and reliable operations. In the case where uncertainty stems from the presence of adversarial attacks this need is becoming more prominent. In this paper we focus on linear and nonlinear classification problems and propose a novel adversarial training method for robust classifiers, inspired by Support Vector Machine (SVM) margins. We view robustness under a data driven lens, and derive finite sample complexity bounds for both linear and non-linear classifiers in binary and multi-class scenarios. Notably, our bounds match natural classifiers' complexity. Our algorithm minimizes a worst-case surrogate loss using Linear Programming (LP) and Second Order Cone Programming (SOCP) for linear and non-linear models. Numerical experiments on the benchmark MNIST and CIFAR10 datasets show our approach's com
    
[^28]: FSD-Inference: 具有可扩展云通信的完全无服务器分布式推断

    FSD-Inference: Fully Serverless Distributed Inference with Scalable Cloud Communication

    [https://arxiv.org/abs/2403.15195](https://arxiv.org/abs/2403.15195)

    FSD-Inference是第一个完全无服务器且高度可扩展的分布式ML推断系统，引入了全新的无服务器通信方案。

    

    arXiv:2403.15195v1 公告类型:跨领域 抽象: 无服务器计算提供了具有吸引力的可伸缩性、弹性和成本效益。然而，对内存、CPU和函数运行时间的限制阻碍了其在数据密集型应用和机器学习（ML）工作负载中的应用。传统的“全服务器”平台通过快速网络和已建立良好的进程间通信（IPC）机制（如MPI和共享内存）实现了分布式计算。在无服务器领域缺乏此类解决方案的情况下，具有重要IPC要求的并行计算具有挑战性。我们提出FSD-Inference，这是第一个完全无服务器且高度可扩展的分布式ML推断系统。我们探讨潜在的通信渠道，与函数即服务（FaaS）计算相结合，为无服务器数据密集型计算环境中的分布式ML设计了一流的解决方案。我们引入了用于ML推断的全新无服务器通信方案。

    arXiv:2403.15195v1 Announce Type: cross  Abstract: Serverless computing offers attractive scalability, elasticity and cost-effectiveness. However, constraints on memory, CPU and function runtime have hindered its adoption for data-intensive applications and machine learning (ML) workloads. Traditional 'server-ful' platforms enable distributed computation via fast networks and well-established inter-process communication (IPC) mechanisms such as MPI and shared memory. In the absence of such solutions in the serverless domain, parallel computation with significant IPC requirements is challenging. We present FSD-Inference, the first fully serverless and highly scalable system for distributed ML inference. We explore potential communication channels, in conjunction with Function-as-a-Service (FaaS) compute, to design a state-of-the-art solution for distributed ML within the context of serverless data-intensive computing. We introduce novel fully serverless communication schemes for ML infe
    
[^29]: 你的图像就是我的视频：通过图像到视频可微分自动数据增强和融合重新塑造感受野

    Your Image is My Video: Reshaping the Receptive Field via Image-To-Video Differentiable AutoAugmentation and Fusion

    [https://arxiv.org/abs/2403.15194](https://arxiv.org/abs/2403.15194)

    通过Differentiable Augmentation Search (DAS) 方法，能够快速生成可处理为视频的图像变体，以提高模型对数据的利用效率。

    

    深度学习研究领域正朝着利用数据真正潜力的创新策略发展。本文提出了一种新颖技术，通过自动数据增强来充分利用可用数据，用于图像分类和语义分割任务。我们引入了第一个可微分增强搜索方法（DAS）来生成图像的变体，这些图像可以被处理为视频。与以往方法相比，DAS 非常快速和灵活，能够在不到一天的 GPU 计算时间内搜索非常庞大的搜索空间。我们的直觉是增大感受野

    arXiv:2403.15194v1 Announce Type: cross  Abstract: The landscape of deep learning research is moving towards innovative strategies to harness the true potential of data. Traditionally, emphasis has been on scaling model architectures, resulting in large and complex neural networks, which can be difficult to train with limited computational resources. However, independently of the model size, data quality (i.e. amount and variability) is still a major factor that affects model generalization. In this work, we propose a novel technique to exploit available data through the use of automatic data augmentation for the tasks of image classification and semantic segmentation. We introduce the first Differentiable Augmentation Search method (DAS) to generate variations of images that can be processed as videos. Compared to previous approaches, DAS is extremely fast and flexible, allowing the search on very large search spaces in less than a GPU day. Our intuition is that the increased receptiv
    
[^30]: PDE-CNNs：公理推导与应用

    PDE-CNNs: Axiomatic Derivations and Applications

    [https://arxiv.org/abs/2403.15182](https://arxiv.org/abs/2403.15182)

    PDE-CNNs通过利用几何意义的演化PDE的求解器替代传统的组件，提供了更少的参数、固有的等变性、更好的性能、数据效率和几何可解释性。

    

    基于偏微分方程组卷积神经网络（PDE-G-CNNs）利用具有几何意义的演化偏微分方程的求解器替代G-CNNs中常规组件。PDE-G-CNNs同时提供了几个关键优势：更少的参数、固有等变性、更好的性能、数据效率和几何可解释性。本文重点研究特征图在整个网络中为二维的欧几里德等变PDE-G-CNNs。我们将这个框架的变体称为PDE-CNN。我们列出了几个在实践中令人满意的公理，并从中推导出应在PDE-CNN中使用哪些PDE。在这里，我们通过经典线性和形态尺度空间理论的公理受启发，通过引入半域值信号对其进行推广。此外，我们通过实验证实，相对于小型网络，PDE-CNN提供了更少的参数、更好的性能和数据效率。

    arXiv:2403.15182v1 Announce Type: new  Abstract: PDE-based Group Convolutional Neural Networks (PDE-G-CNNs) utilize solvers of geometrically meaningful evolution PDEs as substitutes for the conventional components in G-CNNs. PDE-G-CNNs offer several key benefits all at once: fewer parameters, inherent equivariance, better performance, data efficiency, and geometric interpretability. In this article we focus on Euclidean equivariant PDE-G-CNNs where the feature maps are two dimensional throughout. We call this variant of the framework a PDE-CNN. We list several practically desirable axioms and derive from these which PDEs should be used in a PDE-CNN. Here our approach to geometric learning via PDEs is inspired by the axioms of classical linear and morphological scale-space theory, which we generalize by introducing semifield-valued signals. Furthermore, we experimentally confirm for small networks that PDE-CNNs offer fewer parameters, better performance, and data efficiency in compariso
    
[^31]: 自我改进用于神经组合优化问题：无需替换进行采样，但改进

    Self-Improvement for Neural Combinatorial Optimization: Sample without Replacement, but Improvement

    [https://arxiv.org/abs/2403.15180](https://arxiv.org/abs/2403.15180)

    通过结合循环式随机束搜索和来自可证策略改进的更新策略，本研究在神经组合优化中引入了一种新的训练方法，从而在最小采样次数中实现逐步改进的解决方案。

    

    目前，对于端到端的构造性神经组合优化方法通常是使用行为克隆来训练策略，从专家解决方案中或使用策略梯度从强化学习中进行训练。虽然行为克隆方法很直接，但需要昂贵的专家解决方案，而策略梯度方法往往计算要求很高，难以进行精细调整。在这项工作中，我们桥接了这两种方法，并通过在每个纪元中使用当前模型对随机实例进行多个解决方案的采样，然后选择最佳解作为专家轨迹进行监督模仿学习，从而简化了训练过程。为了在最小采样次数中实现逐步改进的解决方案，我们引入了一种将循环式随机束搜索与一种推导自可证策略改进的更新策略相结合的方法。该策略通过利用几乎没有通信开销的样本序列的优势，在轮之间调整策略，以精细化策略。

    arXiv:2403.15180v1 Announce Type: new  Abstract: Current methods for end-to-end constructive neural combinatorial optimization usually train a policy using behavior cloning from expert solutions or policy gradient methods from reinforcement learning. While behavior cloning is straightforward, it requires expensive expert solutions, and policy gradient methods are often computationally demanding and complex to fine-tune. In this work, we bridge the two and simplify the training process by sampling multiple solutions for random instances using the current model in each epoch and then selecting the best solution as an expert trajectory for supervised imitation learning. To achieve progressively improving solutions with minimal sampling, we introduce a method that combines round-wise Stochastic Beam Search with an update strategy derived from a provable policy improvement. This strategy refines the policy between rounds by utilizing the advantage of the sampled sequences with almost no com
    
[^32]: 在检测心理疾病的情境中探索自监督学习的任务无关特性

    Exploring the Task-agnostic Trait of Self-supervised Learning in the Context of Detecting Mental Disorders

    [https://arxiv.org/abs/2403.15170](https://arxiv.org/abs/2403.15170)

    本研究探索了在检测主要抑郁症和创伤后应激障碍时，在交互会话期间收集的音频和视频数据上使用自监督学习的任务无关表示。

    

    自监督学习（SSL）已经被研究用于在各个领域生成任务无关的表示。然而，到目前为止，尚未有人探索用于检测多种心理障碍的这种方法。存在任务无关表示的理由在于多种心理障碍之间的症状重叠。因此，收集用于心理健康评估的行为数据可能包含与多种障碍相关的属性。受此启发，本研究探讨了通过SSL推导出的任务无关表示，用于使用在互动会话期间收集的音频和视频数据检测重度抑郁障碍（MDD）和创伤后应激障碍（PTSD）的情境。本研究采用了通过预测多个固定目标或掩膜帧训练的SSL模型。我们提出了一系列固定目标，以使生成的表示对MDD的检测更加高效。

    arXiv:2403.15170v1 Announce Type: cross  Abstract: Self-supervised learning (SSL) has been investigated to generate task-agnostic representations across various domains. However, such investigation has not been conducted for detecting multiple mental disorders. The rationale behind the existence of a task-agnostic representation lies in the overlapping symptoms among multiple mental disorders. Consequently, the behavioural data collected for mental health assessment may carry a mixed bag of attributes related to multiple disorders. Motivated by that, in this study, we explore a task-agnostic representation derived through SSL in the context of detecting major depressive disorder (MDD) and post-traumatic stress disorder (PTSD) using audio and video data collected during interactive sessions. This study employs SSL models trained by predicting multiple fixed targets or masked frames. We propose a list of fixed targets to make the generated representation more efficient for detecting MDD 
    
[^33]: 目标类分类的转换图属性

    Transition Graph Properties of Target Class Classification

    [https://arxiv.org/abs/2403.15167](https://arxiv.org/abs/2403.15167)

    目标类分类的关键在于转换图的属性，研究表明理想的转换图结构是朝根顶点方向取向的有根树。

    

    目标类分类是一个混合分类和转换模型，其综合目标是将对象分配到某个所谓的目标或正常类。分类过程是迭代的，在每一步中，某个类中的对象经历与该类相对应的动作，引发对象向其中一个类的转变。我们称之为类转换的转换序列必须设计得能为对象最终分配到目标类提供支持。转换过程可以用有向图的形式描述，最终分类的成功主要取决于这个图的属性。在我们之前的研究中，我们表明了转换图的理想结构是一个朝根顶点方向取向的有根树，该顶点对应于正常类。很明显，任意算法（策略）的转换图可能没有

    arXiv:2403.15167v1 Announce Type: cross  Abstract: Target class classification is a mixed classification and transition model whose integrated goal is to assign objects to a certain, so called target or normal class. The classification process is iterative, and in each step an object in a certain class undergoes an action attached to that class, initiating the transition of the object to one of the classes. The sequence of transitions, which we call class transitions, must be designed to provide the final assignment of objects to the target class. The transition process can be described in the form of a directed graph, and the success of the final classification is mainly due to the properties of this graph. In our previous research we showed that the desirable structure of the transition graph is an oriented rooted tree with orientation towards the root vertex, which corresponds to the normal class. It is clear that the transition graph of an arbitrary algorithm (policy) may not have 
    
[^34]: 深度学习数据减少方法的深度分析

    An In-Depth Analysis of Data Reduction Methods for Sustainable Deep Learning

    [https://arxiv.org/abs/2403.15150](https://arxiv.org/abs/2403.15150)

    本文深度分析了深度学习数据减少方法对提升效率的作用，提出了多种减小训练数据集大小的方法，并开发了用于衡量数据集相似度的拓扑代表性度量。

    

    近年来，深度学习因其解决复杂分类任务的能力而备受青睐，随着更精确模型的开发、海量数据的可用性以及现代计算机改进的计算能力，不断取得更好的结果。然而，这些性能的提升也带来了效率问题，涉及数据集和模型的存储，以及训练和推理过程中涉及的能源和时间浪费。在这种背景下，数据减少有助于在训练深度学习模型时减少能源消耗。本文介绍了八种不同的方法来减小表格训练数据集的大小，并开发了一个Python软件包来应用这些方法。我们还引入了一种基于拓扑的代表性度量，用以衡量减少的数据集和完整训练数据集之间的相似程度。

    arXiv:2403.15150v1 Announce Type: new  Abstract: In recent years, Deep Learning has gained popularity for its ability to solve complex classification tasks, increasingly delivering better results thanks to the development of more accurate models, the availability of huge volumes of data and the improved computational capabilities of modern computers. However, these improvements in performance also bring efficiency problems, related to the storage of datasets and models, and to the waste of energy and time involved in both the training and inference processes. In this context, data reduction can help reduce energy consumption when training a deep learning model. In this paper, we present up to eight different methods to reduce the size of a tabular training dataset, and we develop a Python package to apply them. We also introduce a representativeness metric based on topology to measure how similar are the reduced datasets and the full training dataset. Additionally, we develop a methodo
    
[^35]: Adam在非均匀光滑情况下的收敛性：与SGDM的可分性及其拓展

    On the Convergence of Adam under Non-uniform Smoothness: Separability from SGDM and Beyond

    [https://arxiv.org/abs/2403.15146](https://arxiv.org/abs/2403.15146)

    Adam在非均匀光滑情况下与SGDM的收敛速率有明显区别，Adam更快地达到收敛，并具有更低的下界。

    

    本文旨在明确区分动量随机梯度下降（SGDM）和Adam在收敛速率方面的差异。我们证明了在非均匀有界光滑度条件下，Adam相对于SGDM实现了更快的收敛。我们的研究发现：（1）在确定性环境中，Adam可以达到确定性一阶优化器收敛速率的已知下界，而动量梯度下降（GDM）的收敛速率对初始函数值具有更高阶的依赖性；（2）在随机设置下，Adam的收敛速率上界匹配了随机一阶优化器的下界，考虑到初始函数值和最终误差，而SGDM存在学习率下失败收敛的情况。这些发现清晰地区分了Adam和SGDM在收敛速率方面的差异。

    arXiv:2403.15146v1 Announce Type: new  Abstract: This paper aims to clearly distinguish between Stochastic Gradient Descent with Momentum (SGDM) and Adam in terms of their convergence rates. We demonstrate that Adam achieves a faster convergence compared to SGDM under the condition of non-uniformly bounded smoothness. Our findings reveal that: (1) in deterministic environments, Adam can attain the known lower bound for the convergence rate of deterministic first-order optimizers, whereas the convergence rate of Gradient Descent with Momentum (GDM) has higher order dependence on the initial function value; (2) in stochastic setting, Adam's convergence rate upper bound matches the lower bounds of stochastic first-order optimizers, considering both the initial function value and the final error, whereas there are instances where SGDM fails to converge with any learning rate. These insights distinctly differentiate Adam and SGDM regarding their convergence rates. Additionally, by introduci
    
[^36]: 基于直方图的置换不变网络的量化方法

    Quantification using Permutation-Invariant Networks based on Histograms

    [https://arxiv.org/abs/2403.15123](https://arxiv.org/abs/2403.15123)

    本文研究了深度神经网络在量化任务中的应用，提出了基于直方图的置换不变网络HistNetQ，在量化比赛中表现优异。

    

    量化，也称为类别普遍性估计，是监督学习任务，模型被训练用来预测给定样本集中每个类的普遍性。本文研究了深度神经网络在量化任务中的应用，特别关注可以应用对称监督方法的情况，从而消除了分类作为中间步骤的需求，直接解决量化问题。此外，本文讨论了为集合处理设计的现有置换不变层，并评估了它们对量化的适用性。在我们的分析基础上，我们提出了HistNetQ，一种新颖的神经架构，它依赖于基于直方图的置换不变表示，特别适用于量化问题。我们在迄今为止唯一的量化竞赛中进行的实验表明，HistNetQ胜过其他深度神经网络架构。

    arXiv:2403.15123v1 Announce Type: new  Abstract: Quantification, also known as class prevalence estimation, is the supervised learning task in which a model is trained to predict the prevalence of each class in a given bag of examples. This paper investigates the application of deep neural networks to tasks of quantification in scenarios where it is possible to apply a symmetric supervised approach that eliminates the need for classification as an intermediary step, directly addressing the quantification problem. Additionally, it discusses existing permutation-invariant layers designed for set processing and assesses their suitability for quantification. In light of our analysis, we propose HistNetQ, a novel neural architecture that relies on a permutation-invariant representation based on histograms that is specially suited for quantification problems. Our experiments carried out in the only quantification competition held to date, show that HistNetQ outperforms other deep neural arch
    
[^37]: 使用LLM嵌入进行文本聚类

    Text clustering with LLM embeddings

    [https://arxiv.org/abs/2403.15112](https://arxiv.org/abs/2403.15112)

    研究表明，LLM嵌入能够捕捉结构化语言的细微差别，BERT在性能上领先于轻量级选项，增加嵌入维度和摘要技术并不一致地提高聚类效率

    

    文本聚类是组织不断增长的数字内容的重要方法，有助于结构化和发现未分类数据中的隐藏模式。在这项研究中，我们调查了不同文本嵌入（特别是大型语言模型LLMs中使用的）和聚类算法如何影响文本数据集的聚类方式。进行了一系列实验以评估嵌入是如何影响聚类结果的，以及通过摘要进行降维和嵌入大小调整的作用。结果显示，LLM嵌入在捕获结构化语言的细微差别方面表现出色，而BERT在性能上领先于轻量级选项。此外，我们发现增加嵌入维度和摘要技术并不一致地提高聚类效率，这表明这些策略需要仔细分析才能在实际模型中使用。这些结果突出了一种

    arXiv:2403.15112v1 Announce Type: cross  Abstract: Text clustering is an important approach for organising the growing amount of digital content, helping to structure and find hidden patterns in uncategorised data. In this research, we investigated how different textual embeddings - particularly those used in large language models (LLMs) - and clustering algorithms affect how text datasets are clustered. A series of experiments were conducted to assess how embeddings influence clustering results, the role played by dimensionality reduction through summarisation, and embedding size adjustment. Results reveal that LLM embeddings excel at capturing the nuances of structured language, while BERT leads the lightweight options in performance. In addition, we find that increasing embedding dimensionality and summarisation techniques do not uniformly improve clustering efficiency, suggesting that these strategies require careful analysis to use in real-life models. These results highlight a co
    
[^38]: 基于Wasserstein距离和GroupSort神经网络的回归主动学习

    Active Learning for Regression based on Wasserstein distance and GroupSort Neural Networks

    [https://arxiv.org/abs/2403.15108](https://arxiv.org/abs/2403.15108)

    该论文提出了一种基于Wasserstein距离和GroupSort神经网络的主动学习方法，该方法在回归问题中实现了更精确的估计并比其他模型更快提高准确性。

    

    本文介绍了一种新的用于回归问题的主动学习策略。所提出的Wasserstein主动回归模型基于分布匹配原则，用于衡量标记数据集的代表性。使用GroupSort神经网络计算Wasserstein距离。这些网络的使用提供了理论基础，可以量化错误并明确其大小和深度。此解决方案结合了另一种基于不确定性的方法，对异常值更具容忍性，以完成查询策略。最后，该方法与其他经典和最近的解决方案进行了比较。研究实验性地展示了这种代表性-不确定性方法的相关性，该方法在整个查询过程中提供了良好的估计。此外，Wasserstein主动回归通常能够实现更精确的估计，并且往往比其他模型更快提高准确性。

    arXiv:2403.15108v1 Announce Type: new  Abstract: This paper addresses a new active learning strategy for regression problems. The presented Wasserstein active regression model is based on the principles of distribution-matching to measure the representativeness of the labeled dataset. The Wasserstein distance is computed using GroupSort Neural Networks. The use of such networks provides theoretical foundations giving a way to quantify errors with explicit bounds for their size and depth. This solution is combined with another uncertainty-based approach that is more outlier-tolerant to complete the query strategy. Finally, this method is compared with other classical and recent solutions. The study empirically shows the pertinence of such a representativity-uncertainty approach, which provides good estimation all along the query procedure. Moreover, the Wasserstein active regression often achieves more precise estimations and tends to improve accuracy faster than other models.
    
[^39]: 用合成数据改进胎儿MRI中跨领域脑组织分割

    Improving cross-domain brain tissue segmentation in fetal MRI with synthetic data

    [https://arxiv.org/abs/2403.15103](https://arxiv.org/abs/2403.15103)

    提出了FetalSynthSeg方法，用于改进胎儿MRI中的脑组织分割，通过领域随机化方法，模型在跨领域数据集上的效果优于传统模型。

    

    胎儿脑组织在磁共振成像（MRI）中的分割对于子宫内神经发育的研究起着至关重要的作用。然而，自动化工具面临着重大的领域转移挑战，因为它们必须对高度异质的临床数据具有健壮性，这些数据通常数量有限且缺乏注释。本研究提出了一种灵感来源于SynthSeg的FetalSynthSeg领域随机化方法，用于分割胎儿脑MRI。我们的结果表明，仅在合成数据上训练的模型在跨领域数据集上的表现优于在真实数据上训练的模型，在一个包含120个对象的数据集上进行了验证。此外，我们将评估扩展到使用低磁场（0.55T）MRI采集并用新型SR模型重建的40个对象。

    arXiv:2403.15103v1 Announce Type: cross  Abstract: Segmentation of fetal brain tissue from magnetic resonance imaging (MRI) plays a crucial role in the study of in utero neurodevelopment. However, automated tools face substantial domain shift challenges as they must be robust to highly heterogeneous clinical data, often limited in numbers and lacking annotations. Indeed, high variability of the fetal brain morphology, MRI acquisition parameters, and superresolution reconstruction (SR) algorithms adversely affect the model's performance when evaluated out-of-domain. In this work, we introduce FetalSynthSeg, a domain randomization method to segment fetal brain MRI, inspired by SynthSeg. Our results show that models trained solely on synthetic data outperform models trained on real data in out-ofdomain settings, validated on a 120-subject cross-domain dataset. Furthermore, we extend our evaluation to 40 subjects acquired using lowfield (0.55T) MRI and reconstructed with novel SR models, s
    
[^40]: 利用人工智能和环境噪声层析成像的端到端矿产勘探

    End-to-End Mineral Exploration with Artificial Intelligence and Ambient Noise Tomography

    [https://arxiv.org/abs/2403.15095](https://arxiv.org/abs/2403.15095)

    该论文提出了一种端到端工作流程，将环境噪声层析成像（ANT）和人工智能（AI）相结合，以增强对于铜等矿产资源的发现和描绘。

    

    本文提出了一种创新的端到端工作流程，将环境噪声层析成像（ANT）和人工智能（AI）相结合，以增强对矿产资源的发现和描绘，这对全球转向低碳经济至关重要。我们集中讨论铜作为一种关键元素，可在可再生能源解决方案中大量需要。我们展示了利用ANT的好处，其特点是速度快、可伸缩、穿透深度高、分辨率高和环境影响小，结合人工智能（AI）技术，在本地高分辨率数据上微调我们的模型，在矿床尺度上细化所在大陆尺度上远景性的模型。我们首先展示了针对澳大利亚铜矿的新一代数据驱动的AI远景模型，作为我们进一步微调的基础模型。然后我们专注于Hillside IOCG矿床的远景。

    arXiv:2403.15095v1 Announce Type: cross  Abstract: This paper presents an innovative end-to-end workflow for mineral exploration, integrating ambient noise tomography (ANT) and artificial intelligence (AI) to enhance the discovery and delineation of mineral resources essential for the global transition to a low carbon economy. We focus on copper as a critical element, required in significant quantities for renewable energy solutions. We show the benefits of utilising ANT, characterised by its speed, scalability, depth penetration, resolution, and low environmental impact, alongside artificial intelligence (AI) techniques to refine a continent-scale prospectivity model at the deposit scale by fine-tuning our model on local high-resolution data. We show the promise of the method by first presenting a new data-driven AI prospectivity model for copper within Australia, which serves as our foundation model for further fine-tuning. We then focus on the Hillside IOCG deposit on the prospectiv
    
[^41]: 针对深度强化学习的改进长短期记忆污水处理模拟器

    Improved Long Short-Term Memory-based Wastewater Treatment Simulators for Deep Reinforcement Learning

    [https://arxiv.org/abs/2403.15091](https://arxiv.org/abs/2403.15091)

    改进长短期记忆污水处理模拟器，解决DRL优化工业过程中的挑战，通过减少复合误差提高模型的准确性

    

    虽然深度强化学习(DRL)在机器人技术和游戏领域取得了杰出成果，但在污水处理等工业过程的优化中实施DRL仍然具有挑战性。其中一个挑战是缺乏能够尽可能准确地代表实际工厂的模拟环境，以训练DRL策略。污水处理数据的随机性和非线性导致模型在长时间范围内产生不稳定和不正确的预测。改进的模型中可能出现模拟行为不正确的一个可能原因是复合误差问题，即在模拟过程中误差的累积。复合误差是因为模型在每个时间步中使用其预测作为输入，实际数据与预测之间的误差随着模拟的进行而累积。我们实施了两种方法来改善污水处理模型的训练结果。

    arXiv:2403.15091v1 Announce Type: cross  Abstract: Even though Deep Reinforcement Learning (DRL) showed outstanding results in the fields of Robotics and Games, it is still challenging to implement it in the optimization of industrial processes like wastewater treatment. One of the challenges is the lack of a simulation environment that will represent the actual plant as accurately as possible to train DRL policies. Stochasticity and non-linearity of wastewater treatment data lead to unstable and incorrect predictions of models over long time horizons. One possible reason for the models' incorrect simulation behavior can be related to the issue of compounding error, which is the accumulation of errors throughout the simulation. The compounding error occurs because the model utilizes its predictions as inputs at each time step. The error between the actual data and the prediction accumulates as the simulation continues. We implemented two methods to improve the trained models for wastew
    
[^42]: SIMAP：神经网络的一个单纯同调图层

    SIMAP: A simplicial-map layer for neural networks

    [https://arxiv.org/abs/2403.15083](https://arxiv.org/abs/2403.15083)

    SIMAP是一个神经网络图层，与其他深度学习架构结合，作为可解释图层替代经典的密集最终图层，支持集基于固定的最大单纯体。

    

    在本文中，我们介绍了SIMAP，这是一个嵌入深度学习模型中的新颖图层，旨在增强输出的可解释性。SIMAP图层是Simplicial-Map神经网络（SMNNs）的增强版本，是一种基于支持集和单纯同调映射（拓扑学中用来在保持结构连通性的同时转换形状的函数）的可解释神经网络。该论文提出的方法的创新性有两个方面：首先，SIMAP图层与其他深度学习架构配合工作，作为一个可解释的图层替代经典的密集最终图层。其次，与SMNNs不同，支持集基于固定的最大单纯体，其重心分割可以通过基于矩阵的乘法算法高效计算。

    arXiv:2403.15083v1 Announce Type: new  Abstract: In this paper, we present SIMAP, a novel layer integrated into deep learning models, aimed at enhancing the interpretability of the output. The SIMAP layer is an enhanced version of Simplicial-Map Neural Networks (SMNNs), an explainable neural network based on support sets and simplicial maps (functions used in topology to transform shapes while preserving their structural connectivity). The novelty of the methodology proposed in this paper is two-fold: Firstly, SIMAP layers work in combination with other deep learning architectures as an interpretable layer substituting classic dense final layers. Secondly, unlike SMNNs, the support set is based on a fixed maximal simplex, the barycentric subdivision being efficiently computed with a matrix-based multiplication algorithm.
    
[^43]: 逆强化学习的自动特征选择

    Automated Feature Selection for Inverse Reinforcement Learning

    [https://arxiv.org/abs/2403.15079](https://arxiv.org/abs/2403.15079)

    提出了一种使用多项式基函数进行特征选择的方法，通过匹配状态分布的统计矩和利用轨迹概率与特征期望的相关性，有效地恢复奖励函数。

    

    逆强化学习（IRL）是一种从专家示范中学习奖励函数的模仿学习方法。它的使用避免了手动指定奖励的困难和繁琐过程，同时保留了强化学习的泛化能力。在IRL中，奖励通常被表示为特征的线性组合。在连续状态空间中，仅使用状态变量作为特征不够丰富，但通常不清楚哪些特征是好的。为了解决这个问题，我们提出了一种方法，该方法利用多项式基函数来形成候选特征集合，这些特征被证明可以匹配状态分布的统计矩。然后通过利用轨迹概率和特征期望之间的相关性对候选特征进行特征选择。我们通过恢复捕获奖励函数的方式展示了该方法的有效性。

    arXiv:2403.15079v1 Announce Type: new  Abstract: Inverse reinforcement learning (IRL) is an imitation learning approach to learning reward functions from expert demonstrations. Its use avoids the difficult and tedious procedure of manual reward specification while retaining the generalization power of reinforcement learning. In IRL, the reward is usually represented as a linear combination of features. In continuous state spaces, the state variables alone are not sufficiently rich to be used as features, but which features are good is not known in general. To address this issue, we propose a method that employs polynomial basis functions to form a candidate set of features, which are shown to allow the matching of statistical moments of state distributions. Feature selection is then performed for the candidates by leveraging the correlation between trajectory probabilities and feature expectations. We demonstrate the approach's effectiveness by recovering reward functions that capture 
    
[^44]: GTAGCN：广义拓扑自适应图卷积网络

    GTAGCN: Generalized Topology Adaptive Graph Convolutional Networks

    [https://arxiv.org/abs/2403.15077](https://arxiv.org/abs/2403.15077)

    GTAGCN提出了一种基于广义聚合网络和拓扑自适应图卷积网络的混合方法，可以有效应用于序列数据和静态数据，适用于节点和图分类，实证分析显示结果良好。

    

    arXiv:2403.15077v1 公告类型：新摘要：图神经网络（GNN）已经成为学习图结构数据的常用和标准方法。 GNN的文献强调了这一不断发展的研究领域的潜力以及它在现实应用中的广泛应用。然而，大多数方法要么是概念上新颖的，要么是从特定技术派生出来的。因此，混合形式的多种方法的潜力尚未得到广泛研究，这可以很好地用于序列数据或静态数据。我们提出了一种基于两种成熟技术的混合方法，即广义聚合网络和拓扑自适应图卷积网络，这解决了我们在效果上可以应用于序列型和静态型数据的目的。所提出的方法适用于节点和图分类。我们的实证分析显示，结果与文献结果相当，并且对手写笔画更好。

    arXiv:2403.15077v1 Announce Type: new  Abstract: Graph Neural Networks (GNN) have emerged as a popular and standard approach for learning from graph-structured data. The literature on GNN highlights the potential of this evolving research area and its widespread adoption in real-life applications. However, most of the approaches are either new in concept or derived from specific techniques. Therefore, the potential of more than one approach in hybrid form has not been studied extensively, which can be well utilized for sequenced data or static data together. We derive a hybrid approach based on two established techniques as generalized aggregation networks and topology adaptive graph convolution networks that solve our purpose to apply on both types of sequenced and static nature of data, effectively. The proposed method applies to both node and graph classification. Our empirical analysis reveals that the results are at par with literature results and better for handwritten strokes as
    
[^45]: 论笛卡尔张量神经网络势中包含电荷和自旋状态的研究

    On the Inclusion of Charge and Spin States in Cartesian Tensor Neural Network Potentials

    [https://arxiv.org/abs/2403.15073](https://arxiv.org/abs/2403.15073)

    TensorNet扩展了其能力，可以处理带电分子和自旋状态，提高了模型在各种化学系统中的预测准确性。

    

    在这封信中，我们提出了一种扩展TensorNet的方法，这是一种最先进的等变笛卡尔张量神经网络势，使其能够处理带电分子和自旋状态，而无需进行架构更改或增加成本。通过合并这些属性，我们解决了输入退化问题，增强了该模型在各种化学系统中的预测准确性。这一进展显著拓宽了TensorNet的适用范围，同时保持其效率和准确性。

    arXiv:2403.15073v1 Announce Type: new  Abstract: In this letter, we present an extension to TensorNet, a state-of-the-art equivariant Cartesian tensor neural network potential, allowing it to handle charged molecules and spin states without architectural changes or increased costs. By incorporating these attributes, we address input degeneracy issues, enhancing the model's predictive accuracy across diverse chemical systems. This advancement significantly broadens TensorNet's applicability, maintaining its efficiency and accuracy.
    
[^46]: 卡通幻觉检测: 姿势感知上下文视觉学习

    Cartoon Hallucinations Detection: Pose-aware In Context Visual Learning

    [https://arxiv.org/abs/2403.15048](https://arxiv.org/abs/2403.15048)

    该研究提出了一种用于检测由TTI模型生成的卡通角色图像中视觉幻觉的系统，通过结合姿势感知上下文视觉学习和视觉语言模型，利用RGB图像和姿势信息，实现了更准确的决策，显著提高了视觉幻觉的识别能力，推动了TTI模型在非照片真实领域的发展。

    

    大规模文本到图像（TTI）模型已经成为各种生成领域中生成训练数据的常见方法。然而，视觉幻觉，尤其是在非照片真实风格如卡通人物中包含了感知上关键的缺陷，依然是一个令人担忧的问题。我们提出了一种新颖的用于检测TTI模型生成的卡通角色图像的视觉幻觉检测系统。我们的方法利用了姿势感知上下文视觉学习（PA-ICVL）与视觉语言模型（VLMs），同时利用RGB图像和姿势信息。通过从一个经过微调的姿势估计器中获得姿势指导，我们使VLM能够做出更准确的决策。实验结果表明，在识别视觉幻觉方面，与仅依赖于RGB图像的基线方法相比，取得了显著的改进。这项研究通过减轻视觉幻觉，推动了TTI模型在非照片真实领域的潜力。

    arXiv:2403.15048v1 Announce Type: cross  Abstract: Large-scale Text-to-Image (TTI) models have become a common approach for generating training data in various generative fields. However, visual hallucinations, which contain perceptually critical defects, remain a concern, especially in non-photorealistic styles like cartoon characters. We propose a novel visual hallucination detection system for cartoon character images generated by TTI models. Our approach leverages pose-aware in-context visual learning (PA-ICVL) with Vision-Language Models (VLMs), utilizing both RGB images and pose information. By incorporating pose guidance from a fine-tuned pose estimator, we enable VLMs to make more accurate decisions. Experimental results demonstrate significant improvements in identifying visual hallucinations compared to baseline methods relying solely on RGB images. This research advances TTI models by mitigating visual hallucinations, expanding their potential in non-photorealistic domains.
    
[^47]: DP-Dueling: 在不损害用户隐私的情况下从偏好反馈中学习

    DP-Dueling: Learning from Preference Feedback without Compromising User Privacy

    [https://arxiv.org/abs/2403.15045](https://arxiv.org/abs/2403.15045)

    提出了第一个针对带用户偏好的主动学习的差分私密对抗式双臂老虎机算法，并在计算效率方面表现优异，同时具有接近最优的私密和非私密遗憾上界。

    

    我们考虑了广泛研究的对抗式双臂老虎机问题，其中学习者旨在使用成对比较来识别近似最优动作，同时受到差分隐私的约束。我们考虑了大型（可能是无界的）决策空间的基于效用的偏好矩阵的一般类，并为带有用户偏好的主动学习提供了第一个差分私密对抗式双臂老虎机算法。我们提出的算法在计算效率方面表现出色，并在私密和非私密遗憾上都接近最优性能。更确切地说，当决策空间是有限大小$K$时，我们提出的算法为纯$\epsilon$-DP产生了顺序最优$O\Big(\sum_{i = 2}^K\log\frac{KT}{\Delta_i} + \frac{K}{\epsilon}\Big)$遗憾上界，其中$\Delta_i$表示第$i$个臂的次优差距。我们还提供了一致的下界分析，证明了我们算法的最优性。

    arXiv:2403.15045v1 Announce Type: new  Abstract: We consider the well-studied dueling bandit problem, where a learner aims to identify near-optimal actions using pairwise comparisons, under the constraint of differential privacy. We consider a general class of utility-based preference matrices for large (potentially unbounded) decision spaces and give the first differentially private dueling bandit algorithm for active learning with user preferences. Our proposed algorithms are computationally efficient with near-optimal performance, both in terms of the private and non-private regret bound. More precisely, we show that when the decision space is of finite size $K$, our proposed algorithm yields order optimal $O\Big(\sum_{i = 2}^K\log\frac{KT}{\Delta_i} + \frac{K}{\epsilon}\Big)$ regret bound for pure $\epsilon$-DP, where $\Delta_i$ denotes the suboptimality gap of the $i$-th arm. We also present a matching lower bound analysis which proves the optimality of our algorithms. Finally, we
    
[^48]: 高维情况下多个均值向量的估计

    Estimation of multiple mean vectors in high dimension

    [https://arxiv.org/abs/2403.15038](https://arxiv.org/abs/2403.15038)

    通过凸组合的方法估计高维空间中不同概率分布的多维均值，引入了两种权重确定策略：一种通过测试程序识别低方差的相邻均值，提出了封闭形式插补公式；另一种通过最小化二次风险的上置信界确定权重，通过理论分析得出方法对经验均值的二次风险改进，在维度渐近的角度上渐近地接近 Oracle（Minimax）改进。

    

    我们致力于基于独立样本在一个共同空间中估计来自不同概率分布的多维均值。我们的方法是通过对这些样本导出的经验均值进行凸组合来形成估计量。我们引入了两种策略来找到适当的依赖于数据的凸组合权重：第一种利用测试程序来识别具有低方差的相邻均值，从而产生了一个关于权重的封闭形式插补公式；第二种通过最小化二次风险的上置信区间来确定权重。通过理论分析，我们评估了我们的方法相对于经验均值提供的二次风险改进。我们的分析集中在维度渐近的角度上，显示我们的方法在数据的有效维度增加时渐近地接近于一个 Oracle（Minimax）改进。我们展示了通过提出的方法在均值估计中的应用。

    arXiv:2403.15038v1 Announce Type: cross  Abstract: We endeavour to estimate numerous multi-dimensional means of various probability distributions on a common space based on independent samples. Our approach involves forming estimators through convex combinations of empirical means derived from these samples. We introduce two strategies to find appropriate data-dependent convex combination weights: a first one employing a testing procedure to identify neighbouring means with low variance, which results in a closed-form plug-in formula for the weights, and a second one determining weights via minimization of an upper confidence bound on the quadratic risk.Through theoretical analysis, we evaluate the improvement in quadratic risk offered by our methods compared to the empirical means. Our analysis focuses on a dimensional asymptotics perspective, showing that our methods asymptotically approach an oracle (minimax) improvement as the effective dimension of the data increases.We demonstrat
    
[^49]: 使用旋转不变变分量子电路进行图像分类

    Image Classification with Rotation-Invariant Variational Quantum Circuits

    [https://arxiv.org/abs/2403.15031](https://arxiv.org/abs/2403.15031)

    提出了一种使用旋转不变变分量子电路进行图像分类的等变架构，通过引入几何归纳偏差，成功提升了模型性能。

    

    变分量子算法作为嘈杂中等规模量子（NISQ）设备的早期应用正受到关注。变分方法的主要问题之一在于Barren Plateaus现象，在变分参数优化过程中存在。提出将几何归纳偏差添加到量子模型作为缓解这一问题的潜在解决方案，从而导致了一个称为几何量子机器学习的新领域。本文引入了一种等变结构的变分量子分类器，以创建具有$C_4$旋转标签对称性的图像分类的标签不变模型。等变电路与两种不同的结构进行了基准测试，实验证明几何方法提升了模型的性能。最后，提出了经典等变卷积操作，以扩展量子模型处理更大图像的能力。

    arXiv:2403.15031v1 Announce Type: cross  Abstract: Variational quantum algorithms are gaining attention as an early application of Noisy Intermediate-Scale Quantum (NISQ) devices. One of the main problems of variational methods lies in the phenomenon of Barren Plateaus, present in the optimization of variational parameters. Adding geometric inductive bias to the quantum models has been proposed as a potential solution to mitigate this problem, leading to a new field called Geometric Quantum Machine Learning. In this work, an equivariant architecture for variational quantum classifiers is introduced to create a label-invariant model for image classification with $C_4$ rotational label symmetry. The equivariant circuit is benchmarked against two different architectures, and it is experimentally observed that the geometric approach boosts the model's performance. Finally, a classical equivariant convolution operation is proposed to extend the quantum model for the processing of larger ima
    
[^50]: 灰色信息神经网络用于时间序列预测

    Grey-informed neural network for time-series forecasting

    [https://arxiv.org/abs/2403.15027](https://arxiv.org/abs/2403.15027)

    本研究提出了灰色信息神经网络（GINN），通过遵循灰色系统的微分方程模型，提高了神经网络输出的可解释性，使其能够有效处理小数据样本，产生可靠的预测。

    

    神经网络模型在各个领域展现出了出色的性能，成功解决了复杂问题。然而，大多数模型被视为黑盒，需要大量数据进行开发。因此，在数据有限的情况下，由于缺乏透明度和数据稀缺性，构建适当的模型变得具有挑战性。为了解决这些挑战，本研究建议实施灰色信息神经网络（GINN）。GINN 确保神经网络的输出遵循灰色系统的微分方程模型，提高了可解释性。此外，结合灰色系统理论中的先验知识使传统神经网络能够有效处理小数据样本。我们提出的模型已被观察到能够揭示现实世界中的潜在模式，并基于经验数据产生可靠的预测。

    arXiv:2403.15027v1 Announce Type: cross  Abstract: Neural network models have shown outstanding performance and successful resolutions to complex problems in various fields. However, the majority of these models are viewed as black-box, requiring a significant amount of data for development. Consequently, in situations with limited data, constructing appropriate models becomes challenging due to the lack of transparency and scarcity of data. To tackle these challenges, this study suggests the implementation of a grey-informed neural network (GINN). The GINN ensures that the output of the neural network follows the differential equation model of the grey system, improving interpretability. Moreover, incorporating prior knowledge from grey system theory enables traditional neural networks to effectively handle small data samples. Our proposed model has been observed to uncover underlying patterns in the real world and produce reliable forecasts based on empirical data.
    
[^51]: 通过物理信息结构因果模型在分布转移下的稳健符合预测

    Robust Conformal Prediction under Distribution Shift via Physics-Informed Structural Causal Model

    [https://arxiv.org/abs/2403.15025](https://arxiv.org/abs/2403.15025)

    通过引入物理信息指导的结构因果模型，我们提出了一种在分布转移下稳健的符合预测方法。

    

    不确定性对于利用机器学习进行可靠决策至关重要。 符合预测（CP）通过预测测试输入的一个集合来处理不确定性，希望该集合以至少$(1-\alpha)$的置信度覆盖真实标签。 即使在校准和测试数据集之间的边缘分布 $P_X$ 不同的情况下，这种覆盖也可以在测试数据上得到保证。 但是，实践中很常见的情况是，当校准和测试数据上的条件分布 $P_{Y|X}$ 不同时，覆盖就无法保证，在所有可能的置信水平下测量和最小化分布转移下的覆盖损失是至关重要的。 为了解决这些问题，我们使用校准和测试符合分数的累积密度函数以及Wasserstein距离在各个水平上上界覆盖差异。 受物理学在数据分布方面的不变性启发，我们提出了一种受物理信息指导的结构因果模型。

    arXiv:2403.15025v1 Announce Type: new  Abstract: Uncertainty is critical to reliable decision-making with machine learning. Conformal prediction (CP) handles uncertainty by predicting a set on a test input, hoping the set to cover the true label with at least $(1-\alpha)$ confidence. This coverage can be guaranteed on test data even if the marginal distributions $P_X$ differ between calibration and test datasets. However, as it is common in practice, when the conditional distribution $P_{Y|X}$ is different on calibration and test data, the coverage is not guaranteed and it is essential to measure and minimize the coverage loss under distributional shift at \textit{all} possible confidence levels. To address these issues, we upper bound the coverage difference at all levels using the cumulative density functions of calibration and test conformal scores and Wasserstein distance. Inspired by the invariance of physics across data distributions, we propose a physics-informed structural caus
    
[^52]: 走势彩票假设和迭代幅度剪枝的洞见

    Insights into the Lottery Ticket Hypothesis and the Iterative Magnitude Pruning

    [https://arxiv.org/abs/2403.15022](https://arxiv.org/abs/2403.15022)

    通过对迭代幅度剪枝过程中不同阶段获得的解决方案的体积/几何和损失景观特征进行经验研究，我们试图洞察走势彩票假设和迭代幅度剪枝中的现象。

    

    arXiv:2403.15022v1 公告类型：新摘要：深度神经网络的走势彩票假设强调了重新训练利用迭代幅度剪枝过程获得的更稀疏网络时所使用的初始化的重要性。至今尚缺乏关于走势彩票假设中提出的特定初始化为何更有利于泛化（和训练）性能的解释。此外，迭代幅度剪枝中的基本原理，如剪枝较小幅度权重和迭代过程的作用，尚缺乏完全理解和解释。在本研究中，我们尝试通过对在迭代幅度剪枝过程的各个阶段获得的解决方案的体积/几何和损失景观特征进行经验研究，以洞察这些现象。

    arXiv:2403.15022v1 Announce Type: new  Abstract: Lottery ticket hypothesis for deep neural networks emphasizes the importance of initialization used to re-train the sparser networks obtained using the iterative magnitude pruning process. An explanation for why the specific initialization proposed by the lottery ticket hypothesis tends to work better in terms of generalization (and training) performance has been lacking. Moreover, the underlying principles in iterative magnitude pruning, like the pruning of smaller magnitude weights and the role of the iterative process, lack full understanding and explanation. In this work, we attempt to provide insights into these phenomena by empirically studying the volume/geometry and loss landscape characteristics of the solutions obtained at various stages of the iterative magnitude pruning process.
    
[^53]: 北欧地区车辆检测性能研究

    Vehicle Detection Performance in Nordic Region

    [https://arxiv.org/abs/2403.15017](https://arxiv.org/abs/2403.15017)

    本研究针对北欧恶劣冬季条件下车辆检测的挑战，使用北欧车辆数据集评估了最先进的检测算法性能，并提出了针对每种检测框架的一系列增强措施。

    

    本文关注在北欧地区恶劣冬季条件下车辆检测的关键挑战，该地区以暴雪、低能见度和低照明为特征。由于传统车辆检测方法易受环境扭曲和遮挡的影响，在这些恶劣条件下表现不佳。先进的深度学习架构带来了希望，然而在北欧冬季检测车辆的独特困难仍未得到充分解决。该研究使用了北欧车辆数据集(NVD)，该数据集包含瑞典北部的无人机图像，以评估在恶劣天气条件下最先进的车辆检测算法的性能。我们的方法包括针对每个检测框架量身定制的一系列增强措施，包括数据增强。

    arXiv:2403.15017v1 Announce Type: cross  Abstract: This paper addresses the critical challenge of vehicle detection in the harsh winter conditions in the Nordic regions, characterized by heavy snowfall, reduced visibility, and low lighting. Due to their susceptibility to environmental distortions and occlusions, traditional vehicle detection methods have struggled in these adverse conditions. The advanced proposed deep learning architectures brought promise, yet the unique difficulties of detecting vehicles in Nordic winters remain inadequately addressed. This study uses the Nordic Vehicle Dataset (NVD), which has UAV images from northern Sweden, to evaluate the performance of state-of-the-art vehicle detection algorithms under challenging weather conditions. Our methodology includes a comprehensive evaluation of single-stage, two-stage, and transformer-based detectors against the NVD. We propose a series of enhancements tailored to each detection framework, including data augmentation
    
[^54]: 临床机器学习中多源交叉验证的实证研究

    Empirical investigation of multi-source cross-validation in clinical machine learning

    [https://arxiv.org/abs/2403.15012](https://arxiv.org/abs/2403.15012)

    本研究在多源环境中系统地评估了标准K折交叉验证和留出源交叉验证方法，为实现更全面和真实的精确度评估提供了新的机会

    

    传统上，基于机器学习的临床预测模型是在来自单一来源（如医院）的患者数据上进行训练和评估的。交叉验证方法可通过重复随机拆分数据来估计这些模型在来自同一来源的新患者上的精确度。然而，与部署模型到数据集中未代表的源头（如新医院）获得的精确度相比，这些估计往往过于乐观。多源医疗数据集的不断增加为通过基于源头的交叉验证设计获得更全面和真实的预期精确度评估提供了新机会。

    arXiv:2403.15012v1 Announce Type: new  Abstract: Traditionally, machine learning-based clinical prediction models have been trained and evaluated on patient data from a single source, such as a hospital. Cross-validation methods can be used to estimate the accuracy of such models on new patients originating from the same source, by repeated random splitting of the data. However, such estimates tend to be highly overoptimistic when compared to accuracy obtained from deploying models to sources not represented in the dataset, such as a new hospital. The increasing availability of multi-source medical datasets provides new opportunities for obtaining more comprehensive and realistic evaluations of expected accuracy through source-level cross-validation designs.   In this study, we present a systematic empirical evaluation of standard K-fold cross-validation and leave-source-out cross-validation methods in a multi-source setting. We consider the task of electrocardiogram based cardiovascul
    
[^55]: ParFormer：具有并行局部全局标记混合器和卷积注意力补丁嵌入的视觉Transformer基线

    ParFormer: Vision Transformer Baseline with Parallel Local Global Token Mixer and Convolution Attention Patch Embedding

    [https://arxiv.org/abs/2403.15004](https://arxiv.org/abs/2403.15004)

    ParFormer提出了并行局部全局标记混合器和卷积注意力补丁嵌入，优化了特征提取能力，在图像分类和对象识别等任务中表现优于CNN和最先进的Transformer架构。

    

    本文提出了ParFormer作为一种增强型Transformer架构，允许将不同的标记混合器整合到单个阶段中，从而提高特征提取能力。同时整合本地和全局数据，实现对短程和长程空间关系的精确表示，而无需像平移窗口这样需要大量计算的方法。除了并行标记混合器编码器外，我们提供了卷积注意力补丁嵌入(CAPE)，作为标准补丁嵌入的增强，通过卷积注意力模块改进标记混合器提取。我们的全面评估表明，我们的ParFormer在图像分类和物体识别等多个复杂任务中优于基于CNN和最先进的基于Transformer的架构。所提出的CAPE已被证明有益于整体MetaFormer架构，即使使用Id。

    arXiv:2403.15004v1 Announce Type: cross  Abstract: This work presents ParFormer as an enhanced transformer architecture that allows the incorporation of different token mixers into a single stage, hence improving feature extraction capabilities. Integrating both local and global data allows for precise representation of short- and long-range spatial relationships without the need for computationally intensive methods such as shifting windows. Along with the parallel token mixer encoder, We offer the Convolutional Attention Patch Embedding (CAPE) as an enhancement of standard patch embedding to improve token mixer extraction with a convolutional attention module. Our comprehensive evaluation demonstrates that our ParFormer outperforms CNN-based and state-of-the-art transformer-based architectures in image classification and several complex tasks such as object recognition. The proposed CAPE has been demonstrated to benefit the overall MetaFormer architecture, even while utilizing the Id
    
[^56]: 魔法与量子化深度神经网络时代

    Magic for the Age of Quantized DNNs

    [https://arxiv.org/abs/2403.14999](https://arxiv.org/abs/2403.14999)

    提出了一种量化感知训练方法，引入新型标准化方法并使用缩放量化加权，实现了在最小精度降级的情况下有效的量化深度神经网络

    

    最近，深度神经网络中的参数数量急剧增加，如大型语言模型（LLMs）所示，使得在小规模计算机上进行推理变得更加困难。因此，模型压缩技术对产品整合至关重要。在本文中，我们提出了一种量化感知训练方法。我们引入了一种新颖的标准化方法（层批标准化），其独立于小批量大小，并且在推理期间不需要额外的计算成本。然后，我们通过带权标准化的缩放量化加权。我们还使用相同的函数量化激活函数，并应用代理梯度来训练既具有量化权重又具有量化激活函数的模型。我们将这种方法称为魔法与量子化DNN时代（MaQD）。实验结果表明，我们的量化方法可以在最小精度降级的情况下实现。

    arXiv:2403.14999v1 Announce Type: cross  Abstract: Recently, the number of parameters in DNNs has explosively increased, as exemplified by LLMs (Large Language Models), making inference on small-scale computers more difficult. Model compression technology is, therefore, essential for integration into products. In this paper, we propose a method of quantization-aware training. We introduce a novel normalization (Layer-Batch Normalization) that is independent of the mini-batch size and does not require any additional computation cost during inference. Then, we quantize the weights by the scaled round-clip function with the weight standardization. We also quantize activation functions using the same function and apply surrogate gradients to train the model with both quantized weights and the quantized activation functions. We call this method Magic for the age of Quantised DNNs (MaQD). Experimental results show that our quantization method can be achieved with minimal accuracy degradation
    
[^57]: 分段线性流形在深度度量学习中的应用

    Piecewise-Linear Manifolds for Deep Metric Learning

    [https://arxiv.org/abs/2403.14977](https://arxiv.org/abs/2403.14977)

    提出了一种在深度度量学习中使用分段线性流形的方法，并通过模拟高维数据流形来改善相似性估计，从而提高了无监督度量学习的性能。

    

    无监督深度度量学习（UDML）致力于仅使用无标签数据学习语义表示空间。我们提出使用分段线性逼近模型高维数据流形，其中每个低维线性片段近似于点的小邻域内的数据流形。这些邻域用于估计数据点之间的相似性。我们在实验中表明，这种相似性估计与基准相比更好地反映了地面真相。我们还展示了在无监督设置中，可以使用在监督度量学习中常用的代理来模拟分段线性流形，从而有助于提高性能。

    arXiv:2403.14977v1 Announce Type: cross  Abstract: Unsupervised deep metric learning (UDML) focuses on learning a semantic representation space using only unlabeled data. This challenging problem requires accurately estimating the similarity between data points, which is used to supervise a deep network. For this purpose, we propose to model the high-dimensional data manifold using a piecewise-linear approximation, with each low-dimensional linear piece approximating the data manifold in a small neighborhood of a point. These neighborhoods are used to estimate similarity between data points. We empirically show that this similarity estimate correlates better with the ground truth than the similarity estimates of current state-of-the-art techniques. We also show that proxies, commonly used in supervised metric learning, can be used to model the piecewise-linear manifold in an unsupervised setting, helping improve performance. Our method outperforms existing unsupervised metric learning 
    
[^58]: 轨迹正则化增强自监督几何表示

    Trajectory Regularization Enhances Self-Supervised Geometric Representation

    [https://arxiv.org/abs/2403.14973](https://arxiv.org/abs/2403.14973)

    引入新的pose-estimation基准用于评估SSL几何表示，提出无监督轨迹正则化损失来增强SSL几何表示，在姿势估计性能上取得10-20%的提升，并提高了4%的性能和泛化能力。

    

    自监督学习（SSL）已被证明能够有效地学习高质量的表示，用于各种下游任务，主要关注语义任务。然而，在几何任务中的应用仍未得到充分探索，部分原因是缺乏用于评估几何表示的标准化评估方法。为了填补这一空白，我们引入了一个新的姿势估计基准，用于评估SSL几何表示，该基准要求在没有语义或姿势标签的情况下进行训练，并在语义和几何下游任务中表现出熟练度。在这个基准上，我们研究了如何增强SSL几何表示而不牺牲语义分类准确性。我们发现利用中间层表示可以将姿势估计性能提高10-20％。此外，我们引入了一种无监督轨迹正则化损失，该损失额外提高了4％的性能，并提高了在越界上的泛化能力。

    arXiv:2403.14973v1 Announce Type: cross  Abstract: Self-supervised learning (SSL) has proven effective in learning high-quality representations for various downstream tasks, with a primary focus on semantic tasks. However, its application in geometric tasks remains underexplored, partially due to the absence of a standardized evaluation method for geometric representations. To address this gap, we introduce a new pose-estimation benchmark for assessing SSL geometric representations, which demands training without semantic or pose labels and achieving proficiency in both semantic and geometric downstream tasks. On this benchmark, we study enhancing SSL geometric representations without sacrificing semantic classification accuracy. We find that leveraging mid-layer representations improves pose-estimation performance by 10-20%. Further, we introduce an unsupervised trajectory-regularization loss, which improves performance by an additional 4% and improves generalization ability on out-of
    
[^59]: Adapprox:自适应近似在Adam优化中使用随机低秩矩阵

    Adapprox: Adaptive Approximation in Adam Optimization via Randomized Low-Rank Matrices

    [https://arxiv.org/abs/2403.14958](https://arxiv.org/abs/2403.14958)

    Adapprox是一种采用随机低秩矩阵近似的自适应方法，用于更有效和准确地逼近Adam优化算法的二阶矩。在GPT-2的训练和下游任务中，Adapprox相比AdamW能够实现34.5%至49.9%和33.8%至49.9%的内存节约，并通过余弦相似性指导策略提高了稳定性和加快了收敛速度。

    

    随着深度学习模型的规模呈指数增长，诸如Adam之类的优化器在存储一、二阶矩数据时遇到了显著的内存消耗挑战。当前的内存高效方法如Adafactor和CAME通常通过其矩阵因式分解技术来牺牲准确性。针对这一问题，我们引入了Adapprox，一种新颖的方法，它采用随机低秩矩阵近似来更有效和准确地近似Adam的二阶矩。Adapprox具有自适应秩选择机制，精细平衡准确性和内存效率，并包括一个可选的余弦相似性指导策略，以增强稳定性并加快收敛速度。在GPT-2训练和下游任务中，Adapprox通过实现对117M和345M模型的34.5%至49.9%和33.8%至49.9%内存节约（分别启用了第一阶矩），超越了AdamW，并进一步增加了这些节约。

    arXiv:2403.14958v1 Announce Type: cross  Abstract: As deep learning models exponentially increase in size, optimizers such as Adam encounter significant memory consumption challenges due to the storage of first and second moment data. Current memory-efficient methods like Adafactor and CAME often compromise accuracy with their matrix factorization techniques. Addressing this, we introduce Adapprox, a novel approach that employs randomized low-rank matrix approximation for a more effective and accurate approximation of Adam's second moment. Adapprox features an adaptive rank selection mechanism, finely balancing accuracy and memory efficiency, and includes an optional cosine similarity guidance strategy to enhance stability and expedite convergence. In GPT-2 training and downstream tasks, Adapprox surpasses AdamW by achieving 34.5% to 49.9% and 33.8% to 49.9% memory savings for the 117M and 345M models, respectively, with the first moment enabled, and further increases these savings wit
    
[^60]: 简单图压缩

    Simple Graph Condensation

    [https://arxiv.org/abs/2403.14951](https://arxiv.org/abs/2403.14951)

    提出了一种简化的图压缩方法，旨在减少图神经网络所带来的不必要复杂性。

    

    大规模图上繁重的训练成本已经引起了对图压缩的极大兴趣，涉及调整图神经网络（GNNs）在小尺度压缩图上的训练以在大规模原始图上使用。现有方法主要集中在调整压缩图和原始图之间的关键指标，如梯度、GNNs的分布和轨迹，从而在下游任务上实现了令人满意的性能。然而，这些复杂指标需要复杂的计算，可能会干扰压缩图的优化过程，使得压缩过程非常繁重和不稳定。在各个领域简化模型取得成功的背景下，我们提出了一种简化的图压缩中的指标对准方法，旨在减少从GNNs继承的不必要复杂性。在我们的方法中，我们消除外部参数，仅保留目标的压缩

    arXiv:2403.14951v1 Announce Type: cross  Abstract: The burdensome training costs on large-scale graphs have aroused significant interest in graph condensation, which involves tuning Graph Neural Networks (GNNs) on a small condensed graph for use on the large-scale original graph. Existing methods primarily focus on aligning key metrics between the condensed and original graphs, such as gradients, distribution and trajectory of GNNs, yielding satisfactory performance on downstream tasks. However, these complex metrics necessitate intricate computations and can potentially disrupt the optimization process of the condensation graph, making the condensation process highly demanding and unstable. Motivated by the recent success of simplified models in various fields, we propose a simplified approach to metric alignment in graph condensation, aiming to reduce unnecessary complexity inherited from GNNs. In our approach, we eliminate external parameters and exclusively retain the target conden
    
[^61]: KnowLA：利用知识自适应提升参数高效微调

    KnowLA: Enhancing Parameter-efficient Finetuning with Knowledgeable Adaptation

    [https://arxiv.org/abs/2403.14950](https://arxiv.org/abs/2403.14950)

    该论文提出了一种名为KnowLA的知识自适应方法，通过在大型语言模型中插入自适应层和知识图嵌入，能够提升参数高效微调的有效性和鲁棒性。

    

    参数高效微调（PEFT）是调整大型语言模型（LLMs）以适应下游任务的关键技术。本文研究了利用知识图嵌入来改善PEFT的有效性。我们提出了一种称为KnowLA的知识自适应方法。它在LLM中插入一个自适应层，将输入文本中出现的实体的嵌入整合在一起。自适应层与LoRA在指导数据上组合训练。在两个流行的LLMs和三个知识图上进行的六项基准实验表明了KnowLA的有效性和鲁棒性。我们展示了 \modelname 能够帮助激活LLM中的相关参数化知识以回答问题，而不改变其参数或输入提示。

    arXiv:2403.14950v1 Announce Type: new  Abstract: Parameter-efficient finetuning (PEFT) is a key technique for adapting large language models (LLMs) to downstream tasks. In this paper, we study leveraging knowledge graph embeddings to improve the effectiveness of PEFT. We propose a knowledgeable adaptation method called KnowLA. It inserts an adaptation layer into an LLM to integrate the embeddings of entities appearing in the input text. The adaptation layer is trained in combination with LoRA on instruction data. Experiments on six benchmarks with two popular LLMs and three knowledge graphs demonstrate the effectiveness and robustness of KnowLA. We show that \modelname can help activate the relevant parameterized knowledge in an LLM to answer a question without changing its parameters or input prompts.
    
[^62]: 在在线时间序列预测中解决概念漂移：先检测再调整

    Addressing Concept Shift in Online Time Series Forecasting: Detect-then-Adapt

    [https://arxiv.org/abs/2403.14949](https://arxiv.org/abs/2403.14949)

    提出了一种名为Concept Drift Detection and Adaptation（D3A）的新方法，通过检测漂移概念并在检测后积极调整模型来解决在线时间序列预测中遇到的概念漂移问题。

    

    时间序列预测模型的在线更新旨在通过基于流数据调整预测模型来解决概念漂移的挑战。尽管已经发展了许多算法，但大多数算法侧重于模型设计和更新。实际上，许多方法在面对随时间累积的概念漂移时，很难保持持续的性能。为解决这一局限性，我们提出了一种新方法，称为概念漂移检测和适应（D3A），该方法首先检测漂移概念，然后在检测后积极调整当前模型以适应漂移的概念，实现快速适应。为了最大程度地利用历史数据进行模型适应，我们提出了一种数据增强策略，将高斯噪声引入现有训练实例。这有助于缓解数据分布差距，这是影响训练 - 测试性能的关键因素。

    arXiv:2403.14949v1 Announce Type: new  Abstract: Online updating of time series forecasting models aims to tackle the challenge of concept drifting by adjusting forecasting models based on streaming data. While numerous algorithms have been developed, most of them focus on model design and updating. In practice, many of these methods struggle with continuous performance regression in the face of accumulated concept drifts over time. To address this limitation, we present a novel approach, Concept \textbf{D}rift \textbf{D}etection an\textbf{D} \textbf{A}daptation (D3A), that first detects drifting conception and then aggressively adapts the current model to the drifted concepts after the detection for rapid adaption. To best harness the utility of historical data for model adaptation, we propose a data augmentation strategy introducing Gaussian noise into existing training instances. It helps mitigate the data distribution gap, a critical factor contributing to train-test performance in
    
[^63]: 一个线性层生成任务自适应低秩矩阵

    A Single Linear Layer Yields Task-Adapted Low-Rank Matrices

    [https://arxiv.org/abs/2403.14946](https://arxiv.org/abs/2403.14946)

    通过研究转换矩阵将$ W_0 $转换为低秩矩阵的关系信息，我们提出单一线性层可以生成任务自适应的低秩矩阵。

    

    低秩适应（LoRA）是一种广泛使用的参数高效调整（PEFT）方法，它通过由两个低秩矩阵$ A $和$ B $组成的增量矩阵$ \Delta W $更新初始权重矩阵$ W_0 $。先前的研究表明$ W_0 $和$ \Delta W $之间存在关联。在这项研究中，我们旨在深入探讨$ W_0 $与低秩矩阵$ A $和$ B $之间的关系，以进一步理解LoRA的行为。特别地，我们分析了一个将$ W_0 $转换为低秩矩阵的转换矩阵，其中蕴含了关系的信息。我们的分析表明转换矩阵在每一层之间是相似的。受到这些发现的启发，我们假设一个单一线性层，将每一层的$ W_0 $作为输入，可以生成任务自适应的低秩矩阵。为了验证这一假设，我们设计了一种名为有条件参数化的LoRA (CondLoRA) 方法，来更新初始权重...

    arXiv:2403.14946v1 Announce Type: cross  Abstract: Low-Rank Adaptation (LoRA) is a widely used Parameter-Efficient Fine-Tuning (PEFT) method that updates an initial weight matrix $W_0$ with a delta matrix $\Delta W$ consisted by two low-rank matrices $A$ and $B$. A previous study suggested that there is correlation between $W_0$ and $\Delta W$. In this study, we aim to delve deeper into relationships between $W_0$ and low-rank matrices $A$ and $B$ to further comprehend the behavior of LoRA. In particular, we analyze a conversion matrix that transform $W_0$ into low-rank matrices, which encapsulates information about the relationships. Our analysis reveals that the conversion matrices are similar across each layer. Inspired by these findings, we hypothesize that a single linear layer, which takes each layer's $W_0$ as input, can yield task-adapted low-rank matrices. To confirm this hypothesis, we devise a method named Conditionally Parameterized LoRA (CondLoRA) that updates initial weig
    
[^64]: 从图结构角度统一车道级交通预测：基准和基线

    Unifying Lane-Level Traffic Prediction from a Graph Structural Perspective: Benchmark and Baseline

    [https://arxiv.org/abs/2403.14941](https://arxiv.org/abs/2403.14941)

    本文提出了一个简单的基线模型GraphMLP，基于图结构和MLP网络，在车道级交通预测中建立了统一的空间拓扑结构和预测任务，帮助突破了现有评估标准和数据公开性的限制。

    

    交通预测长期以来一直是研究中的一个焦点和关键领域，在过去几年里，既见证了从城市级到道路级预测取得的重大进展。随着车辆对一切（V2X）技术、自动驾驶和交通领域的大规模模型的进步，道路级交通预测已经成为一个不可或缺的方向。然而，这一领域的进一步进展受到了全面和统一的评估标准的缺乏以及有限的公开数据和代码的阻碍。本文对车道级交通预测中现有研究进行了广泛的分析和分类，建立了统一的空间拓扑结构和预测任务，并介绍了一个基于图结构和MLP网络的简单基线模型GraphMLP。我们复制了现有研究中尚不公开的代码，并基于此充分而公正地评估了各种模型。

    arXiv:2403.14941v1 Announce Type: cross  Abstract: Traffic prediction has long been a focal and pivotal area in research, witnessing both significant strides from city-level to road-level predictions in recent years. With the advancement of Vehicle-to-Everything (V2X) technologies, autonomous driving, and large-scale models in the traffic domain, lane-level traffic prediction has emerged as an indispensable direction. However, further progress in this field is hindered by the absence of comprehensive and unified evaluation standards, coupled with limited public availability of data and code. This paper extensively analyzes and categorizes existing research in lane-level traffic prediction, establishes a unified spatial topology structure and prediction tasks, and introduces a simple baseline model, GraphMLP, based on graph structure and MLP networks. We have replicated codes not publicly available in existing studies and, based on this, thoroughly and fairly assessed various models in 
    
[^65]: 电子健康记录的多模态分析上的对比学习

    Contrastive Learning on Multimodal Analysis of Electronic Health Records

    [https://arxiv.org/abs/2403.14926](https://arxiv.org/abs/2403.14926)

    该论文研究了电子健康记录的多模态分析，强调了结构化和非结构化数据之间的协同作用，并尝试将多模态对比学习方法应用于提高患者医疗历史的完整性。

    

    电子健康记录（EHR）系统包含大量的多模态临床数据，包括结构化数据如临床编码和非结构化数据如临床笔记。然而，许多现有的针对EHR的研究传统上要么集中于个别模态，要么以一种相当粗糙的方式合并不同的模态。这种方法通常会导致将结构化和非结构化数据视为单独实体，忽略它们之间固有的协同作用。具体来说，这两个重要的模态包含临床相关、密切相关和互补的健康信息。通过联合分析这两种数据模态可以捕捉到患者医疗历史的更完整画面。尽管多模态对比学习在视觉语言领域取得了巨大成功，但在多模态EHR领域，尤其是在理论理解方面，其潜力仍未充分挖掘。

    arXiv:2403.14926v1 Announce Type: cross  Abstract: Electronic health record (EHR) systems contain a wealth of multimodal clinical data including structured data like clinical codes and unstructured data such as clinical notes. However, many existing EHR-focused studies has traditionally either concentrated on an individual modality or merged different modalities in a rather rudimentary fashion. This approach often results in the perception of structured and unstructured data as separate entities, neglecting the inherent synergy between them. Specifically, the two important modalities contain clinically relevant, inextricably linked and complementary health information. A more complete picture of a patient's medical history is captured by the joint analysis of the two modalities of data. Despite the great success of multimodal contrastive learning on vision-language, its potential remains under-explored in the realm of multimodal EHR, particularly in terms of its theoretical understandi
    
[^66]: CODA：一种用于HAR的节约成本的测试时域自适应机制

    CODA: A COst-efficient Test-time Domain Adaptation Mechanism for HAR

    [https://arxiv.org/abs/2403.14922](https://arxiv.org/abs/2403.14922)

    CODA 提出了一种节约成本的测试时域自适应机制，通过主动学习理论处理实时漂移，实现在设备上直接进行成本有效的自适应，并保留数据分布中的有意义结构。

    

    近年来，移动感知的新兴研究导致了增强人类日常生活的新型场景，但是动态的使用条件经常导致系统在实际环境中部署时性能下降。现有的解决方案通常采用基于神经网络的一次性自适应方案，这些方案往往难以确保针对人类感知场景中不确定漂移条件的稳健性。本文提出了CODA，一种针对移动感知的节约成本域自适应机制，从数据分布角度利用主动学习理论解决实时漂移，以确保在设备上直接进行成本有效的自适应。通过结合聚类损失和重要性加权主动学习算法，CODA在成本效益的实例级更新过程中保留不同聚类之间的关系，保留数据分布中的有意义结构。

    arXiv:2403.14922v1 Announce Type: new  Abstract: In recent years, emerging research on mobile sensing has led to novel scenarios that enhance daily life for humans, but dynamic usage conditions often result in performance degradation when systems are deployed in real-world settings. Existing solutions typically employ one-off adaptation schemes based on neural networks, which struggle to ensure robustness against uncertain drifting conditions in human-centric sensing scenarios. In this paper, we propose CODA, a COst-efficient Domain Adaptation mechanism for mobile sensing that addresses real-time drifts from the data distribution perspective with active learning theory, ensuring cost-efficient adaptation directly on the device. By incorporating a clustering loss and importance-weighted active learning algorithm, CODA retains the relationship between different clusters during cost-effective instance-level updates, preserving meaningful structure within the data distribution. We also sho
    
[^67]: 基于深度学习的天气预测方法：以糸島为例研究

    Deep learning-based method for weather forecasting: A case study in Itoshima

    [https://arxiv.org/abs/2403.14918](https://arxiv.org/abs/2403.14918)

    该研究提出了一个针对日本九州糸島天气预测的多层感知器模型，表现出比现有模型更优越的性能。

    

    准确的天气预测对于广泛的实际应用至关重要，引起了大量的科学和社会关注。然而，天气系统的复杂性给准确预测带来了重大挑战。本研究引入了一个特别针对日本九州糸島天气预测的多层感知器模型。我们精心设计的架构表现出优越的性能，超越了诸如长短期记忆和循环神经网络等现有模型的基准。

    arXiv:2403.14918v1 Announce Type: new  Abstract: Accurate weather forecasting is of paramount importance for a wide range of practical applications, drawing substantial scientific and societal interest. However, the intricacies of weather systems pose substantial challenges to accurate predictions. This research introduces a multilayer perceptron model tailored for weather forecasting in Itoshima, Kyushu, Japan. Our meticulously designed architecture demonstrates superior performance compared to existing models, surpassing benchmarks such as Long Short-Term Memory and Recurrent Neural Networks.
    
[^68]: 从核方法的角度对两层神经网络进行平均场分析

    Mean-field Analysis on Two-layer Neural Networks from a Kernel Perspective

    [https://arxiv.org/abs/2403.14917](https://arxiv.org/abs/2403.14917)

    本文通过核方法的视角研究了两层神经网络在平均场极限下的特征学习能力，展示了它们比任何核方法更有效地学习多个再现核希尔伯特空间的并集，并且神经网络会获得与目标函数对齐的数据相关核。

    

    在本文中，我们通过核方法的视角研究了两层神经网络在平均场极限下的特征学习能力。为了聚焦于第一层诱导的核的动态，我们利用了两个时间尺度的极限，其中第二层比第一层移动得快得多。在这个极限下，学习问题被简化为在内在核上的最小化问题。然后，我们展示了平均场 Langevin 动力学的全局收敛性，并推导了时间和粒子离散化误差。我们还证明了两层神经网络可以比任何核方法更有效地学习多个再现核希尔伯特空间的并集，并且神经网络会获得与目标函数对齐的数据相关核。此外，我们还开发了一个收敛到全局最优的标签噪声过程，并展示自由度出现作为一种隐式正则化。

    arXiv:2403.14917v1 Announce Type: new  Abstract: In this paper, we study the feature learning ability of two-layer neural networks in the mean-field regime through the lens of kernel methods. To focus on the dynamics of the kernel induced by the first layer, we utilize a two-timescale limit, where the second layer moves much faster than the first layer. In this limit, the learning problem is reduced to the minimization problem over the intrinsic kernel. Then, we show the global convergence of the mean-field Langevin dynamics and derive time and particle discretization error. We also demonstrate that two-layer neural networks can learn a union of multiple reproducing kernel Hilbert spaces more efficiently than any kernel methods, and neural networks acquire data-dependent kernel which aligns with the target function. In addition, we develop a label noise procedure, which converges to the global optimum and show that the degrees of freedom appears as an implicit regularization.
    
[^69]: 自适应编码联邦学习：隐私保护与慢节点缓解

    Adaptive Coded Federated Learning: Privacy Preservation and Straggler Mitigation

    [https://arxiv.org/abs/2403.14905](https://arxiv.org/abs/2403.14905)

    ACFL提出了一种新的自适应编码联邦学习方法，通过在训练之前采用个性化的数据上传到中央服务器来生成全局编码数据集，以解决原有固定权重生成全局编码数据集时可能导致学习性能下降的问题。

    

    在本文中，我们讨论了在存在慢节点情况下的联邦学习问题。针对这一问题，我们提出了一种编码联邦学习框架，其中中央服务器聚合来自非慢节点的梯度和来自隐私保护全局编码数据集的梯度，以减轻慢节点的负面影响。然而，在聚合这些梯度时，固定权重在迭代中一直被应用，忽略了全局编码数据集的生成过程以及训练模型随着迭代的动态性。这一疏漏可能导致学习性能下降。为克服这一缺陷，我们提出了一种名为自适应编码联邦学习（ACFL）的新方法。在ACFL中，在训练之前，每个设备向中央服务器上传一个带有附加噪声的编码本地数据集，以生成符合隐私保护要求的全局编码数据集。在...

    arXiv:2403.14905v1 Announce Type: cross  Abstract: In this article, we address the problem of federated learning in the presence of stragglers. For this problem, a coded federated learning framework has been proposed, where the central server aggregates gradients received from the non-stragglers and gradient computed from a privacy-preservation global coded dataset to mitigate the negative impact of the stragglers. However, when aggregating these gradients, fixed weights are consistently applied across iterations, neglecting the generation process of the global coded dataset and the dynamic nature of the trained model over iterations. This oversight may result in diminished learning performance. To overcome this drawback, we propose a new method named adaptive coded federated learning (ACFL). In ACFL, before the training, each device uploads a coded local dataset with additive noise to the central server to generate a global coded dataset under privacy preservation requirements. During
    
[^70]: Hydro: 自适应机器学习查询处理

    Hydro: Adaptive Query Processing of ML Queries

    [https://arxiv.org/abs/2403.14902](https://arxiv.org/abs/2403.14902)

    该论文提出了一种Hydro系统，用于处理机器学习查询，通过动态调整查询计划以适应数据的变化，解决了传统DBMSs在处理ML查询时遇到的性能瓶颈和优化挑战。

    

    关系数据库管理系统（DBMSs）中的查询优化对于快速查询处理至关重要。查询优化器依赖于精确的选择性和成本估计，以便在执行之前有效地优化查询。传统的DBMSs可以有效利用该策略，但对于专门用于处理机器学习（ML）查询的DBMSs来说则不够。在以ML为中心的DBMSs中，查询优化面临两个挑战。首先，查询的性能瓶颈转移到用户定义函数（UDFs）上，这些函数通常封装深度学习模型，使得在没有对查询进行分析的情况下准确估计UDF统计数据变得困难。这导致统计数据不准确和查询计划次优。其次，ML查询的最佳查询计划取决于数据，因此DBMSs需要在执行过程中动态调整查询计划。因此，静态查询计划对这类查询来说是不够的。

    arXiv:2403.14902v1 Announce Type: cross  Abstract: Query optimization in relational database management systems (DBMSs) is critical for fast query processing. The query optimizer relies on precise selectivity and cost estimates to effectively optimize queries prior to execution. While this strategy is effective for relational DBMSs, it is not sufficient for DBMSs tailored for processing machine learning (ML) queries. In ML-centric DBMSs, query optimization is challenging for two reasons. First, the performance bottleneck of the queries shifts to user-defined functions (UDFs) that often wrap around deep learning models, making it difficult to accurately estimate UDF statistics without profiling the query. This leads to inaccurate statistics and sub-optimal query plans. Second, the optimal query plan for ML queries is data-dependent, necessitating DBMSs to adapt the query plan on the fly during execution. So, a static query plan is not sufficient for such queries.   In this paper, we pre
    
[^71]: 基于Web的黑色素瘤检测

    Web-based Melanoma Detection

    [https://arxiv.org/abs/2403.14898](https://arxiv.org/abs/2403.14898)

    本研究提出了一种统一的黑色素瘤分类方法，支持多种数据集和深度学习架构组合，能够以极快的速度和高准确率进行实时的黑色素瘤检测。

    

    黑色素瘤是皮肤癌中最具侵略性的形式，早期检测可以显著提高存活率并预防癌症扩散。然而，由于缺乏标准化数据集和评估方法，开发可靠的自动化检测技术是困难的。本研究引入了一种统一的黑色素瘤分类方法，支持11个数据集和24种最先进的深度学习架构的54种组合。它通过1,296个实验的公平比较，并产生一个轻量级模型，可部署到名为Mela-D的基于Web的MeshNet架构。这种方法通过减少参数，使速度提高了33倍，达到了类似于ResNet50的88.8%的准确率，可在以前未见过的图像上运行。这可以在消费级硬件上高效准确地检测黑色素瘤，可在实际环境中运行。

    arXiv:2403.14898v1 Announce Type: cross  Abstract: Melanoma is the most aggressive form of skin cancer, and early detection can significantly increase survival rates and prevent cancer spread. However, developing reliable automated detection techniques is difficult due to the lack of standardized datasets and evaluation methods. This study introduces a unified melanoma classification approach that supports 54 combinations of 11 datasets and 24 state-of-the-art deep learning architectures. It enables a fair comparison of 1,296 experiments and results in a lightweight model deployable to the web-based MeshNet architecture named Mela-D. This approach can run up to 33x faster by reducing parameters 24x to yield an analogous 88.8\% accuracy comparable with ResNet50 on previously unseen images. This allows efficient and accurate melanoma detection in real-world settings that can run on consumer-level hardware.
    
[^72]: WeatherProof:借助语言指导在恶劣天气条件下进行语义分割

    WeatherProof: Leveraging Language Guidance for Semantic Segmentation in Adverse Weather

    [https://arxiv.org/abs/2403.14874](https://arxiv.org/abs/2403.14874)

    该论文提出了一种在恶劣天气条件下进行语义分割的方法，通过引入语言指导以提高模型的鲁棒性。

    

    我们提出了一种方法来推断在恶劣天气条件下拍摄的图像的语义分割图。我们首先检查了针对受天气条件（如雨、雾或雪）影响而降级的图像的现有模型，发现它们与在晴朗天气下拍摄的图像相比性能大幅下降。为了控制场景结构的变化，我们提出了WeatherProof，这是第一个具有准确的晴朗和恶劣天气图像对的语义分割数据集，它们共享相同的场景。通过这个数据集，我们分析了现有模型的错误模式，发现它们对在拍摄过程中施加在图像上的不同天气效应的高度复杂组合敏感。为了提高鲁棒性，我们提出了一种使用语言作为指导的方式，通过识别恶劣天气条件的影响并将其注入为“辅助信息”。使用我们的语言指导训练的模型表现

    arXiv:2403.14874v1 Announce Type: cross  Abstract: We propose a method to infer semantic segmentation maps from images captured under adverse weather conditions. We begin by examining existing models on images degraded by weather conditions such as rain, fog, or snow, and found that they exhibit a large performance drop as compared to those captured under clear weather. To control for changes in scene structures, we propose WeatherProof, the first semantic segmentation dataset with accurate clear and adverse weather image pairs that share an underlying scene. Through this dataset, we analyze the error modes in existing models and found that they were sensitive to the highly complex combination of different weather effects induced on the image during capture. To improve robustness, we propose a way to use language as guidance by identifying contributions of adverse weather conditions and injecting that as "side information". Models trained using our language guidance exhibit performance
    
[^73]: VidLA: 规模化视频语言对齐

    VidLA: Video-Language Alignment at Scale

    [https://arxiv.org/abs/2403.14870](https://arxiv.org/abs/2403.14870)

    VidLA 提出了一种规模化视频语言对齐方法，通过简化网络架构和使用分层数据令牌来捕捉短程和长程时间依赖关系，从而成功融合预训练图像-文本基础模型，提高了最终性能。

    

    在这篇论文中，我们提出了VidLA，一种用于规模化视频语言对齐的方法。我们解决了以往视频语言对齐方法的两个主要局限。首先，它们没有捕捉到短程和长程时间依赖关系，并且通常采用复杂的分层深度网络架构，难以与现有的预训练图像-文本基础模型集成。为了有效解决这一限制，我们保持网络架构简单，使用一组在不同时间分辨率下以分层方式运行的数据令牌，从而考虑视频的时间分层性质。通过使用简单的双塔架构，我们能够使用预训练的图像-文本基础模型初始化我们的视频-语言模型，从而提高最终性能。

    arXiv:2403.14870v1 Announce Type: cross  Abstract: In this paper, we propose VidLA, an approach for video-language alignment at scale. There are two major limitations of previous video-language alignment approaches. First, they do not capture both short-range and long-range temporal dependencies and typically employ complex hierarchical deep network architectures that are hard to integrate with existing pretrained image-text foundation models. To effectively address this limitation, we instead keep the network architecture simple and use a set of data tokens that operate at different temporal resolutions in a hierarchical manner, accounting for the temporally hierarchical nature of videos. By employing a simple two-tower architecture, we are able to initialize our video-language model with pretrained image-text foundation models, thereby boosting the final performance. Second, existing video-language alignment works struggle due to the lack of semantically aligned large-scale training 
    
[^74]: 基于分布信息和波长灵活性的数据驱动声光血氧测量

    Distribution-informed and wavelength-flexible data-driven photoacoustic oximetry

    [https://arxiv.org/abs/2403.14863](https://arxiv.org/abs/2403.14863)

    该研究提出了一种基于递归神经网络架构的方法，解决了传声成像中现有数据驱动方法对血氧饱和度估计的不灵活性。

    

    论文翻译: 传声成像（PAI）有望测量具有空间分辨率的血氧饱和度，但目前缺乏准确和稳健的光谱解混方法以兑现这一承诺。准确的血氧饱和度估计在癌症检测到炎症定量等临床应用中具有重要意义。本研究通过引入递归神经网络架构来解决PAI中现有数据驱动方法估计血氧饱和度的不灵活性。

    arXiv:2403.14863v1 Announce Type: cross  Abstract: Significance: Photoacoustic imaging (PAI) promises to measure spatially-resolved blood oxygen saturation, but suffers from a lack of accurate and robust spectral unmixing methods to deliver on this promise. Accurate blood oxygenation estimation could have important clinical applications, from cancer detection to quantifying inflammation.   Aim: This study addresses the inflexibility of existing data-driven methods for estimating blood oxygenation in PAI by introducing a recurrent neural network architecture.   Approach: We created 25 simulated training dataset variations to assess neural network performance. We used a long short-term memory network to implement a wavelength-flexible network architecture and proposed the Jensen-Shannon divergence to predict the most suitable training dataset.   Results: The network architecture can handle arbitrary input wavelengths and outperforms linear unmixing and the previously proposed learned spe
    
[^75]: 使用$\mathcal{L}_1$自适应控制的鲁棒性基于模型的强化学习

    Robust Model Based Reinforcement Learning Using $\mathcal{L}_1$ Adaptive Control

    [https://arxiv.org/abs/2403.14860](https://arxiv.org/abs/2403.14860)

    本研究引入了一种使用$\mathcal{L}_1$自适应控制的鲁棒性基于模型的强化学习方法，通过增强系统对不确定性的鲁棒性，提高了MBRL算法的性能和样本效率。

    

    我们引入了$\mathcal{L}_1$-MBRL，这是一种用于模型基强化学习（MBRL）算法的控制理论增强方案。与无模型方法不同，MBRL算法通过数据学习转移函数模型，并用它设计控制输入。我们的方法根据提出的切换规律生成一系列学习转移函数的近似控制仿射模型。通过近似模型，底层MBRL生成的控制输入被$\mathcal{L}_1$自适应控制所扰动，旨在增强系统对不确定性的鲁棒性。重要的是，这种方法对MBRL算法的选择是不可知的，可以与各种MBRL算法一起使用。具有$\mathcal{L}_1$增强的MBRL算法在多个MuJoCo环境中表现出更佳的性能和样本效率，优于原始MBRL算法。

    arXiv:2403.14860v1 Announce Type: cross  Abstract: We introduce $\mathcal{L}_1$-MBRL, a control-theoretic augmentation scheme for Model-Based Reinforcement Learning (MBRL) algorithms. Unlike model-free approaches, MBRL algorithms learn a model of the transition function using data and use it to design a control input. Our approach generates a series of approximate control-affine models of the learned transition function according to the proposed switching law. Using the approximate model, control input produced by the underlying MBRL is perturbed by the $\mathcal{L}_1$ adaptive control, which is designed to enhance the robustness of the system against uncertainties. Importantly, this approach is agnostic to the choice of MBRL algorithm, enabling the use of the scheme with various MBRL algorithms. MBRL algorithms with $\mathcal{L}_1$ augmentation exhibit enhanced performance and sample efficiency across multiple MuJoCo environments, outperforming the original MBRL algorithms, both with 
    
[^76]: iSpLib：使用自动调优稀疏操作加速图神经网络的库

    iSpLib: A Library for Accelerating Graph Neural Networks using Auto-tuned Sparse Operations

    [https://arxiv.org/abs/2403.14853](https://arxiv.org/abs/2403.14853)

    iSpLib是一个基于PyTorch的C++库，提供了自动调优的稀疏操作，加速了图神经网络的训练，并通过缓存优化和用户友好的Python插件实现了简便的操作。

    

    图神经网络（GNN）训练和推断中的核心计算通常被映射到稀疏矩阵运算，如稀疏-稠密矩阵乘法（SpMM）。这些稀疏操作很难通过手动调优进行优化，因为它们的性能在很大程度上取决于输入图的稀疏性、GNN模型和计算平台。为解决这一挑战，我们提出了iSpLib，一个基于PyTorch的C++库，配备了自动调优的稀疏操作。iSpLib通过具有缓存功能的反向传播加快了GNN训练，该反向传播将中间矩阵存储在本地缓存中。该库提供了一个用户友好的Python插件，允许用户利用我们优化过的PyTorch操作，仅需两行额外代码即可直接在任何现有基于线性代数的PyTorch实现的流行GNN（图卷积网络、GraphSAGE、图推理网络等）中使用。我们展示了iSpLib在不同数据集上的训练加速，最大可达2倍。

    arXiv:2403.14853v1 Announce Type: new  Abstract: Core computations in Graph Neural Network (GNN) training and inference are often mapped to sparse matrix operations such as sparse-dense matrix multiplication (SpMM). These sparse operations are harder to optimize by manual tuning because their performance depends significantly on the sparsity of input graphs, GNN models, and computing platforms. To address this challenge, we present iSpLib, a PyTorch-based C++ library equipped with auto-tuned sparse operations. iSpLib expedites GNN training with a cache-enabled backpropagation that stores intermediate matrices in local caches. The library offers a user-friendly Python plug-in that allows users to take advantage of our optimized PyTorch operations out-of-the-box for any existing linear algebra-based PyTorch implementation of popular GNNs (Graph Convolution Network, GraphSAGE, Graph Inference Network, etc.) with only two lines of additional code. We demonstrate that iSpLib obtains up to 2
    
[^77]: 输出受限失真源编码及在速率-失真-感知理论中的应用

    Output-Constrained Lossy Source Coding With Application to Rate-Distortion-Perception Theory

    [https://arxiv.org/abs/2403.14849](https://arxiv.org/abs/2403.14849)

    分析了具有有限通用随机性的输出受限失真源编码在均方误差失真度量下的特殊情况，推导出了高斯分布情况下的明确表达式，并部分刻画了二次高斯速率-失真-感知编码的信息论极限。

    

    分析了具有有限通用随机性的输出受限失真源编码的失真-速率函数，特别是对于均方误差失真度量的特殊情况。当源和重建分布均为高斯分布时，得到了一个明确的表达式。进一步导致了利用Kullback-Leibler散度或平方二次Wasserstein距离给定感知度量的二次高斯速率-失真-感知编码的信息论极限的部分表征。

    arXiv:2403.14849v1 Announce Type: cross  Abstract: The distortion-rate function of output-constrained lossy source coding with limited common randomness is analyzed for the special case of squared error distortion measure. An explicit expression is obtained when both source and reconstruction distributions are Gaussian. This further leads to a partial characterization of the information-theoretic limit of quadratic Gaussian rate-distortion-perception coding with the perception measure given by Kullback-Leibler divergence or squared quadratic Wasserstein distance.
    
[^78]: 学习WENO用于熵稳定方案以解决守恒定律

    Learning WENO for entropy stable schemes to solve conservation laws

    [https://arxiv.org/abs/2403.14848](https://arxiv.org/abs/2403.14848)

    提出了一种称为Deep Sign-Preserving WENO（DSP-WENO）的变种，通过神经网络学习WENO加权策略，以改进在震荡附近表现不佳的WENO算法。

    

    熵条件在提取系统守恒律的物理相关解时起着至关重要的作用，因此促使构建满足离散条件的熵稳定方案。 TeCNO方案（Fjordholm等，2012）形成了一类任意高阶熵稳定有限差分求解器，它们需要满足每个单元格界面的符号特性的专业重构算法。最近，设计了满足符号特性的第三阶WENO方案，称为SP-WENO（Fjordholm和Ray，2016）和SP-WENOc（Ray，2018）。然而，这些WENO算法在震荡附近的性能可能很差，数值解表现出大的人工振荡。在本研究中，我们提出了SP-WENO的一个变种，称为Deep Sign-Preserving WENO（DSP-WENO），在其中，一个神经网络被训练来学习WENO加权策略。

    arXiv:2403.14848v1 Announce Type: cross  Abstract: Entropy conditions play a crucial role in the extraction of a physically relevant solution for a system of conservation laws, thus motivating the construction of entropy stable schemes that satisfy a discrete analogue of such conditions. TeCNO schemes (Fjordholm et al. 2012) form a class of arbitrary high-order entropy stable finite difference solvers, which require specialized reconstruction algorithms satisfying the sign property at each cell interface. Recently, third-order WENO schemes called SP-WENO (Fjordholm and Ray, 2016) and SP-WENOc (Ray, 2018) have been designed to satisfy the sign property. However, these WENO algorithms can perform poorly near shocks, with the numerical solutions exhibiting large spurious oscillations. In the present work, we propose a variant of the SP-WENO, termed as Deep Sign-Preserving WENO (DSP-WENO), where a neural network is trained to learn the WENO weighting strategy. The sign property and third-o
    
[^79]: 具有线性非高斯循环模型的局部因果发现

    Local Causal Discovery with Linear non-Gaussian Cyclic Models

    [https://arxiv.org/abs/2403.14843](https://arxiv.org/abs/2403.14843)

    提出一种通用的、统一的局部因果发现方法，使用线性非高斯模型，实现了从目标变量的马尔可夫毯中精确识别等效的局部有向结构和因果强度

    

    局部因果发现具有重要的实际意义，因为经常会出现发现全局因果结构并非必要的情况，兴趣仅仅在于单个目标变量。本工作提出了一种通用的、统一的局部因果发现方法，使用线性非高斯模型，无论其是否是循环的或非循环的。我们将独立成分分析的应用从全局上下文扩展到独立子空间分析，从目标变量的马尔可夫毯中精确识别等效的局部有向结构和因果强度。

    arXiv:2403.14843v1 Announce Type: cross  Abstract: Local causal discovery is of great practical significance, as there are often situations where the discovery of the global causal structure is unnecessary, and the interest lies solely on a single target variable. Most existing local methods utilize conditional independence relations, providing only a partially directed graph, and assume acyclicity for the ground-truth structure, even though real-world scenarios often involve cycles like feedback mechanisms. In this work, we present a general, unified local causal discovery method with linear non-Gaussian models, whether they are cyclic or acyclic. We extend the application of independent component analysis from the global context to independent subspace analysis, enabling the exact identification of the equivalent local directed structures and causal strengths from the Markov blanket of the target variable. We also propose an alternative regression-based method in the particular acycl
    
[^80]: 深度结构状态空间模型的模型降阶：一种系统论方法

    Model order reduction of deep structured state-space models: A system-theoretic approach

    [https://arxiv.org/abs/2403.14833](https://arxiv.org/abs/2403.14833)

    通过系统论方法针对深度结构状态空间模型的线性动态块进行模型降阶，引入了模态$\ell_1$和Hankel核范数正则化，促进稀疏性，可在不牺牲准确性的前提下仅保留相关状态。

    

    在控制设计目标的特定强调下，通过有限的复杂度实现准确的系统建模对于参数系统辨识至关重要。最近引入的深度结构状态空间模型（SSM），其具有线性动态块作为关键组成部分，提供了较高的预测性能。然而，所学表示经常受到过大的模型阶数的影响，这使它们不适用于控制设计目的。本文通过系统论模型降阶技术来解决这一挑战，该技术针对SSM的线性动态块。我们引入了两个正则化项，可结合到训练损失中以实现改善的模型降阶。具体而言，我们考虑模态$\ell_1$ 和 Hankel核范数正则化来促进稀疏性，使得能够保留仅相关状态而不损失准确性。

    arXiv:2403.14833v1 Announce Type: new  Abstract: With a specific emphasis on control design objectives, achieving accurate system modeling with limited complexity is crucial in parametric system identification. The recently introduced deep structured state-space models (SSM), which feature linear dynamical blocks as key constituent components, offer high predictive performance. However, the learned representations often suffer from excessively large model orders, which render them unsuitable for control design purposes. The current paper addresses this challenge by means of system-theoretic model order reduction techniques that target the linear dynamical blocks of SSMs. We introduce two regularization terms which can be incorporated into the training loss for improved model order reduction. In particular, we consider modal $\ell_1$ and Hankel nuclear norm regularization to promote sparsity, allowing one to retain only the relevant states without sacrificing accuracy. The presented reg
    
[^81]: 深度聚类评估：如何验证内部聚类有效性测量方法

    Deep Clustering Evaluation: How to Validate Internal Clustering Validation Measures

    [https://arxiv.org/abs/2403.14830](https://arxiv.org/abs/2403.14830)

    本文解决了深度聚类方法在评估聚类质量时面临的挑战，提出了一种系统方法来应用聚类有效性指标。

    

    arXiv:2403.14830v1 通告类型：跨领域 摘要：深度聚类是一种使用深度神经网络对复杂、高维数据进行划分的方法，它面临着独特的评估挑战。传统的聚类验证方法，设计用于低维空间，对于涉及将数据投影到较低维嵌入空间后再进行划分的深度聚类来说是有问题的。论文确定了两个关键问题：1）在将这些方法应用于原始数据时的维度灾难，2）由于不同聚类模型的训练过程和参数设置的变化而导致不同嵌入空间中的聚类结果无法可靠比较。本文解决了在深度学习中评估聚类质量所面临的挑战。我们提出了一个理论框架来强调在原始数据和嵌入数据上使用内部验证方法可能出现的无效性，并提出了一种系统方法来应用深度聚类有效性指标。

    arXiv:2403.14830v1 Announce Type: cross  Abstract: Deep clustering, a method for partitioning complex, high-dimensional data using deep neural networks, presents unique evaluation challenges. Traditional clustering validation measures, designed for low-dimensional spaces, are problematic for deep clustering, which involves projecting data into lower-dimensional embeddings before partitioning. Two key issues are identified: 1) the curse of dimensionality when applying these measures to raw data, and 2) the unreliable comparison of clustering results across different embedding spaces stemming from variations in training procedures and parameter settings in different clustering models. This paper addresses these challenges in evaluating clustering quality in deep learning. We present a theoretical framework to highlight ineffectiveness arising from using internal validation measures on raw and embedded data and propose a systematic approach to applying clustering validity indices in deep 
    
[^82]: 逻辑函数的双曲正割表示：在CT颅内出血检测中的概率多示例学习应用

    Hyperbolic Secant representation of the logistic function: Application to probabilistic Multiple Instance Learning for CT intracranial hemorrhage detection

    [https://arxiv.org/abs/2403.14829](https://arxiv.org/abs/2403.14829)

    通过使用P\'olya-Gamma随机变量制定VGPMIL，该方法产生与原始VGPMIL相同的变分后验近似，这是双曲正割分布所承认的两种表示的结果。

    

    多示例学习（MIL）是一种成功应用于许多不同科学领域的弱监督范式，特别适用于医学成像。概率MIL方法，尤其是高斯过程（GPs），由于其高表达性和不确定性量化能力已经取得了出色的结果。最成功的基于GP的MIL方法之一，VGPMIL，使用变分边界处理逻辑函数的不可解性。在这里，我们使用P\'olya-Gamma随机变量来制定VGPMIL。这种方法产生与原始VGPMIL相同的变分后验近似，这是双曲正割分布所承认的两种表示的结果。这导致我们提出了一种通用的基于GP的MIL方法，通过简单利用除双曲正割以外的分布，可以采取不同形式。使用Gamma分布

    arXiv:2403.14829v1 Announce Type: new  Abstract: Multiple Instance Learning (MIL) is a weakly supervised paradigm that has been successfully applied to many different scientific areas and is particularly well suited to medical imaging. Probabilistic MIL methods, and more specifically Gaussian Processes (GPs), have achieved excellent results due to their high expressiveness and uncertainty quantification capabilities. One of the most successful GP-based MIL methods, VGPMIL, resorts to a variational bound to handle the intractability of the logistic function. Here, we formulate VGPMIL using P\'olya-Gamma random variables. This approach yields the same variational posterior approximations as the original VGPMIL, which is a consequence of the two representations that the Hyperbolic Secant distribution admits. This leads us to propose a general GP-based MIL method that takes different forms by simply leveraging distributions other than the Hyperbolic Secant one. Using the Gamma distribution
    
[^83]: 使用Sinkhorn不确定性集的非凸鲁棒假设检验

    Non-Convex Robust Hypothesis Testing using Sinkhorn Uncertainty Sets

    [https://arxiv.org/abs/2403.14822](https://arxiv.org/abs/2403.14822)

    提出了使用Sinkhorn不确定性集解决非凸鲁棒假设检验问题的新框架，并引入了确切的混合整数指数锥重构方法，证明了优于目前文献中最先进方法的凸逼近。

    

    我们提出了一个新框架来解决非凸鲁棒假设检验问题，其中目标是寻找最优探测器，以最小化最坏情况下的类型I和类型II风险函数的最大值。分布不确定性集围绕基于Sinkhorn距离的样本得出的经验分布构建。由于目标涉及非凸、非平滑的概率函数，通常难以优化，现有方法往往采用近似而非精确解决方案。为了解决这一挑战，我们引入了一个确切的混合整数指数锥重构问题的方法，可以在适量的输入数据下达到全局最优解。随后，我们提出了一个凸逼近，展示了其优于当前文献中最先进方法的方法。此外，我们建立了鲁棒假设检验与...

    arXiv:2403.14822v1 Announce Type: cross  Abstract: We present a new framework to address the non-convex robust hypothesis testing problem, wherein the goal is to seek the optimal detector that minimizes the maximum of worst-case type-I and type-II risk functions. The distributional uncertainty sets are constructed to center around the empirical distribution derived from samples based on Sinkhorn discrepancy. Given that the objective involves non-convex, non-smooth probabilistic functions that are often intractable to optimize, existing methods resort to approximations rather than exact solutions. To tackle the challenge, we introduce an exact mixed-integer exponential conic reformulation of the problem, which can be solved into a global optimum with a moderate amount of input data. Subsequently, we propose a convex approximation, demonstrating its superiority over current state-of-the-art methodologies in literature. Furthermore, we establish connections between robust hypothesis testi
    
[^84]: 大型语言模型在心理健康领域的机会和风险

    The opportunities and risks of large language models in mental health

    [https://arxiv.org/abs/2403.14814](https://arxiv.org/abs/2403.14814)

    大型语言模型在心理健康领域有望提供新颖的解决方案，但应注意其应用可能带来的风险，并积极采取策略减轻这些风险。

    

    全球心理健康问题的发生率正在上升，人们越来越意识到现有的心理保健模式无法充分扩展以满足需求。随着大型语言模型（LLMs）的出现，人们对它们具有创造新颖、大规模解决方案以支持心理健康的承诺感到乐观。尽管它们还处于初期阶段，LLMs已被应用于与心理健康相关的任务。本综述总结了已有文献中关于利用LLMs提供心理健康教育、评估和干预的努力，并突出了每个领域中产生积极影响的关键机会。然后，我们强调了将LLMs应用于心理健康领域所伴随的风险，并鼓励采用策略来减轻这些风险。对于心理健康支持的迫切需求必须与负责任的心理健康LLMs的开发、测试和部署相平衡。特别关键的是确保心理健康...

    arXiv:2403.14814v1 Announce Type: cross  Abstract: Global rates of mental health concerns are rising and there is increasing realization that existing models of mental healthcare will not adequately expand to meet the demand. With the emergence of large language models (LLMs) has come great optimism regarding their promise to create novel, large-scale solutions to support mental health. Despite their nascence, LLMs have already been applied to mental health-related tasks. In this review, we summarize the extant literature on efforts to use LLMs to provide mental health education, assessment, and intervention and highlight key opportunities for positive impact in each area. We then highlight risks associated with LLMs application to mental health and encourage adoption of strategies to mitigate these risks. The urgent need for mental health support must be balanced with responsible development, testing, and deployment of mental health LLMs. Especially critical is ensuring that mental he
    
[^85]: 曲率增强流形嵌入与学习

    Curvature Augmented Manifold Embedding and Learning

    [https://arxiv.org/abs/2403.14813](https://arxiv.org/abs/2403.14813)

    将降维问题建模为机械/物理模型，引入曲率增强力的曲率增强流形嵌入与学习（CAMEL）方法提供了一种新的方法来捕捉数据集的n维流形表示。

    

    发表于arXiv:2403.14813v1，其中提出了一种新的降维（DR）和数据可视化方法，称为曲率增强流形嵌入与学习（CAMEL）。其关键创新贡献在于将降维问题建模为一个机械/物理模型，其中节点（数据点）之间的力场被用来找到数据集的n维流形表示。与许多现有的吸引-排斥力方法相比，本方法的一个独特贡献是包含了一个非成对力。引入和讨论了一种新的力场模型，灵感来自于晶格粒子物理学中的多体势和拓扑学中的黎曼曲率。CAMEL中包含了一种曲率增强力。其次，提供了CAMEL用于无监督学习、监督学习、半监督学习/度量学习和逆向学习的公式。然后，通过与现有模型的比较，将CAMEL应用于许多基准数据集。

    arXiv:2403.14813v1 Announce Type: cross  Abstract: A new dimensional reduction (DR) and data visualization method, Curvature-Augmented Manifold Embedding and Learning (CAMEL), is proposed. The key novel contribution is to formulate the DR problem as a mechanistic/physics model, where the force field among nodes (data points) is used to find an n-dimensional manifold representation of the data sets. Compared with many existing attractive-repulsive force-based methods, one unique contribution of the proposed method is to include a non-pairwise force. A new force field model is introduced and discussed, inspired by the multi-body potential in lattice-particle physics and Riemann curvature in topology. A curvature-augmented force is included in CAMEL. Following this, CAMEL formulation for unsupervised learning, supervised learning, semi-supervised learning/metric learning, and inverse learning are provided. Next, CAMEL is applied to many benchmark datasets by comparing existing models, suc
    
[^86]: 深度主动学习：现实检验

    Deep Active Learning: A Reality Check

    [https://arxiv.org/abs/2403.14800](https://arxiv.org/abs/2403.14800)

    深度主动学习方法的全面评估发现在一般情况下，没有单一模型方法能明显优于基于熵的主动学习，同时揭示了起始预算、预算步长和预训练等因素对取得优越结果的重要性，并拓展了在其他任务中的应用。

    

    我们对最先进的深度主动学习方法进行了全面评估。令人惊讶的是，在一般情况下，没有单一模型方法能明显优于基于熵的主动学习，甚至有些方法表现不如随机抽样。我们深入探讨了一些被忽视的方面，如起始预算、预算步长和预训练的影响，揭示了它们在取得卓越结果中的重要性。此外，我们将评估扩展到其他任务，探索主动学习与半监督学习、目标检测相结合的有效性。我们的实验提供了有价值的见解和具体建议，为未来的主动学习研究提供了指导。通过揭示当前方法的局限性，了解不同实验设置的影响，我们旨在激发在具有有限注释预算的真实场景中更有效地训练深度学习模型。这项工作有助于推动

    arXiv:2403.14800v1 Announce Type: cross  Abstract: We conduct a comprehensive evaluation of state-of-the-art deep active learning methods. Surprisingly, under general settings, no single-model method decisively outperforms entropy-based active learning, and some even fall short of random sampling. We delve into overlooked aspects like starting budget, budget step, and pretraining's impact, revealing their significance in achieving superior results. Additionally, we extend our evaluation to other tasks, exploring the active learning effectiveness in combination with semi-supervised learning, and object detection. Our experiments provide valuable insights and concrete recommendations for future active learning studies. By uncovering the limitations of current methods and understanding the impact of different experimental settings, we aim to inspire more efficient training of deep learning models in real-world scenarios with limited annotation budgets. This work contributes to advancing a
    
[^87]: 通过记忆网络在连续检测中防止灾难性遗忘

    Preventing Catastrophic Forgetting through Memory Networks in Continuous Detection

    [https://arxiv.org/abs/2403.14797](https://arxiv.org/abs/2403.14797)

    通过引入记忆网络和局部查询函数，这项工作致力于在连续检测中防止灾难性遗忘，并解决了持续检测中的背景贬低问题。

    

    现代预训练架构在持续对新任务进行微调时很难保留先前的信息。尽管在持续分类方面取得了显著进展，但针对复杂视觉任务（如检测或分割）设计的系统仍然难以获得满意的性能。在这项工作中，我们引入了一种基于记忆的检测变压器架构，以使预训练的DETR风格检测器适应新任务，同时保留先前任务的知识。我们提出了一种新颖的局部查询函数，用于有效地从记忆单元中检索信息，旨在最小化遗忘。此外，我们确定了持续检测中一个称为背景贬低的基本挑战。当来自先前任务的对象类别在未来任务中重新出现时，可能没有标签，导致它们被隐式视为背景。这是持续检测或分割中不可避免的问题。

    arXiv:2403.14797v1 Announce Type: cross  Abstract: Modern pre-trained architectures struggle to retain previous information while undergoing continuous fine-tuning on new tasks. Despite notable progress in continual classification, systems designed for complex vision tasks such as detection or segmentation still struggle to attain satisfactory performance. In this work, we introduce a memory-based detection transformer architecture to adapt a pre-trained DETR-style detector to new tasks while preserving knowledge from previous tasks. We propose a novel localized query function for efficient information retrieval from memory units, aiming to minimize forgetting. Furthermore, we identify a fundamental challenge in continual detection referred to as background relegation. This arises when object categories from earlier tasks reappear in future tasks, potentially without labels, leading them to be implicitly treated as background. This is an inevitable issue in continual detection or segme
    
[^88]: 多智体VQA：探索零样本视觉问答中的多智体基础模型

    Multi-Agent VQA: Exploring Multi-Agent Foundation Models in Zero-Shot Visual Question Answering

    [https://arxiv.org/abs/2403.14783](https://arxiv.org/abs/2403.14783)

    本研究提出了一种自适应多智体系统，名为多智体VQA，通过使用专门的智体工具，克服了基础模型在目标检测和计数中的局限性，在零样本情况下实现了良好的性能，为未来研究提供了新的方向。

    

    这项工作探讨了基础模型在视觉问答（VQA）任务中的零样本能力。我们提出了一种自适应多智体系统，命名为多智体VQA，通过使用专门的智体作为工具，以克服基础模型在目标检测和计数中的局限性。与现有方法不同，我们的研究侧重于在不对其进行特定VQA数据集微调的情况下系统的性能，使其在开放世界中更加实用和稳健。我们在零样本场景下提出了初步实验结果，并突出了一些失败案例，为未来研究提供了新的方向。

    arXiv:2403.14783v1 Announce Type: cross  Abstract: This work explores the zero-shot capabilities of foundation models in Visual Question Answering (VQA) tasks. We propose an adaptive multi-agent system, named Multi-Agent VQA, to overcome the limitations of foundation models in object detection and counting by using specialized agents as tools. Unlike existing approaches, our study focuses on the system's performance without fine-tuning it on specific VQA datasets, making it more practical and robust in the open world. We present preliminary experimental results under zero-shot scenarios and highlight some failure cases, offering new directions for future research.
    
[^89]: 视觉-语言模型上的少样本对抗提示学习

    Few-Shot Adversarial Prompt Learning on Vision-Language Models

    [https://arxiv.org/abs/2403.14774](https://arxiv.org/abs/2403.14774)

    本文提出了一个少样本对抗提示框架，在视觉-语言模型中通过有限数据调整输入序列，显著提升对抗鲁棒性，并通过端到端学习对抗性相关的文本监督。

    

    深度神经网络对于微不可见的对抗性扰动的脆弱性已经引起了广泛关注。受到视觉-语言基础模型成功的启发，先前的努力通过将对抗性视觉特征与文本监督对齐来实现零样本对抗鲁棒性。但在实践中，由于包括重大适应成本、次优文本监督和未受控制的自然泛化能力在内的多个问题，它们仍然不尽人意。为了解决这些问题，本文提出了一个少样本对抗提示框架，通过有限的数据调整输入序列使得对抗鲁棒性得到显著提升。具体而言，我们通过提供对抗相关的文本监督，该监督是从对抗性示例中端到端学习的，来实现这一点。我们还提出了一个增强多模态特征一致性并鼓励不同

    arXiv:2403.14774v1 Announce Type: cross  Abstract: The vulnerability of deep neural networks to imperceptible adversarial perturbations has attracted widespread attention. Inspired by the success of vision-language foundation models, previous efforts achieved zero-shot adversarial robustness by aligning adversarial visual features with text supervision. However, in practice, they are still unsatisfactory due to several issues, including heavy adaptation cost, suboptimal text supervision, and uncontrolled natural generalization capacity. In this paper, to address these issues, we propose a few-shot adversarial prompt framework where adapting input sequences with limited data makes significant adversarial robustness improvement. Specifically, we achieve this by providing adversarially correlated text supervision that is end-to-end learned from adversarial examples. We also propose a novel training objective that enhances the consistency of multi-modal features while encourages differenti
    
[^90]: StreamingT2V: 一种一致、动态和可扩展的基于文本的长视频生成方法

    StreamingT2V: Consistent, Dynamic, and Extendable Long Video Generation from Text

    [https://arxiv.org/abs/2403.14773](https://arxiv.org/abs/2403.14773)

    StreamingT2V是一种自回归方法，用于生成长视频，可以产生80、240、600、1200帧甚至更多帧的视频，并具有平滑的过渡。

    

    arXiv:2403.14773v1 公告类型: 交叉 摘要: 文本到视频的扩散模型可以生成遵循文本指令的高质量视频，使得创建多样化和个性化内容变得更加容易。然而，现有方法大多集中在生成高质量的短视频（通常为16或24帧），当天真地扩展到长视频合成的情况时，通常会出现硬裁剪。为了克服这些限制，我们引入了StreamingT2V，这是一种自回归方法，用于生成80、240、600、1200或更多帧的长视频，具有平滑的过渡。主要组件包括：（i）一种名为条件注意力模块（CAM）的短期记忆块，通过注意机制将当前生成条件设置为先前块提取的特征，实现一致的块过渡，（ii）一种名为外观保存模块的长期记忆块，从第一个视频块中提取高级场景和对象特征，以防止th

    arXiv:2403.14773v1 Announce Type: cross  Abstract: Text-to-video diffusion models enable the generation of high-quality videos that follow text instructions, making it easy to create diverse and individual content. However, existing approaches mostly focus on high-quality short video generation (typically 16 or 24 frames), ending up with hard-cuts when naively extended to the case of long video synthesis. To overcome these limitations, we introduce StreamingT2V, an autoregressive approach for long video generation of 80, 240, 600, 1200 or more frames with smooth transitions. The key components are:(i) a short-term memory block called conditional attention module (CAM), which conditions the current generation on the features extracted from the previous chunk via an attentional mechanism, leading to consistent chunk transitions, (ii) a long-term memory block called appearance preservation module, which extracts high-level scene and object features from the first video chunk to prevent th
    
[^91]: 通过稀疏编码架构提高模型逆推攻击的鲁棒性

    Improving Robustness to Model Inversion Attacks via Sparse Coding Architectures

    [https://arxiv.org/abs/2403.14772](https://arxiv.org/abs/2403.14772)

    通过稀疏编码层设计新网络架构以提高对模型逆推攻击的鲁棒性。

    

    最近的模型逆推攻击算法允许对手通过反复查询神经网络并检查其输出来重建网络的私有训练数据。 在这项工作中，我们开发了一种新颖的网络架构，利用稀疏编码层来获得对这类攻击的卓越鲁棒性。 三十年来，计算机科学研究已经研究了稀疏编码在图像去噪，目标识别和对抗性误分设置中的作用，但据我们所知，其与最先进的隐私漏洞之间的联系尚未被研究。然而，稀疏编码架构提供了一种有利的手段来抵御模型逆推攻击，因为它们允许我们控制编码在网络的中间表示中的无关私人信息的数量，而这种方式可以在训练过程中高效计算，并且众所周知只有较小的影响。

    arXiv:2403.14772v1 Announce Type: cross  Abstract: Recent model inversion attack algorithms permit adversaries to reconstruct a neural network's private training data just by repeatedly querying the network and inspecting its outputs. In this work, we develop a novel network architecture that leverages sparse-coding layers to obtain superior robustness to this class of attacks. Three decades of computer science research has studied sparse coding in the context of image denoising, object recognition, and adversarial misclassification settings, but to the best of our knowledge, its connection to state-of-the-art privacy vulnerabilities remains unstudied. However, sparse coding architectures suggest an advantageous means to defend against model inversion attacks because they allow us to control the amount of irrelevant private information encoded in a network's intermediate representations in a manner that can be computed efficiently during training and that is known to have little effect
    
[^92]: 与SASQuaTCh学习：基于核自注意力的新型变分量子变压器架构

    Learning with SASQuaTCh: a Novel Variational Quantum Transformer Architecture with Kernel-Based Self-Attention

    [https://arxiv.org/abs/2403.14753](https://arxiv.org/abs/2403.14753)

    本研究提出了一种通过核自注意力来学习的新型变分量子变压器架构，可以用简单的卷积核表示深层的视觉变压器网络。

    

    由生成式预训练变压器（GPT）普及的广泛流行的变压器网络在许多领域都有广泛的应用，包括预测文本和图像、分类，甚至预测物理系统动力学的解。本工作中，我们探讨了能够通过基于核的运算符学习视角高效表达自我注意机制的量子电路。在这个视角下，我们能够使用简单的卷积核来表示视觉变压器网络的深层。

    arXiv:2403.14753v1 Announce Type: cross  Abstract: The widely popular transformer network popularized by the generative pre-trained transformer (GPT) has a large field of applicability, including predicting text and images, classification, and even predicting solutions to the dynamics of physical systems. In the latter context, the continuous analog of the self-attention mechanism at the heart of transformer networks has been applied to learning the solutions of partial differential equations and reveals a convolution kernel nature that can be exploited by the Fourier transform. It is well known that many quantum algorithms that have provably demonstrated a speedup over classical algorithms utilize the quantum Fourier transform. In this work, we explore quantum circuits that can efficiently express a self-attention mechanism through the perspective of kernel-based operator learning. In this perspective, we are able to represent deep layers of a vision transformer network using simple g
    
[^93]: 一个基于分类器的多类异常检测方法，用于天文暂变星

    A Classifier-Based Approach to Multi-Class Anomaly Detection for Astronomical Transients

    [https://arxiv.org/abs/2403.14742](https://arxiv.org/abs/2403.14742)

    使用神经网络分类器的倒数第二层作为异常检测的潜在空间，并提出了一种名为多类孤立森林（MCIF）的新方法来训练每个类别的孤立森林，以推导异常值

    

    实时自动异常检测对于在大规模天文调查时代识别稀有的短暂现象至关重要。目前，大部分天文暂变检测算法要么依赖于从光变曲线中提取的手工特征，要么依赖于通过无监督表示学习生成的特征，然后与标准机器学习异常检测算法结合。在本研究中，我们引入了一种另类的检测异常的方法：使用神经网络分类器的倒数第二层作为异常检测的潜在空间。然后，我们提出了一种名为多类孤立森林（MCIF）的新方法，该方法为每个类别训练单独的孤立森林来推导异常值。

    arXiv:2403.14742v1 Announce Type: cross  Abstract: Automating real-time anomaly detection is essential for identifying rare transients in the era of large-scale astronomical surveys. Modern survey telescopes are generating tens of thousands of alerts per night, and future telescopes, such as the Vera C. Rubin Observatory, are projected to increase this number dramatically. Currently, most anomaly detection algorithms for astronomical transients rely either on hand-crafted features extracted from light curves or on features generated through unsupervised representation learning, which are then coupled with standard machine learning anomaly detection algorithms. In this work, we introduce an alternative approach to detecting anomalies: using the penultimate layer of a neural network classifier as the latent space for anomaly detection. We then propose a novel method, named Multi-Class Isolation Forests (MCIF), which trains separate isolation forests for each class to derive an anomaly sc
    
[^94]: 一种用于智能卫星物联网系统的异常检测任务

    A task of anomaly detection for a smart satellite Internet of things system

    [https://arxiv.org/abs/2403.14738](https://arxiv.org/abs/2403.14738)

    提出了一种基于生成对抗网络和自注意机制的无监督深度学习异常检测系统

    

    当设备工作时，实时收集环境传感器数据以进行异常检测是防止工业过程事故和网络攻击、确保系统安全的关键环节之一。然而，在具有特定实时需求的环境中，环境传感器的异常检测仍然面临以下困难：（1）环境传感器数据变量之间复杂的非线性相关特性缺乏有效的表达方法，数据之间的分布难以捕捉。（2）使用复杂的机器学习模型很难确保实时监控要求，并且设备成本过高。（3）样本数据太少导致监督学习中标记数据较少。本文提出了一种无监督深度学习异常检测系统。基于生成对抗网络和自注意机制，consi

    arXiv:2403.14738v1 Announce Type: new  Abstract: When the equipment is working, real-time collection of environmental sensor data for anomaly detection is one of the key links to prevent industrial process accidents and network attacks and ensure system security. However, under the environment with specific real-time requirements, the anomaly detection for environmental sensors still faces the following difficulties: (1) The complex nonlinear correlation characteristics between environmental sensor data variables lack effective expression methods, and the distribution between the data is difficult to be captured. (2) it is difficult to ensure the real-time monitoring requirements by using complex machine learning models, and the equipment cost is too high. (3) Too little sample data leads to less labeled data in supervised learning. This paper proposes an unsupervised deep learning anomaly detection system. Based on the generative adversarial network and self-attention mechanism, consi
    
[^95]: FedMef：面向内存高效的联邦动态剪枝

    FedMef: Towards Memory-efficient Federated Dynamic Pruning

    [https://arxiv.org/abs/2403.14737](https://arxiv.org/abs/2403.14737)

    FedMef提出了一种新颖且内存高效的联邦动态剪枝框架，通过预算感知的挤出机制和缩放激活剪枝来解决联邦学习中的性能退化和高激活内存使用等挑战。

    

    引入预算感知的挤出机制以维持剪枝效率，并通过在给定预算内从标记为剪枝的参数中挽救关键信息来保持剪枝后性能；提出了缩放激活剪枝以有效减少激活内存使用的Federated dynamic pruning framework。

    arXiv:2403.14737v1 Announce Type: new  Abstract: Federated learning (FL) promotes decentralized training while prioritizing data confidentiality. However, its application on resource-constrained devices is challenging due to the high demand for computation and memory resources to train deep learning models. Neural network pruning techniques, such as dynamic pruning, could enhance model efficiency, but directly adopting them in FL still poses substantial challenges, including post-pruning performance degradation, high activation memory usage, etc. To address these challenges, we propose FedMef, a novel and memory-efficient federated dynamic pruning framework. FedMef comprises two key components. First, we introduce the budget-aware extrusion that maintains pruning efficiency while preserving post-pruning performance by salvaging crucial information from parameters marked for pruning within a given budget. Second, we propose scaled activation pruning to effectively reduce activation memo
    
[^96]: NaNa和MiGu：语义数据增强技术在图神经网络中增强蛋白质分类

    NaNa and MiGu: Semantic Data Augmentation Techniques to Enhance Protein Classification in Graph Neural Networks

    [https://arxiv.org/abs/2403.14736](https://arxiv.org/abs/2403.14736)

    提出了NaNa和MiGu两种语义数据增强方法，结合了蛋白质的主链化学和侧链生物物理信息，用于增强图神经网络中的蛋白质分类任务。

    

    蛋白质分类任务在药物发现中至关重要。现实世界中的蛋白质结构是动态变化的，这将决定蛋白质的性质。然而，现有的机器学习方法，如ProNet，仅访问有限的构象特征和蛋白质侧链特征，导致预测中蛋白质结构的不切实际和蛋白质类别的不准确性。在本文中，我们提出了新颖的语义数据增强方法NaNa和MiGu，将蛋白质主链化学和侧链生物物理信息纳入蛋白质分类任务和共嵌残差学习框架。具体来说，我们利用了蛋白质的分子生物物理、二级结构、化学键和离子特征来促进蛋白质分类任务。

    arXiv:2403.14736v1 Announce Type: cross  Abstract: Protein classification tasks are essential in drug discovery. Real-world protein structures are dynamic, which will determine the properties of proteins. However, the existing machine learning methods, like ProNet (Wang et al., 2022a), only access limited conformational characteristics and protein side-chain features, leading to impractical protein structure and inaccuracy of protein classes in their predictions. In this paper, we propose novel semantic data augmentation methods, Novel Augmentation of New Node Attributes (NaNa), and Molecular Interactions and Geometric Upgrading (MiGu) to incorporate backbone chemical and side-chain biophysical information into protein classification tasks and a co-embedding residual learning framework. Specifically, we leverage molecular biophysical, secondary structure, chemical bonds, and ionic features of proteins to facilitate protein classification tasks. Furthermore, our semantic augmentation me
    
[^97]: 基于Foundation Models的时间序列分析：教程与调查

    Foundation Models for Time Series Analysis: A Tutorial and Survey

    [https://arxiv.org/abs/2403.14735](https://arxiv.org/abs/2403.14735)

    Foundation Models为时间序列分析带来创新，利用预训练或微调的模型来获得具体定制的广义知识，提升了实践中多个下游任务的效果。

    

    时间序列分析作为数据挖掘领域的焦点，是提取有价值见解的基石，对众多实际应用至关重要。最近Foundation Models（FMs）的发展根本性地改变了时间序列分析模型设计的范式，提升了实践中各种下游任务的效果。这些创新方法通常利用预训练或微调的FMs，以获取专门为时间序列分析量身定制的广义知识。在本调查中，我们旨在提供Foundation Models用于时间序列分析的全面和最新概述。尽管先前的调查主要集中在Foundation Models在时间序列分析中的应用或管道方面，但它们往往缺乏深入了解阐明Foundation Models如何受益时间序列分析的基本机制。为弥补这一空白，我们的调查采用了以模型为中心的分类

    arXiv:2403.14735v1 Announce Type: new  Abstract: Time series analysis stands as a focal point within the data mining community, serving as a cornerstone for extracting valuable insights crucial to a myriad of real-world applications. Recent advancements in Foundation Models (FMs) have fundamentally reshaped the paradigm of model design for time series analysis, boosting various downstream tasks in practice. These innovative approaches often leverage pre-trained or fine-tuned FMs to harness generalized knowledge tailored specifically for time series analysis. In this survey, we aim to furnish a comprehensive and up-to-date overview of FMs for time series analysis. While prior surveys have predominantly focused on either the application or the pipeline aspects of FMs in time series analysis, they have often lacked an in-depth understanding of the underlying mechanisms that elucidate why and how FMs benefit time series analysis. To address this gap, our survey adopts a model-centric class
    
[^98]: 用多任务学习进行开放知识库规范化

    Open Knowledge Base Canonicalization with Multi-task Learning

    [https://arxiv.org/abs/2403.14733](https://arxiv.org/abs/2403.14733)

    提出了一个多任务学习框架MulCanon来处理开放知识库（OKB）规范化问题，并通过在软聚类过程中使用扩散模型来改进名词短语的表示。

    

    大型开放知识库（OKB）的构建对于诸多基于知识的网络应用如网络搜索至关重要。然而，OKB中的名词短语和关系短语往往存在冗余和歧义，这需要对OKB进行规范化的研究。当前的解决方案通过设计先进的聚类算法，并使用知识图嵌入（KGE）进一步促进规范化过程。然而，这些工作未能充分利用聚类和KGE学习之间的协同作用，并且为这些子任务设计的方法是次优的。因此，我们提出了一个名为MulCanon的多任务学习框架来解决OKB的规范化问题。此外，在软聚类过程中使用扩散模型来改进名词短语的表示，带来更准确的表征。

    arXiv:2403.14733v1 Announce Type: new  Abstract: The construction of large open knowledge bases (OKBs) is integral to many knowledge-driven applications on the world wide web such as web search. However, noun phrases and relational phrases in OKBs often suffer from redundancy and ambiguity, which calls for the investigation on OKB canonicalization. Current solutions address OKB canonicalization by devising advanced clustering algorithms and using knowledge graph embedding (KGE) to further facilitate the canonicalization process. Nevertheless, these works fail to fully exploit the synergy between clustering and KGE learning, and the methods designed for these subtasks are sub-optimal. To this end, we put forward a multi-task learning framework, namely MulCanon, to tackle OKB canonicalization. In addition, diffusion model is used in the soft clustering process to improve the noun phrase representations with neighboring information, which can lead to more accurate representations. MulCano
    
[^99]: 可逆跳动攻击对文本分类器的修改缩减

    Reversible Jump Attack to Textual Classifiers with Modification Reduction

    [https://arxiv.org/abs/2403.14731](https://arxiv.org/abs/2403.14731)

    提出了两种算法，可逆跳动攻击（RJA）和Metropolis-Hasting修改缩减（MMR），用于生成高度有效的对抗示例，并分别改善示例的不可察觉性。

    

    最近的对抗样本研究揭示了自然语言处理（NLP）模型的漏洞。现有生成对抗样本的技术通常由确定性的层次规则驱动，这些规则对最优对抗样本毫不关心，通常导致对抗样本在变化幅度和攻击成功之间存在次优平衡。在此研究中，我们提出了两种算法，可逆跳动攻击（RJA）和Metropolis-Hasting修改缩减（MMR），用于生成高度有效的对抗示例并分别改善示例的不可察觉性。RJA利用新颖的随机化机制来扩大搜索空间，有效适应对抗样本中的多个扰动词汇。利用生成的对抗示例，MMR应用Metropolis-Hasting采样器以增强对抗示例的不可察觉性。

    arXiv:2403.14731v1 Announce Type: cross  Abstract: Recent studies on adversarial examples expose vulnerabilities of natural language processing (NLP) models. Existing techniques for generating adversarial examples are typically driven by deterministic hierarchical rules that are agnostic to the optimal adversarial examples, a strategy that often results in adversarial samples with a suboptimal balance between magnitudes of changes and attack successes. To this end, in this research we propose two algorithms, Reversible Jump Attack (RJA) and Metropolis-Hasting Modification Reduction (MMR), to generate highly effective adversarial examples and to improve the imperceptibility of the examples, respectively. RJA utilizes a novel randomization mechanism to enlarge the search space and efficiently adapts to a number of perturbed words for adversarial examples. With these generated adversarial examples, MMR applies the Metropolis-Hasting sampler to enhance the imperceptibility of adversarial e
    
[^100]: Auto-Train-Once：从零开始指导的控制器网络自动网络剪枝

    Auto-Train-Once: Controller Network Guided Automatic Network Pruning from Scratch

    [https://arxiv.org/abs/2403.14729](https://arxiv.org/abs/2403.14729)

    提出了Auto-Train-Once（ATO）网络剪枝算法，利用控制器网络自动降低DNN的计算和存储成本，并通过新颖的随机梯度算法增强协调性。

    

    现有的深度神经网络（DNN）剪枝技术通常涉及复杂的多步骤过程，需要领域专业知识，使其普遍采用具有挑战性。为了解决这一限制，提出了一次训练（OTO）和OTOv2，它们通过直接训练和压缩通用DNN来消除额外的微调步骤。然而，优化器的静态设计（在OTO中）可能导致局部最优解的收敛问题。本文提出了Auto-Train-Once（ATO），一种创新的网络剪枝算法，旨在自动减少DNN的计算和存储成本。在模型训练阶段，我们的方法不仅训练目标模型，还利用控制器网络作为架构生成器来引导目标模型权重的学习。此外，我们还开发了一种新颖的随机梯度算法，以增强协调性。

    arXiv:2403.14729v1 Announce Type: cross  Abstract: Current techniques for deep neural network (DNN) pruning often involve intricate multi-step processes that require domain-specific expertise, making their widespread adoption challenging. To address the limitation, the Only-Train-Once (OTO) and OTOv2 are proposed to eliminate the need for additional fine-tuning steps by directly training and compressing a general DNN from scratch. Nevertheless, the static design of optimizers (in OTO) can lead to convergence issues of local optima. In this paper, we proposed the Auto-Train-Once (ATO), an innovative network pruning algorithm designed to automatically reduce the computational and storage costs of DNNs. During the model training phase, our approach not only trains the target model but also leverages a controller network as an architecture generator to guide the learning of target model weights. Furthermore, we developed a novel stochastic gradient algorithm that enhances the coordination 
    
[^101]: 大型语言模型中的受保护群体偏见和刻板印象

    Protected group bias and stereotypes in Large Language Models

    [https://arxiv.org/abs/2403.14727](https://arxiv.org/abs/2403.14727)

    该研究调查了大型语言模型在伦理和公平领域中的行为，发现模型不仅反映了社会偏见，还似乎放大了这些偏见。

    

    随着现代大型语言模型在各种领域中打破许多最新技术基准，本文调查了它们在伦理和公平领域的行为，重点关注受保护群体偏见。我们进行了两部分研究：首先，我们征集了描述来自不同受保护群体（包括性别、性取向、宗教和种族）个人职业的句子延续；其次，我们让模型生成关于拥有不同类型职业的个人的故事。我们收集了一款公开可用的大型语言模型生成的 >10k 个句子延续，受到人类标注。我们发现模型在被边缘化群体中存在偏见，尤其在性别和性取向领域，以及在模型生成中存在西方偏见。模型不仅反映了社会偏见，还似乎放大了这些偏见。该模型对于与边缘化群体相关的查询回复过于谨慎，提供了

    arXiv:2403.14727v1 Announce Type: cross  Abstract: As modern Large Language Models (LLMs) shatter many state-of-the-art benchmarks in a variety of domains, this paper investigates their behavior in the domains of ethics and fairness, focusing on protected group bias. We conduct a two-part study: first, we solicit sentence continuations describing the occupations of individuals from different protected groups, including gender, sexuality, religion, and race. Second, we have the model generate stories about individuals who hold different types of occupations. We collect >10k sentence completions made by a publicly available LLM, which we subject to human annotation. We find bias across minoritized groups, but in particular in the domains of gender and sexuality, as well as Western bias, in model generations. The model not only reflects societal biases, but appears to amplify them. The model is additionally overly cautious in replies to queries relating to minoritized groups, providing re
    
[^102]: Jailbreaking的最佳解决方案是通过定义

    Jailbreaking is Best Solved by Definition

    [https://arxiv.org/abs/2403.14725](https://arxiv.org/abs/2403.14725)

    语言模型中"越狱"攻击的关键是通过定义好的不安全响应来进行防御，而不是依赖于执行策略。

    

    语言模型上"越狱"攻击的增多引发了大量防御工作，旨在防止产生不良回应。在这项工作中，我们批判性地审视了防御管道的两个阶段：（i）定义何为不安全输出，和（ii）通过输入处理或微调等方法来执行该定义。我们严重怀疑现有的执行机制的有效性，通过展示它们即使对于简单的不安全输出定义--包含单词"purple"的输出也无法防御。相比之下，对输出进行后处理对于这样的定义是完全健壮的。基于我们的结果，我们提出我们的观点，即在防御越狱攻击中真正的挑战在于得到一个良好的不安全响应定义：没有良好的定义，任何执行策略都无法成功，但有了良好的定义，输出处理已经作为一个强大的基线。

    arXiv:2403.14725v1 Announce Type: cross  Abstract: The rise of "jailbreak" attacks on language models has led to a flurry of defenses aimed at preventing the output of undesirable responses. In this work, we critically examine the two stages of the defense pipeline: (i) the definition of what constitutes unsafe outputs, and (ii) the enforcement of the definition via methods such as input processing or fine-tuning. We cast severe doubt on the efficacy of existing enforcement mechanisms by showing that they fail to defend even for a simple definition of unsafe outputs--outputs that contain the word "purple". In contrast, post-processing outputs is perfectly robust for such a definition. Drawing on our results, we present our position that the real challenge in defending jailbreaks lies in obtaining a good definition of unsafe responses: without a good definition, no enforcement strategy can succeed, but with a good definition, output processing already serves as a robust baseline albeit 
    
[^103]: 隐私的六个层次：金融合成数据的框架

    Six Levels of Privacy: A Framework for Financial Synthetic Data

    [https://arxiv.org/abs/2403.14724](https://arxiv.org/abs/2403.14724)

    该论文介绍了一种用于金融合成数据的“隐私层次”层级，有助于评估隐私保护程度和分类生成方法。

    

    合成数据在金融应用中变得越来越重要。除了它提供的好处，如改进金融建模和更好的测试程序，它也存在着隐私风险。这些数据可能源自客户信息、商业信息或其他必须受到保护的专有来源。虽然生成合成数据的过程在一定程度上有助于掩盖原始数据，但很难评估隐私保护的程度。因此，我们引入了一组有用于分类合成数据生成方法和逐渐改进的保护措施的"隐私层次"的等级。尽管这六个级别是在金融应用的背景下设计的，但它们在其他行业中也可能适用。我们的论文包括：对金融合成数据的简要概述，它如何被使用，如何评估其价值，隐私风险等。

    arXiv:2403.14724v1 Announce Type: cross  Abstract: Synthetic Data is increasingly important in financial applications. In addition to the benefits it provides, such as improved financial modeling and better testing procedures, it poses privacy risks as well. Such data may arise from client information, business information, or other proprietary sources that must be protected. Even though the process by which Synthetic Data is generated serves to obscure the original data to some degree, the extent to which privacy is preserved is hard to assess. Accordingly, we introduce a hierarchy of ``levels'' of privacy that are useful for categorizing Synthetic Data generation methods and the progressively improved protections they offer. While the six levels were devised in the context of financial applications, they may also be appropriate for other industries as well. Our paper includes: A brief overview of Financial Synthetic Data, how it can be used, how its value can be assessed, privacy ris
    
[^104]: 使用聚焦技术抵御间接提示注入攻击

    Defending Against Indirect Prompt Injection Attacks With Spotlighting

    [https://arxiv.org/abs/2403.14720](https://arxiv.org/abs/2403.14720)

    引入了聚焦技术，一种提示工程技术，用于改进大型语言模型在处理多个输入源时的能力，通过提供可靠的输入来源信号来防御间接提示注入攻击。

    

    大型语言模型(LLMs)虽然强大，却是建立和训练用于处理单个文本输入的。在常见应用中，可以通过将多个输入连接在一起形成单个文本流来进行处理。然而，LLM无法区分提示的哪些部分属于不同的输入源。间接提示注入攻击利用这一漏洞，将对手指令嵌入到与用户命令一起处理的不受信任数据中。通常情况下，LLM会误将对手指令作为要遵循的用户指令，从而在整个系统中创建安全漏洞。我们引入了聚焦技术，这是一种用于改进LLMs区分多个输入源能力的提示工程技术系列。关键的见解是利用输入的变换提供其来源的可靠连续信号。我们将聚焦技术作为一种防御手段进行评估。

    arXiv:2403.14720v1 Announce Type: cross  Abstract: Large Language Models (LLMs), while powerful, are built and trained to process a single text input. In common applications, multiple inputs can be processed by concatenating them together into a single stream of text. However, the LLM is unable to distinguish which sections of prompt belong to various input sources. Indirect prompt injection attacks take advantage of this vulnerability by embedding adversarial instructions into untrusted data being processed alongside user commands. Often, the LLM will mistake the adversarial instructions as user commands to be followed, creating a security vulnerability in the larger system. We introduce spotlighting, a family of prompt engineering techniques that can be used to improve LLMs' ability to distinguish among multiple sources of input. The key insight is to utilize transformations of an input to provide a reliable and continuous signal of its provenance. We evaluate spotlighting as a defen
    
[^105]: 使用色彩感知替换绕过LLM水印

    Bypassing LLM Watermarks with Color-Aware Substitutions

    [https://arxiv.org/abs/2403.14719](https://arxiv.org/abs/2403.14719)

    提出了第一种“色彩感知”攻击方法——基于自我颜色测试的替换（SCTS），成功地规避了LLM水印检测。

    

    提出了一种水印技术，用于识别传播的文本是人类生成还是大型语言模型（LLM）生成的。现有攻击方法无法规避长文本段落的检测，为此，我们提出了第一种“色彩感知”攻击方法——基于自我颜色测试的替换（SCTS）。SCTS通过引导带有水印的LLM获取颜色信息，并比较输出标记的频率，从而确定标记的颜色，并用非绿色标记替换绿色标记。在实验证明，SCTS成功地规避了水印检测，且所需的编辑次数比相关研究要少。

    arXiv:2403.14719v1 Announce Type: cross  Abstract: Watermarking approaches are proposed to identify if text being circulated is human or large language model (LLM) generated. The state-of-the-art watermarking strategy of Kirchenbauer et al. (2023a) biases the LLM to generate specific (``green'') tokens. However, determining the robustness of this watermarking method is an open problem. Existing attack methods fail to evade detection for longer text segments. We overcome this limitation, and propose {\em Self Color Testing-based Substitution (SCTS)}, the first ``color-aware'' attack. SCTS obtains color information by strategically prompting the watermarked LLM and comparing output tokens frequencies. It uses this information to determine token colors, and substitutes green tokens with non-green ones. In our experiments, SCTS successfully evades watermark detection using fewer number of edits than related work. Additionally, we show both theoretically and empirically that SCTS can remove
    
[^106]: FedSR：用于物联网系统中非独立分布问题的半分散式联邦学习算法

    FedSR: A Semi-Decentralized Federated Learning Algorithm for Non-IIDness in IoT System

    [https://arxiv.org/abs/2403.14718](https://arxiv.org/abs/2403.14718)

    FedSR提出了一种半分散式的云-边缘-设备分层联邦学习框架，旨在解决在物联网系统中出现的数据分布不均和通信资源有限的问题。

    

    在工业物联网中，每天都会产生大量数据。由于隐私和安全问题，难以将所有这些数据汇集在一起训练深度学习模型，因此联邦学习，一种保护数据隐私的分布式机器学习范式在物联网中被广泛应用。然而，在实际的联邦学习中，设备之间的数据分布通常存在较大差异，数据的异构性会降低模型的性能。此外，物联网中的联邦学习通常涉及大量设备参与训练，云服务器的通信资源有限成为训练的瓶颈。为了解决上述问题，本文将集中式联邦学习与分散式联邦学习相结合，设计了一个半分散式的云-边缘-设备分层联邦学习框架，可以缓解这些问题。

    arXiv:2403.14718v1 Announce Type: new  Abstract: In the Industrial Internet of Things (IoT), a large amount of data will be generated every day. Due to privacy and security issues, it is difficult to collect all these data together to train deep learning models, thus the federated learning, a distributed machine learning paradigm that protects data privacy, has been widely used in IoT. However, in practical federated learning, the data distributions usually have large differences across devices, and the heterogeneity of data will deteriorate the performance of the model. Moreover, federated learning in IoT usually has a large number of devices involved in training, and the limited communication resource of cloud servers become a bottleneck for training. To address the above issues, in this paper, we combine centralized federated learning with decentralized federated learning to design a semi-decentralized cloud-edge-device hierarchical federated learning framework, which can mitigate t
    
[^107]: 基于1比特梯度编码的存在滞后者的分布式学习

    Distributed Learning based on 1-Bit Gradient Coding in the Presence of Stragglers

    [https://arxiv.org/abs/2403.14716](https://arxiv.org/abs/2403.14716)

    提出了一种基于1比特梯度编码的新型分布式学习方法，能够在存在滞后者的情况下降低通信负担，并在凸损失函数和非凸损失函数下具有收敛保证，实验证明其性能优于基准方法。

    

    本文考虑了在存在滞后者的情况下的分布式学习（DL）问题。针对这个问题，研究了基于梯度编码的DL方法，这些方法通过冗余地将训练数据分发给工作节点，以确保在一些工作节点是滞后者时收敛。然而，这些方法要求工作节点在学习过程中传输实值向量，这导致了非常高的通信负担。为了克服这一缺点，我们提出了一种基于1比特梯度编码（1-bit GCDL）的新型DL方法，其中工作节点传输从本地计算的梯度编码而成的1比特数据，以减少通信开销。我们在理论上为所提出的方法在凸损失函数和非凸损失函数下提供了收敛保证。实验证明，1比特GC-DL优于基准方法，其在存在滞后者的情况下实现更好的学习性能。

    arXiv:2403.14716v1 Announce Type: new  Abstract: This paper considers the problem of distributed learning (DL) in the presence of stragglers. For this problem, DL methods based on gradient coding have been widely investigated, which redundantly distribute the training data to the workers to guarantee convergence when some workers are stragglers. However, these methods require the workers to transmit real-valued vectors during the process of learning, which induces very high communication burden. To overcome this drawback, we propose a novel DL method based on 1-bit gradient coding (1-bit GCDL), where 1-bit data encoded from the locally computed gradients are transmitted by the workers to reduce the communication overhead. We theoretically provide the convergence guarantees of the proposed method for both the convex loss functions and nonconvex loss functions. It is shown empirically that 1-bit GC-DL outperforms the baseline methods, which attains better learning performance under the s
    
[^108]: 理解为何标签平滑会降低选择性分类的效果以及如何解决这个问题

    Understanding Why Label Smoothing Degrades Selective Classification and How to Fix It

    [https://arxiv.org/abs/2403.14715](https://arxiv.org/abs/2403.14715)

    LS方法在深度神经网络分类器训练中的标签平滑效果被发现会负面影响选择性分类，通过影响模型预测不确定性，此研究阐明了这一现象。

    

    标签平滑（LS）是一种流行的深度神经网络分类器训练的正则化方法，因为它在提高测试准确性方面效果显著，并且实现简单。"硬"的one-hot标签通过将概率质量均匀分配给其他类别来进行"平滑化"，从而减少过度拟合。在这项工作中，我们揭示了LS如何负面影响选择性分类（SC）- 其目标是利用模型的预测不确定性来拒绝错误分类。我们首先在一系列任务和架构中从经验上证明LS会导致SC的一致性降级。然后，我们通过分析logit级别的梯度来解释这一点，表明LS通过在错误概率低时更加正则化最大logit，而在错误概率高时更少正则化，加剧了过度自信和低自信。这阐明了以前报道的强分类器在SC中性能不佳的实验结果。

    arXiv:2403.14715v1 Announce Type: cross  Abstract: Label smoothing (LS) is a popular regularisation method for training deep neural network classifiers due to its effectiveness in improving test accuracy and its simplicity in implementation. "Hard" one-hot labels are "smoothed" by uniformly distributing probability mass to other classes, reducing overfitting. In this work, we reveal that LS negatively affects selective classification (SC) - where the aim is to reject misclassifications using a model's predictive uncertainty. We first demonstrate empirically across a range of tasks and architectures that LS leads to a consistent degradation in SC. We then explain this by analysing logit-level gradients, showing that LS exacerbates overconfidence and underconfidence by regularising the max logit more when the probability of error is low, and less when the probability of error is high. This elucidates previously reported experimental results where strong classifiers underperform in SC. We
    
[^109]: 编译器生成的大型语言模型反馈

    Compiler generated feedback for Large Language Models

    [https://arxiv.org/abs/2403.14714](https://arxiv.org/abs/2403.14714)

    该研究提出了一种利用大型语言模型进行编译器优化反馈的新范式，能够在优化LLVM汇编代码大小方面取得额外改进。

    

    我们引入了一种新颖的编译器优化范式，由大型语言模型提供编译器反馈，以优化LLVM汇编代码的大小。该模型以未优化的LLVM IR作为输入，生成优化的IR、最佳优化传递以及未优化和优化IR的指令计数。然后我们使用生成的优化传递编译输入，并评估预测的指令计数是否正确，生成的IR是否可编译，并且与编译后的代码相对应。我们将这些反馈发送回LLM，让其再次优化代码。该方法比原模型的-Oz额外提升了0.53%。尽管添加更多反馈信息似乎直观，但简单的抽样技术在采样10次或更多次时能够实现更高的性能。

    arXiv:2403.14714v1 Announce Type: cross  Abstract: We introduce a novel paradigm in compiler optimization powered by Large Language Models with compiler feedback to optimize the code size of LLVM assembly. The model takes unoptimized LLVM IR as input and produces optimized IR, the best optimization passes, and instruction counts of both unoptimized and optimized IRs. Then we compile the input with generated optimization passes and evaluate if the predicted instruction count is correct, generated IR is compilable, and corresponds to compiled code. We provide this feedback back to LLM and give it another chance to optimize code. This approach adds an extra 0.53% improvement over -Oz to the original model. Even though, adding more information with feedback seems intuitive, simple sampling techniques achieve much higher performance given 10 or more samples.
    
[^110]: 在未观测混杂因素下审计公平性

    Auditing Fairness under Unobserved Confounding

    [https://arxiv.org/abs/2403.14713](https://arxiv.org/abs/2403.14713)

    在未观测混杂因素的情况下，本文展示了即使在放宽或甚至在排除所有相关风险因素被观测到的假设的情况下，仍然可以给出对高风险个体分配率的信息丰富的界限。

    

    决策系统中的一个基本问题是跨越人口统计线存在不公平性。然而，不公平性可能难以量化，特别是如果我们对公平性的理解依赖于难以衡量的风险等观念（例如，对于那些没有其治疗就会死亡的人平等获得治疗）。审计这种不公平性需要准确测量个体风险，而在未观测混杂的现实环境中，难以估计。在这些未观测到的因素“解释”明显差异的情况下，我们可能低估或高估不公平性。在本文中，我们展示了即使在放宽或（令人惊讶地）甚至在排除所有相关风险因素被观测到的假设的情况下，仍然可以对高风险个体的分配率给出信息丰富的界限。我们利用了在许多实际环境中（例如引入新型治疗）我们拥有在任何分配之前的数据的事实。

    arXiv:2403.14713v1 Announce Type: cross  Abstract: A fundamental problem in decision-making systems is the presence of inequity across demographic lines. However, inequity can be difficult to quantify, particularly if our notion of equity relies on hard-to-measure notions like risk (e.g., equal access to treatment for those who would die without it). Auditing such inequity requires accurate measurements of individual risk, which is difficult to estimate in the realistic setting of unobserved confounding. In the case that these unobservables "explain" an apparent disparity, we may understate or overstate inequity. In this paper, we show that one can still give informative bounds on allocation rates among high-risk individuals, even while relaxing or (surprisingly) even when eliminating the assumption that all relevant risk factors are observed. We utilize the fact that in many real-world settings (e.g., the introduction of a novel treatment) we have data from a period prior to any alloc
    
[^111]: 人在环AI用于作弊环检测

    Human-in-the-Loop AI for Cheating Ring Detection

    [https://arxiv.org/abs/2403.14711](https://arxiv.org/abs/2403.14711)

    本文介绍了一种人在环AI作弊环检测系统，通过设计原则、评估方法及符合负责任AI标准，实现了检测作弊者的目标。

    

    近年来，由于在线考试的易获取性，在线考试变得越来越受欢迎。然而，人们对在线考试的安全性提出了一些担忧，特别是在专业作弊服务帮助恶意考生通过考试的背景下，形成了所谓的“作弊环”。本文介绍了一种人在环AI作弊环检测系统，旨在检测和阻止这些作弊环。我们概述了这种人在环AI系统的基本逻辑，探讨了其设计原则，旨在实现检测作弊者的目标。此外，我们阐述了用于评估其性能和公平性的方法，旨在减轻与AI系统相关的意外风险。系统的设计和开发遵循了负责任的AI（RAI）标准，确保在整个开发过程中整合了伦理考虑。

    arXiv:2403.14711v1 Announce Type: cross  Abstract: Online exams have become popular in recent years due to their accessibility. However, some concerns have been raised about the security of the online exams, particularly in the context of professional cheating services aiding malicious test takers in passing exams, forming so-called "cheating rings". In this paper, we introduce a human-in-the-loop AI cheating ring detection system designed to detect and deter these cheating rings. We outline the underlying logic of this human-in-the-loop AI system, exploring its design principles tailored to achieve its objectives of detecting cheaters. Moreover, we illustrate the methodologies used to evaluate its performance and fairness, aiming to mitigate the unintended risks associated with the AI system. The design and development of the system adhere to Responsible AI (RAI) standards, ensuring that ethical considerations are integrated throughout the entire development process.
    
[^112]: ClimateQ&A：弥合气候科学家与普通大众之间的差距

    ClimateQ&A: Bridging the gap between climate scientists and the general public

    [https://arxiv.org/abs/2403.14709](https://arxiv.org/abs/2403.14709)

    通过分析ClimateQ&A平台上提出的问题，研究公众对气候变化和生物多样性损失的看法，为使自然科学更易接近和收集分析问题提供新的视角。

    

    本研究论文通过分析向ClimateQ&A平台提出的问题，调查了公众对气候变化和生物多样性丧失的看法。ClimateQ&A是一个会话代理，利用LLMs来回应基于来自IPCC和IPBES报告的超过14,000页科学文献的查询。该工具于2023年3月上线，已搜集了来自法国受众主要提出的超过30,000个问题。其聊天机器人界面允许自由提出与自然相关的问题*. 尽管其主要目标是使自然科学更易接近，但它也允许收集和分析问题及其主题。与涉及封闭问题的传统调查不同，这种新颖方法为个体关于自然的质询提供了新的视角。在对3,425个问题的样本运行NLP聚类算法后，我们发现有显著的25.8%的问题询问气候变化和生物多样性丧失将如何影响环境。

    arXiv:2403.14709v1 Announce Type: cross  Abstract: This research paper investigates public views on climate change and biodiversity loss by analyzing questions asked to the ClimateQ&A platform. ClimateQ&A is a conversational agent that uses LLMs to respond to queries based on over 14,000 pages of scientific literature from the IPCC and IPBES reports. Launched online in March 2023, the tool has gathered over 30,000 questions, mainly from a French audience. Its chatbot interface allows for the free formulation of questions related to nature*. While its main goal is to make nature science more accessible, it also allows for the collection and analysis of questions and their themes. Unlike traditional surveys involving closed questions, this novel method offers a fresh perspective on individual interrogations about nature. Running NLP clustering algorithms on a sample of 3,425 questions, we find that a significant 25.8% inquire about how climate change and biodiversity loss will affect the
    
[^113]: 针对金融时间序列预测的链式神经架构搜索

    Chain-structured neural architecture search for financial time series forecasting

    [https://arxiv.org/abs/2403.14695](https://arxiv.org/abs/2403.14695)

    在金融时间序列预测领域，比较了贝叶斯优化、超带方法和强化学习等神经架构搜索策略。

    

    我们在链式搜索空间上比较了三种流行的神经架构搜索策略：贝叶斯优化、超带方法和强化学习，这在金融时间序列预测的背景下进行了研究。

    arXiv:2403.14695v1 Announce Type: cross  Abstract: We compare three popular neural architecture search strategies on chain-structured search spaces: Bayesian optimization, the hyperband method, and reinforcement learning in the context of financial time series forecasting.
    
[^114]: 将图注意机制融入基于深度强化学习的几何问题求解

    Incorporating Graph Attention Mechanism into Geometric Problem Solving Based on Deep Reinforcement Learning

    [https://arxiv.org/abs/2403.14690](https://arxiv.org/abs/2403.14690)

    提出了基于深度强化学习的图注意机制，用于自动且高效地添加几何问题中的辅助组件

    

    在在线教育背景下，设计一个自动求解几何问题的求解器被认为是迈向通用数学人工智能的关键一步，其依托自然语言理解和传统逻辑推理。在大多数情况下，问题的解决是通过添加辅助组件如线条或点来进行的。然而，由于在需要做出关键决策时选择合适的辅助组件的复杂性，自动添加辅助组件具有挑战性。目前的最新性能是通过从类别库中穷举所有可能的策略，以识别具有最大可能性的策略来实现的。然而，为了在效率方面做出妥协，必须采用广泛的策略搜索。为了自动且高效地添加辅助组件，我们提出了基于语言模型（如BERT）的深度强化学习框架。

    arXiv:2403.14690v1 Announce Type: cross  Abstract: In the context of online education, designing an automatic solver for geometric problems has been considered a crucial step towards general math Artificial Intelligence (AI), empowered by natural language understanding and traditional logical inference. In most instances, problems are addressed by adding auxiliary components such as lines or points. However, adding auxiliary components automatically is challenging due to the complexity in selecting suitable auxiliary components especially when pivotal decisions have to be made. The state-of-the-art performance has been achieved by exhausting all possible strategies from the category library to identify the one with the maximum likelihood. However, an extensive strategy search have to be applied to trade accuracy for ef-ficiency. To add auxiliary components automatically and efficiently, we present deep reinforcement learning framework based on the language model, such as BERT. We first
    
[^115]: 发展和部署教育领域人工智能产业标准：挑战、策略和未来方向

    Developing and Deploying Industry Standards for Artificial Intelligence in Education (AIED): Challenges, Strategies, and Future Directions

    [https://arxiv.org/abs/2403.14689](https://arxiv.org/abs/2403.14689)

    教育领域人工智能的发展需要制定和实施产业标准，以解决互操作性、可扩展性和道德治理等挑战。

    

    人工智能在教育领域的应用承诺通过提供个性化学习体验、自动化行政和教学任务以及降低内容创建成本来革新教育实践。然而，在开发和部署教育领域人工智能解决方案方面缺乏标准化实践导致生态系统分散，给互操作性、可扩展性和道德治理带来挑战。本文旨在解决在教育领域人工智能发展和实施产业标准的紧迫需求，提供对当前局势、挑战和克服这些障碍的策略方法的全面分析。我们开始通过研究AIED在不同教育环境中的各种应用，并确定缺乏标准化的关键领域，包括系统互操作性、本体映射、数据集成、评估和道德治理。

    arXiv:2403.14689v1 Announce Type: cross  Abstract: The adoption of Artificial Intelligence in Education (AIED) holds the promise of revolutionizing educational practices by offering personalized learning experiences, automating administrative and pedagogical tasks, and reducing the cost of content creation. However, the lack of standardized practices in the development and deployment of AIED solutions has led to fragmented ecosystems, which presents challenges in interoperability, scalability, and ethical governance. This article aims to address the critical need to develop and implement industry standards in AIED, offering a comprehensive analysis of the current landscape, challenges, and strategic approaches to overcome these obstacles. We begin by examining the various applications of AIED in various educational settings and identify key areas lacking in standardization, including system interoperability, ontology mapping, data integration, evaluation, and ethical governance. Then, 
    
[^116]: 通过矩阵分解实现无监督特征选择的核对齐方法

    Kernel Alignment for Unsupervised Feature Selection via Matrix Factorization

    [https://arxiv.org/abs/2403.14688](https://arxiv.org/abs/2403.14688)

    该论文提出了一种通过整合核函数和核对齐实现无监督特征选择的方法，并进一步提出了基于多核学习的方法。

    

    通过消除无关和冗余特征，特征选择旨在找到原始特征的良好表示。随着无标记数据的普及，无监督特征选择已被证明在缓解所谓的维度灾难中是有效的。大多数现有基于矩阵分解的无监督特征选择方法建立在子空间学习之上，但在捕获特征之间的非线性结构信息方面存在局限性。众所周知，核技术可以捕获非线性结构信息。在本文中，我们通过集成核函数和核对齐构建了一个模型，这等效地可以被表征为一个矩阵分解问题。然而，这种扩展引发了另一个问题：算法性能严重依赖于核的选择，而这通常是未知的。因此，我们进一步提出了一种基于多核学习的方法。

    arXiv:2403.14688v1 Announce Type: new  Abstract: By removing irrelevant and redundant features, feature selection aims to find a good representation of the original features. With the prevalence of unlabeled data, unsupervised feature selection has been proven effective in alleviating the so-called curse of dimensionality. Most existing matrix factorization-based unsupervised feature selection methods are built upon subspace learning, but they have limitations in capturing nonlinear structural information among features. It is well-known that kernel techniques can capture nonlinear structural information. In this paper, we construct a model by integrating kernel functions and kernel alignment, which can be equivalently characterized as a matrix factorization problem. However, such an extension raises another issue: the algorithm performance heavily depends on the choice of kernel, which is often unknown a priori. Therefore, we further propose a multiple kernel-based learning method. By
    
[^117]: 在健康数据集上缺失值填补技术的性能

    On the Performance of Imputation Techniques for Missing Values on Healthcare Datasets

    [https://arxiv.org/abs/2403.14687](https://arxiv.org/abs/2403.14687)

    本研究比较了七种填补技术在健康数据集上的性能，结果显示...

    

    缺失值是真实世界数据集的一种常见特征，尤其是在健康数据中。本研究旨在比较七种填补技术（均值填补、中位数填补、最近观察值填补、K-最近邻填补、插值填补、Missforest填补和链式方程多重填补）在三个健康数据集上的性能。将数据集引入了不同百分比的缺失值（10\%、15\%、20\%和25\%），并使用填补技术对这些缺失值进行填补。通过均方根误差（RMSE）和平均绝对误差（MAE）对其性能进行评估。结果表明Mi

    arXiv:2403.14687v1 Announce Type: cross  Abstract: Missing values or data is one popular characteristic of real-world datasets, especially healthcare data. This could be frustrating when using machine learning algorithms on such datasets, simply because most machine learning models perform poorly in the presence of missing values. The aim of this study is to compare the performance of seven imputation techniques, namely Mean imputation, Median Imputation, Last Observation carried Forward (LOCF) imputation, K-Nearest Neighbor (KNN) imputation, Interpolation imputation, Missforest imputation, and Multiple imputation by Chained Equations (MICE), on three healthcare datasets. Some percentage of missing values - 10\%, 15\%, 20\% and 25\% - were introduced into the dataset, and the imputation techniques were employed to impute these missing values. The comparison of their performance was evaluated by using root mean squared error (RMSE) and mean absolute error (MAE). The results show that Mi
    
[^118]: 周期性对数温度调度作为学习率调度器

    Cyclical Log Annealing as a Learning Rate Scheduler

    [https://arxiv.org/abs/2403.14685](https://arxiv.org/abs/2403.14685)

    该论文介绍了一种新的对数方法作为学习率调度器，通过更积极的重启模式，可能使得在在线凸优化框架上使用更贪婪的算法，实验结果表明它性能类似于余弦退火方案。

    

    学习率调度器是一组预定义的指令，用于在模型训练过程中改变搜索步长。本文介绍了一种新的对数方法，通过随机梯度下降对步长进行严格的重启。周期性对数温度调度更积极地实现了重启模式，或许可以允许在在线凸优化框架上使用更贪婪的算法。该算法在CIFAR-10图像数据集上进行了测试，似乎在大型变压器增强残差神经网络上的余弦退火方案表现类似。未来的实验将涉及在生成对抗网络中测试调度器，并通过更多实验找到调度器的最佳参数。

    arXiv:2403.14685v1 Announce Type: new  Abstract: A learning rate scheduler is a predefined set of instructions for varying search stepsizes during model training processes. This paper introduces a new logarithmic method using harsh restarting of step sizes through stochastic gradient descent. Cyclical log annealing implements the restart pattern more aggressively to maybe allow the usage of more greedy algorithms on the online convex optimization framework. The algorithm was tested on the CIFAR-10 image datasets, and seemed to perform analogously with cosine annealing on large transformer-enhanced residual neural networks. Future experiments would involve testing the scheduler in generative adversarial networks and finding the best parameters for the scheduler with more experiments.
    
[^119]: FOCIL: 通过训练随机修剪稀疏专家进行在线类递增学习的微调和冻结

    FOCIL: Finetune-and-Freeze for Online Class Incremental Learning by Training Randomly Pruned Sparse Experts

    [https://arxiv.org/abs/2403.14684](https://arxiv.org/abs/2403.14684)

    FOCIL通过训练随机修剪稀疏子网络实现在线持续类递增学习，在避免存储重放数据的同时有效防止遗忘。

    

    在线持续学习中的类递增学习（CIL）旨在从数据流中获取一系列新类的知识，仅使用每个数据点进行一次训练。与离线模式相比，这更加现实，离线模式假定所有新类的数据已经准备好。当前的在线CIL方法存储先前数据的子集，这会在内存和计算方面造成沉重的开销，还存在隐私问题。本文提出了一种名为FOCIL的新型在线CIL方法。它通过训练随机修剪稀疏子网络不断微调主体系结构，然后冻结训练连接以防止遗忘。FOCIL还自适应确定每个任务的稀疏度级别和学习速率，并确保（几乎）零遗忘跨所有任务，且不存储任何重放数据。

    arXiv:2403.14684v1 Announce Type: cross  Abstract: Class incremental learning (CIL) in an online continual learning setting strives to acquire knowledge on a series of novel classes from a data stream, using each data point only once for training. This is more realistic compared to offline modes, where it is assumed that all data from novel class(es) is readily available. Current online CIL approaches store a subset of the previous data which creates heavy overhead costs in terms of both memory and computation, as well as privacy issues. In this paper, we propose a new online CIL approach called FOCIL. It fine-tunes the main architecture continually by training a randomly pruned sparse subnetwork for each task. Then, it freezes the trained connections to prevent forgetting. FOCIL also determines the sparsity level and learning rate per task adaptively and ensures (almost) zero forgetting across all tasks without storing any replay data. Experimental results on 10-Task CIFAR100, 20-Task
    
[^120]: 一项道义使命：对大型语言模型持续超对齐的需求

    A Moral Imperative: The Need for Continual Superalignment of Large Language Models

    [https://arxiv.org/abs/2403.14683](https://arxiv.org/abs/2403.14683)

    实现终身超对齐需要对当前大型语言模型架构进行重大变革，以解决其在理解和适应动态人类道德和不断发展的全球情景方面的局限性。

    

    这篇论文探讨了在人工智能系统中实现终身超对齐的挑战，尤其是在大型语言模型（LLMs）中。超对齐是一个理论框架，旨在确保超智能人工智能系统符合人类的价值观和目标。尽管其展望令人振奋，我们认为实现超对齐需要对当前LLM架构进行重大变革，因为它们在理解和适应人类道德的动态性和不断发展的全球情景方面固有的局限性。我们剖析了将不断变化的人类价值观谱系编码到LLMs中的挑战，突出了静态人工智能模型与人类社会动态性之间的差异。为了说明这些挑战，我们分析了两个不同的示例：一个展示了人类价值观的定性转变，另一个呈现了可量化的变化。通过这些示例，我们说明…

    arXiv:2403.14683v1 Announce Type: cross  Abstract: This paper examines the challenges associated with achieving life-long superalignment in AI systems, particularly large language models (LLMs). Superalignment is a theoretical framework that aspires to ensure that superintelligent AI systems act in accordance with human values and goals. Despite its promising vision, we argue that achieving superalignment requires substantial changes in the current LLM architectures due to their inherent limitations in comprehending and adapting to the dynamic nature of these human ethics and evolving global scenarios. We dissect the challenges of encoding an ever-changing spectrum of human values into LLMs, highlighting the discrepancies between static AI models and the dynamic nature of human societies. To illustrate these challenges, we analyze two distinct examples: one demonstrates a qualitative shift in human values, while the other presents a quantifiable change. Through these examples, we illus
    
[^121]: 使用时间关系知识的深度生成领域自适应方法用于跨用户活动识别

    Deep Generative Domain Adaptation with Temporal Relation Knowledge for Cross-User Activity Recognition

    [https://arxiv.org/abs/2403.14682](https://arxiv.org/abs/2403.14682)

    该研究引入了一种CVAE-USM方法，通过放松独立同分布假设和利用时间关系，有效地在不同用户之间对齐数据分布，从而改进活动识别。

    

    在人类活动识别（HAR）中，训练和测试数据是独立同分布（i.i.d.）的假设通常失败，特别是在跨用户场景中，其中数据分布存在显著差异。我们的研究引入了一个条件变分自动编码器与通用序列映射（CVAE-USM）方法，通过放松 i.i.d. 假设并利用时间关系来有效地对齐不同用户之间的数据分布，从而解决时间序列领域自适应在HAR中的独特挑战。

    arXiv:2403.14682v1 Announce Type: cross  Abstract: In human activity recognition (HAR), the assumption that training and testing data are independent and identically distributed (i.i.d.) often fails, particularly in cross-user scenarios where data distributions vary significantly. This discrepancy highlights the limitations of conventional domain adaptation methods in HAR, which typically overlook the inherent temporal relations in time-series data. To bridge this gap, our study introduces a Conditional Variational Autoencoder with Universal Sequence Mapping (CVAE-USM) approach, which addresses the unique challenges of time-series domain adaptation in HAR by relaxing the i.i.d. assumption and leveraging temporal relations to align data distributions effectively across different users. This method combines the strengths of Variational Autoencoder (VAE) and Universal Sequence Mapping (USM) to capture and utilize common temporal patterns between users for improved activity recognition. Ou
    
[^122]: 三阶段巩固的持续学习

    Continual Learning by Three-Phase Consolidation

    [https://arxiv.org/abs/2403.14679](https://arxiv.org/abs/2403.14679)

    通过三阶段巩固的持续学习方法，旨在解决类别不平衡问题，限制梯度校正避免遗忘少数类，并在复杂数据集上展示了其准确性和效率优势。

    

    TPC (Three-Phase Consolidation)被引入作为一种简单但有效的方法，用于在控制遗忘先前知识的同时持续学习新类别（和/或已知类别的实例）。每个经验（也称为任务）都通过具有不同规则和学习动态的三个阶段来学习，旨在消除由于类别不平衡而导致的类别偏差问题，并限制基于梯度的校正，以防止遗忘少数类。复杂数据集上的多个实验证明了它在准确性和效率上优于现有竞争方法的优势。由于其发布在持续学习的Avalanche开放框架上，本文展示的算法和所有结果均可以完全可复制。

    arXiv:2403.14679v1 Announce Type: new  Abstract: TPC (Three-Phase Consolidation) is here introduced as a simple but effective approach to continually learn new classes (and/or instances of known classes) while controlling forgetting of previous knowledge. Each experience (a.k.a. task) is learned in three phases characterized by different rules and learning dynamics, aimed at removing the class-bias problem (due to class unbalancing) and limiting gradient-based corrections to prevent forgetting of underrepresented classes. Several experiments on complex datasets demonstrate its accuracy and efficiency advantages over competitive existing approaches. The algorithm and all the results presented in this paper are fully reproducible thanks to its publication on the Avalanche open framework for continual learning.
    
[^123]: 面向安全关键应用的深度学习认证框架：采用固有安全设计和运行时错误检测

    Towards a Framework for Deep Learning Certification in Safety-Critical Applications Using Inherently Safe Design and Run-Time Error Detection

    [https://arxiv.org/abs/2403.14678](https://arxiv.org/abs/2403.14678)

    本研究构建了面向安全关键应用的深度学习认证框架，结合固有安全设计和运行时错误检测，以应对现实世界问题。

    

    尽管越来越多的应用程序采用基于深度学习的系统进行预测、决策或状态估计，几乎没有建立证书流程，使得这样的系统能够应用于安全关键应用。本研究考虑了在航空和其他安全关键领域中出现的现实世界问题，并研究了认证模型的需求。为此，我们调查了机器学习研究社区针对验证深度学习系统稳健性和可靠性的方法，并评估了这些方法对现实世界问题的适用性。然后，我们建立了一个基于（i）固有安全设计和（ii）运行时错误检测的深度学习认证新框架。通过使用航空案例，我们展示了深度学习模型如何通过使用恢复解耦变量。

    arXiv:2403.14678v1 Announce Type: new  Abstract: Although an ever-growing number of applications employ deep learning based systems for prediction, decision-making, or state estimation, almost no certification processes have been established that would allow such systems to be deployed in safety-critical applications. In this work we consider real-world problems arising in aviation and other safety-critical areas, and investigate their requirements for a certified model. To this end, we investigate methodologies from the machine learning research community aimed towards verifying robustness and reliability of deep learning systems, and evaluate these methodologies with regard to their applicability to real-world problems. Then, we establish a new framework towards deep learning certification based on (i) inherently safe design, and (ii) run-time error detection. Using a concrete use case from aviation, we show how deep learning models can recover disentangled variables through the use 
    
[^124]: 统一不确定性评估方法用于认知诊断模型

    Unified Uncertainty Estimation for Cognitive Diagnosis Models

    [https://arxiv.org/abs/2403.14676](https://arxiv.org/abs/2403.14676)

    提出了一种统一不确定性评估方法，适用于各种认知诊断模型，填补了对于具有交互功能参数的复杂模型的学术空白

    

    认知诊断模型已被广泛应用于不同领域，尤其是智能教育，用于测量用户对知识概念的熟练程度，基于此，用户可以获得个性化的指导。然而，由于模型和数据的联系薄弱，测量并不总是可靠，测量的不确定性也为决策提供了重要信息。然而，对于认知诊断中不确定性评估的研究落后于对认知诊断高级模型结构的研究。现有方法效率有限，并为具有交互功能参数（如基于深度学习的模型）的精密模型留下了一个学术空白。为解决这些问题，我们提出了一种适用于广泛认知诊断模型的统一不确定性评估方法。具体而言，基于估计认知诊断模型参数的后验分布的思想，我们首先提供一种u

    arXiv:2403.14676v1 Announce Type: cross  Abstract: Cognitive diagnosis models have been widely used in different areas, especially intelligent education, to measure users' proficiency levels on knowledge concepts, based on which users can get personalized instructions. As the measurement is not always reliable due to the weak links of the models and data, the uncertainty of measurement also offers important information for decisions. However, the research on the uncertainty estimation lags behind that on advanced model structures for cognitive diagnosis. Existing approaches have limited efficiency and leave an academic blank for sophisticated models which have interaction function parameters (e.g., deep learning-based models). To address these problems, we propose a unified uncertainty estimation approach for a wide range of cognitive diagnosis models. Specifically, based on the idea of estimating the posterior distributions of cognitive diagnosis model parameters, we first provide a u
    
[^125]: 了解过境缺口：南卡罗来纳州夏洛特市南端和田纳西州查塔努加市阿冯代尔的即需公共汽车服务及城市气候适应能力的比较研究

    Understanding the Transit Gap: A Comparative Study of On-Demand Bus Services and Urban Climate Resilience in South End, Charlotte, NC and Avondale, Chattanooga, TN

    [https://arxiv.org/abs/2403.14671](https://arxiv.org/abs/2403.14671)

    本研究揭示了城市设计在公共交通效率和减少碳排放方面的关键作用，指出城市布局对公共交通结果有重要影响，提出了针对不同城市设计元素的定制策略对于气候适应至关重要。

    

    城市设计在可持续性方面具有重要影响，特别是在公共交通效率和减少碳排放方面。本研究探讨了具有不同城市设计的两个社区：北卡罗来纳州夏洛特市南端，具有动态混合用途的城市设计模式；和田纳西州查塔努加市阿冯代尔，采用住宅郊区网格布局。通过使用TRANSIT-GYM工具，我们评估了在这些不同城市环境中增加公共汽车利用率对交通和CO2排放的影响。我们的结果突显了城市设计和规划在交通系统效率中的关键作用。在夏洛特市南端，混合用途设计导致更多的排放减少，表明城市布局可以显著影响公共交通结果。考虑到独特的城市设计元素的量身定制策略对于气候适应至关重要。值得注意的是，在南端，公共汽车利用率翻倍使日常排放减少了10.18％。

    arXiv:2403.14671v1 Announce Type: cross  Abstract: Urban design significantly impacts sustainability, particularly in the context of public transit efficiency and carbon emissions reduction. This study explores two neighborhoods with distinct urban designs: South End, Charlotte, NC, featuring a dynamic mixed-use urban design pattern, and Avondale, Chattanooga, TN, with a residential suburban grid layout. Using the TRANSIT-GYM tool, we assess the impact of increased bus utilization in these different urban settings on traffic and CO2 emissions. Our results highlight the critical role of urban design and planning in transit system efficiency. In South End, the mixed-use design led to more substantial emission reductions, indicating that urban layout can significantly influence public transit outcomes. Tailored strategies that consider the unique urban design elements are essential for climate resilience. Notably, doubling bus utilization decreased daily emissions by 10.18% in South End a
    
[^126]: 用大型语言模型预测学习表现：成人识字研究

    Predicting Learning Performance with Large Language Models: A Study in Adult Literacy

    [https://arxiv.org/abs/2403.14668](https://arxiv.org/abs/2403.14668)

    该研究使用大型语言模型GPT-4探讨了在ITS中预测成人识字计划学习表现的应用，并发现GPT-4在此方面具有竞争力的预测能力。

    

    arXiv:2403.14668v1 公告类别：跨领域 智能辅导系统（ITS）显著增强了成人识字培训，这是社会参与、就业机会和终身学习的关键因素。我们的研究探讨了高级AI模型（包括GPT-4等大型语言模型）在ITS中预测成人识字计划学习表现的应用。这项研究受到了LLMs基于其内在推理和计算能力预测学习表现的潜力的启发。通过使用ITS AutoTutor的阅读理解数据集，我们通过五折交叉验证技术评估了GPT-4与传统机器学习方法在预测学习表现方面的预测能力。我们的研究结果显示，GPT-4展现出与传统的机器学习方法（如贝叶斯知识跟踪、表现因素分析、稀疏因素分析）具有竞争力的预测能力。

    arXiv:2403.14668v1 Announce Type: cross  Abstract: Intelligent Tutoring Systems (ITSs) have significantly enhanced adult literacy training, a key factor for societal participation, employment opportunities, and lifelong learning. Our study investigates the application of advanced AI models, including Large Language Models (LLMs) like GPT-4, for predicting learning performance in adult literacy programs in ITSs. This research is motivated by the potential of LLMs to predict learning performance based on its inherent reasoning and computational capabilities. By using reading comprehension datasets from the ITS, AutoTutor, we evaluate the predictive capabilities of GPT-4 versus traditional machine learning methods in predicting learning performance through five-fold cross-validation techniques. Our findings show that the GPT-4 presents the competitive predictive abilities with traditional machine learning methods such as Bayesian Knowledge Tracing, Performance Factor Analysis, Sparse Fact
    
[^127]: SyllabusQA：一个课程逻辑问题回答数据集

    SyllabusQA: A Course Logistics Question Answering Dataset

    [https://arxiv.org/abs/2403.14666](https://arxiv.org/abs/2403.14666)

    SyllabusQA数据集是一个包含63个真实课程大纲的开源数据集，对36个专业涵盖5,078对多样化的开放式课程逻辑相关问题-答案对进行了详细收集，旨在评估答案事实性，多个强基线模型在该任务上表现出色，但仍存在与人类之间的显著差距。

    

    自动化教学助理和聊天机器人有显著潜力减轻人类教师的工作量，尤其是对于与课程逻辑相关的问题回答，这对学生很重要，但对教师来说是重复的。然而，由于隐私问题，缺乏公开可用的数据集。我们介绍了SyllabusQA，这是一个开源数据集，包含63个真实课程大纲，涵盖36个专业，包含5,078对多样化的开放式课程逻辑相关问题-答案对，问题类型和答案格式都是多样的。由于许多逻辑相关问题包含关键信息，如考试日期，评估答案的事实性很重要。我们在该任务上对几个强基线进行了基准测试，从大型语言模型提示到检索增强生成。我们发现，尽管在传统的文本相似性指标上接近人类表现，但在准确性方面仍存在显著差距。

    arXiv:2403.14666v1 Announce Type: cross  Abstract: Automated teaching assistants and chatbots have significant potential to reduce the workload of human instructors, especially for logistics-related question answering, which is important to students yet repetitive for instructors. However, due to privacy concerns, there is a lack of publicly available datasets. We introduce SyllabusQA, an open-source dataset with 63 real course syllabi covering 36 majors, containing 5,078 open-ended course logistics-related question-answer pairs that are diverse in both question types and answer formats. Since many logistics-related questions contain critical information like the date of an exam, it is important to evaluate the factuality of answers. We benchmark several strong baselines on this task, from large language model prompting to retrieval-augmented generation. We find that despite performing close to humans on traditional metrics of textual similarity, there remains a significant gap between
    
[^128]: ClickTree：基于点击数据的树形方法用于预测数学学生表现

    ClickTree: A Tree-based Method for Predicting Math Students' Performance Based on Clickstream Data

    [https://arxiv.org/abs/2403.14664](https://arxiv.org/abs/2403.14664)

    ClickTree是一种基于树形方法的预测学生数学作业表现的技术，在2023年教育数据挖掘杯比赛中取得了0.78844的AUC，排名第二。

    

    通过分析捕获学生行为的大量点击数据，教育工作者可以深入了解影响学术成果的因素，并确定课程改进的方向。在本研究中，我们开发了ClickTree，一种基于树形方法的技术，根据学生的点击数据来预测数学作业表现。我们从大量的点击数据中提取了一组特征，包括问题级别、任务级别和学生级别的特征，并训练了一个CatBoost树来预测学生是否成功回答了任务中的问题。该方法在2023年教育数据挖掘杯比赛中取得了0.78844的AUC，获得了第二名的成绩。

    arXiv:2403.14664v1 Announce Type: cross  Abstract: The prediction of student performance and the analysis of students' learning behavior play an important role in enhancing online courses. By analysing a massive amount of clickstream data that captures student behavior, educators can gain valuable insights into the factors that influence academic outcomes and identify areas of improvement in courses. In this study, we developed ClickTree, a tree-based methodology, to predict student performance in mathematical assignments based on students' clickstream data. We extracted a set of features, including problem-level, assignment-level and student-level features, from the extensive clickstream data and trained a CatBoost tree to predict whether a student successfully answers a problem in an assignment. The developed method achieved an AUC of 0.78844 in the Educational Data Mining Cup 2023 and ranked second in the competition. Furthermore, our results indicate that students encounter more di
    
[^129]: 机器学习可预测初中辍学，甚至在小学结束时就能预测

    Machine Learning Predicts Upper Secondary Education Dropout as Early as the End of Primary School

    [https://arxiv.org/abs/2403.14663](https://arxiv.org/abs/2403.14663)

    该研究利用长达13年的数据集，包括从幼儿园到9年级的数据，通过机器学习模型成功预测了初中辍学的可能性

    

    教育在减轻贫困、推动经济增长和赋予个人权力方面起着至关重要的作用，从而显着影响社会和个人发展。尽管以前的研究采用机器学习进行辍学分类，但这些研究往往受短期焦点的影响，依赖于仅在研究期间收集了几年数据。本研究通过利用一个为期13年的纵向数据集扩展了建模视角，涵盖了从幼儿园到9年级的数据。我们的方法结合了一系列广泛的参数，包括学生的学术和认知能力、动机、行为、幸福感以及官方记录的辍学数据。本研究开发的机器学习模型展现出显著的分类能力，实现了平均面积u

    arXiv:2403.14663v1 Announce Type: cross  Abstract: Education plays a pivotal role in alleviating poverty, driving economic growth, and empowering individuals, thereby significantly influencing societal and personal development. However, the persistent issue of school dropout poses a significant challenge, with its effects extending beyond the individual. While previous research has employed machine learning for dropout classification, these studies often suffer from a short-term focus, relying on data collected only a few years into the study period. This study expanded the modeling horizon by utilizing a 13-year longitudinal dataset, encompassing data from kindergarten to Grade 9. Our methodology incorporated a comprehensive range of parameters, including students' academic and cognitive skills, motivation, behavior, well-being, and officially recorded dropout data. The machine learning models developed in this study demonstrated notable classification ability, achieving a mean area u
    
[^130]: 非洲人工智能政策发展案例研究

    Case Studies of AI Policy Development in Africa

    [https://arxiv.org/abs/2403.14662](https://arxiv.org/abs/2403.14662)

    非洲国家在AI准备方面取得的进展没有完全被全球准备情况评估捕捉到，通过对四个非洲国家进行案例研究，提出了如何改善国家的AI准备标准以及如何使社会能够获益于AI的高层政策考虑。

    

    arXiv:2403.14662v1 公告类型：跨领域 摘要：人工智能（AI）需要新的评估方式，以评估非洲国家在国家技术使用和战略方面的准备情况。我们对现有的针对一般数字采纳和特定AI政策的“准备情况”评估进行了调查。我们得出结论，现有的全球准备情况评估并没有完全捕捉到非洲国家在AI准备方面的进步，并为如何更好地利用这些评估来适应非洲背景奠定了基础。我们考虑这些指标在多大程度上与非洲背景相吻合，以及这些指标在捕捉非洲国家在实现AI能力方面的实际工作方面所遗漏的内容。通过对非洲四个地理和经济尺度不同的国家进行案例研究，我们提出了全球评估遗漏的细微差别，并提供了如何改善国家的AI准备标准以及如何使社会能够获益于AI的高层政策考虑。

    arXiv:2403.14662v1 Announce Type: cross  Abstract: Artificial Intelligence (AI) requires new ways of evaluating national technology use and strategy for African nations. We conduct a survey of existing 'readiness' assessments both for general digital adoption and for AI policy in particular. We conclude that existing global readiness assessments do not fully capture African states' progress in AI readiness and lay the groundwork for how assessments can be better used for the African context. We consider the extent to which these indicators map to the African context and what these indicators miss in capturing African states' on-the-ground work in meeting AI capability. Through case studies of four African nations of diverse geographic and economic dimensions, we identify nuances missed by global assessments and offer high-level policy considerations for how states can best improve their AI readiness standards and prepare their societies to capture the benefits of AI.
    
[^131]: 基于大型语言模型的学习者表现建模研究

    Towards Modeling Learner Performance with Large Language Models

    [https://arxiv.org/abs/2403.14661](https://arxiv.org/abs/2403.14661)

    本文研究了预训练大型语言模型（LLMs）在知识追踪领域的应用，通过比较零-shot提示和模型微调两种方法，提出了LLMs在智能辅导系统中预测学习者表现的潜力。

    

    最近关于预训练大型语言模型（LLMs）能力的研究表明它们能够充当一般模式机器，通过完成代表各种任务的复杂令牌序列，包括时间序列预测和机器人控制。本文研究了LLMs的模式识别和序列建模能力是否能够扩展到知识追踪领域，这在智能辅导系统（ITSs）的发展中是一个关键组成部分，通过预测学习者随时间的表现来个性化教育体验。在多个真实世界数据集上进行了经验性评估，我们比较了使用LLMs进行此任务的两种方法，零-shot提示和模型微调，以及现有的非LLM方法。虽然基于LLMs的方法没有达到最先进的性能，但经过微调的LLMs超过了天真的基线模型的表现。

    arXiv:2403.14661v1 Announce Type: cross  Abstract: Recent work exploring the capabilities of pre-trained large language models (LLMs) has demonstrated their ability to act as general pattern machines by completing complex token sequences representing a wide array of tasks, including time-series prediction and robot control. This paper investigates whether the pattern recognition and sequence modeling capabilities of LLMs can be extended to the domain of knowledge tracing, a critical component in the development of intelligent tutoring systems (ITSs) that tailor educational experiences by predicting learner performance over time. In an empirical evaluation across multiple real-world datasets, we compare two approaches to using LLMs for this task, zero-shot prompting and model fine-tuning, with existing, non-LLM approaches to knowledge tracing. While LLM-based approaches do not achieve state-of-the-art performance, fine-tuned LLMs surpass the performance of naive baseline models and perf
    
[^132]: 革新远程学习：基于人工智能辅导的学习进展的比较研究

    Revolutionising Distance Learning: A Comparative Study of Learning Progress with AI-Driven Tutoring

    [https://arxiv.org/abs/2403.14642](https://arxiv.org/abs/2403.14642)

    本研究首次证明生成式AI能显著提高大学生的学习速度，使用AI助手Syntea在远程学习学生中平均减少了27%的学习时间，表明生成式AI可以通过个性化显著改进和加快学习。

    

    Generative AI预计将对教育产生巨大积极影响; 但是，目前尚未在大学层面展示这种潜力。在这项研究中，我们首次提出证据表明，生成式AI能够显著提高大学生的学习速度。我们测试了是否使用AI动力学辅导助手Syntea影响了IU国际应用科学大学40多个课程中数百名远程学习学生的学习速度。我们的分析表明，使用Syntea在Syntea发布后第三个月显著减少了他们的学习时间--平均约减少了27\%。总的来说，该效应的幅度和方法的可扩展性证明了生成式AI作为显著改进和加快学习的关键杠杆。

    arXiv:2403.14642v1 Announce Type: cross  Abstract: Generative AI is expected to have a vast, positive impact on education; however, at present, this potential has not yet been demonstrated at scale at university level. In this study, we present first evidence that generative AI can increase the speed of learning substantially in university students. We tested whether using the AI-powered teaching assistant Syntea affected the speed of learning of hundreds of distance learning students across more than 40 courses at the IU International University of Applied Sciences. Our analysis suggests that using Syntea reduced their study time substantially--by about 27\% on average--in the third month after the release of Syntea. Taken together, the magnitude of the effect and the scalability of the approach implicate generative AI as a key lever to significantly improve and accelerate learning by personalisation.
    
[^133]: 测试自动驾驶车辆和人工智能：从网络安全、透明度、稳健性和公平性的视角探讨挑战与前景

    Testing autonomous vehicles and AI: perspectives and challenges from cybersecurity, transparency, robustness and fairness

    [https://arxiv.org/abs/2403.14641](https://arxiv.org/abs/2403.14641)

    探讨了将人工智能整合到自动驾驶车辆中所涉及的挑战，重点关注了网络安全审计、决策过程的可解释性以及评估预测系统的稳健性和道德行为等方面的重要性

    

    本研究探讨了将人工智能（AI）整合到自动驾驶车辆（AVs）中所涉及的复杂性，研究了AI组件引入的挑战以及对测试程序的影响，着重关注可信赖AI的一些基本要求。讨论的主题包括AI在AVs的各个操作层中的作用、欧盟AI法案对AVs的影响，以及对高级驾驶辅助系统（ADAS）和自动驾驶系统（ADS）的新测试方法的需求。研究还就网络安全审计的重要性、AI决策过程中的可解释性需求以及评估AVs中预测系统稳健性和道德行为的协议提供了详细分析。该论文指出了一些重要挑战，并提出了AI在AV技术研究和开发中未来方向的建议，强调了跨学科专业知识的需求。

    arXiv:2403.14641v1 Announce Type: cross  Abstract: This study explores the complexities of integrating Artificial Intelligence (AI) into Autonomous Vehicles (AVs), examining the challenges introduced by AI components and the impact on testing procedures, focusing on some of the essential requirements for trustworthy AI. Topics addressed include the role of AI at various operational layers of AVs, the implications of the EU's AI Act on AVs, and the need for new testing methodologies for Advanced Driver Assistance Systems (ADAS) and Automated Driving Systems (ADS). The study also provides a detailed analysis on the importance of cybersecurity audits, the need for explainability in AI decision-making processes and protocols for assessing the robustness and ethical behaviour of predictive systems in AVs. The paper identifies significant challenges and suggests future directions for research and development of AI in AV technology, highlighting the need for multidisciplinary expertise.
    
[^134]: 使用Transformer神经网络来定义智慧城市

    On Defining Smart Cities using Transformer Neural Networks

    [https://arxiv.org/abs/2403.14639](https://arxiv.org/abs/2403.14639)

    使用Transformer神经网络和语义文本分析，本论文尝试创建一个新的智慧城市定义“妥协”版本，并提出语义相似度度量作为评估技术。

    

    全球各地的城市正在迅速采用智能技术，改变城市生活。尽管存在这一趋势，但有关“智慧城市”的普遍接受的定义仍然难以界定。本文旨在创建一个应与先前参与定义这一概念的大多数专家 resonating 的新“妥协”定义，并旨在验证现有定义之一。我们从行业、学术界和各种相关组织中审查了60个智慧城市的定义，采用基于Transformer架构的生成AI和语义文本分析以达成这一妥协。我们提出了一种语义相似度度量作为评估技术，通常可用于比较不同智慧城市定义，评估其独特性或相似性。我们的方法利用生成AI来分析各种现有定义。

    arXiv:2403.14639v1 Announce Type: cross  Abstract: Cities worldwide are rapidly adopting smart technologies, transforming urban life. Despite this trend, a universally accepted definition of 'smart city' remains elusive. Past efforts to define it have not yielded a consensus, as evidenced by the numerous definitions in use. In this paper, we endeavored to create a new 'compromise' definition that should resonate with most experts previously involved in defining this concept and aimed to validate one of the existing definitions. We reviewed 60 definitions of smart cities from industry, academia, and various relevant organizations, employing transformer architecture-based generative AI and semantic text analysis to reach this compromise. We proposed a semantic similarity measure as an evaluation technique, which could generally be used to compare different smart city definitions, assessing their uniqueness or resemblance. Our methodology employed generative AI to analyze various existing
    
[^135]: 基于深度编程学习风格捕捉的个性化编程指导

    Personalized Programming Guidance based on Deep Programming Learning Style Capturing

    [https://arxiv.org/abs/2403.14638](https://arxiv.org/abs/2403.14638)

    本文提出了一种名为具有学习风格的编程练习推荐器（PERS）的新模型，旨在解决编程中如何识别复杂编程行为和捕捉内在学习模式的挑战。

    

    随着大数据和人工智能技术的快速发展，编程需求量大增，已成为学生的必备技能。与此同时，研究人员也致力于提高在线评判系统的指导能力，以减少学生的辍学率。先前的研究主要集中在通过提供个性化推荐增强学习者在在线平台上的参与度。然而，在编程方面仍需解决两个重要挑战：C1) 如何识别复杂的编程行为；C2) 如何捕捉与实际学习过程相符的内在学习模式。为了填补这些空白，本文提出了一种名为具有学习风格的编程练习推荐器（PERS）的新模型，该模型模拟了学习者复杂的编程行为。具体而言，由于编程是一个迭代和试错的过程，我们首先引入了位置编码和区分模块

    arXiv:2403.14638v1 Announce Type: cross  Abstract: With the rapid development of big data and AI technology, programming is in high demand and has become an essential skill for students. Meanwhile, researchers also focus on boosting the online judging system's guidance ability to reduce students' dropout rates. Previous studies mainly targeted at enhancing learner engagement on online platforms by providing personalized recommendations. However, two significant challenges still need to be addressed in programming: C1) how to recognize complex programming behaviors; C2) how to capture intrinsic learning patterns that align with the actual learning process. To fill these gaps, in this paper, we propose a novel model called Programming Exercise Recommender with Learning Style (PERS), which simulates learners' intricate programming behaviors. Specifically, since programming is an iterative and trial-and-error process, we first introduce a positional encoding and a differentiating module to
    
[^136]: Videoshop：具有噪声外推扩散反演的本地化语义视频编辑

    Videoshop: Localized Semantic Video Editing with Noise-Extrapolated Diffusion Inversion

    [https://arxiv.org/abs/2403.14617](https://arxiv.org/abs/2403.14617)

    Videoshop是一个无需训练的视频编辑算法，通过图像为基础的方法实现了本地化语义编辑，从而允许用户对视频进行精细控制，取得了更高质量的编辑效果。

    

    我们介绍了Videoshop，这是一个无需训练的用于本地化语义编辑的视频编辑算法。Videoshop允许用户使用任何编辑软件，包括Photoshop和生成填充，修改第一帧；它会自动将这些更改传播到其余帧，保持语义、空间和时间上的一致运动。与现有方法只能通过不精确的文本指令进行编辑不同，Videoshop允许用户添加或删除对象，语义上更改对象，将素材照片插入视频等，并对位置和外观进行细粒度控制。我们通过对潜在值进行噪声外推反演的图像为基础的视频编辑来实现这一目标，从中我们生成根据编辑图像调整的视频。Videoshop在2个编辑基准测试中使用10个评估指标对6个基线取得了更高质量的编辑效果。

    arXiv:2403.14617v1 Announce Type: cross  Abstract: We introduce Videoshop, a training-free video editing algorithm for localized semantic edits. Videoshop allows users to use any editing software, including Photoshop and generative inpainting, to modify the first frame; it automatically propagates those changes, with semantic, spatial, and temporally consistent motion, to the remaining frames. Unlike existing methods that enable edits only through imprecise textual instructions, Videoshop allows users to add or remove objects, semantically change objects, insert stock photos into videos, etc. with fine-grained control over locations and appearance. We achieve this through image-based video editing by inverting latents with noise extrapolation, from which we generate videos conditioned on the edited image. Videoshop produces higher quality edits against 6 baselines on 2 editing benchmarks using 10 evaluation metrics.
    
[^137]: 进化优化和贝叶斯优化中的模型不确定性：一项比较分析

    Model Uncertainty in Evolutionary Optimization and Bayesian Optimization: A Comparative Analysis

    [https://arxiv.org/abs/2403.14413](https://arxiv.org/abs/2403.14413)

    这项研究比较了进化优化和贝叶斯优化中的模型不确定性，引入了一种新的模型辅助策略以增强算法性能。

    

    黑盒优化问题在许多实际应用中很常见，需要通过输入输出交互来进行优化，而没有访问内部工作原理。贝叶斯优化（BO）和辅助代理进化算法（SAEA）是两种广泛使用的无梯度优化技术，用于解决这些挑战。本文旨在阐明这两种方法在利用模型不确定性方面的相似性和差异，以及模型不准确性对算法性能的影响。引入了一种新颖的模型辅助策略，利用未评估的解决方案生成后代，利用进化算法的基于种群的搜索能力来增强。

    arXiv:2403.14413v1 Announce Type: cross  Abstract: Black-box optimization problems, which are common in many real-world applications, require optimization through input-output interactions without access to internal workings. This often leads to significant computational resources being consumed for simulations. Bayesian Optimization (BO) and Surrogate-Assisted Evolutionary Algorithm (SAEA) are two widely used gradient-free optimization techniques employed to address such challenges. Both approaches follow a similar iterative procedure that relies on surrogate models to guide the search process. This paper aims to elucidate the similarities and differences in the utilization of model uncertainty between these two methods, as well as the impact of model inaccuracies on algorithmic performance. A novel model-assisted strategy is introduced, which utilizes unevaluated solutions to generate offspring, leveraging the population-based search capabilities of evolutionary algorithm to enhance 
    
[^138]: 准确预测智能系统的安全关键稀有事件概率

    Accurately Predicting Probabilities of Safety-Critical Rare Events for Intelligent Systems

    [https://arxiv.org/abs/2403.13869](https://arxiv.org/abs/2403.13869)

    该研究致力于发展一个在评估安全关键自主安全性的重要性方面，在精度和召回率方面都表现出色的关键性预测模型。

    

    智能系统越来越成为我们日常生活中的重要组成部分，然而罕见的安全关键事件对它们的实际部署构成了重大潜在威胁。应对这一挑战的关键在于准确预测在给定时间步长内从当前状态发生安全关键事件的概率，一个我们定义为“重要性”的指标。预测重要性的复杂性源自于极端数据不平衡，这是由高维变量中与罕见事件相关联引起的一个挑战，我们称之为罕见性诅咒。现有方法往往要么过于保守，要么容易忽视安全关键事件，因此很难同时实现高精度和召回率，这严重限制了它们的适用性。本研究旨在开发一个重要性预测模型，在评估安全关键自主安全性的重要性方面，在精度和召回率方面都表现出色。

    arXiv:2403.13869v1 Announce Type: cross  Abstract: Intelligent systems are increasingly integral to our daily lives, yet rare safety-critical events present significant latent threats to their practical deployment. Addressing this challenge hinges on accurately predicting the probability of safety-critical events occurring within a given time step from the current state, a metric we define as 'criticality'. The complexity of predicting criticality arises from the extreme data imbalance caused by rare events in high dimensional variables associated with the rare events, a challenge we refer to as the curse of rarity. Existing methods tend to be either overly conservative or prone to overlooking safety-critical events, thus struggling to achieve both high precision and recall rates, which severely limits their applicability. This study endeavors to develop a criticality prediction model that excels in both precision and recall rates for evaluating the criticality of safety-critical auton
    
[^139]: 模型开放框架: 促进人工智能中的可重现性、透明度和可用性的完整性和开放性

    The Model Openness Framework: Promoting Completeness and Openness for Reproducibility, Transparency and Usability in AI

    [https://arxiv.org/abs/2403.13784](https://arxiv.org/abs/2403.13784)

    提出了模型开放框架（MOF），它是一个排名分类系统，根据完整性和开放性评估机器学习模型，旨在促进完整性、开放性以及遵循开放科学原则，可以帮助准确识别模型的透明性和可重现性。

    

    生成式人工智能（GAI）提供了前所未有的可能性，但其商业化引发了关于透明度、可重现性、偏见和安全性的担忧。许多"开源"的GAI模型缺乏完整理解和再现所必需的组件，一些采用限制性许可证，这种行为被称为"开源洗白"。我们提出了模型开放框架（MOF），这是一个根据完整性和开放性对机器学习模型进行排名分类的系统，遵循开放科学、开源、开放数据和开放获取的原则。MOF要求模型开发生命周期的特定组件被包含并根据适当的开放许可证发布。该框架旨在防止宣称自己是开放的模型被误解，指导研究人员和开发者以宽松的许可证发布所有模型组件，并帮助公司、学术界和爱好者识别可以安全采用的模型。

    arXiv:2403.13784v1 Announce Type: new  Abstract: Generative AI (GAI) offers unprecedented possibilities but its commercialization has raised concerns about transparency, reproducibility, bias, and safety. Many "open-source" GAI models lack the necessary components for full understanding and reproduction, and some use restrictive licenses, a practice known as "openwashing." We propose the Model Openness Framework (MOF), a ranked classification system that rates machine learning models based on their completeness and openness, following principles of open science, open source, open data, and open access. The MOF requires specific components of the model development lifecycle to be included and released under appropriate open licenses. This framework aims to prevent misrepresentation of models claiming to be open, guide researchers and developers in providing all model components under permissive licenses, and help companies, academia, and hobbyists identify models that can be safely adop
    
[^140]: AltGraph：利用生成图模型重新设计量子电路以进行高效优化

    AltGraph: Redesigning Quantum Circuits Using Generative Graph Models for Efficient Optimization

    [https://arxiv.org/abs/2403.12979](https://arxiv.org/abs/2403.12979)

    该论文提出了AltGraph这一基于搜索的电路转换方法，利用生成图模型生成等效的量子电路，以在保持等效性的同时优化电路。

    

    量子电路转换旨在生成等效电路的同时优化各方面，如电路深度、门数量以及与现代嘈杂中间尺度量子（NISQ）设备的兼容性。本文提出了AltGraph，一种新颖的基于搜索的电路转换方法，利用现有的生成图模型生成等效的量子电路。我们使用了三个主要的图模型：DAG（有向无环图）、AND-OR图和蛋白质结构图，以在保持等效性的同时对电路进行优化。

    arXiv:2403.12979v1 Announce Type: cross  Abstract: Quantum circuit transformation aims to produce equivalent circuits while optimizing for various aspects such as circuit depth, gate count, and compatibility with modern Noisy Intermediate Scale Quantum (NISQ) devices. There are two techniques for circuit transformation. The first is a rule-based approach that greedily cancels out pairs of gates that equate to the identity unitary operation. Rule-based approaches are used in quantum compilers such as Qiskit, tket, and Quilc. The second is a search-based approach that tries to find an equivalent quantum circuit by exploring the quantum circuits search space. Search-based approaches typically rely on machine learning techniques such as generative models and Reinforcement Learning (RL). In this work, we propose AltGraph, a novel search-based circuit transformation approach that generates equivalent quantum circuits using existing generative graph models. We use three main graph models: DAG
    
[^141]: 超越数量：基于机器学习的城市基础设施质量不平等特征化

    Beyond Quantities: Machine Learning-based Characterization of Inequality in Infrastructure Quality Provision in Cities

    [https://arxiv.org/abs/2403.12074](https://arxiv.org/abs/2403.12074)

    通过机器学习的方法，超越了传统基于数量的基础设施不平等特征化研究，从而填补了城市不平等和环境正义考虑之间的研究空白。

    

    本研究的目标是对城市地区的基础设施质量不平等进行特征化。尽管越来越多的文献已经意识到特征化城市基础设施不平等的重要性，并提供了定量指标以指导城市发展规划，但大多数现有方法主要集中在测量基础设施的数量上，假定更多的基础设施更好。此外，现有研究主要集中在基于指数的方法上，其中城市地区基础设施供给状况是根据设定的主观权重确定的。对基础设施数量的关注和使用来自主观权重的指数已经妨碍了适当地研究基础设施不平等与城市不平等和环境正义考虑之间的关系。鉴此，我们提出一种基于机器学习的方法

    arXiv:2403.12074v1 Announce Type: cross  Abstract: The objective of this study is to characterize inequality in infrastructure quality across urban areas. While a growing of body of literature has recognized the importance of characterizing infrastructure inequality in cities and provided quantified metrics to inform urban development plans, the majority of the existing approaches focus primarily on measuring the quantity of infrastructure, assuming that more infrastructure is better. Also, the existing research focuses primarily on index-based approaches in which the status of infrastructure provision in urban areas is determined based on assumed subjective weights. The focus on infrastructure quantity and use of indices obtained from subjective weights has hindered the ability to properly examine infrastructure inequality as it pertains to urban inequality and environmental justice considerations. Recognizing this gap, we propose a machine learning-based approach in which infrastruct
    
[^142]: LSKNet：一种用于遥感的轻量级基础架构

    LSKNet: A Foundation Lightweight Backbone for Remote Sensing

    [https://arxiv.org/abs/2403.11735](https://arxiv.org/abs/2403.11735)

    LSKNet是一种轻量级的大型选择核网络骨干，能动态调整其较大的空间感受野，以更好地模拟遥感场景中各种对象的远程上下文。

    

    遥感图像由于其固有的复杂性对下游任务提出了独特的挑战。尽管已经有大量研究致力于遥感分类、目标检测和语义分割，但其中大多数研究都忽视了嵌入在遥感场景中的宝贵先验知识。这些先验知识可能会很有用，因为在没有参考足够长程上下文的情况下，遥感对象可能会被错误识别，而这可以因不同对象而异。本文考虑了这些先验知识，并提出了一种轻量级的大型选择核网络（LSKNet）骨干网络。LSKNet可以动态调整其较大的空间感受野，以更好地模拟遥感场景中各种对象的远距离上下文。据我们所知，先前尚未在遥感图像中探索过大型和选择性核机制。我们的轻量级方法没有太多复杂性。

    arXiv:2403.11735v1 Announce Type: cross  Abstract: Remote sensing images pose distinct challenges for downstream tasks due to their inherent complexity. While a considerable amount of research has been dedicated to remote sensing classification, object detection and semantic segmentation, most of these studies have overlooked the valuable prior knowledge embedded within remote sensing scenarios. Such prior knowledge can be useful because remote sensing objects may be mistakenly recognized without referencing a sufficiently long-range context, which can vary for different objects. This paper considers these priors and proposes a lightweight Large Selective Kernel Network (LSKNet) backbone. LSKNet can dynamically adjust its large spatial receptive field to better model the ranging context of various objects in remote sensing scenarios. To our knowledge, large and selective kernel mechanisms have not been previously explored in remote sensing images. Without bells and whistles, our lightw
    
[^143]: LOOPer: 一个针对多面体编译器的学习型自动代码优化器

    LOOPer: A Learned Automatic Code Optimizer For Polyhedral Compilers

    [https://arxiv.org/abs/2403.11522](https://arxiv.org/abs/2403.11522)

    LOOPer是针对多面体编译器的学习型自动代码优化器，通过机器学习建立成本模型来指导多面体优化搜索，突破了传统编译器在选择代码转换方面的限制。

    

    虽然多面体编译器在实现高级代码转换方面已经取得成功，但在选择能够带来最佳加速的最有利转换方面仍然面临挑战。这促使使用机器学习构建成本模型来引导多面体优化的搜索。最先进的多面体编译器已经展示了这种方法的可行性概念验证。虽然这种概念验证显示出了希望，但仍然存在显著限制。使用深度学习成本模型的最先进多面体编译器只支持少量仿射变换的子集，限制了它们应用复杂代码变换的能力。它们还只支持具有单个循环嵌套和矩形迭代域的简单程序，限制了它们对许多程序的适用性。这些限制显著影响了这样的编译器和自动调度器的通用性

    arXiv:2403.11522v1 Announce Type: cross  Abstract: While polyhedral compilers have shown success in implementing advanced code transformations, they still have challenges in selecting the most profitable transformations that lead to the best speedups. This has motivated the use of machine learning to build cost models to guide the search for polyhedral optimizations. State-of-the-art polyhedral compilers have demonstrated a viable proof-of-concept of this approach. While such a proof-of-concept has shown promise, it still has significant limitations. State-of-the-art polyhedral compilers that use a deep-learning cost model only support a small subset of affine transformations, limiting their ability to apply complex code transformations. They also only support simple programs that have a single loop nest and a rectangular iteration domain, limiting their applicability to many programs. These limitations significantly impact the generality of such compilers and autoschedulers and put in
    
[^144]: CPA-Enhancer：链式思维驱动自适应增强器用于未知退化下的目标检测

    CPA-Enhancer: Chain-of-Thought Prompted Adaptive Enhancer for Object Detection under Unknown Degradations

    [https://arxiv.org/abs/2403.11220](https://arxiv.org/abs/2403.11220)

    提出了一种用于未知退化下目标检测的链式思维驱动自适应增强器CPA-Enhancer，并将其集成到通用检测器中，有效提升受损图像的检测性能

    

    目前，已经广泛研究了在已知单一退化情况下的目标检测方法。然而，现有方法需要先验知识来确定退化类型，并为每种类型训练一个单独的模型，从而限制了它们在不可预测环境中的实际应用。为了解决这一挑战，我们提出了一种链式思维（CoT）驱动的自适应增强器CPA-Enhancer，用于未知退化情况下的目标检测。具体而言，CPA-Enhancer在CoT提示的逐步指导下逐步调整其增强策略，这些提示编码了与退化相关的信息。据我们所知，这是首个利用CoT提示进行目标检测任务的工作。总的来说，CPA-Enhancer是一个即插即用的增强模型，可以集成到任何通用检测器中，在不事先知道退化类型的情况下，在受损图像上实现显著提升。实验结果表明，CPA-E

    arXiv:2403.11220v1 Announce Type: cross  Abstract: Object detection methods under known single degradations have been extensively investigated. However, existing approaches require prior knowledge of the degradation type and train a separate model for each, limiting their practical applications in unpredictable environments. To address this challenge, we propose a chain-of-thought (CoT) prompted adaptive enhancer, CPA-Enhancer, for object detection under unknown degradations. Specifically, CPA-Enhancer progressively adapts its enhancement strategy under the step-by-step guidance of CoT prompts, that encode degradation-related information. To the best of our knowledge, it's the first work that exploits CoT prompting for object detection tasks. Overall, CPA-Enhancer is a plug-and-play enhancement model that can be integrated into any generic detectors to achieve substantial gains on degraded images, without knowing the degradation type priorly. Experimental results demonstrate that CPA-E
    
[^145]: 大型语言模型指导的心力衰竭风险预测的ECG双注意力网络

    Large Language Model-informed ECG Dual Attention Network for Heart Failure Risk Prediction

    [https://arxiv.org/abs/2403.10581](https://arxiv.org/abs/2403.10581)

    提出了一种大型语言模型指导的双注意力ECG网络，用于心力衰竭风险预测，能够捕捉复杂的心电图特征，有效应对低风险和高风险组之间的不平衡。

    

    心力衰竭（HF）由于全球死亡率不断上升而构成重大公共卫生挑战。通过早期诊断和预防来解决这一问题可显著减少疾病对社会的影响。本文引入了一种使用临床获取的12导联心电图（ECG）进行HF风险预测的方法。我们提出了一种新颖的、轻量级的双注意力ECG网络，旨在捕捉对早期HF预测至关重要的复杂心电图特征，尽管低风险和高风险组之间存在明显的不平衡。该网络具有一个跨导注意力模块和12个导联特定的时间注意力模块，以捕捉交叉导联交互作用和每个导联内的局部时间动态。为了防止模型过拟合于有限的训练数据，我们利用一个大型语言模型（LLM）与公共ECG-Report数据集进行预训练，用于进行ECG-报告对齐任务。然后对网络进行fine-tune以用于HF风险预测

    arXiv:2403.10581v1 Announce Type: cross  Abstract: Heart failure (HF) poses a significant public health challenge due to its rising global mortality rate. Addressing this issue through early diagnosis and prevention could significantly reduce the disease's impact. This work introduces a methodology for HF risk prediction using clinically acquired 12-lead electrocardiograms (ECGs). We present a novel, lightweight dual-attention ECG network designed to capture complex ECG features essential for early HF prediction, despite the notable imbalance between low and high-risk groups. The network features a cross-lead attention module and twelve lead-specific temporal attention modules to capture cross-lead interactions and local temporal dynamics within each lead. To prevent model overfitting from limited training data, we leverage a large language model (LLM) with a public ECG-Report dataset for pretraining on an ECG-report alignment task. The network is then fine-tuned for HF risk prediction
    
[^146]: 大型语言模型中用于快速推测解码的循环草稿机制

    Recurrent Drafter for Fast Speculative Decoding in Large Language Models

    [https://arxiv.org/abs/2403.09919](https://arxiv.org/abs/2403.09919)

    本文介绍了一种适用于大型语言模型的循环草稿机制，结合了经典双模型和最新单模型方法，通过运用循环依赖设计，实现了高效的推测解码。

    

    在本文中，我们介绍一种改进的推测解码方法，旨在提高大型语言模型的效率。我们的方法利用了两种成熟技术的优势：经典的双模型推测解码方法和较新的单模型方法Medusa。从Medusa得到灵感，我们的方法采用了单模型策略进行推测解码。然而，我们的方法通过使用具有循环依赖设计的单个轻量级草稿头来区分自己，本质上类似于经典推测解码中使用的小型草稿模型，但避免了完整transformer架构的复杂性。由于循环依赖，我们可以使用波束搜索快速过滤出草稿头中不需要的候选项。其结果是一种结合了单模型设计简易性并避免了创建数据相关树依赖的方法。

    arXiv:2403.09919v1 Announce Type: new  Abstract: In this paper, we introduce an improved approach of speculative decoding aimed at enhancing the efficiency of serving large language models. Our method capitalizes on the strengths of two established techniques: the classic two-model speculative decoding approach, and the more recent single-model approach, Medusa. Drawing inspiration from Medusa, our approach adopts a single-model strategy for speculative decoding. However, our method distinguishes itself by employing a single, lightweight draft head with a recurrent dependency design, akin in essence to the small, draft model uses in classic speculative decoding, but without the complexities of the full transformer architecture. And because of the recurrent dependency, we can use beam search to swiftly filter out undesired candidates with the draft head. The outcome is a method that combines the simplicity of single-model design and avoids the need to create a data-dependent tree attent
    
[^147]: MM1：多模式LLM预训练的方法、分析与见解

    MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training

    [https://arxiv.org/abs/2403.09611](https://arxiv.org/abs/2403.09611)

    通过详细研究图像编码器、视觉语言连接器和预训练数据选择的重要性，确定了对于实现多个基准测试中最新潮的少样本结果至关重要的关键设计经验。

    

    在这项工作中，我们讨论了构建高性能的多模式大型语言模型（MLLMs）。具体来说，我们研究了各种架构组件和数据选择的重要性。通过对图像编码器、视觉语言连接器和各种预训练数据选择进行仔细和全面的消融实验，我们确定了几个关键的设计经验。例如，我们展示了对大规模多模式预训练使用仔细混合的图像标题、交替图像文本和仅文本数据对于在多个基准测试中实现最新潮（SOTA）的少样本结果至关重要，与其他已发表的预训练结果相比。此外，我们表明图像编码器连同图像分辨率和图像标记计数具有重要影响，而视觉语言连接器设计相对重要性较小。通过扩大所提出的方法，我们构建了MM1，一个多模式模型系列。

    arXiv:2403.09611v1 Announce Type: cross  Abstract: In this work, we discuss building performant Multimodal Large Language Models (MLLMs). In particular, we study the importance of various architecture components and data choices. Through careful and comprehensive ablations of the image encoder, the vision language connector, and various pre-training data choices, we identified several crucial design lessons. For example, we demonstrate that for large-scale multimodal pre-training using a careful mix of image-caption, interleaved image-text, and text-only data is crucial for achieving state-of-the-art (SOTA) few-shot results across multiple benchmarks, compared to other published pre-training results. Further, we show that the image encoder together with image resolution and the image token count has substantial impact, while the vision-language connector design is of comparatively negligible importance. By scaling up the presented recipe, we build MM1, a family of multimodal models up 
    
[^148]: 持续预训练大型语言模型的简单可扩展策略

    Simple and Scalable Strategies to Continually Pre-train Large Language Models

    [https://arxiv.org/abs/2403.08763](https://arxiv.org/abs/2403.08763)

    通过简单和可扩展的学习率调整、重放数据的方法，可以在不重新训练的情况下，持续预训练大型语言模型以匹配完全重新训练时的性能。

    

    大型语言模型（LLMs）通常在数十亿的标记上进行常规预训练，一旦有新数据可用就重新开始该过程。一个更有效率的解决方案是持续预训练这些模型，与重新训练相比能节省大量计算资源。然而，新数据引起的分布转移通常会导致在以前数据上降低性能或无法适应新数据。在本工作中，我们展示了一种简单且可扩展的学习率（LR）重新升温、LR重新衰减和重放上一数据的组合足以与完全从头开始重新训练在所有可用数据上的性能相匹配，从最终损失和语言模型（LM）评估基准的角度衡量。具体而言，我们展示了在两个常用的LLM预训练数据集（英语→英语）之间的弱但现实的分布转移以及更强烈的分布转移（英语→德语）下的情况。

    arXiv:2403.08763v1 Announce Type: cross  Abstract: Large language models (LLMs) are routinely pre-trained on billions of tokens, only to start the process over again once new data becomes available. A much more efficient solution is to continually pre-train these models, saving significant compute compared to re-training. However, the distribution shift induced by new data typically results in degraded performance on previous data or poor adaptation to the new data. In this work, we show that a simple and scalable combination of learning rate (LR) re-warming, LR re-decaying, and replay of previous data is sufficient to match the performance of fully re-training from scratch on all available data, as measured by final loss and language model (LM) evaluation benchmarks. Specifically, we show this for a weak but realistic distribution shift between two commonly used LLM pre-training datasets (English$\rightarrow$English) and a stronger distribution shift (English$\rightarrow$German) at th
    
[^149]: TeleMoMa：一种用于移动操作的模块化多功能远程操作系统

    TeleMoMa: A Modular and Versatile Teleoperation System for Mobile Manipulation

    [https://arxiv.org/abs/2403.07869](https://arxiv.org/abs/2403.07869)

    TeleMoMa 是一种面向移动操作的模块化多功能远程操作系统，通过整合多种人机接口、降低门槛且具有通用性，为移动操作器提供了全身远程操作的解决方案。

    

    机器人学中限制模仿学习的关键瓶颈是数据的匮乏。这个问题在移动操作中更为严重，因为与静止操作相比，由于缺乏可用且易于使用的远程操作界面，收集演示更加困难。在这项工作中，我们展示了TeleMoMa，这是一种用于全身远程操作移动操作器的通用和模块化界面。TeleMoMa将包括RGB和深度摄像头、虚拟现实控制器、键盘、操纵杆等多个人机接口整合在一起，以及这些接口的任何组合。在其更易访问的版本中， TeleMoMa可以仅使用视觉（如RGB-D相机）即可工作，降低了人类提供移动操作演示的门槛。我们通过在模拟环境和现实世界中远程操作几个现有的移动操作器——PAL Tiago++, Toyota HSR和Fetch来展现TeleMoMa的多功能性。

    arXiv:2403.07869v1 Announce Type: cross  Abstract: A critical bottleneck limiting imitation learning in robotics is the lack of data. This problem is more severe in mobile manipulation, where collecting demonstrations is harder than in stationary manipulation due to the lack of available and easy-to-use teleoperation interfaces. In this work, we demonstrate TeleMoMa, a general and modular interface for whole-body teleoperation of mobile manipulators. TeleMoMa unifies multiple human interfaces including RGB and depth cameras, virtual reality controllers, keyboard, joysticks, etc., and any combination thereof. In its more accessible version, TeleMoMa works using simply vision (e.g., an RGB-D camera), lowering the entry bar for humans to provide mobile manipulation demonstrations. We demonstrate the versatility of TeleMoMa by teleoperating several existing mobile manipulators - PAL Tiago++, Toyota HSR, and Fetch - in simulation and the real world. We demonstrate the quality of the demonst
    
[^150]: 多条件图扩散用于神经架构搜索

    Multi-conditioned Graph Diffusion for Neural Architecture Search

    [https://arxiv.org/abs/2403.06020](https://arxiv.org/abs/2403.06020)

    提出了一种基于图扩散的NAS方法，结合多条件无分类器指导方法，能在架构搜索中生成快速且性能优越的神经网络架构，并在多个标准基准和ImageNet数据集上取得了有希望的结果

    

    神经架构搜索通过探索庞大且复杂的架构搜索空间来自动设计神经网络架构。为了推动架构搜索，我们提出了一种基于图扩散的NAS方法，该方法使用离散条件图扩散过程生成性能优越的神经网络架构。我们随后提出了一种多条件无分类器指导方法，应用于图扩散网络，共同施加诸如高准确性和低硬件延迟等约束。与相关工作不同，我们的方法完全可微分，并且仅需要单模型训练。在我们的评估中，我们展示了在六个标准基准上取得了有希望的结果，以快速速度生成新颖且独特的架构，即每种架构少于0.2秒。此外，我们通过在ImageNet数据集上的实验展示了我们方法的泛化能力和效率。

    arXiv:2403.06020v1 Announce Type: new  Abstract: Neural architecture search automates the design of neural network architectures usually by exploring a large and thus complex architecture search space. To advance the architecture search, we present a graph diffusion-based NAS approach that uses discrete conditional graph diffusion processes to generate high-performing neural network architectures. We then propose a multi-conditioned classifier-free guidance approach applied to graph diffusion networks to jointly impose constraints such as high accuracy and low hardware latency. Unlike the related work, our method is completely differentiable and requires only a single model training. In our evaluations, we show promising results on six standard benchmarks, yielding novel and unique architectures at a fast speed, i.e. less than 0.2 seconds per architecture. Furthermore, we demonstrate the generalisability and efficiency of our method through experiments on ImageNet dataset.
    
[^151]: tLaSDI: 热力学信息驱动的潜空间动力学识别

    tLaSDI: Thermodynamics-informed latent space dynamics identification

    [https://arxiv.org/abs/2403.05848](https://arxiv.org/abs/2403.05848)

    提出了一种融合热力学定律的数据驱动潜空间动力学识别方法，通过自动编码器学习潜变量并构建动力学模型，实现对热力学定律的遵守，并通过新的损失函数进行训练。演示了其在稳健泛化能力方面的表现，以及在潜空间中熵产生速率与系统行为之间的相关性。

    

    我们提出了一种数据驱动的潜空间动力学识别方法（tLaSDI），该方法融入了热力学的第一和第二定律。通过自动编码器学习潜变量作为非线性降维模型。潜变量的动力学由基于神经网络的模型构建，通过通用形式主义保留某些结构以尊重热力学定律。建立了对近似值的抽象误差估计，提供了涉及自动编码器雅可比计算的新损失制定。自动编码器和潜动态都经过训练以最小化新的损失。展示了数值示例以演示tLaSDI的性能，即使在外推情况下也表现出稳健的泛化能力。此外，在潜空间中观察到了熵产生速率与完整行为之间的有趣相关性。

    arXiv:2403.05848v1 Announce Type: new  Abstract: We propose a data-driven latent space dynamics identification method (tLaSDI) that embeds the first and second principles of thermodynamics. The latent variables are learned through an autoencoder as a nonlinear dimension reduction model. The dynamics of the latent variables are constructed by a neural network-based model that preserves certain structures to respect the thermodynamic laws through the GENERIC formalism. An abstract error estimate of the approximation is established, which provides a new loss formulation involving the Jacobian computation of autoencoder. Both the autoencoder and the latent dynamics are trained to minimize the new loss. Numerical examples are presented to demonstrate the performance of tLaSDI, which exhibits robust generalization ability, even in extrapolation. In addition, an intriguing correlation is empirically observed between the entropy production rates in the latent space and the behaviors of the ful
    
[^152]: 在大型知识图上训练面向任务的图神经网络，实现准确高效建模

    Task-Oriented GNNs Training on Large Knowledge Graphs for Accurate and Efficient Modeling

    [https://arxiv.org/abs/2403.05752](https://arxiv.org/abs/2403.05752)

    本文提出了一种自动化TOSG提取的方法KG-TOSA，用于在大型知识图上进行面向任务的图神经网络训练，以减轻对大型KG的过多计算负担。

    

    知识图（KG）是一种包含各种节点和边类型的异构图。异构图神经网络（HGNNs）通常用于在KG上训练节点分类和链接预测等机器学习任务。然而，HGNN方法受KG的大小、密度以及节点和边类型数量的影响，表现出过多的复杂性。AI从业者手工设计出一个与特定任务相关的KG G的子图，我们称之为面向任务的子图（TOSG），其中包含G中与任务相关的节点和边类型的子集。使用TOSG而不是G来训练任务可以减轻对大型KG所需的过多计算。设计TOSG需要深入了解KG的结构和任务的目标，因此具有挑战性且耗时。本文提出了KG-TOSA，一种自动化TOSG提取的方法，用于在大型KG上进行面向任务的HGNN训练。

    arXiv:2403.05752v1 Announce Type: cross  Abstract: A Knowledge Graph (KG) is a heterogeneous graph encompassing a diverse range of node and edge types. Heterogeneous Graph Neural Networks (HGNNs) are popular for training machine learning tasks like node classification and link prediction on KGs. However, HGNN methods exhibit excessive complexity influenced by the KG's size, density, and the number of node and edge types. AI practitioners handcraft a subgraph of a KG G relevant to a specific task. We refer to this subgraph as a task-oriented subgraph (TOSG), which contains a subset of task-related node and edge types in G. Training the task using TOSG instead of G alleviates the excessive computation required for a large KG. Crafting the TOSG demands a deep understanding of the KG's structure and the task's objectives. Hence, it is challenging and time-consuming. This paper proposes KG-TOSA, an approach to automate the TOSG extraction for task-oriented HGNN training on a large KG. In KG
    
[^153]: 更快的邻域注意力: 在线程块级别减少自注意力的O(n^2)成本

    Faster Neighborhood Attention: Reducing the O(n^2) Cost of Self Attention at the Threadblock Level

    [https://arxiv.org/abs/2403.04690](https://arxiv.org/abs/2403.04690)

    该研究提出了一种更快的邻域注意力机制，通过将注意力限制在最近的邻居之间来降低自注意力的计算复杂度，实现了显著的性能提升。

    

    邻域注意力通过限制每个标记的注意力范围为其最近的邻居来降低自注意力的成本。该限制由窗口大小和扩张因子参数化，介于线性投影和自注意力之间绘制了可能的注意力模式谱。邻域注意力，以及更一般地滑动窗口注意力模式，在基础设施方面长期受到限制，特别是在更高秩的空间（2-D和3-D），促使开发定制内核的发展，这些内核在功能或性能方面受限，如果不是两者都有。在这项工作中，我们首先展示邻域注意力可以表示为批量化的GEMM问题，类似于标准注意力，并为1-D和2-D邻域注意力实现它。与现有的简单内核相比，这些内核平均提供了分别是1-D和2-D邻域注意力的全精度延迟改进分别为895%和272%。

    arXiv:2403.04690v1 Announce Type: cross  Abstract: Neighborhood attention reduces the cost of self attention by restricting each token's attention span to its nearest neighbors. This restriction, parameterized by a window size and dilation factor, draws a spectrum of possible attention patterns between linear projection and self attention. Neighborhood attention, and more generally sliding window attention patterns, have long been bounded by infrastructure, particularly in higher-rank spaces (2-D and 3-D), calling for the development of custom kernels, which have been limited in either functionality, or performance, if not both. In this work, we first show that neighborhood attention can be represented as a batched GEMM problem, similar to standard attention, and implement it for 1-D and 2-D neighborhood attention. These kernels on average provide 895% and 272% improvement in full precision latency compared to existing naive kernels for 1-D and 2-D neighborhood attention respectively. 
    
[^154]: ChunkAttention: 具有前缀感知KV缓存和两阶段分区的高效自注意力

    ChunkAttention: Efficient Self-Attention with Prefix-Aware KV Cache and Two-Phase Partition

    [https://arxiv.org/abs/2402.15220](https://arxiv.org/abs/2402.15220)

    ChunkAttention是一种前缀感知的自注意力模块，通过将键/值张量分解为较小的块并结构化到辅助前缀树中，实现了在运行时改善内存利用率的KV缓存，同时设计了两阶段分区算法以提高自注意力计算中的数据局部性。

    

    自注意力是大型语言模型（LLMs）的重要组成部分，但对于长序列来说是推理延迟的一个显著来源。在多租户LLMs服务场景中，通过利用多个LLM请求在前缀中共享系统提示的概率，可以优化自注意力的计算和内存操作成本。本文介绍了ChunkAttention，一种具有前缀感知的自注意力模块，可以在运行时检测多个请求之间匹配的提示前缀，并共享它们的键/值张量以改进KV缓存的内存利用率。这是通过将整体键/值张量分解为较小的块，并将它们结构化到辅助前缀树中来实现的。因此，在基于前缀树的KV缓存之上，我们设计了一个高效的自注意力内核，其中实现了两阶段分区算法，以改善自注意力计算中的数据局部性。

    arXiv:2402.15220v1 Announce Type: cross  Abstract: Self-attention is an essential component of large language models(LLMs) but a significant source of inference latency for long sequences. In multi-tenant LLMs serving scenarios, the compute and memory operation cost of self-attention can be optimized by using the probability that multiple LLM requests have shared system prompts in prefixes. In this paper, we introduce ChunkAttention, a prefix-aware self-attention module that can detect matching prompt prefixes across multiple requests and share their key/value tensors in memory at runtime to improve the memory utilization of KV cache. This is achieved by breaking monolithic key/value tensors into smaller chunks and structuring them into the auxiliary prefix tree. Consequently, on top of the prefix-tree based KV cache, we design an efficient self-attention kernel, where a two-phase partition algorithm is implemented to improve the data locality during self-attention computation in the p
    
[^155]: 统计无偏回归：一种用于验证回归模型的机器学习方法

    Statistical Agnostic Regression: a machine learning method to validate regression models

    [https://arxiv.org/abs/2402.15213](https://arxiv.org/abs/2402.15213)

    本文提出了一种新的方法，统计无关地评估了线性回归模型，并评估了ML估计在检测方面的表现。

    

    回归分析是统计建模中的一个核心主题，旨在估计因变量（通常称为响应变量）与一个或多个自变量（即解释变量）之间的关系。线性回归是迄今为止在预测、预测或因果推断等多个研究领域执行此任务的最流行方法。除了解决线性回归问题的各种传统方法外，如普通最小二乘法、岭回归或套索回归——这些方法往往是更高级机器学习（ML）技术的基础——后者已成功地应用在这种场景中，但没有对统计显著性进行正式定义。最多，基于经验测量（如残差或准确度）进行置换或基于经典分析，以反映ML估计对检测的更高能力。本文介绍了一种新的方法，该方法统计无关地评估了线性回归模型，并对ML估计在检测方面的表现进行了评估。

    arXiv:2402.15213v1 Announce Type: cross  Abstract: Regression analysis is a central topic in statistical modeling, aiming to estimate the relationships between a dependent variable, commonly referred to as the response variable, and one or more independent variables, i.e., explanatory variables. Linear regression is by far the most popular method for performing this task in several fields of research, such as prediction, forecasting, or causal inference. Beyond various classical methods to solve linear regression problems, such as Ordinary Least Squares, Ridge, or Lasso regressions - which are often the foundation for more advanced machine learning (ML) techniques - the latter have been successfully applied in this scenario without a formal definition of statistical significance. At most, permutation or classical analyses based on empirical measures (e.g., residuals or accuracy) have been conducted to reflect the greater ability of ML estimations for detection. In this paper, we introd
    
[^156]: 时间解耦对比扩散模型用于时空插补

    Temporal Disentangled Contrastive Diffusion Model for Spatiotemporal Imputation

    [https://arxiv.org/abs/2402.11558](https://arxiv.org/abs/2402.11558)

    基于深度学习的时间解耦对比扩散模型应用于时空插补，旨在通过生成模型来提高预测效能。

    

    arXiv:2402.11558v1 发布类型: 新内容 摘要: 时空数据分析在各个领域至关重要，包括交通、气象和医疗保健。然而，在现实场景中收集的数据往往因传感器故障和网络传输错误而不完整。时空插补旨在通过利用观测数据中存在的固有空间和时间依赖关系来预测缺失值。传统方法主要依赖于经典统计和机器学习技术，通常不足够，特别是当数据未能符合严格的分布假设时。相比之下，最近基于深度学习的方法，利用图形和循环神经网络，已经表现出增强的功效。然而，这些方法容易积累误差。生成模型越来越多地被采用，以规避依赖于潜在不准确的历史插补值进行未来预测的情况。

    arXiv:2402.11558v1 Announce Type: new  Abstract: Spatiotemporal data analysis is pivotal across various domains, including transportation, meteorology, and healthcare. However, the data collected in real-world scenarios often suffers incompleteness due to sensor malfunctions and network transmission errors. Spatiotemporal imputation endeavours to predict missing values by exploiting the inherent spatial and temporal dependencies present in the observed data. Traditional approaches, which rely on classical statistical and machine learning techniques, are often inadequate, particularly when the data fails to meet strict distributional assumptions. In contrast, recent deep learning-based methods, leveraging graph and recurrent neural networks, have demonstrated enhanced efficacy. Nonetheless, these approaches are prone to error accumulation. Generative models have been increasingly adopted to circumvent the reliance on potentially inaccurate historical imputed values for future prediction
    
[^157]: 短视频和心理健康：基于知识导向的多模态神经主题模型

    Short-Form Videos and Mental Health: A Knowledge-Guided Multimodal Neural Topic Model

    [https://arxiv.org/abs/2402.10045](https://arxiv.org/abs/2402.10045)

    这项研究针对短视频对观众心理健康的抑郁影响问题，开发了一种基于医学知识的多模态神经主题模型，以预测其影响并采取相应的干预措施。

    

    短视频正试图重新塑造整个社交媒体景观，然而专家们对其对观众的抑郁影响感到极度担忧，这一点已由医学研究证明。为了防止广泛影响，各平台渴望预测这些视频对观众心理健康的影响，从而采取干预措施，比如修订推荐算法和显示观众慎重选择。然而，现有的预测方法缺乏与抑郁症的临床证实的外部环境因素相关的医学知识。为了考虑这样的医学知识，我们采用了一种新兴的方法论学科——种子神经主题模型（NTMs）。然而，现有的种子NTMs存在单一来源主题、未知主题来源、模糊的种子监督和次优的收敛等局限性。为了解决这些挑战，我们开发了一种新颖的基于知识指导的多模态神经主题模型（Knowledg...（待补充）

    arXiv:2402.10045v1 Announce Type: cross  Abstract: While short-form videos head to reshape the entire social media landscape, experts are exceedingly worried about their depressive impacts on viewers, as evidenced by medical studies. To prevent widespread consequences, platforms are eager to predict these videos' impact on viewers' mental health. Subsequently, they can take intervention measures, such as revising recommendation algorithms and displaying viewer discretion. Nevertheless, applicable predictive methods lack relevance to well-established medical knowledge, which outlines clinically proven external and environmental factors of depression. To account for such medical knowledge, we resort to an emergent methodological discipline, seeded Neural Topic Models (NTMs). However, existing seeded NTMs suffer from the limitations of single-origin topics, unknown topic sources, unclear seed supervision, and suboptimal convergence. To address those challenges, we develop a novel Knowledg
    
[^158]: 揭示特定群体的分布式概念漂移: 联邦学习中的公平要求

    Unveiling Group-Specific Distributed Concept Drift: A Fairness Imperative in Federated Learning

    [https://arxiv.org/abs/2402.07586](https://arxiv.org/abs/2402.07586)

    该研究在联邦学习中的分布式环境下，首次探索了在存在特定群体概念漂移的情况下实现公平性的挑战和解决方案。

    

    在机器学习领域的不断发展中，确保公平性已成为一个重要关注点，推动了开发旨在减少决策过程中歧视结果的算法。然而，在存在特定群体的概念漂移的情况下实现公平性仍然是一个未被探索的领域，我们的研究代表了在这方面的开拓性努力。特定群体的概念漂移是指一个群体随时间经历概念漂移，而另一个群体却没有，导致公平性下降，即使准确性保持相对稳定。在联邦学习的框架下，客户端共同训练模型，其分布式性质进一步放大了这些挑战，因为每个客户端可以独立经历特定群体的概念漂移，同时仍共享相同的基本概念，从而创造了一个复杂而动态的环境来维持公平性。我们研究的一个重要贡献之一是对群体特定的概念漂移进行形式化和内部化的过程。

    In the evolving field of machine learning, ensuring fairness has become a critical concern, prompting the development of algorithms designed to mitigate discriminatory outcomes in decision-making processes. However, achieving fairness in the presence of group-specific concept drift remains an unexplored frontier, and our research represents pioneering efforts in this regard. Group-specific concept drift refers to situations where one group experiences concept drift over time while another does not, leading to a decrease in fairness even if accuracy remains fairly stable. Within the framework of federated learning, where clients collaboratively train models, its distributed nature further amplifies these challenges since each client can experience group-specific concept drift independently while still sharing the same underlying concept, creating a complex and dynamic environment for maintaining fairness. One of the significant contributions of our research is the formalization and intr
    
[^159]: ToonAging: 艺术肖像风格转换下的人脸逆龄化

    ToonAging: Face Re-Aging upon Artistic Portrait Style Transfer

    [https://arxiv.org/abs/2402.02733](https://arxiv.org/abs/2402.02733)

    本研究提出了一种新颖的一阶段方法，结合肖像风格转换实现人脸逆龄化，解决了NPR图像上编辑年龄的问题，并在单个生成步骤中执行。该方法利用了现有的人脸逆龄化和风格转换网络，并且独特地融合了不同的潜在向量，从而保留了面部属性。

    

    人脸逆龄化是计算机视觉和图形学中的一个重要领域，在电影、广告和直播等逼真领域中具有重要应用。最近，将人脸逆龄化应用于非逼真图像，如漫画、插图和动画，在各种娱乐行业中成为一个新的需求。然而，缺乏一个能够无缝编辑NPR图像上显现年龄的网络意味着这些任务一直局限于一个简单的顺序方法，这往往会导致不愉快的伪影和由于域差异而丢失面部属性。在本文中，我们引入了一种新颖的单阶段人脸逆龄化方法，结合了肖像风格转换，在一个生成步骤中完成。我们利用现有的人脸逆龄化和风格转换网络，两者都在相同的PR领域进行训练。我们的方法独特地融合了不同的潜在向量，每个向量负责管理与衰老相关的属性。

    Face re-aging is a prominent field in computer vision and graphics, with significant applications in photorealistic domains such as movies, advertising, and live streaming. Recently, the need to apply face re-aging to non-photorealistic images, like comics, illustrations, and animations, has emerged as an extension in various entertainment sectors. However, the absence of a network capable of seamlessly editing the apparent age on NPR images means that these tasks have been confined to a naive approach, applying each task sequentially. This often results in unpleasant artifacts and a loss of facial attributes due to domain discrepancies. In this paper, we introduce a novel one-stage method for face re-aging combined with portrait style transfer, executed in a single generative step. We leverage existing face re-aging and style transfer networks, both trained within the same PR domain. Our method uniquely fuses distinct latent vectors, each responsible for managing aging-related attribu
    
[^160]: 结合荷兰调查和登记数据的数据挑战，预测生育率（PreFer）

    Combining the Strengths of Dutch Survey and Register Data in a Data Challenge to Predict Fertility (PreFer)

    [https://arxiv.org/abs/2402.00705](https://arxiv.org/abs/2402.00705)

    该论文介绍了两个数据集，分别基于荷兰的调查数据和登记数据，用于研究荷兰生育结果的预测能力。研究者提供了数据集的信息和样本，并描述了生育结果的具体内容。他们还介绍了生育率预测的方法。

    

    社会科学领域已经积累了大量有关生育结果的研究，即人们是否以及何时生育子女的决定因素。然而，这些决定因素和基本理论的预测能力很少在新数据上进行评估。这使得我们无法系统地比较研究，阻碍了知识的评估和积累。在本文中，我们介绍了两个数据集，用于研究荷兰生育结果的可预测性。一个数据集基于LISS面板，这是一个纵向调查，包括了数千个关于各种主题的变量，包括个体偏好和价值观。另一个数据集基于荷兰登记数据，缺乏态度数据，但包括了数百万荷兰居民生活轨迹的详细信息。我们提供关于数据集和样本的信息，并描述感兴趣的生育结果。我们还介绍了生育率预测的方法。

    The social sciences have produced an impressive body of research on determinants of fertility outcomes, or whether and when people have children. However, the strength of these determinants and underlying theories are rarely evaluated on their predictive ability on new data. This prevents us from systematically comparing studies, hindering the evaluation and accumulation of knowledge. In this paper, we present two datasets which can be used to study the predictability of fertility outcomes in the Netherlands. One dataset is based on the LISS panel, a longitudinal survey which includes thousands of variables on a wide range of topics, including individual preferences and values. The other is based on the Dutch register data which lacks attitudinal data but includes detailed information about the life courses of millions of Dutch residents. We provide information about the datasets and the samples, and describe the fertility outcome of interest. We also introduce the fertility prediction
    
[^161]: 独立学习将时间序列片段嵌入

    Learning to Embed Time Series Patches Independently

    [https://arxiv.org/abs/2312.16427](https://arxiv.org/abs/2312.16427)

    学习独立嵌入时间序列片段可以产生更好的时间序列表示，通过简单的块重构任务和独立嵌入每个块的MLP模型以及互补对比学习来实现。

    

    最近，掩码时间序列建模作为一种自监督表示学习策略引起了广泛关注。受计算机视觉中的掩码图像建模启发，最近的研究首先将时间序列进行分块处理并部分掩盖，然后训练Transformer模型通过从未掩盖的块预测被掩盖块来捕捉块之间的依赖关系。然而，我们认为捕捉这种块之间的依赖关系可能不是时间序列表示学习的最佳策略；相反，独立学习嵌入片段会产生更好的时间序列表示。具体而言，我们建议使用1）简单的块重构任务，自动将每个块进行编码而不查看其他块，以及2）独自嵌入每个块的简单块式MLP。此外，我们引入互补对比学习来有效地分层捕获相邻时间序列信息。

    arXiv:2312.16427v2 Announce Type: replace-cross  Abstract: Masked time series modeling has recently gained much attention as a self-supervised representation learning strategy for time series. Inspired by masked image modeling in computer vision, recent works first patchify and partially mask out time series, and then train Transformers to capture the dependencies between patches by predicting masked patches from unmasked patches. However, we argue that capturing such patch dependencies might not be an optimal strategy for time series representation learning; rather, learning to embed patches independently results in better time series representations. Specifically, we propose to use 1) the simple patch reconstruction task, which autoencode each patch without looking at other patches, and 2) the simple patch-wise MLP that embeds each patch independently. In addition, we introduce complementary contrastive learning to hierarchically capture adjacent time series information efficiently. 
    
[^162]: 时间序列的软对比学习

    Soft Contrastive Learning for Time Series

    [https://arxiv.org/abs/2312.16424](https://arxiv.org/abs/2312.16424)

    提出了一种名为SoftCLT的方法，通过引入实例级和时间级软对比损失，解决了在时间序列中忽略固有相关性所导致的学习表示质量下降的问题。

    

    对比学习已经被证明在自监督学习中对于从时间序列中学习表示是有效的。然而，将时间序列中相似的实例或相邻时间戳的值进行对比会忽略它们固有的相关性，从而导致学习表示的质量下降。为了解决这个问题，我们提出了SoftCLT，一种简单而有效的时间序列软对比学习策略。这是通过引入从零到一的软赋值的实例级和时间级对比损失来实现的。具体来说，我们为1)基于数据空间上的时间序列之间的距离定义了实例级对比损失的软赋值，并为2)基于时间戳之间的差异定义了时间级对比损失。SoftCLT是一种即插即用的时间序列对比学习方法，可以提高学习表示的质量，没有过多复杂的设计。

    arXiv:2312.16424v2 Announce Type: replace-cross  Abstract: Contrastive learning has shown to be effective to learn representations from time series in a self-supervised way. However, contrasting similar time series instances or values from adjacent timestamps within a time series leads to ignore their inherent correlations, which results in deteriorating the quality of learned representations. To address this issue, we propose SoftCLT, a simple yet effective soft contrastive learning strategy for time series. This is achieved by introducing instance-wise and temporal contrastive loss with soft assignments ranging from zero to one. Specifically, we define soft assignments for 1) instance-wise contrastive loss by the distance between time series on the data space, and 2) temporal contrastive loss by the difference of timestamps. SoftCLT is a plug-and-play method for time series contrastive learning that improves the quality of learned representations without bells and whistles. In experi
    
[^163]: 大规模局部排队系统中的稀疏均场负载平衡

    Sparse Mean Field Load Balancing in Large Localized Queueing Systems

    [https://arxiv.org/abs/2312.12973](https://arxiv.org/abs/2312.12973)

    本研究利用稀疏均场理论的进展，提出了一种在大型局部排队网络中学习近似最优负载平衡策略的方法，为稀疏有界度无线拓扑提供了通用的负载平衡框架。

    

    可扩展的负载平衡算法在云网络和数据中心中具有很大的兴趣，需要使用可处理的技术来计算良好性能的最佳负载平衡策略。然而，大多数现有的可扩展技术，特别是基于均场理论的渐近缩放方法，尚无法建模具有强局部性的大型排队网络。与此同时，一般的多Agent强化学习技术很难扩展，并且通常缺乏理论基础。在这项工作中，我们通过利用稀疏均场理论的最新进展，以可处理的方式学习稀疏连接排队网络中的近似最优负载平衡策略，这相对于全局方法可能更可取，从无线通信开销的角度来看。重要的是，我们获得了一个大类稀疏有界度无线拓扑的通用负载平衡框架。

    arXiv:2312.12973v2 Announce Type: replace-cross  Abstract: Scalable load balancing algorithms are of great interest in cloud networks and data centers, necessitating the use of tractable techniques to compute optimal load balancing policies for good performance. However, most existing scalable techniques, especially asymptotically scaling methods based on mean field theory, have not been able to model large queueing networks with strong locality. Meanwhile, general multi-agent reinforcement learning techniques can be hard to scale and usually lack a theoretical foundation. In this work, we address this challenge by leveraging recent advances in sparse mean field theory to learn a near-optimal load balancing policy in sparsely connected queueing networks in a tractable manner, which may be preferable to global approaches in terms of wireless communication overhead. Importantly, we obtain a general load balancing framework for a large class of sparse bounded-degree wireless topologies. B
    
[^164]: UniChest：征服分割预训练用于多源胸部X射线分类

    UniChest: Conquer-and-Divide Pre-training for Multi-Source Chest X-Ray Classification

    [https://arxiv.org/abs/2312.11038](https://arxiv.org/abs/2312.11038)

    提出了UniChest框架，采用征服和分割的预训练方法，使得模型能够充分利用多个来源的胸部X射线数据，提高模型泛化能力。

    

    Vision-Language Pre-training (VLP)利用多模态信息促进训练效率和有效性，在自然领域视觉识别取得巨大成功，并在胸部X射线（CXR）的医学影像诊断中显示出潜力。本文提出了一个名为UniChest的Conquer-and-Divide预训练框架，旨在充分利用多个CXR来源的合作效益，同时减少负面影响。

    arXiv:2312.11038v2 Announce Type: replace-cross  Abstract: Vision-Language Pre-training (VLP) that utilizes the multi-modal information to promote the training efficiency and effectiveness, has achieved great success in vision recognition of natural domains and shown promise in medical imaging diagnosis for the Chest X-Rays (CXRs). However, current works mainly pay attention to the exploration on single dataset of CXRs, which locks the potential of this powerful paradigm on larger hybrid of multi-source CXRs datasets. We identify that although blending samples from the diverse sources offers the advantages to improve the model generalization, it is still challenging to maintain the consistent superiority for the task of each source due to the existing heterogeneity among sources. To handle this dilemma, we design a Conquer-and-Divide pre-training framework, termed as UniChest, aiming to make full use of the collaboration benefit of multiple sources of CXRs while reducing the negative i
    
[^165]: 对称破缺和等变神经网络

    Symmetry Breaking and Equivariant Neural Networks

    [https://arxiv.org/abs/2312.09016](https://arxiv.org/abs/2312.09016)

    提出了一种新颖的“放松等变性”的概念，用于解决等变函数无法在单个数据样本层面打破对称的限制，并展示了如何将其应用于等变多层感知机（E-MLP）中。

    

    在深度学习中使用对称作为归纳偏差已被证明是一种有效的方法，可以设计出高效的模型。然而，神经网络中对称和等变性的关系并不总是显而易见。本文分析了等变函数中出现的一个关键限制：它们不能在单个数据样本的层面打破对称。为此，我们引入了一个新颖的“放松等变性”的概念来规避这个限制。我们进一步展示了如何将这种放松引入等变多层感知机（E-MLP），提供了一种替代注入噪声的方法。接着讨论了对称破缺在物理、图表示学习、组合优化和等变解码等各种应用领域的相关性。

    arXiv:2312.09016v2 Announce Type: replace  Abstract: Using symmetry as an inductive bias in deep learning has been proven to be a principled approach for sample-efficient model design. However, the relationship between symmetry and the imperative for equivariance in neural networks is not always obvious. Here, we analyze a key limitation that arises in equivariant functions: their incapacity to break symmetry at the level of individual data samples. In response, we introduce a novel notion of 'relaxed equivariance' that circumvents this limitation. We further demonstrate how to incorporate this relaxation into equivariant multilayer perceptrons (E-MLPs), offering an alternative to the noise-injection method. The relevance of symmetry breaking is then discussed in various application domains: physics, graph representation learning, combinatorial optimization and equivariant decoding.
    
[^166]: FERGI：来自自发面部表情反应的文本到图像生成用户偏好的自动注释

    FERGI: Automatic Annotation of User Preferences for Text-to-Image Generation from Spontaneous Facial Expression Reaction

    [https://arxiv.org/abs/2312.03187](https://arxiv.org/abs/2312.03187)

    开发了一种从用户自发面部表情反应中自动注释用户对生成图像偏好的方法，发现多个面部动作单元与用户对生成图像的评估高度相关，可用于通过这些面部动作单元区分图像对并自动标注用户偏好。

    

    研究人员提出使用人类偏好反馈数据来微调文本到图像生成模型。然而，由于其依赖于手动注释，人类反馈收集的可扩展性受到限制。因此，我们开发并测试了一种方法，从用户的自发面部表情反应中自动注释其对生成图像的偏好。我们收集了一个面部表情反应到生成图像（FERGI）的数据集，并展示了多个面部运动单元（AUs）的激活与用户对生成图像的评估高度相关。具体来说，AU4（眉毛下垂者）反映了对生成图像的负面评价，而AU12（嘴角拉动者）反映了正面评价。这两者在两个方面都很有用。首先，我们可以准确地使用这些AU响应存在实质差异的图像对之间自动注释用户偏好。

    arXiv:2312.03187v2 Announce Type: replace-cross  Abstract: Researchers have proposed to use data of human preference feedback to fine-tune text-to-image generative models. However, the scalability of human feedback collection has been limited by its reliance on manual annotation. Therefore, we develop and test a method to automatically annotate user preferences from their spontaneous facial expression reaction to the generated images. We collect a dataset of Facial Expression Reaction to Generated Images (FERGI) and show that the activations of multiple facial action units (AUs) are highly correlated with user evaluations of the generated images. Specifically, AU4 (brow lowerer) is reflective of negative evaluations of the generated image whereas AU12 (lip corner puller) is reflective of positive evaluations. These can be useful in two ways. Firstly, we can automatically annotate user preferences between image pairs with substantial difference in these AU responses with an accuracy sig
    
[^167]: 用大型语言模型赋能自动驾驶：一个安全的视角

    Empowering Autonomous Driving with Large Language Models: A Safety Perspective

    [https://arxiv.org/abs/2312.00812](https://arxiv.org/abs/2312.00812)

    本文通过整合大型语言模型（LLMs）到自动驾驶系统中，利用其常识知识和推理能力，作为智能决策者来增强驾驶性能和安全性。

    

    自动驾驶（AD）在长尾未知驾驶场景中遇到了重大的安全障碍，主要源自AD系统内部深度神经网络的不可解释性和泛化能力差，特别是在分布外和不确定数据方面。为此，本文探讨了将大型语言模型（LLM）整合到AD系统中，利用它们强大的常识知识和推理能力。所提出的方法将LLM用作行为规划中的智能决策者，配备一个安全验证器护盾进行上下文安全学习，以增强驾驶性能和安全性。我们在模拟环境中展示了两个关键研究：一种自适应LLM调节的模型预测控制（MPC）和一种带有状态机的LLM启用交互式行为规划方案。表现出比现有技术方法更优越的性能和安全度量指标。

    arXiv:2312.00812v4 Announce Type: replace  Abstract: Autonomous Driving (AD) encounters significant safety hurdles in long-tail unforeseen driving scenarios, largely stemming from the non-interpretability and poor generalization of the deep neural networks within the AD system, particularly in out-of-distribution and uncertain data. To this end, this paper explores the integration of Large Language Models (LLMs) into AD systems, leveraging their robust common-sense knowledge and reasoning abilities. The proposed methodologies employ LLMs as intelligent decision-makers in behavioral planning, augmented with a safety verifier shield for contextual safety learning, for enhancing driving performance and safety. We present two key studies in a simulated environment: an adaptive LLM-conditioned Model Predictive Control (MPC) and an LLM-enabled interactive behavior planning scheme with a state machine. Demonstrating superior performance and safety metrics compared to state-of-the-art approach
    
[^168]: 通用智能体用于神经网络优化

    Generalisable Agents for Neural Network Optimisation

    [https://arxiv.org/abs/2311.18598](https://arxiv.org/abs/2311.18598)

    通用智能体用于神经网络优化是一种多智能体强化学习方法，通过动态调度超参数来优化神经网络训练，可以有效改善全局性能并与手工设计启发式方法相竞争。

    

    深度神经网络的优化是一项具有挑战性的任务，原因在于复杂的训练动态、高计算要求和长时间训练。为了解决这一困难，我们提出了通用智能体用于神经网络优化（GANNO）的框架--一种多智能体强化学习（MARL）方法，通过动态和响应式地调度超参数来优化神经网络训练。GANNO利用每层一个智能体观察局部化的网络动态，并相应地采取行动来调整这些动态，从而在层级上集体改善全局性能。本文中，我们使用GANNO来控制层级学习率，并展示该框架可以产生有用且响应灵活的调度，与手工设计的启发式方法相竞争。此外，显示GANNO在各种看不见的初始条件下表现出稳健性，并且能够成功...

    arXiv:2311.18598v2 Announce Type: replace-cross  Abstract: Optimising deep neural networks is a challenging task due to complex training dynamics, high computational requirements, and long training times. To address this difficulty, we propose the framework of Generalisable Agents for Neural Network Optimisation (GANNO) -- a multi-agent reinforcement learning (MARL) approach that learns to improve neural network optimisation by dynamically and responsively scheduling hyperparameters during training. GANNO utilises an agent per layer that observes localised network dynamics and accordingly takes actions to adjust these dynamics at a layerwise level to collectively improve global performance. In this paper, we use GANNO to control the layerwise learning rate and show that the framework can yield useful and responsive schedules that are competitive with handcrafted heuristics. Furthermore, GANNO is shown to perform robustly across a wide variety of unseen initial conditions, and can succe
    
[^169]: 量子朗之万动力学用于优化

    Quantum Langevin Dynamics for Optimization

    [https://arxiv.org/abs/2311.15587](https://arxiv.org/abs/2311.15587)

    该研究引入了量子朗之万动力学（QLD）来解决非凸优化问题，证明了在凸景观中 QLD 的收敛性，并展示了其能量耗散能力和低温极限下指数衰减速率。

    

    我们开始研究利用量子朗之万动力学（QLD）来解决优化问题，特别是那些对传统梯度下降算法产生重大障碍的非凸目标函数。具体来说，我们研究了与无限热浴耦合的系统动力学。该相互作用既引起了随机量子噪声，又引起了对系统的确定性阻尼效应，从而将系统推向接近目标函数全局最小值的稳定状态。我们在凸景观中理论上证明了 QLD 的收敛性，证明了系统的平均能量可以在低温极限下接近零，并且具有与演化时间相关的指数衰减速率。在数值上，我们首先通过将其起源追溯到自发辐射来展示 QLD 的能量耗散能力。此外，我们对每个 p 的影响进行了详细讨论。

    arXiv:2311.15587v2 Announce Type: replace-cross  Abstract: We initiate the study of utilizing Quantum Langevin Dynamics (QLD) to solve optimization problems, particularly those non-convex objective functions that present substantial obstacles for traditional gradient descent algorithms. Specifically, we examine the dynamics of a system coupled with an infinite heat bath. This interaction induces both random quantum noise and a deterministic damping effect to the system, which nudge the system towards a steady state that hovers near the global minimum of objective functions. We theoretically prove the convergence of QLD in convex landscapes, demonstrating that the average energy of the system can approach zero in the low temperature limit with an exponential decay rate correlated with the evolution time. Numerically, we first show the energy dissipation capability of QLD by retracing its origins to spontaneous emission. Furthermore, we conduct detailed discussion of the impact of each p
    
[^170]: ID样式提示学习用于少样本异常检测

    ID-like Prompt Learning for Few-Shot Out-of-Distribution Detection

    [https://arxiv.org/abs/2311.15243](https://arxiv.org/abs/2311.15243)

    提出了一种利用CLIP识别ID样式异常值并通过提示学习进行OOD检测的新框架，能够有效提高识别最具挑战性OOD样本的能力。

    

    异常检测方法通常利用辅助异常值来训练模型识别异常样本，尤其是从辅助异常值数据集中发现具有挑战性的异常值以改善异常检测。然而，它们可能仍面临有效区分与ID数据非常相似的最具挑战性的OOD样本的局限性，即ID样式样本。为此，我们提出了一个新颖的OOD检测框架，利用CLIP从ID样本的邻近空间中发现ID样式的异常值，从而帮助识别这些最具挑战性的OOD样本。然后提出了一个提示学习框架，利用识别的ID样式异常值进一步利用CLIP的能力进行OOD检测。受益于强大的CLIP，我们只需要少量ID样本即可学习模型的提示，而无需暴露其他辅助信息。

    arXiv:2311.15243v3 Announce Type: replace-cross  Abstract: Out-of-distribution (OOD) detection methods often exploit auxiliary outliers to train model identifying OOD samples, especially discovering challenging outliers from auxiliary outliers dataset to improve OOD detection. However, they may still face limitations in effectively distinguishing between the most challenging OOD samples that are much like in-distribution (ID) data, i.e., \idlike samples. To this end, we propose a novel OOD detection framework that discovers \idlike outliers using CLIP \cite{DBLP:conf/icml/RadfordKHRGASAM21} from the vicinity space of the ID samples, thus helping to identify these most challenging OOD samples. Then a prompt learning framework is proposed that utilizes the identified \idlike outliers to further leverage the capabilities of CLIP for OOD detection. Benefiting from the powerful CLIP, we only need a small number of ID samples to learn the prompts of the model without exposing other auxiliary
    
[^171]: 使用正规化流生成日前电力价格的多元场景生成

    Multivariate Scenario Generation of Day-Ahead Electricity Prices using Normalizing Flows

    [https://arxiv.org/abs/2311.14033](https://arxiv.org/abs/2311.14033)

    使用正规化流生成日前电力价格的多元场景生成，并提出扩展特征集和重新训练方案来适应现代电力市场的变化条件

    

    在日前电力市场交易中，需要准确的关于电力价格实现和预测不确定性的信息。由于日前价格的非平稳性，导致了由2021年能源危机引起的市场情况变化等原因，准确建立预测模型是一项困难的任务。我们提出了一种使用完全数据驱动的深层生成模型——正规化流来进行日前电力价格概率预测的方法。我们的建模方法基于条件特征（如剩余负荷预测）生成日前电力价格的全天场景。此外，我们提出了先前实现的扩展特征集和周期性重新训练方案，使正则化流能够适应现代电力市场的变化条件。我们的结果突出表明，正规化流生成了高

    arXiv:2311.14033v2 Announce Type: replace  Abstract: Trading on the day-ahead electricity markets requires accurate information about the realization of electricity prices and the uncertainty attached to the predictions. Deriving accurate forecasting models presents a difficult task due to the day-ahead price's non-stationarity resulting from changing market conditions, e.g., due to changes resulting from the energy crisis in 2021. We present a probabilistic forecasting approach for day-ahead electricity prices using the fully data-driven deep generative model called normalizing flow. Our modeling approach generates full-day scenarios of day-ahead electricity prices based on conditional features such as residual load forecasts. Furthermore, we propose extended feature sets of prior realizations and a periodic retraining scheme that allows the normalizing flow to adapt to the changing conditions of modern electricity markets. Our results highlight that the normalizing flow generates hig
    
[^172]: 物理增强的光学表面印迹多保真学习

    Physics-Enhanced Multi-fidelity Learning for Optical Surface Imprint

    [https://arxiv.org/abs/2311.10278](https://arxiv.org/abs/2311.10278)

    本文提出了一种利用多保真神经网络(MFNN)解决光学图像与实际机械性能之间映射的方法。

    

    人类指纹作为每个人的独特而强大的特征，可以帮助警察识别身份。类似地，许多自然体和内在机械特性也可以通过表面特征得到唯一识别。本文提出了一种新颖的方法，使用多保真神经网络(MFNN)解决这个反问题。

    arXiv:2311.10278v2 Announce Type: replace-cross  Abstract: Human fingerprints serve as one unique and powerful characteristic for each person, from which policemen can recognize the identity. Similar to humans, many natural bodies and intrinsic mechanical qualities can also be uniquely identified from surface characteristics. To measure the elasto-plastic properties of one material, one formally sharp indenter is pushed into the measured body under constant force and retracted, leaving a unique residual imprint of the minute size from several micrometers to nanometers. However, one great challenge is how to map the optical image of this residual imprint into the real wanted mechanical properties, \ie, the tensile force curve. In this paper, we propose a novel method to use multi-fidelity neural networks (MFNN) to solve this inverse problem. We first build up the NN model via pure simulation data, and then bridge the sim-to-real gap via transfer learning. Considering the difficulty of c
    
[^173]: 用于数据分析的多尺度霍奇散射网络

    Multiscale Hodge Scattering Networks for Data Analysis

    [https://arxiv.org/abs/2311.10270](https://arxiv.org/abs/2311.10270)

    提出了多尺度霍奇散射网络（MHSNs），利用多尺度基础词典和卷积结构，生成对节点排列不变的特征。

    

    我们提出了一种新的散射网络，用于在单纯复合仿射上测量的信号，称为\emph{多尺度霍奇散射网络}（MHSNs）。我们的构造基于单纯复合仿射上的多尺度基础词典，即$\kappa$-GHWT和$\kappa$-HGLET，我们最近为给定单纯复合仿射中的维度$\kappa \in \mathbb{N}$推广了基于节点的广义哈-沃什变换（GHWT）和分层图拉普拉斯特征变换（HGLET）。$\kappa$-GHWT和$\kappa$-HGLET都形成冗余集合（即词典）的多尺度基础向量和给定信号的相应扩展系数。我们的MHSNs使用类似于卷积神经网络（CNN）的分层结构来级联词典系数模的矩。所得特征对单纯复合仿射的重新排序不变（即节点排列的置换

    arXiv:2311.10270v2 Announce Type: replace  Abstract: We propose new scattering networks for signals measured on simplicial complexes, which we call \emph{Multiscale Hodge Scattering Networks} (MHSNs). Our construction is based on multiscale basis dictionaries on simplicial complexes, i.e., the $\kappa$-GHWT and $\kappa$-HGLET, which we recently developed for simplices of dimension $\kappa \in \mathbb{N}$ in a given simplicial complex by generalizing the node-based Generalized Haar-Walsh Transform (GHWT) and Hierarchical Graph Laplacian Eigen Transform (HGLET). The $\kappa$-GHWT and the $\kappa$-HGLET both form redundant sets (i.e., dictionaries) of multiscale basis vectors and the corresponding expansion coefficients of a given signal. Our MHSNs use a layered structure analogous to a convolutional neural network (CNN) to cascade the moments of the modulus of the dictionary coefficients. The resulting features are invariant to reordering of the simplices (i.e., node permutation of the u
    
[^174]: 多分辨率时间序列Transformer用于长期预测

    Multi-resolution Time-Series Transformer for Long-term Forecasting

    [https://arxiv.org/abs/2311.04147](https://arxiv.org/abs/2311.04147)

    提出了一种Multi-resolution Time-Series Transformer框架，采用多分支架构和相对位置编码，用于同时建模不同分辨率下的多样化时间模式。

    

    最近transformers在时间序列预测方面的表现显著提高。最近的架构通过将时间序列分割为片段并将这些片段用作标记来学习复杂的时间模式。片段大小控制了transformers学习不同频率的时间模式的能力：较短的片段适用于学习局部的高频模式，而挖掘长期的季节性和趋势则需要较长的片段。受到这一观察的启发，我们提出了一种新颖的框架，即多分辨率时间序列Transformer（MTST），它由多分支架构组成，用于同时建模不同分辨率下的多样化时间模式。与许多现有的时间序列transformers不同，我们采用相对位置编码，更适合提取不同尺度上的周期成分。我们在几个真实世界数据集上进行了大量实验。

    arXiv:2311.04147v2 Announce Type: replace  Abstract: The performance of transformers for time-series forecasting has improved significantly. Recent architectures learn complex temporal patterns by segmenting a time-series into patches and using the patches as tokens. The patch size controls the ability of transformers to learn the temporal patterns at different frequencies: shorter patches are effective for learning localized, high-frequency patterns, whereas mining long-term seasonalities and trends requires longer patches. Inspired by this observation, we propose a novel framework, Multi-resolution Time-Series Transformer (MTST), which consists of a multi-branch architecture for simultaneous modeling of diverse temporal patterns at different resolutions. In contrast to many existing time-series transformers, we employ relative positional encoding, which is better suited for extracting periodic components at different scales. Extensive experiments on several real-world datasets demons
    
[^175]: E-Sparse: 通过基于信息熵的 N:M 稀疏性提升大型语言模型推理能力

    E-Sparse: Boosting the Large Language Model Inference through Entropy-based N:M Sparsity

    [https://arxiv.org/abs/2310.15929](https://arxiv.org/abs/2310.15929)

    首次将信息熵引入剪枝度量设计，提高在大型语言模型中 N:M 稀疏性的准确性。

    

    传统的剪枝方法在大型语言模型（LLMs）中很难实现，因为它们训练过程昂贵，计算需求大。本文首次将隐藏状态特征的信息熵引入到剪枝度量设计中，即 E-Sparse，以提高LLM中 N:M 稀疏性的准确性。E-Sparse利用信息丰富性来提升通道的重要性，并进一步结合几种新颖技术来实现：(1)引入信息熵来增强参数权重和输入特征范数的重要性作为一种新颖的剪枝度量，并在不修改剩余权重的情况下执行N:M稀疏性。(2)设计全局朴素洗牌和局部块洗牌，快速优化信息分布，充分应对 N:M 稀疏性对LLMs准确性的影响。E-Sparse 被实现为一种 Spars

    arXiv:2310.15929v2 Announce Type: replace-cross  Abstract: Traditional pruning methods are known to be challenging to work in Large Language Models (LLMs) for Generative AI because of their unaffordable training process and large computational demands. For the first time, we introduce the information entropy of hidden state features into a pruning metric design, namely E-Sparse, to improve the accuracy of N:M sparsity on LLM. E-Sparse employs the information richness to leverage the channel importance, and further incorporates several novel techniques to put it into effect: (1) it introduces information entropy to enhance the significance of parameter weights and input feature norms as a novel pruning metric, and performs N:M sparsity without modifying the remaining weights. (2) it designs global naive shuffle and local block shuffle to quickly optimize the information distribution and adequately cope with the impact of N:M sparsity on LLMs' accuracy. E-Sparse is implemented as a Spars
    
[^176]: 稳定强化学习控制：用于优化所有稳定行为的模块化框架

    Stabilizing reinforcement learning control: A modular framework for optimizing over all stable behavior

    [https://arxiv.org/abs/2310.14098](https://arxiv.org/abs/2310.14098)

    提出了一个框架，结合了深度强化学习的优化驱动和无模型的优势，以及使用Youla-Kucera参数化提供的稳定性保证，为设计反馈控制器提供了一种优化过程。

    

    我们提出了一个用于设计反馈控制器的框架，结合了深度强化学习的优化驱动和无模型的优势，以及使用Youla-Kucera参数化提供的稳定性保证来定义搜索域。最近在行为系统方面的进展使我们能够构建一个数据驱动的内部模型；这使得在完全基于输入-输出探索数据的基础上构建Youla-Kucera参数化的替代性实现成为可能。或许更值得关注的是，我们在存在噪声的情况下制定和分析了这类数据驱动模型的稳定性。Youla-Kucera方法对于控制器设计需要一个稳定的“参数”。为了训练强化学习代理，所有稳定线性运算符的集合通过矩阵因子化方法被明确给出。此外，我们还通过神经网络进行了非线性扩展，以表达参数化的一组稳定运算符。

    arXiv:2310.14098v2 Announce Type: replace-cross  Abstract: We propose a framework for the design of feedback controllers that combines the optimization-driven and model-free advantages of deep reinforcement learning with the stability guarantees provided by using the Youla-Kucera parameterization to define the search domain. Recent advances in behavioral systems allow us to construct a data-driven internal model; this enables an alternative realization of the Youla-Kucera parameterization based entirely on input-output exploration data. Perhaps of independent interest, we formulate and analyze the stability of such data-driven models in the presence of noise. The Youla-Kucera approach requires a stable "parameter" for controller design. For the training of reinforcement learning agents, the set of all stable linear operators is given explicitly through a matrix factorization approach. Moreover, a nonlinear extension is given using a neural network to express a parameterized set of stab
    
[^177]: 为SLAM学习高级语义关系概念

    Learning High-level Semantic-Relational Concepts for SLAM

    [https://arxiv.org/abs/2310.00401](https://arxiv.org/abs/2310.00401)

    提出了一种基于图神经网络的算法，用于学习SLAM中的高级语义关系概念。

    

    最近关于SLAM的研究将其姿态图与更高级的语义概念（如Rooms）扩展，利用它们之间的关系，不仅提供了更丰富的情境/环境表示，而且提高了其估计的准确性。具体而言，我们先前的工作Situational Graphs (S-Graphs+)，作为在因子优化过程中共同利用语义关系的先驱，依赖于数学定义的Plane和Room等语义实体的关系。然而，在发现与不同性质的高级概念对应的所有隐藏模式的下级因子图中并没有唯一方法。目前，它通过特定算法来解决，限制了其图表达能力。为了克服这一局限性，在这项工作中，我们提出了一种基于图神经网络的算法，用于学习可以从中推断各种高级语义关系概念的内容。

    arXiv:2310.00401v2 Announce Type: replace  Abstract: Recent works on SLAM extend their pose graphs with higher-level semantic concepts like Rooms exploiting relationships between them, to provide, not only a richer representation of the situation/environment but also to improve the accuracy of its estimation. Concretely, our previous work, Situational Graphs (S-Graphs+), a pioneer in jointly leveraging semantic relationships in the factor optimization process, relies on semantic entities such as Planes and Rooms, whose relationship is mathematically defined. Nevertheless, there is no unique approach to finding all the hidden patterns in lower-level factor-graphs that correspond to high-level concepts of different natures. It is currently tackled with ad-hoc algorithms, which limits its graph expressiveness.   To overcome this limitation, in this work, we propose an algorithm based on Graph Neural Networks for learning high-level semantic-relational concepts that can be inferred from th
    
[^178]: 本文描述了一组季节性和非季节性时间序列模型，可以看作是加法和乘法指数平滑模型的推广，用于建模增长速度介于线性和指数之间的时间序列。这些模型的开发是基于快速增长、波动性较大的时间序列，具有从加法到乘法平滑变化的全局趋势，与线性局部趋势相结合。在我们的模型中，季节性(如果有使用)是乘法的，误差始终是加法的，但具有异方差性，并可通过参数sigma增长。我们利用最先进的贝叶斯拟合技术准确拟合这些比标准指数平滑模型更复杂、更灵活的模型。当应用于M3竞赛数据集时，我们的模型表现优于竞赛中的最佳算法和其他基准模型，据我们所知，取得了每个序列的最佳结果。

    Local and Global Trend Bayesian Exponential Smoothing Models

    [https://arxiv.org/abs/2309.13950](https://arxiv.org/abs/2309.13950)

    本文描述了一组季节性和非季节性时间序列模型，可以用于建模增长速度介于线性和指数之间的时间序列。模型包括全局趋势从加法到乘法的平滑变化，与线性局部趋势相结合，并采用乘法季节性和异方差的加法误差。通过贝叶斯拟合技术，该模型在M3竞赛数据集上表现优于其他模型。

    

    本文描述了一组季节性和非季节性时间序列模型，这些模型可以被视为加法和乘法指数平滑模型的推广，用来建模增长速度介于线性和指数之间的时间序列。我们的模型具有全局趋势，可以从加法平滑平滑地转变为乘法平滑，并与线性局部趋势相结合。我们的模型中的季节性是乘法的，误差始终是加法的，但具有异方差性，并可以通过参数sigma增长。我们利用最先进的贝叶斯拟合技术准确拟合这些比标准指数平滑模型更复杂、更灵活的模型。在应用于M3竞赛数据集时，我们的模型表现优于竞赛中的最佳算法和其他基准模型，据我们所知，取得了每个序列的最佳结果。

    This paper describes a family of seasonal and non-seasonal time series models that can be viewed as generalisations of additive and multiplicative exponential smoothing models, to model series that grow faster than linear but slower than exponential. Their development is motivated by fast-growing, volatile time series. In particular, our models have a global trend that can smoothly change from additive to multiplicative, and is combined with a linear local trend. Seasonality when used is multiplicative in our models, and the error is always additive but is heteroscedastic and can grow through a parameter sigma. We leverage state-of-the-art Bayesian fitting techniques to accurately fit these models that are more complex and flexible than standard exponential smoothing models. When applied to the M3 competition data set, our models outperform the best algorithms in the competition as well as other benchmarks, thus achieving to the best of our knowledge the best results of per-series univ
    
[^179]: Dynamic-SUPERB: 面向动态、协作和全面指令调优的语音基准

    Dynamic-SUPERB: Towards A Dynamic, Collaborative, and Comprehensive Instruction-Tuning Benchmark for Speech

    [https://arxiv.org/abs/2309.09510](https://arxiv.org/abs/2309.09510)

    提出了 Dynamic-SUPERB 基准测试，旨在构建通用语音模型，利用指令调优实现零-shot执行多任务，通过合作和贡献动态增长基准。

    

    文本语言模型在提供良好制定的指令时，展示出了在泛化到未见任务时的卓越零-shot能力。然而，目前关于语音处理的研究主要集中在有限或特定任务上。此外，缺乏标准化的基准测试妨碍了在不同方法之间进行公平比较。因此，我们提出Dynamic-SUPERB，这是一个专为构建能够利用指令调优以零-shot方式执行多项任务的通用语音模型而设计的基准测试。为了实现对多样的语音任务的全面覆盖并利用指令调优，我们邀请社区合作和贡献，促进基准测试的动态增长。作为开端，Dynamic-SUPERB通过结合33个任务和22个数据集，提供了55个评估实例。这涵盖了广泛的维度，为评估提供了全面的平台。此外，我们提出了一些

    arXiv:2309.09510v2 Announce Type: replace-cross  Abstract: Text language models have shown remarkable zero-shot capability in generalizing to unseen tasks when provided with well-formulated instructions. However, existing studies in speech processing primarily focus on limited or specific tasks. Moreover, the lack of standardized benchmarks hinders a fair comparison across different approaches. Thus, we present Dynamic-SUPERB, a benchmark designed for building universal speech models capable of leveraging instruction tuning to perform multiple tasks in a zero-shot fashion. To achieve comprehensive coverage of diverse speech tasks and harness instruction tuning, we invite the community to collaborate and contribute, facilitating the dynamic growth of the benchmark. To initiate, Dynamic-SUPERB features 55 evaluation instances by combining 33 tasks and 22 datasets. This spans a broad spectrum of dimensions, providing a comprehensive platform for evaluation. Additionally, we propose severa
    
[^180]: 一个公理化的深度神经网络偏微分方程模型

    An axiomatized PDE model of deep neural networks

    [https://arxiv.org/abs/2307.12333](https://arxiv.org/abs/2307.12333)

    通过将深度神经网络表述为一个简单基础模型到演化算子，我们提出了一个对流-扩散方程模型，为有效网络提供了数学解释，并设计了一种新的训练方法，实验证实了其性能提升。

    

    受深度神经网络（DNN）与偏微分方程（PDE）之间关系的启发，我们研究了深度神经网络PDE模型的一般形式。为实现这一目标，我们将DNN表述为从简单基础模型到演化算子。基于几个合理假设，我们证明演化算子实际上由对流-扩散方程决定。该对流-扩散方程模型为几个有效网络提供了数学解释。此外，我们表明对流-扩散模型提高了鲁棒性并减小了Rademacher复杂性。基于对流-扩散方程，我们为ResNets设计了一种新的训练方法。实验证实了所提方法的性能。

    arXiv:2307.12333v2 Announce Type: replace  Abstract: Inspired by the relation between deep neural network (DNN) and partial differential equations (PDEs), we study the general form of the PDE models of deep neural networks. To achieve this goal, we formulate DNN as an evolution operator from a simple base model. Based on several reasonable assumptions, we prove that the evolution operator is actually determined by convection-diffusion equation. This convection-diffusion equation model gives mathematical explanation for several effective networks. Moreover, we show that the convection-diffusion model improves the robustness and reduces the Rademacher complexity. Based on the convection-diffusion equation, we design a new training method for ResNets. Experiments validate the performance of the proposed method.
    
[^181]: KGLiDS：用于数据科学的语义抽象、链接和自动化平台

    KGLiDS: A Platform for Semantic Abstraction, Linking, and Automation of Data Science

    [https://arxiv.org/abs/2303.02204](https://arxiv.org/abs/2303.02204)

    提出了一个可扩展平台KGLiDS，利用机器学习和知识图技术来抽象和捕获数据科学工具及其联系的语义，从而支持数据发现和管道自动化。

    

    最近几年，我们见证了学术界和工业界对应用数据科学技术来分析大量数据的日益浓厚兴趣。在这个过程中，我们创造了大量的工具（数据集、管道脚本等）。然而，尚未有系统性的尝试来全面收集和利用这些工具中隐含的所有知识和经验。相反，数据科学家从同事那里恢复信息和专业知识，或通过反复试验学习。因此，本文提出了一种可扩展的平台，KGLiDS，利用机器学习和知识图技术来抽象和捕获数据科学工具及其联系的语义。基于这些信息，KGLiDS能够支持各种下游应用，如数据发现和管道自动化。我们的全面评估涵盖了数据发现、数据清洗、转换和AutoM等用例。

    arXiv:2303.02204v3 Announce Type: replace  Abstract: In recent years, we have witnessed the growing interest from academia and industry in applying data science technologies to analyze large amounts of data. In this process, a myriad of artifacts (datasets, pipeline scripts, etc.) are created. However, there has been no systematic attempt to holistically collect and exploit all the knowledge and experiences that are implicitly contained in those artifacts. Instead, data scientists recover information and expertise from colleagues or learn via trial and error. Hence, this paper presents a scalable platform, KGLiDS, that employs machine learning and knowledge graph technologies to abstract and capture the semantics of data science artifacts and their connections. Based on this information, KGLiDS enables various downstream applications, such as data discovery and pipeline automation. Our comprehensive evaluation covers use cases in data discovery, data cleaning, transformation, and AutoM
    
[^182]: 确定正确的XAI方法--气候科学中可解释人工智能方法的评估和排序指南

    Finding the right XAI method -- A Guide for the Evaluation and Ranking of Explainable AI Methods in Climate Science

    [https://arxiv.org/abs/2303.00652](https://arxiv.org/abs/2303.00652)

    这项工作介绍了气候背景下的XAI评估，并讨论了不同的期望解释特性，为了评估和排序可解释人工智能方法在气候科学中的应用。

    

    可解释人工智能（XAI）方法揭示了机器学习算法的预测。存在几种不同的方法，已经应用于气候科学中。然而，通常缺少地面真实解释使他们的评估和比较变得复杂，进而阻碍了XAI方法的选择。因此，在这项工作中，我们介绍了气候背景下的XAI评估，并讨论了不同的期望解释特性，即稳健性、忠实性、随机性、复杂性和定位性。为此，我们选择以某一案例研究先前的工作，预测了十年的年均温度图。在训练了多层感知器（MLP）和卷积神经网络（CNN）之后，应用多种XAI方法，并计算它们在每个属性上与随机均匀解释的技能分数。独立于网络，我们发现XAI m

    arXiv:2303.00652v2 Announce Type: replace-cross  Abstract: Explainable artificial intelligence (XAI) methods shed light on the predictions of machine learning algorithms. Several different approaches exist and have already been applied in climate science. However, usually missing ground truth explanations complicate their evaluation and comparison, subsequently impeding the choice of the XAI method. Therefore, in this work, we introduce XAI evaluation in the climate context and discuss different desired explanation properties, namely robustness, faithfulness, randomization, complexity, and localization. To this end, we chose previous work as a case study where the decade of annual-mean temperature maps is predicted. After training both a multi-layer perceptron (MLP) and a convolutional neural network (CNN), multiple XAI methods are applied and their skill scores in reference to a random uniform explanation are calculated for each property. Independent of the network, we find that XAI m
    
[^183]: 具有原型的跨领域随机预训练用于强化学习

    Cross-domain Random Pre-training with Prototypes for Reinforcement Learning

    [https://arxiv.org/abs/2302.05614](https://arxiv.org/abs/2302.05614)

    提出了CRPTpro框架，利用原型进行跨领域自监督随机预训练，提高预训练效率，并实现在不同领域中定义的视觉控制RL任务。

    

    此工作已提交给IEEE进行可能的出版。 CRPTpro提出了一种用于基于图像的RL的跨领域自监督随机预训练框架，利用原型。 CRPTpro采用了跨领域随机策略，可以轻松快速地从多个领域中抽样多样化数据，以提高预训练效率。此外，通过提出一种新颖的内在损失进行原型表示学习，以在不同领域中预训练有效且通用的编码器。在没有微调的情况下，跨领域编码器可以高效地应用于不同领域中定义的具有挑战性的下游视觉控制RL任务。 与以前的方法如APT和Proto-RL相比，CRP

    arXiv:2302.05614v2 Announce Type: replace-cross  Abstract: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. Task-agnostic cross-domain pre-training shows great potential in image-based Reinforcement Learning (RL) but poses a big challenge. In this paper, we propose CRPTpro, a Cross-domain self-supervised Random Pre-Training framework with prototypes for image-based RL. CRPTpro employs cross-domain random policy to easily and quickly sample diverse data from multiple domains, to improve pre-training efficiency. Moreover, prototypical representation learning with a novel intrinsic loss is proposed to pre-train an effective and generic encoder across different domains. Without finetuning, the cross-domain encoder can be implemented for challenging downstream visual-control RL tasks defined in different domains efficiently. Compared with prior arts like APT and Proto-RL, CRP
    
[^184]: 具有自上而下反馈的前馈学习：实证和分析特性

    Forward Learning with Top-Down Feedback: Empirical and Analytical Characterization

    [https://arxiv.org/abs/2302.05440](https://arxiv.org/abs/2302.05440)

    本研究揭示了具有自上而下反馈的前馈学习算法与自适应反馈对齐算法之间的联系，分析了它们在学习过程中的性能，并比较了不同版本的仅向前算法，揭示它们共享相同的学习原理。

    

    "仅向前"算法近来受到关注，这些算法在训练神经网络时避免了向后传递，被认为是解决反向传播中生物不现实因素的一种方法。本文首先针对与“仅向前”规则相关的引人注目的挑战，包括缩小与反向传播的性能差距和对其动态特性进行分析。我们展示了具有自上而下反馈的仅向前算法可被很好地近似为“自适应反馈对齐”算法，并在原型高维设置中对其学习过程进行了分析跟踪。然后，我们比较了不同版本的仅向前算法，重点关注前-前和PEPITA框架，并且表明它们共享相同的学习原理。总体而言，我们的工作揭示了三种重要的受神经启发的学习规则之间的联系，为“向前-

    arXiv:2302.05440v2 Announce Type: replace  Abstract: "Forward-only" algorithms, which train neural networks while avoiding a backward pass, have recently gained attention as a way of solving the biologically unrealistic aspects of backpropagation. Here, we first address compelling challenges related to the "forward-only" rules, which include reducing the performance gap with backpropagation and providing an analytical understanding of their dynamics. To this end, we show that the forward-only algorithm with top-down feedback is well-approximated by an "adaptive-feedback-alignment" algorithm, and we analytically track its performance during learning in a prototype high-dimensional setting. Then, we compare different versions of forward-only algorithms, focusing on the Forward-Forward and PEPITA frameworks, and we show that they share the same learning principles. Overall, our work unveils the connections between three key neuro-inspired learning rules, providing a link between "forward-
    
[^185]: 用推测对手模型进行决策

    Decision-making with Speculative Opponent Models

    [https://arxiv.org/abs/2211.11940](https://arxiv.org/abs/2211.11940)

    提出了一种使用纯粹局部信息实现推测对手建模的多智能体分布式演员-评论家算法，能够帮助受控代理做出决策。

    

    对手建模通过构建其他代理的模型，使受控代理的决策受益。现有方法通常假设可以访问对手的观察和行为，但当对手的行为不可观察或难以获得时，这是不可行的。我们提出了一种新颖的多智能体分布式演员-评论家算法，通过纯粹的局部信息（即受控代理的观察、行为和奖励）实现推测对手建模。具体而言，演员维持对对手的推测信念，我们称之为推测对手模型，以使用局部观察来预测对手的动作，并相应地做出决策。此外，分布式评论家模型政策的回报分布。它反映了演员的质量，因此可以指导演员所依赖的推测对手模型的训练。大量实验证实了我们的方法成功地...

    arXiv:2211.11940v2 Announce Type: replace  Abstract: Opponent modeling has benefited a controlled agent's decision-making by constructing models of other agents. Existing methods commonly assume access to opponents' observations and actions, which is infeasible when opponents' behaviors are unobservable or hard to obtain. We propose a novel multi-agent distributional actor-critic algorithm to achieve speculative opponent modeling with purely local information (i.e., the controlled agent's observations, actions, and rewards). Specifically, the actor maintains a speculated belief of the opponents, which we call the speculative opponent models, to predict opponent actions using local observations and makes decisions accordingly. Further, the distributional critic models the return distribution of the policy. It reflects the quality of the actor and thus can guide the training of the speculative opponent model that the actor relies on. Extensive experiments confirm that our method successf
    
[^186]: 训练全连接神经网络是$\exists\mathbb{R}$-完全的

    Training Fully Connected Neural Networks is $\exists\mathbb{R}$-Complete

    [https://arxiv.org/abs/2204.01368](https://arxiv.org/abs/2204.01368)

    该论文证明了训练全连接神经网络的权重和偏置的相关决策问题是$\exists\mathbb{R}$-完全的，同时指出必须使用任意大阶的代数数作为权重才能训练一些实例达到最优。

    

    我们考虑在一个两层全连接神经网络中找到适合给定数据点集的权重和偏置，也称为经验风险最小化的问题。我们的主要结果是相关的决策问题是$\exists\mathbb{R}$-完全的，即，多项式时间等价于确定多变量整系数多项式是否有任何实根。此外，我们证明需要具有任意大阶的代数数作为权重，才能训练某些实例达到最优，即使所有数据点都是有理数。我们的结果已经适用于具有两个输入、两个输出和一个使用ReLU神经元的隐藏层的全连接实例。因此，我们加强了Abrahamsen、Kleist和Miltzow在NeurIPS 2021中的一个结果。由此带来的一个结论是像Arora、Basu、Mianjy和Mukherjee在ICLR 2018中提出的一种组合搜索算法是不可能实现的。

    arXiv:2204.01368v3 Announce Type: replace-cross  Abstract: We consider the problem of finding weights and biases for a two-layer fully connected neural network to fit a given set of data points as well as possible, also known as EmpiricalRiskMinimization. Our main result is that the associated decision problem is $\exists\mathbb{R}$-complete, that is, polynomial-time equivalent to determining whether a multivariate polynomial with integer coefficients has any real roots. Furthermore, we prove that algebraic numbers of arbitrarily large degree are required as weights to be able to train some instances to optimality, even if all data points are rational. Our result already applies to fully connected instances with two inputs, two outputs, and one hidden layer of ReLU neurons. Thereby, we strengthen a result by Abrahamsen, Kleist and Miltzow [NeurIPS 2021]. A consequence of this is that a combinatorial search algorithm like the one by Arora, Basu, Mianjy and Mukherjee [ICLR 2018] is impos
    
[^187]: BBE-LSWCM: 一种长短窗口点击流模型的自举集成

    BBE-LSWCM: A Bootstrapped Ensemble of Long and Short Window Clickstream Models

    [https://arxiv.org/abs/2203.16155](https://arxiv.org/abs/2203.16155)

    提出了一种融合长短窗口的点击流模型自举集成框架（BBE-LSWCM），在实时客户事件预测中表现出优越性能，特别适用于QBO订阅取消和有意任务检测。

    

    我们考虑了为SaaS产品如QBO开发一个用于实时客户事件预测问题的点击流建模框架的问题。我们开发了一种低延迟、成本效益和鲁棒性的集成架构（BBE-LSWCM），它结合了长时间历史窗口中的用户行为数据（如过去几周内的数据）以及最近短窗口内的用户活动（如当前会话中的活动）。与其他基线方法相比，我们展示了所提出方法在两个重要的实时事件预测问题上的卓越性能：QBO订阅取消和有意任务检测。最后，我们呈现了在QBO中的在线部署细节和实验结果。

    arXiv:2203.16155v3 Announce Type: replace  Abstract: We consider the problem of developing a clickstream modeling framework for real-time customer event prediction problems in SaaS products like QBO. We develop a low-latency, cost-effective, and robust ensemble architecture (BBE-LSWCM), which combines both aggregated user behavior data from a longer historical window (e.g., over the last few weeks) as well as user activities over a short window in recent-past (e.g., in the current session). As compared to other baseline approaches, we demonstrate the superior performance of the proposed method for two important real-time event prediction problems: subscription cancellation and intended task detection for QBO subscribers. Finally, we present details of the live deployment and results from online experiments in QBO.
    
[^188]: 基于相似性的标签推断攻击：针对分布式学习的训练和推理

    Similarity-based Label Inference Attack against Training and Inference of Split Learning

    [https://arxiv.org/abs/2203.05222](https://arxiv.org/abs/2203.05222)

    本文研究了在Split learning的训练和推理过程中基于相似性的标签推断攻击，提出了相似性度量并设计了三种标签推断攻击。

    

    Split learning是一种有望实现隐私保护的分布式学习范式。学习模型可以被切割成多个部分，在参与者之间进行协作训练，只交换切割层的中间结果。了解Split learning的安全性能对许多隐私敏感应用至关重要。本文表明，在Split learning的训练和推理过程中，交换的中间结果，包括破碎的数据（即从原始数据提取的特征）和梯度，已经可以透露出私密标签。我们对潜在的标签泄漏进行了数学分析，并针对梯度和破碎的数据提出了余弦相似度和欧氏相似度测量。然后，这两种相似度测量显示可以在欧氏空间中统一。基于相似性度量，我们设计了三种标签推断攻击，可以高效地恢复私密

    arXiv:2203.05222v2 Announce Type: replace-cross  Abstract: Split learning is a promising paradigm for privacy-preserving distributed learning. The learning model can be cut into multiple portions to be collaboratively trained at the participants by exchanging only the intermediate results at the cut layer. Understanding the security performance of split learning is critical for many privacy-sensitive applications. This paper shows that the exchanged intermediate results, including the smashed data (i.e., extracted features from the raw data) and gradients during training and inference of split learning, can already reveal the private labels. We mathematically analyze the potential label leakages and propose the cosine and Euclidean similarity measurements for gradients and smashed data, respectively. Then, the two similarity measurements are shown to be unified in Euclidean space. Based on the similarity metric, we design three label inference attacks to efficiently recover the private
    
[^189]: 在主采样空间中学习重要性采样

    Learning to Importance Sample in Primary Sample Space

    [https://arxiv.org/abs/1808.07840](https://arxiv.org/abs/1808.07840)

    提出了一种利用神经网络在主采样空间中学习重要性采样的新方法，用于渲染算法中的方差缩减。

    

    重要性采样是蒙特卡洛渲染中最广泛使用的方差缩减策略之一。本文提出了一种新颖的重要性采样技术，该技术利用神经网络学习如何从一组样本表示的目标密度中进行采样。我们的方法将现有的蒙特卡洛渲染算法视为黑匣子。在场景相关的训练阶段，我们通过最大似然估计学习在渲染算法的主采样空间中生成具有目标密度的样本。我们利用最近设计用于在高维空间中表示实值非体积保持（'Real NVP'）变换的神经网络架构。我们使用Real NVP来非线性扭曲主采样空间并获得期望的密度。此外，Real NVP有效地计算了扭曲的雅可比行列式，这是实现积分变换所需的。

    arXiv:1808.07840v2 Announce Type: replace  Abstract: Importance sampling is one of the most widely used variance reduction strategies in Monte Carlo rendering. In this paper, we propose a novel importance sampling technique that uses a neural network to learn how to sample from a desired density represented by a set of samples. Our approach considers an existing Monte Carlo rendering algorithm as a black box. During a scene-dependent training phase, we learn to generate samples with a desired density in the primary sample space of the rendering algorithm using maximum likelihood estimation. We leverage a recent neural network architecture that was designed to represent real-valued non-volume preserving ('Real NVP') transformations in high dimensional spaces. We use Real NVP to non-linearly warp primary sample space and obtain desired densities. In addition, Real NVP efficiently computes the determinant of the Jacobian of the warp, which is required to implement the change of integratio
    
[^190]: 快速非线性的两时间尺度随机逼近：实现$\mathcal{O}(1/k)$有限样本复杂度

    Fast Nonlinear Two-Time-Scale Stochastic Approximation: Achieving $\mathcal{O}(1/k)$ Finite-Sample Complexity. (arXiv:2401.12764v1 [math.OC])

    [http://arxiv.org/abs/2401.12764](http://arxiv.org/abs/2401.12764)

    本文提出了一种新型的两时间尺度随机逼近方法，用于寻找耦合非线性算子的根，并且在强单调条件下证明了该方法的优化收敛速率为$\mathcal{O}(1/k)$。

    

    本文提出了一种新型的两时间尺度随机逼近方法，用于寻找耦合非线性算子的根，仅假设可以观测到这些算子的噪声样本。我们的关键思想是利用经典的Ruppert-Polyak平均技术通过样本动态估计算子的值。然后，这些平均步骤的估计值将用于两时间尺度随机逼近更新以找到所需的解。我们的主要理论结果是在底层非线性算子的强单调条件下，所提出方法产生的迭代的均方误差以优化的速率$\mathcal{O}(1/k)$收敛于零，其中$k$为迭代次数。我们的结果显著改进了现有的两时间尺度随机逼近结果，最佳已知有限时间收敛速率为$\mathcal{O}(1/k^{2/3})$。

    This paper proposes to develop a new variant of the two-time-scale stochastic approximation to find the roots of two coupled nonlinear operators, assuming only noisy samples of these operators can be observed. Our key idea is to leverage the classic Ruppert-Polyak averaging technique to dynamically estimate the operators through their samples. The estimated values of these averaging steps will then be used in the two-time-scale stochastic approximation updates to find the desired solution. Our main theoretical result is to show that under the strongly monotone condition of the underlying nonlinear operators the mean-squared errors of the iterates generated by the proposed method converge to zero at an optimal rate $\mathcal{O}(1/k)$, where $k$ is the number of iterations. Our result significantly improves the existing result of two-time-scale stochastic approximation, where the best known finite-time convergence rate is $\mathcal{O}(1/k^{2/3})$.
    
[^191]: 使用储层计算进行吸引子重建：储层的条件Lyapunov指数对忠实吸引子重建的影响

    Attractor reconstruction with reservoir computers: The effect of the reservoir's conditional Lyapunov exponents on faithful attractor reconstruction. (arXiv:2401.00885v1 [cs.LG])

    [http://arxiv.org/abs/2401.00885](http://arxiv.org/abs/2401.00885)

    该论文研究了储层计算在吸引子重建中的表现，发现驱动式储层的最大条件Lyapunov指数需要比真实系统的最小Lyapunov指数更小，储层的谱半径对吸引子重建起到重要作用。

    

    储层计算是一种机器学习技术，已被证明能够复制动力系统的混沌吸引子，包括分形维度和整个Lyapunov谱。我们定量地将驱动式储层计算的广义同步动力学与自主式储层计算在吸引子重建任务上的性能相关联。我们发现，为了成功进行吸引子重建和Lyapunov指数估计，驱动式储层的最大条件Lyapunov指数必须显著小于真实系统的最小（最负）Lyapunov指数。我们发现，储层的最大条件Lyapunov指数强烈依赖于储层邻接矩阵的谱半径，因此，对于吸引子重建和Lyapunov指数估计，谱半径较小的储层计算表现更好。

    Reservoir computing is a machine learning technique which has been shown to be able to replicate the chaotic attractor, including the fractal dimension and the entire Lyapunov spectrum, of the dynamical system on which it is trained. We quantitatively relate the generalized synchronization dynamics of a driven reservoir computer during the training stage to the performance of the autonomous reservoir computer at the attractor reconstruction task. We show that, for successful attractor reconstruction and Lyapunov exponent estimation, the largest conditional Lyapunov exponent of the driven reservoir must be significantly smaller (more negative) than the smallest (most negative) Lyapunov exponent of the true system. We find that the maximal conditional Lyapunov exponent of the reservoir depends strongly on the spectral radius of the reservoir adjacency matrix, and therefore, for attractor reconstruction and Lyapunov exponent estimation, small spectral radius reservoir computers perform be
    
[^192]: 强化图转换器与正则化关注分数

    Stronger Graph Transformer with Regularized Attention Scores. (arXiv:2312.11730v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.11730](http://arxiv.org/abs/2312.11730)

    本论文提出了一种新颖的边缘正则化技术版本，用于缓解图神经网络在内存问题上存在的困扰。与没有位置编码的Graph Transformer相比，应用了边缘正则化技术确实可以稳定地提高性能。

    

    图神经网络以其内存消耗大而臭名昭著。最近发现，基于Transformer的GNN称为Graph Transformer在存在长程依赖性时可以获得更好的性能。然而，将图数据和Transformer架构相结合导致了记忆问题更加严重。我们提出了一种新颖的“边缘正则化技术”的版本，可以减轻对位置编码的需求，从而减轻GT的内存溢出问题。我们观察到，不清楚在位置编码的基础上是否有边缘正则化是有帮助的。然而，显然，应用我们的边缘正则化技术确实可以稳定地改善GT的性能，相比于没有位置编码的GT。

    Graph Neural Networks are notorious for its memory consumption. A recent Transformer-based GNN called Graph Transformer is shown to obtain superior performances when long range dependencies exist. However, combining graph data and Transformer architecture led to a combinationally worse memory issue. We propose a novel version of "edge regularization technique" that alleviates the need for Positional Encoding and ultimately alleviate GT's out of memory issue. We observe that it is not clear whether having an edge regularization on top of positional encoding is helpful. However, it seems evident that applying our edge regularization technique indeed stably improves GT's performance compared to GT without Positional Encoding.
    
[^193]: 使用生成式回放的类原型条件扩散模型进行Continual Learning

    Class-Prototype Conditional Diffusion Model for Continual Learning with Generative Replay. (arXiv:2312.06710v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.06710](http://arxiv.org/abs/2312.06710)

    本论文提出了一个类原型条件扩散模型（CPDM）来解决Continual Learning中的灾难性遗忘问题。CPDM通过提高生成器的图像质量，减少了分类器的灾难性遗忘风险。

    

    缓解灾难性遗忘是Continual Learning中的一个关键难题。深度生成式回放（GR）提供了一种通过从先前任务中生成样本来增强模型记忆能力的技术。随着生成式人工智能的发展，生成模型已经从生成对抗网络（GANs）发展到了最新的扩散模型（DMs）。一个主要问题是生成的数据质量与原始数据相比会逐渐下降，因为生成器不断从其输出中进行自我学习。这种退化可能导致分类器中发生灾难性遗忘的潜在风险。为了解决这个问题，我们提出了类原型条件扩散模型（CPDM），一种基于生成式回放的Continual Learning方法，它通过提高生成器中的图像质量从而减少了分类器中的灾难性遗忘。CPDM的核心是一个可学习的类原型，它捕捉了给定类别中图像的核心特征。

    Mitigating catastrophic forgetting is a key hurdle in continual learning. Deep Generative Replay (GR) provides techniques focused on generating samples from prior tasks to enhance the model's memory capabilities. With the progression in generative AI, generative models have advanced from Generative Adversarial Networks (GANs) to the more recent Diffusion Models (DMs). A major issue is the deterioration in the quality of generated data compared to the original, as the generator continuously self-learns from its outputs. This degradation can lead to the potential risk of catastrophic forgetting occurring in the classifier. To address this, we propose the Class-Prototype Conditional Diffusion Model (CPDM), a GR-based approach for continual learning that enhances image quality in generators and thus reduces catastrophic forgetting in classifiers. The cornerstone of CPDM is a learnable class-prototype that captures the core characteristics of images in a given class. This prototype, integra
    
[^194]: 一个简单的方法在世界模型中实现新颖性检测

    A Simple Way to Incorporate Novelty Detection in World Models. (arXiv:2310.08731v1 [cs.AI])

    [http://arxiv.org/abs/2310.08731](http://arxiv.org/abs/2310.08731)

    本文提出了一个简单的方法，通过利用世界模型幻觉状态和真实观察状态的不匹配性作为异常分数，将新颖性检测纳入世界模型强化学习代理中。在新环境中与传统方法相比，我们的工作具有优势。

    

    使用世界模型进行强化学习已经取得了显著的成功。然而，当世界机制或属性发生突然变化时，代理的性能和可靠性可能会显著下降。我们将视觉属性或状态转换的突变称为“新颖性”。在生成的世界模型框架中实施新颖性检测是保护部署时代理的关键任务。在本文中，我们提出了一种简单的边界方法，用于将新颖性检测纳入世界模型强化学习代理中，通过利用世界模型幻觉状态和真实观察状态的不匹配性作为异常分数。首先，我们提供了与序列决策相关的新颖性检测本体论，然后我们提供了在代理在世界模型中学习的转换分布中检测新颖性的有效方法。最后，我们展示了我们的工作在新环境中与传统方法相比的优势。

    Reinforcement learning (RL) using world models has found significant recent successes. However, when a sudden change to world mechanics or properties occurs then agent performance and reliability can dramatically decline. We refer to the sudden change in visual properties or state transitions as {\em novelties}. Implementing novelty detection within generated world model frameworks is a crucial task for protecting the agent when deployed. In this paper, we propose straightforward bounding approaches to incorporate novelty detection into world model RL agents, by utilizing the misalignment of the world model's hallucinated states and the true observed states as an anomaly score. We first provide an ontology of novelty detection relevant to sequential decision making, then we provide effective approaches to detecting novelties in a distribution of transitions learned by an agent in a world model. Finally, we show the advantage of our work in a novel environment compared to traditional ma
    
[^195]: 基于查询式操作网络的振动声学频响预测

    Vibroacoustic Frequency Response Prediction with Query-based Operator Networks. (arXiv:2310.05469v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.05469](http://arxiv.org/abs/2310.05469)

    该论文提出了一个基于查询式操作网络的振动声学频响预测方法，并设计了一个用于代表性振动声学问题的结构化基准测试。该方法可以加速频响模拟，有助于设计优化和不确定性量化。

    

    理解飞机、汽车和房屋等机械结构中的振动声学波传播对保证用户的健康和舒适至关重要。为了分析这些系统，设计师和工程师主要考虑频域中的动态响应，这通过像有限元方法这样的昂贵数值模拟来计算。相比之下，基于数据的替代模型承诺加速这些模拟，从而促进设计优化、不确定性量化和设计空间探索等任务的实施。我们提出了一个结构化的基准测试用于代表性振动声学问题：预测带有不同形式镶边的振动板的频响。该基准测试包含了共计12,000个板几何形状以及相应的数值解，并引入了评估指标以量化预测质量。为了解决频响预测任务，我们提出了一种新颖的频率查询操作模型。

    Understanding vibroacoustic wave propagation in mechanical structures like airplanes, cars and houses is crucial to ensure health and comfort of their users. To analyze such systems, designers and engineers primarily consider the dynamic response in the frequency domain, which is computed through expensive numerical simulations like the finite element method. In contrast, data-driven surrogate models offer the promise of speeding up these simulations, thereby facilitating tasks like design optimization, uncertainty quantification, and design space exploration. We present a structured benchmark for a representative vibroacoustic problem: Predicting the frequency response for vibrating plates with varying forms of beadings. The benchmark features a total of 12,000 plate geometries with an associated numerical solution and introduces evaluation metrics to quantify the prediction quality. To address the frequency response prediction task, we propose a novel frequency query operator model, 
    
[^196]: 从复杂到清晰：通过Clifford的几何代数和凸优化的分析表达深度神经网络的权重

    From Complexity to Clarity: Analytical Expressions of Deep Neural Network Weights via Clifford's Geometric Algebra and Convexity. (arXiv:2309.16512v1 [cs.LG])

    [http://arxiv.org/abs/2309.16512](http://arxiv.org/abs/2309.16512)

    本文通过Clifford的几何代数和凸优化，提出了一种分析深度神经网络的新方法。我们展示了深度ReLU神经网络的最优权重可以通过训练样本的楔积来获得，并且训练问题可以简化为对楔积特征进行凸优化，从而揭示了神经网络内部的几何结构。

    

    本文介绍了一种基于几何（Clifford）代数和凸优化的神经网络分析方法。我们展示了当使用标准正则化损失进行训练时，深度ReLU神经网络的最优权重由训练样本的楔积给出。此外，训练问题可简化为对楔积特征进行凸优化，在其中编码训练数据集的几何结构。该结构以数据向量生成的三角形和平行体的有符号体积表示。凸问题通过$\ell_1$正则化找到样本的一个小子集，以发现仅相关的楔积特征。我们的分析提供了对深度神经网络内部工作机制的新视角，并揭示了隐藏层的作用。

    In this paper, we introduce a novel analysis of neural networks based on geometric (Clifford) algebra and convex optimization. We show that optimal weights of deep ReLU neural networks are given by the wedge product of training samples when trained with standard regularized loss. Furthermore, the training problem reduces to convex optimization over wedge product features, which encode the geometric structure of the training dataset. This structure is given in terms of signed volumes of triangles and parallelotopes generated by data vectors. The convex problem finds a small subset of samples via $\ell_1$ regularization to discover only relevant wedge product features. Our analysis provides a novel perspective on the inner workings of deep neural networks and sheds light on the role of the hidden layers.
    
[^197]: 剩余去噪扩散模型

    Residual Denoising Diffusion Models. (arXiv:2308.13712v1 [cs.CV])

    [http://arxiv.org/abs/2308.13712](http://arxiv.org/abs/2308.13712)

    提出了剩余去噪扩散模型（RDDM），相比于现有的扩散模型，该模型通过预测残差来表示从目标域到输入域的方向性扩散，并同时估计噪声来考虑扩散过程中的随机扰动，从而实现了统一的图像生成和恢复。

    

    当前基于扩散的图像恢复方法将退化的输入图像作为条件输入到噪声估计网络中。然而，解释这个扩散过程是具有挑战性的，因为它基本上是从噪声生成目标图像。为了建立一个统一且更可解释的图像生成和恢复模型，我们提出了剩余去噪扩散模型（RDDM）。与现有的扩散模型（例如DDPM或DDIM）仅专注于噪声估计不同，我们的RDDM预测残差来表示从目标域到输入域的方向性扩散，并同时估计噪声来考虑扩散过程中的随机扰动。残差的引入使我们能够重新定义正向扩散过程，其中目标图像逐渐扩散成一个纯噪声图像或携带噪声的输入图像，从而统一了图像生成和恢复。我们证明了我们的采样过程与真实的目标图像分布一致。

    Current diffusion-based image restoration methods feed degraded input images as conditions into the noise estimation network. However, interpreting this diffusion process is challenging since it essentially generates the target image from the noise. To establish a unified and more interpretable model for image generation and restoration, we propose residual denoising diffusion models (RDDM). In contrast to existing diffusion models (e.g., DDPM or DDIM) that focus solely on noise estimation, our RDDM predicts residuals to represent directional diffusion from the target domain to the input domain, while concurrently estimating noise to account for random perturbations in the diffusion process. The introduction of residuals allows us to redefine the forward diffusion process, wherein the target image progressively diffuses into a purely noisy image or a noise-carrying input image, thus unifying image generation and restoration. We demonstrate that our sampling process is consistent with t
    
[^198]: 经济非线性MPC的Koopman模型的端到端强化学习

    End-to-End Reinforcement Learning of Koopman Models for Economic Nonlinear MPC. (arXiv:2308.01674v1 [cs.LG])

    [http://arxiv.org/abs/2308.01674](http://arxiv.org/abs/2308.01674)

    本论文提出了一种用于经济非线性MPC的Koopman模型的端到端强化学习方法，旨在实现控制性能和计算需求之间的平衡。

    

    （经济）非线性模型预测控制（（e）NMPC）需要在所有相关状态空间区域都具有足够准确性的动态系统模型。这些模型还必须计算成本足够低以确保实时可行性。基于数据驱动的替代机制模型可以用来减少（e）NMPC的计算负担；但是，这些模型通常通过系统辨识以在模拟样本上获得最大平均预测准确性进行训练，并作为实际（e）NMPC的一部分表现不佳。我们提出了一种用于实现最佳（e）NMPC性能的动态替代模型的端到端强化学习方法，从而得到具有控制性能和计算需求之间良好平衡的预测控制器。我们通过两个基于已建立的非线性连续搅拌反应器模型的应用来验证我们的方法。

    (Economic) nonlinear model predictive control ((e)NMPC) requires dynamic system models that are sufficiently accurate in all relevant state-space regions. These models must also be computationally cheap enough to ensure real-time tractability. Data-driven surrogate models for mechanistic models can be used to reduce the computational burden of (e)NMPC; however, such models are typically trained by system identification for maximum average prediction accuracy on simulation samples and perform suboptimally as part of actual (e)NMPC. We present a method for end-to-end reinforcement learning of dynamic surrogate models for optimal performance in (e)NMPC applications, resulting in predictive controllers that strike a favorable balance between control performance and computational demand. We validate our method on two applications derived from an established nonlinear continuous stirred-tank reactor model. We compare the controller performance to that of MPCs utilizing models trained by the 
    
[^199]: 基于浅层单变量ReLU网络的噪声插值学习

    Noisy Interpolation Learning with Shallow Univariate ReLU Networks. (arXiv:2307.15396v1 [cs.LG])

    [http://arxiv.org/abs/2307.15396](http://arxiv.org/abs/2307.15396)

    使用最小范数的两层ReLU网络进行噪声单变量回归的插值，对于$L_1$损失和$ p <2 $的$L_p$损失抑制过拟合，但对于$ p \geq 2 $的损失是灾难性的。

    

    我们研究了噪声单变量回归中使用最小范数（权重的$\ell_2$范数）的两层ReLU网络进行插值的渐近过拟合行为。我们发现对于$L_1$损失和$ p <2 $的任何$L_p$损失，过拟合现象会被抑制，但对于$ p \geq 2 $的损失是灾难性的。

    We study the asymptotic overfitting behavior of interpolation with minimum norm ($\ell_2$ of the weights) two-layer ReLU networks for noisy univariate regression. We show that overfitting is tempered for the $L_1$ loss, and any $L_p$ loss for $p<2$, but catastrophic for $p\geq 2$.
    
[^200]: 用度量的Dikin步骤有效地抽样PSD锥体

    Efficiently Sampling the PSD Cone with the Metric Dikin Walk. (arXiv:2307.12943v2 [cs.DS] UPDATED)

    [http://arxiv.org/abs/2307.12943](http://arxiv.org/abs/2307.12943)

    本文通过对Dikin步行方法进行分析并适应一般度量，为带约束的PSD锥体抽样问题提供了一种有效的解决方案，并提出了优化的自共轭矩阵函数概念。

    

    半定规划代表了高效计算的前沿。尽管在半定最优化上已取得了很大进展，如今内点法能够在实践中解决中等规模的问题，但是抽样半定解的基本问题仍然是一个巨大的挑战。直接应用已知的多项式时间算法来抽样一般凸体的方法导致运行时间过长。此外，已知的通用方法需要昂贵的舍入阶段作为预处理。本文分析了Dikin步行，并首先将其适应于一般度量，然后为带有仿射约束的PSD锥体设计合适的度量。所得到的混合时间和每步复杂度相当小，并且通过适当选择度量，可以使其对约束的依赖关系变为多对数级的。我们介绍了一个优化的自共轭矩阵函数概念，并给出了组合规则。

    Semi-definite programs represent a frontier of efficient computation. While there has been much progress on semi-definite optimization, with moderate-sized instances currently solvable in practice by the interior-point method, the basic problem of sampling semi-definite solutions remains a formidable challenge. The direct application of known polynomial-time algorithms for sampling general convex bodies to semi-definite sampling leads to a prohibitively high running time. In addition, known general methods require an expensive rounding phase as pre-processing. Here we analyze the Dikin walk, by first adapting it to general metrics, then devising suitable metrics for the PSD cone with affine constraints. The resulting mixing time and per-step complexity are considerably smaller, and by an appropriate choice of the metric, the dependence on the number of constraints can be made polylogarithmic. We introduce a refined notion of self-concordant matrix functions and give rules for combining
    
[^201]: 带有网络可分离交互的多人零和马尔可夫游戏

    Multi-Player Zero-Sum Markov Games with Networked Separable Interactions. (arXiv:2307.09470v1 [cs.GT])

    [http://arxiv.org/abs/2307.09470](http://arxiv.org/abs/2307.09470)

    本文研究了一种新的马尔可夫游戏类别，通过带有网络可分离交互的多人零和马尔可夫游戏模型（MZNMGs）来模拟非合作多智能体顺序决策中的局部交互结构。作者确定了MG可被表示为MZNMG的必要和充分条件，并证明其Markov CCE集合与Markov NE集合相等；此外，在无限时间折扣MZNMG中找到近似的Markov稳定CCE是PPAD难题，除非网络具有“星状结构”。

    

    本文研究了一种新的马尔可夫游戏类别，即带有网络可分离交互的多人零和马尔可夫游戏（MZNMGs），以模拟非合作多智能体顺序决策中的局部交互结构。我们将MZNMG定义为一个模型，其中与每个状态相关的辅助游戏的收益是零和的，并且在某个交互网络上的邻居之间具有一些可分离（即聚合矩阵）结构。我们首先确定了马尔可夫游戏能够被表示为MZNMG的必要和充分条件，并且证明在这些游戏中，马尔可夫粗糙相关均衡（CCE）的集合缩减为马尔可夫纳什均衡（NE）的集合，即前者对所有玩家的每个状态的边际化乘积结果得到后者。此外，我们证明在无限时间折扣MZNMGs中找到近似马尔可夫\emph{稳定}CCE是PPAD难题，除非底层网络具有``星状结构''。

    We study a new class of Markov games (MGs), \textit{Multi-player Zero-sum Markov Games} with {\it Networked separable interactions} (MZNMGs), to model the local interaction structure in non-cooperative multi-agent sequential decision-making. We define an MZNMG as a model where {the payoffs of the auxiliary games associated with each state are zero-sum and} have some separable (i.e., polymatrix) structure across the neighbors over some interaction network. We first identify the necessary and sufficient conditions under which an MG can be presented as an MZNMG, and show that the set of Markov coarse correlated equilibrium (CCE) collapses to the set of Markov Nash equilibrium (NE) in these games, in that the {product of} per-state marginalization of the former for all players yields the latter. Furthermore, we show that finding approximate Markov \emph{stationary} CCE in infinite-horizon discounted MZNMGs is \texttt{PPAD}-hard, unless the underlying network has a ``star topology''. Then, 
    
[^202]: (核) 岭回归中过度拟合成本的不可知观察

    An Agnostic View on the Cost of Overfitting in (Kernel) Ridge Regression. (arXiv:2306.13185v1 [stat.ML])

    [http://arxiv.org/abs/2306.13185](http://arxiv.org/abs/2306.13185)

    本文研究了核岭回归中过拟合成本，采用“不可知”的观点，以分析样本量和任务特征结构对成本的影响。通过分析提供了更细致的过度拟合表征。

    

    本研究研究了有噪声的核岭回归 (KRR) 中过拟合的成本，我们将其定义为插值无岭模型的测试误差与最优调节模型的测试误差之比。我们采用“不可知”的观点，即对于任何目标函数，即使样本量不足以达到一致性或目标函数不在 RKHS 中，我们也将成本看作样本量的函数。使用最近推导出的（非严格的）风险评估，以任务特征结构为基础，利用高斯普适性假设分析过度拟合成本。我们的分析提供了良性、缓和和灾难性过度拟合（参见 Mallinar 等人 2022）的更精细的表征。

    We study the cost of overfitting in noisy kernel ridge regression (KRR), which we define as the ratio between the test error of the interpolating ridgeless model and the test error of the optimally-tuned model. We take an "agnostic" view in the following sense: we consider the cost as a function of sample size for any target function, even if the sample size is not large enough for consistency or the target is outside the RKHS. We analyze the cost of overfitting under a Gaussian universality ansatz using recently derived (non-rigorous) risk estimates in terms of the task eigenstructure. Our analysis provides a more refined characterization of benign, tempered and catastrophic overfitting (qv Mallinar et al. 2022).
    
[^203]: 基于GCN可信度预测的协同移动群感知的高效招募策略

    Efficient Recruitment Strategy for Collaborative Mobile Crowd Sensing Based on GCN Trustworthiness Prediction. (arXiv:2306.04366v1 [cs.SI])

    [http://arxiv.org/abs/2306.04366](http://arxiv.org/abs/2306.04366)

    本文提出了一种基于GCN可信度预测的协同移动群感知的高效招募策略，通过捕获工人之间的非对称信任关系和工人能力来实现有效的任务分配，优于现有方法。

    

    协同移动群感知可以通过促进任务感知的团队合作来提高数据质量和覆盖范围，而工人招募则代表着一个复杂的多目标优化问题。现有策略主要关注工人本身的特征，忽略了工人之间的非对称信任关系，从而影响了任务效用评估的合理性。为解决这个问题，本文首先使用Mini-Batch K-Means聚类算法和边缘服务器来实现高效的分布式工人招募。利用历史数据和任务要求获得工人的能力类型和距离。使用工人社交网络中的信任导向图输入至图卷积网络（GCN）框架进行训练，捕获工人之间的非对称信任关系。通过工人之间的高信任值，防止CMCS场景下的隐私泄露。最终，利用预测的信任和工人能力构建了一个无向招募图，以实现有效的任务分配。实验结果表明，与现有方法相比，这种招募方法在招募准确度、任务完成时间和能量消耗方面表现优异。

    Collaborative Mobile Crowd Sensing (CMCS) enhances data quality and coverage by promoting teamwork in task sensing, with worker recruitment representing a complex multi-objective optimization problem. Existing strategies mainly focus on the characteristics of workers themselves, neglecting the asymmetric trust relationships between them, which affects the rationality of task utility evaluation. To address this, this paper first employs the Mini-Batch K-Means clustering algorithm and deploys edge servers to enable efficient distributed worker recruitment. Historical data and task requirements are utilized to obtain workers' ability types and distances. A trust-directed graph in the worker's social network is input into the Graph Convolutional Network (GCN) framework for training, capturing asymmetric trustworthiness between worker pairs. Privacy leakage is prevented in CMCS scenarios through high trust values between workers. Ultimately, an undirected recruitment graph is constructed us
    
[^204]: 通过数据混合消除预训练模型中的虚假相关性

    Eliminating Spurious Correlations from Pre-trained Models via Data Mixing. (arXiv:2305.14521v1 [cs.LG])

    [http://arxiv.org/abs/2305.14521](http://arxiv.org/abs/2305.14521)

    本文提出了一种通过数据混合来消除预训练模型中虚假相关性的方法，来提高模型对于新样本的预测能力。这种方法经过理论证明和多种任务实验验证，可以取得良好的效果。

    

    在大数据集上预训练的机器学习模型取得了显著的收敛性和鲁棒性。然而，这些模型往往利用了某些属性和标签之间的虚假相关性，在特定类别的大多数示例中普遍存在，但并不足以预测这些类别。学到的虚假相关性可能会在对新数据进行微调后仍然存在，这会降低模型对不展现虚假相关性的示例的性能。本文提出了一种简单而高效的方法，以消除预训练模型中的虚假相关性。我们方法的关键思想是利用一小组带有虚假属性的示例，并通过数据混合来平衡所有类别中的虚假属性。我们在理论上证实了我们的方法的有效性，并在各种视觉和NLP任务上进行了实证，包括消除虚假相关性。

    Machine learning models pre-trained on large datasets have achieved remarkable convergence and robustness properties. However, these models often exploit spurious correlations between certain attributes and labels, which are prevalent in the majority of examples within specific categories but are not predictive of these categories in general. The learned spurious correlations may persist even after fine-tuning on new data, which degrades models' performance on examples that do not exhibit the spurious correlation. In this work, we propose a simple and highly effective method to eliminate spurious correlations from pre-trained models. The key idea of our method is to leverage a small set of examples with spurious attributes, and balance the spurious attributes across all classes via data mixing. We theoretically confirm the effectiveness of our method, and empirically demonstrate its state-of-the-art performance on various vision and NLP tasks, including eliminating spurious correlation
    
[^205]: 大数据时代的地球移动者: 最优输运在机器学习中的回顾

    Earth Movers in The Big Data Era: A Review of Optimal Transport in Machine Learning. (arXiv:2305.05080v1 [cs.LG])

    [http://arxiv.org/abs/2305.05080](http://arxiv.org/abs/2305.05080)

    本文回顾了最优输运在机器学习中的应用，并探讨了如何将其扩展以适应大数据和高维数据的需求。

    

    最优输运(OT)是一个数学框架,首次出现于18世纪,并引发出大量方法来回答许多理论和应用问题。过去的十年见证了这个经典优化问题对机器学习的显着贡献。本文探讨了最优输运在机器学习中的使用方式及其扩展的问题。在专题与背景的允许下,我们提供了关于最优输运的全面调查,并确保其呈现具有可访问性。首先,我们解释了最优输运的背景,并介绍了不同的类型、特性和显著应用。然后,我们着重探讨了如何将最优输运扩展以应对当前大数据和高维数据的需求。我们对用于扩展OT的文献方法进行了系统分析,并以结构化的方式呈现结果以促进理解。最后,我们探讨了可扩展最优输运在机器学习中未来研究的一些最有前途的方向。

    Optimal Transport (OT) is a mathematical framework that first emerged in the eighteenth century and has led to a plethora of methods for answering many theoretical and applied questions. The last decade is a witness of the remarkable contributions of this classical optimization problem to machine learning. This paper is about where and how optimal transport is used in machine learning with a focus on the question of salable optimal transport. We provide a comprehensive survey of optimal transport while ensuring an accessible presentation as permitted by the nature of the topic and the context. First, we explain optimal transport background and introduce different flavors (i.e. mathematical formulations), properties, and notable applications. We then address the fundamental question of how to scale optimal transport to cope with the current demands of big and high dimensional data. We conduct a systematic analysis of the methods used in the literature for scaling OT and present the find
    
[^206]: mPLUG-Owl: 模块化增强了大型语言模型的多模态能力

    mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality. (arXiv:2304.14178v1 [cs.CL])

    [http://arxiv.org/abs/2304.14178](http://arxiv.org/abs/2304.14178)

    本文介绍了一种名为mPLUG-Owl的训练范式，它通过模块化学习基础LLM、视觉知识模块和视觉抽象器模块，赋予LLMs多模态的能力。实验结果表明，mPLUG-Owl在图像字幕和视觉问答任务中表现优于基线模型，并在某些情况下达到了最先进的性能水平。

    

    大型语言模型(LLMs)已经在各种开放式任务中展示出了令人印象深刻的零-shot表现，而最近的研究还探讨了将LLMs用于多模态生成的应用。在本研究中，我们引入了一种新的训练范式mPLUG-Owl，通过基础LLM、视觉知识模块和视觉抽象器模块的模块化学习，使LLMs具备了多模态的能力。该方法可以支持多种模态，并通过模态协作促进了多单模态和多模态的能力。mPLUG-Owl的训练范式包括用于对齐图像和文本的两阶段方法，该方法利用LLM的辅助学习视觉知识，同时保持甚至改进了LLM的生成能力。在第一阶段中，使用冻结的LLM模块对视觉知识模块和抽象器模块进行训练以对齐图像和文本。在第二阶段中，使用仅语言和多模态监督数据集共同对模型进行微调。对于图像字幕和视觉问答任务的实验结果表明，mPLUG-Owl优于基线模型，在某些情况下达到了最先进的性能水平。

    Large language models (LLMs) have demonstrated impressive zero-shot abilities on a variety of open-ended tasks, while recent research has also explored the use of LLMs for multi-modal generation. In this study, we introduce mPLUG-Owl, a novel training paradigm that equips LLMs with multi-modal abilities through modularized learning of foundation LLM, a visual knowledge module, and a visual abstractor module. This approach can support multiple modalities and facilitate diverse unimodal and multimodal abilities through modality collaboration. The training paradigm of mPLUG-Owl involves a two-stage method for aligning image and text, which learns visual knowledge with the assistance of LLM while maintaining and even improving the generation abilities of LLM. In the first stage, the visual knowledge module and abstractor module are trained with a frozen LLM module to align the image and text. In the second stage, language-only and multi-modal supervised datasets are used to jointly fine-tu
    
[^207]: EC-NAS: 面向神经架构搜索的能耗感知表格基准

    EC-NAS: Energy Consumption Aware Tabular Benchmarks for Neural Architecture Search. (arXiv:2210.06015v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.06015](http://arxiv.org/abs/2210.06015)

    提出了一个能耗感知的神经架构搜索表格基准 EC-NAS，该基准通过添加能耗和碳足迹信息，支持设计能效高的深度学习模型，并降低总能耗。

    

    近年来，选择、训练和部署深度学习模型所需的能量消耗不断增加。本文旨在支持设计能效高、训练资源消耗较低、适用于实际边缘/移动计算环境并具有环境可持续性的深度学习模型。我们提出将能效作为神经架构搜索 (NAS) 的一项额外性能指标，并通过添加不同架构的能耗和碳足迹信息，提供更新的表格基准 EC-NAS 以在较低计算成本下评估 NAS 策略。EC-NAS 还包括用于预测能耗的代理模型，并有助于降低总能耗。

    Energy consumption from selecting, training and deploying deep learning models has continued to increase over the past few years. Our goal in this work is to support the design of energy-efficient deep learning models that are easier to train with lower compute resources, practical to deploy in real-world edge/mobile computing settings and environmentally sustainable. Tabular benchmarks for neural architecture search (NAS) allow the evaluation of NAS strategies at lower computational cost by providing pre-computed performance statistics. In this work, we suggest including energy efficiency as an additional performance criterion to NAS and present an updated tabular benchmark by including information on energy consumption and carbon footprint for different architectures. The benchmark called EC-NAS is made available open-source to support energy consumption-aware NAS research. EC-NAS also includes a surrogate model for predicting energy consumption, and helps us reduce the overall energ
    
[^208]: Merlin-Arthur分类器的形式可解释性

    Formal Interpretability with Merlin-Arthur Classifiers. (arXiv:2206.00759v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.00759](http://arxiv.org/abs/2206.00759)

    该论文提出了一种新型的多智能体交互分类器，利用“Merlin-Arthur”协议的启发，在不假设最优智能体或特征独立分布的情况下，通过相对强度和“非对称特征相关性”概念捕捉特征之间精确的相关性，提供可证明的可解释性保证。

    

    我们提出了一种新类型的多智能体交互分类器，即使是像神经网络这样的复杂智能体也能提供可证明的可解释性保证。这些保证包括对此分类器选择的特征之间互信息的上下界约束。我们的结果受交互式证明系统中 Merlin-Arthur 协议的启发，并以可测量的指标（如声音和完整性）表达了这些约束。与现有的交互式设置相比，我们不依赖于最优智能体或特征独立分布的假设。相反，我们利用智能体的相对强度以及新的“非对称特征相关性”概念来捕捉使可解释性保证困难的精确相关性类型。 我们通过两个小规模数据集的数值实验来测试我们的结果，这些实验可验证高互信息性。

    We propose a new type of multi-agent interactive classifier that provides provable interpretability guarantees even for complex agents such as neural networks. These guarantees consist of bounds on the mutual information of the features selected by this classifier. Our results are inspired by the Merlin-Arthur protocol from Interactive Proof Systems and express these bounds in terms of measurable metrics such as soundness and completeness. Compared to existing interactive setups we do not rely on optimal agents or on the assumption that features are distributed independently. Instead, we use the relative strength of the agents as well as the new concept of Asymmetric Feature Correlation which captures the precise kind of correlations that make interpretability guarantees difficult. %relates the information carried by sets of features to one of the individual features. We test our results through numerical experiments on two small-scale datasets where high mutual information can be veri
    

