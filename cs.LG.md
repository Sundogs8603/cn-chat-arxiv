# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Effective Human-AI Teams via Learned Natural Language Rules and Onboarding.](http://arxiv.org/abs/2311.01007) | 本论文提出了一种通过学习自然语言规则和引导的方法，以提高人工智能团队的效果。通过找到数据的局部区域和使用语言模型进行描述，我们教导人类如何与AI合作。通过目标检测和问答任务的用户研究，我们证明了我们的方法可以使人工智能团队更加准确。 |
| [^2] | [Electronic excited states from physically-constrained machine learning.](http://arxiv.org/abs/2311.00844) | 本文介绍了一种综合建模方法，通过训练一个对称自适应的机器学习模型来再现量子力学计算中的电子激发，从而实现了针对更大更复杂分子的预测，并通过最小原子中心基础对应的参数化实现了极大的计算效益。 |
| [^3] | [Robust Graph Clustering via Meta Weighting for Noisy Graphs.](http://arxiv.org/abs/2311.00322) | 该论文提出了一种鲁棒的基于元权重的图聚类方法，通过对节点对应权重的自适应调整，能够在存在噪声边的图中找到有意义的聚类。 |
| [^4] | [Stochastic Thermodynamics of Learning Generative Parametric Probabilistic Models.](http://arxiv.org/abs/2310.19802) | 本文将生成式机器学习问题视为参数概率模型的时间演化过程，通过研究模型参数与生成样本之间的热力学交换，发现模型通过耗散热量来学习，参数子系统充当热库存储学到的信息。这为超参数模型的泛化能力提供了有价值的热力学洞察。 |
| [^5] | [Causal disentanglement of multimodal data.](http://arxiv.org/abs/2310.18471) | 这篇论文介绍了一种可以利用多模态数据和已知物理学知识发现因果关系的因果表示学习算法。 |
| [^6] | [Streaming Factor Trajectory Learning for Temporal Tensor Decomposition.](http://arxiv.org/abs/2310.17021) | 这篇论文提出了一种流式因子轨迹学习方法，用于时间张量分解。该方法使用高斯过程来灵活估计因子的时间演变，并开发了一种高效的在线滤波算法来估计因子状态的演变轨迹。 |
| [^7] | [MACP: Efficient Model Adaptation for Cooperative Perception.](http://arxiv.org/abs/2310.16870) | 本文提出了MACP框架，通过将单个预训练模型配备合作能力来提高连接和自动驾驶车辆的感知能力。通过冻结大部分参数并添加几个轻量级模块，该框架能够有效利用合作观测，并在模拟和真实环境中胜过其他最先进的方法。 |
| [^8] | [Physics-Informed Graph Convolutional Networks: Towards a generalized framework for complex geometries.](http://arxiv.org/abs/2310.14948) | 本研究提出了物理信息图卷积网络作为解决复杂几何体中偏微分方程问题的广义框架，并结合经典数值求解器从而解决了物理信息框架在复杂几何体上的问题。 |
| [^9] | [Quality-Diversity through AI Feedback.](http://arxiv.org/abs/2310.13032) | 基于AI反馈的质量-多样性（QDAIF）算法利用语言模型来生成和评估创造性写作，比传统算法更广泛地覆盖高质量样本的搜索空间。 |
| [^10] | [Question Answering for Electronic Health Records: A Scoping Review of datasets and models.](http://arxiv.org/abs/2310.08759) | 本文对电子健康记录（EHR）中的问题回答进行了范围回顾。与其他医学QA任务不同，EHR QA通过从患者的医疗记录中获取答案。这项研究为现有的EHR QA作品提供了方法论回顾。 |
| [^11] | [LGL-BCI: A Lightweight Geometric Learning Framework for Motor Imagery-Based Brain-Computer Interfaces.](http://arxiv.org/abs/2310.08051) | LGL-BCI是一种轻量级几何学习框架，通过处理EEG数据在非欧几里德度量空间中捕捉运动想象任务的空间相关性，并通过特征分解算法进行EEG通道选择以提高推断速度。实验证明LGL-BCI相比现有解决方案具有更高的准确性和效率。 |
| [^12] | [RTDK-BO: High Dimensional Bayesian Optimization with Reinforced Transformer Deep kernels.](http://arxiv.org/abs/2310.03912) | 本文提出了一种新的提高贝叶斯优化模型建模能力的方法，通过将注意机制融入深度核学习中，使得代理能够适应上下文信息，提高优化性能。 |
| [^13] | [PyDCM: Custom Data Center Models with Reinforcement Learning for Sustainability.](http://arxiv.org/abs/2310.03906) | PyDCM是一个用强化学习实现的可定制的数据中心模型，通过使用自定义配置和向量化的热计算，实现了对数据中心的优化，具有较高的效率。 |
| [^14] | [The Geometric Structure of Fully-Connected ReLU-Layers.](http://arxiv.org/abs/2310.03482) | 该论文研究了神经网络中完全连接的ReLU层的几何结构。研究发现，在每个划分区域内，ReLU层可以被大大简化，可以将其解释为一个投影到多面体锥体，然后进行仿射变换。此结构还简化了分区区域与超平面交集的反像表达式，对于描述分类问题中的决策边界非常有用。此外，对于具有一个隐藏ReLU层的前馈网络，论文提供了关于这些网络生成的决策边界几何复杂性的结果，并证明了这些决策边界在仿射变换的模下是相等的。 |
| [^15] | [PB-LLM: Partially Binarized Large Language Models.](http://arxiv.org/abs/2310.00034) | 本文提出的PB-LLM是一种部分二值化的大型语言模型压缩方法，可以在保持语言推理能力的同时实现极低比特量化，并通过后训练量化和量化感知训练等方法恢复量化LLMM的容量。 |
| [^16] | [Uncertainty Quantification for Eosinophil Segmentation.](http://arxiv.org/abs/2309.16536) | 本研究提出了一种改进的方法，利用深度图像分割和蒙特卡洛辍学来量化嗜酸性粒细胞，为诊断嗜酸性食管炎提供不确定性评估和模型性能可视化。 |
| [^17] | [AnglE-Optimized Text Embeddings.](http://arxiv.org/abs/2309.12871) | 本文提出了一种名为AnglE的角度优化文本嵌入模型，通过在复杂空间中引入角度优化来缓解文本嵌入中余弦函数饱和区域造成的梯度消失问题。该模型在多个STS任务中实现了高质量的文本嵌入，并在有限标签数据的特定领域STS场景中展现出优秀的性能。 |
| [^18] | [PDFTriage: Question Answering over Long, Structured Documents.](http://arxiv.org/abs/2309.08872) | PDFTriage是一种处理长篇结构化文档问答的方法，通过使用结构或内容来检索上下文，解决了大型语言模型在问答中遇到的问题。 |
| [^19] | [Cure the headache of Transformers via Collinear Constrained Attention.](http://arxiv.org/abs/2309.08646) | 通过引入共线约束注意力（CoCA）结构，解决Transformer模型中的头痛问题，实现了出色的外推性能和提高的计算效率。 |
| [^20] | [Chain-of-Thought Reasoning is a Policy Improvement Operator.](http://arxiv.org/abs/2309.08589) | 大型语言模型SECToR通过链式思考推理成功地自学新技能， |
| [^21] | [Oobleck: Resilient Distributed Training of Large Models Using Pipeline Templates.](http://arxiv.org/abs/2309.08125) | Oobleck采用流水线模板和已复制模型状态来实现对大型模型的弹性分布式训练，并通过有效利用资源和快速恢复来提供高吞吐量。在评估中，Oobleck在吞吐量上胜过了Bamboo和Varuna等最先进的容错解决方案。 |
| [^22] | [Federated Dataset Dictionary Learning for Multi-Source Domain Adaptation.](http://arxiv.org/abs/2309.07670) | 本文提出了一种用于联邦领域自适应的方法，通过字典学习经验分布来解决客户端间分布偏移和部分无标签数据的问题。该方法通过设计协作通信协议和聚合操作，保护了客户端数据隐私，并成功在目标领域生成了标记数据。 |
| [^23] | [Rank2Tell: A Multimodal Driving Dataset for Joint Importance Ranking and Reasoning.](http://arxiv.org/abs/2309.06597) | Rank2Tell是一个多模态驾驶数据集，用于联合重要性排序和推理，为研究人员提供了复杂交通情景中各种重要对象的密集注释和独特属性。 |
| [^24] | [Assessing the Generalization Gap of Learning-Based Speech Enhancement Systems in Noisy and Reverberant Environments.](http://arxiv.org/abs/2309.06183) | 本研究介绍了一种泛化评估框架，用于评估学习型语音增强系统在噪声和混响环境中的泛化能力，并提出了使用在测试条件下训练的参考模型作为难度代理。 |
| [^25] | [LoopTune: Optimizing Tensor Computations with Reinforcement Learning.](http://arxiv.org/abs/2309.01825) | LoopTune是一个使用强化学习优化张量计算的编译器，通过优化张量遍历顺序和使用代码生成器LoopNest执行硬件特定优化，LoopTune能够生成比其他编译器更快的代码。通过采用新的图形表示和动作空间，LoopTune比TVM快一个数量级，比MetaSchedule快2.8倍，比AutoTVM快1.08倍，并持续在与手工调优的库Numpy相当的水平上工作。此外，LoopTune优化代码的时间只需几秒钟。 |
| [^26] | [ToddlerBERTa: Exploiting BabyBERTa for Grammar Learning and Language Understanding.](http://arxiv.org/abs/2308.16336) | ToddlerBERTa是一个类似于BabyBERTa的语言模型，尽管在较小的数据集上进行训练，但它展示了令人称赞的性能，并具有强大的语言理解能力，与最先进的RoBERTa-base相媲美。 |
| [^27] | [Conditional Sampling of Variational Autoencoders via Iterated Approximate Ancestral Sampling.](http://arxiv.org/abs/2308.09078) | 本文提出了两种原始方法来解决变分自编码器（VAE）条件采样中的困难，并在采样任务中展示了改进性能。 |
| [^28] | [Exploring Predicate Visual Context in Detecting of Human-Object Interactions.](http://arxiv.org/abs/2308.06202) | 本文研究了在人物和物体交互检测中的谓词视觉背景问题，并通过交叉注意力和盒子配对位置嵌入等方式来改进模型，取得了比现有方法更好的性能。 |
| [^29] | [From Discrete Tokens to High-Fidelity Audio Using Multi-Band Diffusion.](http://arxiv.org/abs/2308.02560) | 提出了一种高保真多频带扩散模型，可以根据低比特率的离散表示生成任何类型的音频形式，具有优于最先进生成技术的感知质量。 |
| [^30] | [Multi-Source Domain Adaptation through Dataset Dictionary Learning in Wasserstein Space.](http://arxiv.org/abs/2307.14953) | 本文提出了一种基于字典学习和最优传输的MSDA框架，通过将每个域表示为字典原子的Wasserstein重心来缓解数据分布偏移。根据该字典，提出了两种新的MSDA方法，分别基于目标域标记样本的重构和在原子分布上学习的分类器的集成。在多个基准测试集上进行的实验证明，这些方法在分类任务上取得了显著的改进效果。 |
| [^31] | [Efficient Beam Tree Recursion.](http://arxiv.org/abs/2307.10779) | 本文提出了一种高效的Beam Tree递归算法（BT-RvNN），通过解决评分函数和递归单元函数的纠缠问题以及简化内存使用，成功降低了BT-RvNN的内存使用。这个算法在ListOps任务中达到了新的最先进水平，并在其他任务中保持了类似的性能。 |
| [^32] | [Spuriosity Didn't Kill the Classifier: Using Invariant Predictions to Harness Spurious Features.](http://arxiv.org/abs/2307.09933) | 本研究通过理论证明和算法提出，展示了在没有标签的情况下如何利用不稳定特征来提高分类器的性能。 |
| [^33] | [Learning to Select SAT Encodings for Pseudo-Boolean and Linear Integer Constraints.](http://arxiv.org/abs/2307.09342) | 该论文提出了一种学习选择伪布尔和线性整数约束的SAT编码的方法，通过使用监督机器学习方法和一组特征，可以有效地选择编码方式，并且专门为伪布尔和线性约束设计的新特征能够取得更好的性能。 |
| [^34] | [Adaptive Linear Estimating Equations.](http://arxiv.org/abs/2307.07320) | 本文提出了一种解决自适应线性回归模型中非正态渐近行为的方法，使用自适应线性估计方程构建去偏估计量，并在多臂老虎机的背景下保持了最小二乘估计量的非渐近性能。 |
| [^35] | [Policy Space Diversity for Non-Transitive Games.](http://arxiv.org/abs/2306.16884) | 这项研究提出了一种新的策略空间多样性度量，并通过将其纳入策略空间响应预言机（PSRO）中，实现了更好的逼近纳什均衡（NE）的效果。 |
| [^36] | [Solving Kernel Ridge Regression with Gradient-Based Optimization Methods.](http://arxiv.org/abs/2306.16838) | 本研究提出了一种新的方法来解决核岭回归问题，通过等价的目标函数形式和基于梯度的优化方法，我们不仅可以使用其他惩罚方法，还能够从梯度下降的角度研究核岭回归。通过提前停止的正则化，我们推导出了一个闭合解，即核梯度流（KGF），并证明了KGF和KRR之间的差异。我们还将KRR泛化，使用$\ell_1$和$\ell_\infty$惩罚方法，并发现使用这些方法得到的解与前向分步回归和符号梯度下降结合提前停止得到的解非常相似。因此，我们减少了计算复杂度重的近端梯度下降算法的需求。 |
| [^37] | [Eigensubspace of Temporal-Difference Dynamics and How It Improves Value Approximation in Reinforcement Learning.](http://arxiv.org/abs/2306.16750) | ERC是一种新的值估计方法，通过在深度强化学习中利用时间差分动力学的特征子空间，实现了更高效和稳定的值估计路径。实验证明ERC有效地减少了值函数的方差，并在多项任务中优于其他最先进方法。 |
| [^38] | [Improving Fairness in Deepfake Detection.](http://arxiv.org/abs/2306.16635) | 本研究首次尝试通过提出新的损失函数来改善深度伪造检测的公平性，并在多个数据集和检测器上进行了广泛实验证明了其有效性。 |
| [^39] | [Pretraining task diversity and the emergence of non-Bayesian in-context learning for regression.](http://arxiv.org/abs/2306.15063) | 预训练的transformer在回归问题中展现了非贝叶斯上下文学习能力，其在任务多样性阈值以下表现类似于贝叶斯估计器，而在阈值以上明显优于贝叶斯估计器，与岭回归一致。 |
| [^40] | [More PAC-Bayes bounds: From bounded losses, to losses with general tail behaviors, to anytime-validity.](http://arxiv.org/abs/2306.12214) | 本文提出了一种新的高概率PAC-Bayes界限，在有界和一般尾部行为的损失中均适用。此外，这些界限还能够保持随时有效性。 |
| [^41] | [TopP\&R: Robust Support Estimation Approach for Evaluating Fidelity and Diversity in Generative Models.](http://arxiv.org/abs/2306.08013) | 本文提出了一种鲁棒可靠的生成模型评估指标TopP\&R，通过引入拓扑和统计处理进行严格的支持估计。TopP\&R仅保留具有一定置信水平的具有拓扑和统计上重要性的特征，对于噪声特征具有强大的鲁棒性，并提供了统计一致性。 |
| [^42] | [Efficient and Equivariant Graph Networks for Predicting Quantum Hamiltonian.](http://arxiv.org/abs/2306.04922) | 本文提出了一种名为QHNet的SE(3)-等变网络，具有高效和等变性。与最先进的方法相比，QHNet在更快的速度下实现了与其可比的表现，并且消耗的内存少了50％。 |
| [^43] | [Survival Instinct in Offline Reinforcement Learning.](http://arxiv.org/abs/2306.03286) | 离线强化学习算法即使使用错误的奖励标签，也能产生良好的表现和安全的策略，这种鲁棒性属性是由离线强化学习算法的悲观主义和常见数据收集实践中的偏见之间相互作用的结果，赋予了代理生存本能。 |
| [^44] | [Investigating Navigation Strategies in the Morris Water Maze through Deep Reinforcement Learning.](http://arxiv.org/abs/2306.01066) | 本文利用深度强化学习代理程序模拟了莫里斯水迷宫，通过自动分类导航策略，分析人工智能代理程序使用的策略分布，并与实验结果做对比。该研究发现了类似于人和啮齿类动物的学习规律，发展了内部表征与导航策略之间的关联，为生物学特征的探索提供了一定的参考。 |
| [^45] | [What Can We Learn from Unlearnable Datasets?.](http://arxiv.org/abs/2305.19254) | 无法学习的数据集方法具有保护数据隐私的潜力，但实际使用受到限制。我们发现神经网络在无法学习的数据集上可以学习到有用的特征，而不仅仅是简单规则，这对图像保护的效果不确定。此外，线性可分的扰动并不是诱导学习捷径的必要条件，因此不能依赖它们。 |
| [^46] | [Sample Efficient Reinforcement Learning in Mixed Systems through Augmented Samples and Its Applications to Queueing Networks.](http://arxiv.org/abs/2305.16483) | 本文提出了一种在混合系统中通过增强数据样本进行学习的方法，应用于排队网络问题，能够显著提高学习效率和降低样本复杂度。 |
| [^47] | [Concept-Centric Transformers: Concept Transformers with Object-Centric Concept Learning for Interpretability.](http://arxiv.org/abs/2305.15775) | 本文研究了以物体为中心的概念学习，它可以提高基于概念的Transformer模型的分类性能和可解释性。 |
| [^48] | [Hierarchical clustering with dot products recovers hidden tree structure.](http://arxiv.org/abs/2305.15022) | 本文发现一种基于点积的层次聚类算法，可以通过最大平均点积合并聚类，并且输出的树结构可用于准确估计数据的生成层次结构，树形恢复性能优于现有方法。 |
| [^49] | [Federated Foundation Models: Privacy-Preserving and Collaborative Learning for Large Models.](http://arxiv.org/abs/2305.11414) | 本文提出了联邦基础模型（FFMs）的概念，结合了基础模型和联邦学习的优势，可实现跨多个机构的隐私保护和协作学习。 |
| [^50] | [Variational Classification.](http://arxiv.org/abs/2305.10406) | 提出一种新的变分分类方法，通过引入潜变量建模来优化训练，允许灵活的设计选择以改善校准和对抗鲁棒性，实验结果表明其对于域外数据的分类准确性得到了保持。 |
| [^51] | [Search for the UGLE Truth: An Investigation into Unsupervised GNN Learning Environments.](http://arxiv.org/abs/2305.06026) | 本文提出了一种GNN学习环境下的社区检测算法比较框架，包括数据集和评估指标，以解决目前文献中对于基于GNN的社区检测缺乏公平且严谨评估的问题。 |
| [^52] | [PTW: Pivotal Tuning Watermarking for Pre-Trained Image Generators.](http://arxiv.org/abs/2304.07361) | PTW是一种预训练生成器水印技术，可以比从头开始水印技术快三个数量级和更好的保留了生成器的图像质量，解决了恶意用户利用提供的模型制作出有害的深度伪造而不会被发现的问题。 |
| [^53] | [FetMRQC: Automated Quality Control for fetal brain MRI.](http://arxiv.org/abs/2304.05879) | FetMRQC 是一种针对胎儿脑 MRI 的自动图像质量评估机器学习框架，通过提取一系列质量指标可以预测专家评分，并能够在大部分数据集上实现准确评估，并发布了一个新的机器学习数据集。 |
| [^54] | [Debiasing Scores and Prompts of 2D Diffusion for Robust Text-to-3D Generation.](http://arxiv.org/abs/2303.15413) | 本文提出了两种去偏置的方法，一种通过增加2D扩散模型得出的分数的截断值，一种通过调整视角提示和物体空间摄像机姿态之间的差异。实验结果表明这些方法可以显著减少伪影，提高真实感。 |
| [^55] | [PULSNAR -- Positive unlabeled learning selected not at random: class proportion estimation when the SCAR assumption does not hold.](http://arxiv.org/abs/2303.08269) | 本文提出了一种新的PU方法PULSNAR，即使在SCAR不成立时，也可以实现准确的α估计和校准模型。 |
| [^56] | [Zero-Shot Batch-Level Anomaly Detection.](http://arxiv.org/abs/2302.07849) | 本文提出了一种名为“自适应中心表示”的方法，用于零样本批次级异常检测。该方法利用批量归一化来训练现成的深度异常检测器，可以自动零样本泛化为未见过的AD任务。在实验中，该方法显示出了在多种数据集上的优秀表现，对表格数据进行了零样本AD。 |
| [^57] | [MarioGPT: Open-Ended Text2Level Generation through Large Language Models.](http://arxiv.org/abs/2302.05981) | MarioGPT是第一个文本到超级马里奥兄弟游戏关卡的生成模型，通过大型语言模型实现开放式的、可控制的关卡生成。 |
| [^58] | [Sharp Spectral Rates for Koopman Operator Learning.](http://arxiv.org/abs/2302.02004) | 本文提出了Koopman算子的非渐进学习界限，重点研究了时间可逆随机动力系统，提出了扩展动态模分解（EDMD）和降低秩回归（RRR）两种流行的估计器，并比较了它们的方差。 |
| [^59] | [Versatile Energy-Based Probabilistic Models for High Energy Physics.](http://arxiv.org/abs/2302.00695) | 本文提出了一个多功能的能量概率模型，用于描述高能物理事件，可用于参数化的事件生成，异常信号探测以及粒子识别。 |
| [^60] | [How to select an objective function using information theory.](http://arxiv.org/abs/2212.06566) | 信息论告诉我们，为了最大化模型的信息量，选择可能性最高或表示误差比特最少的客观函数。将不同的客观函数转换为似然函数，它们的相对大小表示我们应该更喜欢哪个客观函数，而其大小的对数表示模型的预期不确定性。 |
| [^61] | [Implicit models, latent compression, intrinsic biases, and cheap lunches in community detection.](http://arxiv.org/abs/2210.09186) | 本文提出了一种将社区检测目标与其对应的隐式网络生成模型相联系的解决方案，可以计算网络在任意目标下的描述长度，比较不同算法的性能，同时还可以访问隐式模型。 |
| [^62] | [Dual control variate for faster black-box variational inference.](http://arxiv.org/abs/2210.07290) | 本论文提出了双控制变量方法，能够同时减少数据子抽样和蒙特卡罗抽样带来的梯度估计方差，提高黑盒变分推断的准确性和效率。 |

# 详细

[^1]: 通过学习自然语言规则和引导来提高人工智能团队的效果

    Effective Human-AI Teams via Learned Natural Language Rules and Onboarding. (arXiv:2311.01007v1 [cs.LG])

    [http://arxiv.org/abs/2311.01007](http://arxiv.org/abs/2311.01007)

    本论文提出了一种通过学习自然语言规则和引导的方法，以提高人工智能团队的效果。通过找到数据的局部区域和使用语言模型进行描述，我们教导人类如何与AI合作。通过目标检测和问答任务的用户研究，我们证明了我们的方法可以使人工智能团队更加准确。

    

    人们越来越依赖于AI代理来帮助他们完成各种任务。人类必须知道何时依赖于代理，与代理合作或忽略其建议。在这项工作中，我们提出了一种通过数据区域和自然语言描述的学习规则的方法，以说明人类应该如何与AI合作。我们的新颖区域发现算法在嵌入空间中找到数据的局部区域作为邻域，纠正了人类的先验知识。然后，每个区域都通过迭代和对比过程进行描述，其中一个大型语言模型描述该区域。然后我们通过引导阶段将这些规则教给人类。通过在目标检测和问答任务上的用户研究，我们证明了我们的方法可以使人工智能团队更加准确。我们还分别评估了我们的区域发现和描述算法。

    People are relying on AI agents to assist them with various tasks. The human must know when to rely on the agent, collaborate with the agent, or ignore its suggestions. In this work, we propose to learn rules grounded in data regions and described in natural language that illustrate how the human should collaborate with the AI. Our novel region discovery algorithm finds local regions in the data as neighborhoods in an embedding space that corrects the human prior. Each region is then described using an iterative and contrastive procedure where a large language model describes the region. We then teach these rules to the human via an onboarding stage. Through user studies on object detection and question-answering tasks, we show that our method can lead to more accurate human-AI teams. We also evaluate our region discovery and description algorithms separately.
    
[^2]: 通过物理约束的机器学习来研究电子激发态

    Electronic excited states from physically-constrained machine learning. (arXiv:2311.00844v1 [physics.chem-ph])

    [http://arxiv.org/abs/2311.00844](http://arxiv.org/abs/2311.00844)

    本文介绍了一种综合建模方法，通过训练一个对称自适应的机器学习模型来再现量子力学计算中的电子激发，从而实现了针对更大更复杂分子的预测，并通过最小原子中心基础对应的参数化实现了极大的计算效益。

    

    数据驱动技术越来越多地用于替代物质的电子结构计算。在这种情况下，一个相关的问题是，机器学习(ML)是否应当直接应用于预测所需的性质，还是明确地与物理基础操作结合起来。我们提出了一个综合建模方法的示例，其中对一个有效哈密顿量的对称自适应ML模型进行训练，以再现量子力学计算中的电子激发。所得模型可以预测比其训练集更大更复杂的分子，并通过间接针对良好收敛计算的输出而使用与最小原子中心基础对应的参数化，实现了极大的计算效益。这些结果强调了将数据驱动技术与物理近似相结合的优点，提高了ML模型的可转移性和可解释性，而不需要明确建立物理模型。

    Data-driven techniques are increasingly used to replace electronic-structure calculations of matter. In this context, a relevant question is whether machine learning (ML) should be applied directly to predict the desired properties or be combined explicitly with physically-grounded operations. We present an example of an integrated modeling approach, in which a symmetry-adapted ML model of an effective Hamiltonian is trained to reproduce electronic excitations from a quantum-mechanical calculation. The resulting model can make predictions for molecules that are much larger and more complex than those that it is trained on, and allows for dramatic computational savings by indirectly targeting the outputs of well-converged calculations while using a parameterization corresponding to a minimal atom-centered basis. These results emphasize the merits of intertwining data-driven techniques with physical approximations, improving the transferability and interpretability of ML models without a
    
[^3]: 噪声图中的鲁棒图聚类通过元权重

    Robust Graph Clustering via Meta Weighting for Noisy Graphs. (arXiv:2311.00322v1 [cs.LG])

    [http://arxiv.org/abs/2311.00322](http://arxiv.org/abs/2311.00322)

    该论文提出了一种鲁棒的基于元权重的图聚类方法，通过对节点对应权重的自适应调整，能够在存在噪声边的图中找到有意义的聚类。

    

    如何在噪声边上鲁棒地找到图中的有意义的聚类？图聚类是图分析中的一个基本问题，应用于各个领域。最近的研究表明，基于图神经网络（GNN）的方法在图聚类方面取得了有希望的结果。然而，我们观察到它们在存在噪声边的图上的性能明显下降。在这项工作中，我们提出了用于鲁棒GNN-based图聚类的MetaGC。MetaGC采用可分解的聚类损失函数，将其重新表述为节点对之间损失的求和。我们为每个节点对添加可学习的权重，并使用元权重来自适应地调整节点对的权重，使有意义的节点对的权重增加，而不那么有意义的节点对（例如噪声边）的权重减小。我们通过实验证明，MetaGC按照预期学习权重，并且因此在性能上优于其他方法。

    How can we find meaningful clusters in a graph robustly against noise edges? Graph clustering (i.e., dividing nodes into groups of similar ones) is a fundamental problem in graph analysis with applications in various fields. Recent studies have demonstrated that graph neural network (GNN) based approaches yield promising results for graph clustering. However, we observe that their performance degenerates significantly on graphs with noise edges, which are prevalent in practice. In this work, we propose MetaGC for robust GNN-based graph clustering. MetaGC employs a decomposable clustering loss function, which can be rephrased as a sum of losses over node pairs. We add a learnable weight to each node pair, and MetaGC adaptively adjusts the weights of node pairs using meta-weighting so that the weights of meaningful node pairs increase and the weights of less-meaningful ones (e.g., noise edges) decrease. We show empirically that MetaGC learns weights as intended and consequently outperfor
    
[^4]: 学习生成参数概率模型的随机热力学

    Stochastic Thermodynamics of Learning Generative Parametric Probabilistic Models. (arXiv:2310.19802v1 [cs.LG])

    [http://arxiv.org/abs/2310.19802](http://arxiv.org/abs/2310.19802)

    本文将生成式机器学习问题视为参数概率模型的时间演化过程，通过研究模型参数与生成样本之间的热力学交换，发现模型通过耗散热量来学习，参数子系统充当热库存储学到的信息。这为超参数模型的泛化能力提供了有价值的热力学洞察。

    

    我们将生成式机器学习问题形式化为参数化概率模型（PPM）的时间演化，从本质上来说，这是一个热力学过程。然后，我们研究了模型参数（记为$\Theta$）与模型生成样本（记为$X$）之间的热力学交换。我们证明了训练数据集和随机梯度下降（SGD）优化器的作用是驱动这两个子系统的时间演化的能源。我们的发现表明，在生成样本$X$的过程中，模型通过耗散热量来学习，导致模型参数$\Theta$的熵增加。因此，参数子系统充当了一个热库，有效地存储了学到的信息。此外，模型参数作为热库的角色为超参数模型的泛化能力提供了有价值的热力学洞察。这种方法提供了一个明确且一致的方式来理解生成模型学习过程中的热力学行为。

    We have formulated generative machine learning problems as the time evolution of Parametric Probabilistic Models (PPMs), inherently rendering a thermodynamic process. Then, we have studied the thermodynamic exchange between the model's parameters, denoted as $\Theta$, and the model's generated samples, denoted as $X$. We demonstrate that the training dataset and the action of the Stochastic Gradient Descent (SGD) optimizer serve as a work source that governs the time evolution of these two subsystems. Our findings reveal that the model learns through the dissipation of heat during the generation of samples $X$, leading to an increase in the entropy of the model's parameters, $\Theta$. Thus, the parameter subsystem acts as a heat reservoir, effectively storing the learned information. Furthermore, the role of the model's parameters as a heat reservoir provides valuable thermodynamic insights into the generalization power of over-parameterized models. This approach offers an unambiguous 
    
[^5]: 多模态数据的因果分解

    Causal disentanglement of multimodal data. (arXiv:2310.18471v1 [cs.LG])

    [http://arxiv.org/abs/2310.18471](http://arxiv.org/abs/2310.18471)

    这篇论文介绍了一种可以利用多模态数据和已知物理学知识发现因果关系的因果表示学习算法。

    

    因果表示学习算法发现了数据的较低维度表示，可以对因果关系进行可解释的解释；由于实现这样的可解释表示很具挑战性，许多因果学习算法利用了指示先验信息的元素，例如（线性）结构因果模型、干预数据或弱监督。然而，在探索性因果表示学习中，这些元素和先验信息可能不可用或不合适。相反，科学数据集通常具有多个模态或基于物理学的约束，并且已经证明在完全无监督的设置中使用这种科学的多模态数据可以改善因果分解。因此，我们引入了一种因果表示学习算法（causalPIMA），它可以利用多模态数据和已知的物理学知识发现具有因果关系的重要特征。我们的创新算法利用新的可微参数化来学习这种因果关系。

    Causal representation learning algorithms discover lower-dimensional representations of data that admit a decipherable interpretation of cause and effect; as achieving such interpretable representations is challenging, many causal learning algorithms utilize elements indicating prior information, such as (linear) structural causal models, interventional data, or weak supervision. Unfortunately, in exploratory causal representation learning, such elements and prior information may not be available or warranted. Alternatively, scientific datasets often have multiple modalities or physics-based constraints, and the use of such scientific, multimodal data has been shown to improve disentanglement in fully unsupervised settings. Consequently, we introduce a causal representation learning algorithm (causalPIMA) that can use multimodal data and known physics to discover important features with causal relationships. Our innovative algorithm utilizes a new differentiable parametrization to lear
    
[^6]: 流式因子轨迹学习用于时间张量分解

    Streaming Factor Trajectory Learning for Temporal Tensor Decomposition. (arXiv:2310.17021v1 [cs.LG])

    [http://arxiv.org/abs/2310.17021](http://arxiv.org/abs/2310.17021)

    这篇论文提出了一种流式因子轨迹学习方法，用于时间张量分解。该方法使用高斯过程来灵活估计因子的时间演变，并开发了一种高效的在线滤波算法来估计因子状态的演变轨迹。

    

    实际的张量数据通常具有时间信息。大多数现有的时间分解方法估计每个张量模式中对象的一组固定因子，因此无法捕捉对象表示的时间演变。更重要的是，我们缺乏从流数据中捕捉这种演变的有效方法，在现实世界的应用中很常见。为了解决这些问题，我们提出了用于时间张量分解的流式因子轨迹学习（SFTL）。我们使用高斯过程（GPs）来建模因子的轨迹，从而灵活地估计它们的时间演变。为了解决处理流数据时的计算挑战，我们通过构造等效的随机微分方程（SDE）将GPs转换为状态空间先验。我们开发了一种高效的在线滤波算法，在接收到新数据时估计涉及的因子状态的分解式运行后验。分解估计使我们能够同时学习多个因子的演变轨迹。

    Practical tensor data is often along with time information. Most existing temporal decomposition approaches estimate a set of fixed factors for the objects in each tensor mode, and hence cannot capture the temporal evolution of the objects' representation. More important, we lack an effective approach to capture such evolution from streaming data, which is common in real-world applications. To address these issues, we propose Streaming Factor Trajectory Learning (SFTL) for temporal tensor decomposition. We use Gaussian processes (GPs) to model the trajectory of factors so as to flexibly estimate their temporal evolution. To address the computational challenges in handling streaming data, we convert the GPs into a state-space prior by constructing an equivalent stochastic differential equation (SDE). We develop an efficient online filtering algorithm to estimate a decoupled running posterior of the involved factor states upon receiving new data. The decoupled estimation enables us to co
    
[^7]: MACP：高效的合作感知模型适应

    MACP: Efficient Model Adaptation for Cooperative Perception. (arXiv:2310.16870v1 [cs.CV])

    [http://arxiv.org/abs/2310.16870](http://arxiv.org/abs/2310.16870)

    本文提出了MACP框架，通过将单个预训练模型配备合作能力来提高连接和自动驾驶车辆的感知能力。通过冻结大部分参数并添加几个轻量级模块，该框架能够有效利用合作观测，并在模拟和真实环境中胜过其他最先进的方法。

    

    车辆间的通信极大地增强了连接和自动驾驶车辆的感知能力，通过实现信息共享以"穿透"遮挡物，从而显著提高性能。然而，从头开始开发和训练复杂的多智能体感知模型可能昂贵且不必要，因为现有的单智能体模型展现出了令人瞩目的泛化能力。在本文中，我们提出了一个名为MACP的新框架，将单个预训练模型配备了合作能力。我们通过确定从单智能体到合作环境的关键挑战，通过冻结大部分参数并添加几个轻量级模块来使模型适应。我们在实验中证明，所提出的框架可以有效利用合作观测，并在模拟和真实环境中胜过其他最先进的方法。

    Vehicle-to-vehicle (V2V) communications have greatly enhanced the perception capabilities of connected and automated vehicles (CAVs) by enabling information sharing to "see through the occlusions", resulting in significant performance improvements. However, developing and training complex multi-agent perception models from scratch can be expensive and unnecessary when existing single-agent models show remarkable generalization capabilities. In this paper, we propose a new framework termed MACP, which equips a single-agent pre-trained model with cooperation capabilities. We approach this objective by identifying the key challenges of shifting from single-agent to cooperative settings, adapting the model by freezing most of its parameters and adding a few lightweight modules. We demonstrate in our experiments that the proposed framework can effectively utilize cooperative observations and outperform other state-of-the-art approaches in both simulated and real-world cooperative perception
    
[^8]: 物理信息图卷积网络：面向复杂几何的广义框架

    Physics-Informed Graph Convolutional Networks: Towards a generalized framework for complex geometries. (arXiv:2310.14948v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.14948](http://arxiv.org/abs/2310.14948)

    本研究提出了物理信息图卷积网络作为解决复杂几何体中偏微分方程问题的广义框架，并结合经典数值求解器从而解决了物理信息框架在复杂几何体上的问题。

    

    自从[9]的开创性工作以及他们的物理信息神经网络（PINNs）之后，已经有很多工作致力于使用深度学习模型来解决偏微分方程（PDEs）。然而，仍然存在一些挑战，例如将这些模型扩展到复杂的三维几何体，以及如何将这些方法与经典的数值求解器结合起来进行研究。在本工作中，我们基于图神经网络和传统数值技术中用于求解偏微分方程的网格之间的相似性，证明了将图神经网络用于这些问题的合理性。在证明了物理信息框架在复杂几何体上计算PDE残差时存在问题后，我们提出了一种替代方案，将经典的数值求解器与物理信息框架相结合。最后，我们提出了一种实现该方法的方案，并在一个不规则几何体上的三维问题上进行了测试。

    Since the seminal work of [9] and their Physics-Informed neural networks (PINNs), many efforts have been conducted towards solving partial differential equations (PDEs) with Deep Learning models. However, some challenges remain, for instance the extension of such models to complex three-dimensional geometries, and a study on how such approaches could be combined to classical numerical solvers. In this work, we justify the use of graph neural networks for these problems, based on the similarity between these architectures and the meshes used in traditional numerical techniques for solving partial differential equations. After proving an issue with the Physics-Informed framework for complex geometries, during the computation of PDE residuals, an alternative procedure is proposed, by combining classical numerical solvers and the Physics-Informed framework. Finally, we propose an implementation of this approach, that we test on a three-dimensional problem on an irregular geometry.
    
[^9]: AI反馈促进的质量-多样性算法

    Quality-Diversity through AI Feedback. (arXiv:2310.13032v1 [cs.CL])

    [http://arxiv.org/abs/2310.13032](http://arxiv.org/abs/2310.13032)

    基于AI反馈的质量-多样性（QDAIF）算法利用语言模型来生成和评估创造性写作，比传统算法更广泛地覆盖高质量样本的搜索空间。

    

    在许多文本生成问题中，用户可能不仅偏好单一回复，而是希望得到多样性的高质量输出以供选择。质量-多样性（QD）搜索算法旨在通过不断改进和多样化候选人群来实现这一目标。然而，QD在创作性写作等质性领域的应用受到算法指定质量和多样性度量的困难的限制。有趣的是，最近语言模型（LMs）的发展使得通过AI反馈指导搜索成为可能，其中LMs在自然语言中被提示来评估文本的质性方面。借助这一进展，我们引入了通过AI反馈实现的质量-多样性算法（QDAIF），其中进化算法应用LMs来生成变异并评估候选文本的质量和多样性。在创作性写作领域的评估中，与非QDAIF算法相比，QDAIF更广泛地覆盖高质量样本的指定搜索空间。

    In many text-generation problems, users may prefer not only a single response, but a diverse range of high-quality outputs from which to choose. Quality-diversity (QD) search algorithms aim at such outcomes, by continually improving and diversifying a population of candidates. However, the applicability of QD to qualitative domains, like creative writing, has been limited by the difficulty of algorithmically specifying measures of quality and diversity. Interestingly, recent developments in language models (LMs) have enabled guiding search through AI feedback, wherein LMs are prompted in natural language to evaluate qualitative aspects of text. Leveraging this development, we introduce Quality-Diversity through AI Feedback (QDAIF), wherein an evolutionary algorithm applies LMs to both generate variation and evaluate the quality and diversity of candidate text. When assessed on creative writing domains, QDAIF covers more of a specified search space with high-quality samples than do non-
    
[^10]: 电子健康记录的问题回答：数据集和模型的范围回顾

    Question Answering for Electronic Health Records: A Scoping Review of datasets and models. (arXiv:2310.08759v1 [cs.LG])

    [http://arxiv.org/abs/2310.08759](http://arxiv.org/abs/2310.08759)

    本文对电子健康记录（EHR）中的问题回答进行了范围回顾。与其他医学QA任务不同，EHR QA通过从患者的医疗记录中获取答案。这项研究为现有的EHR QA作品提供了方法论回顾。

    

    与患者相关的问题回答（QA）系统可以帮助临床医生和患者。它们可以帮助临床医生做决策，并使患者更好地了解他们的病历。大量的患者数据存储在电子健康记录（EHR）中，使得EHR QA成为一个重要的研究领域。在EHR QA中，答案是从患者的医疗记录中获得的。由于数据格式和模式的差异，这与其他使用医学网站或科学论文检索答案的医学QA任务有很大的不同，这使得研究EHR问题回答变得至关重要。本研究旨在对现有关于EHR QA的作品进行方法论回顾。我们在包括Google Scholar、ACL Anthology、ACM Digital Library和PubMed在内的四个数字资源中搜索了从2005年1月1日到2023年9月30日的文章，以收集有关EHR QA的相关出版物。共发现了4111篇论文。

    Question Answering (QA) systems on patient-related data can assist both clinicians and patients. They can, for example, assist clinicians in decision-making and enable patients to have a better understanding of their medical history. Significant amounts of patient data are stored in Electronic Health Records (EHRs), making EHR QA an important research area. In EHR QA, the answer is obtained from the medical record of the patient. Because of the differences in data format and modality, this differs greatly from other medical QA tasks that employ medical websites or scientific papers to retrieve answers, making it critical to research EHR question answering. This study aimed to provide a methodological review of existing works on QA over EHRs. We searched for articles from January 1st, 2005 to September 30th, 2023 in four digital sources including Google Scholar, ACL Anthology, ACM Digital Library, and PubMed to collect relevant publications on EHR QA. 4111 papers were identified for our
    
[^11]: LGL-BCI：一种轻量级几何学习框架用于基于运动想象的脑机接口

    LGL-BCI: A Lightweight Geometric Learning Framework for Motor Imagery-Based Brain-Computer Interfaces. (arXiv:2310.08051v1 [cs.LG])

    [http://arxiv.org/abs/2310.08051](http://arxiv.org/abs/2310.08051)

    LGL-BCI是一种轻量级几何学习框架，通过处理EEG数据在非欧几里德度量空间中捕捉运动想象任务的空间相关性，并通过特征分解算法进行EEG通道选择以提高推断速度。实验证明LGL-BCI相比现有解决方案具有更高的准确性和效率。

    

    脑机接口是一种使用脑信号与外部设备进行交互的开创性技术。尽管有所进展，基于脑电图（EEG）的运动想象任务面临挑战，如幅度和相位变异，以及复杂的空间相关性，需要更小的模型大小和更快的推断。本研究介绍了LGL-BCI框架，采用几何深度学习框架处理非欧几里德度量空间中的EEG，特别是对称正定（SPD）流形空间。LGL-BCI提供了稳健的EEG数据表示，并捕捉了空间相关性。我们提出了一种通过特征分解算法进行EEG通道选择的解决方案，以减少SPD矩阵的维度，同时提高了推断速度。广泛的实验显示，与当前解决方案相比，LGL-BCI具有更高的准确性和效率，突出了几何深度学习在运动想象-脑机接口应用中的潜力。

    Brain-Computer Interfaces (BCIs) are a groundbreaking technology for interacting with external devices using brain signals. Despite advancements, electroencephalogram (EEG)-based Motor Imagery (MI) tasks face challenges like amplitude and phase variability, and complex spatial correlations, with a need for smaller model size and faster inference. This study introduces the LGL-BCI framework, employing a Geometric Deep Learning Framework for EEG processing in non-Euclidean metric spaces, particularly the Symmetric Positive Definite (SPD) Manifold space. LGL-BCI offers robust EEG data representation and captures spatial correlations. We propose an EEG channel selection solution via a feature decomposition algorithm to reduce SPD matrix dimensionality, with a lossless transformation boosting inference speed. Extensive experiments show LGL-BCI's superior accuracy and efficiency compared to current solutions, highlighting geometric deep learning's potential in MI-BCI applications. The effici
    
[^12]: RTDK-BO：具有Reinforced Transformer深度核函数的高维贝叶斯优化

    RTDK-BO: High Dimensional Bayesian Optimization with Reinforced Transformer Deep kernels. (arXiv:2310.03912v1 [cs.LG])

    [http://arxiv.org/abs/2310.03912](http://arxiv.org/abs/2310.03912)

    本文提出了一种新的提高贝叶斯优化模型建模能力的方法，通过将注意机制融入深度核学习中，使得代理能够适应上下文信息，提高优化性能。

    

    贝叶斯优化（BO）通过高斯过程（GP）代理指导，已经被证明是一种对于高维黑盒优化非常有效的技术，在工业设计和科学计算等许多应用中具有重要意义。最近的研究在单函数优化和少样本多目标优化上引入了强化学习（RL）来提高优化性能。然而，即使是少样本技术也不能充分利用紧密相关目标之间的相似性。本文结合了深度核学习（DKL）和基于注意力的Transformer模型的最新进展，改进了GP代理的建模能力与元学习相结合。我们提出了一种新的方法，通过将注意机制融入DKL中来改进元学习BO代理，使代理能够在BO过程中适应上下文信息。我们将这种Transformer深度核方法与少样本元学习相结合，通过元学习来提高BO的建模能力。

    Bayesian Optimization (BO), guided by Gaussian process (GP) surrogates, has proven to be an invaluable technique for efficient, high-dimensional, black-box optimization, a critical problem inherent to many applications such as industrial design and scientific computing. Recent contributions have introduced reinforcement learning (RL) to improve the optimization performance on both single function optimization and \textit{few-shot} multi-objective optimization. However, even few-shot techniques fail to exploit similarities shared between closely related objectives. In this paper, we combine recent developments in Deep Kernel Learning (DKL) and attention-based Transformer models to improve the modeling powers of GP surrogates with meta-learning. We propose a novel method for improving meta-learning BO surrogates by incorporating attention mechanisms into DKL, empowering the surrogates to adapt to contextual information gathered during the BO process. We combine this Transformer Deep Kern
    
[^13]: 用强化学习实现的PyDCM：为可持续性定制数据中心模型

    PyDCM: Custom Data Center Models with Reinforcement Learning for Sustainability. (arXiv:2310.03906v1 [cs.LG])

    [http://arxiv.org/abs/2310.03906](http://arxiv.org/abs/2310.03906)

    PyDCM是一个用强化学习实现的可定制的数据中心模型，通过使用自定义配置和向量化的热计算，实现了对数据中心的优化，具有较高的效率。

    

    全球对可持续性和减少碳排放的强调日益增加，促使政府和企业重新思考数据中心的设计和运营方法。鉴于数据中心的高能耗和指数级计算工作量，优化能耗特别是在冷却和IT能源使用方面，数据中心是优化电力消耗的理想候选。解决这个问题的一个重要挑战是缺乏可配置和可扩展的热数据中心模型，它提供了一个端到端的管道。数据中心由多个IT组件组成，其几何配置和散热使得热建模变得困难。本文介绍了PyDCM，这是一个用Python实现的可定制的数据中心模型，用户可以使用自定义的服务器规格和IT机柜的几何布置创建独特的配置。使用向量化的热计算使得PyDCM比当前方法快了数个数量级（30倍）。

    The increasing global emphasis on sustainability and reducing carbon emissions is pushing governments and corporations to rethink their approach to data center design and operation. Given their high energy consumption and exponentially large computational workloads, data centers are prime candidates for optimizing power consumption, especially in areas such as cooling and IT energy usage. A significant challenge in this pursuit is the lack of a configurable and scalable thermal data center model that offers an end-to-end pipeline. Data centers consist of multiple IT components whose geometric configuration and heat dissipation make thermal modeling difficult. This paper presents PyDCM, a customizable Data Center Model implemented in Python, that allows users to create unique configurations of IT equipment with custom server specifications and geometric arrangements of IT cabinets. The use of vectorized thermal calculations makes PyDCM orders of magnitude faster (30 times) than current 
    
[^14]: 完全连接的ReLU层的几何结构

    The Geometric Structure of Fully-Connected ReLU-Layers. (arXiv:2310.03482v1 [cs.LG])

    [http://arxiv.org/abs/2310.03482](http://arxiv.org/abs/2310.03482)

    该论文研究了神经网络中完全连接的ReLU层的几何结构。研究发现，在每个划分区域内，ReLU层可以被大大简化，可以将其解释为一个投影到多面体锥体，然后进行仿射变换。此结构还简化了分区区域与超平面交集的反像表达式，对于描述分类问题中的决策边界非常有用。此外，对于具有一个隐藏ReLU层的前馈网络，论文提供了关于这些网络生成的决策边界几何复杂性的结果，并证明了这些决策边界在仿射变换的模下是相等的。

    

    我们对神经网络中d维完全连接的ReLU层的几何结构进行了形式化和解释。ReLU层的参数会引导输入域的自然划分，使得在划分的每个区域内，ReLU层可以被大大简化。这导致了将ReLU层解释为一个投影到多面体锥体，然后进行仿射变换的几何解释，与在具有ReLU激活的卷积网络中的描述一致。此外，这种结构便于简化分区区域与超平面交集的反像表达式，这在描述分类问题中的决策边界时非常有用。我们详细研究了具有一个隐藏ReLU层的前馈网络，在这个网络中，我们提供了关于这些网络生成的决策边界的几何复杂性的结果，同时证明在仿射变换的模下，这些决策边界相等。

    We formalize and interpret the geometric structure of $d$-dimensional fully connected ReLU-layers in neural networks. The parameters of a ReLU-layer induce a natural partition of the input domain, such that in each sector of the partition, the ReLU-layer can be greatly simplified. This leads to a geometric interpretation of a ReLU-layer as a projection onto a polyhedral cone followed by an affine transformation, in line with the description in [doi:10.48550/arXiv.1905.08922] for convolutional networks with ReLU activations. Further, this structure facilitates simplified expressions for preimages of the intersection between partition sectors and hyperplanes, which is useful when describing decision boundaries in a classification setting. We investigate this in detail for a feed-forward network with one hidden ReLU-layer, where we provide results on the geometric complexity of the decision boundary generated by such networks, as well as proving that modulo an affine transformation, such 
    
[^15]: PB-LLM: 部分二值化大型语言模型

    PB-LLM: Partially Binarized Large Language Models. (arXiv:2310.00034v1 [cs.LG])

    [http://arxiv.org/abs/2310.00034](http://arxiv.org/abs/2310.00034)

    本文提出的PB-LLM是一种部分二值化的大型语言模型压缩方法，可以在保持语言推理能力的同时实现极低比特量化，并通过后训练量化和量化感知训练等方法恢复量化LLMM的容量。

    

    本文探讨了网络二值化，一种压缩模型权重为单个比特的量化的激进形式，专门应用于大型语言模型（LLMs）的压缩。由于之前的二值化方法会导致LLMs崩溃，我们提出了一种新颖的方法，部分二值化LLM（PB-LLM），可以实现极低比特量化，并同时保持量化LLMs的语言推理能力。具体而言，我们的研究首先揭示了现有二值化算法的原生应用的无效性，并强调了显著权重在实现低位量化中的重要作用。因此，PB-LLM在二进制化过程中过滤了一小部分显著权重，将它们分配到高位存储中，即部分二值化。PB-LLM在后训练量化（PTQ）和量化感知训练（QAT）的角度分析后，扩展了恢复量化LLMM容量的能力。在PTQ下，结合了GPTQ的概念，我们重构了...

    This paper explores network binarization, a radical form of quantization, compressing model weights to a single bit, specifically for Large Language Models (LLMs) compression. Due to previous binarization methods collapsing LLMs, we propose a novel approach, Partially-Binarized LLM (PB-LLM), which can achieve extreme low-bit quantization while maintaining the linguistic reasoning capacity of quantized LLMs. Specifically, our exploration first uncovers the ineffectiveness of naive applications of existing binarization algorithms and highlights the imperative role of salient weights in achieving low-bit quantization. Thus, PB-LLM filters a small ratio of salient weights during binarization, allocating them to higher-bit storage, i.e., partially-binarization. PB-LLM is extended to recover the capacities of quantized LMMs, by analyzing from the perspective of post-training quantization (PTQ) and quantization-aware training (QAT). Under PTQ, combining the concepts from GPTQ, we reconstruct 
    
[^16]: 对嗜酸性粒细胞分割的不确定性量化

    Uncertainty Quantification for Eosinophil Segmentation. (arXiv:2309.16536v1 [eess.IV])

    [http://arxiv.org/abs/2309.16536](http://arxiv.org/abs/2309.16536)

    本研究提出了一种改进的方法，利用深度图像分割和蒙特卡洛辍学来量化嗜酸性粒细胞，为诊断嗜酸性食管炎提供不确定性评估和模型性能可视化。

    

    嗜酸性食管炎（EoE）是一种日益普及的过敏性疾病。为了诊断EoE，病理学家必须在一个高倍视场（400倍放大率）内找到15个或更多的嗜酸性粒细胞。确定一个患者是否患有EoE可以是一个艰巨的过程，并且用于辅助诊断的任何医学成像方法都必须考虑效率和精确性。我们提出了一种改进Adorno等人对使用深度图像分割进行嗜酸性粒细胞定量的方法。我们的新方法利用了蒙特卡洛辍学（Monte Carlo Dropout），这是深度学习中常用的一种减少过拟合的方法，用于对当前深度学习模型进行不确定性量化。不确定性可以在输出图像中可视化，以评估模型性能，理解深度学习算法的工作原理，并帮助病理学家识别嗜酸性粒细胞。

    Eosinophilic Esophagitis (EoE) is an allergic condition increasing in prevalence. To diagnose EoE, pathologists must find 15 or more eosinophils within a single high-power field (400X magnification). Determining whether or not a patient has EoE can be an arduous process and any medical imaging approaches used to assist diagnosis must consider both efficiency and precision. We propose an improvement of Adorno et al's approach for quantifying eosinphils using deep image segmentation. Our new approach leverages Monte Carlo Dropout, a common approach in deep learning to reduce overfitting, to provide uncertainty quantification on current deep learning models. The uncertainty can be visualized in an output image to evaluate model performance, provide insight to how deep learning algorithms function, and assist pathologists in identifying eosinophils.
    
[^17]: 角度优化的文本嵌入

    AnglE-Optimized Text Embeddings. (arXiv:2309.12871v1 [cs.CL])

    [http://arxiv.org/abs/2309.12871](http://arxiv.org/abs/2309.12871)

    本文提出了一种名为AnglE的角度优化文本嵌入模型，通过在复杂空间中引入角度优化来缓解文本嵌入中余弦函数饱和区域造成的梯度消失问题。该模型在多个STS任务中实现了高质量的文本嵌入，并在有限标签数据的特定领域STS场景中展现出优秀的性能。

    

    高质量的文本嵌入对于提升语义文本相似度（STS）任务至关重要，而这些任务又是大型语言模型（LLM）应用中的关键组成部分。然而，现有的文本嵌入模型面临的一个普遍挑战是渐变消失问题，主要是由于它们在优化目标中依赖余弦函数，而余弦函数具有饱和区域。为了解决这个问题，本文提出了一种称为AnglE的新型角度优化文本嵌入模型。AnglE的核心思想是在一个复杂空间中引入角度优化。这种新颖的方法有效地缓解了余弦函数饱和区域产生的不利影响，从而可以阻碍梯度并阻碍优化过程。为了建立全面的STS评估，我们在现有的短文本STS数据集和从GitHub Issues中新收集的长文本STS数据集上进行了实验。此外，我们还研究了具有有限标签数据的特定领域STS场景，并探讨了AnglE的工作原理。

    High-quality text embedding is pivotal in improving semantic textual similarity (STS) tasks, which are crucial components in Large Language Model (LLM) applications. However, a common challenge existing text embedding models face is the problem of vanishing gradients, primarily due to their reliance on the cosine function in the optimization objective, which has saturation zones. To address this issue, this paper proposes a novel angle-optimized text embedding model called AnglE. The core idea of AnglE is to introduce angle optimization in a complex space. This novel approach effectively mitigates the adverse effects of the saturation zone in the cosine function, which can impede gradient and hinder optimization processes. To set up a comprehensive STS evaluation, we experimented on existing short-text STS datasets and a newly collected long-text STS dataset from GitHub Issues. Furthermore, we examine domain-specific STS scenarios with limited labeled data and explore how AnglE works w
    
[^18]: PDFTriage: 对长篇结构化文档进行问答

    PDFTriage: Question Answering over Long, Structured Documents. (arXiv:2309.08872v1 [cs.CL])

    [http://arxiv.org/abs/2309.08872](http://arxiv.org/abs/2309.08872)

    PDFTriage是一种处理长篇结构化文档问答的方法，通过使用结构或内容来检索上下文，解决了大型语言模型在问答中遇到的问题。

    

    大型语言模型在处理长篇文档的问答时存在问题，因为文档无法适应语言模型的上下文长度限制。为了解决这个问题，现有的大多数方法集中于从文档中检索相关的上下文，并将其表示为纯文本。然而，像PDF、网页和演示文稿这样的文档是有结构的，包括不同的页码、表格、章节等。将这样的结构化文档表示为纯文本与用户对这些具有丰富结构的文档的认知模型不符。当系统需要从文档中查询上下文时，这种不符会显现出来，甚至简单的问题也可能使问答系统出错。为了弥合处理结构化文档中的基本差距，我们提出了一种名为PDFTriage的方法，使模型能够根据结构或内容检索上下文。我们的实验证明了所提出的PDFTriage的有效性。

    Large Language Models (LLMs) have issues with document question answering (QA) in situations where the document is unable to fit in the small context length of an LLM. To overcome this issue, most existing works focus on retrieving the relevant context from the document, representing them as plain text. However, documents such as PDFs, web pages, and presentations are naturally structured with different pages, tables, sections, and so on. Representing such structured documents as plain text is incongruous with the user's mental model of these documents with rich structure. When a system has to query the document for context, this incongruity is brought to the fore, and seemingly trivial questions can trip up the QA system. To bridge this fundamental gap in handling structured documents, we propose an approach called PDFTriage that enables models to retrieve the context based on either structure or content. Our experiments demonstrate the effectiveness of the proposed PDFTriage-augmente
    
[^19]: 通过共线约束注意力解决Transformer的头痛问题

    Cure the headache of Transformers via Collinear Constrained Attention. (arXiv:2309.08646v1 [cs.LG])

    [http://arxiv.org/abs/2309.08646](http://arxiv.org/abs/2309.08646)

    通过引入共线约束注意力（CoCA）结构，解决Transformer模型中的头痛问题，实现了出色的外推性能和提高的计算效率。

    

    随着基于大型语言模型的实际应用的快速进展，推断性能的外推变得在研究领域中变得越来越重要。在我们的研究中，我们发现了Transformer模型中的一个被之前忽视的异常行为，导致了最接近的标记之间的混乱，这些标记携带了最重要的信息。我们将这一发现称为“Transformer的头痛问题”。为了从根本上解决这个问题，我们引入了一种新的自注意结构，命名为Collinear Constrained Attention（CoCA）。这个结构可以无缝地与现有的推断、插值方法和其他针对传统Transformer模型设计的优化策略集成。我们在推断过程中实现了优秀的外推性能，即使是16到24倍的序列长度，而且没有对我们的模型进行任何微调。我们还增强了CoCA的计算和空间效率，以确保其实用性。我们计划...

    As the rapid progression of practical applications based on Large Language Models continues, the importance of extrapolating performance has grown exponentially in the research domain. In our study, we identified an anomalous behavior in Transformer models that had been previously overlooked, leading to a chaos around closest tokens which carried the most important information. We've coined this discovery the "headache of Transformers". To address this at its core, we introduced a novel self-attention structure named Collinear Constrained Attention (CoCA). This structure can be seamlessly integrated with existing extrapolation, interpolation methods, and other optimization strategies designed for traditional Transformer models. We have achieved excellent extrapolating performance even for 16 times to 24 times of sequence lengths during inference without any fine-tuning on our model. We have also enhanced CoCA's computational and spatial efficiency to ensure its practicality. We plan to
    
[^20]: 链式思考推理是一种策略改进操作

    Chain-of-Thought Reasoning is a Policy Improvement Operator. (arXiv:2309.08589v1 [cs.LG])

    [http://arxiv.org/abs/2309.08589](http://arxiv.org/abs/2309.08589)

    大型语言模型SECToR通过链式思考推理成功地自学新技能，

    

    大型语言模型以其令人赞叹的新能力令世界为之惊叹。然而，它们目前缺乏自我学习新技能的能力，而是依赖于接受大量由人类生成的数据的训练。我们介绍了SECToR（通过链式思考推理实现自我教育），这是一个概念验证，证明语言模型可以通过链式思考推理成功地自学新技能。受到以前在强化学习（Silver等人，2017）和人类认知（Kahneman，2011）中的相关工作的启发，SECToR首先使用链式思考推理逐渐思考问题。然后，SECToR通过微调模型生成相同的答案，这次不再使用链式思考推理。通过SECToR训练的语言模型自主学会了进行多达29位数字的加法运算，而没有任何超过6位数字的基准真实示例，仅通过初始的监督微调阶段。我们的核心假设是...

    Large language models have astounded the world with fascinating new capabilities. However, they currently lack the ability to teach themselves new skills, relying instead on being trained on large amounts of human-generated data. We introduce SECToR (Self-Education via Chain-of-Thought Reasoning), a proof-of-concept demonstration that language models can successfully teach themselves new skills using chain-of-thought reasoning. Inspired by previous work in both reinforcement learning (Silver et al., 2017) and human cognition (Kahneman, 2011), SECToR first uses chain-of-thought reasoning to slowly think its way through problems. SECToR then fine-tunes the model to generate those same answers, this time without using chain-of-thought reasoning. Language models trained via SECToR autonomously learn to add up to 29-digit numbers without any access to any ground truth examples beyond an initial supervised fine-tuning phase consisting only of numbers with 6 or fewer digits. Our central hypot
    
[^21]: Oobleck：使用流水线模板实现大型模型的弹性分布式训练

    Oobleck: Resilient Distributed Training of Large Models Using Pipeline Templates. (arXiv:2309.08125v1 [cs.DC])

    [http://arxiv.org/abs/2309.08125](http://arxiv.org/abs/2309.08125)

    Oobleck采用流水线模板和已复制模型状态来实现对大型模型的弹性分布式训练，并通过有效利用资源和快速恢复来提供高吞吐量。在评估中，Oobleck在吞吐量上胜过了Bamboo和Varuna等最先进的容错解决方案。

    

    Oobleck通过采用规定的容错率，可实现对大型深度神经网络模型的弹性分布式训练。它采用了规划-执行的协同设计方法，首先生成一组异构的流水线模板，并实例化至少$ f + 1 $个逻辑等效的流水线副本，以容纳任何$f$个同时故障。在执行过程中，它依赖于跨副本的已复制模型状态来提供快速恢复。Oobleck可以可靠地保证在$f$个或更少的同时故障后，初始创建的流水线模板的某种组合可以用于覆盖所有可用资源，从而始终避免资源闲置。在具有数十亿参数的大型深度神经网络模型上的评估表明，Oobleck提供了一致高吞吐量，并且在吞吐量上胜过了Bamboo和Varuna等最先进的容错解决方案。

    Oobleck enables resilient distributed training of large DNN models with guaranteed fault tolerance. It takes a planning-execution co-design approach, where it first generates a set of heterogeneous pipeline templates and instantiates at least $f+1$ logically equivalent pipeline replicas to tolerate any $f$ simultaneous failures. During execution, it relies on already-replicated model states across the replicas to provide fast recovery. Oobleck provably guarantees that some combination of the initially created pipeline templates can be used to cover all available resources after $f$ or fewer simultaneous failures, thereby avoiding resource idling at all times. Evaluation on large DNN models with billions of parameters shows that Oobleck provides consistently high throughput, and it outperforms state-of-the-art fault tolerance solutions like Bamboo and Varuna by up to $13.9x$.
    
[^22]: 多源领域自适应的联邦数据集字典学习

    Federated Dataset Dictionary Learning for Multi-Source Domain Adaptation. (arXiv:2309.07670v1 [cs.LG])

    [http://arxiv.org/abs/2309.07670](http://arxiv.org/abs/2309.07670)

    本文提出了一种用于联邦领域自适应的方法，通过字典学习经验分布来解决客户端间分布偏移和部分无标签数据的问题。该方法通过设计协作通信协议和聚合操作，保护了客户端数据隐私，并成功在目标领域生成了标记数据。

    

    本文提出了一种联邦领域自适应的方法，该方法在客户端中存在分布偏移且部分客户端具有无标签的数据。所提出的框架FedDaDiL通过字典学习经验分布来解决这一挑战。在我们的设置中，客户端的分布代表着特定的领域，而FedDaDiL则共同训练了一个联邦经验分布字典。具体而言，我们在数据集字典学习框架上设计了协作通信协议和聚合操作。所选择的协议保护了客户端的数据隐私，相比于集中式方法提高了整体隐私性。我们通过对Caltech-Office、TEP和CWRU基准数据集进行了大量实验证明了我们的方法成功地在目标领域生成了标记数据。此外，我们还将我们的方法与其集中式方法和其他联邦领域基准进行了比较。

    In this article, we propose an approach for federated domain adaptation, a setting where distributional shift exists among clients and some have unlabeled data. The proposed framework, FedDaDiL, tackles the resulting challenge through dictionary learning of empirical distributions. In our setting, clients' distributions represent particular domains, and FedDaDiL collectively trains a federated dictionary of empirical distributions. In particular, we build upon the Dataset Dictionary Learning framework by designing collaborative communication protocols and aggregation operations. The chosen protocols keep clients' data private, thus enhancing overall privacy compared to its centralized counterpart. We empirically demonstrate that our approach successfully generates labeled data on the target domain with extensive experiments on (i) Caltech-Office, (ii) TEP, and (iii) CWRU benchmarks. Furthermore, we compare our method to its centralized counterpart and other benchmarks in federated doma
    
[^23]: Rank2Tell: 一个用于联合重要性排序和推理的多模态驾驶数据集

    Rank2Tell: A Multimodal Driving Dataset for Joint Importance Ranking and Reasoning. (arXiv:2309.06597v1 [cs.CV])

    [http://arxiv.org/abs/2309.06597](http://arxiv.org/abs/2309.06597)

    Rank2Tell是一个多模态驾驶数据集，用于联合重要性排序和推理，为研究人员提供了复杂交通情景中各种重要对象的密集注释和独特属性。

    

    商用自动驾驶车辆（AVs）和先进驾驶辅助系统（ADAS）的广泛应用可能在很大程度上取决于社会对它们的接受程度，而对骑车人来说，它们被视为可信和可解释性是至关重要的。一般来说，这个任务是具有挑战性的，因为现代自主系统软件严重依赖于黑盒人工智能模型。为了实现这个目标，本文介绍了一种新的数据集，Rank2Tell，这是一个用于重要性级别排序和原因解释的多模态驾驶数据集。使用各种闭合和开放式视觉问答，该数据集提供了复杂交通情景中各种重要对象的各种语义、空间、时间和关系属性的密集注释。数据集的密集注释和独特属性使其成为从事视觉场景理解和相关领域研究的研究人员的宝贵资源。此外，我们还介绍了一个联合模型，用于联合表示和推理重要性和原因。

    The widespread adoption of commercial autonomous vehicles (AVs) and advanced driver assistance systems (ADAS) may largely depend on their acceptance by society, for which their perceived trustworthiness and interpretability to riders are crucial. In general, this task is challenging because modern autonomous systems software relies heavily on black-box artificial intelligence models. Towards this goal, this paper introduces a novel dataset, Rank2Tell, a multi-modal ego-centric dataset for Ranking the importance level and Telling the reason for the importance. Using various close and open-ended visual question answering, the dataset provides dense annotations of various semantic, spatial, temporal, and relational attributes of various important objects in complex traffic scenarios. The dense annotations and unique attributes of the dataset make it a valuable resource for researchers working on visual scene understanding and related fields. Further, we introduce a joint model for joint i
    
[^24]: 评估学习型语音增强系统在噪声和混响环境中的泛化差距

    Assessing the Generalization Gap of Learning-Based Speech Enhancement Systems in Noisy and Reverberant Environments. (arXiv:2309.06183v1 [eess.AS])

    [http://arxiv.org/abs/2309.06183](http://arxiv.org/abs/2309.06183)

    本研究介绍了一种泛化评估框架，用于评估学习型语音增强系统在噪声和混响环境中的泛化能力，并提出了使用在测试条件下训练的参考模型作为难度代理。

    

    噪声和混响语音混合物的声学变异性受多个因素影响，例如目标说话者和干扰噪声的频谱时域特性，信噪比和房间特性。这种大的变异性给基于学习的语音增强系统带来了很大的挑战，因为训练和测试条件之间的不匹配会大大降低系统的性能。通常通过使用与训练期间使用的不同的新语音、噪声或双耳房间脉冲响应（BRIR）数据库对系统进行测试来评估对未知条件的泛化能力。然而，语音增强任务的难度可能会随着数据库的变化而改变，这可能会对结果产生重大影响。本研究引入了一种泛化评估框架，该框架使用在测试条件下训练的参考模型作为测试条件难度的代理。

    The acoustic variability of noisy and reverberant speech mixtures is influenced by multiple factors, such as the spectro-temporal characteristics of the target speaker and the interfering noise, the signal-to-noise ratio (SNR) and the room characteristics. This large variability poses a major challenge for learning-based speech enhancement systems, since a mismatch between the training and testing conditions can substantially reduce the performance of the system. Generalization to unseen conditions is typically assessed by testing the system with a new speech, noise or binaural room impulse response (BRIR) database different from the one used during training. However, the difficulty of the speech enhancement task can change across databases, which can substantially influence the results. The present study introduces a generalization assessment framework that uses a reference model trained on the test condition, such that it can be used as a proxy for the difficulty of the test conditio
    
[^25]: LoopTune: 使用强化学习优化张量计算

    LoopTune: Optimizing Tensor Computations with Reinforcement Learning. (arXiv:2309.01825v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2309.01825](http://arxiv.org/abs/2309.01825)

    LoopTune是一个使用强化学习优化张量计算的编译器，通过优化张量遍历顺序和使用代码生成器LoopNest执行硬件特定优化，LoopTune能够生成比其他编译器更快的代码。通过采用新的图形表示和动作空间，LoopTune比TVM快一个数量级，比MetaSchedule快2.8倍，比AutoTVM快1.08倍，并持续在与手工调优的库Numpy相当的水平上工作。此外，LoopTune优化代码的时间只需几秒钟。

    

    先进的编译器技术对于使机器学习应用在新型硬件上运行至关重要，但传统编译器无法提供性能，普通的自动调节器搜索时间长，经专家优化的库导致不可持续的成本。为了解决这个问题，我们开发了LoopTune，这是一个深度强化学习编译器，用于优化CPU中深度学习模型中的张量计算。LoopTune在使用超快轻量级代码生成器LoopNest执行硬件特定优化的同时，优化张量遍历顺序。通过采用新颖的基于图的表示和动作空间，LoopTune将LoopNest的速度提高了3.2倍，生成的代码比TVM快一个数量级，比MetaSchedule快2.8倍，比AutoTVM快1.08倍，并持续在手工调整的库Numpy的水平上运行。此外，LoopTune可以在几秒钟内优化代码。

    Advanced compiler technology is crucial for enabling machine learning applications to run on novel hardware, but traditional compilers fail to deliver performance, popular auto-tuners have long search times and expert-optimized libraries introduce unsustainable costs. To address this, we developed LoopTune, a deep reinforcement learning compiler that optimizes tensor computations in deep learning models for the CPU. LoopTune optimizes tensor traversal order while using the ultra-fast lightweight code generator LoopNest to perform hardware-specific optimizations. With a novel graph-based representation and action space, LoopTune speeds up LoopNest by 3.2x, generating an order of magnitude faster code than TVM, 2.8x faster than MetaSchedule, and 1.08x faster than AutoTVM, consistently performing at the level of the hand-tuned library Numpy. Moreover, LoopTune tunes code in order of seconds.
    
[^26]: ToddlerBERTa: 利用BabyBERTa进行语法学习和语言理解

    ToddlerBERTa: Exploiting BabyBERTa for Grammar Learning and Language Understanding. (arXiv:2308.16336v1 [cs.CL])

    [http://arxiv.org/abs/2308.16336](http://arxiv.org/abs/2308.16336)

    ToddlerBERTa是一个类似于BabyBERTa的语言模型，尽管在较小的数据集上进行训练，但它展示了令人称赞的性能，并具有强大的语言理解能力，与最先进的RoBERTa-base相媲美。

    

    我们提出了ToddlerBERTa，这是一个类似于BabyBERTa的语言模型，并通过五种不同的具有不同超参数的模型来探索其能力。在BLiMP，SuperGLUE，MSGS和BabyLM挑战中进行评估，我们发现较小的模型在特定任务上表现出色，而较大的模型在大量数据方面表现良好。尽管在较小的数据集上训练，ToddlerBERTa展示了令人称赞的性能，与最先进的RoBERTa-base相媲美。该模型展示了强大的语言理解能力，即使是在单句预训练的情况下，也能与利用更广泛上下文信息的基线竞争。我们的工作为超参数选择和数据利用提供了洞察，并为语言模型的发展做出了贡献。

    We present ToddlerBERTa, a BabyBERTa-like language model, exploring its capabilities through five different models with varied hyperparameters. Evaluating on BLiMP, SuperGLUE, MSGS, and a Supplement benchmark from the BabyLM challenge, we find that smaller models can excel in specific tasks, while larger models perform well with substantial data. Despite training on a smaller dataset, ToddlerBERTa demonstrates commendable performance, rivalling the state-of-the-art RoBERTa-base. The model showcases robust language understanding, even with single-sentence pretraining, and competes with baselines that leverage broader contextual information. Our work provides insights into hyperparameter choices, and data utilization, contributing to the advancement of language models.
    
[^27]: 通过迭代近似祖先采样实现变分自编码器的条件采样

    Conditional Sampling of Variational Autoencoders via Iterated Approximate Ancestral Sampling. (arXiv:2308.09078v1 [cs.LG])

    [http://arxiv.org/abs/2308.09078](http://arxiv.org/abs/2308.09078)

    本文提出了两种原始方法来解决变分自编码器（VAE）条件采样中的困难，并在采样任务中展示了改进性能。

    

    在各种应用中，如缺失数据填充，需要对变分自编码器（VAE）进行条件采样，但这是计算上不可行的。渐近精确条件采样的原则选择是Metropolis-within-Gibbs（MWG）。然而，我们观察到VAE倾向于学习结构化潜变量空间，这是一个常见的期望特性，但却导致MWG采样器远离目标分布。本文克服了MWG的局限性：我们系统地概述了在VAE上上述局限性，并提出了两种原始方法来解决这些问题，并在一组采样任务上展示了所提方法的改进性能。

    Conditional sampling of variational autoencoders (VAEs) is needed in various applications, such as missing data imputation, but is computationally intractable. A principled choice for asymptotically exact conditional sampling is Metropolis-within-Gibbs (MWG). However, we observe that the tendency of VAEs to learn a structured latent space, a commonly desired property, can cause the MWG sampler to get "stuck" far from the target distribution. This paper mitigates the limitations of MWG: we systematically outline the pitfalls in the context of VAEs, propose two original methods that address these pitfalls, and demonstrate an improved performance of the proposed methods on a set of sampling tasks.
    
[^28]: 在检测人物和物体交互中探索谓词视觉背景

    Exploring Predicate Visual Context in Detecting of Human-Object Interactions. (arXiv:2308.06202v1 [cs.CV])

    [http://arxiv.org/abs/2308.06202](http://arxiv.org/abs/2308.06202)

    本文研究了在人物和物体交互检测中的谓词视觉背景问题，并通过交叉注意力和盒子配对位置嵌入等方式来改进模型，取得了比现有方法更好的性能。

    

    最近，DETR框架已成为人物和物体交互（HOI）研究的主要方法。特别是，基于两阶段变换器的HOI检测器是性能最好和训练最高效的方法之一。然而，这些方法通常以缺乏细粒度上下文信息的物体特征作为HOI分类的条件，而忽视了姿势和方向信息，而更注重关于物体身份和边界的视觉提示。这自然地阻碍了对复杂或模糊交互的识别。本文通过可视化和精心设计的实验研究了这些问题。因此，我们通过交叉注意力重新引入图像特征，并改进了查询设计，广泛探索了键和值，以及使用盒子配对位置嵌入作为空间指导。我们的改进谓词视觉背景（PViC）模型在HICO-DET和V-COCO基准测试上优于现有方法，同时保持了性能。

    Recently, the DETR framework has emerged as the dominant approach for human--object interaction (HOI) research. In particular, two-stage transformer-based HOI detectors are amongst the most performant and training-efficient approaches. However, these often condition HOI classification on object features that lack fine-grained contextual information, eschewing pose and orientation information in favour of visual cues about object identity and box extremities. This naturally hinders the recognition of complex or ambiguous interactions. In this work, we study these issues through visualisations and carefully designed experiments. Accordingly, we investigate how best to re-introduce image features via cross-attention. With an improved query design, extensive exploration of keys and values, and box pair positional embeddings as spatial guidance, our model with enhanced predicate visual context (PViC) outperforms state-of-the-art methods on the HICO-DET and V-COCO benchmarks, while maintaini
    
[^29]: 从离散标记到高保真音频：使用多频带扩散模型

    From Discrete Tokens to High-Fidelity Audio Using Multi-Band Diffusion. (arXiv:2308.02560v1 [cs.SD])

    [http://arxiv.org/abs/2308.02560](http://arxiv.org/abs/2308.02560)

    提出了一种高保真多频带扩散模型，可以根据低比特率的离散表示生成任何类型的音频形式，具有优于最先进生成技术的感知质量。

    

    深度生成模型可以根据各种表示（如mel频谱、MFCC）生成高保真音频。最近，这样的模型已经被用于根据高度压缩的表示合成音频波形。尽管这些方法产生了令人印象深刻的结果，但是当条件不完美时，易于产生可听到的伪影。另一种建模方法是使用扩散模型。然而，这些模型主要用作语音模型（或基于mel频谱的条件模型）或生成相对较低采样率的信号。在这项工作中，我们提出了一个高保真多频带扩散模型，可以根据低比特率的离散表示生成任何类型的音频形式（如语音、音乐、环境声音）。在相同的比特率下，所提出的方法在感知质量上优于最先进的生成技术。

    Deep generative models can generate high-fidelity audio conditioned on various types of representations (e.g., mel-spectrograms, Mel-frequency Cepstral Coefficients (MFCC)). Recently, such models have been used to synthesize audio waveforms conditioned on highly compressed representations. Although such methods produce impressive results, they are prone to generate audible artifacts when the conditioning is flawed or imperfect. An alternative modeling approach is to use diffusion models. However, these have mainly been used as speech vocoders (i.e., conditioned on mel-spectrograms) or generating relatively low sampling rate signals. In this work, we propose a high-fidelity multi-band diffusion-based framework that generates any type of audio modality (e.g., speech, music, environmental sounds) from low-bitrate discrete representations. At equal bit rate, the proposed approach outperforms state-of-the-art generative techniques in terms of perceptual quality. Training and, evaluation cod
    
[^30]: 在Wasserstein空间中通过数据集字典学习进行多源域自适应

    Multi-Source Domain Adaptation through Dataset Dictionary Learning in Wasserstein Space. (arXiv:2307.14953v1 [cs.LG])

    [http://arxiv.org/abs/2307.14953](http://arxiv.org/abs/2307.14953)

    本文提出了一种基于字典学习和最优传输的MSDA框架，通过将每个域表示为字典原子的Wasserstein重心来缓解数据分布偏移。根据该字典，提出了两种新的MSDA方法，分别基于目标域标记样本的重构和在原子分布上学习的分类器的集成。在多个基准测试集上进行的实验证明，这些方法在分类任务上取得了显著的改进效果。

    

    本文旨在解决多源域自适应（MSDA）问题，该问题旨在在从多个标记的源域转移知识到未标记的目标域时缓解数据分布偏移。我们提出了一种基于字典学习和最优传输的新型MSDA框架。我们将MSDA中的每个域解释为经验分布。因此，我们将每个域表达为字典原子的Wasserstein重心，这些原子是经验分布。我们提出了一种新的通过小批量学习的算法DaDiL：（i）原子分布；（ii）重心坐标矩阵。根据我们的字典，我们提出了两种新的MSDA方法：DaDiL-R，基于目标域标记样本的重构；DaDiL-E，基于在原子分布上学习的分类器的集成。我们在3个基准测试集中评估了我们的方法：Caltech-Office、Office 31和CRWU，在分类上改进了以前的最先进技术3.15％、2.29％和7.71％。

    This paper seeks to solve Multi-Source Domain Adaptation (MSDA), which aims to mitigate data distribution shifts when transferring knowledge from multiple labeled source domains to an unlabeled target domain. We propose a novel MSDA framework based on dictionary learning and optimal transport. We interpret each domain in MSDA as an empirical distribution. As such, we express each domain as a Wasserstein barycenter of dictionary atoms, which are empirical distributions. We propose a novel algorithm, DaDiL, for learning via mini-batches: (i) atom distributions; (ii) a matrix of barycentric coordinates. Based on our dictionary, we propose two novel methods for MSDA: DaDil-R, based on the reconstruction of labeled samples in the target domain, and DaDiL-E, based on the ensembling of classifiers learned on atom distributions. We evaluate our methods in 3 benchmarks: Caltech-Office, Office 31, and CRWU, where we improved previous state-of-the-art by 3.15%, 2.29%, and 7.71% in classification 
    
[^31]: 高效的Beam Tree递归

    Efficient Beam Tree Recursion. (arXiv:2307.10779v1 [cs.LG])

    [http://arxiv.org/abs/2307.10779](http://arxiv.org/abs/2307.10779)

    本文提出了一种高效的Beam Tree递归算法（BT-RvNN），通过解决评分函数和递归单元函数的纠缠问题以及简化内存使用，成功降低了BT-RvNN的内存使用。这个算法在ListOps任务中达到了新的最先进水平，并在其他任务中保持了类似的性能。

    

    最近提出的Beam Tree递归神经网络（BT-RvNN）是Gumbel Tree RvNN的简单扩展，已经在ListOps中取得了最先进的长度泛化性能，同时在其他任务上保持了可比较的性能。然而，尽管不是最差的，但BT-RvNN的内存使用仍然非常昂贵。在本文中，我们确定了BT-RvNN内存使用的主要瓶颈是评分函数和递归单元函数的纠缠。我们提出了策略来解决这个瓶颈，并进一步简化内存使用。总体上，我们的策略不仅将BT-RvNN的内存使用减少了10-16倍，而且在ListOps中创造了新的最先进水平，同时在其他任务中保持了类似的性能。此外，我们还提出了一种利用BT-RvNN产生的引导隐层树节点表示的策略，将BT-RvNN从形式为f：R^n×d ->的句子编码器转换成。”

    Beam Tree Recursive Neural Network (BT-RvNN) was recently proposed as a simple extension of Gumbel Tree RvNN and it was shown to achieve state-of-the-art length generalization performance in ListOps while maintaining comparable performance on other tasks. However, although not the worst in its kind, BT-RvNN can be still exorbitantly expensive in memory usage. In this paper, we identify the main bottleneck in BT-RvNN's memory usage to be the entanglement of the scorer function and the recursive cell function. We propose strategies to remove this bottleneck and further simplify its memory usage. Overall, our strategies not only reduce the memory usage of BT-RvNN by $10$-$16$ times but also create a new state-of-the-art in ListOps while maintaining similar performance in other tasks. In addition, we also propose a strategy to utilize the induced latent-tree node representations produced by BT-RvNN to turn BT-RvNN from a sentence encoder of the form $f:\mathbb{R}^{n \times d} \rightarrow \
    
[^32]: Spuriosity并没有导致分类器失败：利用不变的预测来利用虚假特征

    Spuriosity Didn't Kill the Classifier: Using Invariant Predictions to Harness Spurious Features. (arXiv:2307.09933v1 [cs.LG])

    [http://arxiv.org/abs/2307.09933](http://arxiv.org/abs/2307.09933)

    本研究通过理论证明和算法提出，展示了在没有标签的情况下如何利用不稳定特征来提高分类器的性能。

    

    为了避免在域外数据上的失败，最近的研究试图提取具有与标签在不同域之间稳定或不变关系的特征，舍弃与标签在不同域之间关系变化的"虚假"或不稳定特征。然而，不稳定特征常常携带关于标签的补充信息，如果在测试域中正确使用，可以提高性能。我们的主要贡献是显示在没有标签的情况下学习如何在测试域中使用这些不稳定特征是可能的。特别是，我们证明基于稳定特征的伪标签提供了足够的指导来做到这一点，前提是在给定标签的条件下，稳定特征和不稳定特征是条件独立的。基于这个理论洞见，我们提出了稳定特征增强（SFB）算法：(i)学习一个能够分离稳定特征和条件独立不稳定特征的预测器；(ii)使用稳定特征预测来适应测试域

    To avoid failures on out-of-distribution data, recent works have sought to extract features that have a stable or invariant relationship with the label across domains, discarding the "spurious" or unstable features whose relationship with the label changes across domains. However, unstable features often carry complementary information about the label that could boost performance if used correctly in the test domain. Our main contribution is to show that it is possible to learn how to use these unstable features in the test domain without labels. In particular, we prove that pseudo-labels based on stable features provide sufficient guidance for doing so, provided that stable and unstable features are conditionally independent given the label. Based on this theoretical insight, we propose Stable Feature Boosting (SFB), an algorithm for: (i) learning a predictor that separates stable and conditionally-independent unstable features; and (ii) using the stable-feature predictions to adapt t
    
[^33]: 学习选择伪布尔和线性整数约束的SAT编码

    Learning to Select SAT Encodings for Pseudo-Boolean and Linear Integer Constraints. (arXiv:2307.09342v1 [cs.AI])

    [http://arxiv.org/abs/2307.09342](http://arxiv.org/abs/2307.09342)

    该论文提出了一种学习选择伪布尔和线性整数约束的SAT编码的方法，通过使用监督机器学习方法和一组特征，可以有效地选择编码方式，并且专门为伪布尔和线性约束设计的新特征能够取得更好的性能。

    

    许多约束满足和优化问题可以通过将它们编码为布尔可满足性问题（SAT）的实例来有效地解决。然而，即使是最简单的约束类型在文献中也有很多编码方式，性能差异很大，选择适当的编码方式对于给定的问题实例并不是一件简单的事情。我们采用监督机器学习方法研究选择伪布尔和线性约束的编码问题。我们展示了可以使用标准约束问题的特征集来有效地选择编码方式；然而，我们使用专门为伪布尔和线性约束设计的一组新特征获得了更好的性能。事实上，在选择未见过的问题类别的编码方式时，我们取得了不错的结果。当使用相同的特征集时，我们的结果与AutoFolio相比表现良好。我们讨论了实例特征对于选择编码方式任务的相对重要性。

    Many constraint satisfaction and optimisation problems can be solved effectively by encoding them as instances of the Boolean Satisfiability problem (SAT). However, even the simplest types of constraints have many encodings in the literature with widely varying performance, and the problem of selecting suitable encodings for a given problem instance is not trivial. We explore the problem of selecting encodings for pseudo-Boolean and linear constraints using a supervised machine learning approach. We show that it is possible to select encodings effectively using a standard set of features for constraint problems; however we obtain better performance with a new set of features specifically designed for the pseudo-Boolean and linear constraints. In fact, we achieve good results when selecting encodings for unseen problem classes. Our results compare favourably to AutoFolio when using the same feature set. We discuss the relative importance of instance features to the task of selecting the
    
[^34]: 自适应线性估计方程

    Adaptive Linear Estimating Equations. (arXiv:2307.07320v1 [math.ST])

    [http://arxiv.org/abs/2307.07320](http://arxiv.org/abs/2307.07320)

    本文提出了一种解决自适应线性回归模型中非正态渐近行为的方法，使用自适应线性估计方程构建去偏估计量，并在多臂老虎机的背景下保持了最小二乘估计量的非渐近性能。

    

    顺序数据收集已成为增强数据收集过程效率的广泛采用的技术。尽管具有优势，但这种数据收集机制常常给统计推断过程引入复杂性。例如，在自适应线性回归模型中，普通最小二乘（OLS）估计量可能表现出非正态的渐近行为，从而对准确的推断和解释提出挑战。本文提出了一种构建去偏估计量的通用方法，该方法采用自适应线性估计方程的思想，并在理论上保证了渐近正态性，并讨论了实现近似最优渐近方差的问题。我们的估计量的一个显著特点是，在多臂老虎机的背景下，我们的估计量保留了最小二乘估计量的非渐近性能，同时获得了渐近正态性。因此，本工作解决了自适应线性回归模型中非正态渐近行为的问题，并为统计推断提供了可靠的方法。

    Sequential data collection has emerged as a widely adopted technique for enhancing the efficiency of data gathering processes. Despite its advantages, such data collection mechanism often introduces complexities to the statistical inference procedure. For instance, the ordinary least squares (OLS) estimator in an adaptive linear regression model can exhibit non-normal asymptotic behavior, posing challenges for accurate inference and interpretation. In this paper, we propose a general method for constructing debiased estimator which remedies this issue. It makes use of the idea of adaptive linear estimating equations, and we establish theoretical guarantees of asymptotic normality, supplemented by discussions on achieving near-optimal asymptotic variance. A salient feature of our estimator is that in the context of multi-armed bandits, our estimator retains the non-asymptotic performance of the least square estimator while obtaining asymptotic normality property. Consequently, this work
    
[^35]: 非传递性游戏的策略空间多样性

    Policy Space Diversity for Non-Transitive Games. (arXiv:2306.16884v1 [cs.GT])

    [http://arxiv.org/abs/2306.16884](http://arxiv.org/abs/2306.16884)

    这项研究提出了一种新的策略空间多样性度量，并通过将其纳入策略空间响应预言机（PSRO）中，实现了更好的逼近纳什均衡（NE）的效果。

    

    策略空间响应预言机（PSRO）是一种在多智能体非传递性游戏中近似纳什均衡（NE）的重要算法框架。许多之前的研究一直在尝试促进PSRO中的策略多样性。然而，现有多样性度量的一个主要弱点在于更多样化的人口（根据多样性度量）不一定意味着更好地逼近NE（正如我们在论文中证明的那样）。为了解决这个问题，我们提出了一种新的多样性度量，其改进保证了更好地逼近NE。同时，我们开发了一种实用且有正当理由的方法，仅使用状态-行动样本来优化我们的多样性度量。通过将多样性正则化纳入PSRO中的最佳应答求解，我们得到了一个新的PSRO变种，即策略空间多样性PSRO（PSD-PSRO）。我们展示了PSD-PSRO的收敛性。经验上，在各种游戏上进行了大量的实验，证明PSD-PSRO在促进策略多样性、提高逼近NE效果方面更加有效。

    Policy-Space Response Oracles (PSRO) is an influential algorithm framework for approximating a Nash Equilibrium (NE) in multi-agent non-transitive games. Many previous studies have been trying to promote policy diversity in PSRO. A major weakness in existing diversity metrics is that a more diverse (according to their diversity metrics) population does not necessarily mean (as we proved in the paper) a better approximation to a NE. To alleviate this problem, we propose a new diversity metric, the improvement of which guarantees a better approximation to a NE. Meanwhile, we develop a practical and well-justified method to optimize our diversity metric using only state-action samples. By incorporating our diversity regularization into the best response solving in PSRO, we obtain a new PSRO variant, Policy Space Diversity PSRO (PSD-PSRO). We present the convergence property of PSD-PSRO. Empirically, extensive experiments on various games demonstrate that PSD-PSRO is more effective in prod
    
[^36]: 用基于梯度的优化方法解决核岭回归问题

    Solving Kernel Ridge Regression with Gradient-Based Optimization Methods. (arXiv:2306.16838v1 [stat.ML])

    [http://arxiv.org/abs/2306.16838](http://arxiv.org/abs/2306.16838)

    本研究提出了一种新的方法来解决核岭回归问题，通过等价的目标函数形式和基于梯度的优化方法，我们不仅可以使用其他惩罚方法，还能够从梯度下降的角度研究核岭回归。通过提前停止的正则化，我们推导出了一个闭合解，即核梯度流（KGF），并证明了KGF和KRR之间的差异。我们还将KRR泛化，使用$\ell_1$和$\ell_\infty$惩罚方法，并发现使用这些方法得到的解与前向分步回归和符号梯度下降结合提前停止得到的解非常相似。因此，我们减少了计算复杂度重的近端梯度下降算法的需求。

    

    核岭回归（KRR）是线性岭回归的非线性推广。在这里，我们引入了KRR目标函数的等价形式，为使用其他惩罚方法和从梯度下降的角度研究核岭回归打开了可能。通过连续时间的视角，我们推导出了一个闭合解——核梯度流（KGF），通过提前停止的正则化，让我们能够在KGF和KRR之间理论上界定差异。我们用$\ell_1$和$\ell_\infty$惩罚方法将KRR泛化，并利用类似KGF和KRR之间的相似性，使用这些惩罚方法得到的解与使用前向分步回归（也称为坐标下降）和符号梯度下降结合提前停止得到的解非常相似。因此，减少了计算复杂度重的近端梯度下降算法的需求。

    Kernel ridge regression, KRR, is a non-linear generalization of linear ridge regression. Here, we introduce an equivalent formulation of the objective function of KRR, opening up both for using other penalties than the ridge penalty and for studying kernel ridge regression from the perspective of gradient descent. Using a continuous-time perspective, we derive a closed-form solution, kernel gradient flow, KGF, with regularization through early stopping, which allows us to theoretically bound the differences between KGF and KRR. We generalize KRR by replacing the ridge penalty with the $\ell_1$ and $\ell_\infty$ penalties and utilize the fact that analogously to the similarities between KGF and KRR, the solutions obtained when using these penalties are very similar to those obtained from forward stagewise regression (also known as coordinate descent) and sign gradient descent in combination with early stopping. Thus the need for computationally heavy proximal gradient descent algorithms
    
[^37]: 时间差分动力学的特征子空间及其如何在强化学习中改进值估计

    Eigensubspace of Temporal-Difference Dynamics and How It Improves Value Approximation in Reinforcement Learning. (arXiv:2306.16750v1 [cs.LG])

    [http://arxiv.org/abs/2306.16750](http://arxiv.org/abs/2306.16750)

    ERC是一种新的值估计方法，通过在深度强化学习中利用时间差分动力学的特征子空间，实现了更高效和稳定的值估计路径。实验证明ERC有效地减少了值函数的方差，并在多项任务中优于其他最先进方法。

    

    我们提出了一种新的值估计方法，即特征子空间规范化批评家（ERC），用于深度强化学习（RL）。 ERC受到了对时序差分（TD）方法中Q值估计误差动力学的分析的启发，该方法遵循由与马尔可夫决策过程（MDP）相关的转移核关联的1-特征子空间定义的路径。它揭示了TD学习的一个基本性质，在先前的深度RL方法中未被使用。在ERC中，我们提出了一个正则化器，指导近似误差趋向于1-特征子空间，从而得到更高效稳定的值估计路径。此外，我们在理论上证明了ERC方法的收敛性。此外，理论分析和实验证明ERC有效地减少了值函数的方差。在DMControl基准测试的26个任务中，ERC优于20个最先进方法。此外，在Q值估计方面也显示出明显的优势。

    We propose a novel value approximation method, namely Eigensubspace Regularized Critic (ERC) for deep reinforcement learning (RL). ERC is motivated by an analysis of the dynamics of Q-value approximation error in the Temporal-Difference (TD) method, which follows a path defined by the 1-eigensubspace of the transition kernel associated with the Markov Decision Process (MDP). It reveals a fundamental property of TD learning that has remained unused in previous deep RL approaches. In ERC, we propose a regularizer that guides the approximation error tending towards the 1-eigensubspace, resulting in a more efficient and stable path of value approximation. Moreover, we theoretically prove the convergence of the ERC method. Besides, theoretical analysis and experiments demonstrate that ERC effectively reduces the variance of value functions. Among 26 tasks in the DMControl benchmark, ERC outperforms state-of-the-art methods for 20. Besides, it shows significant advantages in Q-value approxim
    
[^38]: 改进深度伪造检测中的公平性

    Improving Fairness in Deepfake Detection. (arXiv:2306.16635v1 [cs.CV])

    [http://arxiv.org/abs/2306.16635](http://arxiv.org/abs/2306.16635)

    本研究首次尝试通过提出新的损失函数来改善深度伪造检测的公平性，并在多个数据集和检测器上进行了广泛实验证明了其有效性。

    

    尽管近年来已经开发出有效的深度伪造检测模型，但是一些最近的研究表明，在开发深度伪造检测模型时所使用的训练数据中存在偏见可能导致不同种族和/或性别的人群的不公平表现。这可能导致这些群体受到不公平的定位或被排除在检测之外，从而让被错误分类的深度伪造操纵舆论并破坏对模型的信任。虽然这些研究着重于确定和评估深度伪造检测中的不公平性，但目前还没有开发出解决深度伪造检测算法层面公平性问题的方法。在这项工作中，我们首次尝试通过提出新的损失函数来改进深度伪造检测的公平性，以在不考虑或考虑人口因素的情况下训练公平的深度伪造检测模型。对四个深度伪造数据集和五个深度伪造检测器的大量实验证明了这种方法的有效性和灵活性。

    Despite the development of effective deepfake detection models in recent years, several recent studies have demonstrated that biases in the training data utilized to develop deepfake detection models can lead to unfair performance for demographic groups of different races and/or genders. Such can result in these groups being unfairly targeted or excluded from detection, allowing misclassified deepfakes to manipulate public opinion and erode trust in the model. While these studies have focused on identifying and evaluating the unfairness in deepfake detection, no methods have been developed to address the fairness issue of deepfake detection at the algorithm level. In this work, we make the first attempt to improve deepfake detection fairness by proposing novel loss functions to train fair deepfake detection models in ways that are agnostic or aware of demographic factors. Extensive experiments on four deepfake datasets and five deepfake detectors demonstrate the effectiveness and flexi
    
[^39]: 预训练任务多样性与回归问题中非贝叶斯上下文学习的出现

    Pretraining task diversity and the emergence of non-Bayesian in-context learning for regression. (arXiv:2306.15063v1 [cs.LG])

    [http://arxiv.org/abs/2306.15063](http://arxiv.org/abs/2306.15063)

    预训练的transformer在回归问题中展现了非贝叶斯上下文学习能力，其在任务多样性阈值以下表现类似于贝叶斯估计器，而在阈值以上明显优于贝叶斯估计器，与岭回归一致。

    

    预训练的transformer表现出了令人钦佩的上下文学习能力（ICL）：它们可以从仅提供在提示中的少量示例中学习任务，而无需更新任何权重。这引发了一个基本问题：ICL能够解决在预训练期间未见过的、在本质上与之前任务非常不同的新任务吗？为了探索这个问题，我们在预训练数据集中改变任务的多样性，研究了ICL在线性回归中的表现。我们经验性地证明了出现ICL的任务多样性阈值。在这个阈值以下，预训练的transformer无法解决未见的回归任务，因为它的行为类似于具有非多样性预训练任务分布作为先验的贝叶斯估计器。超过这个阈值后，transformer明显优于这个估计器；它的行为与岭回归一致，对$\textit{所有任务}$，包括在预训练期间未见过的任务，具有高斯先验。

    Pretrained transformers exhibit the remarkable ability of in-context learning (ICL): they can learn tasks from just a few examples provided in the prompt without updating any weights. This raises a foundational question: can ICL solve fundamentally $\textit{new}$ tasks that are very different from those seen during pretraining? To probe this question, we examine ICL's performance on linear regression while varying the diversity of tasks in the pretraining dataset. We empirically demonstrate a $\textit{task diversity threshold}$ for the emergence of ICL. Below this threshold, the pretrained transformer cannot solve unseen regression tasks as it behaves like a Bayesian estimator with the $\textit{non-diverse pretraining task distribution}$ as the prior. Beyond this threshold, the transformer significantly outperforms this estimator; its behavior aligns with that of ridge regression, corresponding to a Gaussian prior over $\textit{all tasks}$, including those not seen during pretraining. 
    
[^40]: 更多的PAC-Bayes Bounds：从有界损失到具有一般性尾部行为的损失，到任何时间均有效的损失。

    More PAC-Bayes bounds: From bounded losses, to losses with general tail behaviors, to anytime-validity. (arXiv:2306.12214v1 [stat.ML])

    [http://arxiv.org/abs/2306.12214](http://arxiv.org/abs/2306.12214)

    本文提出了一种新的高概率PAC-Bayes界限，在有界和一般尾部行为的损失中均适用。此外，这些界限还能够保持随时有效性。

    

    本文针对不同类型的损失提出了新的高概率PAC-Bayes界限。首先，针对有界范围的损失，我们提出了Catoni界的加强版本，适用于所有参数值的统一界。这导致了新的快速速率和混合速率上限，这些上限可解释性强且比文献中先前界限更紧。其次，针对更一般的尾部行为的损失，我们引入了两个新的无参数上限：当损失的累积生成函数有界时，我们引入了一个PAC-Bayes Chernoff类比，另一个上限是损失的二阶矩有界。这两个上限是利用一种基于可能事件空间的离散化的新技术获得的，“在概率”参数优化问题。最后，我们使用一种适用于任何现有界限的简单技术将所有先前结果扩展到任何时间有效的上限。

    In this paper, we present new high-probability PAC-Bayes bounds for different types of losses. Firstly, for losses with a bounded range, we present a strengthened version of Catoni's bound that holds uniformly for all parameter values. This leads to new fast rate and mixed rate bounds that are interpretable and tighter than previous bounds in the literature. Secondly, for losses with more general tail behaviors, we introduce two new parameter-free bounds: a PAC-Bayes Chernoff analogue when the loss' cumulative generating function is bounded, and a bound when the loss' second moment is bounded. These two bounds are obtained using a new technique based on a discretization of the space of possible events for the "in probability" parameter optimization problem. Finally, we extend all previous results to anytime-valid bounds using a simple technique applicable to any existing bound.
    
[^41]: TopP\&R: 具有鲁棒性的支持估计方法，用于评估生成模型中的保真度和多样性

    TopP\&R: Robust Support Estimation Approach for Evaluating Fidelity and Diversity in Generative Models. (arXiv:2306.08013v1 [cs.LG])

    [http://arxiv.org/abs/2306.08013](http://arxiv.org/abs/2306.08013)

    本文提出了一种鲁棒可靠的生成模型评估指标TopP\&R，通过引入拓扑和统计处理进行严格的支持估计。TopP\&R仅保留具有一定置信水平的具有拓扑和统计上重要性的特征，对于噪声特征具有强大的鲁棒性，并提供了统计一致性。

    

    本文提出了一种鲁棒可靠的生成模型评估指标，通过引入拓扑和统计处理进行严格的支持估计。现有的度量标准，如Inception Score（IS），Fr\'echet Inception Distance（FID）以及Precision and Recall（P\&R）的变体，严重依赖于从样本特征估计的支持。然而，尽管评估的质量完全取决于其可靠性，但其估计的可靠性并没有得到严肃的讨论（并被忽视）。本文提出了拓扑精度和召回率（TopP\&R，发音为“topper”），它提供了一种系统的方法来估计支持，仅保留具有一定置信水平的具有拓扑和统计上重要性的特征。这不仅使TopP\&R对于噪声特征具有强大的鲁棒性，而且还提供了统计一致性。我们的理论和实验结果表明，TopP\&R对于离群值和非独立同分布具有鲁棒性。

    We propose a robust and reliable evaluation metric for generative models by introducing topological and statistical treatments for rigorous support estimation. Existing metrics, such as Inception Score (IS), Fr\'echet Inception Distance (FID), and the variants of Precision and Recall (P\&R), heavily rely on supports that are estimated from sample features. However, the reliability of their estimation has not been seriously discussed (and overlooked) even though the quality of the evaluation entirely depends on it. In this paper, we propose Topological Precision and Recall (TopP\&R, pronounced 'topper'), which provides a systematic approach to estimating supports, retaining only topologically and statistically important features with a certain level of confidence. This not only makes TopP\&R strong for noisy features, but also provides statistical consistency. Our theoretical and experimental results show that TopP\&R is robust to outliers and non-independent and identically distributed
    
[^42]: 高效和等变图网络预测量子哈密顿

    Efficient and Equivariant Graph Networks for Predicting Quantum Hamiltonian. (arXiv:2306.04922v1 [cs.LG])

    [http://arxiv.org/abs/2306.04922](http://arxiv.org/abs/2306.04922)

    本文提出了一种名为QHNet的SE(3)-等变网络，具有高效和等变性。与最先进的方法相比，QHNet在更快的速度下实现了与其可比的表现，并且消耗的内存少了50％。

    

    我们考虑用于量子化学和凝聚态物理中的哈密顿矩阵预测。效率和等变性是两个重要但冲突的因素。在本研究中，我们提出了一种SE(3)-等变网络，称为QHNet，既实现了效率又实现了等变性。我们的关键进展在于QHNet架构的创新设计，它不仅遵守基本的对称性，还可以通过92％的张量积数量来减少数量。此外，QHNet在涉及更多原子类型时，可以防止通道维度的指数增长。我们在MD17数据集上进行了实验，包括四个分子系统。实验结果表明，我们的QHNet可以在显著更快的速度下实现与最先进方法可比拟的性能。此外，由于其简化的架构，我们的QHNet消耗的内存少了50％。我们的代码可作为AIRS库的一部分公开使用（\url{https://github.com/divelab/AIRS}）。

    We consider the prediction of the Hamiltonian matrix, which finds use in quantum chemistry and condensed matter physics. Efficiency and equivariance are two important, but conflicting factors. In this work, we propose a SE(3)-equivariant network, named QHNet, that achieves efficiency and equivariance. Our key advance lies at the innovative design of QHNet architecture, which not only obeys the underlying symmetries, but also enables the reduction of number of tensor products by 92\%. In addition, QHNet prevents the exponential growth of channel dimension when more atom types are involved. We perform experiments on MD17 datasets, including four molecular systems. Experimental results show that our QHNet can achieve comparable performance to the state of the art methods at a significantly faster speed. Besides, our QHNet consumes 50\% less memory due to its streamlined architecture. Our code is publicly available as part of the AIRS library (\url{https://github.com/divelab/AIRS}).
    
[^43]: 离线强化学习中的生存本能

    Survival Instinct in Offline Reinforcement Learning. (arXiv:2306.03286v1 [cs.LG])

    [http://arxiv.org/abs/2306.03286](http://arxiv.org/abs/2306.03286)

    离线强化学习算法即使使用错误的奖励标签，也能产生良好的表现和安全的策略，这种鲁棒性属性是由离线强化学习算法的悲观主义和常见数据收集实践中的偏见之间相互作用的结果，赋予了代理生存本能。

    

    我们提出了一个关于离线强化学习算法行为的新观察：在许多基准数据集上，离线强化学习即使使用“错误”的奖励标签（例如在所有地方都为零或是真实奖励的负数），也能产生良好的表现和安全的策略。这种现象不能仅通过离线强化学习的回报最大化目标来解释。此外，它赋予了离线强化学习一定的鲁棒性，这在其在线强化学习对应物中是不典型的，因为后者对奖励设计敏感。我们证明了此惊人的鲁棒性属性是离线强化学习算法中悲观主义概念和常见数据收集实践中某种偏见之间相互作用的结果。悲观主义赋予了代理生存本能，即长期内留在数据支持中的激励，而有限且有偏见的数据覆盖进一步限制了生存行为集合。

    We present a novel observation about the behavior of offline reinforcement learning (RL) algorithms: on many benchmark datasets, offline RL can produce well-performing and safe policies even when trained with "wrong" reward labels, such as those that are zero everywhere or are negatives of the true rewards. This phenomenon cannot be easily explained by offline RL's return maximization objective. Moreover, it gives offline RL a degree of robustness that is uncharacteristic of its online RL counterparts, which are known to be sensitive to reward design. We demonstrate that this surprising robustness property is attributable to an interplay between the notion of pessimism in offline RL algorithms and a certain bias implicit in common data collection practices. As we prove in this work, pessimism endows the agent with a "survival instinct", i.e., an incentive to stay within the data support in the long term, while the limited and biased data coverage further constrains the set of survival 
    
[^44]: 基于深度强化学习的莫里斯水迷宫导航策略研究

    Investigating Navigation Strategies in the Morris Water Maze through Deep Reinforcement Learning. (arXiv:2306.01066v1 [cs.LG])

    [http://arxiv.org/abs/2306.01066](http://arxiv.org/abs/2306.01066)

    本文利用深度强化学习代理程序模拟了莫里斯水迷宫，通过自动分类导航策略，分析人工智能代理程序使用的策略分布，并与实验结果做对比。该研究发现了类似于人和啮齿类动物的学习规律，发展了内部表征与导航策略之间的关联，为生物学特征的探索提供了一定的参考。

    

    导航是一项复杂的技能，其在动物和人类的研究历史悠久。本文通过模拟2D的莫里斯水迷宫，训练深度强化学习代理程序，自动分类导航策略，分析人工智能代理程序使用的策略分布，并与实验数据进行比较，展示了与人类和啮齿类动物相似的学习动态。同时，我们开发了特定于环境的辅助任务，并研究对其有用性的影响因素。我们认为，最具益处的任务可能更符合真实代理使用的生物学特征。最后，我们探讨了代理程序神经网络激活中内部表征的发展。这些表征类似于发现于鼠脑中的位置细胞和头方向细胞，其存在与代理程序使用的导航策略有关。

    Navigation is a complex skill with a long history of research in animals and humans. In this work, we simulate the Morris Water Maze in 2D to train deep reinforcement learning agents. We perform automatic classification of navigation strategies, analyze the distribution of strategies used by artificial agents, and compare them with experimental data to show similar learning dynamics as those seen in humans and rodents. We develop environment-specific auxiliary tasks and examine factors affecting their usefulness. We suggest that the most beneficial tasks are potentially more biologically feasible for real agents to use. Lastly, we explore the development of internal representations in the activations of artificial agent neural networks. These representations resemble place cells and head-direction cells found in mouse brains, and their presence has correlation to the navigation strategies that artificial agents employ.
    
[^45]: 无法学习的数据集可以给我们带来哪些启示？

    What Can We Learn from Unlearnable Datasets?. (arXiv:2305.19254v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.19254](http://arxiv.org/abs/2305.19254)

    无法学习的数据集方法具有保护数据隐私的潜力，但实际使用受到限制。我们发现神经网络在无法学习的数据集上可以学习到有用的特征，而不仅仅是简单规则，这对图像保护的效果不确定。此外，线性可分的扰动并不是诱导学习捷径的必要条件，因此不能依赖它们。

    

    在普遍进行网络爬虫的时代，无法学习的数据集方法具有保护数据隐私、防止深度神经网络泛化的潜力。但除了一些实际限制使得它们的使用不太可能外，我们发现一些结果对其保护数据能力提出了质疑。首先，人们普遍认为在无法学习的数据集上训练的神经网络只会学习到捷径，即并不适用于泛化的简单规则。然而，我们发现网络实际上可以学习到有用的特征，并且这些特征可以重新加权以获得高测试性能，这表明图像的保护并不能得到保证。无法学习的数据集据信通过添加扰动的线性可分性来诱导学习捷径。我们提供了一个反例，证明了扰动的线性可分性并不是必要条件。为了强调为什么不能依赖线性可分的扰动，我们提出了一个正交投影的方法。

    In an era of widespread web scraping, unlearnable dataset methods have the potential to protect data privacy by preventing deep neural networks from generalizing. But in addition to a number of practical limitations that make their use unlikely, we make a number of findings that call into question their ability to safeguard data. First, it is widely believed that neural networks trained on unlearnable datasets only learn shortcuts, simpler rules that are not useful for generalization. In contrast, we find that networks actually can learn useful features that can be reweighed for high test performance, suggesting that image protection is not assured. Unlearnable datasets are also believed to induce learning shortcuts through linear separability of added perturbations. We provide a counterexample, demonstrating that linear separability of perturbations is not a necessary condition. To emphasize why linearly separable perturbations should not be relied upon, we propose an orthogonal proje
    
[^46]: 增强样本下混合系统中有效强化学习及其在排队网络中的应用。

    Sample Efficient Reinforcement Learning in Mixed Systems through Augmented Samples and Its Applications to Queueing Networks. (arXiv:2305.16483v1 [cs.LG])

    [http://arxiv.org/abs/2305.16483](http://arxiv.org/abs/2305.16483)

    本文提出了一种在混合系统中通过增强数据样本进行学习的方法，应用于排队网络问题，能够显著提高学习效率和降低样本复杂度。

    

    本文研究了一类强化学习问题，涉及具有两种状态的系统：随机状态和伪随机状态。在这种系统中，随机状态遵循随机转移核而伪随机状态的转移是在给定随机状态/转移的情况下是确定的。我们称这样的系统为混合系统。这种系统被广泛应用于各种应用，包括制造系统、通信网络和排队网络。我们提出了一种能够通过产生增强的数据样本来加速学习的样本高效的强化学习方法。该算法是数据驱动的，并从实际和增强样本的数据样本中学习策略，从而显著改善了学习的效果。我们分析了在Fitted Q Iteration（FQI）下提出的方法的样本复杂度，并证明了学习策略的最优性差随着真实数据样本数量的增加而减少。我们将我们的方法应用于解决一类排队网络问题，其中混合状态空间自然而然地出现。

    This paper considers a class of reinforcement learning problems, which involve systems with two types of states: stochastic and pseudo-stochastic. In such systems, stochastic states follow a stochastic transition kernel while the transitions of pseudo-stochastic states are deterministic given the stochastic states/transitions. We refer to such systems as mixed systems, which are widely used in various applications, including manufacturing systems, communication networks, and queueing networks. We propose a sample efficient RL method that accelerates learning by generating augmented data samples. The proposed algorithm is data-driven and learns the policy from data samples from both real and augmented samples. This method significantly improves learning by reducing the sample complexity such that the dataset only needs to have sufficient coverage of the stochastic states. We analyze the sample complexity of the proposed method under Fitted Q Iteration (FQI) and demonstrate that the opti
    
[^47]: 以概念为中心的Transformer：具有面向物体的概念学习，以实现可解释性。

    Concept-Centric Transformers: Concept Transformers with Object-Centric Concept Learning for Interpretability. (arXiv:2305.15775v1 [cs.LG])

    [http://arxiv.org/abs/2305.15775](http://arxiv.org/abs/2305.15775)

    本文研究了以物体为中心的概念学习，它可以提高基于概念的Transformer模型的分类性能和可解释性。

    

    注意机制大大提高了深度学习模型在视觉、NLP和多模态任务上的性能，同时也提供了工具来帮助模型的可解释性。最近提出的概念Transformer（CT）将Transformer的注意力机制从低级输入特征泛化到更抽象的中间层潜在概念，更好地允许人类分析员直接评估解释关于任何特定输出分类的推理。然而，CT采用的概念学习默认假设类别中的每个图像都对表征该类别的概念作出了相同的贡献，而使用以物体为中心的概念可能会导致更好的分类结果。

    Attention mechanisms have greatly improved the performance of deep-learning models on visual, NLP, and multimodal tasks while also providing tools to aid in the model's interpretability. In particular, attention scores over input regions or concrete image features can be used to measure how much the attended elements contribute to the model inference. The recently proposed Concept Transformer (CT) generalizes the Transformer attention mechanism from such low-level input features to more abstract, intermediate-level latent concepts that better allow human analysts to more directly assess an explanation for the reasoning of the model about any particular output classification. However, the concept learning employed by CT implicitly assumes that across every image in a class, each image patch makes the same contribution to concepts that characterize membership in that class. Instead of using the CT's image-patch-centric concepts, object-centric concepts could lead to better classification
    
[^48]: 基于点积的层次聚类可以恢复隐藏的树形结构

    Hierarchical clustering with dot products recovers hidden tree structure. (arXiv:2305.15022v1 [stat.ML])

    [http://arxiv.org/abs/2305.15022](http://arxiv.org/abs/2305.15022)

    本文发现一种基于点积的层次聚类算法，可以通过最大平均点积合并聚类，并且输出的树结构可用于准确估计数据的生成层次结构，树形恢复性能优于现有方法。

    

    本文提供了一个对于已有凝聚聚类算法的新视角，专注于层次结构的恢复。我们建议一种简单的标准算法变体，其中聚类是通过最大平均点积而不是最小距离或簇内方差来合并的。我们证明了此算法输出的树可以作为数据生成层次结构的可靠估计。关键技术创新在于理解模型中的层次信息如何转化为可从数据中恢复的树形几何信息，并同时增长样本大小和数据维数的好处。我们在真实数据上展示了优于现有方法（如UPGMA、Ward's方法和HDBSCAN）的树形恢复性能。

    In this paper we offer a new perspective on the well established agglomerative clustering algorithm, focusing on recovery of hierarchical structure. We recommend a simple variant of the standard algorithm, in which clusters are merged by maximum average dot product and not, for example, by minimum distance or within-cluster variance. We demonstrate that the tree output by this algorithm provides a bona fide estimate of generative hierarchical structure in data, under a generic probabilistic graphical model. The key technical innovations are to understand how hierarchical information in this model translates into tree geometry which can be recovered from data, and to characterise the benefits of simultaneously growing sample size and data dimension. We demonstrate superior tree recovery performance with real data over existing approaches such as UPGMA, Ward's method, and HDBSCAN.
    
[^49]: 联邦基础模型：用于大模型的隐私保护协作学习

    Federated Foundation Models: Privacy-Preserving and Collaborative Learning for Large Models. (arXiv:2305.11414v1 [cs.LG])

    [http://arxiv.org/abs/2305.11414](http://arxiv.org/abs/2305.11414)

    本文提出了联邦基础模型（FFMs）的概念，结合了基础模型和联邦学习的优势，可实现跨多个机构的隐私保护和协作学习。

    

    基础模型通常需要大量数据进行预训练，如BERT、GPT、ViT和CLIP，但其优化通常需要访问敏感数据，引发隐私问题并限制其适用性。为解决这一问题，本文提出了联邦基础模型（FFMs）的概念，这是一种新颖的方法，结合了基础模型和联邦学习的优势，可实现跨多个机构的隐私保护和协作学习。

    Foundation Models (FMs), such as BERT, GPT, ViT, and CLIP, have demonstrated remarkable success in a wide range of applications, driven by their ability to leverage vast amounts of data for pre-training. However, optimizing FMs often requires access to sensitive data, raising privacy concerns and limiting their applicability in certain domains. In this paper, we introduce the concept of Federated Foundation Models (FFMs), a novel approach that combines the benefits of FMs and Federated Learning (FL) to enable privacy-preserving and collaborative learning across multiple institutions. We discuss the potential benefits and challenges of integrating FL into the lifespan of FMs, covering pre-training, fine-tuning, and application. We further provide formal definitions of FFM tasks, including FFM pre-training, FFM fine-tuning, and federated prompt engineering, allowing for more personalized and context-aware models while maintaining data privacy. Moreover, we explore the possibility of cont
    
[^50]: 变分分类

    Variational Classification. (arXiv:2305.10406v1 [cs.LG])

    [http://arxiv.org/abs/2305.10406](http://arxiv.org/abs/2305.10406)

    提出一种新的变分分类方法，通过引入潜变量建模来优化训练，允许灵活的设计选择以改善校准和对抗鲁棒性，实验结果表明其对于域外数据的分类准确性得到了保持。

    

    我们提出了一种传统神经网络方法的新型扩展，称为变分分类 (VC)。通过引入潜变量建模，类似于变分自编码器和传统自编码器之间的关系，我们得到了一个基于证据下界 (ELBO) 的训练目标，采用对抗性方法优化。我们的VC模型允许在设计选择方面更加灵活，特别是类条件潜先验，而不是在现成的softmax分类器中做出的隐式假设。在图像和文本分类数据集上的实证评估表明，我们的方法在保持预测准确性的同时，改善了其他良好特性，如校准和对抗鲁棒性，即使应用于域外数据。

    We present a novel extension of the traditional neural network approach to classification tasks, referred to as variational classification (VC). By incorporating latent variable modeling, akin to the relationship between variational autoencoders and traditional autoencoders, we derive a training objective based on the evidence lower bound (ELBO), optimized using an adversarial approach. Our VC model allows for more flexibility in design choices, in particular class-conditional latent priors, in place of the implicit assumptions made in off-the-shelf softmax classifiers. Empirical evaluation on image and text classification datasets demonstrates the effectiveness of our approach in terms of maintaining prediction accuracy while improving other desirable properties such as calibration and adversarial robustness, even when applied to out-of-domain data.
    
[^51]: 搜索UGLE真相：无监督GNN学习环境的调查

    Search for the UGLE Truth: An Investigation into Unsupervised GNN Learning Environments. (arXiv:2305.06026v1 [cs.LG])

    [http://arxiv.org/abs/2305.06026](http://arxiv.org/abs/2305.06026)

    本文提出了一种GNN学习环境下的社区检测算法比较框架，包括数据集和评估指标，以解决目前文献中对于基于GNN的社区检测缺乏公平且严谨评估的问题。

    

    图神经网络 (GNN) 是任何机器学习任务中的一个重要工具，因为它们能够学习图结构上的函数，这是一种强大和表达性强的数据表示。社区检测是一种无监督任务，越来越多地使用GNN进行。利用节点特征的多维度与图的连接性对图中的节点进行聚类，对从社交网络到基因组学的真实世界任务有许多应用。不幸的是，目前文献中缺乏公平且严谨评估基于GNN的社区检测的充分基准环境，从而可能阻碍这一新兴领域的进展。我们观察到这种情况下的特定困难是模糊的超参数调整环境与性能和评估数据集的冲突指标。在这项工作中，我们提出和评估了框架，用于在GNN学习环境中进行一致的社区检测算法比较。我们提供了一个基准数据集，并提出了评估指标，反映了检测到的社区的内在质量以及聚类的准确性。

    Graph Neural Networks (GNNs) are a pertinent tool for any machine learning task due to their ability to learn functions over graph structures, a powerful and expressive data representation. The detection of communities, an unsupervised task has increasingly been performed with GNNs. Clustering nodes in a graph using the multi-dimensionality of node features with the connectivity of the graph has many applications to real world tasks from social networks to genomics. Unfortunately, there is currently a gap in the literature with no established sufficient benchmarking environment for fairly and rigorously evaluating GNN based community detection, thereby potentially impeding progress in this nascent field. We observe the particular difficulties in this setting is the ambiguous hyperparameter tuning environments combined with conflicting metrics of performance and evaluation datasets. In this work, we propose and evaluate frameworks for the consistent comparisons of community detection al
    
[^52]: PTW: 针对预训练图像生成器的关键调整型水印技术

    PTW: Pivotal Tuning Watermarking for Pre-Trained Image Generators. (arXiv:2304.07361v1 [cs.LG])

    [http://arxiv.org/abs/2304.07361](http://arxiv.org/abs/2304.07361)

    PTW是一种预训练生成器水印技术，可以比从头开始水印技术快三个数量级和更好的保留了生成器的图像质量，解决了恶意用户利用提供的模型制作出有害的深度伪造而不会被发现的问题。

    

    深度伪造是泛指利用深度生成器综合出来的内容，若被“误用”，可以破坏数字媒体的信任。而制作高质量的深度伪造需要接触大型和复杂的生成器，只有少数实体可以训练和提供这些生成器。威胁的是，恶意用户会利用提供的模型制作出有害的深度伪造，而不会被发现。为了可探测起来，深度伪造需要在生成器中嵌入识别码，以便在后续生成的图像中进行提取。我们提出了Pivotal Tuning Watermarking (PTW)，这是一种预训练生成器水印技术，(i) 比从头开始水印技术快三个数量级，(ii) 不需要任何训练数据。我们改进了现有的水印技术，同时缩放到了比相关工作大4倍的生成器。与现有方法相比，PTW可以嵌入更长的识别码，同时更好地保留了生成器的图像质量。我们提出了严格的基于博弈论的定义来评估水印技术。

    Deepfakes refer to content synthesized using deep generators, which, when \emph{misused}, have the potential to erode trust in digital media. Synthesizing high-quality deepfakes requires access to large and complex generators only few entities can train and provide. The threat are malicious users that exploit access to the provided model and generate harmful deepfakes without risking detection. Watermarking makes deepfakes detectable by embedding an identifiable code into the generator that is later extractable from its generated images. We propose Pivotal Tuning Watermarking (PTW), a method for watermarking pre-trained generators (i) three orders of magnitude faster than watermarking from scratch and (ii) without the need for any training data. We improve existing watermarking methods and scale to generators $4 \times$ larger than related work. PTW can embed longer codes than existing methods while better preserving the generator's image quality. We propose rigorous, game-based defini
    
[^53]: FetMRQC: 自动化胎儿脑 MRI 质量控制

    FetMRQC: Automated Quality Control for fetal brain MRI. (arXiv:2304.05879v1 [eess.IV])

    [http://arxiv.org/abs/2304.05879](http://arxiv.org/abs/2304.05879)

    FetMRQC 是一种针对胎儿脑 MRI 的自动图像质量评估机器学习框架，通过提取一系列质量指标可以预测专家评分，并能够在大部分数据集上实现准确评估，并发布了一个新的机器学习数据集。

    

    质量控制一直被认为是确保神经影像学研究可靠性的重要因素。对于胎儿脑 MRI 尤为重要，因为胎动频繁且不可预测，会导致图像中产生严重伪影。现有的胎儿脑质量评估方法仅从 \textit{层面} 考虑，无法全面了解图像质量，而评估整个脑容积才能实现这一点。本文提出了 FetMRQC，一种针对胎儿脑 MRI 的自动图像质量评估机器学习框架，该框架提取一系列质量指标，并使用这些指标预测专家评分。基于在两个不同机构收集的超过 1000 个低分辨率胎儿脑 MRI 样本的手动评分，我们发现 FetMRQC 能够一般化到其他数据集，并且是可解释的和高效的。我们还发布了一个新颖的机器学习数据集，其中包括高质量和低质量的胎儿脑 MRI 容积和专家评分。

    Quality control (QC) has long been considered essential to guarantee the reliability of neuroimaging studies. It is particularly important for fetal brain MRI, where large and unpredictable fetal motion can lead to substantial artifacts in the acquired images. Existing methods for fetal brain quality assessment operate at the \textit{slice} level, and fail to get a comprehensive picture of the quality of an image, that can only be achieved by looking at the \textit{entire} brain volume. In this work, we propose FetMRQC, a machine learning framework for automated image quality assessment tailored to fetal brain MRI, which extracts an ensemble of quality metrics that are then used to predict experts' ratings. Based on the manual ratings of more than 1000 low-resolution stacks acquired across two different institutions, we show that, compared with existing quality metrics, FetMRQC is able to generalize out-of-domain, while being interpretable and data efficient. We also release a novel ma
    
[^54]: 2D扩散算法的去偏置方法用于文本到3D生成

    Debiasing Scores and Prompts of 2D Diffusion for Robust Text-to-3D Generation. (arXiv:2303.15413v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.15413](http://arxiv.org/abs/2303.15413)

    本文提出了两种去偏置的方法，一种通过增加2D扩散模型得出的分数的截断值，一种通过调整视角提示和物体空间摄像机姿态之间的差异。实验结果表明这些方法可以显著减少伪影，提高真实感。

    

    本文探讨了在文本到3D生成中出现的视角一致性问题，也称为Janus问题。这个问题来自于2D扩散模型的固有偏置，导致生成的3D对象不真实。通过对其进行研究，我们提出了两种方法来去除偏置以实现文本到3D生成的鲁棒性。第一种方法叫做score debiasing，通过逐渐增加2D扩散模型得出的分数的截断值，来达到去除偏置的效果。第二种方法叫做prompt debiasing，利用语言模型确定用户提示和视角提示之间的矛盾词语，并调整视角提示和物体空间摄像机姿态之间的差异。我们的实验结果表明，我们的方法通过显著减少伪影，提高了真实感，并在质量与速度方面取得了良好的平衡。

    The view inconsistency problem in score-distilling text-to-3D generation, also known as the Janus problem, arises from the intrinsic bias of 2D diffusion models, which leads to the unrealistic generation of 3D objects. In this work, we explore score-distilling text-to-3D generation and identify the main causes of the Janus problem. Based on these findings, we propose two approaches to debias the score-distillation frameworks for robust text-to-3D generation. Our first approach, called score debiasing, involves gradually increasing the truncation value for the score estimated by 2D diffusion models throughout the optimization process. Our second approach, called prompt debiasing, identifies conflicting words between user prompts and view prompts utilizing a language model and adjusts the discrepancy between view prompts and object-space camera poses. Our experimental results show that our methods improve realism by significantly reducing artifacts and achieve a good trade-off between fa
    
[^55]: PULSNAR -- 在SCAR假设不成立时选择正无标记学习：分类比例估计

    PULSNAR -- Positive unlabeled learning selected not at random: class proportion estimation when the SCAR assumption does not hold. (arXiv:2303.08269v1 [cs.LG])

    [http://arxiv.org/abs/2303.08269](http://arxiv.org/abs/2303.08269)

    本文提出了一种新的PU方法PULSNAR，即使在SCAR不成立时，也可以实现准确的α估计和校准模型。

    

    正无标记（PU）学习是半监督二元分类的一种，其中机器学习算法区分一组正实例（带有标签）和一组既有正类又有负类实例（没有标签）。在确认负例不可用或难以获取，并且在未标记的实例中发现正例具有价值的情况下（例如，在未测试的化合物中找到可行药物），PU学习具有广泛的应用。大多数PU学习算法认为选择正实例独立于它们的特征，即进行完全随机选择（SCAR）假设。然而，在许多现实世界的应用中，例如医疗保健，正实例不是SCAR（例如，严重情况更容易被诊断出），导致在无标记示例中估计阳性比例α和模型校准性能差，进而导致选择正例的不确定决策阈值。PU学习算法可以通过估计每个未标记实例是阳性的概率来估计α并提供校准模型。然而，当SCAR假设不成立时，现有方法表现不佳。本文提出了一种新的PU方法PULSNAR，即使在SCAR不成立时，也可以实现准确的α估计和校准模型。我们的方法基于对未标记示例分布的新假设，称为阳性均匀条件。实证研究表明，我们的方法在合成和实际数据集中均优于现有最先进的PU方法。

    Positive and Unlabeled (PU) learning is a type of semi-supervised binary classification where the machine learning algorithm differentiates between a set of positive instances (labeled) and a set of both positive and negative instances (unlabeled). PU learning has broad applications in settings where confirmed negatives are unavailable or difficult to obtain, and there is value in discovering positives among the unlabeled (e.g., viable drugs among untested compounds). Most PU learning algorithms make the selected completely at random (SCAR) assumption, namely that positives are selected independently of their features. However, in many real-world applications, such as healthcare, positives are not SCAR (e.g., severe cases are more likely to be diagnosed), leading to a poor estimate of the proportion, $\alpha$, of positives among unlabeled examples and poor model calibration, resulting in an uncertain decision threshold for selecting positives. PU learning algorithms can estimate $\alph
    
[^56]: 零样本批次级异常检测

    Zero-Shot Batch-Level Anomaly Detection. (arXiv:2302.07849v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.07849](http://arxiv.org/abs/2302.07849)

    本文提出了一种名为“自适应中心表示”的方法，用于零样本批次级异常检测。该方法利用批量归一化来训练现成的深度异常检测器，可以自动零样本泛化为未见过的AD任务。在实验中，该方法显示出了在多种数据集上的优秀表现，对表格数据进行了零样本AD。

    

    异常检测（AD）在许多安全关键的应用领域中发挥着关键作用。适应正常数据分布漂移的异常检测器调整，特别是当没有针对“新正常”进行训练的数据时，这一挑战导致产生了零样本AD技术。在本文中，我们提出了一种名为自适应中心表示（ACR）的简单而有效的方法，用于零样本批次级AD。我们的方法使用批量归一化来训练现成的深度异常检测器（例如深度SVDD）来适应一组相互关联的训练数据分布，使其能够自动零样本泛化为未见过的AD任务。这个简单的方法，批量归一化加元训练，是一种非常有效和多功能的工具。我们的结果展示了对表格数据的第一个零样本AD结果，并在来自专业领域的图像数据的零样本异常检测和分段方面优于现有方法。

    Anomaly detection (AD) plays a crucial role in many safety-critical application domains. The challenge of adapting an anomaly detector to drift in the normal data distribution, especially when no training data is available for the "new normal," has led to the development of zero-shot AD techniques. In this paper, we propose a simple yet effective method called Adaptive Centered Representations (ACR) for zero-shot batch-level AD. Our approach trains off-the-shelf deep anomaly detectors (such as deep SVDD) to adapt to a set of inter-related training data distributions in combination with batch normalization, enabling automatic zero-shot generalization for unseen AD tasks. This simple recipe, batch normalization plus meta-training, is a highly effective and versatile tool. Our results demonstrate the first zero-shot AD results for tabular data and outperform existing methods in zero-shot anomaly detection and segmentation on image data from specialized domains.
    
[^57]: MarioGPT: 通过大语言模型进行开放式文本关卡生成

    MarioGPT: Open-Ended Text2Level Generation through Large Language Models. (arXiv:2302.05981v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.05981](http://arxiv.org/abs/2302.05981)

    MarioGPT是第一个文本到超级马里奥兄弟游戏关卡的生成模型，通过大型语言模型实现开放式的、可控制的关卡生成。

    

    流程内容生成算法可以自动生成复杂数一致的环境。然而，使用流程内容生成方法生成反映特定意图和限制的有意义内容仍然具有挑战性。此外，许多流程内容生成算法缺乏以开放式方式生成内容的能力。最近，大型语言模型在许多不同领域都表现出了非常高的效率。这些训练有素的大型语言模型可以进行微调，重复使用信息并加速新任务的培训。在这项工作中，我们介绍了MarioGPT，这是一个经过优化的GPT2模型，用于生成基于瓷砖的游戏关卡，我们以超级马里奥兄弟的关卡为例。我们展示了MarioGPT不仅可以生成不同的游戏关卡，而且可以通过文本提示控制关卡生成，解决了当前PCG技术的主要挑战之一。据我们所知，MarioGPT是第一个文本到关卡模型。

    Procedural Content Generation (PCG) algorithms provide a technique to generate complex and diverse environments in an automated way. However, while generating content with PCG methods is often straightforward, generating meaningful content that reflects specific intentions and constraints remains challenging. Furthermore, many PCG algorithms lack the ability to generate content in an open-ended manner. Recently, Large Language Models (LLMs) have shown to be incredibly effective in many diverse domains. These trained LLMs can be fine-tuned, re-using information and accelerating training for new tasks. In this work, we introduce MarioGPT, a fine-tuned GPT2 model trained to generate tile-based game levels, in our case Super Mario Bros levels. We show that MarioGPT can not only generate diverse levels, but can be text-prompted for controllable level generation, addressing one of the key challenges of current PCG techniques. As far as we know, MarioGPT is the first text-to-level model. We a
    
[^58]: Koopman算子学习的尖锐谱率

    Sharp Spectral Rates for Koopman Operator Learning. (arXiv:2302.02004v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.02004](http://arxiv.org/abs/2302.02004)

    本文提出了Koopman算子的非渐进学习界限，重点研究了时间可逆随机动力系统，提出了扩展动态模分解（EDMD）和降低秩回归（RRR）两种流行的估计器，并比较了它们的方差。

    

    非线性动力系统可以方便地描述为相关的Koopman算子，其作用使系统的每个可观测量随时间向前演化。通过许多算法可以从数据中学习Koopman算子及其谱分解。在本文中，我们首次提出了Koopman特征值和特征函数的非渐进学习界限。我们重点研究了时间可逆随机动力系统，包括重要的Langevin动力学示例。我们分析了两种流行的估计器：扩展动态模分解（EDMD）和降低秩回归（RRR）。我们的结果关键依赖于最小二乘估计误差的新奇极小化界限，这可能是独立工作的重要内容。我们的谱学习边界受到算子范数误差和估计特征函数的新型度量失真函数的同时控制驱动。边界表明，EDMD和RRR的方差相似，但EDMD优于...

    Non-linear dynamical systems can be handily described by the associated Koopman operator, whose action evolves every observable of the system forward in time. Learning the Koopman operator and its spectral decomposition from data is enabled by a number of algorithms. In this work we present for the first time non-asymptotic learning bounds for the Koopman eigenvalues and eigenfunctions. We focus on time-reversal-invariant stochastic dynamical systems, including the important example of Langevin dynamics. We analyze two popular estimators: Extended Dynamic Mode Decomposition (EDMD) and Reduced Rank Regression (RRR). Our results critically hinge on novel minimax estimation bounds for the operator norm error, that may be of independent interest. Our spectral learning bounds are driven by the simultaneous control of the operator norm error and a novel metric distortion functional of the estimated eigenfunctions. The bounds indicates that both EDMD and RRR have similar variance, but EDMD su
    
[^59]: 多功能能量概率模型在高能物理中的应用

    Versatile Energy-Based Probabilistic Models for High Energy Physics. (arXiv:2302.00695v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.00695](http://arxiv.org/abs/2302.00695)

    本文提出了一个多功能的能量概率模型，用于描述高能物理事件，可用于参数化的事件生成，异常信号探测以及粒子识别。

    

    作为一种经典的生成建模方法，基于能量的模型具有能量函数形式灵活性的天然优势。最近，基于能量的模型在计算机视觉和自然语言处理中建模高维数据方面取得了巨大成功。与这些进展一致，我们建立了一个多功能能量概率模型，用于描述来自大型强子对撞机的高能物理事件。该框架基于一个强大的生成模型，并描述了更高阶的粒子间相互作用，适用于不同的编码体系结构和隐式生成。在应用方面，它可以作为强大的参数化事件生成器用于物理仿真，一种泛用的无假设关联的异常信号探测器，以及用于粒子识别的增强事件分类器。

    As a classical generative modeling approach, energy-based models have the natural advantage of flexibility in the form of the energy function. Recently, energy-based models have achieved great success in modeling high-dimensional data in computer vision and natural language processing. In line with these advancements, we build a multi-purpose energy-based probabilistic model for High Energy Physics events at the Large Hadron Collider. This framework builds on a powerful generative model and describes higher-order inter-particle interactions.It suits different encoding architectures and builds on implicit generation. As for applicational aspects, it can serve as a powerful parameterized event generator for physics simulation, a generic anomalous signal detector free from spurious correlations, and an augmented event classifier for particle identification.
    
[^60]: 如何使用信息论选择客观函数

    How to select an objective function using information theory. (arXiv:2212.06566v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.06566](http://arxiv.org/abs/2212.06566)

    信息论告诉我们，为了最大化模型的信息量，选择可能性最高或表示误差比特最少的客观函数。将不同的客观函数转换为似然函数，它们的相对大小表示我们应该更喜欢哪个客观函数，而其大小的对数表示模型的预期不确定性。

    

    在机器学习或科学计算中，模型性能是通过客观函数衡量的。但是为什么要选择某个客观函数而不是另一个？信息论给出了一个答案：为了最大化模型中的信息量，选择最有可能的客观函数或者代表误差的比特最少的函数。要评估不同的客观函数，将它们转换为似然函数。作为似然函数，它们的相对大小表示我们应该更喜欢哪个客观函数，而其大小的对数表示模型的预期不确定性。

    In machine learning or scientific computing, model performance is measured with an objective function. But why choose one objective over another? Information theory gives one answer: To maximize the information in the model, select the most likely objective function or whichever represents the error in the fewest bits. To evaluate different objectives, transform them into likelihood functions. As likelihoods, their relative magnitudes represent how much we should prefer one objective versus another, and the log of their magnitude represents the expected uncertainty of the model.
    
[^61]: 隐式模型、潜在压缩、内在偏差和廉价午餐在社区检测中的应用

    Implicit models, latent compression, intrinsic biases, and cheap lunches in community detection. (arXiv:2210.09186v6 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2210.09186](http://arxiv.org/abs/2210.09186)

    本文提出了一种将社区检测目标与其对应的隐式网络生成模型相联系的解决方案，可以计算网络在任意目标下的描述长度，比较不同算法的性能，同时还可以访问隐式模型。

    

    社区检测的任务旨在将网络划分为节点集群，以总结其大规模结构，已经引出了许多具有不同目标的竞争算法。 一些社区检测方法是推断性的，通过概率生成模型明确地导出聚类目标，而其他方法是描述性的，根据特定应用的目标将网络分成子集，这使得在同一规模下比较这些方法变得具有挑战性。本文提出了将任何社区检测目标（推断性或描述性）与其相应的隐式网络生成模型相联系的解决方案。这使我们能够计算网络及其在任意目标下的分区的描述长度，无需“地面实况”标签即可比较不同算法的性能，同时还可以访问隐式模型，这是其他方法所不具备的。

    The task of community detection, which aims to partition a network into clusters of nodes to summarize its large-scale structure, has spawned the development of many competing algorithms with varying objectives. Some community detection methods are inferential, explicitly deriving the clustering objective through a probabilistic generative model, while other methods are descriptive, dividing a network according to an objective motivated by a particular application, making it challenging to compare these methods on the same scale. Here we present a solution to this problem that associates any community detection objective, inferential or descriptive, with its corresponding implicit network generative model. This allows us to compute the description length of a network and its partition under arbitrary objectives, providing a principled measure to compare the performance of different algorithms without the need for "ground truth" labels. Our approach also gives access to instances of the
    
[^62]: 双控制变量加速黑盒变分推断

    Dual control variate for faster black-box variational inference. (arXiv:2210.07290v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.07290](http://arxiv.org/abs/2210.07290)

    本论文提出了双控制变量方法，能够同时减少数据子抽样和蒙特卡罗抽样带来的梯度估计方差，提高黑盒变分推断的准确性和效率。

    

    黑盒变分推断是一种广泛使用的贝叶斯后验推断框架，但在某些情况下，梯度估计中的高方差会损害准确性和效率。这种方差来自两个随机源：数据子抽样和蒙特卡罗抽样。现有的控制变量仅解决蒙特卡罗噪声，而增量梯度方法通常仅解决数据子抽样，我们提出了一种新的“双”控制变量，能够同时减少两种噪声源的方差。我们确认这导致了减少方差和在多个现实世界应用中提高优化效果。

    Black-box variational inference is a widely-used framework for Bayesian posterior inference, but in some cases suffers from high variance in gradient estimates, harming accuracy and efficiency. This variance comes from two sources of randomness: Data subsampling and Monte Carlo sampling. Whereas existing control variates only address Monte Carlo noise and incremental gradient methods typically only address data subsampling, we propose a new "dual" control variate capable of jointly reducing variance from both sources of noise. We confirm that this leads to reduced variance and improved optimization in several real-world applications.
    

