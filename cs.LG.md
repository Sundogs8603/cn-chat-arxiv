# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [TRABSA: Interpretable Sentiment Analysis of Tweets using Attention-based BiLSTM and Twitter-RoBERTa](https://arxiv.org/abs/2404.00297) | TRABSA是一个集成了transformer架构、注意力机制和BiLSTM网络的混合框架，利用RoBERTa在大量推特上训练，填补了情感分析领域的差距，实现了94%的准确性和显著的性能提升。 |
| [^2] | [Interpreting Key Mechanisms of Factual Recall in Transformer-Based Language Models](https://arxiv.org/abs/2403.19521) | 通过深入研究Transformer-based语言模型在事实回忆任务中的机制，我们发现了零/少次样本情况下的特定任务头、MLP层和残差流的功能，以及抗过度自信机制。 |
| [^3] | [Sample complexity of quantum hypothesis testing](https://arxiv.org/abs/2403.17868) | 本文研究了量子假设检验的样本复杂度，得出了对称和非对称设置中的二进制量子假设检验的样本复杂度与反错误概率的对数和保真度的负对数的关系。 |
| [^4] | [A Survey on Deep Learning and State-of-the-arts Applications](https://arxiv.org/abs/2403.17561) | 深度学习是解决复杂问题的强大工具，本研究旨在全面审视深度学习模型及其应用的最新发展 |
| [^5] | [Multi-Scale Protein Language Model for Unified Molecular Modeling](https://arxiv.org/abs/2403.12995) | 提出了一种多尺度蛋白质语言模型，能够在蛋白质和小分子相关任务中超越先前的方法，并且通过统一分子建模实现了充分利用蛋白质语言模型的潜力。 |
| [^6] | [BurstAttention: An Efficient Distributed Attention Framework for Extremely Long Sequences](https://arxiv.org/abs/2403.09347) | BurstAttention是一种用于优化内存访问和通信操作的分布式注意力框架，适用于处理极长序列。 |
| [^7] | [FSL Model can Score Higher as It Is](https://arxiv.org/abs/2402.18292) | 为了增加测试期间正确预测的机会，研究旨在通过图像到图像的转换纠正FSL模型的测试输入，生成被测试类别的新样本。 |
| [^8] | [Generalization or Memorization: Data Contamination and Trustworthy Evaluation for Large Language Models](https://arxiv.org/abs/2402.15938) | 本文提出了一种通过LLMs输出分布进行污染检测的方法CDD，以及一种基于LLMs输出修正的可信评估方法TED，以应对大语言模型在数据污染和可信评估方面面临的挑战。 |
| [^9] | [GenTranslate: Large Language Models are Generative Multilingual Speech and Machine Translators](https://arxiv.org/abs/2402.06894) | GenTranslate是一个新的翻译任务生成模型，通过利用大型语言模型的丰富语言知识和强大推理能力，可以从N-best列表中生成更高质量的翻译结果。 |
| [^10] | [Randomized Confidence Bounds for Stochastic Partial Monitoring](https://arxiv.org/abs/2402.05002) | 本文研究了随机部分监控中基于随机化的偏置界策略，该策略扩展了现有随机策略无法应用的情境和非情境设置，实验证明该策略优于最先进的方法。 |
| [^11] | [Towards Aligned Layout Generation via Diffusion Model with Aesthetic Constraints](https://arxiv.org/abs/2402.04754) | 本文提出了一种统一的布局生成模型，通过考虑美学约束，在图形设计中创建合理的元素可视排列。与之前的方法相比，该模型表现出更好的对齐性能，并在各种布局生成任务中取得了优秀的性能。 |
| [^12] | [Training-Free Consistent Text-to-Image Generation](https://arxiv.org/abs/2402.03286) | 本文提出了一种无需训练的方法ConsiStory，通过共享预训练模型的内部激活，实现了一致的文本到图像生成。引入了主题驱动的共享注意力块和基于对应的特征注入，促进了图像之间的主题一致性，并采用了策略来保持布局多样性。 |
| [^13] | [Rate-Optimal Policy Optimization for Linear Markov Decision Processes](https://arxiv.org/abs/2308.14642) | 本文中，我们研究了在线周期性线性马尔可夫决策过程中的遗憾最小化问题，并提出了一种与周期数K成比率最优的遗憾收敛率O(√K)。这是首个针对带有乐观反馈的随机设置使用基于策略优化的方法并建立与K最优收敛速率的研究，也是首个针对具有全信息反馈的对抗设置并建立与K最优速率的研究，目前尚未找到具有最优速率保证的算法。 |
| [^14] | [Lookbehind-SAM: k steps back, 1 step forward](https://arxiv.org/abs/2307.16704) | 本研究提出了一种名为Lookbehind-SAM的方法，通过多次上升步骤和线性插值来增强最大化和最小化过程，以实现更好的损失锐度折衷。实验证明，该方法在各种任务中都有多种优点，包括提高的泛化性能、更高的鲁棒性和改进的学习过程。 |
| [^15] | [Querying Easily Flip-flopped Samples for Deep Active Learning.](http://arxiv.org/abs/2401.09787) | 本文提出了一种基于模型的预测不确定性度量，即最小不一致度量（LDM），用于解决复杂决策边界情况下的主动学习问题。通过查询具有最小LDM的未标记数据，可以提高深度学习模型的性能。 |
| [^16] | [Data-Driven Physics-Informed Neural Networks: A Digital Twin Perspective.](http://arxiv.org/abs/2401.08667) | 该论文研究了利用物理信息神经网络(PINNs)实现数字孪生(DT)的潜力。提出了适用于无网格框架的自适应采样方法，并验证了PINNs在参数化的Navier-Stokes方程中的可扩展性和多保真度的优势。 |
| [^17] | [$f$-Divergence Based Classification: Beyond the Use of Cross-Entropy.](http://arxiv.org/abs/2401.01268) | 这项研究提出了一种基于$f$散度的分类方法，超越了传统的使用交叉熵的方法。通过提取基于变分表示的$f$散度目标函数，该方法采用贝叶斯视角将分类任务视为最大后验概率问题，并提出了五个采用不同$f$散度的后验概率估计器。此外，通过一种自底向上的方法，还提出了一种新的基于平移对数的$f$散度的目标函数。这项研究在理论上证明了收敛性的属性。 |
| [^18] | [Large Language Model-Enhanced Algorithm Selection: Towards Comprehensive Algorithm Representation.](http://arxiv.org/abs/2311.13184) | 本论文提出了一种方法，通过将算法表示集成到算法选择中，从而填补了当前算法选择技术对算法特征的研究空白。 |
| [^19] | [GOPlan: Goal-conditioned Offline Reinforcement Learning by Planning with Learned Models.](http://arxiv.org/abs/2310.20025) | GOPlan是一个使用学习模型进行计划的目标条件下的离线强化学习方法，通过预训练先验策略和使用重新分析方法生成虚构轨迹，用以提高性能和处理有限数据预算和未见目标泛化的能力。 |
| [^20] | [Machine Learning Infused Distributed Optimization for Coordinating Virtual Power Plant Assets.](http://arxiv.org/abs/2310.17882) | 本文提出了一种名为LOOP-MAC的方法，利用机器学习辅助的分布式优化来协调虚拟电厂（VPP）的资产。该方法采用多智能体协调视角，利用神经网络逼近器加速解决方案搜索。该方法通过引入测量图来保证最佳解之间的关系。 |
| [^21] | [Image Clustering with External Guidance.](http://arxiv.org/abs/2310.11989) | 这项工作提出了一种新的聚类方法，利用外部知识来引导聚类。通过利用WordNet的文本语义，该方法能够提高图像聚类的效果。 |
| [^22] | [ReMax: A Simple, Effective, and Efficient Reinforcement Learning Method for Aligning Large Language Models.](http://arxiv.org/abs/2310.10505) | ReMax是一种用于对齐大型语言模型的简单、有效和高效的强化学习方法，相比于PPO，ReMax简化了实现，减少了内存使用，并解决了fine-tuning时的内存溢出问题。 |
| [^23] | [SuperCalo: Calorimeter shower super-resolution.](http://arxiv.org/abs/2308.11700) | 本文介绍了一种名为SuperCalo的能量沉积模拟超分辨率模型，能够快速上采样高维细粒度的能量沉积模拟，从而降低计算成本和生成时间。 |
| [^24] | [Foundation Model-oriented Robustness: Robust Image Model Evaluation with Pretrained Models.](http://arxiv.org/abs/2308.10632) | 本文提出了一种通过预训练模型对稳健性图像模型进行评估的新方法，通过与基础模型进行比较，直接测量图像分类模型的性能，扩展图像数据集以完成超出基准范围的评估。 |
| [^25] | [MIMIC: Masked Image Modeling with Image Correspondences.](http://arxiv.org/abs/2306.15128) | MIMIC是一种基于图像对应关系的遮蔽图像建模方法，通过挖掘不需要任何注释的数据集，使用多个自监督模型进行训练，达到了在多个下游任务上优于使用注释挖掘的表示的效果。 |
| [^26] | [Complexity of Feed-Forward Neural Networks from the Perspective of Functional Equivalence.](http://arxiv.org/abs/2305.11417) | 本文从功能等价的角度出发研究前馈神经网络的复杂性，发现利用置换不变性的特性可以降低网络的复杂度，通过过参数化可以增加训练网络的容易程度，并对深度学习中的优化和泛化理解具有重要意义。 |
| [^27] | [OpenBox: A Python Toolkit for Generalized Black-box Optimization.](http://arxiv.org/abs/2304.13339) | OpenBox是一个通用黑盒优化的Python工具包，提供了用户友好的接口和可视化功能，模块化设计能够在现有系统中灵活部署，并且实验证明其比现有系统更有效和高效。 |
| [^28] | [End-to-End Integration of Speech Separation and Voice Activity Detection for Low-Latency Diarization of Telephone Conversations.](http://arxiv.org/abs/2303.12002) | 本文重点研究了低延迟流式分离应用中的基于语音分离的发言者分离（SSGD）在会话电话语音（CTS）领域中的应用。通过分离说话人并在每个分离的流上应用语音活动检测（VAD）来执行发言者分离，提出了一种新型、因果和计算效率高的泄漏去除算法。在CALLHOME和Fisher语料库（第1和2部分）上的性能评估表明，SSGD算法能够有效地提高分离和发言者分离的性能。 |
| [^29] | [Goal-conditioned Offline Reinforcement Learning through State Space Partitioning.](http://arxiv.org/abs/2303.09367) | 本文提出了一种通过状态空间划分实现目标导向的离线强化学习方法，并采用补充的优势加权方案，以解决分布转移和多模式问题。 |
| [^30] | [Uniform Pessimistic Risk and Optimal Portfolio.](http://arxiv.org/abs/2303.07158) | 本文提出了一种称为统一悲观风险的综合$\alpha$-风险版本和基于风险获得最优组合的计算算法，该方法可以用于估计韩国股票的悲观最优组合模型。 |
| [^31] | [CaloFlow for CaloChallenge Dataset 1.](http://arxiv.org/abs/2210.14245) | CaloFlow是一种新的、有前景的快速量能器模拟方法，可以比Geant4快几个数量级生成高保真度的样本。使用量能器图片、直方图和分类器证明了其样本的保真度。 |

# 详细

[^1]: TRABSA：使用基于注意力的BiLSTM和Twitter-RoBERTa进行可解释的推文情感分析

    TRABSA: Interpretable Sentiment Analysis of Tweets using Attention-based BiLSTM and Twitter-RoBERTa

    [https://arxiv.org/abs/2404.00297](https://arxiv.org/abs/2404.00297)

    TRABSA是一个集成了transformer架构、注意力机制和BiLSTM网络的混合框架，利用RoBERTa在大量推特上训练，填补了情感分析领域的差距，实现了94%的准确性和显著的性能提升。

    

    情感分析对于理解公众舆论和消费者行为至关重要。现有模型面临着语言多样性、泛化能力和可解释性方面的挑战。我们提出了TRABSA，这是一个集成了基于transformer的架构、注意力机制和BiLSTM网络的混合框架，旨在解决这些挑战。利用在124M条推文上训练的RoBERTa，我们填补了情感分析基准测试中的差距，确保了最先进的准确性。通过将来自32个国家和美国各州的推文与数据集相结合，我们比较了六种词嵌入技术和三种基于词典的标注技术，并选择了最佳技术以实现最佳情感分析效果。TRABSA以94%的准确性和显著的精确度、召回率和F1得分增益，胜过了传统的机器学习和深度学习模型。在不同数据集上的评估显示了一致的优越性和泛化能力。SHAP和LIME分析提高了可解释性，增强了信心。

    arXiv:2404.00297v1 Announce Type: new  Abstract: Sentiment analysis is crucial for understanding public opinion and consumer behavior. Existing models face challenges with linguistic diversity, generalizability, and explainability. We propose TRABSA, a hybrid framework integrating transformer-based architectures, attention mechanisms, and BiLSTM networks to address this. Leveraging RoBERTa-trained on 124M tweets, we bridge gaps in sentiment analysis benchmarks, ensuring state-of-the-art accuracy. Augmenting datasets with tweets from 32 countries and US states, we compare six word-embedding techniques and three lexicon-based labeling techniques, selecting the best for optimal sentiment analysis. TRABSA outperforms traditional ML and deep learning models with 94% accuracy and significant precision, recall, and F1-score gains. Evaluation across diverse datasets demonstrates consistent superiority and generalizability. SHAP and LIME analyses enhance interpretability, improving confidence i
    
[^2]: 解释基于Transformer模型的语言模型在事实回忆中的关键机制

    Interpreting Key Mechanisms of Factual Recall in Transformer-Based Language Models

    [https://arxiv.org/abs/2403.19521](https://arxiv.org/abs/2403.19521)

    通过深入研究Transformer-based语言模型在事实回忆任务中的机制，我们发现了零/少次样本情况下的特定任务头、MLP层和残差流的功能，以及抗过度自信机制。

    

    本文深入探讨了Transformer-based语言模型在事实回忆任务中所采用的机制。在零次样本情况下，给定类似“法国的首都是”的提示，特定任务的注意力头会从上下文中提取主题实体，如“法国”，并将其传递给后续的MLP以回忆所需的答案，如“巴黎”。我们引入了一种新颖的分析方法，旨在将MLP的输出分解为人类可理解的组件。通过这种方法，我们量化了跟随这些特定任务头的MLP层的功能。在残差流中，它会擦除或放大来自各个头的信息。此外，它会生成一个组件，将残差流重新定向到预期答案的方向。这些零次机制也适用于少次样本情况。此外，我们观察到一种广泛存在的抗过度自信机制。

    arXiv:2403.19521v1 Announce Type: cross  Abstract: In this paper, we deeply explore the mechanisms employed by Transformer-based language models in factual recall tasks. In zero-shot scenarios, given a prompt like "The capital of France is," task-specific attention heads extract the topic entity, such as "France," from the context and pass it to subsequent MLPs to recall the required answer such as "Paris." We introduce a novel analysis method aimed at decomposing the outputs of the MLP into components understandable by humans. Through this method, we quantify the function of the MLP layer following these task-specific heads. In the residual stream, it either erases or amplifies the information originating from individual heads. Moreover, it generates a component that redirects the residual stream towards the direction of its expected answer. These zero-shot mechanisms are also employed in few-shot scenarios. Additionally, we observed a widely existent anti-overconfidence mechanism in 
    
[^3]: 量子假设检验的样本复杂度

    Sample complexity of quantum hypothesis testing

    [https://arxiv.org/abs/2403.17868](https://arxiv.org/abs/2403.17868)

    本文研究了量子假设检验的样本复杂度，得出了对称和非对称设置中的二进制量子假设检验的样本复杂度与反错误概率的对数和保真度的负对数的关系。

    

    传统上，人们从信息论的角度研究量子假设检验，在这种情况下，人们对错误概率的最优衰减速率感兴趣，这个速率是未知状态的样本数量函数。本文研究了量子假设检验的样本复杂度，旨在确定达到所需错误概率所需的最少样本数量。通过利用已有文献中关于量子假设检验的丰富知识，我们表征了对称和非对称设置中的二进制量子假设检验的样本复杂度，并提供了多个量子假设检验的样本复杂度的界限。更详细地说，我们证明了对称二进制量子假设检验的样本复杂度对反错误概率的对数和保真度的负对数的对数。

    arXiv:2403.17868v1 Announce Type: cross  Abstract: Quantum hypothesis testing has been traditionally studied from the information-theoretic perspective, wherein one is interested in the optimal decay rate of error probabilities as a function of the number of samples of an unknown state. In this paper, we study the sample complexity of quantum hypothesis testing, wherein the goal is to determine the minimum number of samples needed to reach a desired error probability. By making use of the wealth of knowledge that already exists in the literature on quantum hypothesis testing, we characterize the sample complexity of binary quantum hypothesis testing in the symmetric and asymmetric settings, and we provide bounds on the sample complexity of multiple quantum hypothesis testing. In more detail, we prove that the sample complexity of symmetric binary quantum hypothesis testing depends logarithmically on the inverse error probability and inversely on the negative logarithm of the fidelity. 
    
[^4]: 深度学习及其最新应用综述

    A Survey on Deep Learning and State-of-the-arts Applications

    [https://arxiv.org/abs/2403.17561](https://arxiv.org/abs/2403.17561)

    深度学习是解决复杂问题的强大工具，本研究旨在全面审视深度学习模型及其应用的最新发展

    

    深度学习, 是人工智能的一个分支，是一种利用多层互连单元（神经元）从原始输入数据中直接学习复杂模式和表示的计算模型。受到这种学习能力的赋能，深度学习已成为解决复杂问题的强大工具，是许多突破性技术和创新的核心驱动力。构建深度学习模型是一项具有挑战性的任务，因为算法的复杂性和现实问题的动态性。有几项研究回顾了深度学习的概念和应用。然而，这些研究大多集中于深度学习模型类型和卷积神经网络架构，对深度学习模型及其在不同领域解决复杂问题的最新发展的覆盖面有限。因此，受到这些限制的启发，本研究旨在全面审视th

    arXiv:2403.17561v1 Announce Type: new  Abstract: Deep learning, a branch of artificial intelligence, is a computational model that uses multiple layers of interconnected units (neurons) to learn intricate patterns and representations directly from raw input data. Empowered by this learning capability, it has become a powerful tool for solving complex problems and is the core driver of many groundbreaking technologies and innovations. Building a deep learning model is a challenging task due to the algorithm`s complexity and the dynamic nature of real-world problems. Several studies have reviewed deep learning concepts and applications. However, the studies mostly focused on the types of deep learning models and convolutional neural network architectures, offering limited coverage of the state-of-the-art of deep learning models and their applications in solving complex problems across different domains. Therefore, motivated by the limitations, this study aims to comprehensively review th
    
[^5]: 多尺度蛋白质语言模型用于统一分子建模

    Multi-Scale Protein Language Model for Unified Molecular Modeling

    [https://arxiv.org/abs/2403.12995](https://arxiv.org/abs/2403.12995)

    提出了一种多尺度蛋白质语言模型，能够在蛋白质和小分子相关任务中超越先前的方法，并且通过统一分子建模实现了充分利用蛋白质语言模型的潜力。

    

    蛋白质语言模型在蛋白质工程领域展现出了显著潜力。然而，当前的蛋白质语言模型主要在残基级别上运行，这限制了它们在原子水平提供信息的能力。这一限制阻碍了我们充分利用蛋白质语言模型在涉及蛋白质和小分子的应用中的能力。本文提出了ms-ESM（多尺度ESM），一种新颖的方法，实现了多尺度统一分子建模。ms-ESM通过预训练多尺度代码切换蛋白质序列并利用多尺度位置编码来捕获残基和原子之间的关系来实现这一目标。实验结果表明，ms-ESM在蛋白质-分子任务中超越了先前的方法，展示了对蛋白质语言模型的充分利用。进一步的研究揭示通过统一分子建模，ms-ESM不

    arXiv:2403.12995v1 Announce Type: cross  Abstract: Protein language models have demonstrated significant potential in the field of protein engineering. However, current protein language models primarily operate at the residue scale, which limits their ability to provide information at the atom level. This limitation prevents us from fully exploiting the capabilities of protein language models for applications involving both proteins and small molecules. In this paper, we propose ms-ESM (multi-scale ESM), a novel approach that enables multi-scale unified molecular modeling. ms-ESM achieves this by pre-training on multi-scale code-switch protein sequences and utilizing a multi-scale position encoding to capture relationships among residues and atoms. Experimental results indicate that ms-ESM surpasses previous methods in protein-molecule tasks, demonstrating the full utilization of protein language models. Further investigations reveal that through unified molecular modeling, ms-ESM not 
    
[^6]: BurstAttention：一种用于处理极长序列的高效分布式注意力框架

    BurstAttention: An Efficient Distributed Attention Framework for Extremely Long Sequences

    [https://arxiv.org/abs/2403.09347](https://arxiv.org/abs/2403.09347)

    BurstAttention是一种用于优化内存访问和通信操作的分布式注意力框架，适用于处理极长序列。

    

    有效的注意力模块在基于Transformer的大型语言模型（LLMs）的成功中起着关键作用，但这些注意力模块的二次时间和内存复杂度在处理长序列时也构成了挑战。本文提出了一种名为“BurstAttention”的分布式注意力框架，以优化全局集群和本地设备级别的内存访问和通信操作。

    arXiv:2403.09347v1 Announce Type: cross  Abstract: Effective attention modules have played a crucial role in the success of Transformer-based large language models (LLMs), but the quadratic time and memory complexities of these attention modules also pose a challenge when processing long sequences. One potential solution for the long sequence problem is to utilize distributed clusters to parallelize the computation of attention modules across multiple devices (e.g., GPUs). However, adopting a distributed approach inevitably introduces extra memory overheads to store local attention results and incurs additional communication costs to aggregate local results into global ones. In this paper, we propose a distributed attention framework named ``BurstAttention'' to optimize memory access and communication operations at both the global cluster and local device levels. In our experiments, we compare BurstAttention with other competitive distributed attention solutions for long sequence proce
    
[^7]: FSL模型可以因为其优越性得分更高

    FSL Model can Score Higher as It Is

    [https://arxiv.org/abs/2402.18292](https://arxiv.org/abs/2402.18292)

    为了增加测试期间正确预测的机会，研究旨在通过图像到图像的转换纠正FSL模型的测试输入，生成被测试类别的新样本。

    

    在日常生活中，为了增加被正确识别的机会，我们倾向于面对面地直视面部识别机，而不是侧着面对。少样本学习（FSL）分类本身就具有挑战性，因为模型必须识别属于训练时未见的类别的图像。因此，在测试期间对扭曲和非典型的查询或支持图像会让模型更难正确预测。在我们的研究中，为了增加测试期间正确预测的机会，我们旨在通过图像到图像的转换纠正训练过的FSL模型的测试输入，生成被测试类别的新样本。FSL模型通常是在具有足够样本的类别上进行训练，然后在具有少样本样本的类别上进行测试。我们提出的方法首先捕捉测试图像的风格或形状，然后识别一个适当的训

    arXiv:2402.18292v1 Announce Type: cross  Abstract: In daily life, we tend to present the front of our faces by staring squarely at a facial recognition machine, instead of facing it sideways, in order to increase the chance of being correctly recognised. Few-shot-learning (FSL) classification is challenging in itself because a model has to identify images that belong to classes previously unseen during training. Therefore, a warped and non-typical query or support image during testing can make it even more challenging for a model to predict correctly. In our work, to increase the chance of correct prediction during testing, we aim to rectify the test input of a trained FSL model by generating new samples of the tested classes through image-to-image translation. An FSL model is usually trained on classes with sufficient samples, and then tested on classes with few-shot samples. Our proposed method first captures the style or shape of the test image, and then identifies a suitable traine
    
[^8]: 大语言模型的泛化或记忆：数据污染与可信评估

    Generalization or Memorization: Data Contamination and Trustworthy Evaluation for Large Language Models

    [https://arxiv.org/abs/2402.15938](https://arxiv.org/abs/2402.15938)

    本文提出了一种通过LLMs输出分布进行污染检测的方法CDD，以及一种基于LLMs输出修正的可信评估方法TED，以应对大语言模型在数据污染和可信评估方面面临的挑战。

    

    最近关于大语言模型（LLMs）令人印象深刻能力的说法通常是通过在开放获取的基准上进行评估来支持的。考虑到LLMs的训练数据的庞大规模和广泛来源，它可能明确或隐含地包含测试数据，导致LLMs更容易受到数据污染的影响。然而，由于训练数据的不透明性、模型的黑盒访问以及合成训练数据的快速增长，对于LLMs来说检测和减轻数据污染面临着重大挑战。在本文中，我们提出了CDD，即通过LLMs输出分布进行污染检测的CDD。CDD仅需要采样文本来检测数据污染，通过识别LLMs输出分布的峰值来进行检测。为了减轻评估中数据污染的影响，我们还提出了TED：基于LLMs输出修正的可信评估。

    arXiv:2402.15938v1 Announce Type: cross  Abstract: Recent statements about the impressive capabilities of large language models (LLMs) are usually supported by evaluating on open-access benchmarks. Considering the vast size and wide-ranging sources of LLMs' training data, it could explicitly or implicitly include test data, leading to LLMs being more susceptible to data contamination. However, due to the opacity of training data, the black-box access of models, and the rapid growth of synthetic training data, detecting and mitigating data contamination for LLMs faces significant challenges. In this paper, we propose CDD, which stands for Contamination Detection via output Distribution for LLMs. CDD necessitates only the sampled texts to detect data contamination, by identifying the peakedness of LLM's output distribution. To mitigate the impact of data contamination in evaluation, we also present TED: Trustworthy Evaluation via output Distribution, based on the correction of LLM's outp
    
[^9]: GenTranslate: 大型语言模型是生成的多语言语音和机器翻译工具

    GenTranslate: Large Language Models are Generative Multilingual Speech and Machine Translators

    [https://arxiv.org/abs/2402.06894](https://arxiv.org/abs/2402.06894)

    GenTranslate是一个新的翻译任务生成模型，通过利用大型语言模型的丰富语言知识和强大推理能力，可以从N-best列表中生成更高质量的翻译结果。

    

    大型语言模型（LLMs）的最新进展通过减少表示误差和引入外部知识，推动了多语言语音和机器翻译的发展。然而，翻译任务通常使用束搜索解码和前k个假设选择进行推理。这些技术往往不能充分利用多样化的N-best假设中的丰富信息，使得它们在需要单个高质量输出序列的翻译任务中效果不佳。在本文中，我们提出了一个新的翻译任务生成模型，即“GenTranslate”，它基于LLMs来从N-best列表中生成更好的结果。利用LLMs丰富的语言知识和强大的推理能力，我们的新模型可以将N-best候选人中的丰富信息整合起来，生成更高质量的翻译结果。此外，为了支持LLM的微调，我们构建并发布了一个HypoTransla模型。

    Recent advances in large language models (LLMs) have stepped forward the development of multilingual speech and machine translation by its reduced representation errors and incorporated external knowledge. However, both translation tasks typically utilize beam search decoding and top-1 hypothesis selection for inference. These techniques struggle to fully exploit the rich information in the diverse N-best hypotheses, making them less optimal for translation tasks that require a single, high-quality output sequence. In this paper, we propose a new generative paradigm for translation tasks, namely "GenTranslate", which builds upon LLMs to generate better results from the diverse translation versions in N-best list. Leveraging the rich linguistic knowledge and strong reasoning abilities of LLMs, our new paradigm can integrate the rich information in N-best candidates to generate a higher-quality translation result. Furthermore, to support LLM finetuning, we build and release a HypoTransla
    
[^10]: 随机偏置界对随机部分监控的应用

    Randomized Confidence Bounds for Stochastic Partial Monitoring

    [https://arxiv.org/abs/2402.05002](https://arxiv.org/abs/2402.05002)

    本文研究了随机部分监控中基于随机化的偏置界策略，该策略扩展了现有随机策略无法应用的情境和非情境设置，实验证明该策略优于最先进的方法。

    

    部分监控 (PM) 框架提供了通过不完整的反馈进行顺序学习问题的理论表述。在每个回合中，学习代理选择一个动作，而环境同时选择一个结果。然后代理观察到一个仅部分提供信息关于（未观察到的）结果的反馈信号。代理利用接收到的反馈信号选择能够最小化（未观察到的）累计损失的动作。在情境 PM 中，结果依赖于代理在每轮选择动作之前可观察到的某些附加信息。在本文中，我们考虑了具有随机结果的情境和非情境的 PM 设置。我们引入了一种基于确定性置信界的随机化策略的新类方法，将遗憾保证扩展到现有的随机策略不适用的设置中。我们的实验表明，所提出的 RandCBP 和 RandCBPside* 策略改进了最先进的方法。

    The partial monitoring (PM) framework provides a theoretical formulation of sequential learning problems with incomplete feedback. On each round, a learning agent plays an action while the environment simultaneously chooses an outcome. The agent then observes a feedback signal that is only partially informative about the (unobserved) outcome. The agent leverages the received feedback signals to select actions that minimize the (unobserved) cumulative loss. In contextual PM, the outcomes depend on some side information that is observable by the agent before selecting the action on each round. In this paper, we consider the contextual and non-contextual PM settings with stochastic outcomes. We introduce a new class of strategies based on the randomization of deterministic confidence bounds, that extend regret guarantees to settings where existing stochastic strategies are not applicable. Our experiments show that the proposed RandCBP and RandCBPside* strategies improve state-of-the-art b
    
[^11]: 通过考虑美学约束的扩散模型实现对齐布局生成

    Towards Aligned Layout Generation via Diffusion Model with Aesthetic Constraints

    [https://arxiv.org/abs/2402.04754](https://arxiv.org/abs/2402.04754)

    本文提出了一种统一的布局生成模型，通过考虑美学约束，在图形设计中创建合理的元素可视排列。与之前的方法相比，该模型表现出更好的对齐性能，并在各种布局生成任务中取得了优秀的性能。

    

    可控布局生成是指在具有代表设计意图的约束条件下，在图形设计（例如文档和网页设计）中创建一种合理的元素可视排列的过程。尽管最近基于扩散模型的方法取得了最先进的FID分数，但与之前基于转换器的模型相比，它们往往表现出更明显的偏离对齐。在这项工作中，我们提出了一种统一的模型——LACE（Layout Constraint Diffusion Model），用于处理各种布局生成任务，例如根据指定属性排列元素、完善或完成粗糙的布局设计。该模型基于连续的扩散模型。与使用离散扩散模型的现有方法相比，连续状态空间设计可以在训练中引入可微的美学约束函数。对于条件生成，我们通过掩码输入引入条件。大量实验证明，LACE模型在不同布局生成任务上都取得了优秀的性能。

    Controllable layout generation refers to the process of creating a plausible visual arrangement of elements within a graphic design (e.g., document and web designs) with constraints representing design intentions. Although recent diffusion-based models have achieved state-of-the-art FID scores, they tend to exhibit more pronounced misalignment compared to earlier transformer-based models. In this work, we propose the $\textbf{LA}$yout $\textbf{C}$onstraint diffusion mod$\textbf{E}$l (LACE), a unified model to handle a broad range of layout generation tasks, such as arranging elements with specified attributes and refining or completing a coarse layout design. The model is based on continuous diffusion models. Compared with existing methods that use discrete diffusion models, continuous state-space design can enable the incorporation of differentiable aesthetic constraint functions in training. For conditional generation, we introduce conditions via masked input. Extensive experiment re
    
[^12]: 无需训练的一致性文本到图像生成

    Training-Free Consistent Text-to-Image Generation

    [https://arxiv.org/abs/2402.03286](https://arxiv.org/abs/2402.03286)

    本文提出了一种无需训练的方法ConsiStory，通过共享预训练模型的内部激活，实现了一致的文本到图像生成。引入了主题驱动的共享注意力块和基于对应的特征注入，促进了图像之间的主题一致性，并采用了策略来保持布局多样性。

    

    文本到图像模型通过自然语言引导图像生成过程，提供了一种新的创造性灵活性。然而，使用这些模型在多样化的提示下一致地描绘相同的主题仍然具有挑战性。现有方法通过优化模型来教授它描述特定用户提供主题的新词汇或者为模型添加图像条件。这些方法要求针对每个主题进行漫长的优化或进行大规模预训练。此外，它们在将生成的图像与文本提示对齐和描绘多个主题方面遇到困难。在这里，我们介绍了一种无训练方法ConsiStory，通过共享预训练模型的内部激活来实现一致的主题生成。我们引入了一个主题驱动共享注意力块和基于对应的特征注入，以促进图像之间的主题一致性。此外，我们开发了策略以鼓励布局多样性，同时保持主题一致性。

    Text-to-image models offer a new level of creative flexibility by allowing users to guide the image generation process through natural language. However, using these models to consistently portray the same subject across diverse prompts remains challenging. Existing approaches fine-tune the model to teach it new words that describe specific user-provided subjects or add image conditioning to the model. These methods require lengthy per-subject optimization or large-scale pre-training. Moreover, they struggle to align generated images with text prompts and face difficulties in portraying multiple subjects. Here, we present ConsiStory, a training-free approach that enables consistent subject generation by sharing the internal activations of the pretrained model. We introduce a subject-driven shared attention block and correspondence-based feature injection to promote subject consistency between images. Additionally, we develop strategies to encourage layout diversity while maintaining su
    
[^13]: 线性马尔可夫决策过程的速率最优策略优化

    Rate-Optimal Policy Optimization for Linear Markov Decision Processes

    [https://arxiv.org/abs/2308.14642](https://arxiv.org/abs/2308.14642)

    本文中，我们研究了在线周期性线性马尔可夫决策过程中的遗憾最小化问题，并提出了一种与周期数K成比率最优的遗憾收敛率O(√K)。这是首个针对带有乐观反馈的随机设置使用基于策略优化的方法并建立与K最优收敛速率的研究，也是首个针对具有全信息反馈的对抗设置并建立与K最优速率的研究，目前尚未找到具有最优速率保证的算法。

    

    我们研究在线周期性线性马尔可夫决策过程中最小化遗憾，并且得到了与$K$（表示周期数）成比率最优的$\widetilde{O}(\sqrt{K})$的遗憾。我们的工作是首次在带有乐观反馈的随机设置中使用基于策略优化的方法建立了与$K$最优（相对于$K$）的收敛速率，也是首次建立在完全信息反馈的敌对设置中与$K$最优的速率，这种情况下目前没有已知具有最优速率保证的算法。

    arXiv:2308.14642v2 Announce Type: replace  Abstract: We study regret minimization in online episodic linear Markov Decision Processes, and obtain rate-optimal $\widetilde O (\sqrt K)$ regret where $K$ denotes the number of episodes. Our work is the first to establish the optimal (w.r.t.~$K$) rate of convergence in the stochastic setting with bandit feedback using a policy optimization based approach, and the first to establish the optimal (w.r.t.~$K$) rate in the adversarial setup with full information feedback, for which no algorithm with an optimal rate guarantee is currently known.
    
[^14]: Lookbehind-SAM: k步回望，1步前进

    Lookbehind-SAM: k steps back, 1 step forward

    [https://arxiv.org/abs/2307.16704](https://arxiv.org/abs/2307.16704)

    本研究提出了一种名为Lookbehind-SAM的方法，通过多次上升步骤和线性插值来增强最大化和最小化过程，以实现更好的损失锐度折衷。实验证明，该方法在各种任务中都有多种优点，包括提高的泛化性能、更高的鲁棒性和改进的学习过程。

    

    锐度感知优化（SAM）方法通过将最小化损失值和损失锐度问题表述为极小极大型目标，得到了越来越多的关注。在本研究中，我们增加了SAM目标中最大化和最小化部分的效率，以实现更好的损失锐度折衷。受Lookahead优化器的启发，该优化器使用多个向前的下降步骤，我们提出了Lookbehind，它在后面执行多个上升步骤，增强了SAM的最大化步骤，并找到了一个具有更高损失的最坏情况扰动。然后，为了减小由于收集到的多个上升步骤的梯度所引起的下降步骤的方差，我们采用线性插值来改进最小化过程。Lookbehind在各种任务中带来了许多好处。特别是，我们展示了提高的泛化性能，对噪声权重的更高鲁棒性，以及在学习过程中改进的效果和较少的灾难性遗忘。

    Sharpness-aware minimization (SAM) methods have gained increasing popularity by formulating the problem of minimizing both loss value and loss sharpness as a minimax objective. In this work, we increase the efficiency of the maximization and minimization parts of SAM's objective to achieve a better loss-sharpness trade-off. By taking inspiration from the Lookahead optimizer, which uses multiple descent steps ahead, we propose Lookbehind, which performs multiple ascent steps behind to enhance the maximization step of SAM and find a worst-case perturbation with higher loss. Then, to mitigate the variance in the descent step arising from the gathered gradients across the multiple ascent steps, we employ linear interpolation to refine the minimization step. Lookbehind leads to a myriad of benefits across a variety of tasks. Particularly, we show increased generalization performance, greater robustness against noisy weights, as well as improved learning and less catastrophic forgetting in l
    
[^15]: 查询易于翻转样本的深度主动学习

    Querying Easily Flip-flopped Samples for Deep Active Learning. (arXiv:2401.09787v1 [cs.LG])

    [http://arxiv.org/abs/2401.09787](http://arxiv.org/abs/2401.09787)

    本文提出了一种基于模型的预测不确定性度量，即最小不一致度量（LDM），用于解决复杂决策边界情况下的主动学习问题。通过查询具有最小LDM的未标记数据，可以提高深度学习模型的性能。

    

    主动学习是一种机器学习范式，旨在通过选择和查询未标记数据来提高模型的性能。一种有效的选择策略是基于模型的预测不确定性，这可以解释为样本的信息量度量。样本到决策边界的距离是一种自然的预测不确定性度量，但通常难以计算，特别是对于多类分类任务中形成的复杂决策边界。为了解决这个问题，本文提出了“最小不一致度量”（LDM），定义为预测标签不一致的最小概率，并且证明了LDM的估计器在温和假设下是渐近一致的。该估计器计算效率高，并且可以通过参数扰动轻松实现在深度学习模型中使用。基于LDM的主动学习通过查询具有最小LDM的未标记数据来执行。

    Active learning is a machine learning paradigm that aims to improve the performance of a model by strategically selecting and querying unlabeled data. One effective selection strategy is to base it on the model's predictive uncertainty, which can be interpreted as a measure of how informative a sample is. The sample's distance to the decision boundary is a natural measure of predictive uncertainty, but it is often intractable to compute, especially for complex decision boundaries formed in multiclass classification tasks. To address this issue, this paper proposes the {\it least disagree metric} (LDM), defined as the smallest probability of disagreement of the predicted label, and an estimator for LDM proven to be asymptotically consistent under mild assumptions. The estimator is computationally efficient and can be easily implemented for deep learning models using parameter perturbation. The LDM-based active learning is performed by querying unlabeled data with the smallest LDM. Exper
    
[^16]: 数据驱动的物理信息神经网络：数字孪生的观点

    Data-Driven Physics-Informed Neural Networks: A Digital Twin Perspective. (arXiv:2401.08667v1 [physics.flu-dyn])

    [http://arxiv.org/abs/2401.08667](http://arxiv.org/abs/2401.08667)

    该论文研究了利用物理信息神经网络(PINNs)实现数字孪生(DT)的潜力。提出了适用于无网格框架的自适应采样方法，并验证了PINNs在参数化的Navier-Stokes方程中的可扩展性和多保真度的优势。

    

    本研究从不同角度探索了利用物理信息神经网络(PINNs)实现数字孪生(DT)的潜力。首先，研究了用于配点的各种自适应采样方法，以验证它们在无网格框架的PINNs中的有效性，该框架允许自动构建虚拟表示，无需手动生成网格。然后，检验了数据驱动的PINNs(DD-PINNs)框架的整体性能，该框架可以利用在DT场景中获得的数据集。其对参数化的Navier-Stokes方程的更一般物理性的可扩展性得到了验证，其中PINNs在雷诺数变化时无需重新训练。此外，由于实际上数据集经常可以在不同的保真度/稀疏度下收集，还提出并评估了多保真度的DD-PINNs。它们在外推任务中表现出了显著的预测性能，相对于单保真度方法提高了42％到62％。

    This study explores the potential of physics-informed neural networks (PINNs) for the realization of digital twins (DT) from various perspectives. First, various adaptive sampling approaches for collocation points are investigated to verify their effectiveness in the mesh-free framework of PINNs, which allows automated construction of virtual representation without manual mesh generation. Then, the overall performance of the data-driven PINNs (DD-PINNs) framework is examined, which can utilize the acquired datasets in DT scenarios. Its scalability to more general physics is validated within parametric Navier-Stokes equations, where PINNs do not need to be retrained as the Reynolds number varies. In addition, since datasets can be often collected from different fidelity/sparsity in practice, multi-fidelity DD-PINNs are also proposed and evaluated. They show remarkable prediction performance even in the extrapolation tasks, with $42\sim62\%$ improvement over the single-fidelity approach.
    
[^17]: 基于$f$散度的分类：超越交叉熵的应用

    $f$-Divergence Based Classification: Beyond the Use of Cross-Entropy. (arXiv:2401.01268v1 [cs.LG])

    [http://arxiv.org/abs/2401.01268](http://arxiv.org/abs/2401.01268)

    这项研究提出了一种基于$f$散度的分类方法，超越了传统的使用交叉熵的方法。通过提取基于变分表示的$f$散度目标函数，该方法采用贝叶斯视角将分类任务视为最大后验概率问题，并提出了五个采用不同$f$散度的后验概率估计器。此外，通过一种自底向上的方法，还提出了一种新的基于平移对数的$f$散度的目标函数。这项研究在理论上证明了收敛性的属性。

    

    在深度学习中，分类任务被形式化为通过最小化交叉熵来解决的优化问题。然而，目前在目标函数设计方面的最新进展使得$f$散度度量可以推广分类问题的优化问题。为了实现这个目标，我们采用贝叶斯视角，并将分类任务形式化为一个最大后验概率问题。我们提出了一类基于$f$散度变分表示的目标函数，从中提取了一系列五个后验概率估计器，利用了众所周知的$f$散度。此外，受到改进最先进方法的挑战的驱动力，我们提出了一种自底向上的方法，使我们能够提出一个对应于一种新的被称为平移对数 (SL) 的$f$散度的新目标函数（和后验概率估计器）的公式。首先，我们在理论上证明了收敛性的属性。

    In deep learning, classification tasks are formalized as optimization problems solved via the minimization of the cross-entropy. However, recent advancements in the design of objective functions allow the $f$-divergence measure to generalize the formulation of the optimization problem for classification. With this goal in mind, we adopt a Bayesian perspective and formulate the classification task as a maximum a posteriori probability problem. We propose a class of objective functions based on the variational representation of the $f$-divergence, from which we extract a list of five posterior probability estimators leveraging well-known $f$-divergences. In addition, driven by the challenge of improving the state-of-the-art approach, we propose a bottom-up method that leads us to the formulation of a new objective function (and posterior probability estimator) corresponding to a novel $f$-divergence referred to as shifted log (SL). First, we theoretically prove the convergence property o
    
[^18]: 大型语言模型增强的算法选择：朝着全面算法表示的方向

    Large Language Model-Enhanced Algorithm Selection: Towards Comprehensive Algorithm Representation. (arXiv:2311.13184v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2311.13184](http://arxiv.org/abs/2311.13184)

    本论文提出了一种方法，通过将算法表示集成到算法选择中，从而填补了当前算法选择技术对算法特征的研究空白。

    

    算法选择旨在在执行之前识别解决特定问题的最合适算法，已成为自动机器学习中的关键过程。当前主流的算法选择技术主要依赖于各种问题的特征表示，并使用每个算法的性能作为监督信息。然而，目前对算法特征的考虑存在重要的研究空白。这主要归因于算法的固有复杂性，使得在不同种类的算法中找到一种普适有效的特征提取方法特别具有挑战性。不幸的是，忽视了这一方面无疑会影响算法选择的准确性，并间接需要增加训练数据的数量。本文提出了一种方法来解决这一空白，即将算法表示集成到算法选择中。

    Algorithm selection aims to identify the most suitable algorithm for solving a specific problem before execution, which has become a critical process of the AutoML. Current mainstream algorithm selection techniques rely heavily on feature representations of various problems and employ the performance of each algorithm as supervised information. However, there is a significant research gap concerning the consideration of algorithm features. This gap is primarily attributed to the inherent complexity of algorithms, making it particularly challenging to find a universally effective feature extraction method that is applicable across a diverse range of algorithms. Unfortunately, neglecting this aspect undoubtedly impacts the accuracy of algorithm selection and indirectly necessitates an increased volume of problem data for training purposes. This paper takes a significant stride towards addressing this gap by proposing an approach that integrates algorithm representation into the algorithm
    
[^19]: GOPlan:通过学习模型进行计划的目标条件下的离线强化学习

    GOPlan: Goal-conditioned Offline Reinforcement Learning by Planning with Learned Models. (arXiv:2310.20025v1 [cs.LG])

    [http://arxiv.org/abs/2310.20025](http://arxiv.org/abs/2310.20025)

    GOPlan是一个使用学习模型进行计划的目标条件下的离线强化学习方法，通过预训练先验策略和使用重新分析方法生成虚构轨迹，用以提高性能和处理有限数据预算和未见目标泛化的能力。

    

    离线目标条件下的强化学习（GCRL）为从多样化和多任务的离线数据集中学习通用策略提供了可行的范例。尽管近期取得了显著进展，但主导的离线GCRL方法仍然受限于无模型方法，限制了它们应对有限数据预算和未见目标泛化的能力。在这项工作中，我们提出了一种新的两阶段模型为基础的框架，Goal-conditioned Offline Planning（GOPlan），包括（1）预训练一个能够捕捉多目标数据集中多模态动作分布的先验策略；（2）利用规划的重新分析方法为微调策略生成虚构轨迹。具体而言，先验策略基于一个具有明显模式分离的带优势权重的条件生成对抗网络，以克服超出分布（OOD）动作的缺点。为进一步优化策略，重新分析方法通过规划生成高质量的虚构数据。

    Offline goal-conditioned RL (GCRL) offers a feasible paradigm to learn general-purpose policies from diverse and multi-task offline datasets. Despite notable recent progress, the predominant offline GCRL methods have been restricted to model-free approaches, constraining their capacity to tackle limited data budgets and unseen goal generalization. In this work, we propose a novel two-stage model-based framework, Goal-conditioned Offline Planning (GOPlan), including (1) pretraining a prior policy capable of capturing multi-modal action distribution within the multi-goal dataset; (2) employing the reanalysis method with planning to generate imagined trajectories for funetuning policies. Specifically, the prior policy is based on an advantage-weighted Conditioned Generative Adversarial Networks that exhibits distinct mode separation to overcome the pitfalls of out-of-distribution (OOD) actions. For further policy optimization, the reanalysis method generates high-quality imaginary data by
    
[^20]: 为协调虚拟电厂资产的分布式优化引入机器学习

    Machine Learning Infused Distributed Optimization for Coordinating Virtual Power Plant Assets. (arXiv:2310.17882v1 [cs.LG])

    [http://arxiv.org/abs/2310.17882](http://arxiv.org/abs/2310.17882)

    本文提出了一种名为LOOP-MAC的方法，利用机器学习辅助的分布式优化来协调虚拟电厂（VPP）的资产。该方法采用多智能体协调视角，利用神经网络逼近器加速解决方案搜索。该方法通过引入测量图来保证最佳解之间的关系。

    

    随着对分布式能源资源（DER）部署日益增加的兴趣，虚拟电厂（VPP）已成为汇集各种DER并促进其参与批发能源市场的关键工具。这些VPP部署得到了联邦能源监管委员会第2222号命令的推动，该命令使DER和VPP在市场领域具有竞争力。然而，DER的多样性和分散性质给VPP资产的可扩展协调带来了显著挑战。为了解决效率和速度瓶颈，本文提出了一种新颖的机器学习辅助的分布式优化方法来协调VPP资产。我们的方法名为LOOP-MAC（为多智能体协调优化过程学习优化），采用多智能体协调视角，每个VPP代理管理多个DER并利用神经网络逼近器加速解决方案搜索。LOOP-MAC方法使用一个测量图确保了最佳解之间的关系。

    Amid the increasing interest in the deployment of Distributed Energy Resources (DERs), the Virtual Power Plant (VPP) has emerged as a pivotal tool for aggregating diverse DERs and facilitating their participation in wholesale energy markets. These VPP deployments have been fueled by the Federal Energy Regulatory Commission's Order 2222, which makes DERs and VPPs competitive across market segments. However, the diversity and decentralized nature of DERs present significant challenges to the scalable coordination of VPP assets. To address efficiency and speed bottlenecks, this paper presents a novel machine learning-assisted distributed optimization to coordinate VPP assets. Our method, named LOOP-MAC(Learning to Optimize the Optimization Process for Multi-agent Coordination), adopts a multi-agent coordination perspective where each VPP agent manages multiple DERs and utilizes neural network approximators to expedite the solution search. The LOOP-MAC method employs a gauge map to guarant
    
[^21]: 带有外部引导的图像聚类

    Image Clustering with External Guidance. (arXiv:2310.11989v1 [cs.LG])

    [http://arxiv.org/abs/2310.11989](http://arxiv.org/abs/2310.11989)

    这项工作提出了一种新的聚类方法，利用外部知识来引导聚类。通过利用WordNet的文本语义，该方法能够提高图像聚类的效果。

    

    聚类的核心是融入先前的知识来构建监督信号。从基于数据紧密性的经典k均值到最近的基于自监督引导的对比聚类，聚类方法的进步与监督信号的发展内在地相对应。目前，很多工作已经致力于从数据中挖掘内部监督信号。然而，丰富的外部知识，例如语义描述，自然地促进了聚类，却被遗憾地忽视了。在这项工作中，我们提出利用外部知识作为新的监督信号来引导聚类，即使它似乎与给定的数据无关。为了实现和验证我们的想法，我们设计了一种外部引导的聚类方法（文本辅助聚类，TAC），它利用WordNet的文本语义来促进图像聚类。具体而言，TAC首先选择并检索最能区分图像的WordNet名词以增强聚类的效果。

    The core of clustering is incorporating prior knowledge to construct supervision signals. From classic k-means based on data compactness to recent contrastive clustering guided by self-supervision, the evolution of clustering methods intrinsically corresponds to the progression of supervision signals. At present, substantial efforts have been devoted to mining internal supervision signals from data. Nevertheless, the abundant external knowledge such as semantic descriptions, which naturally conduces to clustering, is regrettably overlooked. In this work, we propose leveraging external knowledge as a new supervision signal to guide clustering, even though it seems irrelevant to the given data. To implement and validate our idea, we design an externally guided clustering method (Text-Aided Clustering, TAC), which leverages the textual semantics of WordNet to facilitate image clustering. Specifically, TAC first selects and retrieves WordNet nouns that best distinguish images to enhance th
    
[^22]: ReMax:一种用于对齐大型语言模型的简单、有效和高效的强化学习方法

    ReMax: A Simple, Effective, and Efficient Reinforcement Learning Method for Aligning Large Language Models. (arXiv:2310.10505v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.10505](http://arxiv.org/abs/2310.10505)

    ReMax是一种用于对齐大型语言模型的简单、有效和高效的强化学习方法，相比于PPO，ReMax简化了实现，减少了内存使用，并解决了fine-tuning时的内存溢出问题。

    

    对齐对于训练大型语言模型（LLMs）非常重要。目前解决这个问题的主要策略是通过从人类反馈中进行强化学习（RLHF），其中PPO是事实上的算法。然而，众所周知，PPO在计算效率上存在问题，这是本论文试图解决的挑战。我们在RLHF任务中确定了三个重要特性：快速模拟、确定性转换和轨迹级奖励，这些特性在PPO中没有得到充分利用。基于这些观察，我们开发了一种针对RLHF的新算法，称为ReMax。ReMax的算法设计是基于一种广为使用的算法REINFORCE，但配备了一种新的方差减少技术。我们的方法相对于PPO具有三重优势：首先，ReMax实现简单，消除了PPO中的许多与规模相关且繁琐的超参数。其次，ReMax原则上可以节约约50%的内存使用。结果导致PPO在进行fine-tuning时出现内存溢出的问题。

    Alignment is of critical importance for training large language models (LLMs). The predominant strategy to address this is through Reinforcement Learning from Human Feedback (RLHF), where PPO serves as the de-facto algorithm. Yet, PPO is known to suffer from computational inefficiency, which is a challenge that this paper aims to address. We identify three important properties in RLHF tasks: fast simulation, deterministic transitions, and trajectory-level rewards, which are not leveraged in PPO. Based on such observations, we develop a new algorithm tailored for RLHF, called ReMax. The algorithm design of ReMax is built on a celebrated algorithm REINFORCE but is equipped with a new variance-reduction technique.  Our method has three-fold advantages over PPO: first, ReMax is simple to implement and removes many hyper-parameters in PPO, which are scale-sensitive and laborious to tune. Second, ReMax saves about 50% memory usage in principle. As a result, PPO runs out-of-memory when fine-t
    
[^23]: SuperCalo: 能量沉积量模拟的超分辨率技术

    SuperCalo: Calorimeter shower super-resolution. (arXiv:2308.11700v1 [physics.ins-det])

    [http://arxiv.org/abs/2308.11700](http://arxiv.org/abs/2308.11700)

    本文介绍了一种名为SuperCalo的能量沉积模拟超分辨率模型，能够快速上采样高维细粒度的能量沉积模拟，从而降低计算成本和生成时间。

    

    能量沉积模拟是大型强子对撞机计算流程中的主要瓶颈。最近有一些工作使用深度生成模型来克服这个挑战，但许多表现最佳的模型在训练和生成时间上无法很好地适应高维能量沉积模拟。在本文中，我们介绍了一种名为SuperCalo的基于流的超分辨率模型，并证明了高维细粒度的能量沉积模拟可以从粗粒度模拟中快速上采样。这种新颖的方法可以降低与快速能量沉积模拟模型相关的计算成本、内存需求和生成时间。另外，我们还展示了由SuperCalo上采样得到的能量沉积模拟具有高度变化的特点。这使得可以从较少的粗粒度模拟中上采样出多个高维能量沉积模拟，以高保真度的方式进一步减少生成时间。

    Calorimeter shower simulation is a major bottleneck in the Large Hadron Collider computational pipeline. There have been recent efforts to employ deep-generative surrogate models to overcome this challenge. However, many of best performing models have training and generation times that do not scale well to high-dimensional calorimeter showers. In this work, we introduce SuperCalo, a flow-based super-resolution model, and demonstrate that high-dimensional fine-grained calorimeter showers can be quickly upsampled from coarse-grained showers. This novel approach presents a way to reduce computational cost, memory requirements and generation time associated with fast calorimeter simulation models. Additionally, we show that the showers upsampled by SuperCalo possess a high degree of variation. This allows a large number of high-dimensional calorimeter showers to be upsampled from much fewer coarse showers with high-fidelity, which results in additional reduction in generation time.
    
[^24]: 基础模型导向的稳健性: 通过预训练模型对稳健性图像模型进行评估

    Foundation Model-oriented Robustness: Robust Image Model Evaluation with Pretrained Models. (arXiv:2308.10632v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2308.10632](http://arxiv.org/abs/2308.10632)

    本文提出了一种通过预训练模型对稳健性图像模型进行评估的新方法，通过与基础模型进行比较，直接测量图像分类模型的性能，扩展图像数据集以完成超出基准范围的评估。

    

    机器学习在有限数据集上表现出了出色的性能，然而，固定基准上的分数是否足以充分体现模型在真实世界中的性能仍有讨论。实际上，理想的稳健模型可能与神谕（例如，人类用户）表现类似，因此一个好的评估协议可能是评估模型相对于神谕的行为。本文介绍了一种新的稳健性测量方法，直接测量图像分类模型相对于替代神谕（即基础模型）的性能。此外，我们设计了一种简单的方法，可以在基准范围之外完成评估。我们的方法通过添加具有足够扰动的新样本来扩展图像数据集，这些样本与原始集合中的样本有所不同，但仍限制在原始测试图像所代表的相同图像-标签结构内，由预训练的基础模型限定。

    Machine learning has demonstrated remarkable performance over finite datasets, yet whether the scores over the fixed benchmarks can sufficiently indicate the model's performance in the real world is still in discussion. In reality, an ideal robust model will probably behave similarly to the oracle (e.g., the human users), thus a good evaluation protocol is probably to evaluate the models' behaviors in comparison to the oracle. In this paper, we introduce a new robustness measurement that directly measures the image classification model's performance compared with a surrogate oracle (i.e., a foundation model). Besides, we design a simple method that can accomplish the evaluation beyond the scope of the benchmarks. Our method extends the image datasets with new samples that are sufficiently perturbed to be distinct from the ones in the original sets, but are still bounded within the same image-label structure the original test image represents, constrained by a foundation model pretraine
    
[^25]: MIMIC: 基于图像对应关系的遮蔽图像建模

    MIMIC: Masked Image Modeling with Image Correspondences. (arXiv:2306.15128v1 [cs.CV])

    [http://arxiv.org/abs/2306.15128](http://arxiv.org/abs/2306.15128)

    MIMIC是一种基于图像对应关系的遮蔽图像建模方法，通过挖掘不需要任何注释的数据集，使用多个自监督模型进行训练，达到了在多个下游任务上优于使用注释挖掘的表示的效果。

    

    许多像素级的密集预测任务——如计算机视觉中的深度估计和语义分割——如今依赖于预训练的图像表示。因此，筛选有效的预训练数据集至关重要。不幸的是，有效的预训练数据集仅通过模拟环境中的带有注释的3D网格、点云和相机参数筛选而来，并不具备多视角场景。我们提出了一种不需要任何注释的数据集筛选机制。我们从开源视频数据集和合成的3D环境中挖掘了两个数据集：MIMIC-1M(包含1.3M个多视角图像对)和MIMIC-3M(包含3.1M个多视角图像对)。我们使用多个自监督模型进行训练，采用不同的遮蔽图像建模目标，展示了以下发现：在多个下游任务中，基于MIMIC-3M训练的表示优于使用注释挖掘的表示，包括深度估计、语义分割、表面法线和姿态估计等。

    Many pixelwise dense prediction tasks-depth estimation and semantic segmentation in computer vision today rely on pretrained image representations. Therefore, curating effective pretraining datasets is vital. Unfortunately, the effective pretraining datasets are those with multi-view scenes and have only been curated using annotated 3D meshes, point clouds, and camera parameters from simulated environments. We propose a dataset-curation mechanism that does not require any annotations. We mine two datasets: MIMIC-1M with 1.3M and MIMIC-3M with 3.1M multi-view image pairs from open-sourced video datasets and from synthetic 3D environments. We train multiple self-supervised models with different masked image modeling objectives to showcase the following findings: Representations trained on MIMIC-3M outperform those mined using annotations on multiple downstream tasks, including depth estimation, semantic segmentation, surface normals, and pose estimation. They also outperform representati
    
[^26]: 从功能等价的角度看前馈神经网络的复杂性。

    Complexity of Feed-Forward Neural Networks from the Perspective of Functional Equivalence. (arXiv:2305.11417v1 [cs.LG])

    [http://arxiv.org/abs/2305.11417](http://arxiv.org/abs/2305.11417)

    本文从功能等价的角度出发研究前馈神经网络的复杂性，发现利用置换不变性的特性可以降低网络的复杂度，通过过参数化可以增加训练网络的容易程度，并对深度学习中的优化和泛化理解具有重要意义。

    

    本文通过考察功能等价的概念来研究前馈神经网络的复杂性，该概念表明不同的网络参数化可以导致相同的函数。我们利用置换不变性的特性为前馈神经网络类导出了一个新的覆盖数上界，发现利用该性质可以降低神经网络的复杂度。此外，基于参数空间的对称结构，我们证明适当的随机参数初始化策略可以增加优化收敛的概率。我们发现，过参数化的网络往往更容易训练，即增加神经网络的宽度会导致有效参数空间的体积趋近于零。本研究结果揭示了过参数化的新见解，并对深度学习中的泛化和优化理解具有重要意义。

    In this paper, we investigate the complexity of feed-forward neural networks by examining the concept of functional equivalence, which suggests that different network parameterizations can lead to the same function. We utilize the permutation invariance property to derive a novel covering number bound for the class of feedforward neural networks, which reveals that the complexity of a neural network can be reduced by exploiting this property. Furthermore, based on the symmetric structure of parameter space, we demonstrate that an appropriate strategy of random parameter initialization can increase the probability of convergence for optimization. We found that overparameterized networks tend to be easier to train in the sense that increasing the width of neural networks leads to a vanishing volume of the effective parameter space. Our findings offer new insights into overparameterization and have significant implications for understanding generalization and optimization in deep learning
    
[^27]: OpenBox：通用黑盒优化的 Python 工具包

    OpenBox: A Python Toolkit for Generalized Black-box Optimization. (arXiv:2304.13339v1 [cs.LG])

    [http://arxiv.org/abs/2304.13339](http://arxiv.org/abs/2304.13339)

    OpenBox是一个通用黑盒优化的Python工具包，提供了用户友好的接口和可视化功能，模块化设计能够在现有系统中灵活部署，并且实验证明其比现有系统更有效和高效。

    

    黑盒优化具有广泛的应用，包括自动机器学习、实验设计和数据库参数调整。然而，使用现有软件包时，用户在适用性、性能和效率方面仍面临挑战。本文介绍了 OpenBox，这是一个开源的黑盒优化工具包，提高了其可用性。它实现了用户友好的接口和可视化功能，让用户能够定义和管理任务。OpenBox 的模块化设计有助于在现有系统中灵活部署。实验结果表明，OpenBox比现有系统更有效和高效。OpenBox 的源代码可在 https://github.com/PKU-DAIR/open-box 中找到。

    Black-box optimization (BBO) has a broad range of applications, including automatic machine learning, experimental design, and database knob tuning. However, users still face challenges when applying BBO methods to their problems at hand with existing software packages in terms of applicability, performance, and efficiency. This paper presents OpenBox, an open-source BBO toolkit with improved usability. It implements user-friendly inferfaces and visualization for users to define and manage their tasks. The modular design behind OpenBox facilitates its flexible deployment in existing systems. Experimental results demonstrate the effectiveness and efficiency of OpenBox over existing systems. The source code of OpenBox is available at https://github.com/PKU-DAIR/open-box.
    
[^28]: 电话会话的低延迟发言分离和语音活动检测的端到端集成

    End-to-End Integration of Speech Separation and Voice Activity Detection for Low-Latency Diarization of Telephone Conversations. (arXiv:2303.12002v1 [eess.AS])

    [http://arxiv.org/abs/2303.12002](http://arxiv.org/abs/2303.12002)

    本文重点研究了低延迟流式分离应用中的基于语音分离的发言者分离（SSGD）在会话电话语音（CTS）领域中的应用。通过分离说话人并在每个分离的流上应用语音活动检测（VAD）来执行发言者分离，提出了一种新型、因果和计算效率高的泄漏去除算法。在CALLHOME和Fisher语料库（第1和2部分）上的性能评估表明，SSGD算法能够有效地提高分离和发言者分离的性能。

    

    最近的研究表明，基于语音分离的发言者分离（SSGD）是一个越来越有前途的方向，这主要得益于语音分离的最新进展。它通过首先分离说话人，然后在每个分离的流上应用语音活动检测（VAD）来执行发言者分离。在本研究中，我们对会话电话语音（CTS）领域中的SSGD进行了深入研究，重点是低延迟流式分离应用。我们考虑了三种最先进的语音分离（SSep）算法，并研究了它们在在线和离线场景下的性能，考虑了非因果和因果实现以及连续SSep（CSS）窗口推理。我们比较了不同的SSGD算法在两个广泛使用的CTS数据集CALLHOME和Fisher语料库（第1和2部分）上的性能，并评估了分离和发言者分离的性能。为了提高性能，我们提出了一种新型、因果和计算效率高的泄漏去除算法。

    Recent works show that speech separation guided diarization (SSGD) is an increasingly promising direction, mainly thanks to the recent progress in speech separation. It performs diarization by first separating the speakers and then applying voice activity detection (VAD) on each separated stream. In this work we conduct an in-depth study of SSGD in the conversational telephone speech (CTS) domain, focusing mainly on low-latency streaming diarization applications. We consider three state-of-the-art speech separation (SSep) algorithms and study their performance both in online and offline scenarios, considering non-causal and causal implementations as well as continuous SSep (CSS) windowed inference. We compare different SSGD algorithms on two widely used CTS datasets: CALLHOME and Fisher Corpus (Part 1 and 2) and evaluate both separation and diarization performance. To improve performance, a novel, causal and computationally efficient leakage removal algorithm is proposed, which signifi
    
[^29]: 通过状态空间划分实现目标导向的离线强化学习

    Goal-conditioned Offline Reinforcement Learning through State Space Partitioning. (arXiv:2303.09367v1 [cs.LG])

    [http://arxiv.org/abs/2303.09367](http://arxiv.org/abs/2303.09367)

    本文提出了一种通过状态空间划分实现目标导向的离线强化学习方法，并采用补充的优势加权方案，以解决分布转移和多模式问题。

    

    离线强化学习旨在仅使用离线数据集来推断出顺序决策策略。本文提出了一种想要学习实现多个不同目标或结果的目标导向决策策略的方法。为了解决分布转移和多模式问题，我们提出了一种补充的优势加权方案。

    Offline reinforcement learning (RL) aims to infer sequential decision policies using only offline datasets. This is a particularly difficult setup, especially when learning to achieve multiple different goals or outcomes under a given scenario with only sparse rewards. For offline learning of goal-conditioned policies via supervised learning, previous work has shown that an advantage weighted log-likelihood loss guarantees monotonic policy improvement. In this work we argue that, despite its benefits, this approach is still insufficient to fully address the distribution shift and multi-modality problems. The latter is particularly severe in long-horizon tasks where finding a unique and optimal policy that goes from a state to the desired goal is challenging as there may be multiple and potentially conflicting solutions. To tackle these challenges, we propose a complementary advantage-based weighting scheme that introduces an additional source of inductive bias: given a value-based part
    
[^30]: 统一悲观风险和最优组合

    Uniform Pessimistic Risk and Optimal Portfolio. (arXiv:2303.07158v1 [q-fin.PM])

    [http://arxiv.org/abs/2303.07158](http://arxiv.org/abs/2303.07158)

    本文提出了一种称为统一悲观风险的综合$\alpha$-风险版本和基于风险获得最优组合的计算算法，该方法可以用于估计韩国股票的悲观最优组合模型。

    This paper proposes a version of integrated $\alpha$-risk called the uniform pessimistic risk and a computational algorithm to obtain an optimal portfolio based on the risk. The proposed method can be used to estimate the pessimistic optimal portfolio models for Korean stocks.

    资产配置的最优性已经在风险度量的理论分析中得到广泛讨论。悲观主义是一种超越传统最优组合模型的最有吸引力的方法之一，$\alpha$-风险在推导出广泛的悲观最优组合中起着关键作用。然而，由悲观风险评估的最优组合的估计仍然具有挑战性，因为缺乏可用的估计模型和计算算法。在本研究中，我们提出了一种称为统一悲观风险的综合$\alpha$-风险版本和基于风险获得最优组合的计算算法。此外，我们从多个分位数回归、适当的评分规则和分布鲁棒优化三个不同的方法来研究所提出的风险的理论性质。同时，统一悲观风险被应用于估计韩国股票的悲观最优组合模型。

    The optimality of allocating assets has been widely discussed with the theoretical analysis of risk measures. Pessimism is one of the most attractive approaches beyond the conventional optimal portfolio model, and the $\alpha$-risk plays a crucial role in deriving a broad class of pessimistic optimal portfolios. However, estimating an optimal portfolio assessed by a pessimistic risk is still challenging due to the absence of an available estimation model and a computational algorithm. In this study, we propose a version of integrated $\alpha$-risk called the uniform pessimistic risk and the computational algorithm to obtain an optimal portfolio based on the risk. Further, we investigate the theoretical properties of the proposed risk in view of three different approaches: multiple quantile regression, the proper scoring rule, and distributionally robust optimization. Also, the uniform pessimistic risk is applied to estimate the pessimistic optimal portfolio models for the Korean stock 
    
[^31]: CaloFlow用于CaloChallenge数据集1的新方法

    CaloFlow for CaloChallenge Dataset 1. (arXiv:2210.14245v2 [physics.ins-det] UPDATED)

    [http://arxiv.org/abs/2210.14245](http://arxiv.org/abs/2210.14245)

    CaloFlow是一种新的、有前景的快速量能器模拟方法，可以比Geant4快几个数量级生成高保真度的样本。使用量能器图片、直方图和分类器证明了其样本的保真度。

    

    CaloFlow是一种基于归一化流的快速量能器模拟的新方法。将CaloFlow应用于Fast Calorimeter Simulation Challenge 2022的光子和带电π介子Geant4 shower的Dataset 1，我们展示它可以比Geant4快几个数量级产生高保真度的样本。我们使用量能器shower图像、高级特征的直方图以及分类器将CaloFlow与Geant4样本区分开来来证明样本的保真度。

    CaloFlow is a new and promising approach to fast calorimeter simulation based on normalizing flows. Applying CaloFlow to the photon and charged pion Geant4 showers of Dataset 1 of the Fast Calorimeter Simulation Challenge 2022, we show how it can produce high-fidelity samples with a sampling time that is several orders of magnitude faster than Geant4. We demonstrate the fidelity of the samples using calorimeter shower images, histograms of high-level features, and aggregate metrics such as a classifier trained to distinguish CaloFlow from Geant4 samples.
    

