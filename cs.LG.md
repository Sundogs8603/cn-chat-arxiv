# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Harnessing machine learning for accurate treatment of overlapping opacity species in GCMs.](http://arxiv.org/abs/2311.00775) | 本论文基于机器学习提出了一种快速且准确的方法来处理GCM中重叠的透明度物种，通过有效地结合各个相关-k透明度表（k-tables），该方法在热木星HD~209458 b的模拟中表现出了精确性和高效性。 |
| [^2] | [From External to Swap Regret 2.0: An Efficient Reduction and Oblivious Adversary for Large Action Spaces.](http://arxiv.org/abs/2310.19786) | 通过新的约化方法，我们改进了经典的Swap遗憾最小化算法，并提供了一个无外部遗憾算法的替代方法。对于学习专家建议问题，我们的算法可以在较少的轮数和更低的复杂度下达到相同的Swap遗憾限制。 |
| [^3] | [Cross-feature Contrastive Loss for Decentralized Deep Learning on Heterogeneous Data.](http://arxiv.org/abs/2310.15890) | 本文提出了一种用于异构数据的分散式学习方法，通过跨特征对比损失实现数据无关知识蒸馏，实验结果表明该方法在各种计算机视觉任务上取得了优越性能。 |
| [^4] | [A Hyperparameter Study for Quantum Kernel Methods.](http://arxiv.org/abs/2310.11891) | 本研究调查了超参数选择对模型性能和经典核与量子核之间的泛化差距的影响。 |
| [^5] | [Zipformer: A faster and better encoder for automatic speech recognition.](http://arxiv.org/abs/2310.11230) | Zipformer是一种更快速、更节省内存、性能更好的自动语音识别编码器，通过U-Net-like编码器结构、重新组织的块结构、改进的LayerNorm、新的激活函数和新的优化器等方式实现了优化。实验证明它在LibriSpeech、Aishell-1和Wenet等数据集上表现出更快的收敛和更好的性能。 |
| [^6] | [Visual Data-Type Understanding does not emerge from Scaling Vision-Language Models.](http://arxiv.org/abs/2310.08577) | 本文研究了视觉语言模型对视觉数据类型的理解能力，发现虽然在某些样式化数据类型上表现良好，但在基本操作引起的简单数据类型上表现困难。 |
| [^7] | [Banach Space Optimality of Neural Architectures With Multivariate Nonlinearities.](http://arxiv.org/abs/2310.03696) | 本文研究了具有多变量非线性激活函数的神经网络架构在Banach空间的优化性，并构建了一类新的Banach空间家族。结果表明，学习问题的解集完全由具有多变量非线性的神经网络架构来描述。这些最优架构具有跳跃连接，并与正交权重归一化和多索引模型密切相关。 |
| [^8] | [Point-PEFT: Parameter-Efficient Fine-Tuning for 3D Pre-trained Models.](http://arxiv.org/abs/2310.03059) | Point-PEFT是一种用于3D预训练模型的参数高效微调框架，它通过冻结大部分参数，只微调新增的PEFT模块，包括Point-prior Prompt和Geometry-aware Adapter，以最小化学习参数，并利用内存库和准确的聚合方法来提高模型性能。 |
| [^9] | [In-Context Learning for Text Classification with Many Labels.](http://arxiv.org/abs/2309.10954) | 本文通过使用预训练的密集检索模型，解决了上下文学习中的标签限制问题，并在多个意图分类数据集的少样本设置中取得了新的最佳性能，同时在某些情况下超越了微调模型的表现。研究还发现，更大规模的模型对于有效利用更长的上下文长度进行上下文学习是必要的。 |
| [^10] | [An Automated Machine Learning Approach for Detecting Anomalous Peak Patterns in Time Series Data from a Research Watershed in the Northeastern United States Critical Zone.](http://arxiv.org/abs/2309.07992) | 本文提出了一个自动化机器学习框架，用于检测美国东北地区临界地带研究流域传感器生成的时间序列数据中的异常峰值模式。通过合成生成带有标记的数据集和自动超参数优化机制，该框架克服了标记数据和选择合适的深度学习模型的挑战。 |
| [^11] | [TpuGraphs: A Performance Prediction Dataset on Large Tensor Computational Graphs.](http://arxiv.org/abs/2308.13490) | TpuGraphs是一种关于大型张量计算图的性能预测数据集，可用于优化编译器或自动调优工具的决策，并提供了图的执行时间信息。 |
| [^12] | [zkDL: Efficient Zero-Knowledge Proofs of Deep Learning Training.](http://arxiv.org/abs/2307.16273) | zkDL是一种高效的深度学习训练零知识证明，通过zkReLU协议和新颖的算术电路构建方案，实现了对深度网络训练过程的有效验证。 |
| [^13] | [Towards Ordinal Data Science.](http://arxiv.org/abs/2307.09477) | 本文讨论了序列数据科学的发展，并介绍了一种新的研究议程：使用序列结构来衡量和计算对象之间的关系，并从中推断知识。这种方法具有广泛的学科应用价值。 |
| [^14] | [Divide, Evaluate, and Refine: Evaluating and Improving Text-to-Image Alignment with Iterative VQA Feedback.](http://arxiv.org/abs/2307.04749) | 本文提出了一种划分、评估和细化的方法来改善文本到图像对齐。通过分解复杂的提示并使用VQA模型进行测量，最终得到文本到图像的对齐分数。 |
| [^15] | [Dynamic Graph Attention for Anomaly Detection in Heterogeneous Sensor Networks.](http://arxiv.org/abs/2307.03761) | 该论文提出了一种基于图的方法，命名为DyGATAD，用于在异构传感器网络中进行异常检测。该方法利用动态图注意力机制来识别集体异常行为，其中异常行为可能由于系统内部相互关系的变化引起。这在工业物联网监控系统中具有重要的实际应用价值。 |
| [^16] | [Time Regularization in Optimal Time Variable Learning.](http://arxiv.org/abs/2306.16111) | 本文研究了时间正则化在最优时间变量学习中的应用，通过引入一个与离散动力系统中的时间范围直接相关的正则化项，并提出了一种适应性剪枝方法用于减少网络复杂性和训练时间，同时保持表达能力。在MNIST和Fashion MNIST数据集上的分类任务上验证了方法的有效性。 |
| [^17] | [A General Framework for Sequential Decision-Making under Adaptivity Constraints.](http://arxiv.org/abs/2306.14468) | 本论文提出了一个通用框架，研究了在适应性约束下的顺序决策问题。具体地，我们提供了Eluder Condition类，并针对稀缺策略切换和批次学习约束分别提供了相应的算法。此工作是第一个考虑通用函数类别下稀缺策略切换和批次学习的工作，涵盖了之前研究中的大部分模型。 |
| [^18] | [Adaptive Privacy Composition for Accuracy-first Mechanisms.](http://arxiv.org/abs/2306.13824) | 本文提出了一种自适应隐私组合的框架，将噪声减少机制与事前隐私机制结合使用以同时实现高精度和隐私。 |
| [^19] | [Precise Asymptotic Generalization for Multiclass Classification with Overparameterized Linear Models.](http://arxiv.org/abs/2306.13255) | 本文研究了高斯协变量下的过参数化线性模型在多类分类问题中的泛化能力，成功解决了之前的猜想，并提出的新下界具有信息论中的强对偶定理的性质。 |
| [^20] | [Why Using Either Aggregated Features or Adjacency Lists in Directed or Undirected Graph? Empirical Study and Simple Classification Method.](http://arxiv.org/abs/2306.08274) | 本文实证研究了在节点分类任务中使用聚合特征或邻接表以及边方向对分类效果的影响，并提出了一个简单全面的分类方法A2DUG，该方法利用了有向和无向图中节点表示变量的所有组合，其在各种数据集上稳定表现良好，并在几个数据集上优于当前的最先进方法。 |
| [^21] | [Publicly available datasets of breast histopathology H&E whole-slide images: A systematic review.](http://arxiv.org/abs/2306.01546) | 本文从乳腺H&E染色全切片图像数据集的公开来源出发，系统性地综述了当前可用的数据集情况，包含了12个公开数据集和相关特征信息。总结出数据集的缺失以及更全面和标准化的数据集建立的必要性。 |
| [^22] | [Feature-Learning Networks Are Consistent Across Widths At Realistic Scales.](http://arxiv.org/abs/2305.18411) | 本研究发现宽度对于神经网络的动态没有影响，网络在早期训练中表现出一致性，对于简单任务来说这一一致性贯穿整个训练过程，且大宽度下的结构特性是一致的。这表明特征学习极限可以捕捉到现实模型中出现的现象。 |
| [^23] | [Functional Flow Matching.](http://arxiv.org/abs/2305.17209) | 本文介绍了一种名为功能流匹配（FFM）的函数空间生成模型，该模型利用概率测度插值和学习底层函数空间上生成测度的向量场来生成数据分布。这种无需似然或模拟的方法在合成和真实世界基准数据集上表现优异，优于最近提出的几种函数空间生成模型。 |
| [^24] | [Deep Equivariant Hyperspheres.](http://arxiv.org/abs/2305.15613) | 本文提出了深度等变超球体的理论模型，解决了几何深度学习中等变和几何变换下不变的重大问题。 |
| [^25] | [AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback.](http://arxiv.org/abs/2305.14387) | 该论文提出了一种名为AlpacaFarm的低成本模拟器，该模拟器为从人类反馈中学习的研究和开发提供了一种解决方案，通过设计LLM提示来模拟人类反馈，提出自动评估并提供参考实现，克服了数据收集的高昂成本、缺乏可信的评估和缺乏参考方法实现的挑战。 |
| [^26] | [Improved Convergence of Score-Based Diffusion Models via Prediction-Correction.](http://arxiv.org/abs/2305.14164) | 本文通过使用预测校正方案，提高了基于得分扩散模型的收敛性。 |
| [^27] | [A unified framework for information-theoretic generalization bounds.](http://arxiv.org/abs/2305.11042) | 该论文提出了一种基于概率去相关引理和概率测度空间中一些其他技术的通用方法，可以得到新的学习算法的信息论泛化上限，并且能够恢复许多现有的泛化界，如基于互信息、条件互信息、随机chaining和PAC-Bayes不等式的界。 |
| [^28] | [Autoencoders for discovering manifold dimension and coordinates in data from complex dynamical systems.](http://arxiv.org/abs/2305.01090) | 本文提出了一种自动编码器框架，结合implicit regularization，内部线性层和L2正则化（权重衰减）自动估计数据集的潜在维度，产生正交的流形坐标系，并提供环境空间和流形空间之间的映射函数，从而允许进行样本之外的投影。该方法在动力系统数据集中表现出了较好的低秩表示效果，为底层动态提供了物理洞见，并可以用于提高机器学习模型和控制策略的效果。 |
| [^29] | [Exploring the flavor structure of quarks and leptons with reinforcement learning.](http://arxiv.org/abs/2304.14176) | 通过利用强化学习，探索了具有 $U(1)$ 味道对称性的模型的味道结构，找到了21个与实验测量值一致的模型，预测了无中微子双贝塔衰变的有效质量和可观的轻子 CP 破坏。 |
| [^30] | [Model sparsification can simplify machine unlearning.](http://arxiv.org/abs/2304.04934) | 本文提出了一种基于模型稀疏化的机器反学习方案，称为prune first, then unlearn和sparsity-aware unlearning。此方案可以提高近似反学习器的多标准反学习性能，并在不同的场景中表现出一致的效果。 |
| [^31] | [Exploring Distributional Shifts in Large Language Models for Code Analysis.](http://arxiv.org/abs/2303.09128) | 研究了两种大型语言模型在代码分析中处理领域外数据的能力，提出了组织、项目和模块的自然边界分割方法，发现每个新领域的样本都会产生分布偏移的挑战，实现了多任务学习与少量微调相结合的解决方案。 |
| [^32] | [Causal Estimation of Exposure Shifts with Neural Networks: Evaluating the Health Benefits of Stricter Air Quality Standards in the US.](http://arxiv.org/abs/2302.02560) | 本研究提出了一种神经网络方法，利用其理论基础和实施的可行性，从而估计连续暴露/治疗的分布对政策相关结果的因果效应。我们将此方法应用于包含6800万个个体和2700万个美国境内死亡事件的数据中，通过评估美国国家环境保护局（EPA）对PM2.5的国家环境空气质量标准（NAAQS）进行修订后的健康效益。 |
| [^33] | [CD-GraB: Coordinating Distributed Example Orders for Provably Accelerated Training.](http://arxiv.org/abs/2302.00845) | 该论文提出了一种名为CD-GraB的算法，可以协调分布式示例顺序以加速机器学习训练。CD-GraB展现出线性加速收敛速率并且在基准任务上优于其他基线方法。 |
| [^34] | [An Approach for Noisy, Crowdsourced Datasets Utilizing Ensemble Modeling, Normalized Distributions of Annotations, and Entropic Measures of Uncertainty.](http://arxiv.org/abs/2210.16380) | 在众包图像数据集上的分类是具有挑战性的。本文提出了一种利用集合建模、注释的归一化分布和熵测量的方法，以帮助识别标签不确定的图像，并量化这些样本的可信度。 |
| [^35] | [Occam learning.](http://arxiv.org/abs/2210.13179) | 本文讨论了一种具有固定隐藏层分布的概率神经网络模型，该模型选择简单、易解释，不需要过度参数化，同时训练有效。模型的隐藏单元为二元变量时具有以特征为基础的自然解释。作者认为隐藏变量的分布应该遵循最大关联度原则，并介绍了分层特征模型（HFM）作为满足这一原则并对特征空间进行中性先验组织的模型。 |
| [^36] | [Targeted Separation and Convergence with Kernel Discrepancies.](http://arxiv.org/abs/2209.12835) | 通过核差异度量，我们推导出了新的充分必要条件，实现了将目标分离出来，以及控制对目标的弱收敛性。此外，我们在$\mathbb{R}^d$上使用了这些结果来扩展了核Stein差异分离和收敛控制的已知条件，并开发了能够精确度量目标的弱收敛性的核差异度量。 |
| [^37] | [Quantifying Spatial Under-reporting Disparities in Resident Crowdsourcing.](http://arxiv.org/abs/2204.08620) | 本文研究了城市治理中居民众包的问题，并提出了一种准确测量报道率的方法，使不同的报道率不再成为城市治理下游解决事件速度方面的不公平根源。 |
| [^38] | [Model Reprogramming: Resource-Efficient Cross-Domain Machine Learning.](http://arxiv.org/abs/2202.10629) | 模型重新编程是一种资源高效的跨领域机器学习方法，通过重新利用和重用预训练模型，无需模型细调即可在目标领域解决任务。这种方法在许多应用中优于迁移学习和从头训练。 |
| [^39] | [Optimal Variable Clustering for High-Dimensional Matrix Valued Data.](http://arxiv.org/abs/2112.12909) | 提出了一种新的针对高维矩阵数据的特征潜变量模型，使用加权协方差矩阵的差异作为不相似度测量的层次聚类算法，理论上实现了聚类一致性，在模拟和真实数据示例中证明了方法的优越性。 |

# 详细

[^1]: 利用机器学习来准确处理GCM中重叠透明度物种的论文

    Harnessing machine learning for accurate treatment of overlapping opacity species in GCMs. (arXiv:2311.00775v1 [astro-ph.EP])

    [http://arxiv.org/abs/2311.00775](http://arxiv.org/abs/2311.00775)

    本论文基于机器学习提出了一种快速且准确的方法来处理GCM中重叠的透明度物种，通过有效地结合各个相关-k透明度表（k-tables），该方法在热木星HD~209458 b的模拟中表现出了精确性和高效性。

    

    为了理解外行星和棕矮星的高精度观测结果，我们需要详细和复杂的涵盖了流体力学、化学和辐射的通用环流模型（GCMs）。本研究具体考察了GCMs中化学和辐射之间的耦合关系，并比较了在相关-k假设中混合不同化学物种透明度的不同方法，在不能假设平衡化学反应的情况下。我们提出了一种基于DeepSets（DS）的快速机器学习方法，有效地结合了各个相关-k透明度表（k-tables）。我们将DS方法与其他已发表的方法如自适应等价消光（AEE）和带有重新分组和排序的随机重叠（RORR）进行了评估。我们将这些混合方法整合到了我们的GCM (expeRT/MITgcm)中，并对热木星HD~209458 b进行了准确性和性能评估。我们的研究结果表明，DS方法在GCM使用时既准确又高效，而RORR方法则不然。

    To understand high precision observations of exoplanets and brown dwarfs, we need detailed and complex general circulation models (GCMs) that incorporate hydrodynamics, chemistry, and radiation. In this study, we specifically examine the coupling between chemistry and radiation in GCMs and compare different methods for mixing opacities of different chemical species in the correlated-k assumption, when equilibrium chemistry cannot be assumed. We propose a fast machine learning method based on DeepSets (DS), which effectively combines individual correlated-k opacities (k-tables). We evaluate the DS method alongside other published methods like adaptive equivalent extinction (AEE) and random overlap with rebinning and resorting (RORR). We integrate these mixing methods into our GCM (expeRT/MITgcm) and assess their accuracy and performance for the example of the hot Jupiter HD~209458 b. Our findings indicate that the DS method is both accurate and efficient for GCM usage, whereas RORR is t
    
[^2]: 从外部到Swap遗憾2.0：针对大动作空间的高效约化和无知对手

    From External to Swap Regret 2.0: An Efficient Reduction and Oblivious Adversary for Large Action Spaces. (arXiv:2310.19786v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.19786](http://arxiv.org/abs/2310.19786)

    通过新的约化方法，我们改进了经典的Swap遗憾最小化算法，并提供了一个无外部遗憾算法的替代方法。对于学习专家建议问题，我们的算法可以在较少的轮数和更低的复杂度下达到相同的Swap遗憾限制。

    

    我们提供了一种新颖的从Swap遗憾最小化到外部遗憾最小化的约化方法，改进了Blum-Mansour和Stolz-Lugosi的经典约化方法，不需要行为空间的有限性。我们证明，只要存在某个假设类的无外部遗憾算法，就必然存在相同类别的无Swap遗憾算法。对于学习专家建议问题，我们的结果意味着可以保证在$\log(N)^{O(1/\epsilon)}$轮后，每次迭代复杂度为$O(N)$的情况下，Swap遗憾被限定为$\epsilon$，而Blum-Mansour和Stolz-Lugosi的经典约化方法需要$O(N/\epsilon^2)$轮和至少$\Omega(N^2)$的每次迭代复杂度。我们的结果伴随着一个相关的下界，与[BM07]不同，这个下界适用于无知和$\ell_1$-受限的对手和可以利用这个下界的学习者。

    We provide a novel reduction from swap-regret minimization to external-regret minimization, which improves upon the classical reductions of Blum-Mansour [BM07] and Stolz-Lugosi [SL05] in that it does not require finiteness of the space of actions. We show that, whenever there exists a no-external-regret algorithm for some hypothesis class, there must also exist a no-swap-regret algorithm for that same class. For the problem of learning with expert advice, our result implies that it is possible to guarantee that the swap regret is bounded by {\epsilon} after $\log(N)^{O(1/\epsilon)}$ rounds and with $O(N)$ per iteration complexity, where $N$ is the number of experts, while the classical reductions of Blum-Mansour and Stolz-Lugosi require $O(N/\epsilon^2)$ rounds and at least $\Omega(N^2)$ per iteration complexity. Our result comes with an associated lower bound, which -- in contrast to that in [BM07] -- holds for oblivious and $\ell_1$-constrained adversaries and learners that can emplo
    
[^3]: 跨特征对比损失用于异构数据的分散式深度学习

    Cross-feature Contrastive Loss for Decentralized Deep Learning on Heterogeneous Data. (arXiv:2310.15890v1 [cs.LG])

    [http://arxiv.org/abs/2310.15890](http://arxiv.org/abs/2310.15890)

    本文提出了一种用于异构数据的分散式学习方法，通过跨特征对比损失实现数据无关知识蒸馏，实验结果表明该方法在各种计算机视觉任务上取得了优越性能。

    

    当前最先进的分散式学习算法大多数假设数据分布是独立同分布（IID）。然而，在实际场景中，分散式数据集在代理之间可以具有显著的异构数据分布。在这项工作中，我们提出了一种新颖的针对异构数据的分散式学习方法，通过交叉特征上的无数据知识蒸馏和对比损失来提高性能。对于一对相邻代理，跨特征是从一个代理的数据获取的特征（即最后一个隐藏层的激活）关于另一个代理的模型参数。我们通过一系列详尽的实验在各种计算机视觉数据集（CIFAR-10、CIFAR-100、Fashion MNIST 和 ImageNet）、模型架构和网络拓扑上展示了所提出技术的有效性。我们的实验结果表明，所提出的方法在性能上取得了更好的表现。

    The current state-of-the-art decentralized learning algorithms mostly assume the data distribution to be Independent and Identically Distributed (IID). However, in practical scenarios, the distributed datasets can have significantly heterogeneous data distributions across the agents. In this work, we present a novel approach for decentralized learning on heterogeneous data, where data-free knowledge distillation through contrastive loss on cross-features is utilized to improve performance. Cross-features for a pair of neighboring agents are the features (i.e., last hidden layer activations) obtained from the data of an agent with respect to the model parameters of the other agent. We demonstrate the effectiveness of the proposed technique through an exhaustive set of experiments on various Computer Vision datasets (CIFAR-10, CIFAR-100, Fashion MNIST, and ImageNet), model architectures, and network topologies. Our experiments show that the proposed method achieves superior performance (
    
[^4]: 量子核方法的超参数研究

    A Hyperparameter Study for Quantum Kernel Methods. (arXiv:2310.11891v1 [quant-ph])

    [http://arxiv.org/abs/2310.11891](http://arxiv.org/abs/2310.11891)

    本研究调查了超参数选择对模型性能和经典核与量子核之间的泛化差距的影响。

    

    量子核方法在量子机器学习中具有潜力，因为与之相关的保证。它们的可访问性也打开了基于潜在量子优势对数据集进行预先筛选的可能性。为了做到这一点，早期的研究开发了几何差异，它可以被理解为两种基于核的机器学习方法之间的接近度度量，特别是量子核和经典核之间的接近度。该度量指示了量子和经典模型的复杂性之间的联系。因此，它引发了一个问题，即基于与模型复杂性的关系，几何差异是否可以成为除了潜在的量子优势之外的评估工具。在这项工作中，我们研究了超参数选择对模型性能和经典核与量子核之间的泛化差距的影响。对于经典的机器学习方法来说，超参数优化的重要性是众所周知的。

    Quantum kernel methods are a promising method in quantum machine learning thanks to the guarantees connected to them. Their accessibility for analytic considerations also opens up the possibility of prescreening datasets based on their potential for a quantum advantage. To do so, earlier works developed the geometric difference, which can be understood as a closeness measure between two kernel-based machine learning approaches, most importantly between a quantum kernel and classical kernel. This metric links the quantum and classical model complexities. Therefore, it raises the question of whether the geometric difference, based on its relation to model complexity, can be a useful tool in evaluations other than for the potential for quantum advantage. In this work, we investigate the effects of hyperparameter choice on the model performance and the generalization gap between classical and quantum kernels. The importance of hyperparameter optimization is well known also for classical ma
    
[^5]: Zipformer：一种更快速、更好的自动语音识别编码器

    Zipformer: A faster and better encoder for automatic speech recognition. (arXiv:2310.11230v1 [eess.AS])

    [http://arxiv.org/abs/2310.11230](http://arxiv.org/abs/2310.11230)

    Zipformer是一种更快速、更节省内存、性能更好的自动语音识别编码器，通过U-Net-like编码器结构、重新组织的块结构、改进的LayerNorm、新的激活函数和新的优化器等方式实现了优化。实验证明它在LibriSpeech、Aishell-1和Wenet等数据集上表现出更快的收敛和更好的性能。

    

    Conformer已成为自动语音识别（ASR）中最流行的编码器模型。它在变换器中加入了卷积模块以学习局部和全局依赖关系。本文介绍了一种更快速、更节省内存、性能更好的变换器——Zipformer。建模改变包括：1）类似U-Net的编码器结构，中间堆栈在较低的帧率下运行；2）重新组织的块结构，增加了更多的模块，其中我们重复使用注意力权重以提高效率；3）一种改进的LayerNorm形式，称为BiasNorm，允许我们保留一些长度信息；4）新的激活函数SwooshR和SwooshL的性能优于Swish。我们还提出了一种新的优化器，称为ScaledAdam，它通过当前张量的规模来缩放更新，以保持相对变化大致相同，并明确学习参数规模。与Adam相比，它实现了更快的收敛和更好的性能。在LibriSpeech、Aishell-1和Wenet上进行了大量实验。

    The Conformer has become the most popular encoder model for automatic speech recognition (ASR). It adds convolution modules to a transformer to learn both local and global dependencies. In this work we describe a faster, more memory-efficient, and better-performing transformer, called Zipformer. Modeling changes include: 1) a U-Net-like encoder structure where middle stacks operate at lower frame rates; 2) reorganized block structure with more modules, within which we re-use attention weights for efficiency; 3) a modified form of LayerNorm called BiasNorm allows us to retain some length information; 4) new activation functions SwooshR and SwooshL work better than Swish. We also propose a new optimizer, called ScaledAdam, which scales the update by each tensor's current scale to keep the relative change about the same, and also explictly learns the parameter scale. It achieves faster convergence and better performance than Adam. Extensive experiments on LibriSpeech, Aishell-1, and Wenet
    
[^6]: 视觉数据类型理解并非源自扩展视觉语言模型

    Visual Data-Type Understanding does not emerge from Scaling Vision-Language Models. (arXiv:2310.08577v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2310.08577](http://arxiv.org/abs/2310.08577)

    本文研究了视觉语言模型对视觉数据类型的理解能力，发现虽然在某些样式化数据类型上表现良好，但在基本操作引起的简单数据类型上表现困难。

    

    最近对视觉语言模型（VLMs）的发展取得了显著进展，取得了较好的视觉语义内容识别效果，包括出色的复合图像理解实例。本文介绍了一项新的任务，即视觉数据类型识别，这是一项基本的感知技能，对数据整理（例如从大型数据集中去除噪声数据，领域特定的检索）和自主视觉（例如区分不同的天气变化和相机镜头污染）具有重要意义。我们构建了两个数据集，其中包含经过27种视觉数据类型的动物图像的修改，涵盖了四个广泛的类别。对39个参数范围从100M到80B的VLMs进行了广泛的零样本评估，结果显示了一个细致的性能景观。虽然VLMs在识别某些样式化的数据类型（例如卡通和草图）方面表现良好，但在基本操作（例如图像旋转或添加噪声）引起的简单数据类型上表现出困难。

    Recent advances in the development of vision-language models (VLMs) are yielding remarkable success in recognizing visual semantic content, including impressive instances of compositional image understanding. Here, we introduce the novel task of Visual Data-Type Identification, a basic perceptual skill with implications for data curation (e.g., noisy data-removal from large datasets, domain-specific retrieval) and autonomous vision (e.g., distinguishing changing weather conditions from camera lens staining). We develop two datasets consisting of animal images altered across a diverse set of 27 visual data-types, spanning four broad categories. An extensive zero-shot evaluation of 39 VLMs, ranging from 100M to 80B parameters, shows a nuanced performance landscape. While VLMs are reasonably good at identifying certain stylistic \textit{data-types}, such as cartoons and sketches, they struggle with simpler data-types arising from basic manipulations like image rotations or additive noise.
    
[^7]: 具有多变量非线性的神经网络架构的Banach空间优化性研究

    Banach Space Optimality of Neural Architectures With Multivariate Nonlinearities. (arXiv:2310.03696v1 [stat.ML])

    [http://arxiv.org/abs/2310.03696](http://arxiv.org/abs/2310.03696)

    本文研究了具有多变量非线性激活函数的神经网络架构在Banach空间的优化性，并构建了一类新的Banach空间家族。结果表明，学习问题的解集完全由具有多变量非线性的神经网络架构来描述。这些最优架构具有跳跃连接，并与正交权重归一化和多索引模型密切相关。

    

    本文研究了一大类具有多变量非线性/激活函数的神经网络架构的变分优化性（具体而言，是Banach空间优化性）。为此，我们通过正则化算子和k-平面变换构建了一类新的Banach空间家族。我们证明了一个表示定理，该定理说明在这些Banach空间上提出的学习问题的解集完全由具有多变量非线性的神经网络架构来描述。这些最优的架构具有跳跃连接，并与正交权重归一化和多索引模型息息相关，这两个模型在神经网络界引起了相当大的兴趣。我们的框架适用于包括修正线性单元（ReLU）激活函数、范数激活函数以及在薄板/多次谐波样条理论中找到的径向基函数在内的多种经典非线性函数。

    We investigate the variational optimality (specifically, the Banach space optimality) of a large class of neural architectures with multivariate nonlinearities/activation functions. To that end, we construct a new family of Banach spaces defined via a regularization operator and the $k$-plane transform. We prove a representer theorem that states that the solution sets to learning problems posed over these Banach spaces are completely characterized by neural architectures with multivariate nonlinearities. These optimal architectures have skip connections and are tightly connected to orthogonal weight normalization and multi-index models, both of which have received considerable interest in the neural network community. Our framework is compatible with a number of classical nonlinearities including the rectified linear unit (ReLU) activation function, the norm activation function, and the radial basis functions found in the theory of thin-plate/polyharmonic splines. We also show that the
    
[^8]: Point-PEFT: 用于3D预训练模型的参数高效微调

    Point-PEFT: Parameter-Efficient Fine-Tuning for 3D Pre-trained Models. (arXiv:2310.03059v1 [cs.CV])

    [http://arxiv.org/abs/2310.03059](http://arxiv.org/abs/2310.03059)

    Point-PEFT是一种用于3D预训练模型的参数高效微调框架，它通过冻结大部分参数，只微调新增的PEFT模块，包括Point-prior Prompt和Geometry-aware Adapter，以最小化学习参数，并利用内存库和准确的聚合方法来提高模型性能。

    

    大型预训练模型的流行已经彻底改变了语言、视觉和多模态等领域的下游任务。为了降低下游任务的适应成本，许多参数高效微调（PEFT）技术被提出用于语言和2D图像预训练模型。然而，对于3D预训练模型的专门PEFT方法仍未得到充分探索。为此，我们引入了Point-PEFT，一种用于适应点云预训练模型的新型框架，其具有最少的可学习参数。具体而言，对于预训练的3D模型，我们冻结大部分参数，只微调新增的PEFT模块。这些模块包括Point-prior Prompt和Geometry-aware Adapter。Point-prior Prompt采用一组可学习的提示标记，并提出使用具有领域特定知识的内存库来增强提示标记的参数无关的注意力机制。Geometry-aware Adapter旨在对不同任务或数据进行准确地聚合。

    The popularity of pre-trained large models has revolutionized downstream tasks across diverse fields, such as language, vision, and multi-modality. To minimize the adaption cost for downstream tasks, many Parameter-Efficient Fine-Tuning (PEFT) techniques are proposed for language and 2D image pre-trained models. However, the specialized PEFT method for 3D pre-trained models is still under-explored. To this end, we introduce Point-PEFT, a novel framework for adapting point cloud pre-trained models with minimal learnable parameters. Specifically, for a pre-trained 3D model, we freeze most of its parameters, and only tune the newly added PEFT modules on downstream tasks, which consist of a Point-prior Prompt and a Geometry-aware Adapter. The Point-prior Prompt adopts a set of learnable prompt tokens, for which we propose to construct a memory bank with domain-specific knowledge, and utilize a parameter-free attention to enhance the prompt tokens. The Geometry-aware Adapter aims to aggrega
    
[^9]: 带有多个标签的文本分类中的上下文学习

    In-Context Learning for Text Classification with Many Labels. (arXiv:2309.10954v1 [cs.CL])

    [http://arxiv.org/abs/2309.10954](http://arxiv.org/abs/2309.10954)

    本文通过使用预训练的密集检索模型，解决了上下文学习中的标签限制问题，并在多个意图分类数据集的少样本设置中取得了新的最佳性能，同时在某些情况下超越了微调模型的表现。研究还发现，更大规模的模型对于有效利用更长的上下文长度进行上下文学习是必要的。

    

    使用大型语言模型进行具有许多标签的任务的上下文学习是具有挑战性的，因为有限的上下文窗口使得在提示中难以适应足够数量的示例。在本文中，我们使用预训练的密集检索模型绕过了这个限制，每次推理调用只给模型提供了对完整标签空间的部分视图。在最近的开源语言模型(OPT, LLaMA)上进行测试，我们在三个常见的意图分类数据集的少样本设置中，无需微调即取得了最新的最佳性能。在某些情况下，我们还超越了微调性能在细粒度情感分类上的表现。我们分析了不同数量的上下文示例以及不同模型规模下的性能，表明更大规模的模型对于有效而一致地利用更长的上下文长度进行上下文学习是必要的。通过运行几个消融实验，我们分析了模型对以下内容的使用：a)上下文示例与当前输入的相似度, b) 即时查询语句的相似度。

    In-context learning (ICL) using large language models for tasks with many labels is challenging due to the limited context window, which makes it difficult to fit a sufficient number of examples in the prompt. In this paper, we use a pre-trained dense retrieval model to bypass this limitation, giving the model only a partial view of the full label space for each inference call. Testing with recent open-source LLMs (OPT, LLaMA), we set new state of the art performance in few-shot settings for three common intent classification datasets, with no finetuning. We also surpass fine-tuned performance on fine-grained sentiment classification in certain cases. We analyze the performance across number of in-context examples and different model scales, showing that larger models are necessary to effectively and consistently make use of larger context lengths for ICL. By running several ablations, we analyze the model's use of: a) the similarity of the in-context examples to the current input, b) 
    
[^10]: 使用自动化机器学习方法检测美国东北地区临界地带内研究流域时间序列数据的异常峰行为

    An Automated Machine Learning Approach for Detecting Anomalous Peak Patterns in Time Series Data from a Research Watershed in the Northeastern United States Critical Zone. (arXiv:2309.07992v1 [cs.LG])

    [http://arxiv.org/abs/2309.07992](http://arxiv.org/abs/2309.07992)

    本文提出了一个自动化机器学习框架，用于检测美国东北地区临界地带研究流域传感器生成的时间序列数据中的异常峰值模式。通过合成生成带有标记的数据集和自动超参数优化机制，该框架克服了标记数据和选择合适的深度学习模型的挑战。

    

    本文提出了一种自动化机器学习框架，旨在帮助水文学家检测美国东北地区临界地带研究流域传感器生成的时间序列数据中的异常情况。该框架专注于识别峰值模式异常，这可能是由于传感器故障或自然现象引起的。然而，使用分类方法进行异常检测存在挑战，例如需要标记数据作为基准和选择最适合给定任务和数据集的深度学习模型。为了解决这些挑战，我们的框架通过将合成的峰值模式注入到合成生成的时间序列数据中生成带有标记的数据集，并结合自动化的超参数优化机制。该机制从五种选择的模型中生成一个具有最佳架构和训练参数的优化模型实例，即时序卷积网络（

    This paper presents an automated machine learning framework designed to assist hydrologists in detecting anomalies in time series data generated by sensors in a research watershed in the northeastern United States critical zone. The framework specifically focuses on identifying peak-pattern anomalies, which may arise from sensor malfunctions or natural phenomena. However, the use of classification methods for anomaly detection poses challenges, such as the requirement for labeled data as ground truth and the selection of the most suitable deep learning model for the given task and dataset. To address these challenges, our framework generates labeled datasets by injecting synthetic peak patterns into synthetically generated time series data and incorporates an automated hyperparameter optimization mechanism. This mechanism generates an optimized model instance with the best architectural and training parameters from a pool of five selected models, namely Temporal Convolutional Network (
    
[^11]: TpuGraphs:一种关于大型张量计算图的性能预测数据集

    TpuGraphs: A Performance Prediction Dataset on Large Tensor Computational Graphs. (arXiv:2308.13490v1 [cs.LG])

    [http://arxiv.org/abs/2308.13490](http://arxiv.org/abs/2308.13490)

    TpuGraphs是一种关于大型张量计算图的性能预测数据集，可用于优化编译器或自动调优工具的决策，并提供了图的执行时间信息。

    

    精确的硬件性能模型在代码优化中起着关键作用。它们可以帮助编译器做出启发性决策，或者帮助自动调优工具找到给定程序的最佳配置。本文介绍了TpuGraphs，一种在Tensor Processing Units（TPUs）上运行的全张量程序的性能预测数据集，这些程序以计算图的形式表示。数据集中的每个图表示机器学习工作负载的主要计算，例如训练周期或推断步骤。每个数据样本包含一个计算图、一个编译配置，以及使用该配置编译时图的执行时间。

    Precise hardware performance models play a crucial role in code optimizations. They can assist compilers in making heuristic decisions or aid autotuners in identifying the optimal configuration for a given program. For example, the autotuner for XLA, a machine learning compiler, discovered 10-20% speedup on state-of-the-art models serving substantial production traffic at Google. Although there exist a few datasets for program performance prediction, they target small sub-programs such as basic blocks or kernels. This paper introduces TpuGraphs, a performance prediction dataset on full tensor programs, represented as computational graphs, running on Tensor Processing Units (TPUs). Each graph in the dataset represents the main computation of a machine learning workload, e.g., a training epoch or an inference step. Each data sample contains a computational graph, a compilation configuration, and the execution time of the graph when compiled with the configuration. The graphs in the datas
    
[^12]: zkDL: 高效的深度学习训练零知识证明

    zkDL: Efficient Zero-Knowledge Proofs of Deep Learning Training. (arXiv:2307.16273v1 [cs.LG])

    [http://arxiv.org/abs/2307.16273](http://arxiv.org/abs/2307.16273)

    zkDL是一种高效的深度学习训练零知识证明，通过zkReLU协议和新颖的算术电路构建方案，实现了对深度网络训练过程的有效验证。

    

    深度学习的最新进展给人们的生活带来了重大变化。与此同时，这些快速发展引发了人们对深度网络训练过程的合法性的担忧。然而，为了保护不受信任的人工智能开发者的知识产权，通常禁止验证者通过访问模型参数和训练数据来直接检查训练过程。为了应对这个挑战，我们提出了zkDL，一种高效的深度学习训练零知识证明。zkDL的核心是zkReLU，一种专门针对ReLU激活函数的零知识证明协议，具有优化的证明时间和证明大小，这是可验证训练中的一个主要障碍，因为它的非算术性质。为了将zkReLU整合到整个训练过程的证明系统中，我们设计了一种新颖的从神经网络中构建算术电路的方法。通过利用丰富的并行计算资源，这个构建方案能够有效减少证明时间。

    The recent advancements in deep learning have brought about significant changes in various aspects of people's lives. Meanwhile, these rapid developments have raised concerns about the legitimacy of the training process of deep networks. However, to protect the intellectual properties of untrusted AI developers, directly examining the training process by accessing the model parameters and training data by verifiers is often prohibited.  In response to this challenge, we present zkDL, an efficient zero-knowledge proof of deep learning training. At the core of zkDL is zkReLU, a specialized zero-knowledge proof protocol with optimized proving time and proof size for the ReLU activation function, a major obstacle in verifiable training due to its non-arithmetic nature. To integrate zkReLU into the proof system for the entire training process, we devise a novel construction of an arithmetic circuit from neural networks. By leveraging the abundant parallel computation resources, this constru
    
[^13]: 进展中的序列数据科学

    Towards Ordinal Data Science. (arXiv:2307.09477v1 [cs.AI])

    [http://arxiv.org/abs/2307.09477](http://arxiv.org/abs/2307.09477)

    本文讨论了序列数据科学的发展，并介绍了一种新的研究议程：使用序列结构来衡量和计算对象之间的关系，并从中推断知识。这种方法具有广泛的学科应用价值。

    

    排序是衡量（经验）数据中对象之间关系的主要方法之一。然而，与使用对象的数字属性的方法相比，发展出的序列方法数量相对较少。造成这一情况的原因之一是在上个世纪，计算资源的可用性有限，无法满足序列计算所需。此外，对于这一研究领域来说，另一个重要原因是基于顺序的方法通常被视为对实际数据应用过于数学严谨。因此，本文将讨论不同的方法来衡量和“计算”序列结构（一类特定的有向图），并展示如何从其中推断知识。我们的目标是将序列数据科学建立为一项全新的研究议程。除了与其他重要的机器学习和知识表示方法的交叉互补外，广泛的学科领域也将受益于此。

    Order is one of the main instruments to measure the relationship between objects in (empirical) data. However, compared to methods that use numerical properties of objects, the amount of ordinal methods developed is rather small. One reason for this is the limited availability of computational resources in the last century that would have been required for ordinal computations. Another reason -- particularly important for this line of research -- is that order-based methods are often seen as too mathematically rigorous for applying them to real-world data. In this paper, we will therefore discuss different means for measuring and 'calculating' with ordinal structures -- a specific class of directed graphs -- and show how to infer knowledge from them. Our aim is to establish Ordinal Data Science as a fundamentally new research agenda. Besides cross-fertilization with other cornerstone machine learning and knowledge representation methods, a broad range of disciplines will benefit from t
    
[^14]: 划分、评估和细化：通过迭代VQA反馈评估和改善文本到图像对齐

    Divide, Evaluate, and Refine: Evaluating and Improving Text-to-Image Alignment with Iterative VQA Feedback. (arXiv:2307.04749v1 [cs.CV])

    [http://arxiv.org/abs/2307.04749](http://arxiv.org/abs/2307.04749)

    本文提出了一种划分、评估和细化的方法来改善文本到图像对齐。通过分解复杂的提示并使用VQA模型进行测量，最终得到文本到图像的对齐分数。

    

    随着潜在扩散模型的最新出现，以文本为条件的图像生成领域取得了前所未有的进展。然而，尽管具有显著性，但是随着文本输入的复杂性增加，最先进的扩散模型仍可能无法生成准确传达给定提示语义的图像。此外，观察到这种不对齐往往被预训练的多模型（如CLIP）未能检测到。为了解决这些问题，在本文中，我们探索了一种简单且有效的分解方法来评估和改善文本到图像对齐。具体而言，我们首先引入了一种分解对齐分数，它将复杂提示分解为一组不相交的断言。然后，使用VQA模型来测量每个断言与生成的图像的对齐情况。最后，将不同断言的对齐分数合并后，得到最终的文本到图像对齐分数。

    The field of text-conditioned image generation has made unparalleled progress with the recent advent of latent diffusion models. While remarkable, as the complexity of given text input increases, the state-of-the-art diffusion models may still fail in generating images which accurately convey the semantics of the given prompt. Furthermore, it has been observed that such misalignments are often left undetected by pretrained multi-modal models such as CLIP. To address these problems, in this paper we explore a simple yet effective decompositional approach towards both evaluation and improvement of text-to-image alignment. In particular, we first introduce a Decompositional-Alignment-Score which given a complex prompt decomposes it into a set of disjoint assertions. The alignment of each assertion with generated images is then measured using a VQA model. Finally, alignment scores for different assertions are combined aposteriori to give the final text-to-image alignment score. Experimenta
    
[^15]: 异构传感器网络中的异常检测的动态图注意力

    Dynamic Graph Attention for Anomaly Detection in Heterogeneous Sensor Networks. (arXiv:2307.03761v1 [cs.LG])

    [http://arxiv.org/abs/2307.03761](http://arxiv.org/abs/2307.03761)

    该论文提出了一种基于图的方法，命名为DyGATAD，用于在异构传感器网络中进行异常检测。该方法利用动态图注意力机制来识别集体异常行为，其中异常行为可能由于系统内部相互关系的变化引起。这在工业物联网监控系统中具有重要的实际应用价值。

    

    在数字化转型的时代，由工业物联网 (IIoT) 监控的系统通过异构传感器网络生成大量的多元时间序列 (MTS) 数据。虽然这些数据有助于条件监控和异常检测，但是传感器网络中日益复杂和相互依赖的关系也给异常检测带来了重大挑战。尽管在这个领域取得了一些进展，但主要集中在点异常和背景异常，对集体异常的关注较少。集体异常的一种常见变种是异常集体行为由系统内部的相互关系变化引起。这可能是由于异常环境条件（如过热）、由于网络攻击造成的不正确操作设置或系统级故障引起的。为了解决这些挑战，本文提出了 DyGATAD（一种动态图注意力的异常检测方法），采用基于图的方法来识别传感器网络中的异常行为。

    In the era of digital transformation, systems monitored by the Industrial Internet of Things (IIoTs) generate large amounts of Multivariate Time Series (MTS) data through heterogeneous sensor networks. While this data facilitates condition monitoring and anomaly detection, the increasing complexity and interdependencies within the sensor network pose significant challenges for anomaly detection. Despite progress in this field, much of the focus has been on point anomalies and contextual anomalies, with lesser attention paid to collective anomalies. A less addressed but common variant of collective anomalies is when the abnormal collective behavior is caused by shifts in interrelationships within the system. This can be due to abnormal environmental conditions like overheating, improper operational settings resulting from cyber-physical attacks, or system-level faults. To address these challenges, this paper proposes DyGATAD (Dynamic Graph Attention for Anomaly Detection), a graph-based
    
[^16]: 时间正则化在最优时间变量学习中的应用

    Time Regularization in Optimal Time Variable Learning. (arXiv:2306.16111v1 [cs.LG])

    [http://arxiv.org/abs/2306.16111](http://arxiv.org/abs/2306.16111)

    本文研究了时间正则化在最优时间变量学习中的应用，通过引入一个与离散动力系统中的时间范围直接相关的正则化项，并提出了一种适应性剪枝方法用于减少网络复杂性和训练时间，同时保持表达能力。在MNIST和Fashion MNIST数据集上的分类任务上验证了方法的有效性。

    

    最近，在arXiv:2204.08528中引入了深度神经网络（DNNs）中的最优时间变量学习。在本文中，我们通过引入一个与离散动力系统中的时间范围直接相关的正则化项，扩展了这个概念。此外，我们提出了一种适应性剪枝方法，用于Residual Neural Networks (ResNets)，可以减少网络复杂性，同时不损害表达能力，同时减少训练时间。通过将这些概念应用于著名的MNIST和Fashion MNIST数据集上的分类任务，我们展示了结果。我们的PyTorch代码可在https://github.com/frederikkoehne/time_variable_learning上找到。

    Recently, optimal time variable learning in deep neural networks (DNNs) was introduced in arXiv:2204.08528. In this manuscript we extend the concept by introducing a regularization term that directly relates to the time horizon in discrete dynamical systems. Furthermore, we propose an adaptive pruning approach for Residual Neural Networks (ResNets), which reduces network complexity without compromising expressiveness, while simultaneously decreasing training time. The results are illustrated by applying the proposed concepts to classification tasks on the well known MNIST and Fashion MNIST data sets. Our PyTorch code is available on https://github.com/frederikkoehne/time_variable_learning.
    
[^17]: 通用框架下适应性约束下的顺序决策问题研究

    A General Framework for Sequential Decision-Making under Adaptivity Constraints. (arXiv:2306.14468v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.14468](http://arxiv.org/abs/2306.14468)

    本论文提出了一个通用框架，研究了在适应性约束下的顺序决策问题。具体地，我们提供了Eluder Condition类，并针对稀缺策略切换和批次学习约束分别提供了相应的算法。此工作是第一个考虑通用函数类别下稀缺策略切换和批次学习的工作，涵盖了之前研究中的大部分模型。

    

    我们在研究通用的顺序决策问题下对两个适应性约束进行了首次探索：策略切换稀缺和批次学习。首先，我们提供了一个称为Eluder Condition类的通用类别，其中包括了广泛的强化学习类别。然后，对于策略切换稀缺约束，我们提供了一个通用算法，在EC类别上实现了大约$ \widetilde{\mathcal{O}}(\log K)$的切换代价和$\widetilde{\mathcal{O}}(\sqrt{K})$的后悔代价。对于批次学习约束，我们提供了一个算法，在$B$个批次的情况下，提供了大约$\widetilde{\mathcal{O}}(\sqrt{K}+K/B)$的后悔代价。这篇论文是第一篇考虑通用函数类别下稀缺策略切换和批次学习的工作，涵盖了之前研究中几乎所有的模型，如表格MDP (Bai et al. 2019; Zhang et al. 2020)、线性MDP (Wang et al. 2021; Gao et al. 2021)、低Eluder维度MDP (Kong et al. 2021; Gao et al. 2021)、广义线性函数类别等。

    We take the first step in studying general sequential decision-making under two adaptivity constraints: rare policy switch and batch learning. First, we provide a general class called the Eluder Condition class, which includes a wide range of reinforcement learning classes. Then, for the rare policy switch constraint, we provide a generic algorithm to achieve a $\widetilde{\mathcal{O}}(\log K) $ switching cost with a $\widetilde{\mathcal{O}}(\sqrt{K})$ regret on the EC class. For the batch learning constraint, we provide an algorithm that provides a $\widetilde{\mathcal{O}}(\sqrt{K}+K/B)$ regret with the number of batches $B.$ This paper is the first work considering rare policy switch and batch learning under general function classes, which covers nearly all the models studied in the previous works such as tabular MDP (Bai et al. 2019; Zhang et al. 2020), linear MDP (Wang et al. 2021; Gao et al. 2021), low eluder dimension MDP (Kong et al. 2021; Gao et al. 2021), generalized linear fu
    
[^18]: 面向精度优先机制的自适应隐私组合

    Adaptive Privacy Composition for Accuracy-first Mechanisms. (arXiv:2306.13824v1 [cs.CR])

    [http://arxiv.org/abs/2306.13824](http://arxiv.org/abs/2306.13824)

    本文提出了一种自适应隐私组合的框架，将噪声减少机制与事前隐私机制结合使用以同时实现高精度和隐私。

    

    在许多差分隐私的实际应用中，从业者试图在目标精度水平下提供最佳的隐私保证。最近，一系列通过利用“噪声减少”思想将相关噪声加到私有计算的充分统计中并生成一系列越来越准确答案的“精度优先”机制已被开发出来。噪声减少机制的一个主要优点是分析人员仅需支付发布的最不嘈杂或最准确答案的隐私成本。虽然这种单独的吸引力属性，但没有系统地研究如何将它们与其他差分隐私机制结合使用。一个基本的挑战是噪声减少机制的隐私保证被（必然地）制定为“事后隐私”，其以发布的结果为函数边界隐私损失。此外，至今仍缺乏一种将噪声减少机制与“事前隐私”机制（例如随机响应或拉普拉斯机制）进行组合的原则方法，这些机制直接作为输入大小或查询工作量的隐私损失边界。本文通过提出一种新的框架，介绍了用于自适应隐私组合的噪声减少机制和事前隐私机制，以同时实现高精度和隐私。我们在一系列真实世界的数据集和查询上证明了我们方法的有效性。

    In many practical applications of differential privacy, practitioners seek to provide the best privacy guarantees subject to a target level of accuracy. A recent line of work by \cite{LigettNeRoWaWu17, WhitehouseWuRaRo22} has developed such accuracy-first mechanisms by leveraging the idea of \emph{noise reduction} that adds correlated noise to the sufficient statistic in a private computation and produces a sequence of increasingly accurate answers. A major advantage of noise reduction mechanisms is that the analysts only pay the privacy cost of the least noisy or most accurate answer released. Despite this appealing property in isolation, there has not been a systematic study on how to use them in conjunction with other differentially private mechanisms. A fundamental challenge is that the privacy guarantee for noise reduction mechanisms is (necessarily) formulated as \emph{ex-post privacy} that bounds the privacy loss as a function of the released outcome. Furthermore, there has yet 
    
[^19]: 过参数化线性模型下多类分类的渐进泛化精度研究

    Precise Asymptotic Generalization for Multiclass Classification with Overparameterized Linear Models. (arXiv:2306.13255v1 [cs.LG])

    [http://arxiv.org/abs/2306.13255](http://arxiv.org/abs/2306.13255)

    本文研究了高斯协变量下的过参数化线性模型在多类分类问题中的泛化能力，成功解决了之前的猜想，并提出的新下界具有信息论中的强对偶定理的性质。

    

    本文研究了在具有高斯协变量双层模型下，过参数化线性模型在多类分类中的渐进泛化问题，其中数据点数、特征和类别数都同时增长。我们完全解决了Subramanian等人在'22年所提出的猜想，与预测的泛化区间相匹配。此外，我们的新的下界类似于信息论中的强对偶定理：它们能够确立误分类率逐渐趋近于0或1.我们紧密的结果的一个令人惊讶的结果是，最小范数插值分类器在最小范数插值回归器最优的范围内，可以在渐进上次优。我们分析的关键在于一种新的Hanson-Wright不等式变体，该变体在具有稀疏标签的多类问题中具有广泛的适用性。作为应用，我们展示了相同类型分析在几种不同类型的分类模型上的结果。

    We study the asymptotic generalization of an overparameterized linear model for multiclass classification under the Gaussian covariates bi-level model introduced in Subramanian et al.~'22, where the number of data points, features, and classes all grow together. We fully resolve the conjecture posed in Subramanian et al.~'22, matching the predicted regimes for generalization. Furthermore, our new lower bounds are akin to an information-theoretic strong converse: they establish that the misclassification rate goes to 0 or 1 asymptotically. One surprising consequence of our tight results is that the min-norm interpolating classifier can be asymptotically suboptimal relative to noninterpolating classifiers in the regime where the min-norm interpolating regressor is known to be optimal.  The key to our tight analysis is a new variant of the Hanson-Wright inequality which is broadly useful for multiclass problems with sparse labels. As an application, we show that the same type of analysis 
    
[^20]: 使用聚合特征或邻接表在有向或无向图中，为什么要选择哪个？实证研究和简单分类方法。

    Why Using Either Aggregated Features or Adjacency Lists in Directed or Undirected Graph? Empirical Study and Simple Classification Method. (arXiv:2306.08274v1 [cs.LG])

    [http://arxiv.org/abs/2306.08274](http://arxiv.org/abs/2306.08274)

    本文实证研究了在节点分类任务中使用聚合特征或邻接表以及边方向对分类效果的影响，并提出了一个简单全面的分类方法A2DUG，该方法利用了有向和无向图中节点表示变量的所有组合，其在各种数据集上稳定表现良好，并在几个数据集上优于当前的最先进方法。

    

    节点分类是图分析中最热门的任务之一。本文关注节点表示（聚合特征 vs. 邻接表）和输入图的边方向（有向 vs. 无向）选择对分类结果的影响。我们进行了第一项实证研究，以基准测试使用不同节点表示和边方向的各种GNNs的性能。我们的实验表明，在数据集中没有单一的组合稳定地实现了最先进的结果，这表明我们需要根据数据集的特征选择合适的组合。为此，我们提出了一个简单但全面的分类方法A2DUG，该方法利用有向和无向图中节点表示变量的所有组合。我们表明，A2DUG在各种数据集上稳定表现良好。令人惊讶的是，在几个数据集上，它在很大程度上优于当前的最先进方法。

    Node classification is one of the hottest tasks in graph analysis. In this paper, we focus on the choices of node representations (aggregated features vs. adjacency lists) and the edge direction of an input graph (directed vs. undirected), which have a large influence on classification results. We address the first empirical study to benchmark the performance of various GNNs that use either combination of node representations and edge directions. Our experiments demonstrate that no single combination stably achieves state-of-the-art results across datasets, which indicates that we need to select appropriate combinations depending on the characteristics of datasets. In response, we propose a simple yet holistic classification method A2DUG which leverages all combinations of node representation variants in directed and undirected graphs. We demonstrate that A2DUG stably performs well on various datasets. Surprisingly, it largely outperforms the current state-of-the-art methods in several
    
[^21]: 公开可用的乳腺组织病理学H&E全切片图像数据集：一项系统性综述。

    Publicly available datasets of breast histopathology H&E whole-slide images: A systematic review. (arXiv:2306.01546v1 [eess.IV])

    [http://arxiv.org/abs/2306.01546](http://arxiv.org/abs/2306.01546)

    本文从乳腺H&E染色全切片图像数据集的公开来源出发，系统性地综述了当前可用的数据集情况，包含了12个公开数据集和相关特征信息。总结出数据集的缺失以及更全面和标准化的数据集建立的必要性。

    

    数字病理学和计算资源的进步对乳腺癌诊断和治疗的计算病理学领域产生了重大影响。 然而，获得高质量的标记乳腺癌组织学图像表示着一个重大难题，从而限制了准确和强大的深度学习模型的开发。 在这项系统性综述中，我们确定了可用于开发深度学习算法的公开可用的乳腺H＆E染色全切片图像（WSI）数据集。 我们系统地搜索了9个科学文献数据库和9个研究数据存储库。 我们找到了12个公开可用的数据集，包含5153个乳腺癌H&E WSI。 此外，我们针对每个数据集报告了图像元数据和特征，以帮助研究人员选择适合乳腺癌计算病理学具体任务的数据集。 另外，我们还编制了用于包括文章的修补程序和私有数据集的列表。 我们的综述强调了需要更全面和标准化的数据集，以促进准确和强大的乳腺癌诊断和治疗深度学习算法的发展。

    Advancements in digital pathology and computing resources have made a significant impact in the field of computational pathology for breast cancer diagnosis and treatment. However, access to high-quality labeled histopathological images of breast cancer is a big challenge that limits the development of accurate and robust deep learning models. In this systematic review, we identified the publicly available datasets of breast H&E stained whole-slide images (WSI) that can be used to develop deep learning algorithms. We systematically searched nine scientific literature databases and nine research data repositories. We found twelve publicly available datasets, containing 5153 H&E WSIs of breast cancer. Moreover, we reported image metadata and characteristics for each dataset to assist researchers in selecting proper datasets for specific tasks in breast cancer computational pathology. In addition, we compiled a list of patch and private datasets that were used in the included articles as 
    
[^22]: 特征学习网络在实际规模下具有一致性

    Feature-Learning Networks Are Consistent Across Widths At Realistic Scales. (arXiv:2305.18411v1 [cs.LG])

    [http://arxiv.org/abs/2305.18411](http://arxiv.org/abs/2305.18411)

    本研究发现宽度对于神经网络的动态没有影响，网络在早期训练中表现出一致性，对于简单任务来说这一一致性贯穿整个训练过程，且大宽度下的结构特性是一致的。这表明特征学习极限可以捕捉到现实模型中出现的现象。

    

    我们研究了一系列网络结构和数据集上的特征学习神经网络宽度对网络动态的影响。在训练早期，基于在线数据训练的宽网络不仅具有相同的损失曲线，而且在整个训练过程中的测试预测也是一致的。对于像CIFAR-5m这样的简单任务，这适用于具有实际宽度的网络的整个训练过程。我们还展示了模型的结构特性，包括内部表示、预激活分布、稳定性边缘现象和大学习率效应，在大宽度下是一致的。这启发了一个假设：在特征学习极限下，可以捕捉到现实模型中出现的现象。对于更难的任务（如ImageNet和语言建模）和更晚的训练时间，有限宽度的偏差会系统地增长。这些偏差是由两个不同的效应引起的。首先，网络输出具有初始化相关的方差

    We study the effect of width on the dynamics of feature-learning neural networks across a variety of architectures and datasets. Early in training, wide neural networks trained on online data have not only identical loss curves but also agree in their point-wise test predictions throughout training. For simple tasks such as CIFAR-5m this holds throughout training for networks of realistic widths. We also show that structural properties of the models, including internal representations, preactivation distributions, edge of stability phenomena, and large learning rate effects are consistent across large widths. This motivates the hypothesis that phenomena seen in realistic models can be captured by infinite-width, feature-learning limits. For harder tasks (such as ImageNet and language modeling), and later training times, finite-width deviations grow systematically. Two distinct effects cause these deviations across widths. First, the network output has initialization-dependent variance 
    
[^23]: 功能流匹配

    Functional Flow Matching. (arXiv:2305.17209v1 [cs.LG])

    [http://arxiv.org/abs/2305.17209](http://arxiv.org/abs/2305.17209)

    本文介绍了一种名为功能流匹配（FFM）的函数空间生成模型，该模型利用概率测度插值和学习底层函数空间上生成测度的向量场来生成数据分布。这种无需似然或模拟的方法在合成和真实世界基准数据集上表现优异，优于最近提出的几种函数空间生成模型。

    

    本文提出了一种名为功能流匹配（Functional Flow Matching, FFM）的函数空间生成模型，该模型将最近引入的流匹配（Flow Matching）直接推广到无限维空间中进行。我们的方法首先定义了一组概率测度路径，在固定的高斯测度和数据分布之间进行插值，然后学习函数的底层空间上生成此测度路径的向量场。我们的方法不依赖于似然或模拟，因此非常适合函数空间的设置。我们不仅提供构建这种模型的理论框架，还对我们的技术进行了经验评估。通过对合成和真实世界基准数据集的实验，我们证明了我们提出的FFM方法优于最近提出的几种函数空间生成模型。

    In this work, we propose Functional Flow Matching (FFM), a function-space generative model that generalizes the recently-introduced Flow Matching model to operate directly in infinite-dimensional spaces. Our approach works by first defining a path of probability measures that interpolates between a fixed Gaussian measure and the data distribution, followed by learning a vector field on the underlying space of functions that generates this path of measures. Our method does not rely on likelihoods or simulations, making it well-suited to the function space setting. We provide both a theoretical framework for building such models and an empirical evaluation of our techniques. We demonstrate through experiments on synthetic and real-world benchmarks that our proposed FFM method outperforms several recently proposed function-space generative models.
    
[^24]: 深度等变超球体

    Deep Equivariant Hyperspheres. (arXiv:2305.15613v1 [cs.LG])

    [http://arxiv.org/abs/2305.15613](http://arxiv.org/abs/2305.15613)

    本文提出了深度等变超球体的理论模型，解决了几何深度学习中等变和几何变换下不变的重大问题。

    

    本文提出了一种学习nD特征的方法，其在点云分析中等变于正交转换，利用了超球体和常规n单形体。我们的主要贡献在于理论方面，解决了几何深度学习中等变和几何变换下不变的重大问题。我们扩展了近期发展的可操纵3D球形神经元理论--基于球形决策面的SO（3）-等变滤波器组，将该神经元扩展到了nD，我们称之为深度等变超球体，并使它们能够堆叠在多层中。利用ModelNet40基准测试，我们实验验证了我们的理论贡献，并展示了所提出的等变超球体的潜在实用配置。

    This paper presents an approach to learning nD features equivariant under orthogonal transformations for point cloud analysis, utilizing hyperspheres and regular n-simplexes. Our main contributions are theoretical and tackle major issues in geometric deep learning such as equivariance and invariance under geometric transformations. Namely, we enrich the recently developed theory of steerable 3D spherical neurons -- SO(3)-equivariant filter banks based on neurons with spherical decision surfaces -- by extending said neurons to nD, which we call deep equivariant hyperspheres, and enabling their stacking in multiple layers. Using the ModelNet40 benchmark, we experimentally verify our theoretical contributions and show a potential practical configuration of the proposed equivariant hyperspheres.
    
[^25]: AlpacaFarm: 一种从人类反馈中学习的方法模拟框架

    AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback. (arXiv:2305.14387v1 [cs.LG])

    [http://arxiv.org/abs/2305.14387](http://arxiv.org/abs/2305.14387)

    该论文提出了一种名为AlpacaFarm的低成本模拟器，该模拟器为从人类反馈中学习的研究和开发提供了一种解决方案，通过设计LLM提示来模拟人类反馈，提出自动评估并提供参考实现，克服了数据收集的高昂成本、缺乏可信的评估和缺乏参考方法实现的挑战。

    

    大型语言模型（LLMs）如ChatGPT因其良好的指令跟随能力而得到了广泛应用。开发这些LLMs需要使用人类反馈进行训练的复杂且尚不明确的工作流程。将此指令跟随过程复制和理解面临三大挑战： 数据收集的高昂成本，缺乏可信的评估和缺乏参考方法实现。我们通过AlpacaFarm解决了这些挑战，这是一个低成本的模拟器，可用于从反馈中学习的研究和开发。第一，我们设计了LLM提示来模拟人类反馈，其成本比众包工作者便宜45倍，并且与人类反馈具有高度一致性。第二，我们提出了一种自动评估方法，并将其与真实世界交互中获得的人类指令进行验证。第三，我们为几种从配对反馈中学习的方法（PPO，best-of-n，expert iteration等）提供了参考实现。

    Large language models (LLMs) such as ChatGPT have seen widespread adoption due to their ability to follow user instructions well. Developing these LLMs involves a complex yet poorly understood workflow requiring training with human feedback. Replicating and understanding this instruction-following process faces three major challenges: the high cost of data collection, the lack of trustworthy evaluation, and the absence of reference method implementations. We address these challenges with AlpacaFarm, a simulator that enables research and development for learning from feedback at a low cost. First, we design LLM prompts to simulate human feedback that are 45x cheaper than crowdworkers and display high agreement with humans. Second, we propose an automatic evaluation and validate it against human instructions obtained on real-world interactions. Third, we contribute reference implementations for several methods (PPO, best-of-n, expert iteration, and more) that learn from pairwise feedback
    
[^26]: 通过预测修正提高基于得分扩散模型的收敛性

    Improved Convergence of Score-Based Diffusion Models via Prediction-Correction. (arXiv:2305.14164v1 [cs.LG])

    [http://arxiv.org/abs/2305.14164](http://arxiv.org/abs/2305.14164)

    本文通过使用预测校正方案，提高了基于得分扩散模型的收敛性。

    

    基于得分的生成模型（SGM）是从复杂数据分布中进行采样的强大工具。其基本思想是（i）通过向数据添加噪声运行时间为$T_1$的正向过程，（ii）估计其得分函数，并（iii）使用此估计值运行反向过程。由于反向过程以正向过程的平稳分布作为初始值，因此现有的分析范式要求$T_1\to\infty$。然而，从理论角度来看，对于给定的分数逼近精度，当$T_1$发散时，收敛保证将失败；从实际角度来看，$T_1$越大，计算成本就越高，并且会导致误差传播。本文通过考虑流行的预测器校正方案的一个版本来解决这个问题：在运行正向过程之后，我们首先通过不精确的 Langevin 动力学估计最终分布，然后恢复该过程。我们的关键技术贡献是提供了收敛保证。

    Score-based generative models (SGMs) are powerful tools to sample from complex data distributions. Their underlying idea is to (i) run a forward process for time $T_1$ by adding noise to the data, (ii) estimate its score function, and (iii) use such estimate to run a reverse process. As the reverse process is initialized with the stationary distribution of the forward one, the existing analysis paradigm requires $T_1\to\infty$. This is however problematic: from a theoretical viewpoint, for a given precision of the score approximation, the convergence guarantee fails as $T_1$ diverges; from a practical viewpoint, a large $T_1$ increases computational costs and leads to error propagation. This paper addresses the issue by considering a version of the popular predictor-corrector scheme: after running the forward process, we first estimate the final distribution via an inexact Langevin dynamics and then revert the process. Our key technical contribution is to provide convergence guarantees
    
[^27]: 一种信息论通用泛化界统一框架

    A unified framework for information-theoretic generalization bounds. (arXiv:2305.11042v1 [cs.LG])

    [http://arxiv.org/abs/2305.11042](http://arxiv.org/abs/2305.11042)

    该论文提出了一种基于概率去相关引理和概率测度空间中一些其他技术的通用方法，可以得到新的学习算法的信息论泛化上限，并且能够恢复许多现有的泛化界，如基于互信息、条件互信息、随机chaining和PAC-Bayes不等式的界。

    

    本文提出了一种通用的方法来导出学习算法的信息论泛化界。主要的技术工具是基于改变测度和松弛Young不等式在$L_{\psi_p}$Orlicz空间中的概率去相关性引理。采用去相关性引理与其他技术，如对称化、耦合和概率测度空间中的chaining，我们得到了新的泛化误差上限，包括期望和高概率，同时，我们也恢复了许多现有的泛化界，包括基于互信息、条件互信息、随机chaining和PAC-Bayes不等式的界。此外，Fernique-Talagrand上界也作为一种特殊情况呈现出来。

    This paper presents a general methodology for deriving information-theoretic generalization bounds for learning algorithms. The main technical tool is a probabilistic decorrelation lemma based on a change of measure and a relaxation of Young's inequality in $L_{\psi_p}$ Orlicz spaces. Using the decorrelation lemma in combination with other techniques, such as symmetrization, couplings, and chaining in the space of probability measures, we obtain new upper bounds on the generalization error, both in expectation and in high probability, and recover as special cases many of the existing generalization bounds, including the ones based on mutual information, conditional mutual information, stochastic chaining, and PAC-Bayes inequalities. In addition, the Fernique-Talagrand upper bound on the expected supremum of a subgaussian process emerges as a special case.
    
[^28]: 自动编码器用于发现复杂动力系统数据中的流形维度和坐标

    Autoencoders for discovering manifold dimension and coordinates in data from complex dynamical systems. (arXiv:2305.01090v1 [cs.LG])

    [http://arxiv.org/abs/2305.01090](http://arxiv.org/abs/2305.01090)

    本文提出了一种自动编码器框架，结合implicit regularization，内部线性层和L2正则化（权重衰减）自动估计数据集的潜在维度，产生正交的流形坐标系，并提供环境空间和流形空间之间的映射函数，从而允许进行样本之外的投影。该方法在动力系统数据集中表现出了较好的低秩表示效果，为底层动态提供了物理洞见，并可以用于提高机器学习模型和控制策略的效果。

    

    尽管物理和工程学中的许多现象在形式上是高维的，但它们的长时间动态往往生活在较低维的流形上。本文介绍了一种自动编码器框架，将隐式正则化与内部线性层和$L_2$正则化（权重衰减）相结合，自动估计数据集的潜在维度、产生正交的流形坐标系，并提供环境空间和流形空间之间的映射函数，从而允许进行样本之外的投影。我们验证了我们的框架估计流形维度的能力，针对多种复杂度的动力系统数据集进行比较，并与其他最先进的估计器进行对比。我们分析网络的训练动态，以了解低秩学习的机制，并发现每个隐式正则化层共同构成了低秩表示，甚至在训练过程中进行了自我纠正。学习的坐标系的分析可以为底层动态提供物理洞见，也可以用于提高机器学习模型和控制策略的效果。

    While many phenomena in physics and engineering are formally high-dimensional, their long-time dynamics often live on a lower-dimensional manifold. The present work introduces an autoencoder framework that combines implicit regularization with internal linear layers and $L_2$ regularization (weight decay) to automatically estimate the underlying dimensionality of a data set, produce an orthogonal manifold coordinate system, and provide the mapping functions between the ambient space and manifold space, allowing for out-of-sample projections. We validate our framework's ability to estimate the manifold dimension for a series of datasets from dynamical systems of varying complexities and compare to other state-of-the-art estimators. We analyze the training dynamics of the network to glean insight into the mechanism of low-rank learning and find that collectively each of the implicit regularizing layers compound the low-rank representation and even self-correct during training. Analysis o
    
[^29]: 基于强化学习探索夸克和轻子的味道结构

    Exploring the flavor structure of quarks and leptons with reinforcement learning. (arXiv:2304.14176v1 [hep-ph])

    [http://arxiv.org/abs/2304.14176](http://arxiv.org/abs/2304.14176)

    通过利用强化学习，探索了具有 $U(1)$ 味道对称性的模型的味道结构，找到了21个与实验测量值一致的模型，预测了无中微子双贝塔衰变的有效质量和可观的轻子 CP 破坏。

    

    我们提出了一种利用强化学习探索夸克和轻子味道结构的方法。作为具体模型，我们利用一个基本的基于策略的算法，针对具有 $U(1)$ 味道对称性的模型。通过训练神经网络对夸克和轻子的 $U(1)$ 荷进行学习，代理方案找到了21个与夸克和轻子的实验测量质量和混合角一致的模型。特别是，正序的固有值往往大于反序，正序与目前的实验数据相比更加符合。代理的自主行为根据无中微子双贝塔衰变的有效质量和叶子场的角成分引起的可观的轻子 CP 破坏来预测。

    We propose a method to explore the flavor structure of quarks and leptons with reinforcement learning. As a concrete model, we utilize a basic policy-based algorithm for models with $U(1)$ flavor symmetry. By training neural networks on the $U(1)$ charges of quarks and leptons, the agent finds 21 models to be consistent with experimentally measured masses and mixing angles of quarks and leptons. In particular, an intrinsic value of normal ordering tends to be larger than that of inverted ordering, and the normal ordering is well fitted with the current experimental data in contrast to the inverted ordering. A specific value of effective mass for the neutrinoless double beta decay and a sizable leptonic CP violation induced by an angular component of flavon field are predicted by autonomous behavior of the agent.
    
[^30]: 模型稀疏化可以简化机器反学习

    Model sparsification can simplify machine unlearning. (arXiv:2304.04934v1 [cs.LG])

    [http://arxiv.org/abs/2304.04934](http://arxiv.org/abs/2304.04934)

    本文提出了一种基于模型稀疏化的机器反学习方案，称为prune first, then unlearn和sparsity-aware unlearning。此方案可以提高近似反学习器的多标准反学习性能，并在不同的场景中表现出一致的效果。

    

    最近的数据管制要求机器反学习（MU）：从模型中移除指定样例的影响。虽然可以通过使用剩余数据从头开始进行模型重新训练来进行精确反学习，但是其计算成本导致了近似但高效的反学习方案的开发。除了数据中心的MU解决方案，我们通过一种新颖的基于模型的视角推进MU：通过权值修剪进行稀疏化。我们的理论和实践结果表明，模型稀疏性可以提高近似反学习器的多标准反学习性能，缩小近似间隙，同时保持高效。有了这个认识，我们制定了两个新的稀疏感知反学习元方案，称为“先修剪，然后反学习”和“稀疏感知反学习”。广泛的实验表明，我们的发现和提议在各种场景下始终有益于MU，包括按类数据擦除、随机数据擦除和后门数据伪造等。

    Recent data regulations necessitate machine unlearning (MU): The removal of the effect of specific examples from the model. While exact unlearning is possible by conducting a model retraining with the remaining data from scratch, its computational cost has led to the development of approximate but efficient unlearning schemes. Beyond data-centric MU solutions, we advance MU through a novel model-based viewpoint: sparsification via weight pruning. Our results in both theory and practice indicate that model sparsity can boost the multi-criteria unlearning performance of an approximate unlearner, closing the approximation gap, while continuing to be efficient. With this insight, we develop two new sparsity-aware unlearning meta-schemes, termed `prune first, then unlearn' and `sparsity-aware unlearning'. Extensive experiments show that our findings and proposals consistently benefit MU in various scenarios, including class-wise data scrubbing, random data scrubbing, and backdoor data forge
    
[^31]: 探索用于代码分析的大型语言模型中的分布偏移

    Exploring Distributional Shifts in Large Language Models for Code Analysis. (arXiv:2303.09128v1 [cs.CL])

    [http://arxiv.org/abs/2303.09128](http://arxiv.org/abs/2303.09128)

    研究了两种大型语言模型在代码分析中处理领域外数据的能力，提出了组织、项目和模块的自然边界分割方法，发现每个新领域的样本都会产生分布偏移的挑战，实现了多任务学习与少量微调相结合的解决方案。

    

    我们系统地研究了两种大型语言模型 CodeT5 和 Codex 的能力，以便推广到领域外数据。在本研究中，我们考虑了两种基本应用：代码摘要和代码生成。我们按照其自然边界（按组织、按项目和按软件项目中的模块）将数据分为不同的领域。这样，在部署时，识别领域内和领域外的数据变得简单。我们发现，来自每个新领域的样本都会给这两个模型带来分布偏移的重大挑战。我们研究了不同的方法如何适应模型以更好地推广到新领域。我们的实验表明，虽然多任务学习本身是一个合理的基线，但将其与从训练数据中检索的示例的少量微调相结合可以实现非常强的性能。事实上，根据我们的实验，这种解决方案可以在非常低的数据情况下优于直接调整微调。

    We systematically study the capacity of two large language models for code CodeT5 and Codex - to generalize to out-of-domain data. In this study, we consider two fundamental applications - code summarization, and code generation. We split data into domains following its natural boundaries - by an organization, by a project, and by a module within the software project. This makes recognition of in-domain vs out-of-domain data at the time of deployment trivial. We establish that samples from each new domain present both models with a significant challenge of distribution shift. We study how well different established methods can adapt models to better generalize to new domains. Our experiments show that while multitask learning alone is a reasonable baseline, combining it with few-shot finetuning on examples retrieved from training data can achieve very strong performance. In fact, according to our experiments, this solution can outperform direct finetuning for very low-data scenarios.
    
[^32]: 神经网络在因果估计中的应用: 在美国评估更严格的空气质量标准的健康效益

    Causal Estimation of Exposure Shifts with Neural Networks: Evaluating the Health Benefits of Stricter Air Quality Standards in the US. (arXiv:2302.02560v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.02560](http://arxiv.org/abs/2302.02560)

    本研究提出了一种神经网络方法，利用其理论基础和实施的可行性，从而估计连续暴露/治疗的分布对政策相关结果的因果效应。我们将此方法应用于包含6800万个个体和2700万个美国境内死亡事件的数据中，通过评估美国国家环境保护局（EPA）对PM2.5的国家环境空气质量标准（NAAQS）进行修订后的健康效益。

    

    在政策研究中，估计连续性暴露/治疗的分布对感兴趣的结果的因果效应是最关键的分析任务之一。我们称之为偏移-响应函数（SRF）估计问题。现有的涉及强健因果效应估计器的神经网络方法缺乏理论保证和实际实现，用于SRF估计。受公共卫生中的关键政策问题的启发，我们开发了一种神经网络方法及其理论基础，以提供具有强健性和效率保证的SRF估计。然后，我们将我们的方法应用于包含6800万个个体和2700万个美国境内死亡事件的数据中，以估计将美国国家环境保护局（EPA）最近提议从12 μg/m³改为9 μg/m³的PM2.5的美国国家环境空气质量标准（NAAQS）的修订对结果的因果效应。我们的目标是首次估计

    In policy research, one of the most critical analytic tasks is to estimate the causal effect of a policy-relevant shift to the distribution of a continuous exposure/treatment on an outcome of interest. We call this problem shift-response function (SRF) estimation. Existing neural network methods involving robust causal-effect estimators lack theoretical guarantees and practical implementations for SRF estimation. Motivated by a key policy-relevant question in public health, we develop a neural network method and its theoretical underpinnings to estimate SRFs with robustness and efficiency guarantees. We then apply our method to data consisting of 68 million individuals and 27 million deaths across the U.S. to estimate the causal effect from revising the US National Ambient Air Quality Standards (NAAQS) for PM 2.5 from 12 $\mu g/m^3$ to 9 $\mu g/m^3$. This change has been recently proposed by the US Environmental Protection Agency (EPA). Our goal is to estimate, for the first time, the 
    
[^33]: CD-GraB：协调分布式示例顺序以证明加速训练

    CD-GraB: Coordinating Distributed Example Orders for Provably Accelerated Training. (arXiv:2302.00845v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.00845](http://arxiv.org/abs/2302.00845)

    该论文提出了一种名为CD-GraB的算法，可以协调分布式示例顺序以加速机器学习训练。CD-GraB展现出线性加速收敛速率并且在基准任务上优于其他基线方法。

    

    最近有关在线梯度平衡（GraB）的研究表明，存在基于置换的示例排序可以保证优于随机重排（RR）。而RR会任意排列训练示例，GraB利用先前时期的陈旧梯度对示例进行排序--实现比RR更快的收敛速率。但是，GraB在设计上存在限制：虽然它展示了在集中数据上扩展训练的出色能力，但并不自然地扩展到现代分布式ML工作负载。因此，我们提出了协调分布式GraB（CD-GraB），它利用先前关于内核稀疏化工作的洞察力，将置换排序的可证明更快的优势转化为分布式设置。CD-GraB具有可忽略的开销，在中央集权GraB上具有线性加速收敛速率的性能，并在各种基准任务上经验性地优于分布式RR等基线方法。

    Recent research on online Gradient Balancing (GraB) has revealed that there exist permutation-based example orderings that are guaranteed to outperform random reshuffling (RR). Whereas RR arbitrarily permutes training examples, GraB leverages stale gradients from prior epochs to order examples -- achieving a provably faster convergence rate than RR. However, GraB is limited by design: While it demonstrates an impressive ability to scale-up training on centralized data, it does not naturally extend to modern distributed ML workloads. We therefore propose Coordinated Distributed GraB (CD-GraB), which uses insights from prior work on kernel thinning to translate the benefits of provably faster permutation-based example ordering to distributed settings. With negligible overhead, CD-GraB exhibits a linear speedup in convergence rate over centralized GraB and outperforms baselines empirically, including distributed RR, on a variety of benchmark tasks.
    
[^34]: 一种利用集合建模、注释的归一化分布和熵测量的不精确、众包数据集的方法

    An Approach for Noisy, Crowdsourced Datasets Utilizing Ensemble Modeling, Normalized Distributions of Annotations, and Entropic Measures of Uncertainty. (arXiv:2210.16380v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.16380](http://arxiv.org/abs/2210.16380)

    在众包图像数据集上的分类是具有挑战性的。本文提出了一种利用集合建模、注释的归一化分布和熵测量的方法，以帮助识别标签不确定的图像，并量化这些样本的可信度。

    

    在不精确的、众包的图像数据集上进行分类对于最好的神经网络来说都是具有挑战性的。两个问题使得这类数据集上的问题更加复杂，即类别不平衡和标签的不确定性。AL-ALL和AL-PUB数据集--包含来自古希腊纸草的图像的紧密裁剪的单个字符--受到这两个问题的严重影响。将集合建模应用于这样的数据集可以帮助识别标签不确定的图像，并量化这些样本的可信度。因此，我们应用由几乎相同的ResNets组成的堆叠泛化，它们具有不同的损失函数：一个利用稀疏交叉熵（CXE），另一个利用Kullback-Liebler散度（KLD）。两个网络都使用从众包一致性中得出的标签。对于第二个网络，KLD是相对于所提出的注释的归一化分布（NDA）计算的。对于我们的集合模型，我们应用k-近邻算法。

    Performing classification on noisy, crowdsourced image datasets can prove challenging even for the best neural networks. Two issues which complicate the problem on such datasets are class imbalance and ground-truth uncertainty in labeling. The AL-ALL and AL-PUB datasets -- consisting of tightly cropped, individual characters from images of ancient Greek papyri -- are strongly affected by both issues. The application of ensemble modeling to such datasets can help identify images where the ground-truth is questionable and quantify the trustworthiness of those samples. As such, we apply stacked generalization consisting of nearly identical ResNets with different loss functions: one utilizing sparse cross-entropy (CXE) and the other Kullback-Liebler Divergence (KLD). Both networks use labels drawn from the crowdsourced consensus. For the second network, the KLD is calculated with respect to the proposed Normalized Distribution of Annotations (NDA). For our ensemble model, we apply a k-near
    
[^35]: Occam学习

    Occam learning. (arXiv:2210.13179v2 [cond-mat.dis-nn] UPDATED)

    [http://arxiv.org/abs/2210.13179](http://arxiv.org/abs/2210.13179)

    本文讨论了一种具有固定隐藏层分布的概率神经网络模型，该模型选择简单、易解释，不需要过度参数化，同时训练有效。模型的隐藏单元为二元变量时具有以特征为基础的自然解释。作者认为隐藏变量的分布应该遵循最大关联度原则，并介绍了分层特征模型（HFM）作为满足这一原则并对特征空间进行中性先验组织的模型。

    

    我们讨论了一种无监督学习的概率神经网络模型，在这种模型中，隐藏层的分布是固定的。我们认为采用这种体系架构的机器学习具有许多令人满意的性质。例如，该模型可以选择为简单且易解释的模型，不需要过度参数化，而且在热力学意义下，训练更有效。当隐藏单元为二元变量时，这些模型具有以特征为基础的自然解释。我们表明，缺乏特征的状态对应于在特征方面最大程度的无知状态，并且，学习第一个特征取决于数据的非高斯统计属性。我们认为应该根据最大关联度原则选择隐藏变量的分布。我们介绍了分层特征模型（HFM）作为满足这一原则并对特征空间进行中性先验组织的模型。

    We discuss probabilistic neural network models for unsupervised learning where the distribution of the hidden layer is fixed. We argue that learning machines with this architecture enjoy a number of desirable properties. For example, the model can be chosen as a simple and interpretable one, it does not need to be over-parametrised and training is argued to be efficient in a thermodynamic sense. When hidden units are binary variables, these models have a natural interpretation in terms of features. We show that the featureless state corresponds to a state of maximal ignorance about the features and that learning the first feature depends on non-Gaussian statistical properties of the data. We suggest that the distribution of hidden variables should be chosen according to the principle of maximal relevance. We introduce the Hierarchical Feature Model (HFM) as an example of a model that satisfies this principle, and that encodes a neutral a priori organisation of the feature space. We pre
    
[^36]: 通过核差异实现有针对性的分离与收敛

    Targeted Separation and Convergence with Kernel Discrepancies. (arXiv:2209.12835v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2209.12835](http://arxiv.org/abs/2209.12835)

    通过核差异度量，我们推导出了新的充分必要条件，实现了将目标分离出来，以及控制对目标的弱收敛性。此外，我们在$\mathbb{R}^d$上使用了这些结果来扩展了核Stein差异分离和收敛控制的已知条件，并开发了能够精确度量目标的弱收敛性的核差异度量。

    

    最大均值差异（MMDs）如核Stein差异（KSD）已经成为广泛应用的中心，包括假设检验、采样器选择、分布近似和变分推断。在每个设置中，这些基于核的差异度量需要实现（i）将目标P与其他概率测度分离，甚至（ii）控制对P的弱收敛。在本文中，我们推导了确保（i）和（ii）的新的充分必要条件。对于可分的度量空间上的MMDs，我们描述了分离Bochner可嵌入测度的核，并引入简单的条件来分离所有具有无界核的测度和用有界核来控制收敛。我们利用这些结果在$\mathbb{R}^d$上大大扩展了KSD分离和收敛控制的已知条件，并开发了首个能够精确度量对P的弱收敛的KSDs。在这个过程中，我们强调了我们的结果的影响。

    Maximum mean discrepancies (MMDs) like the kernel Stein discrepancy (KSD) have grown central to a wide range of applications, including hypothesis testing, sampler selection, distribution approximation, and variational inference. In each setting, these kernel-based discrepancy measures are required to (i) separate a target P from other probability measures or even (ii) control weak convergence to P. In this article we derive new sufficient and necessary conditions to ensure (i) and (ii). For MMDs on separable metric spaces, we characterize those kernels that separate Bochner embeddable measures and introduce simple conditions for separating all measures with unbounded kernels and for controlling convergence with bounded kernels. We use these results on $\mathbb{R}^d$ to substantially broaden the known conditions for KSD separation and convergence control and to develop the first KSDs known to exactly metrize weak convergence to P. Along the way, we highlight the implications of our res
    
[^37]: 居民众包中空间欠报告差异的量化

    Quantifying Spatial Under-reporting Disparities in Resident Crowdsourcing. (arXiv:2204.08620v2 [stat.AP] UPDATED)

    [http://arxiv.org/abs/2204.08620](http://arxiv.org/abs/2204.08620)

    本文研究了城市治理中居民众包的问题，并提出了一种准确测量报道率的方法，使不同的报道率不再成为城市治理下游解决事件速度方面的不公平根源。

    

    现代城市治理在很大程度上依赖于众包(“协同生产”)，以识别 downed trees 和 power lines 等问题。一个主要问题是，居民不以相同的速率报告问题，不同的报告异质性直接转化为下游在解决事件的速度方面的差异。测量这样的欠报告是一个困难的统计任务，因为根据定义，我们不能观察到没有被报告的事件或报告事件第一次发生的时间。因此，不能单纯地区分低报道率和低基准真实事件率。我们开发了一种方法来识别(异质的)报道率，而不使用外部基准真实数据。我们的想法是，在相同事件的 $\textit{duplicate}$ 报告中的比率可以利用来消除报告率随事件发生而发生的不确定性。借助这个思想，我们将问题简化为标准的泊松率估计任务，尽管标题有很多技术术语，但论文讨论了如何通过众包来帮助城市治理，不同的报道率如何导致问题解决的差异。作者提出了一种准确测量报道率的方法，而不依赖于外部数据。他们利用多次报告的事件可以帮助区分事件是否发生以及其报道率。

    Modern city governance relies heavily on crowdsourcing ("co-production") to identify problems such as downed trees and power lines. A major concern is that residents do not report problems at the same rates, with reporting heterogeneity directly translating to downstream disparities in how quickly incidents can be addressed. Measuring such under-reporting is a difficult statistical task, as, by definition, we do not observe incidents that are not reported or when reported incidents first occurred. Thus, low reporting rates and low ground-truth incident rates cannot be naively distinguished. We develop a method to identify (heterogeneous) reporting rates, without using external ground truth data. Our insight is that rates on $\textit{duplicate}$ reports about the same incident can be leveraged to disambiguate whether an incident has occurred with its reporting rate once it has occurred. Using this idea, we reduce the question to a standard Poisson rate estimation task -- even though the
    
[^38]: 模型重新编程：资源高效的跨领域机器学习

    Model Reprogramming: Resource-Efficient Cross-Domain Machine Learning. (arXiv:2202.10629v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.10629](http://arxiv.org/abs/2202.10629)

    模型重新编程是一种资源高效的跨领域机器学习方法，通过重新利用和重用预训练模型，无需模型细调即可在目标领域解决任务。这种方法在许多应用中优于迁移学习和从头训练。

    

    在视觉、语言和语音等数据丰富的领域中，深度学习在提供高性能的特定任务模型方面占据主导地位，甚至可以学习通用的任务无关表示以便有效地进行下游任务的细调。然而，在资源有限的领域中，深度学习仍面临多个挑战，包括：（i）数据有限；（ii）模型开发成本受限；（iii）缺乏足够的预训练模型以便有效进行细调。本文概述了模型重新编程的概念来弥合这一差距。模型重新编程通过从源领域重新利用和重用一个精心开发的预训练模型，在目标领域解决任务而无需进行模型细调，从而实现了资源高效的跨领域机器学习，源领域和目标领域可以差异巨大。在许多应用中，模型重新编程优于迁移学习和从头训练。本文阐述了模型重新编程的方法论，并总结了现有的应用情况。

    In data-rich domains such as vision, language, and speech, deep learning prevails to deliver high-performance task-specific models and can even learn general task-agnostic representations for efficient finetuning to downstream tasks. However, deep learning in resource-limited domains still faces multiple challenges including (i) limited data, (ii) constrained model development cost, and (iii) lack of adequate pre-trained models for effective finetuning. This paper provides an overview of model reprogramming to bridge this gap. Model reprogramming enables resource-efficient cross-domain machine learning by repurposing and reusing a well-developed pre-trained model from a source domain to solve tasks in a target domain without model finetuning, where the source and target domains can be vastly different. In many applications, model reprogramming outperforms transfer learning and training from scratch. This paper elucidates the methodology of model reprogramming, summarizes existing use c
    
[^39]: 针对高维矩阵数据的最优变量聚类

    Optimal Variable Clustering for High-Dimensional Matrix Valued Data. (arXiv:2112.12909v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2112.12909](http://arxiv.org/abs/2112.12909)

    提出了一种新的针对高维矩阵数据的特征潜变量模型，使用加权协方差矩阵的差异作为不相似度测量的层次聚类算法，理论上实现了聚类一致性，在模拟和真实数据示例中证明了方法的优越性。

    

    矩阵值数据在许多应用中日益普及。大多数现有的这种类型数据的聚类方法是针对平均模型设计的，不考虑特征的依赖结构，而该结构在高维情况下尤为重要。为了从依赖结构中提取信息进行聚类，我们提出了一种新的特征潜变量模型，该模型将特征排列成矩阵形式，并使用一些未知的成员矩阵表示行和列的聚类。在此模型下，我们进一步提出了一类使用加权协方差矩阵的差异作为不相似度测量的层次聚类算法。在理论上，我们证明了在温和的条件下，我们的算法可以在高维情况下实现聚类一致性。虽然这种一致性结果适用于我们的算法和广泛的加权协方差矩阵类别，但这个结果的条件依赖于协方差函数和加权机制的选择。通过模拟和真实数据示例，我们证明了我们的方法相对于现有方法提供了更好的聚类性能和特征选择准确性。

    Matrix valued data has become increasingly prevalent in many applications. Most of the existing clustering methods for this type of data are tailored to the mean model and do not account for the dependence structure of the features, which can be very informative, especially in high-dimensional settings. To extract the information from the dependence structure for clustering, we propose a new latent variable model for the features arranged in matrix form, with some unknown membership matrices representing the clusters for the rows and columns. Under this model, we further propose a class of hierarchical clustering algorithms using the difference of a weighted covariance matrix as the dissimilarity measure. Theoretically, we show that under mild conditions, our algorithm attains clustering consistency in the high-dimensional setting. While this consistency result holds for our algorithm with a broad class of weighted covariance matrices, the conditions for this result depend on the choic
    

