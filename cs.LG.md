# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Open-source Frame Semantic Parsing.](http://arxiv.org/abs/2303.12788) | 本文介绍了一个开源Python库Frame Semantic Transformer，该库用于框架语义解析，并在易用性和性能方面实现接近最新水平，可通过在推理时使用FrameNet词汇单元来提高性能，并通过在训练期间使用文本数据增强来提高对真实世界数据的稳健性。 |
| [^2] | [Matryoshka Policy Gradient for Entropy-Regularized RL: Convergence and Global Optimality.](http://arxiv.org/abs/2303.12785) | 本文介绍了一种新的策略梯度算法——莫特里卡多策略梯度(MPG)，该算法尤其在最大熵强化学习中表现突出，能够实现一系列策略的训练和学习以达到任务的最优化，具有极高的收敛性和全局最优性。 |
| [^3] | [Conformal Prediction for Time Series with Modern Hopfield Networks.](http://arxiv.org/abs/2303.12783) | 该论文提出了一种名为 HopCPT 的新一致性时间序列预测方法，不仅能够处理时间结构，而且能够利用其优势，已在多种真实世界的时间序列数据集上证明了优于现有方法的性能。 |
| [^4] | [Can we trust the evaluation on ChatGPT?.](http://arxiv.org/abs/2303.12767) | 本文讨论了ChatGPT评估中面临的数据污染挑战，通过倾向性检测任务阐述了这一问题，并探讨了如何在闭合且持续训练模型的时代确保模型评估的公平性。 |
| [^5] | [LSTM-based Video Quality Prediction Accounting for Temporal Distortions in Videoconferencing Calls.](http://arxiv.org/abs/2303.12761) | 本文提出了一种基于数据的方法，通过训练一个LSTM模型实现了对视频会议通话中出现的时间失真的建模，并成功预测了视频质量，其中模型的每帧输出可以详细分析视频质量损失的原因。 |
| [^6] | [On-Device Unsupervised Image Segmentation.](http://arxiv.org/abs/2303.12753) | 本文提出了一种替代方法来解决缺乏标记数据的问题，即开发在边缘设备上执行的高效无监督分割，基于作者的观察，当像素映射到高维空间时，分割可以获得高性能。 |
| [^7] | [Enabling Calibration In The Zero-Shot Inference of Large Vision-Language Models.](http://arxiv.org/abs/2303.12748) | 本文研究了零样本推理中视觉语言模型的校准问题，发现CLIP存在误校准，并提出了一种修改版的温度缩放方法，可以适用于每个特定的CLIP模型。 |
| [^8] | [Less is More: Unsupervised Mask-guided Annotated CT Image Synthesis with Minimum Manual Segmentations.](http://arxiv.org/abs/2303.12747) | 本文提出了一种新颖的医学图像合成策略——无监督掩模引导合成，能够在最小手动分割的情况下，获得合成图像和分割，有效地避免了分割掩模数量不足、标签不准确等问题。 |
| [^9] | [DR.CPO: Diversified and Realistic 3D Augmentation via Iterative Construction, Random Placement, and HPR Occlusion.](http://arxiv.org/abs/2303.12743) | 该论文提出了一种多样化和逼真的增强方法，可以创建整体对象并灵活地定位和旋转对象，并相应地应用自遮挡和外遮挡。通过迭代构建多个对象来提高整体对象构造的多样性，构造的对象可以在训练帧中随机放置和旋转。 |
| [^10] | [Inverting the Fundamental Diagram and Forecasting Boundary Conditions: How Machine Learning Can Improve Macroscopic Models for Traffic Flow.](http://arxiv.org/abs/2303.12740) | 本文尝试将机器学习和宏观微分模型相结合，借以提高交通流量模型的准确性，通过利用基于LSTM递归神经网络的机器学习模型得出拥堵情况和未来30分钟内通过传感器的车辆总数，进而提高模型的精度，并倒转基础图像以恢复与流量-密度关系相关的信息。 |
| [^11] | [Optimizing CAD Models with Latent Space Manipulation.](http://arxiv.org/abs/2303.12739) | 本文介绍了一种利用潜空间操作优化CAD模型的方法，扩展了StyleCLIP来适用于体素模型形式的CAD模型，能够优化实际CAD模型的自动化能力。 |
| [^12] | [DPPMask: Masked Image Modeling with Determinantal Point Processes.](http://arxiv.org/abs/2303.12736) | 本文提出了一种简单有效的遮盖图像建模方法DPPMask，用确定性点过程（DPPs）替换了随机过程以减少遮盖后图像的语义变化，从而在多个基准数据集上显著改善了代表性能。 |
| [^13] | [MultiModal Bias: Introducing a Framework for Stereotypical Bias Assessment beyond Gender and Race in Vision Language Models.](http://arxiv.org/abs/2303.12734) | 本文提出了一个视觉和文本偏置基准MMBias，涵盖14个人口子群，并利用该基准评估了多个自我监督多模态模型（包括CLIP、ALBEF和ViLT），结果表明这些模型表现出偏向某些群体的有意义的偏见。同时，本文引入了一种针对大规模预先训练模型设计的去偏置方法作为后处理步骤，可以减轻偏差的影响，同时保证模型的性能。 |
| [^14] | [Visualizing Semiotics in Generative Adversarial Networks.](http://arxiv.org/abs/2303.12731) | 该论文演示了如何利用生成对抗网络和符号学对图像进行修改，以展现非物理、抽象属性的变化，并揭示了与符号学属性相关的潜在视觉象征，有助于新的视觉概念产生。 |
| [^15] | [Toward Data-Driven Glare Classification and Prediction for Marine Megafauna Survey.](http://arxiv.org/abs/2303.12730) | 本文针对数据驱动的耀斑建模系统进行了基础建设，允许调查员预先最小化耀斑并最大限度地利用有用的图像来收集数据。 |
| [^16] | [LocalEyenet: Deep Attention framework for Localization of Eyes.](http://arxiv.org/abs/2303.12728) | 本文提出了一种名为LocalEyenet的深度学习架构，用于仅定位眼部区域，可以进行端到端的培训。该架构在堆叠的沙漏骨干上学习自我注意力，并在每个沙漏中合并了深层聚合，以最小化损失。 |
| [^17] | [Learning Fractals by Gradient Descent.](http://arxiv.org/abs/2303.12722) | 本文提出了一种通过梯度下降学习分形图像参数的方法，能够生成高质量视觉效果的分形图像，并且兼容不同的损失函数，有望为下游任务和科学理解提供新的应用。 |
| [^18] | [Non-convex approaches for low-rank tensor completion under tubal sampling.](http://arxiv.org/abs/2303.12721) | 本文提出了两种易于实现的非凸张量完成框架（TL12和TCCUR），针对管状采样的问题进行了探究，实验结果展示它们在低采样率下在时间效率和准确性方面存在折衷，且在至少某个方面优于经典完成方法。 |
| [^19] | [Toward Polar Sea-Ice Classification using Color-based Segmentation and Auto-labeling of Sentinel-2 Imagery to Train an Efficient Deep Learning Model.](http://arxiv.org/abs/2303.12719) | 本研究开发了一种基于Sentinel-2图像的颜色分割和自动标记的极地海冰分类方法，利用U-Net深度学习模型实现精准分类，为对全球变暖进行有效监测提供了技术支持。 |
| [^20] | [Strategy Synthesis in Markov Decision Processes Under Limited Sampling Access.](http://arxiv.org/abs/2303.12718) | 本文提出了一种针对灰箱 MDP 的策略综合算法，使用区间 MDP 作为内部模型，并通过强化学习，结合下置信区间探索和行动划分的方法，解决有限采样下的问题，用于合成最大化回报的实用策略。 |
| [^21] | [Geometry-Aware Latent Representation Learning for Modeling Disease Progression of Barrett's Esophagus.](http://arxiv.org/abs/2303.12711) | 本文提出了一种基于几何思想的潜在表示学习方法，用于建模Barrett食管疾病进程，与传统方法相比，具有更好的重建损失。 |
| [^22] | [Comparison of Probabilistic Deep Learning Methods for Autism Detection.](http://arxiv.org/abs/2303.12707) | 该文章研究了最先进的概率深度学习方法，用于自闭症的检测和诊断，旨在量化方法依赖于机器学习解决客观的自闭症谱系障碍行为特征的挑战。 |
| [^23] | [Multi-modal Variational Autoencoders for normative modelling across multiple imaging modalities.](http://arxiv.org/abs/2303.12706) | 本文提出了一种多模态规范建模框架，能够更好地检测出多种成像和生物变量中的异常性，特别适用于研究带有异质性的疾病。 |
| [^24] | [Open Set Action Recognition via Multi-Label Evidential Learning.](http://arxiv.org/abs/2303.12698) | 本研究提出了一种使用多标签证据学习的新方法，解决了开放集动作识别的新颖性检测问题和同一场景中单个或多个演员以及任何演员的同时动作的更一般问题。 |
| [^25] | [Adaptive Conformal Prediction by Reweighting Nonconformity Score.](http://arxiv.org/abs/2303.12695) | 该论文提出了一种新方法，利用分位数回归森林来学习非拟合分数的分布，并利用其权重分配更多的重要性给残差与测试点相似的样本，从而实现更符合模型的不确定性的预测区间。 |
| [^26] | [An Extended Study of Human-like Behavior under Adversarial Training.](http://arxiv.org/abs/2303.12669) | 对抗训练可以使模型更倾向于人类形状识别，而非仅仅利用纹理线索。在数据集中包含素描的情况下，这种变换效果仍然有效，并且在语言处理领域也适用。 |
| [^27] | [Posthoc Interpretation via Quantization.](http://arxiv.org/abs/2303.12659) | 本文提出了一种新的方法 PIQ，通过对分类器进行向量量化，将其表示转换为离散类特定的潜空间，从而解释分类器所做出的决策，并且通过研究发现该方法相比其他方法更容易让人理解。 |
| [^28] | [Reliable and Efficient Evaluation of Adversarial Robustness for Deep Hashing-Based Retrieval.](http://arxiv.org/abs/2303.12658) | 本文提出了一种名为 Pharos-guided Attack (PgA) 的攻击方法，通过设计代表良性图像语义的 Pharos 代码实现快速且可靠地进行对抗攻击，能够更全面地评估深度哈希检索模型的对抗鲁棒性。 |
| [^29] | [Robust Holographic mmWave Beamforming by Self-Supervised Hybrid Deep Learning.](http://arxiv.org/abs/2303.12653) | 本文提出一种自监督混合深度学习网络用于健壮波束成形，能够在两种不同的数据集和各种场景中表现出更强的鲁棒性。 |
| [^30] | [Traffic Volume Prediction using Memory-Based Recurrent Neural Networks: A comparative analysis of LSTM and GRU.](http://arxiv.org/abs/2303.12643) | 该论文提出了基于记忆的深度神经网络模型，可以在高度动态和异质交通环境下实时预测交通量的有效性。 |
| [^31] | [Democratising AI: Multiple Meanings, Goals, and Methods.](http://arxiv.org/abs/2303.12642) | 这篇论文探讨了AI的民主化，包括四种类型的民主化：AI使用的民主化，AI开发的民主化，AI利润的民主化，和AI治理的民主化。要想实现有效的政策和权衡讨论，需要认识到AI治理的民主化在决策中扮演着重要的角色。 |
| [^32] | [Semi-supervised counterfactual explanations.](http://arxiv.org/abs/2303.12634) | 本论文介绍了一种半监督对抗性解释的方法，通过在对抗性搜索过程中结合自编码器重构损失和将分类器的输出行为与自编码器的潜在空间连接，提高了对抗性搜索过程的速度和生成结果的解释性。 |
| [^33] | [Do Backdoors Assist Membership Inference Attacks?.](http://arxiv.org/abs/2303.12589) | 本文探讨了一种基于后门的新型成员推理攻击，通过实验发现后门并不能成功进行攻击，因为后门不能分离训练和非训练样本的损失分布。 |
| [^34] | [Neuro-Symbolic Reasoning Shortcuts: Mitigation Strategies and their Limitations.](http://arxiv.org/abs/2303.12578) | 本文讨论了神经符号推理的快捷方式带来的问题，并讨论了传统的缓解策略的局限性。 |
| [^35] | [Wasserstein Auto-encoded MDPs: Formal Verification of Efficiently Distilled RL Policies with Many-sided Guarantees.](http://arxiv.org/abs/2303.12558) | 该论文提出了一种名为WAE-MDP的潜在空间模型，可以从任何RL策略中提取形式可验证控制器，并且具有平衡控制性能和安全之间的效果和解决一些学习缺陷的多方保证。 |
| [^36] | [Deployment of Image Analysis Algorithms under Prevalence Shifts.](http://arxiv.org/abs/2303.12540) | 本文通过实证研究表明，在机器学习在医学图像分析领域的实际应用中，流行病变化对算法的部署效果有重要影响。 |
| [^37] | [DevelSet: Deep Neural Level Set for Instant Mask Optimization.](http://arxiv.org/abs/2303.12529) | DevelSet是一种GPU和深度神经网络(DNN)加速的水平集金属光刻掩模综合框架，通过引入曲率项减少掩模复杂度，并应用GPU加速来克服计算瓶颈，进一步提高可打印性和快速迭代收敛。 |
| [^38] | [Split-Et-Impera: A Framework for the Design of Distributed Deep Learning Applications.](http://arxiv.org/abs/2303.12524) | Split-Et-Impera是一种针对分布式深度学习应用程序的框架，可根据神经网络可解释性原则确定最佳的网络分割点、通过通信感知仿真进行快速评估不同的神经网络重新排列，并根据目标硬件平台的特性适应神经网络拓扑。 |
| [^39] | [Is BERT Blind? Exploring the Effect of Vision-and-Language Pretraining on Visual Language Understanding.](http://arxiv.org/abs/2303.12513) | 本文调查了视觉语言预训练对仅文本任务的表现是否有提高。作者提出了一套视觉语言理解任务，证明了多模态训练的文本编码器在视觉推理方面的优越性。 |
| [^40] | [On Domain-Specific Pre-Training for Effective Semantic Perception in Agricultural Robotics.](http://arxiv.org/abs/2303.12499) | 本文研究了如何在农业机器人的语义感知中通过特定领域的自我监督预训练以减少标签数量，并提出了一组特定领域的增强策略来更好地利用数据。 |
| [^41] | [Lower Bound on the Bayesian Risk via Information Measure.](http://arxiv.org/abs/2303.12497) | 新提出一种方法计算贝叶斯风险下界，允许使用几乎任何信息度量，能提供与估计器无关的不可能结果。已应用于离散和连续参数问题，与最先进的技术进行了比较。 |
| [^42] | [Few-shot Multimodal Multitask Multilingual Learning.](http://arxiv.org/abs/2303.12489) | 提出了一种多阶段微调框架，针对少样本多模态多任务多语言学习，可以有效地利用迁移学习和少样本学习的优势，它采用一种通用的编码器-解码器骨架，并使用注意机制处理多模态信息和每个任务的语言特定的微调，在多个基准数据集上表现优异。 |
| [^43] | [Learning Human-Inspired Force Strategies for Robotic Assembly.](http://arxiv.org/abs/2303.12440) | 该论文展示了通过从人类示范中学习概率力策略的方法，以便在机器人组装任务中对低零件间隙和位置变化做出反应，解决了从离线模拟数据学习策略无法直接在线应用的问题。 |
| [^44] | [Unsupervised Domain Adaptation for Training Event-Based Networks Using Contrastive Learning and Uncorrelated Conditioning.](http://arxiv.org/abs/2303.12424) | 发展了一种非监督域适应算法，使用对比学习和不相关条件的数据来训练深度神经网络，涉及事件相机图片分类，这种方法能够应对数据稀缺的困境，并且优于现有算法。 |
| [^45] | [Delay-Aware Hierarchical Federated Learning.](http://arxiv.org/abs/2303.12414) | 本论文提出了延迟感知的联邦学习(DFL)，通过解决边缘和云之间的通信延迟，提高了分布式机器学习模型训练的效率，并实现了一些政策以减少能量消耗和边缘到云端的通信。 |
| [^46] | [EDGI: Equivariant Diffusion for Planning with Embodied Agents.](http://arxiv.org/abs/2303.12410) | EDGI是一种基于模型的强化学习和规划算法，通过等变扩散处理内在对称性，具有更高效的采样和更好的泛化能力，适用于具有内在对称性的机器人操作任务。 |
| [^47] | [Multiscale Attention via Wavelet Neural Operators for Vision Transformers.](http://arxiv.org/abs/2303.12398) | 本文介绍了一种基于小波神经算子的多尺度注意力机制，它通过使用小波神经算子将注意力机制从局部扩展到全域和多尺度范围内，取得了比ViT和AFNO更显著的性能提高。 |
| [^48] | [Disturbance Injection under Partial Automation: Robust Imitation Learning for Long-horizon Tasks.](http://arxiv.org/abs/2303.12375) | 本文提出了一种干扰注入的鲁棒模仿学习框架，针对部分自动化下长时间任务的应用进行优化，通过变量干扰来提升学习效果。 |
| [^49] | [AIIPot: Adaptive Intelligent-Interaction Honeypot for IoT Devices.](http://arxiv.org/abs/2303.12367) | 本文提出一种使用机器学习技术的蜜罐，可以自动学习和与攻击者交互，并有效提高物联网设备的安全水平。 |
| [^50] | [ExBEHRT: Extended Transformer for Electronic Health Records to Predict Disease Subtypes & Progressions.](http://arxiv.org/abs/2303.12364) | ExBEHRT是一种扩展Transformer模型，应用于电子病历数据，将多种类型的记录包括在特征空间中，可以预测不同疾病下游任务的性能更好，并使用预期梯度对结果进行更细粒度的解释。 |
| [^51] | [Distribution-restrained Softmax Loss for the Model Robustness.](http://arxiv.org/abs/2303.12363) | 本文发现影响深度学习模型鲁棒性的因素是softmax对于非真实标签样本的值的分布特征，提出了一种分布约束的softmax损失函数以提高模型鲁棒性。 |
| [^52] | [Wasserstein Adversarial Examples on Univariant Time Series Data.](http://arxiv.org/abs/2303.12357) | 该论文为时间序列数据提出了一种新的对抗性攻击方法WPGD，利用Wasserstein距离限制正常样本和对抗性例子之间的扰动。实验结果表明该方法能够成功地对单变量时间序列数据进行对抗性攻击，并显著提高成功率。 |
| [^53] | [Training Multilayer Perceptrons by Sampling with Quantum Annealers.](http://arxiv.org/abs/2303.12352) | 本论文探索通过量子退火算法来训练多层感知机的方法，通过采样引擎实现多层感知机的训练，具有很好的研究价值。 |
| [^54] | [EasyDGL: Encode, Train and Interpret for Continuous-time Dynamic Graph Learning.](http://arxiv.org/abs/2303.12341) | EasyDGL 提出了一个易于使用的连续时间动态图学习的流水线，其中包含编码、训练和解释三个关键步骤。它使用时间点过程调制的注意力架构来处理连续时间动态图，在任务不可知的损失和任务感知损失的组合下实现动态链接预测、动态节点分类和节点流量预测，并通过敏感性分析对模型输出进行解释。 |
| [^55] | [Re-thinking Federated Active Learning based on Inter-class Diversity.](http://arxiv.org/abs/2303.12317) | 本研究提出了一种新的联邦主动学习采样策略LoGo，它能够抵御不同的本地异质性水平和全局不平衡比例，通过整合全局和仅本地查询选择器模型来解决双方不平衡。 |
| [^56] | [TsSHAP: Robust model agnostic feature-based explainability for time series forecasting.](http://arxiv.org/abs/2303.12316) | 本文提出了一种特征解释算法TsSHAP，该算法可以解释黑盒预测模型的预测结果，在可解释特征空间和预测结果之间建立了映射。这种算法可以提供局部，半局部和全局解释，能够适用于时间序列预测问题。 |
| [^57] | [Self-supervised Meta-Prompt Learning with Meta-Gradient Regularization for Few-shot Generalization.](http://arxiv.org/abs/2303.12314) | 提出了一种自我监督元提示学习框架SUPMER，包括元梯度正则化，用于少样本泛化，通过锚定的元训练任务和基于课程的任务增强丰富了任务分布，解决了在少样本情况下良好初始化软提示和过拟合的问题。 |
| [^58] | [Frozen Language Model Helps ECG Zero-Shot Learning.](http://arxiv.org/abs/2303.12311) | 该论文提出了一种名为METS的心电图分类方法，使用可训练的心电编码器和冻结的语言模型分别嵌入配对的心电图和自动生成的机器临床报告，以实现心电图零样本学习，并在两个基准心电图数据集上获得了比其他最先进的方法更好的性能。 |
| [^59] | [Logical Expressiveness of Graph Neural Network for Knowledge Graph Reasoning.](http://arxiv.org/abs/2303.12306) | 本文提出了一种理论分析图神经网络在知识图谱推理方面的逻辑表达能力的方法，并发现图神经网络可以从分级模态逻辑中捕获逻辑规则，从而设计出更好的知识图谱推理方法。 |
| [^60] | [Anomaly Detection in Aeronautics Data with Quantum-compatible Discrete Deep Generative Model.](http://arxiv.org/abs/2303.12302) | 本文探讨了在飞行操作数据异常检测中，使用量子兼容离散深度生成模型（DVAE），其中具有限制玻尔兹曼机的先验，表现出优异的性能。 |
| [^61] | [A General Algorithm for Solving Rank-one Matrix Sensing.](http://arxiv.org/abs/2303.12298) | 本文提出了一种通用算法，可以用于解决更通用的矩阵感知问题，并使用随机梯度下降设计具有可证收敛保证的高效算法。 |
| [^62] | [Prototype Helps Federated Learning: Towards Faster Convergence.](http://arxiv.org/abs/2303.12296) | 本文提出一种基于原型的联邦学习框架，可以在只对联邦学习进行少量更改的情况下，提高模型推断的性能和精度，并实现高效的通信。 |
| [^63] | [Fairness Improves Learning from Noisily Labeled Long-Tailed Data.](http://arxiv.org/abs/2303.12291) | 该研究提出了一种公平性正则化器（FR），它通过规范任意两个子群体之间的性能差距来提高长尾数据集中学习的性能，并同时避免伤害任何一个子群体。 |
| [^64] | [Adaptive Road Configurations for Improved Autonomous Vehicle-Pedestrian Interactions using Reinforcement Learning.](http://arxiv.org/abs/2303.12289) | 该论文使用强化学习方法探讨如何动态生成行人和自动驾驶汽车 ROW 计划，优化交通流的效率，为行人分配更多空间。 |
| [^65] | [Hardness of Independent Learning and Sparse Equilibrium Computation in Markov Games.](http://arxiv.org/abs/2303.12287) | 本文研究了分散式多智能体强化学习的问题，证明了在标准马尔可夫博弈框架下不存在可获得纳什均衡且可独立学习的算法。 |
| [^66] | [Reducing Air Pollution through Machine Learning.](http://arxiv.org/abs/2303.12285) | 本文介绍了一种基于机器学习的方法来将工业生产对周边城市的空气污染影响降至最低，同时保持生产活动。该方法结合了预测和指导式机器学习模型，并将环境影响减少和生产维持之间达成了多种权衡方案。 |
| [^67] | [Stochastic Nonsmooth Convex Optimization with Heavy-Tailed Noises.](http://arxiv.org/abs/2303.12277) | 本文分析了具有重尾噪声的随机非光滑凸优化问题，并填补了在函数非光滑场景下的研究空白。 |
| [^68] | [AUTO: Adaptive Outlier Optimization for Online Test-Time OOD Detection.](http://arxiv.org/abs/2303.12267) | 本文提出了一个称为AUTO的方法，在在线测试时利用未标记的在线数据直接提高OOD检测性能。该方法自适应地优化网络参数并在线检测OOD样本，取得了优于现有方法的结果。 |
| [^69] | [Challenges and opportunities for machine learning in multiscale computational modeling.](http://arxiv.org/abs/2303.12261) | 本文讨论了机器学习在复杂多尺度建模和模拟中的机遇和挑战，指出了机器学习可以作为传统数值方法的代理、加速或增强，并可以通过提供更好的初始解决方案来促进复杂的多尺度系统的解决问题。 |
| [^70] | [Information-Based Sensor Placement for Data-Driven Estimation of Unsteady Flows.](http://arxiv.org/abs/2303.12260) | 本文提出了一种基于数据驱动的流场估计的传感器选择框架，能够使用少量传感器高效地估计高攻角下机翼后流的流场。 |
| [^71] | [Encoding Binary Concepts in the Latent Space of Generative Models for Enhancing Data Representation.](http://arxiv.org/abs/2303.12255) | 本文提出了一种新的二元正则化方法以便于学习二元概念，从而提高自编码器生成数据的质量并改进模型的泛化性能。 |
| [^72] | [Exploring the Benefits of Visual Prompting in Differential Privacy.](http://arxiv.org/abs/2303.12247) | 本文探讨了在差分隐私（DP）中利用视觉提示（VP）构建神经网络分类器的好处。VP与PATE相配合，在隐私预算最小的情况下实现了最先进的隐私-效用平衡，在跨域图像分类中也显示了其优势。此外，消融研究表明VP在DP中具有很好的有效性和贡献。 |
| [^73] | [Error Analysis of Physics-Informed Neural Networks for Approximating Dynamic PDEs of Second Order in Time.](http://arxiv.org/abs/2303.12245) | 本文采用物理启发式神经网络(PINN)方法逼近一类二阶时间动力学偏微分方程(PDE)，提出一种新的损失函数形式，有效限制了逼近误差，并通过数值实验验证了新算法的有效性。 |
| [^74] | [DG-Trans: Dual-level Graph Transformer for Spatiotemporal Incident Impact Prediction on Traffic Networks.](http://arxiv.org/abs/2303.12238) | 提出了一种名为DG-Trans的交通事故影响预测框架，通过动态图学习预测交通事故的影响，包含一个双层空间变换器和一个基于重要性得分的时态变换器，成功解决了从动态图中提取异常子图或子时间序列的问题。 |
| [^75] | [Secure Aggregation in Federated Learning is not Private: Leaking User Data at Large Scale through Model Modification.](http://arxiv.org/abs/2303.12233) | 联邦学习虽然能够消除数据共享，但共享的梯度可能会包含私密信息，并且攻击者可以通过恶意修改架构和参数或使用优化从共享的梯度中近似用户数据，导致用户数据泄露。 |
| [^76] | [Infrastructure-based End-to-End Learning and Prevention of Driver Failure.](http://arxiv.org/abs/2303.12224) | 本论文介绍了一种基于循环神经网络的端到端训练方法来预测自动驾驶车辆中可能存在的故障和危险驾驶员，并在缩小的微型城市中进行了测试。 |
| [^77] | [Community detection in complex networks via node similarity, graph representation learning, and hierarchical clustering.](http://arxiv.org/abs/2303.12212) | 本文提出了三种算法框架来将层次聚类方法应用于图中的社区检测。相似度矩阵、特征向量矩阵和节点欧几里得向量表示可应用于各种基于连接的聚类算法。同时，可以采用最先进的图表示学习算法和点间互信息正向算法。 |
| [^78] | [A Random Projection k Nearest Neighbours Ensemble for Classification via Extended Neighbourhood Rule.](http://arxiv.org/abs/2303.12210) | 本文提出了一种随机投影的kNN集成分类器，使用扩展邻域规则和降维来增加基本学习者的随机性并保留特征信息。 |
| [^79] | [MAGVLT: Masked Generative Vision-and-Language Transformer.](http://arxiv.org/abs/2303.12208) | 本文提出 MGVLT 模型用于生成图像和文本序列，通过非自回归掩码预测实现了双向上下文编码和快速解码等特点。 |
| [^80] | [Policy Optimization for Personalized Interventions in Behavioral Health.](http://arxiv.org/abs/2303.12206) | 研究如何通过数字平台传递的行为健康介入最大化健康结果和治疗成本，提出了一个名为DecompPI的新算法，从离线数据进行预测任务，减轻了在线实验的需要，并在理论上证明了该算法的可扩展性和渐近收敛性。 |
| [^81] | [EZtune: A Package for Automated Hyperparameter Tuning in R.](http://arxiv.org/abs/2303.12177) | EZtune是一个可以在R中自动调整支持向量机、adaboost、梯度提升机和弹性网络等模型的软件包，具有简单易用的用户界面，适合新手或R上的统计学习模型。 |
| [^82] | [Training and Deploying Spiking NN Applications to the Mixed-Signal Neuromorphic Chip Dynap-SE2 with Rockpool.](http://arxiv.org/abs/2303.12167) | 本文介绍了一种通过优化网络参数和注入对抗性参数噪声，将SNN应用程序离线训练和部署到Dynap-SE2混合信号神经形态处理器的新方法。优化后的网络表现出很强的鲁棒性，对于硬件约束的真实世界应用程序有很大的潜力。 |
| [^83] | [Viscoelastic Constitutive Artificial Neural Networks (vCANNs) $-$ a framework for data-driven anisotropic nonlinear finite viscoelasticity.](http://arxiv.org/abs/2303.12164) | vCANNs是一种适用于有限应变下的各向异性非线性粘弹性的机器学习框架。通过广义Maxwell模型和神经网络表示非线性应变（率）相关属性，vCANNs能够自动识别广泛材料的准确且稀疏的本构模型。 |
| [^84] | [Learning a Depth Covariance Function.](http://arxiv.org/abs/2303.12157) | 该论文提出了学习深度协方差函数，并利用该方法对深度补全、捆集调整和单目密集视觉里程计等几何视觉任务进行了处理。 |
| [^85] | [Neural Pre-Processing: A Learning Framework for End-to-end Brain MRI Pre-processing.](http://arxiv.org/abs/2303.12148) | NPP是一种端到端的学习框架，可以同时解决头部MRI预处理的所有三个子任务，包括去除头骨、强度归一化和空间归一化。与最新方法相比，该模型在定量结果上表现出色，用户可以在推断时灵活控制每个任务。 |
| [^86] | [Universal Approximation Property of Hamiltonian Deep Neural Networks.](http://arxiv.org/abs/2303.12147) | 本文研究了离散化的哈密顿神经常微分方程引起的Hamiltonian深度神经网络的通用逼近能力，证明了其中的一部分流可以逐渐逼近紧致域上的任何连续函数，为实际使用提供了理论基础。 |
| [^87] | [Improving Fabrication Fidelity of Integrated Nanophotonic Devices Using Deep Learning.](http://arxiv.org/abs/2303.12136) | 本论文介绍了一种利用深度学习模型自动纠正制造误差的方法，该方法可以提高集成纳米光子器件的制造精度，从而提高其光学性能和稳定性。 |
| [^88] | [Fundamentals of Generative Large Language Models and Perspectives in Cyber-Defense.](http://arxiv.org/abs/2303.12132) | 生成式语言模型的改进引起了公众广泛关注。它们广泛应用及其真实能力揭示了它们的潜在应用，但同时也带来了对其可能的恶意用途的担忧。本文旨在提供生成式大语言模型的简要概述以及在网络防御中的应用。 |
| [^89] | [CLSA: Contrastive Learning-based Survival Analysis for Popularity Prediction in MEC Networks.](http://arxiv.org/abs/2303.12097) | 本论文提出了一种基于对比学习的移动边缘缓存网络流行度预测框架，用于解决深度神经网络在处理多内容顺序请求模式时面临的问题。 |
| [^90] | [Reply to: Inability of a graph neural network heuristic to outperform greedy algorithms in solving combinatorial optimization problems.](http://arxiv.org/abs/2303.12096) | 回复评论，认为评论聚焦于一种非典型问题且过于简化，强调了原始工作背后更广泛的算法开发以及实验数据的改进，并且指出图神经网络的内部解剖与贪心算法的本质大不相同，因此具有优势。 |
| [^91] | [Adaptive Negative Evidential Deep Learning for Open-set Semi-supervised Learning.](http://arxiv.org/abs/2303.12091) | 本文提出了ANEDL框架，应用证据深度学习量化不同类型的不确定性，并设计了新颖的适应性负优化策略，有效应对在未标记数据集中包含内部值和异常值的开放式半监督学习。 |
| [^92] | [Thrill-K Architecture: Towards a Solution to the Problem of Knowledge Based Understanding.](http://arxiv.org/abs/2303.12084) | Thrill-K架构将神经学习与不同类型的知识相结合，为解决部署端到端学习系统所需要的计算需求增加、以及缺乏灵活性、适应性、可解释性、推理和验证能力等问题提供了一种解决方案。 |
| [^93] | [Feature-adjacent multi-fidelity physics-informed machine learning for partial differential equations.](http://arxiv.org/abs/2303.11577) | 提出了一种基于特征相邻的多保真体系结构，通过共享低保真度和高保真度解决方案的特征空间来减少或消除对高精度数据的依赖，这在解决复杂问题时具有重要意义。 |
| [^94] | [Dynamic Vertex Replacement Grammars.](http://arxiv.org/abs/2303.11553) | 本文提出动态顶点替换文法（DyVeRG），它们提供一种在时间域内更新学习图文法的形式框架，用于生成和预测真实世界的动态图，同时保持了人类可解释性。 |
| [^95] | [Legs as Manipulator: Pushing Quadrupedal Agility Beyond Locomotion.](http://arxiv.org/abs/2303.11330) | 该论文展示了如何训练四足机器人使用前肢执行操纵任务，如攀爬、按下按钮和与物体交互，并使用课程学习将这些技能从模拟环境转移到真实环境中，并获得了成功的实验结果。 |
| [^96] | [Rotating without Seeing: Towards In-hand Dexterity through Touch.](http://arxiv.org/abs/2303.10880) | 本研究提出了一种新系统Touch Dexterity，通过密集二进制力传感器实现了多指机器人手不看就能旋转物体，同时大大降低了成本和与实际应用的差距。 |
| [^97] | [Interpretable Reinforcement Learning via Neural Additive Models for Inventory Management.](http://arxiv.org/abs/2303.10382) | 本文提出了一种基于神经加性模型的可解释强化学习方法，用于开发多级别供应链的动态库存订购策略，在三级供应链仿真测试中证明了实现与最先进深度强化学习方法相当的性能表现，同时具备传统策略的可解释性。 |
| [^98] | [Towards AI-controlled FES-restoration of movements: Learning cycling stimulation pattern with reinforcement learning.](http://arxiv.org/abs/2303.09986) | 本文提出了一种基于人工智能的FES康复方法，通过强化学习和详细的肌肉骨骼模型寻找循环刺激模式，并使用真实的自行车数据进行微调，该方法可由非技术人员使用而无需额外硬件或传感器。 |
| [^99] | [MedNeXt: Transformer-driven Scaling of ConvNets for Medical Image Segmentation.](http://arxiv.org/abs/2303.09975) | MedNeXt是一个定制化的现代化可扩展卷积神经网络，用于解决数据稀缺的医学环境挑战。该网络包含：完全ConvNeXt 3D编码器-解码器网络、残差ConvNeXt上下采样块和一种新的迭代增加核大小的技术。 |
| [^100] | [SemDeDup: Data-efficient learning at web-scale through semantic deduplication.](http://arxiv.org/abs/2303.09540) | SemDeDup是一种利用预训练模型的嵌入来识别和删除语义重复项的方法。通过对LAION的子集进行分析，SemDeDup可以最小化性能损失的同时删除50%的数据，实际上将训练时间减半。此外，SemDeDup在提供效率收益的同时改进了先前的方法。 |
| [^101] | [Learning Spatio-Temporal Aggregations for Large-Scale Capacity Expansion Problems.](http://arxiv.org/abs/2303.08996) | 本文提出了一种新颖的方法，用于有效解决容量扩展问题，该方法通过时空聚合解决了由于网络规模大、节点特征异构等原因而导致的问题，并优于传统方法和现有基准。 |
| [^102] | [WDiscOOD: Out-of-Distribution Detection via Whitened Linear Discriminative Analysis.](http://arxiv.org/abs/2303.07543) | 本论文提出了一种名为WDiscOOD的新型OOD检测方法，其中使用白化线性判别分析将特征投影到判别子空间和残留子空间中，确定OOD分数。在大规模ImageNet-1k基准测试和六个OOD数据集中，WDiscOOD表现出了优越的性能。 |
| [^103] | [Understanding the Diffusion Objective as a Weighted Integral of ELBOs.](http://arxiv.org/abs/2303.00848) | 本文深入理解了扩散目标，并揭示了加权损失和ELBO目标之间的直接关系。 |
| [^104] | [MFBE: Leveraging Multi-Field Information of FAQs for Efficient Dense Retrieval.](http://arxiv.org/abs/2302.11953) | 本文提出了一个双编码器的查询-FAQ匹配模型，称为MFBE，利用FAQ的多个领域组合，在模型训练和推理过程中获益，解决了诸如固有词汇差距、FAQ标题中缺乏足够的上下文等问题，具有很好的实验结果。 |
| [^105] | [Enhanced Sampling of Configuration and Path Space in a Generalized Ensemble by Shooting Point Exchange.](http://arxiv.org/abs/2302.08757) | 本文提出了一种用于模拟分子体系稀有事件的新方法，它结合了转换路径采样和配置空间的增强探索，并依靠广义集合上基于配置和轨迹空间之间的交换移动实现，该方法显著增强了转换路径采样模拟的效率。 |
| [^106] | [A numerical approximation method for the Fisher-Rao distance between multivariate normal distributions.](http://arxiv.org/abs/2302.08175) | 本论文提出了一种用于逼近多元正态分布Fisher-Rao距离的简单方法，通过离散化曲线连接正态分布并逼近相邻正态分布之间的Rao距离，评估了逼近技术的质量，同时介绍了一些信息几何性质。 |
| [^107] | [Scalable Bayesian optimization with high-dimensional outputs using randomized prior networks.](http://arxiv.org/abs/2302.07260) | 本文提出了一个基于带随机先验的神经网络的深度学习框架用于高维输出的贝叶斯优化，可有效地处理全局优化问题，即使在高维度向量空间或无限维函数空间中也能近似功能关系。 |
| [^108] | [On Penalty-based Bilevel Gradient Descent Method.](http://arxiv.org/abs/2302.05185) | 本文提出了基于惩罚的双层梯度下降算法，解决了下层非强凸约束双层问题，实验表明该算法有效。 |
| [^109] | [Membership Inference Attacks against Diffusion Models.](http://arxiv.org/abs/2302.03262) | 本文研究了扩散模型是否能够抵抗成员推断攻击，并在多个数据集上进行了实验证明其易受攻击影响，尤其是在时间步骤的中间步骤。通过引入噪声，攻击的成功率可以显著降低。 |
| [^110] | [Unconstrained Dynamic Regret via Sparse Coding.](http://arxiv.org/abs/2301.13349) | 本文探讨了在线线性优化（OLO）涉及无约束问题和动态遗憾问题的复杂性，提出了一种通过重新构造问题为稀疏编码的复杂度度量方式，在适应性和应用上有较好的应用价值。 |
| [^111] | [Guiding Online Reinforcement Learning with Action-Free Offline Pretraining.](http://arxiv.org/abs/2301.12876) | 本文研究了使用无动作离线数据集来提高在线强化学习的效率和性能的方法，提出了AF-Guide，实现变体的Upside-Down强化学习和指导在线学习的Guided SAC，实验结果表明该方法可以成功改善在离线数据集中不存在动作信息的情况下的性能。 |
| [^112] | [Sequence Generation via Subsequence Similarity: Theory and Application to UAV Identification.](http://arxiv.org/abs/2301.08403) | 本文探究了一种单次生成模型的多样性，主要聚焦于子序列相似性如何影响整个序列相似性，并通过生成子序列相似的序列来增强数据集。 |
| [^113] | [SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot.](http://arxiv.org/abs/2301.00774) | SparseGPT通过一种高效、精确的方法，能使大规模语言模型在不重新训练的情况下至少剪枝50%的稀疏度，而准确度下降很小。 |
| [^114] | [Task-Oriented Communications for NextG: End-to-End Deep Learning and AI Security Aspects.](http://arxiv.org/abs/2212.09668) | 本文探讨了在NextG无线接入网络中，通过端到端深度学习和AI安全保证信号分类任务，并在保证信号传输效率的情况下进行任务导向通信的方法。 |
| [^115] | [SDFusion: Multimodal 3D Shape Completion, Reconstruction, and Generation.](http://arxiv.org/abs/2212.04493) | 本文提出了一个多模态三维形状生成的新框架，支持图像、文本、部分观察到的形状等多种输入模式，模型具有较强的灵活性和性能表现，在目前相关工作中处于领先地位，能够将多种任务整合成一个工具，为业余用户简化了三维资源生成的流程。 |
| [^116] | [Shape-Guided Diffusion with Inside-Outside Attention.](http://arxiv.org/abs/2212.00210) | 该论文提出了一种无需训练的形状引导扩散方法，使用一种新颖的内外部注意机制将形状限制应用于跨注意力图和自注意力图上，从而在文本到图像扩散模型中考虑到对象形状，进而可以实现对象形状忠实度更高的图像生成。 |
| [^117] | [AIREPAIR: A Repair Platform for Neural Networks.](http://arxiv.org/abs/2211.15387) | AIREPAIR是一个神经网络修复平台，它能够集成现有网络修复工具并实现不同方法的公平比较，评估结果表明其实用性。 |
| [^118] | [Solving Bilevel Knapsack Problem using Graph Neural Networks.](http://arxiv.org/abs/2211.13436) | 本研究提出了一种使用图神经网络的深度学习方法来解决双层背包问题，该方法比精确算法快500倍，可找到可行性解决方案。 |
| [^119] | [{\mu}Split: efficient image decomposition for microscopy data.](http://arxiv.org/abs/2211.12872) | uSplit是一种适用于荧光显微镜图像的高效图像分解方法，集成了横向上下文化，帮助训练更深的分层模型，并有效地减少平铺伪影问题。 |
| [^120] | [EfficientTrain: Exploring Generalized Curriculum Learning for Training Visual Backbones.](http://arxiv.org/abs/2211.09703) | 本文提出了一种泛化课程学习方法，用于高效训练视觉主干网络，通过优先让模型学习“更容易学习”的模式，不断引入更难的模式，从而加速训练过程。 |
| [^121] | [Unbiased Supervised Contrastive Learning.](http://arxiv.org/abs/2211.05568) | 本文提出了一种新的监督对比损失形式（epsilon-SupInfoNCE）以及一种新的去偏正则化损失（FairKL），旨在解决从有偏数据中学习无偏模型的问题。 |
| [^122] | [A physics-aware deep learning model for energy localization in multiscale shock-to-detonation simulations of heterogeneous energetic materials.](http://arxiv.org/abs/2211.04561) | 本研究提出了一种应用深度学习的多尺度模型，可以准确地模拟异质高能材料在震爆转变过程中的能量释放和灵敏性。模型使用物理学知识训练了循环卷积神经网络来准确定位微观结构内的热点点火和生长，从而提高计算效率和准确性。 |
| [^123] | [GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers.](http://arxiv.org/abs/2210.17323) | 本文提出了一种名为GPTQ的新型一次性权重量化方法，可在高度准确和高度有效的同时将比特宽度降至每个权重3或4位，适用于巨大的GPT模型。 |
| [^124] | [An Experimental Study of Dimension Reduction Methods on Machine Learning Algorithms with Applications to Psychometrics.](http://arxiv.org/abs/2210.13230) | 本文主要研究了心理测量学领域最近开发的探索性图分析（EGA）和唯一变量分析（UVA）等两种降维技术与机器学习文献中常见的两种降维技术（主成分分析和独立成分分析）在减少数据维度方面的效果，并发现降维可能会降低、提高或者不影响变量的准确性。 |
| [^125] | [Auto-Encoder Neural Network Incorporating X-Ray Fluorescence Fundamental Parameters with Machine Learning.](http://arxiv.org/abs/2210.12239) | 本研究开发了一种神经网络模型，结合领域知识，可以在缺乏标记数据的情况下进行X射线荧光分析，适用于矿山等实际场景。 |
| [^126] | [Orthogonal Non-negative Matrix Factorization: a Maximum-Entropy-Principle Approach.](http://arxiv.org/abs/2210.02672) | 本文提出了一种新的解决正交非负矩阵分解问题的方法，该方法使用了基于最大熵原则的解决方案，并保证了矩阵的正交性和稀疏性以及非负性。该方法在不影响近似质量的情况下具有较好的性能速度和优于文献中类似方法的稀疏性、正交性。 |
| [^127] | [On The Effects Of Data Normalisation For Domain Adaptation On EEG Data.](http://arxiv.org/abs/2210.01081) | 本文研究了数据标准化对脑电领域适应的影响，并在三个EEG数据集上进行了实验评估。 |
| [^128] | [Efficient Multi-view Clustering via Unified and Discrete Bipartite Graph Learning.](http://arxiv.org/abs/2209.04187) | 本文提出了一种高效的多视图聚类方法，通过基于锚点的子空间学习、双向图学习和离散优化实现了单视图和一致性图的联合学习，避免了高计算复杂度，并在多个数据集上取得了优异的性能表现。 |
| [^129] | [The Alberta Plan for AI Research.](http://arxiv.org/abs/2208.11173) | 阿尔伯塔计划是一项人工智能研究计划，在阿尔伯塔的研究团队及全球志同道合的人士中进行，旨在探索AI的研究方法和应用。 |
| [^130] | [Matrix Completion with Cross-Concentrated Sampling: Bridging Uniform Sampling and CUR Sampling.](http://arxiv.org/abs/2208.09723) | 本文提出了一种名为跨度集中采样（CCS）的新型采样策略，可提供额外的灵活性来节省真实应用中的采样成本。作者还提供了CCS矩阵补全的充分条件，并提出了一种高效的非凸算法ICURC。数值实验验证了CCS和ICURC优于均匀采样和基线算法。 |
| [^131] | [Long-term Causal Effects Estimation via Latent Surrogates Representation Learning.](http://arxiv.org/abs/2208.04589) | Laser 是一种基于潜在代理表示学习的估计长期因果效应的灵活方法，能够在代理和其代理混合在一起的真实世界情景中应用。 |
| [^132] | [MobileNeRF: Exploiting the Polygon Rasterization Pipeline for Efficient Neural Field Rendering on Mobile Architectures.](http://arxiv.org/abs/2208.00277) | 这篇论文提出了一种在移动设备上高效呈现神经现场的方法，通过使用纹理多边形而不是基于射线行进的体积渲染算法，并且利用传统渲染管线中的 z-缓冲器，使得 NeRF 可以通过像素级并行性来实现在移动设备上交互式帧速率。 |
| [^133] | [Safe Exploration Incurs Nearly No Additional Sample Complexity for Reward-free RL.](http://arxiv.org/abs/2206.14057) | 本文提出 Safe reWard-frEe ExploraTion (SWEET)框架，在RF-RL任务中可将安全约束和探索效率同时实现，使得安全探索几乎不会增加额外的样本复杂度。 |
| [^134] | [LargeKernel3D: Scaling up Kernels in 3D Sparse CNNs.](http://arxiv.org/abs/2206.10555) | LargeKernel3D是一种解决直接应用大型卷积核在3D CNN中遇到困难的方法，通过提出空间分区卷积和其大核模块来避免优化和效率问题。该网络在多项3D任务中具有很好的表现，包括在语义分割和物体检测基准测试中分别取得了高分数，并可以在 Waymo 3D 物体检测中扩展到17x17x17的核大小。 |
| [^135] | [Estimating the randomness of quantum circuit ensembles up to 50 qubits.](http://arxiv.org/abs/2205.09900) | 本文提出了一个基于张量网络的算法，用于评估随机电路集合与精确随机性之间的距离，该算法复杂度对于浅层电路具有多项式时间，在局部和并行随机电路中验证了复杂度线性增长，同时可以在变分算法中解决“贫瘠高原”问题。 |
| [^136] | [New-Onset Diabetes Assessment Using Artificial Intelligence-Enhanced Electrocardiography.](http://arxiv.org/abs/2205.02900) | 本研究表明，使用人工智能增强的心电图可以有效地识别新发糖尿病成人患者，相较于传统的ADA风险检测方法，该方法具有更好的准确性和特异性。 |
| [^137] | [Fix the Noise: Disentangling Source Feature for Transfer Learning of StyleGAN.](http://arxiv.org/abs/2204.14079) | 本文提出了一种新的方法“FixNoise”，在StyleGAN的迁移学习中引入了简单的特征匹配损失来改善生成质量，并在目标特征空间的一部分中仅保留源特征以控制源特征的程度。实验证明其在领域翻译和属性编辑中的有效性。 |
| [^138] | [Causal Reasoning Meets Visual Representation Learning: A Prospective Study.](http://arxiv.org/abs/2204.12037) | 这项论文讨论了视觉表征学习中缺乏解释性，鲁棒性和泛化性的问题，并提出了因果推理范式来实现这些属性。 |
| [^139] | [CgAT: Center-Guided Adversarial Training for Deep Hashing-Based Retrieval.](http://arxiv.org/abs/2204.10779) | 本文提出了CgAT方法，基于中心引导的对抗性训练方法，可提升深度Hashing网络检索的鲁棒性，取得了领先于现有方法的效果。 |
| [^140] | [Learning Stationary Nash Equilibrium Policies in $n$-Player Stochastic Games with Independent Chains.](http://arxiv.org/abs/2201.12224) | 本文针对一个$n$人随机博弈的子类，设计了多项式时间的学习算法，可以学习出$\epsilon$-NE策略，在奖励函数为社会凸性的情况下具有多项式复杂度上限。 |
| [^141] | [Joint Liver and Hepatic Lesion Segmentation in MRI using a Hybrid CNN with Transformer Layers.](http://arxiv.org/abs/2201.10981) | 本文提出了一种名为SWTR-Unet的混合网络，它通过将卷积和基于Transformer的结构元素相结合，实现了MRI中肝脏和肝部损伤联合分割的高效、精确和可靠。该网络在单模态和多模态数据上都具有超过最新方法的表现。 |
| [^142] | [Dynamic Relevance Learning for Few-Shot Object Detection.](http://arxiv.org/abs/2108.02235) | 本研究提出了一种动态关联学习模型来进行少样本目标检测。该模型利用所有支持图像和查询图像上的感兴趣区域之间的关系来构建动态GCN，并适应不同的任务。 |
| [^143] | [Near-optimal inference in adaptive linear regression.](http://arxiv.org/abs/2107.02266) | 本文提出了一些在线去偏估计的方法来修正自适应线性回归中的渐近偏差，利用数据集中的协方差结构提供更锐利的估计。 |
| [^144] | [Active Learning for Deep Neural Networks on Edge Devices.](http://arxiv.org/abs/2106.10836) | 本研究提出了一个通用的任务无关框架，用于边缘设备上的深度神经网络的主动学习问题，可以有效减少标记和通信成本，并保证解的质量。 |
| [^145] | [RoBIC: A benchmark suite for assessing classifiers robustness.](http://arxiv.org/abs/2102.05368) | RoBIC是一个无参数基准测试套件，用于公正地评估图像分类器的鲁棒性，独立于准确性，并可以评估其对白盒和黑盒攻击的鲁棒性。 |

# 详细

[^1]: 开源框架语义解析

    Open-source Frame Semantic Parsing. (arXiv:2303.12788v1 [cs.CL])

    [http://arxiv.org/abs/2303.12788](http://arxiv.org/abs/2303.12788)

    本文介绍了一个开源Python库Frame Semantic Transformer，该库用于框架语义解析，并在易用性和性能方面实现接近最新水平，可通过在推理时使用FrameNet词汇单元来提高性能，并通过在训练期间使用文本数据增强来提高对真实世界数据的稳健性。

    

    虽然最近几年来框架语义解析的最新技术取得了显著进展，但对于终端用户来说，将最新模型应用于实践仍然很困难。为了解决这个问题，我们提出了Frame Semantic Transformer，这是一个开源Python库，可以在关注易用性的同时，在FrameNet 1.7上实现接近最新水平的性能。我们使用一个在Propbank和FrameNet示例上微调的T5模型作为基础，并通过在推理时使用FrameNet词汇单元为T5提供提示来提高性能。我们通过在训练期间使用文本数据增强来提高对真实世界数据的稳健性。

    While the state-of-the-art for frame semantic parsing has progressed dramatically in recent years, it is still difficult for end-users to apply state-of-the-art models in practice. To address this, we present Frame Semantic Transformer, an open-source Python library which achieves near state-of-the-art performance on FrameNet 1.7, while focusing on ease-of-use. We use a T5 model fine-tuned on Propbank and FrameNet exemplars as a base, and improve performance by using FrameNet lexical units to provide hints to T5 at inference time. We enhance robustness to real-world data by using textual data augmentations during training.
    
[^2]: 熵正则化强化学习的莫特里卡多策略梯度：收敛性与全局最优性

    Matryoshka Policy Gradient for Entropy-Regularized RL: Convergence and Global Optimality. (arXiv:2303.12785v1 [cs.LG])

    [http://arxiv.org/abs/2303.12785](http://arxiv.org/abs/2303.12785)

    本文介绍了一种新的策略梯度算法——莫特里卡多策略梯度(MPG)，该算法尤其在最大熵强化学习中表现突出，能够实现一系列策略的训练和学习以达到任务的最优化，具有极高的收敛性和全局最优性。

    

    本文介绍并研究了一种新的策略梯度算法——莫特里卡多策略梯度(MPG)，在最大熵强化学习的背景下，代理目标是最大化除了累计奖励外的熵奖励。MPG与标准PG的不同之处在于它训练一系列策略同时学习有限的任务，而不是针对单一的标准目标训练一个单一的策略。对于softmax策略，我们证明了MPG的收敛性和极限的全局最优性，通过证明MPG目标的唯一临界点是最优策略；即使在连续紧致状态空间的情况下，这些结果仍然成立。MPG直观、理论上Sound，我们进一步展示了标准最大熵目标的最优策略可以通过MPG框架的最优策略进行任意精度的逼近。最后，我们证明了在策略用神经网络参数化的情况下，MPG非常适合。

    A novel Policy Gradient (PG) algorithm, called Matryoshka Policy Gradient (MPG), is introduced and studied, in the context of max-entropy reinforcement learning, where an agent aims at maximising entropy bonuses additional to its cumulative rewards. MPG differs from standard PG in that it trains a sequence of policies to learn finite horizon tasks simultaneously, instead of a single policy for the single standard objective. For softmax policies, we prove convergence of MPG and global optimality of the limit by showing that the only critical point of the MPG objective is the optimal policy; these results hold true even in the case of continuous compact state space. MPG is intuitive, theoretically sound and we furthermore show that the optimal policy of the standard max-entropy objective can be approximated arbitrarily well by the optimal policy of the MPG framework. Finally, we justify that MPG is well suited when the policies are parametrized with neural networks and we provide an simp
    
[^3]: 基于现代 Hopfield 网络的时间序列一致性预测方法

    Conformal Prediction for Time Series with Modern Hopfield Networks. (arXiv:2303.12783v1 [cs.LG])

    [http://arxiv.org/abs/2303.12783](http://arxiv.org/abs/2303.12783)

    该论文提出了一种名为 HopCPT 的新一致性时间序列预测方法，不仅能够处理时间结构，而且能够利用其优势，已在多种真实世界的时间序列数据集上证明了优于现有方法的性能。

    

    为了量化不确定性，一致性预测方法受到越来越多的关注，并已成功应用于各个领域。然而，它们难以应用于时间序列，因为时间序列的自相关结构违反了一致性预测所需的基本假设。我们提出了 HopCPT，一种新的基于 Hopfield 网络的时间序列一致性预测方法，不仅能够应对时间结构，而且能够利用它们。我们证明了我们的方法在存在时间依赖性的时间序列中在理论上是有很好的理论基础的。在实验中，我们证明了我们的新方法在四个不同领域的多个真实世界时间序列数据集上优于现有的最先进的一致性预测方法。

    To quantify uncertainty, conformal prediction methods are gaining continuously more interest and have already been successfully applied to various domains. However, they are difficult to apply to time series as the autocorrelative structure of time series violates basic assumptions required by conformal prediction. We propose HopCPT, a novel conformal prediction approach for time series that not only copes with temporal structures but leverages them. We show that our approach is theoretically well justified for time series where temporal dependencies are present. In experiments, we demonstrate that our new approach outperforms state-of-the-art conformal prediction methods on multiple real-world time series datasets from four different domains.
    
[^4]: 我们能相信ChatGPT的评估吗？

    Can we trust the evaluation on ChatGPT?. (arXiv:2303.12767v1 [cs.CL])

    [http://arxiv.org/abs/2303.12767](http://arxiv.org/abs/2303.12767)

    本文讨论了ChatGPT评估中面临的数据污染挑战，通过倾向性检测任务阐述了这一问题，并探讨了如何在闭合且持续训练模型的时代确保模型评估的公平性。

    

    ChatGPT是第一个被广泛采纳的大型语言模型，展示出在多项自然语言任务中卓越的表现。但是，由于模型的闭合性以及通过强化学习和人类反馈不断更新，评估ChatGPT在不同问题领域的表现仍然具有挑战性。本文重点讨论了在ChatGPT的评估中存在的数据污染问题，并使用倾向性检测任务作为案例进行了说明。我们还讨论了如何在闭合和持续训练模型的时代，避免数据污染和确保公平的模型评估的挑战。

    ChatGPT, the first large language model (LLM) with mass adoption, has demonstrated remarkable performance in numerous natural language tasks. Despite its evident usefulness, evaluating ChatGPT's performance in diverse problem domains remains challenging due to the closed nature of the model and its continuous updates via Reinforcement Learning from Human Feedback (RLHF). We highlight the issue of data contamination in ChatGPT evaluations, with a case study of the task of stance detection. We discuss the challenge of preventing data contamination and ensuring fair model evaluation in the age of closed and continuously trained models.
    
[^5]: 考虑视频会议通话中的时间失真的基于LSTM的视频质量预测

    LSTM-based Video Quality Prediction Accounting for Temporal Distortions in Videoconferencing Calls. (arXiv:2303.12761v1 [eess.IV])

    [http://arxiv.org/abs/2303.12761](http://arxiv.org/abs/2303.12761)

    本文提出了一种基于数据的方法，通过训练一个LSTM模型实现了对视频会议通话中出现的时间失真的建模，并成功预测了视频质量，其中模型的每帧输出可以详细分析视频质量损失的原因。

    

    目前的视频质量模型（例如VMAF）能够通过将降质视频与参考视频进行比较，获得出色的预测结果。然而，它们没有考虑视频会议通话期间发生的时间失真（例如帧冻结或跳跃）。本文提出了一种数据驱动方法，通过使用经由群众智慧标记的主观质量评分训练LSTM自动建模这种失真。我们从83种不同的网络情况下的实时视频会议中收集了视频。我们在源视频上应用QR码作为标记来创建对齐的参考视频，并根据对齐向量计算时间特征。结合VMAF核心特征，我们提出的模型使用这些特征实现了验证集上0.99的PCC。此外，我们的模型输出每帧质量，可以详细解析导致视频质量损失的原因。VCM模型和数据集在https://github.com/micr上开源。

    Current state-of-the-art video quality models, such as VMAF, give excellent prediction results by comparing the degraded video with its reference video. However, they do not consider temporal distortions (e.g., frame freezes or skips) that occur during videoconferencing calls. In this paper, we present a data-driven approach for modeling such distortions automatically by training an LSTM with subjective quality ratings labeled via crowdsourcing. The videos were collected from live videoconferencing calls in 83 different network conditions. We applied QR codes as markers on the source videos to create aligned references and compute temporal features based on the alignment vectors. Using these features together with VMAF core features, our proposed model achieves a PCC of 0.99 on the validation set. Furthermore, our model outputs per-frame quality that gives detailed insight into the cause of video quality impairments. The VCM model and dataset are open-sourced at https://github.com/micr
    
[^6]: 关于设备端无监督图像分割

    On-Device Unsupervised Image Segmentation. (arXiv:2303.12753v1 [cs.CV])

    [http://arxiv.org/abs/2303.12753](http://arxiv.org/abs/2303.12753)

    本文提出了一种替代方法来解决缺乏标记数据的问题，即开发在边缘设备上执行的高效无监督分割，基于作者的观察，当像素映射到高维空间时，分割可以获得高性能。

    

    随着卷积神经网络的突破，以学习为基础的分割已经在许多研究中出现。它们中的大多数都基于监督学习，需要大量的标记数据；然而，为支持分割，需要每个像素的标签，这显然是昂贵的。因此，缺乏注释分割数据的问题通常存在。连续学习是解决这个问题的一种有前途的方式，但它仍然对人工标注有很高的要求。而且，隐私对于现实世界中的分割数据非常重要，这进一步要求进行设备端的学习。在本文中，我们旨在以一种替代的方式解决上述问题：我们提出开发高效的无监督分割，可在边缘设备上执行，而不是监督式分割。基于我们的观察，当像素映射到高维空间时，分割可以获得高性能。

    Along with the breakthrough of convolutional neural networks, learning-based segmentation has emerged in many research works. Most of them are based on supervised learning, requiring plenty of annotated data; however, to support segmentation, a label for each pixel is required, which is obviously expensive. As a result, the issue of lacking annotated segmentation data commonly exists. Continuous learning is a promising way to deal with this issue; however, it still has high demands on human labor for annotation. What's more, privacy is highly required in segmentation data for real-world applications, which further calls for on-device learning. In this paper, we aim to resolve the above issue in an alternative way: Instead of supervised segmentation, we propose to develop efficient unsupervised segmentation that can be executed on edge devices. Based on our observation that segmentation can obtain high performance when pixels are mapped to a high-dimension space, we for the first time b
    
[^7]: 大型视觉语言模型零样本推理中的校准方法研究

    Enabling Calibration In The Zero-Shot Inference of Large Vision-Language Models. (arXiv:2303.12748v1 [cs.CV])

    [http://arxiv.org/abs/2303.12748](http://arxiv.org/abs/2303.12748)

    本文研究了零样本推理中视觉语言模型的校准问题，发现CLIP存在误校准，并提出了一种修改版的温度缩放方法，可以适用于每个特定的CLIP模型。

    

    深度学习模型的校准对于保证其可靠性和安全使用是至关重要的，因此在监督分类模型中对其进行了广泛研究，提出了降低误校准的方法。然而，视觉语言模型在进行零样本推理时的校准尚未得到全面的研究，例如CLIP。本研究衡量了跨相关变量（如提示，数据集和架构）的校准情况，并发现CLIP的零样本推理存在误校准。此外，我们提出了一种修改版的温度缩放方法，与CLIP作为零样本推理模型的常见用例相一致，并展示出单个学习的温度值可以广泛适用于每个特定的CLIP模型（由选定的预训练数据集和架构定义），跨不同的推理数据集和提示选择。

    Calibration of deep learning models is crucial to their trustworthiness and safe usage, and as such, has been extensively studied in supervised classification models, with methods crafted to decrease miscalibration. However, there has yet to be a comprehensive study of the calibration of vision-language models that are used for zero-shot inference, like CLIP. We measure calibration across relevant variables like prompt, dataset, and architecture, and find that zero-shot inference with CLIP is miscalibrated. Furthermore, we propose a modified version of temperature scaling that is aligned with the common use cases of CLIP as a zero-shot inference model, and show that a single learned temperature generalizes for each specific CLIP model (defined by a chosen pre-training dataset and architecture) across inference dataset and prompt choice.
    
[^8]: 少即是多：最少的手动分割下，无监督掩模引导CT图像合成

    Less is More: Unsupervised Mask-guided Annotated CT Image Synthesis with Minimum Manual Segmentations. (arXiv:2303.12747v1 [eess.IV])

    [http://arxiv.org/abs/2303.12747](http://arxiv.org/abs/2303.12747)

    本文提出了一种新颖的医学图像合成策略——无监督掩模引导合成，能够在最小手动分割的情况下，获得合成图像和分割，有效地避免了分割掩模数量不足、标签不准确等问题。

    

    作为一种实用的数据增强工具，数据合成通常会为基于深度学习的医学图像分析带来更好的表现。然而，为合成的医学图像生成相应的分割掩模是费力和主观的。为了获得配对的合成医学图像和分割，提出了使用分割掩模作为合成条件的条件生成模型。然而，这些分割掩模条件下的生成模型仍然依赖于大量的、多样化的、标记的训练数据集，并且只能提供有限的人体解剖结构约束，导致图像特征不真实。此外，不变的像素级条件可能会减少合成病变的多样性，从而降低数据增强的效果。为了解决这些问题，本文提出了一种新的医学图像合成策略，即无监督掩模引导合成，以获得合成图像和分割。

    As a pragmatic data augmentation tool, data synthesis has generally returned dividends in performance for deep learning based medical image analysis. However, generating corresponding segmentation masks for synthetic medical images is laborious and subjective. To obtain paired synthetic medical images and segmentations, conditional generative models that use segmentation masks as synthesis conditions were proposed. However, these segmentation mask-conditioned generative models still relied on large, varied, and labeled training datasets, and they could only provide limited constraints on human anatomical structures, leading to unrealistic image features. Moreover, the invariant pixel-level conditions could reduce the variety of synthetic lesions and thus reduce the efficacy of data augmentation. To address these issues, in this work, we propose a novel strategy for medical image synthesis, namely Unsupervised Mask (UM)-guided synthesis, to obtain both synthetic images and segmentations
    
[^9]: DR.CPO：通过迭代构建、随机放置和 HPR 遮蔽实现的多样化和逼真的三维增强

    DR.CPO: Diversified and Realistic 3D Augmentation via Iterative Construction, Random Placement, and HPR Occlusion. (arXiv:2303.12743v1 [cs.CV])

    [http://arxiv.org/abs/2303.12743](http://arxiv.org/abs/2303.12743)

    该论文提出了一种多样化和逼真的增强方法，可以创建整体对象并灵活地定位和旋转对象，并相应地应用自遮挡和外遮挡。通过迭代构建多个对象来提高整体对象构造的多样性，构造的对象可以在训练帧中随机放置和旋转。

    

    在自动驾驶中，数据增强常用于改进三维物体检测。最基本的方法包括插入复制对象和旋转和缩放整个训练帧。也已经开发了许多变体。然而，现有方法与现实世界的可能性相比相当有限。在这项工作中，我们开发了一种多样化和逼真增强方法，可以灵活地构造整体对象，自由地定位和旋转对象，并相应地应用自遮挡和外遮挡。为了提高整体对象构造的多样性，我们开发了一种迭代方法，将从现实世界观察到的多个对象随机组合成单个对象。与现有增强方法不同的是，构造的对象可以随机放置和旋转在训练帧中，因为适当的遮挡可以反映在最终整体对象中。最后，为了防止过度增强导致过拟合，我们介绍了一种分层遮挡概率设置，通过对象的位置和大小调整遮挡强度。

    In autonomous driving, data augmentation is commonly used for improving 3D object detection. The most basic methods include insertion of copied objects and rotation and scaling of the entire training frame. Numerous variants have been developed as well. The existing methods, however, are considerably limited when compared to the variety of the real world possibilities. In this work, we develop a diversified and realistic augmentation method that can flexibly construct a whole-body object, freely locate and rotate the object, and apply self-occlusion and external-occlusion accordingly. To improve the diversity of the whole-body object construction, we develop an iterative method that stochastically combines multiple objects observed from the real world into a single object. Unlike the existing augmentation methods, the constructed objects can be randomly located and rotated in the training frame because proper occlusions can be reflected to the whole-body objects in the final step. Fina
    
[^10]: 借助机器学习提高宏观交通流量模型：基础图像的倒转和边界条件的预测

    Inverting the Fundamental Diagram and Forecasting Boundary Conditions: How Machine Learning Can Improve Macroscopic Models for Traffic Flow. (arXiv:2303.12740v1 [cs.LG])

    [http://arxiv.org/abs/2303.12740](http://arxiv.org/abs/2303.12740)

    本文尝试将机器学习和宏观微分模型相结合，借以提高交通流量模型的准确性，通过利用基于LSTM递归神经网络的机器学习模型得出拥堵情况和未来30分钟内通过传感器的车辆总数，进而提高模型的精度，并倒转基础图像以恢复与流量-密度关系相关的信息。

    

    本文旨在开发新方法将机器学习技术与宏观微分模型相结合，用于车辆交通的估计和预测。本文考虑了一组数据，包括通过定点传感器收集的车辆通量和速度数据，并按车道和车辆类型进行分类。利用基于LSTM递归神经网络的机器学习模型，我们推断出两个重要信息：1）是否在传感器下出现拥堵，2）在未来30分钟内将通过传感器的车辆总数。然后利用这些信息来提高基于LWR的一阶多类模型的准确性，该模型描述了传感器之间的交通流动。第一个信息被用来倒转（凹形）基础图像，从而恢复与该段路段相关的流量-密度关系。

    In this paper, we aim at developing new methods to join machine learning techniques and macroscopic differential models for vehicular traffic estimation and forecast. It is well known that data-driven and model-driven approaches have (sometimes complementary) advantages and drawbacks. We consider here a dataset with flux and velocity data of vehicles moving on a highway, collected by fixed sensors and classified by lane and by class of vehicle. By means of a machine learning model based on an LSTM recursive neural network, we extrapolate two important pieces of information: 1) if congestion is appearing under the sensor, and 2) the total amount of vehicles which is going to pass under the sensor in the next future (30 min). These pieces of information are then used to improve the accuracy of an LWR-based first-order multi-class model describing the dynamics of traffic flow between sensors. The first piece of information is used to invert the (concave) fundamental diagram, thus recoveri
    
[^11]: 采用潜空间操作来优化CAD模型

    Optimizing CAD Models with Latent Space Manipulation. (arXiv:2303.12739v1 [cs.CV])

    [http://arxiv.org/abs/2303.12739](http://arxiv.org/abs/2303.12739)

    本文介绍了一种利用潜空间操作优化CAD模型的方法，扩展了StyleCLIP来适用于体素模型形式的CAD模型，能够优化实际CAD模型的自动化能力。

    

    当涉及到自动化领域中CAD模型的优化时，神经网络目前只起到了较小的作用。优化抽象特性如自动化能力是具有挑战性的，因为它们很难被模拟，对于基于规则的系统来说过于复杂，而且机器学习方法缺乏数据。另一方面，像StyleCLIP这样的可操纵图像中的抽象特征方法已经取得了很大的成功。它们依赖于预训练生成对抗性网络的潜空间，并且因此也可以利用大量未标记的CAD数据。在本文中，我们展示了这种方法也适用于优化CAD零件的抽象自动化相关特征。我们通过扩展StyleCLIP以适用于体素模型形式的CAD模型实现了这一点，其中包括使用3D StyleGAN和自定义分类器。最后，我们演示了我们的系统通过优化实际CAD模型的自动化能力而具备的能力。

    When it comes to the optimization of CAD models in the automation domain, neural networks currently play only a minor role. Optimizing abstract features such as automation capability is challenging, since they can be very difficult to simulate, are too complex for rule-based systems, and also have little to no data available for machine-learning methods. On the other hand, image manipulation methods that can manipulate abstract features in images such as StyleCLIP have seen much success. They rely on the latent space of pretrained generative adversarial networks, and could therefore also make use of the vast amount of unlabeled CAD data. In this paper, we show that such an approach is also suitable for optimizing abstract automation-related features of CAD parts. We achieved this by extending StyleCLIP to work with CAD models in the form of voxel models, which includes using a 3D StyleGAN and a custom classifier. Finally, we demonstrate the ability of our system for the optimiziation o
    
[^12]: DPPMask：基于确定性点过程的遮盖图像建模方法

    DPPMask: Masked Image Modeling with Determinantal Point Processes. (arXiv:2303.12736v1 [cs.CV])

    [http://arxiv.org/abs/2303.12736](http://arxiv.org/abs/2303.12736)

    本文提出了一种简单有效的遮盖图像建模方法DPPMask，用确定性点过程（DPPs）替换了随机过程以减少遮盖后图像的语义变化，从而在多个基准数据集上显著改善了代表性能。

    

    遮盖图像建模（MIM）旨在重建随机遮盖的图像，并已取得了令人瞩目的代表性能。尽管具有实证效果，但大多数先前的工作忽略了一个重要事实，即强制模型重建超出恢复范围的物体（如那些被遮盖的物体）是不合理的。本文中，我们展示了先前工作中广泛使用的均匀随机遮盖不可避免地丢失一些关键物体并更改原始语义信息，从而导致了一种不对齐问题并最终伤害了代表性学习。为了解决这个问题，我们将确定性点过程（DPPs）替换为随机过程，提出了一个新的遮盖策略，即DPPMask，以减少遮盖后图像的语义变化。我们的方法简单而有效，实现时不需要额外的可学习参数。我们特别在两个代表性的MIM框架，MASK和GMS上对我们的方法进行了评估，结果在几个基准数据集上显著改善了代表性能。

    Masked Image Modeling (MIM) has achieved impressive representative performance with the aim of reconstructing randomly masked images. Despite the empirical success, most previous works have neglected the important fact that it is unreasonable to force the model to reconstruct something beyond recovery, such as those masked objects. In this work, we show that uniformly random masking widely used in previous works unavoidably loses some key objects and changes original semantic information, resulting in a misalignment problem and hurting the representative learning eventually. To address this issue, we augment MIM with a new masking strategy namely the DPPMask by substituting the random process with Determinantal Point Process (DPPs) to reduce the semantic change of the image after masking. Our method is simple yet effective and requires no extra learnable parameters when implemented within various frameworks. In particular, we evaluate our method on two representative MIM frameworks, MA
    
[^13]: 多模态偏差：引入一种框架以评估视觉语言模型中的刻板印象偏差，超越性别和种族。

    MultiModal Bias: Introducing a Framework for Stereotypical Bias Assessment beyond Gender and Race in Vision Language Models. (arXiv:2303.12734v1 [cs.CV])

    [http://arxiv.org/abs/2303.12734](http://arxiv.org/abs/2303.12734)

    本文提出了一个视觉和文本偏置基准MMBias，涵盖14个人口子群，并利用该基准评估了多个自我监督多模态模型（包括CLIP、ALBEF和ViLT），结果表明这些模型表现出偏向某些群体的有意义的偏见。同时，本文引入了一种针对大规模预先训练模型设计的去偏置方法作为后处理步骤，可以减轻偏差的影响，同时保证模型的性能。

    

    最近自主训练的突破为一类预先训练的视觉语言模型带来了新的机遇。虽然对多模态模型中的偏见进行了一些调查，但主要集中在性别和种族偏见上，对于其他相关群体，如宗教、国籍、性取向或残疾人群，给予的关注较少，这主要是由于缺乏适当的基准。我们通过提供一个称为MMBias的视觉和文本偏差基准来解决这一差距，包括约3800个图像和短语，涵盖14个人口子群。我们利用这个数据集来评估几个著名的自我监督多模态模型，包括CLIP、ALBEF和ViLT。我们的结果显示，这些模型表现出有意义的偏差，偏向某些群体。最后，我们引入了一种针对这种大规模预先训练模型设计的去偏置方法，可以作为后处理步骤应用于减轻偏差，同时保持模型性能。

    Recent breakthroughs in self supervised training have led to a new class of pretrained vision language models. While there have been investigations of bias in multimodal models, they have mostly focused on gender and racial bias, giving much less attention to other relevant groups, such as minorities with regard to religion, nationality, sexual orientation, or disabilities. This is mainly due to lack of suitable benchmarks for such groups. We seek to address this gap by providing a visual and textual bias benchmark called MMBias, consisting of around 3,800 images and phrases covering 14 population subgroups. We utilize this dataset to assess bias in several prominent self supervised multimodal models, including CLIP, ALBEF, and ViLT. Our results show that these models demonstrate meaningful bias favoring certain groups. Finally, we introduce a debiasing method designed specifically for such large pre-trained models that can be applied as a post-processing step to mitigate bias, while p
    
[^14]: 生成对抗网络中符号学的可视化

    Visualizing Semiotics in Generative Adversarial Networks. (arXiv:2303.12731v1 [cs.CV])

    [http://arxiv.org/abs/2303.12731](http://arxiv.org/abs/2303.12731)

    该论文演示了如何利用生成对抗网络和符号学对图像进行修改，以展现非物理、抽象属性的变化，并揭示了与符号学属性相关的潜在视觉象征，有助于新的视觉概念产生。

    

    我们进行了一系列的实验，证明了利用生成对抗网络生成的图像可以通过“符号学”进行修改。我们展示了类似于像素、色调之类的物理属性可以被修改一样，通过我们的方法，也可以修改非物理、抽象的属性。例如，机舱乘务员的制服设计可以被修改为更加“警觉”，不那么“严肃”，或者更加“实用”。一个房子的形式可以被修改为更加“未来感”，一辆车更加“友好”，一双球鞋则可以被更加“邪恶”。我们的方法揭示了与感兴趣的符号学属性相关的潜在视觉象征，使得这一过程可以使用抽象概念进行视觉形式发现。我们的方法是迭代式的，允许对属性存在程度进行控制，可以用于辅助设计过程，产生新的视觉概念。

    We perform a set of experiments to demonstrate that images generated using a Generative Adversarial Network can be modified using 'semiotics.' We show that just as physical attributes such as the hue and saturation of an image can be modified, so too can its non-physical, abstract properties using our method. For example, the design of a flight attendant's uniform may be modified to look more 'alert,' less 'austere,' or more 'practical.' The form of a house can be modified to appear more 'futuristic,' a car more 'friendly' a pair of sneakers, 'evil.' Our method uncovers latent visual iconography associated with the semiotic property of interest, enabling a process of visual form-finding using abstract concepts. Our approach is iterative and allows control over the degree of attribute presence and can be used to aid the design process to yield emergent visual concepts.
    
[^15]: 面向数据驱动的海洋大型动物调查中的耀斑分类和预测

    Toward Data-Driven Glare Classification and Prediction for Marine Megafauna Survey. (arXiv:2303.12730v1 [cs.CV])

    [http://arxiv.org/abs/2303.12730](http://arxiv.org/abs/2303.12730)

    本文针对数据驱动的耀斑建模系统进行了基础建设，允许调查员预先最小化耀斑并最大限度地利用有用的图像来收集数据。

    

    为了估计物种数量，加拿大北大西洋水域的濒危物种进行系统调查，并影响着政策。本文针对数据驱动的耀斑建模系统进行了基础建设，这将允许调查员预先最小化耀斑。调查员使用检测函数估计未明显看到的巨型动物种群。研究的一个目标是最大限度地利用有用的图像来收集数据，为此，我们将使用耀斑模型预测耀斑并优化无耀斑数据的收集。为构建此模型，我们利用小型标记数据集进行半监督学习。大型数据集使用自然伪标签方法使用级联随机森林模型进行标记。使用反射率模型，以确定感兴趣的特征，填充我们的数据集，从而可以进行上下文感知的机器学习模型。

    Critically endangered species in Canadian North Atlantic waters are systematically surveyed to estimate species populations which influence governing policies. Due to its impact on policy, population accuracy is important. This paper lays the foundation towards a data-driven glare modelling system, which will allow surveyors to preemptively minimize glare. Surveyors use a detection function to estimate megafauna populations which are not explicitly seen. A goal of the research is to maximize useful imagery collected, to that end we will use our glare model to predict glare and optimize for glare-free data collection. To build this model, we leverage a small labelled dataset to perform semi-supervised learning. The large dataset is labelled with a Cascading Random Forest Model using a na\"ive pseudo-labelling approach. A reflectance model is used, which pinpoints features of interest, to populate our datasets which allows for context-aware machine learning models. The pseudo-labelled da
    
[^16]: LocalEyenet: 用于眼部定位的深度注意力框架

    LocalEyenet: Deep Attention framework for Localization of Eyes. (arXiv:2303.12728v1 [cs.CV])

    [http://arxiv.org/abs/2303.12728](http://arxiv.org/abs/2303.12728)

    本文提出了一种名为LocalEyenet的深度学习架构，用于仅定位眼部区域，可以进行端到端的培训。该架构在堆叠的沙漏骨干上学习自我注意力，并在每个沙漏中合并了深层聚合，以最小化损失。

    

    发展人机界面对于现代机器的自主性和效率提高已经成为必需。基于凝视的人类干预是创建界面以减少人为误差的有效和方便的选项。面部标志检测对于设计强大的凝视检测系统非常关键。基于回归的方法使得对应于面部不同区域的标志物具有良好的空间定位能力。但是，通过引入注意力仍然存在改进的空间。本文提出了一种名为LocalEyenet的深度粗到细的架构，用于仅定位眼部区域，可以进行端到端的培训。 该模型架构基于堆叠的沙漏骨干，学习特征图中的自我注意力，以帮助保留面部图像中的全局和局部空间依赖关系。我们在每个沙漏中都合并了深层聚合，以最小化损失。

    Development of human machine interface has become a necessity for modern day machines to catalyze more autonomy and more efficiency. Gaze driven human intervention is an effective and convenient option for creating an interface to alleviate human errors. Facial landmark detection is very crucial for designing a robust gaze detection system. Regression based methods capacitate good spatial localization of the landmarks corresponding to different parts of the faces. But there are still scope of improvements which have been addressed by incorporating attention.  In this paper, we have proposed a deep coarse-to-fine architecture called LocalEyenet for localization of only the eye regions that can be trained end-to-end. The model architecture, build on stacked hourglass backbone, learns the self-attention in feature maps which aids in preserving global as well as local spatial dependencies in face image. We have incorporated deep layer aggregation in each hourglass to minimize the loss of a
    
[^17]: 通过梯度下降学习分形

    Learning Fractals by Gradient Descent. (arXiv:2303.12722v1 [cs.CV])

    [http://arxiv.org/abs/2303.12722](http://arxiv.org/abs/2303.12722)

    本文提出了一种通过梯度下降学习分形图像参数的方法，能够生成高质量视觉效果的分形图像，并且兼容不同的损失函数，有望为下游任务和科学理解提供新的应用。

    

    分形是一种可以展示自然界中复杂且自相似的几何形态的图案（例如云和植物）。最近在视觉识别领域中，借助这种属性生成随机分形图像来进行模型预训练。本文中，我们研究了相反的问题--给定一个目标图像（不一定是分形），我们旨在生成一个类似的分形图像。我们提出了一种通过梯度下降学习分形图像参数的新方法。我们展示了我们的方法能够找到高质量视觉效果的分形参数，并且兼容不同的损失函数，开启了多种可能性，例如为下游任务、科学理解等学习分形。

    Fractals are geometric shapes that can display complex and self-similar patterns found in nature (e.g., clouds and plants). Recent works in visual recognition have leveraged this property to create random fractal images for model pre-training. In this paper, we study the inverse problem -- given a target image (not necessarily a fractal), we aim to generate a fractal image that looks like it. We propose a novel approach that learns the parameters underlying a fractal image via gradient descent. We show that our approach can find fractal parameters of high visual quality and be compatible with different loss functions, opening up several potentials, e.g., learning fractals for downstream tasks, scientific understanding, etc.
    
[^18]: 面向管状采样的低秩张量完成的非凸方法

    Non-convex approaches for low-rank tensor completion under tubal sampling. (arXiv:2303.12721v1 [cs.LG])

    [http://arxiv.org/abs/2303.12721](http://arxiv.org/abs/2303.12721)

    本文提出了两种易于实现的非凸张量完成框架（TL12和TCCUR），针对管状采样的问题进行了探究，实验结果展示它们在低采样率下在时间效率和准确性方面存在折衷，且在至少某个方面优于经典完成方法。

    

    张量完成是现代数据分析中的重要问题。本文研究了一种具体的采样策略，称为管状采样。我们提出了两个新颖的易于实现的非凸张量完成框架，称为张量 $L_1$-$L_2$ (TL12) 和张量完成 via CUR (TCCUR)。我们在合成数据和彩色图像修复问题上测试了两种方法的效率。实验结果揭示了这两种方法在低采样率下准确性和时间效率之间的权衡。它们中的每一个在至少某个方面优于一些经典完成方法。

    Tensor completion is an important problem in modern data analysis. In this work, we investigate a specific sampling strategy, referred to as tubal sampling. We propose two novel non-convex tensor completion frameworks that are easy to implement, named tensor $L_1$-$L_2$ (TL12) and tensor completion via CUR (TCCUR). We test the efficiency of both methods on synthetic data and a color image inpainting problem. Empirical results reveal a trade-off between the accuracy and time efficiency of these two methods in a low sampling ratio. Each of them outperforms some classical completion methods in at least one aspect.
    
[^19]: 基于颜色分割和自动标记Sentinel-2图像的极地海冰分类方法

    Toward Polar Sea-Ice Classification using Color-based Segmentation and Auto-labeling of Sentinel-2 Imagery to Train an Efficient Deep Learning Model. (arXiv:2303.12719v1 [cs.CV])

    [http://arxiv.org/abs/2303.12719](http://arxiv.org/abs/2303.12719)

    本研究开发了一种基于Sentinel-2图像的颜色分割和自动标记的极地海冰分类方法，利用U-Net深度学习模型实现精准分类，为对全球变暖进行有效监测提供了技术支持。

    

    全球变暖是一个紧迫的问题，导致了极地区域海冰和冰川的融化等环境灾难。极地海冰的融化模式和退缩是全球变暖的重要指标。本研究旨在开发一个强大有效的系统，利用Sentinel-2卫星图像对极地海冰进行分类，包括厚冰、覆雪薄冰和开阔水域。其中一个关键挑战是缺乏S2标记数据作为基础数据集。我们采用合适的颜色阈值确定颜色分割方法，结合自动标记数据训练了一个U-Net深度学习模型（完全卷积神经网络）来实现图像分类，并取得了良好的分类精度。

    Global warming is an urgent issue that is generating catastrophic environmental changes, such as the melting of sea ice and glaciers, particularly in the polar regions. The melting pattern and retreat of polar sea ice cover is an essential indicator of global warming. The Sentinel-2 satellite (S2) captures high-resolution optical imagery over the polar regions. This research aims at developing a robust and effective system for classifying polar sea ice as thick or snow-covered, young or thin, or open water using S2 images. A key challenge is the lack of labeled S2 training data to serve as the ground truth. We demonstrate a method with high precision to segment and automatically label the S2 images based on suitably determined color thresholds and employ these auto-labeled data to train a U-Net machine model (a fully convolutional neural network), yielding good classification accuracy. Evaluation results over S2 data from the polar summer season in the Ross Sea region of the Antarctic 
    
[^20]: 有限采样下的马尔可夫决策过程策略综合

    Strategy Synthesis in Markov Decision Processes Under Limited Sampling Access. (arXiv:2303.12718v1 [cs.LG])

    [http://arxiv.org/abs/2303.12718](http://arxiv.org/abs/2303.12718)

    本文提出了一种针对灰箱 MDP 的策略综合算法，使用区间 MDP 作为内部模型，并通过强化学习，结合下置信区间探索和行动划分的方法，解决有限采样下的问题，用于合成最大化回报的实用策略。

    

    在控制理论、人工智能和形式方法中，一个核心的任务是为在部分未知环境下操作的代理合成最大化回报的策略。在灰箱马尔可夫决策过程 (MDPs) 模型中，代理的行为影响以后的状态而不是涉及到的概率。在本文中，我们通过强化学习为灰箱 MDP 合成策略设计了一个内部模型为区间 MDP 的策略综合算法。为了应对强化学习中的有限采样问题，我们将两个新的概念引入到算法中，专注于快速成功的学习而不是随机保证和最优性：下置信区间探索加强已经学习的可行策略的变体，行动划分将学习行动空间缩小到有前途的行动。我们通过具有代表性的实例说明了算法的优点。

    A central task in control theory, artificial intelligence, and formal methods is to synthesize reward-maximizing strategies for agents that operate in partially unknown environments. In environments modeled by gray-box Markov decision processes (MDPs), the impact of the agents' actions are known in terms of successor states but not the stochastics involved. In this paper, we devise a strategy synthesis algorithm for gray-box MDPs via reinforcement learning that utilizes interval MDPs as internal model. To compete with limited sampling access in reinforcement learning, we incorporate two novel concepts into our algorithm, focusing on rapid and successful learning rather than on stochastic guarantees and optimality: lower confidence bound exploration reinforces variants of already learned practical strategies and action scoping reduces the learning action space to promising actions. We illustrate benefits of our algorithms by means of a prototypical implementation applied on examples fro
    
[^21]: 基于几何感知的潜在表示学习用于建模Barrett食管疾病进程

    Geometry-Aware Latent Representation Learning for Modeling Disease Progression of Barrett's Esophagus. (arXiv:2303.12711v1 [eess.IV])

    [http://arxiv.org/abs/2303.12711](http://arxiv.org/abs/2303.12711)

    本文提出了一种基于几何思想的潜在表示学习方法，用于建模Barrett食管疾病进程，与传统方法相比，具有更好的重建损失。

    

    Barrett食管是食管腺癌的唯一先驱，这是一种在诊断时预后不良的食管癌症。因此，诊断Barrett食管对于预防和治疗食管癌至关重要。监督机器学习支持Barrett食管诊断，但组织病理学训练数据的高观察者变异限制了这些方法。用变分自动编码器(VAEs)进行无监督表示学习显示出潜在优势，因为它们将输入数据映射到具有仅有用特征的低维流形，为改进下游任务和见解将Barrett食管病程表征。然而，VAE的欧几里得潜在空间扭曲了点之间的关系，从而阻碍了疾病进展建模。几何VAEs为潜在空间提供附加几何结构，RHVAE假设为黎曼流形，$\mathcal{S}$-VAE假设为超球面流形。我们的研究表明，$\mathcal{S}$-VAE优于常规VAE，具有更好的重建损失。

    Barrett's Esophagus (BE) is the only precursor known to Esophageal Adenocarcinoma (EAC), a type of esophageal cancer with poor prognosis upon diagnosis. Therefore, diagnosing BE is crucial in preventing and treating esophageal cancer. While supervised machine learning supports BE diagnosis, high interobserver variability in histopathological training data limits these methods. Unsupervised representation learning via Variational Autoencoders (VAEs) shows promise, as they map input data to a lower-dimensional manifold with only useful features, characterizing BE progression for improved downstream tasks and insights. However, the VAE's Euclidean latent space distorts point relationships, hindering disease progression modeling. Geometric VAEs provide additional geometric structure to the latent space, with RHVAE assuming a Riemannian manifold and $\mathcal{S}$-VAE a hyperspherical manifold. Our study shows that $\mathcal{S}$-VAE outperforms vanilla VAE with better reconstruction losses, 
    
[^22]: 比较概率深度学习在自闭症检测中的方法

    Comparison of Probabilistic Deep Learning Methods for Autism Detection. (arXiv:2303.12707v1 [cs.CV])

    [http://arxiv.org/abs/2303.12707](http://arxiv.org/abs/2303.12707)

    该文章研究了最先进的概率深度学习方法，用于自闭症的检测和诊断，旨在量化方法依赖于机器学习解决客观的自闭症谱系障碍行为特征的挑战。

    

    自闭症谱系障碍（ASD）是一种目前在世界范围内普遍存在的神经发育障碍。ASD 会在个体的整个生命期内存在，影响他们的行为和交流方式，导致明显的社交障碍、重复的行为特征以及兴趣受限。早期发现该疾病有助于启动治疗并帮助患者过上正常的生活。目前已经研究和开发了一些基于机器学习的定量方法，以克服临床方法存在的问题。这些量化方法依赖于机器学习，一些复杂的基于深度学习的方法已经被开发用于加速自闭症的检测和诊断。本文旨在探讨目前最先进的概率方法，以其所应用的数据集类型为特征进行描述。

    Autism Spectrum Disorder (ASD) is one neuro developmental disorder that is now widespread in the world. ASD persists throughout the life of an individual, impacting the way they behave and communicate, resulting to notable deficits consisting of social life retardation, repeated behavioural traits and a restriction in their interests. Early detection of the disorder helps in the onset treatment and helps one to lead a normal life. There are clinical approaches used in detection of autism, relying on behavioural data and in worst cases, neuroimaging. Quantitative methods involving machine learning have been studied and developed to overcome issues with clinical approaches. These quantitative methods rely on machine learning, with some complex methods based on deep learning developed to accelerate detection and diagnosis of ASD. These literature is aimed at exploring most state-of-the-art probabilistic methods in use today, characterizing them with the type of dataset they're most applie
    
[^23]: 多模态变分自编码器用于跨多种成像模态进行规范建模

    Multi-modal Variational Autoencoders for normative modelling across multiple imaging modalities. (arXiv:2303.12706v1 [cs.CV])

    [http://arxiv.org/abs/2303.12706](http://arxiv.org/abs/2303.12706)

    本文提出了一种多模态规范建模框架，能够更好地检测出多种成像和生物变量中的异常性，特别适用于研究带有异质性的疾病。

    

    研究常见神经疾病的挑战之一是疾病异质性，包括病因、神经成像特征、合并症或基因变异的差异。规范建模已成为研究这种人群的流行方法，其中对生理系统的“正常”行为进行建模，并可以用于个体层面上检测与疾病病理相关的偏差。对于许多异质性疾病，我们预计会观察到多种神经成像和生物变量的异常。然而，到目前为止，规范模型主要是为了研究单一成像模态而开发的。我们旨在开发一种多模态规范建模框架，在多个模态的变量中聚合异常性，并且比单模式基线更能检测到偏差。我们提出了两种用于检测T1和DTI数据中的个体层面偏差的多模态VAE规范模型。与单模式基线相比，我们提出的模型能够更好地检测到轻度认知受损的受试者中的偏差，证明了多模态规范建模用于疾病异质性的潜力。

    One of the challenges of studying common neurological disorders is disease heterogeneity including differences in causes, neuroimaging characteristics, comorbidities, or genetic variation. Normative modelling has become a popular method for studying such cohorts where the 'normal' behaviour of a physiological system is modelled and can be used at subject level to detect deviations relating to disease pathology. For many heterogeneous diseases, we expect to observe abnormalities across a range of neuroimaging and biological variables. However, thus far, normative models have largely been developed for studying a single imaging modality. We aim to develop a multi-modal normative modelling framework where abnormality is aggregated across variables of multiple modalities and is better able to detect deviations than uni-modal baselines. We propose two multi-modal VAE normative models to detect subject level deviations across T1 and DTI data. Our proposed models were better able to detect di
    
[^24]: 多标签证据学习用于开放集动作识别

    Open Set Action Recognition via Multi-Label Evidential Learning. (arXiv:2303.12698v1 [cs.CV])

    [http://arxiv.org/abs/2303.12698](http://arxiv.org/abs/2303.12698)

    本研究提出了一种使用多标签证据学习的新方法，解决了开放集动作识别的新颖性检测问题和同一场景中单个或多个演员以及任何演员的同时动作的更一般问题。

    

    现有的开放集动作识别方法集中于新颖性检测，假设视频剪辑显示单个动作，这在现实世界中是不现实的。我们提出了一种通过多标签证据学习（MULE）进行开放集动作识别和新颖性检测的新方法，该方法超越了以前的新动作检测方法，通过解决同一场景中单个或多个演员以及任何演员的同时动作的更一般问题。我们的Beta证据神经网络基于演员-上下文-对象关系表示，使用Beta密度估计多动作不确定性。在优化过程中，添加证据去偏置约束到目标函数中，以减少视频表示的静态偏差，从而可以错误地关联预测和静态线索。我们开发了一个基于原始-对偶平均方案更新的学习算法，以优化所提出的问题。优化算法的理论分析证明了其收敛性和复杂性。

    Existing methods for open-set action recognition focus on novelty detection that assumes video clips show a single action, which is unrealistic in the real world. We propose a new method for open set action recognition and novelty detection via MUlti-Label Evidential learning (MULE), that goes beyond previous novel action detection methods by addressing the more general problems of single or multiple actors in the same scene, with simultaneous action(s) by any actor. Our Beta Evidential Neural Network estimates multi-action uncertainty with Beta densities based on actor-context-object relation representations. An evidence debiasing constraint is added to the objective function for optimization to reduce the static bias of video representations, which can incorrectly correlate predictions and static cues. We develop a learning algorithm based on a primal-dual average scheme update to optimize the proposed problem. Theoretical analysis of the optimization algorithm demonstrates the conve
    
[^25]: 非拟合分数重新权重实现自适应一致性预测

    Adaptive Conformal Prediction by Reweighting Nonconformity Score. (arXiv:2303.12695v1 [stat.ML])

    [http://arxiv.org/abs/2303.12695](http://arxiv.org/abs/2303.12695)

    该论文提出了一种新方法，利用分位数回归森林来学习非拟合分数的分布，并利用其权重分配更多的重要性给残差与测试点相似的样本，从而实现更符合模型的不确定性的预测区间。

    

    尽管具有吸引人的理论保证和实际成功，但由一致性预测（CP）给出的预测区间（PI）可能无法反映给定模型的不确定性。这种限制源于CP方法对所有测试点使用常数修正，无视它们的不确定性，以确保覆盖特性。为了解决这个问题，我们提出使用分位数回归森林（QRF）来学习非拟合分数的分布，并利用QRF的权重将更多的重要性分配给残差与测试点相似的样本。这种方法导致的PI长度更符合模型的不确定性。此外，QRF学习到的权重提供了特征空间的划分，通过组合一致化可以实现更高效的计算和改进PI的适应性。我们的方法享有基于样本和基于训练条件的无假设有限覆盖率，并在适当的假设下，也可以

    Despite attractive theoretical guarantees and practical successes, Predictive Interval (PI) given by Conformal Prediction (CP) may not reflect the uncertainty of a given model. This limitation arises from CP methods using a constant correction for all test points, disregarding their individual uncertainties, to ensure coverage properties. To address this issue, we propose using a Quantile Regression Forest (QRF) to learn the distribution of nonconformity scores and utilizing the QRF's weights to assign more importance to samples with residuals similar to the test point. This approach results in PI lengths that are more aligned with the model's uncertainty. In addition, the weights learnt by the QRF provide a partition of the features space, allowing for more efficient computations and improved adaptiveness of the PI through groupwise conformalization. Our approach enjoys an assumption-free finite sample marginal and training-conditional coverage, and under suitable assumptions, it also
    
[^26]: 对抗训练下基于人类行为的研究扩展的实验

    An Extended Study of Human-like Behavior under Adversarial Training. (arXiv:2303.12669v1 [cs.CV])

    [http://arxiv.org/abs/2303.12669](http://arxiv.org/abs/2303.12669)

    对抗训练可以使模型更倾向于人类形状识别，而非仅仅利用纹理线索。在数据集中包含素描的情况下，这种变换效果仍然有效，并且在语言处理领域也适用。

    

    神经网络存在许多缺陷，其中最严重的之一是对分布偏差的敏感性，这允许模型轻易被小型扰动欺骗并做出错误预测，而这些扰动通常对人类来说不易察觉并不必须具有语义含义。 对抗性训练通过在最坏情况下对模型进行扰动来训练模型来解决这个问题。 然而，最近的工作也指出，神经网络的推理方式不同于人类。 人类通过形状识别对象，而神经网络主要利用纹理线索。 例如，受过照片训练的模型可能无法推广到包含素描的数据集。 有趣的是，还表明对抗性训练似乎有利于增加转向形状偏差的趋势。 本文重新审视了这一观察结果，并就各种架构，常见的$\ell_2$和$\ell_\infty$-training，以及基于Transformer的自然语言处理模型的效应进行了广泛分析。 我们在物体分类和自然语言推理上的实验表明，转向形状偏差的变换不仅限于视觉领域，而且也适用于语言处理。 具体而言，我们观察到对抗性训练导致模型更多地依赖组合结构来识别对象和进行预测，从而具有更接近人类的行为。

    Neural networks have a number of shortcomings. Amongst the severest ones is the sensitivity to distribution shifts which allows models to be easily fooled into wrong predictions by small perturbations to inputs that are often imperceivable to humans and do not have to carry semantic meaning. Adversarial training poses a partial solution to address this issue by training models on worst-case perturbations. Yet, recent work has also pointed out that the reasoning in neural networks is different from humans. Humans identify objects by shape, while neural nets mainly employ texture cues. Exemplarily, a model trained on photographs will likely fail to generalize to datasets containing sketches. Interestingly, it was also shown that adversarial training seems to favorably increase the shift toward shape bias. In this work, we revisit this observation and provide an extensive analysis of this effect on various architectures, the common $\ell_2$- and $\ell_\infty$-training, and Transformer-bas
    
[^27]: 通过量化进行的事后解释

    Posthoc Interpretation via Quantization. (arXiv:2303.12659v1 [cs.AI])

    [http://arxiv.org/abs/2303.12659](http://arxiv.org/abs/2303.12659)

    本文提出了一种新的方法 PIQ，通过对分类器进行向量量化，将其表示转换为离散类特定的潜空间，从而解释分类器所做出的决策，并且通过研究发现该方法相比其他方法更容易让人理解。

    

    本文提出了一种新的方法，称为“通过量化实现的事后解释（PIQ）”，用于解释训练分类器所做出的决策。我们的方法利用向量量化将分类器的表示转换为离散，类特定的潜空间。类特定的码本作为瓶颈，迫使解释者专注于分类器认为用于进行预测的输入数据的相关部分。我们通过定量和定性研究评估了我们的方法，并发现与文献中的几种其他解释方法相比，PIQ生成的解释更容易被参与我们用户研究的人所理解。

    In this paper, we introduce a new approach, called "Posthoc Interpretation via Quantization (PIQ)", for interpreting decisions made by trained classifiers. Our method utilizes vector quantization to transform the representations of a classifier into a discrete, class-specific latent space. The class-specific codebooks act as a bottleneck that forces the interpreter to focus on the parts of the input data deemed relevant by the classifier for making a prediction. We evaluated our method through quantitative and qualitative studies and found that PIQ generates interpretations that are more easily understood by participants to our user studies when compared to several other interpretation methods in the literature.
    
[^28]: 深度哈希检索方法的对抗鲁棒性的可靠高效评估

    Reliable and Efficient Evaluation of Adversarial Robustness for Deep Hashing-Based Retrieval. (arXiv:2303.12658v1 [cs.CV])

    [http://arxiv.org/abs/2303.12658](http://arxiv.org/abs/2303.12658)

    本文提出了一种名为 Pharos-guided Attack (PgA) 的攻击方法，通过设计代表良性图像语义的 Pharos 代码实现快速且可靠地进行对抗攻击，能够更全面地评估深度哈希检索模型的对抗鲁棒性。

    

    深度哈希技术在大规模图像检索领域具有高效性和有效性。然而，现有的攻击方法由于未充分利用原始样本之间的语义关系或需要用深度神经网络学习这些关系，在评估深度哈希模型对抗样本的鲁棒性时存在性能下降或效率低下的问题。本文提出了一种新颖的攻击方法 Pharos-guided Attack (PgA)，旨在通过设计代表良性图像语义的 Pharos 代码，可快速且可靠地进行对抗攻击。实验结果表明，与其他六种攻击方法相比，PgA 在成功率和效率方面均优于现有方法，并能够更全面地评估深度哈希检索模型的对抗鲁棒性。

    Deep hashing has been extensively applied to massive image retrieval due to its efficiency and effectiveness. Recently, several adversarial attacks have been presented to reveal the vulnerability of deep hashing models against adversarial examples. However, existing attack methods suffer from degraded performance or inefficiency because they underutilize the semantic relations between original samples or spend a lot of time learning these relations with a deep neural network. In this paper, we propose a novel Pharos-guided Attack, dubbed PgA, to evaluate the adversarial robustness of deep hashing networks reliably and efficiently. Specifically, we design pharos code to represent the semantics of the benign image, which preserves the similarity to semantically relevant samples and dissimilarity to irrelevant ones. It is proven that we can quickly calculate the pharos code via a simple math formula. Accordingly, PgA can directly conduct a reliable and efficient attack on deep hashing-bas
    
[^29]: 自监督混合深度学习实现健壮全息毫米波波束成形

    Robust Holographic mmWave Beamforming by Self-Supervised Hybrid Deep Learning. (arXiv:2303.12653v1 [cs.IT])

    [http://arxiv.org/abs/2303.12653](http://arxiv.org/abs/2303.12653)

    本文提出一种自监督混合深度学习网络用于健壮波束成形，能够在两种不同的数据集和各种场景中表现出更强的鲁棒性。

    

    近年来，大规模天线阵列的波束成形被广泛应用于5G和即将推出的6G中，因此各种技术被利用来提高其性能，例如深度学习、高级优化算法等。尽管在许多具有深度学习的先前研究方案中其性能相当吸引人，但通常当环境或数据集发生变化时，其性能会迅速下降。因此，设计具有强大鲁棒性的有效波束成形网络是智能无线通信的一个开放问题。在本文中，我们提出了一个健壮的波束成形自监督网络，并在两种不同数据集和各种场景下进行了验证。仿真结果表明，所提出的具有混合学习的自监督网络在经典的DeepMIMO和新的WAIR-D数据集上具有强大的鲁棒性，适用于各种环境。此外，我们还提出了原理来解释这个翻译的合理性。

    Beamforming with large-scale antenna arrays has been widely used in recent years, which is acknowledged as an important part in 5G and incoming 6G. Thus, various techniques are leveraged to improve its performance, e.g., deep learning, advanced optimization algorithms, etc. Although its performance in many previous research scenarios with deep learning is quite attractive, usually it drops rapidly when the environment or dataset is changed. Therefore, designing effective beamforming network with strong robustness is an open issue for the intelligent wireless communications. In this paper, we propose a robust beamforming self-supervised network, and verify it in two kinds of different datasets with various scenarios. Simulation results show that the proposed self-supervised network with hybrid learning performs well in both classic DeepMIMO and new WAIR-D dataset with the strong robustness under the various environments. Also, we present the principle to explain the rationality of this 
    
[^30]: 基于记忆的循环神经网络的交通量预测：LSTM和GRU的比较分析

    Traffic Volume Prediction using Memory-Based Recurrent Neural Networks: A comparative analysis of LSTM and GRU. (arXiv:2303.12643v1 [cs.LG])

    [http://arxiv.org/abs/2303.12643](http://arxiv.org/abs/2303.12643)

    该论文提出了基于记忆的深度神经网络模型，可以在高度动态和异质交通环境下实时预测交通量的有效性。

    

    实时预测交通量可以提高交通流量和道路安全性。精确的交通量预测有助于警示驾驶员沿着他们喜欢的路线的实时交通流量，避免潜在的死锁情况。现有的参数模型无法可靠地预测动态和复杂交通条件下的交通量。因此，为了实时地评估和预测每个给定时间步的交通量，我们开发了非线性的基于记忆的深度神经网络模型。我们在公交高架交通量数据集上进行的大量实验证明了所提出模型在高度动态和异质交通环境下预测交通量的有效性。

    Predicting traffic volume in real-time can improve both traffic flow and road safety. A precise traffic volume forecast helps alert drivers to the flow of traffic along their preferred routes, preventing potential deadlock situations. Existing parametric models cannot reliably forecast traffic volume in dynamic and complex traffic conditions. Therefore, in order to evaluate and forecast the traffic volume for every given time step in a real-time manner, we develop non-linear memory-based deep neural network models. Our extensive experiments run on the Metro Interstate Traffic Volume dataset demonstrate the effectiveness of the proposed models in predicting traffic volume in highly dynamic and heterogeneous traffic environments.
    
[^31]: 智能化的民主化：多种含义、目标和方法

    Democratising AI: Multiple Meanings, Goals, and Methods. (arXiv:2303.12642v1 [cs.AI])

    [http://arxiv.org/abs/2303.12642](http://arxiv.org/abs/2303.12642)

    这篇论文探讨了AI的民主化，包括四种类型的民主化：AI使用的民主化，AI开发的民主化，AI利润的民主化，和AI治理的民主化。要想实现有效的政策和权衡讨论，需要认识到AI治理的民主化在决策中扮演着重要的角色。

    

    许多人呼吁实现AI的民主化，但这个词语用来指代多种目标，有时会相互冲突。本文确定了通常讨论的四种AI民主化类型：(1) AI使用的民主化，(2) AI开发的民主化，(3) AI利润的民主化，和(4) AI治理的民主化。本文讨论了实现每种民主化形式的多个目标和方法。从本文中主要得出的结论是，AI的民主化是一个多元而有时会相互冲突的概念，不应混淆AI可访问性的改善。如果我们想要超越对智能化民主化的模糊承诺，进入具体政策和权衡的生产性讨论，我们需要认识到AI治理的民主化在跨越关于使用、开发和利润的决策中导航权衡和风险的主要作用。

    Numerous parties are calling for the democratisation of AI, but the phrase is used to refer to a variety of goals, the pursuit of which sometimes conflict. This paper identifies four kinds of AI democratisation that are commonly discussed: (1) the democratisation of AI use, (2) the democratisation of AI development, (3) the democratisation of AI profits, and (4) the democratisation of AI governance. Numerous goals and methods of achieving each form of democratisation are discussed. The main takeaway from this paper is that AI democratisation is a multifarious and sometimes conflicting concept that should not be conflated with improving AI accessibility. If we want to move beyond ambiguous commitments to democratising AI, to productive discussions of concrete policies and trade-offs, then we need to recognise the principal role of the democratisation of AI governance in navigating tradeoffs and risks across decisions around use, development, and profits.
    
[^32]: 半监督对抗性解释

    Semi-supervised counterfactual explanations. (arXiv:2303.12634v1 [cs.LG])

    [http://arxiv.org/abs/2303.12634](http://arxiv.org/abs/2303.12634)

    本论文介绍了一种半监督对抗性解释的方法，通过在对抗性搜索过程中结合自编码器重构损失和将分类器的输出行为与自编码器的潜在空间连接，提高了对抗性搜索过程的速度和生成结果的解释性。

    

    机器学习模型的对抗性解释是用于查找最小干预特征值的方法，使得模型将预测更改为不同的输出或目标输出。有效的对抗性解释应具有可能的特征值。在本文中，我们解决了生成对抗性解释的挑战，使其处于与训练数据相同的数据分布中，并且更重要的是，它们属于目标类分布。通过在对抗性搜索过程中结合自编码器重构损失来解决这个要求。将分类器的输出行为与自编码器的潜在空间连接，进一步提高了对抗性搜索过程的速度和生成结果的解释性。在这一研究领域的持续努力下，我们展示了当自编码器在半监督状态下被训练时，对抗性解释的可解释性进一步提高。

    Counterfactual explanations for machine learning models are used to find minimal interventions to the feature values such that the model changes the prediction to a different output or a target output. A valid counterfactual explanation should have likely feature values. Here, we address the challenge of generating counterfactual explanations that lie in the same data distribution as that of the training data and more importantly, they belong to the target class distribution. This requirement has been addressed through the incorporation of auto-encoder reconstruction loss in the counterfactual search process. Connecting the output behavior of the classifier to the latent space of the auto-encoder has further improved the speed of the counterfactual search process and the interpretability of the resulting counterfactual explanations. Continuing this line of research, we show further improvement in the interpretability of counterfactual explanations when the auto-encoder is trained in a 
    
[^33]: 后门是否有助于成员推理攻击？

    Do Backdoors Assist Membership Inference Attacks?. (arXiv:2303.12589v1 [cs.CR])

    [http://arxiv.org/abs/2303.12589](http://arxiv.org/abs/2303.12589)

    本文探讨了一种基于后门的新型成员推理攻击，通过实验发现后门并不能成功进行攻击，因为后门不能分离训练和非训练样本的损失分布。

    

    当对机器学习模型提供了毒瘤样本时，数据隐私可能会泄漏，例如会员推理攻击会推断样本是否包含在模型的训练之中，从而有效地将样本移动到一个异常值之中。然而，攻击可能会被检测到，因为由于毒瘤样本而导致的推断准确性下降。本文中，我们讨论了一种基于后门的新型成员推理攻击，其通过后门返回攻击者预期的输出来进行攻击。通过对一个学术基准数据集的实验，我们发现了三个关键的见解。首先，我们证明了后门辅助的成员推理攻击是不成功的。其次，当我们分析损失分布以了解不成功结果的原因时，我们发现后门不能分离训练和非训练样本的损失分布。换句话说，后门不能影响干净样本的分布。

    When an adversary provides poison samples to a machine learning model, privacy leakage, such as membership inference attacks that infer whether a sample was included in the training of the model, becomes effective by moving the sample to an outlier. However, the attacks can be detected because inference accuracy deteriorates due to poison samples. In this paper, we discuss a \textit{backdoor-assisted membership inference attack}, a novel membership inference attack based on backdoors that return the adversary's expected output for a triggered sample. We found three crucial insights through experiments with an academic benchmark dataset. We first demonstrate that the backdoor-assisted membership inference attack is unsuccessful. Second, when we analyzed loss distributions to understand the reason for the unsuccessful results, we found that backdoors cannot separate loss distributions of training and non-training samples. In other words, backdoors cannot affect the distribution of clean 
    
[^34]: 神经符号推理快捷方式：缓解策略及其限制

    Neuro-Symbolic Reasoning Shortcuts: Mitigation Strategies and their Limitations. (arXiv:2303.12578v1 [cs.AI])

    [http://arxiv.org/abs/2303.12578](http://arxiv.org/abs/2303.12578)

    本文讨论了神经符号推理的快捷方式带来的问题，并讨论了传统的缓解策略的局限性。

    

    神经符号预测器学习从子符号输入到更高层次概念的映射，然后在这个中间表示上执行（概率）逻辑推理。这种设置在符号先验知识的一致性方面具有明显的优势，通常被认为在遵守知识的前提下提供了解释性的好处，因为学习的概念可以更好地被人类利益相关者理解。然而，最近证明了这种设置受到推理快捷方式的影响，通过利用具有意外语义的概念实现高准确性的预测，导致了差的超出分布性能并损害了可解释性。在本文中，我们建立了推理快捷方式和损失函数的最优解之间的形式联系，并确定了推理快捷方式可能出现的情况。基于此，我们讨论了自然缓解策略（如重建和概念监督）的局限性。

    Neuro-symbolic predictors learn a mapping from sub-symbolic inputs to higher-level concepts and then carry out (probabilistic) logical inference on this intermediate representation. This setup offers clear advantages in terms of consistency to symbolic prior knowledge, and is often believed to provide interpretability benefits in that - by virtue of complying with the knowledge the learned concepts can be better understood by human stakeholders. However, it was recently shown that this setup is affected by reasoning shortcuts whereby predictions attain high accuracy by leveraging concepts with unintended semantics, yielding poor out-of-distribution performance and compromising interpretability. In this short paper, we establish a formal link between reasoning shortcuts and the optima of the loss function, and identify situations in which reasoning shortcuts can arise. Based on this, we discuss limitations of natural mitigation strategies such as reconstruction and concept supervision
    
[^35]: Wasserstein自编码MDPs：具有多方保证的高效RL策略正式验证

    Wasserstein Auto-encoded MDPs: Formal Verification of Efficiently Distilled RL Policies with Many-sided Guarantees. (arXiv:2303.12558v1 [cs.LG])

    [http://arxiv.org/abs/2303.12558](http://arxiv.org/abs/2303.12558)

    该论文提出了一种名为WAE-MDP的潜在空间模型，可以从任何RL策略中提取形式可验证控制器，并且具有平衡控制性能和安全之间的效果和解决一些学习缺陷的多方保证。

    

    尽管深度强化学习（DRL）有许多成功案例，但通过这些先进技术学习的决策者在安全关键场景中的大规模部署受到正式保证不足的阻碍。变分马尔可夫决策过程（VAE-MDPs）是离散潜在空间模型，提供了从任何RL策略中提取形式可验证控制器的可靠框架。虽然相关保证涵盖了实际问题的满足性和安全性等方面，但VAE方法因缺乏抽象和表示保证以支持潜在最优化而遭受多种学习缺陷（后验崩塌，学习速度慢，动力学估计不良）。我们引入了Wasserstein自编码MDP（WAE-MDP），这是一种潜在空间模型，通过最小化执行原始策略的智能体行为和提取出的策略之间的最优转运的惩罚形式来解决这些问题。我们证明了所提出的方法可以有利于控制性能和安全之间的平衡，同时减轻了上述的学习问题。我们推导了关于性能和安全的理论保证，并在不同的RL基准上验证了该方法。

    Although deep reinforcement learning (DRL) has many success stories, the large-scale deployment of policies learned through these advanced techniques in safety-critical scenarios is hindered by their lack of formal guarantees. Variational Markov Decision Processes (VAE-MDPs) are discrete latent space models that provide a reliable framework for distilling formally verifiable controllers from any RL policy. While the related guarantees address relevant practical aspects such as the satisfaction of performance and safety properties, the VAE approach suffers from several learning flaws (posterior collapse, slow learning speed, poor dynamics estimates), primarily due to the absence of abstraction and representation guarantees to support latent optimization. We introduce the Wasserstein auto-encoded MDP (WAE-MDP), a latent space model that fixes those issues by minimizing a penalized form of the optimal transport between the behaviors of the agent executing the original policy and the disti
    
[^36]: “图像分析算法在流行病变化下的部署”

    Deployment of Image Analysis Algorithms under Prevalence Shifts. (arXiv:2303.12540v1 [cs.CV])

    [http://arxiv.org/abs/2303.12540](http://arxiv.org/abs/2303.12540)

    本文通过实证研究表明，在机器学习在医学图像分析领域的实际应用中，流行病变化对算法的部署效果有重要影响。

    

    领域差距是医学图像分析的机器学习解决方案临床转化中最重要的障碍之一。尽管当前的研究重点是新的训练范式和网络架构，但很少关注算法在实践中部署时流行病发生率变化的特定影响。对于人工智能民主化的背景，由于疾病流行率可能在时间和地点上变化很大，因此开发/验证方法中使用的数据和部署环境中的数据的类别频率之间的差异非常重要。我们的贡献有两个方面。首先，我们通过分析（i）校准的程度，（ii）决策阈值与最优值的偏差，以及（iii）验证指标反映神经网络性能在部署人口的能力，实证地证明了缺少流行病处理的潜在严重后果。

    Domain gaps are among the most relevant roadblocks in the clinical translation of machine learning (ML)-based solutions for medical image analysis. While current research focuses on new training paradigms and network architectures, little attention is given to the specific effect of prevalence shifts on an algorithm deployed in practice. Such discrepancies between class frequencies in the data used for a method's development/validation and that in its deployment environment(s) are of great importance, for example in the context of artificial intelligence (AI) democratization, as disease prevalences may vary widely across time and location. Our contribution is twofold. First, we empirically demonstrate the potentially severe consequences of missing prevalence handling by analyzing (i) the extent of miscalibration, (ii) the deviation of the decision threshold from the optimum, and (iii) the ability of validation metrics to reflect neural network performance on the deployment population a
    
[^37]: DevelSet: 深度神经水平集优化方法用于光刻掩模制作

    DevelSet: Deep Neural Level Set for Instant Mask Optimization. (arXiv:2303.12529v1 [cs.CV])

    [http://arxiv.org/abs/2303.12529](http://arxiv.org/abs/2303.12529)

    DevelSet是一种GPU和深度神经网络(DNN)加速的水平集金属光刻掩模综合框架，通过引入曲率项减少掩模复杂度，并应用GPU加速来克服计算瓶颈，进一步提高可打印性和快速迭代收敛。

    

    随着先进工艺节点中特征尺寸的不断缩小，掩模优化在传统设计流程中变得越来越重要，并伴随着光刻近似校正(OPC)方法中计算开销的爆炸式增长。最近, 反向光刻技术(ILT)已经引起了重视, 并在新兴的 OPC 解决方案中变得流行。然而，ILT方法要么耗时，要么掩模印刷性能和可制造性不足。本文提出了DevelSet，一种GPU和深度神经网络(DNN)加速的水平集金属光刻掩模综合框架。我们首先通过引入曲率项来降低掩模复杂度并应用GPU加速来克服计算瓶颈，改进了传统的基于水平集的ILT算法。为了进一步提高可打印性和快速迭代收敛，我们提出了一种新颖的深度神经网络，利用水平集固有原理巧妙地设计。

    With the feature size continuously shrinking in advanced technology nodes, mask optimization is increasingly crucial in the conventional design flow, accompanied by an explosive growth in prohibitive computational overhead in optical proximity correction (OPC) methods. Recently, inverse lithography technique (ILT) has drawn significant attention and is becoming prevalent in emerging OPC solutions. However, ILT methods are either time-consuming or in weak performance of mask printability and manufacturability. In this paper, we present DevelSet, a GPU and deep neural network (DNN) accelerated level set OPC framework for metal layer. We first improve the conventional level set-based ILT algorithm by introducing the curvature term to reduce mask complexity and applying GPU acceleration to overcome computational bottlenecks. To further enhance printability and fast iterative convergence, we propose a novel deep neural network delicately designed with level set intrinsic principles to facil
    
[^38]: Split-Et-Impera: 一种用于设计分布式深度学习应用程序的框架

    Split-Et-Impera: A Framework for the Design of Distributed Deep Learning Applications. (arXiv:2303.12524v1 [cs.DC])

    [http://arxiv.org/abs/2303.12524](http://arxiv.org/abs/2303.12524)

    Split-Et-Impera是一种针对分布式深度学习应用程序的框架，可根据神经网络可解释性原则确定最佳的网络分割点、通过通信感知仿真进行快速评估不同的神经网络重新排列，并根据目标硬件平台的特性适应神经网络拓扑。

    

    最近许多模式识别应用都依赖于复杂的分布式架构，其中感知和计算节点通过通信网络相互交互。深度神经网络在这种情况下扮演着重要角色，提供强大的决策机制，但也需要高计算量。因此，我们提出了Split-Et-Impera框架，它可以确定神经网络的最佳分割点，并通过通信感知仿真进行快速评估不同的神经网络重新排列，同时考虑目标硬件平台的特性，以适应神经网络拓扑。我们的框架可以提供一个易于使用的工具箱，设计，验证和优化分布式深度学习应用程序，而不需要对分布式系统或网络通信协议有深入的了解。

    Many recent pattern recognition applications rely on complex distributed architectures in which sensing and computational nodes interact together through a communication network. Deep neural networks (DNNs) play an important role in this scenario, furnishing powerful decision mechanisms, at the price of a high computational effort. Consequently, powerful state-of-the-art DNNs are frequently split over various computational nodes, e.g., a first part stays on an embedded device and the rest on a server. Deciding where to split a DNN is a challenge in itself, making the design of deep learning applications even more complicated. Therefore, we propose Split-Et-Impera, a novel and practical framework that i) determines the set of the best-split points of a neural network based on deep network interpretability principles without performing a tedious try-and-test approach, ii) performs a communication-aware simulation for the rapid evaluation of different neural network rearrangements, and ii
    
[^39]: BERT是否盲目？探索视觉语言预训练对视觉语言理解的影响。

    Is BERT Blind? Exploring the Effect of Vision-and-Language Pretraining on Visual Language Understanding. (arXiv:2303.12513v1 [cs.CV])

    [http://arxiv.org/abs/2303.12513](http://arxiv.org/abs/2303.12513)

    本文调查了视觉语言预训练对仅文本任务的表现是否有提高。作者提出了一套视觉语言理解任务，证明了多模态训练的文本编码器在视觉推理方面的优越性。

    

    大多数人使用视觉想象来理解和推理语言，但是像BERT这样的模型使用在仅包括文本的预训练过程中获取的知识来推理语言。在本文中，我们调查了视觉语言预训练是否可以提高在涉及隐含视觉推理的仅文本任务上的表现，重点是零样本探测方法。我们提出了一套用于探测文本编码器模型视觉推理能力的视觉语言理解（VLU）任务，以及各种非视觉自然语言理解（NLU）任务用于比较。我们还贡献了一种新型的零样本知识探测方法，Stroop probing，用于将像CLIP这样的模型应用于仅文本任务，而不需要像BERT模型的掩码语言建模头那样的预测头。我们证明了SOTA多模态训练的文本编码器在VLU任务上优于单模态训练的文本编码器，但在NLU任务上不及它们。

    Most humans use visual imagination to understand and reason about language, but models such as BERT reason about language using knowledge acquired during text-only pretraining. In this work, we investigate whether vision-and-language pretraining can improve performance on text-only tasks that involve implicit visual reasoning, focusing primarily on zero-shot probing methods. We propose a suite of visual language understanding (VLU) tasks for probing the visual reasoning abilities of text encoder models, as well as various non-visual natural language understanding (NLU) tasks for comparison. We also contribute a novel zero-shot knowledge probing method, Stroop probing, for applying models such as CLIP to text-only tasks without needing a prediction head such as the masked language modelling head of models like BERT. We show that SOTA multimodally trained text encoders outperform unimodally trained text encoders on the VLU tasks while being underperformed by them on the NLU tasks, lendin
    
[^40]: 关于农业机器人有效的领域特定预训练对于语义感知的研究

    On Domain-Specific Pre-Training for Effective Semantic Perception in Agricultural Robotics. (arXiv:2303.12499v1 [cs.CV])

    [http://arxiv.org/abs/2303.12499](http://arxiv.org/abs/2303.12499)

    本文研究了如何在农业机器人的语义感知中通过特定领域的自我监督预训练以减少标签数量，并提出了一组特定领域的增强策略来更好地利用数据。

    

    农业机器人可以提高粮食、饲料和纤维的生产效率和可持续性。作物和杂草的感知是农业机器人的核心组成部分，旨在自动监测田野和评估植物及其生长阶段。语义感知主要依赖于使用有监督方法的深度学习，这需要时间和训练有素的工作人员标记大量的数据。本文研究如何在不影响最终分割性能的情况下减少标签数量的问题。我们探讨了使用来自目标领域的自我监督方式进行预训练的可能性。为了更好地利用这些数据，我们提出了一组特定领域的增强策略。我们对语义分割性能的预训练进行评估。

    Agricultural robots have the prospect to enable more efficient and sustainable agricultural production of food, feed, and fiber. Perception of crops and weeds is a central component of agricultural robots that aim to monitor fields and assess the plants as well as their growth stage in an automatic manner. Semantic perception mostly relies on deep learning using supervised approaches, which require time and qualified workers to label fairly large amounts of data. In this paper, we look into the problem of reducing the amount of labels without compromising the final segmentation performance. For robots operating in the field, pre-training networks in a supervised way is already a popular method to reduce the number of required labeled images. We investigate the possibility of pre-training in a self-supervised fashion using data from the target domain. To better exploit this data, we propose a set of domain-specific augmentation strategies. We evaluate our pre-training on semantic segmen
    
[^41]: 通过信息度量的下界贝叶斯风险

    Lower Bound on the Bayesian Risk via Information Measure. (arXiv:2303.12497v1 [cs.IT])

    [http://arxiv.org/abs/2303.12497](http://arxiv.org/abs/2303.12497)

    新提出一种方法计算贝叶斯风险下界，允许使用几乎任何信息度量，能提供与估计器无关的不可能结果。已应用于离散和连续参数问题，与最先进的技术进行了比较。

    

    本文关注参数估计，介绍了一种新的方法来计算贝叶斯风险下界。该方法允许使用几乎任何信息度量，包括Rényi的α，φ-分歧和Sibson的α-互信息。该 方法将分歧视为度量的函数，并利用度量空间和函数空间之间的对偶性。特别地，我们展示了通过马尔可夫不等式对其对偶进行上界限制，就可以用任何信息度量计算风险的下界。因此，由于分歧满足数据处理不等式，我们能够提供与估计器无关的不可能结果。然后将这些结果应用于涉及离散和连续参数的有趣问题，包括“捉迷藏”问题，并与最先进的技术进行比较。重要的观察是下界在样本数上的行为受到t的影响。

    This paper focuses on parameter estimation and introduces a new method for lower bounding the Bayesian risk. The method allows for the use of virtually \emph{any} information measure, including R\'enyi's $\alpha$, $\varphi$-Divergences, and Sibson's $\alpha$-Mutual Information. The approach considers divergences as functionals of measures and exploits the duality between spaces of measures and spaces of functions. In particular, we show that one can lower bound the risk with any information measure by upper bounding its dual via Markov's inequality. We are thus able to provide estimator-independent impossibility results thanks to the Data-Processing Inequalities that divergences satisfy. The results are then applied to settings of interest involving both discrete and continuous parameters, including the ``Hide-and-Seek'' problem, and compared to the state-of-the-art techniques. An important observation is that the behaviour of the lower bound in the number of samples is influenced by t
    
[^42]: 少样本、多模态、多任务、多语言学习

    Few-shot Multimodal Multitask Multilingual Learning. (arXiv:2303.12489v1 [cs.LG])

    [http://arxiv.org/abs/2303.12489](http://arxiv.org/abs/2303.12489)

    提出了一种多阶段微调框架，针对少样本多模态多任务多语言学习，可以有效地利用迁移学习和少样本学习的优势，它采用一种通用的编码器-解码器骨架，并使用注意机制处理多模态信息和每个任务的语言特定的微调，在多个基准数据集上表现优异。

    

    少样本学习作为一种迁移学习范式，在数据受限的情况下已经得到了广泛的应用。然而，过去主要是在构建单模态单语言模型的背景下探讨了少样本学习。现有的少样本多任务学习领域的大部分文献都是在上下文学习的情况下进行的，需要手动生成提示作为输入，这导致了结果的差异，取决于手动提示工程的水平。此外，上下文学习会带来相当大的计算、内存、存储成本，最终导致高推理延迟，因为它涉及每次进行预测时都要通过模型运行所有提示的示例。相比之下，通过微调范式的迁移学习方法避免了上述问题，在任务的基础上以一次性的代价微调权重。然而，这种方法缺乏少样本多模态多任务学习的经验。在本文中，我们提出了一种多阶段微调框架，针对少样本多模态多任务多语言学习，可以有效地利用迁移学习和少样本学习的优势。我们的方法采用一种通用的编码器-解码器骨架，并使用注意机制处理多模态信息和每个任务的语言特定的微调。所提出的框架表现出了优秀的性能，在几个基准数据集上优于现有模型。

    While few-shot learning as a transfer learning paradigm has gained significant traction for scenarios with limited data, it has primarily been explored in the context of building unimodal and unilingual models. Furthermore, a significant part of the existing literature in the domain of few-shot multitask learning perform in-context learning which requires manually generated prompts as the input, yielding varying outcomes depending on the level of manual prompt-engineering. In addition, in-context learning suffers from substantial computational, memory, and storage costs which eventually leads to high inference latency because it involves running all of the prompt's examples through the model every time a prediction is made. In contrast, methods based on the transfer learning via the fine-tuning paradigm avoid the aforementioned issues at a one-time cost of fine-tuning weights on a per-task basis. However, such methods lack exposure to few-shot multimodal multitask learning. In this pap
    
[^43]: 学习人类启发的力策略用于机器人组装

    Learning Human-Inspired Force Strategies for Robotic Assembly. (arXiv:2303.12440v1 [cs.RO])

    [http://arxiv.org/abs/2303.12440](http://arxiv.org/abs/2303.12440)

    该论文展示了通过从人类示范中学习概率力策略的方法，以便在机器人组装任务中对低零件间隙和位置变化做出反应，解决了从离线模拟数据学习策略无法直接在线应用的问题。

    

    机器人组装任务的编程是制造业和自动化的重要组成部分。然而，对于具有力敏感属性的组装，常常需要反应性策略来处理微小的位置变化和意外的零件卡死。从人类表现中学习这样的策略是一种有前途的方法，但面临两个常见的挑战：处理低部分间隙的难度很大，难以从演示中获取，并学习直观的策略，而无需在离线状态下访问真实硬件。我们通过从操纵杆的人类演示中在没有机器人的模拟环境中轻松获取的数据中学习概率力策略来解决这两个挑战。我们结合了长短期记忆（LSTM）和混合密度网络（MDN）来模拟人类启发式行为，使学习的策略易于转移到真实硬件上。实验表明，UR10e机器人可以完成塑料组装任务，其间隙小于100微米。

    The programming of robotic assembly tasks is a key component in manufacturing and automation. Force-sensitive assembly, however, often requires reactive strategies to handle slight changes in positioning and unforeseen part jamming. Learning such strategies from human performance is a promising approach, but faces two common challenges: the handling of low part clearances which is difficult to capture from demonstrations and learning intuitive strategies offline without access to the real hardware. We address these two challenges by learning probabilistic force strategies from data that are easily acquired offline in a robot-less simulation from human demonstrations with a joystick. We combine a Long Short Term Memory (LSTM) and a Mixture Density Network (MDN) to model human-inspired behavior in such a way that the learned strategies transfer easily onto real hardware. The experiments show a UR10e robot that completes a plastic assembly with clearances of less than 100 micrometers whos
    
[^44]: 使用对比学习和不相关条件的非监督域适应，训练面向事件的网络

    Unsupervised Domain Adaptation for Training Event-Based Networks Using Contrastive Learning and Uncorrelated Conditioning. (arXiv:2303.12424v1 [cs.CV])

    [http://arxiv.org/abs/2303.12424](http://arxiv.org/abs/2303.12424)

    发展了一种非监督域适应算法，使用对比学习和不相关条件的数据来训练深度神经网络，涉及事件相机图片分类，这种方法能够应对数据稀缺的困境，并且优于现有算法。

    

    事件相机在高动态范围环境和快速运动机动期间进行计算机视觉任务时提供可靠的测量。然而，采用深度学习进行事件驱动视觉面临着由于事件相机的最近性而导致的注释数据稀缺的挑战。从传统相机注释数据中获取的知识转移提供了这一挑战的实用解决方法。我们开发了一种非监督域适应算法，使用对比学习和不相关数据条件来训练面向事件的数据图像分类的深度网络。我们的解决方案优于现有的此类算法。

    Event-based cameras offer reliable measurements for preforming computer vision tasks in high-dynamic range environments and during fast motion maneuvers. However, adopting deep learning in event-based vision faces the challenge of annotated data scarcity due to recency of event cameras. Transferring the knowledge that can be obtained from conventional camera annotated data offers a practical solution to this challenge. We develop an unsupervised domain adaptation algorithm for training a deep network for event-based data image classification using contrastive learning and uncorrelated conditioning of data. Our solution outperforms the existing algorithms for this purpose.
    
[^45]: 延迟感知的分层联邦学习

    Delay-Aware Hierarchical Federated Learning. (arXiv:2303.12414v1 [cs.LG])

    [http://arxiv.org/abs/2303.12414](http://arxiv.org/abs/2303.12414)

    本论文提出了延迟感知的联邦学习(DFL)，通过解决边缘和云之间的通信延迟，提高了分布式机器学习模型训练的效率，并实现了一些政策以减少能量消耗和边缘到云端的通信。

    

    联邦学习作为一种在分布式环境下训练模型的方法，已经越来越受到关注。本文引入了延迟感知的联邦学习(DFL)，通过解决边缘和云之间的通信延迟，提高了分布式机器学习模型训练的效率。DFL在每个全局聚合间隔期间对设备数据集执行多个随机梯度下降迭代，并通过边缘服务器在本地子网络中间断地聚合模型参数。云服务器通过局部-全局合并器将本地模型与全局部署模型同步。DFL的收敛行为在广义数据异质性度量下进行了理论研究。得出了一组条件，以实现O(1/k)的次线性收敛率。基于这些发现，开发了一个自适应控制算法来实现DFL，并实现了一些政策以减少能量消耗和边缘到云端的通信。

    Federated learning has gained popularity as a means of training models distributed across the wireless edge. The paper introduces delay-aware federated learning (DFL) to improve the efficiency of distributed machine learning (ML) model training by addressing communication delays between edge and cloud. DFL employs multiple stochastic gradient descent iterations on device datasets during each global aggregation interval and intermittently aggregates model parameters through edge servers in local subnetworks. The cloud server synchronizes the local models with the global deployed model computed via a local-global combiner at global synchronization. The convergence behavior of DFL is theoretically investigated under a generalized data heterogeneity metric. A set of conditions is obtained to achieve the sub-linear convergence rate of O(1/k). Based on these findings, an adaptive control algorithm is developed for DFL, implementing policies to mitigate energy consumption and edge-to-cloud co
    
[^46]: EDGI: 内在对称性规划的等变扩散

    EDGI: Equivariant Diffusion for Planning with Embodied Agents. (arXiv:2303.12410v1 [cs.LG])

    [http://arxiv.org/abs/2303.12410](http://arxiv.org/abs/2303.12410)

    EDGI是一种基于模型的强化学习和规划算法，通过等变扩散处理内在对称性，具有更高效的采样和更好的泛化能力，适用于具有内在对称性的机器人操作任务。

    

    内在对称性是时空和排列上的，大多数计划和基于模型的强化学习算法没有考虑这种丰富的几何结构，导致采样效率低和泛化能力弱。本文提出了一种内在对称性规划的等变扩散算法(EDGI), 可用于基于模型的强化学习和规划，并引入一种新的支持多种表示形式的扩散模型。

    Embodied agents operate in a structured world, often solving tasks with spatial, temporal, and permutation symmetries. Most algorithms for planning and model-based reinforcement learning (MBRL) do not take this rich geometric structure into account, leading to sample inefficiency and poor generalization. We introduce the Equivariant Diffuser for Generating Interactions (EDGI), an algorithm for MBRL and planning that is equivariant with respect to the product of the spatial symmetry group $\mathrm{SE(3)}$, the discrete-time translation group $\mathbb{Z}$, and the object permutation group $\mathrm{S}_n$. EDGI follows the Diffuser framework (Janner et al. 2022) in treating both learning a world model and planning in it as a conditional generative modeling problem, training a diffusion model on an offline trajectory dataset. We introduce a new $\mathrm{SE(3)} \times \mathbb{Z} \times \mathrm{S}_n$-equivariant diffusion model that supports multiple representations. We integrate this model i
    
[^47]: 通过小波神经算子实现Transformers的多尺度注意力机制

    Multiscale Attention via Wavelet Neural Operators for Vision Transformers. (arXiv:2303.12398v1 [cs.CV])

    [http://arxiv.org/abs/2303.12398](http://arxiv.org/abs/2303.12398)

    本文介绍了一种基于小波神经算子的多尺度注意力机制，它通过使用小波神经算子将注意力机制从局部扩展到全域和多尺度范围内，取得了比ViT和AFNO更显著的性能提高。

    

    Transformer在计算机视觉中取得了广泛的成功。其核心是自注意机制（SA），它是一种归纳偏见，通过加权基础将输入中的每个token与每个其他token相关联。标准的SA机制具有二次复杂度，难以处理高分辨率图像中出现的长序列。为此，我们引入了基于小波神经算子的Multiscale Wavelet Attention（MWA），使用小波神经算子将注意力机制从局部扩展到全域和多尺度范围内。我们用CIFAR和ImageNet进行了实验，结果表明，MWA比ViT和AFNO都表现出显著的性能提高。

    Transformers have achieved widespread success in computer vision. At their heart, there is a Self-Attention (SA) mechanism, an inductive bias that associates each token in the input with every other token through a weighted basis. The standard SA mechanism has quadratic complexity with the sequence length, which impedes its utility to long sequences appearing in high resolution vision. Recently, inspired by operator learning for PDEs, Adaptive Fourier Neural Operators (AFNO) were introduced for high resolution attention based on global convolution that is efficiently implemented via FFT. However, the AFNO global filtering cannot well represent small and moderate scale structures that commonly appear in natural images. To leverage the coarse-to-fine scale structures we introduce a Multiscale Wavelet Attention (MWA) by leveraging wavelet neural operators which incurs linear complexity in the sequence size. We replace the attention in ViT with MWA and our experiments with CIFAR and ImageN
    
[^48]: 部分自动化下的干扰注入：长时间任务的鲁棒模仿学习

    Disturbance Injection under Partial Automation: Robust Imitation Learning for Long-horizon Tasks. (arXiv:2303.12375v1 [cs.RO])

    [http://arxiv.org/abs/2303.12375](http://arxiv.org/abs/2303.12375)

    本文提出了一种干扰注入的鲁棒模仿学习框架，针对部分自动化下长时间任务的应用进行优化，通过变量干扰来提升学习效果。

    

    部分自动化 (PA) 技术通过引入智能支持系统，已经应用于工业机械和高级汽车中，以减少人类操作的长时间负担。在 PA 下，操作员执行手动操作（提供动作）和自动 / 手动模式的操作（模式切换）。由于 PA 缩短了手动操作的总时间，因此这两种操作可以通过模仿学习高效地复制。针对此问题，本文提出了 Disturbance Injection under Partial Automation (DIPA) 作为一种新的模仿学习框架。在 DIPA 中，假设状态中的模式和手动模式下的动作是可观测的，用于学习动作和模式转换策略。为了优化在 PA 下的协变量偏移最小化，我们通过向操作员的动作注入干扰来鲁棒化上述学习。我们实验证明了我们方法的有效性。

    Partial Automation (PA) with intelligent support systems has been introduced in industrial machinery and advanced automobiles to reduce the burden of long hours of human operation. Under PA, operators perform manual operations (providing actions) and operations that switch to automatic/manual mode (mode-switching). Since PA reduces the total duration of manual operation, these two action and mode-switching operations can be replicated by imitation learning with high sample efficiency. To this end, this paper proposes Disturbance Injection under Partial Automation (DIPA) as a novel imitation learning framework. In DIPA, mode and actions (in the manual mode) are assumed to be observables in each state and are used to learn both action and mode-switching policies. The above learning is robustified by injecting disturbances into the operator's actions to optimize the disturbance's level for minimizing the covariate shift under PA. We experimentally validated the effectiveness of our method
    
[^49]: AIIPot: 适应性物联网设备智能交互蜜罐

    AIIPot: Adaptive Intelligent-Interaction Honeypot for IoT Devices. (arXiv:2303.12367v1 [cs.CR])

    [http://arxiv.org/abs/2303.12367](http://arxiv.org/abs/2303.12367)

    本文提出一种使用机器学习技术的蜜罐，可以自动学习和与攻击者交互，并有效提高物联网设备的安全水平。

    

    物联网的发展引起了人们对连接设备安全性的担忧。应该开发适合的、经济有效的方法来识别IoT设备的漏洞，以便在攻击者利用它们之前解决这些问题。欺骗技术是改善IoT系统安全性的一种重要方法，其中蜜罐是一种流行的欺骗技术，可以模拟真实交互并鼓励未经授权的用户（攻击者）发动攻击。由于IoT设备的数量和异构性巨大，手动制作低交互和高交互蜜罐是不可承受的。因此，研究人员也要寻求创新的方式来构建IoT设备的蜜罐。在本文中，我们提出了一种适用于IoT设备的蜜罐，它使用机器学习技术来自动学习和自动与攻击者交互。所提出模型的评估表明，我们的系统可以提高会话的以及安全级别。

    The proliferation of the Internet of Things (IoT) has raised concerns about the security of connected devices. There is a need to develop suitable and cost-efficient methods to identify vulnerabilities in IoT devices in order to address them before attackers seize opportunities to compromise them. The deception technique is a prominent approach to improving the security posture of IoT systems. Honeypot is a popular deception technique that mimics interaction in real fashion and encourages unauthorised users (attackers) to launch attacks. Due to the large number and the heterogeneity of IoT devices, manually crafting the low and high-interaction honeypots is not affordable. This has forced researchers to seek innovative ways to build honeypots for IoT devices. In this paper, we propose a honeypot for IoT devices that uses machine learning techniques to learn and interact with attackers automatically. The evaluation of the proposed model indicates that our system can improve the session 
    
[^50]: ExBEHRT：基于电子病历的扩展Transformer预测疾病亚型和进展

    ExBEHRT: Extended Transformer for Electronic Health Records to Predict Disease Subtypes & Progressions. (arXiv:2303.12364v1 [cs.LG])

    [http://arxiv.org/abs/2303.12364](http://arxiv.org/abs/2303.12364)

    ExBEHRT是一种扩展Transformer模型，应用于电子病历数据，将多种类型的记录包括在特征空间中，可以预测不同疾病下游任务的性能更好，并使用预期梯度对结果进行更细粒度的解释。

    

    本研究引入了ExBEHRT，它是BEHRT（应用于电子病历的BERT）的扩展版本，并应用不同的算法来解释其结果。我们将特征空间从仅考虑诊断和患者年龄扩展到包括多种类型的记录，包括人口统计学、临床特征、生命体征、吸烟状态、诊断、手术、药物和实验室检查，并采用一种新方法来统一不同特征的频率和时间维度。我们展示了附加特征可以显著改善不同疾病下游任务的模型性能。为了保证模型的稳健性，我们使用了预期梯度的改进方法对模型预测结果进行解释，该方法以前未应用于将EHR数据与Transformer相结合，提供了比以前方法更细粒度的解释，如特征和令牌重要性。此外，通过对肿瘤学患者的模型表示进行聚类，我们展示了ExBEHRT可以用于预测疾病亚型和进展。

    In this study, we introduce ExBEHRT, an extended version of BEHRT (BERT applied to electronic health records), and apply different algorithms to interpret its results. While BEHRT considers only diagnoses and patient age, we extend the feature space to several multimodal records, namely demographics, clinical characteristics, vital signs, smoking status, diagnoses, procedures, medications, and laboratory tests, by applying a novel method to unify the frequencies and temporal dimensions of the different features. We show that additional features significantly improve model performance for various downstream tasks in different diseases. To ensure robustness, we interpret model predictions using an adaptation of expected gradients, which has not been previously applied to transformers with EHR data and provides more granular interpretations than previous approaches such as feature and token importances. Furthermore, by clustering the model representations of oncology patients, we show tha
    
[^51]: 分布约束的softmax损失函数用于提高模型鲁棒性

    Distribution-restrained Softmax Loss for the Model Robustness. (arXiv:2303.12363v1 [cs.LG])

    [http://arxiv.org/abs/2303.12363](http://arxiv.org/abs/2303.12363)

    本文发现影响深度学习模型鲁棒性的因素是softmax对于非真实标签样本的值的分布特征，提出了一种分布约束的softmax损失函数以提高模型鲁棒性。

    

    深度学习模型的鲁棒性近来引起了广泛关注，提出了许多提高模型鲁棒性的方法，包括对抗训练、模型架构修改、损失函数的设计、认证防御等。然而，鲁棒性原则仍未被充分理解，相关研究尚不足够。本文发现影响模型鲁棒性的一个显著因素是softmax对于非真实标签样本的值的分布特征。我们发现攻击后的结果与分布特征高度相关，因此我们提出了一种能够抑制softmax分布多样性的损失函数。大量实验证明了我们的方法能够提高模型的鲁棒性而不会显著增加时间消耗。

    Recently, the robustness of deep learning models has received widespread attention, and various methods for improving model robustness have been proposed, including adversarial training, model architecture modification, design of loss functions, certified defenses, and so on. However, the principle of the robustness to attacks is still not fully understood, also the related research is still not sufficient. Here, we have identified a significant factor that affects the robustness of models: the distribution characteristics of softmax values for non-real label samples. We found that the results after an attack are highly correlated with the distribution characteristics, and thus we proposed a loss function to suppress the distribution diversity of softmax. A large number of experiments have shown that our method can improve robustness without significant time consumption.
    
[^52]: Wasserstein空间的对抗性例子用于单变量时间序列数据

    Wasserstein Adversarial Examples on Univariant Time Series Data. (arXiv:2303.12357v1 [cs.LG])

    [http://arxiv.org/abs/2303.12357](http://arxiv.org/abs/2303.12357)

    该论文为时间序列数据提出了一种新的对抗性攻击方法WPGD，利用Wasserstein距离限制正常样本和对抗性例子之间的扰动。实验结果表明该方法能够成功地对单变量时间序列数据进行对抗性攻击，并显著提高成功率。

    

    对抗性例子是通过向正常样本添加无法区分的扰动来欺骗良好训练的深度学习模型，使其错误地分类。在计算机视觉的背景下，区分度的概念通常由$L_{\infty}$或其他规范来限定，但是这些规范不适用于时间序列数据的区分度衡量。在本研究中，我们首次针对时间序列数据提出了Wasserstein空间中的对抗性例子，并利用Wasserstein距离来限定正常样本和对抗性例子之间的扰动。我们引入了Wasserstein投影梯度下降（WPGD），一种扰动单变量时间序列数据的对抗性攻击方法。我们利用1D空间中Wasserstein距离的封闭形式解来计算WPGD的投影步骤，以最小化扰动。我们进一步提出了两步投影方法，以有效进行在Wasserstein空间中的对抗性例子搜索。我们的实验结果表明，与其他最先进的方法相比，WPGD能够成功地对单变量时间序列数据进行对抗性攻击，并显著提高攻击的成功率。

    Adversarial examples are crafted by adding indistinguishable perturbations to normal examples in order to fool a well-trained deep learning model to misclassify. In the context of computer vision, this notion of indistinguishability is typically bounded by $L_{\infty}$ or other norms. However, these norms are not appropriate for measuring indistinguishiability for time series data. In this work, we propose adversarial examples in the Wasserstein space for time series data for the first time and utilize Wasserstein distance to bound the perturbation between normal examples and adversarial examples. We introduce Wasserstein projected gradient descent (WPGD), an adversarial attack method for perturbing univariant time series data. We leverage the closed-form solution of Wasserstein distance in the 1D space to calculate the projection step of WPGD efficiently with the gradient descent method. We further propose a two-step projection so that the search of adversarial examples in the Wassers
    
[^53]: 利用量子退火器对多层感知机进行采样训练

    Training Multilayer Perceptrons by Sampling with Quantum Annealers. (arXiv:2303.12352v1 [cs.LG])

    [http://arxiv.org/abs/2303.12352](http://arxiv.org/abs/2303.12352)

    本论文探索通过量子退火算法来训练多层感知机的方法，通过采样引擎实现多层感知机的训练，具有很好的研究价值。

    

    量子退火算法在训练受限玻尔兹曼机的应用较为成功。然而，许多用于视觉应用的神经网络是前向结构，如多层感知机。反向传播是目前用于监督学习的训练多层感知机的最有效技术。本文旨在展望未来，探索利用量子退火器进行多层感知机的训练。我们利用多层感知机与能量模型的等价性（EBM），EBM是一种具有最大条件似然目标的RBM变种。这导致采用量子退火器作为采样引擎来训练多层感知机的策略。我们证明了使用Sigmoid激活函数和一个隐藏层的多层感知机的设置，并演示了在MNIST和Fashion-MNIST数据集的小子集上使用D-Wave量子退火器训练二进制图像分类器的结果。尽管当前量子退火器可行的问题规模有限，但我们获得了全面的结果。

    A successful application of quantum annealing to machine learning is training restricted Boltzmann machines (RBM). However, many neural networks for vision applications are feedforward structures, such as multilayer perceptrons (MLP). Backpropagation is currently the most effective technique to train MLPs for supervised learning. This paper aims to be forward-looking by exploring the training of MLPs using quantum annealers. We exploit an equivalence between MLPs and energy-based models (EBM), which are a variation of RBMs with a maximum conditional likelihood objective. This leads to a strategy to train MLPs with quantum annealers as a sampling engine. We prove our setup for MLPs with sigmoid activation functions and one hidden layer, and demonstrated training of binary image classifiers on small subsets of the MNIST and Fashion-MNIST datasets using the D-Wave quantum annealer. Although problem sizes that are feasible on current annealers are limited, we obtained comprehensive results
    
[^54]: EasyDGL: 连续时间动态图学习的编码、训练和解释

    EasyDGL: Encode, Train and Interpret for Continuous-time Dynamic Graph Learning. (arXiv:2303.12341v1 [cs.LG])

    [http://arxiv.org/abs/2303.12341](http://arxiv.org/abs/2303.12341)

    EasyDGL 提出了一个易于使用的连续时间动态图学习的流水线，其中包含编码、训练和解释三个关键步骤。它使用时间点过程调制的注意力架构来处理连续时间动态图，在任务不可知的损失和任务感知损失的组合下实现动态链接预测、动态节点分类和节点流量预测，并通过敏感性分析对模型输出进行解释。

    

    动态图在各种实际应用中都很常见，直接在连续时间域中建模动态图以实现灵活性是被欢迎的选择。本文旨在设计一个易于使用的流水线（名为EasyDGL，也因其由DGL工具包实现而得名），它由三个关键模块组成，既具有强大的拟合能力，又易于解释。具体来说，所提出的流水线涉及编码、训练和解释：i）时间点过程（TPP）调制的注意力架构将连续时间分辨率赋予观察到的具有边添加事件的图的耦合时空动态；ii）一个合理的损失，由任务不可知的基于观察到的图中事件的TPP后验最大化和一个带遮蔽策略的任务感知损失组成，其中涵盖的任务包括动态链接预测、动态节点分类和节点流量预测；iii）通过敏感性分析解释模型输出（例如节点和边的表示），从而有助于理解每个边和节点对模型预测的贡献。

    Dynamic graphs arise in various real-world applications, and it is often welcomed to model the dynamics directly in continuous time domain for its flexibility. This paper aims to design an easy-to-use pipeline (termed as EasyDGL which is also due to its implementation by DGL toolkit) composed of three key modules with both strong fitting ability and interpretability. Specifically the proposed pipeline which involves encoding, training and interpreting: i) a temporal point process (TPP) modulated attention architecture to endow the continuous-time resolution with the coupled spatiotemporal dynamics of the observed graph with edge-addition events; ii) a principled loss composed of task-agnostic TPP posterior maximization based on observed events on the graph, and a task-aware loss with a masking strategy over dynamic graph, where the covered tasks include dynamic link prediction, dynamic node classification and node traffic forecasting; iii) interpretation of the model outputs (e.g., rep
    
[^55]: 基于类间差异的联邦主动学习重新思考

    Re-thinking Federated Active Learning based on Inter-class Diversity. (arXiv:2303.12317v1 [cs.CV])

    [http://arxiv.org/abs/2303.12317](http://arxiv.org/abs/2303.12317)

    本研究提出了一种新的联邦主动学习采样策略LoGo，它能够抵御不同的本地异质性水平和全局不平衡比例，通过整合全局和仅本地查询选择器模型来解决双方不平衡。

    

    尽管联邦学习取得了令人瞩目的进展，但大多数研究假设客户端的数据是完全标记的。然而，在现实世界中，每个客户端可能会有大量未标记的实例。在利用未标记数据的各种方法中，联邦主动学习框架已经成为一种有前途的解决方案。在分散的设置中，有两种可用的查询选择器模型，即“全局”和“仅本地”模型，但很少有文献讨论它们的性能优劣及其原因。在这项工作中，我们首先展示了两个选择器模型的优越性取决于全局和本地类间多样性。此外，我们观察到全球和仅本地模型是解决双方不平衡的关键。基于我们的发现，我们提出了一种FAL抽样策略LoGo，它能够抵御不同的本地异质性水平和全局不平衡比例，通过两个步骤整合两种模型。

    Although federated learning has made awe-inspiring advances, most studies have assumed that the client's data are fully labeled. However, in a real-world scenario, every client may have a significant amount of unlabeled instances. Among the various approaches to utilizing unlabeled data, a federated active learning framework has emerged as a promising solution. In the decentralized setting, there are two types of available query selector models, namely 'global' and 'local-only' models, but little literature discusses their performance dominance and its causes. In this work, we first demonstrate that the superiority of two selector models depends on the global and local inter-class diversity. Furthermore, we observe that the global and local-only models are the keys to resolving the imbalance of each side. Based on our findings, we propose LoGo, a FAL sampling strategy robust to varying local heterogeneity levels and global imbalance ratio, that integrates both models by two steps of ac
    
[^56]: TsSHAP: 强大的模型不可知特征解释方法，适用于时间序列预测

    TsSHAP: Robust model agnostic feature-based explainability for time series forecasting. (arXiv:2303.12316v1 [cs.LG])

    [http://arxiv.org/abs/2303.12316](http://arxiv.org/abs/2303.12316)

    本文提出了一种特征解释算法TsSHAP，该算法可以解释黑盒预测模型的预测结果，在可解释特征空间和预测结果之间建立了映射。这种算法可以提供局部，半局部和全局解释，能够适用于时间序列预测问题。

    

    一个可靠的机器学习模型应该是准确和可解释的。理解模型为什么做出某些决策定义了可解释性的概念。虽然已经研究了各种解释性模型，并广泛应用于监督学习范式，如分类和回归，但是对于时间序列预测的解释性文献相对较少。 在本文中，我们提出了一个特征解释算法TsSHAP，它可以解释任何黑盒预测模型的预测结果。该方法对预测模型不可知，并且可以根据用户预先定义的可解释特征来解释预测结果。 SHAP值的解释是通过在替代模型上应用TreeSHAP算法获得的，该替代模型学习了可解释特征空间和黑盒模型预测之间的映射。此外，在时间序列的背景下，我们还规范了局部、半局部和全局解释的概念。

    A trustworthy machine learning model should be accurate as well as explainable. Understanding why a model makes a certain decision defines the notion of explainability. While various flavors of explainability have been well-studied in supervised learning paradigms like classification and regression, literature on explainability for time series forecasting is relatively scarce.  In this paper, we propose a feature-based explainability algorithm, TsSHAP, that can explain the forecast of any black-box forecasting model. The method is agnostic of the forecasting model and can provide explanations for a forecast in terms of interpretable features defined by the user a prior.  The explanations are in terms of the SHAP values obtained by applying the TreeSHAP algorithm on a surrogate model that learns a mapping between the interpretable feature space and the forecast of the black-box model.  Moreover, we formalize the notion of local, semi-local, and global explanations in the context of time
    
[^57]: 具有元梯度正则化的自监督元提示学习用于少样本泛化

    Self-supervised Meta-Prompt Learning with Meta-Gradient Regularization for Few-shot Generalization. (arXiv:2303.12314v1 [cs.CL])

    [http://arxiv.org/abs/2303.12314](http://arxiv.org/abs/2303.12314)

    提出了一种自我监督元提示学习框架SUPMER，包括元梯度正则化，用于少样本泛化，通过锚定的元训练任务和基于课程的任务增强丰富了任务分布，解决了在少样本情况下良好初始化软提示和过拟合的问题。

    

    提示调整是一种参数有效的方法，它学习软提示并使冻结的语言模型执行特定的下游任务。尽管有效，但提示调整在少样本情况下一方面严重依赖于良好的软提示初始化。另一方面，它很容易导致过度拟合。现有的方法利用预训练或监督元学习来初始化软提示，但它们不能对未见下游任务进行数据有效的泛化。为了解决以上问题，本文提出了一种新的自我监督元提示学习框架，其中包括元梯度正则化，用于少样本泛化（SUPMER）。我们首先设计了一组自监督锚定的元训练任务，具有不同的任务格式，并通过基于课程的任务增强进一步丰富了任务分布。然后将一种新的元梯度正则化方法集成到元提示学习中。它元学习在少样本情况下如何转换原始梯度。

    Prompt tuning is a parameter-efficient method, which learns soft prompts and conditions frozen language models to perform specific downstream tasks. Though effective, prompt tuning under few-shot settings on the one hand heavily relies on a good initialization of soft prompts. On the other hand, it can easily result in overfitting. Existing works leverage pre-training or supervised meta-learning to initialize soft prompts but they cannot data-efficiently generalize to unseen downstream tasks. To address the above problems, this paper proposes a novel Self-sUpervised meta-Prompt learning framework with meta-gradient Regularization for few-shot generalization (SUPMER). We first design a set of self-supervised anchor meta-training tasks with different task formats and further enrich the task distribution with curriculum-based task augmentation. Then a novel meta-gradient regularization method is integrated into meta-prompt learning. It meta-learns to transform the raw gradients during few
    
[^58]: 冻结语言模型助力心电信号零样本学习

    Frozen Language Model Helps ECG Zero-Shot Learning. (arXiv:2303.12311v1 [cs.LG])

    [http://arxiv.org/abs/2303.12311](http://arxiv.org/abs/2303.12311)

    该论文提出了一种名为METS的心电图分类方法，使用可训练的心电编码器和冻结的语言模型分别嵌入配对的心电图和自动生成的机器临床报告，以实现心电图零样本学习，并在两个基准心电图数据集上获得了比其他最先进的方法更好的性能。

    

    心电图是一种常用的非侵入式、方便的医疗监测工具，可辅助临床诊断心脏疾病。最近，深度学习（DL）技术，特别是自监督学习（SSL），在心电图分类方面展示出了巨大的潜力。在微调之后，SSL的预训练仅依靠少量的注释数据就取得了有竞争力的性能。然而，当前的SSL方法依赖于注释数据的可用性，无法预测微调数据集中不存在的标签。为了解决这一挑战，我们提出了多模态心电图文本自监督预训练（METS），这是第一篇利用自动生成的临床报告来指导心电图SSL预训练的工作。我们使用可训练的心电编码器和冻结的语言模型分别嵌入配对的心电图和自动生成的机器临床报告。SSL旨在最大化心电图和自动生成的报告之间的相似性，同时确保心电和文本模态的嵌入对齐良好。在两个基准心电图数据集上的实验结果表明，METS在零样本学习和少样本学习设置中显著改善了心电图分类性能，优于各种最先进的方法。

    The electrocardiogram (ECG) is one of the most commonly used non-invasive, convenient medical monitoring tools that assist in the clinical diagnosis of heart diseases. Recently, deep learning (DL) techniques, particularly self-supervised learning (SSL), have demonstrated great potential in the classification of ECG. SSL pre-training has achieved competitive performance with only a small amount of annotated data after fine-tuning. However, current SSL methods rely on the availability of annotated data and are unable to predict labels not existing in fine-tuning datasets. To address this challenge, we propose Multimodal ECG-Text Self-supervised pre-training (METS), the first work to utilize the auto-generated clinical reports to guide ECG SSL pre-training. We use a trainable ECG encoder and a frozen language model to embed paired ECG and automatically machine-generated clinical reports separately. The SSL aims to maximize the similarity between paired ECG and auto-generated report while 
    
[^59]: 知识图谱推理的图神经网络的逻辑表达能力

    Logical Expressiveness of Graph Neural Network for Knowledge Graph Reasoning. (arXiv:2303.12306v1 [cs.LG])

    [http://arxiv.org/abs/2303.12306](http://arxiv.org/abs/2303.12306)

    本文提出了一种理论分析图神经网络在知识图谱推理方面的逻辑表达能力的方法，并发现图神经网络可以从分级模态逻辑中捕获逻辑规则，从而设计出更好的知识图谱推理方法。

    

    近年来，图神经网络被引入用于学习知识图谱，并在知识图谱推理方面取得了最先进的性能。然而，对于它们良好的经验性能缺乏理论证明。此外，虽然知识图谱中的逻辑对于归纳和可解释的推理非常重要，但现有的基于图神经网络的方法只是为了适应数据分布，并且对它们的逻辑表达能力知之甚少。本文旨在填补上述空白。具体而言，我们从逻辑的表达能力对GNN进行理论分析，并找出知识图谱中可以捕获哪些逻辑规则。我们的结果首先表明，GNN可以从分级模态逻辑中捕获逻辑规则，为分析GNN在知识图谱推理方面的表达能力提供了新的理论工具；而一个查询标记技巧使得GNN更容易捕获逻辑规则，解释了为什么最先进的方法主要基于标记技巧。最后，我们理论上的见解促进了一个新的基于GNN的知识图谱推理方法的设计，它可以充分利用逻辑表达能力并实现更好的性能。

    Graph Neural Networks (GNNs) have been recently introduced to learn from knowledge graph (KG) and achieved state-of-the-art performance in KG reasoning. However, a theoretical certification for their good empirical performance is still absent. Besides, while logic in KG is important for inductive and interpretable inference, existing GNN-based methods are just designed to fit data distributions with limited knowledge of their logical expressiveness. We propose to fill the above gap in this paper. Specifically, we theoretically analyze GNN from logical expressiveness and find out what kind of logical rules can be captured from KG. Our results first show that GNN can capture logical rules from graded modal logic, providing a new theoretical tool for analyzing the expressiveness of GNN for KG reasoning; and a query labeling trick makes it easier for GNN to capture logical rules, explaining why SOTA methods are mainly based on labeling trick. Finally, insights from our theory motivate the 
    
[^60]: 量子兼容离散深度生成模型在航空数据异常检测中的应用

    Anomaly Detection in Aeronautics Data with Quantum-compatible Discrete Deep Generative Model. (arXiv:2303.12302v1 [cs.LG])

    [http://arxiv.org/abs/2303.12302](http://arxiv.org/abs/2303.12302)

    本文探讨了在飞行操作数据异常检测中，使用量子兼容离散深度生成模型（DVAE），其中具有限制玻尔兹曼机的先验，表现出优异的性能。

    

    深度生成学习不仅可用于生成统计特征源于输入数据的新数据，还可以通过根据重构质量将原本数据分为正常和异常实例，用于异常检测。本文探讨了三种无监督深度生成模型（具有高斯、伯努利和玻尔兹曼先验的变分自编码器（VAE））在商业飞行的飞行操作数据上检测异常的性能。我们制定了两种具有离散潜变量的VAE模型，一种具有分解伯努利先验，一种具有限制玻尔兹曼机作为先验，因为机器学习应用需要离散变量模型，而基于双态量子系统的量子设备要求该模型。使用RBM先验的DVAE在航空中的多元时间序列数据异常检测中有显著优异性能。我们的实验结果表明，与分解伯努利先验的DVAE、正常的高斯VAE和基于Mahalanobis距离的经典方法相比，使用RBM先验的DVAE具有更优秀的性能。

    Deep generative learning cannot only be used for generating new data with statistical characteristics derived from input data but also for anomaly detection, by separating nominal and anomalous instances based on their reconstruction quality. In this paper, we explore the performance of three unsupervised deep generative models -- variational autoencoders (VAEs) with Gaussian, Bernoulli, and Boltzmann priors -- in detecting anomalies in flight-operations data of commercial flights consisting of multivariate time series. We devised two VAE models with discrete latent variables (DVAEs), one with a factorized Bernoulli prior and one with a restricted Boltzmann machine (RBM) as prior, because of the demand for discrete-variable models in machine-learning applications and because the integration of quantum devices based on two-level quantum systems requires such models. The DVAE with RBM prior, using a relatively simple -- and classically or quantum-mechanically enhanceable -- sampling tech
    
[^61]: 一种解决秩一矩阵感知的通用算法

    A General Algorithm for Solving Rank-one Matrix Sensing. (arXiv:2303.12298v1 [cs.DS])

    [http://arxiv.org/abs/2303.12298](http://arxiv.org/abs/2303.12298)

    本文提出了一种通用算法，可以用于解决更通用的矩阵感知问题，并使用随机梯度下降设计具有可证收敛保证的高效算法。

    

    矩阵感知在科学和工程领域中有许多应用，例如系统控制，距离嵌入和计算机视觉。矩阵感知的目标是基于一系列测量$(u_i,b_i) \in \mathbb{R}^{n} \times \mathbb{R}$，从中恢复矩阵$A_\star \in \mathbb{R}^{n \times n}$，使得 $u_i^\top A_\star u_i = b_i$。先前的工作[ZJD15]聚焦于矩阵$A_\star$具有小秩，例如秩-$k$的情形。他们的分析严重依赖于RIP假设，使其不清楚如何推广到高秩矩阵。在本文中，我们放松了秩-$k$的假设，并解决了更通用的矩阵感知问题。给定精度参数$\delta\in (0,1)$，我们可以在$\widetilde{O}(m^{3/2}n^2\delta^{-1})$的时间复杂度内求解矩阵$ A \in \mathbb{R}^{n \times n}$，满足对于所有$i \in[m]$，都有$|u_i^\top A u_i - b_i|\leq \delta$。我们使用随机梯度下降设计了一种具有可证收敛保证的高效算法。

    Matrix sensing has many real-world applications in science and engineering, such as system control, distance embedding, and computer vision. The goal of matrix sensing is to recover a matrix $A_\star \in \mathbb{R}^{n \times n}$, based on a sequence of measurements $(u_i,b_i) \in \mathbb{R}^{n} \times \mathbb{R}$ such that $u_i^\top A_\star u_i = b_i$. Previous work [ZJD15] focused on the scenario where matrix $A_{\star}$ has a small rank, e.g. rank-$k$. Their analysis heavily relies on the RIP assumption, making it unclear how to generalize to high-rank matrices. In this paper, we relax that rank-$k$ assumption and solve a much more general matrix sensing problem. Given an accuracy parameter $\delta \in (0,1)$, we can compute $A \in \mathbb{R}^{n \times n}$ in $\widetilde{O}(m^{3/2} n^2 \delta^{-1} )$, such that $ |u_i^\top A u_i - b_i| \leq \delta$ for all $i \in [m]$. We design an efficient algorithm with provable convergence guarantees using stochastic gradient descent for this pro
    
[^62]: 原型有助于联邦学习：实现更快的收敛

    Prototype Helps Federated Learning: Towards Faster Convergence. (arXiv:2303.12296v1 [cs.LG])

    [http://arxiv.org/abs/2303.12296](http://arxiv.org/abs/2303.12296)

    本文提出一种基于原型的联邦学习框架，可以在只对联邦学习进行少量更改的情况下，提高模型推断的性能和精度，并实现高效的通信。

    

    联邦学习（FL）是一种分布式机器学习技术，多个客户端合作训练共享模型而不交换原始数据。然而，不同客户端数据分布的异质性通常导致模型推断能力不佳。本文提出一种基于原型的联邦学习框架，而只需对典型的联邦学习过程的最后一个全局迭代进行少量更改，即可实现更好的推断性能。在最后一次迭代中，服务器聚合从分布式客户端传输的原型，然后将其发送回本地客户端，以用于各自的模型推断。在两个基准数据集上的实验表明，我们的提议在不同的异质性设置下，可以实现比两个流行基准更高的准确性（至少1％）和相对高效的通信。

    Federated learning (FL) is a distributed machine learning technique in which multiple clients cooperate to train a shared model without exchanging their raw data. However, heterogeneity of data distribution among clients usually leads to poor model inference. In this paper, a prototype-based federated learning framework is proposed, which can achieve better inference performance with only a few changes to the last global iteration of the typical federated learning process. In the last iteration, the server aggregates the prototypes transmitted from distributed clients and then sends them back to local clients for their respective model inferences. Experiments on two baseline datasets show that our proposal can achieve higher accuracy (at least 1%) and relatively efficient communication than two popular baselines under different heterogeneous settings.
    
[^63]: 公平性提高了从嘈杂标记的长尾数据中的学习

    Fairness Improves Learning from Noisily Labeled Long-Tailed Data. (arXiv:2303.12291v1 [cs.LG])

    [http://arxiv.org/abs/2303.12291](http://arxiv.org/abs/2303.12291)

    该研究提出了一种公平性正则化器（FR），它通过规范任意两个子群体之间的性能差距来提高长尾数据集中学习的性能，并同时避免伤害任何一个子群体。

    

    长尾和嘈杂标记的数据在现实世界中经常出现，对学习带来了重大挑战。大多数先前的工作将其中一种问题单独处理，并未明确考虑两者的耦合效应。我们的实证观察表明，这种解决方案在数据集是长尾的标签噪声的情况下无法始终改善学习。此外，在存在标签噪声的情况下，现有方法并未观察到各个子群体普遍的提升;换句话说，某些子群体获得了提高精度的好处，但代价是伤害其他人。基于这些观察，我们引入了公平性正则化器（FR），灵感来自于在任何两个子群体之间规范性能差距。我们表明，引入的公平性正则化器提高了尾部子群体和总体学习性能。广泛的实验表明了该模型的有效性。

    Both long-tailed and noisily labeled data frequently appear in real-world applications and impose significant challenges for learning. Most prior works treat either problem in an isolated way and do not explicitly consider the coupling effects of the two. Our empirical observation reveals that such solutions fail to consistently improve the learning when the dataset is long-tailed with label noise. Moreover, with the presence of label noise, existing methods do not observe universal improvements across different sub-populations; in other words, some sub-populations enjoyed the benefits of improved accuracy at the cost of hurting others. Based on these observations, we introduce the Fairness Regularizer (FR), inspired by regularizing the performance gap between any two sub-populations. We show that the introduced fairness regularizer improves the performances of sub-populations on the tail and the overall learning performance. Extensive experiments demonstrate the effectiveness of the p
    
[^64]: 使用强化学习改善自动驾驶汽车与行人交互的自适应道路配置

    Adaptive Road Configurations for Improved Autonomous Vehicle-Pedestrian Interactions using Reinforcement Learning. (arXiv:2303.12289v1 [cs.LG])

    [http://arxiv.org/abs/2303.12289](http://arxiv.org/abs/2303.12289)

    该论文使用强化学习方法探讨如何动态生成行人和自动驾驶汽车 ROW 计划，优化交通流的效率，为行人分配更多空间。

    

    自动驾驶汽车的部署为未来城市道路基础设施的设计和管理提供了重大挑战和独特的机遇。为了重新定义道路空间的 ROW 构成，已经提出了多种设计方法和智能控制模型，但缺乏一个可以根据实时需求动态生成行人和自动驾驶汽车 ROW 计划的操作框架。本研究基于微观交通仿真，探讨了使用强化学习方法来改进 ROW 构成的方法。我们分别实现了集中式范式和分布式学习范式，以分别对多个路网配置进行动态控制。实验结果表明，这些算法有潜力提高交通流的效率并分配更多的空间给行人。此外，分布式学习算法优于集中式算法并实现了更好的训练效率。

    The deployment of Autonomous Vehicles (AVs) poses considerable challenges and unique opportunities for the design and management of future urban road infrastructure. In light of this disruptive transformation, the Right-Of-Way (ROW) composition of road space has the potential to be renewed. Design approaches and intelligent control models have been proposed to address this problem, but we lack an operational framework that can dynamically generate ROW plans for AVs and pedestrians in response to real-time demand. Based on microscopic traffic simulation, this study explores Reinforcement Learning (RL) methods for evolving ROW compositions. We implement a centralised paradigm and a distributive learning paradigm to separately perform the dynamic control on several road network configurations. Experimental results indicate that the algorithms have the potential to improve traffic flow efficiency and allocate more space for pedestrians. Furthermore, the distributive learning algorithm outp
    
[^65]: 独立学习和稀疏均衡计算在马尔可夫博弈中的难度

    Hardness of Independent Learning and Sparse Equilibrium Computation in Markov Games. (arXiv:2303.12287v1 [cs.LG])

    [http://arxiv.org/abs/2303.12287](http://arxiv.org/abs/2303.12287)

    本文研究了分散式多智能体强化学习的问题，证明了在标准马尔可夫博弈框架下不存在可获得纳什均衡且可独立学习的算法。

    

    本文研究了马尔可夫博弈中分散式多智能体强化学习的问题。一个基本问题是，是否存在算法，当所有代理采用并在分散方式下独立运行时，每个玩家都可以不后悔地进展，类似于正常形式游戏中的著名收敛结果。虽然最近的研究表明，在受限制的情况下（特别是当后悔与马尔可夫策略的偏离有关时），这种算法存在，但是独立的不后悔学习是否能在标准的马尔可夫博弈框架下实现是值得探讨的问题。我们从计算和统计角度相应地提出了一个明确的否定解决这个问题。

    We consider the problem of decentralized multi-agent reinforcement learning in Markov games. A fundamental question is whether there exist algorithms that, when adopted by all agents and run independently in a decentralized fashion, lead to no-regret for each player, analogous to celebrated convergence results in normal-form games. While recent work has shown that such algorithms exist for restricted settings (notably, when regret is defined with respect to deviations to Markovian policies), the question of whether independent no-regret learning can be achieved in the standard Markov game framework was open. We provide a decisive negative resolution this problem, both from a computational and statistical perspective. We show that:  - Under the widely-believed assumption that PPAD-hard problems cannot be solved in polynomial time, there is no polynomial-time algorithm that attains no-regret in general-sum Markov games when executed independently by all players, even when the game is kno
    
[^66]: 基于机器学习的空气污染降低方法

    Reducing Air Pollution through Machine Learning. (arXiv:2303.12285v1 [cs.LG])

    [http://arxiv.org/abs/2303.12285](http://arxiv.org/abs/2303.12285)

    本文介绍了一种基于机器学习的方法来将工业生产对周边城市的空气污染影响降至最低，同时保持生产活动。该方法结合了预测和指导式机器学习模型，并将环境影响减少和生产维持之间达成了多种权衡方案。

    

    本文提出了一种基于数据驱动的方法来减少工业生产对周边城市的空气污染效应，该方法将运营决策与天气条件相结合。我们的方法结合了预测和指导式机器学习模型来预测短期风速和方向，并推荐运营决策以减少或暂停工业生产。我们展示了减少环境影响和维持生产活动之间的几种权衡。我们框架的预测组件采用各种机器学习模型，如梯度提升树模型和集成方法，进行时间序列预测。指导性组件利用可解释的最优策略树提出多个权衡方案，例如将危险排放物减少33-47%和将不必要的成本降低40-63%。我们部署的模型显著降低了预测误差，对于小于12小时的预测，降低了38-52%的误差范围，对于12到48小时的预测，降低了14-46%的误差范围。

    This paper presents a data-driven approach to mitigate the effects of air pollution from industrial plants on nearby cities by linking operational decisions with weather conditions. Our method combines predictive and prescriptive machine learning models to forecast short-term wind speed and direction and recommend operational decisions to reduce or pause the industrial plant's production. We exhibit several trade-offs between reducing environmental impact and maintaining production activities. The predictive component of our framework employs various machine learning models, such as gradient-boosted tree-based models and ensemble methods, for time series forecasting. The prescriptive component utilizes interpretable optimal policy trees to propose multiple trade-offs, such as reducing dangerous emissions by 33-47% and unnecessary costs by 40-63%. Our deployed models significantly reduced forecasting errors, with a range of 38-52% for less than 12-hour lead time and 14-46% for 12 to 48-
    
[^67]: 带有重尾噪声的随机非光滑凸优化

    Stochastic Nonsmooth Convex Optimization with Heavy-Tailed Noises. (arXiv:2303.12277v1 [math.OC])

    [http://arxiv.org/abs/2303.12277](http://arxiv.org/abs/2303.12277)

    本文分析了具有重尾噪声的随机非光滑凸优化问题，并填补了在函数非光滑场景下的研究空白。

    

    最近，一些研究将随机优化问题考虑在重尾噪声范式下，即假设随机梯度和真实梯度之间的差异具有有限的 $p$ 阶矩（例如被某个 $\sigma \geq0$ 上界限制为 $\sigma^{p}$），其中 $p\in (1,2]$，这不仅泛化了传统的有限方差假设（$p=2$），而且在许多不同的任务中都被观察到。在这个具有挑战性的假设下，针对凸或非凸问题已经取得了很多新进展，然而，大多数只考虑光滑的目标函数。相反，在函数非光滑时，人们尚未充分探索并完全理解这个问题。本文旨在通过对带有重尾噪声的随机非光滑凸优化提供全面分析来填补这一关键空白。我们重新考虑了一个简单的基于裁剪的算法，然而，这个算法只被证明能以期望方式收敛，但在附加

    Recently, several studies consider the stochastic optimization problem but in a heavy-tailed noise regime, i.e., the difference between the stochastic gradient and the true gradient is assumed to have a finite $p$-th moment (say being upper bounded by $\sigma^{p}$ for some $\sigma\geq0$) where $p\in(1,2]$, which not only generalizes the traditional finite variance assumption ($p=2$) but also has been observed in practice for several different tasks. Under this challenging assumption, lots of new progress has been made for either convex or nonconvex problems, however, most of which only consider smooth objectives. In contrast, people have not fully explored and well understood this problem when functions are nonsmooth. This paper aims to fill this crucial gap by providing a comprehensive analysis of stochastic nonsmooth convex optimization with heavy-tailed noises. We revisit a simple clipping-based algorithm, whereas, which is only proved to converge in expectation but under the additi
    
[^68]: 自适应离群值优化：用于在线测试时OOD检测的方法

    AUTO: Adaptive Outlier Optimization for Online Test-Time OOD Detection. (arXiv:2303.12267v1 [cs.LG])

    [http://arxiv.org/abs/2303.12267](http://arxiv.org/abs/2303.12267)

    本文提出了一个称为AUTO的方法，在在线测试时利用未标记的在线数据直接提高OOD检测性能。该方法自适应地优化网络参数并在线检测OOD样本，取得了优于现有方法的结果。

    

    在开放世界的应用中，OOD（out-of-distribution）检测是部署机器学习模型的一个关键方面。经验证明，使用辅助离群值训练可以显著提高OOD检测性能。然而，这些离群值通常与测试OOD数据存在分布差距，并且不能覆盖所有可能的测试OOD情况。此外，结合这些离群值还会增加训练的负担。本文提出了一种称为测试时OOD检测的新范式，该范式直接利用未标记的在线数据，以提高OOD检测性能。虽然这种范式很高效，但它也面临着诸如灾难性遗忘等挑战。为了解决这些挑战，我们提出了自适应离群值优化（AUTO），它由内外感知滤波器、ID存储器和语义一致的目标组成。AUTO自适应地从测试数据中挖掘伪ID和伪OOD样本，利用它们来优化网络参数并在线检测OOD样本。实验结果表明，AUTO在各种基准和数据集上始终优于现有方法。

    Out-of-distribution (OOD) detection is a crucial aspect of deploying machine learning models in open-world applications. Empirical evidence suggests that training with auxiliary outliers substantially improves OOD detection. However, such outliers typically exhibit a distribution gap compared to the test OOD data and do not cover all possible test OOD scenarios. Additionally, incorporating these outliers introduces additional training burdens. In this paper, we introduce a novel paradigm called test-time OOD detection, which utilizes unlabeled online data directly at test time to improve OOD detection performance. While this paradigm is efficient, it also presents challenges such as catastrophic forgetting. To address these challenges, we propose adaptive outlier optimization (AUTO), which consists of an in-out-aware filter, an ID memory bank, and a semantically-consistent objective. AUTO adaptively mines pseudo-ID and pseudo-OOD samples from test data, utilizing them to optimize netwo
    
[^69]: 机器学习在多尺度计算模拟中的挑战和机遇

    Challenges and opportunities for machine learning in multiscale computational modeling. (arXiv:2303.12261v1 [cs.LG])

    [http://arxiv.org/abs/2303.12261](http://arxiv.org/abs/2303.12261)

    本文讨论了机器学习在复杂多尺度建模和模拟中的机遇和挑战，指出了机器学习可以作为传统数值方法的代理、加速或增强，并可以通过提供更好的初始解决方案来促进复杂的多尺度系统的解决问题。

    

    许多机械工程应用需要多尺度计算建模和模拟。然而，解决复杂的多尺度系统仍然具有高维度的解空间，计算量巨大。近年来，机器学习（ML）已经成为一种有前途的解决方案，可以作为传统数值方法的代理、加速或增强。先驱性的工作已经证明，ML可以提供与直接数值方法相当精度的控制方程的解决方案，但计算速度显著更快。这些高速、高精度的估计可以通过为传统解算器提供更好的初始解决方案，促进复杂的多尺度系统的解决。本文就使用ML进行复杂多尺度建模和模拟的机遇和挑战提供了一个视角。我们首先概述了用于模拟多尺度系统的现有ML方法，然后讨论了它们提高多尺度模拟速度和精度的潜力。最后，我们确定了为多尺度仿真开发ML算法所面临的挑战和未解决问题，并讨论了可能的研究方向。

    Many mechanical engineering applications call for multiscale computational modeling and simulation. However, solving for complex multiscale systems remains computationally onerous due to the high dimensionality of the solution space. Recently, machine learning (ML) has emerged as a promising solution that can either serve as a surrogate for, accelerate or augment traditional numerical methods. Pioneering work has demonstrated that ML provides solutions to governing systems of equations with comparable accuracy to those obtained using direct numerical methods, but with significantly faster computational speed. These high-speed, high-fidelity estimations can facilitate the solving of complex multiscale systems by providing a better initial solution to traditional solvers. This paper provides a perspective on the opportunities and challenges of using ML for complex multiscale modeling and simulation. We first outline the current state-of-the-art ML approaches for simulating multiscale sys
    
[^70]: 基于信息的传感器放置用于无定常流量的数据驱动估计

    Information-Based Sensor Placement for Data-Driven Estimation of Unsteady Flows. (arXiv:2303.12260v1 [physics.flu-dyn])

    [http://arxiv.org/abs/2303.12260](http://arxiv.org/abs/2303.12260)

    本文提出了一种基于数据驱动的流场估计的传感器选择框架，能够使用少量传感器高效地估计高攻角下机翼后流的流场。

    

    对飞行器周围的无定常流场的估计可能会改善流场交互并导致飞行器性能的提高。尽管流场表示可以是非常高维的，但它们的动态可以具有低阶表示，并且可以使用一些适当放置的测量来估计。本文提出了一个传感器选择框架，用于数据驱动的流场估计。该框架结合了数据驱动建模、稳态卡尔曼滤波器设计和一种用于顺序选择传感器的稀疏化技术。本文还使用传感器选择框架设计了传感器阵列，可以在各种操作条件下表现良好。数值数据上的流量估计结果表明，所提出的框架使用嵌入式压力传感器能够高效地估计高攻角下机翼后流的流场。流场分析表明

    Estimation of unsteady flow fields around flight vehicles may improve flow interactions and lead to enhanced vehicle performance. Although flow-field representations can be very high-dimensional, their dynamics can have low-order representations and may be estimated using a few, appropriately placed measurements. This paper presents a sensor-selection framework for the intended application of data-driven, flow-field estimation. This framework combines data-driven modeling, steady-state Kalman Filter design, and a sparsification technique for sequential selection of sensors. This paper also uses the sensor selection framework to design sensor arrays that can perform well across a variety of operating conditions. Flow estimation results on numerical data show that the proposed framework produces arrays that are highly effective at flow-field estimation for the flow behind and an airfoil at a high angle of attack using embedded pressure sensors. Analysis of the flow fields reveals that pa
    
[^71]: 在生成模型的潜空间中编码二元概念以增强数据表示

    Encoding Binary Concepts in the Latent Space of Generative Models for Enhancing Data Representation. (arXiv:2303.12255v1 [cs.LG])

    [http://arxiv.org/abs/2303.12255](http://arxiv.org/abs/2303.12255)

    本文提出了一种新的二元正则化方法以便于学习二元概念，从而提高自编码器生成数据的质量并改进模型的泛化性能。

    

    人类经验主义地使用二元概念来高效地推广。这些概念基于伯努利分布，是信息的基本组成部分。这些概念涵盖了低级和高级特征，如“大 vs 小”和“神经元处于活跃或非活跃状态”。二元概念是无处不在的特征，可以用于传递知识，以改进模型的泛化性能。我们提出了一种新的二元正则化方法，以便于学习二元概念，从而提高自编码器生成数据的质量。我们在数据生成过程中引入了二元化超参数$r$，以对称地解开潜在空间。我们证明了这种方法可以轻松应用于现有变分自编码器（VAE）变体，以鼓励对称解缠、提高重建质量并防止后验崩溃而无需计算开销。我们还证明了这种方法可以提高现有模型的泛化性能和学习可传递性表示。

    Binary concepts are empirically used by humans to generalize efficiently. And they are based on Bernoulli distribution which is the building block of information. These concepts span both low-level and high-level features such as "large vs small" and "a neuron is active or inactive". Binary concepts are ubiquitous features and can be used to transfer knowledge to improve model generalization. We propose a novel binarized regularization to facilitate learning of binary concepts to improve the quality of data generation in autoencoders. We introduce a binarizing hyperparameter $r$ in data generation process to disentangle the latent space symmetrically. We demonstrate that this method can be applied easily to existing variational autoencoder (VAE) variants to encourage symmetric disentanglement, improve reconstruction quality, and prevent posterior collapse without computation overhead. We also demonstrate that this method can boost existing models to learn more transferable representati
    
[^72]: 探索差分隐私中视觉提示的好处

    Exploring the Benefits of Visual Prompting in Differential Privacy. (arXiv:2303.12247v1 [cs.CV])

    [http://arxiv.org/abs/2303.12247](http://arxiv.org/abs/2303.12247)

    本文探讨了在差分隐私（DP）中利用视觉提示（VP）构建神经网络分类器的好处。VP与PATE相配合，在隐私预算最小的情况下实现了最先进的隐私-效用平衡，在跨域图像分类中也显示了其优势。此外，消融研究表明VP在DP中具有很好的有效性和贡献。

    

    视觉提示（VP）是一种新兴且强大的技术，通过设计一个经过良好训练的冻结源模型，可以实现对下游任务的样本高效适应。在本文中，我们探讨了在差分隐私（DP）中利用VP构建引人注目的神经网络分类器的好处。我们探索并将VP整合到经典的DP训练方法中，并展示了其简单性和效率。特别是，我们发现VP与PATE（一种利用教师集合的知识转移的最先进的DP训练方法）相配合，在隐私预算最小的情况下实现了最先进的隐私-效用平衡。此外，我们对跨域图像分类进行了额外的实验，以进一步揭示在DP中VP的优势。最后，我们进行了广泛的消融研究，以验证VP在DP考虑下的有效性和贡献。

    Visual Prompting (VP) is an emerging and powerful technique that allows sample-efficient adaptation to downstream tasks by engineering a well-trained frozen source model. In this work, we explore the benefits of VP in constructing compelling neural network classifiers with differential privacy (DP). We explore and integrate VP into canonical DP training methods and demonstrate its simplicity and efficiency. In particular, we discover that VP in tandem with PATE, a state-of-the-art DP training method that leverages the knowledge transfer from an ensemble of teachers, achieves the state-of-the-art privacy-utility trade-off with minimum expenditure of privacy budget. Moreover, we conduct additional experiments on cross-domain image classification with a sufficient domain gap to further unveil the advantage of VP in DP. Lastly, we also conduct extensive ablation studies to validate the effectiveness and contribution of VP under DP consideration.
    
[^73]: 物理启发式神经网络逼近二阶时间动力学偏微分方程的误差分析

    Error Analysis of Physics-Informed Neural Networks for Approximating Dynamic PDEs of Second Order in Time. (arXiv:2303.12245v1 [math.NA])

    [http://arxiv.org/abs/2303.12245](http://arxiv.org/abs/2303.12245)

    本文采用物理启发式神经网络(PINN)方法逼近一类二阶时间动力学偏微分方程(PDE)，提出一种新的损失函数形式，有效限制了逼近误差，并通过数值实验验证了新算法的有效性。

    

    本文考虑利用物理启发式神经网络(PINN)方法逼近一类二阶时间动力学偏微分方程(PDE)，并对波动方程、正弦-戈登方程和线性弹性动力学方程进行PINN的误差分析。结果表明，在具有两个隐藏层和$\tanh$激活函数的前馈神经网络中，PINN逼近误差可以通过训练损失和训练数据点数量(积分点)来有效地限制。我们进一步建议损失函数的新形式，其中包含某些残差，这些残差对误差估计至关重要，但在经典的PINN损失公式中可能不存在。采用这些新的损失函数形式可以导致一种变异的PINN算法。我们使用新的PINN算法对波动方程、正弦-戈登方程和线性弹性动力学方程进行了大量的数值实验，验证了误差估计的有效性并展示了新PINN算法的有效性。

    We consider the approximation of a class of dynamic partial differential equations (PDE) of second order in time by the physics-informed neural network (PINN) approach, and provide an error analysis of PINN for the wave equation, the Sine-Gordon equation and the linear elastodynamic equation. Our analyses show that, with feed-forward neural networks having two hidden layers and the $\tanh$ activation function, the PINN approximation errors for the solution field, its time derivative and its gradient field can be effectively bounded by the training loss and the number of training data points (quadrature points). Our analyses further suggest new forms for the training loss function, which contain certain residuals that are crucial to the error estimate but would be absent from the canonical PINN loss formulation. Adopting these new forms for the loss function leads to a variant PINN algorithm. We present ample numerical experiments with the new PINN algorithm for the wave equation, the S
    
[^74]: 基于双层图变换器的时空事故影响预测

    DG-Trans: Dual-level Graph Transformer for Spatiotemporal Incident Impact Prediction on Traffic Networks. (arXiv:2303.12238v1 [cs.LG])

    [http://arxiv.org/abs/2303.12238](http://arxiv.org/abs/2303.12238)

    提出了一种名为DG-Trans的交通事故影响预测框架，通过动态图学习预测交通事故的影响，包含一个双层空间变换器和一个基于重要性得分的时态变换器，成功解决了从动态图中提取异常子图或子时间序列的问题。

    

    及时预估交通事故的影响可以指导人们的出行规划，提高交通机构决策韧性。然而，相比于节点级和图级预测任务，它更具挑战性，因为它需要从动态图中提取异常子图或子时间序列。在本文中，我们提出了DG-Trans，一种新颖的交通事故影响预测框架，通过动态图学习预见交通事故的影响。所提出的框架包含一个双层空间变换器和一个基于重要性得分的时态变换器，并通过两个新构建的基准数据集验证了该框架的性能。双层空间变换器删除节点之间的不必要的边缘，将受影响的子图与其他节点隔离开来。与此同时，基于重要性得分的时态变换器识别节点特征的异常变化，使预测更依赖于最近的过去。

    The prompt estimation of traffic incident impacts can guide commuters in their trip planning and improve the resilience of transportation agencies' decision-making on resilience. However, it is more challenging than node-level and graph-level forecasting tasks, as it requires extracting the anomaly subgraph or sub-time-series from dynamic graphs. In this paper, we propose DG-Trans, a novel traffic incident impact prediction framework, to foresee the impact of traffic incidents through dynamic graph learning. The proposed framework contains a dual-level spatial transformer and an importance-score-based temporal transformer, and the performance of this framework is justified by two newly constructed benchmark datasets. The dual-level spatial transformer removes unnecessary edges between nodes to isolate the affected subgraph from the other nodes. Meanwhile, the importance-score-based temporal transformer identifies abnormal changes in node features, causing the predictions to rely more o
    
[^75]: 联邦学习中的安全聚合并非隐私：通过模型修改大规模泄露用户数据

    Secure Aggregation in Federated Learning is not Private: Leaking User Data at Large Scale through Model Modification. (arXiv:2303.12233v1 [cs.LG])

    [http://arxiv.org/abs/2303.12233](http://arxiv.org/abs/2303.12233)

    联邦学习虽然能够消除数据共享，但共享的梯度可能会包含私密信息，并且攻击者可以通过恶意修改架构和参数或使用优化从共享的梯度中近似用户数据，导致用户数据泄露。

    

    安全和隐私是机器学习中的重要问题。终端用户设备通常包含大量敏感数据，不应与服务器或企业分享。因此，联邦学习被引入以在大规模分散式数据集上进行机器学习，同时通过消除数据共享来保证隐私。然而，先前的研究表明，共享的梯度通常包含私密信息，攻击者可以通过恶意修改架构和参数或使用优化从共享梯度中近似用户数据来获得知识。尽管如此，大多数攻击至今仍受到限制，尤其是在使用安全模型聚合将客户端梯度聚合在一起时会失败。目前仍然可行的攻击在被攻击的客户端数量、泄漏的训练样本数量或训练所需的迭代次数方面都受到严格限制。

    Security and privacy are important concerns in machine learning. End user devices often contain a wealth of data and this information is sensitive and should not be shared with servers or enterprises. As a result, federated learning was introduced to enable machine learning over large decentralized datasets while promising privacy by eliminating the need for data sharing. However, prior work has shown that shared gradients often contain private information and attackers can gain knowledge either through malicious modification of the architecture and parameters or by using optimization to approximate user data from the shared gradients. Despite this, most attacks have so far been limited in scale of number of clients, especially failing when client gradients are aggregated together using secure model aggregation. The attacks that still function are strongly limited in the number of clients attacked, amount of training samples they leak, or number of iterations they take to be trained. I
    
[^76]: 基于基础设施的端到端学习和驾驶员失误预防

    Infrastructure-based End-to-End Learning and Prevention of Driver Failure. (arXiv:2303.12224v1 [cs.RO])

    [http://arxiv.org/abs/2303.12224](http://arxiv.org/abs/2303.12224)

    本论文介绍了一种基于循环神经网络的端到端训练方法来预测自动驾驶车辆中可能存在的故障和危险驾驶员，并在缩小的微型城市中进行了测试。

    

    智能交叉路口管理器可以通过检测自动驾驶车辆中的危险驾驶员或故障模式，警告接近交叉路口的来车，从而提高安全性。在这项工作中，我们介绍了FailureNet，这是一个在缩小的微型城市中基于轨迹对正常和不安全驾驶员进行端到端训练的循环神经网络。FailureNet观察车辆接近交叉口时的姿态，检测自主堆栈中是否存在故障，并警告交叉流量有潜在危险的驾驶员。FailureNet能够准确地识别控制故障、上游感知错误和超速驾驶员，与正常驾驶加以区别。该网络在MiniCity中进行训练和部署，与基于速度或频率的预测器相比，FailureNet的循环神经网络结构提供了更高的预测能力，当部署在硬件上时，其准确性高达84%以上。

    Intelligent intersection managers can improve safety by detecting dangerous drivers or failure modes in autonomous vehicles, warning oncoming vehicles as they approach an intersection. In this work, we present FailureNet, a recurrent neural network trained end-to-end on trajectories of both nominal and reckless drivers in a scaled miniature city. FailureNet observes the poses of vehicles as they approach an intersection and detects whether a failure is present in the autonomy stack, warning cross-traffic of potentially dangerous drivers. FailureNet can accurately identify control failures, upstream perception errors, and speeding drivers, distinguishing them from nominal driving. The network is trained and deployed with autonomous vehicles in the MiniCity. Compared to speed or frequency-based predictors, FailureNet's recurrent neural network structure provides improved predictive power, yielding upwards of 84% accuracy when deployed on hardware.
    
[^77]: 基于节点相似度、图表示学习和层次聚类的复杂网络社群检测

    Community detection in complex networks via node similarity, graph representation learning, and hierarchical clustering. (arXiv:2303.12212v1 [cs.SI])

    [http://arxiv.org/abs/2303.12212](http://arxiv.org/abs/2303.12212)

    本文提出了三种算法框架来将层次聚类方法应用于图中的社区检测。相似度矩阵、特征向量矩阵和节点欧几里得向量表示可应用于各种基于连接的聚类算法。同时，可以采用最先进的图表示学习算法和点间互信息正向算法。

    

    社群检测是分析实际图和复杂网络（如社交、交通、引用、网络安全以及食物链）的一个重要挑战。本文受到社区检测与欧几里得空间中聚类之间的许多相似性的启发，提出了三种算法框架，将层次聚类方法应用于图中的社区检测。我们表明，使用我们的方法，可以基于节点相似度矩阵、其特征向量矩阵以及节点的欧几里得向量表示，应用各种基于连接的聚类算法（单链接、全连接、平均链接、Ward、Genie）来查找社区。我们进行了全面的框架选择分析，包括最先进的图表示学习算法（如深度神经图表示）以及一个已知能够产生高质量结果的点间互信息正向算法。

    Community detection is a critical challenge in the analysis of real-world graphs and complex networks, including social, transportation, citation, cybersecurity networks, and food webs. Motivated by many similarities between community detection and clustering in Euclidean spaces, we propose three algorithm frameworks to apply hierarchical clustering methods for community detection in graphs. We show that using our methods, it is possible to apply various linkage-based (single-, complete-, average- linkage, Ward, Genie) clustering algorithms to find communities based on vertex similarity matrices, eigenvector matrices thereof, and Euclidean vector representations of nodes. We convey a comprehensive analysis of choices for each framework, including state-of-the-art graph representation learning algorithms, such as Deep Neural Graph Representation, and a vertex proximity matrix known to yield high-quality results in machine learning -- Positive Pointwise Mutual Information. Overall, we te
    
[^78]: 随机投影k最近邻集成分类器 via 扩展邻域规则

    A Random Projection k Nearest Neighbours Ensemble for Classification via Extended Neighbourhood Rule. (arXiv:2303.12210v1 [stat.ML])

    [http://arxiv.org/abs/2303.12210](http://arxiv.org/abs/2303.12210)

    本文提出了一种随机投影的kNN集成分类器，使用扩展邻域规则和降维来增加基本学习者的随机性并保留特征信息。

    

    基于k最近邻（kNN）的集成将许多基本学习者组合在一起，每个学习者都是基于给定训练数据中的一个样本构建的。这篇论文提出了一种新颖的随机投影扩展邻域规则（RPExNRule）集成，其中来自给定训练数据的自举样本在降低的维度中被随机投影，以增加基本模型的随机性并保留特征信息，并使用扩展邻域规则（ExNRule）将kNN作为基本学习者拟合随机投影的自举样本。

    Ensembles based on k nearest neighbours (kNN) combine a large number of base learners, each constructed on a sample taken from a given training data. Typical kNN based ensembles determine the k closest observations in the training data bounded to a test sample point by a spherical region to predict its class. In this paper, a novel random projection extended neighbourhood rule (RPExNRule) ensemble is proposed where bootstrap samples from the given training data are randomly projected into lower dimensions for additional randomness in the base models and to preserve features information. It uses the extended neighbourhood rule (ExNRule) to fit kNN as base learners on randomly projected bootstrap samples.
    
[^79]: MAGVLT: 带掩码的生成视觉语言变压器

    MAGVLT: Masked Generative Vision-and-Language Transformer. (arXiv:2303.12208v1 [cs.CV])

    [http://arxiv.org/abs/2303.12208](http://arxiv.org/abs/2303.12208)

    本文提出 MGVLT 模型用于生成图像和文本序列，通过非自回归掩码预测实现了双向上下文编码和快速解码等特点。

    

    虽然在多模态图像文本数据上的生成建模已经得到了广泛的发展，但仍有许多限制，例如仅生成一种模态的固定模型。在本文中，我们探讨了一种可以生成图像和文本序列的统一生成式视觉语言（VL）模型。特别地，我们提出了一种基于非自回归掩码预测的生成VL变压器，名为MAGVLT，并将其与自回归生成VL变压器（ARGVLT）进行了比较。与ARGVLT相比，所提出的MAGVLT实现了双向上下文编码，通过迭代细化的并行标记预测实现了快速解码，具有图像和文本填充等扩展编辑功能。为了从头开始严格训练我们的MAGVLT模型，我们结合了从图像到文本、从文本到图像、以及联合图像和文本的掩码预测任务。

    While generative modeling on multimodal image-text data has been actively developed with large-scale paired datasets, there have been limited attempts to generate both image and text data by a single model rather than a generation of one fixed modality conditioned on the other modality. In this paper, we explore a unified generative vision-and-language (VL) model that can produce both images and text sequences. Especially, we propose a generative VL transformer based on the non-autoregressive mask prediction, named MAGVLT, and compare it with an autoregressive generative VL transformer (ARGVLT). In comparison to ARGVLT, the proposed MAGVLT enables bidirectional context encoding, fast decoding by parallel token predictions in an iterative refinement, and extended editing capabilities such as image and text infilling. For rigorous training of our MAGVLT with image-text pairs from scratch, we combine the image-to-text, text-to-image, and joint image-and-text mask prediction tasks. Moreove
    
[^80]: 行为健康个性化介入的政策优化

    Policy Optimization for Personalized Interventions in Behavioral Health. (arXiv:2303.12206v1 [cs.LG])

    [http://arxiv.org/abs/2303.12206](http://arxiv.org/abs/2303.12206)

    研究如何通过数字平台传递的行为健康介入最大化健康结果和治疗成本，提出了一个名为DecompPI的新算法，从离线数据进行预测任务，减轻了在线实验的需要，并在理论上证明了该算法的可扩展性和渐近收敛性。

    

    问题定义：通过数字平台传递的行为健康介入，通过教育，激励，提醒和外展，有望显着改善健康结果。我们研究了在介入具有成本和能力限制的情况下，优化患者个性化介入以最大化某种长期结果的问题。方法/结果：本文提供了一种无模型方法来解决这个问题。我们发现，来自增强学习文献的通用无模型方法对于医疗应用来说过于数据密集，而更简单的赌臂问题方法取得了进展，但忽略了长期患者动态。我们提出了一种新算法，称为DecompPI，它近似于一步政策迭代。实现DecompPI只需从离线数据进行预测任务，减轻了在线实验的需要。在理论上，我们展示了在一种自然的结构假设下，DecompPI可以获得算法复杂度的渐近收敛性，同时保持一个可扩展的模型.

    Problem definition: Behavioral health interventions, delivered through digital platforms, have the potential to significantly improve health outcomes, through education, motivation, reminders, and outreach. We study the problem of optimizing personalized interventions for patients to maximize some long-term outcome, in a setting where interventions are costly and capacity-constrained.  Methodology/results: This paper provides a model-free approach to solving this problem. We find that generic model-free approaches from the reinforcement learning literature are too data intensive for healthcare applications, while simpler bandit approaches make progress at the expense of ignoring long-term patient dynamics. We present a new algorithm we dub DecompPI that approximates one step of policy iteration. Implementing DecompPI simply consists of a prediction task from offline data, alleviating the need for online experimentation. Theoretically, we show that under a natural set of structural assu
    
[^81]: EZtune： 在R中自动调参的软件包（arXiv:2303.12177v1 [cs.LG]）

    EZtune: A Package for Automated Hyperparameter Tuning in R. (arXiv:2303.12177v1 [cs.LG])

    [http://arxiv.org/abs/2303.12177](http://arxiv.org/abs/2303.12177)

    EZtune是一个可以在R中自动调整支持向量机、adaboost、梯度提升机和弹性网络等模型的软件包，具有简单易用的用户界面，适合新手或R上的统计学习模型。

    

    近年来，统计学习模型越来越受欢迎。许多这些模型都有必须调整的超参数才能表现良好，但这并不是件简单的事情。EZtune 是一个 R 包，具有简单的用户界面，可以调整支持向量机、adaboost、梯度提升机和弹性网络。首先，我们简要总结了 EZtune 可以调整的模型，包括每个模型的超参数。然后，我们比较了 EZtune、caret 和 tidymodels 的易用性。接下来，我们比较了使用 EZtune 和 tidymodels 调整的模型的准确性和计算时间。最后，我们演示了如何使用 EZtune 来帮助选择具有最优预测能力的最终模型。我们的比较表明，“EZtune”可以调整支持向量机和梯度提升机，并提供了易于使用的用户界面，适合新手或R上的统计学习模型。

    Statistical learning models have been growing in popularity in recent years. Many of these models have hyperparameters that must be tuned for models to perform well. Tuning these parameters is not trivial. EZtune is an R package with a simple user interface that can tune support vector machines, adaboost, gradient boosting machines, and elastic net. We first provide a brief summary of the the models that EZtune can tune, including a discussion of each of their hyperparameters. We then compare the ease of using EZtune, caret, and tidymodels. This is followed with a comparison of the accuracy and computation times for models tuned with EZtune and tidymodels. We conclude with a demonstration of how how EZtune can be used to help select a final model with optimal predictive power. Our comparison shows that EZtune can tune support vector machines and gradient boosting machines with EZtune also provides a user interface that is easy to use for a novice to statistical learning models or R.
    
[^82]: 使用Rockpool将脉冲神经网络应用程序训练部署到混合信号神经形态芯片Dynap-SE2上

    Training and Deploying Spiking NN Applications to the Mixed-Signal Neuromorphic Chip Dynap-SE2 with Rockpool. (arXiv:2303.12167v1 [cs.ET])

    [http://arxiv.org/abs/2303.12167](http://arxiv.org/abs/2303.12167)

    本文介绍了一种通过优化网络参数和注入对抗性参数噪声，将SNN应用程序离线训练和部署到Dynap-SE2混合信号神经形态处理器的新方法。优化后的网络表现出很强的鲁棒性，对于硬件约束的真实世界应用程序有很大的潜力。

    

    混合信号神经形态处理器利用脉冲神经网络（SNN）内的稀疏异步计算提供极低功耗的边缘推理负载。然而，由于模拟硬件参数的受限可控性以及由于制造非理想性所导致的模拟电路的无意参数和动态变化，将稳健的应用程序部署到这些设备是复杂的。本文展示了一种用于将SNN应用程序离线训练和部署到混合信号神经形态处理器Dynap-SE2的新型方法。该方法利用一种无监督的重量量化方法来优化网络的参数，并结合在训练过程中注入对抗性参数噪声。优化的网络表现出很强的鲁棒性，可以抵御量化和设备不匹配的影响，使该方法成为具有硬件约束的真实世界应用程序的有前景的候选方法。这项工作扩展了开源设计工具Rockpool。

    Mixed-signal neuromorphic processors provide extremely low-power operation for edge inference workloads, taking advantage of sparse asynchronous computation within Spiking Neural Networks (SNNs). However, deploying robust applications to these devices is complicated by limited controllability over analog hardware parameters, unintended parameter and dynamics variations of analog circuits due to fabrication non-idealities. Here we demonstrate a novel methodology for offline training and deployment of spiking neural networks (SNNs) to the mixed-signal neuromorphic processor Dynap-SE2. The methodology utilizes an unsupervised weight quantization method to optimize the network's parameters, coupled with adversarial parameter noise injection during training. The optimized network is shown to be robust to the effects of quantization and device mismatch, making the method a promising candidate for real-world applications with hardware constraints. This work extends Rockpool, an open-source de
    
[^83]: Viscoelastic Constitutive Artificial Neural Networks (vCANNs) $-$ 基于数据驱动的各向异性非线性有限粘弹性框架

    Viscoelastic Constitutive Artificial Neural Networks (vCANNs) $-$ a framework for data-driven anisotropic nonlinear finite viscoelasticity. (arXiv:2303.12164v1 [cond-mat.mtrl-sci])

    [http://arxiv.org/abs/2303.12164](http://arxiv.org/abs/2303.12164)

    vCANNs是一种适用于有限应变下的各向异性非线性粘弹性的机器学习框架。通过广义Maxwell模型和神经网络表示非线性应变（率）相关属性，vCANNs能够自动识别广泛材料的准确且稀疏的本构模型。

    

    高分子材料的本构行为通常由有限线性粘弹性（FLV）或准线性粘弹性（QLV）模型建模。但是，这些流行的模型是简化的，通常不能准确捕捉材料的非线性粘弹性行为。为了解决这个问题，我们介绍了粘弹性本构人工神经网络（vCANNs），这是一种适用于有限应变下各向异性非线性粘弹性的新型物理观测机器学习框架。vCANNs基于广义Maxwell模型，通过神经网络表示非线性应变（率）相关属性。vCANNs的灵活性使其能够自动识别广泛材料的准确且稀疏的本构模型。为了测试vCANNs，我们将其用于从Polyvinyl Butyral、电活性聚合物VHB 4910和4所获得的应力应变数据进行训练。

    The constitutive behavior of polymeric materials is often modeled by finite linear viscoelastic (FLV) or quasi-linear viscoelastic (QLV) models. These popular models are simplifications that typically cannot accurately capture the nonlinear viscoelastic behavior of materials. For example, the success of attempts to capture strain rate-dependent behavior has been limited so far. To overcome this problem, we introduce viscoelastic Constitutive Artificial Neural Networks (vCANNs), a novel physics-informed machine learning framework for anisotropic nonlinear viscoelasticity at finite strains. vCANNs rely on the concept of generalized Maxwell models enhanced with nonlinear strain (rate)-dependent properties represented by neural networks. The flexibility of vCANNs enables them to automatically identify accurate and sparse constitutive models of a broad range of materials. To test vCANNs, we trained them on stress-strain data from Polyvinyl Butyral, the electro-active polymers VHB 4910 and 4
    
[^84]: 学习深度协方差函数

    Learning a Depth Covariance Function. (arXiv:2303.12157v1 [cs.CV])

    [http://arxiv.org/abs/2303.12157](http://arxiv.org/abs/2303.12157)

    该论文提出了学习深度协方差函数，并利用该方法对深度补全、捆集调整和单目密集视觉里程计等几何视觉任务进行了处理。

    

    我们提出了学习深度协方差函数，并将其应用于几何视觉任务。给定RGB图像作为输入，协方差函数可灵活地用于定义深度函数先验，给定观测的预测分布以及主动点选择方法。我们利用这些技术来解决一系列下游任务：深度补全、捆集调整和单目密集视觉里程计。

    We propose learning a depth covariance function with applications to geometric vision tasks. Given RGB images as input, the covariance function can be flexibly used to define priors over depth functions, predictive distributions given observations, and methods for active point selection. We leverage these techniques for a selection of downstream tasks: depth completion, bundle adjustment, and monocular dense visual odometry.
    
[^85]: 神经预处理：一种用于端到端脑部MRI预处理的学习框架

    Neural Pre-Processing: A Learning Framework for End-to-end Brain MRI Pre-processing. (arXiv:2303.12148v1 [eess.IV])

    [http://arxiv.org/abs/2303.12148](http://arxiv.org/abs/2303.12148)

    NPP是一种端到端的学习框架，可以同时解决头部MRI预处理的所有三个子任务，包括去除头骨、强度归一化和空间归一化。与最新方法相比，该模型在定量结果上表现出色，用户可以在推断时灵活控制每个任务。

    

    头部MRI预处理涉及将原始图像转换为在标准坐标空间中的强度归一化、去除头骨的大脑。在本文中，我们提出了一种称为神经预处理（NPP）的端到端弱监督学习方法，通过神经网络同时解决所有三个子任务，该网络在大型数据集上进行训练，不需要单独的子任务监督。由于总体目标高度不完全约束，我们明确分离了保持几何形状的强度映射（去除头骨和强度归一化）和空间转换（空间归一化）。定量结果表明，我们的模型优于只解决单个子任务的最新方法。我们的消融实验证明了我们选择NPP架构设计的重要性。此外，NPP允许用户在推断时灵活控制每个任务。代码和模型可在\url{https://github.com/Novestars/Neu}上免费获取。

    Head MRI pre-processing involves converting raw images to an intensity-normalized, skull-stripped brain in a standard coordinate space. In this paper, we propose an end-to-end weakly supervised learning approach, called Neural Pre-processing (NPP), for solving all three sub-tasks simultaneously via a neural network, trained on a large dataset without individual sub-task supervision. Because the overall objective is highly under-constrained, we explicitly disentangle geometric-preserving intensity mapping (skull-stripping and intensity normalization) and spatial transformation (spatial normalization). Quantitative results show that our model outperforms state-of-the-art methods which tackle only a single sub-task. Our ablation experiments demonstrate the importance of the architecture design we chose for NPP. Furthermore, NPP affords the user the flexibility to control each of these tasks at inference time. The code and model are freely-available at \url{https://github.com/Novestars/Neu
    
[^86]: Hamiltonian深度神经网络的万能逼近性质研究

    Universal Approximation Property of Hamiltonian Deep Neural Networks. (arXiv:2303.12147v1 [cs.LG])

    [http://arxiv.org/abs/2303.12147](http://arxiv.org/abs/2303.12147)

    本文研究了离散化的哈密顿神经常微分方程引起的Hamiltonian深度神经网络的通用逼近能力，证明了其中的一部分流可以逐渐逼近紧致域上的任何连续函数，为实际使用提供了理论基础。

    

    本文研究了由离散化的哈密顿神经常微分方程引起的Hamiltonian深度神经网络（HDNN）的通用逼近能力。最近的研究表明，HDNN因设计而具有非消失梯度，在训练过程中提供数值稳定性。然而，尽管在几个应用中HDNN已经展示了最先进的性能，但缺少量化其表现力的全面研究。因此，我们提供了一个HDNN的通用逼近定理，并证明了HDNN的一部分流可以逐渐逼近紧致域上的任何连续函数。此结果为实际使用HDNN提供了牢固的理论基础。

    This paper investigates the universal approximation capabilities of Hamiltonian Deep Neural Networks (HDNNs) that arise from the discretization of Hamiltonian Neural Ordinary Differential Equations. Recently, it has been shown that HDNNs enjoy, by design, non-vanishing gradients, which provide numerical stability during training. However, although HDNNs have demonstrated state-of-the-art performance in several applications, a comprehensive study to quantify their expressivity is missing. In this regard, we provide a universal approximation theorem for HDNNs and prove that a portion of the flow of HDNNs can approximate arbitrary well any continuous function over a compact domain. This result provides a solid theoretical foundation for the practical use of HDNNs.
    
[^87]: 利用深度学习提高集成纳米光子器件制造精度

    Improving Fabrication Fidelity of Integrated Nanophotonic Devices Using Deep Learning. (arXiv:2303.12136v1 [cs.LG])

    [http://arxiv.org/abs/2303.12136](http://arxiv.org/abs/2303.12136)

    本论文介绍了一种利用深度学习模型自动纠正制造误差的方法，该方法可以提高集成纳米光子器件的制造精度，从而提高其光学性能和稳定性。

    

    新一代集成纳米光子器件设计利用高级优化技术，如反向设计和拓扑优化，在小特征尺寸的支持下优化大量复杂的设计空间，从而实现高性能和极小化。然而，除非优化受到严格限制，否则生成的小特征无法可靠地加工，导致光学性能下降。即使对于更简单的传统设计，制造引起的性能降级仍会发生。偏差程度不仅取决于特征的大小和形状，而且还取决于特征的分布和周围环境，呈现出复杂的近距离依赖行为。在没有专有制造工艺规范的情况下，只能在校准制造过程之后进行设计修正。在这项工作中，我们介绍了一个通用的深度机器学习模型，它可以自动纠正制造误差。

    Next-generation integrated nanophotonic device designs leverage advanced optimization techniques such as inverse design and topology optimization which achieve high performance and extreme miniaturization by optimizing a massively complex design space enabled by small feature sizes. However, unless the optimization is heavily constrained, the generated small features are not reliably fabricated, leading to optical performance degradation. Even for simpler, conventional designs, fabrication-induced performance degradation still occurs. The degree of deviation from the original design not only depends on the size and shape of its features, but also on the distribution of features and the surrounding environment, presenting complex, proximity-dependent behavior. Without proprietary fabrication process specifications, design corrections can only be made after calibrating fabrication runs take place. In this work, we introduce a general deep machine learning model that automatically correct
    
[^88]: 生成式大语言模型的基础与在网络防御中的应用

    Fundamentals of Generative Large Language Models and Perspectives in Cyber-Defense. (arXiv:2303.12132v1 [cs.CL])

    [http://arxiv.org/abs/2303.12132](http://arxiv.org/abs/2303.12132)

    生成式语言模型的改进引起了公众广泛关注。它们广泛应用及其真实能力揭示了它们的潜在应用，但同时也带来了对其可能的恶意用途的担忧。本文旨在提供生成式大语言模型的简要概述以及在网络防御中的应用。

    

    生成式语言模型在2022年底和2023年初引起了广泛关注，尤其是引入了与用户期望的AI交互一致的模型（对话模型）。人们关注的焦点可以说是GPT3模型的这种改进——ChatGPT及其随后与辅助功能集成的应用，包括作为Microsoft Bing的搜索部分。尽管此前已经投入了大量研究进行开发，但它们在各种日常任务中的性能和适用性仍不清楚且狭窄。然而，他们的广泛应用并不需要技术专业知识，这在相当大的程度上是通过对话微调实现的，揭示了在实际环境中它们真实能力的范围。这引起了公众对其潜在应用的兴奋和对其能力及可能的恶意用途的担忧。本综述旨在提供生成式大语言模型的简要概述以及在网络防御中的应用。

    Generative Language Models gained significant attention in late 2022 / early 2023, notably with the introduction of models refined to act consistently with users' expectations of interactions with AI (conversational models). Arguably the focal point of public attention has been such a refinement of the GPT3 model -- the ChatGPT and its subsequent integration with auxiliary capabilities, including search as part of Microsoft Bing. Despite extensive prior research invested in their development, their performance and applicability to a range of daily tasks remained unclear and niche. However, their wider utilization without a requirement for technical expertise, made in large part possible through conversational fine-tuning, revealed the extent of their true capabilities in a real-world environment. This has garnered both public excitement for their potential applications and concerns about their capabilities and potential malicious uses. This review aims to provide a brief overview of th
    
[^89]: 基于对比学习的MEC网络流行度预测

    CLSA: Contrastive Learning-based Survival Analysis for Popularity Prediction in MEC Networks. (arXiv:2303.12097v1 [cs.LG])

    [http://arxiv.org/abs/2303.12097](http://arxiv.org/abs/2303.12097)

    本论文提出了一种基于对比学习的移动边缘缓存网络流行度预测框架，用于解决深度神经网络在处理多内容顺序请求模式时面临的问题。

    

    移动边缘缓存（MEC）与深度神经网络（DNNs）集成的创新技术具有极大的潜力，可以显著降低用户的延迟。然而，MEC网络的有效性严重依赖于其能力来预测和动态更新缓存节点存储最受欢迎的内容。现有的最先进的时间序列DNN模型通过同时将多个内容的顺序请求模式输入到网络中来捕捉后者，从而大大增加了输入样本的大小。这促使我们提出了一种基于对比学习的DNN流行度预测框架，旨在解决这一挑战。

    Mobile Edge Caching (MEC) integrated with Deep Neural Networks (DNNs) is an innovative technology with significant potential for the future generation of wireless networks, resulting in a considerable reduction in users' latency. The MEC network's effectiveness, however, heavily relies on its capacity to predict and dynamically update the storage of caching nodes with the most popular contents. To be effective, a DNN-based popularity prediction model needs to have the ability to understand the historical request patterns of content, including their temporal and spatial correlations. Existing state-of-the-art time-series DNN models capture the latter by simultaneously inputting the sequential request patterns of multiple contents to the network, considerably increasing the size of the input sample. This motivates us to address this challenge by proposing a DNN-based popularity prediction framework based on the idea of contrasting input samples against each other, designed for the Unmann
    
[^90]: 关于《无法通过图神经网络启发式算法在组合优化问题中胜过贪心算法》的回复(arXiv:2303.12096v1 [cs.LG])

    Reply to: Inability of a graph neural network heuristic to outperform greedy algorithms in solving combinatorial optimization problems. (arXiv:2303.12096v1 [cs.LG])

    [http://arxiv.org/abs/2303.12096](http://arxiv.org/abs/2303.12096)

    回复评论，认为评论聚焦于一种非典型问题且过于简化，强调了原始工作背后更广泛的算法开发以及实验数据的改进，并且指出图神经网络的内部解剖与贪心算法的本质大不相同，因此具有优势。

    

    我们对Stefan Boettcher [arXiv:2210.00623]的评论做了全面回复，并认为这个评论仅针对一种非典型的问题，仅关注稀疏图上的最大割问题(MaxCut)，而贪心算法在这种问题上表现良好。相反，我们强调了我们原始工作背后更广泛的算法开发，并在我们原始框架内提供了额外的数值结果，表明我们的算法在原始数据上有显着改进，因此推翻了评论的原始性能陈述。此外，已经证明物理启发的图神经网络(PI-GNN)能够胜过贪心算法，特别是在困难的、密集的实例上。我们还指出，图神经网络的内部(并行)解剖与贪心算法的(顺序)本质有很大不同，基于它们在实际社交网络规模的使用情况，指出了图神经网络的优势。

    We provide a comprehensive reply to the comment written by Stefan Boettcher [arXiv:2210.00623] and argue that the comment singles out one particular non-representative example problem, entirely focusing on the maximum cut problem (MaxCut) on sparse graphs, for which greedy algorithms are expected to perform well. Conversely, we highlight the broader algorithmic development underlying our original work, and (within our original framework) provide additional numerical results showing sizable improvements over our original data, thereby refuting the comment's original performance statements. Furthermore, it has already been shown that physics-inspired graph neural networks (PI-GNNs) can outperform greedy algorithms, in particular on hard, dense instances. We also argue that the internal (parallel) anatomy of graph neural networks is very different from the (sequential) nature of greedy algorithms, and (based on their usage at the scale of real-world social networks) point out that graph n
    
[^91]: 适应性负证据深度学习用于开放式半监督学习

    Adaptive Negative Evidential Deep Learning for Open-set Semi-supervised Learning. (arXiv:2303.12091v1 [cs.LG])

    [http://arxiv.org/abs/2303.12091](http://arxiv.org/abs/2303.12091)

    本文提出了ANEDL框架，应用证据深度学习量化不同类型的不确定性，并设计了新颖的适应性负优化策略，有效应对在未标记数据集中包含内部值和异常值的开放式半监督学习。

    

    半监督学习方法假设标记数据、未标记数据和测试数据来自同一分布。开放式半监督学习考虑到一个更实际的情况，即未标记数据和测试数据包含标记数据中未观察到的新类别（异常值）。本文提出了一种新颖的框架——适应性负证据深度学习（ANEDL），以应对二元分类器的不足之处，如缺乏可扩展性和无法区分不同类型的不确定性。具体而言，我们首先介绍证据深度学习（EDL）作为一种异常检测器来量化不同类型的不确定性，并设计不同的不确定性度量方法进行自我训练和推理。此外，我们提出了一种新颖的适应性负优化策略，使EDL更加适合包含内部值和异常值的未标记数据集。通过在基准数据集上的实验验证，我们的ANEDL显著优于现有的开放式半监督学习方法。

    Semi-supervised learning (SSL) methods assume that labeled data, unlabeled data and test data are from the same distribution. Open-set semi-supervised learning (Open-set SSL) considers a more practical scenario, where unlabeled data and test data contain new categories (outliers) not observed in labeled data (inliers). Most previous works focused on outlier detection via binary classifiers, which suffer from insufficient scalability and inability to distinguish different types of uncertainty. In this paper, we propose a novel framework, Adaptive Negative Evidential Deep Learning (ANEDL) to tackle these limitations. Concretely, we first introduce evidential deep learning (EDL) as an outlier detector to quantify different types of uncertainty, and design different uncertainty metrics for self-training and inference. Furthermore, we propose a novel adaptive negative optimization strategy, making EDL more tailored to the unlabeled dataset containing both inliers and outliers. As demonstrat
    
[^92]: Thrill-K架构：迈向基于知识的理解问题的解决方案

    Thrill-K Architecture: Towards a Solution to the Problem of Knowledge Based Understanding. (arXiv:2303.12084v1 [cs.LG])

    [http://arxiv.org/abs/2303.12084](http://arxiv.org/abs/2303.12084)

    Thrill-K架构将神经学习与不同类型的知识相结合，为解决部署端到端学习系统所需要的计算需求增加、以及缺乏灵活性、适应性、可解释性、推理和验证能力等问题提供了一种解决方案。

    

    虽然端到端学习系统正迅速获得能力和流行度，但部署这种系统所需的计算需求不断增加，加之灵活性、适应性、可解释性、推理和验证能力的缺乏，需要新类型的架构。在这里，我们介绍了一种混合系统的分类，该分类基于对人类知识和智能的分析，将神经学习与各种类型的知识和知识来源相结合。我们提出了Thrill-K架构作为将瞬时知识、备用知识和外部知识源集成到一个具有推理、学习和智能控制能力的框架中的原型解决方案。

    While end-to-end learning systems are rapidly gaining capabilities and popularity, the increasing computational demands for deploying such systems, along with a lack of flexibility, adaptability, explainability, reasoning and verification capabilities, require new types of architectures. Here we introduce a classification of hybrid systems which, based on an analysis of human knowledge and intelligence, combines neural learning with various types of knowledge and knowledge sources. We present the Thrill-K architecture as a prototypical solution for integrating instantaneous knowledge, standby knowledge and external knowledge sources in a framework capable of inference, learning and intelligent control.
    
[^93]: 特征相邻多保真物理学习用于偏微分方程

    Feature-adjacent multi-fidelity physics-informed machine learning for partial differential equations. (arXiv:2303.11577v1 [cs.LG])

    [http://arxiv.org/abs/2303.11577](http://arxiv.org/abs/2303.11577)

    提出了一种基于特征相邻的多保真体系结构，通过共享低保真度和高保真度解决方案的特征空间来减少或消除对高精度数据的依赖，这在解决复杂问题时具有重要意义。

    

    物理学习神经网络已成为求解偏微分方程的备选方法。然而，对于复杂问题，这种网络的训练仍然需要高精度的数据，而这些数据的生成成本可能很高。为了减少甚至消除对高保真数据的依赖，我们提出了一种基于特征空间的多保真体系结构，该空间由低保真度和高保真度解决方案共享。在特征空间中，低精度和高精度解决方案的投影相邻，并通过约束它们的相对距离来实现。特征空间由编码器表示，其映射到原始解空间通过解码器实现。所提出的多保真方法在由偏微分方程描述的定态和非定态问题的正问题和逆问题上进行了验证。

    Physics-informed neural networks have emerged as an alternative method for solving partial differential equations. However, for complex problems, the training of such networks can still require high-fidelity data which can be expensive to generate. To reduce or even eliminate the dependency on high-fidelity data, we propose a novel multi-fidelity architecture which is based on a feature space shared by the low- and high-fidelity solutions. In the feature space, the projections of the low-fidelity and high-fidelity solutions are adjacent by constraining their relative distance. The feature space is represented with an encoder and its mapping to the original solution space is effected through a decoder. The proposed multi-fidelity approach is validated on forward and inverse problems for steady and unsteady problems described by partial differential equations.
    
[^94]: 动态顶点替换文法

    Dynamic Vertex Replacement Grammars. (arXiv:2303.11553v1 [cs.LG])

    [http://arxiv.org/abs/2303.11553](http://arxiv.org/abs/2303.11553)

    本文提出动态顶点替换文法（DyVeRG），它们提供一种在时间域内更新学习图文法的形式框架，用于生成和预测真实世界的动态图，同时保持了人类可解释性。

    

    上下文无关图文法已经显示出在现实世界中建模结构的惊人能力。然而，图文法缺乏捕捉时变现象的能力，因为产生规则的从左到右的转换不表示时间变化。在本文中，我们描述动态顶点替换文法（DyVeRG），它们在时间域中推广了顶点替换文法，通过为学习图文法更新提供形式框架，以符合其基础数据的修改。我们展示了DyVeRG文法可以从真实世界的动态图中进行学习，并被用于忠实地生成这些图，同时保持可解释性。我们还通过计算DyVeRG曲线生成的德沃尔贝格差异分数（dyvergence scores），展示了它们的预测能力，这是由该框架引出的一种新的图相似度度量。

    Context-free graph grammars have shown a remarkable ability to model structures in real-world relational data. However, graph grammars lack the ability to capture time-changing phenomena since the left-to-right transitions of a production rule do not represent temporal change. In the present work, we describe dynamic vertex-replacement grammars (DyVeRG), which generalize vertex replacement grammars in the time domain by providing a formal framework for updating a learned graph grammar in accordance with modifications to its underlying data. We show that DyVeRG grammars can be learned from, and used to generate, real-world dynamic graphs faithfully while remaining human-interpretable. We also demonstrate their ability to forecast by computing dyvergence scores, a novel graph similarity measurement exposed by this framework.
    
[^95]: 腿部作为机械手臂：将四足机器人敏捷性推向超出运动的领域

    Legs as Manipulator: Pushing Quadrupedal Agility Beyond Locomotion. (arXiv:2303.11330v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2303.11330](http://arxiv.org/abs/2303.11330)

    该论文展示了如何训练四足机器人使用前肢执行操纵任务，如攀爬、按下按钮和与物体交互，并使用课程学习将这些技能从模拟环境转移到真实环境中，并获得了成功的实验结果。

    

    目前，行走或奔跑在各种复杂地形上已经取得了显著的进步。然而，与狗等生物相比，机器人四足动物仍然远远落后，狗能够展示多种敏捷技能，并能使用腿部超出运动的范围，执行几个基本的操纵任务，如与物体进行交互和攀爬。在这篇论文中，我们通过训练四足机器人不仅行走，还使用前肢攀爬墙壁、按下按钮、在现实世界中执行物体交互等任务，来缩小这一差距。为了处理这一具有挑战性的优化问题，我们将技能广泛分为两类：运动，包括任何涉及运动的事物，无论是通过行走还是攀爬墙壁；操纵，涉及使用一条腿进行交互，同时保持其他三条腿的平衡。利用课程学习在模拟环境中训练这些技能，并使用我们提出的 sim2real 方法将其转移到真实环境中。我们的实验表明，我们的方法使得四足机器人能够在保持稳定的同时执行多种操纵任务，如打开门、按下按钮和提起物品。

    Locomotion has seen dramatic progress for walking or running across challenging terrains. However, robotic quadrupeds are still far behind their biological counterparts, such as dogs, which display a variety of agile skills and can use the legs beyond locomotion to perform several basic manipulation tasks like interacting with objects and climbing. In this paper, we take a step towards bridging this gap by training quadruped robots not only to walk but also to use the front legs to climb walls, press buttons, and perform object interaction in the real world. To handle this challenging optimization, we decouple the skill learning broadly into locomotion, which involves anything that involves movement whether via walking or climbing a wall, and manipulation, which involves using one leg to interact while balancing on the other three legs. These skills are trained in simulation using curriculum and transferred to the real world using our proposed sim2real variant that builds upon recent l
    
[^96]: 不看就能旋转: 通过触觉实现手部灵活性

    Rotating without Seeing: Towards In-hand Dexterity through Touch. (arXiv:2303.10880v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2303.10880](http://arxiv.org/abs/2303.10880)

    本研究提出了一种新系统Touch Dexterity，通过密集二进制力传感器实现了多指机器人手不看就能旋转物体，同时大大降低了成本和与实际应用的差距。

    

    触感信息在人类灵巧性中扮演着至关重要的角色，它可以提供有用的接触信息，直接从视觉中无法推断。这篇论文探讨了是否能够使多指机器人手具备与人类类似的不看就能旋转物体的能力。作者们提出了一个新的系统Touch Dexterity，通过使用覆盖整个机器人手的密集二进制力传感器（触摸或未触摸）代替仅仅在小区域内进行精准的触觉传感，使系统具有低成本、覆盖范围广等优点，并通过强化学习在多样的物体模拟中训练出了一种触感旋转策略，能够在真实的机器人手上直接实施不看就能旋转新型物体。

    Tactile information plays a critical role in human dexterity. It reveals useful contact information that may not be inferred directly from vision. In fact, humans can even perform in-hand dexterous manipulation without using vision. Can we enable the same ability for the multi-finger robot hand? In this paper, we present Touch Dexterity, a new system that can perform in-hand object rotation using only touching without seeing the object. Instead of relying on precise tactile sensing in a small region, we introduce a new system design using dense binary force sensors (touch or no touch) overlaying one side of the whole robot hand (palm, finger links, fingertips). Such a design is low-cost, giving a larger coverage of the object, and minimizing the Sim2Real gap at the same time. We train an in-hand rotation policy using Reinforcement Learning on diverse objects in simulation. Relying on touch-only sensing, we can directly deploy the policy in a real robot hand and rotate novel objects tha
    
[^97]: 基于神经加性模型的可解释强化学习在库存管理中的应用

    Interpretable Reinforcement Learning via Neural Additive Models for Inventory Management. (arXiv:2303.10382v1 [cs.LG])

    [http://arxiv.org/abs/2303.10382](http://arxiv.org/abs/2303.10382)

    本文提出了一种基于神经加性模型的可解释强化学习方法，用于开发多级别供应链的动态库存订购策略，在三级供应链仿真测试中证明了实现与最先进深度强化学习方法相当的性能表现，同时具备传统策略的可解释性。

    

    COVID-19疫情彰显了供应链的重要性和数字化管理在应对环境的动态变化中的作用。本文着重于为多级别即多阶段的供应链开发动态库存订购策略。传统的库存优化方法旨在确定静态订购策略，这些策略不能适应如COVID-19危机中观察到的动态变化。然而，传统策略具有可解释性的优势，这是供应链管理者沟通决策与相关方需要具备的关键特征。为了解决这一限制，我们提出了一种可解释性的强化学习方法，既具有传统静态策略的可解释性，又具有其他深度强化学习方法的灵活性和环境无关性。我们建议使用神经加性模型作为库存订购策略的解释函数逼近器。我们的方法在三级供应链仿真中进行了测试，并与传统库存策略以及其他强化学习方法进行了比较。结果表明，我们的方法优于传统策略，并在具有可解释性的同时，实现了与最先进的深度强化学习方法相当的性能。

    The COVID-19 pandemic has highlighted the importance of supply chains and the role of digital management to react to dynamic changes in the environment. In this work, we focus on developing dynamic inventory ordering policies for a multi-echelon, i.e. multi-stage, supply chain. Traditional inventory optimization methods aim to determine a static reordering policy. Thus, these policies are not able to adjust to dynamic changes such as those observed during the COVID-19 crisis. On the other hand, conventional strategies offer the advantage of being interpretable, which is a crucial feature for supply chain managers in order to communicate decisions to their stakeholders. To address this limitation, we propose an interpretable reinforcement learning approach that aims to be as interpretable as the traditional static policies while being as flexible and environment-agnostic as other deep learning-based reinforcement learning solutions. We propose to use Neural Additive Models as an interpr
    
[^98]: 实现AI控制的FES运动康复：利用强化学习学习循环刺激模式。

    Towards AI-controlled FES-restoration of movements: Learning cycling stimulation pattern with reinforcement learning. (arXiv:2303.09986v1 [cs.RO])

    [http://arxiv.org/abs/2303.09986](http://arxiv.org/abs/2303.09986)

    本文提出了一种基于人工智能的FES康复方法，通过强化学习和详细的肌肉骨骼模型寻找循环刺激模式，并使用真实的自行车数据进行微调，该方法可由非技术人员使用而无需额外硬件或传感器。

    

    功能性电刺激（FES）已经越来越多地与其他康复设备（包括机器人）集成在一起。 FES循环是康复治疗中常用的FES应用之一，它通过刺激腿部肌肉以特定模式进行。 适当的模式因人而异，需要手动调整，这可能需要耗费时间并对个体用户具有挑战性。 本文提出了一种基于人工智能的方法，可用于寻找循环刺激模式，而无需额外的硬件或传感器。我们的方法包括两个阶段，首先使用强化学习和详细的肌肉骨骼模型找到基于模型的模式，使用开源软件构建模型，可以通过我们的自动脚本进行定制，并且可以由非技术人员使用而不需要额外费用。接下来，我们的方法使用真实的自行车数据对模式进行微调。 我们在静止三轮车上对我们的方法进行了模拟测试和实验测试。在模拟测试中，我们的方法可以...

    Functional electrical stimulation (FES) has been increasingly integrated with other rehabilitation devices, including robots. FES cycling is one of the common FES applications in rehabilitation, which is performed by stimulating leg muscles in a certain pattern. The appropriate pattern varies across individuals and requires manual tuning which can be time-consuming and challenging for the individual user. Here, we present an AI-based method for finding the patterns, which requires no extra hardware or sensors. Our method has two phases, starting with finding model-based patterns using reinforcement learning and detailed musculoskeletal models. The models, built using open-source software, can be customised through our automated script and can be therefore used by non-technical individuals without extra cost. Next, our method fine-tunes the pattern using real cycling data. We test our both in simulation and experimentally on a stationary tricycle. In the simulation test, our method can 
    
[^99]: MedNeXt：用于医学图像分割的变压器驱动卷积神经网络的可扩展性

    MedNeXt: Transformer-driven Scaling of ConvNets for Medical Image Segmentation. (arXiv:2303.09975v1 [eess.IV])

    [http://arxiv.org/abs/2303.09975](http://arxiv.org/abs/2303.09975)

    MedNeXt是一个定制化的现代化可扩展卷积神经网络，用于解决数据稀缺的医学环境挑战。该网络包含：完全ConvNeXt 3D编码器-解码器网络、残差ConvNeXt上下采样块和一种新的迭代增加核大小的技术。

    

    近年来，在医学图像分割中使用基于 Transformer 的架构越来越多，但是由于缺乏大规模标注的医学数据集，使得其性能远不如自然图像。相比之下，卷积神经网络具有更高的归纳偏差，因此更容易训练到高性能水平。最近，ConvNeXt 架构尝试通过镜像变压器块来现代化标准卷积神经网络。在这项工作中，我们改进了这一架构，设计了一种现代化且可扩展的卷积神经网络，以应对数据稀缺的医学环境的挑战。我们引入 MedNeXt，这是一个受变压器启发的大核分割网络，其中包括：1）用于医学图像分割的完全 ConvNeXt 3D 编码器 - 解码器网络，2）残差 ConvNeXt 上下采样块，以在各个尺度上保留语义信息，3）一种新的技术，通过上采样小核来迭代增加核大小。

    There has been exploding interest in embracing Transformer-based architectures for medical image segmentation. However, the lack of large-scale annotated medical datasets make achieving performances equivalent to those in natural images challenging. Convolutional networks, in contrast, have higher inductive biases and consequently, are easily trainable to high performance. Recently, the ConvNeXt architecture attempted to modernize the standard ConvNet by mirroring Transformer blocks. In this work, we improve upon this to design a modernized and scalable convolutional architecture customized to challenges of data-scarce medical settings. We introduce MedNeXt, a Transformer-inspired large kernel segmentation network which introduces - 1) A fully ConvNeXt 3D Encoder-Decoder Network for medical image segmentation, 2) Residual ConvNeXt up and downsampling blocks to preserve semantic richness across scales, 3) A novel technique to iteratively increase kernel sizes by upsampling small kernel 
    
[^100]: SemDeDup:通过语义去重实现网络规模数据的高效学习（arXiv:2303.09540v1 [cs.LG]）

    SemDeDup: Data-efficient learning at web-scale through semantic deduplication. (arXiv:2303.09540v1 [cs.LG])

    [http://arxiv.org/abs/2303.09540](http://arxiv.org/abs/2303.09540)

    SemDeDup是一种利用预训练模型的嵌入来识别和删除语义重复项的方法。通过对LAION的子集进行分析，SemDeDup可以最小化性能损失的同时删除50%的数据，实际上将训练时间减半。此外，SemDeDup在提供效率收益的同时改进了先前的方法。

    

    机器学习领域的进展很大程度上是由海量数据的增加推动的。然而，像LAION这样的大型网络规模数据集在除查找精确重复项外，大部分未经精心筛选，可能存在很多冗余。在这里，我们介绍SemDeDup，一种基于预训练模型的嵌入来识别和删除语义重复项的方法：即语义上相似但并非完全相同的数据对。去除语义重复项可以保持性能并加速学习。通过对LAION的子集进行分析，我们展示了SemDeDup可以最小化性能损失的同时删除50%的数据，实际上将训练时间减半。此外，性能在分布以外得到提高。同时，通过分析在部分筛选过的数据集C4上训练的语言模型，我们展示了SemDeDup在提供效率收益的同时改进了先前的方法。SemDeDup提供了一个利用质量嵌入简单方法来使模型更快地学习的示例。

    Progress in machine learning has been driven in large part by massive increases in data. However, large web-scale datasets such as LAION are largely uncurated beyond searches for exact duplicates, potentially leaving much redundancy. Here, we introduce SemDeDup, a method which leverages embeddings from pre-trained models to identify and remove semantic duplicates: data pairs which are semantically similar, but not exactly identical. Removing semantic duplicates preserves performance and speeds up learning. Analyzing a subset of LAION, we show that SemDeDup can remove 50% of the data with minimal performance loss, effectively halving training time. Moreover, performance increases out of distribution. Also, analyzing language models trained on C4, a partially curated dataset, we show that SemDeDup improves over prior approaches while providing efficiency gains. SemDeDup provides an example of how simple ways of leveraging quality embeddings can be used to make models learn faster with le
    
[^101]: 学习大规模容量扩展问题的时空聚合

    Learning Spatio-Temporal Aggregations for Large-Scale Capacity Expansion Problems. (arXiv:2303.08996v1 [cs.LG])

    [http://arxiv.org/abs/2303.08996](http://arxiv.org/abs/2303.08996)

    本文提出了一种新颖的方法，用于有效解决容量扩展问题，该方法通过时空聚合解决了由于网络规模大、节点特征异构等原因而导致的问题，并优于传统方法和现有基准。

    

    有效的投资规划决策对于确保网络物理基础设施在扩展期内满足性能要求至关重要。计算这些决策通常需要解决容量扩展问题。在区域规模的能源系统中，由于网络规模大、节点特征异构、操作周期众多等原因，这些问题往往难以解决。为了保持可行性，传统方法会聚合网络节点和/或选择一组代表性时段。然而，这些简化未能捕捉到供需变化对 CEP 成本和约束的重要影响，导致次优决策。本文提出了一种新颖的图卷积自编码器方法，用于到异构节点的泛型 CEP 的时空聚合。我们的架构利用图池化来识别具有相似特征的节点，并最小化一个多目标损失函数，该函数包括成本和性能目标。我们的方法在合成数据集和实际电网数据集上优于传统方法和现有基准。因此，所提出的方法为决策者提供了一种可扩展的工具，用于评估能源基础设施的容量扩展方案。

    Effective investment planning decisions are crucial to ensure cyber-physical infrastructures satisfy performance requirements over an extended time horizon. Computing these decisions often requires solving Capacity Expansion Problems (CEPs). In the context of regional-scale energy systems, these problems are prohibitively expensive to solve due to large network sizes, heterogeneous node characteristics, and a large number of operational periods. To maintain tractability, traditional approaches aggregate network nodes and/or select a set of representative time periods. Often, these reductions do not capture supply-demand variations that crucially impact CEP costs and constraints, leading to suboptimal decisions. Here, we propose a novel graph convolutional autoencoder approach for spatio-temporal aggregation of a generic CEP with heterogeneous nodes (CEPHN). Our architecture leverages graph pooling to identify nodes with similar characteristics and minimizes a multi-objective loss funct
    
[^102]: WDiscOOD：通过白化线性判别分析进行区分度优化的OOD检测

    WDiscOOD: Out-of-Distribution Detection via Whitened Linear Discriminative Analysis. (arXiv:2303.07543v1 [cs.CV])

    [http://arxiv.org/abs/2303.07543](http://arxiv.org/abs/2303.07543)

    本论文提出了一种名为WDiscOOD的新型OOD检测方法，其中使用白化线性判别分析将特征投影到判别子空间和残留子空间中，确定OOD分数。在大规模ImageNet-1k基准测试和六个OOD数据集中，WDiscOOD表现出了优越的性能。

    

    深度神经网络容易在遇到未知概念的情形下产生过度自信但错误的预测。这个挑战突显了在开放世界中检测OOD样本的重要性。本文提出了一种新颖的特征空间OOD检测分数，同时结合了类别特定和类别不可知的信息。具体地，我们的方法使用白化线性判别分析将特征投影到两个子空间中——判别子空间和残留子空间，其中ID类在判别子空间中被最大化地分离，并在残差子空间中被紧密地聚类。然后，在两个子空间中将来自输入数据与ID分布的偏差组合起来确定OOD分数。我们的方法名为WDiscOOD，在覆盖多种分布偏移的六个OOD数据集上验证了其高效性，包括大规模ImageNet-1k基准测试。WDiscOOD在深度分类器上表现出了优越的性能。

    Deep neural networks are susceptible to generating overconfident yet erroneous predictions when presented with data beyond known concepts. This challenge underscores the importance of detecting out-of-distribution (OOD) samples in the open world. In this work, we propose a novel feature-space OOD detection score that jointly reasons with both class-specific and class-agnostic information. Specifically, our approach utilizes Whitened Linear Discriminative Analysis to project features into two subspaces - the discriminative and residual subspaces - in which the ID classes are maximally separated and closely clustered, respectively. The OOD score is then determined by combining the deviation from the input data to the ID distribution in both subspaces. The efficacy of our method, named WDiscOOD, is verified on the large-scale ImageNet-1k benchmark, with six OOD datasets that covers a variety of distribution shifts. WDiscOOD demonstrates superior performance on deep classifiers with divers
    
[^103]: 以ELBOs的加权积分理解扩散目标

    Understanding the Diffusion Objective as a Weighted Integral of ELBOs. (arXiv:2303.00848v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.00848](http://arxiv.org/abs/2303.00848)

    本文深入理解了扩散目标，并揭示了加权损失和ELBO目标之间的直接关系。

    

    文献中的扩散模型采用不同的目标进行优化，并且这些目标都是加权损失的特例，其中加权函数指定每个噪声级别的权重。均匀加权对应于最大似然的原则性近似ELBO的最大化。但是实际上，由于更好的样本质量，目前的扩散模型使用非均匀加权。本文揭示了加权损失（带有任何加权）和ELBO目标之间的直接关系。我们展示了加权损失可以被写成一种ELBOs的加权积分形式，其中每个噪声级别都有一个ELBO。如果权重函数是单调的，那么加权损失是一种基于似然的目标：它在简单的数据增强下（即高斯噪声扰动）下最大化ELBO。我们的主要贡献是更深入地理解了扩散目标，但我们还进行了一些比较单调和非单调权重的实验。

    Diffusion models in the literature are optimized with various objectives that are special cases of a weighted loss, where the weighting function specifies the weight per noise level. Uniform weighting corresponds to maximizing the ELBO, a principled approximation of maximum likelihood. In current practice diffusion models are optimized with non-uniform weighting due to better results in terms of sample quality. In this work we expose a direct relationship between the weighted loss (with any weighting) and the ELBO objective.  We show that the weighted loss can be written as a weighted integral of ELBOs, with one ELBO per noise level. If the weighting function is monotonic, then the weighted loss is a likelihood-based objective: it maximizes the ELBO under simple data augmentation, namely Gaussian noise perturbation. Our main contribution is a deeper theoretical understanding of the diffusion objective, but we also performed some experiments comparing monotonic with non-monotonic weight
    
[^104]: MFBE：利用FAQ的多领域信息进行高效密集检索

    MFBE: Leveraging Multi-Field Information of FAQs for Efficient Dense Retrieval. (arXiv:2302.11953v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2302.11953](http://arxiv.org/abs/2302.11953)

    本文提出了一个双编码器的查询-FAQ匹配模型，称为MFBE，利用FAQ的多个领域组合，在模型训练和推理过程中获益，解决了诸如固有词汇差距、FAQ标题中缺乏足够的上下文等问题，具有很好的实验结果。

    

    在自然语言处理的问答领域中，频繁询问问题（FAQ）的检索是一个被广泛研究的重要子领域。这里，在回应用户查询时，检索系统通常会从知识库返回相关的FAQ。这种系统的有效性取决于其在实时建立查询和FAQ之间的语义匹配的能力。由于查询和FAQ之间的固有词汇差距，FAQ标题中缺乏足够的上下文，标记数据稀缺和高检索延迟，这项任务变得具有挑战性。在这项工作中，我们提出了一个基于双编码器的查询-FAQ匹配模型，它在模型训练和推理过程中利用FAQ的多个领域组合（如问题、答案和类别）。我们提出的多领域双编码器（MFBE）模型从多个FAQ领域的额外上下文中获益，并且即使只有很少的标记数据也表现出色。我们通过实验证明了我们的方法的有效性。

    In the domain of question-answering in NLP, the retrieval of Frequently Asked Questions (FAQ) is an important sub-area which is well researched and has been worked upon for many languages. Here, in response to a user query, a retrieval system typically returns the relevant FAQs from a knowledge-base. The efficacy of such a system depends on its ability to establish semantic match between the query and the FAQs in real-time. The task becomes challenging due to the inherent lexical gap between queries and FAQs, lack of sufficient context in FAQ titles, scarcity of labeled data and high retrieval latency. In this work, we propose a bi-encoder-based query-FAQ matching model that leverages multiple combinations of FAQ fields (like, question, answer, and category) both during model training and inference. Our proposed Multi-Field Bi-Encoder (MFBE) model benefits from the additional context resulting from multiple FAQ fields and performs well even with minimal labeled data. We empirically sup
    
[^105]: 通过着射点交换增强广义集合中配置和路径空间的采样

    Enhanced Sampling of Configuration and Path Space in a Generalized Ensemble by Shooting Point Exchange. (arXiv:2302.08757v2 [physics.comp-ph] UPDATED)

    [http://arxiv.org/abs/2302.08757](http://arxiv.org/abs/2302.08757)

    本文提出了一种用于模拟分子体系稀有事件的新方法，它结合了转换路径采样和配置空间的增强探索，并依靠广义集合上基于配置和轨迹空间之间的交换移动实现，该方法显著增强了转换路径采样模拟的效率。

    

    计算机模拟许多分子过程的复杂性在于由长寿命状态之间的稀有转换引起的长时间尺度。本文提出了一种新方法来模拟这种稀有事件，它结合了转换路径采样和配置空间的增强探索。该方法依靠在广义集合上基于配置和轨迹空间之间的交换移动。这种方案显著增强了转换路径采样模拟的效率，特别是对于具有多个转换通道的系统，并且在不扭曲其动力学的情况下提供了有关分子过程的热力学、动力学和反应坐标的信息。该方法以KPTP四肽中脯氨酸的异构化为例进行了说明。

    The computer simulation of many molecular processes is complicated by long time scales caused by rare transitions between long-lived states. Here, we propose a new approach to simulate such rare events, which combines transition path sampling with enhanced exploration of configuration space. The method relies on exchange moves between configuration and trajectory space, carried out based on a generalized ensemble. This scheme substantially enhances the efficiency of the transition path sampling simulations, particularly for systems with multiple transition channels, and yields information on thermodynamics, kinetics and reaction coordinates of molecular processes without distorting their dynamics. The method is illustrated using the isomerization of proline in the KPTP tetrapeptide.
    
[^106]: 一种用于多元正态分布Fisher-Rao距离的数值逼近方法

    A numerical approximation method for the Fisher-Rao distance between multivariate normal distributions. (arXiv:2302.08175v5 [cs.IT] UPDATED)

    [http://arxiv.org/abs/2302.08175](http://arxiv.org/abs/2302.08175)

    本论文提出了一种用于逼近多元正态分布Fisher-Rao距离的简单方法，通过离散化曲线连接正态分布并逼近相邻正态分布之间的Rao距离，评估了逼近技术的质量，同时介绍了一些信息几何性质。

    

    我们提出了一个简单的方法来逼近基于离散化曲线连接彼此的正态分布和逼近这些曲线上相邻正态分布之间的Rao距离，该方法基于Jeffreys离散度的平方根，即对称化的Kullback-Leibler离散度。我们实验考虑了普通、自然和期望参数化的正态分布的线性插值曲线，并将这些曲线与源自Calvo 和Oller将Fisher-Rao $d$-variate正常流形等距嵌入$(d+1)\times (d+1)$对称正定矩阵锥体的一条曲线进行比较。我们报告了我们的实验结果，并通过将数值逼近与上限和下限进行比较来评估我们逼近技术的质量。最后，我们介绍了Calvo和Oller的一些信息几何性质。

    We present a simple method to approximate Rao's distance between multivariate normal distributions based on discretizing curves joining normal distributions and approximating Rao's distances between successive nearby normal distributions on the curves by the square root of Jeffreys divergence, the symmetrized Kullback-Leibler divergence. We consider experimentally the linear interpolation curves in the ordinary, natural and expectation parameterizations of the normal distributions, and compare these curves with a curve derived from the Calvo and Oller's isometric embedding of the Fisher-Rao $d$-variate normal manifold into the cone of $(d+1)\times (d+1)$ symmetric positive-definite matrices [Journal of multivariate analysis 35.2 (1990): 223-242]. We report on our experiments and assess the quality of our approximation technique by comparing the numerical approximations with both lower and upper bounds. Finally, we present several information-geometric properties of the Calvo and Oller'
    
[^107]: 基于随机先验网络的高维输出可扩展贝叶斯优化

    Scalable Bayesian optimization with high-dimensional outputs using randomized prior networks. (arXiv:2302.07260v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.07260](http://arxiv.org/abs/2302.07260)

    本文提出了一个基于带随机先验的神经网络的深度学习框架用于高维输出的贝叶斯优化，可有效地处理全局优化问题，即使在高维度向量空间或无限维函数空间中也能近似功能关系。

    

    科学和工程中的一些基本问题涉及到未知的高维度映射一组可控变量到昂贵实验结果的黑盒函数的全局优化任务。贝叶斯优化（BO）技术已被证明在使用相对较少的目标函数评估时处理全局优化问题时非常有效，但当处理高维输出时，其性能受到影响。为克服维度主要挑战，本文提出了一个基于带随机先验的神经网络的自举集成的BO和序贯决策制定的深度学习框架。使用适当的体系结构选择，我们证明了所提出的框架可以近似设计变量和感兴趣量之间的功能关系，即使在后者取值于高维向量空间或甚至无限维函数空间的情况下。在贝叶斯优化的背景下，该方法允许高效和可扩展的处理高维度黑盒函数的全局优化。

    Several fundamental problems in science and engineering consist of global optimization tasks involving unknown high-dimensional (black-box) functions that map a set of controllable variables to the outcomes of an expensive experiment. Bayesian Optimization (BO) techniques are known to be effective in tackling global optimization problems using a relatively small number objective function evaluations, but their performance suffers when dealing with high-dimensional outputs. To overcome the major challenge of dimensionality, here we propose a deep learning framework for BO and sequential decision making based on bootstrapped ensembles of neural architectures with randomized priors. Using appropriate architecture choices, we show that the proposed framework can approximate functional relationships between design variables and quantities of interest, even in cases where the latter take values in high-dimensional vector spaces or even infinite-dimensional function spaces. In the context of 
    
[^108]: 基于惩罚的双层梯度下降方法研究

    On Penalty-based Bilevel Gradient Descent Method. (arXiv:2302.05185v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.05185](http://arxiv.org/abs/2302.05185)

    本文提出了基于惩罚的双层梯度下降算法，解决了下层非强凸约束双层问题，实验表明该算法有效。

    This paper proposes a penalty-based bilevel gradient descent algorithm to solve the constrained bilevel problem without lower-level strong convexity, and experiments show its efficiency.

    双层优化在超参数优化、元学习和强化学习等领域有广泛应用，但是双层优化问题难以解决。最近的可扩展双层算法主要集中在下层目标函数是强凸或无约束的双层优化问题上。在本文中，我们通过惩罚方法来解决双层问题。我们证明，在一定条件下，惩罚重构可以恢复原始双层问题的解。此外，我们提出了基于惩罚的双层梯度下降（PBGD）算法，并证明了其在下层非强凸约束双层问题上的有限时间收敛性。实验展示了所提出的PBGD算法的效率。

    Bilevel optimization enjoys a wide range of applications in hyper-parameter optimization, meta-learning and reinforcement learning. However, bilevel optimization problems are difficult to solve. Recent progress on scalable bilevel algorithms mainly focuses on bilevel optimization problems where the lower-level objective is either strongly convex or unconstrained. In this work, we tackle the bilevel problem through the lens of the penalty method. We show that under certain conditions, the penalty reformulation recovers the solutions of the original bilevel problem. Further, we propose the penalty-based bilevel gradient descent (PBGD) algorithm and establish its finite-time convergence for the constrained bilevel problem without lower-level strong convexity. Experiments showcase the efficiency of the proposed PBGD algorithm.
    
[^109]: 扩散模型的成员推断攻击

    Membership Inference Attacks against Diffusion Models. (arXiv:2302.03262v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2302.03262](http://arxiv.org/abs/2302.03262)

    本文研究了扩散模型是否能够抵抗成员推断攻击，并在多个数据集上进行了实验证明其易受攻击影响，尤其是在时间步骤的中间步骤。通过引入噪声，攻击的成功率可以显著降低。

    

    近年来，扩散模型作为创新的生成模型引起了人们的关注。本文研究了扩散模型是否能够抵抗成员推断攻击，以评估机器学习模型的隐私泄露。我们主要从与传统模型生成对抗网络（GAN）的比较和扩散模型独特的超参数，即时间步长、采样步长和采样方差的角度讨论了扩散模型。我们在CelebA和CIFAR-10数据集上使用DDIM作为扩散模型、DCGAN作为GAN进行了广泛的白盒和黑盒实验，然后确认扩散模型是否能够像GAN一样具有抵抗成员推断攻击的能力。接下来，我们证明时间步长的影响显著，并且在噪声计划中的中间步骤最容易受到攻击。通过进一步的分析，我们还发现了两个关键见解。首先，我们确定了攻击的位置。其次，在攻击中加入噪声会显著降低攻击的成功率。

    Diffusion models have attracted attention in recent years as innovative generative models. In this paper, we investigate whether a diffusion model is resistant to a membership inference attack, which evaluates the privacy leakage of a machine learning model. We primarily discuss the diffusion model from the standpoints of comparison with a generative adversarial network (GAN) as conventional models and hyperparameters unique to the diffusion model, i.e., time steps, sampling steps, and sampling variances. We conduct extensive experiments with DDIM as a diffusion model and DCGAN as a GAN on the CelebA and CIFAR-10 datasets in both white-box and black-box settings and then confirm if the diffusion model is comparably resistant to a membership inference attack as GAN. Next, we demonstrate that the impact of time steps is significant and intermediate steps in a noise schedule are the most vulnerable to the attack. We also found two key insights through further analysis. First, we identify 
    
[^110]: 通过稀疏编码实现无约束动态遗憾

    Unconstrained Dynamic Regret via Sparse Coding. (arXiv:2301.13349v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.13349](http://arxiv.org/abs/2301.13349)

    本文探讨了在线线性优化（OLO）涉及无约束问题和动态遗憾问题的复杂性，提出了一种通过重新构造问题为稀疏编码的复杂度度量方式，在适应性和应用上有较好的应用价值。

    

    受时间序列预测的影响，本研究探讨了在线线性优化（OLO）在两个问题结构的耦合下的情况：域无界，而算法的性能是通过动态遗憾来衡量的。处理任一问题都要求遗憾界限依赖于比较序列的某些复杂度量度 - 特别是无约束OLO中的比较器范数，以及动态遗憾中的路径长度。与最近一篇文章(Jacobsen& Cutkosky，2022)适应这两个复杂度量度相比，我们提出了一种通过重新构造问题为稀疏编码的复杂度度量方式。可以通过一个简单的模块化框架实现适应性，这个框架自然地利用了环境更复杂的前置知识。同时，我们还提出了一种新的静态无约束OLO梯度自适应算法，使用了新颖的连续时间机制设计。这可能是具有独立兴趣的。

    Motivated by time series forecasting, we study Online Linear Optimization (OLO) under the coupling of two problem structures: the domain is unbounded, and the performance of an algorithm is measured by its dynamic regret. Handling either of them requires the regret bound to depend on certain complexity measure of the comparator sequence -- specifically, the comparator norm in unconstrained OLO, and the path length in dynamic regret. In contrast to a recent work (Jacobsen & Cutkosky, 2022) that adapts to the combination of these two complexity measures, we propose an alternative complexity measure by recasting the problem into sparse coding. Adaptivity can be achieved by a simple modular framework, which naturally exploits more intricate prior knowledge of the environment. Along the way, we also present a new gradient adaptive algorithm for static unconstrained OLO, designed using novel continuous time machinery. This could be of independent interest.
    
[^111]: 使用无动作离线数据预训练指导在线强化学习

    Guiding Online Reinforcement Learning with Action-Free Offline Pretraining. (arXiv:2301.12876v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12876](http://arxiv.org/abs/2301.12876)

    本文研究了使用无动作离线数据集来提高在线强化学习的效率和性能的方法，提出了AF-Guide，实现变体的Upside-Down强化学习和指导在线学习的Guided SAC，实验结果表明该方法可以成功改善在离线数据集中不存在动作信息的情况下的性能。

    

    离线RL方法通过训练代理使用离线收集的数据来减少环境交互的需求。然而，这些方法通常需要在数据收集期间记录动作信息，这在某些实际情况下可能是困难甚至不可能的。在本文中，我们研究了使用无动作离线数据集来改善在线强化学习的潜力，并将此问题命名为具有无动作离线预训练的强化学习（AFP-RL）。我们介绍了AF-Guide，一种通过从无动作离线数据集中提取知识来指导在线训练的方法。AF-Guide包括实施Upside-Down强化学习变体的无动作决策Transformer（AFDT），它学习从离线数据集中规划下一个状态，以及一个通过AFDT指导在线学习的Guided Soft Actor-Critic（Guided SAC）。实验结果表明，在离线数据集中不存在动作信息的环境中，AF-Guide可以提高在线RL的样本效率和性能。

    Offline RL methods have been shown to reduce the need for environment interaction by training agents using offline collected episodes. However, these methods typically require action information to be logged during data collection, which can be difficult or even impossible in some practical cases. In this paper, we investigate the potential of using action-free offline datasets to improve online reinforcement learning, name this problem Reinforcement Learning with Action-Free Offline Pretraining (AFP-RL). We introduce Action-Free Guide (AF-Guide), a method that guides online training by extracting knowledge from action-free offline datasets. AF-Guide consists of an Action-Free Decision Transformer (AFDT) implementing a variant of Upside-Down Reinforcement Learning. It learns to plan the next states from the offline dataset, and a Guided Soft Actor-Critic (Guided SAC) that learns online with guidance from AFDT. Experimental results show that AF-Guide can improve sample efficiency and pe
    
[^112]: 通过子序列相似性生成序列：理论及其在无人机识别中的应用

    Sequence Generation via Subsequence Similarity: Theory and Application to UAV Identification. (arXiv:2301.08403v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.08403](http://arxiv.org/abs/2301.08403)

    本文探究了一种单次生成模型的多样性，主要聚焦于子序列相似性如何影响整个序列相似性，并通过生成子序列相似的序列来增强数据集。

    

    生成人工合成序列的能力在广泛的应用中至关重要，而深度学习架构和生成框架的最新进展已经极大地促进了这一过程。本文使用一种单次生成模型来采样，通过相似性生成子序列，并证明了子序列相似性对整个序列相似性的影响，给出了相应的界限。我们使用一种一次性生成模型来从单个序列的范围内取样，并生成子序列相似的序列，证明了数据集增强方面的实用性。

    The ability to generate synthetic sequences is crucial for a wide range of applications, and recent advances in deep learning architectures and generative frameworks have greatly facilitated this process. Particularly, unconditional one-shot generative models constitute an attractive line of research that focuses on capturing the internal information of a single image or video to generate samples with similar contents. Since many of those one-shot models are shifting toward efficient non-deep and non-adversarial approaches, we examine the versatility of a one-shot generative model for augmenting whole datasets. In this work, we focus on how similarity at the subsequence level affects similarity at the sequence level, and derive bounds on the optimal transport of real and generated sequences based on that of corresponding subsequences. We use a one-shot generative model to sample from the vicinity of individual sequences and generate subsequence-similar ones and demonstrate the improvem
    
[^113]: SparseGPT：无需重新训练即可将大规模语言模型精确剪枝至至少50%稀疏度的方法

    SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot. (arXiv:2301.00774v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.00774](http://arxiv.org/abs/2301.00774)

    SparseGPT通过一种高效、精确的方法，能使大规模语言模型在不重新训练的情况下至少剪枝50%的稀疏度，而准确度下降很小。

    

    我们首次展示了一种名为SparseGPT的新的剪枝方法，能够高效准确地应用于大规模GPT家族模型，而无需重新训练，将这些模型至少剪枝50%的稀疏度，且准确度下降很小。我们能够在不到4.5小时内即可在最大的开源模型OPT-175B和BLOOM-176B上执行SparseGPT，并在几乎不增加困惑度的情况下实现60%的无结构稀疏度：这些模型的超过1000亿个参数可以在推理时忽略。

    We show for the first time that large-scale generative pretrained transformer (GPT) family models can be pruned to at least 50% sparsity in one-shot, without any retraining, at minimal loss of accuracy. This is achieved via a new pruning method called SparseGPT, specifically designed to work efficiently and accurately on massive GPT-family models. We can execute SparseGPT on the largest available open-source models, OPT-175B and BLOOM-176B, in under 4.5 hours, and can reach 60% unstructured sparsity with negligible increase in perplexity: remarkably, more than 100 billion weights from these models can be ignored at inference time. SparseGPT generalizes to semi-structured (2:4 and 4:8) patterns, and is compatible with weight quantization approaches. The code is available at: https://github.com/IST-DASLab/sparsegpt.
    
[^114]: 面向任务的通信系统：基于端到端深度学习和AI安全的NextG研究

    Task-Oriented Communications for NextG: End-to-End Deep Learning and AI Security Aspects. (arXiv:2212.09668v2 [cs.NI] UPDATED)

    [http://arxiv.org/abs/2212.09668](http://arxiv.org/abs/2212.09668)

    本文探讨了在NextG无线接入网络中，通过端到端深度学习和AI安全保证信号分类任务，并在保证信号传输效率的情况下进行任务导向通信的方法。

    

    传统通信系统主要设计用于可靠地传输数字数据流（比特流），而新一代通信系统（NextG）开始探索把设计范式转向可靠地执行特定任务，例如任务导向的通信。本文探讨了无线信号分类作为NextG无线接入网络（RAN）的任务，在该任务中，边缘设备收集无线信号以获取频谱感知，然后与需要识别信号标签的NextG基站（gNodeB）进行通信。然而边缘设备可能无法足够处理信号分类任务，并且由于严格的延迟、速率和能量限制，将信号传输到gNodeB可能不可行。为此，本研究考虑了通过联合训练发射机、接收机和分类器的功能作为编码器-解码器对，为边缘设备和gNodeB实现任务导向通信。

    Communications systems to date are primarily designed with the goal of reliable transfer of digital sequences (bits). Next generation (NextG) communication systems are beginning to explore shifting this design paradigm to reliably executing a given task such as in task-oriented communications. In this paper, wireless signal classification is considered as the task for the NextG Radio Access Network (RAN), where edge devices collect wireless signals for spectrum awareness and communicate with the NextG base station (gNodeB) that needs to identify the signal label. Edge devices may not have sufficient processing power and may not be trusted to perform the signal classification task, whereas the transfer of signals to the gNodeB may not be feasible due to stringent delay, rate, and energy restrictions. Task-oriented communications is considered by jointly training the transmitter, receiver and classifier functionalities as an encoder-decoder pair for the edge device and the gNodeB. This a
    
[^115]: SDFusion：多模态三维形状完成、重建和生成

    SDFusion: Multimodal 3D Shape Completion, Reconstruction, and Generation. (arXiv:2212.04493v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.04493](http://arxiv.org/abs/2212.04493)

    本文提出了一个多模态三维形状生成的新框架，支持图像、文本、部分观察到的形状等多种输入模式，模型具有较强的灵活性和性能表现，在目前相关工作中处于领先地位，能够将多种任务整合成一个工具，为业余用户简化了三维资源生成的流程。

    

    本文提出了一个新的框架，旨在简化业余用户的三维资源生成。该方法支持各种输入模式，包括图像、文本、部分观察到的形状和这些的组合，进一步允许调整每个输入的强度，以实现交互式生成。在我们方法的核心是一个编码器-解码器，将三维形状压缩成一个紧凑的潜在表示，然后学习扩散模型。为了支持各种多模态输入，我们采用了具有辍学的任务特定编码器，后跟交叉注意机制。由于其灵活性，我们的模型自然支持各种任务，在形状完成、基于图像的三维重建和文本到3D方面的性能表现均优于之前的工作。最有趣的是，我们的模型可以将所有这些任务组合成一个“瑞士军刀”工具，使用户能够使用不完整的形状、图像和文本描述来进行形状生成。

    In this work, we present a novel framework built to simplify 3D asset generation for amateur users. To enable interactive generation, our method supports a variety of input modalities that can be easily provided by a human, including images, text, partially observed shapes and combinations of these, further allowing to adjust the strength of each input. At the core of our approach is an encoder-decoder, compressing 3D shapes into a compact latent representation, upon which a diffusion model is learned. To enable a variety of multi-modal inputs, we employ task-specific encoders with dropout followed by a cross-attention mechanism. Due to its flexibility, our model naturally supports a variety of tasks, outperforming prior works on shape completion, image-based 3D reconstruction, and text-to-3D. Most interestingly, our model can combine all these tasks into one swiss-army-knife tool, enabling the user to perform shape generation using incomplete shapes, images, and textual descriptions a
    
[^116]: 带有内外部注意力的形状引导扩散

    Shape-Guided Diffusion with Inside-Outside Attention. (arXiv:2212.00210v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.00210](http://arxiv.org/abs/2212.00210)

    该论文提出了一种无需训练的形状引导扩散方法，使用一种新颖的内外部注意机制将形状限制应用于跨注意力图和自注意力图上，从而在文本到图像扩散模型中考虑到对象形状，进而可以实现对象形状忠实度更高的图像生成。

    

    在操作对象时，现有的文本到图像扩散模型通常忽略对象的形状并生成错误比例、被截断或被背景内容替换的图像。我们提出了一种无需训练的方法 Shape-Guided Diffusion，该方法修改了预训练扩散模型，使之对用户指定的形状输入或从文本中自动推断的形状敏感。我们使用一种新颖的内外部注意机制，在反演和生成过程中将此形状限制应用于跨注意力图和自注意力图上。我们的机制指定空间区域是对象（内部）还是背景（外部），然后将文本提示指定的编辑与正确的区域相关联。我们在形状引导编辑任务上展示了我们方法的有效性，其中模型必须根据文本提示和对象掩码替换对象。我们创建了一个新的从 MS-COCO 衍生的 ShapePrompts 基准，并在形状忠实度方面实现了 SOTA 的结果，而不需要降级。

    When manipulating an object, existing text-to-image diffusion models often ignore the shape of the object and generate content that is incorrectly scaled, cut off, or replaced with background content. We propose a training-free method, Shape-Guided Diffusion, that modifies pretrained diffusion models to be sensitive to shape input specified by a user or automatically inferred from text. We use a novel Inside-Outside Attention mechanism during the inversion and generation process to apply this shape constraint to the cross- and self-attention maps. Our mechanism designates which spatial region is the object (inside) vs. background (outside) then associates edits specified by text prompts to the correct region. We demonstrate the efficacy of our method on the shape-guided editing task, where the model must replace an object according to a text prompt and object mask. We curate a new ShapePrompts benchmark derived from MS-COCO and achieve SOTA results in shape faithfulness without a degra
    
[^117]: AIREPAIR——一种神经网络修复平台

    AIREPAIR: A Repair Platform for Neural Networks. (arXiv:2211.15387v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2211.15387](http://arxiv.org/abs/2211.15387)

    AIREPAIR是一个神经网络修复平台，它能够集成现有网络修复工具并实现不同方法的公平比较，评估结果表明其实用性。

    

    我们介绍了一种名为AIREPAIR的神经网络修复平台。它包括了现有网络修复工具的集成，使得用户可以在同一个模型上运行不同的网络修复方法并进行公平的比较。我们使用三个最先进的修复工具在流行的深度学习数据集和模型上评估了AIREPAIR。评估结果表明AIREPAIR的实用性，通过比较和分析不同修复技术的结果进行了验证。演示视频可在 https://youtu.be/UkKw5neeWhw 查看。

    We present AIREPAIR, a platform for repairing neural networks. It features the integration of existing network repair tools. Based on AIREPAIR, one can run different repair methods on the same model, thus enabling the fair comparison of different repair techniques. We evaluate AIREPAIR with three state-of-the-art repair tools on popular deep-learning datasets and models. Our evaluation confirms the utility of AIREPAIR, by comparing and analyzing the results from different repair techniques. A demonstration is available at https://youtu.be/UkKw5neeWhw.
    
[^118]: 使用图神经网络求解双层背包问题

    Solving Bilevel Knapsack Problem using Graph Neural Networks. (arXiv:2211.13436v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.13436](http://arxiv.org/abs/2211.13436)

    本研究提出了一种使用图神经网络的深度学习方法来解决双层背包问题，该方法比精确算法快500倍，可找到可行性解决方案。

    

    双层优化问题是一种具有两个代理人（领导者和追随者）的层次优化问题。领导者首先做出自己的决策，追随者随后做出最佳选择。领导者了解追随者的信息，问题的目标是从领导者的角度考虑追随者的反应，找到最优解。对于双层优化问题来说，没有通用的高效算法或商用求解器可以得到最优解，即使是简单的问题也很难得到良好的解。本文提出了一种使用图神经网络的深度学习方法来解决双层背包问题。我们训练模型来预测领导者的解决方案，并将其用于将层次优化问题转化为单层优化问题以获取解决方案。我们的模型发现了可行的解决方案，速度比精确算法快500倍。

    The Bilevel Optimization Problem is a hierarchical optimization problem with two agents, a leader and a follower. The leader make their own decisions first, and the followers make the best choices accordingly. The leader knows the information of the followers, and the goal of the problem is to find the optimal solution by considering the reactions of the followers from the leader's point of view. For the Bilevel Optimization Problem, there are no general and efficient algorithms or commercial solvers to get an optimal solution, and it is very difficult to get a good solution even for a simple problem. In this paper, we propose a deep learning approach using Graph Neural Networks to solve the bilevel knapsack problem. We train the model to predict the leader's solution and use it to transform the hierarchical optimization problem into a single-level optimization problem to get the solution. Our model found the feasible solution that was about 500 times faster than the exact algorithm wi
    
[^119]: {\mu}Split: 显微镜数据的高效图像分解方法

    {\mu}Split: efficient image decomposition for microscopy data. (arXiv:2211.12872v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.12872](http://arxiv.org/abs/2211.12872)

    uSplit是一种适用于荧光显微镜图像的高效图像分解方法，集成了横向上下文化，帮助训练更深的分层模型，并有效地减少平铺伪影问题。

    

    我们提出了 uSplit，一种专门用于荧光显微镜图像中的训练图像分解的方法。我们发现，使用常规的深度结构体系结构在训练时使用大图像块会获得最佳结果，使内存消耗成为进一步提高性能的限制因素。因此，我们引入了横向上下文化（LC），一种内存高效的方法来训练强大的网络，并展示LC在处理任务时始终带来了显著的改进。我们将LC与U-Nets、分层自编码器和分层VAEs集成，为此我们制定了一种改进的ELBO loss。此外，LC使得训练比原本更深的分层模型成为可能，并且有助于减少使用分割VAE预测时不可避免的平铺伪影。我们将uSplit应用于五个分解任务，一个是合成数据集，另外四个来自实际显微镜数据。LC实现了SOTA的结果（平均im）

    We present uSplit, a dedicated approach for trained image decomposition in the context of fluorescence microscopy images. We find that best results using regular deep architectures are achieved when large image patches are used during training, making memory consumption the limiting factor to further improving performance. We therefore introduce lateral contextualization (LC), a memory efficient way to train powerful networks and show that LC leads to consistent and significant improvements on the task at hand. We integrate LC with U-Nets, Hierarchical AEs, and Hierarchical VAEs, for which we formulate a modified ELBO loss. Additionally, LC enables training deeper hierarchical models than otherwise possible and, interestingly, helps to reduce tiling artefacts that are inherently impossible to avoid when using tiled VAE predictions. We apply uSplit to five decomposition tasks, one on a synthetic dataset, four others derived from real microscopy data. LC achieves SOTA results (average im
    
[^120]: 高效训练：探索泛化课程学习来训练视觉主干网络

    EfficientTrain: Exploring Generalized Curriculum Learning for Training Visual Backbones. (arXiv:2211.09703v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.09703](http://arxiv.org/abs/2211.09703)

    本文提出了一种泛化课程学习方法，用于高效训练视觉主干网络，通过优先让模型学习“更容易学习”的模式，不断引入更难的模式，从而加速训练过程。

    

    现代深度网络的卓越性能通常伴随着昂贵的训练过程。本文提出了一种新的课程学习方法，用于高效训练视觉主干网络（例如视觉Transformer）。本文启发于深度网络的内在学习动力学：我们实验性地展示了在较早的训练阶段，模型主要学习在每个示例中识别一些“更容易学习”的判别模式，例如图像的低频成分和数据增广之前的原始信息。基于此现象，我们提出了一种课程，其中模型总是在每个时期利用所有训练数据，而课程始于仅暴露每个示例的“更容易学习”的模式，并逐渐引入更难的模式。为了实现这个想法，我们1）在输入的傅里叶谱中引入一个裁剪操作，使模型只能从低频组分中进行学习。

    The superior performance of modern deep networks usually comes with a costly training procedure. This paper presents a new curriculum learning approach for the efficient training of visual backbones (e.g., vision Transformers). Our work is inspired by the inherent learning dynamics of deep networks: we experimentally show that at an earlier training stage, the model mainly learns to recognize some 'easier-to-learn' discriminative patterns within each example, e.g., the lower-frequency components of images and the original information before data augmentation. Driven by this phenomenon, we propose a curriculum where the model always leverages all the training data at each epoch, while the curriculum starts with only exposing the 'easier-to-learn' patterns of each example, and introduces gradually more difficult patterns. To implement this idea, we 1) introduce a cropping operation in the Fourier spectrum of the inputs, which enables the model to learn from only the lower-frequency compo
    
[^121]: 无偏的监督对比学习

    Unbiased Supervised Contrastive Learning. (arXiv:2211.05568v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.05568](http://arxiv.org/abs/2211.05568)

    本文提出了一种新的监督对比损失形式（epsilon-SupInfoNCE）以及一种新的去偏正则化损失（FairKL），旨在解决从有偏数据中学习无偏模型的问题。

    

    许多数据集存在偏差，即它们包含仅在数据集中与目标类高度相关的易于学习的特征，但不在真实的数据分布中。因此，从有偏数据中学习无偏模型已成为近年来非常相关的研究课题。在这项工作中，我们解决了学习对偏差具有鲁棒性的表征的问题。我们首先提出了一种基于边缘的理论框架，可以帮助我们澄清为什么最近的对比损失（InfoNCE，SupCon等）在处理偏差数据时可能失败。基于此，我们推导出了一种新的监督对比损失形式（epsilon-SupInfoNCE），提供了更准确的对正负样本之间最小距离的控制。此外，由于我们的理论框架，我们还提出了FairKL，一种新的去偏正则化损失，即使在极度偏差的数据情况下也可以很好地工作。我们在标准的视觉数据集上验证了所提出的损失。

    Many datasets are biased, namely they contain easy-to-learn features that are highly correlated with the target class only in the dataset but not in the true underlying distribution of the data. For this reason, learning unbiased models from biased data has become a very relevant research topic in the last years. In this work, we tackle the problem of learning representations that are robust to biases. We first present a margin-based theoretical framework that allows us to clarify why recent contrastive losses (InfoNCE, SupCon, etc.) can fail when dealing with biased data. Based on that, we derive a novel formulation of the supervised contrastive loss (epsilon-SupInfoNCE), providing more accurate control of the minimal distance between positive and negative samples. Furthermore, thanks to our theoretical framework, we also propose FairKL, a new debiasing regularization loss, that works well even with extremely biased data. We validate the proposed losses on standard vision datasets inc
    
[^122]: 一种应用物理学的深度学习模型在多尺度震爆转变中准确定位能量释放的异质高能材料中的应用

    A physics-aware deep learning model for energy localization in multiscale shock-to-detonation simulations of heterogeneous energetic materials. (arXiv:2211.04561v2 [cond-mat.mtrl-sci] UPDATED)

    [http://arxiv.org/abs/2211.04561](http://arxiv.org/abs/2211.04561)

    本研究提出了一种应用深度学习的多尺度模型，可以准确地模拟异质高能材料在震爆转变过程中的能量释放和灵敏性。模型使用物理学知识训练了循环卷积神经网络来准确定位微观结构内的热点点火和生长，从而提高计算效率和准确性。

    

    针对异质高能材料在震爆转变过程中的复杂热力学特性，需要准确地捕获其宏观响应和亚网格介观能量定位。本研究提出了一种高效而准确的多尺度震爆转变模型。该模型使用深度学习方法对震爆转变中微观结构的介观能量定位进行建模，并利用有限元方法建立宏观尺度的响应模型。该模型能够在计算效率上保持高精度，准确地捕获异质高能材料的介观尺度能量定位和宏观尺度震爆转变行为。

    Predictive simulations of the shock-to-detonation transition (SDT) in heterogeneous energetic materials (EM) are vital to the design and control of their energy release and sensitivity. Due to the complexity of the thermo-mechanics of EM during the SDT, both macro-scale response and sub-grid mesoscale energy localization must be captured accurately. This work proposes an efficient and accurate multiscale framework for SDT simulations of EM. We introduce a new approach for SDT simulation by using deep learning to model the mesoscale energy localization of shock-initiated EM microstructures. The proposed multiscale modeling framework is divided into two stages. First, a physics-aware recurrent convolutional neural network (PARC) is used to model the mesoscale energy localization of shock-initiated heterogeneous EM microstructures. PARC is trained using direct numerical simulations (DNS) of hotspot ignition and growth within microstructures of pressed HMX material subjected to different i
    
[^123]: GPTQ: 面向生成预训练transformer的准确后训练量化方法

    GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers. (arXiv:2210.17323v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.17323](http://arxiv.org/abs/2210.17323)

    本文提出了一种名为GPTQ的新型一次性权重量化方法，可在高度准确和高度有效的同时将比特宽度降至每个权重3或4位，适用于巨大的GPT模型。

    

    生成预训练transformer模型以其在复杂语言建模任务中的突破性表现和极高的计算和存储成本而脱颖而出。本文提出了一种基于近似二阶信息的新型一次性权重量化方法GPTQ，可以在约四个GPU小时内将GPT模型量化为每个权重3或4比特，精度几乎没有降低。

    Generative Pre-trained Transformer models, known as GPT or OPT, set themselves apart through breakthrough performance across complex language modelling tasks, but also by their extremely high computational and storage costs. Specifically, due to their massive size, even inference for large, highly-accurate GPT models may require multiple performant GPUs, which limits the usability of such models. While there is emerging work on relieving this pressure via model compression, the applicability and performance of existing compression techniques is limited by the scale and complexity of GPT models. In this paper, we address this challenge, and propose GPTQ, a new one-shot weight quantization method based on approximate second-order information, that is both highly-accurate and highly-efficient. Specifically, GPTQ can quantize GPT models with 175 billion parameters in approximately four GPU hours, reducing the bitwidth down to 3 or 4 bits per weight, with negligible accuracy degradation rel
    
[^124]: 应用于心理测量学的降维方法对机器学习算法的实验研究

    An Experimental Study of Dimension Reduction Methods on Machine Learning Algorithms with Applications to Psychometrics. (arXiv:2210.13230v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.13230](http://arxiv.org/abs/2210.13230)

    本文主要研究了心理测量学领域最近开发的探索性图分析（EGA）和唯一变量分析（UVA）等两种降维技术与机器学习文献中常见的两种降维技术（主成分分析和独立成分分析）在减少数据维度方面的效果，并发现降维可能会降低、提高或者不影响变量的准确性。

    

    开发可解释的机器学习模型已成为一个越来越重要的问题。降维技术是数据科学家开发可解释模型的一种方式。在本文中，我们研究了几种降维技术，包括心理测量学领域最近开发的探索性图分析（EGA）和唯一变量分析（UVA）等两种方法。我们将EGA和UVA与机器学习文献中常见的两种降维技术（主成分分析和独立成分分析）以及没有降维的变量进行比较。我们显示EGA和UVA与其他降维技术或者不降维相当。一致于前期的文献，我们发现降维可能会降低、提高或者不影响变量的准确性。我们初步的结果发现降维往往导致更好的性能。

    Developing interpretable machine learning models has become an increasingly important issue. One way in which data scientists have been able to develop interpretable models has been to use dimension reduction techniques. In this paper, we examine several dimension reduction techniques including two recent approaches developed in the network psychometrics literature called exploratory graph analysis (EGA) and unique variable analysis (UVA). We compared EGA and UVA with two other dimension reduction techniques common in the machine learning literature (principal component analysis and independent component analysis) as well as no reduction to the variables real data. We show that EGA and UVA perform as well as the other reduction techniques or no reduction. Consistent with previous literature, we show that dimension reduction can decrease, increase, or provide the same accuracy as no reduction of variables. Our tentative results find that dimension reduction tends to lead to better perfo
    
[^125]: 自动编码器神经网络结合机器学习的X射线荧光基本参数应用研究

    Auto-Encoder Neural Network Incorporating X-Ray Fluorescence Fundamental Parameters with Machine Learning. (arXiv:2210.12239v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.12239](http://arxiv.org/abs/2210.12239)

    本研究开发了一种神经网络模型，结合领域知识，可以在缺乏标记数据的情况下进行X射线荧光分析，适用于矿山等实际场景。

    

    本文针对能量色散X射线荧光（EDXRF）应用中因仪器参数不可用而无法使用基本参数方法的情况进行研究。例如，在采矿铲车或传送带上，岩石不断移动（导致入射角度和距离不断变化），还可能存在其他未考虑的因素（如灰尘）。神经网络不需要仪器和基本参数，但训练神经网络需要带有元素组成标签的XRF光谱，由于成本限制，这种标签数据通常很有限。本研究开发了一个神经网络模型，可以从有限的标记数据中学习，并通过学习反演正演模型来受益于领域知识。正演模型使用所有元素的跃迁能量和概率以及参数分布来逼近其他基本和仪器参数。我们使用来自锂矿勘探项目的岩石数据集评估了该模型和基线模型。

    We consider energy-dispersive X-ray Fluorescence (EDXRF) applications where the fundamental parameters method is impractical such as when instrument parameters are unavailable. For example, on a mining shovel or conveyor belt, rocks are constantly moving (leading to varying angles of incidence and distances) and there may be other factors not accounted for (like dust). Neural networks do not require instrument and fundamental parameters but training neural networks requires XRF spectra labelled with elemental composition, which is often limited because of its expense. We develop a neural network model that learns from limited labelled data and also benefits from domain knowledge by learning to invert a forward model. The forward model uses transition energies and probabilities of all elements and parameterized distributions to approximate other fundamental and instrument parameters. We evaluate the model and baseline models on a rock dataset from a lithium mineral exploration project. 
    
[^126]: 正交非负矩阵分解:最大熵原则方法

    Orthogonal Non-negative Matrix Factorization: a Maximum-Entropy-Principle Approach. (arXiv:2210.02672v2 [cs.DS] UPDATED)

    [http://arxiv.org/abs/2210.02672](http://arxiv.org/abs/2210.02672)

    本文提出了一种新的解决正交非负矩阵分解问题的方法，该方法使用了基于最大熵原则的解决方案，并保证了矩阵的正交性和稀疏性以及非负性。该方法在不影响近似质量的情况下具有较好的性能速度和优于文献中类似方法的稀疏性、正交性。

    

    本文提出了一种解决正交非负矩阵分解（ONMF）问题的新方法，该问题的目标是通过两个非负矩阵（特征矩阵和混合矩阵）的乘积来近似输入数据矩阵，其中一个矩阵是正交的。我们展示了如何将ONMF解释为特定的设施定位问题，并针对ONMF问题采用基于最大熵原则的FLP解决方案进行了调整。所提出的方法保证了特征矩阵或混合矩阵的正交性和稀疏性，同时确保了两者的非负性。此外，我们的方法还开发了一个定量的“真实”潜在特征数量的特征-超参数用于ONMF。针对合成数据集以及标准的基因芯片数组数据集进行的评估表明，该方法在不影响近似质量的情况下具有较好的稀疏性、正交性和性能速度，相对于文献中类似方法有显著的改善。

    In this paper, we introduce a new methodology to solve the orthogonal nonnegative matrix factorization (ONMF) problem, where the objective is to approximate an input data matrix by a product of two nonnegative matrices, the features matrix and the mixing matrix, where one of them is orthogonal. We show how the ONMF can be interpreted as a specific facility-location problem (FLP), and adapt a maximum-entropy-principle based solution for FLP to the ONMF problem. The proposed approach guarantees orthogonality and sparsity of the features or the mixing matrix, while ensuring nonnegativity of both. Additionally, our methodology develops a quantitative characterization of ``true" number of underlying features - a hyperparameter required for the ONMF. An evaluation of the proposed method conducted on synthetic datasets, as well as a standard genetic microarray dataset indicates significantly better sparsity, orthogonality, and performance speed compared to similar methods in the literature, w
    
[^127]: 数据标准化在脑电领域适应中的影响研究

    On The Effects Of Data Normalisation For Domain Adaptation On EEG Data. (arXiv:2210.01081v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.01081](http://arxiv.org/abs/2210.01081)

    本文研究了数据标准化对脑电领域适应的影响，并在三个EEG数据集上进行了实验评估。

    

    在机器学习文献中，数据集转换问题一直是一个众所周知的问题，与机器学习标准假设不同的是，训练集和测试集中的数据可能遵循不同的概率分布，导致机器学习系统的泛化性能不佳。这个问题在脑机接口领域尤为突出，因为生物信号如脑电图信号通常被用于数据处理。然而，脑电信号在时间和不同受试者之间都非常不稳定。为了解决这个问题，许多提出的解决方法都基于最近的转移学习方法，如领域适应。然而，在许多情况下，改进的实际原因仍然模糊。本文着重研究数据标准化或标准化策略在领域适应方法中的影响。具体而言，本文使用SEED、DEAP和BCI竞赛IV 2a EEG数据集，对数据标准化策略应用于领域适应方法中的影响进行了实验评估。

    In the Machine Learning (ML) literature, a well-known problem is the Dataset Shift problem where, differently from the ML standard hypothesis, the data in the training and test sets can follow different probability distributions, leading ML systems toward poor generalisation performances. This problem is intensely felt in the Brain-Computer Interface (BCI) context, where bio-signals as Electroencephalographic (EEG) are often used. In fact, EEG signals are highly non-stationary both over time and between different subjects. To overcome this problem, several proposed solutions are based on recent transfer learning approaches such as Domain Adaption (DA). In several cases, however, the actual causes of the improvements remain ambiguous. This paper focuses on the impact of data normalisation, or standardisation strategies applied together with DA methods. In particular, using \textit{SEED}, \textit{DEAP}, and \textit{BCI Competition IV 2a} EEG datasets, we experimentally evaluated the impa
    
[^128]: 一种通过统一离散的双向图学习实现高效多视图聚类的方法

    Efficient Multi-view Clustering via Unified and Discrete Bipartite Graph Learning. (arXiv:2209.04187v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.04187](http://arxiv.org/abs/2209.04187)

    本文提出了一种高效的多视图聚类方法，通过基于锚点的子空间学习、双向图学习和离散优化实现了单视图和一致性图的联合学习，避免了高计算复杂度，并在多个数据集上取得了优异的性能表现。

    

    尽管以往基于图的多视图聚类算法已经取得了重大进展，但它们大多仍然面临三个限制。首先，它们往往遭受高计算复杂度的困扰，限制了它们在大规模场景中的应用。其次，它们通常在单视图级别或视图一致性级别上执行图学习，但常常忽略了单视图和一致性图的联合学习可能性。第三，许多算法依赖于k-means对谱嵌入进行离散化，但缺乏直接学习带离散聚类结构的图的能力。因此，本文提出了一种通过统一离散的双向图学习实现高效多视图聚类的方法（UDBGL）。具体来说，该方法采用了基于锚点的子空间学习，从多个视图中学习了视图特定的双向图，然后利用双向图融合学习了视图一致性双向图。在此过程中，UDBGL通过采用低秩矩阵近似和加速交替方向乘数法避免了高计算复杂度。此外，通过最小化统一目标函数，它实现了单视图和一致性图的联合学习。最后，为了解决第三个限制，提出了一种离散优化方法，直接学习所学图的离散聚类结构。在各种数据集上的实验结果表明，UDBGL优于几种最新的多视图聚类算法。

    Although previous graph-based multi-view clustering algorithms have gained significant progress, most of them are still faced with three limitations. First, they often suffer from high computational complexity, which restricts their applications in large-scale scenarios. Second, they usually perform graph learning either at the single-view level or at the view-consensus level, but often neglect the possibility of the joint learning of single-view and consensus graphs. Third, many of them rely on the k-means for discretization of the spectral embeddings, which lack the ability to directly learn the graph with discrete cluster structure. In light of this, this paper presents an efficient multi-view clustering approach via unified and discrete bipartite graph learning (UDBGL). Specifically, the anchor-based subspace learning is incorporated to learn the view-specific bipartite graphs from multiple views, upon which the bipartite graph fusion is leveraged to learn a view-consensus bipartit
    
[^129]: 阿尔伯塔AI研究计划

    The Alberta Plan for AI Research. (arXiv:2208.11173v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2208.11173](http://arxiv.org/abs/2208.11173)

    阿尔伯塔计划是一项人工智能研究计划，在阿尔伯塔的研究团队及全球志同道合的人士中进行，旨在探索AI的研究方法和应用。

    

    本文介绍了我们的人工智能研究方法，我们称之为阿尔伯塔计划。阿尔伯塔计划在阿尔伯塔的研究团队以及世界各地志同道合的人士中开展。我们欢迎所有愿意加入我们这一追求的人。

    Herein we describe our approach to artificial intelligence research, which we call the Alberta Plan. The Alberta Plan is pursued within our research groups in Alberta and by others who are like minded throughout the world. We welcome all who would join us in this pursuit.
    
[^130]: 基于跨度集中采样的矩阵补全：连接均匀采样和CUR采样

    Matrix Completion with Cross-Concentrated Sampling: Bridging Uniform Sampling and CUR Sampling. (arXiv:2208.09723v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.09723](http://arxiv.org/abs/2208.09723)

    本文提出了一种名为跨度集中采样（CCS）的新型采样策略，可提供额外的灵活性来节省真实应用中的采样成本。作者还提供了CCS矩阵补全的充分条件，并提出了一种高效的非凸算法ICURC。数值实验验证了CCS和ICURC优于均匀采样和基线算法。

    

    在矩阵补全领域，虽然均匀采样得到了广泛关注，但CUR采样通过行和列样本逼近低秩矩阵。不幸的是，在真实世界的应用中，这两种采样模型都缺乏灵活性。在这项工作中，我们提出了一种新颖且易于实现的采样策略，称为跨度集中采样（CCS）。通过连接均匀采样和CUR采样，CCS提供了额外的灵活性，有可能在应用中节省采样成本。此外，我们还提供了CCS型矩阵补全的充分条件。我们还提出了一种高效的非凸算法，称为迭代CUR补全（ICURC），用于所提出的CCS模型。数值实验验证了CCS和ICURC在合成和真实数据集上相对于均匀采样及其基线算法的实际优势。

    While uniform sampling has been widely studied in the matrix completion literature, CUR sampling approximates a low-rank matrix via row and column samples. Unfortunately, both sampling models lack flexibility for various circumstances in real-world applications. In this work, we propose a novel and easy-to-implement sampling strategy, coined Cross-Concentrated Sampling (CCS). By bridging uniform sampling and CUR sampling, CCS provides extra flexibility that can potentially save sampling costs in applications. In addition, we also provide a sufficient condition for CCS-based matrix completion. Moreover, we propose a highly efficient non-convex algorithm, termed Iterative CUR Completion (ICURC), for the proposed CCS model. Numerical experiments verify the empirical advantages of CCS and ICURC against uniform sampling and its baseline algorithms, on both synthetic and real-world datasets.
    
[^131]: 基于潜在代理表示学习的长期因果效应估计

    Long-term Causal Effects Estimation via Latent Surrogates Representation Learning. (arXiv:2208.04589v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.04589](http://arxiv.org/abs/2208.04589)

    Laser 是一种基于潜在代理表示学习的估计长期因果效应的灵活方法，能够在代理和其代理混合在一起的真实世界情景中应用。

    

    在许多实际应用，如营销和医学中，基于短期代理来估计长期因果效应是一个重要而具有挑战性的问题。尽管某些领域中已有所成功，但大多数现有方法以一种理想化和简化的方式估计因果效应，忽略了短期结果之间的因果结构，并将它们全部视为代理。然而，这种方法无法很好地应用于真实世界的情景，其中局部观察到的代理与它们在短期结果中的代理混合在一起。因此，我们开发了一种灵活的方法，称为Laser，以在更现实的情况下估计长期因果效应，其中观察到代理或具有观察代理。鉴于代理和代理之间的不可区分性，我们利用可识别变分自编码器（iVAE）在不需要区分观察到的代理或先验条件的情况下恢复所有有效代理候选者上的整个有效代理。

    Estimating long-term causal effects based on short-term surrogates is a significant but challenging problem in many real-world applications, e.g., marketing and medicine. Despite its success in certain domains, most existing methods estimate causal effects in an idealistic and simplistic way - ignoring the causal structure among short-term outcomes and treating all of them as surrogates. However, such methods cannot be well applied to real-world scenarios, in which the partially observed surrogates are mixed with their proxies among short-term outcomes. To this end, we develop our flexible method, Laser, to estimate long-term causal effects in the more realistic situation that the surrogates are observed or have observed proxies.Given the indistinguishability between the surrogates and proxies, we utilize identifiable variational auto-encoder (iVAE) to recover the whole valid surrogates on all the surrogates candidates without the need of distinguishing the observed surrogates or the p
    
[^132]: MobileNeRF：利用多边形光栅化管线在移动架构上高效呈现神经现场。

    MobileNeRF: Exploiting the Polygon Rasterization Pipeline for Efficient Neural Field Rendering on Mobile Architectures. (arXiv:2208.00277v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2208.00277](http://arxiv.org/abs/2208.00277)

    这篇论文提出了一种在移动设备上高效呈现神经现场的方法，通过使用纹理多边形而不是基于射线行进的体积渲染算法，并且利用传统渲染管线中的 z-缓冲器，使得 NeRF 可以通过像素级并行性来实现在移动设备上交互式帧速率。

    

    神经辐射场（NeRF）展示了从新颖的视角合成3D场景图像的惊人能力。然而，它们依赖于基于射线行进的专业体积渲染算法，这些算法与广泛部署的图形硬件的能力不匹配。本文介绍了一种基于纹理多边形的新型NeRF表示法，它可以使用标准渲染管线高效地合成新的图像。将NeRF表示为一组多边形，纹理表示二元不透明度和特征向量。使用z-缓冲器传统呈现多边形，可以在每个像素处获得特征的图像，这些特征由小型、视图相关的MLP在片段着色器中解释以生成最终的像素颜色。这种方法使得NeRF可以使用传统的多边形光栅化管线进行呈现，这提供了大规模的像素级并行性，在包括移动电话在内的各种计算平台上实现交互式帧速率。

    Neural Radiance Fields (NeRFs) have demonstrated amazing ability to synthesize images of 3D scenes from novel views. However, they rely upon specialized volumetric rendering algorithms based on ray marching that are mismatched to the capabilities of widely deployed graphics hardware. This paper introduces a new NeRF representation based on textured polygons that can synthesize novel images efficiently with standard rendering pipelines. The NeRF is represented as a set of polygons with textures representing binary opacities and feature vectors. Traditional rendering of the polygons with a z-buffer yields an image with features at every pixel, which are interpreted by a small, view-dependent MLP running in a fragment shader to produce a final pixel color. This approach enables NeRFs to be rendered with the traditional polygon rasterization pipeline, which provides massive pixel-level parallelism, achieving interactive frame rates on a wide range of compute platforms, including mobile pho
    
[^133]: 安全探索在没有奖励反馈的强化学习任务中几乎不会增加样本的复杂度

    Safe Exploration Incurs Nearly No Additional Sample Complexity for Reward-free RL. (arXiv:2206.14057v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.14057](http://arxiv.org/abs/2206.14057)

    本文提出 Safe reWard-frEe ExploraTion (SWEET)框架，在RF-RL任务中可将安全约束和探索效率同时实现，使得安全探索几乎不会增加额外的样本复杂度。

    

    无奖励反馈的强化学习（RF-RL）是最近引入的一种强化学习范式，依靠随机采取行动来探索未知的环境，没有任何奖励反馈信息。虽然RF-RL中探索阶段的主要目标是在最少轨迹数量的情况下减少对估计模型的不确定性，但在实践中，智能体经常需要同时遵守某些安全约束。目前尚不明确这种安全探索要求会如何影响相应的样本复杂度，以便在规划中实现所得到策略的所需最优性。在本文中，我们首次尝试回答这个问题。具体而言，我们考虑已知一个安全基线策略的情况，提出了一个统一的安全无奖励探索（SWEET）框架。我们然后特化SWEET框架到表格和低秩MDP设置中，并分别开发了被称为Tabular-SWEET和Low-rank-SWEET的算法。这两种算法能够在RF-RL的探索阶段中并入安全约束，并在某些假设下保证可证明的安全性，同时实现所需的性能。我们表明，在我们提出的算法中，安全探索引发的附加样本复杂度几乎为零，这表明安全约束和最优性目标可以同时实现而不会太大地降低样本效率。

    Reward-free reinforcement learning (RF-RL), a recently introduced RL paradigm, relies on random action-taking to explore the unknown environment without any reward feedback information. While the primary goal of the exploration phase in RF-RL is to reduce the uncertainty in the estimated model with minimum number of trajectories, in practice, the agent often needs to abide by certain safety constraint at the same time. It remains unclear how such safe exploration requirement would affect the corresponding sample complexity in order to achieve the desired optimality of the obtained policy in planning. In this work, we make a first attempt to answer this question. In particular, we consider the scenario where a safe baseline policy is known beforehand, and propose a unified Safe reWard-frEe ExploraTion (SWEET) framework. We then particularize the SWEET framework to the tabular and the low-rank MDP settings, and develop algorithms coined Tabular-SWEET and Low-rank-SWEET, respectively. Bot
    
[^134]: 大核3D：在3D稀疏CNN中扩展核

    LargeKernel3D: Scaling up Kernels in 3D Sparse CNNs. (arXiv:2206.10555v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.10555](http://arxiv.org/abs/2206.10555)

    LargeKernel3D是一种解决直接应用大型卷积核在3D CNN中遇到困难的方法，通过提出空间分区卷积和其大核模块来避免优化和效率问题。该网络在多项3D任务中具有很好的表现，包括在语义分割和物体检测基准测试中分别取得了高分数，并可以在 Waymo 3D 物体检测中扩展到17x17x17的核大小。

    

    最近2D CNN的进展表明大核是重要的。然而，当直接应用大的卷积核在3D CNN中时，会遇到严重困难，2D网络中成功的模块设计在3D网络上变得惊人地无效，包括流行的深度卷积。为了解决这个重要的挑战，我们提出了空间分区卷积及其大核模块。这避免了纯粹3D大核的优化和效率问题。我们的大核3D CNN网络LargeKernel3D，在语义分割和物体检测的3D任务中取得了显着的提高。它在ScanNetv2语义分割和nuScenes物体检测基准测试中分别达到73.9%的mIoU和72.8%的NDS，位列nuScenes LIDAR排行榜第一。通过简单的多模态融合，性能进一步提升至74.2%的NDS。此外，LargeKernel3D 可以在 Waymo 3D 物体检测中扩展到17x17x17的核大小。

    Recent advance in 2D CNNs has revealed that large kernels are important. However, when directly applying large convolutional kernels in 3D CNNs, severe difficulties are met, where those successful module designs in 2D become surprisingly ineffective on 3D networks, including the popular depth-wise convolution. To address this vital challenge, we instead propose the spatial-wise partition convolution and its large-kernel module. As a result, it avoids the optimization and efficiency issues of naive 3D large kernels. Our large-kernel 3D CNN network, LargeKernel3D, yields notable improvement in 3D tasks of semantic segmentation and object detection. It achieves 73.9% mIoU on the ScanNetv2 semantic segmentation and 72.8% NDS nuScenes object detection benchmarks, ranking 1st on the nuScenes LIDAR leaderboard. The performance further boosts to 74.2% NDS with a simple multi-modal fusion. In addition, LargeKernel3D can be scaled to 17x17x17 kernel size on Waymo 3D object detection. For the fir
    
[^135]: 评估多达50量子比特的量子电路集合的随机性

    Estimating the randomness of quantum circuit ensembles up to 50 qubits. (arXiv:2205.09900v3 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2205.09900](http://arxiv.org/abs/2205.09900)

    本文提出了一个基于张量网络的算法，用于评估随机电路集合与精确随机性之间的距离，该算法复杂度对于浅层电路具有多项式时间，在局部和并行随机电路中验证了复杂度线性增长，同时可以在变分算法中解决“贫瘠高原”问题。

    

    随着随机量子电路在量子霸权展示、用于化学和机器学习的变分量子算法以及黑洞信息等领域中的应用，研究随机电路正确近似任意随机幺正矩阵的能力对于了解它们的复杂性、可表达性和训练性具有重要意义。本文开发了数值协议，用于评估一个给定电路集合与精确随机性之间的框架潜力距离，提出了基于张量网络的算法，并证明对于浅层电路具有多项式复杂度，可使用CPU和GPU并行进行高效计算。我们研究了1.局部和并行随机电路以验证布朗-萨斯金猜想所述的复杂度线性增长；2.硬件有效近似答案以在变分算法中解决“贫瘠高原”问题。本文表明，大规模张量网络模拟可以提供重要的洞见。

    Random quantum circuits have been utilized in the contexts of quantum supremacy demonstrations, variational quantum algorithms for chemistry and machine learning, and blackhole information. The ability of random circuits to approximate any random unitaries has consequences on their complexity, expressibility, and trainability. To study this property of random circuits, we develop numerical protocols for estimating the frame potential, the distance between a given ensemble and the exact randomness. Our tensor-network-based algorithm has polynomial complexity for shallow circuits and is high-performing using CPU and GPU parallelism. We study 1. local and parallel random circuits to verify the linear growth in complexity as stated by the Brown-Susskind conjecture, and; 2. hardware-efficient ans\"atze to shed light on its expressibility and the barren plateau problem in the context of variational algorithms. Our work shows that large-scale tensor network simulations could provide important
    
[^136]: 使用人工智能增强的心电图进行新发糖尿病评估

    New-Onset Diabetes Assessment Using Artificial Intelligence-Enhanced Electrocardiography. (arXiv:2205.02900v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.02900](http://arxiv.org/abs/2205.02900)

    本研究表明，使用人工智能增强的心电图可以有效地识别新发糖尿病成人患者，相较于传统的ADA风险检测方法，该方法具有更好的准确性和特异性。

    

    未诊断的糖尿病在患者中占21.4％，由于筛查率的限制，糖尿病可能潜伏无症状而未被检测。本研究旨在通过使用人工智能（AI）增强的心电图（ECG）来确定新发糖尿病的成人患者。 我们训练了一个神经网络，使用12导联心电图和可用的人口统计学数据来估计HbA1c。 我们回顾性地收集了一组包含有配对的ECG和HbA1c数据的病人数据集。结果显示，相较于传统的ADA风险检测，基于ECG的评估效果更好。AI增强的ECG评估的准确性达到81％，灵敏度为80％，特异性为82％。研究结果表明，人工智能增强的ECG可以成为新发糖尿病成人患者的一个有前景的工具，特别是在传统筛查方法有限的人群中。

    Undiagnosed diabetes is present in 21.4% of adults with diabetes. Diabetes can remain asymptomatic and undetected due to limitations in screening rates. To address this issue, questionnaires, such as the American Diabetes Association (ADA) Risk test, have been recommended for use by physicians and the public. Based on evidence that blood glucose concentration can affect cardiac electrophysiology, we hypothesized that an artificial intelligence (AI)-enhanced electrocardiogram (ECG) could identify adults with new-onset diabetes. We trained a neural network to estimate HbA1c using a 12-lead ECG and readily available demographics. We retrospectively assembled a dataset comprised of patients with paired ECG and HbA1c data. The population of patients who receive both an ECG and HbA1c may a biased sample of the complete outpatient population, so we adjusted the importance placed on each patient to generate a more representative pseudo-population. We found ECG-based assessment outperforms the 
    
[^137]: 修正噪声：Disentangling Source Feature用于StyleGAN的迁移学习

    Fix the Noise: Disentangling Source Feature for Transfer Learning of StyleGAN. (arXiv:2204.14079v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2204.14079](http://arxiv.org/abs/2204.14079)

    本文提出了一种新的方法“FixNoise”，在StyleGAN的迁移学习中引入了简单的特征匹配损失来改善生成质量，并在目标特征空间的一部分中仅保留源特征以控制源特征的程度。实验证明其在领域翻译和属性编辑中的有效性。

    

    近来，StyleGAN的迁移学习在解决不同任务，特别是领域翻译上表现出了巨大潜力。然而，以往的方法通过交换或冻结权重来利用源模型进行迁移学习，但其在视觉质量和控制源特征方面存在限制。本文提出了一种新的方法，通过引入简单的特征匹配损失来改善生成质量，并通过所提出的策略“FixNoise”训练目标模型以仅在目标特征空间的一部分中保留源特征，从而控制源特征的程度。由于特征空间是分离的，我们的方法可以在单个模型中平滑地控制源特征的程度。大量实验证明了我们的方法在领域翻译和属性编辑中的有效性。

    Transfer learning of StyleGAN has recently shown great potential to solve diverse tasks, especially in domain translation. Previous methods utilized a source model by swapping or freezing weights during transfer learning, however, they have limitations on visual quality and controlling source features. In other words, they require additional models that are computationally demanding and have restricted control steps that prevent a smooth transition. In this paper, we propose a new approach to overcome these limitations. Instead of swapping or freezing, we introduce a simple feature matching loss to improve generation quality. In addition, to control the degree of source features, we train a target model with the proposed strategy, FixNoise, to preserve the source features only in a disentangled subspace of a target feature space. Owing to the disentangled feature space, our method can smoothly control the degree of the source features in a single model. Extensive experiments demonstrat
    
[^138]: 因果推理与视觉表征学习的交汇：一项前瞻性研究

    Causal Reasoning Meets Visual Representation Learning: A Prospective Study. (arXiv:2204.12037v8 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2204.12037](http://arxiv.org/abs/2204.12037)

    这项论文讨论了视觉表征学习中缺乏解释性，鲁棒性和泛化性的问题，并提出了因果推理范式来实现这些属性。

    

    视觉表征学习在各种实际应用中都是无处不在的，包括视觉理解、视频理解、多模态分析、人机交互和城市计算。由于大数据时代涌现的大量多模态异构的时空/时间/时空数据，现有视觉模型的解释性、鲁棒性和超出分布的泛化性缺乏挑战。现有方法中大多数倾向于适应原始数据/变量分布，忽略了多模态知识背后的基本因果关系，缺乏统一的指导和分析，无法解释为什么现代视觉表征学习方法容易陷入数据偏见，并且具有有限的泛化和认知能力。受到人类级别代理的强大推理能力的启发，近年来，人们付出了很大的努力开发因果推理范式，以实现强大的表征。

    Visual representation learning is ubiquitous in various real-world applications, including visual comprehension, video understanding, multi-modal analysis, human-computer interaction, and urban computing. Due to the emergence of huge amounts of multi-modal heterogeneous spatial/temporal/spatial-temporal data in big data era, the lack of interpretability, robustness, and out-of-distribution generalization are becoming the challenges of the existing visual models. The majority of the existing methods tend to fit the original data/variable distributions and ignore the essential causal relations behind the multi-modal knowledge, which lacks unified guidance and analysis about why modern visual representation learning methods easily collapse into data bias and have limited generalization and cognitive abilities. Inspired by the strong inference ability of human-level agents, recent years have therefore witnessed great effort in developing causal reasoning paradigms to realize robust represe
    
[^139]: CgAT：基于中心引导的对抗性训练提升Hashing检索鲁棒性

    CgAT: Center-Guided Adversarial Training for Deep Hashing-Based Retrieval. (arXiv:2204.10779v5 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2204.10779](http://arxiv.org/abs/2204.10779)

    本文提出了CgAT方法，基于中心引导的对抗性训练方法，可提升深度Hashing网络检索的鲁棒性，取得了领先于现有方法的效果。

    

    深度Hashing在图像检索领域被广泛应用，但往往容易受到对抗样本的攻击。为此，本文提出了基于min-max的中心引导的对抗性训练方法（CgAT），通过最坏的对抗性样本来提高深度Hashing网络的鲁棒性。实验表明，该方法在多个基准数据集上优于目前深度Hashing检索领域中的最新对抗性防御算法。

    Deep hashing has been extensively utilized in massive image retrieval because of its efficiency and effectiveness. However, deep hashing models are vulnerable to adversarial examples, making it essential to develop adversarial defense methods for image retrieval. Existing solutions achieved limited defense performance because of using weak adversarial samples for training and lacking discriminative optimization objectives to learn robust features. In this paper, we present a min-max based Center-guided Adversarial Training, namely CgAT, to improve the robustness of deep hashing networks through worst adversarial examples. Specifically, we first formulate the center code as a semantically-discriminative representative of the input image content, which preserves the semantic similarity with positive samples and dissimilarity with negative examples. We prove that a mathematical formula can calculate the center code immediately. After obtaining the center codes in each optimization iterati
    
[^140]: 独立链$n$人随机博弈中学习稳定纳什均衡策略

    Learning Stationary Nash Equilibrium Policies in $n$-Player Stochastic Games with Independent Chains. (arXiv:2201.12224v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2201.12224](http://arxiv.org/abs/2201.12224)

    本文针对一个$n$人随机博弈的子类，设计了多项式时间的学习算法，可以学习出$\epsilon$-NE策略，在奖励函数为社会凸性的情况下具有多项式复杂度上限。

    

    我们研究了一个$n$人随机博弈的子类，在该子类中，玩家具有自己的内部状态/动作空间，但通过其支付功能相互耦合。假设玩家的内部链是由独立的转移概率驱动的。此外，玩家只能收到他们的支付实现，而不是实际的功能，并且不能观察彼此的状态/动作。针对这类游戏，我们首先表明，不假设奖励函数，求解固定纳什均衡（NE）策略是一个不可交互的问题。然而，对于一般的奖励函数，我们基于对偶平均和对偶镜面下降的多项式时间学习算法，这些算法以期望或几乎确定地以平均的Nikaido-Isoda距离收敛到$\epsilon$-NE策略集合。特别地，我们在额外假设奖励函数为社会凸性的情况下，推导出多项式上界，以实现$\epsilon$-NE策略所需的迭代次数。

    We consider a subclass of $n$-player stochastic games, in which players have their own internal state/action spaces while they are coupled through their payoff functions. It is assumed that players' internal chains are driven by independent transition probabilities. Moreover, players can receive only realizations of their payoffs, not the actual functions, and cannot observe each other's states/actions. For this class of games, we first show that finding a stationary Nash equilibrium (NE) policy without any assumption on the reward functions is interactable. However, for general reward functions, we develop polynomial-time learning algorithms based on dual averaging and dual mirror descent, which converge in terms of the averaged Nikaido-Isoda distance to the set of $\epsilon$-NE policies almost surely or in expectation. In particular, under extra assumptions on the reward functions such as social concavity, we derive polynomial upper bounds on the number of iterates to achieve an $\ep
    
[^141]: MRI中肝脏和肝部损伤联合分割的混合CNN与Transformer层

    Joint Liver and Hepatic Lesion Segmentation in MRI using a Hybrid CNN with Transformer Layers. (arXiv:2201.10981v3 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2201.10981](http://arxiv.org/abs/2201.10981)

    本文提出了一种名为SWTR-Unet的混合网络，它通过将卷积和基于Transformer的结构元素相结合，实现了MRI中肝脏和肝部损伤联合分割的高效、精确和可靠。该网络在单模态和多模态数据上都具有超过最新方法的表现。

    

    基于深度学习的肝脏和其中肝部损伤的分割在临床实践中越来越受到重视，因为每年肝癌的发病率不断增加。虽然过去几年中已经成功开发了具有总体有希望结果的各种网络变体在医学图像分割领域，但几乎所有这些网络都难以精准地分割MRI中的肝部损伤。这导致了将卷积和基于Transformer的结构元素相结合的想法，以克服现有限制。本文提出了一种混合网络SWTR-Unet，它由预训练的ResNet、Transformer块以及常见的Unet-style解码器路径组成。该网络主要应用于单模态非增强肝脏MRI，并额外应用于公开可用的CT数据，以验证其在其他模态数据上的适用性。结果表明，所提出的SWTR-Unet相对于最新的方法具有更好的性能，并在训练时间方面高效。

    Deep learning-based segmentation of the liver and hepatic lesions therein steadily gains relevance in clinical practice due to the increasing incidence of liver cancer each year. Whereas various network variants with overall promising results in the field of medical image segmentation have been successfully developed over the last years, almost all of them struggle with the challenge of accurately segmenting hepatic lesions in magnetic resonance imaging (MRI). This led to the idea of combining elements of convolutional and transformer-based architectures to overcome the existing limitations. This work presents a hybrid network called SWTR-Unet, consisting of a pretrained ResNet, transformer blocks as well as a common Unet-style decoder path. This network was primarily applied to single-modality non-contrast-enhanced liver MRI and additionally to the publicly available computed tomography (CT) data of the liver tumor segmentation (LiTS) challenge to verify the applicability on other mod
    
[^142]: 少样本目标检测的动态关联学习

    Dynamic Relevance Learning for Few-Shot Object Detection. (arXiv:2108.02235v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2108.02235](http://arxiv.org/abs/2108.02235)

    本研究提出了一种动态关联学习模型来进行少样本目标检测。该模型利用所有支持图像和查询图像上的感兴趣区域之间的关系来构建动态GCN，并适应不同的任务。

    

    昂贵的边界框注释限制了目标检测任务的发展。因此，有必要关注更具挑战性的少样本目标检测任务。这需要仅使用少量训练样本的检测器识别新类别的对象。当今，许多现有的流行方法采用类似于元学习的训练方式，如Meta R-CNN系列，已经取得了有前途的性能。然而，支持数据仅作为类别注意力，以引导每次查询图像的检测。它们彼此的相关性仍然未被开发。此外，许多最近的工作将支持数据和查询图像视为独立分支，而不考虑它们之间的关系。为了解决这个问题，我们提出了一个动态关联学习模型，它利用所有支持图像和查询图像上的感兴趣区域（RoI）之间的关系来构建一个动态图卷积网络（GCN）。通过调整预测分布，模型可以适应不同的任务。

    Expensive bounding-box annotations have limited the development of object detection task. Thus, it is necessary to focus on more challenging task of few-shot object detection. It requires the detector to recognize objects of novel classes with only a few training samples. Nowadays, many existing popular methods adopting training way similar to meta-learning have achieved promising performance, such as Meta R-CNN series. However, support data is only used as the class attention to guide the detecting of query images each time. Their relevance to each other remains unexploited. Moreover, a lot of recent works treat the support data and query images as independent branch without considering the relationship between them. To address this issue, we propose a dynamic relevance learning model, which utilizes the relationship between all support images and Region of Interest (RoI) on the query images to construct a dynamic graph convolutional network (GCN). By adjusting the prediction distribu
    
[^143]: 自适应线性回归中的近最优推断

    Near-optimal inference in adaptive linear regression. (arXiv:2107.02266v3 [math.ST] UPDATED)

    [http://arxiv.org/abs/2107.02266](http://arxiv.org/abs/2107.02266)

    本文提出了一些在线去偏估计的方法来修正自适应线性回归中的渐近偏差，利用数据集中的协方差结构提供更锐利的估计。

    

    当数据以自适应方式收集时，即使是最简单的方法如普通最小二乘法也可能表现出非正常的渐近行为。 作为不良后果，基于渐近正常性的假设检验和置信区间可能导致错误结果。 我们提出了一些在线去偏估计的方法来纠正这些误差，并利用数据集中存在的协方差结构，在其更多信息已累积的方向上提供更锐利的估计。 我们在数据收集过程的温和条件下证明了我们提出的在线去偏估计的渐近正态性质，并提供了渐近精确的置信区间。 我们还针对自适应线性回归问题证明了最小化下界，从而提供了比较估计器的基线。 在我们提出的估计器达到最小值的各种条件下，最小化下界均实现。

    When data is collected in an adaptive manner, even simple methods like ordinary least squares can exhibit non-normal asymptotic behavior. As an undesirable consequence, hypothesis tests and confidence intervals based on asymptotic normality can lead to erroneous results. We propose a family of online debiasing estimators to correct these distributional anomalies in least squares estimation. Our proposed methods take advantage of the covariance structure present in the dataset and provide sharper estimates in directions for which more information has accrued. We establish an asymptotic normality property for our proposed online debiasing estimators under mild conditions on the data collection process and provide asymptotically exact confidence intervals. We additionally prove a minimax lower bound for the adaptive linear regression problem, thereby providing a baseline by which to compare estimators. There are various conditions under which our proposed estimators achieve the minimax lo
    
[^144]: 边缘设备上的深度神经网络主动学习

    Active Learning for Deep Neural Networks on Edge Devices. (arXiv:2106.10836v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2106.10836](http://arxiv.org/abs/2106.10836)

    本研究提出了一个通用的任务无关框架，用于边缘设备上的深度神经网络的主动学习问题，可以有效减少标记和通信成本，并保证解的质量。

    

    当处理边缘设备上的深度神经网络应用时，持续更新模型非常重要。尽管使用实时数据来更新模型是理想的，但由于标记和通信成本等限制，并不总是可行的。因此，有必要在设备上过滤和选择用于训练的数据（即主动学习）。本文规范了边缘设备上DNN的实际主动学习问题，并提出了一个通用的任务无关框架来解决这个问题，将其减少到流子模块最大化。这个框架足够轻便，可以用低计算资源运行，但由于子模块性质，提供其质量在理论上得到保证的解。通过这个框架，我们可以灵活地配置数据选择标准，包括使用以前的主动学习研究中提出的方法。我们在分类和目标检测任务中评估了我们的方法。

    When dealing with deep neural network (DNN) applications on edge devices, continuously updating the model is important. Although updating a model with real incoming data is ideal, using all of them is not always feasible due to limits, such as labeling and communication costs. Thus, it is necessary to filter and select the data to use for training (i.e., active learning) on the device. In this paper, we formalize a practical active learning problem for DNNs on edge devices and propose a general task-agnostic framework to tackle this problem, which reduces it to a stream submodular maximization. This framework is light enough to be run with low computational resources, yet provides solutions whose quality is theoretically guaranteed thanks to the submodular property. Through this framework, we can configure data selection criteria flexibly, including using methods proposed in previous active learning studies. We evaluate our approach on both classification and object detection tasks in 
    
[^145]: RoBIC：一个用于评估分类器鲁棒性的基准测试套件

    RoBIC: A benchmark suite for assessing classifiers robustness. (arXiv:2102.05368v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2102.05368](http://arxiv.org/abs/2102.05368)

    RoBIC是一个无参数基准测试套件，用于公正地评估图像分类器的鲁棒性，独立于准确性，并可以评估其对白盒和黑盒攻击的鲁棒性。

    

    随着对抗性攻击的发展，许多防御措施已经涌现出来。因此，必须有相应的客观评估模型的方法。本文通过提出一个新的无参数基准测试套件RoBIC来系统地解决这个问题。RoBIC使用一种新的半扭曲度量方法，公正地评估图像分类器的鲁棒性。它独立于分类器的准确性，评估其对白盒和黑盒攻击的鲁棒性。RoBIC比其他现有基准测试套件更快。我们还展示了16个最近模型在RoBIC评估下鲁棒性的显著差异。

    Many defenses have emerged with the development of adversarial attacks. Models must be objectively evaluated accordingly. This paper systematically tackles this concern by proposing a new parameter-free benchmark we coin RoBIC. RoBIC fairly evaluates the robustness of image classifiers using a new half-distortion measure. It gauges the robustness of the network against white and black box attacks, independently of its accuracy. RoBIC is faster than the other available benchmarks. We present the significant differences in the robustness of 16 recent models as assessed by RoBIC.
    

