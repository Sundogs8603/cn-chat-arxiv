# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [ExtremeCast: Boosting Extreme Value Prediction for Global Weather Forecast](https://rss.arxiv.org/abs/2402.01295) | ExtremeCast提出了一种新的损失函数Exloss，实现了针对极值的准确预测，同时引入了无需训练的极值增强策略ExEnsemble，提高了预报的稳健性 |
| [^2] | [Global Optimality without Mixing Time Oracles in Average-reward RL via Multi-level Actor-Critic](https://arxiv.org/abs/2403.11925) | 通过多级Actor-Critic框架和多级蒙特卡罗梯度估计器，本研究成功解决了平均奖励MDPs全局收敛中对混合时间预测的依赖性，展现出最严格的依赖关系。 |
| [^3] | [Cobweb: An Incremental and Hierarchical Model of Human-Like Category Learning](https://arxiv.org/abs/2403.03835) | Cobweb是一种类似人类类别学习系统，采用类别效用度量构建分层组织的类似树状结构，能够捕捉心理效应并在单一模型中展现出实例和原型学习的灵活性，为将来研究人类类别学习提供了基础。 |
| [^4] | [Permutation invariant functions: statistical tests, dimension reduction in metric entropy and estimation](https://arxiv.org/abs/2403.01671) | 本文研究了如何在多元概率分布中测试排列不变性、估计排列不变密度以及分析排列不变函数类的度量熵，比较了它们与没有排列不变性的函数类的差异。 |
| [^5] | [ICE-SEARCH: A Language Model-Driven Feature Selection Approach](https://arxiv.org/abs/2402.18609) | ICE-SEARCH是首个将语言模型与进化算法相结合用于特征选择任务的方法，在医学预测分析应用中取得了State-of-the-Art(SOTA)表现。 |
| [^6] | [DDIPrompt: Drug-Drug Interaction Event Prediction based on Graph Prompt Learning](https://arxiv.org/abs/2402.11472) | 基于图提示学习的DDIPrompt框架旨在解决药物相互作用事件预测中的高度不平衡事件分布和罕见事件标记数据稀缺性问题。 |
| [^7] | [Differentially Private Zeroth-Order Methods for Scalable Large Language Model Finetuning](https://arxiv.org/abs/2402.07818) | 本文研究了差分隐私零阶方法在大型语言模型微调中的应用，该方法通过使用零阶梯度来避免传统优化方法的可扩展性瓶颈，实现了在隐私、效用和可扩展性之间的良好平衡。 |
| [^8] | [Multimodal Clinical Trial Outcome Prediction with Large Language Models](https://arxiv.org/abs/2402.06512) | 本研究提出了一种名为LIFTED的多模态临床试验结果预测方法，通过将不同模态数据转化为自然语言描述来统一数据，并构建统一的抗噪声编码器进行信息提取。 |
| [^9] | [Riemann-Lebesgue Forest for Regression](https://arxiv.org/abs/2402.04550) | 提出了一种新颖的集成方法Riemann-Lebesgue Forest (RLF)用于回归问题，通过划分函数的值域为多个区间来逼近可测函数的思想，开发了一种新的树学习算法Riemann-Lebesgue Tree。通过Hoeffding分解和Stein方法推导了RLF在不同参数设置下的渐近性能，并在仿真数据和真实世界数据集上的实验中证明了RLF与原始随机森林相比具有竞争力的性能。 |
| [^10] | [GD doesn't make the cut: Three ways that non-differentiability affects neural network training](https://arxiv.org/abs/2401.08426) | 本文研究了非可微性对神经网络训练的影响，包括收敛性差异、$L_1$正则化问题的矛盾性质以及稳定边界现象的不适用性。 |
| [^11] | [Multi-agent reinforcement learning using echo-state network and its application to pedestrian dynamics](https://arxiv.org/abs/2312.11834) | 通过使用回声状态网络将行人实现为MARL代理，研究了他们学习避让其他代理向前移动的能力，在密度不太高的情况下取得成功。 |
| [^12] | [Large Human Language Models: A Need and the Challenges](https://arxiv.org/abs/2312.07751) | 大型人类语言模型的建立需要更好地整合人类背景，并面临着如何捕捉人类因素、如何表示以及如何建模的一系列挑战。 |
| [^13] | [Sliced Wasserstein with Random-Path Projecting Directions.](http://arxiv.org/abs/2401.15889) | 本研究提出了一种无需优化的切片分布方法，该方法能够快速进行蒙特卡洛期望估计。通过利用随机向量之间的归一化差异构建随机路径投影方向，从而得到了随机路径切片分布和两个切片瓦瑟斯坦的变种。这种方法在拓扑、统计和计算性质上有重要意义。 |
| [^14] | [TIM: An Efficient Temporal Interaction Module for Spiking Transformer.](http://arxiv.org/abs/2401.11687) | TIM 是一种高效的时间交互模块，用于增强脉冲神经网络 (SNNs) 的时间数据处理能力。 |
| [^15] | [Learning Extrinsic Dexterity with Parameterized Manipulation Primitives.](http://arxiv.org/abs/2310.17785) | 论文通过学习一系列参数化操作原语，并利用环境改变物体姿态，解决了机器人在目标物体抓取被环境遮挡时的问题。 |
| [^16] | [Fusing Models with Complementary Expertise.](http://arxiv.org/abs/2310.01542) | 该论文研究了融合具有互补专长的模型的问题，并将其应用于不同任务和领域中，通过监督学习的方式实现了显著的性能提升。 |
| [^17] | [Diffusion Models as Stochastic Quantization in Lattice Field Theory.](http://arxiv.org/abs/2309.17082) | 该研究通过将生成性扩散模型与随机量子化相连接，证明了生成性扩散模型在随机量子化中的应用。数值模拟表明，生成性扩散模型可以作为全局采样器用于生成量子格点场配置，并可以显著减少马尔可夫链的自相关时间。 |
| [^18] | [ScatterUQ: Interactive Uncertainty Visualizations for Multiclass Deep Learning Problems.](http://arxiv.org/abs/2308.04588) | ScatterUQ是一个交互式系统，通过可视化展示模型在上下文驱动的不确定性设置下的性能，为用户提供了更好的理解模型预测的能力。 |
| [^19] | [Multi-Modality Multi-Loss Fusion Network.](http://arxiv.org/abs/2308.00264) | 多模态多损失融合网络通过最佳选择和融合多个模态的特征，提高了情感检测的性能，并在多个数据集上实现了最先进的结果。这些研究结果表明了用于增强神经网络中情感检测的特征选择和融合方法的优化方向。 |
| [^20] | [In-context Autoencoder for Context Compression in a Large Language Model.](http://arxiv.org/abs/2307.06945) | 在大型语言模型中，我们提出了一种称为In-context Autoencoder (ICAE)的上下文自编码器，它通过将长上下文压缩为有限数量的内存槽，实现了$4\times$的上下文压缩，并能够根据内存槽进行条件处理以响应各种提示。 |
| [^21] | [Contrastive Learning for Predicting Cancer Prognosis Using Gene Expression Values.](http://arxiv.org/abs/2306.06276) | 该论文提出应用对比学习方法，从有限的数据样本中学习基因表达数据的良好特征表示，并应用于Cox模型中，可以显著提高癌症预后的预测性能。 |
| [^22] | [COURIER: Contrastive User Intention Reconstruction for Large-Scale Pre-Train of Image Features.](http://arxiv.org/abs/2306.05001) | 该论文提出了一种基于对比学习的推荐方法，以获得更好的个性化推荐表现。 |
| [^23] | [DiffusionShield: A Watermark for Copyright Protection against Generative Diffusion Models.](http://arxiv.org/abs/2306.04642) | 本文提出了一种针对生成式扩散模型的版权保护数字水印方法DiffusionShield，保护图像免受侵权，简单易学，难以检测，可广泛应用于各行各业。 |
| [^24] | [Learning Embeddings for Sequential Tasks Using Population of Agents.](http://arxiv.org/abs/2306.03311) | 该研究基于代理人群体提出了一个信息理论框架，用于在强化学习任务中学习固定维度的嵌入，可以通过观察代理在一小组任务上的表现，来预测其在测试任务上的表现，并且可以从给定的任务选项中选择具有所需特征的任务。 |
| [^25] | [Learning Causally Disentangled Representations via the Principle of Independent Causal Mechanisms.](http://arxiv.org/abs/2306.01213) | 本文通过定义独立因果机制，提出了ICM-VAE框架，使得学习因果解缠绕表示更准确 |
| [^26] | [Information Bottleneck Analysis of Deep Neural Networks via Lossy Compression.](http://arxiv.org/abs/2305.08013) | 本文提出了一种综合框架，用于对一般神经网络进行信息瓶颈分析，以研究训练过程中的拟合和压缩阶段。通过该分析，可以更好地理解深度神经网络的泛化能力。 |
| [^27] | [Calibrated Chaos: Variance Between Runs of Neural Network Training is Harmless and Inevitable.](http://arxiv.org/abs/2304.01910) | 神经网络训练的运行变化在实际中更少遇到问题，我们提出了一种简化的统计假设并证明方差主要由于训练过程对初始条件的高敏感性所导致。 |
| [^28] | [A Linear Reconstruction Approach for Attribute Inference Attacks against Synthetic Data.](http://arxiv.org/abs/2301.10053) | 本研究提出一种新的属性推断攻击方法，针对合成数据中所有记录，具有高度的准确率和危害性。 |
| [^29] | [Continual Learning of Multi-modal Dynamics with External Memory.](http://arxiv.org/abs/2203.00936) | 本文提出了一种新的连续学习方法，通过在记忆中维护遇到序列模式的描述符来实现，能够有效处理新的行为模式的连续出现。 |

# 详细

[^1]: ExtremeCast: 提升全球天气预报的极值预测能力

    ExtremeCast: Boosting Extreme Value Prediction for Global Weather Forecast

    [https://rss.arxiv.org/abs/2402.01295](https://rss.arxiv.org/abs/2402.01295)

    ExtremeCast提出了一种新的损失函数Exloss，实现了针对极值的准确预测，同时引入了无需训练的极值增强策略ExEnsemble，提高了预报的稳健性

    

    基于机器学习的数据驱动天气预报在全球中期预报中已经得到了快速发展，并且相较于传统的基于物理的动力学模型表现出更好的性能。然而，大多数这些机器学习模型在准确预测极端天气方面存在困难，而极端值预测与此密切相关。通过数学分析，我们证明使用对称损失，如均方误差（MSE），会导致预测有偏差并低估极值。为了解决这个问题，我们引入了Exloss，一种新的损失函数，通过非对称优化突出极值，以获得准确的极端天气预报。此外，我们还引入了一种无需训练的极值增强策略ExEnsemble，它增加了像素值的方差，并提高了预报的稳健性。结合先进的全球天气预报模型，广泛的实验证明了我们的方法

    Data-driven weather forecast based on machine learning (ML) has experienced rapid development and demonstrated superior performance in the global medium-range forecast compared to traditional physics-based dynamical models. However, most of these ML models struggle with accurately predicting extreme weather, which is closely related to the extreme value prediction. Through mathematical analysis, we prove that the use of symmetric losses, such as the Mean Squared Error (MSE), leads to biased predictions and underestimation of extreme values. To address this issue, we introduce Exloss, a novel loss function that performs asymmetric optimization and highlights extreme values to obtain accurate extreme weather forecast. Furthermore, we introduce a training-free extreme value enhancement strategy named ExEnsemble, which increases the variance of pixel values and improves the forecast robustness. Combined with an advanced global weather forecast model, extensive experiments show that our sol
    
[^2]: 在平均奖励强化学习中实现全局最优性而无需混合时间预测：基于多级Actor-Critic方法

    Global Optimality without Mixing Time Oracles in Average-reward RL via Multi-level Actor-Critic

    [https://arxiv.org/abs/2403.11925](https://arxiv.org/abs/2403.11925)

    通过多级Actor-Critic框架和多级蒙特卡罗梯度估计器，本研究成功解决了平均奖励MDPs全局收敛中对混合时间预测的依赖性，展现出最严格的依赖关系。

    

    在平均奖励强化学习的背景下，对于混合时间的预测的oracle知识要求，即度量马尔可夫链在固定策略下达到其稳态分布所需的时间，对于策略梯度方法的全球收敛构成了重大挑战。为了解决这一限制，我们考虑了多级Actor-Critic（MAC）框架，该框架结合了多级蒙特卡洛（MLMC）梯度估计器。通过我们的方法，实现了对混合时间知识的依赖性的有效减轻，这是平均奖励MDPs全局收敛的首次尝试。此外，我们的方法展现出最严格的$\mathcal{O}$依赖关系。

    arXiv:2403.11925v1 Announce Type: new  Abstract: In the context of average-reward reinforcement learning, the requirement for oracle knowledge of the mixing time, a measure of the duration a Markov chain under a fixed policy needs to achieve its stationary distribution-poses a significant challenge for the global convergence of policy gradient methods. This requirement is particularly problematic due to the difficulty and expense of estimating mixing time in environments with large state spaces, leading to the necessity of impractically long trajectories for effective gradient estimation in practical applications. To address this limitation, we consider the Multi-level Actor-Critic (MAC) framework, which incorporates a Multi-level Monte Carlo (MLMC) gradient estimator. With our approach, we effectively alleviate the dependency on mixing time knowledge, a first for average-reward MDPs global convergence. Furthermore, our approach exhibits the tightest-available dependence of $\mathcal{O
    
[^3]: Cobweb：一种增量和分层式的人类类别学习模型

    Cobweb: An Incremental and Hierarchical Model of Human-Like Category Learning

    [https://arxiv.org/abs/2403.03835](https://arxiv.org/abs/2403.03835)

    Cobweb是一种类似人类类别学习系统，采用类别效用度量构建分层组织的类似树状结构，能够捕捉心理效应并在单一模型中展现出实例和原型学习的灵活性，为将来研究人类类别学习提供了基础。

    

    Cobweb是一种类似人类的类别学习系统，与其他增量分类模型不同的是，它利用类别效用度量构建分层组织的类似树状结构。先前的研究表明，Cobweb能够捕捉心理效应，如基本水平、典型性和扇形效应。然而，对Cobweb作为人类分类模型的更广泛评估仍然缺乏。本研究填补了这一空白。它确定了Cobweb与经典的人类类别学习效应的一致性。还探讨了Cobweb展现出在单一模型中既有实例又有原型学习的灵活性。这些发现为将来研究Cobweb作为人类类别学习的综合模型奠定了基础。

    arXiv:2403.03835v1 Announce Type: cross  Abstract: Cobweb, a human like category learning system, differs from other incremental categorization models in constructing hierarchically organized cognitive tree-like structures using the category utility measure. Prior studies have shown that Cobweb can capture psychological effects such as the basic level, typicality, and fan effects. However, a broader evaluation of Cobweb as a model of human categorization remains lacking. The current study addresses this gap. It establishes Cobweb's alignment with classical human category learning effects. It also explores Cobweb's flexibility to exhibit both exemplar and prototype like learning within a single model. These findings set the stage for future research on Cobweb as a comprehensive model of human category learning.
    
[^4]: 排列不变函数：统计检验、度量熵中的降维和估计

    Permutation invariant functions: statistical tests, dimension reduction in metric entropy and estimation

    [https://arxiv.org/abs/2403.01671](https://arxiv.org/abs/2403.01671)

    本文研究了如何在多元概率分布中测试排列不变性、估计排列不变密度以及分析排列不变函数类的度量熵，比较了它们与没有排列不变性的函数类的差异。

    

    排列不变性是机器学习中可以利用来简化复杂问题的最常见的对称性之一。近年来关于构建排列不变的机器学习架构的研究活动激增。然而，在多元概率分布中的变量如何统计测试排列不变性却鲜有研究，其中样本量允许随着维数的增长。此外，在统计理论方面，关于排列不变性如何帮助估计中降维的知识甚少。本文通过研究几个基本问题，回顾并探讨这些问题：（i）测试多元分布排列不变性的假设；（ii）估计排列不变密度；（iii）分析光滑排列不变函数类的度量熵，并将其与未强加排列不变性的对应函数类进行比较。

    arXiv:2403.01671v1 Announce Type: new  Abstract: Permutation invariance is among the most common symmetry that can be exploited to simplify complex problems in machine learning (ML). There has been a tremendous surge of research activities in building permutation invariant ML architectures. However, less attention is given to how to statistically test for permutation invariance of variables in a multivariate probability distribution where the dimension is allowed to grow with the sample size. Also, in terms of a statistical theory, little is known about how permutation invariance helps with estimation in reducing dimensions. In this paper, we take a step back and examine these questions in several fundamental problems: (i) testing the assumption of permutation invariance of multivariate distributions; (ii) estimating permutation invariant densities; (iii) analyzing the metric entropy of smooth permutation invariant function classes and compare them with their counterparts without impos
    
[^5]: ICE-SEARCH: 一种基于语言模型驱动的特征选择方法

    ICE-SEARCH: A Language Model-Driven Feature Selection Approach

    [https://arxiv.org/abs/2402.18609](https://arxiv.org/abs/2402.18609)

    ICE-SEARCH是首个将语言模型与进化算法相结合用于特征选择任务的方法，在医学预测分析应用中取得了State-of-the-Art(SOTA)表现。

    

    本研究揭示了In-Context Evolutionary Search (ICE-SEARCH)方法，这是首个将语言模型(LMs)与进化算法相结合用于特征选择(FS)任务的工作，并展示了其在医学预测分析(MPA)应用中的有效性。ICE-SEARCH利用语言模型中固有的交叉和突变能力，在一个进化框架内显着改进特征选择，通过模型的全面世界知识和其适应各种角色的能力。我们对该方法的评估涵盖了三个关键的MPA任务：中风、心血管疾病和糖尿病，在这些任务中ICE-SEARCH在确定医学应用的关键特征方面优于传统的FS方法。ICE-SEARCH在中风预测和糖尿病预测中实现了领先水平；决策随机化ICE-SEARCH在心血管疾病预测中排名为领先水平。我们的结果不仅证明了

    arXiv:2402.18609v1 Announce Type: cross  Abstract: This study unveils the In-Context Evolutionary Search (ICE-SEARCH) method, the first work that melds language models (LMs) with evolutionary algorithms for feature selection (FS) tasks and demonstrates its effectiveness in Medical Predictive Analytics (MPA) applications. ICE-SEARCH harnesses the crossover and mutation capabilities inherent in LMs within an evolutionary framework, significantly improving FS through the model's comprehensive world knowledge and its adaptability to a variety of roles. Our evaluation of this methodology spans three crucial MPA tasks: stroke, cardiovascular disease, and diabetes, where ICE-SEARCH outperforms traditional FS methods in pinpointing essential features for medical applications. ICE-SEARCH achieves State-of-the-Art (SOTA) performance in stroke prediction and diabetes prediction; the Decision-Randomized ICE-SEARCH ranks as SOTA in cardiovascular disease prediction. Our results not only demonstrate
    
[^6]: 基于图提示学习的药物相互作用事件预测：DDIPrompt

    DDIPrompt: Drug-Drug Interaction Event Prediction based on Graph Prompt Learning

    [https://arxiv.org/abs/2402.11472](https://arxiv.org/abs/2402.11472)

    基于图提示学习的DDIPrompt框架旨在解决药物相互作用事件预测中的高度不平衡事件分布和罕见事件标记数据稀缺性问题。

    

    最近，由于其在建模药物分子内部和之间原子和功能团之间复杂关联方面的熟练表现，图神经网络在预测药物相互作用事件（DDI）方面变得日益普遍。然而，它们仍然受到两个重大挑战的制约：（1）高度不平衡事件分布的问题，在医学数据集中这是一个常见但关键的问题，某些相互作用被广泛地低估。这种不平衡对实现准确可靠的DDI预测构成了重大障碍。（2）罕见事件标记数据的稀缺性，在医学领域是一个普遍问题，由于数据有限，往往忽视或研究不足的罕见但潜在关键的相互作用。为此，我们提出了DDIPrompt，这是一种受最近图提示学进展启发的创新良方。我们的框架旨在解决这些问题。

    arXiv:2402.11472v1 Announce Type: cross  Abstract: Recently, Graph Neural Networks have become increasingly prevalent in predicting adverse drug-drug interactions (DDI) due to their proficiency in modeling the intricate associations between atoms and functional groups within and across drug molecules. However, they are still hindered by two significant challenges: (1) the issue of highly imbalanced event distribution, which is a common but critical problem in medical datasets where certain interactions are vastly underrepresented. This imbalance poses a substantial barrier to achieving accurate and reliable DDI predictions. (2) the scarcity of labeled data for rare events, which is a pervasive issue in the medical field where rare yet potentially critical interactions are often overlooked or under-studied due to limited available data. In response, we offer DDIPrompt, an innovative panacea inspired by the recent advancements in graph prompting. Our framework aims to address these issue
    
[^7]: 可扩展大型语言模型微调的差分隐私零阶方法

    Differentially Private Zeroth-Order Methods for Scalable Large Language Model Finetuning

    [https://arxiv.org/abs/2402.07818](https://arxiv.org/abs/2402.07818)

    本文研究了差分隐私零阶方法在大型语言模型微调中的应用，该方法通过使用零阶梯度来避免传统优化方法的可扩展性瓶颈，实现了在隐私、效用和可扩展性之间的良好平衡。

    

    在特定任务的数据集上进行微调是利用预训练语言模型的强大能力进行各种下游任务的广泛接受的范例。由于预训练语言模型微调的普及以及与之相关的隐私问题，差分隐私预训练语言模型微调引起了越来越多的关注，以保护特定任务数据集的隐私。差分隐私预训练语言模型微调方法的设计核心是在隐私、效用和可扩展性之间达到满意的权衡。大多数现有方法都是基于DP-SGD的创新性工作。尽管将DP-SGD的可扩展性推到了极限，但基于DP-SGD的微调方法不幸地受到了SGD固有低效率的限制。在本文中，我们研究了DP零阶方法在LLM预训练中的潜力，该方法通过用更高效的零阶梯度来近似梯度，避免了SGD的可扩展性瓶颈。与将零阶方法作为一种替代方法进行处理不同，我们引入了一种新的割接框架，该框架能够以非常接近的方式模拟DP-SGD的基本操作，然后利用零阶优化方法来近似梯度。

    Finetuning on task-specific datasets is a widely-embraced paradigm of harnessing the powerful capability of pretrained LLMs for various downstream tasks. Due to the popularity of LLMs finetuning and its accompanying privacy concerns, differentially private (DP) finetuning of pretrained LLMs has garnered increasing attention to safeguarding the privacy of task-specific datasets. Lying at the design core of DP LLM finetuning methods is the satisfactory tradeoff between privacy, utility, and scalability. Most existing methods build upon the seminal work of DP-SGD. Despite pushing the scalability of DP-SGD to its limit, DP-SGD-based finetuning methods are unfortunately limited by the inherent inefficiency of SGD. In this paper, we investigate the potential of DP zeroth-order methods for LLM pretraining, which avoids the scalability bottleneck of SGD by approximating the gradient with the more efficient zeroth-order gradient. Rather than treating the zeroth-order method as a drop-in replace
    
[^8]: 使用大型语言模型的多模态临床试验结果预测

    Multimodal Clinical Trial Outcome Prediction with Large Language Models

    [https://arxiv.org/abs/2402.06512](https://arxiv.org/abs/2402.06512)

    本研究提出了一种名为LIFTED的多模态临床试验结果预测方法，通过将不同模态数据转化为自然语言描述来统一数据，并构建统一的抗噪声编码器进行信息提取。

    

    临床试验是一个关键且昂贵的过程，通常需要多年时间和大量财力资源。因此，开发临床试验结果预测模型旨在排除可能失败的药物，并具有显著的成本节约潜力。最近的数据驱动尝试利用深度学习方法整合多模态数据来预测临床试验结果。然而，这些方法依赖于手动设计的模态特定编码器，这限制了适应新模态的可扩展性和识别不同模态之间相似信息模式的能力。为了解决这些问题，我们提出了一种多模态专家混合（LIFTED）方法用于临床试验结果预测。具体而言，LIFTED通过将不同模态的数据转化为自然语言描述来统一不同模态数据。然后，LIFTED构建统一的抗噪声编码器，从模态特定的语言描述中提取信息。

    The clinical trial is a pivotal and costly process, often spanning multiple years and requiring substantial financial resources. Therefore, the development of clinical trial outcome prediction models aims to exclude drugs likely to fail and holds the potential for significant cost savings. Recent data-driven attempts leverage deep learning methods to integrate multimodal data for predicting clinical trial outcomes. However, these approaches rely on manually designed modal-specific encoders, which limits both the extensibility to adapt new modalities and the ability to discern similar information patterns across different modalities. To address these issues, we propose a multimodal mixture-of-experts (LIFTED) approach for clinical trial outcome prediction. Specifically, LIFTED unifies different modality data by transforming them into natural language descriptions. Then, LIFTED constructs unified noise-resilient encoders to extract information from modal-specific language descriptions. S
    
[^9]: Riemann-Lebesgue Forest回归方法的研究

    Riemann-Lebesgue Forest for Regression

    [https://arxiv.org/abs/2402.04550](https://arxiv.org/abs/2402.04550)

    提出了一种新颖的集成方法Riemann-Lebesgue Forest (RLF)用于回归问题，通过划分函数的值域为多个区间来逼近可测函数的思想，开发了一种新的树学习算法Riemann-Lebesgue Tree。通过Hoeffding分解和Stein方法推导了RLF在不同参数设置下的渐近性能，并在仿真数据和真实世界数据集上的实验中证明了RLF与原始随机森林相比具有竞争力的性能。

    

    我们提出了一种新颖的用于回归问题的集成方法，称为Riemann-Lebesgue Forest (RLF)。RLF的核心思想是通过将函数的值域划分为几个区间来模拟可测函数的逼近方式。基于这个思想，我们开发了一种新的树学习算法，称为Riemann-Lebesgue Tree，它在每个非叶节点上有机会从响应Y或特征空间X中的方向进行切割。我们通过Hoeffding分解和Stein方法来推导不同参数设置下RLF的渐近性能。当底层函数Y=f(X)遵循加法回归模型时，RLF与Scornet等人的论证（2014年）保持一致。通过在仿真数据和真实世界数据集上的实验证明，RLF与原始随机森林相比具有竞争力的性能。

    We propose a novel ensemble method called Riemann-Lebesgue Forest (RLF) for regression. The core idea of RLF is to mimic the way how a measurable function can be approximated by partitioning its range into a few intervals. With this idea in mind, we develop a new tree learner named Riemann-Lebesgue Tree which has a chance to split the node from response $Y$ or a direction in feature space $\mathbf{X}$ at each non-terminal node. We generalize the asymptotic performance of RLF under different parameter settings mainly through Hoeffding decomposition \cite{Vaart} and Stein's method \cite{Chen2010NormalAB}. When the underlying function $Y=f(\mathbf{X})$ follows an additive regression model, RLF is consistent with the argument from \cite{Scornet2014ConsistencyOR}. The competitive performance of RLF against original random forest \cite{Breiman2001RandomF} is demonstrated by experiments in simulation data and real world datasets.
    
[^10]: GD无法胜任：非可微性对神经网络训练的三种影响方式

    GD doesn't make the cut: Three ways that non-differentiability affects neural network training

    [https://arxiv.org/abs/2401.08426](https://arxiv.org/abs/2401.08426)

    本文研究了非可微性对神经网络训练的影响，包括收敛性差异、$L_1$正则化问题的矛盾性质以及稳定边界现象的不适用性。

    

    本文研究了应用于非可微函数（NGDMs）和应用于可微函数的传统梯度下降（GDs）之间的区别。首先，我们证明了NGDMs的收敛性质与GDs存在显著差异，挑战了基于$L$-光滑性的广泛神经网络收敛文献对非光滑神经网络的适用性。接下来，我们展示了NGDM解决$L_1$正则化问题的矛盾性质，表明增加正则化惩罚会导致NGDMs中最优解的$L_1$范数增加。因此，我们证明了广泛采用的基于$L_1$惩罚的网络修剪技术并未产生预期结果。最后，我们探索了稳定边界现象（Edge of Stability），指出即使对于Lipschitz连续凸可微函数，它也不适用于非凸非可微的神经网络。

    This paper investigates the distinctions between gradient methods applied to non-differentiable functions (NGDMs) and classical gradient descents (GDs) designed for differentiable functions. First, we demonstrate significant differences in the convergence properties of NGDMs compared to GDs, challenging the applicability of the extensive neural network convergence literature based on $L-smoothness$ to non-smooth neural networks. Next, we demonstrate the paradoxical nature of NGDM solutions for $L_{1}$-regularized problems, showing that increasing the regularization penalty leads to an increase in the $L_{1}$ norm of optimal solutions in NGDMs. Consequently, we show that widely adopted $L_{1}$ penalization-based techniques for network pruning do not yield expected results. Finally, we explore the Edge of Stability phenomenon, indicating its inapplicability even to Lipschitz continuous convex differentiable functions, leaving its relevance to non-convex non-differentiable neural networks
    
[^11]: 使用回声状态网络的多智能体强化学习及其在行人动态中的应用

    Multi-agent reinforcement learning using echo-state network and its application to pedestrian dynamics

    [https://arxiv.org/abs/2312.11834](https://arxiv.org/abs/2312.11834)

    通过使用回声状态网络将行人实现为MARL代理，研究了他们学习避让其他代理向前移动的能力，在密度不太高的情况下取得成功。

    

    近年来，研究使用多智能体强化学习（MARL）模拟行人。本研究考虑了网格世界环境中的道路，并将行人实现为使用回声状态网络和最小二乘策略迭代方法的MARL代理。在这个环境下，研究了这些代理学习避开其他代理向前移动的能力。具体而言，我们考虑了两种任务：窄直接路径和宽绕道之间的选择，以及走廊中的双向行人流。模拟结果表明，当代理密度不太高时，学习是成功的。

    arXiv:2312.11834v2 Announce Type: replace-cross  Abstract: In recent years, simulations of pedestrians using the multi-agent reinforcement learning (MARL) have been studied. This study considered the roads on a grid-world environment, and implemented pedestrians as MARL agents using an echo-state network and the least squares policy iteration method. Under this environment, the ability of these agents to learn to move forward by avoiding other agents was investigated. Specifically, we considered two types of tasks: the choice between a narrow direct route and a broad detour, and the bidirectional pedestrian flow in a corridor. The simulations results indicated that the learning was successful when the density of the agents was not that high.
    
[^12]: 大型人类语言模型：需求和挑战

    Large Human Language Models: A Need and the Challenges

    [https://arxiv.org/abs/2312.07751](https://arxiv.org/abs/2312.07751)

    大型人类语言模型的建立需要更好地整合人类背景，并面临着如何捕捉人类因素、如何表示以及如何建模的一系列挑战。

    

    随着人类中心的自然语言处理研究的进展，人们越来越意识到将人类和社会因素纳入到自然语言处理模型的重要性。同时，我们的自然语言处理系统已经严重依赖于LLM，其中大多数并没有对作者进行建模。为了构建能够真正理解人类语言的自然语言处理系统，我们必须更好地将人类背景整合到LLM中。这提出了一系列设计考虑和挑战，涉及到要捕捉哪些人类因素、如何表示它们以及要采用何种建模策略等问题。为了应对这些挑战，我们提倡从心理学和行为科学的概念出发，支持三个立场来创建大型人类语言模型（LHLMs）：首先，语言模型训练应包括人类背景。其次，LHLMs应该意识到人不仅仅是他们所属的群体。第三，LHLMs应该能够考虑到人类背景的动态和时间依赖性特点。

    arXiv:2312.07751v2 Announce Type: replace-cross  Abstract: As research in human-centered NLP advances, there is a growing recognition of the importance of incorporating human and social factors into NLP models. At the same time, our NLP systems have become heavily reliant on LLMs, most of which do not model authors. To build NLP systems that can truly understand human language, we must better integrate human contexts into LLMs. This brings to the fore a range of design considerations and challenges in terms of what human aspects to capture, how to represent them, and what modeling strategies to pursue. To address these, we advocate for three positions toward creating large human language models (LHLMs) using concepts from psychological and behavioral sciences: First, LM training should include the human context. Second, LHLMs should recognize that people are more than their group(s). Third, LHLMs should be able to account for the dynamic and temporally-dependent nature of the human con
    
[^13]: 带有随机路径投影方向的切片瓦瑟斯坦方法

    Sliced Wasserstein with Random-Path Projecting Directions. (arXiv:2401.15889v1 [stat.ML])

    [http://arxiv.org/abs/2401.15889](http://arxiv.org/abs/2401.15889)

    本研究提出了一种无需优化的切片分布方法，该方法能够快速进行蒙特卡洛期望估计。通过利用随机向量之间的归一化差异构建随机路径投影方向，从而得到了随机路径切片分布和两个切片瓦瑟斯坦的变种。这种方法在拓扑、统计和计算性质上有重要意义。

    

    在应用中，切片分布选择已被用作提高基于最小化切片瓦瑟斯坦距离的参数估计器性能的有效技术。先前的工作要么利用昂贵的优化来选择切片分布，要么使用需要昂贵的抽样方法的切片分布。在这项工作中，我们提出了一种无需优化的切片分布，可以快速进行蒙特卡洛期望估计的抽样。具体来说，我们引入了随机路径投影方向（RPD），它是通过利用两个输入测量中两个随机向量之间的归一化差异构建的。从RPD中，我们得到了随机路径切片分布（RPSD）和两个切片瓦瑟斯坦的变种，即随机路径投影切片瓦瑟斯坦（RPSW）和重要性加权随机路径投影切片瓦瑟斯坦（IWRPSW）。然后我们讨论了拓扑、统计和计算性质。

    Slicing distribution selection has been used as an effective technique to improve the performance of parameter estimators based on minimizing sliced Wasserstein distance in applications. Previous works either utilize expensive optimization to select the slicing distribution or use slicing distributions that require expensive sampling methods. In this work, we propose an optimization-free slicing distribution that provides a fast sampling for the Monte Carlo estimation of expectation. In particular, we introduce the random-path projecting direction (RPD) which is constructed by leveraging the normalized difference between two random vectors following the two input measures. From the RPD, we derive the random-path slicing distribution (RPSD) and two variants of sliced Wasserstein, i.e., the Random-Path Projection Sliced Wasserstein (RPSW) and the Importance Weighted Random-Path Projection Sliced Wasserstein (IWRPSW). We then discuss the topological, statistical, and computational propert
    
[^14]: TIM: 一种高效的时间交互模块用于脉冲变压器

    TIM: An Efficient Temporal Interaction Module for Spiking Transformer. (arXiv:2401.11687v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2401.11687](http://arxiv.org/abs/2401.11687)

    TIM 是一种高效的时间交互模块，用于增强脉冲神经网络 (SNNs) 的时间数据处理能力。

    

    脉冲神经网络 (SNNs) 作为第三代神经网络，因其生物合理性和计算效率而备受关注，尤其是在处理多样化数据集方面。受神经网络架构进展的启发，注意力机制的整合导致了脉冲变压器的发展。这些变压器在增强 SNNs 的能力方面显示了潜力，尤其是在静态数据集和神经形态数据集的领域。尽管取得了进展，但这些系统中存在着明显的差距，特别是脉冲自注意 (SSA) 机制在利用 SNNs 的时间处理潜力方面的有效性。为了解决这个问题，我们引入了一种名为 Temporal Interaction Module (TIM) 的新型卷积增强技术，旨在增强 SNN 架构中的时间数据处理能力。TIM 的整合与现有的 SNN 框架无缝衔接，高效，只需要额外的最少参数。

    Spiking Neural Networks (SNNs), as the third generation of neural networks, have gained prominence for their biological plausibility and computational efficiency, especially in processing diverse datasets. The integration of attention mechanisms, inspired by advancements in neural network architectures, has led to the development of Spiking Transformers. These have shown promise in enhancing SNNs' capabilities, particularly in the realms of both static and neuromorphic datasets. Despite their progress, a discernible gap exists in these systems, specifically in the Spiking Self Attention (SSA) mechanism's effectiveness in leveraging the temporal processing potential of SNNs. To address this, we introduce the Temporal Interaction Module (TIM), a novel, convolution-based enhancement designed to augment the temporal data processing abilities within SNN architectures. TIM's integration into existing SNN frameworks is seamless and efficient, requiring minimal additional parameters while sign
    
[^15]: 使用参数化操作原语学习外在灵巧性

    Learning Extrinsic Dexterity with Parameterized Manipulation Primitives. (arXiv:2310.17785v1 [cs.RO])

    [http://arxiv.org/abs/2310.17785](http://arxiv.org/abs/2310.17785)

    论文通过学习一系列参数化操作原语，并利用环境改变物体姿态，解决了机器人在目标物体抓取被环境遮挡时的问题。

    

    许多实际相关的机器人抓取问题都涉及到目标物体，其所有抓取都被环境遮挡。在这种情况下，单次抓取计划总是失败的。因此，有必要首先将物体操作到一个适合进行抓取的配置。我们通过学习一系列利用环境改变物体姿态的动作来解决这个问题。具体而言，我们利用分层强化学习来结合一系列学习到的参数化操作原语。通过学习低级操作策略，我们的方法可以通过利用物体、夹具和环境之间的相互作用来控制物体的状态。在无控制条件下分析设计这样一个复杂行为是不可行的，因为分析方法需要准确建模互动和接触动力学。相反，我们学习一个在深度图像上直接操作的分层策略模型。

    Many practically relevant robot grasping problems feature a target object for which all grasps are occluded, e.g., by the environment. Single-shot grasp planning invariably fails in such scenarios. Instead, it is necessary to first manipulate the object into a configuration that affords a grasp. We solve this problem by learning a sequence of actions that utilize the environment to change the object's pose. Concretely, we employ hierarchical reinforcement learning to combine a sequence of learned parameterized manipulation primitives. By learning the low-level manipulation policies, our approach can control the object's state through exploiting interactions between the object, the gripper, and the environment. Designing such a complex behavior analytically would be infeasible under uncontrolled conditions, as an analytic approach requires accurate physical modeling of the interaction and contact dynamics. In contrast, we learn a hierarchical policy model that operates directly on depth
    
[^16]: 融合具有互补专长的模型

    Fusing Models with Complementary Expertise. (arXiv:2310.01542v1 [cs.LG])

    [http://arxiv.org/abs/2310.01542](http://arxiv.org/abs/2310.01542)

    该论文研究了融合具有互补专长的模型的问题，并将其应用于不同任务和领域中，通过监督学习的方式实现了显著的性能提升。

    

    训练能够在不同任务和领域中进行泛化的AI模型一直是推动AI研究的开放问题之一。基础模型的出现使得获得特定任务的专家模型变得更加容易，但是在测试时可能会遇到的数据的异质性意味着任何单个专家都不足够。我们考虑融合专家模型输出的Fusion of Experts（FoE）问题，这些专家模型具有对数据分布的互补知识，并将其形式化为监督学习的一个实例。我们的方法适用于判别任务和生成任务，并在图像和文本分类、文本摘要、多项选择问答和生成文本自动评估等方面取得了显著的性能提升。我们还将我们的方法扩展到“节俭”设置，即希望在测试时减少专家模型的评估次数。

    Training AI models that generalize across tasks and domains has long been among the open problems driving AI research. The emergence of Foundation Models made it easier to obtain expert models for a given task, but the heterogeneity of data that may be encountered at test time often means that any single expert is insufficient. We consider the Fusion of Experts (FoE) problem of fusing outputs of expert models with complementary knowledge of the data distribution and formulate it as an instance of supervised learning. Our method is applicable to both discriminative and generative tasks and leads to significant performance improvements in image and text classification, text summarization, multiple-choice QA, and automatic evaluation of generated text. We also extend our method to the "frugal" setting where it is desired to reduce the number of expert model evaluations at test time.
    
[^17]: 在格点场论中，扩散模型作为随机量子化的实现

    Diffusion Models as Stochastic Quantization in Lattice Field Theory. (arXiv:2309.17082v1 [hep-lat])

    [http://arxiv.org/abs/2309.17082](http://arxiv.org/abs/2309.17082)

    该研究通过将生成性扩散模型与随机量子化相连接，证明了生成性扩散模型在随机量子化中的应用。数值模拟表明，生成性扩散模型可以作为全局采样器用于生成量子格点场配置，并可以显著减少马尔可夫链的自相关时间。

    

    本研究建立了生成性扩散模型（DM）和随机量子化（SQ）之间的直接联系。通过近似满足Langevin方程的随机过程的反演，生成符合目标分布的样本来实现DM。通过数值模拟，我们证明DM可以作为全局采样器来生成二维$\phi^4$理论中的量子格点场配置。我们证明DM可以显著减少马尔科夫链的自相关时间，特别是在标准马尔可夫链蒙特卡洛（MCMC）算法在临界区域遇到临界减慢时。这些发现有望在格点场论模拟中激发进一步的进展，特别是在生成大型数据集昂贵的情况下。

    In this work, we establish a direct connection between generative diffusion models (DMs) and stochastic quantization (SQ). The DM is realized by approximating the reversal of a stochastic process dictated by the Langevin equation, generating samples from a prior distribution to effectively mimic the target distribution. Using numerical simulations, we demonstrate that the DM can serve as a global sampler for generating quantum lattice field configurations in two-dimensional $\phi^4$ theory. We demonstrate that DMs can notably reduce autocorrelation times in the Markov chain, especially in the critical region where standard Markov Chain Monte-Carlo (MCMC) algorithms experience critical slowing down. The findings can potentially inspire further advancements in lattice field theory simulations, in particular in cases where it is expensive to generate large ensembles.
    
[^18]: ScatterUQ: 用于多类别深度学习问题的交互式不确定性可视化

    ScatterUQ: Interactive Uncertainty Visualizations for Multiclass Deep Learning Problems. (arXiv:2308.04588v1 [cs.LG])

    [http://arxiv.org/abs/2308.04588](http://arxiv.org/abs/2308.04588)

    ScatterUQ是一个交互式系统，通过可视化展示模型在上下文驱动的不确定性设置下的性能，为用户提供了更好的理解模型预测的能力。

    

    最近，针对多类别标签问题开发了一种不确定性感知的深度学习方法，提供了校准的类别预测概率和超出分布指示器，使得机器学习的使用者和工程师可以评估模型对其预测的信心。然而，这种额外的神经网络预测信息在多个不确定性环境下对任意数据源进行可视化传达具有挑战性。为了解决这些挑战，我们提出了ScatterUQ，这是一个交互式系统，提供有针对性的可视化，让用户能够更好地理解模型在上下文驱动的不确定性设置下的性能。

    Recently, uncertainty-aware deep learning methods for multiclass labeling problems have been developed that provide calibrated class prediction probabilities and out-of-distribution (OOD) indicators, letting machine learning (ML) consumers and engineers gauge a model's confidence in its predictions. However, this extra neural network prediction information is challenging to scalably convey visually for arbitrary data sources under multiple uncertainty contexts. To address these challenges, we present ScatterUQ, an interactive system that provides targeted visualizations to allow users to better understand model performance in context-driven uncertainty settings. ScatterUQ leverages recent advances in distance-aware neural networks, together with dimensionality reduction techniques, to construct robust, 2-D scatter plots explaining why a model predicts a test example to be (1) in-distribution and of a particular class, (2) in-distribution but unsure of the class, and (3) out-of-distribu
    
[^19]: 多模态多损失融合网络

    Multi-Modality Multi-Loss Fusion Network. (arXiv:2308.00264v1 [cs.CL])

    [http://arxiv.org/abs/2308.00264](http://arxiv.org/abs/2308.00264)

    多模态多损失融合网络通过最佳选择和融合多个模态的特征，提高了情感检测的性能，并在多个数据集上实现了最先进的结果。这些研究结果表明了用于增强神经网络中情感检测的特征选择和融合方法的优化方向。

    

    在这项工作中，我们研究了跨多个模态选择和融合特征的最佳方法，并将其组合在神经网络中以改善情感检测。我们比较了不同的融合方法并且研究了多损失训练在多模态融合网络中的影响，从而确定了与子网性能相关的有用发现。我们最好的模型在三个数据集（CMU-MOSI、CMU-MOSEI和CH-SIMS）上实现了最先进的性能，并且在大多数指标上优于其他方法。我们发现，训练多模态特征可以改善单模态测试，并且基于数据集注释模式设计融合方法可以增强模型性能。这些结果表明了在神经网络中增强情感检测的优化特征选择和融合方法的发展方向。

    In this work we investigate the optimal selection and fusion of features across multiple modalities and combine these in a neural network to improve emotion detection. We compare different fusion methods and examine the impact of multi-loss training within the multi-modality fusion network, identifying useful findings relating to subnet performance. Our best model achieves state-of-the-art performance for three datasets (CMU-MOSI, CMU-MOSEI and CH-SIMS), and outperforms the other methods in most metrics. We have found that training on multimodal features improves single modality testing and designing fusion methods based on dataset annotation schema enhances model performance. These results suggest a roadmap towards an optimized feature selection and fusion approach for enhancing emotion detection in neural networks.
    
[^20]: 在大型语言模型中的上下文压缩的上下文自编码器

    In-context Autoencoder for Context Compression in a Large Language Model. (arXiv:2307.06945v1 [cs.CL])

    [http://arxiv.org/abs/2307.06945](http://arxiv.org/abs/2307.06945)

    在大型语言模型中，我们提出了一种称为In-context Autoencoder (ICAE)的上下文自编码器，它通过将长上下文压缩为有限数量的内存槽，实现了$4\times$的上下文压缩，并能够根据内存槽进行条件处理以响应各种提示。

    

    我们提出了一种用于大型语言模型中上下文压缩的上下文自编码器（ICAE）。 ICAE有两个模块：一个可学习的编码器，通过从LLM中采用LoRA方式将长上下文压缩为有限数量的内存槽，以及一个固定的解码器，作为目标LLM，可以根据内存槽来进行各种目的的条件处理。我们首先使用自编码和语言建模目标在大规模文本数据上预训练ICAE，使其能够生成准确和全面表示原始上下文的内存槽。然后，我们使用少量指导数据对预训练的ICAE进行微调，以增强其与各种提示的交互，从而产生理想的响应。我们的实验结果表明，使用我们提出的预训练和微调范式学习的ICAE可以有效地产生$4\times$上下文压缩的内存槽，目标LLM可以很好地对其进行条件处理，以响应各种提示。

    We propose the In-context Autoencoder (ICAE) for context compression in a large language model (LLM). The ICAE has two modules: a learnable encoder adapted with LoRA from an LLM for compressing a long context into a limited number of memory slots, and a fixed decoder which is the target LLM that can condition on the memory slots for various purposes. We first pretrain the ICAE using both autoencoding and language modeling objectives on massive text data, enabling it to generate memory slots that accurately and comprehensively represent the original context. Then, we fine-tune the pretrained ICAE on a small amount of instruct data to enhance its interaction with various prompts for producing desirable responses. Our experimental results demonstrate that the ICAE learned with our proposed pretraining and fine-tuning paradigm can effectively produce memory slots with $4\times$ context compression, which can be well conditioned on by the target LLM to respond to various prompts. The promis
    
[^21]: 利用对比学习预测癌症预后的基因表达值

    Contrastive Learning for Predicting Cancer Prognosis Using Gene Expression Values. (arXiv:2306.06276v1 [cs.LG])

    [http://arxiv.org/abs/2306.06276](http://arxiv.org/abs/2306.06276)

    该论文提出应用对比学习方法，从有限的数据样本中学习基因表达数据的良好特征表示，并应用于Cox模型中，可以显著提高癌症预后的预测性能。

    

    最近开发了多种人工神经网络（ANNs）作为Cox比例风险模型，以基于肿瘤转录组预测癌症预后。然而，它们并没有表现出比传统有规则化的Cox回归显着更好的性能。在有限数量的数据样本和高维特征空间存在的情况下，训练具有高预测能力的ANN是具有挑战性的。图像分类的最新进展表明，对比学习可以通过从有限数量的数据样本中学习良好的特征表示来促进进一步的学习任务。在本文中，我们将监督对比学习应用于肿瘤基因表达和临床数据，以在低维空间中学习特征表示。然后，我们使用这些学习到的特征来训练Cox模型，以预测癌症预后。使用来自The Cancer Genome Atlas（TCGA）的数据，我们证明了我们基于对比学习的Cox模型能够通过学习基因表达数据的良好特征表征，显著提高癌症预后预测的性能。

    Several artificial neural networks (ANNs) have recently been developed as the Cox proportional hazard model for predicting cancer prognosis based on tumor transcriptome. However, they have not demonstrated significantly better performance than the traditional Cox regression with regularization. Training an ANN with high prediction power is challenging in the presence of a limited number of data samples and a high-dimensional feature space. Recent advancements in image classification have shown that contrastive learning can facilitate further learning tasks by learning good feature representation from a limited number of data samples. In this paper, we applied supervised contrastive learning to tumor gene expression and clinical data to learn feature representations in a low-dimensional space. We then used these learned features to train the Cox model for predicting cancer prognosis. Using data from The Cancer Genome Atlas (TCGA), we demonstrated that our contrastive learning-based Cox 
    
[^22]: COURIER: 基于对比学习的大规模图像特征预训练中的用户意图还原

    COURIER: Contrastive User Intention Reconstruction for Large-Scale Pre-Train of Image Features. (arXiv:2306.05001v1 [cs.CV])

    [http://arxiv.org/abs/2306.05001](http://arxiv.org/abs/2306.05001)

    该论文提出了一种基于对比学习的推荐方法，以获得更好的个性化推荐表现。

    

    随着多媒体互联网的发展，视觉特征已成为影响用户兴趣的重要因素。因此，将视觉特征融入点击率（CTR）预测的进一步提升方向是颇具前景的。但我们发现，仅将已有预训练方法训练得到的图像嵌入注入到模型中仅能产生较小的改进。我们将这种现象归因于以下两个原因：首先，预训练方法是为了明确的、重点放在语义特征上的计算机视觉任务而设计的，无法学习到个性化推荐中的个人兴趣; 其次，预训练的只包含语义信息的图像嵌入与我们在CTR预测任务中所已有的类别和物品标题等语义特征相比有较小的信息增益。我们认为需要一种针对推荐任务的预训练方法以获得更多改进。为此，我们提出了一种基于对比学习的推荐方法。

    With the development of the multi-media internet, visual characteristics have become an important factor affecting user interests. Thus, incorporating visual features is a promising direction for further performance improvements in click-through rate (CTR) prediction. However, we found that simply injecting the image embeddings trained with established pre-training methods only has marginal improvements. We attribute the failure to two reasons: First, The pre-training methods are designed for well-defined computer vision tasks concentrating on semantic features, and they cannot learn personalized interest in recommendations. Secondly, pre-trained image embeddings only containing semantic information have little information gain, considering we already have semantic features such as categories and item titles as inputs in the CTR prediction task. We argue that a pre-training method tailored for recommendation is necessary for further improvements. To this end, we propose a recommendatio
    
[^23]: DiffusionShield：一种针对生成式扩散模型的版权保护数字水印方法

    DiffusionShield: A Watermark for Copyright Protection against Generative Diffusion Models. (arXiv:2306.04642v1 [cs.CR])

    [http://arxiv.org/abs/2306.04642](http://arxiv.org/abs/2306.04642)

    本文提出了一种针对生成式扩散模型的版权保护数字水印方法DiffusionShield，保护图像免受侵权，简单易学，难以检测，可广泛应用于各行各业。

    

    近来，生成式扩散模型(GDMs)在学习和生成图像方面展示了其卓越的能力。大量的GDMs社区自然而然地出现，并促进了GDMs在各个领域的多样化应用。然而，这种无限制的扩散引起了有关版权保护的严重关注。例如，艺术家(包括画家和摄影师)越来越担心GDMs可以毫不费力地复制他们独特的创意作品而无需授权。为了应对这些挑战，我们介绍了一种针对GDMs量身定制的新型水印方案——DiffusionShield。通过将所有权信息编码成一个不可察觉的水印并将其注入图像中，DiffusionShield保护图像免受GDMs侵权。它的水印可以被GDMs轻松地学习并重现在它们生成的图像中。通过从生成的图像中检测水印，可以揭露版权侵权行为。

    Recently, Generative Diffusion Models (GDMs) have showcased their remarkable capabilities in learning and generating images. A large community of GDMs has naturally emerged, further promoting the diversified applications of GDMs in various fields. However, this unrestricted proliferation has raised serious concerns about copyright protection. For example, artists including painters and photographers are becoming increasingly concerned that GDMs could effortlessly replicate their unique creative works without authorization. In response to these challenges, we introduce a novel watermarking scheme, DiffusionShield, tailored for GDMs. DiffusionShield protects images from copyright infringement by GDMs through encoding the ownership information into an imperceptible watermark and injecting it into the images. Its watermark can be easily learned by GDMs and will be reproduced in their generated images. By detecting the watermark from generated images, copyright infringement can be exposed w
    
[^24]: 使用代理人群体学习序列任务的嵌入

    Learning Embeddings for Sequential Tasks Using Population of Agents. (arXiv:2306.03311v1 [cs.LG])

    [http://arxiv.org/abs/2306.03311](http://arxiv.org/abs/2306.03311)

    该研究基于代理人群体提出了一个信息理论框架，用于在强化学习任务中学习固定维度的嵌入，可以通过观察代理在一小组任务上的表现，来预测其在测试任务上的表现，并且可以从给定的任务选项中选择具有所需特征的任务。

    

    我们提出了一个信息理论框架，用于在强化学习任务中学习固定维度的嵌入。我们利用这样的想法：如果观察一个代理在一个任务上的表现减少了我们关于他在另一个任务上表现的不确定性，那么两个任务就相似。我们的信息理论准则捕捉了这种直觉，使用多样化的代理人群体来测量序列决策环境中任务之间的相似性。除了定性评估，我们还通过对两个应用场景进行量化比较，基于任务嵌入展示了我们技术的有效性：通过观察代理在一小组任务上的表现，来预测其在测试任务上的表现；从给定的任务选项中选择具有所需特征的任务。

    We present an information-theoretic framework to learn fixed-dimensional embeddings for tasks in reinforcement learning. We leverage the idea that two tasks are similar to each other if observing an agent's performance on one task reduces our uncertainty about its performance on the other. This intuition is captured by our information-theoretic criterion which uses a diverse population of agents to measure similarity between tasks in sequential decision-making settings. In addition to qualitative assessment, we empirically demonstrate the effectiveness of our techniques based on task embeddings by quantitative comparisons against strong baselines on two application scenarios: predicting an agent's performance on a test task by observing its performance on a small quiz of tasks, and selecting tasks with desired characteristics from a given set of options.
    
[^25]: 基于独立因果机制原则学习因果解缠绕表示

    Learning Causally Disentangled Representations via the Principle of Independent Causal Mechanisms. (arXiv:2306.01213v1 [cs.LG])

    [http://arxiv.org/abs/2306.01213](http://arxiv.org/abs/2306.01213)

    本文通过定义独立因果机制，提出了ICM-VAE框架，使得学习因果解缠绕表示更准确

    

    学习解缠绕的因果表示是一个具有挑战性的问题，近年来因其对提取下游任务的有意义信息而引起了广泛关注。本文从独立因果机制的角度定义了一种新的因果解缠绕概念。我们提出了ICM-VAE框架，通过因因果关系观察标签来监督学习因果解缠绕表示。我们使用可学习的基于流的微分同胚函数将噪声变量映射到潜在因果变量中来建模因果机制。此外，为了促进因果要素的解缠绕，我们提出了一种因果解缠绕先验，利用已知的因果结构来鼓励在潜在空间中学习因果分解分布。在相对温和的条件下，我们提供了理论结果，显示了因果要素和机制的可识别性，直到排列和逐元重参数化的限度。我们进行了实证研究...

    Learning disentangled causal representations is a challenging problem that has gained significant attention recently due to its implications for extracting meaningful information for downstream tasks. In this work, we define a new notion of causal disentanglement from the perspective of independent causal mechanisms. We propose ICM-VAE, a framework for learning causally disentangled representations supervised by causally related observed labels. We model causal mechanisms using learnable flow-based diffeomorphic functions to map noise variables to latent causal variables. Further, to promote the disentanglement of causal factors, we propose a causal disentanglement prior that utilizes the known causal structure to encourage learning a causally factorized distribution in the latent space. Under relatively mild conditions, we provide theoretical results showing the identifiability of causal factors and mechanisms up to permutation and elementwise reparameterization. We empirically demons
    
[^26]: 通过损失压缩分析深度神经网络的信息瓶颈(arXiv:2305.08013v1 [cs.LG])

    Information Bottleneck Analysis of Deep Neural Networks via Lossy Compression. (arXiv:2305.08013v1 [cs.LG])

    [http://arxiv.org/abs/2305.08013](http://arxiv.org/abs/2305.08013)

    本文提出了一种综合框架，用于对一般神经网络进行信息瓶颈分析，以研究训练过程中的拟合和压缩阶段。通过该分析，可以更好地理解深度神经网络的泛化能力。

    

    信息瓶颈原理提供了一个信息论框架，用于分析深度神经网络(DNNs)的训练过程。其核心在于跟踪隐藏层与类标签之间的互信息值和隐藏层与DNN输入之间的互信息值的动态变化。据Shwartz-Ziv和Tishby(2017)提出的假说，训练过程由两个不同的阶段组成:拟合和压缩。后者被认为是DNNs表现良好的泛化能力的原因。本文引入了一个综合框架，用于进行对一般NNs的IB分析。我们的方法利用了Goldfeld等人(2019)提出的随机神经网络方法，并结合了一种压缩方法。

    The Information Bottleneck (IB) principle offers an information-theoretic framework for analyzing the training process of deep neural networks (DNNs). Its essence lies in tracking the dynamics of two mutual information (MI) values: one between the hidden layer and the class label, and the other between the hidden layer and the DNN input. According to the hypothesis put forth by Shwartz-Ziv and Tishby (2017), the training process consists of two distinct phases: fitting and compression. The latter phase is believed to account for the good generalization performance exhibited by DNNs. Due to the challenging nature of estimating MI between high-dimensional random vectors, this hypothesis has only been verified for toy NNs or specific types of NNs, such as quantized NNs and dropout NNs. In this paper, we introduce a comprehensive framework for conducting IB analysis of general NNs. Our approach leverages the stochastic NN method proposed by Goldfeld et al. (2019) and incorporates a compres
    
[^27]: 校准混乱：神经网络训练的运行变化在无意中且无害

    Calibrated Chaos: Variance Between Runs of Neural Network Training is Harmless and Inevitable. (arXiv:2304.01910v1 [cs.LG])

    [http://arxiv.org/abs/2304.01910](http://arxiv.org/abs/2304.01910)

    神经网络训练的运行变化在实际中更少遇到问题，我们提出了一种简化的统计假设并证明方差主要由于训练过程对初始条件的高敏感性所导致。

    

    典型的神经网络训练在重复测试时会有显著的测试集性能差异，影响模型超参数的比较和训练的可重复性。本文通过以下比较来解释这种变化：（1）尽管在测试集上有显著的方差，但标准的CIFAR-10与ImageNet训练在测试分布上的表现却非常一致，这表明方差不像之前想象的那么严重。（2）我们提出了一种简化的统计假设，以紧密近似测试集准确性分布结构。（3）我们认为，在以下两个意义上，测试集方差是不可避免的。首先，我们展示了方差主要是由于训练过程对初始条件的高敏感性而不是特定的随机源（如数据排序和扩充）所导致的。其次，我们证明了方差是频率极限的，但可以通过训练多个模型来减少。

    Typical neural network trainings have substantial variance in test-set performance between repeated runs, impeding hyperparameter comparison and training reproducibility. We present the following results towards understanding this variation. (1) Despite having significant variance on their test-sets, we demonstrate that standard CIFAR-10 and ImageNet trainings have very little variance in their performance on the test-distributions from which those test-sets are sampled, suggesting that variance is less of a practical issue than previously thought. (2) We present a simplifying statistical assumption which closely approximates the structure of the test-set accuracy distribution. (3) We argue that test-set variance is inevitable in the following two senses. First, we show that variance is largely caused by high sensitivity of the training process to initial conditions, rather than by specific sources of randomness like the data order and augmentations. Second, we prove that variance is u
    
[^28]: 一种针对合成数据的属性推断攻击的线性重构方法

    A Linear Reconstruction Approach for Attribute Inference Attacks against Synthetic Data. (arXiv:2301.10053v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.10053](http://arxiv.org/abs/2301.10053)

    本研究提出一种新的属性推断攻击方法，针对合成数据中所有记录，具有高度的准确率和危害性。

    

    最近合成数据生成（SDG）的发展被誉为共享敏感数据和保护隐私的难题的解决方案。SDG旨在学习真实数据的统计属性，生成结构和统计学相似的“人造”数据。然而，先前的研究表明，对合成数据的推论攻击可能会破坏隐私，但仅适用于特定的异常记录。本研究引入了一种新的针对合成数据的属性推断攻击。该攻击基于线性重构方法用于聚合统计数据，攻击目标不仅仅是异常值，而是整个数据集中的所有记录。我们评估了我们的攻击对最先进的SDG算法的影响，包括概率图模型，生成式对抗网络和最近的差分隐私SDG机制。通过定义形式化的隐私博弈，我们展示了我们的攻击甚至对任意记录都可以高度精确，并且这是攻击的结果。

    Recent advances in synthetic data generation (SDG) have been hailed as a solution to the difficult problem of sharing sensitive data while protecting privacy. SDG aims to learn statistical properties of real data in order to generate "artificial" data that are structurally and statistically similar to sensitive data. However, prior research suggests that inference attacks on synthetic data can undermine privacy, but only for specific outlier records. In this work, we introduce a new attribute inference attack against synthetic data. The attack is based on linear reconstruction methods for aggregate statistics, which target all records in the dataset, not only outliers. We evaluate our attack on state-of-the-art SDG algorithms, including Probabilistic Graphical Models, Generative Adversarial Networks, and recent differentially private SDG mechanisms. By defining a formal privacy game, we show that our attack can be highly accurate even on arbitrary records, and that this is the result o
    
[^29]: 带外部记忆的多模态动态连续学习

    Continual Learning of Multi-modal Dynamics with External Memory. (arXiv:2203.00936v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.00936](http://arxiv.org/abs/2203.00936)

    本文提出了一种新的连续学习方法，通过在记忆中维护遇到序列模式的描述符来实现，能够有效处理新的行为模式的连续出现。

    

    本文研究了在新的行为模式连续出现时，如何将模型拟合到动态环境中。学习模型能够意识到新的模式出现，但它没有访问单个训练序列的真实模式的信息。目前的连续学习方法无法处理这种情况，因为参数传递受到灾难性干扰的影响，而情节记忆设计需要知道序列的真实模式。我们设计了一种新的连续学习方法，通过在神经情节记忆中维护遇到的序列模式的描述符来克服这两个限制。我们在记忆的注意权重上使用Dirichlet过程先验，以促进模式描述符的有效存储。通过检索先前任务相似模式的描述符，并将此描述符馈入其转移中，我们的方法通过在任务之间传递知识来执行连续学习。

    We study the problem of fitting a model to a dynamical environment when new modes of behavior emerge sequentially. The learning model is aware when a new mode appears, but it does not have access to the true modes of individual training sequences. The state-of-the-art continual learning approaches cannot handle this setup, because parameter transfer suffers from catastrophic interference and episodic memory design requires the knowledge of the ground-truth modes of sequences. We devise a novel continual learning method that overcomes both limitations by maintaining a descriptor of the mode of an encountered sequence in a neural episodic memory. We employ a Dirichlet Process prior on the attention weights of the memory to foster efficient storage of the mode descriptors. Our method performs continual learning by transferring knowledge across tasks by retrieving the descriptors of similar modes of past tasks to the mode of a current sequence and feeding this descriptor into its transitio
    

