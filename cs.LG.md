# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Physics-informed Gaussian process model for Euler-Bernoulli beam elements.](http://arxiv.org/abs/2308.02894) | 该论文介绍了一种基于物理信息的高斯过程模型，通过欧拉-伯努利梁方程建模，并应用于结构的弯曲刚度回归、响应插值和概率推断。该模型在悬臂梁上进行了实际应用，并用于结构健康监测。实验结果验证了该框架的有效性。 |
| [^2] | [Secure Deep-JSCC Against Multiple Eavesdroppers.](http://arxiv.org/abs/2308.02892) | 本文研究了一种对多个窃听者的安全通信的深度学习辅助联合源信道编码（Deep-JSCC）方法的推广。通过推广隐私漏斗和窃听信道编码的思想，刻画了合法节点图像恢复与信息泄漏给窃听者之间的权衡。 |
| [^3] | [Private Federated Learning with Dynamic Power Control via Non-Coherent Over-the-Air Computation.](http://arxiv.org/abs/2308.02881) | 通过动态功率控制的非相干空中计算方法实现了私密联邦学习，提高了模型性能并保护了模型参数的隐私。 |
| [^4] | [Meta-learning in healthcare: A survey.](http://arxiv.org/abs/2308.02877) | 元学习在医疗领域有广泛应用，可以解决医疗挑战，如样本不足和数据收集差异。主要包括多/单任务学习和多/少样本学习方法。 |
| [^5] | [Data-Based Design of Multi-Model Inferential Sensors.](http://arxiv.org/abs/2308.02872) | 本文提出了两种新方法来设计多模型推理传感器，旨在减轻现有方法的一些缺点。通过设计真实的石化炼厂单元推理传感器进行演示，结果显示在多个指标上取得了显著的改进。 |
| [^6] | [NP-SemiSeg: When Neural Processes meet Semi-Supervised Semantic Segmentation.](http://arxiv.org/abs/2308.02866) | 将神经过程（NPs）应用于半监督语义分割，通过不确定性量化实现了模型对于未知内容的认知，提高了分割结果的质量和安全性。 |
| [^7] | [Generative Adversarial Networks for Stain Normalisation in Histopathology.](http://arxiv.org/abs/2308.02851) | 本论文研究了生成对抗网络在数字病理学染色标准化中的应用，发现基于GAN的方法在染色标准化方面表现出色，但需要更大的计算资源。 |
| [^8] | [Approximating Positive Homogeneous Functions with Scale Invariant Neural Networks.](http://arxiv.org/abs/2308.02836) | 本文研究使用尺度不变神经网络近似解决线性反问题的可行性，证明了单隐藏层ReLU网络无法恢复稀疏向量，但通过两个隐藏层可以稳定且精确地恢复任意稀疏程度的向量，此外还推广到了其他恢复问题。 |
| [^9] | [Reinforcement Learning for Financial Index Tracking.](http://arxiv.org/abs/2308.02820) | 本论文提出了针对金融指数跟踪问题的第一个具有动态性的离散时间无穷期模型，它克服了现有模型的一些局限，可以精确计算交易成本，同时考虑了跟踪误差和交易成本之间的权衡，并能有效利用长时间段的数据。我们使用深度强化学习方法解决该模型，解决了由于数据限制导致的问题。 |
| [^10] | [A generative model for surrogates of spatial-temporal wildfire nowcasting.](http://arxiv.org/abs/2308.02810) | 本文提出了一种生成模型，利用三维量化变分自编码器来生成给定生态区域内未见的空间-时间野火燃烧区域序列。该模型在加利福尼亚州的Chimney火灾生态区域中进行了测试，结果表明该模型能够成功生成连贯且结构良好的火势情景。 |
| [^11] | [MiAMix: Enhancing Image Classification through a Multi-stage Augmented Mixied Sample Data Augmentation Method.](http://arxiv.org/abs/2308.02804) | MiAMix是一种新型的混合样本数据增强方法，通过将图像增强集成到混合框架中并利用多种多样的混合方法来提升图像分类模型的性能和泛化能力。 |
| [^12] | [OBESEYE: Interpretable Diet Recommender for Obesity Management using Machine Learning and Explainable AI.](http://arxiv.org/abs/2308.02796) | OBESEYE是一款基于机器学习和可解释AI的可理解的肥胖管理饮食推荐器，能够预测个体所需的营养物质量，对肥胖管理具有重要贡献。 |
| [^13] | [Semi-supervised Contrastive Regression for Estimation of Eye Gaze.](http://arxiv.org/abs/2308.02784) | 本文提出了一种用于眼球注视估计的半监督对比回归方法。该方法利用小规模标记的数据集来寻找泛化解决方案，能够在未见面部图像上进行准确的估计。通过引入新的对比损失范式，该方法在性能上表现出色。 |
| [^14] | [Unveiling Emotions from EEG: A GRU-Based Approach.](http://arxiv.org/abs/2308.02778) | 本研究通过使用GRU算法对脑电图数据进行情绪识别，取得了出色的结果，并且相对于其他机器学习技术具有最高的准确率。 |
| [^15] | [Dataopsy: Scalable and Fluid Visual Exploration using Aggregate Query Sculpting.](http://arxiv.org/abs/2308.02764) | Dataopsy是一种可扩展和流动的可视化探索方法，使用聚合查询雕刻（AQS）作为一种分面可视化查询技术，可以从整个数据集的聚合开始，逐步探索数据集。 |
| [^16] | [Neural Collapse in the Intermediate Hidden Layers of Classification Neural Networks.](http://arxiv.org/abs/2308.02760) | 本论文首次对分类神经网络中间隐藏层的神经崩溃进行了全面的实证分析。研究发现，大多数中间隐藏层都会出现某种程度的神经崩溃，而崩溃程度通常与层的深度呈正相关。此外，研究还发现类内方差的减小主要发生在较浅的层中，夹角分离量随隐藏层深度的增加而增加。 |
| [^17] | [DaMSTF: Domain Adversarial Learning Enhanced Meta Self-Training for Domain Adaptation.](http://arxiv.org/abs/2308.02753) | DaMSTF是一种领域适应的自我训练框架，通过使用元学习来减少标签噪声并保留困难的例子。 |
| [^18] | [NeRFs: The Search for the Best 3D Representation.](http://arxiv.org/abs/2308.02751) | NeRFs是视图合成和相关问题中寻找最佳3D表示的结果，该方法利用神经网络查询获取体积参数来描述连续体积场景。 |
| [^19] | [Exploiting On-chip Heterogeneity of Versal Architecture for GNN Inference Acceleration.](http://arxiv.org/abs/2308.02749) | 该论文利用AMD Versal ACAP架构的异构计算能力，通过开发自定义硬件模块和设计运行时内核映射策略，实现了对GNN推理的加速。该方法在VCK5000 ACAP平台上的实现具有优越性能。 |
| [^20] | [SABRE: Robust Bayesian Peer-to-Peer Federated Learning.](http://arxiv.org/abs/2308.02747) | SABRE是一种强鲁棒性变分贝叶斯点对点联邦学习框架，通过新的聚合方法克服了现有框架的局限性，在非IID环境中表现良好，对数据/模型攻击具备鲁棒性，在图像分类数据上优于现有框架。 |
| [^21] | [Meta-Tsallis-Entropy Minimization: A New Self-Training Approach for Domain Adaptation on Text Classification.](http://arxiv.org/abs/2308.02746) | 元-Tsallis-熵最小化是一种新的自适应文本分类领域自适应方法，通过优化目标域上的实例自适应Tsallis熵来解决自训练在大领域转移时失败的问题。 |
| [^22] | [Learning to Schedule in Non-Stationary Wireless Networks With Unknown Statistics.](http://arxiv.org/abs/2308.02734) | 本文提出了一种适用于未知统计量的非稳态无线网络中进行调度的有效算法，该算法基于最大权重策略，并利用滑动窗口上界置信度来学习信道的状态。在假设平均服务率的变异性温和的前提下，该算法在吞吐量方面是最优的。 |
| [^23] | [Personalization of Stress Mobile Sensing using Self-Supervised Learning.](http://arxiv.org/abs/2308.02731) | 本研究探讨了使用自监督学习来个性化压力移动感知的方法，以解决压力预测中标签主观性和稀疏性等问题。 |
| [^24] | [Synthesizing Programmatic Policies with Actor-Critic Algorithms and ReLU Networks.](http://arxiv.org/abs/2308.02729) | 本文通过使用Actor-Critic算法和ReLU网络，展示了在编码程序化策略的语言上，不需要特定的PIRL算法。使用ReLU网络可以将使用Actor-Critic算法学习到的策略转化为具有if-then-else结构、线性变换和PID操作等的程序化策略。 |
| [^25] | [Towards Improving Harmonic Sensitivity and Prediction Stability for Singing Melody Extraction.](http://arxiv.org/abs/2308.02723) | 本文提出了通过修改输入特征和训练目标来改进歌唱旋律提取的方法。这些修改包括增强对尾部谐波的敏感性和设计可防止预测极短片段的损失函数。实验结果表明，这些修改对于提高歌唱旋律提取的效果有实际效果。 |
| [^26] | [Fluid Property Prediction Leveraging AI and Robotics.](http://arxiv.org/abs/2308.02715) | 这项工作提出了一种基于视觉的方法来估计液体的粘度，通过学习视频中不同液体振荡模式的潜在表示，可以从视觉上推断液体的类别或动态粘度。 |
| [^27] | [Exploring the Effect of Sparse Recovery on the Quality of Image Superresolution.](http://arxiv.org/abs/2308.02714) | 本研究探讨了稀疏恢复算法对图像超分辨率重构质量的影响，并通过实证实验寻找最佳稀疏恢复算法。 |
| [^28] | [Scalable Computation of Causal Bounds.](http://arxiv.org/abs/2308.02709) | 本论文研究了在存在未观测混淆变量和离散值观测变量的因果图上计算因果查询的界限的问题，并提出了修剪方法来显著减少计算负担，使得可以计算更大规模的因果推断问题的界限，在特殊问题情况下可以以闭合形式计算界限，并将方法扩展到分数线性规划进行计算 |
| [^29] | [FPR Estimation for Fraud Detection in the Presence of Class-Conditional Label Noise.](http://arxiv.org/abs/2308.02695) | 该论文提出了在存在标签噪音的情况下，估计二分类模型的FPR以及TPR的方法，这对于欺诈检测中的准确性至关重要。作者发现，现有的方法虽然减小了总误差，却不能保证模型对FPR和TPR的估计准确，因此提出了一种使清理误差与模型分数解耦的方法。 |
| [^30] | [Explainable Deep Learning-based Solar Flare Prediction with post hoc Attention for Operational Forecasting.](http://arxiv.org/abs/2308.02682) | 本文研究了一个基于深度学习的太阳耀斑预测模型，通过事后分析发现该模型的预测结果与活动区特征一致。 |
| [^31] | [Fair Models in Credit: Intersectional Discrimination and the Amplification of Inequity.](http://arxiv.org/abs/2308.02680) | 本文研究了信贷领域中的公平模型，通过借鉴交叉性理论，揭示了在性别、年龄、婚姻状况、单亲状态和子女数量等多个交叉社会类别的影响下，信贷分配中存在的不平等现象。 |
| [^32] | [Guided Distillation for Semi-Supervised Instance Segmentation.](http://arxiv.org/abs/2308.02668) | 这项研究提出了一种半监督实例分割的引导蒸馏方法，通过引入新的“引导预烧”阶段和利用未标记数据的导师模型指导，取得了显著的改进。 |
| [^33] | [AI-Enhanced Data Processing and Discovery Crowd Sourcing for Meteor Shower Mapping.](http://arxiv.org/abs/2308.02664) | 本研究使用增强型人工智能技术对全球流星雨数据进行处理和分析，并通过开发互动的网页平台，让公众参与流星探测，从而提高了流星雨的发现率。 |
| [^34] | [A Review of Change of Variable Formulas for Generative Modeling.](http://arxiv.org/abs/2308.02652) | 本文从编码器/解码器架构的统一视角出发，系统性地总结了28个变量变换公式，揭示了不同方法之间的有趣关系，强调了重要区别，并提出了未来研究的方向。 |
| [^35] | [Learning from Topology: Cosmological Parameter Estimation from the Large-scale Structure.](http://arxiv.org/abs/2308.02636) | 该论文提出了一种基于持续同调和神经网络的方法，利用大尺度结构的拓扑信息估计宇宙参数。通过参数恢复测试，发现该方法比传统的贝叶斯推断方法更准确和精确。 |
| [^36] | [Generation of Realistic Synthetic Raw Radar Data for Automated Driving Applications using Generative Adversarial Networks.](http://arxiv.org/abs/2308.02632) | 本研究提出了一种使用生成对抗网络生成合成毫米波雷达数据的快速方法，可以增加数据增强的潜力，并进一步开发雷达数据处理算法。 |
| [^37] | [Uncertainty Estimation and Propagation in Accelerated MRI Reconstruction.](http://arxiv.org/abs/2308.02631) | 本文提出了一种基于条件分层变分自编码器的概率重建技术（PHiRec），用于解决深度学习在MRI重建中的不确定性问题。我们的方法在产生高质量重建的同时，能够更好地校准不确定性量化。同时，我们还展示了如何传播MR重建中的不确定性。 |
| [^38] | [Harnessing the Web and Knowledge Graphs for Automated Impact Investing Scoring.](http://arxiv.org/abs/2308.02622) | 本论文介绍了一个利用网络和知识图谱自动评估影响力投资的数据驱动系统，通过收集和过滤文本数据集以及使用分类器来预测分数，实现了自动创建SDG框架的过程。 |
| [^39] | [Color Image Recovery Using Generalized Matrix Completion over Higher-Order Finite Dimensional Algebra.](http://arxiv.org/abs/2308.02621) | 本篇论文提出了一种基于广义高阶标量的彩色图像恢复方法，通过扩展传统的二阶矩阵模型到更全面的高阶矩阵模型，并利用这个模型扩展了一些常用的矩阵和张量补全算法。实验证明，这种方法在彩色图像补全方面具有较好的性能。 |
| [^40] | [ChatGPT for GTFS: From Words to Information.](http://arxiv.org/abs/2308.02618) | 本研究探索了使用ChatGPT语言模型从GTFS数据中检索信息的可行性，验证了ChatGPT（GPT-3.5）在GTFS规范理解和信息提取方面的能力。程序合成方法在信息检索任务中表现出更高的准确率，为解决GTFS数据信息获取问题提供了一种有效的方法。 |
| [^41] | [Vehicles Control: Collision Avoidance using Federated Deep Reinforcement Learning.](http://arxiv.org/abs/2308.02614) | 本文研究了使用联邦深度强化学习技术进行碰撞避免的车辆控制问题，并比较了不同算法的效果。结果表明，联邦深度确定性策略梯度算法在优化车辆控制方面表现更好。 |
| [^42] | [Interoperable synthetic health data with SyntHIR to enable the development of CDSS tools.](http://arxiv.org/abs/2308.02613) | 本论文提出了一种利用合成EHR数据开发CDSS工具的体系架构，通过使用SyntHIR系统和FHIR标准实现数据互操作性和工具可迁移性。 |
| [^43] | [Knowledge-Driven Multi-Agent Reinforcement Learning for Computation Offloading in Cybertwin-Enabled Internet of Vehicles.](http://arxiv.org/abs/2308.02603) | 这项研究提出了一种基于知识驱动的多智能体强化学习方法，用于解决物联网车辆中计算卸载的延迟问题。通过将计算任务卸载到边缘单元，可以减轻车载计算负担。该方法利用图神经网络结合领域知识，选择每辆车的最佳卸载选项。 |
| [^44] | [Branched Latent Neural Operators.](http://arxiv.org/abs/2308.02599) | Branched Latent Neural Operators (BLNOs) are introduced to learn input-output maps for encoding complex physical processes. BLNOs utilize interpretable latent outputs to enhance learned dynamics and overcome the curse of dimensionality, while also showing excellent generalization properties with small training datasets and short training times. The partial connection structure reduces the number of tunable parameters. BLNOs are proven effective in a challenging biophysically detailed test case. |
| [^45] | [Designing a Deep Learning-Driven Resource-Efficient Diagnostic System for Metastatic Breast Cancer: Reducing Long Delays of Clinical Diagnosis and Improving Patient Survival in Developing Countries.](http://arxiv.org/abs/2308.02597) | 这项研究设计了一种基于深度学习的诊断系统，用于转移性乳腺癌的诊断，旨在减少发展中国家临床诊断的长时间延迟，并提高患者的生存率。 |
| [^46] | [SMARLA: A Safety Monitoring Approach for Deep Reinforcement Learning Agents.](http://arxiv.org/abs/2308.02594) | 本文提出了一种基于机器学习的安全监测方法SMARLA，用于深度强化学习智能体。该方法设计为黑盒子，利用状态抽象减少状态空间，实现对智能体状态的安全违规预测。经验证，SMARLA具有准确的违规预测能力，并可在智能体执行的早期阶段进行预测。 |
| [^47] | [Unmasking Parkinson's Disease with Smile: An AI-enabled Screening Framework.](http://arxiv.org/abs/2308.02588) | 本研究使用微表情视频数据集开发了一种基于人工智能的帕金森病筛查框架，通过分析微笑视频中的特征，实现了89.7%的准确性和89.3%的AUROC值，同时在人群子组上没有检测到偏见。 |
| [^48] | [Synthesising Rare Cataract Surgery Samples with Guided Diffusion Models.](http://arxiv.org/abs/2308.02587) | 本研究通过使用引导扩散模型合成白内障手术样本，解决了数据不平衡对分类器性能的负面影响，实现了多类多标签条件下的高质量样本合成。 |
| [^49] | [Aligning Agent Policy with Externalities: Reward Design via Bilevel RL.](http://arxiv.org/abs/2308.02585) | 本文提出了一种将强化学习的策略优化与外部性对齐的方法，通过双层优化框架和委托-代理框架，上层学习适当的奖励参数化，下层学习代理人的策略。 |
| [^50] | [Adapt and Decompose: Efficient Generalization of Text-to-SQL via Domain Adapted Least-To-Most Prompting.](http://arxiv.org/abs/2308.02582) | 该论文介绍了一种通过领域适应和最少到最多提示的方式实现文本到SQL的高效泛化的方法。通过离线抽样获取少量样本，并合成一个通用提示，避免了昂贵的测试时间样本检索，并通过自适应和分解的方法更好地处理跨领域和跨组合式的泛化。 |
| [^51] | [Cream Skimming the Underground: Identifying Relevant Information Points from Online Forums.](http://arxiv.org/abs/2308.02581) | 本文提出了一种基于机器学习的方法，通过监控地下黑客论坛来检测野外漏洞的利用。通过对CrimeBB数据集进行分析，开发了一个监督机器学习模型，可以过滤引用CVE的主题并将其标记为Proof-of-Concept、武器化或漏洞利用。利用随机森林，可以达到准确率、精确率和召回率大于0.99。同时，还提供了对武器化和漏洞利用之间性质差异的insights，以及对黑客社区利润和其他相关方面的分析。 |
| [^52] | [Probabilistic Deep Supervision Network: A Noise-Resilient Approach for QoS Prediction.](http://arxiv.org/abs/2308.02580) | PDS-Net is a novel framework for QoS prediction that effectively reduces errors resulting from noise data by utilizing a probabilistic space and a condition-based multitasking loss function. |
| [^53] | [ADRNet: A Generalized Collaborative Filtering Framework Combining Clinical and Non-Clinical Data for Adverse Drug Reaction Prediction.](http://arxiv.org/abs/2308.02571) | 本文提出了ADRNet，这是一个将临床和非临床数据结合起来的广义协同过滤框架，用于预测不良药物反应。该模型在两个大型公开临床数据集上提供了先前协同过滤方法的广泛基准结果。 |
| [^54] | [Learning Implicit Entity-object Relations by Bidirectional Generative Alignment for Multimodal NER.](http://arxiv.org/abs/2308.02570) | 本文提出了一种名为BGA-MNER的双向生成对齐方法，用于解决多模态命名实体识别中的两个主要挑战：语义鸿沟和实体-物体关系。实验结果表明，该方法能够有效地捕捉隐式实体-物体关系。 |
| [^55] | [Weighted Multi-Level Feature Factorization for App ads CTR and installation prediction.](http://arxiv.org/abs/2308.02568) | 加权多级特征分解方法应用于应用程序广告的CTR和安装预测，通过工程化特定特征和共享特征的交互，取得了较好的结果。 |
| [^56] | [Food Classification using Joint Representation of Visual and Textual Data.](http://arxiv.org/abs/2308.02562) | 本研究提出了一种使用联合表示的多模态分类框架，通过修改版的EfficientNet和Mish激活函数实现图像分类，使用基于BERT的网络实现文本分类。实验结果表明，所提出的网络在图像和文本分类上表现优于其他方法，准确率提高了11.57%和6.34%。比较分析还证明了所提出方法的效率和鲁棒性。 |
| [^57] | [From Discrete Tokens to High-Fidelity Audio Using Multi-Band Diffusion.](http://arxiv.org/abs/2308.02560) | 提出了一种高保真多频带扩散模型，可以根据低比特率的离散表示生成任何类型的音频形式，具有优于最先进生成技术的感知质量。 |
| [^58] | [DLSIA: Deep Learning for Scientific Image Analysis.](http://arxiv.org/abs/2308.02559) | DLSIA是一种Python的机器学习库，为科学家提供了定制化卷积神经网络架构，加速科学图像分析研究，并促进跨学科合作。 |
| [^59] | [Survey on Computer Vision Techniques for Internet-of-Things Devices.](http://arxiv.org/abs/2308.02553) | 本文调查了在物联网设备上部署DNN的低功耗和节能实现的最新进展，这些技术通过减少内存需求和减少算术操作数量改善了DNN的可部署性，并且不显著牺牲准确性。 |
| [^60] | [qgym: A Gym for Training and Benchmarking RL-Based Quantum Compilation.](http://arxiv.org/abs/2308.02536) | qgym是一个用于训练和基准测试基于强化学习的量子编译的健身房，旨在优化并连接人工智能与量子编译的研究领域。 |
| [^61] | [Learning to Generate Training Datasets for Robust Semantic Segmentation.](http://arxiv.org/abs/2308.02535) | 本文提出了一种新的方法，通过生成真实和可信的扰动或异常图像来提高语义分割技术的鲁棒性。通过设计和训练Robusta，一种鲁棒的条件生成对抗网络，可以为训练可靠的分割模型提供可用的数据集，从而显著增强语义分割技术在面对现实世界的扰动和分布变化时的鲁棒性。 |
| [^62] | [Improving Generalization of Adversarial Training via Robust Critical Fine-Tuning.](http://arxiv.org/abs/2308.02533) | 本文提出了一种名为鲁棒性关键微调（RiFT）的方法，通过在非关键鲁棒模块上微调经过对抗训练的模型来提高泛化能力，而不损害对抗性鲁棒性。 |
| [^63] | [Evaluating ChatGPT and GPT-4 for Visual Programming.](http://arxiv.org/abs/2308.02522) | 本研究评估了ChatGPT和GPT-4在视觉编程领域的应用，并发现它们具备与基于文本的Python编程相当的高级能力。 |
| [^64] | [Improving Probabilistic Bisimulation for MDPs Using Machine Learning.](http://arxiv.org/abs/2308.02519) | 本文提出了一种使用机器学习改进MDPs的概率双向建模的新技术。 |
| [^65] | [Feature Reweighting for EEG-based Motor Imagery Classification.](http://arxiv.org/abs/2308.02515) | 本论文提出了一种特征重加权的方法，用于解决使用EEG信号进行运动想象分类时存在的低信噪比、非稳态性、非线性和复杂性等挑战，通过降低噪声和无关信息，提高分类性能。 |
| [^66] | [Language models as master equation solvers.](http://arxiv.org/abs/2308.02514) | 本研究将语言模型用作求解主方程的机器学习方法，通过设计提示网络和使用强化学习算法训练，实现了对多模组和高维系统的高精度求解。 |
| [^67] | [Robust vertebra identification using simultaneous node and edge predicting Graph Neural Networks.](http://arxiv.org/abs/2308.02509) | 本研究提出了一个使用图神经网络进行骨椎骨骼识别的方法，该方法能够准确地关联椎骨的位置和方向，避免了启发式规则，并通过引入一个包含椎弓根检测的新数据集进行验证。 |
| [^68] | [Assessing Intra-class Diversity and Quality of Synthetically Generated Images in a Biomedical and Non-biomedical Setting.](http://arxiv.org/abs/2308.02505) | 本研究主要关注在生物医学和非生物医学环境中评估合成图像的类内多样性和质量，使用多尺度结构相似性指数测量和余弦距离评估类内多样性，使用Frechet Inception距离评估质量。评估这些度量对于了解合成图像的多样性和质量至关重要。 |
| [^69] | [The identification of garbage dumps in the rural areas of Cyprus through the application of deep learning to satellite imagery.](http://arxiv.org/abs/2308.02502) | 通过对卫星图像应用深度学习技术，本研究旨在识别塞浦路斯农村地区的非法垃圾倾倒场所，并为相关部门提供信息。为此，收集了一组包含和不包含垃圾的图像数据集，并采用数据增强方法扩充数据。 |
| [^70] | [Learning to Segment from Noisy Annotations: A Spatial Correction Approach.](http://arxiv.org/abs/2308.02498) | 本文提出了一种基于空间修正的方法，用于从噪声注释中学习分割。这种方法通过马尔可夫模型编码空间相关性和偏差，并提供理论保证。实验证明，该方法在合成和实际噪声注释上优于当前最先进的方法。 |
| [^71] | [Mapping Global Value Chains at the Product Level.](http://arxiv.org/abs/2308.02491) | 本研究提出了一种基于机器学习和贸易理论的方法，通过细粒度的国际贸易数据推断产品层面的价值链关系，为应对经济中断提供重要的数据支持。 |
| [^72] | [Intensity-free Integral-based Learning of Marked Temporal Point Processes.](http://arxiv.org/abs/2308.02360) | 该论文提出了一种基于积分的无强度积分化学能的学习框架IFIB，用于建模离散事件中具有分类或数值属性的事件标记。 |
| [^73] | [Scaling Clinical Trial Matching Using Large Language Models: A Case Study in Oncology.](http://arxiv.org/abs/2308.02180) | 本文研究了使用大型语言模型（LLMs）扩展临床试验匹配的方法，并以肿瘤学为案例研究。研究结果显示，先进的LLMs能够处理临床试验的复杂条件和匹配逻辑，相较于之前的方法，性能显著提升，并可作为人工辅助筛选患者-试验候选人的初步解决方案。 |
| [^74] | [Deep Maxout Network-based Feature Fusion and Political Tangent Search Optimizer enabled Transfer Learning for Thalassemia Detection.](http://arxiv.org/abs/2308.02029) | 本文提出了基于Deep Maxout网络特征融合和Political Tangent Search优化器的转移学习方法，应用于地中海贫血检测。该方法对输入数据进行归一化处理，并利用Deep Maxout网络的特征融合和过采样方法进行数据增强，最终通过转移学习进行地中海贫血检测。 |
| [^75] | [Tensor Programs IVb: Adaptive Optimization in the Infinite-Width Limit.](http://arxiv.org/abs/2308.01814) | 本论文研究了在无限宽度极限中使用自适应优化器训练宽神经网络时的新现象，通过推导相应的“神经切线”和“最大更新”极限，展示了特征学习和核行为之间的二分法，同时引入了简化计算的bra-ket符号。 |
| [^76] | [OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models.](http://arxiv.org/abs/2308.01390) | OpenFlamingo是一个开源框架，用于训练大型自回归视觉语言模型。它在多个数据集上表现良好，达到了对应模型性能的80%至89%。 |
| [^77] | [LLMs Understand Glass-Box Models, Discover Surprises, and Suggest Repairs.](http://arxiv.org/abs/2308.01157) | LLMs在处理可解释模型方面表现出色，提供了全面的模型级总结和自动化的异常检测、原因描述和修复建议。在医疗保健领域使用广义可加模型作为示例，同时介绍了开源的LLM-GAM接口包$\texttt{TalkToEBM}$。 |
| [^78] | [Enhancing Representation Learning for Periodic Time Series with Floss: A Frequency Domain Regularization Approach.](http://arxiv.org/abs/2308.01011) | 本文提出了一种叫做Floss的无监督方法，通过在频域上对学到的表示进行正则化来增强周期性时间序列的表示学习。Floss方法可以自动检测时间序列中的周期性并学习具有周期一致性的有意义的表示。 |
| [^79] | [Human-M3: A Multi-view Multi-modal Dataset for 3D Human Pose Estimation in Outdoor Scenes.](http://arxiv.org/abs/2308.00628) | 这篇论文提出了一个室外多模态多视角多人类姿势数据库Human-M3，并介绍了一种基于多模态数据输入的算法来生成准确的人体姿势。这个数据库解决了现有数据集的不足，提供了更多的数据多样性。 |
| [^80] | [Formally Explaining Neural Networks within Reactive Systems.](http://arxiv.org/abs/2308.00143) | 这项研究在反应式系统中提出了一种基于DNN验证的形式化XAI技术，可以解释DNN的行为，并且通过利用系统的转换约束来计算简洁的解释。 |
| [^81] | [Unsupervised machine learning shock capturing for High-Order CFD solvers.](http://arxiv.org/abs/2308.00086) | 我们提出了一种基于高斯混合模型（GMMs）的无监督机器学习震荡捕捉算法。这种算法具有显著的准确性和鲁棒性，适用于各种复杂几何结构和流动配置。 |
| [^82] | [Efficient Interaction-Aware Interval Analysis of Neural Network Feedback Loops.](http://arxiv.org/abs/2307.14938) | 本文提出了一种计算效率高的神经网络控制系统区间可达性分析框架，通过引入包含函数和构建嵌入系统来捕捉系统和神经网络控制器之间的相互作用。 |
| [^83] | [A Hybrid Machine Learning Model for Classifying Gene Mutations in Cancer using LSTM, BiLSTM, CNN, GRU, and GloVe.](http://arxiv.org/abs/2307.14361) | 本研究提出了一个基于多种机器学习算法和嵌入模型的集成模型，用于基因突变在癌症中的分类。实验结果表明，该模型在准确率、精确率、召回率等指标上优于其他传统和最新的转换器模型，并且具有更高的训练效率。 |
| [^84] | [Neural Memory Decoding with EEG Data and Representation Learning.](http://arxiv.org/abs/2307.13181) | 本研究提出一种使用EEG数据和表示学习进行神经记忆解码的方法，能够实现从EEG数据中识别出被召回的概念，并在信息检索问题中应用该方法。 |
| [^85] | [In-Context Learning in Large Language Models Learns Label Relationships but Is Not Conventional Learning.](http://arxiv.org/abs/2307.12375) | 大型语言模型（LLMs）在包含标签关系示例的上下文中的学习能力使其在下游任务中表现显著提高，但与传统学习方法不同。我们研究了上下文示例中的标签如何影响预测、预训练中学习到的标签关系如何与上下文示例相互作用以及上下文学习如何聚合标签信息。研究结果揭示了LLMs的工作机制及其对上下文信息的处理方式。 |
| [^86] | [Tackling the Curse of Dimensionality with Physics-Informed Neural Networks.](http://arxiv.org/abs/2307.12306) | 本文提出了一种新方法，利用物理信知的神经网络(PINNs)解决高维度的偏微分方程(PDEs)问题，并证明了收敛性和其他期望属性。 |
| [^87] | [NTK-approximating MLP Fusion for Efficient Language Model Fine-tuning.](http://arxiv.org/abs/2307.08941) | 该论文通过使用神经切向核近似MLP融合，提出了一种高效的语言模型微调方法。实验证明，这种方法能够在降低计算和存储开销的同时保持较好的模型性能。 |
| [^88] | [TableGPT: Towards Unifying Tables, Nature Language and Commands into One GPT.](http://arxiv.org/abs/2307.08674) | TableGPT是一个统一的框架，利用大型语言模型（LLMs）和外部功能命令使LLMs能够无缝地与表格进行交互，实现广泛的功能，并提供便利和可访问性给用户。其中的创新是全局表格表示的概念，使LLMs能够全面理解表格的结构和内容。 |
| [^89] | [Thailand Asset Value Estimation Using Aerial or Satellite Imagery.](http://arxiv.org/abs/2307.08650) | 本研究提出了一种利用航空或卫星影像进行泰国资产价值评估的方法，通过使用谷歌地图API的影像数据和深度学习模型，实现了较高的准确性。该方法相比传统方法，在考虑了空间变量的情况下能够得到更精确的土地价格预测结果。 |
| [^90] | [DNAGPT: A Generalized Pretrained Tool for Multiple DNA Sequence Analysis Tasks.](http://arxiv.org/abs/2307.05628) | DNAGPT是一个通用的基础模型，通过预训练模型和独特的标记设计，可以适用于任何DNA序列分析任务。它在多个任务上进行了评估，并展示出了良好的性能。 |
| [^91] | [Boosting Feedback Efficiency of Interactive Reinforcement Learning by Adaptive Learning from Scores.](http://arxiv.org/abs/2307.05405) | 本文提出一种利用人类提供的分数来改进交互式强化学习的反馈效率的方法。通过使用分数代替成对偏好，我们可以获得更多的数据。我们通过对机器人任务的评估表明，该方法能够通过自适应学习分数有效地学习到接近最优的策略。 |
| [^92] | [SoK: Privacy-Preserving Data Synthesis.](http://arxiv.org/abs/2307.02106) | 这篇论文提供了关于隐私保护的数据合成的综述和讨论，结合了统计方法和基于深度学习的方法。通过提供参考表和总结关键要点来巩固研究发现。 |
| [^93] | [Pretraining is All You Need: A Multi-Atlas Enhanced Transformer Framework for Autism Spectrum Disorder Classification.](http://arxiv.org/abs/2307.01759) | 提出了一种用于自闭症谱系障碍分类的多atlas增强transformer框架，利用静息态功能磁共振成像数据进行建模，采用自我监督预训练提高了分类性能。 |
| [^94] | [Pareto-Secure Machine Learning (PSML): Fingerprinting and Securing Inference Serving Systems.](http://arxiv.org/abs/2307.01292) | 本论文研究了模型服务系统的安全性，通过引入一个查询高效的指纹算法，使得攻击者能够一致地触发任何想要的模型，从而增强了对模型提取攻击的鲁棒性和准确性。 |
| [^95] | [Elastically-Constrained Meta-Learner for Federated Learning.](http://arxiv.org/abs/2306.16703) | 这项研究提出了一种弹性约束的元学习方法，用于解决联邦学习中由于非独立同分布数据导致元学习的不稳定目标的收敛问题。 |
| [^96] | [Modeling T1 Resting-State MRI Variants Using Convolutional Neural Networks in Diagnosis of OCD.](http://arxiv.org/abs/2306.12435) | 本研究利用计算建模方法开发了一个卷积神经网络模型，通过T1静息态磁共振成像(TRS-MRI)扫描识别生物标志物，有效地区分出患有OCD和其他精神障碍的患者，准确率超过90%。 |
| [^97] | [Pseudo session-based recommendation with hierarchical embedding and session attributes.](http://arxiv.org/abs/2306.10029) | 本文提出了一种新方法CoHHGN+，用于解决缺乏用户ID的电商网站数据的推荐问题。该方法使用了定义的伪会话以及包括价格、类别、性别和地区等用户信息，得到了较好的推荐结果。 |
| [^98] | [Understanding Deep Generative Models with Generalized Empirical Likelihoods.](http://arxiv.org/abs/2306.09780) | 本文展示了广义经验似然（GEL）方法提供了一系列诊断工具来识别深度生成模型的许多缺陷，并结合最大均值差异和广义经验似然的技术，创造了保留每个样本可解释性的分布测试，还包括标签信息的指标。这些测试可以预测模式降低的程度。 |
| [^99] | [Batches Stabilize the Minimum Norm Risk in High Dimensional Overparameterized Linear Regression.](http://arxiv.org/abs/2306.08432) | 本文研究了将数据分成批次的学习算法，在高维超参数线性回归模型中提供了隐式正则化，通过适当的批量大小选择，稳定了风险行为，消除了插值点处的膨胀和双峰现象 |
| [^100] | [Symmetry & Critical Points for Symmetric Tensor Decompositions Problems.](http://arxiv.org/abs/2306.07886) | 本文研究了将一个实对称张量分解成秩为1项之和的非凸优化问题，得到了精确的分析估计，并发现了各种阻碍局部优化方法的几何障碍和由于对称性导致的丰富的临界点集合。 |
| [^101] | [Membership Inference Attacks against Language Models via Neighbourhood Comparison.](http://arxiv.org/abs/2305.18462) | 本文提出两种新的基于邻域比较的攻击策略，利用语言数据的内在结构来提高成员推断攻击的性能，并在几个公开数据集上证明这些攻击的有效性。 |
| [^102] | [Vehicle Detection and Classification without Residual Calculation: Accelerating HEVC Image Decoding with Random Perturbation Injection.](http://arxiv.org/abs/2305.08265) | 本文介绍了一种用于交通监控的新方法，通过随机扰动重建图像，而不使用残差数据，从而显著减少图像重构所需的数据。该方法通过创建原始图像的精简表示，并保留与视频理解任务相关的信息，重点关注车辆检测和分类等关键用例。 |
| [^103] | [Deep Deterministic Policy Gradient for End-to-End Communication Systems without Prior Channel Knowledge.](http://arxiv.org/abs/2305.07448) | 本研究提出了一种基于深度确定性策略梯度（DDPG）的框架来解决无先验信道知识的端到端通信系统中发射器和接收器联合训练的问题。与现有方案相比，该方法可以获得更好的检测性能。 |
| [^104] | [Automatic Radiology Report Generation by Learning with Increasingly Hard Negatives.](http://arxiv.org/abs/2305.07176) | 本文提出了一种通过学习不断困难负样本的方法实现自动放射学报告生成的框架，以获得更具判别能力的特征，从而避免产生不期望或不匹配的报告。 |
| [^105] | [Similarity of Neural Network Models: A Survey of Functional and Representational Measures.](http://arxiv.org/abs/2305.06329) | 本文综述了神经网络模型相似度的两个观点：表示性相似和功能相似，提供了这两个家族的详细描述，并总结和讨论了其属性和关系，并提出了实践建议。 |
| [^106] | [Deep Learning for Predicting Progression of Patellofemoral Osteoarthritis Based on Lateral Knee Radiographs, Demographic Data and Symptomatic Assessments.](http://arxiv.org/abs/2305.05927) | 本研究利用深度学习和注意力机制预测膝关节骨关节炎进展，发现成像数据在预测中起到重要作用。 |
| [^107] | [Beyond Rule-based Named Entity Recognition and Relation Extraction for Process Model Generation from Natural Language Text.](http://arxiv.org/abs/2305.03960) | 本文扩展了PET数据集，通过聚类流程实体的提及，提出了一种新的基线技术流程提取方法，该方法避免了手动创建业务流程模型的繁琐工作，同时解决了同一流程实体重复提及的歧义问题。 |
| [^108] | [Defending against Insertion-based Textual Backdoor Attacks via Attribution.](http://arxiv.org/abs/2305.02394) | 本文提出了一种基于归因的管道AttDef，用于防御两种插入式污染攻击BadNL和InSent，该管道可以成功缓解插入式文本后门攻击并在四个基准数据集上平均提高了56.59%至79.97%和15.25%至48.34%的准确率。 |
| [^109] | [Learning Human-Human Interactions in Images from Weak Textual Supervision.](http://arxiv.org/abs/2304.14104) | 本文提出了一种新的范式，从单一的静态图像中学习自由文本的形式来灵活建模人际互动。并通过知识蒸馏生成伪标签来训练一种字幕模型，用于有效理解图像中的人际互动，具有较高的预测文本和语义质量，并在此任务上优于SOTA的图像字幕和情境识别模型。 |
| [^110] | [Physics-informed neural networks for predicting gas flow dynamics and unknown parameters in diesel engines.](http://arxiv.org/abs/2304.13799) | 本论文提出了一种物理信息神经网络（PINN）方法，能够同时准确预测柴油机未知参数和动态，以及识别“平均值”模型中的未知参数，为实际案例研究提供了可能性。 |
| [^111] | [Hopfield model with planted patterns: a teacher-student self-supervised learning model.](http://arxiv.org/abs/2304.13710) | 该论文提出了一种基于师生自我监督学习问题的Hopfield模型，能够帮助机器利用结构化的模式来学习，虽然一些条件对于学习非常重要，但这种学习模式在特定条件下可以实现泛化。 |
| [^112] | [Physics-informed Neural Network Combined with Characteristic-Based Split for Solving Navier-Stokes Equations.](http://arxiv.org/abs/2304.10717) | 本文提出了一种基于特征分裂的物理信息神经网络（PINN）方法，可用于处理数据驱动和无数据问题，并且能够快速求解可压缩的浅水方程和不可压缩的N-S方程 |
| [^113] | [Estimate-Then-Optimize Versus Integrated-Estimation-Optimization: A Stochastic Dominance Perspective.](http://arxiv.org/abs/2304.06833) | 本文提出，当模型类足够丰富以涵盖真实情况时，非线性问题的“先估计再优化”方法优于集成方法，包括优化间隙的渐进优势的均值，所有其他时刻和整个渐进分布。 |
| [^114] | [Did we personalize? Assessing personalization by an online reinforcement learning algorithm using resampling.](http://arxiv.org/abs/2304.05365) | 本论文提出了一种使用重复采样的政策评估方法，以评估在线 RL 算法实现的个性化程度。该方法可用于优化数字健康的个性化干预。 |
| [^115] | [Generative Agents: Interactive Simulacra of Human Behavior.](http://arxiv.org/abs/2304.03442) | 本文介绍了一种生成代理的架构，它能够仿真出具有可信度的人类行为，填充交互式沙盒环境，为创造更加真实的人机交互体验提供了一种新的思路。 |
| [^116] | [Self-Supervised Multimodal Learning: A Survey.](http://arxiv.org/abs/2304.01008) | 自监督多模态学习是一项旨在解决多模态数据中的自监督学习挑战的研究方向。它通过学习来自原始多模态数据中的表示，并解决了没有标签的多模态数据学习、不同模态的融合和不对齐数据学习等问题。 |
| [^117] | [Neuro-Symbolic Execution of Generic Source Code.](http://arxiv.org/abs/2304.00989) | 这项研究提出了一种新的神经模型，能够根据源代码执行泛型程序，并引入了神经符号执行问题。该模型能够执行Py150数据集程序，包括没有具体输入的库函数，并可以用于变量误用定位和修复。 |
| [^118] | [MAHALO: Unifying Offline Reinforcement Learning and Imitation Learning from Observations.](http://arxiv.org/abs/2303.17156) | 本文提出了一种名为MAHALO的方法，可以统一离线强化学习和基于观测的模仿学习，帮助处理数据集质量不佳的情况下的顺序决策制定问题，并在实验中证明了其有效性。 |
| [^119] | [Take 5: Interpretable Image Classification with a Handful of Features.](http://arxiv.org/abs/2303.13166) | 人们常常无法理解深度学习模型的决策过程，我们提出了一种Sparse Low-Dimensional Decision模型，它只使用一小部分可解释的特征进行决策，这使得该模型更容易被人理解，同时也具有与其他密集高维模型相似的准确性。 |
| [^120] | [Democratising AI: Multiple Meanings, Goals, and Methods.](http://arxiv.org/abs/2303.12642) | 这篇论文探讨了AI的民主化，包括四种类型的民主化：AI使用的民主化，AI开发的民主化，AI利润的民主化，和AI治理的民主化。要想实现有效的政策和权衡讨论，需要认识到AI治理的民主化在决策中扮演着重要的角色。 |
| [^121] | [Delay-Aware Hierarchical Federated Learning.](http://arxiv.org/abs/2303.12414) | 本论文提出了延迟感知的联邦学习(DFL)，通过解决边缘和云之间的通信延迟，提高了分布式机器学习模型训练的效率，并实现了一些政策以减少能量消耗和边缘到云端的通信。 |
| [^122] | [Dynamic-Aware Loss for Learning with Label Noise.](http://arxiv.org/abs/2303.11562) | 本文提出一种动态感知损失函数，采用增强拟合能力，逐渐增加鲁棒性的权重来处理标签噪声。在后期阶段，引入自举项，让DNN更加重视容易的样例，证明了这种方法的优越性。 |
| [^123] | [eP-ALM: Efficient Perceptual Augmentation of Language Models.](http://arxiv.org/abs/2303.11403) | 本论文提出了一种用对比学习提高语言模型的感知能力的高效方法eP-ALM，可以实现视觉感知信息和文本信息的融合，同时还能在多模态基准测试上实现最先进的结果。 |
| [^124] | [Learning to Incentivize Information Acquisition: Proper Scoring Rules Meet Principal-Agent Model.](http://arxiv.org/abs/2303.08613) | 本文设计了一种样本高效算法，将 UCB 算法（Auer等人，2002）应用于委托代理模型的在线设置，该算法能够通过与策略代理多次互动来设计最优的计分规则，并实现良好的效果。 |
| [^125] | [Bounding the Probabilities of Benefit and Harm Through Sensitivity Parameters and Proxies.](http://arxiv.org/abs/2303.05396) | 本文提出了两种方法来限制未测量混杂下的受益和伤害概率，一种是通过敏感性参数计算概率的上限或下限，另一种是利用代理变量得到更紧的界限。 |
| [^126] | [GOATS: Goal Sampling Adaptation for Scooping with Curriculum Reinforcement Learning.](http://arxiv.org/abs/2303.05193) | 本文提出了一种名为GOATS的方法，使用目标采样自适应课程强化学习技术，通过插值位置目标和数量目标的分布创建学习过程中的课程来解决机器人舀取任务中的位置目标和水量目标问题，取得了比基线更好的表现。 |
| [^127] | [Learning Bipedal Walking for Humanoids with Current Feedback.](http://arxiv.org/abs/2303.03724) | 本文提出了一种使用电流反馈来克服人形机器人中仿真到真实世界差距的方法，通过在仿真中训练模型，并利用真实机器人的电流反馈进行优化，成功实现了双足行走。 |
| [^128] | [Expectation consistency for calibration of neural networks.](http://arxiv.org/abs/2303.02644) | 本文介绍了一种名为期望一致性（EC）的新型校准技术，该方法通过对最后一层权重进行后训练重新缩放，使平均验证置信度与平均正确标签比例相一致，在不同神经网络架构和数据集上实现了类似温度缩放（TS）的校准性能。 |
| [^129] | [NovPhy: A Testbed for Physical Reasoning in Open-world Environments.](http://arxiv.org/abs/2303.01711) | NovPhy是一个为了开放世界物理推理而设计的测试平台，要求智能体在存在新颖情况的物理场景中进行推理并相应地采取行动。 |
| [^130] | [Privacy-Preserving Tree-Based Inference with Fully Homomorphic Encryption.](http://arxiv.org/abs/2303.01254) | 本研究介绍了一种基于全同态加密的数据隐私保护方法，能够针对加密表格数据进行任意计算，并得到了最新的解决方案，适用于一系列树型模型，包括决策树，随机森林和梯度增强树。此方法已应用在Concrete-ML开源库中，能够在准确性方面接近未受保护的版本。 |
| [^131] | [A semantic backdoor attack against Graph Convolutional Networks.](http://arxiv.org/abs/2302.14353) | 该论文研究了图卷积网络（GCNs）是否容易受到语义后门攻击，提出了一种针对GCNs的语义后门攻击方法（SBAG），通过在样本中的特定节点作为触发器，并注入隐藏的后门来攻击GCNs模型。 |
| [^132] | [Towards Memory- and Time-Efficient Backpropagation for Training Spiking Neural Networks.](http://arxiv.org/abs/2302.14311) | 本文提出了一种空间学习通过时间（SLTT）方法以提高训练脉冲神经网络的效率。该方法忽略了不重要的路径，减少了内存开销和训练时间。 |
| [^133] | [Training neural networks with structured noise improves classification and generalization.](http://arxiv.org/abs/2302.13417) | 通过在训练数据中添加结构化噪声，可以显著提高神经网络的分类和泛化能力，并提出了一种采样策略来优于传统的训练和赫布生规则方法。 |
| [^134] | [Empirical analysis of Different Dimensionality Reduction and classification Techniques for Epileptic Seizure detection.](http://arxiv.org/abs/2302.12012) | 本研究对使用不同降维和分类技术进行癫痫发作检测进行了实证分析，通过离散小波变换和机器学习分类器，结合主成分分析、独立成分分析和线性判别分析等降维算法，选择特征来提高检测准确性。 |
| [^135] | [ASSET: Robust Backdoor Data Detection Across a Multiplicity of Deep Learning Paradigms.](http://arxiv.org/abs/2302.11408) | 该论文研究了在多种深度学习范式中实现鲁棒的后门数据检测，并发现现有的检测方法在不同攻击和毒害比例下的性能变化很大，且不能应用于最新的干净标签攻击，以及自监督学习和迁移学习中性能损失较大。为此，论文提出了一种名为ASSET的新的检测方法，通过主动引导不同的模型行为来促进后门和干净样本的分离。 |
| [^136] | [Data Forensics in Diffusion Models: A Systematic Analysis of Membership Privacy.](http://arxiv.org/abs/2302.07801) | 本研究对扩散模型中的会员推断攻击进行了系统分析，并提出了适用于不同攻击场景的新攻击方法，取得了接近完美的攻击性能。 |
| [^137] | [Quantum algorithms applied to satellite mission planning for Earth observation.](http://arxiv.org/abs/2302.07181) | 本文介绍了一组量子算法，用于解决地球观测卫星任务规划问题，并证明了它们在结果优于传统算法方面的优势。 |
| [^138] | [Federated Survival Forests.](http://arxiv.org/abs/2302.02807) | 这篇论文介绍了一种基于随机生存森林的联邦算法，用于处理分布式、不完整、截尾和保密的生存数据集。该方法利用联邦学习的隐私保护技术，在多个数据集上共同训练机器学习模型，从而提高生存分析应用的性能。 |
| [^139] | [On the Within-Group Fairness of Screening Classifiers.](http://arxiv.org/abs/2302.00025) | 本文探讨了筛选分类器的组内公平性问题，指出使用校准的分类器可能存在对感兴趣的人口群体内的合格成员存在不公平对待的问题，并提出了一种基于动态规划的高效后处理算法来最小化修改分类器，以实现组内公平性。 |
| [^140] | [Quadruple-star systems are not always nested triples: a machine learning approach to dynamical stability.](http://arxiv.org/abs/2301.09930) | 这项研究通过机器学习算法，发现四星系统的动力学稳定性问题不总是涉及到嵌套的三元组，对于3+1的四星组合而言，采用四星模型的准确率明显优于传统的“嵌套”三元组模型。 |
| [^141] | [Selective Explanations: Leveraging Human Input to Align Explainable AI.](http://arxiv.org/abs/2301.09656) | 本研究提出一种通过利用人类输入生成选择性解释的通用框架，以弥合可解释人工智能（XAI）与人类解释的差距，并且在决策支持任务中进行了实验证明其有效性。 |
| [^142] | [Interval Reachability of Nonlinear Dynamical Systems with Neural Network Controllers.](http://arxiv.org/abs/2301.07912) | 本文提出了一种基于区间分析的计算高效框架，用于验证具有神经网络控制器的非线性动力系统的区间可达性。通过混合单调理论的启发，将闭环动力学嵌入到更大的系统中，这种嵌入方法在保留系统非线性结构的同时，提供了一种可扩展的安全性分析方法。采用单个轨迹计算超矩形过估计可达集，并通过分区策略优化可达集估计，实现计算效率和准确性的平衡。 |
| [^143] | [Phase-shifted Adversarial Training.](http://arxiv.org/abs/2301.04785) | 本论文通过分析响应频率的视角，发现对抗训练导致神经网络收敛性较低，从而在每个数据附近产生高度振荡的预测。为了有效地学习高频内容，提出了相位偏移对抗训练(PhaseAT)方法。 |
| [^144] | [L-SeqSleepNet: Whole-cycle Long Sequence Modelling for Automatic Sleep Staging.](http://arxiv.org/abs/2301.03441) | L-SeqSleepNet是一种新的深度学习模型，通过高效的长序列建模方法，考虑整个睡眠周期的信息，提高了睡眠分期的性能。 |
| [^145] | [Latent Spectral Regularization for Continual Learning.](http://arxiv.org/abs/2301.03345) | 本研究提出了一种持续谱规范化器（CaSpeR），通过对潜在空间的几何特征进行规范化，在面对不断变化的训练数据分布时改善了基于重演的持续学习方法的性能。 |
| [^146] | [Model Parameter Identification via a Hyperparameter Optimization Scheme for Autonomous Racing Systems.](http://arxiv.org/abs/2301.01470) | 本文提出了基于超参优化方案的模型参数识别方法（MIHO），并实现了AV-21全尺寸自主赛车的模型参数识别。MIHO收敛速度比传统方法快13倍以上，参数模型具有良好适应性和泛化能力，车辆在场地测试中达到了217公里/小时的高速行驶和稳定避障性能。 |
| [^147] | [FFNeRV: Flow-Guided Frame-Wise Neural Representations for Videos.](http://arxiv.org/abs/2212.12294) | FFNeRV是一种新颖的方法，将流信息融入帧级表示中，以利用视频中帧之间的时间冗余，并引入了完全卷积的架构。 |
| [^148] | [Reasoning with Language Model Prompting: A Survey.](http://arxiv.org/abs/2212.09597) | 本文提供了使用语言模型提示进行推理的前沿研究综合调查。讨论了新兴推理能力出现的潜在原因，并提供系统资源帮助初学者。 |
| [^149] | [Spectral Regularized Kernel Two-Sample Tests.](http://arxiv.org/abs/2212.09201) | 本文研究了基于概率分布的再生核希尔伯特空间嵌入的双样本检验的最优性。我们发现最大均值差异（MMD）检验在分离边界方面并不是最优的，因此我们提出了一种基于谱正则化的修改方法，使得检验具有更小的分离边界。同时，我们还提出了自适应版本的检验，通过数据驱动的策略选择正则化参数，展示了其近乎最优的性能。 |
| [^150] | [RepQ-ViT: Scale Reparameterization for Post-Training Quantization of Vision Transformers.](http://arxiv.org/abs/2212.08254) | 本论文提出了一种基于规模重参数化的后训练量化框架RepQ-ViT，用于解决Vision Transformers在低位情况下的准确性下降问题，通过将量化和推断分开处理，实现了准确量化和高效推断。 |
| [^151] | [Sliced Optimal Partial Transport.](http://arxiv.org/abs/2212.08049) | 本文提出了一种适用于一维非负测度之间最优偏转运输问题的高效算法，并通过切片的方式定义了切片最优偏转运输距离。 |
| [^152] | [LLEDA -- Lifelong Self-Supervised Domain Adaptation.](http://arxiv.org/abs/2211.09027) | LLEDA是一个终身自助无监督域自适应框架，受互补学习系统（CLS）理论启发，模仿海马和新皮质之间的互动，通过潜意识回放技术实现了快速适应和渐进学习的目标。 |
| [^153] | [CaloFlow for CaloChallenge Dataset 1.](http://arxiv.org/abs/2210.14245) | CaloFlow是一种新的、有前景的快速量能器模拟方法，可以比Geant4快几个数量级生成高保真度的样本。使用量能器图片、直方图和分类器证明了其样本的保真度。 |
| [^154] | [MotionDeltaCNN: Sparse CNN Inference of Frame Differences in Moving Camera Videos.](http://arxiv.org/abs/2210.09887) | 本文提出了MotionDeltaCNN，一个支持移动摄像机的稀疏CNN推断框架，通过引入球面缓冲区和填充卷积来高效融合新揭示的图像区域和已处理区域，从而实现对帧差异的推断。在移动摄像机视频中，相对于DeltaCNN，我们的方法性能提升了高达90%。 |
| [^155] | [A Bayesian Optimization Framework for Finding Local Optima in Expensive Multi-Modal Functions.](http://arxiv.org/abs/2210.06635) | 该论文开发了一种多模态贝叶斯优化框架，用于在昂贵评估的多模态目标函数中找到一组局部和全局最优解。这使得在实际问题中可以快速切换到最优解，并获得最佳的系统性能。 |
| [^156] | [Fluid Batching: Exit-Aware Preemptive Serving of Early-Exit Neural Networks on Edge NPUs.](http://arxiv.org/abs/2209.13443) | 本论文提出了一种针对边缘NPUs上的提前退出神经网络进行退出感知抢占式服务的流体批处理方法。 |
| [^157] | [Learning to Relight Portrait Images via a Virtual Light Stage and Synthetic-to-Real Adaptation.](http://arxiv.org/abs/2209.10510) | 这个论文提出了一种在不需要光台的情况下进行肖像图像重新照明的方法，并能够与最先进的方法相媲美。该方法基于物理原理，并能够产生高质量的结果。 |
| [^158] | [Deep Learning Based Residuals in Non-linear Factor Models: Precision Matrix Estimation of Returns with Low Signal-to-Noise Ratio.](http://arxiv.org/abs/2209.04512) | 本文介绍了在深度学习框架中使用非线性因子模型对大型投资组合中资产回报的精确矩阵进行一致估计和收敛速度。我们的方法不仅适用于金融市场典型的低信噪比环境，还与弱因子兼容，并且通过理论分析建立了统一的界限，同时提供了基于数据的一致误差协方差估计方法。模拟和实证结果显示我们的模型具有卓越的准确性。 |
| [^159] | [FedOBD: Opportunistic Block Dropout for Efficiently Training Large-scale Neural Networks through Federated Learning.](http://arxiv.org/abs/2208.05174) | FedOBD是一个新的联邦学习方法，它通过将大型模型分解为语义块，允许参与者机会主义地上传量化的块来进行聚合，以此解决了在大规模联邦学习模型训练过程中操作模型参数所产生的通信开销和性能问题。 |
| [^160] | [Visual Interpretable and Explainable Deep Learning Models for Brain Tumor MRI and COVID-19 Chest X-ray Images.](http://arxiv.org/abs/2208.00953) | 本研究通过评估归因方法，揭示深度学习模型分析医学图像的推理过程，提高了医学保健领域对深度学习的信任和可解释性。 |
| [^161] | [A novel Deep Learning approach for one-step Conformal Prediction approximation.](http://arxiv.org/abs/2207.12377) | 本文提出了一种新颖的深度学习方法，用于一步的符合性预测近似。通过将传统的两步符合性预测方法简化为一步，我们提出了一种新的符合性损失函数，可以在保持近似有效性和预测效率的同时，显著减少训练时间。 |
| [^162] | [HybMT: Hybrid Meta-Predictor based ML Algorithm for Fast Test Vector Generation.](http://arxiv.org/abs/2207.11312) | 本文提出一个基于混合元预测的机器学习算法用于快速测试向量生成，该算法通过2级预测器进一步减少了无用工作，顶层元预测器的准确率达到了99% |
| [^163] | [Accelerated and Quantitative 3D Semisolid MT/CEST Imaging using a Generative Adversarial Network (GAN-CEST).](http://arxiv.org/abs/2207.11297) | 这项研究使用生成对抗网络（GAN-CEST）加速和量化了三维半实心MT/CEST成像，并且大大缩短了采集时间。 |
| [^164] | [Statistical and Computational Trade-offs in Variational Inference: A Case Study in Inferential Model Selection.](http://arxiv.org/abs/2207.11208) | 本文通过一个推理模型选择的案例研究，研究了变分推断中的统计和计算权衡。在高斯推理模型中，我们发现，低秩推断模型在固定计算预算下产生了更高的统计近似误差，但较低的计算误差。 |
| [^165] | [QSAN: A Near-term Achievable Quantum Self-Attention Network.](http://arxiv.org/abs/2207.07563) | 本文提出了一种量子自注意力网络（QSAN），用于近期量子设备上的图像分类任务。该网络利用量子自注意力机制来增强数据表示能力，并设计了对应的一步实现和量子电路框架。 |
| [^166] | [Transfer Learning with Deep Tabular Models.](http://arxiv.org/abs/2206.15306) | 深度表格模型的迁移学习在医学诊断等领域展现出了比传统方法更优异的性能，并且提出了应对上下游特征集不同情况的解决方法。 |
| [^167] | [FairGrad: Fairness Aware Gradient Descent.](http://arxiv.org/abs/2206.10923) | FairGrad是一种公平感知梯度下降方法，通过重新加权方案迭代学习群体特定权重来实现群体公平性。它易于实现，适用于各种标准的公平性定义，并且在各种数据集上与标准基线方法具有竞争力。 |
| [^168] | [CARLANE: A Lane Detection Benchmark for Unsupervised Domain Adaptation from Simulation to multiple Real-World Domains.](http://arxiv.org/abs/2206.08083) | 本论文提出了一个适用于2D车道检测的无监督域适应基准- CARLANE，包括模拟到多个真实世界领域的三个不同数据集。该基准数据集涵盖了多样的场景，并包含大量有注释的图片。此外，研究还提出了系统基准，用以评估方法的性能。 |
| [^169] | [A Search-Based Testing Approach for Deep Reinforcement Learning Agents.](http://arxiv.org/abs/2206.07813) | 本文提出一种基于搜索的测试方法，探索状态空间以检测DRL代理的安全性，并在三个基准测试中取得了比基线方法更高的状态空间覆盖率。 |
| [^170] | [Efficient decentralized multi-agent learning in asymmetric bipartite queueing systems.](http://arxiv.org/abs/2206.03324) | 该论文提出了一种简单的学习算法，使得在非对称二分排队系统中实现了高效的性能，并具备附加的鲁棒性质，并且提供了该问题的集中式情况下的首个经过证明的有效的UCB算法。 |
| [^171] | [Robust Fine-Tuning of Deep Neural Networks with Hessian-based Generalization Guarantees.](http://arxiv.org/abs/2206.02659) | 本文通过Hessian-based分析，提出一种基于距离的泛化度量方法，用于理解深度神经网络微调的泛化特性。通过PAC-Bayesian分析，给出了基于Hessian距离的微调模型泛化界。此外，还对微调面对标签噪声的问题进行了研究，并提出了一种相关算法和泛化误差保证。 |
| [^172] | [Persistent Homology of Coarse Grained State Space Networks.](http://arxiv.org/abs/2206.02530) | 本研究利用持续同调分析复杂过渡网络，发现粗粒化状态空间网络能够更好地捕捉底层动态系统的丰富信息，提高动态状态检测和噪声鲁棒性。 |
| [^173] | [Parallel and Distributed Graph Neural Networks: An In-Depth Concurrency Analysis.](http://arxiv.org/abs/2205.09702) | 这项研究深入分析了并行和分布式图神经网络，在设计了并行性分类方法后，研究了各种GNN模型、任务、软件框架和硬件加速器中的并行性，并重点关注相关张量的稀疏性/密度。 |
| [^174] | [Variational Inference for Bayesian Bridge Regression.](http://arxiv.org/abs/2205.09515) | 本文研究了自动微分变分推断在具有桥惩罚的回归模型上的应用，该方法通过使用小批量数据并提供全贝叶斯推断结果来加速计算时间。通过在B样条非参数回归模型上进行的模拟研究，验证了该方法的性能。 |
| [^175] | [MM-BD: Post-Training Detection of Backdoor Attacks with Arbitrary Backdoor Pattern Types Using a Maximum Margin Statistic.](http://arxiv.org/abs/2205.06900) | 本研究提出了一种后训练的后门防御方法，可以检测任意类型的后门嵌入攻击，而不需要对嵌入函数做任何假设。 |
| [^176] | [kNN-Embed: Locally Smoothed Embedding Mixtures For Multi-interest Candidate Retrieval.](http://arxiv.org/abs/2205.06205) | kNN-Embed是一种用于改善密集近似最近邻检索多样性的通用方法，通过将每个用户表示为平滑混合的学习项目聚类，实现了返回反映用户多个兴趣的多样候选集合。 |
| [^177] | [Kernel Robust Hypothesis Testing.](http://arxiv.org/abs/2203.12777) | 本文使用核方法构造不确定性集，在贝叶斯设置和Neyman-Pearson设置中分别研究了最小化最坏情况下错误概率和控制错误概率的问题，并提出了基于MMD的一系列测试。 |
| [^178] | [KINet: Unsupervised Forward Models for Robotic Pushing Manipulation.](http://arxiv.org/abs/2202.09006) | 本文介绍了一种名为KINet的无监督框架，用于推理对象之间的相互作用。通过学习关键点表示和关系，该模型可以自动推广到不同场景中，并成功预测未来的关键点状态。 |
| [^179] | [D4: Detection of Adversarial Diffusion Deepfakes Using Disjoint Ensembles.](http://arxiv.org/abs/2202.05687) | D4是一个使用不相交集合的深度伪造图像检测器，利用频域中的冗余和显著性分割技术提高对抗鲁棒性，减少了输入子空间维度，使对抗性深度伪造图像更难被发现。 |
| [^180] | [Machine Unlearning of Features and Labels.](http://arxiv.org/abs/2108.11577) | 本文提出了一种针对特征和标签的机器退训练方法，通过影响函数和模型参数的封闭形式更新，能够回溯性地调整训练数据对学习模型的影响，实现数据泄露和隐私问题的纠正。 |
| [^181] | [$C^3$: Compositional Counterfactual Contrastive Learning for Video-grounded Dialogues.](http://arxiv.org/abs/2106.08914) | 本研究提出了一种名为$C^3$的新方法，通过对视频对话中的事实和反事实样本进行对比训练，以实现对于视频和对话上下文相关的回应生成。该方法利用了对象级或动作级的对比损失函数，旨在提高多模态推理能力和泛化能力。 |
| [^182] | [Token-Modification Adversarial Attacks for Natural Language Processing: A Survey.](http://arxiv.org/abs/2103.00676) | 这项调研对现有的自然语言处理中的标记修改对抗攻击进行了分类和比较，并旨在指导新的研究并推动进一步的攻击组件研究。 |
| [^183] | [Lazy OCO: Online Convex Optimization on a Switching Budget.](http://arxiv.org/abs/2102.03803) | 本研究提出了一种懒惰型在线凸优化的算法，其在切换次数有限的情况下达到了近似最优的遗憾上界，并且在连续设置中呈现出高效的计算性能。 |
| [^184] | [Bandits in Matching Markets: Ideas and Proposals for Peer Lending.](http://arxiv.org/abs/2011.04400) | 本文探讨了匹配市场中P2P借贷的市场设计和抽象，通过将其建模为一个优化问题，同时考虑市场两边的代理人效用和对借款人公平分配的影响。通过基于顺序决策的技术，贷款人可以根据竞争的动态调整选择，影响其投资回报。模拟实验显示贷款人的遗憾取决于初始偏好设置。 |
| [^185] | [Class-incremental Learning with Pre-allocated Fixed Classifiers.](http://arxiv.org/abs/2010.08657) | 本文提出了一种具有预分配固定分类器的类增量学习方法，通过利用存储在情节性记忆中的过去数据，并在学习阶段的开始就将一些预分配的输出节点纳入分类损失的计算，解决了神经网络在类增量学习中遗忘先前知识的问题。 |
| [^186] | [Spatio-Temporal EEG Representation Learning on Riemannian Manifold and Euclidean Space.](http://arxiv.org/abs/2008.08633) | 本论文提出一种新的深度神经网络架构，用于学习脑电图信号。该模型通过黎曼流形和欧几里德空间学习空间信息，并通过差分熵和对数功率谱密度特征学习时间信息。通过有效的融合策略，结合空间和时间信息来进行决策。在多个公共数据集上进行了验证。 |
| [^187] | [Automated Detection and Forecasting of COVID-19 using Deep Learning Techniques: A Review.](http://arxiv.org/abs/2007.10785) | 这项研究综述了使用深度学习技术进行COVID-19诊断和预测的研究，深度学习模型可以自动完成特征提取、特征选择和分类的所有阶段，为COVID-19的医学诊断提供了一种高性能且一致的方法。 |
| [^188] | [Introduction to Online Convex Optimization.](http://arxiv.org/abs/1909.05207) | 本文将优化描述为一个过程，在实际应用中，采用在线学习的优化方法对复杂环境进行优化建模，并取得了引人注目的成就。 |
| [^189] | [Counterfactual Inference for Consumer Choice Across Many Product Categories.](http://arxiv.org/abs/1906.02635) | 本文提出了一种方法用于估计消费者在多个产品类别中的偏好选择。我们利用机器学习的概率模型，考虑了时变产品属性和产品缺货的情况，并展示了我们的模型相较于传统方法的改进之处在于能够准确估计偏好的异质性。 |

# 详细

[^1]: 物理信息的高斯过程模型用于欧拉-伯努利梁元素

    Physics-informed Gaussian process model for Euler-Bernoulli beam elements. (arXiv:2308.02894v1 [stat.ML])

    [http://arxiv.org/abs/2308.02894](http://arxiv.org/abs/2308.02894)

    该论文介绍了一种基于物理信息的高斯过程模型，通过欧拉-伯努利梁方程建模，并应用于结构的弯曲刚度回归、响应插值和概率推断。该模型在悬臂梁上进行了实际应用，并用于结构健康监测。实验结果验证了该框架的有效性。

    

    通过使用欧拉-伯努利梁方程，构建了一种以多输出高斯过程形式的物理信息机器学习模型。在合适的数据集下，该模型可以用于回归结构的弯曲刚度的解析值、插值响应以及对潜在物理量进行概率推断。该模型被应用于数值模拟的悬臂梁上，评估了回归的弯曲刚度，并研究了预测质量受测量噪声的影响。此外，利用回归得到的概率刚度分布，在结构健康监测背景下，采用马氏距离来推断结构系统中可能的损伤位置和范围。为了验证开发的框架，进行了一项实验，使用测量的异质数据集来更新假定的解析结构模型。

    A physics-informed machine learning model, in the form of a multi-output Gaussian process, is formulated using the Euler-Bernoulli beam equation. Given appropriate datasets, the model can be used to regress the analytical value of the structure's bending stiffness, interpolate responses, and make probabilistic inferences on latent physical quantities. The developed model is applied on a numerically simulated cantilever beam, where the regressed bending stiffness is evaluated and the influence measurement noise on the prediction quality is investigated. Further, the regressed probabilistic stiffness distribution is used in a structural health monitoring context, where the Mahalanobis distance is employed to reason about the possible location and extent of damage in the structural system. To validate the developed framework, an experiment is conducted and measured heterogeneous datasets are used to update the assumed analytical structural model.
    
[^2]: 多个窃听者下的安全深度 JSCC

    Secure Deep-JSCC Against Multiple Eavesdroppers. (arXiv:2308.02892v1 [cs.IT])

    [http://arxiv.org/abs/2308.02892](http://arxiv.org/abs/2308.02892)

    本文研究了一种对多个窃听者的安全通信的深度学习辅助联合源信道编码（Deep-JSCC）方法的推广。通过推广隐私漏斗和窃听信道编码的思想，刻画了合法节点图像恢复与信息泄漏给窃听者之间的权衡。

    

    本文研究了一种对多个窃听者的安全通信的深度学习辅助联合源信道编码（Deep-JSCC）方法的推广。我们提出了一种基于端到端（E2E）学习的方法，用于在复值衰落信道上抵御多个窃听者的安全通信。我们研究了窃听者合谋和非合谋的情况。对于合谋策略，窃听者共享其逻辑以基于集成学习方法共同推测私有属性，而对于非合谋设置，他们独自行动。目标是防止窃听者推测有关传输图像的私人（敏感）信息，同时以最小失真将图像传递给合法接收者。通过推广隐私漏斗和窃听信道编码的思想，刻画了合法节点图像恢复与信息泄漏给窃听者之间的权衡。为了解决这个保密漏斗框架，我们实现了...

    In this paper, a generalization of deep learning-aided joint source channel coding (Deep-JSCC) approach to secure communications is studied. We propose an end-to-end (E2E) learning-based approach for secure communication against multiple eavesdroppers over complex-valued fading channels. Both scenarios of colluding and non-colluding eavesdroppers are studied. For the colluding strategy, eavesdroppers share their logits to collaboratively infer private attributes based on ensemble learning method, while for the non-colluding setup they act alone. The goal is to prevent eavesdroppers from inferring private (sensitive) information about the transmitted images, while delivering the images to a legitimate receiver with minimum distortion. By generalizing the ideas of privacy funnel and wiretap channel coding, the trade-off between the image recovery at the legitimate node and the information leakage to the eavesdroppers is characterized. To solve this secrecy funnel framework, we implement 
    
[^3]: 私密联邦学习的动态功率控制与非相干空中计算方法

    Private Federated Learning with Dynamic Power Control via Non-Coherent Over-the-Air Computation. (arXiv:2308.02881v1 [cs.LG])

    [http://arxiv.org/abs/2308.02881](http://arxiv.org/abs/2308.02881)

    通过动态功率控制的非相干空中计算方法实现了私密联邦学习，提高了模型性能并保护了模型参数的隐私。

    

    为了进一步保护模型参数的隐私，并提高联邦学习中的模型性能，提出了一种基于动态功率控制的非相干空中计算方案。边缘设备通过激活两个相邻的正交频分多路复用（OFDM）子载波来传输本地随机梯度的符号，并利用子载波上的能量累积获得边缘服务器上的多数投票结果。然后，我们提出了一种动态功率控制算法来进一步抵消多数投票聚合值的偏差。我们证明了整个方案可以减轻时间同步误差、信道衰落和噪声的影响。该方案的理论收敛性证明也被重新推导出来。

    To further preserve model weight privacy and improve model performance in Federated Learning (FL), FL via Over-the-Air Computation (AirComp) scheme based on dynamic power control is proposed. The edge devices (EDs) transmit the signs of local stochastic gradients by activating two adjacent orthogonal frequency division multi-plexing (OFDM) subcarriers, and majority votes (MVs) at the edge server (ES) are obtained by exploiting the energy accumulation on the subcarriers. Then, we propose a dynamic power control algorithm to further offset the biased aggregation of the MV aggregation values. We show that the whole scheme can mitigate the impact of the time synchronization error, channel fading and noise. The theoretical convergence proof of the scheme is re-derived.
    
[^4]: 在医疗领域的元学习：一项调查研究。

    Meta-learning in healthcare: A survey. (arXiv:2308.02877v1 [cs.LG])

    [http://arxiv.org/abs/2308.02877](http://arxiv.org/abs/2308.02877)

    元学习在医疗领域有广泛应用，可以解决医疗挑战，如样本不足和数据收集差异。主要包括多/单任务学习和多/少样本学习方法。

    

    作为机器学习的一个子集，元学习旨在通过利用先前的知识和经验来提高模型的能力。元学习范式可以适当地解决传统学习方法所面临的挑战，如样本数量不足、领域转移和泛化问题。这些独特的特点使元学习成为在各种医疗环境中开发有影响力的解决方案的合适选择，这些环境中可用数据通常不足，并且数据收集方法也不同。本调查讨论了元学习在医疗领域的广泛应用，以了解它如何以及在哪些方面可以解决关键的医疗挑战。我们首先描述了元学习的理论基础和关键方法。然后将在医疗领域应用的元学习方法分为多/单任务学习和多/少样本学习两大类。

    As a subset of machine learning, meta-learning, or learning to learn, aims at improving the model's capabilities by employing prior knowledge and experience. A meta-learning paradigm can appropriately tackle the conventional challenges of traditional learning approaches, such as insufficient number of samples, domain shifts, and generalization. These unique characteristics position meta-learning as a suitable choice for developing influential solutions in various healthcare contexts, where the available data is often insufficient, and the data collection methodologies are different. This survey discusses meta-learning broad applications in the healthcare domain to provide insight into how and where it can address critical healthcare challenges. We first describe the theoretical foundations and pivotal methods of meta-learning. We then divide the employed meta-learning approaches in the healthcare domain into two main categories of multi/single-task learning and many/few-shot learning a
    
[^5]: 基于数据的多模型推理传感器设计

    Data-Based Design of Multi-Model Inferential Sensors. (arXiv:2308.02872v1 [cs.LG])

    [http://arxiv.org/abs/2308.02872](http://arxiv.org/abs/2308.02872)

    本文提出了两种新方法来设计多模型推理传感器，旨在减轻现有方法的一些缺点。通过设计真实的石化炼厂单元推理传感器进行演示，结果显示在多个指标上取得了显著的改进。

    

    本文研究推理（软）传感器设计的问题。工业过程的非线性特性通常是设计简单线性推理传感器时的主要限制，由于需要保持线性结构，为了提高推理传感器的预测性能，多模型推理传感器是一个直接的选择。在本文中，我们提出了两种用于设计多模型推理传感器的新方法，旨在减轻现有方法的一些缺点。为了演示所开发技术的性能，我们设计了一个真实的石化炼厂单元——真空加气体油加氢装置的推理传感器。将多模型推理传感器的性能与各种单模型推理传感器以及炼厂中当前（参考）传感器进行了比较。结果显示，在现有技术的基础上取得了显著的改进。

    This paper deals with the problem of inferential (soft) sensor design. The nonlinear character of industrial processes is usually the main limitation to designing simple linear inferential sensors with sufficient accuracy. In order to increase the inferential sensor predictive performance and yet to maintain its linear structure, multi-model inferential sensors represent a straightforward option. In this contribution, we propose two novel approaches for the design of multi-model inferential sensors aiming to mitigate some drawbacks of the state-of-the-art approaches. For a demonstration of the developed techniques, we design inferential sensors for a Vacuum Gasoil Hydrogenation unit, which is a real-world petrochemical refinery unit. The performance of the multi-model inferential sensor is compared against various single-model inferential sensors and the current (referential) inferential sensor used in the refinery. The results show substantial improvements over the state-of-the-art de
    
[^6]: NP-SemiSeg: 当神经过程遇见半监督语义分割

    NP-SemiSeg: When Neural Processes meet Semi-Supervised Semantic Segmentation. (arXiv:2308.02866v1 [cs.CV])

    [http://arxiv.org/abs/2308.02866](http://arxiv.org/abs/2308.02866)

    将神经过程（NPs）应用于半监督语义分割，通过不确定性量化实现了模型对于未知内容的认知，提高了分割结果的质量和安全性。

    

    半监督语义分割涉及在训练时为无标签图像分配逐像素标签。在无法及时或成本高昂地收集逐像素标签的各种实际应用中，这是很有用的。当前的半监督语义分割方法通过从模型输出的类别概率分布中预测每个像素的伪标签来工作。然而，如果预测的概率分布是错误的，这会导致分割结果不佳，对于医疗图像或自动驾驶汽车等安全关键系统来说，可能产生连锁影响。因此，了解模型不知道的内容是很重要的，这主要通过不确定性量化来实现。最近，神经过程（NPs）已被应用于半监督图像分类，并且它们是一种计算高效且有效的不确定性量化方法。在这项工作中，我们进一步将NPs应用于半监督语义分割。

    Semi-supervised semantic segmentation involves assigning pixel-wise labels to unlabeled images at training time. This is useful in a wide range of real-world applications where collecting pixel-wise labels is not feasible in time or cost. Current approaches to semi-supervised semantic segmentation work by predicting pseudo-labels for each pixel from a class-wise probability distribution output by a model. If the predicted probability distribution is incorrect, however, this leads to poor segmentation results, which can have knock-on consequences in safety critical systems, like medical images or self-driving cars. It is, therefore, important to understand what a model does not know, which is mainly achieved by uncertainty quantification. Recently, neural processes (NPs) have been explored in semi-supervised image classification, and they have been a computationally efficient and effective method for uncertainty quantification. In this work, we move one step forward by adapting NPs to s
    
[^7]: 生成对抗网络在组织病理学染色标准化中的应用

    Generative Adversarial Networks for Stain Normalisation in Histopathology. (arXiv:2308.02851v1 [eess.IV])

    [http://arxiv.org/abs/2308.02851](http://arxiv.org/abs/2308.02851)

    本论文研究了生成对抗网络在数字病理学染色标准化中的应用，发现基于GAN的方法在染色标准化方面表现出色，但需要更大的计算资源。

    

    近年来，数字病理学的快速发展为基于人工智能的工具改善临床诊断的准确性和效率提供了理想的机会。然而，当前研究的一个重要障碍是数字病理学图像之间存在高水平的视觉变异性，导致模型对未见过的数据泛化能力较差。染色标准化旨在在不改变图像结构内容的情况下标准化数字病理学图像的视觉特征。在本章中，我们探讨了用于数字病理学染色标准化的不同技术，重点介绍了利用生成对抗网络（GANs）的方法。通常，基于GAN的方法优于非生成方法，但代价是更大的计算需求。然而，目前尚不清楚哪种方法对染色标准化更好，不同的GAN和非GAN方法相互之间表现出色。

    The rapid growth of digital pathology in recent years has provided an ideal opportunity for the development of artificial intelligence-based tools to improve the accuracy and efficiency of clinical diagnoses. One of the significant roadblocks to current research is the high level of visual variability across digital pathology images, causing models to generalise poorly to unseen data. Stain normalisation aims to standardise the visual profile of digital pathology images without changing the structural content of the images. In this chapter, we explore different techniques which have been used for stain normalisation in digital pathology, with a focus on approaches which utilise generative adversarial networks (GANs). Typically, GAN-based methods outperform non-generative approaches but at the cost of much greater computational requirements. However, it is not clear which method is best for stain normalisation in general, with different GAN and non-GAN approaches outperforming each othe
    
[^8]: 使用尺度不变神经网络逼近正齐次函数

    Approximating Positive Homogeneous Functions with Scale Invariant Neural Networks. (arXiv:2308.02836v1 [cs.LG])

    [http://arxiv.org/abs/2308.02836](http://arxiv.org/abs/2308.02836)

    本文研究使用尺度不变神经网络近似解决线性反问题的可行性，证明了单隐藏层ReLU网络无法恢复稀疏向量，但通过两个隐藏层可以稳定且精确地恢复任意稀疏程度的向量，此外还推广到了其他恢复问题。

    

    本文研究使用ReLU网络解决线性反问题的可能性。由于线性关系带来的尺度不变性，对于这类问题的最优重构函数f是正齐次函数，即满足对于所有非负的λ，有f(λx) = λf(x)。在ReLU网络中，这个条件转化为在网络中不考虑偏置项。我们首先考虑从少量线性测量中恢复稀疏向量的问题。我们证明单隐藏层的ReLU网络无法恢复1-稀疏向量，即使是近似恢复，而且不论网络的宽度如何。然而，通过两个隐藏层，可以以稳定的方式近似地恢复任意精度的、任意稀疏程度为s的向量。然后，我们将结果推广到包括低秩矩阵恢复和相位恢复在内的更广泛的恢复问题。此外，我们还考虑了对一般正齐次函数的逼近问题。

    We investigate to what extent it is possible to solve linear inverse problems with $ReLu$ networks. Due to the scaling invariance arising from the linearity, an optimal reconstruction function $f$ for such a problem is positive homogeneous, i.e., satisfies $f(\lambda x) = \lambda f(x)$ for all non-negative $\lambda$. In a $ReLu$ network, this condition translates to considering networks without bias terms. We first consider recovery of sparse vectors from few linear measurements. We prove that $ReLu$- networks with only one hidden layer cannot even recover $1$-sparse vectors, not even approximately, and regardless of the width of the network. However, with two hidden layers, approximate recovery with arbitrary precision and arbitrary sparsity level $s$ is possible in a stable way. We then extend our results to a wider class of recovery problems including low-rank matrix recovery and phase retrieval. Furthermore, we also consider the approximation of general positive homogeneous functio
    
[^9]: 针对金融指数跟踪的强化学习

    Reinforcement Learning for Financial Index Tracking. (arXiv:2308.02820v1 [q-fin.PM])

    [http://arxiv.org/abs/2308.02820](http://arxiv.org/abs/2308.02820)

    本论文提出了针对金融指数跟踪问题的第一个具有动态性的离散时间无穷期模型，它克服了现有模型的一些局限，可以精确计算交易成本，同时考虑了跟踪误差和交易成本之间的权衡，并能有效利用长时间段的数据。我们使用深度强化学习方法解决该模型，解决了由于数据限制导致的问题。

    

    我们提出了第一个离散时间无穷期动态形式的金融指数跟踪问题，同时考虑到基于收益的跟踪误差和基于价值的跟踪误差。该模型克服了现有模型的局限性，包括不仅限于价格的市场信息变量的时间动态性，可以精确计算交易成本，考虑跟踪误差和交易成本之间的权衡，可以有效利用长时间段的数据等。该模型还引入了现金注入或提取的新的决策变量。我们提出了使用Banach不动点迭代求解投资组合再平衡方程的方法，可以准确计算实践中指定为交易量的非线性函数的交易成本。我们还提出了扩展深度强化学习（RL）方法来解决动态模型。我们的RL方法解决了由数据限制引起的问题。

    We propose the first discrete-time infinite-horizon dynamic formulation of the financial index tracking problem under both return-based tracking error and value-based tracking error. The formulation overcomes the limitations of existing models by incorporating the intertemporal dynamics of market information variables not limited to prices, allowing exact calculation of transaction costs, accounting for the tradeoff between overall tracking error and transaction costs, allowing effective use of data in a long time period, etc. The formulation also allows novel decision variables of cash injection or withdraw. We propose to solve the portfolio rebalancing equation using a Banach fixed point iteration, which allows to accurately calculate the transaction costs specified as nonlinear functions of trading volumes in practice. We propose an extension of deep reinforcement learning (RL) method to solve the dynamic formulation. Our RL method resolves the issue of data limitation resulting fro
    
[^10]: 一种用于空间-时间野火预测的生成模型

    A generative model for surrogates of spatial-temporal wildfire nowcasting. (arXiv:2308.02810v1 [cs.LG])

    [http://arxiv.org/abs/2308.02810](http://arxiv.org/abs/2308.02810)

    本文提出了一种生成模型，利用三维量化变分自编码器来生成给定生态区域内未见的空间-时间野火燃烧区域序列。该模型在加利福尼亚州的Chimney火灾生态区域中进行了测试，结果表明该模型能够成功生成连贯且结构良好的火势情景。

    

    近年来全球野火数量的增加导致了对实时火势预测的需求。传统的物理模型，如元胞自动机和计算流体力学，可以提供高保真度的火势传播模拟，但耗时且计算复杂。目前已经有很多研究致力于开发机器学习模型进行火势预测，但这些模型往往特定于某个地区，并需要大量的模拟数据进行训练，这在不同生态区域中需要大量的计算工作。本文提出了一种生成模型，利用三维量化变分自编码器来生成给定生态区域内未见的空间-时间野火燃烧区域序列。该模型在加利福尼亚州最近的一次大规模野火事件 - Chimney火灾的生态区域中进行了测试。数值结果表明，该模型成功生成了连贯且有结构的火势情景。

    Recent increase in wildfires worldwide has led to the need for real-time fire nowcasting. Physics-driven models, such as cellular automata and computational fluid dynamics can provide high-fidelity fire spread simulations but they are computationally expensive and time-consuming. Much effort has been put into developing machine learning models for fire prediction. However, these models are often region-specific and require a substantial quantity of simulation data for training purpose. This results in a significant amount of computational effort for different ecoregions. In this work, a generative model is proposed using a three-dimensional Vector-Quantized Variational Autoencoders to generate spatial-temporal sequences of unseen wildfire burned areas in a given ecoregion. The model is tested in the ecoregion of a recent massive wildfire event in California, known as the Chimney fire. Numerical results show that the model succeed in generating coherent and structured fire scenarios, ta
    
[^11]: MiAMix: 通过多阶段增强混合样本数据增强方法提升图像分类

    MiAMix: Enhancing Image Classification through a Multi-stage Augmented Mixied Sample Data Augmentation Method. (arXiv:2308.02804v1 [cs.CV])

    [http://arxiv.org/abs/2308.02804](http://arxiv.org/abs/2308.02804)

    MiAMix是一种新型的混合样本数据增强方法，通过将图像增强集成到混合框架中并利用多种多样的混合方法来提升图像分类模型的性能和泛化能力。

    

    尽管深度学习领域取得了相当大的进展，但过拟合依然是一个关键的挑战。数据增强作为一种十分有前景的方法，因其能够增强模型在各种计算机视觉任务中的泛化能力而备受关注。虽然已经提出了各种各样的策略，但混合样本数据增强（MSDA）在增强模型性能和泛化能力方面显示出了巨大潜力。我们引入了一种称为MiAMix的新型混合方法，即多阶段增强混合。MiAMix将图像增强集成到混合框架中，同时利用多种多样的混合方法，并通过随机选择混合掩模增强方法来改进混合方法。最近的方法利用了显著性信息，而MiAMix的设计也考虑到了计算效率，减少了额外的开销，并且可以轻松集成到现有的训练流程中。我们对MiAMix进行了全面的评估，使用了四个图像基准和进行了比较。

    Despite substantial progress in the field of deep learning, overfitting persists as a critical challenge, and data augmentation has emerged as a particularly promising approach due to its capacity to enhance model generalization in various computer vision tasks. While various strategies have been proposed, Mixed Sample Data Augmentation (MSDA) has shown great potential for enhancing model performance and generalization. We introduce a novel mixup method called MiAMix, which stands for Multi-stage Augmented Mixup. MiAMix integrates image augmentation into the mixup framework, utilizes multiple diversified mixing methods concurrently, and improves the mixing method by randomly selecting mixing mask augmentation methods. Recent methods utilize saliency information and the MiAMix is designed for computational efficiency as well, reducing additional overhead and offering easy integration into existing training pipelines. We comprehensively evaluate MiaMix using four image benchmarks and pit
    
[^12]: OBESEYE: 使用机器学习和可解释的AI的可理解的肥胖管理饮食推荐器

    OBESEYE: Interpretable Diet Recommender for Obesity Management using Machine Learning and Explainable AI. (arXiv:2308.02796v1 [cs.LG])

    [http://arxiv.org/abs/2308.02796](http://arxiv.org/abs/2308.02796)

    OBESEYE是一款基于机器学习和可解释AI的可理解的肥胖管理饮食推荐器，能够预测个体所需的营养物质量，对肥胖管理具有重要贡献。

    

    肥胖是许多非传染性疾病的主要原因，主要是因为摄入超过身体需求和缺乏适当的活动。因此，保持健康需要健康的饮食计划，特别是对于患有共病的患者。但是，要确定每种营养物质的确切数量是困难的，因为营养物质的需求根据身体和疾病的情况而变化。在我们的研究中，我们提出了一种基于机器学习的新颖系统，用于预测一个人保持健康所需的营养物质的数量。我们应用了不同的机器学习算法：线性回归、支持向量机（SVM）、决策树、随机森林、XGBoost、LightGBM在流体和3种其他主要微量营养素（碳水化合物、蛋白质、脂肪）的消耗预测上。我们使用线性回归在流体预测中获得了高准确性和低均方根误差（RMSE），使用随机森林在碳水化合物预测中，使用LightGBM在蛋白质和脂肪预测中取得了高准确性和低均方根误差（RMSE）。我们认为我们的饮食推荐器会对肥胖管理有重要贡献。

    Obesity, the leading cause of many non-communicable diseases, occurs mainly for eating more than our body requirements and lack of proper activity. So, being healthy requires heathy diet plans, especially for patients with comorbidities. But it is difficult to figure out the exact quantity of each nutrient because nutrients requirement varies based on physical and disease conditions. In our study we proposed a novel machine learning based system to predict the amount of nutrients one individual requires for being healthy. We applied different machine learning algorithms: linear regression, support vector machine (SVM), decision tree, random forest, XGBoost, LightGBM on fluid and 3 other major micronutrients: carbohydrate, protein, fat consumption prediction. We achieved high accuracy with low root mean square error (RMSE) by using linear regression in fluid prediction, random forest in carbohydrate prediction and LightGBM in protein and fat prediction. We believe our diet recommender s
    
[^13]: 半监督对比回归方法用于眼球注视估计

    Semi-supervised Contrastive Regression for Estimation of Eye Gaze. (arXiv:2308.02784v1 [cs.CV])

    [http://arxiv.org/abs/2308.02784](http://arxiv.org/abs/2308.02784)

    本文提出了一种用于眼球注视估计的半监督对比回归方法。该方法利用小规模标记的数据集来寻找泛化解决方案，能够在未见面部图像上进行准确的估计。通过引入新的对比损失范式，该方法在性能上表现出色。

    

    随着智能系统对人机界面的需求不断增长，开发眼球控制系统已成为必要。眼球注视作为一种非侵入性的人机交互方式，是最适合的方法之一。基于外观的深度学习模型是眼球注视估计中最常用的方法。但是，这些模型的性能完全受到标记的眼球注视数据集的大小的影响，并且这种影响会影响性能的泛化能力。本文旨在开发一种用于眼球注视方向估计的半监督对比学习框架。在标记的眼球注视数据集较小的情况下，该框架能够找到一个泛化的解决方案，即使是看不见的人脸图像也能进行估计。我们提出了一种新的对比损失范式，既最大化了相似图片之间的相似性，同时减少了嵌入表示中的冗余。我们的对比回归框架在性能上表现良好，优于其他一些最先进的方法。

    With the escalated demand of human-machine interfaces for intelligent systems, development of gaze controlled system have become a necessity. Gaze, being the non-intrusive form of human interaction, is one of the best suited approach. Appearance based deep learning models are the most widely used for gaze estimation. But the performance of these models is entirely influenced by the size of labeled gaze dataset and in effect affects generalization in performance. This paper aims to develop a semi-supervised contrastive learning framework for estimation of gaze direction. With a small labeled gaze dataset, the framework is able to find a generalized solution even for unseen face images. In this paper, we have proposed a new contrastive loss paradigm that maximizes the similarity agreement between similar images and at the same time reduces the redundancy in embedding representations. Our contrastive regression framework shows good performance in comparison to several state of the art con
    
[^14]: 从脑电图中揭示情绪：一种基于GRU的方法

    Unveiling Emotions from EEG: A GRU-Based Approach. (arXiv:2308.02778v1 [eess.SP])

    [http://arxiv.org/abs/2308.02778](http://arxiv.org/abs/2308.02778)

    本研究通过使用GRU算法对脑电图数据进行情绪识别，取得了出色的结果，并且相对于其他机器学习技术具有最高的准确率。

    

    情感计算中最重要的研究领域之一是使用脑电图数据进行情绪识别。本研究测试了门控循环单元（GRU）算法，这是一种循环神经网络（RNNs）的类型，看它是否能够利用脑电图信号来预测情绪状态。我们的公开可访问数据集包括静息中性数据以及接受引发快乐、中性和消极情绪的刺激的人的脑电图记录。为了进行最佳特征提取，我们使用伪迹去除、带通滤波器和归一化方法对脑电图数据进行预处理。在验证集上达到100%的准确率后，我们的模型利用GRU捕捉时间依赖性的能力取得了出色的结果。与其他机器学习技术相比，我们的GRU模型的极端梯度提升分类器具有最高的准确率。我们对混淆矩阵进行的详细研究揭示了有关模型性能的有价值信息，从而使精准的情绪识别成为可能。

    One of the most important study areas in affective computing is emotion identification using EEG data. In this study, the Gated Recurrent Unit (GRU) algorithm, which is a type of Recurrent Neural Networks (RNNs), is tested to see if it can use EEG signals to predict emotional states. Our publicly accessible dataset consists of resting neutral data as well as EEG recordings from people who were exposed to stimuli evoking happy, neutral, and negative emotions. For the best feature extraction, we pre-process the EEG data using artifact removal, bandpass filters, and normalization methods. With 100% accuracy on the validation set, our model produced outstanding results by utilizing the GRU's capacity to capture temporal dependencies. When compared to other machine learning techniques, our GRU model's Extreme Gradient Boosting Classifier had the highest accuracy. Our investigation of the confusion matrix revealed insightful information about the performance of the model, enabling precise em
    
[^15]: Dataopsy: 可扩展和流动的可视化探索方法——使用聚合查询雕刻

    Dataopsy: Scalable and Fluid Visual Exploration using Aggregate Query Sculpting. (arXiv:2308.02764v1 [cs.LG])

    [http://arxiv.org/abs/2308.02764](http://arxiv.org/abs/2308.02764)

    Dataopsy是一种可扩展和流动的可视化探索方法，使用聚合查询雕刻（AQS）作为一种分面可视化查询技术，可以从整个数据集的聚合开始，逐步探索数据集。

    

    本文介绍了一种适用于大规模多维数据的分面可视化查询技术，称为聚合查询雕刻（AQS）。作为一种“天生可扩展”的查询技术，AQS从一个表示整个数据集聚合的单个视觉标记开始可视化。用户可以通过一系列操作逐步探索数据集，这些操作缩写为P6：枢轴（基于属性对聚合进行分面），分割（将分面布局在空间中），窥视（使用聚合视觉表示查看子集），堆积（合并两个或多个子集），投影（将子集提取到新的基质），和修剪（丢弃当前不感兴趣的聚合）。我们使用Dataopsy来验证AQS，它是AQS的原型实现，旨在在桌面和触摸式移动设备上实现流畅的交互。我们使用两个案例研究和三个应用示例来展示AQS和Dataopsy。

    We present aggregate query sculpting (AQS), a faceted visual query technique for large-scale multidimensional data. As a "born scalable" query technique, AQS starts visualization with a single visual mark representing an aggregation of the entire dataset. The user can then progressively explore the dataset through a sequence of operations abbreviated as P6: pivot (facet an aggregate based on an attribute), partition (lay out a facet in space), peek (see inside a subset using an aggregate visual representation), pile (merge two or more subsets), project (extracting a subset into a new substrate), and prune (discard an aggregate not currently of interest). We validate AQS with Dataopsy, a prototype implementation of AQS that has been designed for fluid interaction on desktop and touch-based mobile devices. We demonstrate AQS and Dataopsy using two case studies and three application examples.
    
[^16]: 分类神经网络中间隐藏层的神经崩溃

    Neural Collapse in the Intermediate Hidden Layers of Classification Neural Networks. (arXiv:2308.02760v1 [cs.LG])

    [http://arxiv.org/abs/2308.02760](http://arxiv.org/abs/2308.02760)

    本论文首次对分类神经网络中间隐藏层的神经崩溃进行了全面的实证分析。研究发现，大多数中间隐藏层都会出现某种程度的神经崩溃，而崩溃程度通常与层的深度呈正相关。此外，研究还发现类内方差的减小主要发生在较浅的层中，夹角分离量随隐藏层深度的增加而增加。

    

    神经崩溃（NC）对分类神经网络中最终隐藏层中类别的表示提供了精确的描述。这个描述揭示了这些网络如何在训练超过零训练误差时学习特征和泛化。然而，迄今为止，（NC）只在这些网络的最终层中进行研究。在本论文中，我们首次对这些分类器的中间隐藏层中（NC）的出现进行了全面的实证分析。我们检查了各种网络架构、激活函数和数据集，并证明了在网络的大多数中间隐藏层中会出现某种程度的（NC），其中每个隐藏层的崩溃程度通常与该层在神经网络中的深度呈正相关。此外，我们还指出：（1）样本中的几乎所有类内方差的减小发生在更浅的层中，（2）夹角分离量随隐藏层深度的增加而增加。

    Neural Collapse (NC) gives a precise description of the representations of classes in the final hidden layer of classification neural networks. This description provides insights into how these networks learn features and generalize well when trained past zero training error. However, to date, (NC) has only been studied in the final layer of these networks. In the present paper, we provide the first comprehensive empirical analysis of the emergence of (NC) in the intermediate hidden layers of these classifiers. We examine a variety of network architectures, activations, and datasets, and demonstrate that some degree of (NC) emerges in most of the intermediate hidden layers of the network, where the degree of collapse in any given layer is typically positively correlated with the depth of that layer in the neural network. Moreover, we remark that: (1) almost all of the reduction in intra-class variance in the samples occurs in the shallower layers of the networks, (2) the angular separa
    
[^17]: DaMSTF: 领域对抗学习增强的领域自我训练适应性

    DaMSTF: Domain Adversarial Learning Enhanced Meta Self-Training for Domain Adaptation. (arXiv:2308.02753v1 [cs.LG])

    [http://arxiv.org/abs/2308.02753](http://arxiv.org/abs/2308.02753)

    DaMSTF是一种领域适应的自我训练框架，通过使用元学习来减少标签噪声并保留困难的例子。

    

    自我训练在领域适应中成为一个重要的研究方向。通过将模型的预测作为无标签数据的伪标签，自我训练利用目标领域中的伪实例来引导模型。然而，伪标签的预测错误（标签噪声）挑战了自我训练的性能。为了解决这个问题，先前的方法只使用可靠的伪实例，即具有高预测置信度的伪实例来重新训练模型。虽然这些策略有效地减少了标签噪声，但容易错过困难的例子。在本文中，我们提出了一种新的领域适应自我训练框架，即领域对抗学习增强自我训练框架（DaMSTF）。首先，DaMSTF通过元学习估计每个伪实例的重要性，以同时减少标签噪声和保留困难的例子。其次，我们设计了一个元构造器来构造元验证堆栈。

    Self-training emerges as an important research line on domain adaptation. By taking the model's prediction as the pseudo labels of the unlabeled data, self-training bootstraps the model with pseudo instances in the target domain. However, the prediction errors of pseudo labels (label noise) challenge the performance of self-training. To address this problem, previous approaches only use reliable pseudo instances, i.e., pseudo instances with high prediction confidence, to retrain the model. Although these strategies effectively reduce the label noise, they are prone to miss the hard examples. In this paper, we propose a new self-training framework for domain adaptation, namely Domain adversarial learning enhanced Self-Training Framework (DaMSTF). Firstly, DaMSTF involves meta-learning to estimate the importance of each pseudo instance, so as to simultaneously reduce the label noise and preserve hard examples. Secondly, we design a meta constructor for constructing the meta-validation se
    
[^18]: NeRFs: 寻找最佳3D表示的研究

    NeRFs: The Search for the Best 3D Representation. (arXiv:2308.02751v1 [cs.CV])

    [http://arxiv.org/abs/2308.02751](http://arxiv.org/abs/2308.02751)

    NeRFs是视图合成和相关问题中寻找最佳3D表示的结果，该方法利用神经网络查询获取体积参数来描述连续体积场景。

    

    神经辐射场（NeRFs）已成为视图合成或基于图像渲染等问题的首选表示方法，也应用于计算机图形学和计算机视觉等多个领域。NeRFs通过查询神经网络获得视图相关辐射和体积密度等体积参数，将场景表示为连续的体积。该表示方法已广泛应用，每年有数千篇论文在其基础上扩展或相关研究，多位作者和网站提供概述和调研，并有众多工业应用和创业公司。本文简要回顾了NeRFs的表示方法，并描述了长达三十年的寻找最佳3D表示方法以及最终引出NeRFs论文的过程。

    Neural Radiance Fields or NeRFs have become the representation of choice for problems in view synthesis or image-based rendering, as well as in many other applications across computer graphics and vision, and beyond. At their core, NeRFs describe a new representation of 3D scenes or 3D geometry. Instead of meshes, disparity maps, multiplane images or even voxel grids, they represent the scene as a continuous volume, with volumetric parameters like view-dependent radiance and volume density obtained by querying a neural network. The NeRF representation has now been widely used, with thousands of papers extending or building on it every year, multiple authors and websites providing overviews and surveys, and numerous industrial applications and startup companies. In this article, we briefly review the NeRF representation, and describe the three decades-long quest to find the best 3D representation for view synthesis and related problems, culminating in the NeRF papers. We then describe n
    
[^19]: 利用Versal体系结构的片上异构性加速GNN推理

    Exploiting On-chip Heterogeneity of Versal Architecture for GNN Inference Acceleration. (arXiv:2308.02749v1 [cs.AR])

    [http://arxiv.org/abs/2308.02749](http://arxiv.org/abs/2308.02749)

    该论文利用AMD Versal ACAP架构的异构计算能力，通过开发自定义硬件模块和设计运行时内核映射策略，实现了对GNN推理的加速。该方法在VCK5000 ACAP平台上的实现具有优越性能。

    

    图神经网络（GNN）在社交网络分析、生物信息学等许多机器学习（ML）应用中都取得了革命性的突破。通过利用输入图中的数据稀疏性、顶点特征和GNN计算中的中间数据，可以加速GNN推理。为了实现动态稀疏性利用，我们利用AMD Versal ACAP架构的异构计算能力来加速GNN推理。我们开发了一个自定义硬件模块，该模块在可编程逻辑（PL）上执行计算核心的稀疏原语，并使用AI引擎（AIE）高效计算密集型原语。为了在推理过程中利用数据稀疏性，我们设计了一种运行时内核映射策略，根据数据稀疏性动态分配计算任务给PL和AIE。在VCK5000 ACAP平台上的实现相比于CPU、GPU、ACAP和其他自定义GNN加速器的最新实现具有更优异的性能。

    Graph Neural Networks (GNNs) have revolutionized many Machine Learning (ML) applications, such as social network analysis, bioinformatics, etc. GNN inference can be accelerated by exploiting data sparsity in the input graph, vertex features, and intermediate data in GNN computations. For dynamic sparsity exploitation, we leverage the heterogeneous computing capabilities of AMD Versal ACAP architecture to accelerate GNN inference. We develop a custom hardware module that executes the sparse primitives of the computation kernel on the Programmable Logic (PL) and efficiently computes the dense primitives using the AI Engine (AIE). To exploit data sparsity during inference, we devise a runtime kernel mapping strategy that dynamically assigns computation tasks to the PL and AIE based on data sparsity. Our implementation on the VCK5000 ACAP platform leads to superior performance compared with the state-of-the-art implementations on CPU, GPU, ACAP, and other custom GNN accelerators. Compared 
    
[^20]: SABRE:强鲁棒贝叶斯点对点联邦学习

    SABRE: Robust Bayesian Peer-to-Peer Federated Learning. (arXiv:2308.02747v1 [cs.LG])

    [http://arxiv.org/abs/2308.02747](http://arxiv.org/abs/2308.02747)

    SABRE是一种强鲁棒性变分贝叶斯点对点联邦学习框架，通过新的聚合方法克服了现有框架的局限性，在非IID环境中表现良好，对数据/模型攻击具备鲁棒性，在图像分类数据上优于现有框架。

    

    我们引入了SABRE，一种新颖的强鲁棒性变分贝叶斯点对点联邦学习框架。我们分析了已知的变分贝叶斯点对点联邦学习框架（BayP2PFL）的抗攻击性，随后证明了BayP2PFL在面对这些攻击时不具备鲁棒性。然后，我们提出了SABRE聚合方法来克服现有框架的局限性。SABRE在非IID环境中表现良好，不要求大多数良性节点多于受损节点，并且在良性环境下甚至优于基准算法。我们从去中心化线性回归设置中在理论上证明了我们算法对数据/模型攻击的鲁棒性。对基准图像分类数据进行的概念证明评估显示了SABRE在各种攻击下优于现有框架的卓越性能。

    We introduce SABRE, a novel framework for robust variational Bayesian peer-to-peer federated learning. We analyze the robustness of the known variational Bayesian peer-to-peer federated learning framework (BayP2PFL) against poisoning attacks and subsequently show that BayP2PFL is not robust against those attacks. The new SABRE aggregation methodology is then devised to overcome the limitations of the existing frameworks. SABRE works well in non-IID settings, does not require the majority of the benign nodes over the compromised ones, and even outperforms the baseline algorithm in benign settings. We theoretically prove the robustness of our algorithm against data / model poisoning attacks in a decentralized linear regression setting. Proof-of-Concept evaluations on benchmark data from image classification demonstrate the superiority of SABRE over the existing frameworks under various poisoning attacks.
    
[^21]: 元-Tsallis-熵最小化：一种新的领域自适应文本分类自训练方法

    Meta-Tsallis-Entropy Minimization: A New Self-Training Approach for Domain Adaptation on Text Classification. (arXiv:2308.02746v1 [cs.CL])

    [http://arxiv.org/abs/2308.02746](http://arxiv.org/abs/2308.02746)

    元-Tsallis-熵最小化是一种新的自适应文本分类领域自适应方法，通过优化目标域上的实例自适应Tsallis熵来解决自训练在大领域转移时失败的问题。

    

    文本分类是自然语言处理的基本任务，跨领域适应文本分类模型具有广泛应用。自训练通过从模型的预测结果中生成伪样本，并迭代在伪样本上进行训练，即在源域上最小化损失，在目标域上最小化Gibbs熵。然而，Gibbs熵对预测误差非常敏感，因此当领域转移较大时，自训练往往会失败。在本文中，我们提出了元-Tsallis-熵最小化（MTEM）方法，该方法应用元学习算法来优化目标域上的实例自适应Tsallis熵。为了降低MTEM的计算成本，我们提出了一种近似技术来近似元学习中涉及的二阶导数。为了高效生成伪标签，我们提出了一种退火采样机制来探索模型的预测概率。从理论上讲，我们证明了m的收敛性

    Text classification is a fundamental task for natural language processing, and adapting text classification models across domains has broad applications. Self-training generates pseudo-examples from the model's predictions and iteratively trains on the pseudo-examples, i.e., minimizes the loss on the source domain and the Gibbs entropy on the target domain. However, Gibbs entropy is sensitive to prediction errors, and thus, self-training tends to fail when the domain shift is large. In this paper, we propose Meta-Tsallis Entropy minimization (MTEM), which applies a meta-learning algorithm to optimize the instance adaptive Tsallis entropy on the target domain. To reduce the computation cost of MTEM, we propose an approximation technique to approximate the Second-order derivation involved in the meta-learning. To efficiently generate pseudo labels, we propose an annealing sampling mechanism for exploring the model's prediction probability. Theoretically, we prove the convergence of the m
    
[^22]: 学习在未知统计量的非稳态无线网络中进行调度

    Learning to Schedule in Non-Stationary Wireless Networks With Unknown Statistics. (arXiv:2308.02734v1 [cs.NI])

    [http://arxiv.org/abs/2308.02734](http://arxiv.org/abs/2308.02734)

    本文提出了一种适用于未知统计量的非稳态无线网络中进行调度的有效算法，该算法基于最大权重策略，并利用滑动窗口上界置信度来学习信道的状态。在假设平均服务率的变异性温和的前提下，该算法在吞吐量方面是最优的。

    

    大规模无线网络的出现，带来了对设计最佳控制策略的新挑战，因为这些网络具有部分可观察和时变动态。本文研究了在具有广义干扰约束的无线网络中的有效调度算法，其中平均到达率和平均服务率是未知和非稳态的。该模型展示了现代网络中无线通信的边缘设备的实际特征。我们提出了一种新颖的算法，称为MW-UCB，用于广义无线网络调度，它基于最大权重策略，并利用滑动窗口上界置信度来学习非稳态下的信道统计量。在对平均服务率的变异性提出温和假设的前提下，我们证明了MW-UCB在吞吐量方面是最优的。具体来说，只要在任何时间段内平均服务率的总变化以次线性增长，我们就可以证明MW-UCB可以实现任意的稳定区域。

    The emergence of large-scale wireless networks with partially-observable and time-varying dynamics has imposed new challenges on the design of optimal control policies. This paper studies efficient scheduling algorithms for wireless networks subject to generalized interference constraint, where mean arrival and mean service rates are unknown and non-stationary. This model exemplifies realistic edge devices' characteristics of wireless communication in modern networks. We propose a novel algorithm termed MW-UCB for generalized wireless network scheduling, which is based on the Max-Weight policy and leverages the Sliding-Window Upper-Confidence Bound to learn the channels' statistics under non-stationarity. MW-UCB is provably throughput-optimal under mild assumptions on the variability of mean service rates. Specifically, as long as the total variation in mean service rates over any time period grows sub-linearly in time, we show that MW-UCB can achieve the stability region arbitrarily c
    
[^23]: 使用自监督学习个性化压力移动感知

    Personalization of Stress Mobile Sensing using Self-Supervised Learning. (arXiv:2308.02731v1 [cs.LG])

    [http://arxiv.org/abs/2308.02731](http://arxiv.org/abs/2308.02731)

    本研究探讨了使用自监督学习来个性化压力移动感知的方法，以解决压力预测中标签主观性和稀疏性等问题。

    

    压力被广泛认为是各种健康问题的主要因素。使用可穿戴设备记录的生物信号数据进行压力预测是移动感知研究的重要领域，因为实时的压力预测可以使数字干预在压力发生时立即做出反应，有助于避免许多心理和生理症状，比如心律不齐。皮电活动（EDA）通常用于测量压力。然而，使用机器学习进行压力预测的主要挑战包括标签的主观性和稀疏性、大量的特征空间、相对较少的标签以及特征和结果之间的复杂非线性和主观关系。为了解决这些问题，我们研究了模型个性化的使用：为每个用户训练单独的压力预测模型。为了让神经网络学习每个个体基线生物信号模式的时间动态，从而实现个性化。

    Stress is widely recognized as a major contributor to a variety of health issues. Stress prediction using biosignal data recorded by wearables is a key area of study in mobile sensing research because real-time stress prediction can enable digital interventions to immediately react at the onset of stress, helping to avoid many psychological and physiological symptoms such as heart rhythm irregularities. Electrodermal activity (EDA) is often used to measure stress. However, major challenges with the prediction of stress using machine learning include the subjectivity and sparseness of the labels, a large feature space, relatively few labels, and a complex nonlinear and subjective relationship between the features and outcomes. To tackle these issues, we examine the use of model personalization: training a separate stress prediction model for each user. To allow the neural network to learn the temporal dynamics of each individual's baseline biosignal patterns, thus enabling personalizati
    
[^24]: 使用Actor-Critic算法和ReLU网络综合编程策略

    Synthesizing Programmatic Policies with Actor-Critic Algorithms and ReLU Networks. (arXiv:2308.02729v1 [cs.LG])

    [http://arxiv.org/abs/2308.02729](http://arxiv.org/abs/2308.02729)

    本文通过使用Actor-Critic算法和ReLU网络，展示了在编码程序化策略的语言上，不需要特定的PIRL算法。使用ReLU网络可以将使用Actor-Critic算法学习到的策略转化为具有if-then-else结构、线性变换和PID操作等的程序化策略。

    

    程序化可解释性强化学习(PIRL)通过人类可读的计算机程序来编码策略。最近引入了一些新算法来处理在程序化策略空间中缺乏梯度信号的问题。大多数PIRL算法首先训练一个神经策略，然后将其用作导引在程序化空间中搜索的“神谕”。本文中，我们展示了在编码程序化策略的语言上，这样的PIRL特定算法是不必要的。这是因为可以使用Actor-Critic算法直接获得程序化策略。我们利用ReLU神经网络和斜率决策树之间的联系，将使用Actor-Critic算法学习到的策略转化为程序化策略。这种从ReLU网络转化使我们能够综合编码了if-then-else结构、输入值的线性变换和PID操作的策略。

    Programmatically Interpretable Reinforcement Learning (PIRL) encodes policies in human-readable computer programs. Novel algorithms were recently introduced with the goal of handling the lack of gradient signal to guide the search in the space of programmatic policies. Most of such PIRL algorithms first train a neural policy that is used as an oracle to guide the search in the programmatic space. In this paper, we show that such PIRL-specific algorithms are not needed, depending on the language used to encode the programmatic policies. This is because one can use actor-critic algorithms to directly obtain a programmatic policy. We use a connection between ReLU neural networks and oblique decision trees to translate the policy learned with actor-critic algorithms into programmatic policies. This translation from ReLU networks allows us to synthesize policies encoded in programs with if-then-else structures, linear transformations of the input values, and PID operations. Empirical result
    
[^25]: 为歌唱旋律提取改进谐波敏感性和预测稳定性的途径

    Towards Improving Harmonic Sensitivity and Prediction Stability for Singing Melody Extraction. (arXiv:2308.02723v1 [cs.SD])

    [http://arxiv.org/abs/2308.02723](http://arxiv.org/abs/2308.02723)

    本文提出了通过修改输入特征和训练目标来改进歌唱旋律提取的方法。这些修改包括增强对尾部谐波的敏感性和设计可防止预测极短片段的损失函数。实验结果表明，这些修改对于提高歌唱旋律提取的效果有实际效果。

    

    在深度学习研究中，许多旋律提取模型依赖于重新设计神经网络架构来提高性能。本文提出了基于两个假设的输入特征修改和训练目标修改。首先，音频数据的频谱图中的谐波在频率轴上迅速衰减。为了增强模型对尾部谐波的敏感性，我们使用离散z-transform修改了联合频率和周期性(CFP)表示。其次，极短时长的人声和非人声片段并不常见。为了确保更稳定的旋律轮廓，我们设计了一个可微分的损失函数，防止模型预测这些片段。我们将这些修改应用于多个模型，包括MSNet、FTANet和新引入的模型PianoNet，该模型是从钢琴转录网络改编而来的。我们的实验结果表明，提出的修改在歌唱旋律提取上具有实证有效性。

    In deep learning research, many melody extraction models rely on redesigning neural network architectures to improve performance. In this paper, we propose an input feature modification and a training objective modification based on two assumptions. First, harmonics in the spectrograms of audio data decay rapidly along the frequency axis. To enhance the model's sensitivity on the trailing harmonics, we modify the Combined Frequency and Periodicity (CFP) representation using discrete z-transform. Second, the vocal and non-vocal segments with extremely short duration are uncommon. To ensure a more stable melody contour, we design a differentiable loss function that prevents the model from predicting such segments. We apply these modifications to several models, including MSNet, FTANet, and a newly introduced model, PianoNet, modified from a piano transcription network. Our experimental results demonstrate that the proposed modifications are empirically effective for singing melody extrac
    
[^26]: AI和机器人技术在流体属性预测中的应用

    Fluid Property Prediction Leveraging AI and Robotics. (arXiv:2308.02715v1 [cs.LG])

    [http://arxiv.org/abs/2308.02715](http://arxiv.org/abs/2308.02715)

    这项工作提出了一种基于视觉的方法来估计液体的粘度，通过学习视频中不同液体振荡模式的潜在表示，可以从视觉上推断液体的类别或动态粘度。

    

    从视觉上推测液体属性是一项具有挑战性的任务，因为液体的行为和检测都十分复杂。然而，能够直接从视觉信息中推断液体属性对于自主流体处理系统非常有价值，因为摄像头很容易获取。此外，仅通过视觉预测液体属性可以加快流体表征的过程，在各种实验环境中节省大量时间和精力。本文提出了一种纯视觉方法来估计粘度，利用液体振荡行为与粘度直接相关的事实。具体地，我们利用3D卷积自编码器学习视频中不同液体振荡模式的潜在表示。借助这些潜在表示，我们可以从视频中直观地推断液体的类别或液体的动态粘度。

    Inferring liquid properties from vision is a challenging task due to the complex nature of fluids, both in behavior and detection. Nevertheless, the ability to infer their properties directly from visual information is highly valuable for autonomous fluid handling systems, as cameras are readily available. Moreover, predicting fluid properties purely from vision can accelerate the process of fluid characterization saving considerable time and effort in various experimental environments. In this work, we present a purely vision-based approach to estimate viscosity, leveraging the fact that the behavior of the fluid oscillations is directly related to the viscosity. Specifically, we utilize a 3D convolutional autoencoder to learn latent representations of different fluid-oscillating patterns present in videos. We leverage this latent representation to visually infer the category of fluid or the dynamics viscosity of fluid from video.
    
[^27]: 探索稀疏恢复对图像超分辨率质量的影响

    Exploring the Effect of Sparse Recovery on the Quality of Image Superresolution. (arXiv:2308.02714v1 [cs.CV])

    [http://arxiv.org/abs/2308.02714](http://arxiv.org/abs/2308.02714)

    本研究探讨了稀疏恢复算法对图像超分辨率重构质量的影响，并通过实证实验寻找最佳稀疏恢复算法。

    

    字典学习可以通过从高分辨率和低分辨率图像对学习一对耦合字典，使得对应的图像对在由耦合字典表示时共享相同的稀疏向量，从而用于图像超分辨率恢复。这些字典可以用于根据稀疏恢复从低分辨率输入图像中重构对应的高分辨率图像块。本研究探讨了我们使用的稀疏恢复算法对重构图像质量的影响。我们进行了实证实验以寻找最适合此目的的稀疏恢复算法。

    Dictionary learning can be used for image superresolution by learning a pair of coupled dictionaries of image patches from high-resolution and low-resolution image pairs such that the corresponding pairs share the same sparse vector when represented by the coupled dictionaries. These dictionaries then can be used to to reconstruct the corresponding high-resolution patches from low-resolution input images based on sparse recovery. The idea is to recover the shared sparse vector using the low-resolution dictionary and then multiply it by the high-resolution dictionary to recover the corresponding high-resolution image patch. In this work, we study the effect of the sparse recovery algorithm that we use on the quality of the reconstructed images. We offer empirical experiments to search for the best sparse recovery algorithm that can be used for this purpose.
    
[^28]: 可伸缩的因果界限计算

    Scalable Computation of Causal Bounds. (arXiv:2308.02709v1 [cs.LG])

    [http://arxiv.org/abs/2308.02709](http://arxiv.org/abs/2308.02709)

    本论文研究了在存在未观测混淆变量和离散值观测变量的因果图上计算因果查询的界限的问题，并提出了修剪方法来显著减少计算负担，使得可以计算更大规模的因果推断问题的界限，在特殊问题情况下可以以闭合形式计算界限，并将方法扩展到分数线性规划进行计算

    

    我们考虑在存在未观测混淆变量和离散值观测变量的因果图上计算因果查询的界限的问题，其中不满足可辨识性。现有的非参数方法用于计算这些界限的线性规划（LP）公式由于线性规划的大小随着因果图中的边的数量呈指数级增长而很快变得不可解。我们展示了这个LP公式可以被显著修剪，使我们能够计算较大因果推断问题的界限，相比现有技术，这个修剪过程允许我们以闭合形式计算一类特殊问题的界限，包括多个混淆处理影响结果的广为研究的问题族。我们将修剪方法扩展到分数线性规划（fractional LP），这些规划公式用于计算包含有关个体的附加观测的因果查询的界限。我们证明了我们的方法提供了显著的运行时间

    We consider the problem of computing bounds for causal queries on causal graphs with unobserved confounders and discrete valued observed variables, where identifiability does not hold. Existing non-parametric approaches for computing such bounds use linear programming (LP) formulations that quickly become intractable for existing solvers because the size of the LP grows exponentially in the number of edges in the causal graph. We show that this LP can be significantly pruned, allowing us to compute bounds for significantly larger causal inference problems compared to existing techniques. This pruning procedure allows us to compute bounds in closed form for a special class of problems, including a well-studied family of problems where multiple confounded treatments influence an outcome. We extend our pruning methodology to fractional LPs which compute bounds for causal queries which incorporate additional observations about the unit. We show that our methods provide significant runtime 
    
[^29]: 存在类条件标签噪音下的欺诈检测中的FPR估计

    FPR Estimation for Fraud Detection in the Presence of Class-Conditional Label Noise. (arXiv:2308.02695v1 [cs.LG])

    [http://arxiv.org/abs/2308.02695](http://arxiv.org/abs/2308.02695)

    该论文提出了在存在标签噪音的情况下，估计二分类模型的FPR以及TPR的方法，这对于欺诈检测中的准确性至关重要。作者发现，现有的方法虽然减小了总误差，却不能保证模型对FPR和TPR的估计准确，因此提出了一种使清理误差与模型分数解耦的方法。

    

    我们考虑了在验证集中存在错误标签（标签噪音）的情况下，对二分类模型的假阳性率（FPR）/真阳性率（TPR）的估计问题。我们的动机应用是欺诈预防，在这种情况下，准确估计FPR对于保护好客户的体验至关重要，而标签噪音具有高度的不对称性。现有方法旨在最小化清理过程中的总误差 - 避免清理非噪音的示例，并确保清理噪音示例。这是一个重要的准确性度量，但不足以保证模型的真实FPR或TPR的良好估计，我们表明，即使总误差较低，使用模型直接清理自己的验证数据也会导致低估。这表明，研究人员需要追求不仅减少总误差，还需要寻求使清理误差与模型分数解耦的方法。

    We consider the problem of estimating the false-/ true-positive-rate (FPR/TPR) for a binary classification model when there are incorrect labels (label noise) in the validation set. Our motivating application is fraud prevention where accurate estimates of FPR are critical to preserving the experience for good customers, and where label noise is highly asymmetric. Existing methods seek to minimize the total error in the cleaning process - to avoid cleaning examples that are not noise, and to ensure cleaning of examples that are. This is an important measure of accuracy but insufficient to guarantee good estimates of the true FPR or TPR for a model, and we show that using the model to directly clean its own validation data leads to underestimates even if total error is low. This indicates a need for researchers to pursue methods that not only reduce total error but also seek to de-correlate cleaning error with model scores.
    
[^30]: 基于可解释的深度学习的太阳耀斑预测与事后注意力的操作预测

    Explainable Deep Learning-based Solar Flare Prediction with post hoc Attention for Operational Forecasting. (arXiv:2308.02682v1 [cs.LG])

    [http://arxiv.org/abs/2308.02682](http://arxiv.org/abs/2308.02682)

    本文研究了一个基于深度学习的太阳耀斑预测模型，通过事后分析发现该模型的预测结果与活动区特征一致。

    

    本文针对基于深度学习的全盘太阳耀斑预测模型进行了事后分析。我们使用每小时的全盘线视磁图像，并选择二进制预测模式来预测未来24小时内发生≥M1.0级耀斑的可能性。我们利用定制的数据增强和样本加权来应对固有的类不平衡问题，并使用真实技能统计和Heidke技能评分作为评估指标。最近渐进的基于梯度的注意力方法使我们能够通过将梯度信号发送到输入特征上来解释模型的决策负担。我们使用三个事后注意力方法来解释我们的模型：(i) 导向渐变加权类激活映射，(ii) 深度Shapley加性解释，以及(iii) 综合梯度。我们的分析表明，全盘太阳耀斑的预测与与活动区相关的特征相吻合。本研究的主要发现是：(1) 我们证明了我们的模型在全盘太阳耀斑预测方面的性能。

    This paper presents a post hoc analysis of a deep learning-based full-disk solar flare prediction model. We used hourly full-disk line-of-sight magnetogram images and selected binary prediction mode to predict the occurrence of $\geq$M1.0-class flares within 24 hours. We leveraged custom data augmentation and sample weighting to counter the inherent class-imbalance problem and used true skill statistic and Heidke skill score as evaluation metrics. Recent advancements in gradient-based attention methods allow us to interpret models by sending gradient signals to assign the burden of the decision on the input features. We interpret our model using three post hoc attention methods: (i) Guided Gradient-weighted Class Activation Mapping, (ii) Deep Shapley Additive Explanations, and (iii) Integrated Gradients. Our analysis shows that full-disk predictions of solar flares align with characteristics related to the active regions. The key findings of this study are: (1) We demonstrate that our 
    
[^31]: 信贷中的公平模型：交叉歧视和不平等的放大

    Fair Models in Credit: Intersectional Discrimination and the Amplification of Inequity. (arXiv:2308.02680v1 [cs.CY])

    [http://arxiv.org/abs/2308.02680](http://arxiv.org/abs/2308.02680)

    本文研究了信贷领域中的公平模型，通过借鉴交叉性理论，揭示了在性别、年龄、婚姻状况、单亲状态和子女数量等多个交叉社会类别的影响下，信贷分配中存在的不平等现象。

    

    在信贷建模中，新数据来源和机器学习技术的增加引发了对潜在不公平决策的关注，这些决策依赖于受保护的特征（如种族、性别、年龄）或其他社会经济和人口统计数据。作者在小额信贷背景下展示了这种算法偏见的影响。在信用评估方面存在不平等的困难在弱势群体中更为凸显，然而，我们对由多个交叉社会类别定义的群体之间的信贷分配不平等非常了解。本研究借鉴交叉性理论，探讨了按性别、年龄、婚姻状况、单亲状态和子女数量交叉的水平不平等在信贷获得中的影响。本文利用西班牙小额信贷市场的数据，展示了多元化的现实和交叉身份如何塑造信贷分配模式。

    The increasing usage of new data sources and machine learning (ML) technology in credit modeling raises concerns with regards to potentially unfair decision-making that rely on protected characteristics (e.g., race, sex, age) or other socio-economic and demographic data. The authors demonstrate the impact of such algorithmic bias in the microfinance context. Difficulties in assessing credit are disproportionately experienced among vulnerable groups, however, very little is known about inequities in credit allocation between groups defined, not only by single, but by multiple and intersecting social categories. Drawing from the intersectionality paradigm, the study examines intersectional horizontal inequities in credit access by gender, age, marital status, single parent status and number of children. This paper utilizes data from the Spanish microfinance market as its context to demonstrate how pluralistic realities and intersectional identities can shape patterns of credit allocation
    
[^32]: 半监督实例分割的引导蒸馏

    Guided Distillation for Semi-Supervised Instance Segmentation. (arXiv:2308.02668v1 [cs.CV])

    [http://arxiv.org/abs/2308.02668](http://arxiv.org/abs/2308.02668)

    这项研究提出了一种半监督实例分割的引导蒸馏方法，通过引入新的“引导预烧”阶段和利用未标记数据的导师模型指导，取得了显著的改进。

    

    虽然实例分割方法有了显著的改进，但主导范式是依赖于完全带注释的训练图像，这需要费时费力。为了减轻这种依赖并提高结果，半监督方法利用未标记数据作为额外的训练信号，以限制对标记样本的过拟合。在这个背景下，我们提出了一些新颖的设计选择来显著改进师生蒸馏模型。特别是，我们(i)通过引入新的“引导预烧”阶段改进了蒸馏方法，(ii)评估了不同的实例分割架构、主干网络和预训练策略。与之前只使用监督数据来对学生模型进行预烧的工作相反，我们还利用导师模型的指导在预烧阶段中利用未标记数据。我们改进的蒸馏方法在之前最先进的结果上取得了显著的改进。

    Although instance segmentation methods have improved considerably, the dominant paradigm is to rely on fully-annotated training images, which are tedious to obtain. To alleviate this reliance, and boost results, semi-supervised approaches leverage unlabeled data as an additional training signal that limits overfitting to the labeled samples. In this context, we present novel design choices to significantly improve teacher-student distillation models. In particular, we (i) improve the distillation approach by introducing a novel "guided burn-in" stage, and (ii) evaluate different instance segmentation architectures, as well as backbone networks and pre-training strategies. Contrary to previous work which uses only supervised data for the burn-in period of the student model, we also use guidance of the teacher model to exploit unlabeled data in the burn-in period. Our improved distillation approach leads to substantial improvements over previous state-of-the-art results. For example, on 
    
[^33]: 增强型人工智能数据处理和发现群体外包用于流星雨制图

    AI-Enhanced Data Processing and Discovery Crowd Sourcing for Meteor Shower Mapping. (arXiv:2308.02664v1 [astro-ph.EP])

    [http://arxiv.org/abs/2308.02664](http://arxiv.org/abs/2308.02664)

    本研究使用增强型人工智能技术对全球流星雨数据进行处理和分析，并通过开发互动的网页平台，让公众参与流星探测，从而提高了流星雨的发现率。

    

    由NASA自2010年开始资助的全球全天候流星观测(CAMS)项目旨在通过对来自16个国家、北半球和南半球的多地低光视频摄像机探测到的流星轨迹进行三角测量，制图全球流星雨。该项目的使命是验证、发现并预测未来的流星雨降临。我们的研究旨在通过实施基于云的自动化AI流程和改善数据可视化，将公众参与到监测流星探测中，从而提高发现率。本文描述了使用可解释活动学习和AI流程自动化进行数据摄取、处理和洞察生成的过程。此外，本研究还描述了一个互动的Web门户（NASA流星雨门户），用于促进流星源地图的可视化。目前，CAMS已经发现了超过200个新的流星雨

    The Cameras for Allsky Meteor Surveillance (CAMS) project, funded by NASA starting in 2010, aims to map our meteor showers by triangulating meteor trajectories detected in low-light video cameras from multiple locations across 16 countries in both the northern and southern hemispheres. Its mission is to validate, discover, and predict the upcoming returns of meteor showers. Our research aimed to streamline the data processing by implementing an automated cloud-based AI-enabled pipeline and improve the data visualization to improve the rate of discoveries by involving the public in monitoring the meteor detections. This article describes the process of automating the data ingestion, processing, and insight generation using an interpretable Active Learning and AI pipeline. This work also describes the development of an interactive web portal (the NASA Meteor Shower portal) to facilitate the visualization of meteor radiant maps. To date, CAMS has discovered over 200 new meteor showers and
    
[^34]: 对生成建模的变量变换公式的综述

    A Review of Change of Variable Formulas for Generative Modeling. (arXiv:2308.02652v1 [cs.LG])

    [http://arxiv.org/abs/2308.02652](http://arxiv.org/abs/2308.02652)

    本文从编码器/解码器架构的统一视角出发，系统性地总结了28个变量变换公式，揭示了不同方法之间的有趣关系，强调了重要区别，并提出了未来研究的方向。

    

    变量变换（CoV）公式通过可计算雅可比行列式的学习变换将复杂的概率密度简化为简单的形式，是最大似然学习、贝叶斯推断、异常检测、模型选择等领域的强大工具。虽然已经为多种模型类型导出了CoV公式，但这些信息散布在许多不同的文献中。本文从编码器/解码器架构的统一视角出发，对28个CoV公式进行了系统性的研究，将看似不同的方法之间的有趣关系呈现出来，强调了文献中不常清楚的重要区别，并为未来的研究提供了令人惊讶的空白。

    Change-of-variables (CoV) formulas allow to reduce complicated probability densities to simpler ones by a learned transformation with tractable Jacobian determinant. They are thus powerful tools for maximum-likelihood learning, Bayesian inference, outlier detection, model selection, etc. CoV formulas have been derived for a large variety of model types, but this information is scattered over many separate works. We present a systematic treatment from the unifying perspective of encoder/decoder architectures, which collects 28 CoV formulas in a single place, reveals interesting relationships between seemingly diverse methods, emphasizes important distinctions that are not always clear in the literature, and identifies surprising gaps for future research.
    
[^35]: 从拓扑学中学习：大尺度结构的宇宙参数估计

    Learning from Topology: Cosmological Parameter Estimation from the Large-scale Structure. (arXiv:2308.02636v1 [astro-ph.CO])

    [http://arxiv.org/abs/2308.02636](http://arxiv.org/abs/2308.02636)

    该论文提出了一种基于持续同调和神经网络的方法，利用大尺度结构的拓扑信息估计宇宙参数。通过参数恢复测试，发现该方法比传统的贝叶斯推断方法更准确和精确。

    

    宇宙大尺度结构的拓扑包含着有关基础宇宙参数的宝贵信息。虽然持续同调可以提取这种拓扑信息，但如何最佳地从这个工具中进行参数估计仍然是一个开放的问题。为了解决这个问题，我们提出了一个神经网络模型，用于将持续图像映射到宇宙参数。通过参数恢复测试，我们证明我们的模型能够准确而精确地估计，明显优于传统的贝叶斯推断方法。

    The topology of the large-scale structure of the universe contains valuable information on the underlying cosmological parameters. While persistent homology can extract this topological information, the optimal method for parameter estimation from the tool remains an open question. To address this, we propose a neural network model to map persistence images to cosmological parameters. Through a parameter recovery test, we demonstrate that our model makes accurate and precise estimates, considerably outperforming conventional Bayesian inference approaches.
    
[^36]: 使用生成对抗网络生成逼真的合成毫米波雷达数据，用于自动驾驶应用

    Generation of Realistic Synthetic Raw Radar Data for Automated Driving Applications using Generative Adversarial Networks. (arXiv:2308.02632v1 [cs.CV])

    [http://arxiv.org/abs/2308.02632](http://arxiv.org/abs/2308.02632)

    本研究提出了一种使用生成对抗网络生成合成毫米波雷达数据的快速方法，可以增加数据增强的潜力，并进一步开发雷达数据处理算法。

    

    目前模拟FMCW雷达的主要方法是基于射线追踪，通常计算密集且不能考虑背景噪声。本研究提出了一种更快速的FMCW雷达模拟方法，能够使用生成对抗网络（GAN）生成合成的原始雷达数据。代码和预训练的权重是开源的，并可在GitHub上获得。该方法生成了16个同时的脉冲，可以用于进一步开发用于处理雷达数据（滤波和聚类）的算法。这可以增加数据增强的潜力，例如通过生成在实际生活中不可复现的不存在或安全关键场景的数据。在本研究中，使用摩托车的雷达测量数据对GAN进行训练，并生成摩托车直线行驶的合成原始雷达数据。生成这些数据时，使用了摩托车的距离和高斯噪声作为输入。

    The main approaches for simulating FMCW radar are based on ray tracing, which is usually computationally intensive and do not account for background noise. This work proposes a faster method for FMCW radar simulation capable of generating synthetic raw radar data using generative adversarial networks (GAN). The code and pre-trained weights are open-source and available on GitHub. This method generates 16 simultaneous chirps, which allows the generated data to be used for the further development of algorithms for processing radar data (filtering and clustering). This can increase the potential for data augmentation, e.g., by generating data in non-existent or safety-critical scenarios that are not reproducible in real life. In this work, the GAN was trained with radar measurements of a motorcycle and used to generate synthetic raw radar data of a motorcycle traveling in a straight line. For generating this data, the distance of the motorcycle and Gaussian noise are used as input to the 
    
[^37]: 加速MRI重建中的不确定性估计和传播

    Uncertainty Estimation and Propagation in Accelerated MRI Reconstruction. (arXiv:2308.02631v1 [eess.IV])

    [http://arxiv.org/abs/2308.02631](http://arxiv.org/abs/2308.02631)

    本文提出了一种基于条件分层变分自编码器的概率重建技术（PHiRec），用于解决深度学习在MRI重建中的不确定性问题。我们的方法在产生高质量重建的同时，能够更好地校准不确定性量化。同时，我们还展示了如何传播MR重建中的不确定性。

    

    基于深度学习的MRI重建技术在高度加速的情况下取得了前所未有的重建质量。然而，深度学习技术也被知道在意外失败和产生虚构结构方面存在问题。如果重建直接用于实时治疗指导或自动提取临床参数（如通过分割），这就特别有问题。良好校准的不确定性量化将是在临床实践中安全使用这项技术的关键因素。本文提出了一种新颖的概率重建技术（PHiRec），基于条件分层变分自编码器的思想。我们证明了我们提出的方法产生了高质量的重建以及比几个强基线模型更为良好校准的不确定性量化。此外，我们还展示了如何传播MR重建中出现的不确定性。

    MRI reconstruction techniques based on deep learning have led to unprecedented reconstruction quality especially in highly accelerated settings. However, deep learning techniques are also known to fail unexpectedly and hallucinate structures. This is particularly problematic if reconstructions are directly used for downstream tasks such as real-time treatment guidance or automated extraction of clinical paramters (e.g. via segmentation). Well-calibrated uncertainty quantification will be a key ingredient for safe use of this technology in clinical practice. In this paper we propose a novel probabilistic reconstruction technique (PHiRec) building on the idea of conditional hierarchical variational autoencoders. We demonstrate that our proposed method produces high-quality reconstructions as well as uncertainty quantification that is substantially better calibrated than several strong baselines. We furthermore demonstrate how uncertainties arising in the MR econstruction can be propagate
    
[^38]: 利用网络和知识图谱自动评估影响力投资

    Harnessing the Web and Knowledge Graphs for Automated Impact Investing Scoring. (arXiv:2308.02622v1 [cs.LG])

    [http://arxiv.org/abs/2308.02622](http://arxiv.org/abs/2308.02622)

    本论文介绍了一个利用网络和知识图谱自动评估影响力投资的数据驱动系统，通过收集和过滤文本数据集以及使用分类器来预测分数，实现了自动创建SDG框架的过程。

    

    可持续发展目标（SDGs）是联合国提出的旨在鼓励有助于保障人类繁荣和可持续性的政策和活动。在金融行业中，为了评估一个公司与每个17个可持续发展目标的一致性，设计了SDG框架提供分数。这种评分能够对潜在建立包容和可持续经济的投资进行一致的评估。由于此类框架需要高质量和可靠性，创建和维护它们的过程耗时且需要广泛的领域专业知识。在这项工作中，我们描述了一个数据驱动的系统，旨在自动化创建SDG框架的过程。首先，我们提出了一种从不同网络来源和与一组公司相关的知识图谱收集和过滤文本数据集的新方法。然后，我们使用此数据训练和部署了分类器来预测分数。

    The Sustainable Development Goals (SDGs) were introduced by the United Nations in order to encourage policies and activities that help guarantee human prosperity and sustainability. SDG frameworks produced in the finance industry are designed to provide scores that indicate how well a company aligns with each of the 17 SDGs. This scoring enables a consistent assessment of investments that have the potential of building an inclusive and sustainable economy. As a result of the high quality and reliability required by such frameworks, the process of creating and maintaining them is time-consuming and requires extensive domain expertise. In this work, we describe a data-driven system that seeks to automate the process of creating an SDG framework. First, we propose a novel method for collecting and filtering a dataset of texts from different web sources and a knowledge graph relevant to a set of companies. We then implement and deploy classifiers trained with this data for predicting score
    
[^39]: 使用广义矩阵补全在高阶有限维代数中恢复彩色图像

    Color Image Recovery Using Generalized Matrix Completion over Higher-Order Finite Dimensional Algebra. (arXiv:2308.02621v1 [cs.CV])

    [http://arxiv.org/abs/2308.02621](http://arxiv.org/abs/2308.02621)

    本篇论文提出了一种基于广义高阶标量的彩色图像恢复方法，通过扩展传统的二阶矩阵模型到更全面的高阶矩阵模型，并利用这个模型扩展了一些常用的矩阵和张量补全算法。实验证明，这种方法在彩色图像补全方面具有较好的性能。

    

    为了提高有缺失条目的彩色图像补全的准确性，我们提出了一种基于广义高阶标量的恢复方法。我们将传统的二阶矩阵模型扩展为更全面的高阶矩阵等效模型，称为“t-矩阵”模型，该模型结合了像素邻域扩展策略来表征局部像素约束。然后，我们使用这个“t-矩阵”模型将一些常用的矩阵和张量补全算法扩展到它们的高阶版本。我们对使用模拟数据和公开可用的图像的各种算法进行了广泛的实验，并比较了它们的性能。结果表明，我们的广义矩阵补全模型和相应的算法与它们的低阶张量和传统矩阵对应物相比具有很好的性能。

    To improve the accuracy of color image completion with missing entries, we present a recovery method based on generalized higher-order scalars. We extend the traditional second-order matrix model to a more comprehensive higher-order matrix equivalent, called the "t-matrix" model, which incorporates a pixel neighborhood expansion strategy to characterize the local pixel constraints. This "t-matrix" model is then used to extend some commonly used matrix and tensor completion algorithms to their higher-order versions. We perform extensive experiments on various algorithms using simulated data and algorithms on simulated data and publicly available images and compare their performance. The results show that our generalized matrix completion model and the corresponding algorithm compare favorably with their lower-order tensor and conventional matrix counterparts.
    
[^40]: ChatGPT用于GTFS: 从文字到信息

    ChatGPT for GTFS: From Words to Information. (arXiv:2308.02618v1 [cs.IR])

    [http://arxiv.org/abs/2308.02618](http://arxiv.org/abs/2308.02618)

    本研究探索了使用ChatGPT语言模型从GTFS数据中检索信息的可行性，验证了ChatGPT（GPT-3.5）在GTFS规范理解和信息提取方面的能力。程序合成方法在信息检索任务中表现出更高的准确率，为解决GTFS数据信息获取问题提供了一种有效的方法。

    

    广泛使用的公交通行数据发布标准General Transit Feed Specification（GTFS）是表格数据，信息分散在不同的文件中，需要专门的工具或包来检索信息。与此同时，使用大型语言模型进行文本和信息检索的趋势也在增长。本研究的想法是看看当前广泛采用的LLMs（ChatGPT）是否能够使用自然语言指令从GTFS中检索信息。我们首先测试ChatGPT（GPT-3.5）是否理解GTFS规范。GPT-3.5在我们的多项选择问题（MCQ）中正确回答了77%。接下来，我们利用过滤的GTFS数据集对LLM进行信息提取任务。对于信息检索，我们比较了零-shot和程序合成。程序合成的效果更好，在简单问题上达到了约90%的准确率，在复杂问题上达到了约40%的准确率。

    The General Transit Feed Specification (GTFS) standard for publishing transit data is ubiquitous. GTFS being tabular data, with information spread across different files, necessitates specialized tools or packages to retrieve information. Concurrently, the use of Large Language Models for text and information retrieval is growing. The idea of this research is to see if the current widely adopted LLMs (ChatGPT) are able to retrieve information from GTFS using natural language instructions. We first test whether ChatGPT (GPT-3.5) understands the GTFS specification. GPT-3.5 answers 77% of our multiple-choice questions (MCQ) correctly. Next, we task the LLM with information extractions from a filtered GTFS feed with 4 routes. For information retrieval, we compare zero-shot and program synthesis. Program synthesis works better, achieving ~90% accuracy on simple questions and ~40% accuracy on complex questions.
    
[^41]: 车辆控制：使用联邦深度强化学习进行碰撞避免

    Vehicles Control: Collision Avoidance using Federated Deep Reinforcement Learning. (arXiv:2308.02614v1 [cs.LG])

    [http://arxiv.org/abs/2308.02614](http://arxiv.org/abs/2308.02614)

    本文研究了使用联邦深度强化学习技术进行碰撞避免的车辆控制问题，并比较了不同算法的效果。结果表明，联邦深度确定性策略梯度算法在优化车辆控制方面表现更好。

    

    在城市人口增长和道路上车辆数量不断增加的情况下，高效管理交通并确保安全已成为重要挑战。为了解决这些问题，开发车辆智能控制系统至关重要。本文介绍了一项关于车辆碰撞避免的综合研究，利用联邦深度强化学习（FDRL）技术的力量。我们的主要目标是在优先考虑安全和保护数据隐私的同时，最大程度地减少出行延误和提高车辆的平均速度。为了实现这一目标，我们在本文中对本地模型深度确定性策略梯度（DDPG）和全球模型联邦深度确定性策略梯度（FDDPG）进行了比较分析，以确定它们在优化车辆碰撞避免方面的效果。所得到的结果表明，FDDPG算法在有效控制车辆和预防碰撞方面优于DDPG。

    In the face of growing urban populations and the escalating number of vehicles on the roads, managing transportation efficiently and ensuring safety have become critical challenges. To tackle these issues, the development of intelligent control systems for vehicles is paramount. This paper presents a comprehensive study on vehicle control for collision avoidance, leveraging the power of Federated Deep Reinforcement Learning (FDRL) techniques. Our main goal is to minimize travel delays and enhance the average speed of vehicles while prioritizing safety and preserving data privacy. To accomplish this, we conducted a comparative analysis between the local model, Deep Deterministic Policy Gradient (DDPG), and the global model, Federated Deep Deterministic Policy Gradient (FDDPG), to determine their effectiveness in optimizing vehicle control for collision avoidance. The results obtained indicate that the FDDPG algorithm outperforms DDPG in terms of effectively controlling vehicles and prev
    
[^42]: 用SyntHIR实现互操作性合成健康数据，以便开发CDSS工具

    Interoperable synthetic health data with SyntHIR to enable the development of CDSS tools. (arXiv:2308.02613v1 [cs.LG])

    [http://arxiv.org/abs/2308.02613](http://arxiv.org/abs/2308.02613)

    本论文提出了一种利用合成EHR数据开发CDSS工具的体系架构，通过使用SyntHIR系统和FHIR标准实现数据互操作性和工具可迁移性。

    

    利用高质量的患者日志和健康登记来开发基于机器学习的临床决策支持系统（CDSS）有很大的机会。为了在临床工作流程中实施CDSS工具，需要将该工具集成、验证和测试在用于存储和管理患者数据的电子健康记录（EHR）系统上。然而，由于合规法规，通常不可能获得对EHR系统的必要访问权限。我们提出了一种用于生成和使用CDSS工具开发的合成EHR数据的体系架构。该体系结构在一个称为SyntHIR的系统中实现。SyntHIR系统使用Fast Healthcare Interoperability Resources (FHIR)标准进行数据互操作性，使用Gretel框架生成合成数据，使用Microsoft Azure FHIR服务器作为基于FHIR的EHR系统，以及使用SMART on FHIR框架进行工具可迁移性。我们通过使用数据开发机器学习基于CDSS工具来展示SyntHIR的实用性。

    There is a great opportunity to use high-quality patient journals and health registers to develop machine learning-based Clinical Decision Support Systems (CDSS). To implement a CDSS tool in a clinical workflow, there is a need to integrate, validate and test this tool on the Electronic Health Record (EHR) systems used to store and manage patient data. However, it is often not possible to get the necessary access to an EHR system due to legal compliance. We propose an architecture for generating and using synthetic EHR data for CDSS tool development. The architecture is implemented in a system called SyntHIR. The SyntHIR system uses the Fast Healthcare Interoperability Resources (FHIR) standards for data interoperability, the Gretel framework for generating synthetic data, the Microsoft Azure FHIR server as the FHIR-based EHR system and SMART on FHIR framework for tool transportability. We demonstrate the usefulness of SyntHIR by developing a machine learning-based CDSS tool using data
    
[^43]: 知识驱动的多智能体强化学习用于物联网车辆中的计算卸载

    Knowledge-Driven Multi-Agent Reinforcement Learning for Computation Offloading in Cybertwin-Enabled Internet of Vehicles. (arXiv:2308.02603v1 [cs.LG])

    [http://arxiv.org/abs/2308.02603](http://arxiv.org/abs/2308.02603)

    这项研究提出了一种基于知识驱动的多智能体强化学习方法，用于解决物联网车辆中计算卸载的延迟问题。通过将计算任务卸载到边缘单元，可以减轻车载计算负担。该方法利用图神经网络结合领域知识，选择每辆车的最佳卸载选项。

    

    通过将车辆的计算密集型任务卸载到道路边的单元(RSU)，移动边缘计算(MEC)在物联网车辆(IoV)中可以减轻车载计算负担。

    By offloading computation-intensive tasks of vehicles to roadside units (RSUs), mobile edge computing (MEC) in the Internet of Vehicles (IoV) can relieve the onboard computation burden. However, existing model-based task offloading methods suffer from heavy computational complexity with the increase of vehicles and data-driven methods lack interpretability. To address these challenges, in this paper, we propose a knowledge-driven multi-agent reinforcement learning (KMARL) approach to reduce the latency of task offloading in cybertwin-enabled IoV. Specifically, in the considered scenario, the cybertwin serves as a communication agent for each vehicle to exchange information and make offloading decisions in the virtual space. To reduce the latency of task offloading, a KMARL approach is proposed to select the optimal offloading option for each vehicle, where graph neural networks are employed by leveraging domain knowledge concerning graph-structure communication topology and permutation
    
[^44]: 分支潜在神经算子

    Branched Latent Neural Operators. (arXiv:2308.02599v1 [cs.LG])

    [http://arxiv.org/abs/2308.02599](http://arxiv.org/abs/2308.02599)

    Branched Latent Neural Operators (BLNOs) are introduced to learn input-output maps for encoding complex physical processes. BLNOs utilize interpretable latent outputs to enhance learned dynamics and overcome the curse of dimensionality, while also showing excellent generalization properties with small training datasets and short training times. The partial connection structure reduces the number of tunable parameters. BLNOs are proven effective in a challenging biophysically detailed test case.

    

    我们介绍了分支潜在神经算子（BLNOs）来学习编码复杂物理过程的输入-输出映射。BLNO由一个简单紧凑的前馈部分连接神经网络定义，该网络在结构上将不同固有角色的输入进行解离，例如将微分方程的时间变量与模型参数分离，并将它们转化为感兴趣的通用领域。BLNO利用可解释的潜在输出增强了学习到的动态，并通过在单个处理器上使用小的训练数据集和短的训练时间展示了出色的泛化性能。实际上，它们的泛化误差在测试阶段采用的离散化方式相同的情况下保持可比性。此外，部分连接在全连接结构的基础上显著减少了可调参数的数量。我们展示了BLNO在涉及生物物理细节的具有挑战性的测试案例中的能力。

    We introduce Branched Latent Neural Operators (BLNOs) to learn input-output maps encoding complex physical processes. A BLNO is defined by a simple and compact feedforward partially-connected neural network that structurally disentangles inputs with different intrinsic roles, such as the time variable from model parameters of a differential equation, while transferring them into a generic field of interest. BLNOs leverage interpretable latent outputs to enhance the learned dynamics and break the curse of dimensionality by showing excellent generalization properties with small training datasets and short training times on a single processor. Indeed, their generalization error remains comparable regardless of the adopted discretization during the testing phase. Moreover, the partial connections, in place of a fully-connected structure, significantly reduce the number of tunable parameters. We show the capabilities of BLNOs in a challenging test case involving biophysically detailed elect
    
[^45]: 设计一种基于深度学习的资源高效诊断系统，用于转移性乳腺癌：减少发展中国家临床诊断的长时间延迟，提高患者生存率

    Designing a Deep Learning-Driven Resource-Efficient Diagnostic System for Metastatic Breast Cancer: Reducing Long Delays of Clinical Diagnosis and Improving Patient Survival in Developing Countries. (arXiv:2308.02597v1 [eess.IV])

    [http://arxiv.org/abs/2308.02597](http://arxiv.org/abs/2308.02597)

    这项研究设计了一种基于深度学习的诊断系统，用于转移性乳腺癌的诊断，旨在减少发展中国家临床诊断的长时间延迟，并提高患者的生存率。

    

    乳腺癌是癌症死亡的主要原因之一。发展中国家，特别是撒哈拉以南非洲、南亚和南美的乳腺癌患者死亡率最高。导致全球死亡率差距的关键因素之一是由于受训病理学家严重短缺而导致的诊断长时间延迟，从而导致诊断时较大比例的晚期表现。初始症状发展到诊断接受时间可能长达15个月。为解决这一关键的医疗差距，本研究开发了一种基于深度学习的转移性乳腺癌诊断系统，既能达到高诊断准确度，又能保证计算效率。根据我们的评估，基于MobileNetV2的诊断模型在诊断准确度、模型泛化性和模型训练方面超过了更复杂的VGG16、ResNet50和ResNet101模型。

    Breast cancer is one of the leading causes of cancer mortality. Breast cancer patients in developing countries, especially sub-Saharan Africa, South Asia, and South America, suffer from the highest mortality rate in the world. One crucial factor contributing to the global disparity in mortality rate is long delay of diagnosis due to a severe shortage of trained pathologists, which consequently has led to a large proportion of late-stage presentation at diagnosis. The delay between the initial development of symptoms and the receipt of a diagnosis could stretch upwards 15 months. To tackle this critical healthcare disparity, this research has developed a deep learning-based diagnosis system for metastatic breast cancer that can achieve high diagnostic accuracy as well as computational efficiency. Based on our evaluation, the MobileNetV2-based diagnostic model outperformed the more complex VGG16, ResNet50 and ResNet101 models in diagnostic accuracy, model generalization, and model traini
    
[^46]: SMARLA：一种用于深度强化学习智能体的安全监测方法

    SMARLA: A Safety Monitoring Approach for Deep Reinforcement Learning Agents. (arXiv:2308.02594v1 [cs.LG])

    [http://arxiv.org/abs/2308.02594](http://arxiv.org/abs/2308.02594)

    本文提出了一种基于机器学习的安全监测方法SMARLA，用于深度强化学习智能体。该方法设计为黑盒子，利用状态抽象减少状态空间，实现对智能体状态的安全违规预测。经验证，SMARLA具有准确的违规预测能力，并可在智能体执行的早期阶段进行预测。

    

    深度强化学习算法(DRL)越来越多地应用于安全关键系统。确保DRL智能体的安全性在这种情况下是一个关键问题。然而，仅依靠测试是不足以确保安全性的，因为它不能提供保证。构建安全监测器是缓解这一挑战的一种解决方案。本文提出了SMARLA，一种基于机器学习的安全监测方法，专为DRL智能体设计。出于实际原因，SMARLA被设计为黑盒子(因为它不需要访问智能体的内部)，并利用状态抽象来减少状态空间，从而促进从智能体的状态学习安全违规预测模型。我们在两个知名的RL案例研究中验证了SMARLA。经验分析表明，SMARLA具有准确的违规预测能力，误报率低，并且可以在智能体执行的一半左右的早期阶段预测安全违规。

    Deep reinforcement learning algorithms (DRL) are increasingly being used in safety-critical systems. Ensuring the safety of DRL agents is a critical concern in such contexts. However, relying solely on testing is not sufficient to ensure safety as it does not offer guarantees. Building safety monitors is one solution to alleviate this challenge. This paper proposes SMARLA, a machine learning-based safety monitoring approach designed for DRL agents. For practical reasons, SMARLA is designed to be black-box (as it does not require access to the internals of the agent) and leverages state abstraction to reduce the state space and thus facilitate the learning of safety violation prediction models from agent's states. We validated SMARLA on two well-known RL case studies. Empirical analysis reveals that SMARLA achieves accurate violation prediction with a low false positive rate, and can predict safety violations at an early stage, approximately halfway through the agent's execution before 
    
[^47]: 用微笑揭示帕金森病：一种基于人工智能的筛查框架

    Unmasking Parkinson's Disease with Smile: An AI-enabled Screening Framework. (arXiv:2308.02588v1 [eess.IV])

    [http://arxiv.org/abs/2308.02588](http://arxiv.org/abs/2308.02588)

    本研究使用微表情视频数据集开发了一种基于人工智能的帕金森病筛查框架，通过分析微笑视频中的特征，实现了89.7%的准确性和89.3%的AUROC值，同时在人群子组上没有检测到偏见。

    

    鉴于目前缺乏可靠的生物标志物和有限的临床护理资源，帕金森病（PD）的诊断仍然具有挑战性。在本研究中，我们使用包含微表情的最大视频数据集进行PD筛查的分析。我们收集了来自1,059名独立参与者的3,871个视频，其中包括256名自报PD患者。这些录像来自不同来源，包括多个国家的参与者家中、一家诊所和一个美国的PD护理机构。通过利用面部标志和行动单位，我们提取了与PD的一个主要症状Hypomimia（面部表情减少）相关的特征。在这些特征上训练的一组AI模型在保留数据上实现了89.7%的准确性和89.3%的接收者操作特性曲线下面积（AUROC），并且在性别和种族等人群子组上无可检测的偏见。进一步的分析揭示，仅通过微笑视频中的特征就可以获得可比较的准确性和AUROC值。

    Parkinson's disease (PD) diagnosis remains challenging due to lacking a reliable biomarker and limited access to clinical care. In this study, we present an analysis of the largest video dataset containing micro-expressions to screen for PD. We collected 3,871 videos from 1,059 unique participants, including 256 self-reported PD patients. The recordings are from diverse sources encompassing participants' homes across multiple countries, a clinic, and a PD care facility in the US. Leveraging facial landmarks and action units, we extracted features relevant to Hypomimia, a prominent symptom of PD characterized by reduced facial expressions. An ensemble of AI models trained on these features achieved an accuracy of 89.7% and an Area Under the Receiver Operating Characteristic (AUROC) of 89.3% while being free from detectable bias across population subgroups based on sex and ethnicity on held-out data. Further analysis reveals that features from the smiling videos alone lead to comparable 
    
[^48]: 使用引导扩散模型合成罕见白内障手术样本

    Synthesising Rare Cataract Surgery Samples with Guided Diffusion Models. (arXiv:2308.02587v1 [eess.IV])

    [http://arxiv.org/abs/2308.02587](http://arxiv.org/abs/2308.02587)

    本研究通过使用引导扩散模型合成白内障手术样本，解决了数据不平衡对分类器性能的负面影响，实现了多类多标签条件下的高质量样本合成。

    

    白内障手术是一个经常进行的需要自动化和先进辅助系统的程序。然而，收集和标注用于训练这些系统的数据是资源密集型的。公开可用的数据也包含手术过程中固有的严重不平衡。受此启发，我们分析了白内障手术视频数据，针对预训练下游工具分类器的表现最差的阶段。分析表明，不平衡会使分类器在少数被低估的情况下的性能恶化。为了解决这个挑战，我们利用基于去噪扩散隐式模型（DDIM）和无分类器引导（CFG）的条件生成模型。我们的模型可以根据复杂的多类多标签条件（如手术阶段和手术工具组合）合成多样化、高质量的样本。我们确认合成的样本显示出分类器识别的工具。这些样本很难与真实样本区分开来。

    Cataract surgery is a frequently performed procedure that demands automation and advanced assistance systems. However, gathering and annotating data for training such systems is resource intensive. The publicly available data also comprises severe imbalances inherent to the surgical process. Motivated by this, we analyse cataract surgery video data for the worst-performing phases of a pre-trained downstream tool classifier. The analysis demonstrates that imbalances deteriorate the classifier's performance on underrepresented cases. To address this challenge, we utilise a conditional generative model based on Denoising Diffusion Implicit Models (DDIM) and Classifier-Free Guidance (CFG). Our model can synthesise diverse, high-quality examples based on complex multi-class multi-label conditions, such as surgical phases and combinations of surgical tools. We affirm that the synthesised samples display tools that the classifier recognises. These samples are hard to differentiate from real i
    
[^49]: 将代理策略与外部性对齐：通过双层强化学习设计奖励

    Aligning Agent Policy with Externalities: Reward Design via Bilevel RL. (arXiv:2308.02585v1 [cs.LG])

    [http://arxiv.org/abs/2308.02585](http://arxiv.org/abs/2308.02585)

    本文提出了一种将强化学习的策略优化与外部性对齐的方法，通过双层优化框架和委托-代理框架，上层学习适当的奖励参数化，下层学习代理人的策略。

    

    在强化学习中，通常在策略优化过程的开始处假设一个奖励函数。在这种固定奖励范式下的学习中，可能会忽略重要的策略优化考虑因素，比如状态空间覆盖和安全性。此外，它可能无法涵盖社会福利、可持续性或市场稳定性方面的更广泛影响，可能导致不可取的 emergent 行为和可能不对齐的策略。为了数学化地概括将强化学习的策略优化与这种外在性对齐问题，我们考虑了一个双层优化问题，并将其与委托-代理框架相联系，在这个框架中，委托人在上层确定系统的更广泛目标和约束，代理人在下层解决一个马尔可夫决策过程。上层任务是学习一个与更广泛目标相对应的适当奖励参数化，下层任务是学习代理人的策略。

    In reinforcement learning (RL), a reward function is often assumed at the outset of a policy optimization procedure. Learning in such a fixed reward paradigm in RL can neglect important policy optimization considerations, such as state space coverage and safety. Moreover, it can fail to encompass broader impacts in terms of social welfare, sustainability, or market stability, potentially leading to undesirable emergent behavior and potentially misaligned policy. To mathematically encapsulate the problem of aligning RL policy optimization with such externalities, we consider a bilevel optimization problem and connect it to a principal-agent framework, where the principal specifies the broader goals and constraints of the system at the upper level and the agent solves a Markov Decision Process (MDP) at the lower level. The upper-level deals with learning a suitable reward parametrization corresponding to the broader goals and the lower-level deals with learning the policy for the agent. 
    
[^50]: 通过领域适应的最少到最多提示的方式实现文本到SQL的高效泛化

    Adapt and Decompose: Efficient Generalization of Text-to-SQL via Domain Adapted Least-To-Most Prompting. (arXiv:2308.02582v1 [cs.CL])

    [http://arxiv.org/abs/2308.02582](http://arxiv.org/abs/2308.02582)

    该论文介绍了一种通过领域适应和最少到最多提示的方式实现文本到SQL的高效泛化的方法。通过离线抽样获取少量样本，并合成一个通用提示，避免了昂贵的测试时间样本检索，并通过自适应和分解的方法更好地处理跨领域和跨组合式的泛化。

    

    跨领域和跨组合式的文本到SQL语义解析的泛化是一项具有挑战性的任务。现有的基于大型语言模型（LLM）的解决方案依赖于从训练集中推理出少量样本，以合成每个自然语言（NL）测试查询的运行时提示。与此相反，我们设计了一种算法，该算法通过离线抽样从训练数据中获取少量样本，完全覆盖SQL子句、运算符和函数，并在允许的令牌长度范围内实现最大领域覆盖。这样可以合成一个固定的通用提示（GP），其中包含NL测试查询之间共用的多样化样本集，避免了昂贵的测试时间样本检索。我们还将GP自适应到目标数据库领域（DA-GP），以更好地处理跨领域泛化；然后采用分解的最少到最多提示（LTMP-DA-GP）来处理跨组合泛化。LTMP-DA-GP的合成是离线任务，

    Cross-domain and cross-compositional generalization of Text-to-SQL semantic parsing is a challenging task. Existing Large Language Model (LLM) based solutions rely on inference-time retrieval of few-shot exemplars from the training set to synthesize a run-time prompt for each Natural Language (NL) test query. In contrast, we devise an algorithm which performs offline sampling of a minimal set-of few-shots from the training data, with complete coverage of SQL clauses, operators and functions, and maximal domain coverage within the allowed token length. This allows for synthesis of a fixed Generic Prompt (GP), with a diverse set-of exemplars common across NL test queries, avoiding expensive test time exemplar retrieval. We further auto-adapt the GP to the target database domain (DA-GP), to better handle cross-domain generalization; followed by a decomposed Least-To-Most-Prompting (LTMP-DA-GP) to handle cross-compositional generalization. The synthesis of LTMP-DA-GP is an offline task, to
    
[^51]: 地下网络论坛中提取相关信息点的方法：奶油撇取

    Cream Skimming the Underground: Identifying Relevant Information Points from Online Forums. (arXiv:2308.02581v1 [cs.CR])

    [http://arxiv.org/abs/2308.02581](http://arxiv.org/abs/2308.02581)

    本文提出了一种基于机器学习的方法，通过监控地下黑客论坛来检测野外漏洞的利用。通过对CrimeBB数据集进行分析，开发了一个监督机器学习模型，可以过滤引用CVE的主题并将其标记为Proof-of-Concept、武器化或漏洞利用。利用随机森林，可以达到准确率、精确率和召回率大于0.99。同时，还提供了对武器化和漏洞利用之间性质差异的insights，以及对黑客社区利润和其他相关方面的分析。

    

    本文提出了一种基于机器学习的方法，用于通过监控地下黑客论坛来检测野外漏洞的利用。讨论野外漏洞利用的帖子数量不断增加，需要自动处理帖子和主题，并根据其内容触发警报。为了说明所提出的系统，我们使用了CrimeBB数据集，该数据集包含从多个地下论坛抓取的数据，并开发了一个监督机器学习模型，可以过滤引用CVE的主题并将其标记为Proof-of-Concept、武器化或漏洞利用。通过利用随机森林，我们指出对于分类任务来说，可以达到准确率、精确率和召回率大于0.99。此外，我们对武器化和漏洞利用之间的性质差异提供了insights，例如解释决策树的输出，并分析了黑客社区的利润和其他相关方面。总体而言，我们提供了一个从地下黑客论坛中提取相关信息点的机器学习方法。

    This paper proposes a machine learning-based approach for detecting the exploitation of vulnerabilities in the wild by monitoring underground hacking forums. The increasing volume of posts discussing exploitation in the wild calls for an automatic approach to process threads and posts that will eventually trigger alarms depending on their content. To illustrate the proposed system, we use the CrimeBB dataset, which contains data scraped from multiple underground forums, and develop a supervised machine learning model that can filter threads citing CVEs and label them as Proof-of-Concept, Weaponization, or Exploitation. Leveraging random forests, we indicate that accuracy, precision and recall above 0.99 are attainable for the classification task. Additionally, we provide insights into the difference in nature between weaponization and exploitation, e.g., interpreting the output of a decision tree, and analyze the profits and other aspects related to the hacking communities. Overall, ou
    
[^52]: Probabilistic Deep Supervision Network: 一种抗噪声的QoS预测方法

    Probabilistic Deep Supervision Network: A Noise-Resilient Approach for QoS Prediction. (arXiv:2308.02580v1 [cs.SE])

    [http://arxiv.org/abs/2308.02580](http://arxiv.org/abs/2308.02580)

    PDS-Net is a novel framework for QoS prediction that effectively reduces errors resulting from noise data by utilizing a probabilistic space and a condition-based multitasking loss function.

    

    在推荐系统中，QoS（服务质量）的预测是一项重要任务，准确预测未知的QoS值可以提高用户满意度。然而，现有的QoS预测技术在存在噪声数据（如虚假位置信息或虚拟网关）时可能表现不佳。在本文中，我们提出了一种新颖的QoS预测框架——概率深度监督网络（PDS-Net），以解决这个问题。PDS-Net利用基于高斯的概率空间监督中间层，并学习已知特征和真实标签的概率空间。此外，PDS-Net采用基于条件的多任务损失函数来识别具有噪声数据的对象，并通过优化这些对象的概率空间与真实标签概率空间之间的Kullback-Leibler距离，直接对从概率空间中采样的深度特征进行监督。因此，PDS-Net有效减少了因传播引起的错误。

    Quality of Service (QoS) prediction is an essential task in recommendation systems, where accurately predicting unknown QoS values can improve user satisfaction. However, existing QoS prediction techniques may perform poorly in the presence of noise data, such as fake location information or virtual gateways. In this paper, we propose the Probabilistic Deep Supervision Network (PDS-Net), a novel framework for QoS prediction that addresses this issue. PDS-Net utilizes a Gaussian-based probabilistic space to supervise intermediate layers and learns probability spaces for both known features and true labels. Moreover, PDS-Net employs a condition-based multitasking loss function to identify objects with noise data and applies supervision directly to deep features sampled from the probability space by optimizing the Kullback-Leibler distance between the probability space of these objects and the real-label probability space. Thus, PDS-Net effectively reduces errors resulting from the propag
    
[^53]: ADRNet：结合临床和非临床数据的广义协同过滤框架用于不良药物反应预测

    ADRNet: A Generalized Collaborative Filtering Framework Combining Clinical and Non-Clinical Data for Adverse Drug Reaction Prediction. (arXiv:2308.02571v1 [cs.IR])

    [http://arxiv.org/abs/2308.02571](http://arxiv.org/abs/2308.02571)

    本文提出了ADRNet，这是一个将临床和非临床数据结合起来的广义协同过滤框架，用于预测不良药物反应。该模型在两个大型公开临床数据集上提供了先前协同过滤方法的广泛基准结果。

    

    不良药物反应（ADR）的预测在医疗保健和药物发现中起着至关重要的作用，可以降低患者死亡率并增强药物安全性。最近，许多研究致力于有效预测药物-ADR发生率。然而，这些方法要么没有有效利用非临床数据，即有关药物的物理、化学和生物信息，要么在训练阶段很少建立内容分析和纯协同过滤之间的联系。本文首先将多标签ADR的预测形式化为药物-ADR协同过滤问题，并且据我们所知，这是首个在两个大型公开临床数据集上提供先前协同过滤方法广泛基准结果的工作。然后，通过利用来自非临床数据的易获得的药物特性，我们提出了ADRNet，这是一个结合临床和非临床数据的广义协同过滤框架。

    Adverse drug reaction (ADR) prediction plays a crucial role in both health care and drug discovery for reducing patient mortality and enhancing drug safety. Recently, many studies have been devoted to effectively predict the drug-ADRs incidence rates. However, these methods either did not effectively utilize non-clinical data, i.e., physical, chemical, and biological information about the drug, or did little to establish a link between content-based and pure collaborative filtering during the training phase. In this paper, we first formulate the prediction of multi-label ADRs as a drug-ADR collaborative filtering problem, and to the best of our knowledge, this is the first work to provide extensive benchmark results of previous collaborative filtering methods on two large publicly available clinical datasets. Then, by exploiting the easy accessible drug characteristics from non-clinical data, we propose ADRNet, a generalized collaborative filtering framework combining clinical and non-
    
[^54]: 通过双向生成对齐学习隐式实体-物体关系，用于多模态NER

    Learning Implicit Entity-object Relations by Bidirectional Generative Alignment for Multimodal NER. (arXiv:2308.02570v1 [cs.LG])

    [http://arxiv.org/abs/2308.02570](http://arxiv.org/abs/2308.02570)

    本文提出了一种名为BGA-MNER的双向生成对齐方法，用于解决多模态命名实体识别中的两个主要挑战：语义鸿沟和实体-物体关系。实验结果表明，该方法能够有效地捕捉隐式实体-物体关系。

    

    多模态命名实体识别(MNER)面临的挑战主要有两方面: (1) 弥合文本和图像之间的语义鸿沟; (2) 匹配实体与图像中其关联的物体。现有方法无法捕捉隐含的实体-物体关系，因为缺乏相应的注释。本文提出了一种名为BGA-MNER的双向生成对齐方法来解决这些问题。我们的BGA-MNER包括针对两种模态中的实体显著内容的\texttt{图像到文本}和\texttt{文本到图像}生成。它通过共同优化双向重建目标来对齐隐含的实体-物体关系，在直接而强大的约束下实现对齐。此外，图像-文本对通常包含不匹配的组件，对于生成来说是噪声。我们提出了一种阶段性改进的上下文采样器，用于提取匹配的跨模态内容进行生成。在两个基准测试中进行的广泛实验证明了我们的方法。

    The challenge posed by multimodal named entity recognition (MNER) is mainly two-fold: (1) bridging the semantic gap between text and image and (2) matching the entity with its associated object in image. Existing methods fail to capture the implicit entity-object relations, due to the lack of corresponding annotation. In this paper, we propose a bidirectional generative alignment method named BGA-MNER to tackle these issues. Our BGA-MNER consists of \texttt{image2text} and \texttt{text2image} generation with respect to entity-salient content in two modalities. It jointly optimizes the bidirectional reconstruction objectives, leading to aligning the implicit entity-object relations under such direct and powerful constraints. Furthermore, image-text pairs usually contain unmatched components which are noisy for generation. A stage-refined context sampler is proposed to extract the matched cross-modal content for generation. Extensive experiments on two benchmarks demonstrate that our met
    
[^55]: 加权多级特征分解在应用程序广告的CTR和安装预测中的应用

    Weighted Multi-Level Feature Factorization for App ads CTR and installation prediction. (arXiv:2308.02568v1 [cs.IR])

    [http://arxiv.org/abs/2308.02568](http://arxiv.org/abs/2308.02568)

    加权多级特征分解方法应用于应用程序广告的CTR和安装预测，通过工程化特定特征和共享特征的交互，取得了较好的结果。

    

    本论文提供了团队ISISTANITOS在ACM RecSys Challenge 2023中所使用的方法概述。该竞赛由ShareChat组织，涉及预测用户点击应用程序广告和/或安装应用程序的概率，以改善深度漏斗优化，并特别关注用户隐私。我们提出的方法将点击和安装的概率推断为两个不同但相关的任务。因此，模型根据不同任务和一组共享特征工程化了一组特定特征。我们的模型称为加权多级特征分解，因为它考虑到不同级别特征的交互，其中级别与神经网络中的深度相关。给定任务的预测是通过在不同级别上组合任务特定和共享特征来生成的。我们在学术领域的比赛中获得了11名和55的总体得分。我们在以下网址发布了源代码：https://githu

    This paper provides an overview of the approach we used as team ISISTANITOS for the ACM RecSys Challenge 2023. The competition was organized by ShareChat, and involved predicting the probability of a user clicking an app ad and/or installing an app, to improve deep funnel optimization and a special focus on user privacy. Our proposed method inferring the probabilities of clicking and installing as two different, but related tasks. Hence, the model engineers a specific set of features for each task and a set of shared features. Our model is called Weighted Multi-Level Feature Factorization because it considers the interaction of different order features, where the order is associated to the depth in a neural network. The prediction for a given task is generated by combining the task specific and shared features on the different levels. Our submission achieved the 11 rank and overall score of 55 in the competition academia-track final results. We release our source code at: https://githu
    
[^56]: 使用视觉和文本数据的联合表示进行食物分类

    Food Classification using Joint Representation of Visual and Textual Data. (arXiv:2308.02562v1 [cs.CV])

    [http://arxiv.org/abs/2308.02562](http://arxiv.org/abs/2308.02562)

    本研究提出了一种使用联合表示的多模态分类框架，通过修改版的EfficientNet和Mish激活函数实现图像分类，使用基于BERT的网络实现文本分类。实验结果表明，所提出的网络在图像和文本分类上表现优于其他方法，准确率提高了11.57%和6.34%。比较分析还证明了所提出方法的效率和鲁棒性。

    

    食物分类是健康保健中的重要任务。在这项工作中，我们提出了一个多模态分类框架，该框架使用了修改版的EfficientNet和Mish激活函数用于图像分类，同时使用传统的基于BERT的网络进行文本分类。我们在一个大型开源数据集UPMC Food-101上评估了所提出的网络和其他最先进的方法。实验结果显示，所提出的网络在图像和文本分类上的准确率分别比第二最好的方法提高了11.57%和6.34%。我们还比较了使用机器学习和深度学习模型进行文本分类的准确率、精确率和召回率。通过对图像和文本的预测结果进行比较分析，证明了所提出方法的效率和鲁棒性。

    Food classification is an important task in health care. In this work, we propose a multimodal classification framework that uses the modified version of EfficientNet with the Mish activation function for image classification, and the traditional BERT transformer-based network is used for text classification. The proposed network and the other state-of-the-art methods are evaluated on a large open-source dataset, UPMC Food-101. The experimental results show that the proposed network outperforms the other methods, a significant difference of 11.57% and 6.34% in accuracy is observed for image and text classification, respectively, when compared with the second-best performing method. We also compared the performance in terms of accuracy, precision, and recall for text classification using both machine learning and deep learning-based models. The comparative analysis from the prediction results of both images and text demonstrated the efficiency and robustness of the proposed approach.
    
[^57]: 从离散标记到高保真音频：使用多频带扩散模型

    From Discrete Tokens to High-Fidelity Audio Using Multi-Band Diffusion. (arXiv:2308.02560v1 [cs.SD])

    [http://arxiv.org/abs/2308.02560](http://arxiv.org/abs/2308.02560)

    提出了一种高保真多频带扩散模型，可以根据低比特率的离散表示生成任何类型的音频形式，具有优于最先进生成技术的感知质量。

    

    深度生成模型可以根据各种表示（如mel频谱、MFCC）生成高保真音频。最近，这样的模型已经被用于根据高度压缩的表示合成音频波形。尽管这些方法产生了令人印象深刻的结果，但是当条件不完美时，易于产生可听到的伪影。另一种建模方法是使用扩散模型。然而，这些模型主要用作语音模型（或基于mel频谱的条件模型）或生成相对较低采样率的信号。在这项工作中，我们提出了一个高保真多频带扩散模型，可以根据低比特率的离散表示生成任何类型的音频形式（如语音、音乐、环境声音）。在相同的比特率下，所提出的方法在感知质量上优于最先进的生成技术。

    Deep generative models can generate high-fidelity audio conditioned on various types of representations (e.g., mel-spectrograms, Mel-frequency Cepstral Coefficients (MFCC)). Recently, such models have been used to synthesize audio waveforms conditioned on highly compressed representations. Although such methods produce impressive results, they are prone to generate audible artifacts when the conditioning is flawed or imperfect. An alternative modeling approach is to use diffusion models. However, these have mainly been used as speech vocoders (i.e., conditioned on mel-spectrograms) or generating relatively low sampling rate signals. In this work, we propose a high-fidelity multi-band diffusion-based framework that generates any type of audio modality (e.g., speech, music, environmental sounds) from low-bitrate discrete representations. At equal bit rate, the proposed approach outperforms state-of-the-art generative techniques in terms of perceptual quality. Training and, evaluation cod
    
[^58]: DLSIA: 用于科学图像分析的深度学习

    DLSIA: Deep Learning for Scientific Image Analysis. (arXiv:2308.02559v1 [cs.CV])

    [http://arxiv.org/abs/2308.02559](http://arxiv.org/abs/2308.02559)

    DLSIA是一种Python的机器学习库，为科学家提供了定制化卷积神经网络架构，加速科学图像分析研究，并促进跨学科合作。

    

    我们介绍了一种名为DLSIA（Deep Learning for Scientific Image Analysis）的基于Python的机器学习库，该库为科学家和研究人员提供了一系列可定制的卷积神经网络（CNN）架构，用于广泛的图像分析任务，以进行下游数据处理或实验中的计算环境。DLSIA包含易于使用的架构，如自动编码器，可调的U-Net和参数精简的混合尺度稠密网络（MSDNets）。此外，我们还介绍了使用随机图和稀疏连接生成的稀疏混合尺度网络（SMSNets）。随着实验数据的规模和复杂性不断增长，DLSIA提供了易于访问的CNN构建和抽象CNN复杂性的方法，使科学家能够定制他们的机器学习方法，加速发现，促进跨学科合作并推动科学图像分析的研究。

    We introduce DLSIA (Deep Learning for Scientific Image Analysis), a Python-based machine learning library that empowers scientists and researchers across diverse scientific domains with a range of customizable convolutional neural network (CNN) architectures for a wide variety of tasks in image analysis to be used in downstream data processing, or for experiment-in-the-loop computing scenarios. DLSIA features easy-to-use architectures such as autoencoders, tunable U-Nets, and parameter-lean mixed-scale dense networks (MSDNets). Additionally, we introduce sparse mixed-scale networks (SMSNets), generated using random graphs and sparse connections. As experimental data continues to grow in scale and complexity, DLSIA provides accessible CNN construction and abstracts CNN complexities, allowing scientists to tailor their machine learning approaches, accelerate discoveries, foster interdisciplinary collaboration, and advance research in scientific image analysis.
    
[^59]: 对于物联网设备的计算机视觉技术调查

    Survey on Computer Vision Techniques for Internet-of-Things Devices. (arXiv:2308.02553v1 [cs.CV])

    [http://arxiv.org/abs/2308.02553](http://arxiv.org/abs/2308.02553)

    本文调查了在物联网设备上部署DNN的低功耗和节能实现的最新进展，这些技术通过减少内存需求和减少算术操作数量改善了DNN的可部署性，并且不显著牺牲准确性。

    

    深度神经网络（DNN）是解决大多数计算机视觉问题的最先进技术。DNN需要数十亿的参数和操作才能达到最先进的结果。这个要求使得DNN非常依赖计算、内存和能量，并且难以在具有有限计算资源的小型电池供电的物联网（IoT）设备上部署。在物联网设备上部署DNN，如交通摄像头，可以通过实现自动事故检测和紧急响应等应用来提高公共安全性。通过本文，我们调查了最新的低功率和节能的DNN实现的进展，这些实现提高了DNN的可部署性而不显著牺牲准确性。一般来说，这些技术要么减少内存需求，要么减少算术操作的数量，或者两者兼而有之。这些技术可以分为三大类：神经网络压缩，网络架构搜索和

    Deep neural networks (DNNs) are state-of-the-art techniques for solving most computer vision problems. DNNs require billions of parameters and operations to achieve state-of-the-art results. This requirement makes DNNs extremely compute, memory, and energy-hungry, and consequently difficult to deploy on small battery-powered Internet-of-Things (IoT) devices with limited computing resources. Deployment of DNNs on Internet-of-Things devices, such as traffic cameras, can improve public safety by enabling applications such as automatic accident detection and emergency response.Through this paper, we survey the recent advances in low-power and energy-efficient DNN implementations that improve the deployability of DNNs without significantly sacrificing accuracy. In general, these techniques either reduce the memory requirements, the number of arithmetic operations, or both. The techniques can be divided into three major categories: neural network compression, network architecture search and 
    
[^60]: qgym: 用于训练和基准测试基于强化学习的量子编译的健身房

    qgym: A Gym for Training and Benchmarking RL-Based Quantum Compilation. (arXiv:2308.02536v1 [quant-ph])

    [http://arxiv.org/abs/2308.02536](http://arxiv.org/abs/2308.02536)

    qgym是一个用于训练和基准测试基于强化学习的量子编译的健身房，旨在优化并连接人工智能与量子编译的研究领域。

    

    将量子电路编译为特定的量子硬件是一项具有挑战性的任务。此外，当前的量子计算机存在严重的硬件限制。为了发挥有限资源的最大作用，编译过程应进行优化。为了改进当前的方法，可以使用强化学习（RL），这是一种技术，其中代理与环境交互以学习复杂策略以达到特定目标。在这项工作中，我们提出了qgym，这是一个从OpenAI gym派生的软件框架，以及专门针对量子编译的环境。qgym的目标是通过抽象对于两个领域都无关的过程的部分，将人工智能（AI）的研究领域与量子编译相连接。它可以用于在高度可定制的环境中训练和基准测试RL代理和算法。

    Compiling a quantum circuit for specific quantum hardware is a challenging task. Moreover, current quantum computers have severe hardware limitations. To make the most use of the limited resources, the compilation process should be optimized. To improve currents methods, Reinforcement Learning (RL), a technique in which an agent interacts with an environment to learn complex policies to attain a specific goal, can be used. In this work, we present qgym, a software framework derived from the OpenAI gym, together with environments that are specifically tailored towards quantum compilation. The goal of qgym is to connect the research fields of Artificial Intelligence (AI) with quantum compilation by abstracting parts of the process that are irrelevant to either domain. It can be used to train and benchmark RL agents and algorithms in highly customizable environments.
    
[^61]: 学习生成用于鲁棒语义分割的训练数据集

    Learning to Generate Training Datasets for Robust Semantic Segmentation. (arXiv:2308.02535v1 [cs.CV])

    [http://arxiv.org/abs/2308.02535](http://arxiv.org/abs/2308.02535)

    本文提出了一种新的方法，通过生成真实和可信的扰动或异常图像来提高语义分割技术的鲁棒性。通过设计和训练Robusta，一种鲁棒的条件生成对抗网络，可以为训练可靠的分割模型提供可用的数据集，从而显著增强语义分割技术在面对现实世界的扰动和分布变化时的鲁棒性。

    

    近年来，语义分割技术取得了显著进展，但是它们对现实世界的扰动和训练过程中未见过的数据样本的鲁棒性仍然是一个挑战，尤其是在安全关键的应用中。本文提出了一种新的方法，通过利用标签到图像生成器和图像到标签分割模型之间的协同作用来提高语义分割技术的鲁棒性。具体来说，我们设计并训练了一个新的鲁棒的条件生成对抗网络Robusta，用于生成真实和可信的扰动或异常图像，这些图像可以用来训练可靠的分割模型。我们对所提出的生成模型进行了深入研究，评估了下游分割网络的性能和鲁棒性，并证明我们的方法可以显著提高语义分割技术在面对现实世界的扰动、分布变化和超出分布的情况下的鲁棒性。

    Semantic segmentation techniques have shown significant progress in recent years, but their robustness to real-world perturbations and data samples not seen during training remains a challenge, particularly in safety-critical applications. In this paper, we propose a novel approach to improve the robustness of semantic segmentation techniques by leveraging the synergy between label-to-image generators and image-to-label segmentation models. Specifically, we design and train Robusta, a novel robust conditional generative adversarial network to generate realistic and plausible perturbed or outlier images that can be used to train reliable segmentation models. We conduct in-depth studies of the proposed generative model, assess the performance and robustness of the downstream segmentation network, and demonstrate that our approach can significantly enhance the robustness of semantic segmentation techniques in the face of real-world perturbations, distribution shifts, and out-of-distributi
    
[^62]: 通过强化关键鲁棒性微调来提高对抗训练的泛化能力

    Improving Generalization of Adversarial Training via Robust Critical Fine-Tuning. (arXiv:2308.02533v1 [cs.LG])

    [http://arxiv.org/abs/2308.02533](http://arxiv.org/abs/2308.02533)

    本文提出了一种名为鲁棒性关键微调（RiFT）的方法，通过在非关键鲁棒模块上微调经过对抗训练的模型来提高泛化能力，而不损害对抗性鲁棒性。

    

    深度神经网络容易受到对抗样本的攻击，这在关键应用中带来了重大的安全风险。对抗训练（AT）是提高对抗性鲁棒性的一种成熟技术，但往往会导致泛化能力的下降。本文提出了一种新颖的方法，即鲁棒性关键微调（RiFT），以提高泛化能力而不损害对抗性鲁棒性。RiFT的核心思想是通过在非关键鲁棒模块上微调经过对抗训练的模型，利用冗余容量来增强模型的鲁棒性。为此，我们引入了模块鲁棒关键性（MRC）指标，用于评估给定模块在最坏情况下权重扰动下对模型鲁棒性的重要性。利用这个指标，我们找到具有最低MRC值的模块作为非关键鲁棒模块，并微调其权重以获得微调后的权重。随后，我们在经过对抗训练的权重和微调后的权重之间进行线性插值。

    Deep neural networks are susceptible to adversarial examples, posing a significant security risk in critical applications. Adversarial Training (AT) is a well-established technique to enhance adversarial robustness, but it often comes at the cost of decreased generalization ability. This paper proposes Robustness Critical Fine-Tuning (RiFT), a novel approach to enhance generalization without compromising adversarial robustness. The core idea of RiFT is to exploit the redundant capacity for robustness by fine-tuning the adversarially trained model on its non-robust-critical module. To do so, we introduce module robust criticality (MRC), a measure that evaluates the significance of a given module to model robustness under worst-case weight perturbations. Using this measure, we identify the module with the lowest MRC value as the non-robust-critical module and fine-tune its weights to obtain fine-tuned weights. Subsequently, we linearly interpolate between the adversarially trained weight
    
[^63]: 评估ChatGPT和GPT-4在视觉编程中的应用

    Evaluating ChatGPT and GPT-4 for Visual Programming. (arXiv:2308.02522v1 [cs.LG])

    [http://arxiv.org/abs/2308.02522](http://arxiv.org/abs/2308.02522)

    本研究评估了ChatGPT和GPT-4在视觉编程领域的应用，并发现它们具备与基于文本的Python编程相当的高级能力。

    

    生成式人工智能和大型语言模型有潜力通过自动生成个性化反馈和内容来极大改善计算机教育的格局。最近的研究探讨了这些模型在不同编程教育场景下的能力，然而这些研究仅考虑了基于文本的编程，特别是Python编程。因此，它们未解答这些模型在K-8编程教育中广泛使用的视觉编程领域中的表现如何。我们主要研究的问题是：最先进的生成模型是否具备与它们在基于文本的Python编程中相当的视觉编程能力？在我们的工作中，我们评估了两个模型，基于GPT-3.5的ChatGPT和GPT-4，针对不同场景在视觉编程领域进行评估，并通过专家的注释来评估性能。

    Generative AI and large language models have the potential to drastically improve the landscape of computing education by automatically generating personalized feedback and content. Recent works have studied the capabilities of these models for different programming education scenarios; however, these works considered only text-based programming, in particular, Python programming. Consequently, they leave open the question of how well these models would perform in visual programming domains popularly used for K-8 programming education. The main research question we study is: Do state-of-the-art generative models show advanced capabilities in visual programming on par with their capabilities in text-based Python programming? In our work, we evaluate two models, ChatGPT (based on GPT-3.5) and GPT-4, in visual programming domains for various scenarios and assess performance using expert-based annotations. In particular, we base our evaluation using reference tasks from the domains of Hour
    
[^64]: 使用机器学习改进MDPs的概率双向建模

    Improving Probabilistic Bisimulation for MDPs Using Machine Learning. (arXiv:2308.02519v1 [cs.LO])

    [http://arxiv.org/abs/2308.02519](http://arxiv.org/abs/2308.02519)

    本文提出了一种使用机器学习改进MDPs的概率双向建模的新技术。

    

    模型检验被提议作为一种形式化验证技术，用于分析关键系统。然而，在应用于复杂系统时，最大的挑战是状态空间爆炸问题。为了解决这个问题，双向最小化已经成为一种主要方法，用于减少带标记的转换系统中的状态数，旨在克服与状态空间爆炸问题相关的困难。对于具有随机行为的系统，采用概率双向建模来最小化给定模型，从而获得具有较少状态的等效形式。最近，引入了各种技术来降低用于计算具有非确定性行为的随机系统的概率双向建模的迭代方法的时间复杂度。在本文中，我们提出了一种新的技术，将给定概率模型的状态空间划分为其双向建模类。

    The utilization of model checking has been suggested as a formal verification technique for analyzing critical systems. However, the primary challenge in applying to complex systems is state space explosion problem. To address this issue, bisimulation minimization has emerged as a prominent method for reducing the number of states in a labeled transition system, aiming to overcome the difficulties associated with the state space explosion problem. In the case of systems exhibiting stochastic behaviors, probabilistic bisimulation is employed to minimize a given model, obtaining its equivalent form with fewer states. Recently, various techniques have been introduced to decrease the time complexity of the iterative methods used to compute probabilistic bisimulation for stochastic systems that display nondeterministic behaviors. In this paper, we propose a new technique to partition the state space of a given probabilistic model to its bisimulation classes. This technique uses the PRISM pr
    
[^65]: 基于EEG的运动想象分类的特征重加权

    Feature Reweighting for EEG-based Motor Imagery Classification. (arXiv:2308.02515v1 [cs.LG])

    [http://arxiv.org/abs/2308.02515](http://arxiv.org/abs/2308.02515)

    本论文提出了一种特征重加权的方法，用于解决使用EEG信号进行运动想象分类时存在的低信噪比、非稳态性、非线性和复杂性等挑战，通过降低噪声和无关信息，提高分类性能。

    

    利用非侵入性脑电图（EEG）信号进行运动想象（MI）分类是一个重要的目标，因为它用于预测主体肢体移动的意图。最近的研究中，基于卷积神经网络（CNN）的方法已被广泛应用于MI-EEG分类。训练神经网络进行MI-EEG信号分类的挑战包括信噪比低、非稳态性、非线性和EEG信号的复杂性。基于CNN的网络计算得到的MI-EEG信号特征包含无关信息。因此，由噪声和无关特征计算得到的CNN网络的特征图也包含无关信息。因此，许多无用的特征常常误导神经网络训练，降低分类性能。为解决这个问题，提出了一种新的特征重加权方法。

    Classification of motor imagery (MI) using non-invasive electroencephalographic (EEG) signals is a critical objective as it is used to predict the intention of limb movements of a subject. In recent research, convolutional neural network (CNN) based methods have been widely utilized for MI-EEG classification. The challenges of training neural networks for MI-EEG signals classification include low signal-to-noise ratio, non-stationarity, non-linearity, and high complexity of EEG signals. The features computed by CNN-based networks on the highly noisy MI-EEG signals contain irrelevant information. Subsequently, the feature maps of the CNN-based network computed from the noisy and irrelevant features contain irrelevant information. Thus, many non-contributing features often mislead the neural network training and degrade the classification performance. Hence, a novel feature reweighting approach is proposed to address this issue. The proposed method gives a noise reduction mechanism named
    
[^66]: 语言模型作为主方程求解器

    Language models as master equation solvers. (arXiv:2308.02514v1 [cs.LG])

    [http://arxiv.org/abs/2308.02514](http://arxiv.org/abs/2308.02514)

    本研究将语言模型用作求解主方程的机器学习方法，通过设计提示网络和使用强化学习算法训练，实现了对多模组和高维系统的高精度求解。

    

    主方程在建模随机动力系统中具有基本重要性，然而由于状态空间维度的增加，解决主方程是具有挑战性的。本研究提出将语言模型重新应用为机器学习方法来解决主方程。我们设计了一个基于提示的神经网络，将速率参数、初始条件和时间值直接映射到与输入上下文完全匹配的状态联合概率分布。通过这种方式，我们近似地求解了主方程的最一般形式。我们使用强化学习框架中的策略梯度算法对网络进行训练，反馈奖励由一组变分自回归模型提供。通过将该方法应用于代表性示例，我们观察到对于多模组和高维系统，准确性很高。训练后的网络还展示了...

    Master equations are of fundamental importance in modeling stochastic dynamical systems.However, solving master equations is challenging due to the exponential increase in the number of possible states or trajectories with the dimension of the state space. In this study, we propose repurposing language models as a machine learning approach to solve master equations. We design a prompt-based neural network to map rate parameters, initial conditions, and time values directly to the state joint probability distribution that exactly matches the input contexts. In this way, we approximate the solution of the master equation in its most general form. We train the network using the policy gradient algorithm within the reinforcement learning framework, with feedback rewards provided by a set of variational autoregressive models. By applying this approach to representative examples, we observe high accuracy for both multi-module and high-dimensional systems. The trained network also exhibits ex
    
[^67]: 使用同时节点和边预测的图神经网络进行骨椎骨骼识别的鲁棒性研究

    Robust vertebra identification using simultaneous node and edge predicting Graph Neural Networks. (arXiv:2308.02509v1 [eess.IV])

    [http://arxiv.org/abs/2308.02509](http://arxiv.org/abs/2308.02509)

    本研究提出了一个使用图神经网络进行骨椎骨骼识别的方法，该方法能够准确地关联椎骨的位置和方向，避免了启发式规则，并通过引入一个包含椎弓根检测的新数据集进行验证。

    

    在CT扫描中自动定位和识别椎骨对于许多临床应用非常重要。在这个领域已取得了很多进展，但大部分方法主要针对椎骨的位置定位，忽略了其方向。此外，大多数方法在其流程中使用启发式规则，可能在真实的临床图像中对异常情况敏感。我们提出了一个简单的流程，它使用标准的U-Net进行预测，然后使用一个单一的图神经网络来关联和分类具有完整方向的椎骨。为了测试我们的方法，我们引入了一个新的椎骨数据集，该数据集还包含了与椎骨体相关联的椎弓根检测，从而创建了一个更具挑战性的地标预测、关联和分类任务。我们的方法能够准确地关联正确的椎骨体和椎弓根地标，忽略误报，并在一个简单的、完全可训练的流程中对椎骨进行分类，避免了特定应用的启发式规则。

    Automatic vertebra localization and identification in CT scans is important for numerous clinical applications. Much progress has been made on this topic, but it mostly targets positional localization of vertebrae, ignoring their orientation. Additionally, most methods employ heuristics in their pipeline that can be sensitive in real clinical images which tend to contain abnormalities. We introduce a simple pipeline that employs a standard prediction with a U-Net, followed by a single graph neural network to associate and classify vertebrae with full orientation. To test our method, we introduce a new vertebra dataset that also contains pedicle detections that are associated with vertebra bodies, creating a more challenging landmark prediction, association and classification task. Our method is able to accurately associate the correct body and pedicle landmarks, ignore false positives and classify vertebrae in a simple, fully trainable pipeline avoiding application-specific heuristics.
    
[^68]: 在生物医学和非生物医学环境中评估合成图像的类内多样性和质量

    Assessing Intra-class Diversity and Quality of Synthetically Generated Images in a Biomedical and Non-biomedical Setting. (arXiv:2308.02505v1 [eess.IV])

    [http://arxiv.org/abs/2308.02505](http://arxiv.org/abs/2308.02505)

    本研究主要关注在生物医学和非生物医学环境中评估合成图像的类内多样性和质量，使用多尺度结构相似性指数测量和余弦距离评估类内多样性，使用Frechet Inception距离评估质量。评估这些度量对于了解合成图像的多样性和质量至关重要。

    

    在生物医学图像分析中，数据不平衡在多种成像模态中很常见。数据增强是解决这个问题的关键之一。生成对抗网络（GANs）越来越多地被用于数据增强任务。生物医学图像特征对于评估合成图像的功效非常敏感。当评估不同生物医学成像模态下的合成图像时，这些特征可能对度量分数产生显著影响。可以通过比较真实图像的多样性和质量来评估合成图像。多尺度结构相似性指数测量和余弦距离被用于评估类内多样性，而Frechet Inception距离用于评估合成图像的质量。评估生物医学和非生物医学成像的这些度量对于研究评估合成图像的多样性和质量的知情策略非常重要。在这项工作中，我们使用一种实证方法来评估生物医学和非生物医学图像的类内多样性和质量。

    In biomedical image analysis, data imbalance is common across several imaging modalities. Data augmentation is one of the key solutions in addressing this limitation. Generative Adversarial Networks (GANs) are increasingly being relied upon for data augmentation tasks. Biomedical image features are sensitive to evaluating the efficacy of synthetic images. These features can have a significant impact on metric scores when evaluating synthetic images across different biomedical imaging modalities. Synthetically generated images can be evaluated by comparing the diversity and quality of real images. Multi-scale Structural Similarity Index Measure and Cosine Distance are used to evaluate intra-class diversity, while Frechet Inception Distance is used to evaluate the quality of synthetic images. Assessing these metrics for biomedical and non-biomedical imaging is important to investigate an informed strategy in evaluating the diversity and quality of synthetic images. In this work, an empir
    
[^69]: 通过对卫星图像应用深度学习技术，识别塞浦路斯农村地区的垃圾倾倒场所

    The identification of garbage dumps in the rural areas of Cyprus through the application of deep learning to satellite imagery. (arXiv:2308.02502v1 [eess.IV])

    [http://arxiv.org/abs/2308.02502](http://arxiv.org/abs/2308.02502)

    通过对卫星图像应用深度学习技术，本研究旨在识别塞浦路斯农村地区的非法垃圾倾倒场所，并为相关部门提供信息。为此，收集了一组包含和不包含垃圾的图像数据集，并采用数据增强方法扩充数据。

    

    垃圾处理是发达国家面临的一个挑战性问题。在塞浦路斯，非法的“乱倒垃圾”也是一个重要问题，特别是在农村地区几乎没有合法的垃圾处理选项。然而，目前缺乏对这一问题规模的研究，也没有足够资源来解决它。本研究旨在调查人工智能技术和卫星图像结合使用，能否用于识别塞浦路斯农村地区的非法垃圾倾倒场所。为此，我们收集了一组新颖的图像数据集，将其分为包含垃圾和不包含垃圾两个类别。由于收集这种数据集的原始数量耗时且成本高昂，因此我们先收集了一组相对较小的基准图像数据集，然后应用数据增强方法扩充数据。

    Garbage disposal is a challenging problem throughout the developed world. In Cyprus, as elsewhere, illegal ``fly-tipping" is a significant issue, especially in rural areas where few legal garbage disposal options exist. However, there is a lack of studies that attempt to measure the scale of this problem, and few resources available to address it. A method of automating the process of identifying garbage dumps would help counter this and provide information to the relevant authorities. The aim of this study was to investigate the degree to which artificial intelligence techniques, together with satellite imagery, can be used to identify illegal garbage dumps in the rural areas of Cyprus. This involved collecting a novel dataset of images that could be categorised as either containing, or not containing, garbage. The collection of such datasets in sufficient raw quantities is time consuming and costly. Therefore a relatively modest baseline set of images was collected, then data augment
    
[^70]: 从噪声注释中学习分割：一种空间修正方法

    Learning to Segment from Noisy Annotations: A Spatial Correction Approach. (arXiv:2308.02498v1 [eess.IV])

    [http://arxiv.org/abs/2308.02498](http://arxiv.org/abs/2308.02498)

    本文提出了一种基于空间修正的方法，用于从噪声注释中学习分割。这种方法通过马尔可夫模型编码空间相关性和偏差，并提供理论保证。实验证明，该方法在合成和实际噪声注释上优于当前最先进的方法。

    

    深度神经网络（DNNs）的性能通常会受到嘈杂标签的显著影响。在医学图像分割任务中，由于注释时间和注释者的专业知识的高需求，注释往往存在错误。现有方法大多假设不同像素点上的噪声标签是独立同分布的。然而，分割标签的噪声通常具有强烈的空间相关性和显著的分布偏差。本文提出了一种新的马尔可夫模型用于编码分割噪声注释中的空间相关性和偏差。为了减轻这种标签噪声，我们提出了一种标签修正方法逐步恢复真实标签。我们提供了所提方法正确性的理论保证。实验证明，我们的方法在合成和实际噪声注释上优于当前最先进的方法。

    Noisy labels can significantly affect the performance of deep neural networks (DNNs). In medical image segmentation tasks, annotations are error-prone due to the high demand in annotation time and in the annotators' expertise. Existing methods mostly assume noisy labels in different pixels are \textit{i.i.d}. However, segmentation label noise usually has strong spatial correlation and has prominent bias in distribution. In this paper, we propose a novel Markov model for segmentation noisy annotations that encodes both spatial correlation and bias. Further, to mitigate such label noise, we propose a label correction method to recover true label progressively. We provide theoretical guarantees of the correctness of the proposed method. Experiments show that our approach outperforms current state-of-the-art methods on both synthetic and real-world noisy annotations.
    
[^71]: 在产品层面上绘制全球价值链

    Mapping Global Value Chains at the Product Level. (arXiv:2308.02491v1 [econ.GN])

    [http://arxiv.org/abs/2308.02491](http://arxiv.org/abs/2308.02491)

    本研究提出了一种基于机器学习和贸易理论的方法，通过细粒度的国际贸易数据推断产品层面的价值链关系，为应对经济中断提供重要的数据支持。

    

    价值链数据对于应对经济中断至关重要，例如COVID-19疫情和乌克兰战争。然而，尽管其重要性，公开可用的价值链数据集，如“世界投入产出数据库”，“国际投入产出表”，“EXIOBASE”或“EORA”，缺乏关于产品（如收音机接收机，电话，电容器，液晶显示器等）的详细信息，而是依赖于更粗略的行业部门（如电器设备，电讯业）。在这里，我们介绍了一种基于机器学习和贸易理论的方法，通过细粒度的国际贸易数据推断产品层面的价值链关系。我们将这种方法应用于总结了300多个世界区域（如美国的州，日本的县等）和1200多个产品的出口和进口的数据上，以推断出其中的贸易模式中隐含的价值链信息。

    Value chain data is crucial to navigate economic disruptions, such as those caused by the COVID-19 pandemic and the war in Ukraine. Yet, despite its importance, publicly available value chain datasets, such as the ``World Input-Output Database'', ``Inter-Country Input-Output Tables'', ``EXIOBASE'' or the ``EORA'', lack detailed information about products (e.g. Radio Receivers, Telephones, Electrical Capacitors, LCDs, etc.) and rely instead on more aggregate industrial sectors (e.g. Electrical Equipment, Telecommunications). Here, we introduce a method based on machine learning and trade theory to infer product-level value chain relationships from fine-grained international trade data. We apply our method to data summarizing the exports and imports of 300+ world regions (e.g. states in the U.S., prefectures in Japan, etc.) and 1200+ products to infer value chain information implicit in their trade patterns. Furthermore, we use proportional allocation to assign the trade flow between reg
    
[^72]: 基于积分的无强度积分化学能的学习

    Intensity-free Integral-based Learning of Marked Temporal Point Processes. (arXiv:2308.02360v1 [cs.LG])

    [http://arxiv.org/abs/2308.02360](http://arxiv.org/abs/2308.02360)

    该论文提出了一种基于积分的无强度积分化学能的学习框架IFIB，用于建模离散事件中具有分类或数值属性的事件标记。

    

    在标记的时间点过程（MTPP）中，一个核心问题是为条件联合概率密度函数（PDF）$p^*（m，t）$参数化插值时间t和标记m在历史条件下。现有研究大多预先定义强度函数。它们的实用性受到指定强度函数正确形式的挑战，这对于平衡表达能力和处理效率至关重要。最近，有研究摆脱预定义强度函数，一个模型$p^*（t）$和$p^*（m）$分开，另一个侧重于不考虑标记的时间点过程（TPP）。本研究旨在开发高保真度的$p^*（m，t）$，适用于事件标记在多维连续空间中具有分类或数值属性的离散事件。我们提出了一个解决方案框架IFIB（无强度积分化学能过程），直接建模条件联合概率密度函数$p^*（m，t）$。

    In the marked temporal point processes (MTPP), a core problem is to parameterize the conditional joint PDF (probability distribution function) $p^*(m,t)$ for inter-event time $t$ and mark $m$, conditioned on the history. The majority of existing studies predefine intensity functions. Their utility is challenged by specifying the intensity function's proper form, which is critical to balance expressiveness and processing efficiency. Recently, there are studies moving away from predefining the intensity function -- one models $p^*(t)$ and $p^*(m)$ separately, while the other focuses on temporal point processes (TPPs), which do not consider marks. This study aims to develop high-fidelity $p^*(m,t)$ for discrete events where the event marks are either categorical or numeric in a multi-dimensional continuous space. We propose a solution framework IFIB (\underline{I}ntensity-\underline{f}ree \underline{I}ntegral-\underline{b}ased process) that models conditional joint PDF $p^*(m,t)$ directly
    
[^73]: 通过大型语言模型扩展临床试验匹配：以肿瘤学为案例研究

    Scaling Clinical Trial Matching Using Large Language Models: A Case Study in Oncology. (arXiv:2308.02180v1 [cs.CL])

    [http://arxiv.org/abs/2308.02180](http://arxiv.org/abs/2308.02180)

    本文研究了使用大型语言模型（LLMs）扩展临床试验匹配的方法，并以肿瘤学为案例研究。研究结果显示，先进的LLMs能够处理临床试验的复杂条件和匹配逻辑，相较于之前的方法，性能显著提升，并可作为人工辅助筛选患者-试验候选人的初步解决方案。

    

    临床试验匹配是医疗传递和发现中的关键过程。实际上，由于庞大的非结构化数据和不可扩展的手动处理，该过程存在问题。本文通过以肿瘤学为重点领域，对使用大型语言模型（LLM）扩展临床试验匹配进行了系统研究。我们的研究基于一个正在美国一个大型医疗网络进行测试部署的临床试验匹配系统。初步结果令人鼓舞：先进的LLM（如GPT-4）可以立即连接临床试验的复杂的合格条件，并提取复杂的匹配逻辑（例如嵌套的AND/OR/NOT）。虽然仍不完美，LLM在性能上显著优于以前的强基准线，并可能作为在人与人之间进行候选患者-试验划分的初步解决方案。我们的研究还揭示了一些应用LLM进行端到端临床试验匹配的重要增长领域，例如上下文限制和准确性。

    Clinical trial matching is a key process in health delivery and discovery. In practice, it is plagued by overwhelming unstructured data and unscalable manual processing. In this paper, we conduct a systematic study on scaling clinical trial matching using large language models (LLMs), with oncology as the focus area. Our study is grounded in a clinical trial matching system currently in test deployment at a large U.S. health network. Initial findings are promising: out of box, cutting-edge LLMs, such as GPT-4, can already structure elaborate eligibility criteria of clinical trials and extract complex matching logic (e.g., nested AND/OR/NOT). While still far from perfect, LLMs substantially outperform prior strong baselines and may serve as a preliminary solution to help triage patient-trial candidates with humans in the loop. Our study also reveals a few significant growth areas for applying LLMs to end-to-end clinical trial matching, such as context limitation and accuracy, especially
    
[^74]: 基于Deep Maxout网络特征融合和Political Tangent Search优化器的转移学习在地中海贫血检测中的应用

    Deep Maxout Network-based Feature Fusion and Political Tangent Search Optimizer enabled Transfer Learning for Thalassemia Detection. (arXiv:2308.02029v1 [cs.LG])

    [http://arxiv.org/abs/2308.02029](http://arxiv.org/abs/2308.02029)

    本文提出了基于Deep Maxout网络特征融合和Political Tangent Search优化器的转移学习方法，应用于地中海贫血检测。该方法对输入数据进行归一化处理，并利用Deep Maxout网络的特征融合和过采样方法进行数据增强，最终通过转移学习进行地中海贫血检测。

    

    地中海贫血是一种遗传性血液病，由遗传缺陷导致血红蛋白多肽链的产生不足。然而，对这些地区的发病频率和共享程度的了解较少。了解地中海贫血发生的频率和可靠突变是预防、控制和治疗计划的重要一步。本文介绍了基于Political Tangent Search优化器的转移学习（PTSO_TL）在地中海贫血检测中的应用。首先，从特定数据集获取的输入数据在数据归一化阶段进行了规范化。数据归一化阶段利用分位数归一化方法，然后将数据传递给特征融合阶段，在该阶段利用Deep Maxout网络的加权欧氏距离进行特征融合。然后，使用过采样方法进行数据增强以增加数据维度。最后，通过转移学习进行地中海贫血检测。

    Thalassemia is a heritable blood disorder which is the outcome of a genetic defect causing lack of production of hemoglobin polypeptide chains. However, there is less understanding of the precise frequency as well as sharing in these areas. Knowing about the frequency of thalassemia occurrence and dependable mutations is thus a significant step in preventing, controlling, and treatment planning. Here, Political Tangent Search Optimizer based Transfer Learning (PTSO_TL) is introduced for thalassemia detection. Initially, input data obtained from a particular dataset is normalized in the data normalization stage. Quantile normalization is utilized in the data normalization stage, and the data are then passed to the feature fusion phase, in which Weighted Euclidean Distance with Deep Maxout Network (DMN) is utilized. Thereafter, data augmentation is performed using the oversampling method to increase data dimensionality. Lastly, thalassemia detection is carried out by TL, wherein a convol
    
[^75]: Tensor程序IVb：无限宽度极限中的自适应优化

    Tensor Programs IVb: Adaptive Optimization in the Infinite-Width Limit. (arXiv:2308.01814v1 [cs.LG])

    [http://arxiv.org/abs/2308.01814](http://arxiv.org/abs/2308.01814)

    本论文研究了在无限宽度极限中使用自适应优化器训练宽神经网络时的新现象，通过推导相应的“神经切线”和“最大更新”极限，展示了特征学习和核行为之间的二分法，同时引入了简化计算的bra-ket符号。

    

    超越随机梯度下降（SGD），当使用Adam等自适应优化器训练宽神经网络时，会出现新的现象吗？在这里，我们展示了以下结果：与SGD一样，对于包括Adam在内的一般优化器，特征学习和核行为之间存在着相同的二分法 - 尽管有一种非线性的“核”概念。我们推导了对于任何架构的相应的“神经切线”和“最大更新”极限。上述结果的两个基础性进展是：1）一种新的Tensor程序语言，NEXORT，可以表达自适应优化器如何将梯度处理为更新。2）引入bra-ket符号来极大地简化Tensor程序中的表达式和计算。该工作总结并概括了Tensor程序系列论文中的所有先前结果。

    Going beyond stochastic gradient descent (SGD), what new phenomena emerge in wide neural networks trained by adaptive optimizers like Adam? Here we show: The same dichotomy between feature learning and kernel behaviors (as in SGD) holds for general optimizers as well, including Adam -- albeit with a nonlinear notion of "kernel." We derive the corresponding "neural tangent" and "maximal update" limits for any architecture. Two foundational advances underlie the above results: 1) A new Tensor Program language, NEXORT, that can express how adaptive optimizers process gradients into updates. 2) The introduction of bra-ket notation to drastically simplify expressions and calculations in Tensor Programs. This work summarizes and generalizes all previous results in the Tensor Programs series of papers.
    
[^76]: OpenFlamingo: 一个用于训练大型自回归视觉语言模型的开源框架

    OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models. (arXiv:2308.01390v1 [cs.CV])

    [http://arxiv.org/abs/2308.01390](http://arxiv.org/abs/2308.01390)

    OpenFlamingo是一个开源框架，用于训练大型自回归视觉语言模型。它在多个数据集上表现良好，达到了对应模型性能的80%至89%。

    

    我们介绍了OpenFlamingo，这是一系列自回归的视觉语言模型，参数范围从3B到9B。 OpenFlamingo是一个持续努力的项目，旨在复制DeepMind的Flamingo模型的开源版本。在七个视觉语言数据集上，OpenFlamingo模型的性能介于对应的Flamingo性能的80%至89%之间。本技术报告介绍了我们的模型、训练数据、超参数和评估套件。我们在https://github.com/mlfoundations/open_flamingo上分享我们的模型和代码。

    We introduce OpenFlamingo, a family of autoregressive vision-language models ranging from 3B to 9B parameters. OpenFlamingo is an ongoing effort to produce an open-source replication of DeepMind's Flamingo models. On seven vision-language datasets, OpenFlamingo models average between 80 - 89% of corresponding Flamingo performance. This technical report describes our models, training data, hyperparameters, and evaluation suite. We share our models and code at https://github.com/mlfoundations/open_flamingo.
    
[^77]: LLMs理解玻璃盒模型，发现惊喜并提出修复建议。

    LLMs Understand Glass-Box Models, Discover Surprises, and Suggest Repairs. (arXiv:2308.01157v1 [stat.ML])

    [http://arxiv.org/abs/2308.01157](http://arxiv.org/abs/2308.01157)

    LLMs在处理可解释模型方面表现出色，提供了全面的模型级总结和自动化的异常检测、原因描述和修复建议。在医疗保健领域使用广义可加模型作为示例，同时介绍了开源的LLM-GAM接口包$\texttt{TalkToEBM}$。

    

    我们展示了大型语言模型(LLMs)在处理可解释模型方面的出色表现，这些模型可以将复杂结果分解为单一变量的图表示组件。通过采用层次推理的方法，LLMs能够在不需要整个模型适应上下文的情况下提供全面的模型级总结。这种方法使LLMs能够应用其广泛的背景知识来自动完成数据科学中的常见任务，如检测与先前知识相矛盾的异常，描述异常的潜在原因，并提出去除异常的修复建议。我们使用医疗保健领域的多个示例来证明LLMs的这些新能力的实用性，特别强调广义可加模型(GAMs)。最后，我们将$\texttt{TalkToEBM}$包作为一个开源的LLM-GAM接口进行介绍。

    We show that large language models (LLMs) are remarkably good at working with interpretable models that decompose complex outcomes into univariate graph-represented components. By adopting a hierarchical approach to reasoning, LLMs can provide comprehensive model-level summaries without ever requiring the entire model to fit in context. This approach enables LLMs to apply their extensive background knowledge to automate common tasks in data science such as detecting anomalies that contradict prior knowledge, describing potential reasons for the anomalies, and suggesting repairs that would remove the anomalies. We use multiple examples in healthcare to demonstrate the utility of these new capabilities of LLMs, with particular emphasis on Generalized Additive Models (GAMs). Finally, we present the package $\texttt{TalkToEBM}$ as an open-source LLM-GAM interface.
    
[^78]: 使用Floss增强周期性时间序列的表示学习：一种频域正则化方法

    Enhancing Representation Learning for Periodic Time Series with Floss: A Frequency Domain Regularization Approach. (arXiv:2308.01011v1 [cs.LG])

    [http://arxiv.org/abs/2308.01011](http://arxiv.org/abs/2308.01011)

    本文提出了一种叫做Floss的无监督方法，通过在频域上对学到的表示进行正则化来增强周期性时间序列的表示学习。Floss方法可以自动检测时间序列中的周期性并学习具有周期一致性的有意义的表示。

    

    时间序列分析是各个应用领域的基础任务，深度学习方法在这个领域表现出了非凡的性能。然而，许多现实世界的时间序列数据展现出重要的周期性或准周期性动态，这些动态往往不能被现有的基于深度学习的解决方案充分捕捉到。这导致对感兴趣的基础动态行为的表示不完整。为了解决这个问题，我们提出了一种无监督的方法叫做Floss，它通过自动化地在频域上调整学到的表示来进行正则化。Floss方法首先自动检测时间序列中的主要周期性。然后，它利用周期移位和谱密度相似度度量来学习具有周期一致性的有意义的表示。此外，Floss可以轻松地整合到有监督、半监督和无监督的学习框架中。

    Time series analysis is a fundamental task in various application domains, and deep learning approaches have demonstrated remarkable performance in this area. However, many real-world time series data exhibit significant periodic or quasi-periodic dynamics that are often not adequately captured by existing deep learning-based solutions. This results in an incomplete representation of the underlying dynamic behaviors of interest. To address this gap, we propose an unsupervised method called Floss that automatically regularizes learned representations in the frequency domain. The Floss method first automatically detects major periodicities from the time series. It then employs periodic shift and spectral density similarity measures to learn meaningful representations with periodic consistency. In addition, Floss can be easily incorporated into both supervised, semi-supervised, and unsupervised learning frameworks. We conduct extensive experiments on common time series classification, for
    
[^79]: 人类-M3：一个用于室外场景中的3D人体姿势估计的多视角多模态数据集

    Human-M3: A Multi-view Multi-modal Dataset for 3D Human Pose Estimation in Outdoor Scenes. (arXiv:2308.00628v1 [cs.CV])

    [http://arxiv.org/abs/2308.00628](http://arxiv.org/abs/2308.00628)

    这篇论文提出了一个室外多模态多视角多人类姿势数据库Human-M3，并介绍了一种基于多模态数据输入的算法来生成准确的人体姿势。这个数据库解决了现有数据集的不足，提供了更多的数据多样性。

    

    最近，对于室外环境中的3D人体姿势估计越来越受到关注。然而，现有的室外场景3D人体姿势数据集缺乏多样性，因为它们主要只使用一种模态（RGB图像或点云），并且场景中通常只有一个人。数据集基础的有限范围严重阻碍了可用数据的变化性。在本文中，我们提出了Human-M3，这是一个室外多模态多视角多人类姿势数据库，其中包括室外场景的多视角RGB视频和相应的点云数据。为了获得准确的人体姿势，我们提出了一种基于多模态数据输入的算法来生成地面真值标注。这种方法利用了鲁棒的点云检测和跟踪，解决了之前室外场景中多个人的多视角RGB视频中可能存在的不准确人体定位和匹配模糊问题，生成了相关信息。

    3D human pose estimation in outdoor environments has garnered increasing attention recently. However, prevalent 3D human pose datasets pertaining to outdoor scenes lack diversity, as they predominantly utilize only one type of modality (RGB image or pointcloud), and often feature only one individual within each scene. This limited scope of dataset infrastructure considerably hinders the variability of available data. In this article, we propose Human-M3, an outdoor multi-modal multi-view multi-person human pose database which includes not only multi-view RGB videos of outdoor scenes but also corresponding pointclouds. In order to obtain accurate human poses, we propose an algorithm based on multi-modal data input to generate ground truth annotation. This benefits from robust pointcloud detection and tracking, which solves the problem of inaccurate human localization and matching ambiguity that may exist in previous multi-view RGB videos in outdoor multi-person scenes, and generates rel
    
[^80]: 在反应式系统内对神经网络进行形式化解释

    Formally Explaining Neural Networks within Reactive Systems. (arXiv:2308.00143v1 [cs.AI])

    [http://arxiv.org/abs/2308.00143](http://arxiv.org/abs/2308.00143)

    这项研究在反应式系统中提出了一种基于DNN验证的形式化XAI技术，可以解释DNN的行为，并且通过利用系统的转换约束来计算简洁的解释。

    

    深度神经网络(DNNs)越来越多地被用作反应式系统中的控制器。然而，DNNs具有高度的不透明性，这使得解释和证明它们的行为变得困难。为了解决这个问题，出现了对可解释AI(XAI)技术的兴趣激增，这些技术能够找出导致DNN行为的输入特征。现有的XAI技术通常存在两个限制：(i)它们是启发式方法，并不能提供解释正确性的正式保证；(ii)它们通常适用于“一次性”系统(即DNN独立于过去的调用)，而不是反应式系统。在这里，我们开始弥合这个差距，提出一种基于DNN验证的形式化XAI技术，用于推理多步骤的反应式系统。我们建议通过利用系统的转换约束来计算简洁的解释的方法，以便减少底层验证器所探索的搜索空间。

    Deep neural networks (DNNs) are increasingly being used as controllers in reactive systems. However, DNNs are highly opaque, which renders it difficult to explain and justify their actions. To mitigate this issue, there has been a surge of interest in explainable AI (XAI) techniques, capable of pinpointing the input features that caused the DNN to act as it did.  Existing XAI techniques typically face two limitations: (i) they are heuristic, and do not provide formal guarantees that the explanations are correct; and (ii) they often apply to ``one-shot'' systems (where the DNN is invoked independently of past invocations), as opposed to reactive systems.  Here, we begin bridging this gap, and propose a formal DNN-verification-based XAI technique for reasoning about multi-step, reactive systems. We suggest methods for efficiently calculating succinct explanations, by exploiting the system's transition constraints in order to curtail the search space explored by the underlying verifier. W
    
[^81]: 无监督机器学习震荡捕捉高阶CFD求解器

    Unsupervised machine learning shock capturing for High-Order CFD solvers. (arXiv:2308.00086v1 [cs.LG])

    [http://arxiv.org/abs/2308.00086](http://arxiv.org/abs/2308.00086)

    我们提出了一种基于高斯混合模型（GMMs）的无监督机器学习震荡捕捉算法。这种算法具有显著的准确性和鲁棒性，适用于各种复杂几何结构和流动配置。

    

    我们提出了一种基于高斯混合模型（GMMs）的新型无监督机器学习震荡捕捉算法。所提出的GMM传感器在检测震荡方面表现出了显著的准确性，并且在不需要参数调优的情况下在多样的测试案例上都表现出了较好的鲁棒性。我们将基于GMM的传感器与最先进的替代方法进行了比较。所有方法都集成到高阶可压性不连续Galerkin求解器中，人工黏性可以调节以捕捉震荡。超音速测试案例，包括高雷诺数，展示了传感器的性能，表明其效果与精调的最先进传感器相当。%节点DG方法允许在亚单元通量有差异的公式中进行潜在应用，超音速特征检测和网格细化。这种基于GMM的传感器适用于复杂几何结构和各种流动配置，其自适应性和无需大量训练数据集的功能使其具备广泛的应用潜力。

    We present a novel unsupervised machine learning shock capturing algorithm based on Gaussian Mixture Models (GMMs). The proposed GMM sensor demonstrates remarkable accuracy in detecting shocks and is robust across diverse test cases without the need for parameter tuning. We compare the GMM-based sensor with state-of-the-art alternatives. All methods are integrated into a high-order compressible discontinuous Galerkin solver where artificial viscosity can be modulated to capture shocks. Supersonic test cases, including high Reynolds numbers, showcase the sensor's performance, demonstrating the same effectiveness as fine-tuned state-of-the-art sensors. %The nodal DG aproach allows for potential applications in sub-cell flux-differencing formulations, supersonic feature detection, and mesh refinement. The adaptive nature and ability to function without extensive training datasets make this GMM-based sensor suitable for complex geometries and varied flow configurations. Our study reveals t
    
[^82]: 高效互动感知神经网络反馈环的区间分析

    Efficient Interaction-Aware Interval Analysis of Neural Network Feedback Loops. (arXiv:2307.14938v1 [eess.SY])

    [http://arxiv.org/abs/2307.14938](http://arxiv.org/abs/2307.14938)

    本文提出了一种计算效率高的神经网络控制系统区间可达性分析框架，通过引入包含函数和构建嵌入系统来捕捉系统和神经网络控制器之间的相互作用。

    

    本文提出了一种计算效率高的神经网络控制系统区间可达性分析框架。我们的方法基于神经网络控制器和开环系统的包含函数。我们观察到，许多最先进的神经网络验证器可以为神经网络生成包含函数。我们介绍并分析了一种基于函数雅可比边界的开环动力学包含函数的新类别，特别适用于捕捉系统和神经网络控制器之间的相互作用。接下来，对于任意动力系统，我们使用包含函数构建一个状态数是原系统两倍的嵌入系统。我们证明嵌入系统的单个轨迹可以提供可达集的超矩形近似。然后，我们提出了两种构建神经网络控制动力系统的闭环嵌入系统的方法，考虑系统之间的互动。

    In this paper, we propose a computationally efficient framework for interval reachability of neural network controlled systems. Our approach builds upon inclusion functions for the neural network controller and the open-loop system. We observe that many state-of-the-art neural network verifiers can produce inclusion functions for neural networks. We introduce and analyze a new class of inclusion functions for the open-loop dynamics based on bounds of the function Jacobian that is particularly suitable for capturing the interactions between systems and neural network controllers. Next, for any dynamical system, we use inclusion functions to construct an embedding system with twice the number of states as the original system. We show that a single trajectory of this embedding system provides hyper-rectangular over-approximations of reachable sets. We then propose two approaches for constructing a closed-loop embedding system for a neural network controlled dynamical system that accounts 
    
[^83]: 一种基于LSTM、BiLSTM、CNN、GRU和GloVe的混合机器学习模型用于基因突变在癌症中的分类

    A Hybrid Machine Learning Model for Classifying Gene Mutations in Cancer using LSTM, BiLSTM, CNN, GRU, and GloVe. (arXiv:2307.14361v1 [q-bio.QM])

    [http://arxiv.org/abs/2307.14361](http://arxiv.org/abs/2307.14361)

    本研究提出了一个基于多种机器学习算法和嵌入模型的集成模型，用于基因突变在癌症中的分类。实验结果表明，该模型在准确率、精确率、召回率等指标上优于其他传统和最新的转换器模型，并且具有更高的训练效率。

    

    本研究提出了一个集成模型，将LSTM、BiLSTM、CNN、GRU和GloVe结合起来，用于在Kaggle的“个性化医学：重新定义癌症治疗”数据集中对基因突变进行分类。通过与BERT、Electra、Roberta、XLNet、Distilbert以及它们的LSTM集成等知名转换器进行比较，结果显示我们的模型在准确率、精确率、召回率、F1分数和均方误差方面都优于其他模型。令人惊讶的是，它还需要较少的训练时间，实现了性能和效率的完美结合。该研究证明了集成模型在基因突变分类等困难任务中的实用性。

    This study presents an ensemble model combining LSTM, BiLSTM, CNN, GRU, and GloVe to classify gene mutations using Kaggle's Personalized Medicine: Redefining Cancer Treatment dataset. The results were compared against well-known transformers like as BERT, Electra, Roberta, XLNet, Distilbert, and their LSTM ensembles. Our model outperformed all other models in terms of accuracy, precision, recall, F1 score, and Mean Squared Error. Surprisingly, it also needed less training time, resulting in a perfect combination of performance and efficiency. This study demonstrates the utility of ensemble models for difficult tasks such as gene mutation classification.
    
[^84]: 使用EEG数据和表示学习的神经记忆解码

    Neural Memory Decoding with EEG Data and Representation Learning. (arXiv:2307.13181v1 [cs.LG])

    [http://arxiv.org/abs/2307.13181](http://arxiv.org/abs/2307.13181)

    本研究提出一种使用EEG数据和表示学习进行神经记忆解码的方法，能够实现从EEG数据中识别出被召回的概念，并在信息检索问题中应用该方法。

    

    我们描述了一种从EEG数据中解码记忆的方法。使用这种方法，可以从EEG波形中识别出被召回的概念，平均准确率达到78.4％（机会4％）。该方法采用了深度表示学习与有监督对比损失来将脑活动的EEG记录映射到一个低维空间。由于使用了表示学习，即使这些概念在训练数据集中没有出现，也可以识别出来。然而，每个概念都必须存在相应的参考EEG数据。我们还展示了该方法在信息检索问题上的应用。在神经信息检索中，当用户回忆文档内容时捕获EEG数据，并生成预测文档的链接列表。

    We describe a method for the neural decoding of memory from EEG data. Using this method, a concept being recalled can be identified from an EEG trace with an average top-1 accuracy of about 78.4% (chance 4%). The method employs deep representation learning with supervised contrastive loss to map an EEG recording of brain activity to a low-dimensional space. Because representation learning is used, concepts can be identified even if they do not appear in the training data set. However, reference EEG data must exist for each such concept. We also show an application of the method to the problem of information retrieval. In neural information retrieval, EEG data is captured while a user recalls the contents of a document, and a list of links to predicted documents is produced.
    
[^85]: 大型语言模型中的上下文学习在学习标签关系上具有创新，但并非传统学习方法

    In-Context Learning in Large Language Models Learns Label Relationships but Is Not Conventional Learning. (arXiv:2307.12375v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.12375](http://arxiv.org/abs/2307.12375)

    大型语言模型（LLMs）在包含标签关系示例的上下文中的学习能力使其在下游任务中表现显著提高，但与传统学习方法不同。我们研究了上下文示例中的标签如何影响预测、预训练中学习到的标签关系如何与上下文示例相互作用以及上下文学习如何聚合标签信息。研究结果揭示了LLMs的工作机制及其对上下文信息的处理方式。

    

    在下游任务中，大型语言模型（LLMs）的性能在包含输入-标签关系示例的上下文中通常显著提高。然而，目前对LLMs的这种上下文学习（ICL）能力的工作机制尚无共识：例如，虽然Xie等人（2021年）将ICL比作一种通用学习算法，但Min等人（2022b年）认为ICL甚至不能从上下文示例中学习标签关系。在本文中，我们研究了以下三个问题：（1）上下文示例的标签如何影响预测结果，（2）预训练期间学习到的标签关系如何与上下文中提供的输入-标签示例相互作用，以及（3）ICL如何聚合来自上下文示例的标签信息。我们的研究发现，LLMs通常会整合上下文标签的信息，但预训练和上下文标签关系被区别对待，模型不会将所有上下文信息等同对待。我们的结果揭示了对LLMs的理解。

    The performance of Large Language Models (LLMs) on downstream tasks often improves significantly when including examples of the input-label relationship in the context. However, there is currently no consensus about how this in-context learning (ICL) ability of LLMs works: for example, while Xie et al. (2021) liken ICL to a general-purpose learning algorithm, Min et al. (2022b) argue ICL does not even learn label relationships from in-context examples. In this paper, we study (1) how labels of in-context examples affect predictions, (2) how label relationships learned during pre-training interact with input-label examples provided in-context, and (3) how ICL aggregates label information across in-context examples. Our findings suggests LLMs usually incorporate information from in-context labels, but that pre-training and in-context label relationships are treated differently, and that the model does not consider all in-context information equally. Our results give insights into underst
    
[^86]: 用物理信知的神经网络解决维度诅咒问题

    Tackling the Curse of Dimensionality with Physics-Informed Neural Networks. (arXiv:2307.12306v1 [cs.LG])

    [http://arxiv.org/abs/2307.12306](http://arxiv.org/abs/2307.12306)

    本文提出了一种新方法，利用物理信知的神经网络(PINNs)解决高维度的偏微分方程(PDEs)问题，并证明了收敛性和其他期望属性。

    

    维度诅咒(CoD)随着维度的增加，以指数级增长的计算成本来极度税费计算资源。这在解决高维偏微分方程(PDEs)中面临极大挑战，正如Richard Bellman在60年前首次指出的那样。尽管近年来在高维度上数值解决偏微分方程(PDEs)取得了一些成功，但这样的计算代价过高，而将一般非线性PDEs扩展到高维度从未实现过。本文提出了一种新方法，将物理信知的神经网络(PINNs)扩展到解决任意高维PDEs。该新方法称为随机维度梯度下降(SDGD)，将PDE的梯度分解为与不同维度对应的部分，并在训练PINNs的每次迭代中随机选择这些维度部分的子集进行采样。我们在理论上证明了所提出方法的收敛保证和其他期望属性。

    The curse-of-dimensionality (CoD) taxes computational resources heavily with exponentially increasing computational cost as the dimension increases. This poses great challenges in solving high-dimensional PDEs as Richard Bellman first pointed out over 60 years ago. While there has been some recent success in solving numerically partial differential equations (PDEs) in high dimensions, such computations are prohibitively expensive, and true scaling of general nonlinear PDEs to high dimensions has never been achieved. In this paper, we develop a new method of scaling up physics-informed neural networks (PINNs) to solve arbitrary high-dimensional PDEs. The new method, called Stochastic Dimension Gradient Descent (SDGD), decomposes a gradient of PDEs into pieces corresponding to different dimensions and samples randomly a subset of these dimensional pieces in each iteration of training PINNs. We theoretically prove the convergence guarantee and other desired properties of the proposed meth
    
[^87]: NTK-近似MLP融合用于高效的语言模型微调

    NTK-approximating MLP Fusion for Efficient Language Model Fine-tuning. (arXiv:2307.08941v1 [cs.LG])

    [http://arxiv.org/abs/2307.08941](http://arxiv.org/abs/2307.08941)

    该论文通过使用神经切向核近似MLP融合，提出了一种高效的语言模型微调方法。实验证明，这种方法能够在降低计算和存储开销的同时保持较好的模型性能。

    

    在许多自然语言处理应用中，微调预训练语言模型(PLM)已成为主要策略。然而，即使是微调PLM和进行推理也是昂贵的，特别是在计算能力较低的边缘设备上。已经广泛研究了一些通用的方法（例如量化和蒸馏）来减少PLM微调的计算/存储开销，但很少有一次性压缩技术被探索。在本文中，我们研究了多层感知器(MLP)模块中预训练语言模型(PLM)的神经切向核(NTK)，并提出通过NTK近似MLP融合来创建一个轻量级的PLM。为实现这一目标，我们将MLP重新视为一束子MLP，并将它们聚类为给定数量的质心，然后将其恢复为压缩的MLP，并意外地显示出对原始PLM的NTK进行良好近似的效果。在自然语言处理数据集上进行了大量实验以验证PLM微调的效果。

    Fine-tuning a pre-trained language model (PLM) emerges as the predominant strategy in many natural language processing applications. However, even fine-tuning the PLMs and doing inference are expensive, especially on edge devices with low computing power. Some general approaches (e.g. quantization and distillation) have been widely studied to reduce the compute/memory of PLM fine-tuning, while very few one-shot compression techniques are explored. In this paper, we investigate the neural tangent kernel (NTK)--which reveals the gradient descent dynamics of neural networks--of the multilayer perceptrons (MLP) modules in a PLM and propose to coin a lightweight PLM through NTK-approximating MLP fusion. To achieve this, we reconsider the MLP as a bundle of sub-MLPs, and cluster them into a given number of centroids, which can then be restored as a compressed MLP and surprisingly shown to well approximate the NTK of the original PLM. Extensive experiments of PLM fine-tuning on both natural l
    
[^88]: TableGPT：将表格，自然语言和命令统一到一个GPT中

    TableGPT: Towards Unifying Tables, Nature Language and Commands into One GPT. (arXiv:2307.08674v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2307.08674](http://arxiv.org/abs/2307.08674)

    TableGPT是一个统一的框架，利用大型语言模型（LLMs）和外部功能命令使LLMs能够无缝地与表格进行交互，实现广泛的功能，并提供便利和可访问性给用户。其中的创新是全局表格表示的概念，使LLMs能够全面理解表格的结构和内容。

    

    表格在现实世界的数据库中非常普遍，需要人们花费大量时间和精力进行分析和操作。大型语言模型（LLMs）的进步使得使用自然语言输入与表格交互成为可能，使得这种能力更加接近现实。本文介绍了TableGPT，这是一个统一的精调框架，使得LLMs能够利用外部功能命令理解和操作表格。它引入了与表格无缝交互的能力，实现了广泛的功能，如问答、数据操作（例如插入、删除、查询和修改操作）、数据可视化、分析报告生成和自动预测。TableGPT旨在通过使用户能够轻松利用表格数据来提供便利和可访问性。TableGPT的核心是全局表格表示的新概念，它使LLMs能够全面理解表格的结构和内容，并将自然语言和命令操作对表格实现无缝集成。

    Tables are prevalent in real-world databases, requiring significant time and effort for humans to analyze and manipulate. The advancements in large language models (LLMs) have made it possible to interact with tables using natural language input, bringing this capability closer to reality. In this paper, we present TableGPT, a unified fine-tuned framework that enables LLMs to understand and operate on tables using external functional commands. It introduces the capability to seamlessly interact with tables, enabling a wide range of functionalities such as question answering, data manipulation (e.g., insert, delete, query, and modify operations), data visualization, analysis report generation, and automated prediction. TableGPT aims to provide convenience and accessibility to users by empowering them to effortlessly leverage tabular data. At the core of TableGPT lies the novel concept of global tabular representations, which empowers LLMs to gain a comprehensive understanding of the ent
    
[^89]: 利用航空或卫星影像评估泰国资产价值

    Thailand Asset Value Estimation Using Aerial or Satellite Imagery. (arXiv:2307.08650v1 [q-fin.ST])

    [http://arxiv.org/abs/2307.08650](http://arxiv.org/abs/2307.08650)

    本研究提出了一种利用航空或卫星影像进行泰国资产价值评估的方法，通过使用谷歌地图API的影像数据和深度学习模型，实现了较高的准确性。该方法相比传统方法，在考虑了空间变量的情况下能够得到更精确的土地价格预测结果。

    

    房地产是泰国经济中的一个关键领域，这导致了对更准确的土地价格预测方法的日益需求。传统的土地价格预测方法，如加权质量得分（WQS），由于依赖主观标准和缺乏对空间变量的考虑而受到限制。在本研究中，我们利用谷歌地图API提供的航空或卫星影像，增强了由卡塞科恩商业科技集团（KBTG）提供的数据集上的土地价格预测模型。我们提出了一种基于相似性的资产估值模型，使用预训练的EfficientNet架构的Siamese启发式神经网络来评估土地对之间的相似性。通过集成深度学习和基于树的模型，我们实现了约0.81的ROC曲线下面积（AUC），优于仅使用表格数据的基准模型。通过具有高于预定义阈值的相似性评分的附近土地的评估价格

    Real estate is a critical sector in Thailand's economy, which has led to a growing demand for a more accurate land price prediction approach. Traditional methods of land price prediction, such as the weighted quality score (WQS), are limited due to their reliance on subjective criteria and their lack of consideration for spatial variables. In this study, we utilize aerial or satellite imageries from Google Map API to enhance land price prediction models from the dataset provided by Kasikorn Business Technology Group (KBTG). We propose a similarity-based asset valuation model that uses a Siamese-inspired Neural Network with pretrained EfficientNet architecture to assess the similarity between pairs of lands. By ensembling deep learning and tree-based models, we achieve an area under the ROC curve (AUC) of approximately 0.81, outperforming the baseline model that used only tabular data. The appraisal prices of nearby lands with similarity scores higher than a predefined threshold were us
    
[^90]: DNAGPT：用于多个DNA序列分析任务的通用预训练工具

    DNAGPT: A Generalized Pretrained Tool for Multiple DNA Sequence Analysis Tasks. (arXiv:2307.05628v1 [q-bio.GN])

    [http://arxiv.org/abs/2307.05628](http://arxiv.org/abs/2307.05628)

    DNAGPT是一个通用的基础模型，通过预训练模型和独特的标记设计，可以适用于任何DNA序列分析任务。它在多个任务上进行了评估，并展示出了良好的性能。

    

    GPT系列的成功证明了GPT可以从序列中提取一般性信息，从而使得所有下游任务受益。这激发了我们使用预训练模型来探索DNA序列中的隐藏信息。然而，DNA序列分析中的数据和任务需求非常复杂和多样化，因为DNA相关数据包含不同类型的信息，如序列、表达水平等，目前还没有专门针对这些特点设计的模型。因此，我们提出了DNAGPT，这是一个通用的基础模型，它在9个物种的超过100亿个碱基对上进行了预训练，并可以针对任何DNA序列分析任务进行微调。我们的模型可以同时处理或输出DNA序列和数值。此外，我们独特的标记设计允许用户根据自己的任务需求来设计提示，使其适用于任何类型的任务。我们在分类、回归和生成任务上对模型进行了评估。

    The success of the GPT series proves that GPT can extract general information from sequences, thereby benefiting all downstream tasks. This motivates us to use pre-trained models to explore the hidden information in DNA sequences. However, data and task requirements in DNA sequence analysis are complexity and diversity as DNA relevant data includes different types of information, such as sequences, expression levels, etc, while there is currently no model specifically designed for these characteristics. Hereby, we present DNAGPT, a generalized foundation model pre-trained on over 10 billion base pairs from 9 species which can be fine-tuned for any DNA sequence analysis task. Our model can simultaneously process or output DNA sequences and numbers. In addition, our unique token design allows users to design prompts according to their own task requirements, making it applicable to any type of task. We have evaluated our model on classification, regression, and generation tasks. We demons
    
[^91]: 提升自适应学习分数来增加交互式强化学习的反馈效率

    Boosting Feedback Efficiency of Interactive Reinforcement Learning by Adaptive Learning from Scores. (arXiv:2307.05405v1 [cs.RO])

    [http://arxiv.org/abs/2307.05405](http://arxiv.org/abs/2307.05405)

    本文提出一种利用人类提供的分数来改进交互式强化学习的反馈效率的方法。通过使用分数代替成对偏好，我们可以获得更多的数据。我们通过对机器人任务的评估表明，该方法能够通过自适应学习分数有效地学习到接近最优的策略。

    

    交互式强化学习在学习复杂的机器人任务方面显示出潜力。然而，由于需要大量的交互反馈，这一过程可能需要人工参与。本文提出了一种新的方法，利用人类提供的分数而不是成对偏好，来提高交互式强化学习的反馈效率。我们的关键洞察是，分数可以产生比成对偏好更多的数据。具体而言，在稀疏奖励环境中，我们要求教师与代理交互评分全面的轨迹来训练行为策略。为了避免人类给出的不稳定分数对训练过程产生负面影响，我们提出了一种自适应学习方案。这使得学习范式对于不完美或不可靠的分数不敏感。我们对机器人运动和操作任务进行了广泛评估。结果表明，所提出的方法可以通过自适应学习分数有效地学习到接近最优的策略。

    Interactive reinforcement learning has shown promise in learning complex robotic tasks. However, the process can be human-intensive due to the requirement of large amount of interactive feedback. This paper presents a new method that uses scores provided by humans, instead of pairwise preferences, to improve the feedback efficiency of interactive reinforcement learning. Our key insight is that scores can yield significantly more data than pairwise preferences. Specifically, we require a teacher to interactively score the full trajectories of an agent to train a behavioral policy in a sparse reward environment. To avoid unstable scores given by human negatively impact the training process, we propose an adaptive learning scheme. This enables the learning paradigm to be insensitive to imperfect or unreliable scores. We extensively evaluate our method on robotic locomotion and manipulation tasks. The results show that the proposed method can efficiently learn near-optimal policies by adap
    
[^92]: SoK: 隐私保护的数据合成

    SoK: Privacy-Preserving Data Synthesis. (arXiv:2307.02106v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2307.02106](http://arxiv.org/abs/2307.02106)

    这篇论文提供了关于隐私保护的数据合成的综述和讨论，结合了统计方法和基于深度学习的方法。通过提供参考表和总结关键要点来巩固研究发现。

    

    随着数据分析的普及，数据隐私保护成为了一个重要的关注点。因此，隐私保护的数据分析机制的发展日益增多。然而，这些方法都是针对特定任务设计的，对于新任务的设计过程繁琐。作为替代方案，可以创建理论上不包含私人信息的合成数据。本文重点讨论隐私保护的数据合成（PPDS）并提供该领域的全面概述、分析和讨论。具体而言，我们提出了一个统一两个主要研究领域，即统计方法和基于深度学习（DL）的方法的总结。在该总结中，我们进一步对统计方法进行了建模和表示的选择，并通过不同的生成模型原则来研究基于DL的方法。为了总结我们的发现，我们提供了全面的参考表，概括了关键要点。

    As the prevalence of data analysis grows, safeguarding data privacy has become a paramount concern. Consequently, there has been an upsurge in the development of mechanisms aimed at privacy-preserving data analyses. However, these approaches are task-specific; designing algorithms for new tasks is a cumbersome process. As an alternative, one can create synthetic data that is (ideally) devoid of private information. This paper focuses on privacy-preserving data synthesis (PPDS) by providing a comprehensive overview, analysis, and discussion of the field. Specifically, we put forth a master recipe that unifies two prominent strands of research in PPDS: statistical methods and deep learning (DL)-based methods. Under the master recipe, we further dissect the statistical methods into choices of modeling and representation, and investigate the DL-based methods by different generative modeling principles. To consolidate our findings, we provide comprehensive reference tables, distill key take
    
[^93]: 只需预训练：一种用于自闭症谱系障碍分类的多atlas增强transformer框架

    Pretraining is All You Need: A Multi-Atlas Enhanced Transformer Framework for Autism Spectrum Disorder Classification. (arXiv:2307.01759v1 [cs.CV])

    [http://arxiv.org/abs/2307.01759](http://arxiv.org/abs/2307.01759)

    提出了一种用于自闭症谱系障碍分类的多atlas增强transformer框架，利用静息态功能磁共振成像数据进行建模，采用自我监督预训练提高了分类性能。

    

    自闭症谱系障碍（ASD）是一种常见的精神疾病，表现为非典型的认知、情绪和社交模式。及时准确的诊断对ASD患者的有效干预和改善结果至关重要。在本研究中，我们提出了一种新颖的多atlas增强transformer框架（METAFormer）用于ASD分类。我们的框架利用了ABIDE I数据集中的静息态功能磁共振成像数据，包括406名ASD患者和476名典型对照（TC）受试者。METAFormer采用了多atlas方法，其中来自AAL、CC200和DOS160图谱的展平连接矩阵作为变压器编码器的输入。值得注意的是，我们证明了自我监督预训练，包括从输入中重建掩码值，可以在不需要额外或独立的训练数据的情况下显著提高分类性能。通过分层交叉验证，我们评估了提出的框架并展示了

    Autism spectrum disorder (ASD) is a prevalent psychiatric condition characterized by atypical cognitive, emotional, and social patterns. Timely and accurate diagnosis is crucial for effective interventions and improved outcomes in individuals with ASD. In this study, we propose a novel Multi-Atlas Enhanced Transformer framework, METAFormer, ASD classification. Our framework utilizes resting-state functional magnetic resonance imaging data from the ABIDE I dataset, comprising 406 ASD and 476 typical control (TC) subjects. METAFormer employs a multi-atlas approach, where flattened connectivity matrices from the AAL, CC200, and DOS160 atlases serve as input to the transformer encoder. Notably, we demonstrate that self-supervised pretraining, involving the reconstruction of masked values from the input, significantly enhances classification performance without the need for additional or separate training data. Through stratified cross-validation, we evaluate the proposed framework and show
    
[^94]: Pareto-安全的机器学习（PSML）：指纹和保护推断服务系统。

    Pareto-Secure Machine Learning (PSML): Fingerprinting and Securing Inference Serving Systems. (arXiv:2307.01292v1 [cs.CR])

    [http://arxiv.org/abs/2307.01292](http://arxiv.org/abs/2307.01292)

    本论文研究了模型服务系统的安全性，通过引入一个查询高效的指纹算法，使得攻击者能够一致地触发任何想要的模型，从而增强了对模型提取攻击的鲁棒性和准确性。

    

    随着大型基础模型的出现，模型服务系统越来越受欢迎。在这样的系统中，用户将查询发送到服务器，并指定所需的性能指标（例如准确性、延迟等）。服务器在后端维护一组模型（模型库），并根据指定的指标提供查询服务。本文研究了这些系统的安全性，特别是对模型提取攻击的鲁棒性。现有的黑盒攻击不能直接应用于提取受害模型，因为模型隐藏在推理服务接口背后的模型库中，攻击者无法确定使用的是哪个模型。需要一个中间步骤来确保每个输入查询都能得到受害模型的输出。为此，我们提出了一种查询高效的指纹算法，使攻击者能够一致地触发任何想要的模型。我们证明，通过使用我们的指纹算法，模型提取可以具有保真度和准确性。

    With the emergence of large foundational models, model-serving systems are becoming popular. In such a system, users send the queries to the server and specify the desired performance metrics (e.g., accuracy, latency, etc.). The server maintains a set of models (model zoo) in the back-end and serves the queries based on the specified metrics. This paper examines the security, specifically robustness against model extraction attacks, of such systems. Existing black-box attacks cannot be directly applied to extract a victim model, as models hide among the model zoo behind the inference serving interface, and attackers cannot identify which model is being used. An intermediate step is required to ensure that every input query gets the output from the victim model. To this end, we propose a query-efficient fingerprinting algorithm to enable the attacker to trigger any desired model consistently. We show that by using our fingerprinting algorithm, model extraction can have fidelity and accu
    
[^95]: 弹性约束下的元学习器用于联邦学习

    Elastically-Constrained Meta-Learner for Federated Learning. (arXiv:2306.16703v1 [cs.LG])

    [http://arxiv.org/abs/2306.16703](http://arxiv.org/abs/2306.16703)

    这项研究提出了一种弹性约束的元学习方法，用于解决联邦学习中由于非独立同分布数据导致元学习的不稳定目标的收敛问题。

    

    联邦学习是一种协作训练机器学习模型的方法，用于多个参与方之间禁止数据共享。在联邦学习中的一个挑战是客户端之间的非独立同分布数据，因为单个模型无法适应所有客户端的数据分布。为了解决这个问题，介绍了元学习（如Per-FedAvg）。元学习学习适用于所有客户端的共享初始参数。每个客户端使用梯度下降法将初始化快速调整到本地数据分布，实现模型个性化。然而，由于非凸损失函数和采样更新的随机性，元学习方法在本地适应同一客户端时具有不稳定的目标。这种不同适应方向的波动阻碍了元学习的收敛。为了克服这个挑战，我们使用了历史本地调整的模型来限制内循环的方向，并提出了一种弹性约束方法。

    Federated learning is an approach to collaboratively training machine learning models for multiple parties that prohibit data sharing. One of the challenges in federated learning is non-IID data between clients, as a single model can not fit the data distribution for all clients. Meta-learning, such as Per-FedAvg, is introduced to cope with the challenge. Meta-learning learns shared initial parameters for all clients. Each client employs gradient descent to adapt the initialization to local data distributions quickly to realize model personalization. However, due to non-convex loss function and randomness of sampling update, meta-learning approaches have unstable goals in local adaptation for the same client. This fluctuation in different adaptation directions hinders the convergence in meta-learning. To overcome this challenge, we use the historical local adapted model to restrict the direction of the inner loop and propose an elastic-constrained method. As a result, the current round
    
[^96]: 应用卷积神经网络对T1静息态磁共振图像进行建模，帮助诊断强迫症

    Modeling T1 Resting-State MRI Variants Using Convolutional Neural Networks in Diagnosis of OCD. (arXiv:2306.12435v1 [q-bio.NC])

    [http://arxiv.org/abs/2306.12435](http://arxiv.org/abs/2306.12435)

    本研究利用计算建模方法开发了一个卷积神经网络模型，通过T1静息态磁共振成像(TRS-MRI)扫描识别生物标志物，有效地区分出患有OCD和其他精神障碍的患者，准确率超过90%。

    

    强迫症是一种高度令人痛苦的疾病，其常常与前额皮层和代谢型谷氨酸受体5(mGluR5)有关。研究发现，通过测量小鼠正电子发射断层扫描的分布容积比，发现该受体信号水平更高。然而，由于需要更多实证数据，尚无法完全验证mGluR5的参与。因此，本研究使用计算建模方法，利用患有精神分裂症、抑郁症和强迫症患者的T1静息态磁共振成像(TRS-MRI)扫描，以回答有关OCD的因果因素的不足。通过这些疾病之间的交叉比较，寻找特定疾病的显著特征。本研究开发了一个卷积神经网络模型，用于识别区分患有OCD和其他精神障碍的生物标志物。结果表明，该模型可以高精度地识别患有OCD 的患者，准确率超过90%。这种方法可以作为一种有效的诊断OCD的工具，为传统诊断流程提供可靠的替代方案。

    Obsessive-compulsive disorder (OCD) presents itself as a highly debilitating disorder. The disorder has common associations with the prefrontal cortex and the glutamate receptor known as Metabotropic Glutamate Receptor 5 (mGluR5). This receptor has been observed to demonstrate higher levels of signaling from positron emission tomography scans measured by its distribution volume ratios in mice. Despite this evidence, studies are unable to fully verify the involvement of mGluR5 as more empirical data is needed. Computational modeling methods were used as a means of validation for previous hypotheses involving mGluR5. The inadequacies in relation to the causal factor of OCD were answered by utilizing T1 resting-state magnetic resonance imaging (TRS-MRI) scans of patients suffering from schizophrenia, major depressive disorder, and obsessive-compulsive disorder. Because comorbid cases often occur within these disorders, cross-comparative abilities become necessary to find distinctive chara
    
[^97]: 采用分层嵌入和会话属性的伪会话推荐

    Pseudo session-based recommendation with hierarchical embedding and session attributes. (arXiv:2306.10029v1 [cs.IR])

    [http://arxiv.org/abs/2306.10029](http://arxiv.org/abs/2306.10029)

    本文提出了一种新方法CoHHGN+，用于解决缺乏用户ID的电商网站数据的推荐问题。该方法使用了定义的伪会话以及包括价格、类别、性别和地区等用户信息，得到了较好的推荐结果。

    

    最近，由于隐私问题，电子商务网站无法为每个交易数据条目提供标识号（用户ID）。因为大多数推荐方法假定所有数据都被分配了用户ID，所以它们不能应用于没有用户ID的数据。最近研究了基于会话信息的会话推荐（SBR），该方法基于用户的短期行为信息。常规的SBR只使用与感兴趣的项目相关的信息来进行推荐（例如，在EC站点上使用项目ID）。特别是在EC网站的情况下，记录的数据包括被购买的物品名称、物品价格、类别层次结构以及用户的性别和地区。在本研究中，我们为没有用户ID和会话ID的EC网站的购买历史数据定义了伪会话。最后，我们提出了一种CoHHGN+会话推荐方法，它使用协同导向的异构超图和全局图网络。

    Recently, electronic commerce (EC) websites have been unable to provide an identification number (user ID) for each transaction data entry because of privacy issues. Because most recommendation methods assume that all data are assigned a user ID, they cannot be applied to the data without user IDs. Recently, session-based recommendation (SBR) based on session information, which is short-term behavioral information of users, has been studied. A general SBR uses only information about the item of interest to make a recommendation (e.g., item ID for an EC site). Particularly in the case of EC sites, the data recorded include the name of the item being purchased, the price of the item, the category hierarchy, and the gender and region of the user. In this study, we define a pseudo--session for the purchase history data of an EC site without user IDs and session IDs. Finally, we propose an SBR with a co-guided heterogeneous hypergraph and globalgraph network plus, called CoHHGN+. The result
    
[^98]: 利用广义经验似然方法理解深度生成模型

    Understanding Deep Generative Models with Generalized Empirical Likelihoods. (arXiv:2306.09780v1 [cs.LG])

    [http://arxiv.org/abs/2306.09780](http://arxiv.org/abs/2306.09780)

    本文展示了广义经验似然（GEL）方法提供了一系列诊断工具来识别深度生成模型的许多缺陷，并结合最大均值差异和广义经验似然的技术，创造了保留每个样本可解释性的分布测试，还包括标签信息的指标。这些测试可以预测模式降低的程度。

    

    理解深度生成模型如何捕获高维数据分布仍然是一个重要的挑战。对于某些模型类别，比如生成对抗网络和扩散模型等不允许精确似然度量的模型，尤其困难。本文展示了广义经验似然（GEL）方法提供了一系列诊断工具来识别深度生成模型的许多缺陷。通过适当的矩条件规定，我们展示了本文提出的方法可以识别哪些模式被删除、DGM存在的模式不平衡程度以及DGM是否足够捕获类内多样性。我们展示了如何结合最大均值差异和广义经验似然的技术，不仅创造了保留每个样本可解释性的分布测试，还包括标签信息的指标。我们发现这些测试可以预测模式降低的程度。

    Understanding how well a deep generative model captures a distribution of high-dimensional data remains an important open challenge. It is especially difficult for certain model classes, such as Generative Adversarial Networks and Diffusion Models, whose models do not admit exact likelihoods. In this work, we demonstrate that generalized empirical likelihood (GEL) methods offer a family of diagnostic tools that can identify many deficiencies of deep generative models (DGMs). We show, with appropriate specification of moment conditions, that the proposed method can identify which modes have been dropped, the degree to which DGMs are mode imbalanced, and whether DGMs sufficiently capture intra-class diversity. We show how to combine techniques from Maximum Mean Discrepancy and Generalized Empirical Likelihood to create not only distribution tests that retain per-sample interpretability, but also metrics that include label information. We find that such tests predict the degree of mode dr
    
[^99]: 批次使高维超参数线性回归的最小规范风险稳定

    Batches Stabilize the Minimum Norm Risk in High Dimensional Overparameterized Linear Regression. (arXiv:2306.08432v1 [cs.LG])

    [http://arxiv.org/abs/2306.08432](http://arxiv.org/abs/2306.08432)

    本文研究了将数据分成批次的学习算法，在高维超参数线性回归模型中提供了隐式正则化，通过适当的批量大小选择，稳定了风险行为，消除了插值点处的膨胀和双峰现象

    

    将数据分成批次的学习算法在许多机器学习应用中很常见，通常在计算效率和性能之间提供有用的权衡。本文通过具有各向同性高斯特征的最小规范超参数线性回归模型的视角来研究批量分区的好处。我们建议最小规范估计量的自然小批量版本，并推导出其二次风险的上界，表明其与噪声水平以及过度参数化比例成反比，对于最佳批量大小的选择。与最小规范相比，我们的估计器具有稳定的风险行为，其在过度参数化比例上单调递增，消除了插值点处的膨胀和双峰现象。有趣的是，我们观察到批处理所提供的隐式正则化在一定程度上可以通过特征重叠来解释。

    Learning algorithms that divide the data into batches are prevalent in many machine-learning applications, typically offering useful trade-offs between computational efficiency and performance. In this paper, we examine the benefits of batch-partitioning through the lens of a minimum-norm overparameterized linear regression model with isotropic Gaussian features. We suggest a natural small-batch version of the minimum-norm estimator, and derive an upper bound on its quadratic risk, showing it is inversely proportional to the noise level as well as to the overparameterization ratio, for the optimal choice of batch size. In contrast to minimum-norm, our estimator admits a stable risk behavior that is monotonically increasing in the overparameterization ratio, eliminating both the blowup at the interpolation point and the double-descent phenomenon. Interestingly, we observe that this implicit regularization offered by the batch partition is partially explained by feature overlap between t
    
[^100]: 对称张量分解问题的对称性与临界点

    Symmetry & Critical Points for Symmetric Tensor Decompositions Problems. (arXiv:2306.07886v1 [math.OC])

    [http://arxiv.org/abs/2306.07886](http://arxiv.org/abs/2306.07886)

    本文研究了将一个实对称张量分解成秩为1项之和的非凸优化问题，得到了精确的分析估计，并发现了各种阻碍局部优化方法的几何障碍和由于对称性导致的丰富的临界点集合。

    

    本文考虑了将一个实对称张量分解成秩为1项之和的非凸优化问题。利用其丰富的对称结构，导出Puiseux级数表示的一系列临界点，并获得了关于临界值和Hessian谱的精确分析估计。这些结果揭示了各种几何障碍，阻碍了局部优化方法的使用，最后，利用一个牛顿多面体论证了固定对称性的所有临界点的完全枚举，并证明了与全局最小值的集合相比，由于对称性的存在，临界点的集合可能会显示出组合的丰富性。

    We consider the non-convex optimization problem associated with the decomposition of a real symmetric tensor into a sum of rank one terms. Use is made of the rich symmetry structure to derive Puiseux series representations of families of critical points, and so obtain precise analytic estimates on the critical values and the Hessian spectrum. The sharp results make possible an analytic characterization of various geometric obstructions to local optimization methods, revealing in particular a complex array of saddles and local minima which differ by their symmetry, structure and analytic properties. A desirable phenomenon, occurring for all critical points considered, concerns the index of a point, i.e., the number of negative Hessian eigenvalues, increasing with the value of the objective function. Lastly, a Newton polytope argument is used to give a complete enumeration of all critical points of fixed symmetry, and it is shown that contrarily to the set of global minima which remains 
    
[^101]: 基于邻域比较的语言模型成员推断攻击

    Membership Inference Attacks against Language Models via Neighbourhood Comparison. (arXiv:2305.18462v1 [cs.CL])

    [http://arxiv.org/abs/2305.18462](http://arxiv.org/abs/2305.18462)

    本文提出两种新的基于邻域比较的攻击策略，利用语言数据的内在结构来提高成员推断攻击的性能，并在几个公开数据集上证明这些攻击的有效性。

    

    成员推断攻击(MIAs)旨在预测一个数据样本是否存在于机器学习模型的训练数据中，广泛用于评估语言模型的隐私风险。现有的大多数攻击依赖于这样一个观察结果，即模型倾向于将更高的概率分配给训练样本而非非训练点。然而，对模型分数的简单阈值设定往往导致高误报率，因为它没有考虑样本的内在复杂性。最近的研究表明，基于参考模型的攻击可以将模型分数与在类似数据上训练的参考模型获得的分数进行比较，可以显著提高MIAs的性能。然而，为了训练参考模型，这种攻击的做法是假定敌方知道与原始训练数据密切相似的样本，这是一个强假设。因此，我们在更现实的情况下，假定攻击者只能访问有限的邻域样本，研究了这些攻击的性能。我们提出了两种新的攻击策略，利用语言数据的内在结构，可以用于评估在更现实的成员推断场景下的语言模型的隐私风险。我们的实验表明，我们的攻击在几个公开可用的数据集上是有效的，其中包括文本分类、自然语言推理和对话生成，并突显了语言模型在实际应用中的潜在隐私风险。

    Membership Inference attacks (MIAs) aim to predict whether a data sample was present in the training data of a machine learning model or not, and are widely used for assessing the privacy risks of language models. Most existing attacks rely on the observation that models tend to assign higher probabilities to their training samples than non-training points. However, simple thresholding of the model score in isolation tends to lead to high false-positive rates as it does not account for the intrinsic complexity of a sample. Recent work has demonstrated that reference-based attacks which compare model scores to those obtained from a reference model trained on similar data can substantially improve the performance of MIAs. However, in order to train reference models, attacks of this kind make the strong and arguably unrealistic assumption that an adversary has access to samples closely resembling the original training data. Therefore, we investigate their performance in more realistic sce
    
[^102]: 无需残差计算的车辆检测与分类：通过随机扰动注入加速HEVC图像解码。

    Vehicle Detection and Classification without Residual Calculation: Accelerating HEVC Image Decoding with Random Perturbation Injection. (arXiv:2305.08265v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.08265](http://arxiv.org/abs/2305.08265)

    本文介绍了一种用于交通监控的新方法，通过随机扰动重建图像，而不使用残差数据，从而显著减少图像重构所需的数据。该方法通过创建原始图像的精简表示，并保留与视频理解任务相关的信息，重点关注车辆检测和分类等关键用例。

    

    在视频分析领域，尤其是交通监控方面，需要有效的高效视频数据处理和理解方法。传统的视频解码技术计算密集且时间耗费大，因此研究人员开始在压缩域中探索替代方法。本文提出了一种基于随机扰动的压缩域方法，特别针对交通监控应用，在HEVC比特流中重建图像。据我们所知，我们的方法是首个建议使用随机扰动代替残差数值，创造出原始图像的精简表示，并保留与视频理解任务相关的信息，重点关注车辆检测和分类。通过不使用残差数据，我们的方法显著减少了图像重构所需的数据。

    In the field of video analytics, particularly traffic surveillance, there is a growing need for efficient and effective methods for processing and understanding video data. Traditional full video decoding techniques can be computationally intensive and time-consuming, leading researchers to explore alternative approaches in the compressed domain. This study introduces a novel random perturbation-based compressed domain method for reconstructing images from High Efficiency Video Coding (HEVC) bitstreams, specifically designed for traffic surveillance applications. To the best of our knowledge, our method is the first to propose substituting random perturbations for residual values, creating a condensed representation of the original image while retaining information relevant to video understanding tasks, particularly focusing on vehicle detection and classification as key use cases.  By not using residual data, our proposed method significantly reduces the data needed in the image recon
    
[^103]: 无先验信道知识的端到端通信系统的深度确定性策略梯度

    Deep Deterministic Policy Gradient for End-to-End Communication Systems without Prior Channel Knowledge. (arXiv:2305.07448v1 [cs.NI])

    [http://arxiv.org/abs/2305.07448](http://arxiv.org/abs/2305.07448)

    本研究提出了一种基于深度确定性策略梯度（DDPG）的框架来解决无先验信道知识的端到端通信系统中发射器和接收器联合训练的问题。与现有方案相比，该方法可以获得更好的检测性能。

    

    最近引入了端到端（E2E）基于学习的概念，以共同优化无线通信系统中的发送器和接收器。不幸的是，这种E2E学习架构需要先前的可微分信道模型来共同训练发射接收器的深度神经网络（DNNs），这在实践中几乎不可能。本文旨在通过开发基于深度确定性策略梯度（DDPG）的框架来解决这个问题。特别地，所提出的解决方案使用接收器DNN的损失值作为奖励来训练发射器DNN。模拟结果显示，我们的提议可以共同训练发射器和接收器而不需要先前的信道模型。此外，我们证明所提出的基于DDPG的解决方案可以实现比现有解决方案更好的检测性能。

    End-to-End (E2E) learning-based concept has been recently introduced to jointly optimize both the transmitter and the receiver in wireless communication systems. Unfortunately, this E2E learning architecture requires a prior differentiable channel model to jointly train the deep neural networks (DNNs) at the transceivers, which is hardly obtained in practice. This paper aims to solve this issue by developing a deep deterministic policy gradient (DDPG)-based framework. In particular, the proposed solution uses the loss value of the receiver DNN as the reward to train the transmitter DNN. The simulation results then show that our proposed solution can jointly train the transmitter and the receiver without requiring the prior channel model. In addition, we demonstrate that the proposed DDPG-based solution can achieve better detection performance compared to the state-of-the-art solutions.
    
[^104]: 通过学习不断困难负样本实现自动放射学报告生成

    Automatic Radiology Report Generation by Learning with Increasingly Hard Negatives. (arXiv:2305.07176v1 [cs.CV])

    [http://arxiv.org/abs/2305.07176](http://arxiv.org/abs/2305.07176)

    本文提出了一种通过学习不断困难负样本的方法实现自动放射学报告生成的框架，以获得更具判别能力的特征，从而避免产生不期望或不匹配的报告。

    

    自动放射学报告生成面临着挑战，因为医学图像或报告通常由于解剖结构的相同内容而相似。这使得模型难以捕捉个体图像的独特性，容易产生不期望的通用或不匹配的报告。为了解决这个问题，本文提出了一个新的框架，通过区分最接近的负样本，即困难负样本来学习判别图像和报告特征。特别地，为了获得更具判别能力的特征，在训练期间逐渐提高这种学习任务的难度，为特征空间中的每个图像创建越来越困难的负样本。通过将不断困难的负样本视为辅助变量，我们将这个过程制定为一个最小-最大交替优化问题。在每次迭代中，条件

    Automatic radiology report generation is challenging as medical images or reports are usually similar to each other due to the common content of anatomy. This makes a model hard to capture the uniqueness of individual images and is prone to producing undesired generic or mismatched reports. This situation calls for learning more discriminative features that could capture even fine-grained mismatches between images and reports. To achieve this, this paper proposes a novel framework to learn discriminative image and report features by distinguishing them from their closest peers, i.e., hard negatives. Especially, to attain more discriminative features, we gradually raise the difficulty of such a learning task by creating increasingly hard negative reports for each image in the feature space during training, respectively. By treating the increasingly hard negatives as auxiliary variables, we formulate this process as a min-max alternating optimisation problem. At each iteration, condition
    
[^105]: 神经网络模型的相似度：功能和表示性测量的综述

    Similarity of Neural Network Models: A Survey of Functional and Representational Measures. (arXiv:2305.06329v1 [cs.LG])

    [http://arxiv.org/abs/2305.06329](http://arxiv.org/abs/2305.06329)

    本文综述了神经网络模型相似度的两个观点：表示性相似和功能相似，提供了这两个家族的详细描述，并总结和讨论了其属性和关系，并提出了实践建议。

    

    衡量神经网络的相似性已成为一个非常重要且备受研究关注的问题，以了解和利用神经网络的差异。虽然有几种观点可以描述神经网络的相似性，但是本文特别关注两个互补的观点，即(i) 表示性相似，考虑中间神经层的激活差异，和(ii) 功能相似，考虑模型输出的差异。在本文中，我们全面概述了这两个神经网络模型相似性测量的家族。除了提供现有测量的详细描述外，我们还总结和讨论了这些测量的属性和关系，并指出了开放的研究问题。此外，我们提供了实用建议，可以指导研究人员和实践者利用这些测量。我们希望本文为我们的社区参与更多有用的工作奠定基础。

    Measuring similarity of neural networks has become an issue of great importance and research interest to understand and utilize differences of neural networks. While there are several perspectives on how neural networks can be similar, we specifically focus on two complementing perspectives, i.e., (i) representational similarity, which considers how activations of intermediate neural layers differ, and (ii) functional similarity, which considers how models differ in their outputs. In this survey, we provide a comprehensive overview of these two families of similarity measures for neural network models. In addition to providing detailed descriptions of existing measures, we summarize and discuss results on the properties and relationships of these measures, and point to open research problems. Further, we provide practical recommendations that can guide researchers as well as practitioners in applying the measures. We hope our work lays a foundation for our community to engage in more s
    
[^106]: 基于深度学习和注意力机制的膝关节X线照片预测髌股关节骨关节炎进展的研究

    Deep Learning for Predicting Progression of Patellofemoral Osteoarthritis Based on Lateral Knee Radiographs, Demographic Data and Symptomatic Assessments. (arXiv:2305.05927v1 [eess.IV])

    [http://arxiv.org/abs/2305.05927](http://arxiv.org/abs/2305.05927)

    本研究利用深度学习和注意力机制预测膝关节骨关节炎进展，发现成像数据在预测中起到重要作用。

    

    本研究提出了一种利用深度学习和注意力机制预测髌股关节骨关节炎（PFOA）在七年内放射性进展的新框架。该研究包括来自MOST研究基线的主体（1832个主体，3276个膝盖），并使用自动化的标志检测工具（BoneFinder）在膝关节X线的侧面识别PF关节感兴趣区域。在5倍交叉验证设置中，基于成像数据开发了一种端到端DL方法来预测PFOA进展。开发了一组基于已知风险因素的基线，并使用梯度提升机（GBM）进行分析。风险因素包括年龄，性别，BMI和WOMAC评分，以及胫骨-股骨关节的放射性骨关节炎分期（KL分数）。最后，我们使用成像和临床数据训练了一个集成模型。在个体模型中，我们的深度卷积神经网络注意模型的性能获得了最佳综合性能，AUC-ROC为0.83。我们的研究证明了利用DL和注意力机制预测PFOA进展的潜力，并强调了除了临床数据外还需要纳入成像数据以进行准确预测的重要性。

    In this study, we propose a novel framework that utilizes deep learning (DL) and attention mechanisms to predict the radiographic progression of patellofemoral osteoarthritis (PFOA) over a period of seven years. This study included subjects (1832 subjects, 3276 knees) from the baseline of the MOST study. PF joint regions-of-interest were identified using an automated landmark detection tool (BoneFinder) on lateral knee X-rays. An end-to-end DL method was developed for predicting PFOA progression based on imaging data in a 5-fold cross-validation setting. A set of baselines based on known risk factors were developed and analyzed using gradient boosting machine (GBM). Risk factors included age, sex, BMI and WOMAC score, and the radiographic osteoarthritis stage of the tibiofemoral joint (KL score). Finally, we trained an ensemble model using both imaging and clinical data. Among the individual models, the performance of our deep convolutional neural network attention model achieved the b
    
[^107]: 从自然语言文本中生成流程模型的方法——基于规则之外的命名实体识别和关系抽取(arXiv:2305.03960v1 [cs.CL])

    Beyond Rule-based Named Entity Recognition and Relation Extraction for Process Model Generation from Natural Language Text. (arXiv:2305.03960v1 [cs.CL])

    [http://arxiv.org/abs/2305.03960](http://arxiv.org/abs/2305.03960)

    本文扩展了PET数据集，通过聚类流程实体的提及，提出了一种新的基线技术流程提取方法，该方法避免了手动创建业务流程模型的繁琐工作，同时解决了同一流程实体重复提及的歧义问题。

    

    从自然语言文本自动生成业务流程模型是一种新兴方法，可避免手动创建形式化业务流程模型。为此，需要从文本流程描述中提取出流程实体（如参与者、活动、对象等）和它们之间的关系。一个高质量的带有文本流程描述的注释语料库(PET)已经出版，其伴随着一种基本的流程提取方法。然而，在其当前状态下，PET缺乏有关两个提及是否指代了相同或不同的流程实体的信息，这对于是否在目标模型中创建一个或两个建模元素的重要决策相对应。因此，例如，两个数据处理的提及是否意味着处理不同或相同的数据是不确定的。在本文中，我们通过聚类流程实体的提及来扩展PET数据集，并提出了一种新的基线技术流程提取方法，其中包含一个

    Automated generation of business process models from natural language text is an emerging methodology for avoiding the manual creation of formal business process models. For this purpose, process entities like actors, activities, objects etc., and relations among them are extracted from textual process descriptions. A high-quality annotated corpus of textual process descriptions (PET) has been published accompanied with a basic process extraction approach. In its current state, however, PET lacks information about whether two mentions refer to the same or different process entities, which corresponds to the crucial decision of whether to create one or two modeling elements in the target model. Consequently, it is ambiguous whether, for instance, two mentions of data processing mean processing of different, or the same data. In this paper, we extend the PET dataset by clustering mentions of process entities and by proposing a new baseline technique for process extraction equipped with a
    
[^108]: 基于归因的防御插入式文本后门攻击

    Defending against Insertion-based Textual Backdoor Attacks via Attribution. (arXiv:2305.02394v1 [cs.CL])

    [http://arxiv.org/abs/2305.02394](http://arxiv.org/abs/2305.02394)

    本文提出了一种基于归因的管道AttDef，用于防御两种插入式污染攻击BadNL和InSent，该管道可以成功缓解插入式文本后门攻击并在四个基准数据集上平均提高了56.59%至79.97%和15.25%至48.34%的准确率。

    

    文本后门攻击是一种新型攻击模式，已被证明在训练期间向模型添加后门是有效的。防御此类后门攻击已变得紧迫和重要。本文提出了一种名为AttDef的高效归因管道，用于防御两种插入式污染攻击BadNL和InSent。具体而言，我们将具有较大归因分数的令牌视为潜在触发器，因为较大的归因词对于错误预测结果做出较大贡献，因此更有可能是污染触发器。此外，我们进一步利用外部预训练语言模型来区分输入是否被污染。我们展示了我们的方法可以在两种常见的攻击场景（污染训练数据和测试数据）中具有足够的泛化性，这一点持续改善了之前的方法。例如，AttDef在四个基准数据集上可以成功缓解两种攻击，平均准确率为79.97%（提高了56.59%）和48.34%（提高了15.25%），证明了它在防御插入式文本后门攻击方面的有效性。

    Textual backdoor attack, as a novel attack model, has been shown to be effective in adding a backdoor to the model during training. Defending against such backdoor attacks has become urgent and important. In this paper, we propose AttDef, an efficient attribution-based pipeline to defend against two insertion-based poisoning attacks, BadNL and InSent. Specifically, we regard the tokens with larger attribution scores as potential triggers since larger attribution words contribute more to the false prediction results and therefore are more likely to be poison triggers. Additionally, we further utilize an external pre-trained language model to distinguish whether input is poisoned or not. We show that our proposed method can generalize sufficiently well in two common attack scenarios (poisoning training data and testing data), which consistently improves previous methods. For instance, AttDef can successfully mitigate both attacks with an average accuracy of 79.97% (56.59% up) and 48.34% 
    
[^109]: 从弱文本监督中学习图像中的人际互动

    Learning Human-Human Interactions in Images from Weak Textual Supervision. (arXiv:2304.14104v1 [cs.CV])

    [http://arxiv.org/abs/2304.14104](http://arxiv.org/abs/2304.14104)

    本文提出了一种新的范式，从单一的静态图像中学习自由文本的形式来灵活建模人际互动。并通过知识蒸馏生成伪标签来训练一种字幕模型，用于有效理解图像中的人际互动，具有较高的预测文本和语义质量，并在此任务上优于SOTA的图像字幕和情境识别模型。

    

    人际互动是多样且依赖于上下文的，但先前的工作将它们视为分类，忽略了可能的互动的重尾。本文提出了一种新的学习人际互动的范式，将其作为自由文本从单一的静态图像中学习，从而允许对情况和人际关系的无限空间进行灵活建模。为了克服缺乏特定于此任务的标记数据的问题，我们使用知识蒸馏应用于由大型语言模型产生的合成字幕数据，以此生成伪标签。我们展示了通过这个过程产生的伪标签可以用于训练一种字幕模型，能有效理解图像中的人际互动，通过衡量我们预测的文本和语义质量与事实的基础性的各种指标来衡量。我们进一步展示了我们的方法在这个任务上的性能优于SOTA的图像字幕和情境识别模型。我们将公开我们的代码。

    Interactions between humans are diverse and context-dependent, but previous works have treated them as categorical, disregarding the heavy tail of possible interactions. We propose a new paradigm of learning human-human interactions as free text from a single still image, allowing for flexibility in modeling the unlimited space of situations and relationships between people. To overcome the absence of data labelled specifically for this task, we use knowledge distillation applied to synthetic caption data produced by a large language model without explicit supervision. We show that the pseudo-labels produced by this procedure can be used to train a captioning model to effectively understand human-human interactions in images, as measured by a variety of metrics that measure textual and semantic faithfulness and factual groundedness of our predictions. We further show that our approach outperforms SOTA image captioning and situation recognition models on this task. We will release our c
    
[^110]: 物理信息神经网络用于预测柴油机气体流动动力学和未知参数

    Physics-informed neural networks for predicting gas flow dynamics and unknown parameters in diesel engines. (arXiv:2304.13799v1 [cs.LG])

    [http://arxiv.org/abs/2304.13799](http://arxiv.org/abs/2304.13799)

    本论文提出了一种物理信息神经网络（PINN）方法，能够同时准确预测柴油机未知参数和动态，以及识别“平均值”模型中的未知参数，为实际案例研究提供了可能性。

    

    本文介绍了一种应用于柴油机健康监测的物理信息神经网络(PINN)方法。该方法旨在评估发动机动力学，识别“平均值”模型中的未知参数，并预测维护需求。PINN模型应用于具有可变几何涡轮增压器和废气再循环的柴油机，使用选定状态变量的测量数据。实验结果表明，在干净和嘈杂的数据下，PINN模型能够同时准确地预测未知参数和动态，自适应权重在损失函数中的重要性，可加速收敛。这些模拟的输入数据来自实际发动机运行条件，而输出数据是模拟数据，使这成为PINN预测真实动态系统能力的实际案例研究。柴油机的平均值模型包括经验公式来表示某些状态，但本文提出的PINN方法可以更准确、更高效地预测动态并识别未知参数。

    This paper presents a physics-informed neural network (PINN) approach for monitoring the health of diesel engines. The aim is to evaluate the engine dynamics, identify unknown parameters in a "mean value" model, and anticipate maintenance requirements. The PINN model is applied to diesel engines with a variable-geometry turbocharger and exhaust gas recirculation, using measurement data of selected state variables. The results demonstrate the ability of the PINN model to predict simultaneously both unknown parameters and dynamics accurately with both clean and noisy data, and the importance of the self-adaptive weight in the loss function for faster convergence. The input data for these simulations are derived from actual engine running conditions, while the outputs are simulated data, making this a practical case study of PINN's ability to predict real-world dynamical systems. The mean value model of the diesel engine incorporates empirical formulae to represent certain states, but the
    
[^111]: 带种植模式的Hopfield模型：一种师生自我监督学习模型

    Hopfield model with planted patterns: a teacher-student self-supervised learning model. (arXiv:2304.13710v1 [cond-mat.dis-nn])

    [http://arxiv.org/abs/2304.13710](http://arxiv.org/abs/2304.13710)

    该论文提出了一种基于师生自我监督学习问题的Hopfield模型，能够帮助机器利用结构化的模式来学习，虽然一些条件对于学习非常重要，但这种学习模式在特定条件下可以实现泛化。

    

    尽管Hopfield网络被认为是记忆存储和检索的典型模型，但现代人工智能系统主要基于机器学习范式。我们展示了如何利用具有结构化模式的Hopfield模型的适当推广来构建Boltzmann机的师生自我监督学习问题，其中自旋变量是机器权重，模式对应于训练集的示例。我们通过研究相图来分析学习性能，这些相图是通过训练集大小、数据集噪声和推断温度（即权重正则化）来构建的。使用小而富信息的数据集，机器可以通过记忆来学习。使用嘈杂的数据集，则需要大量的示例数以超过临界阈值。在这个区域，系统的存储限制成为产生一种学习模式的机会，在这种模式下，系统可以进行泛化。

    While Hopfield networks are known as paradigmatic models for memory storage and retrieval, modern artificial intelligence systems mainly stand on the machine learning paradigm. We show that it is possible to formulate a teacher-student self-supervised learning problem with Boltzmann machines in terms of a suitable generalization of the Hopfield model with structured patterns, where the spin variables are the machine weights and patterns correspond to the training set's examples. We analyze the learning performance by studying the phase diagram in terms of the training set size, the dataset noise and the inference temperature (i.e. the weight regularization). With a small but informative dataset the machine can learn by memorization. With a noisy dataset, an extensive number of examples above a critical threshold is needed. In this regime the memory storage limits of the system becomes an opportunity for the occurrence of a learning regime in which the system can generalize.
    
[^112]: 应用基于特征分裂的物理信息神经网络求解Navier-Stokes方程

    Physics-informed Neural Network Combined with Characteristic-Based Split for Solving Navier-Stokes Equations. (arXiv:2304.10717v1 [physics.flu-dyn])

    [http://arxiv.org/abs/2304.10717](http://arxiv.org/abs/2304.10717)

    本文提出了一种基于特征分裂的物理信息神经网络（PINN）方法，可用于处理数据驱动和无数据问题，并且能够快速求解可压缩的浅水方程和不可压缩的N-S方程

    

    本文提出了一种基于特征分裂的物理信息神经网络（PINN）方法，可用于求解时间依赖的Navier-Stokes方程。该方法将输出参数和相应的损失值分离，使输出参数间的权重不被考虑。不是所有的偏导数都参与梯度反向传播，其余项会被重复使用。因此，与传统的PINN相比，该方法更快速。本方法将标签数据、物理约束和网络输出视为先验信息，将N-S方程的残差视为后验信息。因此，它可以处理数据驱动和无数据问题。结果，它能够求解可压缩的浅水方程和不可压缩的N-S方程。由于边界条件已知，该方法只需要在特定时间点获得流场信息即可。

    In this paper, physics-informed neural network (PINN) based on characteristic-based split (CBS) is proposed, which can be used to solve the time-dependent Navier-Stokes equations (N-S equations). In this method, The output parameters and corresponding losses are separated, so the weights between output parameters are not considered. Not all partial derivatives participate in gradient backpropagation, and the remaining terms will be reused.Therefore, compared with traditional PINN, this method is a rapid version. Here, labeled data, physical constraints and network outputs are regarded as priori information, and the residuals of the N-S equations are regarded as posteriori information. So this method can deal with both data-driven and data-free problems. As a result, it can solve the special form of compressible N-S equations -- -Shallow-Water equations, and incompressible N-S equations. As boundary conditions are known, this method only needs the flow field information at a certain tim
    
[^113]: 评估-优化方法与集成评估优化法：基于随机优势的观点

    Estimate-Then-Optimize Versus Integrated-Estimation-Optimization: A Stochastic Dominance Perspective. (arXiv:2304.06833v1 [stat.ML])

    [http://arxiv.org/abs/2304.06833](http://arxiv.org/abs/2304.06833)

    本文提出，当模型类足够丰富以涵盖真实情况时，非线性问题的“先估计再优化”方法优于集成方法，包括优化间隙的渐进优势的均值，所有其他时刻和整个渐进分布。

    

    在数据驱动的随机优化中，除了需要优化任务，还需要从数据中估计潜在分布的模型参数。最近的文献表明，通过选择导致最佳经验目标性能的模型参数，可以集成估计和优化过程。当模型被错误地指定时，这种集成方法可以很容易地显示出优于简单的“先估计再优化”的方法。本文认为，在模型类足够丰富以涵盖真实情况的情况下，对于非线性问题，两种方法之间的性能排序在强烈的意义下被颠倒。在受限条件和当上下文特征可用时，类似的结果也成立。

    In data-driven stochastic optimization, model parameters of the underlying distribution need to be estimated from data in addition to the optimization task. Recent literature suggests the integration of the estimation and optimization processes, by selecting model parameters that lead to the best empirical objective performance. Such an integrated approach can be readily shown to outperform simple ``estimate then optimize" when the model is misspecified. In this paper, we argue that when the model class is rich enough to cover the ground truth, the performance ordering between the two approaches is reversed for nonlinear problems in a strong sense. Simple ``estimate then optimize" outperforms the integrated approach in terms of stochastic dominance of the asymptotic optimality gap, i,e, the mean, all other moments, and the entire asymptotic distribution of the optimality gap is always better. Analogous results also hold under constrained settings and when contextual features are availa
    
[^114]: 我们实现了个性化治疗吗？使用重复采样的在线强化学习算法进行个性化评估

    Did we personalize? Assessing personalization by an online reinforcement learning algorithm using resampling. (arXiv:2304.05365v1 [cs.LG])

    [http://arxiv.org/abs/2304.05365](http://arxiv.org/abs/2304.05365)

    本论文提出了一种使用重复采样的政策评估方法，以评估在线 RL 算法实现的个性化程度。该方法可用于优化数字健康的个性化干预。

    

    在数字健康中，使用强化学习（RL）个性化治疗序列以支持用户采取更健康的行为越来越受到关注。这种连续决策问题涉及到基于用户的上下文（例如，先前的活动水平、位置等）在何时治疗以及如何治疗的决定。在线RL算法是这个问题的一个有前途的数据驱动方法，因为它基于每个用户的历史反馈进行学习，并利用这些知识个性化这些决策。然而，要决定是否应在实际部署的“优化”干预中包含RL算法，我们必须评估数据证据，表明RL算法实际上正在将治疗个性化适应其用户。由于RL算法中的随机性，人们可能会对其在某些状态下的学习并使用此学习来提供特定治疗的能力产生误解。我们使用工作定义的个性化，并介绍了一种重复采样政策评估方法来评估在线RL算法实现的个性化水平。我们使用模拟评估了我们提出的方法，并展示了我们的方法可以准确地识别个性化的策略。我们提出的方法在优化数字健康的个性化干预方面具有潜在应用。

    There is a growing interest in using reinforcement learning (RL) to personalize sequences of treatments in digital health to support users in adopting healthier behaviors. Such sequential decision-making problems involve decisions about when to treat and how to treat based on the user's context (e.g., prior activity level, location, etc.). Online RL is a promising data-driven approach for this problem as it learns based on each user's historical responses and uses that knowledge to personalize these decisions. However, to decide whether the RL algorithm should be included in an ``optimized'' intervention for real-world deployment, we must assess the data evidence indicating that the RL algorithm is actually personalizing the treatments to its users. Due to the stochasticity in the RL algorithm, one may get a false impression that it is learning in certain states and using this learning to provide specific treatments. We use a working definition of personalization and introduce a resamp
    
[^115]: 生成代理: 人类行为的交互仿真器

    Generative Agents: Interactive Simulacra of Human Behavior. (arXiv:2304.03442v1 [cs.HC])

    [http://arxiv.org/abs/2304.03442](http://arxiv.org/abs/2304.03442)

    本文介绍了一种生成代理的架构，它能够仿真出具有可信度的人类行为，填充交互式沙盒环境，为创造更加真实的人机交互体验提供了一种新的思路。

    

    可信的人类行为仿真可赋能于从沉浸式环境到人际交流排练空间到原型工具的交互式应用程序。在本文中，我们介绍了生成代理——具有可信度的人类行为仿真的计算机软件代理。生成代理会起床，做早餐，去工作；艺术家画画，作家写作；他们形成观点，互相注意，并开始交谈；他们回忆过去的日子并计划未来。为了使生成代理能够实现，我们描述了一种架构，它将大型语言模型扩展到使用自然语言存储代理的经历的完整记录，随着时间的推移综合这些记忆到更高层次的反思，以及动态检索这些记忆以规划行为。我们实例化生成代理以填充受《模拟人生》启发的交互式沙盒环境，最终用户可以使用自然语言对话系统与25个代理交互。

    Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools. In this paper, we introduce generative agents--computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architecture that extends a large language model to store a complete record of the agent's experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty five agents using natur
    
[^116]: 自监督多模态学习：一项综述

    Self-Supervised Multimodal Learning: A Survey. (arXiv:2304.01008v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2304.01008](http://arxiv.org/abs/2304.01008)

    自监督多模态学习是一项旨在解决多模态数据中的自监督学习挑战的研究方向。它通过学习来自原始多模态数据中的表示，并解决了没有标签的多模态数据学习、不同模态的融合和不对齐数据学习等问题。

    

    多模态学习旨在理解和分析来自多种模态的信息，在监督学习范式下取得了重大进展。然而，由于依赖于配对数据和昂贵的人工注释，模型的扩展性受到了限制。与此同时，鉴于野外有大规模未注释的数据可用，自监督学习成为缓解注释瓶颈的一种有吸引力的策略。自监督多模态学习（SSML）建立在这两个方向的基础上，提供了从原始多模态数据中学习的方法。在本综述中，我们全面回顾了SSML的最新进展，阐述了自监督学习在多模态数据中面临的三个主要挑战：（1）在没有标签的多模态数据中学习表示，（2）不同模态的融合，以及（3）与不对齐数据的学习。然后，我们详细介绍了这些挑战的现有解决方案。具体而言，我们考虑了（1）目标

    Multimodal learning, which aims to understand and analyze information from multiple modalities, has achieved substantial progress in the supervised regime in recent years. However, the heavy dependence on data paired with expensive human annotations impedes scaling up models. Meanwhile, given the availability of large-scale unannotated data in the wild, self-supervised learning has become an attractive strategy to alleviate the annotation bottleneck. Building on these two directions, self-supervised multimodal learning (SSML) provides ways to learn from raw multimodal data. In this survey, we provide a comprehensive review of the state-of-the-art in SSML, in which we elucidate three major challenges intrinsic to self-supervised learning with multimodal data: (1) learning representations from multimodal data without labels, (2) fusion of different modalities, and (3) learning with unaligned data. We then detail existing solutions to these challenges. Specifically, we consider (1) object
    
[^117]: 泛型源代码的神经符号执行

    Neuro-Symbolic Execution of Generic Source Code. (arXiv:2304.00989v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2304.00989](http://arxiv.org/abs/2304.00989)

    这项研究提出了一种新的神经模型，能够根据源代码执行泛型程序，并引入了神经符号执行问题。该模型能够执行Py150数据集程序，包括没有具体输入的库函数，并可以用于变量误用定位和修复。

    

    能否使用根据源代码组合而成的神经网络逐语句执行Python程序？我们提出了神经符号执行问题，并引入了神经解释（Neural Interpretation，NI），这是第一个能够按照源代码执行泛型源代码的神经模型，允许缺失定义。NI保留源代码结构，其中每个变量都有一个向量编码，每个函数执行一个神经网络。NI是一种新颖的神经计算机模型，具有编译器架构，可以组装由源代码“编程”的神经层。NI是第一个能够执行Py150数据集程序的神经模型，包括没有具体输入的库函数，并且可以根据灵活的代码理解目标进行训练。我们展示了针对变量误用定位和修复的无具体输入的白盒执行。

    Can a Python program be executed statement-by-statement by neural networks composed according to the source code? We formulate the Neuro-Symbolic Execution Problem and introduce Neural Interpretation (NI), the first neural model for the execution of generic source code that allows missing definitions. NI preserves source code structure, where every variable has a vector encoding, and every function executes a neural network. NI is a novel neural model of computers with a compiler architecture that can assemble neural layers "programmed" by source code. NI is the first neural model capable of executing Py150 dataset programs, including library functions without concrete inputs, and it can be trained with flexible code understanding objectives. We demonstrate white-box execution without concrete inputs for variable misuse localization and repair.
    
[^118]: MAHALO: 统一离线强化学习和基于观测的模仿学习

    MAHALO: Unifying Offline Reinforcement Learning and Imitation Learning from Observations. (arXiv:2303.17156v1 [cs.LG])

    [http://arxiv.org/abs/2303.17156](http://arxiv.org/abs/2303.17156)

    本文提出了一种名为MAHALO的方法，可以统一离线强化学习和基于观测的模仿学习，帮助处理数据集质量不佳的情况下的顺序决策制定问题，并在实验中证明了其有效性。

    

    本文研究了一种名为离线观测学习（PLfO）的新的顺序决策制定范例。离线PLfO旨在使用质量不佳的数据集来学习策略：1）仅有一部分轨迹被标记为奖励，2）标记轨迹可能不包含动作，3）标记轨迹可能质量不高，4）总体数据可能不具备全面性。这些缺陷在真实的学习场景中很常见，因此离线PLfO包括许多现有的离线学习设置，包括离线模仿学习（IL），ILfO和强化学习（RL）。在本文中，我们提出了一种名为模态不可知对抗假设适应学习的离线PLfO的通用方法（MAHALO）。 MAHALO基于离线RL中的悲观主义概念，使用考虑由于数据集不足的不确定性的性能下界来优化策略。我们通过对有关观察和动作模态的有限假设进行对抗变换来实现这一想法。实验结果表明，MAHALO在各种离线PLfO任务上都很有效。

    We study a new paradigm for sequential decision making, called offline Policy Learning from Observation (PLfO). Offline PLfO aims to learn policies using datasets with substandard qualities: 1) only a subset of trajectories is labeled with rewards, 2) labeled trajectories may not contain actions, 3) labeled trajectories may not be of high quality, and 4) the overall data may not have full coverage. Such imperfection is common in real-world learning scenarios, so offline PLfO encompasses many existing offline learning setups, including offline imitation learning (IL), ILfO, and reinforcement learning (RL). In this work, we present a generic approach, called Modality-agnostic Adversarial Hypothesis Adaptation for Learning from Observations (MAHALO), for offline PLfO. Built upon the pessimism concept in offline RL, MAHALO optimizes the policy using a performance lower bound that accounts for uncertainty due to the dataset's insufficient converge. We implement this idea by adversarially tr
    
[^119]: 使用少量特征实现可解释的图像分类

    Take 5: Interpretable Image Classification with a Handful of Features. (arXiv:2303.13166v1 [cs.CV])

    [http://arxiv.org/abs/2303.13166](http://arxiv.org/abs/2303.13166)

    人们常常无法理解深度学习模型的决策过程，我们提出了一种Sparse Low-Dimensional Decision模型，它只使用一小部分可解释的特征进行决策，这使得该模型更容易被人理解，同时也具有与其他密集高维模型相似的准确性。

    

    深度神经网络使用数千个大多不可理解的特征来识别单个类别，这是任何人都无法理解的决策。我们提出了在深度神经网络中采用可解释的稀疏低维决策层，能够量化可解释性，具有可解释性，并在细颗粒度图像分类中进行了演示。我们认为，只有当特征是可解释的，并且只有极少量的特征用于单个决策时，人才能理解机器学习模型的决策。为此，最后一层必须是稀疏且维数较低的。我们将具有稀疏低维决策的模型称为Sparse Low-Dimensional Decision（SLDD）模型。我们展示了，相比密集高维决策层，SLDD模型在本地和全局上更容易解释，并能够保持竞争性准确性。此外，我们提出了一种可以提高模型特征多样性和准确性的损失函数。

    Deep Neural Networks use thousands of mostly incomprehensible features to identify a single class, a decision no human can follow. We propose an interpretable sparse and low dimensional final decision layer in a deep neural network with measurable aspects of interpretability and demonstrate it on fine-grained image classification. We argue that a human can only understand the decision of a machine learning model, if the features are interpretable and only very few of them are used for a single decision. For that matter, the final layer has to be sparse and, to make interpreting the features feasible, low dimensional. We call a model with a Sparse Low-Dimensional Decision SLDD-Model. We show that a SLDD-Model is easier to interpret locally and globally than a dense high-dimensional decision layer while being able to maintain competitive accuracy. Additionally, we propose a loss function that improves a model's feature diversity and accuracy. Our more interpretable SLDD-Model only uses 5
    
[^120]: 智能化的民主化：多种含义、目标和方法

    Democratising AI: Multiple Meanings, Goals, and Methods. (arXiv:2303.12642v1 [cs.AI])

    [http://arxiv.org/abs/2303.12642](http://arxiv.org/abs/2303.12642)

    这篇论文探讨了AI的民主化，包括四种类型的民主化：AI使用的民主化，AI开发的民主化，AI利润的民主化，和AI治理的民主化。要想实现有效的政策和权衡讨论，需要认识到AI治理的民主化在决策中扮演着重要的角色。

    

    许多人呼吁实现AI的民主化，但这个词语用来指代多种目标，有时会相互冲突。本文确定了通常讨论的四种AI民主化类型：(1) AI使用的民主化，(2) AI开发的民主化，(3) AI利润的民主化，和(4) AI治理的民主化。本文讨论了实现每种民主化形式的多个目标和方法。从本文中主要得出的结论是，AI的民主化是一个多元而有时会相互冲突的概念，不应混淆AI可访问性的改善。如果我们想要超越对智能化民主化的模糊承诺，进入具体政策和权衡的生产性讨论，我们需要认识到AI治理的民主化在跨越关于使用、开发和利润的决策中导航权衡和风险的主要作用。

    Numerous parties are calling for the democratisation of AI, but the phrase is used to refer to a variety of goals, the pursuit of which sometimes conflict. This paper identifies four kinds of AI democratisation that are commonly discussed: (1) the democratisation of AI use, (2) the democratisation of AI development, (3) the democratisation of AI profits, and (4) the democratisation of AI governance. Numerous goals and methods of achieving each form of democratisation are discussed. The main takeaway from this paper is that AI democratisation is a multifarious and sometimes conflicting concept that should not be conflated with improving AI accessibility. If we want to move beyond ambiguous commitments to democratising AI, to productive discussions of concrete policies and trade-offs, then we need to recognise the principal role of the democratisation of AI governance in navigating tradeoffs and risks across decisions around use, development, and profits.
    
[^121]: 延迟感知的分层联邦学习

    Delay-Aware Hierarchical Federated Learning. (arXiv:2303.12414v1 [cs.LG])

    [http://arxiv.org/abs/2303.12414](http://arxiv.org/abs/2303.12414)

    本论文提出了延迟感知的联邦学习(DFL)，通过解决边缘和云之间的通信延迟，提高了分布式机器学习模型训练的效率，并实现了一些政策以减少能量消耗和边缘到云端的通信。

    

    联邦学习作为一种在分布式环境下训练模型的方法，已经越来越受到关注。本文引入了延迟感知的联邦学习(DFL)，通过解决边缘和云之间的通信延迟，提高了分布式机器学习模型训练的效率。DFL在每个全局聚合间隔期间对设备数据集执行多个随机梯度下降迭代，并通过边缘服务器在本地子网络中间断地聚合模型参数。云服务器通过局部-全局合并器将本地模型与全局部署模型同步。DFL的收敛行为在广义数据异质性度量下进行了理论研究。得出了一组条件，以实现O(1/k)的次线性收敛率。基于这些发现，开发了一个自适应控制算法来实现DFL，并实现了一些政策以减少能量消耗和边缘到云端的通信。

    Federated learning has gained popularity as a means of training models distributed across the wireless edge. The paper introduces delay-aware federated learning (DFL) to improve the efficiency of distributed machine learning (ML) model training by addressing communication delays between edge and cloud. DFL employs multiple stochastic gradient descent iterations on device datasets during each global aggregation interval and intermittently aggregates model parameters through edge servers in local subnetworks. The cloud server synchronizes the local models with the global deployed model computed via a local-global combiner at global synchronization. The convergence behavior of DFL is theoretically investigated under a generalized data heterogeneity metric. A set of conditions is obtained to achieve the sub-linear convergence rate of O(1/k). Based on these findings, an adaptive control algorithm is developed for DFL, implementing policies to mitigate energy consumption and edge-to-cloud co
    
[^122]: 动态感知损失函数用于标签噪声学习

    Dynamic-Aware Loss for Learning with Label Noise. (arXiv:2303.11562v1 [cs.LG])

    [http://arxiv.org/abs/2303.11562](http://arxiv.org/abs/2303.11562)

    本文提出一种动态感知损失函数，采用增强拟合能力，逐渐增加鲁棒性的权重来处理标签噪声。在后期阶段，引入自举项，让DNN更加重视容易的样例，证明了这种方法的优越性。

    

    标签噪声对深度神经网络(DNN)构成严重威胁。使用既能拟合又具有鲁棒性的强健损失函数是处理此问题的一种简单而有效的策略。然而，这两个因素之间的静态权衡与DNN学习标签噪声的动态性相矛盾，导致性能不佳。因此，我们提出动态感知损失(DAL)来解决这个问题。考虑到DNN倾向于先学习一般化的模式，然后逐渐过拟合标签噪声，DAL最初增强了拟合能力，然后逐渐增加了鲁棒性的权重。此外，在后期阶段，我们让DNN更加重视容易的样例，这些样例更容易标记为正确的标签，并引入自举项来进一步减少标签噪声的负面影响。详细的理论分析和广泛的实验结果都证明了我们方法的优越性。

    Label noise poses a serious threat to deep neural networks (DNNs). Employing robust loss function which reconciles fitting ability with robustness is a simple but effective strategy to handle this problem. However, the widely-used static trade-off between these two factors contradicts the dynamic nature of DNNs learning with label noise, leading to inferior performance. Therefore, we propose a dynamics-aware loss (DAL) to solve this problem. Considering that DNNs tend to first learn generalized patterns, then gradually overfit label noise, DAL strengthens the fitting ability initially, then gradually increases the weight of robustness. Moreover, at the later stage, we let DNNs put more emphasis on easy examples which are more likely to be correctly labeled than hard ones and introduce a bootstrapping term to further reduce the negative impact of label noise. Both the detailed theoretical analyses and extensive experimental results demonstrate the superiority of our method.
    
[^123]: eP-ALM:语言模型的高效感知增强

    eP-ALM: Efficient Perceptual Augmentation of Language Models. (arXiv:2303.11403v1 [cs.CV])

    [http://arxiv.org/abs/2303.11403](http://arxiv.org/abs/2303.11403)

    本论文提出了一种用对比学习提高语言模型的感知能力的高效方法eP-ALM，可以实现视觉感知信息和文本信息的融合，同时还能在多模态基准测试上实现最先进的结果。

    

    大型语言模型(LLM)迄今为止给世界留下了深刻印象，具有大规模模型所具有的非同寻常的能力。在视觉方面，变压器模型（即ViT）也在追随同一趋势，取得了最具挑战性的基准测试的最佳表现。随着这种单模型的丰富多样，自然会引发一个问题：我们是否需要跟随这个趋势来处理多模态任务？在这项工作中，我们提出将努力集中于现有模型的高效适应，并提出用感知来增强语言模型。现有的适应预训练模型用于视觉语言任务的方法仍然依赖于几个关键组件，从而影响了它们的效率。特别地，他们仍然训练大量的参数，依赖大规模的多模态预训练，使用在巨大的图像-文本数据集上训练的编码器（例如CLIP），并添加了显著的推理开销。此外，这些方法中的大多数关注Zero-Shot和In Context Learning，观察到两种范式之间的巨大差异。在本文中，我们介绍了eP-ALM，一种将视觉感知信息与语言模型相结合的高效方法。我们提出了一种方法，利用对比学习来实现视觉感知和文本信息的融合，具有极小的计算成本。我们的方法不需要任何新的预训练，仍然在多模态基准测试上实现了最先进的结果。

    Large Language Models (LLMs) have so far impressed the world, with unprecedented capabilities that emerge in models at large scales. On the vision side, transformer models (i.e., ViT) are following the same trend, achieving the best performance on challenging benchmarks. With the abundance of such unimodal models, a natural question arises; do we need also to follow this trend to tackle multimodal tasks? In this work, we propose to rather direct effort to efficient adaptations of existing models, and propose to augment Language Models with perception. Existing approaches for adapting pretrained models for vision-language tasks still rely on several key components that hinder their efficiency. In particular, they still train a large number of parameters, rely on large multimodal pretraining, use encoders (e.g., CLIP) trained on huge image-text datasets, and add significant inference overhead. In addition, most of these approaches have focused on Zero-Shot and In Context Learning, with l
    
[^124]: 学习奖励信息获取：正确计分规则遇到委托代理模型

    Learning to Incentivize Information Acquisition: Proper Scoring Rules Meet Principal-Agent Model. (arXiv:2303.08613v1 [cs.LG])

    [http://arxiv.org/abs/2303.08613](http://arxiv.org/abs/2303.08613)

    本文设计了一种样本高效算法，将 UCB 算法（Auer等人，2002）应用于委托代理模型的在线设置，该算法能够通过与策略代理多次互动来设计最优的计分规则，并实现良好的效果。

    

    本文研究委托代理模型中的激励信息获取问题。此问题被建模为委托方和代理方之间的 Stackelberg 博弈，其中委托人宣布了一条得分规则来指定付款，然后代理方选择最大化其自身利润和报告信息的努力水平。我们从委托方的角度研究这个问题的在线设置，即通过与策略代理多次交互来设计最优计分规则。我们设计了一种可证明的样本高效算法，将 UCB 算法 (Auer et al., 2002) 量身定制到我们的模型中，其在 T 次迭代后实现了次线性 $T^{2/3}$-遗憾。我们的算法具有对委托方最优利润进行精细估计的过程以及保守纠正方案，以确保代理方的行动得到有效激励。此外，我们的遗憾界的一个关键特征是它是渐进最小可实现的。

    We study the incentivized information acquisition problem, where a principal hires an agent to gather information on her behalf. Such a problem is modeled as a Stackelberg game between the principal and the agent, where the principal announces a scoring rule that specifies the payment, and then the agent then chooses an effort level that maximizes her own profit and reports the information. We study the online setting of such a problem from the principal's perspective, i.e., designing the optimal scoring rule by repeatedly interacting with the strategic agent. We design a provably sample efficient algorithm that tailors the UCB algorithm (Auer et al., 2002) to our model, which achieves a sublinear $T^{2/3}$-regret after $T$ iterations. Our algorithm features a delicate estimation procedure for the optimal profit of the principal, and a conservative correction scheme that ensures the desired agent's actions are incentivized. Furthermore, a key feature of our regret bound is that it is i
    
[^125]: 通过敏感性参数和代理变量限制受益和伤害的概率

    Bounding the Probabilities of Benefit and Harm Through Sensitivity Parameters and Proxies. (arXiv:2303.05396v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2303.05396](http://arxiv.org/abs/2303.05396)

    本文提出了两种方法来限制未测量混杂下的受益和伤害概率，一种是通过敏感性参数计算概率的上限或下限，另一种是利用代理变量得到更紧的界限。

    This paper presents two methods for bounding the probabilities of benefit and harm under unmeasured confounding, one is to compute the upper or lower bound of the probability through sensitivity parameters, and the other is to derive tighter bounds using a measured nondifferential proxy of the unmeasured confounder.

    我们提出了两种方法来限制未测量混杂下的受益和伤害概率。第一种方法计算任一概率的（上限或下限），作为观察数据分布和两个直观敏感性参数的函数，然后可以将其呈现给分析师作为2-D图以协助其决策。第二种方法假设存在未测量混杂因素的测量非差异代理变量（即直接效应）。使用此代理变量，可以从仅观察到的数据分布中导出比现有界限更紧的界限。

    We present two methods for bounding the probabilities of benefit and harm under unmeasured confounding. The first method computes the (upper or lower) bound of either probability as a function of the observed data distribution and two intuitive sensitivity parameters which, then, can be presented to the analyst as a 2-D plot to assist her in decision making. The second method assumes the existence of a measured nondifferential proxy (i.e., direct effect) of the unmeasured confounder. Using this proxy, tighter bounds than the existing ones can be derived from just the observed data distribution.
    
[^126]: GOATS：目标采样自适应课程强化学习用于舀取任务

    GOATS: Goal Sampling Adaptation for Scooping with Curriculum Reinforcement Learning. (arXiv:2303.05193v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2303.05193](http://arxiv.org/abs/2303.05193)

    本文提出了一种名为GOATS的方法，使用目标采样自适应课程强化学习技术，通过插值位置目标和数量目标的分布创建学习过程中的课程来解决机器人舀取任务中的位置目标和水量目标问题，取得了比基线更好的表现。

    

    本文首先使用目标条件强化学习对机器人舀取水的问题进行了阐述。由于流体的复杂动力学和实现多模式目标的需求，该任务具有特别的挑战性。政策需要成功地达到位置目标和水量目标，这导致一个庞大而复杂的目标状态空间。为了克服这些挑战，我们引入了GOATS，一种课程强化学习方法，通过插值位置目标分布和数量目标分布来创建学习过程中的课程，使用目标分解奖励公式，学习一个高效且具有通用性的机器人舀取策略。结果，我们的方法可以在仿真中表现出比基线更好的性能，分别在碗舀和桶舀任务中实现了5.46％和8.71％的误差，涵盖了1000种初始水状态的变化。

    In this work, we first formulate the problem of robotic water scooping using goal-conditioned reinforcement learning. This task is particularly challenging due to the complex dynamics of fluid and the need to achieve multi-modal goals. The policy is required to successfully reach both position goals and water amount goals, which leads to a large convoluted goal state space. To overcome these challenges, we introduce Goal Sampling Adaptation for Scooping (GOATS), a curriculum reinforcement learning method that can learn an effective and generalizable policy for robot scooping tasks. Specifically, we use a goal-factorized reward formulation and interpolate position goal distributions and amount goal distributions to create curriculum throughout the learning process. As a result, our proposed method can outperform the baselines in simulation and achieves 5.46% and 8.71% amount errors on bowl scooping and bucket scooping tasks, respectively, under 1000 variations of initial water states in
    
[^127]: 使用电流反馈学习人形机器人的双足行走

    Learning Bipedal Walking for Humanoids with Current Feedback. (arXiv:2303.03724v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2303.03724](http://arxiv.org/abs/2303.03724)

    本文提出了一种使用电流反馈来克服人形机器人中仿真到真实世界差距的方法，通过在仿真中训练模型，并利用真实机器人的电流反馈进行优化，成功实现了双足行走。

    

    最近在基于深度强化学习的技术和在仿真中进行训练方面取得的进展为开发具有鲁棒控制器的腿式机器人提供了一种新方法。然而，这些方法在真实硬件上的应用主要局限于具有直驱执行器的四足机器人和具有低齿轮传动系统的轻型双足机器人。对于真实大小的人形机器人，由于具有较大的仿真到真实世界的差距，应用较少。本文提出了一种有效克服人形机器人中由于在执行器级别上的扭矩跟踪不准确而产生的仿真到真实世界差距问题的方法。我们的关键思想是在仿真环境中通过训练策略，在人工降级的贫弱扭矩跟踪条件下利用真实机器人上的执行器电流反馈。我们的方法成功地在仿真中训练了一个统一的端到端策略，可以在真实的HRP-5P人形机器人上部署，实现双足行走。

    Recent advances in deep reinforcement learning (RL) based techniques combined with training in simulation have offered a new approach to developing robust controllers for legged robots. However, the application of such approaches to real hardware has largely been limited to quadrupedal robots with direct-drive actuators and light-weight bipedal robots with low gear-ratio transmission systems. Application to real, life-sized humanoid robots has been less common arguably due to a large sim2real gap. In this paper, we present an approach for effectively overcoming the sim2real gap issue for humanoid robots arising from inaccurate torque-tracking at the actuator level. Our key idea is to utilize the current feedback from the actuators on the real robot, after training the policy in a simulation environment artificially degraded with poor torque-tracking. Our approach successfully trains a unified, end-to-end policy in simulation that can be deployed on a real HRP-5P humanoid robot to achie
    
[^128]: 神经网络校准的期望一致性

    Expectation consistency for calibration of neural networks. (arXiv:2303.02644v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.02644](http://arxiv.org/abs/2303.02644)

    本文介绍了一种名为期望一致性（EC）的新型校准技术，该方法通过对最后一层权重进行后训练重新缩放，使平均验证置信度与平均正确标签比例相一致，在不同神经网络架构和数据集上实现了类似温度缩放（TS）的校准性能。

    

    尽管深度神经网络有着出色的性能，但已经有报道指出它们在预测置信度方面往往存在过度乐观的问题。寻找有效和高效的神经网络校准方法对于深度学习中更好地量化不确定性是一项重要的努力。在本文中，我们介绍了一种名为期望一致性（EC）的新型校准技术，它通过对最后一层权重进行后训练重新缩放，强制要求平均验证置信度与平均正确标签比例相一致。首先，我们证明了EC方法在不同神经网络架构和数据集上实现了与温度缩放（TS）相似的校准性能，同时需要类似的验证样本和计算资源。然而，我们认为EC提供了一种基于贝叶斯最优性原理（即Nishimori恒等式）的原则性方法。接下来，我们提供了一个渐近定义。

    Despite their incredible performance, it is well reported that deep neural networks tend to be overoptimistic about their prediction confidence. Finding effective and efficient calibration methods for neural networks is therefore an important endeavour towards better uncertainty quantification in deep learning. In this manuscript, we introduce a novel calibration technique named expectation consistency (EC), consisting of a post-training rescaling of the last layer weights by enforcing that the average validation confidence coincides with the average proportion of correct labels. First, we show that the EC method achieves similar calibration performance to temperature scaling (TS) across different neural network architectures and data sets, all while requiring similar validation samples and computational resources. However, we argue that EC provides a principled method grounded on a Bayesian optimality principle known as the Nishimori identity. Next, we provide an asymptotic characteri
    
[^129]: NovPhy：一个在开放世界环境中进行物理推理的测试平台

    NovPhy: A Testbed for Physical Reasoning in Open-world Environments. (arXiv:2303.01711v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.01711](http://arxiv.org/abs/2303.01711)

    NovPhy是一个为了开放世界物理推理而设计的测试平台，要求智能体在存在新颖情况的物理场景中进行推理并相应地采取行动。

    

    随着与物理环境交互的AI系统的出现，将物理推理能力融入这些AI系统越来越受关注。但仅仅具备物理推理能力是否足以在真实物理环境中运行？在现实世界中，我们经常面对之前从未遇到过的新颖情况。作为人类，我们能够成功地适应这些情况。同样，一个智能体需要具备在面对新颖情况时正常运作的能力，才能在开放世界的物理环境中有效运行。为了推动这样的AI系统的发展，我们提出了一个新的测试平台NovPhy，要求智能体在存在新颖情况的物理场景中进行推理并相应地采取行动。测试平台包括需要智能体检测和适应物理场景中的新颖情况的任务。为了创建测试平台中的任务，我们开发了八种代表不同新颖情况的创新点。

    Due to the emergence of AI systems that interact with the physical environment, there is an increased interest in incorporating physical reasoning capabilities into those AI systems. But is it enough to only have physical reasoning capabilities to operate in a real physical environment? In the real world, we constantly face novel situations we have not encountered before. As humans, we are competent at successfully adapting to those situations. Similarly, an agent needs to have the ability to function under the impact of novelties in order to properly operate in an open-world physical environment. To facilitate the development of such AI systems, we propose a new testbed, NovPhy, that requires an agent to reason about physical scenarios in the presence of novelties and take actions accordingly. The testbed consists of tasks that require agents to detect and adapt to novelties in physical scenarios. To create tasks in the testbed, we develop eight novelties representing a diverse novelt
    
[^130]: 基于全同态加密的隐私保护树型推理

    Privacy-Preserving Tree-Based Inference with Fully Homomorphic Encryption. (arXiv:2303.01254v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2303.01254](http://arxiv.org/abs/2303.01254)

    本研究介绍了一种基于全同态加密的数据隐私保护方法，能够针对加密表格数据进行任意计算，并得到了最新的解决方案，适用于一系列树型模型，包括决策树，随机森林和梯度增强树。此方法已应用在Concrete-ML开源库中，能够在准确性方面接近未受保护的版本。

    

    隐私增强技术(PETs)被提出作为一种保护数据隐私同时允许数据分析的方式。在本文中，我们关注一种强大的工具——全同态加密(FHE)，它允许对加密数据进行任意计算。我们展示了如何将FHE应用于基于树型模型的数据分析中，得到了针对加密表格数据的最新解决方案。我们证明了该方法适用于一系列树型模型，包括决策树，随机森林和梯度增强树，并已实现在Concrete-ML库中，该库在https://github.com/zama-ai/concrete-ml. 开源。通过选择一组应用案例，我们证明了我们的FHE版本在准确性方面非常接近未受保护的版本。

    Privacy enhancing technologies (PETs) have been proposed as a way to protect the privacy of data while still allowing for data analysis. In this work, we focus on Fully Homomorphic Encryption (FHE), a powerful tool that allows for arbitrary computations to be performed on encrypted data. FHE has received lots of attention in the past few years and has reached realistic execution times and correctness.  More precisely, we explain in this paper how we apply FHE to tree-based models and get state-of-the-art solutions over encrypted tabular data. We show that our method is applicable to a wide range of tree-based models, including decision trees, random forests, and gradient boosted trees, and has been implemented within the Concrete-ML library, which is open-source at https://github.com/zama-ai/concrete-ml. With a selected set of use-cases, we demonstrate that our FHE version is very close to the unprotected version in terms of accuracy.
    
[^131]: 对图卷积网络的语义后门攻击

    A semantic backdoor attack against Graph Convolutional Networks. (arXiv:2302.14353v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.14353](http://arxiv.org/abs/2302.14353)

    该论文研究了图卷积网络（GCNs）是否容易受到语义后门攻击，提出了一种针对GCNs的语义后门攻击方法（SBAG），通过在样本中的特定节点作为触发器，并注入隐藏的后门来攻击GCNs模型。

    

    图卷积网络（GCNs）在解决各种图结构相关任务（如节点分类和图分类）方面非常有效。然而，最近的研究表明，GCNs容易受到一种新型威胁，称为后门攻击。攻击者可以将隐藏的后门注入GCNs中，使得攻击模型在良性样本上表现良好，但是如果攻击者定义的触发器激活了隐藏的后门，其预测结果将被恶意地修改为攻击者指定的目标标签。本文研究了GCNs是否容易受到这种语义后门攻击，并提出了一种针对GCNs的语义后门攻击（SBAG）来揭示GCNs中存在的安全漏洞。SBAG使用样本中的某种节点作为后门触发器，并通过污染训练数据将隐藏的后门注入到GCNs模型中。

    Graph Convolutional Networks (GCNs) have been very effective in addressing the issue of various graph-structured related tasks, such as node classification and graph classification. However, recent research has shown that GCNs are vulnerable to a new type of threat called the backdoor attack, where the adversary can inject hidden backdoor into the GCNs so that the attacked model performs well on benign samples, whereas its prediction will be maliciously changed to the attacker-specified target label if the hidden backdoor is activated by the attacker-defined trigger. In this paper, we investigate whether such semantic backdoor attacks are possible for GCNs and propose a Semantic Backdoor Attack against GCNs(SBAG) under the context of graph classification to reveal the existence of this security vulnerability in GCNs. The SBAG uses a certain type of node in the samples as a backdoor trigger and injects hidden backdoor into GCNs models through poisoning training data. The backdoor will b
    
[^132]: 面向训练脉冲神经网络的内存和时间高效反向传播

    Towards Memory- and Time-Efficient Backpropagation for Training Spiking Neural Networks. (arXiv:2302.14311v3 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2302.14311](http://arxiv.org/abs/2302.14311)

    本文提出了一种空间学习通过时间（SLTT）方法以提高训练脉冲神经网络的效率。该方法忽略了不重要的路径，减少了内存开销和训练时间。

    

    脉冲神经网络（SNN）是能源高效的神经形态计算的有前途的模型。为了训练不可微分的SNN模型，通过代理梯度（SG）的时间反向传播（BPTT）方法已经取得了很高的性能。然而，这种方法在训练过程中存在较大的内存开销和训练时间。本文提出了一种空间学习通过时间（SLTT）方法，可以在与BPTT相比大大提高训练效率的同时实现高性能。首先，我们表明SNN的反向传播通过时间域对最终计算的梯度的贡献很小。因此，我们提出在反向传播过程中忽略计算图中的不重要路径。所提出的方法减少了标量乘法的数量，并实现了独立于总时间步长的小内存占用。此外，我们还提出了SLTT的一种变体SLTT-K，该方法只允许反向传播在特定时间步长上进行。

    Spiking Neural Networks (SNNs) are promising energy-efficient models for neuromorphic computing. For training the non-differentiable SNN models, the backpropagation through time (BPTT) with surrogate gradients (SG) method has achieved high performance. However, this method suffers from considerable memory cost and training time during training. In this paper, we propose the Spatial Learning Through Time (SLTT) method that can achieve high performance while greatly improving training efficiency compared with BPTT. First, we show that the backpropagation of SNNs through the temporal domain contributes just a little to the final calculated gradients. Thus, we propose to ignore the unimportant routes in the computational graph during backpropagation. The proposed method reduces the number of scalar multiplications and achieves a small memory occupation that is independent of the total time steps. Furthermore, we propose a variant of SLTT, called SLTT-K, that allows backpropagation only at 
    
[^133]: 通过结构化噪声训练神经网络提高分类和泛化能力。

    Training neural networks with structured noise improves classification and generalization. (arXiv:2302.13417v3 [cond-mat.dis-nn] UPDATED)

    [http://arxiv.org/abs/2302.13417](http://arxiv.org/abs/2302.13417)

    通过在训练数据中添加结构化噪声，可以显著提高神经网络的分类和泛化能力，并提出了一种采样策略来优于传统的训练和赫布生规则方法。

    

    噪声在学习中的积极作用是人工神经网络领域中一个已经被确认的概念，这表明甚至生物系统可能利用类似的机制来最大化性能。Gardner和合作者提出的噪声训练算法是在循环网络中注入噪声的典型示例，循环网络通常用于建模真实神经系统。我们展示了在噪声训练数据中添加结构可以显着提高算法性能，使得可以接近完美分类和最大吸引域。我们还证明了所谓的赫布生规则在噪声达到最大且数据是网络动力学的固定点时与噪声训练算法一致。最后，我们提出并实施了一种用于最佳噪声数据的采样策略，来超越噪声训练和赫布生规则的性能。

    The beneficial role of noise in learning is nowadays a consolidated concept in the field of artificial neural networks, suggesting that even biological systems might take advantage of similar mechanisms to maximize their performance. The training-with-noise algorithm proposed by Gardner and collaborators is an emblematic example of a noise injection procedure in recurrent networks, which are usually employed to model real neural systems. We show how adding structure into noisy training data can substantially improve the algorithm performance, allowing to approach perfect classification and maximal basins of attraction. We also prove that the so-called Hebbian unlearning rule coincides with the training-with-noise algorithm when noise is maximal and data are fixed points of the network dynamics. A sampling scheme for optimal noisy data is eventually proposed and implemented to outperform both the training-with-noise and the Hebbian unlearning procedures.
    
[^134]: 使用不同降维和分类技术的癫痫发作检测的经验分析

    Empirical analysis of Different Dimensionality Reduction and classification Techniques for Epileptic Seizure detection. (arXiv:2302.12012v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.12012](http://arxiv.org/abs/2302.12012)

    本研究对使用不同降维和分类技术进行癫痫发作检测进行了实证分析，通过离散小波变换和机器学习分类器，结合主成分分析、独立成分分析和线性判别分析等降维算法，选择特征来提高检测准确性。

    

    脑电图（EEG）是一种非侵入性检查，记录大脑的电活动。该检查用于帮助诊断各种脑问题。通过离散小波变换（DWT）和机器学习分类器，可以进行癫痫检测。在癫痫发作检测中，主要使用机器学习分类器和统计特征。EEG信号中的隐藏信息对于检测影响大脑的疾病很有用。有时，在时间和频率域内识别EEG的最小变化是非常困难的。DWT可以在不同频带进行信号良好的分解和特征提取。我们使用三个降维算法：主成分分析（PCA）、独立成分分析（ICA）和线性判别分析（LDA）。最后，通过融合规则选择特征。

    An Electroencephalogram (EEG) is a non-invasive exam that records the electrical activity of the brain. This exam is used to help diagnose conditions such as different brain problems. EEG signals are taken for the purpose of epilepsy detection and with Discrete Wavelet Transform (DWT) and machine learning classifier, they perform epilepsy detection. In Epilepsy seizure detection, mainly machine learning classifiers and statistical features are used. The hidden information in the EEG signal is useful for detecting diseases affecting the brain. Sometimes it is very difficult to identify the minimum changes in the EEG in the time and frequency domains purpose. The DWT can give a good decomposition of the signals in different frequency bands and feature extraction. We use the tri-dimensionality reduction algorithm.; Principal Component Analysis (PCA), Independent Component Analysis (ICA), and Linear Discriminant Analysis (LDA). Finally, features are selected by using a fusion rule and at t
    
[^135]: ASSET：在多种深度学习范式中实现鲁棒的后门数据检测

    ASSET: Robust Backdoor Data Detection Across a Multiplicity of Deep Learning Paradigms. (arXiv:2302.11408v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.11408](http://arxiv.org/abs/2302.11408)

    该论文研究了在多种深度学习范式中实现鲁棒的后门数据检测，并发现现有的检测方法在不同攻击和毒害比例下的性能变化很大，且不能应用于最新的干净标签攻击，以及自监督学习和迁移学习中性能损失较大。为此，论文提出了一种名为ASSET的新的检测方法，通过主动引导不同的模型行为来促进后门和干净样本的分离。

    

    传统上，后门数据检测是在端到端监督学习（SL）的设置中进行研究的。然而，近年来，自监督学习（SSL）和迁移学习（TL）的普及应用增加，因为它们对标注数据的需求较少。成功的后门攻击也在这些新的设置中得到了证明。然而，我们对现有检测方法在不同学习设置下的适用性缺乏深入的理解。通过评估56种攻击设置，我们发现大多数现有检测方法的性能在不同攻击和毒害比例下存在显著差异，并且在最新的干净标签攻击下全部失败。此外，当应用于SSL和TL时，它们要么变得不适用，要么遭受较大的性能损失。我们提出了一种名为Active Separation via Offset (ASSET)的新的检测方法，通过在后门和干净样本之间主动引导不同的模型行为来促进它们的分离。

    Backdoor data detection is traditionally studied in an end-to-end supervised learning (SL) setting. However, recent years have seen the proliferating adoption of self-supervised learning (SSL) and transfer learning (TL), due to their lesser need for labeled data. Successful backdoor attacks have also been demonstrated in these new settings. However, we lack a thorough understanding of the applicability of existing detection methods across a variety of learning settings. By evaluating 56 attack settings, we show that the performance of most existing detection methods varies significantly across different attacks and poison ratios, and all fail on the state-of-the-art clean-label attack. In addition, they either become inapplicable or suffer large performance losses when applied to SSL and TL. We propose a new detection method called Active Separation via Offset (ASSET), which actively induces different model behaviors between the backdoor and clean samples to promote their separation. W
    
[^136]: 扩散模型中的数据取证: 对会员隐私的系统分析

    Data Forensics in Diffusion Models: A Systematic Analysis of Membership Privacy. (arXiv:2302.07801v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.07801](http://arxiv.org/abs/2302.07801)

    本研究对扩散模型中的会员推断攻击进行了系统分析，并提出了适用于不同攻击场景的新攻击方法，取得了接近完美的攻击性能。

    

    近年来，扩散模型在图像生成领域取得了巨大的成功，成为基于人工智能的图像处理应用的最先进技术。尽管最近在扩散模型方面取得了诸多好处，但人们也担忧其潜在的滥用，尤其是在隐私侵犯和知识产权侵权方面。特别是，考虑到这些模型的真实世界应用，它们的某些独特特性为攻击提供了新的攻击面。通过对攻击向量进行深入研究，我们对扩散模型上的会员推断攻击进行了系统分析，并提出了针对每种与扩散模型相关的攻击场景的新攻击方法。我们的方法利用易得的数量并具有极高的效果，在实际场景中实现了接近完美的攻击性能（>0.9 AUCROC）。我们的广泛实验证明了我们方法的有效性。

    In recent years, diffusion models have achieved tremendous success in the field of image generation, becoming the stateof-the-art technology for AI-based image processing applications. Despite the numerous benefits brought by recent advances in diffusion models, there are also concerns about their potential misuse, specifically in terms of privacy breaches and intellectual property infringement. In particular, some of their unique characteristics open up new attack surfaces when considering the real-world deployment of such models. With a thorough investigation of the attack vectors, we develop a systematic analysis of membership inference attacks on diffusion models and propose novel attack methods tailored to each attack scenario specifically relevant to diffusion models. Our approach exploits easily obtainable quantities and is highly effective, achieving near-perfect attack performance (>0.9 AUCROC) in realistic scenarios. Our extensive experiments demonstrate the effectiveness of 
    
[^137]: 量子算法在地球观测卫星任务规划中的应用

    Quantum algorithms applied to satellite mission planning for Earth observation. (arXiv:2302.07181v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2302.07181](http://arxiv.org/abs/2302.07181)

    本文介绍了一组量子算法，用于解决地球观测卫星任务规划问题，并证明了它们在结果优于传统算法方面的优势。

    

    地球成像卫星是我们日常生活中不可或缺的一部分，能够全球追踪工业活动。应用案例涵盖许多应用领域，从天气预报到数字地图、碳足迹追踪和植被监测等。然而，存在一些限制：卫星难以制造、维护成本高且发射进入轨道困难。因此，卫星必须被有效地利用。这带来了一个挑战，即卫星任务规划问题，该问题在大规模上可能具有计算上的限制。然而，近似最优算法，如贪婪强化学习和优化算法，通常可以提供令人满意的解决方案。本文提出了一组量子算法来解决任务规划问题，并证明了它们在结果优于迄今为止实现的经典算法方面的优势。该问题被建模为在包含实际数据集的情况下最大化完成高优先级任务的数量。

    Earth imaging satellites are a crucial part of our everyday lives that enable global tracking of industrial activities. Use cases span many applications, from weather forecasting to digital maps, carbon footprint tracking, and vegetation monitoring. However, there are limitations; satellites are difficult to manufacture, expensive to maintain, and tricky to launch into orbit. Therefore, satellites must be employed efficiently. This poses a challenge known as the satellite mission planning problem, which could be computationally prohibitive to solve on large scales. However, close-to-optimal algorithms, such as greedy reinforcement learning and optimization algorithms, can often provide satisfactory resolutions. This paper introduces a set of quantum algorithms to solve the mission planning problem and demonstrate an advantage over the classical algorithms implemented thus far. The problem is formulated as maximizing the number of high-priority tasks completed on real datasets containin
    
[^138]: 联邦生存森林

    Federated Survival Forests. (arXiv:2302.02807v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.02807](http://arxiv.org/abs/2302.02807)

    这篇论文介绍了一种基于随机生存森林的联邦算法，用于处理分布式、不完整、截尾和保密的生存数据集。该方法利用联邦学习的隐私保护技术，在多个数据集上共同训练机器学习模型，从而提高生存分析应用的性能。

    

    生存分析是统计学的一个子领域，关注于对人群中特定事件发生时间建模。生存分析在医疗、工程和社会科学中有广泛的应用。然而，在实际应用中，涉及到分布式、不完整、截尾和保密的生存数据集。在这个背景下，联邦学习可以极大地提高生存分析应用的性能。联邦学习提供了一组隐私保护技术，可以在多个数据集上共同训练机器学习模型，而不损害用户隐私，从而获得更好的泛化性能。然而，尽管近年来联邦学习在人工智能研究中得到了广泛的发展，但很少有研究集中在联邦生存分析上。在这项工作中，我们提出了一种基于最成功的生存模型之一——随机生存森林的联邦算法。

    Survival analysis is a subfield of statistics concerned with modeling the occurrence time of a particular event of interest for a population. Survival analysis found widespread applications in healthcare, engineering, and social sciences. However, real-world applications involve survival datasets that are distributed, incomplete, censored, and confidential. In this context, federated learning can tremendously improve the performance of survival analysis applications. Federated learning provides a set of privacy-preserving techniques to jointly train machine learning models on multiple datasets without compromising user privacy, leading to a better generalization performance. However, despite the widespread development of federated learning in recent AI research, few studies focus on federated survival analysis. In this work, we present a novel federated algorithm for survival analysis based on one of the most successful survival models, the random survival forest. We call the proposed 
    
[^139]: 关于筛选分类器的组内公平性

    On the Within-Group Fairness of Screening Classifiers. (arXiv:2302.00025v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.00025](http://arxiv.org/abs/2302.00025)

    本文探讨了筛选分类器的组内公平性问题，指出使用校准的分类器可能存在对感兴趣的人口群体内的合格成员存在不公平对待的问题，并提出了一种基于动态规划的高效后处理算法来最小化修改分类器，以实现组内公平性。

    

    筛选分类器越来越多地用于各种选择过程中的候选人识别。在这个背景下，最近的研究表明，如果一个分类器被校准，可以使用一个阈值决策规则识别出期望数目的合格候选人的最小集合。这支持将校准作为筛选分类器的唯一要求。本文中，我们认为使用校准的分类器的筛选策略可能存在一种鲜为人知的组内不公平类型——它们可能不公平地对待感兴趣的人口群体中的合格成员。此外，我们认为如果分类器满足组内单调性，这种不公平性可以避免，组内单调性是每个群体内的一种自然单调性属性。然后，我们介绍了一种基于动态规划的高效后处理算法，可以最小化修改给定的校准分类器，以便其概率。

    Screening classifiers are increasingly used to identify qualified candidates in a variety of selection processes. In this context, it has been recently shown that, if a classifier is calibrated, one can identify the smallest set of candidates which contains, in expectation, a desired number of qualified candidates using a threshold decision rule. This lends support to focusing on calibration as the only requirement for screening classifiers. In this paper, we argue that screening policies that use calibrated classifiers may suffer from an understudied type of within-group unfairness -- they may unfairly treat qualified members within demographic groups of interest. Further, we argue that this type of unfairness can be avoided if classifiers satisfy within-group monotonicity, a natural monotonicity property within each of the groups. Then, we introduce an efficient post-processing algorithm based on dynamic programming to minimally modify a given calibrated classifier so that its probab
    
[^140]: 四星系统并非总是嵌套的三元组：一种基于机器学习的动力学稳定性研究

    Quadruple-star systems are not always nested triples: a machine learning approach to dynamical stability. (arXiv:2301.09930v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.09930](http://arxiv.org/abs/2301.09930)

    这项研究通过机器学习算法，发现四星系统的动力学稳定性问题不总是涉及到嵌套的三元组，对于3+1的四星组合而言，采用四星模型的准确率明显优于传统的“嵌套”三元组模型。

    

    过去对于四星系统的动力学稳定性问题通常被视为涉及到构成四星的两个“嵌套”三元组的问题。在这项新颖的研究中，我们采用了一种机器学习算法——多层感知器（MLP），根据其稳定性（或长期有界性）直接对2+2和3+1的四星组合进行分类。分类的训练数据集分别由$5\times10^5$个四星组合进行模拟，模拟采用了高精度的直接$N$-body代码MSTAR。我们还进行了有限的参数空间研究，将四星组合和三元组直接进行比较。我们发现，我们的四星MLP模型比“嵌套”三元组MLP方法表现更好，对于3+1的四星组合尤为显著。2+2 MLP模型和3+1 MLP模型的分类准确率分别为94%和93%，而“嵌套”三元组方法的准确率分别为88%和66%。这对于四星系统有着重要的意义。

    The dynamical stability of quadruple-star systems has traditionally been treated as a problem involving two `nested' triples which constitute a quadruple. In this novel study, we employed a machine learning algorithm, the multi-layer perceptron (MLP), to directly classify 2+2 and 3+1 quadruples based on their stability (or long-term boundedness). The training data sets for the classification, comprised of $5\times10^5$ quadruples each, were integrated using the highly accurate direct $N$-body code MSTAR. We also carried out a limited parameter space study of zero-inclination systems to directly compare quadruples to triples. We found that both our quadruple MLP models perform better than a `nested' triple MLP approach, which is especially significant for 3+1 quadruples. The classification accuracies for the 2+2 MLP and 3+1 MLP models are 94% and 93% respectively, while the scores for the `nested' triple approach are 88% and 66% respectively. This is a crucial implication for quadruple 
    
[^141]: 选择性解释：利用人类输入对齐可解释人工智能

    Selective Explanations: Leveraging Human Input to Align Explainable AI. (arXiv:2301.09656v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.09656](http://arxiv.org/abs/2301.09656)

    本研究提出一种通过利用人类输入生成选择性解释的通用框架，以弥合可解释人工智能（XAI）与人类解释的差距，并且在决策支持任务中进行了实验证明其有效性。

    

    近年来，出现了大量的可解释人工智能（XAI）算法，但它们经常因与人类解释的生产和消费方式存在显著差距而受到批评。因此，目前的XAI技术往往难以使用并缺乏有效性。在本文中，我们尝试通过使AI解释具有选择性（这是人类解释的基本属性之一）来弥合这些差距，通过根据接收方的偏好有选择性地呈现大量模型原因的子集来实现。我们提出了一个通用的框架，通过利用小样本上的人类输入来生成选择性解释。该框架开辟了一个丰富的设计空间，涵盖了不同的选择性目标、输入类型等。作为一个展示，我们使用决策支持任务来探索基于决策者认为相关的选择性解释。我们进行了两项实验研究，以检查从大一组模型原因中选择的三个子集与未选择的子集相比，选择性解释的效果。

    While a vast collection of explainable AI (XAI) algorithms have been developed in recent years, they are often criticized for significant gaps with how humans produce and consume explanations. As a result, current XAI techniques are often found to be hard to use and lack effectiveness. In this work, we attempt to close these gaps by making AI explanations selective -- a fundamental property of human explanations -- by selectively presenting a subset from a large set of model reasons based on what aligns with the recipient's preferences. We propose a general framework for generating selective explanations by leveraging human input on a small sample. This framework opens up a rich design space that accounts for different selectivity goals, types of input, and more. As a showcase, we use a decision-support task to explore selective explanations based on what the decision-maker would consider relevant to the decision task. We conducted two experimental studies to examine three out of a bro
    
[^142]: 非线性动力系统与神经网络控制器的区间可达性

    Interval Reachability of Nonlinear Dynamical Systems with Neural Network Controllers. (arXiv:2301.07912v2 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2301.07912](http://arxiv.org/abs/2301.07912)

    本文提出了一种基于区间分析的计算高效框架，用于验证具有神经网络控制器的非线性动力系统的区间可达性。通过混合单调理论的启发，将闭环动力学嵌入到更大的系统中，这种嵌入方法在保留系统非线性结构的同时，提供了一种可扩展的安全性分析方法。采用单个轨迹计算超矩形过估计可达集，并通过分区策略优化可达集估计，实现计算效率和准确性的平衡。

    

    本文提出了一个基于区间分析的计算高效框架，用于对具有神经网络控制器的非线性连续时间动力系统进行严格验证。给定一个神经网络，我们使用现有的验证算法为其输入-输出行为构建包含函数。受到混合单调理论的启发，我们使用神经网络的包含函数和开环系统的分解函数将闭环动力学嵌入到一个更大的系统中。这种嵌入提供了一种可扩展的方法来进行神经控制回路的安全性分析，同时保留了系统的非线性结构。我们证明可以使用嵌入系统的单个轨迹有效计算可达集的超矩形过估计。我们设计了一种算法通过分区策略利用这种计算优势，改进了我们的可达集估计，同时平衡了其运行时间和可调参数。

    This paper proposes a computationally efficient framework, based on interval analysis, for rigorous verification of nonlinear continuous-time dynamical systems with neural network controllers. Given a neural network, we use an existing verification algorithm to construct inclusion functions for its input-output behavior. Inspired by mixed monotone theory, we embed the closed-loop dynamics into a larger system using an inclusion function of the neural network and a decomposition function of the open-loop system. This embedding provides a scalable approach for safety analysis of the neural control loop while preserving the nonlinear structure of the system.  We show that one can efficiently compute hyper-rectangular over-approximations of the reachable sets using a single trajectory of the embedding system. We design an algorithm to leverage this computational advantage through partitioning strategies, improving our reachable set estimates while balancing its runtime with tunable paramet
    
[^143]: 相位偏移对抗训练

    Phase-shifted Adversarial Training. (arXiv:2301.04785v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.04785](http://arxiv.org/abs/2301.04785)

    本论文通过分析响应频率的视角，发现对抗训练导致神经网络收敛性较低，从而在每个数据附近产生高度振荡的预测。为了有效地学习高频内容，提出了相位偏移对抗训练(PhaseAT)方法。

    

    对抗训练被认为是确保神经网络应用程序安全部署到现实世界的关键组成部分。现有方法主要集中在如何通过增加更新步骤的数量、使用平滑的损失函数对模型进行正则化以及将随机性注入到攻击中来生成强有力的攻击。然而，我们通过响应频率的视角分析了对抗训练的行为。我们经验性地发现，对抗训练导致神经网络对高频信息的收敛性较低，从而在每个数据附近产生高度振荡的预测。为了高效而有效地学习高频内容，我们首先证明了一个频率原理的普遍现象，即\textit{较低的频率先学习}在对抗训练中仍然成立。基于此，我们提出了相位偏移对抗训练(PhaseAT)，模型通过学习高频内容来改善对抗训练的收敛性问题。

    Adversarial training has been considered an imperative component for safely deploying neural network-based applications to the real world. To achieve stronger robustness, existing methods primarily focus on how to generate strong attacks by increasing the number of update steps, regularizing the models with the smoothed loss function, and injecting the randomness into the attack. Instead, we analyze the behavior of adversarial training through the lens of response frequency. We empirically discover that adversarial training causes neural networks to have low convergence to high-frequency information, resulting in highly oscillated predictions near each data. To learn high-frequency contents efficiently and effectively, we first prove that a universal phenomenon of frequency principle, i.e., \textit{lower frequencies are learned first}, still holds in adversarial training. Based on that, we propose phase-shifted adversarial training (PhaseAT) in which the model learns high-frequency com
    
[^144]: L-SeqSleepNet：全周期长序列建模自动睡眠分期

    L-SeqSleepNet: Whole-cycle Long Sequence Modelling for Automatic Sleep Staging. (arXiv:2301.03441v3 [eess.SP] UPDATED)

    [http://arxiv.org/abs/2301.03441](http://arxiv.org/abs/2301.03441)

    L-SeqSleepNet是一种新的深度学习模型，通过高效的长序列建模方法，考虑整个睡眠周期的信息，提高了睡眠分期的性能。

    

    人类睡眠呈周期性，大约90分钟一周期，这意味着睡眠数据中存在长期的时间依赖性。然而，在开发睡眠分期模型时，探索这种长期依赖性一直未被触及。在这项工作中，我们表明，编码整个睡眠周期的逻辑对于改进睡眠分期性能至关重要，然而，现有的最先进的深度学习模型中的顺序建模方法对此目的来说是低效的。因此，我们引入了一种高效的长序列建模方法，并提出了一种新的深度学习模型L-SeqSleepNet，该模型考虑了整个周期的睡眠信息进行睡眠分期。通过对四个不同大小的数据库进行评估，我们展示了该模型在三种不同的脑电图设置下，包括传统多导睡眠监测（PSG）中的头皮脑电图、耳内脑电图和耳后脑电图（cEEGrid），即使只有一个脑电通道输入，也能取得最先进的性能。我们的分析还表明，使用L-SeqSleepNet进行整个周期建模能够提高睡眠分期的效果。

    Human sleep is cyclical with a period of approximately 90 minutes, implying long temporal dependency in the sleep data. Yet, exploring this long-term dependency when developing sleep staging models has remained untouched. In this work, we show that while encoding the logic of a whole sleep cycle is crucial to improve sleep staging performance, the sequential modelling approach in existing state-of-the-art deep learning models are inefficient for that purpose. We thus introduce a method for efficient long sequence modelling and propose a new deep learning model, L-SeqSleepNet, which takes into account whole-cycle sleep information for sleep staging. Evaluating L-SeqSleepNet on four distinct databases of various sizes, we demonstrate state-of-the-art performance obtained by the model over three different EEG setups, including scalp EEG in conventional Polysomnography (PSG), in-ear EEG, and around-the-ear EEG (cEEGrid), even with a single EEG channel input. Our analyses also show that L-S
    
[^145]: 潜在谱规范化用于持续学习的研究

    Latent Spectral Regularization for Continual Learning. (arXiv:2301.03345v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.03345](http://arxiv.org/abs/2301.03345)

    本研究提出了一种持续谱规范化器（CaSpeR），通过对潜在空间的几何特征进行规范化，在面对不断变化的训练数据分布时改善了基于重演的持续学习方法的性能。

    

    尽管生物智能在一生中随着获取新知识的积累而有机地增长，但人工神经网络在面对不断变化的训练数据分布时容易遭受灾难性的遗忘。基于重演的持续学习（CL）方法已被证明是克服这个限制的一种多功能可靠解决方案；然而，突然的输入中断和内存限制会改变它们预测的一致性。我们通过研究学习者潜在空间的几何特征来研究这一现象，并发现重新演示的不同类别的数据点越来越混合，干扰了分类。因此，我们提出了一种几何规范化方法，它对潜在空间的拉普拉斯谱施加了较弱的要求，促进了分区行为。我们证明了我们的方法，称为持续谱规范化器（CaSpeR），可以与任何基于重演的CL方法轻松组合，并提高了SOTA方法的性能。

    While biological intelligence grows organically as new knowledge is gathered throughout life, Artificial Neural Networks forget catastrophically whenever they face a changing training data distribution. Rehearsal-based Continual Learning (CL) approaches have been established as a versatile and reliable solution to overcome this limitation; however, sudden input disruptions and memory constraints are known to alter the consistency of their predictions. We study this phenomenon by investigating the geometric characteristics of the learner's latent space and find that replayed data points of different classes increasingly mix up, interfering with classification. Hence, we propose a geometric regularizer that enforces weak requirements on the Laplacian spectrum of the latent space, promoting a partitioning behavior. We show that our proposal, called Continual Spectral Regularizer (CaSpeR), can be easily combined with any rehearsal-based CL approach and improves the performance of SOTA meth
    
[^146]: 通过超参优化方案实现自主赛车系统的模型参数识别

    Model Parameter Identification via a Hyperparameter Optimization Scheme for Autonomous Racing Systems. (arXiv:2301.01470v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2301.01470](http://arxiv.org/abs/2301.01470)

    本文提出了基于超参优化方案的模型参数识别方法（MIHO），并实现了AV-21全尺寸自主赛车的模型参数识别。MIHO收敛速度比传统方法快13倍以上，参数模型具有良好适应性和泛化能力，车辆在场地测试中达到了217公里/小时的高速行驶和稳定避障性能。

    

    本文提出了一种通过超参数优化方案（MIHO）实现模型参数识别的方法。我们采用高效的探索-利用策略来以数据驱动的方式识别动态模型的参数。我们利用MIHO进行AV-21全尺寸自主赛车的模型参数识别。我们将优化后的参数融入我们平台的基于模型的规划和控制系统的设计中。实验结果显示，MIHO的收敛速度比传统的参数识别方法快13倍以上。此外，通过MIHO学习到的参数模型表现出良好的适应性和泛化能力。我们还进行了广泛的场地测试，证明了我们基于模型的系统具有稳定的避障性能和高速行驶性能，在印第安纳波利斯车速公园和拉斯维加斯车速公园的测试中达到了217公里/小时的高速行驶。

    In this letter, we propose a model parameter identification method via a hyperparameter optimization scheme (MIHO). Our method adopts an efficient explore-exploit strategy to identify the parameters of dynamic models in a data-driven optimization manner. We utilize MIHO for model parameter identification of the AV-21, a full-scaled autonomous race vehicle. We then incorporate the optimized parameters for the design of model-based planning and control systems of our platform. In experiments, MIHO exhibits more than 13 times faster convergence than traditional parameter identification methods. Furthermore, the parametric models learned via MIHO demonstrate good fitness to the given datasets and show generalization ability in unseen dynamic scenarios. We further conduct extensive field tests to validate our model-based system, demonstrating stable obstacle avoidance and high-speed driving up to 217 km/h at the Indianapolis Motor Speedway and Las Vegas Motor Speedway. The source code for M
    
[^147]: FFNeRV：流导引的逐帧神经表示视频

    FFNeRV: Flow-Guided Frame-Wise Neural Representations for Videos. (arXiv:2212.12294v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.12294](http://arxiv.org/abs/2212.12294)

    FFNeRV是一种新颖的方法，将流信息融入帧级表示中，以利用视频中帧之间的时间冗余，并引入了完全卷积的架构。

    

    神经领域，也被称为基于坐标或隐式神经表示，展示了对各种形式信号的出色表示、生成和操作能力。然而，对于视频表示来说，将像素坐标映射到RGB颜色的压缩性能相对较低，收敛速度慢且推理速度慢。逐帧视频表示最近作为一种替代方法出现，将时间坐标映射到整个帧，提高了压缩率和编码速度。虽然有前景，但它仍然无法达到最先进的视频压缩算法的性能。在这项工作中，我们提出了FFNeRV，一种新颖的方法，将流信息融入帧级表示中，以利用视频中帧之间的时间冗余，受到标准视频编解码器的启发。此外，我们引入了一个完全卷积的架构，利用一维时间网格的能力。

    Neural fields, also known as coordinate-based or implicit neural representations, have shown a remarkable capability of representing, generating, and manipulating various forms of signals. For video representations, however, mapping pixel-wise coordinates to RGB colors has shown relatively low compression performance and slow convergence and inference speed. Frame-wise video representation, which maps a temporal coordinate to its entire frame, has recently emerged as an alternative method to represent videos, improving compression rates and encoding speed. While promising, it has still failed to reach the performance of state-of-the-art video compression algorithms. In this work, we propose FFNeRV, a novel method for incorporating flow information into frame-wise representations to exploit the temporal redundancy across the frames in videos inspired by the standard video codecs. Furthermore, we introduce a fully convolutional architecture, enabled by one-dimensional temporal grids, imp
    
[^148]: 使用语言模型提示进行推理：一项调查

    Reasoning with Language Model Prompting: A Survey. (arXiv:2212.09597v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09597](http://arxiv.org/abs/2212.09597)

    本文提供了使用语言模型提示进行推理的前沿研究综合调查。讨论了新兴推理能力出现的潜在原因，并提供系统资源帮助初学者。

    

    推理作为复杂问题解决的重要能力，可以为医疗诊断、谈判等各种实际应用提供后端支持。本文对使用语言模型提示进行推理的前沿研究进行了综合调查。我们介绍了研究成果的比较和总结，并提供了系统资源以帮助初学者。我们还讨论了新兴推理能力出现的潜在原因，并突出了未来的研究方向。资源可在 https://github.com/zjunlp/Prompt4ReasoningPapers 上获取（定期更新）。

    Reasoning, as an essential ability for complex problem-solving, can provide back-end support for various real-world applications, such as medical diagnosis, negotiation, etc. This paper provides a comprehensive survey of cutting-edge research on reasoning with language model prompting. We introduce research works with comparisons and summaries and provide systematic resources to help beginners. We also discuss the potential reasons for emerging such reasoning abilities and highlight future research directions. Resources are available at https://github.com/zjunlp/Prompt4ReasoningPapers (updated periodically).
    
[^149]: 具有谱正则化的核双样本检验

    Spectral Regularized Kernel Two-Sample Tests. (arXiv:2212.09201v2 [math.ST] UPDATED)

    [http://arxiv.org/abs/2212.09201](http://arxiv.org/abs/2212.09201)

    本文研究了基于概率分布的再生核希尔伯特空间嵌入的双样本检验的最优性。我们发现最大均值差异（MMD）检验在分离边界方面并不是最优的，因此我们提出了一种基于谱正则化的修改方法，使得检验具有更小的分离边界。同时，我们还提出了自适应版本的检验，通过数据驱动的策略选择正则化参数，展示了其近乎最优的性能。

    

    在过去的十年中，一种在非参数检验问题中广受欢迎的方法是基于概率分布的再生核希尔伯特空间（RKHS）嵌入的概念来处理一般（即非欧几里得）域上的问题。我们工作的主要目标是理解基于这种方法构建的双样本检验的最优性。首先，我们展示了流行的最大均值差异（MMD）双样本检验在Hellinger距离下的分离边界方面并不是最优的。其次，我们提出了一种基于谱正则化的MMD检验修改方法，通过考虑协方差信息（MMD检验无法捕获），证明了所提出的检验具有比MMD检验更小的分离边界的极小极大最优性。第三，我们提出了上述检验的自适应版本，其中涉及一种数据驱动策略来选择正则化参数，并展示了自适应检验几乎是最优的。

    Over the last decade, an approach that has gained a lot of popularity to tackle non-parametric testing problems on general (i.e., non-Euclidean) domains is based on the notion of reproducing kernel Hilbert space (RKHS) embedding of probability distributions. The main goal of our work is to understand the optimality of two-sample tests constructed based on this approach. First, we show that the popular MMD (maximum mean discrepancy) two-sample test is not optimal in terms of the separation boundary measured in Hellinger distance. Second, we propose a modification to the MMD test based on spectral regularization by taking into account the covariance information (which is not captured by the MMD test) and prove the proposed test to be minimax optimal with a smaller separation boundary than that achieved by the MMD test. Third, we propose an adaptive version of the above test which involves a data-driven strategy to choose the regularization parameter and show the adaptive test to be almos
    
[^150]: RepQ-ViT：基于规模重参数化实现对Vision Transformers的后训练量化

    RepQ-ViT: Scale Reparameterization for Post-Training Quantization of Vision Transformers. (arXiv:2212.08254v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.08254](http://arxiv.org/abs/2212.08254)

    本论文提出了一种基于规模重参数化的后训练量化框架RepQ-ViT，用于解决Vision Transformers在低位情况下的准确性下降问题，通过将量化和推断分开处理，实现了准确量化和高效推断。

    

    后训练量化(PTQ)是一种轻量级且实用的模型压缩技术，只需要一个小型数据集进行校准，无需进行端到端的重新训练。最近，针对Vision Transformers (ViTs) 提出了几种PTQ方案；然而，它们通常会在低位情况下出现非常严重的准确性下降。本文提出了一种基于量化规模重参数化的ViTs PTQ框架——RepQ-ViT，以解决上述问题。RepQ-ViT将量化和推断过程分开，前者采用复杂的量化器，后者采用具有规模重参数化的简化量化器。这保证了准确量化和高效推断，与现有方法不同，后者为了满足目标硬件而牺牲了量化性能。更具体地说，我们关注两个具有极端分布的组件：具有严重通道间变异的LayerNorm后激活和pos。

    Post-training quantization (PTQ), which only requires a tiny dataset for calibration without end-to-end retraining, is a light and practical model compression technique. Recently, several PTQ schemes for vision transformers (ViTs) have been presented; unfortunately, they typically suffer from non-trivial accuracy degradation, especially in low-bit cases. In this paper, we propose RepQ-ViT, a novel PTQ framework for ViTs based on quantization scale reparameterization, to address the above issues. RepQ-ViT decouples the quantization and inference processes, where the former employs complex quantizers and the latter employs scale-reparameterized simplified quantizers. This ensures both accurate quantization and efficient inference, which distinguishes it from existing approaches that sacrifice quantization performance to meet the target hardware. More specifically, we focus on two components with extreme distributions: post-LayerNorm activations with severe inter-channel variation and pos
    
[^151]: 切片最优偏转运输

    Sliced Optimal Partial Transport. (arXiv:2212.08049v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.08049](http://arxiv.org/abs/2212.08049)

    本文提出了一种适用于一维非负测度之间最优偏转运输问题的高效算法，并通过切片的方式定义了切片最优偏转运输距离。

    

    最优传输（OT）已经在机器学习、数据科学和计算机视觉中变得极其流行。OT问题的核心假设是源和目标测度的总质量相等，这限制了它的应用。最优偏转运输（OPT）是最近提出的解决这个限制的方法。与OT问题类似，OPT的计算依赖于解决线性规划问题（通常在高维度中），这可能会变得计算上困难。在本文中，我们提出了一种计算一维非负测度之间OPT问题的有效算法。接下来，遵循切片OT距离的思想，我们利用切片定义了切片OPT距离。最后，我们展示了切片OPT-based方法在各种数值实验中的计算和精度优势。特别是，我们展示了我们提出的Sliced-OPT在噪声点云配准中的应用。

    Optimal transport (OT) has become exceedingly popular in machine learning, data science, and computer vision. The core assumption in the OT problem is the equal total amount of mass in source and target measures, which limits its application. Optimal Partial Transport (OPT) is a recently proposed solution to this limitation. Similar to the OT problem, the computation of OPT relies on solving a linear programming problem (often in high dimensions), which can become computationally prohibitive. In this paper, we propose an efficient algorithm for calculating the OPT problem between two non-negative measures in one dimension. Next, following the idea of sliced OT distances, we utilize slicing to define the sliced OPT distance. Finally, we demonstrate the computational and accuracy benefits of the sliced OPT-based method in various numerical experiments. In particular, we show an application of our proposed Sliced-OPT in noisy point cloud registration.
    
[^152]: LLEDA -- 终身自助无监督域自适应

    LLEDA -- Lifelong Self-Supervised Domain Adaptation. (arXiv:2211.09027v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.09027](http://arxiv.org/abs/2211.09027)

    LLEDA是一个终身自助无监督域自适应框架，受互补学习系统（CLS）理论启发，模仿海马和新皮质之间的互动，通过潜意识回放技术实现了快速适应和渐进学习的目标。

    

    人类和动物具有终身学习的能力，不会因为学习新知识而丢失先前获得的知识。然而，人工神经网络在这方面遇到困难，因为新信息与旧知识冲突，导致灾难性遗忘。互补学习系统（CLS）理论认为，海马和新皮质系统之间的相互作用使哺乳动物大脑能够进行长期且高效的学习，内存回放助于降低遗忘。所提出的终身自助无监督域自适应（LLEDA）框架从CLS理论中获得灵感，模仿两个网络之间的互动：受海马启发的DA网络迅速适应数据分布的变化，受新皮质启发的SSL网络逐渐学习无域信息的普遍表示。LLEDA的潜意识回放技术促进了这两个系统之间的通信。

    Humans and animals have the ability to continuously learn new information over their lifetime without losing previously acquired knowledge. However, artificial neural networks struggle with this due to new information conflicting with old knowledge, resulting in catastrophic forgetting. The complementary learning systems (CLS) theory suggests that the interplay between hippocampus and neocortex systems enables long-term and efficient learning in the mammalian brain, with memory replay facilitating the interaction between these two systems to reduce forgetting. The proposed Lifelong Self-Supervised Domain Adaptation (LLEDA) framework draws inspiration from the CLS theory and mimics the interaction between two networks: a DA network inspired by the hippocampus that quickly adjusts to changes in data distribution and an SSL network inspired by the neocortex that gradually learns domain-agnostic general representations. LLEDA's latent replay technique facilitates communication between thes
    
[^153]: CaloFlow用于CaloChallenge数据集1的新方法

    CaloFlow for CaloChallenge Dataset 1. (arXiv:2210.14245v2 [physics.ins-det] UPDATED)

    [http://arxiv.org/abs/2210.14245](http://arxiv.org/abs/2210.14245)

    CaloFlow是一种新的、有前景的快速量能器模拟方法，可以比Geant4快几个数量级生成高保真度的样本。使用量能器图片、直方图和分类器证明了其样本的保真度。

    

    CaloFlow是一种基于归一化流的快速量能器模拟的新方法。将CaloFlow应用于Fast Calorimeter Simulation Challenge 2022的光子和带电π介子Geant4 shower的Dataset 1，我们展示它可以比Geant4快几个数量级产生高保真度的样本。我们使用量能器shower图像、高级特征的直方图以及分类器将CaloFlow与Geant4样本区分开来来证明样本的保真度。

    CaloFlow is a new and promising approach to fast calorimeter simulation based on normalizing flows. Applying CaloFlow to the photon and charged pion Geant4 showers of Dataset 1 of the Fast Calorimeter Simulation Challenge 2022, we show how it can produce high-fidelity samples with a sampling time that is several orders of magnitude faster than Geant4. We demonstrate the fidelity of the samples using calorimeter shower images, histograms of high-level features, and aggregate metrics such as a classifier trained to distinguish CaloFlow from Geant4 samples.
    
[^154]: MotionDeltaCNN：移动摄像机视频中稀疏CNN对帧差异的推断

    MotionDeltaCNN: Sparse CNN Inference of Frame Differences in Moving Camera Videos. (arXiv:2210.09887v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.09887](http://arxiv.org/abs/2210.09887)

    本文提出了MotionDeltaCNN，一个支持移动摄像机的稀疏CNN推断框架，通过引入球面缓冲区和填充卷积来高效融合新揭示的图像区域和已处理区域，从而实现对帧差异的推断。在移动摄像机视频中，相对于DeltaCNN，我们的方法性能提升了高达90%。

    

    在视频输入上进行卷积神经网络推断计算代价高昂，并且需要高内存带宽。最近，DeltaCNN通过仅处理与上一帧相比有显著更新的像素来减少成本。然而，DeltaCNN依赖于静态摄像机输入。移动摄像机给如何高效融合新揭示的图像区域与已处理区域带来了新的挑战，以最小化更新率 - 同时不增加内存开销且无需知道未来帧的摄像机外参数。在这项工作中，我们提出了MotionDeltaCNN，这是一个支持移动摄像机的稀疏CNN推断框架。我们引入了球面缓冲区和填充卷积，以便无缝融合新揭示的区域和以前处理的区域 - 同时不增加内存占用。我们的评估结果表明，对于移动摄像头视频，我们的性能超过DeltaCNN多达90%。

    Convolutional neural network inference on video input is computationally expensive and requires high memory bandwidth. Recently, DeltaCNN managed to reduce the cost by only processing pixels with significant updates over the previous frame. However, DeltaCNN relies on static camera input. Moving cameras add new challenges in how to fuse newly unveiled image regions with already processed regions efficiently to minimize the update rate - without increasing memory overhead and without knowing the camera extrinsics of future frames. In this work, we propose MotionDeltaCNN, a sparse CNN inference framework that supports moving cameras. We introduce spherical buffers and padded convolutions to enable seamless fusion of newly unveiled regions and previously processed regions -- without increasing memory footprint. Our evaluation shows that we outperform DeltaCNN by up to 90% for moving camera videos.
    
[^155]: 一种用于在昂贵的多模态函数中找到局部最优解的贝叶斯优化框架

    A Bayesian Optimization Framework for Finding Local Optima in Expensive Multi-Modal Functions. (arXiv:2210.06635v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2210.06635](http://arxiv.org/abs/2210.06635)

    该论文开发了一种多模态贝叶斯优化框架，用于在昂贵评估的多模态目标函数中找到一组局部和全局最优解。这使得在实际问题中可以快速切换到最优解，并获得最佳的系统性能。

    

    贝叶斯优化是一种在具有昂贵函数评估的领域中进行样本高效优化的流行全局优化方案。现有的贝叶斯优化技术能够找到单个全局最优解。然而，在许多实际问题中，找到一组全局和局部最优解是至关重要的，因为由于各种实际限制（例如资源限制、物理约束等），实施某些最优解可能是不可行的。在这种情况下，如果已知多个解，可以快速切换到另一个解，并且仍然可以获得最佳的系统性能。本文开发了一个多模态贝叶斯优化框架，有效地找到昂贵评估的多模态目标函数的一组局部/全局解。我们考虑具有高斯过程回归表示目标函数的标准贝叶斯优化设置。我们从数学上推导了联合分布。

    Bayesian optimization (BO) is a popular global optimization scheme for sample-efficient optimization in domains with expensive function evaluations. The existing BO techniques are capable of finding a single global optimum solution. However, finding a set of global and local optimum solutions is crucial in a wide range of real-world problems, as implementing some of the optimal solutions might not be feasible due to various practical restrictions (e.g., resource limitation, physical constraints, etc.). In such domains, if multiple solutions are known, the implementation can be quickly switched to another solution, and the best possible system performance can still be obtained. This paper develops a multimodal BO framework to effectively find a set of local/global solutions for expensive-to-evaluate multimodal objective functions. We consider the standard BO setting with Gaussian process regression representing the objective function. We analytically derive the joint distribution of the
    
[^156]: 流体批处理：边缘NPUs上提前退出神经网络的退出感知抢占式服务

    Fluid Batching: Exit-Aware Preemptive Serving of Early-Exit Neural Networks on Edge NPUs. (arXiv:2209.13443v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.13443](http://arxiv.org/abs/2209.13443)

    本论文提出了一种针对边缘NPUs上的提前退出神经网络进行退出感知抢占式服务的流体批处理方法。

    

    随着深度神经网络在多种计算机视觉任务中成为主干，它们在现实世界应用中的采用不断扩展。鉴于智能设备在消费领域的丰富和无处不在，正在形成“智能生态系统”，其中感知是并发进行的而不是独立进行的。这将在边缘部署中心化的神经处理单元（NPUs）的设备推理范式转向，智能家居或自动驾驶等多个设备可以流式传输数据以便使用动态速率进行处理。虽然这提供了输入批处理的增强潜力，但简单的解决方案可能导致次优的性能和体验质量，特别是在高负载下。同时，部署动态DNN，包括随机计算图（例如提前退出（EE）模型），在这类系统中引入了一维动态行为。在这项工作中，我们提出了一种新颖的提前退出感知调度算法。

    With deep neural networks (DNNs) emerging as the backbone in a multitude of computer vision tasks, their adoption in real-world applications broadens continuously. Given the abundance and omnipresence of smart devices in the consumer landscape, "smart ecosystems'' are being formed where sensing happens concurrently rather than standalone. This is shifting the on-device inference paradigm towards deploying centralised neural processing units (NPUs) at the edge, where multiple devices (e.g. in smart homes or autonomous vehicles) can stream their data for processing with dynamic rates. While this provides enhanced potential for input batching, naive solutions can lead to subpar performance and quality of experience, especially under spiking loads. At the same time, the deployment of dynamic DNNs, comprising stochastic computation graphs (e.g. early-exit (EE) models), introduces a new dimension of dynamic behaviour in such systems. In this work, we propose a novel early-exit-aware scheduli
    
[^157]: 通过虚拟光台和合成到实际适应学习对肖像图像重新照明

    Learning to Relight Portrait Images via a Virtual Light Stage and Synthetic-to-Real Adaptation. (arXiv:2209.10510v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2209.10510](http://arxiv.org/abs/2209.10510)

    这个论文提出了一种在不需要光台的情况下进行肖像图像重新照明的方法，并能够与最先进的方法相媲美。该方法基于物理原理，并能够产生高质量的结果。

    

    给定一个人的肖像图像和目标照明的环境图，肖像照明旨在重新照明图像中的人物，好像该人出现在具有目标照明的环境中。为了实现高质量的结果，最近的方法依赖于深度学习。一种有效的方法是使用具有高保真度的输入-输出配对的数据集来监督训练深度神经网络，该数据集是利用光台捕捉到的。然而，获取这样的数据需要昂贵的特殊捕捉设备和耗时的努力，限制只有少数资源丰富的实验室才能使用。为了解决这个限制，我们提出了一种新的方法，可以在不需要光台的情况下与最先进的重新照明方法相媲美。我们的方法基于一个认识，即肖像图像的成功重新照明取决于两个条件。首先，该方法需要模仿基于物理原理的重新照明的行为。其次，输出必须是照片质量的。

    Given a portrait image of a person and an environment map of the target lighting, portrait relighting aims to re-illuminate the person in the image as if the person appeared in an environment with the target lighting. To achieve high-quality results, recent methods rely on deep learning. An effective approach is to supervise the training of deep neural networks with a high-fidelity dataset of desired input-output pairs, captured with a light stage. However, acquiring such data requires an expensive special capture rig and time-consuming efforts, limiting access to only a few resourceful laboratories. To address the limitation, we propose a new approach that can perform on par with the state-of-the-art (SOTA) relighting methods without requiring a light stage. Our approach is based on the realization that a successful relighting of a portrait image depends on two conditions. First, the method needs to mimic the behaviors of physically-based relighting. Second, the output has to be photo
    
[^158]: 基于深度学习的非线性因子模型中的残差：低信噪比下资产回报的精确矩阵估计

    Deep Learning Based Residuals in Non-linear Factor Models: Precision Matrix Estimation of Returns with Low Signal-to-Noise Ratio. (arXiv:2209.04512v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2209.04512](http://arxiv.org/abs/2209.04512)

    本文介绍了在深度学习框架中使用非线性因子模型对大型投资组合中资产回报的精确矩阵进行一致估计和收敛速度。我们的方法不仅适用于金融市场典型的低信噪比环境，还与弱因子兼容，并且通过理论分析建立了统一的界限，同时提供了基于数据的一致误差协方差估计方法。模拟和实证结果显示我们的模型具有卓越的准确性。

    

    本文介绍了在深度学习框架中使用非线性因子模型对大型投资组合中资产回报的精确矩阵进行一致估计和收敛速度。我们的估计方法即使在金融市场典型的信噪比低的环境中仍然有效，并且与弱因子兼容。我们的理论分析对于不断增加的资产数量，基于深度神经网络的预期估计风险建立了统一的界限。此外，我们提供了深度神经网络中基于数据的一致误差协方差估计方法。我们的模型在广泛的模拟和实证中表现出卓越的准确性。

    This paper introduces a consistent estimator and rate of convergence for the precision matrix of asset returns in large portfolios using a non-linear factor model within the deep learning framework. Our estimator remains valid even in low signal-to-noise ratio environments typical for financial markets and is compatible with weak factors. Our theoretical analysis establishes uniform bounds on expected estimation risk based on deep neural networks for an expanding number of assets. Additionally, we provide a new consistent data-dependent estimator of error covariance in deep neural networks. Our models demonstrate superior accuracy in extensive simulations and the empirics.
    
[^159]: FedOBD：机会主义块丢弃在联邦学习中高效训练大型神经网络

    FedOBD: Opportunistic Block Dropout for Efficiently Training Large-scale Neural Networks through Federated Learning. (arXiv:2208.05174v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.05174](http://arxiv.org/abs/2208.05174)

    FedOBD是一个新的联邦学习方法，它通过将大型模型分解为语义块，允许参与者机会主义地上传量化的块来进行聚合，以此解决了在大规模联邦学习模型训练过程中操作模型参数所产生的通信开销和性能问题。

    

    大型神经网络具有相当的表达能力，非常适合行业应用中的复杂学习任务。然而，大型模型在当前的联邦学习范式下训练存在显著的挑战。现有的高效联邦学习训练方法通常利用模型参数dropout，但单独操作模型参数不仅在大规模联邦学习模型训练中无法有效减少通信开销，而且还可能对缩放和模型性能产生不利影响。为了解决这些问题，我们提出了联邦机会主义块丢弃（FedOBD）方法。其关键创新点在于将大型模型分解为语义块，以便联邦学习参与者可以机会主义地上传量化的块，这些块被认为对于训练模型非常重要，以进行聚合。通过大量的实验证明了FedOBD的有效性。

    Large-scale neural networks possess considerable expressive power. They are well-suited for complex learning tasks in industrial applications. However, large-scale models pose significant challenges for training under the current Federated Learning (FL) paradigm. Existing approaches for efficient FL training often leverage model parameter dropout. However, manipulating individual model parameters is not only inefficient in meaningfully reducing the communication overhead when training large-scale FL models, but may also be detrimental to the scaling efforts and model performance as shown by recent research. To address these issues, we propose the Federated Opportunistic Block Dropout (FedOBD) approach. The key novelty is that it decomposes large-scale models into semantic blocks so that FL participants can opportunistically upload quantized blocks, which are deemed to be significant towards training the model, to the FL server for aggregation. Extensive experiments evaluating FedOBD ag
    
[^160]: 对脑部肿瘤MRI和COVID-19胸部X-ray图像的视觉可解释和可解释深度学习模型的研究

    Visual Interpretable and Explainable Deep Learning Models for Brain Tumor MRI and COVID-19 Chest X-ray Images. (arXiv:2208.00953v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.00953](http://arxiv.org/abs/2208.00953)

    本研究通过评估归因方法，揭示深度学习模型分析医学图像的推理过程，提高了医学保健领域对深度学习的信任和可解释性。

    

    深度学习在医学图像分析方面显示出潜力，但缺乏可解释性，这阻碍了其在医疗保健领域的应用。通过解释模型推理的归因技术可能增加临床利益相关者对深度学习的信任。本文旨在评估用于揭示深度神经网络分析医学图像过程中的归因方法。使用自适应基于路径的梯度积分，我们对最近的深度卷积神经网络模型对脑部肿瘤MRI和COVID-19胸部X-ray数据集所做的预测进行了归因。该技术突出了可能的生物标志物，暴露了模型的偏差，并提供了输入与预测之间关联的见解。我们的分析证明了该方法在这些数据集上阐明模型推理能力。由此产生的归因显示了提高深度学习透明度的潜力，为领域专家揭示了预测背后的理由。本研究推进了模型可解释性的发展，以增加医学保健领域对深度学习的信任。

    Deep learning shows promise for medical image analysis but lacks interpretability, hindering adoption in healthcare. Attribution techniques that explain model reasoning may increase trust in deep learning among clinical stakeholders. This paper aimed to evaluate attribution methods for illuminating how deep neural networks analyze medical images. Using adaptive path-based gradient integration, we attributed predictions from brain tumor MRI and COVID-19 chest X-ray datasets made by recent deep convolutional neural network models. The technique highlighted possible biomarkers, exposed model biases, and offered insights into the links between input and prediction. Our analysis demonstrates the method's ability to elucidate model reasoning on these datasets. The resulting attributions show promise for improving deep learning transparency for domain experts by revealing the rationale behind predictions. This study advances model interpretability to increase trust in deep learning among heal
    
[^161]: 一种新颖的深度学习方法用于一步的符合性预测近似

    A novel Deep Learning approach for one-step Conformal Prediction approximation. (arXiv:2207.12377v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.12377](http://arxiv.org/abs/2207.12377)

    本文提出了一种新颖的深度学习方法，用于一步的符合性预测近似。通过将传统的两步符合性预测方法简化为一步，我们提出了一种新的符合性损失函数，可以在保持近似有效性和预测效率的同时，显著减少训练时间。

    

    对于现实世界的问题，特别是在高风险环境中，带有可测置信度的深度学习预测越来越受人们的欢迎。符合性预测（CP）框架是一个灵活的解决方案，可以在最小限制条件下保证最大错误率。本文提出了一种新颖的符合性损失函数，它将传统的两步CP方法近似为一步。通过评估和惩罚与严格预期的CP输出分布的偏差，深度学习模型可以学习输入数据和符合性p值之间的直接关系。我们对五个基准数据集上的七个二元和多类别预测任务进行了全面的实证评估，展示了我们的新型损失函数在训练时间减少高达86%的同时，仍保持着可比较的近似有效性和预测效率。

    Deep Learning predictions with measurable confidence are increasingly desirable for real-world problems, especially in high-risk settings. The Conformal Prediction (CP) framework is a versatile solution that guarantees a maximum error rate given minimal constraints. In this paper, we propose a novel conformal loss function that approximates the traditionally two-step CP approach in a single step. By evaluating and penalising deviations from the stringent expected CP output distribution, a Deep Learning model may learn the direct relationship between the input data and the conformal p-values. We carry out a comprehensive empirical evaluation to show our novel loss function's competitiveness for seven binary and multi-class prediction tasks on five benchmark datasets. On the same datasets, our approach achieves significant training time reductions up to 86% compared to Aggregated Conformal Prediction (ACP), while maintaining comparable approximate validity and predictive efficiency.
    
[^162]: HybMT: 基于混合元预测的机器学习算法用于快速测试向量生成

    HybMT: Hybrid Meta-Predictor based ML Algorithm for Fast Test Vector Generation. (arXiv:2207.11312v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.11312](http://arxiv.org/abs/2207.11312)

    本文提出一个基于混合元预测的机器学习算法用于快速测试向量生成，该算法通过2级预测器进一步减少了无用工作，顶层元预测器的准确率达到了99%

    

    集成电路测试是一项高度计算密集型的过程。对于现今的复杂设计，通常使用确定性测试生成（DTG）算法生成许多难以检测的故障的测试。机器学习（ML）越来越被用于增加测试覆盖率并减少总体测试时间。这些方法主要减少了传统的路径导向决策制定（PODEM）算法中的无用工作，而不会影响测试质量。对于PODEM的变体，很多时候需要回溯，因为继续执行已经无法取得进展。因此，有必要在算法执行的不同阶段预测最佳策略。本文的新贡献是一个2级预测器:顶层是一个元预测器，在较低层中选择几个预测器之一。我们选择给定电路和目标网的最佳预测器。发现顶层元预测器的准确度为99\%。这导致了

    Testing an integrated circuit (IC) is a highly compute-intensive process. For today's complex designs, tests for many hard-to-detect faults are typically generated using deterministic test generation (DTG) algorithms. Machine Learning (ML) is being increasingly used to increase the test coverage and decrease the overall testing time. Such proposals primarily reduce the wasted work in the classic Path Oriented Decision Making (PODEM) algorithm without compromising on the test quality. With variants of PODEM, many times there is a need to backtrack because further progress cannot be made. There is thus a need to predict the best strategy at different points in the execution of the algorithm. The novel contribution of this paper is a 2-level predictor: the top level is a meta predictor that chooses one of several predictors at the lower level. We choose the best predictor given a circuit and a target net. The accuracy of the top-level meta predictor was found to be 99\%. This leads to a s
    
[^163]: 使用生成对抗网络（GAN-CEST）加速和量化的三维半实心MT/CEST成像

    Accelerated and Quantitative 3D Semisolid MT/CEST Imaging using a Generative Adversarial Network (GAN-CEST). (arXiv:2207.11297v2 [physics.med-ph] UPDATED)

    [http://arxiv.org/abs/2207.11297](http://arxiv.org/abs/2207.11297)

    这项研究使用生成对抗网络（GAN-CEST）加速和量化了三维半实心MT/CEST成像，并且大大缩短了采集时间。

    

    目的：大大缩短获取量化的三维化学交换饱和转移（CEST）和半实心磁化转移（MT）成像所需的采集时间，以及实现快速的化学交换参数图重建。方法：使用3个不同位置、3个不同扫描仪型号和线圈的3T临床扫描仪，获取了L-精氨酸妖魔、整个脑部和健康志愿者、癌症患者和心脏患者的小腿肌肉的三维CEST和MT磁共振指纹（MRF）数据集。然后设计并训练了一个生成对抗网络监督框架（GAN-CEST），学习从减少的输入数据空间到量化交换参数空间的映射，同时保留感知和定量内容。结果：GAN-CEST的三维采集时间为42-52秒，比CEST-MRF缩短了70%。整个脑部的定量重建只需0.8秒。观察到了极好的一致性。

    Purpose: To substantially shorten the acquisition time required for quantitative 3D chemical exchange saturation transfer (CEST) and semisolid magnetization transfer (MT) imaging and allow for rapid chemical exchange parameter map reconstruction. Methods: Three-dimensional CEST and MT magnetic resonance fingerprinting (MRF) datasets of L-arginine phantoms, whole-brains, and calf muscles from healthy volunteers, cancer patients, and cardiac patients were acquired using 3T clinical scanners at 3 different sites, using 3 different scanner models and coils. A generative adversarial network supervised framework (GAN-CEST) was then designed and trained to learn the mapping from a reduced input data space to the quantitative exchange parameter space, while preserving perceptual and quantitative content. Results: The GAN-CEST 3D acquisition time was 42-52 seconds, 70% shorter than CEST-MRF. The quantitative reconstruction of the entire brain took 0.8 seconds. An excellent agreement was observe
    
[^164]: 变分推断中的统计和计算权衡：推理模型选择中的案例研究

    Statistical and Computational Trade-offs in Variational Inference: A Case Study in Inferential Model Selection. (arXiv:2207.11208v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2207.11208](http://arxiv.org/abs/2207.11208)

    本文通过一个推理模型选择的案例研究，研究了变分推断中的统计和计算权衡。在高斯推理模型中，我们发现，低秩推断模型在固定计算预算下产生了更高的统计近似误差，但较低的计算误差。

    

    变分推断最近在大规模贝叶斯推断中成为了传统马尔可夫链蒙特卡洛(MCMC)的热门替代方法。其核心思想是通过权衡统计准确性和计算效率。本文通过一个推理模型选择的案例研究，研究了变分推断中的统计和计算权衡。我们着重研究了具有对角加低秩精度矩阵的高斯推理模型（或变分逼近家族）中的这种权衡的两个方面：贝叶斯后验推断误差和频率主义不确定性量化误差。从贝叶斯后验推断的角度，我们表征了变分后验相对于精确后验的误差。我们证明，在固定的计算预算下，低秩推断模型产生具有更高统计逼近误差但更低计算误差的变分后验。

    Variational inference has recently emerged as a popular alternative to the classical Markov chain Monte Carlo (MCMC) in large-scale Bayesian inference. The core idea is to trade statistical accuracy for computational efficiency. In this work, we study these statistical and computational trade-offs in variational inference via a case study in inferential model selection. Focusing on Gaussian inferential models (or variational approximating families) with diagonal plus low-rank precision matrices, we initiate a theoretical study of the trade-offs in two aspects, Bayesian posterior inference error and frequentist uncertainty quantification error. From the Bayesian posterior inference perspective, we characterize the error of the variational posterior relative to the exact posterior. We prove that, given a fixed computation budget, a lower-rank inferential model produces variational posteriors with a higher statistical approximation error, but a lower computational error; it reduces varian
    
[^165]: QSAN: 一种近期可实现的量子自注意力网络

    QSAN: A Near-term Achievable Quantum Self-Attention Network. (arXiv:2207.07563v4 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2207.07563](http://arxiv.org/abs/2207.07563)

    本文提出了一种量子自注意力网络（QSAN），用于近期量子设备上的图像分类任务。该网络利用量子自注意力机制来增强数据表示能力，并设计了对应的一步实现和量子电路框架。

    

    自注意机制（SAM）擅长捕捉特征的内部连接，并极大地提高了机器学习模型的性能，尤其是对高维数据的高效特征提取和表征。本文提出了一种新型的量子自注意力网络（QSAN），用于近期量子设备上的图像分类任务。首先，探索了量子自注意力机制（QSAM），包括量子逻辑相似度（QLS）和量子位自注意力得分矩阵（QBSASM），作为QSAN的理论基础，以增强SAM的数据表示能力。QLS用于防止测量获取内积，使得QSAN能够在量子计算机上完全实现，而QBSASM作为QSAN演进的结果，产生一个能有效反映输出的注意力分布的密度矩阵。然后，设计了QSAN的一步实现和量子电路框架，充分考虑了数据压缩等因素。

    Self-Attention Mechanism (SAM) is good at capturing the internal connections of features and greatly improves the performance of machine learning models, espeacially requiring efficient characterization and feature extraction of high-dimensional data. A novel Quantum Self-Attention Network (QSAN) is proposed for image classification tasks on near-term quantum devices. First, a Quantum Self-Attention Mechanism (QSAM) including Quantum Logic Similarity (QLS) and Quantum Bit Self-Attention Score Matrix (QBSASM) is explored as the theoretical basis of QSAN to enhance the data representation of SAM. QLS is employed to prevent measurements from obtaining inner products to allow QSAN to be fully implemented on quantum computers, and QBSASM as a result of the evolution of QSAN to produce a density matrix that effectively reflects the attention distribution of the output. Then, the framework for one-step realization and quantum circuits of QSAN are designed for fully considering the compression
    
[^166]: 深度表格模型的迁移学习

    Transfer Learning with Deep Tabular Models. (arXiv:2206.15306v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.15306](http://arxiv.org/abs/2206.15306)

    深度表格模型的迁移学习在医学诊断等领域展现出了比传统方法更优异的性能，并且提出了应对上下游特征集不同情况的解决方法。

    

    最近的关于深度学习用于表格数据的研究表明，深度表格模型展现了强大的性能，通常填补了梯度提升决策树和神经网络之间的差距。除了准确性之外，神经模型的一个主要优势是它们学习了可重复使用的特征，并且在新领域中可以很容易地进行微调。这种特性在计算机视觉和自然语言应用中经常被利用，尤其是在任务特定的训练数据稀缺时，迁移学习变得不可或缺。在这项工作中，我们证明了上游数据为表格神经网络带来了比广泛使用的GBDT模型更具决定性的优势。我们提出了一个适用于表格迁移学习的现实医学诊断基准，并提供了一份使用上游数据提高各种表格神经网络架构性能的指南。最后，我们提出了一种伪特征方法，用于处理上游和下游特征集不同的情况，这是现实世界中广泛存在的表格特定问题。

    Recent work on deep learning for tabular data demonstrates the strong performance of deep tabular models, often bridging the gap between gradient boosted decision trees and neural networks. Accuracy aside, a major advantage of neural models is that they learn reusable features and are easily fine-tuned in new domains. This property is often exploited in computer vision and natural language applications, where transfer learning is indispensable when task-specific training data is scarce. In this work, we demonstrate that upstream data gives tabular neural networks a decisive advantage over widely used GBDT models. We propose a realistic medical diagnosis benchmark for tabular transfer learning, and we present a how-to guide for using upstream data to boost performance with a variety of tabular neural network architectures. Finally, we propose a pseudo-feature method for cases where the upstream and downstream feature sets differ, a tabular-specific problem widespread in real-world appli
    
[^167]: 公平感知梯度下降：FairGrad

    FairGrad: Fairness Aware Gradient Descent. (arXiv:2206.10923v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.10923](http://arxiv.org/abs/2206.10923)

    FairGrad是一种公平感知梯度下降方法，通过重新加权方案迭代学习群体特定权重来实现群体公平性。它易于实现，适用于各种标准的公平性定义，并且在各种数据集上与标准基线方法具有竞争力。

    

    本文解决了分类中的群体公平性问题，目标是学习不会不公平歧视人群子集的模型。之前的方法大多限于简单的二分类任务，或者涉及难以实现的训练机制，降低了它们的实际可应用性。本文提出了一种名为FairGrad的方法，它基于重新加权方案来强化公平性，通过迭代学习群体特定的权重，这些权重取决于是否具有优势。FairGrad易于实现，适用于各种标准的公平性定义，并且开销最小。此外，我们还展示了FairGrad在包括自然语言处理和计算机视觉在内的各种数据集上与标准基线方法具有竞争力。FairGrad可以在https://pypi.org/project/fairgrad上作为一个PyPI包获得。

    We address the problem of group fairness in classification, where the objective is to learn models that do not unjustly discriminate against subgroups of the population. Most existing approaches are limited to simple binary tasks or involve difficult to implement training mechanisms which reduces their practical applicability. In this paper, we propose FairGrad, a method to enforce fairness based on a re-weighting scheme that iteratively learns group specific weights based on whether they are advantaged or not. FairGrad is easy to implement, accommodates various standard fairness definitions, and comes with minimal overhead. Furthermore, we show that it is competitive with standard baselines over various datasets including ones used in natural language processing and computer vision.  FairGrad is available as a PyPI package at https://pypi.org/project/fairgrad
    
[^168]: CARLANE: 从模拟到多个真实世界领域的无监督域适应的车道检测基准

    CARLANE: A Lane Detection Benchmark for Unsupervised Domain Adaptation from Simulation to multiple Real-World Domains. (arXiv:2206.08083v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.08083](http://arxiv.org/abs/2206.08083)

    本论文提出了一个适用于2D车道检测的无监督域适应基准- CARLANE，包括模拟到多个真实世界领域的三个不同数据集。该基准数据集涵盖了多样的场景，并包含大量有注释的图片。此外，研究还提出了系统基准，用以评估方法的性能。

    

    无监督域适应通过将模型从有标签的源领域转移到无标签的目标领域，展示了减轻域漂移的巨大潜力。虽然无监督域适应已经应用于各种复杂的视觉任务，但只有少数工作集中在自动驾驶的车道检测上。这可以归因于缺乏公开可用的数据集。为了促进在这些方向上的研究，我们提出了CARLANE，一个适用于2D车道检测的3向模拟到真实域适应基准。CARLANE包括单目标数据集MoLane和TuLane，以及多目标数据集MuLane。这些数据集来自于三个不同的领域，涵盖了多样的场景，共包含16.3万张独特的图片，其中有11.8万张有注释。此外，我们评估和报告了系统基准，包括我们自己的方法，该方法基于原型交叉域自监督学习。我们发现评估中的误报率和漏报率

    Unsupervised Domain Adaptation demonstrates great potential to mitigate domain shifts by transferring models from labeled source domains to unlabeled target domains. While Unsupervised Domain Adaptation has been applied to a wide variety of complex vision tasks, only few works focus on lane detection for autonomous driving. This can be attributed to the lack of publicly available datasets. To facilitate research in these directions, we propose CARLANE, a 3-way sim-to-real domain adaptation benchmark for 2D lane detection. CARLANE encompasses the single-target datasets MoLane and TuLane and the multi-target dataset MuLane. These datasets are built from three different domains, which cover diverse scenes and contain a total of 163K unique images, 118K of which are annotated. In addition we evaluate and report systematic baselines, including our own method, which builds upon Prototypical Cross-domain Self-supervised Learning. We find that false positive and false negative rates of the eva
    
[^169]: 一种基于搜索的测试方法，用于深度强化学习代理

    A Search-Based Testing Approach for Deep Reinforcement Learning Agents. (arXiv:2206.07813v3 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2206.07813](http://arxiv.org/abs/2206.07813)

    本文提出一种基于搜索的测试方法，探索状态空间以检测DRL代理的安全性，并在三个基准测试中取得了比基线方法更高的状态空间覆盖率。

    

    近十年来，深度强化学习算法越来越多地被应用于解决自动驾驶和机器人等各种决策问题。然而，由于深度强化学习代理在生命安全环境中经常表现出错误行为，导致潜在的重大错误，因此它们面临着巨大的挑战。为了评估DRL代理的安全性，一种方法是对它们进行测试，以检测可能导致关键故障的故障。这就提出了一个问题，即我们如何有效地测试DRL策略，以确保它们的正确性和遵守安全要求。本文提出了一种基于搜索的测试方法，通过引导代理生成满足安全要求的状态序列变化，以探索环境的状态空间。我们的方法在三种不同的DRL基准测试中进行了评估，并在保持相似或更好的测试效果的同时，实现了比基线方法更高的状态空间覆盖率。

    Deep Reinforcement Learning (DRL) algorithms have been increasingly employed during the last decade to solve various decision-making problems such as autonomous driving and robotics. However, these algorithms have faced great challenges when deployed in safety-critical environments since they often exhibit erroneous behaviors that can lead to potentially critical errors. One way to assess the safety of DRL agents is to test them to detect possible faults leading to critical failures during their execution. This raises the question of how we can efficiently test DRL policies to ensure their correctness and adherence to safety requirements. Most existing works on testing DRL agents use adversarial attacks that perturb states or actions of the agent. However, such attacks often lead to unrealistic states of the environment. Their main goal is to test the robustness of DRL agents rather than testing the compliance of agents' policies with respect to requirements. Due to the huge state spac
    
[^170]: 非对称二分排队系统中的高效分散式多智能体学习

    Efficient decentralized multi-agent learning in asymmetric bipartite queueing systems. (arXiv:2206.03324v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.03324](http://arxiv.org/abs/2206.03324)

    该论文提出了一种简单的学习算法，使得在非对称二分排队系统中实现了高效的性能，并具备附加的鲁棒性质，并且提供了该问题的集中式情况下的首个经过证明的有效的UCB算法。

    

    我们研究了二分排队系统中的分散式多智能体学习，这是一个服务系统的标准模型。特别地，N个代理以完全分散的方式从K个服务器请求服务，即不进行通信地运行相同的算法。先前的分散式算法仅局限于对称系统，其性能随着服务器数量指数级降低，需要通过共享随机性和唯一的代理身份进行通信，且计算量巨大。相比之下，我们提供了一种简单的学习算法，当每个代理分散地运行时，在普通的非对称二分排队系统中实现了高效的性能，同时还具备附加的鲁棒性质。同时，我们为该问题的集中式情况提供了首个经过证明的有效的UCB算法。

    We study decentralized multi-agent learning in bipartite queueing systems, a standard model for service systems. In particular, N agents request service from K servers in a fully decentralized way, i.e, by running the same algorithm without communication. Previous decentralized algorithms are restricted to symmetric systems, have performance that is degrading exponentially in the number of servers, require communication through shared randomness and unique agent identities, and are computationally demanding. In contrast, we provide a simple learning algorithm that, when run decentrally by each agent, leads the queueing system to have efficient performance in general asymmetric bipartite queueing systems while also having additional robustness properties. Along the way, we provide the first provably efficient UCB-based algorithm for the centralized case of the problem.
    
[^171]: 具有基于Hessian的泛化保证的深度神经网络鲁棒微调

    Robust Fine-Tuning of Deep Neural Networks with Hessian-based Generalization Guarantees. (arXiv:2206.02659v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.02659](http://arxiv.org/abs/2206.02659)

    本文通过Hessian-based分析，提出一种基于距离的泛化度量方法，用于理解深度神经网络微调的泛化特性。通过PAC-Bayesian分析，给出了基于Hessian距离的微调模型泛化界。此外，还对微调面对标签噪声的问题进行了研究，并提出了一种相关算法和泛化误差保证。

    

    本文考虑在目标任务上对预训练的深度神经网络进行微调。我们研究微调的泛化特性，以理解过拟合问题，这在目标数据集较小或训练标签噪声时经常观察到。现有的深度网络泛化度量依赖于与微调模型的初始化（即预训练网络）距离和深度网络的噪声稳定性等概念。本文通过PAC-Bayesian分析确定了一种基于Hessian的距离度量，它与微调模型的观察到的泛化差距相关性很强。从理论上我们证明了基于Hessian距离的微调模型的泛化界。我们还对微调对抗标签噪声进行了扩展研究，过拟合是一个关键问题；我们提出了一种算法，并在类条件独立假设下给出了该算法的泛化误差保证。

    We consider fine-tuning a pretrained deep neural network on a target task. We study the generalization properties of fine-tuning to understand the problem of overfitting, which has often been observed (e.g., when the target dataset is small or when the training labels are noisy). Existing generalization measures for deep networks depend on notions such as distance from the initialization (i.e., the pretrained network) of the fine-tuned model and noise stability properties of deep networks. This paper identifies a Hessian-based distance measure through PAC-Bayesian analysis, which is shown to correlate well with observed generalization gaps of fine-tuned models. Theoretically, we prove Hessian distance-based generalization bounds for fine-tuned models. We also describe an extended study of fine-tuning against label noise, where overfitting is against a critical problem; We present an algorithm and a generalization error guarantee for this algorithm under a class conditional independent 
    
[^172]: 粗粒化状态空间网络的持续同调

    Persistent Homology of Coarse Grained State Space Networks. (arXiv:2206.02530v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2206.02530](http://arxiv.org/abs/2206.02530)

    本研究利用持续同调分析复杂过渡网络，发现粗粒化状态空间网络能够更好地捕捉底层动态系统的丰富信息，提高动态状态检测和噪声鲁棒性。

    

    本研究致力于对动态状态检测的复杂过渡网络进行拓扑分析。过渡网络由时间序列数据构成，并利用图论工具揭示底层动态系统的信息。然而，传统工具在总结这种图中的复杂拓扑时可能失败。在这项工作中，我们利用拓扑数据分析中的持续同调来研究这些网络的结构。我们将使用粗粒化状态空间网络（CGSSN）和拓扑数据分析（TDA）对时间序列进行动态状态检测与两种先进方法进行对比：使用TDA结合序数分区网络（OPNs）和将持续同调标准应用于信号的时滞嵌入。我们展示了CGSSN捕捉到底层动态系统的丰富信息，表现为动态状态检测和噪声鲁棒性显著提高。

    This work is dedicated to the topological analysis of complex transitional networks for dynamic state detection. Transitional networks are formed from time series data and they leverage graph theory tools to reveal information about the underlying dynamic system. However, traditional tools can fail to summarize the complex topology present in such graphs. In this work, we leverage persistent homology from topological data analysis to study the structure of these networks. We contrast dynamic state detection from time series using a coarse-grained state-space network (CGSSN) and topological data analysis (TDA) to two state of the art approaches: ordinal partition networks (OPNs) combined with TDA and the standard application of persistent homology to the time-delay embedding of the signal. We show that the CGSSN captures rich information about the dynamic state of the underlying dynamical system as evidenced by a significant improvement in dynamic state detection and noise robustness in
    
[^173]: 并行和分布式图神经网络：深入并发性分析

    Parallel and Distributed Graph Neural Networks: An In-Depth Concurrency Analysis. (arXiv:2205.09702v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.09702](http://arxiv.org/abs/2205.09702)

    这项研究深入分析了并行和分布式图神经网络，在设计了并行性分类方法后，研究了各种GNN模型、任务、软件框架和硬件加速器中的并行性，并重点关注相关张量的稀疏性/密度。

    

    图神经网络（GNNs）是深度学习中最强大的工具之一。它们常常在无结构网络上解决复杂问题，如节点分类、图分类或链接预测，具有高准确性。然而，GNNs的推理和训练都非常复杂，它们独特地将不规则图处理的特性与密集和规则计算相结合。这种复杂性使得在现代大规模并行架构上高效执行GNNs非常具有挑战性。为了缓解这一问题，我们首先设计了GNNs中的并行性分类方法，考虑了数据并行性和模型并行性，以及不同形式的流水线。然后，我们使用这个分类方法来研究众多GNN模型、GNN驱动的机器学习任务、软件框架或硬件加速器中的并行性。我们使用工作深度模型，并评估通信量和同步。我们特别关注相关张量的稀疏性/密度。

    Graph neural networks (GNNs) are among the most powerful tools in deep learning. They routinely solve complex problems on unstructured networks, such as node classification, graph classification, or link prediction, with high accuracy. However, both inference and training of GNNs are complex, and they uniquely combine the features of irregular graph processing with dense and regular computations. This complexity makes it very challenging to execute GNNs efficiently on modern massively parallel architectures. To alleviate this, we first design a taxonomy of parallelism in GNNs, considering data and model parallelism, and different forms of pipelining. Then, we use this taxonomy to investigate the amount of parallelism in numerous GNN models, GNN-driven machine learning tasks, software frameworks, or hardware accelerators. We use the work-depth model, and we also assess communication volume and synchronization. We specifically focus on the sparsity/density of the associated tensors, in o
    
[^174]: 变分推断用于贝叶斯桥回归

    Variational Inference for Bayesian Bridge Regression. (arXiv:2205.09515v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2205.09515](http://arxiv.org/abs/2205.09515)

    本文研究了自动微分变分推断在具有桥惩罚的回归模型上的应用，该方法通过使用小批量数据并提供全贝叶斯推断结果来加速计算时间。通过在B样条非参数回归模型上进行的模拟研究，验证了该方法的性能。

    

    我们研究了自动微分变分推断在具有桥惩罚的回归模型上的贝叶斯推断实现。桥方法使用$\ell_{\alpha}$范数，其中$\alpha \in (0, +\infty)$，对回归系数的大值进行惩罚，包括Lasso ($\alpha = 1$)和岭回归$(\alpha = 2)$惩罚作为特殊情况。全贝叶斯推断无缝地提供了所有模型参数的联合不确定性估计。尽管桥回归的MCMC方法可用，但对于大规模数据集，特别是在高维情况下，可能较慢。ADVI实现允许在每次迭代中使用小批量数据（由于基于随机梯度的算法），从而加速计算时间与MCMC相比。我们通过对B样条非参数回归模型进行了方法说明，尽管该方法对于其他基础函数的选择也可以无缝使用。模拟研究说明了方法的性能。

    We study the implementation of Automatic Differentiation Variational inference (ADVI) for Bayesian inference on regression models with bridge penalization. The bridge approach uses $\ell_{\alpha}$ norm, with $\alpha \in (0, +\infty)$ to define a penalization on large values of the regression coefficients, which includes the Lasso ($\alpha = 1$) and ridge $(\alpha = 2)$ penalizations as special cases. Full Bayesian inference seamlessly provides joint uncertainty estimates for all model parameters. Although MCMC aproaches are available for bridge regression, it can be slow for large dataset, specially in high dimensions. The ADVI implementation allows the use of small batches of data at each iteration (due to stochastic gradient based algorithms), therefore speeding up computational time in comparison with MCMC. We illustrate the approach on non-parametric regression models with B-splines, although the method works seamlessly for other choices of basis functions. A simulation study shows
    
[^175]: MM-BD: 使用最大边缘统计检测任意类型背景模式的后训练后门攻击 (arXiv:2205.06900v2 [cs.LG] 更新)

    MM-BD: Post-Training Detection of Backdoor Attacks with Arbitrary Backdoor Pattern Types Using a Maximum Margin Statistic. (arXiv:2205.06900v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.06900](http://arxiv.org/abs/2205.06900)

    本研究提出了一种后训练的后门防御方法，可以检测任意类型的后门嵌入攻击，而不需要对嵌入函数做任何假设。

    

    后门攻击是针对深度神经网络分类器的一种重要对抗威胁，当嵌入后门模式时，来自一个或多个源类的测试样本将被(误)分类为攻击者的目标类。本文聚焦于文献中常见的后训练后门防御场景，防御者的目标是在无法访问训练集的情况下检测出是否受到了后门攻击。许多后训练检测器设计用于检测使用特定的一种或少数几种后门嵌入函数的攻击 (例如，补丁替换或加法攻击)。当攻击者使用的后门嵌入函数（防御者未知）与防御者假设的后门嵌入函数不同时，这些检测器可能会失败。相比之下，我们提出了一种后训练防御方法，可以检测任意类型的后门嵌入攻击，并且不对嵌入函数做任何假设。

    Backdoor attacks are an important type of adversarial threat against deep neural network classifiers, wherein test samples from one or more source classes will be (mis)classified to the attacker's target class when a backdoor pattern is embedded. In this paper, we focus on the post-training backdoor defense scenario commonly considered in the literature, where the defender aims to detect whether a trained classifier was backdoor-attacked without any access to the training set. Many post-training detectors are designed to detect attacks that use either one or a few specific backdoor embedding functions (e.g., patch-replacement or additive attacks). These detectors may fail when the backdoor embedding function used by the attacker (unknown to the defender) is different from the backdoor embedding function assumed by the defender. In contrast, we propose a post-training defense that detects backdoor attacks with arbitrary types of backdoor embeddings, without making any assumptions about 
    
[^176]: kNN-Embed:基于局部平滑的嵌入混合用于多兴趣候选检索

    kNN-Embed: Locally Smoothed Embedding Mixtures For Multi-interest Candidate Retrieval. (arXiv:2205.06205v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2205.06205](http://arxiv.org/abs/2205.06205)

    kNN-Embed是一种用于改善密集近似最近邻检索多样性的通用方法，通过将每个用户表示为平滑混合的学习项目聚类，实现了返回反映用户多个兴趣的多样候选集合。

    

    候选检索是推荐系统中的第一阶段，它使用轻量级系统来检索与用户输入相关的潜在商品。这些候选商品随后会使用更复杂的排名模型在推荐系统的后续阶段进行排名和修剪。作为推荐漏斗的顶部，检索到一个高回忆的候选集合以输入到下游的排名模型非常重要。常见的方法是利用来自单个密集查询嵌入的近似最近邻搜索（ANN）; 然而，这种方法可能会产生具有许多近似重复项的低多样性结果集。由于用户通常具有多个兴趣，候选检索理想情况下应返回一个反映用户多个兴趣的多样的候选集合。为了实现这一目标，我们引入了kNN-Embed，一种改善密集ANN检索多样性的通用方法。kNN-Embed将每个用户表示为平滑混合的学习项目聚类，代表不同的兴趣。

    Candidate retrieval is the first stage in recommendation systems, where a light-weight system is used to retrieve potentially relevant items for an input user. These candidate items are then ranked and pruned in later stages of recommender systems using a more complex ranking model. As the top of the recommendation funnel, it is important to retrieve a high-recall candidate set to feed into downstream ranking models. A common approach is to leverage approximate nearest neighbor (ANN) search from a single dense query embedding; however, this approach this can yield a low-diversity result set with many near duplicates. As users often have multiple interests, candidate retrieval should ideally return a diverse set of candidates reflective of the user's multiple interests. To this end, we introduce kNN-Embed, a general approach to improving diversity in dense ANN-based retrieval. kNN-Embed represents each user as a smoothed mixture over learned item clusters that represent distinct "intere
    
[^177]: 核鲁棒假设检验

    Kernel Robust Hypothesis Testing. (arXiv:2203.12777v2 [eess.SP] CROSS LISTED)

    [http://arxiv.org/abs/2203.12777](http://arxiv.org/abs/2203.12777)

    本文使用核方法构造不确定性集，在贝叶斯设置和Neyman-Pearson设置中分别研究了最小化最坏情况下错误概率和控制错误概率的问题，并提出了基于MMD的一系列测试。

    

    本论文研究了鲁棒假设检验问题，在零假设和备择假设下，数据生成分布被假设在某些不确定性集合中，并旨在设计一种测试，在不确定性集合中表现最优。本文将使用核方法以数据驱动的方式构造不确定性集，即以来自零假设和备择假设的训练样本的经验分布为中心，并通过核均值嵌入的距离来约束，即最大平均差异（MMD）。同时，本文还研究了贝叶斯设置和Neyman-Pearson设置。对于贝叶斯设置，即目标是最小化最坏情况下的错误概率，当字母表是有限的时，首先得到了最佳测试。当字母表是无限的时，提出了一种可行的近似方法来量化最坏情况下的错误概率。对于Neyman-Pearson设置，即目标是在最小化第二类错误概率的同时控制在给定水平下的第一类错误概率，提出了一系列基于MMD的测试，并研究了它们的渐近特性。

    The problem of robust hypothesis testing is studied, where under the null and the alternative hypotheses, the data-generating distributions are assumed to be in some uncertainty sets, and the goal is to design a test that performs well under the worst-case distributions over the uncertainty sets. In this paper, uncertainty sets are constructed in a data-driven manner using kernel method, i.e., they are centered around empirical distributions of training samples from the null and alternative hypotheses, respectively; and are constrained via the distance between kernel mean embeddings of distributions in the reproducing kernel Hilbert space, i.e., maximum mean discrepancy (MMD). The Bayesian setting and the Neyman-Pearson setting are investigated. For the Bayesian setting where the goal is to minimize the worst-case error probability, an optimal test is firstly obtained when the alphabet is finite. When the alphabet is infinite, a tractable approximation is proposed to quantify the worst
    
[^178]: KINet：用于机器人推动操作的无监督前向模型

    KINet: Unsupervised Forward Models for Robotic Pushing Manipulation. (arXiv:2202.09006v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2202.09006](http://arxiv.org/abs/2202.09006)

    本文介绍了一种名为KINet的无监督框架，用于推理对象之间的相互作用。通过学习关键点表示和关系，该模型可以自动推广到不同场景中，并成功预测未来的关键点状态。

    

    对象为中心的表示是前向预测的重要抽象。大多数现有的前向模型通过广泛的监督学习这种表示（例如对象类别和边界框），尽管在现实中很难获得这样的真实信息。为了解决这个问题，我们引入了KINet（关键点交互网络）--一种基于关键点表示的端到端无监督框架，用于推理对象之间的相互作用。使用视觉观测，我们的模型学习将对象与关键点坐标关联起来，并发现系统的图表达，其中包括一组关键点嵌入和它们之间的关系。然后，它使用对比估计学习一个动作条件的前向模型，以预测未来的关键点状态。通过在关键点空间中学习进行物理推理，我们的模型可以自动推广到具有不同数量的对象，新颖的背景和未见过的对象几何形状的情况。实验证明了该方法的效果。

    Object-centric representation is an essential abstraction for forward prediction. Most existing forward models learn this representation through extensive supervision (e.g., object class and bounding box) although such ground-truth information is not readily accessible in reality. To address this, we introduce KINet (Keypoint Interaction Network) -- an end-to-end unsupervised framework to reason about object interactions based on a keypoint representation. Using visual observations, our model learns to associate objects with keypoint coordinates and discovers a graph representation of the system as a set of keypoint embeddings and their relations. It then learns an action-conditioned forward model using contrastive estimation to predict future keypoint states. By learning to perform physical reasoning in the keypoint space, our model automatically generalizes to scenarios with a different number of objects, novel backgrounds, and unseen object geometries. Experiments demonstrate the ef
    
[^179]: D4: 使用不相交集合共同检测对抗性扩散深度伪造图像

    D4: Detection of Adversarial Diffusion Deepfakes Using Disjoint Ensembles. (arXiv:2202.05687v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.05687](http://arxiv.org/abs/2202.05687)

    D4是一个使用不相交集合的深度伪造图像检测器，利用频域中的冗余和显著性分割技术提高对抗鲁棒性，减少了输入子空间维度，使对抗性深度伪造图像更难被发现。

    

    检测扩散生成的深度伪造图像仍然是一个尚未解决的问题。目前的检测方法无法对抗手段添加了不可察觉的对抗扰动以逃避检测的对手。在本研究中，我们提出了Disjoint Diffusion Deepfake Detection (D4)，这是一个旨在改善黑盒对抗鲁棒性的深度伪造图像检测器。D4使用一个在频谱不相交子集上的模型集合，显著提高了对抗鲁棒性。我们的关键洞察是利用频域中的冗余，并应用一个显著性分割技术将频率分量分配给多个模型。我们正式证明了这些不相交的集合导致输入子空间维度的降低，从而使黑盒攻击者更难找到对抗性的深度伪造图像。然后，我们通过实验证实了D4方法对抗多个黑盒攻击的有效性。

    Detecting diffusion-generated deepfake images remains an open problem. Current detection methods fail against an adversary who adds imperceptible adversarial perturbations to the deepfake to evade detection. In this work, we propose Disjoint Diffusion Deepfake Detection (D4), a deepfake detector designed to improve black-box adversarial robustness beyond de facto solutions such as adversarial training. D4 uses an ensemble of models over disjoint subsets of the frequency spectrum to significantly improve adversarial robustness. Our key insight is to leverage a redundancy in the frequency domain and apply a saliency partitioning technique to disjointly distribute frequency components across multiple models. We formally prove that these disjoint ensembles lead to a reduction in the dimensionality of the input subspace where adversarial deepfakes lie, thereby making adversarial deepfakes harder to find for black-box attacks. We then empirically validate the D4 method against several black-
    
[^180]: 特征和标签的机器退训练

    Machine Unlearning of Features and Labels. (arXiv:2108.11577v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2108.11577](http://arxiv.org/abs/2108.11577)

    本文提出了一种针对特征和标签的机器退训练方法，通过影响函数和模型参数的封闭形式更新，能够回溯性地调整训练数据对学习模型的影响，实现数据泄露和隐私问题的纠正。

    

    从机器学习模型中删除信息是一项非常复杂的任务，需要部分撤销训练过程。当敏感数据（如信用卡号码或密码）意外进入模型并需要之后删除时，这项任务是不可避免的。最近，已经提出了不同的机器退训练概念来解决这个问题。虽然这些方法在删除个别数据点方面是有效的，但在需要撤销较大组的特征和标签的情况下并不适用。在本文中，我们提出了第一种特征和标签的退训练方法。我们的方法基于影响函数的概念，并通过模型参数的封闭形式更新实现退训练。它能够对学习模型上的训练数据的影响进行回溯性调整，从而纠正数据泄露和隐私问题。对于具有强凸损失函数的学习模型，我们的方法提供了具有理论支持的退训练。

    Removing information from a machine learning model is a non-trivial task that requires to partially revert the training process. This task is unavoidable when sensitive data, such as credit card numbers or passwords, accidentally enter the model and need to be removed afterwards. Recently, different concepts for machine unlearning have been proposed to address this problem. While these approaches are effective in removing individual data points, they do not scale to scenarios where larger groups of features and labels need to be reverted. In this paper, we propose the first method for unlearning features and labels. Our approach builds on the concept of influence functions and realizes unlearning through closed-form updates of model parameters. It enables to adapt the influence of training data on a learning model retrospectively, thereby correcting data leaks and privacy issues. For learning models with strongly convex loss functions, our method provides certified unlearning with theo
    
[^181]: $C^3$: 用于视频对话的组合对抗对比学习

    $C^3$: Compositional Counterfactual Contrastive Learning for Video-grounded Dialogues. (arXiv:2106.08914v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2106.08914](http://arxiv.org/abs/2106.08914)

    本研究提出了一种名为$C^3$的新方法，通过对视频对话中的事实和反事实样本进行对比训练，以实现对于视频和对话上下文相关的回应生成。该方法利用了对象级或动作级的对比损失函数，旨在提高多模态推理能力和泛化能力。

    

    视频对话系统旨在将视频理解和对话理解相结合，以生成与对话和视频上下文相关的回应。大多数现有方法采用深度学习模型，在相对较小的数据集条件下取得了显著的性能。然而，这些结果部分是通过利用数据集中的偏见而非发展多模态推理实现的，从而导致了有限的泛化能力。在本文中，我们提出了一种新颖的组合对抗对比学习（$C^3$）方法，以开发视频对话中关于事实和反事实样本的对比训练。具体而言，我们设计了基于视频中的时间步长和对话中的标记的事实/反事实采样，并提出了利用对象级或动作级变化的对比损失函数。与之前的方法不同，我们集中于对比隐藏状态表示。

    Video-grounded dialogue systems aim to integrate video understanding and dialogue understanding to generate responses that are relevant to both the dialogue and video context. Most existing approaches employ deep learning models and have achieved remarkable performance, given the relatively small datasets available. However, the results are partly accomplished by exploiting biases in the datasets rather than developing multimodal reasoning, resulting in limited generalization. In this paper, we propose a novel approach of Compositional Counterfactual Contrastive Learning ($C^3$) to develop contrastive training between factual and counterfactual samples in video-grounded dialogues. Specifically, we design factual/counterfactual sampling based on the temporal steps in videos and tokens in dialogues and propose contrastive loss functions that exploit object-level or action-level variance. Different from prior approaches, we focus on contrastive hidden state representations among compositi
    
[^182]: 自然语言处理中的标记修改对抗攻击：一项调研

    Token-Modification Adversarial Attacks for Natural Language Processing: A Survey. (arXiv:2103.00676v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2103.00676](http://arxiv.org/abs/2103.00676)

    这项调研对现有的自然语言处理中的标记修改对抗攻击进行了分类和比较，并旨在指导新的研究并推动进一步的攻击组件研究。

    

    现在有很多针对自然语言处理系统的对抗攻击。其中，绝大多数攻击通过修改单个文档标记来实现成功，我们将其称为标记修改攻击。每种标记修改攻击都由一组特定的基本组件定义，例如对攻击者的约束或特定的搜索算法。基于这一观察，我们对现有的标记修改攻击进行调查，并提取每种攻击的组件。我们使用一个与攻击无关的框架来组织我们的调研，从而对该领域进行有效的分类，并方便进行组件比较。本调研旨在指导新的研究人员进入这一领域，并推动对于个体攻击组件的进一步研究。

    There are now many adversarial attacks for natural language processing systems. Of these, a vast majority achieve success by modifying individual document tokens, which we call here a token-modification attack. Each token-modification attack is defined by a specific combination of fundamental components, such as a constraint on the adversary or a particular search algorithm. Motivated by this observation, we survey existing token-modification attacks and extract the components of each. We use an attack-independent framework to structure our survey which results in an effective categorisation of the field and an easy comparison of components. This survey aims to guide new researchers to this field and spark further research into individual attack components.
    
[^183]: 懒惰型在线凸优化: 切换预算下的研究

    Lazy OCO: Online Convex Optimization on a Switching Budget. (arXiv:2102.03803v6 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2102.03803](http://arxiv.org/abs/2102.03803)

    本研究提出了一种懒惰型在线凸优化的算法，其在切换次数有限的情况下达到了近似最优的遗憾上界，并且在连续设置中呈现出高效的计算性能。

    

    我们研究了一种在线凸优化的变种，其中玩家在T轮中的期望切换决策不超过S次。之前的研究已经解决了离散决策设置中的类似问题，最近也在连续设置中使用自适应对手进行了研究。在本研究中，我们旨在填补这一空白，并在普遍存在的无知设置中提出计算有效的算法，为一般凸损失建立了O(T/S)的遗憾上界以及强凸损失的近似O(T/S^2)的遗憾上界。此外，对于随机独立同分布的损失，我们提出了一种简单的算法，在一般和强凸设置中遗憾仅有对数因子的乘法log T的情况下进行了log T次切换。最后，我们补充了与我们考虑的一些情况相匹配的下界来补充我们的算法。

    We study a variant of online convex optimization where the player is permitted to switch decisions at most $S$ times in expectation throughout $T$ rounds. Similar problems have been addressed in prior work for the discrete decision set setting, and more recently in the continuous setting but only with an adaptive adversary. In this work, we aim to fill the gap and present computationally efficient algorithms in the more prevalent oblivious setting, establishing a regret bound of $O(T/S)$ for general convex losses and $\widetilde O(T/S^2)$ for strongly convex losses. In addition, for stochastic i.i.d.~losses, we present a simple algorithm that performs $\log T$ switches with only a multiplicative $\log T$ factor overhead in its regret in both the general and strongly convex settings. Finally, we complement our algorithms with lower bounds that match our upper bounds in some of the cases we consider.
    
[^184]: 匹配市场中的赌徒：点子和对等借贷的提议

    Bandits in Matching Markets: Ideas and Proposals for Peer Lending. (arXiv:2011.04400v5 [cs.GT] UPDATED)

    [http://arxiv.org/abs/2011.04400](http://arxiv.org/abs/2011.04400)

    本文探讨了匹配市场中P2P借贷的市场设计和抽象，通过将其建模为一个优化问题，同时考虑市场两边的代理人效用和对借款人公平分配的影响。通过基于顺序决策的技术，贷款人可以根据竞争的动态调整选择，影响其投资回报。模拟实验显示贷款人的遗憾取决于初始偏好设置。

    

    在本文中，受到匹配市场中顺序决策的最新应用的启发，我们试图制定和抽象P2P借贷市场设计。我们描述了一个范式，为对等借贷从匹配市场的角度进行构想，特别是在同时尊重借款人和贷款人偏好时。我们将这些专门的市场建模为一个优化问题，并考虑市场两边的代理人的不同效用，同时理解对借款人的公平分配的影响。我们设计了一种基于顺序决策的技术，允许贷款人根据竞争的不确定性动态调整选择，这也会影响他们的投资回报。通过模拟实验，我们展示了基于最佳借款人-贷款人匹配的遗憾动态，并发现贷款人的遗憾取决于初始偏好设置。

    Motivated by recent applications of sequential decision making in matching markets, in this paper we attempt at formulating and abstracting market designs for P2P lending. We describe a paradigm to set the stage for how peer to peer investments can be conceived from a matching market perspective, especially when both borrower and lender preferences are respected. We model these specialized markets as an optimization problem and consider different utilities for agents on both sides of the market while also understanding the impact of equitable allocations to borrowers. We devise a technique based on sequential decision making that allow the lenders to adjust their choices based on the dynamics of uncertainty from competition over time and that also impacts the rewards in return for their investments. Using simulated experiments we show the dynamics of the regret based on the optimal borrower-lender matching and find that the lender regret depends on the initial preferences set by the le
    
[^185]: 具有预分配固定分类器的类增量学习

    Class-incremental Learning with Pre-allocated Fixed Classifiers. (arXiv:2010.08657v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2010.08657](http://arxiv.org/abs/2010.08657)

    本文提出了一种具有预分配固定分类器的类增量学习方法，通过利用存储在情节性记忆中的过去数据，并在学习阶段的开始就将一些预分配的输出节点纳入分类损失的计算，解决了神经网络在类增量学习中遗忘先前知识的问题。

    

    在类增量学习中，学习代理面对一系列数据的任务是学习新类别而不忘记以前的类别。神经网络在这种情况下常常会忘记先前获得的知识。为了解决这个问题，有效的方法利用存储在一个情节性记忆中的过去数据，同时扩展最终分类器节点以容纳新的类别。在这项工作中，我们用一个新颖的固定分类器替代了扩展分类器，其中一些预分配的输出节点从学习阶段开始就受到分类损失的影响。与标准扩展分类器相反，这样做有以下好处：(a)未来未见过的类别的输出节点从学习的一开始就能看到负样本，以及逐渐增加的正样本；(b)能够学习不随着新类别的加入而改变其几何配置的特征。

    In class-incremental learning, a learning agent faces a stream of data with the goal of learning new classes while not forgetting previous ones. Neural networks are known to suffer under this setting, as they forget previously acquired knowledge. To address this problem, effective methods exploit past data stored in an episodic memory while expanding the final classifier nodes to accommodate the new classes.  In this work, we substitute the expanding classifier with a novel fixed classifier in which a number of pre-allocated output nodes are subject to the classification loss right from the beginning of the learning phase. Contrarily to the standard expanding classifier, this allows: (a) the output nodes of future unseen classes to firstly see negative samples since the beginning of learning together with the positive samples that incrementally arrive; (b) to learn features that do not change their geometric configuration as novel classes are incorporated in the learning model.  Experi
    
[^186]: 在黎曼流形和欧几里德空间上的时空脑电图表示学习

    Spatio-Temporal EEG Representation Learning on Riemannian Manifold and Euclidean Space. (arXiv:2008.08633v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2008.08633](http://arxiv.org/abs/2008.08633)

    本论文提出一种新的深度神经网络架构，用于学习脑电图信号。该模型通过黎曼流形和欧几里德空间学习空间信息，并通过差分熵和对数功率谱密度特征学习时间信息。通过有效的融合策略，结合空间和时间信息来进行决策。在多个公共数据集上进行了验证。

    

    我们提出了一种用于学习脑电图(EEG)的新型深度神经网络架构。为了学习空间信息，我们的模型首先从黎曼流形上的空间协方差矩阵(Riemannian manifold)中获取黎曼平均值和距离。然后，我们通过切空间学习将空间信息投影到欧几里德空间上。接下来，我们使用两个全连接层来学习空间信息嵌入。此外，我们提出的方法通过从欧几里德空间中的EEG信号中提取差分熵和对数功率谱密度特征来学习时间信息，使用带有软注意机制的深层长短时记忆网络。为了结合空间和时间信息，我们使用了一种有效的融合策略，该策略学习将注意权重应用于特定嵌入特征以进行决策。我们在四个公共数据集上评估了我们提出的框架，涵盖了三个流行的与EEG相关的任务，特别是情绪识别、警觉性识别和睡眠呼吸暂停检测。

    We present a novel deep neural architecture for learning electroencephalogram (EEG). To learn the spatial information, our model first obtains the Riemannian mean and distance from spatial covariance matrices (SCMs) on a Riemannian manifold. We then project the spatial information onto a Euclidean space via tangent space learning. Following, two fully connected layers are used to learn the spatial information embeddings. Moreover, our proposed method learns the temporal information via differential entropy and logarithm power spectrum density features extracted from EEG signals in a Euclidean space using a deep long short-term memory network with a soft attention mechanism. To combine the spatial and temporal information, we use an effective fusion strategy, which learns attention weights applied to embedding-specific features for decision making. We evaluate our proposed framework on four public datasets across three popular EEG-related tasks, notably emotion recognition, vigilance es
    
[^187]: 使用深度学习技术自动检测和预测COVID-19：一项综述

    Automated Detection and Forecasting of COVID-19 using Deep Learning Techniques: A Review. (arXiv:2007.10785v6 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2007.10785](http://arxiv.org/abs/2007.10785)

    这项研究综述了使用深度学习技术进行COVID-19诊断和预测的研究，深度学习模型可以自动完成特征提取、特征选择和分类的所有阶段，为COVID-19的医学诊断提供了一种高性能且一致的方法。

    

    冠状病毒（或COVID-19）是一种危险的疾病，通过直接影响肺部危及全球许多人的健康。COVID-19是一种中等大小、有包被的病毒，具有单链RNA，同时也拥有最大的RNA基因组之一，大约120纳米。X射线和计算机断层扫描（CT）成像方法被广泛用于快速准确的医学诊断。从这些医学图像中识别COVID-19非常具有挑战性，因为它耗时且容易出现人为错误。因此，可以使用人工智能（AI）方法来获得一致的高性能。在AI方法中，与传统的机器学习（ML）相比，深度学习（DL）网络最近变得越来越受欢迎。与ML不同，DL模型可以自动完成特征提取、特征选择和分类的所有阶段。本文全面调查了关于使用DL技术进行COVID-19诊断和预测的研究。

    Coronavirus, or COVID-19, is a hazardous disease that has endangered the health of many people around the world by directly affecting the lungs. COVID-19 is a medium-sized, coated virus with a single-stranded RNA, and also has one of the largest RNA genomes and is approximately 120 nm. The X-Ray and computed tomography (CT) imaging modalities are widely used to obtain a fast and accurate medical diagnosis. Identifying COVID-19 from these medical images is extremely challenging as it is time-consuming and prone to human errors. Hence, artificial intelligence (AI) methodologies can be used to obtain consistent high performance. Among the AI methods, deep learning (DL) networks have gained popularity recently compared to conventional machine learning (ML). Unlike ML, all stages of feature extraction, feature selection, and classification are accomplished automatically in DL models. In this paper, a complete survey of studies on the application of DL techniques for COVID-19 diagnostic and 
    
[^188]: 在线凸优化导论

    Introduction to Online Convex Optimization. (arXiv:1909.05207v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1909.05207](http://arxiv.org/abs/1909.05207)

    本文将优化描述为一个过程，在实际应用中，采用在线学习的优化方法对复杂环境进行优化建模，并取得了引人注目的成就。

    

    本文将优化描述为一个过程。在许多实际应用中，环境太复杂，无法建立全面的理论模型并使用经典算法和数学优化。因此，采用一种学习的优化方法，在观察到问题的更多方面时通过经验进行学习是必要且有益的。将优化视为一个过程的观点在各个领域变得突出，并在建模和成为我们日常生活一部分的系统中取得了一些引人注目的成就。

    This manuscript portrays optimization as a process. In many practical applications the environment is so complex that it is infeasible to lay out a comprehensive theoretical model and use classical algorithmic theory and mathematical optimization. It is necessary as well as beneficial to take a robust approach, by applying an optimization method that learns as one goes along, learning from experience as more aspects of the problem are observed. This view of optimization as a process has become prominent in varied fields and has led to some spectacular success in modeling and systems that are now part of our daily lives.
    
[^189]: 在多个产品类别中进行消费者选择的反事实推断

    Counterfactual Inference for Consumer Choice Across Many Product Categories. (arXiv:1906.02635v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1906.02635](http://arxiv.org/abs/1906.02635)

    本文提出了一种方法用于估计消费者在多个产品类别中的偏好选择。我们利用机器学习的概率模型，考虑了时变产品属性和产品缺货的情况，并展示了我们的模型相较于传统方法的改进之处在于能够准确估计偏好的异质性。

    

    本文提出了一种用于估计离散选择中消费者偏好的方法，其中消费者在一个类别中选择至多一个产品，但在多个类别中并行选择。消费者的效用对不同类别是可加性的。她对产品属性的偏好以及她对价格的敏感度在不同产品间有所变化，并且在一般情况下在产品间是相关的。我们借鉴了机器学习文献中关于概率模型中矩阵分解的技术，将这些方法扩展到考虑时变产品属性和产品缺货的情况。我们使用含有价格变动或缺货产品的留存数据来评估模型的性能。我们展示了我们的模型相较于考虑每个类别的传统建模方法的改进。模型的改进之一是能够准确估计偏好的异质性（通过跨类别汇总信息）。

    This paper proposes a method for estimating consumer preferences among discrete choices, where the consumer chooses at most one product in a category, but selects from multiple categories in parallel. The consumer's utility is additive in the different categories. Her preferences about product attributes as well as her price sensitivity vary across products and are in general correlated across products. We build on techniques from the machine learning literature on probabilistic models of matrix factorization, extending the methods to account for time-varying product attributes and products going out of stock. We evaluate the performance of the model using held-out data from weeks with price changes or out of stock products. We show that our model improves over traditional modeling approaches that consider each category in isolation. One source of the improvement is the ability of the model to accurately estimate heterogeneity in preferences (by pooling information across categories); 
    

