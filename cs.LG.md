# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Monotone, Bi-Lipschitz, and Polyak-\L{}ojasiewicz Networks](https://rss.arxiv.org/abs/2402.01344) | 这篇论文介绍了一种新的可逆神经网络BiLipNet，它具有调控输出敏感性和输入可区分性的能力。其中的主要创新是通过认证的强单调性和Lipschitz性的可逆残差层，与正交层组合构建了Bi-Lipschitz网络。另外，该论文还提出了满足Polyak-\L{}ojasiewicz条件的PLNet，并介绍了其应用于学习非凸代理损失的优势特性。 |
| [^2] | [Bridging Dimensions: Confident Reachability for High-Dimensional Controllers](https://rss.arxiv.org/abs/2311.04843) | 本文介绍了一种连接高维控制器的详尽闭环验证方法，通过将高维控制器的行为近似为不同状态空间区域内的低维控制器，平衡了逼近精度和可验证性。 |
| [^3] | [Self-Improved Learning for Scalable Neural Combinatorial Optimization](https://arxiv.org/abs/2403.19561) | 提出一种新颖的自我改进学习(SIL)方法，实现神经组合优化的更好可扩展性，通过自身生成解决方案作为伪标签，设计线性复杂度的注意机制来处理大规模组合优化问题实例。 |
| [^4] | [Detecting Generative Parroting through Overfitting Masked Autoencoders](https://arxiv.org/abs/2403.19050) | 本研究提出利用过拟合的遮蔽自编码器(MAE)来检测生成模型中的生成性模仿，建立了基于训练数据集损失的检测阈值，为了确保生成模型的合法使用和提升其法律合规性提供了一种新方法。 |
| [^5] | [Knowledge-guided Machine Learning: Current Trends and Future Prospects](https://arxiv.org/abs/2403.15989) | 知识引导的机器学习（KGML）结合科学知识和数据在机器学习框架中，以实现更好的泛化能力、科学一致性和结果可解释性。 |
| [^6] | [Conformal online model aggregation](https://arxiv.org/abs/2403.15527) | 该论文提出了一种基于投票的在线依从模型聚合方法，可以根据过去表现调整模型权重。 |
| [^7] | [Efficient Transformer-based Hyper-parameter Optimization for Resource-constrained IoT Environments](https://arxiv.org/abs/2403.12237) | 本文提出了一种通过将Transformer架构和演员-评论家强化学习模型相结合的新方法TRL-HPO，在资源受限的IoT环境中实现了高效的超参数优化，该方法在MNIST数据集上表现优良。 |
| [^8] | [Chronos: Learning the Language of Time Series](https://arxiv.org/abs/2403.07815) | Chronos框架通过在固定词汇上训练预训练的概率时间序列模型，在大量数据集上进行了全面基准测试，表现出在训练语料库中的数据集上明显优于其他方法，并且在新数据集上的零样本性能表现可比甚至优于其他方法。 |
| [^9] | [Minimizing the Thompson Sampling Regret-to-Sigma Ratio (TS-RSR): a provably efficient algorithm for batch Bayesian Optimization](https://arxiv.org/abs/2403.04764) | 该论文提出了一种用于批量贝叶斯优化的高效算法，通过最小化Thompson抽样近似的遗憾与不确定性比率，成功协调每个批次的动作选择，同时实现高概率的理论保证，并在非凸测试函数上表现出色. |
| [^10] | [Neural Exec: Learning (and Learning from) Execution Triggers for Prompt Injection Attacks](https://arxiv.org/abs/2403.03792) | 通过学习方法生成的执行触发器可以比当前手工制作的触发器更加有效，并表现出形状、属性和功能上的固有灵活性。 |
| [^11] | [Disaggregated Multi-Tower: Topology-aware Modeling Technique for Efficient Large-Scale Recommendation](https://arxiv.org/abs/2403.00877) | Disaggregated Multi-Tower提出了一种面向拓扑感知的建模技术，通过SPTT、TM和TP三个组件实现了高效的大规模推荐，加速性能提升了1.9倍。 |
| [^12] | [Behavioral Refinement via Interpolant-based Policy Diffusion](https://arxiv.org/abs/2402.16075) | 使用比高斯更具信息量的源头启动扩散方法有助于克服模仿学习任务中的限制。 |
| [^13] | [Zero-shot generalization across architectures for visual classification](https://arxiv.org/abs/2402.14095) | 不同神经网络在跨架构和层间泛化到未知类别的能力存在差异，准确性并不是泛化能力的良好预测因子，泛化能力随着层深度呈非单调变化。 |
| [^14] | [SimPro: A Simple Probabilistic Framework Towards Realistic Long-Tailed Semi-Supervised Learning](https://arxiv.org/abs/2402.13505) | SimPro提出了一种高度适应的框架，不依赖于任何关于未标记数据分布的预定义假设，通过创新地改进期望最大化（EM）算法，明确分离条件和边缘类别分布的建模。 |
| [^15] | [Scalable Decentralized Algorithms for Online Personalized Mean Estimation](https://arxiv.org/abs/2402.12812) | 本研究提出了一种可扩展的分散算法框架，使代理能够自组织成图，并提出了两种协同均值估计算法，解决了每个代理在学习模型的同时识别具有相似分布客户的挑战。 |
| [^16] | [What Changed? Converting Representational Interventions to Natural Language](https://arxiv.org/abs/2402.11355) | 将表征空间的反事实转化为自然语言，以分析和解释模型干预所引起的语言变化，并减轻分类中的偏见。 |
| [^17] | [The Effect of Data Poisoning on Counterfactual Explanations](https://arxiv.org/abs/2402.08290) | 本研究研究了反事实解释在数据污染方面的脆弱性，发现最先进的反事实生成方法和工具包容易受到数据污染的影响。 |
| [^18] | [Instance-Level Safety-Aware Fidelity of Synthetic Data and Its Calibration](https://arxiv.org/abs/2402.07031) | 本论文研究了实例级别的合成数据质量与安全感知，引入了四种超越纯视觉特征的合成数据质量，并提出了优化方法来减少合成和真实图像之间的质量差距。 |
| [^19] | [Blue noise for diffusion models](https://arxiv.org/abs/2402.04930) | 本文提出了一种新颖且通用的扩散模型，利用蓝噪声改善了训练过程中的生成质量，并通过引入相关噪声模型和相关噪声掩码来考虑图像内部和跨图像的相关性，以提高梯度流动和重构频谱内容。 |
| [^20] | [Diffusive Gibbs Sampling](https://arxiv.org/abs/2402.03008) | 扩散吉布斯采样是一种创新的采样方法，通过集成扩散模型并应用吉布斯采样，有效地从具有远程和断开模态特征的分布中采样，表现出比其他方法更好的混合性能，并在多种任务中取得显著改进的结果。 |
| [^21] | [Retrieval-Augmented Score Distillation for Text-to-3D Generation](https://arxiv.org/abs/2402.02972) | RetDream是一种针对文本到3D生成的检索增强的得分蒸馏方法，通过直接使用语义相关的资源，可以充分利用2D扩散模型的表现力和3D资源的几何一致性。 |
| [^22] | [Learning to Embed Time Series Patches Independently](https://arxiv.org/abs/2312.16427) | 学习独立嵌入时间序列片段可以产生更好的时间序列表示，通过简单的块重构任务和独立嵌入每个块的MLP模型以及互补对比学习来实现。 |
| [^23] | [Structured Probabilistic Coding](https://arxiv.org/abs/2312.13933) | 结构化概率编码（SPC）是一种新的监督式表示学习框架，通过编码和预测任务的信息来学习紧凑且信息丰富的表示，提高语言模型的泛化能力和语言理解能力，并通过结构化正则化实现更好的覆盖率。 |
| [^24] | [Building a Safer Maritime Environment Through Multi-Path Long-Term Vessel Trajectory Forecasting](https://arxiv.org/abs/2310.18948) | 通过利用AIS数据预测船舶轨迹，本研究旨在通过减少船舶与鲸鱼碰撞来建立更安全的海洋环境。 |
| [^25] | [Differentially Private Bayesian Tests.](http://arxiv.org/abs/2401.15502) | 本文提出了一种差分隐私贝叶斯检验框架，利用规范化的数据生成机制来进行推断，并避免了对完整数据生成机制的建模需求。该框架具有可解释性，并在计算上具有实质性的优势。 |
| [^26] | [Near-Optimal Policy Optimization for Correlated Equilibrium in General-Sum Markov Games.](http://arxiv.org/abs/2401.15240) | 本文提出了一个协方差均衡的近最优策略优化算法，通过结合平滑价值更新和乐观实行者算法，以及对数障碍正则化器，实现了在一般性和的马尔可夫博弈中计算协方差均衡的近最优收敛速度$\tilde{O}(T^{-1})$。 |
| [^27] | [Scalable network reconstruction in subquadratic time.](http://arxiv.org/abs/2401.01404) | 这篇论文提出了一个可扩展的网络重建算法，能够在次二次时间内实现结果，通过随机的二阶邻居搜索产生最佳的边候选。 |
| [^28] | [Mixture-of-Linear-Experts for Long-term Time Series Forecasting.](http://arxiv.org/abs/2312.06786) | MoLE是一种混合线性专家模型，通过训练多个线性中心模型和一个路由模型，能够适应时间序列模式的周期性变化，并显著降低了预测误差。 |
| [^29] | [On the Learnability of Watermarks for Language Models.](http://arxiv.org/abs/2312.04469) | 该论文研究了语言模型水印的可学习性，提出了水印蒸馏方法，通过训练学生模型使其模仿使用解码水印的教师模型的行为。结果表明，语言模型具有直接学习生成水印的能力，这对于水印的实际应用具有重要影响。 |
| [^30] | [Language Models As Semantic Indexers.](http://arxiv.org/abs/2310.07815) | 本文介绍了一种使用生成性语言模型学习语义ID的自监督框架LMINDEXER。 |
| [^31] | [Conformal Decision Theory: Safe Autonomous Decisions from Imperfect Predictions.](http://arxiv.org/abs/2310.05921) | 符合决策理论是一种框架，可以通过不完美的机器学习预测产生安全的自主决策。该理论的创新之处在于可以在没有对世界模型做出任何假设的情况下提供具有低风险的统计保证的决策。 |
| [^32] | [BrainSCUBA: Fine-Grained Natural Language Captions of Visual Cortex Selectivity.](http://arxiv.org/abs/2310.04420) | "BrainSCUBA通过生成自然语言描述来预测最大激活个体感兴趣体素的图像，达到了细粒度的视觉皮层选择性描述。" |
| [^33] | [Federated Fine-Tuning of LLMs on the Very Edge: The Good, the Bad, the Ugly.](http://arxiv.org/abs/2310.03150) | 本论文以硬件为中心，探讨了如何将LLMs引入现代边缘计算系统。通过联邦学习（FL）对FLAN-T5模型进行微调，并对其在文本摘要任务上的性能进行了评估。同时提供了硬件基准测试和与数据中心GPU的比较。 |
| [^34] | [Learning to Relax: Setting Solver Parameters Across a Sequence of Linear System Instances.](http://arxiv.org/abs/2310.02246) | 本文提出了一种解决一系列线性系统实例中设置求解器参数的方法，通过使用在线学习算法选择参数，可以接近最佳总迭代次数的性能，而无需进行额外的矩阵计算。 |
| [^35] | [Differential 2D Copula Approximating Transforms via Sobolev Training: 2-Cats Networks.](http://arxiv.org/abs/2309.16391) | 本文介绍了一种通过Sobolev训练的2-Cats网络，它能够非参数地逼近任何二维Copula，并且在估计输出方面优于现有技术。 |
| [^36] | [CPLLM: Clinical Prediction with Large Language Models.](http://arxiv.org/abs/2309.11295) | CPLLM是一种使用大规模语言模型进行临床疾病预测的方法。通过量化和提示来微调语言模型，利用患者的历史诊断记录来预测目标疾病的诊断结果。实验证明，CPLLM在各项指标上均超越了其他基线模型，显示出显著的改进。 |
| [^37] | [Large language models can accurately predict searcher preferences.](http://arxiv.org/abs/2309.10621) | 大型语言模型可以通过从真实用户那里获取高质量的第一方数据来准确预测搜索者的偏好。 |
| [^38] | [Fin-Fact: A Benchmark Dataset for Multimodal Financial Fact Checking and Explanation Generation.](http://arxiv.org/abs/2309.08793) | Fin-Fact是一个用于多模态金融事实核查和解释生成的基准数据集，通过提供专业的注释和证据，以及多模态信息源来增强事实性分析，从而打击金融领域的错误信息，促进透明度，并建立信任。 |
| [^39] | [Delegating Data Collection in Decentralized Machine Learning.](http://arxiv.org/abs/2309.01837) | 这项研究在分散机器学习生态系统中研究了委托的数据收集问题，通过设计最优契约解决了模型质量评估的不确定性和对最优性能缺乏预先知识的挑战。 |
| [^40] | [Learned Visual Features to Textual Explanations.](http://arxiv.org/abs/2309.00733) | 本研究提出了一种名为TExplain的方法，将大型语言模型与预训练图像分类器的特征空间连接起来，通过生成解释性句子来理解分类器学习到的特征。该方法首次利用这些频繁单词揭示出分类器的决策过程，实现了检测虚假特征的能力。 |
| [^41] | [A Policy Adaptation Method for Implicit Multitask Reinforcement Learning Problems.](http://arxiv.org/abs/2308.16471) | 本研究提出了一种适用于动态运动生成任务的多任务强化学习算法，可用于适应单个运动类别中的隐式变化，并在头球任务中取得良好的适应效果。 |
| [^42] | [Memory capacity of two layer neural networks with smooth activations.](http://arxiv.org/abs/2308.02001) | 研究发现，具有平滑激活函数的两层神经网络的存储容量下界为md/2，并且准确性大致为2倍。分析存储容量的方法包括计算网络雅可比矩阵的秩，并扩展了有关Hadamard幂秩的经典线性代数事实。 |
| [^43] | [Adaptive Federated Learning with Auto-Tuned Clients.](http://arxiv.org/abs/2306.11201) | 本研究提出了一种自适应的联邦学习方法，其中包括了自动调整客户端的步长规则。实证结果表明，这种方法在各种联邦学习场景中具有显著的优势。 |
| [^44] | [Online Dynamic Submodular Optimization.](http://arxiv.org/abs/2306.10835) | 该论文介绍了在线动态子模规划优化问题，并提出了在线子模贪婪算法（OSGA）和在线子模映射梯度下降（OSPGD）算法以解决此类问题。实验结果表明，这些算法在不同的电力系统中表现良好。 |
| [^45] | [A Probabilistic Framework for Modular Continual Learning.](http://arxiv.org/abs/2306.06545) | 本文提出了一种名为PICLE的模块化增量学习框架，利用概率模型快速计算每个组合的适应度来加速搜索，是第一个可以实现不同类型的转移的模块化增量学习算法。 |
| [^46] | [On the Reliability of Watermarks for Large Language Models.](http://arxiv.org/abs/2306.04634) | 本文研究了大型语言模型水印在混合其他文本来源时的可靠性，并提供了在实际应用中的建议。 |
| [^47] | [Sharp high-probability sample complexities for policy evaluation with linear function approximation.](http://arxiv.org/abs/2305.19001) | 本文研究线性函数逼近下的策略评估问题，提出了两个广泛使用的算法所需的样本复杂度，具有高概率收敛保证且与容差水平的关联性最佳。 |
| [^48] | [Causal Discovery with Unobserved Variables: A Proxy Variable Approach.](http://arxiv.org/abs/2305.05281) | 本文提出了一种基于代理变量的方法，以解决因未观察变量而在观测数据中导致错误识别的问题。该方法可适用于连续变量系统，通过提出正则条件控制离散化误差来识别因果关系。 |
| [^49] | [Continual Diffusion: Continual Customization of Text-to-Image Diffusion with C-LoRA.](http://arxiv.org/abs/2304.06027) | 本文提出了一种新方法C-LoRA，用于持续自定制文本到图像扩散模型，并避免了新概念加入后过去相似概念的图像质量下降的问题。 |
| [^50] | [Skeleton Regression: A Graph-Based Approach to Estimation with Manifold Structure.](http://arxiv.org/abs/2303.11786) | 这是一个处理低维流形数据的回归框架，首先通过构建图形骨架来捕捉潜在的流形几何结构，然后在其上运用非参数回归技术来估计回归函数，除了具有非参数优点之外，在处理多个流形数据，嘈杂观察时也表现出较好的鲁棒性。 |
| [^51] | [A Watermark for Large Language Models.](http://arxiv.org/abs/2301.10226) | 本文提出了一种在大型语言模型中实现水印技术的方法，该技术可以在不降低文本质量的前提下嵌入信号，且可以使用高效的开源算法进行检测，并且该技术十分鲁棒和安全。 |
| [^52] | [Spectral Regularized Kernel Two-Sample Tests.](http://arxiv.org/abs/2212.09201) | 本文研究了基于概率分布的再生核希尔伯特空间嵌入的双样本检验的最优性。我们发现最大均值差异（MMD）检验在分离边界方面并不是最优的，因此我们提出了一种基于谱正则化的修改方法，使得检验具有更小的分离边界。同时，我们还提出了自适应版本的检验，通过数据驱动的策略选择正则化参数，展示了其近乎最优的性能。 |
| [^53] | [Disentangled Representation Learning.](http://arxiv.org/abs/2211.11695) | 解缠表示学习旨在学习一个模型，能够识别和解缠观测数据中隐藏的因素，从而产生可解释的数据表示。它在提高模型可解释性、可控性、鲁棒性和泛化能力方面具有广泛的应用潜力。 |
| [^54] | [TAX-Pose: Task-Specific Cross-Pose Estimation for Robot Manipulation.](http://arxiv.org/abs/2211.09325) | 本论文提出了一种名为TAX-Pose的系统，在机器人操作中实现了任务特定跨姿势的估计。通过学习对象之间的对应关系，这种系统能够在给定操作任务的情况下准确估计两个对象之间的跨姿势，并利用估计结果指导下游的运动规划。 |
| [^55] | [Quadratic models for understanding neural network dynamics.](http://arxiv.org/abs/2205.11787) | 神经二次模型可以展示出神经网络在大学习率情况下的“弹弓阶段”，并且在泛化特性上与神经网络有相似之处，是分析神经网络的有效工具。 |
| [^56] | [An extension of McDiarmid's inequality.](http://arxiv.org/abs/1511.05240) | 本文推广了McDiarmid不等式，使其适用于具有有界差异的函数，并进一步将结果推广到一般度量空间的集中性。 |

# 详细

[^1]: 单调、Bi-Lipschitz和Polyak-\L{}ojasiewicz网络

    Monotone, Bi-Lipschitz, and Polyak-\L{}ojasiewicz Networks

    [https://rss.arxiv.org/abs/2402.01344](https://rss.arxiv.org/abs/2402.01344)

    这篇论文介绍了一种新的可逆神经网络BiLipNet，它具有调控输出敏感性和输入可区分性的能力。其中的主要创新是通过认证的强单调性和Lipschitz性的可逆残差层，与正交层组合构建了Bi-Lipschitz网络。另外，该论文还提出了满足Polyak-\L{}ojasiewicz条件的PLNet，并介绍了其应用于学习非凸代理损失的优势特性。

    

    本文介绍了一种新的BiLipNet，这是一种可逆的\emph{Bi-Lipschitz}神经网络，具有控制其\emph{Lipschitzness}（对输入扰动的输出敏感性）和\emph{inverse Lipschitzness}（不同输出的输入可区分性）的能力。主要贡献是一个新颖的可逆残差层，具有认证的强单调性和Lipschitz性，我们将其与正交层组合以构建Bi-Lipschitz网络。认证是基于增量二次约束的，与谱归一化相比，它能实现更紧密的界限。此外，我们将模型的反向计算形式化为三算子分裂问题，已知存在快速算法。基于所提出的Bi-Lipschitz网络，我们引入了一种新的标量输出网络，即PLNet，它满足Polyak-\L{}ojasiewicz条件。它可以用于学习具有有利特性的非凸代理损失，例如独特性和高效计算性。

    This paper presents a new \emph{bi-Lipschitz} invertible neural network, the BiLipNet, which has the ability to control both its \emph{Lipschitzness} (output sensitivity to input perturbations) and \emph{inverse Lipschitzness} (input distinguishability from different outputs). The main contribution is a novel invertible residual layer with certified strong monotonicity and Lipschitzness, which we compose with orthogonal layers to build bi-Lipschitz networks. The certification is based on incremental quadratic constraints, which achieves much tighter bounds compared to spectral normalization. Moreover, we formulate the model inverse calculation as a three-operator splitting problem, for which fast algorithms are known. Based on the proposed bi-Lipschitz network, we introduce a new scalar-output network, the PLNet, which satisfies the Polyak-\L{}ojasiewicz condition. It can be applied to learn non-convex surrogate losses with favourable properties, e.g., a unique and efficiently-computab
    
[^2]: 跨越维度：高维控制器的可信达性

    Bridging Dimensions: Confident Reachability for High-Dimensional Controllers

    [https://rss.arxiv.org/abs/2311.04843](https://rss.arxiv.org/abs/2311.04843)

    本文介绍了一种连接高维控制器的详尽闭环验证方法，通过将高维控制器的行为近似为不同状态空间区域内的低维控制器，平衡了逼近精度和可验证性。

    

    自主系统越来越多地使用端到端学习的控制器进行实现。这样的控制器做出的决策通过图像作为主要感知模式在真实系统上执行。深度神经网络是这种控制器的基本构建模块。然而，现有的神经网络验证工具在处理具有数千个维度的输入时无法扩展，特别是当各个输入（如像素）缺乏明确的物理意义时。本文在连接详尽的闭环验证与高维控制器方面迈出了一步。我们的关键洞见是，高维控制器的行为可以用不同状态空间区域内的几个低维控制器来近似。为了平衡低维控制器的逼近精度和可验证性，我们利用了最新的验证感知知识蒸馏。然后，如果低维可达性结果已经得到了收敛。

    Autonomous systems are increasingly implemented using end-to-end learning-based controllers. Such controllers make decisions that are executed on the real system with images as one of the primary sensing modalities. Deep neural networks form a fundamental building block of such controllers. Unfortunately, the existing neural-network verification tools do not scale to inputs with thousands of dimensions -- especially when the individual inputs (such as pixels) are devoid of clear physical meaning. This paper takes a step towards connecting exhaustive closed-loop verification with high-dimensional controllers. Our key insight is that the behavior of a high-dimensional controller can be approximated with several low-dimensional controllers in different regions of the state space. To balance the approximation accuracy and verifiability of our low-dimensional controllers, we leverage the latest verification-aware knowledge distillation. Then, if low-dimensional reachability results are infl
    
[^3]: 自我改进学习用于可扩展神经组合优化

    Self-Improved Learning for Scalable Neural Combinatorial Optimization

    [https://arxiv.org/abs/2403.19561](https://arxiv.org/abs/2403.19561)

    提出一种新颖的自我改进学习(SIL)方法，实现神经组合优化的更好可扩展性，通过自身生成解决方案作为伪标签，设计线性复杂度的注意机制来处理大规模组合优化问题实例。

    

    end-to-end神经组合优化(NCO)方法在解决复杂组合优化问题方面表现出有希望的性能，而不需要专家设计。然而，现有方法在处理大规模问题时存在困难，限制了它们的实际适用性。为了克服这一限制，本研究提出了一种新颖的自我改进学习(SIL)方法，以实现神经组合优化的更好可扩展性。具体来说，我们开发了一种高效的自我改进机制，使模型能够在没有标记数据的情况下直接在大规模问题实例上进行训练。通过一种创新的局部重构方法，该方法可以通过自身迭代生成更好的解决方案作为伪标签，以指导有效的模型训练。此外，我们设计了一种线性复杂度的注意机制，使模型能够有效处理低计算开销的大规模组合优化问题实例。

    arXiv:2403.19561v1 Announce Type: cross  Abstract: The end-to-end neural combinatorial optimization (NCO) method shows promising performance in solving complex combinatorial optimization problems without the need for expert design. However, existing methods struggle with large-scale problems, hindering their practical applicability. To overcome this limitation, this work proposes a novel Self-Improved Learning (SIL) method for better scalability of neural combinatorial optimization. Specifically, we develop an efficient self-improved mechanism that enables direct model training on large-scale problem instances without any labeled data. Powered by an innovative local reconstruction approach, this method can iteratively generate better solutions by itself as pseudo-labels to guide efficient model training. In addition, we design a linear complexity attention mechanism for the model to efficiently handle large-scale combinatorial problem instances with low computation overhead. Comprehens
    
[^4]: 通过过拟合的遮蔽自编码器检测生成性模仿

    Detecting Generative Parroting through Overfitting Masked Autoencoders

    [https://arxiv.org/abs/2403.19050](https://arxiv.org/abs/2403.19050)

    本研究提出利用过拟合的遮蔽自编码器(MAE)来检测生成模型中的生成性模仿，建立了基于训练数据集损失的检测阈值，为了确保生成模型的合法使用和提升其法律合规性提供了一种新方法。

    

    生成式人工智能模型的出现彻底改变了数字内容创建的方式，然而由于生成性模仿问题，模型过于模仿其训练数据而给版权完整性带来挑战。本研究提出了一种新方法来解决这个问题，即利用一个过拟合的遮蔽自编码器(MAE)来有效地检测这种模仿样本。我们基于训练数据集上的平均损失建立一个检测阈值，从而精确定位修改后数据集中的模仿内容。初步评估表明了有希望的结果，显示了我们方法确保生成模型的合法使用并加强法律合规性方面的潜力。

    arXiv:2403.19050v1 Announce Type: cross  Abstract: The advent of generative AI models has revolutionized digital content creation, yet it introduces challenges in maintaining copyright integrity due to generative parroting, where models mimic their training data too closely. Our research presents a novel approach to tackle this issue by employing an overfitted Masked Autoencoder (MAE) to detect such parroted samples effectively. We establish a detection threshold based on the mean loss across the training dataset, allowing for the precise identification of parroted content in modified datasets. Preliminary evaluations demonstrate promising results, suggesting our method's potential to ensure ethical use and enhance the legal compliance of generative models.
    
[^5]: 知识引导的机器学习：当前趋势与未来展望

    Knowledge-guided Machine Learning: Current Trends and Future Prospects

    [https://arxiv.org/abs/2403.15989](https://arxiv.org/abs/2403.15989)

    知识引导的机器学习（KGML）结合科学知识和数据在机器学习框架中，以实现更好的泛化能力、科学一致性和结果可解释性。

    

    本文概述了科学建模，并讨论了与基于过程的模型相比，机器学习方法在科学建模中的互补优势和劣势。文章还介绍了新兴领域科学知识引导的机器学习（KGML）研究的当前状态，旨在利用科学知识和数据在机器学习框架中实现更好的泛化能力、科学一致性和结果可解释性。我们从使用的科学知识类型、探讨的知识-ML集成形式以及在机器学习中整合科学知识的方法等方面讨论了KGML研究的不同方面。我们还讨论了在环境科学中发展的KGML方法的一些常见用例类别，以每个类别中的实例为例。

    arXiv:2403.15989v1 Announce Type: cross  Abstract: This paper presents an overview of scientific modeling and discusses the complementary strengths and weaknesses of ML methods for scientific modeling in comparison to process-based models. It also provides an introduction to the current state of research in the emerging field of scientific knowledge-guided machine learning (KGML) that aims to use both scientific knowledge and data in ML frameworks to achieve better generalizability, scientific consistency, and explainability of results. We discuss different facets of KGML research in terms of the type of scientific knowledge used, the form of knowledge-ML integration explored, and the method for incorporating scientific knowledge in ML. We also discuss some of the common categories of use cases in environmental sciences where KGML methods are being developed, using illustrative examples in each category.
    
[^6]: 依从在线模型聚合

    Conformal online model aggregation

    [https://arxiv.org/abs/2403.15527](https://arxiv.org/abs/2403.15527)

    该论文提出了一种基于投票的在线依从模型聚合方法，可以根据过去表现调整模型权重。

    

    依从预测为机器学习模型提供了一种合理的不确定性量化概念，而不需要做出强烈的分布假设。它适用于任何黑盒预测模型，并将点预测转换成具有预定义边际覆盖保证的集预测。然而，依从预测只在事先确定底层机器学习模型的情况下起作用。依从预测中相对较少涉及的问题是模型选择和/或聚合：对于给定的问题，应该如何依从化众多预测方法（随机森林、神经网络、正则化线性模型等）？本文提出了一种新的依从模型聚合方法，用于在线设置，该方法基于将来自多个算法的预测集进行投票，其中根据过去表现调整模型上的权重。

    arXiv:2403.15527v1 Announce Type: cross  Abstract: Conformal prediction equips machine learning models with a reasonable notion of uncertainty quantification without making strong distributional assumptions. It wraps around any black-box prediction model and converts point predictions into set predictions that have a predefined marginal coverage guarantee. However, conformal prediction only works if we fix the underlying machine learning model in advance. A relatively unaddressed issue in conformal prediction is that of model selection and/or aggregation: for a given problem, which of the plethora of prediction methods (random forests, neural nets, regularized linear models, etc.) should we conformalize? This paper proposes a new approach towards conformal model aggregation in online settings that is based on combining the prediction sets from several algorithms by voting, where weights on the models are adapted over time based on past performance.
    
[^7]: 面向资源受限的IoT环境的高效基于Transformer的超参数优化

    Efficient Transformer-based Hyper-parameter Optimization for Resource-constrained IoT Environments

    [https://arxiv.org/abs/2403.12237](https://arxiv.org/abs/2403.12237)

    本文提出了一种通过将Transformer架构和演员-评论家强化学习模型相结合的新方法TRL-HPO，在资源受限的IoT环境中实现了高效的超参数优化，该方法在MNIST数据集上表现优良。

    

    超参数优化（HPO）过程对于找到表现最佳的卷积神经网络（CNNs）至关重要。HPO的自动化过程以其可观的计算占用和缺乏透明度而闻名；这两个因素在资源受限的物联网（IoT）环境中至关重要。本文通过提出一种结合Transformer架构和演员-评论家强化学习（RL）模型的新方法TRL-HPO，旨在解决这些问题，TRL-HPO配备了多头注意力，实现了并行化和渐进生成层。我们通过在MNIST数据集上评估TRL-HPO，并将其与从头开始构建CNN模型的最新方法进行比较，从而从经验上验证了这些假设。结果显示，在相同时间范围内，TRL-HPO的分类结果优于这些方法的结果6.8%，证明了TRL-HPO的高效性。

    arXiv:2403.12237v1 Announce Type: cross  Abstract: The hyper-parameter optimization (HPO) process is imperative for finding the best-performing Convolutional Neural Networks (CNNs). The automation process of HPO is characterized by its sizable computational footprint and its lack of transparency; both important factors in a resource-constrained Internet of Things (IoT) environment. In this paper, we address these problems by proposing a novel approach that combines transformer architecture and actor-critic Reinforcement Learning (RL) model, TRL-HPO, equipped with multi-headed attention that enables parallelization and progressive generation of layers. These assumptions are founded empirically by evaluating TRL-HPO on the MNIST dataset and comparing it with state-of-the-art approaches that build CNN models from scratch. The results show that TRL-HPO outperforms the classification results of these approaches by 6.8% within the same time frame, demonstrating the efficiency of TRL-HPO for 
    
[^8]: Chronos: 学习时间序列的语言

    Chronos: Learning the Language of Time Series

    [https://arxiv.org/abs/2403.07815](https://arxiv.org/abs/2403.07815)

    Chronos框架通过在固定词汇上训练预训练的概率时间序列模型，在大量数据集上进行了全面基准测试，表现出在训练语料库中的数据集上明显优于其他方法，并且在新数据集上的零样本性能表现可比甚至优于其他方法。

    

    我们介绍了Chronos，一个简单但有效的预训练概率时间序列模型框架。Chronos使用缩放和量化将时间序列值标记化为固定词汇，并通过交叉熵损失在这些标记化的时间序列上训练现有的基于Transformer的语言模型架构。我们在大量公开可用数据集上基于T5系列（参数范围从20M到710M）对Chronos模型进行了预训练，同时通过高斯过程生成了一个合成数据集以提高泛化能力。在包含42个数据集的全面基准测试中，涵盖了传统的本地模型和深度学习方法，我们展示了Chronos模型：（a）在训练语料库中的数据集上明显优于其他方法；（b）相对于专门训练的方法，在新数据集上的零样本性能可比甚至优于其他方法。

    arXiv:2403.07815v1 Announce Type: cross  Abstract: We introduce Chronos, a simple yet effective framework for pretrained probabilistic time series models. Chronos tokenizes time series values using scaling and quantization into a fixed vocabulary and trains existing transformer-based language model architectures on these tokenized time series via the cross-entropy loss. We pretrained Chronos models based on the T5 family (ranging from 20M to 710M parameters) on a large collection of publicly available datasets, complemented by a synthetic dataset that we generated via Gaussian processes to improve generalization. In a comprehensive benchmark consisting of 42 datasets, and comprising both classical local models and deep learning methods, we show that Chronos models: (a) significantly outperform other methods on datasets that were part of the training corpus; and (b) have comparable and occasionally superior zero-shot performance on new datasets, relative to methods that were trained spe
    
[^9]: 将Thompson抽样遗憾与Sigma比率（TS-RSR）最小化：一种用于批量贝叶斯优化的经过证明的高效算法

    Minimizing the Thompson Sampling Regret-to-Sigma Ratio (TS-RSR): a provably efficient algorithm for batch Bayesian Optimization

    [https://arxiv.org/abs/2403.04764](https://arxiv.org/abs/2403.04764)

    该论文提出了一种用于批量贝叶斯优化的高效算法，通过最小化Thompson抽样近似的遗憾与不确定性比率，成功协调每个批次的动作选择，同时实现高概率的理论保证，并在非凸测试函数上表现出色.

    

    本文提出了一个新的方法，用于批量贝叶斯优化（BO），其中抽样通过最小化Thompson抽样方法的遗憾与不确定性比率来进行。我们的目标是能够协调每个批次中选择的动作，以最小化点之间的冗余，同时关注具有高预测均值或高不确定性的点。我们对算法的遗憾提供了高概率的理论保证。最后，从数字上看，我们证明了我们的方法在一系列非凸测试函数上达到了最先进的性能，在平均值上比几个竞争对手的基准批量BO算法表现提高了一个数量级。

    arXiv:2403.04764v1 Announce Type: new  Abstract: This paper presents a new approach for batch Bayesian Optimization (BO), where the sampling takes place by minimizing a Thompson Sampling approximation of a regret to uncertainty ratio. Our objective is able to coordinate the actions chosen in each batch in a way that minimizes redundancy between points whilst focusing on points with high predictive means or high uncertainty. We provide high-probability theoretical guarantees on the regret of our algorithm. Finally, numerically, we demonstrate that our method attains state-of-the-art performance on a range of nonconvex test functions, where it outperforms several competitive benchmark batch BO algorithms by an order of magnitude on average.
    
[^10]: 神经执行：学习执行触发器用于提示注入攻击

    Neural Exec: Learning (and Learning from) Execution Triggers for Prompt Injection Attacks

    [https://arxiv.org/abs/2403.03792](https://arxiv.org/abs/2403.03792)

    通过学习方法生成的执行触发器可以比当前手工制作的触发器更加有效，并表现出形状、属性和功能上的固有灵活性。

    

    我们引入了一种名为神经执行（Neural Exec）的新型提示注入攻击。与依赖手工制作的字符串（例如“忽略先前的指令并...”）的已知攻击不同，我们展示了将创建执行触发器概念化为可微分搜索问题，并使用基于学习的方法自动生成执行触发器的可能性。我们的结果表明，一个积极进取的对手可以伪造出不仅比当前手工制作的触发器更加有效，而且在形状、属性和功能上表现出固有灵活性的触发器。在这方面，我们展示了攻击者可以设计和生成能够在经历多阶段预处理流水线的情况下持久存在的神经执行（Neural Exec），例如在基于检索增强生成（RAG）的应用中。更为关键的是，我们的发现表明，攻击者可以生成与任何已知攻击明显不同的形式和形状的触发器，绕过...

    arXiv:2403.03792v1 Announce Type: cross  Abstract: We introduce a new family of prompt injection attacks, termed Neural Exec. Unlike known attacks that rely on handcrafted strings (e.g., "Ignore previous instructions and..."), we show that it is possible to conceptualize the creation of execution triggers as a differentiable search problem and use learning-based methods to autonomously generate them.   Our results demonstrate that a motivated adversary can forge triggers that are not only drastically more effective than current handcrafted ones but also exhibit inherent flexibility in shape, properties, and functionality. In this direction, we show that an attacker can design and generate Neural Execs capable of persisting through multi-stage preprocessing pipelines, such as in the case of Retrieval-Augmented Generation (RAG)-based applications. More critically, our findings show that attackers can produce triggers that deviate markedly in form and shape from any known attack, sidestep
    
[^11]: Disaggregated Multi-Tower: 面向拓扑感知的高效大规模推荐建模技术

    Disaggregated Multi-Tower: Topology-aware Modeling Technique for Efficient Large-Scale Recommendation

    [https://arxiv.org/abs/2403.00877](https://arxiv.org/abs/2403.00877)

    Disaggregated Multi-Tower提出了一种面向拓扑感知的建模技术，通过SPTT、TM和TP三个组件实现了高效的大规模推荐，加速性能提升了1.9倍。

    

    我们研究了深度学习推荐模型的扁平架构、常见的分布式训练模式和分层数据中心拓扑之间的不匹配。为了解决相关的低效性，我们提出了Disaggregated Multi-Tower（DMT），这是一种建模技术，包括（1）语义保留的Tower Transform（SPTT），一个将单片全局嵌入查找过程分解为不相交塔以利用数据中心位置关系的新型训练模式；（2）Tower Module（TM），一个附加到每个塔的协同稠密组件，通过分层特征交互降低模型复杂性和通信量；和（3）Tower Partitioner（TP），一个特征分区器，系统地创建具有有意义特征交互和负载平衡分配的塔，通过学习的嵌入来保持模型质量和训练吞吐量。我们展示了DMT相比于最新的方法可以实现高达1.9倍的加速。

    arXiv:2403.00877v1 Announce Type: new  Abstract: We study a mismatch between the deep learning recommendation models' flat architecture, common distributed training paradigm and hierarchical data center topology. To address the associated inefficiencies, we propose Disaggregated Multi-Tower (DMT), a modeling technique that consists of (1) Semantic-preserving Tower Transform (SPTT), a novel training paradigm that decomposes the monolithic global embedding lookup process into disjoint towers to exploit data center locality; (2) Tower Module (TM), a synergistic dense component attached to each tower to reduce model complexity and communication volume through hierarchical feature interaction; and (3) Tower Partitioner (TP), a feature partitioner to systematically create towers with meaningful feature interactions and load balanced assignments to preserve model quality and training throughput via learned embeddings. We show that DMT can achieve up to 1.9x speedup compared to the state-of-th
    
[^12]: 基于插值的策略扩散的行为细化

    Behavioral Refinement via Interpolant-based Policy Diffusion

    [https://arxiv.org/abs/2402.16075](https://arxiv.org/abs/2402.16075)

    使用比高斯更具信息量的源头启动扩散方法有助于克服模仿学习任务中的限制。

    

    模仿学习使人工智能代理通过从演示中学习来模仿行为。最近，拥有建模高维度和多模态分布能力的扩散模型在模仿学习任务上表现出色。这些模型通过将动作（或状态）从标准高斯噪声中扩散来塑造策略。然而，要学习的目标策略通常与高斯分布显著不同，这种不匹配可能导致在使用少量扩散步骤（以提高推理速度）和有限数据下性能不佳。这项工作的关键思想是，从比高斯更具信息量的源头开始，可以使扩散方法克服上述限制。我们提供了理论结果、一种新方法和实证发现，展示了使用信息量丰富的源策略的好处。我们的方法，称为BRIDGER，利用了随机性。

    arXiv:2402.16075v1 Announce Type: cross  Abstract: Imitation learning empowers artificial agents to mimic behavior by learning from demonstrations. Recently, diffusion models, which have the ability to model high-dimensional and multimodal distributions, have shown impressive performance on imitation learning tasks. These models learn to shape a policy by diffusing actions (or states) from standard Gaussian noise. However, the target policy to be learned is often significantly different from Gaussian and this mismatch can result in poor performance when using a small number of diffusion steps (to improve inference speed) and under limited data. The key idea in this work is that initiating from a more informative source than Gaussian enables diffusion methods to overcome the above limitations. We contribute both theoretical results, a new method, and empirical findings that show the benefits of using an informative source policy. Our method, which we call BRIDGER, leverages the stochast
    
[^13]: 跨架构零样本泛化的视觉分类

    Zero-shot generalization across architectures for visual classification

    [https://arxiv.org/abs/2402.14095](https://arxiv.org/abs/2402.14095)

    不同神经网络在跨架构和层间泛化到未知类别的能力存在差异，准确性并不是泛化能力的良好预测因子，泛化能力随着层深度呈非单调变化。

    

    深度网络的一个关键优势是对未见数据的泛化能力，但其与分类准确性的关系尚不清楚。我们利用一种极简的视觉数据集和一种泛化度量，展示了从深度卷积网络（CNNs）到transformers的流行网络在通过层和架构泛化到未见类别方面的能力存在差异。准确性并不是泛化能力的良好预测因子，并且泛化能力随着层深度呈非单调变化。代码可在https://github.com/dyballa/zero-shot-generalization 找到。

    arXiv:2402.14095v1 Announce Type: cross  Abstract: Generalization to unseen data is a key desideratum for deep networks, but its relation to classification accuracy is unclear. Using a minimalist vision dataset and a measure of generalizability, we show that popular networks, from deep convolutional networks (CNNs) to transformers, vary in their power to extrapolate to unseen classes both across layers and across architectures. Accuracy is not a good predictor of generalizability, and generalization varies non-monotonically with layer depth. Code is available at https://github.com/dyballa/zero-shot-generalization.
    
[^14]: SimPro：一个简单的概率框架实现逼真的长尾半监督学习

    SimPro: A Simple Probabilistic Framework Towards Realistic Long-Tailed Semi-Supervised Learning

    [https://arxiv.org/abs/2402.13505](https://arxiv.org/abs/2402.13505)

    SimPro提出了一种高度适应的框架，不依赖于任何关于未标记数据分布的预定义假设，通过创新地改进期望最大化（EM）算法，明确分离条件和边缘类别分布的建模。

    

    近年来半监督学习的最新进展集中在解决一个更为逼真但具有挑战性的任务：解决标记数据的不平衡问题，同时未标记数据的类别分布既未知又可能不匹配。当前这一领域的方法往往预设了关于未标记数据类别分布的严格假设，从而限制了模型仅适应于某些分布范围。在本研究中，我们提出了一种新颖的方法，引入了一个高度适应性的框架，命名为SimPro，它不依赖于任何关于未标记数据分布的预定义假设。我们的框架建立在一个概率模型上，通过明确分离条件和边缘类别分布的建模，创新地改进了期望最大化（EM）算法。这种分离促进了在最大化过程中对类别分布进行估计的闭合形式解决方案。

    arXiv:2402.13505v1 Announce Type: new  Abstract: Recent advancements in semi-supervised learning have focused on a more realistic yet challenging task: addressing imbalances in labeled data while the class distribution of unlabeled data remains both unknown and potentially mismatched. Current approaches in this sphere often presuppose rigid assumptions regarding the class distribution of unlabeled data, thereby limiting the adaptability of models to only certain distribution ranges. In this study, we propose a novel approach, introducing a highly adaptable framework, designated as SimPro, which does not rely on any predefined assumptions about the distribution of unlabeled data. Our framework, grounded in a probabilistic model, innovatively refines the expectation-maximization (EM) algorithm by explicitly decoupling the modeling of conditional and marginal class distributions. This separation facilitates a closed-form solution for class distribution estimation during the maximization p
    
[^15]: 可扩展的分散算法用于在线个性化均值估计

    Scalable Decentralized Algorithms for Online Personalized Mean Estimation

    [https://arxiv.org/abs/2402.12812](https://arxiv.org/abs/2402.12812)

    本研究提出了一种可扩展的分散算法框架，使代理能够自组织成图，并提出了两种协同均值估计算法，解决了每个代理在学习模型的同时识别具有相似分布客户的挑战。

    

    在许多情况下，代理缺乏足够的数据直接学习模型。与其他代理合作可能有所帮助，但当本地数据分布不同时，会引入偏差-方差权衡。一个关键挑战是每个代理在学习模型的同时识别具有相似分布的客户，这个问题主要仍未解决。本研究着眼于一个简化版本的普遍问题，即每个代理随时间从实值分布中收集样本来估计其均值。现有算法面临着不切实际的空间和时间复杂度（与代理数量A的平方成正比）。为了解决可扩展性挑战，我们提出了一个框架，代理自组织成一个图，使得每个代理只能与选定数量的对等体r进行通信。我们介绍了两种协作均值估计算法：一种灵感来源于信念传播，另一种采用基于共识的方法。

    arXiv:2402.12812v1 Announce Type: new  Abstract: In numerous settings, agents lack sufficient data to directly learn a model. Collaborating with other agents may help, but it introduces a bias-variance trade-off, when local data distributions differ. A key challenge is for each agent to identify clients with similar distributions while learning the model, a problem that remains largely unresolved. This study focuses on a simplified version of the overarching problem, where each agent collects samples from a real-valued distribution over time to estimate its mean. Existing algorithms face impractical space and time complexities (quadratic in the number of agents A). To address scalability challenges, we propose a framework where agents self-organize into a graph, allowing each agent to communicate with only a selected number of peers r. We introduce two collaborative mean estimation algorithms: one draws inspiration from belief propagation, while the other employs a consensus-based appr
    
[^16]: 改变了什么？将表征干预转化为自然语言

    What Changed? Converting Representational Interventions to Natural Language

    [https://arxiv.org/abs/2402.11355](https://arxiv.org/abs/2402.11355)

    将表征空间的反事实转化为自然语言，以分析和解释模型干预所引起的语言变化，并减轻分类中的偏见。

    

    针对语言模型（LMs）表征空间的干预方法已经被证明是影响模型行为的有效手段。这些方法被用来消除或改变模型表示中的人口统计信息（如性别）的编码，创建一个反事实的表示。然而，由于干预操作在表示空间内，准确理解它修改了哪些特征是一个挑战。我们展示了表征空间的反事实可以转化为自然语言的反事实。我们证明了这种方法使我们能够分析对应于给定表示空间干预的语言变化，并解释用于编码特定概念的特征。此外，由此产生的反事实可以用于减轻分类中的偏见。

    arXiv:2402.11355v1 Announce Type: new  Abstract: Interventions targeting the representation space of language models (LMs) have emerged as effective means to influence model behavior. These methods are employed, for example, to eliminate or alter the encoding of demographic information such as gender within the model's representations, creating a counterfactual representation. However, since the intervention operates within the representation space, understanding precisely which features it modifies poses a challenge. We show that representation-space counterfactuals can be converted into natural language counterfactuals. We demonstrate that this approach enables us to analyze the linguistic alterations corresponding to a given representation-space intervention and to interpret the features utilized for encoding a specific concept. Moreover, the resulting counterfactuals can be used to mitigate bias in classification.
    
[^17]: 数据污染对反事实解释的影响

    The Effect of Data Poisoning on Counterfactual Explanations

    [https://arxiv.org/abs/2402.08290](https://arxiv.org/abs/2402.08290)

    本研究研究了反事实解释在数据污染方面的脆弱性，发现最先进的反事实生成方法和工具包容易受到数据污染的影响。

    

    反事实解释是分析黑盒系统预测的一种流行方法，它们提供了根据不同情况建议改变输入以获得不同（更有利）系统输出的计算补救机会。然而，最近的研究突显了它们对不同类型操纵的脆弱性。本研究研究了反事实解释对数据污染的脆弱性。我们在增加三个不同层次的补救成本方面，形式化地研究了反事实解释在单个实例、某个子组或所有实例上的数据污染。我们证明了最先进的反事实生成方法和工具包对此类数据污染是脆弱的。

    Counterfactual explanations provide a popular method for analyzing the predictions of black-box systems, and they can offer the opportunity for computational recourse by suggesting actionable changes on how to change the input to obtain a different (i.e. more favorable) system output. However, recent work highlighted their vulnerability to different types of manipulations. This work studies the vulnerability of counterfactual explanations to data poisoning. We formalize data poisoning in the context of counterfactual explanations for increasing the cost of recourse on three different levels: locally for a single instance, or a sub-group of instances, or globally for all instances. We demonstrate that state-of-the-art counterfactual generation methods \& toolboxes are vulnerable to such data poisoning.
    
[^18]: 实例级别的安全感知与合成数据质量及其校准

    Instance-Level Safety-Aware Fidelity of Synthetic Data and Its Calibration

    [https://arxiv.org/abs/2402.07031](https://arxiv.org/abs/2402.07031)

    本论文研究了实例级别的合成数据质量与安全感知，引入了四种超越纯视觉特征的合成数据质量，并提出了优化方法来减少合成和真实图像之间的质量差距。

    

    建模和校准合成数据的质量对塑造未来安全可靠的自动驾驶技术至关重要，它提供了一种成本效益高且可扩展的替代方案，可以取代真实世界的数据收集。我们关注其在安全关键应用中的作用，引入了超越纯视觉输入特征的四种实例级别质量，旨在使合成数据与现实世界的安全问题相一致。我们提出了一种优化方法来改进合成数据生成器，减少由基于DNN的组件识别出的质量差距。我们的研究结果表明，这种调优可以增强合成和真实图像中安全关键错误之间的相关性。

    Modeling and calibrating the fidelity of synthetic data is paramount in shaping the future of safe and reliable self-driving technology by offering a cost-effective and scalable alternative to real-world data collection. We focus on its role in safety-critical applications, introducing four types of instance-level fidelity that go beyond mere visual input characteristics. The aim is to align synthetic data with real-world safety issues. We suggest an optimization method to refine the synthetic data generator, reducing fidelity gaps identified by the DNN-based component. Our findings show this tuning enhances the correlation between safety-critical errors in synthetic and real images.
    
[^19]: 扩散模型中的蓝噪声

    Blue noise for diffusion models

    [https://arxiv.org/abs/2402.04930](https://arxiv.org/abs/2402.04930)

    本文提出了一种新颖且通用的扩散模型，利用蓝噪声改善了训练过程中的生成质量，并通过引入相关噪声模型和相关噪声掩码来考虑图像内部和跨图像的相关性，以提高梯度流动和重构频谱内容。

    

    现有的大多数扩散模型在训练和采样过程中使用高斯噪声，但这可能无法最优地考虑去噪网络重构的频谱内容。尽管相关噪声在计算机图形学中应用广泛，但其在改进训练过程方面的潜力尚未充分探索。本文介绍了一种新颖且通用的扩散模型类，考虑了图像内部和跨图像的相关噪声。具体而言，我们提出了一种时变噪声模型来将相关噪声纳入训练过程，并提出了一种快速生成相关噪声掩码的方法。我们的模型基于确定性扩散模型，利用蓝噪声相比仅使用高斯白噪声（随机噪声）有助于提高生成质量。此外，我们的框架还允许在单个小批量中引入图像之间的相关性来改善梯度流动。我们进行了定性和定量实验证明了我们模型的有效性。

    Most of the existing diffusion models use Gaussian noise for training and sampling across all time steps, which may not optimally account for the frequency contents reconstructed by the denoising network. Despite the diverse applications of correlated noise in computer graphics, its potential for improving the training process has been underexplored. In this paper, we introduce a novel and general class of diffusion models taking correlated noise within and across images into account. More specifically, we propose a time-varying noise model to incorporate correlated noise into the training process, as well as a method for fast generation of correlated noise mask. Our model is built upon deterministic diffusion models and utilizes blue noise to help improve the generation quality compared to using Gaussian white (random) noise only. Further, our framework allows introducing correlation across images within a single mini-batch to improve gradient flow. We perform both qualitative and qua
    
[^20]: 扩散吉布斯采样

    Diffusive Gibbs Sampling

    [https://arxiv.org/abs/2402.03008](https://arxiv.org/abs/2402.03008)

    扩散吉布斯采样是一种创新的采样方法，通过集成扩散模型并应用吉布斯采样，有效地从具有远程和断开模态特征的分布中采样，表现出比其他方法更好的混合性能，并在多种任务中取得显著改进的结果。

    

    传统马尔可夫链蒙特卡洛（MCMC）方法在多模态分布的混合不足方面存在着挑战，特别是在贝叶斯推断和分子动力学等实际应用中。针对这个问题，我们提出了一种创新的采样方法——扩散吉布斯采样（DiGS），用于有效采样具有远程和断开模态特征的分布。DiGS集成了扩散模型的最新发展，利用高斯卷积创建一个辅助噪声分布，以在原始空间中连接孤立的模态，并应用吉布斯采样从两个空间中交替抽取样本。我们的方法在采样多模态分布方面表现出比并行温度法等最先进方法更好的混合性能。我们证明我们的采样器在各种任务中取得了显著改进的结果，包括高斯混合模型、贝叶斯神经网络和分子动力学。

    The inadequate mixing of conventional Markov Chain Monte Carlo (MCMC) methods for multi-modal distributions presents a significant challenge in practical applications such as Bayesian inference and molecular dynamics. Addressing this, we propose Diffusive Gibbs Sampling (DiGS), an innovative family of sampling methods designed for effective sampling from distributions characterized by distant and disconnected modes. DiGS integrates recent developments in diffusion models, leveraging Gaussian convolution to create an auxiliary noisy distribution that bridges isolated modes in the original space and applying Gibbs sampling to alternately draw samples from both spaces. Our approach exhibits a better mixing property for sampling multi-modal distributions than state-of-the-art methods such as parallel tempering. We demonstrate that our sampler attains substantially improved results across various tasks, including mixtures of Gaussians, Bayesian neural networks and molecular dynamics.
    
[^21]: 检索增强的得分蒸馏用于文本到3D生成

    Retrieval-Augmented Score Distillation for Text-to-3D Generation

    [https://arxiv.org/abs/2402.02972](https://arxiv.org/abs/2402.02972)

    RetDream是一种针对文本到3D生成的检索增强的得分蒸馏方法，通过直接使用语义相关的资源，可以充分利用2D扩散模型的表现力和3D资源的几何一致性。

    

    文本到3D生成通过引入强大的2D扩散模型取得了显著的成功，但不足的3D先验知识也导致了3D几何的不一致性。最近，由于发布了大规模的多视角数据集，将扩散模型在多视角数据集上进行微调成为解决3D一致性问题的主流方法。然而，与2D数据相比，3D数据的质量和多样性有限，这导致了困难。为了回避这些平衡问题，我们探索了一种针对得分蒸馏的检索增强方法，名为RetDream。我们假设通过在优化过程中直接使用语义相关的资源，可以充分利用2D扩散模型的表现力和3D资源的几何一致性。为此，我们引入了一种新的基于检索的质量增强框架，用于文本到3D生成。我们利用检索到的资源来融入其

    Text-to-3D generation has achieved significant success by incorporating powerful 2D diffusion models, but insufficient 3D prior knowledge also leads to the inconsistency of 3D geometry. Recently, since large-scale multi-view datasets have been released, fine-tuning the diffusion model on the multi-view datasets becomes a mainstream to solve the 3D inconsistency problem. However, it has confronted with fundamental difficulties regarding the limited quality and diversity of 3D data, compared with 2D data. To sidestep these trade-offs, we explore a retrieval-augmented approach tailored for score distillation, dubbed RetDream. We postulate that both expressiveness of 2D diffusion models and geometric consistency of 3D assets can be fully leveraged by employing the semantically relevant assets directly within the optimization process. To this end, we introduce novel framework for retrieval-based quality enhancement in text-to-3D generation. We leverage the retrieved asset to incorporate its
    
[^22]: 独立学习将时间序列片段嵌入

    Learning to Embed Time Series Patches Independently

    [https://arxiv.org/abs/2312.16427](https://arxiv.org/abs/2312.16427)

    学习独立嵌入时间序列片段可以产生更好的时间序列表示，通过简单的块重构任务和独立嵌入每个块的MLP模型以及互补对比学习来实现。

    

    最近，掩码时间序列建模作为一种自监督表示学习策略引起了广泛关注。受计算机视觉中的掩码图像建模启发，最近的研究首先将时间序列进行分块处理并部分掩盖，然后训练Transformer模型通过从未掩盖的块预测被掩盖块来捕捉块之间的依赖关系。然而，我们认为捕捉这种块之间的依赖关系可能不是时间序列表示学习的最佳策略；相反，独立学习嵌入片段会产生更好的时间序列表示。具体而言，我们建议使用1）简单的块重构任务，自动将每个块进行编码而不查看其他块，以及2）独自嵌入每个块的简单块式MLP。此外，我们引入互补对比学习来有效地分层捕获相邻时间序列信息。

    arXiv:2312.16427v2 Announce Type: replace-cross  Abstract: Masked time series modeling has recently gained much attention as a self-supervised representation learning strategy for time series. Inspired by masked image modeling in computer vision, recent works first patchify and partially mask out time series, and then train Transformers to capture the dependencies between patches by predicting masked patches from unmasked patches. However, we argue that capturing such patch dependencies might not be an optimal strategy for time series representation learning; rather, learning to embed patches independently results in better time series representations. Specifically, we propose to use 1) the simple patch reconstruction task, which autoencode each patch without looking at other patches, and 2) the simple patch-wise MLP that embeds each patch independently. In addition, we introduce complementary contrastive learning to hierarchically capture adjacent time series information efficiently. 
    
[^23]: 结构化概率编码

    Structured Probabilistic Coding

    [https://arxiv.org/abs/2312.13933](https://arxiv.org/abs/2312.13933)

    结构化概率编码（SPC）是一种新的监督式表示学习框架，通过编码和预测任务的信息来学习紧凑且信息丰富的表示，提高语言模型的泛化能力和语言理解能力，并通过结构化正则化实现更好的覆盖率。

    

    本论文提出了一种新的监督式表示学习框架，即结构化概率编码（SPC），用于从与目标任务相关的输入中学习紧凑和信息丰富的表示。SPC是一种仅有编码器的概率编码技术，具有来自目标空间的结构化正则化。它可以提高预训练语言模型的泛化能力，以实现更好的语言理解。具体而言，我们的概率编码在一个模块中同时进行信息编码和任务预测，以更充分地利用输入数据中的有效信息。它使用输出空间的变分推断来减少随机性和不确定性。此外，为了更好地控制概率表示的学习过程，在潜在空间中提出了结构化正则化，以促进类别之间的均匀性。通过正则化项，SPC可以保持潜在编码的高斯结构，并实现更好的覆盖率。

    This paper presents a new supervised representation learning framework, namely structured probabilistic coding (SPC), to learn compact and informative representations from input related to the target task. SPC is an encoder-only probabilistic coding technology with a structured regularization from the target space. It can enhance the generalization ability of pre-trained language models for better language understanding. Specifically, our probabilistic coding simultaneously performs information encoding and task prediction in one module to more fully utilize the effective information from input data. It uses variational inference in the output space to reduce randomness and uncertainty. Besides, to better control the learning process of probabilistic representations, a structured regularization is proposed to promote uniformity across classes in the latent space. With the regularization term, SPC can preserve the Gaussian structure of the latent code and achieve better coverage of the 
    
[^24]: 通过多路径长期船舶轨迹预测建立更安全的海洋环境

    Building a Safer Maritime Environment Through Multi-Path Long-Term Vessel Trajectory Forecasting

    [https://arxiv.org/abs/2310.18948](https://arxiv.org/abs/2310.18948)

    通过利用AIS数据预测船舶轨迹，本研究旨在通过减少船舶与鲸鱼碰撞来建立更安全的海洋环境。

    

    海上交通对于实现全球经济增长至关重要，同时也需要在可持续性和保护濒危海洋物种方面履行生态义务，尤其是保护大型鲸类种群。在这方面，自动识别系统(AIS)数据通过提供船舶运动的实时流数据，可以实现强化的交通监控，从而避免船舶与鲸鱼碰撞。本研究探讨利用AIS数据预测长期船舶轨迹，从而预防船舶与鲸鱼的碰撞。为此，我们采用双向长短期记忆网络(Bi-LSTM)构建了一种编码器-解码器模型架构，通过将1到3小时的AIS数据作为输入，预测接下来12小时的船舶轨迹。我们从历史AIS数据中提取潜在路线和目的地的概率特征，并将其作为模型的输入。模型随后预测船舶的轨迹，考虑到潜在路线和目的地的影响。

    Maritime transportation is paramount in achieving global economic growth, entailing concurrent ecological obligations in sustainability and safeguarding endangered marine species, most notably preserving large whale populations. In this regard, the Automatic Identification System (AIS) data plays a significant role by offering real-time streaming data on vessel movement, allowing enhanced traffic monitoring. This study explores using AIS data to prevent vessel-to-whale collisions by forecasting long-term vessel trajectories from engineered AIS data sequences. For such a task, we have developed an encoder-decoder model architecture using Bidirectional Long Short-Term Memory Networks (Bi-LSTM) to predict the next 12 hours of vessel trajectories using 1 to 3 hours of AIS data as input. We feed the model with probabilistic features engineered from historical AIS data that refer to each trajectory's potential route and destination. The model then predicts the vessel's trajectory, considerin
    
[^25]: 差分隐私贝叶斯检验

    Differentially Private Bayesian Tests. (arXiv:2401.15502v1 [stat.ML])

    [http://arxiv.org/abs/2401.15502](http://arxiv.org/abs/2401.15502)

    本文提出了一种差分隐私贝叶斯检验框架，利用规范化的数据生成机制来进行推断，并避免了对完整数据生成机制的建模需求。该框架具有可解释性，并在计算上具有实质性的优势。

    

    在利用机密数据进行科学假设检验的领域中，差分隐私已经成为一个重要的基石。在报告科学发现时，广泛采用贝叶斯检验，因为它们有效地避免了P值的主要批评，即缺乏可解释性和无法量化对竞争假设的支持证据。我们提出了一个新颖的差分隐私贝叶斯假设检验框架，该框架在基于规范化的数据生成机制基础上自然产生，从而保持了推断结果的可解释性。此外，通过专注于基于广泛使用的检验统计量的差分隐私贝叶斯因子，我们避免了对完整数据生成机制建模的需求，并确保了实质性的计算优势。我们还提供了一组充分条件，以在所提框架下确立贝叶斯因子一致性的结果。

    Differential privacy has emerged as an significant cornerstone in the realm of scientific hypothesis testing utilizing confidential data. In reporting scientific discoveries, Bayesian tests are widely adopted since they effectively circumnavigate the key criticisms of P-values, namely, lack of interpretability and inability to quantify evidence in support of the competing hypotheses. We present a novel differentially private Bayesian hypotheses testing framework that arise naturally under a principled data generative mechanism, inherently maintaining the interpretability of the resulting inferences. Furthermore, by focusing on differentially private Bayes factors based on widely used test statistics, we circumvent the need to model the complete data generative mechanism and ensure substantial computational benefits. We also provide a set of sufficient conditions to establish results on Bayes factor consistency under the proposed framework. The utility of the devised technology is showc
    
[^26]: 协方差均衡的近最优策略优化在一般性和的马尔可夫博弈中的应用

    Near-Optimal Policy Optimization for Correlated Equilibrium in General-Sum Markov Games. (arXiv:2401.15240v1 [cs.LG])

    [http://arxiv.org/abs/2401.15240](http://arxiv.org/abs/2401.15240)

    本文提出了一个协方差均衡的近最优策略优化算法，通过结合平滑价值更新和乐观实行者算法，以及对数障碍正则化器，实现了在一般性和的马尔可夫博弈中计算协方差均衡的近最优收敛速度$\tilde{O}(T^{-1})$。

    

    我们研究了用于计算多人一般性和的马尔可夫博弈中的协方差均衡的策略优化算法。之前的结果实现了$O(T^{-1/2})$收敛速度到协方差均衡和$O(T^{-3/4})$加速收敛速度到较弱的疏松协方差均衡。在本文中，我们通过提供一个非耦合策略优化算法，显著改进了这两个结果，使其达到计算协方差均衡的近最优$\tilde{O}(T^{-1})$收敛速度。我们的算法通过结合两个主要因素（i）平滑的价值更新和（ii）具有对数障碍正则化器的乐观实行者算法构建而成。

    We study policy optimization algorithms for computing correlated equilibria in multi-player general-sum Markov Games. Previous results achieve $O(T^{-1/2})$ convergence rate to a correlated equilibrium and an accelerated $O(T^{-3/4})$ convergence rate to the weaker notion of coarse correlated equilibrium. In this paper, we improve both results significantly by providing an uncoupled policy optimization algorithm that attains a near-optimal $\tilde{O}(T^{-1})$ convergence rate for computing a correlated equilibrium. Our algorithm is constructed by combining two main elements (i) smooth value updates and (ii) the optimistic-follow-the-regularized-leader algorithm with the log barrier regularizer.
    
[^27]: 可扩展的子二次时间网络重建

    Scalable network reconstruction in subquadratic time. (arXiv:2401.01404v1 [cs.DS])

    [http://arxiv.org/abs/2401.01404](http://arxiv.org/abs/2401.01404)

    这篇论文提出了一个可扩展的网络重建算法，能够在次二次时间内实现结果，通过随机的二阶邻居搜索产生最佳的边候选。

    

    网络重建是指在只有关于条件偶联的观测数据，例如时间序列或图模型的独立样本的情况下，确定N个节点之间未观测到的成对耦合。针对这个问题提出的算法的可扩展性的主要障碍是似乎无法避免的二次复杂度O(N^2)，即要考虑每种可能的成对耦合至少一次，尽管大多数感兴趣的网络都是稀疏的，非零耦合的数量只有O(N)。在这里，我们提出了一个适用于广泛重建问题的通用算法，其在子二次时间内实现结果，其数据相关复杂度宽松上界为O(N^(3/2)logN)，但具有更典型的对数线性复杂度O(Nlog^2 N)。我们的算法依赖于一个随机的二阶邻居搜索，产生了最佳的边候选。

    Network reconstruction consists in determining the unobserved pairwise couplings between $N$ nodes given only observational data on the resulting behavior that is conditioned on those couplings -- typically a time-series or independent samples from a graphical model. A major obstacle to the scalability of algorithms proposed for this problem is a seemingly unavoidable quadratic complexity of $O(N^2)$, corresponding to the requirement of each possible pairwise coupling being contemplated at least once, despite the fact that most networks of interest are sparse, with a number of non-zero couplings that is only $O(N)$. Here we present a general algorithm applicable to a broad range of reconstruction problems that achieves its result in subquadratic time, with a data-dependent complexity loosely upper bounded by $O(N^{3/2}\log N)$, but with a more typical log-linear complexity of $O(N\log^2N)$. Our algorithm relies on a stochastic second neighbor search that produces the best edge candidat
    
[^28]: 混合线性专家用于长期时间序列预测

    Mixture-of-Linear-Experts for Long-term Time Series Forecasting. (arXiv:2312.06786v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.06786](http://arxiv.org/abs/2312.06786)

    MoLE是一种混合线性专家模型，通过训练多个线性中心模型和一个路由模型，能够适应时间序列模式的周期性变化，并显著降低了预测误差。

    

    长期时间序列预测(LTSF)旨在预测给定过去值的时间序列的未来值。当前在这个问题上的最先进技术(SOTA)在某些情况下是由以线性为中心的模型实现的，这些模型主要具有线性映射层。然而，由于其固有的简单性，它们不能够适应时间序列模式的周期性变化。为了解决这个挑战，我们提出了一种混合专家风格的增强线性模型的方法，并提出了混合线性专家(MoLE)。MoLE不是训练单个模型，而是训练多个以线性为中心的模型(即专家)和一个权衡和混合其输出的路由模型。虽然整个框架是端到端训练的，但每个专家都学会专门处理特定的时间模式，而路由模型则学会自适应地组合专家们的输出。实验证明，MoLE降低了线性中心模型(DLinear，RLinear和RMLP)的预测误差。

    Long-term time series forecasting (LTSF) aims to predict future values of a time series given the past values. The current state-of-the-art (SOTA) on this problem is attained in some cases by linear-centric models, which primarily feature a linear mapping layer. However, due to their inherent simplicity, they are not able to adapt their prediction rules to periodic changes in time series patterns. To address this challenge, we propose a Mixture-of-Experts-style augmentation for linear-centric models and propose Mixture-of-Linear-Experts (MoLE). Instead of training a single model, MoLE trains multiple linear-centric models (i.e., experts) and a router model that weighs and mixes their outputs. While the entire framework is trained end-to-end, each expert learns to specialize in a specific temporal pattern, and the router model learns to compose the experts adaptively. Experiments show that MoLE reduces forecasting error of linear-centric models, including DLinear, RLinear, and RMLP, in 
    
[^29]: 论语言模型的水印可学习性研究

    On the Learnability of Watermarks for Language Models. (arXiv:2312.04469v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.04469](http://arxiv.org/abs/2312.04469)

    该论文研究了语言模型水印的可学习性，提出了水印蒸馏方法，通过训练学生模型使其模仿使用解码水印的教师模型的行为。结果表明，语言模型具有直接学习生成水印的能力，这对于水印的实际应用具有重要影响。

    

    语言模型输出的水印可以实现对模型生成文本的统计检测，广泛应用于语言模型的负责任部署中。现有的水印策略通过改变现有语言模型的解码器来操作，而语言模型直接学习生成水印的能力将对水印在实际应用中产生重要影响。首先，学习得到的水印可以用于构建能自然生成带水印文本的开放模型，使开放模型也能从水印中受益。其次，如果水印用于确定生成文本的来源，攻击者可以通过伪造水印并生成有害的带水印文本来损害受害模型的声誉。为了研究水印的可学习性，我们提出了水印蒸馏方法，该方法通过训练学生模型使其行为类似于使用基于解码的水印的教师模型。我们在三个实验数据集上测试了我们的方法。

    Watermarking of language model outputs enables statistical detection of model-generated text, which has many applications in the responsible deployment of language models. Existing watermarking strategies operate by altering the decoder of an existing language model, and the ability for a language model to directly learn to generate the watermark would have significant implications for the real-world deployment of watermarks. First, learned watermarks could be used to build open models that naturally generate watermarked text, allowing for open models to benefit from watermarking. Second, if watermarking is used to determine the provenance of generated text, an adversary can hurt the reputation of a victim model by spoofing its watermark and generating damaging watermarked text. To investigate the learnability of watermarks, we propose watermark distillation, which trains a student model to behave like a teacher model that uses decoding-based watermarking. We test our approach on three
    
[^30]: 语言模型作为语义索引器

    Language Models As Semantic Indexers. (arXiv:2310.07815v1 [cs.IR])

    [http://arxiv.org/abs/2310.07815](http://arxiv.org/abs/2310.07815)

    本文介绍了一种使用生成性语言模型学习语义ID的自监督框架LMINDEXER。

    

    语义标识符（ID）是信息检索中的一个重要概念，旨在保留对象（如文档和项）内部的语义。先前的研究通常采用两阶段流程来学习语义ID，首先使用现成的文本编码器获取嵌入，并根据嵌入来推导ID。然而，每个步骤都会引入潜在的信息损失，并且文本编码器生成的潜在空间内的嵌入分布通常与语义索引所需的预期分布存在固有的不匹配。然而，设计一个既能学习文档的语义表示又能同时学习其分层结构的方法并不容易，因为语义ID是离散和顺序结构的，并且语义监督是不充分的。在本文中，我们引入了LMINDEXER，它是一个自监督框架，用于使用生成性语言模型学习语义ID。

    Semantic identifier (ID) is an important concept in information retrieval that aims to preserve the semantics of objects such as documents and items inside their IDs. Previous studies typically adopt a two-stage pipeline to learn semantic IDs by first procuring embeddings using off-the-shelf text encoders and then deriving IDs based on the embeddings. However, each step introduces potential information loss and there is usually an inherent mismatch between the distribution of embeddings within the latent space produced by text encoders and the anticipated distribution required for semantic indexing. Nevertheless, it is non-trivial to design a method that can learn the document's semantic representations and its hierarchical structure simultaneously, given that semantic IDs are discrete and sequentially structured, and the semantic supervision is deficient. In this paper, we introduce LMINDEXER, a self-supervised framework to learn semantic IDs with a generative language model. We tackl
    
[^31]: 符合决策理论: 通过不完美的预测产生安全的自主决策

    Conformal Decision Theory: Safe Autonomous Decisions from Imperfect Predictions. (arXiv:2310.05921v1 [stat.ML])

    [http://arxiv.org/abs/2310.05921](http://arxiv.org/abs/2310.05921)

    符合决策理论是一种框架，可以通过不完美的机器学习预测产生安全的自主决策。该理论的创新之处在于可以在没有对世界模型做出任何假设的情况下提供具有低风险的统计保证的决策。

    

    我们介绍了一种符合决策理论的框架，可以在机器学习预测不完美的情况下产生安全的自主决策。这种决策的例子是普遍存在的，从依赖于行人预测的机器人规划算法，到校准自动化制造以实现高吞吐量和低错误率，再到在运行时选择信任名义策略还是切换到安全备份策略。我们算法产生的决策在统计保证的情况下是安全的，无需对世界模型作出任何假设；观测数据可以不满足独立同分布(I.I.D.)的条件，甚至可能是对抗性的。该理论将符合预测的结果扩展到直接校准决策，而不需要构建预测集合。实验证明了我们方法在围绕人类进行机器人运动规划、自动股票交易和机器人制造方面的实用性。

    We introduce Conformal Decision Theory, a framework for producing safe autonomous decisions despite imperfect machine learning predictions. Examples of such decisions are ubiquitous, from robot planning algorithms that rely on pedestrian predictions, to calibrating autonomous manufacturing to exhibit high throughput and low error, to the choice of trusting a nominal policy versus switching to a safe backup policy at run-time. The decisions produced by our algorithms are safe in the sense that they come with provable statistical guarantees of having low risk without any assumptions on the world model whatsoever; the observations need not be I.I.D. and can even be adversarial. The theory extends results from conformal prediction to calibrate decisions directly, without requiring the construction of prediction sets. Experiments demonstrate the utility of our approach in robot motion planning around humans, automated stock trading, and robot manufacturin
    
[^32]: "BrainSCUBA: 视觉皮层选择性的细粒度自然语言描述"

    BrainSCUBA: Fine-Grained Natural Language Captions of Visual Cortex Selectivity. (arXiv:2310.04420v1 [cs.LG])

    [http://arxiv.org/abs/2310.04420](http://arxiv.org/abs/2310.04420)

    "BrainSCUBA通过生成自然语言描述来预测最大激活个体感兴趣体素的图像，达到了细粒度的视觉皮层选择性描述。"

    

    "理解高级视觉皮层的功能组织是神经科学的核心关注点。过去的研究主要使用手动选择的刺激来映射神经群体的视觉和语义选择性，这可能会导致对视觉皮层功能的预设假设的结果偏差。我们引入了一种数据驱动的方法，通过生成自然语言描述来预测最大激活个体感兴趣体素的图像。我们的方法- 基于对比视觉-语言模型学到的丰富嵌入空间，并利用预训练的大型语言模型生成可解释的描述。我们通过高阶视觉区域进行了细粒度的体素级描述，并通过文本条件的图像合成验证了我们的方法，结果表明我们的图像在语义上是连贯的并且具有高的质量。"

    Understanding the functional organization of higher visual cortex is a central focus in neuroscience. Past studies have primarily mapped the visual and semantic selectivity of neural populations using hand-selected stimuli, which may potentially bias results towards pre-existing hypotheses of visual cortex functionality. Moving beyond conventional approaches, we introduce a data-driven method that generates natural language descriptions for images predicted to maximally activate individual voxels of interest. Our method -Semantic Captioning Using Brain Alignments ("BrainSCUBA") -- builds upon the rich embedding space learned by a contrastive vision-language model and utilizes a pre-trained large language model to generate interpretable captions. We validate our method through fine-grained voxel-level captioning across higher-order visual regions. We further perform text-conditioned image synthesis with the captions, and show that our images are semantically coherent and yield high pr
    
[^33]: 在非常边缘上对LLMs进行联邦微调：好、坏和丑(arXiv:2310.03150v1 [cs.LG])

    Federated Fine-Tuning of LLMs on the Very Edge: The Good, the Bad, the Ugly. (arXiv:2310.03150v1 [cs.LG])

    [http://arxiv.org/abs/2310.03150](http://arxiv.org/abs/2310.03150)

    本论文以硬件为中心，探讨了如何将LLMs引入现代边缘计算系统。通过联邦学习（FL）对FLAN-T5模型进行微调，并对其在文本摘要任务上的性能进行了评估。同时提供了硬件基准测试和与数据中心GPU的比较。

    

    大规模语言模型（LLM）和基础模型因为提供了改进自然语言处理、与数据交互和快速检索信息的新机会而受到欢迎。然而，训练或微调LLMs需要大量的数据，由于法律或技术限制可能难以访问，并且可能需要私有计算资源。联邦学习（FL）是一种旨在克服这些挑战并扩大深度学习应用数据访问的解决方案。本文采用硬件为中心的方法，探索了如何将LLMs引入现代边缘计算系统。我们对FLAN-T5模型系列进行微调，参数范围从80M到3B，并应用于文本摘要任务。我们提供了微观水平的硬件基准测试，将模型的FLOP利用率与最先进的数据中心GPU进行了比较，并研究了在实际条件下的网络利用率。我们的贡献具有两个方面：首先，我们评估了...

    Large Language Models (LLM) and foundation models are popular as they offer new opportunities for individuals and businesses to improve natural language processing, interact with data, and retrieve information faster. However, training or fine-tuning LLMs requires a vast amount of data, which can be challenging to access due to legal or technical restrictions and may require private computing resources. Federated Learning (FL) is a solution designed to overcome these challenges and expand data access for deep learning applications.  This paper takes a hardware-centric approach to explore how LLMs can be brought to modern edge computing systems. Our study fine-tunes the FLAN-T5 model family, ranging from 80M to 3B parameters, using FL for a text summarization task. We provide a micro-level hardware benchmark, compare the model FLOP utilization to a state-of-the-art data center GPU, and study the network utilization in realistic conditions. Our contribution is twofold: First, we evaluate
    
[^34]: 学习放松：在一系列线性系统实例中设置求解器参数

    Learning to Relax: Setting Solver Parameters Across a Sequence of Linear System Instances. (arXiv:2310.02246v1 [cs.LG])

    [http://arxiv.org/abs/2310.02246](http://arxiv.org/abs/2310.02246)

    本文提出了一种解决一系列线性系统实例中设置求解器参数的方法，通过使用在线学习算法选择参数，可以接近最佳总迭代次数的性能，而无需进行额外的矩阵计算。

    

    解决线性系统$Ax=b$是一种基本的科学计算原理，已经开发了许多求解器和预处理器。它们带有参数，其最佳值取决于要解决的系统，并且通常无法或成本过高以确定；因此在实践中使用次优启发式。我们考虑在需要解决许多相关线性系统的常见情况下，例如在单个数值模拟期间。在这种情况下，我们是否可以顺序选择参数，以获得接近最佳总迭代次数的性能，而无需进行额外的矩阵计算？对于过度轻松（SOR）这种标准求解器，我们回答肯定的。这种方法能够使用仅迭代次数作为反馈的赌徒在线学习算法，选择序列实例的参数，使得总成本接近最佳固定的ω值。

    Solving a linear system $Ax=b$ is a fundamental scientific computing primitive for which numerous solvers and preconditioners have been developed. These come with parameters whose optimal values depend on the system being solved and are often impossible or too expensive to identify; thus in practice sub-optimal heuristics are used. We consider the common setting in which many related linear systems need to be solved, e.g. during a single numerical simulation. In this scenario, can we sequentially choose parameters that attain a near-optimal overall number of iterations, without extra matrix computations? We answer in the affirmative for Successive Over-Relaxation (SOR), a standard solver whose parameter $\omega$ has a strong impact on its runtime. For this method, we prove that a bandit online learning algorithm -- using only the number of iterations as feedback -- can select parameters for a sequence of instances such that the overall cost approaches that of the best fixed $\omega$ as
    
[^35]: 通过Sobolev训练的二维Copula逼近变换：2-Cats网络

    Differential 2D Copula Approximating Transforms via Sobolev Training: 2-Cats Networks. (arXiv:2309.16391v1 [cs.LG])

    [http://arxiv.org/abs/2309.16391](http://arxiv.org/abs/2309.16391)

    本文介绍了一种通过Sobolev训练的2-Cats网络，它能够非参数地逼近任何二维Copula，并且在估计输出方面优于现有技术。

    

    Copula是一种强大的统计工具，用于捕捉数据维度之间的依赖关系。在应用Copula时，我们可以通过首先估计独立的边际分布（一个简单任务），然后估计连接边际的单个Copula函数C（一个困难任务）来估计多元分布函数。对于二维数据，Copula是一个形如C：(u，v)∈\mathbf{I}^2\rightarrow \mathbf{I}的二次增函数，其中\mathbf{I}=[0，1]。在本文中，我们展示了神经网络（NNs）如何能够非参数地逼近任何二维Copula。我们的方法被称为2-Cats，受到物理启发的神经网络和Sobolev训练文献的启发。我们不仅证明了我们能够比现有技术更好地估计2D Copula的输出，而且我们的方法是非参数的，并且符合Copula C的数学性质。

    Copulas are a powerful statistical tool that captures dependencies across data dimensions. When applying Copulas, we can estimate multivariate distribution functions by initially estimating independent marginals, an easy task, and then a single copulating function, $C$, to connect the marginals, a hard task. For two-dimensional data, a copula is a two-increasing function of the form $C: (u,v)\in \mathbf{I}^2 \rightarrow \mathbf{I}$, where $\mathbf{I} = [0, 1]$. In this paper, we show how Neural Networks (NNs) can approximate any two-dimensional copula non-parametrically. Our approach, denoted as 2-Cats, is inspired by the Physics-Informed Neural Networks and Sobolev Training literature. Not only do we show that we can estimate the output of a 2d Copula better than the state-of-the-art, our approach is non-parametric and respects the mathematical properties of a Copula $C$.
    
[^36]: CPLLM: 基于大规模语言模型的临床预测

    CPLLM: Clinical Prediction with Large Language Models. (arXiv:2309.11295v1 [cs.CL])

    [http://arxiv.org/abs/2309.11295](http://arxiv.org/abs/2309.11295)

    CPLLM是一种使用大规模语言模型进行临床疾病预测的方法。通过量化和提示来微调语言模型，利用患者的历史诊断记录来预测目标疾病的诊断结果。实验证明，CPLLM在各项指标上均超越了其他基线模型，显示出显著的改进。

    

    我们提出了一种使用大规模语言模型 (LLM) 进行临床疾病预测的方法，该方法包括对预训练的语言模型进行微调。我们利用量化和提示来微调LLM，任务是预测患者在下一次就诊或随后的诊断中是否会被诊断为目标疾病，并利用他们的历史诊断记录。我们将结果与多个基线模型进行了比较，包括逻辑回归、RETAIN和Med-BERT，后者是使用结构化电子病历数据进行疾病预测的当前最先进模型。实验结果显示，CPLLM在PR-AUC和ROC-AUC指标上均超过了所有测试模型，相比基线模型显示出显著的改进。

    We present Clinical Prediction with Large Language Models (CPLLM), a method that involves fine-tuning a pre-trained Large Language Model (LLM) for clinical disease prediction. We utilized quantization and fine-tuned the LLM using prompts, with the task of predicting whether patients will be diagnosed with a target disease during their next visit or in the subsequent diagnosis, leveraging their historical diagnosis records. We compared our results versus various baselines, including Logistic Regression, RETAIN, and Med-BERT, which is the current state-of-the-art model for disease prediction using structured EHR data. Our experiments have shown that CPLLM surpasses all the tested models in terms of both PR-AUC and ROC-AUC metrics, displaying noteworthy enhancements compared to the baseline models.
    
[^37]: 大型语言模型能够准确预测搜索者的偏好

    Large language models can accurately predict searcher preferences. (arXiv:2309.10621v1 [cs.IR])

    [http://arxiv.org/abs/2309.10621](http://arxiv.org/abs/2309.10621)

    大型语言模型可以通过从真实用户那里获取高质量的第一方数据来准确预测搜索者的偏好。

    

    相关性标签是评估和优化搜索系统的关键。获取大量相关性标签通常需要第三方标注人员，但存在低质量数据的风险。本论文介绍了一种改进标签质量的替代方法，通过从真实用户那里获得仔细反馈来获取高质量的第一方数据。

    Relevance labels, which indicate whether a search result is valuable to a searcher, are key to evaluating and optimising search systems. The best way to capture the true preferences of users is to ask them for their careful feedback on which results would be useful, but this approach does not scale to produce a large number of labels. Getting relevance labels at scale is usually done with third-party labellers, who judge on behalf of the user, but there is a risk of low-quality data if the labeller doesn't understand user needs. To improve quality, one standard approach is to study real users through interviews, user studies and direct feedback, find areas where labels are systematically disagreeing with users, then educate labellers about user needs through judging guidelines, training and monitoring. This paper introduces an alternate approach for improving label quality. It takes careful feedback from real users, which by definition is the highest-quality first-party gold data that 
    
[^38]: Fin-Fact:一种面向多模态金融事实核查和解释生成的基准数据集

    Fin-Fact: A Benchmark Dataset for Multimodal Financial Fact Checking and Explanation Generation. (arXiv:2309.08793v1 [cs.AI])

    [http://arxiv.org/abs/2309.08793](http://arxiv.org/abs/2309.08793)

    Fin-Fact是一个用于多模态金融事实核查和解释生成的基准数据集，通过提供专业的注释和证据，以及多模态信息源来增强事实性分析，从而打击金融领域的错误信息，促进透明度，并建立信任。

    

    金融领域的事实核查尚未充分探索，该领域缺乏高质量的数据集。本文提出了Fin-Fact，一种用于金融领域多模态事实核查的基准数据集。值得注意的是，它包括专业事实核查人员的注释和证据，提供专业知识和可信度。由于其多模态性质涵盖了文本和视觉内容，Fin-Fact提供了补充信息源，以增强事实性分析。其主要目标是在金融领域打击错误信息，促进透明度，并在财务报告和新闻传播中建立信任。通过提供有深度的解释，Fin-Fact使用户，包括领域专家和终端用户，能够理解事实核查决策的推理过程，验证声明的可信度，并促进对事实核查流程的信任。Fin-Fact数据集以及我们的实验代码可在https://github.com/IIT-DM/Fin-Fact/ 上找到。

    Fact-checking in financial domain is under explored, and there is a shortage of quality dataset in this domain. In this paper, we propose Fin-Fact, a benchmark dataset for multimodal fact-checking within the financial domain. Notably, it includes professional fact-checker annotations and justifications, providing expertise and credibility. With its multimodal nature encompassing both textual and visual content, Fin-Fact provides complementary information sources to enhance factuality analysis. Its primary objective is combating misinformation in finance, fostering transparency, and building trust in financial reporting and news dissemination. By offering insightful explanations, Fin-Fact empowers users, including domain experts and end-users, to understand the reasoning behind fact-checking decisions, validating claim credibility, and fostering trust in the fact-checking process. The Fin-Fact dataset, along with our experimental codes is available at https://github.com/IIT-DM/Fin-Fact/
    
[^39]: 委托分散机器学习中的数据收集

    Delegating Data Collection in Decentralized Machine Learning. (arXiv:2309.01837v1 [cs.LG])

    [http://arxiv.org/abs/2309.01837](http://arxiv.org/abs/2309.01837)

    这项研究在分散机器学习生态系统中研究了委托的数据收集问题，通过设计最优契约解决了模型质量评估的不确定性和对最优性能缺乏预先知识的挑战。

    

    受分散机器学习生态系统的出现的启发，我们研究了数据收集的委托问题。以契约理论为出发点，我们设计了解决两个基本机器学习挑战的最优和近似最优契约：模型质量评估的不确定性和对任何模型最优性能的缺乏知识。我们证明，通过简单的线性契约可以解决不确定性问题，即使委托人只有一个小的测试集，也能实现1-1/e的一等效用水平。此外，我们给出了委托人测试集大小的充分条件，可以达到对最优效用的逼近。为了解决对最优性能缺乏预先知识的问题，我们提出了一个凸问题，可以自适应和高效地计算最优契约。

    Motivated by the emergence of decentralized machine learning ecosystems, we study the delegation of data collection. Taking the field of contract theory as our starting point, we design optimal and near-optimal contracts that deal with two fundamental machine learning challenges: lack of certainty in the assessment of model quality and lack of knowledge regarding the optimal performance of any model. We show that lack of certainty can be dealt with via simple linear contracts that achieve 1-1/e fraction of the first-best utility, even if the principal has a small test set. Furthermore, we give sufficient conditions on the size of the principal's test set that achieves a vanishing additive approximation to the optimal utility. To address the lack of a priori knowledge regarding the optimal performance, we give a convex program that can adaptively and efficiently compute the optimal contract.
    
[^40]: 学习的视觉特征到文本解释

    Learned Visual Features to Textual Explanations. (arXiv:2309.00733v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2309.00733](http://arxiv.org/abs/2309.00733)

    本研究提出了一种名为TExplain的方法，将大型语言模型与预训练图像分类器的特征空间连接起来，通过生成解释性句子来理解分类器学习到的特征。该方法首次利用这些频繁单词揭示出分类器的决策过程，实现了检测虚假特征的能力。

    

    在机器学习领域，解释视觉模型学习到的特征一直是一个长期存在的挑战。为了解决这个问题，我们提出了一种新颖的方法，利用大型语言模型（LLMs）的能力来解释预训练图像分类器学习到的特征。我们的方法名为TExplain，通过训练一个神经网络在图像分类器的特征空间和LLMs之间建立连接来解决这个任务。然后，在推断过程中，我们的方法生成大量的句子来解释分类器对给定图像学习到的特征。这些句子然后用于提取最频繁的单词，从而全面理解分类器中学习到的特征和模式。我们的方法首次利用与视觉表示对应的这些频繁单词来揭示独立训练的分类器的决策过程，从而实现检测虚假特征的能力。

    Interpreting the learned features of vision models has posed a longstanding challenge in the field of machine learning. To address this issue, we propose a novel method that leverages the capabilities of large language models (LLMs) to interpret the learned features of pre-trained image classifiers. Our method, called TExplain, tackles this task by training a neural network to establish a connection between the feature space of image classifiers and LLMs. Then, during inference, our approach generates a vast number of sentences to explain the features learned by the classifier for a given image. These sentences are then used to extract the most frequent words, providing a comprehensive understanding of the learned features and patterns within the classifier. Our method, for the first time, utilizes these frequent words corresponding to a visual representation to provide insights into the decision-making process of the independently trained classifier, enabling the detection of spurious
    
[^41]: 一种适用于隐式多任务强化学习问题的策略适应方法

    A Policy Adaptation Method for Implicit Multitask Reinforcement Learning Problems. (arXiv:2308.16471v1 [cs.RO])

    [http://arxiv.org/abs/2308.16471](http://arxiv.org/abs/2308.16471)

    本研究提出了一种适用于动态运动生成任务的多任务强化学习算法，可用于适应单个运动类别中的隐式变化，并在头球任务中取得良好的适应效果。

    

    在动态运动生成任务中，包括接触和碰撞，策略参数的小改变可能导致极其不同的回报。例如，在足球中，通过稍微改变踢球位置或施加球的力或者球的摩擦力发生变化，球可以以完全不同的方向飞行。然而，很难想象在不同的方向上头球需要完全不同的技能。在本研究中，我们提出了一种多任务强化学习算法，用于在单个运动类别中适应目标或环境的隐式变化，包括不同的奖励函数或环境的物理参数。我们利用单脚机器人模型对所提出的方法进行了评估，在头球任务中取得了良好的适应效果。结果表明，所提出的方法可以适应目标位置的隐式变化或球的恢复系数的变化，而标准的领域随机化方法则不能。

    In dynamic motion generation tasks, including contact and collisions, small changes in policy parameters can lead to extremely different returns. For example, in soccer, the ball can fly in completely different directions with a similar heading motion by slightly changing the hitting position or the force applied to the ball or when the friction of the ball varies. However, it is difficult to imagine that completely different skills are needed for heading a ball in different directions. In this study, we proposed a multitask reinforcement learning algorithm for adapting a policy to implicit changes in goals or environments in a single motion category with different reward functions or physical parameters of the environment. We evaluated the proposed method on the ball heading task using a monopod robot model. The results showed that the proposed method can adapt to implicit changes in the goal positions or the coefficients of restitution of the ball, whereas the standard domain randomi
    
[^42]: 具有平滑激活函数的两层神经网络的存储容量研究

    Memory capacity of two layer neural networks with smooth activations. (arXiv:2308.02001v1 [cs.LG])

    [http://arxiv.org/abs/2308.02001](http://arxiv.org/abs/2308.02001)

    研究发现，具有平滑激活函数的两层神经网络的存储容量下界为md/2，并且准确性大致为2倍。分析存储容量的方法包括计算网络雅可比矩阵的秩，并扩展了有关Hadamard幂秩的经典线性代数事实。

    

    确定具有m个隐藏神经元和输入维数d（即md+m个训练参数）的两层神经网络的存储容量，即网络能够记忆的一般数据的最大尺寸，是一个基本的机器学习问题。对于非多项式实解析激活函数，如sigmoid和平滑的修正线性单元（平滑ReLU），我们建立了md/2的下界，并且准确性大约为2倍。类似的先前结果仅限于阶跃函数和ReLU激活函数，对于平滑激活函数的结果受到对数因子和随机数据的限制。为了分析存储容量，我们通过计算涉及Hadamard幂和Khati-Rao积的矩阵的秩来考察网络雅可比矩阵的秩。我们的计算扩展了关于Hadamard幂秩的经典线性代数事实。总体而言，我们的方法与之前关于存储容量的研究不同，并有希望实现。

    Determining the memory capacity of two-layer neural networks with m hidden neurons and input dimension d (i.e., md+m total trainable parameters), which refers to the largest size of general data the network can memorize, is a fundamental machine-learning question. For non-polynomial real analytic activation functions, such as sigmoids and smoothed rectified linear units (smoothed ReLUs), we establish a lower bound of md/2 and optimality up to a factor of approximately 2. Analogous prior results were limited to Heaviside and ReLU activations, with results for smooth activations suffering from logarithmic factors and requiring random data. To analyze the memory capacity, we examine the rank of the network's Jacobian by computing the rank of matrices involving both Hadamard powers and the Khati-Rao product. Our computation extends classical linear algebraic facts about the rank of Hadamard powers. Overall, our approach differs from previous works on memory capacity and holds promise for e
    
[^43]: 自适应带有自动调整客户端的联邦学习

    Adaptive Federated Learning with Auto-Tuned Clients. (arXiv:2306.11201v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.11201](http://arxiv.org/abs/2306.11201)

    本研究提出了一种自适应的联邦学习方法，其中包括了自动调整客户端的步长规则。实证结果表明，这种方法在各种联邦学习场景中具有显著的优势。

    

    联邦学习（FL）是一种分布式机器学习框架，通过参与的客户端在不共享数据的情况下，通过多次协作步骤训练中央服务器的全局模型。虽然FL是一个灵活的框架，其中本地数据的分布、参与率和每个客户端的计算能力可能大大变化，但这种灵活性也带来了许多新的挑战，特别是在客户端的超参数调整方面。我们提出了$\Delta$-SGD，这是一种简单的SGD步长规则，使每个客户端能够通过适应该客户端正在优化的函数的局部平滑性来使用自己的步长。我们提供了理论和实证结果，展示了客户端适应性在各种FL场景中的好处。

    Federated learning (FL) is a distributed machine learning framework where the global model of a central server is trained via multiple collaborative steps by participating clients without sharing their data. While being a flexible framework, where the distribution of local data, participation rate, and computing power of each client can greatly vary, such flexibility gives rise to many new challenges, especially in the hyperparameter tuning on the client side. We propose $\Delta$-SGD, a simple step size rule for SGD that enables each client to use its own step size by adapting to the local smoothness of the function each client is optimizing. We provide theoretical and empirical results where the benefit of the client adaptivity is shown in various FL scenarios.
    
[^44]: 在线动态子模规划优化

    Online Dynamic Submodular Optimization. (arXiv:2306.10835v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2306.10835](http://arxiv.org/abs/2306.10835)

    该论文介绍了在线动态子模规划优化问题，并提出了在线子模贪婪算法（OSGA）和在线子模映射梯度下降（OSPGD）算法以解决此类问题。实验结果表明，这些算法在不同的电力系统中表现良好。

    

    我们提出了一种新的具有可证明性能的算法，用于处理满足一般约束条件和动态环境下的在线二元优化问题。我们考虑了目标函数为子模规划的问题子集。我们提出了在线子模贪婪算法（OSGA），该算法通过求解先前轮损失函数的近似值来避免原问题的NP-困难性。我们将OSGA扩展为通用的近似函数。我们证明了OSGA在时间长度和累积轮次最优变化方面具有与在线凸优化中最严格边界相似的动态遗憾界。对于没有近似解或需要更简单的实现的情况，我们设计了在线子模映射梯度下降（OSPGD）算法，利用Lova\'sz扩展。我们得到了类似于传统在线梯度下降（OGD）的遗憾界。最后，我们在两个电力系统中对算法进行了数值测试。

    We propose new algorithms with provable performance for online binary optimization subject to general constraints and in dynamic settings. We consider the subset of problems in which the objective function is submodular. We propose the online submodular greedy algorithm (OSGA) which solves to optimality an approximation of the previous round loss function to avoid the NP-hardness of the original problem. We extend OSGA to a generic approximation function. We show that OSGA has a dynamic regret bound similar to the tightest bounds in online convex optimization with respect to the time horizon and the cumulative round optimum variation. For instances where no approximation exists or a computationally simpler implementation is desired, we design the online submodular projected gradient descent (OSPGD) by leveraging the Lova\'sz extension. We obtain a regret bound that is akin to the conventional online gradient descent (OGD). Finally, we numerically test our algorithms in two power system
    
[^45]: 一种基于概率框架的模块化增量学习方法

    A Probabilistic Framework for Modular Continual Learning. (arXiv:2306.06545v1 [cs.LG])

    [http://arxiv.org/abs/2306.06545](http://arxiv.org/abs/2306.06545)

    本文提出了一种名为PICLE的模块化增量学习框架，利用概率模型快速计算每个组合的适应度来加速搜索，是第一个可以实现不同类型的转移的模块化增量学习算法。

    

    模块化方法是增量学习领域的有前途方向，每个问题使用不同的模块组合且避免遗忘。然而，搜索可能的模块组合是一个挑战，因为评估组合性能需要一轮神经网络训练。为了解决这个问题，我们发展了一种名为PICLE的模块化增量学习框架，通过使用概率模型来快速计算每个组合的适应度来加速搜索。模型结合先前关于良好模块组合的知识与数据集特定信息。它的使用被分为感知和潜在子集等子集的搜索空间加以补充。我们展示了PICLE是第一个可以实现不同类型的转移的模块化增量学习算法，同时还能扩展到大型搜索空间。我们在两个基准套件上对其进行评估，这些套件旨在捕捉增量学习技术的不同要求。

    Modular approaches, which use a different composition of modules for each problem and avoid forgetting by design, have been shown to be a promising direction in continual learning (CL). However, searching through the large, discrete space of possible module compositions is a challenge because evaluating a composition's performance requires a round of neural network training. To address this challenge, we develop a modular CL framework, called PICLE, that accelerates search by using a probabilistic model to cheaply compute the fitness of each composition. The model combines prior knowledge about good module compositions with dataset-specific information. Its use is complemented by splitting up the search space into subsets, such as perceptual and latent subsets. We show that PICLE is the first modular CL algorithm to achieve different types of transfer while scaling to large search spaces. We evaluate it on two benchmark suites designed to capture different desiderata of CL techniques. 
    
[^46]: 论大型语言模型水印的可靠性

    On the Reliability of Watermarks for Large Language Models. (arXiv:2306.04634v1 [cs.LG])

    [http://arxiv.org/abs/2306.04634](http://arxiv.org/abs/2306.04634)

    本文研究了大型语言模型水印在混合其他文本来源时的可靠性，并提供了在实际应用中的建议。

    

    大型语言模型(LLMs)已经开始应用于日常使用，并有能力在未来的十年内产生大量的文本。机器生成的文本可能会取代互联网上的人类写作文本，并有可能被用于恶意目的，如钓鱼攻击和社交媒体机器人。水印是一种简单有效的策略，通过使LLM生成的文本可检测和可记录，来降低这些伤害。然而，一个关键问题仍然存在：在现实中混合了其他的文本来源，被人类写作者或其他语言模型改写，被用于社交和技术领域的各种应用时，水印在实际设置中的可靠性如何？在本文中，我们探讨了不同的检测方案，量化了它们检测水印的能力，并确定在每个情况下需要观察多少机器生成的文本才能可靠地检测水印。我们特别强调了当水印与其他文本来源混合时水印的可靠性，并提供了未来使用LLM生成的文本水印的建议。

    Large language models (LLMs) are now deployed to everyday use and positioned to produce large quantities of text in the coming decade. Machine-generated text may displace human-written text on the internet and has the potential to be used for malicious purposes, such as spearphishing attacks and social media bots. Watermarking is a simple and effective strategy for mitigating such harms by enabling the detection and documentation of LLM-generated text. Yet, a crucial question remains: How reliable is watermarking in realistic settings in the wild? There, watermarked text might be mixed with other text sources, paraphrased by human writers or other language models, and used for applications in a broad number of domains, both social and technical. In this paper, we explore different detection schemes, quantify their power at detecting watermarks, and determine how much machine-generated text needs to be observed in each scenario to reliably detect the watermark. We especially highlight o
    
[^47]: 线性函数逼近下的策略评估的高概率样本复杂度

    Sharp high-probability sample complexities for policy evaluation with linear function approximation. (arXiv:2305.19001v1 [stat.ML])

    [http://arxiv.org/abs/2305.19001](http://arxiv.org/abs/2305.19001)

    本文研究线性函数逼近下的策略评估问题，提出了两个广泛使用的算法所需的样本复杂度，具有高概率收敛保证且与容差水平的关联性最佳。

    

    本文涉及使用线性函数逼近在无限时间马尔可夫决策过程中进行策略评估的问题。我们研究了两种广泛使用的策略评估算法（时间差分学习算法和带有梯度校正的两个时间尺度线性时间差分算法）所需的样本复杂度，以保证最佳线性系数的预定义估计误差。在策略设置和离线设置中，我们建立了第一个具有高概率收敛保证的样本复杂度界限，达到了与容差水平的最佳关联性。我们还展示了与问题相关量明确的关系，并在策略设置中展示了我们的上限界限与关键问题参数上的极小极大下限界限相匹配。

    This paper is concerned with the problem of policy evaluation with linear function approximation in discounted infinite horizon Markov decision processes. We investigate the sample complexities required to guarantee a predefined estimation error of the best linear coefficients for two widely-used policy evaluation algorithms: the temporal difference (TD) learning algorithm and the two-timescale linear TD with gradient correction (TDC) algorithm. In both the on-policy setting, where observations are generated from the target policy, and the off-policy setting, where samples are drawn from a behavior policy potentially different from the target policy, we establish the first sample complexity bound with high-probability convergence guarantee that attains the optimal dependence on the tolerance level. We also exhihit an explicit dependence on problem-related quantities, and show in the on-policy setting that our upper bound matches the minimax lower bound on crucial problem parameters, in
    
[^48]: 带有未观察变量的因果关系发现：一种代理变量方法

    Causal Discovery with Unobserved Variables: A Proxy Variable Approach. (arXiv:2305.05281v1 [stat.ME])

    [http://arxiv.org/abs/2305.05281](http://arxiv.org/abs/2305.05281)

    本文提出了一种基于代理变量的方法，以解决因未观察变量而在观测数据中导致错误识别的问题。该方法可适用于连续变量系统，通过提出正则条件控制离散化误差来识别因果关系。

    

    从观测数据中发现因果关系具有重要意义。未观察变量（例如潜在混杂或中介）的存在可能会导致错误的因果识别。为了克服这个问题，近端因果探索方法试图通过未观察变量的代理来调整偏差。特别地，基于假设检验的方法通过测试引发的线性违规来识别因果边缘。然而，这些方法只适用于有严格级别约束的离散数据，这限制了它们在现实世界中的应用。本文通过扩展近端假设检验来解决这个问题，以适用于由连续变量组成的系统。我们的策略是提出给定隐藏因子的观测变量的条件分布的正则条件，使得如果我们将其观察代理以足够的有限细格离散化，则涉及的离散化误差可以有效地受到控制。基于这个方法，我们提出并分析了一种具有一般先验限制的新近端因果搜索算法。

    Discovering causal relations from observational data is important. The existence of unobserved variables (e.g. latent confounding or mediation) can mislead the causal identification. To overcome this problem, proximal causal discovery methods attempted to adjust for the bias via the proxy of the unobserved variable. Particularly, hypothesis test-based methods proposed to identify the causal edge by testing the induced violation of linearity. However, these methods only apply to discrete data with strict level constraints, which limits their practice in the real world. In this paper, we fix this problem by extending the proximal hypothesis test to cases where the system consists of continuous variables. Our strategy is to present regularity conditions on the conditional distributions of the observed variables given the hidden factor, such that if we discretize its observed proxy with sufficiently fine, finite bins, the involved discretization error can be effectively controlled. Based o
    
[^49]: 持续扩散：使用C-LoRA进行文本到图像扩散的持续定制

    Continual Diffusion: Continual Customization of Text-to-Image Diffusion with C-LoRA. (arXiv:2304.06027v1 [cs.CV])

    [http://arxiv.org/abs/2304.06027](http://arxiv.org/abs/2304.06027)

    本文提出了一种新方法C-LoRA，用于持续自定制文本到图像扩散模型，并避免了新概念加入后过去相似概念的图像质量下降的问题。

    

    最近的研究表明，在只提供少量示例图像的情况下，自定义文本到图像扩散模型具有显着的能力。我们的研究表明，当使用多个细粒度概念以连续方式（即持续性地）自定义这样的模型时，最近的文本到图像定制技术会遭受灾难性的遗忘。为了解决这个问题，我们提出了一种新方法，C-LoRA，采用流行的稳定扩散模型中的跨注意力层中的连续自我正则化低秩适应。此外，我们使用不包括自定义对象的单词（即“人”用于人脸数据集）并初始化为完全随机嵌入的定制提示。重要的是，我们的方法只引入了微小的额外参数成本。

    Recent works demonstrate a remarkable ability to customize text-to-image diffusion models while only providing a few example images. What happens if you try to customize such models using multiple, fine-grained concepts in a sequential (i.e., continual) manner? In our work, we show that recent state-of-the-art customization of text-to-image models suffer from catastrophic forgetting when new concepts arrive sequentially. Specifically, when adding a new concept, the ability to generate high quality images of past, similar concepts degrade. To circumvent this forgetting, we propose a new method, C-LoRA, composed of a continually self-regularized low-rank adaptation in cross attention layers of the popular Stable Diffusion model. Furthermore, we use customization prompts which do not include the word of the customized object (i.e., "person" for a human face dataset) and are initialized as completely random embeddings. Importantly, our method induces only marginal additional parameter cost
    
[^50]: Skeleton Regression：一种基于流形结构估计的基于图形的方法。

    Skeleton Regression: A Graph-Based Approach to Estimation with Manifold Structure. (arXiv:2303.11786v1 [cs.LG])

    [http://arxiv.org/abs/2303.11786](http://arxiv.org/abs/2303.11786)

    这是一个处理低维流形数据的回归框架，首先通过构建图形骨架来捕捉潜在的流形几何结构，然后在其上运用非参数回归技术来估计回归函数，除了具有非参数优点之外，在处理多个流形数据，嘈杂观察时也表现出较好的鲁棒性。

    

    我们引入了一个新的回归框架，旨在处理围绕低维流形的复杂数据。我们的方法首先构建一个图形表示，称为骨架，以捕获潜在的几何结构。然后，我们在骨架图上定义指标，应用非参数回归技术，以及基于图形的特征转换来估计回归函数。除了包括的非参数方法外，我们还讨论了一些非参数回归器在骨架图等一般度量空间方面的限制。所提出的回归框架使我们能够避开维度灾难，具有可以处理多个流形的并集并且鲁棒性能应对加性噪声和嘈杂观察的额外优势。我们为所提出的方法提供了统计保证，并通过模拟和实际数据示例证明了其有效性。

    We introduce a new regression framework designed to deal with large-scale, complex data that lies around a low-dimensional manifold. Our approach first constructs a graph representation, referred to as the skeleton, to capture the underlying geometric structure. We then define metrics on the skeleton graph and apply nonparametric regression techniques, along with feature transformations based on the graph, to estimate the regression function. In addition to the included nonparametric methods, we also discuss the limitations of some nonparametric regressors with respect to the general metric space such as the skeleton graph. The proposed regression framework allows us to bypass the curse of dimensionality and provides additional advantages that it can handle the union of multiple manifolds and is robust to additive noise and noisy observations. We provide statistical guarantees for the proposed method and demonstrate its effectiveness through simulations and real data examples.
    
[^51]: 大型语言模型的水印技术

    A Watermark for Large Language Models. (arXiv:2301.10226v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.10226](http://arxiv.org/abs/2301.10226)

    本文提出了一种在大型语言模型中实现水印技术的方法，该技术可以在不降低文本质量的前提下嵌入信号，且可以使用高效的开源算法进行检测，并且该技术十分鲁棒和安全。

    

    通过在生成的文本中嵌入信号，即将水印技术应用于模型输出，可以减轻大型语言模型潜在的危害。我们提出了一种专有语言模型的水印技术框架。水印可以嵌入到文本中，对文本质量的影响可以忽略不计，并且可以使用高效的开源算法在不访问语言模型API或参数的情况下进行检测。水印技术通过在生成单词之前选择一组随机的“绿色”标记，然后在抽样过程中软性地推广使用这些标记。我们提出了一个可解释的P值统计检验方法，用于检测水印技术， 并推导了一个信息论框架来分析水印技术的敏感性。我们使用Open Pretrained Transformer（OPT）家族的一个数十亿参数模型来测试水印技术，并讨论了其鲁棒性和安全性。

    Potential harms of large language models can be mitigated by watermarking model output, i.e., embedding signals into generated text that are invisible to humans but algorithmically detectable from a short span of tokens. We propose a watermarking framework for proprietary language models. The watermark can be embedded with negligible impact on text quality, and can be detected using an efficient open-source algorithm without access to the language model API or parameters. The watermark works by selecting a randomized set of "green" tokens before a word is generated, and then softly promoting use of green tokens during sampling. We propose a statistical test for detecting the watermark with interpretable p-values, and derive an information-theoretic framework for analyzing the sensitivity of the watermark. We test the watermark using a multi-billion parameter model from the Open Pretrained Transformer (OPT) family, and discuss robustness and security.
    
[^52]: 具有谱正则化的核双样本检验

    Spectral Regularized Kernel Two-Sample Tests. (arXiv:2212.09201v2 [math.ST] UPDATED)

    [http://arxiv.org/abs/2212.09201](http://arxiv.org/abs/2212.09201)

    本文研究了基于概率分布的再生核希尔伯特空间嵌入的双样本检验的最优性。我们发现最大均值差异（MMD）检验在分离边界方面并不是最优的，因此我们提出了一种基于谱正则化的修改方法，使得检验具有更小的分离边界。同时，我们还提出了自适应版本的检验，通过数据驱动的策略选择正则化参数，展示了其近乎最优的性能。

    

    在过去的十年中，一种在非参数检验问题中广受欢迎的方法是基于概率分布的再生核希尔伯特空间（RKHS）嵌入的概念来处理一般（即非欧几里得）域上的问题。我们工作的主要目标是理解基于这种方法构建的双样本检验的最优性。首先，我们展示了流行的最大均值差异（MMD）双样本检验在Hellinger距离下的分离边界方面并不是最优的。其次，我们提出了一种基于谱正则化的MMD检验修改方法，通过考虑协方差信息（MMD检验无法捕获），证明了所提出的检验具有比MMD检验更小的分离边界的极小极大最优性。第三，我们提出了上述检验的自适应版本，其中涉及一种数据驱动策略来选择正则化参数，并展示了自适应检验几乎是最优的。

    Over the last decade, an approach that has gained a lot of popularity to tackle non-parametric testing problems on general (i.e., non-Euclidean) domains is based on the notion of reproducing kernel Hilbert space (RKHS) embedding of probability distributions. The main goal of our work is to understand the optimality of two-sample tests constructed based on this approach. First, we show that the popular MMD (maximum mean discrepancy) two-sample test is not optimal in terms of the separation boundary measured in Hellinger distance. Second, we propose a modification to the MMD test based on spectral regularization by taking into account the covariance information (which is not captured by the MMD test) and prove the proposed test to be minimax optimal with a smaller separation boundary than that achieved by the MMD test. Third, we propose an adaptive version of the above test which involves a data-driven strategy to choose the regularization parameter and show the adaptive test to be almos
    
[^53]: 解缠表示学习

    Disentangled Representation Learning. (arXiv:2211.11695v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.11695](http://arxiv.org/abs/2211.11695)

    解缠表示学习旨在学习一个模型，能够识别和解缠观测数据中隐藏的因素，从而产生可解释的数据表示。它在提高模型可解释性、可控性、鲁棒性和泛化能力方面具有广泛的应用潜力。

    

    解缠表示学习（DRL）旨在学习一个能够识别和解缠可观测数据中隐藏因素的模型。将变化的潜在要素分离成具有语义意义的变量的过程有助于学习可解释的数据表示，模仿人类观察对象或关系时的有意义理解过程。作为一种通用的学习策略，DRL在多个领域中展示了提高模型可解释性、可控性、鲁棒性以及泛化能力的优势，如计算机视觉、自然语言处理、数据挖掘等。本文综合评述了DRL的各个方面，包括动机、定义、方法论、评估、应用和模型设计。我们讨论了基于两个公认定义（直观定义和群论定义）的DRL方法。我们进一步分析了DRL的开展。

    Disentangled Representation Learning (DRL) aims to learn a model capable of identifying and disentangling the underlying factors hidden in the observable data in representation form. The process of separating underlying factors of variation into variables with semantic meaning benefits in learning explainable representations of data, which imitates the meaningful understanding process of humans when observing an object or relation. As a general learning strategy, DRL has demonstrated its power in improving the model explainability, controlability, robustness, as well as generalization capacity in a wide range of scenarios such as computer vision, natural language processing, data mining etc. In this article, we comprehensively review DRL from various aspects including motivations, definitions, methodologies, evaluations, applications and model designs. We discuss works on DRL based on two well-recognized definitions, i.e., Intuitive Definition and Group Theory Definition. We further ca
    
[^54]: TAX-Pose：机器人操作的任务特定跨姿势估计

    TAX-Pose: Task-Specific Cross-Pose Estimation for Robot Manipulation. (arXiv:2211.09325v2 [cs.RO] CROSS LISTED)

    [http://arxiv.org/abs/2211.09325](http://arxiv.org/abs/2211.09325)

    本论文提出了一种名为TAX-Pose的系统，在机器人操作中实现了任务特定跨姿势的估计。通过学习对象之间的对应关系，这种系统能够在给定操作任务的情况下准确估计两个对象之间的跨姿势，并利用估计结果指导下游的运动规划。

    

    我们如何赋予机器人有效地操作未知物体的能力，并基于示范转移相关技能？端到端学习方法通常无法泛化到新的物体或未见过的配置。相反，我们关注交互对象相关部分的任务特定姿势关系。我们推测这种关系是一种可以转移到同一类别新物体的操作任务的可泛化概念；例如，平底锅相对于烤箱的姿势关系或者杯子相对于杯架的姿势关系。我们称这种任务特定姿势关系为“跨姿势”，并提供了该概念的数学定义。我们提出了一个基于视觉的系统，使用学习的对象间对应关系来学习估计给定操作任务的两个对象之间的跨姿势。然后，估计的跨姿势用于引导下游的运动规划器将对象操纵到所需的姿势。

    How do we imbue robots with the ability to efficiently manipulate unseen objects and transfer relevant skills based on demonstrations? End-to-end learning methods often fail to generalize to novel objects or unseen configurations. Instead, we focus on the task-specific pose relationship between relevant parts of interacting objects. We conjecture that this relationship is a generalizable notion of a manipulation task that can transfer to new objects in the same category; examples include the relationship between the pose of a pan relative to an oven or the pose of a mug relative to a mug rack. We call this task-specific pose relationship "cross-pose" and provide a mathematical definition of this concept. We propose a vision-based system that learns to estimate the cross-pose between two objects for a given manipulation task using learned cross-object correspondences. The estimated cross-pose is then used to guide a downstream motion planner to manipulate the objects into the desired po
    
[^55]: 用于理解神经网络动态的二次模型

    Quadratic models for understanding neural network dynamics. (arXiv:2205.11787v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.11787](http://arxiv.org/abs/2205.11787)

    神经二次模型可以展示出神经网络在大学习率情况下的“弹弓阶段”，并且在泛化特性上与神经网络有相似之处，是分析神经网络的有效工具。

    

    当神经网络的宽度增加时，可以用线性模型来逼近神经网络，但宽神经网络的某些特性不能被线性模型捕捉。在这项工作中，我们展示了最近提出的神经二次模型可以展示“弹弓阶段”[Lewkowycz等人，2020]，当使用大学习率训练此类模型时会出现。接着，我们经验证明，神经二次模型的行为与神经网络在泛化特性上有相似之处，尤其是在弹弓阶段范围内。我们的分析进一步表明，二次模型可以成为分析神经网络的有效工具。

    While neural networks can be approximated by linear models as their width increases, certain properties of wide neural networks cannot be captured by linear models. In this work we show that recently proposed Neural Quadratic Models can exhibit the "catapult phase" [Lewkowycz et al. 2020] that arises when training such models with large learning rates. We then empirically show that the behaviour of neural quadratic models parallels that of neural networks in generalization, especially in the catapult phase regime. Our analysis further demonstrates that quadratic models can be an effective tool for analysis of neural networks.
    
[^56]: McDiarmid不等式的推广

    An extension of McDiarmid's inequality. (arXiv:1511.05240v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1511.05240](http://arxiv.org/abs/1511.05240)

    本文推广了McDiarmid不等式，使其适用于具有有界差异的函数，并进一步将结果推广到一般度量空间的集中性。

    

    我们使用推广论证推广McDiarmid不等式，使它适用于具有有界差异的函数，并且适用于高概率集合。这些函数集中于它们的条件期望周围。我们进一步将结果推广到一般度量空间的集中性。

    We generalize McDiarmid's inequality for functions with bounded differences on a high probability set, using an extension argument. Those functions concentrate around their conditional expectations. We further extend the results to concentration in general metric spaces.
    

