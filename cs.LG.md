# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Learning Collective Variables for Protein Folding with Labeled Data Augmentation through Geodesic Interpolation](https://rss.arxiv.org/abs/2402.01542) | 本实验提出了一种使用标记数据增强和测地插值方法学习蛋白质折叠的集体变量的策略，有效提高了采样效率，并在过渡态数据有限且嘈杂时表现优于基于分类器的方法。 |
| [^2] | [Multi-intention Inverse Q-learning for Interpretable Behavior Representation](https://rss.arxiv.org/abs/2311.13870) | 本研究引入了一种多意图逆Q学习算法，用于解决在推断离散时变奖励时的挑战。通过聚类观察到的专家轨迹并独立解决每个意图的逆强化学习问题，我们的方法在动物行为预测方面超越了当前的基准，产生了可解释的奖励函数。 |
| [^3] | [MedCLIP-SAM: Bridging Text and Image Towards Universal Medical Image Segmentation](https://arxiv.org/abs/2403.20253) | 提出了MedCLIP-SAM框架，结合了CLIP和SAM模型，实现使用少量标记数据的临床图像分割 |
| [^4] | [TFB: Towards Comprehensive and Fair Benchmarking of Time Series Forecasting Methods](https://arxiv.org/abs/2403.20150) | TFB通过解决数据领域覆盖不足、对传统方法的刻板印象以及不一致、不灵活的流程等问题，推动了时间序列预测方法基准比较的最新技术发展。 |
| [^5] | [MambaMixer: Efficient Selective State Space Models with Dual Token and Channel Selection](https://arxiv.org/abs/2403.19888) | MambaMixer是一种新的架构，提出了具有数据依赖权重的双重选择机制，称为选择性标记和通道混合器，对长序列建模具有潜在优势。 |
| [^6] | [Detecting Generative Parroting through Overfitting Masked Autoencoders](https://arxiv.org/abs/2403.19050) | 本研究提出利用过拟合的遮蔽自编码器(MAE)来检测生成模型中的生成性模仿，建立了基于训练数据集损失的检测阈值，为了确保生成模型的合法使用和提升其法律合规性提供了一种新方法。 |
| [^7] | [Learning-based Multi-continuum Model for Multiscale Flow Problems](https://arxiv.org/abs/2403.14084) | 提出了一种基于学习的多连续体模型，用于改进多尺度问题中单一连续体模型的准确性 |
| [^8] | [Multimodal Variational Autoencoder for Low-cost Cardiac Hemodynamics Instability Detection](https://arxiv.org/abs/2403.13658) | 提出了一种新颖的多模态变分自编码器（$\text{CardioVAE}_\text{X,G}$），将低成本胸部X射线（CXR）和心电图（ECG）数据形式整合起来，并实现了共享特征和独特特征的学习。 |
| [^9] | [Listenable Maps for Audio Classifiers](https://arxiv.org/abs/2403.13086) | 引入了一种名为Listenable Maps for Audio Classifiers (L-MAC)的可听图方法，用于生成忠实且可听的音频分类器解释。 |
| [^10] | [HumanoidBench: Simulated Humanoid Benchmark for Whole-Body Locomotion and Manipulation](https://arxiv.org/abs/2403.10506) | 提出了一个高维度的仿真机器人学习基准测试HumanoidBench，揭示了目前最先进的强化学习算法在大多数任务上面临挑战，而具备鲁棒低级策略支持的分层学习基线表现更优秀。 |
| [^11] | [EquiAV: Leveraging Equivariance for Audio-Visual Contrastive Learning](https://arxiv.org/abs/2403.09502) | 这项研究提出了一种利用等变性进行音频-视觉对比学习的新框架，通过一个共享的基于注意力的变换预测器来实现特征聚合和嵌入表示，有效提供了强大的监督，且计算开销最小。 |
| [^12] | [A Question-centric Multi-experts Contrastive Learning Framework for Improving the Accuracy and Interpretability of Deep Sequential Knowledge Tracing Models](https://arxiv.org/abs/2403.07322) | 通过一个问题中心的多专家对比学习框架，提高深度序列知识追踪模型的准确性和可解释性，解决了知识追踪中个体问题信息建模和模型预测结果解释的重要挑战 |
| [^13] | [Adaptive Hyperparameter Optimization for Continual Learning Scenarios](https://arxiv.org/abs/2403.07015) | 本文旨在探讨在持续学习中的超参数选择作用和根据任务复杂性持续自动调整它们的必要性，通过利用序列任务学习特性来提高超参数优化效率，实验证明这种方法可以使超参数优化在不同任务中持续加速。 |
| [^14] | [On the Diminishing Returns of Width for Continual Learning](https://arxiv.org/abs/2403.06398) | 增加神经网络宽度以减少遗忘会带来递减的回报，并且在先前研究中尚未探索的宽度范围内进行了实证验证。 |
| [^15] | [Decoding the AI Pen: Techniques and Challenges in Detecting AI-Generated Text](https://arxiv.org/abs/2403.05750) | 大型语言模型在自然语言生成领域取得了重大突破，提出了识别AI生成文本的解决方案，并探索了未来研究方向。 |
| [^16] | [Vlearn: Off-Policy Learning with Efficient State-Value Function Estimation](https://arxiv.org/abs/2403.04453) | Vlearn提出了一种新颖的离策略优化方法，称为Vlearn，它通过仅利用状态值函数作为评论家，消除了对明确状态-动作-值函数的需求，从而解决了高维动作空间中的计算挑战。 |
| [^17] | [Active Adaptive Experimental Design for Treatment Effect Estimation with Covariate Choices](https://arxiv.org/abs/2403.03589) | 该研究提出了一种更有效地估计处理效应的活跃自适应实验设计方法，通过优化协变量密度和倾向得分来降低渐近方差。 |
| [^18] | [Evidence-Focused Fact Summarization for Knowledge-Augmented Zero-Shot Question Answering](https://arxiv.org/abs/2403.02966) | 提出了一种面向证据的事实摘要化框架EFSum，用于增强LLMs的零-shot QA性能，并确保摘要的有益性和忠实性。 |
| [^19] | [On the Convergence of Federated Learning Algorithms without Data Similarity](https://arxiv.org/abs/2403.02347) | 本文提出了一种无需数据相似性条件的联邦学习算法收敛性分析框架，通过推导出三种常用步长调度的精确表达式，实现了对算法收敛性能的全面评估。 |
| [^20] | [FlowPrecision: Advancing FPGA-Based Real-Time Fluid Flow Estimation with Linear Quantization](https://arxiv.org/abs/2403.01922) | 本研究将线性量化应用于FPGA-based soft sensors中，显著提高了神经网络模型精度，通过硬件优化实现了降低均方误差和提升推理速度，为实时流体流量估计提供了高效、精确的替代方案 |
| [^21] | [Overestimation, Overfitting, and Plasticity in Actor-Critic: the Bitter Lesson of Reinforcement Learning](https://arxiv.org/abs/2403.00514) | 实施超过60种不同的离策略代理，发现某些组合表现出稳健和优越的性能，揭示了特定正则化设置与任务的关联性约几维多多。 |
| [^22] | [Optimization of Array Encoding for Ultrasound Imaging](https://arxiv.org/abs/2403.00289) | 利用机器学习构建扫描序列，产生高质量超声B模式图像，并优化超声成像编码序列。 |
| [^23] | [FedStruct: Federated Decoupled Learning over Interconnected Graphs](https://arxiv.org/abs/2402.19163) | FedStruct提出了一种新的框架，利用深层结构依赖关系在互联图上进行联合解耦学习，有效地维护隐私并捕捉节点间的依赖关系。 |
| [^24] | [Multi-objective Differentiable Neural Architecture Search](https://arxiv.org/abs/2402.18213) | 提出了一种新颖的NAS算法，可以在一个搜索运行中编码用户对性能和硬件指标之间的权衡偏好，生成精心选择的多设备架构。 |
| [^25] | [On the Inductive Biases of Demographic Parity-based Fair Learning Algorithms](https://arxiv.org/abs/2402.18129) | 分析了标准 DP 基础正则化方法对给定敏感属性的预测标签条件分布的影响，并提出了一种基于敏感属性的分布稳健优化方法来控制归纳偏差。 |
| [^26] | [Pretraining Strategy for Neural Potentials](https://arxiv.org/abs/2402.15921) | 通过提出的面向图神经网络的掩码预训练方法，改善了GNN在拟合水系统势能表面方面的性能，并在精度和收敛速度上优于从头开始训练或使用其他预训练技术。 |
| [^27] | [OAG-Bench: A Human-Curated Benchmark for Academic Graph Mining](https://arxiv.org/abs/2402.15810) | OAG-Bench是一个基于开放学术图的全面、多方面和精细化人工筛选基准，涵盖了多个任务、数据集、基准和实验结果，旨在促进学术图挖掘。 |
| [^28] | [Evaluating the Performance of ChatGPT for Spam Email Detection](https://arxiv.org/abs/2402.15537) | 该研究评估了ChatGPT在英文和中文电子邮件数据集中用于垃圾邮件检测的性能，并探讨了其在这一领域的潜力。 |
| [^29] | [Active Few-Shot Fine-Tuning](https://arxiv.org/abs/2402.15441) | 该论文提出了ITL方法来实现主动少样本微调，通过最大化对下游任务的信息获取，从而在大型神经网络的微调中取得了显著的改进。 |
| [^30] | [Chain-of-Thought Unfaithfulness as Disguised Accuracy](https://arxiv.org/abs/2402.14897) | 了解Chain-of-Thought生成与大语言模型内部计算的一致程度对于决定是否信任模型输出至关重要，研究发现模型大小与忠实度之间存在着特定关系，并且发现130亿参数模型表现出更高的忠实度。 |
| [^31] | [DynGMA: a robust approach for learning stochastic differential equations from data](https://arxiv.org/abs/2402.14475) | DynGMA方法通过引入新的密度近似，优于基准方法在学习完全未知的漂移和扩散函数以及计算不变性方面的准确性。 |
| [^32] | [Modeling 3D Infant Kinetics Using Adaptive Graph Convolutional Networks](https://arxiv.org/abs/2402.14400) | 使用数据驱动评估个体动作模式，利用自适应图卷积网络对3D婴儿动力学进行建模，相较于传统机器学习取得了改进。 |
| [^33] | [Right on Time: Revising Time Series Models by Constraining their Explanations](https://arxiv.org/abs/2402.12921) | 引入了准时到位（RioT）方法，通过使模型解释在时间和频率域之间交互，并利用反馈来约束模型，有效地解决了时间序列数据中的混杂因素问题。 |
| [^34] | [Identifying Factual Inconsistency in Summaries: Towards Effective Utilization of Large Language Model](https://arxiv.org/abs/2402.12821) | 该研究提出了针对摘要中事实不一致性的解决方案：通过大型语言模型在正确的范式设计下无需训练即可解决任务，并提出了训练策略以精炼更小型的高准确性的语言模型。 |
| [^35] | [Diffeomorphism Neural Operator for various domains and parameters of partial differential equations](https://arxiv.org/abs/2402.12475) | 通过微分同胚神经算子学习框架，提出了一种适用于各种和复杂领域的物理系统的领域灵活模型，从而将学习函数映射在不同领域的问题转化为在共享的微分同胚上学习算子的问题。 |
| [^36] | [Prospector Heads: Generalized Feature Attribution for Large Models & Data](https://arxiv.org/abs/2402.11729) | Prospector heads是一种高效且可解释的基于特征归因的替代方法，它可以应用于任何编码器和任何数据形态，并且通过对不同数据形态的实验，表现优越于传统方法。 |
| [^37] | [Attractor Memory for Long-Term Time Series Forecasting: A Chaos Perspective](https://arxiv.org/abs/2402.11463) | Attraos模型基于混沌理论，在长期时间序列预测中利用多尺度动态记忆单元和局部演化策略，表现优异于其他LTSF方法。 |
| [^38] | [The Mirrored Influence Hypothesis: Efficient Data Influence Estimation by Harnessing Forward Passes](https://arxiv.org/abs/2402.08922) | 本文介绍和探讨了镜像影响假设，突出了训练和测试数据之间影响的相互性。具体而言，它指出，评估训练数据对测试预测的影响可以重新表述为一个等效但相反的问题：评估如果模型在特定的测试样本上进行训练，对训练样本的预测将如何改变。通过实证和理论验证，我们演示了这一假设的正确性。 |
| [^39] | [Top-$K$ ranking with a monotone adversary](https://arxiv.org/abs/2402.07445) | 本文针对具有单调对手的Top-K排名问题，提出了一种加权最大似然估计器(MLE)，在样本复杂度方面接近最优。算法创新包括了对加权MLE的精确且紧密的$\ell_\infty$误差分析，并与加权比较图的谱特性相关联。 |
| [^40] | [Gradient descent induces alignment between weights and the empirical NTK for deep non-linear networks](https://arxiv.org/abs/2402.05271) | 了解神经网络从输入-标签对中提取统计信息的机制是监督学习中最重要的未解决问题之一。前人的研究表明，在训练过程中，权重的格拉姆矩阵与模型的平均梯度外积成正比，这被称为神经特征分析（NFA）。本研究解释了这种相关性的出现，并发现NFA等价于权重矩阵的左奇异结构与与这些权重相关的经验神经切线核的显著成分之间的对齐。在早期训练阶段，可以通过解析的方式预测NFA的发展速度。 |
| [^41] | [Anatomically-Controllable Medical Image Generation with Segmentation-Guided Diffusion Models](https://arxiv.org/abs/2402.05210) | 这篇论文提出了一种采用分割引导扩散模型的解剖可控医学图像生成方法，通过随机掩模消融训练算法实现对解剖约束的条件化，同时提高了网络对解剖真实性的学习能力。 |
| [^42] | [A Bandit Approach with Evolutionary Operators for Model Selection](https://arxiv.org/abs/2402.05144) | 本文提出了一种使用进化算子的强盗方法来进行模型选择，通过将模型选择问题建模为无穷臂赌博机问题，利用部分训练和准确性作为奖励，最终的算法Mutant-UCB在测试中表现出色，优于固定预算下的最先进技术。 |
| [^43] | [LEVI: Generalizable Fine-tuning via Layer-wise Ensemble of Different Views](https://arxiv.org/abs/2402.04644) | 本论文中，我们提出了一种名为LEVI的方法，通过以层为单位的多视角集成，实现了对预训练和微调数据中问题的解决，并提升微调模型对未见过的分布的泛化能力。 |
| [^44] | [Structured Entity Extraction Using Large Language Models](https://arxiv.org/abs/2402.04437) | 本论文提出了一种使用大型语言模型的结构化实体提取方法，在此任务上通过引入AESOP度量评估模型性能，并将整个提取任务分解为多个阶段，相较于基准模型取得了更好的效果，为未来结构化实体提取的进一步发展提供了有希望的方向。 |
| [^45] | [Resource-Aware Hierarchical Federated Learning in Wireless Video Caching Networks](https://arxiv.org/abs/2402.04216) | 通过资源感知的分层联邦学习，我们提出了一种解决方案，可以预测用户未来的内容请求，并减轻无线视频缓存网络中回程流量拥塞的问题。 |
| [^46] | [Discounted Adaptive Online Prediction](https://arxiv.org/abs/2402.02720) | 本论文提出了一种折扣自适应在线预测算法，该算法适应于复杂的损失序列和比较器，并改进了非自适应算法。算法具有无需结构性假设的理论保证，并且在超参数调整方面具有鲁棒性。通过在线符合预测任务的实验证明了算法的好处。 |
| [^47] | [What Will My Model Forget? Forecasting Forgotten Examples in Language Model Refinement](https://arxiv.org/abs/2402.01865) | 本文研究了语言模型更新中的遗忘现象，提出了一种预测上游实例遗忘的方法，以改进重播过程的可控性和解释性。根据预训练实例的预-softmax对数几率分数变化与在线学习实例的相似性，提出了一种部分可解释的预测模型，在BART模型上表现良好但在T5模型上失败。此外，还展示了基于内积的黑盒分类器。 |
| [^48] | [A Single Graph Convolution Is All You Need: Efficient Grayscale Image Classification](https://arxiv.org/abs/2402.00564) | 本论文提出了一种高效的灰度图像分类方法，通过将图像视为矢量，并使用单个图卷积层进行处理，提高了分类模型的准确性和稳定性。 |
| [^49] | [A Survey of Data-Efficient Graph Learning](https://arxiv.org/abs/2402.00447) | 这项研究提出了数据高效图学习（DEGL）的概念，并总结了近期在这一领域的进展。DEGL的目标是在资源有限的场景下提高图机器学习的性能，通过探索各种最小监督方法来解决大规模标记数据的挑战。 |
| [^50] | [In-Context Reinforcement Learning for Variable Action Spaces](https://arxiv.org/abs/2312.13327) | 本文提出了一种Headless-AD模型，通过只训练一次，能够在变化的行动空间中实现强化学习任务的泛化。实验证明该模型能够在从未遇到过的行动空间上表现出显著的泛化能力，甚至胜过针对特定行动集训练的模型。 |
| [^51] | [Learning from Emergence: A Study on Proactively Inhibiting the Monosemantic Neurons of Artificial Neural Networks](https://arxiv.org/abs/2312.11560) | 本文研究了积极抑制人工神经网络中的单意义神经元，这对于提高性能具有重要意义，并提出了一种基于自发现的方法来实现抑制。 |
| [^52] | [Precipitation Downscaling with Spatiotemporal Video Diffusion](https://arxiv.org/abs/2312.06071) | 通过扩展视频扩散模型至降水超分辨率，本研究提出了一种利用确定性降尺度器和暂时条件扩散模型来捕捉噪声特征和高频率模式的方法。 |
| [^53] | [Remembering to Be Fair: Non-Markovian Fairness in Sequential Decision Making](https://arxiv.org/abs/2312.04772) | 本文研究了在序贯决策过程中的非马尔可夫公平性，发现公平往往取决于历史，需要在过程中的不同时间点进行评估。 |
| [^54] | [FRAPP\'E: A Group Fairness Framework for Post-Processing Everything](https://arxiv.org/abs/2312.02592) | 提出了一个将任何正则化的处理中方法转化为后处理方法的框架，适用于更广泛的问题设置，保持了良好的公平错误权衡，并且可能提高之前方法的效力 |
| [^55] | [Analyzing Sharpness-aware Minimization under Overparameterization](https://arxiv.org/abs/2311.17539) | 本文分析了在过参数化条件下的锐度感知最小化方法。通过实证和理论结果，发现过参数化对锐度感知最小化具有重要影响，并且在过参数化增加的情况下，锐度感知最小化仍然受益。 |
| [^56] | [CV-Attention UNet: Attention-based UNet for 3D Cerebrovascular Segmentation of Enhanced TOF-MRA Images](https://arxiv.org/abs/2311.10224) | 本文提出了一种3D脑血管注意力UNet方法，用于精确提取脑血管图像，通过一系列预处理技术和深度监督UNet来改善脑血管分割的准确性，有助于预防中风。 |
| [^57] | [TAP: The Attention Patch for Cross-Modal Knowledge Transfer from Unlabeled Modality](https://arxiv.org/abs/2302.02224) | 通过引入The Attention Patch（TAP）神经网络附加组件，本文提出了一种简单且有效的方法，允许从未标记的次要模态实现跨模态的数据级知识传递。 |
| [^58] | [Outline of an Independent Systematic Blackbox Test for ML-based Systems.](http://arxiv.org/abs/2401.17062) | 本文提出了一种独立测试ML模型和基于ML的系统的方法，可以独立验证其黑盒特性和随机属性。建议扩展现有测试方法以更好地反映ML系统的特点。 |
| [^59] | [M2CURL: Sample-Efficient Multimodal Reinforcement Learning via Self-Supervised Representation Learning for Robotic Manipulation.](http://arxiv.org/abs/2401.17032) | M2CURL是一种样本高效的多模态强化学习方法，通过自监督表示学习从视触觉数据中学习出高效的表示，并加速强化学习算法的收敛。 |
| [^60] | [Diffusion model for relational inference.](http://arxiv.org/abs/2401.16755) | 这项研究提出了一种关系推理的扩散模型(DiffRI)，通过条件扩散建模学习推断组件之间连接存在的概率，并在无监督方式下发现地面真实相互作用方面具有很高的能力。 |
| [^61] | [Lessons on Datasets and Paradigms in Machine Learning for Symbolic Computation: A Case Study on CAD.](http://arxiv.org/abs/2401.13343) | 这项研究提出了机器学习在符号计算中的应用经验教训，包括在机器学习之前对数据集进行分析的重要性以及不同机器学习范式的选择。通过在柱面代数分解中的变量排序选择中的案例研究，发现了数据集中的不平衡问题，并引入了增强技术来改善数据集的平衡性。 |
| [^62] | [Multimodal Sentiment Analysis with Missing Modality: A Knowledge-Transfer Approach.](http://arxiv.org/abs/2401.10747) | 本文提出了一种知识迁移方法，用于在缺失模态下进行多模态情感分析。通过翻译不同模态之间的内容以重构缺失的音频模态，并利用跨模态注意机制进行情感预测，实验证明了该方法在多个数据集上表现出显著的改进和与完整多模态监督方法相媲美的效果。 |
| [^63] | [Predicting and Interpreting Energy Barriers of Metallic Glasses with Graph Neural Networks.](http://arxiv.org/abs/2401.08627) | 本研究使用图神经网络建模原子图结构并预测金属玻璃的能垒，通过提出的对称图神经网络模型，实现了在结构正交变换下的不变性，为理解金属玻璃的局部结构与物理性质关系提供了新的方法。 |
| [^64] | [Towards Enhancing the Reproducibility of Deep Learning Bugs: An Empirical Study.](http://arxiv.org/abs/2401.03069) | 本研究旨在提高深度学习Bug的可复现性，通过构建数据集和确定编辑动作和有用信息，这能够解决目前研究中忽视的问题。 |
| [^65] | [ALEXR: An Optimal Single-Loop Algorithm for Convex Finite-Sum Coupled Compositional Stochastic Optimization.](http://arxiv.org/abs/2312.02277) | 本文提出了一种名为ALEXR的高效算法，用于解决凸有限和耦合组成随机优化问题。此算法在解决平滑和非平滑问题时具有优越的收敛速度，并且可应用于多个领域，包括组分布鲁棒优化、不平衡数据学习、强化学习和排序学习。 |
| [^66] | [Revisiting the Learnability of Apple Tasting.](http://arxiv.org/abs/2310.19064) | 该论文重新审视了苹果品尝的可学习性，从组合角度研究了在线可学习性。作者通过引入Effective width参数，紧密量化了在可实现设置中的极小期望错误，并在可实现设置中建立了极小期望错误数量的三分法。 |
| [^67] | [The statistical thermodynamics of generative diffusion models.](http://arxiv.org/abs/2310.17467) | 本文通过在生成性扩散模型中应用平衡统计力学的工具，揭示了这些模型中的二阶相变现象，并且认为这种稳定性形式是生成能力的关键。 |
| [^68] | [Compressed representation of brain genetic transcription.](http://arxiv.org/abs/2310.16113) | 本文研究了大脑基因转录的压缩表示方法，通过比较不同的线性和非线性方法，评估了它们在重建、解剖和预测方面的性能。 |
| [^69] | [Neural Collapse in Multi-label Learning with Pick-all-label Loss.](http://arxiv.org/abs/2310.15903) | 这项论文研究了在多标签分类任务中的神经坍缩现象。他们推广了之前在多类别分类中发现的神经坍缩现象，证明了在“选择所有标签”公式下存在广义的神经坍缩现象。他们还发现了在广义的神经坍缩中的一个组合性质。 |
| [^70] | [RSAdapter: Adapting Multimodal Models for Remote Sensing Visual Question Answering.](http://arxiv.org/abs/2310.13120) | RSAdapter是一种针对遥感视觉问答的多模态模型，通过并行适配器和线性转换层的设计，提高了运行时和参数效率。 |
| [^71] | [Pseudo-Bayesian Optimization.](http://arxiv.org/abs/2310.09766) | 本文提出了伪贝叶斯优化，并通过研究最小要求的公理框架，构建了能确保黑盒优化收敛性的算法。 |
| [^72] | [DKEC: Domain Knowledge Enhanced Multi-Label Classification for Electronic Health Records.](http://arxiv.org/abs/2310.07059) | 本文提出了DKEC，一种领域知识增强的分类器，用于医学诊断预测。它利用标签的注意力机制和组内训练方法来捕捉医学实体之间的语义关系，并增加罕见类别的样本数量。评估结果显示其在医学数据集上表现良好。 |
| [^73] | [Physics-aware Machine Learning Revolutionizes Scientific Paradigm for Machine Learning and Process-based Hydrology.](http://arxiv.org/abs/2310.05227) | 物理感知机器学习是一种革命性方法，它将物理知识和机器学习相结合，提供了准确的水文学理解和水循环预测，对于管理水资源以应对气候变化等挑战具有重要意义。 |
| [^74] | [Instances and Labels: Hierarchy-aware Joint Supervised Contrastive Learning for Hierarchical Multi-Label Text Classification.](http://arxiv.org/abs/2310.05128) | 提出了一种层次感知联合监督对比学习方法（HJCL），用于层次化多标签文本分类。该方法通过使用实例级和标签级对比学习技术，以及精心构建批次来处理标签层次结构，解决了在HMTC中使用监督对比学习的问题。 |
| [^75] | [FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things.](http://arxiv.org/abs/2310.00109) | FedAIoT是一个用于AIoT的联邦学习基准，包括八个数据集和一个统一的端到端FL框架。它填补了现有FL研究中缺乏真实物联网设备数据集的关键差距，并揭示了FL在AIoT领域的机遇和挑战。 |
| [^76] | [Transferring climate change knowledge.](http://arxiv.org/abs/2309.14780) | 通过转移学习方法，研究表明机器学习，尤其是深度神经网络，可以通过充分利用地球系统模型模拟和历史观测所获得的知识，更准确地预测21世纪的全球表面温度场。 |
| [^77] | [COVID-19 Detection System: A Comparative Analysis of System Performance Based on Acoustic Features of Cough Audio Signals.](http://arxiv.org/abs/2309.04505) | 本研究通过比较分析声学特征对咳嗽音频信号的机器学习模型性能的影响，提出了一种高效的COVID-19检测系统。 |
| [^78] | [Everything, Everywhere All in One Evaluation: Using Multiverse Analysis to Evaluate the Influence of Model Design Decisions on Algorithmic Fairness.](http://arxiv.org/abs/2308.16681) | 通过多元宇宙分析评估模型设计决策对算法公平性的影响，可以揭示算法决策系统中设计决策的关键作用。 |
| [^79] | [How Safe Am I Given What I See? Calibrated Prediction of Safety Chances for Image-Controlled Autonomy.](http://arxiv.org/abs/2308.12252) | 本文提出了一种基于生成世界模型的学习流水线族，通过克服学习安全知情表示和分布漂移下缺失安全标签的挑战，实现了在线安全预测。这些流水线具有统计校准保证的安全机会预测能力。 |
| [^80] | [The Challenges of Machine Learning for Trust and Safety: A Case Study on Misinformation Detection.](http://arxiv.org/abs/2308.12215) | 本研究通过虚假信息检测为例，检查了机器学习在信任与安全问题中学术与实践之间的脱节，并发现了文献中存在的严重不足之处，包括任务不符合在线服务面临的挑战、数据集和模型评估不真实、评估不独立于模型训练等。在此基础上，提出了评估机器学习应用于信任与安全问题的建议。 |
| [^81] | [Exploring Transfer Learning in Medical Image Segmentation using Vision-Language Models.](http://arxiv.org/abs/2308.07706) | 本论文提出使用视觉-语言模型进行医学图像分割的迁移学习，并评估了其在医学领域的可迁移性。通过捕捉语义信息和引入新的图像描述变化，实现了对多样化医学图像的分割。 |
| [^82] | [Inverse Optimization for Routing Problems.](http://arxiv.org/abs/2307.07357) | 本研究提出了一种使用反向最优化（IO）学习路由问题决策者行为的方法，并在亚马逊末端路由研究挑战中测试了该方法，在复制人类驾驶员的路由偏好方面取得了第2名的成绩。 |
| [^83] | [SwinGNN: Rethinking Permutation Invariance in Diffusion Models for Graph Generation.](http://arxiv.org/abs/2307.01646) | 本文提出了一种新的图生成扩散模型SwinGNN，通过使用高效的2-WL消息传递网络和移动窗口自注意力，以及结合关键的训练和采样技术，显著提高了图生成样本的质量，并引入了随机置换的后处理技巧转换生成的图形统计量。 |
| [^84] | [Online Learning with Set-Valued Feedback.](http://arxiv.org/abs/2306.06247) | 本文研究了一种在线多类分类的变体，其中使用集合型反馈。通过引入新的组合维度，该论文表明确定性和随机性的在线可学习性在实现设置下不等价，并将在线多标签排名和在线多标签分类等实际学习设置作为其特定实例。 |
| [^85] | [Pruning Meets Low-Rank Parameter-Efficient Fine-Tuning.](http://arxiv.org/abs/2305.18403) | 本论文提出了一种名为LoRAPrune的框架，可以高效微调和部署大型预训练模型，通过利用低秩自适应的值和梯度来设计PEFT感知的剪枝准则，并提出了一个迭代剪枝过程来去除冗余参数，实验结果表明与最先进的方法相比，可以显著降低模型大小和推理时间，同时保持竞争性的准确性。 |
| [^86] | [Emergent representations in networks trained with the Forward-Forward algorithm.](http://arxiv.org/abs/2305.18353) | 研究表明使用Forward-Forward算法训练的网络内部表征具有高稀疏度，类别特定的集合，这与生物学观察到的皮层表征相似。 |
| [^87] | [DOCTOR: A Multi-Disease Detection Continual Learning Framework Based on Wearable Medical Sensors.](http://arxiv.org/abs/2305.05738) | DOCTOR是一种基于可穿戴医疗传感器的多疾病检测持续学习框架，采用了多头深度神经网络和Exemplar-replay风格的CL算法。它可以不断地学习新任务，并在内存使用、电池消耗和检测复杂度方面优于传统的ML驱动疾病检测方法。 |
| [^88] | [Synthesizing PET images from High-field and Ultra-high-field MR images Using Joint Diffusion Attention Model.](http://arxiv.org/abs/2305.03901) | 本文提出了一种方法，使用联合扩散注意力模型来合成PET图像，以解决PET成像成本高且涉及辐射暴露的缺陷。该方法相比现有方法具有更好的性能和噪声敏感度更低。 |
| [^89] | [Dynamic Data Assimilation of MPAS-O and the Global Drifter Dataset.](http://arxiv.org/abs/2301.05551) | 本研究提出了一种新的动态数据同化方法，将全球漂流器数据集与海洋预测模型相结合，通过利用地球系统模型的动态和模式，提高了海洋温度预测的准确性。 |
| [^90] | [RFold: RNA Secondary Structure Prediction with Decoupled Optimization.](http://arxiv.org/abs/2212.14041) | 所提出的RFold方法采用解耦优化过程和注意力机制进行简单又有效的RNA二级结构预测，具有较高的准确性和速度。 |
| [^91] | [Physics-informed neural networks with unknown measurement noise.](http://arxiv.org/abs/2211.15498) | 这篇论文提出了一种解决物理信息神经网络在存在非高斯噪声情况下失效的问题的方法，即通过同时训练一个能量模型来学习正确的噪声分布。通过多个例子的实验证明了该方法的改进性能。 |
| [^92] | [Imputation of missing values in multi-view data.](http://arxiv.org/abs/2210.14484) | 本文提出了一种基于StaPLR算法的新的多视角数据插补算法，通过在降维空间中执行插补以解决计算挑战，并在模拟数据集中得到了竞争性结果。 |
| [^93] | [Self-supervised Learning for Human Activity Recognition Using 700,000 Person-days of Wearable Data.](http://arxiv.org/abs/2206.02909) | 本研究利用700,000人日的未标记可穿戴传感器数据，通过自监督学习技术，成功构建了一种能够在多个数据集上泛化且效果显著优于基线模型的人体活动识别模型，有望帮助研究人员和开发者开发高性能的可定制和泛化的活动分类器。 |

# 详细

[^1]: 使用标记数据增强的测地插值方法学习蛋白质折叠的集体变量

    Learning Collective Variables for Protein Folding with Labeled Data Augmentation through Geodesic Interpolation

    [https://rss.arxiv.org/abs/2402.01542](https://rss.arxiv.org/abs/2402.01542)

    本实验提出了一种使用标记数据增强和测地插值方法学习蛋白质折叠的集体变量的策略，有效提高了采样效率，并在过渡态数据有限且嘈杂时表现优于基于分类器的方法。

    

    在分子动力学（MD）模拟中，通常通过增强采样技术来研究蛋白质折叠等罕见事件，其中大部分依赖于沿着加速发生的集体变量（CV）的定义。获得富有表达力的CV至关重要，但往往受到关于特定事件的信息不足的阻碍，例如从未折叠到折叠构象的转变。我们提出了一种模拟无关的数据增强策略，利用受物理启发的度量来生成类似蛋白质折叠转变的测地插值，从而提高采样效率，而无需真实的过渡态样本。通过利用插值进度参数，我们引入了基于回归的学习方案来构建CV模型，当过渡态数据有限且嘈杂时，该方法表现优于基于分类器的方法。

    In molecular dynamics (MD) simulations, rare events, such as protein folding, are typically studied by means of enhanced sampling techniques, most of which rely on the definition of a collective variable (CV) along which the acceleration occurs. Obtaining an expressive CV is crucial, but often hindered by the lack of information about the particular event, e.g., the transition from unfolded to folded conformation. We propose a simulation-free data augmentation strategy using physics-inspired metrics to generate geodesic interpolations resembling protein folding transitions, thereby improving sampling efficiency without true transition state samples. Leveraging interpolation progress parameters, we introduce a regression-based learning scheme for CV models, which outperforms classifier-based methods when transition state data is limited and noisy
    
[^2]: 可解释行为表示的多意图逆Q学习

    Multi-intention Inverse Q-learning for Interpretable Behavior Representation

    [https://rss.arxiv.org/abs/2311.13870](https://rss.arxiv.org/abs/2311.13870)

    本研究引入了一种多意图逆Q学习算法，用于解决在推断离散时变奖励时的挑战。通过聚类观察到的专家轨迹并独立解决每个意图的逆强化学习问题，我们的方法在动物行为预测方面超越了当前的基准，产生了可解释的奖励函数。

    

    在推动决策过程理解方面，逆强化学习（IRL）在重构动物复杂行为中的多个意图方面证明了其重要性。鉴于最近发展的连续时间多意图IRL框架，人们一直在研究如何使用IRL推断离散的时变奖励。为了解决这个挑战，我们引入了潜（马尔科夫）变量逆Q学习（L(M)V-IQL），这是一种专门用于适应离散内在奖励函数的IRL算法。通过利用期望最大化方法，我们将观察到的专家轨迹聚类成不同的意图，并为每个意图独立解决IRL问题。通过模拟实验和对不同真实鼠类行为数据集的应用，我们的方法在动物行为预测方面超越了当前的基准，产生了可解释的奖励函数。这一进展有望打开推动科学与工程应用的新机遇。

    In advancing the understanding of decision-making processes, Inverse Reinforcement Learning (IRL) have proven instrumental in reconstructing animal's multiple intentions amidst complex behaviors. Given the recent development of a continuous-time multi-intention IRL framework, there has been persistent inquiry into inferring discrete time-varying rewards with IRL. To tackle the challenge, we introduce Latent (Markov) Variable Inverse Q-learning (L(M)V-IQL), a novel class of IRL algorthms tailored for accommodating discrete intrinsic reward functions. Leveraging an Expectation-Maximization approach, we cluster observed expert trajectories into distinct intentions and independently solve the IRL problem for each. Demonstrating the efficacy of L(M)V-IQL through simulated experiments and its application to different real mouse behavior datasets, our approach surpasses current benchmarks in animal behavior prediction, producing interpretable reward functions. This advancement holds promise f
    
[^3]: MedCLIP-SAM：将文本和图像进行桥接，实现通用医学图像分割

    MedCLIP-SAM: Bridging Text and Image Towards Universal Medical Image Segmentation

    [https://arxiv.org/abs/2403.20253](https://arxiv.org/abs/2403.20253)

    提出了MedCLIP-SAM框架，结合了CLIP和SAM模型，实现使用少量标记数据的临床图像分割

    

    医学图像中解剖结构和病变的分割在现代临床诊断、疾病研究和治疗规划中至关重要。本文提出了一个新颖的框架，称为MedCLIP-SAM，结合了CLIP和SAM模型，以生成使用少量标记数据的临床扫描的分割。

    arXiv:2403.20253v1 Announce Type: cross  Abstract: Medical image segmentation of anatomical structures and pathology is crucial in modern clinical diagnosis, disease study, and treatment planning. To date, great progress has been made in deep learning-based segmentation techniques, but most methods still lack data efficiency, generalizability, and interactability. Consequently, the development of new, precise segmentation methods that demand fewer labeled datasets is of utmost importance in medical image analysis. Recently, the emergence of foundation models, such as CLIP and Segment-Anything-Model (SAM), with comprehensive cross-domain representation opened the door for interactive and universal image segmentation. However, exploration of these models for data-efficient medical image segmentation is still limited, but is highly necessary. In this paper, we propose a novel framework, called MedCLIP-SAM that combines CLIP and SAM models to generate segmentation of clinical scans using t
    
[^4]: TFB：面向时间序列预测方法全面且公平的基准比较

    TFB: Towards Comprehensive and Fair Benchmarking of Time Series Forecasting Methods

    [https://arxiv.org/abs/2403.20150](https://arxiv.org/abs/2403.20150)

    TFB通过解决数据领域覆盖不足、对传统方法的刻板印象以及不一致、不灵活的流程等问题，推动了时间序列预测方法基准比较的最新技术发展。

    

    时间序列会在经济、交通、健康和能源等不同领域中产生，对未来数值的预测在许多重要应用中起着关键作用。不出所料，许多预测方法被提出。为了确保进展，有必要能够以全面且可靠的方式经验性地研究和比较这些方法。为了实现这一目标，我们提出了TFB，一个自动化的时间序列预测（TSF）方法基准测试。TFB通过解决与数据集、比较方法和评估管道相关的缺点，推动了最新技术的发展：1）数据领域覆盖不足，2）对传统方法的刻板印象，3）不一致和不灵活的流程。为了获得更好的领域覆盖率，我们包括了来自10个不同领域的数据集：交通、电力、能源、环境、自然、经济、股票市场、银行、健康和网络。我们还提供了一个时间序列特性

    arXiv:2403.20150v1 Announce Type: cross  Abstract: Time series are generated in diverse domains such as economic, traffic, health, and energy, where forecasting of future values has numerous important applications. Not surprisingly, many forecasting methods are being proposed. To ensure progress, it is essential to be able to study and compare such methods empirically in a comprehensive and reliable manner. To achieve this, we propose TFB, an automated benchmark for Time Series Forecasting (TSF) methods. TFB advances the state-of-the-art by addressing shortcomings related to datasets, comparison methods, and evaluation pipelines: 1) insufficient coverage of data domains, 2) stereotype bias against traditional methods, and 3) inconsistent and inflexible pipelines. To achieve better domain coverage, we include datasets from 10 different domains: traffic, electricity, energy, the environment, nature, economic, stock markets, banking, health, and the web. We also provide a time series char
    
[^5]: MambaMixer：具有双重标记和通道选择的高效选择性状态空间模型

    MambaMixer: Efficient Selective State Space Models with Dual Token and Channel Selection

    [https://arxiv.org/abs/2403.19888](https://arxiv.org/abs/2403.19888)

    MambaMixer是一种新的架构，提出了具有数据依赖权重的双重选择机制，称为选择性标记和通道混合器，对长序列建模具有潜在优势。

    

    深度学习的最新进展主要依赖于Transformers，因为它们具有数据依赖性并且能够实现大规模学习。然而，这些架构中的注意力模块展现出输入大小的二次时间和空间，限制了它们用于长序列建模的可扩展性。尽管最近有尝试为多维数据设计高效有效的架构主干，例如图像和多变量时间序列，但现有模型要么是数据独立的，要么无法允许跨维度和内部维度之间的通信。最近，状态空间模型（SSMs），尤其是具有高效硬件感知实现的选择性状态空间模型，展现出了用于长序列建模的潜在优势。受到SSMs成功的启发，我们提出了MambaMixer，一种新的具有数据依赖权重的架构，使用跨标记和通道的双重选择机制，称为选择性标记和通道混合器。

    arXiv:2403.19888v1 Announce Type: cross  Abstract: Recent advances in deep learning have mainly relied on Transformers due to their data dependency and ability to learn at scale. The attention module in these architectures, however, exhibits quadratic time and space in input size, limiting their scalability for long-sequence modeling. Despite recent attempts to design efficient and effective architecture backbone for multi-dimensional data, such as images and multivariate time series, existing models are either data independent, or fail to allow inter- and intra-dimension communication. Recently, State Space Models (SSMs), and more specifically Selective State Space Models, with efficient hardware-aware implementation, have shown promising potential for long sequence modeling. Motivated by the success of SSMs, we present MambaMixer, a new architecture with data-dependent weights that uses a dual selection mechanism across tokens and channels, called Selective Token and Channel Mixer. M
    
[^6]: 通过过拟合的遮蔽自编码器检测生成性模仿

    Detecting Generative Parroting through Overfitting Masked Autoencoders

    [https://arxiv.org/abs/2403.19050](https://arxiv.org/abs/2403.19050)

    本研究提出利用过拟合的遮蔽自编码器(MAE)来检测生成模型中的生成性模仿，建立了基于训练数据集损失的检测阈值，为了确保生成模型的合法使用和提升其法律合规性提供了一种新方法。

    

    生成式人工智能模型的出现彻底改变了数字内容创建的方式，然而由于生成性模仿问题，模型过于模仿其训练数据而给版权完整性带来挑战。本研究提出了一种新方法来解决这个问题，即利用一个过拟合的遮蔽自编码器(MAE)来有效地检测这种模仿样本。我们基于训练数据集上的平均损失建立一个检测阈值，从而精确定位修改后数据集中的模仿内容。初步评估表明了有希望的结果，显示了我们方法确保生成模型的合法使用并加强法律合规性方面的潜力。

    arXiv:2403.19050v1 Announce Type: cross  Abstract: The advent of generative AI models has revolutionized digital content creation, yet it introduces challenges in maintaining copyright integrity due to generative parroting, where models mimic their training data too closely. Our research presents a novel approach to tackle this issue by employing an overfitted Masked Autoencoder (MAE) to detect such parroted samples effectively. We establish a detection threshold based on the mean loss across the training dataset, allowing for the precise identification of parroted content in modified datasets. Preliminary evaluations demonstrate promising results, suggesting our method's potential to ensure ethical use and enhance the legal compliance of generative models.
    
[^7]: 基于学习的多孔介质模型用于多尺度流动问题

    Learning-based Multi-continuum Model for Multiscale Flow Problems

    [https://arxiv.org/abs/2403.14084](https://arxiv.org/abs/2403.14084)

    提出了一种基于学习的多连续体模型，用于改进多尺度问题中单一连续体模型的准确性

    

    多尺度问题通常可以通过数值均质化来近似，通过具有某些有效参数的方程来捕获原始系统在粗网格上的宏观行为，以加快模拟速度。然而，这种方法通常假设尺度分离，并且解的异质性可以通过每个粗块中的解的平均值来近似。对于复杂的多尺度问题，计算的单一有效性特性/连续体可能不足够。在本文中，我们提出了一种新颖的基于学习的多连续体模型，用于丰富均质化方程并提高多尺度问题单一连续体模型的准确性，给定一些数据。不失一般性，我们考虑了一个双连续体的情况。第一个流动方程保留了原始均质化方程的信息，具有额外的交互项。第二个连续体是新引入的。

    arXiv:2403.14084v1 Announce Type: cross  Abstract: Multiscale problems can usually be approximated through numerical homogenization by an equation with some effective parameters that can capture the macroscopic behavior of the original system on the coarse grid to speed up the simulation. However, this approach usually assumes scale separation and that the heterogeneity of the solution can be approximated by the solution average in each coarse block. For complex multiscale problems, the computed single effective properties/continuum might be inadequate. In this paper, we propose a novel learning-based multi-continuum model to enrich the homogenized equation and improve the accuracy of the single continuum model for multiscale problems with some given data. Without loss of generalization, we consider a two-continuum case. The first flow equation keeps the information of the original homogenized equation with an additional interaction term. The second continuum is newly introduced, and t
    
[^8]: 用于低成本心脏血液动力学不稳定性检测的多模态变分自编码器

    Multimodal Variational Autoencoder for Low-cost Cardiac Hemodynamics Instability Detection

    [https://arxiv.org/abs/2403.13658](https://arxiv.org/abs/2403.13658)

    提出了一种新颖的多模态变分自编码器（$\text{CardioVAE}_\text{X,G}$），将低成本胸部X射线（CXR）和心电图（ECG）数据形式整合起来，并实现了共享特征和独特特征的学习。

    

    最近在非侵入性检测心脏血液动力学不稳定性（CHDI）方面取得了进展，主要集中在将机器学习技术应用于单一数据形式，如心脏磁共振成像（MRI）。尽管这些方法具有潜力，但在标记的患者数据量有限时，这些方法通常效果不佳，这是医学领域的常见挑战。此外，只有少数研究探讨了多模态方法来研究CHDI，这些方法主要依赖昂贵的数据形式，如心脏MRI和心脏超声图。为了应对这些限制，我们提出了一种新颖的多模态变分自编码器（$\text{CardioVAE}_\text{X,G}$）来整合低成本胸部X射线（CXR）和心电图（ECG）数据形式，并在大型未标记数据集上进行预训练。具体来说，$\text{CardioVAE}_\text{X,G}$引入了一种新颖的三流预训练策略，以学习共享特征和各数据形式独有的特征，从而实现了fi

    arXiv:2403.13658v1 Announce Type: new  Abstract: Recent advancements in non-invasive detection of cardiac hemodynamic instability (CHDI) primarily focus on applying machine learning techniques to a single data modality, e.g. cardiac magnetic resonance imaging (MRI). Despite their potential, these approaches often fall short especially when the size of labeled patient data is limited, a common challenge in the medical domain. Furthermore, only a few studies have explored multimodal methods to study CHDI, which mostly rely on costly modalities such as cardiac MRI and echocardiogram. In response to these limitations, we propose a novel multimodal variational autoencoder ($\text{CardioVAE}_\text{X,G}$) to integrate low-cost chest X-ray (CXR) and electrocardiogram (ECG) modalities with pre-training on a large unlabeled dataset. Specifically, $\text{CardioVAE}_\text{X,G}$ introduces a novel tri-stream pre-training strategy to learn both shared and modality-specific features, thus enabling fi
    
[^9]: 可听图用于音频分类器

    Listenable Maps for Audio Classifiers

    [https://arxiv.org/abs/2403.13086](https://arxiv.org/abs/2403.13086)

    引入了一种名为Listenable Maps for Audio Classifiers (L-MAC)的可听图方法，用于生成忠实且可听的音频分类器解释。

    

    尽管深度学习模型在各种任务上表现出色，其复杂性给解释提出了挑战。这一挑战在音频信号中尤为明显，传达解释变得困难。为解决这一问题，我们引入了用于音频分类器的可听图（Listenable Maps for Audio Classifiers，L-MAC），这是一种生成忠实且可听解释的后处理解释方法。L-MAC利用预训练分类器之上的解码器生成二值掩码，突出显示输入音频的相关部分。我们用一种特殊损失来训练解码器，该损失最大化分类器对输入音频的掩码部分的置信度，同时最小化模型对掩码部分输出的概率。对领域内和领域外数据的定量评估表明，L-MAC始终产生比几种梯度和掩码方法更忠实的解释。

    arXiv:2403.13086v1 Announce Type: cross  Abstract: Despite the impressive performance of deep learning models across diverse tasks, their complexity poses challenges for interpretation. This challenge is particularly evident for audio signals, where conveying interpretations becomes inherently difficult. To address this issue, we introduce Listenable Maps for Audio Classifiers (L-MAC), a posthoc interpretation method that generates faithful and listenable interpretations. L-MAC utilizes a decoder on top of a pretrained classifier to generate binary masks that highlight relevant portions of the input audio. We train the decoder with a special loss that maximizes the confidence of the classifier decision on the masked-in portion of the audio while minimizing the probability of model output for the masked-out portion. Quantitative evaluations on both in-domain and out-of-domain data demonstrate that L-MAC consistently produces more faithful interpretations than several gradient and maskin
    
[^10]: HumanoidBench：用于全身运动和操作的仿真人型机器人基准测试

    HumanoidBench: Simulated Humanoid Benchmark for Whole-Body Locomotion and Manipulation

    [https://arxiv.org/abs/2403.10506](https://arxiv.org/abs/2403.10506)

    提出了一个高维度的仿真机器人学习基准测试HumanoidBench，揭示了目前最先进的强化学习算法在大多数任务上面临挑战，而具备鲁棒低级策略支持的分层学习基线表现更优秀。

    

    人型机器人在协助人类在不同环境和任务中有着巨大潜力，由于其灵活性和适应性，可以利用类人形态。然而，人型机器人的研究常常受到昂贵且易损的硬件设置的限制。为了加速人型机器人算法研究，我们提出了一个高维度的仿真机器人学习基准测试，HumanoidBench，该测试包括一个配备灵巧手部和各种具有挑战性的全身操作和运动任务的人型机器人。我们的研究发现表明，最先进的强化学习算法在大多数任务上表现不佳，而具备鲁棒的低级策略支持的分层学习基线在行走或到达等任务中表现优异。借助HumanoidBench，我们为机器人社区提供了一个平台，用于识别解决人型机器人在解决各种任务时面临的挑战，促进算法研究。

    arXiv:2403.10506v1 Announce Type: cross  Abstract: Humanoid robots hold great promise in assisting humans in diverse environments and tasks, due to their flexibility and adaptability leveraging human-like morphology. However, research in humanoid robots is often bottlenecked by the costly and fragile hardware setups. To accelerate algorithmic research in humanoid robots, we present a high-dimensional, simulated robot learning benchmark, HumanoidBench, featuring a humanoid robot equipped with dexterous hands and a variety of challenging whole-body manipulation and locomotion tasks. Our findings reveal that state-of-the-art reinforcement learning algorithms struggle with most tasks, whereas a hierarchical learning baseline achieves superior performance when supported by robust low-level policies, such as walking or reaching. With HumanoidBench, we provide the robotics community with a platform to identify the challenges arising when solving diverse tasks with humanoid robots, facilitatin
    
[^11]: EquiAV: 利用等变性进行音频-视觉对比学习

    EquiAV: Leveraging Equivariance for Audio-Visual Contrastive Learning

    [https://arxiv.org/abs/2403.09502](https://arxiv.org/abs/2403.09502)

    这项研究提出了一种利用等变性进行音频-视觉对比学习的新框架，通过一个共享的基于注意力的变换预测器来实现特征聚合和嵌入表示，有效提供了强大的监督，且计算开销最小。

    

    自我监督的音频-视觉表示学习最近取得了重大进展，展示出捕捉丰富综合表示的潜力。然而，尽管数据增强在许多学习方法中已经得到验证，音频-视觉学习仍然很难充分利用这些优势，因为增强可能会轻易破坏输入对之间的对应关系。为了解决这一限制，我们引入了EquiAV，一种利用等变性进行音频-视觉对比学习的新框架。我们的方法从扩展等变性开始进行音频-视觉学习，通过一个共享的基于注意力的变换预测器来促进。它使得来自不同增强的特征能够聚合到一个代表性的嵌入中，提供强大的监督。值得注意的是，这是在最小计算开销的情况下实现的。大量消融研究和定性结果验证了我们方法的有效性。

    arXiv:2403.09502v1 Announce Type: cross  Abstract: Recent advancements in self-supervised audio-visual representation learning have demonstrated its potential to capture rich and comprehensive representations. However, despite the advantages of data augmentation verified in many learning methods, audio-visual learning has struggled to fully harness these benefits, as augmentations can easily disrupt the correspondence between input pairs. To address this limitation, we introduce EquiAV, a novel framework that leverages equivariance for audio-visual contrastive learning. Our approach begins with extending equivariance to audio-visual learning, facilitated by a shared attention-based transformation predictor. It enables the aggregation of features from diverse augmentations into a representative embedding, providing robust supervision. Notably, this is achieved with minimal computational overhead. Extensive ablation studies and qualitative results verify the effectiveness of our method. 
    
[^12]: 一个问题中心的多专家对比学习框架，用于提高深度序列知识追踪模型的准确性和可解释性

    A Question-centric Multi-experts Contrastive Learning Framework for Improving the Accuracy and Interpretability of Deep Sequential Knowledge Tracing Models

    [https://arxiv.org/abs/2403.07322](https://arxiv.org/abs/2403.07322)

    通过一个问题中心的多专家对比学习框架，提高深度序列知识追踪模型的准确性和可解释性，解决了知识追踪中个体问题信息建模和模型预测结果解释的重要挑战

    

    知识追踪在通过分析学生历史学习过程来预测其未来表现中发挥着至关重要的作用。深度神经网络在解决知识追踪问题方面展现出巨大潜力。然而，将深度学习技术应用于模拟知识追踪过程仍然存在一些重要挑战。第一个挑战在于将问题的个体信息融入建模中。这很关键，因为尽管问题共享相同的知识组件（KC），但学生对同质问题的知识习得可以有显著差异。第二个挑战在于解释现有基于深度学习的知识追踪模型的预测结果。在真实应用中，虽然可能并不需要完全透明和可解释的模型参数，但关键是以老师能理解的方式呈现模型的预测结果。

    arXiv:2403.07322v1 Announce Type: cross  Abstract: Knowledge tracing (KT) plays a crucial role in predicting students' future performance by analyzing their historical learning processes. Deep neural networks (DNNs) have shown great potential in solving the KT problem. However, there still exist some important challenges when applying deep learning techniques to model the KT process. The first challenge lies in taking the individual information of the question into modeling. This is crucial because, despite questions sharing the same knowledge component (KC), students' knowledge acquisition on homogeneous questions can vary significantly. The second challenge lies in interpreting the prediction results from existing deep learning-based KT models. In real-world applications, while it may not be necessary to have complete transparency and interpretability of the model parameters, it is crucial to present the model's prediction results in a manner that teachers find interpretable. This ma
    
[^13]: 针对持续学习场景的自适应超参数优化

    Adaptive Hyperparameter Optimization for Continual Learning Scenarios

    [https://arxiv.org/abs/2403.07015](https://arxiv.org/abs/2403.07015)

    本文旨在探讨在持续学习中的超参数选择作用和根据任务复杂性持续自动调整它们的必要性，通过利用序列任务学习特性来提高超参数优化效率，实验证明这种方法可以使超参数优化在不同任务中持续加速。

    

    在持续学习场景中，超参数选择是一个具有挑战性和尚未充分探索的方面，特别是在实际非平稳环境中。本文旨在探讨超参数选择在持续学习中的作用，以及根据手头任务的复杂性持续自动调整它们的必要性。因此，我们提出利用序列任务学习的特性来提高超参数优化效率。通过使用基于方差的功能分析技术，我们识别出对性能产生影响的最关键的超参数。我们通过经验性地证明，这种方法无视持续场景和策略，使我们能够持续加快超参数在不同任务间的优化，并展示

    arXiv:2403.07015v1 Announce Type: new  Abstract: Hyperparameter selection in continual learning scenarios is a challenging and underexplored aspect, especially in practical non-stationary environments. Traditional approaches, such as grid searches with held-out validation data from all tasks, are unrealistic for building accurate lifelong learning systems. This paper aims to explore the role of hyperparameter selection in continual learning and the necessity of continually and automatically tuning them according to the complexity of the task at hand. Hence, we propose leveraging the nature of sequence task learning to improve Hyperparameter Optimization efficiency. By using the functional analysis of variance-based techniques, we identify the most crucial hyperparameters that have an impact on performance. We demonstrate empirically that this approach, agnostic to continual scenarios and strategies, allows us to speed up hyperparameters optimization continually across tasks and exhibit
    
[^14]: 关于持续学习中宽度递减回报的研究

    On the Diminishing Returns of Width for Continual Learning

    [https://arxiv.org/abs/2403.06398](https://arxiv.org/abs/2403.06398)

    增加神经网络宽度以减少遗忘会带来递减的回报，并且在先前研究中尚未探索的宽度范围内进行了实证验证。

    

    深度神经网络在各种设置中展示了突破性的性能，但这些模型在按顺序训练新任务时经常出现“灾难性遗忘”。 一些研究已经经验性地证明增加神经网络宽度会导致灾难性遗忘减少，但尚未准确刻画宽度和持续学习之间的确切关系。我们设计了其中一个最早的框架来分析持续学习理论，并证明宽度与前馈网络（FFN）中的遗忘直接相关。 具体来说，我们证明增加网络宽度以减少遗忘会带来递减的回报。我们在先前研究中尚未探索的宽度上经验性验证了我们的论断，结果显示递减回报如我们的理论所预测的那样清晰可见。

    arXiv:2403.06398v1 Announce Type: cross  Abstract: While deep neural networks have demonstrated groundbreaking performance in various settings, these models often suffer from \emph{catastrophic forgetting} when trained on new tasks in sequence. Several works have empirically demonstrated that increasing the width of a neural network leads to a decrease in catastrophic forgetting but have yet to characterize the exact relationship between width and continual learning. We design one of the first frameworks to analyze Continual Learning Theory and prove that width is directly related to forgetting in Feed-Forward Networks (FFN). Specifically, we demonstrate that increasing network widths to reduce forgetting yields diminishing returns. We empirically verify our claims at widths hitherto unexplored in prior studies where the diminishing returns are clearly observed as predicted by our theory.
    
[^15]: 解读AI笔: 检测AI生成文本的技术与挑战

    Decoding the AI Pen: Techniques and Challenges in Detecting AI-Generated Text

    [https://arxiv.org/abs/2403.05750](https://arxiv.org/abs/2403.05750)

    大型语言模型在自然语言生成领域取得了重大突破，提出了识别AI生成文本的解决方案，并探索了未来研究方向。

    

    大型语言模型(LLMs)通过展示生成类人文本的惊人能力，彻底颠覆了自然语言生成(NLG)领域。然而，它们广泛的应用带来挑战，需要深入审查、伦理审查和负责任的实践。本研究探讨了这些挑战，探索了现有的缓解策略，重点是识别AI生成文本作为最终解决方案。此外，我们从理论角度评估了检测的可行性，并提出了解决当前领域限制的新颖研究方向。

    arXiv:2403.05750v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have revolutionized the field of Natural Language Generation (NLG) by demonstrating an impressive ability to generate human-like text. However, their widespread usage introduces challenges that necessitate thoughtful examination, ethical scrutiny, and responsible practices. In this study, we delve into these challenges, explore existing strategies for mitigating them, with a particular emphasis on identifying AI-generated text as the ultimate solution. Additionally, we assess the feasibility of detection from a theoretical perspective and propose novel research directions to address the current limitations in this domain.
    
[^16]: Vlearn：使用高效状态值函数估计的离策略学习

    Vlearn: Off-Policy Learning with Efficient State-Value Function Estimation

    [https://arxiv.org/abs/2403.04453](https://arxiv.org/abs/2403.04453)

    Vlearn提出了一种新颖的离策略优化方法，称为Vlearn，它通过仅利用状态值函数作为评论家，消除了对明确状态-动作-值函数的需求，从而解决了高维动作空间中的计算挑战。

    

    存在的离策略强化学习算法通常需要明确状态-动作-值函数表示，这在高维动作空间中变得棘手。这些算法经常遇到挑战，即它们在处理维度灾难时遇到困难，因为在这样的空间中维护状态-动作-值函数变得数据效率低下。在这项工作中，我们提出了一种名为Vlearn的新型离策略信任区域优化方法，它消除了对明确状态-动作-值函数的要求。相反，我们展示了如何有效地利用状态值函数作为评论家，从而克服现有方法的几个局限性。通过这样做，Vlearn解决了高维动作空间所带来的计算挑战。此外，Vlearn引入了一种有效的方法来解决与纯状态值函数学习相关的离策略学习中的挑战。

    arXiv:2403.04453v1 Announce Type: new  Abstract: Existing off-policy reinforcement learning algorithms typically necessitate an explicit state-action-value function representation, which becomes problematic in high-dimensional action spaces. These algorithms often encounter challenges where they struggle with the curse of dimensionality, as maintaining a state-action-value function in such spaces becomes data-inefficient. In this work, we propose a novel off-policy trust region optimization approach, called Vlearn, that eliminates the requirement for an explicit state-action-value function. Instead, we demonstrate how to efficiently leverage just a state-value function as the critic, thus overcoming several limitations of existing methods. By doing so, Vlearn addresses the computational challenges posed by high-dimensional action spaces. Furthermore, Vlearn introduces an efficient approach to address the challenges associated with pure state-value function learning in the off-policy se
    
[^17]: 用于处理因变量选择的活跃自适应实验设计的处理效应估计

    Active Adaptive Experimental Design for Treatment Effect Estimation with Covariate Choices

    [https://arxiv.org/abs/2403.03589](https://arxiv.org/abs/2403.03589)

    该研究提出了一种更有效地估计处理效应的活跃自适应实验设计方法，通过优化协变量密度和倾向得分来降低渐近方差。

    

    这项研究设计了一个自适应实验，用于高效地估计平均处理效应（ATEs）。我们考虑了一个自适应实验，其中实验者按顺序从由实验者决定的协变量密度中抽样一个实验单元，并分配一种处理。在分配处理后，实验者立即观察相应的结果。在实验结束时，实验者利用收集的样本估算出一个ATE。实验者的目标是通过较小的渐近方差估计ATE。现有研究已经设计了一些能够自适应优化倾向得分（处理分配概率）的实验。作为这种方法的一个概括，我们提出了一个框架，该框架下实验者优化协变量密度以及倾向得分，并发现优化协变量密度和倾向得分比仅优化倾向得分可以减少渐近方差更多的情况。

    arXiv:2403.03589v1 Announce Type: cross  Abstract: This study designs an adaptive experiment for efficiently estimating average treatment effect (ATEs). We consider an adaptive experiment where an experimenter sequentially samples an experimental unit from a covariate density decided by the experimenter and assigns a treatment. After assigning a treatment, the experimenter observes the corresponding outcome immediately. At the end of the experiment, the experimenter estimates an ATE using gathered samples. The objective of the experimenter is to estimate the ATE with a smaller asymptotic variance. Existing studies have designed experiments that adaptively optimize the propensity score (treatment-assignment probability). As a generalization of such an approach, we propose a framework under which an experimenter optimizes the covariate density, as well as the propensity score, and find that optimizing both covariate density and propensity score reduces the asymptotic variance more than o
    
[^18]: 面向证据的事实摘要化用于知识增强的零-shot问答

    Evidence-Focused Fact Summarization for Knowledge-Augmented Zero-Shot Question Answering

    [https://arxiv.org/abs/2403.02966](https://arxiv.org/abs/2403.02966)

    提出了一种面向证据的事实摘要化框架EFSum，用于增强LLMs的零-shot QA性能，并确保摘要的有益性和忠实性。

    

    最近的研究探讨了利用知识图谱（KGs）来增强大语言模型（LLMs）的问答（QA）性能，然而结构化的KG形式化仍然具有挑战性。现有方法，如三元组形式或三元组事实的自由文本转换，遇到了一些问题。这些问题包括由于重复实体或关系而导致的证据密度降低，以及由于无法强调关键证据而导致的证据清晰度降低。为解决这些问题，我们提出了EFSum，一个面向证据的事实摘要化框架，用于通过知识增强的LLMs增强QA。我们通过蒸馏和偏好对齐来优化一个开源的LLM作为事实摘要器。我们的广泛实验证明，EFSum提高了LLM的零-shot QA性能，并且可以确保摘要的同时有益和忠实。

    arXiv:2403.02966v1 Announce Type: cross  Abstract: Recent studies have investigated utilizing Knowledge Graphs (KGs) to enhance Quesetion Answering (QA) performance of Large Language Models (LLMs), yet structured KG verbalization remains challengin. Existing methods, such as triple-form or free-form textual conversion of triple-form facts, encounter several issues. These include reduced evidence density due to duplicated entities or relationships, and reduced evidence clarity due to an inability to emphasize crucial evidence. To address these issues, we propose EFSum, an Evidence-focused Fact Summarization framework for enhanced QA with knowledge-augmented LLMs. We optimize an open-source LLM as a fact summarizer through distillation and preference alignment. Our extensive experiments show that EFSum improves LLM's zero-shot QA performance, and it is possible to ensure both the helpfulness and faithfulness of the summary.
    
[^19]: 关于无需数据相似性条件的联邦学习算法收敛性

    On the Convergence of Federated Learning Algorithms without Data Similarity

    [https://arxiv.org/abs/2403.02347](https://arxiv.org/abs/2403.02347)

    本文提出了一种无需数据相似性条件的联邦学习算法收敛性分析框架，通过推导出三种常用步长调度的精确表达式，实现了对算法收敛性能的全面评估。

    

    数据相似性假设传统上被广泛依赖于理解联邦学习方法的收敛行为。不幸的是，这种方法通常要求根据数据相似性程度微调步长。当数据相似性较低时，这些小步长会导致联邦方法的收敛速度不可接受地慢。本文提出了一种新颖和统一的框架，用于分析联邦学习算法的收敛性，无需数据相似性条件。我们的分析集中在一个不等式上，这个不等式捕捉了步长对算法收敛性能的影响。通过将我们的定理应用于众所周知的联邦算法，我们推导出了三种广泛使用的步长调度的精确表达式：固定步长、递减步长和步衰减步长，这些表达式独立于数据相似性条件。最后，我们对性能进行了全面评估。

    arXiv:2403.02347v1 Announce Type: new  Abstract: Data similarity assumptions have traditionally been relied upon to understand the convergence behaviors of federated learning methods. Unfortunately, this approach often demands fine-tuning step sizes based on the level of data similarity. When data similarity is low, these small step sizes result in an unacceptably slow convergence speed for federated methods. In this paper, we present a novel and unified framework for analyzing the convergence of federated learning algorithms without the need for data similarity conditions. Our analysis centers on an inequality that captures the influence of step sizes on algorithmic convergence performance. By applying our theorems to well-known federated algorithms, we derive precise expressions for three widely used step size schedules: fixed, diminishing, and step-decay step sizes, which are independent of data similarity conditions. Finally, we conduct comprehensive evaluations of the performance 
    
[^20]: FlowPrecision: 利用线性量化推进基于FPGA的实时流体流量估计

    FlowPrecision: Advancing FPGA-Based Real-Time Fluid Flow Estimation with Linear Quantization

    [https://arxiv.org/abs/2403.01922](https://arxiv.org/abs/2403.01922)

    本研究将线性量化应用于FPGA-based soft sensors中，显著提高了神经网络模型精度，通过硬件优化实现了降低均方误差和提升推理速度，为实时流体流量估计提供了高效、精确的替代方案

    

    在工业和环境监测中，实现实时和精确的流体流量测量仍然是一个重要挑战。本研究将线性量化应用于基于FPGA的软传感器中，用于流体流量估计，通过克服传统定点量化的局限性，显著增强了神经网络模型的精度。我们的方法通过针对性的硬件优化，实现了均方误差的最多减少10.10％，推理速度显著提高了9.39％。经过多个数据集的验证，我们的研究结果表明，优化后的基于FPGA的量化模型可以提供高效、精确的实时推理，为普遍自主系统中的云处理提供了一种可行的替代方案。

    arXiv:2403.01922v1 Announce Type: new  Abstract: In industrial and environmental monitoring, achieving real-time and precise fluid flow measurement remains a critical challenge. This study applies linear quantization in FPGA-based soft sensors for fluid flow estimation, significantly enhancing Neural Network model precision by overcoming the limitations of traditional fixed-point quantization. Our approach achieves up to a 10.10% reduction in Mean Squared Error and a notable 9.39% improvement in inference speed through targeted hardware optimizations. Validated across multiple data sets, our findings demonstrate that the optimized FPGA-based quantized models can provide efficient, accurate real-time inference, offering a viable alternative to cloud-based processing in pervasive autonomous systems.
    
[^21]: Actor-Critic中的过度估计、过拟合和可塑性：强化学习的苦涩教训

    Overestimation, Overfitting, and Plasticity in Actor-Critic: the Bitter Lesson of Reinforcement Learning

    [https://arxiv.org/abs/2403.00514](https://arxiv.org/abs/2403.00514)

    实施超过60种不同的离策略代理，发现某些组合表现出稳健和优越的性能，揭示了特定正则化设置与任务的关联性约几维多多。

    

    最近，强化学习（RL）中离策略的进展显著提高了样本效率，主要是由于各种形式的正则化的应用，使其比传统的代理更能进行梯度更新步骤。然而，许多这些技术都在有限的情景下进行了测试，通常只在单个仿真基准任务上测试，与众所周知的算法相比，而不是与一系列正则化方法相比。这限制了我们对推动RL改进的具体机制的理解。为了解决这个问题，我们实现了超过60种不同的离策略代理，每个代理都整合了最近最先进算法中的已建立的正则化技术。我们在来自2个仿真基准的14个不同任务上测试了这些代理。我们的研究结果表明，尽管特定的正则化设置的效果因任务而异，但某些组合始终表现出稳健和优越的性能。

    arXiv:2403.00514v1 Announce Type: new  Abstract: Recent advancements in off-policy Reinforcement Learning (RL) have significantly improved sample efficiency, primarily due to the incorporation of various forms of regularization that enable more gradient update steps than traditional agents. However, many of these techniques have been tested in limited settings, often on tasks from single simulation benchmarks and against well-known algorithms rather than a range of regularization approaches. This limits our understanding of the specific mechanisms driving RL improvements. To address this, we implemented over 60 different off-policy agents, each integrating established regularization techniques from recent state-of-the-art algorithms. We tested these agents across 14 diverse tasks from 2 simulation benchmarks. Our findings reveal that while the effectiveness of a specific regularization setup varies with the task, certain combinations consistently demonstrate robust and superior perform
    
[^22]: 超声成像阵列编码的优化

    Optimization of Array Encoding for Ultrasound Imaging

    [https://arxiv.org/abs/2403.00289](https://arxiv.org/abs/2403.00289)

    利用机器学习构建扫描序列，产生高质量超声B模式图像，并优化超声成像编码序列。

    

    目标：合成孔径成像的发射编码模型是理解超声成像重建的声学传输效应的稳健而灵活的框架。我们的目标是利用机器学习（ML）构建由时间延迟和簧应权参数化的扫描序列，以产生高质量的B模式图像。方法：我们使用PyTorch中的ML模型，并从Field II生成模拟RF数据，探究可能编码序列空间，以找到能够最小化描述图像质量的损失函数的序列。这种方法通过一种新颖的延迟-求和波束成形导数的公式化，在计算上变得可行。我们在金属丝靶和组织模拟幻像上通过实验证实了这些结果。主要结果：根据给定的成像参数（成像域，硬件限制）训练后，我们的ML成像模型产生了优化的编码序列。

    arXiv:2403.00289v1 Announce Type: cross  Abstract: Objective: The transmit encoding model for synthetic aperture imaging is a robust and flexible framework for understanding the effect of acoustic transmission on ultrasound image reconstruction. Our objective is to use machine learning (ML) to construct scanning sequences, parameterized by time delays and apodization weights, that produce high quality B-mode images. Approach: We use an ML model in PyTorch and simulated RF data from Field II to probe the space of possible encoding sequences for those that minimize a loss function that describes image quality. This approach is made computationally feasible by a novel formulation of the derivative for delay-and-sum beamforming. We demonstrate these results experimentally on wire targets and a tissue-mimicking phantom. Main Results: When trained according to a given set of imaging parameters (imaging domain, hardware restrictions), our ML imaging model produces optimized encoding sequences
    
[^23]: FedStruct：联合解耦学习在互联图上

    FedStruct: Federated Decoupled Learning over Interconnected Graphs

    [https://arxiv.org/abs/2402.19163](https://arxiv.org/abs/2402.19163)

    FedStruct提出了一种新的框架，利用深层结构依赖关系在互联图上进行联合解耦学习，有效地维护隐私并捕捉节点间的依赖关系。

    

    我们解决了分布在多个客户端上的图结构数据上的联合学习挑战。具体来说，我们关注互联子图的普遍情况，其中不同客户端之间的相互连接起着关键作用。我们提出了针对这种情况的一种新颖框架，名为FedStruct，它利用深层结构依赖关系。为了维护隐私，与现有方法不同，FedStruct消除了在客户端之间共享或生成敏感节点特征或嵌入的必要性。相反，它利用显式全局图结构信息来捕捉节点间的依赖关系。我们通过在六个数据集上进行的实验结果验证了FedStruct的有效性，展示了在各种情况下（包括不同数据分区方法、不同标签可用性以及客户个数的）接近于集中式方法的性能。

    arXiv:2402.19163v1 Announce Type: new  Abstract: We address the challenge of federated learning on graph-structured data distributed across multiple clients. Specifically, we focus on the prevalent scenario of interconnected subgraphs, where inter-connections between different clients play a critical role. We present a novel framework for this scenario, named FedStruct, that harnesses deep structural dependencies. To uphold privacy, unlike existing methods, FedStruct eliminates the necessity of sharing or generating sensitive node features or embeddings among clients. Instead, it leverages explicit global graph structure information to capture inter-node dependencies. We validate the effectiveness of FedStruct through experimental results conducted on six datasets for semi-supervised node classification, showcasing performance close to the centralized approach across various scenarios, including different data partitioning methods, varying levels of label availability, and number of cl
    
[^24]: 多目标可微神经架构搜索

    Multi-objective Differentiable Neural Architecture Search

    [https://arxiv.org/abs/2402.18213](https://arxiv.org/abs/2402.18213)

    提出了一种新颖的NAS算法，可以在一个搜索运行中编码用户对性能和硬件指标之间的权衡偏好，生成精心选择的多设备架构。

    

    多目标优化（MOO）中的Pareto前沿轮廓剖析是具有挑战性的，尤其是在像神经网络训练这样的昂贵目标中。 相对于传统的NAS方法，我们提出了一种新颖的NAS算法，该算法在一个搜索运行中编码用户对性能和硬件指标之间的权衡偏好，并生成精心选择的多设备架构。为此，我们通过一个超网络参数化跨多个设备和多个目标的联合架构分布，超网络可以根据硬件特征和偏好向量进行条件化，实现零次搜索。

    arXiv:2402.18213v1 Announce Type: new  Abstract: Pareto front profiling in multi-objective optimization (MOO), i.e. finding a diverse set of Pareto optimal solutions, is challenging, especially with expensive objectives like neural network training. Typically, in MOO neural architecture search (NAS), we aim to balance performance and hardware metrics across devices. Prior NAS approaches simplify this task by incorporating hardware constraints into the objective function, but profiling the Pareto front necessitates a search for each constraint. In this work, we propose a novel NAS algorithm that encodes user preferences for the trade-off between performance and hardware metrics, and yields representative and diverse architectures across multiple devices in just one search run. To this end, we parameterize the joint architectural distribution across devices and multiple objectives via a hypernetwork that can be conditioned on hardware features and preference vectors, enabling zero-shot t
    
[^25]: 关于基于人口统计学平等的公平学习算法的归纳偏差

    On the Inductive Biases of Demographic Parity-based Fair Learning Algorithms

    [https://arxiv.org/abs/2402.18129](https://arxiv.org/abs/2402.18129)

    分析了标准 DP 基础正则化方法对给定敏感属性的预测标签条件分布的影响，并提出了一种基于敏感属性的分布稳健优化方法来控制归纳偏差。

    

    公平的监督式学习算法在机器学习领域备受关注，这些算法在分配标签时很少依赖敏感属性。本文分析了标准DP（人口统计学平等）基础正则化方法对给定敏感属性的预测标签条件分布的影响。我们的分析表明，在具有非均匀分布敏感属性的训练数据集中，可能会导致分类规则偏向占据大多数训练数据的敏感属性结果。为了控制DP-based公平学习中的这种归纳偏差，我们提出了基于敏感属性的分布稳健优化（SA）

    arXiv:2402.18129v1 Announce Type: cross  Abstract: Fair supervised learning algorithms assigning labels with little dependence on a sensitive attribute have attracted great attention in the machine learning community. While the demographic parity (DP) notion has been frequently used to measure a model's fairness in training fair classifiers, several studies in the literature suggest potential impacts of enforcing DP in fair learning algorithms. In this work, we analytically study the effect of standard DP-based regularization methods on the conditional distribution of the predicted label given the sensitive attribute. Our analysis shows that an imbalanced training dataset with a non-uniform distribution of the sensitive attribute could lead to a classification rule biased toward the sensitive attribute outcome holding the majority of training data. To control such inductive biases in DP-based fair learning, we propose a sensitive attribute-based distributionally robust optimization (SA
    
[^26]: 神经势预训练策略

    Pretraining Strategy for Neural Potentials

    [https://arxiv.org/abs/2402.15921](https://arxiv.org/abs/2402.15921)

    通过提出的面向图神经网络的掩码预训练方法，改善了GNN在拟合水系统势能表面方面的性能，并在精度和收敛速度上优于从头开始训练或使用其他预训练技术。

    

    我们提出了一种面向图神经网络(GNNs)的掩码预训练方法，以提高其在拟合势能表面方面的性能，特别是在水系统中。GNNs通过从分子中恢复与掩码的原子相关的空间信息进行预训练，然后在原子力场上进行转移和微调。通过这种预训练，GNNs学习了关于分子系统的结构和潜在物理信息的有意义先验，对于下游任务是有用的。通过全面的实验和消融研究，我们展示了所提出的方法相对于从头开始训练或使用其他预训练技术（如去噪）的GNNs，在精度和收敛速度上的提高。另一方面，我们的预训练方法适用于以能量为中心和以力为中心的GNNs。这种方法展示了它在拟合分子力场方面提高了GNNs的性能和数据效率的潜力。

    arXiv:2402.15921v1 Announce Type: new  Abstract: We propose a mask pretraining method for Graph Neural Networks (GNNs) to improve their performance on fitting potential energy surfaces, particularly in water systems. GNNs are pretrained by recovering spatial information related to masked-out atoms from molecules, then transferred and finetuned on atomic forcefields. Through such pretraining, GNNs learn meaningful prior about structural and underlying physical information of molecule systems that are useful for downstream tasks. From comprehensive experiments and ablation studies, we show that the proposed method improves the accuracy and convergence speed compared to GNNs trained from scratch or using other pretraining techniques such as denoising. On the other hand, our pretraining method is suitable for both energy-centric and force-centric GNNs. This approach showcases its potential to enhance the performance and data efficiency of GNNs in fitting molecular force fields.
    
[^27]: OAG-Bench：面向学术图挖掘的人工筛选基准

    OAG-Bench: A Human-Curated Benchmark for Academic Graph Mining

    [https://arxiv.org/abs/2402.15810](https://arxiv.org/abs/2402.15810)

    OAG-Bench是一个基于开放学术图的全面、多方面和精细化人工筛选基准，涵盖了多个任务、数据集、基准和实验结果，旨在促进学术图挖掘。

    

    随着科学文献的迅速增长，多功能的学术知识服务越来越依赖全面的学术图挖掘。尽管公开学术图、基准和数据集已经有了，但这些资源通常在多方面和细粒度注释方面存在不足，受限于特定任务类型和领域，或者缺乏真实学术图。本文提出了基于开放学术图（OAG）的全面、多方面和精细化人工筛选基准OAG-Bench。OAG-Bench涵盖了10个任务，20个数据集，70+个基准和120+个截至目前的实验结果。我们针对某些任务提出了新的数据注释策略，并提供一套数据预处理代码、算法实现和标准化评估协议，以促进学术图挖掘。大量实验表明，即使是大型语言模型（LLMs）这样的先进算法也会在某些任务上受限。

    arXiv:2402.15810v1 Announce Type: cross  Abstract: With the rapid proliferation of scientific literature, versatile academic knowledge services increasingly rely on comprehensive academic graph mining. Despite the availability of public academic graphs, benchmarks, and datasets, these resources often fall short in multi-aspect and fine-grained annotations, are constrained to specific task types and domains, or lack underlying real academic graphs. In this paper, we present OAG-Bench, a comprehensive, multi-aspect, and fine-grained human-curated benchmark based on the Open Academic Graph (OAG). OAG-Bench covers 10 tasks, 20 datasets, 70+ baselines, and 120+ experimental results to date. We propose new data annotation strategies for certain tasks and offer a suite of data pre-processing codes, algorithm implementations, and standardized evaluation protocols to facilitate academic graph mining. Extensive experiments reveal that even advanced algorithms like large language models (LLMs) en
    
[^28]: 评估ChatGPT用于垃圾邮件检测的性能

    Evaluating the Performance of ChatGPT for Spam Email Detection

    [https://arxiv.org/abs/2402.15537](https://arxiv.org/abs/2402.15537)

    该研究评估了ChatGPT在英文和中文电子邮件数据集中用于垃圾邮件检测的性能，并探讨了其在这一领域的潜力。

    

    电子邮件继续是专业和商业领域中至关重要且广泛使用的通信媒介。然而，垃圾邮件的普及给用户带来了重大挑战，扰乱了他们的日常工作并降低了生产率。因此，基于内容准确地识别和过滤垃圾邮件对网络安全至关重要。最近自然语言处理领域的发展，特别是大型语言模型如ChatGPT，在诸如问答和文本生成等任务中表现出色。然而，其在垃圾邮件识别方面的潜力尚未得到充分探索。为了填补这一空白，本研究尝试评估ChatGPT在英文和中文电子邮件数据集中用于垃圾邮件识别的能力。我们利用ChatGPT进行垃圾邮件检测，采用上下文学习，需要提示说明和少量示范。

    arXiv:2402.15537v1 Announce Type: cross  Abstract: Email continues to be a pivotal and extensively utilized communication medium within professional and commercial domains. Nonetheless, the prevalence of spam emails poses a significant challenge for users, disrupting their daily routines and diminishing productivity. Consequently, accurately identifying and filtering spam based on content has become crucial for cybersecurity. Recent advancements in natural language processing, particularly with large language models like ChatGPT, have shown remarkable performance in tasks such as question answering and text generation. However, its potential in spam identification remains underexplored. To fill in the gap, this study attempts to evaluate ChatGPT's capabilities for spam identification in both English and Chinese email datasets. We employ ChatGPT for spam email detection using in-context learning, which requires a prompt instruction and a few demonstrations. We also investigate how the t
    
[^29]: 主动少样本微调

    Active Few-Shot Fine-Tuning

    [https://arxiv.org/abs/2402.15441](https://arxiv.org/abs/2402.15441)

    该论文提出了ITL方法来实现主动少样本微调，通过最大化对下游任务的信息获取，从而在大型神经网络的微调中取得了显著的改进。

    

    我们研究了大型神经网络对下游任务进行主动少样本微调。我们表明少样本微调是传统主动学习和转导主动学习的泛化实例，我们提出了信息基于转导学习（ITL）的方法，该方法自适应地进行采样以最大化获得对指定下游任务的信息。在一般正则性假设下，我们证明ITL均匀收敛到可从可访问数据获取的最小可能的不确定性。据我们所知，我们是首批推导出这种泛化界限的人，这对于主动学习可能是具有独立意义的。我们将ITL应用于大型神经网络的少样本微调中，结果显示ITL明显改进了现有技术。

    arXiv:2402.15441v1 Announce Type: cross  Abstract: We study the active few-shot fine-tuning of large neural networks to downstream tasks. We show that few-shot fine-tuning is an instance of a generalization of classical active learning, transductive active learning, and we propose ITL, short for information-based transductive learning, an approach which samples adaptively to maximize the information gained about specified downstream tasks. Under general regularity assumptions, we prove that ITL converges uniformly to the smallest possible uncertainty obtainable from the accessible data. To the best of our knowledge, we are the first to derive generalization bounds of this kind, and they may be of independent interest for active learning. We apply ITL to the few-shot fine-tuning of large neural networks and show that ITL substantially improves upon the state-of-the-art.
    
[^30]: Chain-of-Thought不忠诚作为伪装的准确性

    Chain-of-Thought Unfaithfulness as Disguised Accuracy

    [https://arxiv.org/abs/2402.14897](https://arxiv.org/abs/2402.14897)

    了解Chain-of-Thought生成与大语言模型内部计算的一致程度对于决定是否信任模型输出至关重要，研究发现模型大小与忠实度之间存在着特定关系，并且发现130亿参数模型表现出更高的忠实度。

    

    了解Chain-of-Thought (CoT)生成与大语言模型(LLM)内部计算的一致程度对于决定是否信任LLM的输出至关重要。作为CoT忠实度的代理，arXiv:2307.13702提出了一个度量模型依赖其CoT生成答案的指标。在一个专有模型系列中，他们发现LLM表现出模型大小与其忠实度测量之间的缩放-反向缩放关系，并且130亿参数模型相比于尺寸介于8.1亿到1750亿参数之间的模型表现出增加的忠实度。我们评估这些结果是否作为所有LLM的特性泛化。我们使用三种不同系列的模型复制他们的实验设置，并在特定条件下，成功复制了他们报告的CoT忠实度的缩放趋势。然而，我们发现简单的改变设定会导致这些模式在多大程度上重复。

    arXiv:2402.14897v1 Announce Type: cross  Abstract: Understanding the extent to which Chain-of-Thought (CoT) generations align with a large language model's (LLM) internal computations is critical for deciding whether to trust an LLM's output. As a proxy for CoT faithfulness, arXiv:2307.13702 propose a metric that measures a model's dependence on its CoT for producing an answer. Within a single family of proprietary models, they find that LLMs exhibit a scaling-then-inverse-scaling relationship between model size and their measure of faithfulness, and that a 13 billion parameter model exhibits increased faithfulness compared to models ranging from 810 million to 175 billion parameters in size. We evaluate whether these results generalize as a property of all LLMs. We replicate their experimental setup with three different families of models and, under specific conditions, successfully reproduce the scaling trends for CoT faithfulness they report. However, we discover that simply changin
    
[^31]: DynGMA：一种从数据学习随机微分方程的稳健方法

    DynGMA: a robust approach for learning stochastic differential equations from data

    [https://arxiv.org/abs/2402.14475](https://arxiv.org/abs/2402.14475)

    DynGMA方法通过引入新的密度近似，优于基准方法在学习完全未知的漂移和扩散函数以及计算不变性方面的准确性。

    

    从观测数据中学习未知的随机微分方程（SDEs）是一项重要且具有挑战性的任务，应用于各个领域。本文引入了新的近似参数化SDE转移密度的方法：受动力系统随机摄动理论启发的高斯密度近似，以及它的扩展，动力高斯混合近似（DynGMA）。受益于稳健的密度近似，我们的方法在学习完全未知的漂移和扩散函数以及计算矩不变性方面表现出优越的准确性。

    arXiv:2402.14475v1 Announce Type: new  Abstract: Learning unknown stochastic differential equations (SDEs) from observed data is a significant and challenging task with applications in various fields. Current approaches often use neural networks to represent drift and diffusion functions, and construct likelihood-based loss by approximating the transition density to train these networks. However, these methods often rely on one-step stochastic numerical schemes, necessitating data with sufficiently high time resolution. In this paper, we introduce novel approximations to the transition density of the parameterized SDE: a Gaussian density approximation inspired by the random perturbation theory of dynamical systems, and its extension, the dynamical Gaussian mixture approximation (DynGMA). Benefiting from the robust density approximation, our method exhibits superior accuracy compared to baseline methods in learning the fully unknown drift and diffusion functions and computing the invari
    
[^32]: 使用自适应图卷积网络对3D婴儿动力学进行建模

    Modeling 3D Infant Kinetics Using Adaptive Graph Convolutional Networks

    [https://arxiv.org/abs/2402.14400](https://arxiv.org/abs/2402.14400)

    使用数据驱动评估个体动作模式，利用自适应图卷积网络对3D婴儿动力学进行建模，相较于传统机器学习取得了改进。

    

    可靠的婴儿神经发育评估方法对于早期发现可能需要及时干预的医学问题至关重要。自发的运动活动，即“动力学”，被证明可提供一个强有力的预测未来神经发育的替代性测量。然而，它的评估在很大程度上是定性和主观的，侧重于对通过视觉识别的特定年龄手势的描述。在这里，我们采用了一种替代方法，根据数据驱动评估个体动作模式来预测婴儿神经发育成熟。我们利用处理过的3D婴儿视频录像进行姿势估计，提取解剖标志物的时空系列，并应用自适应图卷积网络来预测实际年龄。我们展示了我们的数据驱动方法相对于基于手动设计特征的传统机器学习基线取得了改进。

    arXiv:2402.14400v1 Announce Type: cross  Abstract: Reliable methods for the neurodevelopmental assessment of infants are essential for early detection of medical issues that may need prompt interventions. Spontaneous motor activity, or `kinetics', is shown to provide a powerful surrogate measure of upcoming neurodevelopment. However, its assessment is by and large qualitative and subjective, focusing on visually identified, age-specific gestures. Here, we follow an alternative approach, predicting infants' neurodevelopmental maturation based on data-driven evaluation of individual motor patterns. We utilize 3D video recordings of infants processed with pose-estimation to extract spatio-temporal series of anatomical landmarks, and apply adaptive graph convolutional networks to predict the actual age. We show that our data-driven approach achieves improvement over traditional machine learning baselines based on manually engineered features.
    
[^33]: 准时到位：通过限制时间序列模型的解释来修订它们

    Right on Time: Revising Time Series Models by Constraining their Explanations

    [https://arxiv.org/abs/2402.12921](https://arxiv.org/abs/2402.12921)

    引入了准时到位（RioT）方法，通过使模型解释在时间和频率域之间交互，并利用反馈来约束模型，有效地解决了时间序列数据中的混杂因素问题。

    

    深度时间序列模型的可靠性经常会受到其依赖混杂因素的倾向的损害，这可能导致误导性结果。我们的新记录的、自然混杂的数据集P2S来自真实的机械生产线，强调了这一点。为了解决时间序列数据中的混杂因素的挑战性问题，我们引入了准时到位（RioT）。我们的方法使模型解释在时间和频率域之间进行交互。然后利用两个域内的解释反馈来约束模型，使其远离标注的混杂因素。在处理时间序列数据集中混杂因素方面，双域交互策略至关重要。我们凭经验证明，RioT能够有效地引导模型远离P2S以及流行的时间序列分类和预测数据集中的错误原因。

    arXiv:2402.12921v1 Announce Type: new  Abstract: The reliability of deep time series models is often compromised by their tendency to rely on confounding factors, which may lead to misleading results. Our newly recorded, naturally confounded dataset named P2S from a real mechanical production line emphasizes this. To tackle the challenging problem of mitigating confounders in time series data, we introduce Right on Time (RioT). Our method enables interactions with model explanations across both the time and frequency domain. Feedback on explanations in both domains is then used to constrain the model, steering it away from the annotated confounding factors. The dual-domain interaction strategy is crucial for effectively addressing confounders in time series datasets. We empirically demonstrate that RioT can effectively guide models away from the wrong reasons in P2S as well as popular time series classification and forecasting datasets.
    
[^34]: 在摘要中识别事实不一致性：朝向大型语言模型的有效利用

    Identifying Factual Inconsistency in Summaries: Towards Effective Utilization of Large Language Model

    [https://arxiv.org/abs/2402.12821](https://arxiv.org/abs/2402.12821)

    该研究提出了针对摘要中事实不一致性的解决方案：通过大型语言模型在正确的范式设计下无需训练即可解决任务，并提出了训练策略以精炼更小型的高准确性的语言模型。

    

    事实上的不一致性对抽象性摘要生成器的商业部署构成重要障碍。本研究围绕两个重要问题展开：如何最好地利用大型语言模型来检测事实不一致性，以及如何精炼一个同时具有高效性和功效性的更小型语言模型？首先提出并评估了三种零样本范式，跨越五个不同数据集：直接推理整个摘要或每个摘要窗口；通过问题生成和回答进行实体验证。实验表明，在适当的范式设计下，语言模型本身能够在无需训练的情况下解决这一任务，平均超过强大的训练基线2.8%。为进一步促进实用性，我们提出针对精炼更小的开源语言模型的训练策略，该模型可以一次性高准确地评分整个摘要，胜过零

    arXiv:2402.12821v1 Announce Type: new  Abstract: Factual inconsistency poses a significant hurdle for the commercial deployment of abstractive summarizers. Under this Large Language Model (LLM) era, this work focuses around two important questions: what is the best way to leverage LLM for factual inconsistency detection, and how could we distill a smaller LLM with both high efficiency and efficacy? Three zero-shot paradigms are firstly proposed and evaluated across five diverse datasets: direct inference on the entire summary or each summary window; entity verification through question generation and answering. Experiments suggest that LLM itself is capable to resolve this task train-free under the proper paradigm design, surpassing strong trained baselines by 2.8% on average. To further promote practical utility, we then propose training strategies aimed at distilling smaller open-source LLM that learns to score the entire summary at once with high accuracy, which outperforms the zero
    
[^35]: 不同领域和参数的微分同胚神经算子

    Diffeomorphism Neural Operator for various domains and parameters of partial differential equations

    [https://arxiv.org/abs/2402.12475](https://arxiv.org/abs/2402.12475)

    通过微分同胚神经算子学习框架，提出了一种适用于各种和复杂领域的物理系统的领域灵活模型，从而将学习函数映射在不同领域的问题转化为在共享的微分同胚上学习算子的问题。

    

    许多科学和工程应用需要对传统上使用资源密集型数值求解器计算的偏微分方程（PDE）进行评估。神经算子模型通过直接从数据中学习控制物理定律，提供了一种有效的替代方案，适用于具有不同参数的PDE类别，但在固定边界（领域）内受限。许多应用，例如设计和制造，在大规模研究时将受益于具有灵活领域的神经算子。在这里，我们提出了一种微分同胚神经算子学习框架，旨在为具有各种和复杂领域的物理系统开发领域灵活模型。具体来说，提出了一个在由微分同胚从各领域映射而来的共享领域中训练的神经算子，该方法将在不同领域（空间）学习函数映射的问题转化为在共享的微分同胚上学习算子的问题。

    arXiv:2402.12475v1 Announce Type: cross  Abstract: Many science and engineering applications demand partial differential equations (PDE) evaluations that are traditionally computed with resource-intensive numerical solvers. Neural operator models provide an efficient alternative by learning the governing physical laws directly from data in a class of PDEs with different parameters, but constrained in a fixed boundary (domain). Many applications, such as design and manufacturing, would benefit from neural operators with flexible domains when studied at scale. Here we present a diffeomorphism neural operator learning framework towards developing domain-flexible models for physical systems with various and complex domains. Specifically, a neural operator trained in a shared domain mapped from various domains of fields by diffeomorphism is proposed, which transformed the problem of learning function mappings in varying domains (spaces) into the problem of learning operators on a shared dif
    
[^36]: Prospector Heads:大规模模型和数据的广义特征归因

    Prospector Heads: Generalized Feature Attribution for Large Models & Data

    [https://arxiv.org/abs/2402.11729](https://arxiv.org/abs/2402.11729)

    Prospector heads是一种高效且可解释的基于特征归因的替代方法，它可以应用于任何编码器和任何数据形态，并且通过对不同数据形态的实验，表现优越于传统方法。

    

    特征归因是一种定位输入数据中与分类相关的区域的能力，对于科学和生物医学领域的机器学习模型而言，这是一种重要的能力。当前的特征归因方法依赖于“解释”端到端分类器的预测，存在特征定位不精确以及由于计算挑战而无法在小样本尺寸和高维数据集上使用的问题。我们引入了探寻者头部（prospector heads），这是一种高效且可解释的基于特征归因的替代方法，可以应用于任何编码器和任何数据形态。通过对序列（文本）、图像（病理学）和图（蛋白质结构）的实验，探寻者头部在模态之间进行概括，表现优于基线归因方法，平均局部化AUPRC得分提升了高达49点。我们还演示了探寻者头部如何实现了改进的解释能力。

    arXiv:2402.11729v1 Announce Type: cross  Abstract: Feature attribution, the ability to localize regions of the input data that are relevant for classification, is an important capability for machine learning models in scientific and biomedical domains. Current methods for feature attribution, which rely on "explaining" the predictions of end-to-end classifiers, suffer from imprecise feature localization and are inadequate for use with small sample sizes and high-dimensional datasets due to computational challenges. We introduce prospector heads, an efficient and interpretable alternative to explanation-based methods for feature attribution that can be applied to any encoder and any data modality. Prospector heads generalize across modalities through experiments on sequences (text), images (pathology), and graphs (protein structures), outperforming baseline attribution methods by up to 49 points in mean localization AUPRC. We also demonstrate how prospector heads enable improved interpr
    
[^37]: 长期时间序列预测中的吸引子记忆：混沌视角

    Attractor Memory for Long-Term Time Series Forecasting: A Chaos Perspective

    [https://arxiv.org/abs/2402.11463](https://arxiv.org/abs/2402.11463)

    Attraos模型基于混沌理论，在长期时间序列预测中利用多尺度动态记忆单元和局部演化策略，表现优异于其他LTSF方法。

    

    在长期时间序列预测（LTSF）任务中，现有的深度学习模型忽视了离散时间序列源自潜在连续动态系统的关键特征，导致缺乏外推和演化能力。 鉴别真实世界数据的混沌性质，我们的模型\textbf{\textit{Attraos}}将混沌理论融入到LTSF中，将实际时间序列视为未知高维混沌动态系统的观测。 在吸引子不变性的概念下，Attraos利用提出的多尺度动态记忆单元来记忆历史动态结构，并通过频率增强的局部演化策略进行预测。 详细的理论分析和丰富的经验证据一致表明，Attraos在主流LTSF数据集和混沌数据集上的表现优于各种LTSF方法。

    arXiv:2402.11463v1 Announce Type: cross  Abstract: In long-term time series forecasting (LTSF) tasks, existing deep learning models overlook the crucial characteristic that discrete time series originate from underlying continuous dynamic systems, resulting in a lack of extrapolation and evolution capabilities. Recognizing the chaotic nature of real-world data, our model, \textbf{\textit{Attraos}}, incorporates chaos theory into LTSF, perceiving real-world time series as observations from unknown high-dimensional chaotic dynamic systems. Under the concept of attractor invariance, Attraos utilizes the proposed multi-scale dynamic memory unit to memorize historical dynamics structure and predicts by a frequency-enhanced local evolution strategy. Detailed theoretical analysis and abundant empirical evidence consistently show that Attraos outperforms various LTSF methods on mainstream LTSF datasets and chaotic datasets.
    
[^38]: 镜像影响假设：通过利用前向传递实现高效的数据影响估计

    The Mirrored Influence Hypothesis: Efficient Data Influence Estimation by Harnessing Forward Passes

    [https://arxiv.org/abs/2402.08922](https://arxiv.org/abs/2402.08922)

    本文介绍和探讨了镜像影响假设，突出了训练和测试数据之间影响的相互性。具体而言，它指出，评估训练数据对测试预测的影响可以重新表述为一个等效但相反的问题：评估如果模型在特定的测试样本上进行训练，对训练样本的预测将如何改变。通过实证和理论验证，我们演示了这一假设的正确性。

    

    大规模黑盒模型已经在许多应用中变得无处不在。了解个别训练数据源对这些模型所做预测的影响对于改善其可信性至关重要。当前的影响评估技术涉及计算每个训练点的梯度或在不同子集上重复训练。当扩展到大规模数据集和模型时，这些方法面临明显的计算挑战。

    arXiv:2402.08922v1 Announce Type: new Abstract: Large-scale black-box models have become ubiquitous across numerous applications. Understanding the influence of individual training data sources on predictions made by these models is crucial for improving their trustworthiness. Current influence estimation techniques involve computing gradients for every training point or repeated training on different subsets. These approaches face obvious computational challenges when scaled up to large datasets and models.   In this paper, we introduce and explore the Mirrored Influence Hypothesis, highlighting a reciprocal nature of influence between training and test data. Specifically, it suggests that evaluating the influence of training data on test predictions can be reformulated as an equivalent, yet inverse problem: assessing how the predictions for training samples would be altered if the model were trained on specific test samples. Through both empirical and theoretical validations, we demo
    
[^39]: 具有单调对手的Top-K排名问题

    Top-$K$ ranking with a monotone adversary

    [https://arxiv.org/abs/2402.07445](https://arxiv.org/abs/2402.07445)

    本文针对具有单调对手的Top-K排名问题，提出了一种加权最大似然估计器(MLE)，在样本复杂度方面接近最优。算法创新包括了对加权MLE的精确且紧密的$\ell_\infty$误差分析，并与加权比较图的谱特性相关联。

    

    本文解决了具有单调对手的Top-K排名问题。我们考虑了一个比较图被随机生成且对手可以添加任意边的情况。统计学家的目标是根据从这个半随机比较图导出的两两比较准确地识别出Top-K的首选项。本文的主要贡献是开发出一种加权最大似然估计器(MLE)，它在样本复杂度方面达到了近似最优，最多差一个$log^2(n)$的因子，其中n表示比较项的数量。这得益于分析和算法创新的结合。在分析方面，我们提供了一种更明确、更紧密的加权MLE的$\ell_\infty$误差分析，它与加权比较图的谱特性相关。受此启发，我们的算法创新涉及到了

    In this paper, we address the top-$K$ ranking problem with a monotone adversary. We consider the scenario where a comparison graph is randomly generated and the adversary is allowed to add arbitrary edges. The statistician's goal is then to accurately identify the top-$K$ preferred items based on pairwise comparisons derived from this semi-random comparison graph. The main contribution of this paper is to develop a weighted maximum likelihood estimator (MLE) that achieves near-optimal sample complexity, up to a $\log^2(n)$ factor, where n denotes the number of items under comparison. This is made possible through a combination of analytical and algorithmic innovations. On the analytical front, we provide a refined $\ell_\infty$ error analysis of the weighted MLE that is more explicit and tighter than existing analyses. It relates the $\ell_\infty$ error with the spectral properties of the weighted comparison graph. Motivated by this, our algorithmic innovation involves the development 
    
[^40]: 梯度下降引发了深度非线性网络权重与经验NTK之间的对齐

    Gradient descent induces alignment between weights and the empirical NTK for deep non-linear networks

    [https://arxiv.org/abs/2402.05271](https://arxiv.org/abs/2402.05271)

    了解神经网络从输入-标签对中提取统计信息的机制是监督学习中最重要的未解决问题之一。前人的研究表明，在训练过程中，权重的格拉姆矩阵与模型的平均梯度外积成正比，这被称为神经特征分析（NFA）。本研究解释了这种相关性的出现，并发现NFA等价于权重矩阵的左奇异结构与与这些权重相关的经验神经切线核的显著成分之间的对齐。在早期训练阶段，可以通过解析的方式预测NFA的发展速度。

    

    理解神经网络从输入-标签对中提取统计信息的机制是监督学习中最重要的未解决问题之一。先前的研究已经确定，在一般结构的训练神经网络中，权重的格拉姆矩阵与模型的平均梯度外积成正比，这个说法被称为神经特征分析（NFA）。然而，这些数量在训练过程中如何相关尚不清楚。在这项工作中，我们解释了这种相关性的出现。我们发现NFA等价于权重矩阵的左奇异结构与与这些权重相关的经验神经切线核的显著成分之间的对齐。我们证明了先前研究中引入的NFA是由隔离这种对齐的中心化NFA驱动的。我们还展示了在早期训练阶段，可以通过解析的方式预测NFA的发展速度。

    Understanding the mechanisms through which neural networks extract statistics from input-label pairs is one of the most important unsolved problems in supervised learning. Prior works have identified that the gram matrices of the weights in trained neural networks of general architectures are proportional to the average gradient outer product of the model, in a statement known as the Neural Feature Ansatz (NFA). However, the reason these quantities become correlated during training is poorly understood. In this work, we explain the emergence of this correlation. We identify that the NFA is equivalent to alignment between the left singular structure of the weight matrices and a significant component of the empirical neural tangent kernels associated with those weights. We establish that the NFA introduced in prior works is driven by a centered NFA that isolates this alignment. We show that the speed of NFA development can be predicted analytically at early training times in terms of sim
    
[^41]: 采用分割引导扩散模型的解剖可控医学图像生成

    Anatomically-Controllable Medical Image Generation with Segmentation-Guided Diffusion Models

    [https://arxiv.org/abs/2402.05210](https://arxiv.org/abs/2402.05210)

    这篇论文提出了一种采用分割引导扩散模型的解剖可控医学图像生成方法，通过随机掩模消融训练算法实现对解剖约束的条件化，同时提高了网络对解剖真实性的学习能力。

    

    扩散模型已经实现了非常高质量的医学图像生成，可以通过为小型或不平衡的数据集提供补充，从而帮助减轻获取和注释新图像的费用，同时还可以应用于其他方面。然而，这些模型在生成图像时面临着全局解剖真实性的挑战。因此，我们提出了一种解剖可控的医学图像生成模型。我们的模型在每个采样步骤中遵循多类解剖分割掩模，并采用随机掩模消融训练算法，以实现对所选解剖约束的条件化，同时允许其他解剖区域的灵活性。这也改善了网络在完全无条件（无约束生成）情况下对解剖真实性的学习。通过对乳腺MRI和腹部/颈部到盆腔CT数据集的比较评估，证明了我们模型在解剖真实性和输入掩模保真度方面具有优越性。

    Diffusion models have enabled remarkably high-quality medical image generation, which can help mitigate the expenses of acquiring and annotating new images by supplementing small or imbalanced datasets, along with other applications. However, these are hampered by the challenge of enforcing global anatomical realism in generated images. To this end, we propose a diffusion model for anatomically-controlled medical image generation. Our model follows a multi-class anatomical segmentation mask at each sampling step and incorporates a \textit{random mask ablation} training algorithm, to enable conditioning on a selected combination of anatomical constraints while allowing flexibility in other anatomical areas. This also improves the network's learning of anatomical realism for the completely unconditional (unconstrained generation) case. Comparative evaluation on breast MRI and abdominal/neck-to-pelvis CT datasets demonstrates superior anatomical realism and input mask faithfulness over st
    
[^42]: 一种使用进化算子的强盗方法进行模型选择

    A Bandit Approach with Evolutionary Operators for Model Selection

    [https://arxiv.org/abs/2402.05144](https://arxiv.org/abs/2402.05144)

    本文提出了一种使用进化算子的强盗方法来进行模型选择，通过将模型选择问题建模为无穷臂赌博机问题，利用部分训练和准确性作为奖励，最终的算法Mutant-UCB在测试中表现出色，优于固定预算下的最先进技术。

    

    本文将模型选择问题建模为无穷臂赌博机问题。模型是臂，选择一个臂对应部分训练模型（资源分配）。奖励是选择模型在部分训练后的准确性。在这个最佳臂识别问题中，遗憾是最优模型的预期准确性与最终选择模型的准确性之间的差距。我们首先考虑了UCB-E在随机无穷臂赌博机问题上的直接推广，并且证明了在基本假设下，期望遗憾的顺序是$T^{-\alpha}$，其中$\alpha \in (0,1/5)$，$T$是要分配的资源数量。从这个基本算法出发，我们介绍了一种算法Mutant-UCB，它结合了进化算法的操作符。在三个开源图片分类数据集上进行的测试表明了这种新颖的组合方法的相关性，该方法优于固定预算下的国际领先技术。

    This paper formulates model selection as an infinite-armed bandit problem. The models are arms, and picking an arm corresponds to a partial training of the model (resource allocation). The reward is the accuracy of the selected model after its partial training. In this best arm identification problem, regret is the gap between the expected accuracy of the optimal model and that of the model finally chosen. We first consider a straightforward generalization of UCB-E to the stochastic infinite-armed bandit problem and show that, under basic assumptions, the expected regret order is $T^{-\alpha}$ for some $\alpha \in (0,1/5)$ and $T$ the number of resources to allocate. From this vanilla algorithm, we introduce the algorithm Mutant-UCB that incorporates operators from evolutionary algorithms. Tests carried out on three open source image classification data sets attest to the relevance of this novel combining approach, which outperforms the state-of-the-art for a fixed budget.
    
[^43]: LEVI:通过以层为单位的多视角集成实现可泛化的微调

    LEVI: Generalizable Fine-tuning via Layer-wise Ensemble of Different Views

    [https://arxiv.org/abs/2402.04644](https://arxiv.org/abs/2402.04644)

    本论文中，我们提出了一种名为LEVI的方法，通过以层为单位的多视角集成，实现了对预训练和微调数据中问题的解决，并提升微调模型对未见过的分布的泛化能力。

    

    微调越来越广泛地用于在新的下游任务中利用预训练基础模型的能力。虽然在各种任务上微调取得了许多成功，但最近的研究观察到微调模型在未见过的分布（即，超出分布；OOD）上的泛化存在挑战。为了改善OOB泛化，一些先前的研究确定了微调数据的限制，并调整微调以保留自预训练数据学习到的通用表示。然而，预训练数据和模型中的潜在限制经常被忽视。在本文中，我们认为过度依赖预训练表示可能会阻碍微调学习下游任务的重要表示，从而影响其OOB泛化。当新任务来自于与预训练数据不同的（子）领域时，这可能尤为灾难性。为了解决预训练和微调数据中的问题，我们提出了一种新颖的方法。

    Fine-tuning is becoming widely used for leveraging the power of pre-trained foundation models in new downstream tasks. While there are many successes of fine-tuning on various tasks, recent studies have observed challenges in the generalization of fine-tuned models to unseen distributions (i.e., out-of-distribution; OOD). To improve OOD generalization, some previous studies identify the limitations of fine-tuning data and regulate fine-tuning to preserve the general representation learned from pre-training data. However, potential limitations in the pre-training data and models are often ignored. In this paper, we contend that overly relying on the pre-trained representation may hinder fine-tuning from learning essential representations for downstream tasks and thus hurt its OOD generalization. It can be especially catastrophic when new tasks are from different (sub)domains compared to pre-training data. To address the issues in both pre-training and fine-tuning data, we propose a nove
    
[^44]: 使用大型语言模型的结构化实体提取

    Structured Entity Extraction Using Large Language Models

    [https://arxiv.org/abs/2402.04437](https://arxiv.org/abs/2402.04437)

    本论文提出了一种使用大型语言模型的结构化实体提取方法，在此任务上通过引入AESOP度量评估模型性能，并将整个提取任务分解为多个阶段，相较于基准模型取得了更好的效果，为未来结构化实体提取的进一步发展提供了有希望的方向。

    

    近年来，机器学习的最新进展显著影响了信息提取领域，大型语言模型（LLMs）在从非结构化文本中提取结构化信息方面起着关键作用。本文探讨了当前结构化实体提取方法的挑战和限制，并引入了一种新的方法来解决这些问题。我们首先介绍和规范化了结构化实体提取（SEE）任务，然后提出了适用于该任务的近似实体集重叠（AESOP）度量，以适当评估模型在这一任务上的性能。随后，我们提出了一种新模型，通过将整个提取任务分解为多个阶段，利用LLMs的强大功能来提高效果和效率。定量评估和人工并行评估证实了我们的模型优于基准模型，为结构化实体提取领域的未来进展提供了有希望的方向。

    Recent advances in machine learning have significantly impacted the field of information extraction, with Large Language Models (LLMs) playing a pivotal role in extracting structured information from unstructured text. This paper explores the challenges and limitations of current methodologies in structured entity extraction and introduces a novel approach to address these issues. We contribute to the field by first introducing and formalizing the task of Structured Entity Extraction (SEE), followed by proposing Approximate Entity Set OverlaP (AESOP) Metric designed to appropriately assess model performance on this task. Later, we propose a new model that harnesses the power of LLMs for enhanced effectiveness and efficiency through decomposing the entire extraction task into multiple stages. Quantitative evaluation and human side-by-side evaluation confirm that our model outperforms baselines, offering promising directions for future advancements in structured entity extraction.
    
[^45]: 无线视频缓存网络中的资源感知分层联邦学习

    Resource-Aware Hierarchical Federated Learning in Wireless Video Caching Networks

    [https://arxiv.org/abs/2402.04216](https://arxiv.org/abs/2402.04216)

    通过资源感知的分层联邦学习，我们提出了一种解决方案，可以预测用户未来的内容请求，并减轻无线视频缓存网络中回程流量拥塞的问题。

    

    在无线视频缓存网络中，通过将待请求内容存储在不同级别上，可以减轻由少数热门文件的视频流量造成的回程拥塞。通常，内容服务提供商（CSP）拥有内容，用户使用其（无线）互联网服务提供商（ISP）从CSP请求其首选内容。由于这些参与方不会透露其私密信息和商业机密，传统技术可能无法用于预测用户未来需求的动态变化。出于这个原因，我们提出了一种新颖的资源感知分层联邦学习（RawHFL）解决方案，用于预测用户未来的内容请求。采用了一种实用的数据获取技术，允许用户根据其请求的内容更新其本地训练数据集。此外，由于网络和其他计算资源有限，考虑到只有一部分用户参与模型训练，我们推导出

    Backhaul traffic congestion caused by the video traffic of a few popular files can be alleviated by storing the to-be-requested content at various levels in wireless video caching networks. Typically, content service providers (CSPs) own the content, and the users request their preferred content from the CSPs using their (wireless) internet service providers (ISPs). As these parties do not reveal their private information and business secrets, traditional techniques may not be readily used to predict the dynamic changes in users' future demands. Motivated by this, we propose a novel resource-aware hierarchical federated learning (RawHFL) solution for predicting user's future content requests. A practical data acquisition technique is used that allows the user to update its local training dataset based on its requested content. Besides, since networking and other computational resources are limited, considering that only a subset of the users participate in the model training, we derive
    
[^46]: 折扣自适应在线预测

    Discounted Adaptive Online Prediction

    [https://arxiv.org/abs/2402.02720](https://arxiv.org/abs/2402.02720)

    本论文提出了一种折扣自适应在线预测算法，该算法适应于复杂的损失序列和比较器，并改进了非自适应算法。算法具有无需结构性假设的理论保证，并且在超参数调整方面具有鲁棒性。通过在线符合预测任务的实验证明了算法的好处。

    

    在线学习并不总是要记住一切。由于未来在统计上可能与过去有很大的不同，一个关键的挑战是在新数据到来时优雅地忘记历史。为了形式化这种直觉，我们运用最近发展的自适应在线学习技术重新思考了经典的折扣遗憾概念。我们的主要结果是一个新的算法，它适应于损失序列和比较器的复杂性，改进了广泛使用的非自适应算法-梯度下降算法，且具有恒定的学习率。特别地，我们的理论保证不需要任何结构性假设，只要求凸性，并且该算法经过证明对次优的超参数调整具有鲁棒性。我们进一步通过在线符合预测来展示这些好处，而在线符合预测是一个带有集合成员决策的下游在线学习任务。

    Online learning is not always about memorizing everything. Since the future can be statistically very different from the past, a critical challenge is to gracefully forget the history while new data comes in. To formalize this intuition, we revisit the classical notion of discounted regret using recently developed techniques in adaptive online learning. Our main result is a new algorithm that adapts to the complexity of both the loss sequence and the comparator, improving the widespread non-adaptive algorithm - gradient descent with a constant learning rate. In particular, our theoretical guarantee does not require any structural assumption beyond convexity, and the algorithm is provably robust to suboptimal hyperparameter tuning. We further demonstrate such benefits through online conformal prediction, a downstream online learning task with set-membership decisions.
    
[^47]: 我的模型会忘记什么？语言模型改进中的被遗忘实例预测

    What Will My Model Forget? Forecasting Forgotten Examples in Language Model Refinement

    [https://arxiv.org/abs/2402.01865](https://arxiv.org/abs/2402.01865)

    本文研究了语言模型更新中的遗忘现象，提出了一种预测上游实例遗忘的方法，以改进重播过程的可控性和解释性。根据预训练实例的预-softmax对数几率分数变化与在线学习实例的相似性，提出了一种部分可解释的预测模型，在BART模型上表现良好但在T5模型上失败。此外，还展示了基于内积的黑盒分类器。

    

    在实际应用中，语言模型会出现错误。然而，仅仅通过将模型更新为纠正错误实例，会导致灾难性的遗忘，更新后的模型在指导微调或上游训练阶段中学到的实例上出现错误。随机重播上游数据的效果不令人满意，往往伴随着较高的方差和较差的可控性。为了改善重播过程的可控性和解释性，我们试图预测由于模型更新而遗忘的上游实例。我们根据一组在线学习的实例和相应被遗忘的上游预训练实例训练预测模型。我们提出了一种部分可解释的预测模型，该模型基于这样的观察结果：预训练实例的预-softmax对数几率分数的变化类似于在线学习实例的变化，这在BART模型上表现出不错的效果，但在T5模型上失败。我们进一步展示了基于内积的黑盒分类器

    Language models deployed in the wild make errors. However, simply updating the model with the corrected error instances causes catastrophic forgetting -- the updated model makes errors on instances learned during the instruction tuning or upstream training phase. Randomly replaying upstream data yields unsatisfactory performance and often comes with high variance and poor controllability. To this end, we try to forecast upstream examples that will be forgotten due to a model update for improved controllability of the replay process and interpretability. We train forecasting models given a collection of online learned examples and corresponding forgotten upstream pre-training examples. We propose a partially interpretable forecasting model based on the observation that changes in pre-softmax logit scores of pretraining examples resemble that of online learned examples, which performs decently on BART but fails on T5 models. We further show a black-box classifier based on inner products 
    
[^48]: 一次图卷积就够了：高效灰度图像分类

    A Single Graph Convolution Is All You Need: Efficient Grayscale Image Classification

    [https://arxiv.org/abs/2402.00564](https://arxiv.org/abs/2402.00564)

    本论文提出了一种高效的灰度图像分类方法，通过将图像视为矢量，并使用单个图卷积层进行处理，提高了分类模型的准确性和稳定性。

    

    图像分类器通常依赖于卷积神经网络(CNN)来完成任务，而CNN相比于多层感知机(MLP)更加庞大，这在实时应用中可能会带来问题。此外，许多图像分类模型适用于RGB和灰度数据集，但仅仅使用灰度图像的分类器相对较少见。灰度图像分类具有广泛的应用，包括但不限于医学图像分类和合成孔径雷达(SAR)自动目标识别(ATR)。因此，我们提出了一种使用图像的矢量化视图的新型灰度(单通道)图像分类方法。我们通过将图像视为矢量，并将问题设置为灰度图像分类问题，充分利用了MLP的轻量级特性。我们发现，批次级别使用单个图卷积层可以提高模型的准确性并减小性能的差异。此外，我们开发了定制的准确率估计方法。

    Image classifiers often rely on convolutional neural networks (CNN) for their tasks, which are inherently more heavyweight than multilayer perceptrons (MLPs), which can be problematic in real-time applications. Additionally, many image classification models work on both RGB and grayscale datasets. Classifiers that operate solely on grayscale images are much less common. Grayscale image classification has diverse applications, including but not limited to medical image classification and synthetic aperture radar (SAR) automatic target recognition (ATR). Thus, we present a novel grayscale (single channel) image classification approach using a vectorized view of images. We exploit the lightweightness of MLPs by viewing images as a vector and reducing our problem setting to the grayscale image classification setting. We find that using a single graph convolutional layer batch-wise increases accuracy and reduces variance in the performance of our model. Moreover, we develop a customized acc
    
[^49]: 数据高效图学习的综述

    A Survey of Data-Efficient Graph Learning

    [https://arxiv.org/abs/2402.00447](https://arxiv.org/abs/2402.00447)

    这项研究提出了数据高效图学习（DEGL）的概念，并总结了近期在这一领域的进展。DEGL的目标是在资源有限的场景下提高图机器学习的性能，通过探索各种最小监督方法来解决大规模标记数据的挑战。

    

    图结构化数据在社交网络到生物化学分析等领域中广泛存在，是各种现实世界系统的基础。虽然图神经网络在建模这种数据方面表现出色，但它们的成功往往依赖于大量标记数据，这在标注资源有限的实际场景中构成了挑战。为了解决这个问题，我们致力于通过探索各种最小监督方法来提高低资源设置下的图机器学习性能。本文介绍了一种新颖的数据高效图学习(DEGL)的研究前沿，并提供了对DEGL当前进展的首次综述。我们首先强调了使用大规模标记数据训练模型所固有的挑战，为我们对DEGL的探索铺平了道路。接下来，我们从几个关键方面系统地回顾了这一主题的最新进展，其中包括...

    Graph-structured data, prevalent in domains ranging from social networks to biochemical analysis, serve as the foundation for diverse real-world systems. While graph neural networks demonstrate proficiency in modeling this type of data, their success is often reliant on significant amounts of labeled data, posing a challenge in practical scenarios with limited annotation resources. To tackle this problem, tremendous efforts have been devoted to enhancing graph machine learning performance under low-resource settings by exploring various approaches to minimal supervision. In this paper, we introduce a novel concept of Data-Efficient Graph Learning (DEGL) as a research frontier, and present the first survey that summarizes the current progress of DEGL. We initiate by highlighting the challenges inherent in training models with large labeled data, paving the way for our exploration into DEGL. Next, we systematically review recent advances on this topic from several key aspects, including 
    
[^50]: 变化的行动空间中的情境式强化学习

    In-Context Reinforcement Learning for Variable Action Spaces

    [https://arxiv.org/abs/2312.13327](https://arxiv.org/abs/2312.13327)

    本文提出了一种Headless-AD模型，通过只训练一次，能够在变化的行动空间中实现强化学习任务的泛化。实验证明该模型能够在从未遇到过的行动空间上表现出显著的泛化能力，甚至胜过针对特定行动集训练的模型。

    

    最近的研究表明，预先在多样数据集上进行上下文多情节训练的变形金刚网络可以在情境中泛化到新的强化学习任务。先前提出的模型的一个关键限制是它们依赖于预定义的行动空间大小和结构。引入新的行动空间通常需要数据重新收集和模型重新训练，这对于一些应用来说可能是昂贵的。我们的工作表明，通过提出一种只训练一次的Headless-AD模型，可以缓解这个问题，该模型能够泛化到具有可变大小、语义内容和顺序的离散动作空间。通过在伯努利和上下文赌博机以及一个网格世界环境中进行实验，我们展示了Headless-AD在从未遇到的行动空间上表现出显著的泛化能力，甚至在几个环境配置上胜过专门针对特定行动集训练的模型。

    Recently, it has been shown that transformers pre-trained on diverse datasets with multi-episode contexts can generalize to new reinforcement learning tasks in-context. A key limitation of previously proposed models is their reliance on a predefined action space size and structure. The introduction of a new action space often requires data re-collection and model re-training, which can be costly for some applications. In our work, we show that it is possible to mitigate this issue by proposing the Headless-AD model that, despite being trained only once, is capable of generalizing to discrete action spaces of variable size, semantic content and order. By experimenting with Bernoulli and contextual bandits, as well as a gridworld environment, we show that Headless-AD exhibits significant capability to generalize to action spaces it has never encountered, even outperforming specialized models trained for a specific set of actions on several environment configurations.
    
[^51]: 学习自发现：关于积极抑制人工神经网络单意义神经元的研究

    Learning from Emergence: A Study on Proactively Inhibiting the Monosemantic Neurons of Artificial Neural Networks

    [https://arxiv.org/abs/2312.11560](https://arxiv.org/abs/2312.11560)

    本文研究了积极抑制人工神经网络中的单意义神经元，这对于提高性能具有重要意义，并提出了一种基于自发现的方法来实现抑制。

    

    最近，随着大型语言模型的成功，自发现受到了研究界的广泛关注。与现有文献不同，我们提出了一个关键因素的假设，即在规模扩大的过程中高度促进性能的因素：减少只能与特定特征形成一对一关系的单意义神经元。单意义神经元往往更稀疏，并对大型模型的性能产生负面影响。受到这一观点的启发，我们提出了一种直观的思路来识别和抑制单意义神经元。然而，实现这一目标是一个非平凡的任务，因为没有统一的定量评估指标，简单地禁止单意义神经元并不能促进神经网络的多意思性。因此，本文提出了从自发现中学习的方法，并展开了关于积极抑制单意义神经元的研究。具体来说，我们首先提出了一种新的方法

    arXiv:2312.11560v2 Announce Type: replace-cross  Abstract: Recently, emergence has received widespread attention from the research community along with the success of large language models. Different from the literature, we hypothesize a key factor that highly promotes the performance during the increase of scale: the reduction of monosemantic neurons that can only form one-to-one correlations with specific features. Monosemantic neurons tend to be sparser and have negative impacts on the performance in large models. Inspired by this insight, we propose an intuitive idea to identify monosemantic neurons and inhibit them. However, achieving this goal is a non-trivial task as there is no unified quantitative evaluation metric and simply banning monosemantic neurons does not promote polysemanticity in neural networks. Therefore, we propose to learn from emergence and present a study on proactively inhibiting the monosemantic neurons in this paper. More specifically, we first propose a new
    
[^52]: 具有时空视频扩散的降水降尺度

    Precipitation Downscaling with Spatiotemporal Video Diffusion

    [https://arxiv.org/abs/2312.06071](https://arxiv.org/abs/2312.06071)

    通过扩展视频扩散模型至降水超分辨率，本研究提出了一种利用确定性降尺度器和暂时条件扩散模型来捕捉噪声特征和高频率模式的方法。

    

    在气候科学和气象学领域，高分辨率的局部降水（雨雪）预测受到基于模拟方法的计算成本限制。统计降尺度，或者称为超分辨率，是一种常见的解决方法，其中低分辨率预测通过统计方法得到改进。与传统计算机视觉任务不同，天气和气候应用需要捕捉给定低分辨率模式的高分辨率的准确条件分布，以确保可靠的集合平均和极端事件（如暴雨）的无偏估计。本研究将最新的视频扩散模型扩展到降水超分辨率，使用确定性降尺度器，然后是暂时条件的扩散模型来捕捉噪声特征和高频率模式。我们在FV3GFS输出上测试了我们的方法，这是一个已建立的大规模全球大气模型，并将其与其他方法进行了比较。

    arXiv:2312.06071v2 Announce Type: replace-cross  Abstract: In climate science and meteorology, high-resolution local precipitation (rain and snowfall) predictions are limited by the computational costs of simulation-based methods. Statistical downscaling, or super-resolution, is a common workaround where a low-resolution prediction is improved using statistical approaches. Unlike traditional computer vision tasks, weather and climate applications require capturing the accurate conditional distribution of high-resolution given low-resolution patterns to assure reliable ensemble averages and unbiased estimates of extreme events, such as heavy rain. This work extends recent video diffusion models to precipitation super-resolution, employing a deterministic downscaler followed by a temporally-conditioned diffusion model to capture noise characteristics and high-frequency patterns. We test our approach on FV3GFS output, an established large-scale global atmosphere model, and compare it agai
    
[^53]: 在序贯决策中记住公平：非马尔可夫公平性

    Remembering to Be Fair: Non-Markovian Fairness in Sequential Decision Making

    [https://arxiv.org/abs/2312.04772](https://arxiv.org/abs/2312.04772)

    本文研究了在序贯决策过程中的非马尔可夫公平性，发现公平往往取决于历史，需要在过程中的不同时间点进行评估。

    

    公平的决策制定在很大程度上是针对单一决策进行研究的。本文在多个利益相关者可能受到决策结果影响的情况下，研究了顺序决策中的公平概念。我们观察到，公平往往取决于顺序决策过程的历史，从这个意义上讲，它是固有的非马尔可夫性。我们进一步观察到，公平通常需要在过程中的某个时间点进行评估，而不仅仅是在过程结束时。为了推进我们对这类公平性问题的理解，我们探讨了顺序决策背景下非马尔可夫公平的概念。我们确定了非马尔可夫公平的属性，包括长期公平性、任意时刻公平性、周期性公平性和有界公平性等概念。我们进一步探讨了非马尔可夫公平性和记忆之间的相互作用，以及这如何支持制定公平政策。

    arXiv:2312.04772v3 Announce Type: replace  Abstract: Fair decision making has largely been studied with respect to a single decision. In this paper we investigate the notion of fairness in the context of sequential decision making where multiple stakeholders can be affected by the outcomes of decisions. We observe that fairness often depends on the history of the sequential decision-making process, and in this sense that it is inherently non-Markovian. We further observe that fairness often needs to be assessed at time points within the process, not just at the end of the process. To advance our understanding of this class of fairness problems, we explore the notion of non-Markovian fairness in the context of sequential decision making. We identify properties of non-Markovian fairness, including notions of long-term, anytime, periodic, and bounded fairness. We further explore the interplay between non-Markovian fairness and memory, and how this can support construction of fair policies
    
[^54]: FRAPP'E：一个用于后处理的群体公平性框架

    FRAPP\'E: A Group Fairness Framework for Post-Processing Everything

    [https://arxiv.org/abs/2312.02592](https://arxiv.org/abs/2312.02592)

    提出了一个将任何正则化的处理中方法转化为后处理方法的框架，适用于更广泛的问题设置，保持了良好的公平错误权衡，并且可能提高之前方法的效力

    

    尽管在处理中实现了有前途的公平错误权衡，但群体公平性的处理方法无法在许多计算资源有限或无法访问预测模型训练管道的实际应用中使用。在这些情况下，后处理是一个可行的替代方法。然而，当前方法专为特定问题设置和公平性定义而设计，因此不如处理中方法广泛适用。在这项工作中，我们提出了一个框架，将任何正则化的处理中方法转化为后处理方法。这一方法提供了一种获得更广泛问题设置的后处理技术的途径，远超过以前的后处理文献。我们理论上并通过大量实验展示，我们的框架保留了处理中实现的良好公平错误权衡，并且能够提高先前方法的效力。

    arXiv:2312.02592v2 Announce Type: replace  Abstract: Despite achieving promising fairness-error trade-offs, in-processing mitigation techniques for group fairness cannot be employed in numerous practical applications with limited computation resources or no access to the training pipeline of the prediction model. In these situations, post-processing is a viable alternative. However, current methods are tailored to specific problem settings and fairness definitions and hence, are not as broadly applicable as in-processing. In this work, we propose a framework that turns any regularized in-processing method into a post-processing approach. This procedure prescribes a way to obtain post-processing techniques for a much broader range of problem settings than the prior post-processing literature. We show theoretically and through extensive experiments that our framework preserves the good fairness-error trade-offs achieved with in-processing and can improve over the effectiveness of prior p
    
[^55]: 在过参数化下分析锐度感知最小化

    Analyzing Sharpness-aware Minimization under Overparameterization

    [https://arxiv.org/abs/2311.17539](https://arxiv.org/abs/2311.17539)

    本文分析了在过参数化条件下的锐度感知最小化方法。通过实证和理论结果，发现过参数化对锐度感知最小化具有重要影响，并且在过参数化增加的情况下，锐度感知最小化仍然受益。

    

    在训练过参数化的神经网络时，尽管训练损失相同，但可以得到具有不同泛化能力的极小值。有证据表明，极小值的锐度与其泛化误差之间存在相关性，因此已经做出了更多努力开发一种优化方法，以显式地找到扁平极小值作为更具有泛化能力的解。然而，至今为止，关于过参数化对锐度感知最小化（SAM）策略的影响的研究还不多。在这项工作中，我们分析了在不同程度的过参数化下的SAM，并提出了实证和理论结果，表明过参数化对SAM具有重要影响。具体而言，我们进行了广泛的数值实验，涵盖了各个领域，并表明存在一种一致的趋势，即SAM在过参数化增加的情况下仍然受益。我们还发现了一些令人信服的案例，说明了过参数化的影响。

    Training an overparameterized neural network can yield minimizers of different generalization capabilities despite the same level of training loss. With evidence that suggests a correlation between sharpness of minima and their generalization errors, increasing efforts have been made to develop an optimization method to explicitly find flat minima as more generalizable solutions. However, this sharpness-aware minimization (SAM) strategy has not been studied much yet as to whether and how it is affected by overparameterization.   In this work, we analyze SAM under overparameterization of varying degrees and present both empirical and theoretical results that indicate a critical influence of overparameterization on SAM. Specifically, we conduct extensive numerical experiments across various domains, and show that there exists a consistent trend that SAM continues to benefit from increasing overparameterization. We also discover compelling cases where the effect of overparameterization is
    
[^56]: CV-Attention UNet: Attention-based UNet for 3D Cerebrovascular Segmentation of Enhanced TOF-MRA Images

    CV-Attention UNet: Attention-based UNet for 3D Cerebrovascular Segmentation of Enhanced TOF-MRA Images

    [https://arxiv.org/abs/2311.10224](https://arxiv.org/abs/2311.10224)

    本文提出了一种3D脑血管注意力UNet方法，用于精确提取脑血管图像，通过一系列预处理技术和深度监督UNet来改善脑血管分割的准确性，有助于预防中风。

    

    由于缺乏自动化方法来诊断脑血管疾病，时间飞行磁共振血管造影图（TOF-MRA）通常是通过目视评估，这导致耗时。本文提出了一种3D脑血管注意力UNet方法，命名为CV-Attention UNet，用于精确提取脑血管图像。我们提出了一系列预处理技术，随后采用深度监督UNet来改善脑血管分割的准确性，从而有助于预防中风。为了结合低语义和高语义，

    arXiv:2311.10224v2 Announce Type: replace-cross  Abstract: Due to the lack of automated methods, to diagnose cerebrovascular disease, time-of-flight magnetic resonance angiography (TOF-MRA) is assessed visually, making it time-consuming. The commonly used encoder-decoder architectures for cerebrovascular segmentation utilize redundant features, eventually leading to the extraction of low-level features multiple times. Additionally, convolutional neural networks (CNNs) suffer from performance degradation when the batch size is small, and deeper networks experience the vanishing gradient problem. Methods: In this paper, we attempt to solve these limitations and propose the 3D cerebrovascular attention UNet method, named CV-AttentionUNet, for precise extraction of brain vessel images. We proposed a sequence of preprocessing techniques followed by deeply supervised UNet to improve the accuracy of segmentation of the brain vessels leading to a stroke. To combine the low and high semantics, 
    
[^57]: TAP: 跨模态知识传递中的注意力补丁

    TAP: The Attention Patch for Cross-Modal Knowledge Transfer from Unlabeled Modality

    [https://arxiv.org/abs/2302.02224](https://arxiv.org/abs/2302.02224)

    通过引入The Attention Patch（TAP）神经网络附加组件，本文提出了一种简单且有效的方法，允许从未标记的次要模态实现跨模态的数据级知识传递。

    

    本文解决了跨模态学习框架，其目标是通过未标记、不配对的次要模态，增强主要模态中监督学习的性能。采用概率方法进行缺失信息估计，我们表明次要模态中包含的额外信息可以通过Nadaraya-Watson（NW）核回归进行估计，其可以进一步表示为经过线性变换的核交叉注意力模块。我们的结果为引入The Attention Patch（TAP）奠定了基础，这是一个简单的神经网络附加组件，允许从未标记的模态进行数据级知识传递。我们使用四个真实世界数据集进行了大量数值模拟，结果表明TAP能够显著提高跨不同领域和不同神经网络架构的泛化能力，利用看似无用的未标记信息。

    arXiv:2302.02224v2 Announce Type: replace  Abstract: This paper addresses a cross-modal learning framework, where the objective is to enhance the performance of supervised learning in the primary modality using an unlabeled, unpaired secondary modality. Taking a probabilistic approach for missing information estimation, we show that the extra information contained in the secondary modality can be estimated via Nadaraya-Watson (NW) kernel regression, which can further be expressed as a kernelized cross-attention module (under linear transformation). Our results lay the foundations for introducing The Attention Patch (TAP), a simple neural network add-on that allows data-level knowledge transfer from the unlabeled modality. We provide extensive numerical simulations using four real-world datasets to show that TAP can provide statistically significant improvement in generalization across different domains and different neural network architectures, making use of seemingly unusable unlabel
    
[^58]: 一种独立的系统化黑盒测试ML系统的概要

    Outline of an Independent Systematic Blackbox Test for ML-based Systems. (arXiv:2401.17062v1 [cs.LG])

    [http://arxiv.org/abs/2401.17062](http://arxiv.org/abs/2401.17062)

    本文提出了一种独立测试ML模型和基于ML的系统的方法，可以独立验证其黑盒特性和随机属性。建议扩展现有测试方法以更好地反映ML系统的特点。

    

    本文提出了一种测试程序，可用于独立于实际训练过程测试ML模型和基于ML的系统。通过考虑其黑盒特性和ML模型及其训练数据的固有随机属性，可以独立验证这些模型和系统的典型质量参数，如准确性和精度。文章介绍了一系列测试实验的初步结果，并提出了扩展现有测试方法以反映ML模型和基于ML的系统的随机特性的建议。

    This article proposes a test procedure that can be used to test ML models and ML-based systems independently of the actual training process. In this way, the typical quality statements such as accuracy and precision of these models and system can be verified independently, taking into account their black box character and the immanent stochastic properties of ML models and their training data. The article presents first results from a set of test experiments and suggest extensions to existing test methods reflecting the stochastic nature of ML models and ML-based systems.
    
[^59]: M2CURL: 通过自监督表示学习实现样本高效的多模态强化学习，用于机器人操纵

    M2CURL: Sample-Efficient Multimodal Reinforcement Learning via Self-Supervised Representation Learning for Robotic Manipulation. (arXiv:2401.17032v1 [cs.RO])

    [http://arxiv.org/abs/2401.17032](http://arxiv.org/abs/2401.17032)

    M2CURL是一种样本高效的多模态强化学习方法，通过自监督表示学习从视触觉数据中学习出高效的表示，并加速强化学习算法的收敛。

    

    多模态强化学习中最重要的方面之一是有效地整合不同的观测模态。从这些模态中得到稳健准确的表示对于提升强化学习算法的鲁棒性和样本效率至关重要。然而，在视触觉数据的强化学习环境中学习表示面临着重要挑战，特别是由于数据的高维度和将视触觉输入与动态环境和任务目标进行相关性分析的复杂性。为了解决这些挑战，我们提出了多模态对比无监督强化学习（M2CURL）。我们的方法采用了一种新颖的多模态自监督学习技术，学习出高效的表示并加速了强化学习算法的收敛。我们的方法与强化学习算法无关，因此可以与任何可用的强化学习算法进行整合。我们在Tactile Gym 2模拟器上评估了M2CURL。

    One of the most critical aspects of multimodal Reinforcement Learning (RL) is the effective integration of different observation modalities. Having robust and accurate representations derived from these modalities is key to enhancing the robustness and sample efficiency of RL algorithms. However, learning representations in RL settings for visuotactile data poses significant challenges, particularly due to the high dimensionality of the data and the complexity involved in correlating visual and tactile inputs with the dynamic environment and task objectives. To address these challenges, we propose Multimodal Contrastive Unsupervised Reinforcement Learning (M2CURL). Our approach employs a novel multimodal self-supervised learning technique that learns efficient representations and contributes to faster convergence of RL algorithms. Our method is agnostic to the RL algorithm, thus enabling its integration with any available RL algorithm. We evaluate M2CURL on the Tactile Gym 2 simulator 
    
[^60]: 关系推理的扩散模型

    Diffusion model for relational inference. (arXiv:2401.16755v1 [cs.LG])

    [http://arxiv.org/abs/2401.16755](http://arxiv.org/abs/2401.16755)

    这项研究提出了一种关系推理的扩散模型(DiffRI)，通过条件扩散建模学习推断组件之间连接存在的概率，并在无监督方式下发现地面真实相互作用方面具有很高的能力。

    

    复杂相互作用系统的动态行为，包括大脑活动、金融价格波动和物理集体现象，与系统组成部分之间的相互作用相关。利用可观测的动态来发现这些系统中的相互作用关系被称为关系推理。在本研究中，我们提出了一种关系推理的扩散模型(DiffRI)，它借鉴了一种自监督的概率时间序列插值方法。DiffRI通过条件扩散建模学习推断组件之间连接存在的概率。对于模拟和准真实数据集的实验证明，DiffRI在无监督方式下发现地面真实相互作用方面与其他最先进的模型相比具有很高的能力。我们的代码将很快公开。

    Dynamical behaviors of complex interacting systems, including brain activities, financial price movements, and physical collective phenomena, are associated with underlying interactions between the system's components. The issue of uncovering interaction relations in such systems using observable dynamics is called relational inference. In this study, we propose a Diffusion model for Relational Inference (DiffRI), inspired by a self-supervised method for probabilistic time series imputation. DiffRI learns to infer the probability of the presence of connections between components through conditional diffusion modeling. Experiments on both simulated and quasi-real datasets show that DiffRI is highly competent compared with other state-of-the-art models in discovering ground truth interactions in an unsupervised manner. Our code will be made public soon.
    
[^61]: 机器学习在符号计算中的数据集和范式的教训：基于CAD的案例研究

    Lessons on Datasets and Paradigms in Machine Learning for Symbolic Computation: A Case Study on CAD. (arXiv:2401.13343v1 [cs.SC])

    [http://arxiv.org/abs/2401.13343](http://arxiv.org/abs/2401.13343)

    这项研究提出了机器学习在符号计算中的应用经验教训，包括在机器学习之前对数据集进行分析的重要性以及不同机器学习范式的选择。通过在柱面代数分解中的变量排序选择中的案例研究，发现了数据集中的不平衡问题，并引入了增强技术来改善数据集的平衡性。

    

    符号计算算法及其在计算机代数系统中的实现通常包含一些选择，这些选择不会影响结果的正确性，但对所需资源有显著影响：利用机器学习模型可以针对每个问题单独做出这些选择。本研究报告了在符号计算中使用机器学习的经验教训，特别是在机器学习之前对数据集进行分析的重要性，以及可能使用的不同机器学习范式。下面以柱面代数分解中的变量排序选择作为一个具体案例研究的结果来展示，但认为所学到的教训适用于符号计算中的其他决策。我们利用一个现有的从应用中导出的示例数据集，发现该数据集在变量排序决策方面存在不平衡。我们引入了一个多项式系统问题的增强技术，使得每个问题可以有多个示例以增强数据集的平衡性。

    Symbolic Computation algorithms and their implementation in computer algebra systems often contain choices which do not affect the correctness of the output but can significantly impact the resources required: such choices can benefit from having them made separately for each problem via a machine learning model. This study reports lessons on such use of machine learning in symbolic computation, in particular on the importance of analysing datasets prior to machine learning and on the different machine learning paradigms that may be utilised. We present results for a particular case study, the selection of variable ordering for cylindrical algebraic decomposition, but expect that the lessons learned are applicable to other decisions in symbolic computation.  We utilise an existing dataset of examples derived from applications which was found to be imbalanced with respect to the variable ordering decision. We introduce an augmentation technique for polynomial systems problems that allow
    
[^62]: 缺失模态下的多模态情感分析:一种知识迁移方法

    Multimodal Sentiment Analysis with Missing Modality: A Knowledge-Transfer Approach. (arXiv:2401.10747v1 [cs.SD])

    [http://arxiv.org/abs/2401.10747](http://arxiv.org/abs/2401.10747)

    本文提出了一种知识迁移方法，用于在缺失模态下进行多模态情感分析。通过翻译不同模态之间的内容以重构缺失的音频模态，并利用跨模态注意机制进行情感预测，实验证明了该方法在多个数据集上表现出显著的改进和与完整多模态监督方法相媲美的效果。

    

    多模态情感分析旨在通过视觉、语言和声音线索来识别个体表达的情绪。然而，现有研究大多假设在训练和测试过程中所有模态都是可用的，这使得它们的算法容易受到缺失模态的影响。在本文中，我们提出了一种新颖的知识迁移网络，用于在不同模态之间进行翻译，以重构缺失的音频模态。此外，我们还开发了一种跨模态注意机制，以保留重构和观察到的模态的最大信息，用于情感预测。在三个公开数据集上进行的大量实验证明了相对于基线算法的显著改进，并实现了与具有完整多模态监督的先前方法相媲美的结果。

    Multimodal sentiment analysis aims to identify the emotions expressed by individuals through visual, language, and acoustic cues. However, most of the existing research efforts assume that all modalities are available during both training and testing, making their algorithms susceptible to the missing modality scenario. In this paper, we propose a novel knowledge-transfer network to translate between different modalities to reconstruct the missing audio modalities. Moreover, we develop a cross-modality attention mechanism to retain the maximal information of the reconstructed and observed modalities for sentiment prediction. Extensive experiments on three publicly available datasets demonstrate significant improvements over baselines and achieve comparable results to the previous methods with complete multi-modality supervision.
    
[^63]: 使用图神经网络预测和解释金属玻璃的能垒

    Predicting and Interpreting Energy Barriers of Metallic Glasses with Graph Neural Networks. (arXiv:2401.08627v1 [cond-mat.dis-nn])

    [http://arxiv.org/abs/2401.08627](http://arxiv.org/abs/2401.08627)

    本研究使用图神经网络建模原子图结构并预测金属玻璃的能垒，通过提出的对称图神经网络模型，实现了在结构正交变换下的不变性，为理解金属玻璃的局部结构与物理性质关系提供了新的方法。

    

    金属玻璃是广泛使用的无序材料。理解金属玻璃的局部结构与物理性质之间的关系是材料科学和凝聚态物理学的最大挑战之一。本研究利用图神经网络来建模原子图结构，并研究结构与相应的局部能垒之间的联系，据信能够控制金属玻璃的许多关键物理性质。我们的一个重要贡献是提出了一种用于预测能垒的新型对称图神经网络（SymGNN）模型，该模型在结构的正交变换下具有不变性，例如旋转和反射。这种不变性是标准图神经网络如图卷积网络无法捕捉的性质。SymGNN通过聚合图结构的正交变换来进行表示学习，并对所有三维正交变换进行最优分布处理。

    Metallic Glasses (MGs) are widely used disordered materials. Understanding the relationship between the local structure and physical properties of MGs is one of the greatest challenges for both material science and condensed matter physics. In this work, we utilize Graph Neural Networks (GNNs) to model the atomic graph structure and study the connection between the structure and the corresponding local energy barrier, which is believed to govern many critical physical properties in MGs. One of our key contributions is to propose a novel Symmetrized GNN (SymGNN) model for predicting the energy barriers, which is invariant under orthogonal transformations of the structure, e.g., rotations and reflections. Such invariance is a desired property that standard GNNs like Graph Convolutional Networks cannot capture. SymGNNs handle the invariance by aggregating over orthogonal transformations of the graph structure for representation learning, and an optimal distribution over all 3D orthogonal 
    
[^64]: 提高深度学习Bug可复现性的探索性研究

    Towards Enhancing the Reproducibility of Deep Learning Bugs: An Empirical Study. (arXiv:2401.03069v1 [cs.SE])

    [http://arxiv.org/abs/2401.03069](http://arxiv.org/abs/2401.03069)

    本研究旨在提高深度学习Bug的可复现性，通过构建数据集和确定编辑动作和有用信息，这能够解决目前研究中忽视的问题。

    

    背景：深度学习在各个领域取得了显著进展。然而，与传统软件系统一样，深度学习系统也存在Bug，这可能对自动驾驶等领域产生严重影响。尽管深度学习技术取得了重大进展，但很少有研究关注深度学习Bug的可复现性，这阻碍了Bug的解决。现有文献指出，仅有3%的深度学习Bug是可复现的，这凸显了进一步研究的必要性。目标：本文考察深度学习Bug的可复现性，识别可提高深度学习Bug可复现性的编辑动作和有用信息。方法：首先，构建了一个包含来自Stack Overflow和Defects4ML的3个框架和22个架构的668个深度学习Bug的数据集。其次，使用分层抽样选择了102个Bug，并尝试确定它们的可复现性。在复现这些Bug的过程中，我们识别了编辑动作和有用信息。

    Context: Deep learning has achieved remarkable progress in various domains. However, like traditional software systems, deep learning systems contain bugs, which can have severe impacts, as evidenced by crashes involving autonomous vehicles. Despite substantial advancements in deep learning techniques, little research has focused on reproducing deep learning bugs, which hinders resolving them. Existing literature suggests that only 3% of deep learning bugs are reproducible, underscoring the need for further research.  Objective: This paper examines the reproducibility of deep learning bugs. We identify edit actions and useful information that could improve deep learning bug reproducibility.  Method: First, we construct a dataset of 668 deep learning bugs from Stack Overflow and Defects4ML across 3 frameworks and 22 architectures. Second, we select 102 bugs using stratified sampling and try to determine their reproducibility. While reproducing these bugs, we identify edit actions and us
    
[^65]: ALEXR:一种用于凸有限和耦合组成随机优化的最优单循环算法

    ALEXR: An Optimal Single-Loop Algorithm for Convex Finite-Sum Coupled Compositional Stochastic Optimization. (arXiv:2312.02277v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2312.02277](http://arxiv.org/abs/2312.02277)

    本文提出了一种名为ALEXR的高效算法，用于解决凸有限和耦合组成随机优化问题。此算法在解决平滑和非平滑问题时具有优越的收敛速度，并且可应用于多个领域，包括组分布鲁棒优化、不平衡数据学习、强化学习和排序学习。

    

    本文重新审视了一类具有多个应用的凸有限和耦合组成随机优化（cFCCO）问题，包括组分布鲁棒优化（GDRO），不平衡数据学习，强化学习和排序学习。为了更好地解决这些问题，我们引入了一个高效的单循环原始-对偶块坐标近端算法，称为ALEXR。该算法利用块坐标随机镜像上升更新对偶变量和随机近端梯度下降更新原始变量。我们在平滑和非平滑函数条件下建立了ALEXR在凸和强凸情况下的收敛速度，这不仅改进了以前在平滑cFCCO问题上的最佳速度，还扩展了cFCCO的范围，用于解决更具挑战性的非平滑问题，如GDRO的对偶形式。最后，我们提供了较低的复杂性下界，以证明算法具有很强的效率。

    This paper revisits a class of convex Finite-Sum Coupled Compositional Stochastic Optimization (cFCCO) problems with many applications, including group distributionally robust optimization (GDRO), learning with imbalanced data, reinforcement learning, and learning to rank. To better solve these problems, we introduce an efficient single-loop primal-dual block-coordinate proximal algorithm, dubbed ALEXR. This algorithm leverages block-coordinate stochastic mirror ascent updates for the dual variable and stochastic proximal gradient descent updates for the primal variable. We establish the convergence rates of ALEXR in both convex and strongly convex cases under smoothness and non-smoothness conditions of involved functions, which not only improve the best rates in previous works on smooth cFCCO problems but also expand the realm of cFCCO for solving more challenging non-smooth problems such as the dual form of GDRO. Finally, we present lower complexity bounds to demonstrate that the con
    
[^66]: 重新审视苹果品尝的可学习性

    Revisiting the Learnability of Apple Tasting. (arXiv:2310.19064v1 [cs.LG])

    [http://arxiv.org/abs/2310.19064](http://arxiv.org/abs/2310.19064)

    该论文重新审视了苹果品尝的可学习性，从组合角度研究了在线可学习性。作者通过引入Effective width参数，紧密量化了在可实现设置中的极小期望错误，并在可实现设置中建立了极小期望错误数量的三分法。

    

    在在线二元分类中，学习者只有在预测为"1"时观察到真实标签。本文重新研究了这种经典的部分反馈设置，并从组合角度研究了在线可学习性。我们证明了在不可知设置下，Littlestone维度仍然是苹果品尝的紧密定量刻画，解决了\cite{helmbold2000apple}提出的一个悬而未决的问题。此外，我们给出了一个新的组合参数，称为有效宽度，紧密量化了在可实现设置中的极小期望错误。作为推论，我们使用有效宽度在可实现设置中建立了极小期望错误数量的三分法。特别地，我们证明了在可实现设置中，任何学习者在苹果品尝反馈下的期望错误数量只能是$\Theta(1), \Theta(\sqrt{T})$, 或 $\Theta(T)$。

    In online binary classification under \textit{apple tasting} feedback, the learner only observes the true label if it predicts "1". First studied by \cite{helmbold2000apple}, we revisit this classical partial-feedback setting and study online learnability from a combinatorial perspective. We show that the Littlestone dimension continues to prove a tight quantitative characterization of apple tasting in the agnostic setting, closing an open question posed by \cite{helmbold2000apple}. In addition, we give a new combinatorial parameter, called the Effective width, that tightly quantifies the minimax expected mistakes in the realizable setting. As a corollary, we use the Effective width to establish a \textit{trichotomy} of the minimax expected number of mistakes in the realizable setting. In particular, we show that in the realizable setting, the expected number of mistakes for any learner under apple tasting feedback can only be $\Theta(1), \Theta(\sqrt{T})$, or $\Theta(T)$.
    
[^67]: 生成性扩散模型的统计热力学

    The statistical thermodynamics of generative diffusion models. (arXiv:2310.17467v1 [stat.ML])

    [http://arxiv.org/abs/2310.17467](http://arxiv.org/abs/2310.17467)

    本文通过在生成性扩散模型中应用平衡统计力学的工具，揭示了这些模型中的二阶相变现象，并且认为这种稳定性形式是生成能力的关键。

    

    生成性扩散模型在生成建模的许多领域取得了惊人的表现。虽然这些模型的基本思想来自非平衡物理学，但本文中我们表明，可以用平衡统计力学的工具来理解这些模型的许多方面。利用这种重构，我们展示了生成性扩散模型经历了与对称性破缺现象相对应的二阶相变。我们认为，这导致了一种稳定性形式，它是生成能力的核心，并可以用一组平均场临界指数来描述。最后，我们根据热力学的公式分析了将扩散模型与关联记忆网络连接的最近研究。

    Generative diffusion models have achieved spectacular performance in many areas of generative modeling. While the fundamental ideas behind these models come from non-equilibrium physics, in this paper we show that many aspects of these models can be understood using the tools of equilibrium statistical mechanics. Using this reformulation, we show that generative diffusion models undergo second-order phase transitions corresponding to symmetry breaking phenomena. We argue that this lead to a form of instability that lies at the heart of their generative capabilities and that can be described by a set of mean field critical exponents. We conclude by analyzing recent work connecting diffusion models and associative memory networks in view of the thermodynamic formulations.
    
[^68]: 大脑基因转录的压缩表示

    Compressed representation of brain genetic transcription. (arXiv:2310.16113v1 [cs.LG])

    [http://arxiv.org/abs/2310.16113](http://arxiv.org/abs/2310.16113)

    本文研究了大脑基因转录的压缩表示方法，通过比较不同的线性和非线性方法，评估了它们在重建、解剖和预测方面的性能。

    

    大脑的结构过于复杂，无法直观地进行观察，需要使用压缩表示将其变化投影到紧凑、可导航的空间中。在高维数据（如基因表达）中，尤其具有挑战性，其中解剖和转录模式的联合复杂性要求最大压缩。目前的实践是使用标准的主成分分析（PCA），其计算效率受到限制，尤其在大压缩比下表现力有限。本研究利用全脑体素级Allen大脑图谱转录数据，系统比较了基于最广泛支持的线性和非线性方法（PCA，核PCA，非负矩阵分解（NMF），t-随机邻居嵌入（t-SNE），统一流形逼近和投影（UMAP），深度自编码）的压缩表示，量化重建保真度，解剖连贯性和预测效果。

    The architecture of the brain is too complex to be intuitively surveyable without the use of compressed representations that project its variation into a compact, navigable space. The task is especially challenging with high-dimensional data, such as gene expression, where the joint complexity of anatomical and transcriptional patterns demands maximum compression. Established practice is to use standard principal component analysis (PCA), whose computational felicity is offset by limited expressivity, especially at great compression ratios. Employing whole-brain, voxel-wise Allen Brain Atlas transcription data, here we systematically compare compressed representations based on the most widely supported linear and non-linear methods-PCA, kernel PCA, non-negative matrix factorization (NMF), t-stochastic neighbour embedding (t-SNE), uniform manifold approximation and projection (UMAP), and deep auto-encoding-quantifying reconstruction fidelity, anatomical coherence, and predictive utility
    
[^69]: 多标签学习中的神经坍缩问题研究

    Neural Collapse in Multi-label Learning with Pick-all-label Loss. (arXiv:2310.15903v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.15903](http://arxiv.org/abs/2310.15903)

    这项论文研究了在多标签分类任务中的神经坍缩现象。他们推广了之前在多类别分类中发现的神经坍缩现象，证明了在“选择所有标签”公式下存在广义的神经坍缩现象。他们还发现了在广义的神经坍缩中的一个组合性质。

    

    我们通过神经坍缩（NC）的角度研究了深度神经网络在多标签分类（MLab）任务中的应用。之前的研究都局限于多类别分类，发现了一种普遍存在的NC现象，其中最后一层特征具有以下特点：（i）每个类别内的特征变异性为零，（ii）特征均值集合构成一个等角紧框架（ETF），（iii）最后一层分类器收缩到特征均值乘以某个缩放因子。我们将这个研究推广到多标签学习，并首次证明了“选择所有标签”公式存在广义NC现象。在自然的无约束特征模型（UFM）的情况下，我们证明了“选择所有标签”的交叉熵损失函数的全局分类器只显示出相同的ETF几何结构，进一步坍缩到多重性为1的特征类均值。

    We study deep neural networks for the multi-label classification (MLab) task through the lens of neural collapse (NC). Previous works have been restricted to the multi-class classification setting and discovered a prevalent NC phenomenon comprising of the following properties for the last-layer features: (i) the variability of features within every class collapses to zero, (ii) the set of feature means form an equi-angular tight frame (ETF), and (iii) the last layer classifiers collapse to the feature mean upon some scaling. We generalize the study to multi-label learning, and prove for the first time that a generalized NC phenomenon holds with the "pick-all-label" formulation. Under the natural analog of the unconstrained feature model (UFM), we establish that the only global classifier of the pick-all-label cross entropy loss display the same ETF geometry which further collapse to multiplicity-1 feature class means. Besides, we discover a combinatorial property in generalized NC whic
    
[^70]: RSAdapter: 适应遥感视觉问答的多模态模型

    RSAdapter: Adapting Multimodal Models for Remote Sensing Visual Question Answering. (arXiv:2310.13120v1 [cs.CV])

    [http://arxiv.org/abs/2310.13120](http://arxiv.org/abs/2310.13120)

    RSAdapter是一种针对遥感视觉问答的多模态模型，通过并行适配器和线性转换层的设计，提高了运行时和参数效率。

    

    近年来，随着Transformer模型的快速发展，基于Transformer的多模态架构在各种下游任务中都得到了广泛应用，包括但不限于图像描述、视觉问答（VQA）和图像文本生成。然而，当前的遥感VQA方法通常涉及资源密集型技术，如对大型模型进行全面微调或从预训练的多模态模型中提取图像-文本特征，然后使用解码器进行模态融合。这些方法需要大量的计算资源和时间，并引入了相当数量的可训练参数。为了解决这些挑战，我们提出了一种名为RSAdapter的新方法，该方法优先考虑运行时和参数效率。RSAdapter包括两个关键组件：并行适配器和插入在适配器的每个全连接（FC）层后的额外线性转换层。

    In recent years, with the rapid advancement of transformer models, transformer-based multimodal architectures have found wide application in various downstream tasks, including but not limited to Image Captioning, Visual Question Answering (VQA), and Image-Text Generation. However, contemporary approaches to Remote Sensing (RS) VQA often involve resource-intensive techniques, such as full fine-tuning of large models or the extraction of image-text features from pre-trained multimodal models, followed by modality fusion using decoders. These approaches demand significant computational resources and time, and a considerable number of trainable parameters are introduced. To address these challenges, we introduce a novel method known as RSAdapter, which prioritizes runtime and parameter efficiency. RSAdapter comprises two key components: the Parallel Adapter and an additional linear transformation layer inserted after each fully connected (FC) layer within the Adapter. This approach not on
    
[^71]: 伪贝叶斯优化

    Pseudo-Bayesian Optimization. (arXiv:2310.09766v1 [stat.ML])

    [http://arxiv.org/abs/2310.09766](http://arxiv.org/abs/2310.09766)

    本文提出了伪贝叶斯优化，并通过研究最小要求的公理框架，构建了能确保黑盒优化收敛性的算法。

    

    贝叶斯优化是一种优化昂贵黑盒函数的流行方法。其关键思想是使用一个替代模型来近似目标，并且重要的是量化相关的不确定性，从而实现探索和开发之间的平衡的顺序搜索。高斯过程(GP)一直是替代模型的首选，因为它具有贝叶斯的不确定性量化能力和建模灵活性。然而，它的挑战也引发了一系列收敛性更显得不明显的备选方案。在本文中，我们通过研究引出最小要求的公理框架来确保黑盒优化的收敛性，以应用于除了GP相关方法之外的情况。此外，我们利用我们的框架中的设计自由，我们称之为伪贝叶斯优化，来构建经验上更优的算法。特别地，我们展示了如何使用简单的局部回归和一个适应问题特性的代理模型来实现这一目标。

    Bayesian Optimization is a popular approach for optimizing expensive black-box functions. Its key idea is to use a surrogate model to approximate the objective and, importantly, quantify the associated uncertainty that allows a sequential search of query points that balance exploitation-exploration. Gaussian process (GP) has been a primary candidate for the surrogate model, thanks to its Bayesian-principled uncertainty quantification power and modeling flexibility. However, its challenges have also spurred an array of alternatives whose convergence properties could be more opaque. Motivated by these, we study in this paper an axiomatic framework that elicits the minimal requirements to guarantee black-box optimization convergence that could apply beyond GP-related methods. Moreover, we leverage the design freedom in our framework, which we call Pseudo-Bayesian Optimization, to construct empirically superior algorithms. In particular, we show how using simple local regression, and a sui
    
[^72]: DKEC: 领域知识增强的电子病历多标签分类

    DKEC: Domain Knowledge Enhanced Multi-Label Classification for Electronic Health Records. (arXiv:2310.07059v1 [cs.CL])

    [http://arxiv.org/abs/2310.07059](http://arxiv.org/abs/2310.07059)

    本文提出了DKEC，一种领域知识增强的分类器，用于医学诊断预测。它利用标签的注意力机制和组内训练方法来捕捉医学实体之间的语义关系，并增加罕见类别的样本数量。评估结果显示其在医学数据集上表现良好。

    

    医学领域的多标签文本分类任务经常面临长尾标签分布，即罕见类别的训练样本少于频繁类别。虽然之前的工作已经探索了不同的模型架构和层次化标签结构来找到重要特征，但大多数忽略了从医学指南中融入领域知识。本文提出了DKEC，一种增强医学诊断预测的领域知识增强分类器，其中包括两个创新点：（1）一个基于标签的注意力机制，结合异构图和领域本体来捕捉医学实体之间的语义关系，（2）一种基于标签相似性的简单而有效的组内训练方法，用于增加罕见类别的样本数量。我们在两个真实的医学数据集上评估了DKEC：RAA数据集，包含来自急救服务（EMS）事件的4,417个患者护理报告的收集，和来自53898报告的子集。

    Multi-label text classification (MLTC) tasks in the medical domain often face long-tail label distribution, where rare classes have fewer training samples than frequent classes. Although previous works have explored different model architectures and hierarchical label structures to find important features, most of them neglect to incorporate the domain knowledge from medical guidelines. In this paper, we present DKEC, Domain Knowledge Enhanced Classifier for medical diagnosis prediction with two innovations: (1) a label-wise attention mechanism that incorporates a heterogeneous graph and domain ontologies to capture the semantic relationships between medical entities, (2) a simple yet effective group-wise training method based on similarity of labels to increase samples of rare classes. We evaluate DKEC on two real-world medical datasets: the RAA dataset, a collection of 4,417 patient care reports from emergency medical services (EMS) incidents, and a subset of 53,898 reports from the 
    
[^73]: 物理感知机器学习革命科学范式对于机器学习和基于过程的水文学的影响

    Physics-aware Machine Learning Revolutionizes Scientific Paradigm for Machine Learning and Process-based Hydrology. (arXiv:2310.05227v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.05227](http://arxiv.org/abs/2310.05227)

    物理感知机器学习是一种革命性方法，它将物理知识和机器学习相结合，提供了准确的水文学理解和水循环预测，对于管理水资源以应对气候变化等挑战具有重要意义。

    

    准确的水文学理解和水循环预测对于解决水资源管理中的科学和社会挑战至关重要，特别是在人为气候变化的动态影响下。现有的评论主要关注机器学习在这个领域的发展，然而水文学和机器学习作为独立的范式存在明显的区别。在这里，我们介绍了以物理感知机器学习作为一种变革性方法，克服了这种认知障碍，并革新了这两个领域。具体来说，我们提出了一个综合的物理感知机器学习方法的评论，构建了一个结构化社区（PaML），将先前的物理知识或基于物理的建模与机器学习相结合。我们系统地从物理数据引导的机器学习、物理信息处理的机器学习、物理嵌入式机器学习和物理感知混合学习四个方面分析了这些PaML方法。PaML促进了机器学习辅助的假设推导。

    Accurate hydrological understanding and water cycle prediction are crucial for addressing scientific and societal challenges associated with the management of water resources, particularly under the dynamic influence of anthropogenic climate change. Existing reviews predominantly concentrate on the development of machine learning (ML) in this field, yet there is a clear distinction between hydrology and ML as separate paradigms. Here, we introduce physics-aware ML as a transformative approach to overcome the perceived barrier and revolutionize both fields. Specifically, we present a comprehensive review of the physics-aware ML methods, building a structured community (PaML) of existing methodologies that integrate prior physical knowledge or physics-based modeling into ML. We systematically analyze these PaML methodologies with respect to four aspects: physical data-guided ML, physics-informed ML, physics-embedded ML, and physics-aware hybrid learning. PaML facilitates ML-aided hypothe
    
[^74]: 实例和标签: 针对层次化多标签文本分类的层次感知联合监督对比学习

    Instances and Labels: Hierarchy-aware Joint Supervised Contrastive Learning for Hierarchical Multi-Label Text Classification. (arXiv:2310.05128v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.05128](http://arxiv.org/abs/2310.05128)

    提出了一种层次感知联合监督对比学习方法（HJCL），用于层次化多标签文本分类。该方法通过使用实例级和标签级对比学习技术，以及精心构建批次来处理标签层次结构，解决了在HMTC中使用监督对比学习的问题。

    

    层次化多标签文本分类（HMTC）旨在利用标签层次结构进行多标签分类。近期关于HMTC的方法采用对比学习在生成的样本上以半监督的方式将文本和标签嵌入接近，从而解决了对输出空间施加过度约束的问题。然而，样本的生成往往引入噪声，因为它忽略了同一批次中相似样本之间的相关性。解决这个问题的一个方法是使用监督对比学习，但由于其复杂的结构化标签，这仍然是一个未被充分研究的领域。为了克服这一挑战，我们提出了一种称为$\textbf{HJCL}$的层次感知联合监督对比学习方法，用于填补监督对比学习和HMTC之间的差距。具体而言，我们采用实例级和标签级对比学习技术，并仔细构造批次来满足标签层次结构的要求。

    Hierarchical multi-label text classification (HMTC) aims at utilizing a label hierarchy in multi-label classification. Recent approaches to HMTC deal with the problem of imposing an over-constrained premise on the output space by using contrastive learning on generated samples in a semi-supervised manner to bring text and label embeddings closer. However, the generation of samples tends to introduce noise as it ignores the correlation between similar samples in the same batch. One solution to this issue is supervised contrastive learning, but it remains an underexplored topic in HMTC due to its complex structured labels. To overcome this challenge, we propose $\textbf{HJCL}$, a $\textbf{H}$ierarchy-aware $\textbf{J}$oint Supervised $\textbf{C}$ontrastive $\textbf{L}$earning method that bridges the gap between supervised contrastive learning and HMTC. Specifically, we employ both instance-wise and label-wise contrastive learning techniques and carefully construct batches to fulfill the 
    
[^75]: FedAIoT: 一种用于物联网人工智能的联邦学习基准

    FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things. (arXiv:2310.00109v1 [cs.LG])

    [http://arxiv.org/abs/2310.00109](http://arxiv.org/abs/2310.00109)

    FedAIoT是一个用于AIoT的联邦学习基准，包括八个数据集和一个统一的端到端FL框架。它填补了现有FL研究中缺乏真实物联网设备数据集的关键差距，并揭示了FL在AIoT领域的机遇和挑战。

    

    在物联网人工智能领域，联邦学习（FL）具有重要的相关性。然而，大多数现有的FL研究并不是基于从真实物联网设备收集的数据集，这些数据集捕捉了物联网数据的独特模式和固有挑战。在这项工作中，我们引入了FedAIoT，一种用于AIoT的FL基准，以填补这个关键的差距。FedAIoT包括从各种物联网设备收集的八个数据集。这些数据集涵盖了物联网的独特模式，并针对AIoT的典型应用。FedAIoT还包括一种用于AIoT的统一的端到端FL框架，简化了数据集性能的基准测试。我们的基准测试结果揭示了FL在AIoT领域的机遇和挑战。我们希望FedAIoT能成为在FL for AIoT这一重要领域推动进展的珍贵资源。FedAIoT的代码仓库位于https://github.com/AIoT-MLSys-Lab/FedAIoT。

    There is a significant relevance of federated learning (FL) in the realm of Artificial Intelligence of Things (AIoT). However, most existing FL works are not conducted on datasets collected from authentic IoT devices that capture unique modalities and inherent challenges of IoT data. In this work, we introduce FedAIoT, an FL benchmark for AIoT to fill this critical gap. FedAIoT includes eight datatsets collected from a wide range of IoT devices. These datasets cover unique IoT modalities and target representative applications of AIoT. FedAIoT also includes a unified end-to-end FL framework for AIoT that simplifies benchmarking the performance of the datasets. Our benchmark results shed light on the opportunities and challenges of FL for AIoT. We hope FedAIoT could serve as an invaluable resource to foster advancements in the important field of FL for AIoT. The repository of FedAIoT is maintained at https://github.com/AIoT-MLSys-Lab/FedAIoT.
    
[^76]: 转移气候变化知识

    Transferring climate change knowledge. (arXiv:2309.14780v1 [physics.ao-ph])

    [http://arxiv.org/abs/2309.14780](http://arxiv.org/abs/2309.14780)

    通过转移学习方法，研究表明机器学习，尤其是深度神经网络，可以通过充分利用地球系统模型模拟和历史观测所获得的知识，更准确地预测21世纪的全球表面温度场。

    

    准确的气候预测对于气候适应和减缓至关重要。用于预测气候变化的地球系统模型模拟在对小尺度物理过程（例如云）的表示中本质上进行了近似，这是全球平均温度对增加的温室气体浓度的响应中不确定性的根源。已经开发了多种方法，用于使用历史观测约束未来预测，并减少气候预测和气候反馈的不确定性。然而，这些方法无法捕捉气候系统固有的非线性复杂性。通过使用转移学习方法，我们展示了机器学习，特别是深度神经网络，可以用于最大程度地利用和整合从地球系统模型模拟和历史观测中获得的知识，以更准确地预测21世纪全球表面温度场。

    Accurate climate projections are required for climate adaptation and mitigation. Earth system model simulations, used to project climate change, inherently make approximations in their representation of small-scale physical processes, such as clouds, that are at the root of the uncertainties in global mean temperature's response to increased greenhouse gas concentrations. Several approaches have been developed to use historical observations to constrain future projections and reduce uncertainties in climate projections and climate feedbacks. Yet those methods cannot capture the non-linear complexity inherent in the climate system. Using a Transfer Learning approach, we show that Machine Learning, in particular Deep Neural Networks, can be used to optimally leverage and merge the knowledge gained from Earth system model simulations and historical observations to more accurately project global surface temperature fields in the 21st century. For the Shared Socioeconomic Pathways (SSPs) 2-
    
[^77]: COVID-19检测系统：基于咳嗽音频信号的声学特征系统性能比较分析

    COVID-19 Detection System: A Comparative Analysis of System Performance Based on Acoustic Features of Cough Audio Signals. (arXiv:2309.04505v1 [cs.SD])

    [http://arxiv.org/abs/2309.04505](http://arxiv.org/abs/2309.04505)

    本研究通过比较分析声学特征对咳嗽音频信号的机器学习模型性能的影响，提出了一种高效的COVID-19检测系统。

    

    各种呼吸道疾病如感冒和流感、哮喘以及COVID-19等在全球范围内影响着人们的日常生活。在医学实践中，呼吸声音被广泛用于医疗服务中，用于诊断各种呼吸系统疾病和肺部疾病。传统的诊断方法需要专业知识，成本高且依赖于人类专业知识。最近，咳嗽音频记录被用来自动化检测呼吸系统疾病的过程。本研究旨在检查各种声学特征，以提高机器学习模型在咳嗽信号中检测COVID-19的性能。本研究调查了三种特征提取技术（MFCC，Chroma和Spectral Contrast特征）在两种机器学习算法（SVM和MLP）上的功效，并提出了一种高效的COVID-19检测系统。

    A wide range of respiratory diseases, such as cold and flu, asthma, and COVID-19, affect people's daily lives worldwide. In medical practice, respiratory sounds are widely used in medical services to diagnose various respiratory illnesses and lung disorders. The traditional diagnosis of such sounds requires specialized knowledge, which can be costly and reliant on human expertise. Recently, cough audio recordings have been used to automate the process of detecting respiratory conditions. This research aims to examine various acoustic features that enhance the performance of machine learning (ML) models in detecting COVID-19 from cough signals. This study investigates the efficacy of three feature extraction techniques, including Mel Frequency Cepstral Coefficients (MFCC), Chroma, and Spectral Contrast features, on two ML algorithms, Support Vector Machine (SVM) and Multilayer Perceptron (MLP), and thus proposes an efficient COVID-19 detection system. The proposed system produces a prac
    
[^78]: 通过多元宇宙分析评估模型设计决策对算法公平性的影响：一切，无处不在，全方位评估

    Everything, Everywhere All in One Evaluation: Using Multiverse Analysis to Evaluate the Influence of Model Design Decisions on Algorithmic Fairness. (arXiv:2308.16681v1 [stat.ML])

    [http://arxiv.org/abs/2308.16681](http://arxiv.org/abs/2308.16681)

    通过多元宇宙分析评估模型设计决策对算法公平性的影响，可以揭示算法决策系统中设计决策的关键作用。

    

    全球范围内的许多系统都利用算法决策来（部分）自动化以前由人类进行的决策。当设计良好时，这些系统承诺更客观的决策，同时节省大量资源，节约人力。然而，当算法决策系统设计不良时，可能会导致对社会群体进行歧视的不公平决策。算法决策系统的下游效应在很大程度上取决于系统设计和实施过程中的决策，因为数据中的偏见可能会在建模过程中缓解或加强。许多这些设计决策是隐含进行的，不知道它们确切地如何影响最终系统。因此，明确算法决策系统设计中的决策并了解这些决策如何影响结果系统的公平性非常重要。为了研究这个问题，我们借鉴了心理学领域的见解，并引入了多元宇宙分析方法。

    A vast number of systems across the world use algorithmic decision making (ADM) to (partially) automate decisions that have previously been made by humans. When designed well, these systems promise more objective decisions while saving large amounts of resources and freeing up human time. However, when ADM systems are not designed well, they can lead to unfair decisions which discriminate against societal groups. The downstream effects of ADMs critically depend on the decisions made during the systems' design and implementation, as biases in data can be mitigated or reinforced along the modeling pipeline. Many of these design decisions are made implicitly, without knowing exactly how they will influence the final system. It is therefore important to make explicit the decisions made during the design of ADM systems and understand how these decisions affect the fairness of the resulting system.  To study this issue, we draw on insights from the field of psychology and introduce the metho
    
[^79]: 我看到的东西有多安全？基于图像控制的自治安全性预测的校准预测

    How Safe Am I Given What I See? Calibrated Prediction of Safety Chances for Image-Controlled Autonomy. (arXiv:2308.12252v1 [cs.LG])

    [http://arxiv.org/abs/2308.12252](http://arxiv.org/abs/2308.12252)

    本文提出了一种基于生成世界模型的学习流水线族，通过克服学习安全知情表示和分布漂移下缺失安全标签的挑战，实现了在线安全预测。这些流水线具有统计校准保证的安全机会预测能力。

    

    端到端学习已经成为开发自治系统的主要范 paradigm。不幸的是，随着其性能和便利性，安全保证面临着更大的挑战。挑战的一个关键因素是缺乏低维可解释动态状态的概念，传统的保证方法都围绕这一概念展开。本文针对在线安全预测问题，提出了一种基于生成世界模型的可配置学习流水线族，不需要低维状态。为了实现这些流水线，我们克服了学习安全知情潜在表示和预测引起的分布漂移下的缺失安全标签的挑战。这些流水线基于符合性预测，对其安全机会预测提供了统计校准保证。我们对提出的学习流水线在两个图像控制系统的案例研究上进行了广泛评估：赛车和汽车。

    End-to-end learning has emerged as a major paradigm for developing autonomous systems. Unfortunately, with its performance and convenience comes an even greater challenge of safety assurance. A key factor of this challenge is the absence of the notion of a low-dimensional and interpretable dynamical state, around which traditional assurance methods revolve. Focusing on the online safety prediction problem, this paper proposes a configurable family of learning pipelines based on generative world models, which do not require low-dimensional states. To implement these pipelines, we overcome the challenges of learning safety-informed latent representations and missing safety labels under prediction-induced distribution shift. These pipelines come with statistical calibration guarantees on their safety chance predictions based on conformal prediction. We perform an extensive evaluation of the proposed learning pipelines on two case studies of image-controlled systems: a racing car and a car
    
[^80]: 机器学习在信任与安全方面的挑战：一个针对虚假信息检测的案例研究

    The Challenges of Machine Learning for Trust and Safety: A Case Study on Misinformation Detection. (arXiv:2308.12215v1 [cs.LG])

    [http://arxiv.org/abs/2308.12215](http://arxiv.org/abs/2308.12215)

    本研究通过虚假信息检测为例，检查了机器学习在信任与安全问题中学术与实践之间的脱节，并发现了文献中存在的严重不足之处，包括任务不符合在线服务面临的挑战、数据集和模型评估不真实、评估不独立于模型训练等。在此基础上，提出了评估机器学习应用于信任与安全问题的建议。

    

    我们使用虚假信息检测作为案例研究，检查了在将机器学习应用于信任与安全问题上学术和实践之间的脱节。我们对该领域中270篇广受引用的论文进行了自动检测虚假信息的文献系统化，并对子集中的论文进行了数据和代码的可用性、设计失误、可复现性和泛化性等方面的研究。我们发现文献中存在严重的不足之处，这对所声称的性能和实用性提出了质疑。检测任务通常与在线服务真正面临的挑战有本质上的区别。数据集和模型评估通常不代表现实世界的情景，而且评估往往不独立于模型训练。数据和代码的可用性很差。模型在领域外的数据上泛化能力不强。基于这些结果，我们提出了评估机器学习应用于信任与安全问题的建议。

    We examine the disconnect between scholarship and practice in applying machine learning to trust and safety problems, using misinformation detection as a case study. We systematize literature on automated detection of misinformation across a corpus of 270 well-cited papers in the field. We then examine subsets of papers for data and code availability, design missteps, reproducibility, and generalizability. We find significant shortcomings in the literature that call into question claimed performance and practicality. Detection tasks are often meaningfully distinct from the challenges that online services actually face. Datasets and model evaluation are often non-representative of real-world contexts, and evaluation frequently is not independent of model training. Data and code availability is poor. Models do not generalize well to out-of-domain data. Based on these results, we offer recommendations for evaluating machine learning applications to trust and safety problems. Our aim is fo
    
[^81]: 利用视觉-语言模型在医学图像分割中探索迁移学习

    Exploring Transfer Learning in Medical Image Segmentation using Vision-Language Models. (arXiv:2308.07706v1 [cs.CV])

    [http://arxiv.org/abs/2308.07706](http://arxiv.org/abs/2308.07706)

    本论文提出使用视觉-语言模型进行医学图像分割的迁移学习，并评估了其在医学领域的可迁移性。通过捕捉语义信息和引入新的图像描述变化，实现了对多样化医学图像的分割。

    

    医学图像分割在医学领域的各种临床应用中至关重要。尽管最先进的分割模型已被证明有效，但在这个任务中整合文本指导以增强视觉特征仍然是一个进展有限的领域。现有利用文本指导的分割模型主要在开放领域图像上训练，这引发了在医学领域直接应用的难题，需要手动介入或进行微调。为了解决这些挑战，我们提出使用多模态的视觉-语言模型从图像描述和图像中捕捉语义信息，使得能够对多样化的医学图像进行分割。该研究全面评估了现有的视觉-语言模型在多个数据集上的可迁移性，以评估其从开放领域向医学领域的迁移能力。此外，我们对数据集中以前未见图像的图像描述引入了变化，揭示了显著的变异。

    Medical Image Segmentation is crucial in various clinical applications within the medical domain. While state-of-the-art segmentation models have proven effective, integrating textual guidance to enhance visual features for this task remains an area with limited progress. Existing segmentation models that utilize textual guidance are primarily trained on open-domain images, raising concerns about their direct applicability in the medical domain without manual intervention or fine-tuning.  To address these challenges, we propose using multimodal vision-language models for capturing semantic information from image descriptions and images, enabling the segmentation of diverse medical images. This study comprehensively evaluates existing vision language models across multiple datasets to assess their transferability from the open domain to the medical field. Furthermore, we introduce variations of image descriptions for previously unseen images in the dataset, revealing notable variations 
    
[^82]: 反向最优化用于路由问题

    Inverse Optimization for Routing Problems. (arXiv:2307.07357v1 [math.OC] CROSS LISTED)

    [http://arxiv.org/abs/2307.07357](http://arxiv.org/abs/2307.07357)

    本研究提出了一种使用反向最优化（IO）学习路由问题决策者行为的方法，并在亚马逊末端路由研究挑战中测试了该方法，在复制人类驾驶员的路由偏好方面取得了第2名的成绩。

    

    我们提出了一种使用反向最优化（IO）学习路由问题决策者行为的方法。IO框架属于监督学习类别，并建立在目标行为是未知成本函数的优化器的前提下。这个成本函数通过历史数据进行学习，在路由问题的背景下，可以理解为决策者的路由偏好。在这个视角下，本研究的主要贡献是提出了一种适用于路由问题的IO方法，包括假设函数、损失函数和基于随机一阶算法。我们进一步在亚马逊末端路由研究挑战中测试了我们的IO方法，该挑战的目标是使用成千上万个真实世界的路由案例学习模型以复制人类驾驶员的路由偏好。我们最终学习到的IO路由模型在48个晋级到决赛的模型中排名第2。

    We propose a method for learning decision-makers' behavior in routing problems using Inverse Optimization (IO). The IO framework falls into the supervised learning category and builds on the premise that the target behavior is an optimizer of an unknown cost function. This cost function is to be learned through historical data, and in the context of routing problems, can be interpreted as the routing preferences of the decision-makers. In this view, the main contributions of this study are to propose an IO methodology with a hypothesis function, loss function, and stochastic first-order algorithm tailored to routing problems. We further test our IO approach in the Amazon Last Mile Routing Research Challenge, where the goal is to learn models that replicate the routing preferences of human drivers, using thousands of real-world routing examples. Our final IO-learned routing model achieves a score that ranks 2nd compared with the 48 models that qualified for the final round of the challe
    
[^83]: SwinGNN:重新思考在图生成的扩散模型中的置换不变性

    SwinGNN: Rethinking Permutation Invariance in Diffusion Models for Graph Generation. (arXiv:2307.01646v1 [cs.LG])

    [http://arxiv.org/abs/2307.01646](http://arxiv.org/abs/2307.01646)

    本文提出了一种新的图生成扩散模型SwinGNN，通过使用高效的2-WL消息传递网络和移动窗口自注意力，以及结合关键的训练和采样技术，显著提高了图生成样本的质量，并引入了随机置换的后处理技巧转换生成的图形统计量。

    

    基于置换等变网络的扩散模型可以学习图数据的置换不变分布。然而，相对于非不变模型，我们发现这些不变模型遇到了更大的学习挑战，因为1）它们的目标分布更具模态性；2）它们的最优一步去噪得分是具有更多成分的高斯混合物的得分函数。受到这个分析的启发，我们提出了一种非不变的扩散模型，称为“SwinGNN”，它采用了一种高效的边到边的2-WL消息传递网络，并利用SwinTransformers中的移动窗口自注意力。此外，通过系统性的实验和剖析，我们确定了几种关键的训练和采样技术，显著提高了图生成样本的质量。最后，我们引入了一种简单的后处理技巧，即随机置换生成的图，可以证明将任何图转换成图形统计量。

    Diffusion models based on permutation-equivariant networks can learn permutation-invariant distributions for graph data. However, in comparison to their non-invariant counterparts, we have found that these invariant models encounter greater learning challenges since 1) their effective target distributions exhibit more modes; 2) their optimal one-step denoising scores are the score functions of Gaussian mixtures with more components. Motivated by this analysis, we propose a non-invariant diffusion model, called $\textit{SwinGNN}$, which employs an efficient edge-to-edge 2-WL message passing network and utilizes shifted window based self-attention inspired by SwinTransformers. Further, through systematic ablations, we identify several critical training and sampling techniques that significantly improve the sample quality of graph generation. At last, we introduce a simple post-processing trick, $\textit{i.e.}$, randomly permuting the generated graphs, which provably converts any graph ge
    
[^84]: 使用集合型反馈的在线学习

    Online Learning with Set-Valued Feedback. (arXiv:2306.06247v1 [cs.LG])

    [http://arxiv.org/abs/2306.06247](http://arxiv.org/abs/2306.06247)

    本文研究了一种在线多类分类的变体，其中使用集合型反馈。通过引入新的组合维度，该论文表明确定性和随机性的在线可学习性在实现设置下不等价，并将在线多标签排名和在线多标签分类等实际学习设置作为其特定实例。

    

    本文研究了在线多类分类的一种变体，其中学习器预测单个标签，但接收到一个标签的集合作为反馈。在该模型中，如果学习器没有输出包含在反馈集合中的标签，则会受到惩罚。我们表明，与具有单标签反馈的在线多类学习不同，在实现设置中使用集合型反馈时，确定性和随机化的在线可学习性\textit{不等价}。因此，我们提供了两个新的组合维度，分别命名为集合小石和度量破裂维度，严格描述了确定性和随机化的在线可学习性。此外，我们表明度量破裂维度在悟性设置下严格描述在线可学习性。最后，我们证明了在线多标签排名和在线多标签分类等实际学习设置是我们通用在线学习框架的具体实例。

    We study a variant of online multiclass classification where the learner predicts a single label but receives a \textit{set of labels} as feedback. In this model, the learner is penalized for not outputting a label contained in the revealed set. We show that unlike online multiclass learning with single-label feedback, deterministic and randomized online learnability are \textit{not equivalent} even in the realizable setting with set-valued feedback. Accordingly, we give two new combinatorial dimensions, named the Set Littlestone and Measure Shattering dimension, that tightly characterize deterministic and randomized online learnability respectively in the realizable setting. In addition, we show that the Measure Shattering dimension tightly characterizes online learnability in the agnostic setting. Finally, we show that practical learning settings like online multilabel ranking and online multilabel classification are specific instances of our general online learning framework.
    
[^85]: 剪枝与低秩参数高效微调相遇

    Pruning Meets Low-Rank Parameter-Efficient Fine-Tuning. (arXiv:2305.18403v1 [cs.LG])

    [http://arxiv.org/abs/2305.18403](http://arxiv.org/abs/2305.18403)

    本论文提出了一种名为LoRAPrune的框架，可以高效微调和部署大型预训练模型，通过利用低秩自适应的值和梯度来设计PEFT感知的剪枝准则，并提出了一个迭代剪枝过程来去除冗余参数，实验结果表明与最先进的方法相比，可以显著降低模型大小和推理时间，同时保持竞争性的准确性。

    

    大型预训练模型（LPM）在各种任务中表现出卓越的性能。虽然出现了参数高效微调（PEFT）来便宜地微调这些大型模型用于下游任务，但它们的部署仍然受到巨大的模型规模和计算成本的制约。神经网络剪枝通过删除冗余参数来提供模型压缩的解决方案，但大多数现有方法依赖于计算参数梯度。然而，对于LPM而言，获得梯度是计算上禁止的，这需要探索替代方法。为此，我们提出了一种用于LPM高效微调和部署的统一框架，称为LoRAPrune。我们首先设计了一个PEFT感知的剪枝准则，该准则利用了低秩自适应（LoRA）的值和梯度，而不是预训练参数的梯度进行重要性评估。然后，我们提出了一个迭代剪枝过程来基于剪枝准则去除冗余参数。各种基准数据集上的实验结果表明，与最先进的方法相比，我们的框架可以显著降低模型大小和推理时间，同时保持竞争性的准确性。

    Large pre-trained models (LPMs), such as LLaMA and ViT-G, have shown exceptional performance across various tasks. Although parameter-efficient fine-tuning (PEFT) has emerged to cheaply fine-tune these large models on downstream tasks, their deployment is still hindered by the vast model scale and computational costs. Neural network pruning offers a solution for model compression by removing redundant parameters, but most existing methods rely on computing parameter gradients. However, obtaining the gradients is computationally prohibitive for LPMs, which necessitates the exploration of alternative approaches. To this end, we propose a unified framework for efficient fine-tuning and deployment of LPMs, termed LoRAPrune. We first design a PEFT-aware pruning criterion, which utilizes the values and gradients of Low-Rank Adaption (LoRA), rather than the gradients of pre-trained parameters for importance estimation. We then propose an iterative pruning procedure to remove redundant paramet
    
[^86]: Forward-Forward算法训练的网络中的突现表征

    Emergent representations in networks trained with the Forward-Forward algorithm. (arXiv:2305.18353v1 [cs.NE])

    [http://arxiv.org/abs/2305.18353](http://arxiv.org/abs/2305.18353)

    研究表明使用Forward-Forward算法训练的网络内部表征具有高稀疏度，类别特定的集合，这与生物学观察到的皮层表征相似。

    

    Backpropagation算法被广泛用于训练神经网络，但其缺乏生物学上的现实性。为了寻找一种更具生物学可行性的替代方案，并避免反向传播梯度，而是使用本地学习规则，最近介绍的Forward-Forward算法将Backpropagation的传递替换为两个前向传递。本研究表明，使用Forward-Forward算法获得的内部表征组织为稳健的，类别特定的集合，由极少量的有效单元(高稀疏度)组成。这与感觉处理过程中观察到的皮层表征非常相似。虽然在使用标准Backpropagation进行训练的模型中没有发现，但是在使用与Forward-Forward相同的训练目标进行优化的网络中也出现了稀疏性。这些结果表明，Forward-Forward提议的学习过程可能更接近生物学学习的现实情况。

    The Backpropagation algorithm, widely used to train neural networks, has often been criticised for its lack of biological realism. In an attempt to find a more biologically plausible alternative, and avoid to back-propagate gradients in favour of using local learning rules, the recently introduced Forward-Forward algorithm replaces the traditional forward and backward passes of Backpropagation with two forward passes. In this work, we show that internal representations obtained with the Forward-Forward algorithm organize into robust, category-specific ensembles, composed by an extremely low number of active units (high sparsity). This is remarkably similar to what is observed in cortical representations during sensory processing. While not found in models trained with standard Backpropagation, sparsity emerges also in networks optimized by Backpropagation, on the same training objective of Forward-Forward. These results suggest that the learning procedure proposed by Forward-Forward ma
    
[^87]: DOCTOR：基于可穿戴医疗传感器的多疾病检测持续学习框架

    DOCTOR: A Multi-Disease Detection Continual Learning Framework Based on Wearable Medical Sensors. (arXiv:2305.05738v1 [cs.LG])

    [http://arxiv.org/abs/2305.05738](http://arxiv.org/abs/2305.05738)

    DOCTOR是一种基于可穿戴医疗传感器的多疾病检测持续学习框架，采用了多头深度神经网络和Exemplar-replay风格的CL算法。它可以不断地学习新任务，并在内存使用、电池消耗和检测复杂度方面优于传统的ML驱动疾病检测方法。

    

    现代机器学习（ML）和边缘设备中的可穿戴医疗传感器（WMS）的进步使得智能医疗的ML驱动疾病检测成为可能。传统的ML驱动疾病检测方法依赖于为每种疾病和相应的WMS数据定制个别模型。然而，这种方法缺乏对分布变化和新任务分类的适应性。同时，为了检测每个新疾病，需要从头开始重新构建和训练模型。针对这些挑战，我们提出了基于WMS的多疾病检测持续学习框架DOCTOR。它采用了多头深度神经网络（DNN）和一种Exemplar-replay风格的CL算法。CL算法使得框架能够不断地学习新任务，其中涉及不同的数据分布、分类类别和疾病检测任务。DOCTOR在使用来自实际WMS的公共数据集进行四种常见疾病检测方面取得了最先进的性能。同时，在内存使用、电池消耗和检测复杂度方面，DOCTOR也优于基线方法。

    Modern advances in machine learning (ML) and wearable medical sensors (WMSs) in edge devices have enabled ML-driven disease detection for smart healthcare. Conventional ML-driven disease detection methods rely on customizing individual models for each disease and its corresponding WMS data. However, such methods lack adaptability to distribution shifts and new task classification classes. Also, they need to be rearchitected and retrained from scratch for each new disease. Moreover, installing multiple ML models in an edge device consumes excessive memory, drains the battery faster, and complicates the detection process. To address these challenges, we propose DOCTOR, a multi-disease detection continual learning (CL) framework based on WMSs. It employs a multi-headed deep neural network (DNN) and an exemplar-replay-style CL algorithm. The CL algorithm enables the framework to continually learn new missions where different data distributions, classification classes, and disease detection
    
[^88]: 使用联合扩散注意力模型将高场和超高场MRI图像合成PET图像

    Synthesizing PET images from High-field and Ultra-high-field MR images Using Joint Diffusion Attention Model. (arXiv:2305.03901v1 [cs.LG])

    [http://arxiv.org/abs/2305.03901](http://arxiv.org/abs/2305.03901)

    本文提出了一种方法，使用联合扩散注意力模型来合成PET图像，以解决PET成像成本高且涉及辐射暴露的缺陷。该方法相比现有方法具有更好的性能和噪声敏感度更低。

    

    MRI和PET是诊断脑部疾病的重要工具，因为它们提供了有关脑结构和功能的互补信息。然而，PET扫描成本高且涉及辐射暴露，导致PET缺乏。此外，同时进行超高场MRI和PET目前几乎不可行。超高场成像在临床和学术环境中都被证明是有价值的，特别是在认知神经影像学领域。为此，我们提出了一种从高场和超高场MRI合成PET的方法。从统计的角度来看，联合概率分布（JPD）是描绘PET和MRI之间相关性的最直接和基本的方法。本文提出了一种新的联合扩散注意力模型，该模型具有联合概率分布和注意策略，命名为JDAM。JDAM具有扩散过程和采样过程。扩散过程涉及将PET逐渐扩散到高斯PET，采样过程从高场和超高场MRI中选择适当的特征。实验结果表明，JDAM优于最先进的PET合成方法，并且对噪声 lesss 敏感。

    MRI and PET are crucial diagnostic tools for brain diseases, as they provide complementary information on brain structure and function. However, PET scanning is costly and involves radioactive exposure, resulting in a lack of PET. Moreover, simultaneous PET and MRI at ultra-high-field are currently hardly infeasible. Ultra-high-field imaging has unquestionably proven valuable in both clinical and academic settings, especially in the field of cognitive neuroimaging. These motivate us to propose a method for synthetic PET from high-filed MRI and ultra-high-field MRI. From a statistical perspective, the joint probability distribution (JPD) is the most direct and fundamental means of portraying the correlation between PET and MRI. This paper proposes a novel joint diffusion attention model which has the joint probability distribution and attention strategy, named JDAM. JDAM has a diffusion process and a sampling process. The diffusion process involves the gradual diffusion of PET to Gaussi
    
[^89]: MPAS-O与全球漂流器数据集的动态数据同化方法

    Dynamic Data Assimilation of MPAS-O and the Global Drifter Dataset. (arXiv:2301.05551v2 [physics.ao-ph] UPDATED)

    [http://arxiv.org/abs/2301.05551](http://arxiv.org/abs/2301.05551)

    本研究提出了一种新的动态数据同化方法，将全球漂流器数据集与海洋预测模型相结合，通过利用地球系统模型的动态和模式，提高了海洋温度预测的准确性。

    

    本研究提出了一种新的方法，将现场浮标测量结果与地球系统模型（ESMs）相结合，以提高海洋温度预测的准确性。该技术利用ESMs中确定的动态和模式来改善浮标测量的准确性，同时保留季节性等特征。使用这种技术，可以纠正MPAS-O模型产生的本地温度预测误差。我们证明了我们的方法相对于其他插值和数据同化方法能够提高准确性。我们将我们的方法应用于将跨尺度海洋预测模型（MPAS-O）与全球漂流器计划的现场海洋浮标数据集同化的情况。

    In this study, we propose a new method for combining in situ buoy measurements with Earth system models (ESMs) to improve the accuracy of temperature predictions in the ocean. The technique utilizes the dynamics and modes identified in ESMs to improve the accuracy of buoy measurements while still preserving features such as seasonality. Using this technique, errors in localized temperature predictions made by the MPAS-O model can be corrected. We demonstrate that our approach improves accuracy compared to other interpolation and data assimilation methods. We apply our method to assimilate the Model for Prediction Across Scales Ocean component (MPAS-O) with the Global Drifter Program's in-situ ocean buoy dataset.
    
[^90]: RFold：基于解耦优化方法的RNA二级结构预测

    RFold: RNA Secondary Structure Prediction with Decoupled Optimization. (arXiv:2212.14041v2 [q-bio.BM] UPDATED)

    [http://arxiv.org/abs/2212.14041](http://arxiv.org/abs/2212.14041)

    所提出的RFold方法采用解耦优化过程和注意力机制进行简单又有效的RNA二级结构预测，具有较高的准确性和速度。

    

    核糖核酸（RNA）的二级结构比三级结构更稳定和更易于在细胞中访问，因此对于功能预测至关重要。尽管深度学习在这个领域中显示出了很好的结果，但当前的方法存在泛化性差和复杂性高的问题。在这项工作中，我们提出了一种简单而有效的RNA二级结构预测方法RFold。RFold引入了一种解耦优化的过程，将传统的约束满足问题分解为逐行和逐列优化，简化了求解过程，同时保证了输出的有效性。此外，RFold采用注意力地图作为信息表示，而不是设计手工特征。广泛的实验表明，RFold具有竞争性能，并且比现有最先进的方法具有约8倍的推理效率。代码和Colab演示可在\href{this http URL}{this http UR}上找到。

    The secondary structure of ribonucleic acid (RNA) is more stable and accessible in the cell than its tertiary structure, making it essential for functional prediction. Although deep learning has shown promising results in this field, current methods suffer from poor generalization and high complexity. In this work, we present RFold, a simple yet effective RNA secondary structure prediction in an end-to-end manner. RFold introduces a decoupled optimization process that decomposes the vanilla constraint satisfaction problem into row-wise and column-wise optimization, simplifying the solving process while guaranteeing the validity of the output. Moreover, RFold adopts attention maps as informative representations instead of designing hand-crafted features. Extensive experiments demonstrate that RFold achieves competitive performance and about eight times faster inference efficiency than the state-of-the-art method. The code and Colab demo are available in \href{this http URL}{this http UR
    
[^91]: 具有未知测量噪声的物理信息神经网络

    Physics-informed neural networks with unknown measurement noise. (arXiv:2211.15498v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.15498](http://arxiv.org/abs/2211.15498)

    这篇论文提出了一种解决物理信息神经网络在存在非高斯噪声情况下失效的问题的方法，即通过同时训练一个能量模型来学习正确的噪声分布。通过多个例子的实验证明了该方法的改进性能。

    

    物理信息神经网络(PINNs)是一种既能找到解决方案又能识别偏微分方程参数的灵活方法。大多数相关的研究都假设数据是无噪声的，或者是受弱高斯噪声污染的。我们展示了标准PINN框架在非高斯噪声情况下失效的问题，并提出了一种解决这个根本性问题的方法，即同时训练一个能量模型(Energy-Based Model, EBM)来学习正确的噪声分布。我们通过多个例子展示了我们方法的改进性能。

    Physics-informed neural networks (PINNs) constitute a flexible approach to both finding solutions and identifying parameters of partial differential equations. Most works on the topic assume noiseless data, or data contaminated by weak Gaussian noise. We show that the standard PINN framework breaks down in case of non-Gaussian noise. We give a way of resolving this fundamental issue and we propose to jointly train an energy-based model (EBM) to learn the correct noise distribution. We illustrate the improved performance of our approach using multiple examples.
    
[^92]: 多视角数据中缺失值的插补问题解决方法

    Imputation of missing values in multi-view data. (arXiv:2210.14484v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.14484](http://arxiv.org/abs/2210.14484)

    本文提出了一种基于StaPLR算法的新的多视角数据插补算法，通过在降维空间中执行插补以解决计算挑战，并在模拟数据集中得到了竞争性结果。

    

    多视角数据是指由多个不同特征集描述的数据。在处理多视角数据时，若出现缺失值，则一个视角中的所有特征极有可能同时缺失，因而导致非常大量的缺失数据问题。本文提出了一种新的多视角学习算法中的插补方法，它基于堆叠惩罚逻辑回归(StaPLR)算法，在降维空间中执行插补，以解决固有的多视角计算挑战。实验结果表明，该方法在模拟数据集上具有竞争性结果，而且具有更低的计算成本，从而可以使用先进的插补算法，例如missForest。

    Data for which a set of objects is described by multiple distinct feature sets (called views) is known as multi-view data. When missing values occur in multi-view data, all features in a view are likely to be missing simultaneously. This leads to very large quantities of missing data which, especially when combined with high-dimensionality, makes the application of conditional imputation methods computationally infeasible. We introduce a new imputation method based on the existing stacked penalized logistic regression (StaPLR) algorithm for multi-view learning. It performs imputation in a dimension-reduced space to address computational challenges inherent to the multi-view context. We compare the performance of the new imputation method with several existing imputation algorithms in simulated data sets. The results show that the new imputation method leads to competitive results at a much lower computational cost, and makes the use of advanced imputation algorithms such as missForest 
    
[^93]: 使用70万人日的可穿戴数据进行自监督学习的人体活动识别

    Self-supervised Learning for Human Activity Recognition Using 700,000 Person-days of Wearable Data. (arXiv:2206.02909v2 [eess.SP] UPDATED)

    [http://arxiv.org/abs/2206.02909](http://arxiv.org/abs/2206.02909)

    本研究利用700,000人日的未标记可穿戴传感器数据，通过自监督学习技术，成功构建了一种能够在多个数据集上泛化且效果显著优于基线模型的人体活动识别模型，有望帮助研究人员和开发者开发高性能的可定制和泛化的活动分类器。

    

    由于缺乏大规模标记数据集，深度学习在人体活动识别方面的进展相对有限。在本研究中，我们利用自监督学习技术对UK-Biobank活动追踪器数据集进行了分析，这是迄今为止最大的数据集，包含超过70万人日的未标记可穿戴传感器数据。我们得到的活动识别模型在七个基准数据集上始终优于强基线模型，F1相对改善2.5%-100%（中位数18.4%），改进最大的是规模较小的数据集。与之前的研究不同的是，我们的结果可以泛化到外部数据集、设备和环境。我们的开源模型将帮助研究人员和开发者构建具有高性能的可定制和泛化的活动分类器。

    Advances in deep learning for human activity recognition have been relatively limited due to the lack of large labelled datasets. In this study, we leverage self-supervised learning techniques on the UK-Biobank activity tracker dataset--the largest of its kind to date--containing more than 700,000 person-days of unlabelled wearable sensor data. Our resulting activity recognition model consistently outperformed strong baselines across seven benchmark datasets, with an F1 relative improvement of 2.5%-100% (median 18.4%), the largest improvements occurring in the smaller datasets. In contrast to previous studies, our results generalise across external datasets, devices, and environments. Our open-source model will help researchers and developers to build customisable and generalisable activity classifiers with high performance.
    

